Epoch: 1| Step: 0
Training loss: 5.5296180171001925
Validation loss: 5.86912112621553

Epoch: 6| Step: 1
Training loss: 5.705271695727585
Validation loss: 5.866637968224355

Epoch: 6| Step: 2
Training loss: 5.553605758988437
Validation loss: 5.8641866365719455

Epoch: 6| Step: 3
Training loss: 6.5933079865177024
Validation loss: 5.861819395726278

Epoch: 6| Step: 4
Training loss: 6.852243944162562
Validation loss: 5.85938850909901

Epoch: 6| Step: 5
Training loss: 6.597480188869786
Validation loss: 5.857112491785926

Epoch: 6| Step: 6
Training loss: 5.442261814132471
Validation loss: 5.854829698621961

Epoch: 6| Step: 7
Training loss: 6.335397417448389
Validation loss: 5.852663175167669

Epoch: 6| Step: 8
Training loss: 5.002121284634291
Validation loss: 5.850549831797913

Epoch: 6| Step: 9
Training loss: 6.62189511651174
Validation loss: 5.848461706376555

Epoch: 6| Step: 10
Training loss: 5.7593291522481636
Validation loss: 5.846271344952635

Epoch: 6| Step: 11
Training loss: 4.852309803681974
Validation loss: 5.843893283984539

Epoch: 6| Step: 12
Training loss: 6.02228825115747
Validation loss: 5.841531995598674

Epoch: 6| Step: 13
Training loss: 6.296401846173423
Validation loss: 5.839234482571146

Epoch: 2| Step: 0
Training loss: 5.667281884100827
Validation loss: 5.836614648633283

Epoch: 6| Step: 1
Training loss: 6.23733641385093
Validation loss: 5.834162689470624

Epoch: 6| Step: 2
Training loss: 6.87178491496063
Validation loss: 5.8314188494943595

Epoch: 6| Step: 3
Training loss: 6.344024201278416
Validation loss: 5.828454929589112

Epoch: 6| Step: 4
Training loss: 5.507644023077066
Validation loss: 5.825559458791424

Epoch: 6| Step: 5
Training loss: 5.522557038702954
Validation loss: 5.822517185690842

Epoch: 6| Step: 6
Training loss: 5.8138419622325825
Validation loss: 5.819193578435071

Epoch: 6| Step: 7
Training loss: 6.170627593483578
Validation loss: 5.815837817813696

Epoch: 6| Step: 8
Training loss: 5.938035800249024
Validation loss: 5.8124766742416005

Epoch: 6| Step: 9
Training loss: 5.968031914940146
Validation loss: 5.808737217102586

Epoch: 6| Step: 10
Training loss: 5.136889552768655
Validation loss: 5.805028783007839

Epoch: 6| Step: 11
Training loss: 6.302906262182035
Validation loss: 5.801260770593064

Epoch: 6| Step: 12
Training loss: 5.5778947029337695
Validation loss: 5.797220197546365

Epoch: 6| Step: 13
Training loss: 5.797832399670412
Validation loss: 5.793010400273822

Epoch: 3| Step: 0
Training loss: 6.835399811443029
Validation loss: 5.7887011649912985

Epoch: 6| Step: 1
Training loss: 5.919384112926545
Validation loss: 5.784182572835047

Epoch: 6| Step: 2
Training loss: 4.707428341652889
Validation loss: 5.779549783422234

Epoch: 6| Step: 3
Training loss: 5.898180095790804
Validation loss: 5.774863239557069

Epoch: 6| Step: 4
Training loss: 6.50763576675163
Validation loss: 5.770041795928508

Epoch: 6| Step: 5
Training loss: 6.114928704233708
Validation loss: 5.764935790843328

Epoch: 6| Step: 6
Training loss: 6.333039661759736
Validation loss: 5.759702844063082

Epoch: 6| Step: 7
Training loss: 6.771129175227511
Validation loss: 5.754050776782985

Epoch: 6| Step: 8
Training loss: 4.692578222550569
Validation loss: 5.748318246563744

Epoch: 6| Step: 9
Training loss: 5.150566529158619
Validation loss: 5.742431552397657

Epoch: 6| Step: 10
Training loss: 4.900670468917684
Validation loss: 5.736551923134421

Epoch: 6| Step: 11
Training loss: 6.521899963828301
Validation loss: 5.730481065192118

Epoch: 6| Step: 12
Training loss: 5.2334668638522075
Validation loss: 5.7240582620253395

Epoch: 6| Step: 13
Training loss: 5.9990252656730485
Validation loss: 5.717931303195372

Epoch: 4| Step: 0
Training loss: 5.330997352829853
Validation loss: 5.71138103830995

Epoch: 6| Step: 1
Training loss: 6.437238965714181
Validation loss: 5.704617852738648

Epoch: 6| Step: 2
Training loss: 5.722058282538682
Validation loss: 5.697238898081093

Epoch: 6| Step: 3
Training loss: 4.8358073425032755
Validation loss: 5.690281533649275

Epoch: 6| Step: 4
Training loss: 5.5256346739360795
Validation loss: 5.682497724182148

Epoch: 6| Step: 5
Training loss: 4.512663507008941
Validation loss: 5.675469246620218

Epoch: 6| Step: 6
Training loss: 5.843770562610046
Validation loss: 5.667820738164058

Epoch: 6| Step: 7
Training loss: 6.781199090300691
Validation loss: 5.6599622596228345

Epoch: 6| Step: 8
Training loss: 5.664869285213445
Validation loss: 5.652193641734485

Epoch: 6| Step: 9
Training loss: 6.579716650708698
Validation loss: 5.644184683573814

Epoch: 6| Step: 10
Training loss: 5.651871646338888
Validation loss: 5.636107039926679

Epoch: 6| Step: 11
Training loss: 6.096500969093838
Validation loss: 5.627732637472691

Epoch: 6| Step: 12
Training loss: 5.5529804852797255
Validation loss: 5.619342077712705

Epoch: 6| Step: 13
Training loss: 5.935120437029966
Validation loss: 5.61074679149834

Epoch: 5| Step: 0
Training loss: 5.916223249699356
Validation loss: 5.602657847690919

Epoch: 6| Step: 1
Training loss: 6.378405689752448
Validation loss: 5.5940347098241

Epoch: 6| Step: 2
Training loss: 4.639846479572778
Validation loss: 5.585880732748046

Epoch: 6| Step: 3
Training loss: 5.58528647730529
Validation loss: 5.577919807542431

Epoch: 6| Step: 4
Training loss: 6.31657504750878
Validation loss: 5.570189115736993

Epoch: 6| Step: 5
Training loss: 5.6929777825593915
Validation loss: 5.562003781477068

Epoch: 6| Step: 6
Training loss: 5.790969184573484
Validation loss: 5.554096374677425

Epoch: 6| Step: 7
Training loss: 5.623234450566254
Validation loss: 5.5463143651903

Epoch: 6| Step: 8
Training loss: 4.54441845789793
Validation loss: 5.538112714982213

Epoch: 6| Step: 9
Training loss: 5.878833575132193
Validation loss: 5.530671859958262

Epoch: 6| Step: 10
Training loss: 5.013155034898747
Validation loss: 5.522937167472688

Epoch: 6| Step: 11
Training loss: 6.025992676566833
Validation loss: 5.515155804699434

Epoch: 6| Step: 12
Training loss: 5.6849574180222815
Validation loss: 5.507852035633075

Epoch: 6| Step: 13
Training loss: 5.9381472586144435
Validation loss: 5.500024564283597

Epoch: 6| Step: 0
Training loss: 5.68312256423158
Validation loss: 5.4924933039549595

Epoch: 6| Step: 1
Training loss: 5.179504851606232
Validation loss: 5.484861897503738

Epoch: 6| Step: 2
Training loss: 5.965866271026323
Validation loss: 5.477442142442746

Epoch: 6| Step: 3
Training loss: 4.954034860117929
Validation loss: 5.469914484930528

Epoch: 6| Step: 4
Training loss: 6.244589332779105
Validation loss: 5.462417802112207

Epoch: 6| Step: 5
Training loss: 5.2220724345881075
Validation loss: 5.455239921489539

Epoch: 6| Step: 6
Training loss: 5.594247636023916
Validation loss: 5.4479610327038

Epoch: 6| Step: 7
Training loss: 5.449024484104393
Validation loss: 5.44072355984149

Epoch: 6| Step: 8
Training loss: 4.94296001387129
Validation loss: 5.433635259013133

Epoch: 6| Step: 9
Training loss: 5.876988825082662
Validation loss: 5.426490951492581

Epoch: 6| Step: 10
Training loss: 4.533061329778282
Validation loss: 5.41943650463693

Epoch: 6| Step: 11
Training loss: 6.34713218990536
Validation loss: 5.41283895768833

Epoch: 6| Step: 12
Training loss: 6.2166947078669
Validation loss: 5.40584614151167

Epoch: 6| Step: 13
Training loss: 5.3656024841298295
Validation loss: 5.399165691868845

Epoch: 7| Step: 0
Training loss: 6.453839057043393
Validation loss: 5.392495447262118

Epoch: 6| Step: 1
Training loss: 5.631333578931128
Validation loss: 5.385644412313213

Epoch: 6| Step: 2
Training loss: 6.249124694566607
Validation loss: 5.378948624277081

Epoch: 6| Step: 3
Training loss: 4.949996393375817
Validation loss: 5.372409018646594

Epoch: 6| Step: 4
Training loss: 5.458168473799513
Validation loss: 5.365821690509976

Epoch: 6| Step: 5
Training loss: 5.1625063769137185
Validation loss: 5.359625718727814

Epoch: 6| Step: 6
Training loss: 5.492457853909991
Validation loss: 5.353362838233092

Epoch: 6| Step: 7
Training loss: 5.200619022497523
Validation loss: 5.34693320127671

Epoch: 6| Step: 8
Training loss: 6.2301078093922575
Validation loss: 5.340697221470406

Epoch: 6| Step: 9
Training loss: 5.20044371105679
Validation loss: 5.334388489455673

Epoch: 6| Step: 10
Training loss: 4.993574018564442
Validation loss: 5.327523892112036

Epoch: 6| Step: 11
Training loss: 4.24347544977254
Validation loss: 5.320965682464571

Epoch: 6| Step: 12
Training loss: 5.837430260055843
Validation loss: 5.314688527217477

Epoch: 6| Step: 13
Training loss: 5.1122575846982405
Validation loss: 5.308079065594021

Epoch: 8| Step: 0
Training loss: 5.3251543909176355
Validation loss: 5.301640829970527

Epoch: 6| Step: 1
Training loss: 6.753801193876398
Validation loss: 5.295330771494155

Epoch: 6| Step: 2
Training loss: 5.581731917709043
Validation loss: 5.289072236766333

Epoch: 6| Step: 3
Training loss: 5.66924332025172
Validation loss: 5.281992722752431

Epoch: 6| Step: 4
Training loss: 5.711283828524958
Validation loss: 5.275775999389247

Epoch: 6| Step: 5
Training loss: 5.3145223919365066
Validation loss: 5.268795157133831

Epoch: 6| Step: 6
Training loss: 5.21270474916832
Validation loss: 5.26271506479407

Epoch: 6| Step: 7
Training loss: 4.490081027856708
Validation loss: 5.256366593273191

Epoch: 6| Step: 8
Training loss: 5.653044240025679
Validation loss: 5.249844654751939

Epoch: 6| Step: 9
Training loss: 4.164157773300323
Validation loss: 5.244625549817282

Epoch: 6| Step: 10
Training loss: 5.041846448146696
Validation loss: 5.239028790087985

Epoch: 6| Step: 11
Training loss: 5.952907127738881
Validation loss: 5.233379455330771

Epoch: 6| Step: 12
Training loss: 4.801547182594344
Validation loss: 5.228436311375066

Epoch: 6| Step: 13
Training loss: 5.2374304209163896
Validation loss: 5.2228687654948045

Epoch: 9| Step: 0
Training loss: 5.142853320589613
Validation loss: 5.217883253170528

Epoch: 6| Step: 1
Training loss: 5.285239975316134
Validation loss: 5.212540653963673

Epoch: 6| Step: 2
Training loss: 5.8008660820817175
Validation loss: 5.207643427614181

Epoch: 6| Step: 3
Training loss: 6.333556154581123
Validation loss: 5.2019128924542715

Epoch: 6| Step: 4
Training loss: 6.197119431284625
Validation loss: 5.196595395431198

Epoch: 6| Step: 5
Training loss: 5.180564380373468
Validation loss: 5.1912764319422005

Epoch: 6| Step: 6
Training loss: 6.008617570408511
Validation loss: 5.186046718494373

Epoch: 6| Step: 7
Training loss: 5.151748634425943
Validation loss: 5.18110983198434

Epoch: 6| Step: 8
Training loss: 4.985698464454784
Validation loss: 5.176082716505435

Epoch: 6| Step: 9
Training loss: 5.375751531535716
Validation loss: 5.1704935647188925

Epoch: 6| Step: 10
Training loss: 5.502689570931481
Validation loss: 5.165952504955639

Epoch: 6| Step: 11
Training loss: 4.465202150286135
Validation loss: 5.161402199366474

Epoch: 6| Step: 12
Training loss: 3.5094936225116857
Validation loss: 5.156460597814153

Epoch: 6| Step: 13
Training loss: 4.7389614940913445
Validation loss: 5.15193282217453

Epoch: 10| Step: 0
Training loss: 4.757292921136978
Validation loss: 5.147616408249817

Epoch: 6| Step: 1
Training loss: 4.5931171837726055
Validation loss: 5.142702156461371

Epoch: 6| Step: 2
Training loss: 5.958262872168148
Validation loss: 5.138386154785937

Epoch: 6| Step: 3
Training loss: 5.302414599589276
Validation loss: 5.133686798278823

Epoch: 6| Step: 4
Training loss: 4.498227724124364
Validation loss: 5.128741410592474

Epoch: 6| Step: 5
Training loss: 5.676569569523192
Validation loss: 5.124524660474268

Epoch: 6| Step: 6
Training loss: 4.988231924555463
Validation loss: 5.119603083394878

Epoch: 6| Step: 7
Training loss: 4.606379786905433
Validation loss: 5.114883517632256

Epoch: 6| Step: 8
Training loss: 5.081969886075048
Validation loss: 5.110334471539076

Epoch: 6| Step: 9
Training loss: 5.505891592114859
Validation loss: 5.105362680661831

Epoch: 6| Step: 10
Training loss: 5.661747236931577
Validation loss: 5.101202476458947

Epoch: 6| Step: 11
Training loss: 5.251649688205777
Validation loss: 5.09578715584461

Epoch: 6| Step: 12
Training loss: 5.41925319636376
Validation loss: 5.090993185917582

Epoch: 6| Step: 13
Training loss: 5.7989146302279595
Validation loss: 5.086691711100815

Epoch: 11| Step: 0
Training loss: 4.833065332458532
Validation loss: 5.082057381048908

Epoch: 6| Step: 1
Training loss: 5.677554647030668
Validation loss: 5.076826068348545

Epoch: 6| Step: 2
Training loss: 5.290827086318756
Validation loss: 5.071726879464871

Epoch: 6| Step: 3
Training loss: 5.09592134031135
Validation loss: 5.066518970060082

Epoch: 6| Step: 4
Training loss: 5.809125022988819
Validation loss: 5.061280719880227

Epoch: 6| Step: 5
Training loss: 5.124750456898696
Validation loss: 5.05662449981134

Epoch: 6| Step: 6
Training loss: 4.161996411169394
Validation loss: 5.051110882585435

Epoch: 6| Step: 7
Training loss: 5.3285932139400956
Validation loss: 5.04598928263571

Epoch: 6| Step: 8
Training loss: 4.99207498008709
Validation loss: 5.040407711926236

Epoch: 6| Step: 9
Training loss: 5.467402177658566
Validation loss: 5.035158554404131

Epoch: 6| Step: 10
Training loss: 5.94733521870201
Validation loss: 5.030056324132172

Epoch: 6| Step: 11
Training loss: 5.1164811207350205
Validation loss: 5.024439876330676

Epoch: 6| Step: 12
Training loss: 5.2063295502555595
Validation loss: 5.019489863085297

Epoch: 6| Step: 13
Training loss: 4.004323053762831
Validation loss: 5.014330957472806

Epoch: 12| Step: 0
Training loss: 5.290266477510955
Validation loss: 5.009059645574037

Epoch: 6| Step: 1
Training loss: 5.523791786065146
Validation loss: 5.003964473674487

Epoch: 6| Step: 2
Training loss: 5.612383447469157
Validation loss: 4.998618093894798

Epoch: 6| Step: 3
Training loss: 5.376551914176952
Validation loss: 4.993360434349545

Epoch: 6| Step: 4
Training loss: 3.926805535296615
Validation loss: 4.987870858919789

Epoch: 6| Step: 5
Training loss: 4.729407395385117
Validation loss: 4.982586706274443

Epoch: 6| Step: 6
Training loss: 5.022837554084997
Validation loss: 4.977585715796913

Epoch: 6| Step: 7
Training loss: 4.784338259166569
Validation loss: 4.972725387536114

Epoch: 6| Step: 8
Training loss: 5.827992128386513
Validation loss: 4.967117489232073

Epoch: 6| Step: 9
Training loss: 5.385836655591486
Validation loss: 4.961996579198902

Epoch: 6| Step: 10
Training loss: 5.466564504707765
Validation loss: 4.957008003038066

Epoch: 6| Step: 11
Training loss: 5.140461000186034
Validation loss: 4.951193480033812

Epoch: 6| Step: 12
Training loss: 4.276849643264742
Validation loss: 4.946435464372533

Epoch: 6| Step: 13
Training loss: 4.68168829176297
Validation loss: 4.941066660916409

Epoch: 13| Step: 0
Training loss: 5.357767737138488
Validation loss: 4.936379220970814

Epoch: 6| Step: 1
Training loss: 4.789154499906493
Validation loss: 4.93118638971428

Epoch: 6| Step: 2
Training loss: 4.398529864843915
Validation loss: 4.925918936160128

Epoch: 6| Step: 3
Training loss: 4.700120137079319
Validation loss: 4.92021730956178

Epoch: 6| Step: 4
Training loss: 4.717768080654431
Validation loss: 4.915570535618761

Epoch: 6| Step: 5
Training loss: 5.392630118478975
Validation loss: 4.9104599435178065

Epoch: 6| Step: 6
Training loss: 4.792847374558317
Validation loss: 4.905428937173372

Epoch: 6| Step: 7
Training loss: 5.075690522218997
Validation loss: 4.9008586442632485

Epoch: 6| Step: 8
Training loss: 5.62188295254614
Validation loss: 4.8959297441228875

Epoch: 6| Step: 9
Training loss: 5.074146202690586
Validation loss: 4.89238154155339

Epoch: 6| Step: 10
Training loss: 5.40727268314379
Validation loss: 4.8856867516967935

Epoch: 6| Step: 11
Training loss: 4.316789787824469
Validation loss: 4.881438218060486

Epoch: 6| Step: 12
Training loss: 5.261996232881434
Validation loss: 4.87644216610442

Epoch: 6| Step: 13
Training loss: 5.2790399927097456
Validation loss: 4.87088141938364

Epoch: 14| Step: 0
Training loss: 5.2987347154156135
Validation loss: 4.867122153735943

Epoch: 6| Step: 1
Training loss: 4.748685152876778
Validation loss: 4.862081054317342

Epoch: 6| Step: 2
Training loss: 5.216401811077657
Validation loss: 4.855784865482724

Epoch: 6| Step: 3
Training loss: 5.234762513349292
Validation loss: 4.851066166730757

Epoch: 6| Step: 4
Training loss: 5.329910113523239
Validation loss: 4.846436967369588

Epoch: 6| Step: 5
Training loss: 4.492799508242567
Validation loss: 4.841437134196144

Epoch: 6| Step: 6
Training loss: 4.814854826040928
Validation loss: 4.836952542550432

Epoch: 6| Step: 7
Training loss: 4.781111970791533
Validation loss: 4.8322556817974265

Epoch: 6| Step: 8
Training loss: 4.903521319601569
Validation loss: 4.827974121633314

Epoch: 6| Step: 9
Training loss: 5.080627012830784
Validation loss: 4.821966199822077

Epoch: 6| Step: 10
Training loss: 4.870100248899007
Validation loss: 4.8171441924946565

Epoch: 6| Step: 11
Training loss: 4.361875849017394
Validation loss: 4.81260327645331

Epoch: 6| Step: 12
Training loss: 4.904349183624367
Validation loss: 4.809231362316123

Epoch: 6| Step: 13
Training loss: 5.291326897393792
Validation loss: 4.803134772762961

Epoch: 15| Step: 0
Training loss: 5.204219668596704
Validation loss: 4.798003106519471

Epoch: 6| Step: 1
Training loss: 5.3799710019829785
Validation loss: 4.793791601074293

Epoch: 6| Step: 2
Training loss: 5.420000175391613
Validation loss: 4.7897803311558595

Epoch: 6| Step: 3
Training loss: 5.2180432966138675
Validation loss: 4.783841995060415

Epoch: 6| Step: 4
Training loss: 5.418116957350163
Validation loss: 4.777875602938033

Epoch: 6| Step: 5
Training loss: 4.719278066026364
Validation loss: 4.772493076495955

Epoch: 6| Step: 6
Training loss: 4.557037846354303
Validation loss: 4.767713278907554

Epoch: 6| Step: 7
Training loss: 4.242502218413349
Validation loss: 4.764024275971171

Epoch: 6| Step: 8
Training loss: 5.149254139341767
Validation loss: 4.759616119495366

Epoch: 6| Step: 9
Training loss: 4.359811193595295
Validation loss: 4.752473956549609

Epoch: 6| Step: 10
Training loss: 4.693694230928051
Validation loss: 4.748493758857147

Epoch: 6| Step: 11
Training loss: 4.349026336442819
Validation loss: 4.745745744753765

Epoch: 6| Step: 12
Training loss: 4.490049593169444
Validation loss: 4.740552139476705

Epoch: 6| Step: 13
Training loss: 5.06238471005876
Validation loss: 4.7354858236749475

Epoch: 16| Step: 0
Training loss: 5.479097353807468
Validation loss: 4.728766952404936

Epoch: 6| Step: 1
Training loss: 4.566640151195166
Validation loss: 4.723681737953847

Epoch: 6| Step: 2
Training loss: 4.237508930208142
Validation loss: 4.719174667011216

Epoch: 6| Step: 3
Training loss: 5.5555664740561115
Validation loss: 4.714217461742845

Epoch: 6| Step: 4
Training loss: 4.61920524697133
Validation loss: 4.709210181943436

Epoch: 6| Step: 5
Training loss: 4.513561793808557
Validation loss: 4.704768792341885

Epoch: 6| Step: 6
Training loss: 5.350695106769806
Validation loss: 4.700250433614386

Epoch: 6| Step: 7
Training loss: 4.536271463334453
Validation loss: 4.695145725159443

Epoch: 6| Step: 8
Training loss: 5.484321094041525
Validation loss: 4.69094252590691

Epoch: 6| Step: 9
Training loss: 4.605830701690708
Validation loss: 4.685425159293428

Epoch: 6| Step: 10
Training loss: 5.104474158334575
Validation loss: 4.680811879088083

Epoch: 6| Step: 11
Training loss: 4.61900601019492
Validation loss: 4.6764731685298715

Epoch: 6| Step: 12
Training loss: 4.365921410210202
Validation loss: 4.671280090490994

Epoch: 6| Step: 13
Training loss: 4.202249542161866
Validation loss: 4.66668392359858

Epoch: 17| Step: 0
Training loss: 5.1780347762135355
Validation loss: 4.663257352597644

Epoch: 6| Step: 1
Training loss: 4.097162818837262
Validation loss: 4.659256546899325

Epoch: 6| Step: 2
Training loss: 4.857738943147368
Validation loss: 4.654523764184062

Epoch: 6| Step: 3
Training loss: 5.064605086842304
Validation loss: 4.649690757230895

Epoch: 6| Step: 4
Training loss: 4.608527878327554
Validation loss: 4.6443258956115505

Epoch: 6| Step: 5
Training loss: 5.245692711425735
Validation loss: 4.638974736549401

Epoch: 6| Step: 6
Training loss: 4.673652438389933
Validation loss: 4.635031500540927

Epoch: 6| Step: 7
Training loss: 4.984280289374962
Validation loss: 4.630214466595816

Epoch: 6| Step: 8
Training loss: 4.278899278368659
Validation loss: 4.625414374406803

Epoch: 6| Step: 9
Training loss: 3.527264802203441
Validation loss: 4.620762782795164

Epoch: 6| Step: 10
Training loss: 5.212253936155711
Validation loss: 4.616349731106217

Epoch: 6| Step: 11
Training loss: 4.803282394262616
Validation loss: 4.611788532690493

Epoch: 6| Step: 12
Training loss: 5.461436935092824
Validation loss: 4.607117853487587

Epoch: 6| Step: 13
Training loss: 4.260908600527683
Validation loss: 4.602607129211036

Epoch: 18| Step: 0
Training loss: 4.270764953562092
Validation loss: 4.597706066586617

Epoch: 6| Step: 1
Training loss: 4.964599795466941
Validation loss: 4.593660781928183

Epoch: 6| Step: 2
Training loss: 4.740351062119626
Validation loss: 4.588582408549513

Epoch: 6| Step: 3
Training loss: 5.255101586257374
Validation loss: 4.5840934238755615

Epoch: 6| Step: 4
Training loss: 5.06654064791381
Validation loss: 4.580300570402147

Epoch: 6| Step: 5
Training loss: 4.251652564595242
Validation loss: 4.5750431107398954

Epoch: 6| Step: 6
Training loss: 5.130039621538482
Validation loss: 4.570071969943744

Epoch: 6| Step: 7
Training loss: 4.260661720497039
Validation loss: 4.565322542888228

Epoch: 6| Step: 8
Training loss: 4.259067959259608
Validation loss: 4.561104007864617

Epoch: 6| Step: 9
Training loss: 5.335802380930149
Validation loss: 4.556177993575207

Epoch: 6| Step: 10
Training loss: 4.375250236984219
Validation loss: 4.551652109538858

Epoch: 6| Step: 11
Training loss: 4.3924059530925295
Validation loss: 4.547075719434041

Epoch: 6| Step: 12
Training loss: 5.015795553284507
Validation loss: 4.542288443090325

Epoch: 6| Step: 13
Training loss: 4.169854864435224
Validation loss: 4.538059283520911

Epoch: 19| Step: 0
Training loss: 4.348409445230422
Validation loss: 4.533715062104525

Epoch: 6| Step: 1
Training loss: 4.256770407165085
Validation loss: 4.529524656651516

Epoch: 6| Step: 2
Training loss: 4.004468091296754
Validation loss: 4.525317831802643

Epoch: 6| Step: 3
Training loss: 4.2541909591075875
Validation loss: 4.520975816769586

Epoch: 6| Step: 4
Training loss: 5.0381399803568305
Validation loss: 4.517181374664358

Epoch: 6| Step: 5
Training loss: 4.131953534170601
Validation loss: 4.512137327827846

Epoch: 6| Step: 6
Training loss: 4.798761748498007
Validation loss: 4.507205510166409

Epoch: 6| Step: 7
Training loss: 4.182981416001191
Validation loss: 4.503072537415057

Epoch: 6| Step: 8
Training loss: 4.558071757081079
Validation loss: 4.499437791531296

Epoch: 6| Step: 9
Training loss: 5.38709017086527
Validation loss: 4.495223830905124

Epoch: 6| Step: 10
Training loss: 5.108606869881551
Validation loss: 4.490112780915347

Epoch: 6| Step: 11
Training loss: 5.077292412214973
Validation loss: 4.486039370083568

Epoch: 6| Step: 12
Training loss: 4.742377338663133
Validation loss: 4.481344619099659

Epoch: 6| Step: 13
Training loss: 4.70113292593961
Validation loss: 4.476276985548017

Epoch: 20| Step: 0
Training loss: 4.557150853479309
Validation loss: 4.471878557183792

Epoch: 6| Step: 1
Training loss: 4.736477325291754
Validation loss: 4.467350525008926

Epoch: 6| Step: 2
Training loss: 4.220322605475452
Validation loss: 4.462263579388019

Epoch: 6| Step: 3
Training loss: 4.145630082303156
Validation loss: 4.457724603944554

Epoch: 6| Step: 4
Training loss: 4.297813507237508
Validation loss: 4.45403750701903

Epoch: 6| Step: 5
Training loss: 3.5955935849522
Validation loss: 4.449270907334393

Epoch: 6| Step: 6
Training loss: 5.21302838105965
Validation loss: 4.44534970375766

Epoch: 6| Step: 7
Training loss: 4.5766799260498665
Validation loss: 4.440412917453991

Epoch: 6| Step: 8
Training loss: 5.519869200773905
Validation loss: 4.436725495137338

Epoch: 6| Step: 9
Training loss: 4.883761626503869
Validation loss: 4.431453615145766

Epoch: 6| Step: 10
Training loss: 3.879293216945209
Validation loss: 4.426737130783918

Epoch: 6| Step: 11
Training loss: 4.229968942298231
Validation loss: 4.422835929709898

Epoch: 6| Step: 12
Training loss: 4.82351672049102
Validation loss: 4.418670445669841

Epoch: 6| Step: 13
Training loss: 4.923045573226441
Validation loss: 4.4140386620162

Epoch: 21| Step: 0
Training loss: 4.022568455143848
Validation loss: 4.409312921921102

Epoch: 6| Step: 1
Training loss: 3.8843531785200116
Validation loss: 4.404886472136102

Epoch: 6| Step: 2
Training loss: 4.635238861217091
Validation loss: 4.399900438164862

Epoch: 6| Step: 3
Training loss: 4.978786863688102
Validation loss: 4.395495156150778

Epoch: 6| Step: 4
Training loss: 5.021890784798427
Validation loss: 4.390584671722227

Epoch: 6| Step: 5
Training loss: 3.75643419775724
Validation loss: 4.38613741910224

Epoch: 6| Step: 6
Training loss: 4.423603057188603
Validation loss: 4.382099893791408

Epoch: 6| Step: 7
Training loss: 4.948212988831111
Validation loss: 4.377911770384232

Epoch: 6| Step: 8
Training loss: 4.929675505755021
Validation loss: 4.373487047444247

Epoch: 6| Step: 9
Training loss: 4.738899712639021
Validation loss: 4.36850152352791

Epoch: 6| Step: 10
Training loss: 4.256678102896634
Validation loss: 4.363980174969783

Epoch: 6| Step: 11
Training loss: 4.906358073799735
Validation loss: 4.3594198828498

Epoch: 6| Step: 12
Training loss: 4.1651369465710735
Validation loss: 4.355044074231505

Epoch: 6| Step: 13
Training loss: 4.186945636550316
Validation loss: 4.350946644202129

Epoch: 22| Step: 0
Training loss: 4.205577035835357
Validation loss: 4.345760438233954

Epoch: 6| Step: 1
Training loss: 4.325252970976317
Validation loss: 4.341628473642267

Epoch: 6| Step: 2
Training loss: 4.564451035648858
Validation loss: 4.337405669316172

Epoch: 6| Step: 3
Training loss: 4.942177596973263
Validation loss: 4.332484944752698

Epoch: 6| Step: 4
Training loss: 4.188882400300802
Validation loss: 4.328343391646688

Epoch: 6| Step: 5
Training loss: 3.488862163363048
Validation loss: 4.323526282778113

Epoch: 6| Step: 6
Training loss: 4.503787671899586
Validation loss: 4.31912656652221

Epoch: 6| Step: 7
Training loss: 4.608027477818261
Validation loss: 4.315284861816075

Epoch: 6| Step: 8
Training loss: 4.183018350078068
Validation loss: 4.31052049180233

Epoch: 6| Step: 9
Training loss: 5.54444802071136
Validation loss: 4.306170273380979

Epoch: 6| Step: 10
Training loss: 4.387967537425165
Validation loss: 4.3017647404349715

Epoch: 6| Step: 11
Training loss: 3.936557233055439
Validation loss: 4.297171158265606

Epoch: 6| Step: 12
Training loss: 4.355799367356365
Validation loss: 4.292849436366831

Epoch: 6| Step: 13
Training loss: 4.702017314663205
Validation loss: 4.288422620762745

Epoch: 23| Step: 0
Training loss: 3.5508584663547906
Validation loss: 4.283922758007419

Epoch: 6| Step: 1
Training loss: 4.636482213453841
Validation loss: 4.2799020951799545

Epoch: 6| Step: 2
Training loss: 4.296355614916463
Validation loss: 4.276140602940427

Epoch: 6| Step: 3
Training loss: 3.8322878254923642
Validation loss: 4.271979902235659

Epoch: 6| Step: 4
Training loss: 4.815509202123117
Validation loss: 4.267533188735338

Epoch: 6| Step: 5
Training loss: 4.335869755946014
Validation loss: 4.2635168285315865

Epoch: 6| Step: 6
Training loss: 3.7540053276142085
Validation loss: 4.258605155306715

Epoch: 6| Step: 7
Training loss: 4.974284993840941
Validation loss: 4.254263515783535

Epoch: 6| Step: 8
Training loss: 5.1640665628529785
Validation loss: 4.250266048107534

Epoch: 6| Step: 9
Training loss: 4.944691888758678
Validation loss: 4.245802171247765

Epoch: 6| Step: 10
Training loss: 4.706564827124325
Validation loss: 4.241419058107206

Epoch: 6| Step: 11
Training loss: 4.652763956280324
Validation loss: 4.237426184027251

Epoch: 6| Step: 12
Training loss: 3.3304209065697674
Validation loss: 4.2317548765224

Epoch: 6| Step: 13
Training loss: 3.9164958402567014
Validation loss: 4.2276466281336464

Epoch: 24| Step: 0
Training loss: 5.239284661074031
Validation loss: 4.2226380128140235

Epoch: 6| Step: 1
Training loss: 4.468745945215053
Validation loss: 4.218831530124611

Epoch: 6| Step: 2
Training loss: 4.0418674904131375
Validation loss: 4.214451669976838

Epoch: 6| Step: 3
Training loss: 3.5566210507938845
Validation loss: 4.2102553948131005

Epoch: 6| Step: 4
Training loss: 4.114575246811015
Validation loss: 4.205650601278157

Epoch: 6| Step: 5
Training loss: 4.968494336730303
Validation loss: 4.2013628360721675

Epoch: 6| Step: 6
Training loss: 4.001888306271071
Validation loss: 4.1971674109284836

Epoch: 6| Step: 7
Training loss: 4.290423957132162
Validation loss: 4.192446012958771

Epoch: 6| Step: 8
Training loss: 4.297760473394245
Validation loss: 4.188185773274867

Epoch: 6| Step: 9
Training loss: 4.518692822444163
Validation loss: 4.183843031199278

Epoch: 6| Step: 10
Training loss: 4.395384031839939
Validation loss: 4.17972847511433

Epoch: 6| Step: 11
Training loss: 4.549638989557604
Validation loss: 4.1754614645418755

Epoch: 6| Step: 12
Training loss: 4.11741264060664
Validation loss: 4.170085489843652

Epoch: 6| Step: 13
Training loss: 3.7057990225960746
Validation loss: 4.16593807843981

Epoch: 25| Step: 0
Training loss: 3.8486318213174315
Validation loss: 4.162095989824549

Epoch: 6| Step: 1
Training loss: 3.807053474597811
Validation loss: 4.157607198752701

Epoch: 6| Step: 2
Training loss: 4.27356180013753
Validation loss: 4.1533251153263535

Epoch: 6| Step: 3
Training loss: 4.366464845104135
Validation loss: 4.149330804482877

Epoch: 6| Step: 4
Training loss: 4.199134265138489
Validation loss: 4.144741214823189

Epoch: 6| Step: 5
Training loss: 4.501805261264814
Validation loss: 4.140626957730964

Epoch: 6| Step: 6
Training loss: 4.124969019917993
Validation loss: 4.13618317361883

Epoch: 6| Step: 7
Training loss: 4.4902169591060686
Validation loss: 4.1318930436613925

Epoch: 6| Step: 8
Training loss: 4.783719490936812
Validation loss: 4.127439124561286

Epoch: 6| Step: 9
Training loss: 5.040442368000721
Validation loss: 4.1229950627369805

Epoch: 6| Step: 10
Training loss: 4.6059381635642
Validation loss: 4.118602569828044

Epoch: 6| Step: 11
Training loss: 4.093034754579695
Validation loss: 4.114061282232934

Epoch: 6| Step: 12
Training loss: 4.127035159132027
Validation loss: 4.10909267369491

Epoch: 6| Step: 13
Training loss: 3.119080697608409
Validation loss: 4.104997592728622

Epoch: 26| Step: 0
Training loss: 3.706437444208661
Validation loss: 4.100427088939218

Epoch: 6| Step: 1
Training loss: 4.318779395703142
Validation loss: 4.095925449539782

Epoch: 6| Step: 2
Training loss: 3.885109787890793
Validation loss: 4.092395412760842

Epoch: 6| Step: 3
Training loss: 4.6168745680359935
Validation loss: 4.087443962063012

Epoch: 6| Step: 4
Training loss: 4.2740141150063415
Validation loss: 4.083084793052462

Epoch: 6| Step: 5
Training loss: 4.027387320933076
Validation loss: 4.079635320958246

Epoch: 6| Step: 6
Training loss: 4.253465025326961
Validation loss: 4.075119899085799

Epoch: 6| Step: 7
Training loss: 4.8552519058578145
Validation loss: 4.071300520910906

Epoch: 6| Step: 8
Training loss: 4.445257149671882
Validation loss: 4.0666098908593655

Epoch: 6| Step: 9
Training loss: 3.825895695749671
Validation loss: 4.062097108865648

Epoch: 6| Step: 10
Training loss: 4.014953082084867
Validation loss: 4.0573099680313565

Epoch: 6| Step: 11
Training loss: 3.9295670052895217
Validation loss: 4.053132922327303

Epoch: 6| Step: 12
Training loss: 4.507089328771873
Validation loss: 4.048477641036333

Epoch: 6| Step: 13
Training loss: 4.041764143459811
Validation loss: 4.044184474018937

Epoch: 27| Step: 0
Training loss: 4.320739393889905
Validation loss: 4.039546757978903

Epoch: 6| Step: 1
Training loss: 4.276337415509232
Validation loss: 4.035081880566689

Epoch: 6| Step: 2
Training loss: 3.58279034840207
Validation loss: 4.030381121381912

Epoch: 6| Step: 3
Training loss: 4.151334451507308
Validation loss: 4.026387517697178

Epoch: 6| Step: 4
Training loss: 5.180984449771531
Validation loss: 4.0217542565476325

Epoch: 6| Step: 5
Training loss: 3.7474789092200145
Validation loss: 4.017652699754007

Epoch: 6| Step: 6
Training loss: 3.188772209446036
Validation loss: 4.012755361890467

Epoch: 6| Step: 7
Training loss: 4.266474041961631
Validation loss: 4.00807376478466

Epoch: 6| Step: 8
Training loss: 4.092967184219017
Validation loss: 4.004368224745801

Epoch: 6| Step: 9
Training loss: 4.0888740679799405
Validation loss: 3.9995462438389233

Epoch: 6| Step: 10
Training loss: 4.393176657546243
Validation loss: 3.994911812074306

Epoch: 6| Step: 11
Training loss: 3.8411511575263244
Validation loss: 3.9909910037669647

Epoch: 6| Step: 12
Training loss: 4.348953094783833
Validation loss: 3.9863695126618017

Epoch: 6| Step: 13
Training loss: 4.198345430626022
Validation loss: 3.9815850157340997

Epoch: 28| Step: 0
Training loss: 3.1777294231580195
Validation loss: 3.977168828259444

Epoch: 6| Step: 1
Training loss: 4.509651853399238
Validation loss: 3.9727154842675567

Epoch: 6| Step: 2
Training loss: 4.318265737055801
Validation loss: 3.9682559409212326

Epoch: 6| Step: 3
Training loss: 4.339728160730025
Validation loss: 3.9635434578863533

Epoch: 6| Step: 4
Training loss: 4.112338197997815
Validation loss: 3.9594141572071284

Epoch: 6| Step: 5
Training loss: 4.357724113019367
Validation loss: 3.9549982912145913

Epoch: 6| Step: 6
Training loss: 3.6109175915501464
Validation loss: 3.95058859371177

Epoch: 6| Step: 7
Training loss: 3.642070172358141
Validation loss: 3.945764617697554

Epoch: 6| Step: 8
Training loss: 3.928428008198774
Validation loss: 3.9412932113503176

Epoch: 6| Step: 9
Training loss: 4.071662312923128
Validation loss: 3.937200645894944

Epoch: 6| Step: 10
Training loss: 4.595539393266418
Validation loss: 3.93298613961011

Epoch: 6| Step: 11
Training loss: 4.17180139140938
Validation loss: 3.927850596034539

Epoch: 6| Step: 12
Training loss: 3.7631123497558194
Validation loss: 3.923178730924328

Epoch: 6| Step: 13
Training loss: 4.296649053008262
Validation loss: 3.9188337553363115

Epoch: 29| Step: 0
Training loss: 4.601590478679267
Validation loss: 3.9142429211239365

Epoch: 6| Step: 1
Training loss: 3.512470101334466
Validation loss: 3.909656270391073

Epoch: 6| Step: 2
Training loss: 3.714233219907608
Validation loss: 3.90519694057596

Epoch: 6| Step: 3
Training loss: 3.6866763213331883
Validation loss: 3.9009090277103784

Epoch: 6| Step: 4
Training loss: 4.302045672654405
Validation loss: 3.8963679322552536

Epoch: 6| Step: 5
Training loss: 4.447323094709922
Validation loss: 3.8922692517842874

Epoch: 6| Step: 6
Training loss: 3.576176808477277
Validation loss: 3.8877446595424843

Epoch: 6| Step: 7
Training loss: 4.612180728769104
Validation loss: 3.8826042646502

Epoch: 6| Step: 8
Training loss: 3.7245563729350235
Validation loss: 3.8783873242624325

Epoch: 6| Step: 9
Training loss: 3.164018644806028
Validation loss: 3.874168614445623

Epoch: 6| Step: 10
Training loss: 3.869378596251648
Validation loss: 3.8695955838634926

Epoch: 6| Step: 11
Training loss: 4.356964867058627
Validation loss: 3.8651276827995824

Epoch: 6| Step: 12
Training loss: 4.30204678105058
Validation loss: 3.8609427743955735

Epoch: 6| Step: 13
Training loss: 4.086687825092681
Validation loss: 3.8567959176981494

Epoch: 30| Step: 0
Training loss: 3.493269443388782
Validation loss: 3.852077653439538

Epoch: 6| Step: 1
Training loss: 3.383642927264713
Validation loss: 3.8478514955816006

Epoch: 6| Step: 2
Training loss: 3.9622807679766137
Validation loss: 3.8436368186435095

Epoch: 6| Step: 3
Training loss: 4.043986700049319
Validation loss: 3.8392660146822517

Epoch: 6| Step: 4
Training loss: 3.2331288466402093
Validation loss: 3.835096195776764

Epoch: 6| Step: 5
Training loss: 3.958022630778146
Validation loss: 3.83085265264203

Epoch: 6| Step: 6
Training loss: 3.809855560208082
Validation loss: 3.8264327480404896

Epoch: 6| Step: 7
Training loss: 4.586214905233119
Validation loss: 3.822287269495915

Epoch: 6| Step: 8
Training loss: 3.571409361651393
Validation loss: 3.8173380729009865

Epoch: 6| Step: 9
Training loss: 4.220446888190296
Validation loss: 3.813424066173292

Epoch: 6| Step: 10
Training loss: 3.1857920540036098
Validation loss: 3.808799740690102

Epoch: 6| Step: 11
Training loss: 4.037402758298315
Validation loss: 3.8047460699044624

Epoch: 6| Step: 12
Training loss: 4.453866140696548
Validation loss: 3.8004630969436968

Epoch: 6| Step: 13
Training loss: 5.004663581326507
Validation loss: 3.795751554583161

Epoch: 31| Step: 0
Training loss: 3.5538314291540702
Validation loss: 3.7914350599599667

Epoch: 6| Step: 1
Training loss: 4.035022005874395
Validation loss: 3.786611407866266

Epoch: 6| Step: 2
Training loss: 4.309852782742252
Validation loss: 3.7820273196751506

Epoch: 6| Step: 3
Training loss: 4.001604950309904
Validation loss: 3.777567749324759

Epoch: 6| Step: 4
Training loss: 3.862504809725338
Validation loss: 3.7731747532491418

Epoch: 6| Step: 5
Training loss: 4.358056091087677
Validation loss: 3.7689263314685455

Epoch: 6| Step: 6
Training loss: 4.208942683958253
Validation loss: 3.764441804208121

Epoch: 6| Step: 7
Training loss: 4.000921858417518
Validation loss: 3.7595651706912276

Epoch: 6| Step: 8
Training loss: 3.425383976483883
Validation loss: 3.7554887233959793

Epoch: 6| Step: 9
Training loss: 3.5937733525056483
Validation loss: 3.7510309921376894

Epoch: 6| Step: 10
Training loss: 3.8472042534718804
Validation loss: 3.7464838285621105

Epoch: 6| Step: 11
Training loss: 3.798239505931845
Validation loss: 3.741760144556364

Epoch: 6| Step: 12
Training loss: 3.304767869193007
Validation loss: 3.7370575403729864

Epoch: 6| Step: 13
Training loss: 4.094344933064165
Validation loss: 3.732997347551724

Epoch: 32| Step: 0
Training loss: 4.129538149375598
Validation loss: 3.728936953724246

Epoch: 6| Step: 1
Training loss: 3.7434788269773
Validation loss: 3.724208725556399

Epoch: 6| Step: 2
Training loss: 4.320799429357979
Validation loss: 3.719498438811612

Epoch: 6| Step: 3
Training loss: 4.094797713764429
Validation loss: 3.715212402877728

Epoch: 6| Step: 4
Training loss: 3.705149680549146
Validation loss: 3.7107215042162935

Epoch: 6| Step: 5
Training loss: 4.408025721950912
Validation loss: 3.7060125711265224

Epoch: 6| Step: 6
Training loss: 3.4925837281334373
Validation loss: 3.7014381869820205

Epoch: 6| Step: 7
Training loss: 3.7691203629689083
Validation loss: 3.697324950824878

Epoch: 6| Step: 8
Training loss: 3.7682669461282483
Validation loss: 3.692450492404748

Epoch: 6| Step: 9
Training loss: 3.6747248851536334
Validation loss: 3.687741374074013

Epoch: 6| Step: 10
Training loss: 4.007543841126358
Validation loss: 3.6828415966759227

Epoch: 6| Step: 11
Training loss: 3.3461910856217014
Validation loss: 3.6783645962376283

Epoch: 6| Step: 12
Training loss: 3.4031273763909287
Validation loss: 3.6738949677847303

Epoch: 6| Step: 13
Training loss: 3.676238239351234
Validation loss: 3.670007888411274

Epoch: 33| Step: 0
Training loss: 3.9460951227167973
Validation loss: 3.6658806319559054

Epoch: 6| Step: 1
Training loss: 4.32739207538123
Validation loss: 3.6615355453200134

Epoch: 6| Step: 2
Training loss: 4.1513068841553435
Validation loss: 3.656999429695934

Epoch: 6| Step: 3
Training loss: 3.2384240794232735
Validation loss: 3.6522967493633587

Epoch: 6| Step: 4
Training loss: 3.668844717645437
Validation loss: 3.6484233629931655

Epoch: 6| Step: 5
Training loss: 3.618378741733365
Validation loss: 3.6440582895261424

Epoch: 6| Step: 6
Training loss: 3.9288556107621573
Validation loss: 3.640078938889323

Epoch: 6| Step: 7
Training loss: 3.3090566336107576
Validation loss: 3.6356808294091114

Epoch: 6| Step: 8
Training loss: 3.7253861399980868
Validation loss: 3.6316138693087985

Epoch: 6| Step: 9
Training loss: 3.9569017063336847
Validation loss: 3.627086389764195

Epoch: 6| Step: 10
Training loss: 4.06421801112984
Validation loss: 3.622437206976338

Epoch: 6| Step: 11
Training loss: 2.993864142485779
Validation loss: 3.6182608388570032

Epoch: 6| Step: 12
Training loss: 3.533951257858535
Validation loss: 3.613905910074266

Epoch: 6| Step: 13
Training loss: 4.138243022480719
Validation loss: 3.609591941313901

Epoch: 34| Step: 0
Training loss: 3.327613612183624
Validation loss: 3.60545302277755

Epoch: 6| Step: 1
Training loss: 3.8199047034794664
Validation loss: 3.6014190225991065

Epoch: 6| Step: 2
Training loss: 3.5614942502917004
Validation loss: 3.5974683239646623

Epoch: 6| Step: 3
Training loss: 3.3294021949638464
Validation loss: 3.5933366841906302

Epoch: 6| Step: 4
Training loss: 3.5510633837049896
Validation loss: 3.5886639637401574

Epoch: 6| Step: 5
Training loss: 3.43267511397603
Validation loss: 3.5844205419412605

Epoch: 6| Step: 6
Training loss: 4.127941123453819
Validation loss: 3.5806538225974736

Epoch: 6| Step: 7
Training loss: 3.121085194371878
Validation loss: 3.5762415430688317

Epoch: 6| Step: 8
Training loss: 3.9282286952738694
Validation loss: 3.572212097868177

Epoch: 6| Step: 9
Training loss: 4.4310414769618935
Validation loss: 3.568025709454466

Epoch: 6| Step: 10
Training loss: 3.972296024220819
Validation loss: 3.5639615546456658

Epoch: 6| Step: 11
Training loss: 3.9279411181836066
Validation loss: 3.5598476418742626

Epoch: 6| Step: 12
Training loss: 3.723637166434643
Validation loss: 3.5549981844325553

Epoch: 6| Step: 13
Training loss: 3.5367560207525752
Validation loss: 3.5505834117983732

Epoch: 35| Step: 0
Training loss: 3.6270086051054236
Validation loss: 3.545977508327286

Epoch: 6| Step: 1
Training loss: 4.193068715910539
Validation loss: 3.5419109409838474

Epoch: 6| Step: 2
Training loss: 3.9657277291581634
Validation loss: 3.5376153700204944

Epoch: 6| Step: 3
Training loss: 3.58421294187716
Validation loss: 3.5333751708978576

Epoch: 6| Step: 4
Training loss: 3.8516835779808933
Validation loss: 3.5287012224905934

Epoch: 6| Step: 5
Training loss: 3.8297620114720132
Validation loss: 3.524226312524214

Epoch: 6| Step: 6
Training loss: 3.687173602642733
Validation loss: 3.519802668722584

Epoch: 6| Step: 7
Training loss: 3.156025944679284
Validation loss: 3.5162629403478425

Epoch: 6| Step: 8
Training loss: 3.744497967673
Validation loss: 3.511589820200835

Epoch: 6| Step: 9
Training loss: 3.6118888522818353
Validation loss: 3.507221628110449

Epoch: 6| Step: 10
Training loss: 3.4437592826482764
Validation loss: 3.502932546128956

Epoch: 6| Step: 11
Training loss: 3.086988207449476
Validation loss: 3.4987440353475368

Epoch: 6| Step: 12
Training loss: 3.7042399470343548
Validation loss: 3.4948339142308997

Epoch: 6| Step: 13
Training loss: 3.5732955657566796
Validation loss: 3.490656711362607

Epoch: 36| Step: 0
Training loss: 3.2001915874348934
Validation loss: 3.486360335000892

Epoch: 6| Step: 1
Training loss: 3.6144972615982933
Validation loss: 3.482686225127388

Epoch: 6| Step: 2
Training loss: 4.050843402970624
Validation loss: 3.4786832248951134

Epoch: 6| Step: 3
Training loss: 3.7212882475445888
Validation loss: 3.4742041886401007

Epoch: 6| Step: 4
Training loss: 3.3334087999066244
Validation loss: 3.470364524225783

Epoch: 6| Step: 5
Training loss: 3.920362203563455
Validation loss: 3.465980936661655

Epoch: 6| Step: 6
Training loss: 3.744885835626368
Validation loss: 3.4621120781844725

Epoch: 6| Step: 7
Training loss: 4.0117843607706805
Validation loss: 3.4578239264904895

Epoch: 6| Step: 8
Training loss: 3.0230802576312112
Validation loss: 3.4535264232098344

Epoch: 6| Step: 9
Training loss: 3.7897349596578813
Validation loss: 3.4498756966795607

Epoch: 6| Step: 10
Training loss: 3.6151386167929895
Validation loss: 3.445125398868115

Epoch: 6| Step: 11
Training loss: 2.7741648405311037
Validation loss: 3.4416871665239386

Epoch: 6| Step: 12
Training loss: 3.617955565011537
Validation loss: 3.4372921505136254

Epoch: 6| Step: 13
Training loss: 3.7241241347031804
Validation loss: 3.433153687718432

Epoch: 37| Step: 0
Training loss: 3.301050804914395
Validation loss: 3.429206623263311

Epoch: 6| Step: 1
Training loss: 3.126861018123472
Validation loss: 3.425332979968706

Epoch: 6| Step: 2
Training loss: 3.37562724748525
Validation loss: 3.421494507791847

Epoch: 6| Step: 3
Training loss: 3.9414224614848714
Validation loss: 3.4174516442911846

Epoch: 6| Step: 4
Training loss: 3.3834082803427226
Validation loss: 3.41367599196629

Epoch: 6| Step: 5
Training loss: 3.284461493401276
Validation loss: 3.409463550642623

Epoch: 6| Step: 6
Training loss: 3.458005192520541
Validation loss: 3.4060535199255053

Epoch: 6| Step: 7
Training loss: 3.879683832481024
Validation loss: 3.4015588566730353

Epoch: 6| Step: 8
Training loss: 3.534678322536725
Validation loss: 3.3977470193437758

Epoch: 6| Step: 9
Training loss: 4.6580213211377455
Validation loss: 3.3938317435988865

Epoch: 6| Step: 10
Training loss: 3.27182338495358
Validation loss: 3.389801183138635

Epoch: 6| Step: 11
Training loss: 3.18328488963816
Validation loss: 3.385493601389438

Epoch: 6| Step: 12
Training loss: 3.7658043023313135
Validation loss: 3.3808758649124564

Epoch: 6| Step: 13
Training loss: 3.108581441704868
Validation loss: 3.3771892440789983

Epoch: 38| Step: 0
Training loss: 3.4278407936204816
Validation loss: 3.373498665115396

Epoch: 6| Step: 1
Training loss: 3.797600821989303
Validation loss: 3.368800013919342

Epoch: 6| Step: 2
Training loss: 3.8218242251999497
Validation loss: 3.365098274122278

Epoch: 6| Step: 3
Training loss: 3.012573121002577
Validation loss: 3.3608586546680757

Epoch: 6| Step: 4
Training loss: 3.1936499413868322
Validation loss: 3.357154360638421

Epoch: 6| Step: 5
Training loss: 4.005933175971807
Validation loss: 3.35276548763854

Epoch: 6| Step: 6
Training loss: 3.1427603527126466
Validation loss: 3.3487126965810554

Epoch: 6| Step: 7
Training loss: 3.7483621199336277
Validation loss: 3.344643161597059

Epoch: 6| Step: 8
Training loss: 3.8614363011212793
Validation loss: 3.3403013752407587

Epoch: 6| Step: 9
Training loss: 3.621300750050243
Validation loss: 3.336560491180363

Epoch: 6| Step: 10
Training loss: 3.3708882186313036
Validation loss: 3.3325213675208616

Epoch: 6| Step: 11
Training loss: 2.85195125908419
Validation loss: 3.328122062860903

Epoch: 6| Step: 12
Training loss: 3.314340044384337
Validation loss: 3.324433107259728

Epoch: 6| Step: 13
Training loss: 3.4429588669162667
Validation loss: 3.3206841713316892

Epoch: 39| Step: 0
Training loss: 2.667697786615435
Validation loss: 3.3168483000689934

Epoch: 6| Step: 1
Training loss: 3.2344487131168433
Validation loss: 3.3135101409598824

Epoch: 6| Step: 2
Training loss: 3.468876466937255
Validation loss: 3.3103380165495904

Epoch: 6| Step: 3
Training loss: 4.03934063129067
Validation loss: 3.3069183419251416

Epoch: 6| Step: 4
Training loss: 3.716361681366403
Validation loss: 3.3028813710465688

Epoch: 6| Step: 5
Training loss: 3.1374368000124346
Validation loss: 3.299501900216989

Epoch: 6| Step: 6
Training loss: 3.1786281311218954
Validation loss: 3.2956550112652248

Epoch: 6| Step: 7
Training loss: 3.0662636498988336
Validation loss: 3.2920801329580076

Epoch: 6| Step: 8
Training loss: 3.830985110212888
Validation loss: 3.288460272401082

Epoch: 6| Step: 9
Training loss: 3.3643310893235325
Validation loss: 3.284851374561438

Epoch: 6| Step: 10
Training loss: 3.3169400669556692
Validation loss: 3.281103342805439

Epoch: 6| Step: 11
Training loss: 3.5721312049699434
Validation loss: 3.2772628780263964

Epoch: 6| Step: 12
Training loss: 3.7509252042663404
Validation loss: 3.2735975252183467

Epoch: 6| Step: 13
Training loss: 3.476718033301098
Validation loss: 3.269692232034409

Epoch: 40| Step: 0
Training loss: 3.732192419196289
Validation loss: 3.266150266514254

Epoch: 6| Step: 1
Training loss: 3.1561091929838407
Validation loss: 3.26249332938846

Epoch: 6| Step: 2
Training loss: 3.769197028172263
Validation loss: 3.2583966482373605

Epoch: 6| Step: 3
Training loss: 3.2094911905296457
Validation loss: 3.2551832803397907

Epoch: 6| Step: 4
Training loss: 3.206565981161237
Validation loss: 3.2515978308827607

Epoch: 6| Step: 5
Training loss: 3.774112238296029
Validation loss: 3.2481519628955313

Epoch: 6| Step: 6
Training loss: 2.7796255789899114
Validation loss: 3.243795438924753

Epoch: 6| Step: 7
Training loss: 2.7822867186481024
Validation loss: 3.240332505585648

Epoch: 6| Step: 8
Training loss: 3.2339347502873665
Validation loss: 3.2368433282676023

Epoch: 6| Step: 9
Training loss: 3.3439610494873113
Validation loss: 3.2334446943579156

Epoch: 6| Step: 10
Training loss: 3.740872783309826
Validation loss: 3.230314153426234

Epoch: 6| Step: 11
Training loss: 3.294723893725948
Validation loss: 3.22651764697657

Epoch: 6| Step: 12
Training loss: 4.07269065340411
Validation loss: 3.2231998486051494

Epoch: 6| Step: 13
Training loss: 2.9473159411605407
Validation loss: 3.219572042533699

Epoch: 41| Step: 0
Training loss: 3.527936883443984
Validation loss: 3.21593527574394

Epoch: 6| Step: 1
Training loss: 3.023277416476215
Validation loss: 3.212034212971379

Epoch: 6| Step: 2
Training loss: 4.01714085567047
Validation loss: 3.2089234878605306

Epoch: 6| Step: 3
Training loss: 3.2360673245663443
Validation loss: 3.204570933924635

Epoch: 6| Step: 4
Training loss: 3.7578982781595007
Validation loss: 3.2016640409518082

Epoch: 6| Step: 5
Training loss: 3.024190015565183
Validation loss: 3.1976784152435425

Epoch: 6| Step: 6
Training loss: 3.493426280301807
Validation loss: 3.1941263971163085

Epoch: 6| Step: 7
Training loss: 3.1910046029387926
Validation loss: 3.1902867769667895

Epoch: 6| Step: 8
Training loss: 3.0875202996826028
Validation loss: 3.1869970186600804

Epoch: 6| Step: 9
Training loss: 3.371112986981613
Validation loss: 3.1832752903212005

Epoch: 6| Step: 10
Training loss: 3.466985855324551
Validation loss: 3.18018746409278

Epoch: 6| Step: 11
Training loss: 3.163667932091783
Validation loss: 3.176469854106832

Epoch: 6| Step: 12
Training loss: 2.5870525802559623
Validation loss: 3.17316573366252

Epoch: 6| Step: 13
Training loss: 3.4953920821712505
Validation loss: 3.170146314471377

Epoch: 42| Step: 0
Training loss: 3.23881896263207
Validation loss: 3.166019402826665

Epoch: 6| Step: 1
Training loss: 3.3957517337161343
Validation loss: 3.162148230166493

Epoch: 6| Step: 2
Training loss: 3.3861601653773525
Validation loss: 3.159436181969889

Epoch: 6| Step: 3
Training loss: 3.3309308613106983
Validation loss: 3.155742692621968

Epoch: 6| Step: 4
Training loss: 2.9096284323674246
Validation loss: 3.152237800163287

Epoch: 6| Step: 5
Training loss: 3.787051455687834
Validation loss: 3.149468555225437

Epoch: 6| Step: 6
Training loss: 3.6190321896279105
Validation loss: 3.1458727263622035

Epoch: 6| Step: 7
Training loss: 3.4009960847207883
Validation loss: 3.1428910236576013

Epoch: 6| Step: 8
Training loss: 2.7771739451761275
Validation loss: 3.1389554015757963

Epoch: 6| Step: 9
Training loss: 3.3759196406016247
Validation loss: 3.135895212012198

Epoch: 6| Step: 10
Training loss: 3.165511338809705
Validation loss: 3.1323769663816696

Epoch: 6| Step: 11
Training loss: 2.603793816895985
Validation loss: 3.1291570860559026

Epoch: 6| Step: 12
Training loss: 3.617002676079277
Validation loss: 3.1264614883874313

Epoch: 6| Step: 13
Training loss: 3.1804304824809555
Validation loss: 3.1228904088506737

Epoch: 43| Step: 0
Training loss: 3.2674133660550653
Validation loss: 3.1194488048287097

Epoch: 6| Step: 1
Training loss: 2.9789480026844632
Validation loss: 3.1167380918046494

Epoch: 6| Step: 2
Training loss: 3.5375164772970935
Validation loss: 3.1131062572124115

Epoch: 6| Step: 3
Training loss: 3.488053915683268
Validation loss: 3.110494159841193

Epoch: 6| Step: 4
Training loss: 3.0869460377278624
Validation loss: 3.106948378489431

Epoch: 6| Step: 5
Training loss: 3.082292862342189
Validation loss: 3.104094489536441

Epoch: 6| Step: 6
Training loss: 2.6174002034310027
Validation loss: 3.1008030035976746

Epoch: 6| Step: 7
Training loss: 3.513208940850623
Validation loss: 3.0978306788961643

Epoch: 6| Step: 8
Training loss: 3.1491548464061063
Validation loss: 3.0944452243151805

Epoch: 6| Step: 9
Training loss: 3.072672861201285
Validation loss: 3.091159378103497

Epoch: 6| Step: 10
Training loss: 3.017671355254776
Validation loss: 3.0889360241491595

Epoch: 6| Step: 11
Training loss: 3.316706164203137
Validation loss: 3.0858530282478807

Epoch: 6| Step: 12
Training loss: 3.7268965789308384
Validation loss: 3.0827305092778445

Epoch: 6| Step: 13
Training loss: 3.34617341539241
Validation loss: 3.0800427757529496

Epoch: 44| Step: 0
Training loss: 3.5800019384623987
Validation loss: 3.0768017320822465

Epoch: 6| Step: 1
Training loss: 2.744956854253609
Validation loss: 3.074170213612673

Epoch: 6| Step: 2
Training loss: 3.5066932982773946
Validation loss: 3.0709295841766004

Epoch: 6| Step: 3
Training loss: 3.657684566406609
Validation loss: 3.0676592751138676

Epoch: 6| Step: 4
Training loss: 4.228661994074702
Validation loss: 3.064145599747908

Epoch: 6| Step: 5
Training loss: 2.0301891197468467
Validation loss: 3.0606829773860125

Epoch: 6| Step: 6
Training loss: 3.1517829632563763
Validation loss: 3.0572694759224257

Epoch: 6| Step: 7
Training loss: 2.8903851383801684
Validation loss: 3.054005370276292

Epoch: 6| Step: 8
Training loss: 2.7651847876941633
Validation loss: 3.051004607571507

Epoch: 6| Step: 9
Training loss: 3.549842702040263
Validation loss: 3.047722227543951

Epoch: 6| Step: 10
Training loss: 3.203154177649121
Validation loss: 3.044731181471949

Epoch: 6| Step: 11
Training loss: 2.9113567154858724
Validation loss: 3.0413931283799216

Epoch: 6| Step: 12
Training loss: 2.989042935504287
Validation loss: 3.0386113319784753

Epoch: 6| Step: 13
Training loss: 3.0376795586154373
Validation loss: 3.0360619933550965

Epoch: 45| Step: 0
Training loss: 3.0719893441015445
Validation loss: 3.033554931203634

Epoch: 6| Step: 1
Training loss: 3.2974925253828937
Validation loss: 3.0305936568145873

Epoch: 6| Step: 2
Training loss: 3.7287470974017314
Validation loss: 3.027746502737115

Epoch: 6| Step: 3
Training loss: 3.2902774696104835
Validation loss: 3.024676079917516

Epoch: 6| Step: 4
Training loss: 2.6233070909123852
Validation loss: 3.0219098814641163

Epoch: 6| Step: 5
Training loss: 3.0624964188535344
Validation loss: 3.0188378594396386

Epoch: 6| Step: 6
Training loss: 2.873324030118369
Validation loss: 3.0158780507334093

Epoch: 6| Step: 7
Training loss: 3.104329525219167
Validation loss: 3.012912525196488

Epoch: 6| Step: 8
Training loss: 3.431802223669128
Validation loss: 3.0104939187949404

Epoch: 6| Step: 9
Training loss: 2.7092429369779563
Validation loss: 3.007776526033689

Epoch: 6| Step: 10
Training loss: 2.7744463737778817
Validation loss: 3.0050273997263113

Epoch: 6| Step: 11
Training loss: 3.7091309336170437
Validation loss: 3.00229448418188

Epoch: 6| Step: 12
Training loss: 3.326515202434645
Validation loss: 2.9996165454366643

Epoch: 6| Step: 13
Training loss: 2.9681676996259876
Validation loss: 2.9967218078134112

Epoch: 46| Step: 0
Training loss: 2.546628600763097
Validation loss: 2.9945614314380817

Epoch: 6| Step: 1
Training loss: 2.867955242760092
Validation loss: 2.992317203535906

Epoch: 6| Step: 2
Training loss: 2.8397591222775556
Validation loss: 2.989834888964446

Epoch: 6| Step: 3
Training loss: 2.731465388344617
Validation loss: 3.0094696103993397

Epoch: 6| Step: 4
Training loss: 3.3844399006574353
Validation loss: 2.986340473050556

Epoch: 6| Step: 5
Training loss: 3.13506146992799
Validation loss: 2.9812275798389085

Epoch: 6| Step: 6
Training loss: 3.6526917970028077
Validation loss: 2.979967280940049

Epoch: 6| Step: 7
Training loss: 3.1300965520329926
Validation loss: 2.977993491846082

Epoch: 6| Step: 8
Training loss: 3.6217398617459633
Validation loss: 2.977159642139627

Epoch: 6| Step: 9
Training loss: 3.2976382849953376
Validation loss: 2.975585870729234

Epoch: 6| Step: 10
Training loss: 3.0339030817151564
Validation loss: 2.9740172523412007

Epoch: 6| Step: 11
Training loss: 3.179863252398612
Validation loss: 2.9720814132809013

Epoch: 6| Step: 12
Training loss: 3.288622901516516
Validation loss: 2.9683992412888816

Epoch: 6| Step: 13
Training loss: 2.7690846845820665
Validation loss: 2.9646681447518315

Epoch: 47| Step: 0
Training loss: 2.702506286726705
Validation loss: 2.961854321365419

Epoch: 6| Step: 1
Training loss: 3.117109790110627
Validation loss: 2.9585432775083986

Epoch: 6| Step: 2
Training loss: 3.072317308499238
Validation loss: 2.9548815392698153

Epoch: 6| Step: 3
Training loss: 3.0699409861903546
Validation loss: 2.9528212887307554

Epoch: 6| Step: 4
Training loss: 3.37267336298719
Validation loss: 2.9495235193011853

Epoch: 6| Step: 5
Training loss: 3.603794556447152
Validation loss: 2.947159583440486

Epoch: 6| Step: 6
Training loss: 2.4457387339435734
Validation loss: 2.9442876218223444

Epoch: 6| Step: 7
Training loss: 3.0096737341991284
Validation loss: 2.9414240417347663

Epoch: 6| Step: 8
Training loss: 3.2268797785420475
Validation loss: 2.9383946672840717

Epoch: 6| Step: 9
Training loss: 3.6490412667916003
Validation loss: 2.935956048695384

Epoch: 6| Step: 10
Training loss: 2.7289673438824895
Validation loss: 2.9339493063239965

Epoch: 6| Step: 11
Training loss: 3.1734621183190845
Validation loss: 2.932043025495175

Epoch: 6| Step: 12
Training loss: 2.9561669561807467
Validation loss: 2.929685262043416

Epoch: 6| Step: 13
Training loss: 2.8302206631418683
Validation loss: 2.92786977029461

Epoch: 48| Step: 0
Training loss: 2.7037044190803097
Validation loss: 2.9246207271202924

Epoch: 6| Step: 1
Training loss: 2.666180168914928
Validation loss: 2.9237643438571514

Epoch: 6| Step: 2
Training loss: 3.4595743426855794
Validation loss: 2.9191742653348096

Epoch: 6| Step: 3
Training loss: 3.2631324125891434
Validation loss: 2.91570417781169

Epoch: 6| Step: 4
Training loss: 2.9225978671118407
Validation loss: 2.9132657295591775

Epoch: 6| Step: 5
Training loss: 3.6202751147859304
Validation loss: 2.910460413115013

Epoch: 6| Step: 6
Training loss: 3.0855267601453793
Validation loss: 2.908290871107077

Epoch: 6| Step: 7
Training loss: 3.4038800035208556
Validation loss: 2.905423870733307

Epoch: 6| Step: 8
Training loss: 2.949936856386089
Validation loss: 2.9030385612592475

Epoch: 6| Step: 9
Training loss: 3.3858924570507094
Validation loss: 2.901375610380424

Epoch: 6| Step: 10
Training loss: 2.8584579915110524
Validation loss: 2.8994267395845643

Epoch: 6| Step: 11
Training loss: 2.710509868390644
Validation loss: 2.8963216923278416

Epoch: 6| Step: 12
Training loss: 3.227397967557024
Validation loss: 2.895107018112923

Epoch: 6| Step: 13
Training loss: 2.1227500448329133
Validation loss: 2.892242157988252

Epoch: 49| Step: 0
Training loss: 2.6827221472516025
Validation loss: 2.8906652911703183

Epoch: 6| Step: 1
Training loss: 2.7697753798651665
Validation loss: 2.8877921580025534

Epoch: 6| Step: 2
Training loss: 3.360302890113578
Validation loss: 2.885245450077866

Epoch: 6| Step: 3
Training loss: 2.5656358093703093
Validation loss: 2.8825465547453084

Epoch: 6| Step: 4
Training loss: 3.60950340934325
Validation loss: 2.8805328701364057

Epoch: 6| Step: 5
Training loss: 2.871372090036984
Validation loss: 2.8783671108473534

Epoch: 6| Step: 6
Training loss: 2.826090718588988
Validation loss: 2.875617783279058

Epoch: 6| Step: 7
Training loss: 2.736611111348461
Validation loss: 2.8736367379736905

Epoch: 6| Step: 8
Training loss: 3.209186011287209
Validation loss: 2.8723958148881366

Epoch: 6| Step: 9
Training loss: 2.701928816715371
Validation loss: 2.8690003251928404

Epoch: 6| Step: 10
Training loss: 3.4592737198556978
Validation loss: 2.868379613586839

Epoch: 6| Step: 11
Training loss: 2.739468435529991
Validation loss: 2.8639436365891293

Epoch: 6| Step: 12
Training loss: 2.875983194495749
Validation loss: 2.8624109990083637

Epoch: 6| Step: 13
Training loss: 3.5616732524786543
Validation loss: 2.859463299497921

Epoch: 50| Step: 0
Training loss: 3.102071648228356
Validation loss: 2.8579843610224884

Epoch: 6| Step: 1
Training loss: 3.2061930036033357
Validation loss: 2.8572089741073126

Epoch: 6| Step: 2
Training loss: 2.893849157360598
Validation loss: 2.855378712679686

Epoch: 6| Step: 3
Training loss: 3.226413972775078
Validation loss: 2.8544233350598955

Epoch: 6| Step: 4
Training loss: 3.5235985425191068
Validation loss: 2.852712892126472

Epoch: 6| Step: 5
Training loss: 2.5348895245618492
Validation loss: 2.8497305223990863

Epoch: 6| Step: 6
Training loss: 2.5085007148058858
Validation loss: 2.8475378331949592

Epoch: 6| Step: 7
Training loss: 2.4499724717442617
Validation loss: 2.84403881241273

Epoch: 6| Step: 8
Training loss: 2.439152377596872
Validation loss: 2.842520842910528

Epoch: 6| Step: 9
Training loss: 3.275684978108497
Validation loss: 2.8407387632692562

Epoch: 6| Step: 10
Training loss: 2.9319078500273923
Validation loss: 2.837337039967795

Epoch: 6| Step: 11
Training loss: 3.1770755621809843
Validation loss: 2.836254652099919

Epoch: 6| Step: 12
Training loss: 3.121229720227376
Validation loss: 2.8351768685617174

Epoch: 6| Step: 13
Training loss: 3.1646676697500067
Validation loss: 2.833403521023722

Epoch: 51| Step: 0
Training loss: 2.9426944338489953
Validation loss: 2.8289360302573776

Epoch: 6| Step: 1
Training loss: 2.8460144417262976
Validation loss: 2.8271773069463677

Epoch: 6| Step: 2
Training loss: 3.3546114482529865
Validation loss: 2.8252360163759676

Epoch: 6| Step: 3
Training loss: 3.001029791516624
Validation loss: 2.8232950517685573

Epoch: 6| Step: 4
Training loss: 2.8115412455475446
Validation loss: 2.821040206678547

Epoch: 6| Step: 5
Training loss: 2.9086554632164208
Validation loss: 2.8193173330265964

Epoch: 6| Step: 6
Training loss: 2.9326703565047803
Validation loss: 2.818209736905752

Epoch: 6| Step: 7
Training loss: 3.0339862232637285
Validation loss: 2.8191663644602367

Epoch: 6| Step: 8
Training loss: 2.768666292393371
Validation loss: 2.818346728047356

Epoch: 6| Step: 9
Training loss: 2.991112259380743
Validation loss: 2.8157916128050684

Epoch: 6| Step: 10
Training loss: 3.0918621121414205
Validation loss: 2.809791772781641

Epoch: 6| Step: 11
Training loss: 3.3414853707186944
Validation loss: 2.8062907022697687

Epoch: 6| Step: 12
Training loss: 2.8989464654838333
Validation loss: 2.8062205538942937

Epoch: 6| Step: 13
Training loss: 2.4536787246402985
Validation loss: 2.8057310806946747

Epoch: 52| Step: 0
Training loss: 2.8745266068521573
Validation loss: 2.808619669306977

Epoch: 6| Step: 1
Training loss: 2.7393753108155625
Validation loss: 2.8088547289566184

Epoch: 6| Step: 2
Training loss: 3.125642634118735
Validation loss: 2.809465933443002

Epoch: 6| Step: 3
Training loss: 3.0386608025010378
Validation loss: 2.8083303696779938

Epoch: 6| Step: 4
Training loss: 2.9786603448448385
Validation loss: 2.8089292111030995

Epoch: 6| Step: 5
Training loss: 2.9157912620902806
Validation loss: 2.802321871751954

Epoch: 6| Step: 6
Training loss: 3.0022831811684183
Validation loss: 2.7971458943204537

Epoch: 6| Step: 7
Training loss: 3.178061629632239
Validation loss: 2.794860881830328

Epoch: 6| Step: 8
Training loss: 2.2404742457538385
Validation loss: 2.7892417672012337

Epoch: 6| Step: 9
Training loss: 3.1768822444793394
Validation loss: 2.7861844483769747

Epoch: 6| Step: 10
Training loss: 3.377307103293761
Validation loss: 2.784202323151657

Epoch: 6| Step: 11
Training loss: 2.640945144297395
Validation loss: 2.782245386429754

Epoch: 6| Step: 12
Training loss: 2.633582480832831
Validation loss: 2.7793885191558676

Epoch: 6| Step: 13
Training loss: 3.0046522308041195
Validation loss: 2.7783673667386957

Epoch: 53| Step: 0
Training loss: 3.292941526614932
Validation loss: 2.779083122206359

Epoch: 6| Step: 1
Training loss: 2.709958650055341
Validation loss: 2.776472810875563

Epoch: 6| Step: 2
Training loss: 2.762799128567039
Validation loss: 2.7743654373277993

Epoch: 6| Step: 3
Training loss: 3.1538442375506506
Validation loss: 2.7773043043551904

Epoch: 6| Step: 4
Training loss: 2.30473705173823
Validation loss: 2.7853814917211994

Epoch: 6| Step: 5
Training loss: 2.870232651481899
Validation loss: 2.7946736429672794

Epoch: 6| Step: 6
Training loss: 3.228695365393305
Validation loss: 2.78693835440628

Epoch: 6| Step: 7
Training loss: 3.1418220933535017
Validation loss: 2.7680455479172745

Epoch: 6| Step: 8
Training loss: 2.9169550798505983
Validation loss: 2.7637569634556733

Epoch: 6| Step: 9
Training loss: 3.4229444809517044
Validation loss: 2.7646156236324235

Epoch: 6| Step: 10
Training loss: 2.8246781224887383
Validation loss: 2.7682839810150024

Epoch: 6| Step: 11
Training loss: 2.1802839878137643
Validation loss: 2.772866074702176

Epoch: 6| Step: 12
Training loss: 2.82566338573591
Validation loss: 2.786263123326339

Epoch: 6| Step: 13
Training loss: 2.933241334108241
Validation loss: 2.786525537744019

Epoch: 54| Step: 0
Training loss: 3.1494790145918565
Validation loss: 2.781601072863303

Epoch: 6| Step: 1
Training loss: 2.7156922256348897
Validation loss: 2.7711959018454158

Epoch: 6| Step: 2
Training loss: 3.3046722051027557
Validation loss: 2.7650933338345167

Epoch: 6| Step: 3
Training loss: 2.9786059156396627
Validation loss: 2.758592605122433

Epoch: 6| Step: 4
Training loss: 2.9060549106542695
Validation loss: 2.7549747928128525

Epoch: 6| Step: 5
Training loss: 3.0281922953935503
Validation loss: 2.7523754293102254

Epoch: 6| Step: 6
Training loss: 3.2073164149823805
Validation loss: 2.7479760351316007

Epoch: 6| Step: 7
Training loss: 3.124944915285992
Validation loss: 2.746108712109918

Epoch: 6| Step: 8
Training loss: 3.1121458043556314
Validation loss: 2.7435912391188655

Epoch: 6| Step: 9
Training loss: 3.025477310229233
Validation loss: 2.7411612014779423

Epoch: 6| Step: 10
Training loss: 2.6931166397712145
Validation loss: 2.73899387259864

Epoch: 6| Step: 11
Training loss: 2.6335754194727876
Validation loss: 2.7378182085448914

Epoch: 6| Step: 12
Training loss: 1.8442837217437729
Validation loss: 2.735723951114672

Epoch: 6| Step: 13
Training loss: 2.3974040535512335
Validation loss: 2.7335140362375645

Epoch: 55| Step: 0
Training loss: 3.512059416917861
Validation loss: 2.7343134264598215

Epoch: 6| Step: 1
Training loss: 2.560837369105242
Validation loss: 2.7323374395478854

Epoch: 6| Step: 2
Training loss: 2.633471126411873
Validation loss: 2.7369109682732455

Epoch: 6| Step: 3
Training loss: 2.816810525986198
Validation loss: 2.729666632558146

Epoch: 6| Step: 4
Training loss: 2.5768307298127717
Validation loss: 2.7284350154604557

Epoch: 6| Step: 5
Training loss: 3.390104192297244
Validation loss: 2.7257786510335236

Epoch: 6| Step: 6
Training loss: 2.7885150104930614
Validation loss: 2.721723866637384

Epoch: 6| Step: 7
Training loss: 2.7949606028392133
Validation loss: 2.7207438878248333

Epoch: 6| Step: 8
Training loss: 2.617723461329542
Validation loss: 2.7184269300244286

Epoch: 6| Step: 9
Training loss: 2.7929839447248392
Validation loss: 2.716351002411208

Epoch: 6| Step: 10
Training loss: 2.507137599934899
Validation loss: 2.713859427231543

Epoch: 6| Step: 11
Training loss: 2.982408284953893
Validation loss: 2.7135995186308968

Epoch: 6| Step: 12
Training loss: 3.0535671199044763
Validation loss: 2.711017896942347

Epoch: 6| Step: 13
Training loss: 2.8977642254164704
Validation loss: 2.712461719154919

Epoch: 56| Step: 0
Training loss: 2.217777952645668
Validation loss: 2.7098061933812643

Epoch: 6| Step: 1
Training loss: 2.989288120558539
Validation loss: 2.7071701094924436

Epoch: 6| Step: 2
Training loss: 2.617730747607128
Validation loss: 2.70954098308547

Epoch: 6| Step: 3
Training loss: 2.913541281878205
Validation loss: 2.704972828125115

Epoch: 6| Step: 4
Training loss: 2.8504825585057025
Validation loss: 2.705045322995126

Epoch: 6| Step: 5
Training loss: 3.136768307419072
Validation loss: 2.7038603647874786

Epoch: 6| Step: 6
Training loss: 2.8260967927461746
Validation loss: 2.7026141939083175

Epoch: 6| Step: 7
Training loss: 2.871786062629694
Validation loss: 2.6995639166290952

Epoch: 6| Step: 8
Training loss: 2.620310363586683
Validation loss: 2.701225966111709

Epoch: 6| Step: 9
Training loss: 2.4746641952355692
Validation loss: 2.6995885276440257

Epoch: 6| Step: 10
Training loss: 3.269703193983455
Validation loss: 2.6961647492290886

Epoch: 6| Step: 11
Training loss: 2.6901741031050554
Validation loss: 2.695532055449493

Epoch: 6| Step: 12
Training loss: 3.030495775913101
Validation loss: 2.6961756406860578

Epoch: 6| Step: 13
Training loss: 3.103703987066269
Validation loss: 2.6935252727991474

Epoch: 57| Step: 0
Training loss: 2.730758367849547
Validation loss: 2.6948910738483347

Epoch: 6| Step: 1
Training loss: 2.767910890892381
Validation loss: 2.6926203602058627

Epoch: 6| Step: 2
Training loss: 2.659001888364858
Validation loss: 2.6918993877826303

Epoch: 6| Step: 3
Training loss: 2.481252855736461
Validation loss: 2.6906774647936795

Epoch: 6| Step: 4
Training loss: 2.537031282628266
Validation loss: 2.687812949596992

Epoch: 6| Step: 5
Training loss: 2.5986850164159327
Validation loss: 2.6855628698624057

Epoch: 6| Step: 6
Training loss: 3.242125434741032
Validation loss: 2.683601286839133

Epoch: 6| Step: 7
Training loss: 2.8719967622233975
Validation loss: 2.682149247521135

Epoch: 6| Step: 8
Training loss: 2.7099956888256056
Validation loss: 2.6816944729074828

Epoch: 6| Step: 9
Training loss: 2.92831885348543
Validation loss: 2.679734832968444

Epoch: 6| Step: 10
Training loss: 2.985221063808288
Validation loss: 2.679657278826563

Epoch: 6| Step: 11
Training loss: 3.328104654885731
Validation loss: 2.679341537637988

Epoch: 6| Step: 12
Training loss: 2.854009210925887
Validation loss: 2.6788643776688046

Epoch: 6| Step: 13
Training loss: 2.7080465507281524
Validation loss: 2.673614619749555

Epoch: 58| Step: 0
Training loss: 2.600212044505525
Validation loss: 2.674152006341111

Epoch: 6| Step: 1
Training loss: 3.305938844515542
Validation loss: 2.6740186097251937

Epoch: 6| Step: 2
Training loss: 3.1560560110171894
Validation loss: 2.674298769108166

Epoch: 6| Step: 3
Training loss: 3.0395185819705137
Validation loss: 2.6714921643561502

Epoch: 6| Step: 4
Training loss: 2.5001596399835817
Validation loss: 2.673239688477749

Epoch: 6| Step: 5
Training loss: 1.7189038294530754
Validation loss: 2.674036085253837

Epoch: 6| Step: 6
Training loss: 2.7761217479117364
Validation loss: 2.6733347528371425

Epoch: 6| Step: 7
Training loss: 2.8847537237398377
Validation loss: 2.6708370817716562

Epoch: 6| Step: 8
Training loss: 2.4959791273564806
Validation loss: 2.6700490322682833

Epoch: 6| Step: 9
Training loss: 3.1612545410702855
Validation loss: 2.6667072074510547

Epoch: 6| Step: 10
Training loss: 2.9894158895743903
Validation loss: 2.664882410686608

Epoch: 6| Step: 11
Training loss: 2.735608155249019
Validation loss: 2.6639920371722257

Epoch: 6| Step: 12
Training loss: 2.9454798967060385
Validation loss: 2.662006752161318

Epoch: 6| Step: 13
Training loss: 2.7167393934036337
Validation loss: 2.663498931669242

Epoch: 59| Step: 0
Training loss: 2.265927840414674
Validation loss: 2.6640560713137624

Epoch: 6| Step: 1
Training loss: 2.7792541543514835
Validation loss: 2.67369588632204

Epoch: 6| Step: 2
Training loss: 2.88124567060497
Validation loss: 2.6651839863032287

Epoch: 6| Step: 3
Training loss: 3.0790698155376535
Validation loss: 2.6647626864687837

Epoch: 6| Step: 4
Training loss: 2.5549195910377884
Validation loss: 2.661315934066365

Epoch: 6| Step: 5
Training loss: 2.62441846672995
Validation loss: 2.655388845835404

Epoch: 6| Step: 6
Training loss: 3.104434281319424
Validation loss: 2.6518468377287734

Epoch: 6| Step: 7
Training loss: 2.9579380111543974
Validation loss: 2.651145803108728

Epoch: 6| Step: 8
Training loss: 2.824226094469833
Validation loss: 2.6501224075692633

Epoch: 6| Step: 9
Training loss: 2.7770728127999766
Validation loss: 2.6505630051045244

Epoch: 6| Step: 10
Training loss: 2.8097597123986344
Validation loss: 2.650658905237004

Epoch: 6| Step: 11
Training loss: 2.8730870392544388
Validation loss: 2.6501407004137616

Epoch: 6| Step: 12
Training loss: 3.0761740451381234
Validation loss: 2.6470575779348864

Epoch: 6| Step: 13
Training loss: 2.382797391249487
Validation loss: 2.647766823559419

Epoch: 60| Step: 0
Training loss: 3.0366325175783064
Validation loss: 2.644559663801189

Epoch: 6| Step: 1
Training loss: 2.8661179379609902
Validation loss: 2.6446890922408475

Epoch: 6| Step: 2
Training loss: 2.6580884069260042
Validation loss: 2.643427653760529

Epoch: 6| Step: 3
Training loss: 3.220585420122128
Validation loss: 2.641130778914776

Epoch: 6| Step: 4
Training loss: 2.4537137048012334
Validation loss: 2.643839923721132

Epoch: 6| Step: 5
Training loss: 2.989187783757886
Validation loss: 2.640239965895063

Epoch: 6| Step: 6
Training loss: 2.7639915685787315
Validation loss: 2.6360651105568182

Epoch: 6| Step: 7
Training loss: 2.282899338717446
Validation loss: 2.6349133751013762

Epoch: 6| Step: 8
Training loss: 2.6380452754001467
Validation loss: 2.6367467958819

Epoch: 6| Step: 9
Training loss: 2.6561800779227602
Validation loss: 2.6347700589809335

Epoch: 6| Step: 10
Training loss: 2.805771981967694
Validation loss: 2.6332996947719343

Epoch: 6| Step: 11
Training loss: 2.4083125204839133
Validation loss: 2.6315085845039907

Epoch: 6| Step: 12
Training loss: 3.2759001215612957
Validation loss: 2.6315331751414837

Epoch: 6| Step: 13
Training loss: 2.640352133472524
Validation loss: 2.628254689249714

Epoch: 61| Step: 0
Training loss: 3.0523955583630302
Validation loss: 2.630624331571422

Epoch: 6| Step: 1
Training loss: 2.6929741930484683
Validation loss: 2.628731573006716

Epoch: 6| Step: 2
Training loss: 2.79635402153433
Validation loss: 2.627234975828185

Epoch: 6| Step: 3
Training loss: 2.6792614656548124
Validation loss: 2.6264857220249835

Epoch: 6| Step: 4
Training loss: 3.3675604876981295
Validation loss: 2.6243926359854264

Epoch: 6| Step: 5
Training loss: 2.009701801024353
Validation loss: 2.6256038183229458

Epoch: 6| Step: 6
Training loss: 2.4224364583566254
Validation loss: 2.621510638811845

Epoch: 6| Step: 7
Training loss: 3.252632981909032
Validation loss: 2.6263153776867183

Epoch: 6| Step: 8
Training loss: 2.5075242301705836
Validation loss: 2.629273334662838

Epoch: 6| Step: 9
Training loss: 3.146658951162588
Validation loss: 2.6276000180068344

Epoch: 6| Step: 10
Training loss: 2.794123654905303
Validation loss: 2.6263936823825764

Epoch: 6| Step: 11
Training loss: 2.898923108326311
Validation loss: 2.6195121348042267

Epoch: 6| Step: 12
Training loss: 2.427019328527262
Validation loss: 2.6196677834030755

Epoch: 6| Step: 13
Training loss: 2.322610250428756
Validation loss: 2.6181599494724392

Epoch: 62| Step: 0
Training loss: 3.3898469234327737
Validation loss: 2.6168177708855733

Epoch: 6| Step: 1
Training loss: 2.4001681268930963
Validation loss: 2.6226303818992944

Epoch: 6| Step: 2
Training loss: 2.6776254800124977
Validation loss: 2.6243598248196767

Epoch: 6| Step: 3
Training loss: 2.687238370003759
Validation loss: 2.629556561279699

Epoch: 6| Step: 4
Training loss: 2.747443050804389
Validation loss: 2.6326252826417442

Epoch: 6| Step: 5
Training loss: 3.029405799742207
Validation loss: 2.628251045582199

Epoch: 6| Step: 6
Training loss: 2.9943447852157945
Validation loss: 2.6292676445803993

Epoch: 6| Step: 7
Training loss: 2.6603121942864782
Validation loss: 2.628054416115374

Epoch: 6| Step: 8
Training loss: 2.7110032834912956
Validation loss: 2.6266502309743265

Epoch: 6| Step: 9
Training loss: 2.3065434628403776
Validation loss: 2.62105421177643

Epoch: 6| Step: 10
Training loss: 2.817669335246435
Validation loss: 2.621189909685703

Epoch: 6| Step: 11
Training loss: 2.5266570819615906
Validation loss: 2.6207346397783575

Epoch: 6| Step: 12
Training loss: 2.81134789499527
Validation loss: 2.6207072564766896

Epoch: 6| Step: 13
Training loss: 2.7330343393066068
Validation loss: 2.614817777257163

Epoch: 63| Step: 0
Training loss: 2.8312994070563184
Validation loss: 2.6136593547508435

Epoch: 6| Step: 1
Training loss: 2.5683253064815075
Validation loss: 2.6136195976362893

Epoch: 6| Step: 2
Training loss: 2.927662060272694
Validation loss: 2.619089412923406

Epoch: 6| Step: 3
Training loss: 2.7831369920871003
Validation loss: 2.613863680055058

Epoch: 6| Step: 4
Training loss: 3.0166229020065063
Validation loss: 2.6115830800333977

Epoch: 6| Step: 5
Training loss: 2.804038480083775
Validation loss: 2.6099277451502347

Epoch: 6| Step: 6
Training loss: 2.5854322049280847
Validation loss: 2.6053759145139814

Epoch: 6| Step: 7
Training loss: 2.6378199559533315
Validation loss: 2.6046998253866143

Epoch: 6| Step: 8
Training loss: 2.6575691089274773
Validation loss: 2.6027851458372493

Epoch: 6| Step: 9
Training loss: 2.456128656627188
Validation loss: 2.604139256650996

Epoch: 6| Step: 10
Training loss: 3.0754522347720274
Validation loss: 2.6068862040951233

Epoch: 6| Step: 11
Training loss: 2.0928663979878555
Validation loss: 2.600014089277191

Epoch: 6| Step: 12
Training loss: 2.9389979013160983
Validation loss: 2.6002781688610788

Epoch: 6| Step: 13
Training loss: 2.8813393403143213
Validation loss: 2.599331514912462

Epoch: 64| Step: 0
Training loss: 2.8822649510704155
Validation loss: 2.598492266516903

Epoch: 6| Step: 1
Training loss: 2.6012399834399234
Validation loss: 2.5991871082675795

Epoch: 6| Step: 2
Training loss: 2.9120487895064224
Validation loss: 2.5973518977258974

Epoch: 6| Step: 3
Training loss: 2.134768640458472
Validation loss: 2.5992136634262453

Epoch: 6| Step: 4
Training loss: 2.619839090836962
Validation loss: 2.597751778206088

Epoch: 6| Step: 5
Training loss: 2.766431443046646
Validation loss: 2.598837883450896

Epoch: 6| Step: 6
Training loss: 2.3530698488619173
Validation loss: 2.6017605665108476

Epoch: 6| Step: 7
Training loss: 2.940826804749342
Validation loss: 2.6006663385583506

Epoch: 6| Step: 8
Training loss: 2.7722769874747333
Validation loss: 2.5982180798090413

Epoch: 6| Step: 9
Training loss: 2.637284462605511
Validation loss: 2.597170248435227

Epoch: 6| Step: 10
Training loss: 3.151634694351975
Validation loss: 2.5962621786694826

Epoch: 6| Step: 11
Training loss: 2.6903774027927767
Validation loss: 2.5938311491378605

Epoch: 6| Step: 12
Training loss: 2.98128793240453
Validation loss: 2.5906967208376845

Epoch: 6| Step: 13
Training loss: 2.7018576942258474
Validation loss: 2.587459273946916

Epoch: 65| Step: 0
Training loss: 2.4562532924795044
Validation loss: 2.5869100994743617

Epoch: 6| Step: 1
Training loss: 2.509257438062586
Validation loss: 2.5845343095171573

Epoch: 6| Step: 2
Training loss: 2.9100238539514427
Validation loss: 2.58412221943129

Epoch: 6| Step: 3
Training loss: 2.1662939802615058
Validation loss: 2.579761294120649

Epoch: 6| Step: 4
Training loss: 2.8323706693154476
Validation loss: 2.5827880919761483

Epoch: 6| Step: 5
Training loss: 3.018801108612791
Validation loss: 2.581702353286444

Epoch: 6| Step: 6
Training loss: 3.0506760582757098
Validation loss: 2.578961646991091

Epoch: 6| Step: 7
Training loss: 3.0632625331175514
Validation loss: 2.580193323782944

Epoch: 6| Step: 8
Training loss: 2.052169359085439
Validation loss: 2.5869201452717276

Epoch: 6| Step: 9
Training loss: 2.670467876201833
Validation loss: 2.596700009518385

Epoch: 6| Step: 10
Training loss: 2.98365687173426
Validation loss: 2.5994819669123093

Epoch: 6| Step: 11
Training loss: 3.0168359726522542
Validation loss: 2.599344417254224

Epoch: 6| Step: 12
Training loss: 2.4976435045591874
Validation loss: 2.581387114866365

Epoch: 6| Step: 13
Training loss: 2.749157516434971
Validation loss: 2.5791436851188347

Epoch: 66| Step: 0
Training loss: 2.840672431104974
Validation loss: 2.574187398670406

Epoch: 6| Step: 1
Training loss: 3.152686193837948
Validation loss: 2.5768661970860522

Epoch: 6| Step: 2
Training loss: 3.020479396386703
Validation loss: 2.5812521262541135

Epoch: 6| Step: 3
Training loss: 2.383714548936547
Validation loss: 2.582903016049142

Epoch: 6| Step: 4
Training loss: 1.6305001417134821
Validation loss: 2.587941310554156

Epoch: 6| Step: 5
Training loss: 2.5339977279929897
Validation loss: 2.5936106755474855

Epoch: 6| Step: 6
Training loss: 2.6798431084386167
Validation loss: 2.6018204814090176

Epoch: 6| Step: 7
Training loss: 2.427148209606592
Validation loss: 2.5980195902789855

Epoch: 6| Step: 8
Training loss: 3.069508066184479
Validation loss: 2.590079901406629

Epoch: 6| Step: 9
Training loss: 3.178897243964187
Validation loss: 2.586734952254704

Epoch: 6| Step: 10
Training loss: 2.8154564471499715
Validation loss: 2.581644757421858

Epoch: 6| Step: 11
Training loss: 2.7565649739258555
Validation loss: 2.578576682241019

Epoch: 6| Step: 12
Training loss: 2.472767518539628
Validation loss: 2.5765525723604017

Epoch: 6| Step: 13
Training loss: 2.7002615342806378
Validation loss: 2.5728352542820687

Epoch: 67| Step: 0
Training loss: 2.264662860595781
Validation loss: 2.5707665132301796

Epoch: 6| Step: 1
Training loss: 2.5743205349933462
Validation loss: 2.5689878441807745

Epoch: 6| Step: 2
Training loss: 2.843793093176667
Validation loss: 2.5662418740563955

Epoch: 6| Step: 3
Training loss: 2.319103401171916
Validation loss: 2.567159169699183

Epoch: 6| Step: 4
Training loss: 2.816109354610585
Validation loss: 2.565863007484041

Epoch: 6| Step: 5
Training loss: 2.749886250310808
Validation loss: 2.5684334825236093

Epoch: 6| Step: 6
Training loss: 2.8004187611376863
Validation loss: 2.565049647544167

Epoch: 6| Step: 7
Training loss: 2.761330497677003
Validation loss: 2.5648778567068717

Epoch: 6| Step: 8
Training loss: 2.7686303829764425
Validation loss: 2.563429067020325

Epoch: 6| Step: 9
Training loss: 2.724638776723081
Validation loss: 2.5626675465711632

Epoch: 6| Step: 10
Training loss: 2.6214031827060236
Validation loss: 2.561860051145212

Epoch: 6| Step: 11
Training loss: 2.674703963111283
Validation loss: 2.56261352349625

Epoch: 6| Step: 12
Training loss: 2.635651368155593
Validation loss: 2.563753038786165

Epoch: 6| Step: 13
Training loss: 3.0395378780474114
Validation loss: 2.5582209580019724

Epoch: 68| Step: 0
Training loss: 2.273272636177534
Validation loss: 2.5645294371787375

Epoch: 6| Step: 1
Training loss: 1.9908205615986305
Validation loss: 2.5717298470591903

Epoch: 6| Step: 2
Training loss: 2.59634233100257
Validation loss: 2.575142354641289

Epoch: 6| Step: 3
Training loss: 2.929679361967864
Validation loss: 2.56463256734965

Epoch: 6| Step: 4
Training loss: 2.901936272708168
Validation loss: 2.561809772480976

Epoch: 6| Step: 5
Training loss: 2.8912052706215996
Validation loss: 2.5588140572395592

Epoch: 6| Step: 6
Training loss: 2.69951940427145
Validation loss: 2.555315179738285

Epoch: 6| Step: 7
Training loss: 2.9274757276094
Validation loss: 2.557475972315985

Epoch: 6| Step: 8
Training loss: 2.778371800379679
Validation loss: 2.5608988465919524

Epoch: 6| Step: 9
Training loss: 2.7056875265452383
Validation loss: 2.5659800678340283

Epoch: 6| Step: 10
Training loss: 2.920621062295889
Validation loss: 2.571732875501573

Epoch: 6| Step: 11
Training loss: 2.63900616926171
Validation loss: 2.577027304885007

Epoch: 6| Step: 12
Training loss: 2.5709787913945887
Validation loss: 2.575680971068965

Epoch: 6| Step: 13
Training loss: 2.9484391754744013
Validation loss: 2.5844299132214754

Epoch: 69| Step: 0
Training loss: 2.838886335719736
Validation loss: 2.5889638688203847

Epoch: 6| Step: 1
Training loss: 2.9734674818057867
Validation loss: 2.578432531028777

Epoch: 6| Step: 2
Training loss: 3.219887541708561
Validation loss: 2.57272783479665

Epoch: 6| Step: 3
Training loss: 2.725615416162021
Validation loss: 2.568676026602565

Epoch: 6| Step: 4
Training loss: 2.1620536872839207
Validation loss: 2.565409613430217

Epoch: 6| Step: 5
Training loss: 3.0499122544471113
Validation loss: 2.5618445015480344

Epoch: 6| Step: 6
Training loss: 2.2958089209872345
Validation loss: 2.558724521857359

Epoch: 6| Step: 7
Training loss: 2.444077835142203
Validation loss: 2.556485631104438

Epoch: 6| Step: 8
Training loss: 2.514082441612422
Validation loss: 2.5520660140299736

Epoch: 6| Step: 9
Training loss: 2.9488575290998225
Validation loss: 2.5504127691951997

Epoch: 6| Step: 10
Training loss: 2.466120611355206
Validation loss: 2.551560443068308

Epoch: 6| Step: 11
Training loss: 2.772901628330722
Validation loss: 2.550355175627121

Epoch: 6| Step: 12
Training loss: 2.4389819995173654
Validation loss: 2.547759497331504

Epoch: 6| Step: 13
Training loss: 2.7030999507735687
Validation loss: 2.5488320459016576

Epoch: 70| Step: 0
Training loss: 2.471067668573335
Validation loss: 2.549326413143547

Epoch: 6| Step: 1
Training loss: 2.626302486804836
Validation loss: 2.5497068797666707

Epoch: 6| Step: 2
Training loss: 3.088148189566468
Validation loss: 2.551415715508891

Epoch: 6| Step: 3
Training loss: 2.5156068031174157
Validation loss: 2.550710555416714

Epoch: 6| Step: 4
Training loss: 2.9893460240476104
Validation loss: 2.5455626868833505

Epoch: 6| Step: 5
Training loss: 2.33016980383346
Validation loss: 2.5441406175029746

Epoch: 6| Step: 6
Training loss: 2.5976171504928645
Validation loss: 2.545911626241451

Epoch: 6| Step: 7
Training loss: 2.503865686525471
Validation loss: 2.549557137522807

Epoch: 6| Step: 8
Training loss: 2.6610197438708543
Validation loss: 2.5468915381021398

Epoch: 6| Step: 9
Training loss: 2.49719376421102
Validation loss: 2.544333377461146

Epoch: 6| Step: 10
Training loss: 2.5372746672905104
Validation loss: 2.543405084243672

Epoch: 6| Step: 11
Training loss: 2.329386119933693
Validation loss: 2.545181148005325

Epoch: 6| Step: 12
Training loss: 3.1596187327744185
Validation loss: 2.5419987294848947

Epoch: 6| Step: 13
Training loss: 2.982720520615628
Validation loss: 2.5422631303869108

Epoch: 71| Step: 0
Training loss: 2.7061399723794524
Validation loss: 2.540677383589766

Epoch: 6| Step: 1
Training loss: 2.0939103250184212
Validation loss: 2.540508355485129

Epoch: 6| Step: 2
Training loss: 2.787805011979955
Validation loss: 2.5413560104212283

Epoch: 6| Step: 3
Training loss: 1.9476495515453405
Validation loss: 2.540600918025785

Epoch: 6| Step: 4
Training loss: 2.4924413856646903
Validation loss: 2.5407856732839753

Epoch: 6| Step: 5
Training loss: 2.973510940133934
Validation loss: 2.5392078377624565

Epoch: 6| Step: 6
Training loss: 2.470451637707261
Validation loss: 2.5413928640087144

Epoch: 6| Step: 7
Training loss: 2.8365844324954934
Validation loss: 2.540857222651095

Epoch: 6| Step: 8
Training loss: 2.6559957943618753
Validation loss: 2.539234722850027

Epoch: 6| Step: 9
Training loss: 2.5923129777390774
Validation loss: 2.5404324948559855

Epoch: 6| Step: 10
Training loss: 2.955173972441802
Validation loss: 2.539341055433263

Epoch: 6| Step: 11
Training loss: 2.7458318854073935
Validation loss: 2.5370688255305818

Epoch: 6| Step: 12
Training loss: 2.803227036404107
Validation loss: 2.537638729669077

Epoch: 6| Step: 13
Training loss: 3.0267045066025333
Validation loss: 2.535518140389563

Epoch: 72| Step: 0
Training loss: 2.2939496777177495
Validation loss: 2.535662882083646

Epoch: 6| Step: 1
Training loss: 2.907498983446962
Validation loss: 2.5380855617544933

Epoch: 6| Step: 2
Training loss: 2.6364536180357336
Validation loss: 2.5319312477942053

Epoch: 6| Step: 3
Training loss: 2.8162868860693147
Validation loss: 2.535493464836174

Epoch: 6| Step: 4
Training loss: 2.292102656650231
Validation loss: 2.5322727915600334

Epoch: 6| Step: 5
Training loss: 1.7451562604922106
Validation loss: 2.528385472406535

Epoch: 6| Step: 6
Training loss: 2.7452597945771324
Validation loss: 2.5351970808427464

Epoch: 6| Step: 7
Training loss: 2.8643543683648502
Validation loss: 2.533538176595298

Epoch: 6| Step: 8
Training loss: 3.1073405448776965
Validation loss: 2.5304265743367136

Epoch: 6| Step: 9
Training loss: 2.7931916261324843
Validation loss: 2.5314959104418158

Epoch: 6| Step: 10
Training loss: 2.466838241314877
Validation loss: 2.5301681530022138

Epoch: 6| Step: 11
Training loss: 2.560989958416111
Validation loss: 2.5286667754500702

Epoch: 6| Step: 12
Training loss: 2.5018983309341927
Validation loss: 2.530184046467895

Epoch: 6| Step: 13
Training loss: 3.139618517790953
Validation loss: 2.5281843411868947

Epoch: 73| Step: 0
Training loss: 2.53838707963629
Validation loss: 2.530428874891247

Epoch: 6| Step: 1
Training loss: 2.3991117741129737
Validation loss: 2.5273246705456773

Epoch: 6| Step: 2
Training loss: 2.86655629041634
Validation loss: 2.529583841783647

Epoch: 6| Step: 3
Training loss: 2.860901805377921
Validation loss: 2.528133184532117

Epoch: 6| Step: 4
Training loss: 2.483735872025954
Validation loss: 2.525144112128617

Epoch: 6| Step: 5
Training loss: 2.361932946832067
Validation loss: 2.5278333045347625

Epoch: 6| Step: 6
Training loss: 3.0252011697256713
Validation loss: 2.525277001700604

Epoch: 6| Step: 7
Training loss: 2.291068282176721
Validation loss: 2.5255002152654242

Epoch: 6| Step: 8
Training loss: 2.32728694706875
Validation loss: 2.5227156591838025

Epoch: 6| Step: 9
Training loss: 2.4444051893530925
Validation loss: 2.521964778192358

Epoch: 6| Step: 10
Training loss: 3.0747010992900736
Validation loss: 2.524571607778337

Epoch: 6| Step: 11
Training loss: 2.455216603406126
Validation loss: 2.5235225478131738

Epoch: 6| Step: 12
Training loss: 2.884315326441225
Validation loss: 2.5208782370695295

Epoch: 6| Step: 13
Training loss: 2.9409296021919378
Validation loss: 2.5220652688505107

Epoch: 74| Step: 0
Training loss: 2.718343068504404
Validation loss: 2.5292130268588577

Epoch: 6| Step: 1
Training loss: 2.5411339394354315
Validation loss: 2.520604435850782

Epoch: 6| Step: 2
Training loss: 2.7662863937307525
Validation loss: 2.5254082242741402

Epoch: 6| Step: 3
Training loss: 1.9947241098569446
Validation loss: 2.5234490267369285

Epoch: 6| Step: 4
Training loss: 2.283320284432578
Validation loss: 2.523768793961592

Epoch: 6| Step: 5
Training loss: 2.5708963490516568
Validation loss: 2.5212898051281765

Epoch: 6| Step: 6
Training loss: 2.360107510267694
Validation loss: 2.5211857373368343

Epoch: 6| Step: 7
Training loss: 2.563906957916956
Validation loss: 2.519408640478009

Epoch: 6| Step: 8
Training loss: 2.530496273144305
Validation loss: 2.5164636671117817

Epoch: 6| Step: 9
Training loss: 2.3393301423990414
Validation loss: 2.5177725713634316

Epoch: 6| Step: 10
Training loss: 2.8612541319357727
Validation loss: 2.5186056245581137

Epoch: 6| Step: 11
Training loss: 2.9818360078621367
Validation loss: 2.5186359401778735

Epoch: 6| Step: 12
Training loss: 3.3334532875094145
Validation loss: 2.5219489904907695

Epoch: 6| Step: 13
Training loss: 2.9142483813034343
Validation loss: 2.5204487551904515

Epoch: 75| Step: 0
Training loss: 2.8233729107577488
Validation loss: 2.5192480120289984

Epoch: 6| Step: 1
Training loss: 2.230153290308248
Validation loss: 2.520854734429766

Epoch: 6| Step: 2
Training loss: 2.6360536089584707
Validation loss: 2.5232128913368252

Epoch: 6| Step: 3
Training loss: 2.7569094468037894
Validation loss: 2.5239465473659237

Epoch: 6| Step: 4
Training loss: 2.901882376266067
Validation loss: 2.527294883668329

Epoch: 6| Step: 5
Training loss: 2.986559482791275
Validation loss: 2.5286007113348035

Epoch: 6| Step: 6
Training loss: 2.632444995620661
Validation loss: 2.531908193028693

Epoch: 6| Step: 7
Training loss: 2.924147594176268
Validation loss: 2.529958136291334

Epoch: 6| Step: 8
Training loss: 2.913110326907204
Validation loss: 2.5340258914876257

Epoch: 6| Step: 9
Training loss: 2.3079484014974447
Validation loss: 2.537502729167003

Epoch: 6| Step: 10
Training loss: 2.453259798464775
Validation loss: 2.5352123550139467

Epoch: 6| Step: 11
Training loss: 2.5002092273897993
Validation loss: 2.5373004922594045

Epoch: 6| Step: 12
Training loss: 1.9715981242222995
Validation loss: 2.5318810575047555

Epoch: 6| Step: 13
Training loss: 3.025164601285055
Validation loss: 2.5267805506707877

Epoch: 76| Step: 0
Training loss: 2.3705599590926445
Validation loss: 2.5207993896553047

Epoch: 6| Step: 1
Training loss: 2.9361806300881566
Validation loss: 2.5197825225205785

Epoch: 6| Step: 2
Training loss: 2.1633770129002174
Validation loss: 2.516758017955682

Epoch: 6| Step: 3
Training loss: 2.4142278225778697
Validation loss: 2.515176626491293

Epoch: 6| Step: 4
Training loss: 2.9049691279702867
Validation loss: 2.515328936797033

Epoch: 6| Step: 5
Training loss: 2.9354359294258425
Validation loss: 2.5178525788402064

Epoch: 6| Step: 6
Training loss: 3.2096987374374284
Validation loss: 2.5167134617461198

Epoch: 6| Step: 7
Training loss: 2.5183094936263246
Validation loss: 2.517381769439002

Epoch: 6| Step: 8
Training loss: 2.970199873392838
Validation loss: 2.5161955603016395

Epoch: 6| Step: 9
Training loss: 2.593907087234115
Validation loss: 2.515579081051091

Epoch: 6| Step: 10
Training loss: 2.22116816741869
Validation loss: 2.514736879639088

Epoch: 6| Step: 11
Training loss: 2.597284872712651
Validation loss: 2.512995868354616

Epoch: 6| Step: 12
Training loss: 2.3387381308991984
Validation loss: 2.508445699420241

Epoch: 6| Step: 13
Training loss: 2.6266054965737333
Validation loss: 2.509424897454344

Epoch: 77| Step: 0
Training loss: 2.815004124070936
Validation loss: 2.5093905830453687

Epoch: 6| Step: 1
Training loss: 2.608400722604063
Validation loss: 2.5140986106275447

Epoch: 6| Step: 2
Training loss: 2.726985778307087
Validation loss: 2.518365524266339

Epoch: 6| Step: 3
Training loss: 2.8999730076026946
Validation loss: 2.5092615158117306

Epoch: 6| Step: 4
Training loss: 2.7270093841279364
Validation loss: 2.5168824301263366

Epoch: 6| Step: 5
Training loss: 2.4912254844489037
Validation loss: 2.5259105268173485

Epoch: 6| Step: 6
Training loss: 2.771624421122511
Validation loss: 2.5238764551358255

Epoch: 6| Step: 7
Training loss: 2.6362856813044613
Validation loss: 2.5087521101013444

Epoch: 6| Step: 8
Training loss: 2.898953538388778
Validation loss: 2.5096480009270077

Epoch: 6| Step: 9
Training loss: 2.2666667779286676
Validation loss: 2.508551238238449

Epoch: 6| Step: 10
Training loss: 2.3639261169829218
Validation loss: 2.5076844845240656

Epoch: 6| Step: 11
Training loss: 2.2373213115925377
Validation loss: 2.507180931605405

Epoch: 6| Step: 12
Training loss: 2.4882167646115745
Validation loss: 2.5093079225055535

Epoch: 6| Step: 13
Training loss: 2.858063610759812
Validation loss: 2.507206511837687

Epoch: 78| Step: 0
Training loss: 2.3025222175843347
Validation loss: 2.50767652988721

Epoch: 6| Step: 1
Training loss: 2.818867997704516
Validation loss: 2.507672774402476

Epoch: 6| Step: 2
Training loss: 1.9721212435856614
Validation loss: 2.510171796535073

Epoch: 6| Step: 3
Training loss: 3.172952703787693
Validation loss: 2.50774913481997

Epoch: 6| Step: 4
Training loss: 2.5218219132254216
Validation loss: 2.5088879902461407

Epoch: 6| Step: 5
Training loss: 2.8332981406625453
Validation loss: 2.508293129566025

Epoch: 6| Step: 6
Training loss: 2.552864941130613
Validation loss: 2.5068639147626013

Epoch: 6| Step: 7
Training loss: 2.709101074169422
Validation loss: 2.507648957843039

Epoch: 6| Step: 8
Training loss: 2.6898037994192285
Validation loss: 2.5022186289302817

Epoch: 6| Step: 9
Training loss: 3.0327363450297415
Validation loss: 2.5057680188179146

Epoch: 6| Step: 10
Training loss: 2.115132816373974
Validation loss: 2.504534820516652

Epoch: 6| Step: 11
Training loss: 2.428052247674614
Validation loss: 2.5114639334904307

Epoch: 6| Step: 12
Training loss: 2.9397746268323672
Validation loss: 2.5129190902010943

Epoch: 6| Step: 13
Training loss: 2.6624171750076346
Validation loss: 2.505564140277863

Epoch: 79| Step: 0
Training loss: 1.6909729576587926
Validation loss: 2.504966840518202

Epoch: 6| Step: 1
Training loss: 2.780029543438367
Validation loss: 2.5074179587566623

Epoch: 6| Step: 2
Training loss: 3.2051900022369115
Validation loss: 2.5051110474115275

Epoch: 6| Step: 3
Training loss: 2.521631214407815
Validation loss: 2.5094473037025944

Epoch: 6| Step: 4
Training loss: 2.2926034457663618
Validation loss: 2.5126539736709104

Epoch: 6| Step: 5
Training loss: 2.2753293270646213
Validation loss: 2.5180949609624372

Epoch: 6| Step: 6
Training loss: 2.3030619432779473
Validation loss: 2.5263689648406085

Epoch: 6| Step: 7
Training loss: 3.1256938926886324
Validation loss: 2.5285883437646173

Epoch: 6| Step: 8
Training loss: 2.5845030525707564
Validation loss: 2.5306733655904545

Epoch: 6| Step: 9
Training loss: 2.6172485344445695
Validation loss: 2.5361077747227854

Epoch: 6| Step: 10
Training loss: 2.6302863886868346
Validation loss: 2.5293742792763014

Epoch: 6| Step: 11
Training loss: 2.9887297649009654
Validation loss: 2.525075453710433

Epoch: 6| Step: 12
Training loss: 2.3401334197978616
Validation loss: 2.5181605511495415

Epoch: 6| Step: 13
Training loss: 3.2087519649177128
Validation loss: 2.5172221482313692

Epoch: 80| Step: 0
Training loss: 2.665727917024954
Validation loss: 2.5161263734326487

Epoch: 6| Step: 1
Training loss: 2.9469434841446613
Validation loss: 2.5129865311305823

Epoch: 6| Step: 2
Training loss: 2.6752519292828922
Validation loss: 2.5109552910963155

Epoch: 6| Step: 3
Training loss: 2.4014944668765064
Validation loss: 2.509848824592702

Epoch: 6| Step: 4
Training loss: 3.030082556478002
Validation loss: 2.5064323327258466

Epoch: 6| Step: 5
Training loss: 2.750212227695034
Validation loss: 2.5035351554119516

Epoch: 6| Step: 6
Training loss: 2.847102442343743
Validation loss: 2.501881288940952

Epoch: 6| Step: 7
Training loss: 2.4766883216448576
Validation loss: 2.5011403979592086

Epoch: 6| Step: 8
Training loss: 2.4829926873728154
Validation loss: 2.5011761282974487

Epoch: 6| Step: 9
Training loss: 2.758046170025961
Validation loss: 2.5009642807632755

Epoch: 6| Step: 10
Training loss: 2.022575990359765
Validation loss: 2.495914044823812

Epoch: 6| Step: 11
Training loss: 2.631680117720312
Validation loss: 2.4968446687551777

Epoch: 6| Step: 12
Training loss: 2.5218331637215323
Validation loss: 2.499366966209845

Epoch: 6| Step: 13
Training loss: 2.4130281374287175
Validation loss: 2.4943459151740544

Epoch: 81| Step: 0
Training loss: 2.2642794066174097
Validation loss: 2.4968613313468695

Epoch: 6| Step: 1
Training loss: 2.720485089746892
Validation loss: 2.4916664304275997

Epoch: 6| Step: 2
Training loss: 2.721065718894972
Validation loss: 2.4937075261551844

Epoch: 6| Step: 3
Training loss: 2.5625910859085343
Validation loss: 2.4934440801201943

Epoch: 6| Step: 4
Training loss: 2.415562136129435
Validation loss: 2.4961799045553112

Epoch: 6| Step: 5
Training loss: 2.3564422771815305
Validation loss: 2.4969916522133886

Epoch: 6| Step: 6
Training loss: 2.685730107385475
Validation loss: 2.492305900288403

Epoch: 6| Step: 7
Training loss: 2.790206375419503
Validation loss: 2.494243383717888

Epoch: 6| Step: 8
Training loss: 2.620946206319095
Validation loss: 2.4960237989737872

Epoch: 6| Step: 9
Training loss: 2.541052499161974
Validation loss: 2.499042820479531

Epoch: 6| Step: 10
Training loss: 2.7452181075254733
Validation loss: 2.4973354285887024

Epoch: 6| Step: 11
Training loss: 2.7520547473086063
Validation loss: 2.4966978357998304

Epoch: 6| Step: 12
Training loss: 2.5736144402826633
Validation loss: 2.4936081395794845

Epoch: 6| Step: 13
Training loss: 2.843830987804097
Validation loss: 2.4969700890275908

Epoch: 82| Step: 0
Training loss: 2.4776253811148057
Validation loss: 2.4940214355157355

Epoch: 6| Step: 1
Training loss: 2.870921019463963
Validation loss: 2.496723921322621

Epoch: 6| Step: 2
Training loss: 2.248956332280192
Validation loss: 2.4967256561036724

Epoch: 6| Step: 3
Training loss: 2.078946058945113
Validation loss: 2.495716701280972

Epoch: 6| Step: 4
Training loss: 2.6125510981915014
Validation loss: 2.5000437891621967

Epoch: 6| Step: 5
Training loss: 2.747002528575154
Validation loss: 2.4940943582973802

Epoch: 6| Step: 6
Training loss: 2.7379526330209774
Validation loss: 2.4977463737092127

Epoch: 6| Step: 7
Training loss: 2.717305994767917
Validation loss: 2.4940168309687722

Epoch: 6| Step: 8
Training loss: 2.358306845077016
Validation loss: 2.4937405585267225

Epoch: 6| Step: 9
Training loss: 2.7273172902310097
Validation loss: 2.4929391968992842

Epoch: 6| Step: 10
Training loss: 2.6782284871318707
Validation loss: 2.4947214348981075

Epoch: 6| Step: 11
Training loss: 3.045409177651859
Validation loss: 2.492168526093933

Epoch: 6| Step: 12
Training loss: 2.6268275120990174
Validation loss: 2.492234671055612

Epoch: 6| Step: 13
Training loss: 2.4052928655833314
Validation loss: 2.491323706032139

Epoch: 83| Step: 0
Training loss: 2.5755608031305646
Validation loss: 2.4916477715106455

Epoch: 6| Step: 1
Training loss: 2.6406835064247125
Validation loss: 2.490466010596393

Epoch: 6| Step: 2
Training loss: 2.414987035207126
Validation loss: 2.4999522363550466

Epoch: 6| Step: 3
Training loss: 2.1120589523829736
Validation loss: 2.498479921427321

Epoch: 6| Step: 4
Training loss: 2.861986978859807
Validation loss: 2.4994689854290457

Epoch: 6| Step: 5
Training loss: 2.3642965358507877
Validation loss: 2.492071693145333

Epoch: 6| Step: 6
Training loss: 2.8276688856015517
Validation loss: 2.489954171965452

Epoch: 6| Step: 7
Training loss: 2.7235504389602907
Validation loss: 2.4890053422634755

Epoch: 6| Step: 8
Training loss: 2.62245036235486
Validation loss: 2.4886819705450005

Epoch: 6| Step: 9
Training loss: 2.875515103842572
Validation loss: 2.4916006451623725

Epoch: 6| Step: 10
Training loss: 2.495333512515728
Validation loss: 2.492365321529027

Epoch: 6| Step: 11
Training loss: 2.9326087324012313
Validation loss: 2.4930143031181666

Epoch: 6| Step: 12
Training loss: 2.3591137671954368
Validation loss: 2.4916503470874094

Epoch: 6| Step: 13
Training loss: 2.5987898798126223
Validation loss: 2.4893544995045387

Epoch: 84| Step: 0
Training loss: 2.412962036162995
Validation loss: 2.4947477162948917

Epoch: 6| Step: 1
Training loss: 2.4898328030994645
Validation loss: 2.4922913118144434

Epoch: 6| Step: 2
Training loss: 2.5620753238751512
Validation loss: 2.4945636451275157

Epoch: 6| Step: 3
Training loss: 2.505174526903825
Validation loss: 2.4926139761610178

Epoch: 6| Step: 4
Training loss: 2.437533060485431
Validation loss: 2.494964152978765

Epoch: 6| Step: 5
Training loss: 2.702299841033035
Validation loss: 2.492542373121046

Epoch: 6| Step: 6
Training loss: 3.438814362755946
Validation loss: 2.494513005652785

Epoch: 6| Step: 7
Training loss: 2.8210269097116716
Validation loss: 2.496172526135822

Epoch: 6| Step: 8
Training loss: 2.31980464014115
Validation loss: 2.4948623477318024

Epoch: 6| Step: 9
Training loss: 2.8823268243492586
Validation loss: 2.4954607921687866

Epoch: 6| Step: 10
Training loss: 2.7751887420527117
Validation loss: 2.4928846350840415

Epoch: 6| Step: 11
Training loss: 2.133783252280419
Validation loss: 2.4926007764231737

Epoch: 6| Step: 12
Training loss: 2.4462999781443093
Validation loss: 2.4903422253759335

Epoch: 6| Step: 13
Training loss: 2.421889963411436
Validation loss: 2.4910104776358875

Epoch: 85| Step: 0
Training loss: 2.6241777131215684
Validation loss: 2.4909793392699258

Epoch: 6| Step: 1
Training loss: 2.689119427713985
Validation loss: 2.4870563009127293

Epoch: 6| Step: 2
Training loss: 3.2219447604747633
Validation loss: 2.489759643781156

Epoch: 6| Step: 3
Training loss: 2.2635590703733754
Validation loss: 2.483875296378789

Epoch: 6| Step: 4
Training loss: 2.571282850026914
Validation loss: 2.490025554204133

Epoch: 6| Step: 5
Training loss: 1.8333786034052193
Validation loss: 2.490040874069121

Epoch: 6| Step: 6
Training loss: 2.569553529869536
Validation loss: 2.487132575344933

Epoch: 6| Step: 7
Training loss: 2.6170417403440713
Validation loss: 2.4920581477128354

Epoch: 6| Step: 8
Training loss: 2.29920270618022
Validation loss: 2.4909253726246536

Epoch: 6| Step: 9
Training loss: 2.886191933015984
Validation loss: 2.485792495395501

Epoch: 6| Step: 10
Training loss: 2.605386117885928
Validation loss: 2.4880452266202977

Epoch: 6| Step: 11
Training loss: 3.081720875630668
Validation loss: 2.4882083325204443

Epoch: 6| Step: 12
Training loss: 2.2356708743513325
Validation loss: 2.4895649407849927

Epoch: 6| Step: 13
Training loss: 2.5964771319432223
Validation loss: 2.490848480498465

Epoch: 86| Step: 0
Training loss: 2.571429627282062
Validation loss: 2.4875071472755383

Epoch: 6| Step: 1
Training loss: 2.3829386693351435
Validation loss: 2.490265395027385

Epoch: 6| Step: 2
Training loss: 2.7549520468303026
Validation loss: 2.490153719524617

Epoch: 6| Step: 3
Training loss: 3.013991471833515
Validation loss: 2.485306786993831

Epoch: 6| Step: 4
Training loss: 2.6805646256033695
Validation loss: 2.482201062938256

Epoch: 6| Step: 5
Training loss: 2.5840360444569526
Validation loss: 2.485585827332137

Epoch: 6| Step: 6
Training loss: 2.3442225679182025
Validation loss: 2.4837451192305204

Epoch: 6| Step: 7
Training loss: 2.4859032878523606
Validation loss: 2.4907487405362

Epoch: 6| Step: 8
Training loss: 2.580652373730671
Validation loss: 2.4830672782963292

Epoch: 6| Step: 9
Training loss: 1.9962727863919822
Validation loss: 2.481608115616323

Epoch: 6| Step: 10
Training loss: 2.6300566878210714
Validation loss: 2.4891590624108733

Epoch: 6| Step: 11
Training loss: 2.4858039249424477
Validation loss: 2.485560472223297

Epoch: 6| Step: 12
Training loss: 3.041010764135887
Validation loss: 2.4817617335491264

Epoch: 6| Step: 13
Training loss: 2.691236426943346
Validation loss: 2.484930044426556

Epoch: 87| Step: 0
Training loss: 2.510933713310724
Validation loss: 2.4851400928677627

Epoch: 6| Step: 1
Training loss: 2.6945479483458925
Validation loss: 2.486466541018375

Epoch: 6| Step: 2
Training loss: 2.6603905214734183
Validation loss: 2.488930482270846

Epoch: 6| Step: 3
Training loss: 2.691425738658577
Validation loss: 2.491727094863745

Epoch: 6| Step: 4
Training loss: 2.991546482516303
Validation loss: 2.487472857993337

Epoch: 6| Step: 5
Training loss: 2.3161630229399286
Validation loss: 2.489827201316666

Epoch: 6| Step: 6
Training loss: 3.0030956191452667
Validation loss: 2.490420050586556

Epoch: 6| Step: 7
Training loss: 2.4592798856885616
Validation loss: 2.486467100356241

Epoch: 6| Step: 8
Training loss: 2.6928680392236757
Validation loss: 2.4860378594383863

Epoch: 6| Step: 9
Training loss: 2.268086431474433
Validation loss: 2.484888195718256

Epoch: 6| Step: 10
Training loss: 3.0609226446487403
Validation loss: 2.4854662435937094

Epoch: 6| Step: 11
Training loss: 2.167002529619868
Validation loss: 2.483242536544785

Epoch: 6| Step: 12
Training loss: 2.256373068710362
Validation loss: 2.480402363366872

Epoch: 6| Step: 13
Training loss: 2.445417408018205
Validation loss: 2.478369301438969

Epoch: 88| Step: 0
Training loss: 2.7674083240352694
Validation loss: 2.4751329999567444

Epoch: 6| Step: 1
Training loss: 2.8261416736141127
Validation loss: 2.4782669828452515

Epoch: 6| Step: 2
Training loss: 2.591560174730988
Validation loss: 2.484477394920872

Epoch: 6| Step: 3
Training loss: 2.4075337738171636
Validation loss: 2.4771120282033214

Epoch: 6| Step: 4
Training loss: 2.3646395728415444
Validation loss: 2.4785577416254747

Epoch: 6| Step: 5
Training loss: 2.523509399523537
Validation loss: 2.4801205768678103

Epoch: 6| Step: 6
Training loss: 2.6953765419248548
Validation loss: 2.4776072900600177

Epoch: 6| Step: 7
Training loss: 2.94326152271817
Validation loss: 2.4800056726124193

Epoch: 6| Step: 8
Training loss: 2.685838940084225
Validation loss: 2.479387230772022

Epoch: 6| Step: 9
Training loss: 2.5846744460739153
Validation loss: 2.4811679765674732

Epoch: 6| Step: 10
Training loss: 2.2462693120925485
Validation loss: 2.4827829534054118

Epoch: 6| Step: 11
Training loss: 2.502803660898822
Validation loss: 2.4846484755500162

Epoch: 6| Step: 12
Training loss: 2.439394483632638
Validation loss: 2.4809319331528754

Epoch: 6| Step: 13
Training loss: 2.5223891026114793
Validation loss: 2.4778948227598594

Epoch: 89| Step: 0
Training loss: 2.350125707145468
Validation loss: 2.4837360000151794

Epoch: 6| Step: 1
Training loss: 2.493704880997008
Validation loss: 2.483987086179073

Epoch: 6| Step: 2
Training loss: 2.8373643212502526
Validation loss: 2.4827334180736615

Epoch: 6| Step: 3
Training loss: 2.891356174681637
Validation loss: 2.4866484789997103

Epoch: 6| Step: 4
Training loss: 2.7837076365652305
Validation loss: 2.48591044898973

Epoch: 6| Step: 5
Training loss: 2.579928605326423
Validation loss: 2.4858860882506537

Epoch: 6| Step: 6
Training loss: 2.693153821640911
Validation loss: 2.4848768099332053

Epoch: 6| Step: 7
Training loss: 2.621693299536759
Validation loss: 2.479413698748789

Epoch: 6| Step: 8
Training loss: 2.968101350292869
Validation loss: 2.476156977716861

Epoch: 6| Step: 9
Training loss: 2.5335410781640926
Validation loss: 2.4786658435667634

Epoch: 6| Step: 10
Training loss: 2.5068534371954443
Validation loss: 2.4732399121563993

Epoch: 6| Step: 11
Training loss: 2.17298224238352
Validation loss: 2.479808361022163

Epoch: 6| Step: 12
Training loss: 2.423307524293977
Validation loss: 2.4785414369490093

Epoch: 6| Step: 13
Training loss: 2.2234685449316105
Validation loss: 2.4726038762030402

Epoch: 90| Step: 0
Training loss: 2.5328898828111863
Validation loss: 2.4803035971461056

Epoch: 6| Step: 1
Training loss: 2.3501417360782693
Validation loss: 2.4718539366083894

Epoch: 6| Step: 2
Training loss: 2.579120328257884
Validation loss: 2.4744056912894155

Epoch: 6| Step: 3
Training loss: 2.3826526025372314
Validation loss: 2.476199872637481

Epoch: 6| Step: 4
Training loss: 2.566469235278756
Validation loss: 2.47385363440907

Epoch: 6| Step: 5
Training loss: 2.4311951501145836
Validation loss: 2.47901596017316

Epoch: 6| Step: 6
Training loss: 2.4902232689703325
Validation loss: 2.4813425842743366

Epoch: 6| Step: 7
Training loss: 2.4825350107603477
Validation loss: 2.4769546888188385

Epoch: 6| Step: 8
Training loss: 2.6688366842374127
Validation loss: 2.4804371428791283

Epoch: 6| Step: 9
Training loss: 2.382942971581684
Validation loss: 2.478038857218737

Epoch: 6| Step: 10
Training loss: 2.428246760905519
Validation loss: 2.478566078291765

Epoch: 6| Step: 11
Training loss: 2.9803082784147024
Validation loss: 2.47604398383606

Epoch: 6| Step: 12
Training loss: 2.5492783890486748
Validation loss: 2.472610762480557

Epoch: 6| Step: 13
Training loss: 3.162368735503042
Validation loss: 2.478285950945518

Epoch: 91| Step: 0
Training loss: 2.260690300430479
Validation loss: 2.4731862734014363

Epoch: 6| Step: 1
Training loss: 2.9462821032296826
Validation loss: 2.477672532711255

Epoch: 6| Step: 2
Training loss: 3.1628723166615353
Validation loss: 2.472861941813216

Epoch: 6| Step: 3
Training loss: 2.8851522239576397
Validation loss: 2.478235852719389

Epoch: 6| Step: 4
Training loss: 1.7727293373531599
Validation loss: 2.4744732826102465

Epoch: 6| Step: 5
Training loss: 3.1623777825784973
Validation loss: 2.4769636084067974

Epoch: 6| Step: 6
Training loss: 2.616258689840423
Validation loss: 2.4759944821939732

Epoch: 6| Step: 7
Training loss: 2.641809141566875
Validation loss: 2.471238278618612

Epoch: 6| Step: 8
Training loss: 2.723999042583639
Validation loss: 2.4784212247257775

Epoch: 6| Step: 9
Training loss: 2.078013022711502
Validation loss: 2.4740289831948843

Epoch: 6| Step: 10
Training loss: 2.8331125023745245
Validation loss: 2.4706659728864317

Epoch: 6| Step: 11
Training loss: 2.4941578314059973
Validation loss: 2.474653083557773

Epoch: 6| Step: 12
Training loss: 2.156664601147629
Validation loss: 2.4736473182466754

Epoch: 6| Step: 13
Training loss: 1.8399023220838573
Validation loss: 2.477600313421149

Epoch: 92| Step: 0
Training loss: 2.0244173601034405
Validation loss: 2.4778659892048993

Epoch: 6| Step: 1
Training loss: 2.958842238232223
Validation loss: 2.478219618079348

Epoch: 6| Step: 2
Training loss: 3.0860821267533383
Validation loss: 2.4726482469570823

Epoch: 6| Step: 3
Training loss: 2.6677901067170398
Validation loss: 2.473458511992653

Epoch: 6| Step: 4
Training loss: 2.142867313088397
Validation loss: 2.4753705996345015

Epoch: 6| Step: 5
Training loss: 1.829014227676741
Validation loss: 2.4747849110862417

Epoch: 6| Step: 6
Training loss: 2.34110833386582
Validation loss: 2.472735588002163

Epoch: 6| Step: 7
Training loss: 3.2329661668823655
Validation loss: 2.47593350450382

Epoch: 6| Step: 8
Training loss: 2.550311993230903
Validation loss: 2.467281194336815

Epoch: 6| Step: 9
Training loss: 2.4697938474733743
Validation loss: 2.4688275642925928

Epoch: 6| Step: 10
Training loss: 2.968004795708085
Validation loss: 2.474630635247235

Epoch: 6| Step: 11
Training loss: 2.562839020423345
Validation loss: 2.4759702405522614

Epoch: 6| Step: 12
Training loss: 2.487497346962899
Validation loss: 2.4702570053838757

Epoch: 6| Step: 13
Training loss: 2.3012131186891303
Validation loss: 2.4746865790130537

Epoch: 93| Step: 0
Training loss: 2.6373914072542575
Validation loss: 2.478546310727844

Epoch: 6| Step: 1
Training loss: 2.582830400629892
Validation loss: 2.474793549478149

Epoch: 6| Step: 2
Training loss: 2.687425479299307
Validation loss: 2.476386399932579

Epoch: 6| Step: 3
Training loss: 2.2706275170057917
Validation loss: 2.470350977714398

Epoch: 6| Step: 4
Training loss: 2.7710517185358587
Validation loss: 2.4786928162140183

Epoch: 6| Step: 5
Training loss: 2.4965062524406667
Validation loss: 2.4655464730370764

Epoch: 6| Step: 6
Training loss: 2.19738172436332
Validation loss: 2.468831926105112

Epoch: 6| Step: 7
Training loss: 2.634601562459458
Validation loss: 2.468761315299713

Epoch: 6| Step: 8
Training loss: 3.0295306176443617
Validation loss: 2.467268116757079

Epoch: 6| Step: 9
Training loss: 2.5540944382213095
Validation loss: 2.4673523950665897

Epoch: 6| Step: 10
Training loss: 3.2233442092391176
Validation loss: 2.4690499425312114

Epoch: 6| Step: 11
Training loss: 2.292192629942975
Validation loss: 2.4728497132705005

Epoch: 6| Step: 12
Training loss: 1.892474318296065
Validation loss: 2.474846214114823

Epoch: 6| Step: 13
Training loss: 2.6054085377108263
Validation loss: 2.4755725827631236

Epoch: 94| Step: 0
Training loss: 2.169780901733984
Validation loss: 2.4833891650031905

Epoch: 6| Step: 1
Training loss: 2.8115707557780034
Validation loss: 2.479466705972599

Epoch: 6| Step: 2
Training loss: 2.717107868837459
Validation loss: 2.4767631184761987

Epoch: 6| Step: 3
Training loss: 2.2855727117835496
Validation loss: 2.481685085890105

Epoch: 6| Step: 4
Training loss: 2.4990215294052893
Validation loss: 2.4850383808541543

Epoch: 6| Step: 5
Training loss: 2.6481393291778064
Validation loss: 2.477923030568207

Epoch: 6| Step: 6
Training loss: 2.551979052430762
Validation loss: 2.4778943897779224

Epoch: 6| Step: 7
Training loss: 2.1380800586695234
Validation loss: 2.4724389855108195

Epoch: 6| Step: 8
Training loss: 2.9867117955283766
Validation loss: 2.4730253581901227

Epoch: 6| Step: 9
Training loss: 2.503403445031134
Validation loss: 2.4782828724471444

Epoch: 6| Step: 10
Training loss: 2.6816957472257132
Validation loss: 2.4769841265456627

Epoch: 6| Step: 11
Training loss: 2.6486319411477255
Validation loss: 2.468096296462778

Epoch: 6| Step: 12
Training loss: 2.953254010647206
Validation loss: 2.470984023539757

Epoch: 6| Step: 13
Training loss: 2.5077246534701674
Validation loss: 2.47352868348036

Epoch: 95| Step: 0
Training loss: 2.585080653100059
Validation loss: 2.4702262166843436

Epoch: 6| Step: 1
Training loss: 2.8225431206841356
Validation loss: 2.4743951565765494

Epoch: 6| Step: 2
Training loss: 2.656647955311255
Validation loss: 2.4719597275878264

Epoch: 6| Step: 3
Training loss: 2.723481194238112
Validation loss: 2.4780831787634083

Epoch: 6| Step: 4
Training loss: 2.713747530478782
Validation loss: 2.475746525779458

Epoch: 6| Step: 5
Training loss: 2.275064102778849
Validation loss: 2.4760680562497264

Epoch: 6| Step: 6
Training loss: 2.157545502183938
Validation loss: 2.475032401916385

Epoch: 6| Step: 7
Training loss: 2.757333686910984
Validation loss: 2.4802974932165625

Epoch: 6| Step: 8
Training loss: 2.384023589990379
Validation loss: 2.475343004855902

Epoch: 6| Step: 9
Training loss: 2.612717184137914
Validation loss: 2.466594141031401

Epoch: 6| Step: 10
Training loss: 2.73834063020718
Validation loss: 2.466228307830647

Epoch: 6| Step: 11
Training loss: 2.0624495991415217
Validation loss: 2.4667720194390172

Epoch: 6| Step: 12
Training loss: 2.7115510361708175
Validation loss: 2.47091832285497

Epoch: 6| Step: 13
Training loss: 2.80564961627198
Validation loss: 2.4637477753589017

Epoch: 96| Step: 0
Training loss: 3.16140296213008
Validation loss: 2.4660305867697243

Epoch: 6| Step: 1
Training loss: 2.412931405665073
Validation loss: 2.4707282305058884

Epoch: 6| Step: 2
Training loss: 2.4167060081524374
Validation loss: 2.46693646742512

Epoch: 6| Step: 3
Training loss: 3.2182068597988
Validation loss: 2.469711808471936

Epoch: 6| Step: 4
Training loss: 2.6976625673875767
Validation loss: 2.475963002518555

Epoch: 6| Step: 5
Training loss: 2.3931159711155865
Validation loss: 2.478363377128831

Epoch: 6| Step: 6
Training loss: 2.8412954615636763
Validation loss: 2.4747930758124594

Epoch: 6| Step: 7
Training loss: 2.7342067993746975
Validation loss: 2.479127712638275

Epoch: 6| Step: 8
Training loss: 2.4353084003889287
Validation loss: 2.4811715479570617

Epoch: 6| Step: 9
Training loss: 2.8669262177121295
Validation loss: 2.4768796330640535

Epoch: 6| Step: 10
Training loss: 1.9043736212499753
Validation loss: 2.4742236881831166

Epoch: 6| Step: 11
Training loss: 2.2440784734580568
Validation loss: 2.471075371203447

Epoch: 6| Step: 12
Training loss: 1.8173614287514805
Validation loss: 2.470650838467038

Epoch: 6| Step: 13
Training loss: 2.6004559337224737
Validation loss: 2.465613146851336

Epoch: 97| Step: 0
Training loss: 2.7331165142437905
Validation loss: 2.471374332089786

Epoch: 6| Step: 1
Training loss: 2.4753119262494305
Validation loss: 2.4646291019664623

Epoch: 6| Step: 2
Training loss: 2.605136375445241
Validation loss: 2.4680221869019086

Epoch: 6| Step: 3
Training loss: 2.5495972857649654
Validation loss: 2.466482497333543

Epoch: 6| Step: 4
Training loss: 3.0905427588155745
Validation loss: 2.464120636880876

Epoch: 6| Step: 5
Training loss: 2.433891461869827
Validation loss: 2.4658594713784217

Epoch: 6| Step: 6
Training loss: 2.65436558918714
Validation loss: 2.463463551504005

Epoch: 6| Step: 7
Training loss: 2.5000473017986016
Validation loss: 2.4626972748794502

Epoch: 6| Step: 8
Training loss: 1.9383026429379178
Validation loss: 2.461063975157144

Epoch: 6| Step: 9
Training loss: 2.696221682028868
Validation loss: 2.4632882329952923

Epoch: 6| Step: 10
Training loss: 2.8323683123771186
Validation loss: 2.471001865585407

Epoch: 6| Step: 11
Training loss: 2.044561228607056
Validation loss: 2.46783051087018

Epoch: 6| Step: 12
Training loss: 2.5870552528476507
Validation loss: 2.464229710786969

Epoch: 6| Step: 13
Training loss: 2.5843334928083066
Validation loss: 2.475102456537768

Epoch: 98| Step: 0
Training loss: 2.3898226320219695
Validation loss: 2.47050838381486

Epoch: 6| Step: 1
Training loss: 2.6847104521329657
Validation loss: 2.467889144755164

Epoch: 6| Step: 2
Training loss: 2.8805456992895984
Validation loss: 2.470477807346834

Epoch: 6| Step: 3
Training loss: 2.345112315662363
Validation loss: 2.469004267865398

Epoch: 6| Step: 4
Training loss: 2.8398937866336396
Validation loss: 2.4703417447132723

Epoch: 6| Step: 5
Training loss: 3.0362523283307574
Validation loss: 2.4686231459849637

Epoch: 6| Step: 6
Training loss: 2.752384365885477
Validation loss: 2.466710258004202

Epoch: 6| Step: 7
Training loss: 2.58455941627412
Validation loss: 2.461902344496855

Epoch: 6| Step: 8
Training loss: 2.346921885259553
Validation loss: 2.4703859872039473

Epoch: 6| Step: 9
Training loss: 2.46058579611075
Validation loss: 2.474660020333578

Epoch: 6| Step: 10
Training loss: 2.316740632648822
Validation loss: 2.4618692400295887

Epoch: 6| Step: 11
Training loss: 2.5304890183393476
Validation loss: 2.4660218371135754

Epoch: 6| Step: 12
Training loss: 2.3499285829121694
Validation loss: 2.4683105946879444

Epoch: 6| Step: 13
Training loss: 2.2307269853796052
Validation loss: 2.4631714304068257

Epoch: 99| Step: 0
Training loss: 2.2877360071057167
Validation loss: 2.4627325867929963

Epoch: 6| Step: 1
Training loss: 2.9868368011222315
Validation loss: 2.464841879931112

Epoch: 6| Step: 2
Training loss: 2.554184703752845
Validation loss: 2.4678172510301106

Epoch: 6| Step: 3
Training loss: 2.3966060442767025
Validation loss: 2.4761363082941545

Epoch: 6| Step: 4
Training loss: 2.1873820681798652
Validation loss: 2.4771854808419453

Epoch: 6| Step: 5
Training loss: 2.9596968897711955
Validation loss: 2.474563963527849

Epoch: 6| Step: 6
Training loss: 2.8949056735838137
Validation loss: 2.4795605055481986

Epoch: 6| Step: 7
Training loss: 2.215490068596353
Validation loss: 2.477513047641716

Epoch: 6| Step: 8
Training loss: 2.0900617539257995
Validation loss: 2.4689381362758036

Epoch: 6| Step: 9
Training loss: 2.773805062021253
Validation loss: 2.468629488035704

Epoch: 6| Step: 10
Training loss: 2.943312717364104
Validation loss: 2.4665376673508868

Epoch: 6| Step: 11
Training loss: 2.8549503633423186
Validation loss: 2.4627738438911475

Epoch: 6| Step: 12
Training loss: 2.2479220437688805
Validation loss: 2.461083350325203

Epoch: 6| Step: 13
Training loss: 2.2630384742274576
Validation loss: 2.4575021329956526

Epoch: 100| Step: 0
Training loss: 2.842241998268478
Validation loss: 2.461649021850794

Epoch: 6| Step: 1
Training loss: 2.3500779240451735
Validation loss: 2.4629078883857534

Epoch: 6| Step: 2
Training loss: 2.9338069995727714
Validation loss: 2.4617207083154056

Epoch: 6| Step: 3
Training loss: 2.2914518313421577
Validation loss: 2.456061223794318

Epoch: 6| Step: 4
Training loss: 2.2949333028305894
Validation loss: 2.456503790766232

Epoch: 6| Step: 5
Training loss: 2.6501381964007034
Validation loss: 2.456902594096405

Epoch: 6| Step: 6
Training loss: 2.9066362021830012
Validation loss: 2.4570427567334354

Epoch: 6| Step: 7
Training loss: 2.2665600129822177
Validation loss: 2.4637628231556783

Epoch: 6| Step: 8
Training loss: 2.5997622564631975
Validation loss: 2.4686178341025165

Epoch: 6| Step: 9
Training loss: 2.7259457828002747
Validation loss: 2.453507557579203

Epoch: 6| Step: 10
Training loss: 2.2142418206606407
Validation loss: 2.455925818640133

Epoch: 6| Step: 11
Training loss: 2.365214214664287
Validation loss: 2.4670587371989985

Epoch: 6| Step: 12
Training loss: 3.0330924500896796
Validation loss: 2.4701169410492896

Epoch: 6| Step: 13
Training loss: 2.254517682210684
Validation loss: 2.474301883869538

Epoch: 101| Step: 0
Training loss: 2.255895520205556
Validation loss: 2.474197919521208

Epoch: 6| Step: 1
Training loss: 1.782887693084891
Validation loss: 2.477154280980905

Epoch: 6| Step: 2
Training loss: 2.5709127635421902
Validation loss: 2.480816481839183

Epoch: 6| Step: 3
Training loss: 3.074792907688402
Validation loss: 2.482071230234869

Epoch: 6| Step: 4
Training loss: 3.592269725281609
Validation loss: 2.479470279812671

Epoch: 6| Step: 5
Training loss: 2.4793689121703366
Validation loss: 2.4829805247269867

Epoch: 6| Step: 6
Training loss: 2.377517369925889
Validation loss: 2.4820530194944923

Epoch: 6| Step: 7
Training loss: 2.388789650484675
Validation loss: 2.4813706568056895

Epoch: 6| Step: 8
Training loss: 2.578165319878843
Validation loss: 2.4862669292709145

Epoch: 6| Step: 9
Training loss: 2.5101533701571754
Validation loss: 2.4829414918335657

Epoch: 6| Step: 10
Training loss: 2.7928581162528703
Validation loss: 2.4877053097800594

Epoch: 6| Step: 11
Training loss: 2.2370781186429616
Validation loss: 2.483302046644871

Epoch: 6| Step: 12
Training loss: 2.445953382657625
Validation loss: 2.479846081212937

Epoch: 6| Step: 13
Training loss: 2.8723638307385877
Validation loss: 2.476786253375053

Epoch: 102| Step: 0
Training loss: 2.658481154522295
Validation loss: 2.479639053752836

Epoch: 6| Step: 1
Training loss: 2.5042341615675467
Validation loss: 2.479044700208267

Epoch: 6| Step: 2
Training loss: 2.115745701016171
Validation loss: 2.484707216326845

Epoch: 6| Step: 3
Training loss: 2.460376493904999
Validation loss: 2.4792857074741472

Epoch: 6| Step: 4
Training loss: 3.480895353432483
Validation loss: 2.4753973754257825

Epoch: 6| Step: 5
Training loss: 2.5699160191808
Validation loss: 2.4781695265295403

Epoch: 6| Step: 6
Training loss: 2.171877634609463
Validation loss: 2.4746642273501727

Epoch: 6| Step: 7
Training loss: 2.6675910738240964
Validation loss: 2.4738915899542637

Epoch: 6| Step: 8
Training loss: 2.3814723514263
Validation loss: 2.4796836912289755

Epoch: 6| Step: 9
Training loss: 2.326564701199691
Validation loss: 2.4736179532582305

Epoch: 6| Step: 10
Training loss: 2.252865979336012
Validation loss: 2.4756352145716125

Epoch: 6| Step: 11
Training loss: 3.041507786472581
Validation loss: 2.4674195837375343

Epoch: 6| Step: 12
Training loss: 2.824539271906351
Validation loss: 2.4659067996125907

Epoch: 6| Step: 13
Training loss: 2.046096304199675
Validation loss: 2.459553922020358

Epoch: 103| Step: 0
Training loss: 2.1890451696065196
Validation loss: 2.464170610873855

Epoch: 6| Step: 1
Training loss: 2.3534009470245514
Validation loss: 2.4652540507241882

Epoch: 6| Step: 2
Training loss: 2.2264751216407417
Validation loss: 2.4650405345779665

Epoch: 6| Step: 3
Training loss: 2.5478302270091744
Validation loss: 2.473115529840857

Epoch: 6| Step: 4
Training loss: 2.88834567546317
Validation loss: 2.481664734714321

Epoch: 6| Step: 5
Training loss: 2.9578541828811473
Validation loss: 2.4576764656991514

Epoch: 6| Step: 6
Training loss: 2.1955573871907785
Validation loss: 2.4559459462497695

Epoch: 6| Step: 7
Training loss: 3.337627188441429
Validation loss: 2.464029168464122

Epoch: 6| Step: 8
Training loss: 2.3164422738424615
Validation loss: 2.46809421955775

Epoch: 6| Step: 9
Training loss: 2.3004409201550957
Validation loss: 2.4727868020062442

Epoch: 6| Step: 10
Training loss: 3.0497901469093813
Validation loss: 2.469611898696516

Epoch: 6| Step: 11
Training loss: 2.4594075609157784
Validation loss: 2.4774753881644047

Epoch: 6| Step: 12
Training loss: 2.253672886871133
Validation loss: 2.4813904338975012

Epoch: 6| Step: 13
Training loss: 2.7308871449381926
Validation loss: 2.475202554062905

Epoch: 104| Step: 0
Training loss: 2.8677036745860573
Validation loss: 2.478493355965881

Epoch: 6| Step: 1
Training loss: 2.4536056533618993
Validation loss: 2.477587274271007

Epoch: 6| Step: 2
Training loss: 2.244405679347009
Validation loss: 2.4729345083731267

Epoch: 6| Step: 3
Training loss: 2.5639712134365507
Validation loss: 2.471061493587388

Epoch: 6| Step: 4
Training loss: 2.4276647458023266
Validation loss: 2.4626256491140626

Epoch: 6| Step: 5
Training loss: 2.4086513674486203
Validation loss: 2.4659591222790085

Epoch: 6| Step: 6
Training loss: 2.183339221839632
Validation loss: 2.458186506207811

Epoch: 6| Step: 7
Training loss: 2.703325914622835
Validation loss: 2.458991372136631

Epoch: 6| Step: 8
Training loss: 2.6079631343646477
Validation loss: 2.4575615549641032

Epoch: 6| Step: 9
Training loss: 1.9713532931999043
Validation loss: 2.462740533315584

Epoch: 6| Step: 10
Training loss: 2.77118972169036
Validation loss: 2.4784628780074005

Epoch: 6| Step: 11
Training loss: 2.4240587787174226
Validation loss: 2.477155612396883

Epoch: 6| Step: 12
Training loss: 2.6487307765923807
Validation loss: 2.4825071434745443

Epoch: 6| Step: 13
Training loss: 3.5499194015164885
Validation loss: 2.4803094447285607

Epoch: 105| Step: 0
Training loss: 2.871792538261164
Validation loss: 2.4669718394646973

Epoch: 6| Step: 1
Training loss: 2.501057591851653
Validation loss: 2.4594880210179935

Epoch: 6| Step: 2
Training loss: 2.2443222888693857
Validation loss: 2.4621699965696835

Epoch: 6| Step: 3
Training loss: 2.549527618186792
Validation loss: 2.4638450199218096

Epoch: 6| Step: 4
Training loss: 2.494968118712364
Validation loss: 2.4705052473718547

Epoch: 6| Step: 5
Training loss: 2.7250662909327596
Validation loss: 2.471161103554308

Epoch: 6| Step: 6
Training loss: 2.3798473482303244
Validation loss: 2.473238650931994

Epoch: 6| Step: 7
Training loss: 2.6938636313278135
Validation loss: 2.481337331649057

Epoch: 6| Step: 8
Training loss: 2.5648787087955096
Validation loss: 2.4794289960367357

Epoch: 6| Step: 9
Training loss: 2.9423363014391475
Validation loss: 2.482617778436381

Epoch: 6| Step: 10
Training loss: 3.057234772776141
Validation loss: 2.4825046464480236

Epoch: 6| Step: 11
Training loss: 2.4174062539892156
Validation loss: 2.4844309802516054

Epoch: 6| Step: 12
Training loss: 2.3844996748460296
Validation loss: 2.4865469725116305

Epoch: 6| Step: 13
Training loss: 2.4785961381537245
Validation loss: 2.4880956783194335

Epoch: 106| Step: 0
Training loss: 2.675321263781402
Validation loss: 2.4862905510967255

Epoch: 6| Step: 1
Training loss: 2.2917275391788103
Validation loss: 2.4812793518559566

Epoch: 6| Step: 2
Training loss: 3.2788665834526602
Validation loss: 2.4798800032564374

Epoch: 6| Step: 3
Training loss: 2.993915108923992
Validation loss: 2.4731786737473387

Epoch: 6| Step: 4
Training loss: 3.1590313129279948
Validation loss: 2.475227116269307

Epoch: 6| Step: 5
Training loss: 2.592855368144071
Validation loss: 2.4705089708922108

Epoch: 6| Step: 6
Training loss: 2.0454631333219018
Validation loss: 2.4704481071169626

Epoch: 6| Step: 7
Training loss: 2.0860813962759046
Validation loss: 2.4658815966755254

Epoch: 6| Step: 8
Training loss: 2.444885411609984
Validation loss: 2.467589914602619

Epoch: 6| Step: 9
Training loss: 2.1040111018420995
Validation loss: 2.4674174096361257

Epoch: 6| Step: 10
Training loss: 2.621191531772169
Validation loss: 2.462780604374371

Epoch: 6| Step: 11
Training loss: 2.259261883743976
Validation loss: 2.461585049482544

Epoch: 6| Step: 12
Training loss: 2.1560173462008927
Validation loss: 2.455049589967963

Epoch: 6| Step: 13
Training loss: 3.0763175808746466
Validation loss: 2.46341402289039

Epoch: 107| Step: 0
Training loss: 2.2532586765712677
Validation loss: 2.4537791779011338

Epoch: 6| Step: 1
Training loss: 2.8810010558380976
Validation loss: 2.4586059020495363

Epoch: 6| Step: 2
Training loss: 2.9023674082144777
Validation loss: 2.4641683855288354

Epoch: 6| Step: 3
Training loss: 2.1323438415952203
Validation loss: 2.4624416538045573

Epoch: 6| Step: 4
Training loss: 3.555526600825775
Validation loss: 2.464647965431546

Epoch: 6| Step: 5
Training loss: 2.326616451337285
Validation loss: 2.4666965974675787

Epoch: 6| Step: 6
Training loss: 2.5610215178527462
Validation loss: 2.469066760509275

Epoch: 6| Step: 7
Training loss: 2.4678969056098654
Validation loss: 2.4613626183556527

Epoch: 6| Step: 8
Training loss: 2.559718413363644
Validation loss: 2.46377409684674

Epoch: 6| Step: 9
Training loss: 2.742033429721803
Validation loss: 2.455477321705678

Epoch: 6| Step: 10
Training loss: 1.9166577242214184
Validation loss: 2.4569754217665416

Epoch: 6| Step: 11
Training loss: 2.3235949793218453
Validation loss: 2.4526018690442912

Epoch: 6| Step: 12
Training loss: 2.6895505489968263
Validation loss: 2.4512692537253504

Epoch: 6| Step: 13
Training loss: 2.165952112283154
Validation loss: 2.460190884800725

Epoch: 108| Step: 0
Training loss: 3.1265993221922765
Validation loss: 2.4553870039936476

Epoch: 6| Step: 1
Training loss: 2.6793782136335915
Validation loss: 2.4486026749586087

Epoch: 6| Step: 2
Training loss: 2.371438116113492
Validation loss: 2.4514628325042542

Epoch: 6| Step: 3
Training loss: 2.139441949864974
Validation loss: 2.451486238582462

Epoch: 6| Step: 4
Training loss: 2.616547281331938
Validation loss: 2.4591958639526665

Epoch: 6| Step: 5
Training loss: 2.3066739072667666
Validation loss: 2.4592986609225234

Epoch: 6| Step: 6
Training loss: 2.8463233790196965
Validation loss: 2.4576748650377582

Epoch: 6| Step: 7
Training loss: 2.1208879290175595
Validation loss: 2.451450829508349

Epoch: 6| Step: 8
Training loss: 2.4563170639861105
Validation loss: 2.4563963716232826

Epoch: 6| Step: 9
Training loss: 2.857610940056222
Validation loss: 2.4546839221302608

Epoch: 6| Step: 10
Training loss: 2.7096967248734303
Validation loss: 2.4544396168247973

Epoch: 6| Step: 11
Training loss: 2.567800761346075
Validation loss: 2.4662721729780253

Epoch: 6| Step: 12
Training loss: 2.750842658898341
Validation loss: 2.4622424344362845

Epoch: 6| Step: 13
Training loss: 2.129028988721021
Validation loss: 2.464806533750153

Epoch: 109| Step: 0
Training loss: 2.70960882425282
Validation loss: 2.46890299359207

Epoch: 6| Step: 1
Training loss: 2.731061573643253
Validation loss: 2.474158467011202

Epoch: 6| Step: 2
Training loss: 2.7877171795322213
Validation loss: 2.468835225626067

Epoch: 6| Step: 3
Training loss: 2.8976538079344825
Validation loss: 2.4725176394212327

Epoch: 6| Step: 4
Training loss: 2.638067688797289
Validation loss: 2.467370174797034

Epoch: 6| Step: 5
Training loss: 1.8350978148581196
Validation loss: 2.4656108502851053

Epoch: 6| Step: 6
Training loss: 1.9333325758746187
Validation loss: 2.4591364572372174

Epoch: 6| Step: 7
Training loss: 2.482459523465495
Validation loss: 2.4586874550545996

Epoch: 6| Step: 8
Training loss: 2.7622805270875634
Validation loss: 2.4606629233602684

Epoch: 6| Step: 9
Training loss: 2.3520440403843876
Validation loss: 2.462987459736004

Epoch: 6| Step: 10
Training loss: 2.6254144977107976
Validation loss: 2.4575841591887433

Epoch: 6| Step: 11
Training loss: 2.576306620812701
Validation loss: 2.4551973437868635

Epoch: 6| Step: 12
Training loss: 2.8484990634846366
Validation loss: 2.460121721962419

Epoch: 6| Step: 13
Training loss: 2.553933595246643
Validation loss: 2.458568130745962

Epoch: 110| Step: 0
Training loss: 2.3653553334058466
Validation loss: 2.4662769501636777

Epoch: 6| Step: 1
Training loss: 2.5611536164065356
Validation loss: 2.4721142504779956

Epoch: 6| Step: 2
Training loss: 2.5553242767648547
Validation loss: 2.4716293669458684

Epoch: 6| Step: 3
Training loss: 2.5686775735636247
Validation loss: 2.471452834983853

Epoch: 6| Step: 4
Training loss: 2.3582168667165258
Validation loss: 2.470372548058155

Epoch: 6| Step: 5
Training loss: 2.505382941512987
Validation loss: 2.4723351115861147

Epoch: 6| Step: 6
Training loss: 2.788123221072955
Validation loss: 2.4700410903313355

Epoch: 6| Step: 7
Training loss: 2.523699673003954
Validation loss: 2.470130711364604

Epoch: 6| Step: 8
Training loss: 2.4464451905641726
Validation loss: 2.466556427614393

Epoch: 6| Step: 9
Training loss: 2.2443433226833283
Validation loss: 2.463380067671926

Epoch: 6| Step: 10
Training loss: 2.956733880151731
Validation loss: 2.4639643547784646

Epoch: 6| Step: 11
Training loss: 2.4703258844600544
Validation loss: 2.4604427021876765

Epoch: 6| Step: 12
Training loss: 2.623346261942252
Validation loss: 2.46306767383181

Epoch: 6| Step: 13
Training loss: 2.7914940415335363
Validation loss: 2.4616459225465204

Epoch: 111| Step: 0
Training loss: 2.352612435292077
Validation loss: 2.4633962307368997

Epoch: 6| Step: 1
Training loss: 2.465465727135234
Validation loss: 2.4666193527976437

Epoch: 6| Step: 2
Training loss: 2.1761682464125647
Validation loss: 2.46166375963491

Epoch: 6| Step: 3
Training loss: 2.1052123640859586
Validation loss: 2.4627421790896458

Epoch: 6| Step: 4
Training loss: 2.261136890996527
Validation loss: 2.462117674075877

Epoch: 6| Step: 5
Training loss: 2.9657691848161383
Validation loss: 2.4636864864911434

Epoch: 6| Step: 6
Training loss: 3.342873146382126
Validation loss: 2.4652128996095253

Epoch: 6| Step: 7
Training loss: 2.6479854591811702
Validation loss: 2.459220876877211

Epoch: 6| Step: 8
Training loss: 2.858379253170589
Validation loss: 2.4587486584363494

Epoch: 6| Step: 9
Training loss: 2.2315535437715766
Validation loss: 2.461716584100056

Epoch: 6| Step: 10
Training loss: 2.606835414354531
Validation loss: 2.466390117616268

Epoch: 6| Step: 11
Training loss: 2.381878879436856
Validation loss: 2.46676747678836

Epoch: 6| Step: 12
Training loss: 2.5445377414188384
Validation loss: 2.4681315552814493

Epoch: 6| Step: 13
Training loss: 2.7399369701737486
Validation loss: 2.4772410300589005

Epoch: 112| Step: 0
Training loss: 2.308628449929572
Validation loss: 2.464467611898612

Epoch: 6| Step: 1
Training loss: 2.58787275200196
Validation loss: 2.4591069593671255

Epoch: 6| Step: 2
Training loss: 2.2393427756586375
Validation loss: 2.450507628472506

Epoch: 6| Step: 3
Training loss: 2.4534321003534867
Validation loss: 2.4543664953442104

Epoch: 6| Step: 4
Training loss: 1.9885376051123098
Validation loss: 2.4525627091142144

Epoch: 6| Step: 5
Training loss: 2.7586819842327994
Validation loss: 2.456024481181257

Epoch: 6| Step: 6
Training loss: 2.5221190418400474
Validation loss: 2.4549521264939522

Epoch: 6| Step: 7
Training loss: 2.843844234037058
Validation loss: 2.4506490810994426

Epoch: 6| Step: 8
Training loss: 3.122467846181839
Validation loss: 2.4541138035035934

Epoch: 6| Step: 9
Training loss: 2.083011704095638
Validation loss: 2.4557569440859806

Epoch: 6| Step: 10
Training loss: 2.972762758850789
Validation loss: 2.4581777528788753

Epoch: 6| Step: 11
Training loss: 2.3251776760670917
Validation loss: 2.4592802088435426

Epoch: 6| Step: 12
Training loss: 2.5673285790915075
Validation loss: 2.4659798447774532

Epoch: 6| Step: 13
Training loss: 2.549857143065612
Validation loss: 2.4660177120347146

Epoch: 113| Step: 0
Training loss: 2.8972050187683243
Validation loss: 2.4745367130329154

Epoch: 6| Step: 1
Training loss: 3.0362661485175817
Validation loss: 2.4693003012982726

Epoch: 6| Step: 2
Training loss: 2.667557915127674
Validation loss: 2.4765026995862827

Epoch: 6| Step: 3
Training loss: 2.1227228642113998
Validation loss: 2.47720498657086

Epoch: 6| Step: 4
Training loss: 2.6083502670404655
Validation loss: 2.475897024699224

Epoch: 6| Step: 5
Training loss: 2.3194436652613057
Validation loss: 2.472611686542008

Epoch: 6| Step: 6
Training loss: 2.4178486487615123
Validation loss: 2.472630047169677

Epoch: 6| Step: 7
Training loss: 2.4862916858337236
Validation loss: 2.474970838586885

Epoch: 6| Step: 8
Training loss: 2.6402356464525716
Validation loss: 2.4821402457270225

Epoch: 6| Step: 9
Training loss: 2.5888192061931896
Validation loss: 2.4691058357136333

Epoch: 6| Step: 10
Training loss: 2.7793157473665295
Validation loss: 2.4725364427031193

Epoch: 6| Step: 11
Training loss: 2.0887296469956387
Validation loss: 2.4720777625359727

Epoch: 6| Step: 12
Training loss: 1.834808651876665
Validation loss: 2.4686145986776062

Epoch: 6| Step: 13
Training loss: 2.9921613647275707
Validation loss: 2.4641011404597086

Epoch: 114| Step: 0
Training loss: 2.3538462553029067
Validation loss: 2.4641879056063187

Epoch: 6| Step: 1
Training loss: 2.5094211445861365
Validation loss: 2.45824182199963

Epoch: 6| Step: 2
Training loss: 2.6055195358794307
Validation loss: 2.4502691260589926

Epoch: 6| Step: 3
Training loss: 2.5835635072445142
Validation loss: 2.4579618033143493

Epoch: 6| Step: 4
Training loss: 2.4802246934868393
Validation loss: 2.4450165525836924

Epoch: 6| Step: 5
Training loss: 2.235376947008008
Validation loss: 2.4511126547824214

Epoch: 6| Step: 6
Training loss: 2.399486399372567
Validation loss: 2.4503613270417337

Epoch: 6| Step: 7
Training loss: 2.1408124410051097
Validation loss: 2.458285579109813

Epoch: 6| Step: 8
Training loss: 2.75015145665023
Validation loss: 2.464628166850762

Epoch: 6| Step: 9
Training loss: 2.725543599635343
Validation loss: 2.465867770402423

Epoch: 6| Step: 10
Training loss: 3.775144076597907
Validation loss: 2.471443091595828

Epoch: 6| Step: 11
Training loss: 2.9133136185852657
Validation loss: 2.4548242114463905

Epoch: 6| Step: 12
Training loss: 2.021526362033763
Validation loss: 2.452440299922226

Epoch: 6| Step: 13
Training loss: 1.7239263787050032
Validation loss: 2.4527250640185323

Epoch: 115| Step: 0
Training loss: 2.444613323254198
Validation loss: 2.4548993992701007

Epoch: 6| Step: 1
Training loss: 3.0452132951168376
Validation loss: 2.4517805298747217

Epoch: 6| Step: 2
Training loss: 2.7572266385939814
Validation loss: 2.4596889497428536

Epoch: 6| Step: 3
Training loss: 1.9522205547467248
Validation loss: 2.457227528246977

Epoch: 6| Step: 4
Training loss: 2.5700915395264445
Validation loss: 2.4611896204093

Epoch: 6| Step: 5
Training loss: 1.897395786142641
Validation loss: 2.4660103239367746

Epoch: 6| Step: 6
Training loss: 2.9219507217795124
Validation loss: 2.4673442298757116

Epoch: 6| Step: 7
Training loss: 2.1641235342955576
Validation loss: 2.4614157398707435

Epoch: 6| Step: 8
Training loss: 2.8006775649283284
Validation loss: 2.4674377011747772

Epoch: 6| Step: 9
Training loss: 1.9793851096085098
Validation loss: 2.465564797637054

Epoch: 6| Step: 10
Training loss: 2.40499865208705
Validation loss: 2.464797562107489

Epoch: 6| Step: 11
Training loss: 2.4768564910158606
Validation loss: 2.4701956206372593

Epoch: 6| Step: 12
Training loss: 3.3503913878504146
Validation loss: 2.464992802824149

Epoch: 6| Step: 13
Training loss: 2.3568544376501057
Validation loss: 2.463515256668912

Epoch: 116| Step: 0
Training loss: 2.106339821187877
Validation loss: 2.4631211376893933

Epoch: 6| Step: 1
Training loss: 2.2800555302734122
Validation loss: 2.4567432163981153

Epoch: 6| Step: 2
Training loss: 2.7918856141123687
Validation loss: 2.458916503357403

Epoch: 6| Step: 3
Training loss: 2.832696244662736
Validation loss: 2.453894735360094

Epoch: 6| Step: 4
Training loss: 2.310875605643519
Validation loss: 2.4552636998218422

Epoch: 6| Step: 5
Training loss: 2.800543058048369
Validation loss: 2.4476102488400073

Epoch: 6| Step: 6
Training loss: 2.4143230211240563
Validation loss: 2.4469300060496053

Epoch: 6| Step: 7
Training loss: 2.2869901161797586
Validation loss: 2.447453399541874

Epoch: 6| Step: 8
Training loss: 2.5451638493883166
Validation loss: 2.4473503648152666

Epoch: 6| Step: 9
Training loss: 2.5554282138260245
Validation loss: 2.44572958674746

Epoch: 6| Step: 10
Training loss: 2.7643298548669604
Validation loss: 2.4552187397579455

Epoch: 6| Step: 11
Training loss: 2.331707955958963
Validation loss: 2.450485834621067

Epoch: 6| Step: 12
Training loss: 3.0117923712730748
Validation loss: 2.452677384214772

Epoch: 6| Step: 13
Training loss: 2.3448583398256915
Validation loss: 2.4588137388929163

Epoch: 117| Step: 0
Training loss: 2.4046802106700964
Validation loss: 2.454267280428922

Epoch: 6| Step: 1
Training loss: 2.3971699400154085
Validation loss: 2.4550777527356935

Epoch: 6| Step: 2
Training loss: 2.2497990836401476
Validation loss: 2.45447843111733

Epoch: 6| Step: 3
Training loss: 2.50347258670244
Validation loss: 2.4609419726780204

Epoch: 6| Step: 4
Training loss: 3.178629331229737
Validation loss: 2.4544027608919343

Epoch: 6| Step: 5
Training loss: 2.33862028152648
Validation loss: 2.457793909363504

Epoch: 6| Step: 6
Training loss: 2.971088973750434
Validation loss: 2.460665192247147

Epoch: 6| Step: 7
Training loss: 2.584112162756921
Validation loss: 2.4600153088287136

Epoch: 6| Step: 8
Training loss: 2.594112508788305
Validation loss: 2.4643158828541987

Epoch: 6| Step: 9
Training loss: 2.60353174226069
Validation loss: 2.457771080720587

Epoch: 6| Step: 10
Training loss: 2.0967247171457073
Validation loss: 2.4545931138496884

Epoch: 6| Step: 11
Training loss: 2.4616632269454546
Validation loss: 2.4551176332518256

Epoch: 6| Step: 12
Training loss: 2.770090237741712
Validation loss: 2.449833356289165

Epoch: 6| Step: 13
Training loss: 2.0684835164365647
Validation loss: 2.457523137006635

Epoch: 118| Step: 0
Training loss: 2.473825187446444
Validation loss: 2.4477213369044604

Epoch: 6| Step: 1
Training loss: 2.3501791703119914
Validation loss: 2.4542055362241992

Epoch: 6| Step: 2
Training loss: 2.4766819681419694
Validation loss: 2.458701386351731

Epoch: 6| Step: 3
Training loss: 2.203109849377205
Validation loss: 2.4563195876342028

Epoch: 6| Step: 4
Training loss: 2.6817586918655607
Validation loss: 2.467300585103319

Epoch: 6| Step: 5
Training loss: 3.2757774129199593
Validation loss: 2.4657454899178073

Epoch: 6| Step: 6
Training loss: 2.71314073018064
Validation loss: 2.4700662347404623

Epoch: 6| Step: 7
Training loss: 2.2788982026353994
Validation loss: 2.4700810509998874

Epoch: 6| Step: 8
Training loss: 2.4267567317967917
Validation loss: 2.467532231778364

Epoch: 6| Step: 9
Training loss: 2.5543391838950904
Validation loss: 2.465140355597653

Epoch: 6| Step: 10
Training loss: 2.461546032462948
Validation loss: 2.4570326084927685

Epoch: 6| Step: 11
Training loss: 2.572777583472492
Validation loss: 2.4489905876221787

Epoch: 6| Step: 12
Training loss: 2.9600931941646107
Validation loss: 2.4431796456314547

Epoch: 6| Step: 13
Training loss: 2.1240506014786
Validation loss: 2.4431036905078423

Epoch: 119| Step: 0
Training loss: 2.485148759223228
Validation loss: 2.4460970886396125

Epoch: 6| Step: 1
Training loss: 2.6518300700916133
Validation loss: 2.4398515964804925

Epoch: 6| Step: 2
Training loss: 3.062121153773669
Validation loss: 2.4455090526038106

Epoch: 6| Step: 3
Training loss: 2.7513769343903456
Validation loss: 2.438030869799381

Epoch: 6| Step: 4
Training loss: 2.7527938868819772
Validation loss: 2.4385210083340785

Epoch: 6| Step: 5
Training loss: 2.705825250784086
Validation loss: 2.4387816295726705

Epoch: 6| Step: 6
Training loss: 2.5719122734474382
Validation loss: 2.4429212584483024

Epoch: 6| Step: 7
Training loss: 2.2235356687854884
Validation loss: 2.4451973982464055

Epoch: 6| Step: 8
Training loss: 2.6634585235671864
Validation loss: 2.4447938736747292

Epoch: 6| Step: 9
Training loss: 2.4922551352193256
Validation loss: 2.447963248817439

Epoch: 6| Step: 10
Training loss: 2.2553149074072754
Validation loss: 2.449528367845318

Epoch: 6| Step: 11
Training loss: 2.08562635751508
Validation loss: 2.4475717883285903

Epoch: 6| Step: 12
Training loss: 2.650540217631489
Validation loss: 2.452760349392729

Epoch: 6| Step: 13
Training loss: 2.380252851630539
Validation loss: 2.4555093633853438

Epoch: 120| Step: 0
Training loss: 2.1275148657022775
Validation loss: 2.4528620552665292

Epoch: 6| Step: 1
Training loss: 2.639448998778131
Validation loss: 2.4454871817079784

Epoch: 6| Step: 2
Training loss: 2.586518467298706
Validation loss: 2.4483852397938084

Epoch: 6| Step: 3
Training loss: 2.3721786606198934
Validation loss: 2.4469082128122834

Epoch: 6| Step: 4
Training loss: 2.73239945026873
Validation loss: 2.447880007421991

Epoch: 6| Step: 5
Training loss: 2.597931765522911
Validation loss: 2.445230744674027

Epoch: 6| Step: 6
Training loss: 2.56114337645218
Validation loss: 2.449158427962388

Epoch: 6| Step: 7
Training loss: 2.654043380612743
Validation loss: 2.452164099331974

Epoch: 6| Step: 8
Training loss: 2.0818930288385644
Validation loss: 2.4511975696123804

Epoch: 6| Step: 9
Training loss: 2.32341274102057
Validation loss: 2.4504783753714388

Epoch: 6| Step: 10
Training loss: 3.1570870073355923
Validation loss: 2.4516374649895103

Epoch: 6| Step: 11
Training loss: 2.900383720004407
Validation loss: 2.4552754009561544

Epoch: 6| Step: 12
Training loss: 2.07503388618468
Validation loss: 2.4509525195855666

Epoch: 6| Step: 13
Training loss: 2.4560565319016434
Validation loss: 2.4524175024593626

Epoch: 121| Step: 0
Training loss: 1.835123214326895
Validation loss: 2.4540528569496955

Epoch: 6| Step: 1
Training loss: 2.960672250909771
Validation loss: 2.456126068068926

Epoch: 6| Step: 2
Training loss: 1.8455840218681192
Validation loss: 2.4535595130406325

Epoch: 6| Step: 3
Training loss: 2.7628334741709923
Validation loss: 2.454658223541523

Epoch: 6| Step: 4
Training loss: 2.2029559564330574
Validation loss: 2.463921988703462

Epoch: 6| Step: 5
Training loss: 2.763153868746394
Validation loss: 2.463391730253414

Epoch: 6| Step: 6
Training loss: 2.8794849078178175
Validation loss: 2.4589088757604705

Epoch: 6| Step: 7
Training loss: 3.2736842533601562
Validation loss: 2.4547935043682476

Epoch: 6| Step: 8
Training loss: 2.104889232593496
Validation loss: 2.4671377075917404

Epoch: 6| Step: 9
Training loss: 2.5566709325755643
Validation loss: 2.455418933569807

Epoch: 6| Step: 10
Training loss: 2.243745800641309
Validation loss: 2.4538469001550265

Epoch: 6| Step: 11
Training loss: 2.7485757954531342
Validation loss: 2.4489677174814446

Epoch: 6| Step: 12
Training loss: 2.2731056626645616
Validation loss: 2.4458487332025496

Epoch: 6| Step: 13
Training loss: 2.5728058475819364
Validation loss: 2.442519383283614

Epoch: 122| Step: 0
Training loss: 2.4391445578652813
Validation loss: 2.448791994010955

Epoch: 6| Step: 1
Training loss: 2.087955256176347
Validation loss: 2.4469672911977782

Epoch: 6| Step: 2
Training loss: 2.3652147186747743
Validation loss: 2.4459494755434994

Epoch: 6| Step: 3
Training loss: 2.446999452429532
Validation loss: 2.4431236879155422

Epoch: 6| Step: 4
Training loss: 2.604911870509038
Validation loss: 2.44822579454316

Epoch: 6| Step: 5
Training loss: 2.654237051788593
Validation loss: 2.4475571767475186

Epoch: 6| Step: 6
Training loss: 2.7942455867730094
Validation loss: 2.4472885029284877

Epoch: 6| Step: 7
Training loss: 1.597417016060447
Validation loss: 2.4526363299136165

Epoch: 6| Step: 8
Training loss: 2.427717679887788
Validation loss: 2.446564253444533

Epoch: 6| Step: 9
Training loss: 3.191831749480569
Validation loss: 2.451282708447312

Epoch: 6| Step: 10
Training loss: 2.513569436286803
Validation loss: 2.4545107448630477

Epoch: 6| Step: 11
Training loss: 2.683376164617742
Validation loss: 2.4661882041720617

Epoch: 6| Step: 12
Training loss: 2.8046475463401626
Validation loss: 2.463939857696403

Epoch: 6| Step: 13
Training loss: 2.5958961891495793
Validation loss: 2.464335135707388

Epoch: 123| Step: 0
Training loss: 2.3294233759592378
Validation loss: 2.4674934215258273

Epoch: 6| Step: 1
Training loss: 2.470734004253673
Validation loss: 2.464838526700587

Epoch: 6| Step: 2
Training loss: 2.153981439041174
Validation loss: 2.4675924589284173

Epoch: 6| Step: 3
Training loss: 2.5291181464361867
Validation loss: 2.4534503534732073

Epoch: 6| Step: 4
Training loss: 2.7524508045869127
Validation loss: 2.4567289666808505

Epoch: 6| Step: 5
Training loss: 2.285609221598255
Validation loss: 2.4626410506850247

Epoch: 6| Step: 6
Training loss: 2.8409730536456217
Validation loss: 2.4656359190028247

Epoch: 6| Step: 7
Training loss: 2.9935732986450074
Validation loss: 2.4564090622252768

Epoch: 6| Step: 8
Training loss: 3.2921896088552214
Validation loss: 2.4635093450274175

Epoch: 6| Step: 9
Training loss: 2.577240115808473
Validation loss: 2.451262947812171

Epoch: 6| Step: 10
Training loss: 2.620267689548642
Validation loss: 2.45249961770068

Epoch: 6| Step: 11
Training loss: 1.8662371271791964
Validation loss: 2.450506744722628

Epoch: 6| Step: 12
Training loss: 2.2689798706291584
Validation loss: 2.445970570636499

Epoch: 6| Step: 13
Training loss: 2.3199752408383647
Validation loss: 2.447035551102097

Epoch: 124| Step: 0
Training loss: 1.9956929799253418
Validation loss: 2.4524700481051807

Epoch: 6| Step: 1
Training loss: 2.5642939545043237
Validation loss: 2.4415991216133217

Epoch: 6| Step: 2
Training loss: 2.9078820680949637
Validation loss: 2.445430391209976

Epoch: 6| Step: 3
Training loss: 2.589481932623266
Validation loss: 2.449444644291851

Epoch: 6| Step: 4
Training loss: 2.8672521932096124
Validation loss: 2.443898906545112

Epoch: 6| Step: 5
Training loss: 2.5788288427255583
Validation loss: 2.445384665369884

Epoch: 6| Step: 6
Training loss: 2.0411396773754
Validation loss: 2.4521337802681344

Epoch: 6| Step: 7
Training loss: 3.3466514762087862
Validation loss: 2.4473042526910844

Epoch: 6| Step: 8
Training loss: 2.3408017752577437
Validation loss: 2.4467482571765697

Epoch: 6| Step: 9
Training loss: 2.224008266296393
Validation loss: 2.4464962240231944

Epoch: 6| Step: 10
Training loss: 2.137023792425365
Validation loss: 2.450491429043388

Epoch: 6| Step: 11
Training loss: 2.715253488920369
Validation loss: 2.4542273699037778

Epoch: 6| Step: 12
Training loss: 2.4227566990699216
Validation loss: 2.4591812164081324

Epoch: 6| Step: 13
Training loss: 2.4301110784629194
Validation loss: 2.446657600992369

Epoch: 125| Step: 0
Training loss: 2.8455435996810077
Validation loss: 2.4511967914829635

Epoch: 6| Step: 1
Training loss: 2.0317354062442106
Validation loss: 2.447362103784191

Epoch: 6| Step: 2
Training loss: 2.8552207578165825
Validation loss: 2.4453555947305854

Epoch: 6| Step: 3
Training loss: 2.2952804739777735
Validation loss: 2.4500620564886195

Epoch: 6| Step: 4
Training loss: 2.4918851758731435
Validation loss: 2.444876374991858

Epoch: 6| Step: 5
Training loss: 2.4024959857125143
Validation loss: 2.4487582011504982

Epoch: 6| Step: 6
Training loss: 2.50408125576744
Validation loss: 2.448368474510345

Epoch: 6| Step: 7
Training loss: 2.212940185207378
Validation loss: 2.4502341048310825

Epoch: 6| Step: 8
Training loss: 3.115806943120725
Validation loss: 2.453825759417749

Epoch: 6| Step: 9
Training loss: 1.8169468229130157
Validation loss: 2.451826201261298

Epoch: 6| Step: 10
Training loss: 2.2545573386664977
Validation loss: 2.456065207851319

Epoch: 6| Step: 11
Training loss: 2.841419816319088
Validation loss: 2.4529000440340694

Epoch: 6| Step: 12
Training loss: 3.1071272350100205
Validation loss: 2.456280406087478

Epoch: 6| Step: 13
Training loss: 2.288608336718296
Validation loss: 2.454598682722299

Epoch: 126| Step: 0
Training loss: 2.6532646906262802
Validation loss: 2.4585045146071858

Epoch: 6| Step: 1
Training loss: 2.2097371755504693
Validation loss: 2.456009175641733

Epoch: 6| Step: 2
Training loss: 2.3829992002292943
Validation loss: 2.45878820467527

Epoch: 6| Step: 3
Training loss: 2.4821525565699853
Validation loss: 2.4560704781218696

Epoch: 6| Step: 4
Training loss: 2.2432766173261025
Validation loss: 2.453540143240372

Epoch: 6| Step: 5
Training loss: 2.5120882560448483
Validation loss: 2.4463142398800004

Epoch: 6| Step: 6
Training loss: 2.685343919887844
Validation loss: 2.4482718243889092

Epoch: 6| Step: 7
Training loss: 2.8373618004035297
Validation loss: 2.4444509660267775

Epoch: 6| Step: 8
Training loss: 2.4196269769303314
Validation loss: 2.447051367446726

Epoch: 6| Step: 9
Training loss: 2.5649577194209248
Validation loss: 2.442831005169328

Epoch: 6| Step: 10
Training loss: 2.1571454386483646
Validation loss: 2.4474773878586262

Epoch: 6| Step: 11
Training loss: 2.532854678292874
Validation loss: 2.448638392980608

Epoch: 6| Step: 12
Training loss: 2.8197545056994073
Validation loss: 2.447676648216185

Epoch: 6| Step: 13
Training loss: 2.8132427506380133
Validation loss: 2.4494021487485567

Epoch: 127| Step: 0
Training loss: 2.2010802391224122
Validation loss: 2.447569353071136

Epoch: 6| Step: 1
Training loss: 2.3842202952581375
Validation loss: 2.4453982499660234

Epoch: 6| Step: 2
Training loss: 1.766300983489542
Validation loss: 2.448130120785042

Epoch: 6| Step: 3
Training loss: 2.6767393749650035
Validation loss: 2.4500542472490885

Epoch: 6| Step: 4
Training loss: 2.9226874379663634
Validation loss: 2.45364528249239

Epoch: 6| Step: 5
Training loss: 3.8555409773503047
Validation loss: 2.4485228714526794

Epoch: 6| Step: 6
Training loss: 2.177357292885986
Validation loss: 2.4425656752149867

Epoch: 6| Step: 7
Training loss: 2.4442120595732044
Validation loss: 2.4518205450569526

Epoch: 6| Step: 8
Training loss: 2.6438612208858383
Validation loss: 2.445821438965694

Epoch: 6| Step: 9
Training loss: 1.914044687616417
Validation loss: 2.444157100957479

Epoch: 6| Step: 10
Training loss: 2.5715394961183144
Validation loss: 2.444397760316321

Epoch: 6| Step: 11
Training loss: 2.5070078857322198
Validation loss: 2.4520494569454834

Epoch: 6| Step: 12
Training loss: 2.4075600166802147
Validation loss: 2.4497470884119283

Epoch: 6| Step: 13
Training loss: 2.2510517629114264
Validation loss: 2.451443997256884

Epoch: 128| Step: 0
Training loss: 2.5954679751462484
Validation loss: 2.4531839934623796

Epoch: 6| Step: 1
Training loss: 2.8901008749387587
Validation loss: 2.4508770647614684

Epoch: 6| Step: 2
Training loss: 2.420045420007629
Validation loss: 2.4529183497119917

Epoch: 6| Step: 3
Training loss: 2.322092317702635
Validation loss: 2.4522301404420226

Epoch: 6| Step: 4
Training loss: 3.0103476405342486
Validation loss: 2.4496456344095408

Epoch: 6| Step: 5
Training loss: 2.3374364630075855
Validation loss: 2.45428754306986

Epoch: 6| Step: 6
Training loss: 2.297908731990429
Validation loss: 2.4529674989714256

Epoch: 6| Step: 7
Training loss: 2.354161445364324
Validation loss: 2.4583948634146844

Epoch: 6| Step: 8
Training loss: 2.4997644313453296
Validation loss: 2.4546188697796025

Epoch: 6| Step: 9
Training loss: 2.133130283924782
Validation loss: 2.4563212862420354

Epoch: 6| Step: 10
Training loss: 2.4050717131774104
Validation loss: 2.4490514654518023

Epoch: 6| Step: 11
Training loss: 2.897418971669043
Validation loss: 2.4519639719970847

Epoch: 6| Step: 12
Training loss: 2.8633575221125422
Validation loss: 2.4487811381560847

Epoch: 6| Step: 13
Training loss: 2.076788680572697
Validation loss: 2.448741032738305

Epoch: 129| Step: 0
Training loss: 2.1569447158427932
Validation loss: 2.4447744181712197

Epoch: 6| Step: 1
Training loss: 2.510512755099656
Validation loss: 2.4456305495057094

Epoch: 6| Step: 2
Training loss: 2.339515420998616
Validation loss: 2.4475172542162555

Epoch: 6| Step: 3
Training loss: 2.787890276081052
Validation loss: 2.4402694619020857

Epoch: 6| Step: 4
Training loss: 2.2580770053825776
Validation loss: 2.44793123822576

Epoch: 6| Step: 5
Training loss: 2.5793889502001814
Validation loss: 2.4513887550082605

Epoch: 6| Step: 6
Training loss: 2.43269853367854
Validation loss: 2.458310278013923

Epoch: 6| Step: 7
Training loss: 3.064280556754778
Validation loss: 2.4582064536590567

Epoch: 6| Step: 8
Training loss: 2.471457433335156
Validation loss: 2.4605708257802763

Epoch: 6| Step: 9
Training loss: 2.9045674365399408
Validation loss: 2.460838420831227

Epoch: 6| Step: 10
Training loss: 2.5034555395531366
Validation loss: 2.4560234780727077

Epoch: 6| Step: 11
Training loss: 2.3434084834189517
Validation loss: 2.439733118095198

Epoch: 6| Step: 12
Training loss: 2.208288756106565
Validation loss: 2.441379492040866

Epoch: 6| Step: 13
Training loss: 2.840342397869276
Validation loss: 2.4402204314183042

Epoch: 130| Step: 0
Training loss: 2.468537043790545
Validation loss: 2.443488874086024

Epoch: 6| Step: 1
Training loss: 2.385323623997115
Validation loss: 2.4478601706187657

Epoch: 6| Step: 2
Training loss: 2.7458729553451215
Validation loss: 2.4596913003033913

Epoch: 6| Step: 3
Training loss: 2.195649362152572
Validation loss: 2.457649690862351

Epoch: 6| Step: 4
Training loss: 2.9219432149665843
Validation loss: 2.4654825856796707

Epoch: 6| Step: 5
Training loss: 2.2544795056035714
Validation loss: 2.4641020919015424

Epoch: 6| Step: 6
Training loss: 2.5927741731401968
Validation loss: 2.467537932486033

Epoch: 6| Step: 7
Training loss: 2.677947700177824
Validation loss: 2.470377984848861

Epoch: 6| Step: 8
Training loss: 2.418941172849203
Validation loss: 2.4691343209547734

Epoch: 6| Step: 9
Training loss: 2.4244060457527774
Validation loss: 2.469307446216742

Epoch: 6| Step: 10
Training loss: 2.755907475993226
Validation loss: 2.46158300744038

Epoch: 6| Step: 11
Training loss: 2.6845793711765134
Validation loss: 2.4536723601407298

Epoch: 6| Step: 12
Training loss: 2.5533329817105175
Validation loss: 2.4512656387693936

Epoch: 6| Step: 13
Training loss: 2.358853718347746
Validation loss: 2.447776454941149

Epoch: 131| Step: 0
Training loss: 2.6998353024866124
Validation loss: 2.445694102451555

Epoch: 6| Step: 1
Training loss: 2.944969582262965
Validation loss: 2.4390565352822096

Epoch: 6| Step: 2
Training loss: 2.4308426738878213
Validation loss: 2.444375521839346

Epoch: 6| Step: 3
Training loss: 2.8361273247527996
Validation loss: 2.4563834625689016

Epoch: 6| Step: 4
Training loss: 2.1571056492681326
Validation loss: 2.4452095863209284

Epoch: 6| Step: 5
Training loss: 2.254598157649834
Validation loss: 2.4571154023574096

Epoch: 6| Step: 6
Training loss: 2.487711459425889
Validation loss: 2.457631662954651

Epoch: 6| Step: 7
Training loss: 2.2185666720448376
Validation loss: 2.451175522516584

Epoch: 6| Step: 8
Training loss: 2.149039444260971
Validation loss: 2.4486236660537437

Epoch: 6| Step: 9
Training loss: 2.328415820499916
Validation loss: 2.4500415156214053

Epoch: 6| Step: 10
Training loss: 2.783912498688492
Validation loss: 2.458486509130812

Epoch: 6| Step: 11
Training loss: 2.11632844170054
Validation loss: 2.460492597458615

Epoch: 6| Step: 12
Training loss: 3.054582911113113
Validation loss: 2.4664591691231914

Epoch: 6| Step: 13
Training loss: 2.67124521072094
Validation loss: 2.4763722151088396

Epoch: 132| Step: 0
Training loss: 2.110295638756068
Validation loss: 2.4757058379802954

Epoch: 6| Step: 1
Training loss: 2.898167024315555
Validation loss: 2.4777761347679235

Epoch: 6| Step: 2
Training loss: 2.7201830715391178
Validation loss: 2.4832166294436586

Epoch: 6| Step: 3
Training loss: 2.7913311619112022
Validation loss: 2.484847113897223

Epoch: 6| Step: 4
Training loss: 2.6147889034923373
Validation loss: 2.4795643196366264

Epoch: 6| Step: 5
Training loss: 2.75326058684977
Validation loss: 2.4739656843109676

Epoch: 6| Step: 6
Training loss: 2.1946925037820733
Validation loss: 2.477128326246952

Epoch: 6| Step: 7
Training loss: 2.7535308365571454
Validation loss: 2.468443815341805

Epoch: 6| Step: 8
Training loss: 2.48127389891523
Validation loss: 2.4641566782458546

Epoch: 6| Step: 9
Training loss: 2.3926283476871726
Validation loss: 2.459565328094514

Epoch: 6| Step: 10
Training loss: 2.649687345522527
Validation loss: 2.4612329376337074

Epoch: 6| Step: 11
Training loss: 2.3402413108492404
Validation loss: 2.449719788947267

Epoch: 6| Step: 12
Training loss: 2.784124453454004
Validation loss: 2.447560992002102

Epoch: 6| Step: 13
Training loss: 2.243180111739223
Validation loss: 2.4413418123006676

Epoch: 133| Step: 0
Training loss: 2.4963760813284344
Validation loss: 2.445211820794668

Epoch: 6| Step: 1
Training loss: 2.869949548789605
Validation loss: 2.438996222583431

Epoch: 6| Step: 2
Training loss: 1.9849008178915275
Validation loss: 2.4537678744830558

Epoch: 6| Step: 3
Training loss: 2.0202706199134677
Validation loss: 2.4586383474107496

Epoch: 6| Step: 4
Training loss: 2.501259009913622
Validation loss: 2.45952178762616

Epoch: 6| Step: 5
Training loss: 2.675987246860741
Validation loss: 2.4644041158007646

Epoch: 6| Step: 6
Training loss: 3.290790602238429
Validation loss: 2.4709656506812303

Epoch: 6| Step: 7
Training loss: 2.8856941025498895
Validation loss: 2.4701427603275317

Epoch: 6| Step: 8
Training loss: 2.2783439625192354
Validation loss: 2.464565593906084

Epoch: 6| Step: 9
Training loss: 2.2144129096911747
Validation loss: 2.4630406672054983

Epoch: 6| Step: 10
Training loss: 2.3539524037128094
Validation loss: 2.4579488216490573

Epoch: 6| Step: 11
Training loss: 2.863342700834868
Validation loss: 2.4535292760028615

Epoch: 6| Step: 12
Training loss: 2.306781606217671
Validation loss: 2.4502340399614764

Epoch: 6| Step: 13
Training loss: 2.3338325738422308
Validation loss: 2.454837549562045

Epoch: 134| Step: 0
Training loss: 2.4806236879513963
Validation loss: 2.4459762728598973

Epoch: 6| Step: 1
Training loss: 2.227430100976533
Validation loss: 2.448777998224963

Epoch: 6| Step: 2
Training loss: 2.284282497719673
Validation loss: 2.449769416001044

Epoch: 6| Step: 3
Training loss: 2.2573917617281163
Validation loss: 2.4414656893806

Epoch: 6| Step: 4
Training loss: 2.754641344156535
Validation loss: 2.4463872528166957

Epoch: 6| Step: 5
Training loss: 2.2241015302549307
Validation loss: 2.4479401499386126

Epoch: 6| Step: 6
Training loss: 3.2121183354205103
Validation loss: 2.4463976157666005

Epoch: 6| Step: 7
Training loss: 2.1514704710228085
Validation loss: 2.449693162349245

Epoch: 6| Step: 8
Training loss: 2.604627024332384
Validation loss: 2.4547855240262253

Epoch: 6| Step: 9
Training loss: 2.559922107912247
Validation loss: 2.4539808007556405

Epoch: 6| Step: 10
Training loss: 2.8071724342027693
Validation loss: 2.459569278202765

Epoch: 6| Step: 11
Training loss: 2.612690355584649
Validation loss: 2.458772496151404

Epoch: 6| Step: 12
Training loss: 2.2231538078236888
Validation loss: 2.4586675034248864

Epoch: 6| Step: 13
Training loss: 2.8952003354344593
Validation loss: 2.4540813064194626

Epoch: 135| Step: 0
Training loss: 2.9507087631957503
Validation loss: 2.451558611226285

Epoch: 6| Step: 1
Training loss: 2.0042507775224183
Validation loss: 2.452385906478139

Epoch: 6| Step: 2
Training loss: 2.3833681553072976
Validation loss: 2.445470965271117

Epoch: 6| Step: 3
Training loss: 2.4078453027073854
Validation loss: 2.447026798481407

Epoch: 6| Step: 4
Training loss: 2.5036927606797867
Validation loss: 2.4350577370301907

Epoch: 6| Step: 5
Training loss: 1.922228152695305
Validation loss: 2.4382696974249543

Epoch: 6| Step: 6
Training loss: 2.5046329485211256
Validation loss: 2.4450500314920403

Epoch: 6| Step: 7
Training loss: 2.276099674931792
Validation loss: 2.440056593087523

Epoch: 6| Step: 8
Training loss: 2.8063610471236133
Validation loss: 2.4503516538449976

Epoch: 6| Step: 9
Training loss: 2.4558755797950838
Validation loss: 2.447535843682506

Epoch: 6| Step: 10
Training loss: 1.933030911612389
Validation loss: 2.4444050024082427

Epoch: 6| Step: 11
Training loss: 3.020928497569374
Validation loss: 2.439789682897331

Epoch: 6| Step: 12
Training loss: 3.0057825942516616
Validation loss: 2.4371401529334933

Epoch: 6| Step: 13
Training loss: 2.8280562081585128
Validation loss: 2.4464061757250306

Epoch: 136| Step: 0
Training loss: 2.3604196421062125
Validation loss: 2.4515475569091936

Epoch: 6| Step: 1
Training loss: 2.772512964161591
Validation loss: 2.456364009887011

Epoch: 6| Step: 2
Training loss: 2.479299098305782
Validation loss: 2.456826723579176

Epoch: 6| Step: 3
Training loss: 2.460829765746978
Validation loss: 2.4647657620867873

Epoch: 6| Step: 4
Training loss: 2.7642384302228877
Validation loss: 2.4663325920138237

Epoch: 6| Step: 5
Training loss: 2.5562002387018423
Validation loss: 2.469445899068516

Epoch: 6| Step: 6
Training loss: 2.836433472362722
Validation loss: 2.4643465841501144

Epoch: 6| Step: 7
Training loss: 2.0759616002480263
Validation loss: 2.460580515324961

Epoch: 6| Step: 8
Training loss: 2.678248783843043
Validation loss: 2.459369026380407

Epoch: 6| Step: 9
Training loss: 3.188115827124329
Validation loss: 2.4586768691553917

Epoch: 6| Step: 10
Training loss: 1.9183613983187127
Validation loss: 2.4568064090971853

Epoch: 6| Step: 11
Training loss: 2.4550525843005704
Validation loss: 2.456819882016819

Epoch: 6| Step: 12
Training loss: 2.4404806839284614
Validation loss: 2.4488092594268895

Epoch: 6| Step: 13
Training loss: 2.152981699921138
Validation loss: 2.4477575426260474

Epoch: 137| Step: 0
Training loss: 2.268419108155312
Validation loss: 2.45060535789167

Epoch: 6| Step: 1
Training loss: 2.2318354760107164
Validation loss: 2.451167854619877

Epoch: 6| Step: 2
Training loss: 2.5597416988833936
Validation loss: 2.4511640449794014

Epoch: 6| Step: 3
Training loss: 2.4747809611795244
Validation loss: 2.450773274103996

Epoch: 6| Step: 4
Training loss: 2.607907550741186
Validation loss: 2.4468261535238125

Epoch: 6| Step: 5
Training loss: 2.906492653837949
Validation loss: 2.4563480108506517

Epoch: 6| Step: 6
Training loss: 2.348866891596558
Validation loss: 2.454458615263235

Epoch: 6| Step: 7
Training loss: 3.1096363053675837
Validation loss: 2.4560661745403176

Epoch: 6| Step: 8
Training loss: 2.8349190556779735
Validation loss: 2.459609538248956

Epoch: 6| Step: 9
Training loss: 2.281410420669162
Validation loss: 2.4622392874639702

Epoch: 6| Step: 10
Training loss: 2.2969976898434172
Validation loss: 2.463257663693333

Epoch: 6| Step: 11
Training loss: 2.35926272901986
Validation loss: 2.463038311774827

Epoch: 6| Step: 12
Training loss: 2.7478435037131277
Validation loss: 2.467411531500503

Epoch: 6| Step: 13
Training loss: 2.084215689408855
Validation loss: 2.4658899439683766

Epoch: 138| Step: 0
Training loss: 2.2491241445781975
Validation loss: 2.4584321524807295

Epoch: 6| Step: 1
Training loss: 2.7978696279957775
Validation loss: 2.4585452446417086

Epoch: 6| Step: 2
Training loss: 2.111618544289407
Validation loss: 2.454066523099272

Epoch: 6| Step: 3
Training loss: 2.5220334897823986
Validation loss: 2.4508230987079176

Epoch: 6| Step: 4
Training loss: 2.6335172077961717
Validation loss: 2.4410699394012374

Epoch: 6| Step: 5
Training loss: 2.7738454599272617
Validation loss: 2.447440191661016

Epoch: 6| Step: 6
Training loss: 2.911829361223256
Validation loss: 2.4495690849120373

Epoch: 6| Step: 7
Training loss: 2.3144916515121485
Validation loss: 2.4431086349817495

Epoch: 6| Step: 8
Training loss: 2.629143396708853
Validation loss: 2.443708094557083

Epoch: 6| Step: 9
Training loss: 2.051757115287245
Validation loss: 2.4557336919802855

Epoch: 6| Step: 10
Training loss: 3.0780148559072997
Validation loss: 2.4508032532988047

Epoch: 6| Step: 11
Training loss: 2.15633978173025
Validation loss: 2.448623674167777

Epoch: 6| Step: 12
Training loss: 2.0841010650027285
Validation loss: 2.4546153649816436

Epoch: 6| Step: 13
Training loss: 2.568319643822918
Validation loss: 2.4524451283555373

Epoch: 139| Step: 0
Training loss: 2.601816067638717
Validation loss: 2.442359416798265

Epoch: 6| Step: 1
Training loss: 2.7314596274651706
Validation loss: 2.442732842708086

Epoch: 6| Step: 2
Training loss: 2.4742663596619274
Validation loss: 2.4416362033631813

Epoch: 6| Step: 3
Training loss: 2.134285219239502
Validation loss: 2.445226795778704

Epoch: 6| Step: 4
Training loss: 1.794501553241167
Validation loss: 2.440496526471697

Epoch: 6| Step: 5
Training loss: 2.91918952458876
Validation loss: 2.445674028575386

Epoch: 6| Step: 6
Training loss: 1.7371473407306568
Validation loss: 2.441116380903845

Epoch: 6| Step: 7
Training loss: 2.734262169826128
Validation loss: 2.4409158849990273

Epoch: 6| Step: 8
Training loss: 2.127509710735747
Validation loss: 2.4348552408081674

Epoch: 6| Step: 9
Training loss: 2.9432041706965
Validation loss: 2.436162858986352

Epoch: 6| Step: 10
Training loss: 2.931004098692169
Validation loss: 2.437890469828632

Epoch: 6| Step: 11
Training loss: 2.4831549569739377
Validation loss: 2.438805295850787

Epoch: 6| Step: 12
Training loss: 2.4025614818125174
Validation loss: 2.44481371910401

Epoch: 6| Step: 13
Training loss: 2.737442824232569
Validation loss: 2.4510156508228405

Epoch: 140| Step: 0
Training loss: 2.9600563046538815
Validation loss: 2.442210170374599

Epoch: 6| Step: 1
Training loss: 2.55676688865305
Validation loss: 2.454003243653284

Epoch: 6| Step: 2
Training loss: 1.9603868904514503
Validation loss: 2.462712401703585

Epoch: 6| Step: 3
Training loss: 2.326749869155101
Validation loss: 2.460517855594877

Epoch: 6| Step: 4
Training loss: 2.2762314450357697
Validation loss: 2.458082320981418

Epoch: 6| Step: 5
Training loss: 2.3662313916199627
Validation loss: 2.456728877720949

Epoch: 6| Step: 6
Training loss: 2.7725864017875432
Validation loss: 2.4561614259210645

Epoch: 6| Step: 7
Training loss: 2.418097127486103
Validation loss: 2.4488409908019784

Epoch: 6| Step: 8
Training loss: 2.0679321424171757
Validation loss: 2.4525036115940577

Epoch: 6| Step: 9
Training loss: 3.1201081707127147
Validation loss: 2.454244694227675

Epoch: 6| Step: 10
Training loss: 2.6851004600556045
Validation loss: 2.449321170756267

Epoch: 6| Step: 11
Training loss: 1.7558756690706705
Validation loss: 2.4498379465602067

Epoch: 6| Step: 12
Training loss: 2.813360464076738
Validation loss: 2.4438231770257723

Epoch: 6| Step: 13
Training loss: 2.7119879982100406
Validation loss: 2.4456662053244735

Epoch: 141| Step: 0
Training loss: 2.7527895563949083
Validation loss: 2.443751298882935

Epoch: 6| Step: 1
Training loss: 2.950959395529688
Validation loss: 2.4453469335957125

Epoch: 6| Step: 2
Training loss: 1.9731616892891082
Validation loss: 2.4486327618686183

Epoch: 6| Step: 3
Training loss: 2.8454051807607637
Validation loss: 2.4429278461483093

Epoch: 6| Step: 4
Training loss: 2.1253506988157373
Validation loss: 2.448044068829089

Epoch: 6| Step: 5
Training loss: 2.166307847559799
Validation loss: 2.4419905388065883

Epoch: 6| Step: 6
Training loss: 2.932080402973621
Validation loss: 2.448968204255022

Epoch: 6| Step: 7
Training loss: 2.323818345401184
Validation loss: 2.447506538826582

Epoch: 6| Step: 8
Training loss: 2.3993991576536455
Validation loss: 2.447589987742583

Epoch: 6| Step: 9
Training loss: 2.579741462498942
Validation loss: 2.4482097585544222

Epoch: 6| Step: 10
Training loss: 2.2548811207496904
Validation loss: 2.4487298196555307

Epoch: 6| Step: 11
Training loss: 2.4538730525577006
Validation loss: 2.4464819714695145

Epoch: 6| Step: 12
Training loss: 2.7569990390226606
Validation loss: 2.443109366893155

Epoch: 6| Step: 13
Training loss: 2.324100779897384
Validation loss: 2.440080515700412

Epoch: 142| Step: 0
Training loss: 2.1331794618706206
Validation loss: 2.4455835194250053

Epoch: 6| Step: 1
Training loss: 2.317115919431316
Validation loss: 2.438904895370296

Epoch: 6| Step: 2
Training loss: 3.0795306564021576
Validation loss: 2.445527901064398

Epoch: 6| Step: 3
Training loss: 2.105055165055017
Validation loss: 2.4457612118547694

Epoch: 6| Step: 4
Training loss: 2.8953274804194553
Validation loss: 2.44196216001673

Epoch: 6| Step: 5
Training loss: 1.9137475202209233
Validation loss: 2.4261252404560927

Epoch: 6| Step: 6
Training loss: 2.4035420228329025
Validation loss: 2.4316641238301475

Epoch: 6| Step: 7
Training loss: 2.0917505994677126
Validation loss: 2.432821511521633

Epoch: 6| Step: 8
Training loss: 2.6410102337512917
Validation loss: 2.4398493163816597

Epoch: 6| Step: 9
Training loss: 3.2358801836199285
Validation loss: 2.4375840767600008

Epoch: 6| Step: 10
Training loss: 2.353539329820974
Validation loss: 2.4364837908274466

Epoch: 6| Step: 11
Training loss: 2.526940527327444
Validation loss: 2.434855012330501

Epoch: 6| Step: 12
Training loss: 2.390178763435739
Validation loss: 2.4405410901964792

Epoch: 6| Step: 13
Training loss: 2.618272425547954
Validation loss: 2.4506737840021255

Epoch: 143| Step: 0
Training loss: 2.6168230856371313
Validation loss: 2.4481725410219375

Epoch: 6| Step: 1
Training loss: 2.64782275601862
Validation loss: 2.462637936493532

Epoch: 6| Step: 2
Training loss: 2.307086278128012
Validation loss: 2.4629545069897

Epoch: 6| Step: 3
Training loss: 1.7595908430648184
Validation loss: 2.4623410213937937

Epoch: 6| Step: 4
Training loss: 2.070142515869558
Validation loss: 2.4599825666424993

Epoch: 6| Step: 5
Training loss: 2.0917798922265205
Validation loss: 2.459992549259512

Epoch: 6| Step: 6
Training loss: 2.482820036236301
Validation loss: 2.467602137004479

Epoch: 6| Step: 7
Training loss: 2.4545854242519147
Validation loss: 2.458076372025293

Epoch: 6| Step: 8
Training loss: 2.5762309197057527
Validation loss: 2.461726616181324

Epoch: 6| Step: 9
Training loss: 3.2958560471811014
Validation loss: 2.461654308415486

Epoch: 6| Step: 10
Training loss: 2.913757144587008
Validation loss: 2.4524880815502192

Epoch: 6| Step: 11
Training loss: 2.863169669231911
Validation loss: 2.4531373592640406

Epoch: 6| Step: 12
Training loss: 1.9835526572166962
Validation loss: 2.4527492599898335

Epoch: 6| Step: 13
Training loss: 2.6979587998408032
Validation loss: 2.453727672434512

Epoch: 144| Step: 0
Training loss: 2.8857560675427614
Validation loss: 2.4559611874650042

Epoch: 6| Step: 1
Training loss: 2.260116932299844
Validation loss: 2.4483433669447097

Epoch: 6| Step: 2
Training loss: 2.318806271757074
Validation loss: 2.452170589280628

Epoch: 6| Step: 3
Training loss: 2.197105028853309
Validation loss: 2.4511523728525724

Epoch: 6| Step: 4
Training loss: 1.4901897378738393
Validation loss: 2.447374516505437

Epoch: 6| Step: 5
Training loss: 2.5654557092085306
Validation loss: 2.4530932754441435

Epoch: 6| Step: 6
Training loss: 2.6750682465591002
Validation loss: 2.456634926178992

Epoch: 6| Step: 7
Training loss: 2.5851584929349594
Validation loss: 2.4534589293153077

Epoch: 6| Step: 8
Training loss: 2.659487199041431
Validation loss: 2.4592922786516724

Epoch: 6| Step: 9
Training loss: 2.889736389492446
Validation loss: 2.4635550731807614

Epoch: 6| Step: 10
Training loss: 2.7744293588433484
Validation loss: 2.4576888829157615

Epoch: 6| Step: 11
Training loss: 2.2656609894097364
Validation loss: 2.459103517521927

Epoch: 6| Step: 12
Training loss: 2.414117806304167
Validation loss: 2.470274265547567

Epoch: 6| Step: 13
Training loss: 2.880911513034557
Validation loss: 2.458981013781791

Epoch: 145| Step: 0
Training loss: 3.036235367106406
Validation loss: 2.45340986278456

Epoch: 6| Step: 1
Training loss: 2.207671108159401
Validation loss: 2.4533040250663674

Epoch: 6| Step: 2
Training loss: 2.696168625354812
Validation loss: 2.445181521156878

Epoch: 6| Step: 3
Training loss: 2.7110060097780107
Validation loss: 2.44682294612388

Epoch: 6| Step: 4
Training loss: 2.7792496935230115
Validation loss: 2.446438149422521

Epoch: 6| Step: 5
Training loss: 2.9848357638827494
Validation loss: 2.448268919145671

Epoch: 6| Step: 6
Training loss: 2.256435515578035
Validation loss: 2.4494852654161288

Epoch: 6| Step: 7
Training loss: 1.9908238549670176
Validation loss: 2.446329216237322

Epoch: 6| Step: 8
Training loss: 1.3344194141295256
Validation loss: 2.4474388359617745

Epoch: 6| Step: 9
Training loss: 2.742117247809149
Validation loss: 2.4494859061992336

Epoch: 6| Step: 10
Training loss: 2.379296983221913
Validation loss: 2.449791954250942

Epoch: 6| Step: 11
Training loss: 2.230151686705488
Validation loss: 2.4423886695251644

Epoch: 6| Step: 12
Training loss: 2.459147259299435
Validation loss: 2.447516685977072

Epoch: 6| Step: 13
Training loss: 2.5324679611604566
Validation loss: 2.4473131666870596

Epoch: 146| Step: 0
Training loss: 2.2370242971738685
Validation loss: 2.4480681649801963

Epoch: 6| Step: 1
Training loss: 2.253742602141008
Validation loss: 2.4635927115724257

Epoch: 6| Step: 2
Training loss: 1.8912998602850586
Validation loss: 2.4549735488813296

Epoch: 6| Step: 3
Training loss: 2.5843629220959365
Validation loss: 2.457457036017614

Epoch: 6| Step: 4
Training loss: 2.788341012166226
Validation loss: 2.4520377161087445

Epoch: 6| Step: 5
Training loss: 2.5252471198592468
Validation loss: 2.4429685268355237

Epoch: 6| Step: 6
Training loss: 2.251633580903831
Validation loss: 2.4533231456776576

Epoch: 6| Step: 7
Training loss: 2.8835117556836862
Validation loss: 2.4568898009161138

Epoch: 6| Step: 8
Training loss: 2.4541851109932593
Validation loss: 2.464127845196044

Epoch: 6| Step: 9
Training loss: 2.900674373220477
Validation loss: 2.466875402751587

Epoch: 6| Step: 10
Training loss: 2.349115156421124
Validation loss: 2.470508214929569

Epoch: 6| Step: 11
Training loss: 2.6801405098363444
Validation loss: 2.4770842442833008

Epoch: 6| Step: 12
Training loss: 2.500496814953828
Validation loss: 2.4778819615604446

Epoch: 6| Step: 13
Training loss: 2.9336191067063258
Validation loss: 2.475455324437985

Epoch: 147| Step: 0
Training loss: 2.2395767803244127
Validation loss: 2.4792415196207465

Epoch: 6| Step: 1
Training loss: 2.2949638460257775
Validation loss: 2.4758644283434457

Epoch: 6| Step: 2
Training loss: 3.2414820627507357
Validation loss: 2.4743083398416506

Epoch: 6| Step: 3
Training loss: 2.624968755626927
Validation loss: 2.4740143190708106

Epoch: 6| Step: 4
Training loss: 2.050599531569558
Validation loss: 2.478466068510886

Epoch: 6| Step: 5
Training loss: 2.415350511754973
Validation loss: 2.478280290995039

Epoch: 6| Step: 6
Training loss: 2.4649640762775564
Validation loss: 2.4764304782724333

Epoch: 6| Step: 7
Training loss: 1.9552634167588276
Validation loss: 2.475215493399402

Epoch: 6| Step: 8
Training loss: 2.9842182537677444
Validation loss: 2.469046144388251

Epoch: 6| Step: 9
Training loss: 3.3903565190632947
Validation loss: 2.471922674736099

Epoch: 6| Step: 10
Training loss: 2.28174805103368
Validation loss: 2.4589336007238916

Epoch: 6| Step: 11
Training loss: 2.4627796846915864
Validation loss: 2.4590377902813696

Epoch: 6| Step: 12
Training loss: 2.6785120040114707
Validation loss: 2.459916660969928

Epoch: 6| Step: 13
Training loss: 2.111384585999225
Validation loss: 2.4559825282433216

Epoch: 148| Step: 0
Training loss: 1.8490381214674543
Validation loss: 2.45478115344252

Epoch: 6| Step: 1
Training loss: 2.3447165975553554
Validation loss: 2.457755058508166

Epoch: 6| Step: 2
Training loss: 3.38799130864025
Validation loss: 2.451431467360705

Epoch: 6| Step: 3
Training loss: 2.822950994041218
Validation loss: 2.4662219354367125

Epoch: 6| Step: 4
Training loss: 2.6421352785116916
Validation loss: 2.4558320062705152

Epoch: 6| Step: 5
Training loss: 2.4941057338678823
Validation loss: 2.4686301318978123

Epoch: 6| Step: 6
Training loss: 2.4166956494226732
Validation loss: 2.462175120628285

Epoch: 6| Step: 7
Training loss: 2.5330610036872145
Validation loss: 2.460204274579098

Epoch: 6| Step: 8
Training loss: 2.3365276701105295
Validation loss: 2.456317371353645

Epoch: 6| Step: 9
Training loss: 2.1199975316015305
Validation loss: 2.459198320013369

Epoch: 6| Step: 10
Training loss: 2.5066339213011304
Validation loss: 2.4484143231497337

Epoch: 6| Step: 11
Training loss: 2.550467549263984
Validation loss: 2.453665023941356

Epoch: 6| Step: 12
Training loss: 2.4056776282524264
Validation loss: 2.4545444989978544

Epoch: 6| Step: 13
Training loss: 2.378729451943199
Validation loss: 2.453654173451739

Epoch: 149| Step: 0
Training loss: 2.9174830429512704
Validation loss: 2.4497680048190897

Epoch: 6| Step: 1
Training loss: 2.569584612989615
Validation loss: 2.4535339241416367

Epoch: 6| Step: 2
Training loss: 2.5147376539088646
Validation loss: 2.452680430047143

Epoch: 6| Step: 3
Training loss: 2.332369423632521
Validation loss: 2.4505316274299136

Epoch: 6| Step: 4
Training loss: 2.02864071441775
Validation loss: 2.4509314511592644

Epoch: 6| Step: 5
Training loss: 2.2997304592585843
Validation loss: 2.45179741769025

Epoch: 6| Step: 6
Training loss: 2.752692378473369
Validation loss: 2.446765991744894

Epoch: 6| Step: 7
Training loss: 2.167913102819048
Validation loss: 2.451218352060823

Epoch: 6| Step: 8
Training loss: 2.165782258900638
Validation loss: 2.4552683689533543

Epoch: 6| Step: 9
Training loss: 2.217154453023242
Validation loss: 2.461879021308083

Epoch: 6| Step: 10
Training loss: 2.4555049940900093
Validation loss: 2.469512620465637

Epoch: 6| Step: 11
Training loss: 3.1519629946923025
Validation loss: 2.474034251336528

Epoch: 6| Step: 12
Training loss: 2.676341467358443
Validation loss: 2.4703320210711204

Epoch: 6| Step: 13
Training loss: 2.5870943276660205
Validation loss: 2.472677117250124

Epoch: 150| Step: 0
Training loss: 2.3431939037547154
Validation loss: 2.470490111967844

Epoch: 6| Step: 1
Training loss: 2.3794792499956094
Validation loss: 2.461707326785256

Epoch: 6| Step: 2
Training loss: 2.6547973250853394
Validation loss: 2.460736059593041

Epoch: 6| Step: 3
Training loss: 2.4879688683674925
Validation loss: 2.4514941891419753

Epoch: 6| Step: 4
Training loss: 2.744116732130192
Validation loss: 2.4598571989692575

Epoch: 6| Step: 5
Training loss: 2.424231779190736
Validation loss: 2.4435844693785267

Epoch: 6| Step: 6
Training loss: 2.2591230027685927
Validation loss: 2.451170302513398

Epoch: 6| Step: 7
Training loss: 2.6644993756637656
Validation loss: 2.455013835735918

Epoch: 6| Step: 8
Training loss: 2.607921629599949
Validation loss: 2.4599086487873953

Epoch: 6| Step: 9
Training loss: 2.44713302947231
Validation loss: 2.4613071063178027

Epoch: 6| Step: 10
Training loss: 2.453749656113665
Validation loss: 2.4693953881709

Epoch: 6| Step: 11
Training loss: 2.4753941809670983
Validation loss: 2.4555733483975493

Epoch: 6| Step: 12
Training loss: 3.024345163133911
Validation loss: 2.457204807541868

Epoch: 6| Step: 13
Training loss: 2.0201628709983033
Validation loss: 2.4475611218830045

Epoch: 151| Step: 0
Training loss: 2.7780821686437003
Validation loss: 2.4459289326307965

Epoch: 6| Step: 1
Training loss: 2.3878468845679
Validation loss: 2.446825885563979

Epoch: 6| Step: 2
Training loss: 2.8353381824118578
Validation loss: 2.446196480608879

Epoch: 6| Step: 3
Training loss: 3.026015963858319
Validation loss: 2.4548568929383907

Epoch: 6| Step: 4
Training loss: 2.8538859059892876
Validation loss: 2.446717513705489

Epoch: 6| Step: 5
Training loss: 1.62324517205838
Validation loss: 2.45806203304198

Epoch: 6| Step: 6
Training loss: 2.0414329576697834
Validation loss: 2.4537780929048094

Epoch: 6| Step: 7
Training loss: 2.128282592136718
Validation loss: 2.4696741587533406

Epoch: 6| Step: 8
Training loss: 2.904124805763549
Validation loss: 2.468132038275468

Epoch: 6| Step: 9
Training loss: 2.701401618681276
Validation loss: 2.457205971882041

Epoch: 6| Step: 10
Training loss: 2.5709749892749434
Validation loss: 2.453472744537086

Epoch: 6| Step: 11
Training loss: 2.2283308535980297
Validation loss: 2.4471844545274877

Epoch: 6| Step: 12
Training loss: 2.649212389088731
Validation loss: 2.4509458967100133

Epoch: 6| Step: 13
Training loss: 2.2514458355404234
Validation loss: 2.44818171155238

Epoch: 152| Step: 0
Training loss: 2.368045059832162
Validation loss: 2.4599694825685665

Epoch: 6| Step: 1
Training loss: 2.886823804541385
Validation loss: 2.467127335120622

Epoch: 6| Step: 2
Training loss: 2.2450901077980294
Validation loss: 2.4626188801375286

Epoch: 6| Step: 3
Training loss: 1.7831204949879287
Validation loss: 2.4685172281099987

Epoch: 6| Step: 4
Training loss: 3.318656526387857
Validation loss: 2.461743338916184

Epoch: 6| Step: 5
Training loss: 2.580624565111541
Validation loss: 2.462990299217624

Epoch: 6| Step: 6
Training loss: 2.9023092480915293
Validation loss: 2.4608952190662494

Epoch: 6| Step: 7
Training loss: 2.796953082992619
Validation loss: 2.4563502918116487

Epoch: 6| Step: 8
Training loss: 2.1802251556034244
Validation loss: 2.453581036661053

Epoch: 6| Step: 9
Training loss: 2.4580340984577305
Validation loss: 2.454116232266889

Epoch: 6| Step: 10
Training loss: 2.6476848061587073
Validation loss: 2.4563803323556463

Epoch: 6| Step: 11
Training loss: 2.1050284355218265
Validation loss: 2.4572794131406988

Epoch: 6| Step: 12
Training loss: 2.7366084976921914
Validation loss: 2.4545905398606944

Epoch: 6| Step: 13
Training loss: 1.8058073194337911
Validation loss: 2.454023516570529

Epoch: 153| Step: 0
Training loss: 2.327648856609715
Validation loss: 2.4549060843192674

Epoch: 6| Step: 1
Training loss: 2.998474050898412
Validation loss: 2.456667203471808

Epoch: 6| Step: 2
Training loss: 2.5903756126311412
Validation loss: 2.4449797902640427

Epoch: 6| Step: 3
Training loss: 2.2332618981888577
Validation loss: 2.4526379743670677

Epoch: 6| Step: 4
Training loss: 2.755816464052881
Validation loss: 2.449735377092394

Epoch: 6| Step: 5
Training loss: 1.825387780260563
Validation loss: 2.4555566969198086

Epoch: 6| Step: 6
Training loss: 2.487365458314836
Validation loss: 2.456085572955448

Epoch: 6| Step: 7
Training loss: 2.4525562769103493
Validation loss: 2.4506790455990495

Epoch: 6| Step: 8
Training loss: 2.144583501683
Validation loss: 2.453241187581774

Epoch: 6| Step: 9
Training loss: 1.8201378996450694
Validation loss: 2.4558720444302455

Epoch: 6| Step: 10
Training loss: 2.8939509871945273
Validation loss: 2.4493905655636508

Epoch: 6| Step: 11
Training loss: 2.5439440004195273
Validation loss: 2.4552593786419594

Epoch: 6| Step: 12
Training loss: 3.1847375605327
Validation loss: 2.451080993345494

Epoch: 6| Step: 13
Training loss: 2.168794821680037
Validation loss: 2.446317009375981

Epoch: 154| Step: 0
Training loss: 2.08071943972291
Validation loss: 2.4524821514292867

Epoch: 6| Step: 1
Training loss: 2.7120070752301944
Validation loss: 2.4442737229532887

Epoch: 6| Step: 2
Training loss: 2.1125947468293713
Validation loss: 2.445087556577939

Epoch: 6| Step: 3
Training loss: 2.281150084097221
Validation loss: 2.4472005946598534

Epoch: 6| Step: 4
Training loss: 2.7946566516530544
Validation loss: 2.44514550887058

Epoch: 6| Step: 5
Training loss: 2.242606200358247
Validation loss: 2.435291610348184

Epoch: 6| Step: 6
Training loss: 2.713120606618126
Validation loss: 2.4449737444184945

Epoch: 6| Step: 7
Training loss: 2.272606242165037
Validation loss: 2.440163778895269

Epoch: 6| Step: 8
Training loss: 2.672193541695621
Validation loss: 2.436827216262433

Epoch: 6| Step: 9
Training loss: 2.319437497776413
Validation loss: 2.4380437456399116

Epoch: 6| Step: 10
Training loss: 2.3488157331963575
Validation loss: 2.4476678167159736

Epoch: 6| Step: 11
Training loss: 3.2039738716555517
Validation loss: 2.4437594941223906

Epoch: 6| Step: 12
Training loss: 1.8917170751748091
Validation loss: 2.4426214749009345

Epoch: 6| Step: 13
Training loss: 2.803644863135345
Validation loss: 2.441046050902512

Epoch: 155| Step: 0
Training loss: 2.3253102536492456
Validation loss: 2.445681201897687

Epoch: 6| Step: 1
Training loss: 3.0945498270672824
Validation loss: 2.4550163769094815

Epoch: 6| Step: 2
Training loss: 2.6666129424723297
Validation loss: 2.447073427341892

Epoch: 6| Step: 3
Training loss: 2.1601842840489898
Validation loss: 2.4395351146707376

Epoch: 6| Step: 4
Training loss: 2.259240672232505
Validation loss: 2.447975033544455

Epoch: 6| Step: 5
Training loss: 2.3243432788987133
Validation loss: 2.4565059179106243

Epoch: 6| Step: 6
Training loss: 2.2182223270117047
Validation loss: 2.441900910174215

Epoch: 6| Step: 7
Training loss: 2.654405559366577
Validation loss: 2.445799855182371

Epoch: 6| Step: 8
Training loss: 2.0368797341052063
Validation loss: 2.4536174838661147

Epoch: 6| Step: 9
Training loss: 2.8432150536726315
Validation loss: 2.4518432670365926

Epoch: 6| Step: 10
Training loss: 2.6695013377830583
Validation loss: 2.4504673648288624

Epoch: 6| Step: 11
Training loss: 2.4861269357794478
Validation loss: 2.451763042273285

Epoch: 6| Step: 12
Training loss: 2.506436930318184
Validation loss: 2.4482571358332788

Epoch: 6| Step: 13
Training loss: 2.4187970691605747
Validation loss: 2.4495742758838523

Epoch: 156| Step: 0
Training loss: 2.3642106175586908
Validation loss: 2.4484045367688667

Epoch: 6| Step: 1
Training loss: 2.237014172198337
Validation loss: 2.445198990824927

Epoch: 6| Step: 2
Training loss: 2.763642025843665
Validation loss: 2.447677362527309

Epoch: 6| Step: 3
Training loss: 2.5518587182259216
Validation loss: 2.4509461885384436

Epoch: 6| Step: 4
Training loss: 3.010088804842327
Validation loss: 2.4433947061799266

Epoch: 6| Step: 5
Training loss: 2.5831886271484232
Validation loss: 2.4439793731934505

Epoch: 6| Step: 6
Training loss: 2.616956558286783
Validation loss: 2.4426411590341006

Epoch: 6| Step: 7
Training loss: 2.49253646655558
Validation loss: 2.451077832042853

Epoch: 6| Step: 8
Training loss: 2.0364810197612098
Validation loss: 2.445443991801273

Epoch: 6| Step: 9
Training loss: 2.1451168407282566
Validation loss: 2.4518672772306247

Epoch: 6| Step: 10
Training loss: 2.6153744011243667
Validation loss: 2.457339042626239

Epoch: 6| Step: 11
Training loss: 2.254845487963879
Validation loss: 2.4592568931026686

Epoch: 6| Step: 12
Training loss: 1.9855653691786055
Validation loss: 2.4536242614804062

Epoch: 6| Step: 13
Training loss: 2.9337562891889073
Validation loss: 2.4546276681764465

Epoch: 157| Step: 0
Training loss: 2.5494130599764366
Validation loss: 2.4447959541204103

Epoch: 6| Step: 1
Training loss: 2.2356910297815644
Validation loss: 2.4504544407562707

Epoch: 6| Step: 2
Training loss: 2.8378976820498973
Validation loss: 2.454160969656877

Epoch: 6| Step: 3
Training loss: 2.6491501111087956
Validation loss: 2.442841391338682

Epoch: 6| Step: 4
Training loss: 2.358134265581173
Validation loss: 2.472923822775569

Epoch: 6| Step: 5
Training loss: 2.746250283784292
Validation loss: 2.4630982454917176

Epoch: 6| Step: 6
Training loss: 1.9990034600896311
Validation loss: 2.4599917335293826

Epoch: 6| Step: 7
Training loss: 2.590630367259688
Validation loss: 2.4572062467956126

Epoch: 6| Step: 8
Training loss: 2.2242149425349393
Validation loss: 2.463622679934186

Epoch: 6| Step: 9
Training loss: 2.1919102488681004
Validation loss: 2.456293736295734

Epoch: 6| Step: 10
Training loss: 2.1212513339971912
Validation loss: 2.4508888760105143

Epoch: 6| Step: 11
Training loss: 2.402154186182039
Validation loss: 2.4512320988565737

Epoch: 6| Step: 12
Training loss: 2.9036886762300806
Validation loss: 2.453248687023326

Epoch: 6| Step: 13
Training loss: 2.74981394051643
Validation loss: 2.4553383482176567

Epoch: 158| Step: 0
Training loss: 2.1688775984195763
Validation loss: 2.4571109631439167

Epoch: 6| Step: 1
Training loss: 2.6216714736820035
Validation loss: 2.453000480585457

Epoch: 6| Step: 2
Training loss: 3.1672711715598867
Validation loss: 2.4598958066258754

Epoch: 6| Step: 3
Training loss: 2.067868960761149
Validation loss: 2.4585236190169253

Epoch: 6| Step: 4
Training loss: 2.5447061114946403
Validation loss: 2.454501678925219

Epoch: 6| Step: 5
Training loss: 2.511924153853359
Validation loss: 2.455772477729121

Epoch: 6| Step: 6
Training loss: 2.6022543230727244
Validation loss: 2.449768475213165

Epoch: 6| Step: 7
Training loss: 2.0041421673308957
Validation loss: 2.4590195382381266

Epoch: 6| Step: 8
Training loss: 2.5270731809139075
Validation loss: 2.442473684290839

Epoch: 6| Step: 9
Training loss: 1.7724310754199324
Validation loss: 2.453986792025455

Epoch: 6| Step: 10
Training loss: 2.290047183154578
Validation loss: 2.449838644021132

Epoch: 6| Step: 11
Training loss: 2.276932484573629
Validation loss: 2.4443214528854447

Epoch: 6| Step: 12
Training loss: 2.64295414337894
Validation loss: 2.460367465731833

Epoch: 6| Step: 13
Training loss: 3.16726033183942
Validation loss: 2.454899925333952

Epoch: 159| Step: 0
Training loss: 2.498568888174316
Validation loss: 2.4550287266518307

Epoch: 6| Step: 1
Training loss: 2.42347890595924
Validation loss: 2.458480868249776

Epoch: 6| Step: 2
Training loss: 2.340706031119904
Validation loss: 2.450406862717244

Epoch: 6| Step: 3
Training loss: 2.6822220185258785
Validation loss: 2.4546861317916284

Epoch: 6| Step: 4
Training loss: 2.2856579352142483
Validation loss: 2.44796843507826

Epoch: 6| Step: 5
Training loss: 2.3395352932444045
Validation loss: 2.4631021657351697

Epoch: 6| Step: 6
Training loss: 2.4561082716570235
Validation loss: 2.4646457405175335

Epoch: 6| Step: 7
Training loss: 2.151238297780297
Validation loss: 2.458068176021397

Epoch: 6| Step: 8
Training loss: 2.5049159354535164
Validation loss: 2.4627181781089793

Epoch: 6| Step: 9
Training loss: 2.2965874524382426
Validation loss: 2.4567625285958425

Epoch: 6| Step: 10
Training loss: 3.079981829602037
Validation loss: 2.4515005349828995

Epoch: 6| Step: 11
Training loss: 2.517726991453047
Validation loss: 2.4516769152318387

Epoch: 6| Step: 12
Training loss: 2.9175386124567027
Validation loss: 2.454316062676169

Epoch: 6| Step: 13
Training loss: 2.1228088975480186
Validation loss: 2.4541227251489626

Epoch: 160| Step: 0
Training loss: 2.4290109164611833
Validation loss: 2.458778782805202

Epoch: 6| Step: 1
Training loss: 2.6769546497651793
Validation loss: 2.4680334250362472

Epoch: 6| Step: 2
Training loss: 2.152720340523114
Validation loss: 2.4736018409200695

Epoch: 6| Step: 3
Training loss: 2.58298104458011
Validation loss: 2.4730580482035687

Epoch: 6| Step: 4
Training loss: 2.7944199853192804
Validation loss: 2.4767531713658775

Epoch: 6| Step: 5
Training loss: 2.3366581752403324
Validation loss: 2.470822377901626

Epoch: 6| Step: 6
Training loss: 2.7897727767133507
Validation loss: 2.4727720340982113

Epoch: 6| Step: 7
Training loss: 2.623574369312499
Validation loss: 2.4737412902925433

Epoch: 6| Step: 8
Training loss: 3.0205127063591943
Validation loss: 2.4745521368177896

Epoch: 6| Step: 9
Training loss: 2.769150550405844
Validation loss: 2.46963596140101

Epoch: 6| Step: 10
Training loss: 2.2119886507843414
Validation loss: 2.4623793641827976

Epoch: 6| Step: 11
Training loss: 2.3164552422886064
Validation loss: 2.465723750172

Epoch: 6| Step: 12
Training loss: 1.585451399246845
Validation loss: 2.4584999243546375

Epoch: 6| Step: 13
Training loss: 2.7649334403885844
Validation loss: 2.4649768920341484

Epoch: 161| Step: 0
Training loss: 2.3328382670773764
Validation loss: 2.4528669800695857

Epoch: 6| Step: 1
Training loss: 2.2074901002551766
Validation loss: 2.4529402029486036

Epoch: 6| Step: 2
Training loss: 2.2740673752586082
Validation loss: 2.4597373982995303

Epoch: 6| Step: 3
Training loss: 2.7345059608705595
Validation loss: 2.459128402115809

Epoch: 6| Step: 4
Training loss: 3.307898438228828
Validation loss: 2.4480720524811774

Epoch: 6| Step: 5
Training loss: 3.0651907485923853
Validation loss: 2.4550787886014502

Epoch: 6| Step: 6
Training loss: 2.363150096438205
Validation loss: 2.4457017875098663

Epoch: 6| Step: 7
Training loss: 2.505053467170425
Validation loss: 2.4533222224495326

Epoch: 6| Step: 8
Training loss: 2.239182641904986
Validation loss: 2.4526065918483857

Epoch: 6| Step: 9
Training loss: 1.916270947724453
Validation loss: 2.4600677891051697

Epoch: 6| Step: 10
Training loss: 2.08774479784093
Validation loss: 2.464859049044776

Epoch: 6| Step: 11
Training loss: 2.585474624004666
Validation loss: 2.4534376070764914

Epoch: 6| Step: 12
Training loss: 2.4463262924437457
Validation loss: 2.4514094709973784

Epoch: 6| Step: 13
Training loss: 2.1893941035895113
Validation loss: 2.459294193334667

Epoch: 162| Step: 0
Training loss: 2.9910060851029785
Validation loss: 2.456653220201578

Epoch: 6| Step: 1
Training loss: 1.8156807711992855
Validation loss: 2.4623869164799466

Epoch: 6| Step: 2
Training loss: 1.9809978914360367
Validation loss: 2.454145247706503

Epoch: 6| Step: 3
Training loss: 2.3669378067116726
Validation loss: 2.4537854854448904

Epoch: 6| Step: 4
Training loss: 2.3897176778510856
Validation loss: 2.4630318746617084

Epoch: 6| Step: 5
Training loss: 2.5537277425355285
Validation loss: 2.4558120233521405

Epoch: 6| Step: 6
Training loss: 2.3934787845599703
Validation loss: 2.463560404044276

Epoch: 6| Step: 7
Training loss: 2.6195773472471564
Validation loss: 2.4661299407242803

Epoch: 6| Step: 8
Training loss: 2.8195631558670744
Validation loss: 2.460643480286574

Epoch: 6| Step: 9
Training loss: 2.2205364933085954
Validation loss: 2.4653756947540835

Epoch: 6| Step: 10
Training loss: 2.863600979761158
Validation loss: 2.4609972749746922

Epoch: 6| Step: 11
Training loss: 2.660736782457991
Validation loss: 2.4626040673897642

Epoch: 6| Step: 12
Training loss: 2.5982940579183054
Validation loss: 2.46437364096253

Epoch: 6| Step: 13
Training loss: 2.5462027756698995
Validation loss: 2.4698692070415733

Epoch: 163| Step: 0
Training loss: 3.0165527181724623
Validation loss: 2.4590928041419526

Epoch: 6| Step: 1
Training loss: 2.078563557864135
Validation loss: 2.453730797934608

Epoch: 6| Step: 2
Training loss: 3.465792383085197
Validation loss: 2.452466726566701

Epoch: 6| Step: 3
Training loss: 2.7976574362736595
Validation loss: 2.4522841079392768

Epoch: 6| Step: 4
Training loss: 2.3592011848744248
Validation loss: 2.4528074281694905

Epoch: 6| Step: 5
Training loss: 2.1728590238635936
Validation loss: 2.452888396367885

Epoch: 6| Step: 6
Training loss: 1.649457209346298
Validation loss: 2.462557208176094

Epoch: 6| Step: 7
Training loss: 2.889142620322923
Validation loss: 2.4591290484655413

Epoch: 6| Step: 8
Training loss: 2.0869510774092217
Validation loss: 2.4526198853184606

Epoch: 6| Step: 9
Training loss: 2.4978015770274236
Validation loss: 2.4587906126602834

Epoch: 6| Step: 10
Training loss: 2.315987097142568
Validation loss: 2.462618775254551

Epoch: 6| Step: 11
Training loss: 2.0845721058680096
Validation loss: 2.4618590471212936

Epoch: 6| Step: 12
Training loss: 2.2203775803050014
Validation loss: 2.455274850696593

Epoch: 6| Step: 13
Training loss: 2.3932176879563256
Validation loss: 2.461641015306773

Epoch: 164| Step: 0
Training loss: 2.5158574725476943
Validation loss: 2.4654250953130097

Epoch: 6| Step: 1
Training loss: 2.5383212371992148
Validation loss: 2.459555400289326

Epoch: 6| Step: 2
Training loss: 2.777747016312555
Validation loss: 2.463188554701605

Epoch: 6| Step: 3
Training loss: 2.6902600686663263
Validation loss: 2.4596239085994323

Epoch: 6| Step: 4
Training loss: 2.4391937240109476
Validation loss: 2.4635955019681104

Epoch: 6| Step: 5
Training loss: 1.9071123017648879
Validation loss: 2.4594497139361593

Epoch: 6| Step: 6
Training loss: 2.5210266879831793
Validation loss: 2.458624456161565

Epoch: 6| Step: 7
Training loss: 2.3305383245381557
Validation loss: 2.461324848995623

Epoch: 6| Step: 8
Training loss: 1.8760005824285388
Validation loss: 2.467267794648329

Epoch: 6| Step: 9
Training loss: 2.631806586107202
Validation loss: 2.463262632238943

Epoch: 6| Step: 10
Training loss: 2.401904852247584
Validation loss: 2.4595640921697703

Epoch: 6| Step: 11
Training loss: 2.6739537590610882
Validation loss: 2.461414319222139

Epoch: 6| Step: 12
Training loss: 2.301521013951672
Validation loss: 2.4664311524242564

Epoch: 6| Step: 13
Training loss: 2.5711534046356856
Validation loss: 2.4646796138097646

Epoch: 165| Step: 0
Training loss: 2.274520563602468
Validation loss: 2.4530764532448797

Epoch: 6| Step: 1
Training loss: 2.15284748032915
Validation loss: 2.456748594391377

Epoch: 6| Step: 2
Training loss: 2.126346834501771
Validation loss: 2.4622645922351825

Epoch: 6| Step: 3
Training loss: 2.744394311005134
Validation loss: 2.4559679586114918

Epoch: 6| Step: 4
Training loss: 2.4557908267184985
Validation loss: 2.4698119957606237

Epoch: 6| Step: 5
Training loss: 1.972732633112771
Validation loss: 2.4580485507649112

Epoch: 6| Step: 6
Training loss: 2.6797952435689623
Validation loss: 2.4714362261821874

Epoch: 6| Step: 7
Training loss: 2.013554063638124
Validation loss: 2.4596018077896016

Epoch: 6| Step: 8
Training loss: 2.8951001965934493
Validation loss: 2.4633466927041803

Epoch: 6| Step: 9
Training loss: 2.620363409449729
Validation loss: 2.46851849979533

Epoch: 6| Step: 10
Training loss: 3.0548080069340715
Validation loss: 2.458296530388821

Epoch: 6| Step: 11
Training loss: 2.0227952328137526
Validation loss: 2.46741074237986

Epoch: 6| Step: 12
Training loss: 2.702017496601552
Validation loss: 2.4530334131593587

Epoch: 6| Step: 13
Training loss: 2.3625378156592376
Validation loss: 2.452488194967693

Epoch: 166| Step: 0
Training loss: 2.5250997353675886
Validation loss: 2.4596713406611923

Epoch: 6| Step: 1
Training loss: 2.777833189941422
Validation loss: 2.4585261080746066

Epoch: 6| Step: 2
Training loss: 2.3010898247153873
Validation loss: 2.461537694653902

Epoch: 6| Step: 3
Training loss: 2.7677691924716936
Validation loss: 2.4647749111842123

Epoch: 6| Step: 4
Training loss: 2.2682053177488926
Validation loss: 2.4556220885172397

Epoch: 6| Step: 5
Training loss: 2.496789301044895
Validation loss: 2.4610325870611764

Epoch: 6| Step: 6
Training loss: 2.2991447392748046
Validation loss: 2.4643192367958915

Epoch: 6| Step: 7
Training loss: 2.8842579595722637
Validation loss: 2.460171890249453

Epoch: 6| Step: 8
Training loss: 2.2821018248565665
Validation loss: 2.4640011080082966

Epoch: 6| Step: 9
Training loss: 2.5254143214460076
Validation loss: 2.4640562206987364

Epoch: 6| Step: 10
Training loss: 2.102360797133947
Validation loss: 2.460691554782954

Epoch: 6| Step: 11
Training loss: 2.676431618612074
Validation loss: 2.4588143045213178

Epoch: 6| Step: 12
Training loss: 1.9684013179028135
Validation loss: 2.451279352878988

Epoch: 6| Step: 13
Training loss: 2.5136026344751725
Validation loss: 2.454725015031042

Epoch: 167| Step: 0
Training loss: 2.4452816897270258
Validation loss: 2.4700159939288002

Epoch: 6| Step: 1
Training loss: 2.540623956471284
Validation loss: 2.4439455219176134

Epoch: 6| Step: 2
Training loss: 2.118630681011774
Validation loss: 2.4652304207517193

Epoch: 6| Step: 3
Training loss: 2.8110058524370425
Validation loss: 2.465481989346891

Epoch: 6| Step: 4
Training loss: 2.6425974324290054
Validation loss: 2.454247851451099

Epoch: 6| Step: 5
Training loss: 2.35049931517532
Validation loss: 2.452307068679151

Epoch: 6| Step: 6
Training loss: 1.545114305088719
Validation loss: 2.4521032825739897

Epoch: 6| Step: 7
Training loss: 2.387572689847201
Validation loss: 2.455955459885659

Epoch: 6| Step: 8
Training loss: 3.0018581357979017
Validation loss: 2.4592312423007754

Epoch: 6| Step: 9
Training loss: 2.6631836993881985
Validation loss: 2.457966604734828

Epoch: 6| Step: 10
Training loss: 2.0622391969340255
Validation loss: 2.46490131840933

Epoch: 6| Step: 11
Training loss: 2.518680399271475
Validation loss: 2.4657282625145434

Epoch: 6| Step: 12
Training loss: 2.2042948545547736
Validation loss: 2.462010257772918

Epoch: 6| Step: 13
Training loss: 2.7563294483593697
Validation loss: 2.467871481474123

Epoch: 168| Step: 0
Training loss: 3.0853487249840565
Validation loss: 2.459993340759775

Epoch: 6| Step: 1
Training loss: 2.3032634926386986
Validation loss: 2.469557666245069

Epoch: 6| Step: 2
Training loss: 2.2757015948984693
Validation loss: 2.4720113434546733

Epoch: 6| Step: 3
Training loss: 2.655285738782879
Validation loss: 2.4657267637731146

Epoch: 6| Step: 4
Training loss: 2.3686182715191397
Validation loss: 2.4809523624145244

Epoch: 6| Step: 5
Training loss: 1.9212016344901
Validation loss: 2.4778253041353246

Epoch: 6| Step: 6
Training loss: 2.5541430718564793
Validation loss: 2.486639690031255

Epoch: 6| Step: 7
Training loss: 2.1679094736054574
Validation loss: 2.4637948054667262

Epoch: 6| Step: 8
Training loss: 2.8594136886897648
Validation loss: 2.456130112690011

Epoch: 6| Step: 9
Training loss: 2.942852905683073
Validation loss: 2.48061186610383

Epoch: 6| Step: 10
Training loss: 2.05984603750916
Validation loss: 2.472342906701755

Epoch: 6| Step: 11
Training loss: 2.0528598097379906
Validation loss: 2.458383160964393

Epoch: 6| Step: 12
Training loss: 2.158458739458285
Validation loss: 2.459435520291884

Epoch: 6| Step: 13
Training loss: 2.821872269300658
Validation loss: 2.462299563388269

Epoch: 169| Step: 0
Training loss: 2.749268000888682
Validation loss: 2.4601771719123584

Epoch: 6| Step: 1
Training loss: 2.1095998008467545
Validation loss: 2.4658592941174104

Epoch: 6| Step: 2
Training loss: 2.5285717016655602
Validation loss: 2.4551172609935095

Epoch: 6| Step: 3
Training loss: 2.9338947654735414
Validation loss: 2.4518295884949026

Epoch: 6| Step: 4
Training loss: 2.3123684407520644
Validation loss: 2.4563662261254886

Epoch: 6| Step: 5
Training loss: 2.034599594164768
Validation loss: 2.45914908522299

Epoch: 6| Step: 6
Training loss: 2.3403635609868854
Validation loss: 2.461651346326439

Epoch: 6| Step: 7
Training loss: 1.9360527047399836
Validation loss: 2.463719018166863

Epoch: 6| Step: 8
Training loss: 2.19195299586834
Validation loss: 2.4526908028601286

Epoch: 6| Step: 9
Training loss: 2.2384256845578068
Validation loss: 2.4640869252299136

Epoch: 6| Step: 10
Training loss: 2.6209394747816575
Validation loss: 2.464418966101246

Epoch: 6| Step: 11
Training loss: 2.992161046003327
Validation loss: 2.457951553786054

Epoch: 6| Step: 12
Training loss: 2.8986704442275397
Validation loss: 2.465489918949351

Epoch: 6| Step: 13
Training loss: 2.4568443530492248
Validation loss: 2.465629472555239

Epoch: 170| Step: 0
Training loss: 2.1290590003973238
Validation loss: 2.4724871038724783

Epoch: 6| Step: 1
Training loss: 2.215942540838845
Validation loss: 2.4701470554710014

Epoch: 6| Step: 2
Training loss: 2.541612020019743
Validation loss: 2.470814192013203

Epoch: 6| Step: 3
Training loss: 2.5972979994093084
Validation loss: 2.4681350167364955

Epoch: 6| Step: 4
Training loss: 2.0676094114789376
Validation loss: 2.48329330183786

Epoch: 6| Step: 5
Training loss: 2.866312584707389
Validation loss: 2.4625814931071597

Epoch: 6| Step: 6
Training loss: 1.9066269923908565
Validation loss: 2.4759800463690533

Epoch: 6| Step: 7
Training loss: 2.0220243608118458
Validation loss: 2.473267972224777

Epoch: 6| Step: 8
Training loss: 2.6809639518047357
Validation loss: 2.4726485040833617

Epoch: 6| Step: 9
Training loss: 2.1676858803354473
Validation loss: 2.475762736511186

Epoch: 6| Step: 10
Training loss: 2.9085838217287914
Validation loss: 2.474739358323855

Epoch: 6| Step: 11
Training loss: 2.741112914199693
Validation loss: 2.4662155469140026

Epoch: 6| Step: 12
Training loss: 2.4916932384218113
Validation loss: 2.4702284204859324

Epoch: 6| Step: 13
Training loss: 2.6685790317633633
Validation loss: 2.465480168113457

Epoch: 171| Step: 0
Training loss: 2.6980744736716433
Validation loss: 2.4647495032104687

Epoch: 6| Step: 1
Training loss: 2.552083312573076
Validation loss: 2.47183445295603

Epoch: 6| Step: 2
Training loss: 2.446379310024434
Validation loss: 2.4725457157219646

Epoch: 6| Step: 3
Training loss: 2.7877365935636735
Validation loss: 2.4753694839702463

Epoch: 6| Step: 4
Training loss: 2.5953366126330386
Validation loss: 2.467435043958973

Epoch: 6| Step: 5
Training loss: 2.5188354477693564
Validation loss: 2.46621524078009

Epoch: 6| Step: 6
Training loss: 2.5085986084773686
Validation loss: 2.484628436519194

Epoch: 6| Step: 7
Training loss: 2.4295813239838413
Validation loss: 2.479810796667782

Epoch: 6| Step: 8
Training loss: 2.231366245863989
Validation loss: 2.486651147643984

Epoch: 6| Step: 9
Training loss: 2.541734152559787
Validation loss: 2.4901448950554803

Epoch: 6| Step: 10
Training loss: 2.556293321163133
Validation loss: 2.4737198617675724

Epoch: 6| Step: 11
Training loss: 1.8051500264425941
Validation loss: 2.4720764444592658

Epoch: 6| Step: 12
Training loss: 2.5795268553466997
Validation loss: 2.473585383094425

Epoch: 6| Step: 13
Training loss: 1.7232119816468914
Validation loss: 2.471407421785712

Epoch: 172| Step: 0
Training loss: 2.786961894420544
Validation loss: 2.462298982422547

Epoch: 6| Step: 1
Training loss: 2.2514624611141425
Validation loss: 2.4675691170563505

Epoch: 6| Step: 2
Training loss: 2.690041161261252
Validation loss: 2.4635105305828513

Epoch: 6| Step: 3
Training loss: 2.6190363033264905
Validation loss: 2.466000905489749

Epoch: 6| Step: 4
Training loss: 2.0870081978944435
Validation loss: 2.46603327772587

Epoch: 6| Step: 5
Training loss: 2.8666028666235026
Validation loss: 2.473412115465212

Epoch: 6| Step: 6
Training loss: 1.8584133193702614
Validation loss: 2.4785439379682925

Epoch: 6| Step: 7
Training loss: 1.5178318278020835
Validation loss: 2.475295399527823

Epoch: 6| Step: 8
Training loss: 2.5233862904174034
Validation loss: 2.474267684601974

Epoch: 6| Step: 9
Training loss: 2.7563275453899863
Validation loss: 2.4747202426128276

Epoch: 6| Step: 10
Training loss: 2.330418832815323
Validation loss: 2.471667597799025

Epoch: 6| Step: 11
Training loss: 2.494464467890329
Validation loss: 2.476119650668003

Epoch: 6| Step: 12
Training loss: 2.8696825360954463
Validation loss: 2.47957234843385

Epoch: 6| Step: 13
Training loss: 2.215871098332723
Validation loss: 2.470168852806818

Epoch: 173| Step: 0
Training loss: 2.503934624997667
Validation loss: 2.4790329028889384

Epoch: 6| Step: 1
Training loss: 2.5274068597522836
Validation loss: 2.463988988695373

Epoch: 6| Step: 2
Training loss: 1.865165413585291
Validation loss: 2.46733345564758

Epoch: 6| Step: 3
Training loss: 2.5538993342910725
Validation loss: 2.4562359985004263

Epoch: 6| Step: 4
Training loss: 2.4587662094815323
Validation loss: 2.4534603869625426

Epoch: 6| Step: 5
Training loss: 2.0874207898490527
Validation loss: 2.47519028892219

Epoch: 6| Step: 6
Training loss: 3.1613118589721156
Validation loss: 2.483020181134225

Epoch: 6| Step: 7
Training loss: 2.748785877973764
Validation loss: 2.479232536103366

Epoch: 6| Step: 8
Training loss: 2.1814525389980695
Validation loss: 2.482927664535943

Epoch: 6| Step: 9
Training loss: 2.492379208070331
Validation loss: 2.4684496588237885

Epoch: 6| Step: 10
Training loss: 2.322083179695877
Validation loss: 2.468232458729161

Epoch: 6| Step: 11
Training loss: 2.2998000223877844
Validation loss: 2.467990114466336

Epoch: 6| Step: 12
Training loss: 2.9948557617405167
Validation loss: 2.4753119423025303

Epoch: 6| Step: 13
Training loss: 2.0668434877534034
Validation loss: 2.471336458475699

Epoch: 174| Step: 0
Training loss: 2.16709076569944
Validation loss: 2.4747987116254624

Epoch: 6| Step: 1
Training loss: 2.7081719179224804
Validation loss: 2.4722461490925784

Epoch: 6| Step: 2
Training loss: 2.6521023849757928
Validation loss: 2.468204977337314

Epoch: 6| Step: 3
Training loss: 2.5587479639534427
Validation loss: 2.4744837527566137

Epoch: 6| Step: 4
Training loss: 2.121134889319622
Validation loss: 2.480236645349637

Epoch: 6| Step: 5
Training loss: 1.8439975507682704
Validation loss: 2.4727000171871754

Epoch: 6| Step: 6
Training loss: 2.602952007576697
Validation loss: 2.46853825107707

Epoch: 6| Step: 7
Training loss: 2.2562985739934516
Validation loss: 2.4726533653720546

Epoch: 6| Step: 8
Training loss: 2.125257364283422
Validation loss: 2.469935152821645

Epoch: 6| Step: 9
Training loss: 2.7194032432371285
Validation loss: 2.4713228556689844

Epoch: 6| Step: 10
Training loss: 2.453539965089325
Validation loss: 2.4731264234848367

Epoch: 6| Step: 11
Training loss: 2.3559446344395347
Validation loss: 2.481393484519898

Epoch: 6| Step: 12
Training loss: 2.862285862538317
Validation loss: 2.47020189430556

Epoch: 6| Step: 13
Training loss: 2.5813380708979383
Validation loss: 2.4821895847842486

Epoch: 175| Step: 0
Training loss: 2.418851675809294
Validation loss: 2.4793045956579722

Epoch: 6| Step: 1
Training loss: 2.620828219976324
Validation loss: 2.462336196227798

Epoch: 6| Step: 2
Training loss: 2.817082296174826
Validation loss: 2.4645951312425782

Epoch: 6| Step: 3
Training loss: 2.441381445186491
Validation loss: 2.4649099108345265

Epoch: 6| Step: 4
Training loss: 2.4826784879168775
Validation loss: 2.4677978643233187

Epoch: 6| Step: 5
Training loss: 2.221754377178586
Validation loss: 2.4661325510077545

Epoch: 6| Step: 6
Training loss: 2.0894231925698836
Validation loss: 2.466898775349372

Epoch: 6| Step: 7
Training loss: 2.4163582265172154
Validation loss: 2.4692900022803177

Epoch: 6| Step: 8
Training loss: 3.6439998848556017
Validation loss: 2.470984867803496

Epoch: 6| Step: 9
Training loss: 2.1391210911642133
Validation loss: 2.460788847455191

Epoch: 6| Step: 10
Training loss: 2.4353457981977256
Validation loss: 2.476227233206934

Epoch: 6| Step: 11
Training loss: 1.8472337300158055
Validation loss: 2.4675120537439947

Epoch: 6| Step: 12
Training loss: 2.7218540931012596
Validation loss: 2.463153934949268

Epoch: 6| Step: 13
Training loss: 1.7470224799340441
Validation loss: 2.4674083186505933

Epoch: 176| Step: 0
Training loss: 2.3542442871620723
Validation loss: 2.458703519675645

Epoch: 6| Step: 1
Training loss: 2.643072855920567
Validation loss: 2.4637617425559717

Epoch: 6| Step: 2
Training loss: 2.335622504694634
Validation loss: 2.4575023270289083

Epoch: 6| Step: 3
Training loss: 2.899079202939194
Validation loss: 2.481522680140132

Epoch: 6| Step: 4
Training loss: 2.1858231793409075
Validation loss: 2.487289798104401

Epoch: 6| Step: 5
Training loss: 2.3825846578761944
Validation loss: 2.4834226546342446

Epoch: 6| Step: 6
Training loss: 2.945625915850961
Validation loss: 2.476095899716301

Epoch: 6| Step: 7
Training loss: 2.789445952227422
Validation loss: 2.4783144108405413

Epoch: 6| Step: 8
Training loss: 2.540748763970222
Validation loss: 2.4813311982341246

Epoch: 6| Step: 9
Training loss: 2.531113609124435
Validation loss: 2.471771676612406

Epoch: 6| Step: 10
Training loss: 1.9646390349446317
Validation loss: 2.474630811879944

Epoch: 6| Step: 11
Training loss: 2.0868330615348913
Validation loss: 2.4706784856520088

Epoch: 6| Step: 12
Training loss: 2.2382746458372247
Validation loss: 2.4608547782114254

Epoch: 6| Step: 13
Training loss: 2.573284714870354
Validation loss: 2.4711433752196426

Epoch: 177| Step: 0
Training loss: 2.254023134053614
Validation loss: 2.461025022534768

Epoch: 6| Step: 1
Training loss: 2.4520482901567706
Validation loss: 2.4658496736597653

Epoch: 6| Step: 2
Training loss: 2.062798680728877
Validation loss: 2.4584913256894763

Epoch: 6| Step: 3
Training loss: 2.415777393582496
Validation loss: 2.4708923026173

Epoch: 6| Step: 4
Training loss: 2.261622504260188
Validation loss: 2.458261833659785

Epoch: 6| Step: 5
Training loss: 2.90137918496131
Validation loss: 2.460067433748491

Epoch: 6| Step: 6
Training loss: 2.811815475237425
Validation loss: 2.463652938254676

Epoch: 6| Step: 7
Training loss: 2.1925350552652274
Validation loss: 2.4711665627301644

Epoch: 6| Step: 8
Training loss: 2.4183704245956785
Validation loss: 2.464686594777864

Epoch: 6| Step: 9
Training loss: 2.704516102490945
Validation loss: 2.4640300634906436

Epoch: 6| Step: 10
Training loss: 2.60543772894881
Validation loss: 2.4586256521535295

Epoch: 6| Step: 11
Training loss: 2.4853895502990753
Validation loss: 2.468545559172231

Epoch: 6| Step: 12
Training loss: 2.64876840150282
Validation loss: 2.4678350193605914

Epoch: 6| Step: 13
Training loss: 2.044734621993143
Validation loss: 2.4675957601067138

Epoch: 178| Step: 0
Training loss: 2.801774746566766
Validation loss: 2.4737195244354853

Epoch: 6| Step: 1
Training loss: 2.4398549759087724
Validation loss: 2.4855006484887303

Epoch: 6| Step: 2
Training loss: 2.268538817778381
Validation loss: 2.4767889166019668

Epoch: 6| Step: 3
Training loss: 2.237963802068773
Validation loss: 2.478994481067123

Epoch: 6| Step: 4
Training loss: 2.8945114814608344
Validation loss: 2.477294011590646

Epoch: 6| Step: 5
Training loss: 2.378021827494911
Validation loss: 2.4690741475084073

Epoch: 6| Step: 6
Training loss: 2.410365264089521
Validation loss: 2.474537387474243

Epoch: 6| Step: 7
Training loss: 2.2827516603815785
Validation loss: 2.477041412803018

Epoch: 6| Step: 8
Training loss: 2.5190576862364455
Validation loss: 2.4811459555539734

Epoch: 6| Step: 9
Training loss: 2.5681532860519014
Validation loss: 2.4735894553923714

Epoch: 6| Step: 10
Training loss: 2.6986966766842437
Validation loss: 2.488022116557661

Epoch: 6| Step: 11
Training loss: 2.3645374332852045
Validation loss: 2.4933205383740864

Epoch: 6| Step: 12
Training loss: 2.056531419598875
Validation loss: 2.5084088449317443

Epoch: 6| Step: 13
Training loss: 1.9338252998195489
Validation loss: 2.5067860769641506

Epoch: 179| Step: 0
Training loss: 2.1192178035341054
Validation loss: 2.51354327264369

Epoch: 6| Step: 1
Training loss: 2.648869572056281
Validation loss: 2.5135621010088958

Epoch: 6| Step: 2
Training loss: 2.227850611672809
Validation loss: 2.47726093636221

Epoch: 6| Step: 3
Training loss: 2.9987014503253895
Validation loss: 2.4886405282218633

Epoch: 6| Step: 4
Training loss: 2.2694992089430897
Validation loss: 2.48297756407392

Epoch: 6| Step: 5
Training loss: 2.0304945494600477
Validation loss: 2.4794121441736467

Epoch: 6| Step: 6
Training loss: 3.024607823699234
Validation loss: 2.474529077380777

Epoch: 6| Step: 7
Training loss: 2.8580616086882413
Validation loss: 2.4789151029351566

Epoch: 6| Step: 8
Training loss: 2.306630908968212
Validation loss: 2.4749607076640627

Epoch: 6| Step: 9
Training loss: 2.4253627151896135
Validation loss: 2.4710641790649435

Epoch: 6| Step: 10
Training loss: 2.138945540246269
Validation loss: 2.4787490289929557

Epoch: 6| Step: 11
Training loss: 2.284021862199308
Validation loss: 2.4808987462555505

Epoch: 6| Step: 12
Training loss: 2.588628837811387
Validation loss: 2.4753511918205655

Epoch: 6| Step: 13
Training loss: 2.435997622214724
Validation loss: 2.496155094831633

Epoch: 180| Step: 0
Training loss: 2.6487437383443604
Validation loss: 2.4973181486063574

Epoch: 6| Step: 1
Training loss: 2.9985328901661563
Validation loss: 2.502731928638866

Epoch: 6| Step: 2
Training loss: 2.3476463990472918
Validation loss: 2.501534825302383

Epoch: 6| Step: 3
Training loss: 1.9531547849291417
Validation loss: 2.4838923179323893

Epoch: 6| Step: 4
Training loss: 2.4274018260145898
Validation loss: 2.487158825095496

Epoch: 6| Step: 5
Training loss: 2.0953051357154098
Validation loss: 2.4797575323979673

Epoch: 6| Step: 6
Training loss: 2.841508254243782
Validation loss: 2.472543497914729

Epoch: 6| Step: 7
Training loss: 2.554309035332204
Validation loss: 2.4784554147784332

Epoch: 6| Step: 8
Training loss: 2.686027833352702
Validation loss: 2.4761090028877613

Epoch: 6| Step: 9
Training loss: 2.3331645722894727
Validation loss: 2.46482171211527

Epoch: 6| Step: 10
Training loss: 2.2807129528244348
Validation loss: 2.471934080000603

Epoch: 6| Step: 11
Training loss: 2.13292137678545
Validation loss: 2.465072000598474

Epoch: 6| Step: 12
Training loss: 1.7056186164577147
Validation loss: 2.467633666979028

Epoch: 6| Step: 13
Training loss: 2.588661626010061
Validation loss: 2.464289954150905

Epoch: 181| Step: 0
Training loss: 2.760723706329634
Validation loss: 2.464327331386367

Epoch: 6| Step: 1
Training loss: 3.1338331885721655
Validation loss: 2.46846432380994

Epoch: 6| Step: 2
Training loss: 2.157679982021355
Validation loss: 2.465391683558822

Epoch: 6| Step: 3
Training loss: 2.942049926199335
Validation loss: 2.4643965696854493

Epoch: 6| Step: 4
Training loss: 2.0835216691401044
Validation loss: 2.4784121981525216

Epoch: 6| Step: 5
Training loss: 2.6326567380203865
Validation loss: 2.464941974986068

Epoch: 6| Step: 6
Training loss: 1.8793678906188602
Validation loss: 2.48677973455253

Epoch: 6| Step: 7
Training loss: 2.3618571380642397
Validation loss: 2.479749087566602

Epoch: 6| Step: 8
Training loss: 2.9687463057645602
Validation loss: 2.4738941438612785

Epoch: 6| Step: 9
Training loss: 2.5523017218953257
Validation loss: 2.4813243922076422

Epoch: 6| Step: 10
Training loss: 1.254036489597664
Validation loss: 2.4943162044260045

Epoch: 6| Step: 11
Training loss: 1.6788269677487258
Validation loss: 2.501525540607996

Epoch: 6| Step: 12
Training loss: 2.1182645753655938
Validation loss: 2.501671153053295

Epoch: 6| Step: 13
Training loss: 2.304785774851221
Validation loss: 2.4906744594281887

Epoch: 182| Step: 0
Training loss: 2.2877589344996148
Validation loss: 2.5000389731866153

Epoch: 6| Step: 1
Training loss: 2.7369224670712318
Validation loss: 2.4861921946008643

Epoch: 6| Step: 2
Training loss: 2.456815531226119
Validation loss: 2.4859220298479143

Epoch: 6| Step: 3
Training loss: 2.0859013815049496
Validation loss: 2.483215653321532

Epoch: 6| Step: 4
Training loss: 2.5131535681158828
Validation loss: 2.482173127868326

Epoch: 6| Step: 5
Training loss: 2.2582760239352413
Validation loss: 2.477374965439383

Epoch: 6| Step: 6
Training loss: 2.537142828999032
Validation loss: 2.490169988061608

Epoch: 6| Step: 7
Training loss: 2.2734970661762706
Validation loss: 2.485021543044843

Epoch: 6| Step: 8
Training loss: 2.700666423074709
Validation loss: 2.4938366893210437

Epoch: 6| Step: 9
Training loss: 3.1982055102858773
Validation loss: 2.4859857116154593

Epoch: 6| Step: 10
Training loss: 2.34703921621007
Validation loss: 2.4923688290438926

Epoch: 6| Step: 11
Training loss: 2.5475937466878116
Validation loss: 2.4872561049262947

Epoch: 6| Step: 12
Training loss: 2.2216468490018135
Validation loss: 2.4759227355545064

Epoch: 6| Step: 13
Training loss: 2.7254751928527012
Validation loss: 2.474041687749084

Epoch: 183| Step: 0
Training loss: 2.8298186399761116
Validation loss: 2.476400239685122

Epoch: 6| Step: 1
Training loss: 2.640805842058988
Validation loss: 2.476493377202261

Epoch: 6| Step: 2
Training loss: 3.084735104952224
Validation loss: 2.4967178734526496

Epoch: 6| Step: 3
Training loss: 2.422718614884518
Validation loss: 2.5103225426552354

Epoch: 6| Step: 4
Training loss: 2.2561493658305296
Validation loss: 2.5350542092029142

Epoch: 6| Step: 5
Training loss: 2.4829932634966663
Validation loss: 2.5570190087513076

Epoch: 6| Step: 6
Training loss: 2.335491431267711
Validation loss: 2.553837532713006

Epoch: 6| Step: 7
Training loss: 2.0213447264565803
Validation loss: 2.5233407961618717

Epoch: 6| Step: 8
Training loss: 1.9646642766022595
Validation loss: 2.4955061577621795

Epoch: 6| Step: 9
Training loss: 2.137327006517273
Validation loss: 2.4860066587881176

Epoch: 6| Step: 10
Training loss: 2.3611336526231033
Validation loss: 2.4795134379320265

Epoch: 6| Step: 11
Training loss: 2.0123511644379795
Validation loss: 2.483292589770791

Epoch: 6| Step: 12
Training loss: 2.9131111453401464
Validation loss: 2.478706065968598

Epoch: 6| Step: 13
Training loss: 2.349009296910388
Validation loss: 2.4737102638485586

Epoch: 184| Step: 0
Training loss: 2.0953975287586437
Validation loss: 2.4739723339019277

Epoch: 6| Step: 1
Training loss: 1.9336346862775258
Validation loss: 2.4800090614148176

Epoch: 6| Step: 2
Training loss: 2.5521924261533937
Validation loss: 2.472620445020353

Epoch: 6| Step: 3
Training loss: 2.2916266235552225
Validation loss: 2.4800272390961626

Epoch: 6| Step: 4
Training loss: 2.7683397320652947
Validation loss: 2.4819906857203318

Epoch: 6| Step: 5
Training loss: 2.8679008739797185
Validation loss: 2.4878608991328766

Epoch: 6| Step: 6
Training loss: 2.6424909691489376
Validation loss: 2.4828396097299237

Epoch: 6| Step: 7
Training loss: 2.1884165342406017
Validation loss: 2.48286955383571

Epoch: 6| Step: 8
Training loss: 1.8659535564395564
Validation loss: 2.4772591558693944

Epoch: 6| Step: 9
Training loss: 2.3084322232250254
Validation loss: 2.4813432248376346

Epoch: 6| Step: 10
Training loss: 2.7628302812559626
Validation loss: 2.4811569580775124

Epoch: 6| Step: 11
Training loss: 2.8755006768841547
Validation loss: 2.4691559984858804

Epoch: 6| Step: 12
Training loss: 3.0123312558601083
Validation loss: 2.4695983266163455

Epoch: 6| Step: 13
Training loss: 1.8811109776630468
Validation loss: 2.487629995351884

Epoch: 185| Step: 0
Training loss: 2.5844969641102535
Validation loss: 2.4848035846559893

Epoch: 6| Step: 1
Training loss: 2.0213219618859077
Validation loss: 2.486897641321991

Epoch: 6| Step: 2
Training loss: 2.395078811145195
Validation loss: 2.48961928805853

Epoch: 6| Step: 3
Training loss: 2.538476119188524
Validation loss: 2.4853660638032657

Epoch: 6| Step: 4
Training loss: 2.8176253348282168
Validation loss: 2.4755109606342067

Epoch: 6| Step: 5
Training loss: 2.5478936714970826
Validation loss: 2.490875169673461

Epoch: 6| Step: 6
Training loss: 1.9375773998920687
Validation loss: 2.4816149528893257

Epoch: 6| Step: 7
Training loss: 2.4624813989236887
Validation loss: 2.4782696124130434

Epoch: 6| Step: 8
Training loss: 2.4004003588212934
Validation loss: 2.4892077195884124

Epoch: 6| Step: 9
Training loss: 1.9536641101665309
Validation loss: 2.4832122608941076

Epoch: 6| Step: 10
Training loss: 2.2049024189227593
Validation loss: 2.480461364895297

Epoch: 6| Step: 11
Training loss: 2.9492061387354536
Validation loss: 2.4847995227407966

Epoch: 6| Step: 12
Training loss: 2.644016773661214
Validation loss: 2.475783922654027

Epoch: 6| Step: 13
Training loss: 2.401115190176044
Validation loss: 2.4826424273367134

Epoch: 186| Step: 0
Training loss: 1.8996332743241668
Validation loss: 2.4833141597118553

Epoch: 6| Step: 1
Training loss: 2.732481906059647
Validation loss: 2.49425240079248

Epoch: 6| Step: 2
Training loss: 1.826322139330876
Validation loss: 2.515513099724762

Epoch: 6| Step: 3
Training loss: 2.008279115359214
Validation loss: 2.535652507845588

Epoch: 6| Step: 4
Training loss: 3.1848631779433223
Validation loss: 2.5558191062183835

Epoch: 6| Step: 5
Training loss: 3.0008554828323897
Validation loss: 2.552603599819662

Epoch: 6| Step: 6
Training loss: 2.657957179164475
Validation loss: 2.5963856737577586

Epoch: 6| Step: 7
Training loss: 2.6424665180781037
Validation loss: 2.5654395076281564

Epoch: 6| Step: 8
Training loss: 2.0924357374525635
Validation loss: 2.562014231345252

Epoch: 6| Step: 9
Training loss: 2.5247181574578117
Validation loss: 2.5268506881496644

Epoch: 6| Step: 10
Training loss: 2.4757015043291464
Validation loss: 2.4977656870549727

Epoch: 6| Step: 11
Training loss: 2.1651824366853845
Validation loss: 2.48431885853798

Epoch: 6| Step: 12
Training loss: 2.3426303477952155
Validation loss: 2.4831863214727266

Epoch: 6| Step: 13
Training loss: 1.7138001344611065
Validation loss: 2.484526735546426

Epoch: 187| Step: 0
Training loss: 2.158030120681827
Validation loss: 2.48712215045843

Epoch: 6| Step: 1
Training loss: 2.616634936859123
Validation loss: 2.480985284324219

Epoch: 6| Step: 2
Training loss: 2.95859066197728
Validation loss: 2.479406863418848

Epoch: 6| Step: 3
Training loss: 2.639702810841673
Validation loss: 2.487235847262383

Epoch: 6| Step: 4
Training loss: 2.08831948282084
Validation loss: 2.484442927873399

Epoch: 6| Step: 5
Training loss: 2.6267490917511753
Validation loss: 2.4810872105414714

Epoch: 6| Step: 6
Training loss: 2.9512083908437443
Validation loss: 2.482902218266154

Epoch: 6| Step: 7
Training loss: 2.3000791867763803
Validation loss: 2.4869743999548697

Epoch: 6| Step: 8
Training loss: 2.5251276833760894
Validation loss: 2.4712983189748665

Epoch: 6| Step: 9
Training loss: 2.732825226969498
Validation loss: 2.4812636656108595

Epoch: 6| Step: 10
Training loss: 2.1291886728521856
Validation loss: 2.4775556464286144

Epoch: 6| Step: 11
Training loss: 2.637095784675117
Validation loss: 2.488815114606304

Epoch: 6| Step: 12
Training loss: 1.5478571076399097
Validation loss: 2.4820950040553025

Epoch: 6| Step: 13
Training loss: 2.3752467378642717
Validation loss: 2.49327020833826

Epoch: 188| Step: 0
Training loss: 2.8399196441457772
Validation loss: 2.48257696316069

Epoch: 6| Step: 1
Training loss: 2.0287777454220617
Validation loss: 2.4902975954495425

Epoch: 6| Step: 2
Training loss: 1.9254356832527586
Validation loss: 2.4808711488981245

Epoch: 6| Step: 3
Training loss: 2.357952977793111
Validation loss: 2.4842846772031324

Epoch: 6| Step: 4
Training loss: 2.2782951971665413
Validation loss: 2.4872870342904743

Epoch: 6| Step: 5
Training loss: 2.756865773865511
Validation loss: 2.482365185130078

Epoch: 6| Step: 6
Training loss: 2.132979613523712
Validation loss: 2.4980150051236394

Epoch: 6| Step: 7
Training loss: 2.676827553331491
Validation loss: 2.482831223395049

Epoch: 6| Step: 8
Training loss: 2.2443315310240335
Validation loss: 2.4812549856858084

Epoch: 6| Step: 9
Training loss: 3.0934463506090872
Validation loss: 2.4896783903694337

Epoch: 6| Step: 10
Training loss: 2.489689259423752
Validation loss: 2.4845926281438864

Epoch: 6| Step: 11
Training loss: 2.258956672067186
Validation loss: 2.4895609025995484

Epoch: 6| Step: 12
Training loss: 2.6213014068437914
Validation loss: 2.4868421320418155

Epoch: 6| Step: 13
Training loss: 2.074539533332664
Validation loss: 2.4887792227725187

Epoch: 189| Step: 0
Training loss: 2.2013047727391433
Validation loss: 2.492216263528338

Epoch: 6| Step: 1
Training loss: 1.9773192634407764
Validation loss: 2.4987777583234454

Epoch: 6| Step: 2
Training loss: 2.9276037511512523
Validation loss: 2.4963870565209785

Epoch: 6| Step: 3
Training loss: 2.333934933445997
Validation loss: 2.491524499539371

Epoch: 6| Step: 4
Training loss: 2.361490274041392
Validation loss: 2.4957868201284534

Epoch: 6| Step: 5
Training loss: 2.28604218353439
Validation loss: 2.4929277044280695

Epoch: 6| Step: 6
Training loss: 2.035129656773531
Validation loss: 2.4878648602171802

Epoch: 6| Step: 7
Training loss: 2.6142220621154717
Validation loss: 2.4746289331495754

Epoch: 6| Step: 8
Training loss: 2.7942789485892954
Validation loss: 2.4864700728353593

Epoch: 6| Step: 9
Training loss: 2.297805908890932
Validation loss: 2.490236960017041

Epoch: 6| Step: 10
Training loss: 2.359481505964763
Validation loss: 2.481733169083062

Epoch: 6| Step: 11
Training loss: 2.2244449651850697
Validation loss: 2.488804640886228

Epoch: 6| Step: 12
Training loss: 2.3625671821205336
Validation loss: 2.4804994436052086

Epoch: 6| Step: 13
Training loss: 2.9178996250283733
Validation loss: 2.4849308439746873

Epoch: 190| Step: 0
Training loss: 2.404758734388478
Validation loss: 2.4822849943258363

Epoch: 6| Step: 1
Training loss: 2.0259686402118433
Validation loss: 2.48556346177354

Epoch: 6| Step: 2
Training loss: 2.455803835971824
Validation loss: 2.4851397171118146

Epoch: 6| Step: 3
Training loss: 2.4840874655492757
Validation loss: 2.4892538855586426

Epoch: 6| Step: 4
Training loss: 2.857559378099646
Validation loss: 2.488153443380327

Epoch: 6| Step: 5
Training loss: 2.5704126773316207
Validation loss: 2.500167952300096

Epoch: 6| Step: 6
Training loss: 1.4163880167659164
Validation loss: 2.5174847159605176

Epoch: 6| Step: 7
Training loss: 2.355157075571915
Validation loss: 2.518236419972359

Epoch: 6| Step: 8
Training loss: 2.330878249076477
Validation loss: 2.5311522759305425

Epoch: 6| Step: 9
Training loss: 2.3308018394236445
Validation loss: 2.5334901982814153

Epoch: 6| Step: 10
Training loss: 2.7565372966067825
Validation loss: 2.536906777804944

Epoch: 6| Step: 11
Training loss: 2.68447226369238
Validation loss: 2.5201269584040027

Epoch: 6| Step: 12
Training loss: 2.083350473969201
Validation loss: 2.4915720340105056

Epoch: 6| Step: 13
Training loss: 2.9932801963094207
Validation loss: 2.4841126117457866

Epoch: 191| Step: 0
Training loss: 2.486131155358274
Validation loss: 2.4881697968614827

Epoch: 6| Step: 1
Training loss: 2.1791306744940737
Validation loss: 2.4769831960942565

Epoch: 6| Step: 2
Training loss: 2.710129675208423
Validation loss: 2.484868422478122

Epoch: 6| Step: 3
Training loss: 2.5860265618514195
Validation loss: 2.4814058551155878

Epoch: 6| Step: 4
Training loss: 2.4392921510702044
Validation loss: 2.483415014301897

Epoch: 6| Step: 5
Training loss: 2.392405426643517
Validation loss: 2.476812516517745

Epoch: 6| Step: 6
Training loss: 2.955145250807334
Validation loss: 2.4818296689040675

Epoch: 6| Step: 7
Training loss: 2.383113454355064
Validation loss: 2.482832407726501

Epoch: 6| Step: 8
Training loss: 1.960819803178535
Validation loss: 2.4784176413564927

Epoch: 6| Step: 9
Training loss: 1.3705133584508173
Validation loss: 2.481042253972165

Epoch: 6| Step: 10
Training loss: 2.020837947669775
Validation loss: 2.4786112240590565

Epoch: 6| Step: 11
Training loss: 3.0263537947932933
Validation loss: 2.480786440872445

Epoch: 6| Step: 12
Training loss: 2.6712585094925076
Validation loss: 2.471342407670232

Epoch: 6| Step: 13
Training loss: 2.7222585729736735
Validation loss: 2.486471175528322

Epoch: 192| Step: 0
Training loss: 2.5384458761465623
Validation loss: 2.493133469027944

Epoch: 6| Step: 1
Training loss: 2.3068716271064966
Validation loss: 2.4953638958878104

Epoch: 6| Step: 2
Training loss: 2.1365215761473175
Validation loss: 2.5039838281953237

Epoch: 6| Step: 3
Training loss: 2.973718280534877
Validation loss: 2.499348595312711

Epoch: 6| Step: 4
Training loss: 2.5194296173179063
Validation loss: 2.506960857921161

Epoch: 6| Step: 5
Training loss: 2.7046738966363386
Validation loss: 2.4964459747320102

Epoch: 6| Step: 6
Training loss: 2.1335136183417385
Validation loss: 2.5052809569260677

Epoch: 6| Step: 7
Training loss: 2.1710846924429856
Validation loss: 2.519023014035658

Epoch: 6| Step: 8
Training loss: 2.000118728928253
Validation loss: 2.5139453327195493

Epoch: 6| Step: 9
Training loss: 2.1453443420669833
Validation loss: 2.499693835902571

Epoch: 6| Step: 10
Training loss: 2.6362752809935714
Validation loss: 2.486695890953758

Epoch: 6| Step: 11
Training loss: 2.530755359686565
Validation loss: 2.4858938408739606

Epoch: 6| Step: 12
Training loss: 2.1584682388071994
Validation loss: 2.484408924183059

Epoch: 6| Step: 13
Training loss: 2.523006059830593
Validation loss: 2.4736877025684256

Epoch: 193| Step: 0
Training loss: 2.0916899610136706
Validation loss: 2.4812238049665822

Epoch: 6| Step: 1
Training loss: 2.893923635196281
Validation loss: 2.474314876094763

Epoch: 6| Step: 2
Training loss: 2.4531430772248948
Validation loss: 2.4895474472545307

Epoch: 6| Step: 3
Training loss: 2.0632480074115884
Validation loss: 2.4857962839364656

Epoch: 6| Step: 4
Training loss: 2.4106951193072823
Validation loss: 2.472813388839248

Epoch: 6| Step: 5
Training loss: 2.553428783110083
Validation loss: 2.480305711889845

Epoch: 6| Step: 6
Training loss: 2.2704585638140014
Validation loss: 2.482190977533799

Epoch: 6| Step: 7
Training loss: 1.7818078623111893
Validation loss: 2.48460263183083

Epoch: 6| Step: 8
Training loss: 2.3309998651649306
Validation loss: 2.478602005796253

Epoch: 6| Step: 9
Training loss: 3.4342548658274437
Validation loss: 2.4782803070289114

Epoch: 6| Step: 10
Training loss: 1.6594268273487407
Validation loss: 2.489077374321475

Epoch: 6| Step: 11
Training loss: 2.570387633364741
Validation loss: 2.49692021449548

Epoch: 6| Step: 12
Training loss: 2.0223911481500614
Validation loss: 2.5141606145964412

Epoch: 6| Step: 13
Training loss: 2.6702124347542666
Validation loss: 2.5222531935974444

Epoch: 194| Step: 0
Training loss: 2.7263570014003067
Validation loss: 2.5181990065768933

Epoch: 6| Step: 1
Training loss: 2.0038364093351526
Validation loss: 2.5257665477780633

Epoch: 6| Step: 2
Training loss: 2.754125361822964
Validation loss: 2.522521853772895

Epoch: 6| Step: 3
Training loss: 2.399810894827469
Validation loss: 2.5180572929757403

Epoch: 6| Step: 4
Training loss: 2.0440025850119174
Validation loss: 2.5041804964399845

Epoch: 6| Step: 5
Training loss: 1.911473605920409
Validation loss: 2.5093542016585886

Epoch: 6| Step: 6
Training loss: 2.832387167828834
Validation loss: 2.4977238306777085

Epoch: 6| Step: 7
Training loss: 2.0679963597499897
Validation loss: 2.4927235408520456

Epoch: 6| Step: 8
Training loss: 2.48766219793998
Validation loss: 2.50337261954752

Epoch: 6| Step: 9
Training loss: 2.9575215869157665
Validation loss: 2.50868557698863

Epoch: 6| Step: 10
Training loss: 1.7344530792531863
Validation loss: 2.500008153902108

Epoch: 6| Step: 11
Training loss: 2.0957750235220263
Validation loss: 2.5052630497170933

Epoch: 6| Step: 12
Training loss: 2.4854284008566636
Validation loss: 2.495927497688026

Epoch: 6| Step: 13
Training loss: 2.889367237183781
Validation loss: 2.503706314586948

Epoch: 195| Step: 0
Training loss: 2.076978898045434
Validation loss: 2.515986130345156

Epoch: 6| Step: 1
Training loss: 2.738888225680003
Validation loss: 2.52323697044309

Epoch: 6| Step: 2
Training loss: 2.426979346496697
Validation loss: 2.522504226484435

Epoch: 6| Step: 3
Training loss: 2.4443766110092313
Validation loss: 2.550520848082146

Epoch: 6| Step: 4
Training loss: 2.0120073130040526
Validation loss: 2.563272809362849

Epoch: 6| Step: 5
Training loss: 2.354886465393306
Validation loss: 2.553014878474331

Epoch: 6| Step: 6
Training loss: 2.541105510696417
Validation loss: 2.5388126817706955

Epoch: 6| Step: 7
Training loss: 2.863160009796731
Validation loss: 2.531045756321939

Epoch: 6| Step: 8
Training loss: 1.9894125367463444
Validation loss: 2.5100564553141704

Epoch: 6| Step: 9
Training loss: 2.4310681507972585
Validation loss: 2.482219504714718

Epoch: 6| Step: 10
Training loss: 2.062015939031171
Validation loss: 2.4876043575767017

Epoch: 6| Step: 11
Training loss: 2.510902473855831
Validation loss: 2.4797391364096186

Epoch: 6| Step: 12
Training loss: 2.4474596827988364
Validation loss: 2.4787109274004155

Epoch: 6| Step: 13
Training loss: 2.575420648974656
Validation loss: 2.483307175103825

Epoch: 196| Step: 0
Training loss: 2.337723983396326
Validation loss: 2.474111095865247

Epoch: 6| Step: 1
Training loss: 2.9306487680790516
Validation loss: 2.4657590670895457

Epoch: 6| Step: 2
Training loss: 1.7229446550315415
Validation loss: 2.4868760545269293

Epoch: 6| Step: 3
Training loss: 1.6777337355162854
Validation loss: 2.468242915101059

Epoch: 6| Step: 4
Training loss: 2.3255098747744203
Validation loss: 2.4866515151815936

Epoch: 6| Step: 5
Training loss: 2.462592062221632
Validation loss: 2.480234290228414

Epoch: 6| Step: 6
Training loss: 2.947053672899791
Validation loss: 2.4798518337319657

Epoch: 6| Step: 7
Training loss: 2.4090799311785256
Validation loss: 2.4811216841668537

Epoch: 6| Step: 8
Training loss: 2.3953743425860154
Validation loss: 2.486631204652237

Epoch: 6| Step: 9
Training loss: 2.6819324931923196
Validation loss: 2.483690403436237

Epoch: 6| Step: 10
Training loss: 2.430709967174003
Validation loss: 2.4768803229103518

Epoch: 6| Step: 11
Training loss: 2.673566673096664
Validation loss: 2.4876948952802427

Epoch: 6| Step: 12
Training loss: 1.9189215195129599
Validation loss: 2.503991199466771

Epoch: 6| Step: 13
Training loss: 2.370313135698971
Validation loss: 2.4944124723375882

Epoch: 197| Step: 0
Training loss: 1.9752411779591237
Validation loss: 2.489509075977999

Epoch: 6| Step: 1
Training loss: 2.835257792921013
Validation loss: 2.4952310853406923

Epoch: 6| Step: 2
Training loss: 2.656110423291734
Validation loss: 2.495609942985579

Epoch: 6| Step: 3
Training loss: 2.1039142142455667
Validation loss: 2.5014661939970897

Epoch: 6| Step: 4
Training loss: 2.490628989873392
Validation loss: 2.493511585639845

Epoch: 6| Step: 5
Training loss: 2.463093808994688
Validation loss: 2.4980296794745915

Epoch: 6| Step: 6
Training loss: 2.6021792851988725
Validation loss: 2.499316225320292

Epoch: 6| Step: 7
Training loss: 2.1413898076313753
Validation loss: 2.501820576889285

Epoch: 6| Step: 8
Training loss: 2.6459864975057807
Validation loss: 2.5095185906612834

Epoch: 6| Step: 9
Training loss: 2.391086110043829
Validation loss: 2.507506418216766

Epoch: 6| Step: 10
Training loss: 1.75372531017018
Validation loss: 2.510045524060214

Epoch: 6| Step: 11
Training loss: 2.88590791745971
Validation loss: 2.514303440760695

Epoch: 6| Step: 12
Training loss: 2.345735649753695
Validation loss: 2.508679835148187

Epoch: 6| Step: 13
Training loss: 2.0723127958374197
Validation loss: 2.5016727732160917

Epoch: 198| Step: 0
Training loss: 1.9399365516984
Validation loss: 2.5066008527550103

Epoch: 6| Step: 1
Training loss: 2.381667865924609
Validation loss: 2.5288150519896053

Epoch: 6| Step: 2
Training loss: 2.096925292001796
Validation loss: 2.511671209206763

Epoch: 6| Step: 3
Training loss: 2.887812220219744
Validation loss: 2.503586564705945

Epoch: 6| Step: 4
Training loss: 2.888962055975166
Validation loss: 2.5084171378329123

Epoch: 6| Step: 5
Training loss: 2.1516937548259243
Validation loss: 2.4887382850134947

Epoch: 6| Step: 6
Training loss: 2.3071718435984683
Validation loss: 2.503789715527301

Epoch: 6| Step: 7
Training loss: 2.205653477931081
Validation loss: 2.5163496723069905

Epoch: 6| Step: 8
Training loss: 2.4038597223925957
Validation loss: 2.501119950888624

Epoch: 6| Step: 9
Training loss: 2.2098265104249153
Validation loss: 2.492766724564272

Epoch: 6| Step: 10
Training loss: 2.528477881550767
Validation loss: 2.479540168986072

Epoch: 6| Step: 11
Training loss: 2.401277432620114
Validation loss: 2.477759383924015

Epoch: 6| Step: 12
Training loss: 2.3149118990849096
Validation loss: 2.482677719654319

Epoch: 6| Step: 13
Training loss: 2.5394528132991367
Validation loss: 2.4855780018075393

Epoch: 199| Step: 0
Training loss: 2.32033777704824
Validation loss: 2.4884427595595953

Epoch: 6| Step: 1
Training loss: 2.5835647069211625
Validation loss: 2.4761532065229463

Epoch: 6| Step: 2
Training loss: 2.0652688831832458
Validation loss: 2.482446829977792

Epoch: 6| Step: 3
Training loss: 2.705625755431558
Validation loss: 2.4756266272697696

Epoch: 6| Step: 4
Training loss: 2.027436182638164
Validation loss: 2.4836053355809633

Epoch: 6| Step: 5
Training loss: 2.352629359354409
Validation loss: 2.4805736769863542

Epoch: 6| Step: 6
Training loss: 2.399056618770115
Validation loss: 2.4859434091372683

Epoch: 6| Step: 7
Training loss: 2.494624653258388
Validation loss: 2.4769901584290612

Epoch: 6| Step: 8
Training loss: 2.6682698874363715
Validation loss: 2.483010547150032

Epoch: 6| Step: 9
Training loss: 2.8671514108657723
Validation loss: 2.4912948524481227

Epoch: 6| Step: 10
Training loss: 2.2904610901770925
Validation loss: 2.4839190338574317

Epoch: 6| Step: 11
Training loss: 2.113629042798263
Validation loss: 2.497414889509883

Epoch: 6| Step: 12
Training loss: 2.404595338717298
Validation loss: 2.5026059714690234

Epoch: 6| Step: 13
Training loss: 2.324120476191801
Validation loss: 2.5143659137912815

Epoch: 200| Step: 0
Training loss: 1.5161576269178791
Validation loss: 2.509446812825801

Epoch: 6| Step: 1
Training loss: 2.959535291896674
Validation loss: 2.537482716042671

Epoch: 6| Step: 2
Training loss: 1.9034565954608007
Validation loss: 2.5384176521131128

Epoch: 6| Step: 3
Training loss: 2.1787934469332826
Validation loss: 2.557370564680329

Epoch: 6| Step: 4
Training loss: 2.6788629536705195
Validation loss: 2.541258190246283

Epoch: 6| Step: 5
Training loss: 1.5467572408222736
Validation loss: 2.524923054621192

Epoch: 6| Step: 6
Training loss: 2.7288496595314573
Validation loss: 2.5553207157104483

Epoch: 6| Step: 7
Training loss: 2.586150653271386
Validation loss: 2.5338754421071465

Epoch: 6| Step: 8
Training loss: 2.553640541871515
Validation loss: 2.506190590538805

Epoch: 6| Step: 9
Training loss: 2.030257584150767
Validation loss: 2.499516408560302

Epoch: 6| Step: 10
Training loss: 2.1213951950420182
Validation loss: 2.4956621683449667

Epoch: 6| Step: 11
Training loss: 3.0899406639747578
Validation loss: 2.500901059847234

Epoch: 6| Step: 12
Training loss: 2.536673868931869
Validation loss: 2.4904049484575475

Epoch: 6| Step: 13
Training loss: 2.536381923352317
Validation loss: 2.483755790269819

Epoch: 201| Step: 0
Training loss: 1.7796010198170507
Validation loss: 2.482717789031252

Epoch: 6| Step: 1
Training loss: 2.7330977590351786
Validation loss: 2.483691547360647

Epoch: 6| Step: 2
Training loss: 1.6131657519803806
Validation loss: 2.472870731543096

Epoch: 6| Step: 3
Training loss: 2.4147699300984384
Validation loss: 2.476892708025153

Epoch: 6| Step: 4
Training loss: 2.747397318232468
Validation loss: 2.47120679463508

Epoch: 6| Step: 5
Training loss: 2.5290713883562765
Validation loss: 2.482585942578916

Epoch: 6| Step: 6
Training loss: 2.9279120596827766
Validation loss: 2.4833820205967885

Epoch: 6| Step: 7
Training loss: 3.133346093604977
Validation loss: 2.4827544326985933

Epoch: 6| Step: 8
Training loss: 2.125284400308826
Validation loss: 2.487978738693945

Epoch: 6| Step: 9
Training loss: 2.672014377818
Validation loss: 2.4944797127044582

Epoch: 6| Step: 10
Training loss: 2.223980607956794
Validation loss: 2.5058465780405657

Epoch: 6| Step: 11
Training loss: 1.9001376227679863
Validation loss: 2.5265606271724645

Epoch: 6| Step: 12
Training loss: 2.163314083975726
Validation loss: 2.555159483384468

Epoch: 6| Step: 13
Training loss: 2.4023612169080457
Validation loss: 2.552946767262736

Epoch: 202| Step: 0
Training loss: 2.6451119668550342
Validation loss: 2.525745403311917

Epoch: 6| Step: 1
Training loss: 2.6758361365264904
Validation loss: 2.5075574053896275

Epoch: 6| Step: 2
Training loss: 2.3584301806222965
Validation loss: 2.4954414530226035

Epoch: 6| Step: 3
Training loss: 2.489593303665776
Validation loss: 2.4840599356109503

Epoch: 6| Step: 4
Training loss: 1.9446047065932925
Validation loss: 2.486418964877109

Epoch: 6| Step: 5
Training loss: 2.566416468955587
Validation loss: 2.48482135145897

Epoch: 6| Step: 6
Training loss: 2.681125533053781
Validation loss: 2.4900694868562114

Epoch: 6| Step: 7
Training loss: 2.23635989503907
Validation loss: 2.4851902357901725

Epoch: 6| Step: 8
Training loss: 2.6555068827823427
Validation loss: 2.494908823170588

Epoch: 6| Step: 9
Training loss: 1.8762538532214972
Validation loss: 2.481582575753137

Epoch: 6| Step: 10
Training loss: 2.644492573081969
Validation loss: 2.4769473574068437

Epoch: 6| Step: 11
Training loss: 2.4243873608857474
Validation loss: 2.4835362168030333

Epoch: 6| Step: 12
Training loss: 2.762106257207484
Validation loss: 2.474559820572712

Epoch: 6| Step: 13
Training loss: 2.3075822657244394
Validation loss: 2.4816059059081397

Epoch: 203| Step: 0
Training loss: 2.5166224048419035
Validation loss: 2.4879113865135465

Epoch: 6| Step: 1
Training loss: 2.539051419747458
Validation loss: 2.5026758814184618

Epoch: 6| Step: 2
Training loss: 2.788457981279366
Validation loss: 2.5035244734471775

Epoch: 6| Step: 3
Training loss: 2.481706829920257
Validation loss: 2.510198169448854

Epoch: 6| Step: 4
Training loss: 2.821170750266748
Validation loss: 2.5227694261857847

Epoch: 6| Step: 5
Training loss: 2.089611917631739
Validation loss: 2.529596565784606

Epoch: 6| Step: 6
Training loss: 1.3319193773470996
Validation loss: 2.516105337467852

Epoch: 6| Step: 7
Training loss: 2.1519762892072727
Validation loss: 2.520689484666591

Epoch: 6| Step: 8
Training loss: 2.8338033248938936
Validation loss: 2.509623743937697

Epoch: 6| Step: 9
Training loss: 2.4431402045611437
Validation loss: 2.516079405503448

Epoch: 6| Step: 10
Training loss: 1.9562672477181202
Validation loss: 2.522037806843415

Epoch: 6| Step: 11
Training loss: 2.7411498799198433
Validation loss: 2.500343712385136

Epoch: 6| Step: 12
Training loss: 2.5994793223831496
Validation loss: 2.50976875196131

Epoch: 6| Step: 13
Training loss: 1.7978593866529233
Validation loss: 2.522534030549913

Epoch: 204| Step: 0
Training loss: 2.279365701951941
Validation loss: 2.5284034515931024

Epoch: 6| Step: 1
Training loss: 2.0189765448754784
Validation loss: 2.5272257648110648

Epoch: 6| Step: 2
Training loss: 2.566932194669117
Validation loss: 2.5283264105074847

Epoch: 6| Step: 3
Training loss: 2.4695970072163105
Validation loss: 2.5310725868122637

Epoch: 6| Step: 4
Training loss: 2.0271222943609413
Validation loss: 2.529973905426271

Epoch: 6| Step: 5
Training loss: 2.591313516120843
Validation loss: 2.512552157694137

Epoch: 6| Step: 6
Training loss: 2.1867949303171392
Validation loss: 2.502133381068017

Epoch: 6| Step: 7
Training loss: 2.7513271943857216
Validation loss: 2.4883213169738654

Epoch: 6| Step: 8
Training loss: 2.375014154492412
Validation loss: 2.489593838359637

Epoch: 6| Step: 9
Training loss: 2.1640373806924362
Validation loss: 2.4831425710882633

Epoch: 6| Step: 10
Training loss: 2.6708237213898123
Validation loss: 2.495885069177687

Epoch: 6| Step: 11
Training loss: 2.7088968913302858
Validation loss: 2.488158306316372

Epoch: 6| Step: 12
Training loss: 2.2410437029109747
Validation loss: 2.4780745358037115

Epoch: 6| Step: 13
Training loss: 2.696073474437488
Validation loss: 2.4895294109128514

Epoch: 205| Step: 0
Training loss: 2.770953030020552
Validation loss: 2.4886450229629777

Epoch: 6| Step: 1
Training loss: 2.814652784626223
Validation loss: 2.508719758486788

Epoch: 6| Step: 2
Training loss: 1.8360854068995383
Validation loss: 2.5439110810361845

Epoch: 6| Step: 3
Training loss: 2.4710001288259202
Validation loss: 2.596737898640022

Epoch: 6| Step: 4
Training loss: 2.7250016343698062
Validation loss: 2.6010684287869275

Epoch: 6| Step: 5
Training loss: 1.925015001114693
Validation loss: 2.5691667842050387

Epoch: 6| Step: 6
Training loss: 2.80745957438033
Validation loss: 2.5669840216026056

Epoch: 6| Step: 7
Training loss: 3.092909727716163
Validation loss: 2.5276575222917295

Epoch: 6| Step: 8
Training loss: 1.986137148398195
Validation loss: 2.5106769337156343

Epoch: 6| Step: 9
Training loss: 2.19600669229596
Validation loss: 2.494538564459223

Epoch: 6| Step: 10
Training loss: 1.9536387263831245
Validation loss: 2.486778392310207

Epoch: 6| Step: 11
Training loss: 2.337999129426531
Validation loss: 2.4914220991853635

Epoch: 6| Step: 12
Training loss: 1.997313184822854
Validation loss: 2.489778683924114

Epoch: 6| Step: 13
Training loss: 2.076569742458507
Validation loss: 2.49210267435807

Epoch: 206| Step: 0
Training loss: 2.0728390805343
Validation loss: 2.4771620288493965

Epoch: 6| Step: 1
Training loss: 2.331395661658735
Validation loss: 2.4825881514147863

Epoch: 6| Step: 2
Training loss: 1.70147134836238
Validation loss: 2.491342327501665

Epoch: 6| Step: 3
Training loss: 2.696623287189951
Validation loss: 2.4933915533146553

Epoch: 6| Step: 4
Training loss: 2.705191555468138
Validation loss: 2.499271541004915

Epoch: 6| Step: 5
Training loss: 1.7333971308313738
Validation loss: 2.4969178432820045

Epoch: 6| Step: 6
Training loss: 2.5195755355846354
Validation loss: 2.4976542912231823

Epoch: 6| Step: 7
Training loss: 2.2768659924798347
Validation loss: 2.4962613920570433

Epoch: 6| Step: 8
Training loss: 2.9362842397695
Validation loss: 2.4963832840526963

Epoch: 6| Step: 9
Training loss: 2.386292564687882
Validation loss: 2.4895267453539276

Epoch: 6| Step: 10
Training loss: 2.572769150514122
Validation loss: 2.481033677377014

Epoch: 6| Step: 11
Training loss: 3.0856964403474065
Validation loss: 2.4780316332449535

Epoch: 6| Step: 12
Training loss: 2.284819123269041
Validation loss: 2.4837257768550165

Epoch: 6| Step: 13
Training loss: 2.2502924411188516
Validation loss: 2.4896811036473494

Epoch: 207| Step: 0
Training loss: 1.7133995700654414
Validation loss: 2.5151091968904487

Epoch: 6| Step: 1
Training loss: 1.6259998033483558
Validation loss: 2.529568620024344

Epoch: 6| Step: 2
Training loss: 2.7555172800495837
Validation loss: 2.5459741664793474

Epoch: 6| Step: 3
Training loss: 2.6165369848038993
Validation loss: 2.558358637366723

Epoch: 6| Step: 4
Training loss: 2.91132248417666
Validation loss: 2.575513191070378

Epoch: 6| Step: 5
Training loss: 2.9469926731729186
Validation loss: 2.5543803303532826

Epoch: 6| Step: 6
Training loss: 2.2542576243252705
Validation loss: 2.534159099321274

Epoch: 6| Step: 7
Training loss: 3.12010969898358
Validation loss: 2.527077945369083

Epoch: 6| Step: 8
Training loss: 2.1556085931779037
Validation loss: 2.541786290047989

Epoch: 6| Step: 9
Training loss: 2.747588747793591
Validation loss: 2.5278256490969593

Epoch: 6| Step: 10
Training loss: 1.981922827233475
Validation loss: 2.5080843388949527

Epoch: 6| Step: 11
Training loss: 2.168110390924855
Validation loss: 2.5108197206553795

Epoch: 6| Step: 12
Training loss: 1.7775567566385297
Validation loss: 2.4940196590219803

Epoch: 6| Step: 13
Training loss: 2.1468675460574977
Validation loss: 2.5036685253490742

Epoch: 208| Step: 0
Training loss: 1.998107252951982
Validation loss: 2.4966959736746026

Epoch: 6| Step: 1
Training loss: 2.116835448777185
Validation loss: 2.4964619873838485

Epoch: 6| Step: 2
Training loss: 2.7175923656218264
Validation loss: 2.489201190514525

Epoch: 6| Step: 3
Training loss: 2.2844524114723823
Validation loss: 2.5055362119395546

Epoch: 6| Step: 4
Training loss: 1.861477088371223
Validation loss: 2.505715877223106

Epoch: 6| Step: 5
Training loss: 2.0466016048109354
Validation loss: 2.516850648769624

Epoch: 6| Step: 6
Training loss: 2.729084935796611
Validation loss: 2.5207399923735103

Epoch: 6| Step: 7
Training loss: 2.517637880976004
Validation loss: 2.511954376100484

Epoch: 6| Step: 8
Training loss: 2.043025116297882
Validation loss: 2.516300213472732

Epoch: 6| Step: 9
Training loss: 2.6341786448290736
Validation loss: 2.5187651502028983

Epoch: 6| Step: 10
Training loss: 2.249060328616236
Validation loss: 2.5159224182341475

Epoch: 6| Step: 11
Training loss: 2.799001386221665
Validation loss: 2.523566007540573

Epoch: 6| Step: 12
Training loss: 2.539809929802367
Validation loss: 2.5412853350968394

Epoch: 6| Step: 13
Training loss: 2.614991499411076
Validation loss: 2.537609212620405

Epoch: 209| Step: 0
Training loss: 2.641606977813303
Validation loss: 2.533928446973094

Epoch: 6| Step: 1
Training loss: 2.26176460496343
Validation loss: 2.522460433402647

Epoch: 6| Step: 2
Training loss: 1.7670341877158575
Validation loss: 2.5148414908070413

Epoch: 6| Step: 3
Training loss: 2.740438484970021
Validation loss: 2.504578197217807

Epoch: 6| Step: 4
Training loss: 2.0450377627292777
Validation loss: 2.5062724580971456

Epoch: 6| Step: 5
Training loss: 1.7911914668399151
Validation loss: 2.4809238526968023

Epoch: 6| Step: 6
Training loss: 2.6151855099523713
Validation loss: 2.4905764036969797

Epoch: 6| Step: 7
Training loss: 2.658047774552173
Validation loss: 2.4721910100269118

Epoch: 6| Step: 8
Training loss: 2.214997462837368
Validation loss: 2.4875565555986743

Epoch: 6| Step: 9
Training loss: 2.8739197401548227
Validation loss: 2.4871504852778097

Epoch: 6| Step: 10
Training loss: 2.7720457211531655
Validation loss: 2.484577410627598

Epoch: 6| Step: 11
Training loss: 1.3484381577367492
Validation loss: 2.477519014082183

Epoch: 6| Step: 12
Training loss: 2.5771066214872027
Validation loss: 2.4849284293385465

Epoch: 6| Step: 13
Training loss: 2.2408918830974818
Validation loss: 2.486655550101781

Epoch: 210| Step: 0
Training loss: 1.8840398942809538
Validation loss: 2.480559756394214

Epoch: 6| Step: 1
Training loss: 2.4776393342317253
Validation loss: 2.481540222234503

Epoch: 6| Step: 2
Training loss: 2.8678212310002995
Validation loss: 2.4636145023818625

Epoch: 6| Step: 3
Training loss: 2.4757529298336856
Validation loss: 2.477816628202381

Epoch: 6| Step: 4
Training loss: 2.5123388969430978
Validation loss: 2.4661986692113422

Epoch: 6| Step: 5
Training loss: 2.669409791384301
Validation loss: 2.4799133479966966

Epoch: 6| Step: 6
Training loss: 1.5656832503334626
Validation loss: 2.475738925959276

Epoch: 6| Step: 7
Training loss: 2.0329215581258713
Validation loss: 2.4870591928012717

Epoch: 6| Step: 8
Training loss: 2.243585449815491
Validation loss: 2.4902589165967983

Epoch: 6| Step: 9
Training loss: 2.4148889997100094
Validation loss: 2.491535288771664

Epoch: 6| Step: 10
Training loss: 2.380507858651195
Validation loss: 2.4988313884116478

Epoch: 6| Step: 11
Training loss: 3.0630228024542183
Validation loss: 2.5032157719568464

Epoch: 6| Step: 12
Training loss: 2.47424853312686
Validation loss: 2.5011695669174365

Epoch: 6| Step: 13
Training loss: 1.6938748218670563
Validation loss: 2.5086666090657173

Epoch: 211| Step: 0
Training loss: 2.0193922928424177
Validation loss: 2.5021549156382425

Epoch: 6| Step: 1
Training loss: 3.003175644144871
Validation loss: 2.50282877781773

Epoch: 6| Step: 2
Training loss: 2.822816450491474
Validation loss: 2.4966014650164072

Epoch: 6| Step: 3
Training loss: 1.796090128771768
Validation loss: 2.499964785327852

Epoch: 6| Step: 4
Training loss: 2.046845414042501
Validation loss: 2.5035428533820827

Epoch: 6| Step: 5
Training loss: 2.577240855882456
Validation loss: 2.499313538401291

Epoch: 6| Step: 6
Training loss: 2.1559325274736216
Validation loss: 2.5132610120621552

Epoch: 6| Step: 7
Training loss: 2.7137014936261483
Validation loss: 2.5145792712726878

Epoch: 6| Step: 8
Training loss: 2.5698646224765316
Validation loss: 2.533792733483074

Epoch: 6| Step: 9
Training loss: 1.9635516975072413
Validation loss: 2.5334180330455776

Epoch: 6| Step: 10
Training loss: 2.27480534569649
Validation loss: 2.5117761616253578

Epoch: 6| Step: 11
Training loss: 2.6841019728060154
Validation loss: 2.514166177967274

Epoch: 6| Step: 12
Training loss: 2.067669487755648
Validation loss: 2.49509249461597

Epoch: 6| Step: 13
Training loss: 2.2906490725388187
Validation loss: 2.494437641888778

Epoch: 212| Step: 0
Training loss: 2.9911291576418617
Validation loss: 2.495377240249822

Epoch: 6| Step: 1
Training loss: 2.1149325027697627
Validation loss: 2.49355523377423

Epoch: 6| Step: 2
Training loss: 2.693097605996408
Validation loss: 2.4951846636801176

Epoch: 6| Step: 3
Training loss: 2.310916564722774
Validation loss: 2.5008648965740514

Epoch: 6| Step: 4
Training loss: 2.187933742573035
Validation loss: 2.502678961666569

Epoch: 6| Step: 5
Training loss: 1.9730971042037408
Validation loss: 2.507900787098744

Epoch: 6| Step: 6
Training loss: 3.312375048314028
Validation loss: 2.5116825842737946

Epoch: 6| Step: 7
Training loss: 2.2652387618647167
Validation loss: 2.5023137035505294

Epoch: 6| Step: 8
Training loss: 2.633039425089322
Validation loss: 2.497778143606502

Epoch: 6| Step: 9
Training loss: 2.2606794377428114
Validation loss: 2.4949120722778644

Epoch: 6| Step: 10
Training loss: 2.2663623530736845
Validation loss: 2.499932176941538

Epoch: 6| Step: 11
Training loss: 1.772624968197675
Validation loss: 2.4936347036072024

Epoch: 6| Step: 12
Training loss: 2.1821885065597844
Validation loss: 2.495221219814769

Epoch: 6| Step: 13
Training loss: 2.3178346292324736
Validation loss: 2.5009940316969086

Epoch: 213| Step: 0
Training loss: 2.9852549269299877
Validation loss: 2.5130658450402716

Epoch: 6| Step: 1
Training loss: 2.3053114224318003
Validation loss: 2.537729063797808

Epoch: 6| Step: 2
Training loss: 2.738603211111934
Validation loss: 2.5253281414723157

Epoch: 6| Step: 3
Training loss: 1.9171144404710296
Validation loss: 2.523517170407189

Epoch: 6| Step: 4
Training loss: 2.4944732611487215
Validation loss: 2.5172735305693092

Epoch: 6| Step: 5
Training loss: 2.857167877360192
Validation loss: 2.510310314558526

Epoch: 6| Step: 6
Training loss: 1.7071281772217208
Validation loss: 2.5118718394784567

Epoch: 6| Step: 7
Training loss: 1.940799672102527
Validation loss: 2.5145473185828036

Epoch: 6| Step: 8
Training loss: 2.3630840124627976
Validation loss: 2.521756993415892

Epoch: 6| Step: 9
Training loss: 2.127383970510119
Validation loss: 2.5086452016718903

Epoch: 6| Step: 10
Training loss: 1.940348838039503
Validation loss: 2.495682819351716

Epoch: 6| Step: 11
Training loss: 2.4826578407779474
Validation loss: 2.504481495020262

Epoch: 6| Step: 12
Training loss: 2.425452070276537
Validation loss: 2.4920208993870157

Epoch: 6| Step: 13
Training loss: 2.4543012969605438
Validation loss: 2.4896631799978968

Epoch: 214| Step: 0
Training loss: 2.187447901514086
Validation loss: 2.4721341257317335

Epoch: 6| Step: 1
Training loss: 1.8394439327636507
Validation loss: 2.487065471862608

Epoch: 6| Step: 2
Training loss: 2.6218160665842887
Validation loss: 2.473889204699105

Epoch: 6| Step: 3
Training loss: 2.0205769589273856
Validation loss: 2.475341495882989

Epoch: 6| Step: 4
Training loss: 1.712917488609543
Validation loss: 2.4736522819876314

Epoch: 6| Step: 5
Training loss: 2.019592402286786
Validation loss: 2.4679267895029535

Epoch: 6| Step: 6
Training loss: 2.3286932949302335
Validation loss: 2.4844562029413395

Epoch: 6| Step: 7
Training loss: 1.8928257767374004
Validation loss: 2.4886473062564205

Epoch: 6| Step: 8
Training loss: 2.3386461762748927
Validation loss: 2.4726774948999286

Epoch: 6| Step: 9
Training loss: 2.480575439081055
Validation loss: 2.4710935100788873

Epoch: 6| Step: 10
Training loss: 2.5976707515455186
Validation loss: 2.4779705934337075

Epoch: 6| Step: 11
Training loss: 2.4665911929294464
Validation loss: 2.480830425016855

Epoch: 6| Step: 12
Training loss: 3.1506995317496838
Validation loss: 2.5058053640926006

Epoch: 6| Step: 13
Training loss: 2.6648023366715727
Validation loss: 2.506339855913977

Epoch: 215| Step: 0
Training loss: 1.9643660888081362
Validation loss: 2.4993912273521546

Epoch: 6| Step: 1
Training loss: 2.5371230009798165
Validation loss: 2.525200604820169

Epoch: 6| Step: 2
Training loss: 2.2525501634302247
Validation loss: 2.5147958182690733

Epoch: 6| Step: 3
Training loss: 1.7608761009201495
Validation loss: 2.509456947036904

Epoch: 6| Step: 4
Training loss: 2.014953264778298
Validation loss: 2.495231602901508

Epoch: 6| Step: 5
Training loss: 2.4802751600759825
Validation loss: 2.4884313740699397

Epoch: 6| Step: 6
Training loss: 2.104558574576446
Validation loss: 2.5076990151401892

Epoch: 6| Step: 7
Training loss: 2.1239215133591136
Validation loss: 2.5157155085802296

Epoch: 6| Step: 8
Training loss: 1.705445554805334
Validation loss: 2.507399734008674

Epoch: 6| Step: 9
Training loss: 2.728427369445512
Validation loss: 2.5202314167889672

Epoch: 6| Step: 10
Training loss: 2.684840372266933
Validation loss: 2.5155021526914085

Epoch: 6| Step: 11
Training loss: 2.6544684325881396
Validation loss: 2.5366870743042993

Epoch: 6| Step: 12
Training loss: 3.1339066799270223
Validation loss: 2.5214722719500386

Epoch: 6| Step: 13
Training loss: 2.3314835050499645
Validation loss: 2.5278221121825464

Epoch: 216| Step: 0
Training loss: 1.8555414767819407
Validation loss: 2.518436984797288

Epoch: 6| Step: 1
Training loss: 2.226680926469534
Validation loss: 2.50731375895457

Epoch: 6| Step: 2
Training loss: 2.025976289480484
Validation loss: 2.5040536917423597

Epoch: 6| Step: 3
Training loss: 2.038702337384981
Validation loss: 2.5073179428779784

Epoch: 6| Step: 4
Training loss: 2.6801477153835447
Validation loss: 2.5040132734781744

Epoch: 6| Step: 5
Training loss: 2.683529959951905
Validation loss: 2.5078013767459217

Epoch: 6| Step: 6
Training loss: 2.3596791456617976
Validation loss: 2.5042773292662153

Epoch: 6| Step: 7
Training loss: 2.7945762009987267
Validation loss: 2.495180363859964

Epoch: 6| Step: 8
Training loss: 2.763639265211763
Validation loss: 2.518962880770599

Epoch: 6| Step: 9
Training loss: 1.779228870754681
Validation loss: 2.515195805995986

Epoch: 6| Step: 10
Training loss: 2.7579834968786843
Validation loss: 2.512890705962743

Epoch: 6| Step: 11
Training loss: 2.6136842881584808
Validation loss: 2.52272039249012

Epoch: 6| Step: 12
Training loss: 2.054496030987944
Validation loss: 2.533179399452291

Epoch: 6| Step: 13
Training loss: 1.8335463515706807
Validation loss: 2.530506684224169

Epoch: 217| Step: 0
Training loss: 2.6484349793728788
Validation loss: 2.5390943711065623

Epoch: 6| Step: 1
Training loss: 2.0696245309983894
Validation loss: 2.549673465939961

Epoch: 6| Step: 2
Training loss: 1.9422475423454835
Validation loss: 2.518170318915287

Epoch: 6| Step: 3
Training loss: 2.3737276584242784
Validation loss: 2.5145387535494477

Epoch: 6| Step: 4
Training loss: 2.4168202471986384
Validation loss: 2.5092632181710637

Epoch: 6| Step: 5
Training loss: 2.89642148711652
Validation loss: 2.4970301312955963

Epoch: 6| Step: 6
Training loss: 2.5311612714121896
Validation loss: 2.502894553737798

Epoch: 6| Step: 7
Training loss: 1.8032803685042604
Validation loss: 2.4915252172281135

Epoch: 6| Step: 8
Training loss: 1.8992093875706026
Validation loss: 2.5034550951193864

Epoch: 6| Step: 9
Training loss: 1.9916136868930743
Validation loss: 2.5011125632112905

Epoch: 6| Step: 10
Training loss: 1.716626884715524
Validation loss: 2.508758588293733

Epoch: 6| Step: 11
Training loss: 2.7557855781390983
Validation loss: 2.507608819377069

Epoch: 6| Step: 12
Training loss: 2.868476266205233
Validation loss: 2.512700135846234

Epoch: 6| Step: 13
Training loss: 2.2514618257441548
Validation loss: 2.4953750268104633

Epoch: 218| Step: 0
Training loss: 2.7391617212424
Validation loss: 2.504116182458402

Epoch: 6| Step: 1
Training loss: 2.067253991727842
Validation loss: 2.48996339607655

Epoch: 6| Step: 2
Training loss: 1.7829712699248526
Validation loss: 2.483548744724264

Epoch: 6| Step: 3
Training loss: 2.2666386934499037
Validation loss: 2.489774837603534

Epoch: 6| Step: 4
Training loss: 2.342175170784553
Validation loss: 2.490294938691125

Epoch: 6| Step: 5
Training loss: 2.463283909760844
Validation loss: 2.511977273896957

Epoch: 6| Step: 6
Training loss: 2.593981261456998
Validation loss: 2.495754523351805

Epoch: 6| Step: 7
Training loss: 2.878297324722023
Validation loss: 2.4855405284739214

Epoch: 6| Step: 8
Training loss: 1.8151474395220266
Validation loss: 2.5078433025999667

Epoch: 6| Step: 9
Training loss: 1.9205557163998503
Validation loss: 2.499642600897675

Epoch: 6| Step: 10
Training loss: 2.5417440955036343
Validation loss: 2.4953550739195647

Epoch: 6| Step: 11
Training loss: 2.682896063896783
Validation loss: 2.499649372944279

Epoch: 6| Step: 12
Training loss: 2.3379035764509157
Validation loss: 2.514391974052795

Epoch: 6| Step: 13
Training loss: 1.7319977422836073
Validation loss: 2.490106142021076

Epoch: 219| Step: 0
Training loss: 1.7773674931879069
Validation loss: 2.495248634573693

Epoch: 6| Step: 1
Training loss: 2.248828264945117
Validation loss: 2.4985033959785587

Epoch: 6| Step: 2
Training loss: 2.9159603535242375
Validation loss: 2.5042401595499744

Epoch: 6| Step: 3
Training loss: 1.9212481709299707
Validation loss: 2.521165216420246

Epoch: 6| Step: 4
Training loss: 2.1030844243799
Validation loss: 2.5044778140753166

Epoch: 6| Step: 5
Training loss: 2.1467683723990034
Validation loss: 2.507423949123162

Epoch: 6| Step: 6
Training loss: 2.44224555885582
Validation loss: 2.518660489015019

Epoch: 6| Step: 7
Training loss: 2.3745245206606627
Validation loss: 2.5029714171321595

Epoch: 6| Step: 8
Training loss: 1.8443893358635846
Validation loss: 2.51554601162254

Epoch: 6| Step: 9
Training loss: 2.6737057843861507
Validation loss: 2.5021370336999125

Epoch: 6| Step: 10
Training loss: 2.943039560947118
Validation loss: 2.506910397541154

Epoch: 6| Step: 11
Training loss: 1.6605699450088953
Validation loss: 2.5149347373174726

Epoch: 6| Step: 12
Training loss: 2.7359821936825446
Validation loss: 2.50532752458685

Epoch: 6| Step: 13
Training loss: 2.1803258692564014
Validation loss: 2.5130022960763165

Epoch: 220| Step: 0
Training loss: 1.87603839095227
Validation loss: 2.5152932653214197

Epoch: 6| Step: 1
Training loss: 2.3975500397139013
Validation loss: 2.496405178615091

Epoch: 6| Step: 2
Training loss: 2.638231083938308
Validation loss: 2.5138483190570575

Epoch: 6| Step: 3
Training loss: 2.6132995878525604
Validation loss: 2.513446093271899

Epoch: 6| Step: 4
Training loss: 2.5048194207987424
Validation loss: 2.5155733312509336

Epoch: 6| Step: 5
Training loss: 2.24694128880451
Validation loss: 2.526773741255817

Epoch: 6| Step: 6
Training loss: 2.291448293743053
Validation loss: 2.5726842324806447

Epoch: 6| Step: 7
Training loss: 2.4680644181931464
Validation loss: 2.5932166841973587

Epoch: 6| Step: 8
Training loss: 2.222349658596936
Validation loss: 2.5775562930689233

Epoch: 6| Step: 9
Training loss: 2.1516688235405304
Validation loss: 2.5621802898165487

Epoch: 6| Step: 10
Training loss: 2.5259586176378264
Validation loss: 2.5291010836080035

Epoch: 6| Step: 11
Training loss: 2.531040135855519
Validation loss: 2.5075296022563753

Epoch: 6| Step: 12
Training loss: 2.2080456048429813
Validation loss: 2.4910762306319447

Epoch: 6| Step: 13
Training loss: 2.161020282034112
Validation loss: 2.483894365630225

Epoch: 221| Step: 0
Training loss: 2.1665329036014422
Validation loss: 2.5047902784798723

Epoch: 6| Step: 1
Training loss: 3.0054067527459045
Validation loss: 2.509165825524301

Epoch: 6| Step: 2
Training loss: 2.171067231720865
Validation loss: 2.5059004136310556

Epoch: 6| Step: 3
Training loss: 2.3802293126846275
Validation loss: 2.499013348432704

Epoch: 6| Step: 4
Training loss: 2.4502863891751616
Validation loss: 2.500320406091014

Epoch: 6| Step: 5
Training loss: 2.733693762795152
Validation loss: 2.487361975695206

Epoch: 6| Step: 6
Training loss: 2.848959040016956
Validation loss: 2.4911814286256195

Epoch: 6| Step: 7
Training loss: 1.9464941151233828
Validation loss: 2.5002571450547033

Epoch: 6| Step: 8
Training loss: 1.9053883715854036
Validation loss: 2.4732524520659815

Epoch: 6| Step: 9
Training loss: 2.2541449831932123
Validation loss: 2.49220774930343

Epoch: 6| Step: 10
Training loss: 1.966859060779883
Validation loss: 2.488713983887953

Epoch: 6| Step: 11
Training loss: 2.373620485907679
Validation loss: 2.4821735120777237

Epoch: 6| Step: 12
Training loss: 2.5625952726191468
Validation loss: 2.502639061045765

Epoch: 6| Step: 13
Training loss: 1.9260363922404526
Validation loss: 2.515866522715917

Epoch: 222| Step: 0
Training loss: 2.715211165560422
Validation loss: 2.505904330343168

Epoch: 6| Step: 1
Training loss: 1.516789726183498
Validation loss: 2.529780993776935

Epoch: 6| Step: 2
Training loss: 2.3880553553313946
Validation loss: 2.544719556259663

Epoch: 6| Step: 3
Training loss: 2.5716793982470216
Validation loss: 2.53577782642775

Epoch: 6| Step: 4
Training loss: 1.8391584995205397
Validation loss: 2.514748888694517

Epoch: 6| Step: 5
Training loss: 2.354299783459606
Validation loss: 2.5144910132257094

Epoch: 6| Step: 6
Training loss: 2.3229916707290648
Validation loss: 2.5109614866638545

Epoch: 6| Step: 7
Training loss: 2.0936192713677393
Validation loss: 2.507156523953342

Epoch: 6| Step: 8
Training loss: 2.470272415675588
Validation loss: 2.5109533050299224

Epoch: 6| Step: 9
Training loss: 2.3301482146114405
Validation loss: 2.523739232781442

Epoch: 6| Step: 10
Training loss: 2.3883450675227103
Validation loss: 2.530434025613267

Epoch: 6| Step: 11
Training loss: 2.4938112906283387
Validation loss: 2.5195159675075516

Epoch: 6| Step: 12
Training loss: 2.3533531291154293
Validation loss: 2.520105561639035

Epoch: 6| Step: 13
Training loss: 2.8336712317841863
Validation loss: 2.5222213066153563

Epoch: 223| Step: 0
Training loss: 1.9932715365017757
Validation loss: 2.527191361909075

Epoch: 6| Step: 1
Training loss: 2.4372485104449773
Validation loss: 2.535479265901431

Epoch: 6| Step: 2
Training loss: 2.3366600118516017
Validation loss: 2.5233487329134907

Epoch: 6| Step: 3
Training loss: 1.8821297828404278
Validation loss: 2.539135365540998

Epoch: 6| Step: 4
Training loss: 1.9617041802634354
Validation loss: 2.582988105799707

Epoch: 6| Step: 5
Training loss: 2.456064589008371
Validation loss: 2.5380886068571034

Epoch: 6| Step: 6
Training loss: 2.1872227084294664
Validation loss: 2.5448470749966727

Epoch: 6| Step: 7
Training loss: 1.7916935393809534
Validation loss: 2.4995750463439173

Epoch: 6| Step: 8
Training loss: 2.076640007231636
Validation loss: 2.51014656312769

Epoch: 6| Step: 9
Training loss: 2.9864223308187166
Validation loss: 2.4954365246612635

Epoch: 6| Step: 10
Training loss: 2.8576758500638393
Validation loss: 2.4963462355644443

Epoch: 6| Step: 11
Training loss: 2.887638012779074
Validation loss: 2.4903567933553745

Epoch: 6| Step: 12
Training loss: 2.6653355216544807
Validation loss: 2.4978726872848314

Epoch: 6| Step: 13
Training loss: 2.0149033311699998
Validation loss: 2.5047628809008198

Epoch: 224| Step: 0
Training loss: 2.1990004002534747
Validation loss: 2.497785755912967

Epoch: 6| Step: 1
Training loss: 2.6621244210414865
Validation loss: 2.500101866236218

Epoch: 6| Step: 2
Training loss: 2.335881159176323
Validation loss: 2.492567063369681

Epoch: 6| Step: 3
Training loss: 2.154163290743024
Validation loss: 2.4826600015330897

Epoch: 6| Step: 4
Training loss: 2.4285574980744964
Validation loss: 2.5094041299297025

Epoch: 6| Step: 5
Training loss: 2.595767787475247
Validation loss: 2.5032937922023732

Epoch: 6| Step: 6
Training loss: 1.9164374117644565
Validation loss: 2.51986083405839

Epoch: 6| Step: 7
Training loss: 2.1831471322524307
Validation loss: 2.4910851475106246

Epoch: 6| Step: 8
Training loss: 2.6354244870357557
Validation loss: 2.5015040879872856

Epoch: 6| Step: 9
Training loss: 1.7411253560975304
Validation loss: 2.51339634015296

Epoch: 6| Step: 10
Training loss: 1.8275466395322246
Validation loss: 2.4937945120526903

Epoch: 6| Step: 11
Training loss: 2.347072027192621
Validation loss: 2.4935167409083596

Epoch: 6| Step: 12
Training loss: 3.070923567282538
Validation loss: 2.4880819435485844

Epoch: 6| Step: 13
Training loss: 2.3675176308447714
Validation loss: 2.485474285300947

Epoch: 225| Step: 0
Training loss: 2.221935939892032
Validation loss: 2.4854238763167977

Epoch: 6| Step: 1
Training loss: 2.856863617875403
Validation loss: 2.4878544623574315

Epoch: 6| Step: 2
Training loss: 2.6788246834330747
Validation loss: 2.4964245819235593

Epoch: 6| Step: 3
Training loss: 2.2723515069872824
Validation loss: 2.481119033598486

Epoch: 6| Step: 4
Training loss: 2.237120109147353
Validation loss: 2.49500524340673

Epoch: 6| Step: 5
Training loss: 2.377079103841092
Validation loss: 2.492415701723359

Epoch: 6| Step: 6
Training loss: 2.462213772632241
Validation loss: 2.494278766786474

Epoch: 6| Step: 7
Training loss: 1.9789942080666945
Validation loss: 2.5020383154773427

Epoch: 6| Step: 8
Training loss: 2.213978754908244
Validation loss: 2.5115472033955144

Epoch: 6| Step: 9
Training loss: 2.338074794006942
Validation loss: 2.5071074067956474

Epoch: 6| Step: 10
Training loss: 2.218612129333567
Validation loss: 2.523542309484907

Epoch: 6| Step: 11
Training loss: 2.152328352691353
Validation loss: 2.548068104504005

Epoch: 6| Step: 12
Training loss: 2.1146043171961137
Validation loss: 2.563666287621997

Epoch: 6| Step: 13
Training loss: 2.0867673673289797
Validation loss: 2.5777743014315844

Epoch: 226| Step: 0
Training loss: 1.3535940964975874
Validation loss: 2.5784765292866076

Epoch: 6| Step: 1
Training loss: 2.3418424854816005
Validation loss: 2.606014288009467

Epoch: 6| Step: 2
Training loss: 2.4113268119478444
Validation loss: 2.6069446903346747

Epoch: 6| Step: 3
Training loss: 2.266215385597688
Validation loss: 2.5812874404125425

Epoch: 6| Step: 4
Training loss: 2.133430363514778
Validation loss: 2.5502821242649483

Epoch: 6| Step: 5
Training loss: 2.6145058629285187
Validation loss: 2.5168499698788382

Epoch: 6| Step: 6
Training loss: 2.558690845307012
Validation loss: 2.5097811885207695

Epoch: 6| Step: 7
Training loss: 2.3722843907488875
Validation loss: 2.5136646506781952

Epoch: 6| Step: 8
Training loss: 2.3421058482773387
Validation loss: 2.5110285529018914

Epoch: 6| Step: 9
Training loss: 2.667554250664233
Validation loss: 2.5072527505358284

Epoch: 6| Step: 10
Training loss: 2.566114342286405
Validation loss: 2.504329318340848

Epoch: 6| Step: 11
Training loss: 2.8711734682810333
Validation loss: 2.5079537230090114

Epoch: 6| Step: 12
Training loss: 2.206875469820269
Validation loss: 2.514414462466454

Epoch: 6| Step: 13
Training loss: 2.5685098466199885
Validation loss: 2.5025012378518077

Epoch: 227| Step: 0
Training loss: 2.544040155381755
Validation loss: 2.5057682566876673

Epoch: 6| Step: 1
Training loss: 2.5143945184301377
Validation loss: 2.507394797456311

Epoch: 6| Step: 2
Training loss: 1.9738989211294944
Validation loss: 2.5212520115065287

Epoch: 6| Step: 3
Training loss: 1.8965086380479983
Validation loss: 2.546638196924197

Epoch: 6| Step: 4
Training loss: 2.4085844531577387
Validation loss: 2.53711112915323

Epoch: 6| Step: 5
Training loss: 2.4885529709616847
Validation loss: 2.537967449659873

Epoch: 6| Step: 6
Training loss: 3.311303408441508
Validation loss: 2.54665602384294

Epoch: 6| Step: 7
Training loss: 1.7897381568641537
Validation loss: 2.549572941292958

Epoch: 6| Step: 8
Training loss: 2.3122137768919266
Validation loss: 2.5688096960700326

Epoch: 6| Step: 9
Training loss: 1.716809095875161
Validation loss: 2.5651114113539166

Epoch: 6| Step: 10
Training loss: 2.490495352439932
Validation loss: 2.558677505015321

Epoch: 6| Step: 11
Training loss: 2.277858564706796
Validation loss: 2.530721789847362

Epoch: 6| Step: 12
Training loss: 2.6171020493862778
Validation loss: 2.506902638583143

Epoch: 6| Step: 13
Training loss: 2.226263836020345
Validation loss: 2.490892302920203

Epoch: 228| Step: 0
Training loss: 2.0233960239475026
Validation loss: 2.494974935299965

Epoch: 6| Step: 1
Training loss: 2.4796591090672475
Validation loss: 2.4903637342575546

Epoch: 6| Step: 2
Training loss: 2.9268547502819553
Validation loss: 2.501419967476185

Epoch: 6| Step: 3
Training loss: 1.930258106702311
Validation loss: 2.5003829662728356

Epoch: 6| Step: 4
Training loss: 2.997414110240125
Validation loss: 2.5126115271264635

Epoch: 6| Step: 5
Training loss: 2.1727999906098896
Validation loss: 2.5035691691506914

Epoch: 6| Step: 6
Training loss: 1.9534986214907497
Validation loss: 2.5155379159832734

Epoch: 6| Step: 7
Training loss: 2.4194729614134443
Validation loss: 2.497846629667113

Epoch: 6| Step: 8
Training loss: 2.62089053416537
Validation loss: 2.4972732614636843

Epoch: 6| Step: 9
Training loss: 2.7862399482117888
Validation loss: 2.48890346889918

Epoch: 6| Step: 10
Training loss: 2.162316675077985
Validation loss: 2.479700789629317

Epoch: 6| Step: 11
Training loss: 2.151077036224292
Validation loss: 2.4722356212505274

Epoch: 6| Step: 12
Training loss: 1.9007180413124933
Validation loss: 2.4734250481027624

Epoch: 6| Step: 13
Training loss: 2.5217594200601994
Validation loss: 2.4810927519788364

Epoch: 229| Step: 0
Training loss: 2.327060123101318
Validation loss: 2.5079585871626127

Epoch: 6| Step: 1
Training loss: 2.297746661604962
Validation loss: 2.518412275997829

Epoch: 6| Step: 2
Training loss: 2.3434474495476754
Validation loss: 2.5475714107808147

Epoch: 6| Step: 3
Training loss: 2.0557259955783223
Validation loss: 2.536223067091589

Epoch: 6| Step: 4
Training loss: 3.023910603730783
Validation loss: 2.520304968661655

Epoch: 6| Step: 5
Training loss: 2.739544847650799
Validation loss: 2.5083117121866163

Epoch: 6| Step: 6
Training loss: 1.8897462804732221
Validation loss: 2.5081523692689975

Epoch: 6| Step: 7
Training loss: 2.2725215784103834
Validation loss: 2.485061182871796

Epoch: 6| Step: 8
Training loss: 2.1409892865144102
Validation loss: 2.485928319773816

Epoch: 6| Step: 9
Training loss: 2.7011681678729986
Validation loss: 2.4862641803023173

Epoch: 6| Step: 10
Training loss: 2.424283804775128
Validation loss: 2.488677451920287

Epoch: 6| Step: 11
Training loss: 2.031998716429057
Validation loss: 2.4886586268901696

Epoch: 6| Step: 12
Training loss: 2.1492935971893057
Validation loss: 2.5069820023174567

Epoch: 6| Step: 13
Training loss: 1.7997596474288402
Validation loss: 2.4988122184707904

Epoch: 230| Step: 0
Training loss: 1.8216820668683198
Validation loss: 2.51027395441617

Epoch: 6| Step: 1
Training loss: 2.0687460677463925
Validation loss: 2.502243513516798

Epoch: 6| Step: 2
Training loss: 3.1104817170079655
Validation loss: 2.508229839897776

Epoch: 6| Step: 3
Training loss: 2.4353473645855632
Validation loss: 2.506622079451006

Epoch: 6| Step: 4
Training loss: 1.9716015101630753
Validation loss: 2.517863428854576

Epoch: 6| Step: 5
Training loss: 2.542826705692286
Validation loss: 2.5068655474204085

Epoch: 6| Step: 6
Training loss: 2.4203486401080427
Validation loss: 2.513617605133817

Epoch: 6| Step: 7
Training loss: 2.644325327216231
Validation loss: 2.5092798141345596

Epoch: 6| Step: 8
Training loss: 2.232860558795469
Validation loss: 2.5494166760421626

Epoch: 6| Step: 9
Training loss: 2.423199100930723
Validation loss: 2.5694902954363683

Epoch: 6| Step: 10
Training loss: 1.9646899426667914
Validation loss: 2.5654406228453808

Epoch: 6| Step: 11
Training loss: 2.7460168255250905
Validation loss: 2.570689319634776

Epoch: 6| Step: 12
Training loss: 1.8435311268350587
Validation loss: 2.5537868082459485

Epoch: 6| Step: 13
Training loss: 2.2270855205680973
Validation loss: 2.529726158445179

Epoch: 231| Step: 0
Training loss: 2.1693294619498538
Validation loss: 2.5283479891632856

Epoch: 6| Step: 1
Training loss: 1.8322270335526325
Validation loss: 2.5132086701763643

Epoch: 6| Step: 2
Training loss: 2.424718553393648
Validation loss: 2.534970402579293

Epoch: 6| Step: 3
Training loss: 1.8861767481995446
Validation loss: 2.5210939593138213

Epoch: 6| Step: 4
Training loss: 2.574646423656682
Validation loss: 2.5067170266873884

Epoch: 6| Step: 5
Training loss: 2.0250850141599477
Validation loss: 2.511173376949617

Epoch: 6| Step: 6
Training loss: 1.9548337252023449
Validation loss: 2.5105458037743746

Epoch: 6| Step: 7
Training loss: 3.000475368984117
Validation loss: 2.503166196486495

Epoch: 6| Step: 8
Training loss: 1.826577730009284
Validation loss: 2.502151842685465

Epoch: 6| Step: 9
Training loss: 2.4377001166726155
Validation loss: 2.5033922148847374

Epoch: 6| Step: 10
Training loss: 2.4212236082167893
Validation loss: 2.4966649062180606

Epoch: 6| Step: 11
Training loss: 2.0964747676554603
Validation loss: 2.506397343186465

Epoch: 6| Step: 12
Training loss: 2.4195059726024115
Validation loss: 2.4859417947076303

Epoch: 6| Step: 13
Training loss: 2.8136610389722185
Validation loss: 2.4759038295957665

Epoch: 232| Step: 0
Training loss: 2.5205278658152293
Validation loss: 2.486439165271335

Epoch: 6| Step: 1
Training loss: 2.887165700873741
Validation loss: 2.4911054217260076

Epoch: 6| Step: 2
Training loss: 3.0387482076095886
Validation loss: 2.4938683257876066

Epoch: 6| Step: 3
Training loss: 1.9388701608634462
Validation loss: 2.4781848876182018

Epoch: 6| Step: 4
Training loss: 1.9919650682925465
Validation loss: 2.4898308081640153

Epoch: 6| Step: 5
Training loss: 2.77687895114093
Validation loss: 2.4760970712212873

Epoch: 6| Step: 6
Training loss: 2.0666987134643278
Validation loss: 2.488337030589003

Epoch: 6| Step: 7
Training loss: 1.7488090686215696
Validation loss: 2.498050979002444

Epoch: 6| Step: 8
Training loss: 2.32025372466068
Validation loss: 2.46283312253204

Epoch: 6| Step: 9
Training loss: 1.8242894553096969
Validation loss: 2.4745783514111954

Epoch: 6| Step: 10
Training loss: 2.1727958209142257
Validation loss: 2.4849497452175804

Epoch: 6| Step: 11
Training loss: 1.9622106180835555
Validation loss: 2.4866894351830475

Epoch: 6| Step: 12
Training loss: 2.138773765052913
Validation loss: 2.4973408544148463

Epoch: 6| Step: 13
Training loss: 2.5650984452598524
Validation loss: 2.492702243625861

Epoch: 233| Step: 0
Training loss: 1.923242656095232
Validation loss: 2.5045813861848454

Epoch: 6| Step: 1
Training loss: 1.7719594703198425
Validation loss: 2.52893729974028

Epoch: 6| Step: 2
Training loss: 2.091153940934885
Validation loss: 2.5060449156403295

Epoch: 6| Step: 3
Training loss: 2.030939753387793
Validation loss: 2.5172176176953425

Epoch: 6| Step: 4
Training loss: 1.720161136132029
Validation loss: 2.5172946514842387

Epoch: 6| Step: 5
Training loss: 2.720983267640494
Validation loss: 2.4928422504250345

Epoch: 6| Step: 6
Training loss: 2.5405664303493074
Validation loss: 2.5177807781848425

Epoch: 6| Step: 7
Training loss: 2.8081336990924703
Validation loss: 2.5251778190621152

Epoch: 6| Step: 8
Training loss: 1.8791191630762876
Validation loss: 2.538829663678224

Epoch: 6| Step: 9
Training loss: 2.533580696008808
Validation loss: 2.548722702710854

Epoch: 6| Step: 10
Training loss: 3.1659669772345924
Validation loss: 2.5479646001898852

Epoch: 6| Step: 11
Training loss: 1.9602790122058085
Validation loss: 2.5571614923125434

Epoch: 6| Step: 12
Training loss: 2.603109180635925
Validation loss: 2.561328480580724

Epoch: 6| Step: 13
Training loss: 1.9170698557280934
Validation loss: 2.5512325244026557

Epoch: 234| Step: 0
Training loss: 2.293843039306973
Validation loss: 2.560451153698042

Epoch: 6| Step: 1
Training loss: 2.4552181571167244
Validation loss: 2.564891536568428

Epoch: 6| Step: 2
Training loss: 1.6158323645560142
Validation loss: 2.5895082497139703

Epoch: 6| Step: 3
Training loss: 2.3314284882725773
Validation loss: 2.569950607780087

Epoch: 6| Step: 4
Training loss: 1.9781588414387457
Validation loss: 2.5615543543464385

Epoch: 6| Step: 5
Training loss: 1.4617792652189314
Validation loss: 2.549372706205323

Epoch: 6| Step: 6
Training loss: 1.931935533743276
Validation loss: 2.5551924211390475

Epoch: 6| Step: 7
Training loss: 2.2685429165912874
Validation loss: 2.5495616261775442

Epoch: 6| Step: 8
Training loss: 2.132920594323247
Validation loss: 2.5467069293462696

Epoch: 6| Step: 9
Training loss: 2.356406055412742
Validation loss: 2.5369141082368167

Epoch: 6| Step: 10
Training loss: 2.6057071147816444
Validation loss: 2.526103576740459

Epoch: 6| Step: 11
Training loss: 2.80457052767916
Validation loss: 2.535185388085109

Epoch: 6| Step: 12
Training loss: 2.9579333361786326
Validation loss: 2.5411199205728

Epoch: 6| Step: 13
Training loss: 2.4564025753865595
Validation loss: 2.5234154069403814

Epoch: 235| Step: 0
Training loss: 2.337932130577421
Validation loss: 2.5498907726555577

Epoch: 6| Step: 1
Training loss: 2.294737567399563
Validation loss: 2.551651008474029

Epoch: 6| Step: 2
Training loss: 2.3119320558642324
Validation loss: 2.5439599015396612

Epoch: 6| Step: 3
Training loss: 2.6059854386889687
Validation loss: 2.5616990830408253

Epoch: 6| Step: 4
Training loss: 2.8230668669621264
Validation loss: 2.565795949738121

Epoch: 6| Step: 5
Training loss: 1.621384633635088
Validation loss: 2.5426278928425163

Epoch: 6| Step: 6
Training loss: 2.6835033951253293
Validation loss: 2.5440382185730273

Epoch: 6| Step: 7
Training loss: 2.697459728375209
Validation loss: 2.532933056311825

Epoch: 6| Step: 8
Training loss: 1.8768152351022827
Validation loss: 2.5252231228638746

Epoch: 6| Step: 9
Training loss: 1.9959173255188694
Validation loss: 2.5253378500443175

Epoch: 6| Step: 10
Training loss: 1.7151892798378774
Validation loss: 2.497124496427066

Epoch: 6| Step: 11
Training loss: 2.117647691100157
Validation loss: 2.4779166481587245

Epoch: 6| Step: 12
Training loss: 2.378123989430838
Validation loss: 2.470704942383431

Epoch: 6| Step: 13
Training loss: 2.482829638950737
Validation loss: 2.469465055607344

Epoch: 236| Step: 0
Training loss: 2.3610213642890643
Validation loss: 2.482569680364479

Epoch: 6| Step: 1
Training loss: 2.765588275212998
Validation loss: 2.476082403296964

Epoch: 6| Step: 2
Training loss: 3.0055021057578455
Validation loss: 2.484663780590797

Epoch: 6| Step: 3
Training loss: 2.1140893318407645
Validation loss: 2.4884004030389115

Epoch: 6| Step: 4
Training loss: 2.546714450011756
Validation loss: 2.467414269264042

Epoch: 6| Step: 5
Training loss: 1.8916080535793056
Validation loss: 2.4882118618650955

Epoch: 6| Step: 6
Training loss: 2.6180846541249485
Validation loss: 2.5030190040983555

Epoch: 6| Step: 7
Training loss: 1.9665871501731302
Validation loss: 2.524657876533871

Epoch: 6| Step: 8
Training loss: 1.7458088277524753
Validation loss: 2.5296756259513087

Epoch: 6| Step: 9
Training loss: 1.911797752353669
Validation loss: 2.5531714837874895

Epoch: 6| Step: 10
Training loss: 2.2063499276762366
Validation loss: 2.551428470801766

Epoch: 6| Step: 11
Training loss: 2.100856960375109
Validation loss: 2.5465252720025524

Epoch: 6| Step: 12
Training loss: 2.0494653748981695
Validation loss: 2.5725196398203756

Epoch: 6| Step: 13
Training loss: 2.572465545601512
Validation loss: 2.5789595823292384

Epoch: 237| Step: 0
Training loss: 1.6098210725813378
Validation loss: 2.560724154808847

Epoch: 6| Step: 1
Training loss: 2.306695612834202
Validation loss: 2.559648198477374

Epoch: 6| Step: 2
Training loss: 2.2585958949909823
Validation loss: 2.54615857866128

Epoch: 6| Step: 3
Training loss: 2.301040505276121
Validation loss: 2.5270653108948444

Epoch: 6| Step: 4
Training loss: 2.5145301094732897
Validation loss: 2.5284629831619956

Epoch: 6| Step: 5
Training loss: 2.321854923207699
Validation loss: 2.5093674003641184

Epoch: 6| Step: 6
Training loss: 2.218423953747798
Validation loss: 2.5195023409345607

Epoch: 6| Step: 7
Training loss: 2.243204132240342
Validation loss: 2.528387853398814

Epoch: 6| Step: 8
Training loss: 2.3077953009975025
Validation loss: 2.535375600297828

Epoch: 6| Step: 9
Training loss: 2.3617599256574855
Validation loss: 2.550778819808854

Epoch: 6| Step: 10
Training loss: 2.4628618739338397
Validation loss: 2.5712458066855115

Epoch: 6| Step: 11
Training loss: 2.0261648054056587
Validation loss: 2.55883291742835

Epoch: 6| Step: 12
Training loss: 2.232545757444185
Validation loss: 2.6004899480325077

Epoch: 6| Step: 13
Training loss: 3.136188162919646
Validation loss: 2.591200820620553

Epoch: 238| Step: 0
Training loss: 1.9328859825628968
Validation loss: 2.5660883117716025

Epoch: 6| Step: 1
Training loss: 1.7836200941081037
Validation loss: 2.5234786779234666

Epoch: 6| Step: 2
Training loss: 2.643577414937397
Validation loss: 2.5002609911425533

Epoch: 6| Step: 3
Training loss: 2.2599424459505135
Validation loss: 2.485420311037532

Epoch: 6| Step: 4
Training loss: 1.7580171593098797
Validation loss: 2.4969261027339678

Epoch: 6| Step: 5
Training loss: 2.334176002201404
Validation loss: 2.497951558441825

Epoch: 6| Step: 6
Training loss: 2.552669743228286
Validation loss: 2.493387106971762

Epoch: 6| Step: 7
Training loss: 2.5542566711930075
Validation loss: 2.4721673097357817

Epoch: 6| Step: 8
Training loss: 2.4274133176874666
Validation loss: 2.47656288507982

Epoch: 6| Step: 9
Training loss: 1.7665416397382767
Validation loss: 2.4664032965179117

Epoch: 6| Step: 10
Training loss: 2.601353909031637
Validation loss: 2.4719818465091987

Epoch: 6| Step: 11
Training loss: 1.6942104853817503
Validation loss: 2.474444858830008

Epoch: 6| Step: 12
Training loss: 2.3027670925103636
Validation loss: 2.4756826929851146

Epoch: 6| Step: 13
Training loss: 3.0922110997591403
Validation loss: 2.4839062838380306

Epoch: 239| Step: 0
Training loss: 2.5344151617177046
Validation loss: 2.5160092046606697

Epoch: 6| Step: 1
Training loss: 2.4545712429515776
Validation loss: 2.5077954427390567

Epoch: 6| Step: 2
Training loss: 2.0261698652043845
Validation loss: 2.502593602460197

Epoch: 6| Step: 3
Training loss: 1.8372503253740788
Validation loss: 2.4909273826359515

Epoch: 6| Step: 4
Training loss: 2.6019992404499748
Validation loss: 2.4854131325000877

Epoch: 6| Step: 5
Training loss: 1.8029215044991553
Validation loss: 2.4977161147733287

Epoch: 6| Step: 6
Training loss: 2.5273222413835543
Validation loss: 2.4983445408497404

Epoch: 6| Step: 7
Training loss: 2.0130967244741678
Validation loss: 2.5178059666465864

Epoch: 6| Step: 8
Training loss: 1.8256011887159498
Validation loss: 2.518324231178233

Epoch: 6| Step: 9
Training loss: 2.5912787373003248
Validation loss: 2.528108924151322

Epoch: 6| Step: 10
Training loss: 2.22254458182111
Validation loss: 2.5230529775632817

Epoch: 6| Step: 11
Training loss: 2.1071725155126324
Validation loss: 2.5460059744761554

Epoch: 6| Step: 12
Training loss: 2.9496523506793415
Validation loss: 2.5340526433814086

Epoch: 6| Step: 13
Training loss: 2.751358823586838
Validation loss: 2.5290843977475674

Epoch: 240| Step: 0
Training loss: 2.7855002684352557
Validation loss: 2.5169298803817486

Epoch: 6| Step: 1
Training loss: 2.0862394535810656
Validation loss: 2.5541582560647096

Epoch: 6| Step: 2
Training loss: 2.73223182611724
Validation loss: 2.5581615752758653

Epoch: 6| Step: 3
Training loss: 2.4093567250074495
Validation loss: 2.574111311064082

Epoch: 6| Step: 4
Training loss: 1.9780072748187354
Validation loss: 2.5835138355281115

Epoch: 6| Step: 5
Training loss: 2.3220082261484403
Validation loss: 2.5910480321065896

Epoch: 6| Step: 6
Training loss: 2.666981281159044
Validation loss: 2.561520908910502

Epoch: 6| Step: 7
Training loss: 2.1494400182298117
Validation loss: 2.5722894071282396

Epoch: 6| Step: 8
Training loss: 2.198735185652419
Validation loss: 2.527421835116126

Epoch: 6| Step: 9
Training loss: 2.4490870390160726
Validation loss: 2.5242973728621583

Epoch: 6| Step: 10
Training loss: 1.740633147133298
Validation loss: 2.5207390150179974

Epoch: 6| Step: 11
Training loss: 1.8098220114895538
Validation loss: 2.5051128556951854

Epoch: 6| Step: 12
Training loss: 2.5104971802860327
Validation loss: 2.490643556175524

Epoch: 6| Step: 13
Training loss: 2.1324993644257253
Validation loss: 2.4972657828467937

Epoch: 241| Step: 0
Training loss: 2.1136530691849598
Validation loss: 2.4846308674397672

Epoch: 6| Step: 1
Training loss: 2.0575730400980023
Validation loss: 2.5064775869358065

Epoch: 6| Step: 2
Training loss: 2.5157844066463837
Validation loss: 2.5000257331795317

Epoch: 6| Step: 3
Training loss: 2.732814757846185
Validation loss: 2.4986219899839144

Epoch: 6| Step: 4
Training loss: 1.8325917376861445
Validation loss: 2.5188632286500563

Epoch: 6| Step: 5
Training loss: 1.9380389048605113
Validation loss: 2.519524168650215

Epoch: 6| Step: 6
Training loss: 1.9693165524016785
Validation loss: 2.533139783174686

Epoch: 6| Step: 7
Training loss: 2.656511989463777
Validation loss: 2.5175710776156173

Epoch: 6| Step: 8
Training loss: 1.7305825499580303
Validation loss: 2.5592721597816945

Epoch: 6| Step: 9
Training loss: 2.294955846656804
Validation loss: 2.565127119294055

Epoch: 6| Step: 10
Training loss: 1.9823713625030175
Validation loss: 2.561725468387773

Epoch: 6| Step: 11
Training loss: 2.5889100107560177
Validation loss: 2.623355910710176

Epoch: 6| Step: 12
Training loss: 2.37942143516431
Validation loss: 2.58716134789947

Epoch: 6| Step: 13
Training loss: 2.6158873104065186
Validation loss: 2.5854340185115423

Epoch: 242| Step: 0
Training loss: 2.3836834425853546
Validation loss: 2.6100866752059027

Epoch: 6| Step: 1
Training loss: 2.399717505041772
Validation loss: 2.592201000176169

Epoch: 6| Step: 2
Training loss: 1.8578785877327888
Validation loss: 2.5710575681938113

Epoch: 6| Step: 3
Training loss: 2.415209451442242
Validation loss: 2.5273721448668143

Epoch: 6| Step: 4
Training loss: 2.899659261745855
Validation loss: 2.517281139170444

Epoch: 6| Step: 5
Training loss: 2.0647230017028884
Validation loss: 2.5045978941806446

Epoch: 6| Step: 6
Training loss: 2.1123113468962873
Validation loss: 2.504189445997103

Epoch: 6| Step: 7
Training loss: 1.7074282116969823
Validation loss: 2.5025646247611175

Epoch: 6| Step: 8
Training loss: 2.5895625863710863
Validation loss: 2.5049796261088955

Epoch: 6| Step: 9
Training loss: 2.717622281914281
Validation loss: 2.4991989044326868

Epoch: 6| Step: 10
Training loss: 2.1775843820963408
Validation loss: 2.4972767063935053

Epoch: 6| Step: 11
Training loss: 1.6517170468347675
Validation loss: 2.504989096287228

Epoch: 6| Step: 12
Training loss: 2.3503427985943968
Validation loss: 2.4697808153763314

Epoch: 6| Step: 13
Training loss: 2.1977783689936317
Validation loss: 2.496371624383676

Epoch: 243| Step: 0
Training loss: 2.3026008081889833
Validation loss: 2.4900847426194614

Epoch: 6| Step: 1
Training loss: 1.7144407176718042
Validation loss: 2.4933905891441994

Epoch: 6| Step: 2
Training loss: 1.9895317776642667
Validation loss: 2.5075327557763023

Epoch: 6| Step: 3
Training loss: 2.8072245819248303
Validation loss: 2.5139415312770597

Epoch: 6| Step: 4
Training loss: 1.5360691763082472
Validation loss: 2.5269025508898686

Epoch: 6| Step: 5
Training loss: 2.021812935632744
Validation loss: 2.5111541271627913

Epoch: 6| Step: 6
Training loss: 2.1127159504862374
Validation loss: 2.520464331571959

Epoch: 6| Step: 7
Training loss: 2.12944239593433
Validation loss: 2.5080288390651733

Epoch: 6| Step: 8
Training loss: 3.0856381814391933
Validation loss: 2.51327759743756

Epoch: 6| Step: 9
Training loss: 2.142403636354376
Validation loss: 2.512341032170856

Epoch: 6| Step: 10
Training loss: 2.8421498921628823
Validation loss: 2.5132538656130827

Epoch: 6| Step: 11
Training loss: 2.7535720514194644
Validation loss: 2.5383466601590703

Epoch: 6| Step: 12
Training loss: 1.67624001792308
Validation loss: 2.5412556571290783

Epoch: 6| Step: 13
Training loss: 2.0309633492901016
Validation loss: 2.538738179156633

Epoch: 244| Step: 0
Training loss: 1.6938291467846793
Validation loss: 2.552236378550717

Epoch: 6| Step: 1
Training loss: 2.565732638183895
Validation loss: 2.528681766923867

Epoch: 6| Step: 2
Training loss: 2.2311035963052657
Validation loss: 2.554243961137544

Epoch: 6| Step: 3
Training loss: 2.7079343844286727
Validation loss: 2.5063762889826595

Epoch: 6| Step: 4
Training loss: 2.5099799276210453
Validation loss: 2.4995357400244522

Epoch: 6| Step: 5
Training loss: 2.0950569514725204
Validation loss: 2.483095283320883

Epoch: 6| Step: 6
Training loss: 2.2192105097444133
Validation loss: 2.4694135554779626

Epoch: 6| Step: 7
Training loss: 2.5115690527841505
Validation loss: 2.455891420108691

Epoch: 6| Step: 8
Training loss: 2.0756744621469037
Validation loss: 2.45402613973129

Epoch: 6| Step: 9
Training loss: 3.1113377802639732
Validation loss: 2.449599971032345

Epoch: 6| Step: 10
Training loss: 1.8288769601906951
Validation loss: 2.4466038585764114

Epoch: 6| Step: 11
Training loss: 1.9846660370552893
Validation loss: 2.455285257055066

Epoch: 6| Step: 12
Training loss: 2.059595664073168
Validation loss: 2.4650956320895308

Epoch: 6| Step: 13
Training loss: 2.143101728195612
Validation loss: 2.4594900890341167

Epoch: 245| Step: 0
Training loss: 2.3046529476355895
Validation loss: 2.5058786099598294

Epoch: 6| Step: 1
Training loss: 2.477417422245474
Validation loss: 2.5250599057736363

Epoch: 6| Step: 2
Training loss: 2.086522852458263
Validation loss: 2.5264996509995914

Epoch: 6| Step: 3
Training loss: 2.2068547271082566
Validation loss: 2.5202836680078637

Epoch: 6| Step: 4
Training loss: 2.410598788446527
Validation loss: 2.5192098171018418

Epoch: 6| Step: 5
Training loss: 2.451301042413418
Validation loss: 2.5042001568611836

Epoch: 6| Step: 6
Training loss: 1.8345189884478792
Validation loss: 2.5195450104724566

Epoch: 6| Step: 7
Training loss: 2.438015027532664
Validation loss: 2.533787095586084

Epoch: 6| Step: 8
Training loss: 1.9905196444958542
Validation loss: 2.545672766767047

Epoch: 6| Step: 9
Training loss: 1.946138199061619
Validation loss: 2.5440312991556087

Epoch: 6| Step: 10
Training loss: 2.5721920295446505
Validation loss: 2.565248674430588

Epoch: 6| Step: 11
Training loss: 2.3659175072136267
Validation loss: 2.56707619448784

Epoch: 6| Step: 12
Training loss: 2.1952471197309453
Validation loss: 2.5570136007773487

Epoch: 6| Step: 13
Training loss: 2.2478638151058457
Validation loss: 2.564981112295983

Epoch: 246| Step: 0
Training loss: 2.0264643707870453
Validation loss: 2.558042463941854

Epoch: 6| Step: 1
Training loss: 1.7224202589116648
Validation loss: 2.5515042536811774

Epoch: 6| Step: 2
Training loss: 2.496061274118741
Validation loss: 2.5485568587938325

Epoch: 6| Step: 3
Training loss: 2.2391879656845477
Validation loss: 2.553041369135744

Epoch: 6| Step: 4
Training loss: 1.911196809456399
Validation loss: 2.5399074928579184

Epoch: 6| Step: 5
Training loss: 1.6946080585692873
Validation loss: 2.525445759017263

Epoch: 6| Step: 6
Training loss: 2.1376924127007513
Validation loss: 2.5266384769954002

Epoch: 6| Step: 7
Training loss: 2.8158958279404187
Validation loss: 2.5304704965081135

Epoch: 6| Step: 8
Training loss: 2.4993515127251262
Validation loss: 2.5067280200118764

Epoch: 6| Step: 9
Training loss: 2.2381736636310814
Validation loss: 2.516850917168256

Epoch: 6| Step: 10
Training loss: 2.7161609994252154
Validation loss: 2.546821078800369

Epoch: 6| Step: 11
Training loss: 2.310505599800395
Validation loss: 2.553874392897639

Epoch: 6| Step: 12
Training loss: 2.0498842439301748
Validation loss: 2.536889704708423

Epoch: 6| Step: 13
Training loss: 2.3702851728298664
Validation loss: 2.5614080195833004

Epoch: 247| Step: 0
Training loss: 1.837993039268455
Validation loss: 2.59184852669366

Epoch: 6| Step: 1
Training loss: 2.4316500376323846
Validation loss: 2.6012191469512715

Epoch: 6| Step: 2
Training loss: 2.422027583084102
Validation loss: 2.5650522656039088

Epoch: 6| Step: 3
Training loss: 2.268847994619024
Validation loss: 2.5676228094398494

Epoch: 6| Step: 4
Training loss: 2.7964613624603145
Validation loss: 2.5381402869360286

Epoch: 6| Step: 5
Training loss: 2.146850665758309
Validation loss: 2.4864006581280833

Epoch: 6| Step: 6
Training loss: 2.278379123155979
Validation loss: 2.4862148581748356

Epoch: 6| Step: 7
Training loss: 2.3886269590906872
Validation loss: 2.4893764159804883

Epoch: 6| Step: 8
Training loss: 2.1517656661152857
Validation loss: 2.491700797554247

Epoch: 6| Step: 9
Training loss: 2.7779234805571167
Validation loss: 2.5209715676566176

Epoch: 6| Step: 10
Training loss: 2.0661157068457485
Validation loss: 2.4887357623058497

Epoch: 6| Step: 11
Training loss: 2.3064233482155543
Validation loss: 2.500492865934355

Epoch: 6| Step: 12
Training loss: 1.9787494487364068
Validation loss: 2.5046945522222552

Epoch: 6| Step: 13
Training loss: 1.8530198168695946
Validation loss: 2.538675460660286

Epoch: 248| Step: 0
Training loss: 2.1556582537281868
Validation loss: 2.5311503135611884

Epoch: 6| Step: 1
Training loss: 2.603672855606052
Validation loss: 2.5334104885933915

Epoch: 6| Step: 2
Training loss: 2.2000917155481794
Validation loss: 2.546319397779792

Epoch: 6| Step: 3
Training loss: 1.984089447862301
Validation loss: 2.5687080949148156

Epoch: 6| Step: 4
Training loss: 2.169017531194403
Validation loss: 2.5829952746870015

Epoch: 6| Step: 5
Training loss: 2.271534546079095
Validation loss: 2.5591245920773504

Epoch: 6| Step: 6
Training loss: 2.030162344017445
Validation loss: 2.5606901398867103

Epoch: 6| Step: 7
Training loss: 2.6280796514311278
Validation loss: 2.553793685671381

Epoch: 6| Step: 8
Training loss: 1.5791796191379663
Validation loss: 2.5174629179146932

Epoch: 6| Step: 9
Training loss: 2.7583414494451723
Validation loss: 2.504483264093171

Epoch: 6| Step: 10
Training loss: 2.4265835183259474
Validation loss: 2.5028681514943307

Epoch: 6| Step: 11
Training loss: 1.938875202536288
Validation loss: 2.4909303178876314

Epoch: 6| Step: 12
Training loss: 2.082551186288578
Validation loss: 2.491764403396394

Epoch: 6| Step: 13
Training loss: 2.4716658936608877
Validation loss: 2.481773509891077

Epoch: 249| Step: 0
Training loss: 2.6491808002963277
Validation loss: 2.4904927437582187

Epoch: 6| Step: 1
Training loss: 2.2076477810048383
Validation loss: 2.4903580379323613

Epoch: 6| Step: 2
Training loss: 1.7912956193650509
Validation loss: 2.496634029366943

Epoch: 6| Step: 3
Training loss: 1.9017905306227427
Validation loss: 2.490693301130271

Epoch: 6| Step: 4
Training loss: 1.7854174666994573
Validation loss: 2.491436437561688

Epoch: 6| Step: 5
Training loss: 1.8147661577601906
Validation loss: 2.5108776750857817

Epoch: 6| Step: 6
Training loss: 2.5819412192664872
Validation loss: 2.5256307654443613

Epoch: 6| Step: 7
Training loss: 1.9927581568177613
Validation loss: 2.5517700366313676

Epoch: 6| Step: 8
Training loss: 1.750989089469969
Validation loss: 2.580672498607558

Epoch: 6| Step: 9
Training loss: 2.918470878242728
Validation loss: 2.566250158137437

Epoch: 6| Step: 10
Training loss: 2.6580461600079315
Validation loss: 2.562131436522404

Epoch: 6| Step: 11
Training loss: 2.51635627306128
Validation loss: 2.5351067505379588

Epoch: 6| Step: 12
Training loss: 1.7659240739427107
Validation loss: 2.50569897220307

Epoch: 6| Step: 13
Training loss: 2.8502301173417135
Validation loss: 2.486091740377061

Epoch: 250| Step: 0
Training loss: 2.2982726742727544
Validation loss: 2.4881769115504446

Epoch: 6| Step: 1
Training loss: 2.1488971010533584
Validation loss: 2.4826508303149826

Epoch: 6| Step: 2
Training loss: 1.7899821886849394
Validation loss: 2.485346102505565

Epoch: 6| Step: 3
Training loss: 2.4718824384073446
Validation loss: 2.492061639714837

Epoch: 6| Step: 4
Training loss: 1.7926430001139502
Validation loss: 2.4837197133332554

Epoch: 6| Step: 5
Training loss: 2.6016656895239993
Validation loss: 2.469441522249205

Epoch: 6| Step: 6
Training loss: 2.8686243765259043
Validation loss: 2.4903054779473273

Epoch: 6| Step: 7
Training loss: 2.0371457733969582
Validation loss: 2.486596192170058

Epoch: 6| Step: 8
Training loss: 2.25783456969777
Validation loss: 2.4916931586840048

Epoch: 6| Step: 9
Training loss: 2.379302995542684
Validation loss: 2.496687140497551

Epoch: 6| Step: 10
Training loss: 2.3450556869239096
Validation loss: 2.5226701292063933

Epoch: 6| Step: 11
Training loss: 2.3572475112867917
Validation loss: 2.5343865165025456

Epoch: 6| Step: 12
Training loss: 1.7916785025390496
Validation loss: 2.5513633387110057

Epoch: 6| Step: 13
Training loss: 2.2577886349165848
Validation loss: 2.539349599403421

Epoch: 251| Step: 0
Training loss: 2.1321384356859765
Validation loss: 2.544041420554402

Epoch: 6| Step: 1
Training loss: 2.022654142411815
Validation loss: 2.552661835375073

Epoch: 6| Step: 2
Training loss: 1.8827842615313022
Validation loss: 2.548252926521189

Epoch: 6| Step: 3
Training loss: 2.0699031785076314
Validation loss: 2.5311793564722644

Epoch: 6| Step: 4
Training loss: 2.319904946649068
Validation loss: 2.5324471550838403

Epoch: 6| Step: 5
Training loss: 2.654497353769989
Validation loss: 2.5137990006967

Epoch: 6| Step: 6
Training loss: 1.9927085045593262
Validation loss: 2.5101650212159687

Epoch: 6| Step: 7
Training loss: 2.5078629818407654
Validation loss: 2.520720035329355

Epoch: 6| Step: 8
Training loss: 2.203719904234837
Validation loss: 2.5194204222283836

Epoch: 6| Step: 9
Training loss: 1.5088702825024243
Validation loss: 2.517102409896292

Epoch: 6| Step: 10
Training loss: 2.4365421271515157
Validation loss: 2.5172455269305307

Epoch: 6| Step: 11
Training loss: 2.4871570676649757
Validation loss: 2.5209721193387193

Epoch: 6| Step: 12
Training loss: 2.62588767528648
Validation loss: 2.517681126624442

Epoch: 6| Step: 13
Training loss: 2.4655981103472735
Validation loss: 2.5303075001174773

Epoch: 252| Step: 0
Training loss: 2.5427707296172883
Validation loss: 2.540874847726884

Epoch: 6| Step: 1
Training loss: 2.036600548606963
Validation loss: 2.558144721700694

Epoch: 6| Step: 2
Training loss: 2.056671461144067
Validation loss: 2.552312713487278

Epoch: 6| Step: 3
Training loss: 1.4397133911533857
Validation loss: 2.5619581006207626

Epoch: 6| Step: 4
Training loss: 1.8562069358068882
Validation loss: 2.557677639322928

Epoch: 6| Step: 5
Training loss: 2.822070643675581
Validation loss: 2.542314827201406

Epoch: 6| Step: 6
Training loss: 2.8471826648807177
Validation loss: 2.537153941079486

Epoch: 6| Step: 7
Training loss: 1.7410219681529893
Validation loss: 2.5111775069709683

Epoch: 6| Step: 8
Training loss: 2.2120666855457296
Validation loss: 2.5144889588385735

Epoch: 6| Step: 9
Training loss: 2.5173502627318034
Validation loss: 2.4860995562928365

Epoch: 6| Step: 10
Training loss: 2.681169372626786
Validation loss: 2.485052867994789

Epoch: 6| Step: 11
Training loss: 2.200045333742016
Validation loss: 2.4977066806557913

Epoch: 6| Step: 12
Training loss: 2.0817172330767617
Validation loss: 2.501564791835392

Epoch: 6| Step: 13
Training loss: 2.115381237507504
Validation loss: 2.4841355662258335

Epoch: 253| Step: 0
Training loss: 2.4172873083713857
Validation loss: 2.4838728807165236

Epoch: 6| Step: 1
Training loss: 1.8107821775613915
Validation loss: 2.4842688259893104

Epoch: 6| Step: 2
Training loss: 1.8073874090011306
Validation loss: 2.493758293526864

Epoch: 6| Step: 3
Training loss: 1.9519476431875946
Validation loss: 2.4854551162580814

Epoch: 6| Step: 4
Training loss: 2.3699904361966473
Validation loss: 2.5411749244229354

Epoch: 6| Step: 5
Training loss: 2.195551197474106
Validation loss: 2.5483357271774087

Epoch: 6| Step: 6
Training loss: 1.8369563745292996
Validation loss: 2.6208470508436803

Epoch: 6| Step: 7
Training loss: 2.3973861527287195
Validation loss: 2.6459796945134455

Epoch: 6| Step: 8
Training loss: 2.5178463055378395
Validation loss: 2.697518622493483

Epoch: 6| Step: 9
Training loss: 1.4581741064430296
Validation loss: 2.6816254735983076

Epoch: 6| Step: 10
Training loss: 2.906202910667318
Validation loss: 2.716722726438514

Epoch: 6| Step: 11
Training loss: 3.0164616664409016
Validation loss: 2.598484651034911

Epoch: 6| Step: 12
Training loss: 2.0168546725614998
Validation loss: 2.527866834136023

Epoch: 6| Step: 13
Training loss: 2.8443911322260056
Validation loss: 2.4999396475818605

Epoch: 254| Step: 0
Training loss: 2.2291650385865536
Validation loss: 2.50519535328337

Epoch: 6| Step: 1
Training loss: 1.5521468676507177
Validation loss: 2.5145326537108574

Epoch: 6| Step: 2
Training loss: 2.863712044193359
Validation loss: 2.514948752041015

Epoch: 6| Step: 3
Training loss: 1.9625728520763328
Validation loss: 2.5159449482465877

Epoch: 6| Step: 4
Training loss: 2.5585266570401717
Validation loss: 2.5325223213284085

Epoch: 6| Step: 5
Training loss: 2.323431006539871
Validation loss: 2.5265500582843

Epoch: 6| Step: 6
Training loss: 2.0711207701403693
Validation loss: 2.5298399745958617

Epoch: 6| Step: 7
Training loss: 2.006604020206451
Validation loss: 2.543639712243063

Epoch: 6| Step: 8
Training loss: 2.2947111771629736
Validation loss: 2.557351204256114

Epoch: 6| Step: 9
Training loss: 2.4619478603949894
Validation loss: 2.529371168697526

Epoch: 6| Step: 10
Training loss: 1.9033040280376994
Validation loss: 2.529965502562815

Epoch: 6| Step: 11
Training loss: 2.8549456867456477
Validation loss: 2.5667828380831943

Epoch: 6| Step: 12
Training loss: 2.4576236756599963
Validation loss: 2.5417128204365964

Epoch: 6| Step: 13
Training loss: 2.5970483054162243
Validation loss: 2.540736596290801

Epoch: 255| Step: 0
Training loss: 2.5948028266102177
Validation loss: 2.537830182847553

Epoch: 6| Step: 1
Training loss: 2.238482561095924
Validation loss: 2.555342237465812

Epoch: 6| Step: 2
Training loss: 1.4336173655880176
Validation loss: 2.554693628395188

Epoch: 6| Step: 3
Training loss: 2.7549140547069744
Validation loss: 2.521796544275491

Epoch: 6| Step: 4
Training loss: 2.062030160737001
Validation loss: 2.540249763108578

Epoch: 6| Step: 5
Training loss: 2.134234726235308
Validation loss: 2.5267677810368907

Epoch: 6| Step: 6
Training loss: 2.7399658593605554
Validation loss: 2.512483771985029

Epoch: 6| Step: 7
Training loss: 1.3270734326498823
Validation loss: 2.4993560915453745

Epoch: 6| Step: 8
Training loss: 2.202706912796812
Validation loss: 2.4965922176820516

Epoch: 6| Step: 9
Training loss: 2.265909637460845
Validation loss: 2.4751180694494863

Epoch: 6| Step: 10
Training loss: 2.217063262663164
Validation loss: 2.479818568284191

Epoch: 6| Step: 11
Training loss: 1.9122083753258963
Validation loss: 2.4878843461045945

Epoch: 6| Step: 12
Training loss: 2.682659047469865
Validation loss: 2.5101669841607688

Epoch: 6| Step: 13
Training loss: 2.5041330505585964
Validation loss: 2.508661730445238

Epoch: 256| Step: 0
Training loss: 2.141581746160599
Validation loss: 2.499307457050282

Epoch: 6| Step: 1
Training loss: 2.0748428009419424
Validation loss: 2.507952542618523

Epoch: 6| Step: 2
Training loss: 2.178895868089958
Validation loss: 2.537822150465832

Epoch: 6| Step: 3
Training loss: 2.2151339440071287
Validation loss: 2.5841614462381393

Epoch: 6| Step: 4
Training loss: 2.406976565365409
Validation loss: 2.552996356638266

Epoch: 6| Step: 5
Training loss: 2.402913939256897
Validation loss: 2.5385596144120925

Epoch: 6| Step: 6
Training loss: 2.283650011067124
Validation loss: 2.5544367053695614

Epoch: 6| Step: 7
Training loss: 1.7489605950376312
Validation loss: 2.5388569440531588

Epoch: 6| Step: 8
Training loss: 2.371450984885026
Validation loss: 2.51582929520116

Epoch: 6| Step: 9
Training loss: 2.5505542975462108
Validation loss: 2.5118370048089953

Epoch: 6| Step: 10
Training loss: 2.489438445106176
Validation loss: 2.5190266264027787

Epoch: 6| Step: 11
Training loss: 2.0578057013119113
Validation loss: 2.5390073017086987

Epoch: 6| Step: 12
Training loss: 2.1580071407762103
Validation loss: 2.53118844605002

Epoch: 6| Step: 13
Training loss: 2.257476992907046
Validation loss: 2.536546401440824

Epoch: 257| Step: 0
Training loss: 2.6850599700652276
Validation loss: 2.547919014539492

Epoch: 6| Step: 1
Training loss: 1.6742792400730602
Validation loss: 2.5609509818199543

Epoch: 6| Step: 2
Training loss: 3.438467548491806
Validation loss: 2.5463648091998468

Epoch: 6| Step: 3
Training loss: 2.0803755426674897
Validation loss: 2.562036193184034

Epoch: 6| Step: 4
Training loss: 2.193013898590618
Validation loss: 2.5785654173467583

Epoch: 6| Step: 5
Training loss: 1.7049322076783378
Validation loss: 2.5989872555598224

Epoch: 6| Step: 6
Training loss: 2.34432894867689
Validation loss: 2.608575024441906

Epoch: 6| Step: 7
Training loss: 2.5161337012349394
Validation loss: 2.6157062039366155

Epoch: 6| Step: 8
Training loss: 1.8835535767431177
Validation loss: 2.5974092064887966

Epoch: 6| Step: 9
Training loss: 2.3110553249733963
Validation loss: 2.591654133740834

Epoch: 6| Step: 10
Training loss: 1.836117609807356
Validation loss: 2.5517808592210933

Epoch: 6| Step: 11
Training loss: 1.4339717190027348
Validation loss: 2.533243861835336

Epoch: 6| Step: 12
Training loss: 2.6651571491564447
Validation loss: 2.5126152119704064

Epoch: 6| Step: 13
Training loss: 1.8313156064099825
Validation loss: 2.4863319766525955

Epoch: 258| Step: 0
Training loss: 1.9168812451977608
Validation loss: 2.4734576043127032

Epoch: 6| Step: 1
Training loss: 2.2016306469281273
Validation loss: 2.463181795338047

Epoch: 6| Step: 2
Training loss: 1.8153942283216704
Validation loss: 2.443654856411017

Epoch: 6| Step: 3
Training loss: 1.97093775461152
Validation loss: 2.452994697495608

Epoch: 6| Step: 4
Training loss: 2.5025501596033126
Validation loss: 2.4639029261511616

Epoch: 6| Step: 5
Training loss: 2.097832528491356
Validation loss: 2.4605980856019953

Epoch: 6| Step: 6
Training loss: 1.8962579468250664
Validation loss: 2.4732663173884677

Epoch: 6| Step: 7
Training loss: 2.98921155223924
Validation loss: 2.469354177335851

Epoch: 6| Step: 8
Training loss: 2.365597433234465
Validation loss: 2.4879239882339776

Epoch: 6| Step: 9
Training loss: 2.25180214659496
Validation loss: 2.4688789076488424

Epoch: 6| Step: 10
Training loss: 1.781279580389323
Validation loss: 2.484165006835581

Epoch: 6| Step: 11
Training loss: 2.9053799547175263
Validation loss: 2.4964476937890177

Epoch: 6| Step: 12
Training loss: 2.0848292003170497
Validation loss: 2.4835770323139603

Epoch: 6| Step: 13
Training loss: 2.2379878785569574
Validation loss: 2.4899848443965484

Epoch: 259| Step: 0
Training loss: 2.475516113259628
Validation loss: 2.4909092446181402

Epoch: 6| Step: 1
Training loss: 1.477432801837262
Validation loss: 2.5085345028106314

Epoch: 6| Step: 2
Training loss: 2.1998791964915925
Validation loss: 2.508631698208907

Epoch: 6| Step: 3
Training loss: 2.6345580339481462
Validation loss: 2.5112908029920358

Epoch: 6| Step: 4
Training loss: 2.0838914759343106
Validation loss: 2.5187703090003564

Epoch: 6| Step: 5
Training loss: 2.526268755481224
Validation loss: 2.489713535069767

Epoch: 6| Step: 6
Training loss: 1.8729234004368167
Validation loss: 2.53497791887607

Epoch: 6| Step: 7
Training loss: 2.252188148376702
Validation loss: 2.528765585539089

Epoch: 6| Step: 8
Training loss: 2.4096700960128654
Validation loss: 2.4954949318848287

Epoch: 6| Step: 9
Training loss: 2.2128737096316753
Validation loss: 2.509623862689848

Epoch: 6| Step: 10
Training loss: 2.1522632175340566
Validation loss: 2.5111796115386227

Epoch: 6| Step: 11
Training loss: 2.571814194026503
Validation loss: 2.5048266071758323

Epoch: 6| Step: 12
Training loss: 1.606670217800305
Validation loss: 2.4887473699331317

Epoch: 6| Step: 13
Training loss: 2.0448608972298765
Validation loss: 2.492721532289084

Epoch: 260| Step: 0
Training loss: 1.9582771401425745
Validation loss: 2.5075161165560655

Epoch: 6| Step: 1
Training loss: 2.560831782990903
Validation loss: 2.510797943877008

Epoch: 6| Step: 2
Training loss: 1.725408660469681
Validation loss: 2.513080724025584

Epoch: 6| Step: 3
Training loss: 2.266063042749385
Validation loss: 2.5196671165876023

Epoch: 6| Step: 4
Training loss: 2.714676886171442
Validation loss: 2.5055671535382342

Epoch: 6| Step: 5
Training loss: 2.3163559186076523
Validation loss: 2.541131758033555

Epoch: 6| Step: 6
Training loss: 1.8514420997328893
Validation loss: 2.5490931113751425

Epoch: 6| Step: 7
Training loss: 2.472407275737875
Validation loss: 2.554486856932126

Epoch: 6| Step: 8
Training loss: 2.370406678151287
Validation loss: 2.5404632147733723

Epoch: 6| Step: 9
Training loss: 2.7686408888972194
Validation loss: 2.5163693560841014

Epoch: 6| Step: 10
Training loss: 1.6136935171441165
Validation loss: 2.5190165780150267

Epoch: 6| Step: 11
Training loss: 2.0039033945520592
Validation loss: 2.480355616114624

Epoch: 6| Step: 12
Training loss: 2.1217001931457533
Validation loss: 2.511101931252293

Epoch: 6| Step: 13
Training loss: 2.60471608787551
Validation loss: 2.4869975277420964

Epoch: 261| Step: 0
Training loss: 2.70079266250843
Validation loss: 2.4911206073402274

Epoch: 6| Step: 1
Training loss: 2.3647195269872276
Validation loss: 2.493292313517112

Epoch: 6| Step: 2
Training loss: 2.1663306293571436
Validation loss: 2.508671551035231

Epoch: 6| Step: 3
Training loss: 2.488486959676547
Validation loss: 2.5009955649130045

Epoch: 6| Step: 4
Training loss: 1.9611086827672248
Validation loss: 2.4941873050663843

Epoch: 6| Step: 5
Training loss: 1.54524221848678
Validation loss: 2.498399762760672

Epoch: 6| Step: 6
Training loss: 2.5508635012581093
Validation loss: 2.482107395168408

Epoch: 6| Step: 7
Training loss: 2.067001631981104
Validation loss: 2.5001710674249784

Epoch: 6| Step: 8
Training loss: 2.118761891919637
Validation loss: 2.5013036031220306

Epoch: 6| Step: 9
Training loss: 2.0901477628245986
Validation loss: 2.487349594783188

Epoch: 6| Step: 10
Training loss: 2.3453659590309153
Validation loss: 2.5140602821480984

Epoch: 6| Step: 11
Training loss: 2.4812599662369217
Validation loss: 2.5249613047615425

Epoch: 6| Step: 12
Training loss: 2.1358292591990313
Validation loss: 2.551312097805785

Epoch: 6| Step: 13
Training loss: 1.8761403748510506
Validation loss: 2.533258355645703

Epoch: 262| Step: 0
Training loss: 2.3826657109307563
Validation loss: 2.534238236669102

Epoch: 6| Step: 1
Training loss: 2.409826617830198
Validation loss: 2.5439029663232193

Epoch: 6| Step: 2
Training loss: 1.4756914425489025
Validation loss: 2.5046663365508124

Epoch: 6| Step: 3
Training loss: 1.7577801510695297
Validation loss: 2.4952246914651433

Epoch: 6| Step: 4
Training loss: 2.09899632219971
Validation loss: 2.5181430511319953

Epoch: 6| Step: 5
Training loss: 1.4373560294327496
Validation loss: 2.484039403933048

Epoch: 6| Step: 6
Training loss: 2.522040012638162
Validation loss: 2.4786205224459352

Epoch: 6| Step: 7
Training loss: 2.148543920482187
Validation loss: 2.4675141150352005

Epoch: 6| Step: 8
Training loss: 2.672473238176718
Validation loss: 2.489840144448153

Epoch: 6| Step: 9
Training loss: 2.1689521277611297
Validation loss: 2.469660707689077

Epoch: 6| Step: 10
Training loss: 2.482880244642222
Validation loss: 2.474757133153242

Epoch: 6| Step: 11
Training loss: 2.540291450630082
Validation loss: 2.4787200450642226

Epoch: 6| Step: 12
Training loss: 1.9640654886324653
Validation loss: 2.501378966537792

Epoch: 6| Step: 13
Training loss: 2.6315035410166288
Validation loss: 2.5058348910453003

Epoch: 263| Step: 0
Training loss: 2.527381106635624
Validation loss: 2.5048209120133436

Epoch: 6| Step: 1
Training loss: 2.1507768691212648
Validation loss: 2.508974315217897

Epoch: 6| Step: 2
Training loss: 1.9761330360385778
Validation loss: 2.5051749075855834

Epoch: 6| Step: 3
Training loss: 1.683323247646421
Validation loss: 2.4815715911292626

Epoch: 6| Step: 4
Training loss: 1.6582604927410798
Validation loss: 2.484691367808633

Epoch: 6| Step: 5
Training loss: 2.639323077259081
Validation loss: 2.474490834532951

Epoch: 6| Step: 6
Training loss: 2.1726125658589304
Validation loss: 2.5075819596815707

Epoch: 6| Step: 7
Training loss: 2.195286869428894
Validation loss: 2.526619675303322

Epoch: 6| Step: 8
Training loss: 1.9508270783821782
Validation loss: 2.5258546714128918

Epoch: 6| Step: 9
Training loss: 2.8430770245401833
Validation loss: 2.5143124728164534

Epoch: 6| Step: 10
Training loss: 2.8624277963652283
Validation loss: 2.539762836607979

Epoch: 6| Step: 11
Training loss: 1.512293822052292
Validation loss: 2.4995883602755864

Epoch: 6| Step: 12
Training loss: 2.188400954949532
Validation loss: 2.525117155699742

Epoch: 6| Step: 13
Training loss: 1.8971879402452945
Validation loss: 2.55756298006284

Epoch: 264| Step: 0
Training loss: 1.8131108405669176
Validation loss: 2.590718892002339

Epoch: 6| Step: 1
Training loss: 2.2558897074191804
Validation loss: 2.6020990606911334

Epoch: 6| Step: 2
Training loss: 2.7594660915662925
Validation loss: 2.6132114098857286

Epoch: 6| Step: 3
Training loss: 2.428823433952215
Validation loss: 2.5727061341260065

Epoch: 6| Step: 4
Training loss: 1.8578161549191339
Validation loss: 2.541801399557963

Epoch: 6| Step: 5
Training loss: 1.7579527396314816
Validation loss: 2.499568997423772

Epoch: 6| Step: 6
Training loss: 2.4959926913105503
Validation loss: 2.4924476272529166

Epoch: 6| Step: 7
Training loss: 1.9527640047246348
Validation loss: 2.4733762651977704

Epoch: 6| Step: 8
Training loss: 2.7415444687933364
Validation loss: 2.488535677898786

Epoch: 6| Step: 9
Training loss: 2.112299608285329
Validation loss: 2.4700941780349637

Epoch: 6| Step: 10
Training loss: 2.611948263505939
Validation loss: 2.468557068573386

Epoch: 6| Step: 11
Training loss: 2.5972458594114145
Validation loss: 2.4771763053966085

Epoch: 6| Step: 12
Training loss: 1.9550025155522
Validation loss: 2.4843474572532314

Epoch: 6| Step: 13
Training loss: 1.9581007176758667
Validation loss: 2.5148807870129066

Epoch: 265| Step: 0
Training loss: 2.510547798077034
Validation loss: 2.522175972526637

Epoch: 6| Step: 1
Training loss: 2.4070562027699847
Validation loss: 2.5215050509092913

Epoch: 6| Step: 2
Training loss: 2.001171722501458
Validation loss: 2.547076117877006

Epoch: 6| Step: 3
Training loss: 2.0310398873451048
Validation loss: 2.524413487958812

Epoch: 6| Step: 4
Training loss: 1.3700087729402866
Validation loss: 2.4811040310078414

Epoch: 6| Step: 5
Training loss: 2.393100429278265
Validation loss: 2.458100491073483

Epoch: 6| Step: 6
Training loss: 2.5888845010737542
Validation loss: 2.463023743547406

Epoch: 6| Step: 7
Training loss: 1.8034391503069527
Validation loss: 2.4984973842242506

Epoch: 6| Step: 8
Training loss: 2.2160656231276863
Validation loss: 2.478818906440919

Epoch: 6| Step: 9
Training loss: 2.62339879201082
Validation loss: 2.4896236932481064

Epoch: 6| Step: 10
Training loss: 1.9455718208493378
Validation loss: 2.503120977658053

Epoch: 6| Step: 11
Training loss: 2.338952303872668
Validation loss: 2.5215439359730336

Epoch: 6| Step: 12
Training loss: 2.0021291366985023
Validation loss: 2.50623854446647

Epoch: 6| Step: 13
Training loss: 2.131298715700278
Validation loss: 2.526055630255314

Epoch: 266| Step: 0
Training loss: 1.719538559783276
Validation loss: 2.5408788981928634

Epoch: 6| Step: 1
Training loss: 1.7525418078214943
Validation loss: 2.5425131018947127

Epoch: 6| Step: 2
Training loss: 2.554390892985543
Validation loss: 2.526253458694237

Epoch: 6| Step: 3
Training loss: 2.0508816939687793
Validation loss: 2.5299088806711394

Epoch: 6| Step: 4
Training loss: 1.464232212843739
Validation loss: 2.524145257388233

Epoch: 6| Step: 5
Training loss: 2.364054101095767
Validation loss: 2.5261546368588617

Epoch: 6| Step: 6
Training loss: 1.6990380202019604
Validation loss: 2.5636453317460344

Epoch: 6| Step: 7
Training loss: 2.144203480615629
Validation loss: 2.5397237924021625

Epoch: 6| Step: 8
Training loss: 2.2740434710760273
Validation loss: 2.5748618542548463

Epoch: 6| Step: 9
Training loss: 2.1580545365634256
Validation loss: 2.5684827419575242

Epoch: 6| Step: 10
Training loss: 2.7063058649160037
Validation loss: 2.577169792392301

Epoch: 6| Step: 11
Training loss: 2.581728549590753
Validation loss: 2.567192023148115

Epoch: 6| Step: 12
Training loss: 1.8701521190438648
Validation loss: 2.5642228111473733

Epoch: 6| Step: 13
Training loss: 2.3615953721740266
Validation loss: 2.52466901208708

Epoch: 267| Step: 0
Training loss: 2.2973501531406253
Validation loss: 2.52349662908323

Epoch: 6| Step: 1
Training loss: 1.9169341052793532
Validation loss: 2.515344766049758

Epoch: 6| Step: 2
Training loss: 2.8713505013812277
Validation loss: 2.507732972402248

Epoch: 6| Step: 3
Training loss: 2.2103819671505525
Validation loss: 2.4720950180241354

Epoch: 6| Step: 4
Training loss: 1.7477055903748324
Validation loss: 2.476722864520566

Epoch: 6| Step: 5
Training loss: 1.908064369615339
Validation loss: 2.4863378420208133

Epoch: 6| Step: 6
Training loss: 2.008764137925706
Validation loss: 2.496284115436741

Epoch: 6| Step: 7
Training loss: 1.761364412727073
Validation loss: 2.4911422131832635

Epoch: 6| Step: 8
Training loss: 2.0379689525302025
Validation loss: 2.4936726448981084

Epoch: 6| Step: 9
Training loss: 2.4884525641330657
Validation loss: 2.5142162003367017

Epoch: 6| Step: 10
Training loss: 2.4238471092691776
Validation loss: 2.492847231735793

Epoch: 6| Step: 11
Training loss: 2.030346831022213
Validation loss: 2.5259823716797682

Epoch: 6| Step: 12
Training loss: 2.748879464480336
Validation loss: 2.5125432853702585

Epoch: 6| Step: 13
Training loss: 1.4435128219452578
Validation loss: 2.483500600681753

Epoch: 268| Step: 0
Training loss: 2.0025499300976692
Validation loss: 2.4958606306651956

Epoch: 6| Step: 1
Training loss: 2.4877520946255807
Validation loss: 2.5030783615180616

Epoch: 6| Step: 2
Training loss: 2.4598130336516353
Validation loss: 2.5129877328751635

Epoch: 6| Step: 3
Training loss: 2.2979195224424886
Validation loss: 2.519985195537758

Epoch: 6| Step: 4
Training loss: 2.2978487610546563
Validation loss: 2.5215666836543025

Epoch: 6| Step: 5
Training loss: 2.3138273399118052
Validation loss: 2.5400853058114317

Epoch: 6| Step: 6
Training loss: 1.7870295272249157
Validation loss: 2.542704125546343

Epoch: 6| Step: 7
Training loss: 2.4842424657246163
Validation loss: 2.5158550639023245

Epoch: 6| Step: 8
Training loss: 1.6967513487217383
Validation loss: 2.5339184027929624

Epoch: 6| Step: 9
Training loss: 2.1813147155430435
Validation loss: 2.5179362687223183

Epoch: 6| Step: 10
Training loss: 2.2051006143671588
Validation loss: 2.541028823446859

Epoch: 6| Step: 11
Training loss: 1.8385426968867915
Validation loss: 2.5175505351273006

Epoch: 6| Step: 12
Training loss: 2.2310807278748195
Validation loss: 2.493596506772793

Epoch: 6| Step: 13
Training loss: 1.913533289404238
Validation loss: 2.502123328362268

Epoch: 269| Step: 0
Training loss: 2.7090780163610035
Validation loss: 2.4724663716270645

Epoch: 6| Step: 1
Training loss: 1.9688442752609108
Validation loss: 2.506455978529001

Epoch: 6| Step: 2
Training loss: 1.9561911967156764
Validation loss: 2.4824740736760975

Epoch: 6| Step: 3
Training loss: 1.5765282134759726
Validation loss: 2.5223898587788547

Epoch: 6| Step: 4
Training loss: 2.4680742715204524
Validation loss: 2.532724978993762

Epoch: 6| Step: 5
Training loss: 1.6186630225656413
Validation loss: 2.5353106200442683

Epoch: 6| Step: 6
Training loss: 1.945339401855747
Validation loss: 2.555041476271995

Epoch: 6| Step: 7
Training loss: 2.6184257652565175
Validation loss: 2.5071645594858096

Epoch: 6| Step: 8
Training loss: 1.3826097673846705
Validation loss: 2.533038492571167

Epoch: 6| Step: 9
Training loss: 1.826854753568043
Validation loss: 2.5257115151599328

Epoch: 6| Step: 10
Training loss: 2.6000127902083148
Validation loss: 2.519303737885804

Epoch: 6| Step: 11
Training loss: 2.075928868510253
Validation loss: 2.5023800090918336

Epoch: 6| Step: 12
Training loss: 2.2871464857418315
Validation loss: 2.5098617752993095

Epoch: 6| Step: 13
Training loss: 2.8768675999253075
Validation loss: 2.527046197889364

Epoch: 270| Step: 0
Training loss: 2.2646958122874654
Validation loss: 2.494438621584528

Epoch: 6| Step: 1
Training loss: 1.9016056077846382
Validation loss: 2.513806177210572

Epoch: 6| Step: 2
Training loss: 2.4890872242879567
Validation loss: 2.5226404763921106

Epoch: 6| Step: 3
Training loss: 2.5631287896538275
Validation loss: 2.5001981815623346

Epoch: 6| Step: 4
Training loss: 2.5944036556344003
Validation loss: 2.47645815720751

Epoch: 6| Step: 5
Training loss: 2.131700610183118
Validation loss: 2.511118602096821

Epoch: 6| Step: 6
Training loss: 2.0268011818758325
Validation loss: 2.528097662288698

Epoch: 6| Step: 7
Training loss: 1.9637083864811065
Validation loss: 2.5208475149296956

Epoch: 6| Step: 8
Training loss: 2.279935170473336
Validation loss: 2.4860316577009693

Epoch: 6| Step: 9
Training loss: 2.181653739049663
Validation loss: 2.483523648818555

Epoch: 6| Step: 10
Training loss: 2.224019736902219
Validation loss: 2.5130024541996443

Epoch: 6| Step: 11
Training loss: 2.1570824384573877
Validation loss: 2.4914185743883364

Epoch: 6| Step: 12
Training loss: 1.9579142331713502
Validation loss: 2.5048148519655005

Epoch: 6| Step: 13
Training loss: 1.728637277233913
Validation loss: 2.506435693725212

Epoch: 271| Step: 0
Training loss: 2.6131265135429724
Validation loss: 2.5235427661272847

Epoch: 6| Step: 1
Training loss: 2.7051509255208277
Validation loss: 2.5352506223255955

Epoch: 6| Step: 2
Training loss: 1.7177685102659934
Validation loss: 2.5316906847598233

Epoch: 6| Step: 3
Training loss: 2.033187177230923
Validation loss: 2.5113745849602958

Epoch: 6| Step: 4
Training loss: 1.893715342591671
Validation loss: 2.5155919074810065

Epoch: 6| Step: 5
Training loss: 2.3875277532592176
Validation loss: 2.511400328168974

Epoch: 6| Step: 6
Training loss: 2.891548627776624
Validation loss: 2.494008705276922

Epoch: 6| Step: 7
Training loss: 2.2229150711907115
Validation loss: 2.50229634678651

Epoch: 6| Step: 8
Training loss: 2.2195902563118057
Validation loss: 2.478335863773548

Epoch: 6| Step: 9
Training loss: 1.7842360781489537
Validation loss: 2.482413647325649

Epoch: 6| Step: 10
Training loss: 1.7937785129739896
Validation loss: 2.487140739478413

Epoch: 6| Step: 11
Training loss: 1.768888984314891
Validation loss: 2.53574830338797

Epoch: 6| Step: 12
Training loss: 1.8495219772943032
Validation loss: 2.5186785376218364

Epoch: 6| Step: 13
Training loss: 2.156639837877392
Validation loss: 2.5400491294089367

Epoch: 272| Step: 0
Training loss: 1.8290864421425221
Validation loss: 2.513329345002623

Epoch: 6| Step: 1
Training loss: 2.2938787938684713
Validation loss: 2.4952100563558277

Epoch: 6| Step: 2
Training loss: 2.3498553292403717
Validation loss: 2.4820143162245056

Epoch: 6| Step: 3
Training loss: 2.468134163448028
Validation loss: 2.4972811935466996

Epoch: 6| Step: 4
Training loss: 2.664798310540247
Validation loss: 2.467060444519559

Epoch: 6| Step: 5
Training loss: 1.2363178077978378
Validation loss: 2.4794283870317906

Epoch: 6| Step: 6
Training loss: 1.965346588649502
Validation loss: 2.461635849780681

Epoch: 6| Step: 7
Training loss: 2.1272234784274198
Validation loss: 2.483125816439176

Epoch: 6| Step: 8
Training loss: 2.1269443816538613
Validation loss: 2.487160758267634

Epoch: 6| Step: 9
Training loss: 2.266299338121936
Validation loss: 2.489096595289578

Epoch: 6| Step: 10
Training loss: 2.557620543382678
Validation loss: 2.524599357017297

Epoch: 6| Step: 11
Training loss: 2.099202813108234
Validation loss: 2.520736461280836

Epoch: 6| Step: 12
Training loss: 2.1155671961225466
Validation loss: 2.4978271658174256

Epoch: 6| Step: 13
Training loss: 2.0797416880574833
Validation loss: 2.4933298615909143

Epoch: 273| Step: 0
Training loss: 1.8473538237933234
Validation loss: 2.4988431638187882

Epoch: 6| Step: 1
Training loss: 1.5992361152574532
Validation loss: 2.512198220976817

Epoch: 6| Step: 2
Training loss: 1.5216102792849937
Validation loss: 2.4955375182966364

Epoch: 6| Step: 3
Training loss: 1.714054282211314
Validation loss: 2.4962443036208777

Epoch: 6| Step: 4
Training loss: 2.0873199339543875
Validation loss: 2.507876259695379

Epoch: 6| Step: 5
Training loss: 2.9288923074467257
Validation loss: 2.4861501593574853

Epoch: 6| Step: 6
Training loss: 2.0306291071414946
Validation loss: 2.4987805968906915

Epoch: 6| Step: 7
Training loss: 2.2665838908994442
Validation loss: 2.464330749811013

Epoch: 6| Step: 8
Training loss: 2.3145398602550515
Validation loss: 2.4839450776083654

Epoch: 6| Step: 9
Training loss: 2.206656797258294
Validation loss: 2.505253675741782

Epoch: 6| Step: 10
Training loss: 1.9478515233317453
Validation loss: 2.4927239234352836

Epoch: 6| Step: 11
Training loss: 2.6933514966289325
Validation loss: 2.531302337733334

Epoch: 6| Step: 12
Training loss: 1.8794300515041
Validation loss: 2.5244938201405556

Epoch: 6| Step: 13
Training loss: 2.3666582680494983
Validation loss: 2.538137132305202

Epoch: 274| Step: 0
Training loss: 2.3259490424467777
Validation loss: 2.5530286530299926

Epoch: 6| Step: 1
Training loss: 2.6136947783625573
Validation loss: 2.5294318242936678

Epoch: 6| Step: 2
Training loss: 1.3977452274869424
Validation loss: 2.5223116651459403

Epoch: 6| Step: 3
Training loss: 2.452349497681123
Validation loss: 2.4977139193157676

Epoch: 6| Step: 4
Training loss: 1.6693271224776765
Validation loss: 2.5164058965986515

Epoch: 6| Step: 5
Training loss: 1.9378430462751803
Validation loss: 2.5021708044113917

Epoch: 6| Step: 6
Training loss: 2.361509052725294
Validation loss: 2.4958482441485943

Epoch: 6| Step: 7
Training loss: 2.219519790571493
Validation loss: 2.4942037464380338

Epoch: 6| Step: 8
Training loss: 1.8300074479206883
Validation loss: 2.50089317102314

Epoch: 6| Step: 9
Training loss: 2.482735530747729
Validation loss: 2.4752570561455247

Epoch: 6| Step: 10
Training loss: 2.0482314179996624
Validation loss: 2.498773496490937

Epoch: 6| Step: 11
Training loss: 2.2957683154786577
Validation loss: 2.494307553991555

Epoch: 6| Step: 12
Training loss: 2.2322561180807603
Validation loss: 2.496189455875011

Epoch: 6| Step: 13
Training loss: 1.7776488995859039
Validation loss: 2.50341374656282

Epoch: 275| Step: 0
Training loss: 1.7072646201945145
Validation loss: 2.5309224721362957

Epoch: 6| Step: 1
Training loss: 1.925770974276908
Validation loss: 2.5200347318476033

Epoch: 6| Step: 2
Training loss: 2.191965178066912
Validation loss: 2.5264978265673084

Epoch: 6| Step: 3
Training loss: 1.9590811890918383
Validation loss: 2.539212438606711

Epoch: 6| Step: 4
Training loss: 1.9251865915799673
Validation loss: 2.5308348389806237

Epoch: 6| Step: 5
Training loss: 2.0345345570799815
Validation loss: 2.5480163606700303

Epoch: 6| Step: 6
Training loss: 2.3039984238672164
Validation loss: 2.5560279385990414

Epoch: 6| Step: 7
Training loss: 1.9640462481691998
Validation loss: 2.5490870864291653

Epoch: 6| Step: 8
Training loss: 1.988197669650152
Validation loss: 2.5416752914115617

Epoch: 6| Step: 9
Training loss: 2.6050512617050052
Validation loss: 2.5392912776289003

Epoch: 6| Step: 10
Training loss: 2.38653683632507
Validation loss: 2.5568087886547852

Epoch: 6| Step: 11
Training loss: 2.268019680038727
Validation loss: 2.5867230316129746

Epoch: 6| Step: 12
Training loss: 2.0237159095611923
Validation loss: 2.591491543249117

Epoch: 6| Step: 13
Training loss: 2.3841199945999203
Validation loss: 2.545308073792064

Epoch: 276| Step: 0
Training loss: 1.6922217819108651
Validation loss: 2.5087523952055175

Epoch: 6| Step: 1
Training loss: 1.6366258107749092
Validation loss: 2.5081317892457196

Epoch: 6| Step: 2
Training loss: 1.3872135193084592
Validation loss: 2.4826469489428407

Epoch: 6| Step: 3
Training loss: 2.4604408368488158
Validation loss: 2.4888726873476013

Epoch: 6| Step: 4
Training loss: 1.477361230933396
Validation loss: 2.505181093656049

Epoch: 6| Step: 5
Training loss: 2.8853227804358816
Validation loss: 2.4869346787765996

Epoch: 6| Step: 6
Training loss: 2.1582930464157415
Validation loss: 2.469743166709704

Epoch: 6| Step: 7
Training loss: 1.5956523238164937
Validation loss: 2.4942967369235753

Epoch: 6| Step: 8
Training loss: 2.4658829664069852
Validation loss: 2.490129807215283

Epoch: 6| Step: 9
Training loss: 2.66648669430274
Validation loss: 2.5015785002330766

Epoch: 6| Step: 10
Training loss: 1.5750993485376317
Validation loss: 2.536923004971833

Epoch: 6| Step: 11
Training loss: 2.5409694611727045
Validation loss: 2.4951316001958572

Epoch: 6| Step: 12
Training loss: 2.0160085623650144
Validation loss: 2.5141106543424936

Epoch: 6| Step: 13
Training loss: 2.484255038070215
Validation loss: 2.5280442836782027

Epoch: 277| Step: 0
Training loss: 2.258923531111485
Validation loss: 2.513781288530176

Epoch: 6| Step: 1
Training loss: 2.1764515472634463
Validation loss: 2.508840768018194

Epoch: 6| Step: 2
Training loss: 3.106992028871053
Validation loss: 2.496115973447789

Epoch: 6| Step: 3
Training loss: 2.2312919847828523
Validation loss: 2.5075069570143778

Epoch: 6| Step: 4
Training loss: 1.5925219423228634
Validation loss: 2.5265041019797203

Epoch: 6| Step: 5
Training loss: 1.590230308982919
Validation loss: 2.551634205334086

Epoch: 6| Step: 6
Training loss: 2.2356000622986674
Validation loss: 2.5198047420503618

Epoch: 6| Step: 7
Training loss: 2.0274225414451865
Validation loss: 2.533715291675532

Epoch: 6| Step: 8
Training loss: 1.628820622889922
Validation loss: 2.5546446319312035

Epoch: 6| Step: 9
Training loss: 1.6381720234082828
Validation loss: 2.5297475994998577

Epoch: 6| Step: 10
Training loss: 1.6680874570107078
Validation loss: 2.531489608161659

Epoch: 6| Step: 11
Training loss: 1.8782512450989022
Validation loss: 2.5402783969562996

Epoch: 6| Step: 12
Training loss: 3.301508824444257
Validation loss: 2.533277908040961

Epoch: 6| Step: 13
Training loss: 1.9918542919871958
Validation loss: 2.5500876791846068

Epoch: 278| Step: 0
Training loss: 1.324387891201703
Validation loss: 2.538095346775596

Epoch: 6| Step: 1
Training loss: 1.6200749516514679
Validation loss: 2.5566546053852663

Epoch: 6| Step: 2
Training loss: 2.7625255566273568
Validation loss: 2.585700140409811

Epoch: 6| Step: 3
Training loss: 2.694920431176233
Validation loss: 2.6109805240735073

Epoch: 6| Step: 4
Training loss: 2.163031818065924
Validation loss: 2.611389965921949

Epoch: 6| Step: 5
Training loss: 2.2581311697285673
Validation loss: 2.634583297464842

Epoch: 6| Step: 6
Training loss: 2.626584891564793
Validation loss: 2.643211482447706

Epoch: 6| Step: 7
Training loss: 2.4436774591864885
Validation loss: 2.6271976626569313

Epoch: 6| Step: 8
Training loss: 2.630127938933521
Validation loss: 2.537719449605934

Epoch: 6| Step: 9
Training loss: 1.6434040329189985
Validation loss: 2.4955744832542925

Epoch: 6| Step: 10
Training loss: 1.468376030894702
Validation loss: 2.4553409295145414

Epoch: 6| Step: 11
Training loss: 2.043305991001781
Validation loss: 2.44293274218051

Epoch: 6| Step: 12
Training loss: 1.9590312309404485
Validation loss: 2.457465080447773

Epoch: 6| Step: 13
Training loss: 1.9540916797210737
Validation loss: 2.421503165629012

Epoch: 279| Step: 0
Training loss: 2.396372350236708
Validation loss: 2.4480665499205623

Epoch: 6| Step: 1
Training loss: 3.031479659671487
Validation loss: 2.4382980051130088

Epoch: 6| Step: 2
Training loss: 1.5496365336371805
Validation loss: 2.43775692425265

Epoch: 6| Step: 3
Training loss: 1.8275573370793323
Validation loss: 2.443492053338062

Epoch: 6| Step: 4
Training loss: 2.3957114368333716
Validation loss: 2.414568275051432

Epoch: 6| Step: 5
Training loss: 1.8625737732479257
Validation loss: 2.4155365230647297

Epoch: 6| Step: 6
Training loss: 2.069776357649496
Validation loss: 2.422660486963285

Epoch: 6| Step: 7
Training loss: 2.2256142186388725
Validation loss: 2.4610163277409005

Epoch: 6| Step: 8
Training loss: 2.4307492012509897
Validation loss: 2.456691522364693

Epoch: 6| Step: 9
Training loss: 2.203856867440144
Validation loss: 2.501029152437037

Epoch: 6| Step: 10
Training loss: 1.843615769494768
Validation loss: 2.4815166912999675

Epoch: 6| Step: 11
Training loss: 1.81600967507999
Validation loss: 2.549225594233433

Epoch: 6| Step: 12
Training loss: 2.3353066501572237
Validation loss: 2.5375310808229474

Epoch: 6| Step: 13
Training loss: 1.3974944189980425
Validation loss: 2.5682443803346806

Epoch: 280| Step: 0
Training loss: 1.4609404375179358
Validation loss: 2.5779983489398983

Epoch: 6| Step: 1
Training loss: 1.491356903107056
Validation loss: 2.6060235587592424

Epoch: 6| Step: 2
Training loss: 2.618798150323203
Validation loss: 2.582074555973115

Epoch: 6| Step: 3
Training loss: 2.3872765920877552
Validation loss: 2.561299515793672

Epoch: 6| Step: 4
Training loss: 1.9968350521384104
Validation loss: 2.5942977572008137

Epoch: 6| Step: 5
Training loss: 1.5965760550275407
Validation loss: 2.6083310869672403

Epoch: 6| Step: 6
Training loss: 2.430597950399114
Validation loss: 2.5956293980155274

Epoch: 6| Step: 7
Training loss: 1.4147665894825423
Validation loss: 2.579551101981894

Epoch: 6| Step: 8
Training loss: 2.135692175483258
Validation loss: 2.6086804042246143

Epoch: 6| Step: 9
Training loss: 2.3639812851373194
Validation loss: 2.579769172815813

Epoch: 6| Step: 10
Training loss: 2.6171961542242643
Validation loss: 2.559765993216543

Epoch: 6| Step: 11
Training loss: 2.887074202151803
Validation loss: 2.5905292997948317

Epoch: 6| Step: 12
Training loss: 2.0198924702643613
Validation loss: 2.5564295344274206

Epoch: 6| Step: 13
Training loss: 3.0732901308522034
Validation loss: 2.570971619912184

Epoch: 281| Step: 0
Training loss: 2.1889001997167594
Validation loss: 2.543866711437671

Epoch: 6| Step: 1
Training loss: 2.122824958215504
Validation loss: 2.5603159924779795

Epoch: 6| Step: 2
Training loss: 1.9382547323680128
Validation loss: 2.539725630802398

Epoch: 6| Step: 3
Training loss: 2.5200147534498645
Validation loss: 2.543608273018828

Epoch: 6| Step: 4
Training loss: 2.1569305672751495
Validation loss: 2.551493554508521

Epoch: 6| Step: 5
Training loss: 2.265589641426674
Validation loss: 2.587671633877504

Epoch: 6| Step: 6
Training loss: 1.9532891776700099
Validation loss: 2.5813899472579265

Epoch: 6| Step: 7
Training loss: 2.70699390644336
Validation loss: 2.5486723441778247

Epoch: 6| Step: 8
Training loss: 2.277019392571778
Validation loss: 2.582093684855057

Epoch: 6| Step: 9
Training loss: 1.9233666190777166
Validation loss: 2.5387437199725125

Epoch: 6| Step: 10
Training loss: 2.618677608973424
Validation loss: 2.5291803320861694

Epoch: 6| Step: 11
Training loss: 1.535555566779132
Validation loss: 2.507126465761826

Epoch: 6| Step: 12
Training loss: 1.9057538371762464
Validation loss: 2.488427693335984

Epoch: 6| Step: 13
Training loss: 2.0645510560972866
Validation loss: 2.513230457687937

Epoch: 282| Step: 0
Training loss: 2.3765330135364646
Validation loss: 2.5295976025522346

Epoch: 6| Step: 1
Training loss: 1.926434264977568
Validation loss: 2.558348533779884

Epoch: 6| Step: 2
Training loss: 2.0403064426560653
Validation loss: 2.5492072475063563

Epoch: 6| Step: 3
Training loss: 3.007223968395728
Validation loss: 2.579662119083789

Epoch: 6| Step: 4
Training loss: 1.9920295802336874
Validation loss: 2.6458023224662823

Epoch: 6| Step: 5
Training loss: 2.2690876775137245
Validation loss: 2.6448537760399713

Epoch: 6| Step: 6
Training loss: 2.2137291204328373
Validation loss: 2.6294113966207027

Epoch: 6| Step: 7
Training loss: 2.038720580917273
Validation loss: 2.591526043215853

Epoch: 6| Step: 8
Training loss: 1.1513098264840955
Validation loss: 2.529572421545569

Epoch: 6| Step: 9
Training loss: 1.8132697476897812
Validation loss: 2.516611944218396

Epoch: 6| Step: 10
Training loss: 2.3242255202763786
Validation loss: 2.5062211514633574

Epoch: 6| Step: 11
Training loss: 1.5517525885885952
Validation loss: 2.4742727996668896

Epoch: 6| Step: 12
Training loss: 2.382623383568466
Validation loss: 2.471029074658001

Epoch: 6| Step: 13
Training loss: 2.3741359142678635
Validation loss: 2.46691618787132

Epoch: 283| Step: 0
Training loss: 2.3569086586008785
Validation loss: 2.46053698474612

Epoch: 6| Step: 1
Training loss: 3.097178399460699
Validation loss: 2.4646398074036804

Epoch: 6| Step: 2
Training loss: 2.2254373484911514
Validation loss: 2.4403417764038347

Epoch: 6| Step: 3
Training loss: 2.210551737098989
Validation loss: 2.4370839342584083

Epoch: 6| Step: 4
Training loss: 2.2428678218146496
Validation loss: 2.437756590094285

Epoch: 6| Step: 5
Training loss: 2.217850086226381
Validation loss: 2.451151002995154

Epoch: 6| Step: 6
Training loss: 2.370372077932449
Validation loss: 2.458209169344925

Epoch: 6| Step: 7
Training loss: 1.6757497362139193
Validation loss: 2.4831505963171003

Epoch: 6| Step: 8
Training loss: 1.6438504438569825
Validation loss: 2.485759325433722

Epoch: 6| Step: 9
Training loss: 2.135044146043402
Validation loss: 2.4699291439292312

Epoch: 6| Step: 10
Training loss: 2.317017035667411
Validation loss: 2.454044372240339

Epoch: 6| Step: 11
Training loss: 1.5753331937000172
Validation loss: 2.4357982629145196

Epoch: 6| Step: 12
Training loss: 2.2934013621457203
Validation loss: 2.465495076400677

Epoch: 6| Step: 13
Training loss: 2.0397849721340595
Validation loss: 2.4911122807859103

Epoch: 284| Step: 0
Training loss: 1.5306394488648412
Validation loss: 2.4816599631320377

Epoch: 6| Step: 1
Training loss: 2.004579784089126
Validation loss: 2.5059900049069634

Epoch: 6| Step: 2
Training loss: 1.5496131475742614
Validation loss: 2.5127693617053315

Epoch: 6| Step: 3
Training loss: 1.9383284735625539
Validation loss: 2.516688183404086

Epoch: 6| Step: 4
Training loss: 2.661573125126704
Validation loss: 2.548438904569119

Epoch: 6| Step: 5
Training loss: 2.5603261891812386
Validation loss: 2.5470679976466912

Epoch: 6| Step: 6
Training loss: 1.3958620191824367
Validation loss: 2.555674464343443

Epoch: 6| Step: 7
Training loss: 1.747156967308406
Validation loss: 2.5550937232403705

Epoch: 6| Step: 8
Training loss: 2.61022259314772
Validation loss: 2.5389078885468193

Epoch: 6| Step: 9
Training loss: 1.9367324785528448
Validation loss: 2.5257045927331276

Epoch: 6| Step: 10
Training loss: 2.68962137642058
Validation loss: 2.5226899999410777

Epoch: 6| Step: 11
Training loss: 2.0832597210912613
Validation loss: 2.493655291729174

Epoch: 6| Step: 12
Training loss: 1.8069934067513491
Validation loss: 2.533882883241768

Epoch: 6| Step: 13
Training loss: 2.3417424059618783
Validation loss: 2.518554797942312

Epoch: 285| Step: 0
Training loss: 1.642344128138038
Validation loss: 2.5452919781417447

Epoch: 6| Step: 1
Training loss: 2.005342738283369
Validation loss: 2.5177665977275634

Epoch: 6| Step: 2
Training loss: 2.7741326119175773
Validation loss: 2.4985570558114176

Epoch: 6| Step: 3
Training loss: 1.8104802420822534
Validation loss: 2.4720404703382903

Epoch: 6| Step: 4
Training loss: 1.858980537694348
Validation loss: 2.4710537909140173

Epoch: 6| Step: 5
Training loss: 2.338565942401811
Validation loss: 2.473005498133151

Epoch: 6| Step: 6
Training loss: 2.0144868934793903
Validation loss: 2.480271795668653

Epoch: 6| Step: 7
Training loss: 1.7596766103232437
Validation loss: 2.439512807433117

Epoch: 6| Step: 8
Training loss: 1.6655616275834169
Validation loss: 2.4390801907471475

Epoch: 6| Step: 9
Training loss: 1.9308122453565617
Validation loss: 2.449799245277679

Epoch: 6| Step: 10
Training loss: 2.334400909157485
Validation loss: 2.454263208451726

Epoch: 6| Step: 11
Training loss: 1.8215144695468535
Validation loss: 2.47328460085827

Epoch: 6| Step: 12
Training loss: 2.461069836161574
Validation loss: 2.4951212485442733

Epoch: 6| Step: 13
Training loss: 2.9975558497019734
Validation loss: 2.5382107758652563

Epoch: 286| Step: 0
Training loss: 1.6963089506381244
Validation loss: 2.508422222864768

Epoch: 6| Step: 1
Training loss: 2.2090342387027935
Validation loss: 2.5790632602091645

Epoch: 6| Step: 2
Training loss: 2.34115141180871
Validation loss: 2.5706545091093562

Epoch: 6| Step: 3
Training loss: 2.5647339736076327
Validation loss: 2.574897425809097

Epoch: 6| Step: 4
Training loss: 2.1818038893000318
Validation loss: 2.519631538070874

Epoch: 6| Step: 5
Training loss: 2.378646260102726
Validation loss: 2.4925695463303033

Epoch: 6| Step: 6
Training loss: 1.6033015044311933
Validation loss: 2.51165124338735

Epoch: 6| Step: 7
Training loss: 1.615384409715828
Validation loss: 2.514709037371549

Epoch: 6| Step: 8
Training loss: 2.360263884387267
Validation loss: 2.5294133339954

Epoch: 6| Step: 9
Training loss: 1.850593216612498
Validation loss: 2.527633328089121

Epoch: 6| Step: 10
Training loss: 2.136226506692754
Validation loss: 2.5382652713503218

Epoch: 6| Step: 11
Training loss: 1.6713596868934024
Validation loss: 2.5373446399752857

Epoch: 6| Step: 12
Training loss: 2.278492763645919
Validation loss: 2.5618882107989283

Epoch: 6| Step: 13
Training loss: 2.3051847277118016
Validation loss: 2.552741410922623

Epoch: 287| Step: 0
Training loss: 2.306028021490823
Validation loss: 2.537765406366685

Epoch: 6| Step: 1
Training loss: 1.5848780508691225
Validation loss: 2.5397391801622344

Epoch: 6| Step: 2
Training loss: 1.7355919769629171
Validation loss: 2.542412575463054

Epoch: 6| Step: 3
Training loss: 1.3380637397979533
Validation loss: 2.531331394598018

Epoch: 6| Step: 4
Training loss: 1.5599374739025125
Validation loss: 2.517374997740112

Epoch: 6| Step: 5
Training loss: 1.7270941972870184
Validation loss: 2.519966549197206

Epoch: 6| Step: 6
Training loss: 2.9768261730123
Validation loss: 2.498421488558112

Epoch: 6| Step: 7
Training loss: 1.8177071455666525
Validation loss: 2.5208537886449074

Epoch: 6| Step: 8
Training loss: 1.7493433401521323
Validation loss: 2.5204587032751733

Epoch: 6| Step: 9
Training loss: 2.1271740507034407
Validation loss: 2.529899142520445

Epoch: 6| Step: 10
Training loss: 2.2827950040236877
Validation loss: 2.546139452917076

Epoch: 6| Step: 11
Training loss: 2.0163012412572696
Validation loss: 2.570040981248001

Epoch: 6| Step: 12
Training loss: 2.577632232737264
Validation loss: 2.566105097690028

Epoch: 6| Step: 13
Training loss: 2.5222420237469243
Validation loss: 2.584548039084405

Epoch: 288| Step: 0
Training loss: 2.4453047974681503
Validation loss: 2.563483561188363

Epoch: 6| Step: 1
Training loss: 2.145051375442974
Validation loss: 2.5344013957488585

Epoch: 6| Step: 2
Training loss: 1.8340554838034966
Validation loss: 2.5332651397871073

Epoch: 6| Step: 3
Training loss: 1.5116877589634625
Validation loss: 2.522923435881459

Epoch: 6| Step: 4
Training loss: 2.1536141469731684
Validation loss: 2.5189722747160332

Epoch: 6| Step: 5
Training loss: 2.286870434118708
Validation loss: 2.5502817503163655

Epoch: 6| Step: 6
Training loss: 2.083977281867615
Validation loss: 2.532624848537253

Epoch: 6| Step: 7
Training loss: 1.8112197168950162
Validation loss: 2.5163348284422287

Epoch: 6| Step: 8
Training loss: 2.56883907117281
Validation loss: 2.52164939933289

Epoch: 6| Step: 9
Training loss: 1.8653588697818257
Validation loss: 2.5324239481044124

Epoch: 6| Step: 10
Training loss: 2.5190415963754984
Validation loss: 2.4828619678163424

Epoch: 6| Step: 11
Training loss: 1.6496693857899891
Validation loss: 2.4751892293652973

Epoch: 6| Step: 12
Training loss: 2.0603351213025403
Validation loss: 2.5161976053992685

Epoch: 6| Step: 13
Training loss: 1.2105043682600993
Validation loss: 2.5250380944377886

Epoch: 289| Step: 0
Training loss: 1.8930572123841745
Validation loss: 2.5364420509729624

Epoch: 6| Step: 1
Training loss: 2.6661946554471343
Validation loss: 2.494271709330202

Epoch: 6| Step: 2
Training loss: 2.656417572121214
Validation loss: 2.559717140415791

Epoch: 6| Step: 3
Training loss: 1.6774649176077239
Validation loss: 2.5803358443571205

Epoch: 6| Step: 4
Training loss: 1.9996762609724854
Validation loss: 2.5868899616805088

Epoch: 6| Step: 5
Training loss: 2.082013042434751
Validation loss: 2.5942417276145235

Epoch: 6| Step: 6
Training loss: 2.330975215150045
Validation loss: 2.591118055542978

Epoch: 6| Step: 7
Training loss: 2.247261181831443
Validation loss: 2.586648249839161

Epoch: 6| Step: 8
Training loss: 2.1466165489759463
Validation loss: 2.5119613996954806

Epoch: 6| Step: 9
Training loss: 1.909160830509496
Validation loss: 2.489930074212931

Epoch: 6| Step: 10
Training loss: 1.7197735599679096
Validation loss: 2.4675967665626333

Epoch: 6| Step: 11
Training loss: 1.8269186359614091
Validation loss: 2.4645691893540667

Epoch: 6| Step: 12
Training loss: 1.886605774713448
Validation loss: 2.441098141365437

Epoch: 6| Step: 13
Training loss: 1.6125859200704238
Validation loss: 2.4476794080534665

Epoch: 290| Step: 0
Training loss: 1.9750138801376689
Validation loss: 2.4540925112424694

Epoch: 6| Step: 1
Training loss: 2.022921581111744
Validation loss: 2.447294478108086

Epoch: 6| Step: 2
Training loss: 1.8646902838638721
Validation loss: 2.4391952553461573

Epoch: 6| Step: 3
Training loss: 1.8628176706258646
Validation loss: 2.445697709395249

Epoch: 6| Step: 4
Training loss: 1.8053290477731871
Validation loss: 2.4410818550760767

Epoch: 6| Step: 5
Training loss: 1.810327675069471
Validation loss: 2.4779235597622256

Epoch: 6| Step: 6
Training loss: 2.2168283872003083
Validation loss: 2.4618650757111085

Epoch: 6| Step: 7
Training loss: 2.395900515291652
Validation loss: 2.440925213026649

Epoch: 6| Step: 8
Training loss: 2.14500313658585
Validation loss: 2.468080212478201

Epoch: 6| Step: 9
Training loss: 1.7958983047427222
Validation loss: 2.5228471567378743

Epoch: 6| Step: 10
Training loss: 1.8792223119285665
Validation loss: 2.5945982867238264

Epoch: 6| Step: 11
Training loss: 2.716395882605099
Validation loss: 2.631900361451559

Epoch: 6| Step: 12
Training loss: 2.8489757772094126
Validation loss: 2.6990588113643943

Epoch: 6| Step: 13
Training loss: 1.771115164675688
Validation loss: 2.658650962444911

Epoch: 291| Step: 0
Training loss: 1.7138875672087819
Validation loss: 2.590491427240187

Epoch: 6| Step: 1
Training loss: 1.8841146817544534
Validation loss: 2.51782836143949

Epoch: 6| Step: 2
Training loss: 2.2060242102393413
Validation loss: 2.4708900672441754

Epoch: 6| Step: 3
Training loss: 1.618698814496008
Validation loss: 2.4780269749332646

Epoch: 6| Step: 4
Training loss: 3.087781292537876
Validation loss: 2.492731080919199

Epoch: 6| Step: 5
Training loss: 2.538554261032459
Validation loss: 2.5237678965034296

Epoch: 6| Step: 6
Training loss: 1.8204142660746685
Validation loss: 2.532767566970292

Epoch: 6| Step: 7
Training loss: 2.3746385801276095
Validation loss: 2.5229867034523434

Epoch: 6| Step: 8
Training loss: 2.8196253903792847
Validation loss: 2.5289969130165746

Epoch: 6| Step: 9
Training loss: 2.4166578643463135
Validation loss: 2.4968185844938966

Epoch: 6| Step: 10
Training loss: 2.209322390004146
Validation loss: 2.485627064801955

Epoch: 6| Step: 11
Training loss: 2.4973539654534096
Validation loss: 2.4893202675943216

Epoch: 6| Step: 12
Training loss: 1.7741020402773924
Validation loss: 2.5137339685334483

Epoch: 6| Step: 13
Training loss: 1.9626942702434975
Validation loss: 2.5673722414089535

Epoch: 292| Step: 0
Training loss: 2.736660857463561
Validation loss: 2.582238254915457

Epoch: 6| Step: 1
Training loss: 2.0800778957599637
Validation loss: 2.611112263749141

Epoch: 6| Step: 2
Training loss: 2.445368854494898
Validation loss: 2.551551208035053

Epoch: 6| Step: 3
Training loss: 2.0413639337217413
Validation loss: 2.496700167433307

Epoch: 6| Step: 4
Training loss: 1.7856439304116094
Validation loss: 2.481953974741512

Epoch: 6| Step: 5
Training loss: 1.6140668309496136
Validation loss: 2.4573359055449586

Epoch: 6| Step: 6
Training loss: 2.449383743788367
Validation loss: 2.461604323694298

Epoch: 6| Step: 7
Training loss: 2.2102762588168265
Validation loss: 2.439359949723447

Epoch: 6| Step: 8
Training loss: 1.6133168657634152
Validation loss: 2.4317005155201974

Epoch: 6| Step: 9
Training loss: 2.448201870367574
Validation loss: 2.428433780682863

Epoch: 6| Step: 10
Training loss: 2.315608023762734
Validation loss: 2.4294177658966087

Epoch: 6| Step: 11
Training loss: 1.6001750611856285
Validation loss: 2.4540530350635086

Epoch: 6| Step: 12
Training loss: 1.5969161952130397
Validation loss: 2.45976347999667

Epoch: 6| Step: 13
Training loss: 2.1807802803992367
Validation loss: 2.467422522797505

Epoch: 293| Step: 0
Training loss: 2.6185821005956287
Validation loss: 2.508872191528251

Epoch: 6| Step: 1
Training loss: 1.5874026441383136
Validation loss: 2.5477003542722394

Epoch: 6| Step: 2
Training loss: 2.4224907861304072
Validation loss: 2.5191123752209816

Epoch: 6| Step: 3
Training loss: 1.6613939406334401
Validation loss: 2.531570657584246

Epoch: 6| Step: 4
Training loss: 2.772331339570717
Validation loss: 2.524005436244557

Epoch: 6| Step: 5
Training loss: 1.6254078279926563
Validation loss: 2.533729571068938

Epoch: 6| Step: 6
Training loss: 1.7747798998128024
Validation loss: 2.5568280754797024

Epoch: 6| Step: 7
Training loss: 1.956430369584076
Validation loss: 2.5217402274459673

Epoch: 6| Step: 8
Training loss: 1.9273042981733757
Validation loss: 2.5324398431038033

Epoch: 6| Step: 9
Training loss: 2.2086614209101394
Validation loss: 2.5449792714452064

Epoch: 6| Step: 10
Training loss: 2.229143112866278
Validation loss: 2.541488294648157

Epoch: 6| Step: 11
Training loss: 1.402467557494477
Validation loss: 2.546409899909965

Epoch: 6| Step: 12
Training loss: 2.5806993982553013
Validation loss: 2.511265517535448

Epoch: 6| Step: 13
Training loss: 1.5316445757020347
Validation loss: 2.5711194658688608

Epoch: 294| Step: 0
Training loss: 2.0583571238307634
Validation loss: 2.570682842934168

Epoch: 6| Step: 1
Training loss: 2.5849411995728304
Validation loss: 2.57800608659336

Epoch: 6| Step: 2
Training loss: 1.913357725597149
Validation loss: 2.571060782891274

Epoch: 6| Step: 3
Training loss: 1.5404881105097261
Validation loss: 2.5236153712143667

Epoch: 6| Step: 4
Training loss: 2.5426204226022096
Validation loss: 2.481910282685711

Epoch: 6| Step: 5
Training loss: 2.1525886520933
Validation loss: 2.4869140190392742

Epoch: 6| Step: 6
Training loss: 2.3980186668286674
Validation loss: 2.4571902047286773

Epoch: 6| Step: 7
Training loss: 1.2572215332765069
Validation loss: 2.4795830214054777

Epoch: 6| Step: 8
Training loss: 2.4525200164631364
Validation loss: 2.4558610823398674

Epoch: 6| Step: 9
Training loss: 1.509662185421963
Validation loss: 2.4624429286275125

Epoch: 6| Step: 10
Training loss: 1.8320119893377196
Validation loss: 2.4404993921211546

Epoch: 6| Step: 11
Training loss: 1.5947923430630948
Validation loss: 2.4748722891176884

Epoch: 6| Step: 12
Training loss: 2.3882522276767437
Validation loss: 2.4330440694416353

Epoch: 6| Step: 13
Training loss: 2.0814998442379236
Validation loss: 2.4294186982089094

Epoch: 295| Step: 0
Training loss: 2.4877043673654593
Validation loss: 2.460425865636345

Epoch: 6| Step: 1
Training loss: 1.434154515160449
Validation loss: 2.4315884299849158

Epoch: 6| Step: 2
Training loss: 1.5041933256342312
Validation loss: 2.458378651303624

Epoch: 6| Step: 3
Training loss: 1.9022023111202
Validation loss: 2.4424979492772376

Epoch: 6| Step: 4
Training loss: 1.8263569947114249
Validation loss: 2.456170137901189

Epoch: 6| Step: 5
Training loss: 1.6630518893543824
Validation loss: 2.4609600732161647

Epoch: 6| Step: 6
Training loss: 1.4739886259419128
Validation loss: 2.4440060376531316

Epoch: 6| Step: 7
Training loss: 2.619557324059858
Validation loss: 2.474625689526266

Epoch: 6| Step: 8
Training loss: 1.6390471364074923
Validation loss: 2.4759826783656407

Epoch: 6| Step: 9
Training loss: 2.298092266531247
Validation loss: 2.487640873356094

Epoch: 6| Step: 10
Training loss: 1.9053943151846262
Validation loss: 2.436273176429758

Epoch: 6| Step: 11
Training loss: 1.458690853799395
Validation loss: 2.474272968295223

Epoch: 6| Step: 12
Training loss: 2.8573397704796752
Validation loss: 2.472710342177145

Epoch: 6| Step: 13
Training loss: 2.443055985579442
Validation loss: 2.478638453805584

Epoch: 296| Step: 0
Training loss: 1.9287773178845928
Validation loss: 2.4926247128527486

Epoch: 6| Step: 1
Training loss: 2.0143220223784644
Validation loss: 2.5050495174029

Epoch: 6| Step: 2
Training loss: 2.019979578424846
Validation loss: 2.5554199413123286

Epoch: 6| Step: 3
Training loss: 2.0409443674014334
Validation loss: 2.5361557035180593

Epoch: 6| Step: 4
Training loss: 1.5562618086646458
Validation loss: 2.5132487271139126

Epoch: 6| Step: 5
Training loss: 2.1541970472819023
Validation loss: 2.552874591676376

Epoch: 6| Step: 6
Training loss: 2.031673563297991
Validation loss: 2.5597880209141906

Epoch: 6| Step: 7
Training loss: 2.07724117902388
Validation loss: 2.5526937546206465

Epoch: 6| Step: 8
Training loss: 1.872883428576411
Validation loss: 2.5329605256960672

Epoch: 6| Step: 9
Training loss: 2.7126986804397157
Validation loss: 2.494206247683719

Epoch: 6| Step: 10
Training loss: 1.9527337254559207
Validation loss: 2.4804721301598933

Epoch: 6| Step: 11
Training loss: 2.413270098066759
Validation loss: 2.5186101447087976

Epoch: 6| Step: 12
Training loss: 1.7578490528968593
Validation loss: 2.4964868656839005

Epoch: 6| Step: 13
Training loss: 1.7592255740630938
Validation loss: 2.515364955311378

Epoch: 297| Step: 0
Training loss: 1.91617626329505
Validation loss: 2.52567322131565

Epoch: 6| Step: 1
Training loss: 2.7089108853867896
Validation loss: 2.516676483598303

Epoch: 6| Step: 2
Training loss: 2.3443771540469935
Validation loss: 2.503337190407509

Epoch: 6| Step: 3
Training loss: 2.1466475364867286
Validation loss: 2.519480789034112

Epoch: 6| Step: 4
Training loss: 1.8485866405849154
Validation loss: 2.5016445155203977

Epoch: 6| Step: 5
Training loss: 1.9101350311161691
Validation loss: 2.5413879231260132

Epoch: 6| Step: 6
Training loss: 1.4968220106075434
Validation loss: 2.5062074843151465

Epoch: 6| Step: 7
Training loss: 1.9125638739198019
Validation loss: 2.503937164131672

Epoch: 6| Step: 8
Training loss: 1.9814598718430725
Validation loss: 2.471842747995115

Epoch: 6| Step: 9
Training loss: 1.6105100462350577
Validation loss: 2.496792858047379

Epoch: 6| Step: 10
Training loss: 2.613516621617266
Validation loss: 2.4886796872833616

Epoch: 6| Step: 11
Training loss: 1.8246503233678852
Validation loss: 2.5034990936779478

Epoch: 6| Step: 12
Training loss: 2.2122385894312133
Validation loss: 2.509140566163606

Epoch: 6| Step: 13
Training loss: 1.7688379676969246
Validation loss: 2.4781331277451835

Epoch: 298| Step: 0
Training loss: 1.7529479809499842
Validation loss: 2.531343481904326

Epoch: 6| Step: 1
Training loss: 2.3043819936217336
Validation loss: 2.5281279033806108

Epoch: 6| Step: 2
Training loss: 2.0112959630442884
Validation loss: 2.539224629238766

Epoch: 6| Step: 3
Training loss: 2.471001190179085
Validation loss: 2.5587478319515156

Epoch: 6| Step: 4
Training loss: 2.174678612126408
Validation loss: 2.5881424307526006

Epoch: 6| Step: 5
Training loss: 2.4245146118151717
Validation loss: 2.6411393170711106

Epoch: 6| Step: 6
Training loss: 2.0019239470053565
Validation loss: 2.640881753511518

Epoch: 6| Step: 7
Training loss: 2.075677908039584
Validation loss: 2.6028646240437925

Epoch: 6| Step: 8
Training loss: 1.4794668063262244
Validation loss: 2.581293782747274

Epoch: 6| Step: 9
Training loss: 2.5239736265022765
Validation loss: 2.5217269438023044

Epoch: 6| Step: 10
Training loss: 1.8372657678487847
Validation loss: 2.504912968999961

Epoch: 6| Step: 11
Training loss: 2.0774246986229095
Validation loss: 2.5069581633451032

Epoch: 6| Step: 12
Training loss: 2.090988273591373
Validation loss: 2.4913946183958777

Epoch: 6| Step: 13
Training loss: 1.5319631044910085
Validation loss: 2.4988109463002877

Epoch: 299| Step: 0
Training loss: 2.453999551762149
Validation loss: 2.509552333293453

Epoch: 6| Step: 1
Training loss: 2.0908043480824428
Validation loss: 2.4933454400506414

Epoch: 6| Step: 2
Training loss: 1.6619313522373782
Validation loss: 2.5028243482403503

Epoch: 6| Step: 3
Training loss: 2.078395395685548
Validation loss: 2.4745466208786975

Epoch: 6| Step: 4
Training loss: 2.0568360673250363
Validation loss: 2.5094767086308423

Epoch: 6| Step: 5
Training loss: 1.9735586387441149
Validation loss: 2.5025143694901737

Epoch: 6| Step: 6
Training loss: 1.6518513552315395
Validation loss: 2.507817728863075

Epoch: 6| Step: 7
Training loss: 2.0067290117499974
Validation loss: 2.496476837992016

Epoch: 6| Step: 8
Training loss: 1.132275157949664
Validation loss: 2.5040649427253414

Epoch: 6| Step: 9
Training loss: 2.5539921272054924
Validation loss: 2.51034039002928

Epoch: 6| Step: 10
Training loss: 2.05341325707552
Validation loss: 2.5131298667432413

Epoch: 6| Step: 11
Training loss: 2.508358334472699
Validation loss: 2.577365401139388

Epoch: 6| Step: 12
Training loss: 2.297469081732887
Validation loss: 2.5720308969618446

Epoch: 6| Step: 13
Training loss: 1.8283820338386116
Validation loss: 2.520774908938805

Epoch: 300| Step: 0
Training loss: 1.8906954917692156
Validation loss: 2.5186778118936384

Epoch: 6| Step: 1
Training loss: 2.149846617084518
Validation loss: 2.4847906632649392

Epoch: 6| Step: 2
Training loss: 2.3532957868669717
Validation loss: 2.4731529986332923

Epoch: 6| Step: 3
Training loss: 1.7967971121451456
Validation loss: 2.4728822368827093

Epoch: 6| Step: 4
Training loss: 1.632495320008187
Validation loss: 2.4841081327981187

Epoch: 6| Step: 5
Training loss: 2.2978824819291424
Validation loss: 2.4694053810108993

Epoch: 6| Step: 6
Training loss: 1.640815869082299
Validation loss: 2.4662694500586224

Epoch: 6| Step: 7
Training loss: 2.516256312415917
Validation loss: 2.4635355964784793

Epoch: 6| Step: 8
Training loss: 1.7732163345968268
Validation loss: 2.4748430671131394

Epoch: 6| Step: 9
Training loss: 2.106585997091234
Validation loss: 2.455418901203493

Epoch: 6| Step: 10
Training loss: 2.2416312029372025
Validation loss: 2.476682240893691

Epoch: 6| Step: 11
Training loss: 2.5821432530844337
Validation loss: 2.4978293214044873

Epoch: 6| Step: 12
Training loss: 2.219892717982517
Validation loss: 2.5240679446444223

Epoch: 6| Step: 13
Training loss: 1.540371720422982
Validation loss: 2.5498046952920537

Testing loss: 2.0876033763606876
