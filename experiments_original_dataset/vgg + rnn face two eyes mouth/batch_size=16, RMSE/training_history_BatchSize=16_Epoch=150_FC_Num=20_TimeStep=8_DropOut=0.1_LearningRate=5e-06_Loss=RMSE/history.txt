Epoch: 1| Step: 0
Training loss: 5.800658931791176
Validation loss: 5.915959714463917

Epoch: 6| Step: 1
Training loss: 6.378684381666643
Validation loss: 5.913795347575409

Epoch: 6| Step: 2
Training loss: 4.86287727363317
Validation loss: 5.911787394188986

Epoch: 6| Step: 3
Training loss: 5.934714858702275
Validation loss: 5.9098489012877

Epoch: 6| Step: 4
Training loss: 5.868424002111188
Validation loss: 5.907886957793875

Epoch: 6| Step: 5
Training loss: 6.781512699224716
Validation loss: 5.905852935200124

Epoch: 6| Step: 6
Training loss: 4.650076030806932
Validation loss: 5.903794843029692

Epoch: 6| Step: 7
Training loss: 7.30853372586923
Validation loss: 5.901656771657571

Epoch: 6| Step: 8
Training loss: 6.219869081646515
Validation loss: 5.899583071185485

Epoch: 6| Step: 9
Training loss: 5.539333837236348
Validation loss: 5.8973552595215795

Epoch: 6| Step: 10
Training loss: 6.113398249179925
Validation loss: 5.895040380130913

Epoch: 6| Step: 11
Training loss: 5.639372541276357
Validation loss: 5.892621229109141

Epoch: 6| Step: 12
Training loss: 6.4518619067838845
Validation loss: 5.890073688048294

Epoch: 6| Step: 13
Training loss: 6.195442727489264
Validation loss: 5.887428637461518

Epoch: 2| Step: 0
Training loss: 6.236801860627806
Validation loss: 5.8846908076717295

Epoch: 6| Step: 1
Training loss: 6.686846834888752
Validation loss: 5.881817967079541

Epoch: 6| Step: 2
Training loss: 5.996182816928069
Validation loss: 5.878788585478083

Epoch: 6| Step: 3
Training loss: 6.958671637741938
Validation loss: 5.875798272624425

Epoch: 6| Step: 4
Training loss: 5.363343840676292
Validation loss: 5.8723579309654275

Epoch: 6| Step: 5
Training loss: 6.168307043248184
Validation loss: 5.86888041921808

Epoch: 6| Step: 6
Training loss: 5.789908858192989
Validation loss: 5.865354858746277

Epoch: 6| Step: 7
Training loss: 6.290317045387628
Validation loss: 5.861664700190078

Epoch: 6| Step: 8
Training loss: 4.850594490032978
Validation loss: 5.857682806861774

Epoch: 6| Step: 9
Training loss: 5.765862519455499
Validation loss: 5.853544245130094

Epoch: 6| Step: 10
Training loss: 5.195220166296511
Validation loss: 5.849414602697825

Epoch: 6| Step: 11
Training loss: 5.968197142875767
Validation loss: 5.845286964483772

Epoch: 6| Step: 12
Training loss: 5.989701651911074
Validation loss: 5.840706180438994

Epoch: 6| Step: 13
Training loss: 6.116721027073809
Validation loss: 5.836074275976268

Epoch: 3| Step: 0
Training loss: 6.116900635834448
Validation loss: 5.8310754039121475

Epoch: 6| Step: 1
Training loss: 6.156292135801235
Validation loss: 5.825937141705321

Epoch: 6| Step: 2
Training loss: 5.762329151988749
Validation loss: 5.820596914148185

Epoch: 6| Step: 3
Training loss: 6.394619837982118
Validation loss: 5.814967025002957

Epoch: 6| Step: 4
Training loss: 5.210537050064768
Validation loss: 5.8092564929669175

Epoch: 6| Step: 5
Training loss: 5.65060598448904
Validation loss: 5.803125403176032

Epoch: 6| Step: 6
Training loss: 5.5909271789731845
Validation loss: 5.796793454702867

Epoch: 6| Step: 7
Training loss: 4.879081191506802
Validation loss: 5.790041313529107

Epoch: 6| Step: 8
Training loss: 5.62101842049073
Validation loss: 5.783541168670543

Epoch: 6| Step: 9
Training loss: 5.979940898182185
Validation loss: 5.776616729737672

Epoch: 6| Step: 10
Training loss: 6.072345722071445
Validation loss: 5.769508880041546

Epoch: 6| Step: 11
Training loss: 6.267238799146506
Validation loss: 5.761732708757808

Epoch: 6| Step: 12
Training loss: 6.282021546305931
Validation loss: 5.753923211091062

Epoch: 6| Step: 13
Training loss: 6.469901604353773
Validation loss: 5.745519551023549

Epoch: 4| Step: 0
Training loss: 5.436790332303761
Validation loss: 5.737179713842773

Epoch: 6| Step: 1
Training loss: 6.270087652977859
Validation loss: 5.727931755373302

Epoch: 6| Step: 2
Training loss: 5.1259976788298625
Validation loss: 5.718908255633459

Epoch: 6| Step: 3
Training loss: 6.058709601568045
Validation loss: 5.709407408339918

Epoch: 6| Step: 4
Training loss: 5.498851309378737
Validation loss: 5.699774021554675

Epoch: 6| Step: 5
Training loss: 5.397717042758137
Validation loss: 5.689953229518649

Epoch: 6| Step: 6
Training loss: 5.659067706101959
Validation loss: 5.679771426217891

Epoch: 6| Step: 7
Training loss: 5.952753330753499
Validation loss: 5.669570104234485

Epoch: 6| Step: 8
Training loss: 5.5845014953802545
Validation loss: 5.658830675713317

Epoch: 6| Step: 9
Training loss: 5.7129684156028535
Validation loss: 5.647691831354851

Epoch: 6| Step: 10
Training loss: 5.803293463788943
Validation loss: 5.636707132300629

Epoch: 6| Step: 11
Training loss: 5.3219059869891145
Validation loss: 5.625484813001184

Epoch: 6| Step: 12
Training loss: 6.531978000788368
Validation loss: 5.613685418154372

Epoch: 6| Step: 13
Training loss: 6.4543104214437514
Validation loss: 5.602118456999828

Epoch: 5| Step: 0
Training loss: 4.882871484018739
Validation loss: 5.590681857819816

Epoch: 6| Step: 1
Training loss: 5.678931856327261
Validation loss: 5.578555534837428

Epoch: 6| Step: 2
Training loss: 4.893595905240753
Validation loss: 5.566945474841733

Epoch: 6| Step: 3
Training loss: 6.549190721675978
Validation loss: 5.554995414258161

Epoch: 6| Step: 4
Training loss: 4.94806053621703
Validation loss: 5.543539672439853

Epoch: 6| Step: 5
Training loss: 6.089202279397036
Validation loss: 5.531519507902374

Epoch: 6| Step: 6
Training loss: 4.929276390284026
Validation loss: 5.519922414040912

Epoch: 6| Step: 7
Training loss: 5.704684945583685
Validation loss: 5.508741252682461

Epoch: 6| Step: 8
Training loss: 5.94040199435124
Validation loss: 5.496875424481741

Epoch: 6| Step: 9
Training loss: 6.123080517252077
Validation loss: 5.485505830663328

Epoch: 6| Step: 10
Training loss: 5.764957378987547
Validation loss: 5.473942672847435

Epoch: 6| Step: 11
Training loss: 6.140874726553747
Validation loss: 5.462412127989043

Epoch: 6| Step: 12
Training loss: 4.875386931885068
Validation loss: 5.45148417827586

Epoch: 6| Step: 13
Training loss: 5.930025234329543
Validation loss: 5.440006423834205

Epoch: 6| Step: 0
Training loss: 5.78617096836048
Validation loss: 5.429063061271862

Epoch: 6| Step: 1
Training loss: 5.521633085468645
Validation loss: 5.418162545256583

Epoch: 6| Step: 2
Training loss: 5.595093805448883
Validation loss: 5.406954710202363

Epoch: 6| Step: 3
Training loss: 5.405200834398354
Validation loss: 5.395236341916818

Epoch: 6| Step: 4
Training loss: 4.731914825292015
Validation loss: 5.384275934153389

Epoch: 6| Step: 5
Training loss: 4.9532428330325455
Validation loss: 5.373380668437953

Epoch: 6| Step: 6
Training loss: 6.196509381549019
Validation loss: 5.361623961318419

Epoch: 6| Step: 7
Training loss: 4.8384689582916165
Validation loss: 5.350531040111238

Epoch: 6| Step: 8
Training loss: 6.448516604153467
Validation loss: 5.339320006657595

Epoch: 6| Step: 9
Training loss: 4.97361680168123
Validation loss: 5.3284164155113345

Epoch: 6| Step: 10
Training loss: 6.150943230969965
Validation loss: 5.3173316376287065

Epoch: 6| Step: 11
Training loss: 5.574349458654977
Validation loss: 5.306087168788848

Epoch: 6| Step: 12
Training loss: 4.775259815756981
Validation loss: 5.295731352577765

Epoch: 6| Step: 13
Training loss: 5.372902926836297
Validation loss: 5.285248275598488

Epoch: 7| Step: 0
Training loss: 4.518993137936026
Validation loss: 5.275149250781597

Epoch: 6| Step: 1
Training loss: 5.175169664633157
Validation loss: 5.26542528869852

Epoch: 6| Step: 2
Training loss: 5.45231871669547
Validation loss: 5.255103884951668

Epoch: 6| Step: 3
Training loss: 5.0517609273803945
Validation loss: 5.245707376718745

Epoch: 6| Step: 4
Training loss: 5.707346067420547
Validation loss: 5.236631235496146

Epoch: 6| Step: 5
Training loss: 5.872332028016266
Validation loss: 5.22684406915283

Epoch: 6| Step: 6
Training loss: 5.150526904956584
Validation loss: 5.216840825002258

Epoch: 6| Step: 7
Training loss: 5.9290476819464795
Validation loss: 5.2080720861400485

Epoch: 6| Step: 8
Training loss: 6.138886572068795
Validation loss: 5.198336760746171

Epoch: 6| Step: 9
Training loss: 5.18532875306318
Validation loss: 5.188896052627647

Epoch: 6| Step: 10
Training loss: 4.8850459735624145
Validation loss: 5.180343808825896

Epoch: 6| Step: 11
Training loss: 5.086086757362478
Validation loss: 5.172317931540215

Epoch: 6| Step: 12
Training loss: 5.19625666937493
Validation loss: 5.164454088931581

Epoch: 6| Step: 13
Training loss: 5.103501796886165
Validation loss: 5.156215135861062

Epoch: 8| Step: 0
Training loss: 5.209858704040298
Validation loss: 5.1486631429850265

Epoch: 6| Step: 1
Training loss: 4.86194760830456
Validation loss: 5.141697703081845

Epoch: 6| Step: 2
Training loss: 4.849412524637025
Validation loss: 5.134154509633329

Epoch: 6| Step: 3
Training loss: 4.578270815457291
Validation loss: 5.1268317817981695

Epoch: 6| Step: 4
Training loss: 5.661276928177911
Validation loss: 5.1202147248561385

Epoch: 6| Step: 5
Training loss: 4.344129806489991
Validation loss: 5.1130714538603

Epoch: 6| Step: 6
Training loss: 6.005825393704679
Validation loss: 5.1063754641785355

Epoch: 6| Step: 7
Training loss: 5.417247017312579
Validation loss: 5.099319128325837

Epoch: 6| Step: 8
Training loss: 5.460652836487114
Validation loss: 5.092673689199727

Epoch: 6| Step: 9
Training loss: 4.897971780592101
Validation loss: 5.085508079389621

Epoch: 6| Step: 10
Training loss: 6.058893133620915
Validation loss: 5.0787810698990725

Epoch: 6| Step: 11
Training loss: 5.288377635797091
Validation loss: 5.071428909787858

Epoch: 6| Step: 12
Training loss: 5.517641730828071
Validation loss: 5.064616887075461

Epoch: 6| Step: 13
Training loss: 4.673318391160209
Validation loss: 5.057449050272066

Epoch: 9| Step: 0
Training loss: 4.492758540471379
Validation loss: 5.0511257352131045

Epoch: 6| Step: 1
Training loss: 5.728707737892675
Validation loss: 5.04426247263386

Epoch: 6| Step: 2
Training loss: 5.52516796840617
Validation loss: 5.038248695287683

Epoch: 6| Step: 3
Training loss: 5.800714501404689
Validation loss: 5.031359400853071

Epoch: 6| Step: 4
Training loss: 4.954511093516821
Validation loss: 5.025663982952248

Epoch: 6| Step: 5
Training loss: 6.39263004103575
Validation loss: 5.019543409518346

Epoch: 6| Step: 6
Training loss: 5.078312797008255
Validation loss: 5.013168287874653

Epoch: 6| Step: 7
Training loss: 4.778110445747639
Validation loss: 5.007527851618309

Epoch: 6| Step: 8
Training loss: 4.279554045073742
Validation loss: 5.001261742656015

Epoch: 6| Step: 9
Training loss: 5.151082726891245
Validation loss: 4.995937095415074

Epoch: 6| Step: 10
Training loss: 4.79947236657933
Validation loss: 4.989862751420637

Epoch: 6| Step: 11
Training loss: 4.760756911034925
Validation loss: 4.984300857997016

Epoch: 6| Step: 12
Training loss: 4.0755494853059675
Validation loss: 4.978928159909655

Epoch: 6| Step: 13
Training loss: 5.58219867772876
Validation loss: 4.973566020519841

Epoch: 10| Step: 0
Training loss: 5.431992471074546
Validation loss: 4.967821846249871

Epoch: 6| Step: 1
Training loss: 5.099821813125902
Validation loss: 4.9624617990709785

Epoch: 6| Step: 2
Training loss: 4.958472220561991
Validation loss: 4.956163342918127

Epoch: 6| Step: 3
Training loss: 4.0176068473238
Validation loss: 4.950469547697044

Epoch: 6| Step: 4
Training loss: 4.740376008648379
Validation loss: 4.945118028976233

Epoch: 6| Step: 5
Training loss: 4.72763256224029
Validation loss: 4.939643845119813

Epoch: 6| Step: 6
Training loss: 5.066343567400886
Validation loss: 4.934328501222356

Epoch: 6| Step: 7
Training loss: 5.0613910732077665
Validation loss: 4.928657823204246

Epoch: 6| Step: 8
Training loss: 5.002365697061609
Validation loss: 4.9224824076464575

Epoch: 6| Step: 9
Training loss: 5.374879170323837
Validation loss: 4.917227675333704

Epoch: 6| Step: 10
Training loss: 4.844537880100487
Validation loss: 4.911365409719056

Epoch: 6| Step: 11
Training loss: 5.825565215754417
Validation loss: 4.905219291739038

Epoch: 6| Step: 12
Training loss: 5.455841349781386
Validation loss: 4.899839209818418

Epoch: 6| Step: 13
Training loss: 4.941359544616231
Validation loss: 4.89472229166896

Epoch: 11| Step: 0
Training loss: 4.017598539234718
Validation loss: 4.8891196894833815

Epoch: 6| Step: 1
Training loss: 5.651797570741511
Validation loss: 4.883892605146757

Epoch: 6| Step: 2
Training loss: 5.402758402436901
Validation loss: 4.878796036887747

Epoch: 6| Step: 3
Training loss: 5.205895221982081
Validation loss: 4.872286799597468

Epoch: 6| Step: 4
Training loss: 5.462764057961326
Validation loss: 4.867060300941639

Epoch: 6| Step: 5
Training loss: 5.1048804997161135
Validation loss: 4.861721800939522

Epoch: 6| Step: 6
Training loss: 4.277858309517579
Validation loss: 4.855832295760007

Epoch: 6| Step: 7
Training loss: 5.505464959877456
Validation loss: 4.850874061083646

Epoch: 6| Step: 8
Training loss: 4.816958653312753
Validation loss: 4.845440870919957

Epoch: 6| Step: 9
Training loss: 3.950646630004513
Validation loss: 4.840389341032219

Epoch: 6| Step: 10
Training loss: 4.867545860164613
Validation loss: 4.834898870515745

Epoch: 6| Step: 11
Training loss: 4.968031537396616
Validation loss: 4.8301862906893

Epoch: 6| Step: 12
Training loss: 4.822393379357748
Validation loss: 4.825158550444355

Epoch: 6| Step: 13
Training loss: 5.282324687252999
Validation loss: 4.820256146843997

Epoch: 12| Step: 0
Training loss: 5.229327236106491
Validation loss: 4.815064609737153

Epoch: 6| Step: 1
Training loss: 5.396768358830316
Validation loss: 4.8094526939404085

Epoch: 6| Step: 2
Training loss: 4.680236886052918
Validation loss: 4.804083561350793

Epoch: 6| Step: 3
Training loss: 4.516349760717477
Validation loss: 4.798014850194353

Epoch: 6| Step: 4
Training loss: 4.818428252446497
Validation loss: 4.792464325343735

Epoch: 6| Step: 5
Training loss: 5.118625677552941
Validation loss: 4.786472501792596

Epoch: 6| Step: 6
Training loss: 4.993109532846925
Validation loss: 4.780402663201603

Epoch: 6| Step: 7
Training loss: 4.916600674116284
Validation loss: 4.77510224078104

Epoch: 6| Step: 8
Training loss: 4.987543802857756
Validation loss: 4.769027395917226

Epoch: 6| Step: 9
Training loss: 4.5770687408052595
Validation loss: 4.762603619133275

Epoch: 6| Step: 10
Training loss: 4.8973549067846625
Validation loss: 4.7572930547808125

Epoch: 6| Step: 11
Training loss: 4.1902215568578995
Validation loss: 4.751941016626408

Epoch: 6| Step: 12
Training loss: 5.060955989529458
Validation loss: 4.74619987798224

Epoch: 6| Step: 13
Training loss: 5.146883508597627
Validation loss: 4.740373057990534

Epoch: 13| Step: 0
Training loss: 4.645620617750901
Validation loss: 4.734645319608453

Epoch: 6| Step: 1
Training loss: 5.071925866135777
Validation loss: 4.729477433848469

Epoch: 6| Step: 2
Training loss: 5.1180450885630595
Validation loss: 4.723530451004823

Epoch: 6| Step: 3
Training loss: 4.447631874466623
Validation loss: 4.718094298087282

Epoch: 6| Step: 4
Training loss: 4.476574856140234
Validation loss: 4.712470332962136

Epoch: 6| Step: 5
Training loss: 3.8774654789758496
Validation loss: 4.707334710729318

Epoch: 6| Step: 6
Training loss: 4.617993795926837
Validation loss: 4.702320575039073

Epoch: 6| Step: 7
Training loss: 5.638827135137318
Validation loss: 4.6975010295418125

Epoch: 6| Step: 8
Training loss: 4.806473166018333
Validation loss: 4.692152892959109

Epoch: 6| Step: 9
Training loss: 4.825128014007763
Validation loss: 4.686926370066125

Epoch: 6| Step: 10
Training loss: 5.467948636877657
Validation loss: 4.681878818165313

Epoch: 6| Step: 11
Training loss: 4.201664894362886
Validation loss: 4.677222552135552

Epoch: 6| Step: 12
Training loss: 5.604247743759862
Validation loss: 4.671881906425619

Epoch: 6| Step: 13
Training loss: 4.390535509819762
Validation loss: 4.667166660408327

Epoch: 14| Step: 0
Training loss: 5.029071976160836
Validation loss: 4.6620437453377885

Epoch: 6| Step: 1
Training loss: 4.2796405077969535
Validation loss: 4.656542229069504

Epoch: 6| Step: 2
Training loss: 4.502700842868766
Validation loss: 4.651416240900406

Epoch: 6| Step: 3
Training loss: 4.647675472597456
Validation loss: 4.646127489069132

Epoch: 6| Step: 4
Training loss: 5.260344169293388
Validation loss: 4.642562170754209

Epoch: 6| Step: 5
Training loss: 5.62215622966637
Validation loss: 4.63725632869656

Epoch: 6| Step: 6
Training loss: 4.118434420407263
Validation loss: 4.631574236887951

Epoch: 6| Step: 7
Training loss: 4.7533814290214105
Validation loss: 4.625599521580023

Epoch: 6| Step: 8
Training loss: 4.986118884539529
Validation loss: 4.620271413407773

Epoch: 6| Step: 9
Training loss: 3.6655595726424663
Validation loss: 4.615663021811754

Epoch: 6| Step: 10
Training loss: 3.650822188908862
Validation loss: 4.610684655984174

Epoch: 6| Step: 11
Training loss: 5.174552846562226
Validation loss: 4.60565452643179

Epoch: 6| Step: 12
Training loss: 5.700866753782688
Validation loss: 4.60039581033361

Epoch: 6| Step: 13
Training loss: 4.6304380047380675
Validation loss: 4.5947249712182865

Epoch: 15| Step: 0
Training loss: 4.218659124455258
Validation loss: 4.58962595754332

Epoch: 6| Step: 1
Training loss: 5.430712091390969
Validation loss: 4.584489410713229

Epoch: 6| Step: 2
Training loss: 4.164262204990707
Validation loss: 4.5791963749281415

Epoch: 6| Step: 3
Training loss: 4.354629394669194
Validation loss: 4.5740699559266265

Epoch: 6| Step: 4
Training loss: 4.896840980669662
Validation loss: 4.569681707687792

Epoch: 6| Step: 5
Training loss: 4.776284824894305
Validation loss: 4.5641851404993385

Epoch: 6| Step: 6
Training loss: 4.8921424534690505
Validation loss: 4.559138344228343

Epoch: 6| Step: 7
Training loss: 3.989561766457427
Validation loss: 4.553950621473336

Epoch: 6| Step: 8
Training loss: 4.310124060666347
Validation loss: 4.549189010418965

Epoch: 6| Step: 9
Training loss: 4.506884077647823
Validation loss: 4.544514028896811

Epoch: 6| Step: 10
Training loss: 5.241863667112093
Validation loss: 4.539799309270506

Epoch: 6| Step: 11
Training loss: 4.573167427620043
Validation loss: 4.534907476286748

Epoch: 6| Step: 12
Training loss: 5.067582204986603
Validation loss: 4.530257508774182

Epoch: 6| Step: 13
Training loss: 4.902683006189538
Validation loss: 4.525660573047489

Epoch: 16| Step: 0
Training loss: 5.080802704477529
Validation loss: 4.520924820684751

Epoch: 6| Step: 1
Training loss: 5.0075748286034125
Validation loss: 4.515415983191515

Epoch: 6| Step: 2
Training loss: 4.071126845420554
Validation loss: 4.510489248113176

Epoch: 6| Step: 3
Training loss: 5.541469465298791
Validation loss: 4.505562664349884

Epoch: 6| Step: 4
Training loss: 4.712642734298633
Validation loss: 4.500465333685642

Epoch: 6| Step: 5
Training loss: 2.3517288706785187
Validation loss: 4.4955887542653645

Epoch: 6| Step: 6
Training loss: 5.0441255904677975
Validation loss: 4.490780481218738

Epoch: 6| Step: 7
Training loss: 4.477139367554232
Validation loss: 4.48627232411831

Epoch: 6| Step: 8
Training loss: 4.389056268282221
Validation loss: 4.481195436905409

Epoch: 6| Step: 9
Training loss: 4.81884703779666
Validation loss: 4.476989636950343

Epoch: 6| Step: 10
Training loss: 5.282664092765334
Validation loss: 4.4720838866284875

Epoch: 6| Step: 11
Training loss: 4.418280228782882
Validation loss: 4.467026028956587

Epoch: 6| Step: 12
Training loss: 4.073727630244801
Validation loss: 4.462093170171321

Epoch: 6| Step: 13
Training loss: 4.547450288120235
Validation loss: 4.457889172304356

Epoch: 17| Step: 0
Training loss: 5.5463077738695095
Validation loss: 4.453374023613279

Epoch: 6| Step: 1
Training loss: 4.4268391381027925
Validation loss: 4.449199440913937

Epoch: 6| Step: 2
Training loss: 4.067452566366161
Validation loss: 4.444031542565642

Epoch: 6| Step: 3
Training loss: 3.7600437447864246
Validation loss: 4.439742188973269

Epoch: 6| Step: 4
Training loss: 4.673201458784935
Validation loss: 4.435741989702122

Epoch: 6| Step: 5
Training loss: 4.171831795115114
Validation loss: 4.430858925877079

Epoch: 6| Step: 6
Training loss: 4.329060477507784
Validation loss: 4.426525927589039

Epoch: 6| Step: 7
Training loss: 4.33561152702043
Validation loss: 4.4228248609423435

Epoch: 6| Step: 8
Training loss: 5.352370776095831
Validation loss: 4.418099920572466

Epoch: 6| Step: 9
Training loss: 4.983936254629463
Validation loss: 4.413452574414645

Epoch: 6| Step: 10
Training loss: 4.711276774422709
Validation loss: 4.408729054237464

Epoch: 6| Step: 11
Training loss: 3.7600407011791677
Validation loss: 4.404767772371172

Epoch: 6| Step: 12
Training loss: 4.420322105097928
Validation loss: 4.399743942555118

Epoch: 6| Step: 13
Training loss: 4.803044926925873
Validation loss: 4.395336840223497

Epoch: 18| Step: 0
Training loss: 4.121146743216744
Validation loss: 4.3913166410936695

Epoch: 6| Step: 1
Training loss: 3.801024253737727
Validation loss: 4.386823698777289

Epoch: 6| Step: 2
Training loss: 4.274374682999148
Validation loss: 4.382763142118

Epoch: 6| Step: 3
Training loss: 4.4244696347779655
Validation loss: 4.379023055538658

Epoch: 6| Step: 4
Training loss: 4.385955608291127
Validation loss: 4.373845665644902

Epoch: 6| Step: 5
Training loss: 4.844255974707192
Validation loss: 4.369826864192492

Epoch: 6| Step: 6
Training loss: 5.655707064541298
Validation loss: 4.364888340649586

Epoch: 6| Step: 7
Training loss: 4.792514670702269
Validation loss: 4.3607794391886605

Epoch: 6| Step: 8
Training loss: 4.809216060081813
Validation loss: 4.356256953653033

Epoch: 6| Step: 9
Training loss: 3.9529816974705447
Validation loss: 4.351375737910903

Epoch: 6| Step: 10
Training loss: 4.4962664056499335
Validation loss: 4.3473198398656985

Epoch: 6| Step: 11
Training loss: 3.668263318925938
Validation loss: 4.342786851397141

Epoch: 6| Step: 12
Training loss: 4.681155781631743
Validation loss: 4.338663759685059

Epoch: 6| Step: 13
Training loss: 4.614987644827889
Validation loss: 4.334492063878179

Epoch: 19| Step: 0
Training loss: 4.4764470323513565
Validation loss: 4.329926300713747

Epoch: 6| Step: 1
Training loss: 4.383977996840566
Validation loss: 4.32595436576986

Epoch: 6| Step: 2
Training loss: 4.678874102736971
Validation loss: 4.3211285428048996

Epoch: 6| Step: 3
Training loss: 4.200100743130027
Validation loss: 4.316912839686957

Epoch: 6| Step: 4
Training loss: 4.0705172730700125
Validation loss: 4.313139421171453

Epoch: 6| Step: 5
Training loss: 4.970517018249805
Validation loss: 4.308317616555171

Epoch: 6| Step: 6
Training loss: 4.866678422539156
Validation loss: 4.304228437976899

Epoch: 6| Step: 7
Training loss: 4.617410154186264
Validation loss: 4.299891223566616

Epoch: 6| Step: 8
Training loss: 4.236689649309979
Validation loss: 4.2960089163258495

Epoch: 6| Step: 9
Training loss: 4.353898084226597
Validation loss: 4.291179475013097

Epoch: 6| Step: 10
Training loss: 4.3836588594846075
Validation loss: 4.2876082678230825

Epoch: 6| Step: 11
Training loss: 4.031993708651039
Validation loss: 4.282951258281446

Epoch: 6| Step: 12
Training loss: 3.6246110115495687
Validation loss: 4.278807748651325

Epoch: 6| Step: 13
Training loss: 4.950817449099355
Validation loss: 4.2746253632100615

Epoch: 20| Step: 0
Training loss: 3.725555219811111
Validation loss: 4.270262120202459

Epoch: 6| Step: 1
Training loss: 4.450896552133947
Validation loss: 4.266269844695287

Epoch: 6| Step: 2
Training loss: 3.1803142857741005
Validation loss: 4.26215568934296

Epoch: 6| Step: 3
Training loss: 4.794261307286447
Validation loss: 4.258133323784852

Epoch: 6| Step: 4
Training loss: 4.0377058041678495
Validation loss: 4.25424812281255

Epoch: 6| Step: 5
Training loss: 4.2640937040815015
Validation loss: 4.249946724800845

Epoch: 6| Step: 6
Training loss: 4.259672490098317
Validation loss: 4.246079862186446

Epoch: 6| Step: 7
Training loss: 4.363403209323964
Validation loss: 4.242112469931702

Epoch: 6| Step: 8
Training loss: 4.355868552978852
Validation loss: 4.238234653011658

Epoch: 6| Step: 9
Training loss: 4.537045475497079
Validation loss: 4.233773990034161

Epoch: 6| Step: 10
Training loss: 4.288032894549239
Validation loss: 4.2301349126585555

Epoch: 6| Step: 11
Training loss: 5.05735592812733
Validation loss: 4.225747547566533

Epoch: 6| Step: 12
Training loss: 5.078435612495611
Validation loss: 4.221637707678838

Epoch: 6| Step: 13
Training loss: 4.471137629401471
Validation loss: 4.217165048771981

Epoch: 21| Step: 0
Training loss: 3.542954214585674
Validation loss: 4.2132280733645615

Epoch: 6| Step: 1
Training loss: 4.357015429203503
Validation loss: 4.209325025186767

Epoch: 6| Step: 2
Training loss: 3.824889267459281
Validation loss: 4.2049339589827

Epoch: 6| Step: 3
Training loss: 4.721005538578416
Validation loss: 4.200822144982628

Epoch: 6| Step: 4
Training loss: 5.398411001314306
Validation loss: 4.196380005838567

Epoch: 6| Step: 5
Training loss: 4.673590609823717
Validation loss: 4.191903489224922

Epoch: 6| Step: 6
Training loss: 4.061095713945579
Validation loss: 4.187389125589746

Epoch: 6| Step: 7
Training loss: 4.047401423440811
Validation loss: 4.183084009853985

Epoch: 6| Step: 8
Training loss: 4.057955033505802
Validation loss: 4.178650172915728

Epoch: 6| Step: 9
Training loss: 3.880684651404628
Validation loss: 4.174388571184684

Epoch: 6| Step: 10
Training loss: 4.766645278526997
Validation loss: 4.170192193375205

Epoch: 6| Step: 11
Training loss: 4.759927915139495
Validation loss: 4.165873731821842

Epoch: 6| Step: 12
Training loss: 3.632640022367272
Validation loss: 4.1619077335599375

Epoch: 6| Step: 13
Training loss: 4.305563835765027
Validation loss: 4.157581374243127

Epoch: 22| Step: 0
Training loss: 3.4525215001303473
Validation loss: 4.153184434222929

Epoch: 6| Step: 1
Training loss: 4.258201539351026
Validation loss: 4.149074852708994

Epoch: 6| Step: 2
Training loss: 4.318398905503713
Validation loss: 4.14499392550046

Epoch: 6| Step: 3
Training loss: 4.429325580108612
Validation loss: 4.1406652100727905

Epoch: 6| Step: 4
Training loss: 4.197465340685362
Validation loss: 4.136730238502598

Epoch: 6| Step: 5
Training loss: 3.61547257243048
Validation loss: 4.132530813346522

Epoch: 6| Step: 6
Training loss: 4.690958603617133
Validation loss: 4.128358668091868

Epoch: 6| Step: 7
Training loss: 3.5422980400240056
Validation loss: 4.12415175916149

Epoch: 6| Step: 8
Training loss: 4.114209482455572
Validation loss: 4.120053899869219

Epoch: 6| Step: 9
Training loss: 4.185044436930976
Validation loss: 4.115853215877759

Epoch: 6| Step: 10
Training loss: 4.457468156855948
Validation loss: 4.111629491348557

Epoch: 6| Step: 11
Training loss: 4.901314749763079
Validation loss: 4.107436231635534

Epoch: 6| Step: 12
Training loss: 4.2483400581299655
Validation loss: 4.102764890721275

Epoch: 6| Step: 13
Training loss: 4.880148687442612
Validation loss: 4.098549744512044

Epoch: 23| Step: 0
Training loss: 4.1230929040982325
Validation loss: 4.09447336964517

Epoch: 6| Step: 1
Training loss: 3.9963100818535975
Validation loss: 4.0899387896309225

Epoch: 6| Step: 2
Training loss: 3.7601752516303857
Validation loss: 4.08538830228715

Epoch: 6| Step: 3
Training loss: 5.323016002148675
Validation loss: 4.081165412933693

Epoch: 6| Step: 4
Training loss: 4.531194857557795
Validation loss: 4.076799939883884

Epoch: 6| Step: 5
Training loss: 3.8359842394683037
Validation loss: 4.072545742826337

Epoch: 6| Step: 6
Training loss: 4.5084852116657315
Validation loss: 4.068233161442119

Epoch: 6| Step: 7
Training loss: 4.48163672657919
Validation loss: 4.063872628749101

Epoch: 6| Step: 8
Training loss: 3.545194656343596
Validation loss: 4.059432960274628

Epoch: 6| Step: 9
Training loss: 4.5656754404110735
Validation loss: 4.0551382413317345

Epoch: 6| Step: 10
Training loss: 3.24426408931227
Validation loss: 4.050868181493225

Epoch: 6| Step: 11
Training loss: 3.813598474563796
Validation loss: 4.04620624844232

Epoch: 6| Step: 12
Training loss: 4.32086255398725
Validation loss: 4.042418373965081

Epoch: 6| Step: 13
Training loss: 4.327704564134848
Validation loss: 4.0378689112188155

Epoch: 24| Step: 0
Training loss: 3.7133372688843322
Validation loss: 4.034071159395855

Epoch: 6| Step: 1
Training loss: 4.537923594477589
Validation loss: 4.030043695037833

Epoch: 6| Step: 2
Training loss: 4.301526690194433
Validation loss: 4.0258065073178555

Epoch: 6| Step: 3
Training loss: 4.64071747658805
Validation loss: 4.02171297613979

Epoch: 6| Step: 4
Training loss: 4.362600138479542
Validation loss: 4.0175847319439075

Epoch: 6| Step: 5
Training loss: 4.584574768248857
Validation loss: 4.013224912385013

Epoch: 6| Step: 6
Training loss: 3.904796604618159
Validation loss: 4.008711368924594

Epoch: 6| Step: 7
Training loss: 3.576292676567688
Validation loss: 4.004334108395826

Epoch: 6| Step: 8
Training loss: 4.018549347847303
Validation loss: 4.000002721944519

Epoch: 6| Step: 9
Training loss: 4.247279025431817
Validation loss: 3.996061611450268

Epoch: 6| Step: 10
Training loss: 3.526758493935804
Validation loss: 3.9918017813817928

Epoch: 6| Step: 11
Training loss: 3.8868681759121886
Validation loss: 3.987713799878524

Epoch: 6| Step: 12
Training loss: 3.782438233369821
Validation loss: 3.983504156549174

Epoch: 6| Step: 13
Training loss: 4.641015444170311
Validation loss: 3.9795614848899943

Epoch: 25| Step: 0
Training loss: 4.216212208700357
Validation loss: 3.9752419508067707

Epoch: 6| Step: 1
Training loss: 4.285844773622113
Validation loss: 3.971249671770322

Epoch: 6| Step: 2
Training loss: 3.5064094983166547
Validation loss: 3.9669460492091932

Epoch: 6| Step: 3
Training loss: 3.79881733007785
Validation loss: 3.962807539308137

Epoch: 6| Step: 4
Training loss: 4.969214843502812
Validation loss: 3.9590456806812915

Epoch: 6| Step: 5
Training loss: 4.259060346101975
Validation loss: 3.9547417190715533

Epoch: 6| Step: 6
Training loss: 4.028113749438807
Validation loss: 3.950427536018857

Epoch: 6| Step: 7
Training loss: 4.486246496046669
Validation loss: 3.946094478248877

Epoch: 6| Step: 8
Training loss: 3.4964304841761504
Validation loss: 3.941866315714468

Epoch: 6| Step: 9
Training loss: 4.067770488164833
Validation loss: 3.9376273159858566

Epoch: 6| Step: 10
Training loss: 4.33891982880091
Validation loss: 3.933289067509594

Epoch: 6| Step: 11
Training loss: 3.5728841322297127
Validation loss: 3.929189985468341

Epoch: 6| Step: 12
Training loss: 4.070227916812498
Validation loss: 3.925184558165852

Epoch: 6| Step: 13
Training loss: 3.799585450297994
Validation loss: 3.9208882421580293

Epoch: 26| Step: 0
Training loss: 3.801518869522027
Validation loss: 3.9169243396382267

Epoch: 6| Step: 1
Training loss: 3.980589021582137
Validation loss: 3.912890128610757

Epoch: 6| Step: 2
Training loss: 3.6560629772379842
Validation loss: 3.9087255542732002

Epoch: 6| Step: 3
Training loss: 3.730864466904441
Validation loss: 3.904970310406033

Epoch: 6| Step: 4
Training loss: 3.4881606812694987
Validation loss: 3.900907458996168

Epoch: 6| Step: 5
Training loss: 3.925876961675301
Validation loss: 3.8970495899188426

Epoch: 6| Step: 6
Training loss: 4.284290876613035
Validation loss: 3.892828933743603

Epoch: 6| Step: 7
Training loss: 4.618317802969349
Validation loss: 3.8889936425466143

Epoch: 6| Step: 8
Training loss: 4.590997610946961
Validation loss: 3.884668245752434

Epoch: 6| Step: 9
Training loss: 4.090241071316503
Validation loss: 3.8804732605613714

Epoch: 6| Step: 10
Training loss: 3.7516967749407835
Validation loss: 3.876114408156814

Epoch: 6| Step: 11
Training loss: 4.5145306696663825
Validation loss: 3.8720489462879923

Epoch: 6| Step: 12
Training loss: 3.4736192224133227
Validation loss: 3.86768844904858

Epoch: 6| Step: 13
Training loss: 4.191613753018303
Validation loss: 3.8634575011931207

Epoch: 27| Step: 0
Training loss: 4.539566721133747
Validation loss: 3.859470093414016

Epoch: 6| Step: 1
Training loss: 3.629562137982564
Validation loss: 3.855028183335567

Epoch: 6| Step: 2
Training loss: 3.87067627411939
Validation loss: 3.8506003023286457

Epoch: 6| Step: 3
Training loss: 4.102463628687893
Validation loss: 3.8463478510173514

Epoch: 6| Step: 4
Training loss: 3.989844543564514
Validation loss: 3.8423374961190007

Epoch: 6| Step: 5
Training loss: 3.5877151903217226
Validation loss: 3.8381336397298336

Epoch: 6| Step: 6
Training loss: 4.567872111546185
Validation loss: 3.834142509693328

Epoch: 6| Step: 7
Training loss: 3.58582154462577
Validation loss: 3.8297562633345072

Epoch: 6| Step: 8
Training loss: 3.7680020882343572
Validation loss: 3.8257180256806462

Epoch: 6| Step: 9
Training loss: 4.210504003515855
Validation loss: 3.8213373537470594

Epoch: 6| Step: 10
Training loss: 3.381939147555159
Validation loss: 3.817306969306324

Epoch: 6| Step: 11
Training loss: 4.2355644554301755
Validation loss: 3.8130428782354127

Epoch: 6| Step: 12
Training loss: 3.495023186297039
Validation loss: 3.8089245148838287

Epoch: 6| Step: 13
Training loss: 4.335786174161138
Validation loss: 3.804884094130497

Epoch: 28| Step: 0
Training loss: 4.308735849452984
Validation loss: 3.8008390019084666

Epoch: 6| Step: 1
Training loss: 3.978362449877182
Validation loss: 3.796502198387677

Epoch: 6| Step: 2
Training loss: 3.806610060324959
Validation loss: 3.7921768865239023

Epoch: 6| Step: 3
Training loss: 3.3100867927904343
Validation loss: 3.788059712799681

Epoch: 6| Step: 4
Training loss: 4.007004089322918
Validation loss: 3.7840265005956666

Epoch: 6| Step: 5
Training loss: 3.7492110376105816
Validation loss: 3.7799505938306845

Epoch: 6| Step: 6
Training loss: 4.335952236391061
Validation loss: 3.7758054812876107

Epoch: 6| Step: 7
Training loss: 3.657750009477949
Validation loss: 3.7716015337080626

Epoch: 6| Step: 8
Training loss: 3.3785673996910837
Validation loss: 3.7673258758787935

Epoch: 6| Step: 9
Training loss: 4.44324132741542
Validation loss: 3.7635093011141008

Epoch: 6| Step: 10
Training loss: 4.055332375109027
Validation loss: 3.7592148837362416

Epoch: 6| Step: 11
Training loss: 3.7076666300517918
Validation loss: 3.754895469270498

Epoch: 6| Step: 12
Training loss: 4.405441751141998
Validation loss: 3.7508604545999837

Epoch: 6| Step: 13
Training loss: 3.339206496450907
Validation loss: 3.7465685721505775

Epoch: 29| Step: 0
Training loss: 2.7138473328821218
Validation loss: 3.742512157270094

Epoch: 6| Step: 1
Training loss: 4.024802559695475
Validation loss: 3.738707196275365

Epoch: 6| Step: 2
Training loss: 4.250351835160973
Validation loss: 3.734649733222979

Epoch: 6| Step: 3
Training loss: 3.8700508999495966
Validation loss: 3.7308373926507166

Epoch: 6| Step: 4
Training loss: 4.775071883534312
Validation loss: 3.7266943139863065

Epoch: 6| Step: 5
Training loss: 3.7354882787480492
Validation loss: 3.7224858856445975

Epoch: 6| Step: 6
Training loss: 3.5419442610315586
Validation loss: 3.71828945096971

Epoch: 6| Step: 7
Training loss: 4.161741830322474
Validation loss: 3.7142182206913925

Epoch: 6| Step: 8
Training loss: 3.9616058207134817
Validation loss: 3.7102422979908214

Epoch: 6| Step: 9
Training loss: 3.6052535665489285
Validation loss: 3.7059270931455583

Epoch: 6| Step: 10
Training loss: 3.802724092740978
Validation loss: 3.7018891752496432

Epoch: 6| Step: 11
Training loss: 4.263808314210669
Validation loss: 3.697559321514198

Epoch: 6| Step: 12
Training loss: 3.3295829337647356
Validation loss: 3.6935254023860846

Epoch: 6| Step: 13
Training loss: 3.488303394824025
Validation loss: 3.689311126943616

Epoch: 30| Step: 0
Training loss: 3.9085329022456765
Validation loss: 3.6853276766909824

Epoch: 6| Step: 1
Training loss: 4.0778969887318155
Validation loss: 3.681132233424724

Epoch: 6| Step: 2
Training loss: 3.339774647494187
Validation loss: 3.677308789798814

Epoch: 6| Step: 3
Training loss: 4.65161742106528
Validation loss: 3.673142364601111

Epoch: 6| Step: 4
Training loss: 3.778538133421471
Validation loss: 3.6688300744090765

Epoch: 6| Step: 5
Training loss: 4.210339335631629
Validation loss: 3.6646633455361948

Epoch: 6| Step: 6
Training loss: 3.4534130407828463
Validation loss: 3.660216329292525

Epoch: 6| Step: 7
Training loss: 3.629554780922151
Validation loss: 3.656250217361661

Epoch: 6| Step: 8
Training loss: 3.815731492614551
Validation loss: 3.6520587340747066

Epoch: 6| Step: 9
Training loss: 4.095729669531292
Validation loss: 3.6478559641831856

Epoch: 6| Step: 10
Training loss: 3.4849558803660834
Validation loss: 3.6437070186428984

Epoch: 6| Step: 11
Training loss: 3.4688447131723845
Validation loss: 3.639538233011212

Epoch: 6| Step: 12
Training loss: 3.7396528543936416
Validation loss: 3.6355533228040624

Epoch: 6| Step: 13
Training loss: 3.250513182984925
Validation loss: 3.6314954769920975

Epoch: 31| Step: 0
Training loss: 4.05839824480996
Validation loss: 3.6276956707800543

Epoch: 6| Step: 1
Training loss: 3.9824594717603676
Validation loss: 3.623646318966366

Epoch: 6| Step: 2
Training loss: 3.470752584762946
Validation loss: 3.619646020973438

Epoch: 6| Step: 3
Training loss: 3.677961264492919
Validation loss: 3.615595929494106

Epoch: 6| Step: 4
Training loss: 3.1170476819951047
Validation loss: 3.6114207933776443

Epoch: 6| Step: 5
Training loss: 4.036483324855429
Validation loss: 3.607445161032101

Epoch: 6| Step: 6
Training loss: 4.067211763922893
Validation loss: 3.6035097144542765

Epoch: 6| Step: 7
Training loss: 3.333040717314868
Validation loss: 3.599394503641783

Epoch: 6| Step: 8
Training loss: 3.999325456963683
Validation loss: 3.595303351788388

Epoch: 6| Step: 9
Training loss: 4.085565670446894
Validation loss: 3.590945523406072

Epoch: 6| Step: 10
Training loss: 3.180418638107733
Validation loss: 3.5872054507460005

Epoch: 6| Step: 11
Training loss: 3.277670224539082
Validation loss: 3.5829618542353248

Epoch: 6| Step: 12
Training loss: 3.9084335937870884
Validation loss: 3.5790197372624184

Epoch: 6| Step: 13
Training loss: 3.924062658262694
Validation loss: 3.57519855792612

Epoch: 32| Step: 0
Training loss: 2.6767571890105533
Validation loss: 3.571229378731181

Epoch: 6| Step: 1
Training loss: 4.341266168926168
Validation loss: 3.567650824684294

Epoch: 6| Step: 2
Training loss: 3.2347078750996117
Validation loss: 3.563609368778493

Epoch: 6| Step: 3
Training loss: 4.04615759658305
Validation loss: 3.559839582615071

Epoch: 6| Step: 4
Training loss: 3.3445815719030207
Validation loss: 3.555749487223974

Epoch: 6| Step: 5
Training loss: 3.424616860448646
Validation loss: 3.55190014110418

Epoch: 6| Step: 6
Training loss: 2.983186974655936
Validation loss: 3.5480468651444204

Epoch: 6| Step: 7
Training loss: 3.6407787634340623
Validation loss: 3.544476139009276

Epoch: 6| Step: 8
Training loss: 3.9189191523158136
Validation loss: 3.540499072123568

Epoch: 6| Step: 9
Training loss: 3.1720665183290375
Validation loss: 3.5365726113523865

Epoch: 6| Step: 10
Training loss: 4.285302242271505
Validation loss: 3.532716699690684

Epoch: 6| Step: 11
Training loss: 3.521661484210968
Validation loss: 3.528868060369491

Epoch: 6| Step: 12
Training loss: 4.560452772717584
Validation loss: 3.5249421486943366

Epoch: 6| Step: 13
Training loss: 3.8752992575977276
Validation loss: 3.520808511379407

Epoch: 33| Step: 0
Training loss: 3.4456742630897854
Validation loss: 3.516807572011227

Epoch: 6| Step: 1
Training loss: 3.856019078393489
Validation loss: 3.51265216737618

Epoch: 6| Step: 2
Training loss: 4.352372866224859
Validation loss: 3.5087122113809364

Epoch: 6| Step: 3
Training loss: 4.237950240890364
Validation loss: 3.5042349194484324

Epoch: 6| Step: 4
Training loss: 4.066779127806824
Validation loss: 3.499835918758422

Epoch: 6| Step: 5
Training loss: 3.3658138579897345
Validation loss: 3.495523030388494

Epoch: 6| Step: 6
Training loss: 3.0616058289850434
Validation loss: 3.4912560548512452

Epoch: 6| Step: 7
Training loss: 4.316658116237661
Validation loss: 3.4872441360884134

Epoch: 6| Step: 8
Training loss: 3.314575552716445
Validation loss: 3.483006092987295

Epoch: 6| Step: 9
Training loss: 2.9732169826762087
Validation loss: 3.4790040090460512

Epoch: 6| Step: 10
Training loss: 3.154060586399415
Validation loss: 3.475101281023442

Epoch: 6| Step: 11
Training loss: 3.4158726831871444
Validation loss: 3.471195973795613

Epoch: 6| Step: 12
Training loss: 3.468614317843612
Validation loss: 3.4673883096592673

Epoch: 6| Step: 13
Training loss: 3.40204661984713
Validation loss: 3.463633684738156

Epoch: 34| Step: 0
Training loss: 3.3146703555617774
Validation loss: 3.4601730524273706

Epoch: 6| Step: 1
Training loss: 4.416818268291362
Validation loss: 3.4561160382964697

Epoch: 6| Step: 2
Training loss: 2.967250083677146
Validation loss: 3.4520669642451507

Epoch: 6| Step: 3
Training loss: 3.040709218567254
Validation loss: 3.4484661774623286

Epoch: 6| Step: 4
Training loss: 4.16699253079592
Validation loss: 3.4449592576480583

Epoch: 6| Step: 5
Training loss: 4.285441553429626
Validation loss: 3.4412777804911414

Epoch: 6| Step: 6
Training loss: 3.8063308331404824
Validation loss: 3.437204197958856

Epoch: 6| Step: 7
Training loss: 2.5235096829604435
Validation loss: 3.4331468009893125

Epoch: 6| Step: 8
Training loss: 3.295812209520191
Validation loss: 3.429247527407099

Epoch: 6| Step: 9
Training loss: 2.4336642872000587
Validation loss: 3.4253868302245842

Epoch: 6| Step: 10
Training loss: 3.7224904971132746
Validation loss: 3.421889910382398

Epoch: 6| Step: 11
Training loss: 3.9523850302530197
Validation loss: 3.418181912995859

Epoch: 6| Step: 12
Training loss: 3.1807733504692948
Validation loss: 3.4144914999143974

Epoch: 6| Step: 13
Training loss: 4.173176880200203
Validation loss: 3.410819741775072

Epoch: 35| Step: 0
Training loss: 4.008312885657887
Validation loss: 3.4070850130437575

Epoch: 6| Step: 1
Training loss: 3.248589429655693
Validation loss: 3.403223168598026

Epoch: 6| Step: 2
Training loss: 3.6118396089413736
Validation loss: 3.399457405776181

Epoch: 6| Step: 3
Training loss: 3.583317216940426
Validation loss: 3.395604451585011

Epoch: 6| Step: 4
Training loss: 3.731030742394895
Validation loss: 3.3918907510150276

Epoch: 6| Step: 5
Training loss: 2.932214730282778
Validation loss: 3.3883147448173547

Epoch: 6| Step: 6
Training loss: 3.6225010381029747
Validation loss: 3.3845990920147084

Epoch: 6| Step: 7
Training loss: 3.986724998234497
Validation loss: 3.380997050960548

Epoch: 6| Step: 8
Training loss: 3.5537894319700802
Validation loss: 3.377267452604443

Epoch: 6| Step: 9
Training loss: 3.0537532538741363
Validation loss: 3.3734441868154934

Epoch: 6| Step: 10
Training loss: 3.3503290498743015
Validation loss: 3.369577655550813

Epoch: 6| Step: 11
Training loss: 2.7091040663897163
Validation loss: 3.3659168037805585

Epoch: 6| Step: 12
Training loss: 3.7394150436631683
Validation loss: 3.3621846832330724

Epoch: 6| Step: 13
Training loss: 3.8955007128915
Validation loss: 3.3585245638057866

Epoch: 36| Step: 0
Training loss: 3.566986471318929
Validation loss: 3.3544721207626997

Epoch: 6| Step: 1
Training loss: 3.262768970378525
Validation loss: 3.3505763549726955

Epoch: 6| Step: 2
Training loss: 2.8633750077909284
Validation loss: 3.3470851391746628

Epoch: 6| Step: 3
Training loss: 3.584095999411233
Validation loss: 3.3434652046776465

Epoch: 6| Step: 4
Training loss: 3.7008658813566253
Validation loss: 3.339922202454861

Epoch: 6| Step: 5
Training loss: 3.9825759715696236
Validation loss: 3.336546259418323

Epoch: 6| Step: 6
Training loss: 3.0347442936525058
Validation loss: 3.332879766759199

Epoch: 6| Step: 7
Training loss: 3.327119057371381
Validation loss: 3.3291638563301023

Epoch: 6| Step: 8
Training loss: 3.74295259112726
Validation loss: 3.3254675605746824

Epoch: 6| Step: 9
Training loss: 3.602813701961971
Validation loss: 3.3218701587162047

Epoch: 6| Step: 10
Training loss: 3.8259615020011535
Validation loss: 3.318237997001491

Epoch: 6| Step: 11
Training loss: 3.0982670031570168
Validation loss: 3.314524913363324

Epoch: 6| Step: 12
Training loss: 3.8679569596319117
Validation loss: 3.3107518555564126

Epoch: 6| Step: 13
Training loss: 2.8679171680954525
Validation loss: 3.3069194714431345

Epoch: 37| Step: 0
Training loss: 3.604570237572742
Validation loss: 3.303368319400884

Epoch: 6| Step: 1
Training loss: 3.2168245945508023
Validation loss: 3.29965317088421

Epoch: 6| Step: 2
Training loss: 3.861596830875605
Validation loss: 3.2963520135428976

Epoch: 6| Step: 3
Training loss: 3.154214032387367
Validation loss: 3.292690303036687

Epoch: 6| Step: 4
Training loss: 3.2090056239310933
Validation loss: 3.2891683553906064

Epoch: 6| Step: 5
Training loss: 3.9695292030814198
Validation loss: 3.285914493467553

Epoch: 6| Step: 6
Training loss: 3.673761929975818
Validation loss: 3.282360785041167

Epoch: 6| Step: 7
Training loss: 3.197413269250611
Validation loss: 3.2785804424880274

Epoch: 6| Step: 8
Training loss: 3.7103335240405464
Validation loss: 3.2753115367496726

Epoch: 6| Step: 9
Training loss: 2.9154733305607405
Validation loss: 3.2717686346497015

Epoch: 6| Step: 10
Training loss: 3.182007639062369
Validation loss: 3.268233624742768

Epoch: 6| Step: 11
Training loss: 2.9253007522247687
Validation loss: 3.264830034708993

Epoch: 6| Step: 12
Training loss: 3.393919860073535
Validation loss: 3.2615018426037192

Epoch: 6| Step: 13
Training loss: 3.6707855556350584
Validation loss: 3.2582400229736503

Epoch: 38| Step: 0
Training loss: 3.4023807492965266
Validation loss: 3.2547126005990092

Epoch: 6| Step: 1
Training loss: 3.5095334323845533
Validation loss: 3.2514015012468676

Epoch: 6| Step: 2
Training loss: 3.125636989522455
Validation loss: 3.248094048752941

Epoch: 6| Step: 3
Training loss: 3.602066898400383
Validation loss: 3.244607449726835

Epoch: 6| Step: 4
Training loss: 2.6564280730751726
Validation loss: 3.241236584791694

Epoch: 6| Step: 5
Training loss: 3.1704060577831394
Validation loss: 3.238107821579667

Epoch: 6| Step: 6
Training loss: 3.8307443804755392
Validation loss: 3.23503710470485

Epoch: 6| Step: 7
Training loss: 2.9613233329996844
Validation loss: 3.2318195438735757

Epoch: 6| Step: 8
Training loss: 3.389423772850319
Validation loss: 3.228718453751737

Epoch: 6| Step: 9
Training loss: 4.068862158757381
Validation loss: 3.2253768380376977

Epoch: 6| Step: 10
Training loss: 3.6167339922238977
Validation loss: 3.221936595980383

Epoch: 6| Step: 11
Training loss: 3.38370746993079
Validation loss: 3.2185659757185814

Epoch: 6| Step: 12
Training loss: 2.9325552370766794
Validation loss: 3.2151788202432137

Epoch: 6| Step: 13
Training loss: 3.316511783785383
Validation loss: 3.2116582452940454

Epoch: 39| Step: 0
Training loss: 3.6861195970859377
Validation loss: 3.2084331538207262

Epoch: 6| Step: 1
Training loss: 3.4817777113845363
Validation loss: 3.204985758868321

Epoch: 6| Step: 2
Training loss: 3.8340672053106823
Validation loss: 3.2014898204730007

Epoch: 6| Step: 3
Training loss: 3.1563397385332186
Validation loss: 3.1980445827949473

Epoch: 6| Step: 4
Training loss: 3.493565912463797
Validation loss: 3.194841444989443

Epoch: 6| Step: 5
Training loss: 2.320664915300976
Validation loss: 3.1913022569501064

Epoch: 6| Step: 6
Training loss: 3.3129988960427776
Validation loss: 3.18809083686098

Epoch: 6| Step: 7
Training loss: 3.310070658502961
Validation loss: 3.184850027524862

Epoch: 6| Step: 8
Training loss: 3.8868949198453926
Validation loss: 3.181503951772917

Epoch: 6| Step: 9
Training loss: 2.311073481832141
Validation loss: 3.178194862580596

Epoch: 6| Step: 10
Training loss: 3.0258448280137853
Validation loss: 3.175257578236127

Epoch: 6| Step: 11
Training loss: 3.2014940529130147
Validation loss: 3.1719531470883697

Epoch: 6| Step: 12
Training loss: 3.863222991534946
Validation loss: 3.168948171464427

Epoch: 6| Step: 13
Training loss: 3.248624217000743
Validation loss: 3.1657117650354163

Epoch: 40| Step: 0
Training loss: 3.3702078812322136
Validation loss: 3.162909365910943

Epoch: 6| Step: 1
Training loss: 3.5146109920032207
Validation loss: 3.159625498836459

Epoch: 6| Step: 2
Training loss: 3.6051301642210594
Validation loss: 3.1562922131828315

Epoch: 6| Step: 3
Training loss: 3.388415201014021
Validation loss: 3.1536290330804224

Epoch: 6| Step: 4
Training loss: 3.693167001120982
Validation loss: 3.149970590867909

Epoch: 6| Step: 5
Training loss: 3.187776441367355
Validation loss: 3.146701507685283

Epoch: 6| Step: 6
Training loss: 3.5954551300444684
Validation loss: 3.1434734832112876

Epoch: 6| Step: 7
Training loss: 2.8594538776795577
Validation loss: 3.1403140140245975

Epoch: 6| Step: 8
Training loss: 2.770840656777554
Validation loss: 3.1371405077658365

Epoch: 6| Step: 9
Training loss: 3.5363032550921165
Validation loss: 3.134253141316985

Epoch: 6| Step: 10
Training loss: 3.378769923640764
Validation loss: 3.131292061386804

Epoch: 6| Step: 11
Training loss: 2.8416518970750784
Validation loss: 3.1281019074676593

Epoch: 6| Step: 12
Training loss: 2.978033548333941
Validation loss: 3.1251236446079584

Epoch: 6| Step: 13
Training loss: 3.0929820330961615
Validation loss: 3.1225967703149053

Epoch: 41| Step: 0
Training loss: 3.193483608057452
Validation loss: 3.1194607023647896

Epoch: 6| Step: 1
Training loss: 3.371311291231899
Validation loss: 3.116609779559523

Epoch: 6| Step: 2
Training loss: 3.123874461612775
Validation loss: 3.113721381665546

Epoch: 6| Step: 3
Training loss: 2.783109065022436
Validation loss: 3.1111019329283827

Epoch: 6| Step: 4
Training loss: 3.415157605132669
Validation loss: 3.1087021091618743

Epoch: 6| Step: 5
Training loss: 3.0907345342560038
Validation loss: 3.1060396641337533

Epoch: 6| Step: 6
Training loss: 3.104213398489907
Validation loss: 3.1032819105764506

Epoch: 6| Step: 7
Training loss: 3.3023933401506382
Validation loss: 3.1004703241855736

Epoch: 6| Step: 8
Training loss: 2.674764219927085
Validation loss: 3.0977278032092284

Epoch: 6| Step: 9
Training loss: 2.8410692259999277
Validation loss: 3.095084958777181

Epoch: 6| Step: 10
Training loss: 3.836014570095169
Validation loss: 3.0921875190188715

Epoch: 6| Step: 11
Training loss: 3.377930675637684
Validation loss: 3.089653668382217

Epoch: 6| Step: 12
Training loss: 3.533533219015734
Validation loss: 3.086920215568778

Epoch: 6| Step: 13
Training loss: 3.548921641585685
Validation loss: 3.0838848385442272

Epoch: 42| Step: 0
Training loss: 3.350002824013502
Validation loss: 3.080790080835776

Epoch: 6| Step: 1
Training loss: 3.1152176907370617
Validation loss: 3.077786189762866

Epoch: 6| Step: 2
Training loss: 3.3508348364179557
Validation loss: 3.074880229095744

Epoch: 6| Step: 3
Training loss: 3.280464586989797
Validation loss: 3.072099781834822

Epoch: 6| Step: 4
Training loss: 3.0501320669629255
Validation loss: 3.0692184479158895

Epoch: 6| Step: 5
Training loss: 3.521706301719911
Validation loss: 3.0665151524086727

Epoch: 6| Step: 6
Training loss: 2.7306418084351747
Validation loss: 3.063663949161348

Epoch: 6| Step: 7
Training loss: 3.6024495850740905
Validation loss: 3.0607236524276327

Epoch: 6| Step: 8
Training loss: 3.1193558649123205
Validation loss: 3.057985260686122

Epoch: 6| Step: 9
Training loss: 2.868482416842122
Validation loss: 3.0550164633399404

Epoch: 6| Step: 10
Training loss: 2.964204219150906
Validation loss: 3.052250806533982

Epoch: 6| Step: 11
Training loss: 2.8233843107549212
Validation loss: 3.049499815695305

Epoch: 6| Step: 12
Training loss: 3.7331051762436287
Validation loss: 3.04682850598457

Epoch: 6| Step: 13
Training loss: 3.188941180974163
Validation loss: 3.0440186112436862

Epoch: 43| Step: 0
Training loss: 3.0009120508441853
Validation loss: 3.0414581140237256

Epoch: 6| Step: 1
Training loss: 3.4222499694222295
Validation loss: 3.038847378763609

Epoch: 6| Step: 2
Training loss: 3.101165515466933
Validation loss: 3.0362230387496134

Epoch: 6| Step: 3
Training loss: 3.062289950894129
Validation loss: 3.033305595257152

Epoch: 6| Step: 4
Training loss: 3.136910742635688
Validation loss: 3.030460097439975

Epoch: 6| Step: 5
Training loss: 3.759219724979351
Validation loss: 3.027706447737136

Epoch: 6| Step: 6
Training loss: 2.963821013592142
Validation loss: 3.025011899625214

Epoch: 6| Step: 7
Training loss: 2.741109869941699
Validation loss: 3.022689529673508

Epoch: 6| Step: 8
Training loss: 3.0659384595414356
Validation loss: 3.020044964925071

Epoch: 6| Step: 9
Training loss: 3.1136638257917224
Validation loss: 3.017804019048732

Epoch: 6| Step: 10
Training loss: 2.863878050013925
Validation loss: 3.0151153291877946

Epoch: 6| Step: 11
Training loss: 2.851139235763737
Validation loss: 3.0125088049204614

Epoch: 6| Step: 12
Training loss: 3.595131915222862
Validation loss: 3.0102246409136026

Epoch: 6| Step: 13
Training loss: 3.476649456865453
Validation loss: 3.0071807594227735

Epoch: 44| Step: 0
Training loss: 3.182515754031424
Validation loss: 3.0047280882634646

Epoch: 6| Step: 1
Training loss: 3.5494276095718336
Validation loss: 3.0026867544435043

Epoch: 6| Step: 2
Training loss: 3.3249282886544824
Validation loss: 2.9999915096374745

Epoch: 6| Step: 3
Training loss: 3.0785612000575853
Validation loss: 2.997079725966467

Epoch: 6| Step: 4
Training loss: 3.7895545246748195
Validation loss: 2.9947030140014714

Epoch: 6| Step: 5
Training loss: 2.888746321249534
Validation loss: 2.9924652262881897

Epoch: 6| Step: 6
Training loss: 2.8512313859558587
Validation loss: 2.9901359171472657

Epoch: 6| Step: 7
Training loss: 2.303255625608715
Validation loss: 2.9877867312344666

Epoch: 6| Step: 8
Training loss: 2.840597228532425
Validation loss: 2.9855187373116636

Epoch: 6| Step: 9
Training loss: 2.910085137029627
Validation loss: 2.9838300943138827

Epoch: 6| Step: 10
Training loss: 3.2423022146498077
Validation loss: 2.9828989929266747

Epoch: 6| Step: 11
Training loss: 3.3278596440942363
Validation loss: 2.978736597421333

Epoch: 6| Step: 12
Training loss: 2.9278508240162906
Validation loss: 2.9754986668304206

Epoch: 6| Step: 13
Training loss: 3.3445422223380517
Validation loss: 2.9731900925908694

Epoch: 45| Step: 0
Training loss: 2.7627349235793663
Validation loss: 2.971085295797647

Epoch: 6| Step: 1
Training loss: 2.905144758179703
Validation loss: 2.9689285626167

Epoch: 6| Step: 2
Training loss: 3.537596679013409
Validation loss: 2.9669002860661684

Epoch: 6| Step: 3
Training loss: 2.768715720900949
Validation loss: 2.9646437505881904

Epoch: 6| Step: 4
Training loss: 3.697910935661639
Validation loss: 2.9620341314254928

Epoch: 6| Step: 5
Training loss: 3.365018991583956
Validation loss: 2.9594885804650497

Epoch: 6| Step: 6
Training loss: 3.2622312588556444
Validation loss: 2.9564280262115132

Epoch: 6| Step: 7
Training loss: 2.8914275833658074
Validation loss: 2.954053029904362

Epoch: 6| Step: 8
Training loss: 2.5415734654415987
Validation loss: 2.9518848486170723

Epoch: 6| Step: 9
Training loss: 3.708340734124389
Validation loss: 2.949303200967335

Epoch: 6| Step: 10
Training loss: 3.462987150771526
Validation loss: 2.9470871520982858

Epoch: 6| Step: 11
Training loss: 2.6326551984664555
Validation loss: 2.94452490086865

Epoch: 6| Step: 12
Training loss: 2.4575829303521184
Validation loss: 2.9421150937374234

Epoch: 6| Step: 13
Training loss: 3.003857199239886
Validation loss: 2.939635048746377

Epoch: 46| Step: 0
Training loss: 2.907104038556448
Validation loss: 2.9377991950069897

Epoch: 6| Step: 1
Training loss: 3.041603261905147
Validation loss: 2.935192324474471

Epoch: 6| Step: 2
Training loss: 3.095759500176745
Validation loss: 2.9327583190107998

Epoch: 6| Step: 3
Training loss: 3.301721851928172
Validation loss: 2.93083004522225

Epoch: 6| Step: 4
Training loss: 3.168249604632024
Validation loss: 2.928899891418138

Epoch: 6| Step: 5
Training loss: 3.2150731984017944
Validation loss: 2.9266419785015128

Epoch: 6| Step: 6
Training loss: 3.1100159564329535
Validation loss: 2.9249168107030123

Epoch: 6| Step: 7
Training loss: 2.6877536210440316
Validation loss: 2.922327329605159

Epoch: 6| Step: 8
Training loss: 2.831738266094876
Validation loss: 2.919785525945729

Epoch: 6| Step: 9
Training loss: 3.379927111635436
Validation loss: 2.917775451984949

Epoch: 6| Step: 10
Training loss: 2.9065072550792173
Validation loss: 2.9156452888308926

Epoch: 6| Step: 11
Training loss: 2.8822998583509154
Validation loss: 2.912604082073276

Epoch: 6| Step: 12
Training loss: 3.4734100107331316
Validation loss: 2.9106952074291015

Epoch: 6| Step: 13
Training loss: 2.7967846392307907
Validation loss: 2.9083511113349405

Epoch: 47| Step: 0
Training loss: 3.2286206347770414
Validation loss: 2.906069992670865

Epoch: 6| Step: 1
Training loss: 3.009222161045337
Validation loss: 2.9060216971250545

Epoch: 6| Step: 2
Training loss: 2.5649131019551237
Validation loss: 2.9022862055170817

Epoch: 6| Step: 3
Training loss: 2.866933535936105
Validation loss: 2.900151461449722

Epoch: 6| Step: 4
Training loss: 3.238019576043559
Validation loss: 2.9060603459321905

Epoch: 6| Step: 5
Training loss: 2.8853887196276506
Validation loss: 2.8948658669538774

Epoch: 6| Step: 6
Training loss: 3.239699546634814
Validation loss: 2.891896973232325

Epoch: 6| Step: 7
Training loss: 3.2568510178155363
Validation loss: 2.891480176740402

Epoch: 6| Step: 8
Training loss: 3.033452128784457
Validation loss: 2.8884452780814507

Epoch: 6| Step: 9
Training loss: 3.4609661574716477
Validation loss: 2.8869163710520405

Epoch: 6| Step: 10
Training loss: 2.9919406400595814
Validation loss: 2.885096457624734

Epoch: 6| Step: 11
Training loss: 2.8356492918074214
Validation loss: 2.8834417357674975

Epoch: 6| Step: 12
Training loss: 2.854776823069308
Validation loss: 2.883097309768207

Epoch: 6| Step: 13
Training loss: 2.899806765991543
Validation loss: 2.8828274417203965

Epoch: 48| Step: 0
Training loss: 3.247586454513723
Validation loss: 2.88039544976803

Epoch: 6| Step: 1
Training loss: 2.466630436227393
Validation loss: 2.877699842056373

Epoch: 6| Step: 2
Training loss: 2.6117902530851973
Validation loss: 2.873643928485072

Epoch: 6| Step: 3
Training loss: 3.3996888411012844
Validation loss: 2.8719433692982346

Epoch: 6| Step: 4
Training loss: 3.5192678609130437
Validation loss: 2.8689285798958775

Epoch: 6| Step: 5
Training loss: 2.5201311210549284
Validation loss: 2.8664538062340585

Epoch: 6| Step: 6
Training loss: 3.3359069108118917
Validation loss: 2.864790230417482

Epoch: 6| Step: 7
Training loss: 2.870331830503175
Validation loss: 2.861715376929453

Epoch: 6| Step: 8
Training loss: 2.943044745646578
Validation loss: 2.86065090875309

Epoch: 6| Step: 9
Training loss: 2.790930712658214
Validation loss: 2.859342244834411

Epoch: 6| Step: 10
Training loss: 3.2340512320966983
Validation loss: 2.8578170395348064

Epoch: 6| Step: 11
Training loss: 2.6667407939462673
Validation loss: 2.856368549760936

Epoch: 6| Step: 12
Training loss: 3.2655553490908824
Validation loss: 2.85411208627309

Epoch: 6| Step: 13
Training loss: 2.9789587272865923
Validation loss: 2.852130098333351

Epoch: 49| Step: 0
Training loss: 2.8545282696359617
Validation loss: 2.8502664207277917

Epoch: 6| Step: 1
Training loss: 3.5849586763221555
Validation loss: 2.8478743020966713

Epoch: 6| Step: 2
Training loss: 2.8114339715543584
Validation loss: 2.845768418323375

Epoch: 6| Step: 3
Training loss: 2.6694075585060864
Validation loss: 2.8432925488661387

Epoch: 6| Step: 4
Training loss: 2.3257278287606398
Validation loss: 2.8416485550005866

Epoch: 6| Step: 5
Training loss: 3.0944277858989624
Validation loss: 2.8395464644040826

Epoch: 6| Step: 6
Training loss: 2.77956708075792
Validation loss: 2.8378404410279527

Epoch: 6| Step: 7
Training loss: 3.071267947562553
Validation loss: 2.8391051873381703

Epoch: 6| Step: 8
Training loss: 3.4561033911074497
Validation loss: 2.836245307296428

Epoch: 6| Step: 9
Training loss: 2.1751835274272198
Validation loss: 2.8345739976814337

Epoch: 6| Step: 10
Training loss: 2.9273630101364665
Validation loss: 2.8305545157581533

Epoch: 6| Step: 11
Training loss: 3.397653353319931
Validation loss: 2.827712434635342

Epoch: 6| Step: 12
Training loss: 3.2229157684331495
Validation loss: 2.8250845764237837

Epoch: 6| Step: 13
Training loss: 2.9698747612335623
Validation loss: 2.826432102528064

Epoch: 50| Step: 0
Training loss: 2.9809022840616604
Validation loss: 2.8265200815414735

Epoch: 6| Step: 1
Training loss: 2.558339812511809
Validation loss: 2.8283109515969307

Epoch: 6| Step: 2
Training loss: 3.3514973382906534
Validation loss: 2.82136025872059

Epoch: 6| Step: 3
Training loss: 2.81566890635747
Validation loss: 2.8192163311444522

Epoch: 6| Step: 4
Training loss: 2.7261640809594487
Validation loss: 2.8159366239050287

Epoch: 6| Step: 5
Training loss: 2.3181128559632675
Validation loss: 2.812294436819199

Epoch: 6| Step: 6
Training loss: 2.919251921992622
Validation loss: 2.8132074384709145

Epoch: 6| Step: 7
Training loss: 2.785674529787531
Validation loss: 2.8112994139339844

Epoch: 6| Step: 8
Training loss: 3.3567037208226713
Validation loss: 2.8093649734244597

Epoch: 6| Step: 9
Training loss: 3.045203430195496
Validation loss: 2.808533039595242

Epoch: 6| Step: 10
Training loss: 3.351793685800248
Validation loss: 2.80628026650015

Epoch: 6| Step: 11
Training loss: 2.644462911379293
Validation loss: 2.801942535795905

Epoch: 6| Step: 12
Training loss: 2.9905810314043504
Validation loss: 2.803321668741979

Epoch: 6| Step: 13
Training loss: 3.306856350021533
Validation loss: 2.799333717057118

Epoch: 51| Step: 0
Training loss: 2.6624976789437507
Validation loss: 2.7958677243326675

Epoch: 6| Step: 1
Training loss: 3.2548675765657507
Validation loss: 2.7951404300366898

Epoch: 6| Step: 2
Training loss: 3.2011641292233928
Validation loss: 2.794148357417456

Epoch: 6| Step: 3
Training loss: 3.510353578326982
Validation loss: 2.792028536520483

Epoch: 6| Step: 4
Training loss: 3.1478140618403625
Validation loss: 2.790819428588576

Epoch: 6| Step: 5
Training loss: 2.599756845695051
Validation loss: 2.7894504109955127

Epoch: 6| Step: 6
Training loss: 2.7890243741376106
Validation loss: 2.788118859946821

Epoch: 6| Step: 7
Training loss: 3.1001477606229213
Validation loss: 2.7857963037002986

Epoch: 6| Step: 8
Training loss: 3.138966744131604
Validation loss: 2.7809727276952305

Epoch: 6| Step: 9
Training loss: 2.659651608991933
Validation loss: 2.778635961103316

Epoch: 6| Step: 10
Training loss: 2.056795960272283
Validation loss: 2.77958073331467

Epoch: 6| Step: 11
Training loss: 2.7193571267826147
Validation loss: 2.7770763184405647

Epoch: 6| Step: 12
Training loss: 3.2344190806457975
Validation loss: 2.776866616113293

Epoch: 6| Step: 13
Training loss: 2.62742012722811
Validation loss: 2.772575452194653

Epoch: 52| Step: 0
Training loss: 2.6324456296053618
Validation loss: 2.774486332683548

Epoch: 6| Step: 1
Training loss: 2.5815513268702177
Validation loss: 2.770334088850448

Epoch: 6| Step: 2
Training loss: 2.1989119266568746
Validation loss: 2.769815033155001

Epoch: 6| Step: 3
Training loss: 2.705489959765846
Validation loss: 2.7690669335463007

Epoch: 6| Step: 4
Training loss: 3.1832484894741953
Validation loss: 2.7689426444080865

Epoch: 6| Step: 5
Training loss: 3.3524133273647325
Validation loss: 2.7665328064290247

Epoch: 6| Step: 6
Training loss: 3.2883369569779424
Validation loss: 2.765024339064063

Epoch: 6| Step: 7
Training loss: 2.309518903035124
Validation loss: 2.764360300327299

Epoch: 6| Step: 8
Training loss: 2.973825553072167
Validation loss: 2.76035230069722

Epoch: 6| Step: 9
Training loss: 3.072233031355238
Validation loss: 2.7595906635248317

Epoch: 6| Step: 10
Training loss: 2.9656768955075608
Validation loss: 2.756382125490298

Epoch: 6| Step: 11
Training loss: 2.9297561840907127
Validation loss: 2.7557728603092793

Epoch: 6| Step: 12
Training loss: 2.9298941984375624
Validation loss: 2.7532461398806647

Epoch: 6| Step: 13
Training loss: 3.2926394477806182
Validation loss: 2.7523452266472956

Epoch: 53| Step: 0
Training loss: 3.497810087384629
Validation loss: 2.751475516306756

Epoch: 6| Step: 1
Training loss: 2.672508298541639
Validation loss: 2.7515031290084475

Epoch: 6| Step: 2
Training loss: 2.9532690265391053
Validation loss: 2.7491164522035967

Epoch: 6| Step: 3
Training loss: 2.678811155218349
Validation loss: 2.74773929612535

Epoch: 6| Step: 4
Training loss: 2.5762542410662457
Validation loss: 2.7471052453036857

Epoch: 6| Step: 5
Training loss: 2.6526807253550446
Validation loss: 2.7441544393279953

Epoch: 6| Step: 6
Training loss: 3.0954535831994296
Validation loss: 2.7430421198476966

Epoch: 6| Step: 7
Training loss: 2.846743004227234
Validation loss: 2.7409832258132214

Epoch: 6| Step: 8
Training loss: 2.5626771446963854
Validation loss: 2.739972762554884

Epoch: 6| Step: 9
Training loss: 2.7410071459972443
Validation loss: 2.7396499906101157

Epoch: 6| Step: 10
Training loss: 2.4805021028454015
Validation loss: 2.7376938070499164

Epoch: 6| Step: 11
Training loss: 3.3800663538632723
Validation loss: 2.7361846022141116

Epoch: 6| Step: 12
Training loss: 3.247938529367783
Validation loss: 2.7315194905564626

Epoch: 6| Step: 13
Training loss: 2.7627046328050633
Validation loss: 2.730792388872926

Epoch: 54| Step: 0
Training loss: 3.1405568281527616
Validation loss: 2.729532309540385

Epoch: 6| Step: 1
Training loss: 2.705812298131285
Validation loss: 2.728161769996394

Epoch: 6| Step: 2
Training loss: 2.791393855035628
Validation loss: 2.7263664313559723

Epoch: 6| Step: 3
Training loss: 2.187083395387873
Validation loss: 2.7252952888154383

Epoch: 6| Step: 4
Training loss: 3.112512586943519
Validation loss: 2.724162571229965

Epoch: 6| Step: 5
Training loss: 3.0921848846470747
Validation loss: 2.722064705160217

Epoch: 6| Step: 6
Training loss: 2.9703490117059936
Validation loss: 2.720882631666303

Epoch: 6| Step: 7
Training loss: 3.0742404650996087
Validation loss: 2.720469373240235

Epoch: 6| Step: 8
Training loss: 3.155858988194679
Validation loss: 2.720816984804195

Epoch: 6| Step: 9
Training loss: 2.5888102729150297
Validation loss: 2.722082178791089

Epoch: 6| Step: 10
Training loss: 2.7399200890019055
Validation loss: 2.7221413284617584

Epoch: 6| Step: 11
Training loss: 3.1206696070533835
Validation loss: 2.720529288283552

Epoch: 6| Step: 12
Training loss: 2.614285536951421
Validation loss: 2.719351106452641

Epoch: 6| Step: 13
Training loss: 2.661719312519432
Validation loss: 2.716018810331614

Epoch: 55| Step: 0
Training loss: 2.6100396320651775
Validation loss: 2.713946516669593

Epoch: 6| Step: 1
Training loss: 2.847664454988608
Validation loss: 2.7118526237029417

Epoch: 6| Step: 2
Training loss: 2.028572077914159
Validation loss: 2.714607824965037

Epoch: 6| Step: 3
Training loss: 3.02393536078785
Validation loss: 2.735608750799754

Epoch: 6| Step: 4
Training loss: 2.885800020571077
Validation loss: 2.7233675771386725

Epoch: 6| Step: 5
Training loss: 2.7507536462310505
Validation loss: 2.7142475452344654

Epoch: 6| Step: 6
Training loss: 2.5825445960478923
Validation loss: 2.71088927534819

Epoch: 6| Step: 7
Training loss: 2.88224278224624
Validation loss: 2.7032094365274624

Epoch: 6| Step: 8
Training loss: 3.32281844772227
Validation loss: 2.700637834467396

Epoch: 6| Step: 9
Training loss: 2.973824430659074
Validation loss: 2.700024026010309

Epoch: 6| Step: 10
Training loss: 2.4402714159361576
Validation loss: 2.700526890737177

Epoch: 6| Step: 11
Training loss: 2.855106690880149
Validation loss: 2.703674980765331

Epoch: 6| Step: 12
Training loss: 3.087415278581259
Validation loss: 2.7029856533818113

Epoch: 6| Step: 13
Training loss: 3.2922701383049082
Validation loss: 2.7017014711347502

Epoch: 56| Step: 0
Training loss: 2.638691482075793
Validation loss: 2.7012709799179384

Epoch: 6| Step: 1
Training loss: 2.7081886448480623
Validation loss: 2.701116885427481

Epoch: 6| Step: 2
Training loss: 2.763153005896811
Validation loss: 2.700031281513744

Epoch: 6| Step: 3
Training loss: 3.146499378019399
Validation loss: 2.6996904578378365

Epoch: 6| Step: 4
Training loss: 2.393236118067185
Validation loss: 2.69858818583279

Epoch: 6| Step: 5
Training loss: 2.8065843888437882
Validation loss: 2.6971058799366605

Epoch: 6| Step: 6
Training loss: 2.991170924632394
Validation loss: 2.694628642582005

Epoch: 6| Step: 7
Training loss: 2.562166331827558
Validation loss: 2.6926696794245424

Epoch: 6| Step: 8
Training loss: 3.227412003455907
Validation loss: 2.6920038823000088

Epoch: 6| Step: 9
Training loss: 3.1344479979270647
Validation loss: 2.690266774455435

Epoch: 6| Step: 10
Training loss: 2.9813250390291706
Validation loss: 2.6885371313952255

Epoch: 6| Step: 11
Training loss: 2.567779777311857
Validation loss: 2.6842661186047674

Epoch: 6| Step: 12
Training loss: 2.962020796636484
Validation loss: 2.682351822163106

Epoch: 6| Step: 13
Training loss: 2.6416948848464736
Validation loss: 2.678903878486172

Epoch: 57| Step: 0
Training loss: 3.4107729779074614
Validation loss: 2.6778728839750934

Epoch: 6| Step: 1
Training loss: 3.2195054436223076
Validation loss: 2.674561575734579

Epoch: 6| Step: 2
Training loss: 2.6058943142133306
Validation loss: 2.674578156290681

Epoch: 6| Step: 3
Training loss: 2.5583410240165434
Validation loss: 2.6719818540031195

Epoch: 6| Step: 4
Training loss: 2.4503033197223925
Validation loss: 2.6698791604670378

Epoch: 6| Step: 5
Training loss: 3.0964035830178505
Validation loss: 2.6720201181484313

Epoch: 6| Step: 6
Training loss: 3.160196084807649
Validation loss: 2.672964769873578

Epoch: 6| Step: 7
Training loss: 2.3815276136797654
Validation loss: 2.6776175998681473

Epoch: 6| Step: 8
Training loss: 2.8590614688932723
Validation loss: 2.6766360066258437

Epoch: 6| Step: 9
Training loss: 2.884678347951913
Validation loss: 2.6737389114242687

Epoch: 6| Step: 10
Training loss: 2.6432959236522002
Validation loss: 2.668031899341103

Epoch: 6| Step: 11
Training loss: 2.6054114660002416
Validation loss: 2.67581280692025

Epoch: 6| Step: 12
Training loss: 2.5791656243522976
Validation loss: 2.6794927468813574

Epoch: 6| Step: 13
Training loss: 2.689459685052366
Validation loss: 2.662082730759569

Epoch: 58| Step: 0
Training loss: 2.809598909987627
Validation loss: 2.6597213800449437

Epoch: 6| Step: 1
Training loss: 2.655384865289097
Validation loss: 2.6602080830711765

Epoch: 6| Step: 2
Training loss: 2.746811318554438
Validation loss: 2.6612627936766886

Epoch: 6| Step: 3
Training loss: 3.0893128297026875
Validation loss: 2.662460859963199

Epoch: 6| Step: 4
Training loss: 3.1753292723998214
Validation loss: 2.6601433587940595

Epoch: 6| Step: 5
Training loss: 2.583465685581653
Validation loss: 2.6578627234573995

Epoch: 6| Step: 6
Training loss: 2.693389206375994
Validation loss: 2.6564257470127397

Epoch: 6| Step: 7
Training loss: 2.4774624606309272
Validation loss: 2.657121388238274

Epoch: 6| Step: 8
Training loss: 3.042843386377853
Validation loss: 2.655768795930962

Epoch: 6| Step: 9
Training loss: 2.826976564022113
Validation loss: 2.6542764250749045

Epoch: 6| Step: 10
Training loss: 3.278702391767099
Validation loss: 2.6546495290835646

Epoch: 6| Step: 11
Training loss: 2.6920770216206917
Validation loss: 2.65248587690567

Epoch: 6| Step: 12
Training loss: 2.235812065183546
Validation loss: 2.6530758760694964

Epoch: 6| Step: 13
Training loss: 2.676885446638965
Validation loss: 2.649557651331921

Epoch: 59| Step: 0
Training loss: 2.9845215127341844
Validation loss: 2.6503121522077766

Epoch: 6| Step: 1
Training loss: 3.1524193812566033
Validation loss: 2.647046034029895

Epoch: 6| Step: 2
Training loss: 3.0857477443637067
Validation loss: 2.6448777843716513

Epoch: 6| Step: 3
Training loss: 3.1542418483977404
Validation loss: 2.6448100406528834

Epoch: 6| Step: 4
Training loss: 2.757422400702953
Validation loss: 2.6434565303839173

Epoch: 6| Step: 5
Training loss: 2.4629066944732503
Validation loss: 2.643553019009794

Epoch: 6| Step: 6
Training loss: 3.406300675601398
Validation loss: 2.641739002725577

Epoch: 6| Step: 7
Training loss: 2.813777887586614
Validation loss: 2.641200963997529

Epoch: 6| Step: 8
Training loss: 2.3367283735775377
Validation loss: 2.64021097883896

Epoch: 6| Step: 9
Training loss: 2.828550865186667
Validation loss: 2.638590086924262

Epoch: 6| Step: 10
Training loss: 2.6303487507317493
Validation loss: 2.6384712931729357

Epoch: 6| Step: 11
Training loss: 2.392798638594485
Validation loss: 2.6366877047747956

Epoch: 6| Step: 12
Training loss: 1.9703129210989712
Validation loss: 2.6348854001898037

Epoch: 6| Step: 13
Training loss: 2.6092713843691304
Validation loss: 2.6356338642668744

Epoch: 60| Step: 0
Training loss: 2.6071099598371155
Validation loss: 2.6330506229346606

Epoch: 6| Step: 1
Training loss: 2.872125930532964
Validation loss: 2.633450348785261

Epoch: 6| Step: 2
Training loss: 2.870633665836276
Validation loss: 2.628382048130223

Epoch: 6| Step: 3
Training loss: 2.960793363339135
Validation loss: 2.632607034123617

Epoch: 6| Step: 4
Training loss: 2.41799911948315
Validation loss: 2.6296759844093587

Epoch: 6| Step: 5
Training loss: 2.575952157577357
Validation loss: 2.6282044031680156

Epoch: 6| Step: 6
Training loss: 2.582162366068643
Validation loss: 2.6287334020661715

Epoch: 6| Step: 7
Training loss: 2.534185802768392
Validation loss: 2.6272929183363694

Epoch: 6| Step: 8
Training loss: 2.8851794938391477
Validation loss: 2.62678022418338

Epoch: 6| Step: 9
Training loss: 3.0719233744820142
Validation loss: 2.628235367170987

Epoch: 6| Step: 10
Training loss: 2.4140354389538077
Validation loss: 2.62821840353876

Epoch: 6| Step: 11
Training loss: 3.375589672427127
Validation loss: 2.6268995012485017

Epoch: 6| Step: 12
Training loss: 2.818132482583473
Validation loss: 2.628704333474798

Epoch: 6| Step: 13
Training loss: 2.6494882125405113
Validation loss: 2.6248065937787617

Epoch: 61| Step: 0
Training loss: 2.594715995609129
Validation loss: 2.6216298979573396

Epoch: 6| Step: 1
Training loss: 2.313260752320745
Validation loss: 2.623985669785036

Epoch: 6| Step: 2
Training loss: 2.569237202944227
Validation loss: 2.6206698048754857

Epoch: 6| Step: 3
Training loss: 2.8226163547208287
Validation loss: 2.6196184094714363

Epoch: 6| Step: 4
Training loss: 2.9024894749650194
Validation loss: 2.6178943950946922

Epoch: 6| Step: 5
Training loss: 2.331498435029534
Validation loss: 2.617415794929718

Epoch: 6| Step: 6
Training loss: 2.633751766745577
Validation loss: 2.6138457870262934

Epoch: 6| Step: 7
Training loss: 3.004167523077544
Validation loss: 2.616171234349803

Epoch: 6| Step: 8
Training loss: 2.9146358140788253
Validation loss: 2.617305711192691

Epoch: 6| Step: 9
Training loss: 3.0343893253133625
Validation loss: 2.6323672256725668

Epoch: 6| Step: 10
Training loss: 2.4432481333339924
Validation loss: 2.647293999245794

Epoch: 6| Step: 11
Training loss: 2.997770911820698
Validation loss: 2.6571755685321183

Epoch: 6| Step: 12
Training loss: 2.7215170098214183
Validation loss: 2.640061026696274

Epoch: 6| Step: 13
Training loss: 3.225300170177055
Validation loss: 2.637868266135876

Epoch: 62| Step: 0
Training loss: 2.676092021186748
Validation loss: 2.6386024509260193

Epoch: 6| Step: 1
Training loss: 2.817943307007142
Validation loss: 2.6183797673220415

Epoch: 6| Step: 2
Training loss: 2.4843677064800564
Validation loss: 2.613873561454298

Epoch: 6| Step: 3
Training loss: 2.494445543163863
Validation loss: 2.606770020344112

Epoch: 6| Step: 4
Training loss: 3.0629613100722497
Validation loss: 2.609383040547118

Epoch: 6| Step: 5
Training loss: 3.0064345336871514
Validation loss: 2.6092509470554726

Epoch: 6| Step: 6
Training loss: 2.569010767265614
Validation loss: 2.6174419829731757

Epoch: 6| Step: 7
Training loss: 3.0375935355647385
Validation loss: 2.613651570613885

Epoch: 6| Step: 8
Training loss: 2.519676594644948
Validation loss: 2.612871017150564

Epoch: 6| Step: 9
Training loss: 2.695558221645702
Validation loss: 2.6122194118188067

Epoch: 6| Step: 10
Training loss: 2.961079858261501
Validation loss: 2.6119688318465832

Epoch: 6| Step: 11
Training loss: 2.5961895236528107
Validation loss: 2.6071782716260623

Epoch: 6| Step: 12
Training loss: 2.807565386750397
Validation loss: 2.6049248977544592

Epoch: 6| Step: 13
Training loss: 2.665139525949728
Validation loss: 2.604725576823062

Epoch: 63| Step: 0
Training loss: 2.9456417800227883
Validation loss: 2.6008215260464294

Epoch: 6| Step: 1
Training loss: 2.851387248467429
Validation loss: 2.5997805979663466

Epoch: 6| Step: 2
Training loss: 2.7735314581630703
Validation loss: 2.5997492950562733

Epoch: 6| Step: 3
Training loss: 2.693714497414138
Validation loss: 2.596608069480587

Epoch: 6| Step: 4
Training loss: 2.3058098597883285
Validation loss: 2.5961742255868225

Epoch: 6| Step: 5
Training loss: 2.747344555609793
Validation loss: 2.5998004830664847

Epoch: 6| Step: 6
Training loss: 2.5427262854238655
Validation loss: 2.609564905622837

Epoch: 6| Step: 7
Training loss: 2.837894153527142
Validation loss: 2.6272912546434344

Epoch: 6| Step: 8
Training loss: 2.261376126020924
Validation loss: 2.611669129632382

Epoch: 6| Step: 9
Training loss: 3.3809208679777383
Validation loss: 2.6136265760798887

Epoch: 6| Step: 10
Training loss: 2.8444399153984623
Validation loss: 2.5975634794950455

Epoch: 6| Step: 11
Training loss: 2.622811540512333
Validation loss: 2.5947029477366783

Epoch: 6| Step: 12
Training loss: 2.834763633387753
Validation loss: 2.5908758486055588

Epoch: 6| Step: 13
Training loss: 2.6011999295725805
Validation loss: 2.5912550757812802

Epoch: 64| Step: 0
Training loss: 2.9702271651401717
Validation loss: 2.5950688146092338

Epoch: 6| Step: 1
Training loss: 2.8637261975222073
Validation loss: 2.599107517606146

Epoch: 6| Step: 2
Training loss: 2.5021151178285566
Validation loss: 2.601634378748098

Epoch: 6| Step: 3
Training loss: 2.6522782195455537
Validation loss: 2.6068435313287885

Epoch: 6| Step: 4
Training loss: 2.9505864287871106
Validation loss: 2.5986492811596484

Epoch: 6| Step: 5
Training loss: 3.1639661986212917
Validation loss: 2.5965917715143667

Epoch: 6| Step: 6
Training loss: 2.2152222002233333
Validation loss: 2.5934585805899495

Epoch: 6| Step: 7
Training loss: 2.876494641101924
Validation loss: 2.59198940226072

Epoch: 6| Step: 8
Training loss: 2.4432442300256665
Validation loss: 2.5917043930529675

Epoch: 6| Step: 9
Training loss: 2.8808072360218278
Validation loss: 2.590456192535625

Epoch: 6| Step: 10
Training loss: 2.383075436952848
Validation loss: 2.5873167234125325

Epoch: 6| Step: 11
Training loss: 2.3538780598134625
Validation loss: 2.5878643375237202

Epoch: 6| Step: 12
Training loss: 2.7266445202227305
Validation loss: 2.5862195186745445

Epoch: 6| Step: 13
Training loss: 3.0290406030784163
Validation loss: 2.5868240173727877

Epoch: 65| Step: 0
Training loss: 3.1475007814826026
Validation loss: 2.5849512837662894

Epoch: 6| Step: 1
Training loss: 2.561495328131605
Validation loss: 2.584537937942916

Epoch: 6| Step: 2
Training loss: 2.9538034134150735
Validation loss: 2.583620275948215

Epoch: 6| Step: 3
Training loss: 2.9421794224738096
Validation loss: 2.581914871217002

Epoch: 6| Step: 4
Training loss: 2.9589635867153423
Validation loss: 2.581511044483743

Epoch: 6| Step: 5
Training loss: 3.0050373700907764
Validation loss: 2.577746955049697

Epoch: 6| Step: 6
Training loss: 2.5354860441003972
Validation loss: 2.5767579278497963

Epoch: 6| Step: 7
Training loss: 2.212738058785286
Validation loss: 2.577748419491254

Epoch: 6| Step: 8
Training loss: 2.6371090748419044
Validation loss: 2.575047160460559

Epoch: 6| Step: 9
Training loss: 2.6916764210936615
Validation loss: 2.5756859695881618

Epoch: 6| Step: 10
Training loss: 2.3213144316227834
Validation loss: 2.573177252377835

Epoch: 6| Step: 11
Training loss: 2.69974743403537
Validation loss: 2.5745571533426164

Epoch: 6| Step: 12
Training loss: 2.424408209254394
Validation loss: 2.578321183572002

Epoch: 6| Step: 13
Training loss: 2.6967325643716835
Validation loss: 2.5941251154128024

Epoch: 66| Step: 0
Training loss: 2.2615892969483404
Validation loss: 2.600277038021893

Epoch: 6| Step: 1
Training loss: 2.3828409161983894
Validation loss: 2.6065861461557596

Epoch: 6| Step: 2
Training loss: 2.7467962156070556
Validation loss: 2.605989357457908

Epoch: 6| Step: 3
Training loss: 2.2547120450508555
Validation loss: 2.6074803035061658

Epoch: 6| Step: 4
Training loss: 3.073700644277963
Validation loss: 2.6086890409738275

Epoch: 6| Step: 5
Training loss: 3.0941531756704803
Validation loss: 2.6044061220068895

Epoch: 6| Step: 6
Training loss: 2.8039570231715336
Validation loss: 2.5962406747105957

Epoch: 6| Step: 7
Training loss: 2.6324841212475727
Validation loss: 2.585302976147077

Epoch: 6| Step: 8
Training loss: 3.100983918847954
Validation loss: 2.585764130987803

Epoch: 6| Step: 9
Training loss: 2.9162120101422917
Validation loss: 2.582412022202691

Epoch: 6| Step: 10
Training loss: 2.709560429300616
Validation loss: 2.574564993943708

Epoch: 6| Step: 11
Training loss: 2.5080412287996556
Validation loss: 2.5714900789019417

Epoch: 6| Step: 12
Training loss: 2.70696175886523
Validation loss: 2.5705625340942486

Epoch: 6| Step: 13
Training loss: 2.784926994914659
Validation loss: 2.5706423747789966

Epoch: 67| Step: 0
Training loss: 2.372197354692863
Validation loss: 2.5721336336674576

Epoch: 6| Step: 1
Training loss: 2.327226913608098
Validation loss: 2.572213410137435

Epoch: 6| Step: 2
Training loss: 3.0713479040965135
Validation loss: 2.5713588513403836

Epoch: 6| Step: 3
Training loss: 3.230489414799383
Validation loss: 2.5692262218929436

Epoch: 6| Step: 4
Training loss: 2.82476379284748
Validation loss: 2.5671032598244583

Epoch: 6| Step: 5
Training loss: 2.5572980788720896
Validation loss: 2.566371164609473

Epoch: 6| Step: 6
Training loss: 2.265565016379981
Validation loss: 2.564645163944789

Epoch: 6| Step: 7
Training loss: 2.9725561538666727
Validation loss: 2.56375651063159

Epoch: 6| Step: 8
Training loss: 2.721944576385879
Validation loss: 2.5631515015877926

Epoch: 6| Step: 9
Training loss: 3.28602470684921
Validation loss: 2.56022300970756

Epoch: 6| Step: 10
Training loss: 2.3915068551965617
Validation loss: 2.5606465343302

Epoch: 6| Step: 11
Training loss: 2.444708703909866
Validation loss: 2.558411150524396

Epoch: 6| Step: 12
Training loss: 2.2231918789056713
Validation loss: 2.5598085892415647

Epoch: 6| Step: 13
Training loss: 2.767016303325637
Validation loss: 2.557285135316504

Epoch: 68| Step: 0
Training loss: 2.7260544093097425
Validation loss: 2.5583512596554363

Epoch: 6| Step: 1
Training loss: 2.224339925173796
Validation loss: 2.556343855996319

Epoch: 6| Step: 2
Training loss: 2.744494128281589
Validation loss: 2.557839396464858

Epoch: 6| Step: 3
Training loss: 2.5666190745742745
Validation loss: 2.5548209681434315

Epoch: 6| Step: 4
Training loss: 2.34716101070648
Validation loss: 2.5547746027136276

Epoch: 6| Step: 5
Training loss: 2.969154571271598
Validation loss: 2.5514542771028372

Epoch: 6| Step: 6
Training loss: 2.7843455543202675
Validation loss: 2.5499641235171464

Epoch: 6| Step: 7
Training loss: 2.9514702899154206
Validation loss: 2.5499170464380625

Epoch: 6| Step: 8
Training loss: 1.8355161142704413
Validation loss: 2.5534970837649813

Epoch: 6| Step: 9
Training loss: 2.74557537976188
Validation loss: 2.55114115755576

Epoch: 6| Step: 10
Training loss: 2.7884301930089945
Validation loss: 2.550534690635968

Epoch: 6| Step: 11
Training loss: 2.8887438452410366
Validation loss: 2.546898660374365

Epoch: 6| Step: 12
Training loss: 2.766142026342809
Validation loss: 2.550189048329146

Epoch: 6| Step: 13
Training loss: 2.999339030885369
Validation loss: 2.545078853392355

Epoch: 69| Step: 0
Training loss: 2.539411784869631
Validation loss: 2.5453309759628997

Epoch: 6| Step: 1
Training loss: 2.7378913286153503
Validation loss: 2.5456133254698465

Epoch: 6| Step: 2
Training loss: 2.374648620311285
Validation loss: 2.548492542064587

Epoch: 6| Step: 3
Training loss: 2.9964635986276207
Validation loss: 2.5450397424149185

Epoch: 6| Step: 4
Training loss: 3.0425424926097477
Validation loss: 2.5448498465629985

Epoch: 6| Step: 5
Training loss: 2.8471595529828675
Validation loss: 2.547759255583925

Epoch: 6| Step: 6
Training loss: 2.6247743782083486
Validation loss: 2.547560211558205

Epoch: 6| Step: 7
Training loss: 2.6428033996331526
Validation loss: 2.545812716819418

Epoch: 6| Step: 8
Training loss: 2.138848897496792
Validation loss: 2.5468542180061817

Epoch: 6| Step: 9
Training loss: 2.4716984006971376
Validation loss: 2.548459049946886

Epoch: 6| Step: 10
Training loss: 3.259913802850339
Validation loss: 2.5475829687012728

Epoch: 6| Step: 11
Training loss: 2.619854925667253
Validation loss: 2.546796520560821

Epoch: 6| Step: 12
Training loss: 2.3443601704115475
Validation loss: 2.549999512566414

Epoch: 6| Step: 13
Training loss: 2.6536157448472584
Validation loss: 2.550372400080906

Epoch: 70| Step: 0
Training loss: 2.653113094882742
Validation loss: 2.5484115864340393

Epoch: 6| Step: 1
Training loss: 2.421045665872797
Validation loss: 2.5465721777251735

Epoch: 6| Step: 2
Training loss: 2.8137963592221586
Validation loss: 2.546838803024348

Epoch: 6| Step: 3
Training loss: 1.9843347500300956
Validation loss: 2.5453208909151086

Epoch: 6| Step: 4
Training loss: 2.602842457104607
Validation loss: 2.545573738793958

Epoch: 6| Step: 5
Training loss: 2.698243247828239
Validation loss: 2.542536904446344

Epoch: 6| Step: 6
Training loss: 3.0285421645095045
Validation loss: 2.5444504132078185

Epoch: 6| Step: 7
Training loss: 3.0434568354047946
Validation loss: 2.540378202280949

Epoch: 6| Step: 8
Training loss: 2.3984447566118337
Validation loss: 2.538433118233536

Epoch: 6| Step: 9
Training loss: 2.5610887316399267
Validation loss: 2.537763824904247

Epoch: 6| Step: 10
Training loss: 2.6951566347029807
Validation loss: 2.5383586514421554

Epoch: 6| Step: 11
Training loss: 2.7256690367684127
Validation loss: 2.5331167394084693

Epoch: 6| Step: 12
Training loss: 2.816514435064597
Validation loss: 2.538195840673125

Epoch: 6| Step: 13
Training loss: 2.793136570296839
Validation loss: 2.5356543100198983

Epoch: 71| Step: 0
Training loss: 2.399248613515145
Validation loss: 2.5360224125330024

Epoch: 6| Step: 1
Training loss: 2.1765628417617955
Validation loss: 2.5332531322365894

Epoch: 6| Step: 2
Training loss: 3.0233479173582607
Validation loss: 2.5316848381383146

Epoch: 6| Step: 3
Training loss: 2.342750946738386
Validation loss: 2.531652583379627

Epoch: 6| Step: 4
Training loss: 2.529860880649261
Validation loss: 2.5351060138382224

Epoch: 6| Step: 5
Training loss: 2.653597505907434
Validation loss: 2.5493665494324413

Epoch: 6| Step: 6
Training loss: 3.0800007173611683
Validation loss: 2.5596953604904304

Epoch: 6| Step: 7
Training loss: 2.5562329765070095
Validation loss: 2.5719285115035984

Epoch: 6| Step: 8
Training loss: 3.2146909730747315
Validation loss: 2.5696062395058274

Epoch: 6| Step: 9
Training loss: 2.9633043637770946
Validation loss: 2.5562694601672185

Epoch: 6| Step: 10
Training loss: 2.572679166347126
Validation loss: 2.536658830701611

Epoch: 6| Step: 11
Training loss: 3.0203826217286815
Validation loss: 2.5347666076071946

Epoch: 6| Step: 12
Training loss: 2.74990731863419
Validation loss: 2.531227362888666

Epoch: 6| Step: 13
Training loss: 1.9887646760045385
Validation loss: 2.5335999243989704

Epoch: 72| Step: 0
Training loss: 2.5782818370855645
Validation loss: 2.537286851571776

Epoch: 6| Step: 1
Training loss: 3.1987969163477903
Validation loss: 2.539897652238579

Epoch: 6| Step: 2
Training loss: 2.5781346176430455
Validation loss: 2.544535601975949

Epoch: 6| Step: 3
Training loss: 2.4156609338848773
Validation loss: 2.549195696950294

Epoch: 6| Step: 4
Training loss: 2.2921740114820195
Validation loss: 2.553540826970441

Epoch: 6| Step: 5
Training loss: 2.7294078943547206
Validation loss: 2.562742857550993

Epoch: 6| Step: 6
Training loss: 3.061509575576672
Validation loss: 2.569900000342317

Epoch: 6| Step: 7
Training loss: 3.1674501721347634
Validation loss: 2.5667265329769138

Epoch: 6| Step: 8
Training loss: 2.570232448084943
Validation loss: 2.5699625443723746

Epoch: 6| Step: 9
Training loss: 2.326340676435972
Validation loss: 2.568530932983212

Epoch: 6| Step: 10
Training loss: 3.039238539747951
Validation loss: 2.574492807035115

Epoch: 6| Step: 11
Training loss: 2.338126187419819
Validation loss: 2.564655947696639

Epoch: 6| Step: 12
Training loss: 2.3876427892357053
Validation loss: 2.5515176859850754

Epoch: 6| Step: 13
Training loss: 2.7220340931906395
Validation loss: 2.5475151334094073

Epoch: 73| Step: 0
Training loss: 2.7550892122089667
Validation loss: 2.539660026470849

Epoch: 6| Step: 1
Training loss: 2.7637376110225382
Validation loss: 2.5371163289574636

Epoch: 6| Step: 2
Training loss: 2.7849413774165828
Validation loss: 2.5364526099754685

Epoch: 6| Step: 3
Training loss: 2.5765716497051763
Validation loss: 2.5317446378445996

Epoch: 6| Step: 4
Training loss: 2.1791227969634033
Validation loss: 2.5321384173811725

Epoch: 6| Step: 5
Training loss: 2.5680032577493983
Validation loss: 2.5307585627723665

Epoch: 6| Step: 6
Training loss: 2.5372102055177934
Validation loss: 2.528460940127155

Epoch: 6| Step: 7
Training loss: 2.779128733713983
Validation loss: 2.5263291709859907

Epoch: 6| Step: 8
Training loss: 2.041920730457041
Validation loss: 2.5278539285146726

Epoch: 6| Step: 9
Training loss: 2.9653104432386628
Validation loss: 2.533571081759002

Epoch: 6| Step: 10
Training loss: 3.179397157352269
Validation loss: 2.531672940810438

Epoch: 6| Step: 11
Training loss: 2.7097639462467322
Validation loss: 2.530071219546312

Epoch: 6| Step: 12
Training loss: 2.501941689815788
Validation loss: 2.5281008215880907

Epoch: 6| Step: 13
Training loss: 2.7635260769293732
Validation loss: 2.53020520095558

Epoch: 74| Step: 0
Training loss: 2.7300940435231738
Validation loss: 2.5286533867631187

Epoch: 6| Step: 1
Training loss: 2.6426766455443
Validation loss: 2.5239390848086787

Epoch: 6| Step: 2
Training loss: 2.3724469969027324
Validation loss: 2.522724346093582

Epoch: 6| Step: 3
Training loss: 2.410811027725186
Validation loss: 2.520656143350468

Epoch: 6| Step: 4
Training loss: 2.5668753510227154
Validation loss: 2.5195016154436547

Epoch: 6| Step: 5
Training loss: 2.784271998699865
Validation loss: 2.5199015342811175

Epoch: 6| Step: 6
Training loss: 2.779759039555976
Validation loss: 2.520204258025387

Epoch: 6| Step: 7
Training loss: 2.9924220697872816
Validation loss: 2.518591827398786

Epoch: 6| Step: 8
Training loss: 3.009822025550395
Validation loss: 2.519497010148683

Epoch: 6| Step: 9
Training loss: 1.93182372179104
Validation loss: 2.5184672156679038

Epoch: 6| Step: 10
Training loss: 2.465324246202924
Validation loss: 2.5207116016178612

Epoch: 6| Step: 11
Training loss: 2.2693700946575195
Validation loss: 2.516605194132598

Epoch: 6| Step: 12
Training loss: 2.8307371774026104
Validation loss: 2.51650863829197

Epoch: 6| Step: 13
Training loss: 3.0534137694690195
Validation loss: 2.5155805027029494

Epoch: 75| Step: 0
Training loss: 2.5722769329312
Validation loss: 2.5156583448139034

Epoch: 6| Step: 1
Training loss: 2.622395449464398
Validation loss: 2.5145046195473686

Epoch: 6| Step: 2
Training loss: 2.0582323716250963
Validation loss: 2.5116541781512627

Epoch: 6| Step: 3
Training loss: 2.7373318624899743
Validation loss: 2.5113665628985005

Epoch: 6| Step: 4
Training loss: 3.1404998906206445
Validation loss: 2.517939795851246

Epoch: 6| Step: 5
Training loss: 2.759664027455805
Validation loss: 2.513718397870397

Epoch: 6| Step: 6
Training loss: 2.6337071378793153
Validation loss: 2.514182109370192

Epoch: 6| Step: 7
Training loss: 2.415647214957633
Validation loss: 2.5106736100479496

Epoch: 6| Step: 8
Training loss: 2.6662184418045993
Validation loss: 2.513308672982142

Epoch: 6| Step: 9
Training loss: 2.943126079423844
Validation loss: 2.516610625782008

Epoch: 6| Step: 10
Training loss: 2.5596243377072163
Validation loss: 2.506820323991071

Epoch: 6| Step: 11
Training loss: 3.2365196599553268
Validation loss: 2.509815758824118

Epoch: 6| Step: 12
Training loss: 1.8316799062794769
Validation loss: 2.514992897119724

Epoch: 6| Step: 13
Training loss: 2.265866391706695
Validation loss: 2.5099077513512666

Epoch: 76| Step: 0
Training loss: 2.4979657479863078
Validation loss: 2.5116301066575586

Epoch: 6| Step: 1
Training loss: 2.4983943551389727
Validation loss: 2.5144320358443677

Epoch: 6| Step: 2
Training loss: 2.971321839076762
Validation loss: 2.5136427088470366

Epoch: 6| Step: 3
Training loss: 2.71260120888621
Validation loss: 2.513865406378657

Epoch: 6| Step: 4
Training loss: 2.260530096861605
Validation loss: 2.515535341169617

Epoch: 6| Step: 5
Training loss: 2.8172496109651695
Validation loss: 2.5111379787485584

Epoch: 6| Step: 6
Training loss: 2.4696435397769476
Validation loss: 2.5160861017244813

Epoch: 6| Step: 7
Training loss: 2.359152271797715
Validation loss: 2.5099774579255554

Epoch: 6| Step: 8
Training loss: 2.4145600136482996
Validation loss: 2.512164039355168

Epoch: 6| Step: 9
Training loss: 2.9721942397213565
Validation loss: 2.5127983561386857

Epoch: 6| Step: 10
Training loss: 3.0264262722632633
Validation loss: 2.508723425288055

Epoch: 6| Step: 11
Training loss: 2.656332306428183
Validation loss: 2.5104926850982787

Epoch: 6| Step: 12
Training loss: 2.585544060686686
Validation loss: 2.5045168921069223

Epoch: 6| Step: 13
Training loss: 2.573219487417664
Validation loss: 2.5028152032816062

Epoch: 77| Step: 0
Training loss: 2.71609376081449
Validation loss: 2.5110985606741685

Epoch: 6| Step: 1
Training loss: 2.3377152124565517
Validation loss: 2.530726327611243

Epoch: 6| Step: 2
Training loss: 2.7780187459907775
Validation loss: 2.546150010720196

Epoch: 6| Step: 3
Training loss: 2.9402803289968693
Validation loss: 2.5524307533508215

Epoch: 6| Step: 4
Training loss: 2.552758004415551
Validation loss: 2.546914020387636

Epoch: 6| Step: 5
Training loss: 2.983029366747981
Validation loss: 2.5308485458447723

Epoch: 6| Step: 6
Training loss: 2.6424342170546424
Validation loss: 2.512045372845761

Epoch: 6| Step: 7
Training loss: 2.5519819486033426
Validation loss: 2.5088893206599474

Epoch: 6| Step: 8
Training loss: 2.406621929010017
Validation loss: 2.504636407126001

Epoch: 6| Step: 9
Training loss: 2.515591070289916
Validation loss: 2.507109197789905

Epoch: 6| Step: 10
Training loss: 2.4238897987406953
Validation loss: 2.50701270417062

Epoch: 6| Step: 11
Training loss: 2.722628578253389
Validation loss: 2.5037363344842603

Epoch: 6| Step: 12
Training loss: 2.2465267924942562
Validation loss: 2.5002924271264013

Epoch: 6| Step: 13
Training loss: 2.9881625282789015
Validation loss: 2.5029226068085726

Epoch: 78| Step: 0
Training loss: 2.7723482813827944
Validation loss: 2.503952684532307

Epoch: 6| Step: 1
Training loss: 2.917834747383256
Validation loss: 2.5082340222930917

Epoch: 6| Step: 2
Training loss: 2.784173607526902
Validation loss: 2.5104725357951176

Epoch: 6| Step: 3
Training loss: 2.4559518841866965
Validation loss: 2.5066178626608813

Epoch: 6| Step: 4
Training loss: 2.9549695264145406
Validation loss: 2.5111200974827814

Epoch: 6| Step: 5
Training loss: 2.2744708776850717
Validation loss: 2.513106939919258

Epoch: 6| Step: 6
Training loss: 2.1374412305460204
Validation loss: 2.505311417920624

Epoch: 6| Step: 7
Training loss: 2.9172890317030005
Validation loss: 2.5046467353167206

Epoch: 6| Step: 8
Training loss: 2.610830483563383
Validation loss: 2.507771841256349

Epoch: 6| Step: 9
Training loss: 2.0849051331817656
Validation loss: 2.5045328055601903

Epoch: 6| Step: 10
Training loss: 2.8060270632949798
Validation loss: 2.5056494617227556

Epoch: 6| Step: 11
Training loss: 2.678159405944669
Validation loss: 2.5054557794406276

Epoch: 6| Step: 12
Training loss: 2.640315923716795
Validation loss: 2.505252089617278

Epoch: 6| Step: 13
Training loss: 2.4929245961916626
Validation loss: 2.502557114321892

Epoch: 79| Step: 0
Training loss: 2.3742111301331223
Validation loss: 2.501998642867971

Epoch: 6| Step: 1
Training loss: 2.4150131970789372
Validation loss: 2.501452477041276

Epoch: 6| Step: 2
Training loss: 2.855613026450877
Validation loss: 2.502474704427853

Epoch: 6| Step: 3
Training loss: 2.82632228659332
Validation loss: 2.503567962885079

Epoch: 6| Step: 4
Training loss: 2.2751328481934214
Validation loss: 2.4976155512913123

Epoch: 6| Step: 5
Training loss: 2.448392348369177
Validation loss: 2.5020752717416843

Epoch: 6| Step: 6
Training loss: 2.2004950226543487
Validation loss: 2.500676572166655

Epoch: 6| Step: 7
Training loss: 2.4452627743671163
Validation loss: 2.4939322268799744

Epoch: 6| Step: 8
Training loss: 2.888261643400706
Validation loss: 2.5003262148058507

Epoch: 6| Step: 9
Training loss: 2.419284838309812
Validation loss: 2.49511096055261

Epoch: 6| Step: 10
Training loss: 2.766939443523251
Validation loss: 2.503948423573001

Epoch: 6| Step: 11
Training loss: 3.211551950884111
Validation loss: 2.5036629465871445

Epoch: 6| Step: 12
Training loss: 2.7207819919697993
Validation loss: 2.511184406148572

Epoch: 6| Step: 13
Training loss: 2.6212141802390976
Validation loss: 2.507157126222941

Epoch: 80| Step: 0
Training loss: 2.4603669973641638
Validation loss: 2.507092951998698

Epoch: 6| Step: 1
Training loss: 2.981104471745323
Validation loss: 2.5036180700343693

Epoch: 6| Step: 2
Training loss: 2.4121650226058247
Validation loss: 2.510721058943941

Epoch: 6| Step: 3
Training loss: 2.7681326838869245
Validation loss: 2.511642257134744

Epoch: 6| Step: 4
Training loss: 2.192796126999439
Validation loss: 2.5114074324253393

Epoch: 6| Step: 5
Training loss: 2.4459758017365307
Validation loss: 2.5086678445590085

Epoch: 6| Step: 6
Training loss: 2.7991455068542757
Validation loss: 2.5080963877251476

Epoch: 6| Step: 7
Training loss: 2.004089941934076
Validation loss: 2.498424987570783

Epoch: 6| Step: 8
Training loss: 3.2205606941482072
Validation loss: 2.498065295237256

Epoch: 6| Step: 9
Training loss: 2.9929391101234817
Validation loss: 2.4927876705472802

Epoch: 6| Step: 10
Training loss: 2.1518979588817526
Validation loss: 2.496411752517461

Epoch: 6| Step: 11
Training loss: 2.6667176380849162
Validation loss: 2.496037888038636

Epoch: 6| Step: 12
Training loss: 2.694353281250811
Validation loss: 2.4954713016460577

Epoch: 6| Step: 13
Training loss: 2.5889930766437796
Validation loss: 2.4981438580920154

Epoch: 81| Step: 0
Training loss: 2.3477812621080805
Validation loss: 2.4971730938742818

Epoch: 6| Step: 1
Training loss: 2.8670803954365294
Validation loss: 2.502732357323817

Epoch: 6| Step: 2
Training loss: 2.503980329015814
Validation loss: 2.501575704552045

Epoch: 6| Step: 3
Training loss: 2.669330299769509
Validation loss: 2.498079690923976

Epoch: 6| Step: 4
Training loss: 2.510653113999999
Validation loss: 2.4983085234820197

Epoch: 6| Step: 5
Training loss: 2.7983334963421513
Validation loss: 2.495351188421852

Epoch: 6| Step: 6
Training loss: 2.059000688031208
Validation loss: 2.4940497636487766

Epoch: 6| Step: 7
Training loss: 3.2359604934619615
Validation loss: 2.4957488313697858

Epoch: 6| Step: 8
Training loss: 2.303583430262126
Validation loss: 2.4966019425026214

Epoch: 6| Step: 9
Training loss: 2.836744125450226
Validation loss: 2.4966026268993686

Epoch: 6| Step: 10
Training loss: 2.487064561160038
Validation loss: 2.500802181608754

Epoch: 6| Step: 11
Training loss: 2.404138108937272
Validation loss: 2.496933661938699

Epoch: 6| Step: 12
Training loss: 2.058526112207147
Validation loss: 2.4893153430770165

Epoch: 6| Step: 13
Training loss: 3.1421732715832755
Validation loss: 2.4974009355022884

Epoch: 82| Step: 0
Training loss: 2.6412574868337564
Validation loss: 2.500975402649046

Epoch: 6| Step: 1
Training loss: 2.9622002880578187
Validation loss: 2.4989584024505374

Epoch: 6| Step: 2
Training loss: 2.3305491685179875
Validation loss: 2.509601719274997

Epoch: 6| Step: 3
Training loss: 2.650904403960193
Validation loss: 2.512014289582463

Epoch: 6| Step: 4
Training loss: 2.7561649231528516
Validation loss: 2.5033569368180055

Epoch: 6| Step: 5
Training loss: 2.458344658863251
Validation loss: 2.497766689308543

Epoch: 6| Step: 6
Training loss: 2.8396257949158312
Validation loss: 2.4948496854933726

Epoch: 6| Step: 7
Training loss: 2.626835317699973
Validation loss: 2.49056534705685

Epoch: 6| Step: 8
Training loss: 2.3973040061291213
Validation loss: 2.4924267501551407

Epoch: 6| Step: 9
Training loss: 2.2386219770588007
Validation loss: 2.4913252850743564

Epoch: 6| Step: 10
Training loss: 2.407473958826296
Validation loss: 2.4919327273832965

Epoch: 6| Step: 11
Training loss: 2.903595563285182
Validation loss: 2.4918644136615855

Epoch: 6| Step: 12
Training loss: 2.331139782302071
Validation loss: 2.4927987013899555

Epoch: 6| Step: 13
Training loss: 2.8757180685508863
Validation loss: 2.4944250093546416

Epoch: 83| Step: 0
Training loss: 3.093470088741995
Validation loss: 2.4930135380407568

Epoch: 6| Step: 1
Training loss: 2.254610847338629
Validation loss: 2.496038827306798

Epoch: 6| Step: 2
Training loss: 2.5994255751844197
Validation loss: 2.4971305592250626

Epoch: 6| Step: 3
Training loss: 3.0962438839115483
Validation loss: 2.4967712056115148

Epoch: 6| Step: 4
Training loss: 2.009410533917133
Validation loss: 2.4985063541380668

Epoch: 6| Step: 5
Training loss: 2.675318768483578
Validation loss: 2.5032296300539487

Epoch: 6| Step: 6
Training loss: 2.7801479770878412
Validation loss: 2.499982054963875

Epoch: 6| Step: 7
Training loss: 2.2014435107183172
Validation loss: 2.4978284464431737

Epoch: 6| Step: 8
Training loss: 2.52653554171852
Validation loss: 2.4973723908014605

Epoch: 6| Step: 9
Training loss: 2.94567253684722
Validation loss: 2.491866247504441

Epoch: 6| Step: 10
Training loss: 2.623849525835755
Validation loss: 2.4924728246168404

Epoch: 6| Step: 11
Training loss: 2.9238131209952365
Validation loss: 2.49484411090262

Epoch: 6| Step: 12
Training loss: 2.4319818096484473
Validation loss: 2.4873219731457503

Epoch: 6| Step: 13
Training loss: 2.1410656774746566
Validation loss: 2.491505735892549

Epoch: 84| Step: 0
Training loss: 1.8312182218639115
Validation loss: 2.4893822103260743

Epoch: 6| Step: 1
Training loss: 3.240230401642003
Validation loss: 2.4902114926951144

Epoch: 6| Step: 2
Training loss: 3.017169300026429
Validation loss: 2.4903436773908516

Epoch: 6| Step: 3
Training loss: 2.7481997406065704
Validation loss: 2.4915925753835726

Epoch: 6| Step: 4
Training loss: 2.272729297983828
Validation loss: 2.4913725123289763

Epoch: 6| Step: 5
Training loss: 2.518091449831228
Validation loss: 2.4891604831883964

Epoch: 6| Step: 6
Training loss: 1.8268387663070529
Validation loss: 2.491512817132431

Epoch: 6| Step: 7
Training loss: 1.9381637666793035
Validation loss: 2.4915881417785615

Epoch: 6| Step: 8
Training loss: 2.897634883502547
Validation loss: 2.4927667564456586

Epoch: 6| Step: 9
Training loss: 2.7848566223165516
Validation loss: 2.4913913009033974

Epoch: 6| Step: 10
Training loss: 3.279547840214392
Validation loss: 2.4948805047917424

Epoch: 6| Step: 11
Training loss: 2.4591933109395994
Validation loss: 2.4899613533697718

Epoch: 6| Step: 12
Training loss: 2.328051981965008
Validation loss: 2.4852812611567905

Epoch: 6| Step: 13
Training loss: 2.702462263946607
Validation loss: 2.4894904487765284

Epoch: 85| Step: 0
Training loss: 2.5705123870022835
Validation loss: 2.490131546590206

Epoch: 6| Step: 1
Training loss: 1.776242629807045
Validation loss: 2.485810047321505

Epoch: 6| Step: 2
Training loss: 2.6434865040154114
Validation loss: 2.487637518910529

Epoch: 6| Step: 3
Training loss: 2.7214918670616877
Validation loss: 2.491331234386044

Epoch: 6| Step: 4
Training loss: 2.652710834432989
Validation loss: 2.485418200645602

Epoch: 6| Step: 5
Training loss: 3.0257230099550076
Validation loss: 2.4853381163427612

Epoch: 6| Step: 6
Training loss: 2.5045702168496637
Validation loss: 2.4875541834465187

Epoch: 6| Step: 7
Training loss: 2.2557325451359582
Validation loss: 2.488469714059576

Epoch: 6| Step: 8
Training loss: 2.6968179672416714
Validation loss: 2.491893898501817

Epoch: 6| Step: 9
Training loss: 3.0971248214148277
Validation loss: 2.5023563168333505

Epoch: 6| Step: 10
Training loss: 2.080948367327481
Validation loss: 2.492725979819181

Epoch: 6| Step: 11
Training loss: 3.0380889196083887
Validation loss: 2.4856483507102674

Epoch: 6| Step: 12
Training loss: 2.289981384201678
Validation loss: 2.4917812514564073

Epoch: 6| Step: 13
Training loss: 2.7076036692996417
Validation loss: 2.4903765469526036

Epoch: 86| Step: 0
Training loss: 2.769201692200292
Validation loss: 2.4829989127040104

Epoch: 6| Step: 1
Training loss: 2.4502289801269006
Validation loss: 2.4904933261247097

Epoch: 6| Step: 2
Training loss: 2.08067326158291
Validation loss: 2.4899842698903853

Epoch: 6| Step: 3
Training loss: 2.447038815058385
Validation loss: 2.495424343047854

Epoch: 6| Step: 4
Training loss: 2.9782751567888917
Validation loss: 2.4902094023206582

Epoch: 6| Step: 5
Training loss: 2.2289619232937032
Validation loss: 2.4870655517487825

Epoch: 6| Step: 6
Training loss: 2.7518763643149193
Validation loss: 2.491167655039466

Epoch: 6| Step: 7
Training loss: 2.4286184626921337
Validation loss: 2.4847644844486343

Epoch: 6| Step: 8
Training loss: 2.807864034664839
Validation loss: 2.488632568598232

Epoch: 6| Step: 9
Training loss: 2.778577570745577
Validation loss: 2.488858062784092

Epoch: 6| Step: 10
Training loss: 2.9359392930492794
Validation loss: 2.4877489799226775

Epoch: 6| Step: 11
Training loss: 2.736793015692306
Validation loss: 2.4887161872849393

Epoch: 6| Step: 12
Training loss: 2.112233464508042
Validation loss: 2.486757235918837

Epoch: 6| Step: 13
Training loss: 2.6256723905162533
Validation loss: 2.489262282181812

Epoch: 87| Step: 0
Training loss: 2.79985279990598
Validation loss: 2.4837712607956037

Epoch: 6| Step: 1
Training loss: 1.8910432463269473
Validation loss: 2.484058807852759

Epoch: 6| Step: 2
Training loss: 2.861282796142659
Validation loss: 2.482235433048522

Epoch: 6| Step: 3
Training loss: 2.7482283694286083
Validation loss: 2.485584052802672

Epoch: 6| Step: 4
Training loss: 2.3271666736984806
Validation loss: 2.4844518045833133

Epoch: 6| Step: 5
Training loss: 2.8905586853668623
Validation loss: 2.4827400601868295

Epoch: 6| Step: 6
Training loss: 2.6942866487823607
Validation loss: 2.4832510815083637

Epoch: 6| Step: 7
Training loss: 2.2952748648075003
Validation loss: 2.4773898903648037

Epoch: 6| Step: 8
Training loss: 2.933014712224271
Validation loss: 2.48196820771489

Epoch: 6| Step: 9
Training loss: 3.0386706886627555
Validation loss: 2.485485332613795

Epoch: 6| Step: 10
Training loss: 2.3679295752144
Validation loss: 2.480639386252684

Epoch: 6| Step: 11
Training loss: 1.954372160409024
Validation loss: 2.4791830099726506

Epoch: 6| Step: 12
Training loss: 2.434145649008781
Validation loss: 2.485043545705371

Epoch: 6| Step: 13
Training loss: 2.68112250960853
Validation loss: 2.4873140652173618

Epoch: 88| Step: 0
Training loss: 2.148280578431167
Validation loss: 2.4914127688294205

Epoch: 6| Step: 1
Training loss: 2.5525485075433565
Validation loss: 2.4867403937686317

Epoch: 6| Step: 2
Training loss: 2.789170890860374
Validation loss: 2.4890234302967422

Epoch: 6| Step: 3
Training loss: 2.650579615849574
Validation loss: 2.4838475241198634

Epoch: 6| Step: 4
Training loss: 2.442631528469759
Validation loss: 2.4920036702534696

Epoch: 6| Step: 5
Training loss: 2.585763147475052
Validation loss: 2.4819242757546904

Epoch: 6| Step: 6
Training loss: 2.8401209552958213
Validation loss: 2.4869634870797173

Epoch: 6| Step: 7
Training loss: 2.4100270538077884
Validation loss: 2.4836854437578744

Epoch: 6| Step: 8
Training loss: 2.468478900172518
Validation loss: 2.487598862592371

Epoch: 6| Step: 9
Training loss: 2.636760615263701
Validation loss: 2.488606182702916

Epoch: 6| Step: 10
Training loss: 3.282678347737498
Validation loss: 2.4848230785581555

Epoch: 6| Step: 11
Training loss: 2.331785051650261
Validation loss: 2.4834285988765563

Epoch: 6| Step: 12
Training loss: 2.4665225639865502
Validation loss: 2.4898623917943783

Epoch: 6| Step: 13
Training loss: 2.6355224608244208
Validation loss: 2.487049526530824

Epoch: 89| Step: 0
Training loss: 3.116959871858064
Validation loss: 2.485871014524173

Epoch: 6| Step: 1
Training loss: 2.4275784185375793
Validation loss: 2.484883158474282

Epoch: 6| Step: 2
Training loss: 2.7971870631870837
Validation loss: 2.480716642873673

Epoch: 6| Step: 3
Training loss: 2.5087062871039394
Validation loss: 2.484659686461643

Epoch: 6| Step: 4
Training loss: 2.835501477059007
Validation loss: 2.4812879276019313

Epoch: 6| Step: 5
Training loss: 2.2205673082299575
Validation loss: 2.4822917496946264

Epoch: 6| Step: 6
Training loss: 2.319682334329886
Validation loss: 2.479063870732438

Epoch: 6| Step: 7
Training loss: 2.5806382384899558
Validation loss: 2.481416760405107

Epoch: 6| Step: 8
Training loss: 2.410834762549963
Validation loss: 2.4828170753918584

Epoch: 6| Step: 9
Training loss: 3.332917537187559
Validation loss: 2.482086999427385

Epoch: 6| Step: 10
Training loss: 2.0308022812619186
Validation loss: 2.481032227921497

Epoch: 6| Step: 11
Training loss: 2.426722345534337
Validation loss: 2.4722060466146694

Epoch: 6| Step: 12
Training loss: 2.884440306216607
Validation loss: 2.4726042779700497

Epoch: 6| Step: 13
Training loss: 2.0812240094919017
Validation loss: 2.475876593847939

Epoch: 90| Step: 0
Training loss: 1.8925769912196682
Validation loss: 2.4825193404526043

Epoch: 6| Step: 1
Training loss: 3.0826789745835286
Validation loss: 2.4843677064800564

Epoch: 6| Step: 2
Training loss: 2.2133926401273945
Validation loss: 2.4801111959837137

Epoch: 6| Step: 3
Training loss: 2.765594396044698
Validation loss: 2.4759890657603583

Epoch: 6| Step: 4
Training loss: 2.3692876482422993
Validation loss: 2.4763448962572685

Epoch: 6| Step: 5
Training loss: 2.4483427826673307
Validation loss: 2.480710315706138

Epoch: 6| Step: 6
Training loss: 2.114251723071485
Validation loss: 2.4873801875054036

Epoch: 6| Step: 7
Training loss: 2.5548636932742492
Validation loss: 2.4812076219067434

Epoch: 6| Step: 8
Training loss: 3.1942190523842062
Validation loss: 2.477129657676881

Epoch: 6| Step: 9
Training loss: 2.5222126258503224
Validation loss: 2.482716428587678

Epoch: 6| Step: 10
Training loss: 2.723989939946939
Validation loss: 2.4735823067781193

Epoch: 6| Step: 11
Training loss: 2.5357952987654997
Validation loss: 2.4817817316820046

Epoch: 6| Step: 12
Training loss: 2.6342135813211125
Validation loss: 2.4821336740491833

Epoch: 6| Step: 13
Training loss: 2.82690032239187
Validation loss: 2.4777687256005736

Epoch: 91| Step: 0
Training loss: 2.2605055221696047
Validation loss: 2.481725883810679

Epoch: 6| Step: 1
Training loss: 3.1300435374586595
Validation loss: 2.483368323760188

Epoch: 6| Step: 2
Training loss: 2.4647270936761476
Validation loss: 2.4821330577033534

Epoch: 6| Step: 3
Training loss: 2.7520338686921555
Validation loss: 2.4834526637121486

Epoch: 6| Step: 4
Training loss: 2.557421699734844
Validation loss: 2.4848417407477887

Epoch: 6| Step: 5
Training loss: 2.8079882567287844
Validation loss: 2.482198293458256

Epoch: 6| Step: 6
Training loss: 2.41218439518333
Validation loss: 2.4856078969373265

Epoch: 6| Step: 7
Training loss: 2.579600333965633
Validation loss: 2.4864755063901542

Epoch: 6| Step: 8
Training loss: 2.1857013392131783
Validation loss: 2.482965993487807

Epoch: 6| Step: 9
Training loss: 2.1047059554641034
Validation loss: 2.4818137699881495

Epoch: 6| Step: 10
Training loss: 2.6686110163284806
Validation loss: 2.484348624867161

Epoch: 6| Step: 11
Training loss: 2.324920394519096
Validation loss: 2.485645633030284

Epoch: 6| Step: 12
Training loss: 2.8386547007788576
Validation loss: 2.4810447364544905

Epoch: 6| Step: 13
Training loss: 2.9324292183973757
Validation loss: 2.480000000564001

Epoch: 92| Step: 0
Training loss: 2.9732599635401904
Validation loss: 2.476968485290229

Epoch: 6| Step: 1
Training loss: 2.592043211670946
Validation loss: 2.4761443000634547

Epoch: 6| Step: 2
Training loss: 2.4781669930631818
Validation loss: 2.4768761437222766

Epoch: 6| Step: 3
Training loss: 2.5518028468447636
Validation loss: 2.474109529927831

Epoch: 6| Step: 4
Training loss: 2.099071061078688
Validation loss: 2.479129251363393

Epoch: 6| Step: 5
Training loss: 2.3710308035173284
Validation loss: 2.4773158102024877

Epoch: 6| Step: 6
Training loss: 2.5916529991386454
Validation loss: 2.4823300164307573

Epoch: 6| Step: 7
Training loss: 2.4229560654231235
Validation loss: 2.4786384457898065

Epoch: 6| Step: 8
Training loss: 2.5707729124350074
Validation loss: 2.477460094852921

Epoch: 6| Step: 9
Training loss: 2.467053566909716
Validation loss: 2.4822586570163865

Epoch: 6| Step: 10
Training loss: 3.0328000225142606
Validation loss: 2.477106181093619

Epoch: 6| Step: 11
Training loss: 2.6882226549019115
Validation loss: 2.478480626132957

Epoch: 6| Step: 12
Training loss: 2.4774547618196365
Validation loss: 2.475651730999267

Epoch: 6| Step: 13
Training loss: 2.5984329783296496
Validation loss: 2.476748598890472

Epoch: 93| Step: 0
Training loss: 2.0388417325411905
Validation loss: 2.478075097035776

Epoch: 6| Step: 1
Training loss: 2.069469121775893
Validation loss: 2.476071297983553

Epoch: 6| Step: 2
Training loss: 2.46666900230847
Validation loss: 2.479371813025292

Epoch: 6| Step: 3
Training loss: 3.1153246827623473
Validation loss: 2.480272148130587

Epoch: 6| Step: 4
Training loss: 2.808957220971955
Validation loss: 2.4771877907389133

Epoch: 6| Step: 5
Training loss: 2.7123005103661937
Validation loss: 2.4814286264586403

Epoch: 6| Step: 6
Training loss: 2.2937077074023775
Validation loss: 2.4761508154225527

Epoch: 6| Step: 7
Training loss: 2.5992791863934817
Validation loss: 2.4809196803201816

Epoch: 6| Step: 8
Training loss: 2.09760135173885
Validation loss: 2.4768316882756296

Epoch: 6| Step: 9
Training loss: 2.643427067506188
Validation loss: 2.476815837493963

Epoch: 6| Step: 10
Training loss: 2.4177593085029243
Validation loss: 2.4786477280430703

Epoch: 6| Step: 11
Training loss: 2.415948519935092
Validation loss: 2.4822994975357235

Epoch: 6| Step: 12
Training loss: 3.0131091756351736
Validation loss: 2.4808940212509585

Epoch: 6| Step: 13
Training loss: 3.0064779912897044
Validation loss: 2.481904951209612

Epoch: 94| Step: 0
Training loss: 2.8624567819855993
Validation loss: 2.479291228897031

Epoch: 6| Step: 1
Training loss: 2.8018120181722685
Validation loss: 2.4777041269863957

Epoch: 6| Step: 2
Training loss: 2.38609543073439
Validation loss: 2.4739807984520032

Epoch: 6| Step: 3
Training loss: 2.7824726631898695
Validation loss: 2.479260552389015

Epoch: 6| Step: 4
Training loss: 2.4722964731655477
Validation loss: 2.479420630218877

Epoch: 6| Step: 5
Training loss: 2.6444765251503997
Validation loss: 2.4724890163731805

Epoch: 6| Step: 6
Training loss: 2.0772886959727135
Validation loss: 2.4677279726929386

Epoch: 6| Step: 7
Training loss: 2.5645812351973314
Validation loss: 2.472205709076022

Epoch: 6| Step: 8
Training loss: 2.302051653291604
Validation loss: 2.467772600188652

Epoch: 6| Step: 9
Training loss: 3.0015143704862304
Validation loss: 2.4633385948913022

Epoch: 6| Step: 10
Training loss: 2.8220779937358698
Validation loss: 2.4729853808254605

Epoch: 6| Step: 11
Training loss: 1.9890908502204991
Validation loss: 2.4775038734095243

Epoch: 6| Step: 12
Training loss: 3.072823388359605
Validation loss: 2.48120945561848

Epoch: 6| Step: 13
Training loss: 2.057505484628146
Validation loss: 2.4790277255150404

Epoch: 95| Step: 0
Training loss: 2.4356821568658957
Validation loss: 2.481062994635282

Epoch: 6| Step: 1
Training loss: 2.344582575103093
Validation loss: 2.475670558629337

Epoch: 6| Step: 2
Training loss: 2.058062084822251
Validation loss: 2.481521102866785

Epoch: 6| Step: 3
Training loss: 2.5390724534059714
Validation loss: 2.4766092707151603

Epoch: 6| Step: 4
Training loss: 2.758274115381039
Validation loss: 2.4783563705516074

Epoch: 6| Step: 5
Training loss: 2.4817801305564036
Validation loss: 2.46898455250016

Epoch: 6| Step: 6
Training loss: 2.4723368795526417
Validation loss: 2.469276388200038

Epoch: 6| Step: 7
Training loss: 2.55987749581481
Validation loss: 2.4812198973398303

Epoch: 6| Step: 8
Training loss: 2.2590888088782446
Validation loss: 2.4740859684729086

Epoch: 6| Step: 9
Training loss: 2.747817734177879
Validation loss: 2.4807623581818583

Epoch: 6| Step: 10
Training loss: 3.3491913915593003
Validation loss: 2.472246213384606

Epoch: 6| Step: 11
Training loss: 2.923683952900059
Validation loss: 2.470740244389311

Epoch: 6| Step: 12
Training loss: 2.970765724500699
Validation loss: 2.4706086513867156

Epoch: 6| Step: 13
Training loss: 2.2012325302201967
Validation loss: 2.47802347918931

Epoch: 96| Step: 0
Training loss: 3.1468613988891154
Validation loss: 2.4785421263327816

Epoch: 6| Step: 1
Training loss: 3.0186853247875787
Validation loss: 2.480078863305135

Epoch: 6| Step: 2
Training loss: 2.422955868623361
Validation loss: 2.482092666706619

Epoch: 6| Step: 3
Training loss: 2.393528091861882
Validation loss: 2.480591345933838

Epoch: 6| Step: 4
Training loss: 2.438405382296111
Validation loss: 2.4835744883640447

Epoch: 6| Step: 5
Training loss: 2.5143010227245135
Validation loss: 2.4817300148029195

Epoch: 6| Step: 6
Training loss: 2.6135441714827596
Validation loss: 2.479754920432325

Epoch: 6| Step: 7
Training loss: 2.4721615554090475
Validation loss: 2.4790601360182025

Epoch: 6| Step: 8
Training loss: 2.0952200212772487
Validation loss: 2.4798580829714987

Epoch: 6| Step: 9
Training loss: 2.4573388324095777
Validation loss: 2.480866760201269

Epoch: 6| Step: 10
Training loss: 3.0136158629556635
Validation loss: 2.4755906565845063

Epoch: 6| Step: 11
Training loss: 2.366757596198867
Validation loss: 2.478626005271505

Epoch: 6| Step: 12
Training loss: 2.3816392355162934
Validation loss: 2.4763106931116234

Epoch: 6| Step: 13
Training loss: 2.74607447567249
Validation loss: 2.474341839963767

Epoch: 97| Step: 0
Training loss: 3.1905467114385107
Validation loss: 2.4728268629274277

Epoch: 6| Step: 1
Training loss: 2.892611424204853
Validation loss: 2.474260879220563

Epoch: 6| Step: 2
Training loss: 2.6532464492732397
Validation loss: 2.4749907952596666

Epoch: 6| Step: 3
Training loss: 2.3645443906112016
Validation loss: 2.476587899094873

Epoch: 6| Step: 4
Training loss: 2.5136900858897446
Validation loss: 2.4778674164577263

Epoch: 6| Step: 5
Training loss: 2.894077198488414
Validation loss: 2.4765813608183413

Epoch: 6| Step: 6
Training loss: 2.2966565917098145
Validation loss: 2.473125796860599

Epoch: 6| Step: 7
Training loss: 1.7270830155185581
Validation loss: 2.4736292864501657

Epoch: 6| Step: 8
Training loss: 2.387506982283843
Validation loss: 2.4755595489841093

Epoch: 6| Step: 9
Training loss: 2.4475385874432964
Validation loss: 2.4728603670502665

Epoch: 6| Step: 10
Training loss: 2.439925722961528
Validation loss: 2.475726294316358

Epoch: 6| Step: 11
Training loss: 2.505991622277555
Validation loss: 2.467752432170838

Epoch: 6| Step: 12
Training loss: 2.47888152034722
Validation loss: 2.4663095926753407

Epoch: 6| Step: 13
Training loss: 2.9311174895505006
Validation loss: 2.4680940263571935

Epoch: 98| Step: 0
Training loss: 2.8636452728397117
Validation loss: 2.471247878098658

Epoch: 6| Step: 1
Training loss: 2.4021333431740777
Validation loss: 2.4707795665309606

Epoch: 6| Step: 2
Training loss: 2.4158629582739994
Validation loss: 2.476359554603644

Epoch: 6| Step: 3
Training loss: 2.6707878354899193
Validation loss: 2.4783663753606304

Epoch: 6| Step: 4
Training loss: 2.4730403656031057
Validation loss: 2.476160764952629

Epoch: 6| Step: 5
Training loss: 2.852886906160288
Validation loss: 2.4771425227822204

Epoch: 6| Step: 6
Training loss: 2.165270967155394
Validation loss: 2.4825857345000735

Epoch: 6| Step: 7
Training loss: 2.321596965341405
Validation loss: 2.486804166432016

Epoch: 6| Step: 8
Training loss: 2.8121171478787215
Validation loss: 2.48313794636834

Epoch: 6| Step: 9
Training loss: 2.567812738881652
Validation loss: 2.4793267291887906

Epoch: 6| Step: 10
Training loss: 2.018770233147384
Validation loss: 2.48389057418837

Epoch: 6| Step: 11
Training loss: 2.5740536997187227
Validation loss: 2.4823117515614763

Epoch: 6| Step: 12
Training loss: 2.8177035197124627
Validation loss: 2.4801670962359093

Epoch: 6| Step: 13
Training loss: 2.9769150732892364
Validation loss: 2.4804143303936463

Epoch: 99| Step: 0
Training loss: 2.184302909218122
Validation loss: 2.4732600273937515

Epoch: 6| Step: 1
Training loss: 2.8507769613110896
Validation loss: 2.4724708234494575

Epoch: 6| Step: 2
Training loss: 2.6634042771319613
Validation loss: 2.4633683405114923

Epoch: 6| Step: 3
Training loss: 2.3312291694099097
Validation loss: 2.463534935155036

Epoch: 6| Step: 4
Training loss: 2.734490877148478
Validation loss: 2.457853712288909

Epoch: 6| Step: 5
Training loss: 2.096907554862669
Validation loss: 2.4709122922309548

Epoch: 6| Step: 6
Training loss: 2.7059757437284935
Validation loss: 2.4688010230606374

Epoch: 6| Step: 7
Training loss: 2.7886940421556456
Validation loss: 2.468943141673458

Epoch: 6| Step: 8
Training loss: 2.860222362597177
Validation loss: 2.4651311594983465

Epoch: 6| Step: 9
Training loss: 2.8894258228397836
Validation loss: 2.4683256790622856

Epoch: 6| Step: 10
Training loss: 2.83296724834153
Validation loss: 2.4770457601518285

Epoch: 6| Step: 11
Training loss: 2.3859189655455917
Validation loss: 2.478679069418586

Epoch: 6| Step: 12
Training loss: 2.169379797523269
Validation loss: 2.4770054706841105

Epoch: 6| Step: 13
Training loss: 2.4281591778759126
Validation loss: 2.478601733255787

Epoch: 100| Step: 0
Training loss: 2.7641082742630334
Validation loss: 2.480414410494032

Epoch: 6| Step: 1
Training loss: 2.565959734808155
Validation loss: 2.478722257345066

Epoch: 6| Step: 2
Training loss: 2.818127237278026
Validation loss: 2.479348413767045

Epoch: 6| Step: 3
Training loss: 3.3005953222875335
Validation loss: 2.4771217492934317

Epoch: 6| Step: 4
Training loss: 2.4197941854931555
Validation loss: 2.472023817261417

Epoch: 6| Step: 5
Training loss: 2.246980230124763
Validation loss: 2.467981468361928

Epoch: 6| Step: 6
Training loss: 2.4423601652038767
Validation loss: 2.464707634296533

Epoch: 6| Step: 7
Training loss: 2.5310043404133875
Validation loss: 2.4664347290418407

Epoch: 6| Step: 8
Training loss: 2.1202078245970184
Validation loss: 2.475816905265582

Epoch: 6| Step: 9
Training loss: 2.718786743617323
Validation loss: 2.4651313206923198

Epoch: 6| Step: 10
Training loss: 2.5180131463881
Validation loss: 2.471421144714768

Epoch: 6| Step: 11
Training loss: 1.9425087452106171
Validation loss: 2.476047995921257

Epoch: 6| Step: 12
Training loss: 2.770876623594705
Validation loss: 2.471888723869823

Epoch: 6| Step: 13
Training loss: 2.5119129538913656
Validation loss: 2.479227206882757

Epoch: 101| Step: 0
Training loss: 2.318849044288514
Validation loss: 2.4656010918693014

Epoch: 6| Step: 1
Training loss: 2.2592750748820194
Validation loss: 2.465108656716276

Epoch: 6| Step: 2
Training loss: 2.8430210059453627
Validation loss: 2.4667564261919046

Epoch: 6| Step: 3
Training loss: 2.8523603603409127
Validation loss: 2.4623520433930253

Epoch: 6| Step: 4
Training loss: 2.391659780707288
Validation loss: 2.468153354317365

Epoch: 6| Step: 5
Training loss: 1.901361168615281
Validation loss: 2.475521619012634

Epoch: 6| Step: 6
Training loss: 2.7218631152869124
Validation loss: 2.4642591553988473

Epoch: 6| Step: 7
Training loss: 2.307549513164731
Validation loss: 2.461924053425574

Epoch: 6| Step: 8
Training loss: 2.7165822123250387
Validation loss: 2.4676080629957107

Epoch: 6| Step: 9
Training loss: 2.7585843224635793
Validation loss: 2.4634949812118254

Epoch: 6| Step: 10
Training loss: 2.4248408707781612
Validation loss: 2.4693891768200222

Epoch: 6| Step: 11
Training loss: 2.66807044353454
Validation loss: 2.4799851474265933

Epoch: 6| Step: 12
Training loss: 2.4384996369553047
Validation loss: 2.4785996491218243

Epoch: 6| Step: 13
Training loss: 2.8589914200111313
Validation loss: 2.48131813064679

Epoch: 102| Step: 0
Training loss: 2.4730421009297823
Validation loss: 2.483516616799491

Epoch: 6| Step: 1
Training loss: 2.1978918378491215
Validation loss: 2.477475003226417

Epoch: 6| Step: 2
Training loss: 2.6337227988049206
Validation loss: 2.476974084068908

Epoch: 6| Step: 3
Training loss: 2.625170384281521
Validation loss: 2.480126096432052

Epoch: 6| Step: 4
Training loss: 2.490251033951631
Validation loss: 2.4776182361262378

Epoch: 6| Step: 5
Training loss: 2.9529060403697156
Validation loss: 2.4800085246544628

Epoch: 6| Step: 6
Training loss: 2.6642158889240584
Validation loss: 2.476682176716818

Epoch: 6| Step: 7
Training loss: 2.1263010866373455
Validation loss: 2.479252338264842

Epoch: 6| Step: 8
Training loss: 1.9851656562615354
Validation loss: 2.4771133115177326

Epoch: 6| Step: 9
Training loss: 2.657348764589443
Validation loss: 2.4742040465287114

Epoch: 6| Step: 10
Training loss: 2.9116408689506423
Validation loss: 2.4783998045978506

Epoch: 6| Step: 11
Training loss: 2.6745570591495116
Validation loss: 2.4802701294842855

Epoch: 6| Step: 12
Training loss: 2.817549940206537
Validation loss: 2.4774042538164003

Epoch: 6| Step: 13
Training loss: 2.5071628953243956
Validation loss: 2.479900385101927

Epoch: 103| Step: 0
Training loss: 2.6083404865918367
Validation loss: 2.4774306547620384

Epoch: 6| Step: 1
Training loss: 2.7452000429398287
Validation loss: 2.470014916064775

Epoch: 6| Step: 2
Training loss: 2.795929988852274
Validation loss: 2.464735396512984

Epoch: 6| Step: 3
Training loss: 2.397550437484217
Validation loss: 2.4629372842650996

Epoch: 6| Step: 4
Training loss: 2.5270535569246313
Validation loss: 2.457316177416253

Epoch: 6| Step: 5
Training loss: 2.0993078680681547
Validation loss: 2.462960323161296

Epoch: 6| Step: 6
Training loss: 2.470175609137542
Validation loss: 2.463259002620571

Epoch: 6| Step: 7
Training loss: 2.0925020512761097
Validation loss: 2.4649079440906894

Epoch: 6| Step: 8
Training loss: 2.9746119398380277
Validation loss: 2.4613333247519864

Epoch: 6| Step: 9
Training loss: 2.275943489197772
Validation loss: 2.462299095388115

Epoch: 6| Step: 10
Training loss: 2.8643545348376684
Validation loss: 2.4640706134953647

Epoch: 6| Step: 11
Training loss: 2.42719162684375
Validation loss: 2.4666132472242257

Epoch: 6| Step: 12
Training loss: 2.739556161337198
Validation loss: 2.4657973486709173

Epoch: 6| Step: 13
Training loss: 2.548936536098412
Validation loss: 2.466502281029641

Epoch: 104| Step: 0
Training loss: 3.014922223202929
Validation loss: 2.4674459465777234

Epoch: 6| Step: 1
Training loss: 2.0797920137736465
Validation loss: 2.46684062533369

Epoch: 6| Step: 2
Training loss: 2.7260519604506186
Validation loss: 2.4656652178947245

Epoch: 6| Step: 3
Training loss: 2.692011041332348
Validation loss: 2.462864947506598

Epoch: 6| Step: 4
Training loss: 1.6490311841682233
Validation loss: 2.465003039195036

Epoch: 6| Step: 5
Training loss: 2.4351986511474863
Validation loss: 2.468484904546429

Epoch: 6| Step: 6
Training loss: 2.013497464371878
Validation loss: 2.4691930284829855

Epoch: 6| Step: 7
Training loss: 2.2613040102386037
Validation loss: 2.4645671739690727

Epoch: 6| Step: 8
Training loss: 2.8067182664213
Validation loss: 2.465131852632356

Epoch: 6| Step: 9
Training loss: 2.742093250361256
Validation loss: 2.4647875102821737

Epoch: 6| Step: 10
Training loss: 2.626916730550633
Validation loss: 2.463849253468883

Epoch: 6| Step: 11
Training loss: 2.7464663604115143
Validation loss: 2.461858474122029

Epoch: 6| Step: 12
Training loss: 2.9601805028780155
Validation loss: 2.466329168308022

Epoch: 6| Step: 13
Training loss: 2.6518559632347403
Validation loss: 2.471488496099575

Epoch: 105| Step: 0
Training loss: 3.073127213501148
Validation loss: 2.4717436236719874

Epoch: 6| Step: 1
Training loss: 2.6573046217517486
Validation loss: 2.467072138022962

Epoch: 6| Step: 2
Training loss: 2.6495216873643375
Validation loss: 2.4713207975545917

Epoch: 6| Step: 3
Training loss: 2.321042957347208
Validation loss: 2.4733847237549407

Epoch: 6| Step: 4
Training loss: 2.7226640435740768
Validation loss: 2.473045346630112

Epoch: 6| Step: 5
Training loss: 2.5867583018061215
Validation loss: 2.4686072907868306

Epoch: 6| Step: 6
Training loss: 2.410069394517336
Validation loss: 2.4719305033024583

Epoch: 6| Step: 7
Training loss: 2.719616455917518
Validation loss: 2.4720783894258673

Epoch: 6| Step: 8
Training loss: 2.548122170853512
Validation loss: 2.473959074856831

Epoch: 6| Step: 9
Training loss: 2.295753049283275
Validation loss: 2.4774929990133816

Epoch: 6| Step: 10
Training loss: 2.5155876583384384
Validation loss: 2.4837426874430366

Epoch: 6| Step: 11
Training loss: 2.6853228777322324
Validation loss: 2.486871596534805

Epoch: 6| Step: 12
Training loss: 1.8777895204125492
Validation loss: 2.48615883018355

Epoch: 6| Step: 13
Training loss: 2.5664257588799027
Validation loss: 2.48506006356305

Epoch: 106| Step: 0
Training loss: 2.161290676248234
Validation loss: 2.4830353521830566

Epoch: 6| Step: 1
Training loss: 2.689955720501599
Validation loss: 2.4804840808304527

Epoch: 6| Step: 2
Training loss: 2.6886220851745652
Validation loss: 2.472730140325257

Epoch: 6| Step: 3
Training loss: 2.430076641553859
Validation loss: 2.4641783350630737

Epoch: 6| Step: 4
Training loss: 2.3318778902934127
Validation loss: 2.468724375402681

Epoch: 6| Step: 5
Training loss: 2.9719842258922973
Validation loss: 2.4655653939498046

Epoch: 6| Step: 6
Training loss: 2.81437146123282
Validation loss: 2.466131898437145

Epoch: 6| Step: 7
Training loss: 2.905527496769711
Validation loss: 2.4614227946704172

Epoch: 6| Step: 8
Training loss: 2.3790875445658264
Validation loss: 2.467981114144714

Epoch: 6| Step: 9
Training loss: 2.6660682086160445
Validation loss: 2.461265001252895

Epoch: 6| Step: 10
Training loss: 2.423835010503415
Validation loss: 2.4617710699963893

Epoch: 6| Step: 11
Training loss: 2.6826276747724567
Validation loss: 2.464018670020649

Epoch: 6| Step: 12
Training loss: 1.8199979322023487
Validation loss: 2.462400520238807

Epoch: 6| Step: 13
Training loss: 2.7888059524811837
Validation loss: 2.4601936952065713

Epoch: 107| Step: 0
Training loss: 2.9286513467178583
Validation loss: 2.4612291758624876

Epoch: 6| Step: 1
Training loss: 2.8992704855091618
Validation loss: 2.465817041174604

Epoch: 6| Step: 2
Training loss: 2.8790783358401018
Validation loss: 2.4680176787534087

Epoch: 6| Step: 3
Training loss: 1.7464958939655568
Validation loss: 2.4703402648562247

Epoch: 6| Step: 4
Training loss: 2.676107523162121
Validation loss: 2.465818773527263

Epoch: 6| Step: 5
Training loss: 1.649483154728891
Validation loss: 2.4693494463330348

Epoch: 6| Step: 6
Training loss: 2.9133200019106575
Validation loss: 2.463672825317296

Epoch: 6| Step: 7
Training loss: 2.661908215586249
Validation loss: 2.4598734497973145

Epoch: 6| Step: 8
Training loss: 2.9184891774125727
Validation loss: 2.460640638096818

Epoch: 6| Step: 9
Training loss: 2.386050566246973
Validation loss: 2.4645160310078995

Epoch: 6| Step: 10
Training loss: 1.9524533146785215
Validation loss: 2.461571521930563

Epoch: 6| Step: 11
Training loss: 3.09636723949003
Validation loss: 2.459983406605362

Epoch: 6| Step: 12
Training loss: 1.957700877497322
Validation loss: 2.468713832542009

Epoch: 6| Step: 13
Training loss: 2.530474508667035
Validation loss: 2.468659282578851

Epoch: 108| Step: 0
Training loss: 2.711972261765224
Validation loss: 2.469907400786738

Epoch: 6| Step: 1
Training loss: 2.3013264604305985
Validation loss: 2.465657224392196

Epoch: 6| Step: 2
Training loss: 2.7472140331894113
Validation loss: 2.4690367294747895

Epoch: 6| Step: 3
Training loss: 2.435997720087798
Validation loss: 2.465376339465958

Epoch: 6| Step: 4
Training loss: 2.658802735631117
Validation loss: 2.4577433287596904

Epoch: 6| Step: 5
Training loss: 2.776162197986643
Validation loss: 2.4601937840411865

Epoch: 6| Step: 6
Training loss: 3.081968125541773
Validation loss: 2.4621918887329106

Epoch: 6| Step: 7
Training loss: 2.9022254560347736
Validation loss: 2.462759193424678

Epoch: 6| Step: 8
Training loss: 2.121977507821695
Validation loss: 2.464466515484191

Epoch: 6| Step: 9
Training loss: 2.8690807941345056
Validation loss: 2.4666450556461337

Epoch: 6| Step: 10
Training loss: 2.025907091968456
Validation loss: 2.4809010206613324

Epoch: 6| Step: 11
Training loss: 2.4276905746375674
Validation loss: 2.477685346884609

Epoch: 6| Step: 12
Training loss: 2.429057735751059
Validation loss: 2.4853177631030974

Epoch: 6| Step: 13
Training loss: 2.1504861947285923
Validation loss: 2.4684443626657733

Epoch: 109| Step: 0
Training loss: 2.96114942451519
Validation loss: 2.470050469241958

Epoch: 6| Step: 1
Training loss: 3.084029368289189
Validation loss: 2.4676847614296675

Epoch: 6| Step: 2
Training loss: 1.844567392488748
Validation loss: 2.4583229344896975

Epoch: 6| Step: 3
Training loss: 2.4469022123302238
Validation loss: 2.4713343842936975

Epoch: 6| Step: 4
Training loss: 2.897830210606618
Validation loss: 2.4723331989663575

Epoch: 6| Step: 5
Training loss: 2.5265465824944537
Validation loss: 2.470794925316129

Epoch: 6| Step: 6
Training loss: 2.8369100285040165
Validation loss: 2.4729338817002584

Epoch: 6| Step: 7
Training loss: 2.493422055969333
Validation loss: 2.4674428142941074

Epoch: 6| Step: 8
Training loss: 2.2717858046452135
Validation loss: 2.4681084117072745

Epoch: 6| Step: 9
Training loss: 2.318112547412378
Validation loss: 2.469515822532453

Epoch: 6| Step: 10
Training loss: 2.511611865010481
Validation loss: 2.4676437152621564

Epoch: 6| Step: 11
Training loss: 2.40741196357535
Validation loss: 2.469274344472287

Epoch: 6| Step: 12
Training loss: 2.770095918282321
Validation loss: 2.473128464029332

Epoch: 6| Step: 13
Training loss: 2.1997078441487123
Validation loss: 2.4711597608685607

Epoch: 110| Step: 0
Training loss: 2.1247980358413443
Validation loss: 2.4720424314075276

Epoch: 6| Step: 1
Training loss: 2.483061149154542
Validation loss: 2.4716031291132086

Epoch: 6| Step: 2
Training loss: 2.5914336742736017
Validation loss: 2.472259875402517

Epoch: 6| Step: 3
Training loss: 3.210592952165096
Validation loss: 2.4675984654592935

Epoch: 6| Step: 4
Training loss: 2.5026820101558087
Validation loss: 2.4712628239485603

Epoch: 6| Step: 5
Training loss: 2.489864977197618
Validation loss: 2.467518736830317

Epoch: 6| Step: 6
Training loss: 2.413825261085037
Validation loss: 2.4659216086351314

Epoch: 6| Step: 7
Training loss: 2.257667932864944
Validation loss: 2.4617416440495807

Epoch: 6| Step: 8
Training loss: 2.7686823955058184
Validation loss: 2.46439269987376

Epoch: 6| Step: 9
Training loss: 2.5934547348176045
Validation loss: 2.459321297653431

Epoch: 6| Step: 10
Training loss: 2.200753200082772
Validation loss: 2.4612994215514084

Epoch: 6| Step: 11
Training loss: 2.6733784154608933
Validation loss: 2.46597027313185

Epoch: 6| Step: 12
Training loss: 2.462219098330527
Validation loss: 2.4604548631933794

Epoch: 6| Step: 13
Training loss: 2.7208834641079997
Validation loss: 2.463683889744921

Epoch: 111| Step: 0
Training loss: 2.8532736464820516
Validation loss: 2.464536394804656

Epoch: 6| Step: 1
Training loss: 2.7201909598467946
Validation loss: 2.4620111938829465

Epoch: 6| Step: 2
Training loss: 2.382777679689231
Validation loss: 2.4635969374883584

Epoch: 6| Step: 3
Training loss: 3.1113241402791494
Validation loss: 2.461399144060887

Epoch: 6| Step: 4
Training loss: 2.3751459578788054
Validation loss: 2.4562294788490195

Epoch: 6| Step: 5
Training loss: 2.8600884886703946
Validation loss: 2.458206696131131

Epoch: 6| Step: 6
Training loss: 1.7545417704747928
Validation loss: 2.4590897339339586

Epoch: 6| Step: 7
Training loss: 2.8015388517557147
Validation loss: 2.463199871351097

Epoch: 6| Step: 8
Training loss: 2.5259638089375906
Validation loss: 2.4677596379286624

Epoch: 6| Step: 9
Training loss: 2.585784630996547
Validation loss: 2.468279765610541

Epoch: 6| Step: 10
Training loss: 2.5013561385253165
Validation loss: 2.4677494129923105

Epoch: 6| Step: 11
Training loss: 2.0724543019077872
Validation loss: 2.4628233934463344

Epoch: 6| Step: 12
Training loss: 2.8513768801957835
Validation loss: 2.4666592239147316

Epoch: 6| Step: 13
Training loss: 2.043874157042018
Validation loss: 2.4553228927469393

Epoch: 112| Step: 0
Training loss: 2.1742128372797342
Validation loss: 2.464977133840236

Epoch: 6| Step: 1
Training loss: 2.225688347797372
Validation loss: 2.4675291881748085

Epoch: 6| Step: 2
Training loss: 2.7752475903006353
Validation loss: 2.4708799517534583

Epoch: 6| Step: 3
Training loss: 2.9859640474601514
Validation loss: 2.476458365801209

Epoch: 6| Step: 4
Training loss: 2.546628975248111
Validation loss: 2.4804580808395054

Epoch: 6| Step: 5
Training loss: 2.6976783873055457
Validation loss: 2.4783729971110575

Epoch: 6| Step: 6
Training loss: 2.1582685227648164
Validation loss: 2.4819513010467427

Epoch: 6| Step: 7
Training loss: 2.2320431365490068
Validation loss: 2.474297114147978

Epoch: 6| Step: 8
Training loss: 2.0603763166230276
Validation loss: 2.480458489344243

Epoch: 6| Step: 9
Training loss: 2.3018605626461657
Validation loss: 2.4807891558667965

Epoch: 6| Step: 10
Training loss: 2.524798613722678
Validation loss: 2.4762164173933243

Epoch: 6| Step: 11
Training loss: 2.868574674812916
Validation loss: 2.477268250805753

Epoch: 6| Step: 12
Training loss: 3.2399821306842607
Validation loss: 2.4734936140502475

Epoch: 6| Step: 13
Training loss: 2.74583544540517
Validation loss: 2.478671839295001

Epoch: 113| Step: 0
Training loss: 2.55218513960418
Validation loss: 2.4797428060035562

Epoch: 6| Step: 1
Training loss: 2.815244310662405
Validation loss: 2.4786355761397076

Epoch: 6| Step: 2
Training loss: 3.5942513821019393
Validation loss: 2.47680739867611

Epoch: 6| Step: 3
Training loss: 2.737637997985474
Validation loss: 2.4691907111070175

Epoch: 6| Step: 4
Training loss: 2.542979531917187
Validation loss: 2.468224658681554

Epoch: 6| Step: 5
Training loss: 2.052448633924236
Validation loss: 2.457731324100427

Epoch: 6| Step: 6
Training loss: 2.734915979548851
Validation loss: 2.4591959609024774

Epoch: 6| Step: 7
Training loss: 2.258385819767139
Validation loss: 2.4597587628566946

Epoch: 6| Step: 8
Training loss: 2.82106054640916
Validation loss: 2.4554656053507378

Epoch: 6| Step: 9
Training loss: 2.4436841911957545
Validation loss: 2.451502820454152

Epoch: 6| Step: 10
Training loss: 2.390329878797878
Validation loss: 2.4530112205732904

Epoch: 6| Step: 11
Training loss: 2.37353028448186
Validation loss: 2.4596884650909168

Epoch: 6| Step: 12
Training loss: 2.3075868117843146
Validation loss: 2.453090780873974

Epoch: 6| Step: 13
Training loss: 1.790547383541899
Validation loss: 2.455860977168284

Epoch: 114| Step: 0
Training loss: 2.7043958554081953
Validation loss: 2.4579961082069706

Epoch: 6| Step: 1
Training loss: 2.7766185301889634
Validation loss: 2.4632210768215947

Epoch: 6| Step: 2
Training loss: 2.6193174889890267
Validation loss: 2.4620360813673283

Epoch: 6| Step: 3
Training loss: 1.866354209714103
Validation loss: 2.465393923917332

Epoch: 6| Step: 4
Training loss: 2.5294774760570378
Validation loss: 2.465898984151349

Epoch: 6| Step: 5
Training loss: 2.067082025975703
Validation loss: 2.461311578324177

Epoch: 6| Step: 6
Training loss: 2.542607951315302
Validation loss: 2.460304098006311

Epoch: 6| Step: 7
Training loss: 3.149777867795613
Validation loss: 2.4604725958668796

Epoch: 6| Step: 8
Training loss: 2.852910640222324
Validation loss: 2.458478670080595

Epoch: 6| Step: 9
Training loss: 2.2265708521636114
Validation loss: 2.4569704809391255

Epoch: 6| Step: 10
Training loss: 2.732052585168338
Validation loss: 2.463766766534169

Epoch: 6| Step: 11
Training loss: 2.384852402316538
Validation loss: 2.462514769482414

Epoch: 6| Step: 12
Training loss: 2.6283012702968143
Validation loss: 2.460006844684207

Epoch: 6| Step: 13
Training loss: 2.0373932886555535
Validation loss: 2.4659949434088815

Epoch: 115| Step: 0
Training loss: 2.0011944780147357
Validation loss: 2.4600131281835815

Epoch: 6| Step: 1
Training loss: 2.9777554101562544
Validation loss: 2.4659694674360804

Epoch: 6| Step: 2
Training loss: 2.798828125
Validation loss: 2.46816359367989

Epoch: 6| Step: 3
Training loss: 2.674837667227772
Validation loss: 2.4633292388193726

Epoch: 6| Step: 4
Training loss: 2.257460517242319
Validation loss: 2.4641599437126103

Epoch: 6| Step: 5
Training loss: 2.204916151532871
Validation loss: 2.4601046732340324

Epoch: 6| Step: 6
Training loss: 2.617433997545372
Validation loss: 2.453214234755923

Epoch: 6| Step: 7
Training loss: 2.4247174717815367
Validation loss: 2.4546819067231027

Epoch: 6| Step: 8
Training loss: 2.3135291206698696
Validation loss: 2.4500691520896636

Epoch: 6| Step: 9
Training loss: 2.32345655750291
Validation loss: 2.4588855080175027

Epoch: 6| Step: 10
Training loss: 2.5611503582436814
Validation loss: 2.4491082125456245

Epoch: 6| Step: 11
Training loss: 2.516057516316954
Validation loss: 2.4539090339218164

Epoch: 6| Step: 12
Training loss: 2.7170041496798345
Validation loss: 2.4520651437176033

Epoch: 6| Step: 13
Training loss: 2.8782680016197153
Validation loss: 2.452860775464116

Epoch: 116| Step: 0
Training loss: 2.6783284558495306
Validation loss: 2.457219507296069

Epoch: 6| Step: 1
Training loss: 2.592333671215
Validation loss: 2.4634769315595078

Epoch: 6| Step: 2
Training loss: 2.3522557855665274
Validation loss: 2.463772645301428

Epoch: 6| Step: 3
Training loss: 2.5333682016014283
Validation loss: 2.469451804544041

Epoch: 6| Step: 4
Training loss: 2.233213963331339
Validation loss: 2.4710582694023957

Epoch: 6| Step: 5
Training loss: 2.744949731974503
Validation loss: 2.468629584615031

Epoch: 6| Step: 6
Training loss: 2.2707450102915376
Validation loss: 2.469325002674087

Epoch: 6| Step: 7
Training loss: 1.712156584339255
Validation loss: 2.464959723741292

Epoch: 6| Step: 8
Training loss: 2.631384397141554
Validation loss: 2.4602570253973566

Epoch: 6| Step: 9
Training loss: 3.0184602207395432
Validation loss: 2.4600189755387625

Epoch: 6| Step: 10
Training loss: 2.980104756658185
Validation loss: 2.4598969212312305

Epoch: 6| Step: 11
Training loss: 2.8166283719621563
Validation loss: 2.458181511237223

Epoch: 6| Step: 12
Training loss: 2.2301427065087207
Validation loss: 2.455619426606727

Epoch: 6| Step: 13
Training loss: 2.450747850681177
Validation loss: 2.4545595708381187

Epoch: 117| Step: 0
Training loss: 2.5279588378319584
Validation loss: 2.4547922255727928

Epoch: 6| Step: 1
Training loss: 2.2480566321193556
Validation loss: 2.455746847165249

Epoch: 6| Step: 2
Training loss: 3.0116261271323945
Validation loss: 2.4537922140134896

Epoch: 6| Step: 3
Training loss: 2.3514955834280946
Validation loss: 2.4520220048527923

Epoch: 6| Step: 4
Training loss: 2.3888379567160403
Validation loss: 2.45748895486786

Epoch: 6| Step: 5
Training loss: 2.599674398868646
Validation loss: 2.457203109544793

Epoch: 6| Step: 6
Training loss: 2.519669403310192
Validation loss: 2.4612464670466223

Epoch: 6| Step: 7
Training loss: 2.5064703180978167
Validation loss: 2.4638254164880546

Epoch: 6| Step: 8
Training loss: 2.746050773273457
Validation loss: 2.4613007292549467

Epoch: 6| Step: 9
Training loss: 2.867140101734841
Validation loss: 2.4599108941395675

Epoch: 6| Step: 10
Training loss: 2.2633036329580123
Validation loss: 2.450499334183588

Epoch: 6| Step: 11
Training loss: 2.213226104383268
Validation loss: 2.455594967640411

Epoch: 6| Step: 12
Training loss: 2.453617119477719
Validation loss: 2.461567792962233

Epoch: 6| Step: 13
Training loss: 2.5504526858462753
Validation loss: 2.466116703966481

Epoch: 118| Step: 0
Training loss: 2.561362781787609
Validation loss: 2.4759523781380723

Epoch: 6| Step: 1
Training loss: 2.707449216075787
Validation loss: 2.4693474187576245

Epoch: 6| Step: 2
Training loss: 2.637481805096823
Validation loss: 2.471731421749259

Epoch: 6| Step: 3
Training loss: 2.8463334306460104
Validation loss: 2.466758020960339

Epoch: 6| Step: 4
Training loss: 3.35684094332371
Validation loss: 2.4717194287599225

Epoch: 6| Step: 5
Training loss: 1.7536438743581122
Validation loss: 2.4692470356013656

Epoch: 6| Step: 6
Training loss: 2.051696340664986
Validation loss: 2.4704517663847168

Epoch: 6| Step: 7
Training loss: 2.5903555477991187
Validation loss: 2.470204516372462

Epoch: 6| Step: 8
Training loss: 2.53967108842183
Validation loss: 2.4714178486462006

Epoch: 6| Step: 9
Training loss: 1.5328427808533427
Validation loss: 2.4696139904153385

Epoch: 6| Step: 10
Training loss: 2.3228753831784363
Validation loss: 2.468500341998365

Epoch: 6| Step: 11
Training loss: 2.626763704979589
Validation loss: 2.466871810664894

Epoch: 6| Step: 12
Training loss: 2.6192998304346693
Validation loss: 2.4608075627330637

Epoch: 6| Step: 13
Training loss: 3.043720823300868
Validation loss: 2.462512292524661

Epoch: 119| Step: 0
Training loss: 2.4902715223945004
Validation loss: 2.456987713143525

Epoch: 6| Step: 1
Training loss: 2.7648087498502116
Validation loss: 2.4599867745304995

Epoch: 6| Step: 2
Training loss: 2.888214260786574
Validation loss: 2.4614266368640236

Epoch: 6| Step: 3
Training loss: 2.1330865816623956
Validation loss: 2.46726819728426

Epoch: 6| Step: 4
Training loss: 2.8739044755896903
Validation loss: 2.4662425671101476

Epoch: 6| Step: 5
Training loss: 1.8715326674410662
Validation loss: 2.4649670585664856

Epoch: 6| Step: 6
Training loss: 2.9095125651385696
Validation loss: 2.4623795739691428

Epoch: 6| Step: 7
Training loss: 2.7860045351702163
Validation loss: 2.466741525527925

Epoch: 6| Step: 8
Training loss: 2.451567817716259
Validation loss: 2.4709305448744994

Epoch: 6| Step: 9
Training loss: 2.3322224243117127
Validation loss: 2.460432769847589

Epoch: 6| Step: 10
Training loss: 2.2790299155467513
Validation loss: 2.4647314143791954

Epoch: 6| Step: 11
Training loss: 2.2252706427401505
Validation loss: 2.4700831584085035

Epoch: 6| Step: 12
Training loss: 2.2746412099097255
Validation loss: 2.468236040786108

Epoch: 6| Step: 13
Training loss: 2.8739953981069357
Validation loss: 2.460787733253831

Epoch: 120| Step: 0
Training loss: 2.1354300397748807
Validation loss: 2.465460424567311

Epoch: 6| Step: 1
Training loss: 2.979083097837454
Validation loss: 2.4589753093961413

Epoch: 6| Step: 2
Training loss: 2.7443162963676904
Validation loss: 2.4591522199912412

Epoch: 6| Step: 3
Training loss: 2.296387289778395
Validation loss: 2.453836180018403

Epoch: 6| Step: 4
Training loss: 2.4530598820104257
Validation loss: 2.4654262718884783

Epoch: 6| Step: 5
Training loss: 2.80245976714385
Validation loss: 2.4552606571941027

Epoch: 6| Step: 6
Training loss: 2.499258217435856
Validation loss: 2.450606768591435

Epoch: 6| Step: 7
Training loss: 2.3297832139307673
Validation loss: 2.464156081592202

Epoch: 6| Step: 8
Training loss: 2.7155955638980185
Validation loss: 2.458268752031055

Epoch: 6| Step: 9
Training loss: 2.676432242177364
Validation loss: 2.4611468755875614

Epoch: 6| Step: 10
Training loss: 2.7481377104690194
Validation loss: 2.460306916358336

Epoch: 6| Step: 11
Training loss: 2.092524041478678
Validation loss: 2.4618734366224815

Epoch: 6| Step: 12
Training loss: 2.205018008065593
Validation loss: 2.458446311509798

Epoch: 6| Step: 13
Training loss: 2.6201655056053075
Validation loss: 2.463527838014229

Epoch: 121| Step: 0
Training loss: 2.605625222238818
Validation loss: 2.455425649570735

Epoch: 6| Step: 1
Training loss: 2.5804055040157987
Validation loss: 2.455684549540558

Epoch: 6| Step: 2
Training loss: 2.729815185215763
Validation loss: 2.4579436483635835

Epoch: 6| Step: 3
Training loss: 3.161712451925714
Validation loss: 2.4571429673487404

Epoch: 6| Step: 4
Training loss: 2.0579661619705796
Validation loss: 2.455842928039772

Epoch: 6| Step: 5
Training loss: 2.3168355148404314
Validation loss: 2.453889812619678

Epoch: 6| Step: 6
Training loss: 2.5097072965619924
Validation loss: 2.4563570942394906

Epoch: 6| Step: 7
Training loss: 2.7520463439011147
Validation loss: 2.4573979349243116

Epoch: 6| Step: 8
Training loss: 2.4155699335017595
Validation loss: 2.452656743740419

Epoch: 6| Step: 9
Training loss: 2.4706898082027484
Validation loss: 2.4566693789994662

Epoch: 6| Step: 10
Training loss: 2.5411614296297644
Validation loss: 2.459192373756922

Epoch: 6| Step: 11
Training loss: 2.7813672673223904
Validation loss: 2.45243761025391

Epoch: 6| Step: 12
Training loss: 2.244769692958783
Validation loss: 2.4662927236721712

Epoch: 6| Step: 13
Training loss: 1.992675242836395
Validation loss: 2.4595233386171214

Epoch: 122| Step: 0
Training loss: 2.2065798677658575
Validation loss: 2.4641323927128864

Epoch: 6| Step: 1
Training loss: 2.739467043034211
Validation loss: 2.467205192014473

Epoch: 6| Step: 2
Training loss: 2.6392567718352495
Validation loss: 2.4579561288962366

Epoch: 6| Step: 3
Training loss: 2.952485514838647
Validation loss: 2.4467546072061914

Epoch: 6| Step: 4
Training loss: 2.3804923346527658
Validation loss: 2.459407997152345

Epoch: 6| Step: 5
Training loss: 2.8279740941373235
Validation loss: 2.453118229105488

Epoch: 6| Step: 6
Training loss: 2.8088322778253625
Validation loss: 2.456614351306473

Epoch: 6| Step: 7
Training loss: 1.8213398535143055
Validation loss: 2.449782100381661

Epoch: 6| Step: 8
Training loss: 1.8434284382384167
Validation loss: 2.4539498888094937

Epoch: 6| Step: 9
Training loss: 2.406744373613333
Validation loss: 2.4517721102341783

Epoch: 6| Step: 10
Training loss: 2.5341384796143847
Validation loss: 2.4560662716136688

Epoch: 6| Step: 11
Training loss: 2.9920781765480653
Validation loss: 2.454407731173017

Epoch: 6| Step: 12
Training loss: 2.163781103024102
Validation loss: 2.4469300304085544

Epoch: 6| Step: 13
Training loss: 2.6897051436194706
Validation loss: 2.449365314355149

Epoch: 123| Step: 0
Training loss: 3.149647671810764
Validation loss: 2.4528797861312492

Epoch: 6| Step: 1
Training loss: 2.1474778130021335
Validation loss: 2.45622530496881

Epoch: 6| Step: 2
Training loss: 2.2162536762204907
Validation loss: 2.47379045954215

Epoch: 6| Step: 3
Training loss: 2.096992714501324
Validation loss: 2.484060255542259

Epoch: 6| Step: 4
Training loss: 2.791473457900345
Validation loss: 2.4958871707193793

Epoch: 6| Step: 5
Training loss: 2.7332484077037953
Validation loss: 2.4964458314772062

Epoch: 6| Step: 6
Training loss: 2.720223476962494
Validation loss: 2.499988643302554

Epoch: 6| Step: 7
Training loss: 2.5407415384401126
Validation loss: 2.4869385934019954

Epoch: 6| Step: 8
Training loss: 2.919709244452871
Validation loss: 2.488267212832634

Epoch: 6| Step: 9
Training loss: 2.9571875023219545
Validation loss: 2.483950100757416

Epoch: 6| Step: 10
Training loss: 2.526537051571068
Validation loss: 2.4846553044565582

Epoch: 6| Step: 11
Training loss: 1.9877906298922312
Validation loss: 2.481718582505251

Epoch: 6| Step: 12
Training loss: 2.1579707922527738
Validation loss: 2.476484183147159

Epoch: 6| Step: 13
Training loss: 2.7398237599126847
Validation loss: 2.473533133390822

Epoch: 124| Step: 0
Training loss: 2.2615393269316146
Validation loss: 2.479662041632589

Epoch: 6| Step: 1
Training loss: 2.402294921378769
Validation loss: 2.474223816664398

Epoch: 6| Step: 2
Training loss: 2.8197662585358203
Validation loss: 2.472546945157727

Epoch: 6| Step: 3
Training loss: 2.763117973976202
Validation loss: 2.4719835986536673

Epoch: 6| Step: 4
Training loss: 2.4423140890221378
Validation loss: 2.4627984816487

Epoch: 6| Step: 5
Training loss: 2.4581328380313296
Validation loss: 2.4647130835831965

Epoch: 6| Step: 6
Training loss: 2.548889673885693
Validation loss: 2.4613972229433756

Epoch: 6| Step: 7
Training loss: 1.9732981628857909
Validation loss: 2.454242799891671

Epoch: 6| Step: 8
Training loss: 2.5960671059879643
Validation loss: 2.4609362001768846

Epoch: 6| Step: 9
Training loss: 2.5576884990595388
Validation loss: 2.4549659252197515

Epoch: 6| Step: 10
Training loss: 3.0691440678873714
Validation loss: 2.455453565281341

Epoch: 6| Step: 11
Training loss: 2.9287645030425757
Validation loss: 2.4657938194740145

Epoch: 6| Step: 12
Training loss: 2.005578011128444
Validation loss: 2.4660000675765517

Epoch: 6| Step: 13
Training loss: 2.4241053002402415
Validation loss: 2.449002359292807

Epoch: 125| Step: 0
Training loss: 2.7422484475342768
Validation loss: 2.458424798158339

Epoch: 6| Step: 1
Training loss: 2.3857727673413693
Validation loss: 2.4637494688454438

Epoch: 6| Step: 2
Training loss: 2.2681287939650128
Validation loss: 2.4586412484819697

Epoch: 6| Step: 3
Training loss: 2.689711082570512
Validation loss: 2.4647732022804885

Epoch: 6| Step: 4
Training loss: 2.7220289254708248
Validation loss: 2.467257664306685

Epoch: 6| Step: 5
Training loss: 2.4333018806027287
Validation loss: 2.473393575889207

Epoch: 6| Step: 6
Training loss: 2.766845778523586
Validation loss: 2.4718125417014662

Epoch: 6| Step: 7
Training loss: 2.571365001816097
Validation loss: 2.4675971288866636

Epoch: 6| Step: 8
Training loss: 2.523348496701005
Validation loss: 2.471538023680163

Epoch: 6| Step: 9
Training loss: 3.0356667971703324
Validation loss: 2.4709725495649133

Epoch: 6| Step: 10
Training loss: 2.1236699373580006
Validation loss: 2.4709160473012375

Epoch: 6| Step: 11
Training loss: 2.614000344093259
Validation loss: 2.469701382453481

Epoch: 6| Step: 12
Training loss: 2.403393325409625
Validation loss: 2.456422666736625

Epoch: 6| Step: 13
Training loss: 2.2131529582686134
Validation loss: 2.456705092962491

Epoch: 126| Step: 0
Training loss: 2.0802438589343986
Validation loss: 2.4495824840855858

Epoch: 6| Step: 1
Training loss: 2.2599020399958043
Validation loss: 2.459228309609374

Epoch: 6| Step: 2
Training loss: 2.710162225069534
Validation loss: 2.4553963417788474

Epoch: 6| Step: 3
Training loss: 2.2137907239634997
Validation loss: 2.4581745117953417

Epoch: 6| Step: 4
Training loss: 2.5387003009388605
Validation loss: 2.4525261895261976

Epoch: 6| Step: 5
Training loss: 2.18411516164021
Validation loss: 2.449693357001027

Epoch: 6| Step: 6
Training loss: 2.983932702008741
Validation loss: 2.4561379430575028

Epoch: 6| Step: 7
Training loss: 2.4490681530467504
Validation loss: 2.4499238138614814

Epoch: 6| Step: 8
Training loss: 1.6962553997136574
Validation loss: 2.4495170934781116

Epoch: 6| Step: 9
Training loss: 2.544534930471605
Validation loss: 2.4517181962971115

Epoch: 6| Step: 10
Training loss: 2.5738627024018648
Validation loss: 2.444129519574277

Epoch: 6| Step: 11
Training loss: 3.058760871072835
Validation loss: 2.463953968948529

Epoch: 6| Step: 12
Training loss: 2.5653140735749185
Validation loss: 2.4548346844632167

Epoch: 6| Step: 13
Training loss: 3.050870027117393
Validation loss: 2.449619007005482

Epoch: 127| Step: 0
Training loss: 2.667043679130351
Validation loss: 2.4565938571387176

Epoch: 6| Step: 1
Training loss: 2.9158576569946777
Validation loss: 2.457335606390091

Epoch: 6| Step: 2
Training loss: 2.5779215414509715
Validation loss: 2.4600603266041294

Epoch: 6| Step: 3
Training loss: 2.362911176473901
Validation loss: 2.4621170527194085

Epoch: 6| Step: 4
Training loss: 2.25567124147864
Validation loss: 2.462363952906285

Epoch: 6| Step: 5
Training loss: 2.513229935928256
Validation loss: 2.4631353988240816

Epoch: 6| Step: 6
Training loss: 2.2455402256130244
Validation loss: 2.455220908476831

Epoch: 6| Step: 7
Training loss: 2.4358465014987143
Validation loss: 2.462181689090959

Epoch: 6| Step: 8
Training loss: 2.573499842562021
Validation loss: 2.468298568978753

Epoch: 6| Step: 9
Training loss: 2.7046083118078843
Validation loss: 2.4719991026668917

Epoch: 6| Step: 10
Training loss: 2.487400443993793
Validation loss: 2.465909071731727

Epoch: 6| Step: 11
Training loss: 2.5717490219836723
Validation loss: 2.464119508060036

Epoch: 6| Step: 12
Training loss: 2.2079101972838524
Validation loss: 2.4588365578554545

Epoch: 6| Step: 13
Training loss: 2.730460542112574
Validation loss: 2.4563899090161923

Epoch: 128| Step: 0
Training loss: 2.2075895700395294
Validation loss: 2.4524388740743293

Epoch: 6| Step: 1
Training loss: 2.7841665855696194
Validation loss: 2.457158767148615

Epoch: 6| Step: 2
Training loss: 2.5470504232267315
Validation loss: 2.452984135626858

Epoch: 6| Step: 3
Training loss: 2.711212759857003
Validation loss: 2.4545978004453586

Epoch: 6| Step: 4
Training loss: 2.6055018753165067
Validation loss: 2.459775006257834

Epoch: 6| Step: 5
Training loss: 2.8767432856900346
Validation loss: 2.457141738291472

Epoch: 6| Step: 6
Training loss: 2.538927467863695
Validation loss: 2.4582224244352706

Epoch: 6| Step: 7
Training loss: 2.1796393713884505
Validation loss: 2.459790627607573

Epoch: 6| Step: 8
Training loss: 2.7674488153178287
Validation loss: 2.459099623221785

Epoch: 6| Step: 9
Training loss: 2.510908455909195
Validation loss: 2.452854036240393

Epoch: 6| Step: 10
Training loss: 2.1200193490638886
Validation loss: 2.451832837965805

Epoch: 6| Step: 11
Training loss: 2.5438462485210267
Validation loss: 2.448168889031224

Epoch: 6| Step: 12
Training loss: 2.099344550886052
Validation loss: 2.4491150432007798

Epoch: 6| Step: 13
Training loss: 2.8160644831806314
Validation loss: 2.451185630161957

Epoch: 129| Step: 0
Training loss: 2.238707390341921
Validation loss: 2.4523169286062636

Epoch: 6| Step: 1
Training loss: 2.5756680890380492
Validation loss: 2.4467280863849243

Epoch: 6| Step: 2
Training loss: 2.654002057475002
Validation loss: 2.4475953290257317

Epoch: 6| Step: 3
Training loss: 2.579853564993386
Validation loss: 2.4485535354562455

Epoch: 6| Step: 4
Training loss: 2.2197798367177173
Validation loss: 2.4579493228105087

Epoch: 6| Step: 5
Training loss: 3.1506933266696557
Validation loss: 2.451656395998494

Epoch: 6| Step: 6
Training loss: 2.859917927878214
Validation loss: 2.4591807882105376

Epoch: 6| Step: 7
Training loss: 2.039649148203218
Validation loss: 2.459498991177419

Epoch: 6| Step: 8
Training loss: 2.221098395794583
Validation loss: 2.46479970627663

Epoch: 6| Step: 9
Training loss: 2.6191111313356163
Validation loss: 2.4626552339218577

Epoch: 6| Step: 10
Training loss: 2.370044557820525
Validation loss: 2.467655993757708

Epoch: 6| Step: 11
Training loss: 2.7052521026521372
Validation loss: 2.4594104933934338

Epoch: 6| Step: 12
Training loss: 2.6377718708518882
Validation loss: 2.457833341626146

Epoch: 6| Step: 13
Training loss: 2.161499599078192
Validation loss: 2.460043430901245

Epoch: 130| Step: 0
Training loss: 3.2036605759373806
Validation loss: 2.4571842212696366

Epoch: 6| Step: 1
Training loss: 2.4201694512744516
Validation loss: 2.4559788716864333

Epoch: 6| Step: 2
Training loss: 3.1839666791734667
Validation loss: 2.460589736506218

Epoch: 6| Step: 3
Training loss: 1.9434734061825854
Validation loss: 2.4659573255689566

Epoch: 6| Step: 4
Training loss: 2.0582664272950626
Validation loss: 2.465620302454507

Epoch: 6| Step: 5
Training loss: 2.2869969966653536
Validation loss: 2.467702377739404

Epoch: 6| Step: 6
Training loss: 2.214048427841274
Validation loss: 2.4690109147244783

Epoch: 6| Step: 7
Training loss: 2.7956912130134306
Validation loss: 2.4571409539585516

Epoch: 6| Step: 8
Training loss: 2.6281597556992327
Validation loss: 2.471500425898089

Epoch: 6| Step: 9
Training loss: 2.7951976498784457
Validation loss: 2.464534653488947

Epoch: 6| Step: 10
Training loss: 2.2891993563104394
Validation loss: 2.4584564135069478

Epoch: 6| Step: 11
Training loss: 2.6437681553715504
Validation loss: 2.4554945401148034

Epoch: 6| Step: 12
Training loss: 2.379304899441094
Validation loss: 2.4521429764962672

Epoch: 6| Step: 13
Training loss: 2.114014334457722
Validation loss: 2.4509103987647807

Epoch: 131| Step: 0
Training loss: 1.9522766712353565
Validation loss: 2.4587266144046835

Epoch: 6| Step: 1
Training loss: 1.6966615574253299
Validation loss: 2.4620358715517154

Epoch: 6| Step: 2
Training loss: 2.429285341202621
Validation loss: 2.4555457900597744

Epoch: 6| Step: 3
Training loss: 2.3513632655101127
Validation loss: 2.4517151330617266

Epoch: 6| Step: 4
Training loss: 2.2082316417192267
Validation loss: 2.4546380368078666

Epoch: 6| Step: 5
Training loss: 2.682848964436687
Validation loss: 2.4597550957587515

Epoch: 6| Step: 6
Training loss: 2.726073650269173
Validation loss: 2.464804075217002

Epoch: 6| Step: 7
Training loss: 2.5522765002164496
Validation loss: 2.445276774022564

Epoch: 6| Step: 8
Training loss: 2.8053775034220516
Validation loss: 2.447198183389297

Epoch: 6| Step: 9
Training loss: 3.0796864223623497
Validation loss: 2.447555293470723

Epoch: 6| Step: 10
Training loss: 2.299243562119241
Validation loss: 2.457655382156421

Epoch: 6| Step: 11
Training loss: 2.5224206724065645
Validation loss: 2.4557417339651977

Epoch: 6| Step: 12
Training loss: 2.593222047318825
Validation loss: 2.457811596565703

Epoch: 6| Step: 13
Training loss: 2.8362246701625513
Validation loss: 2.4639197147519245

Epoch: 132| Step: 0
Training loss: 2.345510508230558
Validation loss: 2.465105134593183

Epoch: 6| Step: 1
Training loss: 2.760730615192849
Validation loss: 2.4702092939964095

Epoch: 6| Step: 2
Training loss: 2.2216175515005947
Validation loss: 2.465960943158712

Epoch: 6| Step: 3
Training loss: 2.673620178295355
Validation loss: 2.463602590849292

Epoch: 6| Step: 4
Training loss: 2.5349830133294096
Validation loss: 2.470145977664166

Epoch: 6| Step: 5
Training loss: 3.008483653306415
Validation loss: 2.4644111781698075

Epoch: 6| Step: 6
Training loss: 2.645276729479338
Validation loss: 2.463298920062813

Epoch: 6| Step: 7
Training loss: 2.628908517278229
Validation loss: 2.4644565671133982

Epoch: 6| Step: 8
Training loss: 2.5914117775674956
Validation loss: 2.4623149105164504

Epoch: 6| Step: 9
Training loss: 2.516131427091685
Validation loss: 2.4601375349360013

Epoch: 6| Step: 10
Training loss: 2.5499713073312984
Validation loss: 2.464717081868707

Epoch: 6| Step: 11
Training loss: 1.5799937750295348
Validation loss: 2.4728339012412563

Epoch: 6| Step: 12
Training loss: 2.287726419218315
Validation loss: 2.4613498564289884

Epoch: 6| Step: 13
Training loss: 2.5979792114495024
Validation loss: 2.4595115122863342

Epoch: 133| Step: 0
Training loss: 2.3617809230685554
Validation loss: 2.4590677171985416

Epoch: 6| Step: 1
Training loss: 2.3915167248695566
Validation loss: 2.458677879262245

Epoch: 6| Step: 2
Training loss: 2.7605676477756447
Validation loss: 2.459507586319689

Epoch: 6| Step: 3
Training loss: 2.629175044881184
Validation loss: 2.452880053429737

Epoch: 6| Step: 4
Training loss: 2.3015962203301403
Validation loss: 2.4562083343518113

Epoch: 6| Step: 5
Training loss: 2.4628916898478566
Validation loss: 2.4541043232078623

Epoch: 6| Step: 6
Training loss: 2.3971477606996188
Validation loss: 2.461075939341434

Epoch: 6| Step: 7
Training loss: 2.5645887654234323
Validation loss: 2.4566582506295314

Epoch: 6| Step: 8
Training loss: 2.3399099808682586
Validation loss: 2.460253326739378

Epoch: 6| Step: 9
Training loss: 3.020006228813165
Validation loss: 2.4509019112831263

Epoch: 6| Step: 10
Training loss: 2.3823338762710327
Validation loss: 2.4565916087547364

Epoch: 6| Step: 11
Training loss: 2.315397148917299
Validation loss: 2.4574234350778905

Epoch: 6| Step: 12
Training loss: 2.573951255781405
Validation loss: 2.452754711543322

Epoch: 6| Step: 13
Training loss: 2.6299537057029396
Validation loss: 2.4519984904487364

Epoch: 134| Step: 0
Training loss: 1.6872489177266858
Validation loss: 2.4554959156403995

Epoch: 6| Step: 1
Training loss: 2.6159454586922837
Validation loss: 2.4571261809608

Epoch: 6| Step: 2
Training loss: 2.264565266031476
Validation loss: 2.460914304916628

Epoch: 6| Step: 3
Training loss: 2.955478598214989
Validation loss: 2.4615823052357664

Epoch: 6| Step: 4
Training loss: 2.282247560377569
Validation loss: 2.4583607418881543

Epoch: 6| Step: 5
Training loss: 2.9034223028566797
Validation loss: 2.4639417284499032

Epoch: 6| Step: 6
Training loss: 2.1626507392340697
Validation loss: 2.4556909573691588

Epoch: 6| Step: 7
Training loss: 2.4461422813374685
Validation loss: 2.461060003228852

Epoch: 6| Step: 8
Training loss: 2.355480390175167
Validation loss: 2.4500605400546456

Epoch: 6| Step: 9
Training loss: 2.8335768277126006
Validation loss: 2.4491335394160147

Epoch: 6| Step: 10
Training loss: 2.625610825451113
Validation loss: 2.4588341175940776

Epoch: 6| Step: 11
Training loss: 2.545492721556203
Validation loss: 2.4566938919679226

Epoch: 6| Step: 12
Training loss: 2.362914607083517
Validation loss: 2.4628642779359566

Epoch: 6| Step: 13
Training loss: 2.7848228907813906
Validation loss: 2.454990892218576

Epoch: 135| Step: 0
Training loss: 2.7390543109011927
Validation loss: 2.4542915664349105

Epoch: 6| Step: 1
Training loss: 2.502593602460197
Validation loss: 2.455467612023231

Epoch: 6| Step: 2
Training loss: 1.4852562145802382
Validation loss: 2.458845769416311

Epoch: 6| Step: 3
Training loss: 2.2796201762663824
Validation loss: 2.456024602525005

Epoch: 6| Step: 4
Training loss: 2.7557186142128143
Validation loss: 2.4611819029855426

Epoch: 6| Step: 5
Training loss: 2.308891780611997
Validation loss: 2.4622595490537615

Epoch: 6| Step: 6
Training loss: 2.504770686147845
Validation loss: 2.459343352512058

Epoch: 6| Step: 7
Training loss: 3.0458174997762684
Validation loss: 2.4593946515097564

Epoch: 6| Step: 8
Training loss: 2.7674232283422184
Validation loss: 2.452761912759594

Epoch: 6| Step: 9
Training loss: 2.55558177916115
Validation loss: 2.4552724230794065

Epoch: 6| Step: 10
Training loss: 2.579538408727346
Validation loss: 2.45841532640522

Epoch: 6| Step: 11
Training loss: 2.0185494904988737
Validation loss: 2.461370827605575

Epoch: 6| Step: 12
Training loss: 2.1116858363717843
Validation loss: 2.458615389230584

Epoch: 6| Step: 13
Training loss: 2.9146796588009005
Validation loss: 2.4586795035131948

Epoch: 136| Step: 0
Training loss: 2.425673625235541
Validation loss: 2.457660798574617

Epoch: 6| Step: 1
Training loss: 2.949434264942233
Validation loss: 2.4581625658196304

Epoch: 6| Step: 2
Training loss: 2.2689669460681556
Validation loss: 2.4594720180688117

Epoch: 6| Step: 3
Training loss: 1.9816036546515596
Validation loss: 2.4654998752382764

Epoch: 6| Step: 4
Training loss: 2.9335495377826843
Validation loss: 2.462051672231324

Epoch: 6| Step: 5
Training loss: 3.2073605701709624
Validation loss: 2.459935075967961

Epoch: 6| Step: 6
Training loss: 2.176452642709469
Validation loss: 2.454858479250358

Epoch: 6| Step: 7
Training loss: 2.4337029838233053
Validation loss: 2.4580854247788984

Epoch: 6| Step: 8
Training loss: 2.1913167081820606
Validation loss: 2.452923128605422

Epoch: 6| Step: 9
Training loss: 2.6415573370258163
Validation loss: 2.4568146982671695

Epoch: 6| Step: 10
Training loss: 2.7900130845176667
Validation loss: 2.4565442547219476

Epoch: 6| Step: 11
Training loss: 2.3048097739677447
Validation loss: 2.4652577579980863

Epoch: 6| Step: 12
Training loss: 2.3111955211071797
Validation loss: 2.456496026269168

Epoch: 6| Step: 13
Training loss: 1.8727259515133108
Validation loss: 2.460782565936581

Epoch: 137| Step: 0
Training loss: 2.3222915994460442
Validation loss: 2.4606657332269837

Epoch: 6| Step: 1
Training loss: 2.638619648990467
Validation loss: 2.4715040434132147

Epoch: 6| Step: 2
Training loss: 2.5844884771413787
Validation loss: 2.465611938132534

Epoch: 6| Step: 3
Training loss: 2.7977963427142396
Validation loss: 2.4676479181376747

Epoch: 6| Step: 4
Training loss: 2.8295867682926557
Validation loss: 2.4626212117656343

Epoch: 6| Step: 5
Training loss: 2.242832529680954
Validation loss: 2.466127636582869

Epoch: 6| Step: 6
Training loss: 2.4996822155203784
Validation loss: 2.4543034017280685

Epoch: 6| Step: 7
Training loss: 2.9533933487327535
Validation loss: 2.4636536156755082

Epoch: 6| Step: 8
Training loss: 2.0665024733179016
Validation loss: 2.464192009559979

Epoch: 6| Step: 9
Training loss: 2.076270286833002
Validation loss: 2.464443111757083

Epoch: 6| Step: 10
Training loss: 2.389374449518067
Validation loss: 2.466578852748596

Epoch: 6| Step: 11
Training loss: 2.4573691034237055
Validation loss: 2.472151155795748

Epoch: 6| Step: 12
Training loss: 2.1067876701169452
Validation loss: 2.4678250765181122

Epoch: 6| Step: 13
Training loss: 2.8075872960365316
Validation loss: 2.460547942154112

Epoch: 138| Step: 0
Training loss: 2.6727821639351026
Validation loss: 2.4595780669689153

Epoch: 6| Step: 1
Training loss: 2.7998393455465194
Validation loss: 2.4579957363845932

Epoch: 6| Step: 2
Training loss: 2.3486342336923975
Validation loss: 2.4586689822268117

Epoch: 6| Step: 3
Training loss: 2.9452733206735973
Validation loss: 2.4609741854077805

Epoch: 6| Step: 4
Training loss: 2.0763023242179193
Validation loss: 2.4540950533700485

Epoch: 6| Step: 5
Training loss: 2.3528178466703698
Validation loss: 2.4631992663996596

Epoch: 6| Step: 6
Training loss: 2.608081885538409
Validation loss: 2.4616078588976626

Epoch: 6| Step: 7
Training loss: 1.6723750427278021
Validation loss: 2.460739515302963

Epoch: 6| Step: 8
Training loss: 2.1662571104255464
Validation loss: 2.4624070881002282

Epoch: 6| Step: 9
Training loss: 2.326373676863955
Validation loss: 2.4590020697989483

Epoch: 6| Step: 10
Training loss: 2.346405559376355
Validation loss: 2.4643793489767862

Epoch: 6| Step: 11
Training loss: 2.1317502684773655
Validation loss: 2.461146891733055

Epoch: 6| Step: 12
Training loss: 2.9683297913958753
Validation loss: 2.449814321981602

Epoch: 6| Step: 13
Training loss: 3.2142383844433207
Validation loss: 2.450240170131676

Epoch: 139| Step: 0
Training loss: 2.36657223401145
Validation loss: 2.4524651225050436

Epoch: 6| Step: 1
Training loss: 2.6690508098947014
Validation loss: 2.455387570411439

Epoch: 6| Step: 2
Training loss: 2.936449228204741
Validation loss: 2.4662084897120486

Epoch: 6| Step: 3
Training loss: 2.707598209871818
Validation loss: 2.460949787734907

Epoch: 6| Step: 4
Training loss: 2.604897866910273
Validation loss: 2.4606607836607615

Epoch: 6| Step: 5
Training loss: 1.80150439126493
Validation loss: 2.4620331116677545

Epoch: 6| Step: 6
Training loss: 2.4044292546758297
Validation loss: 2.4593271789684037

Epoch: 6| Step: 7
Training loss: 2.483377124306399
Validation loss: 2.4636071474003742

Epoch: 6| Step: 8
Training loss: 2.7748272919393653
Validation loss: 2.458326627970026

Epoch: 6| Step: 9
Training loss: 2.263393381677106
Validation loss: 2.462217823391683

Epoch: 6| Step: 10
Training loss: 2.851503638091117
Validation loss: 2.461450254922386

Epoch: 6| Step: 11
Training loss: 1.7773151772686142
Validation loss: 2.4623604429947457

Epoch: 6| Step: 12
Training loss: 2.2265395849286835
Validation loss: 2.4660455239562737

Epoch: 6| Step: 13
Training loss: 2.7665333091430773
Validation loss: 2.463097245263994

Epoch: 140| Step: 0
Training loss: 2.2109848394818767
Validation loss: 2.452832546741093

Epoch: 6| Step: 1
Training loss: 2.7753744749046296
Validation loss: 2.453587247542753

Epoch: 6| Step: 2
Training loss: 2.4062983520405785
Validation loss: 2.460325990621562

Epoch: 6| Step: 3
Training loss: 3.1977149493852597
Validation loss: 2.4537539799522423

Epoch: 6| Step: 4
Training loss: 1.9601931432032123
Validation loss: 2.454689822650137

Epoch: 6| Step: 5
Training loss: 2.237361805660021
Validation loss: 2.4600164395328354

Epoch: 6| Step: 6
Training loss: 2.8066622017155134
Validation loss: 2.4551817579507587

Epoch: 6| Step: 7
Training loss: 1.754797762007598
Validation loss: 2.4600017241857013

Epoch: 6| Step: 8
Training loss: 3.161664793677237
Validation loss: 2.459418579904611

Epoch: 6| Step: 9
Training loss: 2.771649625232246
Validation loss: 2.462828467742099

Epoch: 6| Step: 10
Training loss: 2.685547585227179
Validation loss: 2.462849498932794

Epoch: 6| Step: 11
Training loss: 2.238920483341268
Validation loss: 2.4664985917367863

Epoch: 6| Step: 12
Training loss: 1.9789519210225888
Validation loss: 2.464419530443147

Epoch: 6| Step: 13
Training loss: 2.3576763176947244
Validation loss: 2.466860486698168

Epoch: 141| Step: 0
Training loss: 2.076150515456331
Validation loss: 2.4610812513560303

Epoch: 6| Step: 1
Training loss: 2.0468300384941425
Validation loss: 2.463495658676093

Epoch: 6| Step: 2
Training loss: 2.315887856332934
Validation loss: 2.470152717970829

Epoch: 6| Step: 3
Training loss: 2.528706532518176
Validation loss: 2.460912472229298

Epoch: 6| Step: 4
Training loss: 2.8649103336383144
Validation loss: 2.4607480899640994

Epoch: 6| Step: 5
Training loss: 2.589622982966573
Validation loss: 2.4603689838884923

Epoch: 6| Step: 6
Training loss: 3.4229146693094794
Validation loss: 2.46375785561878

Epoch: 6| Step: 7
Training loss: 2.477374692763928
Validation loss: 2.4644112104180214

Epoch: 6| Step: 8
Training loss: 2.1540872535849447
Validation loss: 2.464714873139207

Epoch: 6| Step: 9
Training loss: 2.58920938539046
Validation loss: 2.4634924326541006

Epoch: 6| Step: 10
Training loss: 2.24617293508516
Validation loss: 2.4607937483204005

Epoch: 6| Step: 11
Training loss: 2.4075832884138015
Validation loss: 2.460736624779575

Epoch: 6| Step: 12
Training loss: 2.715933118752354
Validation loss: 2.4558571990784026

Epoch: 6| Step: 13
Training loss: 2.1095603578860818
Validation loss: 2.46113958588664

Epoch: 142| Step: 0
Training loss: 2.184474051089372
Validation loss: 2.4602100407217633

Epoch: 6| Step: 1
Training loss: 2.8166160135022116
Validation loss: 2.463596485864101

Epoch: 6| Step: 2
Training loss: 3.197818286554638
Validation loss: 2.463183634403

Epoch: 6| Step: 3
Training loss: 2.64325325990918
Validation loss: 2.4696341432309254

Epoch: 6| Step: 4
Training loss: 2.1324124921797374
Validation loss: 2.4700145782267002

Epoch: 6| Step: 5
Training loss: 2.2629920129436987
Validation loss: 2.454303094108312

Epoch: 6| Step: 6
Training loss: 2.3111036053967657
Validation loss: 2.466607947123174

Epoch: 6| Step: 7
Training loss: 2.925356825232033
Validation loss: 2.463305267755686

Epoch: 6| Step: 8
Training loss: 2.9761530076347746
Validation loss: 2.4573821932579705

Epoch: 6| Step: 9
Training loss: 2.1535494935437582
Validation loss: 2.4623029442832918

Epoch: 6| Step: 10
Training loss: 2.617105511192445
Validation loss: 2.4697496989554053

Epoch: 6| Step: 11
Training loss: 1.9282092405245186
Validation loss: 2.4704936264137047

Epoch: 6| Step: 12
Training loss: 2.099972488586416
Validation loss: 2.4650179987283187

Epoch: 6| Step: 13
Training loss: 2.3730179396384057
Validation loss: 2.4675915088323817

Epoch: 143| Step: 0
Training loss: 2.628293196912545
Validation loss: 2.4659943794275128

Epoch: 6| Step: 1
Training loss: 2.237744758048346
Validation loss: 2.4648982393153376

Epoch: 6| Step: 2
Training loss: 2.0220006605952814
Validation loss: 2.468937846574021

Epoch: 6| Step: 3
Training loss: 2.737059577803576
Validation loss: 2.464339182979838

Epoch: 6| Step: 4
Training loss: 2.461593298347086
Validation loss: 2.4620493481336365

Epoch: 6| Step: 5
Training loss: 2.488081176954489
Validation loss: 2.4623827611056424

Epoch: 6| Step: 6
Training loss: 2.679372162796273
Validation loss: 2.4711859873287834

Epoch: 6| Step: 7
Training loss: 2.9746818308230725
Validation loss: 2.4677778011756946

Epoch: 6| Step: 8
Training loss: 2.520794030085413
Validation loss: 2.4704925568002762

Epoch: 6| Step: 9
Training loss: 2.450562906799306
Validation loss: 2.4712759045079484

Epoch: 6| Step: 10
Training loss: 2.5118120570671834
Validation loss: 2.4662228618919735

Epoch: 6| Step: 11
Training loss: 2.30433098573297
Validation loss: 2.4579902317902143

Epoch: 6| Step: 12
Training loss: 2.4318889690263656
Validation loss: 2.4633405628881158

Epoch: 6| Step: 13
Training loss: 2.378268753098121
Validation loss: 2.448861306454974

Epoch: 144| Step: 0
Training loss: 1.7741779680490881
Validation loss: 2.446824220964357

Epoch: 6| Step: 1
Training loss: 2.909998619367659
Validation loss: 2.4476568178820934

Epoch: 6| Step: 2
Training loss: 1.7342398650989679
Validation loss: 2.4556149685069726

Epoch: 6| Step: 3
Training loss: 2.1435137560158095
Validation loss: 2.4528683570686716

Epoch: 6| Step: 4
Training loss: 2.1864058891889844
Validation loss: 2.4520095751442157

Epoch: 6| Step: 5
Training loss: 2.6983418565332373
Validation loss: 2.457022112499363

Epoch: 6| Step: 6
Training loss: 2.2736808934963673
Validation loss: 2.45253579743858

Epoch: 6| Step: 7
Training loss: 2.991668417105698
Validation loss: 2.4538751495958753

Epoch: 6| Step: 8
Training loss: 2.5855329029923513
Validation loss: 2.4639987534957473

Epoch: 6| Step: 9
Training loss: 2.488466360731286
Validation loss: 2.468706766385762

Epoch: 6| Step: 10
Training loss: 2.409552351662107
Validation loss: 2.4704208514334196

Epoch: 6| Step: 11
Training loss: 3.0575590173822302
Validation loss: 2.4604051851870885

Epoch: 6| Step: 12
Training loss: 2.596315884220234
Validation loss: 2.463259389780119

Epoch: 6| Step: 13
Training loss: 2.5651571871833694
Validation loss: 2.4574652017203875

Epoch: 145| Step: 0
Training loss: 2.0514764679115323
Validation loss: 2.4653556763664817

Epoch: 6| Step: 1
Training loss: 2.3745323523837465
Validation loss: 2.4723126824100983

Epoch: 6| Step: 2
Training loss: 2.730451548335256
Validation loss: 2.4705509425402017

Epoch: 6| Step: 3
Training loss: 2.6507941369671824
Validation loss: 2.4648323199878193

Epoch: 6| Step: 4
Training loss: 1.5547802001306756
Validation loss: 2.4700077812365695

Epoch: 6| Step: 5
Training loss: 2.558458164495538
Validation loss: 2.4627574831222505

Epoch: 6| Step: 6
Training loss: 2.3503177428012716
Validation loss: 2.461609917061667

Epoch: 6| Step: 7
Training loss: 2.7855852607218785
Validation loss: 2.4661032254419846

Epoch: 6| Step: 8
Training loss: 2.0450629447073116
Validation loss: 2.455321848892268

Epoch: 6| Step: 9
Training loss: 2.990530327042829
Validation loss: 2.4700226380653145

Epoch: 6| Step: 10
Training loss: 2.8351620961830912
Validation loss: 2.4601913693536863

Epoch: 6| Step: 11
Training loss: 2.2600192469224596
Validation loss: 2.4577643549609887

Epoch: 6| Step: 12
Training loss: 2.707034772950449
Validation loss: 2.460674695711447

Epoch: 6| Step: 13
Training loss: 2.5477611661690087
Validation loss: 2.467509863620202

Epoch: 146| Step: 0
Training loss: 1.9292477867367852
Validation loss: 2.4608401163199116

Epoch: 6| Step: 1
Training loss: 2.6068842530069185
Validation loss: 2.4642624852301283

Epoch: 6| Step: 2
Training loss: 2.60102458352949
Validation loss: 2.472238562621598

Epoch: 6| Step: 3
Training loss: 2.5834295090851356
Validation loss: 2.469781056712087

Epoch: 6| Step: 4
Training loss: 2.8676945292598672
Validation loss: 2.466236380043066

Epoch: 6| Step: 5
Training loss: 2.7967929934621205
Validation loss: 2.465645636990706

Epoch: 6| Step: 6
Training loss: 2.4137051512286813
Validation loss: 2.4615185894225116

Epoch: 6| Step: 7
Training loss: 2.452185578484656
Validation loss: 2.453028164711875

Epoch: 6| Step: 8
Training loss: 2.4184469264786124
Validation loss: 2.4564259667494257

Epoch: 6| Step: 9
Training loss: 2.4578652232554323
Validation loss: 2.461991285328299

Epoch: 6| Step: 10
Training loss: 1.710191956169547
Validation loss: 2.458133306824691

Epoch: 6| Step: 11
Training loss: 3.000063100786984
Validation loss: 2.4710325159732625

Epoch: 6| Step: 12
Training loss: 2.0666178430922364
Validation loss: 2.462775473508133

Epoch: 6| Step: 13
Training loss: 2.651783947304141
Validation loss: 2.4553614745989485

Epoch: 147| Step: 0
Training loss: 2.695554683695994
Validation loss: 2.4558341501772007

Epoch: 6| Step: 1
Training loss: 1.9454088302109143
Validation loss: 2.4598870189949555

Epoch: 6| Step: 2
Training loss: 2.1632423361560176
Validation loss: 2.4588230636645267

Epoch: 6| Step: 3
Training loss: 2.9306111825140113
Validation loss: 2.4659484467404233

Epoch: 6| Step: 4
Training loss: 2.5417195194773434
Validation loss: 2.4600243867528593

Epoch: 6| Step: 5
Training loss: 1.834880768231077
Validation loss: 2.471853888381717

Epoch: 6| Step: 6
Training loss: 2.4823605029355473
Validation loss: 2.4787273071091596

Epoch: 6| Step: 7
Training loss: 2.1933391566716183
Validation loss: 2.47355767201321

Epoch: 6| Step: 8
Training loss: 2.5820398373828928
Validation loss: 2.461627843193817

Epoch: 6| Step: 9
Training loss: 2.6699592012867246
Validation loss: 2.4676969350538425

Epoch: 6| Step: 10
Training loss: 2.8694663489376464
Validation loss: 2.460585715364875

Epoch: 6| Step: 11
Training loss: 2.614774314521494
Validation loss: 2.4594970281848867

Epoch: 6| Step: 12
Training loss: 2.7177440492313782
Validation loss: 2.466247287960788

Epoch: 6| Step: 13
Training loss: 2.258822838728229
Validation loss: 2.4573019795338156

Epoch: 148| Step: 0
Training loss: 2.280310345826838
Validation loss: 2.4597911768569474

Epoch: 6| Step: 1
Training loss: 2.339511446529203
Validation loss: 2.4615346678527303

Epoch: 6| Step: 2
Training loss: 3.1573120445433727
Validation loss: 2.4641529370638082

Epoch: 6| Step: 3
Training loss: 2.299121303223746
Validation loss: 2.466999254057253

Epoch: 6| Step: 4
Training loss: 1.935405029272838
Validation loss: 2.4519460967581383

Epoch: 6| Step: 5
Training loss: 2.337661770205408
Validation loss: 2.4643403439491944

Epoch: 6| Step: 6
Training loss: 2.196784343992375
Validation loss: 2.4555677655531634

Epoch: 6| Step: 7
Training loss: 3.0400307493160508
Validation loss: 2.470283386200462

Epoch: 6| Step: 8
Training loss: 2.215566473485144
Validation loss: 2.4660683887947403

Epoch: 6| Step: 9
Training loss: 2.3893141799198805
Validation loss: 2.4690779295146594

Epoch: 6| Step: 10
Training loss: 2.1084274989674414
Validation loss: 2.480488454184779

Epoch: 6| Step: 11
Training loss: 2.5765739630356834
Validation loss: 2.488401480923496

Epoch: 6| Step: 12
Training loss: 2.9587068635336773
Validation loss: 2.4803818735042404

Epoch: 6| Step: 13
Training loss: 2.6432042814439454
Validation loss: 2.4708813830416236

Epoch: 149| Step: 0
Training loss: 2.58243214875386
Validation loss: 2.459027698752293

Epoch: 6| Step: 1
Training loss: 2.1193091540849767
Validation loss: 2.46341269211273

Epoch: 6| Step: 2
Training loss: 2.0827128312802383
Validation loss: 2.4714113208096253

Epoch: 6| Step: 3
Training loss: 2.222652281102289
Validation loss: 2.4701408138368337

Epoch: 6| Step: 4
Training loss: 2.397571916983291
Validation loss: 2.465654516909658

Epoch: 6| Step: 5
Training loss: 2.700263123583417
Validation loss: 2.4673522018079463

Epoch: 6| Step: 6
Training loss: 2.366919776204877
Validation loss: 2.469176002156066

Epoch: 6| Step: 7
Training loss: 2.179892253487866
Validation loss: 2.4759100888001297

Epoch: 6| Step: 8
Training loss: 2.4921381356543253
Validation loss: 2.4796338215566363

Epoch: 6| Step: 9
Training loss: 3.505250806773146
Validation loss: 2.475279017175696

Epoch: 6| Step: 10
Training loss: 2.055686330787939
Validation loss: 2.470660311562932

Epoch: 6| Step: 11
Training loss: 2.2872100729726847
Validation loss: 2.461605461739771

Epoch: 6| Step: 12
Training loss: 2.6316060094947695
Validation loss: 2.4526402344761697

Epoch: 6| Step: 13
Training loss: 2.814822784862426
Validation loss: 2.4567551692754153

Epoch: 150| Step: 0
Training loss: 2.8645000283815074
Validation loss: 2.4519920081474575

Epoch: 6| Step: 1
Training loss: 2.731296397498142
Validation loss: 2.460758901099726

Epoch: 6| Step: 2
Training loss: 2.278443687555086
Validation loss: 2.4676144640164464

Epoch: 6| Step: 3
Training loss: 2.4386404255115113
Validation loss: 2.4578885036971156

Epoch: 6| Step: 4
Training loss: 2.1479775786126485
Validation loss: 2.4605477402863145

Epoch: 6| Step: 5
Training loss: 1.682541095520836
Validation loss: 2.4591991764023793

Epoch: 6| Step: 6
Training loss: 2.8102572505936463
Validation loss: 2.4585140021794785

Epoch: 6| Step: 7
Training loss: 2.8084698942885686
Validation loss: 2.4650734836182173

Epoch: 6| Step: 8
Training loss: 2.4612155333392263
Validation loss: 2.468561463057853

Epoch: 6| Step: 9
Training loss: 2.3263862824939405
Validation loss: 2.474596464609673

Epoch: 6| Step: 10
Training loss: 2.5673815123974455
Validation loss: 2.471356299787645

Epoch: 6| Step: 11
Training loss: 2.5060888528743304
Validation loss: 2.47140095019636

Epoch: 6| Step: 12
Training loss: 2.23939249571115
Validation loss: 2.4676523142411897

Epoch: 6| Step: 13
Training loss: 2.655808984385313
Validation loss: 2.4637908701971964

Testing loss: 1.9872377370428165
