Epoch: 1| Step: 0
Training loss: 6.391921977382187
Validation loss: 5.853742925799984

Epoch: 6| Step: 1
Training loss: 5.974077812758269
Validation loss: 5.851782977538983

Epoch: 6| Step: 2
Training loss: 6.342036574908763
Validation loss: 5.849958552243591

Epoch: 6| Step: 3
Training loss: 6.22341330042527
Validation loss: 5.847944362544446

Epoch: 6| Step: 4
Training loss: 6.212329099211829
Validation loss: 5.84600800053661

Epoch: 6| Step: 5
Training loss: 6.263274477278988
Validation loss: 5.844113044545351

Epoch: 6| Step: 6
Training loss: 5.511198088171521
Validation loss: 5.842108647291404

Epoch: 6| Step: 7
Training loss: 4.661693693502504
Validation loss: 5.840238934162323

Epoch: 6| Step: 8
Training loss: 5.032229120930118
Validation loss: 5.838144479990049

Epoch: 6| Step: 9
Training loss: 5.718925431692716
Validation loss: 5.835995048705614

Epoch: 6| Step: 10
Training loss: 5.470814691159788
Validation loss: 5.833846187753542

Epoch: 6| Step: 11
Training loss: 6.8574485767423745
Validation loss: 5.831526785356968

Epoch: 6| Step: 12
Training loss: 6.211024714403388
Validation loss: 5.829215512765221

Epoch: 6| Step: 13
Training loss: 6.167554361871537
Validation loss: 5.8267197129186705

Epoch: 2| Step: 0
Training loss: 5.800205805843161
Validation loss: 5.82417464841899

Epoch: 6| Step: 1
Training loss: 5.903362234264921
Validation loss: 5.821476448301292

Epoch: 6| Step: 2
Training loss: 6.157342339439849
Validation loss: 5.818652052282016

Epoch: 6| Step: 3
Training loss: 5.47263185330929
Validation loss: 5.815718685969107

Epoch: 6| Step: 4
Training loss: 5.4301599530288716
Validation loss: 5.81264287848202

Epoch: 6| Step: 5
Training loss: 5.341551211215803
Validation loss: 5.809542214441143

Epoch: 6| Step: 6
Training loss: 5.804373033099531
Validation loss: 5.8061731011068805

Epoch: 6| Step: 7
Training loss: 6.120813301249271
Validation loss: 5.802684631784996

Epoch: 6| Step: 8
Training loss: 5.574920503194943
Validation loss: 5.799177317535769

Epoch: 6| Step: 9
Training loss: 5.855186328350044
Validation loss: 5.795240529959867

Epoch: 6| Step: 10
Training loss: 6.698426349364553
Validation loss: 5.791131834222567

Epoch: 6| Step: 11
Training loss: 6.3880798196123285
Validation loss: 5.787019809386431

Epoch: 6| Step: 12
Training loss: 5.927742097400242
Validation loss: 5.7822223567319195

Epoch: 6| Step: 13
Training loss: 6.225794803481608
Validation loss: 5.777591764479805

Epoch: 3| Step: 0
Training loss: 5.384445939175118
Validation loss: 5.772409033462653

Epoch: 6| Step: 1
Training loss: 5.201439570185827
Validation loss: 5.767113993867093

Epoch: 6| Step: 2
Training loss: 6.1344668349913976
Validation loss: 5.761737150173656

Epoch: 6| Step: 3
Training loss: 5.831986771431193
Validation loss: 5.7561110212935604

Epoch: 6| Step: 4
Training loss: 5.726198442448089
Validation loss: 5.74984635963285

Epoch: 6| Step: 5
Training loss: 6.0929636912563945
Validation loss: 5.743915545236731

Epoch: 6| Step: 6
Training loss: 5.514607192409289
Validation loss: 5.737231881186981

Epoch: 6| Step: 7
Training loss: 6.094369084137537
Validation loss: 5.7304954051459855

Epoch: 6| Step: 8
Training loss: 4.992836398127012
Validation loss: 5.723408592512837

Epoch: 6| Step: 9
Training loss: 5.822613521139174
Validation loss: 5.716449323402136

Epoch: 6| Step: 10
Training loss: 7.044365480437018
Validation loss: 5.7090056457366885

Epoch: 6| Step: 11
Training loss: 6.828827217359565
Validation loss: 5.701282750622278

Epoch: 6| Step: 12
Training loss: 5.901557471101743
Validation loss: 5.6931105945949465

Epoch: 6| Step: 13
Training loss: 4.868775526574811
Validation loss: 5.685224056743799

Epoch: 4| Step: 0
Training loss: 5.2859837010479085
Validation loss: 5.67698093520276

Epoch: 6| Step: 1
Training loss: 5.527589955592137
Validation loss: 5.66863315718415

Epoch: 6| Step: 2
Training loss: 6.390516956413999
Validation loss: 5.6603746075893415

Epoch: 6| Step: 3
Training loss: 5.527253339587436
Validation loss: 5.651440678117505

Epoch: 6| Step: 4
Training loss: 5.679778842112825
Validation loss: 5.642627786708523

Epoch: 6| Step: 5
Training loss: 6.220357869147375
Validation loss: 5.63364424364809

Epoch: 6| Step: 6
Training loss: 5.221841775730256
Validation loss: 5.624427540224227

Epoch: 6| Step: 7
Training loss: 5.523764507536215
Validation loss: 5.615358213081905

Epoch: 6| Step: 8
Training loss: 5.70479227020506
Validation loss: 5.605779715850053

Epoch: 6| Step: 9
Training loss: 5.847357793924194
Validation loss: 5.596217117536749

Epoch: 6| Step: 10
Training loss: 5.973204543280695
Validation loss: 5.586362197487897

Epoch: 6| Step: 11
Training loss: 5.5732821430854855
Validation loss: 5.576239772189521

Epoch: 6| Step: 12
Training loss: 6.514986807399224
Validation loss: 5.565823851339952

Epoch: 6| Step: 13
Training loss: 5.097448024662512
Validation loss: 5.555289520675646

Epoch: 5| Step: 0
Training loss: 6.407162485033382
Validation loss: 5.545033954393718

Epoch: 6| Step: 1
Training loss: 5.722666248924712
Validation loss: 5.533986249955566

Epoch: 6| Step: 2
Training loss: 4.798039496910797
Validation loss: 5.523245211450617

Epoch: 6| Step: 3
Training loss: 5.7880667423388905
Validation loss: 5.512304875502321

Epoch: 6| Step: 4
Training loss: 5.99053717495612
Validation loss: 5.501301553639644

Epoch: 6| Step: 5
Training loss: 6.3376850770790485
Validation loss: 5.489588216915769

Epoch: 6| Step: 6
Training loss: 5.5428615610782055
Validation loss: 5.478900346943636

Epoch: 6| Step: 7
Training loss: 5.8259865772578525
Validation loss: 5.466857001239854

Epoch: 6| Step: 8
Training loss: 4.606228650068186
Validation loss: 5.455142430428279

Epoch: 6| Step: 9
Training loss: 5.491385910120249
Validation loss: 5.443824291050797

Epoch: 6| Step: 10
Training loss: 6.137344687802253
Validation loss: 5.43219548033877

Epoch: 6| Step: 11
Training loss: 4.766745913898287
Validation loss: 5.421166687943061

Epoch: 6| Step: 12
Training loss: 5.894606967083278
Validation loss: 5.410232811488206

Epoch: 6| Step: 13
Training loss: 4.52704188185544
Validation loss: 5.398616259679598

Epoch: 6| Step: 0
Training loss: 5.58797322771872
Validation loss: 5.387274012948327

Epoch: 6| Step: 1
Training loss: 5.832812186076874
Validation loss: 5.376548100579426

Epoch: 6| Step: 2
Training loss: 5.584525744896352
Validation loss: 5.365402020942496

Epoch: 6| Step: 3
Training loss: 6.071916640723465
Validation loss: 5.354536239198846

Epoch: 6| Step: 4
Training loss: 5.162089053001051
Validation loss: 5.34363521579062

Epoch: 6| Step: 5
Training loss: 5.75039737820998
Validation loss: 5.333410630063363

Epoch: 6| Step: 6
Training loss: 6.551601988593581
Validation loss: 5.322633271657905

Epoch: 6| Step: 7
Training loss: 5.523003071449996
Validation loss: 5.311773721753022

Epoch: 6| Step: 8
Training loss: 5.17617001782851
Validation loss: 5.301555444885291

Epoch: 6| Step: 9
Training loss: 4.5956680549421565
Validation loss: 5.291069637871071

Epoch: 6| Step: 10
Training loss: 4.483660172433914
Validation loss: 5.281546198798292

Epoch: 6| Step: 11
Training loss: 4.082863813122342
Validation loss: 5.27215880161663

Epoch: 6| Step: 12
Training loss: 5.7595679248242275
Validation loss: 5.262303331918134

Epoch: 6| Step: 13
Training loss: 5.5157451670581015
Validation loss: 5.252867626970802

Epoch: 7| Step: 0
Training loss: 4.718377307043291
Validation loss: 5.2438268244393305

Epoch: 6| Step: 1
Training loss: 4.995489374727723
Validation loss: 5.234688547337088

Epoch: 6| Step: 2
Training loss: 5.484846741474717
Validation loss: 5.226021640316714

Epoch: 6| Step: 3
Training loss: 3.9581334649204347
Validation loss: 5.216921335571131

Epoch: 6| Step: 4
Training loss: 5.289704366979223
Validation loss: 5.208595462560575

Epoch: 6| Step: 5
Training loss: 4.952036259606252
Validation loss: 5.2000683119761755

Epoch: 6| Step: 6
Training loss: 6.130569106002849
Validation loss: 5.191862975563118

Epoch: 6| Step: 7
Training loss: 4.987036876161958
Validation loss: 5.183234548496231

Epoch: 6| Step: 8
Training loss: 5.621389289811498
Validation loss: 5.175003626725405

Epoch: 6| Step: 9
Training loss: 5.666374797410295
Validation loss: 5.166649490245858

Epoch: 6| Step: 10
Training loss: 6.390482035858858
Validation loss: 5.1580961371114675

Epoch: 6| Step: 11
Training loss: 5.370570109417705
Validation loss: 5.149240927941953

Epoch: 6| Step: 12
Training loss: 4.366694605109452
Validation loss: 5.141249258367644

Epoch: 6| Step: 13
Training loss: 5.838228115767513
Validation loss: 5.133120484501272

Epoch: 8| Step: 0
Training loss: 6.354497515293794
Validation loss: 5.124702227866129

Epoch: 6| Step: 1
Training loss: 4.173171852652078
Validation loss: 5.116760857343667

Epoch: 6| Step: 2
Training loss: 5.26448694263411
Validation loss: 5.108403415831863

Epoch: 6| Step: 3
Training loss: 4.8295605941779955
Validation loss: 5.100002297544274

Epoch: 6| Step: 4
Training loss: 5.203560842411072
Validation loss: 5.092096477708311

Epoch: 6| Step: 5
Training loss: 5.407053805005063
Validation loss: 5.084155261186329

Epoch: 6| Step: 6
Training loss: 5.133928848171819
Validation loss: 5.076514418070879

Epoch: 6| Step: 7
Training loss: 4.814383398328753
Validation loss: 5.068453329853304

Epoch: 6| Step: 8
Training loss: 4.841876842950953
Validation loss: 5.061527708271238

Epoch: 6| Step: 9
Training loss: 5.369708628217468
Validation loss: 5.054194352131006

Epoch: 6| Step: 10
Training loss: 4.255888505952389
Validation loss: 5.0470758010395285

Epoch: 6| Step: 11
Training loss: 6.266887585148054
Validation loss: 5.040511584833913

Epoch: 6| Step: 12
Training loss: 4.741406748820825
Validation loss: 5.033502189170174

Epoch: 6| Step: 13
Training loss: 5.605569127476703
Validation loss: 5.026028405470146

Epoch: 9| Step: 0
Training loss: 4.548703170245983
Validation loss: 5.018842875063495

Epoch: 6| Step: 1
Training loss: 5.811680233480716
Validation loss: 5.011654178226204

Epoch: 6| Step: 2
Training loss: 5.158724474315749
Validation loss: 5.005169897762181

Epoch: 6| Step: 3
Training loss: 5.768894498757363
Validation loss: 4.99844262982513

Epoch: 6| Step: 4
Training loss: 5.149890283693628
Validation loss: 4.991069383927071

Epoch: 6| Step: 5
Training loss: 5.109203837382955
Validation loss: 4.984258987208694

Epoch: 6| Step: 6
Training loss: 4.183576881239334
Validation loss: 4.977827980198961

Epoch: 6| Step: 7
Training loss: 4.958332970028819
Validation loss: 4.971687712020058

Epoch: 6| Step: 8
Training loss: 5.869116251509291
Validation loss: 4.965143778429636

Epoch: 6| Step: 9
Training loss: 4.772806928225894
Validation loss: 4.9578336682986315

Epoch: 6| Step: 10
Training loss: 5.501763841259477
Validation loss: 4.951317939886063

Epoch: 6| Step: 11
Training loss: 5.071852345865534
Validation loss: 4.944862927837508

Epoch: 6| Step: 12
Training loss: 4.420131380018695
Validation loss: 4.938558601822937

Epoch: 6| Step: 13
Training loss: 4.751141059748585
Validation loss: 4.932480848390883

Epoch: 10| Step: 0
Training loss: 4.996075615987907
Validation loss: 4.926219592958447

Epoch: 6| Step: 1
Training loss: 5.724260853856858
Validation loss: 4.919513761689113

Epoch: 6| Step: 2
Training loss: 5.046895785923721
Validation loss: 4.913382365388836

Epoch: 6| Step: 3
Training loss: 4.475332467286539
Validation loss: 4.906917907218871

Epoch: 6| Step: 4
Training loss: 4.738775543570696
Validation loss: 4.901189863320364

Epoch: 6| Step: 5
Training loss: 4.733791806399285
Validation loss: 4.895199262533201

Epoch: 6| Step: 6
Training loss: 4.494916375626687
Validation loss: 4.88860109353931

Epoch: 6| Step: 7
Training loss: 5.170710591046207
Validation loss: 4.8820716560373665

Epoch: 6| Step: 8
Training loss: 4.393192070256218
Validation loss: 4.875383639116042

Epoch: 6| Step: 9
Training loss: 5.918317143725968
Validation loss: 4.869740999607605

Epoch: 6| Step: 10
Training loss: 5.410028625525368
Validation loss: 4.863140940652943

Epoch: 6| Step: 11
Training loss: 5.25642310910923
Validation loss: 4.856859854392837

Epoch: 6| Step: 12
Training loss: 5.323907071994258
Validation loss: 4.850912364863552

Epoch: 6| Step: 13
Training loss: 4.115556020890007
Validation loss: 4.844593770358307

Epoch: 11| Step: 0
Training loss: 5.500691630485778
Validation loss: 4.838808948154821

Epoch: 6| Step: 1
Training loss: 4.587251595156475
Validation loss: 4.832220683885684

Epoch: 6| Step: 2
Training loss: 5.2554256922292195
Validation loss: 4.826368150125249

Epoch: 6| Step: 3
Training loss: 4.8146068370492445
Validation loss: 4.819908285890865

Epoch: 6| Step: 4
Training loss: 4.558594168407222
Validation loss: 4.814044522890877

Epoch: 6| Step: 5
Training loss: 5.541900381260514
Validation loss: 4.807915638455941

Epoch: 6| Step: 6
Training loss: 4.965219262881671
Validation loss: 4.802248716781927

Epoch: 6| Step: 7
Training loss: 5.768204440256917
Validation loss: 4.7967357801681

Epoch: 6| Step: 8
Training loss: 4.00260030150201
Validation loss: 4.790276212327322

Epoch: 6| Step: 9
Training loss: 4.580078541444544
Validation loss: 4.784758134746209

Epoch: 6| Step: 10
Training loss: 4.2240081796711415
Validation loss: 4.778888459936712

Epoch: 6| Step: 11
Training loss: 5.301015130479653
Validation loss: 4.77340756504227

Epoch: 6| Step: 12
Training loss: 4.851954838956907
Validation loss: 4.767282700023074

Epoch: 6| Step: 13
Training loss: 4.679267877224095
Validation loss: 4.762297889512606

Epoch: 12| Step: 0
Training loss: 4.404166953460674
Validation loss: 4.756653960455373

Epoch: 6| Step: 1
Training loss: 4.610245341228951
Validation loss: 4.751322645785984

Epoch: 6| Step: 2
Training loss: 4.403042538955707
Validation loss: 4.745477263255513

Epoch: 6| Step: 3
Training loss: 4.506665062273933
Validation loss: 4.7400086376256345

Epoch: 6| Step: 4
Training loss: 4.615983576912316
Validation loss: 4.733832434188388

Epoch: 6| Step: 5
Training loss: 4.639293954997776
Validation loss: 4.7276209799384326

Epoch: 6| Step: 6
Training loss: 5.956857707513131
Validation loss: 4.721751355400166

Epoch: 6| Step: 7
Training loss: 4.558215075719187
Validation loss: 4.71586621819653

Epoch: 6| Step: 8
Training loss: 4.526318622480834
Validation loss: 4.709535321546642

Epoch: 6| Step: 9
Training loss: 4.510046446702741
Validation loss: 4.703816410582251

Epoch: 6| Step: 10
Training loss: 5.143209717790231
Validation loss: 4.698240800433264

Epoch: 6| Step: 11
Training loss: 5.1503098922379404
Validation loss: 4.691748867816741

Epoch: 6| Step: 12
Training loss: 5.402729630221689
Validation loss: 4.6861968878253535

Epoch: 6| Step: 13
Training loss: 5.104667337994886
Validation loss: 4.680398181240449

Epoch: 13| Step: 0
Training loss: 4.468175891197406
Validation loss: 4.674284535839351

Epoch: 6| Step: 1
Training loss: 5.427116916232866
Validation loss: 4.6691486139111325

Epoch: 6| Step: 2
Training loss: 5.107817526202502
Validation loss: 4.664098282617658

Epoch: 6| Step: 3
Training loss: 5.124867693426053
Validation loss: 4.6588066984274175

Epoch: 6| Step: 4
Training loss: 4.934007592562248
Validation loss: 4.653105661912661

Epoch: 6| Step: 5
Training loss: 4.744790885023548
Validation loss: 4.646528468564866

Epoch: 6| Step: 6
Training loss: 4.651567395931354
Validation loss: 4.641430409215602

Epoch: 6| Step: 7
Training loss: 3.034378953768102
Validation loss: 4.6366204859565805

Epoch: 6| Step: 8
Training loss: 4.395015598308498
Validation loss: 4.630712091985583

Epoch: 6| Step: 9
Training loss: 4.810062336032005
Validation loss: 4.626332340272164

Epoch: 6| Step: 10
Training loss: 4.282057637239669
Validation loss: 4.620260060795091

Epoch: 6| Step: 11
Training loss: 4.483793107935024
Validation loss: 4.6151678893361

Epoch: 6| Step: 12
Training loss: 5.687693162928623
Validation loss: 4.610413411732988

Epoch: 6| Step: 13
Training loss: 5.045582325260045
Validation loss: 4.605888712088618

Epoch: 14| Step: 0
Training loss: 4.8161361630983714
Validation loss: 4.6005929336705185

Epoch: 6| Step: 1
Training loss: 5.016090442772949
Validation loss: 4.594779247450781

Epoch: 6| Step: 2
Training loss: 4.833609912895233
Validation loss: 4.589674129733702

Epoch: 6| Step: 3
Training loss: 5.581765918018222
Validation loss: 4.584430089410236

Epoch: 6| Step: 4
Training loss: 4.573607002351961
Validation loss: 4.5787955738007025

Epoch: 6| Step: 5
Training loss: 3.8305747154247833
Validation loss: 4.573527834753529

Epoch: 6| Step: 6
Training loss: 4.20642618204285
Validation loss: 4.56795247323342

Epoch: 6| Step: 7
Training loss: 4.5753277770645155
Validation loss: 4.562608656612753

Epoch: 6| Step: 8
Training loss: 4.45061735521369
Validation loss: 4.55779793969881

Epoch: 6| Step: 9
Training loss: 4.742330281906306
Validation loss: 4.552219828196711

Epoch: 6| Step: 10
Training loss: 5.281362498512883
Validation loss: 4.547326274207728

Epoch: 6| Step: 11
Training loss: 4.370050737099539
Validation loss: 4.542287235851262

Epoch: 6| Step: 12
Training loss: 5.020614471519483
Validation loss: 4.537484030787423

Epoch: 6| Step: 13
Training loss: 4.125257079465435
Validation loss: 4.5320951879346945

Epoch: 15| Step: 0
Training loss: 4.798061957114719
Validation loss: 4.5263636408314945

Epoch: 6| Step: 1
Training loss: 4.820724791170622
Validation loss: 4.521539565560392

Epoch: 6| Step: 2
Training loss: 4.951743525924298
Validation loss: 4.5163060678957025

Epoch: 6| Step: 3
Training loss: 5.060770375106025
Validation loss: 4.511467697402771

Epoch: 6| Step: 4
Training loss: 4.19135528277493
Validation loss: 4.506594911621049

Epoch: 6| Step: 5
Training loss: 4.394357635459398
Validation loss: 4.501191705511466

Epoch: 6| Step: 6
Training loss: 4.527621796358368
Validation loss: 4.496741015444324

Epoch: 6| Step: 7
Training loss: 5.661118577613853
Validation loss: 4.491701987746342

Epoch: 6| Step: 8
Training loss: 4.0322366142932955
Validation loss: 4.486885635130279

Epoch: 6| Step: 9
Training loss: 4.020875815264299
Validation loss: 4.481253730634044

Epoch: 6| Step: 10
Training loss: 4.602521139134685
Validation loss: 4.476975205034186

Epoch: 6| Step: 11
Training loss: 4.9804526654152035
Validation loss: 4.472025544453582

Epoch: 6| Step: 12
Training loss: 4.1350988975423615
Validation loss: 4.467396528955976

Epoch: 6| Step: 13
Training loss: 4.2411663027598925
Validation loss: 4.463022220377047

Epoch: 16| Step: 0
Training loss: 4.486516036008054
Validation loss: 4.45808423615011

Epoch: 6| Step: 1
Training loss: 5.021754622188706
Validation loss: 4.453248817551766

Epoch: 6| Step: 2
Training loss: 4.556450582727941
Validation loss: 4.4483271401225135

Epoch: 6| Step: 3
Training loss: 5.1999300291782395
Validation loss: 4.442894839642485

Epoch: 6| Step: 4
Training loss: 4.3018818485594
Validation loss: 4.4376068997827085

Epoch: 6| Step: 5
Training loss: 4.841699769283902
Validation loss: 4.432694855703114

Epoch: 6| Step: 6
Training loss: 4.707322994070814
Validation loss: 4.427657499292424

Epoch: 6| Step: 7
Training loss: 3.5853606115315206
Validation loss: 4.423089910783698

Epoch: 6| Step: 8
Training loss: 5.091804366843357
Validation loss: 4.4181390083620835

Epoch: 6| Step: 9
Training loss: 4.59458116550636
Validation loss: 4.41323387447857

Epoch: 6| Step: 10
Training loss: 5.121571580372655
Validation loss: 4.408267648179895

Epoch: 6| Step: 11
Training loss: 3.6071416377344727
Validation loss: 4.4032357188649645

Epoch: 6| Step: 12
Training loss: 3.6674843367727736
Validation loss: 4.398461006964503

Epoch: 6| Step: 13
Training loss: 4.559980559056651
Validation loss: 4.393732674837208

Epoch: 17| Step: 0
Training loss: 4.7049340098959505
Validation loss: 4.388889770802813

Epoch: 6| Step: 1
Training loss: 4.590823532392244
Validation loss: 4.384200349547954

Epoch: 6| Step: 2
Training loss: 5.054013143892938
Validation loss: 4.379470502994247

Epoch: 6| Step: 3
Training loss: 3.6402265469822743
Validation loss: 4.374521647142317

Epoch: 6| Step: 4
Training loss: 4.566961745778296
Validation loss: 4.370393598683968

Epoch: 6| Step: 5
Training loss: 3.845558547387081
Validation loss: 4.365888317033999

Epoch: 6| Step: 6
Training loss: 5.390100602890204
Validation loss: 4.360870505874993

Epoch: 6| Step: 7
Training loss: 3.9975023816681925
Validation loss: 4.355806373545358

Epoch: 6| Step: 8
Training loss: 4.530010816885389
Validation loss: 4.351148401871656

Epoch: 6| Step: 9
Training loss: 4.185840334731047
Validation loss: 4.346478417206961

Epoch: 6| Step: 10
Training loss: 4.833545592459511
Validation loss: 4.3424008147179185

Epoch: 6| Step: 11
Training loss: 3.7240596019429177
Validation loss: 4.3378904967556355

Epoch: 6| Step: 12
Training loss: 4.120380936576131
Validation loss: 4.332843691721274

Epoch: 6| Step: 13
Training loss: 5.201588446752084
Validation loss: 4.328642886469895

Epoch: 18| Step: 0
Training loss: 4.776171611431149
Validation loss: 4.323468454220511

Epoch: 6| Step: 1
Training loss: 4.897380027216741
Validation loss: 4.318929146097964

Epoch: 6| Step: 2
Training loss: 4.282841518878568
Validation loss: 4.314410942657738

Epoch: 6| Step: 3
Training loss: 3.1433970804988154
Validation loss: 4.309519765375774

Epoch: 6| Step: 4
Training loss: 4.860998734885818
Validation loss: 4.304964789328904

Epoch: 6| Step: 5
Training loss: 3.3856682473628705
Validation loss: 4.300735755192407

Epoch: 6| Step: 6
Training loss: 5.257049913354819
Validation loss: 4.295973397656223

Epoch: 6| Step: 7
Training loss: 5.286235916144191
Validation loss: 4.291410913840463

Epoch: 6| Step: 8
Training loss: 4.011820018348174
Validation loss: 4.286879910039252

Epoch: 6| Step: 9
Training loss: 4.05416131693901
Validation loss: 4.282038335313499

Epoch: 6| Step: 10
Training loss: 4.416610981332271
Validation loss: 4.277788215200618

Epoch: 6| Step: 11
Training loss: 3.727303933015099
Validation loss: 4.273283477369383

Epoch: 6| Step: 12
Training loss: 4.289538525567652
Validation loss: 4.268953545457092

Epoch: 6| Step: 13
Training loss: 4.907151254863696
Validation loss: 4.264554663808539

Epoch: 19| Step: 0
Training loss: 4.021741194674077
Validation loss: 4.260358677899244

Epoch: 6| Step: 1
Training loss: 4.652941661371436
Validation loss: 4.255395643141918

Epoch: 6| Step: 2
Training loss: 4.802741920617294
Validation loss: 4.251057063271682

Epoch: 6| Step: 3
Training loss: 3.7496913782915633
Validation loss: 4.246439246211961

Epoch: 6| Step: 4
Training loss: 4.964560031662765
Validation loss: 4.2423097184233995

Epoch: 6| Step: 5
Training loss: 4.165919707419598
Validation loss: 4.237637978767057

Epoch: 6| Step: 6
Training loss: 4.747381994660073
Validation loss: 4.23276339897102

Epoch: 6| Step: 7
Training loss: 4.266750089505354
Validation loss: 4.228855547556093

Epoch: 6| Step: 8
Training loss: 4.334717065010288
Validation loss: 4.224428965184387

Epoch: 6| Step: 9
Training loss: 3.7556925482157926
Validation loss: 4.2200259692702256

Epoch: 6| Step: 10
Training loss: 3.6858726401967523
Validation loss: 4.215519400467103

Epoch: 6| Step: 11
Training loss: 4.007320619258238
Validation loss: 4.211838964861078

Epoch: 6| Step: 12
Training loss: 5.060320538104702
Validation loss: 4.206855564823463

Epoch: 6| Step: 13
Training loss: 4.5444721807635045
Validation loss: 4.202231689214732

Epoch: 20| Step: 0
Training loss: 4.494646066345909
Validation loss: 4.198460236878106

Epoch: 6| Step: 1
Training loss: 4.680567994495821
Validation loss: 4.193716284232145

Epoch: 6| Step: 2
Training loss: 4.3227446127360425
Validation loss: 4.189782920015042

Epoch: 6| Step: 3
Training loss: 4.238482408100722
Validation loss: 4.185076111679079

Epoch: 6| Step: 4
Training loss: 4.803898841205765
Validation loss: 4.180970980653233

Epoch: 6| Step: 5
Training loss: 4.6201333912670295
Validation loss: 4.176589930337609

Epoch: 6| Step: 6
Training loss: 4.6428077778969055
Validation loss: 4.172038957324331

Epoch: 6| Step: 7
Training loss: 3.7744662381177063
Validation loss: 4.167396684909481

Epoch: 6| Step: 8
Training loss: 4.070260016456258
Validation loss: 4.163030423724794

Epoch: 6| Step: 9
Training loss: 4.690212431368881
Validation loss: 4.158601081550724

Epoch: 6| Step: 10
Training loss: 3.529247289920422
Validation loss: 4.154132351339798

Epoch: 6| Step: 11
Training loss: 3.8635843773266627
Validation loss: 4.150158234915536

Epoch: 6| Step: 12
Training loss: 4.603421365244682
Validation loss: 4.1455113591035575

Epoch: 6| Step: 13
Training loss: 3.609515695182939
Validation loss: 4.1415582145036085

Epoch: 21| Step: 0
Training loss: 4.498170692770432
Validation loss: 4.13732131541436

Epoch: 6| Step: 1
Training loss: 4.279960716637702
Validation loss: 4.133500347813749

Epoch: 6| Step: 2
Training loss: 3.570642902603821
Validation loss: 4.12897421384831

Epoch: 6| Step: 3
Training loss: 4.246361465226362
Validation loss: 4.125153760259918

Epoch: 6| Step: 4
Training loss: 5.275322652051906
Validation loss: 4.12092149805397

Epoch: 6| Step: 5
Training loss: 3.9584796811539147
Validation loss: 4.116290308985396

Epoch: 6| Step: 6
Training loss: 3.782889270909461
Validation loss: 4.111802190540061

Epoch: 6| Step: 7
Training loss: 3.8733795223228764
Validation loss: 4.107494779874859

Epoch: 6| Step: 8
Training loss: 4.724638441673713
Validation loss: 4.103349723772853

Epoch: 6| Step: 9
Training loss: 4.95036706045149
Validation loss: 4.098727628944077

Epoch: 6| Step: 10
Training loss: 3.5885463026189366
Validation loss: 4.094821566434798

Epoch: 6| Step: 11
Training loss: 3.7980983945245215
Validation loss: 4.090384772124142

Epoch: 6| Step: 12
Training loss: 4.258197060113446
Validation loss: 4.08605511449264

Epoch: 6| Step: 13
Training loss: 4.186984130056702
Validation loss: 4.081574268710114

Epoch: 22| Step: 0
Training loss: 4.459953988013252
Validation loss: 4.07745815783436

Epoch: 6| Step: 1
Training loss: 5.015862670210979
Validation loss: 4.07272439228019

Epoch: 6| Step: 2
Training loss: 4.471111393956537
Validation loss: 4.068272993074482

Epoch: 6| Step: 3
Training loss: 3.5222531377142237
Validation loss: 4.0640875819848885

Epoch: 6| Step: 4
Training loss: 3.9382943457181594
Validation loss: 4.0596495776543575

Epoch: 6| Step: 5
Training loss: 4.122458397428092
Validation loss: 4.0552271175790535

Epoch: 6| Step: 6
Training loss: 4.146873509766829
Validation loss: 4.050978947287429

Epoch: 6| Step: 7
Training loss: 3.9915966933029825
Validation loss: 4.046995772397016

Epoch: 6| Step: 8
Training loss: 4.354431411993181
Validation loss: 4.0423304743500434

Epoch: 6| Step: 9
Training loss: 4.483526382166171
Validation loss: 4.038011759792043

Epoch: 6| Step: 10
Training loss: 3.7587397139281333
Validation loss: 4.033730623419165

Epoch: 6| Step: 11
Training loss: 3.673144311859008
Validation loss: 4.0295737672661405

Epoch: 6| Step: 12
Training loss: 3.6801687521182207
Validation loss: 4.025608047617857

Epoch: 6| Step: 13
Training loss: 4.6486026510184395
Validation loss: 4.021230463896129

Epoch: 23| Step: 0
Training loss: 3.2641864145003114
Validation loss: 4.0169420667602775

Epoch: 6| Step: 1
Training loss: 4.31223816007636
Validation loss: 4.012023319914449

Epoch: 6| Step: 2
Training loss: 4.8902724263886235
Validation loss: 4.008159064762768

Epoch: 6| Step: 3
Training loss: 4.610656353281671
Validation loss: 4.003740667625442

Epoch: 6| Step: 4
Training loss: 3.980806555372771
Validation loss: 3.9988737507598047

Epoch: 6| Step: 5
Training loss: 3.2836472246679205
Validation loss: 3.9946911470514483

Epoch: 6| Step: 6
Training loss: 4.044281942528743
Validation loss: 3.9900601585971156

Epoch: 6| Step: 7
Training loss: 4.739429558016491
Validation loss: 3.985516632682191

Epoch: 6| Step: 8
Training loss: 4.027666968798171
Validation loss: 3.9797808720698677

Epoch: 6| Step: 9
Training loss: 4.3538231721786325
Validation loss: 3.974048691801801

Epoch: 6| Step: 10
Training loss: 3.929936122423692
Validation loss: 3.9681354757813474

Epoch: 6| Step: 11
Training loss: 4.1220787570616535
Validation loss: 3.964682950672478

Epoch: 6| Step: 12
Training loss: 3.8161723476172758
Validation loss: 3.9587750372472827

Epoch: 6| Step: 13
Training loss: 3.961962445015153
Validation loss: 3.9547516462794987

Epoch: 24| Step: 0
Training loss: 3.9735215706581175
Validation loss: 3.948830122272191

Epoch: 6| Step: 1
Training loss: 4.075811555708444
Validation loss: 3.944638880264063

Epoch: 6| Step: 2
Training loss: 3.314577854486841
Validation loss: 3.9398299090467392

Epoch: 6| Step: 3
Training loss: 4.1444688912751015
Validation loss: 3.9363863545836155

Epoch: 6| Step: 4
Training loss: 3.878729225567755
Validation loss: 3.932021371339015

Epoch: 6| Step: 5
Training loss: 4.078711924210063
Validation loss: 3.927855168727771

Epoch: 6| Step: 6
Training loss: 3.961880844311692
Validation loss: 3.9232010543636173

Epoch: 6| Step: 7
Training loss: 4.048964737806202
Validation loss: 3.9186990145459752

Epoch: 6| Step: 8
Training loss: 4.623979404324397
Validation loss: 3.914375683506632

Epoch: 6| Step: 9
Training loss: 4.084982765936479
Validation loss: 3.910357175092329

Epoch: 6| Step: 10
Training loss: 4.051279624070304
Validation loss: 3.9060236750840853

Epoch: 6| Step: 11
Training loss: 3.6824255473372616
Validation loss: 3.9018236640413977

Epoch: 6| Step: 12
Training loss: 4.8290998838786265
Validation loss: 3.8975942103508396

Epoch: 6| Step: 13
Training loss: 3.802868292615005
Validation loss: 3.893039572021345

Epoch: 25| Step: 0
Training loss: 3.711875395459284
Validation loss: 3.8877620351125657

Epoch: 6| Step: 1
Training loss: 3.4208210754794433
Validation loss: 3.8829831981938905

Epoch: 6| Step: 2
Training loss: 4.04120725137724
Validation loss: 3.8788582247257746

Epoch: 6| Step: 3
Training loss: 3.9026531291588293
Validation loss: 3.874466459398148

Epoch: 6| Step: 4
Training loss: 4.161877486501313
Validation loss: 3.869999068372616

Epoch: 6| Step: 5
Training loss: 4.709427472931581
Validation loss: 3.865119211448371

Epoch: 6| Step: 6
Training loss: 3.5763534758130326
Validation loss: 3.860780014887417

Epoch: 6| Step: 7
Training loss: 2.9555431335430375
Validation loss: 3.855958010244404

Epoch: 6| Step: 8
Training loss: 4.422714531128201
Validation loss: 3.8513947012499354

Epoch: 6| Step: 9
Training loss: 4.041061880474756
Validation loss: 3.8472091492493137

Epoch: 6| Step: 10
Training loss: 4.373340837038008
Validation loss: 3.8428218516976145

Epoch: 6| Step: 11
Training loss: 4.020644320194428
Validation loss: 3.838182195276532

Epoch: 6| Step: 12
Training loss: 4.398039832017631
Validation loss: 3.833582282620906

Epoch: 6| Step: 13
Training loss: 3.8216998305769305
Validation loss: 3.828993427618003

Epoch: 26| Step: 0
Training loss: 3.630993984737472
Validation loss: 3.8249191874026742

Epoch: 6| Step: 1
Training loss: 4.180929010269849
Validation loss: 3.8203295789881637

Epoch: 6| Step: 2
Training loss: 4.0468182062707605
Validation loss: 3.816060389266822

Epoch: 6| Step: 3
Training loss: 3.7613641843137944
Validation loss: 3.8116381770710714

Epoch: 6| Step: 4
Training loss: 3.740929888009391
Validation loss: 3.807057827066692

Epoch: 6| Step: 5
Training loss: 3.279562234508168
Validation loss: 3.8027108427970955

Epoch: 6| Step: 6
Training loss: 3.5974179332881473
Validation loss: 3.7984240267143403

Epoch: 6| Step: 7
Training loss: 4.313978301169233
Validation loss: 3.7947407861035587

Epoch: 6| Step: 8
Training loss: 3.942384626772248
Validation loss: 3.789805703177608

Epoch: 6| Step: 9
Training loss: 4.3161417746322455
Validation loss: 3.7858042337848605

Epoch: 6| Step: 10
Training loss: 3.9568242191182788
Validation loss: 3.7816093211045216

Epoch: 6| Step: 11
Training loss: 4.435319606614318
Validation loss: 3.7770977078203027

Epoch: 6| Step: 12
Training loss: 3.407345236988157
Validation loss: 3.77237713370384

Epoch: 6| Step: 13
Training loss: 4.21208376313738
Validation loss: 3.7682694136608497

Epoch: 27| Step: 0
Training loss: 4.512647445679104
Validation loss: 3.7636099419136158

Epoch: 6| Step: 1
Training loss: 4.137003455662454
Validation loss: 3.75943605241803

Epoch: 6| Step: 2
Training loss: 3.501401756781152
Validation loss: 3.754545233490893

Epoch: 6| Step: 3
Training loss: 3.2684597141770375
Validation loss: 3.750372910501608

Epoch: 6| Step: 4
Training loss: 4.000458691046507
Validation loss: 3.745598753365037

Epoch: 6| Step: 5
Training loss: 4.0919574569474415
Validation loss: 3.7413639869408475

Epoch: 6| Step: 6
Training loss: 3.0926194099926807
Validation loss: 3.737071682341937

Epoch: 6| Step: 7
Training loss: 4.292100730105034
Validation loss: 3.732518776235092

Epoch: 6| Step: 8
Training loss: 4.310576521335523
Validation loss: 3.728058925745538

Epoch: 6| Step: 9
Training loss: 3.1772083862374587
Validation loss: 3.7239006553753744

Epoch: 6| Step: 10
Training loss: 3.5350754533670896
Validation loss: 3.7197701046091822

Epoch: 6| Step: 11
Training loss: 4.505907631406093
Validation loss: 3.7153262451116125

Epoch: 6| Step: 12
Training loss: 3.8746057125196924
Validation loss: 3.7109025491775163

Epoch: 6| Step: 13
Training loss: 3.5025535532569116
Validation loss: 3.7067356239623757

Epoch: 28| Step: 0
Training loss: 4.769197719449995
Validation loss: 3.702096766825132

Epoch: 6| Step: 1
Training loss: 3.2865740498253424
Validation loss: 3.697746953517359

Epoch: 6| Step: 2
Training loss: 2.8228021765057405
Validation loss: 3.6933121647096154

Epoch: 6| Step: 3
Training loss: 2.9458444453942167
Validation loss: 3.6890894163798604

Epoch: 6| Step: 4
Training loss: 3.2640225069728594
Validation loss: 3.6849583417175955

Epoch: 6| Step: 5
Training loss: 3.8739606632486536
Validation loss: 3.6812255841294466

Epoch: 6| Step: 6
Training loss: 3.753352129286686
Validation loss: 3.6769672335846377

Epoch: 6| Step: 7
Training loss: 3.9712396457190127
Validation loss: 3.6731902668457286

Epoch: 6| Step: 8
Training loss: 4.694826224689184
Validation loss: 3.669379827190506

Epoch: 6| Step: 9
Training loss: 3.3617916906884684
Validation loss: 3.6644805582947995

Epoch: 6| Step: 10
Training loss: 3.8785657166577203
Validation loss: 3.6606992293700618

Epoch: 6| Step: 11
Training loss: 3.425414323458334
Validation loss: 3.6564776140533897

Epoch: 6| Step: 12
Training loss: 4.651626646953352
Validation loss: 3.6521388140894566

Epoch: 6| Step: 13
Training loss: 3.9854362719954772
Validation loss: 3.6478464436085383

Epoch: 29| Step: 0
Training loss: 3.3277367020585538
Validation loss: 3.643224571212404

Epoch: 6| Step: 1
Training loss: 4.16194485464963
Validation loss: 3.6388452679362913

Epoch: 6| Step: 2
Training loss: 4.308515615437837
Validation loss: 3.6341166462670866

Epoch: 6| Step: 3
Training loss: 3.468853785706294
Validation loss: 3.629469494862545

Epoch: 6| Step: 4
Training loss: 3.68752043120333
Validation loss: 3.6250995315392487

Epoch: 6| Step: 5
Training loss: 4.022599275548165
Validation loss: 3.621162422129815

Epoch: 6| Step: 6
Training loss: 3.594085943027676
Validation loss: 3.616358970409397

Epoch: 6| Step: 7
Training loss: 3.7406006317492215
Validation loss: 3.611975587578586

Epoch: 6| Step: 8
Training loss: 3.779405632721302
Validation loss: 3.6073099809857867

Epoch: 6| Step: 9
Training loss: 4.24567732045475
Validation loss: 3.6029303236481542

Epoch: 6| Step: 10
Training loss: 3.3166006366029124
Validation loss: 3.598528308636387

Epoch: 6| Step: 11
Training loss: 3.3746176609061664
Validation loss: 3.5941074580560493

Epoch: 6| Step: 12
Training loss: 4.009395532116903
Validation loss: 3.5894825684139704

Epoch: 6| Step: 13
Training loss: 3.27709974578673
Validation loss: 3.5854291701038785

Epoch: 30| Step: 0
Training loss: 3.826506104994165
Validation loss: 3.581230404075105

Epoch: 6| Step: 1
Training loss: 4.153850120694693
Validation loss: 3.576594207120944

Epoch: 6| Step: 2
Training loss: 4.302158505919859
Validation loss: 3.5725377199759047

Epoch: 6| Step: 3
Training loss: 3.8851356847921803
Validation loss: 3.5680635855494343

Epoch: 6| Step: 4
Training loss: 3.6289238575158147
Validation loss: 3.563406410687173

Epoch: 6| Step: 5
Training loss: 4.065678453497208
Validation loss: 3.5591478024638317

Epoch: 6| Step: 6
Training loss: 2.7950621968891425
Validation loss: 3.555196224042625

Epoch: 6| Step: 7
Training loss: 3.6981479339636336
Validation loss: 3.551211715361184

Epoch: 6| Step: 8
Training loss: 3.5622677643687926
Validation loss: 3.54693023145696

Epoch: 6| Step: 9
Training loss: 3.7493486474521633
Validation loss: 3.5427597752535553

Epoch: 6| Step: 10
Training loss: 3.0444792890140264
Validation loss: 3.538582607178808

Epoch: 6| Step: 11
Training loss: 3.1088385191042347
Validation loss: 3.534524395362977

Epoch: 6| Step: 12
Training loss: 4.200368665227866
Validation loss: 3.530237452181596

Epoch: 6| Step: 13
Training loss: 3.298119188180342
Validation loss: 3.5260479625080348

Epoch: 31| Step: 0
Training loss: 3.327216225782501
Validation loss: 3.5218602701153836

Epoch: 6| Step: 1
Training loss: 3.202150373350665
Validation loss: 3.5176782560244053

Epoch: 6| Step: 2
Training loss: 3.1333168746299536
Validation loss: 3.5140375919231044

Epoch: 6| Step: 3
Training loss: 3.997771596073868
Validation loss: 3.509881658941041

Epoch: 6| Step: 4
Training loss: 4.362008779244944
Validation loss: 3.5061051958162115

Epoch: 6| Step: 5
Training loss: 3.0895375559410687
Validation loss: 3.5022326569017155

Epoch: 6| Step: 6
Training loss: 4.7226627119476055
Validation loss: 3.497780186753155

Epoch: 6| Step: 7
Training loss: 4.308842310302584
Validation loss: 3.4933156034029382

Epoch: 6| Step: 8
Training loss: 3.4374564428170795
Validation loss: 3.488829110849002

Epoch: 6| Step: 9
Training loss: 4.06755174375328
Validation loss: 3.484441280447352

Epoch: 6| Step: 10
Training loss: 3.381647415921043
Validation loss: 3.4798359408018418

Epoch: 6| Step: 11
Training loss: 3.385441769237863
Validation loss: 3.475594923839008

Epoch: 6| Step: 12
Training loss: 2.9745769937296926
Validation loss: 3.4716339036772434

Epoch: 6| Step: 13
Training loss: 2.887688212019931
Validation loss: 3.467246110491522

Epoch: 32| Step: 0
Training loss: 2.865577848789089
Validation loss: 3.4635832399249065

Epoch: 6| Step: 1
Training loss: 2.98420626977206
Validation loss: 3.4598321003317136

Epoch: 6| Step: 2
Training loss: 3.827310031634107
Validation loss: 3.455957117254684

Epoch: 6| Step: 3
Training loss: 3.313276379848608
Validation loss: 3.45227143798289

Epoch: 6| Step: 4
Training loss: 3.456877589717068
Validation loss: 3.4482750989650013

Epoch: 6| Step: 5
Training loss: 3.666939783039329
Validation loss: 3.444642962781785

Epoch: 6| Step: 6
Training loss: 3.4917609105710254
Validation loss: 3.4405294536151616

Epoch: 6| Step: 7
Training loss: 4.287482854959
Validation loss: 3.436920348337246

Epoch: 6| Step: 8
Training loss: 4.202123359536196
Validation loss: 3.432744395258065

Epoch: 6| Step: 9
Training loss: 3.723708493403808
Validation loss: 3.4287340465271394

Epoch: 6| Step: 10
Training loss: 3.703267412626172
Validation loss: 3.4247300127450835

Epoch: 6| Step: 11
Training loss: 2.770214174164111
Validation loss: 3.4203723180195027

Epoch: 6| Step: 12
Training loss: 3.6685524050580534
Validation loss: 3.416389120660749

Epoch: 6| Step: 13
Training loss: 3.747320107690555
Validation loss: 3.4126595670588094

Epoch: 33| Step: 0
Training loss: 3.302132270201669
Validation loss: 3.4084700952588753

Epoch: 6| Step: 1
Training loss: 3.8319080577961837
Validation loss: 3.4046461546629634

Epoch: 6| Step: 2
Training loss: 3.0815324077446387
Validation loss: 3.4003540831736343

Epoch: 6| Step: 3
Training loss: 3.3050698494275013
Validation loss: 3.396154883827334

Epoch: 6| Step: 4
Training loss: 4.345972604004293
Validation loss: 3.39231341816645

Epoch: 6| Step: 5
Training loss: 3.4104364548755544
Validation loss: 3.3881762872325685

Epoch: 6| Step: 6
Training loss: 3.5036825153276787
Validation loss: 3.3843740804335782

Epoch: 6| Step: 7
Training loss: 3.4291669237608753
Validation loss: 3.380335111351688

Epoch: 6| Step: 8
Training loss: 4.14969755242612
Validation loss: 3.375971854356229

Epoch: 6| Step: 9
Training loss: 3.5290296207437697
Validation loss: 3.371943962233379

Epoch: 6| Step: 10
Training loss: 3.2080849555507798
Validation loss: 3.3679196298619165

Epoch: 6| Step: 11
Training loss: 3.106489673478839
Validation loss: 3.363976619726905

Epoch: 6| Step: 12
Training loss: 3.3142433617145475
Validation loss: 3.360158914581096

Epoch: 6| Step: 13
Training loss: 3.559225082924367
Validation loss: 3.356078217252296

Epoch: 34| Step: 0
Training loss: 2.6972571392878826
Validation loss: 3.3525729371665283

Epoch: 6| Step: 1
Training loss: 3.6097937667141053
Validation loss: 3.3487313264328766

Epoch: 6| Step: 2
Training loss: 3.215697535520655
Validation loss: 3.3453436645595604

Epoch: 6| Step: 3
Training loss: 3.5957879963503503
Validation loss: 3.3414542020446394

Epoch: 6| Step: 4
Training loss: 3.367410108107066
Validation loss: 3.33792338644445

Epoch: 6| Step: 5
Training loss: 3.6834953675223474
Validation loss: 3.333920371497728

Epoch: 6| Step: 6
Training loss: 3.159295755933894
Validation loss: 3.3299761237280356

Epoch: 6| Step: 7
Training loss: 3.4389004715529454
Validation loss: 3.3264209760809726

Epoch: 6| Step: 8
Training loss: 3.3434164290847654
Validation loss: 3.3230620126217656

Epoch: 6| Step: 9
Training loss: 3.676044320919599
Validation loss: 3.31953944163854

Epoch: 6| Step: 10
Training loss: 3.916384680045765
Validation loss: 3.3159732483512174

Epoch: 6| Step: 11
Training loss: 4.183707498380693
Validation loss: 3.31219863720331

Epoch: 6| Step: 12
Training loss: 2.6354719817094874
Validation loss: 3.3079435331867493

Epoch: 6| Step: 13
Training loss: 3.701312687995821
Validation loss: 3.304502681917909

Epoch: 35| Step: 0
Training loss: 3.85969350635678
Validation loss: 3.300614705295131

Epoch: 6| Step: 1
Training loss: 3.3200219599445666
Validation loss: 3.297066657354679

Epoch: 6| Step: 2
Training loss: 3.384521616457136
Validation loss: 3.2931336542231673

Epoch: 6| Step: 3
Training loss: 3.477345719140857
Validation loss: 3.289450156713304

Epoch: 6| Step: 4
Training loss: 3.179173683435405
Validation loss: 3.2856019239780565

Epoch: 6| Step: 5
Training loss: 3.2347557838860537
Validation loss: 3.2817916907393503

Epoch: 6| Step: 6
Training loss: 4.024653989716194
Validation loss: 3.278042197113565

Epoch: 6| Step: 7
Training loss: 2.885881480616627
Validation loss: 3.2739028903313594

Epoch: 6| Step: 8
Training loss: 3.184908542727265
Validation loss: 3.270418715874674

Epoch: 6| Step: 9
Training loss: 2.995346115313705
Validation loss: 3.2666770177469586

Epoch: 6| Step: 10
Training loss: 3.490228090456709
Validation loss: 3.2632804862689633

Epoch: 6| Step: 11
Training loss: 3.332111961397908
Validation loss: 3.2595429920611463

Epoch: 6| Step: 12
Training loss: 2.943850207394918
Validation loss: 3.2567468206822974

Epoch: 6| Step: 13
Training loss: 4.2378314223414515
Validation loss: 3.2530704934680736

Epoch: 36| Step: 0
Training loss: 3.045490752513463
Validation loss: 3.2495868126771135

Epoch: 6| Step: 1
Training loss: 3.080869583881035
Validation loss: 3.245940093478945

Epoch: 6| Step: 2
Training loss: 3.373731586735367
Validation loss: 3.242350195054318

Epoch: 6| Step: 3
Training loss: 2.992421113697753
Validation loss: 3.239087503314948

Epoch: 6| Step: 4
Training loss: 4.067773770413692
Validation loss: 3.236012742908255

Epoch: 6| Step: 5
Training loss: 3.4791653265731575
Validation loss: 3.2326598111541025

Epoch: 6| Step: 6
Training loss: 3.2789661997326625
Validation loss: 3.2284723437808793

Epoch: 6| Step: 7
Training loss: 2.606689350227853
Validation loss: 3.2253555860814904

Epoch: 6| Step: 8
Training loss: 3.423677431349318
Validation loss: 3.22188954490341

Epoch: 6| Step: 9
Training loss: 3.711854199070029
Validation loss: 3.2186821742149077

Epoch: 6| Step: 10
Training loss: 3.1983999245453254
Validation loss: 3.2152055403135917

Epoch: 6| Step: 11
Training loss: 3.641425441780578
Validation loss: 3.2117974954223305

Epoch: 6| Step: 12
Training loss: 3.8517714747441008
Validation loss: 3.208212879116072

Epoch: 6| Step: 13
Training loss: 3.112329967098071
Validation loss: 3.2051451476700796

Epoch: 37| Step: 0
Training loss: 3.8242474283111356
Validation loss: 3.2013873837886497

Epoch: 6| Step: 1
Training loss: 3.555809833123242
Validation loss: 3.198102148353473

Epoch: 6| Step: 2
Training loss: 3.2228823310849455
Validation loss: 3.1944036333729797

Epoch: 6| Step: 3
Training loss: 3.454789118866007
Validation loss: 3.1908045076542835

Epoch: 6| Step: 4
Training loss: 3.0219524196108054
Validation loss: 3.1871619824469137

Epoch: 6| Step: 5
Training loss: 3.3254762236795217
Validation loss: 3.183728948113413

Epoch: 6| Step: 6
Training loss: 3.519961382697423
Validation loss: 3.1801096942863607

Epoch: 6| Step: 7
Training loss: 3.3157255195243764
Validation loss: 3.1762671918027188

Epoch: 6| Step: 8
Training loss: 3.400687198753671
Validation loss: 3.1732911204354037

Epoch: 6| Step: 9
Training loss: 3.1615076370207347
Validation loss: 3.1699482871048392

Epoch: 6| Step: 10
Training loss: 3.1593532603013017
Validation loss: 3.166236363002698

Epoch: 6| Step: 11
Training loss: 3.3517350728170703
Validation loss: 3.163227526848478

Epoch: 6| Step: 12
Training loss: 3.6641033633948705
Validation loss: 3.1598154708647432

Epoch: 6| Step: 13
Training loss: 2.2689973134159005
Validation loss: 3.156521209546441

Epoch: 38| Step: 0
Training loss: 3.516140234597168
Validation loss: 3.1534488321393743

Epoch: 6| Step: 1
Training loss: 3.1716055920069883
Validation loss: 3.149977768713597

Epoch: 6| Step: 2
Training loss: 2.964392264547307
Validation loss: 3.1469187895409214

Epoch: 6| Step: 3
Training loss: 3.0266774090255577
Validation loss: 3.144162768144075

Epoch: 6| Step: 4
Training loss: 3.5196011586078653
Validation loss: 3.1410490796678365

Epoch: 6| Step: 5
Training loss: 3.0461412377678236
Validation loss: 3.138181821036077

Epoch: 6| Step: 6
Training loss: 3.2721547820548786
Validation loss: 3.135223767164876

Epoch: 6| Step: 7
Training loss: 3.3314667879888367
Validation loss: 3.132731169471752

Epoch: 6| Step: 8
Training loss: 2.8264451913018926
Validation loss: 3.1294875031698295

Epoch: 6| Step: 9
Training loss: 3.4475757318910376
Validation loss: 3.126607100184374

Epoch: 6| Step: 10
Training loss: 3.4289536092829045
Validation loss: 3.123792605802173

Epoch: 6| Step: 11
Training loss: 3.5522345159282973
Validation loss: 3.1210619972978697

Epoch: 6| Step: 12
Training loss: 3.2325173170860557
Validation loss: 3.1178791040583342

Epoch: 6| Step: 13
Training loss: 3.3875721490925645
Validation loss: 3.1141818924401425

Epoch: 39| Step: 0
Training loss: 3.281171525289274
Validation loss: 3.111374357605997

Epoch: 6| Step: 1
Training loss: 3.119796234959658
Validation loss: 3.1079548798824495

Epoch: 6| Step: 2
Training loss: 4.005136529736055
Validation loss: 3.1042105951123844

Epoch: 6| Step: 3
Training loss: 2.8842412617965927
Validation loss: 3.1022362477718133

Epoch: 6| Step: 4
Training loss: 2.987184011435564
Validation loss: 3.098175608201274

Epoch: 6| Step: 5
Training loss: 2.900510637773781
Validation loss: 3.094398892872286

Epoch: 6| Step: 6
Training loss: 3.4483360811434296
Validation loss: 3.0919511748107102

Epoch: 6| Step: 7
Training loss: 3.3659328592622764
Validation loss: 3.0889093567225725

Epoch: 6| Step: 8
Training loss: 3.683942598266398
Validation loss: 3.085451549785313

Epoch: 6| Step: 9
Training loss: 2.9158362341734905
Validation loss: 3.0818335691746293

Epoch: 6| Step: 10
Training loss: 3.308230545663606
Validation loss: 3.078638024347932

Epoch: 6| Step: 11
Training loss: 3.0614961808495607
Validation loss: 3.07605450441597

Epoch: 6| Step: 12
Training loss: 3.214632530272706
Validation loss: 3.072555356956104

Epoch: 6| Step: 13
Training loss: 2.871934998459397
Validation loss: 3.0687193486378557

Epoch: 40| Step: 0
Training loss: 3.6478187314054384
Validation loss: 3.0663687086135796

Epoch: 6| Step: 1
Training loss: 3.2775075732855807
Validation loss: 3.063386140153057

Epoch: 6| Step: 2
Training loss: 3.9030841663383953
Validation loss: 3.0607723371322186

Epoch: 6| Step: 3
Training loss: 3.4533025773592296
Validation loss: 3.0573994467527443

Epoch: 6| Step: 4
Training loss: 2.9232801026993447
Validation loss: 3.0540598088644924

Epoch: 6| Step: 5
Training loss: 3.149126834043769
Validation loss: 3.050697081280306

Epoch: 6| Step: 6
Training loss: 3.00035395123686
Validation loss: 3.0476241535686115

Epoch: 6| Step: 7
Training loss: 3.0423779287431914
Validation loss: 3.0451923908408656

Epoch: 6| Step: 8
Training loss: 2.664197006633524
Validation loss: 3.042142691443073

Epoch: 6| Step: 9
Training loss: 3.322471724390593
Validation loss: 3.0394057445316456

Epoch: 6| Step: 10
Training loss: 3.0255666722201506
Validation loss: 3.036521679766555

Epoch: 6| Step: 11
Training loss: 3.3598104505206443
Validation loss: 3.033759176488996

Epoch: 6| Step: 12
Training loss: 2.8583567322717682
Validation loss: 3.0312959333262715

Epoch: 6| Step: 13
Training loss: 2.824752651627607
Validation loss: 3.0279154969799267

Epoch: 41| Step: 0
Training loss: 2.5982768070449755
Validation loss: 3.025673275363932

Epoch: 6| Step: 1
Training loss: 3.4447571875676273
Validation loss: 3.023090352476393

Epoch: 6| Step: 2
Training loss: 3.1405864352615156
Validation loss: 3.020144921271894

Epoch: 6| Step: 3
Training loss: 2.9636205429191014
Validation loss: 3.0174287662352186

Epoch: 6| Step: 4
Training loss: 3.388387196480639
Validation loss: 3.0148805216516954

Epoch: 6| Step: 5
Training loss: 3.16759363627661
Validation loss: 3.012140161278375

Epoch: 6| Step: 6
Training loss: 2.415680475819367
Validation loss: 3.009905436224844

Epoch: 6| Step: 7
Training loss: 3.2794098553441917
Validation loss: 3.0074129177729265

Epoch: 6| Step: 8
Training loss: 3.179763080720279
Validation loss: 3.0050354791621268

Epoch: 6| Step: 9
Training loss: 3.0515976520472794
Validation loss: 3.002380870093634

Epoch: 6| Step: 10
Training loss: 3.1592133462754863
Validation loss: 2.9996362969018766

Epoch: 6| Step: 11
Training loss: 2.9739462901782936
Validation loss: 2.996932965335596

Epoch: 6| Step: 12
Training loss: 3.8711686420606166
Validation loss: 2.9943069640734694

Epoch: 6| Step: 13
Training loss: 3.228752224486113
Validation loss: 2.991505730284016

Epoch: 42| Step: 0
Training loss: 2.687893328605038
Validation loss: 2.9896396582920994

Epoch: 6| Step: 1
Training loss: 3.17831728793333
Validation loss: 2.987231832835693

Epoch: 6| Step: 2
Training loss: 2.649920293221063
Validation loss: 2.9843333775678573

Epoch: 6| Step: 3
Training loss: 2.7807501011472637
Validation loss: 2.9818678305673054

Epoch: 6| Step: 4
Training loss: 3.1208942144250638
Validation loss: 2.979605440137689

Epoch: 6| Step: 5
Training loss: 3.426437054176024
Validation loss: 2.9771267146764298

Epoch: 6| Step: 6
Training loss: 3.399053829035107
Validation loss: 2.974437953311888

Epoch: 6| Step: 7
Training loss: 3.637053215143094
Validation loss: 2.9714530417963925

Epoch: 6| Step: 8
Training loss: 2.92200310574157
Validation loss: 2.9689286964576738

Epoch: 6| Step: 9
Training loss: 2.9649145145540508
Validation loss: 2.966042525468674

Epoch: 6| Step: 10
Training loss: 3.162642247314272
Validation loss: 2.963472943215869

Epoch: 6| Step: 11
Training loss: 3.337885625041969
Validation loss: 2.9612441629653112

Epoch: 6| Step: 12
Training loss: 2.649135081377
Validation loss: 2.958279774857093

Epoch: 6| Step: 13
Training loss: 3.466417507852324
Validation loss: 2.9561292111517896

Epoch: 43| Step: 0
Training loss: 3.024039275141389
Validation loss: 2.953565036612789

Epoch: 6| Step: 1
Training loss: 3.3626434749355107
Validation loss: 2.950734592291401

Epoch: 6| Step: 2
Training loss: 3.1866816049755045
Validation loss: 2.9474621794228697

Epoch: 6| Step: 3
Training loss: 2.6770303525518506
Validation loss: 2.945449340231842

Epoch: 6| Step: 4
Training loss: 2.616846136348957
Validation loss: 2.9434008883337603

Epoch: 6| Step: 5
Training loss: 3.462808142215991
Validation loss: 2.9411115291849605

Epoch: 6| Step: 6
Training loss: 3.2010506216549373
Validation loss: 2.938597873031659

Epoch: 6| Step: 7
Training loss: 3.1004879721236143
Validation loss: 2.9353240049711986

Epoch: 6| Step: 8
Training loss: 3.4199176921198005
Validation loss: 2.932990149630473

Epoch: 6| Step: 9
Training loss: 3.410363189955337
Validation loss: 2.930505514596505

Epoch: 6| Step: 10
Training loss: 2.5512865859926372
Validation loss: 2.9282410708898987

Epoch: 6| Step: 11
Training loss: 3.2603989540732097
Validation loss: 2.9258207310863584

Epoch: 6| Step: 12
Training loss: 2.5754156499405094
Validation loss: 2.9234445201762984

Epoch: 6| Step: 13
Training loss: 3.037931648635668
Validation loss: 2.9211837712513327

Epoch: 44| Step: 0
Training loss: 3.1285337685982815
Validation loss: 2.9189997787388378

Epoch: 6| Step: 1
Training loss: 3.001258268333018
Validation loss: 2.9177821523981096

Epoch: 6| Step: 2
Training loss: 2.6734432503545333
Validation loss: 2.9149881346751716

Epoch: 6| Step: 3
Training loss: 2.6738292841772964
Validation loss: 2.921718450422112

Epoch: 6| Step: 4
Training loss: 3.055452451026027
Validation loss: 2.9097134315117175

Epoch: 6| Step: 5
Training loss: 2.9286599760592034
Validation loss: 2.9066597160932868

Epoch: 6| Step: 6
Training loss: 3.355954011904378
Validation loss: 2.9054058448688074

Epoch: 6| Step: 7
Training loss: 3.052753743740539
Validation loss: 2.9041337269064758

Epoch: 6| Step: 8
Training loss: 3.242944835775925
Validation loss: 2.902348117474247

Epoch: 6| Step: 9
Training loss: 3.1686166648726526
Validation loss: 2.900695264168412

Epoch: 6| Step: 10
Training loss: 2.984935767730285
Validation loss: 2.897924194399291

Epoch: 6| Step: 11
Training loss: 3.3266724474696794
Validation loss: 2.895518585408044

Epoch: 6| Step: 12
Training loss: 3.145725947351397
Validation loss: 2.89273945223085

Epoch: 6| Step: 13
Training loss: 2.853316094474174
Validation loss: 2.889653002928831

Epoch: 45| Step: 0
Training loss: 3.120389359950202
Validation loss: 2.8875454005956156

Epoch: 6| Step: 1
Training loss: 2.7441553081513312
Validation loss: 2.885131303101096

Epoch: 6| Step: 2
Training loss: 2.7033113624849587
Validation loss: 2.8830547007032155

Epoch: 6| Step: 3
Training loss: 3.122566496337244
Validation loss: 2.880811870635877

Epoch: 6| Step: 4
Training loss: 2.983852480537594
Validation loss: 2.8784996377037926

Epoch: 6| Step: 5
Training loss: 3.233390179032794
Validation loss: 2.8764242845960037

Epoch: 6| Step: 6
Training loss: 3.039839382947904
Validation loss: 2.8745046271756203

Epoch: 6| Step: 7
Training loss: 2.8617998691218367
Validation loss: 2.8722449661066007

Epoch: 6| Step: 8
Training loss: 2.8139341300732528
Validation loss: 2.870887787020569

Epoch: 6| Step: 9
Training loss: 3.0568579258322006
Validation loss: 2.867923984993956

Epoch: 6| Step: 10
Training loss: 3.286621637816123
Validation loss: 2.8657773298060607

Epoch: 6| Step: 11
Training loss: 3.127402793294517
Validation loss: 2.864007390240062

Epoch: 6| Step: 12
Training loss: 3.1808701923630998
Validation loss: 2.862064854337362

Epoch: 6| Step: 13
Training loss: 2.889540350240665
Validation loss: 2.860151897567081

Epoch: 46| Step: 0
Training loss: 3.049809534348134
Validation loss: 2.8582076867146116

Epoch: 6| Step: 1
Training loss: 3.0764209658574817
Validation loss: 2.856321278022858

Epoch: 6| Step: 2
Training loss: 2.7132518904020437
Validation loss: 2.8538681254680394

Epoch: 6| Step: 3
Training loss: 2.745145761618672
Validation loss: 2.852405956366299

Epoch: 6| Step: 4
Training loss: 3.350845651503542
Validation loss: 2.850840200976995

Epoch: 6| Step: 5
Training loss: 3.5623669515828227
Validation loss: 2.8481409456633884

Epoch: 6| Step: 6
Training loss: 2.9670514517997413
Validation loss: 2.8458917119380844

Epoch: 6| Step: 7
Training loss: 3.2613931641859626
Validation loss: 2.8432850999158497

Epoch: 6| Step: 8
Training loss: 3.127892948045632
Validation loss: 2.8408116681127074

Epoch: 6| Step: 9
Training loss: 2.874804282782854
Validation loss: 2.8382677045198443

Epoch: 6| Step: 10
Training loss: 2.4897027618832928
Validation loss: 2.835781951365569

Epoch: 6| Step: 11
Training loss: 3.4104188378819797
Validation loss: 2.8333729058662396

Epoch: 6| Step: 12
Training loss: 2.4722026390795464
Validation loss: 2.831560243923455

Epoch: 6| Step: 13
Training loss: 2.469015952162661
Validation loss: 2.829804724279095

Epoch: 47| Step: 0
Training loss: 3.2955620488058326
Validation loss: 2.8278696215349006

Epoch: 6| Step: 1
Training loss: 3.156957414873335
Validation loss: 2.8263773005375805

Epoch: 6| Step: 2
Training loss: 3.311288288106779
Validation loss: 2.825035318362034

Epoch: 6| Step: 3
Training loss: 2.880385289381128
Validation loss: 2.822241999297378

Epoch: 6| Step: 4
Training loss: 3.3964666856389556
Validation loss: 2.819456109574547

Epoch: 6| Step: 5
Training loss: 2.7477986454774386
Validation loss: 2.817611175573145

Epoch: 6| Step: 6
Training loss: 3.1998406668573245
Validation loss: 2.816141159272917

Epoch: 6| Step: 7
Training loss: 2.7864650738120624
Validation loss: 2.8143360926314767

Epoch: 6| Step: 8
Training loss: 3.1307823090756868
Validation loss: 2.813056184381394

Epoch: 6| Step: 9
Training loss: 2.6474381533451075
Validation loss: 2.811487086119491

Epoch: 6| Step: 10
Training loss: 3.012281392503375
Validation loss: 2.8097545504589303

Epoch: 6| Step: 11
Training loss: 1.9090912703311462
Validation loss: 2.8080891813406037

Epoch: 6| Step: 12
Training loss: 2.259332798396175
Validation loss: 2.807131284379972

Epoch: 6| Step: 13
Training loss: 3.2988636834784266
Validation loss: 2.805622947206608

Epoch: 48| Step: 0
Training loss: 2.8775074846185276
Validation loss: 2.8054384237541403

Epoch: 6| Step: 1
Training loss: 3.5755486020729927
Validation loss: 2.8027398476010017

Epoch: 6| Step: 2
Training loss: 3.1509660359703764
Validation loss: 2.800922484230844

Epoch: 6| Step: 3
Training loss: 2.644929345959394
Validation loss: 2.7982114301904533

Epoch: 6| Step: 4
Training loss: 2.90149784211245
Validation loss: 2.798066650786549

Epoch: 6| Step: 5
Training loss: 3.0150215454343927
Validation loss: 2.7952807125233803

Epoch: 6| Step: 6
Training loss: 2.6423762005377767
Validation loss: 2.793834105839272

Epoch: 6| Step: 7
Training loss: 2.8460972080424365
Validation loss: 2.790701462060184

Epoch: 6| Step: 8
Training loss: 2.8982183574080125
Validation loss: 2.7892541044867825

Epoch: 6| Step: 9
Training loss: 2.567617005948005
Validation loss: 2.787980967882234

Epoch: 6| Step: 10
Training loss: 2.9165532407958
Validation loss: 2.7865036054599632

Epoch: 6| Step: 11
Training loss: 2.733489323638614
Validation loss: 2.7851853977727283

Epoch: 6| Step: 12
Training loss: 3.0752069419139425
Validation loss: 2.7834681120427205

Epoch: 6| Step: 13
Training loss: 3.081156056424758
Validation loss: 2.782332520427184

Epoch: 49| Step: 0
Training loss: 3.494343410042804
Validation loss: 2.780731667213056

Epoch: 6| Step: 1
Training loss: 2.8011557782186367
Validation loss: 2.7788166302305743

Epoch: 6| Step: 2
Training loss: 3.2842193247217786
Validation loss: 2.777171612934463

Epoch: 6| Step: 3
Training loss: 3.8230889027780823
Validation loss: 2.7754969297985483

Epoch: 6| Step: 4
Training loss: 2.839633183497701
Validation loss: 2.773030927345068

Epoch: 6| Step: 5
Training loss: 2.789385095740871
Validation loss: 2.7703068359684297

Epoch: 6| Step: 6
Training loss: 3.108512413722926
Validation loss: 2.769103899196652

Epoch: 6| Step: 7
Training loss: 2.542396774071963
Validation loss: 2.7667486275363626

Epoch: 6| Step: 8
Training loss: 1.8358167892705688
Validation loss: 2.764110703782078

Epoch: 6| Step: 9
Training loss: 2.881187249615372
Validation loss: 2.762839788077688

Epoch: 6| Step: 10
Training loss: 2.2927571447625277
Validation loss: 2.7608057479639387

Epoch: 6| Step: 11
Training loss: 2.6334250442212124
Validation loss: 2.7589742358692604

Epoch: 6| Step: 12
Training loss: 2.7440637326582595
Validation loss: 2.758090803964624

Epoch: 6| Step: 13
Training loss: 3.1387666736617192
Validation loss: 2.7558283021194803

Epoch: 50| Step: 0
Training loss: 2.8174432334833948
Validation loss: 2.755130028768729

Epoch: 6| Step: 1
Training loss: 3.353771557647997
Validation loss: 2.752486217694103

Epoch: 6| Step: 2
Training loss: 2.4836649329828315
Validation loss: 2.7513824513737855

Epoch: 6| Step: 3
Training loss: 3.1636332656382797
Validation loss: 2.7489681620034854

Epoch: 6| Step: 4
Training loss: 2.8293842020426556
Validation loss: 2.7460383431790003

Epoch: 6| Step: 5
Training loss: 3.1871822423187464
Validation loss: 2.7422090187206565

Epoch: 6| Step: 6
Training loss: 2.1580356446611186
Validation loss: 2.741565137411342

Epoch: 6| Step: 7
Training loss: 3.3190297958907724
Validation loss: 2.742094467628162

Epoch: 6| Step: 8
Training loss: 2.9369483592111134
Validation loss: 2.738428450186414

Epoch: 6| Step: 9
Training loss: 2.9050894440162036
Validation loss: 2.739192852625851

Epoch: 6| Step: 10
Training loss: 2.785403290181269
Validation loss: 2.735683977982943

Epoch: 6| Step: 11
Training loss: 2.422799998191719
Validation loss: 2.7357845923777924

Epoch: 6| Step: 12
Training loss: 3.010077557499249
Validation loss: 2.7334920711091835

Epoch: 6| Step: 13
Training loss: 2.7897297037102327
Validation loss: 2.731814888064668

Epoch: 51| Step: 0
Training loss: 2.6480963833315845
Validation loss: 2.728059767459902

Epoch: 6| Step: 1
Training loss: 2.7915106962293885
Validation loss: 2.728041560123076

Epoch: 6| Step: 2
Training loss: 2.8657370908357076
Validation loss: 2.7275565593343574

Epoch: 6| Step: 3
Training loss: 2.4934291317669413
Validation loss: 2.727770285543221

Epoch: 6| Step: 4
Training loss: 3.253976296796322
Validation loss: 2.7253647790504956

Epoch: 6| Step: 5
Training loss: 2.9454782778279402
Validation loss: 2.723018262777867

Epoch: 6| Step: 6
Training loss: 2.5678654765132753
Validation loss: 2.723961581537609

Epoch: 6| Step: 7
Training loss: 2.5284010313254344
Validation loss: 2.7217038649356695

Epoch: 6| Step: 8
Training loss: 3.0865153483904155
Validation loss: 2.7210981525418747

Epoch: 6| Step: 9
Training loss: 2.7021405847543556
Validation loss: 2.719460960764914

Epoch: 6| Step: 10
Training loss: 2.977064195539833
Validation loss: 2.7181603022370724

Epoch: 6| Step: 11
Training loss: 3.2379678866777306
Validation loss: 2.7175524913417277

Epoch: 6| Step: 12
Training loss: 3.0653190872350278
Validation loss: 2.7156988100967023

Epoch: 6| Step: 13
Training loss: 2.8263526547603797
Validation loss: 2.711627780711299

Epoch: 52| Step: 0
Training loss: 2.6632887088473125
Validation loss: 2.711336720265259

Epoch: 6| Step: 1
Training loss: 2.7865594483089646
Validation loss: 2.7098559623296

Epoch: 6| Step: 2
Training loss: 2.6521688187319823
Validation loss: 2.709786309008462

Epoch: 6| Step: 3
Training loss: 2.988652384530781
Validation loss: 2.7089242779538796

Epoch: 6| Step: 4
Training loss: 2.7021441140810643
Validation loss: 2.709943033795025

Epoch: 6| Step: 5
Training loss: 2.5262973511801
Validation loss: 2.7102771141568645

Epoch: 6| Step: 6
Training loss: 2.2021159573547053
Validation loss: 2.7106706412796453

Epoch: 6| Step: 7
Training loss: 2.8788766018338516
Validation loss: 2.7113112779196586

Epoch: 6| Step: 8
Training loss: 3.29844447378689
Validation loss: 2.708963677827575

Epoch: 6| Step: 9
Training loss: 2.8740357150179485
Validation loss: 2.7057007147743635

Epoch: 6| Step: 10
Training loss: 2.2030843095200683
Validation loss: 2.702593889043535

Epoch: 6| Step: 11
Training loss: 3.3848501504160393
Validation loss: 2.7015277649246197

Epoch: 6| Step: 12
Training loss: 2.8179710580654014
Validation loss: 2.6995898376738183

Epoch: 6| Step: 13
Training loss: 3.5686627004872054
Validation loss: 2.7005238890132457

Epoch: 53| Step: 0
Training loss: 2.8432405455618346
Validation loss: 2.698969636748915

Epoch: 6| Step: 1
Training loss: 2.9441584342224556
Validation loss: 2.696171852998976

Epoch: 6| Step: 2
Training loss: 3.05712028859241
Validation loss: 2.6943290501122026

Epoch: 6| Step: 3
Training loss: 3.1259332407768174
Validation loss: 2.6944776633488217

Epoch: 6| Step: 4
Training loss: 2.783763649696764
Validation loss: 2.6905303253164323

Epoch: 6| Step: 5
Training loss: 3.117289529531271
Validation loss: 2.6877800108062915

Epoch: 6| Step: 6
Training loss: 2.5418642519668997
Validation loss: 2.6872336677057085

Epoch: 6| Step: 7
Training loss: 2.9174129258002655
Validation loss: 2.686592762130173

Epoch: 6| Step: 8
Training loss: 2.373964585924695
Validation loss: 2.683360238167439

Epoch: 6| Step: 9
Training loss: 2.6821354397705104
Validation loss: 2.6817789470416264

Epoch: 6| Step: 10
Training loss: 3.0959167599293784
Validation loss: 2.679601847741306

Epoch: 6| Step: 11
Training loss: 2.927652287875248
Validation loss: 2.6796915334183686

Epoch: 6| Step: 12
Training loss: 2.180522034286858
Validation loss: 2.6788809909261992

Epoch: 6| Step: 13
Training loss: 2.8116468195128994
Validation loss: 2.6764869371961617

Epoch: 54| Step: 0
Training loss: 2.764731569970528
Validation loss: 2.67465697195509

Epoch: 6| Step: 1
Training loss: 2.478590078114893
Validation loss: 2.6732787075629294

Epoch: 6| Step: 2
Training loss: 2.8816966143041656
Validation loss: 2.671753075626783

Epoch: 6| Step: 3
Training loss: 3.1455158469219806
Validation loss: 2.674081289280278

Epoch: 6| Step: 4
Training loss: 2.8296774296868366
Validation loss: 2.6690455544782457

Epoch: 6| Step: 5
Training loss: 2.9206435928716177
Validation loss: 2.6671315374092095

Epoch: 6| Step: 6
Training loss: 2.1807412502432966
Validation loss: 2.667989221571598

Epoch: 6| Step: 7
Training loss: 2.6224614538918276
Validation loss: 2.666923694343352

Epoch: 6| Step: 8
Training loss: 3.2983880932467415
Validation loss: 2.6662595756061935

Epoch: 6| Step: 9
Training loss: 3.060899900368067
Validation loss: 2.663742821867383

Epoch: 6| Step: 10
Training loss: 2.8195128429950387
Validation loss: 2.6628078963221236

Epoch: 6| Step: 11
Training loss: 2.729601808370056
Validation loss: 2.6616308575655623

Epoch: 6| Step: 12
Training loss: 2.782053970548369
Validation loss: 2.6613170091068494

Epoch: 6| Step: 13
Training loss: 2.6369453389329136
Validation loss: 2.6605745753118244

Epoch: 55| Step: 0
Training loss: 2.905487616842649
Validation loss: 2.6608257450179145

Epoch: 6| Step: 1
Training loss: 2.4462518319896454
Validation loss: 2.659463218005734

Epoch: 6| Step: 2
Training loss: 3.0566131688064
Validation loss: 2.660257584951929

Epoch: 6| Step: 3
Training loss: 2.548279076849614
Validation loss: 2.658294444462403

Epoch: 6| Step: 4
Training loss: 2.849056114364519
Validation loss: 2.6566463473949735

Epoch: 6| Step: 5
Training loss: 2.917508212799568
Validation loss: 2.6545397769210894

Epoch: 6| Step: 6
Training loss: 2.6722017501113835
Validation loss: 2.653680583413115

Epoch: 6| Step: 7
Training loss: 2.4134543433682754
Validation loss: 2.6509391200249417

Epoch: 6| Step: 8
Training loss: 2.92552503780538
Validation loss: 2.6505932656663926

Epoch: 6| Step: 9
Training loss: 3.0497576257676173
Validation loss: 2.6487931394401962

Epoch: 6| Step: 10
Training loss: 2.8848099237035423
Validation loss: 2.650581639714826

Epoch: 6| Step: 11
Training loss: 2.890150536441141
Validation loss: 2.6467534265142594

Epoch: 6| Step: 12
Training loss: 3.115058037720829
Validation loss: 2.6453915374839303

Epoch: 6| Step: 13
Training loss: 2.3132094248733197
Validation loss: 2.6448438150724347

Epoch: 56| Step: 0
Training loss: 1.8854624986785973
Validation loss: 2.6429176009135062

Epoch: 6| Step: 1
Training loss: 2.35315465414504
Validation loss: 2.6426378963728316

Epoch: 6| Step: 2
Training loss: 3.0697513290739162
Validation loss: 2.6396352654948285

Epoch: 6| Step: 3
Training loss: 2.595567640869029
Validation loss: 2.6386311695226077

Epoch: 6| Step: 4
Training loss: 2.4608220148994264
Validation loss: 2.638248148868552

Epoch: 6| Step: 5
Training loss: 3.193405962962916
Validation loss: 2.635115509517477

Epoch: 6| Step: 6
Training loss: 3.1245858490214786
Validation loss: 2.6334573048571595

Epoch: 6| Step: 7
Training loss: 2.69587520309393
Validation loss: 2.633230113972169

Epoch: 6| Step: 8
Training loss: 2.6812594504734477
Validation loss: 2.633426945467031

Epoch: 6| Step: 9
Training loss: 2.9067845006850526
Validation loss: 2.6313865565779113

Epoch: 6| Step: 10
Training loss: 3.1403933007854548
Validation loss: 2.632803700901198

Epoch: 6| Step: 11
Training loss: 2.914950892458454
Validation loss: 2.6299768377475923

Epoch: 6| Step: 12
Training loss: 2.5206762743066187
Validation loss: 2.6299939713451295

Epoch: 6| Step: 13
Training loss: 2.9921116433351282
Validation loss: 2.628501819414285

Epoch: 57| Step: 0
Training loss: 2.500157542033172
Validation loss: 2.628647132562314

Epoch: 6| Step: 1
Training loss: 2.921061683105365
Validation loss: 2.627517083763095

Epoch: 6| Step: 2
Training loss: 2.6932133115647106
Validation loss: 2.6261292405275287

Epoch: 6| Step: 3
Training loss: 2.831376372289643
Validation loss: 2.6256347675924236

Epoch: 6| Step: 4
Training loss: 2.7210734294052656
Validation loss: 2.624683353460008

Epoch: 6| Step: 5
Training loss: 2.7843957320104025
Validation loss: 2.6229669024257447

Epoch: 6| Step: 6
Training loss: 2.297710967231154
Validation loss: 2.6218502281452456

Epoch: 6| Step: 7
Training loss: 3.0011057405385695
Validation loss: 2.621522401266641

Epoch: 6| Step: 8
Training loss: 2.785893796020641
Validation loss: 2.6224300125960576

Epoch: 6| Step: 9
Training loss: 2.597200419651211
Validation loss: 2.619351076323133

Epoch: 6| Step: 10
Training loss: 3.2009082101414554
Validation loss: 2.621046631527397

Epoch: 6| Step: 11
Training loss: 2.5022714786055533
Validation loss: 2.6178623525046874

Epoch: 6| Step: 12
Training loss: 2.769345383534167
Validation loss: 2.617549829406474

Epoch: 6| Step: 13
Training loss: 2.9495597187520826
Validation loss: 2.616514645147254

Epoch: 58| Step: 0
Training loss: 2.950144075657776
Validation loss: 2.6131078247245516

Epoch: 6| Step: 1
Training loss: 3.0552305241344766
Validation loss: 2.6146687092209766

Epoch: 6| Step: 2
Training loss: 3.0489432333331314
Validation loss: 2.6118771402216816

Epoch: 6| Step: 3
Training loss: 2.5702258620110583
Validation loss: 2.6100834933503037

Epoch: 6| Step: 4
Training loss: 2.3314678591468643
Validation loss: 2.613916917552209

Epoch: 6| Step: 5
Training loss: 2.1026989441504567
Validation loss: 2.6197897353016666

Epoch: 6| Step: 6
Training loss: 3.007020365456723
Validation loss: 2.620277016023553

Epoch: 6| Step: 7
Training loss: 2.456387628091983
Validation loss: 2.6198412749571753

Epoch: 6| Step: 8
Training loss: 3.2936831386084653
Validation loss: 2.61444158790437

Epoch: 6| Step: 9
Training loss: 2.8806090992980953
Validation loss: 2.604546181045561

Epoch: 6| Step: 10
Training loss: 2.836247703043586
Validation loss: 2.603158134991437

Epoch: 6| Step: 11
Training loss: 2.551389005500995
Validation loss: 2.603745896996537

Epoch: 6| Step: 12
Training loss: 2.602532558182538
Validation loss: 2.603237189676055

Epoch: 6| Step: 13
Training loss: 2.5673855984318283
Validation loss: 2.602717390505485

Epoch: 59| Step: 0
Training loss: 2.270890214773429
Validation loss: 2.60487712069965

Epoch: 6| Step: 1
Training loss: 2.998826433156192
Validation loss: 2.601118124277462

Epoch: 6| Step: 2
Training loss: 2.389788911507655
Validation loss: 2.601446704750428

Epoch: 6| Step: 3
Training loss: 2.6273640477862235
Validation loss: 2.601042809191417

Epoch: 6| Step: 4
Training loss: 2.8144260169582784
Validation loss: 2.600820670455065

Epoch: 6| Step: 5
Training loss: 2.778301862444231
Validation loss: 2.6004482475880946

Epoch: 6| Step: 6
Training loss: 2.5515095487427515
Validation loss: 2.5943155706183862

Epoch: 6| Step: 7
Training loss: 3.0112326461019574
Validation loss: 2.594458578980213

Epoch: 6| Step: 8
Training loss: 3.2436061467078487
Validation loss: 2.5943233974553577

Epoch: 6| Step: 9
Training loss: 2.8170921982372428
Validation loss: 2.596534215155037

Epoch: 6| Step: 10
Training loss: 1.982009559184868
Validation loss: 2.5936237135940687

Epoch: 6| Step: 11
Training loss: 2.966033656561481
Validation loss: 2.5929052210457155

Epoch: 6| Step: 12
Training loss: 2.3005700524485544
Validation loss: 2.600494853024339

Epoch: 6| Step: 13
Training loss: 3.213045120003183
Validation loss: 2.5915507142437466

Epoch: 60| Step: 0
Training loss: 2.6978238554986964
Validation loss: 2.5948972041718164

Epoch: 6| Step: 1
Training loss: 2.660275449616914
Validation loss: 2.594127321182845

Epoch: 6| Step: 2
Training loss: 3.069451830257162
Validation loss: 2.5938824079796663

Epoch: 6| Step: 3
Training loss: 2.662338370131869
Validation loss: 2.5891161357302037

Epoch: 6| Step: 4
Training loss: 2.7089938800977804
Validation loss: 2.591025948107325

Epoch: 6| Step: 5
Training loss: 3.1035325258153725
Validation loss: 2.5949451496597056

Epoch: 6| Step: 6
Training loss: 2.854905434293284
Validation loss: 2.5982190891946204

Epoch: 6| Step: 7
Training loss: 2.700093151181072
Validation loss: 2.5992226373880185

Epoch: 6| Step: 8
Training loss: 2.549477213208415
Validation loss: 2.5986137289086955

Epoch: 6| Step: 9
Training loss: 2.430856503217209
Validation loss: 2.59992211359691

Epoch: 6| Step: 10
Training loss: 3.041221498982207
Validation loss: 2.598223631424873

Epoch: 6| Step: 11
Training loss: 2.574423149456926
Validation loss: 2.5949703394444876

Epoch: 6| Step: 12
Training loss: 2.4947240471220584
Validation loss: 2.593641072019706

Epoch: 6| Step: 13
Training loss: 2.757078510764658
Validation loss: 2.5916040727798357

Epoch: 61| Step: 0
Training loss: 2.1449247739178645
Validation loss: 2.5891265106115733

Epoch: 6| Step: 1
Training loss: 2.6220854064393304
Validation loss: 2.587122727193143

Epoch: 6| Step: 2
Training loss: 2.3898581477888463
Validation loss: 2.584971129221149

Epoch: 6| Step: 3
Training loss: 2.8351942197013127
Validation loss: 2.582361212734241

Epoch: 6| Step: 4
Training loss: 2.8137677196620907
Validation loss: 2.5804947721944163

Epoch: 6| Step: 5
Training loss: 2.680697059080846
Validation loss: 2.578279201635522

Epoch: 6| Step: 6
Training loss: 3.1953492104209964
Validation loss: 2.5775537185423776

Epoch: 6| Step: 7
Training loss: 3.1036397670262565
Validation loss: 2.5757237050095525

Epoch: 6| Step: 8
Training loss: 2.756526831048101
Validation loss: 2.5784917705395443

Epoch: 6| Step: 9
Training loss: 2.541585754190588
Validation loss: 2.575021837506086

Epoch: 6| Step: 10
Training loss: 3.0547077929512967
Validation loss: 2.574682167956117

Epoch: 6| Step: 11
Training loss: 2.504808760174882
Validation loss: 2.5749544010013707

Epoch: 6| Step: 12
Training loss: 2.740871885482237
Validation loss: 2.5724111413020703

Epoch: 6| Step: 13
Training loss: 2.4839277524653918
Validation loss: 2.574687261015386

Epoch: 62| Step: 0
Training loss: 2.547197660824406
Validation loss: 2.5735018344010654

Epoch: 6| Step: 1
Training loss: 2.7135670685753723
Validation loss: 2.5701340571864315

Epoch: 6| Step: 2
Training loss: 2.9575826919358774
Validation loss: 2.571722414999249

Epoch: 6| Step: 3
Training loss: 2.755013923540603
Validation loss: 2.5677030200916175

Epoch: 6| Step: 4
Training loss: 2.4621989574473235
Validation loss: 2.570298508873672

Epoch: 6| Step: 5
Training loss: 3.2254585058464187
Validation loss: 2.568273522086756

Epoch: 6| Step: 6
Training loss: 2.699360955518226
Validation loss: 2.5697220159791323

Epoch: 6| Step: 7
Training loss: 2.4093382202982707
Validation loss: 2.5687353364227374

Epoch: 6| Step: 8
Training loss: 2.5137301114441764
Validation loss: 2.5686061029898872

Epoch: 6| Step: 9
Training loss: 2.5044129523992282
Validation loss: 2.5693655076373916

Epoch: 6| Step: 10
Training loss: 3.194033938213856
Validation loss: 2.568114928783364

Epoch: 6| Step: 11
Training loss: 2.4693381659121973
Validation loss: 2.5683012014165936

Epoch: 6| Step: 12
Training loss: 2.201764058402278
Validation loss: 2.5669007698241115

Epoch: 6| Step: 13
Training loss: 3.0206055303159647
Validation loss: 2.568661732638297

Epoch: 63| Step: 0
Training loss: 2.4607892672990506
Validation loss: 2.567351733677747

Epoch: 6| Step: 1
Training loss: 2.4025043216789506
Validation loss: 2.5655400765876633

Epoch: 6| Step: 2
Training loss: 2.947160945218962
Validation loss: 2.564767532076018

Epoch: 6| Step: 3
Training loss: 2.2119096431730134
Validation loss: 2.562726375225956

Epoch: 6| Step: 4
Training loss: 2.5341192866718076
Validation loss: 2.560813534932475

Epoch: 6| Step: 5
Training loss: 2.963022268107972
Validation loss: 2.5598552205203777

Epoch: 6| Step: 6
Training loss: 2.55156355774315
Validation loss: 2.5578703733750756

Epoch: 6| Step: 7
Training loss: 2.646247160580733
Validation loss: 2.560701801531581

Epoch: 6| Step: 8
Training loss: 2.4170526547044884
Validation loss: 2.558140667506136

Epoch: 6| Step: 9
Training loss: 2.851173687908298
Validation loss: 2.5600454778903403

Epoch: 6| Step: 10
Training loss: 2.8226822383897376
Validation loss: 2.5585825369009223

Epoch: 6| Step: 11
Training loss: 3.298001932924351
Validation loss: 2.559246028620692

Epoch: 6| Step: 12
Training loss: 2.46489752999471
Validation loss: 2.558547204446019

Epoch: 6| Step: 13
Training loss: 2.939325779789285
Validation loss: 2.5601118325850534

Epoch: 64| Step: 0
Training loss: 2.6983970793682523
Validation loss: 2.5578349378716707

Epoch: 6| Step: 1
Training loss: 2.6893653605982295
Validation loss: 2.561032503052129

Epoch: 6| Step: 2
Training loss: 2.345148101879917
Validation loss: 2.5539718387677235

Epoch: 6| Step: 3
Training loss: 2.496618845455762
Validation loss: 2.555139468592497

Epoch: 6| Step: 4
Training loss: 2.624312901262986
Validation loss: 2.5533001444712204

Epoch: 6| Step: 5
Training loss: 2.892721704478
Validation loss: 2.5529491175656185

Epoch: 6| Step: 6
Training loss: 2.713890116767341
Validation loss: 2.5533828281439397

Epoch: 6| Step: 7
Training loss: 2.689238762052141
Validation loss: 2.5516499884533967

Epoch: 6| Step: 8
Training loss: 2.1286031804775085
Validation loss: 2.5504429949759206

Epoch: 6| Step: 9
Training loss: 2.948834567278365
Validation loss: 2.548449772490065

Epoch: 6| Step: 10
Training loss: 2.838467564913404
Validation loss: 2.5486055669166996

Epoch: 6| Step: 11
Training loss: 2.72752175494643
Validation loss: 2.546136370623356

Epoch: 6| Step: 12
Training loss: 2.80980689067388
Validation loss: 2.543944914189928

Epoch: 6| Step: 13
Training loss: 2.875130857723809
Validation loss: 2.5464746671552936

Epoch: 65| Step: 0
Training loss: 2.4486903057056515
Validation loss: 2.5453796677599305

Epoch: 6| Step: 1
Training loss: 2.576510577028559
Validation loss: 2.544896876850835

Epoch: 6| Step: 2
Training loss: 2.9285710763432626
Validation loss: 2.5445047750590004

Epoch: 6| Step: 3
Training loss: 2.789946002095846
Validation loss: 2.5446766061544577

Epoch: 6| Step: 4
Training loss: 3.078865233358405
Validation loss: 2.5440974936237772

Epoch: 6| Step: 5
Training loss: 2.5116952091140217
Validation loss: 2.5451052314946447

Epoch: 6| Step: 6
Training loss: 2.5624220301233414
Validation loss: 2.5447232414557903

Epoch: 6| Step: 7
Training loss: 2.239418579665528
Validation loss: 2.542542077525593

Epoch: 6| Step: 8
Training loss: 2.853866524241033
Validation loss: 2.5458512384146106

Epoch: 6| Step: 9
Training loss: 2.3621448148929987
Validation loss: 2.545557473112254

Epoch: 6| Step: 10
Training loss: 3.2118940204889292
Validation loss: 2.5503512882286525

Epoch: 6| Step: 11
Training loss: 2.438419853165172
Validation loss: 2.549626788709181

Epoch: 6| Step: 12
Training loss: 2.890192772794925
Validation loss: 2.542855865270009

Epoch: 6| Step: 13
Training loss: 2.4140996343725614
Validation loss: 2.542109331032328

Epoch: 66| Step: 0
Training loss: 2.813156051413517
Validation loss: 2.540759320714284

Epoch: 6| Step: 1
Training loss: 2.8238330118609585
Validation loss: 2.5413614204425072

Epoch: 6| Step: 2
Training loss: 2.6821327730293674
Validation loss: 2.538302216776406

Epoch: 6| Step: 3
Training loss: 2.799659664042498
Validation loss: 2.5383295184745682

Epoch: 6| Step: 4
Training loss: 2.7226247252030733
Validation loss: 2.537467463367746

Epoch: 6| Step: 5
Training loss: 2.8296393455144764
Validation loss: 2.5351281304115103

Epoch: 6| Step: 6
Training loss: 2.332264132988146
Validation loss: 2.5363179088993677

Epoch: 6| Step: 7
Training loss: 3.2604635964490587
Validation loss: 2.5389938423459686

Epoch: 6| Step: 8
Training loss: 2.779599246360423
Validation loss: 2.5334283223246095

Epoch: 6| Step: 9
Training loss: 1.8801526794932284
Validation loss: 2.5328351069419464

Epoch: 6| Step: 10
Training loss: 2.4174478737103997
Validation loss: 2.533562471249822

Epoch: 6| Step: 11
Training loss: 2.849996225454943
Validation loss: 2.5316143401612496

Epoch: 6| Step: 12
Training loss: 2.848340699208845
Validation loss: 2.530011788643574

Epoch: 6| Step: 13
Training loss: 1.9946905231647152
Validation loss: 2.5279170019517276

Epoch: 67| Step: 0
Training loss: 2.8831206366379667
Validation loss: 2.5308419985890276

Epoch: 6| Step: 1
Training loss: 2.897371903386447
Validation loss: 2.529520338636868

Epoch: 6| Step: 2
Training loss: 2.7256838194254636
Validation loss: 2.5306116248892434

Epoch: 6| Step: 3
Training loss: 2.683348887459671
Validation loss: 2.530595781216182

Epoch: 6| Step: 4
Training loss: 2.581265473030766
Validation loss: 2.52952449368433

Epoch: 6| Step: 5
Training loss: 2.30026244449141
Validation loss: 2.529976481251723

Epoch: 6| Step: 6
Training loss: 2.457676643550353
Validation loss: 2.527558425205408

Epoch: 6| Step: 7
Training loss: 2.5125066728645646
Validation loss: 2.5294903105578914

Epoch: 6| Step: 8
Training loss: 2.7745011989682347
Validation loss: 2.524698231859956

Epoch: 6| Step: 9
Training loss: 2.8852647725325293
Validation loss: 2.523762503875295

Epoch: 6| Step: 10
Training loss: 2.2341231624356883
Validation loss: 2.5264491955246475

Epoch: 6| Step: 11
Training loss: 2.662613908363773
Validation loss: 2.525265215803298

Epoch: 6| Step: 12
Training loss: 2.3969453525289754
Validation loss: 2.5271626033651757

Epoch: 6| Step: 13
Training loss: 3.0555894695673307
Validation loss: 2.5243555215901203

Epoch: 68| Step: 0
Training loss: 2.582535456426012
Validation loss: 2.5260139437592906

Epoch: 6| Step: 1
Training loss: 2.552400177471117
Validation loss: 2.527448696215724

Epoch: 6| Step: 2
Training loss: 1.841748654653597
Validation loss: 2.5238106277537096

Epoch: 6| Step: 3
Training loss: 2.6381991829165314
Validation loss: 2.5259361218822276

Epoch: 6| Step: 4
Training loss: 2.5836277353031503
Validation loss: 2.527723029408946

Epoch: 6| Step: 5
Training loss: 3.3131940582395276
Validation loss: 2.5273535451645177

Epoch: 6| Step: 6
Training loss: 2.5203620428051092
Validation loss: 2.524339874771221

Epoch: 6| Step: 7
Training loss: 2.9733767143928063
Validation loss: 2.525947251800335

Epoch: 6| Step: 8
Training loss: 2.631943465886623
Validation loss: 2.530004406800786

Epoch: 6| Step: 9
Training loss: 2.438315719659079
Validation loss: 2.5255033463459884

Epoch: 6| Step: 10
Training loss: 2.6442663603834924
Validation loss: 2.5225279027871954

Epoch: 6| Step: 11
Training loss: 2.8807754556103418
Validation loss: 2.5246704522292442

Epoch: 6| Step: 12
Training loss: 2.7101771802800534
Validation loss: 2.524709201975546

Epoch: 6| Step: 13
Training loss: 2.5345809119097646
Validation loss: 2.5263404800542797

Epoch: 69| Step: 0
Training loss: 3.041058431629113
Validation loss: 2.5252734454810435

Epoch: 6| Step: 1
Training loss: 2.2240337802736585
Validation loss: 2.524031987350787

Epoch: 6| Step: 2
Training loss: 2.7103284871806315
Validation loss: 2.527391876438556

Epoch: 6| Step: 3
Training loss: 2.6166486954122514
Validation loss: 2.5231027292511765

Epoch: 6| Step: 4
Training loss: 2.73400545075326
Validation loss: 2.526453410671477

Epoch: 6| Step: 5
Training loss: 2.865587832876474
Validation loss: 2.5199418080892277

Epoch: 6| Step: 6
Training loss: 2.33478122021153
Validation loss: 2.5211330477348266

Epoch: 6| Step: 7
Training loss: 2.294886240581056
Validation loss: 2.519758095004458

Epoch: 6| Step: 8
Training loss: 2.797717601505019
Validation loss: 2.525023459020232

Epoch: 6| Step: 9
Training loss: 2.750776008009419
Validation loss: 2.524154671403004

Epoch: 6| Step: 10
Training loss: 2.749078075889076
Validation loss: 2.526669757794156

Epoch: 6| Step: 11
Training loss: 2.925705301396591
Validation loss: 2.5258466796077705

Epoch: 6| Step: 12
Training loss: 2.7000759326006154
Validation loss: 2.5280187885495633

Epoch: 6| Step: 13
Training loss: 2.3456649078381338
Validation loss: 2.524535641918347

Epoch: 70| Step: 0
Training loss: 2.595381809436787
Validation loss: 2.526319654971367

Epoch: 6| Step: 1
Training loss: 2.646441492387813
Validation loss: 2.527049044014519

Epoch: 6| Step: 2
Training loss: 2.27648260412308
Validation loss: 2.523289490129487

Epoch: 6| Step: 3
Training loss: 2.451457823833837
Validation loss: 2.524539986180722

Epoch: 6| Step: 4
Training loss: 3.0968991060213726
Validation loss: 2.5241007843520933

Epoch: 6| Step: 5
Training loss: 2.373694412359991
Validation loss: 2.5221628093397155

Epoch: 6| Step: 6
Training loss: 2.9656558325624895
Validation loss: 2.5219982124995877

Epoch: 6| Step: 7
Training loss: 2.3706156768736184
Validation loss: 2.517705227070414

Epoch: 6| Step: 8
Training loss: 3.2209610242975537
Validation loss: 2.5189577065925763

Epoch: 6| Step: 9
Training loss: 2.5251087052013217
Validation loss: 2.5186439233092655

Epoch: 6| Step: 10
Training loss: 2.9721615112695785
Validation loss: 2.5159586651585064

Epoch: 6| Step: 11
Training loss: 2.3615873965911747
Validation loss: 2.516358444358248

Epoch: 6| Step: 12
Training loss: 2.5926737563230113
Validation loss: 2.5148279811131293

Epoch: 6| Step: 13
Training loss: 2.4006532256938278
Validation loss: 2.5095543442196657

Epoch: 71| Step: 0
Training loss: 2.9604267897803056
Validation loss: 2.5115302110531164

Epoch: 6| Step: 1
Training loss: 2.4085407005008737
Validation loss: 2.5095563234761755

Epoch: 6| Step: 2
Training loss: 2.837321802669175
Validation loss: 2.5041557342451455

Epoch: 6| Step: 3
Training loss: 2.439082487856522
Validation loss: 2.5082377531739373

Epoch: 6| Step: 4
Training loss: 2.7121290946550127
Validation loss: 2.509397407960585

Epoch: 6| Step: 5
Training loss: 2.223421900165705
Validation loss: 2.5108186761339852

Epoch: 6| Step: 6
Training loss: 2.817600795834985
Validation loss: 2.510720441702552

Epoch: 6| Step: 7
Training loss: 2.5035805810295
Validation loss: 2.510964493447189

Epoch: 6| Step: 8
Training loss: 2.623472405042975
Validation loss: 2.511032659424337

Epoch: 6| Step: 9
Training loss: 2.6721808721348412
Validation loss: 2.510951326874583

Epoch: 6| Step: 10
Training loss: 2.4977361919841163
Validation loss: 2.509488093645158

Epoch: 6| Step: 11
Training loss: 3.0937367448619137
Validation loss: 2.5083194747068815

Epoch: 6| Step: 12
Training loss: 2.658965573917573
Validation loss: 2.51088178976783

Epoch: 6| Step: 13
Training loss: 2.497085684623441
Validation loss: 2.5103255818622627

Epoch: 72| Step: 0
Training loss: 1.9450762501850187
Validation loss: 2.509723303768298

Epoch: 6| Step: 1
Training loss: 2.850762743692501
Validation loss: 2.508839683076468

Epoch: 6| Step: 2
Training loss: 2.4018484706043863
Validation loss: 2.5093178672509846

Epoch: 6| Step: 3
Training loss: 2.472723069576271
Validation loss: 2.509637645817954

Epoch: 6| Step: 4
Training loss: 2.373710483023226
Validation loss: 2.5086448927958367

Epoch: 6| Step: 5
Training loss: 2.7521444109353306
Validation loss: 2.508923499382308

Epoch: 6| Step: 6
Training loss: 2.4263416079207882
Validation loss: 2.5072527901573123

Epoch: 6| Step: 7
Training loss: 3.0751898854251096
Validation loss: 2.5072291043226995

Epoch: 6| Step: 8
Training loss: 2.1906306072168786
Validation loss: 2.506523728108254

Epoch: 6| Step: 9
Training loss: 2.9595823382501667
Validation loss: 2.5053348363922927

Epoch: 6| Step: 10
Training loss: 2.4000267702834885
Validation loss: 2.5092614603860586

Epoch: 6| Step: 11
Training loss: 3.22985464991388
Validation loss: 2.508849756385982

Epoch: 6| Step: 12
Training loss: 2.9073720427259078
Validation loss: 2.509597238317082

Epoch: 6| Step: 13
Training loss: 2.6656130755785
Validation loss: 2.5064426693698887

Epoch: 73| Step: 0
Training loss: 2.858601616668511
Validation loss: 2.50633294340079

Epoch: 6| Step: 1
Training loss: 2.4263223483792564
Validation loss: 2.503990834474293

Epoch: 6| Step: 2
Training loss: 3.0734203033664333
Validation loss: 2.5039903583970675

Epoch: 6| Step: 3
Training loss: 2.849690028951991
Validation loss: 2.5042117721464527

Epoch: 6| Step: 4
Training loss: 2.3750021081212376
Validation loss: 2.5016277735984547

Epoch: 6| Step: 5
Training loss: 2.411743828260343
Validation loss: 2.5024223036618456

Epoch: 6| Step: 6
Training loss: 2.6377669899843177
Validation loss: 2.503147940782568

Epoch: 6| Step: 7
Training loss: 2.305307699257701
Validation loss: 2.50337541322182

Epoch: 6| Step: 8
Training loss: 1.8855668178504992
Validation loss: 2.502954993663931

Epoch: 6| Step: 9
Training loss: 2.767135293943061
Validation loss: 2.5044721815844313

Epoch: 6| Step: 10
Training loss: 2.585965251485578
Validation loss: 2.5060932132579175

Epoch: 6| Step: 11
Training loss: 2.67342327388365
Validation loss: 2.505956705868685

Epoch: 6| Step: 12
Training loss: 3.04805713120431
Validation loss: 2.505260289870137

Epoch: 6| Step: 13
Training loss: 2.6408012376469783
Validation loss: 2.5070359878756796

Epoch: 74| Step: 0
Training loss: 2.9197840425244586
Validation loss: 2.500476100410004

Epoch: 6| Step: 1
Training loss: 2.57981752267818
Validation loss: 2.500277074718552

Epoch: 6| Step: 2
Training loss: 2.591056988341533
Validation loss: 2.4974736323220066

Epoch: 6| Step: 3
Training loss: 2.7894276612319766
Validation loss: 2.50261283076464

Epoch: 6| Step: 4
Training loss: 2.2423690031271173
Validation loss: 2.5007966838448996

Epoch: 6| Step: 5
Training loss: 2.3350612055661912
Validation loss: 2.4972786715130066

Epoch: 6| Step: 6
Training loss: 3.0463513046532085
Validation loss: 2.497937790370663

Epoch: 6| Step: 7
Training loss: 2.9265890190523827
Validation loss: 2.504459218874188

Epoch: 6| Step: 8
Training loss: 2.7940285972600796
Validation loss: 2.49654261414127

Epoch: 6| Step: 9
Training loss: 2.4965675632617894
Validation loss: 2.498716939058928

Epoch: 6| Step: 10
Training loss: 2.8952411805461518
Validation loss: 2.500368520278136

Epoch: 6| Step: 11
Training loss: 2.5097791144457524
Validation loss: 2.4985859050495978

Epoch: 6| Step: 12
Training loss: 2.1200687186781764
Validation loss: 2.5012751347316167

Epoch: 6| Step: 13
Training loss: 2.2227570790783173
Validation loss: 2.501335717047421

Epoch: 75| Step: 0
Training loss: 2.5429515925940493
Validation loss: 2.500581363792083

Epoch: 6| Step: 1
Training loss: 2.21378813923443
Validation loss: 2.5026359966263785

Epoch: 6| Step: 2
Training loss: 2.3781806327738924
Validation loss: 2.497425358942154

Epoch: 6| Step: 3
Training loss: 2.4778013770895035
Validation loss: 2.5015358975274875

Epoch: 6| Step: 4
Training loss: 2.3788356927139143
Validation loss: 2.4967814549320138

Epoch: 6| Step: 5
Training loss: 2.7966986232958098
Validation loss: 2.5011556656317335

Epoch: 6| Step: 6
Training loss: 2.664709286748883
Validation loss: 2.493416239138693

Epoch: 6| Step: 7
Training loss: 2.6005596255533825
Validation loss: 2.4970374355705416

Epoch: 6| Step: 8
Training loss: 2.6261010358596666
Validation loss: 2.509171613762053

Epoch: 6| Step: 9
Training loss: 2.74408032768496
Validation loss: 2.499897970660719

Epoch: 6| Step: 10
Training loss: 2.590110247264981
Validation loss: 2.5095419777896466

Epoch: 6| Step: 11
Training loss: 3.504579545295932
Validation loss: 2.499727059405903

Epoch: 6| Step: 12
Training loss: 2.56760224180562
Validation loss: 2.492976686534165

Epoch: 6| Step: 13
Training loss: 2.643563706347748
Validation loss: 2.497136940264273

Epoch: 76| Step: 0
Training loss: 2.310850225094085
Validation loss: 2.5005281049520294

Epoch: 6| Step: 1
Training loss: 3.0179391786932195
Validation loss: 2.5036566853445126

Epoch: 6| Step: 2
Training loss: 2.682641716988326
Validation loss: 2.5150304214073538

Epoch: 6| Step: 3
Training loss: 2.6782332942615756
Validation loss: 2.516852653864596

Epoch: 6| Step: 4
Training loss: 2.5542156005287366
Validation loss: 2.524934275561757

Epoch: 6| Step: 5
Training loss: 2.2541541850742797
Validation loss: 2.543086504810103

Epoch: 6| Step: 6
Training loss: 2.9528356339711834
Validation loss: 2.5505451523473956

Epoch: 6| Step: 7
Training loss: 2.5144948375419074
Validation loss: 2.540912670070009

Epoch: 6| Step: 8
Training loss: 3.054773353872636
Validation loss: 2.530609316649688

Epoch: 6| Step: 9
Training loss: 2.5061963539375256
Validation loss: 2.524298931278129

Epoch: 6| Step: 10
Training loss: 2.478025852447211
Validation loss: 2.517861235182714

Epoch: 6| Step: 11
Training loss: 2.845826114256282
Validation loss: 2.5115587530598225

Epoch: 6| Step: 12
Training loss: 2.454326068340869
Validation loss: 2.5058080757660313

Epoch: 6| Step: 13
Training loss: 2.601434561301398
Validation loss: 2.503049627559127

Epoch: 77| Step: 0
Training loss: 2.2992542426130416
Validation loss: 2.498745444546329

Epoch: 6| Step: 1
Training loss: 2.6969322755462466
Validation loss: 2.492320393015684

Epoch: 6| Step: 2
Training loss: 3.0528521475402655
Validation loss: 2.49395517064531

Epoch: 6| Step: 3
Training loss: 2.070166931792768
Validation loss: 2.4901240305669137

Epoch: 6| Step: 4
Training loss: 2.1421739306531395
Validation loss: 2.4934190917778807

Epoch: 6| Step: 5
Training loss: 2.2970252993448024
Validation loss: 2.502996683185334

Epoch: 6| Step: 6
Training loss: 2.678126823219916
Validation loss: 2.509539238482563

Epoch: 6| Step: 7
Training loss: 3.0943288550560397
Validation loss: 2.5140860768839257

Epoch: 6| Step: 8
Training loss: 2.7113965440104977
Validation loss: 2.516975782580767

Epoch: 6| Step: 9
Training loss: 2.6162719947265853
Validation loss: 2.5086293855850825

Epoch: 6| Step: 10
Training loss: 2.609641147220599
Validation loss: 2.506461947414213

Epoch: 6| Step: 11
Training loss: 3.0045478046414864
Validation loss: 2.4978617265739933

Epoch: 6| Step: 12
Training loss: 2.8006619011683225
Validation loss: 2.4994547090302905

Epoch: 6| Step: 13
Training loss: 2.731692060577924
Validation loss: 2.4972643825926313

Epoch: 78| Step: 0
Training loss: 2.7334772870683337
Validation loss: 2.496008866070219

Epoch: 6| Step: 1
Training loss: 2.688616498526233
Validation loss: 2.490556284723575

Epoch: 6| Step: 2
Training loss: 2.5205962539876263
Validation loss: 2.494093497958005

Epoch: 6| Step: 3
Training loss: 2.4105741611507145
Validation loss: 2.493924658577751

Epoch: 6| Step: 4
Training loss: 2.8134949513727845
Validation loss: 2.497871478268289

Epoch: 6| Step: 5
Training loss: 2.365101918449977
Validation loss: 2.4991151515344523

Epoch: 6| Step: 6
Training loss: 3.001912143405205
Validation loss: 2.4977075874780805

Epoch: 6| Step: 7
Training loss: 2.2028797635423754
Validation loss: 2.499633269432508

Epoch: 6| Step: 8
Training loss: 2.369638514897194
Validation loss: 2.502569943980338

Epoch: 6| Step: 9
Training loss: 2.6729129314520397
Validation loss: 2.501069873130165

Epoch: 6| Step: 10
Training loss: 2.337723065508822
Validation loss: 2.498410371208061

Epoch: 6| Step: 11
Training loss: 2.655498084063118
Validation loss: 2.4979482496575307

Epoch: 6| Step: 12
Training loss: 2.7399757790713153
Validation loss: 2.4974722799163565

Epoch: 6| Step: 13
Training loss: 3.241410274875484
Validation loss: 2.497537815061007

Epoch: 79| Step: 0
Training loss: 2.8650849244211782
Validation loss: 2.498890233089202

Epoch: 6| Step: 1
Training loss: 2.251196437200616
Validation loss: 2.4959890456071343

Epoch: 6| Step: 2
Training loss: 2.813429191532174
Validation loss: 2.4941936777039175

Epoch: 6| Step: 3
Training loss: 2.232736800601015
Validation loss: 2.490637964193378

Epoch: 6| Step: 4
Training loss: 2.1845415000055692
Validation loss: 2.4913221429388575

Epoch: 6| Step: 5
Training loss: 2.76494439150196
Validation loss: 2.4898723663291125

Epoch: 6| Step: 6
Training loss: 3.04978467462614
Validation loss: 2.4844366901663775

Epoch: 6| Step: 7
Training loss: 2.4247822693285066
Validation loss: 2.48448761498828

Epoch: 6| Step: 8
Training loss: 2.364439524396081
Validation loss: 2.4840953837492985

Epoch: 6| Step: 9
Training loss: 2.7309768924301254
Validation loss: 2.4842110985646224

Epoch: 6| Step: 10
Training loss: 2.359913543475316
Validation loss: 2.486137996175397

Epoch: 6| Step: 11
Training loss: 2.8940071733197335
Validation loss: 2.482034744582029

Epoch: 6| Step: 12
Training loss: 3.0426636372728617
Validation loss: 2.48495281545666

Epoch: 6| Step: 13
Training loss: 2.5689565682249804
Validation loss: 2.4824117424710845

Epoch: 80| Step: 0
Training loss: 2.3274163313269485
Validation loss: 2.484444615250428

Epoch: 6| Step: 1
Training loss: 2.692752672982653
Validation loss: 2.4847374417776082

Epoch: 6| Step: 2
Training loss: 2.3799297968343747
Validation loss: 2.484503696715016

Epoch: 6| Step: 3
Training loss: 2.8640370535877726
Validation loss: 2.4853593967316767

Epoch: 6| Step: 4
Training loss: 2.128787088121481
Validation loss: 2.4826421392340974

Epoch: 6| Step: 5
Training loss: 2.5829148620149533
Validation loss: 2.485918968798167

Epoch: 6| Step: 6
Training loss: 1.837292564776267
Validation loss: 2.485811885630811

Epoch: 6| Step: 7
Training loss: 3.1338920730868884
Validation loss: 2.4828283905999604

Epoch: 6| Step: 8
Training loss: 2.7787172593741785
Validation loss: 2.4849254390243125

Epoch: 6| Step: 9
Training loss: 2.3942480619912034
Validation loss: 2.487309080813217

Epoch: 6| Step: 10
Training loss: 2.82673788037953
Validation loss: 2.488848826593541

Epoch: 6| Step: 11
Training loss: 2.742841332892425
Validation loss: 2.488794230986624

Epoch: 6| Step: 12
Training loss: 2.919476998927312
Validation loss: 2.491155173408938

Epoch: 6| Step: 13
Training loss: 2.6940416961422438
Validation loss: 2.4913700241879533

Epoch: 81| Step: 0
Training loss: 2.1461651246179696
Validation loss: 2.491062161359528

Epoch: 6| Step: 1
Training loss: 2.9540131055971215
Validation loss: 2.491179833541371

Epoch: 6| Step: 2
Training loss: 2.718692910482905
Validation loss: 2.4917493891513205

Epoch: 6| Step: 3
Training loss: 2.389252411982728
Validation loss: 2.490330577313537

Epoch: 6| Step: 4
Training loss: 2.1816170195119535
Validation loss: 2.49064160975235

Epoch: 6| Step: 5
Training loss: 2.959356122223564
Validation loss: 2.485798841597987

Epoch: 6| Step: 6
Training loss: 2.549833112753277
Validation loss: 2.4866122682500165

Epoch: 6| Step: 7
Training loss: 2.837949097169468
Validation loss: 2.484635425409431

Epoch: 6| Step: 8
Training loss: 2.7904014472229295
Validation loss: 2.4849200660442405

Epoch: 6| Step: 9
Training loss: 3.045311472830445
Validation loss: 2.48304439395605

Epoch: 6| Step: 10
Training loss: 2.311670927975703
Validation loss: 2.480746668667709

Epoch: 6| Step: 11
Training loss: 2.2411360451811606
Validation loss: 2.4838640179355083

Epoch: 6| Step: 12
Training loss: 2.4062876512628573
Validation loss: 2.4813313583756993

Epoch: 6| Step: 13
Training loss: 2.7650887351947633
Validation loss: 2.484252766735134

Epoch: 82| Step: 0
Training loss: 3.0966153217845513
Validation loss: 2.483408854016814

Epoch: 6| Step: 1
Training loss: 2.160459417829376
Validation loss: 2.4824652539216543

Epoch: 6| Step: 2
Training loss: 1.9899433735597516
Validation loss: 2.4773644112734203

Epoch: 6| Step: 3
Training loss: 2.3083995860079427
Validation loss: 2.482408332937837

Epoch: 6| Step: 4
Training loss: 2.8883152987325635
Validation loss: 2.4790264351771376

Epoch: 6| Step: 5
Training loss: 2.3404721545034155
Validation loss: 2.4881160088352474

Epoch: 6| Step: 6
Training loss: 2.669455520319336
Validation loss: 2.478295266586574

Epoch: 6| Step: 7
Training loss: 2.29977089113968
Validation loss: 2.4765632541145917

Epoch: 6| Step: 8
Training loss: 2.9044590836090936
Validation loss: 2.476567056774035

Epoch: 6| Step: 9
Training loss: 2.8725270125776503
Validation loss: 2.4758395514661045

Epoch: 6| Step: 10
Training loss: 3.1495177732439443
Validation loss: 2.4816175468849266

Epoch: 6| Step: 11
Training loss: 2.6725576320675315
Validation loss: 2.4829737392250024

Epoch: 6| Step: 12
Training loss: 2.0378906858362678
Validation loss: 2.482857646655708

Epoch: 6| Step: 13
Training loss: 2.6610311226270165
Validation loss: 2.4794939824153275

Epoch: 83| Step: 0
Training loss: 2.793270068153994
Validation loss: 2.479517997295862

Epoch: 6| Step: 1
Training loss: 2.7351645065570898
Validation loss: 2.478742119691153

Epoch: 6| Step: 2
Training loss: 2.4227604385700614
Validation loss: 2.48243727380362

Epoch: 6| Step: 3
Training loss: 2.257220550341619
Validation loss: 2.476539042108032

Epoch: 6| Step: 4
Training loss: 2.9351285736671775
Validation loss: 2.477681650186833

Epoch: 6| Step: 5
Training loss: 1.8508966592704035
Validation loss: 2.4765475781108526

Epoch: 6| Step: 6
Training loss: 3.0666536462203333
Validation loss: 2.4741176406698733

Epoch: 6| Step: 7
Training loss: 2.7259986972203993
Validation loss: 2.4755305277124067

Epoch: 6| Step: 8
Training loss: 2.8341267166829045
Validation loss: 2.4733217618351113

Epoch: 6| Step: 9
Training loss: 2.8339389452983474
Validation loss: 2.476428448471686

Epoch: 6| Step: 10
Training loss: 2.2630377367542134
Validation loss: 2.4748119822284664

Epoch: 6| Step: 11
Training loss: 2.602749665347224
Validation loss: 2.478601476747086

Epoch: 6| Step: 12
Training loss: 2.6804395682409443
Validation loss: 2.476505282891308

Epoch: 6| Step: 13
Training loss: 1.9758494904220993
Validation loss: 2.476073881738663

Epoch: 84| Step: 0
Training loss: 2.448059294312881
Validation loss: 2.4698437066765067

Epoch: 6| Step: 1
Training loss: 2.4956522328729713
Validation loss: 2.466860663887237

Epoch: 6| Step: 2
Training loss: 2.6180569699050587
Validation loss: 2.467965109913923

Epoch: 6| Step: 3
Training loss: 3.1049119366183757
Validation loss: 2.4710430006986273

Epoch: 6| Step: 4
Training loss: 2.8515822318452586
Validation loss: 2.4714309364242433

Epoch: 6| Step: 5
Training loss: 2.0260411305823185
Validation loss: 2.468045516438825

Epoch: 6| Step: 6
Training loss: 2.0948574496549877
Validation loss: 2.472253414081103

Epoch: 6| Step: 7
Training loss: 2.645051214807584
Validation loss: 2.4805715304329365

Epoch: 6| Step: 8
Training loss: 2.6783461703087994
Validation loss: 2.484760134612484

Epoch: 6| Step: 9
Training loss: 2.6886561368752937
Validation loss: 2.482944292492109

Epoch: 6| Step: 10
Training loss: 2.587937425873983
Validation loss: 2.4860041492925724

Epoch: 6| Step: 11
Training loss: 2.646673284453503
Validation loss: 2.480498386316147

Epoch: 6| Step: 12
Training loss: 2.698689609009144
Validation loss: 2.4764529904964467

Epoch: 6| Step: 13
Training loss: 2.684981385775639
Validation loss: 2.4772429629503194

Epoch: 85| Step: 0
Training loss: 2.614892665199223
Validation loss: 2.473177356257361

Epoch: 6| Step: 1
Training loss: 2.273673762993205
Validation loss: 2.4755826309252242

Epoch: 6| Step: 2
Training loss: 2.4613615124860684
Validation loss: 2.4742622001485666

Epoch: 6| Step: 3
Training loss: 2.3685069419947546
Validation loss: 2.472108206697501

Epoch: 6| Step: 4
Training loss: 1.886077455954776
Validation loss: 2.4714398437912837

Epoch: 6| Step: 5
Training loss: 3.1921968449676603
Validation loss: 2.476446933236054

Epoch: 6| Step: 6
Training loss: 2.5971483694944584
Validation loss: 2.4712704053752517

Epoch: 6| Step: 7
Training loss: 2.1884905071231326
Validation loss: 2.4733641757567257

Epoch: 6| Step: 8
Training loss: 2.3751520810875832
Validation loss: 2.471248521278568

Epoch: 6| Step: 9
Training loss: 2.920937617277349
Validation loss: 2.4719527028599053

Epoch: 6| Step: 10
Training loss: 2.348700622721708
Validation loss: 2.4715059405968085

Epoch: 6| Step: 11
Training loss: 2.630518697927788
Validation loss: 2.474339286518845

Epoch: 6| Step: 12
Training loss: 3.2625748841325857
Validation loss: 2.4716743661096494

Epoch: 6| Step: 13
Training loss: 2.6840214950621784
Validation loss: 2.472914294075946

Epoch: 86| Step: 0
Training loss: 2.768491304940253
Validation loss: 2.4784493303463515

Epoch: 6| Step: 1
Training loss: 2.4651433940909353
Validation loss: 2.479118400125254

Epoch: 6| Step: 2
Training loss: 2.6715723948307173
Validation loss: 2.480918495075639

Epoch: 6| Step: 3
Training loss: 2.5796471003991335
Validation loss: 2.4837114419617596

Epoch: 6| Step: 4
Training loss: 2.2213985055580654
Validation loss: 2.477802162900978

Epoch: 6| Step: 5
Training loss: 3.153721164567009
Validation loss: 2.4801068059420763

Epoch: 6| Step: 6
Training loss: 2.5258267550465114
Validation loss: 2.4795319798268727

Epoch: 6| Step: 7
Training loss: 2.647798804404511
Validation loss: 2.481105964893714

Epoch: 6| Step: 8
Training loss: 2.0982251523556825
Validation loss: 2.4799671376778765

Epoch: 6| Step: 9
Training loss: 2.502709065335092
Validation loss: 2.4799921654249335

Epoch: 6| Step: 10
Training loss: 2.753573090441635
Validation loss: 2.4782015955000607

Epoch: 6| Step: 11
Training loss: 2.435976383664764
Validation loss: 2.4746992801913033

Epoch: 6| Step: 12
Training loss: 2.271701844974586
Validation loss: 2.475905177733428

Epoch: 6| Step: 13
Training loss: 2.9584510851425536
Validation loss: 2.4707018222730013

Epoch: 87| Step: 0
Training loss: 2.5151255804906496
Validation loss: 2.475091491318274

Epoch: 6| Step: 1
Training loss: 2.6198843199548083
Validation loss: 2.47144354178622

Epoch: 6| Step: 2
Training loss: 2.4431749452651537
Validation loss: 2.471365199384325

Epoch: 6| Step: 3
Training loss: 2.226162416083607
Validation loss: 2.4731803527426957

Epoch: 6| Step: 4
Training loss: 2.6571655490744246
Validation loss: 2.4695865163519244

Epoch: 6| Step: 5
Training loss: 2.2010468766499383
Validation loss: 2.466439884517521

Epoch: 6| Step: 6
Training loss: 3.1482566611177782
Validation loss: 2.4699554880278196

Epoch: 6| Step: 7
Training loss: 2.743731202775873
Validation loss: 2.466751384139466

Epoch: 6| Step: 8
Training loss: 2.715908187657116
Validation loss: 2.467880611007091

Epoch: 6| Step: 9
Training loss: 2.428851704492679
Validation loss: 2.4769855863911303

Epoch: 6| Step: 10
Training loss: 2.5555160998555837
Validation loss: 2.476842661834284

Epoch: 6| Step: 11
Training loss: 2.7884083897106677
Validation loss: 2.475552534471187

Epoch: 6| Step: 12
Training loss: 2.4333607667743915
Validation loss: 2.4763340488646244

Epoch: 6| Step: 13
Training loss: 2.5789262855766135
Validation loss: 2.475079514610143

Epoch: 88| Step: 0
Training loss: 2.169298688534925
Validation loss: 2.4750134169089657

Epoch: 6| Step: 1
Training loss: 2.690169405938538
Validation loss: 2.4707403569689332

Epoch: 6| Step: 2
Training loss: 2.714759265490749
Validation loss: 2.476452773879443

Epoch: 6| Step: 3
Training loss: 3.0493398233313216
Validation loss: 2.4754120955665537

Epoch: 6| Step: 4
Training loss: 2.5724390387100797
Validation loss: 2.4735757685892428

Epoch: 6| Step: 5
Training loss: 2.529902535170748
Validation loss: 2.47275510472843

Epoch: 6| Step: 6
Training loss: 2.7107618643291627
Validation loss: 2.470590251611017

Epoch: 6| Step: 7
Training loss: 1.9968376191987944
Validation loss: 2.4748810877635603

Epoch: 6| Step: 8
Training loss: 2.036489214910978
Validation loss: 2.4704252104328113

Epoch: 6| Step: 9
Training loss: 2.793469620189362
Validation loss: 2.4705029473111204

Epoch: 6| Step: 10
Training loss: 2.6117382198318926
Validation loss: 2.469184209568387

Epoch: 6| Step: 11
Training loss: 2.768371597506354
Validation loss: 2.4642423207350195

Epoch: 6| Step: 12
Training loss: 2.608917013396188
Validation loss: 2.4666779913083863

Epoch: 6| Step: 13
Training loss: 2.6677052938872725
Validation loss: 2.4637100183709486

Epoch: 89| Step: 0
Training loss: 2.250869900706393
Validation loss: 2.469701414632618

Epoch: 6| Step: 1
Training loss: 2.59031928344236
Validation loss: 2.471166594890222

Epoch: 6| Step: 2
Training loss: 2.4608514679902496
Validation loss: 2.473076839342818

Epoch: 6| Step: 3
Training loss: 2.5375586178778726
Validation loss: 2.4757800224913464

Epoch: 6| Step: 4
Training loss: 2.7836707220963466
Validation loss: 2.4831351939357846

Epoch: 6| Step: 5
Training loss: 3.1157472576921124
Validation loss: 2.4866261469690496

Epoch: 6| Step: 6
Training loss: 2.3850522380682166
Validation loss: 2.483323728512958

Epoch: 6| Step: 7
Training loss: 2.5877983105586826
Validation loss: 2.4860048366068908

Epoch: 6| Step: 8
Training loss: 2.7915677484855648
Validation loss: 2.486863095968536

Epoch: 6| Step: 9
Training loss: 2.4520541240947833
Validation loss: 2.4840232712100434

Epoch: 6| Step: 10
Training loss: 2.5356001031907183
Validation loss: 2.4832677072989306

Epoch: 6| Step: 11
Training loss: 2.459386815354153
Validation loss: 2.482225667951479

Epoch: 6| Step: 12
Training loss: 2.8180838362309455
Validation loss: 2.4824354009812546

Epoch: 6| Step: 13
Training loss: 2.5385217648366374
Validation loss: 2.4781330636058843

Epoch: 90| Step: 0
Training loss: 2.2608450089671193
Validation loss: 2.474383015906703

Epoch: 6| Step: 1
Training loss: 2.731284525847282
Validation loss: 2.4721432957807807

Epoch: 6| Step: 2
Training loss: 2.652829649608378
Validation loss: 2.477498548489943

Epoch: 6| Step: 3
Training loss: 2.279449693121763
Validation loss: 2.475469193474068

Epoch: 6| Step: 4
Training loss: 3.0548173725588734
Validation loss: 2.471591344505811

Epoch: 6| Step: 5
Training loss: 2.963368728678045
Validation loss: 2.4738995086636537

Epoch: 6| Step: 6
Training loss: 2.283206048837948
Validation loss: 2.473135083736891

Epoch: 6| Step: 7
Training loss: 2.480871357120775
Validation loss: 2.4725449603820424

Epoch: 6| Step: 8
Training loss: 2.784501136465829
Validation loss: 2.4672085903458933

Epoch: 6| Step: 9
Training loss: 1.4952642068269317
Validation loss: 2.4682311466485736

Epoch: 6| Step: 10
Training loss: 2.420001677520423
Validation loss: 2.4683440957187863

Epoch: 6| Step: 11
Training loss: 2.5094703589689886
Validation loss: 2.468345254804459

Epoch: 6| Step: 12
Training loss: 3.119719812821378
Validation loss: 2.4662117121811997

Epoch: 6| Step: 13
Training loss: 2.532581026488827
Validation loss: 2.469273322607777

Epoch: 91| Step: 0
Training loss: 2.2818919284582346
Validation loss: 2.4563004984368284

Epoch: 6| Step: 1
Training loss: 2.7363131384537853
Validation loss: 2.4658190152507933

Epoch: 6| Step: 2
Training loss: 2.523726219454424
Validation loss: 2.461316599231399

Epoch: 6| Step: 3
Training loss: 2.45462223697108
Validation loss: 2.4610702075195108

Epoch: 6| Step: 4
Training loss: 2.727042169651242
Validation loss: 2.4621992640805948

Epoch: 6| Step: 5
Training loss: 2.4014883115548717
Validation loss: 2.4756212501590573

Epoch: 6| Step: 6
Training loss: 2.7703801886416097
Validation loss: 2.473844173541373

Epoch: 6| Step: 7
Training loss: 2.4057358031350997
Validation loss: 2.476270544129619

Epoch: 6| Step: 8
Training loss: 2.6847385147038034
Validation loss: 2.477553882186166

Epoch: 6| Step: 9
Training loss: 2.5967192601993547
Validation loss: 2.478594166237953

Epoch: 6| Step: 10
Training loss: 2.7877249622659117
Validation loss: 2.476308847749025

Epoch: 6| Step: 11
Training loss: 2.4434981272428584
Validation loss: 2.475666112560811

Epoch: 6| Step: 12
Training loss: 2.5991237997972245
Validation loss: 2.4748723533414942

Epoch: 6| Step: 13
Training loss: 2.897911990664942
Validation loss: 2.477434103224443

Epoch: 92| Step: 0
Training loss: 2.532210273852114
Validation loss: 2.477762006011892

Epoch: 6| Step: 1
Training loss: 2.4303315219868042
Validation loss: 2.4722043026644975

Epoch: 6| Step: 2
Training loss: 2.962617181319469
Validation loss: 2.464492426206323

Epoch: 6| Step: 3
Training loss: 2.57054670478494
Validation loss: 2.467445205780929

Epoch: 6| Step: 4
Training loss: 2.558247084100859
Validation loss: 2.46915759170449

Epoch: 6| Step: 5
Training loss: 2.2482254660001697
Validation loss: 2.4657544822844226

Epoch: 6| Step: 6
Training loss: 1.9392368161450544
Validation loss: 2.4669885024833804

Epoch: 6| Step: 7
Training loss: 2.859177379345335
Validation loss: 2.463972676312475

Epoch: 6| Step: 8
Training loss: 2.293367263502284
Validation loss: 2.464426423465944

Epoch: 6| Step: 9
Training loss: 2.654936521816574
Validation loss: 2.4628514673204305

Epoch: 6| Step: 10
Training loss: 2.5807492858123013
Validation loss: 2.4707848576834373

Epoch: 6| Step: 11
Training loss: 3.0734629689622146
Validation loss: 2.4667825222730464

Epoch: 6| Step: 12
Training loss: 2.39694137381871
Validation loss: 2.4660306189967613

Epoch: 6| Step: 13
Training loss: 2.6742243560277568
Validation loss: 2.4691374913256956

Epoch: 93| Step: 0
Training loss: 2.212537099236265
Validation loss: 2.464124490993846

Epoch: 6| Step: 1
Training loss: 2.292874751853129
Validation loss: 2.4704365823987082

Epoch: 6| Step: 2
Training loss: 2.366653533236459
Validation loss: 2.468864599215815

Epoch: 6| Step: 3
Training loss: 2.405207023989218
Validation loss: 2.4648582429857773

Epoch: 6| Step: 4
Training loss: 2.8644787208644362
Validation loss: 2.464142100504448

Epoch: 6| Step: 5
Training loss: 2.2183061612493034
Validation loss: 2.45959810814633

Epoch: 6| Step: 6
Training loss: 2.567673647467665
Validation loss: 2.459180917477744

Epoch: 6| Step: 7
Training loss: 2.6726136552928415
Validation loss: 2.465063078281511

Epoch: 6| Step: 8
Training loss: 2.592839460376434
Validation loss: 2.466410981492845

Epoch: 6| Step: 9
Training loss: 2.333360762661974
Validation loss: 2.4621315133383916

Epoch: 6| Step: 10
Training loss: 3.3297085285641552
Validation loss: 2.4677702492745035

Epoch: 6| Step: 11
Training loss: 2.68020224562506
Validation loss: 2.466165114867508

Epoch: 6| Step: 12
Training loss: 2.903143093681001
Validation loss: 2.473188281762783

Epoch: 6| Step: 13
Training loss: 2.2464835981308973
Validation loss: 2.472394177056103

Epoch: 94| Step: 0
Training loss: 2.716353664816281
Validation loss: 2.4690238704153233

Epoch: 6| Step: 1
Training loss: 2.1170564167504136
Validation loss: 2.4724505089312054

Epoch: 6| Step: 2
Training loss: 2.4306425811688888
Validation loss: 2.4735780416961806

Epoch: 6| Step: 3
Training loss: 2.432863177860091
Validation loss: 2.4737910699350563

Epoch: 6| Step: 4
Training loss: 2.4007070533019905
Validation loss: 2.4693899492168367

Epoch: 6| Step: 5
Training loss: 2.5697841854989076
Validation loss: 2.4689650301099038

Epoch: 6| Step: 6
Training loss: 1.977131818117231
Validation loss: 2.472909473471931

Epoch: 6| Step: 7
Training loss: 2.5876226092051517
Validation loss: 2.4721918217317396

Epoch: 6| Step: 8
Training loss: 2.2550697430908015
Validation loss: 2.4717316468182076

Epoch: 6| Step: 9
Training loss: 2.5569389291630493
Validation loss: 2.470655840394863

Epoch: 6| Step: 10
Training loss: 2.5233726847447095
Validation loss: 2.4716141580400364

Epoch: 6| Step: 11
Training loss: 2.758819050583696
Validation loss: 2.468204582903862

Epoch: 6| Step: 12
Training loss: 3.4391700155877967
Validation loss: 2.470305713159261

Epoch: 6| Step: 13
Training loss: 2.822378991829933
Validation loss: 2.4708347290532595

Epoch: 95| Step: 0
Training loss: 2.488083668384435
Validation loss: 2.462940398078091

Epoch: 6| Step: 1
Training loss: 2.102407746349214
Validation loss: 2.46541171777162

Epoch: 6| Step: 2
Training loss: 2.9825328314126067
Validation loss: 2.4585810444918414

Epoch: 6| Step: 3
Training loss: 2.28169496978006
Validation loss: 2.456989281906952

Epoch: 6| Step: 4
Training loss: 2.2190001440748706
Validation loss: 2.457719287046507

Epoch: 6| Step: 5
Training loss: 2.430812661029986
Validation loss: 2.4635848887699856

Epoch: 6| Step: 6
Training loss: 2.786410997410554
Validation loss: 2.4566352173316117

Epoch: 6| Step: 7
Training loss: 2.534938620702675
Validation loss: 2.4635119984125984

Epoch: 6| Step: 8
Training loss: 2.0601622308348433
Validation loss: 2.460366480544563

Epoch: 6| Step: 9
Training loss: 2.663897198781336
Validation loss: 2.452856790252325

Epoch: 6| Step: 10
Training loss: 2.4889802295333348
Validation loss: 2.459924463130662

Epoch: 6| Step: 11
Training loss: 2.567372133066653
Validation loss: 2.460579514073778

Epoch: 6| Step: 12
Training loss: 3.490837228687402
Validation loss: 2.4588407757849717

Epoch: 6| Step: 13
Training loss: 2.461702355100515
Validation loss: 2.461632847313659

Epoch: 96| Step: 0
Training loss: 2.9525680420453844
Validation loss: 2.4610250629004993

Epoch: 6| Step: 1
Training loss: 2.435572326576117
Validation loss: 2.4591873161959663

Epoch: 6| Step: 2
Training loss: 2.9511712286978113
Validation loss: 2.4633799224942154

Epoch: 6| Step: 3
Training loss: 3.0782768095892674
Validation loss: 2.4617425802617534

Epoch: 6| Step: 4
Training loss: 2.3324184894936493
Validation loss: 2.467726209475651

Epoch: 6| Step: 5
Training loss: 2.802642671899166
Validation loss: 2.47381871415065

Epoch: 6| Step: 6
Training loss: 1.6915752511466193
Validation loss: 2.47389237700765

Epoch: 6| Step: 7
Training loss: 2.266560118171832
Validation loss: 2.4762687950184836

Epoch: 6| Step: 8
Training loss: 2.3474520119991626
Validation loss: 2.479663564001208

Epoch: 6| Step: 9
Training loss: 2.665424435081291
Validation loss: 2.478038857218737

Epoch: 6| Step: 10
Training loss: 2.4785210118637284
Validation loss: 2.475638601331065

Epoch: 6| Step: 11
Training loss: 2.09375
Validation loss: 2.477369030731533

Epoch: 6| Step: 12
Training loss: 2.91007022602513
Validation loss: 2.4752314748314506

Epoch: 6| Step: 13
Training loss: 2.9615492377528145
Validation loss: 2.4767193829799132

Epoch: 97| Step: 0
Training loss: 2.515811889530093
Validation loss: 2.4742586669657016

Epoch: 6| Step: 1
Training loss: 2.6259842798382786
Validation loss: 2.4763493009911604

Epoch: 6| Step: 2
Training loss: 2.1775215352829678
Validation loss: 2.473827612920158

Epoch: 6| Step: 3
Training loss: 2.5845629216684265
Validation loss: 2.4717009407937325

Epoch: 6| Step: 4
Training loss: 2.2023872601235888
Validation loss: 2.4728899338607504

Epoch: 6| Step: 5
Training loss: 2.6962179680956684
Validation loss: 2.4751122577653204

Epoch: 6| Step: 6
Training loss: 2.6885142519436367
Validation loss: 2.4712919676939062

Epoch: 6| Step: 7
Training loss: 2.5546623018754424
Validation loss: 2.4732550387658776

Epoch: 6| Step: 8
Training loss: 2.9080660488598347
Validation loss: 2.4696308125972974

Epoch: 6| Step: 9
Training loss: 2.5794461650935308
Validation loss: 2.4690092811760236

Epoch: 6| Step: 10
Training loss: 2.510893073457464
Validation loss: 2.464507469456408

Epoch: 6| Step: 11
Training loss: 2.869186162100341
Validation loss: 2.467237645083155

Epoch: 6| Step: 12
Training loss: 2.581249955664535
Validation loss: 2.4619656145952034

Epoch: 6| Step: 13
Training loss: 2.297315801764287
Validation loss: 2.4637760644956863

Epoch: 98| Step: 0
Training loss: 2.2425318862196075
Validation loss: 2.4641109209417182

Epoch: 6| Step: 1
Training loss: 2.763350073744895
Validation loss: 2.465855362142607

Epoch: 6| Step: 2
Training loss: 2.1075463174275764
Validation loss: 2.4631411097078058

Epoch: 6| Step: 3
Training loss: 2.445321080006912
Validation loss: 2.463475689532099

Epoch: 6| Step: 4
Training loss: 3.037066983727468
Validation loss: 2.4658503827065013

Epoch: 6| Step: 5
Training loss: 2.8806928580053595
Validation loss: 2.474258747265368

Epoch: 6| Step: 6
Training loss: 2.858001712731822
Validation loss: 2.477874793256986

Epoch: 6| Step: 7
Training loss: 2.992791734846256
Validation loss: 2.483343010015217

Epoch: 6| Step: 8
Training loss: 2.2078717547089775
Validation loss: 2.467071252153432

Epoch: 6| Step: 9
Training loss: 2.437374013921588
Validation loss: 2.4582198219170732

Epoch: 6| Step: 10
Training loss: 2.751024142210346
Validation loss: 2.4639693783435406

Epoch: 6| Step: 11
Training loss: 2.4391094665110917
Validation loss: 2.46051936558394

Epoch: 6| Step: 12
Training loss: 2.1144301135045867
Validation loss: 2.4683325370291027

Epoch: 6| Step: 13
Training loss: 2.606239307848178
Validation loss: 2.4720340566665615

Epoch: 99| Step: 0
Training loss: 2.823974176688634
Validation loss: 2.4689570794796953

Epoch: 6| Step: 1
Training loss: 2.636341480532736
Validation loss: 2.473929938437823

Epoch: 6| Step: 2
Training loss: 2.3719897015044076
Validation loss: 2.4761460653102234

Epoch: 6| Step: 3
Training loss: 2.3000081808525215
Validation loss: 2.481088451760454

Epoch: 6| Step: 4
Training loss: 2.411282120288509
Validation loss: 2.4846526656541474

Epoch: 6| Step: 5
Training loss: 2.273431627193875
Validation loss: 2.481421068061331

Epoch: 6| Step: 6
Training loss: 2.6761068104295904
Validation loss: 2.4823356111206216

Epoch: 6| Step: 7
Training loss: 2.679941593501634
Validation loss: 2.4847713610123083

Epoch: 6| Step: 8
Training loss: 2.656203415406074
Validation loss: 2.484807182803665

Epoch: 6| Step: 9
Training loss: 2.7412716458253557
Validation loss: 2.482731161351649

Epoch: 6| Step: 10
Training loss: 3.2369608838932518
Validation loss: 2.4786308628524476

Epoch: 6| Step: 11
Training loss: 2.68835630747215
Validation loss: 2.480746900927703

Epoch: 6| Step: 12
Training loss: 2.258435226150029
Validation loss: 2.471677693989549

Epoch: 6| Step: 13
Training loss: 2.4514521829888825
Validation loss: 2.4716607169321705

Epoch: 100| Step: 0
Training loss: 2.7705323383266296
Validation loss: 2.4697828667295

Epoch: 6| Step: 1
Training loss: 2.462586640513615
Validation loss: 2.470062518596307

Epoch: 6| Step: 2
Training loss: 2.847941736214689
Validation loss: 2.465548979179941

Epoch: 6| Step: 3
Training loss: 2.3024723075336277
Validation loss: 2.4673520568639535

Epoch: 6| Step: 4
Training loss: 2.3127209325878533
Validation loss: 2.457530267657768

Epoch: 6| Step: 5
Training loss: 2.559702765375369
Validation loss: 2.455372503653694

Epoch: 6| Step: 6
Training loss: 2.2895120953858736
Validation loss: 2.45527057808874

Epoch: 6| Step: 7
Training loss: 2.7729025741284006
Validation loss: 2.4537609596156673

Epoch: 6| Step: 8
Training loss: 3.387699535166005
Validation loss: 2.4598958873943966

Epoch: 6| Step: 9
Training loss: 2.50480257318487
Validation loss: 2.4550273023072586

Epoch: 6| Step: 10
Training loss: 2.277528418354233
Validation loss: 2.4628873013810013

Epoch: 6| Step: 11
Training loss: 2.3348637285024303
Validation loss: 2.4534256218400103

Epoch: 6| Step: 12
Training loss: 2.6742307751290766
Validation loss: 2.4562862137963273

Epoch: 6| Step: 13
Training loss: 2.5643367232483714
Validation loss: 2.4549167350379606

Epoch: 101| Step: 0
Training loss: 2.244864961942517
Validation loss: 2.4533788464650597

Epoch: 6| Step: 1
Training loss: 2.9010951769474933
Validation loss: 2.4594097905685293

Epoch: 6| Step: 2
Training loss: 2.811586867554718
Validation loss: 2.455424824231852

Epoch: 6| Step: 3
Training loss: 1.8464344977446858
Validation loss: 2.460113443935206

Epoch: 6| Step: 4
Training loss: 2.6980242812051665
Validation loss: 2.458970437226249

Epoch: 6| Step: 5
Training loss: 2.681354326828324
Validation loss: 2.454829650298418

Epoch: 6| Step: 6
Training loss: 2.06894543695571
Validation loss: 2.4536503514768047

Epoch: 6| Step: 7
Training loss: 2.220580729229274
Validation loss: 2.4536825627656462

Epoch: 6| Step: 8
Training loss: 3.0319233569218955
Validation loss: 2.4580798638056334

Epoch: 6| Step: 9
Training loss: 2.1959598984939266
Validation loss: 2.454753213897631

Epoch: 6| Step: 10
Training loss: 2.7018331627096135
Validation loss: 2.4580092189513505

Epoch: 6| Step: 11
Training loss: 2.876502266522076
Validation loss: 2.459631404735443

Epoch: 6| Step: 12
Training loss: 2.893704480334306
Validation loss: 2.4547249179046498

Epoch: 6| Step: 13
Training loss: 2.3967307911528173
Validation loss: 2.461674574820132

Epoch: 102| Step: 0
Training loss: 2.456611342702182
Validation loss: 2.4567425855951264

Epoch: 6| Step: 1
Training loss: 2.187655852079168
Validation loss: 2.4566181848453112

Epoch: 6| Step: 2
Training loss: 2.7726089314421256
Validation loss: 2.466974448857366

Epoch: 6| Step: 3
Training loss: 2.6778147745896277
Validation loss: 2.4570849745819716

Epoch: 6| Step: 4
Training loss: 2.7636784314189016
Validation loss: 2.4647427320057522

Epoch: 6| Step: 5
Training loss: 3.046426436832864
Validation loss: 2.4616848814860113

Epoch: 6| Step: 6
Training loss: 2.447443511903292
Validation loss: 2.4614223103598736

Epoch: 6| Step: 7
Training loss: 2.2745978157107434
Validation loss: 2.458335041325725

Epoch: 6| Step: 8
Training loss: 2.9435268827791523
Validation loss: 2.460929361965711

Epoch: 6| Step: 9
Training loss: 2.4617413857840913
Validation loss: 2.4581716303795846

Epoch: 6| Step: 10
Training loss: 2.6376702746347296
Validation loss: 2.4601260022972724

Epoch: 6| Step: 11
Training loss: 2.3299006916543012
Validation loss: 2.4618317447686757

Epoch: 6| Step: 12
Training loss: 2.4709919274451844
Validation loss: 2.462881138153319

Epoch: 6| Step: 13
Training loss: 2.304980036386356
Validation loss: 2.4598087366179064

Epoch: 103| Step: 0
Training loss: 2.9359493626897453
Validation loss: 2.45854120399383

Epoch: 6| Step: 1
Training loss: 2.5822326304612067
Validation loss: 2.4581306153029683

Epoch: 6| Step: 2
Training loss: 2.794165294937751
Validation loss: 2.459724070598995

Epoch: 6| Step: 3
Training loss: 2.028955307853248
Validation loss: 2.4603804507861953

Epoch: 6| Step: 4
Training loss: 3.0255168693903083
Validation loss: 2.4640357964906534

Epoch: 6| Step: 5
Training loss: 2.566473880149618
Validation loss: 2.4641029788385147

Epoch: 6| Step: 6
Training loss: 1.788482838638723
Validation loss: 2.46356461388598

Epoch: 6| Step: 7
Training loss: 2.104529119818044
Validation loss: 2.465348640880063

Epoch: 6| Step: 8
Training loss: 3.3650026955671692
Validation loss: 2.462999704977109

Epoch: 6| Step: 9
Training loss: 2.650185157497218
Validation loss: 2.463520055330635

Epoch: 6| Step: 10
Training loss: 1.9904357987921035
Validation loss: 2.4612954338585507

Epoch: 6| Step: 11
Training loss: 2.6504741028673915
Validation loss: 2.462107433778495

Epoch: 6| Step: 12
Training loss: 2.4585608253177527
Validation loss: 2.4632058805273056

Epoch: 6| Step: 13
Training loss: 2.5315764416841797
Validation loss: 2.462889479481337

Epoch: 104| Step: 0
Training loss: 2.6935591592475663
Validation loss: 2.4670305340251835

Epoch: 6| Step: 1
Training loss: 2.4234954335158077
Validation loss: 2.458623486437923

Epoch: 6| Step: 2
Training loss: 2.8239724037291736
Validation loss: 2.4570725543134126

Epoch: 6| Step: 3
Training loss: 2.6587510843996633
Validation loss: 2.4608448152395894

Epoch: 6| Step: 4
Training loss: 2.4689217036931903
Validation loss: 2.4669706394652904

Epoch: 6| Step: 5
Training loss: 2.5047189997300383
Validation loss: 2.4573437967520935

Epoch: 6| Step: 6
Training loss: 2.792619931506639
Validation loss: 2.4559034903914325

Epoch: 6| Step: 7
Training loss: 2.986470869605944
Validation loss: 2.457263023874691

Epoch: 6| Step: 8
Training loss: 2.2281417867448154
Validation loss: 2.45912130841633

Epoch: 6| Step: 9
Training loss: 2.578582353195157
Validation loss: 2.456689888711989

Epoch: 6| Step: 10
Training loss: 2.192588120258818
Validation loss: 2.458716610486406

Epoch: 6| Step: 11
Training loss: 2.3160951865471704
Validation loss: 2.4558422808251703

Epoch: 6| Step: 12
Training loss: 2.8312711129653945
Validation loss: 2.458821738482502

Epoch: 6| Step: 13
Training loss: 2.133817666427272
Validation loss: 2.458567613548219

Epoch: 105| Step: 0
Training loss: 2.5281126571372834
Validation loss: 2.4577560609099875

Epoch: 6| Step: 1
Training loss: 2.88200106482185
Validation loss: 2.4590161932274643

Epoch: 6| Step: 2
Training loss: 2.699595975670109
Validation loss: 2.455257112851716

Epoch: 6| Step: 3
Training loss: 2.46568774782893
Validation loss: 2.4563571670358817

Epoch: 6| Step: 4
Training loss: 2.2345525497638783
Validation loss: 2.4566961806951517

Epoch: 6| Step: 5
Training loss: 2.7050079667120364
Validation loss: 2.4611649019645703

Epoch: 6| Step: 6
Training loss: 2.1376812595900585
Validation loss: 2.456548411884519

Epoch: 6| Step: 7
Training loss: 2.448435096763887
Validation loss: 2.459297513730756

Epoch: 6| Step: 8
Training loss: 2.421715909593308
Validation loss: 2.461894935978485

Epoch: 6| Step: 9
Training loss: 2.1539351712161063
Validation loss: 2.4631929587638233

Epoch: 6| Step: 10
Training loss: 2.632109505726211
Validation loss: 2.465488065487645

Epoch: 6| Step: 11
Training loss: 2.6719810063263822
Validation loss: 2.4603305128638078

Epoch: 6| Step: 12
Training loss: 2.507535164492369
Validation loss: 2.4620120735032525

Epoch: 6| Step: 13
Training loss: 3.2026597592292303
Validation loss: 2.4597773325044123

Epoch: 106| Step: 0
Training loss: 1.8798688615553767
Validation loss: 2.4587052974441597

Epoch: 6| Step: 1
Training loss: 2.382891043947549
Validation loss: 2.4565558122635167

Epoch: 6| Step: 2
Training loss: 3.1351909028112326
Validation loss: 2.4561876264811047

Epoch: 6| Step: 3
Training loss: 2.658990859585159
Validation loss: 2.4606639488005047

Epoch: 6| Step: 4
Training loss: 2.507822102085638
Validation loss: 2.468027789874996

Epoch: 6| Step: 5
Training loss: 2.138045155568459
Validation loss: 2.469024675114376

Epoch: 6| Step: 6
Training loss: 2.3607537491572805
Validation loss: 2.4715082477630297

Epoch: 6| Step: 7
Training loss: 2.7153695674470137
Validation loss: 2.472123798335157

Epoch: 6| Step: 8
Training loss: 3.2022549075487294
Validation loss: 2.463179859478719

Epoch: 6| Step: 9
Training loss: 2.5496068239966365
Validation loss: 2.4650987270565747

Epoch: 6| Step: 10
Training loss: 2.4330724950887554
Validation loss: 2.4687797608975948

Epoch: 6| Step: 11
Training loss: 2.3311027582627237
Validation loss: 2.464829805055599

Epoch: 6| Step: 12
Training loss: 2.889999404431978
Validation loss: 2.4625628397196433

Epoch: 6| Step: 13
Training loss: 2.5233107024185393
Validation loss: 2.46385534976389

Epoch: 107| Step: 0
Training loss: 2.4522144547253837
Validation loss: 2.457856412197413

Epoch: 6| Step: 1
Training loss: 1.9749794150136815
Validation loss: 2.4580605942893183

Epoch: 6| Step: 2
Training loss: 2.782508308281709
Validation loss: 2.451090023300325

Epoch: 6| Step: 3
Training loss: 2.270326563666222
Validation loss: 2.4443017497702804

Epoch: 6| Step: 4
Training loss: 2.753425718547903
Validation loss: 2.4524922536895497

Epoch: 6| Step: 5
Training loss: 2.461052398421431
Validation loss: 2.441271952686483

Epoch: 6| Step: 6
Training loss: 2.7897073123228777
Validation loss: 2.44456350212404

Epoch: 6| Step: 7
Training loss: 2.4512967628792213
Validation loss: 2.445454829972201

Epoch: 6| Step: 8
Training loss: 2.8034199265008013
Validation loss: 2.455751903721285

Epoch: 6| Step: 9
Training loss: 2.3517727678652043
Validation loss: 2.455880450014741

Epoch: 6| Step: 10
Training loss: 2.8010893882317034
Validation loss: 2.4529550416550694

Epoch: 6| Step: 11
Training loss: 2.9650156727677346
Validation loss: 2.4517836416498566

Epoch: 6| Step: 12
Training loss: 2.401377910203795
Validation loss: 2.454992745512417

Epoch: 6| Step: 13
Training loss: 2.404519090214569
Validation loss: 2.460013709689139

Epoch: 108| Step: 0
Training loss: 2.6460921894313287
Validation loss: 2.4559380667309183

Epoch: 6| Step: 1
Training loss: 2.556694245850754
Validation loss: 2.4585298254937245

Epoch: 6| Step: 2
Training loss: 2.2241965053934627
Validation loss: 2.463182537417053

Epoch: 6| Step: 3
Training loss: 2.5414016043441436
Validation loss: 2.455027601743402

Epoch: 6| Step: 4
Training loss: 2.162319762375755
Validation loss: 2.467246954122829

Epoch: 6| Step: 5
Training loss: 2.864342881717021
Validation loss: 2.464614672124342

Epoch: 6| Step: 6
Training loss: 2.4391046768442046
Validation loss: 2.4619122063461947

Epoch: 6| Step: 7
Training loss: 2.737588095445015
Validation loss: 2.453774384480915

Epoch: 6| Step: 8
Training loss: 2.662253920954241
Validation loss: 2.4586784206793473

Epoch: 6| Step: 9
Training loss: 2.0750510060119653
Validation loss: 2.4539453224229937

Epoch: 6| Step: 10
Training loss: 2.811744758080777
Validation loss: 2.450531935523109

Epoch: 6| Step: 11
Training loss: 2.4866980482001355
Validation loss: 2.44633054818657

Epoch: 6| Step: 12
Training loss: 3.0802827814260505
Validation loss: 2.45118164222666

Epoch: 6| Step: 13
Training loss: 2.250747980191677
Validation loss: 2.45312819106103

Epoch: 109| Step: 0
Training loss: 2.431920439159123
Validation loss: 2.450310893023181

Epoch: 6| Step: 1
Training loss: 2.15723230957813
Validation loss: 2.4584879314712653

Epoch: 6| Step: 2
Training loss: 2.484745597788631
Validation loss: 2.459644191733695

Epoch: 6| Step: 3
Training loss: 2.7922930133439405
Validation loss: 2.4617320882084206

Epoch: 6| Step: 4
Training loss: 2.690869902166082
Validation loss: 2.472166940044802

Epoch: 6| Step: 5
Training loss: 2.6814612921133683
Validation loss: 2.473231228171504

Epoch: 6| Step: 6
Training loss: 2.440206736577114
Validation loss: 2.4703694114426895

Epoch: 6| Step: 7
Training loss: 2.809925935929874
Validation loss: 2.472444723120152

Epoch: 6| Step: 8
Training loss: 3.42841205907723
Validation loss: 2.464373431345935

Epoch: 6| Step: 9
Training loss: 2.4490441072977323
Validation loss: 2.469102713582474

Epoch: 6| Step: 10
Training loss: 2.3691543113269145
Validation loss: 2.4620635347790967

Epoch: 6| Step: 11
Training loss: 2.1781764107852846
Validation loss: 2.458322974899797

Epoch: 6| Step: 12
Training loss: 2.0363900513840005
Validation loss: 2.453239705507998

Epoch: 6| Step: 13
Training loss: 2.767283658856059
Validation loss: 2.4500407533435085

Epoch: 110| Step: 0
Training loss: 2.4286344644235554
Validation loss: 2.447161169682166

Epoch: 6| Step: 1
Training loss: 2.829779209649794
Validation loss: 2.4531658679449344

Epoch: 6| Step: 2
Training loss: 2.5417518809891178
Validation loss: 2.451343075471549

Epoch: 6| Step: 3
Training loss: 2.2462130572932932
Validation loss: 2.457381877938508

Epoch: 6| Step: 4
Training loss: 2.2737887920574837
Validation loss: 2.4482784301526035

Epoch: 6| Step: 5
Training loss: 2.1227583561931493
Validation loss: 2.446501730115715

Epoch: 6| Step: 6
Training loss: 2.427745766893023
Validation loss: 2.4489382675000035

Epoch: 6| Step: 7
Training loss: 2.3137771585066904
Validation loss: 2.4518342722695468

Epoch: 6| Step: 8
Training loss: 2.50113175523959
Validation loss: 2.452221260523851

Epoch: 6| Step: 9
Training loss: 2.305371819749457
Validation loss: 2.45749902846148

Epoch: 6| Step: 10
Training loss: 2.7629705071547512
Validation loss: 2.4563686445732245

Epoch: 6| Step: 11
Training loss: 3.3126443795462492
Validation loss: 2.457024053210305

Epoch: 6| Step: 12
Training loss: 2.6671729401971525
Validation loss: 2.4524089634830393

Epoch: 6| Step: 13
Training loss: 2.7794178274915473
Validation loss: 2.457464441745235

Epoch: 111| Step: 0
Training loss: 2.5838548277474924
Validation loss: 2.4494766351058264

Epoch: 6| Step: 1
Training loss: 2.3853421151006824
Validation loss: 2.4545982456310105

Epoch: 6| Step: 2
Training loss: 2.2294299484167386
Validation loss: 2.4522083943079926

Epoch: 6| Step: 3
Training loss: 2.2375057667918985
Validation loss: 2.451915305016476

Epoch: 6| Step: 4
Training loss: 2.358961460680024
Validation loss: 2.457505471982455

Epoch: 6| Step: 5
Training loss: 2.396771277778378
Validation loss: 2.445986150184071

Epoch: 6| Step: 6
Training loss: 2.6397217780229516
Validation loss: 2.4537245550276

Epoch: 6| Step: 7
Training loss: 2.5225857930106885
Validation loss: 2.4531359824159518

Epoch: 6| Step: 8
Training loss: 2.585020334838928
Validation loss: 2.449861587130862

Epoch: 6| Step: 9
Training loss: 2.8569525791568156
Validation loss: 2.4512401069779957

Epoch: 6| Step: 10
Training loss: 2.820729909002891
Validation loss: 2.452214487133993

Epoch: 6| Step: 11
Training loss: 2.523119832643779
Validation loss: 2.4523776914563413

Epoch: 6| Step: 12
Training loss: 2.6669803871946924
Validation loss: 2.4455182981168546

Epoch: 6| Step: 13
Training loss: 2.59194635392823
Validation loss: 2.449716455569333

Epoch: 112| Step: 0
Training loss: 2.7456379019653148
Validation loss: 2.452793625400834

Epoch: 6| Step: 1
Training loss: 2.1323361266519747
Validation loss: 2.456282072367466

Epoch: 6| Step: 2
Training loss: 2.089035191496552
Validation loss: 2.4513288592035862

Epoch: 6| Step: 3
Training loss: 2.70450111597609
Validation loss: 2.456315074184825

Epoch: 6| Step: 4
Training loss: 2.677694396896817
Validation loss: 2.460019734724742

Epoch: 6| Step: 5
Training loss: 2.071916297282382
Validation loss: 2.462325303259763

Epoch: 6| Step: 6
Training loss: 2.3509733659735685
Validation loss: 2.464408179084056

Epoch: 6| Step: 7
Training loss: 2.168592648473246
Validation loss: 2.4649245001557962

Epoch: 6| Step: 8
Training loss: 2.705407915084066
Validation loss: 2.4839527243089323

Epoch: 6| Step: 9
Training loss: 3.07399011171298
Validation loss: 2.473985536659991

Epoch: 6| Step: 10
Training loss: 3.016733232750786
Validation loss: 2.4564893293707377

Epoch: 6| Step: 11
Training loss: 2.927058879347408
Validation loss: 2.459718367936585

Epoch: 6| Step: 12
Training loss: 2.5130438031084044
Validation loss: 2.4554138196869024

Epoch: 6| Step: 13
Training loss: 2.3738637515067653
Validation loss: 2.4593030881082703

Epoch: 113| Step: 0
Training loss: 2.569694004025092
Validation loss: 2.4618115361518713

Epoch: 6| Step: 1
Training loss: 2.3541526343903616
Validation loss: 2.4684176160893125

Epoch: 6| Step: 2
Training loss: 3.046385427414476
Validation loss: 2.469999978751467

Epoch: 6| Step: 3
Training loss: 2.385896381855757
Validation loss: 2.472735949573215

Epoch: 6| Step: 4
Training loss: 2.7568918912305684
Validation loss: 2.4702206508701177

Epoch: 6| Step: 5
Training loss: 2.510183954071169
Validation loss: 2.478050947906875

Epoch: 6| Step: 6
Training loss: 2.8206937326196453
Validation loss: 2.475184124221184

Epoch: 6| Step: 7
Training loss: 2.8265170589777773
Validation loss: 2.4774713222538893

Epoch: 6| Step: 8
Training loss: 2.257353950583588
Validation loss: 2.4681767470124996

Epoch: 6| Step: 9
Training loss: 2.361686130390532
Validation loss: 2.4690731979825236

Epoch: 6| Step: 10
Training loss: 3.0910009635694244
Validation loss: 2.466833892085431

Epoch: 6| Step: 11
Training loss: 2.0831687353597808
Validation loss: 2.4690087903065727

Epoch: 6| Step: 12
Training loss: 2.6929094742420143
Validation loss: 2.4663178579614247

Epoch: 6| Step: 13
Training loss: 1.8972904837513092
Validation loss: 2.467924229420681

Epoch: 114| Step: 0
Training loss: 3.0936186791494555
Validation loss: 2.4643787685013643

Epoch: 6| Step: 1
Training loss: 2.2825787998397837
Validation loss: 2.4604859760372877

Epoch: 6| Step: 2
Training loss: 2.21627648249003
Validation loss: 2.461606680497105

Epoch: 6| Step: 3
Training loss: 2.518681251212376
Validation loss: 2.464745432428911

Epoch: 6| Step: 4
Training loss: 2.735767990603934
Validation loss: 2.459782598860067

Epoch: 6| Step: 5
Training loss: 2.663023625852415
Validation loss: 2.4465113941714454

Epoch: 6| Step: 6
Training loss: 2.7416844789647192
Validation loss: 2.450184235814482

Epoch: 6| Step: 7
Training loss: 2.660771549446191
Validation loss: 2.4501180503586677

Epoch: 6| Step: 8
Training loss: 2.271033100358959
Validation loss: 2.4441883237156508

Epoch: 6| Step: 9
Training loss: 2.672249929434702
Validation loss: 2.4511425244523273

Epoch: 6| Step: 10
Training loss: 2.953350724570202
Validation loss: 2.4475994202134514

Epoch: 6| Step: 11
Training loss: 2.4704285721650967
Validation loss: 2.4471113841859236

Epoch: 6| Step: 12
Training loss: 1.9250424343237589
Validation loss: 2.4501940313046755

Epoch: 6| Step: 13
Training loss: 2.462288621844154
Validation loss: 2.448910942792772

Epoch: 115| Step: 0
Training loss: 2.5148936091040324
Validation loss: 2.4511634289518747

Epoch: 6| Step: 1
Training loss: 2.4747507104653943
Validation loss: 2.45061774607795

Epoch: 6| Step: 2
Training loss: 2.9740832158383608
Validation loss: 2.4564939799965844

Epoch: 6| Step: 3
Training loss: 2.7171689401950236
Validation loss: 2.4579799257984294

Epoch: 6| Step: 4
Training loss: 2.5201589349551115
Validation loss: 2.459052939616764

Epoch: 6| Step: 5
Training loss: 1.8335510977102407
Validation loss: 2.461665260850027

Epoch: 6| Step: 6
Training loss: 2.677390846570648
Validation loss: 2.4586331674951287

Epoch: 6| Step: 7
Training loss: 2.224158987482487
Validation loss: 2.4679487191554985

Epoch: 6| Step: 8
Training loss: 2.5818485997590246
Validation loss: 2.4632822643487247

Epoch: 6| Step: 9
Training loss: 2.21118615575285
Validation loss: 2.4673869398059347

Epoch: 6| Step: 10
Training loss: 2.5970057999667686
Validation loss: 2.464342520765263

Epoch: 6| Step: 11
Training loss: 3.0326119735436117
Validation loss: 2.4579835147134133

Epoch: 6| Step: 12
Training loss: 2.5956630775456566
Validation loss: 2.462043053691381

Epoch: 6| Step: 13
Training loss: 2.4493764434132723
Validation loss: 2.4615872610203677

Epoch: 116| Step: 0
Training loss: 2.530420237986281
Validation loss: 2.460937726056124

Epoch: 6| Step: 1
Training loss: 2.5178222537884527
Validation loss: 2.4570676055951672

Epoch: 6| Step: 2
Training loss: 3.035930991251708
Validation loss: 2.451217541516214

Epoch: 6| Step: 3
Training loss: 2.633774578774599
Validation loss: 2.4538547216148854

Epoch: 6| Step: 4
Training loss: 2.023056524636368
Validation loss: 2.4536266340458597

Epoch: 6| Step: 5
Training loss: 2.7942977197686187
Validation loss: 2.447539285559456

Epoch: 6| Step: 6
Training loss: 2.502789657551407
Validation loss: 2.44786684242568

Epoch: 6| Step: 7
Training loss: 2.465161093038369
Validation loss: 2.450558739482839

Epoch: 6| Step: 8
Training loss: 2.513263423193596
Validation loss: 2.447495141496989

Epoch: 6| Step: 9
Training loss: 2.8636053091900235
Validation loss: 2.4475245763722175

Epoch: 6| Step: 10
Training loss: 2.051621154272089
Validation loss: 2.446380414545147

Epoch: 6| Step: 11
Training loss: 2.6584693164385613
Validation loss: 2.449461288651871

Epoch: 6| Step: 12
Training loss: 2.2093608073381663
Validation loss: 2.4515292085778326

Epoch: 6| Step: 13
Training loss: 2.669420419859001
Validation loss: 2.4472917015998155

Epoch: 117| Step: 0
Training loss: 3.333482611810385
Validation loss: 2.451311741216223

Epoch: 6| Step: 1
Training loss: 2.7042424532748077
Validation loss: 2.446466321988725

Epoch: 6| Step: 2
Training loss: 2.3085402532533656
Validation loss: 2.444375440557992

Epoch: 6| Step: 3
Training loss: 1.8939325074735347
Validation loss: 2.4473702869325415

Epoch: 6| Step: 4
Training loss: 2.8674908303444275
Validation loss: 2.443748640302327

Epoch: 6| Step: 5
Training loss: 2.7633797534990263
Validation loss: 2.4456375117330817

Epoch: 6| Step: 6
Training loss: 2.2654754589320083
Validation loss: 2.453849734020174

Epoch: 6| Step: 7
Training loss: 2.346608567638488
Validation loss: 2.4570283065964253

Epoch: 6| Step: 8
Training loss: 2.5548731185254416
Validation loss: 2.4543705266748717

Epoch: 6| Step: 9
Training loss: 2.3895087534522044
Validation loss: 2.45642421159611

Epoch: 6| Step: 10
Training loss: 2.2918553939326096
Validation loss: 2.4584804480117017

Epoch: 6| Step: 11
Training loss: 2.4949152736000126
Validation loss: 2.453690870586027

Epoch: 6| Step: 12
Training loss: 2.6387126250265234
Validation loss: 2.461823690395758

Epoch: 6| Step: 13
Training loss: 2.344706530884601
Validation loss: 2.4487871421475367

Epoch: 118| Step: 0
Training loss: 2.333136164191181
Validation loss: 2.4536675827065424

Epoch: 6| Step: 1
Training loss: 3.0252054255068552
Validation loss: 2.451762442603554

Epoch: 6| Step: 2
Training loss: 2.171703194608419
Validation loss: 2.444262798260083

Epoch: 6| Step: 3
Training loss: 2.299850301431939
Validation loss: 2.4439740402666046

Epoch: 6| Step: 4
Training loss: 3.166936327511914
Validation loss: 2.4497348985816108

Epoch: 6| Step: 5
Training loss: 2.7616641890384823
Validation loss: 2.441186546103928

Epoch: 6| Step: 6
Training loss: 2.9039694749683322
Validation loss: 2.4440067123902582

Epoch: 6| Step: 7
Training loss: 1.7527108313499118
Validation loss: 2.4532364417030292

Epoch: 6| Step: 8
Training loss: 2.7038341319715067
Validation loss: 2.4543270559528105

Epoch: 6| Step: 9
Training loss: 2.7107285300852904
Validation loss: 2.4533311145796626

Epoch: 6| Step: 10
Training loss: 1.9370909228237412
Validation loss: 2.455615599599626

Epoch: 6| Step: 11
Training loss: 2.759946867113487
Validation loss: 2.4608931603045088

Epoch: 6| Step: 12
Training loss: 2.194342565250616
Validation loss: 2.457344095905964

Epoch: 6| Step: 13
Training loss: 2.4549914991926953
Validation loss: 2.458065347019625

Epoch: 119| Step: 0
Training loss: 2.1733819138571677
Validation loss: 2.4596895878677576

Epoch: 6| Step: 1
Training loss: 2.202827595867243
Validation loss: 2.456887245506759

Epoch: 6| Step: 2
Training loss: 2.15032299188317
Validation loss: 2.4532984289592275

Epoch: 6| Step: 3
Training loss: 2.5619169362738323
Validation loss: 2.4523642589452415

Epoch: 6| Step: 4
Training loss: 2.520298094451091
Validation loss: 2.4563669864404183

Epoch: 6| Step: 5
Training loss: 2.4031301312336004
Validation loss: 2.451404073186093

Epoch: 6| Step: 6
Training loss: 2.2954463537981633
Validation loss: 2.449214239689245

Epoch: 6| Step: 7
Training loss: 3.0555381273485467
Validation loss: 2.4523167665699837

Epoch: 6| Step: 8
Training loss: 2.5872380884272124
Validation loss: 2.453011625549287

Epoch: 6| Step: 9
Training loss: 3.203055180974971
Validation loss: 2.4544522689754866

Epoch: 6| Step: 10
Training loss: 2.593851661987819
Validation loss: 2.454220893489609

Epoch: 6| Step: 11
Training loss: 2.792919323890678
Validation loss: 2.4510167451481317

Epoch: 6| Step: 12
Training loss: 2.3514610091198382
Validation loss: 2.4502792212262388

Epoch: 6| Step: 13
Training loss: 2.3085556414407007
Validation loss: 2.4507908984776554

Epoch: 120| Step: 0
Training loss: 2.474109770841344
Validation loss: 2.4458496836213808

Epoch: 6| Step: 1
Training loss: 2.9871867251043493
Validation loss: 2.4470834057863824

Epoch: 6| Step: 2
Training loss: 2.800858117489249
Validation loss: 2.4466953775174787

Epoch: 6| Step: 3
Training loss: 2.4535014841601135
Validation loss: 2.4420133685225904

Epoch: 6| Step: 4
Training loss: 2.644400160905784
Validation loss: 2.449781062276252

Epoch: 6| Step: 5
Training loss: 2.5534093616743347
Validation loss: 2.449222238184277

Epoch: 6| Step: 6
Training loss: 3.3810782623394644
Validation loss: 2.45074817496119

Epoch: 6| Step: 7
Training loss: 2.218162996252055
Validation loss: 2.4497324330330406

Epoch: 6| Step: 8
Training loss: 1.9915182148768205
Validation loss: 2.4516052916637476

Epoch: 6| Step: 9
Training loss: 2.560364088900388
Validation loss: 2.4467669336872357

Epoch: 6| Step: 10
Training loss: 2.5869628164349296
Validation loss: 2.4519304740491155

Epoch: 6| Step: 11
Training loss: 2.232552592137564
Validation loss: 2.456740968150826

Epoch: 6| Step: 12
Training loss: 2.133210421041359
Validation loss: 2.4495209543463927

Epoch: 6| Step: 13
Training loss: 2.0895629694191378
Validation loss: 2.449179779342987

Epoch: 121| Step: 0
Training loss: 2.9445497046155733
Validation loss: 2.443358260982106

Epoch: 6| Step: 1
Training loss: 2.9327027127056096
Validation loss: 2.442634798310896

Epoch: 6| Step: 2
Training loss: 2.6089433324412488
Validation loss: 2.4435964947527005

Epoch: 6| Step: 3
Training loss: 2.211339260303067
Validation loss: 2.44800848822483

Epoch: 6| Step: 4
Training loss: 2.1091197671829303
Validation loss: 2.449916888144268

Epoch: 6| Step: 5
Training loss: 2.564004409940977
Validation loss: 2.4435146657504783

Epoch: 6| Step: 6
Training loss: 2.4830657580145292
Validation loss: 2.443122378614881

Epoch: 6| Step: 7
Training loss: 2.359122256453093
Validation loss: 2.4433762640995735

Epoch: 6| Step: 8
Training loss: 2.666929877722091
Validation loss: 2.4470983774363724

Epoch: 6| Step: 9
Training loss: 2.2476900747205053
Validation loss: 2.447326440200132

Epoch: 6| Step: 10
Training loss: 2.14866697993184
Validation loss: 2.457393423455515

Epoch: 6| Step: 11
Training loss: 2.497579260896284
Validation loss: 2.4663370951866885

Epoch: 6| Step: 12
Training loss: 2.7992767592010748
Validation loss: 2.4607478477424434

Epoch: 6| Step: 13
Training loss: 2.67962379491058
Validation loss: 2.469882335202567

Epoch: 122| Step: 0
Training loss: 2.999483699875749
Validation loss: 2.469223974899438

Epoch: 6| Step: 1
Training loss: 2.9672034803043545
Validation loss: 2.4672225057394703

Epoch: 6| Step: 2
Training loss: 2.6006525871282324
Validation loss: 2.4684036591389753

Epoch: 6| Step: 3
Training loss: 2.563259942484445
Validation loss: 2.4641455030602133

Epoch: 6| Step: 4
Training loss: 2.2756032164970863
Validation loss: 2.4599706456001784

Epoch: 6| Step: 5
Training loss: 2.415837002984223
Validation loss: 2.4547525987708165

Epoch: 6| Step: 6
Training loss: 2.4122722617067107
Validation loss: 2.452932718763471

Epoch: 6| Step: 7
Training loss: 2.2863037358346454
Validation loss: 2.446643219449143

Epoch: 6| Step: 8
Training loss: 2.6426857576068805
Validation loss: 2.4482491828768813

Epoch: 6| Step: 9
Training loss: 2.633129972339556
Validation loss: 2.451006628700153

Epoch: 6| Step: 10
Training loss: 2.4454918938788865
Validation loss: 2.450603493172344

Epoch: 6| Step: 11
Training loss: 2.52904046721567
Validation loss: 2.4491456105548384

Epoch: 6| Step: 12
Training loss: 2.4229810588630047
Validation loss: 2.449726415137623

Epoch: 6| Step: 13
Training loss: 2.256899322319546
Validation loss: 2.45002014742242

Epoch: 123| Step: 0
Training loss: 2.7632908858416245
Validation loss: 2.453129486922192

Epoch: 6| Step: 1
Training loss: 2.4723816247572907
Validation loss: 2.4503528619831396

Epoch: 6| Step: 2
Training loss: 2.706236178955307
Validation loss: 2.455458177411675

Epoch: 6| Step: 3
Training loss: 3.0674726636394483
Validation loss: 2.449719894382505

Epoch: 6| Step: 4
Training loss: 2.76948984220081
Validation loss: 2.4497960661007245

Epoch: 6| Step: 5
Training loss: 1.9067861084550666
Validation loss: 2.451165325667711

Epoch: 6| Step: 6
Training loss: 2.4571542875841486
Validation loss: 2.4504990260862938

Epoch: 6| Step: 7
Training loss: 1.9802585467681588
Validation loss: 2.4488852079619208

Epoch: 6| Step: 8
Training loss: 2.483332193190891
Validation loss: 2.4497315895553284

Epoch: 6| Step: 9
Training loss: 2.399738369032576
Validation loss: 2.4584481056275234

Epoch: 6| Step: 10
Training loss: 2.9895190897738986
Validation loss: 2.4526538436912513

Epoch: 6| Step: 11
Training loss: 2.0211644900888435
Validation loss: 2.454828727636869

Epoch: 6| Step: 12
Training loss: 2.465682526317441
Validation loss: 2.457182070455124

Epoch: 6| Step: 13
Training loss: 2.5403071243355018
Validation loss: 2.456612563937164

Epoch: 124| Step: 0
Training loss: 2.5488391627514835
Validation loss: 2.460663343225614

Epoch: 6| Step: 1
Training loss: 2.428950845107158
Validation loss: 2.460800845272653

Epoch: 6| Step: 2
Training loss: 2.222743563956679
Validation loss: 2.4563120490366934

Epoch: 6| Step: 3
Training loss: 2.8412029891146466
Validation loss: 2.4598918651188306

Epoch: 6| Step: 4
Training loss: 2.2314102670935108
Validation loss: 2.456249555437276

Epoch: 6| Step: 5
Training loss: 2.6304478199519545
Validation loss: 2.45786532025773

Epoch: 6| Step: 6
Training loss: 2.5347004673226006
Validation loss: 2.46273031174323

Epoch: 6| Step: 7
Training loss: 2.431934850579299
Validation loss: 2.467301599732254

Epoch: 6| Step: 8
Training loss: 2.6706069703568156
Validation loss: 2.4609587653316085

Epoch: 6| Step: 9
Training loss: 2.0392742412436236
Validation loss: 2.457899400161423

Epoch: 6| Step: 10
Training loss: 2.233292003742617
Validation loss: 2.452925963537803

Epoch: 6| Step: 11
Training loss: 2.886112629565012
Validation loss: 2.4584259780840725

Epoch: 6| Step: 12
Training loss: 2.7473215584259236
Validation loss: 2.4478108863430776

Epoch: 6| Step: 13
Training loss: 2.8614777717906787
Validation loss: 2.452032279166683

Epoch: 125| Step: 0
Training loss: 2.408929893059425
Validation loss: 2.4493752266819744

Epoch: 6| Step: 1
Training loss: 2.3002665904246675
Validation loss: 2.450721778427737

Epoch: 6| Step: 2
Training loss: 2.429839494372891
Validation loss: 2.4497489213419126

Epoch: 6| Step: 3
Training loss: 2.7000256890381737
Validation loss: 2.448409519226369

Epoch: 6| Step: 4
Training loss: 2.753264310431918
Validation loss: 2.452044935636128

Epoch: 6| Step: 5
Training loss: 2.290619928997094
Validation loss: 2.4541738094448253

Epoch: 6| Step: 6
Training loss: 2.881347614877245
Validation loss: 2.448962070900875

Epoch: 6| Step: 7
Training loss: 2.6845967779593067
Validation loss: 2.4476861290559464

Epoch: 6| Step: 8
Training loss: 2.527335259778533
Validation loss: 2.4495121132734834

Epoch: 6| Step: 9
Training loss: 2.8986789983202237
Validation loss: 2.4487538035819045

Epoch: 6| Step: 10
Training loss: 2.9713892398316655
Validation loss: 2.4476123431265715

Epoch: 6| Step: 11
Training loss: 2.0012849018167667
Validation loss: 2.442726400887395

Epoch: 6| Step: 12
Training loss: 2.008691973604768
Validation loss: 2.443842680751678

Epoch: 6| Step: 13
Training loss: 2.1300028085466236
Validation loss: 2.446330743105911

Epoch: 126| Step: 0
Training loss: 2.2422411975345433
Validation loss: 2.4494287298418516

Epoch: 6| Step: 1
Training loss: 2.0529656103034517
Validation loss: 2.44369352491705

Epoch: 6| Step: 2
Training loss: 2.272540672618119
Validation loss: 2.4519096976366366

Epoch: 6| Step: 3
Training loss: 2.162400251083557
Validation loss: 2.4453098674918436

Epoch: 6| Step: 4
Training loss: 2.769760402136203
Validation loss: 2.453713453787966

Epoch: 6| Step: 5
Training loss: 2.3876776384506915
Validation loss: 2.4457673451123365

Epoch: 6| Step: 6
Training loss: 1.8230887268245157
Validation loss: 2.447636200008669

Epoch: 6| Step: 7
Training loss: 2.652049794151071
Validation loss: 2.451226473703009

Epoch: 6| Step: 8
Training loss: 2.5139509044699837
Validation loss: 2.4470939281703443

Epoch: 6| Step: 9
Training loss: 2.5339286665175704
Validation loss: 2.455164861044702

Epoch: 6| Step: 10
Training loss: 2.803777945690028
Validation loss: 2.4482913089060028

Epoch: 6| Step: 11
Training loss: 2.618603223816185
Validation loss: 2.4506912793762727

Epoch: 6| Step: 12
Training loss: 3.3157962736858346
Validation loss: 2.4505716792205368

Epoch: 6| Step: 13
Training loss: 2.771965130326559
Validation loss: 2.4465241928957404

Epoch: 127| Step: 0
Training loss: 2.6897130326709795
Validation loss: 2.4514170246712954

Epoch: 6| Step: 1
Training loss: 2.4318335766819517
Validation loss: 2.4525533929444485

Epoch: 6| Step: 2
Training loss: 2.5699457063394773
Validation loss: 2.4479966874266426

Epoch: 6| Step: 3
Training loss: 2.4109233704979274
Validation loss: 2.4509609906793766

Epoch: 6| Step: 4
Training loss: 2.565528010998852
Validation loss: 2.4478599920543407

Epoch: 6| Step: 5
Training loss: 2.416176472199829
Validation loss: 2.446830684476552

Epoch: 6| Step: 6
Training loss: 2.2889469885730866
Validation loss: 2.4417390560924153

Epoch: 6| Step: 7
Training loss: 2.579015312211492
Validation loss: 2.4477696286674435

Epoch: 6| Step: 8
Training loss: 2.5129752094034217
Validation loss: 2.4446673207354532

Epoch: 6| Step: 9
Training loss: 2.590352234325667
Validation loss: 2.4434907239070864

Epoch: 6| Step: 10
Training loss: 2.6966603322970477
Validation loss: 2.4506003150387445

Epoch: 6| Step: 11
Training loss: 2.8708592325563957
Validation loss: 2.4573532241241187

Epoch: 6| Step: 12
Training loss: 2.469134337048037
Validation loss: 2.4546963140150146

Epoch: 6| Step: 13
Training loss: 1.9499071392543512
Validation loss: 2.452101329865987

Epoch: 128| Step: 0
Training loss: 1.5417651153610312
Validation loss: 2.4536843927557874

Epoch: 6| Step: 1
Training loss: 2.5826240816985706
Validation loss: 2.4566027697772745

Epoch: 6| Step: 2
Training loss: 2.653271430010702
Validation loss: 2.4555155127507913

Epoch: 6| Step: 3
Training loss: 2.216902057320189
Validation loss: 2.460395858336425

Epoch: 6| Step: 4
Training loss: 2.423645061800428
Validation loss: 2.4551342148747812

Epoch: 6| Step: 5
Training loss: 3.0553084032691222
Validation loss: 2.454705670615483

Epoch: 6| Step: 6
Training loss: 2.821388271933847
Validation loss: 2.449954727948289

Epoch: 6| Step: 7
Training loss: 3.1368823169137245
Validation loss: 2.4504694404577565

Epoch: 6| Step: 8
Training loss: 2.506357977389011
Validation loss: 2.4550031530666887

Epoch: 6| Step: 9
Training loss: 2.3166351462582333
Validation loss: 2.450813986701791

Epoch: 6| Step: 10
Training loss: 1.8920810861692487
Validation loss: 2.4580589453807384

Epoch: 6| Step: 11
Training loss: 2.21012804290474
Validation loss: 2.4517002058123043

Epoch: 6| Step: 12
Training loss: 2.520594456811815
Validation loss: 2.455547578205578

Epoch: 6| Step: 13
Training loss: 2.851979013619914
Validation loss: 2.44947489930666

Epoch: 129| Step: 0
Training loss: 2.6196980292167695
Validation loss: 2.4512358435481874

Epoch: 6| Step: 1
Training loss: 2.605370835690629
Validation loss: 2.445690235542046

Epoch: 6| Step: 2
Training loss: 2.280712325603166
Validation loss: 2.440741315700215

Epoch: 6| Step: 3
Training loss: 1.8889903418403606
Validation loss: 2.4447403178425255

Epoch: 6| Step: 4
Training loss: 3.275113134395638
Validation loss: 2.4527045211518272

Epoch: 6| Step: 5
Training loss: 2.6750348240377084
Validation loss: 2.4525084155991794

Epoch: 6| Step: 6
Training loss: 2.620236115772524
Validation loss: 2.452027433714865

Epoch: 6| Step: 7
Training loss: 2.6123359920729445
Validation loss: 2.446374022936761

Epoch: 6| Step: 8
Training loss: 2.0197128125740744
Validation loss: 2.455381032323837

Epoch: 6| Step: 9
Training loss: 2.1955688978455603
Validation loss: 2.4471163855144145

Epoch: 6| Step: 10
Training loss: 1.939601005148632
Validation loss: 2.448459116035541

Epoch: 6| Step: 11
Training loss: 2.315794994379609
Validation loss: 2.446845121757457

Epoch: 6| Step: 12
Training loss: 2.7957842527384167
Validation loss: 2.446518102140625

Epoch: 6| Step: 13
Training loss: 2.8894286283202666
Validation loss: 2.4516169859466146

Epoch: 130| Step: 0
Training loss: 2.189085249745166
Validation loss: 2.459867424403411

Epoch: 6| Step: 1
Training loss: 2.9226849907117325
Validation loss: 2.4645067680850525

Epoch: 6| Step: 2
Training loss: 2.1892067926352707
Validation loss: 2.463770177672435

Epoch: 6| Step: 3
Training loss: 2.6474401345837517
Validation loss: 2.4712546153999053

Epoch: 6| Step: 4
Training loss: 2.8118832229795876
Validation loss: 2.466246852933974

Epoch: 6| Step: 5
Training loss: 2.567502790559108
Validation loss: 2.466223941413317

Epoch: 6| Step: 6
Training loss: 2.2672519498533394
Validation loss: 2.4647142282543077

Epoch: 6| Step: 7
Training loss: 2.7811464440429763
Validation loss: 2.4605173872558352

Epoch: 6| Step: 8
Training loss: 2.4492661564329032
Validation loss: 2.461939838682537

Epoch: 6| Step: 9
Training loss: 2.7468062842478704
Validation loss: 2.4595486551750634

Epoch: 6| Step: 10
Training loss: 2.5523697257727016
Validation loss: 2.452451706675556

Epoch: 6| Step: 11
Training loss: 2.5211585179282108
Validation loss: 2.450593877684079

Epoch: 6| Step: 12
Training loss: 2.2338497371426587
Validation loss: 2.450773525418402

Epoch: 6| Step: 13
Training loss: 2.24881119581738
Validation loss: 2.4491628978146887

Epoch: 131| Step: 0
Training loss: 2.3203572997832094
Validation loss: 2.4532855845897905

Epoch: 6| Step: 1
Training loss: 1.8178556176735141
Validation loss: 2.4460208829579386

Epoch: 6| Step: 2
Training loss: 2.89116849171707
Validation loss: 2.45121570968441

Epoch: 6| Step: 3
Training loss: 2.5206944345927114
Validation loss: 2.446580884916936

Epoch: 6| Step: 4
Training loss: 2.2202888847238818
Validation loss: 2.4520864859933176

Epoch: 6| Step: 5
Training loss: 2.999023596497472
Validation loss: 2.443312309334281

Epoch: 6| Step: 6
Training loss: 2.9376503114593118
Validation loss: 2.452450288935664

Epoch: 6| Step: 7
Training loss: 2.569375560169349
Validation loss: 2.454333969225273

Epoch: 6| Step: 8
Training loss: 2.298674624494923
Validation loss: 2.4480591969220273

Epoch: 6| Step: 9
Training loss: 2.047639660293227
Validation loss: 2.4502164521261367

Epoch: 6| Step: 10
Training loss: 2.3989954992063662
Validation loss: 2.450395146442841

Epoch: 6| Step: 11
Training loss: 2.380372646233468
Validation loss: 2.44752714155693

Epoch: 6| Step: 12
Training loss: 2.558173085349569
Validation loss: 2.4502997925347

Epoch: 6| Step: 13
Training loss: 2.7928461648141996
Validation loss: 2.4485236179743954

Epoch: 132| Step: 0
Training loss: 2.547831256357132
Validation loss: 2.4462372450121603

Epoch: 6| Step: 1
Training loss: 2.117646227474922
Validation loss: 2.4476068232976567

Epoch: 6| Step: 2
Training loss: 2.6208332233600764
Validation loss: 2.4459494511747844

Epoch: 6| Step: 3
Training loss: 2.6473036057605857
Validation loss: 2.4442023701687847

Epoch: 6| Step: 4
Training loss: 2.4234216489095166
Validation loss: 2.4494705516921353

Epoch: 6| Step: 5
Training loss: 2.0961308393918565
Validation loss: 2.4486655259957564

Epoch: 6| Step: 6
Training loss: 2.538219511502939
Validation loss: 2.452365733446436

Epoch: 6| Step: 7
Training loss: 2.696602951950611
Validation loss: 2.45134223254804

Epoch: 6| Step: 8
Training loss: 2.6310794004829097
Validation loss: 2.450867888103151

Epoch: 6| Step: 9
Training loss: 2.130511821091827
Validation loss: 2.4521174862497235

Epoch: 6| Step: 10
Training loss: 2.7875427892847684
Validation loss: 2.4601074352814214

Epoch: 6| Step: 11
Training loss: 2.704383777509832
Validation loss: 2.4566553553040897

Epoch: 6| Step: 12
Training loss: 2.434261812019818
Validation loss: 2.4636596318094903

Epoch: 6| Step: 13
Training loss: 2.6145864742508422
Validation loss: 2.4606122483166994

Epoch: 133| Step: 0
Training loss: 2.5762931095312624
Validation loss: 2.4621362582104895

Epoch: 6| Step: 1
Training loss: 2.6722664351142154
Validation loss: 2.4612999220306224

Epoch: 6| Step: 2
Training loss: 2.791670747061257
Validation loss: 2.452964080910427

Epoch: 6| Step: 3
Training loss: 2.7196599380304574
Validation loss: 2.4468617919201625

Epoch: 6| Step: 4
Training loss: 2.223441416025902
Validation loss: 2.4490967090951914

Epoch: 6| Step: 5
Training loss: 2.234312256685707
Validation loss: 2.4415997319165936

Epoch: 6| Step: 6
Training loss: 2.4353123164167694
Validation loss: 2.438593138409955

Epoch: 6| Step: 7
Training loss: 2.6498645999793795
Validation loss: 2.444032490460733

Epoch: 6| Step: 8
Training loss: 2.529790575308445
Validation loss: 2.4483791455535164

Epoch: 6| Step: 9
Training loss: 2.702279548510994
Validation loss: 2.459298547819133

Epoch: 6| Step: 10
Training loss: 3.1171354896585215
Validation loss: 2.454755625840756

Epoch: 6| Step: 11
Training loss: 2.176507633391266
Validation loss: 2.441992808770087

Epoch: 6| Step: 12
Training loss: 1.4723504758347437
Validation loss: 2.4529895461603957

Epoch: 6| Step: 13
Training loss: 2.6770976817022363
Validation loss: 2.4501008590386797

Epoch: 134| Step: 0
Training loss: 2.8140878221896513
Validation loss: 2.448663237876302

Epoch: 6| Step: 1
Training loss: 3.0943781667749777
Validation loss: 2.4578906458100116

Epoch: 6| Step: 2
Training loss: 2.804111687252086
Validation loss: 2.458759357154675

Epoch: 6| Step: 3
Training loss: 3.067002859208174
Validation loss: 2.463839883208259

Epoch: 6| Step: 4
Training loss: 1.854330705680039
Validation loss: 2.455347063118198

Epoch: 6| Step: 5
Training loss: 2.625192725963126
Validation loss: 2.460710819844903

Epoch: 6| Step: 6
Training loss: 2.4921574605727814
Validation loss: 2.464975989291211

Epoch: 6| Step: 7
Training loss: 2.5564874963094617
Validation loss: 2.46199192285646

Epoch: 6| Step: 8
Training loss: 2.3107632481699674
Validation loss: 2.4611754367990972

Epoch: 6| Step: 9
Training loss: 2.397468395959631
Validation loss: 2.457816551869636

Epoch: 6| Step: 10
Training loss: 2.552691225068075
Validation loss: 2.4546969291559333

Epoch: 6| Step: 11
Training loss: 1.9406930392465358
Validation loss: 2.4632942338902346

Epoch: 6| Step: 12
Training loss: 2.1224966450407474
Validation loss: 2.4565449260152126

Epoch: 6| Step: 13
Training loss: 2.2446934323748264
Validation loss: 2.4541086707092554

Epoch: 135| Step: 0
Training loss: 2.5759840890321937
Validation loss: 2.4454251020707103

Epoch: 6| Step: 1
Training loss: 1.910022879158918
Validation loss: 2.4461715700483717

Epoch: 6| Step: 2
Training loss: 2.5986518042041356
Validation loss: 2.4500739933050966

Epoch: 6| Step: 3
Training loss: 2.666698237073303
Validation loss: 2.4593500739534586

Epoch: 6| Step: 4
Training loss: 2.6786065326388564
Validation loss: 2.4493916606149884

Epoch: 6| Step: 5
Training loss: 2.321694935199573
Validation loss: 2.4528180880010475

Epoch: 6| Step: 6
Training loss: 2.697709761728754
Validation loss: 2.4576673791024533

Epoch: 6| Step: 7
Training loss: 2.924019745463904
Validation loss: 2.456177159233156

Epoch: 6| Step: 8
Training loss: 2.197475250417235
Validation loss: 2.4624114128741046

Epoch: 6| Step: 9
Training loss: 2.442859723592493
Validation loss: 2.458237546466303

Epoch: 6| Step: 10
Training loss: 2.519377758466554
Validation loss: 2.448560335201788

Epoch: 6| Step: 11
Training loss: 2.317149565701956
Validation loss: 2.4449462616364475

Epoch: 6| Step: 12
Training loss: 2.233400999533948
Validation loss: 2.457583415419281

Epoch: 6| Step: 13
Training loss: 2.881259572309038
Validation loss: 2.4575802786499397

Epoch: 136| Step: 0
Training loss: 2.286340025416716
Validation loss: 2.4520842172712376

Epoch: 6| Step: 1
Training loss: 1.8758367578697495
Validation loss: 2.4563164330736824

Epoch: 6| Step: 2
Training loss: 2.4733022897456713
Validation loss: 2.4431527200542758

Epoch: 6| Step: 3
Training loss: 2.5467036839070007
Validation loss: 2.4470506529528695

Epoch: 6| Step: 4
Training loss: 2.700532673460639
Validation loss: 2.4449684705437043

Epoch: 6| Step: 5
Training loss: 2.957966222058224
Validation loss: 2.451853785199806

Epoch: 6| Step: 6
Training loss: 1.9103648066025034
Validation loss: 2.4453338037117383

Epoch: 6| Step: 7
Training loss: 3.2295484419711196
Validation loss: 2.4504014464810915

Epoch: 6| Step: 8
Training loss: 2.3680344882399615
Validation loss: 2.450428924836913

Epoch: 6| Step: 9
Training loss: 2.2631071635388564
Validation loss: 2.4550865090246496

Epoch: 6| Step: 10
Training loss: 2.055623468646102
Validation loss: 2.453256943671393

Epoch: 6| Step: 11
Training loss: 2.7094150632648346
Validation loss: 2.450845554307934

Epoch: 6| Step: 12
Training loss: 2.6688136358960195
Validation loss: 2.454191692744979

Epoch: 6| Step: 13
Training loss: 2.5564839524187533
Validation loss: 2.4533659377298456

Epoch: 137| Step: 0
Training loss: 2.3680466707373062
Validation loss: 2.4563684100081637

Epoch: 6| Step: 1
Training loss: 2.6236456147211475
Validation loss: 2.4500228965104585

Epoch: 6| Step: 2
Training loss: 2.551743423765881
Validation loss: 2.4414901841040724

Epoch: 6| Step: 3
Training loss: 3.0278537246869415
Validation loss: 2.4610046296828565

Epoch: 6| Step: 4
Training loss: 2.5435718108430283
Validation loss: 2.470013427968147

Epoch: 6| Step: 5
Training loss: 2.786945469186251
Validation loss: 2.475122171334378

Epoch: 6| Step: 6
Training loss: 1.9013806672247846
Validation loss: 2.462723131607843

Epoch: 6| Step: 7
Training loss: 2.5711467281923617
Validation loss: 2.467287829732538

Epoch: 6| Step: 8
Training loss: 2.807006896985927
Validation loss: 2.4565416585137383

Epoch: 6| Step: 9
Training loss: 2.6841786287221407
Validation loss: 2.4465993759280873

Epoch: 6| Step: 10
Training loss: 2.759062486450458
Validation loss: 2.4492046268589305

Epoch: 6| Step: 11
Training loss: 2.0586796838533306
Validation loss: 2.4538641542947

Epoch: 6| Step: 12
Training loss: 2.2272789588798583
Validation loss: 2.4610951852486496

Epoch: 6| Step: 13
Training loss: 2.1203974077825958
Validation loss: 2.4672143723303015

Epoch: 138| Step: 0
Training loss: 2.989288918134877
Validation loss: 2.4689711942448547

Epoch: 6| Step: 1
Training loss: 2.6064638813910963
Validation loss: 2.4689560011533835

Epoch: 6| Step: 2
Training loss: 2.668219759793776
Validation loss: 2.4620033176357414

Epoch: 6| Step: 3
Training loss: 2.8127537930739086
Validation loss: 2.4666771052973053

Epoch: 6| Step: 4
Training loss: 2.421100221805595
Validation loss: 2.464631609042149

Epoch: 6| Step: 5
Training loss: 2.5359524973803684
Validation loss: 2.463498699197954

Epoch: 6| Step: 6
Training loss: 2.2646819157858573
Validation loss: 2.4596235854896076

Epoch: 6| Step: 7
Training loss: 2.6519263589395776
Validation loss: 2.452103404111781

Epoch: 6| Step: 8
Training loss: 2.14076143372955
Validation loss: 2.458948976940141

Epoch: 6| Step: 9
Training loss: 2.5132194058460926
Validation loss: 2.45550969512782

Epoch: 6| Step: 10
Training loss: 2.5624913471354955
Validation loss: 2.448101675198225

Epoch: 6| Step: 11
Training loss: 2.389667693303344
Validation loss: 2.446166599276886

Epoch: 6| Step: 12
Training loss: 2.3947552674193076
Validation loss: 2.4485959564718995

Epoch: 6| Step: 13
Training loss: 2.3119373152461735
Validation loss: 2.4514406743281736

Epoch: 139| Step: 0
Training loss: 2.217185207416836
Validation loss: 2.444581732061562

Epoch: 6| Step: 1
Training loss: 2.4236849020940556
Validation loss: 2.444822674687241

Epoch: 6| Step: 2
Training loss: 2.8530301432389353
Validation loss: 2.4476408674558527

Epoch: 6| Step: 3
Training loss: 1.7892733120712798
Validation loss: 2.448593441091698

Epoch: 6| Step: 4
Training loss: 2.519040082030353
Validation loss: 2.445283696631626

Epoch: 6| Step: 5
Training loss: 2.724059434306774
Validation loss: 2.445792154185349

Epoch: 6| Step: 6
Training loss: 2.335904430550829
Validation loss: 2.4462063164336354

Epoch: 6| Step: 7
Training loss: 1.888234795033265
Validation loss: 2.450815186505246

Epoch: 6| Step: 8
Training loss: 2.8162272868656433
Validation loss: 2.444802959358087

Epoch: 6| Step: 9
Training loss: 2.2832444760744335
Validation loss: 2.454374719899337

Epoch: 6| Step: 10
Training loss: 3.03963812154887
Validation loss: 2.44935485039869

Epoch: 6| Step: 11
Training loss: 2.5664198133322147
Validation loss: 2.4440084845904986

Epoch: 6| Step: 12
Training loss: 2.6228926237628936
Validation loss: 2.4439489688509073

Epoch: 6| Step: 13
Training loss: 2.6562580781701612
Validation loss: 2.4435655164881407

Epoch: 140| Step: 0
Training loss: 2.3670118411516965
Validation loss: 2.4492212485138936

Epoch: 6| Step: 1
Training loss: 2.8281751596628752
Validation loss: 2.4432539069661248

Epoch: 6| Step: 2
Training loss: 2.515400941715457
Validation loss: 2.445054256952747

Epoch: 6| Step: 3
Training loss: 2.5378689352091857
Validation loss: 2.4410977669692007

Epoch: 6| Step: 4
Training loss: 2.712591980108567
Validation loss: 2.4521880739756727

Epoch: 6| Step: 5
Training loss: 2.078829079578706
Validation loss: 2.446294861442104

Epoch: 6| Step: 6
Training loss: 2.1181388491180333
Validation loss: 2.4451837800326097

Epoch: 6| Step: 7
Training loss: 2.483098307844637
Validation loss: 2.446644900413104

Epoch: 6| Step: 8
Training loss: 2.7403553115575257
Validation loss: 2.4473644093565343

Epoch: 6| Step: 9
Training loss: 2.4199118256071603
Validation loss: 2.4528094208162963

Epoch: 6| Step: 10
Training loss: 2.6646892448017847
Validation loss: 2.4618264505144953

Epoch: 6| Step: 11
Training loss: 2.217679047350104
Validation loss: 2.4623093106816047

Epoch: 6| Step: 12
Training loss: 2.6122084897591398
Validation loss: 2.459194345071794

Epoch: 6| Step: 13
Training loss: 2.6425859742989024
Validation loss: 2.454106646733774

Epoch: 141| Step: 0
Training loss: 2.449199183627735
Validation loss: 2.4430626705061975

Epoch: 6| Step: 1
Training loss: 2.1459901499313307
Validation loss: 2.4583261188034835

Epoch: 6| Step: 2
Training loss: 2.7445409516712247
Validation loss: 2.4587543471866327

Epoch: 6| Step: 3
Training loss: 2.549655262700855
Validation loss: 2.4592087420857713

Epoch: 6| Step: 4
Training loss: 2.1405203020986017
Validation loss: 2.4572968938259034

Epoch: 6| Step: 5
Training loss: 1.9694426998219776
Validation loss: 2.456850749766024

Epoch: 6| Step: 6
Training loss: 2.687617454623604
Validation loss: 2.456737328897256

Epoch: 6| Step: 7
Training loss: 2.2007517917274324
Validation loss: 2.454018577896055

Epoch: 6| Step: 8
Training loss: 2.9297065429068607
Validation loss: 2.45282338549889

Epoch: 6| Step: 9
Training loss: 2.227145577094103
Validation loss: 2.4625061686998486

Epoch: 6| Step: 10
Training loss: 2.8311948185610563
Validation loss: 2.4584133383022353

Epoch: 6| Step: 11
Training loss: 2.85492531005646
Validation loss: 2.458508927060183

Epoch: 6| Step: 12
Training loss: 2.1867947122641453
Validation loss: 2.4672945053735766

Epoch: 6| Step: 13
Training loss: 2.761478915450211
Validation loss: 2.4578733229341148

Epoch: 142| Step: 0
Training loss: 2.6897535412564135
Validation loss: 2.4607859731376114

Epoch: 6| Step: 1
Training loss: 2.2949285239265387
Validation loss: 2.4560507398286697

Epoch: 6| Step: 2
Training loss: 2.6686149473658967
Validation loss: 2.461146447731958

Epoch: 6| Step: 3
Training loss: 2.132380067911985
Validation loss: 2.4568765709832445

Epoch: 6| Step: 4
Training loss: 2.532397069166696
Validation loss: 2.455227058564743

Epoch: 6| Step: 5
Training loss: 2.799429126854134
Validation loss: 2.4555281917227822

Epoch: 6| Step: 6
Training loss: 2.6598631575527976
Validation loss: 2.4558917760696213

Epoch: 6| Step: 7
Training loss: 2.3040242938111932
Validation loss: 2.4603550781845067

Epoch: 6| Step: 8
Training loss: 2.2911072019208003
Validation loss: 2.453354875359427

Epoch: 6| Step: 9
Training loss: 2.405194930585413
Validation loss: 2.4500348821738878

Epoch: 6| Step: 10
Training loss: 2.654429181908758
Validation loss: 2.4642919375128454

Epoch: 6| Step: 11
Training loss: 2.1951196117440346
Validation loss: 2.4628776531800542

Epoch: 6| Step: 12
Training loss: 2.0643942255227277
Validation loss: 2.4609367249502747

Epoch: 6| Step: 13
Training loss: 2.9386876728647877
Validation loss: 2.4530071222124405

Epoch: 143| Step: 0
Training loss: 2.5340957657106173
Validation loss: 2.453454272936394

Epoch: 6| Step: 1
Training loss: 2.2142333143160524
Validation loss: 2.4569034027654872

Epoch: 6| Step: 2
Training loss: 2.4799620583923607
Validation loss: 2.45553528771108

Epoch: 6| Step: 3
Training loss: 2.38089442364225
Validation loss: 2.4610198799352356

Epoch: 6| Step: 4
Training loss: 2.295397536310634
Validation loss: 2.455396171854131

Epoch: 6| Step: 5
Training loss: 2.6643832284942137
Validation loss: 2.4684147023611

Epoch: 6| Step: 6
Training loss: 1.952119431082181
Validation loss: 2.465618231521941

Epoch: 6| Step: 7
Training loss: 2.5882847208770685
Validation loss: 2.467013106203205

Epoch: 6| Step: 8
Training loss: 2.672600720098276
Validation loss: 2.464290784583131

Epoch: 6| Step: 9
Training loss: 2.062958175168638
Validation loss: 2.4654948346453875

Epoch: 6| Step: 10
Training loss: 3.0177663207394563
Validation loss: 2.4573449933673563

Epoch: 6| Step: 11
Training loss: 2.224541426132494
Validation loss: 2.4566368024952703

Epoch: 6| Step: 12
Training loss: 2.600332891721003
Validation loss: 2.4522345965932213

Epoch: 6| Step: 13
Training loss: 2.785954472034937
Validation loss: 2.454063770444933

Epoch: 144| Step: 0
Training loss: 2.641832966990168
Validation loss: 2.458385246073565

Epoch: 6| Step: 1
Training loss: 2.4148785344570936
Validation loss: 2.4531385174356584

Epoch: 6| Step: 2
Training loss: 3.0005499017904644
Validation loss: 2.4524245669410196

Epoch: 6| Step: 3
Training loss: 2.758592792382259
Validation loss: 2.4549288910449274

Epoch: 6| Step: 4
Training loss: 2.496716059088801
Validation loss: 2.455017445172742

Epoch: 6| Step: 5
Training loss: 2.4906541657505086
Validation loss: 2.4583900951578235

Epoch: 6| Step: 6
Training loss: 2.6481717406760525
Validation loss: 2.4594648041863936

Epoch: 6| Step: 7
Training loss: 2.2754977090547848
Validation loss: 2.458425169915823

Epoch: 6| Step: 8
Training loss: 2.6600646508756847
Validation loss: 2.454218141008412

Epoch: 6| Step: 9
Training loss: 2.203574493222359
Validation loss: 2.454402234721524

Epoch: 6| Step: 10
Training loss: 1.891900003077083
Validation loss: 2.4604385273796954

Epoch: 6| Step: 11
Training loss: 2.765914126008545
Validation loss: 2.463337304400735

Epoch: 6| Step: 12
Training loss: 2.1424755256171895
Validation loss: 2.463445590338753

Epoch: 6| Step: 13
Training loss: 2.087920086102365
Validation loss: 2.471785984293227

Epoch: 145| Step: 0
Training loss: 2.5155355307265403
Validation loss: 2.4772427223415114

Epoch: 6| Step: 1
Training loss: 2.357774608552804
Validation loss: 2.4670537118712454

Epoch: 6| Step: 2
Training loss: 3.0936044986302487
Validation loss: 2.4549564886801694

Epoch: 6| Step: 3
Training loss: 2.144342243919477
Validation loss: 2.463886895430412

Epoch: 6| Step: 4
Training loss: 2.548641785573617
Validation loss: 2.4543072712575

Epoch: 6| Step: 5
Training loss: 2.7125167424260987
Validation loss: 2.4532338338954416

Epoch: 6| Step: 6
Training loss: 2.9433788154633374
Validation loss: 2.4582642502426166

Epoch: 6| Step: 7
Training loss: 2.033236427290908
Validation loss: 2.4518957034405506

Epoch: 6| Step: 8
Training loss: 2.1778355322638165
Validation loss: 2.4526969228397166

Epoch: 6| Step: 9
Training loss: 2.6992059423029624
Validation loss: 2.4580815935283167

Epoch: 6| Step: 10
Training loss: 2.5028109959542943
Validation loss: 2.4536126982275426

Epoch: 6| Step: 11
Training loss: 1.8766352198706233
Validation loss: 2.457503281025525

Epoch: 6| Step: 12
Training loss: 2.6113268467765196
Validation loss: 2.4550340355652285

Epoch: 6| Step: 13
Training loss: 2.2706879968826654
Validation loss: 2.4694567767182054

Epoch: 146| Step: 0
Training loss: 2.547745631900996
Validation loss: 2.455863331392658

Epoch: 6| Step: 1
Training loss: 2.5088364836835364
Validation loss: 2.4609181640511246

Epoch: 6| Step: 2
Training loss: 2.125577623736096
Validation loss: 2.4614983298051754

Epoch: 6| Step: 3
Training loss: 2.406954773576657
Validation loss: 2.4724987476038423

Epoch: 6| Step: 4
Training loss: 2.5747227269487687
Validation loss: 2.4715243657108728

Epoch: 6| Step: 5
Training loss: 2.154244416221562
Validation loss: 2.4710497224776824

Epoch: 6| Step: 6
Training loss: 2.9032411484330045
Validation loss: 2.4550878443155075

Epoch: 6| Step: 7
Training loss: 1.9940495185327871
Validation loss: 2.463228997570516

Epoch: 6| Step: 8
Training loss: 2.7477696651060124
Validation loss: 2.4579829488938314

Epoch: 6| Step: 9
Training loss: 2.368629947730263
Validation loss: 2.4666477539866767

Epoch: 6| Step: 10
Training loss: 2.336283170200283
Validation loss: 2.4662644311785917

Epoch: 6| Step: 11
Training loss: 2.6236223511269694
Validation loss: 2.4691061495358766

Epoch: 6| Step: 12
Training loss: 2.2320542454160877
Validation loss: 2.4662141934795763

Epoch: 6| Step: 13
Training loss: 2.6987408492342655
Validation loss: 2.4607183611147487

Epoch: 147| Step: 0
Training loss: 2.6449791037413726
Validation loss: 2.468277189795521

Epoch: 6| Step: 1
Training loss: 2.354366012730267
Validation loss: 2.4745728275015897

Epoch: 6| Step: 2
Training loss: 2.6252785489475605
Validation loss: 2.463084379395368

Epoch: 6| Step: 3
Training loss: 2.6841814710778658
Validation loss: 2.464695994063955

Epoch: 6| Step: 4
Training loss: 2.141231590142863
Validation loss: 2.4656929693293614

Epoch: 6| Step: 5
Training loss: 2.5006029355640047
Validation loss: 2.4704907231761792

Epoch: 6| Step: 6
Training loss: 2.5776803297865234
Validation loss: 2.4741382466533386

Epoch: 6| Step: 7
Training loss: 2.2374666605761844
Validation loss: 2.466459781330426

Epoch: 6| Step: 8
Training loss: 2.1295786504433387
Validation loss: 2.46790830532729

Epoch: 6| Step: 9
Training loss: 2.0161121578125654
Validation loss: 2.4650647789243623

Epoch: 6| Step: 10
Training loss: 3.2515630631306576
Validation loss: 2.4680686203522493

Epoch: 6| Step: 11
Training loss: 2.2363183167088403
Validation loss: 2.4690534026987376

Epoch: 6| Step: 12
Training loss: 2.776973908985557
Validation loss: 2.467918980438661

Epoch: 6| Step: 13
Training loss: 2.1994488936182237
Validation loss: 2.46521572846842

Epoch: 148| Step: 0
Training loss: 2.8055117785203656
Validation loss: 2.4649969134978806

Epoch: 6| Step: 1
Training loss: 2.4790394427141966
Validation loss: 2.474166368805904

Epoch: 6| Step: 2
Training loss: 3.156029721873145
Validation loss: 2.4708560378611293

Epoch: 6| Step: 3
Training loss: 2.661190330513721
Validation loss: 2.4768120512598513

Epoch: 6| Step: 4
Training loss: 2.067459270809536
Validation loss: 2.479230364347177

Epoch: 6| Step: 5
Training loss: 2.1858976762701054
Validation loss: 2.4779225815550125

Epoch: 6| Step: 6
Training loss: 2.5054338529492064
Validation loss: 2.4753784734808844

Epoch: 6| Step: 7
Training loss: 2.475443975527736
Validation loss: 2.475309823292439

Epoch: 6| Step: 8
Training loss: 2.0087014690582756
Validation loss: 2.4694902058816703

Epoch: 6| Step: 9
Training loss: 2.3818451465586628
Validation loss: 2.4666593286259073

Epoch: 6| Step: 10
Training loss: 2.9242380959443883
Validation loss: 2.4741536970131603

Epoch: 6| Step: 11
Training loss: 2.095013934432783
Validation loss: 2.4701522514585497

Epoch: 6| Step: 12
Training loss: 2.130678331776859
Validation loss: 2.469627514139278

Epoch: 6| Step: 13
Training loss: 2.183178365706581
Validation loss: 2.4743090304048345

Epoch: 149| Step: 0
Training loss: 2.1764247086636583
Validation loss: 2.4681244069589194

Epoch: 6| Step: 1
Training loss: 2.129044666515149
Validation loss: 2.464343818791708

Epoch: 6| Step: 2
Training loss: 2.1328960025077235
Validation loss: 2.465445677243974

Epoch: 6| Step: 3
Training loss: 2.814454141546485
Validation loss: 2.4746483787427462

Epoch: 6| Step: 4
Training loss: 2.7346390950868082
Validation loss: 2.4666190950428706

Epoch: 6| Step: 5
Training loss: 2.5959501931066264
Validation loss: 2.466971227384536

Epoch: 6| Step: 6
Training loss: 2.4945822185180204
Validation loss: 2.4637410981720507

Epoch: 6| Step: 7
Training loss: 2.770189043059977
Validation loss: 2.475842368183152

Epoch: 6| Step: 8
Training loss: 2.5054610687318917
Validation loss: 2.4705280387670294

Epoch: 6| Step: 9
Training loss: 2.0548095666865773
Validation loss: 2.4789053247584105

Epoch: 6| Step: 10
Training loss: 2.586932587260258
Validation loss: 2.486243019535321

Epoch: 6| Step: 11
Training loss: 2.338007593375896
Validation loss: 2.4993325773064843

Epoch: 6| Step: 12
Training loss: 2.4873786858348703
Validation loss: 2.477117618636866

Epoch: 6| Step: 13
Training loss: 2.4787931294423413
Validation loss: 2.4798607028403103

Epoch: 150| Step: 0
Training loss: 2.7450094890604184
Validation loss: 2.4701513063687486

Epoch: 6| Step: 1
Training loss: 2.1045370499858596
Validation loss: 2.4728425303795047

Epoch: 6| Step: 2
Training loss: 3.1111717975086624
Validation loss: 2.4731417194939183

Epoch: 6| Step: 3
Training loss: 2.535644390209774
Validation loss: 2.465608134693504

Epoch: 6| Step: 4
Training loss: 3.15072964891573
Validation loss: 2.467941232181493

Epoch: 6| Step: 5
Training loss: 2.5346026411256024
Validation loss: 2.466363856269767

Epoch: 6| Step: 6
Training loss: 2.080523949068822
Validation loss: 2.477911468452512

Epoch: 6| Step: 7
Training loss: 1.982976585915554
Validation loss: 2.4817303030114237

Epoch: 6| Step: 8
Training loss: 2.3263579965947443
Validation loss: 2.4799929505422345

Epoch: 6| Step: 9
Training loss: 2.099270276032483
Validation loss: 2.480777446931879

Epoch: 6| Step: 10
Training loss: 2.113986590390726
Validation loss: 2.4751640567287585

Epoch: 6| Step: 11
Training loss: 2.3994781522843245
Validation loss: 2.4800550381131696

Epoch: 6| Step: 12
Training loss: 2.646895778533914
Validation loss: 2.4851362793419907

Epoch: 6| Step: 13
Training loss: 2.1947644184185138
Validation loss: 2.474959487455029

Epoch: 151| Step: 0
Training loss: 2.89351662009848
Validation loss: 2.4782780783196663

Epoch: 6| Step: 1
Training loss: 2.254148050491075
Validation loss: 2.4726725452723817

Epoch: 6| Step: 2
Training loss: 2.5102390421687186
Validation loss: 2.468761089959969

Epoch: 6| Step: 3
Training loss: 1.8668363232943566
Validation loss: 2.46320153295028

Epoch: 6| Step: 4
Training loss: 2.3689407553649793
Validation loss: 2.46442915648368

Epoch: 6| Step: 5
Training loss: 2.4662917247399982
Validation loss: 2.4621152289969213

Epoch: 6| Step: 6
Training loss: 2.6443015242493546
Validation loss: 2.46542988219874

Epoch: 6| Step: 7
Training loss: 2.588211396688407
Validation loss: 2.4616448329464347

Epoch: 6| Step: 8
Training loss: 2.3228261157349746
Validation loss: 2.4678748466850906

Epoch: 6| Step: 9
Training loss: 2.560971525290906
Validation loss: 2.4683808481286853

Epoch: 6| Step: 10
Training loss: 3.058150024186938
Validation loss: 2.465184175627699

Epoch: 6| Step: 11
Training loss: 1.908038066804166
Validation loss: 2.46989074137195

Epoch: 6| Step: 12
Training loss: 2.058851424997944
Validation loss: 2.4682578228002554

Epoch: 6| Step: 13
Training loss: 2.4969375927161144
Validation loss: 2.4788125583989835

Epoch: 152| Step: 0
Training loss: 2.479010782763877
Validation loss: 2.473150114584743

Epoch: 6| Step: 1
Training loss: 2.3438890543059547
Validation loss: 2.466403095129358

Epoch: 6| Step: 2
Training loss: 2.335932498786191
Validation loss: 2.481065605223837

Epoch: 6| Step: 3
Training loss: 2.432874741735005
Validation loss: 2.479436576533139

Epoch: 6| Step: 4
Training loss: 2.5298498543375936
Validation loss: 2.478735979854596

Epoch: 6| Step: 5
Training loss: 1.9938202992066674
Validation loss: 2.4718482780057065

Epoch: 6| Step: 6
Training loss: 2.6524029866992906
Validation loss: 2.474877041674818

Epoch: 6| Step: 7
Training loss: 2.442581845867398
Validation loss: 2.4762692282846595

Epoch: 6| Step: 8
Training loss: 2.883196880073849
Validation loss: 2.470404814753222

Epoch: 6| Step: 9
Training loss: 2.011409165347602
Validation loss: 2.4754284770379695

Epoch: 6| Step: 10
Training loss: 2.5296561792330268
Validation loss: 2.4773107736013382

Epoch: 6| Step: 11
Training loss: 3.062329501641444
Validation loss: 2.481065268890496

Epoch: 6| Step: 12
Training loss: 2.03364023279329
Validation loss: 2.4760547522580363

Epoch: 6| Step: 13
Training loss: 2.3754952566861873
Validation loss: 2.4766721651042762

Epoch: 153| Step: 0
Training loss: 2.775300251981299
Validation loss: 2.4683322472562423

Epoch: 6| Step: 1
Training loss: 2.666007039821342
Validation loss: 2.4675798822038093

Epoch: 6| Step: 2
Training loss: 2.7604998498055324
Validation loss: 2.4656479496405543

Epoch: 6| Step: 3
Training loss: 2.1986317367801846
Validation loss: 2.4649590466794047

Epoch: 6| Step: 4
Training loss: 3.00116865919309
Validation loss: 2.462749173617138

Epoch: 6| Step: 5
Training loss: 2.5311938621041477
Validation loss: 2.4650150165010194

Epoch: 6| Step: 6
Training loss: 1.9386154778428875
Validation loss: 2.459534583272344

Epoch: 6| Step: 7
Training loss: 1.7616001943548305
Validation loss: 2.4667208658097635

Epoch: 6| Step: 8
Training loss: 2.509479859703952
Validation loss: 2.4584480328930463

Epoch: 6| Step: 9
Training loss: 2.2904487032006213
Validation loss: 2.4621901134818107

Epoch: 6| Step: 10
Training loss: 2.452565123211563
Validation loss: 2.4689180662996884

Epoch: 6| Step: 11
Training loss: 2.5110205930338636
Validation loss: 2.474637234878977

Epoch: 6| Step: 12
Training loss: 2.8491357798063013
Validation loss: 2.475260828704773

Epoch: 6| Step: 13
Training loss: 2.5555957731132284
Validation loss: 2.4770648498957777

Epoch: 154| Step: 0
Training loss: 2.436916966278726
Validation loss: 2.4704682048745292

Epoch: 6| Step: 1
Training loss: 2.651939394976149
Validation loss: 2.4659874182754242

Epoch: 6| Step: 2
Training loss: 3.009633808356158
Validation loss: 2.475780367567716

Epoch: 6| Step: 3
Training loss: 2.3877396468276677
Validation loss: 2.4793855800199385

Epoch: 6| Step: 4
Training loss: 2.1542692070271103
Validation loss: 2.4808005443948007

Epoch: 6| Step: 5
Training loss: 2.1119430168874325
Validation loss: 2.479210834483726

Epoch: 6| Step: 6
Training loss: 1.8485301493548139
Validation loss: 2.4661730583860697

Epoch: 6| Step: 7
Training loss: 3.075967875180205
Validation loss: 2.4725378489257186

Epoch: 6| Step: 8
Training loss: 2.583081376699372
Validation loss: 2.474220427968362

Epoch: 6| Step: 9
Training loss: 2.545813871851413
Validation loss: 2.4693118715500204

Epoch: 6| Step: 10
Training loss: 2.1619973364715683
Validation loss: 2.4746948323777653

Epoch: 6| Step: 11
Training loss: 2.3166528477245176
Validation loss: 2.465343426709362

Epoch: 6| Step: 12
Training loss: 2.4382214578901698
Validation loss: 2.4731625424802766

Epoch: 6| Step: 13
Training loss: 2.394230336733388
Validation loss: 2.461688497283393

Epoch: 155| Step: 0
Training loss: 2.423115074406983
Validation loss: 2.4747579359880514

Epoch: 6| Step: 1
Training loss: 2.677056536311551
Validation loss: 2.4816603474208834

Epoch: 6| Step: 2
Training loss: 2.4799585012840075
Validation loss: 2.4755239144104166

Epoch: 6| Step: 3
Training loss: 2.6086793988868693
Validation loss: 2.4685775036646143

Epoch: 6| Step: 4
Training loss: 2.059231335457998
Validation loss: 2.481466057800905

Epoch: 6| Step: 5
Training loss: 2.096023691480271
Validation loss: 2.483067086260785

Epoch: 6| Step: 6
Training loss: 2.899456328369522
Validation loss: 2.4879670156804923

Epoch: 6| Step: 7
Training loss: 2.5313287416620263
Validation loss: 2.481142063819993

Epoch: 6| Step: 8
Training loss: 2.6424506382946826
Validation loss: 2.4941917499827815

Epoch: 6| Step: 9
Training loss: 2.3928260394517036
Validation loss: 2.478524723341896

Epoch: 6| Step: 10
Training loss: 3.0225663223751993
Validation loss: 2.486463121064116

Epoch: 6| Step: 11
Training loss: 2.284414526392606
Validation loss: 2.4781050345733795

Epoch: 6| Step: 12
Training loss: 1.7680305365648263
Validation loss: 2.483051963415024

Epoch: 6| Step: 13
Training loss: 2.0067361403105823
Validation loss: 2.472466299304974

Epoch: 156| Step: 0
Training loss: 2.3749357515980827
Validation loss: 2.4800920015108

Epoch: 6| Step: 1
Training loss: 1.9092876433072792
Validation loss: 2.4774849233800516

Epoch: 6| Step: 2
Training loss: 2.4851832964281937
Validation loss: 2.4819198889200447

Epoch: 6| Step: 3
Training loss: 2.3406098756186924
Validation loss: 2.488263867216212

Epoch: 6| Step: 4
Training loss: 2.6755558113859834
Validation loss: 2.4922774566710424

Epoch: 6| Step: 5
Training loss: 2.6857352561769696
Validation loss: 2.4772254866697607

Epoch: 6| Step: 6
Training loss: 2.0389401921681687
Validation loss: 2.4799472691200855

Epoch: 6| Step: 7
Training loss: 2.6641770503231856
Validation loss: 2.5031903255604457

Epoch: 6| Step: 8
Training loss: 2.6820236121495893
Validation loss: 2.5031684268481524

Epoch: 6| Step: 9
Training loss: 2.222786039776543
Validation loss: 2.4853961213619806

Epoch: 6| Step: 10
Training loss: 2.185065195084302
Validation loss: 2.485358741215279

Epoch: 6| Step: 11
Training loss: 2.491572002113832
Validation loss: 2.4787150433785152

Epoch: 6| Step: 12
Training loss: 1.9944250966865953
Validation loss: 2.4802663004602

Epoch: 6| Step: 13
Training loss: 3.0196661086273715
Validation loss: 2.4827411805415163

Epoch: 157| Step: 0
Training loss: 2.034849879658291
Validation loss: 2.487617048707784

Epoch: 6| Step: 1
Training loss: 2.418535847017891
Validation loss: 2.484567590762039

Epoch: 6| Step: 2
Training loss: 2.1248474066306136
Validation loss: 2.4892534705156977

Epoch: 6| Step: 3
Training loss: 2.282254350694648
Validation loss: 2.486196142360978

Epoch: 6| Step: 4
Training loss: 2.4315428687365688
Validation loss: 2.4849003010532886

Epoch: 6| Step: 5
Training loss: 2.948746275792311
Validation loss: 2.4835040727160456

Epoch: 6| Step: 6
Training loss: 2.1282916660556657
Validation loss: 2.4920080552825628

Epoch: 6| Step: 7
Training loss: 1.9207154784659675
Validation loss: 2.481864876714878

Epoch: 6| Step: 8
Training loss: 2.15147279816953
Validation loss: 2.4873321016476106

Epoch: 6| Step: 9
Training loss: 2.6108636321708256
Validation loss: 2.492398515176573

Epoch: 6| Step: 10
Training loss: 2.875697839051147
Validation loss: 2.5148305803522746

Epoch: 6| Step: 11
Training loss: 2.394641967006025
Validation loss: 2.5167427817785835

Epoch: 6| Step: 12
Training loss: 2.6565397216768054
Validation loss: 2.519169255553024

Epoch: 6| Step: 13
Training loss: 2.982986686500357
Validation loss: 2.5020902160837846

Epoch: 158| Step: 0
Training loss: 3.0831960355415453
Validation loss: 2.500256564962427

Epoch: 6| Step: 1
Training loss: 2.4813089704832674
Validation loss: 2.4922763565470345

Epoch: 6| Step: 2
Training loss: 2.5624964644244854
Validation loss: 2.4874757334229987

Epoch: 6| Step: 3
Training loss: 2.2199709044946916
Validation loss: 2.4954336743282917

Epoch: 6| Step: 4
Training loss: 2.4918725463457085
Validation loss: 2.493487107928901

Epoch: 6| Step: 5
Training loss: 2.7843000853593405
Validation loss: 2.48089121827788

Epoch: 6| Step: 6
Training loss: 2.509754795392491
Validation loss: 2.4979776626873007

Epoch: 6| Step: 7
Training loss: 2.611293612746413
Validation loss: 2.489882324864729

Epoch: 6| Step: 8
Training loss: 1.9995678196304105
Validation loss: 2.4851359755388476

Epoch: 6| Step: 9
Training loss: 1.5590204023013523
Validation loss: 2.4777396820924054

Epoch: 6| Step: 10
Training loss: 2.6403836472946733
Validation loss: 2.4732622043924555

Epoch: 6| Step: 11
Training loss: 2.443391478012772
Validation loss: 2.4678135153974585

Epoch: 6| Step: 12
Training loss: 2.4276387202721392
Validation loss: 2.472524855398455

Epoch: 6| Step: 13
Training loss: 2.0930737214571753
Validation loss: 2.469405187912925

Epoch: 159| Step: 0
Training loss: 2.733392157348091
Validation loss: 2.4748096219449316

Epoch: 6| Step: 1
Training loss: 2.5102688652205765
Validation loss: 2.4692031267452337

Epoch: 6| Step: 2
Training loss: 2.693590050570923
Validation loss: 2.4743668121950138

Epoch: 6| Step: 3
Training loss: 2.020115662653212
Validation loss: 2.4755046843688158

Epoch: 6| Step: 4
Training loss: 2.2916379637799147
Validation loss: 2.4768225917362057

Epoch: 6| Step: 5
Training loss: 1.8321212388571506
Validation loss: 2.473651655496604

Epoch: 6| Step: 6
Training loss: 3.002418338068501
Validation loss: 2.4737106413406376

Epoch: 6| Step: 7
Training loss: 2.863330543999281
Validation loss: 2.4769831800519877

Epoch: 6| Step: 8
Training loss: 1.9354782631239098
Validation loss: 2.4820442222582013

Epoch: 6| Step: 9
Training loss: 2.399130059568386
Validation loss: 2.506102782291306

Epoch: 6| Step: 10
Training loss: 2.853377258580638
Validation loss: 2.5047469371803963

Epoch: 6| Step: 11
Training loss: 2.254012133459894
Validation loss: 2.520780788746239

Epoch: 6| Step: 12
Training loss: 1.889983643758733
Validation loss: 2.525608589303442

Epoch: 6| Step: 13
Training loss: 2.7381747629136237
Validation loss: 2.5143349066273437

Epoch: 160| Step: 0
Training loss: 2.326327660610492
Validation loss: 2.502121343226026

Epoch: 6| Step: 1
Training loss: 2.3906902229537113
Validation loss: 2.4778688276731966

Epoch: 6| Step: 2
Training loss: 2.1894475713926553
Validation loss: 2.4793556899984046

Epoch: 6| Step: 3
Training loss: 2.6928143852398168
Validation loss: 2.4712127441417655

Epoch: 6| Step: 4
Training loss: 2.0766959188410454
Validation loss: 2.46623625114567

Epoch: 6| Step: 5
Training loss: 2.5728163191239837
Validation loss: 2.4654760582454527

Epoch: 6| Step: 6
Training loss: 2.322170451325868
Validation loss: 2.467035180886686

Epoch: 6| Step: 7
Training loss: 2.54311031762003
Validation loss: 2.471512950516777

Epoch: 6| Step: 8
Training loss: 2.7836401452398474
Validation loss: 2.4752310975713105

Epoch: 6| Step: 9
Training loss: 2.79614666027776
Validation loss: 2.473472215509654

Epoch: 6| Step: 10
Training loss: 1.8804020310766454
Validation loss: 2.472019846868419

Epoch: 6| Step: 11
Training loss: 2.319813067699073
Validation loss: 2.469600008045856

Epoch: 6| Step: 12
Training loss: 2.5897975359399514
Validation loss: 2.4722499342828472

Epoch: 6| Step: 13
Training loss: 2.674197252985646
Validation loss: 2.474692359582666

Epoch: 161| Step: 0
Training loss: 2.8118324335237883
Validation loss: 2.4812456811567847

Epoch: 6| Step: 1
Training loss: 2.4063356062288337
Validation loss: 2.4822361053980524

Epoch: 6| Step: 2
Training loss: 2.6751346447294275
Validation loss: 2.4822579246422927

Epoch: 6| Step: 3
Training loss: 2.7034218685768434
Validation loss: 2.4962768009983907

Epoch: 6| Step: 4
Training loss: 2.650995959854069
Validation loss: 2.5076647880364957

Epoch: 6| Step: 5
Training loss: 2.0717286071151566
Validation loss: 2.5098279260010163

Epoch: 6| Step: 6
Training loss: 1.9223779780005579
Validation loss: 2.5130196105216154

Epoch: 6| Step: 7
Training loss: 2.1625894428785384
Validation loss: 2.518819672005075

Epoch: 6| Step: 8
Training loss: 2.3212064825445697
Validation loss: 2.533663160620366

Epoch: 6| Step: 9
Training loss: 2.1648210098245158
Validation loss: 2.543963744035117

Epoch: 6| Step: 10
Training loss: 2.539044752792544
Validation loss: 2.5426248141059693

Epoch: 6| Step: 11
Training loss: 2.5175708329692204
Validation loss: 2.51887064314336

Epoch: 6| Step: 12
Training loss: 2.7005469757158633
Validation loss: 2.501907479244284

Epoch: 6| Step: 13
Training loss: 2.2318669895272993
Validation loss: 2.493565862831835

Epoch: 162| Step: 0
Training loss: 2.2757790164432374
Validation loss: 2.4878194830632387

Epoch: 6| Step: 1
Training loss: 2.950798773517848
Validation loss: 2.478188318996604

Epoch: 6| Step: 2
Training loss: 2.2020969021131624
Validation loss: 2.486302146166586

Epoch: 6| Step: 3
Training loss: 2.5326238600783544
Validation loss: 2.486258546505433

Epoch: 6| Step: 4
Training loss: 2.078277582289096
Validation loss: 2.485116556045071

Epoch: 6| Step: 5
Training loss: 2.0045636086004586
Validation loss: 2.4815667873426075

Epoch: 6| Step: 6
Training loss: 1.6745229411793343
Validation loss: 2.4871437750593692

Epoch: 6| Step: 7
Training loss: 1.690307824355274
Validation loss: 2.49069848616299

Epoch: 6| Step: 8
Training loss: 2.647747838970776
Validation loss: 2.4805279902395245

Epoch: 6| Step: 9
Training loss: 2.803212152357411
Validation loss: 2.48957201956462

Epoch: 6| Step: 10
Training loss: 2.693367518909914
Validation loss: 2.4941678843530837

Epoch: 6| Step: 11
Training loss: 2.7216606782783868
Validation loss: 2.5012948338755865

Epoch: 6| Step: 12
Training loss: 2.851745934008033
Validation loss: 2.5022317461713754

Epoch: 6| Step: 13
Training loss: 2.122646824012357
Validation loss: 2.5182547556468897

Epoch: 163| Step: 0
Training loss: 2.9365000544670954
Validation loss: 2.5313428853892646

Epoch: 6| Step: 1
Training loss: 2.5243500278991604
Validation loss: 2.5312575351932596

Epoch: 6| Step: 2
Training loss: 2.564226080902761
Validation loss: 2.5235821079198733

Epoch: 6| Step: 3
Training loss: 2.2550749236387615
Validation loss: 2.5390750669510718

Epoch: 6| Step: 4
Training loss: 2.1310144467662955
Validation loss: 2.5226810136313818

Epoch: 6| Step: 5
Training loss: 2.2984208075917585
Validation loss: 2.5032450278496388

Epoch: 6| Step: 6
Training loss: 1.8107079163732476
Validation loss: 2.494981162586846

Epoch: 6| Step: 7
Training loss: 1.9464760483317347
Validation loss: 2.4756207525750877

Epoch: 6| Step: 8
Training loss: 2.463022662623444
Validation loss: 2.4822004145920586

Epoch: 6| Step: 9
Training loss: 2.364080322359807
Validation loss: 2.476597205078327

Epoch: 6| Step: 10
Training loss: 2.564459818869786
Validation loss: 2.4763290664294453

Epoch: 6| Step: 11
Training loss: 2.4834007416180817
Validation loss: 2.468693631973261

Epoch: 6| Step: 12
Training loss: 2.5528479436290397
Validation loss: 2.4774455232145076

Epoch: 6| Step: 13
Training loss: 2.6884803758089104
Validation loss: 2.482307213336915

Epoch: 164| Step: 0
Training loss: 1.6875144816589622
Validation loss: 2.480629574826021

Epoch: 6| Step: 1
Training loss: 2.3687410701694107
Validation loss: 2.485513718067294

Epoch: 6| Step: 2
Training loss: 2.0131881532471714
Validation loss: 2.475285647185257

Epoch: 6| Step: 3
Training loss: 2.400093327138215
Validation loss: 2.479974011520889

Epoch: 6| Step: 4
Training loss: 2.9953421354942065
Validation loss: 2.4761224750903463

Epoch: 6| Step: 5
Training loss: 2.449968189889356
Validation loss: 2.4791087189214474

Epoch: 6| Step: 6
Training loss: 2.6077407013350022
Validation loss: 2.4832575942230313

Epoch: 6| Step: 7
Training loss: 2.035282768080377
Validation loss: 2.4943057219435767

Epoch: 6| Step: 8
Training loss: 2.078459519157956
Validation loss: 2.5021964755643107

Epoch: 6| Step: 9
Training loss: 2.4445720685048364
Validation loss: 2.502708858929315

Epoch: 6| Step: 10
Training loss: 2.363541316075395
Validation loss: 2.513662643040221

Epoch: 6| Step: 11
Training loss: 2.5473510671698985
Validation loss: 2.5191782465029355

Epoch: 6| Step: 12
Training loss: 2.5996805434942685
Validation loss: 2.513783825621928

Epoch: 6| Step: 13
Training loss: 2.926833407953483
Validation loss: 2.5145216550007707

Epoch: 165| Step: 0
Training loss: 2.4633537903668836
Validation loss: 2.508483297885876

Epoch: 6| Step: 1
Training loss: 2.592125993197826
Validation loss: 2.5050858264770803

Epoch: 6| Step: 2
Training loss: 2.379799660978126
Validation loss: 2.487274301535784

Epoch: 6| Step: 3
Training loss: 2.4888461203912002
Validation loss: 2.500348734374377

Epoch: 6| Step: 4
Training loss: 1.8719778500738176
Validation loss: 2.4869683443536346

Epoch: 6| Step: 5
Training loss: 2.4340937362588426
Validation loss: 2.492425745754275

Epoch: 6| Step: 6
Training loss: 2.7729680913278574
Validation loss: 2.4804853143414283

Epoch: 6| Step: 7
Training loss: 2.2574566095349664
Validation loss: 2.4833713799534065

Epoch: 6| Step: 8
Training loss: 2.4915863555757523
Validation loss: 2.4874261158205395

Epoch: 6| Step: 9
Training loss: 2.1759688400954658
Validation loss: 2.491753981941149

Epoch: 6| Step: 10
Training loss: 2.6121218722537796
Validation loss: 2.496280828319655

Epoch: 6| Step: 11
Training loss: 2.0597529757635966
Validation loss: 2.499491957859431

Epoch: 6| Step: 12
Training loss: 2.4398766692839042
Validation loss: 2.498945077211925

Epoch: 6| Step: 13
Training loss: 2.7990163778389445
Validation loss: 2.5224892770610503

Epoch: 166| Step: 0
Training loss: 2.3234042239034918
Validation loss: 2.5160422285182036

Epoch: 6| Step: 1
Training loss: 2.191574661393027
Validation loss: 2.5191226125136192

Epoch: 6| Step: 2
Training loss: 1.53945584765186
Validation loss: 2.5061798009768212

Epoch: 6| Step: 3
Training loss: 2.8988211241661856
Validation loss: 2.508343071036801

Epoch: 6| Step: 4
Training loss: 2.5643679625758375
Validation loss: 2.5081727590100567

Epoch: 6| Step: 5
Training loss: 2.9374131534805796
Validation loss: 2.5106377932927124

Epoch: 6| Step: 6
Training loss: 2.26176112634362
Validation loss: 2.51234245565502

Epoch: 6| Step: 7
Training loss: 2.3230269766533134
Validation loss: 2.5081471094176804

Epoch: 6| Step: 8
Training loss: 2.3585190388742205
Validation loss: 2.509574785905706

Epoch: 6| Step: 9
Training loss: 2.7951161059180967
Validation loss: 2.513042253524859

Epoch: 6| Step: 10
Training loss: 2.10480767737438
Validation loss: 2.51831026679768

Epoch: 6| Step: 11
Training loss: 2.5496689151423686
Validation loss: 2.507553071322167

Epoch: 6| Step: 12
Training loss: 2.586654517581108
Validation loss: 2.526339567780829

Epoch: 6| Step: 13
Training loss: 1.9878044231162548
Validation loss: 2.5344742698685367

Epoch: 167| Step: 0
Training loss: 2.3940887291191837
Validation loss: 2.5224293051959057

Epoch: 6| Step: 1
Training loss: 2.0419042669603558
Validation loss: 2.50848075543314

Epoch: 6| Step: 2
Training loss: 2.7336853901606766
Validation loss: 2.4893844769810083

Epoch: 6| Step: 3
Training loss: 2.112197908549957
Validation loss: 2.496708101337051

Epoch: 6| Step: 4
Training loss: 2.3482852036160287
Validation loss: 2.4880711313558708

Epoch: 6| Step: 5
Training loss: 2.663726785487924
Validation loss: 2.471137940112884

Epoch: 6| Step: 6
Training loss: 2.956523574526088
Validation loss: 2.4826864426214814

Epoch: 6| Step: 7
Training loss: 2.3206147790134586
Validation loss: 2.4875356055032545

Epoch: 6| Step: 8
Training loss: 2.4026067326204887
Validation loss: 2.4789913874193537

Epoch: 6| Step: 9
Training loss: 2.3489051581635048
Validation loss: 2.4890391075502185

Epoch: 6| Step: 10
Training loss: 2.249179266542993
Validation loss: 2.4838975651547144

Epoch: 6| Step: 11
Training loss: 2.699697272672384
Validation loss: 2.496362328444717

Epoch: 6| Step: 12
Training loss: 1.9547093183609447
Validation loss: 2.5054245906340586

Epoch: 6| Step: 13
Training loss: 2.4328192738345003
Validation loss: 2.5045208109826644

Epoch: 168| Step: 0
Training loss: 2.332464283366138
Validation loss: 2.516281263470218

Epoch: 6| Step: 1
Training loss: 2.7797900879462882
Validation loss: 2.5261331810383427

Epoch: 6| Step: 2
Training loss: 2.966817608397352
Validation loss: 2.5304442092507946

Epoch: 6| Step: 3
Training loss: 2.1053989943801885
Validation loss: 2.519641820566154

Epoch: 6| Step: 4
Training loss: 2.293792524645192
Validation loss: 2.510631968867068

Epoch: 6| Step: 5
Training loss: 2.030465311925956
Validation loss: 2.503391778376263

Epoch: 6| Step: 6
Training loss: 2.021770954550385
Validation loss: 2.4944960565709797

Epoch: 6| Step: 7
Training loss: 2.8907497069805617
Validation loss: 2.4811849846637655

Epoch: 6| Step: 8
Training loss: 2.169027753737691
Validation loss: 2.4814766345548764

Epoch: 6| Step: 9
Training loss: 1.6019121486182908
Validation loss: 2.483982910949272

Epoch: 6| Step: 10
Training loss: 1.89692495867882
Validation loss: 2.4900143834098247

Epoch: 6| Step: 11
Training loss: 2.8205172393115094
Validation loss: 2.4895015181714117

Epoch: 6| Step: 12
Training loss: 2.881516410774286
Validation loss: 2.494660062776419

Epoch: 6| Step: 13
Training loss: 2.6185506885947873
Validation loss: 2.5035277907338362

Epoch: 169| Step: 0
Training loss: 2.766592600034018
Validation loss: 2.509615795447641

Epoch: 6| Step: 1
Training loss: 2.8582975098021226
Validation loss: 2.5258760745380897

Epoch: 6| Step: 2
Training loss: 1.9661301029072893
Validation loss: 2.537215279827509

Epoch: 6| Step: 3
Training loss: 2.4865016831730404
Validation loss: 2.53754432871266

Epoch: 6| Step: 4
Training loss: 1.7171680452808462
Validation loss: 2.5156435995421327

Epoch: 6| Step: 5
Training loss: 2.1821646884827763
Validation loss: 2.500129847333399

Epoch: 6| Step: 6
Training loss: 2.8987049894469643
Validation loss: 2.4855913267667558

Epoch: 6| Step: 7
Training loss: 2.9302021032421512
Validation loss: 2.502629581974685

Epoch: 6| Step: 8
Training loss: 2.2938257854529382
Validation loss: 2.501355884350031

Epoch: 6| Step: 9
Training loss: 2.463064866705231
Validation loss: 2.498828279567688

Epoch: 6| Step: 10
Training loss: 2.2068513780062657
Validation loss: 2.50632319291973

Epoch: 6| Step: 11
Training loss: 2.02051937640178
Validation loss: 2.495038481564016

Epoch: 6| Step: 12
Training loss: 2.1973782523218106
Validation loss: 2.4958984744360047

Epoch: 6| Step: 13
Training loss: 2.5607310446376816
Validation loss: 2.4918528683938335

Epoch: 170| Step: 0
Training loss: 2.136237779005349
Validation loss: 2.4895204964426276

Epoch: 6| Step: 1
Training loss: 2.9198879074111224
Validation loss: 2.4889848114680304

Epoch: 6| Step: 2
Training loss: 1.9438355135736038
Validation loss: 2.481892350948808

Epoch: 6| Step: 3
Training loss: 2.5346144933466337
Validation loss: 2.4824537129615245

Epoch: 6| Step: 4
Training loss: 1.7310528253861417
Validation loss: 2.482596338495814

Epoch: 6| Step: 5
Training loss: 2.0606186117548178
Validation loss: 2.4831105179215944

Epoch: 6| Step: 6
Training loss: 2.5223042213827176
Validation loss: 2.4827966054572057

Epoch: 6| Step: 7
Training loss: 2.755182671141985
Validation loss: 2.4874402535833684

Epoch: 6| Step: 8
Training loss: 2.6559130286604087
Validation loss: 2.481293788879047

Epoch: 6| Step: 9
Training loss: 3.0094043829286607
Validation loss: 2.483868273354166

Epoch: 6| Step: 10
Training loss: 2.1218898677164595
Validation loss: 2.48484743372718

Epoch: 6| Step: 11
Training loss: 2.388626559834373
Validation loss: 2.4915076816406483

Epoch: 6| Step: 12
Training loss: 2.6255677835304665
Validation loss: 2.4986276515658012

Epoch: 6| Step: 13
Training loss: 2.3761415247912745
Validation loss: 2.516464006609306

Epoch: 171| Step: 0
Training loss: 2.097480638707933
Validation loss: 2.5416024674192386

Epoch: 6| Step: 1
Training loss: 1.5031303484974197
Validation loss: 2.5208061363917906

Epoch: 6| Step: 2
Training loss: 2.262316372833069
Validation loss: 2.5224644976846893

Epoch: 6| Step: 3
Training loss: 2.2444331922133665
Validation loss: 2.5163721432250146

Epoch: 6| Step: 4
Training loss: 2.0995192113634675
Validation loss: 2.496511950654175

Epoch: 6| Step: 5
Training loss: 3.0104360260830445
Validation loss: 2.490133365751669

Epoch: 6| Step: 6
Training loss: 2.956831931649394
Validation loss: 2.4913401344022064

Epoch: 6| Step: 7
Training loss: 2.1798973939529454
Validation loss: 2.488182588913911

Epoch: 6| Step: 8
Training loss: 2.4667506753517157
Validation loss: 2.4763226317720775

Epoch: 6| Step: 9
Training loss: 3.4620710802720325
Validation loss: 2.481400746747626

Epoch: 6| Step: 10
Training loss: 1.8693654274958451
Validation loss: 2.4832772602774202

Epoch: 6| Step: 11
Training loss: 2.6215738007559617
Validation loss: 2.476570658865886

Epoch: 6| Step: 12
Training loss: 2.1415726172234524
Validation loss: 2.4807641361603565

Epoch: 6| Step: 13
Training loss: 2.521832123761812
Validation loss: 2.4874230486342674

Epoch: 172| Step: 0
Training loss: 2.0294471369341225
Validation loss: 2.4885684994868607

Epoch: 6| Step: 1
Training loss: 2.7687716067743358
Validation loss: 2.48918749377087

Epoch: 6| Step: 2
Training loss: 2.6814549792349793
Validation loss: 2.5046743086802454

Epoch: 6| Step: 3
Training loss: 2.4994221973279354
Validation loss: 2.503715369000441

Epoch: 6| Step: 4
Training loss: 2.731938960911283
Validation loss: 2.519155287969821

Epoch: 6| Step: 5
Training loss: 1.8806295442637204
Validation loss: 2.5318335971038195

Epoch: 6| Step: 6
Training loss: 2.7440082124414804
Validation loss: 2.553588055096999

Epoch: 6| Step: 7
Training loss: 3.206034311397708
Validation loss: 2.53408880346423

Epoch: 6| Step: 8
Training loss: 2.210088560133741
Validation loss: 2.5043413455695673

Epoch: 6| Step: 9
Training loss: 2.1166101773551267
Validation loss: 2.5022374789875967

Epoch: 6| Step: 10
Training loss: 2.2624157505261406
Validation loss: 2.503035403333639

Epoch: 6| Step: 11
Training loss: 2.3510732553703892
Validation loss: 2.4988537306291385

Epoch: 6| Step: 12
Training loss: 2.043377166244713
Validation loss: 2.4805296562506856

Epoch: 6| Step: 13
Training loss: 2.0088774828999627
Validation loss: 2.487169193910288

Epoch: 173| Step: 0
Training loss: 2.3627101744154175
Validation loss: 2.487923349365023

Epoch: 6| Step: 1
Training loss: 1.8502537733724276
Validation loss: 2.481233117585037

Epoch: 6| Step: 2
Training loss: 2.088253949547395
Validation loss: 2.4833919411555647

Epoch: 6| Step: 3
Training loss: 3.003445236486628
Validation loss: 2.4722185676585795

Epoch: 6| Step: 4
Training loss: 2.777649853197882
Validation loss: 2.4805933723282023

Epoch: 6| Step: 5
Training loss: 1.6907000399874672
Validation loss: 2.480507341219852

Epoch: 6| Step: 6
Training loss: 2.803816551204379
Validation loss: 2.4884261044708373

Epoch: 6| Step: 7
Training loss: 2.0559930751030815
Validation loss: 2.498752203121871

Epoch: 6| Step: 8
Training loss: 2.3636926214152116
Validation loss: 2.498239230936386

Epoch: 6| Step: 9
Training loss: 2.6421942929045774
Validation loss: 2.504329746752362

Epoch: 6| Step: 10
Training loss: 2.002998488503246
Validation loss: 2.511674080664567

Epoch: 6| Step: 11
Training loss: 2.541693911380351
Validation loss: 2.496962482191416

Epoch: 6| Step: 12
Training loss: 2.7512869857804727
Validation loss: 2.5126987600074324

Epoch: 6| Step: 13
Training loss: 2.3015710482208767
Validation loss: 2.52750414693601

Epoch: 174| Step: 0
Training loss: 1.7042735015784212
Validation loss: 2.541290776541211

Epoch: 6| Step: 1
Training loss: 2.931821651066884
Validation loss: 2.551458123885773

Epoch: 6| Step: 2
Training loss: 2.69972650414335
Validation loss: 2.542915589792131

Epoch: 6| Step: 3
Training loss: 2.337198892874964
Validation loss: 2.5508733774618904

Epoch: 6| Step: 4
Training loss: 1.945508525730688
Validation loss: 2.5355949237842883

Epoch: 6| Step: 5
Training loss: 2.611276995572745
Validation loss: 2.518172401858816

Epoch: 6| Step: 6
Training loss: 3.005192395745939
Validation loss: 2.4911402352475074

Epoch: 6| Step: 7
Training loss: 3.2356122732547723
Validation loss: 2.4854142036862785

Epoch: 6| Step: 8
Training loss: 2.220476580146919
Validation loss: 2.481045857574727

Epoch: 6| Step: 9
Training loss: 2.22301728278
Validation loss: 2.4758413490294906

Epoch: 6| Step: 10
Training loss: 2.099864287759582
Validation loss: 2.473356640912416

Epoch: 6| Step: 11
Training loss: 2.452885512792472
Validation loss: 2.4738191639087215

Epoch: 6| Step: 12
Training loss: 2.5270004393045444
Validation loss: 2.4727057782958446

Epoch: 6| Step: 13
Training loss: 2.214988744117261
Validation loss: 2.4785913446321697

Epoch: 175| Step: 0
Training loss: 2.289524279160569
Validation loss: 2.477165076658518

Epoch: 6| Step: 1
Training loss: 1.9387011342681717
Validation loss: 2.477341634652622

Epoch: 6| Step: 2
Training loss: 2.3650348809151964
Validation loss: 2.4819266853083772

Epoch: 6| Step: 3
Training loss: 2.9298627877248826
Validation loss: 2.4809138982434757

Epoch: 6| Step: 4
Training loss: 2.3438448060252295
Validation loss: 2.482967497827087

Epoch: 6| Step: 5
Training loss: 1.8901850921582224
Validation loss: 2.4852070164944147

Epoch: 6| Step: 6
Training loss: 1.9953274385017032
Validation loss: 2.493308617355458

Epoch: 6| Step: 7
Training loss: 2.335475301786321
Validation loss: 2.479009428300531

Epoch: 6| Step: 8
Training loss: 2.6998594106169986
Validation loss: 2.4986237393504735

Epoch: 6| Step: 9
Training loss: 2.6473492662495834
Validation loss: 2.4940397420906844

Epoch: 6| Step: 10
Training loss: 2.678959605836219
Validation loss: 2.509213730509946

Epoch: 6| Step: 11
Training loss: 2.13003381388872
Validation loss: 2.508430254342682

Epoch: 6| Step: 12
Training loss: 2.7357813243200364
Validation loss: 2.502932465792734

Epoch: 6| Step: 13
Training loss: 2.303089065996069
Validation loss: 2.5126959608847868

Epoch: 176| Step: 0
Training loss: 2.7498761062456847
Validation loss: 2.519442660723523

Epoch: 6| Step: 1
Training loss: 2.7806115435606715
Validation loss: 2.529956722718661

Epoch: 6| Step: 2
Training loss: 2.3382963690506346
Validation loss: 2.521282980883944

Epoch: 6| Step: 3
Training loss: 2.1927527440542898
Validation loss: 2.515301843583411

Epoch: 6| Step: 4
Training loss: 2.592181731269952
Validation loss: 2.5004939068233925

Epoch: 6| Step: 5
Training loss: 2.4502595335844295
Validation loss: 2.5024417555894063

Epoch: 6| Step: 6
Training loss: 2.1307715407467316
Validation loss: 2.493214299051584

Epoch: 6| Step: 7
Training loss: 2.4533897305654366
Validation loss: 2.496784255981227

Epoch: 6| Step: 8
Training loss: 1.9973578882571243
Validation loss: 2.488787589064737

Epoch: 6| Step: 9
Training loss: 2.861125472772431
Validation loss: 2.5017597680639265

Epoch: 6| Step: 10
Training loss: 2.142166585006283
Validation loss: 2.4984737028608746

Epoch: 6| Step: 11
Training loss: 2.6188405751881794
Validation loss: 2.49936123475881

Epoch: 6| Step: 12
Training loss: 2.0532639362118177
Validation loss: 2.500673791367583

Epoch: 6| Step: 13
Training loss: 2.087265449184384
Validation loss: 2.495333345310613

Epoch: 177| Step: 0
Training loss: 1.7249502534189267
Validation loss: 2.4882765390140924

Epoch: 6| Step: 1
Training loss: 2.4649267409389273
Validation loss: 2.4854531337965056

Epoch: 6| Step: 2
Training loss: 2.038452057062032
Validation loss: 2.4915307434245086

Epoch: 6| Step: 3
Training loss: 2.867204130784533
Validation loss: 2.496465934821006

Epoch: 6| Step: 4
Training loss: 1.597881124102001
Validation loss: 2.4988149377330693

Epoch: 6| Step: 5
Training loss: 2.621969380913561
Validation loss: 2.500361313141763

Epoch: 6| Step: 6
Training loss: 2.2107446808863713
Validation loss: 2.498690611944741

Epoch: 6| Step: 7
Training loss: 2.4135307047241983
Validation loss: 2.5161749513099783

Epoch: 6| Step: 8
Training loss: 2.135748438919749
Validation loss: 2.51729514083069

Epoch: 6| Step: 9
Training loss: 2.523830796526552
Validation loss: 2.517365763575906

Epoch: 6| Step: 10
Training loss: 2.871584978703746
Validation loss: 2.5183312843444017

Epoch: 6| Step: 11
Training loss: 2.7118103205310238
Validation loss: 2.5046469098326343

Epoch: 6| Step: 12
Training loss: 2.2732486187578176
Validation loss: 2.508086850062891

Epoch: 6| Step: 13
Training loss: 2.658898861640492
Validation loss: 2.5034173179622146

Epoch: 178| Step: 0
Training loss: 2.6462475209681773
Validation loss: 2.4954007201025745

Epoch: 6| Step: 1
Training loss: 2.0010170734674166
Validation loss: 2.4959651573619435

Epoch: 6| Step: 2
Training loss: 2.160804361584868
Validation loss: 2.4885214186161746

Epoch: 6| Step: 3
Training loss: 2.869866805757383
Validation loss: 2.498361177533174

Epoch: 6| Step: 4
Training loss: 1.6827777203691088
Validation loss: 2.494543701676027

Epoch: 6| Step: 5
Training loss: 1.9923713150492932
Validation loss: 2.498742295839011

Epoch: 6| Step: 6
Training loss: 2.739759277573096
Validation loss: 2.4926358161534607

Epoch: 6| Step: 7
Training loss: 2.260791226013771
Validation loss: 2.4995419400511905

Epoch: 6| Step: 8
Training loss: 2.675321442016872
Validation loss: 2.491131549857795

Epoch: 6| Step: 9
Training loss: 2.480472114140189
Validation loss: 2.4965704441330137

Epoch: 6| Step: 10
Training loss: 2.2717031043925693
Validation loss: 2.504612545828207

Epoch: 6| Step: 11
Training loss: 2.246496545914203
Validation loss: 2.5016273129557547

Epoch: 6| Step: 12
Training loss: 2.6427702907887185
Validation loss: 2.507263614723191

Epoch: 6| Step: 13
Training loss: 2.6427351065484768
Validation loss: 2.5010980658240647

Epoch: 179| Step: 0
Training loss: 2.223112196994021
Validation loss: 2.498623763205464

Epoch: 6| Step: 1
Training loss: 2.8114478792436928
Validation loss: 2.505131223976265

Epoch: 6| Step: 2
Training loss: 3.0142781308542985
Validation loss: 2.52046879321006

Epoch: 6| Step: 3
Training loss: 2.1171989862897598
Validation loss: 2.520389728029056

Epoch: 6| Step: 4
Training loss: 2.4310595204870817
Validation loss: 2.529465010662474

Epoch: 6| Step: 5
Training loss: 1.7912155588889245
Validation loss: 2.5290445837714475

Epoch: 6| Step: 6
Training loss: 1.8035965962252434
Validation loss: 2.525654672034438

Epoch: 6| Step: 7
Training loss: 2.0953051357154098
Validation loss: 2.514825113256487

Epoch: 6| Step: 8
Training loss: 2.511235453144358
Validation loss: 2.5180510359640134

Epoch: 6| Step: 9
Training loss: 2.664689960588205
Validation loss: 2.509720738822228

Epoch: 6| Step: 10
Training loss: 2.264659281149923
Validation loss: 2.518919089220927

Epoch: 6| Step: 11
Training loss: 2.4435877948597926
Validation loss: 2.5037317319328296

Epoch: 6| Step: 12
Training loss: 2.8384581573987857
Validation loss: 2.5023819702037136

Epoch: 6| Step: 13
Training loss: 1.9251137092991908
Validation loss: 2.4962963008136456

Epoch: 180| Step: 0
Training loss: 2.076735297161465
Validation loss: 2.4933046489823343

Epoch: 6| Step: 1
Training loss: 2.4269537065678124
Validation loss: 2.4790006523218664

Epoch: 6| Step: 2
Training loss: 2.129994077719035
Validation loss: 2.4805397484097598

Epoch: 6| Step: 3
Training loss: 2.5741295574753447
Validation loss: 2.485311655499845

Epoch: 6| Step: 4
Training loss: 2.8201505239368223
Validation loss: 2.481448707343047

Epoch: 6| Step: 5
Training loss: 2.705644789191804
Validation loss: 2.4816207013080227

Epoch: 6| Step: 6
Training loss: 2.2143750106807216
Validation loss: 2.478173246551398

Epoch: 6| Step: 7
Training loss: 2.745414899589173
Validation loss: 2.4820144282927563

Epoch: 6| Step: 8
Training loss: 2.6506772093700746
Validation loss: 2.4831728475886217

Epoch: 6| Step: 9
Training loss: 2.2585412139746683
Validation loss: 2.4864921505730826

Epoch: 6| Step: 10
Training loss: 2.210929627960533
Validation loss: 2.4971406877248374

Epoch: 6| Step: 11
Training loss: 2.3449409002408905
Validation loss: 2.5084992574602345

Epoch: 6| Step: 12
Training loss: 2.539095177073381
Validation loss: 2.5162340694478447

Epoch: 6| Step: 13
Training loss: 1.9041147624258783
Validation loss: 2.5184037319983146

Epoch: 181| Step: 0
Training loss: 1.6265707493993349
Validation loss: 2.5424321746781655

Epoch: 6| Step: 1
Training loss: 2.6150452913698317
Validation loss: 2.555838416058943

Epoch: 6| Step: 2
Training loss: 1.8312029887860373
Validation loss: 2.5356008632540092

Epoch: 6| Step: 3
Training loss: 2.791909695954762
Validation loss: 2.532708050289914

Epoch: 6| Step: 4
Training loss: 2.569760898199203
Validation loss: 2.501565840220718

Epoch: 6| Step: 5
Training loss: 2.54347329474127
Validation loss: 2.499760346052056

Epoch: 6| Step: 6
Training loss: 2.383027113958336
Validation loss: 2.4959259693189377

Epoch: 6| Step: 7
Training loss: 2.042143967039714
Validation loss: 2.5052777847106005

Epoch: 6| Step: 8
Training loss: 2.346481359310635
Validation loss: 2.5165678078032423

Epoch: 6| Step: 9
Training loss: 2.5954077145670165
Validation loss: 2.5202098001713025

Epoch: 6| Step: 10
Training loss: 3.074675665397522
Validation loss: 2.514799341902119

Epoch: 6| Step: 11
Training loss: 2.162274996126652
Validation loss: 2.517804246389986

Epoch: 6| Step: 12
Training loss: 2.4330890554677933
Validation loss: 2.533878719659125

Epoch: 6| Step: 13
Training loss: 2.4001903776319398
Validation loss: 2.5236146469058784

Epoch: 182| Step: 0
Training loss: 2.425101315456381
Validation loss: 2.5109902962477255

Epoch: 6| Step: 1
Training loss: 2.395207917778928
Validation loss: 2.5120103586690985

Epoch: 6| Step: 2
Training loss: 2.564930577221691
Validation loss: 2.4979871116888037

Epoch: 6| Step: 3
Training loss: 2.243705528052322
Validation loss: 2.5091509233240767

Epoch: 6| Step: 4
Training loss: 2.644138143557707
Validation loss: 2.4993949396359207

Epoch: 6| Step: 5
Training loss: 2.566007493160543
Validation loss: 2.4955813618764906

Epoch: 6| Step: 6
Training loss: 2.3197448241550913
Validation loss: 2.502241996945697

Epoch: 6| Step: 7
Training loss: 1.8574859255107317
Validation loss: 2.4925823955123674

Epoch: 6| Step: 8
Training loss: 2.149758227749032
Validation loss: 2.499286255675555

Epoch: 6| Step: 9
Training loss: 1.9779834690656781
Validation loss: 2.4993215117057512

Epoch: 6| Step: 10
Training loss: 1.9608516598336956
Validation loss: 2.491260009186616

Epoch: 6| Step: 11
Training loss: 2.4370288882666316
Validation loss: 2.501379586084287

Epoch: 6| Step: 12
Training loss: 2.903239670245249
Validation loss: 2.506682191717823

Epoch: 6| Step: 13
Training loss: 2.8073332906738266
Validation loss: 2.518277193786393

Epoch: 183| Step: 0
Training loss: 2.669507410994076
Validation loss: 2.5101582300483276

Epoch: 6| Step: 1
Training loss: 2.2959262679087367
Validation loss: 2.522815261512321

Epoch: 6| Step: 2
Training loss: 2.401611017892408
Validation loss: 2.5266202336157253

Epoch: 6| Step: 3
Training loss: 2.5401054235792513
Validation loss: 2.538059102868514

Epoch: 6| Step: 4
Training loss: 2.36898423297445
Validation loss: 2.527378213717236

Epoch: 6| Step: 5
Training loss: 1.975660940227745
Validation loss: 2.515667877463688

Epoch: 6| Step: 6
Training loss: 2.4063560165235893
Validation loss: 2.519129900052521

Epoch: 6| Step: 7
Training loss: 1.7360280724905752
Validation loss: 2.5283473919414954

Epoch: 6| Step: 8
Training loss: 2.7392386641487594
Validation loss: 2.531269858325564

Epoch: 6| Step: 9
Training loss: 1.9969967704979883
Validation loss: 2.5287500445770847

Epoch: 6| Step: 10
Training loss: 2.0364241210977565
Validation loss: 2.5050139216266514

Epoch: 6| Step: 11
Training loss: 2.9161658992486896
Validation loss: 2.5066627726964263

Epoch: 6| Step: 12
Training loss: 2.753625214217348
Validation loss: 2.512556396155092

Epoch: 6| Step: 13
Training loss: 2.3432026541869715
Validation loss: 2.5237254400697324

Epoch: 184| Step: 0
Training loss: 2.271876792434762
Validation loss: 2.528381401926093

Epoch: 6| Step: 1
Training loss: 2.0230020768913435
Validation loss: 2.5116444720591464

Epoch: 6| Step: 2
Training loss: 2.7208129247237847
Validation loss: 2.4969380542239885

Epoch: 6| Step: 3
Training loss: 2.1532972823314926
Validation loss: 2.500995390142305

Epoch: 6| Step: 4
Training loss: 1.9743043567738663
Validation loss: 2.4893595755882427

Epoch: 6| Step: 5
Training loss: 2.474111023591234
Validation loss: 2.490240063629634

Epoch: 6| Step: 6
Training loss: 2.572065688859131
Validation loss: 2.501858274918692

Epoch: 6| Step: 7
Training loss: 3.0747141263242934
Validation loss: 2.4984192062449337

Epoch: 6| Step: 8
Training loss: 2.909559764793008
Validation loss: 2.5008553154434865

Epoch: 6| Step: 9
Training loss: 2.0250317983132233
Validation loss: 2.5113771719510907

Epoch: 6| Step: 10
Training loss: 2.1345993214542807
Validation loss: 2.5126581012586247

Epoch: 6| Step: 11
Training loss: 2.3983997255015965
Validation loss: 2.522777128468971

Epoch: 6| Step: 12
Training loss: 1.9379041311804148
Validation loss: 2.5271836888030736

Epoch: 6| Step: 13
Training loss: 2.617800148384579
Validation loss: 2.529986886617478

Epoch: 185| Step: 0
Training loss: 2.1577902558635214
Validation loss: 2.5576038959862286

Epoch: 6| Step: 1
Training loss: 2.022737713437123
Validation loss: 2.5521566471286894

Epoch: 6| Step: 2
Training loss: 2.101602433403125
Validation loss: 2.582344140097602

Epoch: 6| Step: 3
Training loss: 2.2067450683856715
Validation loss: 2.5942338852139413

Epoch: 6| Step: 4
Training loss: 2.7161513438523968
Validation loss: 2.590360211199018

Epoch: 6| Step: 5
Training loss: 2.6281334476584655
Validation loss: 2.569279116102893

Epoch: 6| Step: 6
Training loss: 2.4167990374212485
Validation loss: 2.570305450337027

Epoch: 6| Step: 7
Training loss: 1.9274258970668838
Validation loss: 2.555673593637693

Epoch: 6| Step: 8
Training loss: 2.3579350808082897
Validation loss: 2.5289936605625183

Epoch: 6| Step: 9
Training loss: 1.75355577259328
Validation loss: 2.5367991840505195

Epoch: 6| Step: 10
Training loss: 2.591203289577072
Validation loss: 2.517267216360034

Epoch: 6| Step: 11
Training loss: 2.4923095673230717
Validation loss: 2.5170940114235623

Epoch: 6| Step: 12
Training loss: 3.017006671214101
Validation loss: 2.5071224320883476

Epoch: 6| Step: 13
Training loss: 2.510099230016863
Validation loss: 2.509542468647825

Epoch: 186| Step: 0
Training loss: 2.5662852916344048
Validation loss: 2.5157341943266003

Epoch: 6| Step: 1
Training loss: 2.0329332859709734
Validation loss: 2.5092372154960905

Epoch: 6| Step: 2
Training loss: 2.6171224557565687
Validation loss: 2.5181815541660266

Epoch: 6| Step: 3
Training loss: 2.4051443755340522
Validation loss: 2.5193490999998156

Epoch: 6| Step: 4
Training loss: 2.0293016920133518
Validation loss: 2.535137409596707

Epoch: 6| Step: 5
Training loss: 2.547054073848579
Validation loss: 2.535435845817886

Epoch: 6| Step: 6
Training loss: 1.6659990244996512
Validation loss: 2.5352563588459787

Epoch: 6| Step: 7
Training loss: 2.3579260817081007
Validation loss: 2.5277335305119917

Epoch: 6| Step: 8
Training loss: 2.814196604700394
Validation loss: 2.5166062836213556

Epoch: 6| Step: 9
Training loss: 3.0784524656278003
Validation loss: 2.546790849040456

Epoch: 6| Step: 10
Training loss: 1.74890238536284
Validation loss: 2.539487300451743

Epoch: 6| Step: 11
Training loss: 2.4965119824877338
Validation loss: 2.5597347753443156

Epoch: 6| Step: 12
Training loss: 1.7744437568459916
Validation loss: 2.5606257399599155

Epoch: 6| Step: 13
Training loss: 2.504873865420181
Validation loss: 2.557588584636063

Epoch: 187| Step: 0
Training loss: 2.0532216692365344
Validation loss: 2.5692662947701184

Epoch: 6| Step: 1
Training loss: 2.471701969692876
Validation loss: 2.5423864742003683

Epoch: 6| Step: 2
Training loss: 2.5322209132698266
Validation loss: 2.54985338737025

Epoch: 6| Step: 3
Training loss: 2.9105435721696464
Validation loss: 2.543088520469975

Epoch: 6| Step: 4
Training loss: 2.3090414010190186
Validation loss: 2.543498119408795

Epoch: 6| Step: 5
Training loss: 3.0999148818605122
Validation loss: 2.5244009345947336

Epoch: 6| Step: 6
Training loss: 2.145238318553417
Validation loss: 2.532369052317035

Epoch: 6| Step: 7
Training loss: 2.024544313751795
Validation loss: 2.5261419033861894

Epoch: 6| Step: 8
Training loss: 2.2849264958618907
Validation loss: 2.5383609056718144

Epoch: 6| Step: 9
Training loss: 2.316807112335911
Validation loss: 2.540315571202512

Epoch: 6| Step: 10
Training loss: 2.115442549305663
Validation loss: 2.5398945389027405

Epoch: 6| Step: 11
Training loss: 2.0494008095742746
Validation loss: 2.5513245109705935

Epoch: 6| Step: 12
Training loss: 2.118936189555725
Validation loss: 2.542878367609441

Epoch: 6| Step: 13
Training loss: 2.6269852533467466
Validation loss: 2.535262565558331

Epoch: 188| Step: 0
Training loss: 1.9551388543421413
Validation loss: 2.5440595390072365

Epoch: 6| Step: 1
Training loss: 2.345529618147192
Validation loss: 2.536576635799048

Epoch: 6| Step: 2
Training loss: 2.111415751824065
Validation loss: 2.540137430212719

Epoch: 6| Step: 3
Training loss: 2.5667924982247534
Validation loss: 2.525665457065664

Epoch: 6| Step: 4
Training loss: 3.0694252654138587
Validation loss: 2.527595597876291

Epoch: 6| Step: 5
Training loss: 2.5096428867118212
Validation loss: 2.5287488660371418

Epoch: 6| Step: 6
Training loss: 1.9746924438511264
Validation loss: 2.5170885492439283

Epoch: 6| Step: 7
Training loss: 1.9512704818598794
Validation loss: 2.5170658794931002

Epoch: 6| Step: 8
Training loss: 2.462637759000634
Validation loss: 2.5102870058208517

Epoch: 6| Step: 9
Training loss: 2.7265885578648263
Validation loss: 2.51464424997123

Epoch: 6| Step: 10
Training loss: 2.475549918068829
Validation loss: 2.528452312215661

Epoch: 6| Step: 11
Training loss: 1.9633822456488947
Validation loss: 2.532519159699567

Epoch: 6| Step: 12
Training loss: 2.150222203504694
Validation loss: 2.546270177752186

Epoch: 6| Step: 13
Training loss: 2.2977788275714857
Validation loss: 2.562379213913466

Epoch: 189| Step: 0
Training loss: 2.1432796084531263
Validation loss: 2.590084427227071

Epoch: 6| Step: 1
Training loss: 2.7233012022490986
Validation loss: 2.58952075599277

Epoch: 6| Step: 2
Training loss: 2.672633191778365
Validation loss: 2.581491849713165

Epoch: 6| Step: 3
Training loss: 1.9914259707947373
Validation loss: 2.5770563704473792

Epoch: 6| Step: 4
Training loss: 1.804886645934376
Validation loss: 2.5914300555030017

Epoch: 6| Step: 5
Training loss: 1.9339271335070625
Validation loss: 2.5621495511223555

Epoch: 6| Step: 6
Training loss: 2.155744852797132
Validation loss: 2.552117068528361

Epoch: 6| Step: 7
Training loss: 1.898093423941865
Validation loss: 2.5352977523145954

Epoch: 6| Step: 8
Training loss: 3.2213977182703384
Validation loss: 2.5147168433505263

Epoch: 6| Step: 9
Training loss: 2.451973420053514
Validation loss: 2.5039323873836907

Epoch: 6| Step: 10
Training loss: 2.3737128936133267
Validation loss: 2.4958801337319065

Epoch: 6| Step: 11
Training loss: 2.560643710030116
Validation loss: 2.4938766112728437

Epoch: 6| Step: 12
Training loss: 2.6149912258898143
Validation loss: 2.4897378264391734

Epoch: 6| Step: 13
Training loss: 2.6056132355166155
Validation loss: 2.5008664854810445

Epoch: 190| Step: 0
Training loss: 2.530491656452648
Validation loss: 2.5071954492909465

Epoch: 6| Step: 1
Training loss: 1.6023877506547803
Validation loss: 2.5145032446959106

Epoch: 6| Step: 2
Training loss: 2.2556361496698143
Validation loss: 2.5117773797690774

Epoch: 6| Step: 3
Training loss: 2.0023067999328
Validation loss: 2.5262081890996986

Epoch: 6| Step: 4
Training loss: 3.001138471114376
Validation loss: 2.532653843159991

Epoch: 6| Step: 5
Training loss: 1.8349639908794113
Validation loss: 2.552039108412188

Epoch: 6| Step: 6
Training loss: 1.7307568174715837
Validation loss: 2.5677143016898

Epoch: 6| Step: 7
Training loss: 2.3823754081691697
Validation loss: 2.5719176964442942

Epoch: 6| Step: 8
Training loss: 1.974198567476353
Validation loss: 2.57345844593028

Epoch: 6| Step: 9
Training loss: 2.94074573167658
Validation loss: 2.582741090095445

Epoch: 6| Step: 10
Training loss: 1.4879278128762048
Validation loss: 2.573416963706485

Epoch: 6| Step: 11
Training loss: 2.9369028986100747
Validation loss: 2.57639197469037

Epoch: 6| Step: 12
Training loss: 3.2842216477675557
Validation loss: 2.5555013979711

Epoch: 6| Step: 13
Training loss: 2.5938683907939057
Validation loss: 2.53953125368021

Epoch: 191| Step: 0
Training loss: 1.941323476212667
Validation loss: 2.527358356258709

Epoch: 6| Step: 1
Training loss: 2.382954077344989
Validation loss: 2.511918269133792

Epoch: 6| Step: 2
Training loss: 2.5435210066314644
Validation loss: 2.497280915088846

Epoch: 6| Step: 3
Training loss: 1.8688420582426477
Validation loss: 2.492860645359914

Epoch: 6| Step: 4
Training loss: 2.3265284241793402
Validation loss: 2.4896366374375916

Epoch: 6| Step: 5
Training loss: 2.3721368496869184
Validation loss: 2.5039082178513783

Epoch: 6| Step: 6
Training loss: 1.9141324400287931
Validation loss: 2.492716112349206

Epoch: 6| Step: 7
Training loss: 2.5031514331884006
Validation loss: 2.498484644982795

Epoch: 6| Step: 8
Training loss: 1.955245065183159
Validation loss: 2.5113590946049213

Epoch: 6| Step: 9
Training loss: 2.0147438193156724
Validation loss: 2.516037790617079

Epoch: 6| Step: 10
Training loss: 2.356840275256015
Validation loss: 2.524061820605647

Epoch: 6| Step: 11
Training loss: 2.3213791370368333
Validation loss: 2.535365115174229

Epoch: 6| Step: 12
Training loss: 2.210936529476101
Validation loss: 2.5505614796981013

Epoch: 6| Step: 13
Training loss: 3.9151257804844737
Validation loss: 2.5667038681587493

Epoch: 192| Step: 0
Training loss: 1.8252616694732675
Validation loss: 2.5831738443261583

Epoch: 6| Step: 1
Training loss: 2.3252775457292945
Validation loss: 2.579607635500233

Epoch: 6| Step: 2
Training loss: 2.360918765243027
Validation loss: 2.598292222724459

Epoch: 6| Step: 3
Training loss: 2.6079540838224924
Validation loss: 2.6273612195841753

Epoch: 6| Step: 4
Training loss: 2.8682275699472264
Validation loss: 2.598922260367899

Epoch: 6| Step: 5
Training loss: 2.439828200936584
Validation loss: 2.578553104499064

Epoch: 6| Step: 6
Training loss: 2.8533809350698545
Validation loss: 2.5537614300746374

Epoch: 6| Step: 7
Training loss: 2.30029416069076
Validation loss: 2.5598424528861785

Epoch: 6| Step: 8
Training loss: 2.4607034238875745
Validation loss: 2.557914616576241

Epoch: 6| Step: 9
Training loss: 2.2995846912425875
Validation loss: 2.548315331333296

Epoch: 6| Step: 10
Training loss: 2.524617489083549
Validation loss: 2.532948210789086

Epoch: 6| Step: 11
Training loss: 2.2216824776768194
Validation loss: 2.5143018050305916

Epoch: 6| Step: 12
Training loss: 2.1056927223898287
Validation loss: 2.5242620170251553

Epoch: 6| Step: 13
Training loss: 1.907343441399185
Validation loss: 2.517829781821329

Epoch: 193| Step: 0
Training loss: 2.1434034150780077
Validation loss: 2.5046243178532683

Epoch: 6| Step: 1
Training loss: 2.9419100508537737
Validation loss: 2.51042596068713

Epoch: 6| Step: 2
Training loss: 2.7064243533593437
Validation loss: 2.5088523934957077

Epoch: 6| Step: 3
Training loss: 2.0451007170929745
Validation loss: 2.499294785534105

Epoch: 6| Step: 4
Training loss: 1.337102549315674
Validation loss: 2.5097712851929326

Epoch: 6| Step: 5
Training loss: 2.742534387280765
Validation loss: 2.5034997126997705

Epoch: 6| Step: 6
Training loss: 2.3684790584644233
Validation loss: 2.5000175952292194

Epoch: 6| Step: 7
Training loss: 2.266838327620776
Validation loss: 2.5141739540217865

Epoch: 6| Step: 8
Training loss: 1.680003291762624
Validation loss: 2.517841192193027

Epoch: 6| Step: 9
Training loss: 2.5062189951665035
Validation loss: 2.5119923096076415

Epoch: 6| Step: 10
Training loss: 2.6612782177878214
Validation loss: 2.540627272238503

Epoch: 6| Step: 11
Training loss: 2.6267844901147344
Validation loss: 2.5448023079269553

Epoch: 6| Step: 12
Training loss: 2.495756744415393
Validation loss: 2.5489622896821365

Epoch: 6| Step: 13
Training loss: 2.0341660915292157
Validation loss: 2.571378044484763

Epoch: 194| Step: 0
Training loss: 2.5384490695282556
Validation loss: 2.5586197169881424

Epoch: 6| Step: 1
Training loss: 2.409913086333032
Validation loss: 2.571431790708111

Epoch: 6| Step: 2
Training loss: 2.072481796681675
Validation loss: 2.588788814502359

Epoch: 6| Step: 3
Training loss: 1.9033630272352264
Validation loss: 2.5805867473723305

Epoch: 6| Step: 4
Training loss: 2.90438914457078
Validation loss: 2.5593600224952144

Epoch: 6| Step: 5
Training loss: 2.7001061312691372
Validation loss: 2.567901469943972

Epoch: 6| Step: 6
Training loss: 1.7785114183550006
Validation loss: 2.5364130369890003

Epoch: 6| Step: 7
Training loss: 2.0255089249820366
Validation loss: 2.5292312358258067

Epoch: 6| Step: 8
Training loss: 2.8086677721904056
Validation loss: 2.512544534772486

Epoch: 6| Step: 9
Training loss: 1.7626050931291872
Validation loss: 2.5182979118065947

Epoch: 6| Step: 10
Training loss: 2.8546781058488353
Validation loss: 2.517698685092666

Epoch: 6| Step: 11
Training loss: 2.184331179112436
Validation loss: 2.505784249412259

Epoch: 6| Step: 12
Training loss: 2.5603909070359308
Validation loss: 2.504476132262463

Epoch: 6| Step: 13
Training loss: 1.8899118008293245
Validation loss: 2.5060613902113364

Epoch: 195| Step: 0
Training loss: 2.6306879997368044
Validation loss: 2.5010669815538473

Epoch: 6| Step: 1
Training loss: 2.4482344941854093
Validation loss: 2.5158759124284673

Epoch: 6| Step: 2
Training loss: 2.578456695488888
Validation loss: 2.5170759988151814

Epoch: 6| Step: 3
Training loss: 3.371997203857421
Validation loss: 2.5194794563272995

Epoch: 6| Step: 4
Training loss: 2.25732881321523
Validation loss: 2.5124901614779387

Epoch: 6| Step: 5
Training loss: 2.3011384178349394
Validation loss: 2.52032923321373

Epoch: 6| Step: 6
Training loss: 2.6822412183640774
Validation loss: 2.5357310187736237

Epoch: 6| Step: 7
Training loss: 2.4308540512141907
Validation loss: 2.532560456694397

Epoch: 6| Step: 8
Training loss: 1.7174868016520177
Validation loss: 2.5560773593770305

Epoch: 6| Step: 9
Training loss: 1.8566927115407388
Validation loss: 2.5631124958488947

Epoch: 6| Step: 10
Training loss: 2.2056545588738627
Validation loss: 2.5892945287895817

Epoch: 6| Step: 11
Training loss: 2.187844167610117
Validation loss: 2.5714035887614703

Epoch: 6| Step: 12
Training loss: 1.5420038610575784
Validation loss: 2.580805546733432

Epoch: 6| Step: 13
Training loss: 2.074714558283151
Validation loss: 2.5760659212193566

Epoch: 196| Step: 0
Training loss: 2.1599571315608705
Validation loss: 2.5710765472148798

Epoch: 6| Step: 1
Training loss: 2.7587326287092995
Validation loss: 2.562888418393493

Epoch: 6| Step: 2
Training loss: 2.209454042134989
Validation loss: 2.552348474755656

Epoch: 6| Step: 3
Training loss: 2.184743397744746
Validation loss: 2.5300767322257873

Epoch: 6| Step: 4
Training loss: 2.9570470529836976
Validation loss: 2.5334049910106518

Epoch: 6| Step: 5
Training loss: 2.4983297490591947
Validation loss: 2.516188864371903

Epoch: 6| Step: 6
Training loss: 2.5424414115764455
Validation loss: 2.535409907820717

Epoch: 6| Step: 7
Training loss: 2.438739950295237
Validation loss: 2.5415270146844096

Epoch: 6| Step: 8
Training loss: 1.613468778116057
Validation loss: 2.5516040170238763

Epoch: 6| Step: 9
Training loss: 1.7073522479806833
Validation loss: 2.5496413608245594

Epoch: 6| Step: 10
Training loss: 2.834574558420733
Validation loss: 2.5626228427130178

Epoch: 6| Step: 11
Training loss: 1.9027652469355432
Validation loss: 2.553492438631382

Epoch: 6| Step: 12
Training loss: 2.2015039418583986
Validation loss: 2.5672234057320282

Epoch: 6| Step: 13
Training loss: 2.5077615417817247
Validation loss: 2.5654663966194993

Epoch: 197| Step: 0
Training loss: 2.963623439060672
Validation loss: 2.57146267341652

Epoch: 6| Step: 1
Training loss: 2.3448471553094232
Validation loss: 2.574250100947772

Epoch: 6| Step: 2
Training loss: 2.407582100075409
Validation loss: 2.537027335657576

Epoch: 6| Step: 3
Training loss: 2.3102755802465103
Validation loss: 2.5458510511149095

Epoch: 6| Step: 4
Training loss: 2.1337135284113664
Validation loss: 2.5275685732651807

Epoch: 6| Step: 5
Training loss: 1.6939299259126948
Validation loss: 2.522262850988276

Epoch: 6| Step: 6
Training loss: 2.8230682182217786
Validation loss: 2.5214920969676653

Epoch: 6| Step: 7
Training loss: 2.030540694591009
Validation loss: 2.518859205883918

Epoch: 6| Step: 8
Training loss: 1.2585489711455833
Validation loss: 2.5256164717284437

Epoch: 6| Step: 9
Training loss: 2.6112505174401677
Validation loss: 2.5345590962794815

Epoch: 6| Step: 10
Training loss: 1.894592913381152
Validation loss: 2.5167382740629107

Epoch: 6| Step: 11
Training loss: 2.3746040415715726
Validation loss: 2.5447904797328866

Epoch: 6| Step: 12
Training loss: 2.6452507719351184
Validation loss: 2.562034316508839

Epoch: 6| Step: 13
Training loss: 2.8187692070621684
Validation loss: 2.5694724181660056

Epoch: 198| Step: 0
Training loss: 1.8029389601121777
Validation loss: 2.5585985644734444

Epoch: 6| Step: 1
Training loss: 2.7013313649080315
Validation loss: 2.5709150819646096

Epoch: 6| Step: 2
Training loss: 2.7830610914964597
Validation loss: 2.5494486281241784

Epoch: 6| Step: 3
Training loss: 1.5089744083668886
Validation loss: 2.5614147989783564

Epoch: 6| Step: 4
Training loss: 2.1241126732332463
Validation loss: 2.547437172845911

Epoch: 6| Step: 5
Training loss: 3.337702049968696
Validation loss: 2.527925623830764

Epoch: 6| Step: 6
Training loss: 2.0456188511603064
Validation loss: 2.537917911084783

Epoch: 6| Step: 7
Training loss: 2.7264898339674373
Validation loss: 2.537473257515837

Epoch: 6| Step: 8
Training loss: 1.6707797161577933
Validation loss: 2.562511327765013

Epoch: 6| Step: 9
Training loss: 2.68359890289034
Validation loss: 2.566220598555637

Epoch: 6| Step: 10
Training loss: 2.299166308526618
Validation loss: 2.5687163555729504

Epoch: 6| Step: 11
Training loss: 2.4451830162403296
Validation loss: 2.574415238965758

Epoch: 6| Step: 12
Training loss: 1.3771872463446813
Validation loss: 2.5737747866928578

Epoch: 6| Step: 13
Training loss: 2.477160456820068
Validation loss: 2.5562712322618677

Epoch: 199| Step: 0
Training loss: 1.540229703319023
Validation loss: 2.5503151094304646

Epoch: 6| Step: 1
Training loss: 1.944536414317733
Validation loss: 2.544011228052789

Epoch: 6| Step: 2
Training loss: 1.2894918940371816
Validation loss: 2.547254397601476

Epoch: 6| Step: 3
Training loss: 2.6085710029261477
Validation loss: 2.5415859887081207

Epoch: 6| Step: 4
Training loss: 2.167397253643766
Validation loss: 2.5353368411719046

Epoch: 6| Step: 5
Training loss: 2.399476065667143
Validation loss: 2.534058805999215

Epoch: 6| Step: 6
Training loss: 2.5603327076004008
Validation loss: 2.5182275834550323

Epoch: 6| Step: 7
Training loss: 2.596253531191412
Validation loss: 2.503522854482714

Epoch: 6| Step: 8
Training loss: 2.547840520470036
Validation loss: 2.52109861685708

Epoch: 6| Step: 9
Training loss: 1.7539730611535398
Validation loss: 2.5312263581855516

Epoch: 6| Step: 10
Training loss: 3.179211480127734
Validation loss: 2.5392406225081077

Epoch: 6| Step: 11
Training loss: 3.0336599306898657
Validation loss: 2.554610847155325

Epoch: 6| Step: 12
Training loss: 1.8899135669744676
Validation loss: 2.555823941465903

Epoch: 6| Step: 13
Training loss: 2.6554930562104717
Validation loss: 2.556504920367326

Epoch: 200| Step: 0
Training loss: 2.558816914617566
Validation loss: 2.5498465304847797

Epoch: 6| Step: 1
Training loss: 2.240671422841908
Validation loss: 2.557108192051588

Epoch: 6| Step: 2
Training loss: 2.4649531465608003
Validation loss: 2.545333224017642

Epoch: 6| Step: 3
Training loss: 3.4255695342842345
Validation loss: 2.563386004104814

Epoch: 6| Step: 4
Training loss: 1.7488520808280086
Validation loss: 2.548422454471485

Epoch: 6| Step: 5
Training loss: 2.149735935761846
Validation loss: 2.5374703447835856

Epoch: 6| Step: 6
Training loss: 1.8251484823571908
Validation loss: 2.5042084795676436

Epoch: 6| Step: 7
Training loss: 1.8794715966638111
Validation loss: 2.5128061917735045

Epoch: 6| Step: 8
Training loss: 2.5470021221989274
Validation loss: 2.510115424690013

Epoch: 6| Step: 9
Training loss: 2.301762577225128
Validation loss: 2.5029974134601756

Epoch: 6| Step: 10
Training loss: 2.35370687760261
Validation loss: 2.4957249169426468

Epoch: 6| Step: 11
Training loss: 2.66939960944448
Validation loss: 2.5046132439013173

Epoch: 6| Step: 12
Training loss: 2.0121877771653742
Validation loss: 2.508394849113724

Epoch: 6| Step: 13
Training loss: 2.335507050216314
Validation loss: 2.502347527456554

Epoch: 201| Step: 0
Training loss: 2.6737581275934117
Validation loss: 2.52455822885307

Epoch: 6| Step: 1
Training loss: 1.7849664566350416
Validation loss: 2.521807731856296

Epoch: 6| Step: 2
Training loss: 2.142813350593317
Validation loss: 2.5409910497471495

Epoch: 6| Step: 3
Training loss: 2.3220723988551484
Validation loss: 2.537397024260691

Epoch: 6| Step: 4
Training loss: 2.607933057189166
Validation loss: 2.538099198149556

Epoch: 6| Step: 5
Training loss: 2.373358510594641
Validation loss: 2.55137414745137

Epoch: 6| Step: 6
Training loss: 1.9468185539084122
Validation loss: 2.549730568408403

Epoch: 6| Step: 7
Training loss: 2.446211676982087
Validation loss: 2.548899807171698

Epoch: 6| Step: 8
Training loss: 3.0749039425616935
Validation loss: 2.548699020292478

Epoch: 6| Step: 9
Training loss: 2.8863224485349006
Validation loss: 2.562190168925024

Epoch: 6| Step: 10
Training loss: 1.771309336097142
Validation loss: 2.563544905462987

Epoch: 6| Step: 11
Training loss: 1.9464528368516014
Validation loss: 2.569887908836328

Epoch: 6| Step: 12
Training loss: 2.5688375861835744
Validation loss: 2.56424236763171

Epoch: 6| Step: 13
Training loss: 2.0299283936748274
Validation loss: 2.575959909090093

Epoch: 202| Step: 0
Training loss: 2.835999879597606
Validation loss: 2.5827998923139948

Epoch: 6| Step: 1
Training loss: 2.002726127439376
Validation loss: 2.6129896593328445

Epoch: 6| Step: 2
Training loss: 2.4785937333781836
Validation loss: 2.605521548992993

Epoch: 6| Step: 3
Training loss: 2.3601951941895174
Validation loss: 2.610764291627448

Epoch: 6| Step: 4
Training loss: 2.1188465107680283
Validation loss: 2.5803157630540343

Epoch: 6| Step: 5
Training loss: 1.756172466263552
Validation loss: 2.587812283847632

Epoch: 6| Step: 6
Training loss: 2.3742714818613475
Validation loss: 2.588800449343321

Epoch: 6| Step: 7
Training loss: 2.7377014852430945
Validation loss: 2.578718729721763

Epoch: 6| Step: 8
Training loss: 2.4979402640158455
Validation loss: 2.5781825511943723

Epoch: 6| Step: 9
Training loss: 2.3326913995092102
Validation loss: 2.561389884225487

Epoch: 6| Step: 10
Training loss: 2.317021460317276
Validation loss: 2.5584108243590413

Epoch: 6| Step: 11
Training loss: 2.446137602908569
Validation loss: 2.541529015946245

Epoch: 6| Step: 12
Training loss: 2.009083861146818
Validation loss: 2.5378140006256458

Epoch: 6| Step: 13
Training loss: 2.1646835592770133
Validation loss: 2.51303977102678

Epoch: 203| Step: 0
Training loss: 2.3922365030343875
Validation loss: 2.5082490408369695

Epoch: 6| Step: 1
Training loss: 2.0439962862805934
Validation loss: 2.4961143496782183

Epoch: 6| Step: 2
Training loss: 2.396318524753422
Validation loss: 2.4971849964447386

Epoch: 6| Step: 3
Training loss: 2.6156870626107547
Validation loss: 2.4929029978265236

Epoch: 6| Step: 4
Training loss: 2.5022149764174957
Validation loss: 2.4994961787224685

Epoch: 6| Step: 5
Training loss: 2.5302053108893525
Validation loss: 2.494046003577646

Epoch: 6| Step: 6
Training loss: 2.9870285300599475
Validation loss: 2.4995259153352043

Epoch: 6| Step: 7
Training loss: 2.219649441508383
Validation loss: 2.5007435646542544

Epoch: 6| Step: 8
Training loss: 2.594941933924899
Validation loss: 2.50348619735516

Epoch: 6| Step: 9
Training loss: 1.873216289221518
Validation loss: 2.514057579375534

Epoch: 6| Step: 10
Training loss: 1.7542904983027476
Validation loss: 2.5260627247565126

Epoch: 6| Step: 11
Training loss: 2.7358485148025404
Validation loss: 2.5591280080926393

Epoch: 6| Step: 12
Training loss: 2.3268805128304266
Validation loss: 2.5687942117442675

Epoch: 6| Step: 13
Training loss: 1.5925650586024258
Validation loss: 2.597391200107695

Epoch: 204| Step: 0
Training loss: 2.3482049944940906
Validation loss: 2.612256634706988

Epoch: 6| Step: 1
Training loss: 2.0293168479076056
Validation loss: 2.629865950152495

Epoch: 6| Step: 2
Training loss: 2.2809353964226626
Validation loss: 2.6074175621501863

Epoch: 6| Step: 3
Training loss: 2.048626448866618
Validation loss: 2.6133465419000816

Epoch: 6| Step: 4
Training loss: 2.237866960834203
Validation loss: 2.619571552673842

Epoch: 6| Step: 5
Training loss: 1.7322759900174165
Validation loss: 2.58160493825754

Epoch: 6| Step: 6
Training loss: 2.7405512348543706
Validation loss: 2.5673461385211285

Epoch: 6| Step: 7
Training loss: 3.0166614708056585
Validation loss: 2.5542175918489045

Epoch: 6| Step: 8
Training loss: 3.110574615481288
Validation loss: 2.547399993333609

Epoch: 6| Step: 9
Training loss: 2.4821225878053554
Validation loss: 2.5622252650416093

Epoch: 6| Step: 10
Training loss: 2.3324887132116032
Validation loss: 2.546420456591775

Epoch: 6| Step: 11
Training loss: 2.0281451631316667
Validation loss: 2.5447529414433174

Epoch: 6| Step: 12
Training loss: 2.0148906700821345
Validation loss: 2.5261112767227343

Epoch: 6| Step: 13
Training loss: 2.006429114026164
Validation loss: 2.5227649371141854

Epoch: 205| Step: 0
Training loss: 2.181652427648244
Validation loss: 2.526774708414027

Epoch: 6| Step: 1
Training loss: 1.4089037968137312
Validation loss: 2.523672228782059

Epoch: 6| Step: 2
Training loss: 2.3631038882955275
Validation loss: 2.523361299385833

Epoch: 6| Step: 3
Training loss: 2.017294022682414
Validation loss: 2.5281922980971676

Epoch: 6| Step: 4
Training loss: 2.2820978548698694
Validation loss: 2.5508263015857855

Epoch: 6| Step: 5
Training loss: 2.310607135467355
Validation loss: 2.549064521983607

Epoch: 6| Step: 6
Training loss: 2.1326433610746753
Validation loss: 2.5560109543583027

Epoch: 6| Step: 7
Training loss: 2.446050173122451
Validation loss: 2.566963232131015

Epoch: 6| Step: 8
Training loss: 2.5804858870923253
Validation loss: 2.5623130264919998

Epoch: 6| Step: 9
Training loss: 2.5980477633178642
Validation loss: 2.5661163398581306

Epoch: 6| Step: 10
Training loss: 3.014394716708095
Validation loss: 2.565327038579119

Epoch: 6| Step: 11
Training loss: 1.9462439823241355
Validation loss: 2.58458106354544

Epoch: 6| Step: 12
Training loss: 2.5405384644883213
Validation loss: 2.5500500007165305

Epoch: 6| Step: 13
Training loss: 2.5392822170559235
Validation loss: 2.558649861348981

Epoch: 206| Step: 0
Training loss: 2.790462025222523
Validation loss: 2.5398448267042353

Epoch: 6| Step: 1
Training loss: 2.2112760790057417
Validation loss: 2.528190286278269

Epoch: 6| Step: 2
Training loss: 2.339194690177256
Validation loss: 2.5113412623819107

Epoch: 6| Step: 3
Training loss: 2.253405960067542
Validation loss: 2.4862651552275747

Epoch: 6| Step: 4
Training loss: 1.9369545445659906
Validation loss: 2.4920527502480603

Epoch: 6| Step: 5
Training loss: 2.491942582009315
Validation loss: 2.5000939033674534

Epoch: 6| Step: 6
Training loss: 2.557030213166705
Validation loss: 2.4932549242535664

Epoch: 6| Step: 7
Training loss: 2.430651212959457
Validation loss: 2.4924739246541314

Epoch: 6| Step: 8
Training loss: 2.2205510955546037
Validation loss: 2.493736941399798

Epoch: 6| Step: 9
Training loss: 2.6095679662931035
Validation loss: 2.4897539380938682

Epoch: 6| Step: 10
Training loss: 2.269049851119996
Validation loss: 2.506117821535063

Epoch: 6| Step: 11
Training loss: 2.335894836240305
Validation loss: 2.5119392452485925

Epoch: 6| Step: 12
Training loss: 2.166110945617316
Validation loss: 2.5295271799306636

Epoch: 6| Step: 13
Training loss: 2.1930160729358064
Validation loss: 2.539815155372108

Epoch: 207| Step: 0
Training loss: 2.6447020888261417
Validation loss: 2.5462690307300524

Epoch: 6| Step: 1
Training loss: 2.0028920721114396
Validation loss: 2.561590777728905

Epoch: 6| Step: 2
Training loss: 2.514649480430609
Validation loss: 2.5756874660565283

Epoch: 6| Step: 3
Training loss: 2.623230837508485
Validation loss: 2.59836546124588

Epoch: 6| Step: 4
Training loss: 2.070530948270361
Validation loss: 2.603167186943224

Epoch: 6| Step: 5
Training loss: 2.1264535756912992
Validation loss: 2.591115333467082

Epoch: 6| Step: 6
Training loss: 1.970857733265633
Validation loss: 2.5783526695757693

Epoch: 6| Step: 7
Training loss: 2.1585451157206705
Validation loss: 2.5402953925291705

Epoch: 6| Step: 8
Training loss: 2.588414506967845
Validation loss: 2.5379445671544105

Epoch: 6| Step: 9
Training loss: 2.332390685632406
Validation loss: 2.528730197891188

Epoch: 6| Step: 10
Training loss: 1.7685628434766727
Validation loss: 2.517502110065888

Epoch: 6| Step: 11
Training loss: 2.346054368477746
Validation loss: 2.495199187462297

Epoch: 6| Step: 12
Training loss: 2.648012830507248
Validation loss: 2.498025082315923

Epoch: 6| Step: 13
Training loss: 2.9052831210447865
Validation loss: 2.4943092585915085

Epoch: 208| Step: 0
Training loss: 2.260515858338707
Validation loss: 2.492464167784691

Epoch: 6| Step: 1
Training loss: 1.8662824791690091
Validation loss: 2.49067757047265

Epoch: 6| Step: 2
Training loss: 2.922465382053611
Validation loss: 2.4930444597323795

Epoch: 6| Step: 3
Training loss: 2.574557801582195
Validation loss: 2.493323773613961

Epoch: 6| Step: 4
Training loss: 2.393279951274171
Validation loss: 2.490221816885206

Epoch: 6| Step: 5
Training loss: 2.141897561160688
Validation loss: 2.4948326829526364

Epoch: 6| Step: 6
Training loss: 2.9550689273547377
Validation loss: 2.513420110156449

Epoch: 6| Step: 7
Training loss: 2.0505606977757207
Validation loss: 2.5041339153828726

Epoch: 6| Step: 8
Training loss: 2.2163455453277012
Validation loss: 2.5131255422858954

Epoch: 6| Step: 9
Training loss: 2.2621469043009084
Validation loss: 2.5355739004571256

Epoch: 6| Step: 10
Training loss: 2.1264721875770145
Validation loss: 2.549421648124161

Epoch: 6| Step: 11
Training loss: 2.63944908910705
Validation loss: 2.5486898684365644

Epoch: 6| Step: 12
Training loss: 3.0917675718170745
Validation loss: 2.548613908323254

Epoch: 6| Step: 13
Training loss: 1.7573060386927766
Validation loss: 2.547565920360283

Epoch: 209| Step: 0
Training loss: 2.3340280951710612
Validation loss: 2.54406905895294

Epoch: 6| Step: 1
Training loss: 2.406646398615711
Validation loss: 2.5547410685204595

Epoch: 6| Step: 2
Training loss: 3.1890291024402613
Validation loss: 2.549207746314616

Epoch: 6| Step: 3
Training loss: 2.365878508072576
Validation loss: 2.55168290921886

Epoch: 6| Step: 4
Training loss: 1.8565547936919586
Validation loss: 2.544660436239686

Epoch: 6| Step: 5
Training loss: 2.4365643392734255
Validation loss: 2.5549415827553315

Epoch: 6| Step: 6
Training loss: 1.6408096936126007
Validation loss: 2.567247861437746

Epoch: 6| Step: 7
Training loss: 2.1441105219694068
Validation loss: 2.561781115605065

Epoch: 6| Step: 8
Training loss: 2.7696944647340644
Validation loss: 2.5542146982112746

Epoch: 6| Step: 9
Training loss: 1.5321081442748008
Validation loss: 2.533002992056209

Epoch: 6| Step: 10
Training loss: 2.1625486511755456
Validation loss: 2.517429060329507

Epoch: 6| Step: 11
Training loss: 2.0389572642563816
Validation loss: 2.516087530986333

Epoch: 6| Step: 12
Training loss: 2.7691281648114185
Validation loss: 2.511578490205689

Epoch: 6| Step: 13
Training loss: 2.4222251392875784
Validation loss: 2.509253985827062

Epoch: 210| Step: 0
Training loss: 2.2857497267870515
Validation loss: 2.520509278667604

Epoch: 6| Step: 1
Training loss: 2.260428315819697
Validation loss: 2.513343242196535

Epoch: 6| Step: 2
Training loss: 2.333848408206191
Validation loss: 2.516546692630594

Epoch: 6| Step: 3
Training loss: 3.086093560630627
Validation loss: 2.5488325993485232

Epoch: 6| Step: 4
Training loss: 2.0680340591223203
Validation loss: 2.5426745579054826

Epoch: 6| Step: 5
Training loss: 1.9556835049015457
Validation loss: 2.5679842250672205

Epoch: 6| Step: 6
Training loss: 1.9935156490150867
Validation loss: 2.5747419104506593

Epoch: 6| Step: 7
Training loss: 2.262537147680676
Validation loss: 2.5707570535069078

Epoch: 6| Step: 8
Training loss: 2.0369995906868748
Validation loss: 2.5744773954776012

Epoch: 6| Step: 9
Training loss: 2.8303628571612935
Validation loss: 2.5496798557447895

Epoch: 6| Step: 10
Training loss: 2.6205628450074974
Validation loss: 2.5425335677265015

Epoch: 6| Step: 11
Training loss: 2.8403215806521898
Validation loss: 2.537475911857638

Epoch: 6| Step: 12
Training loss: 1.6470899814375366
Validation loss: 2.5439521384315413

Epoch: 6| Step: 13
Training loss: 1.7057515460771477
Validation loss: 2.549619564961216

Epoch: 211| Step: 0
Training loss: 2.227809623666106
Validation loss: 2.5252329419898736

Epoch: 6| Step: 1
Training loss: 1.7726222109395064
Validation loss: 2.541132516442305

Epoch: 6| Step: 2
Training loss: 2.323185128292583
Validation loss: 2.5320344031358526

Epoch: 6| Step: 3
Training loss: 2.516097125181611
Validation loss: 2.564413550236894

Epoch: 6| Step: 4
Training loss: 1.777936295886049
Validation loss: 2.574450369078378

Epoch: 6| Step: 5
Training loss: 2.5418252322237724
Validation loss: 2.558775109616835

Epoch: 6| Step: 6
Training loss: 2.5088160518205713
Validation loss: 2.570747222777212

Epoch: 6| Step: 7
Training loss: 2.8565052410914307
Validation loss: 2.582113998556836

Epoch: 6| Step: 8
Training loss: 2.770874816660484
Validation loss: 2.5818837903304908

Epoch: 6| Step: 9
Training loss: 2.2654700916869603
Validation loss: 2.590412044937243

Epoch: 6| Step: 10
Training loss: 2.58458690581771
Validation loss: 2.5816588178884325

Epoch: 6| Step: 11
Training loss: 2.2537233486704906
Validation loss: 2.579095060703104

Epoch: 6| Step: 12
Training loss: 1.9386503434777396
Validation loss: 2.5623363194486903

Epoch: 6| Step: 13
Training loss: 1.8662228825943918
Validation loss: 2.5432561740278454

Epoch: 212| Step: 0
Training loss: 2.3088398397219025
Validation loss: 2.5318614864749915

Epoch: 6| Step: 1
Training loss: 2.796040586321605
Validation loss: 2.5043885574373697

Epoch: 6| Step: 2
Training loss: 2.2848822535388167
Validation loss: 2.5018575443113438

Epoch: 6| Step: 3
Training loss: 1.751192367879688
Validation loss: 2.49945327820632

Epoch: 6| Step: 4
Training loss: 2.128399541905925
Validation loss: 2.5022676514880726

Epoch: 6| Step: 5
Training loss: 1.8142935330573242
Validation loss: 2.5070291406819334

Epoch: 6| Step: 6
Training loss: 2.49826266003236
Validation loss: 2.507022784821002

Epoch: 6| Step: 7
Training loss: 2.4559703289128403
Validation loss: 2.5101210603484403

Epoch: 6| Step: 8
Training loss: 3.0320255821074795
Validation loss: 2.5136456175734185

Epoch: 6| Step: 9
Training loss: 2.078387251059978
Validation loss: 2.53708389265514

Epoch: 6| Step: 10
Training loss: 2.8805854279176897
Validation loss: 2.5506651123153143

Epoch: 6| Step: 11
Training loss: 2.041762511929546
Validation loss: 2.585285984418075

Epoch: 6| Step: 12
Training loss: 2.124843367245489
Validation loss: 2.59738056756406

Epoch: 6| Step: 13
Training loss: 2.412262773462382
Validation loss: 2.601141940500936

Epoch: 213| Step: 0
Training loss: 1.9822098341418357
Validation loss: 2.6263009283958145

Epoch: 6| Step: 1
Training loss: 2.5056978145380504
Validation loss: 2.591883359192951

Epoch: 6| Step: 2
Training loss: 1.7061065334047625
Validation loss: 2.5707618142870228

Epoch: 6| Step: 3
Training loss: 2.6670822972007264
Validation loss: 2.576483463997525

Epoch: 6| Step: 4
Training loss: 2.139205573391555
Validation loss: 2.570270433632423

Epoch: 6| Step: 5
Training loss: 2.1582006946394685
Validation loss: 2.5609994076687546

Epoch: 6| Step: 6
Training loss: 2.4754948285133
Validation loss: 2.545189984618102

Epoch: 6| Step: 7
Training loss: 1.8523815291150845
Validation loss: 2.5346042872707266

Epoch: 6| Step: 8
Training loss: 2.826005257187885
Validation loss: 2.522959912971859

Epoch: 6| Step: 9
Training loss: 2.2756757172860462
Validation loss: 2.528662233990258

Epoch: 6| Step: 10
Training loss: 2.4451504492156135
Validation loss: 2.522664505830946

Epoch: 6| Step: 11
Training loss: 2.674725801906985
Validation loss: 2.5257319047431883

Epoch: 6| Step: 12
Training loss: 2.613453949152738
Validation loss: 2.5286671368807774

Epoch: 6| Step: 13
Training loss: 1.896211677219344
Validation loss: 2.511714225357592

Epoch: 214| Step: 0
Training loss: 2.4078617395395194
Validation loss: 2.5209553954362245

Epoch: 6| Step: 1
Training loss: 2.7929159946394364
Validation loss: 2.5503774793639282

Epoch: 6| Step: 2
Training loss: 2.352254670634636
Validation loss: 2.5676579551062026

Epoch: 6| Step: 3
Training loss: 2.2955681852543295
Validation loss: 2.5619323613486893

Epoch: 6| Step: 4
Training loss: 2.7726874398384838
Validation loss: 2.578061590474555

Epoch: 6| Step: 5
Training loss: 2.169381446048498
Validation loss: 2.5832044405212544

Epoch: 6| Step: 6
Training loss: 1.89010221961783
Validation loss: 2.585356463628699

Epoch: 6| Step: 7
Training loss: 2.1132494347622455
Validation loss: 2.5842754635445253

Epoch: 6| Step: 8
Training loss: 2.3773146944404706
Validation loss: 2.604203190865288

Epoch: 6| Step: 9
Training loss: 2.6150028049315366
Validation loss: 2.625756805557351

Epoch: 6| Step: 10
Training loss: 1.3291036254059578
Validation loss: 2.614480511795339

Epoch: 6| Step: 11
Training loss: 2.177839473360816
Validation loss: 2.612324842333659

Epoch: 6| Step: 12
Training loss: 2.4925035617079776
Validation loss: 2.595937518809438

Epoch: 6| Step: 13
Training loss: 2.1019721216953666
Validation loss: 2.611325827240676

Epoch: 215| Step: 0
Training loss: 2.404324938116838
Validation loss: 2.5572886625584337

Epoch: 6| Step: 1
Training loss: 2.4322265899469504
Validation loss: 2.539825379621926

Epoch: 6| Step: 2
Training loss: 2.1817253185146837
Validation loss: 2.530449179353534

Epoch: 6| Step: 3
Training loss: 2.452333942356045
Validation loss: 2.501577499506703

Epoch: 6| Step: 4
Training loss: 2.004826325198211
Validation loss: 2.5053014334802644

Epoch: 6| Step: 5
Training loss: 2.24138432914516
Validation loss: 2.5019024842075903

Epoch: 6| Step: 6
Training loss: 3.1393059385018045
Validation loss: 2.5049468688507908

Epoch: 6| Step: 7
Training loss: 2.240343884399766
Validation loss: 2.4976558503536523

Epoch: 6| Step: 8
Training loss: 2.1468809835692064
Validation loss: 2.495527733597415

Epoch: 6| Step: 9
Training loss: 2.1116384159999453
Validation loss: 2.4874155563768983

Epoch: 6| Step: 10
Training loss: 2.254173011794359
Validation loss: 2.4922298001294014

Epoch: 6| Step: 11
Training loss: 2.220146921468323
Validation loss: 2.511034835324645

Epoch: 6| Step: 12
Training loss: 1.6787616395866352
Validation loss: 2.508708457102302

Epoch: 6| Step: 13
Training loss: 2.788794924084787
Validation loss: 2.527563228049

Epoch: 216| Step: 0
Training loss: 2.8586811829003858
Validation loss: 2.5309847469043545

Epoch: 6| Step: 1
Training loss: 1.9625099230472904
Validation loss: 2.5345203952185686

Epoch: 6| Step: 2
Training loss: 2.2179743525859914
Validation loss: 2.5593994735646883

Epoch: 6| Step: 3
Training loss: 2.571276359367358
Validation loss: 2.56066213775611

Epoch: 6| Step: 4
Training loss: 2.340237235734669
Validation loss: 2.533846610444509

Epoch: 6| Step: 5
Training loss: 2.047745846997142
Validation loss: 2.532969859885036

Epoch: 6| Step: 6
Training loss: 1.702105015492478
Validation loss: 2.5208789148754738

Epoch: 6| Step: 7
Training loss: 2.50864698364838
Validation loss: 2.5224156155947064

Epoch: 6| Step: 8
Training loss: 2.500073527208545
Validation loss: 2.528702635410279

Epoch: 6| Step: 9
Training loss: 1.898688217373406
Validation loss: 2.5280624381907564

Epoch: 6| Step: 10
Training loss: 1.936925987613915
Validation loss: 2.544877499603124

Epoch: 6| Step: 11
Training loss: 2.142389948187303
Validation loss: 2.54113501840771

Epoch: 6| Step: 12
Training loss: 2.5462952872637152
Validation loss: 2.549071864218903

Epoch: 6| Step: 13
Training loss: 2.8022077643881733
Validation loss: 2.5472307015317974

Epoch: 217| Step: 0
Training loss: 1.9873904048045037
Validation loss: 2.570415923753906

Epoch: 6| Step: 1
Training loss: 1.5184100017738749
Validation loss: 2.5739608118304416

Epoch: 6| Step: 2
Training loss: 1.8386982390939035
Validation loss: 2.5685003631147967

Epoch: 6| Step: 3
Training loss: 1.6562710886638325
Validation loss: 2.5937358442173015

Epoch: 6| Step: 4
Training loss: 2.441870854229968
Validation loss: 2.6303098501625897

Epoch: 6| Step: 5
Training loss: 2.6929737503806566
Validation loss: 2.6369156149380775

Epoch: 6| Step: 6
Training loss: 2.4644419105263746
Validation loss: 2.6172057193862104

Epoch: 6| Step: 7
Training loss: 2.5266004645633506
Validation loss: 2.58792374499738

Epoch: 6| Step: 8
Training loss: 2.250275912851569
Validation loss: 2.57318479605463

Epoch: 6| Step: 9
Training loss: 2.304580117003103
Validation loss: 2.5845730995846017

Epoch: 6| Step: 10
Training loss: 2.77829903056436
Validation loss: 2.5692793326266608

Epoch: 6| Step: 11
Training loss: 2.6717100929099025
Validation loss: 2.5418960801279025

Epoch: 6| Step: 12
Training loss: 2.1081856094093574
Validation loss: 2.51134757566789

Epoch: 6| Step: 13
Training loss: 2.39166297070509
Validation loss: 2.5191452479821628

Epoch: 218| Step: 0
Training loss: 2.0504229132620373
Validation loss: 2.5157049257206388

Epoch: 6| Step: 1
Training loss: 2.104427384443104
Validation loss: 2.52571639231288

Epoch: 6| Step: 2
Training loss: 2.879654144077367
Validation loss: 2.5173257326877474

Epoch: 6| Step: 3
Training loss: 2.4720285592204063
Validation loss: 2.5185027238549496

Epoch: 6| Step: 4
Training loss: 2.4910251693219716
Validation loss: 2.5144394950108127

Epoch: 6| Step: 5
Training loss: 2.2899416123988403
Validation loss: 2.5371784751904802

Epoch: 6| Step: 6
Training loss: 2.171824173366885
Validation loss: 2.550479125220081

Epoch: 6| Step: 7
Training loss: 2.155124093928118
Validation loss: 2.5724247038671195

Epoch: 6| Step: 8
Training loss: 2.0574197334957764
Validation loss: 2.586852227855996

Epoch: 6| Step: 9
Training loss: 1.7713176139896896
Validation loss: 2.5840985846467115

Epoch: 6| Step: 10
Training loss: 2.635069742600822
Validation loss: 2.597633128433772

Epoch: 6| Step: 11
Training loss: 2.6912900237966735
Validation loss: 2.5983259289113807

Epoch: 6| Step: 12
Training loss: 2.298265723805504
Validation loss: 2.5866319044798924

Epoch: 6| Step: 13
Training loss: 2.204591303726676
Validation loss: 2.575515505351594

Epoch: 219| Step: 0
Training loss: 1.9291326675000655
Validation loss: 2.571870719933917

Epoch: 6| Step: 1
Training loss: 2.3475667774586704
Validation loss: 2.568821931869828

Epoch: 6| Step: 2
Training loss: 2.9346869777142377
Validation loss: 2.541779755332976

Epoch: 6| Step: 3
Training loss: 1.8388447570243094
Validation loss: 2.5733480876868584

Epoch: 6| Step: 4
Training loss: 3.0598994521532235
Validation loss: 2.5668066013469066

Epoch: 6| Step: 5
Training loss: 2.2996085372827375
Validation loss: 2.582528147782547

Epoch: 6| Step: 6
Training loss: 2.0880120066374284
Validation loss: 2.582780014790739

Epoch: 6| Step: 7
Training loss: 2.1779782830058516
Validation loss: 2.5989969718267694

Epoch: 6| Step: 8
Training loss: 2.2583742069988957
Validation loss: 2.6149363539069808

Epoch: 6| Step: 9
Training loss: 2.129058888414243
Validation loss: 2.635388571447457

Epoch: 6| Step: 10
Training loss: 2.8510306920620967
Validation loss: 2.667824081735955

Epoch: 6| Step: 11
Training loss: 1.7466605885717814
Validation loss: 2.6040320908424164

Epoch: 6| Step: 12
Training loss: 1.8892683726315018
Validation loss: 2.5889650046010724

Epoch: 6| Step: 13
Training loss: 2.0957816216805427
Validation loss: 2.5626729116019704

Epoch: 220| Step: 0
Training loss: 2.2308122734450397
Validation loss: 2.5113800437450906

Epoch: 6| Step: 1
Training loss: 2.3498206293356243
Validation loss: 2.515149247257955

Epoch: 6| Step: 2
Training loss: 2.3739309414506167
Validation loss: 2.5016442296061623

Epoch: 6| Step: 3
Training loss: 2.932484667283452
Validation loss: 2.499368730953565

Epoch: 6| Step: 4
Training loss: 2.1747523945147202
Validation loss: 2.494107263352396

Epoch: 6| Step: 5
Training loss: 2.3277341783436736
Validation loss: 2.491033304746045

Epoch: 6| Step: 6
Training loss: 2.302128395801771
Validation loss: 2.498286772843996

Epoch: 6| Step: 7
Training loss: 2.5809041158667347
Validation loss: 2.4901192751943872

Epoch: 6| Step: 8
Training loss: 1.9448711093667777
Validation loss: 2.5033283171707197

Epoch: 6| Step: 9
Training loss: 2.6594854060742787
Validation loss: 2.506750640587024

Epoch: 6| Step: 10
Training loss: 2.272118254471956
Validation loss: 2.509412562056315

Epoch: 6| Step: 11
Training loss: 2.0290063057054626
Validation loss: 2.533783425849454

Epoch: 6| Step: 12
Training loss: 2.233710877215201
Validation loss: 2.556418063134889

Epoch: 6| Step: 13
Training loss: 2.2601397179144986
Validation loss: 2.5572452165434156

Epoch: 221| Step: 0
Training loss: 2.4224716928125347
Validation loss: 2.5821989142556387

Epoch: 6| Step: 1
Training loss: 1.9935246785714709
Validation loss: 2.5908078585067864

Epoch: 6| Step: 2
Training loss: 1.6464813340997275
Validation loss: 2.6083711912883234

Epoch: 6| Step: 3
Training loss: 2.226383884694274
Validation loss: 2.615683181158151

Epoch: 6| Step: 4
Training loss: 3.2080920900744787
Validation loss: 2.5928537589812612

Epoch: 6| Step: 5
Training loss: 2.5762307346147457
Validation loss: 2.5719417521642822

Epoch: 6| Step: 6
Training loss: 2.3276395355585273
Validation loss: 2.5437910290657646

Epoch: 6| Step: 7
Training loss: 2.126867147201941
Validation loss: 2.529327730164918

Epoch: 6| Step: 8
Training loss: 1.7084150837512153
Validation loss: 2.515676446550519

Epoch: 6| Step: 9
Training loss: 2.0055403265311753
Validation loss: 2.516331812284536

Epoch: 6| Step: 10
Training loss: 2.4675146947730418
Validation loss: 2.5216205775840925

Epoch: 6| Step: 11
Training loss: 2.573524393028687
Validation loss: 2.540321405781287

Epoch: 6| Step: 12
Training loss: 2.531541030542236
Validation loss: 2.547973887210925

Epoch: 6| Step: 13
Training loss: 2.081317829481628
Validation loss: 2.5391271025435285

Epoch: 222| Step: 0
Training loss: 1.846832220676127
Validation loss: 2.5856823521616517

Epoch: 6| Step: 1
Training loss: 2.701839692703314
Validation loss: 2.6249120485618445

Epoch: 6| Step: 2
Training loss: 2.2381727049174183
Validation loss: 2.6701700820280347

Epoch: 6| Step: 3
Training loss: 2.3763541326527142
Validation loss: 2.674067053512174

Epoch: 6| Step: 4
Training loss: 2.357433606666128
Validation loss: 2.6333731668413125

Epoch: 6| Step: 5
Training loss: 2.234493866006179
Validation loss: 2.616853910983307

Epoch: 6| Step: 6
Training loss: 2.5370370151223796
Validation loss: 2.569211668061102

Epoch: 6| Step: 7
Training loss: 1.9097482444454492
Validation loss: 2.5564110606471417

Epoch: 6| Step: 8
Training loss: 2.1451516287681143
Validation loss: 2.5322892367247882

Epoch: 6| Step: 9
Training loss: 2.5996033219196057
Validation loss: 2.529344854304824

Epoch: 6| Step: 10
Training loss: 2.710386544562835
Validation loss: 2.52475150808686

Epoch: 6| Step: 11
Training loss: 2.1578820727690444
Validation loss: 2.507252211683589

Epoch: 6| Step: 12
Training loss: 1.8317924295048442
Validation loss: 2.5189853914762796

Epoch: 6| Step: 13
Training loss: 2.5910176052141725
Validation loss: 2.51200258382636

Epoch: 223| Step: 0
Training loss: 1.5525870391232
Validation loss: 2.527154977343198

Epoch: 6| Step: 1
Training loss: 2.0153860497595564
Validation loss: 2.5300173485705173

Epoch: 6| Step: 2
Training loss: 2.4252685398187093
Validation loss: 2.5491418716041188

Epoch: 6| Step: 3
Training loss: 1.4425463625698316
Validation loss: 2.561452511944593

Epoch: 6| Step: 4
Training loss: 2.3360362972940703
Validation loss: 2.5751663570924395

Epoch: 6| Step: 5
Training loss: 2.33067530280302
Validation loss: 2.5915537655229834

Epoch: 6| Step: 6
Training loss: 2.361018738778513
Validation loss: 2.595398252794104

Epoch: 6| Step: 7
Training loss: 2.607879118528443
Validation loss: 2.594106289701892

Epoch: 6| Step: 8
Training loss: 1.9448676768893896
Validation loss: 2.5918187531211667

Epoch: 6| Step: 9
Training loss: 2.624874747784899
Validation loss: 2.6194810980260286

Epoch: 6| Step: 10
Training loss: 2.6239716468302663
Validation loss: 2.5907887786276698

Epoch: 6| Step: 11
Training loss: 2.718560047748685
Validation loss: 2.5909479011324112

Epoch: 6| Step: 12
Training loss: 2.0327551327116185
Validation loss: 2.5790055591838392

Epoch: 6| Step: 13
Training loss: 2.6683374376362727
Validation loss: 2.556897108998332

Epoch: 224| Step: 0
Training loss: 2.1671391729949865
Validation loss: 2.538825062140307

Epoch: 6| Step: 1
Training loss: 2.121559611773804
Validation loss: 2.5191644919139256

Epoch: 6| Step: 2
Training loss: 2.4851570098213824
Validation loss: 2.4968715325539534

Epoch: 6| Step: 3
Training loss: 2.408280147858394
Validation loss: 2.48748795396198

Epoch: 6| Step: 4
Training loss: 2.086201968911527
Validation loss: 2.4870124748089926

Epoch: 6| Step: 5
Training loss: 2.2896863067861255
Validation loss: 2.4781295680115822

Epoch: 6| Step: 6
Training loss: 2.8234703581375262
Validation loss: 2.4844551473361234

Epoch: 6| Step: 7
Training loss: 2.461542545599484
Validation loss: 2.5032850696120357

Epoch: 6| Step: 8
Training loss: 1.333900281453305
Validation loss: 2.5156845338462475

Epoch: 6| Step: 9
Training loss: 2.3673556932177404
Validation loss: 2.525181989122986

Epoch: 6| Step: 10
Training loss: 2.4170281918088543
Validation loss: 2.547313083034406

Epoch: 6| Step: 11
Training loss: 1.9746346703181665
Validation loss: 2.597338908991746

Epoch: 6| Step: 12
Training loss: 3.3067972289222705
Validation loss: 2.6478280835725028

Epoch: 6| Step: 13
Training loss: 2.2289894128601917
Validation loss: 2.591607951963903

Epoch: 225| Step: 0
Training loss: 1.7143439952843422
Validation loss: 2.5521141102290965

Epoch: 6| Step: 1
Training loss: 2.3242448051979694
Validation loss: 2.5332221209642993

Epoch: 6| Step: 2
Training loss: 2.87656442951923
Validation loss: 2.5127092606431267

Epoch: 6| Step: 3
Training loss: 1.6604160958181027
Validation loss: 2.5085159614419643

Epoch: 6| Step: 4
Training loss: 2.0621410404295286
Validation loss: 2.49438220481944

Epoch: 6| Step: 5
Training loss: 1.9042261355050194
Validation loss: 2.496447009349795

Epoch: 6| Step: 6
Training loss: 3.3290441255770498
Validation loss: 2.4812368570359222

Epoch: 6| Step: 7
Training loss: 2.4771475597254615
Validation loss: 2.494166466427978

Epoch: 6| Step: 8
Training loss: 2.3274680625289546
Validation loss: 2.493399633207789

Epoch: 6| Step: 9
Training loss: 1.8230712025851965
Validation loss: 2.504365161850724

Epoch: 6| Step: 10
Training loss: 2.391169866165393
Validation loss: 2.501696694321156

Epoch: 6| Step: 11
Training loss: 2.285939556754511
Validation loss: 2.520734995245371

Epoch: 6| Step: 12
Training loss: 2.2168266664091236
Validation loss: 2.5297516363667474

Epoch: 6| Step: 13
Training loss: 2.356516540184388
Validation loss: 2.5403096114714834

Epoch: 226| Step: 0
Training loss: 2.020033045394576
Validation loss: 2.551269468949361

Epoch: 6| Step: 1
Training loss: 2.4493934775879795
Validation loss: 2.554139057983071

Epoch: 6| Step: 2
Training loss: 2.0871877745165404
Validation loss: 2.574986082490019

Epoch: 6| Step: 3
Training loss: 2.264953724302106
Validation loss: 2.573796285367783

Epoch: 6| Step: 4
Training loss: 2.2314639034373265
Validation loss: 2.5667997897498336

Epoch: 6| Step: 5
Training loss: 2.221428557235164
Validation loss: 2.570654076293462

Epoch: 6| Step: 6
Training loss: 2.4148689577236473
Validation loss: 2.5726404749678866

Epoch: 6| Step: 7
Training loss: 2.0825959490119104
Validation loss: 2.5603261891812386

Epoch: 6| Step: 8
Training loss: 2.5320574567522027
Validation loss: 2.565860932282155

Epoch: 6| Step: 9
Training loss: 2.55507570636065
Validation loss: 2.565010686161816

Epoch: 6| Step: 10
Training loss: 2.5741201101110405
Validation loss: 2.556654193512863

Epoch: 6| Step: 11
Training loss: 1.7225752830940404
Validation loss: 2.558239022627941

Epoch: 6| Step: 12
Training loss: 2.6487832532940305
Validation loss: 2.543838953685752

Epoch: 6| Step: 13
Training loss: 2.1394301372335747
Validation loss: 2.5605651094401827

Epoch: 227| Step: 0
Training loss: 2.5177723504101777
Validation loss: 2.546957026371838

Epoch: 6| Step: 1
Training loss: 2.171675528827579
Validation loss: 2.554066962764053

Epoch: 6| Step: 2
Training loss: 2.0698914297628894
Validation loss: 2.55490089637374

Epoch: 6| Step: 3
Training loss: 2.29197221510791
Validation loss: 2.535176500926276

Epoch: 6| Step: 4
Training loss: 2.447882426137412
Validation loss: 2.5177281435869854

Epoch: 6| Step: 5
Training loss: 2.2302073844991983
Validation loss: 2.510646118399386

Epoch: 6| Step: 6
Training loss: 2.397216883899358
Validation loss: 2.5068618382739514

Epoch: 6| Step: 7
Training loss: 2.066979139557702
Validation loss: 2.518050893938346

Epoch: 6| Step: 8
Training loss: 2.2757902261103236
Validation loss: 2.5227711588077746

Epoch: 6| Step: 9
Training loss: 2.3784517001143017
Validation loss: 2.5373454543282072

Epoch: 6| Step: 10
Training loss: 2.404014143135753
Validation loss: 2.5749167391824983

Epoch: 6| Step: 11
Training loss: 2.5107518733404186
Validation loss: 2.5619908268903524

Epoch: 6| Step: 12
Training loss: 1.4778632030956753
Validation loss: 2.562493114927393

Epoch: 6| Step: 13
Training loss: 2.6086246530919306
Validation loss: 2.5893453863624893

Epoch: 228| Step: 0
Training loss: 1.7730953205732125
Validation loss: 2.5939588654157872

Epoch: 6| Step: 1
Training loss: 2.3248493268812487
Validation loss: 2.6353622601789857

Epoch: 6| Step: 2
Training loss: 2.5759262419027342
Validation loss: 2.6560744283657707

Epoch: 6| Step: 3
Training loss: 1.9297413065586402
Validation loss: 2.66899827015262

Epoch: 6| Step: 4
Training loss: 2.803770802761257
Validation loss: 2.6132321963721803

Epoch: 6| Step: 5
Training loss: 1.854374806012284
Validation loss: 2.5638082777690823

Epoch: 6| Step: 6
Training loss: 2.4970808152032746
Validation loss: 2.5068586205056986

Epoch: 6| Step: 7
Training loss: 2.594634491274358
Validation loss: 2.4989740650804975

Epoch: 6| Step: 8
Training loss: 2.8051465012206664
Validation loss: 2.4946873483104675

Epoch: 6| Step: 9
Training loss: 2.675829899477906
Validation loss: 2.490656120140971

Epoch: 6| Step: 10
Training loss: 2.2239407278848553
Validation loss: 2.4917196474428334

Epoch: 6| Step: 11
Training loss: 2.2306872259189388
Validation loss: 2.486980695208068

Epoch: 6| Step: 12
Training loss: 2.1007995354993994
Validation loss: 2.4888064131194

Epoch: 6| Step: 13
Training loss: 2.445246003925649
Validation loss: 2.4851817534568257

Epoch: 229| Step: 0
Training loss: 1.844088248567801
Validation loss: 2.488447110942654

Epoch: 6| Step: 1
Training loss: 2.517784565939548
Validation loss: 2.5052688628330637

Epoch: 6| Step: 2
Training loss: 2.949216486443668
Validation loss: 2.5090154375179377

Epoch: 6| Step: 3
Training loss: 1.9135747794198912
Validation loss: 2.5219578927498256

Epoch: 6| Step: 4
Training loss: 2.835687967887282
Validation loss: 2.5519589504111417

Epoch: 6| Step: 5
Training loss: 2.2922129124517956
Validation loss: 2.5613459260054454

Epoch: 6| Step: 6
Training loss: 1.8787232625128518
Validation loss: 2.5741341962420203

Epoch: 6| Step: 7
Training loss: 2.776990994184354
Validation loss: 2.6004914302272764

Epoch: 6| Step: 8
Training loss: 2.2916391082031424
Validation loss: 2.609402898155816

Epoch: 6| Step: 9
Training loss: 2.2963075520753446
Validation loss: 2.608711599966958

Epoch: 6| Step: 10
Training loss: 2.247496801932057
Validation loss: 2.6170064379562237

Epoch: 6| Step: 11
Training loss: 2.0035764188536764
Validation loss: 2.6388288931691104

Epoch: 6| Step: 12
Training loss: 1.5931854744197549
Validation loss: 2.660106746233507

Epoch: 6| Step: 13
Training loss: 2.0817597231848017
Validation loss: 2.6357347550251435

Epoch: 230| Step: 0
Training loss: 1.6533011330012015
Validation loss: 2.598574735558036

Epoch: 6| Step: 1
Training loss: 2.109059402027192
Validation loss: 2.567086983506672

Epoch: 6| Step: 2
Training loss: 3.0934055020968123
Validation loss: 2.5531404809937674

Epoch: 6| Step: 3
Training loss: 2.609194629397107
Validation loss: 2.554450192254423

Epoch: 6| Step: 4
Training loss: 1.5593293636272034
Validation loss: 2.5607776436014262

Epoch: 6| Step: 5
Training loss: 2.4073113416866105
Validation loss: 2.5620724856406065

Epoch: 6| Step: 6
Training loss: 2.208490857917876
Validation loss: 2.5679625926279046

Epoch: 6| Step: 7
Training loss: 2.0619485291236956
Validation loss: 2.5563026012427565

Epoch: 6| Step: 8
Training loss: 1.8923733406566094
Validation loss: 2.5424229533756812

Epoch: 6| Step: 9
Training loss: 2.172057000088465
Validation loss: 2.5425489541101127

Epoch: 6| Step: 10
Training loss: 2.642709665344488
Validation loss: 2.531371659231943

Epoch: 6| Step: 11
Training loss: 2.2381308406869738
Validation loss: 2.5154289895851574

Epoch: 6| Step: 12
Training loss: 1.8847017425621349
Validation loss: 2.5106098264299472

Epoch: 6| Step: 13
Training loss: 2.7476146062494093
Validation loss: 2.523413139359525

Epoch: 231| Step: 0
Training loss: 2.311532514108711
Validation loss: 2.526235015915304

Epoch: 6| Step: 1
Training loss: 2.3672157008943118
Validation loss: 2.5105915298870896

Epoch: 6| Step: 2
Training loss: 2.2625121732774205
Validation loss: 2.5279674124121283

Epoch: 6| Step: 3
Training loss: 2.160821353552059
Validation loss: 2.5137565339678667

Epoch: 6| Step: 4
Training loss: 1.9653625410093016
Validation loss: 2.5533529328506193

Epoch: 6| Step: 5
Training loss: 2.4510483425669305
Validation loss: 2.579428464660326

Epoch: 6| Step: 6
Training loss: 1.9204944521290785
Validation loss: 2.6156461969304416

Epoch: 6| Step: 7
Training loss: 1.617980394086654
Validation loss: 2.6394371054434536

Epoch: 6| Step: 8
Training loss: 2.564206555287368
Validation loss: 2.642965479634594

Epoch: 6| Step: 9
Training loss: 2.458500409240875
Validation loss: 2.6326505948929575

Epoch: 6| Step: 10
Training loss: 1.9982667803823977
Validation loss: 2.6201846748766733

Epoch: 6| Step: 11
Training loss: 2.444395825836957
Validation loss: 2.5869914478071676

Epoch: 6| Step: 12
Training loss: 2.9528798803901073
Validation loss: 2.5747359069404943

Epoch: 6| Step: 13
Training loss: 2.058146766619319
Validation loss: 2.5883376094179353

Epoch: 232| Step: 0
Training loss: 2.31232627009867
Validation loss: 2.574054355803735

Epoch: 6| Step: 1
Training loss: 2.164658006610628
Validation loss: 2.5719609486837194

Epoch: 6| Step: 2
Training loss: 2.001650605953854
Validation loss: 2.577840161242385

Epoch: 6| Step: 3
Training loss: 1.9398025858610037
Validation loss: 2.5585241254889555

Epoch: 6| Step: 4
Training loss: 2.7618081862065407
Validation loss: 2.5791461810241842

Epoch: 6| Step: 5
Training loss: 1.6275229309154196
Validation loss: 2.5856083163887384

Epoch: 6| Step: 6
Training loss: 2.652311389484106
Validation loss: 2.617841238485163

Epoch: 6| Step: 7
Training loss: 2.1563772633908687
Validation loss: 2.60190020289155

Epoch: 6| Step: 8
Training loss: 2.6092199405123995
Validation loss: 2.567943312059876

Epoch: 6| Step: 9
Training loss: 2.173815402450416
Validation loss: 2.570612247385016

Epoch: 6| Step: 10
Training loss: 2.4769446622652507
Validation loss: 2.571464056446323

Epoch: 6| Step: 11
Training loss: 2.105254832991654
Validation loss: 2.5707466740482676

Epoch: 6| Step: 12
Training loss: 2.3437988276163844
Validation loss: 2.549617796035995

Epoch: 6| Step: 13
Training loss: 2.1400892046580777
Validation loss: 2.5521579394172513

Epoch: 233| Step: 0
Training loss: 2.712445018580248
Validation loss: 2.550973430285327

Epoch: 6| Step: 1
Training loss: 2.417272513731054
Validation loss: 2.5276745870042627

Epoch: 6| Step: 2
Training loss: 2.715542095573783
Validation loss: 2.5452679359526726

Epoch: 6| Step: 3
Training loss: 1.750727910834073
Validation loss: 2.5688208335892946

Epoch: 6| Step: 4
Training loss: 1.4071673474106676
Validation loss: 2.5730208763197817

Epoch: 6| Step: 5
Training loss: 2.211594123522602
Validation loss: 2.6191522008690793

Epoch: 6| Step: 6
Training loss: 1.7677299982233294
Validation loss: 2.6235310516429444

Epoch: 6| Step: 7
Training loss: 2.346811456747066
Validation loss: 2.6369894910672174

Epoch: 6| Step: 8
Training loss: 2.759169117903324
Validation loss: 2.6381064599096713

Epoch: 6| Step: 9
Training loss: 2.0482546983011045
Validation loss: 2.628133039428172

Epoch: 6| Step: 10
Training loss: 1.8017509315586766
Validation loss: 2.6395777294056293

Epoch: 6| Step: 11
Training loss: 2.469360565784454
Validation loss: 2.6109573226532357

Epoch: 6| Step: 12
Training loss: 2.211238988802564
Validation loss: 2.5793817250735875

Epoch: 6| Step: 13
Training loss: 2.4777684690056363
Validation loss: 2.595783738529454

Epoch: 234| Step: 0
Training loss: 2.5096578968246326
Validation loss: 2.585910362877263

Epoch: 6| Step: 1
Training loss: 2.370551711945206
Validation loss: 2.5688304087235014

Epoch: 6| Step: 2
Training loss: 3.2692376555288294
Validation loss: 2.5588091965837716

Epoch: 6| Step: 3
Training loss: 2.483477352327072
Validation loss: 2.5459148961022824

Epoch: 6| Step: 4
Training loss: 1.4729495780897344
Validation loss: 2.5322120784762605

Epoch: 6| Step: 5
Training loss: 2.1118247041925127
Validation loss: 2.5142829110854485

Epoch: 6| Step: 6
Training loss: 1.8755340451410185
Validation loss: 2.5231331247030857

Epoch: 6| Step: 7
Training loss: 2.9928465433645117
Validation loss: 2.520410271025447

Epoch: 6| Step: 8
Training loss: 1.3872499120275374
Validation loss: 2.53083348870133

Epoch: 6| Step: 9
Training loss: 2.0711170864337376
Validation loss: 2.538165562980416

Epoch: 6| Step: 10
Training loss: 2.3985259695231673
Validation loss: 2.566765468314126

Epoch: 6| Step: 11
Training loss: 1.8423614445715715
Validation loss: 2.6028579831417353

Epoch: 6| Step: 12
Training loss: 2.140476416561499
Validation loss: 2.640966148836469

Epoch: 6| Step: 13
Training loss: 1.836446878098542
Validation loss: 2.691543907775407

Epoch: 235| Step: 0
Training loss: 2.2305660193189816
Validation loss: 2.7104086236348155

Epoch: 6| Step: 1
Training loss: 2.1636062306330444
Validation loss: 2.715207675170897

Epoch: 6| Step: 2
Training loss: 2.7199590340502597
Validation loss: 2.701667363235161

Epoch: 6| Step: 3
Training loss: 2.5421989904893114
Validation loss: 2.6411114457186877

Epoch: 6| Step: 4
Training loss: 2.2173881112032614
Validation loss: 2.587009680173596

Epoch: 6| Step: 5
Training loss: 2.715551489920451
Validation loss: 2.577974157062778

Epoch: 6| Step: 6
Training loss: 2.365094861956849
Validation loss: 2.5210459648389696

Epoch: 6| Step: 7
Training loss: 1.8439372339385844
Validation loss: 2.504371413388662

Epoch: 6| Step: 8
Training loss: 1.9164402731275212
Validation loss: 2.4800855846275818

Epoch: 6| Step: 9
Training loss: 2.230966168470701
Validation loss: 2.4723136387280977

Epoch: 6| Step: 10
Training loss: 2.004286464142958
Validation loss: 2.4763680912251553

Epoch: 6| Step: 11
Training loss: 2.741867785821471
Validation loss: 2.463632551026276

Epoch: 6| Step: 12
Training loss: 2.245172195457591
Validation loss: 2.464063469518303

Epoch: 6| Step: 13
Training loss: 1.9957481727137774
Validation loss: 2.4725740327670342

Epoch: 236| Step: 0
Training loss: 2.1385938377600535
Validation loss: 2.475664972953513

Epoch: 6| Step: 1
Training loss: 2.7416679563973436
Validation loss: 2.480776293654862

Epoch: 6| Step: 2
Training loss: 1.9379570944793192
Validation loss: 2.5020007075108768

Epoch: 6| Step: 3
Training loss: 2.2571980521367245
Validation loss: 2.514260105406712

Epoch: 6| Step: 4
Training loss: 2.684746773569101
Validation loss: 2.518875328460854

Epoch: 6| Step: 5
Training loss: 2.0995119435969287
Validation loss: 2.554772176321102

Epoch: 6| Step: 6
Training loss: 2.2843610896197113
Validation loss: 2.537214763000132

Epoch: 6| Step: 7
Training loss: 2.8703323288815628
Validation loss: 2.5652300860227424

Epoch: 6| Step: 8
Training loss: 1.7368997977985874
Validation loss: 2.5786885734092415

Epoch: 6| Step: 9
Training loss: 1.6034810553853944
Validation loss: 2.596431908293319

Epoch: 6| Step: 10
Training loss: 2.5131446504808914
Validation loss: 2.6280754632019647

Epoch: 6| Step: 11
Training loss: 2.391925931517369
Validation loss: 2.63025286545525

Epoch: 6| Step: 12
Training loss: 1.6811819126565701
Validation loss: 2.5700281482545355

Epoch: 6| Step: 13
Training loss: 2.3718107795314043
Validation loss: 2.5567827100251934

Epoch: 237| Step: 0
Training loss: 2.3197738073512575
Validation loss: 2.534208915213598

Epoch: 6| Step: 1
Training loss: 2.5082406602470977
Validation loss: 2.5200423321120216

Epoch: 6| Step: 2
Training loss: 3.0496303521958494
Validation loss: 2.5330203894100642

Epoch: 6| Step: 3
Training loss: 2.4385436342522855
Validation loss: 2.5352475032831094

Epoch: 6| Step: 4
Training loss: 2.392591278662822
Validation loss: 2.5237577567785103

Epoch: 6| Step: 5
Training loss: 1.951954849666851
Validation loss: 2.545630917616011

Epoch: 6| Step: 6
Training loss: 2.0381921540362438
Validation loss: 2.5261959435192476

Epoch: 6| Step: 7
Training loss: 1.7177617786699289
Validation loss: 2.561991478309485

Epoch: 6| Step: 8
Training loss: 1.4964696347220894
Validation loss: 2.5662523027035924

Epoch: 6| Step: 9
Training loss: 2.5284527051084456
Validation loss: 2.5624694202118143

Epoch: 6| Step: 10
Training loss: 2.096111161895103
Validation loss: 2.5892080348597695

Epoch: 6| Step: 11
Training loss: 2.4389125936751817
Validation loss: 2.5948683690746037

Epoch: 6| Step: 12
Training loss: 2.469104113713946
Validation loss: 2.579503317099091

Epoch: 6| Step: 13
Training loss: 1.9774295880191868
Validation loss: 2.5840367518292537

Epoch: 238| Step: 0
Training loss: 1.7148907422554753
Validation loss: 2.5616544631099796

Epoch: 6| Step: 1
Training loss: 2.0255143395422217
Validation loss: 2.5713804552077466

Epoch: 6| Step: 2
Training loss: 2.2304476922372327
Validation loss: 2.5288445616920994

Epoch: 6| Step: 3
Training loss: 2.1773087842615952
Validation loss: 2.524930467057366

Epoch: 6| Step: 4
Training loss: 2.494727200900989
Validation loss: 2.5416952246223707

Epoch: 6| Step: 5
Training loss: 2.716968610479033
Validation loss: 2.5373132402065797

Epoch: 6| Step: 6
Training loss: 2.218691113187526
Validation loss: 2.5391172745494055

Epoch: 6| Step: 7
Training loss: 2.7282784644940072
Validation loss: 2.5380828297698645

Epoch: 6| Step: 8
Training loss: 1.948714074371968
Validation loss: 2.5180454417247273

Epoch: 6| Step: 9
Training loss: 2.4127899074793637
Validation loss: 2.5589868685176858

Epoch: 6| Step: 10
Training loss: 2.114595973786656
Validation loss: 2.5697931694538707

Epoch: 6| Step: 11
Training loss: 2.1861949842629107
Validation loss: 2.575149668815966

Epoch: 6| Step: 12
Training loss: 1.96324635788514
Validation loss: 2.5734972022148654

Epoch: 6| Step: 13
Training loss: 2.1711108283558227
Validation loss: 2.5907764011711385

Epoch: 239| Step: 0
Training loss: 2.512604220681721
Validation loss: 2.6188899030923083

Epoch: 6| Step: 1
Training loss: 1.9276709270761134
Validation loss: 2.602356538461538

Epoch: 6| Step: 2
Training loss: 2.2364085087218077
Validation loss: 2.5838123359413454

Epoch: 6| Step: 3
Training loss: 1.8348436059231374
Validation loss: 2.5885377010159014

Epoch: 6| Step: 4
Training loss: 1.5628399288437944
Validation loss: 2.5411001157677955

Epoch: 6| Step: 5
Training loss: 2.121017988618775
Validation loss: 2.5281180640629644

Epoch: 6| Step: 6
Training loss: 2.7682930528380845
Validation loss: 2.5319783689474864

Epoch: 6| Step: 7
Training loss: 2.1988427499680174
Validation loss: 2.5300529852132447

Epoch: 6| Step: 8
Training loss: 2.663145024784544
Validation loss: 2.5324138430381185

Epoch: 6| Step: 9
Training loss: 2.750586620531984
Validation loss: 2.554663452906303

Epoch: 6| Step: 10
Training loss: 2.762125764932236
Validation loss: 2.568081197432401

Epoch: 6| Step: 11
Training loss: 2.1791854881898547
Validation loss: 2.558751023290318

Epoch: 6| Step: 12
Training loss: 1.6824951836118869
Validation loss: 2.5673705698415232

Epoch: 6| Step: 13
Training loss: 2.2878470986101
Validation loss: 2.5968077839500654

Epoch: 240| Step: 0
Training loss: 1.9391006502860282
Validation loss: 2.622578033411203

Epoch: 6| Step: 1
Training loss: 2.238703343402051
Validation loss: 2.636633857019755

Epoch: 6| Step: 2
Training loss: 2.4878763920476743
Validation loss: 2.6282683038216

Epoch: 6| Step: 3
Training loss: 2.117421492705455
Validation loss: 2.613812691441285

Epoch: 6| Step: 4
Training loss: 2.732789021080887
Validation loss: 2.6461649459122407

Epoch: 6| Step: 5
Training loss: 2.179199601672748
Validation loss: 2.600301182859831

Epoch: 6| Step: 6
Training loss: 2.2076959469882045
Validation loss: 2.579211443469753

Epoch: 6| Step: 7
Training loss: 2.258912871019199
Validation loss: 2.5379569126166155

Epoch: 6| Step: 8
Training loss: 1.7908899560600582
Validation loss: 2.4988117732111883

Epoch: 6| Step: 9
Training loss: 1.9645492909442823
Validation loss: 2.5002962572672898

Epoch: 6| Step: 10
Training loss: 2.353584915344112
Validation loss: 2.488070428641572

Epoch: 6| Step: 11
Training loss: 3.234288900952452
Validation loss: 2.4921590789481787

Epoch: 6| Step: 12
Training loss: 2.3469482979331664
Validation loss: 2.485352569759742

Epoch: 6| Step: 13
Training loss: 2.3979173524945625
Validation loss: 2.5052971193015066

Epoch: 241| Step: 0
Training loss: 2.172026923924276
Validation loss: 2.4990681739530602

Epoch: 6| Step: 1
Training loss: 2.2208611558766207
Validation loss: 2.522857394626018

Epoch: 6| Step: 2
Training loss: 2.7509061880863652
Validation loss: 2.5454310124772994

Epoch: 6| Step: 3
Training loss: 1.6789414279211448
Validation loss: 2.565256311129108

Epoch: 6| Step: 4
Training loss: 2.002922545391947
Validation loss: 2.5582411506107356

Epoch: 6| Step: 5
Training loss: 1.7094585000797395
Validation loss: 2.5744066184320955

Epoch: 6| Step: 6
Training loss: 2.4868978490400564
Validation loss: 2.5787560663538684

Epoch: 6| Step: 7
Training loss: 1.7540966856612281
Validation loss: 2.5996849456051883

Epoch: 6| Step: 8
Training loss: 2.716777743855628
Validation loss: 2.6050394325054165

Epoch: 6| Step: 9
Training loss: 2.7143011415372986
Validation loss: 2.5852780764247045

Epoch: 6| Step: 10
Training loss: 1.5992288101841456
Validation loss: 2.6066757830129497

Epoch: 6| Step: 11
Training loss: 2.4524665483376795
Validation loss: 2.61153320328933

Epoch: 6| Step: 12
Training loss: 1.4705171708158686
Validation loss: 2.5769279398180642

Epoch: 6| Step: 13
Training loss: 3.4456526746214537
Validation loss: 2.5556458552849795

Epoch: 242| Step: 0
Training loss: 1.8644235496325174
Validation loss: 2.544017975709694

Epoch: 6| Step: 1
Training loss: 2.7339644641589946
Validation loss: 2.514951580256476

Epoch: 6| Step: 2
Training loss: 2.5170833554262884
Validation loss: 2.5150509607803304

Epoch: 6| Step: 3
Training loss: 2.365170869360599
Validation loss: 2.4941497061735127

Epoch: 6| Step: 4
Training loss: 2.4606348245166374
Validation loss: 2.5097753304418777

Epoch: 6| Step: 5
Training loss: 1.719670690682757
Validation loss: 2.506220961201945

Epoch: 6| Step: 6
Training loss: 1.440889426103487
Validation loss: 2.507558902899312

Epoch: 6| Step: 7
Training loss: 2.6337461542319605
Validation loss: 2.503418921122064

Epoch: 6| Step: 8
Training loss: 3.026321967181921
Validation loss: 2.514774692168306

Epoch: 6| Step: 9
Training loss: 1.525982105885154
Validation loss: 2.5142241184783494

Epoch: 6| Step: 10
Training loss: 2.5155216930335857
Validation loss: 2.5659691580164923

Epoch: 6| Step: 11
Training loss: 2.115190302987602
Validation loss: 2.5785345965911066

Epoch: 6| Step: 12
Training loss: 2.179213386846868
Validation loss: 2.5833467795934726

Epoch: 6| Step: 13
Training loss: 2.3684101031981672
Validation loss: 2.608603464302528

Epoch: 243| Step: 0
Training loss: 1.8240031537689583
Validation loss: 2.596376927211304

Epoch: 6| Step: 1
Training loss: 2.48224707107302
Validation loss: 2.6100845894923834

Epoch: 6| Step: 2
Training loss: 1.3990193440570349
Validation loss: 2.583044579478008

Epoch: 6| Step: 3
Training loss: 1.712351593492507
Validation loss: 2.5895581440353928

Epoch: 6| Step: 4
Training loss: 2.353616723386165
Validation loss: 2.573579167518159

Epoch: 6| Step: 5
Training loss: 2.8030803187795126
Validation loss: 2.551824335982284

Epoch: 6| Step: 6
Training loss: 2.920161106681796
Validation loss: 2.5747143466613314

Epoch: 6| Step: 7
Training loss: 2.425956584595404
Validation loss: 2.5389705386992283

Epoch: 6| Step: 8
Training loss: 2.36160647737111
Validation loss: 2.551573073051242

Epoch: 6| Step: 9
Training loss: 2.3067954558138393
Validation loss: 2.5838738204207563

Epoch: 6| Step: 10
Training loss: 2.0109854833988527
Validation loss: 2.60000271858171

Epoch: 6| Step: 11
Training loss: 2.0483092895702413
Validation loss: 2.6088799408649637

Epoch: 6| Step: 12
Training loss: 2.4328082977043026
Validation loss: 2.6278454556687474

Epoch: 6| Step: 13
Training loss: 1.8786488949594138
Validation loss: 2.6263052253660217

Epoch: 244| Step: 0
Training loss: 2.1079074982429096
Validation loss: 2.622501046659626

Epoch: 6| Step: 1
Training loss: 2.535529392801001
Validation loss: 2.6359923918744026

Epoch: 6| Step: 2
Training loss: 2.941769520489688
Validation loss: 2.6456158290781886

Epoch: 6| Step: 3
Training loss: 1.9206252337727776
Validation loss: 2.650605701105533

Epoch: 6| Step: 4
Training loss: 1.9815945106162347
Validation loss: 2.6367933323990753

Epoch: 6| Step: 5
Training loss: 1.963513631308546
Validation loss: 2.6146034199423087

Epoch: 6| Step: 6
Training loss: 2.133451373093031
Validation loss: 2.5887976711076854

Epoch: 6| Step: 7
Training loss: 1.964972732587715
Validation loss: 2.5665018730600164

Epoch: 6| Step: 8
Training loss: 2.133058191477668
Validation loss: 2.5489746519334675

Epoch: 6| Step: 9
Training loss: 2.603386683322397
Validation loss: 2.563665202632624

Epoch: 6| Step: 10
Training loss: 2.340786497200476
Validation loss: 2.567331782980528

Epoch: 6| Step: 11
Training loss: 1.7321974685329804
Validation loss: 2.567632033095897

Epoch: 6| Step: 12
Training loss: 1.7347737446770826
Validation loss: 2.5824735092473565

Epoch: 6| Step: 13
Training loss: 2.8791964215196235
Validation loss: 2.595621911915149

Epoch: 245| Step: 0
Training loss: 2.481863419739435
Validation loss: 2.577865140515172

Epoch: 6| Step: 1
Training loss: 2.161577581463602
Validation loss: 2.563250517067472

Epoch: 6| Step: 2
Training loss: 2.0686739213213685
Validation loss: 2.572628319113045

Epoch: 6| Step: 3
Training loss: 2.568796563016528
Validation loss: 2.575877495046395

Epoch: 6| Step: 4
Training loss: 2.3625248983373006
Validation loss: 2.5685387300978935

Epoch: 6| Step: 5
Training loss: 2.14417256897718
Validation loss: 2.561667400100229

Epoch: 6| Step: 6
Training loss: 2.6310103499855253
Validation loss: 2.578843034109875

Epoch: 6| Step: 7
Training loss: 1.8891214113854504
Validation loss: 2.5967105836382367

Epoch: 6| Step: 8
Training loss: 1.7986902770200557
Validation loss: 2.5975806815645095

Epoch: 6| Step: 9
Training loss: 1.5913300935616108
Validation loss: 2.5803873327817635

Epoch: 6| Step: 10
Training loss: 2.1544857824232255
Validation loss: 2.5952118044309382

Epoch: 6| Step: 11
Training loss: 2.6602995577622512
Validation loss: 2.6351748017510896

Epoch: 6| Step: 12
Training loss: 2.1640407960540124
Validation loss: 2.658316223743191

Epoch: 6| Step: 13
Training loss: 2.358233042854675
Validation loss: 2.662145571930217

Epoch: 246| Step: 0
Training loss: 2.4283325735006756
Validation loss: 2.6642079542021584

Epoch: 6| Step: 1
Training loss: 1.9535576913290351
Validation loss: 2.6521775685659255

Epoch: 6| Step: 2
Training loss: 2.8383207369345858
Validation loss: 2.6344354685174576

Epoch: 6| Step: 3
Training loss: 2.0589221786458385
Validation loss: 2.6345986213664836

Epoch: 6| Step: 4
Training loss: 2.2194134432214074
Validation loss: 2.6374134344807367

Epoch: 6| Step: 5
Training loss: 1.9349588526803774
Validation loss: 2.641836990517402

Epoch: 6| Step: 6
Training loss: 2.573568861202204
Validation loss: 2.6535238899960683

Epoch: 6| Step: 7
Training loss: 2.4076760760257288
Validation loss: 2.6291293710359636

Epoch: 6| Step: 8
Training loss: 1.8009006684068563
Validation loss: 2.593543798990349

Epoch: 6| Step: 9
Training loss: 1.361554689312714
Validation loss: 2.5883417237787114

Epoch: 6| Step: 10
Training loss: 2.134908352030556
Validation loss: 2.573255382795963

Epoch: 6| Step: 11
Training loss: 2.5626859830028432
Validation loss: 2.5344099563715337

Epoch: 6| Step: 12
Training loss: 2.206311890163593
Validation loss: 2.5486115228396806

Epoch: 6| Step: 13
Training loss: 2.1046630223584737
Validation loss: 2.545449675221449

Epoch: 247| Step: 0
Training loss: 2.006593089016838
Validation loss: 2.5658536071158093

Epoch: 6| Step: 1
Training loss: 2.0257580974651934
Validation loss: 2.553408754752087

Epoch: 6| Step: 2
Training loss: 1.7822632166607473
Validation loss: 2.5774253589467477

Epoch: 6| Step: 3
Training loss: 2.3397420564947273
Validation loss: 2.593890848893239

Epoch: 6| Step: 4
Training loss: 2.5967639738694634
Validation loss: 2.615013183477854

Epoch: 6| Step: 5
Training loss: 2.8098991236109145
Validation loss: 2.6416554894998074

Epoch: 6| Step: 6
Training loss: 2.654794271655884
Validation loss: 2.6502943403295594

Epoch: 6| Step: 7
Training loss: 1.666492031802846
Validation loss: 2.665543764344133

Epoch: 6| Step: 8
Training loss: 2.2446150448404123
Validation loss: 2.652345907353688

Epoch: 6| Step: 9
Training loss: 2.339609379565357
Validation loss: 2.6452470465259257

Epoch: 6| Step: 10
Training loss: 2.754389813761804
Validation loss: 2.6374065114427174

Epoch: 6| Step: 11
Training loss: 1.6212131686060052
Validation loss: 2.6325101065615266

Epoch: 6| Step: 12
Training loss: 2.5454640605055094
Validation loss: 2.6241871695526653

Epoch: 6| Step: 13
Training loss: 1.66018123832297
Validation loss: 2.582010019958599

Epoch: 248| Step: 0
Training loss: 1.7054565988440666
Validation loss: 2.588525819378142

Epoch: 6| Step: 1
Training loss: 2.462166615492105
Validation loss: 2.570119941401311

Epoch: 6| Step: 2
Training loss: 2.8959481378938063
Validation loss: 2.5828002923245026

Epoch: 6| Step: 3
Training loss: 2.24597974404961
Validation loss: 2.5727920862428455

Epoch: 6| Step: 4
Training loss: 1.4127847789533092
Validation loss: 2.6049942125877283

Epoch: 6| Step: 5
Training loss: 2.3553506242729423
Validation loss: 2.5823235589187066

Epoch: 6| Step: 6
Training loss: 2.1004253274620113
Validation loss: 2.6211098956138112

Epoch: 6| Step: 7
Training loss: 1.3270221843834278
Validation loss: 2.6194215567451766

Epoch: 6| Step: 8
Training loss: 2.3683205086855015
Validation loss: 2.588757056339163

Epoch: 6| Step: 9
Training loss: 2.40375429007256
Validation loss: 2.624508524101738

Epoch: 6| Step: 10
Training loss: 2.4812794719646485
Validation loss: 2.588080479597396

Epoch: 6| Step: 11
Training loss: 2.3891920395155704
Validation loss: 2.58773619760842

Epoch: 6| Step: 12
Training loss: 2.230154038655808
Validation loss: 2.6057720932343384

Epoch: 6| Step: 13
Training loss: 1.980118459086418
Validation loss: 2.6423306420923165

Epoch: 249| Step: 0
Training loss: 1.6739239837724071
Validation loss: 2.641887498423981

Epoch: 6| Step: 1
Training loss: 1.6971116605224448
Validation loss: 2.665681348997381

Epoch: 6| Step: 2
Training loss: 2.1140002369082054
Validation loss: 2.639285099390316

Epoch: 6| Step: 3
Training loss: 2.7032214020754783
Validation loss: 2.623137297578382

Epoch: 6| Step: 4
Training loss: 2.075936907932255
Validation loss: 2.6392565008287368

Epoch: 6| Step: 5
Training loss: 2.3228913948725727
Validation loss: 2.613988190556405

Epoch: 6| Step: 6
Training loss: 2.81507340425286
Validation loss: 2.591930287273344

Epoch: 6| Step: 7
Training loss: 2.589306069279983
Validation loss: 2.604968906175526

Epoch: 6| Step: 8
Training loss: 1.2520114926733918
Validation loss: 2.5783126608626645

Epoch: 6| Step: 9
Training loss: 2.4276705401276772
Validation loss: 2.543342668317043

Epoch: 6| Step: 10
Training loss: 2.141347832702314
Validation loss: 2.5341347711854207

Epoch: 6| Step: 11
Training loss: 2.3332025854626446
Validation loss: 2.5172159246619294

Epoch: 6| Step: 12
Training loss: 2.522905323140615
Validation loss: 2.5224326763866416

Epoch: 6| Step: 13
Training loss: 2.1833231695195825
Validation loss: 2.548316547603806

Epoch: 250| Step: 0
Training loss: 2.7312742254025215
Validation loss: 2.572102272371409

Epoch: 6| Step: 1
Training loss: 1.779364943641729
Validation loss: 2.596259538513303

Epoch: 6| Step: 2
Training loss: 2.2016042235666613
Validation loss: 2.5999414474056417

Epoch: 6| Step: 3
Training loss: 2.114617395987935
Validation loss: 2.599157189436212

Epoch: 6| Step: 4
Training loss: 2.1043222451685555
Validation loss: 2.6155564117250183

Epoch: 6| Step: 5
Training loss: 1.909450845413842
Validation loss: 2.5779060964417484

Epoch: 6| Step: 6
Training loss: 1.7830333148370638
Validation loss: 2.581370720799807

Epoch: 6| Step: 7
Training loss: 2.879047861330129
Validation loss: 2.5915757530269428

Epoch: 6| Step: 8
Training loss: 1.8900274798499657
Validation loss: 2.59712997880167

Epoch: 6| Step: 9
Training loss: 2.6584644735709313
Validation loss: 2.5887421671676574

Epoch: 6| Step: 10
Training loss: 2.5953413895681936
Validation loss: 2.5981730088138946

Epoch: 6| Step: 11
Training loss: 1.6664362350749213
Validation loss: 2.5970346113319036

Epoch: 6| Step: 12
Training loss: 2.0129035497717207
Validation loss: 2.6014313535884166

Epoch: 6| Step: 13
Training loss: 2.2988586164476335
Validation loss: 2.6070793850831095

Epoch: 251| Step: 0
Training loss: 2.252681194304109
Validation loss: 2.5971040908503746

Epoch: 6| Step: 1
Training loss: 2.552057434781032
Validation loss: 2.5770143524863682

Epoch: 6| Step: 2
Training loss: 2.641921227481394
Validation loss: 2.587767968300018

Epoch: 6| Step: 3
Training loss: 2.352927385317833
Validation loss: 2.568972824963669

Epoch: 6| Step: 4
Training loss: 2.0140569930966827
Validation loss: 2.5591748846781917

Epoch: 6| Step: 5
Training loss: 2.552439596001314
Validation loss: 2.5581270059105026

Epoch: 6| Step: 6
Training loss: 2.7500495906173206
Validation loss: 2.5454507133374538

Epoch: 6| Step: 7
Training loss: 2.3053846436337992
Validation loss: 2.540575189168637

Epoch: 6| Step: 8
Training loss: 1.8228099537450204
Validation loss: 2.548082326856548

Epoch: 6| Step: 9
Training loss: 2.1179528911563907
Validation loss: 2.551589253665524

Epoch: 6| Step: 10
Training loss: 1.5731242045058376
Validation loss: 2.5782915003793394

Epoch: 6| Step: 11
Training loss: 2.106877409538401
Validation loss: 2.5893860225947765

Epoch: 6| Step: 12
Training loss: 2.000704164520748
Validation loss: 2.6450607393305976

Epoch: 6| Step: 13
Training loss: 2.3925454398277632
Validation loss: 2.687937013447281

Epoch: 252| Step: 0
Training loss: 2.2805626238600984
Validation loss: 2.7208312534559944

Epoch: 6| Step: 1
Training loss: 2.1504204494199377
Validation loss: 2.7325061915060798

Epoch: 6| Step: 2
Training loss: 1.8792315734796219
Validation loss: 2.7066824992504492

Epoch: 6| Step: 3
Training loss: 1.7507630455776286
Validation loss: 2.6677577995134087

Epoch: 6| Step: 4
Training loss: 1.6143074374178052
Validation loss: 2.6089757739543713

Epoch: 6| Step: 5
Training loss: 2.5815480020963557
Validation loss: 2.5623193227448504

Epoch: 6| Step: 6
Training loss: 2.9553303229605414
Validation loss: 2.517010017261418

Epoch: 6| Step: 7
Training loss: 2.6127670078631064
Validation loss: 2.5150485750617713

Epoch: 6| Step: 8
Training loss: 2.167858224061843
Validation loss: 2.4996915468028273

Epoch: 6| Step: 9
Training loss: 2.751726388897386
Validation loss: 2.4912197581929707

Epoch: 6| Step: 10
Training loss: 2.0035917693432292
Validation loss: 2.4900471535907114

Epoch: 6| Step: 11
Training loss: 2.4987042884023167
Validation loss: 2.488722374349381

Epoch: 6| Step: 12
Training loss: 2.4357925694913667
Validation loss: 2.517455230941136

Epoch: 6| Step: 13
Training loss: 1.9321023140504823
Validation loss: 2.4955428763784893

Epoch: 253| Step: 0
Training loss: 2.193065864850676
Validation loss: 2.4936491089364092

Epoch: 6| Step: 1
Training loss: 2.527685033286869
Validation loss: 2.509497990173358

Epoch: 6| Step: 2
Training loss: 2.504071924974268
Validation loss: 2.529421518757526

Epoch: 6| Step: 3
Training loss: 3.1248886088545658
Validation loss: 2.55981386712534

Epoch: 6| Step: 4
Training loss: 1.9924851139139537
Validation loss: 2.5848913544869627

Epoch: 6| Step: 5
Training loss: 2.71340328944922
Validation loss: 2.6322803959506453

Epoch: 6| Step: 6
Training loss: 1.9844290658388855
Validation loss: 2.6713027192505088

Epoch: 6| Step: 7
Training loss: 2.173921457979254
Validation loss: 2.6881429065899374

Epoch: 6| Step: 8
Training loss: 2.718842252722734
Validation loss: 2.6981706143805364

Epoch: 6| Step: 9
Training loss: 2.085358157053238
Validation loss: 2.670358833698206

Epoch: 6| Step: 10
Training loss: 2.198627832953853
Validation loss: 2.656978582054438

Epoch: 6| Step: 11
Training loss: 1.7837394584659714
Validation loss: 2.616458650893674

Epoch: 6| Step: 12
Training loss: 1.1289245181602032
Validation loss: 2.5949153044249584

Epoch: 6| Step: 13
Training loss: 2.2895772830326666
Validation loss: 2.586639908188455

Epoch: 254| Step: 0
Training loss: 2.392430041654599
Validation loss: 2.5525116282119433

Epoch: 6| Step: 1
Training loss: 2.1028192442424287
Validation loss: 2.5367169623666754

Epoch: 6| Step: 2
Training loss: 2.58758280524843
Validation loss: 2.524363565339556

Epoch: 6| Step: 3
Training loss: 2.802260855306672
Validation loss: 2.5439522633912155

Epoch: 6| Step: 4
Training loss: 2.334448400362248
Validation loss: 2.560924906580406

Epoch: 6| Step: 5
Training loss: 1.6207967830874574
Validation loss: 2.594233165304887

Epoch: 6| Step: 6
Training loss: 1.8939007840700428
Validation loss: 2.5953355255728487

Epoch: 6| Step: 7
Training loss: 3.1004795134294634
Validation loss: 2.597838767769472

Epoch: 6| Step: 8
Training loss: 2.2077903319890715
Validation loss: 2.6444147667524027

Epoch: 6| Step: 9
Training loss: 2.255161193871839
Validation loss: 2.6501696838178765

Epoch: 6| Step: 10
Training loss: 1.6646698752176154
Validation loss: 2.656953037946219

Epoch: 6| Step: 11
Training loss: 1.794455915039742
Validation loss: 2.6774389918833186

Epoch: 6| Step: 12
Training loss: 2.396133558840015
Validation loss: 2.6333124306810896

Epoch: 6| Step: 13
Training loss: 1.7309199793284082
Validation loss: 2.647774612454036

Epoch: 255| Step: 0
Training loss: 1.8167776732987384
Validation loss: 2.651028081613044

Epoch: 6| Step: 1
Training loss: 3.2383168843221832
Validation loss: 2.6083581736380173

Epoch: 6| Step: 2
Training loss: 2.706941060907415
Validation loss: 2.593954308058142

Epoch: 6| Step: 3
Training loss: 2.3627895884165477
Validation loss: 2.606606086049755

Epoch: 6| Step: 4
Training loss: 1.5750232089315686
Validation loss: 2.581591269999243

Epoch: 6| Step: 5
Training loss: 2.411241382921641
Validation loss: 2.61744383510314

Epoch: 6| Step: 6
Training loss: 2.2763225693423297
Validation loss: 2.619243455765126

Epoch: 6| Step: 7
Training loss: 2.4507363711410783
Validation loss: 2.6293846477298

Epoch: 6| Step: 8
Training loss: 2.1383106501449776
Validation loss: 2.6327291413193503

Epoch: 6| Step: 9
Training loss: 1.8646865759313924
Validation loss: 2.6168654817830665

Epoch: 6| Step: 10
Training loss: 1.9654282900534135
Validation loss: 2.617259435471675

Epoch: 6| Step: 11
Training loss: 2.2134837662847127
Validation loss: 2.602011480527958

Epoch: 6| Step: 12
Training loss: 1.7243398453605292
Validation loss: 2.622947829235371

Epoch: 6| Step: 13
Training loss: 1.3771817930556454
Validation loss: 2.6239835042580366

Epoch: 256| Step: 0
Training loss: 2.1916538581425518
Validation loss: 2.6094595311039406

Epoch: 6| Step: 1
Training loss: 2.618612237552399
Validation loss: 2.6108623993789104

Epoch: 6| Step: 2
Training loss: 1.9845427194439156
Validation loss: 2.581850785235993

Epoch: 6| Step: 3
Training loss: 1.6624105787966814
Validation loss: 2.5760817011894646

Epoch: 6| Step: 4
Training loss: 2.8184615636792887
Validation loss: 2.571140299008331

Epoch: 6| Step: 5
Training loss: 2.884323923107147
Validation loss: 2.5438162489628544

Epoch: 6| Step: 6
Training loss: 1.6291765679386208
Validation loss: 2.5514901749934236

Epoch: 6| Step: 7
Training loss: 2.4249339812425843
Validation loss: 2.555351474348577

Epoch: 6| Step: 8
Training loss: 2.5964949457129305
Validation loss: 2.5760154339207544

Epoch: 6| Step: 9
Training loss: 1.6607593114230959
Validation loss: 2.5735430296102164

Epoch: 6| Step: 10
Training loss: 1.9104295780767548
Validation loss: 2.577451814558134

Epoch: 6| Step: 11
Training loss: 1.6634260939659056
Validation loss: 2.588612689163894

Epoch: 6| Step: 12
Training loss: 1.8299319474537876
Validation loss: 2.595581151327213

Epoch: 6| Step: 13
Training loss: 2.2956050553923726
Validation loss: 2.6272381974107413

Epoch: 257| Step: 0
Training loss: 1.6014256860865763
Validation loss: 2.640936011182806

Epoch: 6| Step: 1
Training loss: 1.7523650808817566
Validation loss: 2.6704078795673922

Epoch: 6| Step: 2
Training loss: 2.476390748431276
Validation loss: 2.670407723324397

Epoch: 6| Step: 3
Training loss: 2.0574569313853486
Validation loss: 2.626166856367453

Epoch: 6| Step: 4
Training loss: 2.747388293118849
Validation loss: 2.5819867428912775

Epoch: 6| Step: 5
Training loss: 2.08146387782609
Validation loss: 2.5978575511366517

Epoch: 6| Step: 6
Training loss: 2.91599420333935
Validation loss: 2.5512642902034486

Epoch: 6| Step: 7
Training loss: 1.7465771852873435
Validation loss: 2.575121831635171

Epoch: 6| Step: 8
Training loss: 1.9354056452124928
Validation loss: 2.5594617463293843

Epoch: 6| Step: 9
Training loss: 1.9792405031050344
Validation loss: 2.565781314500542

Epoch: 6| Step: 10
Training loss: 2.1127103080122116
Validation loss: 2.579099220622438

Epoch: 6| Step: 11
Training loss: 2.2301752060970763
Validation loss: 2.6049757705069316

Epoch: 6| Step: 12
Training loss: 2.298326928690211
Validation loss: 2.623369073571825

Epoch: 6| Step: 13
Training loss: 2.518433513588501
Validation loss: 2.630459308295757

Epoch: 258| Step: 0
Training loss: 1.7984736090116533
Validation loss: 2.658090320429399

Epoch: 6| Step: 1
Training loss: 2.169327044054483
Validation loss: 2.66378547070816

Epoch: 6| Step: 2
Training loss: 2.3426501936176862
Validation loss: 2.6450999036885863

Epoch: 6| Step: 3
Training loss: 2.1430647931078743
Validation loss: 2.7073545203276588

Epoch: 6| Step: 4
Training loss: 2.7379257254324156
Validation loss: 2.6885199570447487

Epoch: 6| Step: 5
Training loss: 2.791164087253757
Validation loss: 2.721196940624232

Epoch: 6| Step: 6
Training loss: 1.9444453746551227
Validation loss: 2.727661902182229

Epoch: 6| Step: 7
Training loss: 1.6916082318866763
Validation loss: 2.7229124921918966

Epoch: 6| Step: 8
Training loss: 2.059523775923393
Validation loss: 2.7236555136610714

Epoch: 6| Step: 9
Training loss: 2.112298818184171
Validation loss: 2.636184781484047

Epoch: 6| Step: 10
Training loss: 1.718267754611628
Validation loss: 2.60886725322609

Epoch: 6| Step: 11
Training loss: 1.8070193331960878
Validation loss: 2.5684770796460286

Epoch: 6| Step: 12
Training loss: 2.497854647424594
Validation loss: 2.5503662768827104

Epoch: 6| Step: 13
Training loss: 2.873320379146868
Validation loss: 2.538511237920992

Epoch: 259| Step: 0
Training loss: 2.0301534186958343
Validation loss: 2.5341588327557916

Epoch: 6| Step: 1
Training loss: 2.6956609086126564
Validation loss: 2.5274591748757396

Epoch: 6| Step: 2
Training loss: 1.8249988399136134
Validation loss: 2.5300145686085727

Epoch: 6| Step: 3
Training loss: 1.6728900430666105
Validation loss: 2.5534367352739222

Epoch: 6| Step: 4
Training loss: 2.370265457803008
Validation loss: 2.5674736710126713

Epoch: 6| Step: 5
Training loss: 2.6172594658365895
Validation loss: 2.544414142697054

Epoch: 6| Step: 6
Training loss: 1.8619692359783984
Validation loss: 2.5973242373046115

Epoch: 6| Step: 7
Training loss: 2.535547258644151
Validation loss: 2.5860850896139658

Epoch: 6| Step: 8
Training loss: 2.749569252264443
Validation loss: 2.5957674813120195

Epoch: 6| Step: 9
Training loss: 1.9973771659313644
Validation loss: 2.6220065108528066

Epoch: 6| Step: 10
Training loss: 1.8879158218820815
Validation loss: 2.6477275785876873

Epoch: 6| Step: 11
Training loss: 2.5489065107079916
Validation loss: 2.6695472288858264

Epoch: 6| Step: 12
Training loss: 2.137103560420085
Validation loss: 2.665685910434229

Epoch: 6| Step: 13
Training loss: 2.0117398455356303
Validation loss: 2.641802327817292

Epoch: 260| Step: 0
Training loss: 1.4048109108556548
Validation loss: 2.640686260167391

Epoch: 6| Step: 1
Training loss: 2.1614871348718014
Validation loss: 2.627266072253526

Epoch: 6| Step: 2
Training loss: 2.460251582392201
Validation loss: 2.6110542665430843

Epoch: 6| Step: 3
Training loss: 1.6664147027611012
Validation loss: 2.599392617023703

Epoch: 6| Step: 4
Training loss: 2.242736749133863
Validation loss: 2.569907422210399

Epoch: 6| Step: 5
Training loss: 1.8219096499463823
Validation loss: 2.547978058951592

Epoch: 6| Step: 6
Training loss: 2.723305316984826
Validation loss: 2.5572341529195315

Epoch: 6| Step: 7
Training loss: 2.139331956141191
Validation loss: 2.568133310635822

Epoch: 6| Step: 8
Training loss: 2.6986367775514584
Validation loss: 2.578016012951444

Epoch: 6| Step: 9
Training loss: 2.496940648214933
Validation loss: 2.586490798564133

Epoch: 6| Step: 10
Training loss: 1.6139338099534215
Validation loss: 2.5981291911654436

Epoch: 6| Step: 11
Training loss: 2.094250633397211
Validation loss: 2.6173494810774494

Epoch: 6| Step: 12
Training loss: 2.594976112388079
Validation loss: 2.6376255915481597

Epoch: 6| Step: 13
Training loss: 2.633371356094062
Validation loss: 2.6275877307772255

Epoch: 261| Step: 0
Training loss: 2.0516446285267573
Validation loss: 2.6291495631448054

Epoch: 6| Step: 1
Training loss: 2.221150885728304
Validation loss: 2.592540681189347

Epoch: 6| Step: 2
Training loss: 1.7842526475743217
Validation loss: 2.587596165441059

Epoch: 6| Step: 3
Training loss: 2.1063479709196122
Validation loss: 2.5715418139756916

Epoch: 6| Step: 4
Training loss: 1.7612718239400684
Validation loss: 2.573199366020798

Epoch: 6| Step: 5
Training loss: 1.7249986980267462
Validation loss: 2.587438510772302

Epoch: 6| Step: 6
Training loss: 2.5989636336420987
Validation loss: 2.580091539454427

Epoch: 6| Step: 7
Training loss: 2.6464816723348745
Validation loss: 2.5969122335042374

Epoch: 6| Step: 8
Training loss: 1.975435802809838
Validation loss: 2.55798784609212

Epoch: 6| Step: 9
Training loss: 2.4217096087679915
Validation loss: 2.5793200718908604

Epoch: 6| Step: 10
Training loss: 2.7028868465582963
Validation loss: 2.573750493360055

Epoch: 6| Step: 11
Training loss: 2.574199485417293
Validation loss: 2.5958486439195716

Epoch: 6| Step: 12
Training loss: 1.7126026150664866
Validation loss: 2.6185775481550864

Epoch: 6| Step: 13
Training loss: 2.177299695618078
Validation loss: 2.6157671058423837

Epoch: 262| Step: 0
Training loss: 2.55062010461982
Validation loss: 2.62373999979174

Epoch: 6| Step: 1
Training loss: 2.247712562022691
Validation loss: 2.658092084439121

Epoch: 6| Step: 2
Training loss: 1.5584342702859288
Validation loss: 2.6681080191190953

Epoch: 6| Step: 3
Training loss: 2.219699280449918
Validation loss: 2.671822605028312

Epoch: 6| Step: 4
Training loss: 2.045941554960326
Validation loss: 2.711288260891522

Epoch: 6| Step: 5
Training loss: 2.598881436868637
Validation loss: 2.6900990656274746

Epoch: 6| Step: 6
Training loss: 2.265710342378368
Validation loss: 2.6289095148800308

Epoch: 6| Step: 7
Training loss: 2.790998113108769
Validation loss: 2.57665392588352

Epoch: 6| Step: 8
Training loss: 1.6074249897923194
Validation loss: 2.557462672299576

Epoch: 6| Step: 9
Training loss: 1.3214856415285
Validation loss: 2.5468193157326118

Epoch: 6| Step: 10
Training loss: 1.6585846766377763
Validation loss: 2.5219125145347934

Epoch: 6| Step: 11
Training loss: 2.004477019941641
Validation loss: 2.5328972327123807

Epoch: 6| Step: 12
Training loss: 2.239403035794601
Validation loss: 2.5310170258736

Epoch: 6| Step: 13
Training loss: 3.225333878141654
Validation loss: 2.566189768896211

Epoch: 263| Step: 0
Training loss: 2.4081662957189884
Validation loss: 2.604753738351332

Epoch: 6| Step: 1
Training loss: 1.7394529358499433
Validation loss: 2.67252771684948

Epoch: 6| Step: 2
Training loss: 2.715989739579833
Validation loss: 2.7015722441915826

Epoch: 6| Step: 3
Training loss: 2.2594154238217383
Validation loss: 2.706433647214861

Epoch: 6| Step: 4
Training loss: 1.6247074157233796
Validation loss: 2.6724224459246737

Epoch: 6| Step: 5
Training loss: 2.0541636448258256
Validation loss: 2.6211225997921335

Epoch: 6| Step: 6
Training loss: 1.977005980425189
Validation loss: 2.5905779856920326

Epoch: 6| Step: 7
Training loss: 1.6287495562888747
Validation loss: 2.5670300891095055

Epoch: 6| Step: 8
Training loss: 2.2585363580675186
Validation loss: 2.5291644166017817

Epoch: 6| Step: 9
Training loss: 2.1945895161809306
Validation loss: 2.530526972359301

Epoch: 6| Step: 10
Training loss: 3.1946549240282844
Validation loss: 2.5320914012116478

Epoch: 6| Step: 11
Training loss: 2.591435514324511
Validation loss: 2.5043622423454273

Epoch: 6| Step: 12
Training loss: 2.7368311722533196
Validation loss: 2.5339769031141444

Epoch: 6| Step: 13
Training loss: 2.042407219412536
Validation loss: 2.53361717650085

Epoch: 264| Step: 0
Training loss: 2.1421023651724016
Validation loss: 2.560553004890125

Epoch: 6| Step: 1
Training loss: 1.5518361690608544
Validation loss: 2.5647815223881385

Epoch: 6| Step: 2
Training loss: 2.512272466728583
Validation loss: 2.569693122606181

Epoch: 6| Step: 3
Training loss: 2.218133867707723
Validation loss: 2.6188269343641406

Epoch: 6| Step: 4
Training loss: 1.1706493835027887
Validation loss: 2.625335997316001

Epoch: 6| Step: 5
Training loss: 2.680369209791733
Validation loss: 2.635703939429128

Epoch: 6| Step: 6
Training loss: 2.0669083156617187
Validation loss: 2.6584472544145754

Epoch: 6| Step: 7
Training loss: 2.478696463310214
Validation loss: 2.648451963552105

Epoch: 6| Step: 8
Training loss: 2.7829848461554123
Validation loss: 2.6736405694392795

Epoch: 6| Step: 9
Training loss: 1.975917786405298
Validation loss: 2.662492977724083

Epoch: 6| Step: 10
Training loss: 1.9540805157810544
Validation loss: 2.6624704266787727

Epoch: 6| Step: 11
Training loss: 2.5101848088957097
Validation loss: 2.6790714278629135

Epoch: 6| Step: 12
Training loss: 2.385493936633734
Validation loss: 2.669106787626159

Epoch: 6| Step: 13
Training loss: 2.1149654199825982
Validation loss: 2.6269343454665837

Epoch: 265| Step: 0
Training loss: 2.138401742536161
Validation loss: 2.563817546146248

Epoch: 6| Step: 1
Training loss: 2.7862316479084943
Validation loss: 2.520198810470369

Epoch: 6| Step: 2
Training loss: 2.691809813607164
Validation loss: 2.5286180132596945

Epoch: 6| Step: 3
Training loss: 2.485816681213906
Validation loss: 2.514643728504895

Epoch: 6| Step: 4
Training loss: 2.4295283323694012
Validation loss: 2.525829067656631

Epoch: 6| Step: 5
Training loss: 1.7258255019931992
Validation loss: 2.5138404313458325

Epoch: 6| Step: 6
Training loss: 1.5918167955521159
Validation loss: 2.5450789626836654

Epoch: 6| Step: 7
Training loss: 2.572456184807412
Validation loss: 2.5725606190638817

Epoch: 6| Step: 8
Training loss: 1.7705137375797162
Validation loss: 2.5703436666993396

Epoch: 6| Step: 9
Training loss: 1.7960829606298379
Validation loss: 2.6037574268490924

Epoch: 6| Step: 10
Training loss: 2.6652206633001385
Validation loss: 2.6308809735932113

Epoch: 6| Step: 11
Training loss: 2.4541466401799115
Validation loss: 2.6521756657791506

Epoch: 6| Step: 12
Training loss: 1.4197693208917033
Validation loss: 2.64416238380692

Epoch: 6| Step: 13
Training loss: 2.5076633302050397
Validation loss: 2.6096774932897264

Epoch: 266| Step: 0
Training loss: 1.7807668733430675
Validation loss: 2.6161178452694984

Epoch: 6| Step: 1
Training loss: 2.4234579512165455
Validation loss: 2.590111321176609

Epoch: 6| Step: 2
Training loss: 2.2266423796663597
Validation loss: 2.5744793865603266

Epoch: 6| Step: 3
Training loss: 1.7424732196342583
Validation loss: 2.5831930573638022

Epoch: 6| Step: 4
Training loss: 3.375698158673503
Validation loss: 2.5820352820722268

Epoch: 6| Step: 5
Training loss: 2.5635358996108772
Validation loss: 2.590605004896453

Epoch: 6| Step: 6
Training loss: 1.9796056427926656
Validation loss: 2.6015475619233763

Epoch: 6| Step: 7
Training loss: 2.5886843748814043
Validation loss: 2.5928860493239276

Epoch: 6| Step: 8
Training loss: 1.6032919872977607
Validation loss: 2.627519246377818

Epoch: 6| Step: 9
Training loss: 1.8305456323632872
Validation loss: 2.6422108209093254

Epoch: 6| Step: 10
Training loss: 1.7001483347634625
Validation loss: 2.6364895794023075

Epoch: 6| Step: 11
Training loss: 1.9966389309077042
Validation loss: 2.6355790149807206

Epoch: 6| Step: 12
Training loss: 1.8719861285763513
Validation loss: 2.630219492872881

Epoch: 6| Step: 13
Training loss: 1.9365198671093535
Validation loss: 2.622574548525407

Epoch: 267| Step: 0
Training loss: 2.5982744212768827
Validation loss: 2.5998485368235635

Epoch: 6| Step: 1
Training loss: 1.952627011709274
Validation loss: 2.611622784466416

Epoch: 6| Step: 2
Training loss: 2.114925513432604
Validation loss: 2.6113868008709513

Epoch: 6| Step: 3
Training loss: 1.6301058736012117
Validation loss: 2.5899174882566784

Epoch: 6| Step: 4
Training loss: 2.4783014876836473
Validation loss: 2.580490506733279

Epoch: 6| Step: 5
Training loss: 1.7765804454262815
Validation loss: 2.57025650411752

Epoch: 6| Step: 6
Training loss: 2.607568720993675
Validation loss: 2.589005570062996

Epoch: 6| Step: 7
Training loss: 1.7493520627114327
Validation loss: 2.580449068258299

Epoch: 6| Step: 8
Training loss: 2.461588455572819
Validation loss: 2.5627990408605497

Epoch: 6| Step: 9
Training loss: 1.8583181246604161
Validation loss: 2.578043418132946

Epoch: 6| Step: 10
Training loss: 2.1807615853696896
Validation loss: 2.598880328356437

Epoch: 6| Step: 11
Training loss: 1.7554824645215907
Validation loss: 2.5903377838502335

Epoch: 6| Step: 12
Training loss: 2.382080265790739
Validation loss: 2.6124343754315205

Epoch: 6| Step: 13
Training loss: 2.2180833486611062
Validation loss: 2.6340273385237936

Epoch: 268| Step: 0
Training loss: 2.2016249074544416
Validation loss: 2.635155907397263

Epoch: 6| Step: 1
Training loss: 1.7582490506093003
Validation loss: 2.65255325231569

Epoch: 6| Step: 2
Training loss: 2.327798500464473
Validation loss: 2.6494113478252386

Epoch: 6| Step: 3
Training loss: 2.595960571289404
Validation loss: 2.6117131156986133

Epoch: 6| Step: 4
Training loss: 2.2018688760326333
Validation loss: 2.6067461945661554

Epoch: 6| Step: 5
Training loss: 2.016659256892608
Validation loss: 2.580486164271016

Epoch: 6| Step: 6
Training loss: 1.3155006893624472
Validation loss: 2.5415773271795534

Epoch: 6| Step: 7
Training loss: 2.097731377589999
Validation loss: 2.5465196857012318

Epoch: 6| Step: 8
Training loss: 2.3207403231690975
Validation loss: 2.533817182521245

Epoch: 6| Step: 9
Training loss: 2.276295965611476
Validation loss: 2.538353438528401

Epoch: 6| Step: 10
Training loss: 2.685861842325396
Validation loss: 2.5310868026179945

Epoch: 6| Step: 11
Training loss: 1.6965850413734953
Validation loss: 2.5851112420983027

Epoch: 6| Step: 12
Training loss: 2.1527969797023196
Validation loss: 2.6012018696482557

Epoch: 6| Step: 13
Training loss: 2.46479751374275
Validation loss: 2.63546664425551

Epoch: 269| Step: 0
Training loss: 2.488128705341768
Validation loss: 2.6556825368263466

Epoch: 6| Step: 1
Training loss: 1.7788317142463597
Validation loss: 2.6908891141356555

Epoch: 6| Step: 2
Training loss: 1.4640790647304476
Validation loss: 2.680144913228602

Epoch: 6| Step: 3
Training loss: 2.282458155270388
Validation loss: 2.637187729559874

Epoch: 6| Step: 4
Training loss: 2.736463174475628
Validation loss: 2.6425389082301924

Epoch: 6| Step: 5
Training loss: 2.379318326891884
Validation loss: 2.6263080244449464

Epoch: 6| Step: 6
Training loss: 2.2342860064089956
Validation loss: 2.5892482895800826

Epoch: 6| Step: 7
Training loss: 1.6754601088612937
Validation loss: 2.5849034142419867

Epoch: 6| Step: 8
Training loss: 1.653690736015813
Validation loss: 2.568814847178693

Epoch: 6| Step: 9
Training loss: 3.1499201688792846
Validation loss: 2.576641141247703

Epoch: 6| Step: 10
Training loss: 1.753025164965953
Validation loss: 2.595001692345667

Epoch: 6| Step: 11
Training loss: 1.9794252795526668
Validation loss: 2.571632672338806

Epoch: 6| Step: 12
Training loss: 2.160022917731882
Validation loss: 2.5809147854955663

Epoch: 6| Step: 13
Training loss: 1.9056249750774779
Validation loss: 2.576914524315278

Epoch: 270| Step: 0
Training loss: 2.330230580000451
Validation loss: 2.6198814078419668

Epoch: 6| Step: 1
Training loss: 2.440195207447892
Validation loss: 2.648756174965742

Epoch: 6| Step: 2
Training loss: 2.3288607874761103
Validation loss: 2.7002591356089316

Epoch: 6| Step: 3
Training loss: 1.3296405896026644
Validation loss: 2.727554840249859

Epoch: 6| Step: 4
Training loss: 2.2352212223768517
Validation loss: 2.7340517416110988

Epoch: 6| Step: 5
Training loss: 2.0549868521536614
Validation loss: 2.738099647700074

Epoch: 6| Step: 6
Training loss: 3.4371358505184855
Validation loss: 2.695716333773805

Epoch: 6| Step: 7
Training loss: 1.2918358763744089
Validation loss: 2.6761816314607025

Epoch: 6| Step: 8
Training loss: 1.8945755471625432
Validation loss: 2.666146582809336

Epoch: 6| Step: 9
Training loss: 2.7742961575175604
Validation loss: 2.6175353772706544

Epoch: 6| Step: 10
Training loss: 1.345784798013671
Validation loss: 2.563375943585821

Epoch: 6| Step: 11
Training loss: 2.1954282682581305
Validation loss: 2.5208724205412594

Epoch: 6| Step: 12
Training loss: 1.606034228011215
Validation loss: 2.521636477649181

Epoch: 6| Step: 13
Training loss: 2.1011517772149526
Validation loss: 2.5027667471439963

Epoch: 271| Step: 0
Training loss: 1.9973550234475497
Validation loss: 2.4855420872095975

Epoch: 6| Step: 1
Training loss: 2.299023512167083
Validation loss: 2.483639910247869

Epoch: 6| Step: 2
Training loss: 1.8853594383139265
Validation loss: 2.481324448257348

Epoch: 6| Step: 3
Training loss: 2.040515133761178
Validation loss: 2.4871042003790453

Epoch: 6| Step: 4
Training loss: 2.860393405346476
Validation loss: 2.508932780456374

Epoch: 6| Step: 5
Training loss: 2.398845327291103
Validation loss: 2.5137092609287985

Epoch: 6| Step: 6
Training loss: 2.2186648930090147
Validation loss: 2.52690465808604

Epoch: 6| Step: 7
Training loss: 2.165091700208677
Validation loss: 2.5421837661112394

Epoch: 6| Step: 8
Training loss: 1.3779439621259637
Validation loss: 2.5724453256257047

Epoch: 6| Step: 9
Training loss: 1.9357976510411328
Validation loss: 2.595985161906423

Epoch: 6| Step: 10
Training loss: 1.9479469324164405
Validation loss: 2.618269633055118

Epoch: 6| Step: 11
Training loss: 3.028878454238756
Validation loss: 2.617722444285016

Epoch: 6| Step: 12
Training loss: 1.530939187404982
Validation loss: 2.639510963690321

Epoch: 6| Step: 13
Training loss: 2.0886246307206515
Validation loss: 2.69967344275467

Epoch: 272| Step: 0
Training loss: 2.2743347075505387
Validation loss: 2.7119617267944363

Epoch: 6| Step: 1
Training loss: 1.4967089949203431
Validation loss: 2.7383651974480925

Epoch: 6| Step: 2
Training loss: 1.5133212169436652
Validation loss: 2.696565788167718

Epoch: 6| Step: 3
Training loss: 2.935672597420081
Validation loss: 2.6658540669770066

Epoch: 6| Step: 4
Training loss: 1.9793835437471021
Validation loss: 2.6699973158281147

Epoch: 6| Step: 5
Training loss: 1.8064406165681544
Validation loss: 2.6388289985776137

Epoch: 6| Step: 6
Training loss: 1.94484781743701
Validation loss: 2.6306057519586927

Epoch: 6| Step: 7
Training loss: 2.418316891555401
Validation loss: 2.595723485280774

Epoch: 6| Step: 8
Training loss: 1.5820020884899142
Validation loss: 2.6138574471532476

Epoch: 6| Step: 9
Training loss: 1.8892154956638474
Validation loss: 2.6304511131312447

Epoch: 6| Step: 10
Training loss: 2.2827198048909993
Validation loss: 2.6197947406687563

Epoch: 6| Step: 11
Training loss: 2.4498385629210344
Validation loss: 2.6577756502025314

Epoch: 6| Step: 12
Training loss: 2.8397126095386747
Validation loss: 2.6032344268476626

Epoch: 6| Step: 13
Training loss: 1.9642484760470291
Validation loss: 2.5827485058336173

Epoch: 273| Step: 0
Training loss: 1.6197679360502524
Validation loss: 2.544024832685298

Epoch: 6| Step: 1
Training loss: 1.6611057573074144
Validation loss: 2.540875660948371

Epoch: 6| Step: 2
Training loss: 2.7846079068543514
Validation loss: 2.5370352765804514

Epoch: 6| Step: 3
Training loss: 2.2074749795914927
Validation loss: 2.5394884740081336

Epoch: 6| Step: 4
Training loss: 2.68584737310272
Validation loss: 2.5439253344395087

Epoch: 6| Step: 5
Training loss: 1.7899840534288403
Validation loss: 2.519610846787549

Epoch: 6| Step: 6
Training loss: 2.1644855182222287
Validation loss: 2.5399427873570857

Epoch: 6| Step: 7
Training loss: 2.7472197610321007
Validation loss: 2.5557441664859923

Epoch: 6| Step: 8
Training loss: 1.9348340304855356
Validation loss: 2.5642077640202574

Epoch: 6| Step: 9
Training loss: 2.431220156920392
Validation loss: 2.5928176521702797

Epoch: 6| Step: 10
Training loss: 1.8643408747333567
Validation loss: 2.6204549406093895

Epoch: 6| Step: 11
Training loss: 1.7999549674652846
Validation loss: 2.6068636902775917

Epoch: 6| Step: 12
Training loss: 1.9469659358504294
Validation loss: 2.6458812519049544

Epoch: 6| Step: 13
Training loss: 2.2874067652311525
Validation loss: 2.6527702576651064

Epoch: 274| Step: 0
Training loss: 1.9394654180438706
Validation loss: 2.6599818474525456

Epoch: 6| Step: 1
Training loss: 2.1182838219659876
Validation loss: 2.6800364868565056

Epoch: 6| Step: 2
Training loss: 1.943628463134585
Validation loss: 2.6999070522416173

Epoch: 6| Step: 3
Training loss: 1.7215914733409672
Validation loss: 2.6915062607563582

Epoch: 6| Step: 4
Training loss: 2.5679638924362713
Validation loss: 2.704019754902872

Epoch: 6| Step: 5
Training loss: 2.4058449144109986
Validation loss: 2.6640749247718953

Epoch: 6| Step: 6
Training loss: 2.0184095207763937
Validation loss: 2.629474867476313

Epoch: 6| Step: 7
Training loss: 1.9011680526177672
Validation loss: 2.596848548237246

Epoch: 6| Step: 8
Training loss: 1.8945070245511386
Validation loss: 2.570951187259952

Epoch: 6| Step: 9
Training loss: 1.8400430429648593
Validation loss: 2.5884719368480185

Epoch: 6| Step: 10
Training loss: 2.7570888012797283
Validation loss: 2.566684167872455

Epoch: 6| Step: 11
Training loss: 2.3649694544813644
Validation loss: 2.5853670072947956

Epoch: 6| Step: 12
Training loss: 2.4990117026944585
Validation loss: 2.5838390644916007

Epoch: 6| Step: 13
Training loss: 1.7490759180865263
Validation loss: 2.5773335947216522

Epoch: 275| Step: 0
Training loss: 1.8028748231279543
Validation loss: 2.596165692609402

Epoch: 6| Step: 1
Training loss: 1.9642530277554644
Validation loss: 2.591089853164462

Epoch: 6| Step: 2
Training loss: 2.4965252570462457
Validation loss: 2.607089337921259

Epoch: 6| Step: 3
Training loss: 1.5212547902742568
Validation loss: 2.62620376052349

Epoch: 6| Step: 4
Training loss: 2.260342141137315
Validation loss: 2.638424500098984

Epoch: 6| Step: 5
Training loss: 1.9050621333965567
Validation loss: 2.619802991919689

Epoch: 6| Step: 6
Training loss: 2.269905414039114
Validation loss: 2.5983555667489564

Epoch: 6| Step: 7
Training loss: 1.5917845930316052
Validation loss: 2.614894701489124

Epoch: 6| Step: 8
Training loss: 1.861103056262348
Validation loss: 2.611633914380227

Epoch: 6| Step: 9
Training loss: 3.1093210186897116
Validation loss: 2.63279724116672

Epoch: 6| Step: 10
Training loss: 2.124403926049758
Validation loss: 2.6305551331772734

Epoch: 6| Step: 11
Training loss: 1.722808969522779
Validation loss: 2.6377220373719408

Epoch: 6| Step: 12
Training loss: 2.000422194741489
Validation loss: 2.6453612850142334

Epoch: 6| Step: 13
Training loss: 2.5100226719656815
Validation loss: 2.647102056775635

Epoch: 276| Step: 0
Training loss: 1.7741837464898031
Validation loss: 2.622357097643965

Epoch: 6| Step: 1
Training loss: 2.250897228638576
Validation loss: 2.621050861309061

Epoch: 6| Step: 2
Training loss: 1.763300014762768
Validation loss: 2.6111978495058774

Epoch: 6| Step: 3
Training loss: 3.0423429773664825
Validation loss: 2.61106650221936

Epoch: 6| Step: 4
Training loss: 1.3342147337820343
Validation loss: 2.6014713809807146

Epoch: 6| Step: 5
Training loss: 1.9800677072142225
Validation loss: 2.6046298695920123

Epoch: 6| Step: 6
Training loss: 1.9805512721458414
Validation loss: 2.595978082465394

Epoch: 6| Step: 7
Training loss: 1.74423275626277
Validation loss: 2.6060433047364158

Epoch: 6| Step: 8
Training loss: 2.0114804024838064
Validation loss: 2.5929717769300558

Epoch: 6| Step: 9
Training loss: 2.182867212504127
Validation loss: 2.575651658569795

Epoch: 6| Step: 10
Training loss: 1.8864344033110734
Validation loss: 2.592698860891921

Epoch: 6| Step: 11
Training loss: 1.5791918481649234
Validation loss: 2.6115927494383704

Epoch: 6| Step: 12
Training loss: 3.286103065662168
Validation loss: 2.621865603733617

Epoch: 6| Step: 13
Training loss: 2.160929039795837
Validation loss: 2.6734607742339884

Epoch: 277| Step: 0
Training loss: 1.9153439338931582
Validation loss: 2.7236409971949227

Epoch: 6| Step: 1
Training loss: 2.2865567081175255
Validation loss: 2.730051338914774

Epoch: 6| Step: 2
Training loss: 1.8524335269095764
Validation loss: 2.7001927813241604

Epoch: 6| Step: 3
Training loss: 2.7336117796454578
Validation loss: 2.6646992807063397

Epoch: 6| Step: 4
Training loss: 1.6860657707680662
Validation loss: 2.633396600816322

Epoch: 6| Step: 5
Training loss: 2.466316375689935
Validation loss: 2.604339377716008

Epoch: 6| Step: 6
Training loss: 2.2545348138851757
Validation loss: 2.5653636872091186

Epoch: 6| Step: 7
Training loss: 2.9973417266725924
Validation loss: 2.5518558374850646

Epoch: 6| Step: 8
Training loss: 2.044650667381481
Validation loss: 2.550486728242067

Epoch: 6| Step: 9
Training loss: 1.4637302082655503
Validation loss: 2.5731675775992793

Epoch: 6| Step: 10
Training loss: 1.5222058134439855
Validation loss: 2.5689994140224397

Epoch: 6| Step: 11
Training loss: 2.1825647539842827
Validation loss: 2.591939715713619

Epoch: 6| Step: 12
Training loss: 2.222232074185891
Validation loss: 2.5986283474415166

Epoch: 6| Step: 13
Training loss: 2.26842142042911
Validation loss: 2.640623450043654

Epoch: 278| Step: 0
Training loss: 2.103938124932604
Validation loss: 2.6929811060346895

Epoch: 6| Step: 1
Training loss: 2.565142501828602
Validation loss: 2.7384504555281075

Epoch: 6| Step: 2
Training loss: 2.446375996459303
Validation loss: 2.7273094371049353

Epoch: 6| Step: 3
Training loss: 1.9342388887849244
Validation loss: 2.7165626847273563

Epoch: 6| Step: 4
Training loss: 2.1034485249279298
Validation loss: 2.668988965046571

Epoch: 6| Step: 5
Training loss: 1.7795562722552627
Validation loss: 2.608072530689614

Epoch: 6| Step: 6
Training loss: 2.555637567927243
Validation loss: 2.557260024942609

Epoch: 6| Step: 7
Training loss: 2.342427503671103
Validation loss: 2.511837906529963

Epoch: 6| Step: 8
Training loss: 2.0606932384703436
Validation loss: 2.4953474701222693

Epoch: 6| Step: 9
Training loss: 1.721544248519153
Validation loss: 2.487203471402539

Epoch: 6| Step: 10
Training loss: 2.683484470857708
Validation loss: 2.478472000591876

Epoch: 6| Step: 11
Training loss: 2.085447561039642
Validation loss: 2.487531308435571

Epoch: 6| Step: 12
Training loss: 2.5927557820726563
Validation loss: 2.478184198135052

Epoch: 6| Step: 13
Training loss: 2.122973878618019
Validation loss: 2.4992241132272626

Epoch: 279| Step: 0
Training loss: 1.514772785131873
Validation loss: 2.518257233004037

Epoch: 6| Step: 1
Training loss: 2.053295635872301
Validation loss: 2.5552646245612247

Epoch: 6| Step: 2
Training loss: 1.752403788190734
Validation loss: 2.567579894242015

Epoch: 6| Step: 3
Training loss: 1.9803083907896355
Validation loss: 2.6138021865079004

Epoch: 6| Step: 4
Training loss: 2.069147437143662
Validation loss: 2.6360695122037208

Epoch: 6| Step: 5
Training loss: 2.2345375055292633
Validation loss: 2.646053505294799

Epoch: 6| Step: 6
Training loss: 1.745852596689559
Validation loss: 2.6746921374032717

Epoch: 6| Step: 7
Training loss: 2.771398520131173
Validation loss: 2.6550427105444205

Epoch: 6| Step: 8
Training loss: 2.2404338079412462
Validation loss: 2.64630521235877

Epoch: 6| Step: 9
Training loss: 2.065219935234476
Validation loss: 2.6316264543929897

Epoch: 6| Step: 10
Training loss: 1.619613081561786
Validation loss: 2.642690486544466

Epoch: 6| Step: 11
Training loss: 2.5207938409239143
Validation loss: 2.5938394217032927

Epoch: 6| Step: 12
Training loss: 2.043410069371512
Validation loss: 2.62278127000156

Epoch: 6| Step: 13
Training loss: 2.8012082081732355
Validation loss: 2.6067829163557428

Epoch: 280| Step: 0
Training loss: 2.010478583718215
Validation loss: 2.600050631054604

Epoch: 6| Step: 1
Training loss: 1.660286285693168
Validation loss: 2.635822676995785

Epoch: 6| Step: 2
Training loss: 1.627125450432545
Validation loss: 2.6574847623879267

Epoch: 6| Step: 3
Training loss: 1.333587095828403
Validation loss: 2.669346823502305

Epoch: 6| Step: 4
Training loss: 1.8397965799752092
Validation loss: 2.6875033711257017

Epoch: 6| Step: 5
Training loss: 1.6668696120997153
Validation loss: 2.674445754117671

Epoch: 6| Step: 6
Training loss: 1.7294695791859394
Validation loss: 2.6913945124443575

Epoch: 6| Step: 7
Training loss: 2.362839939748688
Validation loss: 2.6439005983955544

Epoch: 6| Step: 8
Training loss: 2.850181098671986
Validation loss: 2.667678765119791

Epoch: 6| Step: 9
Training loss: 2.151739406030866
Validation loss: 2.6484597504317837

Epoch: 6| Step: 10
Training loss: 2.529096087288459
Validation loss: 2.635069131867235

Epoch: 6| Step: 11
Training loss: 2.129143545942193
Validation loss: 2.6310992151641552

Epoch: 6| Step: 12
Training loss: 3.076106925157583
Validation loss: 2.622005495469624

Epoch: 6| Step: 13
Training loss: 2.026219521163271
Validation loss: 2.609413953783515

Epoch: 281| Step: 0
Training loss: 1.9274113625061966
Validation loss: 2.6234698604294167

Epoch: 6| Step: 1
Training loss: 2.3273466716541855
Validation loss: 2.589795863503326

Epoch: 6| Step: 2
Training loss: 2.253920318718278
Validation loss: 2.59660912540163

Epoch: 6| Step: 3
Training loss: 2.210547530758429
Validation loss: 2.584238913972693

Epoch: 6| Step: 4
Training loss: 2.0691737083943083
Validation loss: 2.58184914612844

Epoch: 6| Step: 5
Training loss: 2.41662234780901
Validation loss: 2.555789845779379

Epoch: 6| Step: 6
Training loss: 1.9011284237926804
Validation loss: 2.537118020457749

Epoch: 6| Step: 7
Training loss: 2.1093885633244494
Validation loss: 2.5520602841536615

Epoch: 6| Step: 8
Training loss: 2.2904772243737233
Validation loss: 2.551214067504176

Epoch: 6| Step: 9
Training loss: 2.0471475434309063
Validation loss: 2.5717412036997356

Epoch: 6| Step: 10
Training loss: 2.2049940040835563
Validation loss: 2.560354559703569

Epoch: 6| Step: 11
Training loss: 1.422923780714862
Validation loss: 2.569484496162467

Epoch: 6| Step: 12
Training loss: 2.2112378027683603
Validation loss: 2.5657380897294844

Epoch: 6| Step: 13
Training loss: 2.3015058895071365
Validation loss: 2.574119369139825

Epoch: 282| Step: 0
Training loss: 1.810944777861643
Validation loss: 2.6254298751281655

Epoch: 6| Step: 1
Training loss: 2.2752040017016344
Validation loss: 2.617395072031365

Epoch: 6| Step: 2
Training loss: 2.18293383731437
Validation loss: 2.6056449331093163

Epoch: 6| Step: 3
Training loss: 1.5474648169984422
Validation loss: 2.616838422431109

Epoch: 6| Step: 4
Training loss: 1.7752936644143322
Validation loss: 2.5950917905891795

Epoch: 6| Step: 5
Training loss: 2.3615891128581135
Validation loss: 2.563452427341741

Epoch: 6| Step: 6
Training loss: 2.5751664265302567
Validation loss: 2.5729863598814484

Epoch: 6| Step: 7
Training loss: 2.459521367565939
Validation loss: 2.587706038891673

Epoch: 6| Step: 8
Training loss: 2.5371742152150394
Validation loss: 2.5944919444216596

Epoch: 6| Step: 9
Training loss: 1.9031543297222322
Validation loss: 2.6332801833603594

Epoch: 6| Step: 10
Training loss: 1.7151536248802022
Validation loss: 2.704285638912504

Epoch: 6| Step: 11
Training loss: 1.991641699130354
Validation loss: 2.7121204356765087

Epoch: 6| Step: 12
Training loss: 1.860057160719476
Validation loss: 2.7494831972308833

Epoch: 6| Step: 13
Training loss: 1.843344821698683
Validation loss: 2.785105786394711

Epoch: 283| Step: 0
Training loss: 1.3534384701359157
Validation loss: 2.777778630786341

Epoch: 6| Step: 1
Training loss: 2.4526325873602723
Validation loss: 2.79391542410039

Epoch: 6| Step: 2
Training loss: 2.0618616908147747
Validation loss: 2.738764656267947

Epoch: 6| Step: 3
Training loss: 2.130444899825247
Validation loss: 2.703954345251869

Epoch: 6| Step: 4
Training loss: 1.889039186344843
Validation loss: 2.651959668133292

Epoch: 6| Step: 5
Training loss: 2.715554914020033
Validation loss: 2.5975110924110343

Epoch: 6| Step: 6
Training loss: 1.9206252337727776
Validation loss: 2.553098707557867

Epoch: 6| Step: 7
Training loss: 2.5364913363858643
Validation loss: 2.5452691068437647

Epoch: 6| Step: 8
Training loss: 2.3999317993964224
Validation loss: 2.51606836617562

Epoch: 6| Step: 9
Training loss: 1.9715493297514912
Validation loss: 2.527263421929707

Epoch: 6| Step: 10
Training loss: 2.1685783560161345
Validation loss: 2.531610965501067

Epoch: 6| Step: 11
Training loss: 2.3791251246293412
Validation loss: 2.538909484947614

Epoch: 6| Step: 12
Training loss: 1.335372716187393
Validation loss: 2.5711964456423675

Epoch: 6| Step: 13
Training loss: 2.2631941810533105
Validation loss: 2.5588703035176694

Epoch: 284| Step: 0
Training loss: 1.3510401603947195
Validation loss: 2.569015438476439

Epoch: 6| Step: 1
Training loss: 1.6327435054530148
Validation loss: 2.597545420641482

Epoch: 6| Step: 2
Training loss: 1.7636024571272513
Validation loss: 2.6095292432201074

Epoch: 6| Step: 3
Training loss: 2.130177865280722
Validation loss: 2.6710627698817175

Epoch: 6| Step: 4
Training loss: 1.5609570323497188
Validation loss: 2.6304531373770192

Epoch: 6| Step: 5
Training loss: 1.4749386047258277
Validation loss: 2.6217284933448317

Epoch: 6| Step: 6
Training loss: 2.8688140330097474
Validation loss: 2.6095671897054653

Epoch: 6| Step: 7
Training loss: 2.413373830395792
Validation loss: 2.608218654471882

Epoch: 6| Step: 8
Training loss: 2.7305454139697924
Validation loss: 2.610803422542429

Epoch: 6| Step: 9
Training loss: 1.7624757751531535
Validation loss: 2.580599420072251

Epoch: 6| Step: 10
Training loss: 2.5500487229423445
Validation loss: 2.57524127940879

Epoch: 6| Step: 11
Training loss: 2.342254975653095
Validation loss: 2.585512400987706

Epoch: 6| Step: 12
Training loss: 2.838735162048666
Validation loss: 2.570050930639198

Epoch: 6| Step: 13
Training loss: 1.4757382145791849
Validation loss: 2.5450575883366633

Epoch: 285| Step: 0
Training loss: 2.1058917638021213
Validation loss: 2.5343974446824866

Epoch: 6| Step: 1
Training loss: 1.7596608934133728
Validation loss: 2.5401284195883655

Epoch: 6| Step: 2
Training loss: 1.6076413789221327
Validation loss: 2.525466953195052

Epoch: 6| Step: 3
Training loss: 1.4488781634195755
Validation loss: 2.533714915281866

Epoch: 6| Step: 4
Training loss: 2.2237133334880355
Validation loss: 2.508559974198301

Epoch: 6| Step: 5
Training loss: 2.077069236633563
Validation loss: 2.5702034754177814

Epoch: 6| Step: 6
Training loss: 2.939229253310402
Validation loss: 2.5591211217116947

Epoch: 6| Step: 7
Training loss: 1.6497157054237932
Validation loss: 2.5915439983501583

Epoch: 6| Step: 8
Training loss: 1.9862510643698719
Validation loss: 2.613331701592825

Epoch: 6| Step: 9
Training loss: 3.2852632230744088
Validation loss: 2.6495688618517077

Epoch: 6| Step: 10
Training loss: 2.249038278826411
Validation loss: 2.6363500417360832

Epoch: 6| Step: 11
Training loss: 2.1437344208532174
Validation loss: 2.6156576363469353

Epoch: 6| Step: 12
Training loss: 1.5243522049879694
Validation loss: 2.6034358003536227

Epoch: 6| Step: 13
Training loss: 1.9211518702765256
Validation loss: 2.5945397519021443

Epoch: 286| Step: 0
Training loss: 1.7340442238946396
Validation loss: 2.584893898646466

Epoch: 6| Step: 1
Training loss: 1.4535464424243292
Validation loss: 2.5548375792365943

Epoch: 6| Step: 2
Training loss: 1.3743742472606226
Validation loss: 2.572909788876709

Epoch: 6| Step: 3
Training loss: 1.8734393936669433
Validation loss: 2.549100609412214

Epoch: 6| Step: 4
Training loss: 2.4479211901900246
Validation loss: 2.5423750333229123

Epoch: 6| Step: 5
Training loss: 2.731494716269787
Validation loss: 2.5255448367304463

Epoch: 6| Step: 6
Training loss: 2.7188773289822605
Validation loss: 2.5302581178100048

Epoch: 6| Step: 7
Training loss: 3.0155924266577903
Validation loss: 2.5378705322635144

Epoch: 6| Step: 8
Training loss: 2.177467993622577
Validation loss: 2.552797946658853

Epoch: 6| Step: 9
Training loss: 1.9527336033611449
Validation loss: 2.550519071992143

Epoch: 6| Step: 10
Training loss: 2.5757737043627156
Validation loss: 2.612398493618507

Epoch: 6| Step: 11
Training loss: 1.91398720106591
Validation loss: 2.644012099696688

Epoch: 6| Step: 12
Training loss: 1.2005400197557075
Validation loss: 2.6830318701163196

Epoch: 6| Step: 13
Training loss: 1.9381895991547702
Validation loss: 2.6737669256696197

Epoch: 287| Step: 0
Training loss: 2.1632456425594597
Validation loss: 2.6809130091552156

Epoch: 6| Step: 1
Training loss: 2.2161594365050212
Validation loss: 2.676213213355814

Epoch: 6| Step: 2
Training loss: 1.667743462171336
Validation loss: 2.689611788086264

Epoch: 6| Step: 3
Training loss: 1.6638879102358366
Validation loss: 2.6816073733030388

Epoch: 6| Step: 4
Training loss: 1.713638542551974
Validation loss: 2.663512425765045

Epoch: 6| Step: 5
Training loss: 2.1970174556033526
Validation loss: 2.630258485422937

Epoch: 6| Step: 6
Training loss: 2.4466630904806475
Validation loss: 2.6466429715653295

Epoch: 6| Step: 7
Training loss: 2.3934315681309304
Validation loss: 2.625661660622291

Epoch: 6| Step: 8
Training loss: 2.423828518457865
Validation loss: 2.580361430852385

Epoch: 6| Step: 9
Training loss: 1.9975506566276253
Validation loss: 2.5658854164601808

Epoch: 6| Step: 10
Training loss: 2.45373683030048
Validation loss: 2.5640333596696236

Epoch: 6| Step: 11
Training loss: 2.645749598902737
Validation loss: 2.552002969112283

Epoch: 6| Step: 12
Training loss: 1.5253112225252665
Validation loss: 2.5435077430032824

Epoch: 6| Step: 13
Training loss: 1.6203463014702235
Validation loss: 2.5667169267720666

Epoch: 288| Step: 0
Training loss: 2.69599724516459
Validation loss: 2.5617062339465324

Epoch: 6| Step: 1
Training loss: 1.6836731221547239
Validation loss: 2.5650555265562405

Epoch: 6| Step: 2
Training loss: 1.9614040837928919
Validation loss: 2.575709743276619

Epoch: 6| Step: 3
Training loss: 2.033149887106197
Validation loss: 2.557132977588096

Epoch: 6| Step: 4
Training loss: 2.4666395220250994
Validation loss: 2.568726163136318

Epoch: 6| Step: 5
Training loss: 2.091545766652082
Validation loss: 2.572467769943616

Epoch: 6| Step: 6
Training loss: 2.1037919368632534
Validation loss: 2.583863855051707

Epoch: 6| Step: 7
Training loss: 1.9847472434946705
Validation loss: 2.597269221564545

Epoch: 6| Step: 8
Training loss: 2.2911625625567305
Validation loss: 2.5808277643784363

Epoch: 6| Step: 9
Training loss: 1.6046526614440255
Validation loss: 2.5875376641792567

Epoch: 6| Step: 10
Training loss: 2.1409563239754927
Validation loss: 2.5486910377555905

Epoch: 6| Step: 11
Training loss: 2.366604270470721
Validation loss: 2.592898922438126

Epoch: 6| Step: 12
Training loss: 1.5202601236571829
Validation loss: 2.5872270993048483

Epoch: 6| Step: 13
Training loss: 2.1852463148238956
Validation loss: 2.598698216317319

Epoch: 289| Step: 0
Training loss: 1.8872085472584468
Validation loss: 2.5614559713949756

Epoch: 6| Step: 1
Training loss: 2.4376169812423796
Validation loss: 2.5786398556575216

Epoch: 6| Step: 2
Training loss: 1.712065999523632
Validation loss: 2.5800135467479217

Epoch: 6| Step: 3
Training loss: 2.384880594267473
Validation loss: 2.584215526280879

Epoch: 6| Step: 4
Training loss: 1.7533209488918444
Validation loss: 2.6064847064432755

Epoch: 6| Step: 5
Training loss: 1.9870680309604192
Validation loss: 2.6047713734761935

Epoch: 6| Step: 6
Training loss: 1.7028824519761818
Validation loss: 2.592308026608867

Epoch: 6| Step: 7
Training loss: 3.163379887545479
Validation loss: 2.6058057484164516

Epoch: 6| Step: 8
Training loss: 2.4341146973892553
Validation loss: 2.6577551298623336

Epoch: 6| Step: 9
Training loss: 2.0930871625996033
Validation loss: 2.6584524859408885

Epoch: 6| Step: 10
Training loss: 1.604641963680373
Validation loss: 2.6710372563282987

Epoch: 6| Step: 11
Training loss: 2.170334633370367
Validation loss: 2.6634382335007327

Epoch: 6| Step: 12
Training loss: 1.2644766790336897
Validation loss: 2.618146502407348

Epoch: 6| Step: 13
Training loss: 2.369153103713014
Validation loss: 2.5817844659597875

Epoch: 290| Step: 0
Training loss: 1.989217841112437
Validation loss: 2.55739718113985

Epoch: 6| Step: 1
Training loss: 1.902784480557234
Validation loss: 2.5466735229682835

Epoch: 6| Step: 2
Training loss: 2.2840817786439267
Validation loss: 2.583668615261789

Epoch: 6| Step: 3
Training loss: 2.5466072550262906
Validation loss: 2.586472117007939

Epoch: 6| Step: 4
Training loss: 1.3602354461558785
Validation loss: 2.591007253241389

Epoch: 6| Step: 5
Training loss: 1.8752235279358354
Validation loss: 2.6034253451278397

Epoch: 6| Step: 6
Training loss: 2.329996879804757
Validation loss: 2.657810934351498

Epoch: 6| Step: 7
Training loss: 1.8464122237604148
Validation loss: 2.6434560794239776

Epoch: 6| Step: 8
Training loss: 3.0868434686743766
Validation loss: 2.6668696673929753

Epoch: 6| Step: 9
Training loss: 1.7291104257775067
Validation loss: 2.6398165667269735

Epoch: 6| Step: 10
Training loss: 2.0373544371861683
Validation loss: 2.627212954012522

Epoch: 6| Step: 11
Training loss: 2.105261061692449
Validation loss: 2.569764006277303

Epoch: 6| Step: 12
Training loss: 1.776396178123797
Validation loss: 2.5649065641918147

Epoch: 6| Step: 13
Training loss: 2.141765652557168
Validation loss: 2.519045855466339

Epoch: 291| Step: 0
Training loss: 1.348992522799368
Validation loss: 2.5127413315901026

Epoch: 6| Step: 1
Training loss: 2.2993912181401535
Validation loss: 2.498904480909764

Epoch: 6| Step: 2
Training loss: 2.1697136532705694
Validation loss: 2.5038946571022214

Epoch: 6| Step: 3
Training loss: 1.4298424141758492
Validation loss: 2.4910873966646068

Epoch: 6| Step: 4
Training loss: 2.1181853360575897
Validation loss: 2.5302532258546044

Epoch: 6| Step: 5
Training loss: 2.6818836877166983
Validation loss: 2.570191787312322

Epoch: 6| Step: 6
Training loss: 2.011615165339855
Validation loss: 2.553925737983643

Epoch: 6| Step: 7
Training loss: 1.554891908329365
Validation loss: 2.566178170902339

Epoch: 6| Step: 8
Training loss: 2.6816608958856936
Validation loss: 2.6002345471471435

Epoch: 6| Step: 9
Training loss: 1.4922929496853705
Validation loss: 2.6673017033785875

Epoch: 6| Step: 10
Training loss: 2.063738942108012
Validation loss: 2.676827018925898

Epoch: 6| Step: 11
Training loss: 2.081451163436285
Validation loss: 2.7194956783637436

Epoch: 6| Step: 12
Training loss: 1.935516449566934
Validation loss: 2.7417199441744105

Epoch: 6| Step: 13
Training loss: 2.67774746346979
Validation loss: 2.697517885956672

Epoch: 292| Step: 0
Training loss: 1.5349794242299954
Validation loss: 2.661353799119487

Epoch: 6| Step: 1
Training loss: 2.755418208204648
Validation loss: 2.5744757516755863

Epoch: 6| Step: 2
Training loss: 2.372541058167987
Validation loss: 2.57294395113132

Epoch: 6| Step: 3
Training loss: 1.9645804196521865
Validation loss: 2.5317568958251715

Epoch: 6| Step: 4
Training loss: 1.5501104869226194
Validation loss: 2.520979874400057

Epoch: 6| Step: 5
Training loss: 2.0135688644390535
Validation loss: 2.509476851141772

Epoch: 6| Step: 6
Training loss: 2.0825467214117412
Validation loss: 2.5264416774468

Epoch: 6| Step: 7
Training loss: 1.8881343482959485
Validation loss: 2.5274539316206823

Epoch: 6| Step: 8
Training loss: 2.1503150088175444
Validation loss: 2.5430150806681375

Epoch: 6| Step: 9
Training loss: 1.9713879426576426
Validation loss: 2.5626760437823934

Epoch: 6| Step: 10
Training loss: 2.133836214081435
Validation loss: 2.5466122013861994

Epoch: 6| Step: 11
Training loss: 2.1426949621317144
Validation loss: 2.5760332040818703

Epoch: 6| Step: 12
Training loss: 2.36045863043263
Validation loss: 2.565893453909811

Epoch: 6| Step: 13
Training loss: 2.2730521698119937
Validation loss: 2.568664795637336

Epoch: 293| Step: 0
Training loss: 2.9329630126701915
Validation loss: 2.55528221246467

Epoch: 6| Step: 1
Training loss: 2.147132838062398
Validation loss: 2.5647383737272995

Epoch: 6| Step: 2
Training loss: 2.2343274091440675
Validation loss: 2.5689242632586087

Epoch: 6| Step: 3
Training loss: 2.0961714449717816
Validation loss: 2.570222986396041

Epoch: 6| Step: 4
Training loss: 2.0229498669629966
Validation loss: 2.6068911275377733

Epoch: 6| Step: 5
Training loss: 1.2858846623445297
Validation loss: 2.6165809497845682

Epoch: 6| Step: 6
Training loss: 1.5211699997139654
Validation loss: 2.5955697841758703

Epoch: 6| Step: 7
Training loss: 2.5861855010539783
Validation loss: 2.5919893256083415

Epoch: 6| Step: 8
Training loss: 1.9524917186214645
Validation loss: 2.5913627853175605

Epoch: 6| Step: 9
Training loss: 2.444684322705716
Validation loss: 2.574760877746841

Epoch: 6| Step: 10
Training loss: 2.075268725723506
Validation loss: 2.606769898395707

Epoch: 6| Step: 11
Training loss: 1.6108660411063132
Validation loss: 2.622332140626689

Epoch: 6| Step: 12
Training loss: 2.2248427860566817
Validation loss: 2.6351078340010994

Epoch: 6| Step: 13
Training loss: 1.5227955566064866
Validation loss: 2.657046882922141

Epoch: 294| Step: 0
Training loss: 2.5866114726355547
Validation loss: 2.6372987989847574

Epoch: 6| Step: 1
Training loss: 1.9531284179657593
Validation loss: 2.622588972892183

Epoch: 6| Step: 2
Training loss: 3.055928244162758
Validation loss: 2.6163497570914123

Epoch: 6| Step: 3
Training loss: 1.9335853037023543
Validation loss: 2.573040365934114

Epoch: 6| Step: 4
Training loss: 2.045449262669995
Validation loss: 2.579541196935458

Epoch: 6| Step: 5
Training loss: 1.1570971710363027
Validation loss: 2.5777129797720315

Epoch: 6| Step: 6
Training loss: 1.5983112363643617
Validation loss: 2.5811455189000787

Epoch: 6| Step: 7
Training loss: 3.009127242841492
Validation loss: 2.5539355712277914

Epoch: 6| Step: 8
Training loss: 1.8068186409340607
Validation loss: 2.590235546734826

Epoch: 6| Step: 9
Training loss: 2.0336857203739545
Validation loss: 2.585734702280337

Epoch: 6| Step: 10
Training loss: 2.0183274243134686
Validation loss: 2.5915004672845487

Epoch: 6| Step: 11
Training loss: 1.7632101643793776
Validation loss: 2.6298453555796226

Epoch: 6| Step: 12
Training loss: 1.4244515685407364
Validation loss: 2.611445916694994

Epoch: 6| Step: 13
Training loss: 1.5659137817364899
Validation loss: 2.6745589608704696

Epoch: 295| Step: 0
Training loss: 1.4443198429472188
Validation loss: 2.668545140809578

Epoch: 6| Step: 1
Training loss: 1.7265422008581182
Validation loss: 2.644224223237727

Epoch: 6| Step: 2
Training loss: 2.164896339595466
Validation loss: 2.6436001421794026

Epoch: 6| Step: 3
Training loss: 2.126153857049493
Validation loss: 2.661938727831802

Epoch: 6| Step: 4
Training loss: 2.3122773965455443
Validation loss: 2.65979530249566

Epoch: 6| Step: 5
Training loss: 1.7448118142250546
Validation loss: 2.6137367691636797

Epoch: 6| Step: 6
Training loss: 2.0139825324141074
Validation loss: 2.6074224388702962

Epoch: 6| Step: 7
Training loss: 1.830100272094513
Validation loss: 2.589897465903983

Epoch: 6| Step: 8
Training loss: 3.0234237788872274
Validation loss: 2.5704220301085243

Epoch: 6| Step: 9
Training loss: 1.4819294912165206
Validation loss: 2.5545915280357243

Epoch: 6| Step: 10
Training loss: 2.326667073130458
Validation loss: 2.5441724796605687

Epoch: 6| Step: 11
Training loss: 1.6490726061047398
Validation loss: 2.5375185610338193

Epoch: 6| Step: 12
Training loss: 2.723100010352509
Validation loss: 2.57646466361111

Epoch: 6| Step: 13
Training loss: 2.0506119721803096
Validation loss: 2.648698341930429

Epoch: 296| Step: 0
Training loss: 1.5312325612846278
Validation loss: 2.687071145017663

Epoch: 6| Step: 1
Training loss: 3.384405523076232
Validation loss: 2.689636770870435

Epoch: 6| Step: 2
Training loss: 1.8475662435339675
Validation loss: 2.730659707395184

Epoch: 6| Step: 3
Training loss: 1.9937302543595103
Validation loss: 2.6976241366790097

Epoch: 6| Step: 4
Training loss: 1.979952171114063
Validation loss: 2.6314974102974182

Epoch: 6| Step: 5
Training loss: 1.9389786769015176
Validation loss: 2.628738979933842

Epoch: 6| Step: 6
Training loss: 2.3810542389108345
Validation loss: 2.610684186334373

Epoch: 6| Step: 7
Training loss: 1.5914209588953059
Validation loss: 2.601742498607005

Epoch: 6| Step: 8
Training loss: 2.2160037600695386
Validation loss: 2.5855990800179995

Epoch: 6| Step: 9
Training loss: 1.5757245228986598
Validation loss: 2.5681406447725568

Epoch: 6| Step: 10
Training loss: 2.178565279931855
Validation loss: 2.563390158514081

Epoch: 6| Step: 11
Training loss: 1.9888646557052039
Validation loss: 2.547527767849903

Epoch: 6| Step: 12
Training loss: 1.820085372180087
Validation loss: 2.566929075422143

Epoch: 6| Step: 13
Training loss: 2.1599730263897845
Validation loss: 2.5834141277681684

Epoch: 297| Step: 0
Training loss: 2.476033151173556
Validation loss: 2.5952012012370727

Epoch: 6| Step: 1
Training loss: 1.9803129657818856
Validation loss: 2.6079372320559377

Epoch: 6| Step: 2
Training loss: 1.3035780706814972
Validation loss: 2.6198255234661025

Epoch: 6| Step: 3
Training loss: 2.1033342685284278
Validation loss: 2.692796588880358

Epoch: 6| Step: 4
Training loss: 1.785248000710755
Validation loss: 2.696557609708988

Epoch: 6| Step: 5
Training loss: 2.0059499450858542
Validation loss: 2.6845126145260028

Epoch: 6| Step: 6
Training loss: 2.3607260770319813
Validation loss: 2.6476857666699596

Epoch: 6| Step: 7
Training loss: 2.8779409542322725
Validation loss: 2.5960551057461627

Epoch: 6| Step: 8
Training loss: 1.7242703650025353
Validation loss: 2.550686759035897

Epoch: 6| Step: 9
Training loss: 2.0604176268335874
Validation loss: 2.525148982509329

Epoch: 6| Step: 10
Training loss: 1.7729254836308863
Validation loss: 2.5194099337919873

Epoch: 6| Step: 11
Training loss: 1.8981100043243635
Validation loss: 2.507848784916061

Epoch: 6| Step: 12
Training loss: 2.1723599338484267
Validation loss: 2.5182334218717415

Epoch: 6| Step: 13
Training loss: 2.1894779527194004
Validation loss: 2.5064355034800854

Epoch: 298| Step: 0
Training loss: 2.1451108389007394
Validation loss: 2.5295847371784004

Epoch: 6| Step: 1
Training loss: 1.7236490654111554
Validation loss: 2.547683618658415

Epoch: 6| Step: 2
Training loss: 2.263334497649053
Validation loss: 2.5443566632248427

Epoch: 6| Step: 3
Training loss: 1.8562351932641517
Validation loss: 2.5655814461025583

Epoch: 6| Step: 4
Training loss: 2.219040865033192
Validation loss: 2.5864357060213266

Epoch: 6| Step: 5
Training loss: 2.252629333237909
Validation loss: 2.608583981431994

Epoch: 6| Step: 6
Training loss: 1.7425934186109104
Validation loss: 2.622130263416908

Epoch: 6| Step: 7
Training loss: 2.8070267721597495
Validation loss: 2.631804094847372

Epoch: 6| Step: 8
Training loss: 2.126944157465026
Validation loss: 2.5996912277714035

Epoch: 6| Step: 9
Training loss: 2.5509515445523085
Validation loss: 2.5844429360823833

Epoch: 6| Step: 10
Training loss: 1.3356303257851636
Validation loss: 2.5568195588336153

Epoch: 6| Step: 11
Training loss: 1.804316164596194
Validation loss: 2.5215448893784127

Epoch: 6| Step: 12
Training loss: 1.8451090184492538
Validation loss: 2.5309258084636115

Epoch: 6| Step: 13
Training loss: 2.149699336475604
Validation loss: 2.5358381720814425

Epoch: 299| Step: 0
Training loss: 1.9128346767426914
Validation loss: 2.5219906811533184

Epoch: 6| Step: 1
Training loss: 2.829424311985719
Validation loss: 2.5605326598059204

Epoch: 6| Step: 2
Training loss: 2.039914592563226
Validation loss: 2.588635730121706

Epoch: 6| Step: 3
Training loss: 1.9037112856639866
Validation loss: 2.639953979466762

Epoch: 6| Step: 4
Training loss: 1.559789519171164
Validation loss: 2.652896754163789

Epoch: 6| Step: 5
Training loss: 2.3937379602672295
Validation loss: 2.670911009001683

Epoch: 6| Step: 6
Training loss: 2.3620493302584133
Validation loss: 2.64341955141338

Epoch: 6| Step: 7
Training loss: 2.2817036425889667
Validation loss: 2.7088391834195003

Epoch: 6| Step: 8
Training loss: 1.3583701354972
Validation loss: 2.6701813771461507

Epoch: 6| Step: 9
Training loss: 1.5255144877338158
Validation loss: 2.685643123867097

Epoch: 6| Step: 10
Training loss: 2.458733240564009
Validation loss: 2.660443604606003

Epoch: 6| Step: 11
Training loss: 1.9494333397543067
Validation loss: 2.6230321198723274

Epoch: 6| Step: 12
Training loss: 1.4076111881387086
Validation loss: 2.6142404085686013

Epoch: 6| Step: 13
Training loss: 1.9282123935375155
Validation loss: 2.570990290453933

Epoch: 300| Step: 0
Training loss: 2.442186203539523
Validation loss: 2.5723371252010816

Epoch: 6| Step: 1
Training loss: 1.361989061989465
Validation loss: 2.55375663760196

Epoch: 6| Step: 2
Training loss: 2.605539666945059
Validation loss: 2.5343410002046283

Epoch: 6| Step: 3
Training loss: 1.4699952548462971
Validation loss: 2.533266731900897

Epoch: 6| Step: 4
Training loss: 2.155890835689543
Validation loss: 2.5358859962847613

Epoch: 6| Step: 5
Training loss: 1.5513001157671191
Validation loss: 2.5348009076962064

Epoch: 6| Step: 6
Training loss: 1.6144797835420748
Validation loss: 2.578555169486385

Epoch: 6| Step: 7
Training loss: 2.0247288416406852
Validation loss: 2.581956255386842

Epoch: 6| Step: 8
Training loss: 2.0644722958399147
Validation loss: 2.5964629374644903

Epoch: 6| Step: 9
Training loss: 2.8327730036158294
Validation loss: 2.6179519979118733

Epoch: 6| Step: 10
Training loss: 2.154010217569782
Validation loss: 2.6171840990338597

Epoch: 6| Step: 11
Training loss: 1.5405587605750537
Validation loss: 2.597996135455755

Epoch: 6| Step: 12
Training loss: 2.10313113071404
Validation loss: 2.661987227251844

Epoch: 6| Step: 13
Training loss: 1.8867274061047874
Validation loss: 2.6822451294253797

Epoch: 301| Step: 0
Training loss: 1.5047093216530818
Validation loss: 2.6697789051367593

Epoch: 6| Step: 1
Training loss: 2.806109479686654
Validation loss: 2.650701989456946

Epoch: 6| Step: 2
Training loss: 1.6822429291679593
Validation loss: 2.6497672914498134

Epoch: 6| Step: 3
Training loss: 2.3471558302519235
Validation loss: 2.5802917315039324

Epoch: 6| Step: 4
Training loss: 2.290608271476582
Validation loss: 2.5741110023250457

Epoch: 6| Step: 5
Training loss: 1.6673568568064405
Validation loss: 2.5305187990241165

Epoch: 6| Step: 6
Training loss: 1.8243983831733444
Validation loss: 2.517289821156095

Epoch: 6| Step: 7
Training loss: 1.9996266016485447
Validation loss: 2.4849227845177526

Epoch: 6| Step: 8
Training loss: 1.859331018264294
Validation loss: 2.5016571433665216

Epoch: 6| Step: 9
Training loss: 1.588463261237998
Validation loss: 2.461825756449841

Epoch: 6| Step: 10
Training loss: 1.9320251884319084
Validation loss: 2.5228577253878655

Epoch: 6| Step: 11
Training loss: 2.202698361906905
Validation loss: 2.5343311379710123

Epoch: 6| Step: 12
Training loss: 2.408496947049199
Validation loss: 2.5773911173355857

Epoch: 6| Step: 13
Training loss: 2.046021611186246
Validation loss: 2.6519913586782113

Epoch: 302| Step: 0
Training loss: 1.780291650859932
Validation loss: 2.7076791022024276

Epoch: 6| Step: 1
Training loss: 1.5768496959710783
Validation loss: 2.690516250427054

Epoch: 6| Step: 2
Training loss: 2.2197304292201254
Validation loss: 2.691870824159469

Epoch: 6| Step: 3
Training loss: 2.009401872375108
Validation loss: 2.6381736075978175

Epoch: 6| Step: 4
Training loss: 1.5826988036281513
Validation loss: 2.600430017759057

Epoch: 6| Step: 5
Training loss: 2.589487641076152
Validation loss: 2.5660102031571315

Epoch: 6| Step: 6
Training loss: 1.869329715997803
Validation loss: 2.567289915419855

Epoch: 6| Step: 7
Training loss: 2.3883498591587564
Validation loss: 2.5408401291821927

Epoch: 6| Step: 8
Training loss: 2.601409082786369
Validation loss: 2.563227697493374

Epoch: 6| Step: 9
Training loss: 2.1098731688938934
Validation loss: 2.5855348701926446

Epoch: 6| Step: 10
Training loss: 2.3566401717635896
Validation loss: 2.571056424502398

Epoch: 6| Step: 11
Training loss: 1.8237251741263505
Validation loss: 2.627581900939264

Epoch: 6| Step: 12
Training loss: 1.9812459229628916
Validation loss: 2.6186733146613523

Epoch: 6| Step: 13
Training loss: 2.0134905965702465
Validation loss: 2.648100990064719

Epoch: 303| Step: 0
Training loss: 2.036252478872609
Validation loss: 2.6783675343249254

Epoch: 6| Step: 1
Training loss: 2.5192913562211334
Validation loss: 2.7037502146435832

Epoch: 6| Step: 2
Training loss: 1.7291902594125004
Validation loss: 2.707018537982343

Epoch: 6| Step: 3
Training loss: 2.2026578800281706
Validation loss: 2.6987981546784185

Epoch: 6| Step: 4
Training loss: 2.00712555886103
Validation loss: 2.696091823969606

Epoch: 6| Step: 5
Training loss: 1.6256876004260712
Validation loss: 2.656325672044148

Epoch: 6| Step: 6
Training loss: 2.183648124113372
Validation loss: 2.629330076126005

Epoch: 6| Step: 7
Training loss: 1.8927120322774105
Validation loss: 2.6126175186276184

Epoch: 6| Step: 8
Training loss: 1.725047625008647
Validation loss: 2.5890166360510443

Epoch: 6| Step: 9
Training loss: 2.2576532538726313
Validation loss: 2.594954735588389

Epoch: 6| Step: 10
Training loss: 1.9384261963112066
Validation loss: 2.5818143860298175

Epoch: 6| Step: 11
Training loss: 1.8377580422588842
Validation loss: 2.5704161556410554

Epoch: 6| Step: 12
Training loss: 2.2896373664883116
Validation loss: 2.5483014689271073

Epoch: 6| Step: 13
Training loss: 1.8562814960312282
Validation loss: 2.548193311501537

Epoch: 304| Step: 0
Training loss: 1.4656165767338156
Validation loss: 2.550220655730366

Epoch: 6| Step: 1
Training loss: 1.9537272020841534
Validation loss: 2.560796155708317

Epoch: 6| Step: 2
Training loss: 2.626870351855794
Validation loss: 2.567174029261731

Epoch: 6| Step: 3
Training loss: 1.9944097354150943
Validation loss: 2.599782890645142

Epoch: 6| Step: 4
Training loss: 1.994746102260057
Validation loss: 2.6135316433238587

Epoch: 6| Step: 5
Training loss: 1.8076878827004974
Validation loss: 2.611842559152923

Epoch: 6| Step: 6
Training loss: 2.1942929109600104
Validation loss: 2.6505677574673037

Epoch: 6| Step: 7
Training loss: 1.7167667390610861
Validation loss: 2.6543859785448882

Epoch: 6| Step: 8
Training loss: 1.7206316271680968
Validation loss: 2.6681858047058564

Epoch: 6| Step: 9
Training loss: 2.4368159972779733
Validation loss: 2.6574602249819748

Epoch: 6| Step: 10
Training loss: 2.2350550330296985
Validation loss: 2.6497474814007496

Epoch: 6| Step: 11
Training loss: 2.053511134145092
Validation loss: 2.594765552423545

Epoch: 6| Step: 12
Training loss: 2.235730380335949
Validation loss: 2.569042537518693

Epoch: 6| Step: 13
Training loss: 1.6441781940368683
Validation loss: 2.5610222781293626

Epoch: 305| Step: 0
Training loss: 2.2564169190604093
Validation loss: 2.5248606382127385

Epoch: 6| Step: 1
Training loss: 1.613996813490888
Validation loss: 2.5022141347507496

Epoch: 6| Step: 2
Training loss: 2.1464315031306813
Validation loss: 2.508182827076699

Epoch: 6| Step: 3
Training loss: 1.3762042234258676
Validation loss: 2.494792887794233

Epoch: 6| Step: 4
Training loss: 1.959373184519631
Validation loss: 2.5025271199751544

Epoch: 6| Step: 5
Training loss: 2.006123704589334
Validation loss: 2.5302639206148214

Epoch: 6| Step: 6
Training loss: 1.73475491598389
Validation loss: 2.5351392905084853

Epoch: 6| Step: 7
Training loss: 2.212410156667263
Validation loss: 2.576293402584922

Epoch: 6| Step: 8
Training loss: 1.3776285016723469
Validation loss: 2.637087572463746

Epoch: 6| Step: 9
Training loss: 2.4738519799645275
Validation loss: 2.670075850010628

Epoch: 6| Step: 10
Training loss: 2.3531681294940454
Validation loss: 2.6834076322216656

Epoch: 6| Step: 11
Training loss: 2.295394316397299
Validation loss: 2.664700428942638

Epoch: 6| Step: 12
Training loss: 2.2724158229702045
Validation loss: 2.662419368973643

Epoch: 6| Step: 13
Training loss: 1.828428063988481
Validation loss: 2.634483554182778

Epoch: 306| Step: 0
Training loss: 1.7728505108418233
Validation loss: 2.599993686179295

Epoch: 6| Step: 1
Training loss: 1.9326722077975274
Validation loss: 2.5964600832553533

Epoch: 6| Step: 2
Training loss: 1.796753854399528
Validation loss: 2.5795183212163

Epoch: 6| Step: 3
Training loss: 2.363762218619266
Validation loss: 2.5799974057827706

Epoch: 6| Step: 4
Training loss: 1.8758235394383023
Validation loss: 2.567659332447488

Epoch: 6| Step: 5
Training loss: 2.0727288881551114
Validation loss: 2.582645960594653

Epoch: 6| Step: 6
Training loss: 1.813053835734944
Validation loss: 2.5887965352535836

Epoch: 6| Step: 7
Training loss: 2.1891279429987347
Validation loss: 2.601500532387884

Epoch: 6| Step: 8
Training loss: 1.8695328160497384
Validation loss: 2.6131166293187995

Epoch: 6| Step: 9
Training loss: 1.7663771116138676
Validation loss: 2.6163321544459714

Epoch: 6| Step: 10
Training loss: 1.9737807288746336
Validation loss: 2.6323737694863483

Epoch: 6| Step: 11
Training loss: 1.9255169112523522
Validation loss: 2.577112665731591

Epoch: 6| Step: 12
Training loss: 1.6790715707334771
Validation loss: 2.60778129472113

Epoch: 6| Step: 13
Training loss: 2.85879877673505
Validation loss: 2.626798210634207

Epoch: 307| Step: 0
Training loss: 1.6814693492190933
Validation loss: 2.6383861177128014

Epoch: 6| Step: 1
Training loss: 1.885499674899959
Validation loss: 2.6423776441990627

Epoch: 6| Step: 2
Training loss: 2.291845719249506
Validation loss: 2.684165319943576

Epoch: 6| Step: 3
Training loss: 2.35269350753928
Validation loss: 2.6868001484980146

Epoch: 6| Step: 4
Training loss: 1.664691931373308
Validation loss: 2.682552485454709

Epoch: 6| Step: 5
Training loss: 1.5727428399176024
Validation loss: 2.67939817536765

Epoch: 6| Step: 6
Training loss: 2.0430503230831456
Validation loss: 2.653833733901352

Epoch: 6| Step: 7
Training loss: 2.011159163486989
Validation loss: 2.6702661410928625

Epoch: 6| Step: 8
Training loss: 2.009636076819602
Validation loss: 2.638057551578754

Epoch: 6| Step: 9
Training loss: 2.4017254785894275
Validation loss: 2.593089559648002

Epoch: 6| Step: 10
Training loss: 1.7438458816255251
Validation loss: 2.6034390513860743

Epoch: 6| Step: 11
Training loss: 1.5146719698919442
Validation loss: 2.602104367328187

Epoch: 6| Step: 12
Training loss: 1.80312553947877
Validation loss: 2.59164140010264

Epoch: 6| Step: 13
Training loss: 2.5693389069015526
Validation loss: 2.56113180215145

Epoch: 308| Step: 0
Training loss: 1.8472613503400002
Validation loss: 2.5697648412827188

Epoch: 6| Step: 1
Training loss: 2.2942506498444155
Validation loss: 2.57380263072333

Epoch: 6| Step: 2
Training loss: 1.7219250569622457
Validation loss: 2.601214166944667

Epoch: 6| Step: 3
Training loss: 1.6983881882683112
Validation loss: 2.6177055036046535

Epoch: 6| Step: 4
Training loss: 1.7447820938379144
Validation loss: 2.6311110102655992

Epoch: 6| Step: 5
Training loss: 2.03129049407503
Validation loss: 2.629701982361204

Epoch: 6| Step: 6
Training loss: 1.8038855418077708
Validation loss: 2.5731737005878585

Epoch: 6| Step: 7
Training loss: 2.2873878993514873
Validation loss: 2.5874600034193262

Epoch: 6| Step: 8
Training loss: 1.7854613997005246
Validation loss: 2.5521108560959447

Epoch: 6| Step: 9
Training loss: 2.0817689998855005
Validation loss: 2.590603892842791

Epoch: 6| Step: 10
Training loss: 1.6633567208816333
Validation loss: 2.5705101223216826

Epoch: 6| Step: 11
Training loss: 2.3448909779727245
Validation loss: 2.5679147623172573

Epoch: 6| Step: 12
Training loss: 2.211925919187317
Validation loss: 2.57945587794282

Epoch: 6| Step: 13
Training loss: 2.1255337661864444
Validation loss: 2.5933794116884563

Epoch: 309| Step: 0
Training loss: 2.683260123713318
Validation loss: 2.6098109964165612

Epoch: 6| Step: 1
Training loss: 2.388472042630035
Validation loss: 2.5668540188501803

Epoch: 6| Step: 2
Training loss: 1.9513943748653433
Validation loss: 2.585394150120766

Epoch: 6| Step: 3
Training loss: 1.5161193356108986
Validation loss: 2.6026355871034665

Epoch: 6| Step: 4
Training loss: 1.6960395625106504
Validation loss: 2.6301097335211607

Epoch: 6| Step: 5
Training loss: 2.033087618109199
Validation loss: 2.6183892522806347

Epoch: 6| Step: 6
Training loss: 1.4589151674986596
Validation loss: 2.6404877124739574

Epoch: 6| Step: 7
Training loss: 1.8422028467317246
Validation loss: 2.6644955876875147

Epoch: 6| Step: 8
Training loss: 1.9642033832189587
Validation loss: 2.6347228080450797

Epoch: 6| Step: 9
Training loss: 1.8349571694928715
Validation loss: 2.625721726276789

Epoch: 6| Step: 10
Training loss: 1.9673328445952758
Validation loss: 2.62920673045623

Epoch: 6| Step: 11
Training loss: 1.474032864073558
Validation loss: 2.621909638495443

Epoch: 6| Step: 12
Training loss: 2.6591847083821496
Validation loss: 2.606351856220349

Epoch: 6| Step: 13
Training loss: 1.6389583296351733
Validation loss: 2.600943521326671

Epoch: 310| Step: 0
Training loss: 1.5642242073662729
Validation loss: 2.6291890249697145

Epoch: 6| Step: 1
Training loss: 2.4530328623968787
Validation loss: 2.6006764840112924

Epoch: 6| Step: 2
Training loss: 1.727682104490828
Validation loss: 2.5906070065918416

Epoch: 6| Step: 3
Training loss: 2.116560163847241
Validation loss: 2.5995491110649405

Epoch: 6| Step: 4
Training loss: 1.5956749604259772
Validation loss: 2.5994157000094242

Epoch: 6| Step: 5
Training loss: 1.2750880771957005
Validation loss: 2.612017589728933

Epoch: 6| Step: 6
Training loss: 2.2893145425714443
Validation loss: 2.6079540533492334

Epoch: 6| Step: 7
Training loss: 3.0572664345388367
Validation loss: 2.5836974369356502

Epoch: 6| Step: 8
Training loss: 1.5504535165392261
Validation loss: 2.585140831614006

Epoch: 6| Step: 9
Training loss: 1.9398931674447004
Validation loss: 2.5598049568093506

Epoch: 6| Step: 10
Training loss: 1.5690281108528568
Validation loss: 2.603422979340998

Epoch: 6| Step: 11
Training loss: 2.2141529869697423
Validation loss: 2.6302901503927845

Epoch: 6| Step: 12
Training loss: 1.695046399587023
Validation loss: 2.6477871136570346

Epoch: 6| Step: 13
Training loss: 1.6384287348019315
Validation loss: 2.6711014339801014

Epoch: 311| Step: 0
Training loss: 1.8822228232458706
Validation loss: 2.6664659056988285

Epoch: 6| Step: 1
Training loss: 2.252961964204478
Validation loss: 2.660189859455221

Epoch: 6| Step: 2
Training loss: 1.6909076052553842
Validation loss: 2.6143620360646787

Epoch: 6| Step: 3
Training loss: 1.9747993536322426
Validation loss: 2.5880641432836176

Epoch: 6| Step: 4
Training loss: 1.9264213937285917
Validation loss: 2.5334104729084364

Epoch: 6| Step: 5
Training loss: 1.9257842212832048
Validation loss: 2.517666416874102

Epoch: 6| Step: 6
Training loss: 2.436133564123391
Validation loss: 2.5184828910834707

Epoch: 6| Step: 7
Training loss: 2.130587468688145
Validation loss: 2.481050005715196

Epoch: 6| Step: 8
Training loss: 1.7371161167158924
Validation loss: 2.46849453083123

Epoch: 6| Step: 9
Training loss: 1.8092957158086824
Validation loss: 2.4778805503524546

Epoch: 6| Step: 10
Training loss: 2.5164044990995347
Validation loss: 2.4908042744276964

Epoch: 6| Step: 11
Training loss: 1.6848946698600922
Validation loss: 2.5044341103737247

Epoch: 6| Step: 12
Training loss: 2.031506918284874
Validation loss: 2.5479839383651597

Epoch: 6| Step: 13
Training loss: 2.0905354433592858
Validation loss: 2.570592677528951

Epoch: 312| Step: 0
Training loss: 1.8641937388723913
Validation loss: 2.644636894906958

Epoch: 6| Step: 1
Training loss: 2.35370697889754
Validation loss: 2.678883408739893

Epoch: 6| Step: 2
Training loss: 2.0050879372126826
Validation loss: 2.682470316940428

Epoch: 6| Step: 3
Training loss: 1.9136986211436582
Validation loss: 2.710806661154676

Epoch: 6| Step: 4
Training loss: 2.006567305431544
Validation loss: 2.639509939986388

Epoch: 6| Step: 5
Training loss: 1.9550911734314191
Validation loss: 2.625534669223787

Epoch: 6| Step: 6
Training loss: 1.5320190522575436
Validation loss: 2.5623516101826316

Epoch: 6| Step: 7
Training loss: 2.571963443834476
Validation loss: 2.5448247696332724

Epoch: 6| Step: 8
Training loss: 1.7679947335781871
Validation loss: 2.528161303334601

Epoch: 6| Step: 9
Training loss: 2.133818560293821
Validation loss: 2.569343933224485

Epoch: 6| Step: 10
Training loss: 1.5283178944918971
Validation loss: 2.5477957202176813

Epoch: 6| Step: 11
Training loss: 2.674321532440427
Validation loss: 2.581027614505885

Epoch: 6| Step: 12
Training loss: 1.5610805930838507
Validation loss: 2.5709454299212804

Epoch: 6| Step: 13
Training loss: 2.172138335366219
Validation loss: 2.576227503232105

Epoch: 313| Step: 0
Training loss: 1.6111425674407678
Validation loss: 2.5847665338705363

Epoch: 6| Step: 1
Training loss: 2.4611561511558575
Validation loss: 2.564561030530804

Epoch: 6| Step: 2
Training loss: 1.5522295821068568
Validation loss: 2.577949240502193

Epoch: 6| Step: 3
Training loss: 1.4590857699089541
Validation loss: 2.575680431104891

Epoch: 6| Step: 4
Training loss: 1.8578555526429077
Validation loss: 2.610103360854055

Epoch: 6| Step: 5
Training loss: 2.5103573825109535
Validation loss: 2.6125621861261683

Epoch: 6| Step: 6
Training loss: 3.3077737451876947
Validation loss: 2.6147126904184446

Epoch: 6| Step: 7
Training loss: 2.1229779215602145
Validation loss: 2.648898276846935

Epoch: 6| Step: 8
Training loss: 2.1264777935347654
Validation loss: 2.6488786778166085

Epoch: 6| Step: 9
Training loss: 1.5243192810661035
Validation loss: 2.657435358385141

Epoch: 6| Step: 10
Training loss: 1.8033656443993553
Validation loss: 2.6431609998410095

Epoch: 6| Step: 11
Training loss: 1.8383213880236728
Validation loss: 2.635179415994092

Epoch: 6| Step: 12
Training loss: 1.7313525007731942
Validation loss: 2.648661496152647

Epoch: 6| Step: 13
Training loss: 1.1764641993012575
Validation loss: 2.6579969607867566

Epoch: 314| Step: 0
Training loss: 2.325583075145736
Validation loss: 2.65222428380045

Epoch: 6| Step: 1
Training loss: 1.8494568774993745
Validation loss: 2.6147178422794877

Epoch: 6| Step: 2
Training loss: 2.140381179623315
Validation loss: 2.5797903057757026

Epoch: 6| Step: 3
Training loss: 1.7935452999055002
Validation loss: 2.5666952913925742

Epoch: 6| Step: 4
Training loss: 2.1264777935347654
Validation loss: 2.542669353840086

Epoch: 6| Step: 5
Training loss: 2.0756015227430766
Validation loss: 2.540033501043688

Epoch: 6| Step: 6
Training loss: 2.3871670316020155
Validation loss: 2.540646369096603

Epoch: 6| Step: 7
Training loss: 1.3813939118824023
Validation loss: 2.542230142346333

Epoch: 6| Step: 8
Training loss: 1.7445581156485221
Validation loss: 2.581136266559609

Epoch: 6| Step: 9
Training loss: 2.1185362626466135
Validation loss: 2.5779178574701493

Epoch: 6| Step: 10
Training loss: 1.6575344071765512
Validation loss: 2.584200933853113

Epoch: 6| Step: 11
Training loss: 1.970187071423683
Validation loss: 2.5950389018906725

Epoch: 6| Step: 12
Training loss: 2.197842806137027
Validation loss: 2.634017185755659

Epoch: 6| Step: 13
Training loss: 1.8121247396374858
Validation loss: 2.6476212615621026

Epoch: 315| Step: 0
Training loss: 1.4300333240600944
Validation loss: 2.6239516874630247

Epoch: 6| Step: 1
Training loss: 1.6874042059941472
Validation loss: 2.608343000262042

Epoch: 6| Step: 2
Training loss: 2.599253044670386
Validation loss: 2.5985752095983616

Epoch: 6| Step: 3
Training loss: 1.784325003382832
Validation loss: 2.6046347286475156

Epoch: 6| Step: 4
Training loss: 2.22657642025528
Validation loss: 2.5838667231749786

Epoch: 6| Step: 5
Training loss: 1.9392456066597699
Validation loss: 2.6226220486353733

Epoch: 6| Step: 6
Training loss: 1.648241727512267
Validation loss: 2.5831863505070087

Epoch: 6| Step: 7
Training loss: 1.938673033474713
Validation loss: 2.583736639432747

Epoch: 6| Step: 8
Training loss: 1.520975010512987
Validation loss: 2.589048882162578

Epoch: 6| Step: 9
Training loss: 2.0001277882759374
Validation loss: 2.617664532814272

Epoch: 6| Step: 10
Training loss: 1.7667975119354091
Validation loss: 2.648604021116797

Epoch: 6| Step: 11
Training loss: 2.238962332806935
Validation loss: 2.6368831328967115

Epoch: 6| Step: 12
Training loss: 2.1179997198808898
Validation loss: 2.635103174393807

Epoch: 6| Step: 13
Training loss: 2.028210522651516
Validation loss: 2.6638597278857388

Epoch: 316| Step: 0
Training loss: 2.178699775506481
Validation loss: 2.653583369894113

Epoch: 6| Step: 1
Training loss: 1.9589551655349777
Validation loss: 2.6752636188369214

Epoch: 6| Step: 2
Training loss: 1.5318578175484185
Validation loss: 2.6436305651128698

Epoch: 6| Step: 3
Training loss: 1.555627509943101
Validation loss: 2.641797469437652

Epoch: 6| Step: 4
Training loss: 2.018293639763202
Validation loss: 2.6695018885405095

Epoch: 6| Step: 5
Training loss: 1.656438780768243
Validation loss: 2.622055733733136

Epoch: 6| Step: 6
Training loss: 1.84242977137892
Validation loss: 2.638294719149196

Epoch: 6| Step: 7
Training loss: 1.8480939608751679
Validation loss: 2.617123518583995

Epoch: 6| Step: 8
Training loss: 1.9775018683809311
Validation loss: 2.617537077526069

Epoch: 6| Step: 9
Training loss: 2.543108255102006
Validation loss: 2.5985666156925853

Epoch: 6| Step: 10
Training loss: 1.5444555917211036
Validation loss: 2.606972248681311

Epoch: 6| Step: 11
Training loss: 1.6228051401519046
Validation loss: 2.6132595363564466

Epoch: 6| Step: 12
Training loss: 2.229863233263982
Validation loss: 2.639989802841761

Epoch: 6| Step: 13
Training loss: 2.2663591971077626
Validation loss: 2.637747541746377

Epoch: 317| Step: 0
Training loss: 2.194068746423407
Validation loss: 2.62445680356792

Epoch: 6| Step: 1
Training loss: 1.3827588776789859
Validation loss: 2.6357122162562057

Epoch: 6| Step: 2
Training loss: 1.6088092883729197
Validation loss: 2.627049160966255

Epoch: 6| Step: 3
Training loss: 1.2948226315311469
Validation loss: 2.6460664351098777

Epoch: 6| Step: 4
Training loss: 1.5118176331819113
Validation loss: 2.62866905166372

Epoch: 6| Step: 5
Training loss: 2.6876866475429866
Validation loss: 2.6442615365859328

Epoch: 6| Step: 6
Training loss: 2.646605091227464
Validation loss: 2.6482299903438506

Epoch: 6| Step: 7
Training loss: 1.890710749927809
Validation loss: 2.6042462883539206

Epoch: 6| Step: 8
Training loss: 1.1399091799849195
Validation loss: 2.596275685513442

Epoch: 6| Step: 9
Training loss: 2.2873889416693416
Validation loss: 2.591891530657785

Epoch: 6| Step: 10
Training loss: 1.948009964719661
Validation loss: 2.5900583077646235

Epoch: 6| Step: 11
Training loss: 1.384825453656206
Validation loss: 2.6183470629213335

Epoch: 6| Step: 12
Training loss: 1.5489967514161633
Validation loss: 2.6171795441615706

Epoch: 6| Step: 13
Training loss: 2.6307752747322564
Validation loss: 2.6070741724023327

Epoch: 318| Step: 0
Training loss: 1.4834241532086343
Validation loss: 2.5949047383026764

Epoch: 6| Step: 1
Training loss: 2.5878395852867784
Validation loss: 2.608188344096481

Epoch: 6| Step: 2
Training loss: 1.8196019435332982
Validation loss: 2.5860204462461067

Epoch: 6| Step: 3
Training loss: 2.1249528767465775
Validation loss: 2.5977887036201017

Epoch: 6| Step: 4
Training loss: 1.594156400438438
Validation loss: 2.6064896611347015

Epoch: 6| Step: 5
Training loss: 1.6675397334590847
Validation loss: 2.6130735792848685

Epoch: 6| Step: 6
Training loss: 2.3017944799131804
Validation loss: 2.5793122303384455

Epoch: 6| Step: 7
Training loss: 1.9953095151539868
Validation loss: 2.6011665279640717

Epoch: 6| Step: 8
Training loss: 1.1619382588042058
Validation loss: 2.6037630811128585

Epoch: 6| Step: 9
Training loss: 1.8163839359348475
Validation loss: 2.5844940428741126

Epoch: 6| Step: 10
Training loss: 2.3649452593478593
Validation loss: 2.5807490086618707

Epoch: 6| Step: 11
Training loss: 1.6567846910636048
Validation loss: 2.585214142983574

Epoch: 6| Step: 12
Training loss: 2.1735319773847053
Validation loss: 2.6136702403409924

Epoch: 6| Step: 13
Training loss: 1.6622296479187357
Validation loss: 2.6502399668817143

Epoch: 319| Step: 0
Training loss: 2.117057092458078
Validation loss: 2.6770651305850155

Epoch: 6| Step: 1
Training loss: 2.2224266858876374
Validation loss: 2.6848543881098244

Epoch: 6| Step: 2
Training loss: 1.625173119346576
Validation loss: 2.658688835560817

Epoch: 6| Step: 3
Training loss: 1.8941220814998287
Validation loss: 2.6686200696180835

Epoch: 6| Step: 4
Training loss: 1.6118781613292659
Validation loss: 2.6415067851985348

Epoch: 6| Step: 5
Training loss: 1.9204364758319106
Validation loss: 2.6324376896907107

Epoch: 6| Step: 6
Training loss: 2.5406278978544745
Validation loss: 2.5989976369042957

Epoch: 6| Step: 7
Training loss: 2.2848773492662984
Validation loss: 2.582898123803254

Epoch: 6| Step: 8
Training loss: 1.8384849244205885
Validation loss: 2.556938758216165

Epoch: 6| Step: 9
Training loss: 1.9342583641176108
Validation loss: 2.5554237821255894

Epoch: 6| Step: 10
Training loss: 2.2663326868205105
Validation loss: 2.580156031050121

Epoch: 6| Step: 11
Training loss: 1.639415694912211
Validation loss: 2.5986737316512474

Epoch: 6| Step: 12
Training loss: 1.6782838145997274
Validation loss: 2.611063123717462

Epoch: 6| Step: 13
Training loss: 1.7482944078842684
Validation loss: 2.638360401126368

Epoch: 320| Step: 0
Training loss: 2.582491419612667
Validation loss: 2.6479833583001526

Epoch: 6| Step: 1
Training loss: 2.2370371931289794
Validation loss: 2.6391500834538353

Epoch: 6| Step: 2
Training loss: 1.8823981244610848
Validation loss: 2.634187499674649

Epoch: 6| Step: 3
Training loss: 1.5676546900834694
Validation loss: 2.6385571209896326

Epoch: 6| Step: 4
Training loss: 1.83284157602283
Validation loss: 2.622682911155258

Epoch: 6| Step: 5
Training loss: 1.5730115175595505
Validation loss: 2.61388183139664

Epoch: 6| Step: 6
Training loss: 1.8990333155903094
Validation loss: 2.631107023194971

Epoch: 6| Step: 7
Training loss: 1.497823566767564
Validation loss: 2.6203726294330174

Epoch: 6| Step: 8
Training loss: 1.7924760794007821
Validation loss: 2.606568584287926

Epoch: 6| Step: 9
Training loss: 1.7841457453496936
Validation loss: 2.6580140184138523

Epoch: 6| Step: 10
Training loss: 1.8501017155908555
Validation loss: 2.641247933551385

Epoch: 6| Step: 11
Training loss: 2.5720526187788404
Validation loss: 2.6401102440867508

Epoch: 6| Step: 12
Training loss: 1.8117538757998644
Validation loss: 2.6397127309955475

Epoch: 6| Step: 13
Training loss: 1.7312299376058609
Validation loss: 2.6480908462378303

Epoch: 321| Step: 0
Training loss: 2.0146921054177405
Validation loss: 2.5844537909788747

Epoch: 6| Step: 1
Training loss: 2.127365142456936
Validation loss: 2.605342970618765

Epoch: 6| Step: 2
Training loss: 1.7163979823139521
Validation loss: 2.556677133927518

Epoch: 6| Step: 3
Training loss: 2.2154710207700914
Validation loss: 2.5621692087303987

Epoch: 6| Step: 4
Training loss: 2.289038544096596
Validation loss: 2.597312610048434

Epoch: 6| Step: 5
Training loss: 1.4051808001302493
Validation loss: 2.580433884763463

Epoch: 6| Step: 6
Training loss: 1.9331782963951039
Validation loss: 2.63431767906253

Epoch: 6| Step: 7
Training loss: 2.0263861303707964
Validation loss: 2.6633083734150405

Epoch: 6| Step: 8
Training loss: 1.8033358974520821
Validation loss: 2.653295167483946

Epoch: 6| Step: 9
Training loss: 2.4134255960999
Validation loss: 2.6438283056471747

Epoch: 6| Step: 10
Training loss: 1.4319106363884644
Validation loss: 2.6329118085445016

Epoch: 6| Step: 11
Training loss: 1.810734118806853
Validation loss: 2.6668442552759806

Epoch: 6| Step: 12
Training loss: 2.171577597914343
Validation loss: 2.6075051207475375

Epoch: 6| Step: 13
Training loss: 1.4580401897987447
Validation loss: 2.5929755161461854

Epoch: 322| Step: 0
Training loss: 2.4547957058373435
Validation loss: 2.614559558491816

Epoch: 6| Step: 1
Training loss: 1.7636188824403078
Validation loss: 2.6106404797405056

Epoch: 6| Step: 2
Training loss: 2.484117314632146
Validation loss: 2.5853370822294353

Epoch: 6| Step: 3
Training loss: 1.7172237208453889
Validation loss: 2.5888653609726124

Epoch: 6| Step: 4
Training loss: 1.3444996893823165
Validation loss: 2.5914169297502836

Epoch: 6| Step: 5
Training loss: 1.5343155828031096
Validation loss: 2.6348769624155848

Epoch: 6| Step: 6
Training loss: 1.641332056183451
Validation loss: 2.6044020330241957

Epoch: 6| Step: 7
Training loss: 1.9846496992636335
Validation loss: 2.6426868477442764

Epoch: 6| Step: 8
Training loss: 2.3954340615876504
Validation loss: 2.627714781737505

Epoch: 6| Step: 9
Training loss: 1.5806162593263509
Validation loss: 2.606873720153968

Epoch: 6| Step: 10
Training loss: 2.323731340863857
Validation loss: 2.5738751148792414

Epoch: 6| Step: 11
Training loss: 1.3517150351826401
Validation loss: 2.5821218008225406

Epoch: 6| Step: 12
Training loss: 1.908765477665451
Validation loss: 2.5624184789328526

Epoch: 6| Step: 13
Training loss: 1.8670040024488197
Validation loss: 2.5610315100416927

Epoch: 323| Step: 0
Training loss: 1.706567208004716
Validation loss: 2.555915000994667

Epoch: 6| Step: 1
Training loss: 2.375851829757418
Validation loss: 2.5499198904107376

Epoch: 6| Step: 2
Training loss: 2.244612070733715
Validation loss: 2.5613841674500635

Epoch: 6| Step: 3
Training loss: 2.333008834436256
Validation loss: 2.5726293848764397

Epoch: 6| Step: 4
Training loss: 1.6756692773360908
Validation loss: 2.618742007635601

Epoch: 6| Step: 5
Training loss: 1.533880970779523
Validation loss: 2.6533881159938497

Epoch: 6| Step: 6
Training loss: 2.1748200353073175
Validation loss: 2.6650999702230225

Epoch: 6| Step: 7
Training loss: 1.330254317613752
Validation loss: 2.6895987425780588

Epoch: 6| Step: 8
Training loss: 1.9961165036810102
Validation loss: 2.6804634357319292

Epoch: 6| Step: 9
Training loss: 1.3931179204241504
Validation loss: 2.657376966574075

Epoch: 6| Step: 10
Training loss: 1.8116322117149142
Validation loss: 2.635585286974486

Epoch: 6| Step: 11
Training loss: 1.9622770194921018
Validation loss: 2.5795421057982244

Epoch: 6| Step: 12
Training loss: 1.8221753456836915
Validation loss: 2.5408673879714856

Epoch: 6| Step: 13
Training loss: 2.247106386879054
Validation loss: 2.5162421944312867

Epoch: 324| Step: 0
Training loss: 1.7593415116532847
Validation loss: 2.4906349408483015

Epoch: 6| Step: 1
Training loss: 1.1994287263526393
Validation loss: 2.484890962200285

Epoch: 6| Step: 2
Training loss: 2.009433196131276
Validation loss: 2.4779362122764588

Epoch: 6| Step: 3
Training loss: 2.1488949930160666
Validation loss: 2.4726273232164613

Epoch: 6| Step: 4
Training loss: 1.4281978663713977
Validation loss: 2.4750917722725276

Epoch: 6| Step: 5
Training loss: 1.6809341417581543
Validation loss: 2.484678957596657

Epoch: 6| Step: 6
Training loss: 1.9701379999729405
Validation loss: 2.4884160762332357

Epoch: 6| Step: 7
Training loss: 1.7408883078833353
Validation loss: 2.5211794171645017

Epoch: 6| Step: 8
Training loss: 2.3553849390406594
Validation loss: 2.5516896521614605

Epoch: 6| Step: 9
Training loss: 2.6652744254980782
Validation loss: 2.5770971464888355

Epoch: 6| Step: 10
Training loss: 1.8867812373394786
Validation loss: 2.621763535116733

Epoch: 6| Step: 11
Training loss: 1.964993177309883
Validation loss: 2.6943075471907583

Epoch: 6| Step: 12
Training loss: 1.652605689819801
Validation loss: 2.7795845217085846

Epoch: 6| Step: 13
Training loss: 2.1907938545223042
Validation loss: 2.768251683935177

Epoch: 325| Step: 0
Training loss: 1.9449212473638273
Validation loss: 2.7465744068181213

Epoch: 6| Step: 1
Training loss: 2.1484868824225227
Validation loss: 2.695946616063083

Epoch: 6| Step: 2
Training loss: 2.083671338954226
Validation loss: 2.677935651378804

Epoch: 6| Step: 3
Training loss: 2.1640145747527746
Validation loss: 2.6344497223585828

Epoch: 6| Step: 4
Training loss: 2.820073083241677
Validation loss: 2.602896339842342

Epoch: 6| Step: 5
Training loss: 1.5970614568915698
Validation loss: 2.5399234348932316

Epoch: 6| Step: 6
Training loss: 2.049045140325382
Validation loss: 2.526992938591496

Epoch: 6| Step: 7
Training loss: 1.4126024242838862
Validation loss: 2.5008217970867905

Epoch: 6| Step: 8
Training loss: 1.3377231019662401
Validation loss: 2.499099076380909

Epoch: 6| Step: 9
Training loss: 2.0822694223528386
Validation loss: 2.4924690781093797

Epoch: 6| Step: 10
Training loss: 1.9918872083344275
Validation loss: 2.501182308370871

Epoch: 6| Step: 11
Training loss: 2.2402201139067657
Validation loss: 2.5812309128961544

Epoch: 6| Step: 12
Training loss: 1.8150601557281079
Validation loss: 2.6261292026995826

Epoch: 6| Step: 13
Training loss: 1.700922530565861
Validation loss: 2.644687634816317

Epoch: 326| Step: 0
Training loss: 2.000766845555943
Validation loss: 2.6411248811765735

Epoch: 6| Step: 1
Training loss: 1.7918027190368235
Validation loss: 2.6759103562888273

Epoch: 6| Step: 2
Training loss: 1.871708396668352
Validation loss: 2.6573022441187435

Epoch: 6| Step: 3
Training loss: 1.615193339960161
Validation loss: 2.6343542729441363

Epoch: 6| Step: 4
Training loss: 1.8442998809667146
Validation loss: 2.6001210309859912

Epoch: 6| Step: 5
Training loss: 1.3293983189842646
Validation loss: 2.60221357475219

Epoch: 6| Step: 6
Training loss: 2.6033236754071796
Validation loss: 2.5548765246720224

Epoch: 6| Step: 7
Training loss: 1.5406133902771946
Validation loss: 2.5629165279872335

Epoch: 6| Step: 8
Training loss: 1.7748498880015078
Validation loss: 2.525188330749527

Epoch: 6| Step: 9
Training loss: 2.598375906245802
Validation loss: 2.5447672447836758

Epoch: 6| Step: 10
Training loss: 2.045016077999717
Validation loss: 2.51825306725559

Epoch: 6| Step: 11
Training loss: 1.9045858154191684
Validation loss: 2.528693733324752

Epoch: 6| Step: 12
Training loss: 1.391195972966776
Validation loss: 2.5549112080065175

Epoch: 6| Step: 13
Training loss: 2.1206124955811223
Validation loss: 2.540351642137052

Epoch: 327| Step: 0
Training loss: 1.9687056157997616
Validation loss: 2.569438178825185

Epoch: 6| Step: 1
Training loss: 2.4434105054352386
Validation loss: 2.602966876530108

Epoch: 6| Step: 2
Training loss: 1.7952079005434736
Validation loss: 2.557455043403808

Epoch: 6| Step: 3
Training loss: 2.057042501949797
Validation loss: 2.5731761713987957

Epoch: 6| Step: 4
Training loss: 1.5823362456775
Validation loss: 2.5501074843099873

Epoch: 6| Step: 5
Training loss: 1.6634207907537457
Validation loss: 2.565387401660686

Epoch: 6| Step: 6
Training loss: 1.8064993478334095
Validation loss: 2.589796201059429

Epoch: 6| Step: 7
Training loss: 1.9442949812832322
Validation loss: 2.619590893149952

Epoch: 6| Step: 8
Training loss: 2.1585071194274854
Validation loss: 2.6033880875511977

Epoch: 6| Step: 9
Training loss: 1.7858419290971514
Validation loss: 2.636153172245744

Epoch: 6| Step: 10
Training loss: 1.465801770056771
Validation loss: 2.6498879031098377

Epoch: 6| Step: 11
Training loss: 1.9800143651730167
Validation loss: 2.6610099180816342

Epoch: 6| Step: 12
Training loss: 1.9568517911028749
Validation loss: 2.659975192293729

Epoch: 6| Step: 13
Training loss: 1.8923176526164762
Validation loss: 2.6289329130682613

Epoch: 328| Step: 0
Training loss: 2.009683531334763
Validation loss: 2.619645773817628

Epoch: 6| Step: 1
Training loss: 1.2278126462575623
Validation loss: 2.60001836855831

Epoch: 6| Step: 2
Training loss: 1.425329267373514
Validation loss: 2.5813600222683046

Epoch: 6| Step: 3
Training loss: 2.5362327417921113
Validation loss: 2.5662042624437107

Epoch: 6| Step: 4
Training loss: 1.8655912207735499
Validation loss: 2.6049662977248493

Epoch: 6| Step: 5
Training loss: 1.9684894934372155
Validation loss: 2.609277529238024

Epoch: 6| Step: 6
Training loss: 1.9559916097113894
Validation loss: 2.607847059541621

Epoch: 6| Step: 7
Training loss: 2.075459082501317
Validation loss: 2.594218200341653

Epoch: 6| Step: 8
Training loss: 2.2070520990787905
Validation loss: 2.5847309290280176

Epoch: 6| Step: 9
Training loss: 2.147039895200942
Validation loss: 2.608730838170923

Epoch: 6| Step: 10
Training loss: 1.6646561973898464
Validation loss: 2.6111784468641743

Epoch: 6| Step: 11
Training loss: 1.2454774582184773
Validation loss: 2.6022407021949046

Epoch: 6| Step: 12
Training loss: 1.6818118833381752
Validation loss: 2.571213646388956

Epoch: 6| Step: 13
Training loss: 2.038076344985212
Validation loss: 2.554849881952269

Epoch: 329| Step: 0
Training loss: 1.6523455536383846
Validation loss: 2.559646009567582

Epoch: 6| Step: 1
Training loss: 2.4441591900740303
Validation loss: 2.574544497203861

Epoch: 6| Step: 2
Training loss: 1.4417149489739116
Validation loss: 2.6032110266420885

Epoch: 6| Step: 3
Training loss: 2.0758677678855397
Validation loss: 2.584308937393871

Epoch: 6| Step: 4
Training loss: 1.663224775037329
Validation loss: 2.5824868650985575

Epoch: 6| Step: 5
Training loss: 1.6907400180240526
Validation loss: 2.6166073056390258

Epoch: 6| Step: 6
Training loss: 2.2747387914250434
Validation loss: 2.6045943913468887

Epoch: 6| Step: 7
Training loss: 1.655220935630317
Validation loss: 2.599675866243249

Epoch: 6| Step: 8
Training loss: 1.5837105586101803
Validation loss: 2.59405172653605

Epoch: 6| Step: 9
Training loss: 1.8933369755821834
Validation loss: 2.566122595809134

Epoch: 6| Step: 10
Training loss: 1.7062809253167701
Validation loss: 2.5533623792408897

Epoch: 6| Step: 11
Training loss: 2.2890337528858296
Validation loss: 2.561737350236571

Epoch: 6| Step: 12
Training loss: 2.2622368043010286
Validation loss: 2.576874400751052

Epoch: 6| Step: 13
Training loss: 1.3900011356266788
Validation loss: 2.58658282169478

Epoch: 330| Step: 0
Training loss: 2.079144679420224
Validation loss: 2.5938429605148925

Epoch: 6| Step: 1
Training loss: 1.9840878256309358
Validation loss: 2.598593605354517

Epoch: 6| Step: 2
Training loss: 1.7102924681287952
Validation loss: 2.6007336278413096

Epoch: 6| Step: 3
Training loss: 1.2992803489042801
Validation loss: 2.570610407886722

Epoch: 6| Step: 4
Training loss: 2.1931724027053323
Validation loss: 2.5917176860027427

Epoch: 6| Step: 5
Training loss: 2.007633542646376
Validation loss: 2.569420564099479

Epoch: 6| Step: 6
Training loss: 1.8751158996365271
Validation loss: 2.5349777307729813

Epoch: 6| Step: 7
Training loss: 1.7463360987349694
Validation loss: 2.534518482491301

Epoch: 6| Step: 8
Training loss: 2.1650658219971795
Validation loss: 2.5215869964432143

Epoch: 6| Step: 9
Training loss: 1.937031596999873
Validation loss: 2.5223073721846467

Epoch: 6| Step: 10
Training loss: 1.9246422918318011
Validation loss: 2.558956145812787

Epoch: 6| Step: 11
Training loss: 1.7460557220892188
Validation loss: 2.5881580065904295

Epoch: 6| Step: 12
Training loss: 1.87781332670166
Validation loss: 2.6079816924488166

Epoch: 6| Step: 13
Training loss: 1.5299608681854289
Validation loss: 2.6294376163146396

Epoch: 331| Step: 0
Training loss: 2.0530667603011397
Validation loss: 2.656652472428997

Epoch: 6| Step: 1
Training loss: 2.3210067994668577
Validation loss: 2.6948291142391514

Epoch: 6| Step: 2
Training loss: 1.5277355111180575
Validation loss: 2.678881599088131

Epoch: 6| Step: 3
Training loss: 1.6446533882652443
Validation loss: 2.72448826455739

Epoch: 6| Step: 4
Training loss: 2.0303105455964263
Validation loss: 2.661246145092424

Epoch: 6| Step: 5
Training loss: 1.391180720356595
Validation loss: 2.6731510795942564

Epoch: 6| Step: 6
Training loss: 1.9092041638456598
Validation loss: 2.6012495156195583

Epoch: 6| Step: 7
Training loss: 1.4380649617447738
Validation loss: 2.5735205637889247

Epoch: 6| Step: 8
Training loss: 1.601150310787143
Validation loss: 2.5341135946192233

Epoch: 6| Step: 9
Training loss: 2.0904510471293833
Validation loss: 2.516699914733681

Epoch: 6| Step: 10
Training loss: 2.015389953629731
Validation loss: 2.4760946800666854

Epoch: 6| Step: 11
Training loss: 2.040588976788903
Validation loss: 2.4898951719552063

Epoch: 6| Step: 12
Training loss: 2.0844859812872
Validation loss: 2.4672005535261174

Epoch: 6| Step: 13
Training loss: 2.2896107092051765
Validation loss: 2.500564861062291

Epoch: 332| Step: 0
Training loss: 1.9549040969389675
Validation loss: 2.5057551183144953

Epoch: 6| Step: 1
Training loss: 1.2842793357102118
Validation loss: 2.507123303806152

Epoch: 6| Step: 2
Training loss: 1.4536432142062108
Validation loss: 2.5413153410775333

Epoch: 6| Step: 3
Training loss: 2.505866320534266
Validation loss: 2.6099396207068764

Epoch: 6| Step: 4
Training loss: 2.1546262072613844
Validation loss: 2.6382863751166705

Epoch: 6| Step: 5
Training loss: 2.574763100106004
Validation loss: 2.70648754507474

Epoch: 6| Step: 6
Training loss: 1.94419994482192
Validation loss: 2.704116110385433

Epoch: 6| Step: 7
Training loss: 1.5602438850985922
Validation loss: 2.718354470431791

Epoch: 6| Step: 8
Training loss: 1.3875345758477422
Validation loss: 2.6919594220687837

Epoch: 6| Step: 9
Training loss: 1.598607906084616
Validation loss: 2.6231113178804346

Epoch: 6| Step: 10
Training loss: 1.7159949676777781
Validation loss: 2.5615482423652454

Epoch: 6| Step: 11
Training loss: 2.143197066729889
Validation loss: 2.5347750415843624

Epoch: 6| Step: 12
Training loss: 1.8334910873974595
Validation loss: 2.541019847259415

Epoch: 6| Step: 13
Training loss: 2.157900855529494
Validation loss: 2.513178186316312

Epoch: 333| Step: 0
Training loss: 2.650159967740487
Validation loss: 2.5005951252533416

Epoch: 6| Step: 1
Training loss: 2.21910081695752
Validation loss: 2.504977674962178

Epoch: 6| Step: 2
Training loss: 1.422679128782348
Validation loss: 2.47648779338229

Epoch: 6| Step: 3
Training loss: 1.6006452957886383
Validation loss: 2.512413035733398

Epoch: 6| Step: 4
Training loss: 2.0426151122732854
Validation loss: 2.5323623599237166

Epoch: 6| Step: 5
Training loss: 1.920870820987773
Validation loss: 2.5238903572310933

Epoch: 6| Step: 6
Training loss: 1.2924580559482377
Validation loss: 2.5788156836522957

Epoch: 6| Step: 7
Training loss: 1.2321650362881593
Validation loss: 2.6104700984697526

Epoch: 6| Step: 8
Training loss: 1.9783934304103223
Validation loss: 2.6191776129841484

Epoch: 6| Step: 9
Training loss: 1.9397182686726724
Validation loss: 2.598287986480381

Epoch: 6| Step: 10
Training loss: 2.3779756075520004
Validation loss: 2.6173280592794166

Epoch: 6| Step: 11
Training loss: 1.9133669465243728
Validation loss: 2.600240239635128

Epoch: 6| Step: 12
Training loss: 1.8853417973555444
Validation loss: 2.602035021327062

Epoch: 6| Step: 13
Training loss: 1.4147660839179705
Validation loss: 2.6201175969792123

Epoch: 334| Step: 0
Training loss: 1.5172473836723193
Validation loss: 2.642207587504338

Epoch: 6| Step: 1
Training loss: 1.4706249038949166
Validation loss: 2.6294187336276846

Epoch: 6| Step: 2
Training loss: 1.7697003349042197
Validation loss: 2.6173616949157075

Epoch: 6| Step: 3
Training loss: 1.4580007809714068
Validation loss: 2.633226009386973

Epoch: 6| Step: 4
Training loss: 2.363775330906565
Validation loss: 2.5866348386638336

Epoch: 6| Step: 5
Training loss: 1.7455776740575633
Validation loss: 2.55770945713331

Epoch: 6| Step: 6
Training loss: 1.8602045596857708
Validation loss: 2.5812025563064878

Epoch: 6| Step: 7
Training loss: 1.6572483580577275
Validation loss: 2.547567214977554

Epoch: 6| Step: 8
Training loss: 2.1866414156285416
Validation loss: 2.5384079935670334

Epoch: 6| Step: 9
Training loss: 1.9916175176496331
Validation loss: 2.5358170175753525

Epoch: 6| Step: 10
Training loss: 2.191512977326682
Validation loss: 2.550712985672899

Epoch: 6| Step: 11
Training loss: 1.86629525417846
Validation loss: 2.570063864017108

Epoch: 6| Step: 12
Training loss: 2.2013256760542417
Validation loss: 2.567292453805269

Epoch: 6| Step: 13
Training loss: 1.6178887362660022
Validation loss: 2.620611852395608

Epoch: 335| Step: 0
Training loss: 1.8144725720499828
Validation loss: 2.659589792102603

Epoch: 6| Step: 1
Training loss: 1.4019203503195667
Validation loss: 2.6795111654705885

Epoch: 6| Step: 2
Training loss: 1.667552172346508
Validation loss: 2.6968567409611883

Epoch: 6| Step: 3
Training loss: 1.2531354680183002
Validation loss: 2.706508452046087

Epoch: 6| Step: 4
Training loss: 1.941531140859954
Validation loss: 2.61388516064913

Epoch: 6| Step: 5
Training loss: 1.9711492541977178
Validation loss: 2.5807803572663017

Epoch: 6| Step: 6
Training loss: 2.511805697489055
Validation loss: 2.5154776678123327

Epoch: 6| Step: 7
Training loss: 1.3885144709189146
Validation loss: 2.5209704800544066

Epoch: 6| Step: 8
Training loss: 1.6769762735570721
Validation loss: 2.4969919943583783

Epoch: 6| Step: 9
Training loss: 1.7371334787098585
Validation loss: 2.4876698971081246

Epoch: 6| Step: 10
Training loss: 2.179041065902253
Validation loss: 2.49453730603861

Epoch: 6| Step: 11
Training loss: 2.60577692728587
Validation loss: 2.483969001464493

Epoch: 6| Step: 12
Training loss: 1.9974101703101073
Validation loss: 2.5102729650710227

Epoch: 6| Step: 13
Training loss: 1.7474769387749565
Validation loss: 2.5245304870320995

Epoch: 336| Step: 0
Training loss: 1.7883546586674615
Validation loss: 2.51307913493518

Epoch: 6| Step: 1
Training loss: 2.1211473658408377
Validation loss: 2.5383362342716036

Epoch: 6| Step: 2
Training loss: 1.0325969222901232
Validation loss: 2.5348311942262454

Epoch: 6| Step: 3
Training loss: 1.5614701501129002
Validation loss: 2.550749968901163

Epoch: 6| Step: 4
Training loss: 1.1713716570389539
Validation loss: 2.585502380458523

Epoch: 6| Step: 5
Training loss: 2.1677490123015795
Validation loss: 2.6165900160462194

Epoch: 6| Step: 6
Training loss: 1.3099131750497142
Validation loss: 2.5988641975392017

Epoch: 6| Step: 7
Training loss: 1.650951475293321
Validation loss: 2.627669626913307

Epoch: 6| Step: 8
Training loss: 1.5925385601938642
Validation loss: 2.642145189532664

Epoch: 6| Step: 9
Training loss: 1.8176510063101652
Validation loss: 2.5849463800246886

Epoch: 6| Step: 10
Training loss: 1.851126253266599
Validation loss: 2.6084788414909448

Epoch: 6| Step: 11
Training loss: 2.0821940803910493
Validation loss: 2.5884085274938227

Epoch: 6| Step: 12
Training loss: 1.9052964624121296
Validation loss: 2.6378905002724453

Epoch: 6| Step: 13
Training loss: 2.7802457389349535
Validation loss: 2.6325293595288026

Epoch: 337| Step: 0
Training loss: 1.2155148532262765
Validation loss: 2.6545308253034405

Epoch: 6| Step: 1
Training loss: 2.436822454723012
Validation loss: 2.6576134940787774

Epoch: 6| Step: 2
Training loss: 1.8709417930491332
Validation loss: 2.6361540163695754

Epoch: 6| Step: 3
Training loss: 1.7728320865500602
Validation loss: 2.646489968006563

Epoch: 6| Step: 4
Training loss: 1.6769192617335293
Validation loss: 2.591125907374049

Epoch: 6| Step: 5
Training loss: 1.2605999689827525
Validation loss: 2.605096915352656

Epoch: 6| Step: 6
Training loss: 1.4577937444888929
Validation loss: 2.550624700457602

Epoch: 6| Step: 7
Training loss: 2.028060521774552
Validation loss: 2.5555348055683598

Epoch: 6| Step: 8
Training loss: 2.562516933478254
Validation loss: 2.533136543883248

Epoch: 6| Step: 9
Training loss: 1.3967940407318902
Validation loss: 2.5339553723930464

Epoch: 6| Step: 10
Training loss: 2.019937677271815
Validation loss: 2.5300388892455525

Epoch: 6| Step: 11
Training loss: 1.6191147087793214
Validation loss: 2.5416102533385585

Epoch: 6| Step: 12
Training loss: 1.9386654701718955
Validation loss: 2.5990392077342044

Epoch: 6| Step: 13
Training loss: 2.063904255324477
Validation loss: 2.642741902857026

Epoch: 338| Step: 0
Training loss: 2.1111940805404954
Validation loss: 2.649053931351973

Epoch: 6| Step: 1
Training loss: 1.7574145057254085
Validation loss: 2.6575382175610276

Epoch: 6| Step: 2
Training loss: 2.055598184069091
Validation loss: 2.6582425740771884

Epoch: 6| Step: 3
Training loss: 1.7589056388350353
Validation loss: 2.6378016831154723

Epoch: 6| Step: 4
Training loss: 1.7645045413366622
Validation loss: 2.5850284511395003

Epoch: 6| Step: 5
Training loss: 2.288452275410937
Validation loss: 2.568740294315166

Epoch: 6| Step: 6
Training loss: 2.326353692188629
Validation loss: 2.5745742698995975

Epoch: 6| Step: 7
Training loss: 2.2373185409190257
Validation loss: 2.5725049038152292

Epoch: 6| Step: 8
Training loss: 1.7923443939258374
Validation loss: 2.605225040260708

Epoch: 6| Step: 9
Training loss: 1.3815824565986294
Validation loss: 2.6290810740866832

Epoch: 6| Step: 10
Training loss: 1.6805474497421848
Validation loss: 2.634203037065987

Epoch: 6| Step: 11
Training loss: 1.305496330586262
Validation loss: 2.6418476171122025

Epoch: 6| Step: 12
Training loss: 1.9976819433201773
Validation loss: 2.587887592433856

Epoch: 6| Step: 13
Training loss: 1.1225648591944006
Validation loss: 2.5924494903166266

Epoch: 339| Step: 0
Training loss: 1.9157600193451139
Validation loss: 2.61076384263066

Epoch: 6| Step: 1
Training loss: 2.0685992367485326
Validation loss: 2.5951689397006423

Epoch: 6| Step: 2
Training loss: 1.9278289864463254
Validation loss: 2.623621715010169

Epoch: 6| Step: 3
Training loss: 1.78073641416762
Validation loss: 2.6013480127638315

Epoch: 6| Step: 4
Training loss: 2.076907611582851
Validation loss: 2.60441240804239

Epoch: 6| Step: 5
Training loss: 1.8859578685403287
Validation loss: 2.6113151144817763

Epoch: 6| Step: 6
Training loss: 1.8131147197233388
Validation loss: 2.58572797128086

Epoch: 6| Step: 7
Training loss: 1.9362608115458952
Validation loss: 2.6106808834412933

Epoch: 6| Step: 8
Training loss: 2.3155159743121883
Validation loss: 2.6192717191055346

Epoch: 6| Step: 9
Training loss: 1.6500424350714806
Validation loss: 2.5929081481306535

Epoch: 6| Step: 10
Training loss: 1.995896421111003
Validation loss: 2.581982987761256

Epoch: 6| Step: 11
Training loss: 1.102784257085574
Validation loss: 2.5434305969962008

Epoch: 6| Step: 12
Training loss: 1.6641792650403338
Validation loss: 2.5844399225336288

Epoch: 6| Step: 13
Training loss: 1.6202432262653996
Validation loss: 2.5841131007664297

Epoch: 340| Step: 0
Training loss: 1.5756419069623118
Validation loss: 2.601682169532244

Epoch: 6| Step: 1
Training loss: 2.4794548786086335
Validation loss: 2.5908359412565343

Epoch: 6| Step: 2
Training loss: 1.882352907429723
Validation loss: 2.569660432575499

Epoch: 6| Step: 3
Training loss: 2.0019821834781317
Validation loss: 2.618960593169012

Epoch: 6| Step: 4
Training loss: 1.160084166679652
Validation loss: 2.5976362108112547

Epoch: 6| Step: 5
Training loss: 1.8917931344977732
Validation loss: 2.6138922447978508

Epoch: 6| Step: 6
Training loss: 1.5460295245076705
Validation loss: 2.585289850027024

Epoch: 6| Step: 7
Training loss: 1.7440478053496615
Validation loss: 2.600459853183843

Epoch: 6| Step: 8
Training loss: 1.5180943616254394
Validation loss: 2.573436658774576

Epoch: 6| Step: 9
Training loss: 1.6187101558067654
Validation loss: 2.5505182306859204

Epoch: 6| Step: 10
Training loss: 1.8785867716832476
Validation loss: 2.5476545143374985

Epoch: 6| Step: 11
Training loss: 1.8990576716178513
Validation loss: 2.5551657350589183

Epoch: 6| Step: 12
Training loss: 1.9227011540891608
Validation loss: 2.586433263240586

Epoch: 6| Step: 13
Training loss: 2.046088147528961
Validation loss: 2.5958089507923874

Epoch: 341| Step: 0
Training loss: 1.9571184759441203
Validation loss: 2.626200272883536

Epoch: 6| Step: 1
Training loss: 2.286135524013236
Validation loss: 2.655691753891252

Epoch: 6| Step: 2
Training loss: 1.4308448651218812
Validation loss: 2.6740335367463564

Epoch: 6| Step: 3
Training loss: 1.5266665935655157
Validation loss: 2.639780695842274

Epoch: 6| Step: 4
Training loss: 1.9386478223505719
Validation loss: 2.629254798399466

Epoch: 6| Step: 5
Training loss: 1.4534235821854995
Validation loss: 2.6434118398799473

Epoch: 6| Step: 6
Training loss: 1.6369047582717169
Validation loss: 2.6132889288013508

Epoch: 6| Step: 7
Training loss: 1.7450447771945745
Validation loss: 2.6347836323455716

Epoch: 6| Step: 8
Training loss: 2.106130633947813
Validation loss: 2.584200657072865

Epoch: 6| Step: 9
Training loss: 1.5526918417425328
Validation loss: 2.5868047391362508

Epoch: 6| Step: 10
Training loss: 1.6687703049242348
Validation loss: 2.6154038001884454

Epoch: 6| Step: 11
Training loss: 1.5036096057374948
Validation loss: 2.568625270293443

Epoch: 6| Step: 12
Training loss: 2.489093067199412
Validation loss: 2.5905495013320485

Epoch: 6| Step: 13
Training loss: 1.2165409020957179
Validation loss: 2.5807765849838593

Epoch: 342| Step: 0
Training loss: 2.127876130507184
Validation loss: 2.5677595513879603

Epoch: 6| Step: 1
Training loss: 2.125004487874397
Validation loss: 2.5760767805639957

Epoch: 6| Step: 2
Training loss: 1.7995515874117711
Validation loss: 2.617232349827544

Epoch: 6| Step: 3
Training loss: 1.4278013367612037
Validation loss: 2.5988796326692287

Epoch: 6| Step: 4
Training loss: 1.9896023601267965
Validation loss: 2.6042444039504047

Epoch: 6| Step: 5
Training loss: 1.8769692570115146
Validation loss: 2.6732839843859684

Epoch: 6| Step: 6
Training loss: 1.689927368634814
Validation loss: 2.660574470764853

Epoch: 6| Step: 7
Training loss: 1.8913435398122678
Validation loss: 2.658654982939402

Epoch: 6| Step: 8
Training loss: 1.5652303110616852
Validation loss: 2.6680881069549036

Epoch: 6| Step: 9
Training loss: 1.3664154052427664
Validation loss: 2.6530546678522455

Epoch: 6| Step: 10
Training loss: 1.8808456214409852
Validation loss: 2.6371328673881775

Epoch: 6| Step: 11
Training loss: 2.0957749097604905
Validation loss: 2.6195602061947323

Epoch: 6| Step: 12
Training loss: 1.9438213470219385
Validation loss: 2.576181638755545

Epoch: 6| Step: 13
Training loss: 1.638134182726328
Validation loss: 2.5220489775983874

Epoch: 343| Step: 0
Training loss: 1.6134200140363684
Validation loss: 2.4882440888620714

Epoch: 6| Step: 1
Training loss: 1.7332315885808627
Validation loss: 2.5120002743058754

Epoch: 6| Step: 2
Training loss: 1.395788657009585
Validation loss: 2.505871157025067

Epoch: 6| Step: 3
Training loss: 1.6100509853464389
Validation loss: 2.5308999027477714

Epoch: 6| Step: 4
Training loss: 1.6434716369716125
Validation loss: 2.5353714861849928

Epoch: 6| Step: 5
Training loss: 1.537073234317425
Validation loss: 2.559275404809208

Epoch: 6| Step: 6
Training loss: 2.116162266543444
Validation loss: 2.595813757474103

Epoch: 6| Step: 7
Training loss: 1.9495212113859646
Validation loss: 2.608712772846478

Epoch: 6| Step: 8
Training loss: 2.0864156682157495
Validation loss: 2.6298796697050784

Epoch: 6| Step: 9
Training loss: 1.6947736455064357
Validation loss: 2.6131694866737525

Epoch: 6| Step: 10
Training loss: 2.5341175931698956
Validation loss: 2.6592074815500277

Epoch: 6| Step: 11
Training loss: 2.0483437430125284
Validation loss: 2.6555570558741475

Epoch: 6| Step: 12
Training loss: 1.4580623465762004
Validation loss: 2.6327526263061287

Epoch: 6| Step: 13
Training loss: 1.6668711139532104
Validation loss: 2.616998542303239

Epoch: 344| Step: 0
Training loss: 1.355745974287654
Validation loss: 2.597320412555035

Epoch: 6| Step: 1
Training loss: 1.7824903486292831
Validation loss: 2.563157601994471

Epoch: 6| Step: 2
Training loss: 1.8109572849723388
Validation loss: 2.5963117365812063

Epoch: 6| Step: 3
Training loss: 2.1602322942720917
Validation loss: 2.5526036776547576

Epoch: 6| Step: 4
Training loss: 1.0575599267451592
Validation loss: 2.575299558529475

Epoch: 6| Step: 5
Training loss: 1.9707178846851892
Validation loss: 2.544759171838356

Epoch: 6| Step: 6
Training loss: 1.0869302945497292
Validation loss: 2.523521744745951

Epoch: 6| Step: 7
Training loss: 2.537552698649881
Validation loss: 2.5736418305748283

Epoch: 6| Step: 8
Training loss: 1.317784795942554
Validation loss: 2.606568355616991

Epoch: 6| Step: 9
Training loss: 1.4317646883595265
Validation loss: 2.5431937778835376

Epoch: 6| Step: 10
Training loss: 1.848874100033493
Validation loss: 2.5896399232221072

Epoch: 6| Step: 11
Training loss: 1.6070532486169775
Validation loss: 2.5608688373216877

Epoch: 6| Step: 12
Training loss: 1.367601081417936
Validation loss: 2.5146120926782882

Epoch: 6| Step: 13
Training loss: 2.721749328445011
Validation loss: 2.5682300607595523

Epoch: 345| Step: 0
Training loss: 1.663074038648347
Validation loss: 2.5319341747456736

Epoch: 6| Step: 1
Training loss: 1.6445000797316942
Validation loss: 2.5354583199767

Epoch: 6| Step: 2
Training loss: 1.878253847294694
Validation loss: 2.5019623048739508

Epoch: 6| Step: 3
Training loss: 1.9919529197062293
Validation loss: 2.4917901339182866

Epoch: 6| Step: 4
Training loss: 1.561137940880284
Validation loss: 2.520466995943365

Epoch: 6| Step: 5
Training loss: 1.7052165496323735
Validation loss: 2.546060427970195

Epoch: 6| Step: 6
Training loss: 2.145530592910753
Validation loss: 2.570911774347988

Epoch: 6| Step: 7
Training loss: 1.5418010687450883
Validation loss: 2.5769931196634825

Epoch: 6| Step: 8
Training loss: 1.75120972646275
Validation loss: 2.5773157101844513

Epoch: 6| Step: 9
Training loss: 2.20065450469251
Validation loss: 2.6141557432495097

Epoch: 6| Step: 10
Training loss: 1.870462777100576
Validation loss: 2.655671868333031

Epoch: 6| Step: 11
Training loss: 1.8826152017509499
Validation loss: 2.636718900704085

Epoch: 6| Step: 12
Training loss: 1.438067282820318
Validation loss: 2.666334173713218

Epoch: 6| Step: 13
Training loss: 1.527687521879067
Validation loss: 2.691290983510215

Epoch: 346| Step: 0
Training loss: 2.1733224559971993
Validation loss: 2.645035035058171

Epoch: 6| Step: 1
Training loss: 1.8370241236631626
Validation loss: 2.6488587111084656

Epoch: 6| Step: 2
Training loss: 1.5794071994000545
Validation loss: 2.620724905547751

Epoch: 6| Step: 3
Training loss: 1.5465201539219644
Validation loss: 2.5954951960568744

Epoch: 6| Step: 4
Training loss: 1.5836827076719318
Validation loss: 2.5753819756382157

Epoch: 6| Step: 5
Training loss: 2.3181194383724715
Validation loss: 2.5933440170296835

Epoch: 6| Step: 6
Training loss: 1.5770792754040024
Validation loss: 2.5462235395716797

Epoch: 6| Step: 7
Training loss: 1.588122061254191
Validation loss: 2.5463730955262376

Epoch: 6| Step: 8
Training loss: 1.5112048317948619
Validation loss: 2.5559770010847234

Epoch: 6| Step: 9
Training loss: 2.106028975936787
Validation loss: 2.5918552264669

Epoch: 6| Step: 10
Training loss: 1.4211421377407087
Validation loss: 2.586577460169808

Epoch: 6| Step: 11
Training loss: 1.5048043083889746
Validation loss: 2.5767482279625273

Epoch: 6| Step: 12
Training loss: 1.9210822478543808
Validation loss: 2.5793917385698513

Epoch: 6| Step: 13
Training loss: 1.586038896297773
Validation loss: 2.565100567552136

Epoch: 347| Step: 0
Training loss: 1.692784124780573
Validation loss: 2.6062379508955886

Epoch: 6| Step: 1
Training loss: 1.723918149850518
Validation loss: 2.583242389144621

Epoch: 6| Step: 2
Training loss: 1.1377208264809446
Validation loss: 2.594966557164137

Epoch: 6| Step: 3
Training loss: 1.5475715070975165
Validation loss: 2.604685744369089

Epoch: 6| Step: 4
Training loss: 1.7512156487634871
Validation loss: 2.5960866674877057

Epoch: 6| Step: 5
Training loss: 2.210192875105251
Validation loss: 2.6106958301407

Epoch: 6| Step: 6
Training loss: 1.7808690918667585
Validation loss: 2.63158160828573

Epoch: 6| Step: 7
Training loss: 1.802488630579039
Validation loss: 2.6530247873432105

Epoch: 6| Step: 8
Training loss: 1.6113651155791993
Validation loss: 2.64601222257033

Epoch: 6| Step: 9
Training loss: 2.1096207087073577
Validation loss: 2.6737997398606703

Epoch: 6| Step: 10
Training loss: 1.9799413938229669
Validation loss: 2.6387747427585837

Epoch: 6| Step: 11
Training loss: 1.157050190937344
Validation loss: 2.6557410855925747

Epoch: 6| Step: 12
Training loss: 1.1176946595923678
Validation loss: 2.66280726956634

Epoch: 6| Step: 13
Training loss: 2.2513060487911205
Validation loss: 2.6200825786923345

Epoch: 348| Step: 0
Training loss: 1.767413895707059
Validation loss: 2.622055657959708

Epoch: 6| Step: 1
Training loss: 2.2287732308931956
Validation loss: 2.6476744806407373

Epoch: 6| Step: 2
Training loss: 1.6572836763232097
Validation loss: 2.5609359309851305

Epoch: 6| Step: 3
Training loss: 1.5268799060394505
Validation loss: 2.608870482258884

Epoch: 6| Step: 4
Training loss: 1.5238703968528358
Validation loss: 2.5450663473128405

Epoch: 6| Step: 5
Training loss: 1.5402198738578399
Validation loss: 2.5717269576746133

Epoch: 6| Step: 6
Training loss: 1.1868795480585768
Validation loss: 2.5547819440923627

Epoch: 6| Step: 7
Training loss: 2.3968924351422385
Validation loss: 2.5955865631454107

Epoch: 6| Step: 8
Training loss: 2.3629325672525683
Validation loss: 2.5699268658569197

Epoch: 6| Step: 9
Training loss: 1.0680964563081499
Validation loss: 2.598443086625404

Epoch: 6| Step: 10
Training loss: 1.4749428883503468
Validation loss: 2.555091040545139

Epoch: 6| Step: 11
Training loss: 1.4602288960305128
Validation loss: 2.5698164564611377

Epoch: 6| Step: 12
Training loss: 1.7013484543474189
Validation loss: 2.636388235216568

Epoch: 6| Step: 13
Training loss: 1.5859976320188915
Validation loss: 2.6330156710117656

Epoch: 349| Step: 0
Training loss: 1.7710633371616842
Validation loss: 2.624670537830289

Epoch: 6| Step: 1
Training loss: 1.8303036220049298
Validation loss: 2.616219754433806

Epoch: 6| Step: 2
Training loss: 1.7939571407220973
Validation loss: 2.5960721800531115

Epoch: 6| Step: 3
Training loss: 1.5444112867154849
Validation loss: 2.6134589058361533

Epoch: 6| Step: 4
Training loss: 1.4739199612029381
Validation loss: 2.6359534539940435

Epoch: 6| Step: 5
Training loss: 1.6419275834891767
Validation loss: 2.5879142251528062

Epoch: 6| Step: 6
Training loss: 1.7641375192076227
Validation loss: 2.6216856453514388

Epoch: 6| Step: 7
Training loss: 1.7405715084931095
Validation loss: 2.6544696900373808

Epoch: 6| Step: 8
Training loss: 1.5817855078960965
Validation loss: 2.607378014661146

Epoch: 6| Step: 9
Training loss: 1.8715680821250005
Validation loss: 2.658574250544235

Epoch: 6| Step: 10
Training loss: 1.8938290267922675
Validation loss: 2.5979729404386225

Epoch: 6| Step: 11
Training loss: 1.9053119164769883
Validation loss: 2.5856534066167813

Epoch: 6| Step: 12
Training loss: 1.6937342034198006
Validation loss: 2.6180436740901323

Epoch: 6| Step: 13
Training loss: 1.8495768913792212
Validation loss: 2.5972387604575045

Epoch: 350| Step: 0
Training loss: 1.3475863673570507
Validation loss: 2.589784923593071

Epoch: 6| Step: 1
Training loss: 1.7380958029589946
Validation loss: 2.626083014370892

Epoch: 6| Step: 2
Training loss: 1.459855602126059
Validation loss: 2.6257037324518877

Epoch: 6| Step: 3
Training loss: 2.24484042817605
Validation loss: 2.616938033479465

Epoch: 6| Step: 4
Training loss: 2.240366658277008
Validation loss: 2.6587992982250053

Epoch: 6| Step: 5
Training loss: 1.873923946600182
Validation loss: 2.6325003630422623

Epoch: 6| Step: 6
Training loss: 1.854084084489805
Validation loss: 2.580006015336863

Epoch: 6| Step: 7
Training loss: 1.5052926942972789
Validation loss: 2.598852248437995

Epoch: 6| Step: 8
Training loss: 1.6834730914927847
Validation loss: 2.5708444696079056

Epoch: 6| Step: 9
Training loss: 1.6852011386797772
Validation loss: 2.5927200570511326

Epoch: 6| Step: 10
Training loss: 1.268613653890186
Validation loss: 2.55054064984394

Epoch: 6| Step: 11
Training loss: 1.8002131097523681
Validation loss: 2.531478989215767

Epoch: 6| Step: 12
Training loss: 1.5844166044833348
Validation loss: 2.5558592804730864

Epoch: 6| Step: 13
Training loss: 1.5670555842704226
Validation loss: 2.568187233071873

Epoch: 351| Step: 0
Training loss: 1.969433862501996
Validation loss: 2.5868316364609236

Epoch: 6| Step: 1
Training loss: 0.922242010736024
Validation loss: 2.536176001301354

Epoch: 6| Step: 2
Training loss: 2.10869491351434
Validation loss: 2.5781650886886744

Epoch: 6| Step: 3
Training loss: 1.8796164584033317
Validation loss: 2.5939499957947127

Epoch: 6| Step: 4
Training loss: 1.500451894083696
Validation loss: 2.5899803160136674

Epoch: 6| Step: 5
Training loss: 1.7195966542625134
Validation loss: 2.5575225218287434

Epoch: 6| Step: 6
Training loss: 1.4968157189084634
Validation loss: 2.5652581699569508

Epoch: 6| Step: 7
Training loss: 2.3452776190230713
Validation loss: 2.5789925550895956

Epoch: 6| Step: 8
Training loss: 1.6361622012066
Validation loss: 2.5788219242047785

Epoch: 6| Step: 9
Training loss: 1.349584686892613
Validation loss: 2.5951070261318234

Epoch: 6| Step: 10
Training loss: 2.149438465331715
Validation loss: 2.5937136605409608

Epoch: 6| Step: 11
Training loss: 1.2298849991792138
Validation loss: 2.558413169642332

Epoch: 6| Step: 12
Training loss: 1.5868976862135786
Validation loss: 2.6081104069549936

Epoch: 6| Step: 13
Training loss: 1.641040713003373
Validation loss: 2.580553964364125

Epoch: 352| Step: 0
Training loss: 1.801167279156737
Validation loss: 2.572645541177598

Epoch: 6| Step: 1
Training loss: 1.52473926191275
Validation loss: 2.635401350034652

Epoch: 6| Step: 2
Training loss: 1.4640127851417808
Validation loss: 2.6601310052854856

Epoch: 6| Step: 3
Training loss: 2.0172193269117296
Validation loss: 2.61837805243786

Epoch: 6| Step: 4
Training loss: 0.9491341007619777
Validation loss: 2.616346203158734

Epoch: 6| Step: 5
Training loss: 1.415270968666123
Validation loss: 2.6224896825509267

Epoch: 6| Step: 6
Training loss: 1.8745139445683907
Validation loss: 2.5742168513335892

Epoch: 6| Step: 7
Training loss: 1.4719043704461663
Validation loss: 2.600004430302489

Epoch: 6| Step: 8
Training loss: 2.2751270845570386
Validation loss: 2.6011191478143214

Epoch: 6| Step: 9
Training loss: 2.4418317988498943
Validation loss: 2.581597272959434

Epoch: 6| Step: 10
Training loss: 1.6261714234306814
Validation loss: 2.5991197483695405

Epoch: 6| Step: 11
Training loss: 1.2909272548884931
Validation loss: 2.5702274080393077

Epoch: 6| Step: 12
Training loss: 1.6268378648538824
Validation loss: 2.570982176203689

Epoch: 6| Step: 13
Training loss: 1.7616576461176088
Validation loss: 2.553157601056926

Epoch: 353| Step: 0
Training loss: 1.8293551357325963
Validation loss: 2.5393413840480314

Epoch: 6| Step: 1
Training loss: 1.0173110464982937
Validation loss: 2.5807662535208595

Epoch: 6| Step: 2
Training loss: 2.2258985098214588
Validation loss: 2.5937614440665504

Epoch: 6| Step: 3
Training loss: 2.056987562921782
Validation loss: 2.642974981604527

Epoch: 6| Step: 4
Training loss: 1.3195051173710437
Validation loss: 2.6184557522574154

Epoch: 6| Step: 5
Training loss: 1.8485837386802264
Validation loss: 2.627529310830611

Epoch: 6| Step: 6
Training loss: 1.5313502687595293
Validation loss: 2.5999469342073844

Epoch: 6| Step: 7
Training loss: 2.3457979537256333
Validation loss: 2.6294928203832195

Epoch: 6| Step: 8
Training loss: 1.653680211308091
Validation loss: 2.5912033662527025

Epoch: 6| Step: 9
Training loss: 1.3389848452900588
Validation loss: 2.5872222229148436

Epoch: 6| Step: 10
Training loss: 1.5102343306704977
Validation loss: 2.6064876182784547

Epoch: 6| Step: 11
Training loss: 1.7931640784551655
Validation loss: 2.5708239277482643

Epoch: 6| Step: 12
Training loss: 1.816371138038491
Validation loss: 2.5610583056727028

Epoch: 6| Step: 13
Training loss: 1.5592763070655962
Validation loss: 2.571989090444981

Epoch: 354| Step: 0
Training loss: 1.615364115623379
Validation loss: 2.6034350524629533

Epoch: 6| Step: 1
Training loss: 1.581380451234307
Validation loss: 2.5656499808021103

Epoch: 6| Step: 2
Training loss: 2.0107177614318963
Validation loss: 2.569131025037616

Epoch: 6| Step: 3
Training loss: 1.367448967045928
Validation loss: 2.5340254053720543

Epoch: 6| Step: 4
Training loss: 1.6856429159975388
Validation loss: 2.5800506028183303

Epoch: 6| Step: 5
Training loss: 2.071353405965183
Validation loss: 2.5716847599288837

Epoch: 6| Step: 6
Training loss: 1.8193175908226842
Validation loss: 2.5714121034639827

Epoch: 6| Step: 7
Training loss: 1.1665301186261967
Validation loss: 2.6147794966548337

Epoch: 6| Step: 8
Training loss: 0.9027639624361808
Validation loss: 2.5666755368545973

Epoch: 6| Step: 9
Training loss: 1.4655480077891565
Validation loss: 2.59353540291128

Epoch: 6| Step: 10
Training loss: 2.156389757132965
Validation loss: 2.6095224822314136

Epoch: 6| Step: 11
Training loss: 2.030641552689453
Validation loss: 2.616971605800141

Epoch: 6| Step: 12
Training loss: 1.7458201627151069
Validation loss: 2.642478006801311

Epoch: 6| Step: 13
Training loss: 1.7197551909039948
Validation loss: 2.648293775411478

Epoch: 355| Step: 0
Training loss: 1.769027941537576
Validation loss: 2.6251824179344663

Epoch: 6| Step: 1
Training loss: 1.9826510292241224
Validation loss: 2.658153883837411

Epoch: 6| Step: 2
Training loss: 1.4027233831898647
Validation loss: 2.615563909135488

Epoch: 6| Step: 3
Training loss: 1.1812495317407719
Validation loss: 2.6225987986890393

Epoch: 6| Step: 4
Training loss: 1.533360642037947
Validation loss: 2.6373559252543064

Epoch: 6| Step: 5
Training loss: 2.0098474780616566
Validation loss: 2.6388225084176464

Epoch: 6| Step: 6
Training loss: 1.6461627324753685
Validation loss: 2.632922780550558

Epoch: 6| Step: 7
Training loss: 2.111927437922941
Validation loss: 2.6179483702619692

Epoch: 6| Step: 8
Training loss: 1.4905341610530478
Validation loss: 2.6564033912799028

Epoch: 6| Step: 9
Training loss: 1.8020965340485469
Validation loss: 2.640038344244457

Epoch: 6| Step: 10
Training loss: 1.9546151541930132
Validation loss: 2.647000721089133

Epoch: 6| Step: 11
Training loss: 1.6156207617698581
Validation loss: 2.668105591540839

Epoch: 6| Step: 12
Training loss: 1.0892911214046594
Validation loss: 2.65496388134811

Epoch: 6| Step: 13
Training loss: 1.2114052146140617
Validation loss: 2.6529688597115806

Epoch: 356| Step: 0
Training loss: 1.2118615839167868
Validation loss: 2.6261972845549453

Epoch: 6| Step: 1
Training loss: 1.882036864516584
Validation loss: 2.6365301220144537

Epoch: 6| Step: 2
Training loss: 2.014566779504227
Validation loss: 2.5959876033524196

Epoch: 6| Step: 3
Training loss: 1.8708587052876968
Validation loss: 2.6111056590417885

Epoch: 6| Step: 4
Training loss: 1.9230774010144154
Validation loss: 2.6073349460774664

Epoch: 6| Step: 5
Training loss: 1.4219756876748986
Validation loss: 2.588799328839805

Epoch: 6| Step: 6
Training loss: 1.173192771047463
Validation loss: 2.6193939928455303

Epoch: 6| Step: 7
Training loss: 1.8107809925663432
Validation loss: 2.545872574882022

Epoch: 6| Step: 8
Training loss: 1.8771144388763792
Validation loss: 2.5806313864118557

Epoch: 6| Step: 9
Training loss: 1.427856440094482
Validation loss: 2.5590118920707186

Epoch: 6| Step: 10
Training loss: 1.5650855987344483
Validation loss: 2.5488692512945628

Epoch: 6| Step: 11
Training loss: 1.2486275768125508
Validation loss: 2.5507686472528364

Epoch: 6| Step: 12
Training loss: 2.0822342707433417
Validation loss: 2.5900969537363134

Epoch: 6| Step: 13
Training loss: 1.2150534789164187
Validation loss: 2.5520425494821337

Epoch: 357| Step: 0
Training loss: 1.4086545096446164
Validation loss: 2.533300989555216

Epoch: 6| Step: 1
Training loss: 0.9732851806306493
Validation loss: 2.509088431306017

Epoch: 6| Step: 2
Training loss: 0.9599523068541641
Validation loss: 2.538321675528266

Epoch: 6| Step: 3
Training loss: 1.589815781555856
Validation loss: 2.538335451545591

Epoch: 6| Step: 4
Training loss: 2.0472644697454285
Validation loss: 2.5689406826159606

Epoch: 6| Step: 5
Training loss: 1.9196893312525285
Validation loss: 2.5326158425641414

Epoch: 6| Step: 6
Training loss: 1.5165966891120186
Validation loss: 2.594304542549702

Epoch: 6| Step: 7
Training loss: 1.2486721615593193
Validation loss: 2.569749764754263

Epoch: 6| Step: 8
Training loss: 1.4510520998581289
Validation loss: 2.582379170040978

Epoch: 6| Step: 9
Training loss: 1.860179054091635
Validation loss: 2.624941749531953

Epoch: 6| Step: 10
Training loss: 2.3435345359944937
Validation loss: 2.66520790095522

Epoch: 6| Step: 11
Training loss: 1.7346029733203734
Validation loss: 2.6523367685517316

Epoch: 6| Step: 12
Training loss: 1.8370757774543147
Validation loss: 2.6069029864419604

Epoch: 6| Step: 13
Training loss: 2.0950899533645826
Validation loss: 2.5845063120437173

Epoch: 358| Step: 0
Training loss: 1.77856041483005
Validation loss: 2.5704179643601015

Epoch: 6| Step: 1
Training loss: 1.4839732379299615
Validation loss: 2.5489293883415445

Epoch: 6| Step: 2
Training loss: 1.2953353382853567
Validation loss: 2.5507081718939757

Epoch: 6| Step: 3
Training loss: 1.8110333790054303
Validation loss: 2.5798205416264683

Epoch: 6| Step: 4
Training loss: 1.7079302692205127
Validation loss: 2.5899643292173833

Epoch: 6| Step: 5
Training loss: 1.8987129545333514
Validation loss: 2.628614147749382

Epoch: 6| Step: 6
Training loss: 1.6250250887768019
Validation loss: 2.645336845452659

Epoch: 6| Step: 7
Training loss: 1.5204806855219062
Validation loss: 2.6381396724723993

Epoch: 6| Step: 8
Training loss: 2.4575842885399313
Validation loss: 2.6967428051967004

Epoch: 6| Step: 9
Training loss: 1.2682001735916344
Validation loss: 2.6868859188322056

Epoch: 6| Step: 10
Training loss: 1.7074866483956654
Validation loss: 2.6685752793590902

Epoch: 6| Step: 11
Training loss: 1.409854423366707
Validation loss: 2.6183213240430825

Epoch: 6| Step: 12
Training loss: 1.519501045927119
Validation loss: 2.5916587641392113

Epoch: 6| Step: 13
Training loss: 1.3672384198106946
Validation loss: 2.568547888583322

Epoch: 359| Step: 0
Training loss: 1.901099391391812
Validation loss: 2.5202614369336755

Epoch: 6| Step: 1
Training loss: 1.7223474480963796
Validation loss: 2.5193639891943835

Epoch: 6| Step: 2
Training loss: 1.1352463457409534
Validation loss: 2.4985284766070084

Epoch: 6| Step: 3
Training loss: 1.3540344124792092
Validation loss: 2.5584681356330794

Epoch: 6| Step: 4
Training loss: 1.6853069607647009
Validation loss: 2.569113934083279

Epoch: 6| Step: 5
Training loss: 1.514178972517922
Validation loss: 2.6021710391467114

Epoch: 6| Step: 6
Training loss: 1.9441570236069374
Validation loss: 2.623538064307201

Epoch: 6| Step: 7
Training loss: 1.201574738716726
Validation loss: 2.679256378578186

Epoch: 6| Step: 8
Training loss: 1.5789065550247494
Validation loss: 2.6439405614594125

Epoch: 6| Step: 9
Training loss: 2.3565762321821753
Validation loss: 2.6601486317977825

Epoch: 6| Step: 10
Training loss: 1.6202455070867696
Validation loss: 2.6987563241799415

Epoch: 6| Step: 11
Training loss: 1.4427073326061464
Validation loss: 2.677342789442656

Epoch: 6| Step: 12
Training loss: 1.4048073468197595
Validation loss: 2.700114659535662

Epoch: 6| Step: 13
Training loss: 1.8497946625241428
Validation loss: 2.6798159584269654

Epoch: 360| Step: 0
Training loss: 1.765534592736031
Validation loss: 2.6683126128387182

Epoch: 6| Step: 1
Training loss: 1.6810876023376649
Validation loss: 2.6460534902775557

Epoch: 6| Step: 2
Training loss: 1.0322064097303956
Validation loss: 2.6568171624937356

Epoch: 6| Step: 3
Training loss: 2.0380625410432365
Validation loss: 2.6269678883569045

Epoch: 6| Step: 4
Training loss: 1.9554329015758396
Validation loss: 2.6025597815437385

Epoch: 6| Step: 5
Training loss: 1.2871211837203698
Validation loss: 2.5739957783310463

Epoch: 6| Step: 6
Training loss: 1.7114170743582013
Validation loss: 2.593527726910099

Epoch: 6| Step: 7
Training loss: 1.6716642157757566
Validation loss: 2.544564304716867

Epoch: 6| Step: 8
Training loss: 1.790200417130172
Validation loss: 2.556790993671167

Epoch: 6| Step: 9
Training loss: 2.1667389001787574
Validation loss: 2.5753818444888696

Epoch: 6| Step: 10
Training loss: 1.177391951396318
Validation loss: 2.5829119082207703

Epoch: 6| Step: 11
Training loss: 1.7639248519728932
Validation loss: 2.59950347463047

Epoch: 6| Step: 12
Training loss: 1.2763875012579897
Validation loss: 2.617389803986361

Epoch: 6| Step: 13
Training loss: 1.5852235587068157
Validation loss: 2.6510350590132012

Epoch: 361| Step: 0
Training loss: 1.047968677471267
Validation loss: 2.64563372502344

Epoch: 6| Step: 1
Training loss: 1.6615542998944701
Validation loss: 2.6633962504753788

Epoch: 6| Step: 2
Training loss: 1.9943539078522712
Validation loss: 2.6437325785899333

Epoch: 6| Step: 3
Training loss: 1.9423184928390378
Validation loss: 2.6171295007760302

Epoch: 6| Step: 4
Training loss: 1.5999969273776116
Validation loss: 2.6261379106783984

Epoch: 6| Step: 5
Training loss: 1.3941993639011927
Validation loss: 2.5746260819037508

Epoch: 6| Step: 6
Training loss: 2.355278551510691
Validation loss: 2.5268350725072564

Epoch: 6| Step: 7
Training loss: 1.5976487884720323
Validation loss: 2.503478697616896

Epoch: 6| Step: 8
Training loss: 1.654080391402771
Validation loss: 2.5301551648884426

Epoch: 6| Step: 9
Training loss: 1.885675050793821
Validation loss: 2.590270761429798

Epoch: 6| Step: 10
Training loss: 1.548412137252079
Validation loss: 2.659576248222459

Epoch: 6| Step: 11
Training loss: 2.028090852000296
Validation loss: 2.7072517558423366

Epoch: 6| Step: 12
Training loss: 1.70304044461118
Validation loss: 2.7468581169110102

Epoch: 6| Step: 13
Training loss: 1.4584291517477717
Validation loss: 2.766602998789926

Epoch: 362| Step: 0
Training loss: 2.2212516758042486
Validation loss: 2.7866797290918695

Epoch: 6| Step: 1
Training loss: 1.7995692744423166
Validation loss: 2.696496439945515

Epoch: 6| Step: 2
Training loss: 1.4796670237557454
Validation loss: 2.630724160755998

Epoch: 6| Step: 3
Training loss: 1.4711640181652474
Validation loss: 2.587967996460335

Epoch: 6| Step: 4
Training loss: 1.2477855140066516
Validation loss: 2.6139009935430044

Epoch: 6| Step: 5
Training loss: 1.6131191218378802
Validation loss: 2.626102723003628

Epoch: 6| Step: 6
Training loss: 1.4008654184579648
Validation loss: 2.598959581964737

Epoch: 6| Step: 7
Training loss: 1.377852818259743
Validation loss: 2.625660858526905

Epoch: 6| Step: 8
Training loss: 1.8765154118788039
Validation loss: 2.5929462918830635

Epoch: 6| Step: 9
Training loss: 1.7900168193261368
Validation loss: 2.6155475393817236

Epoch: 6| Step: 10
Training loss: 1.6619530143660648
Validation loss: 2.6047260726272494

Epoch: 6| Step: 11
Training loss: 2.0332293916410915
Validation loss: 2.6108598424753042

Epoch: 6| Step: 12
Training loss: 1.635494238437171
Validation loss: 2.5995321665972018

Epoch: 6| Step: 13
Training loss: 1.293564489213157
Validation loss: 2.6454843055616686

Epoch: 363| Step: 0
Training loss: 1.6568013119364968
Validation loss: 2.6440998816829895

Epoch: 6| Step: 1
Training loss: 1.602072434539167
Validation loss: 2.649757183994383

Epoch: 6| Step: 2
Training loss: 1.580308668672437
Validation loss: 2.661837352382855

Epoch: 6| Step: 3
Training loss: 1.894205155771058
Validation loss: 2.6562979450760675

Epoch: 6| Step: 4
Training loss: 1.6255279563675222
Validation loss: 2.680144142264824

Epoch: 6| Step: 5
Training loss: 1.5846712666836484
Validation loss: 2.695775457603089

Epoch: 6| Step: 6
Training loss: 1.667448369131921
Validation loss: 2.676633616473411

Epoch: 6| Step: 7
Training loss: 1.3743526495434157
Validation loss: 2.647927519273065

Epoch: 6| Step: 8
Training loss: 2.137524998390404
Validation loss: 2.6361449118768463

Epoch: 6| Step: 9
Training loss: 1.3086081888341712
Validation loss: 2.564798866860724

Epoch: 6| Step: 10
Training loss: 1.3943148319492147
Validation loss: 2.576652075276713

Epoch: 6| Step: 11
Training loss: 1.7211745760480344
Validation loss: 2.5695037342367795

Epoch: 6| Step: 12
Training loss: 1.6541114532070496
Validation loss: 2.5938744495977013

Epoch: 6| Step: 13
Training loss: 1.7230776316843044
Validation loss: 2.556445497780015

Epoch: 364| Step: 0
Training loss: 1.3083436185995403
Validation loss: 2.567053958440144

Epoch: 6| Step: 1
Training loss: 1.6281033739641586
Validation loss: 2.5560906588286976

Epoch: 6| Step: 2
Training loss: 1.5629612051261055
Validation loss: 2.5680015479085148

Epoch: 6| Step: 3
Training loss: 1.7118131582810479
Validation loss: 2.5868799464874397

Epoch: 6| Step: 4
Training loss: 1.9825544040522205
Validation loss: 2.626398017025107

Epoch: 6| Step: 5
Training loss: 1.4620504780677344
Validation loss: 2.577296545840035

Epoch: 6| Step: 6
Training loss: 1.8838511407806955
Validation loss: 2.580476247414902

Epoch: 6| Step: 7
Training loss: 1.7270119888914437
Validation loss: 2.5955667682364507

Epoch: 6| Step: 8
Training loss: 1.6228816823979701
Validation loss: 2.5976457715121914

Epoch: 6| Step: 9
Training loss: 1.422741133594385
Validation loss: 2.62653681258198

Epoch: 6| Step: 10
Training loss: 1.402471084976641
Validation loss: 2.642313084699899

Epoch: 6| Step: 11
Training loss: 1.375314416483155
Validation loss: 2.6249497121202294

Epoch: 6| Step: 12
Training loss: 1.7897079169799148
Validation loss: 2.6378869904245903

Epoch: 6| Step: 13
Training loss: 1.9504793482716134
Validation loss: 2.607155196402676

Epoch: 365| Step: 0
Training loss: 1.4120872147590164
Validation loss: 2.5797455443597537

Epoch: 6| Step: 1
Training loss: 1.9887906903912156
Validation loss: 2.5471452596924253

Epoch: 6| Step: 2
Training loss: 1.6235333940309986
Validation loss: 2.55208633318874

Epoch: 6| Step: 3
Training loss: 1.1983246094850806
Validation loss: 2.5513195192346654

Epoch: 6| Step: 4
Training loss: 1.8550172919112626
Validation loss: 2.582285596792441

Epoch: 6| Step: 5
Training loss: 1.8068232593497748
Validation loss: 2.612373844550412

Epoch: 6| Step: 6
Training loss: 1.3486145150879054
Validation loss: 2.65982137206959

Epoch: 6| Step: 7
Training loss: 1.7439336536456516
Validation loss: 2.642151506097194

Epoch: 6| Step: 8
Training loss: 1.7071369758180865
Validation loss: 2.663105424511959

Epoch: 6| Step: 9
Training loss: 2.051306666324331
Validation loss: 2.5961644222265083

Epoch: 6| Step: 10
Training loss: 1.2301846615255112
Validation loss: 2.590126938869679

Epoch: 6| Step: 11
Training loss: 2.039801452735842
Validation loss: 2.58951624453229

Epoch: 6| Step: 12
Training loss: 1.240035874709194
Validation loss: 2.5538674845709157

Epoch: 6| Step: 13
Training loss: 1.286508422782478
Validation loss: 2.546868712372615

Epoch: 366| Step: 0
Training loss: 1.9163295477016178
Validation loss: 2.5014098801321323

Epoch: 6| Step: 1
Training loss: 1.7801585952956291
Validation loss: 2.5448718472274856

Epoch: 6| Step: 2
Training loss: 2.114532946156976
Validation loss: 2.557510200895299

Epoch: 6| Step: 3
Training loss: 2.137486070732552
Validation loss: 2.5706785148196536

Epoch: 6| Step: 4
Training loss: 1.5657430943095134
Validation loss: 2.56211524493939

Epoch: 6| Step: 5
Training loss: 1.8310276039663673
Validation loss: 2.609060089540314

Epoch: 6| Step: 6
Training loss: 1.213845631046653
Validation loss: 2.6511379191993805

Epoch: 6| Step: 7
Training loss: 1.623832136254292
Validation loss: 2.6818860954150567

Epoch: 6| Step: 8
Training loss: 1.6243804337402203
Validation loss: 2.6558796942400633

Epoch: 6| Step: 9
Training loss: 1.1416797203282971
Validation loss: 2.6818592550123266

Epoch: 6| Step: 10
Training loss: 1.4061701434031681
Validation loss: 2.6250942909623407

Epoch: 6| Step: 11
Training loss: 1.1981427463098766
Validation loss: 2.581868884607954

Epoch: 6| Step: 12
Training loss: 1.160083293226353
Validation loss: 2.587019948303182

Epoch: 6| Step: 13
Training loss: 1.1607601764536035
Validation loss: 2.585550484791885

Epoch: 367| Step: 0
Training loss: 1.910329237517798
Validation loss: 2.5677448035404153

Epoch: 6| Step: 1
Training loss: 1.36463782029412
Validation loss: 2.549156727076749

Epoch: 6| Step: 2
Training loss: 1.4029839629591048
Validation loss: 2.5514137998733175

Epoch: 6| Step: 3
Training loss: 1.0024932535757862
Validation loss: 2.5908961701362476

Epoch: 6| Step: 4
Training loss: 1.5105759986060607
Validation loss: 2.600013019455811

Epoch: 6| Step: 5
Training loss: 1.9558025469941949
Validation loss: 2.560529385334092

Epoch: 6| Step: 6
Training loss: 1.0791530406980294
Validation loss: 2.620743737157454

Epoch: 6| Step: 7
Training loss: 1.4795263506781737
Validation loss: 2.6373043512031833

Epoch: 6| Step: 8
Training loss: 1.6405960080446187
Validation loss: 2.629796459821505

Epoch: 6| Step: 9
Training loss: 1.5847492746549174
Validation loss: 2.6909580900306556

Epoch: 6| Step: 10
Training loss: 1.728254498946455
Validation loss: 2.7061403982097447

Epoch: 6| Step: 11
Training loss: 2.1142927699910268
Validation loss: 2.7018151610236325

Epoch: 6| Step: 12
Training loss: 1.4746441363349003
Validation loss: 2.668067703162049

Epoch: 6| Step: 13
Training loss: 1.9838862380398754
Validation loss: 2.6621571697703446

Epoch: 368| Step: 0
Training loss: 1.470865065941064
Validation loss: 2.608422537630069

Epoch: 6| Step: 1
Training loss: 1.7781427285327962
Validation loss: 2.603681478442689

Epoch: 6| Step: 2
Training loss: 1.0047367683065231
Validation loss: 2.6125921339614213

Epoch: 6| Step: 3
Training loss: 1.722658879630575
Validation loss: 2.6557201380606443

Epoch: 6| Step: 4
Training loss: 1.497963476532845
Validation loss: 2.649387245590876

Epoch: 6| Step: 5
Training loss: 1.9660563130662003
Validation loss: 2.6357857567586596

Epoch: 6| Step: 6
Training loss: 1.850558109124537
Validation loss: 2.6219402979531163

Epoch: 6| Step: 7
Training loss: 1.8504460183747444
Validation loss: 2.6338590660499737

Epoch: 6| Step: 8
Training loss: 1.7625719529202748
Validation loss: 2.6268080736314934

Epoch: 6| Step: 9
Training loss: 1.933027581449823
Validation loss: 2.646533022500299

Epoch: 6| Step: 10
Training loss: 1.5071426247613995
Validation loss: 2.6255601103713504

Epoch: 6| Step: 11
Training loss: 1.782298465480207
Validation loss: 2.6619113952054607

Epoch: 6| Step: 12
Training loss: 1.331846341809797
Validation loss: 2.6747384891254598

Epoch: 6| Step: 13
Training loss: 1.4549593268933048
Validation loss: 2.6857092458016782

Epoch: 369| Step: 0
Training loss: 1.8302306088297158
Validation loss: 2.7285451739528654

Epoch: 6| Step: 1
Training loss: 1.211146970289972
Validation loss: 2.7281324062414383

Epoch: 6| Step: 2
Training loss: 1.9756714995142588
Validation loss: 2.7098090968394213

Epoch: 6| Step: 3
Training loss: 1.142384569776869
Validation loss: 2.6810648856473103

Epoch: 6| Step: 4
Training loss: 2.0964861399808576
Validation loss: 2.6523576978598578

Epoch: 6| Step: 5
Training loss: 1.720973085666224
Validation loss: 2.629958525525235

Epoch: 6| Step: 6
Training loss: 1.1542805575332487
Validation loss: 2.670736773129549

Epoch: 6| Step: 7
Training loss: 2.040433459325448
Validation loss: 2.6459717051049707

Epoch: 6| Step: 8
Training loss: 1.9420103058271454
Validation loss: 2.6297659826174087

Epoch: 6| Step: 9
Training loss: 1.7070768511724115
Validation loss: 2.6608179644594694

Epoch: 6| Step: 10
Training loss: 1.326075239972635
Validation loss: 2.6232750992893434

Epoch: 6| Step: 11
Training loss: 1.0751475255119085
Validation loss: 2.623526341181915

Epoch: 6| Step: 12
Training loss: 1.5342643806687355
Validation loss: 2.6512708483686658

Epoch: 6| Step: 13
Training loss: 1.3598693737941392
Validation loss: 2.634649071968006

Epoch: 370| Step: 0
Training loss: 1.1325253879151942
Validation loss: 2.685596028196011

Epoch: 6| Step: 1
Training loss: 1.2867741473837286
Validation loss: 2.7188231359707715

Epoch: 6| Step: 2
Training loss: 1.3623253386651593
Validation loss: 2.7183253661864764

Epoch: 6| Step: 3
Training loss: 1.4228236628345239
Validation loss: 2.7348412543096923

Epoch: 6| Step: 4
Training loss: 1.2535139284155121
Validation loss: 2.720621225074155

Epoch: 6| Step: 5
Training loss: 1.3376886145677056
Validation loss: 2.6889750624366053

Epoch: 6| Step: 6
Training loss: 1.288711962577928
Validation loss: 2.657750820196984

Epoch: 6| Step: 7
Training loss: 1.4015056687892624
Validation loss: 2.6699775665807595

Epoch: 6| Step: 8
Training loss: 2.3937227212731034
Validation loss: 2.6320618899894397

Epoch: 6| Step: 9
Training loss: 1.495499774362744
Validation loss: 2.5984835194152

Epoch: 6| Step: 10
Training loss: 2.350524369032945
Validation loss: 2.6186982458519275

Epoch: 6| Step: 11
Training loss: 1.433856659358313
Validation loss: 2.6237068245533814

Epoch: 6| Step: 12
Training loss: 1.2749614373153548
Validation loss: 2.6468154606283485

Epoch: 6| Step: 13
Training loss: 1.9273522953977436
Validation loss: 2.6437969531255376

Epoch: 371| Step: 0
Training loss: 1.410419048643519
Validation loss: 2.6531670125593685

Epoch: 6| Step: 1
Training loss: 1.9317813278191562
Validation loss: 2.6717811255667203

Epoch: 6| Step: 2
Training loss: 1.7018486630030112
Validation loss: 2.638717820383787

Epoch: 6| Step: 3
Training loss: 1.539739237296049
Validation loss: 2.623554406922866

Epoch: 6| Step: 4
Training loss: 1.6461666429599535
Validation loss: 2.6220341533722635

Epoch: 6| Step: 5
Training loss: 1.4676103431509777
Validation loss: 2.5954363599507664

Epoch: 6| Step: 6
Training loss: 1.2826048502903067
Validation loss: 2.5867679487961

Epoch: 6| Step: 7
Training loss: 1.250396760915367
Validation loss: 2.6118390143012604

Epoch: 6| Step: 8
Training loss: 1.2749299740728381
Validation loss: 2.619521509477235

Epoch: 6| Step: 9
Training loss: 1.249004301233269
Validation loss: 2.6018162814547523

Epoch: 6| Step: 10
Training loss: 1.4691289859179841
Validation loss: 2.606327599727915

Epoch: 6| Step: 11
Training loss: 1.8463174433389722
Validation loss: 2.5571075860072474

Epoch: 6| Step: 12
Training loss: 1.749036932658364
Validation loss: 2.612531241697079

Epoch: 6| Step: 13
Training loss: 1.3097748394012572
Validation loss: 2.6348276698916093

Epoch: 372| Step: 0
Training loss: 1.0322015591483045
Validation loss: 2.682112802016971

Epoch: 6| Step: 1
Training loss: 1.3485656323781734
Validation loss: 2.653559170781259

Epoch: 6| Step: 2
Training loss: 1.5862919453635553
Validation loss: 2.6542159277048967

Epoch: 6| Step: 3
Training loss: 1.5942250460065082
Validation loss: 2.688135722473845

Epoch: 6| Step: 4
Training loss: 1.672711528522105
Validation loss: 2.660300931949828

Epoch: 6| Step: 5
Training loss: 1.5460534274108821
Validation loss: 2.6716948628816706

Epoch: 6| Step: 6
Training loss: 2.0665692732022327
Validation loss: 2.671842281148657

Epoch: 6| Step: 7
Training loss: 1.2367313444613215
Validation loss: 2.617562019538831

Epoch: 6| Step: 8
Training loss: 1.7183992895028974
Validation loss: 2.6281968133030253

Epoch: 6| Step: 9
Training loss: 1.7877921045823961
Validation loss: 2.5654742650037567

Epoch: 6| Step: 10
Training loss: 1.6659956614471034
Validation loss: 2.558499741707881

Epoch: 6| Step: 11
Training loss: 1.3463517661844937
Validation loss: 2.5318872724913803

Epoch: 6| Step: 12
Training loss: 1.5799590680095776
Validation loss: 2.5735383666173894

Epoch: 6| Step: 13
Training loss: 1.773065267477135
Validation loss: 2.5714791074711703

Epoch: 373| Step: 0
Training loss: 1.2682639501711668
Validation loss: 2.556258361230683

Epoch: 6| Step: 1
Training loss: 1.5714665058437127
Validation loss: 2.5714434268184236

Epoch: 6| Step: 2
Training loss: 1.5820696790760842
Validation loss: 2.5557106450147415

Epoch: 6| Step: 3
Training loss: 1.1571639289484756
Validation loss: 2.604439878754941

Epoch: 6| Step: 4
Training loss: 1.7566592353986938
Validation loss: 2.5826177349377044

Epoch: 6| Step: 5
Training loss: 1.377541620556917
Validation loss: 2.6479710756159873

Epoch: 6| Step: 6
Training loss: 1.3269934826930165
Validation loss: 2.624207498114236

Epoch: 6| Step: 7
Training loss: 1.4621068996741753
Validation loss: 2.646178971389821

Epoch: 6| Step: 8
Training loss: 1.4504395969546828
Validation loss: 2.6357439363145674

Epoch: 6| Step: 9
Training loss: 1.2512751750719027
Validation loss: 2.5949398896342712

Epoch: 6| Step: 10
Training loss: 1.4666461892576925
Validation loss: 2.583694953116758

Epoch: 6| Step: 11
Training loss: 1.7626083394834906
Validation loss: 2.541609401266221

Epoch: 6| Step: 12
Training loss: 2.1273159421741683
Validation loss: 2.5572967270272113

Epoch: 6| Step: 13
Training loss: 1.9937388046093825
Validation loss: 2.5702724202441023

Epoch: 374| Step: 0
Training loss: 1.9257799500621564
Validation loss: 2.5423602320020553

Epoch: 6| Step: 1
Training loss: 1.4886269956263536
Validation loss: 2.5652149983326735

Epoch: 6| Step: 2
Training loss: 0.9452782616838409
Validation loss: 2.598009816824417

Epoch: 6| Step: 3
Training loss: 1.6486576168389346
Validation loss: 2.5894529758418225

Epoch: 6| Step: 4
Training loss: 2.122932774935309
Validation loss: 2.6607468332705912

Epoch: 6| Step: 5
Training loss: 1.1252823051590282
Validation loss: 2.6753779866202296

Epoch: 6| Step: 6
Training loss: 1.2184102978816578
Validation loss: 2.6885717605824

Epoch: 6| Step: 7
Training loss: 1.4455792979839064
Validation loss: 2.7139618756299515

Epoch: 6| Step: 8
Training loss: 1.7954317350442086
Validation loss: 2.698071292486694

Epoch: 6| Step: 9
Training loss: 1.5501673946435641
Validation loss: 2.615297171931095

Epoch: 6| Step: 10
Training loss: 1.2393857921413252
Validation loss: 2.634896982291648

Epoch: 6| Step: 11
Training loss: 1.715132565171051
Validation loss: 2.5361216881113515

Epoch: 6| Step: 12
Training loss: 1.4762907232212068
Validation loss: 2.5724752152969437

Epoch: 6| Step: 13
Training loss: 1.2564395970232782
Validation loss: 2.6039106217713983

Epoch: 375| Step: 0
Training loss: 0.8125964620989679
Validation loss: 2.6218246827963636

Epoch: 6| Step: 1
Training loss: 1.7863182109304894
Validation loss: 2.6122319006360835

Epoch: 6| Step: 2
Training loss: 1.4480405063864707
Validation loss: 2.6276408641257594

Epoch: 6| Step: 3
Training loss: 1.3783258183669214
Validation loss: 2.608621469453036

Epoch: 6| Step: 4
Training loss: 1.667536016072421
Validation loss: 2.617666134315157

Epoch: 6| Step: 5
Training loss: 1.7128654312838636
Validation loss: 2.625762548647726

Epoch: 6| Step: 6
Training loss: 1.2693633452668818
Validation loss: 2.5958325019169717

Epoch: 6| Step: 7
Training loss: 1.3485742068695055
Validation loss: 2.63241044322355

Epoch: 6| Step: 8
Training loss: 1.7847137236568043
Validation loss: 2.6057420365171216

Epoch: 6| Step: 9
Training loss: 1.477988790482482
Validation loss: 2.6414927725210773

Epoch: 6| Step: 10
Training loss: 1.4815523313870582
Validation loss: 2.640050234870575

Epoch: 6| Step: 11
Training loss: 1.5297463488534444
Validation loss: 2.674229482394633

Epoch: 6| Step: 12
Training loss: 1.7869177877154032
Validation loss: 2.6293967981071935

Epoch: 6| Step: 13
Training loss: 1.5473915547718673
Validation loss: 2.6653065838984613

Epoch: 376| Step: 0
Training loss: 1.5249100830585305
Validation loss: 2.6814365147213306

Epoch: 6| Step: 1
Training loss: 1.6066479586993379
Validation loss: 2.6631144219127014

Epoch: 6| Step: 2
Training loss: 1.3777499875902934
Validation loss: 2.67554642512403

Epoch: 6| Step: 3
Training loss: 1.2253663858065968
Validation loss: 2.6659509522881137

Epoch: 6| Step: 4
Training loss: 2.187158176417946
Validation loss: 2.6335989874424928

Epoch: 6| Step: 5
Training loss: 1.2219400471497897
Validation loss: 2.6350251360568397

Epoch: 6| Step: 6
Training loss: 1.1053862524084284
Validation loss: 2.6302294487939677

Epoch: 6| Step: 7
Training loss: 1.582158062408807
Validation loss: 2.6114468905352024

Epoch: 6| Step: 8
Training loss: 1.217656256108998
Validation loss: 2.6427130936061123

Epoch: 6| Step: 9
Training loss: 2.0457669819044613
Validation loss: 2.6550094400299122

Epoch: 6| Step: 10
Training loss: 1.1061349216239946
Validation loss: 2.664330015054036

Epoch: 6| Step: 11
Training loss: 1.5774813557534155
Validation loss: 2.6430423213270817

Epoch: 6| Step: 12
Training loss: 1.6936232065411903
Validation loss: 2.653941598768532

Epoch: 6| Step: 13
Training loss: 0.7140462627275956
Validation loss: 2.6658316487049323

Epoch: 377| Step: 0
Training loss: 1.5840904115681322
Validation loss: 2.651290557109879

Epoch: 6| Step: 1
Training loss: 1.3735641004521202
Validation loss: 2.701875541205157

Epoch: 6| Step: 2
Training loss: 2.151217018597216
Validation loss: 2.664178109294082

Epoch: 6| Step: 3
Training loss: 1.3737602280018197
Validation loss: 2.624274123208484

Epoch: 6| Step: 4
Training loss: 1.2104562603005906
Validation loss: 2.6835925802332863

Epoch: 6| Step: 5
Training loss: 1.3779791289826577
Validation loss: 2.661831478131228

Epoch: 6| Step: 6
Training loss: 1.312730950517529
Validation loss: 2.6622620555356242

Epoch: 6| Step: 7
Training loss: 1.1720439534782336
Validation loss: 2.660574082447494

Epoch: 6| Step: 8
Training loss: 1.8733354173198435
Validation loss: 2.629298460045624

Epoch: 6| Step: 9
Training loss: 1.3142698253684064
Validation loss: 2.5902506497632696

Epoch: 6| Step: 10
Training loss: 1.0267301402246074
Validation loss: 2.6098119099637023

Epoch: 6| Step: 11
Training loss: 1.546420945853849
Validation loss: 2.595829463321093

Epoch: 6| Step: 12
Training loss: 1.5040386191239115
Validation loss: 2.6548370193486828

Epoch: 6| Step: 13
Training loss: 1.5827787164093432
Validation loss: 2.6299273098423708

Epoch: 378| Step: 0
Training loss: 1.1637294215955063
Validation loss: 2.6170737170637084

Epoch: 6| Step: 1
Training loss: 1.3257396145219074
Validation loss: 2.597630351996332

Epoch: 6| Step: 2
Training loss: 1.5138599303544928
Validation loss: 2.6185355135801642

Epoch: 6| Step: 3
Training loss: 1.1034958559139065
Validation loss: 2.5598894949000535

Epoch: 6| Step: 4
Training loss: 1.4994291967890554
Validation loss: 2.602121027807576

Epoch: 6| Step: 5
Training loss: 1.3183418329272742
Validation loss: 2.6297278969484332

Epoch: 6| Step: 6
Training loss: 1.298570053734442
Validation loss: 2.609949844299856

Epoch: 6| Step: 7
Training loss: 1.6016562085533022
Validation loss: 2.608442920499271

Epoch: 6| Step: 8
Training loss: 1.2550114309694609
Validation loss: 2.631665426096544

Epoch: 6| Step: 9
Training loss: 2.0265794316557293
Validation loss: 2.61837794620606

Epoch: 6| Step: 10
Training loss: 1.5163778421294998
Validation loss: 2.6429975486462074

Epoch: 6| Step: 11
Training loss: 1.671511886951515
Validation loss: 2.663435443604507

Epoch: 6| Step: 12
Training loss: 1.2843257458377972
Validation loss: 2.665560497891373

Epoch: 6| Step: 13
Training loss: 1.6983279644722473
Validation loss: 2.6572836267301585

Epoch: 379| Step: 0
Training loss: 1.6273321143076351
Validation loss: 2.627756994596273

Epoch: 6| Step: 1
Training loss: 1.5776881000318332
Validation loss: 2.6441053219361765

Epoch: 6| Step: 2
Training loss: 1.2487721134400551
Validation loss: 2.6242028494365766

Epoch: 6| Step: 3
Training loss: 0.8021074431788001
Validation loss: 2.600531517927235

Epoch: 6| Step: 4
Training loss: 1.1762651227248488
Validation loss: 2.6281434719602266

Epoch: 6| Step: 5
Training loss: 1.6355223732901714
Validation loss: 2.5886745968822535

Epoch: 6| Step: 6
Training loss: 1.855579188222383
Validation loss: 2.637388228207064

Epoch: 6| Step: 7
Training loss: 1.0422027289380276
Validation loss: 2.6077753672728385

Epoch: 6| Step: 8
Training loss: 1.6386136759629264
Validation loss: 2.5740773263923944

Epoch: 6| Step: 9
Training loss: 1.233304585731819
Validation loss: 2.6316274887133835

Epoch: 6| Step: 10
Training loss: 1.5415562598757337
Validation loss: 2.6155811675305998

Epoch: 6| Step: 11
Training loss: 1.449990532285101
Validation loss: 2.602873280090693

Epoch: 6| Step: 12
Training loss: 1.049281471633013
Validation loss: 2.595087679274156

Epoch: 6| Step: 13
Training loss: 1.4974723818465938
Validation loss: 2.6427392414727957

Epoch: 380| Step: 0
Training loss: 1.2325975199221213
Validation loss: 2.632870214114578

Epoch: 6| Step: 1
Training loss: 1.4177409007386355
Validation loss: 2.6173279378229393

Epoch: 6| Step: 2
Training loss: 1.3530072555234673
Validation loss: 2.7139623441574043

Epoch: 6| Step: 3
Training loss: 1.2646109203532558
Validation loss: 2.705464697436489

Epoch: 6| Step: 4
Training loss: 1.7760634956994712
Validation loss: 2.6925365361220357

Epoch: 6| Step: 5
Training loss: 1.8683261990418056
Validation loss: 2.6275561164165087

Epoch: 6| Step: 6
Training loss: 1.0651299520913982
Validation loss: 2.6289691889173703

Epoch: 6| Step: 7
Training loss: 1.7947387601907228
Validation loss: 2.6154096191888234

Epoch: 6| Step: 8
Training loss: 1.291125963721653
Validation loss: 2.571884841560207

Epoch: 6| Step: 9
Training loss: 1.693693592216126
Validation loss: 2.608822305283836

Epoch: 6| Step: 10
Training loss: 1.4228013762222083
Validation loss: 2.5541913467467743

Epoch: 6| Step: 11
Training loss: 1.0416442232893088
Validation loss: 2.587780068393187

Epoch: 6| Step: 12
Training loss: 1.6217769056581346
Validation loss: 2.6126820818709193

Epoch: 6| Step: 13
Training loss: 1.0599347169134272
Validation loss: 2.5965994996707265

Epoch: 381| Step: 0
Training loss: 1.3218854304053202
Validation loss: 2.618895896422464

Epoch: 6| Step: 1
Training loss: 1.2493791945951425
Validation loss: 2.6947644547271996

Epoch: 6| Step: 2
Training loss: 0.9098854808222074
Validation loss: 2.7085255970324273

Epoch: 6| Step: 3
Training loss: 1.8141202590513499
Validation loss: 2.6809936617276318

Epoch: 6| Step: 4
Training loss: 1.038624147578941
Validation loss: 2.7077167151390036

Epoch: 6| Step: 5
Training loss: 1.8410355581219857
Validation loss: 2.6844592746211116

Epoch: 6| Step: 6
Training loss: 0.844350954019759
Validation loss: 2.6252147647256274

Epoch: 6| Step: 7
Training loss: 1.1260130877166155
Validation loss: 2.563666830116511

Epoch: 6| Step: 8
Training loss: 0.9921981029995248
Validation loss: 2.5948029950625986

Epoch: 6| Step: 9
Training loss: 1.738836238430983
Validation loss: 2.587898855136284

Epoch: 6| Step: 10
Training loss: 1.179390067695143
Validation loss: 2.5666119992845866

Epoch: 6| Step: 11
Training loss: 1.743086783782471
Validation loss: 2.5607030817488408

Epoch: 6| Step: 12
Training loss: 1.89371307639205
Validation loss: 2.5306465701227108

Epoch: 6| Step: 13
Training loss: 1.9082274889293507
Validation loss: 2.5266201707072917

Epoch: 382| Step: 0
Training loss: 1.6000323173120194
Validation loss: 2.5360230079473607

Epoch: 6| Step: 1
Training loss: 1.3438741937066663
Validation loss: 2.5830151197862534

Epoch: 6| Step: 2
Training loss: 1.0542965199603134
Validation loss: 2.6275870426906685

Epoch: 6| Step: 3
Training loss: 1.7224433750096826
Validation loss: 2.6607802859246403

Epoch: 6| Step: 4
Training loss: 1.8543911344406787
Validation loss: 2.6744259262852594

Epoch: 6| Step: 5
Training loss: 1.0423894409174792
Validation loss: 2.663051573761643

Epoch: 6| Step: 6
Training loss: 1.1375113015085039
Validation loss: 2.734425506125352

Epoch: 6| Step: 7
Training loss: 1.4658037219039461
Validation loss: 2.6613537767231246

Epoch: 6| Step: 8
Training loss: 1.54313693518212
Validation loss: 2.6957361745252526

Epoch: 6| Step: 9
Training loss: 1.5781703224850165
Validation loss: 2.6527497809920533

Epoch: 6| Step: 10
Training loss: 1.4807004722080752
Validation loss: 2.663572130164549

Epoch: 6| Step: 11
Training loss: 1.1003417697903952
Validation loss: 2.6151987747151004

Epoch: 6| Step: 12
Training loss: 1.5738928672897938
Validation loss: 2.605934997354893

Epoch: 6| Step: 13
Training loss: 1.4326703582445113
Validation loss: 2.5865775984327697

Epoch: 383| Step: 0
Training loss: 1.632640336738845
Validation loss: 2.553271462119985

Epoch: 6| Step: 1
Training loss: 1.664298457220282
Validation loss: 2.576232030251516

Epoch: 6| Step: 2
Training loss: 1.6954861740948024
Validation loss: 2.614680487257584

Epoch: 6| Step: 3
Training loss: 1.508042234006435
Validation loss: 2.610215270688089

Epoch: 6| Step: 4
Training loss: 1.5039289200300276
Validation loss: 2.6496799671611746

Epoch: 6| Step: 5
Training loss: 1.549237306669349
Validation loss: 2.6490715865690024

Epoch: 6| Step: 6
Training loss: 0.9379606386844677
Validation loss: 2.6970432345421274

Epoch: 6| Step: 7
Training loss: 1.303119379484282
Validation loss: 2.6852892572933142

Epoch: 6| Step: 8
Training loss: 1.85648416140391
Validation loss: 2.6858807202533304

Epoch: 6| Step: 9
Training loss: 1.1253943282029708
Validation loss: 2.675443218626013

Epoch: 6| Step: 10
Training loss: 1.8420200313841617
Validation loss: 2.675749707558156

Epoch: 6| Step: 11
Training loss: 1.2385288315929557
Validation loss: 2.704762133929961

Epoch: 6| Step: 12
Training loss: 1.5351408746546358
Validation loss: 2.7009167480613114

Epoch: 6| Step: 13
Training loss: 1.0084678825480364
Validation loss: 2.6525575292294774

Epoch: 384| Step: 0
Training loss: 1.2646245887893683
Validation loss: 2.657211025145413

Epoch: 6| Step: 1
Training loss: 1.4806083673756287
Validation loss: 2.6108774363565947

Epoch: 6| Step: 2
Training loss: 1.329662644616814
Validation loss: 2.6049142959613065

Epoch: 6| Step: 3
Training loss: 1.346410070128133
Validation loss: 2.636244675202989

Epoch: 6| Step: 4
Training loss: 1.3973724742429452
Validation loss: 2.7416387083102527

Epoch: 6| Step: 5
Training loss: 1.8901908312939955
Validation loss: 2.7536575962655023

Epoch: 6| Step: 6
Training loss: 1.6368888092915062
Validation loss: 2.762626401676247

Epoch: 6| Step: 7
Training loss: 1.1588343014961089
Validation loss: 2.7434189396136337

Epoch: 6| Step: 8
Training loss: 2.1327673379776653
Validation loss: 2.7005613956084393

Epoch: 6| Step: 9
Training loss: 1.5473587358672196
Validation loss: 2.680720657464582

Epoch: 6| Step: 10
Training loss: 1.495329260657438
Validation loss: 2.7170176193542113

Epoch: 6| Step: 11
Training loss: 0.903364850570103
Validation loss: 2.718789885948181

Epoch: 6| Step: 12
Training loss: 0.7991724741077999
Validation loss: 2.6784217447510255

Epoch: 6| Step: 13
Training loss: 1.6686564329968694
Validation loss: 2.6465051704143385

Epoch: 385| Step: 0
Training loss: 1.5561381717320235
Validation loss: 2.6288787779900686

Epoch: 6| Step: 1
Training loss: 1.6995438188075997
Validation loss: 2.5967620916873737

Epoch: 6| Step: 2
Training loss: 0.9145712455582147
Validation loss: 2.6435321176986637

Epoch: 6| Step: 3
Training loss: 1.4430050137459831
Validation loss: 2.640618077857822

Epoch: 6| Step: 4
Training loss: 1.2431763365949453
Validation loss: 2.671938897274169

Epoch: 6| Step: 5
Training loss: 1.4869056411799322
Validation loss: 2.608867618777173

Epoch: 6| Step: 6
Training loss: 1.1499546954311677
Validation loss: 2.589862453264659

Epoch: 6| Step: 7
Training loss: 1.3469128313526644
Validation loss: 2.6345985459538

Epoch: 6| Step: 8
Training loss: 1.546952679157554
Validation loss: 2.636006192599477

Epoch: 6| Step: 9
Training loss: 1.731695287294777
Validation loss: 2.605794128506919

Epoch: 6| Step: 10
Training loss: 1.4838924225838468
Validation loss: 2.652371705572253

Epoch: 6| Step: 11
Training loss: 1.4671083569128294
Validation loss: 2.6322836868372494

Epoch: 6| Step: 12
Training loss: 1.352909937940633
Validation loss: 2.656393391347874

Epoch: 6| Step: 13
Training loss: 1.7035083864194265
Validation loss: 2.6453464290322946

Epoch: 386| Step: 0
Training loss: 1.2114265684827148
Validation loss: 2.720266788689472

Epoch: 6| Step: 1
Training loss: 1.0510392563599749
Validation loss: 2.710214260048996

Epoch: 6| Step: 2
Training loss: 1.4037050743081425
Validation loss: 2.682254492245936

Epoch: 6| Step: 3
Training loss: 1.457247884154931
Validation loss: 2.686433765426738

Epoch: 6| Step: 4
Training loss: 1.5859892136734952
Validation loss: 2.6811622439282554

Epoch: 6| Step: 5
Training loss: 1.4552046957587195
Validation loss: 2.6486593808053844

Epoch: 6| Step: 6
Training loss: 1.6309417521064442
Validation loss: 2.634090999862889

Epoch: 6| Step: 7
Training loss: 1.2974824976245927
Validation loss: 2.5728989624979333

Epoch: 6| Step: 8
Training loss: 1.8190497737951172
Validation loss: 2.581929461174821

Epoch: 6| Step: 9
Training loss: 1.2366110431281088
Validation loss: 2.597455376910898

Epoch: 6| Step: 10
Training loss: 1.4349726144656412
Validation loss: 2.5619601789839637

Epoch: 6| Step: 11
Training loss: 1.4698826095522928
Validation loss: 2.5655071400292924

Epoch: 6| Step: 12
Training loss: 1.7061639673250744
Validation loss: 2.5698427739271694

Epoch: 6| Step: 13
Training loss: 1.2447702201155584
Validation loss: 2.66968108707375

Epoch: 387| Step: 0
Training loss: 0.867950172809219
Validation loss: 2.6632183747513

Epoch: 6| Step: 1
Training loss: 1.0477795465044735
Validation loss: 2.6979130679858936

Epoch: 6| Step: 2
Training loss: 1.2509037565415986
Validation loss: 2.7041848958424244

Epoch: 6| Step: 3
Training loss: 1.6623235221641086
Validation loss: 2.7143844618498076

Epoch: 6| Step: 4
Training loss: 1.6879514867310663
Validation loss: 2.715338514146827

Epoch: 6| Step: 5
Training loss: 1.096289928061468
Validation loss: 2.7273080238312373

Epoch: 6| Step: 6
Training loss: 1.8951293630404444
Validation loss: 2.709633989286375

Epoch: 6| Step: 7
Training loss: 1.5009978472181482
Validation loss: 2.697262870092916

Epoch: 6| Step: 8
Training loss: 1.4168643065571949
Validation loss: 2.7173026313688227

Epoch: 6| Step: 9
Training loss: 1.7257079344166113
Validation loss: 2.6873615288362123

Epoch: 6| Step: 10
Training loss: 1.081503012717782
Validation loss: 2.7239767089768554

Epoch: 6| Step: 11
Training loss: 1.1934052254067762
Validation loss: 2.703741881554852

Epoch: 6| Step: 12
Training loss: 1.4036561568051007
Validation loss: 2.735626123393398

Epoch: 6| Step: 13
Training loss: 1.392117802751612
Validation loss: 2.7023844209764394

Epoch: 388| Step: 0
Training loss: 1.006144244400151
Validation loss: 2.715317382480304

Epoch: 6| Step: 1
Training loss: 1.6149057702130736
Validation loss: 2.692093568101573

Epoch: 6| Step: 2
Training loss: 1.4660815896232553
Validation loss: 2.67994094109819

Epoch: 6| Step: 3
Training loss: 1.5636317160045354
Validation loss: 2.6429837468408044

Epoch: 6| Step: 4
Training loss: 1.3971236039723227
Validation loss: 2.63715461048372

Epoch: 6| Step: 5
Training loss: 1.7181318385216036
Validation loss: 2.6450510495553052

Epoch: 6| Step: 6
Training loss: 1.311382544612444
Validation loss: 2.572361076590285

Epoch: 6| Step: 7
Training loss: 1.4437746681649088
Validation loss: 2.609208457642148

Epoch: 6| Step: 8
Training loss: 1.570499769592754
Validation loss: 2.6081509031741295

Epoch: 6| Step: 9
Training loss: 1.0304356451840972
Validation loss: 2.6639328642596443

Epoch: 6| Step: 10
Training loss: 1.089544494452122
Validation loss: 2.72766489589338

Epoch: 6| Step: 11
Training loss: 1.7801586622611723
Validation loss: 2.729242284955071

Epoch: 6| Step: 12
Training loss: 1.26518015637872
Validation loss: 2.7587405796348228

Epoch: 6| Step: 13
Training loss: 1.0582153094305908
Validation loss: 2.7585788775021243

Epoch: 389| Step: 0
Training loss: 1.9592763848562176
Validation loss: 2.7711190002340667

Epoch: 6| Step: 1
Training loss: 1.1103347065769278
Validation loss: 2.7166292973934034

Epoch: 6| Step: 2
Training loss: 0.9927810935821502
Validation loss: 2.726729816888441

Epoch: 6| Step: 3
Training loss: 1.4598373105579674
Validation loss: 2.6347213903530937

Epoch: 6| Step: 4
Training loss: 1.400478472009307
Validation loss: 2.636258655483844

Epoch: 6| Step: 5
Training loss: 0.9113669140699933
Validation loss: 2.6527717406074927

Epoch: 6| Step: 6
Training loss: 1.0696760081042496
Validation loss: 2.6165419356469224

Epoch: 6| Step: 7
Training loss: 1.5327689752805678
Validation loss: 2.5849878693818034

Epoch: 6| Step: 8
Training loss: 1.3285801724616408
Validation loss: 2.58312444970394

Epoch: 6| Step: 9
Training loss: 1.204611813237032
Validation loss: 2.5613153867379106

Epoch: 6| Step: 10
Training loss: 1.2260421329433664
Validation loss: 2.6195877076695915

Epoch: 6| Step: 11
Training loss: 1.787787703722378
Validation loss: 2.600270375229676

Epoch: 6| Step: 12
Training loss: 1.2605715517241758
Validation loss: 2.622994125793992

Epoch: 6| Step: 13
Training loss: 1.5190864441504426
Validation loss: 2.606707033233417

Epoch: 390| Step: 0
Training loss: 1.2288048044519329
Validation loss: 2.662981785508407

Epoch: 6| Step: 1
Training loss: 1.326220594362374
Validation loss: 2.695476891853234

Epoch: 6| Step: 2
Training loss: 1.5433142939080438
Validation loss: 2.7300744233565934

Epoch: 6| Step: 3
Training loss: 1.761637277685825
Validation loss: 2.6769006026031756

Epoch: 6| Step: 4
Training loss: 1.5729625602578405
Validation loss: 2.673170731071336

Epoch: 6| Step: 5
Training loss: 1.189806154474938
Validation loss: 2.69805086506619

Epoch: 6| Step: 6
Training loss: 1.1880418645437414
Validation loss: 2.63369767791093

Epoch: 6| Step: 7
Training loss: 1.6581379189043717
Validation loss: 2.641210457270671

Epoch: 6| Step: 8
Training loss: 1.0811051905688693
Validation loss: 2.6129156673305594

Epoch: 6| Step: 9
Training loss: 1.6944651089990712
Validation loss: 2.5864398541342806

Epoch: 6| Step: 10
Training loss: 1.2109547275425256
Validation loss: 2.5600021562716226

Epoch: 6| Step: 11
Training loss: 1.1143942105043616
Validation loss: 2.585585955401162

Epoch: 6| Step: 12
Training loss: 1.2071607205479165
Validation loss: 2.5639756148652144

Epoch: 6| Step: 13
Training loss: 1.5367046438945704
Validation loss: 2.571356888748303

Epoch: 391| Step: 0
Training loss: 1.3740564490109803
Validation loss: 2.612900383550338

Epoch: 6| Step: 1
Training loss: 1.2981680433238507
Validation loss: 2.621080090581452

Epoch: 6| Step: 2
Training loss: 1.7415786158132465
Validation loss: 2.6511098906626223

Epoch: 6| Step: 3
Training loss: 1.1191261916369943
Validation loss: 2.713901537402936

Epoch: 6| Step: 4
Training loss: 1.689925040777808
Validation loss: 2.6893790425772504

Epoch: 6| Step: 5
Training loss: 1.176403501996091
Validation loss: 2.696871217420746

Epoch: 6| Step: 6
Training loss: 1.3296520654280375
Validation loss: 2.7146451076954916

Epoch: 6| Step: 7
Training loss: 1.2201248630351258
Validation loss: 2.7003450155579576

Epoch: 6| Step: 8
Training loss: 1.2663943460176807
Validation loss: 2.6292245567304358

Epoch: 6| Step: 9
Training loss: 1.687637040966883
Validation loss: 2.6068971332106465

Epoch: 6| Step: 10
Training loss: 1.11477571532452
Validation loss: 2.6042516058738983

Epoch: 6| Step: 11
Training loss: 1.3184591976097397
Validation loss: 2.6074618028114873

Epoch: 6| Step: 12
Training loss: 1.5161350611106692
Validation loss: 2.593821896088969

Epoch: 6| Step: 13
Training loss: 1.2904081776706895
Validation loss: 2.6289253857668617

Epoch: 392| Step: 0
Training loss: 1.7354565246816351
Validation loss: 2.633687825627031

Epoch: 6| Step: 1
Training loss: 1.3113230923626247
Validation loss: 2.6893259838878856

Epoch: 6| Step: 2
Training loss: 1.0923690797763437
Validation loss: 2.6596048001054475

Epoch: 6| Step: 3
Training loss: 1.6479365595578588
Validation loss: 2.6655314395908243

Epoch: 6| Step: 4
Training loss: 1.286497303402058
Validation loss: 2.663156894306935

Epoch: 6| Step: 5
Training loss: 1.4715824006444889
Validation loss: 2.6450971545408386

Epoch: 6| Step: 6
Training loss: 1.3532192241467986
Validation loss: 2.6686016130848054

Epoch: 6| Step: 7
Training loss: 1.5845141107106038
Validation loss: 2.6570555419170354

Epoch: 6| Step: 8
Training loss: 0.8679119555058095
Validation loss: 2.6735012466735006

Epoch: 6| Step: 9
Training loss: 1.3793718886415958
Validation loss: 2.6138356774869

Epoch: 6| Step: 10
Training loss: 1.6819807853871278
Validation loss: 2.6557167265897985

Epoch: 6| Step: 11
Training loss: 1.0335288444779172
Validation loss: 2.613530153320382

Epoch: 6| Step: 12
Training loss: 1.0205482876430658
Validation loss: 2.6126278306025164

Epoch: 6| Step: 13
Training loss: 0.9874117497956417
Validation loss: 2.56605960202193

Epoch: 393| Step: 0
Training loss: 1.4136505791524472
Validation loss: 2.6116169722437688

Epoch: 6| Step: 1
Training loss: 1.8923272910483886
Validation loss: 2.641658768707246

Epoch: 6| Step: 2
Training loss: 1.6375095396273591
Validation loss: 2.629326615302084

Epoch: 6| Step: 3
Training loss: 1.5233987656584191
Validation loss: 2.67200954462867

Epoch: 6| Step: 4
Training loss: 1.194144781852278
Validation loss: 2.684767731435819

Epoch: 6| Step: 5
Training loss: 1.286847008228867
Validation loss: 2.6738545481730234

Epoch: 6| Step: 6
Training loss: 1.2818599272631814
Validation loss: 2.653888939580273

Epoch: 6| Step: 7
Training loss: 1.4612252671079642
Validation loss: 2.686819788881762

Epoch: 6| Step: 8
Training loss: 1.2284713761407184
Validation loss: 2.7088930334173007

Epoch: 6| Step: 9
Training loss: 1.2797345293693123
Validation loss: 2.692948259969754

Epoch: 6| Step: 10
Training loss: 1.1141309741191834
Validation loss: 2.67759360312754

Epoch: 6| Step: 11
Training loss: 1.1112316337758361
Validation loss: 2.698906151225259

Epoch: 6| Step: 12
Training loss: 1.249124124747124
Validation loss: 2.6722960261222632

Epoch: 6| Step: 13
Training loss: 0.9898069764783028
Validation loss: 2.6861276079605116

Epoch: 394| Step: 0
Training loss: 1.206907938858865
Validation loss: 2.7039370483889957

Epoch: 6| Step: 1
Training loss: 1.6347627081440526
Validation loss: 2.6950043433018154

Epoch: 6| Step: 2
Training loss: 1.4006091257308173
Validation loss: 2.6508066838913695

Epoch: 6| Step: 3
Training loss: 1.7515867396641773
Validation loss: 2.6586154503038992

Epoch: 6| Step: 4
Training loss: 1.2229289765309754
Validation loss: 2.6480451535181193

Epoch: 6| Step: 5
Training loss: 1.0748227727423163
Validation loss: 2.699777695251983

Epoch: 6| Step: 6
Training loss: 1.1973124708062253
Validation loss: 2.718404536021263

Epoch: 6| Step: 7
Training loss: 1.060858636770561
Validation loss: 2.7277768845523256

Epoch: 6| Step: 8
Training loss: 1.3362313555281216
Validation loss: 2.7431829082257666

Epoch: 6| Step: 9
Training loss: 1.2988703441211529
Validation loss: 2.7912659476098396

Epoch: 6| Step: 10
Training loss: 1.3204943740447552
Validation loss: 2.8182106251982924

Epoch: 6| Step: 11
Training loss: 1.3475764596510704
Validation loss: 2.7371160084022645

Epoch: 6| Step: 12
Training loss: 1.1646578501618943
Validation loss: 2.7329943268362644

Epoch: 6| Step: 13
Training loss: 1.413019037673246
Validation loss: 2.7086074445855264

Epoch: 395| Step: 0
Training loss: 1.5152769967339486
Validation loss: 2.6766389831791497

Epoch: 6| Step: 1
Training loss: 1.0001001307901352
Validation loss: 2.659188175176196

Epoch: 6| Step: 2
Training loss: 1.3637532725937387
Validation loss: 2.6076710023580234

Epoch: 6| Step: 3
Training loss: 1.0436898356931874
Validation loss: 2.657468306949664

Epoch: 6| Step: 4
Training loss: 1.0833170718415317
Validation loss: 2.638109758591066

Epoch: 6| Step: 5
Training loss: 1.012221104864022
Validation loss: 2.680281118290994

Epoch: 6| Step: 6
Training loss: 1.70037339541581
Validation loss: 2.68040541215745

Epoch: 6| Step: 7
Training loss: 2.0528054556259003
Validation loss: 2.6684987857456792

Epoch: 6| Step: 8
Training loss: 1.0920189374043192
Validation loss: 2.7398543906678268

Epoch: 6| Step: 9
Training loss: 1.1344043465173252
Validation loss: 2.772650937580212

Epoch: 6| Step: 10
Training loss: 1.235050161632578
Validation loss: 2.718397782702119

Epoch: 6| Step: 11
Training loss: 1.0393983685314594
Validation loss: 2.724848415229963

Epoch: 6| Step: 12
Training loss: 0.9702935688426447
Validation loss: 2.7049627800506144

Epoch: 6| Step: 13
Training loss: 1.2274782686193924
Validation loss: 2.7186848862841817

Epoch: 396| Step: 0
Training loss: 0.8386576238664232
Validation loss: 2.698763745054857

Epoch: 6| Step: 1
Training loss: 1.2828961474041514
Validation loss: 2.688897604858137

Epoch: 6| Step: 2
Training loss: 1.403895590035328
Validation loss: 2.67984496192474

Epoch: 6| Step: 3
Training loss: 1.712894104765921
Validation loss: 2.662121510355571

Epoch: 6| Step: 4
Training loss: 0.9929427028694257
Validation loss: 2.631178940563297

Epoch: 6| Step: 5
Training loss: 1.605381947047989
Validation loss: 2.6494977586075277

Epoch: 6| Step: 6
Training loss: 1.215853354376569
Validation loss: 2.6356509610897336

Epoch: 6| Step: 7
Training loss: 1.157054827216154
Validation loss: 2.583366075944031

Epoch: 6| Step: 8
Training loss: 1.3008825130969628
Validation loss: 2.6362378998272664

Epoch: 6| Step: 9
Training loss: 0.8529600521943236
Validation loss: 2.6737040455397034

Epoch: 6| Step: 10
Training loss: 0.8157912863110545
Validation loss: 2.6635617468868564

Epoch: 6| Step: 11
Training loss: 1.1902190249698614
Validation loss: 2.650033513043179

Epoch: 6| Step: 12
Training loss: 1.3936936884567794
Validation loss: 2.6666213468833195

Epoch: 6| Step: 13
Training loss: 1.5727461749848783
Validation loss: 2.709133915073005

Epoch: 397| Step: 0
Training loss: 0.9365890845877866
Validation loss: 2.7317258663252444

Epoch: 6| Step: 1
Training loss: 1.3300515058769424
Validation loss: 2.679201992231152

Epoch: 6| Step: 2
Training loss: 1.2217093509088586
Validation loss: 2.6236502113769715

Epoch: 6| Step: 3
Training loss: 1.521361908005457
Validation loss: 2.6438657523352345

Epoch: 6| Step: 4
Training loss: 1.742260713279126
Validation loss: 2.6372386579919063

Epoch: 6| Step: 5
Training loss: 1.3758689562142437
Validation loss: 2.6035151213339955

Epoch: 6| Step: 6
Training loss: 1.173085668165651
Validation loss: 2.591308946443549

Epoch: 6| Step: 7
Training loss: 1.1641896837635584
Validation loss: 2.601235782548386

Epoch: 6| Step: 8
Training loss: 1.099473473940589
Validation loss: 2.5951722317125294

Epoch: 6| Step: 9
Training loss: 0.9312769981925455
Validation loss: 2.5330516384597526

Epoch: 6| Step: 10
Training loss: 1.3348913725759706
Validation loss: 2.6230762486672448

Epoch: 6| Step: 11
Training loss: 1.1124563272883576
Validation loss: 2.6494852279814722

Epoch: 6| Step: 12
Training loss: 0.9587951908626747
Validation loss: 2.7225855668104417

Epoch: 6| Step: 13
Training loss: 1.2683610423282417
Validation loss: 2.739660593159388

Epoch: 398| Step: 0
Training loss: 1.0801511881227002
Validation loss: 2.748555627727325

Epoch: 6| Step: 1
Training loss: 1.0695294488149096
Validation loss: 2.7397228007237713

Epoch: 6| Step: 2
Training loss: 1.087396917171153
Validation loss: 2.7453395916711667

Epoch: 6| Step: 3
Training loss: 1.2534665676751402
Validation loss: 2.722314857887615

Epoch: 6| Step: 4
Training loss: 0.8296853606058185
Validation loss: 2.7045796473298798

Epoch: 6| Step: 5
Training loss: 1.1131123732590162
Validation loss: 2.6618067643333996

Epoch: 6| Step: 6
Training loss: 1.0057452387079522
Validation loss: 2.654468440072958

Epoch: 6| Step: 7
Training loss: 1.197620333078885
Validation loss: 2.6317404838808627

Epoch: 6| Step: 8
Training loss: 1.474914195910963
Validation loss: 2.644553277859776

Epoch: 6| Step: 9
Training loss: 1.6790793094045642
Validation loss: 2.5889172860344964

Epoch: 6| Step: 10
Training loss: 0.9344288111983059
Validation loss: 2.6999114528311976

Epoch: 6| Step: 11
Training loss: 1.1282599159783795
Validation loss: 2.658027667426632

Epoch: 6| Step: 12
Training loss: 1.2748458656941497
Validation loss: 2.7419866214799593

Epoch: 6| Step: 13
Training loss: 2.0460644930000083
Validation loss: 2.7129266863285255

Epoch: 399| Step: 0
Training loss: 1.389831402248278
Validation loss: 2.695944095637552

Epoch: 6| Step: 1
Training loss: 1.1312881210395414
Validation loss: 2.7015629998010455

Epoch: 6| Step: 2
Training loss: 1.5466514194630367
Validation loss: 2.7450932597037254

Epoch: 6| Step: 3
Training loss: 0.918949917691536
Validation loss: 2.733031024342221

Epoch: 6| Step: 4
Training loss: 0.9928266614192726
Validation loss: 2.684743991015172

Epoch: 6| Step: 5
Training loss: 1.2908128818708478
Validation loss: 2.768443078107475

Epoch: 6| Step: 6
Training loss: 1.1898371134602344
Validation loss: 2.7516161186832684

Epoch: 6| Step: 7
Training loss: 1.6586865909878221
Validation loss: 2.7353993268321695

Epoch: 6| Step: 8
Training loss: 0.995821867096035
Validation loss: 2.722288175246723

Epoch: 6| Step: 9
Training loss: 1.455366477301148
Validation loss: 2.6773651261705846

Epoch: 6| Step: 10
Training loss: 1.0486595544018125
Validation loss: 2.697994795641299

Epoch: 6| Step: 11
Training loss: 1.4289428772984702
Validation loss: 2.691647737001479

Epoch: 6| Step: 12
Training loss: 0.9882027817284552
Validation loss: 2.696657458888092

Epoch: 6| Step: 13
Training loss: 1.436253629303041
Validation loss: 2.710695957706084

Epoch: 400| Step: 0
Training loss: 1.332396694852405
Validation loss: 2.706957428454524

Epoch: 6| Step: 1
Training loss: 1.2581203865766388
Validation loss: 2.659330773051188

Epoch: 6| Step: 2
Training loss: 0.9227497993351199
Validation loss: 2.6319394347837397

Epoch: 6| Step: 3
Training loss: 0.9321483132453762
Validation loss: 2.6406455105016975

Epoch: 6| Step: 4
Training loss: 1.3177064536260936
Validation loss: 2.671028940196125

Epoch: 6| Step: 5
Training loss: 1.054557735796121
Validation loss: 2.643220750516575

Epoch: 6| Step: 6
Training loss: 0.9395712542268464
Validation loss: 2.636368852169733

Epoch: 6| Step: 7
Training loss: 1.5085039678059287
Validation loss: 2.635407871236687

Epoch: 6| Step: 8
Training loss: 1.5057307286113113
Validation loss: 2.665404562501992

Epoch: 6| Step: 9
Training loss: 1.0905562502115553
Validation loss: 2.6529191244681263

Epoch: 6| Step: 10
Training loss: 1.8299122738265687
Validation loss: 2.6284663912664925

Epoch: 6| Step: 11
Training loss: 0.8732023847361288
Validation loss: 2.676557234391294

Epoch: 6| Step: 12
Training loss: 1.22213275659048
Validation loss: 2.6813059257834033

Epoch: 6| Step: 13
Training loss: 0.96203160221353
Validation loss: 2.6586105180245756

Testing loss: 2.173629464749299
