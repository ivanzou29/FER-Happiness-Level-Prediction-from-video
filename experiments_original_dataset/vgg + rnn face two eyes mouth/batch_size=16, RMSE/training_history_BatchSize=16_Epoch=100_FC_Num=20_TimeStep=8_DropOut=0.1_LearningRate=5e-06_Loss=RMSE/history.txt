Epoch: 1| Step: 0
Training loss: 5.7384889901343
Validation loss: 5.92089443761376

Epoch: 6| Step: 1
Training loss: 5.864611592289635
Validation loss: 5.91927149568871

Epoch: 6| Step: 2
Training loss: 6.081062136783818
Validation loss: 5.917681092173436

Epoch: 6| Step: 3
Training loss: 5.198912785653557
Validation loss: 5.915887252978165

Epoch: 6| Step: 4
Training loss: 5.606426856271877
Validation loss: 5.914215717489418

Epoch: 6| Step: 5
Training loss: 5.448426941800424
Validation loss: 5.912558575609533

Epoch: 6| Step: 6
Training loss: 6.387684786936176
Validation loss: 5.91088669039382

Epoch: 6| Step: 7
Training loss: 5.564010072250628
Validation loss: 5.909196471891962

Epoch: 6| Step: 8
Training loss: 5.515895242527552
Validation loss: 5.907527940070329

Epoch: 6| Step: 9
Training loss: 7.332044777225135
Validation loss: 5.905814610602254

Epoch: 6| Step: 10
Training loss: 6.140830000156356
Validation loss: 5.9040117816445665

Epoch: 6| Step: 11
Training loss: 6.051533956975031
Validation loss: 5.9021382762085475

Epoch: 6| Step: 12
Training loss: 6.54645953988293
Validation loss: 5.900372333954946

Epoch: 6| Step: 13
Training loss: 6.545522472722706
Validation loss: 5.898252397542269

Epoch: 2| Step: 0
Training loss: 5.31268417936708
Validation loss: 5.89622467503552

Epoch: 6| Step: 1
Training loss: 6.298189163327865
Validation loss: 5.894125440552146

Epoch: 6| Step: 2
Training loss: 6.332290898246821
Validation loss: 5.8918926517611565

Epoch: 6| Step: 3
Training loss: 6.781037076780359
Validation loss: 5.889543186082845

Epoch: 6| Step: 4
Training loss: 6.1282794503021885
Validation loss: 5.887039995952162

Epoch: 6| Step: 5
Training loss: 6.424370273944992
Validation loss: 5.884391582868794

Epoch: 6| Step: 6
Training loss: 6.175814604985828
Validation loss: 5.881708657098696

Epoch: 6| Step: 7
Training loss: 5.975451157906601
Validation loss: 5.878802536633614

Epoch: 6| Step: 8
Training loss: 6.326736561610538
Validation loss: 5.8758667110407075

Epoch: 6| Step: 9
Training loss: 5.424115424399358
Validation loss: 5.872719207002638

Epoch: 6| Step: 10
Training loss: 5.253858329242425
Validation loss: 5.869520730030725

Epoch: 6| Step: 11
Training loss: 5.003544504757001
Validation loss: 5.866064811670186

Epoch: 6| Step: 12
Training loss: 5.801582830769992
Validation loss: 5.862568384353248

Epoch: 6| Step: 13
Training loss: 6.39882948423464
Validation loss: 5.85891852063026

Epoch: 3| Step: 0
Training loss: 6.130461768327074
Validation loss: 5.854926778333857

Epoch: 6| Step: 1
Training loss: 7.574665215777098
Validation loss: 5.850731716420893

Epoch: 6| Step: 2
Training loss: 5.874795139068714
Validation loss: 5.846453852040822

Epoch: 6| Step: 3
Training loss: 6.618842088096542
Validation loss: 5.84185708679302

Epoch: 6| Step: 4
Training loss: 7.3507812603790255
Validation loss: 5.836827711973158

Epoch: 6| Step: 5
Training loss: 5.3586816811928255
Validation loss: 5.831574728954147

Epoch: 6| Step: 6
Training loss: 5.976192926686074
Validation loss: 5.826464841840402

Epoch: 6| Step: 7
Training loss: 5.606113856607105
Validation loss: 5.820805402873955

Epoch: 6| Step: 8
Training loss: 5.214738046096304
Validation loss: 5.814965603640053

Epoch: 6| Step: 9
Training loss: 5.241686460197852
Validation loss: 5.809003810778656

Epoch: 6| Step: 10
Training loss: 5.876374428865358
Validation loss: 5.802745030291812

Epoch: 6| Step: 11
Training loss: 5.830905445382242
Validation loss: 5.796239744408634

Epoch: 6| Step: 12
Training loss: 4.824173875360621
Validation loss: 5.789708755670203

Epoch: 6| Step: 13
Training loss: 4.930445786569088
Validation loss: 5.782496494941403

Epoch: 4| Step: 0
Training loss: 4.784544165253645
Validation loss: 5.775516945957478

Epoch: 6| Step: 1
Training loss: 5.5458460753438015
Validation loss: 5.768170960235269

Epoch: 6| Step: 2
Training loss: 5.449316755391077
Validation loss: 5.761115125513512

Epoch: 6| Step: 3
Training loss: 6.473985110836449
Validation loss: 5.753389796749448

Epoch: 6| Step: 4
Training loss: 5.767586723241136
Validation loss: 5.745355388781097

Epoch: 6| Step: 5
Training loss: 6.3604504474934425
Validation loss: 5.737817962412854

Epoch: 6| Step: 6
Training loss: 4.6678496405436665
Validation loss: 5.729170375013596

Epoch: 6| Step: 7
Training loss: 6.451431458598179
Validation loss: 5.72112940359946

Epoch: 6| Step: 8
Training loss: 6.230273740580614
Validation loss: 5.712194218371003

Epoch: 6| Step: 9
Training loss: 5.884568883099373
Validation loss: 5.703391068056901

Epoch: 6| Step: 10
Training loss: 6.130718442251615
Validation loss: 5.694318882661464

Epoch: 6| Step: 11
Training loss: 5.496179120472368
Validation loss: 5.685219555554277

Epoch: 6| Step: 12
Training loss: 6.2663972526155645
Validation loss: 5.675825552473204

Epoch: 6| Step: 13
Training loss: 5.845060640123313
Validation loss: 5.6663740961430165

Epoch: 5| Step: 0
Training loss: 5.362829224054869
Validation loss: 5.657040366913659

Epoch: 6| Step: 1
Training loss: 6.060634994726761
Validation loss: 5.647328543591231

Epoch: 6| Step: 2
Training loss: 5.524188172778125
Validation loss: 5.637925986064091

Epoch: 6| Step: 3
Training loss: 5.573709059618596
Validation loss: 5.628060815004952

Epoch: 6| Step: 4
Training loss: 6.120458047717277
Validation loss: 5.618520041891899

Epoch: 6| Step: 5
Training loss: 5.607476638425548
Validation loss: 5.608631761309357

Epoch: 6| Step: 6
Training loss: 5.991426063909733
Validation loss: 5.599176257719938

Epoch: 6| Step: 7
Training loss: 5.785516267916643
Validation loss: 5.589129054144541

Epoch: 6| Step: 8
Training loss: 5.302562799365128
Validation loss: 5.579717442640389

Epoch: 6| Step: 9
Training loss: 5.341686541936422
Validation loss: 5.570068040132008

Epoch: 6| Step: 10
Training loss: 6.677284209928915
Validation loss: 5.560597983937055

Epoch: 6| Step: 11
Training loss: 4.921047952586944
Validation loss: 5.5510856586110675

Epoch: 6| Step: 12
Training loss: 5.569167352486366
Validation loss: 5.541764232187746

Epoch: 6| Step: 13
Training loss: 5.925776743777126
Validation loss: 5.531915340889217

Epoch: 6| Step: 0
Training loss: 4.958511263863119
Validation loss: 5.522326611752377

Epoch: 6| Step: 1
Training loss: 5.481335093621748
Validation loss: 5.513138510472664

Epoch: 6| Step: 2
Training loss: 5.745948027235319
Validation loss: 5.503437124221295

Epoch: 6| Step: 3
Training loss: 4.885883409318434
Validation loss: 5.494279776740171

Epoch: 6| Step: 4
Training loss: 5.8345143167200915
Validation loss: 5.484958947259027

Epoch: 6| Step: 5
Training loss: 6.188583741502246
Validation loss: 5.475907268861964

Epoch: 6| Step: 6
Training loss: 5.191517572522561
Validation loss: 5.466308106704515

Epoch: 6| Step: 7
Training loss: 5.693565739184542
Validation loss: 5.4573035202970415

Epoch: 6| Step: 8
Training loss: 5.4657905636417965
Validation loss: 5.448052408874696

Epoch: 6| Step: 9
Training loss: 6.136951230876472
Validation loss: 5.438845530098892

Epoch: 6| Step: 10
Training loss: 5.663819364393648
Validation loss: 5.4298793255702025

Epoch: 6| Step: 11
Training loss: 5.498134816958757
Validation loss: 5.420792236094149

Epoch: 6| Step: 12
Training loss: 5.668003074284422
Validation loss: 5.412016599005191

Epoch: 6| Step: 13
Training loss: 5.569201943225243
Validation loss: 5.40304470410758

Epoch: 7| Step: 0
Training loss: 4.595730516811696
Validation loss: 5.394542976751525

Epoch: 6| Step: 1
Training loss: 4.663268873211399
Validation loss: 5.3855570240533375

Epoch: 6| Step: 2
Training loss: 5.766211833914379
Validation loss: 5.376921229066388

Epoch: 6| Step: 3
Training loss: 5.379465776317777
Validation loss: 5.368549201949484

Epoch: 6| Step: 4
Training loss: 6.924612360822535
Validation loss: 5.359977221227041

Epoch: 6| Step: 5
Training loss: 5.780704616906136
Validation loss: 5.351332076186641

Epoch: 6| Step: 6
Training loss: 5.100440002609074
Validation loss: 5.342400125662761

Epoch: 6| Step: 7
Training loss: 5.564203580092383
Validation loss: 5.333687333438487

Epoch: 6| Step: 8
Training loss: 4.981366915030762
Validation loss: 5.325180657177325

Epoch: 6| Step: 9
Training loss: 5.320946654226026
Validation loss: 5.317156348005017

Epoch: 6| Step: 10
Training loss: 4.715301870672479
Validation loss: 5.308739022762386

Epoch: 6| Step: 11
Training loss: 6.3218568251947715
Validation loss: 5.300360688945835

Epoch: 6| Step: 12
Training loss: 6.107711370357456
Validation loss: 5.2920465508218335

Epoch: 6| Step: 13
Training loss: 4.6150207082628905
Validation loss: 5.283619275864104

Epoch: 8| Step: 0
Training loss: 4.451847361605098
Validation loss: 5.275454710394946

Epoch: 6| Step: 1
Training loss: 5.802530578506412
Validation loss: 5.267333767486839

Epoch: 6| Step: 2
Training loss: 6.1425927190804375
Validation loss: 5.260049284642462

Epoch: 6| Step: 3
Training loss: 4.783257156633883
Validation loss: 5.251605227462194

Epoch: 6| Step: 4
Training loss: 6.231940460978401
Validation loss: 5.243912179566048

Epoch: 6| Step: 5
Training loss: 5.650184709348523
Validation loss: 5.236328185708846

Epoch: 6| Step: 6
Training loss: 5.429993106282672
Validation loss: 5.228396517309291

Epoch: 6| Step: 7
Training loss: 5.163503457885423
Validation loss: 5.221063127912609

Epoch: 6| Step: 8
Training loss: 4.338706182480052
Validation loss: 5.213354157522487

Epoch: 6| Step: 9
Training loss: 4.619499028114624
Validation loss: 5.206410940795982

Epoch: 6| Step: 10
Training loss: 5.724118573830003
Validation loss: 5.199105177206595

Epoch: 6| Step: 11
Training loss: 5.356503977145703
Validation loss: 5.192689039168356

Epoch: 6| Step: 12
Training loss: 5.721311568765901
Validation loss: 5.185755578083976

Epoch: 6| Step: 13
Training loss: 5.0261458575529305
Validation loss: 5.178745281890407

Epoch: 9| Step: 0
Training loss: 5.084757725168155
Validation loss: 5.17239337332484

Epoch: 6| Step: 1
Training loss: 5.152623236236044
Validation loss: 5.165826585624428

Epoch: 6| Step: 2
Training loss: 4.836329134611396
Validation loss: 5.159273744479475

Epoch: 6| Step: 3
Training loss: 6.358136180589243
Validation loss: 5.152871013093748

Epoch: 6| Step: 4
Training loss: 5.376096214466604
Validation loss: 5.146322013518525

Epoch: 6| Step: 5
Training loss: 5.452141353350449
Validation loss: 5.139795547555425

Epoch: 6| Step: 6
Training loss: 4.881143464746503
Validation loss: 5.133599889118117

Epoch: 6| Step: 7
Training loss: 4.861464465180818
Validation loss: 5.1267383387548895

Epoch: 6| Step: 8
Training loss: 5.48139216065781
Validation loss: 5.1201426430044625

Epoch: 6| Step: 9
Training loss: 5.663652665668507
Validation loss: 5.114350333671971

Epoch: 6| Step: 10
Training loss: 5.115372337295685
Validation loss: 5.107859815563342

Epoch: 6| Step: 11
Training loss: 4.583661061909874
Validation loss: 5.1016803628529335

Epoch: 6| Step: 12
Training loss: 4.827324365693299
Validation loss: 5.095920622923549

Epoch: 6| Step: 13
Training loss: 5.630061267363578
Validation loss: 5.089566468897812

Epoch: 10| Step: 0
Training loss: 5.238267959703032
Validation loss: 5.084125592555047

Epoch: 6| Step: 1
Training loss: 5.61373944094881
Validation loss: 5.077484403455112

Epoch: 6| Step: 2
Training loss: 5.4195241971222305
Validation loss: 5.071547849034091

Epoch: 6| Step: 3
Training loss: 5.598190505732773
Validation loss: 5.065156341780868

Epoch: 6| Step: 4
Training loss: 5.593641567777608
Validation loss: 5.059433247586518

Epoch: 6| Step: 5
Training loss: 5.052688887442619
Validation loss: 5.052811507875054

Epoch: 6| Step: 6
Training loss: 4.325884628231833
Validation loss: 5.0465392324835765

Epoch: 6| Step: 7
Training loss: 4.6533177506879095
Validation loss: 5.040253412243815

Epoch: 6| Step: 8
Training loss: 5.356531751382088
Validation loss: 5.0347395143175415

Epoch: 6| Step: 9
Training loss: 5.75707208021296
Validation loss: 5.02849037197456

Epoch: 6| Step: 10
Training loss: 4.7696424216671005
Validation loss: 5.0224115363217114

Epoch: 6| Step: 11
Training loss: 5.255695341875453
Validation loss: 5.015753913720054

Epoch: 6| Step: 12
Training loss: 4.942763601248017
Validation loss: 5.009798621155145

Epoch: 6| Step: 13
Training loss: 4.552788209208207
Validation loss: 5.004151528129368

Epoch: 11| Step: 0
Training loss: 4.448524427619779
Validation loss: 4.997805558888785

Epoch: 6| Step: 1
Training loss: 5.385235997999567
Validation loss: 4.991597394934905

Epoch: 6| Step: 2
Training loss: 4.916712399717234
Validation loss: 4.985291718594866

Epoch: 6| Step: 3
Training loss: 5.076674409703048
Validation loss: 4.9791553874932175

Epoch: 6| Step: 4
Training loss: 5.053803686497939
Validation loss: 4.973587464358599

Epoch: 6| Step: 5
Training loss: 5.200290217003706
Validation loss: 4.967284748268992

Epoch: 6| Step: 6
Training loss: 4.910480206347806
Validation loss: 4.961823183631534

Epoch: 6| Step: 7
Training loss: 5.057728909239833
Validation loss: 4.955562725736699

Epoch: 6| Step: 8
Training loss: 4.950474749060828
Validation loss: 4.948888079669781

Epoch: 6| Step: 9
Training loss: 5.639498695928729
Validation loss: 4.942320711662395

Epoch: 6| Step: 10
Training loss: 5.063561222321427
Validation loss: 4.935586904754154

Epoch: 6| Step: 11
Training loss: 5.642947408357729
Validation loss: 4.929109776293001

Epoch: 6| Step: 12
Training loss: 4.7622716894016826
Validation loss: 4.922263639738427

Epoch: 6| Step: 13
Training loss: 4.921998618859288
Validation loss: 4.915068975658609

Epoch: 12| Step: 0
Training loss: 4.467321207474559
Validation loss: 4.90864727957045

Epoch: 6| Step: 1
Training loss: 5.291402054225599
Validation loss: 4.902022530821319

Epoch: 6| Step: 2
Training loss: 5.003950846917777
Validation loss: 4.895640343724376

Epoch: 6| Step: 3
Training loss: 4.896872725300605
Validation loss: 4.889168324335595

Epoch: 6| Step: 4
Training loss: 4.90121434792956
Validation loss: 4.881882626302044

Epoch: 6| Step: 5
Training loss: 5.488090104545066
Validation loss: 4.8753328454269385

Epoch: 6| Step: 6
Training loss: 4.664521723492726
Validation loss: 4.869322543744031

Epoch: 6| Step: 7
Training loss: 4.406026415191165
Validation loss: 4.864259642369829

Epoch: 6| Step: 8
Training loss: 4.984004757323222
Validation loss: 4.857625304899869

Epoch: 6| Step: 9
Training loss: 5.37934930177642
Validation loss: 4.850609760035202

Epoch: 6| Step: 10
Training loss: 5.32552473321475
Validation loss: 4.84346525934537

Epoch: 6| Step: 11
Training loss: 4.652387617210273
Validation loss: 4.836018748055364

Epoch: 6| Step: 12
Training loss: 5.012827060141582
Validation loss: 4.828527472879883

Epoch: 6| Step: 13
Training loss: 5.258536165721519
Validation loss: 4.821182708257441

Epoch: 13| Step: 0
Training loss: 4.555322723848246
Validation loss: 4.814655135161427

Epoch: 6| Step: 1
Training loss: 3.135096300218784
Validation loss: 4.807630858297603

Epoch: 6| Step: 2
Training loss: 4.926253245501936
Validation loss: 4.802372568595408

Epoch: 6| Step: 3
Training loss: 5.459049012922331
Validation loss: 4.795845343704276

Epoch: 6| Step: 4
Training loss: 4.9978026330025545
Validation loss: 4.788340943053046

Epoch: 6| Step: 5
Training loss: 5.895287729995339
Validation loss: 4.781790841955481

Epoch: 6| Step: 6
Training loss: 4.370986405350824
Validation loss: 4.7748720601302805

Epoch: 6| Step: 7
Training loss: 6.079292871613249
Validation loss: 4.768759491903942

Epoch: 6| Step: 8
Training loss: 4.93136176501196
Validation loss: 4.761795322886335

Epoch: 6| Step: 9
Training loss: 4.521978113228608
Validation loss: 4.755285751977157

Epoch: 6| Step: 10
Training loss: 4.928419624186381
Validation loss: 4.749009715133715

Epoch: 6| Step: 11
Training loss: 4.541797437739171
Validation loss: 4.742821874613245

Epoch: 6| Step: 12
Training loss: 4.952381162416363
Validation loss: 4.735464644227482

Epoch: 6| Step: 13
Training loss: 4.615800729969198
Validation loss: 4.730198242114012

Epoch: 14| Step: 0
Training loss: 4.325556795298782
Validation loss: 4.7236498388846195

Epoch: 6| Step: 1
Training loss: 4.729140809558419
Validation loss: 4.716939313487251

Epoch: 6| Step: 2
Training loss: 4.840572176128517
Validation loss: 4.711140372577298

Epoch: 6| Step: 3
Training loss: 5.0331076278775155
Validation loss: 4.704962049514299

Epoch: 6| Step: 4
Training loss: 5.360266430624078
Validation loss: 4.698430858590875

Epoch: 6| Step: 5
Training loss: 4.970428759004584
Validation loss: 4.692640749338467

Epoch: 6| Step: 6
Training loss: 4.105327048428729
Validation loss: 4.686142958134796

Epoch: 6| Step: 7
Training loss: 4.906524067409867
Validation loss: 4.680745526894267

Epoch: 6| Step: 8
Training loss: 4.12649370372296
Validation loss: 4.675180139997887

Epoch: 6| Step: 9
Training loss: 5.088583356152257
Validation loss: 4.668870178609627

Epoch: 6| Step: 10
Training loss: 5.278953639878117
Validation loss: 4.662781625241562

Epoch: 6| Step: 11
Training loss: 3.810518343851414
Validation loss: 4.656218526507688

Epoch: 6| Step: 12
Training loss: 4.661416688303266
Validation loss: 4.65079972968202

Epoch: 6| Step: 13
Training loss: 5.713836059589839
Validation loss: 4.644626283863118

Epoch: 15| Step: 0
Training loss: 5.2937283241882085
Validation loss: 4.638347199437895

Epoch: 6| Step: 1
Training loss: 5.074873508323955
Validation loss: 4.6317218528132935

Epoch: 6| Step: 2
Training loss: 4.592171949403749
Validation loss: 4.62599872425159

Epoch: 6| Step: 3
Training loss: 4.452984081514845
Validation loss: 4.62027490519061

Epoch: 6| Step: 4
Training loss: 4.842480893153996
Validation loss: 4.614428733606861

Epoch: 6| Step: 5
Training loss: 4.250160438650812
Validation loss: 4.6083747425023915

Epoch: 6| Step: 6
Training loss: 3.5292859312140092
Validation loss: 4.601763977234032

Epoch: 6| Step: 7
Training loss: 4.911778730484631
Validation loss: 4.596521281229311

Epoch: 6| Step: 8
Training loss: 4.861614925373789
Validation loss: 4.589966788299903

Epoch: 6| Step: 9
Training loss: 4.555010357205354
Validation loss: 4.585012070679107

Epoch: 6| Step: 10
Training loss: 4.655130751071372
Validation loss: 4.578694209450506

Epoch: 6| Step: 11
Training loss: 4.9134402707460945
Validation loss: 4.573126050229431

Epoch: 6| Step: 12
Training loss: 5.684343740787298
Validation loss: 4.5678683187318985

Epoch: 6| Step: 13
Training loss: 4.192520548088295
Validation loss: 4.561845967693899

Epoch: 16| Step: 0
Training loss: 4.515872935316041
Validation loss: 4.556634590372754

Epoch: 6| Step: 1
Training loss: 4.553227656875605
Validation loss: 4.551736057515683

Epoch: 6| Step: 2
Training loss: 4.540314966106986
Validation loss: 4.544738582231409

Epoch: 6| Step: 3
Training loss: 5.254738440424082
Validation loss: 4.538971401576375

Epoch: 6| Step: 4
Training loss: 3.892308985262523
Validation loss: 4.533207577943292

Epoch: 6| Step: 5
Training loss: 4.710692948150815
Validation loss: 4.527897912494414

Epoch: 6| Step: 6
Training loss: 4.459669584342956
Validation loss: 4.522287243389435

Epoch: 6| Step: 7
Training loss: 3.6046926008104894
Validation loss: 4.5171762021835145

Epoch: 6| Step: 8
Training loss: 4.835642865746894
Validation loss: 4.511182877064217

Epoch: 6| Step: 9
Training loss: 4.796694475684938
Validation loss: 4.505733052238341

Epoch: 6| Step: 10
Training loss: 5.347887902157083
Validation loss: 4.500149406495981

Epoch: 6| Step: 11
Training loss: 5.257174539618658
Validation loss: 4.494319615453175

Epoch: 6| Step: 12
Training loss: 4.8307181989711525
Validation loss: 4.488395492476474

Epoch: 6| Step: 13
Training loss: 4.106390852232509
Validation loss: 4.482946702294145

Epoch: 17| Step: 0
Training loss: 4.212146705731588
Validation loss: 4.476409092838243

Epoch: 6| Step: 1
Training loss: 4.121143040656057
Validation loss: 4.470855252560901

Epoch: 6| Step: 2
Training loss: 4.460250133462445
Validation loss: 4.46581088071431

Epoch: 6| Step: 3
Training loss: 4.0182863908386155
Validation loss: 4.4600122920894725

Epoch: 6| Step: 4
Training loss: 4.608004505274478
Validation loss: 4.454589406653606

Epoch: 6| Step: 5
Training loss: 4.976564416331067
Validation loss: 4.449080637283298

Epoch: 6| Step: 6
Training loss: 4.605048369941618
Validation loss: 4.442872336946766

Epoch: 6| Step: 7
Training loss: 4.857630769281855
Validation loss: 4.43732505775866

Epoch: 6| Step: 8
Training loss: 4.7674917098374845
Validation loss: 4.432809974975369

Epoch: 6| Step: 9
Training loss: 4.691837389444487
Validation loss: 4.426691099256474

Epoch: 6| Step: 10
Training loss: 4.738947407186133
Validation loss: 4.4207224068251065

Epoch: 6| Step: 11
Training loss: 4.33481276762292
Validation loss: 4.41501771386907

Epoch: 6| Step: 12
Training loss: 4.765418876817987
Validation loss: 4.409026495383466

Epoch: 6| Step: 13
Training loss: 4.68777993955761
Validation loss: 4.40301954379117

Epoch: 18| Step: 0
Training loss: 3.975905928153221
Validation loss: 4.397264810980962

Epoch: 6| Step: 1
Training loss: 4.291304539090275
Validation loss: 4.39192898936211

Epoch: 6| Step: 2
Training loss: 3.8276608555516085
Validation loss: 4.38647293575154

Epoch: 6| Step: 3
Training loss: 4.1444815471807654
Validation loss: 4.381306326554411

Epoch: 6| Step: 4
Training loss: 4.765555359378462
Validation loss: 4.375479680967327

Epoch: 6| Step: 5
Training loss: 4.874432653034078
Validation loss: 4.36988307901219

Epoch: 6| Step: 6
Training loss: 5.091290400827343
Validation loss: 4.364193385267436

Epoch: 6| Step: 7
Training loss: 4.15439696341583
Validation loss: 4.356987922885778

Epoch: 6| Step: 8
Training loss: 4.418775570807599
Validation loss: 4.353227298043019

Epoch: 6| Step: 9
Training loss: 4.653320824862249
Validation loss: 4.347798352291271

Epoch: 6| Step: 10
Training loss: 4.15604509121002
Validation loss: 4.340993175633335

Epoch: 6| Step: 11
Training loss: 4.144771241799791
Validation loss: 4.335705431893744

Epoch: 6| Step: 12
Training loss: 4.556558162696825
Validation loss: 4.330028771678549

Epoch: 6| Step: 13
Training loss: 5.48119050953855
Validation loss: 4.324177324555508

Epoch: 19| Step: 0
Training loss: 5.292744243970237
Validation loss: 4.318943830116174

Epoch: 6| Step: 1
Training loss: 4.303650552850996
Validation loss: 4.312373007411071

Epoch: 6| Step: 2
Training loss: 4.345458428855255
Validation loss: 4.306989217131336

Epoch: 6| Step: 3
Training loss: 3.756253178701468
Validation loss: 4.300532260747308

Epoch: 6| Step: 4
Training loss: 4.672715535670337
Validation loss: 4.295307220200408

Epoch: 6| Step: 5
Training loss: 4.5566628100349345
Validation loss: 4.289311302764858

Epoch: 6| Step: 6
Training loss: 4.277940793805208
Validation loss: 4.28294235156969

Epoch: 6| Step: 7
Training loss: 4.833095128119873
Validation loss: 4.277870143509718

Epoch: 6| Step: 8
Training loss: 3.9002145757089144
Validation loss: 4.272082405106354

Epoch: 6| Step: 9
Training loss: 4.0267983630624835
Validation loss: 4.266311590251411

Epoch: 6| Step: 10
Training loss: 4.381764441311357
Validation loss: 4.26064741384945

Epoch: 6| Step: 11
Training loss: 4.590983485486925
Validation loss: 4.254606555360668

Epoch: 6| Step: 12
Training loss: 3.7846872139496655
Validation loss: 4.249007539245232

Epoch: 6| Step: 13
Training loss: 4.770682830879827
Validation loss: 4.243915203701087

Epoch: 20| Step: 0
Training loss: 4.774517829876908
Validation loss: 4.23899793527668

Epoch: 6| Step: 1
Training loss: 4.689926333306401
Validation loss: 4.233152243478046

Epoch: 6| Step: 2
Training loss: 4.2809488232339845
Validation loss: 4.227116443296925

Epoch: 6| Step: 3
Training loss: 4.603662707795657
Validation loss: 4.2215356742655485

Epoch: 6| Step: 4
Training loss: 4.934806185455787
Validation loss: 4.216421280507149

Epoch: 6| Step: 5
Training loss: 4.441912968565739
Validation loss: 4.210738498795774

Epoch: 6| Step: 6
Training loss: 4.240251018363237
Validation loss: 4.205308141587765

Epoch: 6| Step: 7
Training loss: 3.4717479500584933
Validation loss: 4.200143884283209

Epoch: 6| Step: 8
Training loss: 4.599167723621307
Validation loss: 4.1938839356154585

Epoch: 6| Step: 9
Training loss: 4.41319258228219
Validation loss: 4.188559687506973

Epoch: 6| Step: 10
Training loss: 4.091550046627515
Validation loss: 4.182824518535354

Epoch: 6| Step: 11
Training loss: 3.4942433836290863
Validation loss: 4.178313412694281

Epoch: 6| Step: 12
Training loss: 5.017172886516206
Validation loss: 4.173058883572108

Epoch: 6| Step: 13
Training loss: 3.1600210493328302
Validation loss: 4.167981525223998

Epoch: 21| Step: 0
Training loss: 4.612532849698827
Validation loss: 4.163194748460711

Epoch: 6| Step: 1
Training loss: 4.756287078111368
Validation loss: 4.157935888119381

Epoch: 6| Step: 2
Training loss: 4.93089567393357
Validation loss: 4.15208109338639

Epoch: 6| Step: 3
Training loss: 4.207242969225763
Validation loss: 4.146467661932482

Epoch: 6| Step: 4
Training loss: 4.21089016634749
Validation loss: 4.140933983748309

Epoch: 6| Step: 5
Training loss: 3.7185475270264323
Validation loss: 4.136159693974403

Epoch: 6| Step: 6
Training loss: 3.509493079029068
Validation loss: 4.131136019967193

Epoch: 6| Step: 7
Training loss: 4.633829503742124
Validation loss: 4.1260619674962635

Epoch: 6| Step: 8
Training loss: 4.883438827017462
Validation loss: 4.120875753268588

Epoch: 6| Step: 9
Training loss: 4.3255349682832085
Validation loss: 4.1166519888076945

Epoch: 6| Step: 10
Training loss: 3.2058061497005723
Validation loss: 4.110647026421763

Epoch: 6| Step: 11
Training loss: 4.354308544323647
Validation loss: 4.105647786426072

Epoch: 6| Step: 12
Training loss: 4.33723784872032
Validation loss: 4.100684798047445

Epoch: 6| Step: 13
Training loss: 3.544726288078878
Validation loss: 4.095409920669067

Epoch: 22| Step: 0
Training loss: 4.5380992819432056
Validation loss: 4.091772713358457

Epoch: 6| Step: 1
Training loss: 3.6813615040496273
Validation loss: 4.086719620430543

Epoch: 6| Step: 2
Training loss: 3.753232198767645
Validation loss: 4.08136099586056

Epoch: 6| Step: 3
Training loss: 4.443766293180617
Validation loss: 4.076512745165777

Epoch: 6| Step: 4
Training loss: 4.386931797197413
Validation loss: 4.071798022994941

Epoch: 6| Step: 5
Training loss: 4.575871769128781
Validation loss: 4.067117346091287

Epoch: 6| Step: 6
Training loss: 4.063183536245779
Validation loss: 4.062327180756716

Epoch: 6| Step: 7
Training loss: 4.065172460822599
Validation loss: 4.057156574838833

Epoch: 6| Step: 8
Training loss: 2.946594121336285
Validation loss: 4.0521047178094785

Epoch: 6| Step: 9
Training loss: 4.23378127323896
Validation loss: 4.04900407201817

Epoch: 6| Step: 10
Training loss: 3.815917812549981
Validation loss: 4.0430581492984246

Epoch: 6| Step: 11
Training loss: 4.477735329156751
Validation loss: 4.040391989723692

Epoch: 6| Step: 12
Training loss: 4.8112833045605585
Validation loss: 4.0352542910831835

Epoch: 6| Step: 13
Training loss: 4.535804301378135
Validation loss: 4.030148575018398

Epoch: 23| Step: 0
Training loss: 3.4684032919881194
Validation loss: 4.025513700318586

Epoch: 6| Step: 1
Training loss: 4.209978493388644
Validation loss: 4.021206154940507

Epoch: 6| Step: 2
Training loss: 4.149310980899231
Validation loss: 4.016811012639631

Epoch: 6| Step: 3
Training loss: 3.78224610378537
Validation loss: 4.011466360401941

Epoch: 6| Step: 4
Training loss: 3.837359069820976
Validation loss: 4.005564236877694

Epoch: 6| Step: 5
Training loss: 4.695985768012295
Validation loss: 4.000511812208934

Epoch: 6| Step: 6
Training loss: 4.214399567144512
Validation loss: 3.995769150702117

Epoch: 6| Step: 7
Training loss: 3.5039922561211565
Validation loss: 3.9916745806292377

Epoch: 6| Step: 8
Training loss: 3.649912762579193
Validation loss: 3.987963946227641

Epoch: 6| Step: 9
Training loss: 3.885234484181143
Validation loss: 3.982669041253493

Epoch: 6| Step: 10
Training loss: 3.8679585622562005
Validation loss: 3.978115815149309

Epoch: 6| Step: 11
Training loss: 4.913489182449161
Validation loss: 3.972655389786299

Epoch: 6| Step: 12
Training loss: 4.783398712632949
Validation loss: 3.9686601082941846

Epoch: 6| Step: 13
Training loss: 4.455416334159285
Validation loss: 3.963215350412737

Epoch: 24| Step: 0
Training loss: 4.524156371661366
Validation loss: 3.9588452392980673

Epoch: 6| Step: 1
Training loss: 3.623381944158915
Validation loss: 3.954988967455729

Epoch: 6| Step: 2
Training loss: 4.320827239622983
Validation loss: 3.9513288194276495

Epoch: 6| Step: 3
Training loss: 4.12676524913991
Validation loss: 3.9455178991048796

Epoch: 6| Step: 4
Training loss: 4.578858821241205
Validation loss: 3.9398459656453424

Epoch: 6| Step: 5
Training loss: 3.952862515989204
Validation loss: 3.93444382675766

Epoch: 6| Step: 6
Training loss: 4.0781133074245695
Validation loss: 3.928903813771294

Epoch: 6| Step: 7
Training loss: 4.548662915634479
Validation loss: 3.9241117910027676

Epoch: 6| Step: 8
Training loss: 3.1858052254794833
Validation loss: 3.918981267258906

Epoch: 6| Step: 9
Training loss: 3.441831322180359
Validation loss: 3.914558201591263

Epoch: 6| Step: 10
Training loss: 5.081279443934718
Validation loss: 3.910354390746765

Epoch: 6| Step: 11
Training loss: 3.9279027567944573
Validation loss: 3.904739576147395

Epoch: 6| Step: 12
Training loss: 3.3194969701579327
Validation loss: 3.8998705333021966

Epoch: 6| Step: 13
Training loss: 3.688684693459341
Validation loss: 3.8952894324129583

Epoch: 25| Step: 0
Training loss: 4.0167581466029025
Validation loss: 3.8910126397234683

Epoch: 6| Step: 1
Training loss: 4.019649403784577
Validation loss: 3.8860055035800674

Epoch: 6| Step: 2
Training loss: 4.724853206554287
Validation loss: 3.880519852731518

Epoch: 6| Step: 3
Training loss: 4.166439558833431
Validation loss: 3.8751381675124317

Epoch: 6| Step: 4
Training loss: 3.441397243665499
Validation loss: 3.8707604340148185

Epoch: 6| Step: 5
Training loss: 3.1658303679027027
Validation loss: 3.865377661548758

Epoch: 6| Step: 6
Training loss: 4.2917454289489605
Validation loss: 3.8616418912013506

Epoch: 6| Step: 7
Training loss: 4.1979835574340125
Validation loss: 3.8569861881456173

Epoch: 6| Step: 8
Training loss: 3.8655437636724783
Validation loss: 3.8517203875737276

Epoch: 6| Step: 9
Training loss: 3.205065925384308
Validation loss: 3.847640263093374

Epoch: 6| Step: 10
Training loss: 3.8988899167202242
Validation loss: 3.8428232579958195

Epoch: 6| Step: 11
Training loss: 4.0009149458658495
Validation loss: 3.838055121315718

Epoch: 6| Step: 12
Training loss: 4.092372283900156
Validation loss: 3.834029894581411

Epoch: 6| Step: 13
Training loss: 4.499219614814772
Validation loss: 3.829401086405332

Epoch: 26| Step: 0
Training loss: 3.779964007655354
Validation loss: 3.8247273009251868

Epoch: 6| Step: 1
Training loss: 3.7540988138370484
Validation loss: 3.81978817327482

Epoch: 6| Step: 2
Training loss: 3.9808266790434352
Validation loss: 3.816271474665174

Epoch: 6| Step: 3
Training loss: 4.415451938399115
Validation loss: 3.810828712894907

Epoch: 6| Step: 4
Training loss: 3.3001166583162016
Validation loss: 3.8059591874396523

Epoch: 6| Step: 5
Training loss: 4.261942073519666
Validation loss: 3.801208263010446

Epoch: 6| Step: 6
Training loss: 4.676052101595526
Validation loss: 3.796115856913606

Epoch: 6| Step: 7
Training loss: 3.2425178083814585
Validation loss: 3.791400201398195

Epoch: 6| Step: 8
Training loss: 4.438461844206895
Validation loss: 3.786107413897377

Epoch: 6| Step: 9
Training loss: 3.7786139765771756
Validation loss: 3.7813513245681407

Epoch: 6| Step: 10
Training loss: 3.3755795016627737
Validation loss: 3.776898720478617

Epoch: 6| Step: 11
Training loss: 4.004199208032415
Validation loss: 3.7716924977706845

Epoch: 6| Step: 12
Training loss: 3.5997332315150423
Validation loss: 3.766944959931909

Epoch: 6| Step: 13
Training loss: 4.08564456743022
Validation loss: 3.7625422013831997

Epoch: 27| Step: 0
Training loss: 4.293864135113666
Validation loss: 3.757818717713476

Epoch: 6| Step: 1
Training loss: 3.9018780465750385
Validation loss: 3.752897266569183

Epoch: 6| Step: 2
Training loss: 3.5993136917353663
Validation loss: 3.74852543555861

Epoch: 6| Step: 3
Training loss: 3.904587170493811
Validation loss: 3.7445942168337427

Epoch: 6| Step: 4
Training loss: 3.19178469035468
Validation loss: 3.7393939821268485

Epoch: 6| Step: 5
Training loss: 3.492050407159464
Validation loss: 3.734384853291514

Epoch: 6| Step: 6
Training loss: 3.3808946348717366
Validation loss: 3.72992899187081

Epoch: 6| Step: 7
Training loss: 3.73608257246561
Validation loss: 3.7255925076394667

Epoch: 6| Step: 8
Training loss: 3.681673781349373
Validation loss: 3.721749066096804

Epoch: 6| Step: 9
Training loss: 4.543582523832808
Validation loss: 3.7172645786413514

Epoch: 6| Step: 10
Training loss: 3.812144778853684
Validation loss: 3.713188329350403

Epoch: 6| Step: 11
Training loss: 4.672755742062234
Validation loss: 3.7083621006110574

Epoch: 6| Step: 12
Training loss: 4.165045359205381
Validation loss: 3.7036194719343722

Epoch: 6| Step: 13
Training loss: 3.3812030725519095
Validation loss: 3.6989245406834246

Epoch: 28| Step: 0
Training loss: 4.354581213873244
Validation loss: 3.694868151110865

Epoch: 6| Step: 1
Training loss: 3.669981253053769
Validation loss: 3.689794526965529

Epoch: 6| Step: 2
Training loss: 4.140104901740065
Validation loss: 3.6856397041957707

Epoch: 6| Step: 3
Training loss: 3.966642165442271
Validation loss: 3.682357974536789

Epoch: 6| Step: 4
Training loss: 3.4802905035989333
Validation loss: 3.6785523215268103

Epoch: 6| Step: 5
Training loss: 3.1088707289742135
Validation loss: 3.6732742781718097

Epoch: 6| Step: 6
Training loss: 3.6982706822822893
Validation loss: 3.6708921808093242

Epoch: 6| Step: 7
Training loss: 3.1131881259598155
Validation loss: 3.66651659716211

Epoch: 6| Step: 8
Training loss: 3.741888810822496
Validation loss: 3.660778469094569

Epoch: 6| Step: 9
Training loss: 3.7540339072092905
Validation loss: 3.6545515109330764

Epoch: 6| Step: 10
Training loss: 3.683050542363955
Validation loss: 3.6517204854444567

Epoch: 6| Step: 11
Training loss: 3.4006876194072926
Validation loss: 3.6511095215735985

Epoch: 6| Step: 12
Training loss: 4.657137997329677
Validation loss: 3.6491453149912356

Epoch: 6| Step: 13
Training loss: 4.169807521851232
Validation loss: 3.6442446635183803

Epoch: 29| Step: 0
Training loss: 2.5165272865688166
Validation loss: 3.63695058005174

Epoch: 6| Step: 1
Training loss: 3.6948545143898865
Validation loss: 3.630976431035149

Epoch: 6| Step: 2
Training loss: 3.580070399865506
Validation loss: 3.6259638721625156

Epoch: 6| Step: 3
Training loss: 3.4159556013344328
Validation loss: 3.6210323631682577

Epoch: 6| Step: 4
Training loss: 3.3862830985117887
Validation loss: 3.6181902117005196

Epoch: 6| Step: 5
Training loss: 3.1908747441721377
Validation loss: 3.614409619351967

Epoch: 6| Step: 6
Training loss: 3.68352229351424
Validation loss: 3.6093089660504982

Epoch: 6| Step: 7
Training loss: 4.315761051892383
Validation loss: 3.60381021372365

Epoch: 6| Step: 8
Training loss: 4.253478477975134
Validation loss: 3.5966911112037447

Epoch: 6| Step: 9
Training loss: 3.5069829218970456
Validation loss: 3.591152479770956

Epoch: 6| Step: 10
Training loss: 3.6843228634938305
Validation loss: 3.5870039717694184

Epoch: 6| Step: 11
Training loss: 4.40399826627692
Validation loss: 3.582607609795776

Epoch: 6| Step: 12
Training loss: 3.842154815398292
Validation loss: 3.577078253879988

Epoch: 6| Step: 13
Training loss: 4.3953211095720865
Validation loss: 3.5725419021259754

Epoch: 30| Step: 0
Training loss: 3.863953380532523
Validation loss: 3.5674442091395178

Epoch: 6| Step: 1
Training loss: 3.451595191921626
Validation loss: 3.562791957380549

Epoch: 6| Step: 2
Training loss: 4.238854772903479
Validation loss: 3.5585878541732168

Epoch: 6| Step: 3
Training loss: 3.5192373747921972
Validation loss: 3.553860500396503

Epoch: 6| Step: 4
Training loss: 4.014182696356328
Validation loss: 3.5495532171072828

Epoch: 6| Step: 5
Training loss: 3.357023613849821
Validation loss: 3.544980925601493

Epoch: 6| Step: 6
Training loss: 3.3898787138631006
Validation loss: 3.5401217438261123

Epoch: 6| Step: 7
Training loss: 3.425906936967097
Validation loss: 3.5352569846734903

Epoch: 6| Step: 8
Training loss: 4.1888933283486915
Validation loss: 3.531260622621836

Epoch: 6| Step: 9
Training loss: 3.030039437418195
Validation loss: 3.5260014872137617

Epoch: 6| Step: 10
Training loss: 3.812963238698738
Validation loss: 3.521920000729213

Epoch: 6| Step: 11
Training loss: 3.5173986411385894
Validation loss: 3.51776748365006

Epoch: 6| Step: 12
Training loss: 3.5687083975109037
Validation loss: 3.5137058247227864

Epoch: 6| Step: 13
Training loss: 3.882043405422834
Validation loss: 3.509439228542388

Epoch: 31| Step: 0
Training loss: 3.8528229854186415
Validation loss: 3.5051763040894017

Epoch: 6| Step: 1
Training loss: 3.770048590228071
Validation loss: 3.500828451927927

Epoch: 6| Step: 2
Training loss: 3.686457729132952
Validation loss: 3.496266235415701

Epoch: 6| Step: 3
Training loss: 3.7330460358383575
Validation loss: 3.491721626401525

Epoch: 6| Step: 4
Training loss: 3.975945505417339
Validation loss: 3.4873681320362904

Epoch: 6| Step: 5
Training loss: 2.788383508091346
Validation loss: 3.4828667676533307

Epoch: 6| Step: 6
Training loss: 3.065272885942687
Validation loss: 3.47876774143598

Epoch: 6| Step: 7
Training loss: 3.1102989779208787
Validation loss: 3.474519302089843

Epoch: 6| Step: 8
Training loss: 3.476048120742825
Validation loss: 3.4710635468763544

Epoch: 6| Step: 9
Training loss: 4.290424623971326
Validation loss: 3.4671552732510555

Epoch: 6| Step: 10
Training loss: 3.901168081003462
Validation loss: 3.4629131616905067

Epoch: 6| Step: 11
Training loss: 2.87867402546684
Validation loss: 3.4589070031997187

Epoch: 6| Step: 12
Training loss: 3.465220262096444
Validation loss: 3.454823532198307

Epoch: 6| Step: 13
Training loss: 4.226952836209675
Validation loss: 3.451053763446204

Epoch: 32| Step: 0
Training loss: 3.719512604809128
Validation loss: 3.4468288876217845

Epoch: 6| Step: 1
Training loss: 3.009133739842384
Validation loss: 3.4426357398216223

Epoch: 6| Step: 2
Training loss: 2.928155523932919
Validation loss: 3.439025286193394

Epoch: 6| Step: 3
Training loss: 4.355434154150718
Validation loss: 3.4353377737807094

Epoch: 6| Step: 4
Training loss: 3.7203443940007954
Validation loss: 3.431340195212116

Epoch: 6| Step: 5
Training loss: 3.4515286030795074
Validation loss: 3.426969014186789

Epoch: 6| Step: 6
Training loss: 3.6437023074658734
Validation loss: 3.422765375014518

Epoch: 6| Step: 7
Training loss: 3.784947628732278
Validation loss: 3.418884433704452

Epoch: 6| Step: 8
Training loss: 3.2568767859600984
Validation loss: 3.414854968851175

Epoch: 6| Step: 9
Training loss: 3.7664978788474452
Validation loss: 3.4112811248801918

Epoch: 6| Step: 10
Training loss: 3.3336179293892556
Validation loss: 3.4075695363424883

Epoch: 6| Step: 11
Training loss: 4.252939890379553
Validation loss: 3.402836200100133

Epoch: 6| Step: 12
Training loss: 3.3969804819358793
Validation loss: 3.3989153062063244

Epoch: 6| Step: 13
Training loss: 2.8454167438580993
Validation loss: 3.3949465305572954

Epoch: 33| Step: 0
Training loss: 3.251859426437293
Validation loss: 3.390638782104046

Epoch: 6| Step: 1
Training loss: 3.9414893633998855
Validation loss: 3.386592007575031

Epoch: 6| Step: 2
Training loss: 3.659855817028921
Validation loss: 3.383210755619173

Epoch: 6| Step: 3
Training loss: 4.444141414696247
Validation loss: 3.3792163743307535

Epoch: 6| Step: 4
Training loss: 2.4494467207873853
Validation loss: 3.3749019349533036

Epoch: 6| Step: 5
Training loss: 3.534541258877249
Validation loss: 3.370665557294776

Epoch: 6| Step: 6
Training loss: 3.628420038573037
Validation loss: 3.366752484301109

Epoch: 6| Step: 7
Training loss: 3.46961675588807
Validation loss: 3.3631711108124476

Epoch: 6| Step: 8
Training loss: 3.7951624897584337
Validation loss: 3.358954351540677

Epoch: 6| Step: 9
Training loss: 2.765826201797981
Validation loss: 3.354624241168968

Epoch: 6| Step: 10
Training loss: 3.801855392242444
Validation loss: 3.3510424633616096

Epoch: 6| Step: 11
Training loss: 3.359933921981652
Validation loss: 3.3471723612601862

Epoch: 6| Step: 12
Training loss: 3.4096321323679732
Validation loss: 3.3432748046904153

Epoch: 6| Step: 13
Training loss: 3.1148336218522634
Validation loss: 3.339249764431797

Epoch: 34| Step: 0
Training loss: 3.3561263589088672
Validation loss: 3.3354493021435663

Epoch: 6| Step: 1
Training loss: 3.3777196310989215
Validation loss: 3.331435406304433

Epoch: 6| Step: 2
Training loss: 3.1849149805815404
Validation loss: 3.3282505065463703

Epoch: 6| Step: 3
Training loss: 3.686600914955719
Validation loss: 3.324614916996174

Epoch: 6| Step: 4
Training loss: 4.1936836703607945
Validation loss: 3.32080378469406

Epoch: 6| Step: 5
Training loss: 3.3156275829193667
Validation loss: 3.3178156780960553

Epoch: 6| Step: 6
Training loss: 3.431474155129153
Validation loss: 3.312982128252853

Epoch: 6| Step: 7
Training loss: 3.669016143139488
Validation loss: 3.309508598399842

Epoch: 6| Step: 8
Training loss: 3.3613376295896273
Validation loss: 3.30573345733183

Epoch: 6| Step: 9
Training loss: 3.242604277146526
Validation loss: 3.3021089249992053

Epoch: 6| Step: 10
Training loss: 3.3144338468981194
Validation loss: 3.2982456678550336

Epoch: 6| Step: 11
Training loss: 3.7031989110338936
Validation loss: 3.2940417947671228

Epoch: 6| Step: 12
Training loss: 3.9866874417005027
Validation loss: 3.290247736090063

Epoch: 6| Step: 13
Training loss: 2.036978288567579
Validation loss: 3.2865348279043816

Epoch: 35| Step: 0
Training loss: 3.1458981404144795
Validation loss: 3.2830615658928344

Epoch: 6| Step: 1
Training loss: 2.4071031519456008
Validation loss: 3.2793761579461704

Epoch: 6| Step: 2
Training loss: 4.0999052641553595
Validation loss: 3.276259074959624

Epoch: 6| Step: 3
Training loss: 3.7233045880042788
Validation loss: 3.272939105395043

Epoch: 6| Step: 4
Training loss: 3.35308205896134
Validation loss: 3.268965623209816

Epoch: 6| Step: 5
Training loss: 3.2355811777107606
Validation loss: 3.2651095432211465

Epoch: 6| Step: 6
Training loss: 3.2728416610725533
Validation loss: 3.261416435317783

Epoch: 6| Step: 7
Training loss: 3.719035802805785
Validation loss: 3.257811499823425

Epoch: 6| Step: 8
Training loss: 4.12141493860924
Validation loss: 3.2540645858507387

Epoch: 6| Step: 9
Training loss: 3.741986932337181
Validation loss: 3.250370872561932

Epoch: 6| Step: 10
Training loss: 2.673691160206432
Validation loss: 3.2463497913187696

Epoch: 6| Step: 11
Training loss: 2.998902437979524
Validation loss: 3.2426710388672784

Epoch: 6| Step: 12
Training loss: 3.4748721696134104
Validation loss: 3.2393557764005876

Epoch: 6| Step: 13
Training loss: 3.172687144670357
Validation loss: 3.2356794371362896

Epoch: 36| Step: 0
Training loss: 3.584813957973447
Validation loss: 3.232222339814004

Epoch: 6| Step: 1
Training loss: 3.4754770020157704
Validation loss: 3.2288905035902995

Epoch: 6| Step: 2
Training loss: 3.0063235077624624
Validation loss: 3.225511405869861

Epoch: 6| Step: 3
Training loss: 3.297598086063102
Validation loss: 3.2216411432938235

Epoch: 6| Step: 4
Training loss: 3.4711931577155695
Validation loss: 3.21815361744666

Epoch: 6| Step: 5
Training loss: 4.007989533736217
Validation loss: 3.214914042251702

Epoch: 6| Step: 6
Training loss: 3.088075616592629
Validation loss: 3.2113984729204526

Epoch: 6| Step: 7
Training loss: 2.979039400668011
Validation loss: 3.2079433641777424

Epoch: 6| Step: 8
Training loss: 2.964526575384695
Validation loss: 3.204281754694239

Epoch: 6| Step: 9
Training loss: 3.2421801463583773
Validation loss: 3.201442481305161

Epoch: 6| Step: 10
Training loss: 3.0161989288496134
Validation loss: 3.198006635926602

Epoch: 6| Step: 11
Training loss: 3.5510384075179307
Validation loss: 3.194852054316687

Epoch: 6| Step: 12
Training loss: 3.647139585910944
Validation loss: 3.1914941409088766

Epoch: 6| Step: 13
Training loss: 3.3902899932606534
Validation loss: 3.187900842133665

Epoch: 37| Step: 0
Training loss: 3.618860636388617
Validation loss: 3.1841426196800566

Epoch: 6| Step: 1
Training loss: 3.310202899718488
Validation loss: 3.180533981435162

Epoch: 6| Step: 2
Training loss: 3.2205860123586962
Validation loss: 3.1774513948626306

Epoch: 6| Step: 3
Training loss: 3.5855703394465226
Validation loss: 3.174072243716629

Epoch: 6| Step: 4
Training loss: 3.1152998866544235
Validation loss: 3.170239056419149

Epoch: 6| Step: 5
Training loss: 3.4624958189791006
Validation loss: 3.1668308282430067

Epoch: 6| Step: 6
Training loss: 3.4364029954561754
Validation loss: 3.16328539940306

Epoch: 6| Step: 7
Training loss: 3.76404826603752
Validation loss: 3.1600158685374296

Epoch: 6| Step: 8
Training loss: 2.7721187411276036
Validation loss: 3.156539802969433

Epoch: 6| Step: 9
Training loss: 3.4237258991620187
Validation loss: 3.1525055482570017

Epoch: 6| Step: 10
Training loss: 2.5747810641054847
Validation loss: 3.1493978495020345

Epoch: 6| Step: 11
Training loss: 3.503761177929765
Validation loss: 3.1463502665504333

Epoch: 6| Step: 12
Training loss: 2.970819815827408
Validation loss: 3.1437071042076252

Epoch: 6| Step: 13
Training loss: 3.2941502887046235
Validation loss: 3.1419034920902984

Epoch: 38| Step: 0
Training loss: 2.7772348975460215
Validation loss: 3.138592620716217

Epoch: 6| Step: 1
Training loss: 3.3976992451992625
Validation loss: 3.1361466420873985

Epoch: 6| Step: 2
Training loss: 3.291969011802877
Validation loss: 3.1322043725245976

Epoch: 6| Step: 3
Training loss: 3.481318617303729
Validation loss: 3.1285827825111725

Epoch: 6| Step: 4
Training loss: 3.027896402428645
Validation loss: 3.1250589365169916

Epoch: 6| Step: 5
Training loss: 3.02661580839854
Validation loss: 3.1212653032181557

Epoch: 6| Step: 6
Training loss: 3.155663010807834
Validation loss: 3.1177393935407047

Epoch: 6| Step: 7
Training loss: 3.6132792704808767
Validation loss: 3.1145573915827995

Epoch: 6| Step: 8
Training loss: 2.621055909749208
Validation loss: 3.1114630405495567

Epoch: 6| Step: 9
Training loss: 4.141203066222829
Validation loss: 3.1086739112327284

Epoch: 6| Step: 10
Training loss: 3.058833827782465
Validation loss: 3.105584138849782

Epoch: 6| Step: 11
Training loss: 3.2528684135628034
Validation loss: 3.1028233807008303

Epoch: 6| Step: 12
Training loss: 3.6015887145704046
Validation loss: 3.099746723493183

Epoch: 6| Step: 13
Training loss: 2.8698551750194534
Validation loss: 3.0969111286805626

Epoch: 39| Step: 0
Training loss: 3.3803899605519465
Validation loss: 3.092953280732778

Epoch: 6| Step: 1
Training loss: 2.637131857829144
Validation loss: 3.0905121194136607

Epoch: 6| Step: 2
Training loss: 3.7162807184381084
Validation loss: 3.0871587469468267

Epoch: 6| Step: 3
Training loss: 3.4951356054365936
Validation loss: 3.083665022321543

Epoch: 6| Step: 4
Training loss: 3.0259321305655655
Validation loss: 3.0806028458963506

Epoch: 6| Step: 5
Training loss: 2.5020585168205476
Validation loss: 3.077664051946257

Epoch: 6| Step: 6
Training loss: 3.22418332072361
Validation loss: 3.0750141593172917

Epoch: 6| Step: 7
Training loss: 3.137371902586488
Validation loss: 3.071893467787797

Epoch: 6| Step: 8
Training loss: 2.8891762892089075
Validation loss: 3.0690404895619476

Epoch: 6| Step: 9
Training loss: 3.2918521168936294
Validation loss: 3.0660567746588643

Epoch: 6| Step: 10
Training loss: 2.967468949037374
Validation loss: 3.063123457889497

Epoch: 6| Step: 11
Training loss: 3.706453396907516
Validation loss: 3.0601456538817056

Epoch: 6| Step: 12
Training loss: 3.386684958741457
Validation loss: 3.057400746433146

Epoch: 6| Step: 13
Training loss: 3.3791007101737986
Validation loss: 3.0545124026536024

Epoch: 40| Step: 0
Training loss: 2.9411817163532823
Validation loss: 3.0509792887175275

Epoch: 6| Step: 1
Training loss: 3.5519101873504497
Validation loss: 3.0484576817868847

Epoch: 6| Step: 2
Training loss: 3.709284942484993
Validation loss: 3.0453886139701916

Epoch: 6| Step: 3
Training loss: 3.49429100911359
Validation loss: 3.0422504509315194

Epoch: 6| Step: 4
Training loss: 3.443477219649297
Validation loss: 3.038672584814435

Epoch: 6| Step: 5
Training loss: 3.15316364729668
Validation loss: 3.0352811979925427

Epoch: 6| Step: 6
Training loss: 3.204696046696002
Validation loss: 3.03277320214003

Epoch: 6| Step: 7
Training loss: 3.010288398588378
Validation loss: 3.0294346305634883

Epoch: 6| Step: 8
Training loss: 2.790199197747421
Validation loss: 3.0257022993466234

Epoch: 6| Step: 9
Training loss: 2.6139567461528617
Validation loss: 3.023099159149736

Epoch: 6| Step: 10
Training loss: 3.011607602217036
Validation loss: 3.02067343628489

Epoch: 6| Step: 11
Training loss: 2.7357949194146425
Validation loss: 3.016910180297091

Epoch: 6| Step: 12
Training loss: 3.224420238102845
Validation loss: 3.014156623136665

Epoch: 6| Step: 13
Training loss: 3.3176669722553447
Validation loss: 3.0120553745103726

Epoch: 41| Step: 0
Training loss: 2.940162750462386
Validation loss: 3.0093504701686173

Epoch: 6| Step: 1
Training loss: 3.188027282186483
Validation loss: 3.0058873608835337

Epoch: 6| Step: 2
Training loss: 3.260495332169054
Validation loss: 3.0031763057183216

Epoch: 6| Step: 3
Training loss: 3.5985841828040566
Validation loss: 3.0015400403976473

Epoch: 6| Step: 4
Training loss: 3.547373732402447
Validation loss: 2.9983554942181643

Epoch: 6| Step: 5
Training loss: 3.0308271290090927
Validation loss: 2.995326401889348

Epoch: 6| Step: 6
Training loss: 3.3053338611392573
Validation loss: 2.9922388402719213

Epoch: 6| Step: 7
Training loss: 2.589333508430944
Validation loss: 2.989334884758285

Epoch: 6| Step: 8
Training loss: 2.7364142089198267
Validation loss: 2.9864324830480675

Epoch: 6| Step: 9
Training loss: 3.00623135313092
Validation loss: 2.9837204513290585

Epoch: 6| Step: 10
Training loss: 3.653571296886862
Validation loss: 2.981286292984814

Epoch: 6| Step: 11
Training loss: 3.1641188628274675
Validation loss: 2.9787199756999705

Epoch: 6| Step: 12
Training loss: 2.578612310419837
Validation loss: 2.9759842919273516

Epoch: 6| Step: 13
Training loss: 3.0466513527193846
Validation loss: 2.9736633599878006

Epoch: 42| Step: 0
Training loss: 2.9529375289266877
Validation loss: 2.970607109783762

Epoch: 6| Step: 1
Training loss: 3.1508691829837
Validation loss: 2.968123855146127

Epoch: 6| Step: 2
Training loss: 3.5160899215153245
Validation loss: 2.9647963046372547

Epoch: 6| Step: 3
Training loss: 3.050263071440343
Validation loss: 2.9630957046108772

Epoch: 6| Step: 4
Training loss: 2.5119873662618764
Validation loss: 2.960236841404975

Epoch: 6| Step: 5
Training loss: 2.7499722566072142
Validation loss: 2.956536651864983

Epoch: 6| Step: 6
Training loss: 2.6828562515770344
Validation loss: 2.9562026844714193

Epoch: 6| Step: 7
Training loss: 2.9336382866334696
Validation loss: 2.9526063574644152

Epoch: 6| Step: 8
Training loss: 3.3370935371145443
Validation loss: 2.9493136426467825

Epoch: 6| Step: 9
Training loss: 3.1985276888313323
Validation loss: 2.9465302261277233

Epoch: 6| Step: 10
Training loss: 3.4415351072818248
Validation loss: 2.943839287399298

Epoch: 6| Step: 11
Training loss: 3.5977758000461146
Validation loss: 2.9411030985057702

Epoch: 6| Step: 12
Training loss: 3.191038523748403
Validation loss: 2.9385538848511157

Epoch: 6| Step: 13
Training loss: 2.816088188930825
Validation loss: 2.938219712740612

Epoch: 43| Step: 0
Training loss: 2.8720030713503255
Validation loss: 2.9351541337239233

Epoch: 6| Step: 1
Training loss: 3.19806953255341
Validation loss: 2.9341597131763923

Epoch: 6| Step: 2
Training loss: 2.861794537231427
Validation loss: 2.931034737974495

Epoch: 6| Step: 3
Training loss: 3.230553032030465
Validation loss: 2.9292068561891664

Epoch: 6| Step: 4
Training loss: 2.7633443793370156
Validation loss: 2.9263100241754496

Epoch: 6| Step: 5
Training loss: 2.611721605487053
Validation loss: 2.9249705544100877

Epoch: 6| Step: 6
Training loss: 3.211868485301059
Validation loss: 2.9235644564577035

Epoch: 6| Step: 7
Training loss: 3.2631750818781136
Validation loss: 2.919202279140363

Epoch: 6| Step: 8
Training loss: 2.667762848936176
Validation loss: 2.916524820057451

Epoch: 6| Step: 9
Training loss: 3.605967180344976
Validation loss: 2.914693237443007

Epoch: 6| Step: 10
Training loss: 2.611182677413244
Validation loss: 2.912396975156316

Epoch: 6| Step: 11
Training loss: 3.1243871469370297
Validation loss: 2.911652196299758

Epoch: 6| Step: 12
Training loss: 3.3091698947705988
Validation loss: 2.9098567800027495

Epoch: 6| Step: 13
Training loss: 3.307647029177827
Validation loss: 2.9074047898075803

Epoch: 44| Step: 0
Training loss: 3.128778538377543
Validation loss: 2.905009097086702

Epoch: 6| Step: 1
Training loss: 3.14452594259063
Validation loss: 2.9014161631258535

Epoch: 6| Step: 2
Training loss: 3.1960317086758274
Validation loss: 2.8991848512499376

Epoch: 6| Step: 3
Training loss: 2.768819397342943
Validation loss: 2.8968951019171256

Epoch: 6| Step: 4
Training loss: 2.4197905399376265
Validation loss: 2.8943144682351747

Epoch: 6| Step: 5
Training loss: 3.289032054769276
Validation loss: 2.8915438454641667

Epoch: 6| Step: 6
Training loss: 2.543195066914149
Validation loss: 2.8894629539785677

Epoch: 6| Step: 7
Training loss: 2.8194030817147477
Validation loss: 2.887890156070316

Epoch: 6| Step: 8
Training loss: 3.623237312843737
Validation loss: 2.8852273807800835

Epoch: 6| Step: 9
Training loss: 3.1614919510907384
Validation loss: 2.884016603939673

Epoch: 6| Step: 10
Training loss: 2.0930688233922905
Validation loss: 2.8809498849217676

Epoch: 6| Step: 11
Training loss: 3.3862459233267552
Validation loss: 2.8795058282986497

Epoch: 6| Step: 12
Training loss: 3.2886690099205063
Validation loss: 2.876314277444632

Epoch: 6| Step: 13
Training loss: 3.175379428569263
Validation loss: 2.873966376770496

Epoch: 45| Step: 0
Training loss: 2.4948989324797455
Validation loss: 2.86974484681824

Epoch: 6| Step: 1
Training loss: 2.9434991814735483
Validation loss: 2.867814427713544

Epoch: 6| Step: 2
Training loss: 3.1436048955779974
Validation loss: 2.8664753624565757

Epoch: 6| Step: 3
Training loss: 3.248969134652905
Validation loss: 2.864384652385836

Epoch: 6| Step: 4
Training loss: 2.4771323526171978
Validation loss: 2.8611250838974507

Epoch: 6| Step: 5
Training loss: 3.6524279579614087
Validation loss: 2.8584588811974223

Epoch: 6| Step: 6
Training loss: 3.0908332715960554
Validation loss: 2.8558404196154177

Epoch: 6| Step: 7
Training loss: 3.1809748262658277
Validation loss: 2.853235111291425

Epoch: 6| Step: 8
Training loss: 3.0325953064335076
Validation loss: 2.851724043498732

Epoch: 6| Step: 9
Training loss: 2.906491013244459
Validation loss: 2.850341953710515

Epoch: 6| Step: 10
Training loss: 2.5364059871047653
Validation loss: 2.8489152438980834

Epoch: 6| Step: 11
Training loss: 2.8366444444813204
Validation loss: 2.8463012373954055

Epoch: 6| Step: 12
Training loss: 3.0398690298377815
Validation loss: 2.844299417037876

Epoch: 6| Step: 13
Training loss: 3.1935428858299764
Validation loss: 2.841995116984651

Epoch: 46| Step: 0
Training loss: 2.8404231470821353
Validation loss: 2.8402798478280387

Epoch: 6| Step: 1
Training loss: 2.9937524910998086
Validation loss: 2.838085919578545

Epoch: 6| Step: 2
Training loss: 3.033161622381873
Validation loss: 2.8356346199825926

Epoch: 6| Step: 3
Training loss: 3.1342210148023875
Validation loss: 2.8334955398091863

Epoch: 6| Step: 4
Training loss: 3.723173956082495
Validation loss: 2.8318301776231314

Epoch: 6| Step: 5
Training loss: 3.281186493758581
Validation loss: 2.829967004293839

Epoch: 6| Step: 6
Training loss: 2.9822990826883067
Validation loss: 2.8277243792353737

Epoch: 6| Step: 7
Training loss: 2.8493026348680335
Validation loss: 2.824414202063593

Epoch: 6| Step: 8
Training loss: 2.7412130249145954
Validation loss: 2.823165619818117

Epoch: 6| Step: 9
Training loss: 3.404247009997677
Validation loss: 2.8211612991588737

Epoch: 6| Step: 10
Training loss: 2.7689856676507065
Validation loss: 2.8186641818203735

Epoch: 6| Step: 11
Training loss: 2.1934445942928265
Validation loss: 2.819773135472539

Epoch: 6| Step: 12
Training loss: 2.7419751729029054
Validation loss: 2.819004900473938

Epoch: 6| Step: 13
Training loss: 2.556635962264178
Validation loss: 2.8146546340446053

Epoch: 47| Step: 0
Training loss: 3.091367169977429
Validation loss: 2.8105435807679546

Epoch: 6| Step: 1
Training loss: 2.8947694502823684
Validation loss: 2.807696542696477

Epoch: 6| Step: 2
Training loss: 3.210427793714156
Validation loss: 2.806170185882681

Epoch: 6| Step: 3
Training loss: 3.042564590508236
Validation loss: 2.804348286665221

Epoch: 6| Step: 4
Training loss: 2.280270509901761
Validation loss: 2.8024688134115694

Epoch: 6| Step: 5
Training loss: 2.7542774572514364
Validation loss: 2.799570358328813

Epoch: 6| Step: 6
Training loss: 3.2205692816337197
Validation loss: 2.799017570350508

Epoch: 6| Step: 7
Training loss: 3.4419288541543893
Validation loss: 2.7975522860452386

Epoch: 6| Step: 8
Training loss: 2.878077477012056
Validation loss: 2.796071894474029

Epoch: 6| Step: 9
Training loss: 2.6954010437505604
Validation loss: 2.7932691292527254

Epoch: 6| Step: 10
Training loss: 3.113982654089567
Validation loss: 2.7918662573981594

Epoch: 6| Step: 11
Training loss: 3.188704020169804
Validation loss: 2.789704905095599

Epoch: 6| Step: 12
Training loss: 2.087101643637421
Validation loss: 2.7868450050995524

Epoch: 6| Step: 13
Training loss: 2.996577217653886
Validation loss: 2.7853325444264967

Epoch: 48| Step: 0
Training loss: 2.4416917801781715
Validation loss: 2.784523926479432

Epoch: 6| Step: 1
Training loss: 2.812620033245873
Validation loss: 2.782806303948043

Epoch: 6| Step: 2
Training loss: 3.3625555551470367
Validation loss: 2.7818024618815653

Epoch: 6| Step: 3
Training loss: 2.911578799754136
Validation loss: 2.7796275231915373

Epoch: 6| Step: 4
Training loss: 2.6059118806252335
Validation loss: 2.777507528563241

Epoch: 6| Step: 5
Training loss: 2.9225983565775215
Validation loss: 2.7765259788456937

Epoch: 6| Step: 6
Training loss: 3.088287154331252
Validation loss: 2.779619017299385

Epoch: 6| Step: 7
Training loss: 3.109323165691539
Validation loss: 2.772531653390659

Epoch: 6| Step: 8
Training loss: 2.786389862835494
Validation loss: 2.769351510410532

Epoch: 6| Step: 9
Training loss: 2.6845656943394256
Validation loss: 2.7688715067796323

Epoch: 6| Step: 10
Training loss: 3.118235629365841
Validation loss: 2.767525890703631

Epoch: 6| Step: 11
Training loss: 3.0640124264856046
Validation loss: 2.765502079245333

Epoch: 6| Step: 12
Training loss: 2.915553143792331
Validation loss: 2.7643663232563536

Epoch: 6| Step: 13
Training loss: 2.8415491999028895
Validation loss: 2.7646323683835514

Epoch: 49| Step: 0
Training loss: 2.8368540562177844
Validation loss: 2.763717582693102

Epoch: 6| Step: 1
Training loss: 2.4423520628874487
Validation loss: 2.7585586820750394

Epoch: 6| Step: 2
Training loss: 3.148565625785483
Validation loss: 2.757275076022289

Epoch: 6| Step: 3
Training loss: 2.2333199737870437
Validation loss: 2.755253960292333

Epoch: 6| Step: 4
Training loss: 3.086745221626239
Validation loss: 2.753713354835718

Epoch: 6| Step: 5
Training loss: 2.8327790634445953
Validation loss: 2.7521384334510977

Epoch: 6| Step: 6
Training loss: 3.055209454287924
Validation loss: 2.750819416498225

Epoch: 6| Step: 7
Training loss: 2.8300484707728644
Validation loss: 2.7479119754623

Epoch: 6| Step: 8
Training loss: 2.6798782503172487
Validation loss: 2.7461218075067286

Epoch: 6| Step: 9
Training loss: 3.106231787645459
Validation loss: 2.745666644333915

Epoch: 6| Step: 10
Training loss: 3.3395727571893867
Validation loss: 2.742663466254027

Epoch: 6| Step: 11
Training loss: 2.769545109852705
Validation loss: 2.741353805763648

Epoch: 6| Step: 12
Training loss: 2.9298657172356406
Validation loss: 2.7440026371881103

Epoch: 6| Step: 13
Training loss: 2.975709808044853
Validation loss: 2.7371921668150985

Epoch: 50| Step: 0
Training loss: 3.250688626620706
Validation loss: 2.7356617833465737

Epoch: 6| Step: 1
Training loss: 2.655680337294766
Validation loss: 2.733757036406746

Epoch: 6| Step: 2
Training loss: 2.573150274093771
Validation loss: 2.7316917841953052

Epoch: 6| Step: 3
Training loss: 2.6231766680704482
Validation loss: 2.7343959044611075

Epoch: 6| Step: 4
Training loss: 3.289201674608901
Validation loss: 2.73204634555642

Epoch: 6| Step: 5
Training loss: 2.865578847199393
Validation loss: 2.73076421751676

Epoch: 6| Step: 6
Training loss: 3.1425263831488546
Validation loss: 2.7277184543602977

Epoch: 6| Step: 7
Training loss: 3.015724299085661
Validation loss: 2.7240891191194962

Epoch: 6| Step: 8
Training loss: 2.6530264648543884
Validation loss: 2.7264044423457787

Epoch: 6| Step: 9
Training loss: 3.09076461862342
Validation loss: 2.725381094272682

Epoch: 6| Step: 10
Training loss: 2.7652239320107586
Validation loss: 2.7251049470670106

Epoch: 6| Step: 11
Training loss: 2.6242768336026487
Validation loss: 2.7257847009011757

Epoch: 6| Step: 12
Training loss: 2.9526182678463733
Validation loss: 2.728156118663353

Epoch: 6| Step: 13
Training loss: 2.4693698346376767
Validation loss: 2.72105025399881

Epoch: 51| Step: 0
Training loss: 2.810933927456344
Validation loss: 2.718193274896505

Epoch: 6| Step: 1
Training loss: 2.4722715925318544
Validation loss: 2.715693498632085

Epoch: 6| Step: 2
Training loss: 3.0441378305237077
Validation loss: 2.715096953588745

Epoch: 6| Step: 3
Training loss: 2.8972175272189027
Validation loss: 2.71272484218116

Epoch: 6| Step: 4
Training loss: 2.9507944104237236
Validation loss: 2.713270445953279

Epoch: 6| Step: 5
Training loss: 2.299321642643087
Validation loss: 2.71325572747198

Epoch: 6| Step: 6
Training loss: 3.193991539587426
Validation loss: 2.7128462287743362

Epoch: 6| Step: 7
Training loss: 2.4206746726205286
Validation loss: 2.710517227766434

Epoch: 6| Step: 8
Training loss: 3.1387338590643696
Validation loss: 2.7076742592970895

Epoch: 6| Step: 9
Training loss: 2.972788423063569
Validation loss: 2.70367805247668

Epoch: 6| Step: 10
Training loss: 2.205261709377856
Validation loss: 2.7021421288353578

Epoch: 6| Step: 11
Training loss: 2.88449485918269
Validation loss: 2.7004542451384475

Epoch: 6| Step: 12
Training loss: 3.2958603875118446
Validation loss: 2.6984043686980397

Epoch: 6| Step: 13
Training loss: 3.036836490453672
Validation loss: 2.6968007424844185

Epoch: 52| Step: 0
Training loss: 2.1541563180149783
Validation loss: 2.694508595757109

Epoch: 6| Step: 1
Training loss: 3.030510409079397
Validation loss: 2.6940393951809365

Epoch: 6| Step: 2
Training loss: 3.0915794079197827
Validation loss: 2.6939934492921283

Epoch: 6| Step: 3
Training loss: 3.024790537494346
Validation loss: 2.6904498330877646

Epoch: 6| Step: 4
Training loss: 2.715442618862164
Validation loss: 2.689857587318014

Epoch: 6| Step: 5
Training loss: 3.2023269775725685
Validation loss: 2.689924669262726

Epoch: 6| Step: 6
Training loss: 2.4521892731068164
Validation loss: 2.6904722677693345

Epoch: 6| Step: 7
Training loss: 2.963316432302514
Validation loss: 2.6902622103849287

Epoch: 6| Step: 8
Training loss: 3.2106069130116084
Validation loss: 2.6863655238977913

Epoch: 6| Step: 9
Training loss: 3.0077064396377806
Validation loss: 2.682139810257206

Epoch: 6| Step: 10
Training loss: 2.763067927604856
Validation loss: 2.680066229300821

Epoch: 6| Step: 11
Training loss: 2.796712348513366
Validation loss: 2.6811156920233934

Epoch: 6| Step: 12
Training loss: 2.552743901510055
Validation loss: 2.679698488085047

Epoch: 6| Step: 13
Training loss: 2.3549641184087964
Validation loss: 2.681297900847212

Epoch: 53| Step: 0
Training loss: 3.1410564676605586
Validation loss: 2.680714565188171

Epoch: 6| Step: 1
Training loss: 3.2432300775707494
Validation loss: 2.6789257720416915

Epoch: 6| Step: 2
Training loss: 2.3276581776235767
Validation loss: 2.674627317926744

Epoch: 6| Step: 3
Training loss: 3.161038986289058
Validation loss: 2.6721501645581296

Epoch: 6| Step: 4
Training loss: 2.6542514238543258
Validation loss: 2.6687191475269314

Epoch: 6| Step: 5
Training loss: 3.0367619061182065
Validation loss: 2.6635110830720077

Epoch: 6| Step: 6
Training loss: 2.8423648017664447
Validation loss: 2.6641709351309033

Epoch: 6| Step: 7
Training loss: 2.68434863183035
Validation loss: 2.665500062829802

Epoch: 6| Step: 8
Training loss: 2.440420504121877
Validation loss: 2.661786745317172

Epoch: 6| Step: 9
Training loss: 2.7522794639665893
Validation loss: 2.664026642350172

Epoch: 6| Step: 10
Training loss: 2.814899184215549
Validation loss: 2.6636737379485376

Epoch: 6| Step: 11
Training loss: 2.390837915450933
Validation loss: 2.661547251868895

Epoch: 6| Step: 12
Training loss: 2.7772132639002707
Validation loss: 2.660767995109998

Epoch: 6| Step: 13
Training loss: 2.778104653729145
Validation loss: 2.6609048634930246

Epoch: 54| Step: 0
Training loss: 3.0278496301118323
Validation loss: 2.6581778617366583

Epoch: 6| Step: 1
Training loss: 2.8080405591116753
Validation loss: 2.65910506053282

Epoch: 6| Step: 2
Training loss: 2.2240471803545705
Validation loss: 2.655352691481499

Epoch: 6| Step: 3
Training loss: 2.5592620675645654
Validation loss: 2.650796430495394

Epoch: 6| Step: 4
Training loss: 3.129696787812292
Validation loss: 2.6514746131935705

Epoch: 6| Step: 5
Training loss: 2.421465045318276
Validation loss: 2.6510818768182927

Epoch: 6| Step: 6
Training loss: 2.52520151750509
Validation loss: 2.6491473661641436

Epoch: 6| Step: 7
Training loss: 2.632909212684936
Validation loss: 2.6488903337441982

Epoch: 6| Step: 8
Training loss: 2.914652010526859
Validation loss: 2.6463683981545

Epoch: 6| Step: 9
Training loss: 3.2046445638160104
Validation loss: 2.6445681683486337

Epoch: 6| Step: 10
Training loss: 3.238820729339133
Validation loss: 2.6443367778095737

Epoch: 6| Step: 11
Training loss: 2.96116987539466
Validation loss: 2.641950496584252

Epoch: 6| Step: 12
Training loss: 2.531153359157774
Validation loss: 2.6428770435227142

Epoch: 6| Step: 13
Training loss: 2.5435672178840747
Validation loss: 2.6442020799285353

Epoch: 55| Step: 0
Training loss: 2.8418163390656455
Validation loss: 2.642284661778791

Epoch: 6| Step: 1
Training loss: 2.6999995514198214
Validation loss: 2.6442919218554732

Epoch: 6| Step: 2
Training loss: 2.8229888306199826
Validation loss: 2.639533123772249

Epoch: 6| Step: 3
Training loss: 2.835612633123035
Validation loss: 2.6373329031323247

Epoch: 6| Step: 4
Training loss: 3.0559259036103827
Validation loss: 2.63605083530208

Epoch: 6| Step: 5
Training loss: 2.8528294087407287
Validation loss: 2.6327517961848463

Epoch: 6| Step: 6
Training loss: 2.6651821971685172
Validation loss: 2.6329016212902414

Epoch: 6| Step: 7
Training loss: 3.0625283376200105
Validation loss: 2.6336189642247727

Epoch: 6| Step: 8
Training loss: 2.137527340719697
Validation loss: 2.633896450804393

Epoch: 6| Step: 9
Training loss: 2.64532179405531
Validation loss: 2.6373129695489297

Epoch: 6| Step: 10
Training loss: 2.889758995857299
Validation loss: 2.636927271003362

Epoch: 6| Step: 11
Training loss: 3.352538351341681
Validation loss: 2.634824171045005

Epoch: 6| Step: 12
Training loss: 2.8784532125837465
Validation loss: 2.63379118979046

Epoch: 6| Step: 13
Training loss: 1.7843880701337966
Validation loss: 2.6309384129052136

Epoch: 56| Step: 0
Training loss: 2.185603273156649
Validation loss: 2.6264761150132676

Epoch: 6| Step: 1
Training loss: 2.6745570591495116
Validation loss: 2.6256037123834997

Epoch: 6| Step: 2
Training loss: 2.9603016354258695
Validation loss: 2.6233250708815454

Epoch: 6| Step: 3
Training loss: 3.1519198788562965
Validation loss: 2.6214920097644994

Epoch: 6| Step: 4
Training loss: 3.028583100648582
Validation loss: 2.620479521246013

Epoch: 6| Step: 5
Training loss: 2.5368073293189664
Validation loss: 2.619049912715915

Epoch: 6| Step: 6
Training loss: 2.74208438168606
Validation loss: 2.6175177977793953

Epoch: 6| Step: 7
Training loss: 2.872469908288586
Validation loss: 2.619747750512695

Epoch: 6| Step: 8
Training loss: 2.5815650876942757
Validation loss: 2.619680782775021

Epoch: 6| Step: 9
Training loss: 2.859588781817874
Validation loss: 2.617892421853206

Epoch: 6| Step: 10
Training loss: 2.864287944938245
Validation loss: 2.616790073262746

Epoch: 6| Step: 11
Training loss: 2.4940394871697626
Validation loss: 2.616460412597154

Epoch: 6| Step: 12
Training loss: 2.542685778646883
Validation loss: 2.612924487779953

Epoch: 6| Step: 13
Training loss: 2.913719995737753
Validation loss: 2.610208267900826

Epoch: 57| Step: 0
Training loss: 3.046204791572974
Validation loss: 2.6114481839161683

Epoch: 6| Step: 1
Training loss: 3.0644543698212896
Validation loss: 2.608955090632519

Epoch: 6| Step: 2
Training loss: 2.6390206242745964
Validation loss: 2.609285257893967

Epoch: 6| Step: 3
Training loss: 2.3353836270484214
Validation loss: 2.6075543811670756

Epoch: 6| Step: 4
Training loss: 2.9888401680638483
Validation loss: 2.6077849822271504

Epoch: 6| Step: 5
Training loss: 2.7887489292171788
Validation loss: 2.607638361750613

Epoch: 6| Step: 6
Training loss: 2.7934332614708204
Validation loss: 2.611432419840958

Epoch: 6| Step: 7
Training loss: 2.2850635998846025
Validation loss: 2.611448473024767

Epoch: 6| Step: 8
Training loss: 2.7724903477327896
Validation loss: 2.607772426400177

Epoch: 6| Step: 9
Training loss: 3.15803915245713
Validation loss: 2.6091547890214812

Epoch: 6| Step: 10
Training loss: 2.505890391894459
Validation loss: 2.604672990532371

Epoch: 6| Step: 11
Training loss: 2.6431562942957876
Validation loss: 2.60226678336488

Epoch: 6| Step: 12
Training loss: 2.680512682144172
Validation loss: 2.6022218588450445

Epoch: 6| Step: 13
Training loss: 2.499852939095028
Validation loss: 2.5998964903474397

Epoch: 58| Step: 0
Training loss: 2.68572158522614
Validation loss: 2.596922202356486

Epoch: 6| Step: 1
Training loss: 3.0737577332612283
Validation loss: 2.5948177346035872

Epoch: 6| Step: 2
Training loss: 2.1291153271402252
Validation loss: 2.5975704322349262

Epoch: 6| Step: 3
Training loss: 2.9135137864652947
Validation loss: 2.5954009167919083

Epoch: 6| Step: 4
Training loss: 2.7163332139674945
Validation loss: 2.595362962220329

Epoch: 6| Step: 5
Training loss: 2.7525221789278107
Validation loss: 2.600185698211087

Epoch: 6| Step: 6
Training loss: 2.466285344453994
Validation loss: 2.5937466295825553

Epoch: 6| Step: 7
Training loss: 2.6111378454187975
Validation loss: 2.5981825369516742

Epoch: 6| Step: 8
Training loss: 3.0993453780533944
Validation loss: 2.5994426961419475

Epoch: 6| Step: 9
Training loss: 3.0494838402916167
Validation loss: 2.600272102055903

Epoch: 6| Step: 10
Training loss: 2.7600458627843216
Validation loss: 2.5908123523806994

Epoch: 6| Step: 11
Training loss: 2.515158284175771
Validation loss: 2.590997223290531

Epoch: 6| Step: 12
Training loss: 2.7273061006122448
Validation loss: 2.5879787751545473

Epoch: 6| Step: 13
Training loss: 2.5078223872955405
Validation loss: 2.5832684160094983

Epoch: 59| Step: 0
Training loss: 2.8195331373707835
Validation loss: 2.5834651318635853

Epoch: 6| Step: 1
Training loss: 2.392025904862845
Validation loss: 2.585102188407388

Epoch: 6| Step: 2
Training loss: 2.5150153327611022
Validation loss: 2.5810502074278894

Epoch: 6| Step: 3
Training loss: 2.3964329397686783
Validation loss: 2.585439082706072

Epoch: 6| Step: 4
Training loss: 3.042796687108284
Validation loss: 2.584179637064076

Epoch: 6| Step: 5
Training loss: 3.077387222715119
Validation loss: 2.5860396381348605

Epoch: 6| Step: 6
Training loss: 2.96553202444153
Validation loss: 2.5839224010444948

Epoch: 6| Step: 7
Training loss: 3.317980281557398
Validation loss: 2.580123804704997

Epoch: 6| Step: 8
Training loss: 2.32265028402651
Validation loss: 2.581033256981595

Epoch: 6| Step: 9
Training loss: 3.0538129017894566
Validation loss: 2.5795798002142956

Epoch: 6| Step: 10
Training loss: 2.578877287259737
Validation loss: 2.576520077317779

Epoch: 6| Step: 11
Training loss: 2.369471590553202
Validation loss: 2.576786433586985

Epoch: 6| Step: 12
Training loss: 2.3156922447747164
Validation loss: 2.5738989361700173

Epoch: 6| Step: 13
Training loss: 2.542331410597811
Validation loss: 2.5737279058356934

Epoch: 60| Step: 0
Training loss: 2.508849122845695
Validation loss: 2.5747022623314217

Epoch: 6| Step: 1
Training loss: 2.513889543405615
Validation loss: 2.573656668148012

Epoch: 6| Step: 2
Training loss: 2.5265277093439455
Validation loss: 2.5726174143201823

Epoch: 6| Step: 3
Training loss: 2.823176316898466
Validation loss: 2.5708049082202153

Epoch: 6| Step: 4
Training loss: 2.866340865613464
Validation loss: 2.5707687699564055

Epoch: 6| Step: 5
Training loss: 2.862831902731262
Validation loss: 2.5737755817996524

Epoch: 6| Step: 6
Training loss: 2.8622462130989734
Validation loss: 2.5716688293658905

Epoch: 6| Step: 7
Training loss: 3.0064118530100683
Validation loss: 2.572576281519768

Epoch: 6| Step: 8
Training loss: 2.5145428148327387
Validation loss: 2.5798719094142997

Epoch: 6| Step: 9
Training loss: 3.2922741936927244
Validation loss: 2.580911228957523

Epoch: 6| Step: 10
Training loss: 2.310949785407517
Validation loss: 2.582126032810842

Epoch: 6| Step: 11
Training loss: 2.969412799932641
Validation loss: 2.576219228097697

Epoch: 6| Step: 12
Training loss: 1.9816185136189701
Validation loss: 2.574587111101179

Epoch: 6| Step: 13
Training loss: 2.497745450992086
Validation loss: 2.567360571369168

Epoch: 61| Step: 0
Training loss: 2.4072160639350173
Validation loss: 2.5592187947916583

Epoch: 6| Step: 1
Training loss: 2.880002852014613
Validation loss: 2.5648688400424864

Epoch: 6| Step: 2
Training loss: 2.6002447783347398
Validation loss: 2.5632263797807853

Epoch: 6| Step: 3
Training loss: 2.1823238713354702
Validation loss: 2.5623597827788718

Epoch: 6| Step: 4
Training loss: 2.6831181311547208
Validation loss: 2.5627619136535493

Epoch: 6| Step: 5
Training loss: 2.7776972335158385
Validation loss: 2.55966432804571

Epoch: 6| Step: 6
Training loss: 2.6056257712476745
Validation loss: 2.564807147856065

Epoch: 6| Step: 7
Training loss: 2.510486258865188
Validation loss: 2.5612035588698627

Epoch: 6| Step: 8
Training loss: 3.05703028916018
Validation loss: 2.56326872452351

Epoch: 6| Step: 9
Training loss: 2.84319224494645
Validation loss: 2.5597341078272264

Epoch: 6| Step: 10
Training loss: 2.9659759410311946
Validation loss: 2.5593684375323265

Epoch: 6| Step: 11
Training loss: 2.7918271165733435
Validation loss: 2.559440771553428

Epoch: 6| Step: 12
Training loss: 2.7373271591456305
Validation loss: 2.5561856417960134

Epoch: 6| Step: 13
Training loss: 2.583884354758287
Validation loss: 2.5578526945224214

Epoch: 62| Step: 0
Training loss: 2.3202655415005737
Validation loss: 2.553557617564268

Epoch: 6| Step: 1
Training loss: 2.4706451288585916
Validation loss: 2.5577992377755883

Epoch: 6| Step: 2
Training loss: 2.57719265812052
Validation loss: 2.5533093576160524

Epoch: 6| Step: 3
Training loss: 2.4734803283415014
Validation loss: 2.5518100566262922

Epoch: 6| Step: 4
Training loss: 3.0203134725206984
Validation loss: 2.5530171975855156

Epoch: 6| Step: 5
Training loss: 2.785928113646642
Validation loss: 2.5517577813556414

Epoch: 6| Step: 6
Training loss: 2.5487917374976865
Validation loss: 2.5515165724692372

Epoch: 6| Step: 7
Training loss: 2.8066222761665345
Validation loss: 2.5452429333963327

Epoch: 6| Step: 8
Training loss: 2.7492200438964436
Validation loss: 2.5524500421211402

Epoch: 6| Step: 9
Training loss: 2.837117267625501
Validation loss: 2.5540563210013127

Epoch: 6| Step: 10
Training loss: 2.91773750992423
Validation loss: 2.551763963503358

Epoch: 6| Step: 11
Training loss: 2.6616015212228668
Validation loss: 2.5500532574795485

Epoch: 6| Step: 12
Training loss: 2.4839569315839327
Validation loss: 2.545926719072393

Epoch: 6| Step: 13
Training loss: 2.671779340849728
Validation loss: 2.5471264299661165

Epoch: 63| Step: 0
Training loss: 2.8350652188665872
Validation loss: 2.5474566398127516

Epoch: 6| Step: 1
Training loss: 2.3456777147223815
Validation loss: 2.546906765542734

Epoch: 6| Step: 2
Training loss: 2.632032601505339
Validation loss: 2.552543214637025

Epoch: 6| Step: 3
Training loss: 2.475454569985877
Validation loss: 2.550157767757138

Epoch: 6| Step: 4
Training loss: 2.6965741286964793
Validation loss: 2.5538519718862824

Epoch: 6| Step: 5
Training loss: 2.8206862099022403
Validation loss: 2.5426781835543584

Epoch: 6| Step: 6
Training loss: 2.546364762384367
Validation loss: 2.5450124658605304

Epoch: 6| Step: 7
Training loss: 2.822663655972155
Validation loss: 2.5460587892319975

Epoch: 6| Step: 8
Training loss: 2.7859139929788994
Validation loss: 2.547029751871848

Epoch: 6| Step: 9
Training loss: 3.265299949713147
Validation loss: 2.5485837855824536

Epoch: 6| Step: 10
Training loss: 2.6399063848023134
Validation loss: 2.54847500085672

Epoch: 6| Step: 11
Training loss: 2.6518027381662455
Validation loss: 2.5526744754751856

Epoch: 6| Step: 12
Training loss: 2.674519262164961
Validation loss: 2.559753403657988

Epoch: 6| Step: 13
Training loss: 2.176637655632475
Validation loss: 2.563542316865018

Epoch: 64| Step: 0
Training loss: 2.397451191744448
Validation loss: 2.5694259150298033

Epoch: 6| Step: 1
Training loss: 2.829311733056734
Validation loss: 2.563323346115651

Epoch: 6| Step: 2
Training loss: 1.897361418999839
Validation loss: 2.552199245597274

Epoch: 6| Step: 3
Training loss: 3.0735631919956403
Validation loss: 2.5459611497458514

Epoch: 6| Step: 4
Training loss: 2.842533228536559
Validation loss: 2.544716651821666

Epoch: 6| Step: 5
Training loss: 3.0738894372240897
Validation loss: 2.5393889623231987

Epoch: 6| Step: 6
Training loss: 2.534010335743095
Validation loss: 2.537379140121009

Epoch: 6| Step: 7
Training loss: 2.6056071963837764
Validation loss: 2.537784070680606

Epoch: 6| Step: 8
Training loss: 2.6885498125577834
Validation loss: 2.5390563338767276

Epoch: 6| Step: 9
Training loss: 2.896313981891753
Validation loss: 2.534966021328242

Epoch: 6| Step: 10
Training loss: 2.7037680858724955
Validation loss: 2.5357636290852814

Epoch: 6| Step: 11
Training loss: 2.6872068733220553
Validation loss: 2.5342550297135564

Epoch: 6| Step: 12
Training loss: 2.723396014687126
Validation loss: 2.539075051301109

Epoch: 6| Step: 13
Training loss: 2.122129408763533
Validation loss: 2.543504391934334

Epoch: 65| Step: 0
Training loss: 2.924204015427161
Validation loss: 2.54756809625279

Epoch: 6| Step: 1
Training loss: 1.6318346225589406
Validation loss: 2.5453376732867996

Epoch: 6| Step: 2
Training loss: 2.4304568921605827
Validation loss: 2.5515759852579194

Epoch: 6| Step: 3
Training loss: 3.095480078715515
Validation loss: 2.559832153356137

Epoch: 6| Step: 4
Training loss: 2.9070346552381126
Validation loss: 2.55225909399888

Epoch: 6| Step: 5
Training loss: 2.5486154986443954
Validation loss: 2.5396203157039032

Epoch: 6| Step: 6
Training loss: 3.0326399615035737
Validation loss: 2.5279656047578665

Epoch: 6| Step: 7
Training loss: 2.6294750034836447
Validation loss: 2.532003973296364

Epoch: 6| Step: 8
Training loss: 2.781725382092811
Validation loss: 2.5287172809620557

Epoch: 6| Step: 9
Training loss: 2.8354513629151743
Validation loss: 2.5309601135034963

Epoch: 6| Step: 10
Training loss: 2.6031419696231843
Validation loss: 2.531932754429164

Epoch: 6| Step: 11
Training loss: 2.715850511675858
Validation loss: 2.536784491173222

Epoch: 6| Step: 12
Training loss: 2.5019540779296583
Validation loss: 2.536362966719898

Epoch: 6| Step: 13
Training loss: 2.506794660560542
Validation loss: 2.5394711053181704

Epoch: 66| Step: 0
Training loss: 2.760957216323029
Validation loss: 2.537935306061223

Epoch: 6| Step: 1
Training loss: 2.6305891208281897
Validation loss: 2.5373396912096036

Epoch: 6| Step: 2
Training loss: 2.753388484682648
Validation loss: 2.5394437845978897

Epoch: 6| Step: 3
Training loss: 2.5545459206456353
Validation loss: 2.537558829278617

Epoch: 6| Step: 4
Training loss: 3.3306654426179483
Validation loss: 2.5354574266561976

Epoch: 6| Step: 5
Training loss: 2.6215556117272083
Validation loss: 2.531547324846128

Epoch: 6| Step: 6
Training loss: 2.3095278842891953
Validation loss: 2.5295095857507857

Epoch: 6| Step: 7
Training loss: 2.479728335913852
Validation loss: 2.5295173460559237

Epoch: 6| Step: 8
Training loss: 3.2907811836933485
Validation loss: 2.526722504930649

Epoch: 6| Step: 9
Training loss: 2.319028351314761
Validation loss: 2.525521047105319

Epoch: 6| Step: 10
Training loss: 2.531556193352484
Validation loss: 2.5241804259529625

Epoch: 6| Step: 11
Training loss: 2.444032571753493
Validation loss: 2.52843084446112

Epoch: 6| Step: 12
Training loss: 2.040336824547599
Validation loss: 2.527136517557611

Epoch: 6| Step: 13
Training loss: 2.799437217693822
Validation loss: 2.521668498090477

Epoch: 67| Step: 0
Training loss: 3.0811780321487263
Validation loss: 2.5229357209708043

Epoch: 6| Step: 1
Training loss: 2.7236909364316113
Validation loss: 2.521457016981392

Epoch: 6| Step: 2
Training loss: 2.325810043161857
Validation loss: 2.52351376129907

Epoch: 6| Step: 3
Training loss: 2.8805061356529307
Validation loss: 2.5233539138351087

Epoch: 6| Step: 4
Training loss: 2.5797420170162617
Validation loss: 2.5228111662936565

Epoch: 6| Step: 5
Training loss: 2.3866708004594233
Validation loss: 2.524445544009051

Epoch: 6| Step: 6
Training loss: 2.55762613651069
Validation loss: 2.5176176152413388

Epoch: 6| Step: 7
Training loss: 2.7664350627184064
Validation loss: 2.520407307042444

Epoch: 6| Step: 8
Training loss: 3.1294024165746537
Validation loss: 2.5218573190289084

Epoch: 6| Step: 9
Training loss: 2.354753123016344
Validation loss: 2.5177249081410245

Epoch: 6| Step: 10
Training loss: 2.4248493265751168
Validation loss: 2.520016361819238

Epoch: 6| Step: 11
Training loss: 2.5202349012883936
Validation loss: 2.5176712149137006

Epoch: 6| Step: 12
Training loss: 2.7042212936769396
Validation loss: 2.5195682335635525

Epoch: 6| Step: 13
Training loss: 2.4866585463254065
Validation loss: 2.5199831377454256

Epoch: 68| Step: 0
Training loss: 3.0393838197743714
Validation loss: 2.519311293037281

Epoch: 6| Step: 1
Training loss: 2.0239052250350844
Validation loss: 2.517957975873662

Epoch: 6| Step: 2
Training loss: 2.2713084525867444
Validation loss: 2.5182499429397325

Epoch: 6| Step: 3
Training loss: 2.920413054423512
Validation loss: 2.515482043514664

Epoch: 6| Step: 4
Training loss: 2.506850298672099
Validation loss: 2.516246016085952

Epoch: 6| Step: 5
Training loss: 2.8116225675310256
Validation loss: 2.517162934903065

Epoch: 6| Step: 6
Training loss: 2.3715306088561148
Validation loss: 2.513799301035797

Epoch: 6| Step: 7
Training loss: 2.7152482204882755
Validation loss: 2.514278296231602

Epoch: 6| Step: 8
Training loss: 2.581664551335308
Validation loss: 2.5097679128277712

Epoch: 6| Step: 9
Training loss: 2.729342729165
Validation loss: 2.5127804550609074

Epoch: 6| Step: 10
Training loss: 2.8959357886177095
Validation loss: 2.5110063190124965

Epoch: 6| Step: 11
Training loss: 2.698661161429679
Validation loss: 2.5116035351943573

Epoch: 6| Step: 12
Training loss: 2.798980261533755
Validation loss: 2.5131443974978773

Epoch: 6| Step: 13
Training loss: 2.355366313978032
Validation loss: 2.5131856333930185

Epoch: 69| Step: 0
Training loss: 2.799036820824016
Validation loss: 2.509828242647643

Epoch: 6| Step: 1
Training loss: 2.343394544985807
Validation loss: 2.514236777970375

Epoch: 6| Step: 2
Training loss: 2.794729422095207
Validation loss: 2.513404656122547

Epoch: 6| Step: 3
Training loss: 2.097245671672404
Validation loss: 2.510052798375713

Epoch: 6| Step: 4
Training loss: 2.315106752706713
Validation loss: 2.5083164964366405

Epoch: 6| Step: 5
Training loss: 2.7005162522593786
Validation loss: 2.5082576431902677

Epoch: 6| Step: 6
Training loss: 2.4682494996142896
Validation loss: 2.5138689629296036

Epoch: 6| Step: 7
Training loss: 2.2829220013789087
Validation loss: 2.5103597726877838

Epoch: 6| Step: 8
Training loss: 3.0328317821426256
Validation loss: 2.5128109279324504

Epoch: 6| Step: 9
Training loss: 2.7090006568600917
Validation loss: 2.5116741043956097

Epoch: 6| Step: 10
Training loss: 2.8663584994489577
Validation loss: 2.506380522033322

Epoch: 6| Step: 11
Training loss: 2.556607705903185
Validation loss: 2.5098405285059218

Epoch: 6| Step: 12
Training loss: 3.113605018159247
Validation loss: 2.513033193185616

Epoch: 6| Step: 13
Training loss: 2.6844276787204144
Validation loss: 2.5106942483704087

Epoch: 70| Step: 0
Training loss: 2.6750842892210436
Validation loss: 2.5054451928945864

Epoch: 6| Step: 1
Training loss: 2.6095813966545247
Validation loss: 2.506918061370896

Epoch: 6| Step: 2
Training loss: 2.2952534667357547
Validation loss: 2.5075092231324776

Epoch: 6| Step: 3
Training loss: 3.2075084930569124
Validation loss: 2.5078791909545264

Epoch: 6| Step: 4
Training loss: 2.0342011361312204
Validation loss: 2.507919705358404

Epoch: 6| Step: 5
Training loss: 2.5126823131404414
Validation loss: 2.5114235711958526

Epoch: 6| Step: 6
Training loss: 2.5298444825273205
Validation loss: 2.5103948811156935

Epoch: 6| Step: 7
Training loss: 3.3065549655731483
Validation loss: 2.5084877095500837

Epoch: 6| Step: 8
Training loss: 2.926721643295027
Validation loss: 2.509514283732363

Epoch: 6| Step: 9
Training loss: 2.7254625960201118
Validation loss: 2.511358208534718

Epoch: 6| Step: 10
Training loss: 2.0326887463982004
Validation loss: 2.5087004106755924

Epoch: 6| Step: 11
Training loss: 2.3987959305032036
Validation loss: 2.5081001980269235

Epoch: 6| Step: 12
Training loss: 2.306322662118585
Validation loss: 2.506752400132666

Epoch: 6| Step: 13
Training loss: 2.9335469370432676
Validation loss: 2.5042273067128957

Epoch: 71| Step: 0
Training loss: 2.837573711765414
Validation loss: 2.499418954083574

Epoch: 6| Step: 1
Training loss: 2.8413238236536533
Validation loss: 2.5033333807927045

Epoch: 6| Step: 2
Training loss: 2.7262816188820445
Validation loss: 2.5007138186858384

Epoch: 6| Step: 3
Training loss: 2.274512911622605
Validation loss: 2.50145130152564

Epoch: 6| Step: 4
Training loss: 2.4407159180258735
Validation loss: 2.5051252439893523

Epoch: 6| Step: 5
Training loss: 2.6164311924654173
Validation loss: 2.5029715679513296

Epoch: 6| Step: 6
Training loss: 2.6028957673584285
Validation loss: 2.505144730445899

Epoch: 6| Step: 7
Training loss: 2.929306615865922
Validation loss: 2.501272052754735

Epoch: 6| Step: 8
Training loss: 2.522014960998641
Validation loss: 2.504929911051078

Epoch: 6| Step: 9
Training loss: 2.2579512503998243
Validation loss: 2.5002835748696137

Epoch: 6| Step: 10
Training loss: 2.941165341748893
Validation loss: 2.5007968745189926

Epoch: 6| Step: 11
Training loss: 2.1192047531339595
Validation loss: 2.501120665823982

Epoch: 6| Step: 12
Training loss: 2.9634091169395345
Validation loss: 2.501558978054245

Epoch: 6| Step: 13
Training loss: 2.5021557096822744
Validation loss: 2.5030121459158226

Epoch: 72| Step: 0
Training loss: 2.467450536292035
Validation loss: 2.5004317308211665

Epoch: 6| Step: 1
Training loss: 3.218578741461864
Validation loss: 2.5035963893320083

Epoch: 6| Step: 2
Training loss: 2.633982050539813
Validation loss: 2.5036210062790385

Epoch: 6| Step: 3
Training loss: 2.793000334447724
Validation loss: 2.5031812295618554

Epoch: 6| Step: 4
Training loss: 2.619509631851875
Validation loss: 2.505023280636441

Epoch: 6| Step: 5
Training loss: 2.389223373515387
Validation loss: 2.501470308274905

Epoch: 6| Step: 6
Training loss: 2.542288740565334
Validation loss: 2.5028317467415495

Epoch: 6| Step: 7
Training loss: 2.2551232396048033
Validation loss: 2.501607012824263

Epoch: 6| Step: 8
Training loss: 2.320967970206738
Validation loss: 2.5006905078959947

Epoch: 6| Step: 9
Training loss: 2.6942528452267527
Validation loss: 2.501687179911677

Epoch: 6| Step: 10
Training loss: 2.9047040211421633
Validation loss: 2.5021997152085675

Epoch: 6| Step: 11
Training loss: 2.6705700102290733
Validation loss: 2.5007531541578625

Epoch: 6| Step: 12
Training loss: 2.349817585459885
Validation loss: 2.4969317124617736

Epoch: 6| Step: 13
Training loss: 2.6488528305767005
Validation loss: 2.495337191025428

Epoch: 73| Step: 0
Training loss: 2.8504559603910575
Validation loss: 2.4958930932364467

Epoch: 6| Step: 1
Training loss: 2.127182681023721
Validation loss: 2.4939556645712706

Epoch: 6| Step: 2
Training loss: 2.7271767173108947
Validation loss: 2.4910589869888913

Epoch: 6| Step: 3
Training loss: 2.418858378345493
Validation loss: 2.496288564578638

Epoch: 6| Step: 4
Training loss: 2.229708941329162
Validation loss: 2.5000602397018885

Epoch: 6| Step: 5
Training loss: 2.61065761086423
Validation loss: 2.498947923539744

Epoch: 6| Step: 6
Training loss: 2.765232209152104
Validation loss: 2.5018413041255325

Epoch: 6| Step: 7
Training loss: 2.5330894285876795
Validation loss: 2.5010114928277254

Epoch: 6| Step: 8
Training loss: 3.0751284812819777
Validation loss: 2.497011241927765

Epoch: 6| Step: 9
Training loss: 2.9802845989248037
Validation loss: 2.498235429453388

Epoch: 6| Step: 10
Training loss: 2.3209287293950136
Validation loss: 2.4915928624512507

Epoch: 6| Step: 11
Training loss: 2.34853515421964
Validation loss: 2.4928954582793543

Epoch: 6| Step: 12
Training loss: 3.0819925709510496
Validation loss: 2.495783285574299

Epoch: 6| Step: 13
Training loss: 2.289537816611966
Validation loss: 2.4948328342638146

Epoch: 74| Step: 0
Training loss: 3.0021758136539685
Validation loss: 2.4929065683440768

Epoch: 6| Step: 1
Training loss: 1.9584531815021113
Validation loss: 2.4942557463418997

Epoch: 6| Step: 2
Training loss: 2.2673904380699685
Validation loss: 2.4941640925965016

Epoch: 6| Step: 3
Training loss: 2.951956058433603
Validation loss: 2.4958411752092546

Epoch: 6| Step: 4
Training loss: 2.575839977850274
Validation loss: 2.4944311742941734

Epoch: 6| Step: 5
Training loss: 3.072892286990595
Validation loss: 2.498812631926065

Epoch: 6| Step: 6
Training loss: 2.2439291964833843
Validation loss: 2.494857346553485

Epoch: 6| Step: 7
Training loss: 2.407537140842004
Validation loss: 2.4918680653995047

Epoch: 6| Step: 8
Training loss: 2.4191173974290594
Validation loss: 2.4924793291781193

Epoch: 6| Step: 9
Training loss: 3.3228590590566704
Validation loss: 2.489173397859255

Epoch: 6| Step: 10
Training loss: 2.8123474927455874
Validation loss: 2.4927187266746182

Epoch: 6| Step: 11
Training loss: 2.4502212930505305
Validation loss: 2.4928578399020145

Epoch: 6| Step: 12
Training loss: 1.5867037120202276
Validation loss: 2.4939958793761092

Epoch: 6| Step: 13
Training loss: 2.7829964972640875
Validation loss: 2.4933228014487256

Epoch: 75| Step: 0
Training loss: 2.573225880522334
Validation loss: 2.4924887830812823

Epoch: 6| Step: 1
Training loss: 2.3463214246784845
Validation loss: 2.4895360508556057

Epoch: 6| Step: 2
Training loss: 2.7433724736712066
Validation loss: 2.492137194916021

Epoch: 6| Step: 3
Training loss: 2.1527502434176307
Validation loss: 2.487730451353014

Epoch: 6| Step: 4
Training loss: 2.309549459802797
Validation loss: 2.491317732777526

Epoch: 6| Step: 5
Training loss: 2.121425314713144
Validation loss: 2.4903150916886876

Epoch: 6| Step: 6
Training loss: 2.487951810817818
Validation loss: 2.4901339880960753

Epoch: 6| Step: 7
Training loss: 2.8217575302260127
Validation loss: 2.4890812376841254

Epoch: 6| Step: 8
Training loss: 3.122770505966548
Validation loss: 2.4902966380594487

Epoch: 6| Step: 9
Training loss: 2.820588666334051
Validation loss: 2.4895916117978754

Epoch: 6| Step: 10
Training loss: 2.5761272666603183
Validation loss: 2.4886210722062225

Epoch: 6| Step: 11
Training loss: 2.7617103759983985
Validation loss: 2.4840741325231144

Epoch: 6| Step: 12
Training loss: 2.903031731001432
Validation loss: 2.488019313629455

Epoch: 6| Step: 13
Training loss: 2.3798549620728844
Validation loss: 2.4860486964578694

Epoch: 76| Step: 0
Training loss: 2.5062013007781263
Validation loss: 2.4885522843511363

Epoch: 6| Step: 1
Training loss: 2.8716268239178864
Validation loss: 2.490086194784522

Epoch: 6| Step: 2
Training loss: 3.280646277700424
Validation loss: 2.4853519142415434

Epoch: 6| Step: 3
Training loss: 2.5824892039041036
Validation loss: 2.490675113545552

Epoch: 6| Step: 4
Training loss: 2.6651524973568548
Validation loss: 2.486666727994998

Epoch: 6| Step: 5
Training loss: 2.3725046802148992
Validation loss: 2.487008432479079

Epoch: 6| Step: 6
Training loss: 2.630199550702127
Validation loss: 2.4922967007907264

Epoch: 6| Step: 7
Training loss: 2.162179065328974
Validation loss: 2.48831708513982

Epoch: 6| Step: 8
Training loss: 2.5170520028526817
Validation loss: 2.494159902539456

Epoch: 6| Step: 9
Training loss: 2.77278813026714
Validation loss: 2.491579370234613

Epoch: 6| Step: 10
Training loss: 2.1257121071020584
Validation loss: 2.492216725910506

Epoch: 6| Step: 11
Training loss: 2.5090691100933933
Validation loss: 2.491435608202903

Epoch: 6| Step: 12
Training loss: 2.7997141658118965
Validation loss: 2.4902933829303753

Epoch: 6| Step: 13
Training loss: 2.2745623869827383
Validation loss: 2.4880084772078006

Epoch: 77| Step: 0
Training loss: 2.832738159348857
Validation loss: 2.4854017171439455

Epoch: 6| Step: 1
Training loss: 2.3568481657432216
Validation loss: 2.484872228419304

Epoch: 6| Step: 2
Training loss: 2.433839445738325
Validation loss: 2.4852519057203595

Epoch: 6| Step: 3
Training loss: 3.0017925311325864
Validation loss: 2.488824374870878

Epoch: 6| Step: 4
Training loss: 2.561277330437984
Validation loss: 2.4851593922564508

Epoch: 6| Step: 5
Training loss: 2.8398811936041657
Validation loss: 2.4861064851055996

Epoch: 6| Step: 6
Training loss: 2.3248596846375857
Validation loss: 2.4898946133874333

Epoch: 6| Step: 7
Training loss: 2.4514159062103165
Validation loss: 2.4900432997057673

Epoch: 6| Step: 8
Training loss: 2.572744685511447
Validation loss: 2.4878633588391943

Epoch: 6| Step: 9
Training loss: 2.6911289642515994
Validation loss: 2.4884403243785993

Epoch: 6| Step: 10
Training loss: 2.596849818285464
Validation loss: 2.4938014433867997

Epoch: 6| Step: 11
Training loss: 2.630212150545781
Validation loss: 2.4883059066756523

Epoch: 6| Step: 12
Training loss: 2.652306984827804
Validation loss: 2.492496132549524

Epoch: 6| Step: 13
Training loss: 2.2378497015603354
Validation loss: 2.4868436260470146

Epoch: 78| Step: 0
Training loss: 2.878337415711807
Validation loss: 2.4827218463497203

Epoch: 6| Step: 1
Training loss: 2.5615036120503754
Validation loss: 2.485158304970931

Epoch: 6| Step: 2
Training loss: 2.6161695635842883
Validation loss: 2.485591438673729

Epoch: 6| Step: 3
Training loss: 2.863636947125352
Validation loss: 2.4872506411246746

Epoch: 6| Step: 4
Training loss: 2.457795962637566
Validation loss: 2.4843410433641866

Epoch: 6| Step: 5
Training loss: 2.4730923284686757
Validation loss: 2.484186033343819

Epoch: 6| Step: 6
Training loss: 2.7191417894112937
Validation loss: 2.4850431939201796

Epoch: 6| Step: 7
Training loss: 2.1302594565029547
Validation loss: 2.4874031917066413

Epoch: 6| Step: 8
Training loss: 2.57958314292914
Validation loss: 2.4919494068731014

Epoch: 6| Step: 9
Training loss: 2.8403538136977415
Validation loss: 2.4907207098886404

Epoch: 6| Step: 10
Training loss: 2.2956863753217447
Validation loss: 2.485827055627013

Epoch: 6| Step: 11
Training loss: 1.90704385455575
Validation loss: 2.489316931374586

Epoch: 6| Step: 12
Training loss: 2.6354976737095903
Validation loss: 2.4866236940289492

Epoch: 6| Step: 13
Training loss: 2.9609328297600865
Validation loss: 2.4869016039405514

Epoch: 79| Step: 0
Training loss: 2.6673890764506885
Validation loss: 2.4926070574665653

Epoch: 6| Step: 1
Training loss: 2.490055523601857
Validation loss: 2.4860605084356235

Epoch: 6| Step: 2
Training loss: 2.8465703036982037
Validation loss: 2.476842838309245

Epoch: 6| Step: 3
Training loss: 2.3859613343692776
Validation loss: 2.488681100351126

Epoch: 6| Step: 4
Training loss: 2.97928748963957
Validation loss: 2.48389593339774

Epoch: 6| Step: 5
Training loss: 2.701915668902409
Validation loss: 2.490110370814697

Epoch: 6| Step: 6
Training loss: 2.8075381272836033
Validation loss: 2.4906023299694384

Epoch: 6| Step: 7
Training loss: 2.2311489050265934
Validation loss: 2.481712706219711

Epoch: 6| Step: 8
Training loss: 2.655242549356018
Validation loss: 2.482325510255075

Epoch: 6| Step: 9
Training loss: 2.792925555555413
Validation loss: 2.4902624270785187

Epoch: 6| Step: 10
Training loss: 2.431379017679536
Validation loss: 2.4913741072898636

Epoch: 6| Step: 11
Training loss: 2.214369196570595
Validation loss: 2.4866384276132347

Epoch: 6| Step: 12
Training loss: 2.4506826695274957
Validation loss: 2.4851552989437837

Epoch: 6| Step: 13
Training loss: 2.456048668916582
Validation loss: 2.4851044197837644

Epoch: 80| Step: 0
Training loss: 2.60656596219334
Validation loss: 2.484782075620105

Epoch: 6| Step: 1
Training loss: 2.028760470153529
Validation loss: 2.492144736757184

Epoch: 6| Step: 2
Training loss: 2.662250249190099
Validation loss: 2.493653395461889

Epoch: 6| Step: 3
Training loss: 2.7004195770340593
Validation loss: 2.4885629507447744

Epoch: 6| Step: 4
Training loss: 2.032713143033909
Validation loss: 2.4930623112560135

Epoch: 6| Step: 5
Training loss: 2.37926341415172
Validation loss: 2.4944906325218863

Epoch: 6| Step: 6
Training loss: 2.851444440514117
Validation loss: 2.4856307177101793

Epoch: 6| Step: 7
Training loss: 2.7071283936788184
Validation loss: 2.4838389852076785

Epoch: 6| Step: 8
Training loss: 2.6705606362023127
Validation loss: 2.4839541960561307

Epoch: 6| Step: 9
Training loss: 2.622885442724157
Validation loss: 2.4862098076360435

Epoch: 6| Step: 10
Training loss: 3.152139536542904
Validation loss: 2.4846924872834695

Epoch: 6| Step: 11
Training loss: 2.551433392240821
Validation loss: 2.482442788216823

Epoch: 6| Step: 12
Training loss: 2.479569495890109
Validation loss: 2.477645236216153

Epoch: 6| Step: 13
Training loss: 2.6472039064527815
Validation loss: 2.4754190302154075

Epoch: 81| Step: 0
Training loss: 2.863800792734849
Validation loss: 2.4811511885652493

Epoch: 6| Step: 1
Training loss: 2.020506868505096
Validation loss: 2.4803088599709353

Epoch: 6| Step: 2
Training loss: 2.355541424239054
Validation loss: 2.478223338026014

Epoch: 6| Step: 3
Training loss: 2.8192192346819507
Validation loss: 2.4836579253625217

Epoch: 6| Step: 4
Training loss: 2.8216787817105904
Validation loss: 2.4843278636499377

Epoch: 6| Step: 5
Training loss: 2.6145468072252274
Validation loss: 2.47653142065208

Epoch: 6| Step: 6
Training loss: 2.540923108843743
Validation loss: 2.477092922781394

Epoch: 6| Step: 7
Training loss: 2.63634690665076
Validation loss: 2.4769260849594974

Epoch: 6| Step: 8
Training loss: 2.4539511680439046
Validation loss: 2.4790449246132535

Epoch: 6| Step: 9
Training loss: 2.367556804390421
Validation loss: 2.4746611443463458

Epoch: 6| Step: 10
Training loss: 2.6567784400825563
Validation loss: 2.47499830907385

Epoch: 6| Step: 11
Training loss: 2.38884025223578
Validation loss: 2.473951389236074

Epoch: 6| Step: 12
Training loss: 2.5078723935969944
Validation loss: 2.469856561467578

Epoch: 6| Step: 13
Training loss: 2.954672110450403
Validation loss: 2.4731071265989266

Epoch: 82| Step: 0
Training loss: 2.770265898767089
Validation loss: 2.478923823112702

Epoch: 6| Step: 1
Training loss: 2.0465989254272707
Validation loss: 2.4708509559281664

Epoch: 6| Step: 2
Training loss: 2.744499427443695
Validation loss: 2.4810565322156006

Epoch: 6| Step: 3
Training loss: 2.1649843311403556
Validation loss: 2.4820017965680674

Epoch: 6| Step: 4
Training loss: 2.6269965072509875
Validation loss: 2.4788021225674406

Epoch: 6| Step: 5
Training loss: 1.907029727246006
Validation loss: 2.4869614099531074

Epoch: 6| Step: 6
Training loss: 2.8396382211561355
Validation loss: 2.4831922262753805

Epoch: 6| Step: 7
Training loss: 3.068196817483427
Validation loss: 2.4774081113232747

Epoch: 6| Step: 8
Training loss: 2.3003014159690207
Validation loss: 2.482204056534549

Epoch: 6| Step: 9
Training loss: 2.9522891198802466
Validation loss: 2.4805870288272818

Epoch: 6| Step: 10
Training loss: 2.2945802604784484
Validation loss: 2.4826601455833655

Epoch: 6| Step: 11
Training loss: 2.467973128143127
Validation loss: 2.4815952176179557

Epoch: 6| Step: 12
Training loss: 2.5440260041485296
Validation loss: 2.4826581448843403

Epoch: 6| Step: 13
Training loss: 3.056176332549345
Validation loss: 2.474440603264188

Epoch: 83| Step: 0
Training loss: 2.9208986007501627
Validation loss: 2.4778407796149704

Epoch: 6| Step: 1
Training loss: 3.0327182635249796
Validation loss: 2.473130721480138

Epoch: 6| Step: 2
Training loss: 2.6057365771675047
Validation loss: 2.4741724396798133

Epoch: 6| Step: 3
Training loss: 2.3435622076458644
Validation loss: 2.4766888511026957

Epoch: 6| Step: 4
Training loss: 1.6605028217065414
Validation loss: 2.478909925315225

Epoch: 6| Step: 5
Training loss: 2.452193745536721
Validation loss: 2.4735974553901166

Epoch: 6| Step: 6
Training loss: 2.653109051012823
Validation loss: 2.4695907481016635

Epoch: 6| Step: 7
Training loss: 1.8194989527075327
Validation loss: 2.478839617616212

Epoch: 6| Step: 8
Training loss: 2.9620571787361802
Validation loss: 2.4722769608551407

Epoch: 6| Step: 9
Training loss: 3.080477053122924
Validation loss: 2.4726846782703356

Epoch: 6| Step: 10
Training loss: 2.4495435678812667
Validation loss: 2.4727557073420634

Epoch: 6| Step: 11
Training loss: 2.3288344767918114
Validation loss: 2.471119335233868

Epoch: 6| Step: 12
Training loss: 2.709056014452436
Validation loss: 2.473691075930621

Epoch: 6| Step: 13
Training loss: 2.6471358169627917
Validation loss: 2.4817908500726102

Epoch: 84| Step: 0
Training loss: 2.9564155129035097
Validation loss: 2.4763328534020252

Epoch: 6| Step: 1
Training loss: 2.663424060200851
Validation loss: 2.475702515515093

Epoch: 6| Step: 2
Training loss: 2.6654913418210073
Validation loss: 2.47656966407935

Epoch: 6| Step: 3
Training loss: 2.603859651905707
Validation loss: 2.478297495280362

Epoch: 6| Step: 4
Training loss: 2.3531695479473465
Validation loss: 2.47832229938458

Epoch: 6| Step: 5
Training loss: 2.597297356845282
Validation loss: 2.476094704138723

Epoch: 6| Step: 6
Training loss: 2.556752248357036
Validation loss: 2.4749661985972686

Epoch: 6| Step: 7
Training loss: 2.9244926273424543
Validation loss: 2.474084209786804

Epoch: 6| Step: 8
Training loss: 1.990166151021076
Validation loss: 2.479021730647544

Epoch: 6| Step: 9
Training loss: 3.0327765956445516
Validation loss: 2.476864592762703

Epoch: 6| Step: 10
Training loss: 2.547202621637845
Validation loss: 2.4811283866488547

Epoch: 6| Step: 11
Training loss: 2.3115591248697394
Validation loss: 2.4879085674887693

Epoch: 6| Step: 12
Training loss: 2.2157959951425683
Validation loss: 2.483912218924212

Epoch: 6| Step: 13
Training loss: 2.3523993032959383
Validation loss: 2.4903496928722073

Epoch: 85| Step: 0
Training loss: 2.658663023910144
Validation loss: 2.4911843954796056

Epoch: 6| Step: 1
Training loss: 2.445223188140366
Validation loss: 2.4894108466458955

Epoch: 6| Step: 2
Training loss: 2.3840746929193424
Validation loss: 2.48834300301426

Epoch: 6| Step: 3
Training loss: 2.6400814061184965
Validation loss: 2.4804115108584006

Epoch: 6| Step: 4
Training loss: 2.295582933380609
Validation loss: 2.482406396064751

Epoch: 6| Step: 5
Training loss: 2.393248670385763
Validation loss: 2.476429563658864

Epoch: 6| Step: 6
Training loss: 2.837324827727617
Validation loss: 2.476407981889764

Epoch: 6| Step: 7
Training loss: 3.130608979966872
Validation loss: 2.473217105585163

Epoch: 6| Step: 8
Training loss: 2.2743751715827494
Validation loss: 2.4738515784001516

Epoch: 6| Step: 9
Training loss: 2.5531669547883933
Validation loss: 2.4725825985289256

Epoch: 6| Step: 10
Training loss: 3.0863259372816887
Validation loss: 2.4665012016301193

Epoch: 6| Step: 11
Training loss: 2.213418707330902
Validation loss: 2.470461947967132

Epoch: 6| Step: 12
Training loss: 2.394298847115647
Validation loss: 2.470116201053536

Epoch: 6| Step: 13
Training loss: 2.721274683520156
Validation loss: 2.470058480701732

Epoch: 86| Step: 0
Training loss: 3.020944597672561
Validation loss: 2.4703910459657994

Epoch: 6| Step: 1
Training loss: 2.6709996624442587
Validation loss: 2.474372159913378

Epoch: 6| Step: 2
Training loss: 2.580455120072617
Validation loss: 2.4704934896962243

Epoch: 6| Step: 3
Training loss: 2.0951958973049503
Validation loss: 2.4684781274906324

Epoch: 6| Step: 4
Training loss: 2.459985748807984
Validation loss: 2.4718887720958165

Epoch: 6| Step: 5
Training loss: 2.4132937099126486
Validation loss: 2.46594467604858

Epoch: 6| Step: 6
Training loss: 2.918744536890966
Validation loss: 2.4724159063651165

Epoch: 6| Step: 7
Training loss: 2.4127924766544657
Validation loss: 2.4711054417842826

Epoch: 6| Step: 8
Training loss: 2.5669129682825362
Validation loss: 2.4692852389699858

Epoch: 6| Step: 9
Training loss: 2.927844635234057
Validation loss: 2.4693292348719886

Epoch: 6| Step: 10
Training loss: 2.5009788504235924
Validation loss: 2.472823022377872

Epoch: 6| Step: 11
Training loss: 2.6615429371464994
Validation loss: 2.473250234892489

Epoch: 6| Step: 12
Training loss: 2.8766660424059047
Validation loss: 2.471953779878983

Epoch: 6| Step: 13
Training loss: 1.8757572552259625
Validation loss: 2.473976381470283

Epoch: 87| Step: 0
Training loss: 2.20745737468828
Validation loss: 2.477172760329081

Epoch: 6| Step: 1
Training loss: 2.502526437198651
Validation loss: 2.4740728947399138

Epoch: 6| Step: 2
Training loss: 2.645557198920717
Validation loss: 2.4735512060495903

Epoch: 6| Step: 3
Training loss: 2.5090215032575136
Validation loss: 2.4718007580924684

Epoch: 6| Step: 4
Training loss: 2.687090731663002
Validation loss: 2.46811671121918

Epoch: 6| Step: 5
Training loss: 2.9189485796861945
Validation loss: 2.467224841069822

Epoch: 6| Step: 6
Training loss: 1.8234672223621275
Validation loss: 2.4728248060648093

Epoch: 6| Step: 7
Training loss: 2.649623009119241
Validation loss: 2.477890316536739

Epoch: 6| Step: 8
Training loss: 2.2873270271649435
Validation loss: 2.481107045947272

Epoch: 6| Step: 9
Training loss: 2.4089500834296187
Validation loss: 2.4796868961864713

Epoch: 6| Step: 10
Training loss: 2.7412594694782006
Validation loss: 2.481695605669277

Epoch: 6| Step: 11
Training loss: 2.977976065371052
Validation loss: 2.476452717719476

Epoch: 6| Step: 12
Training loss: 2.9472598005658153
Validation loss: 2.476190837966627

Epoch: 6| Step: 13
Training loss: 2.4795431497692033
Validation loss: 2.480102768378674

Epoch: 88| Step: 0
Training loss: 2.451412015907285
Validation loss: 2.479289626163063

Epoch: 6| Step: 1
Training loss: 1.9876542517345608
Validation loss: 2.4839230332226805

Epoch: 6| Step: 2
Training loss: 2.857007990787535
Validation loss: 2.480383699816303

Epoch: 6| Step: 3
Training loss: 2.2614573062406502
Validation loss: 2.481587491596761

Epoch: 6| Step: 4
Training loss: 3.2597615291690865
Validation loss: 2.482450879735648

Epoch: 6| Step: 5
Training loss: 2.5450260495274772
Validation loss: 2.4823505782546933

Epoch: 6| Step: 6
Training loss: 2.280032943688358
Validation loss: 2.4822258200311538

Epoch: 6| Step: 7
Training loss: 3.129117160884675
Validation loss: 2.4805163281300677

Epoch: 6| Step: 8
Training loss: 2.2604437151109447
Validation loss: 2.479920846896232

Epoch: 6| Step: 9
Training loss: 2.648396809583251
Validation loss: 2.476362122011704

Epoch: 6| Step: 10
Training loss: 2.5821077967390735
Validation loss: 2.474707067860014

Epoch: 6| Step: 11
Training loss: 2.9104618193706235
Validation loss: 2.4799197252674015

Epoch: 6| Step: 12
Training loss: 1.9106579455229653
Validation loss: 2.4745625745145934

Epoch: 6| Step: 13
Training loss: 2.663954030622621
Validation loss: 2.4740794155539496

Epoch: 89| Step: 0
Training loss: 2.4979868412633315
Validation loss: 2.4736641692232184

Epoch: 6| Step: 1
Training loss: 2.838147019882819
Validation loss: 2.474436050603594

Epoch: 6| Step: 2
Training loss: 2.997908498944221
Validation loss: 2.4732536891836605

Epoch: 6| Step: 3
Training loss: 2.737752953256145
Validation loss: 2.4693346820057602

Epoch: 6| Step: 4
Training loss: 2.727101444876852
Validation loss: 2.4718517824827586

Epoch: 6| Step: 5
Training loss: 2.169484091752054
Validation loss: 2.474553975461421

Epoch: 6| Step: 6
Training loss: 2.3250000738328493
Validation loss: 2.473770027355862

Epoch: 6| Step: 7
Training loss: 2.2913111555446672
Validation loss: 2.470728857738195

Epoch: 6| Step: 8
Training loss: 2.649085491657103
Validation loss: 2.4701299713729754

Epoch: 6| Step: 9
Training loss: 2.104589841484299
Validation loss: 2.4724697305840526

Epoch: 6| Step: 10
Training loss: 2.9296585285025847
Validation loss: 2.4721403703700555

Epoch: 6| Step: 11
Training loss: 2.5706409372048533
Validation loss: 2.4770205101300595

Epoch: 6| Step: 12
Training loss: 2.5745165917415145
Validation loss: 2.472930298413887

Epoch: 6| Step: 13
Training loss: 2.3574232908938373
Validation loss: 2.470213701627816

Epoch: 90| Step: 0
Training loss: 2.810263528650626
Validation loss: 2.463475270146079

Epoch: 6| Step: 1
Training loss: 3.1154429972758133
Validation loss: 2.4676151484013285

Epoch: 6| Step: 2
Training loss: 2.1334894803639144
Validation loss: 2.4669051701566342

Epoch: 6| Step: 3
Training loss: 2.8177835638940865
Validation loss: 2.4698922295424963

Epoch: 6| Step: 4
Training loss: 2.560386158011562
Validation loss: 2.4722332183245688

Epoch: 6| Step: 5
Training loss: 2.678070737273445
Validation loss: 2.4695298777866785

Epoch: 6| Step: 6
Training loss: 2.1745531872849315
Validation loss: 2.477443951365067

Epoch: 6| Step: 7
Training loss: 2.4305965771316638
Validation loss: 2.4726957505834006

Epoch: 6| Step: 8
Training loss: 2.394770698958888
Validation loss: 2.477180010869009

Epoch: 6| Step: 9
Training loss: 1.9698925033518866
Validation loss: 2.473575648106485

Epoch: 6| Step: 10
Training loss: 2.5256552384267206
Validation loss: 2.470773664228962

Epoch: 6| Step: 11
Training loss: 2.862659839681804
Validation loss: 2.4704406357600366

Epoch: 6| Step: 12
Training loss: 2.4164908334189987
Validation loss: 2.4607376421150096

Epoch: 6| Step: 13
Training loss: 2.9068389623947004
Validation loss: 2.4677169022438856

Epoch: 91| Step: 0
Training loss: 2.504182844908423
Validation loss: 2.471011530308032

Epoch: 6| Step: 1
Training loss: 2.3894367132017713
Validation loss: 2.473861762052595

Epoch: 6| Step: 2
Training loss: 2.4007086422905335
Validation loss: 2.478281349230389

Epoch: 6| Step: 3
Training loss: 2.7057808414306264
Validation loss: 2.479944449053822

Epoch: 6| Step: 4
Training loss: 2.5208629785060883
Validation loss: 2.4775311233459463

Epoch: 6| Step: 5
Training loss: 2.6508128449040864
Validation loss: 2.4767949168737955

Epoch: 6| Step: 6
Training loss: 2.708611185542022
Validation loss: 2.4751998249138145

Epoch: 6| Step: 7
Training loss: 2.450541405316119
Validation loss: 2.4754391036669925

Epoch: 6| Step: 8
Training loss: 2.3019478759498635
Validation loss: 2.472351103600969

Epoch: 6| Step: 9
Training loss: 2.7751591026815983
Validation loss: 2.474439952884616

Epoch: 6| Step: 10
Training loss: 2.442268011971119
Validation loss: 2.472274517787306

Epoch: 6| Step: 11
Training loss: 2.9294055853944556
Validation loss: 2.471213548128057

Epoch: 6| Step: 12
Training loss: 2.2834262657280715
Validation loss: 2.4684132535446865

Epoch: 6| Step: 13
Training loss: 2.7549480659034566
Validation loss: 2.4679250586300094

Epoch: 92| Step: 0
Training loss: 2.880752778748226
Validation loss: 2.4673697399681984

Epoch: 6| Step: 1
Training loss: 2.314756581174429
Validation loss: 2.4684776767594205

Epoch: 6| Step: 2
Training loss: 2.5116674913364094
Validation loss: 2.4644554545702455

Epoch: 6| Step: 3
Training loss: 2.315324656253412
Validation loss: 2.467896503076508

Epoch: 6| Step: 4
Training loss: 2.645491229991403
Validation loss: 2.4657877602017986

Epoch: 6| Step: 5
Training loss: 3.034765976959691
Validation loss: 2.46972533970495

Epoch: 6| Step: 6
Training loss: 2.8804251857657155
Validation loss: 2.470530403141083

Epoch: 6| Step: 7
Training loss: 2.449768880725226
Validation loss: 2.466191555567458

Epoch: 6| Step: 8
Training loss: 2.1915237476855967
Validation loss: 2.468578614350035

Epoch: 6| Step: 9
Training loss: 2.208365626069044
Validation loss: 2.469530650139486

Epoch: 6| Step: 10
Training loss: 2.375967732078741
Validation loss: 2.470384209798675

Epoch: 6| Step: 11
Training loss: 2.4149158537364075
Validation loss: 2.4617549769686757

Epoch: 6| Step: 12
Training loss: 2.7560011667047033
Validation loss: 2.463237482906683

Epoch: 6| Step: 13
Training loss: 2.5878125909520366
Validation loss: 2.4635898969793573

Epoch: 93| Step: 0
Training loss: 2.3832883265943012
Validation loss: 2.45913586744487

Epoch: 6| Step: 1
Training loss: 2.795028332616139
Validation loss: 2.460684820857327

Epoch: 6| Step: 2
Training loss: 2.021577783167998
Validation loss: 2.4645458914029366

Epoch: 6| Step: 3
Training loss: 2.841045057337575
Validation loss: 2.464520932523049

Epoch: 6| Step: 4
Training loss: 2.3775424399132956
Validation loss: 2.4582984943399713

Epoch: 6| Step: 5
Training loss: 2.264230443650364
Validation loss: 2.458158201240276

Epoch: 6| Step: 6
Training loss: 2.6000983439699796
Validation loss: 2.4614177901235337

Epoch: 6| Step: 7
Training loss: 2.8898697149879427
Validation loss: 2.4604700441785647

Epoch: 6| Step: 8
Training loss: 2.2938280721157525
Validation loss: 2.4620738640258435

Epoch: 6| Step: 9
Training loss: 2.7711524683988054
Validation loss: 2.470796388818425

Epoch: 6| Step: 10
Training loss: 2.207546153811901
Validation loss: 2.478877657118188

Epoch: 6| Step: 11
Training loss: 2.6710162651112346
Validation loss: 2.4797552088703836

Epoch: 6| Step: 12
Training loss: 2.751569473457056
Validation loss: 2.4795075083426164

Epoch: 6| Step: 13
Training loss: 2.7300443524121905
Validation loss: 2.476180262706115

Epoch: 94| Step: 0
Training loss: 2.6603182884752896
Validation loss: 2.480220303646095

Epoch: 6| Step: 1
Training loss: 2.954515240921578
Validation loss: 2.474204094709575

Epoch: 6| Step: 2
Training loss: 1.973938538410979
Validation loss: 2.4758522306799824

Epoch: 6| Step: 3
Training loss: 3.1624260332104757
Validation loss: 2.4722314663570133

Epoch: 6| Step: 4
Training loss: 2.3799325016612087
Validation loss: 2.4742970980882943

Epoch: 6| Step: 5
Training loss: 2.0658198139240205
Validation loss: 2.4721311279782605

Epoch: 6| Step: 6
Training loss: 2.1090872109090735
Validation loss: 2.4696447304326243

Epoch: 6| Step: 7
Training loss: 2.802973316388159
Validation loss: 2.470304731935484

Epoch: 6| Step: 8
Training loss: 2.6810993001064416
Validation loss: 2.4662535072246294

Epoch: 6| Step: 9
Training loss: 2.6522771408414005
Validation loss: 2.465938496291147

Epoch: 6| Step: 10
Training loss: 2.409120804059744
Validation loss: 2.466986811220304

Epoch: 6| Step: 11
Training loss: 2.0976660246949868
Validation loss: 2.4656835980174603

Epoch: 6| Step: 12
Training loss: 2.8424468355734507
Validation loss: 2.465005360507875

Epoch: 6| Step: 13
Training loss: 2.505297959932509
Validation loss: 2.4648672063470127

Epoch: 95| Step: 0
Training loss: 2.434257992245037
Validation loss: 2.464490483314702

Epoch: 6| Step: 1
Training loss: 2.9547047098627894
Validation loss: 2.4654282382188297

Epoch: 6| Step: 2
Training loss: 2.5354422244871127
Validation loss: 2.4616773189640484

Epoch: 6| Step: 3
Training loss: 2.767308385568219
Validation loss: 2.4626564763630587

Epoch: 6| Step: 4
Training loss: 2.27921089069018
Validation loss: 2.4709959959766774

Epoch: 6| Step: 5
Training loss: 3.184712705964425
Validation loss: 2.4669338740998956

Epoch: 6| Step: 6
Training loss: 2.61498876419717
Validation loss: 2.4705764195215747

Epoch: 6| Step: 7
Training loss: 2.6057529551820413
Validation loss: 2.4772447193939104

Epoch: 6| Step: 8
Training loss: 1.7971579950809689
Validation loss: 2.474665078387011

Epoch: 6| Step: 9
Training loss: 2.058583905596421
Validation loss: 2.4795398003943605

Epoch: 6| Step: 10
Training loss: 2.197368270171912
Validation loss: 2.477209173224562

Epoch: 6| Step: 11
Training loss: 2.874333843509712
Validation loss: 2.480877860065528

Epoch: 6| Step: 12
Training loss: 3.0243328651414685
Validation loss: 2.4813924996737073

Epoch: 6| Step: 13
Training loss: 2.1121438397713432
Validation loss: 2.4754160123613493

Epoch: 96| Step: 0
Training loss: 2.060062239364071
Validation loss: 2.4704669502774013

Epoch: 6| Step: 1
Training loss: 2.6522150247205665
Validation loss: 2.467793830774236

Epoch: 6| Step: 2
Training loss: 2.885930058129448
Validation loss: 2.469201428952636

Epoch: 6| Step: 3
Training loss: 2.6350072208428656
Validation loss: 2.4626408893280494

Epoch: 6| Step: 4
Training loss: 2.1848998829406625
Validation loss: 2.4643457376121565

Epoch: 6| Step: 5
Training loss: 2.6974538948707933
Validation loss: 2.4581438465690764

Epoch: 6| Step: 6
Training loss: 3.0043956025641068
Validation loss: 2.458278466813921

Epoch: 6| Step: 7
Training loss: 2.0406919085762945
Validation loss: 2.4664186019998993

Epoch: 6| Step: 8
Training loss: 2.0896224145350155
Validation loss: 2.468124471358314

Epoch: 6| Step: 9
Training loss: 2.236917396435676
Validation loss: 2.46211032269255

Epoch: 6| Step: 10
Training loss: 2.2184570548934994
Validation loss: 2.458293305626122

Epoch: 6| Step: 11
Training loss: 2.5949679353236075
Validation loss: 2.458421743279494

Epoch: 6| Step: 12
Training loss: 3.1691261745383446
Validation loss: 2.4533582928759645

Epoch: 6| Step: 13
Training loss: 3.015472566378939
Validation loss: 2.4568958416991795

Epoch: 97| Step: 0
Training loss: 2.808330581920268
Validation loss: 2.461815829689767

Epoch: 6| Step: 1
Training loss: 2.7821408677351984
Validation loss: 2.4625414268765615

Epoch: 6| Step: 2
Training loss: 2.6082949658904293
Validation loss: 2.4643117549196942

Epoch: 6| Step: 3
Training loss: 2.1985664552175384
Validation loss: 2.4716657168162968

Epoch: 6| Step: 4
Training loss: 3.1533494973390064
Validation loss: 2.466778809236372

Epoch: 6| Step: 5
Training loss: 2.14272856553657
Validation loss: 2.4725764032200583

Epoch: 6| Step: 6
Training loss: 2.9920247882795357
Validation loss: 2.474443638366597

Epoch: 6| Step: 7
Training loss: 2.4580987936951253
Validation loss: 2.472479614569773

Epoch: 6| Step: 8
Training loss: 2.4947154458865293
Validation loss: 2.4716075664133013

Epoch: 6| Step: 9
Training loss: 2.442882854243503
Validation loss: 2.4757427058094

Epoch: 6| Step: 10
Training loss: 2.126211269952127
Validation loss: 2.47427002131269

Epoch: 6| Step: 11
Training loss: 2.4038576395787428
Validation loss: 2.4745058892622485

Epoch: 6| Step: 12
Training loss: 2.5210028557222164
Validation loss: 2.4689058343176273

Epoch: 6| Step: 13
Training loss: 2.359362065361896
Validation loss: 2.4745558863647084

Epoch: 98| Step: 0
Training loss: 2.3730684758211846
Validation loss: 2.4645230769328617

Epoch: 6| Step: 1
Training loss: 2.998308022522837
Validation loss: 2.4602750017650252

Epoch: 6| Step: 2
Training loss: 3.2634015704753017
Validation loss: 2.4560385893742223

Epoch: 6| Step: 3
Training loss: 2.3699455686346504
Validation loss: 2.4617334441070593

Epoch: 6| Step: 4
Training loss: 2.4689682489812497
Validation loss: 2.4512345304751557

Epoch: 6| Step: 5
Training loss: 2.5261500279626374
Validation loss: 2.4608778688986934

Epoch: 6| Step: 6
Training loss: 2.84057641318287
Validation loss: 2.4585557826201305

Epoch: 6| Step: 7
Training loss: 2.0150873221131054
Validation loss: 2.4654066729690913

Epoch: 6| Step: 8
Training loss: 1.591727076211259
Validation loss: 2.4673760530311823

Epoch: 6| Step: 9
Training loss: 2.1940908053166575
Validation loss: 2.4659556738836734

Epoch: 6| Step: 10
Training loss: 2.826980106171764
Validation loss: 2.4641016887482676

Epoch: 6| Step: 11
Training loss: 2.96335183302687
Validation loss: 2.465084251604382

Epoch: 6| Step: 12
Training loss: 2.395533092317182
Validation loss: 2.4617634270319515

Epoch: 6| Step: 13
Training loss: 2.2443815654763775
Validation loss: 2.4528417403494007

Epoch: 99| Step: 0
Training loss: 2.7069829851171705
Validation loss: 2.454470304046195

Epoch: 6| Step: 1
Training loss: 3.1469224640222504
Validation loss: 2.456972316566838

Epoch: 6| Step: 2
Training loss: 2.131198817558648
Validation loss: 2.452955803027325

Epoch: 6| Step: 3
Training loss: 2.9833480905633145
Validation loss: 2.45919366642259

Epoch: 6| Step: 4
Training loss: 1.920941133708257
Validation loss: 2.4485386863042726

Epoch: 6| Step: 5
Training loss: 2.2868925361555204
Validation loss: 2.4524030979830265

Epoch: 6| Step: 6
Training loss: 2.170857362620302
Validation loss: 2.4531425750815576

Epoch: 6| Step: 7
Training loss: 2.288120844237308
Validation loss: 2.452712929491097

Epoch: 6| Step: 8
Training loss: 2.67687324461522
Validation loss: 2.4602818014170307

Epoch: 6| Step: 9
Training loss: 2.760898667965369
Validation loss: 2.4527723540806186

Epoch: 6| Step: 10
Training loss: 3.028204892642863
Validation loss: 2.458605643454651

Epoch: 6| Step: 11
Training loss: 2.0930390930315887
Validation loss: 2.4533572238902606

Epoch: 6| Step: 12
Training loss: 2.8937222769873765
Validation loss: 2.4559727720196856

Epoch: 6| Step: 13
Training loss: 2.050749046436141
Validation loss: 2.45521474218901

Epoch: 100| Step: 0
Training loss: 2.5830091047373895
Validation loss: 2.455227090933586

Epoch: 6| Step: 1
Training loss: 2.817136714771641
Validation loss: 2.456019255304807

Epoch: 6| Step: 2
Training loss: 2.459188754289437
Validation loss: 2.4550926918198517

Epoch: 6| Step: 3
Training loss: 2.6811423397902283
Validation loss: 2.455657445535149

Epoch: 6| Step: 4
Training loss: 2.1589747365698777
Validation loss: 2.4547622303440306

Epoch: 6| Step: 5
Training loss: 2.1765919789483434
Validation loss: 2.4598367560504766

Epoch: 6| Step: 6
Training loss: 2.7796851052525344
Validation loss: 2.4578654576776455

Epoch: 6| Step: 7
Training loss: 2.2752430880279895
Validation loss: 2.461829468886414

Epoch: 6| Step: 8
Training loss: 2.3763889467571446
Validation loss: 2.4622643663008756

Epoch: 6| Step: 9
Training loss: 2.6816417808002333
Validation loss: 2.4636765833573246

Epoch: 6| Step: 10
Training loss: 1.9789817389040378
Validation loss: 2.4605177102482876

Epoch: 6| Step: 11
Training loss: 2.7965117490355547
Validation loss: 2.4688688482979466

Epoch: 6| Step: 12
Training loss: 2.7837442936044416
Validation loss: 2.46552642380245

Epoch: 6| Step: 13
Training loss: 2.698130673987295
Validation loss: 2.4657847950206073

Testing loss: 2.0428377859863134
