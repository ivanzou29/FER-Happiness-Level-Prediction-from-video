Epoch: 1| Step: 0
Training loss: 5.993569743098086
Validation loss: 5.8542435212254835

Epoch: 6| Step: 1
Training loss: 6.229325852757583
Validation loss: 5.851752447450062

Epoch: 6| Step: 2
Training loss: 6.420698146234457
Validation loss: 5.8493043067449015

Epoch: 6| Step: 3
Training loss: 5.192446269389607
Validation loss: 5.846836193125157

Epoch: 6| Step: 4
Training loss: 5.768797293786363
Validation loss: 5.84434351227557

Epoch: 6| Step: 5
Training loss: 6.532112904177325
Validation loss: 5.842017693885999

Epoch: 6| Step: 6
Training loss: 5.806694166524933
Validation loss: 5.8397285101331695

Epoch: 6| Step: 7
Training loss: 6.089042527672852
Validation loss: 5.837530760374308

Epoch: 6| Step: 8
Training loss: 6.177102031540085
Validation loss: 5.835367919689213

Epoch: 6| Step: 9
Training loss: 5.954571725865477
Validation loss: 5.833092584637428

Epoch: 6| Step: 10
Training loss: 5.957209590055861
Validation loss: 5.83081712495998

Epoch: 6| Step: 11
Training loss: 6.4809820283470785
Validation loss: 5.828410669165862

Epoch: 6| Step: 12
Training loss: 6.079890213025347
Validation loss: 5.8258792481022486

Epoch: 6| Step: 13
Training loss: 4.353577837150826
Validation loss: 5.8233987771287135

Epoch: 2| Step: 0
Training loss: 6.339182144025123
Validation loss: 5.820673128771025

Epoch: 6| Step: 1
Training loss: 5.756421028437776
Validation loss: 5.817997947139122

Epoch: 6| Step: 2
Training loss: 5.7017619973362255
Validation loss: 5.814944173818774

Epoch: 6| Step: 3
Training loss: 5.8616239173739615
Validation loss: 5.811904603277173

Epoch: 6| Step: 4
Training loss: 5.550224217190148
Validation loss: 5.808665333494689

Epoch: 6| Step: 5
Training loss: 5.366263986174322
Validation loss: 5.805196569478631

Epoch: 6| Step: 6
Training loss: 6.28968358734414
Validation loss: 5.801494639292848

Epoch: 6| Step: 7
Training loss: 4.65839679563328
Validation loss: 5.797684413339632

Epoch: 6| Step: 8
Training loss: 7.260399824329983
Validation loss: 5.793764772639805

Epoch: 6| Step: 9
Training loss: 5.930718976800967
Validation loss: 5.789386995859013

Epoch: 6| Step: 10
Training loss: 5.179143586520355
Validation loss: 5.784789368035083

Epoch: 6| Step: 11
Training loss: 6.477480686384211
Validation loss: 5.780239669908266

Epoch: 6| Step: 12
Training loss: 6.255774310126467
Validation loss: 5.775426154768614

Epoch: 6| Step: 13
Training loss: 5.727462385596082
Validation loss: 5.770110579675625

Epoch: 3| Step: 0
Training loss: 6.5818350652327755
Validation loss: 5.764484957880498

Epoch: 6| Step: 1
Training loss: 6.355854981637594
Validation loss: 5.758931065555679

Epoch: 6| Step: 2
Training loss: 6.1787692037566035
Validation loss: 5.752465673126229

Epoch: 6| Step: 3
Training loss: 4.117123105669338
Validation loss: 5.7460569047297625

Epoch: 6| Step: 4
Training loss: 5.821983885962602
Validation loss: 5.73955804042701

Epoch: 6| Step: 5
Training loss: 4.708386693781502
Validation loss: 5.732564143029802

Epoch: 6| Step: 6
Training loss: 6.164229280756226
Validation loss: 5.72557630456258

Epoch: 6| Step: 7
Training loss: 6.569423547361588
Validation loss: 5.717946174981126

Epoch: 6| Step: 8
Training loss: 5.59880238397156
Validation loss: 5.709998989962496

Epoch: 6| Step: 9
Training loss: 6.221762076272302
Validation loss: 5.702106569535737

Epoch: 6| Step: 10
Training loss: 5.193510135845306
Validation loss: 5.693749567863038

Epoch: 6| Step: 11
Training loss: 5.978896858250823
Validation loss: 5.685059355619116

Epoch: 6| Step: 12
Training loss: 5.2835998724642925
Validation loss: 5.676099900859189

Epoch: 6| Step: 13
Training loss: 6.323913529154138
Validation loss: 5.666936905344911

Epoch: 4| Step: 0
Training loss: 5.2066905775184615
Validation loss: 5.657224989120991

Epoch: 6| Step: 1
Training loss: 5.724836268853091
Validation loss: 5.647334060066064

Epoch: 6| Step: 2
Training loss: 4.8334940960335935
Validation loss: 5.637492090911843

Epoch: 6| Step: 3
Training loss: 5.335658321645211
Validation loss: 5.627453163118142

Epoch: 6| Step: 4
Training loss: 6.7054098010013705
Validation loss: 5.617073974028095

Epoch: 6| Step: 5
Training loss: 5.168819020189869
Validation loss: 5.606249803807465

Epoch: 6| Step: 6
Training loss: 6.501742789572486
Validation loss: 5.595771552128522

Epoch: 6| Step: 7
Training loss: 6.224793531065471
Validation loss: 5.584486922850445

Epoch: 6| Step: 8
Training loss: 4.749855440851266
Validation loss: 5.57302823059025

Epoch: 6| Step: 9
Training loss: 5.813897077774686
Validation loss: 5.561456446680965

Epoch: 6| Step: 10
Training loss: 6.468466342474889
Validation loss: 5.550060092039383

Epoch: 6| Step: 11
Training loss: 5.729697832858149
Validation loss: 5.538358556640445

Epoch: 6| Step: 12
Training loss: 4.8949595002943065
Validation loss: 5.526396840360821

Epoch: 6| Step: 13
Training loss: 6.007052409451939
Validation loss: 5.5151718573079185

Epoch: 5| Step: 0
Training loss: 5.250709122495979
Validation loss: 5.502762620855711

Epoch: 6| Step: 1
Training loss: 5.35509246461398
Validation loss: 5.491010978504813

Epoch: 6| Step: 2
Training loss: 6.440085179020314
Validation loss: 5.47897145125393

Epoch: 6| Step: 3
Training loss: 5.156540371203692
Validation loss: 5.4673979913573545

Epoch: 6| Step: 4
Training loss: 5.939874114170055
Validation loss: 5.455350551046772

Epoch: 6| Step: 5
Training loss: 5.832417152754936
Validation loss: 5.444075806565728

Epoch: 6| Step: 6
Training loss: 6.133165793963995
Validation loss: 5.432437922799934

Epoch: 6| Step: 7
Training loss: 6.12087811721335
Validation loss: 5.421086234727822

Epoch: 6| Step: 8
Training loss: 6.172505406886808
Validation loss: 5.41013765297458

Epoch: 6| Step: 9
Training loss: 4.809158750633415
Validation loss: 5.398992028763896

Epoch: 6| Step: 10
Training loss: 4.840518981284828
Validation loss: 5.3882096191293956

Epoch: 6| Step: 11
Training loss: 4.058897563294901
Validation loss: 5.377959863261613

Epoch: 6| Step: 12
Training loss: 4.96248092071171
Validation loss: 5.368170073114169

Epoch: 6| Step: 13
Training loss: 6.049715070083815
Validation loss: 5.35869876610174

Epoch: 6| Step: 0
Training loss: 6.293400338241864
Validation loss: 5.349132125195437

Epoch: 6| Step: 1
Training loss: 4.730745743722447
Validation loss: 5.340842841184505

Epoch: 6| Step: 2
Training loss: 4.742295290681869
Validation loss: 5.3318190312335

Epoch: 6| Step: 3
Training loss: 4.006484259601742
Validation loss: 5.323604959776902

Epoch: 6| Step: 4
Training loss: 5.909935825470666
Validation loss: 5.315716745705028

Epoch: 6| Step: 5
Training loss: 6.25952277463793
Validation loss: 5.3082124050545

Epoch: 6| Step: 6
Training loss: 5.915249865325917
Validation loss: 5.3004342782939196

Epoch: 6| Step: 7
Training loss: 4.580906774718528
Validation loss: 5.292576098452835

Epoch: 6| Step: 8
Training loss: 5.254238234457825
Validation loss: 5.2850327948422215

Epoch: 6| Step: 9
Training loss: 6.132691828032548
Validation loss: 5.277647215360405

Epoch: 6| Step: 10
Training loss: 5.543077657327302
Validation loss: 5.270133121505363

Epoch: 6| Step: 11
Training loss: 4.177535314039706
Validation loss: 5.262491019898981

Epoch: 6| Step: 12
Training loss: 5.785516597593113
Validation loss: 5.255323405623763

Epoch: 6| Step: 13
Training loss: 5.802266289813006
Validation loss: 5.2477636266758045

Epoch: 7| Step: 0
Training loss: 5.6138534307369365
Validation loss: 5.240630826907027

Epoch: 6| Step: 1
Training loss: 5.6024839954751915
Validation loss: 5.2330999690869975

Epoch: 6| Step: 2
Training loss: 5.144237605514756
Validation loss: 5.225825342825051

Epoch: 6| Step: 3
Training loss: 4.939437486073997
Validation loss: 5.218589064501762

Epoch: 6| Step: 4
Training loss: 5.439374929307782
Validation loss: 5.211734586849939

Epoch: 6| Step: 5
Training loss: 5.477732926486651
Validation loss: 5.204723276874058

Epoch: 6| Step: 6
Training loss: 5.17231421319977
Validation loss: 5.198236744823063

Epoch: 6| Step: 7
Training loss: 4.798661983285965
Validation loss: 5.1911572965235955

Epoch: 6| Step: 8
Training loss: 5.3390912723631185
Validation loss: 5.184274980846055

Epoch: 6| Step: 9
Training loss: 5.155772424024365
Validation loss: 5.177448630797246

Epoch: 6| Step: 10
Training loss: 6.053248947048305
Validation loss: 5.170990959590892

Epoch: 6| Step: 11
Training loss: 4.275322367688342
Validation loss: 5.163559697268292

Epoch: 6| Step: 12
Training loss: 5.994034026320789
Validation loss: 5.157220044066014

Epoch: 6| Step: 13
Training loss: 5.208060092116421
Validation loss: 5.150177988970337

Epoch: 8| Step: 0
Training loss: 5.204580842216217
Validation loss: 5.143706846307231

Epoch: 6| Step: 1
Training loss: 5.153829850478724
Validation loss: 5.1368030381630225

Epoch: 6| Step: 2
Training loss: 5.608344448280751
Validation loss: 5.13030148597482

Epoch: 6| Step: 3
Training loss: 5.547508354026002
Validation loss: 5.1239038861442525

Epoch: 6| Step: 4
Training loss: 4.688026296951958
Validation loss: 5.11706623584053

Epoch: 6| Step: 5
Training loss: 5.365674467753004
Validation loss: 5.110205377730314

Epoch: 6| Step: 6
Training loss: 5.560054970339174
Validation loss: 5.104315411742348

Epoch: 6| Step: 7
Training loss: 4.233537767134815
Validation loss: 5.0975179017684775

Epoch: 6| Step: 8
Training loss: 5.7877540087726995
Validation loss: 5.09126708007465

Epoch: 6| Step: 9
Training loss: 5.237558427361866
Validation loss: 5.0846967692628

Epoch: 6| Step: 10
Training loss: 5.668322751264258
Validation loss: 5.078056108056329

Epoch: 6| Step: 11
Training loss: 4.704726849368925
Validation loss: 5.071798098128626

Epoch: 6| Step: 12
Training loss: 5.309256966251625
Validation loss: 5.065404270829814

Epoch: 6| Step: 13
Training loss: 4.854041800577928
Validation loss: 5.059142800952759

Epoch: 9| Step: 0
Training loss: 6.022013336318904
Validation loss: 5.052817233025201

Epoch: 6| Step: 1
Training loss: 4.827216695634383
Validation loss: 5.046811287461054

Epoch: 6| Step: 2
Training loss: 5.17818635157152
Validation loss: 5.0403857324725285

Epoch: 6| Step: 3
Training loss: 4.753140064142898
Validation loss: 5.0346471086650215

Epoch: 6| Step: 4
Training loss: 5.163481479109557
Validation loss: 5.028126222726101

Epoch: 6| Step: 5
Training loss: 5.3944117417519015
Validation loss: 5.02255744403745

Epoch: 6| Step: 6
Training loss: 5.0454161812013405
Validation loss: 5.01596787529514

Epoch: 6| Step: 7
Training loss: 4.741895487559949
Validation loss: 5.009774286511762

Epoch: 6| Step: 8
Training loss: 5.398868880308872
Validation loss: 5.003312094734618

Epoch: 6| Step: 9
Training loss: 4.977030829366526
Validation loss: 4.996641875127696

Epoch: 6| Step: 10
Training loss: 5.34346694642798
Validation loss: 4.990697918070374

Epoch: 6| Step: 11
Training loss: 4.968121374898921
Validation loss: 4.9840271767619795

Epoch: 6| Step: 12
Training loss: 4.9865977912539
Validation loss: 4.977658169639626

Epoch: 6| Step: 13
Training loss: 5.009660353121526
Validation loss: 4.970872853397271

Epoch: 10| Step: 0
Training loss: 5.748832915907326
Validation loss: 4.965003914679463

Epoch: 6| Step: 1
Training loss: 5.2470082432526
Validation loss: 4.958063144962396

Epoch: 6| Step: 2
Training loss: 4.614216372995138
Validation loss: 4.952105685023009

Epoch: 6| Step: 3
Training loss: 5.650520584294438
Validation loss: 4.946042730606256

Epoch: 6| Step: 4
Training loss: 4.655623220975211
Validation loss: 4.939842408893111

Epoch: 6| Step: 5
Training loss: 5.550567859088798
Validation loss: 4.933274823348722

Epoch: 6| Step: 6
Training loss: 5.247910583339112
Validation loss: 4.927141131437746

Epoch: 6| Step: 7
Training loss: 5.002426702981381
Validation loss: 4.920553056108688

Epoch: 6| Step: 8
Training loss: 5.263296093381177
Validation loss: 4.914385487302978

Epoch: 6| Step: 9
Training loss: 5.244054424920039
Validation loss: 4.908271356956675

Epoch: 6| Step: 10
Training loss: 4.085794420818837
Validation loss: 4.9016168833131415

Epoch: 6| Step: 11
Training loss: 5.210488730441569
Validation loss: 4.896290934935885

Epoch: 6| Step: 12
Training loss: 4.654066969379443
Validation loss: 4.8902972256770525

Epoch: 6| Step: 13
Training loss: 4.220216397346194
Validation loss: 4.884042813749995

Epoch: 11| Step: 0
Training loss: 5.121179785103958
Validation loss: 4.877818507345744

Epoch: 6| Step: 1
Training loss: 4.774856381478412
Validation loss: 4.871728174110818

Epoch: 6| Step: 2
Training loss: 5.815782502023253
Validation loss: 4.865138390491523

Epoch: 6| Step: 3
Training loss: 4.887885645800829
Validation loss: 4.859025785239707

Epoch: 6| Step: 4
Training loss: 4.7245385242336395
Validation loss: 4.852987722013841

Epoch: 6| Step: 5
Training loss: 4.979232957896128
Validation loss: 4.846835001016567

Epoch: 6| Step: 6
Training loss: 4.193992250725495
Validation loss: 4.8405594685245585

Epoch: 6| Step: 7
Training loss: 4.7688085709920855
Validation loss: 4.833774130002812

Epoch: 6| Step: 8
Training loss: 5.529107319969229
Validation loss: 4.828160982296221

Epoch: 6| Step: 9
Training loss: 5.018685901275271
Validation loss: 4.82187103515251

Epoch: 6| Step: 10
Training loss: 5.012768844282175
Validation loss: 4.815502171617822

Epoch: 6| Step: 11
Training loss: 5.961388647123318
Validation loss: 4.808981926520036

Epoch: 6| Step: 12
Training loss: 3.4513934873315346
Validation loss: 4.8026494694408415

Epoch: 6| Step: 13
Training loss: 4.7511227937092215
Validation loss: 4.796776057081333

Epoch: 12| Step: 0
Training loss: 4.94202322142644
Validation loss: 4.791025909483288

Epoch: 6| Step: 1
Training loss: 4.624436009016587
Validation loss: 4.785168174676894

Epoch: 6| Step: 2
Training loss: 4.281529104226306
Validation loss: 4.778754886003052

Epoch: 6| Step: 3
Training loss: 4.2867905900127745
Validation loss: 4.7732453003194255

Epoch: 6| Step: 4
Training loss: 5.181466511987098
Validation loss: 4.767086817935701

Epoch: 6| Step: 5
Training loss: 5.642601786900889
Validation loss: 4.7614565770088895

Epoch: 6| Step: 6
Training loss: 4.1866372201778965
Validation loss: 4.755318424862669

Epoch: 6| Step: 7
Training loss: 4.258501189644327
Validation loss: 4.749588797990833

Epoch: 6| Step: 8
Training loss: 4.862792159769048
Validation loss: 4.743942514164537

Epoch: 6| Step: 9
Training loss: 5.191365651588338
Validation loss: 4.7384905998188

Epoch: 6| Step: 10
Training loss: 5.180183306363243
Validation loss: 4.732488325520749

Epoch: 6| Step: 11
Training loss: 5.857201419763511
Validation loss: 4.72646220287331

Epoch: 6| Step: 12
Training loss: 4.615612297066453
Validation loss: 4.720301459378553

Epoch: 6| Step: 13
Training loss: 4.836599276962892
Validation loss: 4.714771437702769

Epoch: 13| Step: 0
Training loss: 5.004770101627207
Validation loss: 4.7085629747590865

Epoch: 6| Step: 1
Training loss: 4.406354321266166
Validation loss: 4.703334968417014

Epoch: 6| Step: 2
Training loss: 5.576136472359157
Validation loss: 4.697742478665011

Epoch: 6| Step: 3
Training loss: 5.437639958126042
Validation loss: 4.692279701542279

Epoch: 6| Step: 4
Training loss: 4.520798409088292
Validation loss: 4.686489250565556

Epoch: 6| Step: 5
Training loss: 4.6016472645126845
Validation loss: 4.680716391396321

Epoch: 6| Step: 6
Training loss: 4.18267931948803
Validation loss: 4.6748813070097635

Epoch: 6| Step: 7
Training loss: 5.482930484957917
Validation loss: 4.669503723339112

Epoch: 6| Step: 8
Training loss: 4.643579024482754
Validation loss: 4.663918787426387

Epoch: 6| Step: 9
Training loss: 4.621375235773894
Validation loss: 4.658333024427009

Epoch: 6| Step: 10
Training loss: 3.9467961609276307
Validation loss: 4.652645909479309

Epoch: 6| Step: 11
Training loss: 5.312013491624911
Validation loss: 4.646739010423286

Epoch: 6| Step: 12
Training loss: 4.751277751726145
Validation loss: 4.641917963718981

Epoch: 6| Step: 13
Training loss: 4.365404997015038
Validation loss: 4.6372919411269775

Epoch: 14| Step: 0
Training loss: 5.5612723035101475
Validation loss: 4.6320560002782285

Epoch: 6| Step: 1
Training loss: 4.623884736733145
Validation loss: 4.626513293707939

Epoch: 6| Step: 2
Training loss: 5.545996883893573
Validation loss: 4.621487667076226

Epoch: 6| Step: 3
Training loss: 4.944133889283454
Validation loss: 4.615385371905044

Epoch: 6| Step: 4
Training loss: 3.4031988354844582
Validation loss: 4.610158493781846

Epoch: 6| Step: 5
Training loss: 5.150616892190409
Validation loss: 4.606234084869178

Epoch: 6| Step: 6
Training loss: 3.9648259505450216
Validation loss: 4.601069252853253

Epoch: 6| Step: 7
Training loss: 4.359966935198637
Validation loss: 4.595991197758571

Epoch: 6| Step: 8
Training loss: 4.718845795928487
Validation loss: 4.59083838541433

Epoch: 6| Step: 9
Training loss: 4.636774694270759
Validation loss: 4.586040263890222

Epoch: 6| Step: 10
Training loss: 4.636315602208422
Validation loss: 4.580786373033506

Epoch: 6| Step: 11
Training loss: 4.9531646630657615
Validation loss: 4.575726919322214

Epoch: 6| Step: 12
Training loss: 4.979501284710508
Validation loss: 4.570446062445871

Epoch: 6| Step: 13
Training loss: 4.240124392214242
Validation loss: 4.56532102839722

Epoch: 15| Step: 0
Training loss: 4.873496386143816
Validation loss: 4.561027027805291

Epoch: 6| Step: 1
Training loss: 4.743343507742854
Validation loss: 4.555886775409766

Epoch: 6| Step: 2
Training loss: 4.494586231167926
Validation loss: 4.552005211387471

Epoch: 6| Step: 3
Training loss: 4.61426783646398
Validation loss: 4.547516418170145

Epoch: 6| Step: 4
Training loss: 4.1155527767486015
Validation loss: 4.542411159891607

Epoch: 6| Step: 5
Training loss: 3.7972337843681645
Validation loss: 4.537583408342238

Epoch: 6| Step: 6
Training loss: 4.694491043210665
Validation loss: 4.533210943944768

Epoch: 6| Step: 7
Training loss: 5.306123564419113
Validation loss: 4.528501339040955

Epoch: 6| Step: 8
Training loss: 5.593389744585913
Validation loss: 4.523668071380532

Epoch: 6| Step: 9
Training loss: 4.366819308187749
Validation loss: 4.518613466598184

Epoch: 6| Step: 10
Training loss: 4.6997443433989625
Validation loss: 4.51406150422614

Epoch: 6| Step: 11
Training loss: 4.594304473007665
Validation loss: 4.509844607871317

Epoch: 6| Step: 12
Training loss: 4.634124415716716
Validation loss: 4.50530027909434

Epoch: 6| Step: 13
Training loss: 4.422415656476385
Validation loss: 4.500013669311107

Epoch: 16| Step: 0
Training loss: 4.8675640811630325
Validation loss: 4.49573682246002

Epoch: 6| Step: 1
Training loss: 4.497729046318451
Validation loss: 4.490950562832368

Epoch: 6| Step: 2
Training loss: 5.46101311670868
Validation loss: 4.486777659928445

Epoch: 6| Step: 3
Training loss: 4.50121481710348
Validation loss: 4.481879644349401

Epoch: 6| Step: 4
Training loss: 3.469842412266989
Validation loss: 4.477408497278472

Epoch: 6| Step: 5
Training loss: 4.6370885455685835
Validation loss: 4.473360044586281

Epoch: 6| Step: 6
Training loss: 4.495875905954608
Validation loss: 4.468570092054341

Epoch: 6| Step: 7
Training loss: 3.6969074573526965
Validation loss: 4.463599057386873

Epoch: 6| Step: 8
Training loss: 4.148867367529313
Validation loss: 4.460225401971657

Epoch: 6| Step: 9
Training loss: 4.821012820125706
Validation loss: 4.456595209776186

Epoch: 6| Step: 10
Training loss: 5.181424179186472
Validation loss: 4.451767260491874

Epoch: 6| Step: 11
Training loss: 4.554235210176279
Validation loss: 4.447282119025692

Epoch: 6| Step: 12
Training loss: 5.179787291058894
Validation loss: 4.442926429085033

Epoch: 6| Step: 13
Training loss: 4.402404838889594
Validation loss: 4.438082625417759

Epoch: 17| Step: 0
Training loss: 3.808644831388214
Validation loss: 4.433863461618873

Epoch: 6| Step: 1
Training loss: 5.147883800780936
Validation loss: 4.429346554758441

Epoch: 6| Step: 2
Training loss: 3.421977281130493
Validation loss: 4.424351101152568

Epoch: 6| Step: 3
Training loss: 4.637028080456847
Validation loss: 4.4200222056249645

Epoch: 6| Step: 4
Training loss: 4.166214778555552
Validation loss: 4.415645061356457

Epoch: 6| Step: 5
Training loss: 5.255665220192234
Validation loss: 4.4107634061950405

Epoch: 6| Step: 6
Training loss: 5.1656297853312685
Validation loss: 4.405843314663455

Epoch: 6| Step: 7
Training loss: 4.565390102602453
Validation loss: 4.401645608428151

Epoch: 6| Step: 8
Training loss: 4.376256271920045
Validation loss: 4.397123801235152

Epoch: 6| Step: 9
Training loss: 3.4969630007882317
Validation loss: 4.393065565040697

Epoch: 6| Step: 10
Training loss: 3.810944536929107
Validation loss: 4.38892511696222

Epoch: 6| Step: 11
Training loss: 4.404597845176603
Validation loss: 4.38471723160238

Epoch: 6| Step: 12
Training loss: 4.91745542675737
Validation loss: 4.3799579501927814

Epoch: 6| Step: 13
Training loss: 5.611764892830271
Validation loss: 4.375615757797718

Epoch: 18| Step: 0
Training loss: 4.792922985850181
Validation loss: 4.3708846582260605

Epoch: 6| Step: 1
Training loss: 4.842173461302858
Validation loss: 4.366629267428063

Epoch: 6| Step: 2
Training loss: 4.096752434358568
Validation loss: 4.362487666159085

Epoch: 6| Step: 3
Training loss: 3.557999160286181
Validation loss: 4.357899770572942

Epoch: 6| Step: 4
Training loss: 4.83533677420412
Validation loss: 4.35345516445231

Epoch: 6| Step: 5
Training loss: 5.026497248687644
Validation loss: 4.3492839516206985

Epoch: 6| Step: 6
Training loss: 4.202602878743232
Validation loss: 4.345344891016493

Epoch: 6| Step: 7
Training loss: 3.731813198504871
Validation loss: 4.340719451133005

Epoch: 6| Step: 8
Training loss: 5.281641838390143
Validation loss: 4.336588474470878

Epoch: 6| Step: 9
Training loss: 4.9678831483916985
Validation loss: 4.33164902500867

Epoch: 6| Step: 10
Training loss: 4.5187428412374135
Validation loss: 4.327227447759541

Epoch: 6| Step: 11
Training loss: 4.17495191169501
Validation loss: 4.322978387721407

Epoch: 6| Step: 12
Training loss: 4.508166003456581
Validation loss: 4.319202558743808

Epoch: 6| Step: 13
Training loss: 3.649054072883965
Validation loss: 4.314868774009966

Epoch: 19| Step: 0
Training loss: 4.566264441566802
Validation loss: 4.3103568607469285

Epoch: 6| Step: 1
Training loss: 3.999227091502399
Validation loss: 4.306040067312384

Epoch: 6| Step: 2
Training loss: 4.0412780470011995
Validation loss: 4.301672089928144

Epoch: 6| Step: 3
Training loss: 3.983954672988359
Validation loss: 4.297342892227722

Epoch: 6| Step: 4
Training loss: 3.586975213455733
Validation loss: 4.293077712199135

Epoch: 6| Step: 5
Training loss: 4.265603537033916
Validation loss: 4.288891879812547

Epoch: 6| Step: 6
Training loss: 4.731443196110208
Validation loss: 4.285248497219544

Epoch: 6| Step: 7
Training loss: 5.2672341262351505
Validation loss: 4.280835579447088

Epoch: 6| Step: 8
Training loss: 4.126638376100985
Validation loss: 4.277142189885672

Epoch: 6| Step: 9
Training loss: 4.949822994882147
Validation loss: 4.272682620736907

Epoch: 6| Step: 10
Training loss: 5.012372920454061
Validation loss: 4.268500098550888

Epoch: 6| Step: 11
Training loss: 4.19177710891342
Validation loss: 4.263979938099648

Epoch: 6| Step: 12
Training loss: 4.175033916404153
Validation loss: 4.259799150827349

Epoch: 6| Step: 13
Training loss: 4.560056685379794
Validation loss: 4.255475948265323

Epoch: 20| Step: 0
Training loss: 4.3413246024916425
Validation loss: 4.251198375268438

Epoch: 6| Step: 1
Training loss: 4.7906194897126655
Validation loss: 4.247496634323526

Epoch: 6| Step: 2
Training loss: 3.3795988045674865
Validation loss: 4.24296458733512

Epoch: 6| Step: 3
Training loss: 4.775752079239801
Validation loss: 4.238714211846354

Epoch: 6| Step: 4
Training loss: 4.706341527527562
Validation loss: 4.234524282003483

Epoch: 6| Step: 5
Training loss: 4.784971496752248
Validation loss: 4.230596172354584

Epoch: 6| Step: 6
Training loss: 4.388079247996136
Validation loss: 4.226269761793089

Epoch: 6| Step: 7
Training loss: 4.177000861491342
Validation loss: 4.221883707251654

Epoch: 6| Step: 8
Training loss: 4.273450889775641
Validation loss: 4.217447414164578

Epoch: 6| Step: 9
Training loss: 4.049875215091509
Validation loss: 4.213258819454352

Epoch: 6| Step: 10
Training loss: 4.2236661171013505
Validation loss: 4.209131744235866

Epoch: 6| Step: 11
Training loss: 5.0170016197002765
Validation loss: 4.2048286851843155

Epoch: 6| Step: 12
Training loss: 3.500615746966547
Validation loss: 4.201052470263869

Epoch: 6| Step: 13
Training loss: 4.240242471779465
Validation loss: 4.19684569499374

Epoch: 21| Step: 0
Training loss: 4.572470861209651
Validation loss: 4.192686200132848

Epoch: 6| Step: 1
Training loss: 4.348148013096935
Validation loss: 4.188781105805592

Epoch: 6| Step: 2
Training loss: 4.43338337537779
Validation loss: 4.184888699265741

Epoch: 6| Step: 3
Training loss: 3.8812097814567794
Validation loss: 4.180771826680127

Epoch: 6| Step: 4
Training loss: 4.18274817661307
Validation loss: 4.177028677845195

Epoch: 6| Step: 5
Training loss: 4.700770197318525
Validation loss: 4.172127514839567

Epoch: 6| Step: 6
Training loss: 4.497550721659121
Validation loss: 4.168013177102822

Epoch: 6| Step: 7
Training loss: 3.787679707006152
Validation loss: 4.164195504130991

Epoch: 6| Step: 8
Training loss: 4.299837180315283
Validation loss: 4.160718384972071

Epoch: 6| Step: 9
Training loss: 4.516259805482323
Validation loss: 4.155864994124037

Epoch: 6| Step: 10
Training loss: 4.287406560029773
Validation loss: 4.152203552424838

Epoch: 6| Step: 11
Training loss: 4.462273659829702
Validation loss: 4.148225001791327

Epoch: 6| Step: 12
Training loss: 4.254641746922215
Validation loss: 4.1436009874588375

Epoch: 6| Step: 13
Training loss: 3.8337580127713173
Validation loss: 4.139504219813292

Epoch: 22| Step: 0
Training loss: 4.118178999224454
Validation loss: 4.135495330036761

Epoch: 6| Step: 1
Training loss: 4.252353913916868
Validation loss: 4.131624124258457

Epoch: 6| Step: 2
Training loss: 2.6918442678369003
Validation loss: 4.127656351074482

Epoch: 6| Step: 3
Training loss: 4.56446942190608
Validation loss: 4.1237526173201235

Epoch: 6| Step: 4
Training loss: 3.321415258049835
Validation loss: 4.119706446766529

Epoch: 6| Step: 5
Training loss: 4.678303152398548
Validation loss: 4.1160167595497725

Epoch: 6| Step: 6
Training loss: 4.907537206430035
Validation loss: 4.11210329022662

Epoch: 6| Step: 7
Training loss: 4.16261778885344
Validation loss: 4.108119255405087

Epoch: 6| Step: 8
Training loss: 4.909000864712298
Validation loss: 4.104038404342042

Epoch: 6| Step: 9
Training loss: 5.233919676150141
Validation loss: 4.100050060617889

Epoch: 6| Step: 10
Training loss: 4.450030406033651
Validation loss: 4.095786328335446

Epoch: 6| Step: 11
Training loss: 3.8901778734035735
Validation loss: 4.091583396908565

Epoch: 6| Step: 12
Training loss: 3.520211580593353
Validation loss: 4.086960090186602

Epoch: 6| Step: 13
Training loss: 3.951817232114253
Validation loss: 4.08295288389615

Epoch: 23| Step: 0
Training loss: 4.288268191192086
Validation loss: 4.07904889979397

Epoch: 6| Step: 1
Training loss: 4.239717498580942
Validation loss: 4.0748610802434575

Epoch: 6| Step: 2
Training loss: 4.23911417146793
Validation loss: 4.070961966901415

Epoch: 6| Step: 3
Training loss: 4.978178663138158
Validation loss: 4.066659255620322

Epoch: 6| Step: 4
Training loss: 3.3942025292145095
Validation loss: 4.062046456084313

Epoch: 6| Step: 5
Training loss: 4.458001073892771
Validation loss: 4.057908148036724

Epoch: 6| Step: 6
Training loss: 3.3945365879381217
Validation loss: 4.053857932859907

Epoch: 6| Step: 7
Training loss: 4.282069663780442
Validation loss: 4.049693968085504

Epoch: 6| Step: 8
Training loss: 3.4371373765587134
Validation loss: 4.045829844186826

Epoch: 6| Step: 9
Training loss: 4.257035210730631
Validation loss: 4.041841535947319

Epoch: 6| Step: 10
Training loss: 5.083915531192066
Validation loss: 4.0381920944707055

Epoch: 6| Step: 11
Training loss: 4.134398417503833
Validation loss: 4.033833900369557

Epoch: 6| Step: 12
Training loss: 4.049260559396105
Validation loss: 4.029976557402349

Epoch: 6| Step: 13
Training loss: 3.955119357423961
Validation loss: 4.025858938685448

Epoch: 24| Step: 0
Training loss: 4.028195665685186
Validation loss: 4.022012224798152

Epoch: 6| Step: 1
Training loss: 4.274837620199994
Validation loss: 4.018175950092491

Epoch: 6| Step: 2
Training loss: 4.397053963408785
Validation loss: 4.013396737103739

Epoch: 6| Step: 3
Training loss: 3.9210223604716106
Validation loss: 4.009514737785043

Epoch: 6| Step: 4
Training loss: 3.3788098624709497
Validation loss: 4.005352551757872

Epoch: 6| Step: 5
Training loss: 4.991476423218377
Validation loss: 4.001275852496832

Epoch: 6| Step: 6
Training loss: 3.455238765520816
Validation loss: 3.99717063973618

Epoch: 6| Step: 7
Training loss: 3.979918497104094
Validation loss: 3.993390105602314

Epoch: 6| Step: 8
Training loss: 4.130182882697962
Validation loss: 3.98950692577584

Epoch: 6| Step: 9
Training loss: 3.583637638625812
Validation loss: 3.9854544180986267

Epoch: 6| Step: 10
Training loss: 3.4214050806401275
Validation loss: 3.9811733372212497

Epoch: 6| Step: 11
Training loss: 5.251965654329141
Validation loss: 3.97722186084934

Epoch: 6| Step: 12
Training loss: 4.35337980665216
Validation loss: 3.972720925533895

Epoch: 6| Step: 13
Training loss: 4.145172270909567
Validation loss: 3.9688747516559237

Epoch: 25| Step: 0
Training loss: 4.061063541864921
Validation loss: 3.964648472779858

Epoch: 6| Step: 1
Training loss: 3.5680040371534147
Validation loss: 3.9611236107194907

Epoch: 6| Step: 2
Training loss: 3.976668980340106
Validation loss: 3.9566544368740213

Epoch: 6| Step: 3
Training loss: 4.392855583305836
Validation loss: 3.952503341425674

Epoch: 6| Step: 4
Training loss: 3.9011218780433703
Validation loss: 3.9481163611857752

Epoch: 6| Step: 5
Training loss: 3.777053522047397
Validation loss: 3.94433551437931

Epoch: 6| Step: 6
Training loss: 3.458892286852943
Validation loss: 3.9401417907142147

Epoch: 6| Step: 7
Training loss: 4.330232513387141
Validation loss: 3.9358603883473413

Epoch: 6| Step: 8
Training loss: 4.616691962952059
Validation loss: 3.932692746893056

Epoch: 6| Step: 9
Training loss: 4.272349440509436
Validation loss: 3.927946378682444

Epoch: 6| Step: 10
Training loss: 4.25815473108566
Validation loss: 3.9239138993691847

Epoch: 6| Step: 11
Training loss: 4.805440505652852
Validation loss: 3.9199592805226704

Epoch: 6| Step: 12
Training loss: 2.697332537440536
Validation loss: 3.9155700176384243

Epoch: 6| Step: 13
Training loss: 4.425033034723971
Validation loss: 3.9118286986911435

Epoch: 26| Step: 0
Training loss: 4.217324927494606
Validation loss: 3.907447326266081

Epoch: 6| Step: 1
Training loss: 3.508146614186183
Validation loss: 3.9035976916757464

Epoch: 6| Step: 2
Training loss: 4.094782342401196
Validation loss: 3.899442513879008

Epoch: 6| Step: 3
Training loss: 4.017956483611939
Validation loss: 3.895095442523585

Epoch: 6| Step: 4
Training loss: 3.9933992999003776
Validation loss: 3.8912022173944227

Epoch: 6| Step: 5
Training loss: 4.055640195082371
Validation loss: 3.8872236016603177

Epoch: 6| Step: 6
Training loss: 4.1652697446742195
Validation loss: 3.883011995099069

Epoch: 6| Step: 7
Training loss: 4.363476208435429
Validation loss: 3.8792167608439083

Epoch: 6| Step: 8
Training loss: 3.4178018932486625
Validation loss: 3.8751659357781922

Epoch: 6| Step: 9
Training loss: 4.398141962831546
Validation loss: 3.8707706382007614

Epoch: 6| Step: 10
Training loss: 4.772118918549529
Validation loss: 3.8665910151633667

Epoch: 6| Step: 11
Training loss: 3.213346519706969
Validation loss: 3.863298468170522

Epoch: 6| Step: 12
Training loss: 4.267313305213086
Validation loss: 3.8577896960050455

Epoch: 6| Step: 13
Training loss: 3.4283585113308024
Validation loss: 3.8535174604882965

Epoch: 27| Step: 0
Training loss: 4.239759561810996
Validation loss: 3.8499731946400115

Epoch: 6| Step: 1
Training loss: 3.340317434884879
Validation loss: 3.846061321759556

Epoch: 6| Step: 2
Training loss: 2.452830205808011
Validation loss: 3.8421522918945463

Epoch: 6| Step: 3
Training loss: 4.318273024987531
Validation loss: 3.8381693783283546

Epoch: 6| Step: 4
Training loss: 4.15154993000073
Validation loss: 3.833864448214692

Epoch: 6| Step: 5
Training loss: 4.198501937366042
Validation loss: 3.8302232661962052

Epoch: 6| Step: 6
Training loss: 3.5027318919362225
Validation loss: 3.8263138411574555

Epoch: 6| Step: 7
Training loss: 4.357042570545742
Validation loss: 3.8223932030850625

Epoch: 6| Step: 8
Training loss: 3.868928398000219
Validation loss: 3.8183436192596396

Epoch: 6| Step: 9
Training loss: 4.586193279041411
Validation loss: 3.814573318298849

Epoch: 6| Step: 10
Training loss: 4.211439339878536
Validation loss: 3.8099235834383087

Epoch: 6| Step: 11
Training loss: 3.7605161081341127
Validation loss: 3.8059388491311315

Epoch: 6| Step: 12
Training loss: 4.545740569392269
Validation loss: 3.80176949795249

Epoch: 6| Step: 13
Training loss: 3.3240784594185073
Validation loss: 3.797527450787105

Epoch: 28| Step: 0
Training loss: 3.7127794051431176
Validation loss: 3.793503634200562

Epoch: 6| Step: 1
Training loss: 3.5939453071928837
Validation loss: 3.7901168142952293

Epoch: 6| Step: 2
Training loss: 3.9610313991273847
Validation loss: 3.786322205137238

Epoch: 6| Step: 3
Training loss: 3.9903496918374173
Validation loss: 3.7819927316317083

Epoch: 6| Step: 4
Training loss: 3.6167157979930007
Validation loss: 3.777971722417756

Epoch: 6| Step: 5
Training loss: 3.8595939296140562
Validation loss: 3.774091875768951

Epoch: 6| Step: 6
Training loss: 3.414880301079838
Validation loss: 3.769845478355079

Epoch: 6| Step: 7
Training loss: 4.0549876078123495
Validation loss: 3.76667606358214

Epoch: 6| Step: 8
Training loss: 3.7399243099284964
Validation loss: 3.762457986556964

Epoch: 6| Step: 9
Training loss: 3.5159772230241635
Validation loss: 3.75900042520967

Epoch: 6| Step: 10
Training loss: 4.400107356409023
Validation loss: 3.7550299712778465

Epoch: 6| Step: 11
Training loss: 4.1669886401071725
Validation loss: 3.7506943589670985

Epoch: 6| Step: 12
Training loss: 4.605344917890966
Validation loss: 3.7461168529128255

Epoch: 6| Step: 13
Training loss: 3.8251313629531283
Validation loss: 3.7429456692719634

Epoch: 29| Step: 0
Training loss: 3.8057446274269973
Validation loss: 3.738513053103588

Epoch: 6| Step: 1
Training loss: 4.076537075233934
Validation loss: 3.734202126900244

Epoch: 6| Step: 2
Training loss: 3.543201577675753
Validation loss: 3.7302115839383254

Epoch: 6| Step: 3
Training loss: 4.178562704596536
Validation loss: 3.7257551362299757

Epoch: 6| Step: 4
Training loss: 3.589663894348557
Validation loss: 3.7215419514577506

Epoch: 6| Step: 5
Training loss: 3.5372195129266992
Validation loss: 3.7174378973385482

Epoch: 6| Step: 6
Training loss: 4.145949830122946
Validation loss: 3.713777203823498

Epoch: 6| Step: 7
Training loss: 3.6622716109897056
Validation loss: 3.7090534018303365

Epoch: 6| Step: 8
Training loss: 3.8213167645303066
Validation loss: 3.7051760416426345

Epoch: 6| Step: 9
Training loss: 4.269448156499286
Validation loss: 3.7009088937807575

Epoch: 6| Step: 10
Training loss: 4.2439986098536195
Validation loss: 3.6966841170366616

Epoch: 6| Step: 11
Training loss: 3.9847794869747126
Validation loss: 3.692773152129078

Epoch: 6| Step: 12
Training loss: 3.7014457661686326
Validation loss: 3.6881151925410007

Epoch: 6| Step: 13
Training loss: 3.1578630914273687
Validation loss: 3.6843360215040395

Epoch: 30| Step: 0
Training loss: 3.9017819906206372
Validation loss: 3.6806005275226035

Epoch: 6| Step: 1
Training loss: 4.170461579534926
Validation loss: 3.6767666529954033

Epoch: 6| Step: 2
Training loss: 4.419167056763745
Validation loss: 3.672406465201848

Epoch: 6| Step: 3
Training loss: 3.714486378709335
Validation loss: 3.668517548682943

Epoch: 6| Step: 4
Training loss: 3.0923221260052203
Validation loss: 3.6644551948552633

Epoch: 6| Step: 5
Training loss: 2.9170068996532237
Validation loss: 3.6602807066231504

Epoch: 6| Step: 6
Training loss: 3.2773804145371646
Validation loss: 3.6564824174440598

Epoch: 6| Step: 7
Training loss: 3.253105440548188
Validation loss: 3.652960359742751

Epoch: 6| Step: 8
Training loss: 4.18071093997457
Validation loss: 3.649131648965759

Epoch: 6| Step: 9
Training loss: 4.865148126242736
Validation loss: 3.6453745671414284

Epoch: 6| Step: 10
Training loss: 2.939877461066019
Validation loss: 3.6416776496901995

Epoch: 6| Step: 11
Training loss: 3.784192792316018
Validation loss: 3.637338205171587

Epoch: 6| Step: 12
Training loss: 3.6646109945190504
Validation loss: 3.63340735812125

Epoch: 6| Step: 13
Training loss: 4.293353937308903
Validation loss: 3.629647837879358

Epoch: 31| Step: 0
Training loss: 4.885379598621978
Validation loss: 3.6253869299631214

Epoch: 6| Step: 1
Training loss: 3.1472641341570564
Validation loss: 3.6216427394768798

Epoch: 6| Step: 2
Training loss: 3.766278348728046
Validation loss: 3.617195343602288

Epoch: 6| Step: 3
Training loss: 3.597002365548462
Validation loss: 3.613288640195145

Epoch: 6| Step: 4
Training loss: 3.478714523326432
Validation loss: 3.609297978623895

Epoch: 6| Step: 5
Training loss: 3.977229993516302
Validation loss: 3.605205797695858

Epoch: 6| Step: 6
Training loss: 3.1690327354562866
Validation loss: 3.6011497718945673

Epoch: 6| Step: 7
Training loss: 4.183910140638946
Validation loss: 3.5967299780401163

Epoch: 6| Step: 8
Training loss: 3.2305314820182507
Validation loss: 3.5926197430770723

Epoch: 6| Step: 9
Training loss: 3.7639763099743786
Validation loss: 3.588910124991162

Epoch: 6| Step: 10
Training loss: 3.8910576147060474
Validation loss: 3.5844830657180107

Epoch: 6| Step: 11
Training loss: 3.4165462999928917
Validation loss: 3.5806160907808757

Epoch: 6| Step: 12
Training loss: 3.8815520483849357
Validation loss: 3.57684627599857

Epoch: 6| Step: 13
Training loss: 3.583913460427511
Validation loss: 3.5728421810530726

Epoch: 32| Step: 0
Training loss: 3.5697107788812303
Validation loss: 3.5693123360482812

Epoch: 6| Step: 1
Training loss: 4.281192083036624
Validation loss: 3.5652999805577585

Epoch: 6| Step: 2
Training loss: 4.061602684104563
Validation loss: 3.561473631660933

Epoch: 6| Step: 3
Training loss: 3.947292563730132
Validation loss: 3.557226996813719

Epoch: 6| Step: 4
Training loss: 3.475304811131455
Validation loss: 3.5532369148122425

Epoch: 6| Step: 5
Training loss: 3.4717325670638735
Validation loss: 3.5493519518364143

Epoch: 6| Step: 6
Training loss: 3.5116025164996563
Validation loss: 3.5454422441830826

Epoch: 6| Step: 7
Training loss: 2.9681362119917964
Validation loss: 3.5414823297137605

Epoch: 6| Step: 8
Training loss: 4.173885703861149
Validation loss: 3.5378501673847667

Epoch: 6| Step: 9
Training loss: 3.8697976907689204
Validation loss: 3.5337780030864496

Epoch: 6| Step: 10
Training loss: 3.031871299387526
Validation loss: 3.5298021437225238

Epoch: 6| Step: 11
Training loss: 3.835592405874731
Validation loss: 3.5259507288210323

Epoch: 6| Step: 12
Training loss: 3.512072722488023
Validation loss: 3.521904408135512

Epoch: 6| Step: 13
Training loss: 3.5882970157196383
Validation loss: 3.518325672572

Epoch: 33| Step: 0
Training loss: 3.1376386269875716
Validation loss: 3.5142049224293364

Epoch: 6| Step: 1
Training loss: 3.7038131911377756
Validation loss: 3.5105797855199508

Epoch: 6| Step: 2
Training loss: 4.248236795323517
Validation loss: 3.5069685545911926

Epoch: 6| Step: 3
Training loss: 3.8162466931445893
Validation loss: 3.502645457803152

Epoch: 6| Step: 4
Training loss: 2.92258546728725
Validation loss: 3.4989389900353483

Epoch: 6| Step: 5
Training loss: 3.224703865353542
Validation loss: 3.4950268245135128

Epoch: 6| Step: 6
Training loss: 4.195515036355856
Validation loss: 3.4911561220929825

Epoch: 6| Step: 7
Training loss: 3.268654618047762
Validation loss: 3.486918639991266

Epoch: 6| Step: 8
Training loss: 3.4343710790859956
Validation loss: 3.4833113981465864

Epoch: 6| Step: 9
Training loss: 3.8952327544139864
Validation loss: 3.479634982510555

Epoch: 6| Step: 10
Training loss: 3.090703215347026
Validation loss: 3.4758281489385188

Epoch: 6| Step: 11
Training loss: 4.1855915332428575
Validation loss: 3.4722287029629735

Epoch: 6| Step: 12
Training loss: 3.967621169664725
Validation loss: 3.4683460080527606

Epoch: 6| Step: 13
Training loss: 3.347395291389472
Validation loss: 3.4645771897460884

Epoch: 34| Step: 0
Training loss: 3.8484708746617944
Validation loss: 3.460538245508745

Epoch: 6| Step: 1
Training loss: 3.2959917521512434
Validation loss: 3.45685218591541

Epoch: 6| Step: 2
Training loss: 2.9064939663120746
Validation loss: 3.45279179917429

Epoch: 6| Step: 3
Training loss: 4.2271509236885105
Validation loss: 3.4494436672403213

Epoch: 6| Step: 4
Training loss: 3.016861894166944
Validation loss: 3.445458718309005

Epoch: 6| Step: 5
Training loss: 4.228417742083024
Validation loss: 3.441870991058167

Epoch: 6| Step: 6
Training loss: 3.9022415957287353
Validation loss: 3.4377805190790194

Epoch: 6| Step: 7
Training loss: 3.4458981662787544
Validation loss: 3.4337984674303708

Epoch: 6| Step: 8
Training loss: 3.2998805515750242
Validation loss: 3.4299068626978517

Epoch: 6| Step: 9
Training loss: 3.71892566426293
Validation loss: 3.426292494378479

Epoch: 6| Step: 10
Training loss: 3.5763826750831984
Validation loss: 3.4223487328668103

Epoch: 6| Step: 11
Training loss: 3.6528772953789748
Validation loss: 3.4184137777617876

Epoch: 6| Step: 12
Training loss: 3.3208484172279045
Validation loss: 3.4145456258861353

Epoch: 6| Step: 13
Training loss: 3.3293145431377367
Validation loss: 3.410810142069795

Epoch: 35| Step: 0
Training loss: 3.3673475187651465
Validation loss: 3.4069586900289774

Epoch: 6| Step: 1
Training loss: 3.2828777816941366
Validation loss: 3.403206938757531

Epoch: 6| Step: 2
Training loss: 3.880794745388496
Validation loss: 3.39982767135867

Epoch: 6| Step: 3
Training loss: 3.3104289076050444
Validation loss: 3.3956614413764346

Epoch: 6| Step: 4
Training loss: 3.7852695003294694
Validation loss: 3.39176708388331

Epoch: 6| Step: 5
Training loss: 4.014597482991221
Validation loss: 3.387930506978735

Epoch: 6| Step: 6
Training loss: 3.381332249795678
Validation loss: 3.3840380321541894

Epoch: 6| Step: 7
Training loss: 3.6252103284129507
Validation loss: 3.3807587648109934

Epoch: 6| Step: 8
Training loss: 3.613182800601365
Validation loss: 3.3765968501061794

Epoch: 6| Step: 9
Training loss: 3.2868778466812403
Validation loss: 3.3725059383293865

Epoch: 6| Step: 10
Training loss: 3.8001703475114086
Validation loss: 3.3687720350536856

Epoch: 6| Step: 11
Training loss: 3.3962678845790775
Validation loss: 3.3651972979161537

Epoch: 6| Step: 12
Training loss: 3.282505630755625
Validation loss: 3.361532893308014

Epoch: 6| Step: 13
Training loss: 3.1622770570117247
Validation loss: 3.3576598527830916

Epoch: 36| Step: 0
Training loss: 2.678161186410009
Validation loss: 3.3542344617606696

Epoch: 6| Step: 1
Training loss: 2.6592745447068786
Validation loss: 3.3507058116520176

Epoch: 6| Step: 2
Training loss: 3.7115036060799316
Validation loss: 3.3478327986145375

Epoch: 6| Step: 3
Training loss: 3.156729935519227
Validation loss: 3.3445433866736134

Epoch: 6| Step: 4
Training loss: 3.516772680507619
Validation loss: 3.341165333921632

Epoch: 6| Step: 5
Training loss: 3.624554179170412
Validation loss: 3.338112270376426

Epoch: 6| Step: 6
Training loss: 3.1566148301581114
Validation loss: 3.3344294812018798

Epoch: 6| Step: 7
Training loss: 3.3605741977523174
Validation loss: 3.330950115511727

Epoch: 6| Step: 8
Training loss: 3.323615659342306
Validation loss: 3.3278455781124054

Epoch: 6| Step: 9
Training loss: 4.401859774722311
Validation loss: 3.324464029122983

Epoch: 6| Step: 10
Training loss: 4.015918528000183
Validation loss: 3.320786039206299

Epoch: 6| Step: 11
Training loss: 4.022925483197442
Validation loss: 3.3172284572215265

Epoch: 6| Step: 12
Training loss: 3.5061776274421383
Validation loss: 3.31336790986572

Epoch: 6| Step: 13
Training loss: 2.9643637930851043
Validation loss: 3.3093548844650376

Epoch: 37| Step: 0
Training loss: 3.6026240375245253
Validation loss: 3.3055423746104444

Epoch: 6| Step: 1
Training loss: 2.957701996251957
Validation loss: 3.3019183545861925

Epoch: 6| Step: 2
Training loss: 3.1912191796075247
Validation loss: 3.2976950036984323

Epoch: 6| Step: 3
Training loss: 3.6306221870651814
Validation loss: 3.293968812067203

Epoch: 6| Step: 4
Training loss: 3.03081265470177
Validation loss: 3.2901695605279895

Epoch: 6| Step: 5
Training loss: 3.4617118571941785
Validation loss: 3.286446963782778

Epoch: 6| Step: 6
Training loss: 3.5003413987548293
Validation loss: 3.282810312494623

Epoch: 6| Step: 7
Training loss: 3.837901806997069
Validation loss: 3.2790277494470335

Epoch: 6| Step: 8
Training loss: 3.389797127203726
Validation loss: 3.2755423662146432

Epoch: 6| Step: 9
Training loss: 3.489421935642964
Validation loss: 3.271942622795461

Epoch: 6| Step: 10
Training loss: 3.3697737742936087
Validation loss: 3.268256482419256

Epoch: 6| Step: 11
Training loss: 2.869584331649829
Validation loss: 3.2648614358829917

Epoch: 6| Step: 12
Training loss: 3.309817109371053
Validation loss: 3.261355997041784

Epoch: 6| Step: 13
Training loss: 4.069326914774314
Validation loss: 3.2578259901564843

Epoch: 38| Step: 0
Training loss: 3.1171250874860887
Validation loss: 3.254091963519069

Epoch: 6| Step: 1
Training loss: 3.70659130769963
Validation loss: 3.250674984603934

Epoch: 6| Step: 2
Training loss: 3.5904863216223
Validation loss: 3.2470682565782965

Epoch: 6| Step: 3
Training loss: 3.5106418133686694
Validation loss: 3.2436447361677874

Epoch: 6| Step: 4
Training loss: 3.675132961852194
Validation loss: 3.2401516692842978

Epoch: 6| Step: 5
Training loss: 3.1286428962203905
Validation loss: 3.236481304760409

Epoch: 6| Step: 6
Training loss: 3.4638524578115772
Validation loss: 3.2329104020745136

Epoch: 6| Step: 7
Training loss: 2.7371639306701776
Validation loss: 3.229551616406818

Epoch: 6| Step: 8
Training loss: 3.601183029341251
Validation loss: 3.226082040207492

Epoch: 6| Step: 9
Training loss: 3.4362985071759877
Validation loss: 3.2225048052720138

Epoch: 6| Step: 10
Training loss: 3.440698418799715
Validation loss: 3.2191375696610356

Epoch: 6| Step: 11
Training loss: 3.167695397038353
Validation loss: 3.215625468588629

Epoch: 6| Step: 12
Training loss: 2.8769078765853604
Validation loss: 3.2121822546379124

Epoch: 6| Step: 13
Training loss: 3.5970604286155408
Validation loss: 3.2090434655019293

Epoch: 39| Step: 0
Training loss: 3.254569729026212
Validation loss: 3.205774405578832

Epoch: 6| Step: 1
Training loss: 3.074844703784661
Validation loss: 3.202214652855591

Epoch: 6| Step: 2
Training loss: 3.6754988299365223
Validation loss: 3.19889460386003

Epoch: 6| Step: 3
Training loss: 3.4671933917167017
Validation loss: 3.1952808630386738

Epoch: 6| Step: 4
Training loss: 3.5722082267976187
Validation loss: 3.1918952035049775

Epoch: 6| Step: 5
Training loss: 3.063881698635315
Validation loss: 3.188392788388675

Epoch: 6| Step: 6
Training loss: 3.2093595539675928
Validation loss: 3.1849575374653196

Epoch: 6| Step: 7
Training loss: 3.4206190896327326
Validation loss: 3.1817502041363026

Epoch: 6| Step: 8
Training loss: 3.4792407060309767
Validation loss: 3.1784223059243346

Epoch: 6| Step: 9
Training loss: 3.331413256454131
Validation loss: 3.1747373246996458

Epoch: 6| Step: 10
Training loss: 3.625122462867782
Validation loss: 3.171412266644755

Epoch: 6| Step: 11
Training loss: 3.261429861832436
Validation loss: 3.1682013674374563

Epoch: 6| Step: 12
Training loss: 3.134682266220334
Validation loss: 3.164931911752568

Epoch: 6| Step: 13
Training loss: 2.9008515784802045
Validation loss: 3.1616021280198523

Epoch: 40| Step: 0
Training loss: 3.564357072764047
Validation loss: 3.1584826589292194

Epoch: 6| Step: 1
Training loss: 3.2404474575807884
Validation loss: 3.1553837811888688

Epoch: 6| Step: 2
Training loss: 3.7916795639545344
Validation loss: 3.1520343614510984

Epoch: 6| Step: 3
Training loss: 2.7707554703482664
Validation loss: 3.1488139871635537

Epoch: 6| Step: 4
Training loss: 2.9606197458437618
Validation loss: 3.145865728619912

Epoch: 6| Step: 5
Training loss: 3.3814360392893987
Validation loss: 3.142660262806836

Epoch: 6| Step: 6
Training loss: 3.5609555828577726
Validation loss: 3.1395365155700707

Epoch: 6| Step: 7
Training loss: 3.2575510775469274
Validation loss: 3.1363378842242726

Epoch: 6| Step: 8
Training loss: 3.730736144703413
Validation loss: 3.1335137550340626

Epoch: 6| Step: 9
Training loss: 3.1338867476594876
Validation loss: 3.130126486589959

Epoch: 6| Step: 10
Training loss: 3.332163764492009
Validation loss: 3.1269441279246735

Epoch: 6| Step: 11
Training loss: 2.8885358529502967
Validation loss: 3.1235334769956014

Epoch: 6| Step: 12
Training loss: 3.05711670114408
Validation loss: 3.1204061184361556

Epoch: 6| Step: 13
Training loss: 3.0657275572565585
Validation loss: 3.117238196500113

Epoch: 41| Step: 0
Training loss: 3.3264439595299895
Validation loss: 3.1141948308803356

Epoch: 6| Step: 1
Training loss: 3.4748659945110933
Validation loss: 3.111053384423192

Epoch: 6| Step: 2
Training loss: 2.624020348260649
Validation loss: 3.107852710114053

Epoch: 6| Step: 3
Training loss: 3.5233316680509685
Validation loss: 3.1047728840503983

Epoch: 6| Step: 4
Training loss: 3.5329207797288413
Validation loss: 3.1017315079438164

Epoch: 6| Step: 5
Training loss: 3.1117821964937598
Validation loss: 3.0984905926414528

Epoch: 6| Step: 6
Training loss: 3.025797236031228
Validation loss: 3.095241225768522

Epoch: 6| Step: 7
Training loss: 2.9693625370343
Validation loss: 3.09214186054029

Epoch: 6| Step: 8
Training loss: 3.6850624433219092
Validation loss: 3.089130639222114

Epoch: 6| Step: 9
Training loss: 2.77096154817398
Validation loss: 3.085868506324269

Epoch: 6| Step: 10
Training loss: 3.540804739393949
Validation loss: 3.082933842493902

Epoch: 6| Step: 11
Training loss: 3.512264833010482
Validation loss: 3.079936919103067

Epoch: 6| Step: 12
Training loss: 2.688290235864132
Validation loss: 3.076875901166242

Epoch: 6| Step: 13
Training loss: 3.290887829028372
Validation loss: 3.07377616801893

Epoch: 42| Step: 0
Training loss: 3.516895929128179
Validation loss: 3.070936416248469

Epoch: 6| Step: 1
Training loss: 2.3813938608041885
Validation loss: 3.0679253122032693

Epoch: 6| Step: 2
Training loss: 2.8919336604295895
Validation loss: 3.0651412525164337

Epoch: 6| Step: 3
Training loss: 3.405989470711436
Validation loss: 3.0625184116977837

Epoch: 6| Step: 4
Training loss: 3.8081922114050846
Validation loss: 3.0597856390840814

Epoch: 6| Step: 5
Training loss: 2.2334208551973953
Validation loss: 3.0566595269899453

Epoch: 6| Step: 6
Training loss: 3.49536807238176
Validation loss: 3.0539974594255535

Epoch: 6| Step: 7
Training loss: 3.672099394739166
Validation loss: 3.0511347280583716

Epoch: 6| Step: 8
Training loss: 3.200216619789076
Validation loss: 3.0480832825961315

Epoch: 6| Step: 9
Training loss: 2.4448404557298598
Validation loss: 3.0452241256153707

Epoch: 6| Step: 10
Training loss: 2.9217888314499967
Validation loss: 3.042366369756094

Epoch: 6| Step: 11
Training loss: 3.93149532650356
Validation loss: 3.0397498653635737

Epoch: 6| Step: 12
Training loss: 2.8163749280396826
Validation loss: 3.0368813448526484

Epoch: 6| Step: 13
Training loss: 3.3959668529137423
Validation loss: 3.033940566419386

Epoch: 43| Step: 0
Training loss: 3.133566901111683
Validation loss: 3.0310833285414254

Epoch: 6| Step: 1
Training loss: 3.197506773749865
Validation loss: 3.0282388524664094

Epoch: 6| Step: 2
Training loss: 3.3468607755299966
Validation loss: 3.0253854632102715

Epoch: 6| Step: 3
Training loss: 3.201952017029667
Validation loss: 3.022620157167819

Epoch: 6| Step: 4
Training loss: 3.288832704032655
Validation loss: 3.019662187179318

Epoch: 6| Step: 5
Training loss: 2.8722534328841602
Validation loss: 3.016815978161022

Epoch: 6| Step: 6
Training loss: 3.725729539335989
Validation loss: 3.0139047990448344

Epoch: 6| Step: 7
Training loss: 2.3420757162688153
Validation loss: 3.0108424394900792

Epoch: 6| Step: 8
Training loss: 3.535630201740832
Validation loss: 3.007948861602218

Epoch: 6| Step: 9
Training loss: 2.654970825954576
Validation loss: 3.0050352675896166

Epoch: 6| Step: 10
Training loss: 3.6055652940249936
Validation loss: 3.002528952555062

Epoch: 6| Step: 11
Training loss: 2.853677044009849
Validation loss: 2.9995739157411796

Epoch: 6| Step: 12
Training loss: 3.162897945893559
Validation loss: 2.9967874704465975

Epoch: 6| Step: 13
Training loss: 2.9706238304054016
Validation loss: 2.993980660575051

Epoch: 44| Step: 0
Training loss: 3.7264099729660844
Validation loss: 2.991265522584068

Epoch: 6| Step: 1
Training loss: 3.532262606301101
Validation loss: 2.9886593515052877

Epoch: 6| Step: 2
Training loss: 3.2309289532958037
Validation loss: 2.9857116155988357

Epoch: 6| Step: 3
Training loss: 3.329700365762186
Validation loss: 2.982906932478342

Epoch: 6| Step: 4
Training loss: 2.7216943166262295
Validation loss: 2.979998416878879

Epoch: 6| Step: 5
Training loss: 2.8528564861582564
Validation loss: 2.9773370330822866

Epoch: 6| Step: 6
Training loss: 2.7808627598384636
Validation loss: 2.974684502464227

Epoch: 6| Step: 7
Training loss: 2.9525659425560002
Validation loss: 2.972119771275088

Epoch: 6| Step: 8
Training loss: 3.250852032995302
Validation loss: 2.9695441271429037

Epoch: 6| Step: 9
Training loss: 2.7233913748200673
Validation loss: 2.9673681154968676

Epoch: 6| Step: 10
Training loss: 3.2112785956392877
Validation loss: 2.964862098017207

Epoch: 6| Step: 11
Training loss: 3.378899193905205
Validation loss: 2.9620852296738818

Epoch: 6| Step: 12
Training loss: 2.8382799127031153
Validation loss: 2.9595882458444436

Epoch: 6| Step: 13
Training loss: 2.899211605374685
Validation loss: 2.9569510512434714

Epoch: 45| Step: 0
Training loss: 2.6719903753701204
Validation loss: 2.9543651284583583

Epoch: 6| Step: 1
Training loss: 2.4602189241083843
Validation loss: 2.951847964218255

Epoch: 6| Step: 2
Training loss: 2.944349703274205
Validation loss: 2.94920690673067

Epoch: 6| Step: 3
Training loss: 2.838446733946261
Validation loss: 2.9466628698465502

Epoch: 6| Step: 4
Training loss: 3.7940927366386115
Validation loss: 2.9444119453635964

Epoch: 6| Step: 5
Training loss: 3.068840159161984
Validation loss: 2.941904404915139

Epoch: 6| Step: 6
Training loss: 2.9194665458109594
Validation loss: 2.939637279128152

Epoch: 6| Step: 7
Training loss: 3.212221654566952
Validation loss: 2.937263249264931

Epoch: 6| Step: 8
Training loss: 3.3409269305279565
Validation loss: 2.935130915779098

Epoch: 6| Step: 9
Training loss: 2.5542790730951763
Validation loss: 2.932531686900535

Epoch: 6| Step: 10
Training loss: 3.1109849605264217
Validation loss: 2.9302817865127455

Epoch: 6| Step: 11
Training loss: 3.1765340027888924
Validation loss: 2.927926160533607

Epoch: 6| Step: 12
Training loss: 3.1860017434191437
Validation loss: 2.925710109360196

Epoch: 6| Step: 13
Training loss: 3.5583617954470794
Validation loss: 2.923185330091142

Epoch: 46| Step: 0
Training loss: 3.007289613133518
Validation loss: 2.920669783086913

Epoch: 6| Step: 1
Training loss: 2.3664094256798185
Validation loss: 2.918066265718597

Epoch: 6| Step: 2
Training loss: 3.4376287262829335
Validation loss: 2.9157389436939725

Epoch: 6| Step: 3
Training loss: 3.142252486138806
Validation loss: 2.9132277287635513

Epoch: 6| Step: 4
Training loss: 3.5277027779630807
Validation loss: 2.9105632454713772

Epoch: 6| Step: 5
Training loss: 3.2758218098155285
Validation loss: 2.908143018345202

Epoch: 6| Step: 6
Training loss: 3.298801528163948
Validation loss: 2.9055474365279785

Epoch: 6| Step: 7
Training loss: 2.7938295118380148
Validation loss: 2.9030242163304796

Epoch: 6| Step: 8
Training loss: 2.611232986942599
Validation loss: 2.9006836611490203

Epoch: 6| Step: 9
Training loss: 3.035813818830552
Validation loss: 2.898398578173395

Epoch: 6| Step: 10
Training loss: 2.6605502157564183
Validation loss: 2.8962619564911036

Epoch: 6| Step: 11
Training loss: 2.924504529934168
Validation loss: 2.894043023671686

Epoch: 6| Step: 12
Training loss: 3.4220643709639647
Validation loss: 2.891803260750483

Epoch: 6| Step: 13
Training loss: 2.9079483156294352
Validation loss: 2.889400545887889

Epoch: 47| Step: 0
Training loss: 3.6312940479962093
Validation loss: 2.8868127927143177

Epoch: 6| Step: 1
Training loss: 3.002117998786473
Validation loss: 2.8845928866169306

Epoch: 6| Step: 2
Training loss: 3.3521811885708535
Validation loss: 2.882071147314052

Epoch: 6| Step: 3
Training loss: 2.6059383215115552
Validation loss: 2.8790615252128067

Epoch: 6| Step: 4
Training loss: 3.0650995860015597
Validation loss: 2.8770421004235334

Epoch: 6| Step: 5
Training loss: 2.9736733820611017
Validation loss: 2.874304493797442

Epoch: 6| Step: 6
Training loss: 3.1739702492216804
Validation loss: 2.8717585963809102

Epoch: 6| Step: 7
Training loss: 2.6102986785292583
Validation loss: 2.869283299959421

Epoch: 6| Step: 8
Training loss: 2.758539120314973
Validation loss: 2.866930653001617

Epoch: 6| Step: 9
Training loss: 2.9596968897711955
Validation loss: 2.8645178538843794

Epoch: 6| Step: 10
Training loss: 2.663626358263172
Validation loss: 2.862340337973139

Epoch: 6| Step: 11
Training loss: 3.0397904414176935
Validation loss: 2.860207372252117

Epoch: 6| Step: 12
Training loss: 2.9659966801671738
Validation loss: 2.85841039288654

Epoch: 6| Step: 13
Training loss: 3.2498934801692023
Validation loss: 2.8562828952444854

Epoch: 48| Step: 0
Training loss: 2.9938708318802596
Validation loss: 2.8544500354147666

Epoch: 6| Step: 1
Training loss: 3.0938736091349557
Validation loss: 2.8522241251607716

Epoch: 6| Step: 2
Training loss: 3.0337356915350666
Validation loss: 2.8493646103042742

Epoch: 6| Step: 3
Training loss: 3.1463588924000954
Validation loss: 2.8497001244795603

Epoch: 6| Step: 4
Training loss: 2.397435280221671
Validation loss: 2.8472007383657685

Epoch: 6| Step: 5
Training loss: 3.1753725208803933
Validation loss: 2.8449005342648865

Epoch: 6| Step: 6
Training loss: 2.911146080091789
Validation loss: 2.843358973633097

Epoch: 6| Step: 7
Training loss: 2.850348227124037
Validation loss: 2.8412665817284837

Epoch: 6| Step: 8
Training loss: 3.4700875667549465
Validation loss: 2.8390997008575636

Epoch: 6| Step: 9
Training loss: 2.9755920269875333
Validation loss: 2.8374077354812752

Epoch: 6| Step: 10
Training loss: 2.8648292759596528
Validation loss: 2.835691190870126

Epoch: 6| Step: 11
Training loss: 2.664866485543451
Validation loss: 2.8340697920844216

Epoch: 6| Step: 12
Training loss: 3.2103297639967634
Validation loss: 2.83188890121327

Epoch: 6| Step: 13
Training loss: 2.8531148787086016
Validation loss: 2.8296738909136607

Epoch: 49| Step: 0
Training loss: 2.6782178936118775
Validation loss: 2.827675265527749

Epoch: 6| Step: 1
Training loss: 2.710981648989839
Validation loss: 2.8256137721280137

Epoch: 6| Step: 2
Training loss: 2.6630940844610897
Validation loss: 2.823598115508227

Epoch: 6| Step: 3
Training loss: 3.1063418522538635
Validation loss: 2.82189829194689

Epoch: 6| Step: 4
Training loss: 2.6824924035866893
Validation loss: 2.8212628652188876

Epoch: 6| Step: 5
Training loss: 3.1822085871780263
Validation loss: 2.8179544610476532

Epoch: 6| Step: 6
Training loss: 3.3780049262996186
Validation loss: 2.815868747899037

Epoch: 6| Step: 7
Training loss: 2.886161698832316
Validation loss: 2.8137274006552158

Epoch: 6| Step: 8
Training loss: 2.34209566858809
Validation loss: 2.8117784068937

Epoch: 6| Step: 9
Training loss: 3.4580960632801303
Validation loss: 2.810068845799247

Epoch: 6| Step: 10
Training loss: 3.33302970139128
Validation loss: 2.8087015003090916

Epoch: 6| Step: 11
Training loss: 3.2533254482872054
Validation loss: 2.8063782082817528

Epoch: 6| Step: 12
Training loss: 2.731135427485536
Validation loss: 2.8042781747202543

Epoch: 6| Step: 13
Training loss: 2.726928686347482
Validation loss: 2.802257395352239

Epoch: 50| Step: 0
Training loss: 2.5339531299257776
Validation loss: 2.80017533037197

Epoch: 6| Step: 1
Training loss: 3.0043457662145334
Validation loss: 2.79844307585643

Epoch: 6| Step: 2
Training loss: 3.0896216697312235
Validation loss: 2.796245852271073

Epoch: 6| Step: 3
Training loss: 2.8656693682881014
Validation loss: 2.794231294824471

Epoch: 6| Step: 4
Training loss: 3.1219285748441177
Validation loss: 2.792430151734922

Epoch: 6| Step: 5
Training loss: 2.692408846956554
Validation loss: 2.789860174123076

Epoch: 6| Step: 6
Training loss: 3.0045028907532165
Validation loss: 2.787334016952972

Epoch: 6| Step: 7
Training loss: 2.983194167515932
Validation loss: 2.7854560309067793

Epoch: 6| Step: 8
Training loss: 3.2653989576747287
Validation loss: 2.7842778358389015

Epoch: 6| Step: 9
Training loss: 3.0465406968043536
Validation loss: 2.839615593603586

Epoch: 6| Step: 10
Training loss: 2.5576374159483084
Validation loss: 2.8301564221798126

Epoch: 6| Step: 11
Training loss: 3.036163752003421
Validation loss: 2.8043736642633563

Epoch: 6| Step: 12
Training loss: 3.262597976324197
Validation loss: 2.78077233602469

Epoch: 6| Step: 13
Training loss: 2.568705047436848
Validation loss: 2.7750715572994373

Epoch: 51| Step: 0
Training loss: 3.3720573029541976
Validation loss: 2.774957446324785

Epoch: 6| Step: 1
Training loss: 3.1570220607292487
Validation loss: 2.7763678744942872

Epoch: 6| Step: 2
Training loss: 2.672496968652132
Validation loss: 2.780990002655894

Epoch: 6| Step: 3
Training loss: 3.5877131966965377
Validation loss: 2.776816617191833

Epoch: 6| Step: 4
Training loss: 2.610103299957723
Validation loss: 2.7717111148431948

Epoch: 6| Step: 5
Training loss: 3.0733087494281346
Validation loss: 2.7685638876105587

Epoch: 6| Step: 6
Training loss: 2.668648450290711
Validation loss: 2.765048453657772

Epoch: 6| Step: 7
Training loss: 2.6453753297738256
Validation loss: 2.763991007896514

Epoch: 6| Step: 8
Training loss: 2.888662961129756
Validation loss: 2.761969670502328

Epoch: 6| Step: 9
Training loss: 2.456868419497694
Validation loss: 2.7595387820249817

Epoch: 6| Step: 10
Training loss: 2.728652284404257
Validation loss: 2.75824871701763

Epoch: 6| Step: 11
Training loss: 2.7929947004913305
Validation loss: 2.755791879355031

Epoch: 6| Step: 12
Training loss: 2.893834327474219
Validation loss: 2.7541539146216616

Epoch: 6| Step: 13
Training loss: 2.9547290784955442
Validation loss: 2.7522522055605845

Epoch: 52| Step: 0
Training loss: 2.5554569497181503
Validation loss: 2.751192383475565

Epoch: 6| Step: 1
Training loss: 3.178477964052724
Validation loss: 2.7487605075886883

Epoch: 6| Step: 2
Training loss: 2.9036814506410433
Validation loss: 2.7503927268300283

Epoch: 6| Step: 3
Training loss: 2.586443433796778
Validation loss: 2.7447914446855393

Epoch: 6| Step: 4
Training loss: 2.8344450246957447
Validation loss: 2.7432197446548447

Epoch: 6| Step: 5
Training loss: 3.2712185059876413
Validation loss: 2.742293961678155

Epoch: 6| Step: 6
Training loss: 2.907421081206646
Validation loss: 2.74154696903767

Epoch: 6| Step: 7
Training loss: 2.5483509303953844
Validation loss: 2.7394429933600044

Epoch: 6| Step: 8
Training loss: 2.8404253294614334
Validation loss: 2.7394119083355983

Epoch: 6| Step: 9
Training loss: 2.944126851769727
Validation loss: 2.737890936750388

Epoch: 6| Step: 10
Training loss: 2.888137984701693
Validation loss: 2.7354584935969046

Epoch: 6| Step: 11
Training loss: 3.1347205993651146
Validation loss: 2.7342903051429386

Epoch: 6| Step: 12
Training loss: 2.8859251012778464
Validation loss: 2.7310281816227655

Epoch: 6| Step: 13
Training loss: 2.780718720516445
Validation loss: 2.728941468904264

Epoch: 53| Step: 0
Training loss: 3.2577113586387014
Validation loss: 2.726732381722082

Epoch: 6| Step: 1
Training loss: 2.9754369014202764
Validation loss: 2.725807821476488

Epoch: 6| Step: 2
Training loss: 2.569726477142632
Validation loss: 2.7231336746970696

Epoch: 6| Step: 3
Training loss: 2.8700457470268406
Validation loss: 2.7218039449708735

Epoch: 6| Step: 4
Training loss: 2.886361271632652
Validation loss: 2.7197960196939555

Epoch: 6| Step: 5
Training loss: 3.2057600394321346
Validation loss: 2.7194242116452303

Epoch: 6| Step: 6
Training loss: 2.498638545303847
Validation loss: 2.7185729104314764

Epoch: 6| Step: 7
Training loss: 2.860016964415275
Validation loss: 2.7163852916483537

Epoch: 6| Step: 8
Training loss: 2.6103004139442643
Validation loss: 2.7152708454049006

Epoch: 6| Step: 9
Training loss: 2.602203106980554
Validation loss: 2.7137477794036613

Epoch: 6| Step: 10
Training loss: 3.1143838229543395
Validation loss: 2.7124595949647254

Epoch: 6| Step: 11
Training loss: 2.8043323175061254
Validation loss: 2.710751251360201

Epoch: 6| Step: 12
Training loss: 2.4843109890350843
Validation loss: 2.7099541924653296

Epoch: 6| Step: 13
Training loss: 3.1205299450672674
Validation loss: 2.7068600437617523

Epoch: 54| Step: 0
Training loss: 2.896568003892171
Validation loss: 2.706241846696349

Epoch: 6| Step: 1
Training loss: 2.9604917004441065
Validation loss: 2.7040912319843375

Epoch: 6| Step: 2
Training loss: 2.8657241121913364
Validation loss: 2.7021515109466696

Epoch: 6| Step: 3
Training loss: 2.8887270083269714
Validation loss: 2.700444871845125

Epoch: 6| Step: 4
Training loss: 2.800586730927123
Validation loss: 2.6983713088525527

Epoch: 6| Step: 5
Training loss: 2.720174657319048
Validation loss: 2.696754858376898

Epoch: 6| Step: 6
Training loss: 2.690054898889483
Validation loss: 2.696864307039058

Epoch: 6| Step: 7
Training loss: 2.886528617987942
Validation loss: 2.7011113099107242

Epoch: 6| Step: 8
Training loss: 2.8087574960144273
Validation loss: 2.694538834700247

Epoch: 6| Step: 9
Training loss: 2.808492390762732
Validation loss: 2.691329024802876

Epoch: 6| Step: 10
Training loss: 2.685862907541163
Validation loss: 2.690876635969647

Epoch: 6| Step: 11
Training loss: 3.4152652533578496
Validation loss: 2.6920658183702755

Epoch: 6| Step: 12
Training loss: 2.9334573726726623
Validation loss: 2.6920658183702755

Epoch: 6| Step: 13
Training loss: 2.2852191622950433
Validation loss: 2.6999380107521724

Epoch: 55| Step: 0
Training loss: 3.420783718057536
Validation loss: 2.724605262233679

Epoch: 6| Step: 1
Training loss: 2.785920839372198
Validation loss: 2.6927772724665413

Epoch: 6| Step: 2
Training loss: 3.573863594462062
Validation loss: 2.6863404219390628

Epoch: 6| Step: 3
Training loss: 2.2989994526481228
Validation loss: 2.6865529898013363

Epoch: 6| Step: 4
Training loss: 2.6813317417587093
Validation loss: 2.684253432008375

Epoch: 6| Step: 5
Training loss: 2.482942083973064
Validation loss: 2.682794754600601

Epoch: 6| Step: 6
Training loss: 2.2484094507987558
Validation loss: 2.6827489864271734

Epoch: 6| Step: 7
Training loss: 3.0802979520872347
Validation loss: 2.6812227705704377

Epoch: 6| Step: 8
Training loss: 3.360499703850979
Validation loss: 2.681641632620744

Epoch: 6| Step: 9
Training loss: 2.7084005396402837
Validation loss: 2.6789481252366087

Epoch: 6| Step: 10
Training loss: 2.5839773626369325
Validation loss: 2.6776180005540127

Epoch: 6| Step: 11
Training loss: 2.969317251521896
Validation loss: 2.6766166329685754

Epoch: 6| Step: 12
Training loss: 2.3423485189698114
Validation loss: 2.6744997543141817

Epoch: 6| Step: 13
Training loss: 2.615985013370574
Validation loss: 2.674307075072349

Epoch: 56| Step: 0
Training loss: 2.7445631903297274
Validation loss: 2.67169037119661

Epoch: 6| Step: 1
Training loss: 2.7030719024206076
Validation loss: 2.6692854172222913

Epoch: 6| Step: 2
Training loss: 2.6157361005843827
Validation loss: 2.667494694979492

Epoch: 6| Step: 3
Training loss: 3.108632061250789
Validation loss: 2.666683991693802

Epoch: 6| Step: 4
Training loss: 3.3457531499379662
Validation loss: 2.6652442198043236

Epoch: 6| Step: 5
Training loss: 3.178114593398799
Validation loss: 2.662897953625664

Epoch: 6| Step: 6
Training loss: 2.5310849736424945
Validation loss: 2.6617581123387746

Epoch: 6| Step: 7
Training loss: 2.9196961790909413
Validation loss: 2.660427772381295

Epoch: 6| Step: 8
Training loss: 2.290702258546665
Validation loss: 2.6602058574067398

Epoch: 6| Step: 9
Training loss: 2.4808943255735594
Validation loss: 2.66234031043144

Epoch: 6| Step: 10
Training loss: 2.2232195470575875
Validation loss: 2.6621543337523295

Epoch: 6| Step: 11
Training loss: 3.518986565614397
Validation loss: 2.6600121129030243

Epoch: 6| Step: 12
Training loss: 2.443275749062273
Validation loss: 2.6560506110061066

Epoch: 6| Step: 13
Training loss: 2.8303220866208267
Validation loss: 2.655640476080262

Epoch: 57| Step: 0
Training loss: 3.351698794850362
Validation loss: 2.6560277958099134

Epoch: 6| Step: 1
Training loss: 2.986357664432469
Validation loss: 2.6549688204019875

Epoch: 6| Step: 2
Training loss: 2.7523862715811314
Validation loss: 2.6545223826129805

Epoch: 6| Step: 3
Training loss: 2.4654824567428655
Validation loss: 2.655237550950104

Epoch: 6| Step: 4
Training loss: 3.0201366454277636
Validation loss: 2.6555680540243833

Epoch: 6| Step: 5
Training loss: 3.0017472583119322
Validation loss: 2.656751248805308

Epoch: 6| Step: 6
Training loss: 3.1364770323467184
Validation loss: 2.654737782577478

Epoch: 6| Step: 7
Training loss: 2.5718318078086386
Validation loss: 2.6543139713757573

Epoch: 6| Step: 8
Training loss: 2.5182040245171238
Validation loss: 2.651820734712378

Epoch: 6| Step: 9
Training loss: 2.7708315359315323
Validation loss: 2.6497403731411344

Epoch: 6| Step: 10
Training loss: 2.8878066061153973
Validation loss: 2.6480014108162355

Epoch: 6| Step: 11
Training loss: 2.509508931729508
Validation loss: 2.6467493278877536

Epoch: 6| Step: 12
Training loss: 2.7784262048691017
Validation loss: 2.6450940899137527

Epoch: 6| Step: 13
Training loss: 2.0742509340134956
Validation loss: 2.6442781568607012

Epoch: 58| Step: 0
Training loss: 3.060823098226236
Validation loss: 2.642625190370246

Epoch: 6| Step: 1
Training loss: 2.8728155046835493
Validation loss: 2.6397456674454447

Epoch: 6| Step: 2
Training loss: 2.6716712740142308
Validation loss: 2.640461436967583

Epoch: 6| Step: 3
Training loss: 2.5303054742761506
Validation loss: 2.638095614900672

Epoch: 6| Step: 4
Training loss: 2.855728408968292
Validation loss: 2.6360158176391333

Epoch: 6| Step: 5
Training loss: 2.8714851787276965
Validation loss: 2.635397708709038

Epoch: 6| Step: 6
Training loss: 2.654081738688707
Validation loss: 2.6343706540471223

Epoch: 6| Step: 7
Training loss: 3.0116620683098376
Validation loss: 2.632786827075428

Epoch: 6| Step: 8
Training loss: 2.813293429885681
Validation loss: 2.63235567772621

Epoch: 6| Step: 9
Training loss: 2.8524023204130162
Validation loss: 2.6312634960804013

Epoch: 6| Step: 10
Training loss: 2.776626773362943
Validation loss: 2.629540467529172

Epoch: 6| Step: 11
Training loss: 2.1752922563305512
Validation loss: 2.629734190452506

Epoch: 6| Step: 12
Training loss: 2.7472766916677784
Validation loss: 2.627790088458949

Epoch: 6| Step: 13
Training loss: 2.820241911366674
Validation loss: 2.6261643900195546

Epoch: 59| Step: 0
Training loss: 3.5588633396442284
Validation loss: 2.6251751220659307

Epoch: 6| Step: 1
Training loss: 2.3337414475433933
Validation loss: 2.6236860983356007

Epoch: 6| Step: 2
Training loss: 2.7531476646642195
Validation loss: 2.62312133107729

Epoch: 6| Step: 3
Training loss: 2.466737530523795
Validation loss: 2.6221908191194223

Epoch: 6| Step: 4
Training loss: 2.7688061366192063
Validation loss: 2.6208611360014245

Epoch: 6| Step: 5
Training loss: 2.6592291786387885
Validation loss: 2.621801289373644

Epoch: 6| Step: 6
Training loss: 2.6347458982188687
Validation loss: 2.622167754774992

Epoch: 6| Step: 7
Training loss: 2.7889612003170248
Validation loss: 2.62196657720292

Epoch: 6| Step: 8
Training loss: 2.5558171472409006
Validation loss: 2.6204827056422775

Epoch: 6| Step: 9
Training loss: 2.2728423817701495
Validation loss: 2.619731111123665

Epoch: 6| Step: 10
Training loss: 2.9431067993093816
Validation loss: 2.6184136853757196

Epoch: 6| Step: 11
Training loss: 3.1764317745962294
Validation loss: 2.618554087786007

Epoch: 6| Step: 12
Training loss: 2.8501392732019166
Validation loss: 2.6174422866011287

Epoch: 6| Step: 13
Training loss: 2.6573386261570358
Validation loss: 2.6156575300046487

Epoch: 60| Step: 0
Training loss: 2.877091849220337
Validation loss: 2.6142544837220822

Epoch: 6| Step: 1
Training loss: 2.724503753693127
Validation loss: 2.612533515581342

Epoch: 6| Step: 2
Training loss: 1.918433667179249
Validation loss: 2.611784334735243

Epoch: 6| Step: 3
Training loss: 2.1839057822253247
Validation loss: 2.61309470141416

Epoch: 6| Step: 4
Training loss: 2.891984444635748
Validation loss: 2.6136486971668447

Epoch: 6| Step: 5
Training loss: 3.2032458771018377
Validation loss: 2.616811013543006

Epoch: 6| Step: 6
Training loss: 2.337731020521887
Validation loss: 2.6162990143727898

Epoch: 6| Step: 7
Training loss: 2.653656265393018
Validation loss: 2.6142948999672844

Epoch: 6| Step: 8
Training loss: 2.940441849910499
Validation loss: 2.6076267195303493

Epoch: 6| Step: 9
Training loss: 3.1670242576139875
Validation loss: 2.605329243872813

Epoch: 6| Step: 10
Training loss: 2.6854469086507984
Validation loss: 2.603999862415019

Epoch: 6| Step: 11
Training loss: 2.5815874373327428
Validation loss: 2.6051698710579068

Epoch: 6| Step: 12
Training loss: 2.890240617918822
Validation loss: 2.6047517704104437

Epoch: 6| Step: 13
Training loss: 3.104349647266382
Validation loss: 2.6046869495729177

Epoch: 61| Step: 0
Training loss: 2.4678422248772725
Validation loss: 2.6037395940906314

Epoch: 6| Step: 1
Training loss: 2.9655686850471734
Validation loss: 2.6041994830289097

Epoch: 6| Step: 2
Training loss: 2.17510460788368
Validation loss: 2.605427815555658

Epoch: 6| Step: 3
Training loss: 2.8701555652525177
Validation loss: 2.6037484608860995

Epoch: 6| Step: 4
Training loss: 2.5241036023128567
Validation loss: 2.6036402259232623

Epoch: 6| Step: 5
Training loss: 2.279952006587803
Validation loss: 2.6030575768332165

Epoch: 6| Step: 6
Training loss: 3.0340255143180985
Validation loss: 2.602805969789462

Epoch: 6| Step: 7
Training loss: 2.616302249421337
Validation loss: 2.6019713239993085

Epoch: 6| Step: 8
Training loss: 2.585889003333483
Validation loss: 2.6016115751019537

Epoch: 6| Step: 9
Training loss: 2.850741668033308
Validation loss: 2.600050783884046

Epoch: 6| Step: 10
Training loss: 3.1037159705629853
Validation loss: 2.6019153069355143

Epoch: 6| Step: 11
Training loss: 2.7077895474437907
Validation loss: 2.598470230492804

Epoch: 6| Step: 12
Training loss: 3.0110510099480674
Validation loss: 2.596706880405793

Epoch: 6| Step: 13
Training loss: 2.9624161462947987
Validation loss: 2.5964119667856056

Epoch: 62| Step: 0
Training loss: 3.097467828049354
Validation loss: 2.595035693928282

Epoch: 6| Step: 1
Training loss: 3.028802571897226
Validation loss: 2.5913536154602066

Epoch: 6| Step: 2
Training loss: 2.633460262313832
Validation loss: 2.5888047164618615

Epoch: 6| Step: 3
Training loss: 2.562436172806939
Validation loss: 2.5872790649248056

Epoch: 6| Step: 4
Training loss: 3.1008040031584416
Validation loss: 2.596588619032098

Epoch: 6| Step: 5
Training loss: 2.7111993932507765
Validation loss: 2.600489290976825

Epoch: 6| Step: 6
Training loss: 2.727769120153641
Validation loss: 2.589036741955446

Epoch: 6| Step: 7
Training loss: 2.5532125245573742
Validation loss: 2.5875419564154956

Epoch: 6| Step: 8
Training loss: 2.7826171258093804
Validation loss: 2.5833552010953995

Epoch: 6| Step: 9
Training loss: 2.7199834897437816
Validation loss: 2.581977693634243

Epoch: 6| Step: 10
Training loss: 2.497311099739445
Validation loss: 2.5834384917318878

Epoch: 6| Step: 11
Training loss: 2.5446764109605415
Validation loss: 2.5848249671799497

Epoch: 6| Step: 12
Training loss: 2.8916828591134314
Validation loss: 2.584238406549673

Epoch: 6| Step: 13
Training loss: 2.235745843101373
Validation loss: 2.5862690078285144

Epoch: 63| Step: 0
Training loss: 2.78624799178108
Validation loss: 2.5868589021670796

Epoch: 6| Step: 1
Training loss: 2.744758118358683
Validation loss: 2.586539775556071

Epoch: 6| Step: 2
Training loss: 2.465432751102232
Validation loss: 2.5878710936762968

Epoch: 6| Step: 3
Training loss: 2.6698983002342525
Validation loss: 2.587432459934146

Epoch: 6| Step: 4
Training loss: 3.11824342821992
Validation loss: 2.58547632997471

Epoch: 6| Step: 5
Training loss: 2.7498515695915584
Validation loss: 2.5840545590942567

Epoch: 6| Step: 6
Training loss: 2.614509875315555
Validation loss: 2.5838639627025035

Epoch: 6| Step: 7
Training loss: 2.445780066495553
Validation loss: 2.5834114206469043

Epoch: 6| Step: 8
Training loss: 3.183987645781813
Validation loss: 2.5823233742643965

Epoch: 6| Step: 9
Training loss: 3.0451476849600865
Validation loss: 2.5803536386634214

Epoch: 6| Step: 10
Training loss: 2.3144095501238207
Validation loss: 2.5798156127294796

Epoch: 6| Step: 11
Training loss: 2.601094980015581
Validation loss: 2.57834206640256

Epoch: 6| Step: 12
Training loss: 2.519722959336816
Validation loss: 2.5783978789826887

Epoch: 6| Step: 13
Training loss: 2.691323421626643
Validation loss: 2.577433499163789

Epoch: 64| Step: 0
Training loss: 2.6248953662181944
Validation loss: 2.5758278062412083

Epoch: 6| Step: 1
Training loss: 2.5738588119115597
Validation loss: 2.5733735197599157

Epoch: 6| Step: 2
Training loss: 2.5383651010383503
Validation loss: 2.5731199753058767

Epoch: 6| Step: 3
Training loss: 2.6481085378870284
Validation loss: 2.5696171261494403

Epoch: 6| Step: 4
Training loss: 2.37347965768085
Validation loss: 2.570775524666216

Epoch: 6| Step: 5
Training loss: 2.7744754192331045
Validation loss: 2.5692401569936743

Epoch: 6| Step: 6
Training loss: 3.141650891116846
Validation loss: 2.5678382567265676

Epoch: 6| Step: 7
Training loss: 2.791600117435827
Validation loss: 2.5656484629912994

Epoch: 6| Step: 8
Training loss: 2.537652853886035
Validation loss: 2.5667615670664055

Epoch: 6| Step: 9
Training loss: 2.9692886666939655
Validation loss: 2.5626933172234807

Epoch: 6| Step: 10
Training loss: 2.6183633924086647
Validation loss: 2.5645855736019

Epoch: 6| Step: 11
Training loss: 2.450279188792033
Validation loss: 2.563952584771009

Epoch: 6| Step: 12
Training loss: 2.702717568446851
Validation loss: 2.5664865606042686

Epoch: 6| Step: 13
Training loss: 3.04089645318838
Validation loss: 2.5617061563880092

Epoch: 65| Step: 0
Training loss: 2.845510252397025
Validation loss: 2.560456290583808

Epoch: 6| Step: 1
Training loss: 2.6750818828278855
Validation loss: 2.55808544594048

Epoch: 6| Step: 2
Training loss: 2.752418581583893
Validation loss: 2.5604083510890563

Epoch: 6| Step: 3
Training loss: 2.6990803353225075
Validation loss: 2.5617172782562547

Epoch: 6| Step: 4
Training loss: 2.7067092329665137
Validation loss: 2.5626717331568596

Epoch: 6| Step: 5
Training loss: 2.3094586141726317
Validation loss: 2.564656799859004

Epoch: 6| Step: 6
Training loss: 2.8962314981487824
Validation loss: 2.5646932101682895

Epoch: 6| Step: 7
Training loss: 2.78552509021706
Validation loss: 2.5638667392795704

Epoch: 6| Step: 8
Training loss: 2.814676756382502
Validation loss: 2.5630453196296914

Epoch: 6| Step: 9
Training loss: 2.3610746817178243
Validation loss: 2.563270422019206

Epoch: 6| Step: 10
Training loss: 2.3289213930576325
Validation loss: 2.561482281680869

Epoch: 6| Step: 11
Training loss: 2.8026633436393213
Validation loss: 2.5593698814381276

Epoch: 6| Step: 12
Training loss: 3.1490835279554017
Validation loss: 2.5572635289111947

Epoch: 6| Step: 13
Training loss: 2.590484125703858
Validation loss: 2.554676145320316

Epoch: 66| Step: 0
Training loss: 3.114522229534045
Validation loss: 2.5557517693930243

Epoch: 6| Step: 1
Training loss: 2.885433669791866
Validation loss: 2.555597887748211

Epoch: 6| Step: 2
Training loss: 2.377143695498413
Validation loss: 2.5522977518327714

Epoch: 6| Step: 3
Training loss: 2.748013559233017
Validation loss: 2.5494369851435943

Epoch: 6| Step: 4
Training loss: 2.5564223065864993
Validation loss: 2.5463178528409474

Epoch: 6| Step: 5
Training loss: 2.1143578344917424
Validation loss: 2.5470993941670343

Epoch: 6| Step: 6
Training loss: 2.404877010856774
Validation loss: 2.5461130855294707

Epoch: 6| Step: 7
Training loss: 3.0166559384262377
Validation loss: 2.5458737923195396

Epoch: 6| Step: 8
Training loss: 2.9535786921045633
Validation loss: 2.5455915809721104

Epoch: 6| Step: 9
Training loss: 2.560084437229489
Validation loss: 2.54694840651119

Epoch: 6| Step: 10
Training loss: 2.695478174397553
Validation loss: 2.545169501115469

Epoch: 6| Step: 11
Training loss: 3.3704260455490824
Validation loss: 2.544812746360146

Epoch: 6| Step: 12
Training loss: 2.245855222558787
Validation loss: 2.544223036588785

Epoch: 6| Step: 13
Training loss: 2.199864457029791
Validation loss: 2.542938997921832

Epoch: 67| Step: 0
Training loss: 2.915937132650885
Validation loss: 2.5406854851448775

Epoch: 6| Step: 1
Training loss: 2.7153243483386857
Validation loss: 2.5421160055813194

Epoch: 6| Step: 2
Training loss: 2.6297476387060468
Validation loss: 2.5387457703843626

Epoch: 6| Step: 3
Training loss: 2.7039894970740668
Validation loss: 2.536591870332647

Epoch: 6| Step: 4
Training loss: 2.6492726857379587
Validation loss: 2.5391691449583815

Epoch: 6| Step: 5
Training loss: 2.604758650569389
Validation loss: 2.538688765187545

Epoch: 6| Step: 6
Training loss: 3.06153916837067
Validation loss: 2.5422777212647687

Epoch: 6| Step: 7
Training loss: 2.597068134934364
Validation loss: 2.5380887242774395

Epoch: 6| Step: 8
Training loss: 2.374252703700997
Validation loss: 2.5392187138944493

Epoch: 6| Step: 9
Training loss: 2.2025844911959527
Validation loss: 2.5384745538225237

Epoch: 6| Step: 10
Training loss: 2.985108929408535
Validation loss: 2.5380146544504107

Epoch: 6| Step: 11
Training loss: 2.5125218556530564
Validation loss: 2.538470092524126

Epoch: 6| Step: 12
Training loss: 2.316962807295496
Validation loss: 2.536949648000461

Epoch: 6| Step: 13
Training loss: 3.0371781418058896
Validation loss: 2.5329778449034266

Epoch: 68| Step: 0
Training loss: 2.5166985726597138
Validation loss: 2.533027652652287

Epoch: 6| Step: 1
Training loss: 2.911580437480802
Validation loss: 2.5325283856823613

Epoch: 6| Step: 2
Training loss: 2.7394792273482844
Validation loss: 2.535809777992737

Epoch: 6| Step: 3
Training loss: 2.6541747120526202
Validation loss: 2.542776542935349

Epoch: 6| Step: 4
Training loss: 3.090419016454828
Validation loss: 2.540210788958909

Epoch: 6| Step: 5
Training loss: 2.800612185175836
Validation loss: 2.532396676885867

Epoch: 6| Step: 6
Training loss: 2.4234096464011237
Validation loss: 2.5321265378773696

Epoch: 6| Step: 7
Training loss: 2.6550370981386826
Validation loss: 2.5278506903094504

Epoch: 6| Step: 8
Training loss: 2.187156650300033
Validation loss: 2.5299638376930984

Epoch: 6| Step: 9
Training loss: 2.8711608463673524
Validation loss: 2.531534547863764

Epoch: 6| Step: 10
Training loss: 2.0558882421184306
Validation loss: 2.530498455862938

Epoch: 6| Step: 11
Training loss: 2.402969998245813
Validation loss: 2.5312946456927903

Epoch: 6| Step: 12
Training loss: 3.0787396277230883
Validation loss: 2.533160865919441

Epoch: 6| Step: 13
Training loss: 2.7672280875642934
Validation loss: 2.531133083892939

Epoch: 69| Step: 0
Training loss: 2.3736684981863467
Validation loss: 2.531147346455836

Epoch: 6| Step: 1
Training loss: 2.813335548900196
Validation loss: 2.5315426629816566

Epoch: 6| Step: 2
Training loss: 2.7689917809725006
Validation loss: 2.5311243316475185

Epoch: 6| Step: 3
Training loss: 3.408468941102579
Validation loss: 2.5311443793470048

Epoch: 6| Step: 4
Training loss: 2.5316455673266063
Validation loss: 2.5316498366050335

Epoch: 6| Step: 5
Training loss: 2.111380972540497
Validation loss: 2.5305053337697716

Epoch: 6| Step: 6
Training loss: 2.6085155236555715
Validation loss: 2.5290295158877134

Epoch: 6| Step: 7
Training loss: 2.5985529907766023
Validation loss: 2.528826381367656

Epoch: 6| Step: 8
Training loss: 2.7013642855594093
Validation loss: 2.5274921277379847

Epoch: 6| Step: 9
Training loss: 2.7511243255765545
Validation loss: 2.5283013425733967

Epoch: 6| Step: 10
Training loss: 2.6979860176589416
Validation loss: 2.526079619342117

Epoch: 6| Step: 11
Training loss: 2.399558137908342
Validation loss: 2.5239952108848587

Epoch: 6| Step: 12
Training loss: 2.288108027795627
Validation loss: 2.5276165696557786

Epoch: 6| Step: 13
Training loss: 3.0019432767608465
Validation loss: 2.5259403064225623

Epoch: 70| Step: 0
Training loss: 2.912532455852893
Validation loss: 2.5240262331916723

Epoch: 6| Step: 1
Training loss: 2.725401098147293
Validation loss: 2.5280168080294247

Epoch: 6| Step: 2
Training loss: 2.493985857601494
Validation loss: 2.520211061539936

Epoch: 6| Step: 3
Training loss: 2.632780623879734
Validation loss: 2.5212813418017475

Epoch: 6| Step: 4
Training loss: 2.4343879591629953
Validation loss: 2.520187584212762

Epoch: 6| Step: 5
Training loss: 2.450425332965476
Validation loss: 2.5188857560217053

Epoch: 6| Step: 6
Training loss: 2.6515099811916394
Validation loss: 2.5162586180300437

Epoch: 6| Step: 7
Training loss: 2.4508339455180184
Validation loss: 2.5180449604144197

Epoch: 6| Step: 8
Training loss: 2.881246994579676
Validation loss: 2.5170884387372814

Epoch: 6| Step: 9
Training loss: 2.6560974974891667
Validation loss: 2.518999525635763

Epoch: 6| Step: 10
Training loss: 2.9472303546390233
Validation loss: 2.522654818474096

Epoch: 6| Step: 11
Training loss: 2.5617250340632745
Validation loss: 2.5236299990521767

Epoch: 6| Step: 12
Training loss: 3.0168761192937703
Validation loss: 2.524586104157329

Epoch: 6| Step: 13
Training loss: 2.2757513587106972
Validation loss: 2.5225865648713603

Epoch: 71| Step: 0
Training loss: 1.9296782335066602
Validation loss: 2.5206419869514285

Epoch: 6| Step: 1
Training loss: 2.519009510993039
Validation loss: 2.5207293675529243

Epoch: 6| Step: 2
Training loss: 2.384782020956126
Validation loss: 2.518595613933743

Epoch: 6| Step: 3
Training loss: 2.6976303086081654
Validation loss: 2.5171028992801174

Epoch: 6| Step: 4
Training loss: 2.852411514768681
Validation loss: 2.5165335710543526

Epoch: 6| Step: 5
Training loss: 2.753460007894737
Validation loss: 2.515016991726638

Epoch: 6| Step: 6
Training loss: 2.268845367529002
Validation loss: 2.5150727007339193

Epoch: 6| Step: 7
Training loss: 2.5565781436334767
Validation loss: 2.514380627046718

Epoch: 6| Step: 8
Training loss: 2.8186832699203985
Validation loss: 2.5168369130367063

Epoch: 6| Step: 9
Training loss: 2.828052751661542
Validation loss: 2.511858614383814

Epoch: 6| Step: 10
Training loss: 2.789190893129739
Validation loss: 2.510451199200393

Epoch: 6| Step: 11
Training loss: 3.2890236460368376
Validation loss: 2.506381076927074

Epoch: 6| Step: 12
Training loss: 2.3830134072576934
Validation loss: 2.5134244973456874

Epoch: 6| Step: 13
Training loss: 2.66720565673512
Validation loss: 2.508716139198209

Epoch: 72| Step: 0
Training loss: 2.3253854083491796
Validation loss: 2.5106864773655313

Epoch: 6| Step: 1
Training loss: 2.779047747750539
Validation loss: 2.5150169285279707

Epoch: 6| Step: 2
Training loss: 2.7215512631725627
Validation loss: 2.5150120148267483

Epoch: 6| Step: 3
Training loss: 3.019320422630589
Validation loss: 2.51378940563403

Epoch: 6| Step: 4
Training loss: 2.3351655532993627
Validation loss: 2.509965156906057

Epoch: 6| Step: 5
Training loss: 2.6387814739740985
Validation loss: 2.5106095098818964

Epoch: 6| Step: 6
Training loss: 2.7909145670614834
Validation loss: 2.5082576273480233

Epoch: 6| Step: 7
Training loss: 2.3711410090404614
Validation loss: 2.5110151888546093

Epoch: 6| Step: 8
Training loss: 2.7871944037594765
Validation loss: 2.514896445281718

Epoch: 6| Step: 9
Training loss: 2.7582084220270264
Validation loss: 2.5179594593071983

Epoch: 6| Step: 10
Training loss: 2.164734113017073
Validation loss: 2.5205451443299536

Epoch: 6| Step: 11
Training loss: 2.784660562755911
Validation loss: 2.523841424035224

Epoch: 6| Step: 12
Training loss: 2.6026638323163924
Validation loss: 2.531696233151909

Epoch: 6| Step: 13
Training loss: 2.8716178571376174
Validation loss: 2.523566007540573

Epoch: 73| Step: 0
Training loss: 2.7279194512990808
Validation loss: 2.5191491441015272

Epoch: 6| Step: 1
Training loss: 2.482211532505248
Validation loss: 2.5159146791717535

Epoch: 6| Step: 2
Training loss: 2.9483283915746954
Validation loss: 2.5160002023861576

Epoch: 6| Step: 3
Training loss: 2.199626119228468
Validation loss: 2.5177124871464467

Epoch: 6| Step: 4
Training loss: 2.899234466797958
Validation loss: 2.514341259808289

Epoch: 6| Step: 5
Training loss: 2.6108350495122665
Validation loss: 2.514858405473535

Epoch: 6| Step: 6
Training loss: 2.0957490857320398
Validation loss: 2.508963205033513

Epoch: 6| Step: 7
Training loss: 2.976512357835125
Validation loss: 2.5133100405818656

Epoch: 6| Step: 8
Training loss: 2.86494412086411
Validation loss: 2.514432557354606

Epoch: 6| Step: 9
Training loss: 2.673141982189835
Validation loss: 2.5133321829455078

Epoch: 6| Step: 10
Training loss: 3.007795695468479
Validation loss: 2.5081774643113777

Epoch: 6| Step: 11
Training loss: 2.5381072609663615
Validation loss: 2.5134870238410896

Epoch: 6| Step: 12
Training loss: 2.6444021444205523
Validation loss: 2.512124194480776

Epoch: 6| Step: 13
Training loss: 2.232867392525257
Validation loss: 2.5056317950301135

Epoch: 74| Step: 0
Training loss: 2.729585125318473
Validation loss: 2.5039772344992484

Epoch: 6| Step: 1
Training loss: 2.6215099567091102
Validation loss: 2.50401525711453

Epoch: 6| Step: 2
Training loss: 2.842163817321188
Validation loss: 2.504168722328531

Epoch: 6| Step: 3
Training loss: 2.743932793508793
Validation loss: 2.5010428796585447

Epoch: 6| Step: 4
Training loss: 2.680408614308767
Validation loss: 2.5026190549240224

Epoch: 6| Step: 5
Training loss: 2.8359627210267964
Validation loss: 2.502754696471316

Epoch: 6| Step: 6
Training loss: 2.7444599875328746
Validation loss: 2.501346734022562

Epoch: 6| Step: 7
Training loss: 2.418188920111667
Validation loss: 2.502224734966924

Epoch: 6| Step: 8
Training loss: 2.616339064903298
Validation loss: 2.5024379922486872

Epoch: 6| Step: 9
Training loss: 2.588297985332536
Validation loss: 2.5019425156919546

Epoch: 6| Step: 10
Training loss: 2.457696627476125
Validation loss: 2.5038753354866463

Epoch: 6| Step: 11
Training loss: 2.6118475797500493
Validation loss: 2.512952897861624

Epoch: 6| Step: 12
Training loss: 2.1123631540249943
Validation loss: 2.5188512707616804

Epoch: 6| Step: 13
Training loss: 2.763142306539597
Validation loss: 2.526587348018419

Epoch: 75| Step: 0
Training loss: 2.462644826435232
Validation loss: 2.5355282957714422

Epoch: 6| Step: 1
Training loss: 1.9186177136673477
Validation loss: 2.531029397276035

Epoch: 6| Step: 2
Training loss: 3.003416500174917
Validation loss: 2.5111381369892802

Epoch: 6| Step: 3
Training loss: 2.2739941941172916
Validation loss: 2.504767846436803

Epoch: 6| Step: 4
Training loss: 2.6044901735908037
Validation loss: 2.5040301740095834

Epoch: 6| Step: 5
Training loss: 2.224035173885835
Validation loss: 2.4980572304350694

Epoch: 6| Step: 6
Training loss: 2.889776486791967
Validation loss: 2.4990917145302753

Epoch: 6| Step: 7
Training loss: 2.5256230482638116
Validation loss: 2.494291798334968

Epoch: 6| Step: 8
Training loss: 2.8116882000339594
Validation loss: 2.5024373729642293

Epoch: 6| Step: 9
Training loss: 2.925409637197867
Validation loss: 2.493020981596419

Epoch: 6| Step: 10
Training loss: 3.070890648840533
Validation loss: 2.495793602637271

Epoch: 6| Step: 11
Training loss: 3.1662053893237583
Validation loss: 2.4966620413716574

Epoch: 6| Step: 12
Training loss: 2.003742412093485
Validation loss: 2.496114811338302

Epoch: 6| Step: 13
Training loss: 2.5200104013864117
Validation loss: 2.4971102543633705

Testing loss: 2.066542740590832
