Epoch: 1| Step: 0
Training loss: 5.193828169949403
Validation loss: 5.909893277964117

Epoch: 5| Step: 1
Training loss: 5.691307051297482
Validation loss: 5.907739279958399

Epoch: 5| Step: 2
Training loss: 5.776885823742464
Validation loss: 5.905544635829996

Epoch: 5| Step: 3
Training loss: 5.78442262766977
Validation loss: 5.903418492967163

Epoch: 5| Step: 4
Training loss: 5.689743773150208
Validation loss: 5.901166164322791

Epoch: 5| Step: 5
Training loss: 6.288108914507058
Validation loss: 5.898974908258359

Epoch: 5| Step: 6
Training loss: 6.123675456172485
Validation loss: 5.896635798468192

Epoch: 5| Step: 7
Training loss: 5.339245420140766
Validation loss: 5.894366491874719

Epoch: 5| Step: 8
Training loss: 6.681024286009886
Validation loss: 5.89193077691456

Epoch: 5| Step: 9
Training loss: 6.938125169783407
Validation loss: 5.889548455445315

Epoch: 5| Step: 10
Training loss: 6.101196434381391
Validation loss: 5.887064754220885

Epoch: 5| Step: 11
Training loss: 7.444040195756277
Validation loss: 5.884543688910965

Epoch: 2| Step: 0
Training loss: 6.284181129200495
Validation loss: 5.881754029769988

Epoch: 5| Step: 1
Training loss: 6.362876584163248
Validation loss: 5.879085736581701

Epoch: 5| Step: 2
Training loss: 5.560541386764063
Validation loss: 5.876235615541528

Epoch: 5| Step: 3
Training loss: 5.818291188967697
Validation loss: 5.873370465404087

Epoch: 5| Step: 4
Training loss: 5.586050008427715
Validation loss: 5.870299115680582

Epoch: 5| Step: 5
Training loss: 6.0852912295258745
Validation loss: 5.867296674163888

Epoch: 5| Step: 6
Training loss: 5.64807549842754
Validation loss: 5.863929572065425

Epoch: 5| Step: 7
Training loss: 5.711636814870189
Validation loss: 5.8606647343573615

Epoch: 5| Step: 8
Training loss: 6.460016962271232
Validation loss: 5.857029207081782

Epoch: 5| Step: 9
Training loss: 5.860975692815774
Validation loss: 5.853394048983441

Epoch: 5| Step: 10
Training loss: 6.210067745705356
Validation loss: 5.849538346901134

Epoch: 5| Step: 11
Training loss: 6.600736415122469
Validation loss: 5.845629024492674

Epoch: 3| Step: 0
Training loss: 6.402553180204112
Validation loss: 5.84128668234461

Epoch: 5| Step: 1
Training loss: 6.316670163974783
Validation loss: 5.836904749448819

Epoch: 5| Step: 2
Training loss: 4.758111352413662
Validation loss: 5.832244293416567

Epoch: 5| Step: 3
Training loss: 6.7756715673952925
Validation loss: 5.827586901712431

Epoch: 5| Step: 4
Training loss: 5.866680341762441
Validation loss: 5.822460322732837

Epoch: 5| Step: 5
Training loss: 5.0313227867405805
Validation loss: 5.817151597675825

Epoch: 5| Step: 6
Training loss: 5.7384597407782865
Validation loss: 5.811704355563822

Epoch: 5| Step: 7
Training loss: 5.0340293647233985
Validation loss: 5.806292209807161

Epoch: 5| Step: 8
Training loss: 6.544255353912089
Validation loss: 5.800084969018758

Epoch: 5| Step: 9
Training loss: 6.245533377086911
Validation loss: 5.7941656095972975

Epoch: 5| Step: 10
Training loss: 6.072787336364978
Validation loss: 5.787520600976387

Epoch: 5| Step: 11
Training loss: 6.2721771456361335
Validation loss: 5.781079044048225

Epoch: 4| Step: 0
Training loss: 6.241590106054863
Validation loss: 5.773720245251623

Epoch: 5| Step: 1
Training loss: 6.081203593030954
Validation loss: 5.76652171838467

Epoch: 5| Step: 2
Training loss: 6.708150193773005
Validation loss: 5.758994938188825

Epoch: 5| Step: 3
Training loss: 5.4802775060738576
Validation loss: 5.75096272964442

Epoch: 5| Step: 4
Training loss: 5.228769700179446
Validation loss: 5.742987648366285

Epoch: 5| Step: 5
Training loss: 4.95587120580926
Validation loss: 5.734578613214264

Epoch: 5| Step: 6
Training loss: 5.680793581045629
Validation loss: 5.726138215005431

Epoch: 5| Step: 7
Training loss: 6.262264273160651
Validation loss: 5.717566598766486

Epoch: 5| Step: 8
Training loss: 5.678607066574754
Validation loss: 5.708891565171202

Epoch: 5| Step: 9
Training loss: 6.258585716607159
Validation loss: 5.699556824817035

Epoch: 5| Step: 10
Training loss: 5.2130863728937005
Validation loss: 5.690332706380693

Epoch: 5| Step: 11
Training loss: 7.150295929019903
Validation loss: 5.681010410976825

Epoch: 5| Step: 0
Training loss: 5.698578493315892
Validation loss: 5.6711005320536705

Epoch: 5| Step: 1
Training loss: 5.9243732104765074
Validation loss: 5.660964279820422

Epoch: 5| Step: 2
Training loss: 5.827772196300457
Validation loss: 5.650612081439737

Epoch: 5| Step: 3
Training loss: 5.044236760245122
Validation loss: 5.640279799841465

Epoch: 5| Step: 4
Training loss: 5.818672430420797
Validation loss: 5.629713894862204

Epoch: 5| Step: 5
Training loss: 5.494145311664816
Validation loss: 5.619477973599529

Epoch: 5| Step: 6
Training loss: 6.3484410572534955
Validation loss: 5.609243867805988

Epoch: 5| Step: 7
Training loss: 5.214510720580955
Validation loss: 5.5985517298005245

Epoch: 5| Step: 8
Training loss: 6.293722191666781
Validation loss: 5.587560557493114

Epoch: 5| Step: 9
Training loss: 5.877326017893296
Validation loss: 5.5768031701032195

Epoch: 5| Step: 10
Training loss: 5.401717739285543
Validation loss: 5.566309727952897

Epoch: 5| Step: 11
Training loss: 5.718226007521538
Validation loss: 5.555171303441179

Epoch: 6| Step: 0
Training loss: 4.901641430643373
Validation loss: 5.544395458516381

Epoch: 5| Step: 1
Training loss: 4.756535701717572
Validation loss: 5.533500429104652

Epoch: 5| Step: 2
Training loss: 5.593740793572207
Validation loss: 5.522308176605317

Epoch: 5| Step: 3
Training loss: 6.8410806545080565
Validation loss: 5.511411568642674

Epoch: 5| Step: 4
Training loss: 5.848558375429007
Validation loss: 5.499942316850983

Epoch: 5| Step: 5
Training loss: 6.118087916650052
Validation loss: 5.488926548427515

Epoch: 5| Step: 6
Training loss: 6.0248366337705
Validation loss: 5.476833407548722

Epoch: 5| Step: 7
Training loss: 5.596187806234391
Validation loss: 5.465598558929389

Epoch: 5| Step: 8
Training loss: 5.1778817229599685
Validation loss: 5.453804556723614

Epoch: 5| Step: 9
Training loss: 5.46429610763402
Validation loss: 5.44203509193003

Epoch: 5| Step: 10
Training loss: 5.264753592178131
Validation loss: 5.430834576310668

Epoch: 5| Step: 11
Training loss: 4.3238429291292775
Validation loss: 5.419598477999545

Epoch: 7| Step: 0
Training loss: 6.133800801140057
Validation loss: 5.4090114956930675

Epoch: 5| Step: 1
Training loss: 4.802474639682642
Validation loss: 5.39849329402962

Epoch: 5| Step: 2
Training loss: 5.71176204130171
Validation loss: 5.388101512316578

Epoch: 5| Step: 3
Training loss: 6.162966399891484
Validation loss: 5.377608656862122

Epoch: 5| Step: 4
Training loss: 5.003163290741004
Validation loss: 5.367280784362643

Epoch: 5| Step: 5
Training loss: 5.316171970292591
Validation loss: 5.35725817011296

Epoch: 5| Step: 6
Training loss: 5.3354903071439415
Validation loss: 5.346715918291913

Epoch: 5| Step: 7
Training loss: 5.579261813540677
Validation loss: 5.336270211655779

Epoch: 5| Step: 8
Training loss: 5.458493800631563
Validation loss: 5.326254067779375

Epoch: 5| Step: 9
Training loss: 5.92201542750716
Validation loss: 5.3162327387045405

Epoch: 5| Step: 10
Training loss: 4.808681013119658
Validation loss: 5.306870720528825

Epoch: 5| Step: 11
Training loss: 4.52454569522388
Validation loss: 5.297594027258588

Epoch: 8| Step: 0
Training loss: 5.784380750689335
Validation loss: 5.288633035177702

Epoch: 5| Step: 1
Training loss: 5.094453915127644
Validation loss: 5.280137353047372

Epoch: 5| Step: 2
Training loss: 5.655865060764029
Validation loss: 5.271046180599029

Epoch: 5| Step: 3
Training loss: 5.1794291758382425
Validation loss: 5.262858530971322

Epoch: 5| Step: 4
Training loss: 4.968106786013305
Validation loss: 5.254061097010442

Epoch: 5| Step: 5
Training loss: 5.433364347747717
Validation loss: 5.245565047409149

Epoch: 5| Step: 6
Training loss: 5.547979024703042
Validation loss: 5.237417416767438

Epoch: 5| Step: 7
Training loss: 4.952222290571616
Validation loss: 5.229457484918802

Epoch: 5| Step: 8
Training loss: 5.182618935633067
Validation loss: 5.2216041663640524

Epoch: 5| Step: 9
Training loss: 5.381484267820978
Validation loss: 5.214214943301643

Epoch: 5| Step: 10
Training loss: 5.698275576299994
Validation loss: 5.206634178198652

Epoch: 5| Step: 11
Training loss: 5.864212846543883
Validation loss: 5.199402899266996

Epoch: 9| Step: 0
Training loss: 4.940768741299767
Validation loss: 5.191598093101448

Epoch: 5| Step: 1
Training loss: 5.062843216929494
Validation loss: 5.184384908239375

Epoch: 5| Step: 2
Training loss: 5.872088421023342
Validation loss: 5.177306243989349

Epoch: 5| Step: 3
Training loss: 5.3688114824427196
Validation loss: 5.169841708570663

Epoch: 5| Step: 4
Training loss: 5.654946024103365
Validation loss: 5.1625584476663

Epoch: 5| Step: 5
Training loss: 5.237200074268685
Validation loss: 5.155311175333082

Epoch: 5| Step: 6
Training loss: 5.853231805660936
Validation loss: 5.148386174024753

Epoch: 5| Step: 7
Training loss: 5.2890835963044
Validation loss: 5.140892663420499

Epoch: 5| Step: 8
Training loss: 4.579136238772254
Validation loss: 5.133958670170538

Epoch: 5| Step: 9
Training loss: 4.873889698845142
Validation loss: 5.126821977179262

Epoch: 5| Step: 10
Training loss: 5.214365322154809
Validation loss: 5.11992978297454

Epoch: 5| Step: 11
Training loss: 5.172182748172493
Validation loss: 5.113575382190159

Epoch: 10| Step: 0
Training loss: 5.422477227000935
Validation loss: 5.1067771723537865

Epoch: 5| Step: 1
Training loss: 4.8453618474893565
Validation loss: 5.0994821525530964

Epoch: 5| Step: 2
Training loss: 5.340647192608128
Validation loss: 5.09304562868713

Epoch: 5| Step: 3
Training loss: 5.746829610109121
Validation loss: 5.086230791564556

Epoch: 5| Step: 4
Training loss: 5.321810294456264
Validation loss: 5.079559170601841

Epoch: 5| Step: 5
Training loss: 5.242453464634419
Validation loss: 5.073006124575855

Epoch: 5| Step: 6
Training loss: 4.830109321194242
Validation loss: 5.066275981952848

Epoch: 5| Step: 7
Training loss: 4.973609898797355
Validation loss: 5.059935874080292

Epoch: 5| Step: 8
Training loss: 5.758311691280314
Validation loss: 5.053488917979402

Epoch: 5| Step: 9
Training loss: 5.2685828348703625
Validation loss: 5.04750670425199

Epoch: 5| Step: 10
Training loss: 4.474325902877019
Validation loss: 5.041329997883254

Epoch: 5| Step: 11
Training loss: 4.191026483771117
Validation loss: 5.0352335929602665

Epoch: 11| Step: 0
Training loss: 4.926809592300992
Validation loss: 5.028816937999801

Epoch: 5| Step: 1
Training loss: 5.372140522997153
Validation loss: 5.022716788902519

Epoch: 5| Step: 2
Training loss: 5.161617190639488
Validation loss: 5.017264513129364

Epoch: 5| Step: 3
Training loss: 5.227066631551459
Validation loss: 5.011125838226834

Epoch: 5| Step: 4
Training loss: 5.230569760157027
Validation loss: 5.0050080808764195

Epoch: 5| Step: 5
Training loss: 5.1124838607272185
Validation loss: 4.999284955394254

Epoch: 5| Step: 6
Training loss: 4.732287862771843
Validation loss: 4.993423627262797

Epoch: 5| Step: 7
Training loss: 5.1927880600216785
Validation loss: 4.987850966250952

Epoch: 5| Step: 8
Training loss: 5.3536885959720895
Validation loss: 4.98176861324417

Epoch: 5| Step: 9
Training loss: 5.02269780955741
Validation loss: 4.975923122851682

Epoch: 5| Step: 10
Training loss: 4.979796791373522
Validation loss: 4.969736932908733

Epoch: 5| Step: 11
Training loss: 5.183017310580051
Validation loss: 4.963581075708693

Epoch: 12| Step: 0
Training loss: 4.713941334452847
Validation loss: 4.95744841022487

Epoch: 5| Step: 1
Training loss: 5.780679210631781
Validation loss: 4.951558801102513

Epoch: 5| Step: 2
Training loss: 5.4509022727020024
Validation loss: 4.945421857463403

Epoch: 5| Step: 3
Training loss: 5.019147450064431
Validation loss: 4.939967323650753

Epoch: 5| Step: 4
Training loss: 4.6473145226398085
Validation loss: 4.934199400972908

Epoch: 5| Step: 5
Training loss: 4.64006434691963
Validation loss: 4.928463396457434

Epoch: 5| Step: 6
Training loss: 4.944446554195416
Validation loss: 4.922037685067113

Epoch: 5| Step: 7
Training loss: 4.57672722735881
Validation loss: 4.915854850386116

Epoch: 5| Step: 8
Training loss: 4.750621152719918
Validation loss: 4.909830702189206

Epoch: 5| Step: 9
Training loss: 5.628194283456638
Validation loss: 4.903761052179081

Epoch: 5| Step: 10
Training loss: 5.273597545314421
Validation loss: 4.897791761619993

Epoch: 5| Step: 11
Training loss: 4.923029107310931
Validation loss: 4.891851342509845

Epoch: 13| Step: 0
Training loss: 4.18819592514747
Validation loss: 4.886552978110818

Epoch: 5| Step: 1
Training loss: 5.13906975963401
Validation loss: 4.880495829003564

Epoch: 5| Step: 2
Training loss: 4.578800919666466
Validation loss: 4.874073184995195

Epoch: 5| Step: 3
Training loss: 5.2895235342477065
Validation loss: 4.868107112346068

Epoch: 5| Step: 4
Training loss: 5.725661140480239
Validation loss: 4.862202769121332

Epoch: 5| Step: 5
Training loss: 4.6887547148861595
Validation loss: 4.855711051396755

Epoch: 5| Step: 6
Training loss: 4.178022905242205
Validation loss: 4.8494408104871365

Epoch: 5| Step: 7
Training loss: 5.054712593216791
Validation loss: 4.843558703511035

Epoch: 5| Step: 8
Training loss: 5.835672763197153
Validation loss: 4.8372992517445885

Epoch: 5| Step: 9
Training loss: 4.806256492421858
Validation loss: 4.8314506656875995

Epoch: 5| Step: 10
Training loss: 4.876630657077872
Validation loss: 4.825096604429346

Epoch: 5| Step: 11
Training loss: 5.588120510115301
Validation loss: 4.818627918905306

Epoch: 14| Step: 0
Training loss: 4.793756222876298
Validation loss: 4.811905192488438

Epoch: 5| Step: 1
Training loss: 5.23574546978648
Validation loss: 4.8056604160170195

Epoch: 5| Step: 2
Training loss: 3.7034488327140096
Validation loss: 4.798989847636045

Epoch: 5| Step: 3
Training loss: 4.122814639954108
Validation loss: 4.792748307037413

Epoch: 5| Step: 4
Training loss: 5.131345774492054
Validation loss: 4.7860597258397455

Epoch: 5| Step: 5
Training loss: 4.306341224003136
Validation loss: 4.779752625670897

Epoch: 5| Step: 6
Training loss: 5.510723756863784
Validation loss: 4.773781072610843

Epoch: 5| Step: 7
Training loss: 5.22192487253404
Validation loss: 4.767498586101352

Epoch: 5| Step: 8
Training loss: 5.118586178721048
Validation loss: 4.7616257026057704

Epoch: 5| Step: 9
Training loss: 4.9705974095462695
Validation loss: 4.755696469753911

Epoch: 5| Step: 10
Training loss: 5.517433107884099
Validation loss: 4.750011787065303

Epoch: 5| Step: 11
Training loss: 4.718224906758044
Validation loss: 4.743551285459602

Epoch: 15| Step: 0
Training loss: 5.299034556140661
Validation loss: 4.736949526998336

Epoch: 5| Step: 1
Training loss: 4.785945008334585
Validation loss: 4.731382979384941

Epoch: 5| Step: 2
Training loss: 4.300444407009388
Validation loss: 4.7244795399919655

Epoch: 5| Step: 3
Training loss: 4.859233890950096
Validation loss: 4.717964793342203

Epoch: 5| Step: 4
Training loss: 4.891968173992595
Validation loss: 4.711752505258735

Epoch: 5| Step: 5
Training loss: 5.395818624390495
Validation loss: 4.705809121929502

Epoch: 5| Step: 6
Training loss: 4.35456347444592
Validation loss: 4.6997316185774585

Epoch: 5| Step: 7
Training loss: 4.751277149567467
Validation loss: 4.69371488772219

Epoch: 5| Step: 8
Training loss: 4.810336927323295
Validation loss: 4.68726830651623

Epoch: 5| Step: 9
Training loss: 3.564332457289705
Validation loss: 4.681199943332573

Epoch: 5| Step: 10
Training loss: 5.307325468495412
Validation loss: 4.676082931725113

Epoch: 5| Step: 11
Training loss: 7.022549956087332
Validation loss: 4.669326172000949

Epoch: 16| Step: 0
Training loss: 5.760785809002712
Validation loss: 4.664085537221512

Epoch: 5| Step: 1
Training loss: 5.0475261256395365
Validation loss: 4.658409049056273

Epoch: 5| Step: 2
Training loss: 5.219544127570741
Validation loss: 4.651915852182249

Epoch: 5| Step: 3
Training loss: 4.4070407888292
Validation loss: 4.6452309113818195

Epoch: 5| Step: 4
Training loss: 5.1469505837222975
Validation loss: 4.638102726871081

Epoch: 5| Step: 5
Training loss: 4.04679676112835
Validation loss: 4.632063815351503

Epoch: 5| Step: 6
Training loss: 5.125596546716957
Validation loss: 4.626446360313782

Epoch: 5| Step: 7
Training loss: 4.118624528701646
Validation loss: 4.620532335201596

Epoch: 5| Step: 8
Training loss: 4.050878716733636
Validation loss: 4.615434911038156

Epoch: 5| Step: 9
Training loss: 4.262575505726157
Validation loss: 4.608913523531435

Epoch: 5| Step: 10
Training loss: 5.072424309223622
Validation loss: 4.603072544203879

Epoch: 5| Step: 11
Training loss: 3.311364033090224
Validation loss: 4.5965669606114306

Epoch: 17| Step: 0
Training loss: 4.740332754502903
Validation loss: 4.59163842143506

Epoch: 5| Step: 1
Training loss: 4.431144353685978
Validation loss: 4.586254466343949

Epoch: 5| Step: 2
Training loss: 4.129269788720169
Validation loss: 4.581458296297123

Epoch: 5| Step: 3
Training loss: 5.166453305832981
Validation loss: 4.577007157229095

Epoch: 5| Step: 4
Training loss: 5.129579684344236
Validation loss: 4.569874477860756

Epoch: 5| Step: 5
Training loss: 4.246926935705016
Validation loss: 4.564308182702074

Epoch: 5| Step: 6
Training loss: 5.18409010257831
Validation loss: 4.558409455318738

Epoch: 5| Step: 7
Training loss: 4.888888602304932
Validation loss: 4.5534028498470684

Epoch: 5| Step: 8
Training loss: 4.760737279644906
Validation loss: 4.548674088770915

Epoch: 5| Step: 9
Training loss: 4.581004204082579
Validation loss: 4.541878190787281

Epoch: 5| Step: 10
Training loss: 4.239562738292012
Validation loss: 4.5360809093253

Epoch: 5| Step: 11
Training loss: 4.404650458714306
Validation loss: 4.530369306897021

Epoch: 18| Step: 0
Training loss: 4.137772178341083
Validation loss: 4.525131892113954

Epoch: 5| Step: 1
Training loss: 4.838197934766771
Validation loss: 4.52042867750992

Epoch: 5| Step: 2
Training loss: 3.824023482390252
Validation loss: 4.515362187429713

Epoch: 5| Step: 3
Training loss: 4.5143897667149115
Validation loss: 4.510058693486261

Epoch: 5| Step: 4
Training loss: 3.834423255772208
Validation loss: 4.504998164337101

Epoch: 5| Step: 5
Training loss: 4.156172443325963
Validation loss: 4.499626832960126

Epoch: 5| Step: 6
Training loss: 5.501836643468798
Validation loss: 4.493739523983745

Epoch: 5| Step: 7
Training loss: 4.618248006050102
Validation loss: 4.489017861048397

Epoch: 5| Step: 8
Training loss: 5.578305879967369
Validation loss: 4.483920381121884

Epoch: 5| Step: 9
Training loss: 4.604778933774201
Validation loss: 4.478480772982758

Epoch: 5| Step: 10
Training loss: 4.792492383494168
Validation loss: 4.473455463728222

Epoch: 5| Step: 11
Training loss: 5.142930090856145
Validation loss: 4.4682067594252795

Epoch: 19| Step: 0
Training loss: 4.802597757562803
Validation loss: 4.4625926423986035

Epoch: 5| Step: 1
Training loss: 4.447307655159318
Validation loss: 4.458083469602625

Epoch: 5| Step: 2
Training loss: 4.544816327805911
Validation loss: 4.4526432334455395

Epoch: 5| Step: 3
Training loss: 4.926640410673787
Validation loss: 4.4470583767320075

Epoch: 5| Step: 4
Training loss: 4.659063116696983
Validation loss: 4.440977600938796

Epoch: 5| Step: 5
Training loss: 4.30507318946217
Validation loss: 4.435385809319651

Epoch: 5| Step: 6
Training loss: 4.951047828820833
Validation loss: 4.430163125277557

Epoch: 5| Step: 7
Training loss: 4.826714862210527
Validation loss: 4.424678358683777

Epoch: 5| Step: 8
Training loss: 4.49674679465383
Validation loss: 4.419823331207746

Epoch: 5| Step: 9
Training loss: 4.1784426537723665
Validation loss: 4.4139291163633905

Epoch: 5| Step: 10
Training loss: 4.262064471325986
Validation loss: 4.408319834824912

Epoch: 5| Step: 11
Training loss: 2.95053972382431
Validation loss: 4.402485567351206

Epoch: 20| Step: 0
Training loss: 5.132913202374967
Validation loss: 4.397413921789642

Epoch: 5| Step: 1
Training loss: 4.844249674957937
Validation loss: 4.3922135996351255

Epoch: 5| Step: 2
Training loss: 4.3908680478631
Validation loss: 4.386940850568308

Epoch: 5| Step: 3
Training loss: 4.445695213644002
Validation loss: 4.3813680080569055

Epoch: 5| Step: 4
Training loss: 4.099760811504478
Validation loss: 4.3764503663477

Epoch: 5| Step: 5
Training loss: 4.754092411104386
Validation loss: 4.371141626063456

Epoch: 5| Step: 6
Training loss: 4.7731933531313135
Validation loss: 4.365636478482709

Epoch: 5| Step: 7
Training loss: 4.090254827642614
Validation loss: 4.360594115251546

Epoch: 5| Step: 8
Training loss: 4.365469442775948
Validation loss: 4.354783825127782

Epoch: 5| Step: 9
Training loss: 3.8803933050456703
Validation loss: 4.350263889208217

Epoch: 5| Step: 10
Training loss: 4.66589135586925
Validation loss: 4.345104418027771

Epoch: 5| Step: 11
Training loss: 4.029391311226704
Validation loss: 4.339596498383642

Epoch: 21| Step: 0
Training loss: 4.385374357452837
Validation loss: 4.334505269633123

Epoch: 5| Step: 1
Training loss: 4.746792965469555
Validation loss: 4.328794755769476

Epoch: 5| Step: 2
Training loss: 4.415520405323601
Validation loss: 4.323402261079153

Epoch: 5| Step: 3
Training loss: 3.8214698707783374
Validation loss: 4.317960000919345

Epoch: 5| Step: 4
Training loss: 4.814069021505949
Validation loss: 4.312439581774908

Epoch: 5| Step: 5
Training loss: 3.950359598522849
Validation loss: 4.306875006539586

Epoch: 5| Step: 6
Training loss: 4.220195155399594
Validation loss: 4.302827150392541

Epoch: 5| Step: 7
Training loss: 4.632001577492348
Validation loss: 4.2970892742945335

Epoch: 5| Step: 8
Training loss: 4.505661264337908
Validation loss: 4.291323063190725

Epoch: 5| Step: 9
Training loss: 4.389284845724777
Validation loss: 4.286210516080929

Epoch: 5| Step: 10
Training loss: 4.8814072196541645
Validation loss: 4.280772333344828

Epoch: 5| Step: 11
Training loss: 3.9725143722360614
Validation loss: 4.2753074455505535

Epoch: 22| Step: 0
Training loss: 4.2141927334778435
Validation loss: 4.270076399305064

Epoch: 5| Step: 1
Training loss: 4.279597276653703
Validation loss: 4.264088909532866

Epoch: 5| Step: 2
Training loss: 4.36779671720672
Validation loss: 4.258768246209183

Epoch: 5| Step: 3
Training loss: 4.666665326981125
Validation loss: 4.253325507646096

Epoch: 5| Step: 4
Training loss: 4.4895854811283415
Validation loss: 4.24814086342385

Epoch: 5| Step: 5
Training loss: 4.364294851354631
Validation loss: 4.242678300673356

Epoch: 5| Step: 6
Training loss: 4.5431914730039695
Validation loss: 4.237247023256394

Epoch: 5| Step: 7
Training loss: 4.766150673812505
Validation loss: 4.231767665764039

Epoch: 5| Step: 8
Training loss: 3.3772884663511835
Validation loss: 4.226023500381676

Epoch: 5| Step: 9
Training loss: 4.233708290455529
Validation loss: 4.220614668757555

Epoch: 5| Step: 10
Training loss: 4.775545594366884
Validation loss: 4.214271400487389

Epoch: 5| Step: 11
Training loss: 3.5839585638546043
Validation loss: 4.208861495700317

Epoch: 23| Step: 0
Training loss: 3.930896489634297
Validation loss: 4.204603325190144

Epoch: 5| Step: 1
Training loss: 4.477806890333609
Validation loss: 4.199665219724505

Epoch: 5| Step: 2
Training loss: 4.3000057397848455
Validation loss: 4.192414038460621

Epoch: 5| Step: 3
Training loss: 4.173738556303803
Validation loss: 4.18776100446037

Epoch: 5| Step: 4
Training loss: 4.227245226311
Validation loss: 4.183725468366369

Epoch: 5| Step: 5
Training loss: 4.73661665519354
Validation loss: 4.179912867664625

Epoch: 5| Step: 6
Training loss: 3.850398818327871
Validation loss: 4.17381434898739

Epoch: 5| Step: 7
Training loss: 4.5539089473154215
Validation loss: 4.168134462589214

Epoch: 5| Step: 8
Training loss: 4.106009029476979
Validation loss: 4.161559291883337

Epoch: 5| Step: 9
Training loss: 4.19439084746508
Validation loss: 4.157123751090005

Epoch: 5| Step: 10
Training loss: 4.640384346729911
Validation loss: 4.150708857285022

Epoch: 5| Step: 11
Training loss: 4.82796006399355
Validation loss: 4.146301610497214

Epoch: 24| Step: 0
Training loss: 4.914894215560136
Validation loss: 4.140394163594889

Epoch: 5| Step: 1
Training loss: 3.6486071398095117
Validation loss: 4.135088230930724

Epoch: 5| Step: 2
Training loss: 4.3643774501460975
Validation loss: 4.1304176184539845

Epoch: 5| Step: 3
Training loss: 4.471316367604075
Validation loss: 4.124762128464119

Epoch: 5| Step: 4
Training loss: 5.082581803263499
Validation loss: 4.119187643121344

Epoch: 5| Step: 5
Training loss: 3.966426138971703
Validation loss: 4.113444886268932

Epoch: 5| Step: 6
Training loss: 4.2970137140251845
Validation loss: 4.107385470449232

Epoch: 5| Step: 7
Training loss: 3.5402450101731184
Validation loss: 4.102117930754451

Epoch: 5| Step: 8
Training loss: 4.392017075941455
Validation loss: 4.0976731718506105

Epoch: 5| Step: 9
Training loss: 3.699672070997964
Validation loss: 4.092134122826903

Epoch: 5| Step: 10
Training loss: 4.162486739037271
Validation loss: 4.087185763219114

Epoch: 5| Step: 11
Training loss: 3.5932733634327723
Validation loss: 4.082329566677753

Epoch: 25| Step: 0
Training loss: 3.6269719252255745
Validation loss: 4.076760898225172

Epoch: 5| Step: 1
Training loss: 4.2736680214476115
Validation loss: 4.071746671132398

Epoch: 5| Step: 2
Training loss: 4.8267085395668685
Validation loss: 4.06626140862987

Epoch: 5| Step: 3
Training loss: 3.711372558790292
Validation loss: 4.06146285193871

Epoch: 5| Step: 4
Training loss: 4.601886834985907
Validation loss: 4.05677664168613

Epoch: 5| Step: 5
Training loss: 4.234027242984619
Validation loss: 4.052208811068298

Epoch: 5| Step: 6
Training loss: 4.026310696646216
Validation loss: 4.046414976350075

Epoch: 5| Step: 7
Training loss: 4.438828390380512
Validation loss: 4.041496148723602

Epoch: 5| Step: 8
Training loss: 3.9743232342869725
Validation loss: 4.036804916105

Epoch: 5| Step: 9
Training loss: 3.7522710916639426
Validation loss: 4.0315568890922

Epoch: 5| Step: 10
Training loss: 4.49986394040728
Validation loss: 4.026946720714326

Epoch: 5| Step: 11
Training loss: 3.52335981803571
Validation loss: 4.021503440412793

Epoch: 26| Step: 0
Training loss: 4.075319925867041
Validation loss: 4.0170098673875225

Epoch: 5| Step: 1
Training loss: 4.265158156115631
Validation loss: 4.012215657523003

Epoch: 5| Step: 2
Training loss: 3.7970066126237643
Validation loss: 4.007260042202442

Epoch: 5| Step: 3
Training loss: 3.7174268660698138
Validation loss: 4.002615833286151

Epoch: 5| Step: 4
Training loss: 4.116995472202957
Validation loss: 3.998530922767633

Epoch: 5| Step: 5
Training loss: 3.9952904871817934
Validation loss: 3.994087886695299

Epoch: 5| Step: 6
Training loss: 4.699828351721425
Validation loss: 3.989080091896619

Epoch: 5| Step: 7
Training loss: 4.02384019336422
Validation loss: 3.983859887827388

Epoch: 5| Step: 8
Training loss: 3.501069859068947
Validation loss: 3.9792517990805174

Epoch: 5| Step: 9
Training loss: 4.904652134870211
Validation loss: 3.9742723976645227

Epoch: 5| Step: 10
Training loss: 3.94147859626058
Validation loss: 3.969488791038665

Epoch: 5| Step: 11
Training loss: 4.776804334453967
Validation loss: 3.96469138969238

Epoch: 27| Step: 0
Training loss: 4.016807055625045
Validation loss: 3.959666016082128

Epoch: 5| Step: 1
Training loss: 4.0763810327567205
Validation loss: 3.954986209507758

Epoch: 5| Step: 2
Training loss: 4.097447945506776
Validation loss: 3.949736458400777

Epoch: 5| Step: 3
Training loss: 3.5096970149717848
Validation loss: 3.9448326700337795

Epoch: 5| Step: 4
Training loss: 4.6095434125748405
Validation loss: 3.9399499587771736

Epoch: 5| Step: 5
Training loss: 3.8407628307022685
Validation loss: 3.934726591108178

Epoch: 5| Step: 6
Training loss: 4.795795928164034
Validation loss: 3.930061044502002

Epoch: 5| Step: 7
Training loss: 3.878600631921064
Validation loss: 3.924804505260166

Epoch: 5| Step: 8
Training loss: 4.153191150744105
Validation loss: 3.9197693753763896

Epoch: 5| Step: 9
Training loss: 3.913192439123432
Validation loss: 3.91509567705724

Epoch: 5| Step: 10
Training loss: 3.8497119349922633
Validation loss: 3.910379307520498

Epoch: 5| Step: 11
Training loss: 3.2904757184168996
Validation loss: 3.905306068812549

Epoch: 28| Step: 0
Training loss: 3.2442580631870515
Validation loss: 3.9006238016677726

Epoch: 5| Step: 1
Training loss: 3.2768749315493566
Validation loss: 3.896210145661836

Epoch: 5| Step: 2
Training loss: 4.353193378116837
Validation loss: 3.8920571833085544

Epoch: 5| Step: 3
Training loss: 3.40430527914195
Validation loss: 3.8872220274232623

Epoch: 5| Step: 4
Training loss: 4.767193645522096
Validation loss: 3.8825864514995176

Epoch: 5| Step: 5
Training loss: 4.448296535926219
Validation loss: 3.8780458231673456

Epoch: 5| Step: 6
Training loss: 4.079900245568995
Validation loss: 3.8734703993031694

Epoch: 5| Step: 7
Training loss: 4.162887665163276
Validation loss: 3.868592116996765

Epoch: 5| Step: 8
Training loss: 4.589415081378516
Validation loss: 3.8643210579985294

Epoch: 5| Step: 9
Training loss: 3.617408959878301
Validation loss: 3.8591130794549073

Epoch: 5| Step: 10
Training loss: 3.871669938119882
Validation loss: 3.8544108270512343

Epoch: 5| Step: 11
Training loss: 3.721337964623509
Validation loss: 3.849758749789011

Epoch: 29| Step: 0
Training loss: 4.286479568274343
Validation loss: 3.8449571259534383

Epoch: 5| Step: 1
Training loss: 4.1774716216606755
Validation loss: 3.8401707600211834

Epoch: 5| Step: 2
Training loss: 4.362617845227906
Validation loss: 3.835222523362016

Epoch: 5| Step: 3
Training loss: 3.495641583233352
Validation loss: 3.8304444325439158

Epoch: 5| Step: 4
Training loss: 3.431184411594578
Validation loss: 3.825576193218299

Epoch: 5| Step: 5
Training loss: 3.7484375559722145
Validation loss: 3.8210355078408367

Epoch: 5| Step: 6
Training loss: 4.478933828053724
Validation loss: 3.816501867423377

Epoch: 5| Step: 7
Training loss: 3.6714864322329057
Validation loss: 3.811355101021507

Epoch: 5| Step: 8
Training loss: 3.4047705560981423
Validation loss: 3.8068325306860498

Epoch: 5| Step: 9
Training loss: 4.12061122582435
Validation loss: 3.802142864788939

Epoch: 5| Step: 10
Training loss: 4.0619083854076905
Validation loss: 3.797580831302392

Epoch: 5| Step: 11
Training loss: 4.389504286252414
Validation loss: 3.793384512191238

Epoch: 30| Step: 0
Training loss: 4.129001641592604
Validation loss: 3.788502933044426

Epoch: 5| Step: 1
Training loss: 4.198623913174676
Validation loss: 3.78385764443679

Epoch: 5| Step: 2
Training loss: 3.977844151654088
Validation loss: 3.7790266441444986

Epoch: 5| Step: 3
Training loss: 4.056500509135335
Validation loss: 3.774493088908641

Epoch: 5| Step: 4
Training loss: 3.432180554333345
Validation loss: 3.769619620807602

Epoch: 5| Step: 5
Training loss: 3.3277308270923247
Validation loss: 3.7648465366251624

Epoch: 5| Step: 6
Training loss: 3.5832735692444553
Validation loss: 3.7604971037880035

Epoch: 5| Step: 7
Training loss: 4.557767530029158
Validation loss: 3.7560236394532356

Epoch: 5| Step: 8
Training loss: 3.960695037342942
Validation loss: 3.751455670855743

Epoch: 5| Step: 9
Training loss: 3.6022949797870423
Validation loss: 3.746748919005541

Epoch: 5| Step: 10
Training loss: 3.959608468245536
Validation loss: 3.742278536629642

Epoch: 5| Step: 11
Training loss: 3.7099678780535235
Validation loss: 3.73771772717957

Epoch: 31| Step: 0
Training loss: 3.485487003532567
Validation loss: 3.733098353217325

Epoch: 5| Step: 1
Training loss: 4.281597485328016
Validation loss: 3.7286826499801236

Epoch: 5| Step: 2
Training loss: 4.182866507898667
Validation loss: 3.72407670088586

Epoch: 5| Step: 3
Training loss: 3.4262408271229763
Validation loss: 3.719622688582374

Epoch: 5| Step: 4
Training loss: 3.648464423331469
Validation loss: 3.714871978385098

Epoch: 5| Step: 5
Training loss: 3.7845454712327244
Validation loss: 3.710628713509872

Epoch: 5| Step: 6
Training loss: 3.73175212094961
Validation loss: 3.7062068085407964

Epoch: 5| Step: 7
Training loss: 4.250540306303166
Validation loss: 3.7016504520151012

Epoch: 5| Step: 8
Training loss: 3.418473595528805
Validation loss: 3.697459290207053

Epoch: 5| Step: 9
Training loss: 3.490311701280378
Validation loss: 3.6930851477306574

Epoch: 5| Step: 10
Training loss: 4.202400457053138
Validation loss: 3.688971236749576

Epoch: 5| Step: 11
Training loss: 4.917890988947885
Validation loss: 3.684423380871936

Epoch: 32| Step: 0
Training loss: 4.0555858756083065
Validation loss: 3.6796180518765147

Epoch: 5| Step: 1
Training loss: 3.647766835817329
Validation loss: 3.6747433436552943

Epoch: 5| Step: 2
Training loss: 3.466708708165852
Validation loss: 3.6701208375029526

Epoch: 5| Step: 3
Training loss: 3.6711528960839783
Validation loss: 3.665413814053703

Epoch: 5| Step: 4
Training loss: 3.7275597859327
Validation loss: 3.6609930101810884

Epoch: 5| Step: 5
Training loss: 4.065643033714088
Validation loss: 3.6566403118152837

Epoch: 5| Step: 6
Training loss: 3.796136226914927
Validation loss: 3.652024275191045

Epoch: 5| Step: 7
Training loss: 3.9419052670116566
Validation loss: 3.6473395950853047

Epoch: 5| Step: 8
Training loss: 3.845054839180918
Validation loss: 3.6431118462491376

Epoch: 5| Step: 9
Training loss: 3.6778994222873234
Validation loss: 3.6383253756034337

Epoch: 5| Step: 10
Training loss: 3.8073278895932394
Validation loss: 3.63406386067242

Epoch: 5| Step: 11
Training loss: 3.6857590525834936
Validation loss: 3.6293875187283002

Epoch: 33| Step: 0
Training loss: 4.071101546000979
Validation loss: 3.6253457068977704

Epoch: 5| Step: 1
Training loss: 3.7908165086892915
Validation loss: 3.621035282193834

Epoch: 5| Step: 2
Training loss: 4.132179716590879
Validation loss: 3.616602752196969

Epoch: 5| Step: 3
Training loss: 3.625562295382971
Validation loss: 3.612165509042123

Epoch: 5| Step: 4
Training loss: 3.6793595024081878
Validation loss: 3.607814302770297

Epoch: 5| Step: 5
Training loss: 3.7218253618416663
Validation loss: 3.603839890691703

Epoch: 5| Step: 6
Training loss: 3.4349504205715498
Validation loss: 3.5992447241829946

Epoch: 5| Step: 7
Training loss: 3.6710091077192275
Validation loss: 3.5949114816102212

Epoch: 5| Step: 8
Training loss: 3.728751701126964
Validation loss: 3.5906767710557608

Epoch: 5| Step: 9
Training loss: 3.384642495867045
Validation loss: 3.5866194487291563

Epoch: 5| Step: 10
Training loss: 3.806466378010749
Validation loss: 3.5822499748185788

Epoch: 5| Step: 11
Training loss: 3.9563112950209507
Validation loss: 3.578151708333868

Epoch: 34| Step: 0
Training loss: 3.383188979979595
Validation loss: 3.5737990892082525

Epoch: 5| Step: 1
Training loss: 3.432172774174142
Validation loss: 3.5695823685254506

Epoch: 5| Step: 2
Training loss: 3.711136662007569
Validation loss: 3.565389532125886

Epoch: 5| Step: 3
Training loss: 3.421623046517681
Validation loss: 3.5612546573375035

Epoch: 5| Step: 4
Training loss: 3.897119455998403
Validation loss: 3.557235492059832

Epoch: 5| Step: 5
Training loss: 3.1610356676261016
Validation loss: 3.553155506039981

Epoch: 5| Step: 6
Training loss: 3.7019125969707
Validation loss: 3.5490453580474983

Epoch: 5| Step: 7
Training loss: 3.8874383461531066
Validation loss: 3.545189915131139

Epoch: 5| Step: 8
Training loss: 4.22473894926694
Validation loss: 3.540954449043292

Epoch: 5| Step: 9
Training loss: 3.834747564967468
Validation loss: 3.5367688289439627

Epoch: 5| Step: 10
Training loss: 3.9198610522498516
Validation loss: 3.5324052170134284

Epoch: 5| Step: 11
Training loss: 3.041511392331552
Validation loss: 3.528190359113327

Epoch: 35| Step: 0
Training loss: 3.9824909617674065
Validation loss: 3.524037058499013

Epoch: 5| Step: 1
Training loss: 3.4290435812186715
Validation loss: 3.5198487291379723

Epoch: 5| Step: 2
Training loss: 4.1406388192576
Validation loss: 3.515823177827205

Epoch: 5| Step: 3
Training loss: 3.43912717280917
Validation loss: 3.5115229545327145

Epoch: 5| Step: 4
Training loss: 3.573552037160293
Validation loss: 3.507553113651693

Epoch: 5| Step: 5
Training loss: 2.9870984497908126
Validation loss: 3.5033606221714786

Epoch: 5| Step: 6
Training loss: 3.1486839027630324
Validation loss: 3.4991097680486902

Epoch: 5| Step: 7
Training loss: 3.4325031375523376
Validation loss: 3.4954944004502715

Epoch: 5| Step: 8
Training loss: 3.708382395444775
Validation loss: 3.491376203702332

Epoch: 5| Step: 9
Training loss: 4.02915486146972
Validation loss: 3.4874743944912128

Epoch: 5| Step: 10
Training loss: 3.7300866695285815
Validation loss: 3.4834383174523063

Epoch: 5| Step: 11
Training loss: 4.811403620292449
Validation loss: 3.479430620760657

Epoch: 36| Step: 0
Training loss: 3.8146766327567008
Validation loss: 3.4748583099239965

Epoch: 5| Step: 1
Training loss: 3.482513340953897
Validation loss: 3.4705832479823164

Epoch: 5| Step: 2
Training loss: 3.6558621192658523
Validation loss: 3.4665025240448166

Epoch: 5| Step: 3
Training loss: 3.643240189916237
Validation loss: 3.4619986440838457

Epoch: 5| Step: 4
Training loss: 3.797624051024846
Validation loss: 3.457841888040837

Epoch: 5| Step: 5
Training loss: 3.6637137110776385
Validation loss: 3.4533544323220196

Epoch: 5| Step: 6
Training loss: 3.64505037165662
Validation loss: 3.44882568562071

Epoch: 5| Step: 7
Training loss: 3.624298422435797
Validation loss: 3.444806869899321

Epoch: 5| Step: 8
Training loss: 3.9425223880729634
Validation loss: 3.440483971343558

Epoch: 5| Step: 9
Training loss: 2.9791578457219354
Validation loss: 3.436210448239936

Epoch: 5| Step: 10
Training loss: 3.2896917833003396
Validation loss: 3.4320163915497623

Epoch: 5| Step: 11
Training loss: 2.991958967998479
Validation loss: 3.427950445974506

Epoch: 37| Step: 0
Training loss: 3.518184560873707
Validation loss: 3.4240644061156456

Epoch: 5| Step: 1
Training loss: 3.5912847936945056
Validation loss: 3.419964737608116

Epoch: 5| Step: 2
Training loss: 3.768411072631156
Validation loss: 3.4161982195796674

Epoch: 5| Step: 3
Training loss: 3.904134559024351
Validation loss: 3.4120558625515742

Epoch: 5| Step: 4
Training loss: 3.683284095216417
Validation loss: 3.4077648795588966

Epoch: 5| Step: 5
Training loss: 3.97362765248344
Validation loss: 3.403759570898076

Epoch: 5| Step: 6
Training loss: 3.5567948016246675
Validation loss: 3.399457733069584

Epoch: 5| Step: 7
Training loss: 3.112609561079597
Validation loss: 3.3949907179927017

Epoch: 5| Step: 8
Training loss: 3.48176415308918
Validation loss: 3.3907867545410486

Epoch: 5| Step: 9
Training loss: 2.8696733970756654
Validation loss: 3.3862147911422107

Epoch: 5| Step: 10
Training loss: 3.3164979811923496
Validation loss: 3.3827965980490804

Epoch: 5| Step: 11
Training loss: 3.8050461742993087
Validation loss: 3.377881127234794

Epoch: 38| Step: 0
Training loss: 3.2628399960437404
Validation loss: 3.3745779727287655

Epoch: 5| Step: 1
Training loss: 3.175558122254635
Validation loss: 3.371154584221551

Epoch: 5| Step: 2
Training loss: 3.019483874345356
Validation loss: 3.3672524996898408

Epoch: 5| Step: 3
Training loss: 3.8173153593906215
Validation loss: 3.363387262354969

Epoch: 5| Step: 4
Training loss: 2.903776859811151
Validation loss: 3.3588643950164

Epoch: 5| Step: 5
Training loss: 3.6540666892026787
Validation loss: 3.355454770149001

Epoch: 5| Step: 6
Training loss: 3.686245591764767
Validation loss: 3.3513607981112723

Epoch: 5| Step: 7
Training loss: 4.0793749768090715
Validation loss: 3.3475894513285374

Epoch: 5| Step: 8
Training loss: 2.972179479875955
Validation loss: 3.3435770150475372

Epoch: 5| Step: 9
Training loss: 3.8125423991863046
Validation loss: 3.3397528266056202

Epoch: 5| Step: 10
Training loss: 4.017563645072958
Validation loss: 3.3359820313053605

Epoch: 5| Step: 11
Training loss: 1.9876045319520685
Validation loss: 3.3318818548176488

Epoch: 39| Step: 0
Training loss: 3.500305979841569
Validation loss: 3.3286024178041393

Epoch: 5| Step: 1
Training loss: 3.1694364146618357
Validation loss: 3.3250197309611296

Epoch: 5| Step: 2
Training loss: 3.797964308721163
Validation loss: 3.3215551407162125

Epoch: 5| Step: 3
Training loss: 3.9107692363782647
Validation loss: 3.3180571012962177

Epoch: 5| Step: 4
Training loss: 3.9002265570932253
Validation loss: 3.314282816233703

Epoch: 5| Step: 5
Training loss: 3.861024944036135
Validation loss: 3.3104466425933126

Epoch: 5| Step: 6
Training loss: 3.6329637065306266
Validation loss: 3.306156436194807

Epoch: 5| Step: 7
Training loss: 3.1007512566655344
Validation loss: 3.30228069188962

Epoch: 5| Step: 8
Training loss: 3.486140740324828
Validation loss: 3.298346939662827

Epoch: 5| Step: 9
Training loss: 2.462211061363234
Validation loss: 3.2942717400148775

Epoch: 5| Step: 10
Training loss: 2.8010195919333607
Validation loss: 3.291314762152973

Epoch: 5| Step: 11
Training loss: 3.540074083878492
Validation loss: 3.2875477768021444

Epoch: 40| Step: 0
Training loss: 3.099297683899185
Validation loss: 3.2841443027688966

Epoch: 5| Step: 1
Training loss: 3.318293273878131
Validation loss: 3.280714820935019

Epoch: 5| Step: 2
Training loss: 3.497867479521898
Validation loss: 3.27747626902478

Epoch: 5| Step: 3
Training loss: 3.7753183799024033
Validation loss: 3.2742792957520868

Epoch: 5| Step: 4
Training loss: 3.225627773012456
Validation loss: 3.271059560950131

Epoch: 5| Step: 5
Training loss: 3.595042916626684
Validation loss: 3.2678111180070335

Epoch: 5| Step: 6
Training loss: 3.144663629055544
Validation loss: 3.2644796659705224

Epoch: 5| Step: 7
Training loss: 3.472664351394867
Validation loss: 3.260595460972043

Epoch: 5| Step: 8
Training loss: 3.4181922359971866
Validation loss: 3.2574656642647097

Epoch: 5| Step: 9
Training loss: 3.310335135651245
Validation loss: 3.2539600430454034

Epoch: 5| Step: 10
Training loss: 3.7150864707360967
Validation loss: 3.2503498543210663

Epoch: 5| Step: 11
Training loss: 2.481894736517707
Validation loss: 3.246925265865764

Epoch: 41| Step: 0
Training loss: 3.4174377377690908
Validation loss: 3.2437184775112593

Epoch: 5| Step: 1
Training loss: 3.6003897985718374
Validation loss: 3.2403358288763746

Epoch: 5| Step: 2
Training loss: 3.404408648390974
Validation loss: 3.2371732551817844

Epoch: 5| Step: 3
Training loss: 3.4329901502130706
Validation loss: 3.233815425805199

Epoch: 5| Step: 4
Training loss: 3.2915105340039523
Validation loss: 3.2306973223869764

Epoch: 5| Step: 5
Training loss: 3.3611509375056077
Validation loss: 3.227210323888013

Epoch: 5| Step: 6
Training loss: 3.6900729238856176
Validation loss: 3.224100801014168

Epoch: 5| Step: 7
Training loss: 3.3619010476931024
Validation loss: 3.220726030066637

Epoch: 5| Step: 8
Training loss: 2.8354365639382015
Validation loss: 3.2171244544233946

Epoch: 5| Step: 9
Training loss: 3.125946206848472
Validation loss: 3.2136962777178764

Epoch: 5| Step: 10
Training loss: 3.552297606209403
Validation loss: 3.210471831847643

Epoch: 5| Step: 11
Training loss: 2.8311282908571966
Validation loss: 3.2070036936113104

Epoch: 42| Step: 0
Training loss: 3.001742810419031
Validation loss: 3.203853245268581

Epoch: 5| Step: 1
Training loss: 3.0815288487163626
Validation loss: 3.2007387095889372

Epoch: 5| Step: 2
Training loss: 3.342550472543238
Validation loss: 3.197653757568601

Epoch: 5| Step: 3
Training loss: 3.088096307784513
Validation loss: 3.1945333175919925

Epoch: 5| Step: 4
Training loss: 3.4326013513148217
Validation loss: 3.191169885655037

Epoch: 5| Step: 5
Training loss: 3.0284639119653813
Validation loss: 3.188304475479886

Epoch: 5| Step: 6
Training loss: 3.6537061139347804
Validation loss: 3.1850928928965727

Epoch: 5| Step: 7
Training loss: 3.198781413274003
Validation loss: 3.1819339411700156

Epoch: 5| Step: 8
Training loss: 4.08829116863824
Validation loss: 3.178648864171267

Epoch: 5| Step: 9
Training loss: 3.4127524369879207
Validation loss: 3.175291898780911

Epoch: 5| Step: 10
Training loss: 2.8681431147089986
Validation loss: 3.1720903069844453

Epoch: 5| Step: 11
Training loss: 4.340535902697663
Validation loss: 3.168743454313822

Epoch: 43| Step: 0
Training loss: 2.5405794747228065
Validation loss: 3.165575985718913

Epoch: 5| Step: 1
Training loss: 3.483519034173661
Validation loss: 3.1620877732310126

Epoch: 5| Step: 2
Training loss: 3.5102787311443953
Validation loss: 3.158877931124407

Epoch: 5| Step: 3
Training loss: 3.5031922632543586
Validation loss: 3.155618654817541

Epoch: 5| Step: 4
Training loss: 3.2255732241272312
Validation loss: 3.15228634466493

Epoch: 5| Step: 5
Training loss: 2.804982629406024
Validation loss: 3.148979642019672

Epoch: 5| Step: 6
Training loss: 3.400527346610579
Validation loss: 3.1456170618270494

Epoch: 5| Step: 7
Training loss: 3.5392305111109685
Validation loss: 3.1423475940804697

Epoch: 5| Step: 8
Training loss: 3.5350140790645472
Validation loss: 3.1392799394540893

Epoch: 5| Step: 9
Training loss: 3.078025855002277
Validation loss: 3.136116106123016

Epoch: 5| Step: 10
Training loss: 3.2703248294865825
Validation loss: 3.1329076313342243

Epoch: 5| Step: 11
Training loss: 3.913548114044643
Validation loss: 3.129595499246559

Epoch: 44| Step: 0
Training loss: 3.1112907297266212
Validation loss: 3.126126512297411

Epoch: 5| Step: 1
Training loss: 3.2592165914866977
Validation loss: 3.1229233962875718

Epoch: 5| Step: 2
Training loss: 3.6153650821776213
Validation loss: 3.1196919246431913

Epoch: 5| Step: 3
Training loss: 3.250180606225367
Validation loss: 3.116151447897857

Epoch: 5| Step: 4
Training loss: 3.648437107911181
Validation loss: 3.11276270154811

Epoch: 5| Step: 5
Training loss: 3.076101499691024
Validation loss: 3.1094922565990064

Epoch: 5| Step: 6
Training loss: 3.270074468808803
Validation loss: 3.1062560868795255

Epoch: 5| Step: 7
Training loss: 3.4598699779004773
Validation loss: 3.102961937960126

Epoch: 5| Step: 8
Training loss: 2.5572533277653475
Validation loss: 3.099587985058898

Epoch: 5| Step: 9
Training loss: 3.102146199453798
Validation loss: 3.0965088927824342

Epoch: 5| Step: 10
Training loss: 3.257915980024339
Validation loss: 3.093555216324877

Epoch: 5| Step: 11
Training loss: 3.422724927445248
Validation loss: 3.0905511900622407

Epoch: 45| Step: 0
Training loss: 3.0771939956164145
Validation loss: 3.0873731275635397

Epoch: 5| Step: 1
Training loss: 3.884458135572971
Validation loss: 3.0841946666064617

Epoch: 5| Step: 2
Training loss: 2.9363027527131496
Validation loss: 3.080791083665192

Epoch: 5| Step: 3
Training loss: 3.1628742765513174
Validation loss: 3.077565189066761

Epoch: 5| Step: 4
Training loss: 2.561846393873134
Validation loss: 3.0744598404004795

Epoch: 5| Step: 5
Training loss: 3.0392598772063386
Validation loss: 3.071379488294599

Epoch: 5| Step: 6
Training loss: 3.3895060718986754
Validation loss: 3.0683589929636703

Epoch: 5| Step: 7
Training loss: 3.276720681144673
Validation loss: 3.0652968422552713

Epoch: 5| Step: 8
Training loss: 3.114342789733155
Validation loss: 3.0623270362226487

Epoch: 5| Step: 9
Training loss: 3.3782100246855924
Validation loss: 3.059437634947488

Epoch: 5| Step: 10
Training loss: 3.195186248747414
Validation loss: 3.056798444579781

Epoch: 5| Step: 11
Training loss: 4.02241624629974
Validation loss: 3.053944555084488

Epoch: 46| Step: 0
Training loss: 2.952717586448915
Validation loss: 3.050825443509433

Epoch: 5| Step: 1
Training loss: 3.1704805061716828
Validation loss: 3.047898066983908

Epoch: 5| Step: 2
Training loss: 3.0075016009674505
Validation loss: 3.0448551329711555

Epoch: 5| Step: 3
Training loss: 2.9720591523148387
Validation loss: 3.041773837740265

Epoch: 5| Step: 4
Training loss: 3.2156806310766535
Validation loss: 3.038806208220539

Epoch: 5| Step: 5
Training loss: 3.4507726882092533
Validation loss: 3.036109002348096

Epoch: 5| Step: 6
Training loss: 3.2602417302757694
Validation loss: 3.033046645504366

Epoch: 5| Step: 7
Training loss: 2.8463712914531363
Validation loss: 3.030333186978503

Epoch: 5| Step: 8
Training loss: 3.1009364036674216
Validation loss: 3.0277407346922875

Epoch: 5| Step: 9
Training loss: 3.284932858087226
Validation loss: 3.0249211484967513

Epoch: 5| Step: 10
Training loss: 3.4999321522267297
Validation loss: 3.0220773283988493

Epoch: 5| Step: 11
Training loss: 3.772291179158423
Validation loss: 3.0191546390731534

Epoch: 47| Step: 0
Training loss: 3.4219260015998016
Validation loss: 3.0165015546037095

Epoch: 5| Step: 1
Training loss: 3.3452434591467863
Validation loss: 3.013686945859615

Epoch: 5| Step: 2
Training loss: 3.187396328306025
Validation loss: 3.011104410583608

Epoch: 5| Step: 3
Training loss: 2.1022318515037313
Validation loss: 3.008144934972781

Epoch: 5| Step: 4
Training loss: 3.1520685881786457
Validation loss: 3.005715964740075

Epoch: 5| Step: 5
Training loss: 3.6785155938893754
Validation loss: 3.0030357015447806

Epoch: 5| Step: 6
Training loss: 3.417352623039553
Validation loss: 3.000506666234231

Epoch: 5| Step: 7
Training loss: 3.079940338052332
Validation loss: 2.99759388834669

Epoch: 5| Step: 8
Training loss: 3.148847302443617
Validation loss: 2.9946978225378835

Epoch: 5| Step: 9
Training loss: 2.6896999137860536
Validation loss: 2.9918547296697353

Epoch: 5| Step: 10
Training loss: 3.295653926115455
Validation loss: 2.9892586964893915

Epoch: 5| Step: 11
Training loss: 1.9536233495077662
Validation loss: 2.9866619767602076

Epoch: 48| Step: 0
Training loss: 3.8596747278127728
Validation loss: 2.9845396132948054

Epoch: 5| Step: 1
Training loss: 3.0789640415888218
Validation loss: 2.982224956507605

Epoch: 5| Step: 2
Training loss: 2.8647304057889222
Validation loss: 2.979843033970576

Epoch: 5| Step: 3
Training loss: 2.371881947865318
Validation loss: 2.977588139779397

Epoch: 5| Step: 4
Training loss: 3.31275910137902
Validation loss: 2.9754835227382306

Epoch: 5| Step: 5
Training loss: 3.098198207092653
Validation loss: 2.9735108298852886

Epoch: 5| Step: 6
Training loss: 2.917966625616278
Validation loss: 2.971007088069278

Epoch: 5| Step: 7
Training loss: 2.8790414020175623
Validation loss: 2.968728707889697

Epoch: 5| Step: 8
Training loss: 3.5569562106864923
Validation loss: 2.9664477439445074

Epoch: 5| Step: 9
Training loss: 3.1984275053657347
Validation loss: 2.964116888195793

Epoch: 5| Step: 10
Training loss: 2.689610827773548
Validation loss: 2.9619128517243154

Epoch: 5| Step: 11
Training loss: 3.914395316283049
Validation loss: 2.959500580633731

Epoch: 49| Step: 0
Training loss: 3.373247327298716
Validation loss: 2.956934884910327

Epoch: 5| Step: 1
Training loss: 2.93615594511068
Validation loss: 2.954508092561765

Epoch: 5| Step: 2
Training loss: 3.2020945310345152
Validation loss: 2.952009107957313

Epoch: 5| Step: 3
Training loss: 3.1569359666567203
Validation loss: 2.9495865784036397

Epoch: 5| Step: 4
Training loss: 3.3458476394467818
Validation loss: 2.9471875301098573

Epoch: 5| Step: 5
Training loss: 3.3287603640421852
Validation loss: 2.944628874807708

Epoch: 5| Step: 6
Training loss: 2.390366982891273
Validation loss: 2.9421288800321284

Epoch: 5| Step: 7
Training loss: 3.2302762658042066
Validation loss: 2.939874500982603

Epoch: 5| Step: 8
Training loss: 2.783770330086767
Validation loss: 2.937624905007149

Epoch: 5| Step: 9
Training loss: 3.1692200622420463
Validation loss: 2.9353585926282824

Epoch: 5| Step: 10
Training loss: 3.14416031634022
Validation loss: 2.9329721204473356

Epoch: 5| Step: 11
Training loss: 1.478997861157793
Validation loss: 2.9306081859529054

Epoch: 50| Step: 0
Training loss: 3.312923764167763
Validation loss: 2.9285584847123225

Epoch: 5| Step: 1
Training loss: 3.135520924876266
Validation loss: 2.9261484021856385

Epoch: 5| Step: 2
Training loss: 3.0485336093035325
Validation loss: 2.924109432437268

Epoch: 5| Step: 3
Training loss: 3.277140778177324
Validation loss: 2.922039394547837

Epoch: 5| Step: 4
Training loss: 2.6399071976216217
Validation loss: 2.919910123837575

Epoch: 5| Step: 5
Training loss: 3.2325844346397505
Validation loss: 2.9177483812058065

Epoch: 5| Step: 6
Training loss: 2.8704567546447453
Validation loss: 2.9156584268597943

Epoch: 5| Step: 7
Training loss: 3.3145938229749525
Validation loss: 2.913571995693352

Epoch: 5| Step: 8
Training loss: 3.2263040138875407
Validation loss: 2.9111880630220393

Epoch: 5| Step: 9
Training loss: 3.037665587884209
Validation loss: 2.909080951880895

Epoch: 5| Step: 10
Training loss: 2.7319327646753657
Validation loss: 2.9065119888460456

Epoch: 5| Step: 11
Training loss: 1.235930995224764
Validation loss: 2.904654160435294

Epoch: 51| Step: 0
Training loss: 2.997501286370365
Validation loss: 2.902843991857324

Epoch: 5| Step: 1
Training loss: 2.891523891592358
Validation loss: 2.900893090562356

Epoch: 5| Step: 2
Training loss: 3.0184840746654253
Validation loss: 2.8987664090079104

Epoch: 5| Step: 3
Training loss: 2.863714541844709
Validation loss: 2.8965915515197427

Epoch: 5| Step: 4
Training loss: 3.305544766818979
Validation loss: 2.894745225500671

Epoch: 5| Step: 5
Training loss: 3.2536110990276357
Validation loss: 2.8927214778225574

Epoch: 5| Step: 6
Training loss: 2.846183825273507
Validation loss: 2.8903245752603204

Epoch: 5| Step: 7
Training loss: 3.2338616152605035
Validation loss: 2.8883698988883877

Epoch: 5| Step: 8
Training loss: 3.139323406095505
Validation loss: 2.8864946910743914

Epoch: 5| Step: 9
Training loss: 2.846205939888802
Validation loss: 2.8843900091208514

Epoch: 5| Step: 10
Training loss: 3.0101594562053067
Validation loss: 2.88194973241686

Epoch: 5| Step: 11
Training loss: 2.644564336797958
Validation loss: 2.879824774359856

Epoch: 52| Step: 0
Training loss: 3.4302622111553327
Validation loss: 2.8780956567793385

Epoch: 5| Step: 1
Training loss: 2.7965423556659554
Validation loss: 2.8761312118253852

Epoch: 5| Step: 2
Training loss: 2.8067803610232196
Validation loss: 2.873737769922905

Epoch: 5| Step: 3
Training loss: 2.6878903127724714
Validation loss: 2.871718223285715

Epoch: 5| Step: 4
Training loss: 3.031459211228286
Validation loss: 2.8704113449883124

Epoch: 5| Step: 5
Training loss: 2.712529750959666
Validation loss: 2.8686479284374267

Epoch: 5| Step: 6
Training loss: 3.172110412580951
Validation loss: 2.867087221254332

Epoch: 5| Step: 7
Training loss: 3.0426040842249398
Validation loss: 2.8655403492168556

Epoch: 5| Step: 8
Training loss: 2.8602253634353136
Validation loss: 2.8637159467726363

Epoch: 5| Step: 9
Training loss: 3.59123725949931
Validation loss: 2.861928414660449

Epoch: 5| Step: 10
Training loss: 2.8106057463756917
Validation loss: 2.8597766753904934

Epoch: 5| Step: 11
Training loss: 3.0969212779755217
Validation loss: 2.85762198793263

Epoch: 53| Step: 0
Training loss: 3.2881350988027416
Validation loss: 2.855800861574391

Epoch: 5| Step: 1
Training loss: 2.3559413960783004
Validation loss: 2.853442007268824

Epoch: 5| Step: 2
Training loss: 3.1520835646187813
Validation loss: 2.8515392912177133

Epoch: 5| Step: 3
Training loss: 3.0525697357435013
Validation loss: 2.8495794045866103

Epoch: 5| Step: 4
Training loss: 3.1396150246083647
Validation loss: 2.8474705918590586

Epoch: 5| Step: 5
Training loss: 2.3559106314245617
Validation loss: 2.845322380349023

Epoch: 5| Step: 6
Training loss: 3.2087742556170484
Validation loss: 2.8434105694988676

Epoch: 5| Step: 7
Training loss: 3.1373965242503883
Validation loss: 2.841567123931207

Epoch: 5| Step: 8
Training loss: 2.913642914455885
Validation loss: 2.8396129173273295

Epoch: 5| Step: 9
Training loss: 3.0817437757050277
Validation loss: 2.8374029039303497

Epoch: 5| Step: 10
Training loss: 3.2061466014467057
Validation loss: 2.835374693988488

Epoch: 5| Step: 11
Training loss: 1.713884298125057
Validation loss: 2.8333387842312905

Epoch: 54| Step: 0
Training loss: 2.8561543321343343
Validation loss: 2.8319963860832207

Epoch: 5| Step: 1
Training loss: 3.374061453973598
Validation loss: 2.830200608619329

Epoch: 5| Step: 2
Training loss: 2.694557769813002
Validation loss: 2.828257018462601

Epoch: 5| Step: 3
Training loss: 3.1944477431423093
Validation loss: 2.8269172920956023

Epoch: 5| Step: 4
Training loss: 2.896675005843344
Validation loss: 2.8255126437348315

Epoch: 5| Step: 5
Training loss: 2.2837452240858997
Validation loss: 2.8234028849109776

Epoch: 5| Step: 6
Training loss: 2.6708127414268614
Validation loss: 2.827166621490663

Epoch: 5| Step: 7
Training loss: 2.9739036399145604
Validation loss: 2.840183389914613

Epoch: 5| Step: 8
Training loss: 3.0449755885957512
Validation loss: 2.8181149030165997

Epoch: 5| Step: 9
Training loss: 3.6573555081991267
Validation loss: 2.8181091500645428

Epoch: 5| Step: 10
Training loss: 2.8321181290553237
Validation loss: 2.8186576687167837

Epoch: 5| Step: 11
Training loss: 2.548209560358209
Validation loss: 2.820494225900329

Epoch: 55| Step: 0
Training loss: 2.6273006166836
Validation loss: 2.8301508235786357

Epoch: 5| Step: 1
Training loss: 2.8569622595794177
Validation loss: 2.8368199554434814

Epoch: 5| Step: 2
Training loss: 3.041577864792018
Validation loss: 2.8308896519644806

Epoch: 5| Step: 3
Training loss: 3.106066606661011
Validation loss: 2.8134206006920595

Epoch: 5| Step: 4
Training loss: 2.9396247484158624
Validation loss: 2.808808146549561

Epoch: 5| Step: 5
Training loss: 2.7791289910808676
Validation loss: 2.8073484819616197

Epoch: 5| Step: 6
Training loss: 3.0735742070213457
Validation loss: 2.8056549557198256

Epoch: 5| Step: 7
Training loss: 3.283375514835813
Validation loss: 2.807859863408235

Epoch: 5| Step: 8
Training loss: 3.149903516956939
Validation loss: 2.808779045857964

Epoch: 5| Step: 9
Training loss: 2.834672798233841
Validation loss: 2.8055544321815415

Epoch: 5| Step: 10
Training loss: 2.729563725443336
Validation loss: 2.802917945866817

Epoch: 5| Step: 11
Training loss: 3.0056555209768816
Validation loss: 2.8068383416439464

Epoch: 56| Step: 0
Training loss: 2.8642759585919393
Validation loss: 2.8169225359744767

Epoch: 5| Step: 1
Training loss: 3.021282048716324
Validation loss: 2.818938705319242

Epoch: 5| Step: 2
Training loss: 2.879618707953927
Validation loss: 2.8166588199570137

Epoch: 5| Step: 3
Training loss: 2.5016393055225414
Validation loss: 2.812161368717661

Epoch: 5| Step: 4
Training loss: 2.867953413857627
Validation loss: 2.8044614249154245

Epoch: 5| Step: 5
Training loss: 3.0498687903525785
Validation loss: 2.795515650017706

Epoch: 5| Step: 6
Training loss: 3.316417608702206
Validation loss: 2.78665212272274

Epoch: 5| Step: 7
Training loss: 2.9177844131031434
Validation loss: 2.784149901213906

Epoch: 5| Step: 8
Training loss: 2.946715812388343
Validation loss: 2.7868994224078794

Epoch: 5| Step: 9
Training loss: 2.927298993801092
Validation loss: 2.784737650484222

Epoch: 5| Step: 10
Training loss: 2.8964341635798725
Validation loss: 2.7807055772713345

Epoch: 5| Step: 11
Training loss: 3.021270527389166
Validation loss: 2.779483269745136

Epoch: 57| Step: 0
Training loss: 2.774681736334017
Validation loss: 2.777377965817407

Epoch: 5| Step: 1
Training loss: 3.0279874252703256
Validation loss: 2.7754594873506684

Epoch: 5| Step: 2
Training loss: 2.7295518462565584
Validation loss: 2.7743784924466754

Epoch: 5| Step: 3
Training loss: 3.325435214134132
Validation loss: 2.7724605505211732

Epoch: 5| Step: 4
Training loss: 3.323310485909253
Validation loss: 2.770624777944969

Epoch: 5| Step: 5
Training loss: 2.5210563834216626
Validation loss: 2.768481831878689

Epoch: 5| Step: 6
Training loss: 2.619825258033328
Validation loss: 2.7667220933563326

Epoch: 5| Step: 7
Training loss: 2.9439090045984706
Validation loss: 2.7648716509365996

Epoch: 5| Step: 8
Training loss: 2.5656527221520133
Validation loss: 2.7629904653957875

Epoch: 5| Step: 9
Training loss: 2.997323908910947
Validation loss: 2.76187739800105

Epoch: 5| Step: 10
Training loss: 3.06326533505334
Validation loss: 2.7599215057401882

Epoch: 5| Step: 11
Training loss: 2.809350772536793
Validation loss: 2.758455635559454

Epoch: 58| Step: 0
Training loss: 3.352231828060962
Validation loss: 2.7566007774413284

Epoch: 5| Step: 1
Training loss: 2.7981631759551195
Validation loss: 2.7544221471483974

Epoch: 5| Step: 2
Training loss: 2.4671988140907355
Validation loss: 2.752664268845607

Epoch: 5| Step: 3
Training loss: 2.8628708778228082
Validation loss: 2.7514836037376207

Epoch: 5| Step: 4
Training loss: 2.739378269967337
Validation loss: 2.7490359335977272

Epoch: 5| Step: 5
Training loss: 2.652705621542464
Validation loss: 2.74783976555479

Epoch: 5| Step: 6
Training loss: 2.8864157882926835
Validation loss: 2.7460795077031004

Epoch: 5| Step: 7
Training loss: 3.1174767534479826
Validation loss: 2.7438743778907138

Epoch: 5| Step: 8
Training loss: 2.8650869215849815
Validation loss: 2.7422929582305637

Epoch: 5| Step: 9
Training loss: 3.4097609318134876
Validation loss: 2.7409536696005534

Epoch: 5| Step: 10
Training loss: 2.4206593077237915
Validation loss: 2.739652267768481

Epoch: 5| Step: 11
Training loss: 3.133963889395374
Validation loss: 2.7379587902353886

Epoch: 59| Step: 0
Training loss: 2.6559218260049766
Validation loss: 2.736230602064946

Epoch: 5| Step: 1
Training loss: 3.1988282204023677
Validation loss: 2.734563374161458

Epoch: 5| Step: 2
Training loss: 2.7335199381546165
Validation loss: 2.7327449844770793

Epoch: 5| Step: 3
Training loss: 3.1030747884969467
Validation loss: 2.7325476580434045

Epoch: 5| Step: 4
Training loss: 2.9704145081897018
Validation loss: 2.7297081094774267

Epoch: 5| Step: 5
Training loss: 2.894053637267855
Validation loss: 2.7284175315414294

Epoch: 5| Step: 6
Training loss: 2.719849550490068
Validation loss: 2.726541775949849

Epoch: 5| Step: 7
Training loss: 2.462359886249697
Validation loss: 2.726318610795888

Epoch: 5| Step: 8
Training loss: 3.0670025482614913
Validation loss: 2.724499710045422

Epoch: 5| Step: 9
Training loss: 2.445192571752102
Validation loss: 2.723507186748037

Epoch: 5| Step: 10
Training loss: 3.0985597156423124
Validation loss: 2.72257876548171

Epoch: 5| Step: 11
Training loss: 3.351296723327137
Validation loss: 2.7210812859254774

Epoch: 60| Step: 0
Training loss: 2.963928483458012
Validation loss: 2.719190517998605

Epoch: 5| Step: 1
Training loss: 3.239589449926819
Validation loss: 2.717982450565648

Epoch: 5| Step: 2
Training loss: 2.397054764473327
Validation loss: 2.7163676131430674

Epoch: 5| Step: 3
Training loss: 2.7482627236213926
Validation loss: 2.714165377309616

Epoch: 5| Step: 4
Training loss: 3.1359023080323247
Validation loss: 2.7124794487533563

Epoch: 5| Step: 5
Training loss: 2.939857673054494
Validation loss: 2.7103402856849352

Epoch: 5| Step: 6
Training loss: 2.918005517934768
Validation loss: 2.7085352541160996

Epoch: 5| Step: 7
Training loss: 2.479083297567239
Validation loss: 2.7073510601715345

Epoch: 5| Step: 8
Training loss: 2.763918506414637
Validation loss: 2.705381517346937

Epoch: 5| Step: 9
Training loss: 3.084183206363565
Validation loss: 2.703295509384998

Epoch: 5| Step: 10
Training loss: 2.4765138831917253
Validation loss: 2.702583501303906

Epoch: 5| Step: 11
Training loss: 3.2408176699595237
Validation loss: 2.7007052592492067

Epoch: 61| Step: 0
Training loss: 2.664731833759189
Validation loss: 2.7004890231567624

Epoch: 5| Step: 1
Training loss: 2.9225228147374884
Validation loss: 2.6981516604401996

Epoch: 5| Step: 2
Training loss: 2.6621160919933144
Validation loss: 2.697908008713742

Epoch: 5| Step: 3
Training loss: 2.688001718929286
Validation loss: 2.696500212440362

Epoch: 5| Step: 4
Training loss: 2.888703238398872
Validation loss: 2.6939259524016075

Epoch: 5| Step: 5
Training loss: 3.0321524938115396
Validation loss: 2.6930320195946824

Epoch: 5| Step: 6
Training loss: 2.8002053151467874
Validation loss: 2.6901961265028436

Epoch: 5| Step: 7
Training loss: 2.5479979116649845
Validation loss: 2.6898002391276066

Epoch: 5| Step: 8
Training loss: 2.836246862430779
Validation loss: 2.689866521086909

Epoch: 5| Step: 9
Training loss: 2.7402722226259675
Validation loss: 2.6876613102784264

Epoch: 5| Step: 10
Training loss: 3.349237947473483
Validation loss: 2.6858149761121397

Epoch: 5| Step: 11
Training loss: 2.5266953923480546
Validation loss: 2.6831924901057245

Epoch: 62| Step: 0
Training loss: 3.1897682646285217
Validation loss: 2.6841994836970993

Epoch: 5| Step: 1
Training loss: 2.721558446685124
Validation loss: 2.681600571768775

Epoch: 5| Step: 2
Training loss: 2.4897488229141493
Validation loss: 2.6813841102275444

Epoch: 5| Step: 3
Training loss: 2.9275102586835224
Validation loss: 2.679729972925378

Epoch: 5| Step: 4
Training loss: 3.009449857452196
Validation loss: 2.6791249269484188

Epoch: 5| Step: 5
Training loss: 2.7235337188409425
Validation loss: 2.6776295796076144

Epoch: 5| Step: 6
Training loss: 2.897503725564584
Validation loss: 2.6767507277214837

Epoch: 5| Step: 7
Training loss: 3.109862476264321
Validation loss: 2.6766609472195464

Epoch: 5| Step: 8
Training loss: 3.017080163453984
Validation loss: 2.6750934171556593

Epoch: 5| Step: 9
Training loss: 1.96927647892922
Validation loss: 2.6734038026262636

Epoch: 5| Step: 10
Training loss: 2.8048338785465843
Validation loss: 2.672915484744549

Epoch: 5| Step: 11
Training loss: 2.5085118349589566
Validation loss: 2.6712413839648415

Epoch: 63| Step: 0
Training loss: 2.7110509491413715
Validation loss: 2.6688423383463133

Epoch: 5| Step: 1
Training loss: 2.5349401255502095
Validation loss: 2.6675440430215405

Epoch: 5| Step: 2
Training loss: 2.6521591099783426
Validation loss: 2.670097778746828

Epoch: 5| Step: 3
Training loss: 3.4229298537765147
Validation loss: 2.667387765503322

Epoch: 5| Step: 4
Training loss: 3.074671478090164
Validation loss: 2.6673198113663235

Epoch: 5| Step: 5
Training loss: 2.6213015887523428
Validation loss: 2.666217875465221

Epoch: 5| Step: 6
Training loss: 3.3090281015622565
Validation loss: 2.6668039611898084

Epoch: 5| Step: 7
Training loss: 2.864007251495899
Validation loss: 2.665499738587678

Epoch: 5| Step: 8
Training loss: 2.648454784235635
Validation loss: 2.664533493305606

Epoch: 5| Step: 9
Training loss: 2.4887930494922
Validation loss: 2.6656035425023896

Epoch: 5| Step: 10
Training loss: 2.3643223510656357
Validation loss: 2.6621690698182654

Epoch: 5| Step: 11
Training loss: 2.725880097520944
Validation loss: 2.663426137712946

Epoch: 64| Step: 0
Training loss: 2.531599044281756
Validation loss: 2.665488423630924

Epoch: 5| Step: 1
Training loss: 2.9369866754569256
Validation loss: 2.6663141700604256

Epoch: 5| Step: 2
Training loss: 2.969818404840109
Validation loss: 2.663484814638466

Epoch: 5| Step: 3
Training loss: 2.795094098876803
Validation loss: 2.657382222637274

Epoch: 5| Step: 4
Training loss: 2.6426505722411644
Validation loss: 2.654920069292946

Epoch: 5| Step: 5
Training loss: 2.901155826826743
Validation loss: 2.6529575287555964

Epoch: 5| Step: 6
Training loss: 2.6870610965473727
Validation loss: 2.6520612863092228

Epoch: 5| Step: 7
Training loss: 2.7708215545939336
Validation loss: 2.6533225664043343

Epoch: 5| Step: 8
Training loss: 2.8529201672198585
Validation loss: 2.6506789614482558

Epoch: 5| Step: 9
Training loss: 2.832189347688404
Validation loss: 2.6490439824278393

Epoch: 5| Step: 10
Training loss: 2.676676401363674
Validation loss: 2.648800152730923

Epoch: 5| Step: 11
Training loss: 3.3861524202996205
Validation loss: 2.6505450787256457

Epoch: 65| Step: 0
Training loss: 2.645610279282913
Validation loss: 2.654935055050356

Epoch: 5| Step: 1
Training loss: 3.007347328579111
Validation loss: 2.649021395643805

Epoch: 5| Step: 2
Training loss: 2.710763271570546
Validation loss: 2.6485143104600146

Epoch: 5| Step: 3
Training loss: 2.8008030421049
Validation loss: 2.6435020506360054

Epoch: 5| Step: 4
Training loss: 2.484833872900868
Validation loss: 2.6393283466922486

Epoch: 5| Step: 5
Training loss: 2.6200633176767414
Validation loss: 2.640012267462328

Epoch: 5| Step: 6
Training loss: 2.9709008707196167
Validation loss: 2.639384401518301

Epoch: 5| Step: 7
Training loss: 2.4425550031764853
Validation loss: 2.638254222481036

Epoch: 5| Step: 8
Training loss: 3.3281496432112876
Validation loss: 2.6337291996911056

Epoch: 5| Step: 9
Training loss: 2.485866171091065
Validation loss: 2.635623747840628

Epoch: 5| Step: 10
Training loss: 2.741825351548186
Validation loss: 2.6356377577991164

Epoch: 5| Step: 11
Training loss: 3.6284860094570015
Validation loss: 2.6321621666107746

Epoch: 66| Step: 0
Training loss: 2.479057908010035
Validation loss: 2.633155900348474

Epoch: 5| Step: 1
Training loss: 2.762105998254459
Validation loss: 2.64205816227954

Epoch: 5| Step: 2
Training loss: 2.8465652783076996
Validation loss: 2.660013942861226

Epoch: 5| Step: 3
Training loss: 3.124489704429499
Validation loss: 2.663575322715934

Epoch: 5| Step: 4
Training loss: 2.6885127443760357
Validation loss: 2.652580658899436

Epoch: 5| Step: 5
Training loss: 2.332826002916118
Validation loss: 2.648334268604191

Epoch: 5| Step: 6
Training loss: 2.7748167235190677
Validation loss: 2.6442211237867093

Epoch: 5| Step: 7
Training loss: 2.367213384404944
Validation loss: 2.6406740977822287

Epoch: 5| Step: 8
Training loss: 2.5165137385541505
Validation loss: 2.6332033472834926

Epoch: 5| Step: 9
Training loss: 2.9115209874126005
Validation loss: 2.6284681638190515

Epoch: 5| Step: 10
Training loss: 3.597518669753311
Validation loss: 2.630382125450857

Epoch: 5| Step: 11
Training loss: 2.3062333434622504
Validation loss: 2.631740846254834

Epoch: 67| Step: 0
Training loss: 2.48662019439035
Validation loss: 2.6326394142133136

Epoch: 5| Step: 1
Training loss: 3.0540987896283056
Validation loss: 2.632708803091158

Epoch: 5| Step: 2
Training loss: 2.963199928750847
Validation loss: 2.6333262039542764

Epoch: 5| Step: 3
Training loss: 3.1684640668866444
Validation loss: 2.6311281968872593

Epoch: 5| Step: 4
Training loss: 2.3333699586809433
Validation loss: 2.62787710057111

Epoch: 5| Step: 5
Training loss: 3.1065585929125383
Validation loss: 2.627216799524885

Epoch: 5| Step: 6
Training loss: 2.9752098073626922
Validation loss: 2.624098551084095

Epoch: 5| Step: 7
Training loss: 2.5049605746031536
Validation loss: 2.6235095288565464

Epoch: 5| Step: 8
Training loss: 2.5668788805668257
Validation loss: 2.621738981675154

Epoch: 5| Step: 9
Training loss: 2.781747409188881
Validation loss: 2.6192265173368616

Epoch: 5| Step: 10
Training loss: 2.47936016150444
Validation loss: 2.6171930075819985

Epoch: 5| Step: 11
Training loss: 1.8771421275808264
Validation loss: 2.615048843271667

Epoch: 68| Step: 0
Training loss: 3.0274959009144355
Validation loss: 2.614452306850945

Epoch: 5| Step: 1
Training loss: 2.534017956815351
Validation loss: 2.614062209204372

Epoch: 5| Step: 2
Training loss: 3.1627809542976832
Validation loss: 2.613146871125344

Epoch: 5| Step: 3
Training loss: 2.6565468117430524
Validation loss: 2.6127615175663426

Epoch: 5| Step: 4
Training loss: 2.526249219619653
Validation loss: 2.6129463752923545

Epoch: 5| Step: 5
Training loss: 2.8930755949880447
Validation loss: 2.6112437913430364

Epoch: 5| Step: 6
Training loss: 2.7702739887174874
Validation loss: 2.6091460738582204

Epoch: 5| Step: 7
Training loss: 3.184959745766549
Validation loss: 2.6106797837443985

Epoch: 5| Step: 8
Training loss: 2.4706161785281875
Validation loss: 2.607413035936173

Epoch: 5| Step: 9
Training loss: 2.4297241993183953
Validation loss: 2.605088449735016

Epoch: 5| Step: 10
Training loss: 2.4407305705625544
Validation loss: 2.6047430710260264

Epoch: 5| Step: 11
Training loss: 2.610479155510766
Validation loss: 2.6058373750468857

Epoch: 69| Step: 0
Training loss: 2.442126261015931
Validation loss: 2.603330776847906

Epoch: 5| Step: 1
Training loss: 2.574126871463531
Validation loss: 2.605318048895348

Epoch: 5| Step: 2
Training loss: 2.415554634836102
Validation loss: 2.601382466025592

Epoch: 5| Step: 3
Training loss: 2.851688915220146
Validation loss: 2.600188120430855

Epoch: 5| Step: 4
Training loss: 3.119752521725716
Validation loss: 2.5973267884094478

Epoch: 5| Step: 5
Training loss: 3.170855428758216
Validation loss: 2.600376011331433

Epoch: 5| Step: 6
Training loss: 2.57639268416142
Validation loss: 2.5991957154097487

Epoch: 5| Step: 7
Training loss: 2.5220805674063564
Validation loss: 2.596803235417752

Epoch: 5| Step: 8
Training loss: 2.7764082351102983
Validation loss: 2.5961310247086593

Epoch: 5| Step: 9
Training loss: 2.489843527845044
Validation loss: 2.5936050374529875

Epoch: 5| Step: 10
Training loss: 2.8695058986126605
Validation loss: 2.5933305830213613

Epoch: 5| Step: 11
Training loss: 3.3921432260288706
Validation loss: 2.59509342898851

Epoch: 70| Step: 0
Training loss: 2.648874882503505
Validation loss: 2.5932970570717284

Epoch: 5| Step: 1
Training loss: 3.2085715531593126
Validation loss: 2.5926571922321227

Epoch: 5| Step: 2
Training loss: 2.6545392080900965
Validation loss: 2.591237304580953

Epoch: 5| Step: 3
Training loss: 2.8016434410474433
Validation loss: 2.5911303163507915

Epoch: 5| Step: 4
Training loss: 2.8362105477196318
Validation loss: 2.592289011421817

Epoch: 5| Step: 5
Training loss: 2.594452636409935
Validation loss: 2.5929206495046535

Epoch: 5| Step: 6
Training loss: 2.8075656415105206
Validation loss: 2.590231508251405

Epoch: 5| Step: 7
Training loss: 2.4007799470688784
Validation loss: 2.587156678733558

Epoch: 5| Step: 8
Training loss: 3.2847178707582354
Validation loss: 2.585031125823879

Epoch: 5| Step: 9
Training loss: 2.1382189963564056
Validation loss: 2.582570456848199

Epoch: 5| Step: 10
Training loss: 2.250712493831435
Validation loss: 2.5829174504281722

Epoch: 5| Step: 11
Training loss: 3.300267503473381
Validation loss: 2.583722205785366

Epoch: 71| Step: 0
Training loss: 2.791731041313122
Validation loss: 2.5809928625878413

Epoch: 5| Step: 1
Training loss: 2.7035724953042637
Validation loss: 2.580736756273511

Epoch: 5| Step: 2
Training loss: 2.5916607266896694
Validation loss: 2.581650152278788

Epoch: 5| Step: 3
Training loss: 2.366749335801759
Validation loss: 2.581700806434077

Epoch: 5| Step: 4
Training loss: 2.5284373350971996
Validation loss: 2.586743009409914

Epoch: 5| Step: 5
Training loss: 3.1713130058432064
Validation loss: 2.5839606043961387

Epoch: 5| Step: 6
Training loss: 2.483621927001318
Validation loss: 2.5821949670763606

Epoch: 5| Step: 7
Training loss: 2.836598721178707
Validation loss: 2.580299978177718

Epoch: 5| Step: 8
Training loss: 2.746837965506218
Validation loss: 2.577199658107345

Epoch: 5| Step: 9
Training loss: 2.9202582634409775
Validation loss: 2.5750113942224444

Epoch: 5| Step: 10
Training loss: 2.545045253898419
Validation loss: 2.5747511163201624

Epoch: 5| Step: 11
Training loss: 3.0583533415456046
Validation loss: 2.573418496236792

Epoch: 72| Step: 0
Training loss: 2.801806827407612
Validation loss: 2.5722710240799094

Epoch: 5| Step: 1
Training loss: 2.458282588715184
Validation loss: 2.5712887379681955

Epoch: 5| Step: 2
Training loss: 2.6339867573885303
Validation loss: 2.5715137136772235

Epoch: 5| Step: 3
Training loss: 2.725344060472975
Validation loss: 2.5704249132304104

Epoch: 5| Step: 4
Training loss: 2.421779212287955
Validation loss: 2.5702502157130014

Epoch: 5| Step: 5
Training loss: 2.71516366075443
Validation loss: 2.5705461946590926

Epoch: 5| Step: 6
Training loss: 3.0062873441474376
Validation loss: 2.5706040585159

Epoch: 5| Step: 7
Training loss: 2.444615761456366
Validation loss: 2.569015890902864

Epoch: 5| Step: 8
Training loss: 3.1017892596085486
Validation loss: 2.5685427040646482

Epoch: 5| Step: 9
Training loss: 2.681758958576993
Validation loss: 2.567580180552058

Epoch: 5| Step: 10
Training loss: 2.5272395069728253
Validation loss: 2.5682166017560086

Epoch: 5| Step: 11
Training loss: 3.1217295508730327
Validation loss: 2.5660041908322606

Epoch: 73| Step: 0
Training loss: 2.345781082014071
Validation loss: 2.5616203752238706

Epoch: 5| Step: 1
Training loss: 2.6224039955858163
Validation loss: 2.5681118535237357

Epoch: 5| Step: 2
Training loss: 2.9554658523210584
Validation loss: 2.5725623490439697

Epoch: 5| Step: 3
Training loss: 2.811498845248907
Validation loss: 2.5659408224717164

Epoch: 5| Step: 4
Training loss: 2.5021484679913746
Validation loss: 2.567681994635162

Epoch: 5| Step: 5
Training loss: 2.761057730077073
Validation loss: 2.5696348903001938

Epoch: 5| Step: 6
Training loss: 2.900583629415872
Validation loss: 2.5648531189010626

Epoch: 5| Step: 7
Training loss: 2.585348286878449
Validation loss: 2.5625351461465873

Epoch: 5| Step: 8
Training loss: 3.2569233437952447
Validation loss: 2.561601570460932

Epoch: 5| Step: 9
Training loss: 2.5583158618773605
Validation loss: 2.561857135118218

Epoch: 5| Step: 10
Training loss: 2.255363852503124
Validation loss: 2.5647673267912467

Epoch: 5| Step: 11
Training loss: 2.2216964285083542
Validation loss: 2.564649033550615

Epoch: 74| Step: 0
Training loss: 2.6474674214924288
Validation loss: 2.5679177294936344

Epoch: 5| Step: 1
Training loss: 3.239216594646565
Validation loss: 2.563525583918682

Epoch: 5| Step: 2
Training loss: 2.669407290560575
Validation loss: 2.561924125347425

Epoch: 5| Step: 3
Training loss: 2.2879504734761174
Validation loss: 2.563982422341674

Epoch: 5| Step: 4
Training loss: 2.4014033267919084
Validation loss: 2.5597111288333836

Epoch: 5| Step: 5
Training loss: 2.733801383750901
Validation loss: 2.556951066362614

Epoch: 5| Step: 6
Training loss: 2.5455074266105457
Validation loss: 2.5546096999894607

Epoch: 5| Step: 7
Training loss: 2.660498060765211
Validation loss: 2.557457137079607

Epoch: 5| Step: 8
Training loss: 3.0284086458718877
Validation loss: 2.5631630047567504

Epoch: 5| Step: 9
Training loss: 2.5501768088284824
Validation loss: 2.5577856636853324

Epoch: 5| Step: 10
Training loss: 2.5897951423605945
Validation loss: 2.5577103543338953

Epoch: 5| Step: 11
Training loss: 3.217857014752989
Validation loss: 2.556353777090102

Epoch: 75| Step: 0
Training loss: 2.7213954113233396
Validation loss: 2.552286682331625

Epoch: 5| Step: 1
Training loss: 2.918320232502107
Validation loss: 2.5541868273347506

Epoch: 5| Step: 2
Training loss: 2.758642747087921
Validation loss: 2.550973332929279

Epoch: 5| Step: 3
Training loss: 2.658297389234891
Validation loss: 2.5488469343599753

Epoch: 5| Step: 4
Training loss: 2.3907919432748286
Validation loss: 2.5538921809749793

Epoch: 5| Step: 5
Training loss: 2.3504010243857003
Validation loss: 2.554103597937871

Epoch: 5| Step: 6
Training loss: 2.9954051752135786
Validation loss: 2.55226652435091

Epoch: 5| Step: 7
Training loss: 2.8064553472411333
Validation loss: 2.554011470307144

Epoch: 5| Step: 8
Training loss: 2.5243581503721093
Validation loss: 2.55237829618775

Epoch: 5| Step: 9
Training loss: 2.8459434015110863
Validation loss: 2.5530486960430694

Epoch: 5| Step: 10
Training loss: 2.3290172121780426
Validation loss: 2.5499586655190036

Epoch: 5| Step: 11
Training loss: 2.85742137436983
Validation loss: 2.5516780544448814

Epoch: 76| Step: 0
Training loss: 2.6551966654322996
Validation loss: 2.5495193460095433

Epoch: 5| Step: 1
Training loss: 2.439371906330357
Validation loss: 2.549280469955665

Epoch: 5| Step: 2
Training loss: 2.811482054553899
Validation loss: 2.547999079352167

Epoch: 5| Step: 3
Training loss: 3.141306333511113
Validation loss: 2.550443273472106

Epoch: 5| Step: 4
Training loss: 2.3653390043822164
Validation loss: 2.5483300473878314

Epoch: 5| Step: 5
Training loss: 2.851777369098582
Validation loss: 2.545283945890203

Epoch: 5| Step: 6
Training loss: 2.4666291796782676
Validation loss: 2.54429412227242

Epoch: 5| Step: 7
Training loss: 2.6558306194667
Validation loss: 2.5412139189686074

Epoch: 5| Step: 8
Training loss: 2.620333747572899
Validation loss: 2.5410308133726214

Epoch: 5| Step: 9
Training loss: 2.756397089417775
Validation loss: 2.5415343278816382

Epoch: 5| Step: 10
Training loss: 2.3439452026458705
Validation loss: 2.5385921844748705

Epoch: 5| Step: 11
Training loss: 3.3845114725340855
Validation loss: 2.536064694439322

Epoch: 77| Step: 0
Training loss: 2.6079470444902126
Validation loss: 2.542507225458962

Epoch: 5| Step: 1
Training loss: 2.903129789514769
Validation loss: 2.5423393193236943

Epoch: 5| Step: 2
Training loss: 2.6538829354381415
Validation loss: 2.5428144854482797

Epoch: 5| Step: 3
Training loss: 2.7874485336137
Validation loss: 2.5425706308582328

Epoch: 5| Step: 4
Training loss: 3.0146270840169396
Validation loss: 2.5430429997618296

Epoch: 5| Step: 5
Training loss: 2.6615394435599193
Validation loss: 2.541826475049345

Epoch: 5| Step: 6
Training loss: 2.355270756992732
Validation loss: 2.54382521918805

Epoch: 5| Step: 7
Training loss: 2.4503837868734792
Validation loss: 2.545188431187513

Epoch: 5| Step: 8
Training loss: 2.8382945288534684
Validation loss: 2.5439131077578563

Epoch: 5| Step: 9
Training loss: 2.6219802016930007
Validation loss: 2.544442229938608

Epoch: 5| Step: 10
Training loss: 2.3228948845861335
Validation loss: 2.5404297262912117

Epoch: 5| Step: 11
Training loss: 3.028974327756914
Validation loss: 2.5388156868722813

Epoch: 78| Step: 0
Training loss: 2.663974257095639
Validation loss: 2.537017366396726

Epoch: 5| Step: 1
Training loss: 2.783169116431475
Validation loss: 2.5331404773080264

Epoch: 5| Step: 2
Training loss: 2.7246484022182473
Validation loss: 2.530981865954939

Epoch: 5| Step: 3
Training loss: 2.8059679259182095
Validation loss: 2.5299625537008468

Epoch: 5| Step: 4
Training loss: 2.5503828546677654
Validation loss: 2.5288747113586423

Epoch: 5| Step: 5
Training loss: 2.619488880009357
Validation loss: 2.527563786152983

Epoch: 5| Step: 6
Training loss: 3.2370950806482695
Validation loss: 2.527935123975641

Epoch: 5| Step: 7
Training loss: 2.367440288882349
Validation loss: 2.526535246825339

Epoch: 5| Step: 8
Training loss: 2.6635352365244347
Validation loss: 2.5214644987040455

Epoch: 5| Step: 9
Training loss: 2.3522839627607
Validation loss: 2.521724280762118

Epoch: 5| Step: 10
Training loss: 2.5255648972520848
Validation loss: 2.524780120970103

Epoch: 5| Step: 11
Training loss: 1.66862871393643
Validation loss: 2.519328575952568

Epoch: 79| Step: 0
Training loss: 2.372568090042608
Validation loss: 2.527649638371352

Epoch: 5| Step: 1
Training loss: 3.0036852771454976
Validation loss: 2.5218776925035966

Epoch: 5| Step: 2
Training loss: 2.514206385599569
Validation loss: 2.5265550576727347

Epoch: 5| Step: 3
Training loss: 2.776339793464264
Validation loss: 2.5229211954212154

Epoch: 5| Step: 4
Training loss: 2.448633443444822
Validation loss: 2.5269598652133594

Epoch: 5| Step: 5
Training loss: 2.8981772251947766
Validation loss: 2.5248294058224925

Epoch: 5| Step: 6
Training loss: 2.504779538410768
Validation loss: 2.526752605218105

Epoch: 5| Step: 7
Training loss: 2.7773360240201086
Validation loss: 2.5260079424202906

Epoch: 5| Step: 8
Training loss: 2.339503599480022
Validation loss: 2.5273856936339434

Epoch: 5| Step: 9
Training loss: 3.0587982849874535
Validation loss: 2.5299752954299657

Epoch: 5| Step: 10
Training loss: 2.304043023469354
Validation loss: 2.5281670755878127

Epoch: 5| Step: 11
Training loss: 2.6868372255178063
Validation loss: 2.5269504616491827

Epoch: 80| Step: 0
Training loss: 2.8961872095011447
Validation loss: 2.5248651668379076

Epoch: 5| Step: 1
Training loss: 2.339549152762065
Validation loss: 2.521932068233816

Epoch: 5| Step: 2
Training loss: 2.8312739760707872
Validation loss: 2.52120782629349

Epoch: 5| Step: 3
Training loss: 2.3448664739858334
Validation loss: 2.521023366138889

Epoch: 5| Step: 4
Training loss: 2.7921568217243906
Validation loss: 2.5206864027809277

Epoch: 5| Step: 5
Training loss: 2.7034006143641354
Validation loss: 2.5192484655064846

Epoch: 5| Step: 6
Training loss: 2.8462523465153167
Validation loss: 2.518777920968134

Epoch: 5| Step: 7
Training loss: 2.225907400030271
Validation loss: 2.5167535694751666

Epoch: 5| Step: 8
Training loss: 3.0162363964395333
Validation loss: 2.520502905561895

Epoch: 5| Step: 9
Training loss: 2.8467165386765694
Validation loss: 2.520586385269563

Epoch: 5| Step: 10
Training loss: 2.094805664845314
Validation loss: 2.5197962776784246

Epoch: 5| Step: 11
Training loss: 2.3055199105853474
Validation loss: 2.5157424433365767

Epoch: 81| Step: 0
Training loss: 2.6872522994044115
Validation loss: 2.5153446870617184

Epoch: 5| Step: 1
Training loss: 2.900191688779388
Validation loss: 2.5181122956216226

Epoch: 5| Step: 2
Training loss: 2.517446581094775
Validation loss: 2.5177939287712596

Epoch: 5| Step: 3
Training loss: 2.7195779701609792
Validation loss: 2.516338626269155

Epoch: 5| Step: 4
Training loss: 2.6544839710262527
Validation loss: 2.5143390828183674

Epoch: 5| Step: 5
Training loss: 2.287974753387251
Validation loss: 2.514714319051271

Epoch: 5| Step: 6
Training loss: 2.404091399373778
Validation loss: 2.5174342889490244

Epoch: 5| Step: 7
Training loss: 2.8580858002924785
Validation loss: 2.517682002577894

Epoch: 5| Step: 8
Training loss: 2.8836845588286284
Validation loss: 2.510472330027637

Epoch: 5| Step: 9
Training loss: 2.2260899092415607
Validation loss: 2.513842699658109

Epoch: 5| Step: 10
Training loss: 2.7094169111871116
Validation loss: 2.510912958265356

Epoch: 5| Step: 11
Training loss: 3.2524991330285644
Validation loss: 2.5134472276062323

Epoch: 82| Step: 0
Training loss: 2.7406103918888935
Validation loss: 2.5161278461015253

Epoch: 5| Step: 1
Training loss: 2.7141331902292856
Validation loss: 2.514901167628971

Epoch: 5| Step: 2
Training loss: 2.117412710000735
Validation loss: 2.5144934350299275

Epoch: 5| Step: 3
Training loss: 2.404223492863693
Validation loss: 2.513952141317873

Epoch: 5| Step: 4
Training loss: 2.4921234026950296
Validation loss: 2.5139938796379093

Epoch: 5| Step: 5
Training loss: 2.774514518404201
Validation loss: 2.5113681135159935

Epoch: 5| Step: 6
Training loss: 3.149390443225386
Validation loss: 2.512098075102982

Epoch: 5| Step: 7
Training loss: 2.3942352161713822
Validation loss: 2.5133405623681946

Epoch: 5| Step: 8
Training loss: 2.956124855925128
Validation loss: 2.513607479793141

Epoch: 5| Step: 9
Training loss: 2.455536161559988
Validation loss: 2.515621556502803

Epoch: 5| Step: 10
Training loss: 2.669330567722749
Validation loss: 2.517156801958078

Epoch: 5| Step: 11
Training loss: 2.1436032926223447
Validation loss: 2.5155584591107223

Epoch: 83| Step: 0
Training loss: 2.4133933908496106
Validation loss: 2.512477564355687

Epoch: 5| Step: 1
Training loss: 2.297298470210275
Validation loss: 2.509133336713569

Epoch: 5| Step: 2
Training loss: 2.720129868688802
Validation loss: 2.5094130450223333

Epoch: 5| Step: 3
Training loss: 2.3551417894058027
Validation loss: 2.5048797746209854

Epoch: 5| Step: 4
Training loss: 2.734504304280872
Validation loss: 2.503409960873899

Epoch: 5| Step: 5
Training loss: 2.5846815487886863
Validation loss: 2.504756949610711

Epoch: 5| Step: 6
Training loss: 2.4950655877736923
Validation loss: 2.506553868829515

Epoch: 5| Step: 7
Training loss: 2.4546666251884814
Validation loss: 2.5076936751089347

Epoch: 5| Step: 8
Training loss: 3.0114937585686525
Validation loss: 2.505039432777446

Epoch: 5| Step: 9
Training loss: 2.787755836412972
Validation loss: 2.502190718833162

Epoch: 5| Step: 10
Training loss: 2.9406147128664046
Validation loss: 2.50681509304755

Epoch: 5| Step: 11
Training loss: 2.638855380687681
Validation loss: 2.5006503570537166

Epoch: 84| Step: 0
Training loss: 2.9230106207243223
Validation loss: 2.505803477019885

Epoch: 5| Step: 1
Training loss: 2.4298607865632214
Validation loss: 2.50323976562393

Epoch: 5| Step: 2
Training loss: 2.6856858096163916
Validation loss: 2.507252342434511

Epoch: 5| Step: 3
Training loss: 2.6265402316954143
Validation loss: 2.5083648572463764

Epoch: 5| Step: 4
Training loss: 2.829083864988226
Validation loss: 2.507986904429764

Epoch: 5| Step: 5
Training loss: 2.0425408755896637
Validation loss: 2.5057520259897323

Epoch: 5| Step: 6
Training loss: 2.641373477474108
Validation loss: 2.501024906357026

Epoch: 5| Step: 7
Training loss: 3.046823667436174
Validation loss: 2.5009547556232157

Epoch: 5| Step: 8
Training loss: 2.1879047564292113
Validation loss: 2.5031546795339983

Epoch: 5| Step: 9
Training loss: 2.739453118037484
Validation loss: 2.5019460177215156

Epoch: 5| Step: 10
Training loss: 2.7534488379271322
Validation loss: 2.501853343314951

Epoch: 5| Step: 11
Training loss: 1.2724051474273137
Validation loss: 2.5029568035052496

Epoch: 85| Step: 0
Training loss: 2.7046815657261316
Validation loss: 2.5034824078076814

Epoch: 5| Step: 1
Training loss: 2.860175349055325
Validation loss: 2.5003446619550775

Epoch: 5| Step: 2
Training loss: 2.2752419353577324
Validation loss: 2.496259262973216

Epoch: 5| Step: 3
Training loss: 2.9250792207341667
Validation loss: 2.500667026067786

Epoch: 5| Step: 4
Training loss: 2.4608100979236927
Validation loss: 2.4958031713566293

Epoch: 5| Step: 5
Training loss: 2.7621709083864143
Validation loss: 2.498585070112159

Epoch: 5| Step: 6
Training loss: 2.6468797451728885
Validation loss: 2.497010891828613

Epoch: 5| Step: 7
Training loss: 2.21508184966335
Validation loss: 2.497124464601316

Epoch: 5| Step: 8
Training loss: 2.6336551755284225
Validation loss: 2.5017658116870947

Epoch: 5| Step: 9
Training loss: 2.6099828137822145
Validation loss: 2.502003379632724

Epoch: 5| Step: 10
Training loss: 2.625564786914782
Validation loss: 2.5021253968725574

Epoch: 5| Step: 11
Training loss: 2.660649952609062
Validation loss: 2.5029623401827354

Epoch: 86| Step: 0
Training loss: 2.5620565263288015
Validation loss: 2.50236469728085

Epoch: 5| Step: 1
Training loss: 2.4268318886455793
Validation loss: 2.5043823852760196

Epoch: 5| Step: 2
Training loss: 2.606392257796486
Validation loss: 2.5054149238491124

Epoch: 5| Step: 3
Training loss: 2.681024868278889
Validation loss: 2.501768186247262

Epoch: 5| Step: 4
Training loss: 2.95757914497714
Validation loss: 2.5006235656314657

Epoch: 5| Step: 5
Training loss: 2.538227213868213
Validation loss: 2.505505658520092

Epoch: 5| Step: 6
Training loss: 2.515919922783976
Validation loss: 2.499738751112682

Epoch: 5| Step: 7
Training loss: 2.5858458534435105
Validation loss: 2.500335984700027

Epoch: 5| Step: 8
Training loss: 2.698934139809238
Validation loss: 2.5013963098102328

Epoch: 5| Step: 9
Training loss: 2.853719486001586
Validation loss: 2.500567594309609

Epoch: 5| Step: 10
Training loss: 2.3849877606283787
Validation loss: 2.5011458631929657

Epoch: 5| Step: 11
Training loss: 2.4122617851014514
Validation loss: 2.501090896537136

Epoch: 87| Step: 0
Training loss: 2.8422602849179173
Validation loss: 2.500613606172814

Epoch: 5| Step: 1
Training loss: 2.4797086256890446
Validation loss: 2.5013667662063117

Epoch: 5| Step: 2
Training loss: 2.680988140701763
Validation loss: 2.499224872428579

Epoch: 5| Step: 3
Training loss: 2.6339376066112954
Validation loss: 2.49862855407802

Epoch: 5| Step: 4
Training loss: 2.568505205430958
Validation loss: 2.5006814822557506

Epoch: 5| Step: 5
Training loss: 2.7848594475281105
Validation loss: 2.504338366535118

Epoch: 5| Step: 6
Training loss: 2.138015604574212
Validation loss: 2.501088549137338

Epoch: 5| Step: 7
Training loss: 3.027786478463678
Validation loss: 2.4980929631168936

Epoch: 5| Step: 8
Training loss: 2.806333011342477
Validation loss: 2.50227302294902

Epoch: 5| Step: 9
Training loss: 2.603746110654097
Validation loss: 2.4984508721600327

Epoch: 5| Step: 10
Training loss: 2.231240801965898
Validation loss: 2.495080319285875

Epoch: 5| Step: 11
Training loss: 2.1078978841467237
Validation loss: 2.491549823859039

Epoch: 88| Step: 0
Training loss: 2.610169615221787
Validation loss: 2.4925350277746925

Epoch: 5| Step: 1
Training loss: 2.3620841533259984
Validation loss: 2.488885567589324

Epoch: 5| Step: 2
Training loss: 3.1347660813375837
Validation loss: 2.4900133102130186

Epoch: 5| Step: 3
Training loss: 2.744944694253733
Validation loss: 2.4947054787695615

Epoch: 5| Step: 4
Training loss: 2.9148028458521837
Validation loss: 2.4962440807620645

Epoch: 5| Step: 5
Training loss: 2.6131389219930052
Validation loss: 2.4922761632280914

Epoch: 5| Step: 6
Training loss: 2.3580100045675434
Validation loss: 2.493871173926262

Epoch: 5| Step: 7
Training loss: 2.606890289181323
Validation loss: 2.491977607075871

Epoch: 5| Step: 8
Training loss: 2.4224311436176773
Validation loss: 2.4907625802529747

Epoch: 5| Step: 9
Training loss: 2.771031069093699
Validation loss: 2.49384925313332

Epoch: 5| Step: 10
Training loss: 2.1374065401045925
Validation loss: 2.4904033209643273

Epoch: 5| Step: 11
Training loss: 2.8805902284231464
Validation loss: 2.4888204911520426

Epoch: 89| Step: 0
Training loss: 2.8043712554559774
Validation loss: 2.492541293041632

Epoch: 5| Step: 1
Training loss: 2.727303040942871
Validation loss: 2.489398316301224

Epoch: 5| Step: 2
Training loss: 2.85993426747578
Validation loss: 2.4905823228881894

Epoch: 5| Step: 3
Training loss: 2.6291940880104687
Validation loss: 2.4919744458306843

Epoch: 5| Step: 4
Training loss: 2.650806099268981
Validation loss: 2.495819474714095

Epoch: 5| Step: 5
Training loss: 2.428742154315364
Validation loss: 2.49444338465269

Epoch: 5| Step: 6
Training loss: 2.760176123928946
Validation loss: 2.491804573831377

Epoch: 5| Step: 7
Training loss: 2.616104038357048
Validation loss: 2.490064902927915

Epoch: 5| Step: 8
Training loss: 2.6972711053415543
Validation loss: 2.489836030901636

Epoch: 5| Step: 9
Training loss: 2.276693522833414
Validation loss: 2.4903282157819158

Epoch: 5| Step: 10
Training loss: 2.470999356932423
Validation loss: 2.4913556894168334

Epoch: 5| Step: 11
Training loss: 1.6941017010953547
Validation loss: 2.489047696472068

Epoch: 90| Step: 0
Training loss: 2.496266247157297
Validation loss: 2.490586961705431

Epoch: 5| Step: 1
Training loss: 2.5143367714930664
Validation loss: 2.4883371303956925

Epoch: 5| Step: 2
Training loss: 2.746729900533428
Validation loss: 2.4856556324793395

Epoch: 5| Step: 3
Training loss: 2.1355968368321077
Validation loss: 2.483564404536935

Epoch: 5| Step: 4
Training loss: 2.408423197916523
Validation loss: 2.4848617660648773

Epoch: 5| Step: 5
Training loss: 2.8610728075082745
Validation loss: 2.481584625356874

Epoch: 5| Step: 6
Training loss: 2.71372275501774
Validation loss: 2.482242864901962

Epoch: 5| Step: 7
Training loss: 2.5482530668635603
Validation loss: 2.4847086516442642

Epoch: 5| Step: 8
Training loss: 2.7958882045525275
Validation loss: 2.483296846168658

Epoch: 5| Step: 9
Training loss: 2.6124969810942953
Validation loss: 2.480743513133225

Epoch: 5| Step: 10
Training loss: 2.641409762994235
Validation loss: 2.483178924447422

Epoch: 5| Step: 11
Training loss: 2.8980595838425174
Validation loss: 2.486257879239283

Epoch: 91| Step: 0
Training loss: 2.0942785250745373
Validation loss: 2.489537830548791

Epoch: 5| Step: 1
Training loss: 2.6750138790447937
Validation loss: 2.4907435436428655

Epoch: 5| Step: 2
Training loss: 2.3891416448004246
Validation loss: 2.4940271015664006

Epoch: 5| Step: 3
Training loss: 2.398150597724771
Validation loss: 2.493063857319456

Epoch: 5| Step: 4
Training loss: 2.6772875479105296
Validation loss: 2.4921879384709116

Epoch: 5| Step: 5
Training loss: 2.561367622083754
Validation loss: 2.4944011778171915

Epoch: 5| Step: 6
Training loss: 3.0482734796381115
Validation loss: 2.490452811440668

Epoch: 5| Step: 7
Training loss: 2.8442213066151196
Validation loss: 2.488952657922426

Epoch: 5| Step: 8
Training loss: 2.6971548666784804
Validation loss: 2.490576144432892

Epoch: 5| Step: 9
Training loss: 2.5385979330103887
Validation loss: 2.488167553055245

Epoch: 5| Step: 10
Training loss: 2.629627508611326
Validation loss: 2.488074868514943

Epoch: 5| Step: 11
Training loss: 2.6275411748881163
Validation loss: 2.4868586419478227

Epoch: 92| Step: 0
Training loss: 2.658351470821613
Validation loss: 2.486828206591894

Epoch: 5| Step: 1
Training loss: 2.5635430608934446
Validation loss: 2.4853836946839767

Epoch: 5| Step: 2
Training loss: 2.509782344302287
Validation loss: 2.4824335601715704

Epoch: 5| Step: 3
Training loss: 2.798872591292358
Validation loss: 2.482941907931606

Epoch: 5| Step: 4
Training loss: 2.6073080316614976
Validation loss: 2.486151977436424

Epoch: 5| Step: 5
Training loss: 2.6097772710774705
Validation loss: 2.48656136297034

Epoch: 5| Step: 6
Training loss: 2.7245937989586135
Validation loss: 2.4865581468978157

Epoch: 5| Step: 7
Training loss: 2.406322131376257
Validation loss: 2.486323793881448

Epoch: 5| Step: 8
Training loss: 2.6158072860440136
Validation loss: 2.4852611352924145

Epoch: 5| Step: 9
Training loss: 2.7672373926025613
Validation loss: 2.486967733200448

Epoch: 5| Step: 10
Training loss: 2.2313547061747188
Validation loss: 2.485702835570404

Epoch: 5| Step: 11
Training loss: 2.8764405995015676
Validation loss: 2.4844611250945894

Epoch: 93| Step: 0
Training loss: 2.4786298047663204
Validation loss: 2.4825304769455236

Epoch: 5| Step: 1
Training loss: 2.1042442936946237
Validation loss: 2.4792411589984638

Epoch: 5| Step: 2
Training loss: 2.114077039218932
Validation loss: 2.477289442118536

Epoch: 5| Step: 3
Training loss: 2.6831971254391362
Validation loss: 2.483033131742618

Epoch: 5| Step: 4
Training loss: 2.514098752876483
Validation loss: 2.4817963539137637

Epoch: 5| Step: 5
Training loss: 2.867225418047976
Validation loss: 2.4825788438793173

Epoch: 5| Step: 6
Training loss: 2.633076187648382
Validation loss: 2.4772030696906544

Epoch: 5| Step: 7
Training loss: 2.603542914394208
Validation loss: 2.475619865751797

Epoch: 5| Step: 8
Training loss: 2.236192830753255
Validation loss: 2.480049959007679

Epoch: 5| Step: 9
Training loss: 2.658009653106911
Validation loss: 2.484531825491994

Epoch: 5| Step: 10
Training loss: 3.2925763060374322
Validation loss: 2.4802703978361706

Epoch: 5| Step: 11
Training loss: 3.358154217003475
Validation loss: 2.4817832927784713

Epoch: 94| Step: 0
Training loss: 2.0502324414477604
Validation loss: 2.486647903722725

Epoch: 5| Step: 1
Training loss: 2.086882987748288
Validation loss: 2.4862426719154773

Epoch: 5| Step: 2
Training loss: 2.8336321916226006
Validation loss: 2.4852000052277665

Epoch: 5| Step: 3
Training loss: 2.759784803708572
Validation loss: 2.489375805418494

Epoch: 5| Step: 4
Training loss: 2.0683566085321443
Validation loss: 2.489337379617609

Epoch: 5| Step: 5
Training loss: 3.0459092394706664
Validation loss: 2.4912153518380444

Epoch: 5| Step: 6
Training loss: 2.5488538484992667
Validation loss: 2.4920241801640994

Epoch: 5| Step: 7
Training loss: 2.274642782147771
Validation loss: 2.4932903412713743

Epoch: 5| Step: 8
Training loss: 3.013868858243494
Validation loss: 2.495954466880264

Epoch: 5| Step: 9
Training loss: 3.14239725240832
Validation loss: 2.4927598859974616

Epoch: 5| Step: 10
Training loss: 2.533656542220746
Validation loss: 2.493116434859893

Epoch: 5| Step: 11
Training loss: 3.109132996922729
Validation loss: 2.4926367965573926

Epoch: 95| Step: 0
Training loss: 3.049665845482748
Validation loss: 2.4897904901760017

Epoch: 5| Step: 1
Training loss: 2.4024396179423295
Validation loss: 2.485936827532639

Epoch: 5| Step: 2
Training loss: 2.564967572340002
Validation loss: 2.486835786504383

Epoch: 5| Step: 3
Training loss: 3.146060169117482
Validation loss: 2.4869110051479355

Epoch: 5| Step: 4
Training loss: 2.270517578103999
Validation loss: 2.482455133574977

Epoch: 5| Step: 5
Training loss: 2.4558972287374154
Validation loss: 2.483053315673236

Epoch: 5| Step: 6
Training loss: 2.5372111452055433
Validation loss: 2.4820511143631636

Epoch: 5| Step: 7
Training loss: 2.5318886222086814
Validation loss: 2.4814016675357315

Epoch: 5| Step: 8
Training loss: 2.7048438456197452
Validation loss: 2.4776566351856806

Epoch: 5| Step: 9
Training loss: 2.620360315895436
Validation loss: 2.4787480551192154

Epoch: 5| Step: 10
Training loss: 2.3490258409451825
Validation loss: 2.481143965645489

Epoch: 5| Step: 11
Training loss: 1.8182917171556268
Validation loss: 2.479152704781933

Epoch: 96| Step: 0
Training loss: 2.6601763260989864
Validation loss: 2.481321577710058

Epoch: 5| Step: 1
Training loss: 2.0574543820187445
Validation loss: 2.492340976051176

Epoch: 5| Step: 2
Training loss: 2.7726181324316146
Validation loss: 2.4895757504803937

Epoch: 5| Step: 3
Training loss: 2.901451497376094
Validation loss: 2.4830526875533887

Epoch: 5| Step: 4
Training loss: 2.652211608741185
Validation loss: 2.481611354116247

Epoch: 5| Step: 5
Training loss: 2.742024560853126
Validation loss: 2.481562459923501

Epoch: 5| Step: 6
Training loss: 2.368591295225058
Validation loss: 2.48000873294954

Epoch: 5| Step: 7
Training loss: 2.520176720553506
Validation loss: 2.482678187814344

Epoch: 5| Step: 8
Training loss: 2.474476992130361
Validation loss: 2.4795002085178

Epoch: 5| Step: 9
Training loss: 2.3758005499565464
Validation loss: 2.4818346162800857

Epoch: 5| Step: 10
Training loss: 2.829063976223829
Validation loss: 2.4784879249525895

Epoch: 5| Step: 11
Training loss: 3.347053393427872
Validation loss: 2.4756969299113702

Epoch: 97| Step: 0
Training loss: 2.9173400283274056
Validation loss: 2.476930312191143

Epoch: 5| Step: 1
Training loss: 2.352447444640871
Validation loss: 2.478257939676182

Epoch: 5| Step: 2
Training loss: 2.0783787622613317
Validation loss: 2.4780228217323272

Epoch: 5| Step: 3
Training loss: 2.6252760969012265
Validation loss: 2.476309341183072

Epoch: 5| Step: 4
Training loss: 2.879676167242774
Validation loss: 2.4763062963323845

Epoch: 5| Step: 5
Training loss: 2.3975007156832424
Validation loss: 2.481478884411186

Epoch: 5| Step: 6
Training loss: 2.6498524534787817
Validation loss: 2.4787651118813203

Epoch: 5| Step: 7
Training loss: 2.4954076549371345
Validation loss: 2.4781447790221627

Epoch: 5| Step: 8
Training loss: 2.3023980617427555
Validation loss: 2.4784863738049108

Epoch: 5| Step: 9
Training loss: 2.73441127208085
Validation loss: 2.4769832321893603

Epoch: 5| Step: 10
Training loss: 3.0022949341838774
Validation loss: 2.473757823381073

Epoch: 5| Step: 11
Training loss: 1.848677048755927
Validation loss: 2.4680289470966597

Epoch: 98| Step: 0
Training loss: 2.3559596118023434
Validation loss: 2.4699264934158163

Epoch: 5| Step: 1
Training loss: 2.4696823484204624
Validation loss: 2.4714360091254735

Epoch: 5| Step: 2
Training loss: 2.3848532020927884
Validation loss: 2.4749870965441465

Epoch: 5| Step: 3
Training loss: 2.5848940677445915
Validation loss: 2.478524134155128

Epoch: 5| Step: 4
Training loss: 2.686725593595893
Validation loss: 2.4812338022172584

Epoch: 5| Step: 5
Training loss: 2.75863566014322
Validation loss: 2.474306484955865

Epoch: 5| Step: 6
Training loss: 3.0303724139390997
Validation loss: 2.478237075323777

Epoch: 5| Step: 7
Training loss: 2.859516911554863
Validation loss: 2.4683224352051467

Epoch: 5| Step: 8
Training loss: 2.518390722658066
Validation loss: 2.46836121230015

Epoch: 5| Step: 9
Training loss: 2.241617057090628
Validation loss: 2.470959294524845

Epoch: 5| Step: 10
Training loss: 2.550590099048265
Validation loss: 2.473494316889563

Epoch: 5| Step: 11
Training loss: 2.571716481696893
Validation loss: 2.4763228925284677

Epoch: 99| Step: 0
Training loss: 2.6303405023484463
Validation loss: 2.4751462567268163

Epoch: 5| Step: 1
Training loss: 2.6913058811734536
Validation loss: 2.4733425230586414

Epoch: 5| Step: 2
Training loss: 2.7004230203207014
Validation loss: 2.471179611639199

Epoch: 5| Step: 3
Training loss: 2.469860937551401
Validation loss: 2.4736534104742747

Epoch: 5| Step: 4
Training loss: 2.1414603949141435
Validation loss: 2.4755238341517884

Epoch: 5| Step: 5
Training loss: 3.1102634100047313
Validation loss: 2.472450701791341

Epoch: 5| Step: 6
Training loss: 2.526110104816834
Validation loss: 2.4749015950699524

Epoch: 5| Step: 7
Training loss: 3.0125308593182454
Validation loss: 2.47449422687328

Epoch: 5| Step: 8
Training loss: 2.839013147423787
Validation loss: 2.474647114221824

Epoch: 5| Step: 9
Training loss: 2.080042363248921
Validation loss: 2.4707082273407974

Epoch: 5| Step: 10
Training loss: 2.1782601444564627
Validation loss: 2.4732599992775195

Epoch: 5| Step: 11
Training loss: 1.202801301685513
Validation loss: 2.4695351434580606

Epoch: 100| Step: 0
Training loss: 2.470702546010308
Validation loss: 2.4707335659961323

Epoch: 5| Step: 1
Training loss: 3.16389672115861
Validation loss: 2.4691561916033424

Epoch: 5| Step: 2
Training loss: 2.7377448542928597
Validation loss: 2.4734121917760046

Epoch: 5| Step: 3
Training loss: 2.988986142863738
Validation loss: 2.472934624869988

Epoch: 5| Step: 4
Training loss: 2.3316387312631046
Validation loss: 2.471026891671653

Epoch: 5| Step: 5
Training loss: 2.457775882513654
Validation loss: 2.478808069874672

Epoch: 5| Step: 6
Training loss: 2.1655765016087676
Validation loss: 2.4777413660157594

Epoch: 5| Step: 7
Training loss: 2.58674521379405
Validation loss: 2.4763806433750486

Epoch: 5| Step: 8
Training loss: 2.2779964081063557
Validation loss: 2.4809414951253697

Epoch: 5| Step: 9
Training loss: 2.1367496578903165
Validation loss: 2.478373510175727

Epoch: 5| Step: 10
Training loss: 2.691053126496477
Validation loss: 2.482525390899799

Epoch: 5| Step: 11
Training loss: 3.0039589508949867
Validation loss: 2.479134087922844

Epoch: 101| Step: 0
Training loss: 2.3000018575909618
Validation loss: 2.4784509215991357

Epoch: 5| Step: 1
Training loss: 2.3697972783172454
Validation loss: 2.4791020209969363

Epoch: 5| Step: 2
Training loss: 2.5809554774846104
Validation loss: 2.479320538711751

Epoch: 5| Step: 3
Training loss: 2.9069237697121473
Validation loss: 2.4781310111474424

Epoch: 5| Step: 4
Training loss: 2.6623211760308036
Validation loss: 2.4787205901191065

Epoch: 5| Step: 5
Training loss: 2.5748242142313122
Validation loss: 2.4748229486863838

Epoch: 5| Step: 6
Training loss: 3.3255038976673714
Validation loss: 2.4728537385727756

Epoch: 5| Step: 7
Training loss: 2.651620488159329
Validation loss: 2.4737458803741093

Epoch: 5| Step: 8
Training loss: 2.1823266025802806
Validation loss: 2.47224375823162

Epoch: 5| Step: 9
Training loss: 2.4297069291199658
Validation loss: 2.472136870320532

Epoch: 5| Step: 10
Training loss: 2.210870964208368
Validation loss: 2.4704773087269127

Epoch: 5| Step: 11
Training loss: 2.2119984591721864
Validation loss: 2.4722365012512557

Epoch: 102| Step: 0
Training loss: 2.401402532527602
Validation loss: 2.477836108916919

Epoch: 5| Step: 1
Training loss: 2.2140327058562885
Validation loss: 2.4707817416945588

Epoch: 5| Step: 2
Training loss: 2.933659741996594
Validation loss: 2.472331169819829

Epoch: 5| Step: 3
Training loss: 2.549364897232631
Validation loss: 2.4744975790630015

Epoch: 5| Step: 4
Training loss: 2.5785760658322094
Validation loss: 2.469598230074903

Epoch: 5| Step: 5
Training loss: 2.6997011584450727
Validation loss: 2.461672520745698

Epoch: 5| Step: 6
Training loss: 2.836781946149115
Validation loss: 2.465711043048718

Epoch: 5| Step: 7
Training loss: 2.634517129161474
Validation loss: 2.4645043132837365

Epoch: 5| Step: 8
Training loss: 2.5636454557458044
Validation loss: 2.4643151169293733

Epoch: 5| Step: 9
Training loss: 2.6231825758655196
Validation loss: 2.4676101523873233

Epoch: 5| Step: 10
Training loss: 2.1028128949279914
Validation loss: 2.4715004439856783

Epoch: 5| Step: 11
Training loss: 2.8764982880445187
Validation loss: 2.4665899524701937

Epoch: 103| Step: 0
Training loss: 2.739734737336671
Validation loss: 2.4660827899892257

Epoch: 5| Step: 1
Training loss: 2.343589370309397
Validation loss: 2.4669641361026473

Epoch: 5| Step: 2
Training loss: 2.739799133233367
Validation loss: 2.4657316306505592

Epoch: 5| Step: 3
Training loss: 2.5211540732719087
Validation loss: 2.4651322918857836

Epoch: 5| Step: 4
Training loss: 2.790247561228554
Validation loss: 2.470982821468507

Epoch: 5| Step: 5
Training loss: 2.441305759650616
Validation loss: 2.464479241117139

Epoch: 5| Step: 6
Training loss: 2.5483846110475503
Validation loss: 2.467906799859151

Epoch: 5| Step: 7
Training loss: 2.3660534449302615
Validation loss: 2.4662525807808806

Epoch: 5| Step: 8
Training loss: 2.759300716519196
Validation loss: 2.462997510840887

Epoch: 5| Step: 9
Training loss: 2.343657936831189
Validation loss: 2.4622912765447964

Epoch: 5| Step: 10
Training loss: 2.4142278225778697
Validation loss: 2.462250523750507

Epoch: 5| Step: 11
Training loss: 3.2634348848911947
Validation loss: 2.461710135459859

Epoch: 104| Step: 0
Training loss: 2.2861546088038804
Validation loss: 2.4662210694021316

Epoch: 5| Step: 1
Training loss: 2.895761411217402
Validation loss: 2.468514229988507

Epoch: 5| Step: 2
Training loss: 2.3265034193501206
Validation loss: 2.4679331937222897

Epoch: 5| Step: 3
Training loss: 2.9626096165975775
Validation loss: 2.470180233996133

Epoch: 5| Step: 4
Training loss: 2.7306268779934157
Validation loss: 2.4779912154847876

Epoch: 5| Step: 5
Training loss: 2.806220185731056
Validation loss: 2.4751444345773432

Epoch: 5| Step: 6
Training loss: 2.3887435390798246
Validation loss: 2.468554802915792

Epoch: 5| Step: 7
Training loss: 2.5258644172906255
Validation loss: 2.4693943502649103

Epoch: 5| Step: 8
Training loss: 2.4970806242454273
Validation loss: 2.45985297066712

Epoch: 5| Step: 9
Training loss: 2.3504406860761677
Validation loss: 2.4665245576359407

Epoch: 5| Step: 10
Training loss: 2.271153407039984
Validation loss: 2.468942634696344

Epoch: 5| Step: 11
Training loss: 3.2348630969929193
Validation loss: 2.4751367285559276

Epoch: 105| Step: 0
Training loss: 1.8279983607061536
Validation loss: 2.4734444569730645

Epoch: 5| Step: 1
Training loss: 2.7862123089616
Validation loss: 2.468403924756414

Epoch: 5| Step: 2
Training loss: 3.0188511801876086
Validation loss: 2.468928676690307

Epoch: 5| Step: 3
Training loss: 3.0340923079428017
Validation loss: 2.4683715353161793

Epoch: 5| Step: 4
Training loss: 2.174939415625043
Validation loss: 2.4709628123237266

Epoch: 5| Step: 5
Training loss: 2.50895489018051
Validation loss: 2.4771508180929223

Epoch: 5| Step: 6
Training loss: 2.350553784152493
Validation loss: 2.472169278741156

Epoch: 5| Step: 7
Training loss: 3.0491027512844866
Validation loss: 2.4715019774107803

Epoch: 5| Step: 8
Training loss: 2.082118277672236
Validation loss: 2.4741627832893824

Epoch: 5| Step: 9
Training loss: 2.6724769851078976
Validation loss: 2.4739782928197043

Epoch: 5| Step: 10
Training loss: 2.481067495096046
Validation loss: 2.4722692378594293

Epoch: 5| Step: 11
Training loss: 2.032455438779955
Validation loss: 2.4752120057251004

Epoch: 106| Step: 0
Training loss: 2.469148724383815
Validation loss: 2.471501563406194

Epoch: 5| Step: 1
Training loss: 2.298215513835608
Validation loss: 2.468075342181916

Epoch: 5| Step: 2
Training loss: 2.594175280899694
Validation loss: 2.465306633047617

Epoch: 5| Step: 3
Training loss: 2.171732067646702
Validation loss: 2.4691399857771135

Epoch: 5| Step: 4
Training loss: 2.815483714632937
Validation loss: 2.466098532513446

Epoch: 5| Step: 5
Training loss: 2.3734278243610385
Validation loss: 2.467260752535274

Epoch: 5| Step: 6
Training loss: 2.3407643947678167
Validation loss: 2.4693445222184365

Epoch: 5| Step: 7
Training loss: 3.0303920829576882
Validation loss: 2.468834436960484

Epoch: 5| Step: 8
Training loss: 2.6425985150843987
Validation loss: 2.4651144516858814

Epoch: 5| Step: 9
Training loss: 2.6809683983095316
Validation loss: 2.467411603970753

Epoch: 5| Step: 10
Training loss: 2.700776860832464
Validation loss: 2.468967750056466

Epoch: 5| Step: 11
Training loss: 1.975197784564111
Validation loss: 2.4660602193524834

Epoch: 107| Step: 0
Training loss: 2.611970353167121
Validation loss: 2.4677715052426152

Epoch: 5| Step: 1
Training loss: 2.1005403096073056
Validation loss: 2.4668710616416734

Epoch: 5| Step: 2
Training loss: 2.1924434933835095
Validation loss: 2.4665687276324286

Epoch: 5| Step: 3
Training loss: 2.8198875043628893
Validation loss: 2.464647211701843

Epoch: 5| Step: 4
Training loss: 2.7634128840108367
Validation loss: 2.4573509521792793

Epoch: 5| Step: 5
Training loss: 2.935524458809124
Validation loss: 2.458502619512762

Epoch: 5| Step: 6
Training loss: 2.1680194470775613
Validation loss: 2.462913093595495

Epoch: 5| Step: 7
Training loss: 2.5873173377389467
Validation loss: 2.4638747553961777

Epoch: 5| Step: 8
Training loss: 1.9610291113864058
Validation loss: 2.4656490535876268

Epoch: 5| Step: 9
Training loss: 2.39787499606738
Validation loss: 2.4667719026511175

Epoch: 5| Step: 10
Training loss: 3.0914882522747256
Validation loss: 2.462681292784581

Epoch: 5| Step: 11
Training loss: 3.371677175804979
Validation loss: 2.461098293319383

Epoch: 108| Step: 0
Training loss: 2.865272651733935
Validation loss: 2.4671386820219574

Epoch: 5| Step: 1
Training loss: 2.4668805734142807
Validation loss: 2.467046959070958

Epoch: 5| Step: 2
Training loss: 2.606674350067028
Validation loss: 2.4669885669124274

Epoch: 5| Step: 3
Training loss: 2.700111340946799
Validation loss: 2.4659233288286657

Epoch: 5| Step: 4
Training loss: 2.8292513969966024
Validation loss: 2.469979092905877

Epoch: 5| Step: 5
Training loss: 2.3577757208744576
Validation loss: 2.4683196099067453

Epoch: 5| Step: 6
Training loss: 2.887656507337761
Validation loss: 2.4662433042401517

Epoch: 5| Step: 7
Training loss: 2.2525528095248926
Validation loss: 2.466520920734932

Epoch: 5| Step: 8
Training loss: 2.2099889870623817
Validation loss: 2.4636385349533696

Epoch: 5| Step: 9
Training loss: 2.4132669366305257
Validation loss: 2.4585292678812154

Epoch: 5| Step: 10
Training loss: 2.198888506579557
Validation loss: 2.462198483376073

Epoch: 5| Step: 11
Training loss: 3.2811070002321863
Validation loss: 2.463101500262184

Epoch: 109| Step: 0
Training loss: 2.5288541781980713
Validation loss: 2.462276776518871

Epoch: 5| Step: 1
Training loss: 2.3542146143348743
Validation loss: 2.463973611676944

Epoch: 5| Step: 2
Training loss: 2.776212609463096
Validation loss: 2.4589502939736363

Epoch: 5| Step: 3
Training loss: 1.9952616590267498
Validation loss: 2.46484463263978

Epoch: 5| Step: 4
Training loss: 2.273869529128276
Validation loss: 2.466510561780409

Epoch: 5| Step: 5
Training loss: 2.9614782317722246
Validation loss: 2.4646396461775613

Epoch: 5| Step: 6
Training loss: 2.202779431667832
Validation loss: 2.465905752181078

Epoch: 5| Step: 7
Training loss: 2.521632065351774
Validation loss: 2.459819152065467

Epoch: 5| Step: 8
Training loss: 2.3593619643097563
Validation loss: 2.4617886115995917

Epoch: 5| Step: 9
Training loss: 2.6309833454922917
Validation loss: 2.4622432252133106

Epoch: 5| Step: 10
Training loss: 3.060258005771678
Validation loss: 2.4650693811320727

Epoch: 5| Step: 11
Training loss: 3.420491814302292
Validation loss: 2.464647856604277

Epoch: 110| Step: 0
Training loss: 2.4645772508775643
Validation loss: 2.460727137702696

Epoch: 5| Step: 1
Training loss: 2.7541443201063593
Validation loss: 2.474004913025426

Epoch: 5| Step: 2
Training loss: 2.4306594523673133
Validation loss: 2.4877398953502694

Epoch: 5| Step: 3
Training loss: 1.8290994117671218
Validation loss: 2.481645864493873

Epoch: 5| Step: 4
Training loss: 2.6897146282066737
Validation loss: 2.492606164730398

Epoch: 5| Step: 5
Training loss: 2.3811929170269606
Validation loss: 2.491943797888869

Epoch: 5| Step: 6
Training loss: 2.4038734094101626
Validation loss: 2.4921537175773807

Epoch: 5| Step: 7
Training loss: 2.748000371630337
Validation loss: 2.487430289264536

Epoch: 5| Step: 8
Training loss: 2.830232793716089
Validation loss: 2.4882229808650047

Epoch: 5| Step: 9
Training loss: 3.1257344717936584
Validation loss: 2.4797007976416605

Epoch: 5| Step: 10
Training loss: 2.444860349540166
Validation loss: 2.473250009961734

Epoch: 5| Step: 11
Training loss: 2.6181771755779413
Validation loss: 2.474500007892238

Epoch: 111| Step: 0
Training loss: 2.147457828840406
Validation loss: 2.4716613358894355

Epoch: 5| Step: 1
Training loss: 2.5191506268336297
Validation loss: 2.467515524119995

Epoch: 5| Step: 2
Training loss: 3.061740391784478
Validation loss: 2.4722116742611533

Epoch: 5| Step: 3
Training loss: 2.4430379313062804
Validation loss: 2.47117824082359

Epoch: 5| Step: 4
Training loss: 2.7024754973226215
Validation loss: 2.4703789660435422

Epoch: 5| Step: 5
Training loss: 2.429211928751297
Validation loss: 2.4767456508426426

Epoch: 5| Step: 6
Training loss: 2.337830455901272
Validation loss: 2.4755359732396784

Epoch: 5| Step: 7
Training loss: 2.7746549271489953
Validation loss: 2.470689872535275

Epoch: 5| Step: 8
Training loss: 2.3949632363892364
Validation loss: 2.471295722187282

Epoch: 5| Step: 9
Training loss: 2.423108186857798
Validation loss: 2.468395022532142

Epoch: 5| Step: 10
Training loss: 2.8344478845951357
Validation loss: 2.474445926734999

Epoch: 5| Step: 11
Training loss: 2.719869098318392
Validation loss: 2.4739414107429893

Epoch: 112| Step: 0
Training loss: 2.2155845520029187
Validation loss: 2.4704591009885974

Epoch: 5| Step: 1
Training loss: 2.678788370702278
Validation loss: 2.473748767743889

Epoch: 5| Step: 2
Training loss: 2.29150655938545
Validation loss: 2.475328641483354

Epoch: 5| Step: 3
Training loss: 2.3728764727913996
Validation loss: 2.4795409943107924

Epoch: 5| Step: 4
Training loss: 3.235660758127621
Validation loss: 2.4776003374785582

Epoch: 5| Step: 5
Training loss: 1.8322181199670913
Validation loss: 2.4782652992790415

Epoch: 5| Step: 6
Training loss: 2.997695037376113
Validation loss: 2.4826877990801353

Epoch: 5| Step: 7
Training loss: 2.218583758936376
Validation loss: 2.4835639365439643

Epoch: 5| Step: 8
Training loss: 2.601028891702511
Validation loss: 2.4794244745721117

Epoch: 5| Step: 9
Training loss: 2.752971344382637
Validation loss: 2.4829222152152055

Epoch: 5| Step: 10
Training loss: 2.6565515683591694
Validation loss: 2.4797980095015926

Epoch: 5| Step: 11
Training loss: 2.939431063040131
Validation loss: 2.4749529328350244

Epoch: 113| Step: 0
Training loss: 2.4868732103608338
Validation loss: 2.469714821229103

Epoch: 5| Step: 1
Training loss: 2.437171131347596
Validation loss: 2.468685211667457

Epoch: 5| Step: 2
Training loss: 2.7010902287631335
Validation loss: 2.462757596066787

Epoch: 5| Step: 3
Training loss: 2.6450180439613
Validation loss: 2.468706613473273

Epoch: 5| Step: 4
Training loss: 2.8724377036249287
Validation loss: 2.478498185749992

Epoch: 5| Step: 5
Training loss: 2.7024376496948603
Validation loss: 2.4732837995534953

Epoch: 5| Step: 6
Training loss: 2.2482379795645184
Validation loss: 2.4701300859912583

Epoch: 5| Step: 7
Training loss: 2.470467368476515
Validation loss: 2.468450962739368

Epoch: 5| Step: 8
Training loss: 2.385441764688404
Validation loss: 2.467055624557294

Epoch: 5| Step: 9
Training loss: 2.708745240408426
Validation loss: 2.4620992431238484

Epoch: 5| Step: 10
Training loss: 2.570179851784699
Validation loss: 2.466018239755149

Epoch: 5| Step: 11
Training loss: 1.9509467834222454
Validation loss: 2.4650271428595327

Epoch: 114| Step: 0
Training loss: 2.8447629361195856
Validation loss: 2.4699634434881554

Epoch: 5| Step: 1
Training loss: 2.857116307407729
Validation loss: 2.470645635486353

Epoch: 5| Step: 2
Training loss: 2.429703690944094
Validation loss: 2.4727789922203836

Epoch: 5| Step: 3
Training loss: 1.8577863814921813
Validation loss: 2.465492560129874

Epoch: 5| Step: 4
Training loss: 2.7159167906665447
Validation loss: 2.470391918581065

Epoch: 5| Step: 5
Training loss: 2.5393849329527654
Validation loss: 2.470200591314224

Epoch: 5| Step: 6
Training loss: 2.7905442178104214
Validation loss: 2.4660012438776904

Epoch: 5| Step: 7
Training loss: 2.6440431941799303
Validation loss: 2.464717263242392

Epoch: 5| Step: 8
Training loss: 2.235047885970631
Validation loss: 2.4673470039500023

Epoch: 5| Step: 9
Training loss: 2.9830176976772633
Validation loss: 2.4635563433951266

Epoch: 5| Step: 10
Training loss: 2.3001475991697378
Validation loss: 2.46109123355305

Epoch: 5| Step: 11
Training loss: 1.4978157670900498
Validation loss: 2.4568472400650636

Epoch: 115| Step: 0
Training loss: 2.897431314623597
Validation loss: 2.4615822971644477

Epoch: 5| Step: 1
Training loss: 2.579321288946957
Validation loss: 2.465045805809204

Epoch: 5| Step: 2
Training loss: 1.9642763930260585
Validation loss: 2.456450918908607

Epoch: 5| Step: 3
Training loss: 2.5831676758185953
Validation loss: 2.461373959544249

Epoch: 5| Step: 4
Training loss: 2.1846899239438393
Validation loss: 2.4640460287739776

Epoch: 5| Step: 5
Training loss: 2.572844490140587
Validation loss: 2.4579201259438883

Epoch: 5| Step: 6
Training loss: 2.5473876624378313
Validation loss: 2.461054337972478

Epoch: 5| Step: 7
Training loss: 2.644471836972235
Validation loss: 2.4625302403266573

Epoch: 5| Step: 8
Training loss: 2.866840227181067
Validation loss: 2.4616797281584657

Epoch: 5| Step: 9
Training loss: 2.3916874936711134
Validation loss: 2.4680351075318985

Epoch: 5| Step: 10
Training loss: 2.4646129469867253
Validation loss: 2.4595957978859184

Epoch: 5| Step: 11
Training loss: 3.4566770210466626
Validation loss: 2.4599066134304177

Epoch: 116| Step: 0
Training loss: 2.6956629428541414
Validation loss: 2.4604722042313454

Epoch: 5| Step: 1
Training loss: 2.532500346749556
Validation loss: 2.462980486052053

Epoch: 5| Step: 2
Training loss: 2.0189420626424943
Validation loss: 2.4622886057061475

Epoch: 5| Step: 3
Training loss: 2.686960831606892
Validation loss: 2.465714938993604

Epoch: 5| Step: 4
Training loss: 2.7332941153279187
Validation loss: 2.464551699788179

Epoch: 5| Step: 5
Training loss: 2.3969656438485987
Validation loss: 2.4652497712336916

Epoch: 5| Step: 6
Training loss: 2.2362430473036174
Validation loss: 2.4694097739857357

Epoch: 5| Step: 7
Training loss: 2.499791136599923
Validation loss: 2.4770293973970627

Epoch: 5| Step: 8
Training loss: 2.933442905575876
Validation loss: 2.480883902503226

Epoch: 5| Step: 9
Training loss: 3.0585557099725778
Validation loss: 2.4795833138698944

Epoch: 5| Step: 10
Training loss: 2.3194420206002713
Validation loss: 2.473407046816771

Epoch: 5| Step: 11
Training loss: 2.1351951174054538
Validation loss: 2.4787845771264405

Epoch: 117| Step: 0
Training loss: 2.565980826641472
Validation loss: 2.4756593350998335

Epoch: 5| Step: 1
Training loss: 2.5700852313918796
Validation loss: 2.4702105326381467

Epoch: 5| Step: 2
Training loss: 2.6682141304275016
Validation loss: 2.4712679251337666

Epoch: 5| Step: 3
Training loss: 2.4913927682563854
Validation loss: 2.4664710306113102

Epoch: 5| Step: 4
Training loss: 2.346248464853133
Validation loss: 2.465930701073078

Epoch: 5| Step: 5
Training loss: 2.7101758607059745
Validation loss: 2.464499484291417

Epoch: 5| Step: 6
Training loss: 2.689205072359416
Validation loss: 2.4711224186364227

Epoch: 5| Step: 7
Training loss: 2.385240762102346
Validation loss: 2.464470163478815

Epoch: 5| Step: 8
Training loss: 2.817817662363272
Validation loss: 2.4561402080351806

Epoch: 5| Step: 9
Training loss: 2.7910878924229494
Validation loss: 2.4583514274858005

Epoch: 5| Step: 10
Training loss: 2.371703218815982
Validation loss: 2.454984272144435

Epoch: 5| Step: 11
Training loss: 0.3351408472501043
Validation loss: 2.459597134767645

Epoch: 118| Step: 0
Training loss: 2.3116087355868964
Validation loss: 2.4574109235422608

Epoch: 5| Step: 1
Training loss: 2.775625649795508
Validation loss: 2.4601385605952313

Epoch: 5| Step: 2
Training loss: 2.445827052180355
Validation loss: 2.4606868999790166

Epoch: 5| Step: 3
Training loss: 2.5150734433016892
Validation loss: 2.456752213410291

Epoch: 5| Step: 4
Training loss: 2.779387203847703
Validation loss: 2.4581198734346703

Epoch: 5| Step: 5
Training loss: 2.427894249437194
Validation loss: 2.4589608059764325

Epoch: 5| Step: 6
Training loss: 2.196027428905627
Validation loss: 2.4562096649883145

Epoch: 5| Step: 7
Training loss: 3.0318936323365198
Validation loss: 2.459848992744911

Epoch: 5| Step: 8
Training loss: 2.5511685554927874
Validation loss: 2.4571331470022786

Epoch: 5| Step: 9
Training loss: 2.48942101453528
Validation loss: 2.4570943099573426

Epoch: 5| Step: 10
Training loss: 2.232195558198314
Validation loss: 2.463637430105391

Epoch: 5| Step: 11
Training loss: 2.5758524733586854
Validation loss: 2.458647501127312

Epoch: 119| Step: 0
Training loss: 2.5887736185231467
Validation loss: 2.4591296382595242

Epoch: 5| Step: 1
Training loss: 2.929497064123133
Validation loss: 2.4613485083911253

Epoch: 5| Step: 2
Training loss: 2.304520940419406
Validation loss: 2.459535322412751

Epoch: 5| Step: 3
Training loss: 3.017603408065603
Validation loss: 2.4661083977236937

Epoch: 5| Step: 4
Training loss: 2.1955516318407575
Validation loss: 2.462355573488497

Epoch: 5| Step: 5
Training loss: 2.241541965613394
Validation loss: 2.4634709069142158

Epoch: 5| Step: 6
Training loss: 2.451699881658214
Validation loss: 2.4625155763085056

Epoch: 5| Step: 7
Training loss: 2.6127211992718458
Validation loss: 2.461565520871617

Epoch: 5| Step: 8
Training loss: 2.6088758893567348
Validation loss: 2.457191573240742

Epoch: 5| Step: 9
Training loss: 2.4496627964818516
Validation loss: 2.4580539946069093

Epoch: 5| Step: 10
Training loss: 2.416639218229313
Validation loss: 2.463246798997804

Epoch: 5| Step: 11
Training loss: 2.9216626748034
Validation loss: 2.4593698261599184

Epoch: 120| Step: 0
Training loss: 2.7460960073448226
Validation loss: 2.4552682232960064

Epoch: 5| Step: 1
Training loss: 2.6187471667436006
Validation loss: 2.462791172634354

Epoch: 5| Step: 2
Training loss: 2.527442706144497
Validation loss: 2.4560722739750998

Epoch: 5| Step: 3
Training loss: 2.6582411539803616
Validation loss: 2.471110398570832

Epoch: 5| Step: 4
Training loss: 2.7419199582082
Validation loss: 2.465786821496726

Epoch: 5| Step: 5
Training loss: 2.8673907215743895
Validation loss: 2.4551625526820087

Epoch: 5| Step: 6
Training loss: 2.315213750441975
Validation loss: 2.449176534464313

Epoch: 5| Step: 7
Training loss: 2.761037523997698
Validation loss: 2.4507214298229667

Epoch: 5| Step: 8
Training loss: 2.07957946817748
Validation loss: 2.4567173452554663

Epoch: 5| Step: 9
Training loss: 2.687322566362958
Validation loss: 2.4571324152251988

Epoch: 5| Step: 10
Training loss: 1.908449811032147
Validation loss: 2.4577030826051294

Epoch: 5| Step: 11
Training loss: 1.895926427826147
Validation loss: 2.464353461252464

Epoch: 121| Step: 0
Training loss: 2.420246585862059
Validation loss: 2.461980201188891

Epoch: 5| Step: 1
Training loss: 2.64451123544171
Validation loss: 2.4627111633244074

Epoch: 5| Step: 2
Training loss: 2.5007618696897236
Validation loss: 2.447651225098161

Epoch: 5| Step: 3
Training loss: 2.378457413849285
Validation loss: 2.4552861269469535

Epoch: 5| Step: 4
Training loss: 2.3118208841681644
Validation loss: 2.4581838430330083

Epoch: 5| Step: 5
Training loss: 2.831034307284784
Validation loss: 2.4736595629262075

Epoch: 5| Step: 6
Training loss: 2.0773853333705863
Validation loss: 2.460105192127674

Epoch: 5| Step: 7
Training loss: 2.464192590079395
Validation loss: 2.4592588805237106

Epoch: 5| Step: 8
Training loss: 2.7814529859213195
Validation loss: 2.453619959681391

Epoch: 5| Step: 9
Training loss: 2.772384228641164
Validation loss: 2.4550356784126275

Epoch: 5| Step: 10
Training loss: 2.8342320381962183
Validation loss: 2.451187409330185

Epoch: 5| Step: 11
Training loss: 1.8838885386351754
Validation loss: 2.454544911815335

Epoch: 122| Step: 0
Training loss: 2.3488593803139364
Validation loss: 2.465688408574966

Epoch: 5| Step: 1
Training loss: 2.575646613700764
Validation loss: 2.4686279427659588

Epoch: 5| Step: 2
Training loss: 2.78714136801671
Validation loss: 2.4683817375527606

Epoch: 5| Step: 3
Training loss: 2.4153123107902186
Validation loss: 2.475692632358548

Epoch: 5| Step: 4
Training loss: 2.5915822541778755
Validation loss: 2.47769146326345

Epoch: 5| Step: 5
Training loss: 3.1545119835224926
Validation loss: 2.4770767608589606

Epoch: 5| Step: 6
Training loss: 2.737887409963202
Validation loss: 2.479645487816642

Epoch: 5| Step: 7
Training loss: 2.4034181254856772
Validation loss: 2.4786914014598738

Epoch: 5| Step: 8
Training loss: 2.2140090149831173
Validation loss: 2.477750006128303

Epoch: 5| Step: 9
Training loss: 2.3132073635062618
Validation loss: 2.4742213915790816

Epoch: 5| Step: 10
Training loss: 2.2280768347800195
Validation loss: 2.4664697256490262

Epoch: 5| Step: 11
Training loss: 3.434192522805238
Validation loss: 2.47443283884505

Epoch: 123| Step: 0
Training loss: 2.396443883527372
Validation loss: 2.4666634647138106

Epoch: 5| Step: 1
Training loss: 2.6495060298380975
Validation loss: 2.4717774720369197

Epoch: 5| Step: 2
Training loss: 2.259949197788949
Validation loss: 2.468429411824043

Epoch: 5| Step: 3
Training loss: 2.528905277057563
Validation loss: 2.471098629704145

Epoch: 5| Step: 4
Training loss: 2.6154976470825835
Validation loss: 2.467025879101419

Epoch: 5| Step: 5
Training loss: 2.4849327948710473
Validation loss: 2.4687649489002483

Epoch: 5| Step: 6
Training loss: 2.900605986848676
Validation loss: 2.462444110662131

Epoch: 5| Step: 7
Training loss: 2.424090448857456
Validation loss: 2.462589831416133

Epoch: 5| Step: 8
Training loss: 2.6185004286096474
Validation loss: 2.463078763160484

Epoch: 5| Step: 9
Training loss: 2.5829119082207703
Validation loss: 2.4598594403299074

Epoch: 5| Step: 10
Training loss: 2.655072388748723
Validation loss: 2.4628616359536366

Epoch: 5| Step: 11
Training loss: 1.9460251203799452
Validation loss: 2.459841650735555

Epoch: 124| Step: 0
Training loss: 2.567326907495649
Validation loss: 2.45904030305759

Epoch: 5| Step: 1
Training loss: 2.9228027829102814
Validation loss: 2.460284926666459

Epoch: 5| Step: 2
Training loss: 2.3886403341386546
Validation loss: 2.4561431646368277

Epoch: 5| Step: 3
Training loss: 2.4016749497781937
Validation loss: 2.4607605078290478

Epoch: 5| Step: 4
Training loss: 2.575412687545325
Validation loss: 2.464523750083677

Epoch: 5| Step: 5
Training loss: 2.3486867156951066
Validation loss: 2.458281475398416

Epoch: 5| Step: 6
Training loss: 2.3517552293646533
Validation loss: 2.457556174707613

Epoch: 5| Step: 7
Training loss: 2.729279396893281
Validation loss: 2.4647664835366725

Epoch: 5| Step: 8
Training loss: 2.685036883393885
Validation loss: 2.463810187633123

Epoch: 5| Step: 9
Training loss: 2.4341121507194927
Validation loss: 2.4623034849033063

Epoch: 5| Step: 10
Training loss: 2.4368568941408877
Validation loss: 2.4625500840130097

Epoch: 5| Step: 11
Training loss: 1.7454873894722474
Validation loss: 2.4653625425950367

Epoch: 125| Step: 0
Training loss: 2.695582810267887
Validation loss: 2.4629013299268205

Epoch: 5| Step: 1
Training loss: 2.4583521265723216
Validation loss: 2.455996082534472

Epoch: 5| Step: 2
Training loss: 2.347889715636314
Validation loss: 2.459810780133003

Epoch: 5| Step: 3
Training loss: 2.2489586645647033
Validation loss: 2.4568198092341382

Epoch: 5| Step: 4
Training loss: 2.5498655582965473
Validation loss: 2.4632053179238462

Epoch: 5| Step: 5
Training loss: 2.7744471471815175
Validation loss: 2.460415323554783

Epoch: 5| Step: 6
Training loss: 2.3956762068819346
Validation loss: 2.463395283055129

Epoch: 5| Step: 7
Training loss: 2.3508440612129893
Validation loss: 2.4645377491604683

Epoch: 5| Step: 8
Training loss: 2.4743128044095277
Validation loss: 2.4639087360521215

Epoch: 5| Step: 9
Training loss: 2.7563943215297986
Validation loss: 2.463427012049127

Epoch: 5| Step: 10
Training loss: 2.7327752365442053
Validation loss: 2.459246406602446

Epoch: 5| Step: 11
Training loss: 1.8255272691498055
Validation loss: 2.4598753922971626

Epoch: 126| Step: 0
Training loss: 2.456369477683432
Validation loss: 2.4625458805050777

Epoch: 5| Step: 1
Training loss: 2.6238316251825973
Validation loss: 2.460046764419691

Epoch: 5| Step: 2
Training loss: 2.9129679160742787
Validation loss: 2.4580589211320745

Epoch: 5| Step: 3
Training loss: 1.977782223669096
Validation loss: 2.4621640292470524

Epoch: 5| Step: 4
Training loss: 2.5885120495049136
Validation loss: 2.460330989313846

Epoch: 5| Step: 5
Training loss: 2.60776730653105
Validation loss: 2.4600877011116076

Epoch: 5| Step: 6
Training loss: 2.8803746943977537
Validation loss: 2.457760220064792

Epoch: 5| Step: 7
Training loss: 2.076016955907297
Validation loss: 2.4580894964864473

Epoch: 5| Step: 8
Training loss: 2.318447300979829
Validation loss: 2.450171298085089

Epoch: 5| Step: 9
Training loss: 2.7147254533860257
Validation loss: 2.456177531330834

Epoch: 5| Step: 10
Training loss: 2.2440383130847033
Validation loss: 2.457113841760502

Epoch: 5| Step: 11
Training loss: 2.8439927888287895
Validation loss: 2.460796558037733

Epoch: 127| Step: 0
Training loss: 2.187633401345308
Validation loss: 2.473122852527919

Epoch: 5| Step: 1
Training loss: 2.411507349909893
Validation loss: 2.474217810157346

Epoch: 5| Step: 2
Training loss: 2.8713390427210777
Validation loss: 2.469603179830225

Epoch: 5| Step: 3
Training loss: 2.173566530018969
Validation loss: 2.4670575332151565

Epoch: 5| Step: 4
Training loss: 2.550582340540863
Validation loss: 2.4949891178834083

Epoch: 5| Step: 5
Training loss: 2.5995838785963246
Validation loss: 2.5085783607995342

Epoch: 5| Step: 6
Training loss: 2.8771836653959695
Validation loss: 2.4842819740264956

Epoch: 5| Step: 7
Training loss: 2.7478887950379325
Validation loss: 2.4797598318869154

Epoch: 5| Step: 8
Training loss: 2.8081426138784993
Validation loss: 2.465985512817752

Epoch: 5| Step: 9
Training loss: 2.6348086071538077
Validation loss: 2.4616344050456624

Epoch: 5| Step: 10
Training loss: 1.9906772648583941
Validation loss: 2.4579032034040984

Epoch: 5| Step: 11
Training loss: 1.0278237965451007
Validation loss: 2.45921729784708

Epoch: 128| Step: 0
Training loss: 2.525371459982625
Validation loss: 2.470339886849119

Epoch: 5| Step: 1
Training loss: 2.652936776429828
Validation loss: 2.465175088495858

Epoch: 5| Step: 2
Training loss: 2.3616573586972596
Validation loss: 2.4695009988591097

Epoch: 5| Step: 3
Training loss: 2.501137284041611
Validation loss: 2.4675151819137615

Epoch: 5| Step: 4
Training loss: 2.5321031239497658
Validation loss: 2.468258056235434

Epoch: 5| Step: 5
Training loss: 2.4606530403552966
Validation loss: 2.4667229760891045

Epoch: 5| Step: 6
Training loss: 2.8295500310642856
Validation loss: 2.4687548086063216

Epoch: 5| Step: 7
Training loss: 2.3720123170851295
Validation loss: 2.4680402757649547

Epoch: 5| Step: 8
Training loss: 2.711851729877592
Validation loss: 2.4659092449605824

Epoch: 5| Step: 9
Training loss: 2.8925784546969764
Validation loss: 2.465205430519907

Epoch: 5| Step: 10
Training loss: 2.4520101747535077
Validation loss: 2.46649726262338

Epoch: 5| Step: 11
Training loss: 1.431998214715239
Validation loss: 2.462592453520038

Epoch: 129| Step: 0
Training loss: 2.3399820175458066
Validation loss: 2.461007071828621

Epoch: 5| Step: 1
Training loss: 2.3979588133430276
Validation loss: 2.463410762483847

Epoch: 5| Step: 2
Training loss: 2.7095893783849956
Validation loss: 2.4570908491207186

Epoch: 5| Step: 3
Training loss: 2.2493967731139626
Validation loss: 2.4649298764198164

Epoch: 5| Step: 4
Training loss: 2.408367859835996
Validation loss: 2.4702421499646907

Epoch: 5| Step: 5
Training loss: 2.548542436395726
Validation loss: 2.4603552841057836

Epoch: 5| Step: 6
Training loss: 2.3717986163680136
Validation loss: 2.4666810560988086

Epoch: 5| Step: 7
Training loss: 2.7809185730701262
Validation loss: 2.468888635002179

Epoch: 5| Step: 8
Training loss: 2.234933103204559
Validation loss: 2.4743047123743187

Epoch: 5| Step: 9
Training loss: 2.84194570459719
Validation loss: 2.479459217719242

Epoch: 5| Step: 10
Training loss: 2.6208057501169733
Validation loss: 2.491523913426744

Epoch: 5| Step: 11
Training loss: 2.7243839512481274
Validation loss: 2.4799705946304442

Epoch: 130| Step: 0
Training loss: 2.4590302357779112
Validation loss: 2.486924001404782

Epoch: 5| Step: 1
Training loss: 2.4190518567888826
Validation loss: 2.483945273575358

Epoch: 5| Step: 2
Training loss: 2.9392743534715478
Validation loss: 2.4879481972535427

Epoch: 5| Step: 3
Training loss: 2.5243653283497065
Validation loss: 2.4752536207035902

Epoch: 5| Step: 4
Training loss: 2.47680893884273
Validation loss: 2.4749632082879325

Epoch: 5| Step: 5
Training loss: 2.464390829462599
Validation loss: 2.4709230106498707

Epoch: 5| Step: 6
Training loss: 2.6758683907457566
Validation loss: 2.453934509606894

Epoch: 5| Step: 7
Training loss: 2.5321079260195902
Validation loss: 2.4604388503825

Epoch: 5| Step: 8
Training loss: 2.7726361903596
Validation loss: 2.4647090409552646

Epoch: 5| Step: 9
Training loss: 2.399493156002051
Validation loss: 2.4668832272003485

Epoch: 5| Step: 10
Training loss: 2.22171660340209
Validation loss: 2.467815037024372

Epoch: 5| Step: 11
Training loss: 2.722630329638094
Validation loss: 2.4656793998515654

Epoch: 131| Step: 0
Training loss: 2.4251875342777134
Validation loss: 2.4675178752768314

Epoch: 5| Step: 1
Training loss: 2.1131140454157
Validation loss: 2.461379666442875

Epoch: 5| Step: 2
Training loss: 2.1096411643055717
Validation loss: 2.469026119548517

Epoch: 5| Step: 3
Training loss: 2.143429888522533
Validation loss: 2.46599256260094

Epoch: 5| Step: 4
Training loss: 2.9163907238444535
Validation loss: 2.4696746454681087

Epoch: 5| Step: 5
Training loss: 2.348313834563129
Validation loss: 2.470752724613307

Epoch: 5| Step: 6
Training loss: 2.7746288910579127
Validation loss: 2.470830394899659

Epoch: 5| Step: 7
Training loss: 2.5799883957535354
Validation loss: 2.4711172488093576

Epoch: 5| Step: 8
Training loss: 3.287051059253217
Validation loss: 2.4755009563238475

Epoch: 5| Step: 9
Training loss: 2.422765063733302
Validation loss: 2.464709395642726

Epoch: 5| Step: 10
Training loss: 2.4893796403838286
Validation loss: 2.4662561415453883

Epoch: 5| Step: 11
Training loss: 2.7844939440871843
Validation loss: 2.464814388948655

Epoch: 132| Step: 0
Training loss: 2.3978030083104405
Validation loss: 2.4644771127928595

Epoch: 5| Step: 1
Training loss: 2.639471671239831
Validation loss: 2.465608888129456

Epoch: 5| Step: 2
Training loss: 2.2790993782259865
Validation loss: 2.4603916995994077

Epoch: 5| Step: 3
Training loss: 2.7217103472550983
Validation loss: 2.4630552312995744

Epoch: 5| Step: 4
Training loss: 2.3905601742002163
Validation loss: 2.462249446521668

Epoch: 5| Step: 5
Training loss: 2.581199615947388
Validation loss: 2.463580594282827

Epoch: 5| Step: 6
Training loss: 2.0749287512623034
Validation loss: 2.463199641469568

Epoch: 5| Step: 7
Training loss: 2.55961502309767
Validation loss: 2.4587072085438786

Epoch: 5| Step: 8
Training loss: 2.578848904789998
Validation loss: 2.463483637690185

Epoch: 5| Step: 9
Training loss: 2.273987274288647
Validation loss: 2.4618543057501245

Epoch: 5| Step: 10
Training loss: 2.8021077907775913
Validation loss: 2.4578752104302524

Epoch: 5| Step: 11
Training loss: 3.4941922093907474
Validation loss: 2.4604824513343995

Epoch: 133| Step: 0
Training loss: 2.9291171319787748
Validation loss: 2.4621880356294654

Epoch: 5| Step: 1
Training loss: 2.2727458727682377
Validation loss: 2.4586810065504316

Epoch: 5| Step: 2
Training loss: 2.131552411323836
Validation loss: 2.465568294928697

Epoch: 5| Step: 3
Training loss: 2.414731127538725
Validation loss: 2.4757268320051398

Epoch: 5| Step: 4
Training loss: 2.784171980489596
Validation loss: 2.4673676141372316

Epoch: 5| Step: 5
Training loss: 2.101131352439699
Validation loss: 2.4724896431588035

Epoch: 5| Step: 6
Training loss: 2.615225623118291
Validation loss: 2.471876554814174

Epoch: 5| Step: 7
Training loss: 2.4784915763584086
Validation loss: 2.475149884967588

Epoch: 5| Step: 8
Training loss: 2.808400196520852
Validation loss: 2.4712339813518516

Epoch: 5| Step: 9
Training loss: 2.5436209268651218
Validation loss: 2.469013023046502

Epoch: 5| Step: 10
Training loss: 2.4979259470644486
Validation loss: 2.4736818553963897

Epoch: 5| Step: 11
Training loss: 2.757631636354154
Validation loss: 2.4724124288045517

Epoch: 134| Step: 0
Training loss: 2.3761483478024177
Validation loss: 2.4659808841205733

Epoch: 5| Step: 1
Training loss: 3.0024639184008235
Validation loss: 2.4714398638890973

Epoch: 5| Step: 2
Training loss: 2.880821967447812
Validation loss: 2.473355078513787

Epoch: 5| Step: 3
Training loss: 2.5265563021119672
Validation loss: 2.4728592894217263

Epoch: 5| Step: 4
Training loss: 2.629516893406924
Validation loss: 2.466774161891921

Epoch: 5| Step: 5
Training loss: 2.171886745942552
Validation loss: 2.4699477738613256

Epoch: 5| Step: 6
Training loss: 2.535283583630492
Validation loss: 2.458479296397382

Epoch: 5| Step: 7
Training loss: 2.14535123230268
Validation loss: 2.4633508061248297

Epoch: 5| Step: 8
Training loss: 2.5646226976494666
Validation loss: 2.460576934235183

Epoch: 5| Step: 9
Training loss: 2.35102559293887
Validation loss: 2.4641494942037605

Epoch: 5| Step: 10
Training loss: 2.317982335271004
Validation loss: 2.461307235473335

Epoch: 5| Step: 11
Training loss: 2.121240768817154
Validation loss: 2.4646041479599536

Epoch: 135| Step: 0
Training loss: 2.482697214243228
Validation loss: 2.4584440809832326

Epoch: 5| Step: 1
Training loss: 2.105496153361209
Validation loss: 2.4640943956941395

Epoch: 5| Step: 2
Training loss: 2.2303079791007843
Validation loss: 2.4611953761708874

Epoch: 5| Step: 3
Training loss: 2.6563950442936113
Validation loss: 2.457239220029729

Epoch: 5| Step: 4
Training loss: 3.2480329282716958
Validation loss: 2.461078639751503

Epoch: 5| Step: 5
Training loss: 2.3313339954615633
Validation loss: 2.4604063520503328

Epoch: 5| Step: 6
Training loss: 2.5376375395984256
Validation loss: 2.459662998516687

Epoch: 5| Step: 7
Training loss: 2.37989763921315
Validation loss: 2.4540623819725287

Epoch: 5| Step: 8
Training loss: 2.1941526342344817
Validation loss: 2.4581926731235164

Epoch: 5| Step: 9
Training loss: 3.0509630215034633
Validation loss: 2.4631346405984105

Epoch: 5| Step: 10
Training loss: 2.1468544416262305
Validation loss: 2.4607060762612907

Epoch: 5| Step: 11
Training loss: 1.7520557318232062
Validation loss: 2.4555530114098376

Epoch: 136| Step: 0
Training loss: 2.029068112444169
Validation loss: 2.46477951393316

Epoch: 5| Step: 1
Training loss: 3.030249361661125
Validation loss: 2.462109422933368

Epoch: 5| Step: 2
Training loss: 2.3224200300855524
Validation loss: 2.462964707464648

Epoch: 5| Step: 3
Training loss: 2.228092992694479
Validation loss: 2.4609982155066548

Epoch: 5| Step: 4
Training loss: 2.4547372367380227
Validation loss: 2.467159197312586

Epoch: 5| Step: 5
Training loss: 2.365334972507177
Validation loss: 2.471926010319253

Epoch: 5| Step: 6
Training loss: 2.6749257300218288
Validation loss: 2.4672337757012257

Epoch: 5| Step: 7
Training loss: 2.341224835979018
Validation loss: 2.476671062059554

Epoch: 5| Step: 8
Training loss: 3.0091606784769076
Validation loss: 2.4703953527413747

Epoch: 5| Step: 9
Training loss: 2.6057912921431807
Validation loss: 2.4588723474040646

Epoch: 5| Step: 10
Training loss: 2.10891899548769
Validation loss: 2.4540664057067234

Epoch: 5| Step: 11
Training loss: 2.8993173585043612
Validation loss: 2.4529571921260973

Epoch: 137| Step: 0
Training loss: 2.2975824006323067
Validation loss: 2.461056951621054

Epoch: 5| Step: 1
Training loss: 2.121923351158311
Validation loss: 2.4633903107443724

Epoch: 5| Step: 2
Training loss: 2.3600040632956487
Validation loss: 2.4579263905278275

Epoch: 5| Step: 3
Training loss: 2.9753213532577227
Validation loss: 2.460690000491205

Epoch: 5| Step: 4
Training loss: 3.0122826588845544
Validation loss: 2.458932004920849

Epoch: 5| Step: 5
Training loss: 2.0555738270723634
Validation loss: 2.4605875967430686

Epoch: 5| Step: 6
Training loss: 2.906335316708059
Validation loss: 2.465114846613773

Epoch: 5| Step: 7
Training loss: 2.7271565224715433
Validation loss: 2.459924061311912

Epoch: 5| Step: 8
Training loss: 2.188770579138391
Validation loss: 2.4611240740093345

Epoch: 5| Step: 9
Training loss: 2.354316796661088
Validation loss: 2.468832042795562

Epoch: 5| Step: 10
Training loss: 2.290233117444329
Validation loss: 2.460558265651191

Epoch: 5| Step: 11
Training loss: 2.258381808090315
Validation loss: 2.4603220699923165

Epoch: 138| Step: 0
Training loss: 2.407271527533899
Validation loss: 2.464497732872416

Epoch: 5| Step: 1
Training loss: 2.3311606464187795
Validation loss: 2.462743526364652

Epoch: 5| Step: 2
Training loss: 1.722610715234006
Validation loss: 2.458941886763039

Epoch: 5| Step: 3
Training loss: 2.4468841864363493
Validation loss: 2.4685868076516826

Epoch: 5| Step: 4
Training loss: 2.9209547582646844
Validation loss: 2.46080999094516

Epoch: 5| Step: 5
Training loss: 2.8446476117069475
Validation loss: 2.4607906963824213

Epoch: 5| Step: 6
Training loss: 2.0005139644166876
Validation loss: 2.4604690348074567

Epoch: 5| Step: 7
Training loss: 3.021518305148451
Validation loss: 2.4631172416750027

Epoch: 5| Step: 8
Training loss: 2.6483035433489954
Validation loss: 2.4605855619477057

Epoch: 5| Step: 9
Training loss: 2.3600103268154955
Validation loss: 2.4643724800088593

Epoch: 5| Step: 10
Training loss: 2.32780587486157
Validation loss: 2.4618030741478365

Epoch: 5| Step: 11
Training loss: 2.920887826219859
Validation loss: 2.4635667873550786

Epoch: 139| Step: 0
Training loss: 2.5592493978941047
Validation loss: 2.463518111672139

Epoch: 5| Step: 1
Training loss: 2.859991288605341
Validation loss: 2.4610116130023187

Epoch: 5| Step: 2
Training loss: 2.513846485443029
Validation loss: 2.4691525062758375

Epoch: 5| Step: 3
Training loss: 2.3662716947871867
Validation loss: 2.468659419397912

Epoch: 5| Step: 4
Training loss: 2.456115066665877
Validation loss: 2.4700159094693226

Epoch: 5| Step: 5
Training loss: 2.837754689352291
Validation loss: 2.4644947359074396

Epoch: 5| Step: 6
Training loss: 2.420032711123239
Validation loss: 2.464249446052772

Epoch: 5| Step: 7
Training loss: 1.7852180854221453
Validation loss: 2.4625757567214586

Epoch: 5| Step: 8
Training loss: 2.6556724369214137
Validation loss: 2.460676948438895

Epoch: 5| Step: 9
Training loss: 2.32302379503679
Validation loss: 2.4690285859480356

Epoch: 5| Step: 10
Training loss: 2.5263538809987316
Validation loss: 2.4552391725744287

Epoch: 5| Step: 11
Training loss: 2.189423070015615
Validation loss: 2.458610811306651

Epoch: 140| Step: 0
Training loss: 2.5487797641185526
Validation loss: 2.4663942158916674

Epoch: 5| Step: 1
Training loss: 2.190356977449034
Validation loss: 2.462832904717109

Epoch: 5| Step: 2
Training loss: 2.3560701175093675
Validation loss: 2.477758894788049

Epoch: 5| Step: 3
Training loss: 2.9274022662807186
Validation loss: 2.4696752045866077

Epoch: 5| Step: 4
Training loss: 2.9286060829637646
Validation loss: 2.4724880480694384

Epoch: 5| Step: 5
Training loss: 2.1004609691949936
Validation loss: 2.470653057973239

Epoch: 5| Step: 6
Training loss: 1.8971398710688598
Validation loss: 2.4761163407939706

Epoch: 5| Step: 7
Training loss: 2.3201204470905314
Validation loss: 2.4765018451695866

Epoch: 5| Step: 8
Training loss: 2.3005113945363544
Validation loss: 2.466131552010702

Epoch: 5| Step: 9
Training loss: 2.7761240667217644
Validation loss: 2.4677070957973517

Epoch: 5| Step: 10
Training loss: 2.9207046531233463
Validation loss: 2.4647795784199498

Epoch: 5| Step: 11
Training loss: 0.9643666558884338
Validation loss: 2.465147573020539

Epoch: 141| Step: 0
Training loss: 2.6963304449468297
Validation loss: 2.4640872517860277

Epoch: 5| Step: 1
Training loss: 2.8085819504109315
Validation loss: 2.457639807866547

Epoch: 5| Step: 2
Training loss: 2.1655946671644655
Validation loss: 2.4603201359205937

Epoch: 5| Step: 3
Training loss: 2.918422515598662
Validation loss: 2.465834997152283

Epoch: 5| Step: 4
Training loss: 2.3300144797599676
Validation loss: 2.4656705321091312

Epoch: 5| Step: 5
Training loss: 2.6980294949027135
Validation loss: 2.4672771438376935

Epoch: 5| Step: 6
Training loss: 2.112481210839496
Validation loss: 2.4658286237419236

Epoch: 5| Step: 7
Training loss: 2.5850590714986006
Validation loss: 2.472809841534295

Epoch: 5| Step: 8
Training loss: 2.4277104125677837
Validation loss: 2.473319777681197

Epoch: 5| Step: 9
Training loss: 2.6140435764792955
Validation loss: 2.4791115319241324

Epoch: 5| Step: 10
Training loss: 2.028757297129032
Validation loss: 2.472565519205994

Epoch: 5| Step: 11
Training loss: 1.6717843004384216
Validation loss: 2.469196066012427

Epoch: 142| Step: 0
Training loss: 2.2383199159168448
Validation loss: 2.4712023083759713

Epoch: 5| Step: 1
Training loss: 2.2900057466926267
Validation loss: 2.471200109462843

Epoch: 5| Step: 2
Training loss: 2.4360931444635274
Validation loss: 2.4660923007739353

Epoch: 5| Step: 3
Training loss: 2.4785141820880847
Validation loss: 2.4650121471113473

Epoch: 5| Step: 4
Training loss: 2.227635389466993
Validation loss: 2.467175883224934

Epoch: 5| Step: 5
Training loss: 2.686860917864835
Validation loss: 2.4678224680248686

Epoch: 5| Step: 6
Training loss: 2.7808321521067967
Validation loss: 2.474262396882464

Epoch: 5| Step: 7
Training loss: 2.370955788433856
Validation loss: 2.470293254805479

Epoch: 5| Step: 8
Training loss: 2.5915285271957336
Validation loss: 2.465706546790299

Epoch: 5| Step: 9
Training loss: 2.8984368419389415
Validation loss: 2.465966274864005

Epoch: 5| Step: 10
Training loss: 2.5043818220060388
Validation loss: 2.4641235234346714

Epoch: 5| Step: 11
Training loss: 3.2665784986106563
Validation loss: 2.463310284599218

Epoch: 143| Step: 0
Training loss: 2.3440808889148075
Validation loss: 2.469337616774846

Epoch: 5| Step: 1
Training loss: 2.3974818211284945
Validation loss: 2.4854951888217993

Epoch: 5| Step: 2
Training loss: 2.122000203771698
Validation loss: 2.4846979926934516

Epoch: 5| Step: 3
Training loss: 3.0646370418638904
Validation loss: 2.504435060376073

Epoch: 5| Step: 4
Training loss: 1.901556835307176
Validation loss: 2.4920517098196067

Epoch: 5| Step: 5
Training loss: 2.8519841966659327
Validation loss: 2.483632270583859

Epoch: 5| Step: 6
Training loss: 2.744434446847735
Validation loss: 2.4821078914520114

Epoch: 5| Step: 7
Training loss: 2.587870448771585
Validation loss: 2.4750207460221114

Epoch: 5| Step: 8
Training loss: 2.51131282866414
Validation loss: 2.4716086536309945

Epoch: 5| Step: 9
Training loss: 2.6463818519694216
Validation loss: 2.4685882523420313

Epoch: 5| Step: 10
Training loss: 2.381249487368711
Validation loss: 2.4769002842517036

Epoch: 5| Step: 11
Training loss: 1.7068271820510792
Validation loss: 2.4716780155236013

Epoch: 144| Step: 0
Training loss: 2.457830593190466
Validation loss: 2.476901543611626

Epoch: 5| Step: 1
Training loss: 2.737508232069484
Validation loss: 2.474776425201635

Epoch: 5| Step: 2
Training loss: 2.2647963488310525
Validation loss: 2.4769869981090062

Epoch: 5| Step: 3
Training loss: 2.424862698472908
Validation loss: 2.4765138190104894

Epoch: 5| Step: 4
Training loss: 2.1221226678280334
Validation loss: 2.4724668457384946

Epoch: 5| Step: 5
Training loss: 2.4590869545844694
Validation loss: 2.471777411751714

Epoch: 5| Step: 6
Training loss: 2.821903783708448
Validation loss: 2.4763395327410307

Epoch: 5| Step: 7
Training loss: 2.474567945896791
Validation loss: 2.474706461707298

Epoch: 5| Step: 8
Training loss: 2.297759631806931
Validation loss: 2.4715160012727555

Epoch: 5| Step: 9
Training loss: 2.621363709784396
Validation loss: 2.4745963200899967

Epoch: 5| Step: 10
Training loss: 2.7686482085725572
Validation loss: 2.4694304997103234

Epoch: 5| Step: 11
Training loss: 2.6415432569235437
Validation loss: 2.4692381283704266

Epoch: 145| Step: 0
Training loss: 2.609400766211203
Validation loss: 2.4675133601680157

Epoch: 5| Step: 1
Training loss: 2.1786226248700022
Validation loss: 2.4678700685671937

Epoch: 5| Step: 2
Training loss: 2.6307472709214568
Validation loss: 2.4681423260256214

Epoch: 5| Step: 3
Training loss: 1.9065951675845192
Validation loss: 2.462869049631193

Epoch: 5| Step: 4
Training loss: 2.099952506481987
Validation loss: 2.458082409892338

Epoch: 5| Step: 5
Training loss: 2.41497518822855
Validation loss: 2.4676210602710715

Epoch: 5| Step: 6
Training loss: 2.5462835830473853
Validation loss: 2.4624499764501033

Epoch: 5| Step: 7
Training loss: 1.9780512695070833
Validation loss: 2.460566142486667

Epoch: 5| Step: 8
Training loss: 2.984170796862779
Validation loss: 2.4637824149912992

Epoch: 5| Step: 9
Training loss: 3.225854532744876
Validation loss: 2.4632208187112217

Epoch: 5| Step: 10
Training loss: 2.430877001865677
Validation loss: 2.465639960111061

Epoch: 5| Step: 11
Training loss: 3.0728241642536895
Validation loss: 2.470133900565117

Epoch: 146| Step: 0
Training loss: 2.4812570836040555
Validation loss: 2.4636251235170388

Epoch: 5| Step: 1
Training loss: 2.2351128486971596
Validation loss: 2.459554972156875

Epoch: 5| Step: 2
Training loss: 2.474562646775418
Validation loss: 2.4613749846882587

Epoch: 5| Step: 3
Training loss: 2.2605183896382215
Validation loss: 2.468972075409103

Epoch: 5| Step: 4
Training loss: 2.633384755594232
Validation loss: 2.466220094609356

Epoch: 5| Step: 5
Training loss: 2.7564521871094656
Validation loss: 2.4652104737193983

Epoch: 5| Step: 6
Training loss: 2.095359752785022
Validation loss: 2.465932417231729

Epoch: 5| Step: 7
Training loss: 2.7460314986442946
Validation loss: 2.468624771740641

Epoch: 5| Step: 8
Training loss: 2.035180617056621
Validation loss: 2.4679200833698585

Epoch: 5| Step: 9
Training loss: 2.5604348583728793
Validation loss: 2.471973801095948

Epoch: 5| Step: 10
Training loss: 3.0444150726807315
Validation loss: 2.467854353445271

Epoch: 5| Step: 11
Training loss: 1.901511823093311
Validation loss: 2.464183136464942

Epoch: 147| Step: 0
Training loss: 2.0024496811772754
Validation loss: 2.463828073564828

Epoch: 5| Step: 1
Training loss: 2.426749461599062
Validation loss: 2.4622351963939484

Epoch: 5| Step: 2
Training loss: 2.7265455360212782
Validation loss: 2.467505334405824

Epoch: 5| Step: 3
Training loss: 2.843599252582816
Validation loss: 2.4628110001005274

Epoch: 5| Step: 4
Training loss: 2.0321472533779685
Validation loss: 2.464019774697682

Epoch: 5| Step: 5
Training loss: 2.1468868693949545
Validation loss: 2.470049162148917

Epoch: 5| Step: 6
Training loss: 2.778246683174185
Validation loss: 2.4653477503617363

Epoch: 5| Step: 7
Training loss: 2.4011612625843246
Validation loss: 2.4664598820223906

Epoch: 5| Step: 8
Training loss: 2.960103503814672
Validation loss: 2.468255758105387

Epoch: 5| Step: 9
Training loss: 2.4874482729340244
Validation loss: 2.469456450872147

Epoch: 5| Step: 10
Training loss: 2.328099807500547
Validation loss: 2.4627959404375623

Epoch: 5| Step: 11
Training loss: 2.337991685204776
Validation loss: 2.4578654556567647

Epoch: 148| Step: 0
Training loss: 2.720533202726078
Validation loss: 2.4579835672537964

Epoch: 5| Step: 1
Training loss: 2.282154687705398
Validation loss: 2.45681065477311

Epoch: 5| Step: 2
Training loss: 2.4049542393762198
Validation loss: 2.461155158211575

Epoch: 5| Step: 3
Training loss: 2.4502428946468418
Validation loss: 2.4637768104277655

Epoch: 5| Step: 4
Training loss: 2.3411546706279314
Validation loss: 2.460449198562411

Epoch: 5| Step: 5
Training loss: 2.2983271361616247
Validation loss: 2.46222301593911

Epoch: 5| Step: 6
Training loss: 2.4647171302350244
Validation loss: 2.4655519406155735

Epoch: 5| Step: 7
Training loss: 2.451787304463445
Validation loss: 2.4694793122882155

Epoch: 5| Step: 8
Training loss: 2.238403423496761
Validation loss: 2.464518256039011

Epoch: 5| Step: 9
Training loss: 2.8916541664520286
Validation loss: 2.4630233039179417

Epoch: 5| Step: 10
Training loss: 2.5052790218751104
Validation loss: 2.4628894552802327

Epoch: 5| Step: 11
Training loss: 2.9245591507954605
Validation loss: 2.4676072296540537

Epoch: 149| Step: 0
Training loss: 2.6598916615386887
Validation loss: 2.4649835054220994

Epoch: 5| Step: 1
Training loss: 2.390792840787812
Validation loss: 2.4651134200372127

Epoch: 5| Step: 2
Training loss: 2.8339163984352664
Validation loss: 2.467691162251453

Epoch: 5| Step: 3
Training loss: 1.870517841179587
Validation loss: 2.4705314928433286

Epoch: 5| Step: 4
Training loss: 2.7161707427411748
Validation loss: 2.4651876371915056

Epoch: 5| Step: 5
Training loss: 2.2706941917791013
Validation loss: 2.469266547715843

Epoch: 5| Step: 6
Training loss: 2.729859814939663
Validation loss: 2.4635442904457707

Epoch: 5| Step: 7
Training loss: 2.5562959326462327
Validation loss: 2.4709899293595776

Epoch: 5| Step: 8
Training loss: 2.565612670274071
Validation loss: 2.4733802695610625

Epoch: 5| Step: 9
Training loss: 2.2289793583499042
Validation loss: 2.468480614559588

Epoch: 5| Step: 10
Training loss: 2.171418286062562
Validation loss: 2.4679394711292

Epoch: 5| Step: 11
Training loss: 3.0662547857695848
Validation loss: 2.476983934038504

Epoch: 150| Step: 0
Training loss: 2.3170531529111558
Validation loss: 2.467772946384725

Epoch: 5| Step: 1
Training loss: 1.7972883992865365
Validation loss: 2.4824151119817355

Epoch: 5| Step: 2
Training loss: 2.857526671651416
Validation loss: 2.479434585252766

Epoch: 5| Step: 3
Training loss: 2.725779073795796
Validation loss: 2.4733348917527787

Epoch: 5| Step: 4
Training loss: 2.630472382740382
Validation loss: 2.480251026360217

Epoch: 5| Step: 5
Training loss: 2.3638448248149544
Validation loss: 2.47288064204658

Epoch: 5| Step: 6
Training loss: 2.3154284518659716
Validation loss: 2.4753461893475808

Epoch: 5| Step: 7
Training loss: 2.2426508514460513
Validation loss: 2.4696101649820723

Epoch: 5| Step: 8
Training loss: 2.503016940295403
Validation loss: 2.4723925015448702

Epoch: 5| Step: 9
Training loss: 2.1962408634662287
Validation loss: 2.4735464509450615

Epoch: 5| Step: 10
Training loss: 2.9239042854455373
Validation loss: 2.4691961927437065

Epoch: 5| Step: 11
Training loss: 2.5903412814249305
Validation loss: 2.4706190132630215

Epoch: 151| Step: 0
Training loss: 2.4113183087313357
Validation loss: 2.464917185354959

Epoch: 5| Step: 1
Training loss: 2.579415385672118
Validation loss: 2.4660983995805763

Epoch: 5| Step: 2
Training loss: 2.5307577148971077
Validation loss: 2.4609598511987736

Epoch: 5| Step: 3
Training loss: 2.3741876317075232
Validation loss: 2.4621605553629173

Epoch: 5| Step: 4
Training loss: 2.8831763722763033
Validation loss: 2.4619768420432324

Epoch: 5| Step: 5
Training loss: 2.1004724334455216
Validation loss: 2.465624750521687

Epoch: 5| Step: 6
Training loss: 2.4046762447577117
Validation loss: 2.4617929657071795

Epoch: 5| Step: 7
Training loss: 2.572079500432086
Validation loss: 2.4633257262504342

Epoch: 5| Step: 8
Training loss: 2.1789381044725795
Validation loss: 2.467787881076029

Epoch: 5| Step: 9
Training loss: 2.495488578493567
Validation loss: 2.460567509121111

Epoch: 5| Step: 10
Training loss: 2.4605710680193584
Validation loss: 2.464981127667353

Epoch: 5| Step: 11
Training loss: 2.4088061738603086
Validation loss: 2.47467377741187

Epoch: 152| Step: 0
Training loss: 2.5603548701014183
Validation loss: 2.482944536549347

Epoch: 5| Step: 1
Training loss: 2.3531803889550513
Validation loss: 2.4811569760947054

Epoch: 5| Step: 2
Training loss: 2.4722279061622383
Validation loss: 2.47366094843057

Epoch: 5| Step: 3
Training loss: 1.7652610471212586
Validation loss: 2.4859295545795095

Epoch: 5| Step: 4
Training loss: 2.1519038309852134
Validation loss: 2.478766165902008

Epoch: 5| Step: 5
Training loss: 2.577238728169181
Validation loss: 2.4935149799909464

Epoch: 5| Step: 6
Training loss: 2.9227429085217134
Validation loss: 2.47736212961081

Epoch: 5| Step: 7
Training loss: 2.090165899527793
Validation loss: 2.472319392700858

Epoch: 5| Step: 8
Training loss: 2.230254314957648
Validation loss: 2.4813308379155434

Epoch: 5| Step: 9
Training loss: 3.0698710893535943
Validation loss: 2.470916252342384

Epoch: 5| Step: 10
Training loss: 2.7163493640067893
Validation loss: 2.4749031002971393

Epoch: 5| Step: 11
Training loss: 1.622336919785415
Validation loss: 2.4721958882885477

Epoch: 153| Step: 0
Training loss: 2.6200337434008056
Validation loss: 2.473418103847093

Epoch: 5| Step: 1
Training loss: 2.3531699532195614
Validation loss: 2.4743397482268485

Epoch: 5| Step: 2
Training loss: 2.4341237086608687
Validation loss: 2.46372086892727

Epoch: 5| Step: 3
Training loss: 2.1966033072974573
Validation loss: 2.466366027272051

Epoch: 5| Step: 4
Training loss: 2.4832249504691615
Validation loss: 2.4735068956714295

Epoch: 5| Step: 5
Training loss: 2.3949278958801337
Validation loss: 2.4734765008553365

Epoch: 5| Step: 6
Training loss: 2.2441132147885443
Validation loss: 2.474135150948539

Epoch: 5| Step: 7
Training loss: 2.945565534088962
Validation loss: 2.480137646220674

Epoch: 5| Step: 8
Training loss: 1.7295405738131917
Validation loss: 2.48524435495359

Epoch: 5| Step: 9
Training loss: 2.9182841221182056
Validation loss: 2.4887436697084424

Epoch: 5| Step: 10
Training loss: 2.4250558945024716
Validation loss: 2.484683195627046

Epoch: 5| Step: 11
Training loss: 3.1985275397511255
Validation loss: 2.480121794537611

Epoch: 154| Step: 0
Training loss: 2.34340797471847
Validation loss: 2.4791872453770467

Epoch: 5| Step: 1
Training loss: 2.491274675475788
Validation loss: 2.475258633397059

Epoch: 5| Step: 2
Training loss: 2.4534194672363623
Validation loss: 2.4847294016836763

Epoch: 5| Step: 3
Training loss: 2.259555658528202
Validation loss: 2.469949296184411

Epoch: 5| Step: 4
Training loss: 2.61627782698412
Validation loss: 2.4702361096468817

Epoch: 5| Step: 5
Training loss: 3.1311565027345245
Validation loss: 2.475593409379647

Epoch: 5| Step: 6
Training loss: 2.0906416181009346
Validation loss: 2.4715836434837173

Epoch: 5| Step: 7
Training loss: 2.1220173941069227
Validation loss: 2.474252628423307

Epoch: 5| Step: 8
Training loss: 2.7200436200122393
Validation loss: 2.473819746184675

Epoch: 5| Step: 9
Training loss: 2.3808966266825284
Validation loss: 2.4762117636904395

Epoch: 5| Step: 10
Training loss: 1.963995323762163
Validation loss: 2.4775935232080744

Epoch: 5| Step: 11
Training loss: 3.150272563465119
Validation loss: 2.47980055732568

Epoch: 155| Step: 0
Training loss: 1.851149758478284
Validation loss: 2.48145144162953

Epoch: 5| Step: 1
Training loss: 2.0320867135626837
Validation loss: 2.480063281623441

Epoch: 5| Step: 2
Training loss: 2.2674292384906964
Validation loss: 2.484112811698619

Epoch: 5| Step: 3
Training loss: 2.7704124609076257
Validation loss: 2.4801379246005575

Epoch: 5| Step: 4
Training loss: 2.681568253131666
Validation loss: 2.4850906285057914

Epoch: 5| Step: 5
Training loss: 2.4099490974717255
Validation loss: 2.4845808411740893

Epoch: 5| Step: 6
Training loss: 2.3348736333858873
Validation loss: 2.4855218515470905

Epoch: 5| Step: 7
Training loss: 2.858735893825194
Validation loss: 2.483895049528931

Epoch: 5| Step: 8
Training loss: 2.8681195066976737
Validation loss: 2.4849908453301315

Epoch: 5| Step: 9
Training loss: 2.722545298610221
Validation loss: 2.488717292974359

Epoch: 5| Step: 10
Training loss: 2.2126723313971213
Validation loss: 2.479107492739791

Epoch: 5| Step: 11
Training loss: 1.019816099399565
Validation loss: 2.473475135328933

Epoch: 156| Step: 0
Training loss: 2.3712326084558937
Validation loss: 2.4928381298772524

Epoch: 5| Step: 1
Training loss: 2.403455225921684
Validation loss: 2.4802039297920064

Epoch: 5| Step: 2
Training loss: 2.3853596065532097
Validation loss: 2.4945094055754926

Epoch: 5| Step: 3
Training loss: 2.396508749143825
Validation loss: 2.4999456717627973

Epoch: 5| Step: 4
Training loss: 2.2689877514229067
Validation loss: 2.5115808554885133

Epoch: 5| Step: 5
Training loss: 2.6118362605719705
Validation loss: 2.5151130854378123

Epoch: 5| Step: 6
Training loss: 3.15732155918598
Validation loss: 2.498379185902401

Epoch: 5| Step: 7
Training loss: 1.6834140336486751
Validation loss: 2.5040500736440015

Epoch: 5| Step: 8
Training loss: 2.426776773850722
Validation loss: 2.5001944943112235

Epoch: 5| Step: 9
Training loss: 2.721538472969117
Validation loss: 2.4852744939280287

Epoch: 5| Step: 10
Training loss: 2.4515089798696126
Validation loss: 2.4832726838132486

Epoch: 5| Step: 11
Training loss: 1.8207995373043149
Validation loss: 2.4811124552118877

Epoch: 157| Step: 0
Training loss: 2.1775353310803083
Validation loss: 2.4753884140758444

Epoch: 5| Step: 1
Training loss: 2.459023642737746
Validation loss: 2.4813779351140837

Epoch: 5| Step: 2
Training loss: 2.3339434121340004
Validation loss: 2.475477765270016

Epoch: 5| Step: 3
Training loss: 2.2665020527623136
Validation loss: 2.475917008011154

Epoch: 5| Step: 4
Training loss: 3.1125349540739347
Validation loss: 2.478708807288289

Epoch: 5| Step: 5
Training loss: 2.255251900925304
Validation loss: 2.477270568645747

Epoch: 5| Step: 6
Training loss: 2.2495399640584828
Validation loss: 2.48655555805629

Epoch: 5| Step: 7
Training loss: 2.7567055185233214
Validation loss: 2.4782079370898353

Epoch: 5| Step: 8
Training loss: 2.4094840770922787
Validation loss: 2.486890876494364

Epoch: 5| Step: 9
Training loss: 2.147623469719026
Validation loss: 2.4849918247525924

Epoch: 5| Step: 10
Training loss: 2.6508700471998083
Validation loss: 2.486747105075553

Epoch: 5| Step: 11
Training loss: 2.60860098134901
Validation loss: 2.478904787759062

Epoch: 158| Step: 0
Training loss: 2.155283282749659
Validation loss: 2.482042765388036

Epoch: 5| Step: 1
Training loss: 2.7980227539522478
Validation loss: 2.472401598311628

Epoch: 5| Step: 2
Training loss: 2.5226425005129616
Validation loss: 2.4708388058846795

Epoch: 5| Step: 3
Training loss: 2.680432808217299
Validation loss: 2.473452013639472

Epoch: 5| Step: 4
Training loss: 2.7593122084181396
Validation loss: 2.4664956918520664

Epoch: 5| Step: 5
Training loss: 2.891808015151867
Validation loss: 2.4688685585880332

Epoch: 5| Step: 6
Training loss: 2.204777415798827
Validation loss: 2.4648055745194775

Epoch: 5| Step: 7
Training loss: 2.003159292704158
Validation loss: 2.4678418807036304

Epoch: 5| Step: 8
Training loss: 2.3108033838359243
Validation loss: 2.464098779995436

Epoch: 5| Step: 9
Training loss: 1.7391174362567599
Validation loss: 2.4792884882213166

Epoch: 5| Step: 10
Training loss: 2.6436391928968783
Validation loss: 2.504204500698559

Epoch: 5| Step: 11
Training loss: 3.6394192905210576
Validation loss: 2.501135445080801

Epoch: 159| Step: 0
Training loss: 2.230304237618735
Validation loss: 2.477200992400389

Epoch: 5| Step: 1
Training loss: 2.747996033589306
Validation loss: 2.467861623311755

Epoch: 5| Step: 2
Training loss: 2.3802638697805576
Validation loss: 2.4706379375477687

Epoch: 5| Step: 3
Training loss: 2.608772345293213
Validation loss: 2.4730858050519755

Epoch: 5| Step: 4
Training loss: 2.3833370444351147
Validation loss: 2.4727393724432147

Epoch: 5| Step: 5
Training loss: 2.5385182897852956
Validation loss: 2.4766663971777145

Epoch: 5| Step: 6
Training loss: 2.740623702045686
Validation loss: 2.474002309040266

Epoch: 5| Step: 7
Training loss: 1.9634105392370589
Validation loss: 2.4747284597372787

Epoch: 5| Step: 8
Training loss: 2.8177923635385405
Validation loss: 2.472860266618922

Epoch: 5| Step: 9
Training loss: 2.8770396419654056
Validation loss: 2.4722298992290193

Epoch: 5| Step: 10
Training loss: 2.0361651301392096
Validation loss: 2.4721361711137186

Epoch: 5| Step: 11
Training loss: 2.9299949382959594
Validation loss: 2.4756433122897072

Epoch: 160| Step: 0
Training loss: 2.667315692200976
Validation loss: 2.473776830071845

Epoch: 5| Step: 1
Training loss: 2.0894773928662334
Validation loss: 2.473054774401344

Epoch: 5| Step: 2
Training loss: 3.0238648736019456
Validation loss: 2.475271586487096

Epoch: 5| Step: 3
Training loss: 2.1020298548065504
Validation loss: 2.473473705541656

Epoch: 5| Step: 4
Training loss: 2.5022479441223937
Validation loss: 2.482267761648962

Epoch: 5| Step: 5
Training loss: 2.885532326336936
Validation loss: 2.4771323405862207

Epoch: 5| Step: 6
Training loss: 2.8454819320349074
Validation loss: 2.4771117033642556

Epoch: 5| Step: 7
Training loss: 2.246900118500395
Validation loss: 2.4655513080371043

Epoch: 5| Step: 8
Training loss: 1.9645698614322673
Validation loss: 2.478223334017454

Epoch: 5| Step: 9
Training loss: 2.7174453235730223
Validation loss: 2.4708751110985765

Epoch: 5| Step: 10
Training loss: 2.611067354453383
Validation loss: 2.4670453363022427

Epoch: 5| Step: 11
Training loss: 1.1258788384860983
Validation loss: 2.460159857060734

Epoch: 161| Step: 0
Training loss: 2.2609709193482406
Validation loss: 2.4702736261354525

Epoch: 5| Step: 1
Training loss: 2.9644305477772988
Validation loss: 2.46986959718707

Epoch: 5| Step: 2
Training loss: 2.154014645001595
Validation loss: 2.4651386832158

Epoch: 5| Step: 3
Training loss: 2.4585436607085316
Validation loss: 2.4619862617620165

Epoch: 5| Step: 4
Training loss: 2.3182757650980115
Validation loss: 2.458862313777778

Epoch: 5| Step: 5
Training loss: 2.056253163065695
Validation loss: 2.4629642799248304

Epoch: 5| Step: 6
Training loss: 2.8776649065928837
Validation loss: 2.4575373538228926

Epoch: 5| Step: 7
Training loss: 3.030197590091702
Validation loss: 2.4609398473496316

Epoch: 5| Step: 8
Training loss: 2.498721177133841
Validation loss: 2.4631338339751

Epoch: 5| Step: 9
Training loss: 2.16205445920266
Validation loss: 2.4638270736333894

Epoch: 5| Step: 10
Training loss: 2.25106468441934
Validation loss: 2.460926762310197

Epoch: 5| Step: 11
Training loss: 2.1041332531784547
Validation loss: 2.470113486393303

Epoch: 162| Step: 0
Training loss: 2.4631780204109477
Validation loss: 2.4680791337687777

Epoch: 5| Step: 1
Training loss: 2.4779938132737636
Validation loss: 2.463813058422613

Epoch: 5| Step: 2
Training loss: 1.7301585864548508
Validation loss: 2.4595270343338305

Epoch: 5| Step: 3
Training loss: 2.4887606699402034
Validation loss: 2.4716096524239073

Epoch: 5| Step: 4
Training loss: 2.83965115110521
Validation loss: 2.4675366321139034

Epoch: 5| Step: 5
Training loss: 2.697118270351509
Validation loss: 2.462764112554402

Epoch: 5| Step: 6
Training loss: 2.1455104794874185
Validation loss: 2.4688277695071923

Epoch: 5| Step: 7
Training loss: 2.3074399901880636
Validation loss: 2.4731775932449396

Epoch: 5| Step: 8
Training loss: 2.828152819754832
Validation loss: 2.477361327619938

Epoch: 5| Step: 9
Training loss: 2.5966145886384315
Validation loss: 2.4774115297430055

Epoch: 5| Step: 10
Training loss: 2.377089334313733
Validation loss: 2.48675026497629

Epoch: 5| Step: 11
Training loss: 1.4601508485909491
Validation loss: 2.476383347153562

Epoch: 163| Step: 0
Training loss: 2.5211083968818406
Validation loss: 2.490053205694056

Epoch: 5| Step: 1
Training loss: 2.1780240400824886
Validation loss: 2.4755356843100134

Epoch: 5| Step: 2
Training loss: 2.4101175710087683
Validation loss: 2.477747524354281

Epoch: 5| Step: 3
Training loss: 2.5786272889016666
Validation loss: 2.4704917364949273

Epoch: 5| Step: 4
Training loss: 2.6455814411876997
Validation loss: 2.464300902933894

Epoch: 5| Step: 5
Training loss: 2.697260851790219
Validation loss: 2.4639039744340963

Epoch: 5| Step: 6
Training loss: 2.5087652090207486
Validation loss: 2.465953156068613

Epoch: 5| Step: 7
Training loss: 2.655362598062864
Validation loss: 2.4655770582817045

Epoch: 5| Step: 8
Training loss: 2.149285166583281
Validation loss: 2.470747879688475

Epoch: 5| Step: 9
Training loss: 2.3522223373799074
Validation loss: 2.4731743196009592

Epoch: 5| Step: 10
Training loss: 2.527341674615164
Validation loss: 2.4675459198960934

Epoch: 5| Step: 11
Training loss: 2.5458711857538874
Validation loss: 2.4812663880903214

Epoch: 164| Step: 0
Training loss: 2.5135257088610063
Validation loss: 2.478026151108729

Epoch: 5| Step: 1
Training loss: 2.267352162749655
Validation loss: 2.484206659783578

Epoch: 5| Step: 2
Training loss: 2.3410759485073713
Validation loss: 2.4872608657728916

Epoch: 5| Step: 3
Training loss: 2.866361493863078
Validation loss: 2.489910664181428

Epoch: 5| Step: 4
Training loss: 2.4193240605724355
Validation loss: 2.4808772674333377

Epoch: 5| Step: 5
Training loss: 2.4531623205759847
Validation loss: 2.485245737996758

Epoch: 5| Step: 6
Training loss: 2.7750866781908217
Validation loss: 2.483784227485747

Epoch: 5| Step: 7
Training loss: 2.2261818008214957
Validation loss: 2.4736586191764154

Epoch: 5| Step: 8
Training loss: 2.2052857104459878
Validation loss: 2.4835844001542027

Epoch: 5| Step: 9
Training loss: 2.364538945749119
Validation loss: 2.4819612353292433

Epoch: 5| Step: 10
Training loss: 2.592182651030068
Validation loss: 2.4868804605811854

Epoch: 5| Step: 11
Training loss: 0.6253640545091712
Validation loss: 2.477674497341634

Epoch: 165| Step: 0
Training loss: 2.6626704989720738
Validation loss: 2.477453498731125

Epoch: 5| Step: 1
Training loss: 2.2312534107855364
Validation loss: 2.4788359847571315

Epoch: 5| Step: 2
Training loss: 2.2690500612683695
Validation loss: 2.4882502751041877

Epoch: 5| Step: 3
Training loss: 2.5741177945752836
Validation loss: 2.4819574089141003

Epoch: 5| Step: 4
Training loss: 2.961379045965213
Validation loss: 2.4794246448533834

Epoch: 5| Step: 5
Training loss: 2.356184260819824
Validation loss: 2.4830916626890573

Epoch: 5| Step: 6
Training loss: 2.0787924935040016
Validation loss: 2.4884796063517043

Epoch: 5| Step: 7
Training loss: 2.203382111825566
Validation loss: 2.4775049841029038

Epoch: 5| Step: 8
Training loss: 3.0196301048056586
Validation loss: 2.4927632295648134

Epoch: 5| Step: 9
Training loss: 1.8081928245463665
Validation loss: 2.4853457507631993

Epoch: 5| Step: 10
Training loss: 2.5884340341911614
Validation loss: 2.489569936633809

Epoch: 5| Step: 11
Training loss: 0.9828973609178652
Validation loss: 2.4848743792532346

Epoch: 166| Step: 0
Training loss: 3.025114161331257
Validation loss: 2.4831898499540497

Epoch: 5| Step: 1
Training loss: 2.2811822750542063
Validation loss: 2.477425550226901

Epoch: 5| Step: 2
Training loss: 2.8888735852284473
Validation loss: 2.4746766355988736

Epoch: 5| Step: 3
Training loss: 2.4681130082396248
Validation loss: 2.480405098806797

Epoch: 5| Step: 4
Training loss: 2.237903396641914
Validation loss: 2.4771268464339324

Epoch: 5| Step: 5
Training loss: 2.143244345060039
Validation loss: 2.4754050565570513

Epoch: 5| Step: 6
Training loss: 2.240418909615781
Validation loss: 2.478375017302581

Epoch: 5| Step: 7
Training loss: 2.5172240109581017
Validation loss: 2.483781563760354

Epoch: 5| Step: 8
Training loss: 2.1095342505351526
Validation loss: 2.474781631540153

Epoch: 5| Step: 9
Training loss: 2.6419405397110385
Validation loss: 2.499353257606401

Epoch: 5| Step: 10
Training loss: 2.333625082668324
Validation loss: 2.4908318574487733

Epoch: 5| Step: 11
Training loss: 1.190336503848174
Validation loss: 2.486520260850847

Epoch: 167| Step: 0
Training loss: 2.494843314531496
Validation loss: 2.4910113868958477

Epoch: 5| Step: 1
Training loss: 2.422749220052327
Validation loss: 2.488999718662357

Epoch: 5| Step: 2
Training loss: 2.4472285067703354
Validation loss: 2.478266000765101

Epoch: 5| Step: 3
Training loss: 2.186403272086025
Validation loss: 2.4739892549422775

Epoch: 5| Step: 4
Training loss: 2.274078173995536
Validation loss: 2.47744043875914

Epoch: 5| Step: 5
Training loss: 1.8681073337203307
Validation loss: 2.4837729006336917

Epoch: 5| Step: 6
Training loss: 2.1681176486733302
Validation loss: 2.4769534294859366

Epoch: 5| Step: 7
Training loss: 2.3204788508011402
Validation loss: 2.4797237609122185

Epoch: 5| Step: 8
Training loss: 2.99577256213127
Validation loss: 2.4857016126415856

Epoch: 5| Step: 9
Training loss: 2.8569242053153934
Validation loss: 2.4891643623858184

Epoch: 5| Step: 10
Training loss: 2.371371458780766
Validation loss: 2.494978236082479

Epoch: 5| Step: 11
Training loss: 3.0163222381503525
Validation loss: 2.493892899341219

Epoch: 168| Step: 0
Training loss: 2.685989576437374
Validation loss: 2.5097724093136455

Epoch: 5| Step: 1
Training loss: 2.346673997990398
Validation loss: 2.503777078598601

Epoch: 5| Step: 2
Training loss: 2.2572269934481937
Validation loss: 2.499530161974434

Epoch: 5| Step: 3
Training loss: 2.305384229961224
Validation loss: 2.500890775771021

Epoch: 5| Step: 4
Training loss: 2.4294902561994896
Validation loss: 2.5140338074963466

Epoch: 5| Step: 5
Training loss: 2.7491648012609553
Validation loss: 2.503820230372235

Epoch: 5| Step: 6
Training loss: 2.3641052322912626
Validation loss: 2.500457556894029

Epoch: 5| Step: 7
Training loss: 2.106150331035025
Validation loss: 2.499694753926358

Epoch: 5| Step: 8
Training loss: 2.892479543918557
Validation loss: 2.4880689293839815

Epoch: 5| Step: 9
Training loss: 2.099291741053729
Validation loss: 2.4859099514671814

Epoch: 5| Step: 10
Training loss: 2.3807053551365978
Validation loss: 2.4865297893478697

Epoch: 5| Step: 11
Training loss: 2.5363239250107203
Validation loss: 2.4849966538993264

Epoch: 169| Step: 0
Training loss: 2.2255646192827725
Validation loss: 2.4948817630392464

Epoch: 5| Step: 1
Training loss: 2.1411954022343025
Validation loss: 2.478923634763603

Epoch: 5| Step: 2
Training loss: 2.4345687456122116
Validation loss: 2.4784638560013676

Epoch: 5| Step: 3
Training loss: 2.543474044640377
Validation loss: 2.4755042228780852

Epoch: 5| Step: 4
Training loss: 2.495847113756486
Validation loss: 2.4880536153442527

Epoch: 5| Step: 5
Training loss: 2.6583803497589233
Validation loss: 2.48281157781457

Epoch: 5| Step: 6
Training loss: 2.555852501889257
Validation loss: 2.4933533527553142

Epoch: 5| Step: 7
Training loss: 2.178207277689632
Validation loss: 2.49253658213628

Epoch: 5| Step: 8
Training loss: 2.5122005303153254
Validation loss: 2.4945137662879193

Epoch: 5| Step: 9
Training loss: 2.3559701363787067
Validation loss: 2.4920896154172603

Epoch: 5| Step: 10
Training loss: 2.1766500330820553
Validation loss: 2.5043841861524325

Epoch: 5| Step: 11
Training loss: 3.717749709546358
Validation loss: 2.4994564657630445

Epoch: 170| Step: 0
Training loss: 2.2237516094199794
Validation loss: 2.53077045262281

Epoch: 5| Step: 1
Training loss: 2.632702652538518
Validation loss: 2.5152628936154002

Epoch: 5| Step: 2
Training loss: 1.888759039018412
Validation loss: 2.5088176594499285

Epoch: 5| Step: 3
Training loss: 2.5817147896379646
Validation loss: 2.515540739587245

Epoch: 5| Step: 4
Training loss: 2.1555368100931953
Validation loss: 2.5022709069203266

Epoch: 5| Step: 5
Training loss: 2.410359527077687
Validation loss: 2.4991755675877827

Epoch: 5| Step: 6
Training loss: 2.2969106035652027
Validation loss: 2.4859774837479303

Epoch: 5| Step: 7
Training loss: 2.3374183069325123
Validation loss: 2.4897421157085935

Epoch: 5| Step: 8
Training loss: 2.9121403222387294
Validation loss: 2.482035244882563

Epoch: 5| Step: 9
Training loss: 2.5428454578706754
Validation loss: 2.4833440520921437

Epoch: 5| Step: 10
Training loss: 2.4928953307603896
Validation loss: 2.4775150204179766

Epoch: 5| Step: 11
Training loss: 2.9409445188724552
Validation loss: 2.4766763005148436

Epoch: 171| Step: 0
Training loss: 2.6008957016920773
Validation loss: 2.4854801646837594

Epoch: 5| Step: 1
Training loss: 2.119218928564838
Validation loss: 2.494892016140027

Epoch: 5| Step: 2
Training loss: 2.6713404427454326
Validation loss: 2.4776092627612387

Epoch: 5| Step: 3
Training loss: 2.136064669905229
Validation loss: 2.4884695024806627

Epoch: 5| Step: 4
Training loss: 2.3066710131756767
Validation loss: 2.4811751273490925

Epoch: 5| Step: 5
Training loss: 1.880449133446966
Validation loss: 2.497325774248665

Epoch: 5| Step: 6
Training loss: 2.729850469832823
Validation loss: 2.5002209565747497

Epoch: 5| Step: 7
Training loss: 2.396334742170468
Validation loss: 2.5055250825447986

Epoch: 5| Step: 8
Training loss: 2.493947905142458
Validation loss: 2.5210448516557844

Epoch: 5| Step: 9
Training loss: 2.5771970986430017
Validation loss: 2.5114724556109076

Epoch: 5| Step: 10
Training loss: 2.702728154152808
Validation loss: 2.509046510420654

Epoch: 5| Step: 11
Training loss: 2.2153457530191356
Validation loss: 2.500810332895346

Epoch: 172| Step: 0
Training loss: 2.3197352657875903
Validation loss: 2.488484093399415

Epoch: 5| Step: 1
Training loss: 2.724214783674656
Validation loss: 2.481449411932531

Epoch: 5| Step: 2
Training loss: 2.485270596667427
Validation loss: 2.479626349833122

Epoch: 5| Step: 3
Training loss: 2.296196143069557
Validation loss: 2.4757263384549937

Epoch: 5| Step: 4
Training loss: 2.3627904965663085
Validation loss: 2.473205770504454

Epoch: 5| Step: 5
Training loss: 2.3711989252183256
Validation loss: 2.4722358944927962

Epoch: 5| Step: 6
Training loss: 2.2983532774098854
Validation loss: 2.4740082959935723

Epoch: 5| Step: 7
Training loss: 2.640086282707283
Validation loss: 2.4689150606176073

Epoch: 5| Step: 8
Training loss: 2.8442972516016587
Validation loss: 2.4711705304741205

Epoch: 5| Step: 9
Training loss: 2.2368240273043334
Validation loss: 2.4685991699885537

Epoch: 5| Step: 10
Training loss: 1.9372074152388463
Validation loss: 2.479189609506912

Epoch: 5| Step: 11
Training loss: 3.0888739798968947
Validation loss: 2.478959096238473

Epoch: 173| Step: 0
Training loss: 2.633251210231896
Validation loss: 2.4872478612911735

Epoch: 5| Step: 1
Training loss: 2.365925065112335
Validation loss: 2.5158822854093676

Epoch: 5| Step: 2
Training loss: 2.6708496981956067
Validation loss: 2.516128343571246

Epoch: 5| Step: 3
Training loss: 2.454247381915565
Validation loss: 2.5597277081923453

Epoch: 5| Step: 4
Training loss: 2.0610010884896135
Validation loss: 2.531434821614394

Epoch: 5| Step: 5
Training loss: 2.0717052453464975
Validation loss: 2.5429508132419185

Epoch: 5| Step: 6
Training loss: 2.2671835964387483
Validation loss: 2.5147357893404263

Epoch: 5| Step: 7
Training loss: 2.7137991013690663
Validation loss: 2.513248572958775

Epoch: 5| Step: 8
Training loss: 3.0055633458639623
Validation loss: 2.4911988588421883

Epoch: 5| Step: 9
Training loss: 2.2629087805945676
Validation loss: 2.485991781598381

Epoch: 5| Step: 10
Training loss: 2.3960407222605196
Validation loss: 2.482277482558266

Epoch: 5| Step: 11
Training loss: 1.7440285299574845
Validation loss: 2.4795040026665314

Epoch: 174| Step: 0
Training loss: 1.9522744119519617
Validation loss: 2.4765048777458225

Epoch: 5| Step: 1
Training loss: 2.640269328886513
Validation loss: 2.4710015962269556

Epoch: 5| Step: 2
Training loss: 2.521185280267546
Validation loss: 2.4775017482547383

Epoch: 5| Step: 3
Training loss: 2.707433277128683
Validation loss: 2.4714095401221474

Epoch: 5| Step: 4
Training loss: 2.3085191846962934
Validation loss: 2.477921202442548

Epoch: 5| Step: 5
Training loss: 2.549780282671172
Validation loss: 2.4806203280214536

Epoch: 5| Step: 6
Training loss: 2.4949347681298004
Validation loss: 2.4828012948316496

Epoch: 5| Step: 7
Training loss: 2.3821055880188653
Validation loss: 2.4822794075259096

Epoch: 5| Step: 8
Training loss: 2.7514693062990654
Validation loss: 2.4892669793298525

Epoch: 5| Step: 9
Training loss: 2.1762071394712175
Validation loss: 2.5062343825236573

Epoch: 5| Step: 10
Training loss: 2.396623652482931
Validation loss: 2.508790056390047

Epoch: 5| Step: 11
Training loss: 1.538224045138813
Validation loss: 2.5314321020736377

Epoch: 175| Step: 0
Training loss: 2.277218640196854
Validation loss: 2.517888738797262

Epoch: 5| Step: 1
Training loss: 2.1778350943637097
Validation loss: 2.5253368351305148

Epoch: 5| Step: 2
Training loss: 2.2179756425116905
Validation loss: 2.50958562420694

Epoch: 5| Step: 3
Training loss: 2.1001635578585494
Validation loss: 2.5201855187020534

Epoch: 5| Step: 4
Training loss: 2.775969646920034
Validation loss: 2.501642101132496

Epoch: 5| Step: 5
Training loss: 2.638539862277597
Validation loss: 2.5008157789886867

Epoch: 5| Step: 6
Training loss: 2.0630521324253386
Validation loss: 2.4946973035536044

Epoch: 5| Step: 7
Training loss: 2.578424424787987
Validation loss: 2.4950767598419814

Epoch: 5| Step: 8
Training loss: 2.9648287927303048
Validation loss: 2.4967725066727757

Epoch: 5| Step: 9
Training loss: 2.213011614597075
Validation loss: 2.4986942457550154

Epoch: 5| Step: 10
Training loss: 2.736571819119226
Validation loss: 2.5050113915154584

Epoch: 5| Step: 11
Training loss: 1.853820325529668
Validation loss: 2.503458503765508

Epoch: 176| Step: 0
Training loss: 2.248102765751521
Validation loss: 2.506841398242352

Epoch: 5| Step: 1
Training loss: 1.9242721122748876
Validation loss: 2.496013474902334

Epoch: 5| Step: 2
Training loss: 2.4289419128018235
Validation loss: 2.488920364264825

Epoch: 5| Step: 3
Training loss: 2.6259339805433264
Validation loss: 2.4898865899465266

Epoch: 5| Step: 4
Training loss: 2.436444078272989
Validation loss: 2.480935825216479

Epoch: 5| Step: 5
Training loss: 2.580768686268478
Validation loss: 2.4803194256388217

Epoch: 5| Step: 6
Training loss: 2.7750790318412712
Validation loss: 2.4892036010059004

Epoch: 5| Step: 7
Training loss: 2.5932371252923216
Validation loss: 2.4905241315224367

Epoch: 5| Step: 8
Training loss: 2.292722204623679
Validation loss: 2.5108275881822983

Epoch: 5| Step: 9
Training loss: 2.7564128317277827
Validation loss: 2.5328283608701065

Epoch: 5| Step: 10
Training loss: 2.057624139760443
Validation loss: 2.5320143664066976

Epoch: 5| Step: 11
Training loss: 1.8911705175869165
Validation loss: 2.5547378838379946

Epoch: 177| Step: 0
Training loss: 2.13814897110656
Validation loss: 2.5528491227176233

Epoch: 5| Step: 1
Training loss: 2.92192297911393
Validation loss: 2.541061563196299

Epoch: 5| Step: 2
Training loss: 1.7248975916884874
Validation loss: 2.5295869835182296

Epoch: 5| Step: 3
Training loss: 2.236117130637376
Validation loss: 2.5152173077215116

Epoch: 5| Step: 4
Training loss: 2.584855236375449
Validation loss: 2.495728570992784

Epoch: 5| Step: 5
Training loss: 2.4079337236212077
Validation loss: 2.4990093135894247

Epoch: 5| Step: 6
Training loss: 2.810312310372254
Validation loss: 2.4971034595177675

Epoch: 5| Step: 7
Training loss: 2.545816775037628
Validation loss: 2.494266687053729

Epoch: 5| Step: 8
Training loss: 2.471833633096004
Validation loss: 2.4873622153251533

Epoch: 5| Step: 9
Training loss: 2.218037450572265
Validation loss: 2.4980629410176123

Epoch: 5| Step: 10
Training loss: 2.1352750653715233
Validation loss: 2.500641744421404

Epoch: 5| Step: 11
Training loss: 3.4138212838931414
Validation loss: 2.499170712176978

Epoch: 178| Step: 0
Training loss: 2.556556880969466
Validation loss: 2.4810475552701203

Epoch: 5| Step: 1
Training loss: 2.38298449286419
Validation loss: 2.485810383012871

Epoch: 5| Step: 2
Training loss: 2.313161600684515
Validation loss: 2.4841328948791315

Epoch: 5| Step: 3
Training loss: 3.0853977165868005
Validation loss: 2.482297952771815

Epoch: 5| Step: 4
Training loss: 2.026484489262967
Validation loss: 2.488325920083292

Epoch: 5| Step: 5
Training loss: 2.805877603065139
Validation loss: 2.4795165349349126

Epoch: 5| Step: 6
Training loss: 2.4667993879267684
Validation loss: 2.484515631991904

Epoch: 5| Step: 7
Training loss: 2.2837539935064033
Validation loss: 2.4808091258003153

Epoch: 5| Step: 8
Training loss: 2.3829621815179785
Validation loss: 2.477480284089218

Epoch: 5| Step: 9
Training loss: 2.1096613936800113
Validation loss: 2.482067111817583

Epoch: 5| Step: 10
Training loss: 2.6911236485907506
Validation loss: 2.485313841927603

Epoch: 5| Step: 11
Training loss: 1.7222364956595861
Validation loss: 2.479233485745234

Epoch: 179| Step: 0
Training loss: 2.4032812258732363
Validation loss: 2.499513038256839

Epoch: 5| Step: 1
Training loss: 2.5167974736995835
Validation loss: 2.487914620801495

Epoch: 5| Step: 2
Training loss: 1.9524251675888067
Validation loss: 2.4948850838539767

Epoch: 5| Step: 3
Training loss: 2.158994834989136
Validation loss: 2.4873576743337265

Epoch: 5| Step: 4
Training loss: 2.37375457634668
Validation loss: 2.493158125531003

Epoch: 5| Step: 5
Training loss: 2.600897260045466
Validation loss: 2.4954086621187366

Epoch: 5| Step: 6
Training loss: 2.4982123659388105
Validation loss: 2.4871398987017166

Epoch: 5| Step: 7
Training loss: 2.343533925586736
Validation loss: 2.5008608726625763

Epoch: 5| Step: 8
Training loss: 2.7263108276689474
Validation loss: 2.5102570721771356

Epoch: 5| Step: 9
Training loss: 1.8447042032707297
Validation loss: 2.5075984300968166

Epoch: 5| Step: 10
Training loss: 3.0059493202003247
Validation loss: 2.5143502956791575

Epoch: 5| Step: 11
Training loss: 2.541746065327516
Validation loss: 2.513094982311689

Epoch: 180| Step: 0
Training loss: 2.672057474608944
Validation loss: 2.5326528664796437

Epoch: 5| Step: 1
Training loss: 1.9429784046726226
Validation loss: 2.5292410511744494

Epoch: 5| Step: 2
Training loss: 2.459532515293632
Validation loss: 2.5465849572782817

Epoch: 5| Step: 3
Training loss: 2.440888519323123
Validation loss: 2.5471578725671207

Epoch: 5| Step: 4
Training loss: 2.564614981593669
Validation loss: 2.5268842072012094

Epoch: 5| Step: 5
Training loss: 2.2125719047974295
Validation loss: 2.5201907100683063

Epoch: 5| Step: 6
Training loss: 2.9271551555541944
Validation loss: 2.4984331684818537

Epoch: 5| Step: 7
Training loss: 2.082262781377617
Validation loss: 2.490156998772357

Epoch: 5| Step: 8
Training loss: 2.913347499152456
Validation loss: 2.491281683602784

Epoch: 5| Step: 9
Training loss: 2.2885910433994585
Validation loss: 2.4945811433040737

Epoch: 5| Step: 10
Training loss: 2.13264190774092
Validation loss: 2.4871209042621767

Epoch: 5| Step: 11
Training loss: 2.5093092210255064
Validation loss: 2.4807178522418334

Epoch: 181| Step: 0
Training loss: 2.46443620265702
Validation loss: 2.4935741413543107

Epoch: 5| Step: 1
Training loss: 2.571511218090091
Validation loss: 2.488591105493107

Epoch: 5| Step: 2
Training loss: 2.3384182110818914
Validation loss: 2.504054937446067

Epoch: 5| Step: 3
Training loss: 2.34950993074574
Validation loss: 2.5069009108445863

Epoch: 5| Step: 4
Training loss: 2.244828745335873
Validation loss: 2.497245733678243

Epoch: 5| Step: 5
Training loss: 2.6457667204714124
Validation loss: 2.5031715620506807

Epoch: 5| Step: 6
Training loss: 2.1935314406504016
Validation loss: 2.517813885335552

Epoch: 5| Step: 7
Training loss: 2.654553219260122
Validation loss: 2.519981024761512

Epoch: 5| Step: 8
Training loss: 2.296712856667957
Validation loss: 2.5118497119259304

Epoch: 5| Step: 9
Training loss: 2.2476183684242583
Validation loss: 2.50102818723894

Epoch: 5| Step: 10
Training loss: 2.401357259027869
Validation loss: 2.524614329360019

Epoch: 5| Step: 11
Training loss: 2.4574533169756747
Validation loss: 2.538636740176119

Epoch: 182| Step: 0
Training loss: 2.8591858848193477
Validation loss: 2.5216052683582997

Epoch: 5| Step: 1
Training loss: 2.2995731828477877
Validation loss: 2.509764587956275

Epoch: 5| Step: 2
Training loss: 2.285779036728733
Validation loss: 2.501996157353289

Epoch: 5| Step: 3
Training loss: 2.445812235215369
Validation loss: 2.4984579217874154

Epoch: 5| Step: 4
Training loss: 2.078380827107437
Validation loss: 2.4996411264649083

Epoch: 5| Step: 5
Training loss: 2.4868906587892425
Validation loss: 2.4971151157696623

Epoch: 5| Step: 6
Training loss: 2.3230217423786557
Validation loss: 2.4869939247745334

Epoch: 5| Step: 7
Training loss: 3.0067561685079074
Validation loss: 2.498047650466095

Epoch: 5| Step: 8
Training loss: 3.0452579217426763
Validation loss: 2.4866021887517986

Epoch: 5| Step: 9
Training loss: 1.393581162904929
Validation loss: 2.497531685632939

Epoch: 5| Step: 10
Training loss: 2.057916924470879
Validation loss: 2.4935705877282026

Epoch: 5| Step: 11
Training loss: 1.9744067592789551
Validation loss: 2.5014452333145156

Epoch: 183| Step: 0
Training loss: 2.4262522855941486
Validation loss: 2.4955339754278745

Epoch: 5| Step: 1
Training loss: 2.7719301237626732
Validation loss: 2.500839303115572

Epoch: 5| Step: 2
Training loss: 2.1163077127661576
Validation loss: 2.5040902136135474

Epoch: 5| Step: 3
Training loss: 2.025363079534845
Validation loss: 2.506007542222575

Epoch: 5| Step: 4
Training loss: 2.4260299972792945
Validation loss: 2.5042867505314117

Epoch: 5| Step: 5
Training loss: 2.483446439518385
Validation loss: 2.502541914743521

Epoch: 5| Step: 6
Training loss: 2.1580813826664245
Validation loss: 2.5056453780952648

Epoch: 5| Step: 7
Training loss: 2.4695098287105277
Validation loss: 2.494215742835587

Epoch: 5| Step: 8
Training loss: 2.120373232933801
Validation loss: 2.501268504107836

Epoch: 5| Step: 9
Training loss: 2.224961839841578
Validation loss: 2.5093090191215333

Epoch: 5| Step: 10
Training loss: 2.801216123649302
Validation loss: 2.5217281728968266

Epoch: 5| Step: 11
Training loss: 2.930896560410679
Validation loss: 2.5377169599314167

Epoch: 184| Step: 0
Training loss: 2.468310546392041
Validation loss: 2.6056429353412245

Epoch: 5| Step: 1
Training loss: 2.743121300618999
Validation loss: 2.630353275246037

Epoch: 5| Step: 2
Training loss: 2.027489452969627
Validation loss: 2.597364412133876

Epoch: 5| Step: 3
Training loss: 2.6827232137140324
Validation loss: 2.5780440076956577

Epoch: 5| Step: 4
Training loss: 2.830527281149407
Validation loss: 2.5490104288551576

Epoch: 5| Step: 5
Training loss: 2.1538999715830465
Validation loss: 2.5283117076834913

Epoch: 5| Step: 6
Training loss: 2.3531747151628557
Validation loss: 2.5161563458253022

Epoch: 5| Step: 7
Training loss: 2.5997832574735615
Validation loss: 2.50068482119028

Epoch: 5| Step: 8
Training loss: 2.0282570723922015
Validation loss: 2.502487705205592

Epoch: 5| Step: 9
Training loss: 2.3396351614624065
Validation loss: 2.496340893135037

Epoch: 5| Step: 10
Training loss: 2.343701374821114
Validation loss: 2.4959351036983977

Epoch: 5| Step: 11
Training loss: 3.2490935895642585
Validation loss: 2.4962518410125907

Epoch: 185| Step: 0
Training loss: 2.3992793193240822
Validation loss: 2.4924400942996576

Epoch: 5| Step: 1
Training loss: 2.8962690359518195
Validation loss: 2.4969464846847043

Epoch: 5| Step: 2
Training loss: 2.3884180391051113
Validation loss: 2.5114530241846973

Epoch: 5| Step: 3
Training loss: 2.106417695113346
Validation loss: 2.5236734569291768

Epoch: 5| Step: 4
Training loss: 2.0991569279950486
Validation loss: 2.5462154556375642

Epoch: 5| Step: 5
Training loss: 2.658355955149224
Validation loss: 2.543230214230391

Epoch: 5| Step: 6
Training loss: 2.2715636196073365
Validation loss: 2.538536036759996

Epoch: 5| Step: 7
Training loss: 2.36423764383694
Validation loss: 2.547468069567118

Epoch: 5| Step: 8
Training loss: 2.235415129884711
Validation loss: 2.533422875756425

Epoch: 5| Step: 9
Training loss: 2.8331735977323547
Validation loss: 2.528476569301695

Epoch: 5| Step: 10
Training loss: 2.2411956188201976
Validation loss: 2.5201668147159855

Epoch: 5| Step: 11
Training loss: 2.230458915942638
Validation loss: 2.514569086594402

Epoch: 186| Step: 0
Training loss: 2.7712308459895425
Validation loss: 2.504753215528189

Epoch: 5| Step: 1
Training loss: 2.62463449022438
Validation loss: 2.4889279837059255

Epoch: 5| Step: 2
Training loss: 1.7439814342201763
Validation loss: 2.491161480029751

Epoch: 5| Step: 3
Training loss: 2.8310127478891607
Validation loss: 2.4876513200290176

Epoch: 5| Step: 4
Training loss: 2.811235355459482
Validation loss: 2.486267340816824

Epoch: 5| Step: 5
Training loss: 2.3077480877957313
Validation loss: 2.4844563748769954

Epoch: 5| Step: 6
Training loss: 2.08291006238938
Validation loss: 2.5011991922853896

Epoch: 5| Step: 7
Training loss: 2.7043262083916657
Validation loss: 2.502867960978032

Epoch: 5| Step: 8
Training loss: 2.5042709108850385
Validation loss: 2.5005349500835425

Epoch: 5| Step: 9
Training loss: 2.230984870267731
Validation loss: 2.5196857631727356

Epoch: 5| Step: 10
Training loss: 1.9124243752481014
Validation loss: 2.5280586324341523

Epoch: 5| Step: 11
Training loss: 1.305011412106597
Validation loss: 2.524554234836638

Epoch: 187| Step: 0
Training loss: 2.029065057402456
Validation loss: 2.5241567041486586

Epoch: 5| Step: 1
Training loss: 1.9853439968882534
Validation loss: 2.5272185124101028

Epoch: 5| Step: 2
Training loss: 2.644280516149828
Validation loss: 2.530624072859125

Epoch: 5| Step: 3
Training loss: 2.7604545926541646
Validation loss: 2.5225521380805223

Epoch: 5| Step: 4
Training loss: 2.398664134497982
Validation loss: 2.5195443559645807

Epoch: 5| Step: 5
Training loss: 2.1745636030847852
Validation loss: 2.5212574646662276

Epoch: 5| Step: 6
Training loss: 2.5266970908246478
Validation loss: 2.4981147084832602

Epoch: 5| Step: 7
Training loss: 2.324331687940158
Validation loss: 2.499760942155576

Epoch: 5| Step: 8
Training loss: 2.614865585432014
Validation loss: 2.4981442835876906

Epoch: 5| Step: 9
Training loss: 1.7004864052933215
Validation loss: 2.50226871148904

Epoch: 5| Step: 10
Training loss: 3.041758461877812
Validation loss: 2.49928785353571

Epoch: 5| Step: 11
Training loss: 1.962769704861449
Validation loss: 2.4978279055578447

Epoch: 188| Step: 0
Training loss: 2.095736230480306
Validation loss: 2.508785874921695

Epoch: 5| Step: 1
Training loss: 1.861097035267806
Validation loss: 2.507674263920301

Epoch: 5| Step: 2
Training loss: 2.519468983908408
Validation loss: 2.5236628975999005

Epoch: 5| Step: 3
Training loss: 2.3048412207076954
Validation loss: 2.5385577556009995

Epoch: 5| Step: 4
Training loss: 2.2517669944896928
Validation loss: 2.56579219801454

Epoch: 5| Step: 5
Training loss: 2.8918672109168795
Validation loss: 2.5671324532276776

Epoch: 5| Step: 6
Training loss: 2.3757201658886737
Validation loss: 2.537555384227255

Epoch: 5| Step: 7
Training loss: 2.6719901076836123
Validation loss: 2.531840698956528

Epoch: 5| Step: 8
Training loss: 1.929518595728216
Validation loss: 2.5200875863239234

Epoch: 5| Step: 9
Training loss: 2.671531432075228
Validation loss: 2.5132551937157754

Epoch: 5| Step: 10
Training loss: 2.533869106540109
Validation loss: 2.5061105239059134

Epoch: 5| Step: 11
Training loss: 3.0554345039510453
Validation loss: 2.4920251169587075

Epoch: 189| Step: 0
Training loss: 2.4337322752884636
Validation loss: 2.4937271257337765

Epoch: 5| Step: 1
Training loss: 1.9414352322723512
Validation loss: 2.4860943336974426

Epoch: 5| Step: 2
Training loss: 2.0532208564015595
Validation loss: 2.4872876733228693

Epoch: 5| Step: 3
Training loss: 2.5599292793042276
Validation loss: 2.482416104425806

Epoch: 5| Step: 4
Training loss: 2.29132634728197
Validation loss: 2.4754399865419736

Epoch: 5| Step: 5
Training loss: 2.784195101456806
Validation loss: 2.483315075790146

Epoch: 5| Step: 6
Training loss: 2.2496839937187265
Validation loss: 2.485034739067935

Epoch: 5| Step: 7
Training loss: 1.9207612819218651
Validation loss: 2.4888578632124894

Epoch: 5| Step: 8
Training loss: 2.3579752224436548
Validation loss: 2.4945708769786803

Epoch: 5| Step: 9
Training loss: 2.9371577936060937
Validation loss: 2.5052790773888884

Epoch: 5| Step: 10
Training loss: 2.760483353487057
Validation loss: 2.4986144676937534

Epoch: 5| Step: 11
Training loss: 2.632040572836385
Validation loss: 2.5041179022005355

Epoch: 190| Step: 0
Training loss: 2.515382553643544
Validation loss: 2.5246324337746295

Epoch: 5| Step: 1
Training loss: 2.609592360163626
Validation loss: 2.5438044571885787

Epoch: 5| Step: 2
Training loss: 2.716048114856056
Validation loss: 2.5331770974741006

Epoch: 5| Step: 3
Training loss: 2.55275977894781
Validation loss: 2.5480308094382726

Epoch: 5| Step: 4
Training loss: 2.376844192052449
Validation loss: 2.5593594596803984

Epoch: 5| Step: 5
Training loss: 2.229394657442969
Validation loss: 2.539253525028209

Epoch: 5| Step: 6
Training loss: 2.3582639794098608
Validation loss: 2.5363632252203834

Epoch: 5| Step: 7
Training loss: 2.0599194190551455
Validation loss: 2.51747612540634

Epoch: 5| Step: 8
Training loss: 1.9709413231370607
Validation loss: 2.51832857037676

Epoch: 5| Step: 9
Training loss: 2.3651813529487384
Validation loss: 2.4958948365553253

Epoch: 5| Step: 10
Training loss: 2.2284001847907478
Validation loss: 2.4938745877049513

Epoch: 5| Step: 11
Training loss: 3.6109488882812086
Validation loss: 2.490805359248639

Epoch: 191| Step: 0
Training loss: 2.022134014914363
Validation loss: 2.5006258856592165

Epoch: 5| Step: 1
Training loss: 2.9347568446332284
Validation loss: 2.494293921132721

Epoch: 5| Step: 2
Training loss: 2.313516444985218
Validation loss: 2.496444203942883

Epoch: 5| Step: 3
Training loss: 2.6277853402675695
Validation loss: 2.5180806520858074

Epoch: 5| Step: 4
Training loss: 1.9617845142177592
Validation loss: 2.51917609143826

Epoch: 5| Step: 5
Training loss: 2.1519546849467934
Validation loss: 2.520901420293777

Epoch: 5| Step: 6
Training loss: 2.439432991622782
Validation loss: 2.53159333479048

Epoch: 5| Step: 7
Training loss: 2.1412884874331097
Validation loss: 2.527929746131726

Epoch: 5| Step: 8
Training loss: 2.4475834937656074
Validation loss: 2.5276484671786896

Epoch: 5| Step: 9
Training loss: 2.2750073024087603
Validation loss: 2.526478489076907

Epoch: 5| Step: 10
Training loss: 2.8590277789308454
Validation loss: 2.529348110234822

Epoch: 5| Step: 11
Training loss: 2.4679925456745955
Validation loss: 2.52979494588843

Epoch: 192| Step: 0
Training loss: 2.644230745222185
Validation loss: 2.5316652028086057

Epoch: 5| Step: 1
Training loss: 2.809808418014877
Validation loss: 2.55853743551854

Epoch: 5| Step: 2
Training loss: 2.2672678285823795
Validation loss: 2.541623007029365

Epoch: 5| Step: 3
Training loss: 2.792570157719392
Validation loss: 2.5480923035087786

Epoch: 5| Step: 4
Training loss: 2.0842744863086877
Validation loss: 2.540383035634161

Epoch: 5| Step: 5
Training loss: 1.926288901498774
Validation loss: 2.5210735519225818

Epoch: 5| Step: 6
Training loss: 2.3743749097084534
Validation loss: 2.5157368005270264

Epoch: 5| Step: 7
Training loss: 1.8159317545355986
Validation loss: 2.5171211524395085

Epoch: 5| Step: 8
Training loss: 2.921784261834723
Validation loss: 2.5125225515286633

Epoch: 5| Step: 9
Training loss: 1.9144936212297419
Validation loss: 2.5219571856910186

Epoch: 5| Step: 10
Training loss: 2.2064955879960855
Validation loss: 2.5227739585648834

Epoch: 5| Step: 11
Training loss: 3.3511641116663196
Validation loss: 2.521679570024695

Epoch: 193| Step: 0
Training loss: 2.522989144663642
Validation loss: 2.5300257826736567

Epoch: 5| Step: 1
Training loss: 2.4798275576905238
Validation loss: 2.543303597042272

Epoch: 5| Step: 2
Training loss: 2.705338470380157
Validation loss: 2.5622999338033767

Epoch: 5| Step: 3
Training loss: 2.1724197472958955
Validation loss: 2.5650371265203162

Epoch: 5| Step: 4
Training loss: 2.7920505107966953
Validation loss: 2.576294389712794

Epoch: 5| Step: 5
Training loss: 2.8687334180697577
Validation loss: 2.550851810213517

Epoch: 5| Step: 6
Training loss: 1.9970373025045387
Validation loss: 2.5129110256311598

Epoch: 5| Step: 7
Training loss: 1.9081135380310401
Validation loss: 2.508689936818699

Epoch: 5| Step: 8
Training loss: 2.533858662229172
Validation loss: 2.5060254659141465

Epoch: 5| Step: 9
Training loss: 1.8845649256606023
Validation loss: 2.496218571255725

Epoch: 5| Step: 10
Training loss: 2.3471596901995415
Validation loss: 2.493238448734084

Epoch: 5| Step: 11
Training loss: 2.461561142147552
Validation loss: 2.493021822382091

Epoch: 194| Step: 0
Training loss: 2.252240231318656
Validation loss: 2.4992917766357867

Epoch: 5| Step: 1
Training loss: 2.7250032967363764
Validation loss: 2.5113339522414746

Epoch: 5| Step: 2
Training loss: 2.5513955467532727
Validation loss: 2.4996343941382055

Epoch: 5| Step: 3
Training loss: 2.469293269004727
Validation loss: 2.5172891108129396

Epoch: 5| Step: 4
Training loss: 2.348441654285404
Validation loss: 2.5178865352839135

Epoch: 5| Step: 5
Training loss: 2.3214320298053845
Validation loss: 2.509733868310203

Epoch: 5| Step: 6
Training loss: 2.701947964758066
Validation loss: 2.513088697133163

Epoch: 5| Step: 7
Training loss: 2.3222253794346974
Validation loss: 2.492822321097376

Epoch: 5| Step: 8
Training loss: 2.054561016410515
Validation loss: 2.5071821678308104

Epoch: 5| Step: 9
Training loss: 2.0500214831459362
Validation loss: 2.5285153196513317

Epoch: 5| Step: 10
Training loss: 2.389395703169415
Validation loss: 2.5240567710175115

Epoch: 5| Step: 11
Training loss: 1.9707249015459367
Validation loss: 2.514922642248068

Epoch: 195| Step: 0
Training loss: 2.324103960039553
Validation loss: 2.5144907327229493

Epoch: 5| Step: 1
Training loss: 1.965950443757001
Validation loss: 2.5251471295626855

Epoch: 5| Step: 2
Training loss: 1.7845828013835325
Validation loss: 2.529299797144789

Epoch: 5| Step: 3
Training loss: 2.0691364906907794
Validation loss: 2.5085318693268492

Epoch: 5| Step: 4
Training loss: 2.6340672250972994
Validation loss: 2.515792649568671

Epoch: 5| Step: 5
Training loss: 2.7153556066764493
Validation loss: 2.524757111075227

Epoch: 5| Step: 6
Training loss: 2.5551187227141336
Validation loss: 2.5296331744205136

Epoch: 5| Step: 7
Training loss: 2.6231739413913124
Validation loss: 2.5277285943701853

Epoch: 5| Step: 8
Training loss: 3.0332768536294474
Validation loss: 2.516094227185741

Epoch: 5| Step: 9
Training loss: 2.084849098654422
Validation loss: 2.5105128817237614

Epoch: 5| Step: 10
Training loss: 2.0251910884789948
Validation loss: 2.4919612825699087

Epoch: 5| Step: 11
Training loss: 2.9994592179217214
Validation loss: 2.4995597650423984

Epoch: 196| Step: 0
Training loss: 2.115802382184826
Validation loss: 2.4936350621479324

Epoch: 5| Step: 1
Training loss: 2.270150971622804
Validation loss: 2.494146635306696

Epoch: 5| Step: 2
Training loss: 2.3857754655438486
Validation loss: 2.4991644416672827

Epoch: 5| Step: 3
Training loss: 1.9376859268070368
Validation loss: 2.5100361006636893

Epoch: 5| Step: 4
Training loss: 3.020485395366216
Validation loss: 2.505907204444822

Epoch: 5| Step: 5
Training loss: 2.483943685842341
Validation loss: 2.5042718748333233

Epoch: 5| Step: 6
Training loss: 2.573502436584659
Validation loss: 2.5136901688817783

Epoch: 5| Step: 7
Training loss: 2.4943338078878132
Validation loss: 2.5235730932947296

Epoch: 5| Step: 8
Training loss: 2.3816658638093458
Validation loss: 2.5340378444129366

Epoch: 5| Step: 9
Training loss: 2.001971584328006
Validation loss: 2.52883705466386

Epoch: 5| Step: 10
Training loss: 2.4698281167337326
Validation loss: 2.5142250628059535

Epoch: 5| Step: 11
Training loss: 2.415995000259329
Validation loss: 2.5192281851248444

Epoch: 197| Step: 0
Training loss: 2.3150276597679613
Validation loss: 2.52349173189354

Epoch: 5| Step: 1
Training loss: 2.187904974371575
Validation loss: 2.5477324039136198

Epoch: 5| Step: 2
Training loss: 2.4324593877587564
Validation loss: 2.539661814066616

Epoch: 5| Step: 3
Training loss: 2.7270103458422312
Validation loss: 2.5331480500159

Epoch: 5| Step: 4
Training loss: 3.266294419884056
Validation loss: 2.525856057783992

Epoch: 5| Step: 5
Training loss: 2.2006057512199333
Validation loss: 2.513391209850015

Epoch: 5| Step: 6
Training loss: 1.962071915120279
Validation loss: 2.519355909766831

Epoch: 5| Step: 7
Training loss: 1.9998437105147981
Validation loss: 2.50747714865488

Epoch: 5| Step: 8
Training loss: 2.5251104047451753
Validation loss: 2.5059214123692612

Epoch: 5| Step: 9
Training loss: 2.508057199108797
Validation loss: 2.5037261810858404

Epoch: 5| Step: 10
Training loss: 2.035373317396151
Validation loss: 2.5168636344941655

Epoch: 5| Step: 11
Training loss: 0.8376394041957952
Validation loss: 2.5096575326562913

Epoch: 198| Step: 0
Training loss: 1.8196685044772642
Validation loss: 2.504216939106278

Epoch: 5| Step: 1
Training loss: 2.2160380808316
Validation loss: 2.511501858583411

Epoch: 5| Step: 2
Training loss: 1.981331601553289
Validation loss: 2.5196977860959406

Epoch: 5| Step: 3
Training loss: 2.497848061411408
Validation loss: 2.5365706633669514

Epoch: 5| Step: 4
Training loss: 1.9359012899021983
Validation loss: 2.5239788533718888

Epoch: 5| Step: 5
Training loss: 2.7017056481829824
Validation loss: 2.513158390582616

Epoch: 5| Step: 6
Training loss: 2.508755990683146
Validation loss: 2.509878650302228

Epoch: 5| Step: 7
Training loss: 2.646266261047654
Validation loss: 2.5062236050415287

Epoch: 5| Step: 8
Training loss: 2.205450575588473
Validation loss: 2.5163899279537523

Epoch: 5| Step: 9
Training loss: 2.437354743737577
Validation loss: 2.5107906915031872

Epoch: 5| Step: 10
Training loss: 2.8790939042152743
Validation loss: 2.500952086353105

Epoch: 5| Step: 11
Training loss: 3.0269020595124743
Validation loss: 2.508394239220614

Epoch: 199| Step: 0
Training loss: 2.589742298929707
Validation loss: 2.5014963162316457

Epoch: 5| Step: 1
Training loss: 3.0398136573700043
Validation loss: 2.5131803643118356

Epoch: 5| Step: 2
Training loss: 2.5399648148810527
Validation loss: 2.5265711960164188

Epoch: 5| Step: 3
Training loss: 2.0524372499192167
Validation loss: 2.5499441458624994

Epoch: 5| Step: 4
Training loss: 2.0731915877892657
Validation loss: 2.559527467992244

Epoch: 5| Step: 5
Training loss: 2.398939844265339
Validation loss: 2.566871434461509

Epoch: 5| Step: 6
Training loss: 2.191078311093476
Validation loss: 2.5501731704678177

Epoch: 5| Step: 7
Training loss: 2.6433640218575234
Validation loss: 2.556064281385863

Epoch: 5| Step: 8
Training loss: 2.559188098161454
Validation loss: 2.542777187556493

Epoch: 5| Step: 9
Training loss: 2.5485151193704283
Validation loss: 2.541171159805049

Epoch: 5| Step: 10
Training loss: 1.6194990656332704
Validation loss: 2.512059814963948

Epoch: 5| Step: 11
Training loss: 1.2952430292327386
Validation loss: 2.501700514370207

Epoch: 200| Step: 0
Training loss: 2.135522036550152
Validation loss: 2.4914510469904

Epoch: 5| Step: 1
Training loss: 2.451833688824058
Validation loss: 2.4865307102342213

Epoch: 5| Step: 2
Training loss: 2.1978245816820103
Validation loss: 2.4916658244136887

Epoch: 5| Step: 3
Training loss: 2.335488879141998
Validation loss: 2.4926824566499235

Epoch: 5| Step: 4
Training loss: 2.7786139522440805
Validation loss: 2.4924910469111192

Epoch: 5| Step: 5
Training loss: 2.6511595474345504
Validation loss: 2.4875716889976056

Epoch: 5| Step: 6
Training loss: 2.8019650137689105
Validation loss: 2.497975753793768

Epoch: 5| Step: 7
Training loss: 2.2482891996146224
Validation loss: 2.495860160997628

Epoch: 5| Step: 8
Training loss: 2.2427244174898475
Validation loss: 2.4922433565869917

Epoch: 5| Step: 9
Training loss: 2.4621704888025477
Validation loss: 2.4942805510611956

Epoch: 5| Step: 10
Training loss: 2.589115552525579
Validation loss: 2.4944827990909624

Epoch: 5| Step: 11
Training loss: 2.860907138932121
Validation loss: 2.4981271503704234

Testing loss: 2.018127368771513
