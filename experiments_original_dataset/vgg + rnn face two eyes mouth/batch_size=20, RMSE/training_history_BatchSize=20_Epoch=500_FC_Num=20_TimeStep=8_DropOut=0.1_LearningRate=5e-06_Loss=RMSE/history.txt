Epoch: 1| Step: 0
Training loss: 5.588582129093483
Validation loss: 5.917125048365325

Epoch: 5| Step: 1
Training loss: 6.516635148670567
Validation loss: 5.915544634080179

Epoch: 5| Step: 2
Training loss: 6.018083342553501
Validation loss: 5.913750899390135

Epoch: 5| Step: 3
Training loss: 5.264058499831517
Validation loss: 5.912113945409669

Epoch: 5| Step: 4
Training loss: 6.682113902779329
Validation loss: 5.910571641563163

Epoch: 5| Step: 5
Training loss: 5.931601073604556
Validation loss: 5.9088613802340575

Epoch: 5| Step: 6
Training loss: 5.663826436352287
Validation loss: 5.9072474490184455

Epoch: 5| Step: 7
Training loss: 6.720446279329921
Validation loss: 5.905541056179279

Epoch: 5| Step: 8
Training loss: 5.077136322024638
Validation loss: 5.903873900820886

Epoch: 5| Step: 9
Training loss: 6.206430779443168
Validation loss: 5.902148348091915

Epoch: 5| Step: 10
Training loss: 6.338532505535525
Validation loss: 5.90028796274509

Epoch: 5| Step: 11
Training loss: 6.111919214783284
Validation loss: 5.898491750977144

Epoch: 2| Step: 0
Training loss: 5.940116225624359
Validation loss: 5.89655353025014

Epoch: 5| Step: 1
Training loss: 5.989144359480026
Validation loss: 5.894545433544759

Epoch: 5| Step: 2
Training loss: 5.325569322982436
Validation loss: 5.892400634169506

Epoch: 5| Step: 3
Training loss: 6.426581447136548
Validation loss: 5.890267628589512

Epoch: 5| Step: 4
Training loss: 6.88216013420154
Validation loss: 5.887854648985413

Epoch: 5| Step: 5
Training loss: 5.251234000367088
Validation loss: 5.885502261549315

Epoch: 5| Step: 6
Training loss: 6.116154102327537
Validation loss: 5.882972853570339

Epoch: 5| Step: 7
Training loss: 5.186578324030566
Validation loss: 5.880347712858144

Epoch: 5| Step: 8
Training loss: 6.368388618496158
Validation loss: 5.877518256194377

Epoch: 5| Step: 9
Training loss: 5.859462564449871
Validation loss: 5.874563011529129

Epoch: 5| Step: 10
Training loss: 6.5520948481698635
Validation loss: 5.871468084317507

Epoch: 5| Step: 11
Training loss: 5.225779476156916
Validation loss: 5.868054484631242

Epoch: 3| Step: 0
Training loss: 7.165670931935485
Validation loss: 5.864830684922562

Epoch: 5| Step: 1
Training loss: 6.115540342373617
Validation loss: 5.861147409882116

Epoch: 5| Step: 2
Training loss: 6.018201875535355
Validation loss: 5.857400410557608

Epoch: 5| Step: 3
Training loss: 5.63483112369861
Validation loss: 5.853521992583742

Epoch: 5| Step: 4
Training loss: 6.222761077859964
Validation loss: 5.8495298283623445

Epoch: 5| Step: 5
Training loss: 6.354817474889437
Validation loss: 5.845126297660106

Epoch: 5| Step: 6
Training loss: 5.78178675453801
Validation loss: 5.840631533490332

Epoch: 5| Step: 7
Training loss: 5.852884751830749
Validation loss: 5.835806740041051

Epoch: 5| Step: 8
Training loss: 5.1154213689451185
Validation loss: 5.830761733197723

Epoch: 5| Step: 9
Training loss: 5.653688472503257
Validation loss: 5.825879957452422

Epoch: 5| Step: 10
Training loss: 5.5355032392783
Validation loss: 5.82053029039052

Epoch: 5| Step: 11
Training loss: 5.336368571304702
Validation loss: 5.815099121401339

Epoch: 4| Step: 0
Training loss: 5.012581064990917
Validation loss: 5.809711484721558

Epoch: 5| Step: 1
Training loss: 6.261839981476154
Validation loss: 5.80419884221163

Epoch: 5| Step: 2
Training loss: 5.620182602383205
Validation loss: 5.798362081920074

Epoch: 5| Step: 3
Training loss: 5.279561873378236
Validation loss: 5.792014450041606

Epoch: 5| Step: 4
Training loss: 5.876829471219074
Validation loss: 5.785867575616873

Epoch: 5| Step: 5
Training loss: 6.237735464051231
Validation loss: 5.7794295529194235

Epoch: 5| Step: 6
Training loss: 6.155488717503945
Validation loss: 5.7729190289058785

Epoch: 5| Step: 7
Training loss: 6.118642193133837
Validation loss: 5.76596158638088

Epoch: 5| Step: 8
Training loss: 6.0482557824759615
Validation loss: 5.759196349347019

Epoch: 5| Step: 9
Training loss: 6.2560852943713305
Validation loss: 5.752033827625172

Epoch: 5| Step: 10
Training loss: 5.8116657930021045
Validation loss: 5.744601721806696

Epoch: 5| Step: 11
Training loss: 5.8676565823427795
Validation loss: 5.736823284324596

Epoch: 5| Step: 0
Training loss: 6.304292990290178
Validation loss: 5.729396429367552

Epoch: 5| Step: 1
Training loss: 6.85780931821668
Validation loss: 5.721404496603725

Epoch: 5| Step: 2
Training loss: 5.704090778671753
Validation loss: 5.713166893693916

Epoch: 5| Step: 3
Training loss: 5.753008511517582
Validation loss: 5.704665978282355

Epoch: 5| Step: 4
Training loss: 4.532946459774011
Validation loss: 5.696388941773755

Epoch: 5| Step: 5
Training loss: 5.700872441498606
Validation loss: 5.687919594234851

Epoch: 5| Step: 6
Training loss: 6.345200847215469
Validation loss: 5.679374808650831

Epoch: 5| Step: 7
Training loss: 5.666725532375584
Validation loss: 5.670266609079775

Epoch: 5| Step: 8
Training loss: 5.384072741738366
Validation loss: 5.661508662313907

Epoch: 5| Step: 9
Training loss: 5.527723837141482
Validation loss: 5.652369304283742

Epoch: 5| Step: 10
Training loss: 5.673949143502843
Validation loss: 5.643051858207502

Epoch: 5| Step: 11
Training loss: 6.257279696028933
Validation loss: 5.633703428541034

Epoch: 6| Step: 0
Training loss: 5.149787691054793
Validation loss: 5.623709629544491

Epoch: 5| Step: 1
Training loss: 6.14951261744611
Validation loss: 5.614165673324016

Epoch: 5| Step: 2
Training loss: 5.510251634670833
Validation loss: 5.603755250409687

Epoch: 5| Step: 3
Training loss: 6.262633410953433
Validation loss: 5.5937207539111755

Epoch: 5| Step: 4
Training loss: 5.8604989156455956
Validation loss: 5.583254694977951

Epoch: 5| Step: 5
Training loss: 5.215283550333191
Validation loss: 5.572579285103392

Epoch: 5| Step: 6
Training loss: 5.667616409297603
Validation loss: 5.5618568291456425

Epoch: 5| Step: 7
Training loss: 5.922702701267189
Validation loss: 5.55110575197002

Epoch: 5| Step: 8
Training loss: 5.046276328656235
Validation loss: 5.540174364589193

Epoch: 5| Step: 9
Training loss: 5.956715539789747
Validation loss: 5.529219245612737

Epoch: 5| Step: 10
Training loss: 5.789313883606582
Validation loss: 5.518399521444106

Epoch: 5| Step: 11
Training loss: 5.20053466835786
Validation loss: 5.507626368486595

Epoch: 7| Step: 0
Training loss: 5.9359385796425705
Validation loss: 5.497329309140205

Epoch: 5| Step: 1
Training loss: 5.3958806609013745
Validation loss: 5.487089733234274

Epoch: 5| Step: 2
Training loss: 5.574773556340004
Validation loss: 5.476443069469049

Epoch: 5| Step: 3
Training loss: 4.932062946026181
Validation loss: 5.466790260491749

Epoch: 5| Step: 4
Training loss: 6.166156369652006
Validation loss: 5.4568405172647685

Epoch: 5| Step: 5
Training loss: 5.114867638211266
Validation loss: 5.447361688688941

Epoch: 5| Step: 6
Training loss: 5.94067586990401
Validation loss: 5.438242638689313

Epoch: 5| Step: 7
Training loss: 5.656138887947411
Validation loss: 5.42949223521745

Epoch: 5| Step: 8
Training loss: 5.170207235879281
Validation loss: 5.420277817410731

Epoch: 5| Step: 9
Training loss: 5.146164897579184
Validation loss: 5.4117555753882085

Epoch: 5| Step: 10
Training loss: 5.611771010737441
Validation loss: 5.403663008942175

Epoch: 5| Step: 11
Training loss: 7.534263419516084
Validation loss: 5.395305271403455

Epoch: 8| Step: 0
Training loss: 4.977167449065788
Validation loss: 5.387422968821924

Epoch: 5| Step: 1
Training loss: 5.440271482425324
Validation loss: 5.379564542802816

Epoch: 5| Step: 2
Training loss: 5.466331426684392
Validation loss: 5.371914909707189

Epoch: 5| Step: 3
Training loss: 4.314980719424919
Validation loss: 5.3646283441031795

Epoch: 5| Step: 4
Training loss: 4.830254242644375
Validation loss: 5.357039926236419

Epoch: 5| Step: 5
Training loss: 4.92390927857309
Validation loss: 5.349691348813271

Epoch: 5| Step: 6
Training loss: 6.290833407501545
Validation loss: 5.342912857485467

Epoch: 5| Step: 7
Training loss: 6.539626595106021
Validation loss: 5.335440482677654

Epoch: 5| Step: 8
Training loss: 5.947939398923102
Validation loss: 5.3280035100157805

Epoch: 5| Step: 9
Training loss: 5.9033370327771895
Validation loss: 5.3203142327648

Epoch: 5| Step: 10
Training loss: 5.319463496869891
Validation loss: 5.312943937414987

Epoch: 5| Step: 11
Training loss: 4.382683247174995
Validation loss: 5.305279091538484

Epoch: 9| Step: 0
Training loss: 5.919374768516223
Validation loss: 5.298221405761407

Epoch: 5| Step: 1
Training loss: 5.417837437012713
Validation loss: 5.290856361925859

Epoch: 5| Step: 2
Training loss: 5.468556079151087
Validation loss: 5.284165685453365

Epoch: 5| Step: 3
Training loss: 5.55055445745344
Validation loss: 5.276819526392525

Epoch: 5| Step: 4
Training loss: 5.083699989645022
Validation loss: 5.269512224551864

Epoch: 5| Step: 5
Training loss: 5.307649799376581
Validation loss: 5.262172181950095

Epoch: 5| Step: 6
Training loss: 4.878656238903054
Validation loss: 5.254833388271878

Epoch: 5| Step: 7
Training loss: 5.737184922287195
Validation loss: 5.2475917606045694

Epoch: 5| Step: 8
Training loss: 5.5677350730242
Validation loss: 5.240256297259614

Epoch: 5| Step: 9
Training loss: 5.228494284311603
Validation loss: 5.232861458507681

Epoch: 5| Step: 10
Training loss: 5.423133901826385
Validation loss: 5.225907844024836

Epoch: 5| Step: 11
Training loss: 2.459692455389018
Validation loss: 5.2186571063456215

Epoch: 10| Step: 0
Training loss: 5.089222586868871
Validation loss: 5.2117791513678755

Epoch: 5| Step: 1
Training loss: 5.437731156971449
Validation loss: 5.205159924444705

Epoch: 5| Step: 2
Training loss: 5.4835653114912954
Validation loss: 5.198338794067359

Epoch: 5| Step: 3
Training loss: 5.713869440720159
Validation loss: 5.191925084135901

Epoch: 5| Step: 4
Training loss: 5.118791122178188
Validation loss: 5.18528964739104

Epoch: 5| Step: 5
Training loss: 5.258599821774927
Validation loss: 5.178628896760822

Epoch: 5| Step: 6
Training loss: 5.532747227677763
Validation loss: 5.171970178318023

Epoch: 5| Step: 7
Training loss: 5.417474461501007
Validation loss: 5.165427954166199

Epoch: 5| Step: 8
Training loss: 5.47799859692659
Validation loss: 5.158645297011555

Epoch: 5| Step: 9
Training loss: 4.72801824173095
Validation loss: 5.1520512680781465

Epoch: 5| Step: 10
Training loss: 5.149002067395105
Validation loss: 5.145502630667841

Epoch: 5| Step: 11
Training loss: 4.45940718983378
Validation loss: 5.139076695432743

Epoch: 11| Step: 0
Training loss: 5.388648336925304
Validation loss: 5.132825382086828

Epoch: 5| Step: 1
Training loss: 5.001569692266287
Validation loss: 5.126498507249797

Epoch: 5| Step: 2
Training loss: 5.476269070631935
Validation loss: 5.120195198907814

Epoch: 5| Step: 3
Training loss: 5.022476982493085
Validation loss: 5.114236857480759

Epoch: 5| Step: 4
Training loss: 5.685433148446055
Validation loss: 5.107817572879694

Epoch: 5| Step: 5
Training loss: 5.283841372029954
Validation loss: 5.1019574996282655

Epoch: 5| Step: 6
Training loss: 5.108588948577897
Validation loss: 5.09560571891549

Epoch: 5| Step: 7
Training loss: 5.752856664496874
Validation loss: 5.089994212161647

Epoch: 5| Step: 8
Training loss: 5.280433365925795
Validation loss: 5.084046582175905

Epoch: 5| Step: 9
Training loss: 4.219685316601533
Validation loss: 5.07762538701876

Epoch: 5| Step: 10
Training loss: 5.0768303262467835
Validation loss: 5.0717259784522675

Epoch: 5| Step: 11
Training loss: 5.35682052369191
Validation loss: 5.065714294506311

Epoch: 12| Step: 0
Training loss: 5.17618365181005
Validation loss: 5.059398234649582

Epoch: 5| Step: 1
Training loss: 5.127502760716685
Validation loss: 5.053240038667733

Epoch: 5| Step: 2
Training loss: 4.2333841325810795
Validation loss: 5.047152902295893

Epoch: 5| Step: 3
Training loss: 6.40081526808823
Validation loss: 5.040759764302797

Epoch: 5| Step: 4
Training loss: 5.007031455704376
Validation loss: 5.033897587851547

Epoch: 5| Step: 5
Training loss: 4.420892073768062
Validation loss: 5.027745102178476

Epoch: 5| Step: 6
Training loss: 5.29465674479149
Validation loss: 5.02107628620997

Epoch: 5| Step: 7
Training loss: 5.198292730738922
Validation loss: 5.015134373452823

Epoch: 5| Step: 8
Training loss: 4.533712204827427
Validation loss: 5.009639158877271

Epoch: 5| Step: 9
Training loss: 5.054667500805683
Validation loss: 5.003623237716351

Epoch: 5| Step: 10
Training loss: 5.283169910939958
Validation loss: 4.9980421922171585

Epoch: 5| Step: 11
Training loss: 7.641971898474262
Validation loss: 4.9924371265928

Epoch: 13| Step: 0
Training loss: 5.638223321698228
Validation loss: 4.9867411212199215

Epoch: 5| Step: 1
Training loss: 4.827213534642238
Validation loss: 4.981010999892963

Epoch: 5| Step: 2
Training loss: 5.259744411104175
Validation loss: 4.975367843345359

Epoch: 5| Step: 3
Training loss: 4.905433927079179
Validation loss: 4.969164585115435

Epoch: 5| Step: 4
Training loss: 4.617669972676967
Validation loss: 4.963584085812259

Epoch: 5| Step: 5
Training loss: 4.648414316840824
Validation loss: 4.957750208676048

Epoch: 5| Step: 6
Training loss: 4.785576153451474
Validation loss: 4.9515467715612935

Epoch: 5| Step: 7
Training loss: 4.731361361645574
Validation loss: 4.9461116135083385

Epoch: 5| Step: 8
Training loss: 5.507767654128155
Validation loss: 4.940026003296815

Epoch: 5| Step: 9
Training loss: 5.2791977004072645
Validation loss: 4.934323347263032

Epoch: 5| Step: 10
Training loss: 5.229088690228292
Validation loss: 4.9280867116114395

Epoch: 5| Step: 11
Training loss: 6.582063705409597
Validation loss: 4.921968126172867

Epoch: 14| Step: 0
Training loss: 4.274490254668486
Validation loss: 4.916170946551405

Epoch: 5| Step: 1
Training loss: 5.3509376773701645
Validation loss: 4.9098349025780825

Epoch: 5| Step: 2
Training loss: 4.72610123330337
Validation loss: 4.903963580770543

Epoch: 5| Step: 3
Training loss: 5.243455349779089
Validation loss: 4.89792154566907

Epoch: 5| Step: 4
Training loss: 4.712963472033356
Validation loss: 4.892207619857068

Epoch: 5| Step: 5
Training loss: 5.857181229947492
Validation loss: 4.886798446334725

Epoch: 5| Step: 6
Training loss: 5.562393530351752
Validation loss: 4.880854522796291

Epoch: 5| Step: 7
Training loss: 4.4650073618043224
Validation loss: 4.874776362318713

Epoch: 5| Step: 8
Training loss: 4.258798131690355
Validation loss: 4.869254614715653

Epoch: 5| Step: 9
Training loss: 5.168908135464028
Validation loss: 4.863088286834496

Epoch: 5| Step: 10
Training loss: 4.750330662511637
Validation loss: 4.857949807365685

Epoch: 5| Step: 11
Training loss: 6.963264256279752
Validation loss: 4.852188487678998

Epoch: 15| Step: 0
Training loss: 4.31460453594947
Validation loss: 4.846050798889051

Epoch: 5| Step: 1
Training loss: 4.60119731082196
Validation loss: 4.8401967541581

Epoch: 5| Step: 2
Training loss: 5.121034716419374
Validation loss: 4.834333952006365

Epoch: 5| Step: 3
Training loss: 4.497709115019022
Validation loss: 4.827715546695002

Epoch: 5| Step: 4
Training loss: 4.936009628768754
Validation loss: 4.821748343465005

Epoch: 5| Step: 5
Training loss: 5.1509905260695446
Validation loss: 4.816644114581225

Epoch: 5| Step: 6
Training loss: 5.262055497413661
Validation loss: 4.810618061504901

Epoch: 5| Step: 7
Training loss: 5.549857527820111
Validation loss: 4.8039889357622325

Epoch: 5| Step: 8
Training loss: 4.641191544291796
Validation loss: 4.7978118246762085

Epoch: 5| Step: 9
Training loss: 5.102448133908714
Validation loss: 4.791174592445575

Epoch: 5| Step: 10
Training loss: 4.89162291074524
Validation loss: 4.785187448412858

Epoch: 5| Step: 11
Training loss: 5.580051976170356
Validation loss: 4.780182039752844

Epoch: 16| Step: 0
Training loss: 3.1964718084310904
Validation loss: 4.774618315962075

Epoch: 5| Step: 1
Training loss: 4.0233201685713516
Validation loss: 4.768610522529036

Epoch: 5| Step: 2
Training loss: 4.853849648968839
Validation loss: 4.764170598794754

Epoch: 5| Step: 3
Training loss: 4.989521108516727
Validation loss: 4.758210297623415

Epoch: 5| Step: 4
Training loss: 4.807128087901467
Validation loss: 4.752922940646216

Epoch: 5| Step: 5
Training loss: 5.556379744534971
Validation loss: 4.747552107099322

Epoch: 5| Step: 6
Training loss: 5.261273224340484
Validation loss: 4.742288495181859

Epoch: 5| Step: 7
Training loss: 5.464486863737524
Validation loss: 4.73651550551536

Epoch: 5| Step: 8
Training loss: 4.9398408000791845
Validation loss: 4.730517352752528

Epoch: 5| Step: 9
Training loss: 4.511704164952075
Validation loss: 4.725513688678428

Epoch: 5| Step: 10
Training loss: 5.447135893657301
Validation loss: 4.721072435959544

Epoch: 5| Step: 11
Training loss: 5.006023593312048
Validation loss: 4.714384320495284

Epoch: 17| Step: 0
Training loss: 5.0606284744120735
Validation loss: 4.709654292191056

Epoch: 5| Step: 1
Training loss: 4.623785323363611
Validation loss: 4.7040714312842224

Epoch: 5| Step: 2
Training loss: 4.926826239149447
Validation loss: 4.699003972033651

Epoch: 5| Step: 3
Training loss: 4.904433770739724
Validation loss: 4.69257549587591

Epoch: 5| Step: 4
Training loss: 5.328601446691763
Validation loss: 4.686262403932852

Epoch: 5| Step: 5
Training loss: 4.604572238003778
Validation loss: 4.680800265824215

Epoch: 5| Step: 6
Training loss: 4.551882997668425
Validation loss: 4.675709990784605

Epoch: 5| Step: 7
Training loss: 4.604750353148294
Validation loss: 4.670588168340971

Epoch: 5| Step: 8
Training loss: 4.541794078101293
Validation loss: 4.664982358361482

Epoch: 5| Step: 9
Training loss: 5.2950886552717416
Validation loss: 4.6598830290877435

Epoch: 5| Step: 10
Training loss: 4.538373727458757
Validation loss: 4.65409848303556

Epoch: 5| Step: 11
Training loss: 3.8065308916649054
Validation loss: 4.6491947529645214

Epoch: 18| Step: 0
Training loss: 4.080601667284006
Validation loss: 4.643991886580326

Epoch: 5| Step: 1
Training loss: 5.2076099758100405
Validation loss: 4.639041236493794

Epoch: 5| Step: 2
Training loss: 5.584138764698475
Validation loss: 4.633481479695991

Epoch: 5| Step: 3
Training loss: 4.237443888695031
Validation loss: 4.628176925440011

Epoch: 5| Step: 4
Training loss: 4.001762716996055
Validation loss: 4.623245473511385

Epoch: 5| Step: 5
Training loss: 4.819406680870087
Validation loss: 4.618334752998882

Epoch: 5| Step: 6
Training loss: 4.807725197312756
Validation loss: 4.613312620206504

Epoch: 5| Step: 7
Training loss: 4.723893147964787
Validation loss: 4.6082515662161025

Epoch: 5| Step: 8
Training loss: 4.222717679941697
Validation loss: 4.602835867080427

Epoch: 5| Step: 9
Training loss: 5.668781372118089
Validation loss: 4.597662364747144

Epoch: 5| Step: 10
Training loss: 4.908435116259289
Validation loss: 4.5924842716945165

Epoch: 5| Step: 11
Training loss: 1.5794333143077275
Validation loss: 4.586506320350867

Epoch: 19| Step: 0
Training loss: 4.616923523148668
Validation loss: 4.581421126655951

Epoch: 5| Step: 1
Training loss: 4.309195316543803
Validation loss: 4.576757094306495

Epoch: 5| Step: 2
Training loss: 4.843040562020514
Validation loss: 4.571242600267134

Epoch: 5| Step: 3
Training loss: 5.05256997612576
Validation loss: 4.566008738414854

Epoch: 5| Step: 4
Training loss: 3.667781284729544
Validation loss: 4.55996012429041

Epoch: 5| Step: 5
Training loss: 5.048775235457985
Validation loss: 4.5550798407465445

Epoch: 5| Step: 6
Training loss: 4.475659983465864
Validation loss: 4.55029955321536

Epoch: 5| Step: 7
Training loss: 5.788488197411502
Validation loss: 4.545263675634224

Epoch: 5| Step: 8
Training loss: 4.490844313456555
Validation loss: 4.5395703187603935

Epoch: 5| Step: 9
Training loss: 4.671052483967976
Validation loss: 4.534264086035676

Epoch: 5| Step: 10
Training loss: 4.453601048773424
Validation loss: 4.529204974791868

Epoch: 5| Step: 11
Training loss: 3.4998697529127445
Validation loss: 4.523994516919976

Epoch: 20| Step: 0
Training loss: 3.9293717547573634
Validation loss: 4.519524743798885

Epoch: 5| Step: 1
Training loss: 3.9516051012957902
Validation loss: 4.514990721334313

Epoch: 5| Step: 2
Training loss: 5.240668768975785
Validation loss: 4.510036490659976

Epoch: 5| Step: 3
Training loss: 5.135640704959748
Validation loss: 4.504895602564445

Epoch: 5| Step: 4
Training loss: 5.406472967764833
Validation loss: 4.5000814412835926

Epoch: 5| Step: 5
Training loss: 4.350008620330337
Validation loss: 4.49472911639431

Epoch: 5| Step: 6
Training loss: 4.888655098228305
Validation loss: 4.48973569441824

Epoch: 5| Step: 7
Training loss: 3.37284527978561
Validation loss: 4.484749126002494

Epoch: 5| Step: 8
Training loss: 4.652920345317354
Validation loss: 4.479868007429832

Epoch: 5| Step: 9
Training loss: 4.330891850624044
Validation loss: 4.474995612385621

Epoch: 5| Step: 10
Training loss: 4.92626466731008
Validation loss: 4.470059191946957

Epoch: 5| Step: 11
Training loss: 5.6277459118062145
Validation loss: 4.464872505315662

Epoch: 21| Step: 0
Training loss: 4.750621353467203
Validation loss: 4.459525459957373

Epoch: 5| Step: 1
Training loss: 5.022857680014599
Validation loss: 4.454526196711238

Epoch: 5| Step: 2
Training loss: 4.60125306518751
Validation loss: 4.448794015600737

Epoch: 5| Step: 3
Training loss: 4.295724721744838
Validation loss: 4.444550840607653

Epoch: 5| Step: 4
Training loss: 4.471740575618711
Validation loss: 4.438837816835541

Epoch: 5| Step: 5
Training loss: 5.056041601009882
Validation loss: 4.434238641249505

Epoch: 5| Step: 6
Training loss: 4.332754365439535
Validation loss: 4.428997122796311

Epoch: 5| Step: 7
Training loss: 4.305779569533955
Validation loss: 4.425101946071274

Epoch: 5| Step: 8
Training loss: 4.072265156624673
Validation loss: 4.419667918660355

Epoch: 5| Step: 9
Training loss: 4.753089101080224
Validation loss: 4.414438687388595

Epoch: 5| Step: 10
Training loss: 4.767719746462721
Validation loss: 4.408979521890371

Epoch: 5| Step: 11
Training loss: 2.3419290207841725
Validation loss: 4.403722128121649

Epoch: 22| Step: 0
Training loss: 4.233490235632452
Validation loss: 4.3993382996736665

Epoch: 5| Step: 1
Training loss: 4.575732963506536
Validation loss: 4.393929022320353

Epoch: 5| Step: 2
Training loss: 4.336922748422117
Validation loss: 4.388849132326925

Epoch: 5| Step: 3
Training loss: 4.846006003419792
Validation loss: 4.3842269917794505

Epoch: 5| Step: 4
Training loss: 4.24089173818259
Validation loss: 4.380225398891859

Epoch: 5| Step: 5
Training loss: 4.584034929618437
Validation loss: 4.374279280744093

Epoch: 5| Step: 6
Training loss: 4.137067540551279
Validation loss: 4.36956522206719

Epoch: 5| Step: 7
Training loss: 4.382795527624223
Validation loss: 4.364171391835962

Epoch: 5| Step: 8
Training loss: 4.524292965443132
Validation loss: 4.359578117642872

Epoch: 5| Step: 9
Training loss: 4.812208885206293
Validation loss: 4.3543235105650835

Epoch: 5| Step: 10
Training loss: 4.506040122214605
Validation loss: 4.349850416534748

Epoch: 5| Step: 11
Training loss: 5.767343652637424
Validation loss: 4.3449801434384

Epoch: 23| Step: 0
Training loss: 4.4193988242766205
Validation loss: 4.3393027503179855

Epoch: 5| Step: 1
Training loss: 4.134908162841917
Validation loss: 4.333740979363041

Epoch: 5| Step: 2
Training loss: 4.856802599873771
Validation loss: 4.328467097344743

Epoch: 5| Step: 3
Training loss: 4.886488655216901
Validation loss: 4.322991706779009

Epoch: 5| Step: 4
Training loss: 4.299157996132267
Validation loss: 4.31807935690507

Epoch: 5| Step: 5
Training loss: 4.140980370584414
Validation loss: 4.313015266632601

Epoch: 5| Step: 6
Training loss: 4.4346788061698
Validation loss: 4.3077815683255425

Epoch: 5| Step: 7
Training loss: 4.399082278866836
Validation loss: 4.30278575910979

Epoch: 5| Step: 8
Training loss: 4.081844343807137
Validation loss: 4.298485656342804

Epoch: 5| Step: 9
Training loss: 4.6260428412829
Validation loss: 4.2940303472202555

Epoch: 5| Step: 10
Training loss: 4.538953664922617
Validation loss: 4.288537081862007

Epoch: 5| Step: 11
Training loss: 4.292980523826553
Validation loss: 4.283217235703715

Epoch: 24| Step: 0
Training loss: 5.169558095437134
Validation loss: 4.277846326870518

Epoch: 5| Step: 1
Training loss: 4.469524183102698
Validation loss: 4.2733706806730964

Epoch: 5| Step: 2
Training loss: 4.332922744861654
Validation loss: 4.267618097951738

Epoch: 5| Step: 3
Training loss: 4.4462953898826605
Validation loss: 4.263196074329482

Epoch: 5| Step: 4
Training loss: 4.774903517142777
Validation loss: 4.2577196770212185

Epoch: 5| Step: 5
Training loss: 4.635623175775097
Validation loss: 4.25238602641934

Epoch: 5| Step: 6
Training loss: 4.2154756625611665
Validation loss: 4.24775199714401

Epoch: 5| Step: 7
Training loss: 3.844979066432127
Validation loss: 4.242907927186105

Epoch: 5| Step: 8
Training loss: 4.280271989255117
Validation loss: 4.237872341605431

Epoch: 5| Step: 9
Training loss: 3.821470369892179
Validation loss: 4.232673378187482

Epoch: 5| Step: 10
Training loss: 4.182910282786124
Validation loss: 4.227799700478119

Epoch: 5| Step: 11
Training loss: 3.749723169917105
Validation loss: 4.223323579908418

Epoch: 25| Step: 0
Training loss: 3.6168518569809684
Validation loss: 4.219257578514848

Epoch: 5| Step: 1
Training loss: 4.588326918577529
Validation loss: 4.214830240034124

Epoch: 5| Step: 2
Training loss: 4.019492576420488
Validation loss: 4.21084278969779

Epoch: 5| Step: 3
Training loss: 4.609472241426606
Validation loss: 4.205647856533591

Epoch: 5| Step: 4
Training loss: 4.191202604922923
Validation loss: 4.201235264823517

Epoch: 5| Step: 5
Training loss: 4.569381749509873
Validation loss: 4.196112757106895

Epoch: 5| Step: 6
Training loss: 4.830247134881734
Validation loss: 4.191336876211241

Epoch: 5| Step: 7
Training loss: 4.3041535477316755
Validation loss: 4.18706584217023

Epoch: 5| Step: 8
Training loss: 3.354991803450599
Validation loss: 4.182353648307993

Epoch: 5| Step: 9
Training loss: 4.4101700896594185
Validation loss: 4.1777525751740825

Epoch: 5| Step: 10
Training loss: 4.551408009079422
Validation loss: 4.173401818693602

Epoch: 5| Step: 11
Training loss: 5.65216321465746
Validation loss: 4.168417422913103

Epoch: 26| Step: 0
Training loss: 4.965482969275402
Validation loss: 4.164141617835065

Epoch: 5| Step: 1
Training loss: 4.28881990896655
Validation loss: 4.158969199974981

Epoch: 5| Step: 2
Training loss: 4.789566884697734
Validation loss: 4.153854712452997

Epoch: 5| Step: 3
Training loss: 3.535535389501494
Validation loss: 4.148488582624645

Epoch: 5| Step: 4
Training loss: 4.509020347686358
Validation loss: 4.143647939001448

Epoch: 5| Step: 5
Training loss: 4.069966892791986
Validation loss: 4.138600714712202

Epoch: 5| Step: 6
Training loss: 3.9370388184780607
Validation loss: 4.133854043114755

Epoch: 5| Step: 7
Training loss: 4.183512824920514
Validation loss: 4.129181231073022

Epoch: 5| Step: 8
Training loss: 4.309394049654233
Validation loss: 4.124384260942313

Epoch: 5| Step: 9
Training loss: 4.022786563696929
Validation loss: 4.119522132528252

Epoch: 5| Step: 10
Training loss: 4.192728905795154
Validation loss: 4.114766136969535

Epoch: 5| Step: 11
Training loss: 4.244911064231771
Validation loss: 4.109652989682336

Epoch: 27| Step: 0
Training loss: 3.2019097232518114
Validation loss: 4.10567212289182

Epoch: 5| Step: 1
Training loss: 4.064791927854124
Validation loss: 4.1007128510621484

Epoch: 5| Step: 2
Training loss: 4.235394907512522
Validation loss: 4.096419936725433

Epoch: 5| Step: 3
Training loss: 4.348154154300483
Validation loss: 4.091877462948517

Epoch: 5| Step: 4
Training loss: 4.757734526698404
Validation loss: 4.087652922169963

Epoch: 5| Step: 5
Training loss: 4.650196005679261
Validation loss: 4.0827609102123885

Epoch: 5| Step: 6
Training loss: 4.454746954824545
Validation loss: 4.0782308942314955

Epoch: 5| Step: 7
Training loss: 4.475555572972765
Validation loss: 4.073142675517813

Epoch: 5| Step: 8
Training loss: 4.2282756499457115
Validation loss: 4.0686857471383275

Epoch: 5| Step: 9
Training loss: 3.6351817291042385
Validation loss: 4.063816375690992

Epoch: 5| Step: 10
Training loss: 4.319513781700753
Validation loss: 4.059432226124677

Epoch: 5| Step: 11
Training loss: 2.6877522017553575
Validation loss: 4.054897795352253

Epoch: 28| Step: 0
Training loss: 4.383305323019328
Validation loss: 4.050796175236123

Epoch: 5| Step: 1
Training loss: 3.8712346641229374
Validation loss: 4.045881112494586

Epoch: 5| Step: 2
Training loss: 3.969739895618753
Validation loss: 4.041541322095025

Epoch: 5| Step: 3
Training loss: 4.190580459119069
Validation loss: 4.037592543534436

Epoch: 5| Step: 4
Training loss: 4.126713021366736
Validation loss: 4.032515314920144

Epoch: 5| Step: 5
Training loss: 4.592765027800349
Validation loss: 4.02805713017327

Epoch: 5| Step: 6
Training loss: 3.946768010638244
Validation loss: 4.023530145461183

Epoch: 5| Step: 7
Training loss: 4.023886409271117
Validation loss: 4.019362544655032

Epoch: 5| Step: 8
Training loss: 4.236456440397649
Validation loss: 4.014850512081523

Epoch: 5| Step: 9
Training loss: 3.5328190111305267
Validation loss: 4.010379284110619

Epoch: 5| Step: 10
Training loss: 4.335838083038182
Validation loss: 4.006175469683707

Epoch: 5| Step: 11
Training loss: 6.030422015502613
Validation loss: 4.001783499870402

Epoch: 29| Step: 0
Training loss: 4.074745385576305
Validation loss: 3.996963197571627

Epoch: 5| Step: 1
Training loss: 4.203056476700961
Validation loss: 3.9925484142660412

Epoch: 5| Step: 2
Training loss: 4.510546299904701
Validation loss: 3.9872967896456064

Epoch: 5| Step: 3
Training loss: 4.187725459619635
Validation loss: 3.9825106778174306

Epoch: 5| Step: 4
Training loss: 3.994892316376726
Validation loss: 3.977744525735513

Epoch: 5| Step: 5
Training loss: 3.6594399124760146
Validation loss: 3.973362552617525

Epoch: 5| Step: 6
Training loss: 3.8782067105079263
Validation loss: 3.9685719617823785

Epoch: 5| Step: 7
Training loss: 3.717152099953928
Validation loss: 3.9644812707932084

Epoch: 5| Step: 8
Training loss: 4.0503065958650355
Validation loss: 3.9597233874671875

Epoch: 5| Step: 9
Training loss: 4.402669114390786
Validation loss: 3.955363307137408

Epoch: 5| Step: 10
Training loss: 4.348219075064625
Validation loss: 3.950995719931487

Epoch: 5| Step: 11
Training loss: 4.40327255619063
Validation loss: 3.9464085985692186

Epoch: 30| Step: 0
Training loss: 4.1019510139653885
Validation loss: 3.9418067892437123

Epoch: 5| Step: 1
Training loss: 4.085491440533066
Validation loss: 3.937246592001744

Epoch: 5| Step: 2
Training loss: 3.9197578947079115
Validation loss: 3.9330093116300855

Epoch: 5| Step: 3
Training loss: 4.4911042341980485
Validation loss: 3.928242700311082

Epoch: 5| Step: 4
Training loss: 3.8498829860987764
Validation loss: 3.9240443295273337

Epoch: 5| Step: 5
Training loss: 3.9445025226334955
Validation loss: 3.919491548966335

Epoch: 5| Step: 6
Training loss: 4.6069621349556416
Validation loss: 3.915011947511296

Epoch: 5| Step: 7
Training loss: 4.394206585229224
Validation loss: 3.91051310798166

Epoch: 5| Step: 8
Training loss: 4.082528846017436
Validation loss: 3.9056873831892323

Epoch: 5| Step: 9
Training loss: 3.7621511050454663
Validation loss: 3.901322957768097

Epoch: 5| Step: 10
Training loss: 3.5426848948704515
Validation loss: 3.896788988181328

Epoch: 5| Step: 11
Training loss: 1.9405048818470332
Validation loss: 3.892438902329479

Epoch: 31| Step: 0
Training loss: 3.1840926265086904
Validation loss: 3.8881847536962852

Epoch: 5| Step: 1
Training loss: 4.158665464256955
Validation loss: 3.8846001964627113

Epoch: 5| Step: 2
Training loss: 3.70983292051768
Validation loss: 3.8799055335500316

Epoch: 5| Step: 3
Training loss: 3.73956410749305
Validation loss: 3.8760888302947722

Epoch: 5| Step: 4
Training loss: 4.0411208790364554
Validation loss: 3.8719110226026636

Epoch: 5| Step: 5
Training loss: 4.116202017524439
Validation loss: 3.867531331508103

Epoch: 5| Step: 6
Training loss: 4.54514911839236
Validation loss: 3.863281738569218

Epoch: 5| Step: 7
Training loss: 4.552377419243304
Validation loss: 3.858009555007535

Epoch: 5| Step: 8
Training loss: 4.11124554548895
Validation loss: 3.8529842504662435

Epoch: 5| Step: 9
Training loss: 3.644565005621411
Validation loss: 3.84772067201647

Epoch: 5| Step: 10
Training loss: 4.072156023704947
Validation loss: 3.842976344954711

Epoch: 5| Step: 11
Training loss: 3.5958110704023816
Validation loss: 3.8385840232027033

Epoch: 32| Step: 0
Training loss: 3.728287335656193
Validation loss: 3.8320634213858966

Epoch: 5| Step: 1
Training loss: 4.247060769167537
Validation loss: 3.825575086997908

Epoch: 5| Step: 2
Training loss: 4.361545036309927
Validation loss: 3.8196143648131207

Epoch: 5| Step: 3
Training loss: 3.2580071626681657
Validation loss: 3.8147372003118023

Epoch: 5| Step: 4
Training loss: 4.488759944079354
Validation loss: 3.8112715373103714

Epoch: 5| Step: 5
Training loss: 4.838112189617576
Validation loss: 3.8067704412338603

Epoch: 5| Step: 6
Training loss: 3.2669311539629797
Validation loss: 3.8026611289722583

Epoch: 5| Step: 7
Training loss: 4.121130313078324
Validation loss: 3.7984198369638493

Epoch: 5| Step: 8
Training loss: 3.806659790429242
Validation loss: 3.7938020041691516

Epoch: 5| Step: 9
Training loss: 3.4086969668183587
Validation loss: 3.7898333417573515

Epoch: 5| Step: 10
Training loss: 3.721970389910971
Validation loss: 3.7847883572569825

Epoch: 5| Step: 11
Training loss: 2.6216546494616146
Validation loss: 3.780265317340034

Epoch: 33| Step: 0
Training loss: 3.753292164506189
Validation loss: 3.7759683071332932

Epoch: 5| Step: 1
Training loss: 4.050770655648513
Validation loss: 3.772075030636089

Epoch: 5| Step: 2
Training loss: 4.042711863442092
Validation loss: 3.7674940965720545

Epoch: 5| Step: 3
Training loss: 3.7570835604073025
Validation loss: 3.763337053610216

Epoch: 5| Step: 4
Training loss: 3.6418902772969584
Validation loss: 3.7586985367640238

Epoch: 5| Step: 5
Training loss: 3.9416543752036417
Validation loss: 3.754499136541219

Epoch: 5| Step: 6
Training loss: 4.130540306087672
Validation loss: 3.750203286065084

Epoch: 5| Step: 7
Training loss: 4.109592214435066
Validation loss: 3.74602763860479

Epoch: 5| Step: 8
Training loss: 3.989158840189032
Validation loss: 3.7415778473816728

Epoch: 5| Step: 9
Training loss: 3.722161915671731
Validation loss: 3.7373295246485467

Epoch: 5| Step: 10
Training loss: 3.8848377986319695
Validation loss: 3.7329277681842137

Epoch: 5| Step: 11
Training loss: 2.16889166905185
Validation loss: 3.7284241244300764

Epoch: 34| Step: 0
Training loss: 3.7143060112492936
Validation loss: 3.7243105510613597

Epoch: 5| Step: 1
Training loss: 3.3061119238247887
Validation loss: 3.7203347438428715

Epoch: 5| Step: 2
Training loss: 4.173662924096709
Validation loss: 3.7165147223582795

Epoch: 5| Step: 3
Training loss: 3.792174518375944
Validation loss: 3.7124617594966134

Epoch: 5| Step: 4
Training loss: 3.356227233923165
Validation loss: 3.70868161884041

Epoch: 5| Step: 5
Training loss: 3.7071512602824517
Validation loss: 3.704513117948189

Epoch: 5| Step: 6
Training loss: 4.276446020946407
Validation loss: 3.7006472790363185

Epoch: 5| Step: 7
Training loss: 4.205530775683922
Validation loss: 3.6964252025237

Epoch: 5| Step: 8
Training loss: 3.6385174983186888
Validation loss: 3.692642796001654

Epoch: 5| Step: 9
Training loss: 4.019229443844383
Validation loss: 3.6883483600497096

Epoch: 5| Step: 10
Training loss: 4.098001151029352
Validation loss: 3.684251852568593

Epoch: 5| Step: 11
Training loss: 2.725027444683775
Validation loss: 3.680105354357624

Epoch: 35| Step: 0
Training loss: 4.342657816406951
Validation loss: 3.676070247563181

Epoch: 5| Step: 1
Training loss: 3.2803183549972457
Validation loss: 3.6720639119351928

Epoch: 5| Step: 2
Training loss: 3.2385695528138787
Validation loss: 3.668009466961576

Epoch: 5| Step: 3
Training loss: 4.112713636049614
Validation loss: 3.6640036875783975

Epoch: 5| Step: 4
Training loss: 4.08008443595431
Validation loss: 3.660297528135353

Epoch: 5| Step: 5
Training loss: 3.4123947294996504
Validation loss: 3.6561684721635785

Epoch: 5| Step: 6
Training loss: 4.147116815434474
Validation loss: 3.6521408922295078

Epoch: 5| Step: 7
Training loss: 3.851923618062436
Validation loss: 3.6482351874621943

Epoch: 5| Step: 8
Training loss: 3.717651589643653
Validation loss: 3.6442029450101954

Epoch: 5| Step: 9
Training loss: 3.993314162278899
Validation loss: 3.64024456639628

Epoch: 5| Step: 10
Training loss: 3.6621539059792534
Validation loss: 3.636073840986207

Epoch: 5| Step: 11
Training loss: 1.7932503672319815
Validation loss: 3.6319844112219246

Epoch: 36| Step: 0
Training loss: 3.3483467235712014
Validation loss: 3.62825320595326

Epoch: 5| Step: 1
Training loss: 3.831012493195821
Validation loss: 3.624303959198891

Epoch: 5| Step: 2
Training loss: 3.872291110310944
Validation loss: 3.6207849123270135

Epoch: 5| Step: 3
Training loss: 4.172707463907062
Validation loss: 3.616887903405268

Epoch: 5| Step: 4
Training loss: 2.872503108594788
Validation loss: 3.612752520393265

Epoch: 5| Step: 5
Training loss: 3.0702289443743482
Validation loss: 3.6090909535107234

Epoch: 5| Step: 6
Training loss: 4.176409025615566
Validation loss: 3.605567806780168

Epoch: 5| Step: 7
Training loss: 4.436089304885876
Validation loss: 3.601872674214357

Epoch: 5| Step: 8
Training loss: 4.0245122862846445
Validation loss: 3.598250780052366

Epoch: 5| Step: 9
Training loss: 3.5610862737679847
Validation loss: 3.594011811380821

Epoch: 5| Step: 10
Training loss: 3.659929820153953
Validation loss: 3.5899899812344276

Epoch: 5| Step: 11
Training loss: 3.0037273457879747
Validation loss: 3.586313680892492

Epoch: 37| Step: 0
Training loss: 3.4740986869555885
Validation loss: 3.5872209616545248

Epoch: 5| Step: 1
Training loss: 3.7143070382774184
Validation loss: 3.5807178048618273

Epoch: 5| Step: 2
Training loss: 3.909911613928805
Validation loss: 3.574997886132458

Epoch: 5| Step: 3
Training loss: 3.664712356166904
Validation loss: 3.5708923592394264

Epoch: 5| Step: 4
Training loss: 3.9470242554388313
Validation loss: 3.567244819362168

Epoch: 5| Step: 5
Training loss: 3.6580701682659167
Validation loss: 3.563776724403073

Epoch: 5| Step: 6
Training loss: 3.0309948371382602
Validation loss: 3.5603728441041853

Epoch: 5| Step: 7
Training loss: 4.104347780107485
Validation loss: 3.5572525271733517

Epoch: 5| Step: 8
Training loss: 3.5542232000603406
Validation loss: 3.5531895174528474

Epoch: 5| Step: 9
Training loss: 3.9122017646198572
Validation loss: 3.5492249600944406

Epoch: 5| Step: 10
Training loss: 3.666684771984367
Validation loss: 3.5450516241759815

Epoch: 5| Step: 11
Training loss: 3.5742339587278886
Validation loss: 3.54061623123578

Epoch: 38| Step: 0
Training loss: 3.4496011144059455
Validation loss: 3.536607054709252

Epoch: 5| Step: 1
Training loss: 4.0515077209888695
Validation loss: 3.53275261476295

Epoch: 5| Step: 2
Training loss: 3.320049248525431
Validation loss: 3.5288569519774864

Epoch: 5| Step: 3
Training loss: 2.9858832417762935
Validation loss: 3.5249407452141397

Epoch: 5| Step: 4
Training loss: 3.154005555674728
Validation loss: 3.521248712057578

Epoch: 5| Step: 5
Training loss: 4.299460780910997
Validation loss: 3.517617741710643

Epoch: 5| Step: 6
Training loss: 3.545202457473697
Validation loss: 3.5137665647308287

Epoch: 5| Step: 7
Training loss: 4.214757994450242
Validation loss: 3.509715062029996

Epoch: 5| Step: 8
Training loss: 3.337169696593553
Validation loss: 3.5059401308922484

Epoch: 5| Step: 9
Training loss: 3.8192655224747796
Validation loss: 3.5018393871632747

Epoch: 5| Step: 10
Training loss: 3.801911831824264
Validation loss: 3.4979937173257323

Epoch: 5| Step: 11
Training loss: 3.478529058877063
Validation loss: 3.493946062204114

Epoch: 39| Step: 0
Training loss: 4.1976970807646845
Validation loss: 3.489966708327819

Epoch: 5| Step: 1
Training loss: 3.83510181157572
Validation loss: 3.4860787495702183

Epoch: 5| Step: 2
Training loss: 3.2824799185354325
Validation loss: 3.481946232709073

Epoch: 5| Step: 3
Training loss: 3.3614424620116643
Validation loss: 3.4779593929543817

Epoch: 5| Step: 4
Training loss: 3.8175439456591165
Validation loss: 3.474182537265566

Epoch: 5| Step: 5
Training loss: 3.2589419668859207
Validation loss: 3.470166389724996

Epoch: 5| Step: 6
Training loss: 3.3652479777003084
Validation loss: 3.466363085619233

Epoch: 5| Step: 7
Training loss: 3.38904897037266
Validation loss: 3.462472579516964

Epoch: 5| Step: 8
Training loss: 3.9747288641436955
Validation loss: 3.4585037572455275

Epoch: 5| Step: 9
Training loss: 3.9110010170131795
Validation loss: 3.4546229132876847

Epoch: 5| Step: 10
Training loss: 3.301129529286668
Validation loss: 3.4507573441355404

Epoch: 5| Step: 11
Training loss: 2.7908316165178024
Validation loss: 3.4468612361666584

Epoch: 40| Step: 0
Training loss: 2.9978630084090736
Validation loss: 3.443351152727217

Epoch: 5| Step: 1
Training loss: 4.040082378491805
Validation loss: 3.4399363986778226

Epoch: 5| Step: 2
Training loss: 3.3962068098829916
Validation loss: 3.436405568307015

Epoch: 5| Step: 3
Training loss: 3.376395890531015
Validation loss: 3.4326971978982423

Epoch: 5| Step: 4
Training loss: 2.999767294441484
Validation loss: 3.4292355603883276

Epoch: 5| Step: 5
Training loss: 3.3861766412110574
Validation loss: 3.4259729161395427

Epoch: 5| Step: 6
Training loss: 4.084271122166749
Validation loss: 3.4226126318529864

Epoch: 5| Step: 7
Training loss: 3.978126802766186
Validation loss: 3.4190434740784963

Epoch: 5| Step: 8
Training loss: 3.7830235128940033
Validation loss: 3.4150450432535684

Epoch: 5| Step: 9
Training loss: 3.760531324221898
Validation loss: 3.4115996333942746

Epoch: 5| Step: 10
Training loss: 3.3604145659416305
Validation loss: 3.4075880805526504

Epoch: 5| Step: 11
Training loss: 2.5962237775246995
Validation loss: 3.403835922727609

Epoch: 41| Step: 0
Training loss: 3.6601249831908915
Validation loss: 3.4002967980747436

Epoch: 5| Step: 1
Training loss: 3.642986006821662
Validation loss: 3.3968291879961208

Epoch: 5| Step: 2
Training loss: 3.8080221676461745
Validation loss: 3.3932479814938294

Epoch: 5| Step: 3
Training loss: 3.460799031469216
Validation loss: 3.389651532337971

Epoch: 5| Step: 4
Training loss: 3.595800594270673
Validation loss: 3.3860507997182205

Epoch: 5| Step: 5
Training loss: 2.362712596228735
Validation loss: 3.3823491660915748

Epoch: 5| Step: 6
Training loss: 3.8750173506809764
Validation loss: 3.3788417097039374

Epoch: 5| Step: 7
Training loss: 3.9954801295281275
Validation loss: 3.375279874146854

Epoch: 5| Step: 8
Training loss: 3.3401646866999455
Validation loss: 3.371501145070509

Epoch: 5| Step: 9
Training loss: 3.5300351644174772
Validation loss: 3.3682646743289406

Epoch: 5| Step: 10
Training loss: 3.2421302882282768
Validation loss: 3.364420093595827

Epoch: 5| Step: 11
Training loss: 3.31357485048926
Validation loss: 3.3610463501774985

Epoch: 42| Step: 0
Training loss: 2.961741798691557
Validation loss: 3.3574888331061166

Epoch: 5| Step: 1
Training loss: 3.4573017251624183
Validation loss: 3.354086114773102

Epoch: 5| Step: 2
Training loss: 3.0013046606663734
Validation loss: 3.3502920450476217

Epoch: 5| Step: 3
Training loss: 3.568944890300897
Validation loss: 3.347208391497799

Epoch: 5| Step: 4
Training loss: 3.656501174515523
Validation loss: 3.3443335026990946

Epoch: 5| Step: 5
Training loss: 3.7601522985010014
Validation loss: 3.3429829974493823

Epoch: 5| Step: 6
Training loss: 3.3951892983159166
Validation loss: 3.3369675117449105

Epoch: 5| Step: 7
Training loss: 3.724678763036805
Validation loss: 3.3333330820004052

Epoch: 5| Step: 8
Training loss: 3.5856413542354755
Validation loss: 3.3301149785751694

Epoch: 5| Step: 9
Training loss: 3.7761650258226394
Validation loss: 3.326775135311786

Epoch: 5| Step: 10
Training loss: 3.333410230385406
Validation loss: 3.3237520720346416

Epoch: 5| Step: 11
Training loss: 3.195680629724257
Validation loss: 3.3210652234917672

Epoch: 43| Step: 0
Training loss: 3.145886014450932
Validation loss: 3.318215064491471

Epoch: 5| Step: 1
Training loss: 3.021754700910242
Validation loss: 3.3147649998555515

Epoch: 5| Step: 2
Training loss: 3.6112794021777463
Validation loss: 3.310879592905188

Epoch: 5| Step: 3
Training loss: 3.5356729540810496
Validation loss: 3.306251282141857

Epoch: 5| Step: 4
Training loss: 3.8212392732109675
Validation loss: 3.3023151452719537

Epoch: 5| Step: 5
Training loss: 3.6045822756538666
Validation loss: 3.2985883301511554

Epoch: 5| Step: 6
Training loss: 2.922740624460805
Validation loss: 3.29521320519601

Epoch: 5| Step: 7
Training loss: 3.5426336127842393
Validation loss: 3.291722391759411

Epoch: 5| Step: 8
Training loss: 3.3816025752848087
Validation loss: 3.288440174296364

Epoch: 5| Step: 9
Training loss: 3.5289199028232408
Validation loss: 3.284572777810791

Epoch: 5| Step: 10
Training loss: 3.6374529334100583
Validation loss: 3.281337098070721

Epoch: 5| Step: 11
Training loss: 3.2892254496823248
Validation loss: 3.278307185460667

Epoch: 44| Step: 0
Training loss: 3.1848377254713385
Validation loss: 3.274393401861498

Epoch: 5| Step: 1
Training loss: 3.0407623793175858
Validation loss: 3.2712071786229537

Epoch: 5| Step: 2
Training loss: 3.3499746407075666
Validation loss: 3.267035546243793

Epoch: 5| Step: 3
Training loss: 3.156550629150378
Validation loss: 3.263536457666809

Epoch: 5| Step: 4
Training loss: 3.465148705928682
Validation loss: 3.260279571324014

Epoch: 5| Step: 5
Training loss: 3.1072260652872976
Validation loss: 3.2568647559710118

Epoch: 5| Step: 6
Training loss: 3.684831332483556
Validation loss: 3.253850636459207

Epoch: 5| Step: 7
Training loss: 3.2450321081891795
Validation loss: 3.2504444032442548

Epoch: 5| Step: 8
Training loss: 3.383810341067656
Validation loss: 3.2469622891845034

Epoch: 5| Step: 9
Training loss: 3.473240463152583
Validation loss: 3.2439026306052776

Epoch: 5| Step: 10
Training loss: 4.273688105011981
Validation loss: 3.240443472221417

Epoch: 5| Step: 11
Training loss: 2.3961939554122798
Validation loss: 3.2367578902944536

Epoch: 45| Step: 0
Training loss: 3.692815150485702
Validation loss: 3.233580935639376

Epoch: 5| Step: 1
Training loss: 3.7779594795311784
Validation loss: 3.230178543210964

Epoch: 5| Step: 2
Training loss: 3.305937834859655
Validation loss: 3.2271921006932662

Epoch: 5| Step: 3
Training loss: 2.5934156638987926
Validation loss: 3.223278329321424

Epoch: 5| Step: 4
Training loss: 3.3407794913100903
Validation loss: 3.220038480173334

Epoch: 5| Step: 5
Training loss: 2.845557340659206
Validation loss: 3.217189524747049

Epoch: 5| Step: 6
Training loss: 3.7339690558403325
Validation loss: 3.2139924082069964

Epoch: 5| Step: 7
Training loss: 3.4915131807544184
Validation loss: 3.2108294615007296

Epoch: 5| Step: 8
Training loss: 3.4848543530189855
Validation loss: 3.20775638177575

Epoch: 5| Step: 9
Training loss: 3.112676506706148
Validation loss: 3.2056398583291754

Epoch: 5| Step: 10
Training loss: 3.5026851980297318
Validation loss: 3.20174714513692

Epoch: 5| Step: 11
Training loss: 2.5898035198786657
Validation loss: 3.199926891832883

Epoch: 46| Step: 0
Training loss: 2.9751221383291266
Validation loss: 3.1971857786840436

Epoch: 5| Step: 1
Training loss: 3.6874379298271753
Validation loss: 3.1928017474516124

Epoch: 5| Step: 2
Training loss: 3.583261459576053
Validation loss: 3.188536406924672

Epoch: 5| Step: 3
Training loss: 3.6022805513866403
Validation loss: 3.186853926138144

Epoch: 5| Step: 4
Training loss: 3.5092676623566366
Validation loss: 3.1860632993349136

Epoch: 5| Step: 5
Training loss: 3.2265577708803117
Validation loss: 3.1895781331151776

Epoch: 5| Step: 6
Training loss: 3.012401379755677
Validation loss: 3.1854265986691694

Epoch: 5| Step: 7
Training loss: 2.38995850690632
Validation loss: 3.178925137742241

Epoch: 5| Step: 8
Training loss: 3.8248391510297526
Validation loss: 3.1757150840982993

Epoch: 5| Step: 9
Training loss: 2.8965145014342744
Validation loss: 3.171996278746203

Epoch: 5| Step: 10
Training loss: 3.5789899155505864
Validation loss: 3.168038147567209

Epoch: 5| Step: 11
Training loss: 3.3034912541503054
Validation loss: 3.1637747865326635

Epoch: 47| Step: 0
Training loss: 3.1575263435913934
Validation loss: 3.1600495026881856

Epoch: 5| Step: 1
Training loss: 3.5552032431919884
Validation loss: 3.1561058439565093

Epoch: 5| Step: 2
Training loss: 2.9770678794536263
Validation loss: 3.1528675978680227

Epoch: 5| Step: 3
Training loss: 3.2428580820071455
Validation loss: 3.1501231260305085

Epoch: 5| Step: 4
Training loss: 3.185059155164848
Validation loss: 3.1473301532782894

Epoch: 5| Step: 5
Training loss: 3.0791453882565345
Validation loss: 3.1443784372544337

Epoch: 5| Step: 6
Training loss: 3.082230826178456
Validation loss: 3.1407970299110937

Epoch: 5| Step: 7
Training loss: 3.6936628922004053
Validation loss: 3.138120807411155

Epoch: 5| Step: 8
Training loss: 3.885884165656687
Validation loss: 3.1345720114489324

Epoch: 5| Step: 9
Training loss: 2.9410596341880906
Validation loss: 3.1313490902062506

Epoch: 5| Step: 10
Training loss: 3.304601789945697
Validation loss: 3.1284576551630052

Epoch: 5| Step: 11
Training loss: 2.6545051678240594
Validation loss: 3.125195996178102

Epoch: 48| Step: 0
Training loss: 3.294511426902658
Validation loss: 3.12199947629611

Epoch: 5| Step: 1
Training loss: 2.9331579379905164
Validation loss: 3.118921433440452

Epoch: 5| Step: 2
Training loss: 3.270173332216765
Validation loss: 3.1157755860949816

Epoch: 5| Step: 3
Training loss: 3.296064521278395
Validation loss: 3.1129355276536583

Epoch: 5| Step: 4
Training loss: 3.3371735545321655
Validation loss: 3.1099789159168436

Epoch: 5| Step: 5
Training loss: 2.9397322918202606
Validation loss: 3.106815383647137

Epoch: 5| Step: 6
Training loss: 3.5552633301200887
Validation loss: 3.104049595069565

Epoch: 5| Step: 7
Training loss: 3.4232826995324195
Validation loss: 3.1006481510839263

Epoch: 5| Step: 8
Training loss: 3.399005851136772
Validation loss: 3.0975961154201497

Epoch: 5| Step: 9
Training loss: 3.2404030174807334
Validation loss: 3.0943150951484

Epoch: 5| Step: 10
Training loss: 3.2477610285092133
Validation loss: 3.091055039848278

Epoch: 5| Step: 11
Training loss: 1.364940606246859
Validation loss: 3.087921637858508

Epoch: 49| Step: 0
Training loss: 3.3807263714540725
Validation loss: 3.085125271424382

Epoch: 5| Step: 1
Training loss: 3.2867136199671756
Validation loss: 3.0821519770827

Epoch: 5| Step: 2
Training loss: 2.9210611933821924
Validation loss: 3.078924194737936

Epoch: 5| Step: 3
Training loss: 2.9579106060187557
Validation loss: 3.076401252066343

Epoch: 5| Step: 4
Training loss: 3.2843028081478587
Validation loss: 3.0733097223749213

Epoch: 5| Step: 5
Training loss: 2.9400986884544476
Validation loss: 3.0707927842657043

Epoch: 5| Step: 6
Training loss: 3.441578058636969
Validation loss: 3.0679026392662174

Epoch: 5| Step: 7
Training loss: 3.2773238171231593
Validation loss: 3.0649062195121894

Epoch: 5| Step: 8
Training loss: 3.141948819496966
Validation loss: 3.0615218215767763

Epoch: 5| Step: 9
Training loss: 3.619176198472633
Validation loss: 3.0586317960501055

Epoch: 5| Step: 10
Training loss: 2.993604837294829
Validation loss: 3.0558108632517103

Epoch: 5| Step: 11
Training loss: 3.297499032645846
Validation loss: 3.0535657209939497

Epoch: 50| Step: 0
Training loss: 2.9321423634292563
Validation loss: 3.050351225323777

Epoch: 5| Step: 1
Training loss: 3.7035559552357262
Validation loss: 3.04766794303679

Epoch: 5| Step: 2
Training loss: 2.6495897155419303
Validation loss: 3.0447987581932408

Epoch: 5| Step: 3
Training loss: 3.08836914060956
Validation loss: 3.0418594780431794

Epoch: 5| Step: 4
Training loss: 3.3705528063958776
Validation loss: 3.0395745677093875

Epoch: 5| Step: 5
Training loss: 3.0562855474670965
Validation loss: 3.036648138579811

Epoch: 5| Step: 6
Training loss: 3.1181403594366084
Validation loss: 3.0335896956575272

Epoch: 5| Step: 7
Training loss: 3.0162903046869407
Validation loss: 3.031079431696606

Epoch: 5| Step: 8
Training loss: 3.21991271712197
Validation loss: 3.0286064221919458

Epoch: 5| Step: 9
Training loss: 3.183673731261422
Validation loss: 3.0251145521127776

Epoch: 5| Step: 10
Training loss: 3.3137165930412005
Validation loss: 3.0233980450614553

Epoch: 5| Step: 11
Training loss: 4.042423583790562
Validation loss: 3.021267531968431

Epoch: 51| Step: 0
Training loss: 3.422433885892919
Validation loss: 3.0174896589395375

Epoch: 5| Step: 1
Training loss: 3.0902338565367407
Validation loss: 3.0134834169642857

Epoch: 5| Step: 2
Training loss: 2.988706630773436
Validation loss: 3.010320854422261

Epoch: 5| Step: 3
Training loss: 2.979817530530819
Validation loss: 3.008921190179749

Epoch: 5| Step: 4
Training loss: 2.9360354404649165
Validation loss: 3.005134681887792

Epoch: 5| Step: 5
Training loss: 3.546975827569495
Validation loss: 3.002043015162756

Epoch: 5| Step: 6
Training loss: 3.4505220156493652
Validation loss: 2.998568570848922

Epoch: 5| Step: 7
Training loss: 3.168589577009263
Validation loss: 2.996658039957542

Epoch: 5| Step: 8
Training loss: 2.7423780760878014
Validation loss: 2.9939801097825853

Epoch: 5| Step: 9
Training loss: 3.327920540273684
Validation loss: 2.9908444384218766

Epoch: 5| Step: 10
Training loss: 2.7618732759876488
Validation loss: 2.987674117899983

Epoch: 5| Step: 11
Training loss: 3.4433563284338478
Validation loss: 2.9842957690841154

Epoch: 52| Step: 0
Training loss: 3.4681350575320327
Validation loss: 2.9829522181580286

Epoch: 5| Step: 1
Training loss: 2.7463168708810066
Validation loss: 2.9811057613676066

Epoch: 5| Step: 2
Training loss: 3.0361434921611785
Validation loss: 2.978348957672578

Epoch: 5| Step: 3
Training loss: 3.4511054161594115
Validation loss: 2.977559080522657

Epoch: 5| Step: 4
Training loss: 2.843828305015224
Validation loss: 2.975141625011888

Epoch: 5| Step: 5
Training loss: 3.2800165673744663
Validation loss: 2.96854939703214

Epoch: 5| Step: 6
Training loss: 3.0776727799256713
Validation loss: 2.966626716373351

Epoch: 5| Step: 7
Training loss: 3.3302221720128253
Validation loss: 2.9646424404014686

Epoch: 5| Step: 8
Training loss: 3.2226050540441014
Validation loss: 2.963604423023851

Epoch: 5| Step: 9
Training loss: 2.9506766044436707
Validation loss: 2.9590486290798927

Epoch: 5| Step: 10
Training loss: 2.745101293560578
Validation loss: 2.9562730778874737

Epoch: 5| Step: 11
Training loss: 2.987229824219268
Validation loss: 2.954269207697873

Epoch: 53| Step: 0
Training loss: 3.258092927641335
Validation loss: 2.952660596416745

Epoch: 5| Step: 1
Training loss: 3.027448019877719
Validation loss: 2.9504521163565562

Epoch: 5| Step: 2
Training loss: 3.5157038022852314
Validation loss: 2.9482997009658534

Epoch: 5| Step: 3
Training loss: 2.951450256507499
Validation loss: 2.946223488258022

Epoch: 5| Step: 4
Training loss: 2.616078247031668
Validation loss: 2.9435330183400845

Epoch: 5| Step: 5
Training loss: 2.960931058287848
Validation loss: 2.941198144907656

Epoch: 5| Step: 6
Training loss: 3.2861888228881937
Validation loss: 2.9388487201866864

Epoch: 5| Step: 7
Training loss: 3.1797488344917526
Validation loss: 2.9361470772795886

Epoch: 5| Step: 8
Training loss: 3.170226321640132
Validation loss: 2.934730668428632

Epoch: 5| Step: 9
Training loss: 2.9489778331856136
Validation loss: 2.931726934326038

Epoch: 5| Step: 10
Training loss: 3.0803199339331204
Validation loss: 2.9292829310503317

Epoch: 5| Step: 11
Training loss: 2.186553314263836
Validation loss: 2.926582457607941

Epoch: 54| Step: 0
Training loss: 2.6808351778263777
Validation loss: 2.9242515928336874

Epoch: 5| Step: 1
Training loss: 3.0901871019030653
Validation loss: 2.922264365570024

Epoch: 5| Step: 2
Training loss: 3.2053349012581562
Validation loss: 2.9198513605115206

Epoch: 5| Step: 3
Training loss: 3.1531607740204572
Validation loss: 2.916970616352297

Epoch: 5| Step: 4
Training loss: 3.015146800653691
Validation loss: 2.915176298062285

Epoch: 5| Step: 5
Training loss: 2.5762584981172005
Validation loss: 2.9126702426713242

Epoch: 5| Step: 6
Training loss: 3.1418318066759126
Validation loss: 2.910596932790624

Epoch: 5| Step: 7
Training loss: 3.268239412127035
Validation loss: 2.908498031321316

Epoch: 5| Step: 8
Training loss: 3.3828640905238943
Validation loss: 2.905791222515437

Epoch: 5| Step: 9
Training loss: 3.0603863954615873
Validation loss: 2.903608396599579

Epoch: 5| Step: 10
Training loss: 3.0083365640244257
Validation loss: 2.901172940875631

Epoch: 5| Step: 11
Training loss: 2.711724774379517
Validation loss: 2.8992747513942367

Epoch: 55| Step: 0
Training loss: 2.838835609451994
Validation loss: 2.896342453466743

Epoch: 5| Step: 1
Training loss: 3.1411744201772804
Validation loss: 2.8945312431359476

Epoch: 5| Step: 2
Training loss: 2.6309915012409393
Validation loss: 2.8926023164158683

Epoch: 5| Step: 3
Training loss: 3.3823109314399935
Validation loss: 2.890279763027717

Epoch: 5| Step: 4
Training loss: 2.8033164240734982
Validation loss: 2.888300774057465

Epoch: 5| Step: 5
Training loss: 3.03915256082413
Validation loss: 2.887356544415499

Epoch: 5| Step: 6
Training loss: 2.3925273033505454
Validation loss: 2.8855295239537058

Epoch: 5| Step: 7
Training loss: 3.076940318206019
Validation loss: 2.8834095123918284

Epoch: 5| Step: 8
Training loss: 3.3570548628663968
Validation loss: 2.88021670312108

Epoch: 5| Step: 9
Training loss: 3.354513509757562
Validation loss: 2.8778103071343804

Epoch: 5| Step: 10
Training loss: 3.2021296745790644
Validation loss: 2.875078459373988

Epoch: 5| Step: 11
Training loss: 2.655909796975494
Validation loss: 2.8734346910759934

Epoch: 56| Step: 0
Training loss: 3.118848162312187
Validation loss: 2.8731448262501282

Epoch: 5| Step: 1
Training loss: 3.0472548028005333
Validation loss: 2.8716816721900713

Epoch: 5| Step: 2
Training loss: 3.26281559027964
Validation loss: 2.8699714768163127

Epoch: 5| Step: 3
Training loss: 3.458225815415366
Validation loss: 2.8683010004119347

Epoch: 5| Step: 4
Training loss: 2.7773198852372194
Validation loss: 2.866276623191469

Epoch: 5| Step: 5
Training loss: 3.024491316215471
Validation loss: 2.864569526407896

Epoch: 5| Step: 6
Training loss: 2.9805186656206804
Validation loss: 2.8622818469469515

Epoch: 5| Step: 7
Training loss: 3.268372616399689
Validation loss: 2.8597127926830397

Epoch: 5| Step: 8
Training loss: 2.843663308635257
Validation loss: 2.857620312329201

Epoch: 5| Step: 9
Training loss: 2.734605354415326
Validation loss: 2.8556417959844627

Epoch: 5| Step: 10
Training loss: 2.4726279981785995
Validation loss: 2.852208472813875

Epoch: 5| Step: 11
Training loss: 2.7680620565900074
Validation loss: 2.85046997043521

Epoch: 57| Step: 0
Training loss: 2.387732457533156
Validation loss: 2.849308812947934

Epoch: 5| Step: 1
Training loss: 3.0701843700900464
Validation loss: 2.846511415335944

Epoch: 5| Step: 2
Training loss: 3.0833293468002805
Validation loss: 2.8455684492978524

Epoch: 5| Step: 3
Training loss: 2.0115945425854997
Validation loss: 2.8460817768027624

Epoch: 5| Step: 4
Training loss: 3.3221694600463487
Validation loss: 2.8418409940565525

Epoch: 5| Step: 5
Training loss: 2.986932587308915
Validation loss: 2.8397462837742773

Epoch: 5| Step: 6
Training loss: 3.327772524798929
Validation loss: 2.838358736122397

Epoch: 5| Step: 7
Training loss: 3.015364561545731
Validation loss: 2.8364027883410157

Epoch: 5| Step: 8
Training loss: 3.3557540896576294
Validation loss: 2.8336948848962917

Epoch: 5| Step: 9
Training loss: 3.0628322498940768
Validation loss: 2.8310370232516897

Epoch: 5| Step: 10
Training loss: 3.0622810752625456
Validation loss: 2.829250870314435

Epoch: 5| Step: 11
Training loss: 1.8376225307378726
Validation loss: 2.8281769686256935

Epoch: 58| Step: 0
Training loss: 2.9722970753055
Validation loss: 2.825377114621104

Epoch: 5| Step: 1
Training loss: 2.4556130590461636
Validation loss: 2.822904394388209

Epoch: 5| Step: 2
Training loss: 2.941083791618955
Validation loss: 2.8204254627940646

Epoch: 5| Step: 3
Training loss: 2.965053947948604
Validation loss: 2.8200038941843455

Epoch: 5| Step: 4
Training loss: 3.0596529124263494
Validation loss: 2.8185939854190516

Epoch: 5| Step: 5
Training loss: 3.248076823561569
Validation loss: 2.8161803819416047

Epoch: 5| Step: 6
Training loss: 2.902226277537269
Validation loss: 2.8123555075651545

Epoch: 5| Step: 7
Training loss: 3.127689272537615
Validation loss: 2.8102435632496285

Epoch: 5| Step: 8
Training loss: 3.176832562331442
Validation loss: 2.808625965172401

Epoch: 5| Step: 9
Training loss: 2.26624789389898
Validation loss: 2.80706545331788

Epoch: 5| Step: 10
Training loss: 3.2690229487927867
Validation loss: 2.8043607877469388

Epoch: 5| Step: 11
Training loss: 2.7827819719733773
Validation loss: 2.8022423714431737

Epoch: 59| Step: 0
Training loss: 2.9953136398321223
Validation loss: 2.7995304309971307

Epoch: 5| Step: 1
Training loss: 3.675328355509612
Validation loss: 2.7987788378609992

Epoch: 5| Step: 2
Training loss: 2.624090582127307
Validation loss: 2.7961636425377203

Epoch: 5| Step: 3
Training loss: 2.9015989105125803
Validation loss: 2.7949343791462478

Epoch: 5| Step: 4
Training loss: 2.7149800437910394
Validation loss: 2.794193961208046

Epoch: 5| Step: 5
Training loss: 2.875579443879359
Validation loss: 2.7940141335377695

Epoch: 5| Step: 6
Training loss: 2.6082052018581665
Validation loss: 2.79339960505214

Epoch: 5| Step: 7
Training loss: 2.712325123014756
Validation loss: 2.794782765265664

Epoch: 5| Step: 8
Training loss: 2.9757977802421394
Validation loss: 2.795966439458885

Epoch: 5| Step: 9
Training loss: 2.664213741182117
Validation loss: 2.794839882242205

Epoch: 5| Step: 10
Training loss: 3.2600455921003992
Validation loss: 2.791550211588825

Epoch: 5| Step: 11
Training loss: 3.6161736206469794
Validation loss: 2.789325110487719

Epoch: 60| Step: 0
Training loss: 2.827382195646926
Validation loss: 2.7860391224234067

Epoch: 5| Step: 1
Training loss: 2.478961444556452
Validation loss: 2.78273919416114

Epoch: 5| Step: 2
Training loss: 3.1754827417749487
Validation loss: 2.780189479841612

Epoch: 5| Step: 3
Training loss: 3.133381247323195
Validation loss: 2.7778408251336146

Epoch: 5| Step: 4
Training loss: 3.4153166328968525
Validation loss: 2.7767030430281308

Epoch: 5| Step: 5
Training loss: 2.436125441097893
Validation loss: 2.7737154718352737

Epoch: 5| Step: 6
Training loss: 2.7285132657302347
Validation loss: 2.7686180399038327

Epoch: 5| Step: 7
Training loss: 2.9990636635917496
Validation loss: 2.7685230896955857

Epoch: 5| Step: 8
Training loss: 2.662943675008142
Validation loss: 2.7884863784680327

Epoch: 5| Step: 9
Training loss: 3.065152323735347
Validation loss: 2.832430290083756

Epoch: 5| Step: 10
Training loss: 3.4064641762690093
Validation loss: 2.7928342951353518

Epoch: 5| Step: 11
Training loss: 1.494483260218271
Validation loss: 2.7637354938926366

Epoch: 61| Step: 0
Training loss: 2.880805746322871
Validation loss: 2.762681019147007

Epoch: 5| Step: 1
Training loss: 2.7584325509412118
Validation loss: 2.7633341121173984

Epoch: 5| Step: 2
Training loss: 2.90259708002333
Validation loss: 2.765166170957086

Epoch: 5| Step: 3
Training loss: 3.05319684821623
Validation loss: 2.771805489925423

Epoch: 5| Step: 4
Training loss: 2.789202689272636
Validation loss: 2.7720397865830964

Epoch: 5| Step: 5
Training loss: 2.7665845854965787
Validation loss: 2.7822905247803895

Epoch: 5| Step: 6
Training loss: 2.8869595769173637
Validation loss: 2.7903741696054065

Epoch: 5| Step: 7
Training loss: 3.0475600817346042
Validation loss: 2.7734424931297665

Epoch: 5| Step: 8
Training loss: 2.9876563123087827
Validation loss: 2.767620710010746

Epoch: 5| Step: 9
Training loss: 3.1305677024637997
Validation loss: 2.758827076877888

Epoch: 5| Step: 10
Training loss: 2.8726853714401326
Validation loss: 2.755414638955984

Epoch: 5| Step: 11
Training loss: 2.423221632137823
Validation loss: 2.753441113449518

Epoch: 62| Step: 0
Training loss: 2.7644599141502053
Validation loss: 2.750331067617594

Epoch: 5| Step: 1
Training loss: 3.329274153774545
Validation loss: 2.7488068463118673

Epoch: 5| Step: 2
Training loss: 2.4693658760692023
Validation loss: 2.7475467670557414

Epoch: 5| Step: 3
Training loss: 2.8513755423515343
Validation loss: 2.7455255563616725

Epoch: 5| Step: 4
Training loss: 2.9589896929098254
Validation loss: 2.744237258675824

Epoch: 5| Step: 5
Training loss: 3.005299496824367
Validation loss: 2.742983949641415

Epoch: 5| Step: 6
Training loss: 2.772466269202781
Validation loss: 2.7417537567158385

Epoch: 5| Step: 7
Training loss: 2.9187971417624663
Validation loss: 2.739771453335765

Epoch: 5| Step: 8
Training loss: 2.4735558005000122
Validation loss: 2.7378433773524713

Epoch: 5| Step: 9
Training loss: 2.9331070538143917
Validation loss: 2.736069000122325

Epoch: 5| Step: 10
Training loss: 2.8764641392191677
Validation loss: 2.7353345186537146

Epoch: 5| Step: 11
Training loss: 3.946849078095547
Validation loss: 2.7316206874744418

Epoch: 63| Step: 0
Training loss: 2.6702314530824864
Validation loss: 2.730724259092665

Epoch: 5| Step: 1
Training loss: 2.850320289416314
Validation loss: 2.727755579746961

Epoch: 5| Step: 2
Training loss: 2.921920694412084
Validation loss: 2.7251528326683534

Epoch: 5| Step: 3
Training loss: 3.0249488069600456
Validation loss: 2.7246522815748673

Epoch: 5| Step: 4
Training loss: 2.5385217648366374
Validation loss: 2.722633139148704

Epoch: 5| Step: 5
Training loss: 3.0738537582625916
Validation loss: 2.7213754473619223

Epoch: 5| Step: 6
Training loss: 2.7420497761889107
Validation loss: 2.7194541808454007

Epoch: 5| Step: 7
Training loss: 3.0342238477937826
Validation loss: 2.7174926239903217

Epoch: 5| Step: 8
Training loss: 2.9493864100211886
Validation loss: 2.7171062637946433

Epoch: 5| Step: 9
Training loss: 2.8813256044874045
Validation loss: 2.7155070420821668

Epoch: 5| Step: 10
Training loss: 2.8616004163315716
Validation loss: 2.7121606608662483

Epoch: 5| Step: 11
Training loss: 2.321709003906825
Validation loss: 2.710885182076468

Epoch: 64| Step: 0
Training loss: 2.929104434166676
Validation loss: 2.708683718733129

Epoch: 5| Step: 1
Training loss: 2.659377915485008
Validation loss: 2.707136874135985

Epoch: 5| Step: 2
Training loss: 3.1497248817070256
Validation loss: 2.7050155283528627

Epoch: 5| Step: 3
Training loss: 3.039689418587795
Validation loss: 2.70215022421703

Epoch: 5| Step: 4
Training loss: 2.7291736068831476
Validation loss: 2.7039892950111777

Epoch: 5| Step: 5
Training loss: 2.8374191070991
Validation loss: 2.699630451961876

Epoch: 5| Step: 6
Training loss: 2.41335506011428
Validation loss: 2.6990651419581275

Epoch: 5| Step: 7
Training loss: 2.600211952813548
Validation loss: 2.6967192549247967

Epoch: 5| Step: 8
Training loss: 3.1502568215928344
Validation loss: 2.69336216340671

Epoch: 5| Step: 9
Training loss: 2.6556953299841197
Validation loss: 2.693366246425613

Epoch: 5| Step: 10
Training loss: 2.9832061555773857
Validation loss: 2.693319484976852

Epoch: 5| Step: 11
Training loss: 3.0266652780549257
Validation loss: 2.692405537318094

Epoch: 65| Step: 0
Training loss: 3.1228894545319803
Validation loss: 2.689194134200657

Epoch: 5| Step: 1
Training loss: 2.7686904039707203
Validation loss: 2.6880769406051948

Epoch: 5| Step: 2
Training loss: 2.2412314686219186
Validation loss: 2.684631754002207

Epoch: 5| Step: 3
Training loss: 2.7577722130445306
Validation loss: 2.682096642129364

Epoch: 5| Step: 4
Training loss: 3.086749855991236
Validation loss: 2.683384523930166

Epoch: 5| Step: 5
Training loss: 3.054974242506062
Validation loss: 2.6804580414751866

Epoch: 5| Step: 6
Training loss: 2.482973963274892
Validation loss: 2.6793211824662526

Epoch: 5| Step: 7
Training loss: 2.9648561339188833
Validation loss: 2.679118419458008

Epoch: 5| Step: 8
Training loss: 2.7644300735027865
Validation loss: 2.679882394656102

Epoch: 5| Step: 9
Training loss: 2.9960208570622715
Validation loss: 2.677016176996858

Epoch: 5| Step: 10
Training loss: 2.774672628114313
Validation loss: 2.67735322687709

Epoch: 5| Step: 11
Training loss: 2.5668646694780763
Validation loss: 2.6787992030134626

Epoch: 66| Step: 0
Training loss: 2.551148088841083
Validation loss: 2.679670565508095

Epoch: 5| Step: 1
Training loss: 2.679035696938809
Validation loss: 2.676713277174207

Epoch: 5| Step: 2
Training loss: 2.8574851205727096
Validation loss: 2.679682124570862

Epoch: 5| Step: 3
Training loss: 3.0271170845084194
Validation loss: 2.6740896627890614

Epoch: 5| Step: 4
Training loss: 2.9113694907038794
Validation loss: 2.677375919715356

Epoch: 5| Step: 5
Training loss: 2.6636626986764966
Validation loss: 2.6754664920464

Epoch: 5| Step: 6
Training loss: 3.1744171628876447
Validation loss: 2.6810168443540996

Epoch: 5| Step: 7
Training loss: 2.870434328503777
Validation loss: 2.668041952459142

Epoch: 5| Step: 8
Training loss: 2.953998416329426
Validation loss: 2.667080066098647

Epoch: 5| Step: 9
Training loss: 2.9683366989753517
Validation loss: 2.662771917316749

Epoch: 5| Step: 10
Training loss: 2.3409283755889354
Validation loss: 2.664076789228464

Epoch: 5| Step: 11
Training loss: 1.9712235186146079
Validation loss: 2.666021355889464

Epoch: 67| Step: 0
Training loss: 2.8522496897793994
Validation loss: 2.6665944683215566

Epoch: 5| Step: 1
Training loss: 3.05637260456326
Validation loss: 2.665887824454895

Epoch: 5| Step: 2
Training loss: 2.807201225980163
Validation loss: 2.6640769458427567

Epoch: 5| Step: 3
Training loss: 2.4873062211665866
Validation loss: 2.664003339839585

Epoch: 5| Step: 4
Training loss: 2.2036825786626397
Validation loss: 2.6636711869856846

Epoch: 5| Step: 5
Training loss: 2.8278403797560614
Validation loss: 2.6643903312447828

Epoch: 5| Step: 6
Training loss: 2.9450393671535995
Validation loss: 2.662049007127789

Epoch: 5| Step: 7
Training loss: 2.871967042728562
Validation loss: 2.6624783628477044

Epoch: 5| Step: 8
Training loss: 3.365714687048541
Validation loss: 2.660219177756556

Epoch: 5| Step: 9
Training loss: 2.5885335102119096
Validation loss: 2.6592440504563593

Epoch: 5| Step: 10
Training loss: 2.8112591867394325
Validation loss: 2.658879474565528

Epoch: 5| Step: 11
Training loss: 1.8439372985879041
Validation loss: 2.6586724099939283

Epoch: 68| Step: 0
Training loss: 2.3060263672617336
Validation loss: 2.6567166161677704

Epoch: 5| Step: 1
Training loss: 3.3998717339948556
Validation loss: 2.654090433558009

Epoch: 5| Step: 2
Training loss: 3.4120098726190125
Validation loss: 2.6521285713714615

Epoch: 5| Step: 3
Training loss: 2.4379522442040433
Validation loss: 2.6515689555299184

Epoch: 5| Step: 4
Training loss: 2.2471016123621372
Validation loss: 2.6527306148626173

Epoch: 5| Step: 5
Training loss: 3.023497430567204
Validation loss: 2.651020242320928

Epoch: 5| Step: 6
Training loss: 2.7870571075435877
Validation loss: 2.662845904307854

Epoch: 5| Step: 7
Training loss: 2.7418266558901396
Validation loss: 2.665597635555793

Epoch: 5| Step: 8
Training loss: 2.9386067030420344
Validation loss: 2.665606605910549

Epoch: 5| Step: 9
Training loss: 2.70890463647741
Validation loss: 2.6663886846751206

Epoch: 5| Step: 10
Training loss: 2.6761502867665783
Validation loss: 2.664040346323865

Epoch: 5| Step: 11
Training loss: 1.8611351465536248
Validation loss: 2.659908057167873

Epoch: 69| Step: 0
Training loss: 3.0609034833824014
Validation loss: 2.66231133265647

Epoch: 5| Step: 1
Training loss: 2.7271178808469494
Validation loss: 2.6595658717557624

Epoch: 5| Step: 2
Training loss: 3.1691831996131055
Validation loss: 2.6573202856644396

Epoch: 5| Step: 3
Training loss: 2.277523602929694
Validation loss: 2.659019470057961

Epoch: 5| Step: 4
Training loss: 3.194939701185903
Validation loss: 2.657780703639047

Epoch: 5| Step: 5
Training loss: 2.5718941040071153
Validation loss: 2.6557005145620898

Epoch: 5| Step: 6
Training loss: 2.193860642993083
Validation loss: 2.6562122566683137

Epoch: 5| Step: 7
Training loss: 2.854765130852544
Validation loss: 2.6549907841136346

Epoch: 5| Step: 8
Training loss: 2.9551152380146344
Validation loss: 2.654353044115338

Epoch: 5| Step: 9
Training loss: 2.8935897881667016
Validation loss: 2.6531695511563

Epoch: 5| Step: 10
Training loss: 2.580545110262767
Validation loss: 2.6507334327001333

Epoch: 5| Step: 11
Training loss: 3.079396251607458
Validation loss: 2.6497953716781737

Epoch: 70| Step: 0
Training loss: 2.7475958632318775
Validation loss: 2.6478262076744707

Epoch: 5| Step: 1
Training loss: 3.195838045583448
Validation loss: 2.6474907719886858

Epoch: 5| Step: 2
Training loss: 2.639209616283186
Validation loss: 2.6434549933618077

Epoch: 5| Step: 3
Training loss: 2.7969621186567193
Validation loss: 2.643205589352141

Epoch: 5| Step: 4
Training loss: 3.008845481355975
Validation loss: 2.6384517258772613

Epoch: 5| Step: 5
Training loss: 2.634534685718506
Validation loss: 2.639424839445002

Epoch: 5| Step: 6
Training loss: 2.9987095600564135
Validation loss: 2.634710105346861

Epoch: 5| Step: 7
Training loss: 3.2387852477876056
Validation loss: 2.632159347338337

Epoch: 5| Step: 8
Training loss: 2.386934810667178
Validation loss: 2.614802462803974

Epoch: 5| Step: 9
Training loss: 2.279312669818613
Validation loss: 2.6117694361046793

Epoch: 5| Step: 10
Training loss: 2.318782211861416
Validation loss: 2.6131350101442536

Epoch: 5| Step: 11
Training loss: 3.082075652949708
Validation loss: 2.611942026033352

Epoch: 71| Step: 0
Training loss: 3.088296727229273
Validation loss: 2.6071238486741066

Epoch: 5| Step: 1
Training loss: 2.482133537972844
Validation loss: 2.606058125556897

Epoch: 5| Step: 2
Training loss: 3.2920166666529056
Validation loss: 2.607294928690543

Epoch: 5| Step: 3
Training loss: 2.718559433846394
Validation loss: 2.6071847948358045

Epoch: 5| Step: 4
Training loss: 1.7344892309563258
Validation loss: 2.6082450453123327

Epoch: 5| Step: 5
Training loss: 2.334148423562695
Validation loss: 2.608639946690638

Epoch: 5| Step: 6
Training loss: 2.870048903736462
Validation loss: 2.6036614589193032

Epoch: 5| Step: 7
Training loss: 2.8655315887302204
Validation loss: 2.6095685258928762

Epoch: 5| Step: 8
Training loss: 2.8569133564192013
Validation loss: 2.6054729478793663

Epoch: 5| Step: 9
Training loss: 2.537949444284575
Validation loss: 2.606151356038587

Epoch: 5| Step: 10
Training loss: 3.054995470059247
Validation loss: 2.605436527905109

Epoch: 5| Step: 11
Training loss: 2.663107065831111
Validation loss: 2.6039431526902765

Epoch: 72| Step: 0
Training loss: 2.6592464823884714
Validation loss: 2.604759546819355

Epoch: 5| Step: 1
Training loss: 2.638339797554443
Validation loss: 2.606844960370936

Epoch: 5| Step: 2
Training loss: 2.829035491224511
Validation loss: 2.6070117565992743

Epoch: 5| Step: 3
Training loss: 2.615245041316234
Validation loss: 2.6092021184364897

Epoch: 5| Step: 4
Training loss: 2.741820395043103
Validation loss: 2.6102337708960177

Epoch: 5| Step: 5
Training loss: 2.9638245530809195
Validation loss: 2.611578979464538

Epoch: 5| Step: 6
Training loss: 2.3973338417813643
Validation loss: 2.6055853425361013

Epoch: 5| Step: 7
Training loss: 2.745113279162773
Validation loss: 2.602203702522302

Epoch: 5| Step: 8
Training loss: 2.625641517360195
Validation loss: 2.6010885771153456

Epoch: 5| Step: 9
Training loss: 2.75175584745232
Validation loss: 2.603189747994666

Epoch: 5| Step: 10
Training loss: 2.9010254855478004
Validation loss: 2.5919652068249417

Epoch: 5| Step: 11
Training loss: 3.604026894624641
Validation loss: 2.5933276066148903

Epoch: 73| Step: 0
Training loss: 2.6270419761635226
Validation loss: 2.593797430501008

Epoch: 5| Step: 1
Training loss: 2.9187335910376713
Validation loss: 2.5968876937451917

Epoch: 5| Step: 2
Training loss: 2.864757037820518
Validation loss: 2.6024527988129362

Epoch: 5| Step: 3
Training loss: 2.3324532438541237
Validation loss: 2.594870275600483

Epoch: 5| Step: 4
Training loss: 2.3950031556046945
Validation loss: 2.5885569932101395

Epoch: 5| Step: 5
Training loss: 2.613895452421107
Validation loss: 2.5883275153894454

Epoch: 5| Step: 6
Training loss: 3.0262723343476847
Validation loss: 2.5908194267653912

Epoch: 5| Step: 7
Training loss: 2.7210237488023936
Validation loss: 2.591072485315342

Epoch: 5| Step: 8
Training loss: 2.844559103754214
Validation loss: 2.592347800165608

Epoch: 5| Step: 9
Training loss: 2.9668603605267214
Validation loss: 2.5916798921433664

Epoch: 5| Step: 10
Training loss: 2.6591641765006213
Validation loss: 2.591171411487078

Epoch: 5| Step: 11
Training loss: 2.7847900149834044
Validation loss: 2.591908103474522

Epoch: 74| Step: 0
Training loss: 2.2649002494488832
Validation loss: 2.59098429855272

Epoch: 5| Step: 1
Training loss: 2.8280130437957505
Validation loss: 2.5910500372937295

Epoch: 5| Step: 2
Training loss: 2.7957038345325356
Validation loss: 2.5889183853825517

Epoch: 5| Step: 3
Training loss: 2.9189507033552595
Validation loss: 2.584726958811708

Epoch: 5| Step: 4
Training loss: 2.296523398132526
Validation loss: 2.587129558238945

Epoch: 5| Step: 5
Training loss: 2.7799583607580938
Validation loss: 2.581864148156163

Epoch: 5| Step: 6
Training loss: 2.6855329367536025
Validation loss: 2.57951632054401

Epoch: 5| Step: 7
Training loss: 2.5570939888208204
Validation loss: 2.5767639844779

Epoch: 5| Step: 8
Training loss: 2.6368306906214927
Validation loss: 2.57537183468818

Epoch: 5| Step: 9
Training loss: 2.8822278926417444
Validation loss: 2.5773860527452936

Epoch: 5| Step: 10
Training loss: 3.1564225253551426
Validation loss: 2.5760707647395247

Epoch: 5| Step: 11
Training loss: 2.5659956001131032
Validation loss: 2.5767599749993986

Epoch: 75| Step: 0
Training loss: 2.3364512411263036
Validation loss: 2.572364683568306

Epoch: 5| Step: 1
Training loss: 2.5778630903895903
Validation loss: 2.573466228115531

Epoch: 5| Step: 2
Training loss: 2.535133867209069
Validation loss: 2.577843147823531

Epoch: 5| Step: 3
Training loss: 2.7689791237983368
Validation loss: 2.5839353457273657

Epoch: 5| Step: 4
Training loss: 2.9675218149747566
Validation loss: 2.5983554099965764

Epoch: 5| Step: 5
Training loss: 3.0039737133293185
Validation loss: 2.583206692150004

Epoch: 5| Step: 6
Training loss: 2.896393170660339
Validation loss: 2.5827021955847105

Epoch: 5| Step: 7
Training loss: 2.821920765857336
Validation loss: 2.5770513437475704

Epoch: 5| Step: 8
Training loss: 2.8556379067222584
Validation loss: 2.5663948116889497

Epoch: 5| Step: 9
Training loss: 3.1844207251263548
Validation loss: 2.5659800523481597

Epoch: 5| Step: 10
Training loss: 1.8385195492142632
Validation loss: 2.5657574720484826

Epoch: 5| Step: 11
Training loss: 1.6085873500405787
Validation loss: 2.5686765409672208

Epoch: 76| Step: 0
Training loss: 3.00793155583166
Validation loss: 2.5684983906032004

Epoch: 5| Step: 1
Training loss: 2.746082463248053
Validation loss: 2.570624246601044

Epoch: 5| Step: 2
Training loss: 2.8159585668376734
Validation loss: 2.5704951467811403

Epoch: 5| Step: 3
Training loss: 2.406442114356744
Validation loss: 2.5657633107207545

Epoch: 5| Step: 4
Training loss: 3.030186732112351
Validation loss: 2.568186416894228

Epoch: 5| Step: 5
Training loss: 2.2138317561332683
Validation loss: 2.561386781499568

Epoch: 5| Step: 6
Training loss: 2.4962255595333094
Validation loss: 2.5669211186161704

Epoch: 5| Step: 7
Training loss: 2.6562939808514265
Validation loss: 2.567781127506536

Epoch: 5| Step: 8
Training loss: 2.8314681552266308
Validation loss: 2.568840362803374

Epoch: 5| Step: 9
Training loss: 2.5920949044455033
Validation loss: 2.563121809375671

Epoch: 5| Step: 10
Training loss: 2.606128065884057
Validation loss: 2.5607322356140974

Epoch: 5| Step: 11
Training loss: 3.4976946186400655
Validation loss: 2.559564723620377

Epoch: 77| Step: 0
Training loss: 2.8632048093160103
Validation loss: 2.5610675490918435

Epoch: 5| Step: 1
Training loss: 2.472175635804944
Validation loss: 2.5583089733103046

Epoch: 5| Step: 2
Training loss: 2.567178131104994
Validation loss: 2.560746965657725

Epoch: 5| Step: 3
Training loss: 2.3811240295571587
Validation loss: 2.5639037497482278

Epoch: 5| Step: 4
Training loss: 2.581681082061194
Validation loss: 2.5649371827020153

Epoch: 5| Step: 5
Training loss: 2.773657561692007
Validation loss: 2.5573745851352774

Epoch: 5| Step: 6
Training loss: 2.8523530047268375
Validation loss: 2.5564119349876697

Epoch: 5| Step: 7
Training loss: 2.7928064685972815
Validation loss: 2.55876055845894

Epoch: 5| Step: 8
Training loss: 2.908217389729539
Validation loss: 2.553097987722737

Epoch: 5| Step: 9
Training loss: 2.514351943230599
Validation loss: 2.5550586263657844

Epoch: 5| Step: 10
Training loss: 2.8221427917149433
Validation loss: 2.54859033013677

Epoch: 5| Step: 11
Training loss: 2.5811161145085912
Validation loss: 2.5548349623744495

Epoch: 78| Step: 0
Training loss: 2.435671585181758
Validation loss: 2.5547124295666106

Epoch: 5| Step: 1
Training loss: 2.3064299639858943
Validation loss: 2.5571959309938346

Epoch: 5| Step: 2
Training loss: 2.3955056228969815
Validation loss: 2.549922718796855

Epoch: 5| Step: 3
Training loss: 2.921850520556714
Validation loss: 2.5490551064322355

Epoch: 5| Step: 4
Training loss: 2.4208787407175727
Validation loss: 2.548139502018024

Epoch: 5| Step: 5
Training loss: 2.7245935364402993
Validation loss: 2.548990155327853

Epoch: 5| Step: 6
Training loss: 3.1260700682574716
Validation loss: 2.546880335889972

Epoch: 5| Step: 7
Training loss: 2.4705011458634556
Validation loss: 2.545487558376049

Epoch: 5| Step: 8
Training loss: 2.825383243052753
Validation loss: 2.547711720545596

Epoch: 5| Step: 9
Training loss: 2.923546297790111
Validation loss: 2.5441013671495067

Epoch: 5| Step: 10
Training loss: 2.644897075013421
Validation loss: 2.546075098531835

Epoch: 5| Step: 11
Training loss: 3.319518086260746
Validation loss: 2.543762493337183

Epoch: 79| Step: 0
Training loss: 2.4149309589950283
Validation loss: 2.5434784815389007

Epoch: 5| Step: 1
Training loss: 2.668359060487099
Validation loss: 2.5444228648455676

Epoch: 5| Step: 2
Training loss: 2.8080526156916426
Validation loss: 2.5455774773884507

Epoch: 5| Step: 3
Training loss: 2.7022920769556436
Validation loss: 2.543632729253908

Epoch: 5| Step: 4
Training loss: 2.2844032546773496
Validation loss: 2.541730521655896

Epoch: 5| Step: 5
Training loss: 3.0077324398334477
Validation loss: 2.5451991880894287

Epoch: 5| Step: 6
Training loss: 2.6850861643173296
Validation loss: 2.537976432728699

Epoch: 5| Step: 7
Training loss: 2.457561975359306
Validation loss: 2.5403618837802036

Epoch: 5| Step: 8
Training loss: 3.064394929040304
Validation loss: 2.539864226702344

Epoch: 5| Step: 9
Training loss: 2.696351843313378
Validation loss: 2.5342903088562654

Epoch: 5| Step: 10
Training loss: 2.6185138131564556
Validation loss: 2.5354020754337605

Epoch: 5| Step: 11
Training loss: 2.243584174613888
Validation loss: 2.533483128500463

Epoch: 80| Step: 0
Training loss: 2.7771875951892935
Validation loss: 2.5352974114207467

Epoch: 5| Step: 1
Training loss: 2.467465803069791
Validation loss: 2.535534172709968

Epoch: 5| Step: 2
Training loss: 3.101745138868463
Validation loss: 2.5413214196299982

Epoch: 5| Step: 3
Training loss: 2.4688151870040387
Validation loss: 2.541989506610048

Epoch: 5| Step: 4
Training loss: 2.3300885618348612
Validation loss: 2.538072465423216

Epoch: 5| Step: 5
Training loss: 2.757004746536414
Validation loss: 2.5349301128108794

Epoch: 5| Step: 6
Training loss: 2.4627215987672395
Validation loss: 2.5336669599189716

Epoch: 5| Step: 7
Training loss: 2.6705866155671374
Validation loss: 2.5374209922554796

Epoch: 5| Step: 8
Training loss: 2.1760564934745994
Validation loss: 2.535456701812576

Epoch: 5| Step: 9
Training loss: 2.753986070707135
Validation loss: 2.5298791163669394

Epoch: 5| Step: 10
Training loss: 3.0171277348956833
Validation loss: 2.5350144027737205

Epoch: 5| Step: 11
Training loss: 3.057585217465009
Validation loss: 2.535105241870716

Epoch: 81| Step: 0
Training loss: 2.9522640850446016
Validation loss: 2.5296778722104287

Epoch: 5| Step: 1
Training loss: 2.595282044711434
Validation loss: 2.537010611867407

Epoch: 5| Step: 2
Training loss: 2.653011007746964
Validation loss: 2.53569128173497

Epoch: 5| Step: 3
Training loss: 2.529856545523911
Validation loss: 2.5408550605603972

Epoch: 5| Step: 4
Training loss: 2.849489895863113
Validation loss: 2.5360249508774517

Epoch: 5| Step: 5
Training loss: 2.6524655478466497
Validation loss: 2.5280195862586257

Epoch: 5| Step: 6
Training loss: 2.781083777100259
Validation loss: 2.5300105360877243

Epoch: 5| Step: 7
Training loss: 2.5022845320493623
Validation loss: 2.529584898192336

Epoch: 5| Step: 8
Training loss: 2.6164959805292054
Validation loss: 2.5273818652400335

Epoch: 5| Step: 9
Training loss: 2.394807535135251
Validation loss: 2.5281468942556278

Epoch: 5| Step: 10
Training loss: 2.4271384848248405
Validation loss: 2.532119562369972

Epoch: 5| Step: 11
Training loss: 3.1004446018476086
Validation loss: 2.525101875541339

Epoch: 82| Step: 0
Training loss: 2.687492902879437
Validation loss: 2.5253715622593766

Epoch: 5| Step: 1
Training loss: 2.5845875515417296
Validation loss: 2.526158604749984

Epoch: 5| Step: 2
Training loss: 2.360332976628315
Validation loss: 2.52549486173803

Epoch: 5| Step: 3
Training loss: 2.0102334474343007
Validation loss: 2.5254450942378375

Epoch: 5| Step: 4
Training loss: 2.57945984471849
Validation loss: 2.5258914286712755

Epoch: 5| Step: 5
Training loss: 2.633951274783216
Validation loss: 2.5258068027967764

Epoch: 5| Step: 6
Training loss: 2.330803885230117
Validation loss: 2.5242536974697205

Epoch: 5| Step: 7
Training loss: 2.674046576460218
Validation loss: 2.5248766437777417

Epoch: 5| Step: 8
Training loss: 2.8433891318936797
Validation loss: 2.5236717642903654

Epoch: 5| Step: 9
Training loss: 3.1986447146501096
Validation loss: 2.5171462764636092

Epoch: 5| Step: 10
Training loss: 3.0740152410403625
Validation loss: 2.526315758113711

Epoch: 5| Step: 11
Training loss: 2.3311281228614
Validation loss: 2.5238389127983236

Epoch: 83| Step: 0
Training loss: 2.3501055186504933
Validation loss: 2.522285359812367

Epoch: 5| Step: 1
Training loss: 2.6713956882589094
Validation loss: 2.527878462500292

Epoch: 5| Step: 2
Training loss: 2.6808575892119397
Validation loss: 2.5298553125249454

Epoch: 5| Step: 3
Training loss: 2.5731871510362034
Validation loss: 2.5281733861504443

Epoch: 5| Step: 4
Training loss: 2.597304975808505
Validation loss: 2.5451453640936244

Epoch: 5| Step: 5
Training loss: 2.4977036420032634
Validation loss: 2.5477427114168387

Epoch: 5| Step: 6
Training loss: 2.664494364796394
Validation loss: 2.542476100440461

Epoch: 5| Step: 7
Training loss: 2.654294180289747
Validation loss: 2.5290943275760807

Epoch: 5| Step: 8
Training loss: 2.7793494599569057
Validation loss: 2.522046606377385

Epoch: 5| Step: 9
Training loss: 2.9911253316288366
Validation loss: 2.519775871604773

Epoch: 5| Step: 10
Training loss: 2.622967796241431
Validation loss: 2.5111335875645544

Epoch: 5| Step: 11
Training loss: 2.085205178170916
Validation loss: 2.517334651296413

Epoch: 84| Step: 0
Training loss: 2.850588781205759
Validation loss: 2.5163192738729667

Epoch: 5| Step: 1
Training loss: 2.709767377659535
Validation loss: 2.5195656569544096

Epoch: 5| Step: 2
Training loss: 2.078711634847905
Validation loss: 2.5244792642049663

Epoch: 5| Step: 3
Training loss: 2.120925812369378
Validation loss: 2.5243558482203667

Epoch: 5| Step: 4
Training loss: 2.731136649636341
Validation loss: 2.5265915786620536

Epoch: 5| Step: 5
Training loss: 3.001952489630707
Validation loss: 2.5237952137273196

Epoch: 5| Step: 6
Training loss: 2.9078282818578645
Validation loss: 2.522858914555101

Epoch: 5| Step: 7
Training loss: 2.639962559058825
Validation loss: 2.524076859108756

Epoch: 5| Step: 8
Training loss: 2.6545773793731904
Validation loss: 2.5225822014926202

Epoch: 5| Step: 9
Training loss: 2.487563096976233
Validation loss: 2.522359773382179

Epoch: 5| Step: 10
Training loss: 2.810341663834946
Validation loss: 2.5182636630757065

Epoch: 5| Step: 11
Training loss: 2.9355439511587234
Validation loss: 2.5147629202550528

Epoch: 85| Step: 0
Training loss: 2.4429812302619833
Validation loss: 2.5163042640172573

Epoch: 5| Step: 1
Training loss: 2.3847653250729235
Validation loss: 2.5090924618189105

Epoch: 5| Step: 2
Training loss: 2.903318341636566
Validation loss: 2.513969172611917

Epoch: 5| Step: 3
Training loss: 2.6417193430593446
Validation loss: 2.5135922008060745

Epoch: 5| Step: 4
Training loss: 2.6309333230141894
Validation loss: 2.5181057665366438

Epoch: 5| Step: 5
Training loss: 2.807497959424956
Validation loss: 2.5151883056263706

Epoch: 5| Step: 6
Training loss: 2.1259299094846718
Validation loss: 2.527050223347208

Epoch: 5| Step: 7
Training loss: 3.280695841179359
Validation loss: 2.5326058794729525

Epoch: 5| Step: 8
Training loss: 2.544270219025136
Validation loss: 2.5242918042719773

Epoch: 5| Step: 9
Training loss: 2.7455142455640646
Validation loss: 2.514659660832812

Epoch: 5| Step: 10
Training loss: 2.4895105604019405
Validation loss: 2.5125050043337755

Epoch: 5| Step: 11
Training loss: 2.817777302591877
Validation loss: 2.5083097240270513

Epoch: 86| Step: 0
Training loss: 3.0950515013124367
Validation loss: 2.5092216406832337

Epoch: 5| Step: 1
Training loss: 2.1996248185420604
Validation loss: 2.513211101121796

Epoch: 5| Step: 2
Training loss: 2.012927593985116
Validation loss: 2.516731192748956

Epoch: 5| Step: 3
Training loss: 2.651878259905399
Validation loss: 2.519170631801384

Epoch: 5| Step: 4
Training loss: 2.4086593851605342
Validation loss: 2.5237546510859814

Epoch: 5| Step: 5
Training loss: 3.0097019354674384
Validation loss: 2.519007673248582

Epoch: 5| Step: 6
Training loss: 2.698624143788775
Validation loss: 2.5197039522818803

Epoch: 5| Step: 7
Training loss: 2.4398388523293284
Validation loss: 2.5181976041554894

Epoch: 5| Step: 8
Training loss: 2.80496520471326
Validation loss: 2.513820790995417

Epoch: 5| Step: 9
Training loss: 2.7119527449302767
Validation loss: 2.5173430173961746

Epoch: 5| Step: 10
Training loss: 2.633460624451155
Validation loss: 2.5136278727092916

Epoch: 5| Step: 11
Training loss: 3.918758050402292
Validation loss: 2.5137567078513383

Epoch: 87| Step: 0
Training loss: 2.985084649040706
Validation loss: 2.5122190009926517

Epoch: 5| Step: 1
Training loss: 2.4750474212419125
Validation loss: 2.509448546728884

Epoch: 5| Step: 2
Training loss: 2.651766055402597
Validation loss: 2.5106938210449

Epoch: 5| Step: 3
Training loss: 2.814876654244957
Validation loss: 2.5098692480482687

Epoch: 5| Step: 4
Training loss: 2.862454782986721
Validation loss: 2.5083231698165074

Epoch: 5| Step: 5
Training loss: 2.693355391556835
Validation loss: 2.5050782462676744

Epoch: 5| Step: 6
Training loss: 2.4598970666145004
Validation loss: 2.5046982606120043

Epoch: 5| Step: 7
Training loss: 2.611363641102203
Validation loss: 2.503197334060375

Epoch: 5| Step: 8
Training loss: 2.4897030491688708
Validation loss: 2.5032955025884522

Epoch: 5| Step: 9
Training loss: 2.3224687928565855
Validation loss: 2.5031274624866784

Epoch: 5| Step: 10
Training loss: 2.481281105442278
Validation loss: 2.502355161591821

Epoch: 5| Step: 11
Training loss: 2.517567518402793
Validation loss: 2.501868547076594

Epoch: 88| Step: 0
Training loss: 2.1930782582956945
Validation loss: 2.497774627778966

Epoch: 5| Step: 1
Training loss: 1.9013727674906886
Validation loss: 2.5003805427206953

Epoch: 5| Step: 2
Training loss: 2.5896193923546993
Validation loss: 2.5001412470970403

Epoch: 5| Step: 3
Training loss: 2.2105300581811953
Validation loss: 2.499027587600965

Epoch: 5| Step: 4
Training loss: 2.816640815014304
Validation loss: 2.501615522856403

Epoch: 5| Step: 5
Training loss: 2.0544373102490043
Validation loss: 2.5020493730330875

Epoch: 5| Step: 6
Training loss: 3.3585876961702534
Validation loss: 2.5070240330119202

Epoch: 5| Step: 7
Training loss: 2.7078130564658798
Validation loss: 2.5026157523107675

Epoch: 5| Step: 8
Training loss: 2.353191736498402
Validation loss: 2.4983256574436052

Epoch: 5| Step: 9
Training loss: 3.1131789359364173
Validation loss: 2.5052711904548444

Epoch: 5| Step: 10
Training loss: 3.021008523706144
Validation loss: 2.5014987347315176

Epoch: 5| Step: 11
Training loss: 2.6422229875000762
Validation loss: 2.5038199109820116

Epoch: 89| Step: 0
Training loss: 2.4724034184645625
Validation loss: 2.5047588632514817

Epoch: 5| Step: 1
Training loss: 2.6664730140784005
Validation loss: 2.5071908966742606

Epoch: 5| Step: 2
Training loss: 2.4355711518938428
Validation loss: 2.5091520714776125

Epoch: 5| Step: 3
Training loss: 2.9322901850550394
Validation loss: 2.5008206411363973

Epoch: 5| Step: 4
Training loss: 3.0479715574844812
Validation loss: 2.504094882947551

Epoch: 5| Step: 5
Training loss: 2.528461380165568
Validation loss: 2.499365483665172

Epoch: 5| Step: 6
Training loss: 2.8257246421520588
Validation loss: 2.497818161647665

Epoch: 5| Step: 7
Training loss: 2.588864516778847
Validation loss: 2.5037973333624546

Epoch: 5| Step: 8
Training loss: 2.704506229031668
Validation loss: 2.503262751071448

Epoch: 5| Step: 9
Training loss: 2.627887953728445
Validation loss: 2.498685018092994

Epoch: 5| Step: 10
Training loss: 2.1557257194580575
Validation loss: 2.500247064938949

Epoch: 5| Step: 11
Training loss: 1.4325427118561298
Validation loss: 2.4987239958870027

Epoch: 90| Step: 0
Training loss: 2.4786544291991226
Validation loss: 2.4981461804226703

Epoch: 5| Step: 1
Training loss: 2.7755089988940576
Validation loss: 2.4998046719221025

Epoch: 5| Step: 2
Training loss: 2.639855357311388
Validation loss: 2.4994467440997785

Epoch: 5| Step: 3
Training loss: 2.6537413475409464
Validation loss: 2.4992156586504195

Epoch: 5| Step: 4
Training loss: 2.499948310317686
Validation loss: 2.5011093022994615

Epoch: 5| Step: 5
Training loss: 2.852289143825596
Validation loss: 2.4961478675702717

Epoch: 5| Step: 6
Training loss: 3.129038375750829
Validation loss: 2.497010891828613

Epoch: 5| Step: 7
Training loss: 2.5469867705176434
Validation loss: 2.4960486498018284

Epoch: 5| Step: 8
Training loss: 2.379540169476417
Validation loss: 2.4904116219664187

Epoch: 5| Step: 9
Training loss: 2.188084115651857
Validation loss: 2.4966130718845894

Epoch: 5| Step: 10
Training loss: 2.52921533637271
Validation loss: 2.5069379103432485

Epoch: 5| Step: 11
Training loss: 2.7986217989742466
Validation loss: 2.5046848191603703

Epoch: 91| Step: 0
Training loss: 2.7822579261241165
Validation loss: 2.4973100077997605

Epoch: 5| Step: 1
Training loss: 2.781689984098346
Validation loss: 2.4975270398266916

Epoch: 5| Step: 2
Training loss: 2.1953239033358747
Validation loss: 2.5025148617267896

Epoch: 5| Step: 3
Training loss: 2.3990539355048743
Validation loss: 2.49938964545654

Epoch: 5| Step: 4
Training loss: 2.9154128149738705
Validation loss: 2.4947519730587113

Epoch: 5| Step: 5
Training loss: 2.9676624112890484
Validation loss: 2.4924059406402463

Epoch: 5| Step: 6
Training loss: 2.6533845592550684
Validation loss: 2.50301120132671

Epoch: 5| Step: 7
Training loss: 2.7050613788403135
Validation loss: 2.502599397959749

Epoch: 5| Step: 8
Training loss: 2.12112971884788
Validation loss: 2.4946817255715885

Epoch: 5| Step: 9
Training loss: 2.135291032274286
Validation loss: 2.4921189301722957

Epoch: 5| Step: 10
Training loss: 2.758378184281396
Validation loss: 2.4942528627971905

Epoch: 5| Step: 11
Training loss: 2.7046453356968523
Validation loss: 2.493473546281177

Epoch: 92| Step: 0
Training loss: 3.0166368121220692
Validation loss: 2.493137373920245

Epoch: 5| Step: 1
Training loss: 2.4915964029498983
Validation loss: 2.4882514309057044

Epoch: 5| Step: 2
Training loss: 2.625117708019401
Validation loss: 2.4850295781959963

Epoch: 5| Step: 3
Training loss: 2.089429240251584
Validation loss: 2.488315508180953

Epoch: 5| Step: 4
Training loss: 2.2540713667923242
Validation loss: 2.49020112059087

Epoch: 5| Step: 5
Training loss: 2.860072316675963
Validation loss: 2.4934078206467567

Epoch: 5| Step: 6
Training loss: 3.0106520687230285
Validation loss: 2.4903116171831257

Epoch: 5| Step: 7
Training loss: 2.12133270659918
Validation loss: 2.488862138032724

Epoch: 5| Step: 8
Training loss: 2.801306681912773
Validation loss: 2.4872406840342767

Epoch: 5| Step: 9
Training loss: 2.607692518725472
Validation loss: 2.4835891660392213

Epoch: 5| Step: 10
Training loss: 2.459819139949811
Validation loss: 2.4879856502948625

Epoch: 5| Step: 11
Training loss: 3.4733869472570973
Validation loss: 2.4829349342792755

Epoch: 93| Step: 0
Training loss: 2.9737336741412603
Validation loss: 2.485661755223653

Epoch: 5| Step: 1
Training loss: 2.2888391795928045
Validation loss: 2.489356415009039

Epoch: 5| Step: 2
Training loss: 2.901843267855156
Validation loss: 2.4892253472042

Epoch: 5| Step: 3
Training loss: 2.636617927036484
Validation loss: 2.489110823340009

Epoch: 5| Step: 4
Training loss: 2.602191012872492
Validation loss: 2.480401578379162

Epoch: 5| Step: 5
Training loss: 2.669039465328392
Validation loss: 2.4836790161599716

Epoch: 5| Step: 6
Training loss: 2.2470053771582363
Validation loss: 2.4807700747594836

Epoch: 5| Step: 7
Training loss: 2.450970620939936
Validation loss: 2.4824314452396283

Epoch: 5| Step: 8
Training loss: 2.8653100958701843
Validation loss: 2.488797735551245

Epoch: 5| Step: 9
Training loss: 2.590906997996189
Validation loss: 2.4968573089405752

Epoch: 5| Step: 10
Training loss: 2.345526467054637
Validation loss: 2.491489224882875

Epoch: 5| Step: 11
Training loss: 2.086376586876891
Validation loss: 2.4987140527111107

Epoch: 94| Step: 0
Training loss: 2.766006098637784
Validation loss: 2.495468252309862

Epoch: 5| Step: 1
Training loss: 2.368571968735918
Validation loss: 2.5035837752352172

Epoch: 5| Step: 2
Training loss: 2.527657962470009
Validation loss: 2.505381732155544

Epoch: 5| Step: 3
Training loss: 3.2124245720108937
Validation loss: 2.49604853836369

Epoch: 5| Step: 4
Training loss: 2.212344958374202
Validation loss: 2.4972637262232222

Epoch: 5| Step: 5
Training loss: 2.7409883577975642
Validation loss: 2.4888152942238326

Epoch: 5| Step: 6
Training loss: 2.6005881377900946
Validation loss: 2.4857536785033676

Epoch: 5| Step: 7
Training loss: 2.6826619803095104
Validation loss: 2.488045034968968

Epoch: 5| Step: 8
Training loss: 2.1907332367761203
Validation loss: 2.491998065377776

Epoch: 5| Step: 9
Training loss: 2.606759959581519
Validation loss: 2.4913945705474596

Epoch: 5| Step: 10
Training loss: 2.7321628886823293
Validation loss: 2.490778214653196

Epoch: 5| Step: 11
Training loss: 2.5755330321071592
Validation loss: 2.4945516065974984

Epoch: 95| Step: 0
Training loss: 2.3534194863338764
Validation loss: 2.490123723382889

Epoch: 5| Step: 1
Training loss: 2.5136921725457695
Validation loss: 2.490224465743152

Epoch: 5| Step: 2
Training loss: 2.593778679011253
Validation loss: 2.485427117838687

Epoch: 5| Step: 3
Training loss: 2.7677763421706496
Validation loss: 2.4901378099256197

Epoch: 5| Step: 4
Training loss: 2.5529139717510785
Validation loss: 2.4860053321124442

Epoch: 5| Step: 5
Training loss: 2.4535007067613845
Validation loss: 2.487195263539871

Epoch: 5| Step: 6
Training loss: 2.9433363702858464
Validation loss: 2.488640552172548

Epoch: 5| Step: 7
Training loss: 2.7856675972012828
Validation loss: 2.4880655335921436

Epoch: 5| Step: 8
Training loss: 2.6505352703252756
Validation loss: 2.487040790906163

Epoch: 5| Step: 9
Training loss: 2.1978124319613777
Validation loss: 2.4922938867261624

Epoch: 5| Step: 10
Training loss: 2.6263351677907028
Validation loss: 2.489167838492776

Epoch: 5| Step: 11
Training loss: 3.5464485348998593
Validation loss: 2.486118772312581

Epoch: 96| Step: 0
Training loss: 2.4309672330957097
Validation loss: 2.4850773768144188

Epoch: 5| Step: 1
Training loss: 2.5969039860288614
Validation loss: 2.4825206649895932

Epoch: 5| Step: 2
Training loss: 2.5717778536316422
Validation loss: 2.4873235028077842

Epoch: 5| Step: 3
Training loss: 2.3009822738210035
Validation loss: 2.4829046508768036

Epoch: 5| Step: 4
Training loss: 3.0067461774114586
Validation loss: 2.4883514306567975

Epoch: 5| Step: 5
Training loss: 2.7124734094960083
Validation loss: 2.4925472314798545

Epoch: 5| Step: 6
Training loss: 3.0553480443908976
Validation loss: 2.488952817573629

Epoch: 5| Step: 7
Training loss: 2.205628399909824
Validation loss: 2.485358281554287

Epoch: 5| Step: 8
Training loss: 2.7899080592220873
Validation loss: 2.4870070484189575

Epoch: 5| Step: 9
Training loss: 2.3683478907388973
Validation loss: 2.483341697917736

Epoch: 5| Step: 10
Training loss: 2.2593648781028675
Validation loss: 2.485538929769649

Epoch: 5| Step: 11
Training loss: 3.1105657243283273
Validation loss: 2.4880212820679697

Epoch: 97| Step: 0
Training loss: 2.4403682363649217
Validation loss: 2.495501723148579

Epoch: 5| Step: 1
Training loss: 2.706429198501273
Validation loss: 2.4838898982872624

Epoch: 5| Step: 2
Training loss: 2.5110103385344815
Validation loss: 2.4859183573869954

Epoch: 5| Step: 3
Training loss: 2.36957271249116
Validation loss: 2.4942978720010265

Epoch: 5| Step: 4
Training loss: 2.108390748017474
Validation loss: 2.4993080294133607

Epoch: 5| Step: 5
Training loss: 2.263093467983663
Validation loss: 2.5096917404995875

Epoch: 5| Step: 6
Training loss: 2.5873593573194835
Validation loss: 2.5151172425628037

Epoch: 5| Step: 7
Training loss: 3.051630466092989
Validation loss: 2.529369075338697

Epoch: 5| Step: 8
Training loss: 2.6556333835942607
Validation loss: 2.5398581837752747

Epoch: 5| Step: 9
Training loss: 2.8001825818069577
Validation loss: 2.5363750182978633

Epoch: 5| Step: 10
Training loss: 3.232470260211886
Validation loss: 2.527042156700625

Epoch: 5| Step: 11
Training loss: 2.820576240697961
Validation loss: 2.5194199806108895

Epoch: 98| Step: 0
Training loss: 2.383239107559044
Validation loss: 2.5151081817988827

Epoch: 5| Step: 1
Training loss: 2.8426204576022815
Validation loss: 2.506527009719157

Epoch: 5| Step: 2
Training loss: 2.3278585191843932
Validation loss: 2.4988318495697572

Epoch: 5| Step: 3
Training loss: 2.7442464461913914
Validation loss: 2.492364970777269

Epoch: 5| Step: 4
Training loss: 2.7848243462113924
Validation loss: 2.4884940894267924

Epoch: 5| Step: 5
Training loss: 2.8984835639028286
Validation loss: 2.4832567421304987

Epoch: 5| Step: 6
Training loss: 2.663410006180601
Validation loss: 2.4807278114863496

Epoch: 5| Step: 7
Training loss: 2.494123036106736
Validation loss: 2.4804393656434454

Epoch: 5| Step: 8
Training loss: 2.3670411521064394
Validation loss: 2.4835100647638098

Epoch: 5| Step: 9
Training loss: 2.6534780961551014
Validation loss: 2.481228601409859

Epoch: 5| Step: 10
Training loss: 2.7119611846599225
Validation loss: 2.480184780096063

Epoch: 5| Step: 11
Training loss: 1.5449639277274814
Validation loss: 2.4829389672372284

Epoch: 99| Step: 0
Training loss: 2.8330739594462377
Validation loss: 2.486147733918238

Epoch: 5| Step: 1
Training loss: 2.751864668085758
Validation loss: 2.4825546065090625

Epoch: 5| Step: 2
Training loss: 2.7390758977585197
Validation loss: 2.4757880475107523

Epoch: 5| Step: 3
Training loss: 2.1178541647077522
Validation loss: 2.481444691979837

Epoch: 5| Step: 4
Training loss: 2.6959658508118935
Validation loss: 2.4827857462404035

Epoch: 5| Step: 5
Training loss: 2.592102814636786
Validation loss: 2.475100036326955

Epoch: 5| Step: 6
Training loss: 2.534017862728179
Validation loss: 2.482484430044673

Epoch: 5| Step: 7
Training loss: 2.589854797063543
Validation loss: 2.4841492148431183

Epoch: 5| Step: 8
Training loss: 2.547846602950089
Validation loss: 2.483104924977675

Epoch: 5| Step: 9
Training loss: 2.787859146861925
Validation loss: 2.4872126817504885

Epoch: 5| Step: 10
Training loss: 2.486186392820577
Validation loss: 2.4893576999924822

Epoch: 5| Step: 11
Training loss: 2.3093388576544274
Validation loss: 2.4873453692836263

Epoch: 100| Step: 0
Training loss: 3.012473243183009
Validation loss: 2.48299917676013

Epoch: 5| Step: 1
Training loss: 2.329418463110855
Validation loss: 2.4849721962532976

Epoch: 5| Step: 2
Training loss: 2.479361507762742
Validation loss: 2.4815157545415754

Epoch: 5| Step: 3
Training loss: 2.280225549885276
Validation loss: 2.485185742795342

Epoch: 5| Step: 4
Training loss: 2.4773090573049767
Validation loss: 2.4820716104576945

Epoch: 5| Step: 5
Training loss: 2.605708853254655
Validation loss: 2.4844741321674944

Epoch: 5| Step: 6
Training loss: 2.69946181973573
Validation loss: 2.4850701413211294

Epoch: 5| Step: 7
Training loss: 2.276594349488464
Validation loss: 2.4807127504661883

Epoch: 5| Step: 8
Training loss: 2.539800354778416
Validation loss: 2.480665472444867

Epoch: 5| Step: 9
Training loss: 2.5680419725749215
Validation loss: 2.4783711953713947

Epoch: 5| Step: 10
Training loss: 3.1278238888991594
Validation loss: 2.4821093282725295

Epoch: 5| Step: 11
Training loss: 2.7955342067862907
Validation loss: 2.472070557309298

Epoch: 101| Step: 0
Training loss: 2.726276546665603
Validation loss: 2.4784030953892704

Epoch: 5| Step: 1
Training loss: 2.572918622920931
Validation loss: 2.4773506330468478

Epoch: 5| Step: 2
Training loss: 2.0669890593233204
Validation loss: 2.4722365735800684

Epoch: 5| Step: 3
Training loss: 2.519661644215462
Validation loss: 2.47325333572153

Epoch: 5| Step: 4
Training loss: 2.599087657781482
Validation loss: 2.477142899751257

Epoch: 5| Step: 5
Training loss: 2.441577923651667
Validation loss: 2.4766812281022212

Epoch: 5| Step: 6
Training loss: 2.841886979080568
Validation loss: 2.4765082392479454

Epoch: 5| Step: 7
Training loss: 2.4239424218241754
Validation loss: 2.477933353840204

Epoch: 5| Step: 8
Training loss: 2.656713557465712
Validation loss: 2.4758682280638347

Epoch: 5| Step: 9
Training loss: 2.2990474677310635
Validation loss: 2.473226862067672

Epoch: 5| Step: 10
Training loss: 3.102349553790844
Validation loss: 2.472656205806561

Epoch: 5| Step: 11
Training loss: 2.690930151388341
Validation loss: 2.4671920818200146

Epoch: 102| Step: 0
Training loss: 2.550025629400969
Validation loss: 2.470286728018556

Epoch: 5| Step: 1
Training loss: 3.023259120676624
Validation loss: 2.476764867238239

Epoch: 5| Step: 2
Training loss: 2.173122349699882
Validation loss: 2.477973620203506

Epoch: 5| Step: 3
Training loss: 3.0789099917114413
Validation loss: 2.479291998208968

Epoch: 5| Step: 4
Training loss: 2.191410384284759
Validation loss: 2.479759883965909

Epoch: 5| Step: 5
Training loss: 2.244721260353305
Validation loss: 2.4763379080386065

Epoch: 5| Step: 6
Training loss: 2.4705110859779484
Validation loss: 2.480861758839275

Epoch: 5| Step: 7
Training loss: 2.4200170465925113
Validation loss: 2.4865917696318207

Epoch: 5| Step: 8
Training loss: 3.185114397901929
Validation loss: 2.4851418557220377

Epoch: 5| Step: 9
Training loss: 2.314377615296454
Validation loss: 2.4846120437361283

Epoch: 5| Step: 10
Training loss: 2.821539699028415
Validation loss: 2.4879032887963892

Epoch: 5| Step: 11
Training loss: 0.8705079028818735
Validation loss: 2.4878368789346625

Epoch: 103| Step: 0
Training loss: 2.525846577350258
Validation loss: 2.481785124063459

Epoch: 5| Step: 1
Training loss: 2.618737698255246
Validation loss: 2.4801338910932875

Epoch: 5| Step: 2
Training loss: 2.7174157562814294
Validation loss: 2.4863250804322115

Epoch: 5| Step: 3
Training loss: 2.1753838825172713
Validation loss: 2.4784680244959163

Epoch: 5| Step: 4
Training loss: 3.0732449803371487
Validation loss: 2.4861538234844476

Epoch: 5| Step: 5
Training loss: 2.490818999236353
Validation loss: 2.485840958711355

Epoch: 5| Step: 6
Training loss: 2.306114660080772
Validation loss: 2.4784695997040505

Epoch: 5| Step: 7
Training loss: 2.3465845895993223
Validation loss: 2.473597579887869

Epoch: 5| Step: 8
Training loss: 2.529405651920097
Validation loss: 2.4839048240606174

Epoch: 5| Step: 9
Training loss: 2.7545044161431735
Validation loss: 2.483328408891374

Epoch: 5| Step: 10
Training loss: 2.7680800581087546
Validation loss: 2.4826156776665123

Epoch: 5| Step: 11
Training loss: 2.7202136605156957
Validation loss: 2.481631085256235

Epoch: 104| Step: 0
Training loss: 2.829929513761155
Validation loss: 2.4851776401942747

Epoch: 5| Step: 1
Training loss: 2.459407076208391
Validation loss: 2.482730989296518

Epoch: 5| Step: 2
Training loss: 2.5428037340852963
Validation loss: 2.4875046712425752

Epoch: 5| Step: 3
Training loss: 2.7077921008680557
Validation loss: 2.486302985228813

Epoch: 5| Step: 4
Training loss: 2.8427799792199724
Validation loss: 2.484283601531125

Epoch: 5| Step: 5
Training loss: 2.200024851745343
Validation loss: 2.484874547162125

Epoch: 5| Step: 6
Training loss: 2.6372253383431183
Validation loss: 2.4802920941902475

Epoch: 5| Step: 7
Training loss: 2.3111709693448117
Validation loss: 2.476409779040541

Epoch: 5| Step: 8
Training loss: 2.896142096948168
Validation loss: 2.482770517649288

Epoch: 5| Step: 9
Training loss: 2.6833819398762278
Validation loss: 2.4778032574236883

Epoch: 5| Step: 10
Training loss: 2.589061774355615
Validation loss: 2.479632539546695

Epoch: 5| Step: 11
Training loss: 1.2653904450259759
Validation loss: 2.4801352249151862

Epoch: 105| Step: 0
Training loss: 2.0648390482323267
Validation loss: 2.4811477412652594

Epoch: 5| Step: 1
Training loss: 2.6134150859962233
Validation loss: 2.47873067361284

Epoch: 5| Step: 2
Training loss: 2.6405720000055166
Validation loss: 2.483100128158083

Epoch: 5| Step: 3
Training loss: 2.7486030324909607
Validation loss: 2.4824391146105502

Epoch: 5| Step: 4
Training loss: 2.5009645508668017
Validation loss: 2.475245144452628

Epoch: 5| Step: 5
Training loss: 2.3419163970098285
Validation loss: 2.4803975973662373

Epoch: 5| Step: 6
Training loss: 2.534610730742787
Validation loss: 2.476180062112725

Epoch: 5| Step: 7
Training loss: 2.2875683174979624
Validation loss: 2.476292688732571

Epoch: 5| Step: 8
Training loss: 3.1515643398296564
Validation loss: 2.467421866541952

Epoch: 5| Step: 9
Training loss: 2.574235050688147
Validation loss: 2.4776547226643806

Epoch: 5| Step: 10
Training loss: 2.8000879001444146
Validation loss: 2.4744185906309393

Epoch: 5| Step: 11
Training loss: 2.0955884463031613
Validation loss: 2.478994629337709

Epoch: 106| Step: 0
Training loss: 2.971049973844688
Validation loss: 2.4728942965422593

Epoch: 5| Step: 1
Training loss: 2.3224068896268646
Validation loss: 2.4779536755264853

Epoch: 5| Step: 2
Training loss: 2.9694447557738424
Validation loss: 2.4781281369010246

Epoch: 5| Step: 3
Training loss: 2.366839694919995
Validation loss: 2.467531064258925

Epoch: 5| Step: 4
Training loss: 2.741479331189612
Validation loss: 2.472666603295706

Epoch: 5| Step: 5
Training loss: 2.3375926198306285
Validation loss: 2.4685295183578932

Epoch: 5| Step: 6
Training loss: 2.423596957462036
Validation loss: 2.469425712533952

Epoch: 5| Step: 7
Training loss: 2.4353704686891446
Validation loss: 2.4709638113776955

Epoch: 5| Step: 8
Training loss: 2.6928949543508853
Validation loss: 2.471802325492539

Epoch: 5| Step: 9
Training loss: 2.507935517998612
Validation loss: 2.467437314670838

Epoch: 5| Step: 10
Training loss: 2.526223549079114
Validation loss: 2.4704706054961045

Epoch: 5| Step: 11
Training loss: 1.966668678810685
Validation loss: 2.47632954381296

Epoch: 107| Step: 0
Training loss: 2.569043063410521
Validation loss: 2.466753107781555

Epoch: 5| Step: 1
Training loss: 2.290869614679365
Validation loss: 2.473976128497455

Epoch: 5| Step: 2
Training loss: 2.938526866884137
Validation loss: 2.474983859410943

Epoch: 5| Step: 3
Training loss: 2.1406726692627975
Validation loss: 2.476119113064522

Epoch: 5| Step: 4
Training loss: 2.176580806088331
Validation loss: 2.475039365725096

Epoch: 5| Step: 5
Training loss: 2.611626846928492
Validation loss: 2.4734254095730273

Epoch: 5| Step: 6
Training loss: 2.3529339716604665
Validation loss: 2.4793460217413887

Epoch: 5| Step: 7
Training loss: 2.785505660772178
Validation loss: 2.471330247983695

Epoch: 5| Step: 8
Training loss: 2.427014318530044
Validation loss: 2.470305041584013

Epoch: 5| Step: 9
Training loss: 2.80459858107872
Validation loss: 2.4687490382776116

Epoch: 5| Step: 10
Training loss: 2.954299773825515
Validation loss: 2.4675439874605463

Epoch: 5| Step: 11
Training loss: 2.774958577577202
Validation loss: 2.4692830463958413

Epoch: 108| Step: 0
Training loss: 2.1651483008357224
Validation loss: 2.472986123979714

Epoch: 5| Step: 1
Training loss: 2.1721983744338513
Validation loss: 2.4762913889461293

Epoch: 5| Step: 2
Training loss: 2.637241882421657
Validation loss: 2.4790249685189547

Epoch: 5| Step: 3
Training loss: 2.477796565993409
Validation loss: 2.4723089736607435

Epoch: 5| Step: 4
Training loss: 2.942553130701628
Validation loss: 2.4743385357412992

Epoch: 5| Step: 5
Training loss: 2.361654431031629
Validation loss: 2.481949471885638

Epoch: 5| Step: 6
Training loss: 2.681339299775625
Validation loss: 2.4771302872986163

Epoch: 5| Step: 7
Training loss: 2.9918947400329796
Validation loss: 2.4772056241938634

Epoch: 5| Step: 8
Training loss: 2.9056781493323247
Validation loss: 2.48146516906328

Epoch: 5| Step: 9
Training loss: 2.8773099492843115
Validation loss: 2.4759931020075694

Epoch: 5| Step: 10
Training loss: 1.9050121978809789
Validation loss: 2.480469346734724

Epoch: 5| Step: 11
Training loss: 2.211948338931441
Validation loss: 2.4815414592236977

Epoch: 109| Step: 0
Training loss: 2.6752639604622557
Validation loss: 2.4773802184459566

Epoch: 5| Step: 1
Training loss: 2.416497838491953
Validation loss: 2.473327714287304

Epoch: 5| Step: 2
Training loss: 2.4427189830122216
Validation loss: 2.4765281073170726

Epoch: 5| Step: 3
Training loss: 2.528242420162161
Validation loss: 2.4778359144713584

Epoch: 5| Step: 4
Training loss: 2.495069314456344
Validation loss: 2.4835502327107095

Epoch: 5| Step: 5
Training loss: 2.733586660911785
Validation loss: 2.4925427318189026

Epoch: 5| Step: 6
Training loss: 2.871272614804772
Validation loss: 2.4879807550786346

Epoch: 5| Step: 7
Training loss: 2.4127905991806218
Validation loss: 2.4804129486615754

Epoch: 5| Step: 8
Training loss: 2.723775669097741
Validation loss: 2.4677764365214863

Epoch: 5| Step: 9
Training loss: 2.754985971017001
Validation loss: 2.4736084633768476

Epoch: 5| Step: 10
Training loss: 2.389808465473321
Validation loss: 2.476009981152995

Epoch: 5| Step: 11
Training loss: 2.272246897821767
Validation loss: 2.476468225844838

Epoch: 110| Step: 0
Training loss: 2.961362622020742
Validation loss: 2.4834412593452284

Epoch: 5| Step: 1
Training loss: 2.1585171708375492
Validation loss: 2.4785595211854408

Epoch: 5| Step: 2
Training loss: 2.7462845759066545
Validation loss: 2.4781013785892454

Epoch: 5| Step: 3
Training loss: 2.4239535364601617
Validation loss: 2.481324095944889

Epoch: 5| Step: 4
Training loss: 2.860603777236008
Validation loss: 2.4783847975715925

Epoch: 5| Step: 5
Training loss: 2.5580981524428923
Validation loss: 2.4780981154585

Epoch: 5| Step: 6
Training loss: 2.381801903713387
Validation loss: 2.4762331245158005

Epoch: 5| Step: 7
Training loss: 2.6146897880696467
Validation loss: 2.4750786195656196

Epoch: 5| Step: 8
Training loss: 2.4783743118390613
Validation loss: 2.4794762615760626

Epoch: 5| Step: 9
Training loss: 2.771872667313791
Validation loss: 2.4729555741302156

Epoch: 5| Step: 10
Training loss: 2.387533744853149
Validation loss: 2.47314152668767

Epoch: 5| Step: 11
Training loss: 2.139208136784294
Validation loss: 2.470419383687428

Epoch: 111| Step: 0
Training loss: 2.953368807623385
Validation loss: 2.473850831490239

Epoch: 5| Step: 1
Training loss: 2.708301857007345
Validation loss: 2.478976271768779

Epoch: 5| Step: 2
Training loss: 1.7674511942943847
Validation loss: 2.472660472478571

Epoch: 5| Step: 3
Training loss: 2.7224659572746335
Validation loss: 2.475093907523814

Epoch: 5| Step: 4
Training loss: 2.177647227095957
Validation loss: 2.4711542614774062

Epoch: 5| Step: 5
Training loss: 2.1747789248656506
Validation loss: 2.466941356077369

Epoch: 5| Step: 6
Training loss: 2.5138686784057134
Validation loss: 2.472520825542948

Epoch: 5| Step: 7
Training loss: 2.273302736253568
Validation loss: 2.4658873495425437

Epoch: 5| Step: 8
Training loss: 2.9049533699744776
Validation loss: 2.473472681395767

Epoch: 5| Step: 9
Training loss: 3.00212546395559
Validation loss: 2.469090172714317

Epoch: 5| Step: 10
Training loss: 2.716473382576135
Validation loss: 2.4712477655421567

Epoch: 5| Step: 11
Training loss: 2.9872936736169144
Validation loss: 2.4697066960278

Epoch: 112| Step: 0
Training loss: 2.640592947319567
Validation loss: 2.4761413593200197

Epoch: 5| Step: 1
Training loss: 2.6455732402969665
Validation loss: 2.487944431953913

Epoch: 5| Step: 2
Training loss: 2.6922861108858123
Validation loss: 2.488255119885193

Epoch: 5| Step: 3
Training loss: 2.6178474163647185
Validation loss: 2.4821064386215053

Epoch: 5| Step: 4
Training loss: 2.14262408169862
Validation loss: 2.487811936096222

Epoch: 5| Step: 5
Training loss: 2.2844639960407656
Validation loss: 2.482998132538039

Epoch: 5| Step: 6
Training loss: 2.5893183156483865
Validation loss: 2.4878960615216377

Epoch: 5| Step: 7
Training loss: 2.343107618672925
Validation loss: 2.4791075448324884

Epoch: 5| Step: 8
Training loss: 2.6688429376290435
Validation loss: 2.475362364575709

Epoch: 5| Step: 9
Training loss: 2.77406050441026
Validation loss: 2.4747028729590372

Epoch: 5| Step: 10
Training loss: 2.864172074822729
Validation loss: 2.478912506111651

Epoch: 5| Step: 11
Training loss: 2.647248758096536
Validation loss: 2.4726200914676997

Epoch: 113| Step: 0
Training loss: 2.978717654521228
Validation loss: 2.4705354093337792

Epoch: 5| Step: 1
Training loss: 2.8321997862028176
Validation loss: 2.4733588017603063

Epoch: 5| Step: 2
Training loss: 2.4753864757231576
Validation loss: 2.478250501885401

Epoch: 5| Step: 3
Training loss: 2.1546560837057718
Validation loss: 2.4705463103335434

Epoch: 5| Step: 4
Training loss: 2.6247134279318702
Validation loss: 2.46832951856014

Epoch: 5| Step: 5
Training loss: 2.4527850067312476
Validation loss: 2.4723603933872256

Epoch: 5| Step: 6
Training loss: 2.5197244732715545
Validation loss: 2.4711774529057697

Epoch: 5| Step: 7
Training loss: 2.5875953361897315
Validation loss: 2.47186354575415

Epoch: 5| Step: 8
Training loss: 2.5759430871208973
Validation loss: 2.4729482509478227

Epoch: 5| Step: 9
Training loss: 2.4828659368757804
Validation loss: 2.4674232233400497

Epoch: 5| Step: 10
Training loss: 2.352072422845864
Validation loss: 2.466091338015102

Epoch: 5| Step: 11
Training loss: 3.0598397670506237
Validation loss: 2.474546199354462

Epoch: 114| Step: 0
Training loss: 2.357309409858747
Validation loss: 2.471784875049024

Epoch: 5| Step: 1
Training loss: 2.7225001986865207
Validation loss: 2.468800801748377

Epoch: 5| Step: 2
Training loss: 2.4792582283956683
Validation loss: 2.4637935071510393

Epoch: 5| Step: 3
Training loss: 3.012850260652732
Validation loss: 2.4664608204713048

Epoch: 5| Step: 4
Training loss: 2.8139088810617108
Validation loss: 2.482455113566343

Epoch: 5| Step: 5
Training loss: 2.240358463964663
Validation loss: 2.4774098435905194

Epoch: 5| Step: 6
Training loss: 2.539152642630633
Validation loss: 2.4829114405685897

Epoch: 5| Step: 7
Training loss: 2.358609410044743
Validation loss: 2.4749962780985477

Epoch: 5| Step: 8
Training loss: 2.5996190965844708
Validation loss: 2.482089214710745

Epoch: 5| Step: 9
Training loss: 2.3770659646400736
Validation loss: 2.4788444707710005

Epoch: 5| Step: 10
Training loss: 2.707453090722784
Validation loss: 2.478208065364556

Epoch: 5| Step: 11
Training loss: 2.211037893004219
Validation loss: 2.4742007782579205

Epoch: 115| Step: 0
Training loss: 3.0466576131885104
Validation loss: 2.4751207063762686

Epoch: 5| Step: 1
Training loss: 2.25838951472633
Validation loss: 2.47735230921471

Epoch: 5| Step: 2
Training loss: 2.520583389964105
Validation loss: 2.480300749448562

Epoch: 5| Step: 3
Training loss: 2.382561742376846
Validation loss: 2.4858627682939263

Epoch: 5| Step: 4
Training loss: 2.883888271342091
Validation loss: 2.4849408063228275

Epoch: 5| Step: 5
Training loss: 2.8232910827603988
Validation loss: 2.4821402737426643

Epoch: 5| Step: 6
Training loss: 2.73005570546981
Validation loss: 2.4839450856070187

Epoch: 5| Step: 7
Training loss: 2.5126500516655734
Validation loss: 2.4823864549880654

Epoch: 5| Step: 8
Training loss: 2.702658287727279
Validation loss: 2.481983545293372

Epoch: 5| Step: 9
Training loss: 1.9255339365038602
Validation loss: 2.481347924965774

Epoch: 5| Step: 10
Training loss: 2.428320987995563
Validation loss: 2.480797440986058

Epoch: 5| Step: 11
Training loss: 1.9598785824049854
Validation loss: 2.479400420722496

Epoch: 116| Step: 0
Training loss: 2.4369026821586477
Validation loss: 2.4811504518604273

Epoch: 5| Step: 1
Training loss: 2.5437274978729656
Validation loss: 2.4847232766418985

Epoch: 5| Step: 2
Training loss: 2.355085199357792
Validation loss: 2.4909819434540235

Epoch: 5| Step: 3
Training loss: 2.539119121213624
Validation loss: 2.475802953915265

Epoch: 5| Step: 4
Training loss: 2.641888017335818
Validation loss: 2.4827108787704324

Epoch: 5| Step: 5
Training loss: 2.3461449149107296
Validation loss: 2.4828845777666313

Epoch: 5| Step: 6
Training loss: 2.095915173044381
Validation loss: 2.4793076047719755

Epoch: 5| Step: 7
Training loss: 3.046775933635868
Validation loss: 2.4806763609661973

Epoch: 5| Step: 8
Training loss: 2.6480916115279007
Validation loss: 2.4786638957535327

Epoch: 5| Step: 9
Training loss: 2.5941674689334455
Validation loss: 2.4706931735957878

Epoch: 5| Step: 10
Training loss: 2.5608184693692646
Validation loss: 2.475337675287884

Epoch: 5| Step: 11
Training loss: 3.2605944860228657
Validation loss: 2.4797973284789876

Epoch: 117| Step: 0
Training loss: 2.7651728028696914
Validation loss: 2.474477518046724

Epoch: 5| Step: 1
Training loss: 2.1634484256444813
Validation loss: 2.4750283881848842

Epoch: 5| Step: 2
Training loss: 2.1928695172457315
Validation loss: 2.478451310393741

Epoch: 5| Step: 3
Training loss: 1.788800349456603
Validation loss: 2.473611551708725

Epoch: 5| Step: 4
Training loss: 2.3390589243237847
Validation loss: 2.4695006971552003

Epoch: 5| Step: 5
Training loss: 2.4936205531585527
Validation loss: 2.470447324998042

Epoch: 5| Step: 6
Training loss: 3.2673970210477723
Validation loss: 2.4711024789638922

Epoch: 5| Step: 7
Training loss: 2.6679992227224334
Validation loss: 2.474777922476672

Epoch: 5| Step: 8
Training loss: 2.229629385390655
Validation loss: 2.471747272983684

Epoch: 5| Step: 9
Training loss: 2.95560799012802
Validation loss: 2.4808871059102175

Epoch: 5| Step: 10
Training loss: 2.796666824862173
Validation loss: 2.4766523042074557

Epoch: 5| Step: 11
Training loss: 2.6349032559088896
Validation loss: 2.4702893741240204

Epoch: 118| Step: 0
Training loss: 1.9893888075502488
Validation loss: 2.4823285157070827

Epoch: 5| Step: 1
Training loss: 1.9091196816617026
Validation loss: 2.482951764233553

Epoch: 5| Step: 2
Training loss: 2.341148865853037
Validation loss: 2.4797282678096866

Epoch: 5| Step: 3
Training loss: 2.608057294707696
Validation loss: 2.4861725555998535

Epoch: 5| Step: 4
Training loss: 2.6670744306021126
Validation loss: 2.4834463515155334

Epoch: 5| Step: 5
Training loss: 2.7617564758572937
Validation loss: 2.4807154455185234

Epoch: 5| Step: 6
Training loss: 2.665629443470157
Validation loss: 2.485207444205024

Epoch: 5| Step: 7
Training loss: 2.696185338319782
Validation loss: 2.4793727225467963

Epoch: 5| Step: 8
Training loss: 2.5768016771260736
Validation loss: 2.4795580856823305

Epoch: 5| Step: 9
Training loss: 2.6337113925908606
Validation loss: 2.483893669733103

Epoch: 5| Step: 10
Training loss: 2.6590489619102424
Validation loss: 2.484394201368428

Epoch: 5| Step: 11
Training loss: 3.974897534471285
Validation loss: 2.4821312526896855

Epoch: 119| Step: 0
Training loss: 2.6940452360788796
Validation loss: 2.480125916185228

Epoch: 5| Step: 1
Training loss: 2.0520838497051486
Validation loss: 2.483501784693993

Epoch: 5| Step: 2
Training loss: 2.4635317737039295
Validation loss: 2.4758388232118165

Epoch: 5| Step: 3
Training loss: 2.2953217113458058
Validation loss: 2.4649769323351647

Epoch: 5| Step: 4
Training loss: 2.650183538162915
Validation loss: 2.471093827668827

Epoch: 5| Step: 5
Training loss: 2.0095963328009145
Validation loss: 2.474240727954862

Epoch: 5| Step: 6
Training loss: 2.9998332613067165
Validation loss: 2.4677709054374106

Epoch: 5| Step: 7
Training loss: 2.5069073621191738
Validation loss: 2.473359918331525

Epoch: 5| Step: 8
Training loss: 2.5056026621598564
Validation loss: 2.473635539361972

Epoch: 5| Step: 9
Training loss: 2.66615969090488
Validation loss: 2.469693494529871

Epoch: 5| Step: 10
Training loss: 2.991126288132552
Validation loss: 2.4665257739626565

Epoch: 5| Step: 11
Training loss: 2.6245992445434423
Validation loss: 2.4711499520044398

Epoch: 120| Step: 0
Training loss: 2.7125744013976236
Validation loss: 2.4662339672438187

Epoch: 5| Step: 1
Training loss: 2.5986625385842075
Validation loss: 2.462168205164003

Epoch: 5| Step: 2
Training loss: 3.137359135721727
Validation loss: 2.464181245737699

Epoch: 5| Step: 3
Training loss: 2.6319316896136806
Validation loss: 2.4642343750239943

Epoch: 5| Step: 4
Training loss: 2.4475215403589896
Validation loss: 2.4745440596160457

Epoch: 5| Step: 5
Training loss: 2.202612201720819
Validation loss: 2.4752231429877374

Epoch: 5| Step: 6
Training loss: 2.194305840741254
Validation loss: 2.472387049093982

Epoch: 5| Step: 7
Training loss: 2.7651008066078036
Validation loss: 2.4764249424482943

Epoch: 5| Step: 8
Training loss: 2.274268139506319
Validation loss: 2.471892196138917

Epoch: 5| Step: 9
Training loss: 2.8931294906756064
Validation loss: 2.4774166583662236

Epoch: 5| Step: 10
Training loss: 2.1084934229125145
Validation loss: 2.4764152908296557

Epoch: 5| Step: 11
Training loss: 2.0994163247004978
Validation loss: 2.483777684155197

Epoch: 121| Step: 0
Training loss: 2.347221346923344
Validation loss: 2.4710710776735487

Epoch: 5| Step: 1
Training loss: 2.2598735549460467
Validation loss: 2.4737180867577413

Epoch: 5| Step: 2
Training loss: 2.583511736052272
Validation loss: 2.4753019973871755

Epoch: 5| Step: 3
Training loss: 2.6957667755762516
Validation loss: 2.4778403345960505

Epoch: 5| Step: 4
Training loss: 2.1369915496916145
Validation loss: 2.4747730252198368

Epoch: 5| Step: 5
Training loss: 2.627777991139155
Validation loss: 2.4749574444063205

Epoch: 5| Step: 6
Training loss: 2.309101597522964
Validation loss: 2.4712092387584788

Epoch: 5| Step: 7
Training loss: 2.6227868150762172
Validation loss: 2.4695347854410343

Epoch: 5| Step: 8
Training loss: 2.732029284726604
Validation loss: 2.47784514159799

Epoch: 5| Step: 9
Training loss: 2.6134194649723264
Validation loss: 2.4765075573206756

Epoch: 5| Step: 10
Training loss: 2.9900535364365695
Validation loss: 2.470687283149764

Epoch: 5| Step: 11
Training loss: 2.694868322067873
Validation loss: 2.473183072070078

Epoch: 122| Step: 0
Training loss: 2.5789098296419417
Validation loss: 2.4712808991408934

Epoch: 5| Step: 1
Training loss: 2.920402931213371
Validation loss: 2.4646810164539033

Epoch: 5| Step: 2
Training loss: 2.5451558869889888
Validation loss: 2.4625122965587964

Epoch: 5| Step: 3
Training loss: 1.9930177043314097
Validation loss: 2.460935344392347

Epoch: 5| Step: 4
Training loss: 2.5740053496523783
Validation loss: 2.4716789881638555

Epoch: 5| Step: 5
Training loss: 2.972919307102527
Validation loss: 2.463571464944408

Epoch: 5| Step: 6
Training loss: 2.110158139128759
Validation loss: 2.466592223960039

Epoch: 5| Step: 7
Training loss: 2.2742147788324676
Validation loss: 2.4665279891256637

Epoch: 5| Step: 8
Training loss: 2.7135948327262733
Validation loss: 2.4720935191241415

Epoch: 5| Step: 9
Training loss: 2.2968129259921004
Validation loss: 2.4764124908102265

Epoch: 5| Step: 10
Training loss: 2.8228623125725045
Validation loss: 2.468447220016874

Epoch: 5| Step: 11
Training loss: 2.743718776655566
Validation loss: 2.471720734969695

Epoch: 123| Step: 0
Training loss: 2.8897177432335988
Validation loss: 2.4729314553499644

Epoch: 5| Step: 1
Training loss: 2.335356368943421
Validation loss: 2.4642352457880965

Epoch: 5| Step: 2
Training loss: 2.83554452742834
Validation loss: 2.4743489502501284

Epoch: 5| Step: 3
Training loss: 2.8110627634701535
Validation loss: 2.500808430136379

Epoch: 5| Step: 4
Training loss: 2.9543018720827434
Validation loss: 2.4874206763547915

Epoch: 5| Step: 5
Training loss: 2.1956945338044656
Validation loss: 2.482446461817659

Epoch: 5| Step: 6
Training loss: 2.548981246148938
Validation loss: 2.4671040935402044

Epoch: 5| Step: 7
Training loss: 2.320914655957965
Validation loss: 2.4762132801566503

Epoch: 5| Step: 8
Training loss: 2.4330294767727274
Validation loss: 2.4742652073650073

Epoch: 5| Step: 9
Training loss: 2.4651333356160925
Validation loss: 2.48094414187925

Epoch: 5| Step: 10
Training loss: 2.1713145239537206
Validation loss: 2.4747491931029564

Epoch: 5| Step: 11
Training loss: 3.277523576897524
Validation loss: 2.4848839460440533

Epoch: 124| Step: 0
Training loss: 2.1409654555404734
Validation loss: 2.4777360456159236

Epoch: 5| Step: 1
Training loss: 2.232733490322155
Validation loss: 2.4760859338774983

Epoch: 5| Step: 2
Training loss: 2.421935443739188
Validation loss: 2.4785136450039906

Epoch: 5| Step: 3
Training loss: 2.4193776698727216
Validation loss: 2.4778353752356526

Epoch: 5| Step: 4
Training loss: 2.744761940338517
Validation loss: 2.479446280496297

Epoch: 5| Step: 5
Training loss: 2.380344200569236
Validation loss: 2.4725590305590894

Epoch: 5| Step: 6
Training loss: 2.4327155866289107
Validation loss: 2.4770245968330613

Epoch: 5| Step: 7
Training loss: 2.8306731657485753
Validation loss: 2.4766517607029415

Epoch: 5| Step: 8
Training loss: 3.2343977038190164
Validation loss: 2.4808099386897324

Epoch: 5| Step: 9
Training loss: 2.70969566902704
Validation loss: 2.479593285683956

Epoch: 5| Step: 10
Training loss: 2.517832480544615
Validation loss: 2.476030982629313

Epoch: 5| Step: 11
Training loss: 3.5429239322809627
Validation loss: 2.473304293996278

Epoch: 125| Step: 0
Training loss: 2.6481419401187445
Validation loss: 2.472301061911403

Epoch: 5| Step: 1
Training loss: 2.7765986949512844
Validation loss: 2.47390322305968

Epoch: 5| Step: 2
Training loss: 2.6505752982652053
Validation loss: 2.4689925432773703

Epoch: 5| Step: 3
Training loss: 2.8175589098183256
Validation loss: 2.4682355819611264

Epoch: 5| Step: 4
Training loss: 2.363887589281589
Validation loss: 2.466714357761342

Epoch: 5| Step: 5
Training loss: 2.382423244012457
Validation loss: 2.4670181557742743

Epoch: 5| Step: 6
Training loss: 2.4391139629245084
Validation loss: 2.470374920623618

Epoch: 5| Step: 7
Training loss: 2.7877443762431646
Validation loss: 2.469149142806196

Epoch: 5| Step: 8
Training loss: 2.429020928209087
Validation loss: 2.4712946609606106

Epoch: 5| Step: 9
Training loss: 2.33610426903911
Validation loss: 2.4723303019071423

Epoch: 5| Step: 10
Training loss: 2.6154496985316533
Validation loss: 2.4750378284710255

Epoch: 5| Step: 11
Training loss: 2.8329590007859764
Validation loss: 2.4771327817220072

Epoch: 126| Step: 0
Training loss: 3.231586525841297
Validation loss: 2.479865602067679

Epoch: 5| Step: 1
Training loss: 3.064580405359449
Validation loss: 2.482717845049501

Epoch: 5| Step: 2
Training loss: 2.4921777420092077
Validation loss: 2.4787241730504332

Epoch: 5| Step: 3
Training loss: 2.4109647065739503
Validation loss: 2.477423160354518

Epoch: 5| Step: 4
Training loss: 2.339366017068814
Validation loss: 2.475530876836475

Epoch: 5| Step: 5
Training loss: 2.29871548981974
Validation loss: 2.474243588649618

Epoch: 5| Step: 6
Training loss: 2.628074208243912
Validation loss: 2.4793103774809797

Epoch: 5| Step: 7
Training loss: 1.924001432251744
Validation loss: 2.4687145789941214

Epoch: 5| Step: 8
Training loss: 2.5527577242261343
Validation loss: 2.4718023375494584

Epoch: 5| Step: 9
Training loss: 2.295021399105262
Validation loss: 2.4718503236242224

Epoch: 5| Step: 10
Training loss: 2.42408130193404
Validation loss: 2.466607975315231

Epoch: 5| Step: 11
Training loss: 2.8780189917112065
Validation loss: 2.4668738845720872

Epoch: 127| Step: 0
Training loss: 2.3978499398005018
Validation loss: 2.466674982896739

Epoch: 5| Step: 1
Training loss: 3.2238406322647544
Validation loss: 2.4650954749231317

Epoch: 5| Step: 2
Training loss: 2.064570803432635
Validation loss: 2.462324730368999

Epoch: 5| Step: 3
Training loss: 2.154141155020528
Validation loss: 2.472920082805516

Epoch: 5| Step: 4
Training loss: 2.856926208184032
Validation loss: 2.4643723631072443

Epoch: 5| Step: 5
Training loss: 2.4725410229680738
Validation loss: 2.4718399267204103

Epoch: 5| Step: 6
Training loss: 2.799086224088206
Validation loss: 2.4609325913476177

Epoch: 5| Step: 7
Training loss: 2.337780687747751
Validation loss: 2.4664180139489247

Epoch: 5| Step: 8
Training loss: 2.7220840181141295
Validation loss: 2.4652808598303597

Epoch: 5| Step: 9
Training loss: 2.075670441931546
Validation loss: 2.473963435652976

Epoch: 5| Step: 10
Training loss: 2.8054406475124525
Validation loss: 2.4707267910875568

Epoch: 5| Step: 11
Training loss: 1.8275340502654829
Validation loss: 2.476412647258387

Epoch: 128| Step: 0
Training loss: 3.1067991082225674
Validation loss: 2.467641050216692

Epoch: 5| Step: 1
Training loss: 2.410860178332413
Validation loss: 2.4716743500329237

Epoch: 5| Step: 2
Training loss: 2.412006873296557
Validation loss: 2.4712684316338507

Epoch: 5| Step: 3
Training loss: 2.5448969549216396
Validation loss: 2.4768971358490957

Epoch: 5| Step: 4
Training loss: 2.659717854185532
Validation loss: 2.474919946737355

Epoch: 5| Step: 5
Training loss: 2.411841892747697
Validation loss: 2.480817130547062

Epoch: 5| Step: 6
Training loss: 2.1425893638962865
Validation loss: 2.478662621257628

Epoch: 5| Step: 7
Training loss: 2.4576908069319923
Validation loss: 2.480674979380077

Epoch: 5| Step: 8
Training loss: 2.5252527846904584
Validation loss: 2.4862994851387943

Epoch: 5| Step: 9
Training loss: 1.9380426569831364
Validation loss: 2.483680492069113

Epoch: 5| Step: 10
Training loss: 2.9000640993597897
Validation loss: 2.4753934826803543

Epoch: 5| Step: 11
Training loss: 3.8427050651080714
Validation loss: 2.4824417037432056

Epoch: 129| Step: 0
Training loss: 2.555592694450346
Validation loss: 2.4825988274271187

Epoch: 5| Step: 1
Training loss: 2.7716688077287173
Validation loss: 2.4723774620730627

Epoch: 5| Step: 2
Training loss: 2.2975842684794308
Validation loss: 2.473741732033047

Epoch: 5| Step: 3
Training loss: 2.2198167842146246
Validation loss: 2.4826529150494734

Epoch: 5| Step: 4
Training loss: 2.464367223461786
Validation loss: 2.475807712710834

Epoch: 5| Step: 5
Training loss: 2.2431063480616786
Validation loss: 2.4768103867589133

Epoch: 5| Step: 6
Training loss: 2.260247840963859
Validation loss: 2.4799369582372357

Epoch: 5| Step: 7
Training loss: 2.6523753910115646
Validation loss: 2.4729806286500087

Epoch: 5| Step: 8
Training loss: 2.675618454930285
Validation loss: 2.4908084820945247

Epoch: 5| Step: 9
Training loss: 2.924620129298128
Validation loss: 2.484923915881588

Epoch: 5| Step: 10
Training loss: 2.9378880995181773
Validation loss: 2.4798531316522414

Epoch: 5| Step: 11
Training loss: 2.9599271071969717
Validation loss: 2.48328398694437

Epoch: 130| Step: 0
Training loss: 2.658119710472543
Validation loss: 2.4813083179003974

Epoch: 5| Step: 1
Training loss: 2.7390097439478756
Validation loss: 2.475711110578964

Epoch: 5| Step: 2
Training loss: 2.7871346957066354
Validation loss: 2.469684661312693

Epoch: 5| Step: 3
Training loss: 2.4924313416968
Validation loss: 2.4721747598009176

Epoch: 5| Step: 4
Training loss: 2.5274777973833658
Validation loss: 2.4750764762738307

Epoch: 5| Step: 5
Training loss: 2.6162282523806457
Validation loss: 2.47013656292103

Epoch: 5| Step: 6
Training loss: 2.7284983236410127
Validation loss: 2.4665622957053044

Epoch: 5| Step: 7
Training loss: 2.6802193250157695
Validation loss: 2.478898832668938

Epoch: 5| Step: 8
Training loss: 1.6149132996425997
Validation loss: 2.4711394958732145

Epoch: 5| Step: 9
Training loss: 2.4959275454495446
Validation loss: 2.46861791257359

Epoch: 5| Step: 10
Training loss: 2.511932316506064
Validation loss: 2.4713996920531085

Epoch: 5| Step: 11
Training loss: 1.8145146190131136
Validation loss: 2.4755618543788964

Epoch: 131| Step: 0
Training loss: 2.3611270891534053
Validation loss: 2.4698767565470927

Epoch: 5| Step: 1
Training loss: 2.6550855889327005
Validation loss: 2.4726528712084335

Epoch: 5| Step: 2
Training loss: 2.283572021130426
Validation loss: 2.477592226108863

Epoch: 5| Step: 3
Training loss: 2.807730211719598
Validation loss: 2.4824944902469666

Epoch: 5| Step: 4
Training loss: 2.1313904433527378
Validation loss: 2.483091110592249

Epoch: 5| Step: 5
Training loss: 2.567965749304225
Validation loss: 2.471763787257473

Epoch: 5| Step: 6
Training loss: 2.9005277350799066
Validation loss: 2.4647191858026316

Epoch: 5| Step: 7
Training loss: 2.9686317821857133
Validation loss: 2.473577467395508

Epoch: 5| Step: 8
Training loss: 2.114562487068838
Validation loss: 2.4703780451682174

Epoch: 5| Step: 9
Training loss: 2.7685953342474763
Validation loss: 2.4595248896071054

Epoch: 5| Step: 10
Training loss: 2.4272592068803145
Validation loss: 2.4726178295330503

Epoch: 5| Step: 11
Training loss: 2.326268627291001
Validation loss: 2.4702946663264456

Epoch: 132| Step: 0
Training loss: 2.203003792100189
Validation loss: 2.469450114968017

Epoch: 5| Step: 1
Training loss: 2.1402785863207128
Validation loss: 2.464505711996773

Epoch: 5| Step: 2
Training loss: 3.070104693886008
Validation loss: 2.462739036789686

Epoch: 5| Step: 3
Training loss: 2.9491836646816187
Validation loss: 2.4556254098331496

Epoch: 5| Step: 4
Training loss: 2.1112197156487857
Validation loss: 2.465448747595612

Epoch: 5| Step: 5
Training loss: 2.534554291014805
Validation loss: 2.4680163544832223

Epoch: 5| Step: 6
Training loss: 2.2857590100476823
Validation loss: 2.461419767727954

Epoch: 5| Step: 7
Training loss: 2.5758592301639087
Validation loss: 2.463726110724799

Epoch: 5| Step: 8
Training loss: 2.4546979975582146
Validation loss: 2.4638733926121144

Epoch: 5| Step: 9
Training loss: 2.8046415107378095
Validation loss: 2.4626128614610026

Epoch: 5| Step: 10
Training loss: 2.517909179891839
Validation loss: 2.4671794748689133

Epoch: 5| Step: 11
Training loss: 3.6409075058459655
Validation loss: 2.469658024707866

Epoch: 133| Step: 0
Training loss: 2.242848900197566
Validation loss: 2.484727630540641

Epoch: 5| Step: 1
Training loss: 2.6508043903720293
Validation loss: 2.482742532969

Epoch: 5| Step: 2
Training loss: 2.5574942286511106
Validation loss: 2.4829021142399874

Epoch: 5| Step: 3
Training loss: 2.8095149835966704
Validation loss: 2.488416136115348

Epoch: 5| Step: 4
Training loss: 2.2818057284763147
Validation loss: 2.4899216559033577

Epoch: 5| Step: 5
Training loss: 2.6152506935345525
Validation loss: 2.491255694617465

Epoch: 5| Step: 6
Training loss: 2.5024870899031297
Validation loss: 2.483442657393025

Epoch: 5| Step: 7
Training loss: 2.7260384916861127
Validation loss: 2.48490984775544

Epoch: 5| Step: 8
Training loss: 2.6748648529138364
Validation loss: 2.481634303710931

Epoch: 5| Step: 9
Training loss: 2.2904688970606215
Validation loss: 2.480692102984441

Epoch: 5| Step: 10
Training loss: 2.473752229370531
Validation loss: 2.4832067921953307

Epoch: 5| Step: 11
Training loss: 3.282619953273512
Validation loss: 2.4827728183488906

Epoch: 134| Step: 0
Training loss: 2.4682925802503135
Validation loss: 2.4817577427094863

Epoch: 5| Step: 1
Training loss: 2.7209644287991948
Validation loss: 2.484501957398522

Epoch: 5| Step: 2
Training loss: 2.60980531719133
Validation loss: 2.471240602114271

Epoch: 5| Step: 3
Training loss: 2.5623479658476316
Validation loss: 2.4818463122220384

Epoch: 5| Step: 4
Training loss: 2.737310087679743
Validation loss: 2.4787281447277647

Epoch: 5| Step: 5
Training loss: 2.856674837199411
Validation loss: 2.475102540823674

Epoch: 5| Step: 6
Training loss: 2.1339709590662626
Validation loss: 2.485139910985901

Epoch: 5| Step: 7
Training loss: 2.2829967761223746
Validation loss: 2.4775866227126575

Epoch: 5| Step: 8
Training loss: 2.342828391393829
Validation loss: 2.4852189523908823

Epoch: 5| Step: 9
Training loss: 2.0102185034721125
Validation loss: 2.4789543875737063

Epoch: 5| Step: 10
Training loss: 2.837648490347765
Validation loss: 2.47681551662689

Epoch: 5| Step: 11
Training loss: 3.051948119066274
Validation loss: 2.4799990632327167

Epoch: 135| Step: 0
Training loss: 3.073776038743314
Validation loss: 2.4799394498375635

Epoch: 5| Step: 1
Training loss: 2.564437691844745
Validation loss: 2.478183785246795

Epoch: 5| Step: 2
Training loss: 2.3388216209353043
Validation loss: 2.4739036406779116

Epoch: 5| Step: 3
Training loss: 2.5858020574129124
Validation loss: 2.4804412840276235

Epoch: 5| Step: 4
Training loss: 2.452826220546552
Validation loss: 2.482297680637141

Epoch: 5| Step: 5
Training loss: 2.2434807746051555
Validation loss: 2.4705042300375637

Epoch: 5| Step: 6
Training loss: 2.3327937069830242
Validation loss: 2.4777530892980604

Epoch: 5| Step: 7
Training loss: 2.283662017313435
Validation loss: 2.4735427199487066

Epoch: 5| Step: 8
Training loss: 2.840684013467122
Validation loss: 2.4826867387216636

Epoch: 5| Step: 9
Training loss: 2.5054873326334772
Validation loss: 2.467562772280279

Epoch: 5| Step: 10
Training loss: 2.664604154321023
Validation loss: 2.476235517542604

Epoch: 5| Step: 11
Training loss: 2.3622043646664483
Validation loss: 2.483668028808795

Epoch: 136| Step: 0
Training loss: 2.278911384731049
Validation loss: 2.477254881077366

Epoch: 5| Step: 1
Training loss: 2.716942197092855
Validation loss: 2.4815124798876664

Epoch: 5| Step: 2
Training loss: 2.8870575206643374
Validation loss: 2.474381769316695

Epoch: 5| Step: 3
Training loss: 2.7501199869509243
Validation loss: 2.467310304587165

Epoch: 5| Step: 4
Training loss: 2.8328127289239085
Validation loss: 2.4735800015464218

Epoch: 5| Step: 5
Training loss: 2.0040540138777576
Validation loss: 2.4721680069245986

Epoch: 5| Step: 6
Training loss: 2.4264469431168756
Validation loss: 2.4707783603396005

Epoch: 5| Step: 7
Training loss: 2.2389878893478277
Validation loss: 2.479553338090943

Epoch: 5| Step: 8
Training loss: 2.311425242818207
Validation loss: 2.4756990927292493

Epoch: 5| Step: 9
Training loss: 2.8021202983096085
Validation loss: 2.4779829209829303

Epoch: 5| Step: 10
Training loss: 2.4220538657803328
Validation loss: 2.4774312361891755

Epoch: 5| Step: 11
Training loss: 3.1143848947103345
Validation loss: 2.4730284633181077

Epoch: 137| Step: 0
Training loss: 2.8218310381230913
Validation loss: 2.4783918802259173

Epoch: 5| Step: 1
Training loss: 2.4512063073403305
Validation loss: 2.486391197057861

Epoch: 5| Step: 2
Training loss: 2.116207219619196
Validation loss: 2.482411182219464

Epoch: 5| Step: 3
Training loss: 2.8573127355481382
Validation loss: 2.4785128433857233

Epoch: 5| Step: 4
Training loss: 2.8567431068060163
Validation loss: 2.4833989495264253

Epoch: 5| Step: 5
Training loss: 2.0749124347640495
Validation loss: 2.4868289655828546

Epoch: 5| Step: 6
Training loss: 2.826393904331349
Validation loss: 2.47968099104907

Epoch: 5| Step: 7
Training loss: 2.3937543943678556
Validation loss: 2.485230680372634

Epoch: 5| Step: 8
Training loss: 2.1897854446450005
Validation loss: 2.4852147552469512

Epoch: 5| Step: 9
Training loss: 2.5146819058755794
Validation loss: 2.4840885732989793

Epoch: 5| Step: 10
Training loss: 2.628750528652049
Validation loss: 2.489694298914114

Epoch: 5| Step: 11
Training loss: 2.526514214954893
Validation loss: 2.485921098745714

Epoch: 138| Step: 0
Training loss: 2.269850375247933
Validation loss: 2.481815234998257

Epoch: 5| Step: 1
Training loss: 2.593479923756727
Validation loss: 2.482077926150427

Epoch: 5| Step: 2
Training loss: 2.844977145513843
Validation loss: 2.4757662013406967

Epoch: 5| Step: 3
Training loss: 2.188033665546241
Validation loss: 2.480145823366399

Epoch: 5| Step: 4
Training loss: 1.9197537881222915
Validation loss: 2.472518105487213

Epoch: 5| Step: 5
Training loss: 2.702581450216839
Validation loss: 2.4731367707954504

Epoch: 5| Step: 6
Training loss: 2.7502984838623776
Validation loss: 2.4842344360253024

Epoch: 5| Step: 7
Training loss: 2.7109573759290284
Validation loss: 2.483707002287749

Epoch: 5| Step: 8
Training loss: 2.584436632226384
Validation loss: 2.4692712426696537

Epoch: 5| Step: 9
Training loss: 2.6353804293064846
Validation loss: 2.480905421310261

Epoch: 5| Step: 10
Training loss: 2.5655865572280727
Validation loss: 2.4629759505252022

Epoch: 5| Step: 11
Training loss: 1.7690458663592403
Validation loss: 2.47233040637813

Epoch: 139| Step: 0
Training loss: 2.6368631507044906
Validation loss: 2.478105716061054

Epoch: 5| Step: 1
Training loss: 2.52509284273686
Validation loss: 2.4786373596516817

Epoch: 5| Step: 2
Training loss: 2.375771547778765
Validation loss: 2.4621586570304337

Epoch: 5| Step: 3
Training loss: 2.4584939117573485
Validation loss: 2.459569029806574

Epoch: 5| Step: 4
Training loss: 2.249272758786806
Validation loss: 2.46824981555779

Epoch: 5| Step: 5
Training loss: 2.1749110236548597
Validation loss: 2.4676981709309813

Epoch: 5| Step: 6
Training loss: 2.5937215964359233
Validation loss: 2.4710818858569903

Epoch: 5| Step: 7
Training loss: 2.5559805767712294
Validation loss: 2.479779593783296

Epoch: 5| Step: 8
Training loss: 2.7550630777549263
Validation loss: 2.480439133354655

Epoch: 5| Step: 9
Training loss: 2.5462783395410193
Validation loss: 2.4737301905325415

Epoch: 5| Step: 10
Training loss: 2.9200838688341455
Validation loss: 2.4718888163029757

Epoch: 5| Step: 11
Training loss: 2.3582837947679325
Validation loss: 2.4785190879851693

Epoch: 140| Step: 0
Training loss: 2.5341671746740695
Validation loss: 2.481488764538945

Epoch: 5| Step: 1
Training loss: 3.0597967556543826
Validation loss: 2.483155397039799

Epoch: 5| Step: 2
Training loss: 2.0909703720671877
Validation loss: 2.475741409746791

Epoch: 5| Step: 3
Training loss: 2.362415199170693
Validation loss: 2.4881886375674864

Epoch: 5| Step: 4
Training loss: 2.8201101130096875
Validation loss: 2.4784538616063143

Epoch: 5| Step: 5
Training loss: 2.231386440176612
Validation loss: 2.489738899754726

Epoch: 5| Step: 6
Training loss: 1.6664802288046583
Validation loss: 2.485599096296089

Epoch: 5| Step: 7
Training loss: 2.9139273359026814
Validation loss: 2.480604841849291

Epoch: 5| Step: 8
Training loss: 3.0593603739715185
Validation loss: 2.483293325840117

Epoch: 5| Step: 9
Training loss: 2.269011813943772
Validation loss: 2.4834813724039657

Epoch: 5| Step: 10
Training loss: 2.401489304349751
Validation loss: 2.4885287518576664

Epoch: 5| Step: 11
Training loss: 2.5847694547987157
Validation loss: 2.474630514815835

Epoch: 141| Step: 0
Training loss: 2.4722798861042405
Validation loss: 2.478863562693168

Epoch: 5| Step: 1
Training loss: 2.3175083259836238
Validation loss: 2.4757088835694807

Epoch: 5| Step: 2
Training loss: 2.507825999951495
Validation loss: 2.4731798747513105

Epoch: 5| Step: 3
Training loss: 2.269021691061872
Validation loss: 2.4718145913685103

Epoch: 5| Step: 4
Training loss: 2.0920586658151246
Validation loss: 2.470528179503644

Epoch: 5| Step: 5
Training loss: 2.5338390907918567
Validation loss: 2.478723457666908

Epoch: 5| Step: 6
Training loss: 2.9453497360668432
Validation loss: 2.479740434388881

Epoch: 5| Step: 7
Training loss: 2.679608669178035
Validation loss: 2.4808267049751067

Epoch: 5| Step: 8
Training loss: 2.496478461525816
Validation loss: 2.482117012646697

Epoch: 5| Step: 9
Training loss: 2.5874333506675544
Validation loss: 2.4742138312398994

Epoch: 5| Step: 10
Training loss: 2.9241806969496746
Validation loss: 2.4802554461861543

Epoch: 5| Step: 11
Training loss: 1.858826692662633
Validation loss: 2.479461589602902

Epoch: 142| Step: 0
Training loss: 2.6017313034692227
Validation loss: 2.4910413244934775

Epoch: 5| Step: 1
Training loss: 2.4110252260575864
Validation loss: 2.4816194323337313

Epoch: 5| Step: 2
Training loss: 2.6859789247630443
Validation loss: 2.4810211167357465

Epoch: 5| Step: 3
Training loss: 2.5185949197360933
Validation loss: 2.478359913926089

Epoch: 5| Step: 4
Training loss: 2.614593222144729
Validation loss: 2.475025353799549

Epoch: 5| Step: 5
Training loss: 1.9528616155417098
Validation loss: 2.4731628276704236

Epoch: 5| Step: 6
Training loss: 2.2691703680173805
Validation loss: 2.4706194716453704

Epoch: 5| Step: 7
Training loss: 2.7934756799297773
Validation loss: 2.4733904270392695

Epoch: 5| Step: 8
Training loss: 2.224428995135748
Validation loss: 2.470847986771831

Epoch: 5| Step: 9
Training loss: 2.830868059884308
Validation loss: 2.4748785429029603

Epoch: 5| Step: 10
Training loss: 2.911165899468128
Validation loss: 2.467358361919759

Epoch: 5| Step: 11
Training loss: 1.9784371754946253
Validation loss: 2.4638850206033913

Epoch: 143| Step: 0
Training loss: 2.9468193752827796
Validation loss: 2.4564793567816303

Epoch: 5| Step: 1
Training loss: 2.5472252727764375
Validation loss: 2.4652962730203454

Epoch: 5| Step: 2
Training loss: 2.7681443975082916
Validation loss: 2.4648244890285667

Epoch: 5| Step: 3
Training loss: 1.6409736626119593
Validation loss: 2.4635145630800577

Epoch: 5| Step: 4
Training loss: 2.5701863452133376
Validation loss: 2.4664439363916255

Epoch: 5| Step: 5
Training loss: 2.769298204697231
Validation loss: 2.4690029602184964

Epoch: 5| Step: 6
Training loss: 2.602937077474362
Validation loss: 2.4689272382346377

Epoch: 5| Step: 7
Training loss: 2.4037822603390784
Validation loss: 2.467079990034432

Epoch: 5| Step: 8
Training loss: 2.501436774330729
Validation loss: 2.4786277406954924

Epoch: 5| Step: 9
Training loss: 2.260128008668993
Validation loss: 2.4784550500335842

Epoch: 5| Step: 10
Training loss: 2.6420088533344117
Validation loss: 2.486173746331087

Epoch: 5| Step: 11
Training loss: 2.786020880375133
Validation loss: 2.4832178535962752

Epoch: 144| Step: 0
Training loss: 2.2041106487960693
Validation loss: 2.477209105051139

Epoch: 5| Step: 1
Training loss: 2.139688885792656
Validation loss: 2.483041613414321

Epoch: 5| Step: 2
Training loss: 2.7080423247665557
Validation loss: 2.4847894438851483

Epoch: 5| Step: 3
Training loss: 2.1633486896003173
Validation loss: 2.4743488177605073

Epoch: 5| Step: 4
Training loss: 2.435316428239225
Validation loss: 2.47822144197631

Epoch: 5| Step: 5
Training loss: 2.809776513386035
Validation loss: 2.4742382506909064

Epoch: 5| Step: 6
Training loss: 2.8100145165825285
Validation loss: 2.477886433721365

Epoch: 5| Step: 7
Training loss: 2.6505386884651
Validation loss: 2.4719139097666245

Epoch: 5| Step: 8
Training loss: 2.7861622495597027
Validation loss: 2.4692414997651393

Epoch: 5| Step: 9
Training loss: 2.674660730683702
Validation loss: 2.472507542642699

Epoch: 5| Step: 10
Training loss: 2.082281330255371
Validation loss: 2.473761140426576

Epoch: 5| Step: 11
Training loss: 3.4964131640923224
Validation loss: 2.4750962314136284

Epoch: 145| Step: 0
Training loss: 2.379820799772954
Validation loss: 2.4782214860705056

Epoch: 5| Step: 1
Training loss: 2.3077782547669194
Validation loss: 2.4671112407924225

Epoch: 5| Step: 2
Training loss: 2.783029993929824
Validation loss: 2.470051909054415

Epoch: 5| Step: 3
Training loss: 2.7536663410848603
Validation loss: 2.4754210126866827

Epoch: 5| Step: 4
Training loss: 2.5126020382330663
Validation loss: 2.47069477788548

Epoch: 5| Step: 5
Training loss: 2.5297129167360226
Validation loss: 2.473683473811462

Epoch: 5| Step: 6
Training loss: 2.578053976294426
Validation loss: 2.475251489603452

Epoch: 5| Step: 7
Training loss: 2.5419162148294525
Validation loss: 2.480279974374724

Epoch: 5| Step: 8
Training loss: 2.6244799689213267
Validation loss: 2.4781209452573068

Epoch: 5| Step: 9
Training loss: 2.3932546476571845
Validation loss: 2.477758774508698

Epoch: 5| Step: 10
Training loss: 2.357158402808644
Validation loss: 2.483075959887721

Epoch: 5| Step: 11
Training loss: 2.4443230622913004
Validation loss: 2.478447787190913

Epoch: 146| Step: 0
Training loss: 2.477643279581569
Validation loss: 2.4732287137465034

Epoch: 5| Step: 1
Training loss: 2.1275658543723535
Validation loss: 2.4670543058107564

Epoch: 5| Step: 2
Training loss: 2.1924215266626375
Validation loss: 2.4716284505556723

Epoch: 5| Step: 3
Training loss: 2.229652589499279
Validation loss: 2.4718153549695234

Epoch: 5| Step: 4
Training loss: 2.9012805742183767
Validation loss: 2.4714285789410866

Epoch: 5| Step: 5
Training loss: 2.8146961538733004
Validation loss: 2.4701693152943323

Epoch: 5| Step: 6
Training loss: 2.8337730365720426
Validation loss: 2.470195286845487

Epoch: 5| Step: 7
Training loss: 2.319710598850782
Validation loss: 2.4683429124849336

Epoch: 5| Step: 8
Training loss: 2.4721603981126674
Validation loss: 2.471480855049451

Epoch: 5| Step: 9
Training loss: 2.536584014180988
Validation loss: 2.467520037211877

Epoch: 5| Step: 10
Training loss: 2.580273467068163
Validation loss: 2.467254463335554

Epoch: 5| Step: 11
Training loss: 2.954354005226151
Validation loss: 2.4755382284950698

Epoch: 147| Step: 0
Training loss: 1.638473335032843
Validation loss: 2.4741439441855104

Epoch: 5| Step: 1
Training loss: 2.502600938131345
Validation loss: 2.4786542769003224

Epoch: 5| Step: 2
Training loss: 2.8666840404900724
Validation loss: 2.4779410110743694

Epoch: 5| Step: 3
Training loss: 2.721953335498668
Validation loss: 2.485875030730113

Epoch: 5| Step: 4
Training loss: 2.8383486247551435
Validation loss: 2.4847195024572017

Epoch: 5| Step: 5
Training loss: 2.3684547985193625
Validation loss: 2.478366888426671

Epoch: 5| Step: 6
Training loss: 1.958653917518258
Validation loss: 2.4774322787478384

Epoch: 5| Step: 7
Training loss: 2.744138366046668
Validation loss: 2.483863054066172

Epoch: 5| Step: 8
Training loss: 2.358775687995121
Validation loss: 2.4790403323214467

Epoch: 5| Step: 9
Training loss: 2.466894104069106
Validation loss: 2.482534754658054

Epoch: 5| Step: 10
Training loss: 2.928730312383812
Validation loss: 2.470839195877076

Epoch: 5| Step: 11
Training loss: 3.0380195455920647
Validation loss: 2.4740904334420617

Epoch: 148| Step: 0
Training loss: 2.5286614639841525
Validation loss: 2.471129272861695

Epoch: 5| Step: 1
Training loss: 2.6834447561156827
Validation loss: 2.4754297291204974

Epoch: 5| Step: 2
Training loss: 2.197045453378843
Validation loss: 2.474477293227529

Epoch: 5| Step: 3
Training loss: 2.358291680425341
Validation loss: 2.475602719101466

Epoch: 5| Step: 4
Training loss: 2.3048071878680636
Validation loss: 2.480012217883808

Epoch: 5| Step: 5
Training loss: 2.58797188109462
Validation loss: 2.473940314511718

Epoch: 5| Step: 6
Training loss: 2.4391510091456534
Validation loss: 2.4690254596956995

Epoch: 5| Step: 7
Training loss: 3.049271956303828
Validation loss: 2.468033537739341

Epoch: 5| Step: 8
Training loss: 2.6309335042567685
Validation loss: 2.4562863270384248

Epoch: 5| Step: 9
Training loss: 2.5011758899909697
Validation loss: 2.457462076927432

Epoch: 5| Step: 10
Training loss: 2.409313580117301
Validation loss: 2.4668557327912395

Epoch: 5| Step: 11
Training loss: 2.766211754577167
Validation loss: 2.4747334413807818

Epoch: 149| Step: 0
Training loss: 2.9203787659892373
Validation loss: 2.468938152370346

Epoch: 5| Step: 1
Training loss: 2.626968916948351
Validation loss: 2.4608607567825347

Epoch: 5| Step: 2
Training loss: 2.7197308579690045
Validation loss: 2.4648079887169776

Epoch: 5| Step: 3
Training loss: 2.4843931377396573
Validation loss: 2.461947739343185

Epoch: 5| Step: 4
Training loss: 2.3613436740208695
Validation loss: 2.466827211170818

Epoch: 5| Step: 5
Training loss: 1.9205223223385315
Validation loss: 2.4675933546754036

Epoch: 5| Step: 6
Training loss: 2.116028979003863
Validation loss: 2.4641459666782297

Epoch: 5| Step: 7
Training loss: 2.3873649758709155
Validation loss: 2.462016415110802

Epoch: 5| Step: 8
Training loss: 2.120600690491537
Validation loss: 2.4697274433947434

Epoch: 5| Step: 9
Training loss: 2.6424362020451246
Validation loss: 2.4771918771659465

Epoch: 5| Step: 10
Training loss: 2.9405252016100305
Validation loss: 2.476300411215109

Epoch: 5| Step: 11
Training loss: 3.2749053650206914
Validation loss: 2.4747539659673805

Epoch: 150| Step: 0
Training loss: 2.0314219475374307
Validation loss: 2.4739953362893288

Epoch: 5| Step: 1
Training loss: 2.8889719592483485
Validation loss: 2.4748658346167023

Epoch: 5| Step: 2
Training loss: 2.6853829850559907
Validation loss: 2.479209450077431

Epoch: 5| Step: 3
Training loss: 2.9364940462966285
Validation loss: 2.4736128488872846

Epoch: 5| Step: 4
Training loss: 2.313768399833667
Validation loss: 2.4711504625487377

Epoch: 5| Step: 5
Training loss: 2.2753103610441165
Validation loss: 2.4615475821784583

Epoch: 5| Step: 6
Training loss: 2.42464549432754
Validation loss: 2.467380248310278

Epoch: 5| Step: 7
Training loss: 2.6236270765612315
Validation loss: 2.4673750303804947

Epoch: 5| Step: 8
Training loss: 2.0478034789225634
Validation loss: 2.4635790902024555

Epoch: 5| Step: 9
Training loss: 2.807683168382311
Validation loss: 2.461522060176879

Epoch: 5| Step: 10
Training loss: 2.6556817737237597
Validation loss: 2.4621194110488083

Epoch: 5| Step: 11
Training loss: 1.5317231829029547
Validation loss: 2.4617049579724313

Epoch: 151| Step: 0
Training loss: 2.7058717740869196
Validation loss: 2.4665540795686143

Epoch: 5| Step: 1
Training loss: 2.343161750722999
Validation loss: 2.470048054135659

Epoch: 5| Step: 2
Training loss: 2.1637383503988685
Validation loss: 2.4750275613553865

Epoch: 5| Step: 3
Training loss: 2.729095069780887
Validation loss: 2.460919354891615

Epoch: 5| Step: 4
Training loss: 1.9767524115356079
Validation loss: 2.4657368883177995

Epoch: 5| Step: 5
Training loss: 2.846110276188123
Validation loss: 2.4659234053712074

Epoch: 5| Step: 6
Training loss: 2.3496968418751942
Validation loss: 2.4668602772928887

Epoch: 5| Step: 7
Training loss: 2.711482716022197
Validation loss: 2.4743419523795205

Epoch: 5| Step: 8
Training loss: 2.296011730077732
Validation loss: 2.4818632636348723

Epoch: 5| Step: 9
Training loss: 2.5758668199787773
Validation loss: 2.464957253270531

Epoch: 5| Step: 10
Training loss: 3.0193497972141308
Validation loss: 2.4785432165206815

Epoch: 5| Step: 11
Training loss: 1.763092588000328
Validation loss: 2.4669737441605437

Epoch: 152| Step: 0
Training loss: 2.51932192383836
Validation loss: 2.4779417687784533

Epoch: 5| Step: 1
Training loss: 2.133340288190631
Validation loss: 2.4799002448971943

Epoch: 5| Step: 2
Training loss: 2.4852233014239733
Validation loss: 2.4747726599322584

Epoch: 5| Step: 3
Training loss: 2.9344278056600506
Validation loss: 2.4891019353079415

Epoch: 5| Step: 4
Training loss: 1.9636842252617268
Validation loss: 2.481437738140045

Epoch: 5| Step: 5
Training loss: 2.5476904189770124
Validation loss: 2.4872070700724715

Epoch: 5| Step: 6
Training loss: 2.959360633823284
Validation loss: 2.4839082315397087

Epoch: 5| Step: 7
Training loss: 2.2088240911883883
Validation loss: 2.472799320109494

Epoch: 5| Step: 8
Training loss: 2.5865596702738105
Validation loss: 2.4732922564186177

Epoch: 5| Step: 9
Training loss: 2.441792449922752
Validation loss: 2.466649554221189

Epoch: 5| Step: 10
Training loss: 2.487769153544622
Validation loss: 2.475110810862548

Epoch: 5| Step: 11
Training loss: 3.0956815604532824
Validation loss: 2.468280465909785

Epoch: 153| Step: 0
Training loss: 2.491896848561278
Validation loss: 2.4594838405504027

Epoch: 5| Step: 1
Training loss: 2.5311449759088482
Validation loss: 2.465266663491951

Epoch: 5| Step: 2
Training loss: 2.312990909741619
Validation loss: 2.4631961166167757

Epoch: 5| Step: 3
Training loss: 2.551890390589352
Validation loss: 2.4655083305981704

Epoch: 5| Step: 4
Training loss: 2.031794900432998
Validation loss: 2.4641726608502323

Epoch: 5| Step: 5
Training loss: 2.446112553668294
Validation loss: 2.4895368608954866

Epoch: 5| Step: 6
Training loss: 2.992333630213114
Validation loss: 2.494514893301855

Epoch: 5| Step: 7
Training loss: 2.9314008661743975
Validation loss: 2.472466817613243

Epoch: 5| Step: 8
Training loss: 2.528605834351241
Validation loss: 2.46387004612734

Epoch: 5| Step: 9
Training loss: 2.037803290325402
Validation loss: 2.476675708882814

Epoch: 5| Step: 10
Training loss: 2.9023782514983307
Validation loss: 2.4803239394642618

Epoch: 5| Step: 11
Training loss: 2.21142281641375
Validation loss: 2.488730259840508

Epoch: 154| Step: 0
Training loss: 2.830386611626909
Validation loss: 2.475062588982437

Epoch: 5| Step: 1
Training loss: 2.8700083646752086
Validation loss: 2.4942384609549286

Epoch: 5| Step: 2
Training loss: 2.893716839132773
Validation loss: 2.486041028232525

Epoch: 5| Step: 3
Training loss: 2.9591986953117835
Validation loss: 2.485989012345338

Epoch: 5| Step: 4
Training loss: 2.365655787480522
Validation loss: 2.4900923046400547

Epoch: 5| Step: 5
Training loss: 2.6316654411958913
Validation loss: 2.4837246609441417

Epoch: 5| Step: 6
Training loss: 2.241399433794424
Validation loss: 2.4773420115913605

Epoch: 5| Step: 7
Training loss: 2.3004552224835533
Validation loss: 2.4842037405809103

Epoch: 5| Step: 8
Training loss: 2.5587520637746146
Validation loss: 2.476443318929914

Epoch: 5| Step: 9
Training loss: 2.1441334284214943
Validation loss: 2.465829820268386

Epoch: 5| Step: 10
Training loss: 2.074048626203692
Validation loss: 2.469344944630613

Epoch: 5| Step: 11
Training loss: 2.2709349396632006
Validation loss: 2.4638400001351384

Epoch: 155| Step: 0
Training loss: 2.2563626078985517
Validation loss: 2.4714572403975112

Epoch: 5| Step: 1
Training loss: 2.7730864826559785
Validation loss: 2.47015051008004

Epoch: 5| Step: 2
Training loss: 2.645953879025793
Validation loss: 2.4883058068677104

Epoch: 5| Step: 3
Training loss: 2.3648472665257136
Validation loss: 2.4867399663216845

Epoch: 5| Step: 4
Training loss: 2.4348221766028924
Validation loss: 2.4762598689160398

Epoch: 5| Step: 5
Training loss: 2.5821210929256386
Validation loss: 2.4654975866250366

Epoch: 5| Step: 6
Training loss: 2.6600520131755077
Validation loss: 2.471999008228536

Epoch: 5| Step: 7
Training loss: 3.2546517753380217
Validation loss: 2.4625196427079836

Epoch: 5| Step: 8
Training loss: 2.043904952495097
Validation loss: 2.463423233465152

Epoch: 5| Step: 9
Training loss: 2.466675961537075
Validation loss: 2.4652977559051763

Epoch: 5| Step: 10
Training loss: 2.5704777905035803
Validation loss: 2.471497523843239

Epoch: 5| Step: 11
Training loss: 2.7900537604618103
Validation loss: 2.471067254495984

Epoch: 156| Step: 0
Training loss: 2.1987380049455845
Validation loss: 2.4683719538703044

Epoch: 5| Step: 1
Training loss: 2.5679620355669748
Validation loss: 2.4723532673367425

Epoch: 5| Step: 2
Training loss: 2.9407541633802845
Validation loss: 2.4627105098471964

Epoch: 5| Step: 3
Training loss: 1.859249335137695
Validation loss: 2.4814751293117943

Epoch: 5| Step: 4
Training loss: 2.602101862902264
Validation loss: 2.4760730592703255

Epoch: 5| Step: 5
Training loss: 2.5568385969175402
Validation loss: 2.480484437267129

Epoch: 5| Step: 6
Training loss: 2.741204327343295
Validation loss: 2.4698596504687282

Epoch: 5| Step: 7
Training loss: 2.390291776683224
Validation loss: 2.470605133083558

Epoch: 5| Step: 8
Training loss: 2.070025039005416
Validation loss: 2.463865651339227

Epoch: 5| Step: 9
Training loss: 3.1434043618433285
Validation loss: 2.4647274201474447

Epoch: 5| Step: 10
Training loss: 2.77482273807214
Validation loss: 2.4630249232866372

Epoch: 5| Step: 11
Training loss: 1.6902375798010985
Validation loss: 2.4723835674747994

Epoch: 157| Step: 0
Training loss: 2.5423978993968315
Validation loss: 2.4785847014212097

Epoch: 5| Step: 1
Training loss: 2.4866087845755063
Validation loss: 2.469908808506161

Epoch: 5| Step: 2
Training loss: 2.379265718908995
Validation loss: 2.4791569482522036

Epoch: 5| Step: 3
Training loss: 2.4296987846087923
Validation loss: 2.477987234608434

Epoch: 5| Step: 4
Training loss: 2.6662300666389447
Validation loss: 2.47934147808831

Epoch: 5| Step: 5
Training loss: 2.1684077187909354
Validation loss: 2.478938474224292

Epoch: 5| Step: 6
Training loss: 3.1945831287152275
Validation loss: 2.4850203277759393

Epoch: 5| Step: 7
Training loss: 2.5742795065857442
Validation loss: 2.4759585930852106

Epoch: 5| Step: 8
Training loss: 2.587503103355721
Validation loss: 2.4712250290237607

Epoch: 5| Step: 9
Training loss: 2.3148112732189072
Validation loss: 2.481908717666512

Epoch: 5| Step: 10
Training loss: 2.2496578168281864
Validation loss: 2.482486530925608

Epoch: 5| Step: 11
Training loss: 3.132445049854258
Validation loss: 2.4733509054185245

Epoch: 158| Step: 0
Training loss: 2.4128860520524396
Validation loss: 2.474053336210001

Epoch: 5| Step: 1
Training loss: 2.454126141596223
Validation loss: 2.4791167331657036

Epoch: 5| Step: 2
Training loss: 2.799276503686586
Validation loss: 2.4813882960575233

Epoch: 5| Step: 3
Training loss: 2.4687633272608034
Validation loss: 2.4766799385473344

Epoch: 5| Step: 4
Training loss: 2.9348096499218506
Validation loss: 2.478234459751359

Epoch: 5| Step: 5
Training loss: 2.4193261300711444
Validation loss: 2.4760867081973292

Epoch: 5| Step: 6
Training loss: 2.2225371799856255
Validation loss: 2.4796121675185208

Epoch: 5| Step: 7
Training loss: 2.722091725740021
Validation loss: 2.4811586416835243

Epoch: 5| Step: 8
Training loss: 2.26724984670208
Validation loss: 2.4747300935247702

Epoch: 5| Step: 9
Training loss: 2.533292723213086
Validation loss: 2.4802872398627858

Epoch: 5| Step: 10
Training loss: 2.2462548770331505
Validation loss: 2.478917475339438

Epoch: 5| Step: 11
Training loss: 2.8553112732846118
Validation loss: 2.4745013648238974

Epoch: 159| Step: 0
Training loss: 2.5008050576017933
Validation loss: 2.465446736958948

Epoch: 5| Step: 1
Training loss: 2.830913538866663
Validation loss: 2.4651320621844595

Epoch: 5| Step: 2
Training loss: 2.358784279546416
Validation loss: 2.467324187196946

Epoch: 5| Step: 3
Training loss: 2.468595282619765
Validation loss: 2.460367437468269

Epoch: 5| Step: 4
Training loss: 1.6452328596556915
Validation loss: 2.461858106918205

Epoch: 5| Step: 5
Training loss: 2.146206894243411
Validation loss: 2.46459976657302

Epoch: 5| Step: 6
Training loss: 2.579270264532909
Validation loss: 2.4644567807538733

Epoch: 5| Step: 7
Training loss: 2.7859151910989413
Validation loss: 2.461262183997958

Epoch: 5| Step: 8
Training loss: 2.3024711684949475
Validation loss: 2.4672303935101785

Epoch: 5| Step: 9
Training loss: 2.858845812914548
Validation loss: 2.46610230095591

Epoch: 5| Step: 10
Training loss: 2.7948506450839936
Validation loss: 2.471233527103385

Epoch: 5| Step: 11
Training loss: 3.3147750815013652
Validation loss: 2.4688746545602847

Epoch: 160| Step: 0
Training loss: 2.680003244910482
Validation loss: 2.47338325776776

Epoch: 5| Step: 1
Training loss: 2.4140229947212535
Validation loss: 2.4709326636197626

Epoch: 5| Step: 2
Training loss: 2.6717524807150057
Validation loss: 2.4706013212477393

Epoch: 5| Step: 3
Training loss: 2.378368799292233
Validation loss: 2.4734706812978664

Epoch: 5| Step: 4
Training loss: 2.170366051207522
Validation loss: 2.4690584440736747

Epoch: 5| Step: 5
Training loss: 2.507655914266686
Validation loss: 2.469446763972149

Epoch: 5| Step: 6
Training loss: 2.4362725321714693
Validation loss: 2.4649922144330345

Epoch: 5| Step: 7
Training loss: 2.596156738692626
Validation loss: 2.4761345310046043

Epoch: 5| Step: 8
Training loss: 2.9271937628897216
Validation loss: 2.4684951626554663

Epoch: 5| Step: 9
Training loss: 2.362565668394338
Validation loss: 2.4766581904940987

Epoch: 5| Step: 10
Training loss: 2.4447310368794937
Validation loss: 2.4674258443336683

Epoch: 5| Step: 11
Training loss: 2.2185205690205434
Validation loss: 2.47511668074719

Epoch: 161| Step: 0
Training loss: 2.524964145368066
Validation loss: 2.473249290986504

Epoch: 5| Step: 1
Training loss: 2.2030743532243666
Validation loss: 2.474863454314516

Epoch: 5| Step: 2
Training loss: 2.684957499247635
Validation loss: 2.475557255625807

Epoch: 5| Step: 3
Training loss: 2.6608453829865133
Validation loss: 2.481031747438818

Epoch: 5| Step: 4
Training loss: 2.2869415351924025
Validation loss: 2.474018422785704

Epoch: 5| Step: 5
Training loss: 2.9490295753690514
Validation loss: 2.471881650713989

Epoch: 5| Step: 6
Training loss: 2.5173220389538433
Validation loss: 2.4776287451062173

Epoch: 5| Step: 7
Training loss: 2.9099751870582047
Validation loss: 2.4703550714294646

Epoch: 5| Step: 8
Training loss: 1.6940292916405781
Validation loss: 2.4684210489718676

Epoch: 5| Step: 9
Training loss: 2.696850766175836
Validation loss: 2.459052563914375

Epoch: 5| Step: 10
Training loss: 2.2344288852836405
Validation loss: 2.472287665321269

Epoch: 5| Step: 11
Training loss: 2.6904442206957744
Validation loss: 2.4733772893835826

Epoch: 162| Step: 0
Training loss: 2.524274279858196
Validation loss: 2.471116378460269

Epoch: 5| Step: 1
Training loss: 2.356794145725228
Validation loss: 2.4821270563280033

Epoch: 5| Step: 2
Training loss: 2.533637251526066
Validation loss: 2.489927812044387

Epoch: 5| Step: 3
Training loss: 2.715103685847438
Validation loss: 2.4830821970122927

Epoch: 5| Step: 4
Training loss: 2.4693120968395026
Validation loss: 2.4849570370292

Epoch: 5| Step: 5
Training loss: 2.622369083595157
Validation loss: 2.475954508634943

Epoch: 5| Step: 6
Training loss: 2.5443547422745345
Validation loss: 2.480819573211011

Epoch: 5| Step: 7
Training loss: 2.5826481761687314
Validation loss: 2.4757475850978423

Epoch: 5| Step: 8
Training loss: 2.934906646699569
Validation loss: 2.472229702333381

Epoch: 5| Step: 9
Training loss: 2.557064898368873
Validation loss: 2.4729882108360046

Epoch: 5| Step: 10
Training loss: 2.2621786279210583
Validation loss: 2.475611113872329

Epoch: 5| Step: 11
Training loss: 2.4774077985526706
Validation loss: 2.471096042757019

Epoch: 163| Step: 0
Training loss: 2.429120356367505
Validation loss: 2.469116392993875

Epoch: 5| Step: 1
Training loss: 2.273087202528282
Validation loss: 2.4704422965103268

Epoch: 5| Step: 2
Training loss: 3.43619873386078
Validation loss: 2.4712312638996043

Epoch: 5| Step: 3
Training loss: 2.6606404540222703
Validation loss: 2.475633408833044

Epoch: 5| Step: 4
Training loss: 2.508030771994531
Validation loss: 2.470029692413456

Epoch: 5| Step: 5
Training loss: 2.746476951114895
Validation loss: 2.4691059041107923

Epoch: 5| Step: 6
Training loss: 2.582597956022891
Validation loss: 2.474445742059733

Epoch: 5| Step: 7
Training loss: 2.5628472999988845
Validation loss: 2.4719214972339834

Epoch: 5| Step: 8
Training loss: 1.9920140808021447
Validation loss: 2.4699945169972297

Epoch: 5| Step: 9
Training loss: 2.1557743819524733
Validation loss: 2.4648707126889864

Epoch: 5| Step: 10
Training loss: 2.600105037768278
Validation loss: 2.4603401508648584

Epoch: 5| Step: 11
Training loss: 1.7653823955931724
Validation loss: 2.4552991226904535

Epoch: 164| Step: 0
Training loss: 2.59331775418712
Validation loss: 2.4567405597459717

Epoch: 5| Step: 1
Training loss: 2.581721161705756
Validation loss: 2.4481241476450113

Epoch: 5| Step: 2
Training loss: 2.4110594406490216
Validation loss: 2.453740166313896

Epoch: 5| Step: 3
Training loss: 2.376540036067094
Validation loss: 2.4552264516488576

Epoch: 5| Step: 4
Training loss: 1.6557600628263247
Validation loss: 2.4563179294682804

Epoch: 5| Step: 5
Training loss: 2.48416031203747
Validation loss: 2.4559298352763723

Epoch: 5| Step: 6
Training loss: 3.1127172555130276
Validation loss: 2.45304412870477

Epoch: 5| Step: 7
Training loss: 2.6227491810606196
Validation loss: 2.4568934318571136

Epoch: 5| Step: 8
Training loss: 2.478228757593491
Validation loss: 2.4552972433289373

Epoch: 5| Step: 9
Training loss: 2.921840728721974
Validation loss: 2.457011373871108

Epoch: 5| Step: 10
Training loss: 2.3308991155341956
Validation loss: 2.4648364228685296

Epoch: 5| Step: 11
Training loss: 2.9157899538011134
Validation loss: 2.447672739794241

Epoch: 165| Step: 0
Training loss: 2.4488443334849017
Validation loss: 2.4552239572229944

Epoch: 5| Step: 1
Training loss: 1.8922525761672828
Validation loss: 2.456855128798326

Epoch: 5| Step: 2
Training loss: 2.469067420351055
Validation loss: 2.451462642045291

Epoch: 5| Step: 3
Training loss: 2.495802693717598
Validation loss: 2.45791255992187

Epoch: 5| Step: 4
Training loss: 2.6718435899104036
Validation loss: 2.4524914638190562

Epoch: 5| Step: 5
Training loss: 2.1379529328121145
Validation loss: 2.4541702513892565

Epoch: 5| Step: 6
Training loss: 3.0355241667894997
Validation loss: 2.456039588431833

Epoch: 5| Step: 7
Training loss: 2.2759630784725644
Validation loss: 2.456938292539562

Epoch: 5| Step: 8
Training loss: 2.7592442067859606
Validation loss: 2.4548538457597204

Epoch: 5| Step: 9
Training loss: 2.1823851596467536
Validation loss: 2.4572347931683223

Epoch: 5| Step: 10
Training loss: 3.13459495008504
Validation loss: 2.4618553912222874

Epoch: 5| Step: 11
Training loss: 2.629697683386031
Validation loss: 2.4616803657673136

Epoch: 166| Step: 0
Training loss: 2.241581532540989
Validation loss: 2.4563896542322103

Epoch: 5| Step: 1
Training loss: 2.66787125282255
Validation loss: 2.457600554397557

Epoch: 5| Step: 2
Training loss: 2.1800057783837685
Validation loss: 2.4671779447970055

Epoch: 5| Step: 3
Training loss: 2.390929956869248
Validation loss: 2.467452617764922

Epoch: 5| Step: 4
Training loss: 2.697405458619619
Validation loss: 2.46385491028281

Epoch: 5| Step: 5
Training loss: 2.6087859625318486
Validation loss: 2.4749003627899473

Epoch: 5| Step: 6
Training loss: 2.476427140733564
Validation loss: 2.4690794765144837

Epoch: 5| Step: 7
Training loss: 2.725572903805947
Validation loss: 2.467589455657496

Epoch: 5| Step: 8
Training loss: 2.5476512077162328
Validation loss: 2.469233662673446

Epoch: 5| Step: 9
Training loss: 2.8221442278984084
Validation loss: 2.4657778393200287

Epoch: 5| Step: 10
Training loss: 2.2655982706532103
Validation loss: 2.46042894225217

Epoch: 5| Step: 11
Training loss: 3.208889570362351
Validation loss: 2.4581878842682987

Epoch: 167| Step: 0
Training loss: 2.6696575399506273
Validation loss: 2.4661860894069987

Epoch: 5| Step: 1
Training loss: 1.8979354634141046
Validation loss: 2.4609633267778173

Epoch: 5| Step: 2
Training loss: 2.8394229372492483
Validation loss: 2.455296986408575

Epoch: 5| Step: 3
Training loss: 2.7753260240546376
Validation loss: 2.4572062872240763

Epoch: 5| Step: 4
Training loss: 2.738556895619376
Validation loss: 2.460991599482346

Epoch: 5| Step: 5
Training loss: 1.9809598595963602
Validation loss: 2.458236471520081

Epoch: 5| Step: 6
Training loss: 2.502648857635938
Validation loss: 2.454304061491363

Epoch: 5| Step: 7
Training loss: 2.1888601161896686
Validation loss: 2.4531410605518373

Epoch: 5| Step: 8
Training loss: 2.810599978053316
Validation loss: 2.45084450043961

Epoch: 5| Step: 9
Training loss: 2.26337126084443
Validation loss: 2.453805278395738

Epoch: 5| Step: 10
Training loss: 2.9507118336110367
Validation loss: 2.4616839210389387

Epoch: 5| Step: 11
Training loss: 2.0077080012932735
Validation loss: 2.456094778655144

Epoch: 168| Step: 0
Training loss: 2.6672063718462224
Validation loss: 2.460333601711992

Epoch: 5| Step: 1
Training loss: 2.447318329970425
Validation loss: 2.463100713793878

Epoch: 5| Step: 2
Training loss: 2.4100602933060835
Validation loss: 2.468680529683323

Epoch: 5| Step: 3
Training loss: 2.733573578146583
Validation loss: 2.4639879565754836

Epoch: 5| Step: 4
Training loss: 2.760747800915101
Validation loss: 2.457731514073606

Epoch: 5| Step: 5
Training loss: 2.2279855564135516
Validation loss: 2.4665630206572278

Epoch: 5| Step: 6
Training loss: 1.9697784280828026
Validation loss: 2.473022128531523

Epoch: 5| Step: 7
Training loss: 1.8686108132265993
Validation loss: 2.4819672831344524

Epoch: 5| Step: 8
Training loss: 2.838766237293941
Validation loss: 2.470811940487074

Epoch: 5| Step: 9
Training loss: 2.7070737893201167
Validation loss: 2.4823517608145145

Epoch: 5| Step: 10
Training loss: 2.5217592309711168
Validation loss: 2.4716704675006858

Epoch: 5| Step: 11
Training loss: 3.3117683610307083
Validation loss: 2.4686248763684446

Epoch: 169| Step: 0
Training loss: 2.4118457480241067
Validation loss: 2.464493252539432

Epoch: 5| Step: 1
Training loss: 2.249302438051563
Validation loss: 2.474116785429516

Epoch: 5| Step: 2
Training loss: 3.2635698924633383
Validation loss: 2.4657623989241237

Epoch: 5| Step: 3
Training loss: 2.2477951903189157
Validation loss: 2.4638730378043054

Epoch: 5| Step: 4
Training loss: 2.551939066228208
Validation loss: 2.4636827083051283

Epoch: 5| Step: 5
Training loss: 2.652971465899502
Validation loss: 2.4671271519108218

Epoch: 5| Step: 6
Training loss: 2.2715832466524684
Validation loss: 2.4729691579133117

Epoch: 5| Step: 7
Training loss: 2.6348100549615183
Validation loss: 2.471703605480867

Epoch: 5| Step: 8
Training loss: 2.5561196515489386
Validation loss: 2.481042930649045

Epoch: 5| Step: 9
Training loss: 2.1820613281274825
Validation loss: 2.4716034285508295

Epoch: 5| Step: 10
Training loss: 2.581916471807118
Validation loss: 2.4779418128776256

Epoch: 5| Step: 11
Training loss: 1.2671436570340577
Validation loss: 2.484498370804115

Epoch: 170| Step: 0
Training loss: 2.283172528899735
Validation loss: 2.4884123595473318

Epoch: 5| Step: 1
Training loss: 2.0499387918033993
Validation loss: 2.4845583706086414

Epoch: 5| Step: 2
Training loss: 2.0729439763965076
Validation loss: 2.482120202455445

Epoch: 5| Step: 3
Training loss: 3.3841944596170785
Validation loss: 2.482287003329613

Epoch: 5| Step: 4
Training loss: 2.9433409064408966
Validation loss: 2.4817699833988898

Epoch: 5| Step: 5
Training loss: 2.340766941141663
Validation loss: 2.478089612858081

Epoch: 5| Step: 6
Training loss: 2.445681705572981
Validation loss: 2.4805752308335647

Epoch: 5| Step: 7
Training loss: 2.567976426268902
Validation loss: 2.4737621483898846

Epoch: 5| Step: 8
Training loss: 2.95623341206903
Validation loss: 2.4617006985426144

Epoch: 5| Step: 9
Training loss: 2.0797672522978305
Validation loss: 2.4727272356961603

Epoch: 5| Step: 10
Training loss: 2.23516468951843
Validation loss: 2.472723885123919

Epoch: 5| Step: 11
Training loss: 2.566611550304933
Validation loss: 2.4668591175094794

Epoch: 171| Step: 0
Training loss: 2.719634076776904
Validation loss: 2.464922460880169

Epoch: 5| Step: 1
Training loss: 1.8768708114755128
Validation loss: 2.4696022807896667

Epoch: 5| Step: 2
Training loss: 2.2677415103848064
Validation loss: 2.473000380446994

Epoch: 5| Step: 3
Training loss: 2.531946722148076
Validation loss: 2.4642285618594664

Epoch: 5| Step: 4
Training loss: 2.8260227208827096
Validation loss: 2.4684581745069245

Epoch: 5| Step: 5
Training loss: 1.93495768212464
Validation loss: 2.4681952613765916

Epoch: 5| Step: 6
Training loss: 2.4783718106486012
Validation loss: 2.4739772528209376

Epoch: 5| Step: 7
Training loss: 2.8611031401522156
Validation loss: 2.471683270589843

Epoch: 5| Step: 8
Training loss: 2.8900556673806617
Validation loss: 2.460496388618048

Epoch: 5| Step: 9
Training loss: 2.3756062587128253
Validation loss: 2.469984727637248

Epoch: 5| Step: 10
Training loss: 2.6934873731709144
Validation loss: 2.464818596648588

Epoch: 5| Step: 11
Training loss: 2.0826458623207635
Validation loss: 2.4554046842588133

Epoch: 172| Step: 0
Training loss: 2.3855668954866465
Validation loss: 2.467083283845136

Epoch: 5| Step: 1
Training loss: 1.8613477867985337
Validation loss: 2.458824526212152

Epoch: 5| Step: 2
Training loss: 2.7572323456366
Validation loss: 2.469509366099506

Epoch: 5| Step: 3
Training loss: 2.2336194021240328
Validation loss: 2.4617979614207637

Epoch: 5| Step: 4
Training loss: 2.451091141910008
Validation loss: 2.476808613963913

Epoch: 5| Step: 5
Training loss: 2.8695396317282467
Validation loss: 2.47268953948791

Epoch: 5| Step: 6
Training loss: 2.0302343323479644
Validation loss: 2.4693415090094804

Epoch: 5| Step: 7
Training loss: 2.7170634683967885
Validation loss: 2.45607640766831

Epoch: 5| Step: 8
Training loss: 2.1180728876902135
Validation loss: 2.46836054824501

Epoch: 5| Step: 9
Training loss: 2.6386388950277513
Validation loss: 2.4724758980350625

Epoch: 5| Step: 10
Training loss: 3.251255819806057
Validation loss: 2.4766490852952145

Epoch: 5| Step: 11
Training loss: 2.1714370615334277
Validation loss: 2.4846859823279948

Epoch: 173| Step: 0
Training loss: 2.1059341057940957
Validation loss: 2.485638131418793

Epoch: 5| Step: 1
Training loss: 2.945969566493609
Validation loss: 2.4719898034855605

Epoch: 5| Step: 2
Training loss: 2.0728612793339107
Validation loss: 2.4739869300126474

Epoch: 5| Step: 3
Training loss: 2.790720214586384
Validation loss: 2.47449888782087

Epoch: 5| Step: 4
Training loss: 2.501736800574382
Validation loss: 2.474795259490816

Epoch: 5| Step: 5
Training loss: 2.33779323186992
Validation loss: 2.483607755503324

Epoch: 5| Step: 6
Training loss: 2.9612007929915145
Validation loss: 2.4794251376673513

Epoch: 5| Step: 7
Training loss: 2.3845114732635464
Validation loss: 2.482791355908072

Epoch: 5| Step: 8
Training loss: 2.236895440118284
Validation loss: 2.4695205934433995

Epoch: 5| Step: 9
Training loss: 2.661993750498233
Validation loss: 2.478500189807026

Epoch: 5| Step: 10
Training loss: 2.2813915052029556
Validation loss: 2.467506791807269

Epoch: 5| Step: 11
Training loss: 2.8144548192439385
Validation loss: 2.4757787505233826

Epoch: 174| Step: 0
Training loss: 2.4207410557329614
Validation loss: 2.463455613362588

Epoch: 5| Step: 1
Training loss: 2.9624808524112556
Validation loss: 2.468096127412434

Epoch: 5| Step: 2
Training loss: 2.656635121868611
Validation loss: 2.4756063546988427

Epoch: 5| Step: 3
Training loss: 2.9212543011863428
Validation loss: 2.4731316734650033

Epoch: 5| Step: 4
Training loss: 2.234411812859165
Validation loss: 2.475724994232552

Epoch: 5| Step: 5
Training loss: 2.291184623189293
Validation loss: 2.4810972443777897

Epoch: 5| Step: 6
Training loss: 2.4491232529416247
Validation loss: 2.482042837431086

Epoch: 5| Step: 7
Training loss: 2.6664541477715247
Validation loss: 2.4819422552915866

Epoch: 5| Step: 8
Training loss: 2.3926539568658707
Validation loss: 2.4864270554423626

Epoch: 5| Step: 9
Training loss: 2.3240326622589844
Validation loss: 2.4746129317685854

Epoch: 5| Step: 10
Training loss: 2.1678520652368576
Validation loss: 2.4762686626315813

Epoch: 5| Step: 11
Training loss: 2.106796270781969
Validation loss: 2.473872600207629

Epoch: 175| Step: 0
Training loss: 2.320581080244298
Validation loss: 2.4761674126607267

Epoch: 5| Step: 1
Training loss: 2.1272940874694592
Validation loss: 2.473059510366598

Epoch: 5| Step: 2
Training loss: 2.1249997756060313
Validation loss: 2.4787252591505173

Epoch: 5| Step: 3
Training loss: 2.397201965391823
Validation loss: 2.4831694591032933

Epoch: 5| Step: 4
Training loss: 2.640855226130054
Validation loss: 2.483887824589522

Epoch: 5| Step: 5
Training loss: 2.381941739430821
Validation loss: 2.4860187986368487

Epoch: 5| Step: 6
Training loss: 2.7099150122797755
Validation loss: 2.491042957551762

Epoch: 5| Step: 7
Training loss: 2.5785878083947047
Validation loss: 2.4838575028114263

Epoch: 5| Step: 8
Training loss: 2.841201142991556
Validation loss: 2.4880091839323906

Epoch: 5| Step: 9
Training loss: 2.8028571231559285
Validation loss: 2.4932111652734594

Epoch: 5| Step: 10
Training loss: 2.271761981403991
Validation loss: 2.4884537697416316

Epoch: 5| Step: 11
Training loss: 3.1042141665381013
Validation loss: 2.486552262073596

Epoch: 176| Step: 0
Training loss: 2.3229893101394103
Validation loss: 2.4836912513802556

Epoch: 5| Step: 1
Training loss: 2.432780661157165
Validation loss: 2.467039868006753

Epoch: 5| Step: 2
Training loss: 2.750607510133841
Validation loss: 2.46410063651791

Epoch: 5| Step: 3
Training loss: 2.248433627508989
Validation loss: 2.470429766463623

Epoch: 5| Step: 4
Training loss: 2.335269896369925
Validation loss: 2.4810695130935954

Epoch: 5| Step: 5
Training loss: 2.405434011844714
Validation loss: 2.4760508525219547

Epoch: 5| Step: 6
Training loss: 2.584676844395371
Validation loss: 2.4698904356935647

Epoch: 5| Step: 7
Training loss: 1.9600904846714005
Validation loss: 2.4686623167409474

Epoch: 5| Step: 8
Training loss: 3.036072660177285
Validation loss: 2.4712882935910123

Epoch: 5| Step: 9
Training loss: 2.2745282155565882
Validation loss: 2.474289188681216

Epoch: 5| Step: 10
Training loss: 3.1296737815339157
Validation loss: 2.4772010565638207

Epoch: 5| Step: 11
Training loss: 2.2592778186290565
Validation loss: 2.480450259162286

Epoch: 177| Step: 0
Training loss: 2.649659811532757
Validation loss: 2.4800139242981127

Epoch: 5| Step: 1
Training loss: 2.3684344642660977
Validation loss: 2.4774006248673404

Epoch: 5| Step: 2
Training loss: 2.3681501690958435
Validation loss: 2.4831780683273323

Epoch: 5| Step: 3
Training loss: 2.456795443088848
Validation loss: 2.47982060332199

Epoch: 5| Step: 4
Training loss: 2.75553977621681
Validation loss: 2.475483267095315

Epoch: 5| Step: 5
Training loss: 2.7010182014933894
Validation loss: 2.4758284169763187

Epoch: 5| Step: 6
Training loss: 2.4585680014465363
Validation loss: 2.4762955851678052

Epoch: 5| Step: 7
Training loss: 1.89093500543473
Validation loss: 2.472126153146111

Epoch: 5| Step: 8
Training loss: 2.5901003058904832
Validation loss: 2.47517421090026

Epoch: 5| Step: 9
Training loss: 2.8996072963669635
Validation loss: 2.4639374547437023

Epoch: 5| Step: 10
Training loss: 2.2502003686485703
Validation loss: 2.4743627291319954

Epoch: 5| Step: 11
Training loss: 2.004533873905787
Validation loss: 2.4648524232319833

Epoch: 178| Step: 0
Training loss: 2.534774022610916
Validation loss: 2.470760237243523

Epoch: 5| Step: 1
Training loss: 2.7083423516539056
Validation loss: 2.4750648687512253

Epoch: 5| Step: 2
Training loss: 2.1684015615266583
Validation loss: 2.4706804236775137

Epoch: 5| Step: 3
Training loss: 3.0132721730442427
Validation loss: 2.473525101055651

Epoch: 5| Step: 4
Training loss: 3.0539793476638035
Validation loss: 2.4734142923300544

Epoch: 5| Step: 5
Training loss: 2.0716134068749277
Validation loss: 2.476178437305667

Epoch: 5| Step: 6
Training loss: 2.315999965193358
Validation loss: 2.478034094690106

Epoch: 5| Step: 7
Training loss: 2.6680419375656617
Validation loss: 2.478868812545234

Epoch: 5| Step: 8
Training loss: 2.471643225296543
Validation loss: 2.4711640019842287

Epoch: 5| Step: 9
Training loss: 2.402178105792121
Validation loss: 2.4669880836945364

Epoch: 5| Step: 10
Training loss: 1.9379892039278794
Validation loss: 2.474773498889364

Epoch: 5| Step: 11
Training loss: 1.8626645905140198
Validation loss: 2.4674990619334274

Epoch: 179| Step: 0
Training loss: 2.2444888542784036
Validation loss: 2.4591411614320746

Epoch: 5| Step: 1
Training loss: 2.384902587756653
Validation loss: 2.479320963431058

Epoch: 5| Step: 2
Training loss: 2.7060253481752605
Validation loss: 2.4660151983114003

Epoch: 5| Step: 3
Training loss: 2.408330637084437
Validation loss: 2.4676261508687047

Epoch: 5| Step: 4
Training loss: 2.6229219840078914
Validation loss: 2.477119118507134

Epoch: 5| Step: 5
Training loss: 2.4606141861960658
Validation loss: 2.473963331250948

Epoch: 5| Step: 6
Training loss: 3.0509247300407174
Validation loss: 2.4716102090950334

Epoch: 5| Step: 7
Training loss: 2.483504808722691
Validation loss: 2.467163179554333

Epoch: 5| Step: 8
Training loss: 2.453287593045437
Validation loss: 2.475257148452894

Epoch: 5| Step: 9
Training loss: 1.977073995275389
Validation loss: 2.4750271399130606

Epoch: 5| Step: 10
Training loss: 2.480882985527213
Validation loss: 2.4789555376909473

Epoch: 5| Step: 11
Training loss: 2.4762355456250504
Validation loss: 2.4804545484722027

Epoch: 180| Step: 0
Training loss: 2.3558053808867037
Validation loss: 2.48513143447691

Epoch: 5| Step: 1
Training loss: 2.2521712105750673
Validation loss: 2.482243405181231

Epoch: 5| Step: 2
Training loss: 2.1997953102950385
Validation loss: 2.486078178346286

Epoch: 5| Step: 3
Training loss: 2.2988701284196305
Validation loss: 2.490984739060568

Epoch: 5| Step: 4
Training loss: 2.4042497718591176
Validation loss: 2.4818416950934274

Epoch: 5| Step: 5
Training loss: 2.4478114220470606
Validation loss: 2.4709975076032724

Epoch: 5| Step: 6
Training loss: 2.9152819661673797
Validation loss: 2.479247946702413

Epoch: 5| Step: 7
Training loss: 2.274890553283596
Validation loss: 2.471690099144887

Epoch: 5| Step: 8
Training loss: 2.5874579532173985
Validation loss: 2.4659258587598334

Epoch: 5| Step: 9
Training loss: 2.632978847240492
Validation loss: 2.4653722656899664

Epoch: 5| Step: 10
Training loss: 2.988961096328249
Validation loss: 2.4729423498048173

Epoch: 5| Step: 11
Training loss: 1.6529924999419998
Validation loss: 2.475283568285865

Epoch: 181| Step: 0
Training loss: 2.729935185987012
Validation loss: 2.4712202252241

Epoch: 5| Step: 1
Training loss: 2.8335219675736867
Validation loss: 2.468129530730492

Epoch: 5| Step: 2
Training loss: 2.357671665968202
Validation loss: 2.465401974685248

Epoch: 5| Step: 3
Training loss: 2.673000344096232
Validation loss: 2.4609230929159858

Epoch: 5| Step: 4
Training loss: 2.054768607855842
Validation loss: 2.467540062196183

Epoch: 5| Step: 5
Training loss: 3.02641508563661
Validation loss: 2.4642788118195993

Epoch: 5| Step: 6
Training loss: 2.752802547835679
Validation loss: 2.4722257965635923

Epoch: 5| Step: 7
Training loss: 2.092353924719492
Validation loss: 2.4701253705504875

Epoch: 5| Step: 8
Training loss: 2.867847169248988
Validation loss: 2.4749786655392754

Epoch: 5| Step: 9
Training loss: 1.8211161268014027
Validation loss: 2.474474356524921

Epoch: 5| Step: 10
Training loss: 1.8182169103487082
Validation loss: 2.46982767429326

Epoch: 5| Step: 11
Training loss: 2.8933493483081127
Validation loss: 2.474910439771788

Epoch: 182| Step: 0
Training loss: 2.0977592229875657
Validation loss: 2.464962532740113

Epoch: 5| Step: 1
Training loss: 2.746205052254088
Validation loss: 2.467736474764095

Epoch: 5| Step: 2
Training loss: 1.9061984696224106
Validation loss: 2.470649431170407

Epoch: 5| Step: 3
Training loss: 3.081069390069912
Validation loss: 2.4679021304868884

Epoch: 5| Step: 4
Training loss: 2.717524986959372
Validation loss: 2.458535951141661

Epoch: 5| Step: 5
Training loss: 2.3555079214909864
Validation loss: 2.460971456626468

Epoch: 5| Step: 6
Training loss: 2.4139155370921417
Validation loss: 2.4693086450805404

Epoch: 5| Step: 7
Training loss: 2.7674361510867413
Validation loss: 2.46490550177956

Epoch: 5| Step: 8
Training loss: 2.0898510513891146
Validation loss: 2.4681324488203096

Epoch: 5| Step: 9
Training loss: 2.156706609616472
Validation loss: 2.469524632217469

Epoch: 5| Step: 10
Training loss: 2.7613891232188816
Validation loss: 2.4652644733881846

Epoch: 5| Step: 11
Training loss: 3.0982214470973353
Validation loss: 2.4690657747697022

Epoch: 183| Step: 0
Training loss: 2.486357563620644
Validation loss: 2.474255868520693

Epoch: 5| Step: 1
Training loss: 2.0262528205677808
Validation loss: 2.477475532516135

Epoch: 5| Step: 2
Training loss: 1.9758779071471058
Validation loss: 2.480931296487569

Epoch: 5| Step: 3
Training loss: 2.3443086085609233
Validation loss: 2.478645054789757

Epoch: 5| Step: 4
Training loss: 2.4779515748114602
Validation loss: 2.4736453704977057

Epoch: 5| Step: 5
Training loss: 2.656217507556324
Validation loss: 2.4750894845012485

Epoch: 5| Step: 6
Training loss: 3.121475521032603
Validation loss: 2.4705617570201155

Epoch: 5| Step: 7
Training loss: 2.317014051596453
Validation loss: 2.4661126918371825

Epoch: 5| Step: 8
Training loss: 2.3789361159480946
Validation loss: 2.4604483950962353

Epoch: 5| Step: 9
Training loss: 2.727474814210408
Validation loss: 2.467698090417832

Epoch: 5| Step: 10
Training loss: 2.4968700843352054
Validation loss: 2.4576426757583794

Epoch: 5| Step: 11
Training loss: 3.442443622024958
Validation loss: 2.466315682888825

Epoch: 184| Step: 0
Training loss: 2.3114241081914124
Validation loss: 2.4626086741961366

Epoch: 5| Step: 1
Training loss: 2.545885794973644
Validation loss: 2.4701040514176453

Epoch: 5| Step: 2
Training loss: 2.728080348887131
Validation loss: 2.466503892072825

Epoch: 5| Step: 3
Training loss: 2.6597269975062154
Validation loss: 2.4702692105680324

Epoch: 5| Step: 4
Training loss: 2.0698981104298433
Validation loss: 2.4627784423125423

Epoch: 5| Step: 5
Training loss: 2.7143669313455354
Validation loss: 2.4704428675186434

Epoch: 5| Step: 6
Training loss: 2.4358951469493
Validation loss: 2.480696463958342

Epoch: 5| Step: 7
Training loss: 2.1987078600082617
Validation loss: 2.4793114973820756

Epoch: 5| Step: 8
Training loss: 1.690011028276384
Validation loss: 2.475313969005561

Epoch: 5| Step: 9
Training loss: 2.708143129761275
Validation loss: 2.4829192905014197

Epoch: 5| Step: 10
Training loss: 2.96552430636154
Validation loss: 2.48801516113742

Epoch: 5| Step: 11
Training loss: 2.940542552736751
Validation loss: 2.4846478798189886

Epoch: 185| Step: 0
Training loss: 2.6073328124419457
Validation loss: 2.483468730140207

Epoch: 5| Step: 1
Training loss: 2.0725187242350036
Validation loss: 2.4749446080813473

Epoch: 5| Step: 2
Training loss: 2.7851307400983742
Validation loss: 2.482378435292553

Epoch: 5| Step: 3
Training loss: 2.276242442990474
Validation loss: 2.484565535622398

Epoch: 5| Step: 4
Training loss: 3.246577588320862
Validation loss: 2.482716060467524

Epoch: 5| Step: 5
Training loss: 2.566490044234686
Validation loss: 2.477367093928529

Epoch: 5| Step: 6
Training loss: 2.0077731948745816
Validation loss: 2.4746507271370306

Epoch: 5| Step: 7
Training loss: 2.583434215749829
Validation loss: 2.477603384748497

Epoch: 5| Step: 8
Training loss: 2.2390715849772618
Validation loss: 2.4751292111483765

Epoch: 5| Step: 9
Training loss: 2.310283216974286
Validation loss: 2.4797338603572894

Epoch: 5| Step: 10
Training loss: 2.621073192623836
Validation loss: 2.469499381725725

Epoch: 5| Step: 11
Training loss: 0.9879971122139647
Validation loss: 2.462164005038818

Epoch: 186| Step: 0
Training loss: 2.6061503878431833
Validation loss: 2.474585721957425

Epoch: 5| Step: 1
Training loss: 2.793328364769182
Validation loss: 2.4696272285408765

Epoch: 5| Step: 2
Training loss: 2.5399317735234646
Validation loss: 2.484407764594632

Epoch: 5| Step: 3
Training loss: 3.063397645769873
Validation loss: 2.4806959673923705

Epoch: 5| Step: 4
Training loss: 1.988290003549309
Validation loss: 2.481108323191424

Epoch: 5| Step: 5
Training loss: 2.6425364421255244
Validation loss: 2.479444144986607

Epoch: 5| Step: 6
Training loss: 2.718202294614406
Validation loss: 2.477778207566728

Epoch: 5| Step: 7
Training loss: 2.0430699281455653
Validation loss: 2.4733713410671223

Epoch: 5| Step: 8
Training loss: 2.245239944719226
Validation loss: 2.474173262779957

Epoch: 5| Step: 9
Training loss: 2.2626620155620856
Validation loss: 2.4810480797936982

Epoch: 5| Step: 10
Training loss: 1.9718065301339918
Validation loss: 2.4753767036735583

Epoch: 5| Step: 11
Training loss: 3.7712406057936834
Validation loss: 2.485920657171372

Epoch: 187| Step: 0
Training loss: 3.1220884874451427
Validation loss: 2.4742240816570202

Epoch: 5| Step: 1
Training loss: 2.5930604132908894
Validation loss: 2.4729972310964032

Epoch: 5| Step: 2
Training loss: 2.2222053593419613
Validation loss: 2.4687230837034693

Epoch: 5| Step: 3
Training loss: 2.0301918207876604
Validation loss: 2.470795158511608

Epoch: 5| Step: 4
Training loss: 2.766325436273281
Validation loss: 2.4624057729156217

Epoch: 5| Step: 5
Training loss: 1.991960579907217
Validation loss: 2.467104604921755

Epoch: 5| Step: 6
Training loss: 2.4322678580470067
Validation loss: 2.4601752377267236

Epoch: 5| Step: 7
Training loss: 2.5292087377561083
Validation loss: 2.469504542871604

Epoch: 5| Step: 8
Training loss: 1.879074247784404
Validation loss: 2.467825764870036

Epoch: 5| Step: 9
Training loss: 2.3307403621014
Validation loss: 2.460992725701285

Epoch: 5| Step: 10
Training loss: 3.1147737646839735
Validation loss: 2.465466450394944

Epoch: 5| Step: 11
Training loss: 2.284058396803761
Validation loss: 2.4659027750560036

Epoch: 188| Step: 0
Training loss: 2.1877301776220315
Validation loss: 2.4672651855659047

Epoch: 5| Step: 1
Training loss: 1.952202540950804
Validation loss: 2.4758840808998146

Epoch: 5| Step: 2
Training loss: 2.6330286497592237
Validation loss: 2.4806261107824406

Epoch: 5| Step: 3
Training loss: 2.6786190827989826
Validation loss: 2.4774213198304236

Epoch: 5| Step: 4
Training loss: 2.8503341746585718
Validation loss: 2.4786742560182575

Epoch: 5| Step: 5
Training loss: 2.6785327436287587
Validation loss: 2.485721231384575

Epoch: 5| Step: 6
Training loss: 2.439180235186929
Validation loss: 2.4725984362713023

Epoch: 5| Step: 7
Training loss: 2.243446448574347
Validation loss: 2.479753069620649

Epoch: 5| Step: 8
Training loss: 2.9805415433341182
Validation loss: 2.4789069457743946

Epoch: 5| Step: 9
Training loss: 2.3432272773209926
Validation loss: 2.472373624843459

Epoch: 5| Step: 10
Training loss: 2.3415778712296693
Validation loss: 2.4726776576107308

Epoch: 5| Step: 11
Training loss: 2.1523745442868543
Validation loss: 2.467889841139907

Epoch: 189| Step: 0
Training loss: 2.2531871474923597
Validation loss: 2.4749637220594582

Epoch: 5| Step: 1
Training loss: 2.463351467497705
Validation loss: 2.472834692648579

Epoch: 5| Step: 2
Training loss: 3.1213991400087813
Validation loss: 2.47631403481909

Epoch: 5| Step: 3
Training loss: 2.303306967846158
Validation loss: 2.465129245319112

Epoch: 5| Step: 4
Training loss: 2.127563949323139
Validation loss: 2.4622271352715868

Epoch: 5| Step: 5
Training loss: 2.2638801959390302
Validation loss: 2.480085007828277

Epoch: 5| Step: 6
Training loss: 2.1771463874799712
Validation loss: 2.4775185890539695

Epoch: 5| Step: 7
Training loss: 2.7916236039061983
Validation loss: 2.4733110337288906

Epoch: 5| Step: 8
Training loss: 2.4599292445668324
Validation loss: 2.4758951710036463

Epoch: 5| Step: 9
Training loss: 2.4636461640361067
Validation loss: 2.482980324682972

Epoch: 5| Step: 10
Training loss: 2.5931101549835684
Validation loss: 2.4833135676610776

Epoch: 5| Step: 11
Training loss: 2.7052469028743893
Validation loss: 2.4802451526056295

Epoch: 190| Step: 0
Training loss: 2.4484764811730217
Validation loss: 2.4853823876608394

Epoch: 5| Step: 1
Training loss: 2.7634760379487453
Validation loss: 2.483443605424989

Epoch: 5| Step: 2
Training loss: 2.515668501388968
Validation loss: 2.476875133015464

Epoch: 5| Step: 3
Training loss: 2.3076114016802203
Validation loss: 2.4809668854270797

Epoch: 5| Step: 4
Training loss: 2.518987363322486
Validation loss: 2.47488356839803

Epoch: 5| Step: 5
Training loss: 2.3836027242115865
Validation loss: 2.4702319131857005

Epoch: 5| Step: 6
Training loss: 2.5709196260664875
Validation loss: 2.4774694617166744

Epoch: 5| Step: 7
Training loss: 2.5470227157724064
Validation loss: 2.479212040579463

Epoch: 5| Step: 8
Training loss: 1.8865452404284795
Validation loss: 2.4724351765023127

Epoch: 5| Step: 9
Training loss: 2.4323905799461247
Validation loss: 2.465736437085495

Epoch: 5| Step: 10
Training loss: 2.5578079065131325
Validation loss: 2.4646704643585866

Epoch: 5| Step: 11
Training loss: 3.183810323825932
Validation loss: 2.4748858081920657

Epoch: 191| Step: 0
Training loss: 2.4659536435178095
Validation loss: 2.469217521726557

Epoch: 5| Step: 1
Training loss: 2.478420391011686
Validation loss: 2.4689747188999602

Epoch: 5| Step: 2
Training loss: 2.548100650494173
Validation loss: 2.4663088797326993

Epoch: 5| Step: 3
Training loss: 3.0336456270814574
Validation loss: 2.4635995141644584

Epoch: 5| Step: 4
Training loss: 2.221716066838139
Validation loss: 2.4651478954063277

Epoch: 5| Step: 5
Training loss: 2.67761826767789
Validation loss: 2.4623253193975287

Epoch: 5| Step: 6
Training loss: 2.432111310024055
Validation loss: 2.4605925504937916

Epoch: 5| Step: 7
Training loss: 2.5360064616436873
Validation loss: 2.4623944768225883

Epoch: 5| Step: 8
Training loss: 2.3377220456333943
Validation loss: 2.46498240117696

Epoch: 5| Step: 9
Training loss: 2.0776807267115025
Validation loss: 2.4720149883525213

Epoch: 5| Step: 10
Training loss: 2.1777457609007285
Validation loss: 2.4675355410890805

Epoch: 5| Step: 11
Training loss: 3.205726720631852
Validation loss: 2.4697437720694073

Epoch: 192| Step: 0
Training loss: 2.2161281299593707
Validation loss: 2.471908480372879

Epoch: 5| Step: 1
Training loss: 1.9974564829491617
Validation loss: 2.4723406887125896

Epoch: 5| Step: 2
Training loss: 2.3239180682934735
Validation loss: 2.4720853937040697

Epoch: 5| Step: 3
Training loss: 2.7769351020128314
Validation loss: 2.4653239641355396

Epoch: 5| Step: 4
Training loss: 3.04035086890755
Validation loss: 2.4697674594166386

Epoch: 5| Step: 5
Training loss: 2.458438052086085
Validation loss: 2.4689805973375214

Epoch: 5| Step: 6
Training loss: 2.53642290679401
Validation loss: 2.47654085922012

Epoch: 5| Step: 7
Training loss: 2.4024460685464244
Validation loss: 2.466319670520459

Epoch: 5| Step: 8
Training loss: 2.051010264370518
Validation loss: 2.4637460254215853

Epoch: 5| Step: 9
Training loss: 2.163031266944559
Validation loss: 2.469225391054821

Epoch: 5| Step: 10
Training loss: 2.6517275739188855
Validation loss: 2.460305658598483

Epoch: 5| Step: 11
Training loss: 3.847165706753444
Validation loss: 2.467138500826285

Epoch: 193| Step: 0
Training loss: 1.998899753249587
Validation loss: 2.4718519713707154

Epoch: 5| Step: 1
Training loss: 2.4789598095503127
Validation loss: 2.4820064674319307

Epoch: 5| Step: 2
Training loss: 2.96249501674571
Validation loss: 2.502665235480216

Epoch: 5| Step: 3
Training loss: 2.708597101914208
Validation loss: 2.5052314500806214

Epoch: 5| Step: 4
Training loss: 2.6708955810085273
Validation loss: 2.48525316284685

Epoch: 5| Step: 5
Training loss: 2.504520715787375
Validation loss: 2.476695385084428

Epoch: 5| Step: 6
Training loss: 2.1928795198742868
Validation loss: 2.4739228309627106

Epoch: 5| Step: 7
Training loss: 2.660503706457936
Validation loss: 2.4698567987737925

Epoch: 5| Step: 8
Training loss: 1.9193187554086166
Validation loss: 2.4760999638733483

Epoch: 5| Step: 9
Training loss: 2.124648121141916
Validation loss: 2.470784017371985

Epoch: 5| Step: 10
Training loss: 2.8714536272648936
Validation loss: 2.4700246087803355

Epoch: 5| Step: 11
Training loss: 3.273170187148179
Validation loss: 2.4785471924960176

Epoch: 194| Step: 0
Training loss: 1.9278119196267134
Validation loss: 2.4695189421299877

Epoch: 5| Step: 1
Training loss: 2.9535244464679464
Validation loss: 2.4790658142242084

Epoch: 5| Step: 2
Training loss: 2.2130024571118545
Validation loss: 2.473541057263911

Epoch: 5| Step: 3
Training loss: 2.599096739198196
Validation loss: 2.4772352193451184

Epoch: 5| Step: 4
Training loss: 2.5226543144154854
Validation loss: 2.473045471155659

Epoch: 5| Step: 5
Training loss: 2.631912575704661
Validation loss: 2.477967618776873

Epoch: 5| Step: 6
Training loss: 2.5692405436491095
Validation loss: 2.4759443616757943

Epoch: 5| Step: 7
Training loss: 2.942597045594537
Validation loss: 2.4633924642037908

Epoch: 5| Step: 8
Training loss: 2.1053892555870766
Validation loss: 2.475561523317114

Epoch: 5| Step: 9
Training loss: 2.3941161152112094
Validation loss: 2.4669155234272018

Epoch: 5| Step: 10
Training loss: 2.674121024206966
Validation loss: 2.4604769523033143

Epoch: 5| Step: 11
Training loss: 3.2658957045208314
Validation loss: 2.4686131218093537

Epoch: 195| Step: 0
Training loss: 2.663512052794825
Validation loss: 2.466743786810157

Epoch: 5| Step: 1
Training loss: 2.5097537504278913
Validation loss: 2.4538029464875515

Epoch: 5| Step: 2
Training loss: 1.9369253106120976
Validation loss: 2.458964902494178

Epoch: 5| Step: 3
Training loss: 2.6741973421408405
Validation loss: 2.4734127058697037

Epoch: 5| Step: 4
Training loss: 2.5162990448933726
Validation loss: 2.467120546282451

Epoch: 5| Step: 5
Training loss: 2.8392217445536185
Validation loss: 2.462840524194635

Epoch: 5| Step: 6
Training loss: 2.2337835636189642
Validation loss: 2.461628747164606

Epoch: 5| Step: 7
Training loss: 2.141854037785312
Validation loss: 2.476476457226296

Epoch: 5| Step: 8
Training loss: 2.135552291905113
Validation loss: 2.47562032722097

Epoch: 5| Step: 9
Training loss: 2.622097499713569
Validation loss: 2.4761711236547694

Epoch: 5| Step: 10
Training loss: 2.755090856421296
Validation loss: 2.4690431670263373

Epoch: 5| Step: 11
Training loss: 3.318042652446926
Validation loss: 2.4643353735452953

Epoch: 196| Step: 0
Training loss: 2.8113281351767663
Validation loss: 2.465140367687156

Epoch: 5| Step: 1
Training loss: 2.3378398383033225
Validation loss: 2.4698330599950755

Epoch: 5| Step: 2
Training loss: 2.7355973481595064
Validation loss: 2.4741703317391717

Epoch: 5| Step: 3
Training loss: 2.8574515788997785
Validation loss: 2.5014597366323565

Epoch: 5| Step: 4
Training loss: 2.0848378915682275
Validation loss: 2.48204917320894

Epoch: 5| Step: 5
Training loss: 2.3815390263766987
Validation loss: 2.4829952959325166

Epoch: 5| Step: 6
Training loss: 2.1950943047635607
Validation loss: 2.472260574574344

Epoch: 5| Step: 7
Training loss: 2.4718212869356755
Validation loss: 2.489830999677888

Epoch: 5| Step: 8
Training loss: 2.165678226758132
Validation loss: 2.46990633091944

Epoch: 5| Step: 9
Training loss: 2.7085910283271137
Validation loss: 2.4716115173721684

Epoch: 5| Step: 10
Training loss: 2.6557198388089907
Validation loss: 2.473352026009763

Epoch: 5| Step: 11
Training loss: 2.585106661457287
Validation loss: 2.4659038466603014

Epoch: 197| Step: 0
Training loss: 2.5777962214898964
Validation loss: 2.47296975444917

Epoch: 5| Step: 1
Training loss: 2.4531331639245124
Validation loss: 2.473862701709265

Epoch: 5| Step: 2
Training loss: 2.014675537755502
Validation loss: 2.4704578262810433

Epoch: 5| Step: 3
Training loss: 2.3173227282297173
Validation loss: 2.4714436483044704

Epoch: 5| Step: 4
Training loss: 2.77480658467152
Validation loss: 2.4677656762570046

Epoch: 5| Step: 5
Training loss: 2.80754177887862
Validation loss: 2.4776173861037796

Epoch: 5| Step: 6
Training loss: 2.032478547868682
Validation loss: 2.4711635517429102

Epoch: 5| Step: 7
Training loss: 2.4894942795748474
Validation loss: 2.482382012944351

Epoch: 5| Step: 8
Training loss: 2.454966443176277
Validation loss: 2.460749720922628

Epoch: 5| Step: 9
Training loss: 2.4433880628186966
Validation loss: 2.463645510806903

Epoch: 5| Step: 10
Training loss: 2.8756931961950634
Validation loss: 2.4608977582033575

Epoch: 5| Step: 11
Training loss: 1.4402577029212427
Validation loss: 2.4614591419048057

Epoch: 198| Step: 0
Training loss: 3.0534514050649735
Validation loss: 2.4565707261836183

Epoch: 5| Step: 1
Training loss: 2.017288467870612
Validation loss: 2.4638428527460876

Epoch: 5| Step: 2
Training loss: 2.2938355557235703
Validation loss: 2.4689755598272045

Epoch: 5| Step: 3
Training loss: 2.5822294912256005
Validation loss: 2.4602550589718093

Epoch: 5| Step: 4
Training loss: 2.5574669140179287
Validation loss: 2.4645033801361254

Epoch: 5| Step: 5
Training loss: 2.256387122047867
Validation loss: 2.462564981800521

Epoch: 5| Step: 6
Training loss: 2.5544309341433267
Validation loss: 2.467555815552739

Epoch: 5| Step: 7
Training loss: 2.2269669014946727
Validation loss: 2.471184061759703

Epoch: 5| Step: 8
Training loss: 2.784542406660338
Validation loss: 2.466741211404851

Epoch: 5| Step: 9
Training loss: 2.675299340728061
Validation loss: 2.458171428316642

Epoch: 5| Step: 10
Training loss: 2.2561400664115645
Validation loss: 2.4798148767694337

Epoch: 5| Step: 11
Training loss: 0.9522432720200027
Validation loss: 2.4755562383612078

Epoch: 199| Step: 0
Training loss: 2.7229114122833793
Validation loss: 2.471398168613617

Epoch: 5| Step: 1
Training loss: 2.177413136690985
Validation loss: 2.4753131543112747

Epoch: 5| Step: 2
Training loss: 2.4317823008739894
Validation loss: 2.473037846967083

Epoch: 5| Step: 3
Training loss: 2.598007384926253
Validation loss: 2.474261126141809

Epoch: 5| Step: 4
Training loss: 2.703625406682783
Validation loss: 2.4754469010474134

Epoch: 5| Step: 5
Training loss: 2.6613152173724672
Validation loss: 2.473563917073828

Epoch: 5| Step: 6
Training loss: 2.447069018626444
Validation loss: 2.476986825654877

Epoch: 5| Step: 7
Training loss: 2.5005854874711577
Validation loss: 2.463579997489653

Epoch: 5| Step: 8
Training loss: 2.2203231392484035
Validation loss: 2.46673913335889

Epoch: 5| Step: 9
Training loss: 2.4161404551990078
Validation loss: 2.477766620719444

Epoch: 5| Step: 10
Training loss: 2.2228768881110996
Validation loss: 2.4695058060030908

Epoch: 5| Step: 11
Training loss: 2.5287064382333786
Validation loss: 2.467807614052457

Epoch: 200| Step: 0
Training loss: 2.1873786892632285
Validation loss: 2.474364977427116

Epoch: 5| Step: 1
Training loss: 2.144168343610685
Validation loss: 2.4654938474777075

Epoch: 5| Step: 2
Training loss: 2.6109404293936476
Validation loss: 2.4687631019212426

Epoch: 5| Step: 3
Training loss: 2.2450102473239624
Validation loss: 2.4779558403836166

Epoch: 5| Step: 4
Training loss: 2.2368037754943813
Validation loss: 2.471251013599137

Epoch: 5| Step: 5
Training loss: 2.35936994741543
Validation loss: 2.4773448386300707

Epoch: 5| Step: 6
Training loss: 2.7023407785267524
Validation loss: 2.4856485405480964

Epoch: 5| Step: 7
Training loss: 2.3734203908076346
Validation loss: 2.475681822234713

Epoch: 5| Step: 8
Training loss: 2.4962067436707276
Validation loss: 2.463510994320366

Epoch: 5| Step: 9
Training loss: 3.2460793541911532
Validation loss: 2.474175930827078

Epoch: 5| Step: 10
Training loss: 2.4360375541022226
Validation loss: 2.4679941476946237

Epoch: 5| Step: 11
Training loss: 2.3711255242671263
Validation loss: 2.4718647755292045

Epoch: 201| Step: 0
Training loss: 2.682603945038074
Validation loss: 2.47186007344481

Epoch: 5| Step: 1
Training loss: 2.443330003789044
Validation loss: 2.47049059852186

Epoch: 5| Step: 2
Training loss: 2.875251593154587
Validation loss: 2.474144695022105

Epoch: 5| Step: 3
Training loss: 2.7923823241162493
Validation loss: 2.4963371703404116

Epoch: 5| Step: 4
Training loss: 2.060573371608372
Validation loss: 2.4886084939748194

Epoch: 5| Step: 5
Training loss: 2.601576704839927
Validation loss: 2.4896476662808356

Epoch: 5| Step: 6
Training loss: 2.212772537945891
Validation loss: 2.467822391541229

Epoch: 5| Step: 7
Training loss: 2.713080183290412
Validation loss: 2.4699769652987547

Epoch: 5| Step: 8
Training loss: 2.305130014124809
Validation loss: 2.467210730406465

Epoch: 5| Step: 9
Training loss: 2.341717767214453
Validation loss: 2.4693685493104987

Epoch: 5| Step: 10
Training loss: 2.2952107738703384
Validation loss: 2.4704733720386787

Epoch: 5| Step: 11
Training loss: 2.391252223490884
Validation loss: 2.473530149381351

Epoch: 202| Step: 0
Training loss: 2.667261613599397
Validation loss: 2.4724575724238456

Epoch: 5| Step: 1
Training loss: 2.4876631563439515
Validation loss: 2.4715125324945837

Epoch: 5| Step: 2
Training loss: 3.2533087393607563
Validation loss: 2.477090705035004

Epoch: 5| Step: 3
Training loss: 2.322758371293927
Validation loss: 2.474515588473997

Epoch: 5| Step: 4
Training loss: 2.729142856251369
Validation loss: 2.47483505107164

Epoch: 5| Step: 5
Training loss: 2.7457492226977527
Validation loss: 2.470354001756045

Epoch: 5| Step: 6
Training loss: 2.1661868909127633
Validation loss: 2.470349521990902

Epoch: 5| Step: 7
Training loss: 2.4622895901243553
Validation loss: 2.4599217412616636

Epoch: 5| Step: 8
Training loss: 1.9945888034333026
Validation loss: 2.4616576417702873

Epoch: 5| Step: 9
Training loss: 2.3768763909848656
Validation loss: 2.4625725496645576

Epoch: 5| Step: 10
Training loss: 1.9143637906604751
Validation loss: 2.471955009609147

Epoch: 5| Step: 11
Training loss: 2.7009803334451945
Validation loss: 2.468797188319937

Epoch: 203| Step: 0
Training loss: 2.3310853710800004
Validation loss: 2.4766381509901154

Epoch: 5| Step: 1
Training loss: 2.9126549151564722
Validation loss: 2.4873572150421355

Epoch: 5| Step: 2
Training loss: 2.3631664405867663
Validation loss: 2.482630116922195

Epoch: 5| Step: 3
Training loss: 2.379467226229578
Validation loss: 2.493553504755327

Epoch: 5| Step: 4
Training loss: 2.7863380097171504
Validation loss: 2.4908352355103194

Epoch: 5| Step: 5
Training loss: 2.1210358613546796
Validation loss: 2.487845370184088

Epoch: 5| Step: 6
Training loss: 2.262884758537191
Validation loss: 2.473809401730773

Epoch: 5| Step: 7
Training loss: 2.23086186300148
Validation loss: 2.471552429178701

Epoch: 5| Step: 8
Training loss: 2.9332796987774223
Validation loss: 2.4721705806948684

Epoch: 5| Step: 9
Training loss: 2.5507749875796497
Validation loss: 2.4680208747095342

Epoch: 5| Step: 10
Training loss: 2.5165306972463313
Validation loss: 2.469884297985347

Epoch: 5| Step: 11
Training loss: 2.8142366769486635
Validation loss: 2.4742495328616183

Epoch: 204| Step: 0
Training loss: 3.0091457830264488
Validation loss: 2.4771828020004034

Epoch: 5| Step: 1
Training loss: 2.3130708969208293
Validation loss: 2.473124025441221

Epoch: 5| Step: 2
Training loss: 2.6005529329251886
Validation loss: 2.4848844257818623

Epoch: 5| Step: 3
Training loss: 2.8327097112961788
Validation loss: 2.4793273021577287

Epoch: 5| Step: 4
Training loss: 1.8174357460344355
Validation loss: 2.486060652288863

Epoch: 5| Step: 5
Training loss: 2.634406085752935
Validation loss: 2.4878179217613585

Epoch: 5| Step: 6
Training loss: 2.4264064603549116
Validation loss: 2.489542922220026

Epoch: 5| Step: 7
Training loss: 2.3590525223600203
Validation loss: 2.4838865667720165

Epoch: 5| Step: 8
Training loss: 2.3887022177140684
Validation loss: 2.4766546928181348

Epoch: 5| Step: 9
Training loss: 2.203836853600742
Validation loss: 2.476938738558318

Epoch: 5| Step: 10
Training loss: 2.8860780988397625
Validation loss: 2.4755858452048902

Epoch: 5| Step: 11
Training loss: 2.488568299892036
Validation loss: 2.468257887196169

Epoch: 205| Step: 0
Training loss: 2.0451523615406466
Validation loss: 2.4599419775183327

Epoch: 5| Step: 1
Training loss: 2.5437741740059874
Validation loss: 2.4635814289865507

Epoch: 5| Step: 2
Training loss: 2.5387743038064103
Validation loss: 2.470941170745641

Epoch: 5| Step: 3
Training loss: 3.082412599436763
Validation loss: 2.4555275929725466

Epoch: 5| Step: 4
Training loss: 2.8977908829559755
Validation loss: 2.4606782766589506

Epoch: 5| Step: 5
Training loss: 2.0868417444404144
Validation loss: 2.4577084261618354

Epoch: 5| Step: 6
Training loss: 1.862408703608183
Validation loss: 2.4663114978826304

Epoch: 5| Step: 7
Training loss: 2.7092323767270234
Validation loss: 2.4632377571470983

Epoch: 5| Step: 8
Training loss: 2.2946348100047205
Validation loss: 2.468719399741413

Epoch: 5| Step: 9
Training loss: 2.4667670096358676
Validation loss: 2.4675749223511287

Epoch: 5| Step: 10
Training loss: 2.5467549863283243
Validation loss: 2.4644023300501354

Epoch: 5| Step: 11
Training loss: 1.6941642564317652
Validation loss: 2.4628532420948197

Epoch: 206| Step: 0
Training loss: 2.4282618814226993
Validation loss: 2.4554566521730403

Epoch: 5| Step: 1
Training loss: 2.8268158132263834
Validation loss: 2.466618172763854

Epoch: 5| Step: 2
Training loss: 2.73238880500114
Validation loss: 2.4696227836600873

Epoch: 5| Step: 3
Training loss: 2.4425533438004563
Validation loss: 2.4728206642132124

Epoch: 5| Step: 4
Training loss: 2.590019300676108
Validation loss: 2.4706584740425015

Epoch: 5| Step: 5
Training loss: 2.886583131487433
Validation loss: 2.4680264897609656

Epoch: 5| Step: 6
Training loss: 2.1173753267987547
Validation loss: 2.4643254448009233

Epoch: 5| Step: 7
Training loss: 2.3620203611124553
Validation loss: 2.458861558274564

Epoch: 5| Step: 8
Training loss: 2.432007200500219
Validation loss: 2.4680067102327117

Epoch: 5| Step: 9
Training loss: 1.889378538743572
Validation loss: 2.4706412567715517

Epoch: 5| Step: 10
Training loss: 2.416431832139579
Validation loss: 2.47982869338192

Epoch: 5| Step: 11
Training loss: 3.011980136952757
Validation loss: 2.481876948764215

Epoch: 207| Step: 0
Training loss: 2.395800106536891
Validation loss: 2.479870196837127

Epoch: 5| Step: 1
Training loss: 3.039757342692606
Validation loss: 2.473969406638544

Epoch: 5| Step: 2
Training loss: 2.6512015443768604
Validation loss: 2.475203605587192

Epoch: 5| Step: 3
Training loss: 2.6442189335057993
Validation loss: 2.4710825954124793

Epoch: 5| Step: 4
Training loss: 2.9651772935941434
Validation loss: 2.469047868440097

Epoch: 5| Step: 5
Training loss: 2.4545639580051666
Validation loss: 2.461468210468232

Epoch: 5| Step: 6
Training loss: 2.1734460870283843
Validation loss: 2.469731956466993

Epoch: 5| Step: 7
Training loss: 2.1408371646184063
Validation loss: 2.4732792668546812

Epoch: 5| Step: 8
Training loss: 2.317843269677768
Validation loss: 2.4718851913132744

Epoch: 5| Step: 9
Training loss: 1.9809847127641345
Validation loss: 2.4772942040737087

Epoch: 5| Step: 10
Training loss: 2.2985807559597946
Validation loss: 2.4755234328586107

Epoch: 5| Step: 11
Training loss: 2.6009364935760586
Validation loss: 2.4793492712095153

Epoch: 208| Step: 0
Training loss: 2.139373301963121
Validation loss: 2.47660207867209

Epoch: 5| Step: 1
Training loss: 2.2845437296745734
Validation loss: 2.4844757835370803

Epoch: 5| Step: 2
Training loss: 2.6652481259893235
Validation loss: 2.483273799927229

Epoch: 5| Step: 3
Training loss: 2.3147427792113606
Validation loss: 2.48258909177004

Epoch: 5| Step: 4
Training loss: 2.6521438276089437
Validation loss: 2.4913436393729635

Epoch: 5| Step: 5
Training loss: 2.302020582721872
Validation loss: 2.483245104837491

Epoch: 5| Step: 6
Training loss: 2.363073418676547
Validation loss: 2.4839497008255385

Epoch: 5| Step: 7
Training loss: 2.9652749050899727
Validation loss: 2.4865280494510333

Epoch: 5| Step: 8
Training loss: 2.743902468952706
Validation loss: 2.485609163875393

Epoch: 5| Step: 9
Training loss: 2.788239002201647
Validation loss: 2.484491575453021

Epoch: 5| Step: 10
Training loss: 2.411199557190559
Validation loss: 2.4857420529000605

Epoch: 5| Step: 11
Training loss: 1.3957156753296063
Validation loss: 2.4796723837052204

Epoch: 209| Step: 0
Training loss: 2.2163347880178494
Validation loss: 2.468097258439515

Epoch: 5| Step: 1
Training loss: 2.565585349144779
Validation loss: 2.4790842913451243

Epoch: 5| Step: 2
Training loss: 2.670007867551492
Validation loss: 2.4806300313585714

Epoch: 5| Step: 3
Training loss: 2.177896618465876
Validation loss: 2.4635596056252105

Epoch: 5| Step: 4
Training loss: 2.937509252655391
Validation loss: 2.4743341595467916

Epoch: 5| Step: 5
Training loss: 2.8100722112913967
Validation loss: 2.472040554728597

Epoch: 5| Step: 6
Training loss: 2.230382486736276
Validation loss: 2.4756371246403095

Epoch: 5| Step: 7
Training loss: 1.9249063791075287
Validation loss: 2.486366121851316

Epoch: 5| Step: 8
Training loss: 2.634230325330507
Validation loss: 2.50759311164022

Epoch: 5| Step: 9
Training loss: 3.0677523045823807
Validation loss: 2.495754352194493

Epoch: 5| Step: 10
Training loss: 2.0060393225789244
Validation loss: 2.495597798044538

Epoch: 5| Step: 11
Training loss: 2.3994957394141787
Validation loss: 2.491192741731343

Epoch: 210| Step: 0
Training loss: 2.42662144360306
Validation loss: 2.474363367487425

Epoch: 5| Step: 1
Training loss: 2.135832161527866
Validation loss: 2.4693969048001856

Epoch: 5| Step: 2
Training loss: 2.2648236139934697
Validation loss: 2.479988946841973

Epoch: 5| Step: 3
Training loss: 2.0335579305125506
Validation loss: 2.489516264651834

Epoch: 5| Step: 4
Training loss: 3.1198957337783644
Validation loss: 2.489637255915984

Epoch: 5| Step: 5
Training loss: 2.142877215336839
Validation loss: 2.495849605394749

Epoch: 5| Step: 6
Training loss: 2.6382530439076053
Validation loss: 2.501854963359764

Epoch: 5| Step: 7
Training loss: 2.1563701872570413
Validation loss: 2.500801573836321

Epoch: 5| Step: 8
Training loss: 2.6441426519903777
Validation loss: 2.5009616154754464

Epoch: 5| Step: 9
Training loss: 3.0292613004640683
Validation loss: 2.4819016330404016

Epoch: 5| Step: 10
Training loss: 2.7934157647357245
Validation loss: 2.4933360212697453

Epoch: 5| Step: 11
Training loss: 1.8782514355035944
Validation loss: 2.4873878356271666

Epoch: 211| Step: 0
Training loss: 2.599722179828545
Validation loss: 2.484289631686403

Epoch: 5| Step: 1
Training loss: 2.207684715552402
Validation loss: 2.4873617160960704

Epoch: 5| Step: 2
Training loss: 2.2603473096013302
Validation loss: 2.483257858251644

Epoch: 5| Step: 3
Training loss: 2.4751202448139447
Validation loss: 2.4869985023798753

Epoch: 5| Step: 4
Training loss: 2.3390391499609513
Validation loss: 2.4744453767238395

Epoch: 5| Step: 5
Training loss: 2.944119239538143
Validation loss: 2.49348182909418

Epoch: 5| Step: 6
Training loss: 2.4022727893800795
Validation loss: 2.4776974312789872

Epoch: 5| Step: 7
Training loss: 2.111006833172486
Validation loss: 2.4687137560859846

Epoch: 5| Step: 8
Training loss: 2.4599860395640163
Validation loss: 2.4746206835794724

Epoch: 5| Step: 9
Training loss: 2.60102531683604
Validation loss: 2.474845461484045

Epoch: 5| Step: 10
Training loss: 2.488124297505337
Validation loss: 2.4659059818103324

Epoch: 5| Step: 11
Training loss: 3.700095824985443
Validation loss: 2.4804320004762093

Epoch: 212| Step: 0
Training loss: 2.213360648139867
Validation loss: 2.477613412645874

Epoch: 5| Step: 1
Training loss: 2.289269760174863
Validation loss: 2.480520048637289

Epoch: 5| Step: 2
Training loss: 3.2099686620495738
Validation loss: 2.4797383952791794

Epoch: 5| Step: 3
Training loss: 2.605503339409175
Validation loss: 2.4809445302831374

Epoch: 5| Step: 4
Training loss: 2.6400861020930444
Validation loss: 2.4729879437024294

Epoch: 5| Step: 5
Training loss: 2.39085387088025
Validation loss: 2.4792465202443292

Epoch: 5| Step: 6
Training loss: 2.9102602946480545
Validation loss: 2.469328864756112

Epoch: 5| Step: 7
Training loss: 2.0242181987754337
Validation loss: 2.487598938467964

Epoch: 5| Step: 8
Training loss: 2.5115756028172815
Validation loss: 2.4701637332653386

Epoch: 5| Step: 9
Training loss: 1.9606570465027418
Validation loss: 2.485849954313169

Epoch: 5| Step: 10
Training loss: 1.9460034349848354
Validation loss: 2.4836735724875063

Epoch: 5| Step: 11
Training loss: 2.9607018852598697
Validation loss: 2.4812201455704015

Epoch: 213| Step: 0
Training loss: 2.462694685157843
Validation loss: 2.491100548591741

Epoch: 5| Step: 1
Training loss: 2.5918172966297
Validation loss: 2.4857348233379617

Epoch: 5| Step: 2
Training loss: 2.9679191631403214
Validation loss: 2.487690905972176

Epoch: 5| Step: 3
Training loss: 2.1896456413465555
Validation loss: 2.490494235573478

Epoch: 5| Step: 4
Training loss: 2.3435614955118735
Validation loss: 2.4836395142658616

Epoch: 5| Step: 5
Training loss: 2.6644524878934694
Validation loss: 2.487909996966322

Epoch: 5| Step: 6
Training loss: 2.5669215133610175
Validation loss: 2.4785039393933848

Epoch: 5| Step: 7
Training loss: 2.2462387436216944
Validation loss: 2.4851587047083097

Epoch: 5| Step: 8
Training loss: 2.0867856476635143
Validation loss: 2.483570552436399

Epoch: 5| Step: 9
Training loss: 2.6007651633638593
Validation loss: 2.48326660318347

Epoch: 5| Step: 10
Training loss: 2.3143840022971798
Validation loss: 2.490220037680847

Epoch: 5| Step: 11
Training loss: 2.6138624334758847
Validation loss: 2.4726906885015767

Epoch: 214| Step: 0
Training loss: 2.7361480196180925
Validation loss: 2.487053936272085

Epoch: 5| Step: 1
Training loss: 1.860500604060956
Validation loss: 2.4843961886735957

Epoch: 5| Step: 2
Training loss: 2.7152174877639865
Validation loss: 2.482041640715702

Epoch: 5| Step: 3
Training loss: 1.7824776417746488
Validation loss: 2.4808096683940195

Epoch: 5| Step: 4
Training loss: 2.932645967172719
Validation loss: 2.4855171313342925

Epoch: 5| Step: 5
Training loss: 2.593159895722108
Validation loss: 2.4777312825052484

Epoch: 5| Step: 6
Training loss: 2.8223906492636313
Validation loss: 2.4797433067665002

Epoch: 5| Step: 7
Training loss: 2.162346004228832
Validation loss: 2.4744381302150282

Epoch: 5| Step: 8
Training loss: 2.295526640727259
Validation loss: 2.484368198313489

Epoch: 5| Step: 9
Training loss: 2.395016594592364
Validation loss: 2.474186853930547

Epoch: 5| Step: 10
Training loss: 2.541273357623639
Validation loss: 2.4805145019156543

Epoch: 5| Step: 11
Training loss: 2.1217849195458083
Validation loss: 2.480472578711571

Epoch: 215| Step: 0
Training loss: 2.6836541625750963
Validation loss: 2.4776489971200917

Epoch: 5| Step: 1
Training loss: 2.2247582336403737
Validation loss: 2.4819681356696734

Epoch: 5| Step: 2
Training loss: 1.911501794748863
Validation loss: 2.4903961567903496

Epoch: 5| Step: 3
Training loss: 1.9626301910563038
Validation loss: 2.487509803017832

Epoch: 5| Step: 4
Training loss: 2.934661467750216
Validation loss: 2.4865317429848868

Epoch: 5| Step: 5
Training loss: 2.5889795394802113
Validation loss: 2.4902388389397796

Epoch: 5| Step: 6
Training loss: 2.656497450129619
Validation loss: 2.4830630655131625

Epoch: 5| Step: 7
Training loss: 2.62165719583704
Validation loss: 2.4813846409073768

Epoch: 5| Step: 8
Training loss: 2.7059076352535913
Validation loss: 2.47896920280618

Epoch: 5| Step: 9
Training loss: 2.2780637044732055
Validation loss: 2.4758233713306765

Epoch: 5| Step: 10
Training loss: 2.6211621521439743
Validation loss: 2.484597725951019

Epoch: 5| Step: 11
Training loss: 2.404299453250547
Validation loss: 2.478855202982121

Epoch: 216| Step: 0
Training loss: 2.020129707251159
Validation loss: 2.4699661341815298

Epoch: 5| Step: 1
Training loss: 2.2347369134342467
Validation loss: 2.474582104932852

Epoch: 5| Step: 2
Training loss: 2.523685785603669
Validation loss: 2.4777419313326288

Epoch: 5| Step: 3
Training loss: 2.699157979145852
Validation loss: 2.4760726460300337

Epoch: 5| Step: 4
Training loss: 3.0341050378550354
Validation loss: 2.479392287195109

Epoch: 5| Step: 5
Training loss: 2.769213917876592
Validation loss: 2.483958163370322

Epoch: 5| Step: 6
Training loss: 1.9912852319736352
Validation loss: 2.4850797753158322

Epoch: 5| Step: 7
Training loss: 2.161884079026598
Validation loss: 2.485715056832538

Epoch: 5| Step: 8
Training loss: 2.4313312624807546
Validation loss: 2.481998318429798

Epoch: 5| Step: 9
Training loss: 2.317569537060873
Validation loss: 2.4730427958635035

Epoch: 5| Step: 10
Training loss: 2.39999607403752
Validation loss: 2.485554357222964

Epoch: 5| Step: 11
Training loss: 3.2512414468537623
Validation loss: 2.4766096918882563

Epoch: 217| Step: 0
Training loss: 2.6680976981729603
Validation loss: 2.487372798958131

Epoch: 5| Step: 1
Training loss: 2.4746226707047123
Validation loss: 2.4923934612251455

Epoch: 5| Step: 2
Training loss: 2.301934204334521
Validation loss: 2.4989018372773213

Epoch: 5| Step: 3
Training loss: 1.9809906702568114
Validation loss: 2.4856269768763077

Epoch: 5| Step: 4
Training loss: 2.6117962779212474
Validation loss: 2.4856931720184328

Epoch: 5| Step: 5
Training loss: 2.6071362971243848
Validation loss: 2.4766921401564286

Epoch: 5| Step: 6
Training loss: 2.540273148875616
Validation loss: 2.4785215128735247

Epoch: 5| Step: 7
Training loss: 2.42849378301411
Validation loss: 2.4732906538137693

Epoch: 5| Step: 8
Training loss: 2.3547659817218176
Validation loss: 2.4641416288227687

Epoch: 5| Step: 9
Training loss: 2.603358293316797
Validation loss: 2.4854242840053566

Epoch: 5| Step: 10
Training loss: 2.382756967366468
Validation loss: 2.4685927634727474

Epoch: 5| Step: 11
Training loss: 3.360234208345681
Validation loss: 2.4702182580487313

Epoch: 218| Step: 0
Training loss: 2.965362382843701
Validation loss: 2.4709071581481106

Epoch: 5| Step: 1
Training loss: 2.323807777806891
Validation loss: 2.466029225177022

Epoch: 5| Step: 2
Training loss: 2.283002206594944
Validation loss: 2.456591309509231

Epoch: 5| Step: 3
Training loss: 2.370060351444352
Validation loss: 2.476108252646809

Epoch: 5| Step: 4
Training loss: 2.7169065693279775
Validation loss: 2.466560205426066

Epoch: 5| Step: 5
Training loss: 2.170599693372693
Validation loss: 2.4651640227016087

Epoch: 5| Step: 6
Training loss: 1.9230974232974802
Validation loss: 2.4723268463258306

Epoch: 5| Step: 7
Training loss: 2.7734332017462293
Validation loss: 2.476693860891336

Epoch: 5| Step: 8
Training loss: 2.5054447963938657
Validation loss: 2.4693981398265286

Epoch: 5| Step: 9
Training loss: 2.799586510781129
Validation loss: 2.4775789343111945

Epoch: 5| Step: 10
Training loss: 2.100093739551829
Validation loss: 2.4694691346999496

Epoch: 5| Step: 11
Training loss: 2.264282565482152
Validation loss: 2.470337940513746

Epoch: 219| Step: 0
Training loss: 2.0464564470605224
Validation loss: 2.4780811583339712

Epoch: 5| Step: 1
Training loss: 2.7026695793931594
Validation loss: 2.4838032214448167

Epoch: 5| Step: 2
Training loss: 2.3541024010812723
Validation loss: 2.477807898114423

Epoch: 5| Step: 3
Training loss: 2.3402711608471196
Validation loss: 2.4746590207646526

Epoch: 5| Step: 4
Training loss: 2.28248698520188
Validation loss: 2.478786572936633

Epoch: 5| Step: 5
Training loss: 2.365349991206819
Validation loss: 2.478281545645234

Epoch: 5| Step: 6
Training loss: 2.420541211447791
Validation loss: 2.4721803533625737

Epoch: 5| Step: 7
Training loss: 2.562670260099709
Validation loss: 2.4813703285206494

Epoch: 5| Step: 8
Training loss: 2.2205581819040887
Validation loss: 2.4813750546199973

Epoch: 5| Step: 9
Training loss: 2.599925582994516
Validation loss: 2.4766839014696997

Epoch: 5| Step: 10
Training loss: 3.1551814017159736
Validation loss: 2.4731612289984706

Epoch: 5| Step: 11
Training loss: 1.5178032392659533
Validation loss: 2.4736417159542627

Epoch: 220| Step: 0
Training loss: 3.0946687817558787
Validation loss: 2.48508021504084

Epoch: 5| Step: 1
Training loss: 2.3181966774340164
Validation loss: 2.480106269202876

Epoch: 5| Step: 2
Training loss: 2.50253825079374
Validation loss: 2.4827575256586476

Epoch: 5| Step: 3
Training loss: 2.445909421171587
Validation loss: 2.4698743432819876

Epoch: 5| Step: 4
Training loss: 2.4032166422619445
Validation loss: 2.471791329557228

Epoch: 5| Step: 5
Training loss: 1.98503462273601
Validation loss: 2.47021272036749

Epoch: 5| Step: 6
Training loss: 1.9297812744089229
Validation loss: 2.473122977049563

Epoch: 5| Step: 7
Training loss: 2.9302691479901783
Validation loss: 2.4739337732534845

Epoch: 5| Step: 8
Training loss: 2.4631978629117532
Validation loss: 2.489258945884362

Epoch: 5| Step: 9
Training loss: 2.3297193559583214
Validation loss: 2.488579553023253

Epoch: 5| Step: 10
Training loss: 2.5773959891999607
Validation loss: 2.4857101291693255

Epoch: 5| Step: 11
Training loss: 1.0778437814351136
Validation loss: 2.480811540441499

Epoch: 221| Step: 0
Training loss: 2.6087940048944347
Validation loss: 2.4831162148701185

Epoch: 5| Step: 1
Training loss: 2.5929996370255717
Validation loss: 2.4860758647219816

Epoch: 5| Step: 2
Training loss: 2.1977885662431635
Validation loss: 2.488300676734102

Epoch: 5| Step: 3
Training loss: 2.609956961967525
Validation loss: 2.4873491514655184

Epoch: 5| Step: 4
Training loss: 2.114520430608023
Validation loss: 2.48708213606303

Epoch: 5| Step: 5
Training loss: 2.353565769531935
Validation loss: 2.485889804717421

Epoch: 5| Step: 6
Training loss: 2.8917658023898793
Validation loss: 2.4776984416503662

Epoch: 5| Step: 7
Training loss: 2.6909723250413005
Validation loss: 2.485594693965449

Epoch: 5| Step: 8
Training loss: 2.4311914235881678
Validation loss: 2.48875031973075

Epoch: 5| Step: 9
Training loss: 2.2497100643272137
Validation loss: 2.4926793321664533

Epoch: 5| Step: 10
Training loss: 2.222593390408906
Validation loss: 2.483272867832076

Epoch: 5| Step: 11
Training loss: 1.4593209691634117
Validation loss: 2.48045354723339

Epoch: 222| Step: 0
Training loss: 2.814783991492457
Validation loss: 2.482998464608713

Epoch: 5| Step: 1
Training loss: 2.4964873431920336
Validation loss: 2.4891776801194414

Epoch: 5| Step: 2
Training loss: 2.5344990729313155
Validation loss: 2.476508387667385

Epoch: 5| Step: 3
Training loss: 2.273031401659398
Validation loss: 2.49010194114634

Epoch: 5| Step: 4
Training loss: 2.3843254914149683
Validation loss: 2.4832376119761084

Epoch: 5| Step: 5
Training loss: 2.2541002424775183
Validation loss: 2.484010097808196

Epoch: 5| Step: 6
Training loss: 2.0736112980275783
Validation loss: 2.4882271409951064

Epoch: 5| Step: 7
Training loss: 2.589743127493564
Validation loss: 2.4862101832302628

Epoch: 5| Step: 8
Training loss: 2.2084282428811397
Validation loss: 2.475280405786917

Epoch: 5| Step: 9
Training loss: 2.590405157353178
Validation loss: 2.500834236429804

Epoch: 5| Step: 10
Training loss: 2.6429349287655968
Validation loss: 2.4796036741161394

Epoch: 5| Step: 11
Training loss: 1.6474340919428407
Validation loss: 2.485982630663882

Epoch: 223| Step: 0
Training loss: 2.262278538608537
Validation loss: 2.4846839372816207

Epoch: 5| Step: 1
Training loss: 1.8239328948693734
Validation loss: 2.4843322542299875

Epoch: 5| Step: 2
Training loss: 2.4968495545505105
Validation loss: 2.474667691710567

Epoch: 5| Step: 3
Training loss: 2.670725703538051
Validation loss: 2.48331119145586

Epoch: 5| Step: 4
Training loss: 2.279966855728437
Validation loss: 2.485410538468929

Epoch: 5| Step: 5
Training loss: 3.3246113313371786
Validation loss: 2.4879190529670403

Epoch: 5| Step: 6
Training loss: 2.385196981072902
Validation loss: 2.4742074191869174

Epoch: 5| Step: 7
Training loss: 2.2453670487118944
Validation loss: 2.4823412818341755

Epoch: 5| Step: 8
Training loss: 2.461583806500559
Validation loss: 2.4901070795372626

Epoch: 5| Step: 9
Training loss: 2.3503855044115944
Validation loss: 2.4842016571478673

Epoch: 5| Step: 10
Training loss: 2.3915578979144847
Validation loss: 2.477616560138282

Epoch: 5| Step: 11
Training loss: 1.8915211468935544
Validation loss: 2.494788738612698

Epoch: 224| Step: 0
Training loss: 2.730799839100345
Validation loss: 2.4775578116335386

Epoch: 5| Step: 1
Training loss: 2.049396621483015
Validation loss: 2.502603601673286

Epoch: 5| Step: 2
Training loss: 2.8290213328932907
Validation loss: 2.4951328881771944

Epoch: 5| Step: 3
Training loss: 2.6824980918685513
Validation loss: 2.491731468419077

Epoch: 5| Step: 4
Training loss: 2.913275973048486
Validation loss: 2.4814717745380217

Epoch: 5| Step: 5
Training loss: 2.5685163442705425
Validation loss: 2.4872427409575417

Epoch: 5| Step: 6
Training loss: 1.841701468689801
Validation loss: 2.4853538767985603

Epoch: 5| Step: 7
Training loss: 2.2378875226348716
Validation loss: 2.4855796924107008

Epoch: 5| Step: 8
Training loss: 2.073809279778168
Validation loss: 2.487198179231415

Epoch: 5| Step: 9
Training loss: 2.3804567793071594
Validation loss: 2.4937483066498913

Epoch: 5| Step: 10
Training loss: 2.398973634919233
Validation loss: 2.495784690639782

Epoch: 5| Step: 11
Training loss: 2.8243606552836877
Validation loss: 2.498649979701889

Epoch: 225| Step: 0
Training loss: 2.0802510794073017
Validation loss: 2.494019264687993

Epoch: 5| Step: 1
Training loss: 2.3020161292391816
Validation loss: 2.49431545767007

Epoch: 5| Step: 2
Training loss: 2.4126655956616236
Validation loss: 2.503895034011104

Epoch: 5| Step: 3
Training loss: 2.5304621659582165
Validation loss: 2.492083065989861

Epoch: 5| Step: 4
Training loss: 2.3449758756978674
Validation loss: 2.494226791259584

Epoch: 5| Step: 5
Training loss: 2.1704898506354335
Validation loss: 2.4886254352529154

Epoch: 5| Step: 6
Training loss: 2.602381122083704
Validation loss: 2.496647653426675

Epoch: 5| Step: 7
Training loss: 2.9350484804376795
Validation loss: 2.493759639979495

Epoch: 5| Step: 8
Training loss: 2.2556335071922278
Validation loss: 2.4819057237139903

Epoch: 5| Step: 9
Training loss: 2.585816994247752
Validation loss: 2.4877008293142397

Epoch: 5| Step: 10
Training loss: 2.6298923315193954
Validation loss: 2.488508472617776

Epoch: 5| Step: 11
Training loss: 1.7245155041075946
Validation loss: 2.4911894399208117

Epoch: 226| Step: 0
Training loss: 2.2049796231943715
Validation loss: 2.492111619453859

Epoch: 5| Step: 1
Training loss: 2.6771372234298583
Validation loss: 2.4934536100470255

Epoch: 5| Step: 2
Training loss: 2.45002940024038
Validation loss: 2.4883200354475226

Epoch: 5| Step: 3
Training loss: 2.7967149059998757
Validation loss: 2.4969547241494814

Epoch: 5| Step: 4
Training loss: 2.373162713382855
Validation loss: 2.485613096574931

Epoch: 5| Step: 5
Training loss: 2.298162812935215
Validation loss: 2.488559908911129

Epoch: 5| Step: 6
Training loss: 2.4440470093047324
Validation loss: 2.4816739175825933

Epoch: 5| Step: 7
Training loss: 2.2219528935724275
Validation loss: 2.4901907723791985

Epoch: 5| Step: 8
Training loss: 2.806411595778829
Validation loss: 2.493527991627364

Epoch: 5| Step: 9
Training loss: 2.52682673783485
Validation loss: 2.494787173708465

Epoch: 5| Step: 10
Training loss: 2.16501968092926
Validation loss: 2.491493371584799

Epoch: 5| Step: 11
Training loss: 1.5552456874496352
Validation loss: 2.4976352315699857

Epoch: 227| Step: 0
Training loss: 2.3802706809750593
Validation loss: 2.492231474262233

Epoch: 5| Step: 1
Training loss: 2.310631074120955
Validation loss: 2.4977677353108487

Epoch: 5| Step: 2
Training loss: 1.968411734449157
Validation loss: 2.498540233561924

Epoch: 5| Step: 3
Training loss: 2.652896514507683
Validation loss: 2.492755113734742

Epoch: 5| Step: 4
Training loss: 2.6686992845920336
Validation loss: 2.4849075290455596

Epoch: 5| Step: 5
Training loss: 2.4279491424701694
Validation loss: 2.4906087117797275

Epoch: 5| Step: 6
Training loss: 1.9316413038539948
Validation loss: 2.483833121937629

Epoch: 5| Step: 7
Training loss: 2.319043978334544
Validation loss: 2.485289811102281

Epoch: 5| Step: 8
Training loss: 2.7458225946597485
Validation loss: 2.484334181604207

Epoch: 5| Step: 9
Training loss: 2.3638394792022277
Validation loss: 2.500240127634258

Epoch: 5| Step: 10
Training loss: 2.8452982617796554
Validation loss: 2.500487288033044

Epoch: 5| Step: 11
Training loss: 2.5991817727424045
Validation loss: 2.501304659559971

Epoch: 228| Step: 0
Training loss: 2.6366813148384214
Validation loss: 2.5334096141569917

Epoch: 5| Step: 1
Training loss: 2.1613878598654908
Validation loss: 2.525859013406648

Epoch: 5| Step: 2
Training loss: 2.0626033410278946
Validation loss: 2.521153943241952

Epoch: 5| Step: 3
Training loss: 2.947876156010757
Validation loss: 2.4862363747935734

Epoch: 5| Step: 4
Training loss: 2.3941621231405996
Validation loss: 2.491683490456097

Epoch: 5| Step: 5
Training loss: 2.800543994511004
Validation loss: 2.493952362435368

Epoch: 5| Step: 6
Training loss: 2.2019357921167866
Validation loss: 2.486890762648569

Epoch: 5| Step: 7
Training loss: 2.1012932700672304
Validation loss: 2.493609521967631

Epoch: 5| Step: 8
Training loss: 2.9832854354110574
Validation loss: 2.4901792472771094

Epoch: 5| Step: 9
Training loss: 2.2658373502990576
Validation loss: 2.4865099692340102

Epoch: 5| Step: 10
Training loss: 2.551568790388325
Validation loss: 2.4932758382446973

Epoch: 5| Step: 11
Training loss: 1.8698550526138769
Validation loss: 2.4835231088177965

Epoch: 229| Step: 0
Training loss: 2.452505726005566
Validation loss: 2.4959457664023303

Epoch: 5| Step: 1
Training loss: 2.7313145540408255
Validation loss: 2.485295890779147

Epoch: 5| Step: 2
Training loss: 2.45683251382274
Validation loss: 2.5002461590377107

Epoch: 5| Step: 3
Training loss: 2.0942719221804036
Validation loss: 2.487504974756426

Epoch: 5| Step: 4
Training loss: 3.078715001603135
Validation loss: 2.484567490803925

Epoch: 5| Step: 5
Training loss: 2.2838643391700537
Validation loss: 2.483078112277573

Epoch: 5| Step: 6
Training loss: 2.128530486655827
Validation loss: 2.4838801796888754

Epoch: 5| Step: 7
Training loss: 2.730601469860996
Validation loss: 2.4828081968385036

Epoch: 5| Step: 8
Training loss: 2.377611531430412
Validation loss: 2.4849005489162033

Epoch: 5| Step: 9
Training loss: 1.8325895910493468
Validation loss: 2.4762042535583726

Epoch: 5| Step: 10
Training loss: 2.604163625079604
Validation loss: 2.4750961912773803

Epoch: 5| Step: 11
Training loss: 2.9424968992361165
Validation loss: 2.4940197745339443

Epoch: 230| Step: 0
Training loss: 3.121820892689899
Validation loss: 2.4994261241917015

Epoch: 5| Step: 1
Training loss: 2.853229860883642
Validation loss: 2.4923808821028053

Epoch: 5| Step: 2
Training loss: 2.393002991613486
Validation loss: 2.5064483707559635

Epoch: 5| Step: 3
Training loss: 2.3181049364774227
Validation loss: 2.473944402287394

Epoch: 5| Step: 4
Training loss: 2.1986991851295743
Validation loss: 2.465757677145132

Epoch: 5| Step: 5
Training loss: 2.159065950970384
Validation loss: 2.469896042472669

Epoch: 5| Step: 6
Training loss: 2.115207661383427
Validation loss: 2.470978274498054

Epoch: 5| Step: 7
Training loss: 2.4489349736233095
Validation loss: 2.4757678484872465

Epoch: 5| Step: 8
Training loss: 2.286358169991753
Validation loss: 2.4732488451414243

Epoch: 5| Step: 9
Training loss: 2.369515762756427
Validation loss: 2.4743095965059054

Epoch: 5| Step: 10
Training loss: 2.701737152331682
Validation loss: 2.472446623599859

Epoch: 5| Step: 11
Training loss: 2.1089426233292534
Validation loss: 2.4763144821181267

Epoch: 231| Step: 0
Training loss: 2.189916529349367
Validation loss: 2.483710318045035

Epoch: 5| Step: 1
Training loss: 1.867807325330781
Validation loss: 2.4784712390417325

Epoch: 5| Step: 2
Training loss: 2.385787857249379
Validation loss: 2.4736456676801217

Epoch: 5| Step: 3
Training loss: 2.037133952767003
Validation loss: 2.4856041200991954

Epoch: 5| Step: 4
Training loss: 2.1251650353466003
Validation loss: 2.5002495879516324

Epoch: 5| Step: 5
Training loss: 2.192622807542046
Validation loss: 2.483585976117193

Epoch: 5| Step: 6
Training loss: 2.993674603430638
Validation loss: 2.4825234020970237

Epoch: 5| Step: 7
Training loss: 2.574066296521743
Validation loss: 2.4879663049510614

Epoch: 5| Step: 8
Training loss: 2.7655775852772577
Validation loss: 2.4891568833516358

Epoch: 5| Step: 9
Training loss: 2.6742801660321804
Validation loss: 2.4859825587350057

Epoch: 5| Step: 10
Training loss: 2.797257125579489
Validation loss: 2.4840992508610453

Epoch: 5| Step: 11
Training loss: 2.137887359677983
Validation loss: 2.49400258709147

Epoch: 232| Step: 0
Training loss: 2.2157392894714554
Validation loss: 2.484546979313763

Epoch: 5| Step: 1
Training loss: 1.9082232408820086
Validation loss: 2.4837604818329324

Epoch: 5| Step: 2
Training loss: 2.253584655349811
Validation loss: 2.483665266964242

Epoch: 5| Step: 3
Training loss: 2.0526077710571493
Validation loss: 2.4863130679377585

Epoch: 5| Step: 4
Training loss: 3.285133316377293
Validation loss: 2.4902990794034614

Epoch: 5| Step: 5
Training loss: 3.129740819224496
Validation loss: 2.4869979191950207

Epoch: 5| Step: 6
Training loss: 2.210999612643425
Validation loss: 2.489898359778883

Epoch: 5| Step: 7
Training loss: 2.4859094259713688
Validation loss: 2.478208674669388

Epoch: 5| Step: 8
Training loss: 2.1770729052523565
Validation loss: 2.481606062028891

Epoch: 5| Step: 9
Training loss: 2.2175497112701543
Validation loss: 2.487192723290754

Epoch: 5| Step: 10
Training loss: 2.146671637574753
Validation loss: 2.478091645306945

Epoch: 5| Step: 11
Training loss: 3.9997424996462665
Validation loss: 2.482289044347721

Epoch: 233| Step: 0
Training loss: 2.4700208845298106
Validation loss: 2.5152166915835146

Epoch: 5| Step: 1
Training loss: 2.8508022183174804
Validation loss: 2.5542901300727343

Epoch: 5| Step: 2
Training loss: 2.5632231087501363
Validation loss: 2.5663981599646357

Epoch: 5| Step: 3
Training loss: 2.6231152262129536
Validation loss: 2.5551350519428504

Epoch: 5| Step: 4
Training loss: 2.2093804474025625
Validation loss: 2.528018979135249

Epoch: 5| Step: 5
Training loss: 2.624770563180405
Validation loss: 2.509832216559414

Epoch: 5| Step: 6
Training loss: 2.5941046966330226
Validation loss: 2.50790989766874

Epoch: 5| Step: 7
Training loss: 2.258892817243913
Validation loss: 2.4732949635733217

Epoch: 5| Step: 8
Training loss: 1.4978350274445105
Validation loss: 2.469185432631417

Epoch: 5| Step: 9
Training loss: 2.7668082082307066
Validation loss: 2.4673684314550357

Epoch: 5| Step: 10
Training loss: 2.556780409871082
Validation loss: 2.4769431903637678

Epoch: 5| Step: 11
Training loss: 3.24141159884659
Validation loss: 2.4869658378257213

Epoch: 234| Step: 0
Training loss: 2.709393240087373
Validation loss: 2.4816877638746506

Epoch: 5| Step: 1
Training loss: 2.64448653257983
Validation loss: 2.475603934980653

Epoch: 5| Step: 2
Training loss: 2.577125031718032
Validation loss: 2.4712962648598356

Epoch: 5| Step: 3
Training loss: 2.8227631549456036
Validation loss: 2.4852144274696983

Epoch: 5| Step: 4
Training loss: 3.010137278825989
Validation loss: 2.484949777199257

Epoch: 5| Step: 5
Training loss: 2.247862118073009
Validation loss: 2.4775043986833505

Epoch: 5| Step: 6
Training loss: 1.9982203075503746
Validation loss: 2.4814480027533627

Epoch: 5| Step: 7
Training loss: 1.60786871186244
Validation loss: 2.480295442549198

Epoch: 5| Step: 8
Training loss: 2.4052796822581843
Validation loss: 2.4779375633174117

Epoch: 5| Step: 9
Training loss: 2.6896694209955023
Validation loss: 2.470465148803487

Epoch: 5| Step: 10
Training loss: 2.8624001431434727
Validation loss: 2.4860384708201675

Epoch: 5| Step: 11
Training loss: 1.7397309505243626
Validation loss: 2.4708367835519858

Epoch: 235| Step: 0
Training loss: 2.901513947556725
Validation loss: 2.4734265883673556

Epoch: 5| Step: 1
Training loss: 2.7183941136840355
Validation loss: 2.4602603041157187

Epoch: 5| Step: 2
Training loss: 2.6495440036785953
Validation loss: 2.484261364207329

Epoch: 5| Step: 3
Training loss: 1.6697566792833842
Validation loss: 2.4816803703886197

Epoch: 5| Step: 4
Training loss: 2.480483359947131
Validation loss: 2.47785223381318

Epoch: 5| Step: 5
Training loss: 2.0273844396958363
Validation loss: 2.4761725960151892

Epoch: 5| Step: 6
Training loss: 2.774615744028001
Validation loss: 2.4712029596076377

Epoch: 5| Step: 7
Training loss: 2.3265913449786453
Validation loss: 2.4735582141895156

Epoch: 5| Step: 8
Training loss: 2.220666729067677
Validation loss: 2.47688358363473

Epoch: 5| Step: 9
Training loss: 2.5894799070401846
Validation loss: 2.4727432251750234

Epoch: 5| Step: 10
Training loss: 2.704078285720511
Validation loss: 2.4683297036930094

Epoch: 5| Step: 11
Training loss: 1.6023056167089842
Validation loss: 2.4858438500156215

Epoch: 236| Step: 0
Training loss: 2.691962241447882
Validation loss: 2.494530994014247

Epoch: 5| Step: 1
Training loss: 2.4779686049842518
Validation loss: 2.5059533759405213

Epoch: 5| Step: 2
Training loss: 2.2618160457469974
Validation loss: 2.499896869916447

Epoch: 5| Step: 3
Training loss: 2.688569765314839
Validation loss: 2.5116836501892927

Epoch: 5| Step: 4
Training loss: 2.782170861203124
Validation loss: 2.495976098540942

Epoch: 5| Step: 5
Training loss: 2.4392633173380514
Validation loss: 2.518450932697088

Epoch: 5| Step: 6
Training loss: 2.1975326443657166
Validation loss: 2.5110454774280804

Epoch: 5| Step: 7
Training loss: 2.382706836796585
Validation loss: 2.503496903291807

Epoch: 5| Step: 8
Training loss: 2.193672083152936
Validation loss: 2.484988838512292

Epoch: 5| Step: 9
Training loss: 2.5812978005774756
Validation loss: 2.492389204418989

Epoch: 5| Step: 10
Training loss: 2.3650886119024968
Validation loss: 2.495122255841487

Epoch: 5| Step: 11
Training loss: 2.501453168053588
Validation loss: 2.4882537944083443

Epoch: 237| Step: 0
Training loss: 2.052411577594512
Validation loss: 2.4955319532038995

Epoch: 5| Step: 1
Training loss: 2.6400206286173495
Validation loss: 2.4896525143278017

Epoch: 5| Step: 2
Training loss: 2.0736150922805896
Validation loss: 2.500006612133183

Epoch: 5| Step: 3
Training loss: 2.379996615175036
Validation loss: 2.5000616701784852

Epoch: 5| Step: 4
Training loss: 2.3071097366101756
Validation loss: 2.4963097834539805

Epoch: 5| Step: 5
Training loss: 2.166810422187572
Validation loss: 2.487107036292505

Epoch: 5| Step: 6
Training loss: 3.0023937212249456
Validation loss: 2.4824068282597027

Epoch: 5| Step: 7
Training loss: 2.6815164180255135
Validation loss: 2.4947170745486806

Epoch: 5| Step: 8
Training loss: 2.7439102890708718
Validation loss: 2.490340948878603

Epoch: 5| Step: 9
Training loss: 2.9593372701074596
Validation loss: 2.4908721964688527

Epoch: 5| Step: 10
Training loss: 2.3856898211096906
Validation loss: 2.496504545361602

Epoch: 5| Step: 11
Training loss: 1.9679225212019236
Validation loss: 2.4926800774198816

Epoch: 238| Step: 0
Training loss: 2.515111361364482
Validation loss: 2.490465360412965

Epoch: 5| Step: 1
Training loss: 2.3047937401029457
Validation loss: 2.491603424126591

Epoch: 5| Step: 2
Training loss: 2.893080704408233
Validation loss: 2.4836780442193263

Epoch: 5| Step: 3
Training loss: 2.6032374033753665
Validation loss: 2.4947835859726637

Epoch: 5| Step: 4
Training loss: 1.9212981187879028
Validation loss: 2.484652413768316

Epoch: 5| Step: 5
Training loss: 2.2682994973235138
Validation loss: 2.484727630540641

Epoch: 5| Step: 6
Training loss: 1.44585437411225
Validation loss: 2.483556792640325

Epoch: 5| Step: 7
Training loss: 3.198788717616206
Validation loss: 2.4804568232852824

Epoch: 5| Step: 8
Training loss: 2.404720662602816
Validation loss: 2.482517887862888

Epoch: 5| Step: 9
Training loss: 2.4666240568175155
Validation loss: 2.4789815574481633

Epoch: 5| Step: 10
Training loss: 2.2200738959858284
Validation loss: 2.466316818760311

Epoch: 5| Step: 11
Training loss: 2.902687596609098
Validation loss: 2.4742998202032576

Epoch: 239| Step: 0
Training loss: 2.272458734253068
Validation loss: 2.475830824437813

Epoch: 5| Step: 1
Training loss: 2.4655682304625364
Validation loss: 2.4734834208496075

Epoch: 5| Step: 2
Training loss: 2.738297270593292
Validation loss: 2.469176784677682

Epoch: 5| Step: 3
Training loss: 2.757071506274447
Validation loss: 2.4744154711885002

Epoch: 5| Step: 4
Training loss: 2.5617282914952204
Validation loss: 2.458674634797558

Epoch: 5| Step: 5
Training loss: 1.9871751747762934
Validation loss: 2.469306669771085

Epoch: 5| Step: 6
Training loss: 2.539847947923611
Validation loss: 2.4593648295533552

Epoch: 5| Step: 7
Training loss: 2.4991875281951983
Validation loss: 2.4677300056245497

Epoch: 5| Step: 8
Training loss: 2.433207326613807
Validation loss: 2.4701497841701596

Epoch: 5| Step: 9
Training loss: 2.067767497128286
Validation loss: 2.474805206442478

Epoch: 5| Step: 10
Training loss: 2.5668855681107776
Validation loss: 2.4741300275686613

Epoch: 5| Step: 11
Training loss: 2.598152010081911
Validation loss: 2.477488443942406

Epoch: 240| Step: 0
Training loss: 2.2469150799610556
Validation loss: 2.476126394773402

Epoch: 5| Step: 1
Training loss: 2.2428410338603415
Validation loss: 2.4817704957612894

Epoch: 5| Step: 2
Training loss: 2.610349644447247
Validation loss: 2.4788266911860632

Epoch: 5| Step: 3
Training loss: 2.3592087642893658
Validation loss: 2.4885508472586784

Epoch: 5| Step: 4
Training loss: 2.7002848439609832
Validation loss: 2.480042320301839

Epoch: 5| Step: 5
Training loss: 2.7945674135653236
Validation loss: 2.481186738316781

Epoch: 5| Step: 6
Training loss: 2.3806971431345696
Validation loss: 2.4717653185096866

Epoch: 5| Step: 7
Training loss: 2.579911046823414
Validation loss: 2.4788181289669597

Epoch: 5| Step: 8
Training loss: 2.4184536301365394
Validation loss: 2.486522486167676

Epoch: 5| Step: 9
Training loss: 2.6702731500698365
Validation loss: 2.4732833095324023

Epoch: 5| Step: 10
Training loss: 2.0101410540152034
Validation loss: 2.478928760258447

Epoch: 5| Step: 11
Training loss: 1.9046196140774707
Validation loss: 2.4745729519502704

Epoch: 241| Step: 0
Training loss: 2.4686482082579637
Validation loss: 2.4851958240410914

Epoch: 5| Step: 1
Training loss: 2.913541281878205
Validation loss: 2.488152030012896

Epoch: 5| Step: 2
Training loss: 2.8743771417373005
Validation loss: 2.4885935884288317

Epoch: 5| Step: 3
Training loss: 2.299982887701977
Validation loss: 2.503281966299135

Epoch: 5| Step: 4
Training loss: 2.18560578213174
Validation loss: 2.4957936105979512

Epoch: 5| Step: 5
Training loss: 2.1964724045654056
Validation loss: 2.504251576304872

Epoch: 5| Step: 6
Training loss: 2.61419898826586
Validation loss: 2.489723230897736

Epoch: 5| Step: 7
Training loss: 2.078246837285459
Validation loss: 2.4898029666780714

Epoch: 5| Step: 8
Training loss: 2.1675962385835903
Validation loss: 2.4953787172019717

Epoch: 5| Step: 9
Training loss: 2.880996587039577
Validation loss: 2.494139880182986

Epoch: 5| Step: 10
Training loss: 2.1425765671285357
Validation loss: 2.4877253360059166

Epoch: 5| Step: 11
Training loss: 2.036958976014146
Validation loss: 2.4892454090909353

Epoch: 242| Step: 0
Training loss: 2.2755215979607057
Validation loss: 2.494561737603808

Epoch: 5| Step: 1
Training loss: 2.3248889117210014
Validation loss: 2.490455360331131

Epoch: 5| Step: 2
Training loss: 2.8351483048227575
Validation loss: 2.478195390186646

Epoch: 5| Step: 3
Training loss: 2.134751106066249
Validation loss: 2.4992497272008602

Epoch: 5| Step: 4
Training loss: 2.157425601423486
Validation loss: 2.4899222663315017

Epoch: 5| Step: 5
Training loss: 2.4905425475674767
Validation loss: 2.497764151856263

Epoch: 5| Step: 6
Training loss: 2.2610406204887163
Validation loss: 2.488615319998481

Epoch: 5| Step: 7
Training loss: 2.7562669956781845
Validation loss: 2.488933787078102

Epoch: 5| Step: 8
Training loss: 2.231794347531616
Validation loss: 2.493998408712702

Epoch: 5| Step: 9
Training loss: 2.5280224980910457
Validation loss: 2.5076150865979554

Epoch: 5| Step: 10
Training loss: 2.5531167150430716
Validation loss: 2.502329956550229

Epoch: 5| Step: 11
Training loss: 2.718785603608021
Validation loss: 2.494574476967259

Epoch: 243| Step: 0
Training loss: 2.0737352400352753
Validation loss: 2.493270471306572

Epoch: 5| Step: 1
Training loss: 2.9436182466410292
Validation loss: 2.4721374931770095

Epoch: 5| Step: 2
Training loss: 2.36287071508469
Validation loss: 2.4699530346198166

Epoch: 5| Step: 3
Training loss: 2.277049966645033
Validation loss: 2.4781000877689974

Epoch: 5| Step: 4
Training loss: 1.9333094532357786
Validation loss: 2.4785511564408855

Epoch: 5| Step: 5
Training loss: 2.69166402039137
Validation loss: 2.4860695312143806

Epoch: 5| Step: 6
Training loss: 2.427128170619799
Validation loss: 2.4780801751779795

Epoch: 5| Step: 7
Training loss: 2.2507518995464086
Validation loss: 2.4785839419096822

Epoch: 5| Step: 8
Training loss: 2.6148096926351507
Validation loss: 2.4762768425241615

Epoch: 5| Step: 9
Training loss: 2.4556785947757587
Validation loss: 2.480947869753225

Epoch: 5| Step: 10
Training loss: 2.5975326164481483
Validation loss: 2.4757626201474006

Epoch: 5| Step: 11
Training loss: 3.048054002408606
Validation loss: 2.478438933067499

Epoch: 244| Step: 0
Training loss: 2.712224297641431
Validation loss: 2.4878140963679556

Epoch: 5| Step: 1
Training loss: 2.7201630877239547
Validation loss: 2.4883797874083338

Epoch: 5| Step: 2
Training loss: 3.1436114180187027
Validation loss: 2.49891204208065

Epoch: 5| Step: 3
Training loss: 2.3239584897285064
Validation loss: 2.4922371702914696

Epoch: 5| Step: 4
Training loss: 2.163692511594243
Validation loss: 2.494590103406137

Epoch: 5| Step: 5
Training loss: 1.50635976431013
Validation loss: 2.480210666796919

Epoch: 5| Step: 6
Training loss: 2.8444642228525026
Validation loss: 2.484733339773711

Epoch: 5| Step: 7
Training loss: 1.9136875953192145
Validation loss: 2.4781128275741895

Epoch: 5| Step: 8
Training loss: 3.0145479957251093
Validation loss: 2.488629726439594

Epoch: 5| Step: 9
Training loss: 1.8301206602122355
Validation loss: 2.4842658188858704

Epoch: 5| Step: 10
Training loss: 2.188821447961137
Validation loss: 2.483366543645912

Epoch: 5| Step: 11
Training loss: 1.974082687876166
Validation loss: 2.4789904857725804

Epoch: 245| Step: 0
Training loss: 2.1389296006240555
Validation loss: 2.475450625160739

Epoch: 5| Step: 1
Training loss: 2.2652481291817623
Validation loss: 2.4908500399007463

Epoch: 5| Step: 2
Training loss: 2.388537524009425
Validation loss: 2.4841294997052996

Epoch: 5| Step: 3
Training loss: 2.974504054428572
Validation loss: 2.472584422566322

Epoch: 5| Step: 4
Training loss: 2.101029679493207
Validation loss: 2.4718947199610772

Epoch: 5| Step: 5
Training loss: 2.6247215123271554
Validation loss: 2.4688200638884714

Epoch: 5| Step: 6
Training loss: 2.177318967877334
Validation loss: 2.475589998481424

Epoch: 5| Step: 7
Training loss: 2.724675703437715
Validation loss: 2.477719438838509

Epoch: 5| Step: 8
Training loss: 2.434939776073373
Validation loss: 2.4844431917760432

Epoch: 5| Step: 9
Training loss: 2.084794778032123
Validation loss: 2.4881655627734633

Epoch: 5| Step: 10
Training loss: 2.6287253148928373
Validation loss: 2.4806673986634107

Epoch: 5| Step: 11
Training loss: 1.153100337563375
Validation loss: 2.493720915233574

Epoch: 246| Step: 0
Training loss: 2.3671442915494993
Validation loss: 2.4809337730746504

Epoch: 5| Step: 1
Training loss: 2.2925738070888158
Validation loss: 2.49249920146423

Epoch: 5| Step: 2
Training loss: 2.8056939744533245
Validation loss: 2.4828706521261505

Epoch: 5| Step: 3
Training loss: 2.6076605183979424
Validation loss: 2.477379244034128

Epoch: 5| Step: 4
Training loss: 2.223777555195266
Validation loss: 2.4779385254826267

Epoch: 5| Step: 5
Training loss: 2.350447786563931
Validation loss: 2.4937362123967097

Epoch: 5| Step: 6
Training loss: 2.3437085974533205
Validation loss: 2.487319373117524

Epoch: 5| Step: 7
Training loss: 2.215366631469521
Validation loss: 2.4913336248728988

Epoch: 5| Step: 8
Training loss: 2.0276365564834316
Validation loss: 2.480187115237368

Epoch: 5| Step: 9
Training loss: 2.391437068467704
Validation loss: 2.490659526360683

Epoch: 5| Step: 10
Training loss: 2.7391286455731705
Validation loss: 2.4806656326294183

Epoch: 5| Step: 11
Training loss: 2.7978976633691017
Validation loss: 2.4882273725568465

Epoch: 247| Step: 0
Training loss: 2.4441525569195925
Validation loss: 2.482874827225813

Epoch: 5| Step: 1
Training loss: 2.233542333853715
Validation loss: 2.4833269127713695

Epoch: 5| Step: 2
Training loss: 2.4609950467601966
Validation loss: 2.485191996610219

Epoch: 5| Step: 3
Training loss: 2.348063048093007
Validation loss: 2.487956550368751

Epoch: 5| Step: 4
Training loss: 3.125818831931267
Validation loss: 2.5045050799119717

Epoch: 5| Step: 5
Training loss: 2.2914611955487194
Validation loss: 2.501709780546034

Epoch: 5| Step: 6
Training loss: 2.5331865602773758
Validation loss: 2.493831984846196

Epoch: 5| Step: 7
Training loss: 2.4925024138566156
Validation loss: 2.4886193517346555

Epoch: 5| Step: 8
Training loss: 2.47663980357344
Validation loss: 2.489009429244535

Epoch: 5| Step: 9
Training loss: 2.1062833381527364
Validation loss: 2.4924930237749297

Epoch: 5| Step: 10
Training loss: 1.8002173477981358
Validation loss: 2.4990626206977753

Epoch: 5| Step: 11
Training loss: 2.144919216173115
Validation loss: 2.4886630098297466

Epoch: 248| Step: 0
Training loss: 2.226705232027386
Validation loss: 2.506985798462676

Epoch: 5| Step: 1
Training loss: 2.498453043113394
Validation loss: 2.510096610047703

Epoch: 5| Step: 2
Training loss: 2.300316341040915
Validation loss: 2.502313993358239

Epoch: 5| Step: 3
Training loss: 2.681458002305358
Validation loss: 2.5308635813101166

Epoch: 5| Step: 4
Training loss: 2.4504076248812505
Validation loss: 2.5494227703482237

Epoch: 5| Step: 5
Training loss: 2.609003645918124
Validation loss: 2.5712240857796735

Epoch: 5| Step: 6
Training loss: 2.7894801406823513
Validation loss: 2.570498628843642

Epoch: 5| Step: 7
Training loss: 2.698917708881915
Validation loss: 2.537865795898482

Epoch: 5| Step: 8
Training loss: 2.13762627390373
Validation loss: 2.510628779671758

Epoch: 5| Step: 9
Training loss: 2.295996984705789
Validation loss: 2.4814706035687815

Epoch: 5| Step: 10
Training loss: 2.4656431712362132
Validation loss: 2.4892028227846024

Epoch: 5| Step: 11
Training loss: 2.0343331046998387
Validation loss: 2.492610767897833

Epoch: 249| Step: 0
Training loss: 3.2112656771350307
Validation loss: 2.4842755239792362

Epoch: 5| Step: 1
Training loss: 2.6729297006298682
Validation loss: 2.4748649194249017

Epoch: 5| Step: 2
Training loss: 2.135513104998106
Validation loss: 2.4875019496002735

Epoch: 5| Step: 3
Training loss: 2.287551641663013
Validation loss: 2.4760412074692977

Epoch: 5| Step: 4
Training loss: 2.2335507666610575
Validation loss: 2.476323325785179

Epoch: 5| Step: 5
Training loss: 2.733803825668325
Validation loss: 2.4795192312874446

Epoch: 5| Step: 6
Training loss: 3.2330452217127505
Validation loss: 2.4794866104333693

Epoch: 5| Step: 7
Training loss: 2.41443500299076
Validation loss: 2.4734473025235557

Epoch: 5| Step: 8
Training loss: 2.2971965538762924
Validation loss: 2.4719238964441863

Epoch: 5| Step: 9
Training loss: 2.579006437420068
Validation loss: 2.4702744987921963

Epoch: 5| Step: 10
Training loss: 1.5573258752372123
Validation loss: 2.460380890887894

Epoch: 5| Step: 11
Training loss: 2.678982655883782
Validation loss: 2.4627688098199862

Epoch: 250| Step: 0
Training loss: 2.709622902622072
Validation loss: 2.469509048305797

Epoch: 5| Step: 1
Training loss: 2.45244817447636
Validation loss: 2.4628494001100125

Epoch: 5| Step: 2
Training loss: 1.8708308598672647
Validation loss: 2.467611090398782

Epoch: 5| Step: 3
Training loss: 3.0528683916720216
Validation loss: 2.4612231436969574

Epoch: 5| Step: 4
Training loss: 2.334169771500411
Validation loss: 2.4619133119684125

Epoch: 5| Step: 5
Training loss: 2.454336559673639
Validation loss: 2.454193619502905

Epoch: 5| Step: 6
Training loss: 2.6832123197985838
Validation loss: 2.4598444696174266

Epoch: 5| Step: 7
Training loss: 2.6902088441574765
Validation loss: 2.4581161513542304

Epoch: 5| Step: 8
Training loss: 2.257967828073723
Validation loss: 2.4572249934029218

Epoch: 5| Step: 9
Training loss: 2.249578860394385
Validation loss: 2.461150770684685

Epoch: 5| Step: 10
Training loss: 2.178138209649069
Validation loss: 2.4608625551952423

Epoch: 5| Step: 11
Training loss: 3.238488865950861
Validation loss: 2.4693423156165104

Epoch: 251| Step: 0
Training loss: 2.487079611675511
Validation loss: 2.457944159630172

Epoch: 5| Step: 1
Training loss: 2.1825095881964827
Validation loss: 2.468098502166204

Epoch: 5| Step: 2
Training loss: 2.389548464462203
Validation loss: 2.4674288196210536

Epoch: 5| Step: 3
Training loss: 2.7428868806594986
Validation loss: 2.473275812599233

Epoch: 5| Step: 4
Training loss: 1.9183351745508253
Validation loss: 2.4733197736646892

Epoch: 5| Step: 5
Training loss: 2.7423455608493
Validation loss: 2.464883150087073

Epoch: 5| Step: 6
Training loss: 2.484633138429206
Validation loss: 2.4756588174599554

Epoch: 5| Step: 7
Training loss: 2.2420126816920916
Validation loss: 2.4790206286482657

Epoch: 5| Step: 8
Training loss: 2.3714345972966178
Validation loss: 2.4761885431870754

Epoch: 5| Step: 9
Training loss: 2.3416193114500614
Validation loss: 2.4830391449307814

Epoch: 5| Step: 10
Training loss: 2.986024410753571
Validation loss: 2.476239445070266

Epoch: 5| Step: 11
Training loss: 2.5632149234039643
Validation loss: 2.4687372762617747

Epoch: 252| Step: 0
Training loss: 3.207287423871414
Validation loss: 2.4912709710297123

Epoch: 5| Step: 1
Training loss: 2.3614079893377498
Validation loss: 2.4894245301890985

Epoch: 5| Step: 2
Training loss: 2.256949183793268
Validation loss: 2.509873382194582

Epoch: 5| Step: 3
Training loss: 2.2750420954236663
Validation loss: 2.490620418370467

Epoch: 5| Step: 4
Training loss: 2.5068927159583336
Validation loss: 2.494760450726664

Epoch: 5| Step: 5
Training loss: 1.8109768353881222
Validation loss: 2.4839392345854243

Epoch: 5| Step: 6
Training loss: 2.7088883540401847
Validation loss: 2.4767480574125624

Epoch: 5| Step: 7
Training loss: 1.8602468546238533
Validation loss: 2.497642880108555

Epoch: 5| Step: 8
Training loss: 2.6167446388079645
Validation loss: 2.483191478174466

Epoch: 5| Step: 9
Training loss: 2.6770858368818597
Validation loss: 2.4818635758439878

Epoch: 5| Step: 10
Training loss: 2.445897529015193
Validation loss: 2.4914679649526876

Epoch: 5| Step: 11
Training loss: 2.3223886160529137
Validation loss: 2.488764701440915

Epoch: 253| Step: 0
Training loss: 2.670994217461111
Validation loss: 2.490041464520364

Epoch: 5| Step: 1
Training loss: 2.501346416302257
Validation loss: 2.4878356690340784

Epoch: 5| Step: 2
Training loss: 2.0765230127717826
Validation loss: 2.4910477490462646

Epoch: 5| Step: 3
Training loss: 2.9318136816010405
Validation loss: 2.487157181498581

Epoch: 5| Step: 4
Training loss: 2.6960478290990224
Validation loss: 2.493219008676398

Epoch: 5| Step: 5
Training loss: 2.4964355807787775
Validation loss: 2.4951407295206343

Epoch: 5| Step: 6
Training loss: 2.1338124149537356
Validation loss: 2.49012518749342

Epoch: 5| Step: 7
Training loss: 2.38598081977854
Validation loss: 2.5068231415629447

Epoch: 5| Step: 8
Training loss: 2.1639582750031456
Validation loss: 2.496192177994433

Epoch: 5| Step: 9
Training loss: 2.1577101476704104
Validation loss: 2.5048075307101345

Epoch: 5| Step: 10
Training loss: 2.189487753057453
Validation loss: 2.493788349522795

Epoch: 5| Step: 11
Training loss: 2.5596031003479887
Validation loss: 2.4913830151276435

Epoch: 254| Step: 0
Training loss: 3.0742890133032215
Validation loss: 2.487061146022432

Epoch: 5| Step: 1
Training loss: 2.440898775382756
Validation loss: 2.4828700539680293

Epoch: 5| Step: 2
Training loss: 1.847671218392064
Validation loss: 2.4979818383868166

Epoch: 5| Step: 3
Training loss: 2.5247226902732827
Validation loss: 2.485894164565439

Epoch: 5| Step: 4
Training loss: 2.288591772638434
Validation loss: 2.4856132404540645

Epoch: 5| Step: 5
Training loss: 2.2267703310692646
Validation loss: 2.484016836487875

Epoch: 5| Step: 6
Training loss: 2.405891490832789
Validation loss: 2.49227807848005

Epoch: 5| Step: 7
Training loss: 2.5807175057022964
Validation loss: 2.489151852750634

Epoch: 5| Step: 8
Training loss: 2.3490692811690193
Validation loss: 2.4854851447619244

Epoch: 5| Step: 9
Training loss: 2.3589891535051577
Validation loss: 2.4751505191064687

Epoch: 5| Step: 10
Training loss: 2.579085292569848
Validation loss: 2.483653613586318

Epoch: 5| Step: 11
Training loss: 1.6450145310336963
Validation loss: 2.4827438333793475

Epoch: 255| Step: 0
Training loss: 2.49095596928773
Validation loss: 2.4812264033748175

Epoch: 5| Step: 1
Training loss: 1.9633500050331816
Validation loss: 2.4879407225492356

Epoch: 5| Step: 2
Training loss: 2.329502389514006
Validation loss: 2.4782721778423467

Epoch: 5| Step: 3
Training loss: 2.7794198862118025
Validation loss: 2.4911957245226013

Epoch: 5| Step: 4
Training loss: 2.852217591169708
Validation loss: 2.4815144895168615

Epoch: 5| Step: 5
Training loss: 2.059483605445757
Validation loss: 2.483236903893538

Epoch: 5| Step: 6
Training loss: 2.5095438937194134
Validation loss: 2.4915556869117044

Epoch: 5| Step: 7
Training loss: 2.634932663290598
Validation loss: 2.4889002658314565

Epoch: 5| Step: 8
Training loss: 2.1780616959029575
Validation loss: 2.4993741642895797

Epoch: 5| Step: 9
Training loss: 2.462597096654103
Validation loss: 2.5042216895263465

Epoch: 5| Step: 10
Training loss: 2.1805306721406135
Validation loss: 2.489673753849446

Epoch: 5| Step: 11
Training loss: 2.664015873028317
Validation loss: 2.482011922765657

Epoch: 256| Step: 0
Training loss: 2.795241662157249
Validation loss: 2.486133389015

Epoch: 5| Step: 1
Training loss: 2.0401657452288946
Validation loss: 2.4870911990724243

Epoch: 5| Step: 2
Training loss: 2.2389492349666646
Validation loss: 2.4802065292687216

Epoch: 5| Step: 3
Training loss: 2.427324427689529
Validation loss: 2.4824612642130037

Epoch: 5| Step: 4
Training loss: 1.891955325359327
Validation loss: 2.471681552395418

Epoch: 5| Step: 5
Training loss: 2.413401787965491
Validation loss: 2.4763779235473935

Epoch: 5| Step: 6
Training loss: 2.603803248160862
Validation loss: 2.479708148956057

Epoch: 5| Step: 7
Training loss: 2.271434202812734
Validation loss: 2.4859695755387583

Epoch: 5| Step: 8
Training loss: 2.954819611854272
Validation loss: 2.4774461447363327

Epoch: 5| Step: 9
Training loss: 2.2378113471418293
Validation loss: 2.4718174126721317

Epoch: 5| Step: 10
Training loss: 2.5673489167539474
Validation loss: 2.472500537551472

Epoch: 5| Step: 11
Training loss: 2.032002001723858
Validation loss: 2.476840207226701

Epoch: 257| Step: 0
Training loss: 2.387177718215279
Validation loss: 2.467273089305571

Epoch: 5| Step: 1
Training loss: 2.4530167282411184
Validation loss: 2.4721675207007183

Epoch: 5| Step: 2
Training loss: 2.8532504168016875
Validation loss: 2.4730531796764814

Epoch: 5| Step: 3
Training loss: 1.8868481451488253
Validation loss: 2.4965119864669285

Epoch: 5| Step: 4
Training loss: 2.0325489292613126
Validation loss: 2.4990722007510713

Epoch: 5| Step: 5
Training loss: 2.7363464224160725
Validation loss: 2.508409276606837

Epoch: 5| Step: 6
Training loss: 2.1457073829007225
Validation loss: 2.5012559477751104

Epoch: 5| Step: 7
Training loss: 2.732555896016313
Validation loss: 2.484093636148737

Epoch: 5| Step: 8
Training loss: 2.369414437141139
Validation loss: 2.4871278541948496

Epoch: 5| Step: 9
Training loss: 2.5457511247596627
Validation loss: 2.4909274304933438

Epoch: 5| Step: 10
Training loss: 2.456433828526766
Validation loss: 2.4801637837525004

Epoch: 5| Step: 11
Training loss: 1.7312030827193392
Validation loss: 2.48863356255463

Epoch: 258| Step: 0
Training loss: 2.4865493376343832
Validation loss: 2.494629212879265

Epoch: 5| Step: 1
Training loss: 2.7024406492930906
Validation loss: 2.4859966647470246

Epoch: 5| Step: 2
Training loss: 2.7192296449096336
Validation loss: 2.4875078980721437

Epoch: 5| Step: 3
Training loss: 2.558210364585019
Validation loss: 2.4896197708740724

Epoch: 5| Step: 4
Training loss: 2.391389512630041
Validation loss: 2.4842590328957157

Epoch: 5| Step: 5
Training loss: 2.43877465591989
Validation loss: 2.481917435331227

Epoch: 5| Step: 6
Training loss: 2.5785087531035344
Validation loss: 2.4816320980291207

Epoch: 5| Step: 7
Training loss: 1.861902714651411
Validation loss: 2.4833866488624072

Epoch: 5| Step: 8
Training loss: 2.3521461142807487
Validation loss: 2.4718344127668193

Epoch: 5| Step: 9
Training loss: 2.2596773148461318
Validation loss: 2.482701159558073

Epoch: 5| Step: 10
Training loss: 2.246729487136068
Validation loss: 2.4764468610302117

Epoch: 5| Step: 11
Training loss: 2.0288521331632245
Validation loss: 2.4844073467428074

Epoch: 259| Step: 0
Training loss: 1.8159721265913982
Validation loss: 2.489739925189599

Epoch: 5| Step: 1
Training loss: 2.6999191060133847
Validation loss: 2.4889819737028502

Epoch: 5| Step: 2
Training loss: 2.4156744553412475
Validation loss: 2.493177370822091

Epoch: 5| Step: 3
Training loss: 2.0739844813120336
Validation loss: 2.48262638157063

Epoch: 5| Step: 4
Training loss: 1.8962570667072303
Validation loss: 2.490744887736809

Epoch: 5| Step: 5
Training loss: 2.306277899844738
Validation loss: 2.4947819692997952

Epoch: 5| Step: 6
Training loss: 1.9815466240579427
Validation loss: 2.4916866839656295

Epoch: 5| Step: 7
Training loss: 2.5181725912172332
Validation loss: 2.490338874569045

Epoch: 5| Step: 8
Training loss: 2.9876085908060164
Validation loss: 2.4929166024274103

Epoch: 5| Step: 9
Training loss: 2.9636812004042192
Validation loss: 2.490587627811754

Epoch: 5| Step: 10
Training loss: 2.4067162396440724
Validation loss: 2.489996514024299

Epoch: 5| Step: 11
Training loss: 3.242403101359253
Validation loss: 2.505348448823563

Epoch: 260| Step: 0
Training loss: 2.4420095934167825
Validation loss: 2.4852971099104564

Epoch: 5| Step: 1
Training loss: 1.8814186857009103
Validation loss: 2.5062409940638655

Epoch: 5| Step: 2
Training loss: 2.4455217265846882
Validation loss: 2.5025196372108667

Epoch: 5| Step: 3
Training loss: 2.6459355872712633
Validation loss: 2.510056205977627

Epoch: 5| Step: 4
Training loss: 2.559942876953343
Validation loss: 2.513952338897352

Epoch: 5| Step: 5
Training loss: 2.2894526334695984
Validation loss: 2.508523869855399

Epoch: 5| Step: 6
Training loss: 3.2181967843192156
Validation loss: 2.4886275069988493

Epoch: 5| Step: 7
Training loss: 2.1632393603885984
Validation loss: 2.493117982882078

Epoch: 5| Step: 8
Training loss: 2.43175690767396
Validation loss: 2.496560289445065

Epoch: 5| Step: 9
Training loss: 2.083894450599116
Validation loss: 2.495414681314148

Epoch: 5| Step: 10
Training loss: 2.1742903636963584
Validation loss: 2.491271262122015

Epoch: 5| Step: 11
Training loss: 1.7360411193302339
Validation loss: 2.4823730728070474

Epoch: 261| Step: 0
Training loss: 2.6070420120652718
Validation loss: 2.4806022107522483

Epoch: 5| Step: 1
Training loss: 2.5012788362761516
Validation loss: 2.474989336244492

Epoch: 5| Step: 2
Training loss: 2.838780514995285
Validation loss: 2.485508122537484

Epoch: 5| Step: 3
Training loss: 2.617774647000392
Validation loss: 2.4862907828388305

Epoch: 5| Step: 4
Training loss: 2.582744274865277
Validation loss: 2.485101077904302

Epoch: 5| Step: 5
Training loss: 2.2453753309278834
Validation loss: 2.493488793169632

Epoch: 5| Step: 6
Training loss: 1.8070788372682536
Validation loss: 2.482392865923628

Epoch: 5| Step: 7
Training loss: 2.4884483484905746
Validation loss: 2.48461880877093

Epoch: 5| Step: 8
Training loss: 2.5521818699920016
Validation loss: 2.477758758471451

Epoch: 5| Step: 9
Training loss: 2.0049002935109184
Validation loss: 2.5007559150064744

Epoch: 5| Step: 10
Training loss: 2.2521599892113335
Validation loss: 2.48251678341394

Epoch: 5| Step: 11
Training loss: 1.1318894933976449
Validation loss: 2.4815567353889443

Epoch: 262| Step: 0
Training loss: 2.7049761480947434
Validation loss: 2.4930641800800024

Epoch: 5| Step: 1
Training loss: 2.3318748229964044
Validation loss: 2.50144027706833

Epoch: 5| Step: 2
Training loss: 1.7702328804609475
Validation loss: 2.4822161769607156

Epoch: 5| Step: 3
Training loss: 2.7167666863437767
Validation loss: 2.486863056022197

Epoch: 5| Step: 4
Training loss: 2.6878443652578072
Validation loss: 2.4890640400867605

Epoch: 5| Step: 5
Training loss: 2.209436560910272
Validation loss: 2.4919228567722156

Epoch: 5| Step: 6
Training loss: 2.321262974125066
Validation loss: 2.481322470502667

Epoch: 5| Step: 7
Training loss: 2.317481166265144
Validation loss: 2.4964029342522065

Epoch: 5| Step: 8
Training loss: 2.2222548191011007
Validation loss: 2.5039715691436255

Epoch: 5| Step: 9
Training loss: 2.8055813780835286
Validation loss: 2.493896751260642

Epoch: 5| Step: 10
Training loss: 2.101714288271345
Validation loss: 2.5065599444891973

Epoch: 5| Step: 11
Training loss: 2.619557233045021
Validation loss: 2.4872886079074505

Epoch: 263| Step: 0
Training loss: 2.856621422188637
Validation loss: 2.493536704525369

Epoch: 5| Step: 1
Training loss: 2.043991970471999
Validation loss: 2.490256491170174

Epoch: 5| Step: 2
Training loss: 2.188319679366798
Validation loss: 2.493011836539634

Epoch: 5| Step: 3
Training loss: 2.3264172326127905
Validation loss: 2.504680722061477

Epoch: 5| Step: 4
Training loss: 1.9441940585399295
Validation loss: 2.510042385570467

Epoch: 5| Step: 5
Training loss: 2.416125160145837
Validation loss: 2.498874156488767

Epoch: 5| Step: 6
Training loss: 2.9422896275797656
Validation loss: 2.508017191945983

Epoch: 5| Step: 7
Training loss: 2.5457951415381883
Validation loss: 2.5290626093361124

Epoch: 5| Step: 8
Training loss: 1.9328483609054494
Validation loss: 2.5137463301485306

Epoch: 5| Step: 9
Training loss: 2.307422734679034
Validation loss: 2.52775514959913

Epoch: 5| Step: 10
Training loss: 2.5229993504762662
Validation loss: 2.506680277563826

Epoch: 5| Step: 11
Training loss: 3.1638623586392094
Validation loss: 2.491937411524714

Epoch: 264| Step: 0
Training loss: 2.2104672851902794
Validation loss: 2.5073861287517563

Epoch: 5| Step: 1
Training loss: 1.7466991493005068
Validation loss: 2.5041072564421953

Epoch: 5| Step: 2
Training loss: 2.9798600961499777
Validation loss: 2.500467230925412

Epoch: 5| Step: 3
Training loss: 3.0365445804724778
Validation loss: 2.5160651680780375

Epoch: 5| Step: 4
Training loss: 2.5946219943292377
Validation loss: 2.4988511942806917

Epoch: 5| Step: 5
Training loss: 2.1547032212533788
Validation loss: 2.503967109849092

Epoch: 5| Step: 6
Training loss: 2.2295336792569245
Validation loss: 2.517803851835554

Epoch: 5| Step: 7
Training loss: 2.4861100573925246
Validation loss: 2.4981065295117735

Epoch: 5| Step: 8
Training loss: 2.4629502557709815
Validation loss: 2.5112601395961334

Epoch: 5| Step: 9
Training loss: 2.4699327557016586
Validation loss: 2.494940585401766

Epoch: 5| Step: 10
Training loss: 2.6852170429556605
Validation loss: 2.4965066583194333

Epoch: 5| Step: 11
Training loss: 3.3246788845027715
Validation loss: 2.4821789150160813

Epoch: 265| Step: 0
Training loss: 2.2303548005454017
Validation loss: 2.475433974959738

Epoch: 5| Step: 1
Training loss: 2.483101956471564
Validation loss: 2.4776686355214856

Epoch: 5| Step: 2
Training loss: 2.1566193858549907
Validation loss: 2.4926188264094455

Epoch: 5| Step: 3
Training loss: 2.652480378936766
Validation loss: 2.498483058537129

Epoch: 5| Step: 4
Training loss: 2.8341351290881738
Validation loss: 2.5452883054778828

Epoch: 5| Step: 5
Training loss: 2.6289130518288215
Validation loss: 2.5221799703091836

Epoch: 5| Step: 6
Training loss: 2.353985928599548
Validation loss: 2.5467320033458263

Epoch: 5| Step: 7
Training loss: 2.7957543200391513
Validation loss: 2.5373129152443483

Epoch: 5| Step: 8
Training loss: 2.179858894856076
Validation loss: 2.5214648138893465

Epoch: 5| Step: 9
Training loss: 1.983315012016409
Validation loss: 2.507431310281445

Epoch: 5| Step: 10
Training loss: 2.7793932085103448
Validation loss: 2.5029277704762154

Epoch: 5| Step: 11
Training loss: 1.8464903429296868
Validation loss: 2.483487468508152

Epoch: 266| Step: 0
Training loss: 2.177152191484664
Validation loss: 2.4943027488454614

Epoch: 5| Step: 1
Training loss: 2.6729538730361866
Validation loss: 2.5108657859906276

Epoch: 5| Step: 2
Training loss: 2.7303921711979067
Validation loss: 2.510744339912211

Epoch: 5| Step: 3
Training loss: 2.539018366503459
Validation loss: 2.5014535413590107

Epoch: 5| Step: 4
Training loss: 2.155084488489223
Validation loss: 2.500129251317836

Epoch: 5| Step: 5
Training loss: 2.66453785165282
Validation loss: 2.5069170251305506

Epoch: 5| Step: 6
Training loss: 2.6652817606889303
Validation loss: 2.5055829294830527

Epoch: 5| Step: 7
Training loss: 2.047751435618502
Validation loss: 2.501474795848204

Epoch: 5| Step: 8
Training loss: 2.4189461010041104
Validation loss: 2.496970254133872

Epoch: 5| Step: 9
Training loss: 2.4855131025596315
Validation loss: 2.49874214476457

Epoch: 5| Step: 10
Training loss: 2.06273568858581
Validation loss: 2.497674923770205

Epoch: 5| Step: 11
Training loss: 3.333536396199261
Validation loss: 2.4914971793675074

Epoch: 267| Step: 0
Training loss: 2.3422689208676175
Validation loss: 2.497769234712629

Epoch: 5| Step: 1
Training loss: 2.338717130494256
Validation loss: 2.4915530594045996

Epoch: 5| Step: 2
Training loss: 2.3460009129385053
Validation loss: 2.5065406513454818

Epoch: 5| Step: 3
Training loss: 1.717476112610506
Validation loss: 2.505138171529341

Epoch: 5| Step: 4
Training loss: 2.745838658082128
Validation loss: 2.501900121686761

Epoch: 5| Step: 5
Training loss: 2.2457235810799174
Validation loss: 2.496860666914229

Epoch: 5| Step: 6
Training loss: 2.233638722146121
Validation loss: 2.5266491359435514

Epoch: 5| Step: 7
Training loss: 3.107104828951032
Validation loss: 2.518031274593483

Epoch: 5| Step: 8
Training loss: 2.052713933057112
Validation loss: 2.506957563009014

Epoch: 5| Step: 9
Training loss: 2.01230863052244
Validation loss: 2.503221958900285

Epoch: 5| Step: 10
Training loss: 2.8681243280678896
Validation loss: 2.497380123679056

Epoch: 5| Step: 11
Training loss: 2.5889692254033165
Validation loss: 2.4880588218488464

Epoch: 268| Step: 0
Training loss: 1.89409741025699
Validation loss: 2.5030345579739435

Epoch: 5| Step: 1
Training loss: 2.6508910030778283
Validation loss: 2.4963180289997875

Epoch: 5| Step: 2
Training loss: 2.4221365510545323
Validation loss: 2.4978631424014655

Epoch: 5| Step: 3
Training loss: 2.5251334428934533
Validation loss: 2.4998525138901804

Epoch: 5| Step: 4
Training loss: 2.406811636241992
Validation loss: 2.4893059090474523

Epoch: 5| Step: 5
Training loss: 2.5937044070729285
Validation loss: 2.488090819253646

Epoch: 5| Step: 6
Training loss: 2.931698528533763
Validation loss: 2.4902354241661904

Epoch: 5| Step: 7
Training loss: 2.2252237143186004
Validation loss: 2.4955991912725026

Epoch: 5| Step: 8
Training loss: 2.0531807948504617
Validation loss: 2.4998510673983803

Epoch: 5| Step: 9
Training loss: 2.476392096303861
Validation loss: 2.5027860912101896

Epoch: 5| Step: 10
Training loss: 1.9617321942171422
Validation loss: 2.49874154444236

Epoch: 5| Step: 11
Training loss: 2.260904801454549
Validation loss: 2.5026595175368236

Epoch: 269| Step: 0
Training loss: 2.4096055846946207
Validation loss: 2.506628725636829

Epoch: 5| Step: 1
Training loss: 2.284933486905319
Validation loss: 2.5060177854803425

Epoch: 5| Step: 2
Training loss: 2.8455501350325716
Validation loss: 2.508195532903274

Epoch: 5| Step: 3
Training loss: 2.355334124663877
Validation loss: 2.5054216644332

Epoch: 5| Step: 4
Training loss: 2.4451520093224977
Validation loss: 2.5010115921286213

Epoch: 5| Step: 5
Training loss: 2.157706722288263
Validation loss: 2.498151855012636

Epoch: 5| Step: 6
Training loss: 2.435836713564295
Validation loss: 2.5010422759165905

Epoch: 5| Step: 7
Training loss: 2.2644927253833713
Validation loss: 2.5008798123987055

Epoch: 5| Step: 8
Training loss: 2.256898477200328
Validation loss: 2.4995288842077503

Epoch: 5| Step: 9
Training loss: 2.374842789114735
Validation loss: 2.5003053736941743

Epoch: 5| Step: 10
Training loss: 2.221790433366154
Validation loss: 2.506862908220608

Epoch: 5| Step: 11
Training loss: 3.024398453856639
Validation loss: 2.500119270022771

Epoch: 270| Step: 0
Training loss: 2.91214425202329
Validation loss: 2.4992359941052

Epoch: 5| Step: 1
Training loss: 2.340316699188903
Validation loss: 2.4991117369642453

Epoch: 5| Step: 2
Training loss: 2.5426434896333294
Validation loss: 2.498611799899361

Epoch: 5| Step: 3
Training loss: 2.362591906177772
Validation loss: 2.4978393158272025

Epoch: 5| Step: 4
Training loss: 2.381296144373789
Validation loss: 2.4917274775999783

Epoch: 5| Step: 5
Training loss: 2.2318363306204256
Validation loss: 2.4980540729068057

Epoch: 5| Step: 6
Training loss: 2.1417362642173914
Validation loss: 2.4972097143856673

Epoch: 5| Step: 7
Training loss: 2.410388310913245
Validation loss: 2.5150512767693733

Epoch: 5| Step: 8
Training loss: 2.384962568969019
Validation loss: 2.515391127651706

Epoch: 5| Step: 9
Training loss: 1.9019360115125923
Validation loss: 2.499203467632893

Epoch: 5| Step: 10
Training loss: 2.944215119826329
Validation loss: 2.4915453044547253

Epoch: 5| Step: 11
Training loss: 1.6583244719659929
Validation loss: 2.4995878992570484

Epoch: 271| Step: 0
Training loss: 2.238750734739114
Validation loss: 2.4936426910856944

Epoch: 5| Step: 1
Training loss: 2.750124841804061
Validation loss: 2.488158949117552

Epoch: 5| Step: 2
Training loss: 2.669756847268147
Validation loss: 2.4867446961978312

Epoch: 5| Step: 3
Training loss: 2.2107530928092634
Validation loss: 2.4836508297268334

Epoch: 5| Step: 4
Training loss: 2.9435847144892078
Validation loss: 2.4890724932255863

Epoch: 5| Step: 5
Training loss: 2.561635964961861
Validation loss: 2.4988429610691685

Epoch: 5| Step: 6
Training loss: 2.21903688966912
Validation loss: 2.4843419910533235

Epoch: 5| Step: 7
Training loss: 2.127224487144522
Validation loss: 2.5034189369949282

Epoch: 5| Step: 8
Training loss: 2.0748066042202034
Validation loss: 2.4889860407661475

Epoch: 5| Step: 9
Training loss: 2.3155405829688522
Validation loss: 2.5093607099671718

Epoch: 5| Step: 10
Training loss: 2.2351327958221447
Validation loss: 2.48962205327355

Epoch: 5| Step: 11
Training loss: 1.4781545301394992
Validation loss: 2.503315503304127

Epoch: 272| Step: 0
Training loss: 1.968332216045548
Validation loss: 2.499311256902712

Epoch: 5| Step: 1
Training loss: 2.944852190955381
Validation loss: 2.5102313330737966

Epoch: 5| Step: 2
Training loss: 2.2557878226950527
Validation loss: 2.4952072376143604

Epoch: 5| Step: 3
Training loss: 2.5206617081492575
Validation loss: 2.4826987107427003

Epoch: 5| Step: 4
Training loss: 1.7303423350984368
Validation loss: 2.5020708050971363

Epoch: 5| Step: 5
Training loss: 2.3800794592984627
Validation loss: 2.4938839088505036

Epoch: 5| Step: 6
Training loss: 2.740104384000231
Validation loss: 2.4890198382441087

Epoch: 5| Step: 7
Training loss: 2.1616440903840837
Validation loss: 2.5084846918775594

Epoch: 5| Step: 8
Training loss: 2.493872858907459
Validation loss: 2.4905612945386517

Epoch: 5| Step: 9
Training loss: 2.0062588272613557
Validation loss: 2.5003997046106097

Epoch: 5| Step: 10
Training loss: 2.7822478143932114
Validation loss: 2.495971569240939

Epoch: 5| Step: 11
Training loss: 2.195684543999947
Validation loss: 2.504779272684693

Epoch: 273| Step: 0
Training loss: 2.7035457746645952
Validation loss: 2.505809879582258

Epoch: 5| Step: 1
Training loss: 2.3898439814507286
Validation loss: 2.5059844015819026

Epoch: 5| Step: 2
Training loss: 2.5327448257545555
Validation loss: 2.5051582883937065

Epoch: 5| Step: 3
Training loss: 2.2390565711060724
Validation loss: 2.5132007923159074

Epoch: 5| Step: 4
Training loss: 2.1719859801554757
Validation loss: 2.491777862717095

Epoch: 5| Step: 5
Training loss: 2.287782070091453
Validation loss: 2.4966638279220916

Epoch: 5| Step: 6
Training loss: 2.3810742651305303
Validation loss: 2.4952087146671365

Epoch: 5| Step: 7
Training loss: 2.095688790506079
Validation loss: 2.490480346499517

Epoch: 5| Step: 8
Training loss: 2.3847896190439126
Validation loss: 2.4848528708301525

Epoch: 5| Step: 9
Training loss: 2.404500151655034
Validation loss: 2.4905567972727938

Epoch: 5| Step: 10
Training loss: 2.3847898189932644
Validation loss: 2.4907944152980566

Epoch: 5| Step: 11
Training loss: 3.205109962802716
Validation loss: 2.49438371422148

Epoch: 274| Step: 0
Training loss: 2.961553423993311
Validation loss: 2.4936306481095762

Epoch: 5| Step: 1
Training loss: 2.3976244216153755
Validation loss: 2.4964484816897503

Epoch: 5| Step: 2
Training loss: 2.3857665714574607
Validation loss: 2.5001411278944827

Epoch: 5| Step: 3
Training loss: 2.5262076936149365
Validation loss: 2.4980144523483006

Epoch: 5| Step: 4
Training loss: 2.1938692283291457
Validation loss: 2.4813737755114054

Epoch: 5| Step: 5
Training loss: 2.2945515824931197
Validation loss: 2.478838186915588

Epoch: 5| Step: 6
Training loss: 2.87068848117608
Validation loss: 2.4914159267999594

Epoch: 5| Step: 7
Training loss: 2.5148788198471164
Validation loss: 2.4843252284984403

Epoch: 5| Step: 8
Training loss: 2.3717989179348025
Validation loss: 2.493709340716137

Epoch: 5| Step: 9
Training loss: 1.7448998109316216
Validation loss: 2.5110601310163996

Epoch: 5| Step: 10
Training loss: 2.0028875486943454
Validation loss: 2.5059738351078056

Epoch: 5| Step: 11
Training loss: 2.255472627325263
Validation loss: 2.507934595069195

Epoch: 275| Step: 0
Training loss: 3.1665427200420906
Validation loss: 2.4862654109456117

Epoch: 5| Step: 1
Training loss: 2.0067451697843044
Validation loss: 2.500408208819286

Epoch: 5| Step: 2
Training loss: 2.012168700629065
Validation loss: 2.500839489814106

Epoch: 5| Step: 3
Training loss: 2.2984420724456345
Validation loss: 2.497827324901405

Epoch: 5| Step: 4
Training loss: 2.1601868225472733
Validation loss: 2.510480529057279

Epoch: 5| Step: 5
Training loss: 2.587828898143557
Validation loss: 2.4924535539572825

Epoch: 5| Step: 6
Training loss: 2.183123433843969
Validation loss: 2.5061182179293024

Epoch: 5| Step: 7
Training loss: 2.1445545966539963
Validation loss: 2.514793977445362

Epoch: 5| Step: 8
Training loss: 2.7201020835905787
Validation loss: 2.4934430323041106

Epoch: 5| Step: 9
Training loss: 2.169180316723338
Validation loss: 2.5215283032251605

Epoch: 5| Step: 10
Training loss: 2.637599136875834
Validation loss: 2.5056819243422224

Epoch: 5| Step: 11
Training loss: 2.1657056388869287
Validation loss: 2.5033460933753338

Epoch: 276| Step: 0
Training loss: 2.2257447999946827
Validation loss: 2.509341618484911

Epoch: 5| Step: 1
Training loss: 2.4017409646134396
Validation loss: 2.505205300475338

Epoch: 5| Step: 2
Training loss: 2.93130017463346
Validation loss: 2.512406843745363

Epoch: 5| Step: 3
Training loss: 1.9785752734638253
Validation loss: 2.5148667166084757

Epoch: 5| Step: 4
Training loss: 2.234459508618202
Validation loss: 2.5147113483546923

Epoch: 5| Step: 5
Training loss: 2.3456594191520512
Validation loss: 2.50598267519235

Epoch: 5| Step: 6
Training loss: 2.345617338798731
Validation loss: 2.5067046502229275

Epoch: 5| Step: 7
Training loss: 2.6231680335767953
Validation loss: 2.5053609231858767

Epoch: 5| Step: 8
Training loss: 2.609105079075902
Validation loss: 2.5057751905810415

Epoch: 5| Step: 9
Training loss: 2.831519687094427
Validation loss: 2.5040948313746654

Epoch: 5| Step: 10
Training loss: 2.63784291356855
Validation loss: 2.500400074100305

Epoch: 5| Step: 11
Training loss: 2.0923180309370344
Validation loss: 2.507179649813355

Epoch: 277| Step: 0
Training loss: 2.387261311847725
Validation loss: 2.5006532928104424

Epoch: 5| Step: 1
Training loss: 2.5089266669882377
Validation loss: 2.504557655254457

Epoch: 5| Step: 2
Training loss: 2.7335396498837494
Validation loss: 2.502671233253381

Epoch: 5| Step: 3
Training loss: 2.1034922762312562
Validation loss: 2.5302271562056498

Epoch: 5| Step: 4
Training loss: 2.5705158188011663
Validation loss: 2.5349959061694274

Epoch: 5| Step: 5
Training loss: 2.9288540481144243
Validation loss: 2.514369627671615

Epoch: 5| Step: 6
Training loss: 2.216826236211119
Validation loss: 2.505207975127154

Epoch: 5| Step: 7
Training loss: 2.2559385343592333
Validation loss: 2.521612237494999

Epoch: 5| Step: 8
Training loss: 2.0758600727545424
Validation loss: 2.511594022716231

Epoch: 5| Step: 9
Training loss: 2.498037617109262
Validation loss: 2.511952351276658

Epoch: 5| Step: 10
Training loss: 2.306864805899239
Validation loss: 2.4910248104055914

Epoch: 5| Step: 11
Training loss: 1.5625632464006298
Validation loss: 2.4823496177996014

Epoch: 278| Step: 0
Training loss: 2.225200678315746
Validation loss: 2.482426004834045

Epoch: 5| Step: 1
Training loss: 2.763486477190188
Validation loss: 2.484848345242332

Epoch: 5| Step: 2
Training loss: 2.682684109814373
Validation loss: 2.496743491254101

Epoch: 5| Step: 3
Training loss: 2.3425831242390793
Validation loss: 2.4943651990921776

Epoch: 5| Step: 4
Training loss: 2.2480510111753325
Validation loss: 2.5022591476438376

Epoch: 5| Step: 5
Training loss: 2.0583049998733576
Validation loss: 2.5020983830257957

Epoch: 5| Step: 6
Training loss: 3.288289828843273
Validation loss: 2.495062611599521

Epoch: 5| Step: 7
Training loss: 2.322638787269064
Validation loss: 2.4960954056218427

Epoch: 5| Step: 8
Training loss: 1.795968133715907
Validation loss: 2.498982715262477

Epoch: 5| Step: 9
Training loss: 2.548615124451275
Validation loss: 2.4962562822528067

Epoch: 5| Step: 10
Training loss: 1.9566459352585346
Validation loss: 2.4844896182125273

Epoch: 5| Step: 11
Training loss: 1.8404330789866143
Validation loss: 2.4970264751717366

Epoch: 279| Step: 0
Training loss: 2.652353368188332
Validation loss: 2.497371392367474

Epoch: 5| Step: 1
Training loss: 2.683066592572656
Validation loss: 2.5002033667500094

Epoch: 5| Step: 2
Training loss: 2.1486268116166998
Validation loss: 2.503543218439872

Epoch: 5| Step: 3
Training loss: 2.133341852806882
Validation loss: 2.5101128522293616

Epoch: 5| Step: 4
Training loss: 2.4812722654328563
Validation loss: 2.5177191731055584

Epoch: 5| Step: 5
Training loss: 2.7073504107037736
Validation loss: 2.500460616037363

Epoch: 5| Step: 6
Training loss: 2.184888097834998
Validation loss: 2.501617047749445

Epoch: 5| Step: 7
Training loss: 2.224830783881493
Validation loss: 2.5159725517775557

Epoch: 5| Step: 8
Training loss: 2.3961911694424374
Validation loss: 2.5046008332429697

Epoch: 5| Step: 9
Training loss: 1.7457754369830305
Validation loss: 2.5123027203732655

Epoch: 5| Step: 10
Training loss: 2.502853767472994
Validation loss: 2.5115452771278406

Epoch: 5| Step: 11
Training loss: 3.5176759967818185
Validation loss: 2.5112153533158232

Epoch: 280| Step: 0
Training loss: 1.8374982976581187
Validation loss: 2.5045660085041352

Epoch: 5| Step: 1
Training loss: 2.3889781789824998
Validation loss: 2.516424490368976

Epoch: 5| Step: 2
Training loss: 2.345261556845959
Validation loss: 2.5172930295368516

Epoch: 5| Step: 3
Training loss: 2.5190261689417266
Validation loss: 2.5072319055864694

Epoch: 5| Step: 4
Training loss: 2.5520926546718057
Validation loss: 2.5102092266775053

Epoch: 5| Step: 5
Training loss: 2.7787825536773
Validation loss: 2.5149330861977752

Epoch: 5| Step: 6
Training loss: 2.2675462666326305
Validation loss: 2.5127761695366186

Epoch: 5| Step: 7
Training loss: 2.285271640048735
Validation loss: 2.5252491576263822

Epoch: 5| Step: 8
Training loss: 2.8370313820405837
Validation loss: 2.514762442266807

Epoch: 5| Step: 9
Training loss: 2.5460051004638884
Validation loss: 2.5137068581289532

Epoch: 5| Step: 10
Training loss: 2.2358080130029725
Validation loss: 2.5194441353969346

Epoch: 5| Step: 11
Training loss: 1.6034991952330875
Validation loss: 2.5226210778285934

Epoch: 281| Step: 0
Training loss: 2.0479342217014724
Validation loss: 2.537051765271394

Epoch: 5| Step: 1
Training loss: 2.5412597538976187
Validation loss: 2.549830997233417

Epoch: 5| Step: 2
Training loss: 2.8351240856861613
Validation loss: 2.538773572083878

Epoch: 5| Step: 3
Training loss: 1.9314067764596288
Validation loss: 2.543921530936406

Epoch: 5| Step: 4
Training loss: 2.577104771205474
Validation loss: 2.5483842563115195

Epoch: 5| Step: 5
Training loss: 2.940780755518229
Validation loss: 2.5396276383033665

Epoch: 5| Step: 6
Training loss: 1.877240177874106
Validation loss: 2.524270631710946

Epoch: 5| Step: 7
Training loss: 2.3092675169837595
Validation loss: 2.5338616575239485

Epoch: 5| Step: 8
Training loss: 2.2971999788366997
Validation loss: 2.518224214524637

Epoch: 5| Step: 9
Training loss: 2.2821048545786105
Validation loss: 2.515545719390161

Epoch: 5| Step: 10
Training loss: 2.185442692759566
Validation loss: 2.5150287703504732

Epoch: 5| Step: 11
Training loss: 3.1880944389608974
Validation loss: 2.512336271401293

Epoch: 282| Step: 0
Training loss: 2.598031244960784
Validation loss: 2.5086115517782086

Epoch: 5| Step: 1
Training loss: 1.8604798440433459
Validation loss: 2.505613501783977

Epoch: 5| Step: 2
Training loss: 3.027462195263551
Validation loss: 2.5009129248142568

Epoch: 5| Step: 3
Training loss: 2.2668085624187113
Validation loss: 2.4968560238380886

Epoch: 5| Step: 4
Training loss: 2.633885739326896
Validation loss: 2.4969146067311185

Epoch: 5| Step: 5
Training loss: 2.4051508188839987
Validation loss: 2.5034060958145243

Epoch: 5| Step: 6
Training loss: 2.2191505607835134
Validation loss: 2.5035341157873674

Epoch: 5| Step: 7
Training loss: 2.106698605902914
Validation loss: 2.4977051851937526

Epoch: 5| Step: 8
Training loss: 2.20653772828336
Validation loss: 2.4966902201763417

Epoch: 5| Step: 9
Training loss: 1.9518832722689214
Validation loss: 2.4959028725231813

Epoch: 5| Step: 10
Training loss: 2.8625693900014446
Validation loss: 2.492851710921928

Epoch: 5| Step: 11
Training loss: 2.5139306090132227
Validation loss: 2.501179210392529

Epoch: 283| Step: 0
Training loss: 2.916018895468695
Validation loss: 2.5061701331410076

Epoch: 5| Step: 1
Training loss: 1.819594736985809
Validation loss: 2.510346693960564

Epoch: 5| Step: 2
Training loss: 1.8232793901240956
Validation loss: 2.504922617892839

Epoch: 5| Step: 3
Training loss: 2.3624570812383787
Validation loss: 2.5025841232169332

Epoch: 5| Step: 4
Training loss: 2.7109279137697495
Validation loss: 2.509270668948787

Epoch: 5| Step: 5
Training loss: 2.289628307212061
Validation loss: 2.510457882734084

Epoch: 5| Step: 6
Training loss: 2.7993098907155334
Validation loss: 2.505902161880842

Epoch: 5| Step: 7
Training loss: 2.2063354475640677
Validation loss: 2.510159836818089

Epoch: 5| Step: 8
Training loss: 1.673411225042289
Validation loss: 2.5095265869619197

Epoch: 5| Step: 9
Training loss: 2.0846352387586458
Validation loss: 2.5128194553680805

Epoch: 5| Step: 10
Training loss: 2.978030506087946
Validation loss: 2.508667579244795

Epoch: 5| Step: 11
Training loss: 2.187139208876826
Validation loss: 2.515312062814518

Epoch: 284| Step: 0
Training loss: 2.4606002334305637
Validation loss: 2.5097224567030647

Epoch: 5| Step: 1
Training loss: 2.5318194090334516
Validation loss: 2.5086582100711583

Epoch: 5| Step: 2
Training loss: 2.518990392075252
Validation loss: 2.516531395960946

Epoch: 5| Step: 3
Training loss: 2.113350181372038
Validation loss: 2.51997461681159

Epoch: 5| Step: 4
Training loss: 2.312404527497623
Validation loss: 2.5269996845168174

Epoch: 5| Step: 5
Training loss: 1.7778374625492084
Validation loss: 2.515730071785868

Epoch: 5| Step: 6
Training loss: 2.020591236307924
Validation loss: 2.5284368793387935

Epoch: 5| Step: 7
Training loss: 2.8203684624273793
Validation loss: 2.503906817344407

Epoch: 5| Step: 8
Training loss: 2.4701607451855567
Validation loss: 2.504733737924114

Epoch: 5| Step: 9
Training loss: 2.4243819520815726
Validation loss: 2.505579095529224

Epoch: 5| Step: 10
Training loss: 2.481988012065109
Validation loss: 2.5160155615105495

Epoch: 5| Step: 11
Training loss: 1.938184986237974
Validation loss: 2.513656790055008

Epoch: 285| Step: 0
Training loss: 2.3705649878270014
Validation loss: 2.5292578145549607

Epoch: 5| Step: 1
Training loss: 2.0433353948453097
Validation loss: 2.5318524934811557

Epoch: 5| Step: 2
Training loss: 2.3811379473897585
Validation loss: 2.518238410156916

Epoch: 5| Step: 3
Training loss: 2.389373052557836
Validation loss: 2.527011399425925

Epoch: 5| Step: 4
Training loss: 2.2536375523600123
Validation loss: 2.5053239440149047

Epoch: 5| Step: 5
Training loss: 2.665513524433517
Validation loss: 2.498633166029646

Epoch: 5| Step: 6
Training loss: 2.995997460918089
Validation loss: 2.501413966702794

Epoch: 5| Step: 7
Training loss: 2.5187125835053323
Validation loss: 2.512761344096401

Epoch: 5| Step: 8
Training loss: 1.8565737997397262
Validation loss: 2.5079747560483963

Epoch: 5| Step: 9
Training loss: 2.0383676097584082
Validation loss: 2.5085333345738063

Epoch: 5| Step: 10
Training loss: 2.551328264500381
Validation loss: 2.517410004385783

Epoch: 5| Step: 11
Training loss: 1.3158266959446754
Validation loss: 2.504342876736361

Epoch: 286| Step: 0
Training loss: 1.8563974726501304
Validation loss: 2.5092618839965217

Epoch: 5| Step: 1
Training loss: 2.399634941470356
Validation loss: 2.5021390307344444

Epoch: 5| Step: 2
Training loss: 2.210562414696771
Validation loss: 2.5228165255159705

Epoch: 5| Step: 3
Training loss: 2.666188485267114
Validation loss: 2.528122437534362

Epoch: 5| Step: 4
Training loss: 2.4636909703073706
Validation loss: 2.529337175949089

Epoch: 5| Step: 5
Training loss: 2.485965147889692
Validation loss: 2.528915372574169

Epoch: 5| Step: 6
Training loss: 2.17211122394537
Validation loss: 2.520006155752051

Epoch: 5| Step: 7
Training loss: 1.919153286678413
Validation loss: 2.523339571789732

Epoch: 5| Step: 8
Training loss: 2.6382619905093594
Validation loss: 2.5285089294008634

Epoch: 5| Step: 9
Training loss: 2.3128847369193335
Validation loss: 2.512002439481392

Epoch: 5| Step: 10
Training loss: 2.7254611963684523
Validation loss: 2.513604808150783

Epoch: 5| Step: 11
Training loss: 1.8718809888740733
Validation loss: 2.5255729922174592

Epoch: 287| Step: 0
Training loss: 2.1847915230465413
Validation loss: 2.5123816604643645

Epoch: 5| Step: 1
Training loss: 2.011310424845343
Validation loss: 2.5077355116517333

Epoch: 5| Step: 2
Training loss: 2.1236999125016167
Validation loss: 2.507247572002528

Epoch: 5| Step: 3
Training loss: 2.466371476922427
Validation loss: 2.5118360437639233

Epoch: 5| Step: 4
Training loss: 2.6206830267164656
Validation loss: 2.51404169855231

Epoch: 5| Step: 5
Training loss: 1.9828934432778804
Validation loss: 2.5068095093995812

Epoch: 5| Step: 6
Training loss: 2.2347451283595645
Validation loss: 2.509007439588249

Epoch: 5| Step: 7
Training loss: 2.1318434305797656
Validation loss: 2.504527387381821

Epoch: 5| Step: 8
Training loss: 2.74417555165718
Validation loss: 2.5040438808122016

Epoch: 5| Step: 9
Training loss: 2.35701810828703
Validation loss: 2.505055255667527

Epoch: 5| Step: 10
Training loss: 2.898499686095869
Validation loss: 2.505013191939673

Epoch: 5| Step: 11
Training loss: 3.185001965197282
Validation loss: 2.5067158655295354

Epoch: 288| Step: 0
Training loss: 2.5898564541190106
Validation loss: 2.498517644017063

Epoch: 5| Step: 1
Training loss: 2.2519519604086864
Validation loss: 2.498793390281203

Epoch: 5| Step: 2
Training loss: 2.588424178488372
Validation loss: 2.517669561642865

Epoch: 5| Step: 3
Training loss: 2.2653984219609997
Validation loss: 2.526157826115746

Epoch: 5| Step: 4
Training loss: 2.1468357843318375
Validation loss: 2.536614639719492

Epoch: 5| Step: 5
Training loss: 2.6434937192821693
Validation loss: 2.536778715032111

Epoch: 5| Step: 6
Training loss: 1.8849052733239136
Validation loss: 2.526168219683297

Epoch: 5| Step: 7
Training loss: 2.3418650867750177
Validation loss: 2.5349732006193832

Epoch: 5| Step: 8
Training loss: 2.6125140468092014
Validation loss: 2.5120415645734897

Epoch: 5| Step: 9
Training loss: 2.5109607745304325
Validation loss: 2.4954194863095873

Epoch: 5| Step: 10
Training loss: 2.2754051895657796
Validation loss: 2.503379881506905

Epoch: 5| Step: 11
Training loss: 2.267776309740828
Validation loss: 2.496666851924368

Epoch: 289| Step: 0
Training loss: 2.336026499401966
Validation loss: 2.4855015437770387

Epoch: 5| Step: 1
Training loss: 2.287702449324008
Validation loss: 2.5043849755229632

Epoch: 5| Step: 2
Training loss: 2.6379713459902527
Validation loss: 2.513993514121901

Epoch: 5| Step: 3
Training loss: 1.9463928776839239
Validation loss: 2.5096213114965757

Epoch: 5| Step: 4
Training loss: 2.592613154915098
Validation loss: 2.5106525442233023

Epoch: 5| Step: 5
Training loss: 2.29434272113686
Validation loss: 2.5089990813285428

Epoch: 5| Step: 6
Training loss: 2.246761746795328
Validation loss: 2.518108689832978

Epoch: 5| Step: 7
Training loss: 2.4003847648232473
Validation loss: 2.5203773477579303

Epoch: 5| Step: 8
Training loss: 2.4529792110590125
Validation loss: 2.5058359990921364

Epoch: 5| Step: 9
Training loss: 2.4911095850181084
Validation loss: 2.5374429203059083

Epoch: 5| Step: 10
Training loss: 2.4320644514867
Validation loss: 2.526318211837093

Epoch: 5| Step: 11
Training loss: 0.4680151583629413
Validation loss: 2.52224677763505

Epoch: 290| Step: 0
Training loss: 1.9267887474550334
Validation loss: 2.511602265547593

Epoch: 5| Step: 1
Training loss: 2.6130606382847352
Validation loss: 2.520526537603333

Epoch: 5| Step: 2
Training loss: 2.8695058986126605
Validation loss: 2.51459803657268

Epoch: 5| Step: 3
Training loss: 2.7561676047675454
Validation loss: 2.516912036317282

Epoch: 5| Step: 4
Training loss: 2.1029808051684014
Validation loss: 2.513325196778115

Epoch: 5| Step: 5
Training loss: 2.3978980635101736
Validation loss: 2.504615627660869

Epoch: 5| Step: 6
Training loss: 2.5109101650646815
Validation loss: 2.515766120095781

Epoch: 5| Step: 7
Training loss: 1.6322402316300841
Validation loss: 2.5086006954084694

Epoch: 5| Step: 8
Training loss: 2.397204252902338
Validation loss: 2.509181424438227

Epoch: 5| Step: 9
Training loss: 2.081012068427973
Validation loss: 2.5081071215126323

Epoch: 5| Step: 10
Training loss: 2.5061696218030196
Validation loss: 2.5079225850726004

Epoch: 5| Step: 11
Training loss: 1.5605788054559533
Validation loss: 2.513297623460547

Epoch: 291| Step: 0
Training loss: 2.557070026517443
Validation loss: 2.502911025230875

Epoch: 5| Step: 1
Training loss: 2.182083289881088
Validation loss: 2.518317201660752

Epoch: 5| Step: 2
Training loss: 2.302149212154945
Validation loss: 2.504312134218593

Epoch: 5| Step: 3
Training loss: 2.3136544310185725
Validation loss: 2.511681597461084

Epoch: 5| Step: 4
Training loss: 2.769095016579595
Validation loss: 2.5103017073673564

Epoch: 5| Step: 5
Training loss: 2.2033586310561337
Validation loss: 2.5110736491131633

Epoch: 5| Step: 6
Training loss: 2.5176428053354925
Validation loss: 2.509139154720041

Epoch: 5| Step: 7
Training loss: 2.400328744784416
Validation loss: 2.5057682289361973

Epoch: 5| Step: 8
Training loss: 2.081819276593607
Validation loss: 2.5174355201393612

Epoch: 5| Step: 9
Training loss: 2.507104886721914
Validation loss: 2.5184584509617145

Epoch: 5| Step: 10
Training loss: 2.3213818073802477
Validation loss: 2.519337428323904

Epoch: 5| Step: 11
Training loss: 1.3535091075217363
Validation loss: 2.5587740730242796

Epoch: 292| Step: 0
Training loss: 2.7369792634556855
Validation loss: 2.5585955010716317

Epoch: 5| Step: 1
Training loss: 2.575105968628147
Validation loss: 2.5605358062435064

Epoch: 5| Step: 2
Training loss: 2.5844166135378255
Validation loss: 2.5255467916549543

Epoch: 5| Step: 3
Training loss: 2.143997765283701
Validation loss: 2.507045168950445

Epoch: 5| Step: 4
Training loss: 2.232012480061687
Validation loss: 2.5160947799372546

Epoch: 5| Step: 5
Training loss: 2.442075689469043
Validation loss: 2.5086382004720034

Epoch: 5| Step: 6
Training loss: 2.281357122545078
Validation loss: 2.528990922684303

Epoch: 5| Step: 7
Training loss: 2.5286004598981466
Validation loss: 2.5145078946933594

Epoch: 5| Step: 8
Training loss: 2.176606328321681
Validation loss: 2.50905947318706

Epoch: 5| Step: 9
Training loss: 2.096116052850854
Validation loss: 2.4990609789671137

Epoch: 5| Step: 10
Training loss: 2.1557984915995876
Validation loss: 2.501856337220475

Epoch: 5| Step: 11
Training loss: 1.0920211752665467
Validation loss: 2.49770514144352

Epoch: 293| Step: 0
Training loss: 2.085105930262892
Validation loss: 2.4985509944868776

Epoch: 5| Step: 1
Training loss: 2.1171958331968153
Validation loss: 2.507423073547999

Epoch: 5| Step: 2
Training loss: 2.242795004604349
Validation loss: 2.5042120339657865

Epoch: 5| Step: 3
Training loss: 2.3185960991057875
Validation loss: 2.516358341715161

Epoch: 5| Step: 4
Training loss: 2.5143427453756466
Validation loss: 2.510047562295464

Epoch: 5| Step: 5
Training loss: 1.881619783982569
Validation loss: 2.5012049671855334

Epoch: 5| Step: 6
Training loss: 3.047305189232086
Validation loss: 2.5029881421289764

Epoch: 5| Step: 7
Training loss: 2.525798059626441
Validation loss: 2.4990540701710575

Epoch: 5| Step: 8
Training loss: 2.389075980388564
Validation loss: 2.5046522960223503

Epoch: 5| Step: 9
Training loss: 2.505824837331405
Validation loss: 2.50196739111314

Epoch: 5| Step: 10
Training loss: 2.2849561293916847
Validation loss: 2.5196926410251526

Epoch: 5| Step: 11
Training loss: 1.9391784780831391
Validation loss: 2.519825005964542

Epoch: 294| Step: 0
Training loss: 2.293228056768258
Validation loss: 2.5148929257348356

Epoch: 5| Step: 1
Training loss: 2.2046150958029136
Validation loss: 2.5514514776690995

Epoch: 5| Step: 2
Training loss: 2.1231881439458644
Validation loss: 2.5315410580111775

Epoch: 5| Step: 3
Training loss: 2.203789468759102
Validation loss: 2.539638751246511

Epoch: 5| Step: 4
Training loss: 2.7088607176794572
Validation loss: 2.5065452725187383

Epoch: 5| Step: 5
Training loss: 2.316818123493122
Validation loss: 2.5162152097520125

Epoch: 5| Step: 6
Training loss: 2.526621224423349
Validation loss: 2.5000609310990125

Epoch: 5| Step: 7
Training loss: 2.4764681536396163
Validation loss: 2.5033669806016863

Epoch: 5| Step: 8
Training loss: 1.8439850091676544
Validation loss: 2.5050572067538184

Epoch: 5| Step: 9
Training loss: 2.8864612180561657
Validation loss: 2.494156740077291

Epoch: 5| Step: 10
Training loss: 2.4501740024045895
Validation loss: 2.5046077545029726

Epoch: 5| Step: 11
Training loss: 1.3946818636387797
Validation loss: 2.4952084319967267

Epoch: 295| Step: 0
Training loss: 2.5232558997034333
Validation loss: 2.516184377378356

Epoch: 5| Step: 1
Training loss: 2.517723203611724
Validation loss: 2.499060175989497

Epoch: 5| Step: 2
Training loss: 2.854376755010785
Validation loss: 2.5038515859618804

Epoch: 5| Step: 3
Training loss: 2.396772769901388
Validation loss: 2.4935323381202976

Epoch: 5| Step: 4
Training loss: 2.573897160773577
Validation loss: 2.4922060871128706

Epoch: 5| Step: 5
Training loss: 2.308247341753143
Validation loss: 2.505010550788289

Epoch: 5| Step: 6
Training loss: 1.5340552033658623
Validation loss: 2.4996942015224746

Epoch: 5| Step: 7
Training loss: 1.898938964421325
Validation loss: 2.5235706172195664

Epoch: 5| Step: 8
Training loss: 2.1216635597288165
Validation loss: 2.5455538515643688

Epoch: 5| Step: 9
Training loss: 2.5902942478541524
Validation loss: 2.564016157247148

Epoch: 5| Step: 10
Training loss: 2.6314933936115703
Validation loss: 2.534660714127519

Epoch: 5| Step: 11
Training loss: 2.0478181486082416
Validation loss: 2.5262616930173025

Epoch: 296| Step: 0
Training loss: 2.330799384453507
Validation loss: 2.5177208164796294

Epoch: 5| Step: 1
Training loss: 2.3130139991082634
Validation loss: 2.5296941614563986

Epoch: 5| Step: 2
Training loss: 2.548952063108609
Validation loss: 2.533066972629029

Epoch: 5| Step: 3
Training loss: 2.4195728804665424
Validation loss: 2.5159674780572754

Epoch: 5| Step: 4
Training loss: 2.055989364292229
Validation loss: 2.520196800154038

Epoch: 5| Step: 5
Training loss: 2.52229911707524
Validation loss: 2.5169870271104666

Epoch: 5| Step: 6
Training loss: 2.560257651655178
Validation loss: 2.5155760481911074

Epoch: 5| Step: 7
Training loss: 2.0261761016831037
Validation loss: 2.5082007787907665

Epoch: 5| Step: 8
Training loss: 2.5430149712881276
Validation loss: 2.5053022027356224

Epoch: 5| Step: 9
Training loss: 2.2763757758712932
Validation loss: 2.5237908839276897

Epoch: 5| Step: 10
Training loss: 2.386866588352961
Validation loss: 2.535864111574293

Epoch: 5| Step: 11
Training loss: 1.7237976168334435
Validation loss: 2.522445408892317

Epoch: 297| Step: 0
Training loss: 2.4420041260118173
Validation loss: 2.5218523024491275

Epoch: 5| Step: 1
Training loss: 2.0585674595466017
Validation loss: 2.524221060462649

Epoch: 5| Step: 2
Training loss: 2.4746410726129433
Validation loss: 2.5166072981086516

Epoch: 5| Step: 3
Training loss: 2.3205700869424017
Validation loss: 2.5204699756216606

Epoch: 5| Step: 4
Training loss: 2.168312389185642
Validation loss: 2.515579598374499

Epoch: 5| Step: 5
Training loss: 2.5763209649038066
Validation loss: 2.5176063656363628

Epoch: 5| Step: 6
Training loss: 2.246669954114522
Validation loss: 2.511108858329987

Epoch: 5| Step: 7
Training loss: 1.9685941361990775
Validation loss: 2.5217668772496014

Epoch: 5| Step: 8
Training loss: 2.760977163931233
Validation loss: 2.5127066513025107

Epoch: 5| Step: 9
Training loss: 2.374669302955862
Validation loss: 2.526190611128476

Epoch: 5| Step: 10
Training loss: 1.7762151803047386
Validation loss: 2.5180822222394617

Epoch: 5| Step: 11
Training loss: 4.125187031522807
Validation loss: 2.5235403392295606

Epoch: 298| Step: 0
Training loss: 2.2645746361344092
Validation loss: 2.526846772453836

Epoch: 5| Step: 1
Training loss: 2.497211426949803
Validation loss: 2.5189207889971885

Epoch: 5| Step: 2
Training loss: 2.64108552246401
Validation loss: 2.5388252656098467

Epoch: 5| Step: 3
Training loss: 1.6693386911137638
Validation loss: 2.555238471855849

Epoch: 5| Step: 4
Training loss: 2.2692288904791544
Validation loss: 2.5622716119605196

Epoch: 5| Step: 5
Training loss: 2.290772616221378
Validation loss: 2.5521687564696394

Epoch: 5| Step: 6
Training loss: 2.4731558585778357
Validation loss: 2.5349150975466404

Epoch: 5| Step: 7
Training loss: 2.5117157124787233
Validation loss: 2.516186459991842

Epoch: 5| Step: 8
Training loss: 2.6980145607252113
Validation loss: 2.5274163245069934

Epoch: 5| Step: 9
Training loss: 2.0394646843548108
Validation loss: 2.5234618722154

Epoch: 5| Step: 10
Training loss: 2.143495737016842
Validation loss: 2.521306991739955

Epoch: 5| Step: 11
Training loss: 3.353574491238585
Validation loss: 2.5113330701181114

Epoch: 299| Step: 0
Training loss: 2.0785333906166152
Validation loss: 2.5125707009080287

Epoch: 5| Step: 1
Training loss: 2.6221099566369874
Validation loss: 2.5141697064340147

Epoch: 5| Step: 2
Training loss: 2.6729949923838396
Validation loss: 2.5099572372023355

Epoch: 5| Step: 3
Training loss: 2.3237320590750232
Validation loss: 2.509889390320644

Epoch: 5| Step: 4
Training loss: 2.637008266802008
Validation loss: 2.5059655024076353

Epoch: 5| Step: 5
Training loss: 2.5505180281491957
Validation loss: 2.507601383469519

Epoch: 5| Step: 6
Training loss: 2.276403635486843
Validation loss: 2.499795643083502

Epoch: 5| Step: 7
Training loss: 2.1147812122783916
Validation loss: 2.5031803802828128

Epoch: 5| Step: 8
Training loss: 2.1881209445840604
Validation loss: 2.506532502840836

Epoch: 5| Step: 9
Training loss: 2.104816172857144
Validation loss: 2.524170825093613

Epoch: 5| Step: 10
Training loss: 2.2608690526971267
Validation loss: 2.516927022813907

Epoch: 5| Step: 11
Training loss: 1.805930366086162
Validation loss: 2.5173353774118343

Epoch: 300| Step: 0
Training loss: 2.7292282932302685
Validation loss: 2.5199225109601975

Epoch: 5| Step: 1
Training loss: 2.328618451762843
Validation loss: 2.536677542319358

Epoch: 5| Step: 2
Training loss: 2.376632330255425
Validation loss: 2.5375089773636286

Epoch: 5| Step: 3
Training loss: 2.756623095391382
Validation loss: 2.5475879131667494

Epoch: 5| Step: 4
Training loss: 2.4017121764121563
Validation loss: 2.5611448309936455

Epoch: 5| Step: 5
Training loss: 2.1436307645953008
Validation loss: 2.5719040655422694

Epoch: 5| Step: 6
Training loss: 2.095689700635592
Validation loss: 2.57146863434693

Epoch: 5| Step: 7
Training loss: 2.516489674068543
Validation loss: 2.5347120016289693

Epoch: 5| Step: 8
Training loss: 1.8765718229572028
Validation loss: 2.524484358201704

Epoch: 5| Step: 9
Training loss: 1.8861296624588613
Validation loss: 2.5221941653400566

Epoch: 5| Step: 10
Training loss: 2.439292542033722
Validation loss: 2.5079718724330915

Epoch: 5| Step: 11
Training loss: 3.4642764275360354
Validation loss: 2.519430163423154

Epoch: 301| Step: 0
Training loss: 1.6103522287417134
Validation loss: 2.5180654673081153

Epoch: 5| Step: 1
Training loss: 2.400670704901866
Validation loss: 2.5167494604458063

Epoch: 5| Step: 2
Training loss: 2.454011016037519
Validation loss: 2.5156135795760517

Epoch: 5| Step: 3
Training loss: 2.3050304093082357
Validation loss: 2.5263410561233366

Epoch: 5| Step: 4
Training loss: 2.654404122246961
Validation loss: 2.517390814127288

Epoch: 5| Step: 5
Training loss: 2.2318042825323605
Validation loss: 2.51742245054967

Epoch: 5| Step: 6
Training loss: 2.1554584985470586
Validation loss: 2.5309231943534054

Epoch: 5| Step: 7
Training loss: 2.2228256187872373
Validation loss: 2.532192682622409

Epoch: 5| Step: 8
Training loss: 2.247148189993924
Validation loss: 2.5297596708122243

Epoch: 5| Step: 9
Training loss: 2.958886072521403
Validation loss: 2.539800088805013

Epoch: 5| Step: 10
Training loss: 2.0496197417607562
Validation loss: 2.537678095638959

Epoch: 5| Step: 11
Training loss: 3.9680796379972985
Validation loss: 2.5246428729705523

Epoch: 302| Step: 0
Training loss: 2.0048511798070767
Validation loss: 2.5423217317530615

Epoch: 5| Step: 1
Training loss: 2.222505641453795
Validation loss: 2.542964941159632

Epoch: 5| Step: 2
Training loss: 2.558982295462157
Validation loss: 2.535168405277401

Epoch: 5| Step: 3
Training loss: 2.7785763694615584
Validation loss: 2.5403321676501456

Epoch: 5| Step: 4
Training loss: 2.0345003385358384
Validation loss: 2.5349377663877917

Epoch: 5| Step: 5
Training loss: 2.8580667807035973
Validation loss: 2.521952512007622

Epoch: 5| Step: 6
Training loss: 2.4214120730076343
Validation loss: 2.523157736088938

Epoch: 5| Step: 7
Training loss: 2.2294632069746436
Validation loss: 2.5333389445815766

Epoch: 5| Step: 8
Training loss: 2.1769693031442303
Validation loss: 2.52718435312516

Epoch: 5| Step: 9
Training loss: 2.272252039207226
Validation loss: 2.5335817840792347

Epoch: 5| Step: 10
Training loss: 2.0625042770803783
Validation loss: 2.5289594074107353

Epoch: 5| Step: 11
Training loss: 2.2456920496769857
Validation loss: 2.531729950947853

Epoch: 303| Step: 0
Training loss: 2.435932339998644
Validation loss: 2.522371494087303

Epoch: 5| Step: 1
Training loss: 2.0143717336790923
Validation loss: 2.5155566148960236

Epoch: 5| Step: 2
Training loss: 2.903563539624662
Validation loss: 2.521126254589041

Epoch: 5| Step: 3
Training loss: 2.6487065631496667
Validation loss: 2.5281875082366505

Epoch: 5| Step: 4
Training loss: 2.525620027465003
Validation loss: 2.518956535302326

Epoch: 5| Step: 5
Training loss: 2.3469043105081817
Validation loss: 2.5229387489211366

Epoch: 5| Step: 6
Training loss: 2.336265719520584
Validation loss: 2.5256763089160272

Epoch: 5| Step: 7
Training loss: 2.569822224060479
Validation loss: 2.5193739297331916

Epoch: 5| Step: 8
Training loss: 1.7539299706297196
Validation loss: 2.5102006705871567

Epoch: 5| Step: 9
Training loss: 2.083819510634059
Validation loss: 2.5131365550117954

Epoch: 5| Step: 10
Training loss: 1.8786237032349835
Validation loss: 2.505637357514325

Epoch: 5| Step: 11
Training loss: 2.1290717664298886
Validation loss: 2.516579395611537

Epoch: 304| Step: 0
Training loss: 2.1535779457201536
Validation loss: 2.534389515093196

Epoch: 5| Step: 1
Training loss: 1.821165548027791
Validation loss: 2.521642453936127

Epoch: 5| Step: 2
Training loss: 1.9039062099276771
Validation loss: 2.528667845991961

Epoch: 5| Step: 3
Training loss: 2.639317024925718
Validation loss: 2.5313560911009874

Epoch: 5| Step: 4
Training loss: 2.9835010467215484
Validation loss: 2.5483708152879467

Epoch: 5| Step: 5
Training loss: 2.565452549443717
Validation loss: 2.5374048700650276

Epoch: 5| Step: 6
Training loss: 1.853217564244302
Validation loss: 2.54670641834589

Epoch: 5| Step: 7
Training loss: 2.4535199473075284
Validation loss: 2.5171903119662504

Epoch: 5| Step: 8
Training loss: 2.2165840214784733
Validation loss: 2.5247715139247076

Epoch: 5| Step: 9
Training loss: 2.5171820519149803
Validation loss: 2.511936587650978

Epoch: 5| Step: 10
Training loss: 2.3295215284045026
Validation loss: 2.5107276289943257

Epoch: 5| Step: 11
Training loss: 3.255370764176618
Validation loss: 2.525112808496219

Epoch: 305| Step: 0
Training loss: 2.5196302290999055
Validation loss: 2.5143480456041614

Epoch: 5| Step: 1
Training loss: 2.353822148413058
Validation loss: 2.506927769911646

Epoch: 5| Step: 2
Training loss: 1.5061891345630958
Validation loss: 2.5239384629279122

Epoch: 5| Step: 3
Training loss: 2.461688408502717
Validation loss: 2.524231643037761

Epoch: 5| Step: 4
Training loss: 2.6430727657154924
Validation loss: 2.503324424206728

Epoch: 5| Step: 5
Training loss: 2.347211494145402
Validation loss: 2.5144765455636686

Epoch: 5| Step: 6
Training loss: 2.6727153505037
Validation loss: 2.52498288856978

Epoch: 5| Step: 7
Training loss: 1.6440766129706414
Validation loss: 2.5386006761803404

Epoch: 5| Step: 8
Training loss: 2.4372055658384273
Validation loss: 2.5252366949630427

Epoch: 5| Step: 9
Training loss: 2.069012849364982
Validation loss: 2.5254145259960343

Epoch: 5| Step: 10
Training loss: 2.821015500188013
Validation loss: 2.5378636508310795

Epoch: 5| Step: 11
Training loss: 1.6539074868480037
Validation loss: 2.533569344759734

Epoch: 306| Step: 0
Training loss: 2.117687884105518
Validation loss: 2.518052057759551

Epoch: 5| Step: 1
Training loss: 2.5736128654092005
Validation loss: 2.5086448294366415

Epoch: 5| Step: 2
Training loss: 2.0622243986081736
Validation loss: 2.522098516700762

Epoch: 5| Step: 3
Training loss: 2.5398344304345897
Validation loss: 2.515676620301286

Epoch: 5| Step: 4
Training loss: 2.0334357605864124
Validation loss: 2.513501327249968

Epoch: 5| Step: 5
Training loss: 2.2622662080978158
Validation loss: 2.5002120722784666

Epoch: 5| Step: 6
Training loss: 2.2516500992051336
Validation loss: 2.5079315093928423

Epoch: 5| Step: 7
Training loss: 2.910147893496811
Validation loss: 2.513138100584326

Epoch: 5| Step: 8
Training loss: 2.2625694980801314
Validation loss: 2.523007055994943

Epoch: 5| Step: 9
Training loss: 2.398023439135309
Validation loss: 2.521382545248972

Epoch: 5| Step: 10
Training loss: 2.293473612169278
Validation loss: 2.5403395507663666

Epoch: 5| Step: 11
Training loss: 1.5029770395653326
Validation loss: 2.5522537771386284

Epoch: 307| Step: 0
Training loss: 1.939231468050172
Validation loss: 2.5383728225297166

Epoch: 5| Step: 1
Training loss: 2.4543032398229383
Validation loss: 2.5444295762725253

Epoch: 5| Step: 2
Training loss: 2.0916655683577896
Validation loss: 2.544382982440628

Epoch: 5| Step: 3
Training loss: 1.7462239398254191
Validation loss: 2.5701249314097843

Epoch: 5| Step: 4
Training loss: 2.660808645680065
Validation loss: 2.5637124573692707

Epoch: 5| Step: 5
Training loss: 2.559390717063405
Validation loss: 2.545298554577609

Epoch: 5| Step: 6
Training loss: 2.439748362870072
Validation loss: 2.5431006183019558

Epoch: 5| Step: 7
Training loss: 2.6779057665620316
Validation loss: 2.534061154219232

Epoch: 5| Step: 8
Training loss: 2.492306888793932
Validation loss: 2.528250231507691

Epoch: 5| Step: 9
Training loss: 2.019758849904507
Validation loss: 2.5241804928577776

Epoch: 5| Step: 10
Training loss: 2.1820640597009127
Validation loss: 2.526624497624344

Epoch: 5| Step: 11
Training loss: 2.8568587775010794
Validation loss: 2.525459243381101

Epoch: 308| Step: 0
Training loss: 2.344856306281247
Validation loss: 2.5273960860826286

Epoch: 5| Step: 1
Training loss: 3.0927654202414243
Validation loss: 2.535972980902117

Epoch: 5| Step: 2
Training loss: 2.4279215488108705
Validation loss: 2.529274330382352

Epoch: 5| Step: 3
Training loss: 2.373965188507944
Validation loss: 2.528079531606139

Epoch: 5| Step: 4
Training loss: 1.7149816644428009
Validation loss: 2.538023472959473

Epoch: 5| Step: 5
Training loss: 1.8916614308333792
Validation loss: 2.550682673513817

Epoch: 5| Step: 6
Training loss: 1.9656254026961406
Validation loss: 2.5351880213113733

Epoch: 5| Step: 7
Training loss: 2.298873136042456
Validation loss: 2.5385899284939644

Epoch: 5| Step: 8
Training loss: 1.7799876910223396
Validation loss: 2.542477620362968

Epoch: 5| Step: 9
Training loss: 3.016927487248885
Validation loss: 2.530844577456172

Epoch: 5| Step: 10
Training loss: 2.372153332931184
Validation loss: 2.542448323598934

Epoch: 5| Step: 11
Training loss: 1.8071738286221084
Validation loss: 2.5403038316139943

Epoch: 309| Step: 0
Training loss: 2.223538563858203
Validation loss: 2.535657561765956

Epoch: 5| Step: 1
Training loss: 2.0372776682490747
Validation loss: 2.5284164212022873

Epoch: 5| Step: 2
Training loss: 3.1005863988680757
Validation loss: 2.543629272901512

Epoch: 5| Step: 3
Training loss: 1.848378401236366
Validation loss: 2.5448957292097347

Epoch: 5| Step: 4
Training loss: 1.9587169704318101
Validation loss: 2.546121600922367

Epoch: 5| Step: 5
Training loss: 1.6283956408935913
Validation loss: 2.552063390433313

Epoch: 5| Step: 6
Training loss: 1.8510954062482698
Validation loss: 2.5448547455918673

Epoch: 5| Step: 7
Training loss: 2.7128589867215616
Validation loss: 2.5359956050318524

Epoch: 5| Step: 8
Training loss: 2.3611734369566433
Validation loss: 2.5445726437550005

Epoch: 5| Step: 9
Training loss: 2.5287572572295685
Validation loss: 2.5414085817370315

Epoch: 5| Step: 10
Training loss: 2.480800816693705
Validation loss: 2.5332150308274817

Epoch: 5| Step: 11
Training loss: 3.4462777167566143
Validation loss: 2.5349454512925114

Epoch: 310| Step: 0
Training loss: 2.242310523934696
Validation loss: 2.5396502279202795

Epoch: 5| Step: 1
Training loss: 2.7048148457448917
Validation loss: 2.5449894632384913

Epoch: 5| Step: 2
Training loss: 2.2164989388857244
Validation loss: 2.5605274299602927

Epoch: 5| Step: 3
Training loss: 2.144284649343381
Validation loss: 2.5453843511154783

Epoch: 5| Step: 4
Training loss: 2.4459315482267363
Validation loss: 2.546478318602543

Epoch: 5| Step: 5
Training loss: 2.1287608805729485
Validation loss: 2.543232706319947

Epoch: 5| Step: 6
Training loss: 2.905957279025198
Validation loss: 2.5449512096479725

Epoch: 5| Step: 7
Training loss: 1.8569882886616933
Validation loss: 2.5421760093024437

Epoch: 5| Step: 8
Training loss: 2.175563835636566
Validation loss: 2.523216741804504

Epoch: 5| Step: 9
Training loss: 1.7254617211322103
Validation loss: 2.524741746109024

Epoch: 5| Step: 10
Training loss: 2.5000377652176873
Validation loss: 2.521232385550204

Epoch: 5| Step: 11
Training loss: 3.183814816902842
Validation loss: 2.5077024021719234

Epoch: 311| Step: 0
Training loss: 2.2936236146621973
Validation loss: 2.5168810368388064

Epoch: 5| Step: 1
Training loss: 1.6177770304867365
Validation loss: 2.5234606045983052

Epoch: 5| Step: 2
Training loss: 2.12702150121097
Validation loss: 2.5177351786947693

Epoch: 5| Step: 3
Training loss: 2.860391738312507
Validation loss: 2.530271878837676

Epoch: 5| Step: 4
Training loss: 2.094366865241891
Validation loss: 2.5360075506319544

Epoch: 5| Step: 5
Training loss: 2.6273139563988694
Validation loss: 2.5418437338473208

Epoch: 5| Step: 6
Training loss: 1.871078777850621
Validation loss: 2.540959749772993

Epoch: 5| Step: 7
Training loss: 2.771000696926243
Validation loss: 2.554920007078049

Epoch: 5| Step: 8
Training loss: 2.0988981807851523
Validation loss: 2.5424489839324904

Epoch: 5| Step: 9
Training loss: 2.0128243084344835
Validation loss: 2.545515664994256

Epoch: 5| Step: 10
Training loss: 2.4940777250168633
Validation loss: 2.544807999493816

Epoch: 5| Step: 11
Training loss: 3.086207124544362
Validation loss: 2.5513309394710397

Epoch: 312| Step: 0
Training loss: 2.5285616126343333
Validation loss: 2.542629330626835

Epoch: 5| Step: 1
Training loss: 2.7552502538211736
Validation loss: 2.561012751381581

Epoch: 5| Step: 2
Training loss: 2.598938864798752
Validation loss: 2.561781200916944

Epoch: 5| Step: 3
Training loss: 1.7146934495547725
Validation loss: 2.5526462569882438

Epoch: 5| Step: 4
Training loss: 1.8502948783727347
Validation loss: 2.5549179521495615

Epoch: 5| Step: 5
Training loss: 2.350506212620253
Validation loss: 2.553557839311409

Epoch: 5| Step: 6
Training loss: 2.367979615884114
Validation loss: 2.54814015113032

Epoch: 5| Step: 7
Training loss: 1.9187729775112257
Validation loss: 2.549223291157481

Epoch: 5| Step: 8
Training loss: 2.633061971645768
Validation loss: 2.574077750914113

Epoch: 5| Step: 9
Training loss: 2.023289855519229
Validation loss: 2.54303377286146

Epoch: 5| Step: 10
Training loss: 2.1429849132410865
Validation loss: 2.536172558288573

Epoch: 5| Step: 11
Training loss: 3.69656912021107
Validation loss: 2.518894241200581

Epoch: 313| Step: 0
Training loss: 1.8208375754696149
Validation loss: 2.527050702942344

Epoch: 5| Step: 1
Training loss: 1.9886906470284027
Validation loss: 2.523791769569127

Epoch: 5| Step: 2
Training loss: 1.9074958107278601
Validation loss: 2.525279680663581

Epoch: 5| Step: 3
Training loss: 2.66661625059471
Validation loss: 2.5276456256586655

Epoch: 5| Step: 4
Training loss: 2.2859847172771106
Validation loss: 2.5188433711096923

Epoch: 5| Step: 5
Training loss: 2.0810501048459633
Validation loss: 2.522018860562655

Epoch: 5| Step: 6
Training loss: 2.686713081302858
Validation loss: 2.515445201284988

Epoch: 5| Step: 7
Training loss: 2.213959478701844
Validation loss: 2.524920579869874

Epoch: 5| Step: 8
Training loss: 2.4621198447875026
Validation loss: 2.531915047488224

Epoch: 5| Step: 9
Training loss: 1.8813427138690595
Validation loss: 2.537152876075998

Epoch: 5| Step: 10
Training loss: 3.1508407318531484
Validation loss: 2.562932218371011

Epoch: 5| Step: 11
Training loss: 2.4376899449604394
Validation loss: 2.591864130086116

Epoch: 314| Step: 0
Training loss: 2.438819430334201
Validation loss: 2.599874412731334

Epoch: 5| Step: 1
Training loss: 3.018413144226735
Validation loss: 2.6150507274871524

Epoch: 5| Step: 2
Training loss: 1.8954313990949203
Validation loss: 2.6229393985077354

Epoch: 5| Step: 3
Training loss: 2.2508740316941718
Validation loss: 2.5572715041122596

Epoch: 5| Step: 4
Training loss: 2.4697133369740287
Validation loss: 2.5383820154961585

Epoch: 5| Step: 5
Training loss: 2.740392548501994
Validation loss: 2.530600307429237

Epoch: 5| Step: 6
Training loss: 2.6647943738726245
Validation loss: 2.528550411719566

Epoch: 5| Step: 7
Training loss: 2.4716062802401813
Validation loss: 2.5184845477648703

Epoch: 5| Step: 8
Training loss: 1.9877311380206542
Validation loss: 2.5481071144183036

Epoch: 5| Step: 9
Training loss: 1.848463531336639
Validation loss: 2.536376017044849

Epoch: 5| Step: 10
Training loss: 2.0753340946240635
Validation loss: 2.5194290790985394

Epoch: 5| Step: 11
Training loss: 0.9423526106822486
Validation loss: 2.527455664961826

Epoch: 315| Step: 0
Training loss: 2.4840656783716715
Validation loss: 2.5311629668920608

Epoch: 5| Step: 1
Training loss: 1.5641167477890234
Validation loss: 2.5263022468634215

Epoch: 5| Step: 2
Training loss: 2.8137771249935493
Validation loss: 2.5232579705747953

Epoch: 5| Step: 3
Training loss: 2.334421131336978
Validation loss: 2.522137193707083

Epoch: 5| Step: 4
Training loss: 1.695702714443267
Validation loss: 2.5396177887763254

Epoch: 5| Step: 5
Training loss: 3.1542182652743347
Validation loss: 2.5274503627422025

Epoch: 5| Step: 6
Training loss: 2.2119397159798244
Validation loss: 2.540855733037267

Epoch: 5| Step: 7
Training loss: 2.158657996111762
Validation loss: 2.554816337082054

Epoch: 5| Step: 8
Training loss: 2.115286674099529
Validation loss: 2.5707281717671293

Epoch: 5| Step: 9
Training loss: 2.309735062834229
Validation loss: 2.5596740732674093

Epoch: 5| Step: 10
Training loss: 2.266037055066956
Validation loss: 2.5813284882811653

Epoch: 5| Step: 11
Training loss: 3.2852613361982543
Validation loss: 2.5322676995002467

Epoch: 316| Step: 0
Training loss: 1.972845147785891
Validation loss: 2.5426393560242406

Epoch: 5| Step: 1
Training loss: 2.075898662975062
Validation loss: 2.5406601364189787

Epoch: 5| Step: 2
Training loss: 2.4621719412923926
Validation loss: 2.5152932495234883

Epoch: 5| Step: 3
Training loss: 2.3450670737818755
Validation loss: 2.51711437214624

Epoch: 5| Step: 4
Training loss: 2.067705117582676
Validation loss: 2.5141978431119894

Epoch: 5| Step: 5
Training loss: 2.4108934063442438
Validation loss: 2.51198513384374

Epoch: 5| Step: 6
Training loss: 2.334482307469984
Validation loss: 2.51842350622457

Epoch: 5| Step: 7
Training loss: 2.8587150437486737
Validation loss: 2.513787560121483

Epoch: 5| Step: 8
Training loss: 1.8204929115054733
Validation loss: 2.5236050301164044

Epoch: 5| Step: 9
Training loss: 2.884168352554418
Validation loss: 2.5160549973110515

Epoch: 5| Step: 10
Training loss: 2.091307396702465
Validation loss: 2.5272952531566855

Epoch: 5| Step: 11
Training loss: 2.263361780421386
Validation loss: 2.5222155601413014

Epoch: 317| Step: 0
Training loss: 2.03564868907362
Validation loss: 2.523581537125786

Epoch: 5| Step: 1
Training loss: 2.3920671688141217
Validation loss: 2.5568049110684714

Epoch: 5| Step: 2
Training loss: 3.0398407947111212
Validation loss: 2.5612344601843775

Epoch: 5| Step: 3
Training loss: 2.0951379758789086
Validation loss: 2.549422528758363

Epoch: 5| Step: 4
Training loss: 1.936281066901418
Validation loss: 2.5160636637862877

Epoch: 5| Step: 5
Training loss: 2.513300704525021
Validation loss: 2.5304341512405024

Epoch: 5| Step: 6
Training loss: 2.373767532999012
Validation loss: 2.505439927359898

Epoch: 5| Step: 7
Training loss: 2.4559864436654584
Validation loss: 2.514199536202144

Epoch: 5| Step: 8
Training loss: 2.4134706432136888
Validation loss: 2.5080357310605783

Epoch: 5| Step: 9
Training loss: 2.0170232373526966
Validation loss: 2.523976846066315

Epoch: 5| Step: 10
Training loss: 2.284828097264981
Validation loss: 2.5160211997465676

Epoch: 5| Step: 11
Training loss: 0.509188709244955
Validation loss: 2.520659449914403

Epoch: 318| Step: 0
Training loss: 2.4294276451175345
Validation loss: 2.5176515709082987

Epoch: 5| Step: 1
Training loss: 2.345850499182367
Validation loss: 2.5284351388124007

Epoch: 5| Step: 2
Training loss: 2.522187764982253
Validation loss: 2.5389898358242124

Epoch: 5| Step: 3
Training loss: 1.7404602794679107
Validation loss: 2.5225221058154466

Epoch: 5| Step: 4
Training loss: 2.2664103232146267
Validation loss: 2.5307515089126063

Epoch: 5| Step: 5
Training loss: 1.6012277392850869
Validation loss: 2.5312641912619807

Epoch: 5| Step: 6
Training loss: 3.0835028593180924
Validation loss: 2.517168558729447

Epoch: 5| Step: 7
Training loss: 2.2662139127186256
Validation loss: 2.5228922858242746

Epoch: 5| Step: 8
Training loss: 2.4301990816801657
Validation loss: 2.5198472014656432

Epoch: 5| Step: 9
Training loss: 2.4080828337315454
Validation loss: 2.5383081029471706

Epoch: 5| Step: 10
Training loss: 2.053255459662898
Validation loss: 2.51880853819996

Epoch: 5| Step: 11
Training loss: 1.4080108638311801
Validation loss: 2.5469876324920375

Epoch: 319| Step: 0
Training loss: 2.712992568054031
Validation loss: 2.5710841666033066

Epoch: 5| Step: 1
Training loss: 2.3757333125327498
Validation loss: 2.563320439504266

Epoch: 5| Step: 2
Training loss: 1.484042562100595
Validation loss: 2.545643100925487

Epoch: 5| Step: 3
Training loss: 2.1419769250390868
Validation loss: 2.5520236975001596

Epoch: 5| Step: 4
Training loss: 2.595966357337894
Validation loss: 2.5332571164595303

Epoch: 5| Step: 5
Training loss: 2.1826096502596366
Validation loss: 2.5281267441978144

Epoch: 5| Step: 6
Training loss: 2.710970128107638
Validation loss: 2.528132846601622

Epoch: 5| Step: 7
Training loss: 2.4852491076622942
Validation loss: 2.5291881287516222

Epoch: 5| Step: 8
Training loss: 2.5668582605299575
Validation loss: 2.5330718316980843

Epoch: 5| Step: 9
Training loss: 2.5223352251025175
Validation loss: 2.5390365892702116

Epoch: 5| Step: 10
Training loss: 1.7305326084039532
Validation loss: 2.5342382993884294

Epoch: 5| Step: 11
Training loss: 0.9032476942411461
Validation loss: 2.546358504707468

Epoch: 320| Step: 0
Training loss: 2.0632625672875045
Validation loss: 2.558182999349272

Epoch: 5| Step: 1
Training loss: 1.7290319673706016
Validation loss: 2.570629397938116

Epoch: 5| Step: 2
Training loss: 2.4906905410930675
Validation loss: 2.5620242351722804

Epoch: 5| Step: 3
Training loss: 1.8434021831827727
Validation loss: 2.5743588538241196

Epoch: 5| Step: 4
Training loss: 2.442970787757485
Validation loss: 2.5917987569549634

Epoch: 5| Step: 5
Training loss: 2.6400742718334875
Validation loss: 2.5680447810017895

Epoch: 5| Step: 6
Training loss: 2.2917405434462563
Validation loss: 2.55835337589585

Epoch: 5| Step: 7
Training loss: 2.009570350465302
Validation loss: 2.542435320072422

Epoch: 5| Step: 8
Training loss: 2.551266213738872
Validation loss: 2.522549609807631

Epoch: 5| Step: 9
Training loss: 2.704983816327602
Validation loss: 2.529040950361399

Epoch: 5| Step: 10
Training loss: 2.5348593327846842
Validation loss: 2.5425324502760205

Epoch: 5| Step: 11
Training loss: 2.248746310745784
Validation loss: 2.5377240335757394

Epoch: 321| Step: 0
Training loss: 2.307761311722056
Validation loss: 2.5326830257243236

Epoch: 5| Step: 1
Training loss: 2.488305778921486
Validation loss: 2.5291343371625663

Epoch: 5| Step: 2
Training loss: 2.0142726649448175
Validation loss: 2.523689288951651

Epoch: 5| Step: 3
Training loss: 2.39803159180385
Validation loss: 2.5232363995709277

Epoch: 5| Step: 4
Training loss: 2.697390786152918
Validation loss: 2.5211872976761933

Epoch: 5| Step: 5
Training loss: 2.7565949862046746
Validation loss: 2.516673523112509

Epoch: 5| Step: 6
Training loss: 2.6713664145265437
Validation loss: 2.5124649118152727

Epoch: 5| Step: 7
Training loss: 1.9361699368871563
Validation loss: 2.5366043986118965

Epoch: 5| Step: 8
Training loss: 1.4771615079881288
Validation loss: 2.552986515885408

Epoch: 5| Step: 9
Training loss: 2.7592989020044616
Validation loss: 2.557809318287276

Epoch: 5| Step: 10
Training loss: 2.100797265709218
Validation loss: 2.554958822947504

Epoch: 5| Step: 11
Training loss: 1.1570611119199925
Validation loss: 2.5322477509239447

Epoch: 322| Step: 0
Training loss: 1.645508899178981
Validation loss: 2.532615797455746

Epoch: 5| Step: 1
Training loss: 2.3789104593173964
Validation loss: 2.528349163961001

Epoch: 5| Step: 2
Training loss: 1.9956901127257944
Validation loss: 2.520748871315711

Epoch: 5| Step: 3
Training loss: 2.3309516899964726
Validation loss: 2.54061059169586

Epoch: 5| Step: 4
Training loss: 2.0694536838993733
Validation loss: 2.5193005991001356

Epoch: 5| Step: 5
Training loss: 2.817738296058032
Validation loss: 2.5219340968623225

Epoch: 5| Step: 6
Training loss: 2.530847022863533
Validation loss: 2.5250550352211114

Epoch: 5| Step: 7
Training loss: 2.4865576794682953
Validation loss: 2.524105499318191

Epoch: 5| Step: 8
Training loss: 2.718598197119087
Validation loss: 2.532109734639933

Epoch: 5| Step: 9
Training loss: 1.8965340322010125
Validation loss: 2.524954242574966

Epoch: 5| Step: 10
Training loss: 1.6116830515825824
Validation loss: 2.513304483221131

Epoch: 5| Step: 11
Training loss: 3.6325276581038786
Validation loss: 2.5161080696263705

Epoch: 323| Step: 0
Training loss: 2.375558988140272
Validation loss: 2.5120284570335696

Epoch: 5| Step: 1
Training loss: 2.2259102920182547
Validation loss: 2.524333180768022

Epoch: 5| Step: 2
Training loss: 1.9638918320728043
Validation loss: 2.5047021197112285

Epoch: 5| Step: 3
Training loss: 1.9398245249366697
Validation loss: 2.5393793113835263

Epoch: 5| Step: 4
Training loss: 2.2022031113293306
Validation loss: 2.523196516940856

Epoch: 5| Step: 5
Training loss: 2.349058218197601
Validation loss: 2.518046226812655

Epoch: 5| Step: 6
Training loss: 2.862818244667648
Validation loss: 2.513490549308919

Epoch: 5| Step: 7
Training loss: 2.6921072214548
Validation loss: 2.527203522083395

Epoch: 5| Step: 8
Training loss: 1.9811764868927748
Validation loss: 2.5150693236277304

Epoch: 5| Step: 9
Training loss: 2.252906934791101
Validation loss: 2.525336095580665

Epoch: 5| Step: 10
Training loss: 2.036571398732141
Validation loss: 2.5359570747508458

Epoch: 5| Step: 11
Training loss: 2.900199087478182
Validation loss: 2.5342068258509456

Epoch: 324| Step: 0
Training loss: 2.499661804212124
Validation loss: 2.5285026530708956

Epoch: 5| Step: 1
Training loss: 2.521276629434495
Validation loss: 2.5345402200813427

Epoch: 5| Step: 2
Training loss: 2.1934805723625153
Validation loss: 2.5319074671689843

Epoch: 5| Step: 3
Training loss: 2.113539702851831
Validation loss: 2.522187004815601

Epoch: 5| Step: 4
Training loss: 2.4070894832927614
Validation loss: 2.5091013067528034

Epoch: 5| Step: 5
Training loss: 1.9113173748987167
Validation loss: 2.51473308729388

Epoch: 5| Step: 6
Training loss: 2.7789000109199535
Validation loss: 2.508048615872452

Epoch: 5| Step: 7
Training loss: 2.151913913238686
Validation loss: 2.4970619003597787

Epoch: 5| Step: 8
Training loss: 2.2049175572282933
Validation loss: 2.5105946103156747

Epoch: 5| Step: 9
Training loss: 2.1658679027765824
Validation loss: 2.5146838613440905

Epoch: 5| Step: 10
Training loss: 2.5185595154022646
Validation loss: 2.5040819738244875

Epoch: 5| Step: 11
Training loss: 1.7359816524133742
Validation loss: 2.5091776949605205

Epoch: 325| Step: 0
Training loss: 2.600405874117355
Validation loss: 2.5066598102916715

Epoch: 5| Step: 1
Training loss: 2.4350328920246023
Validation loss: 2.523074018599435

Epoch: 5| Step: 2
Training loss: 2.482449727236061
Validation loss: 2.5271194727976938

Epoch: 5| Step: 3
Training loss: 2.0326451132234165
Validation loss: 2.5276904371971587

Epoch: 5| Step: 4
Training loss: 2.4206989016826155
Validation loss: 2.52731907324951

Epoch: 5| Step: 5
Training loss: 2.349472282894003
Validation loss: 2.5478002704620217

Epoch: 5| Step: 6
Training loss: 1.9658692491696728
Validation loss: 2.539829889386978

Epoch: 5| Step: 7
Training loss: 2.2277244346914604
Validation loss: 2.563677966728531

Epoch: 5| Step: 8
Training loss: 1.9901182311126047
Validation loss: 2.550799678874174

Epoch: 5| Step: 9
Training loss: 1.977779752424352
Validation loss: 2.551127746633387

Epoch: 5| Step: 10
Training loss: 2.7167058692241066
Validation loss: 2.5316649752199587

Epoch: 5| Step: 11
Training loss: 2.1668148234648505
Validation loss: 2.527681500105823

Epoch: 326| Step: 0
Training loss: 2.2948731502473767
Validation loss: 2.5236609746753493

Epoch: 5| Step: 1
Training loss: 2.35567907403392
Validation loss: 2.529547878462619

Epoch: 5| Step: 2
Training loss: 2.4735935839084946
Validation loss: 2.5327554354709907

Epoch: 5| Step: 3
Training loss: 1.8161041993063165
Validation loss: 2.537368036857031

Epoch: 5| Step: 4
Training loss: 2.6468444354061456
Validation loss: 2.5281891153360636

Epoch: 5| Step: 5
Training loss: 2.404809495831775
Validation loss: 2.526659665100123

Epoch: 5| Step: 6
Training loss: 2.3552353270405373
Validation loss: 2.535557944787316

Epoch: 5| Step: 7
Training loss: 1.8622600708104222
Validation loss: 2.5423624357944643

Epoch: 5| Step: 8
Training loss: 2.4370165614464256
Validation loss: 2.5252725013511155

Epoch: 5| Step: 9
Training loss: 2.2504764688173124
Validation loss: 2.548381227409553

Epoch: 5| Step: 10
Training loss: 2.157458422847003
Validation loss: 2.5397116119891145

Epoch: 5| Step: 11
Training loss: 2.6879632240118423
Validation loss: 2.534247726869663

Epoch: 327| Step: 0
Training loss: 2.2243278130984407
Validation loss: 2.576187014203901

Epoch: 5| Step: 1
Training loss: 1.9183577319840945
Validation loss: 2.560932750127273

Epoch: 5| Step: 2
Training loss: 2.274085932279732
Validation loss: 2.5721393690355354

Epoch: 5| Step: 3
Training loss: 2.4759651691162294
Validation loss: 2.556496398758859

Epoch: 5| Step: 4
Training loss: 2.3989683675839104
Validation loss: 2.568925520043085

Epoch: 5| Step: 5
Training loss: 2.890799522286483
Validation loss: 2.5551826666004094

Epoch: 5| Step: 6
Training loss: 2.6907019946416413
Validation loss: 2.549131345677746

Epoch: 5| Step: 7
Training loss: 2.18623217218283
Validation loss: 2.5277161635818337

Epoch: 5| Step: 8
Training loss: 2.018106987649226
Validation loss: 2.5002790096674867

Epoch: 5| Step: 9
Training loss: 1.9983254217076585
Validation loss: 2.5176682043027516

Epoch: 5| Step: 10
Training loss: 2.270292748551062
Validation loss: 2.504045773178188

Epoch: 5| Step: 11
Training loss: 2.3033364684124527
Validation loss: 2.5043797037924413

Epoch: 328| Step: 0
Training loss: 2.561548288903228
Validation loss: 2.50984561857005

Epoch: 5| Step: 1
Training loss: 2.113189187574191
Validation loss: 2.5359253581240764

Epoch: 5| Step: 2
Training loss: 2.376997559382077
Validation loss: 2.5221433125721715

Epoch: 5| Step: 3
Training loss: 2.3605099405129084
Validation loss: 2.5355972196495635

Epoch: 5| Step: 4
Training loss: 2.167754511514711
Validation loss: 2.5397711601198183

Epoch: 5| Step: 5
Training loss: 2.138237394329848
Validation loss: 2.5543577115505456

Epoch: 5| Step: 6
Training loss: 2.0993562483681174
Validation loss: 2.5512163726768526

Epoch: 5| Step: 7
Training loss: 2.0923611034020944
Validation loss: 2.5815316513811077

Epoch: 5| Step: 8
Training loss: 2.7119422831456124
Validation loss: 2.608012450887402

Epoch: 5| Step: 9
Training loss: 2.3824608715322744
Validation loss: 2.567354639594526

Epoch: 5| Step: 10
Training loss: 2.2532898904724554
Validation loss: 2.5687616108232065

Epoch: 5| Step: 11
Training loss: 3.620650082169926
Validation loss: 2.545087268809524

Epoch: 329| Step: 0
Training loss: 2.035081038302528
Validation loss: 2.5383763016937717

Epoch: 5| Step: 1
Training loss: 2.074822576819705
Validation loss: 2.5513478614184

Epoch: 5| Step: 2
Training loss: 2.5726302343976704
Validation loss: 2.5402062955130815

Epoch: 5| Step: 3
Training loss: 2.120266410534734
Validation loss: 2.525816784840887

Epoch: 5| Step: 4
Training loss: 2.646628062721786
Validation loss: 2.5351042151927548

Epoch: 5| Step: 5
Training loss: 2.5520709809503894
Validation loss: 2.5345822014012573

Epoch: 5| Step: 6
Training loss: 2.477599303009753
Validation loss: 2.5156854144437735

Epoch: 5| Step: 7
Training loss: 2.33155621110441
Validation loss: 2.5225382955584945

Epoch: 5| Step: 8
Training loss: 2.6117644191609375
Validation loss: 2.538920550168667

Epoch: 5| Step: 9
Training loss: 1.9912886443043114
Validation loss: 2.5245907828025964

Epoch: 5| Step: 10
Training loss: 2.2781123701250445
Validation loss: 2.534394693043339

Epoch: 5| Step: 11
Training loss: 1.9453389728996904
Validation loss: 2.536108395578041

Epoch: 330| Step: 0
Training loss: 2.764678879452013
Validation loss: 2.565107377852287

Epoch: 5| Step: 1
Training loss: 2.1252808104829306
Validation loss: 2.5616920406976913

Epoch: 5| Step: 2
Training loss: 2.3542435782592985
Validation loss: 2.56734053174407

Epoch: 5| Step: 3
Training loss: 1.9286220559029654
Validation loss: 2.5521058620055372

Epoch: 5| Step: 4
Training loss: 2.54588701240484
Validation loss: 2.552890880780943

Epoch: 5| Step: 5
Training loss: 2.1149336300800448
Validation loss: 2.5561731473069487

Epoch: 5| Step: 6
Training loss: 2.417389290295413
Validation loss: 2.5341492795008

Epoch: 5| Step: 7
Training loss: 1.992110306983328
Validation loss: 2.532510255339062

Epoch: 5| Step: 8
Training loss: 2.2180578737267367
Validation loss: 2.522472852678029

Epoch: 5| Step: 9
Training loss: 2.318339629760061
Validation loss: 2.537028502520582

Epoch: 5| Step: 10
Training loss: 2.583158538401269
Validation loss: 2.5338427918124267

Epoch: 5| Step: 11
Training loss: 1.525809139030029
Validation loss: 2.530217521360783

Epoch: 331| Step: 0
Training loss: 2.335717436462117
Validation loss: 2.535261446862246

Epoch: 5| Step: 1
Training loss: 1.895854495702432
Validation loss: 2.528306501558827

Epoch: 5| Step: 2
Training loss: 2.785195712843892
Validation loss: 2.539624063062463

Epoch: 5| Step: 3
Training loss: 2.617323322472623
Validation loss: 2.5678960926255696

Epoch: 5| Step: 4
Training loss: 2.03855193896882
Validation loss: 2.57716981166559

Epoch: 5| Step: 5
Training loss: 2.214615313878317
Validation loss: 2.568386941237274

Epoch: 5| Step: 6
Training loss: 2.181843774638205
Validation loss: 2.5770077953097363

Epoch: 5| Step: 7
Training loss: 2.2018674683909008
Validation loss: 2.554360488353826

Epoch: 5| Step: 8
Training loss: 2.462915019580813
Validation loss: 2.5581371880390162

Epoch: 5| Step: 9
Training loss: 2.387493301302315
Validation loss: 2.5567231520740163

Epoch: 5| Step: 10
Training loss: 2.2800378583810037
Validation loss: 2.5284072273631986

Epoch: 5| Step: 11
Training loss: 2.832389188048359
Validation loss: 2.529783008257679

Epoch: 332| Step: 0
Training loss: 2.306532505999625
Validation loss: 2.5143630493585536

Epoch: 5| Step: 1
Training loss: 2.3473670006919454
Validation loss: 2.5228216484650856

Epoch: 5| Step: 2
Training loss: 2.9104741070121016
Validation loss: 2.5059428588883463

Epoch: 5| Step: 3
Training loss: 2.598395358608122
Validation loss: 2.514056623130743

Epoch: 5| Step: 4
Training loss: 2.0920213993794197
Validation loss: 2.522471594409532

Epoch: 5| Step: 5
Training loss: 2.2586604971112716
Validation loss: 2.5142244661806044

Epoch: 5| Step: 6
Training loss: 2.4840338130805684
Validation loss: 2.5208952176298185

Epoch: 5| Step: 7
Training loss: 1.9890993604818088
Validation loss: 2.5100512825652452

Epoch: 5| Step: 8
Training loss: 1.2119668830715762
Validation loss: 2.5272527773647484

Epoch: 5| Step: 9
Training loss: 2.0882814646391465
Validation loss: 2.5105869399029945

Epoch: 5| Step: 10
Training loss: 2.5509475256570853
Validation loss: 2.527005986201184

Epoch: 5| Step: 11
Training loss: 2.3365069559599054
Validation loss: 2.538606178164204

Epoch: 333| Step: 0
Training loss: 2.230875542685132
Validation loss: 2.5272620265036934

Epoch: 5| Step: 1
Training loss: 2.2799676922968626
Validation loss: 2.5402798047853388

Epoch: 5| Step: 2
Training loss: 2.5644243969437626
Validation loss: 2.5428377030803397

Epoch: 5| Step: 3
Training loss: 2.4884626241601544
Validation loss: 2.5288645371139595

Epoch: 5| Step: 4
Training loss: 2.0012981255086175
Validation loss: 2.5461258868951417

Epoch: 5| Step: 5
Training loss: 2.0796364472024815
Validation loss: 2.526521005409675

Epoch: 5| Step: 6
Training loss: 2.337585480294902
Validation loss: 2.5455840023544116

Epoch: 5| Step: 7
Training loss: 1.7179676009066331
Validation loss: 2.5589698107460297

Epoch: 5| Step: 8
Training loss: 2.8630014571686826
Validation loss: 2.544610848380862

Epoch: 5| Step: 9
Training loss: 2.161687325599715
Validation loss: 2.5391511285425588

Epoch: 5| Step: 10
Training loss: 2.1864199560637205
Validation loss: 2.5584964568686566

Epoch: 5| Step: 11
Training loss: 1.8203142026966956
Validation loss: 2.5599647828314773

Epoch: 334| Step: 0
Training loss: 2.1637180756627483
Validation loss: 2.5534662794465266

Epoch: 5| Step: 1
Training loss: 2.9570198008468083
Validation loss: 2.5478782667030453

Epoch: 5| Step: 2
Training loss: 2.2380027930657325
Validation loss: 2.551630175834356

Epoch: 5| Step: 3
Training loss: 2.529942869664667
Validation loss: 2.5534921701937554

Epoch: 5| Step: 4
Training loss: 2.0335814960358207
Validation loss: 2.5560847708567325

Epoch: 5| Step: 5
Training loss: 2.4724243441000544
Validation loss: 2.5480792157237127

Epoch: 5| Step: 6
Training loss: 2.2080135353820682
Validation loss: 2.538263386884355

Epoch: 5| Step: 7
Training loss: 2.0397604263100906
Validation loss: 2.533626516112446

Epoch: 5| Step: 8
Training loss: 2.1492663085290356
Validation loss: 2.5549869264665084

Epoch: 5| Step: 9
Training loss: 2.35628888733038
Validation loss: 2.5703708097110862

Epoch: 5| Step: 10
Training loss: 1.7983933377912935
Validation loss: 2.573536768536778

Epoch: 5| Step: 11
Training loss: 2.085863090645275
Validation loss: 2.5561602602365174

Epoch: 335| Step: 0
Training loss: 1.9059419852130663
Validation loss: 2.569050534156335

Epoch: 5| Step: 1
Training loss: 2.8157221668340755
Validation loss: 2.5524654115393903

Epoch: 5| Step: 2
Training loss: 1.9721701447979454
Validation loss: 2.5544937927503937

Epoch: 5| Step: 3
Training loss: 2.0393504673858547
Validation loss: 2.552041977268335

Epoch: 5| Step: 4
Training loss: 2.048082534214763
Validation loss: 2.5484072594765323

Epoch: 5| Step: 5
Training loss: 2.548661056246292
Validation loss: 2.5513768652038102

Epoch: 5| Step: 6
Training loss: 2.720554673635281
Validation loss: 2.5392193868046826

Epoch: 5| Step: 7
Training loss: 1.9754621134112993
Validation loss: 2.5608241796490274

Epoch: 5| Step: 8
Training loss: 2.4278150991582295
Validation loss: 2.5370841040954404

Epoch: 5| Step: 9
Training loss: 2.1347887434060984
Validation loss: 2.543315361843968

Epoch: 5| Step: 10
Training loss: 2.192320172406915
Validation loss: 2.550331991375399

Epoch: 5| Step: 11
Training loss: 2.551675590069311
Validation loss: 2.522718817347573

Epoch: 336| Step: 0
Training loss: 1.334341333755217
Validation loss: 2.528165963575455

Epoch: 5| Step: 1
Training loss: 2.7671258162392887
Validation loss: 2.5268730932041863

Epoch: 5| Step: 2
Training loss: 2.4408964311443535
Validation loss: 2.529242555484221

Epoch: 5| Step: 3
Training loss: 2.820845619599385
Validation loss: 2.536910270727047

Epoch: 5| Step: 4
Training loss: 2.3539708373954222
Validation loss: 2.5482055644277755

Epoch: 5| Step: 5
Training loss: 2.3992526877713054
Validation loss: 2.5605211486998303

Epoch: 5| Step: 6
Training loss: 2.4912638611893594
Validation loss: 2.572562125073399

Epoch: 5| Step: 7
Training loss: 1.9909793556327158
Validation loss: 2.5296123960804024

Epoch: 5| Step: 8
Training loss: 2.2586552192295812
Validation loss: 2.517517827004656

Epoch: 5| Step: 9
Training loss: 2.1279168025725665
Validation loss: 2.5255436252271743

Epoch: 5| Step: 10
Training loss: 1.9430988999825833
Validation loss: 2.5122445734232244

Epoch: 5| Step: 11
Training loss: 2.456369186499314
Validation loss: 2.52223877045958

Epoch: 337| Step: 0
Training loss: 2.6033180888759824
Validation loss: 2.526443332841385

Epoch: 5| Step: 1
Training loss: 2.3575381777312643
Validation loss: 2.5136203992780244

Epoch: 5| Step: 2
Training loss: 2.2954220490511683
Validation loss: 2.5290175314353807

Epoch: 5| Step: 3
Training loss: 2.4670556930112935
Validation loss: 2.53779429919878

Epoch: 5| Step: 4
Training loss: 2.1089656856561576
Validation loss: 2.5347550774684677

Epoch: 5| Step: 5
Training loss: 2.1834953709040743
Validation loss: 2.549814069115337

Epoch: 5| Step: 6
Training loss: 2.2537002866046856
Validation loss: 2.5532013967687615

Epoch: 5| Step: 7
Training loss: 1.8556636667768103
Validation loss: 2.5457923827074924

Epoch: 5| Step: 8
Training loss: 2.67699579672186
Validation loss: 2.5724548949923536

Epoch: 5| Step: 9
Training loss: 2.0719848787794337
Validation loss: 2.549181753597984

Epoch: 5| Step: 10
Training loss: 2.450458997432053
Validation loss: 2.5460450237894947

Epoch: 5| Step: 11
Training loss: 1.085086955967635
Validation loss: 2.5441360919509237

Epoch: 338| Step: 0
Training loss: 2.3262848206076048
Validation loss: 2.541039242196095

Epoch: 5| Step: 1
Training loss: 2.292223313668754
Validation loss: 2.532413693972398

Epoch: 5| Step: 2
Training loss: 2.6005312046847866
Validation loss: 2.5137751236236605

Epoch: 5| Step: 3
Training loss: 2.4535619261572106
Validation loss: 2.5201173637827825

Epoch: 5| Step: 4
Training loss: 2.488124297505337
Validation loss: 2.54073007060582

Epoch: 5| Step: 5
Training loss: 2.054318703163528
Validation loss: 2.5123284679110722

Epoch: 5| Step: 6
Training loss: 2.353466289842091
Validation loss: 2.50183293185164

Epoch: 5| Step: 7
Training loss: 2.2662604131527755
Validation loss: 2.502790248964206

Epoch: 5| Step: 8
Training loss: 2.3116289508752605
Validation loss: 2.512594882002259

Epoch: 5| Step: 9
Training loss: 2.013741256155001
Validation loss: 2.4980512613512014

Epoch: 5| Step: 10
Training loss: 2.1666426168231863
Validation loss: 2.515855916799965

Epoch: 5| Step: 11
Training loss: 1.1726085147380005
Validation loss: 2.500848800889303

Epoch: 339| Step: 0
Training loss: 2.410759304776739
Validation loss: 2.509511967963298

Epoch: 5| Step: 1
Training loss: 1.796772033394953
Validation loss: 2.5059897313809514

Epoch: 5| Step: 2
Training loss: 2.2820865717120755
Validation loss: 2.546132445570509

Epoch: 5| Step: 3
Training loss: 2.8146454151760194
Validation loss: 2.544662372574828

Epoch: 5| Step: 4
Training loss: 2.0421824938968864
Validation loss: 2.5447130720191984

Epoch: 5| Step: 5
Training loss: 2.580981527410924
Validation loss: 2.5205952765763793

Epoch: 5| Step: 6
Training loss: 2.816750937862144
Validation loss: 2.5292388712983893

Epoch: 5| Step: 7
Training loss: 1.9177123479129419
Validation loss: 2.5106940465778163

Epoch: 5| Step: 8
Training loss: 2.376636543600215
Validation loss: 2.510770778030789

Epoch: 5| Step: 9
Training loss: 1.976362135309841
Validation loss: 2.520309607954863

Epoch: 5| Step: 10
Training loss: 2.2242289846738865
Validation loss: 2.512009702198058

Epoch: 5| Step: 11
Training loss: 1.3057914220969022
Validation loss: 2.519357538272371

Epoch: 340| Step: 0
Training loss: 2.643167208742493
Validation loss: 2.5235098601084935

Epoch: 5| Step: 1
Training loss: 2.6329220712200496
Validation loss: 2.5243489653644287

Epoch: 5| Step: 2
Training loss: 2.5694661239763334
Validation loss: 2.5092045573698565

Epoch: 5| Step: 3
Training loss: 2.1433651503618427
Validation loss: 2.5146411922807235

Epoch: 5| Step: 4
Training loss: 2.3778970015079026
Validation loss: 2.514720199202968

Epoch: 5| Step: 5
Training loss: 2.2470339192307676
Validation loss: 2.5138132232942927

Epoch: 5| Step: 6
Training loss: 2.3152946905830247
Validation loss: 2.5124098448449175

Epoch: 5| Step: 7
Training loss: 2.188464796655119
Validation loss: 2.5383122553506494

Epoch: 5| Step: 8
Training loss: 1.8953801406401194
Validation loss: 2.5198514907335454

Epoch: 5| Step: 9
Training loss: 1.86205028762682
Validation loss: 2.5425196464464683

Epoch: 5| Step: 10
Training loss: 2.384607758166705
Validation loss: 2.538961770431568

Epoch: 5| Step: 11
Training loss: 2.0462026875128987
Validation loss: 2.5326798760632045

Epoch: 341| Step: 0
Training loss: 1.9420015278269045
Validation loss: 2.5052919168995946

Epoch: 5| Step: 1
Training loss: 2.3348016433273475
Validation loss: 2.506868388717989

Epoch: 5| Step: 2
Training loss: 2.0459161507288095
Validation loss: 2.49685611136831

Epoch: 5| Step: 3
Training loss: 2.166766849060146
Validation loss: 2.5078116879407415

Epoch: 5| Step: 4
Training loss: 2.3060159249132193
Validation loss: 2.504810207769698

Epoch: 5| Step: 5
Training loss: 2.5590210535958047
Validation loss: 2.50287229522024

Epoch: 5| Step: 6
Training loss: 2.7582484432960475
Validation loss: 2.5099004924472603

Epoch: 5| Step: 7
Training loss: 2.2467783009143276
Validation loss: 2.5310088698207736

Epoch: 5| Step: 8
Training loss: 2.225259071440464
Validation loss: 2.512479731096843

Epoch: 5| Step: 9
Training loss: 2.273722732321723
Validation loss: 2.5117790804232825

Epoch: 5| Step: 10
Training loss: 2.3043746477276312
Validation loss: 2.5247237565854617

Epoch: 5| Step: 11
Training loss: 1.662955475560392
Validation loss: 2.5223991887628667

Epoch: 342| Step: 0
Training loss: 2.5746247545910697
Validation loss: 2.527373650288971

Epoch: 5| Step: 1
Training loss: 2.0197508229583225
Validation loss: 2.544670281863957

Epoch: 5| Step: 2
Training loss: 2.2009661763706383
Validation loss: 2.614918320056687

Epoch: 5| Step: 3
Training loss: 2.457515796133288
Validation loss: 2.6232106490714204

Epoch: 5| Step: 4
Training loss: 2.424466033036784
Validation loss: 2.6623845414154395

Epoch: 5| Step: 5
Training loss: 2.138246426004335
Validation loss: 2.598523810125568

Epoch: 5| Step: 6
Training loss: 2.468783028297162
Validation loss: 2.565096934868289

Epoch: 5| Step: 7
Training loss: 2.1848134573562166
Validation loss: 2.5419636843364772

Epoch: 5| Step: 8
Training loss: 2.2496206175650224
Validation loss: 2.5143527926871556

Epoch: 5| Step: 9
Training loss: 2.2456307904333115
Validation loss: 2.515716408911006

Epoch: 5| Step: 10
Training loss: 2.2630718709782265
Validation loss: 2.5251110460079524

Epoch: 5| Step: 11
Training loss: 1.854513207387292
Validation loss: 2.529562552501876

Epoch: 343| Step: 0
Training loss: 2.1768770865496903
Validation loss: 2.5269124244254115

Epoch: 5| Step: 1
Training loss: 2.0337245246965714
Validation loss: 2.523277372115952

Epoch: 5| Step: 2
Training loss: 3.168248551097398
Validation loss: 2.5284443286210583

Epoch: 5| Step: 3
Training loss: 2.6962662488282407
Validation loss: 2.519790533558871

Epoch: 5| Step: 4
Training loss: 1.9320905294552375
Validation loss: 2.513649190243608

Epoch: 5| Step: 5
Training loss: 2.701732034035598
Validation loss: 2.514544430652769

Epoch: 5| Step: 6
Training loss: 1.967160809663834
Validation loss: 2.5074666181848038

Epoch: 5| Step: 7
Training loss: 1.5549133750117023
Validation loss: 2.513842462552392

Epoch: 5| Step: 8
Training loss: 2.1070629871369997
Validation loss: 2.524296605460001

Epoch: 5| Step: 9
Training loss: 2.47296034643927
Validation loss: 2.569281695054441

Epoch: 5| Step: 10
Training loss: 2.791857945356164
Validation loss: 2.5559954857754033

Epoch: 5| Step: 11
Training loss: 2.9665122181267702
Validation loss: 2.595827010245503

Epoch: 344| Step: 0
Training loss: 2.3949478060902463
Validation loss: 2.594885508615383

Epoch: 5| Step: 1
Training loss: 2.660514460125222
Validation loss: 2.563518240453603

Epoch: 5| Step: 2
Training loss: 2.1868026711843425
Validation loss: 2.5276906179823215

Epoch: 5| Step: 3
Training loss: 1.887121690644001
Validation loss: 2.5205017980508484

Epoch: 5| Step: 4
Training loss: 2.4897086033501887
Validation loss: 2.516562001049738

Epoch: 5| Step: 5
Training loss: 2.3481114814131563
Validation loss: 2.510902523310696

Epoch: 5| Step: 6
Training loss: 2.798198876784945
Validation loss: 2.512739046469604

Epoch: 5| Step: 7
Training loss: 2.617539749353775
Validation loss: 2.5234160722545167

Epoch: 5| Step: 8
Training loss: 1.9889243534177372
Validation loss: 2.5133794788868284

Epoch: 5| Step: 9
Training loss: 2.0979989054325183
Validation loss: 2.524974602864266

Epoch: 5| Step: 10
Training loss: 2.0929297363472625
Validation loss: 2.5065756864430346

Epoch: 5| Step: 11
Training loss: 1.6581924132595347
Validation loss: 2.5262579926872877

Epoch: 345| Step: 0
Training loss: 2.5097168913982077
Validation loss: 2.5304783166789138

Epoch: 5| Step: 1
Training loss: 2.349830369711494
Validation loss: 2.546391458772104

Epoch: 5| Step: 2
Training loss: 1.781862053370867
Validation loss: 2.5547662094854506

Epoch: 5| Step: 3
Training loss: 2.614376004168933
Validation loss: 2.5649278079885844

Epoch: 5| Step: 4
Training loss: 2.0897754123245633
Validation loss: 2.5652952920159415

Epoch: 5| Step: 5
Training loss: 2.140524868816005
Validation loss: 2.555751314618546

Epoch: 5| Step: 6
Training loss: 2.3239082193093776
Validation loss: 2.5663573803789745

Epoch: 5| Step: 7
Training loss: 2.2701854189796595
Validation loss: 2.578781764829789

Epoch: 5| Step: 8
Training loss: 2.5009394787798795
Validation loss: 2.5648830738087733

Epoch: 5| Step: 9
Training loss: 1.9653632082154457
Validation loss: 2.577017683109379

Epoch: 5| Step: 10
Training loss: 2.3402644369900347
Validation loss: 2.5851497622013007

Epoch: 5| Step: 11
Training loss: 1.886486726319351
Validation loss: 2.5892522758836556

Epoch: 346| Step: 0
Training loss: 2.2831385907662276
Validation loss: 2.582421785446071

Epoch: 5| Step: 1
Training loss: 2.394819780549475
Validation loss: 2.578960672440087

Epoch: 5| Step: 2
Training loss: 2.1692697831083017
Validation loss: 2.5571509683184295

Epoch: 5| Step: 3
Training loss: 2.587270157045752
Validation loss: 2.536938116036083

Epoch: 5| Step: 4
Training loss: 2.2021770196315864
Validation loss: 2.5659479073551243

Epoch: 5| Step: 5
Training loss: 1.615386549805262
Validation loss: 2.5648727519153782

Epoch: 5| Step: 6
Training loss: 2.135647520907214
Validation loss: 2.5799938941853746

Epoch: 5| Step: 7
Training loss: 2.498797604373121
Validation loss: 2.54972695668399

Epoch: 5| Step: 8
Training loss: 2.2689563331622042
Validation loss: 2.5600499171119018

Epoch: 5| Step: 9
Training loss: 2.3937766051245672
Validation loss: 2.548155219065969

Epoch: 5| Step: 10
Training loss: 1.9833379123004446
Validation loss: 2.5571496785531593

Epoch: 5| Step: 11
Training loss: 1.9908422378504835
Validation loss: 2.5393458868484915

Epoch: 347| Step: 0
Training loss: 1.4992111038879734
Validation loss: 2.5429416543715355

Epoch: 5| Step: 1
Training loss: 2.38874633373576
Validation loss: 2.554338678310669

Epoch: 5| Step: 2
Training loss: 2.725700788767262
Validation loss: 2.533805381459471

Epoch: 5| Step: 3
Training loss: 2.643440235649269
Validation loss: 2.5331379948980848

Epoch: 5| Step: 4
Training loss: 1.6902526727527465
Validation loss: 2.5266430417514782

Epoch: 5| Step: 5
Training loss: 2.5930515865692163
Validation loss: 2.532938731407485

Epoch: 5| Step: 6
Training loss: 2.0986706431632722
Validation loss: 2.5348234149178572

Epoch: 5| Step: 7
Training loss: 2.0453645214345566
Validation loss: 2.5305310747197964

Epoch: 5| Step: 8
Training loss: 2.621886086696241
Validation loss: 2.5360365026629244

Epoch: 5| Step: 9
Training loss: 2.334208176868071
Validation loss: 2.542670084441501

Epoch: 5| Step: 10
Training loss: 2.0939016714245984
Validation loss: 2.553205287609455

Epoch: 5| Step: 11
Training loss: 1.7136278990717473
Validation loss: 2.5289721659783715

Epoch: 348| Step: 0
Training loss: 2.4422409705851185
Validation loss: 2.5441065585237843

Epoch: 5| Step: 1
Training loss: 1.6785032133833575
Validation loss: 2.566221701820111

Epoch: 5| Step: 2
Training loss: 2.2158477499058775
Validation loss: 2.5886556547819617

Epoch: 5| Step: 3
Training loss: 2.208004465147009
Validation loss: 2.549754467219655

Epoch: 5| Step: 4
Training loss: 2.453426658403316
Validation loss: 2.5342587771658063

Epoch: 5| Step: 5
Training loss: 2.699100475231837
Validation loss: 2.5525569294687465

Epoch: 5| Step: 6
Training loss: 2.628805218097154
Validation loss: 2.544581931443674

Epoch: 5| Step: 7
Training loss: 1.942456212869679
Validation loss: 2.5388271359637002

Epoch: 5| Step: 8
Training loss: 2.221823055126906
Validation loss: 2.5524648199605573

Epoch: 5| Step: 9
Training loss: 1.6571075810356226
Validation loss: 2.536465644173135

Epoch: 5| Step: 10
Training loss: 2.3147412342103726
Validation loss: 2.542980446034151

Epoch: 5| Step: 11
Training loss: 2.010711832729838
Validation loss: 2.5747153266779375

Epoch: 349| Step: 0
Training loss: 1.984352532207021
Validation loss: 2.5569848629537373

Epoch: 5| Step: 1
Training loss: 1.5551432032743575
Validation loss: 2.562880148641164

Epoch: 5| Step: 2
Training loss: 2.692858123056364
Validation loss: 2.53065035039707

Epoch: 5| Step: 3
Training loss: 2.5346262514476545
Validation loss: 2.5413696253588705

Epoch: 5| Step: 4
Training loss: 2.3904220395168836
Validation loss: 2.5329397746510534

Epoch: 5| Step: 5
Training loss: 2.337813934623524
Validation loss: 2.532165854192554

Epoch: 5| Step: 6
Training loss: 1.2946772049354824
Validation loss: 2.5304676149732215

Epoch: 5| Step: 7
Training loss: 3.0571349502939973
Validation loss: 2.514384961198189

Epoch: 5| Step: 8
Training loss: 2.3613520542948505
Validation loss: 2.517774370553492

Epoch: 5| Step: 9
Training loss: 2.336980478416592
Validation loss: 2.5167539562998718

Epoch: 5| Step: 10
Training loss: 2.3028616186549447
Validation loss: 2.5020591878136216

Epoch: 5| Step: 11
Training loss: 1.9334960912838086
Validation loss: 2.5033672583825664

Epoch: 350| Step: 0
Training loss: 2.4529422764850333
Validation loss: 2.523099587317002

Epoch: 5| Step: 1
Training loss: 2.363884260942845
Validation loss: 2.5265176986531412

Epoch: 5| Step: 2
Training loss: 2.152723330831258
Validation loss: 2.521690862520228

Epoch: 5| Step: 3
Training loss: 2.180670075807596
Validation loss: 2.521177837118943

Epoch: 5| Step: 4
Training loss: 2.7249092401911392
Validation loss: 2.514456499299057

Epoch: 5| Step: 5
Training loss: 1.856616498428016
Validation loss: 2.516786840129612

Epoch: 5| Step: 6
Training loss: 2.2316790769240034
Validation loss: 2.5098957666282438

Epoch: 5| Step: 7
Training loss: 1.9447813113127081
Validation loss: 2.526886058874067

Epoch: 5| Step: 8
Training loss: 2.2326792437629246
Validation loss: 2.5179663714647083

Epoch: 5| Step: 9
Training loss: 2.052637622415086
Validation loss: 2.508852334101375

Epoch: 5| Step: 10
Training loss: 2.944906758255571
Validation loss: 2.5163592615549852

Epoch: 5| Step: 11
Training loss: 1.1844858766859492
Validation loss: 2.5112628394457395

Epoch: 351| Step: 0
Training loss: 1.8407589201466903
Validation loss: 2.5041724830682606

Epoch: 5| Step: 1
Training loss: 2.3845303706072585
Validation loss: 2.5156436745718542

Epoch: 5| Step: 2
Training loss: 2.0777667891313234
Validation loss: 2.4963048090526527

Epoch: 5| Step: 3
Training loss: 2.2583667114531374
Validation loss: 2.515690247852507

Epoch: 5| Step: 4
Training loss: 2.187648550166738
Validation loss: 2.4944808198216046

Epoch: 5| Step: 5
Training loss: 2.3349228508434425
Validation loss: 2.5087344058606558

Epoch: 5| Step: 6
Training loss: 2.081057437087578
Validation loss: 2.5153049755106323

Epoch: 5| Step: 7
Training loss: 1.8215503985804185
Validation loss: 2.496658022623246

Epoch: 5| Step: 8
Training loss: 2.3546714129085093
Validation loss: 2.5152642799002165

Epoch: 5| Step: 9
Training loss: 2.531720341441382
Validation loss: 2.5094250162159044

Epoch: 5| Step: 10
Training loss: 3.0540026118898744
Validation loss: 2.5144599167362323

Epoch: 5| Step: 11
Training loss: 3.094257659875506
Validation loss: 2.508589833051692

Epoch: 352| Step: 0
Training loss: 2.7528080042225196
Validation loss: 2.5231204862241614

Epoch: 5| Step: 1
Training loss: 2.0088669201307017
Validation loss: 2.5323282739484885

Epoch: 5| Step: 2
Training loss: 1.815982367165283
Validation loss: 2.5408652884451834

Epoch: 5| Step: 3
Training loss: 2.3279265248741
Validation loss: 2.586861029648121

Epoch: 5| Step: 4
Training loss: 1.919321426145757
Validation loss: 2.6094622644996255

Epoch: 5| Step: 5
Training loss: 2.7506835261426263
Validation loss: 2.589097860643899

Epoch: 5| Step: 6
Training loss: 2.757013740170471
Validation loss: 2.6207612836381924

Epoch: 5| Step: 7
Training loss: 1.8490205852792383
Validation loss: 2.553425487856851

Epoch: 5| Step: 8
Training loss: 2.3582895573663247
Validation loss: 2.537997079966804

Epoch: 5| Step: 9
Training loss: 1.852939077896155
Validation loss: 2.5163611091292397

Epoch: 5| Step: 10
Training loss: 2.8664240431317807
Validation loss: 2.52004187483535

Epoch: 5| Step: 11
Training loss: 3.475809697287499
Validation loss: 2.5317216598568417

Epoch: 353| Step: 0
Training loss: 1.9059257856973175
Validation loss: 2.5428403557291666

Epoch: 5| Step: 1
Training loss: 2.3673517654884497
Validation loss: 2.5292068347590146

Epoch: 5| Step: 2
Training loss: 1.9116441045669654
Validation loss: 2.5428376210396104

Epoch: 5| Step: 3
Training loss: 1.9254686206290403
Validation loss: 2.529233741708753

Epoch: 5| Step: 4
Training loss: 2.48009587887039
Validation loss: 2.541241494299168

Epoch: 5| Step: 5
Training loss: 3.0591406010579205
Validation loss: 2.519189883425989

Epoch: 5| Step: 6
Training loss: 2.139678523079789
Validation loss: 2.5449399910879986

Epoch: 5| Step: 7
Training loss: 2.5346849470721815
Validation loss: 2.5489214435511887

Epoch: 5| Step: 8
Training loss: 2.1024990334888463
Validation loss: 2.567086240505394

Epoch: 5| Step: 9
Training loss: 2.0212528409448405
Validation loss: 2.561722133394198

Epoch: 5| Step: 10
Training loss: 2.157637771504114
Validation loss: 2.618513031634345

Epoch: 5| Step: 11
Training loss: 3.5386092209377766
Validation loss: 2.6621105821942144

Epoch: 354| Step: 0
Training loss: 2.6485818019028313
Validation loss: 2.641769108656208

Epoch: 5| Step: 1
Training loss: 2.0400406986739488
Validation loss: 2.600978621601175

Epoch: 5| Step: 2
Training loss: 2.3410137225518404
Validation loss: 2.535661698921178

Epoch: 5| Step: 3
Training loss: 2.064456243160784
Validation loss: 2.5210224007147573

Epoch: 5| Step: 4
Training loss: 2.226217356918538
Validation loss: 2.5075186758337917

Epoch: 5| Step: 5
Training loss: 2.4520120221974304
Validation loss: 2.513454330029427

Epoch: 5| Step: 6
Training loss: 2.23722124547721
Validation loss: 2.5064442468141186

Epoch: 5| Step: 7
Training loss: 3.032148405041434
Validation loss: 2.5192697985724997

Epoch: 5| Step: 8
Training loss: 1.8809880324555408
Validation loss: 2.514272760766456

Epoch: 5| Step: 9
Training loss: 2.7567408049030435
Validation loss: 2.5035178309245536

Epoch: 5| Step: 10
Training loss: 2.0931820454972474
Validation loss: 2.5043888390716185

Epoch: 5| Step: 11
Training loss: 2.1775405865991617
Validation loss: 2.5101167821566475

Epoch: 355| Step: 0
Training loss: 2.6263656696772775
Validation loss: 2.481692629472958

Epoch: 5| Step: 1
Training loss: 2.215322183810354
Validation loss: 2.4922609587459146

Epoch: 5| Step: 2
Training loss: 2.4725794004336796
Validation loss: 2.495109941306544

Epoch: 5| Step: 3
Training loss: 2.2742796711180744
Validation loss: 2.5239633262313053

Epoch: 5| Step: 4
Training loss: 2.3932959900424704
Validation loss: 2.543807766857517

Epoch: 5| Step: 5
Training loss: 1.9410712031688802
Validation loss: 2.567486729579854

Epoch: 5| Step: 6
Training loss: 2.2191636680423286
Validation loss: 2.5490254331881066

Epoch: 5| Step: 7
Training loss: 2.480892980147042
Validation loss: 2.5279869114178837

Epoch: 5| Step: 8
Training loss: 2.2385214365498736
Validation loss: 2.537647310688308

Epoch: 5| Step: 9
Training loss: 2.3621954827615976
Validation loss: 2.5420503066232585

Epoch: 5| Step: 10
Training loss: 2.18777442300717
Validation loss: 2.508296705899484

Epoch: 5| Step: 11
Training loss: 2.529729409957468
Validation loss: 2.5241443148041345

Epoch: 356| Step: 0
Training loss: 2.638528747968728
Validation loss: 2.5062730447244004

Epoch: 5| Step: 1
Training loss: 2.4555288794762515
Validation loss: 2.529461896267915

Epoch: 5| Step: 2
Training loss: 2.7554299758765834
Validation loss: 2.523709399649521

Epoch: 5| Step: 3
Training loss: 2.461905249792091
Validation loss: 2.5349467053288066

Epoch: 5| Step: 4
Training loss: 2.038492525028524
Validation loss: 2.534634395860319

Epoch: 5| Step: 5
Training loss: 2.503079806144857
Validation loss: 2.5388656931187823

Epoch: 5| Step: 6
Training loss: 1.419068217615682
Validation loss: 2.5395060890243926

Epoch: 5| Step: 7
Training loss: 2.070965358074167
Validation loss: 2.5427851906120544

Epoch: 5| Step: 8
Training loss: 2.693908856657648
Validation loss: 2.554475625805474

Epoch: 5| Step: 9
Training loss: 1.8147436264605126
Validation loss: 2.5474804663665758

Epoch: 5| Step: 10
Training loss: 1.7201036844495619
Validation loss: 2.5622843829986404

Epoch: 5| Step: 11
Training loss: 3.008544198744765
Validation loss: 2.5445106312649672

Epoch: 357| Step: 0
Training loss: 2.412632984982807
Validation loss: 2.547397439025818

Epoch: 5| Step: 1
Training loss: 2.1611222216471173
Validation loss: 2.540825573056603

Epoch: 5| Step: 2
Training loss: 2.040574371971678
Validation loss: 2.5209825618700155

Epoch: 5| Step: 3
Training loss: 1.9894427970529767
Validation loss: 2.526678403587643

Epoch: 5| Step: 4
Training loss: 2.717210180134195
Validation loss: 2.51544596348901

Epoch: 5| Step: 5
Training loss: 2.7849466852259095
Validation loss: 2.503413444977749

Epoch: 5| Step: 6
Training loss: 1.9520083477826708
Validation loss: 2.508398571834686

Epoch: 5| Step: 7
Training loss: 2.3561704991535612
Validation loss: 2.509307039669958

Epoch: 5| Step: 8
Training loss: 1.9958688269573646
Validation loss: 2.50935152152904

Epoch: 5| Step: 9
Training loss: 2.6722518922776066
Validation loss: 2.4998705274116317

Epoch: 5| Step: 10
Training loss: 1.7797656650810292
Validation loss: 2.5118571550314854

Epoch: 5| Step: 11
Training loss: 1.7527034857969432
Validation loss: 2.528330023334233

Epoch: 358| Step: 0
Training loss: 2.312033838248862
Validation loss: 2.5297029107959386

Epoch: 5| Step: 1
Training loss: 2.2332725739635815
Validation loss: 2.5266795201863723

Epoch: 5| Step: 2
Training loss: 2.867401863420978
Validation loss: 2.5369199075645468

Epoch: 5| Step: 3
Training loss: 1.6808798173268162
Validation loss: 2.5354520432180845

Epoch: 5| Step: 4
Training loss: 2.425816632441231
Validation loss: 2.5577093017738695

Epoch: 5| Step: 5
Training loss: 1.6834407303168188
Validation loss: 2.5407611192663064

Epoch: 5| Step: 6
Training loss: 1.6437673357495424
Validation loss: 2.5409522355324476

Epoch: 5| Step: 7
Training loss: 2.0157073248086164
Validation loss: 2.5513776361416545

Epoch: 5| Step: 8
Training loss: 2.583048702269688
Validation loss: 2.5205917846927792

Epoch: 5| Step: 9
Training loss: 2.7806459263781322
Validation loss: 2.53037152529026

Epoch: 5| Step: 10
Training loss: 2.177687845460043
Validation loss: 2.5287538473288884

Epoch: 5| Step: 11
Training loss: 1.390412903802429
Validation loss: 2.5373516441849

Epoch: 359| Step: 0
Training loss: 1.8900023136427508
Validation loss: 2.5233999511318643

Epoch: 5| Step: 1
Training loss: 1.720459798523337
Validation loss: 2.5405098570334825

Epoch: 5| Step: 2
Training loss: 1.6410041007781644
Validation loss: 2.5365788994450464

Epoch: 5| Step: 3
Training loss: 2.696521078957154
Validation loss: 2.5288794292087915

Epoch: 5| Step: 4
Training loss: 2.1459775956433975
Validation loss: 2.5326644571799592

Epoch: 5| Step: 5
Training loss: 2.081234319587726
Validation loss: 2.538132055924537

Epoch: 5| Step: 6
Training loss: 2.6022851072155486
Validation loss: 2.5444055649775237

Epoch: 5| Step: 7
Training loss: 2.5324485672663934
Validation loss: 2.5351458149104

Epoch: 5| Step: 8
Training loss: 2.6197266061842983
Validation loss: 2.5485239483211597

Epoch: 5| Step: 9
Training loss: 2.4073485801986534
Validation loss: 2.558347512546557

Epoch: 5| Step: 10
Training loss: 2.214351538809219
Validation loss: 2.566381979817401

Epoch: 5| Step: 11
Training loss: 1.2247904228458923
Validation loss: 2.541327353534071

Epoch: 360| Step: 0
Training loss: 2.2604970844455035
Validation loss: 2.54650663664656

Epoch: 5| Step: 1
Training loss: 2.954902880729906
Validation loss: 2.540495119141588

Epoch: 5| Step: 2
Training loss: 1.7841857008057533
Validation loss: 2.5220088792423256

Epoch: 5| Step: 3
Training loss: 2.1673358715179014
Validation loss: 2.5290817247787625

Epoch: 5| Step: 4
Training loss: 1.6417302359780699
Validation loss: 2.5522708097353046

Epoch: 5| Step: 5
Training loss: 1.9886134381644824
Validation loss: 2.534532561384449

Epoch: 5| Step: 6
Training loss: 2.2103300844062295
Validation loss: 2.542189486986793

Epoch: 5| Step: 7
Training loss: 2.5338129325770917
Validation loss: 2.536680199451875

Epoch: 5| Step: 8
Training loss: 2.7072851549114034
Validation loss: 2.5339259810168664

Epoch: 5| Step: 9
Training loss: 2.132149282328465
Validation loss: 2.519006789868795

Epoch: 5| Step: 10
Training loss: 2.1778685934676125
Validation loss: 2.5345729397806203

Epoch: 5| Step: 11
Training loss: 0.9223880633230296
Validation loss: 2.526271051957444

Epoch: 361| Step: 0
Training loss: 2.217985424423827
Validation loss: 2.5231130054747233

Epoch: 5| Step: 1
Training loss: 2.0843321376894512
Validation loss: 2.5413128275625225

Epoch: 5| Step: 2
Training loss: 2.7785022320713524
Validation loss: 2.5472565932597093

Epoch: 5| Step: 3
Training loss: 2.393413637597398
Validation loss: 2.5306518813476964

Epoch: 5| Step: 4
Training loss: 2.4280140501618197
Validation loss: 2.525527368213089

Epoch: 5| Step: 5
Training loss: 1.6932290630952664
Validation loss: 2.529390401596159

Epoch: 5| Step: 6
Training loss: 2.3979387292805345
Validation loss: 2.5497258618668415

Epoch: 5| Step: 7
Training loss: 2.266787316346381
Validation loss: 2.5482674675091457

Epoch: 5| Step: 8
Training loss: 2.1396405260365485
Validation loss: 2.5365895479533584

Epoch: 5| Step: 9
Training loss: 1.9564969671680663
Validation loss: 2.53542971005581

Epoch: 5| Step: 10
Training loss: 1.8865231240779066
Validation loss: 2.5434182683381117

Epoch: 5| Step: 11
Training loss: 3.2262893819788596
Validation loss: 2.5411730792526637

Epoch: 362| Step: 0
Training loss: 2.1831388323782774
Validation loss: 2.560641774141309

Epoch: 5| Step: 1
Training loss: 2.3888856631511035
Validation loss: 2.544889545991634

Epoch: 5| Step: 2
Training loss: 2.7467502986650523
Validation loss: 2.5568750020016826

Epoch: 5| Step: 3
Training loss: 1.4030013388874085
Validation loss: 2.5374278983785747

Epoch: 5| Step: 4
Training loss: 2.576506690536509
Validation loss: 2.5512843801744665

Epoch: 5| Step: 5
Training loss: 2.218148055828759
Validation loss: 2.532497891170707

Epoch: 5| Step: 6
Training loss: 1.9902359323242802
Validation loss: 2.567798815378139

Epoch: 5| Step: 7
Training loss: 1.870215223646083
Validation loss: 2.586555933304718

Epoch: 5| Step: 8
Training loss: 2.779776364943612
Validation loss: 2.615241071841094

Epoch: 5| Step: 9
Training loss: 2.1813945033785425
Validation loss: 2.5907425852596493

Epoch: 5| Step: 10
Training loss: 1.6632507923467788
Validation loss: 2.6199470774750955

Epoch: 5| Step: 11
Training loss: 2.5302508230608476
Validation loss: 2.594990571488174

Epoch: 363| Step: 0
Training loss: 1.7508181975320356
Validation loss: 2.5825955711571176

Epoch: 5| Step: 1
Training loss: 1.5376768119064408
Validation loss: 2.558755274520131

Epoch: 5| Step: 2
Training loss: 2.1072256935592333
Validation loss: 2.5341793542958495

Epoch: 5| Step: 3
Training loss: 2.0046812347290417
Validation loss: 2.5399166646250024

Epoch: 5| Step: 4
Training loss: 2.108649913355056
Validation loss: 2.527544633683186

Epoch: 5| Step: 5
Training loss: 2.391368775197175
Validation loss: 2.5259685204261713

Epoch: 5| Step: 6
Training loss: 3.178334091045074
Validation loss: 2.5338308379669874

Epoch: 5| Step: 7
Training loss: 2.606842913982339
Validation loss: 2.535528675813879

Epoch: 5| Step: 8
Training loss: 2.3101803254262054
Validation loss: 2.5280984481844384

Epoch: 5| Step: 9
Training loss: 1.5117163054375018
Validation loss: 2.5430515195753305

Epoch: 5| Step: 10
Training loss: 2.538937797418471
Validation loss: 2.537207629205427

Epoch: 5| Step: 11
Training loss: 3.0581877574176413
Validation loss: 2.549514247482783

Epoch: 364| Step: 0
Training loss: 2.448872178180878
Validation loss: 2.5369029794424907

Epoch: 5| Step: 1
Training loss: 2.3650580670444317
Validation loss: 2.557113871767849

Epoch: 5| Step: 2
Training loss: 2.3472241910165006
Validation loss: 2.572387402779347

Epoch: 5| Step: 3
Training loss: 2.1785524756078405
Validation loss: 2.5779318496329338

Epoch: 5| Step: 4
Training loss: 2.126078612402016
Validation loss: 2.544024977165792

Epoch: 5| Step: 5
Training loss: 2.4056628613206894
Validation loss: 2.5449678773545275

Epoch: 5| Step: 6
Training loss: 1.8387176890487436
Validation loss: 2.5327793258009974

Epoch: 5| Step: 7
Training loss: 2.391943673851747
Validation loss: 2.535822392403623

Epoch: 5| Step: 8
Training loss: 1.8210259214229052
Validation loss: 2.5321233404452617

Epoch: 5| Step: 9
Training loss: 1.5929395821722718
Validation loss: 2.5546141019926156

Epoch: 5| Step: 10
Training loss: 2.8625307439627328
Validation loss: 2.530430629749698

Epoch: 5| Step: 11
Training loss: 2.201655337323541
Validation loss: 2.537495784098313

Epoch: 365| Step: 0
Training loss: 2.127691583849188
Validation loss: 2.5363477778117653

Epoch: 5| Step: 1
Training loss: 2.126933956848029
Validation loss: 2.5376755080576614

Epoch: 5| Step: 2
Training loss: 1.9716026589630888
Validation loss: 2.552707886990157

Epoch: 5| Step: 3
Training loss: 2.0603976082635564
Validation loss: 2.5509918207761215

Epoch: 5| Step: 4
Training loss: 2.4707797434389773
Validation loss: 2.5507882835209426

Epoch: 5| Step: 5
Training loss: 2.649019160580489
Validation loss: 2.560725085867881

Epoch: 5| Step: 6
Training loss: 2.4570029155510515
Validation loss: 2.544966554090947

Epoch: 5| Step: 7
Training loss: 1.956605663204254
Validation loss: 2.574122572295111

Epoch: 5| Step: 8
Training loss: 2.231139608264934
Validation loss: 2.5488086412252695

Epoch: 5| Step: 9
Training loss: 1.9272617429335193
Validation loss: 2.5719713715226367

Epoch: 5| Step: 10
Training loss: 2.6037788916205953
Validation loss: 2.5715298692616506

Epoch: 5| Step: 11
Training loss: 1.0875424935819173
Validation loss: 2.5434982834476423

Epoch: 366| Step: 0
Training loss: 2.3695323648522457
Validation loss: 2.56304494366736

Epoch: 5| Step: 1
Training loss: 2.101474235411219
Validation loss: 2.5525573342186196

Epoch: 5| Step: 2
Training loss: 2.470998295578471
Validation loss: 2.563033474851793

Epoch: 5| Step: 3
Training loss: 1.6982868313748105
Validation loss: 2.5615609549594955

Epoch: 5| Step: 4
Training loss: 1.7781208728816134
Validation loss: 2.5899881636227593

Epoch: 5| Step: 5
Training loss: 2.2448828045133573
Validation loss: 2.584925554391473

Epoch: 5| Step: 6
Training loss: 2.860159010835017
Validation loss: 2.574879767410238

Epoch: 5| Step: 7
Training loss: 2.3459804856902586
Validation loss: 2.5591596176632545

Epoch: 5| Step: 8
Training loss: 2.2675515238197983
Validation loss: 2.554768525062622

Epoch: 5| Step: 9
Training loss: 2.256940521497659
Validation loss: 2.5452606256771078

Epoch: 5| Step: 10
Training loss: 2.3929529760565034
Validation loss: 2.5324887003808145

Epoch: 5| Step: 11
Training loss: 1.639249752028951
Validation loss: 2.5310152753466717

Epoch: 367| Step: 0
Training loss: 2.558931890376565
Validation loss: 2.514222609133911

Epoch: 5| Step: 1
Training loss: 1.739494054943692
Validation loss: 2.5282326087950757

Epoch: 5| Step: 2
Training loss: 1.8719180527259243
Validation loss: 2.5358787216422716

Epoch: 5| Step: 3
Training loss: 1.9621046627837913
Validation loss: 2.55066284948631

Epoch: 5| Step: 4
Training loss: 3.2219160489890792
Validation loss: 2.5363061664742523

Epoch: 5| Step: 5
Training loss: 2.404759924122068
Validation loss: 2.517371998613571

Epoch: 5| Step: 6
Training loss: 2.219011962899637
Validation loss: 2.515506864028702

Epoch: 5| Step: 7
Training loss: 2.151019954494846
Validation loss: 2.513256256987961

Epoch: 5| Step: 8
Training loss: 2.044763888693301
Validation loss: 2.513114841791352

Epoch: 5| Step: 9
Training loss: 2.104771882697063
Validation loss: 2.5328529447244073

Epoch: 5| Step: 10
Training loss: 2.6055685822035395
Validation loss: 2.517130884772662

Epoch: 5| Step: 11
Training loss: 1.9386825029342034
Validation loss: 2.54433283474882

Epoch: 368| Step: 0
Training loss: 2.448800521259321
Validation loss: 2.523218907197857

Epoch: 5| Step: 1
Training loss: 2.009679379109421
Validation loss: 2.5192776318239463

Epoch: 5| Step: 2
Training loss: 1.66246263849253
Validation loss: 2.5322842976944

Epoch: 5| Step: 3
Training loss: 2.7610278526595167
Validation loss: 2.529986058116339

Epoch: 5| Step: 4
Training loss: 2.269025263625916
Validation loss: 2.541252029450659

Epoch: 5| Step: 5
Training loss: 2.6381721616359974
Validation loss: 2.5223849712555153

Epoch: 5| Step: 6
Training loss: 2.527119409901688
Validation loss: 2.5303903894009063

Epoch: 5| Step: 7
Training loss: 2.2289716569922016
Validation loss: 2.5147666651515546

Epoch: 5| Step: 8
Training loss: 2.3156247034729063
Validation loss: 2.5385846397468255

Epoch: 5| Step: 9
Training loss: 1.4825095250047253
Validation loss: 2.545611085467355

Epoch: 5| Step: 10
Training loss: 1.887840679825383
Validation loss: 2.543326884422359

Epoch: 5| Step: 11
Training loss: 2.0669985176601546
Validation loss: 2.5556772902480067

Epoch: 369| Step: 0
Training loss: 2.06626744516235
Validation loss: 2.552306482070031

Epoch: 5| Step: 1
Training loss: 2.8870687517754106
Validation loss: 2.5466354156015507

Epoch: 5| Step: 2
Training loss: 1.9936067200839822
Validation loss: 2.5380859414140153

Epoch: 5| Step: 3
Training loss: 1.5388566087595679
Validation loss: 2.5396194199357462

Epoch: 5| Step: 4
Training loss: 2.4363497440907382
Validation loss: 2.5371483184824917

Epoch: 5| Step: 5
Training loss: 1.8896288178285414
Validation loss: 2.547526211945336

Epoch: 5| Step: 6
Training loss: 2.5333155928375404
Validation loss: 2.5503354737008523

Epoch: 5| Step: 7
Training loss: 2.7405197419122067
Validation loss: 2.5452586585732107

Epoch: 5| Step: 8
Training loss: 2.140975366585218
Validation loss: 2.5392183657024563

Epoch: 5| Step: 9
Training loss: 1.780336513856181
Validation loss: 2.560252351405482

Epoch: 5| Step: 10
Training loss: 2.1898904001341277
Validation loss: 2.5698661262003615

Epoch: 5| Step: 11
Training loss: 1.875213738021066
Validation loss: 2.558033827067132

Epoch: 370| Step: 0
Training loss: 2.638319103454014
Validation loss: 2.5429207855404603

Epoch: 5| Step: 1
Training loss: 2.170501274539105
Validation loss: 2.560822278810031

Epoch: 5| Step: 2
Training loss: 1.9821913110611298
Validation loss: 2.545302906334432

Epoch: 5| Step: 3
Training loss: 1.8422557789037262
Validation loss: 2.5425310749516767

Epoch: 5| Step: 4
Training loss: 2.6458693574470464
Validation loss: 2.5401847941279065

Epoch: 5| Step: 5
Training loss: 1.431795660890435
Validation loss: 2.539905650678105

Epoch: 5| Step: 6
Training loss: 2.5798913626753333
Validation loss: 2.521186434761364

Epoch: 5| Step: 7
Training loss: 2.1986679552829007
Validation loss: 2.5339292036173697

Epoch: 5| Step: 8
Training loss: 2.1265506696407015
Validation loss: 2.543998255944504

Epoch: 5| Step: 9
Training loss: 2.6434792887289595
Validation loss: 2.5492766471645507

Epoch: 5| Step: 10
Training loss: 1.9769787255909481
Validation loss: 2.570953192665495

Epoch: 5| Step: 11
Training loss: 2.0228300029551947
Validation loss: 2.5832462808851795

Epoch: 371| Step: 0
Training loss: 2.3981746566836954
Validation loss: 2.660440953461735

Epoch: 5| Step: 1
Training loss: 2.248823282045441
Validation loss: 2.7309180250723695

Epoch: 5| Step: 2
Training loss: 2.6500996912792285
Validation loss: 2.700271202524748

Epoch: 5| Step: 3
Training loss: 2.596820805944695
Validation loss: 2.6409052036152136

Epoch: 5| Step: 4
Training loss: 2.7840043049154213
Validation loss: 2.5863789760682008

Epoch: 5| Step: 5
Training loss: 2.169584754556076
Validation loss: 2.536910760205657

Epoch: 5| Step: 6
Training loss: 2.659668820351089
Validation loss: 2.502720540675646

Epoch: 5| Step: 7
Training loss: 1.8270355630137158
Validation loss: 2.4984783866674753

Epoch: 5| Step: 8
Training loss: 1.8669513888290536
Validation loss: 2.5083844611088852

Epoch: 5| Step: 9
Training loss: 1.8162033788128078
Validation loss: 2.5010385382740092

Epoch: 5| Step: 10
Training loss: 2.7764835447335225
Validation loss: 2.5055180884858905

Epoch: 5| Step: 11
Training loss: 2.2498291798492116
Validation loss: 2.495641752021702

Epoch: 372| Step: 0
Training loss: 3.10052088391401
Validation loss: 2.513295004849221

Epoch: 5| Step: 1
Training loss: 1.894661621641833
Validation loss: 2.5073938307466843

Epoch: 5| Step: 2
Training loss: 2.3372932505843793
Validation loss: 2.5175999536152447

Epoch: 5| Step: 3
Training loss: 2.2884606100621774
Validation loss: 2.5020677399817752

Epoch: 5| Step: 4
Training loss: 2.2088875584925622
Validation loss: 2.5082095021090205

Epoch: 5| Step: 5
Training loss: 1.9196641813088675
Validation loss: 2.483172247503009

Epoch: 5| Step: 6
Training loss: 2.5504464226191614
Validation loss: 2.481793764107847

Epoch: 5| Step: 7
Training loss: 1.8733331901011745
Validation loss: 2.488919909252937

Epoch: 5| Step: 8
Training loss: 2.4316316045264412
Validation loss: 2.4775325989078167

Epoch: 5| Step: 9
Training loss: 2.8376301739783605
Validation loss: 2.4826043094695844

Epoch: 5| Step: 10
Training loss: 2.3336327451519883
Validation loss: 2.518597881907683

Epoch: 5| Step: 11
Training loss: 2.639687095073941
Validation loss: 2.538082606670703

Epoch: 373| Step: 0
Training loss: 1.7196734635204658
Validation loss: 2.520540004930103

Epoch: 5| Step: 1
Training loss: 1.9399146753404692
Validation loss: 2.5145243375210646

Epoch: 5| Step: 2
Training loss: 1.7684704293412274
Validation loss: 2.5053685124528395

Epoch: 5| Step: 3
Training loss: 2.9138365138894278
Validation loss: 2.519179731189604

Epoch: 5| Step: 4
Training loss: 2.7843528327102303
Validation loss: 2.501423299467901

Epoch: 5| Step: 5
Training loss: 1.9700201871970417
Validation loss: 2.5099157424541376

Epoch: 5| Step: 6
Training loss: 2.6286347066181337
Validation loss: 2.5057598400491745

Epoch: 5| Step: 7
Training loss: 2.0001481716582017
Validation loss: 2.4741545040589297

Epoch: 5| Step: 8
Training loss: 2.369084872527733
Validation loss: 2.4747227876362143

Epoch: 5| Step: 9
Training loss: 2.156146834849472
Validation loss: 2.490103034252129

Epoch: 5| Step: 10
Training loss: 2.6324352141230705
Validation loss: 2.4808333161541682

Epoch: 5| Step: 11
Training loss: 1.3833550719579173
Validation loss: 2.492454163765338

Epoch: 374| Step: 0
Training loss: 2.517001326417024
Validation loss: 2.494482050393684

Epoch: 5| Step: 1
Training loss: 2.2480182397312864
Validation loss: 2.5607347533441764

Epoch: 5| Step: 2
Training loss: 2.15940957159034
Validation loss: 2.55761875668643

Epoch: 5| Step: 3
Training loss: 2.110117463733807
Validation loss: 2.5265038464024516

Epoch: 5| Step: 4
Training loss: 2.3011956092751475
Validation loss: 2.528704676285577

Epoch: 5| Step: 5
Training loss: 2.413656651229249
Validation loss: 2.5196137486241135

Epoch: 5| Step: 6
Training loss: 2.287510368448742
Validation loss: 2.5289516768187337

Epoch: 5| Step: 7
Training loss: 2.2543293309589605
Validation loss: 2.5201293274893213

Epoch: 5| Step: 8
Training loss: 2.3648590621729766
Validation loss: 2.524258486923857

Epoch: 5| Step: 9
Training loss: 1.9956047519190663
Validation loss: 2.5140138011678483

Epoch: 5| Step: 10
Training loss: 2.0148951665523556
Validation loss: 2.5292995222119554

Epoch: 5| Step: 11
Training loss: 3.302593027402995
Validation loss: 2.5499674076602923

Epoch: 375| Step: 0
Training loss: 1.8420271501973604
Validation loss: 2.5266629205586217

Epoch: 5| Step: 1
Training loss: 1.8002490666051585
Validation loss: 2.5411670746214896

Epoch: 5| Step: 2
Training loss: 2.5260285577073405
Validation loss: 2.543567135866875

Epoch: 5| Step: 3
Training loss: 2.5923938193138216
Validation loss: 2.5564868085152677

Epoch: 5| Step: 4
Training loss: 2.793426774889129
Validation loss: 2.5397115181128718

Epoch: 5| Step: 5
Training loss: 2.148372024925597
Validation loss: 2.543182940235175

Epoch: 5| Step: 6
Training loss: 1.8643712468354072
Validation loss: 2.5606686611393297

Epoch: 5| Step: 7
Training loss: 1.5451821205672893
Validation loss: 2.576784158999571

Epoch: 5| Step: 8
Training loss: 1.832145963871743
Validation loss: 2.5413557211567603

Epoch: 5| Step: 9
Training loss: 2.70865695682669
Validation loss: 2.553124454176061

Epoch: 5| Step: 10
Training loss: 1.749026163803012
Validation loss: 2.551847693535211

Epoch: 5| Step: 11
Training loss: 3.616287152349701
Validation loss: 2.5586197596967875

Epoch: 376| Step: 0
Training loss: 2.3358768723188894
Validation loss: 2.5490002843171484

Epoch: 5| Step: 1
Training loss: 1.4201306552953996
Validation loss: 2.5575980231504265

Epoch: 5| Step: 2
Training loss: 2.1811494470717556
Validation loss: 2.551309138573139

Epoch: 5| Step: 3
Training loss: 2.170203134899707
Validation loss: 2.555152139202593

Epoch: 5| Step: 4
Training loss: 2.38917577361478
Validation loss: 2.5490886141011617

Epoch: 5| Step: 5
Training loss: 2.1692230720040073
Validation loss: 2.5493909465318807

Epoch: 5| Step: 6
Training loss: 1.7980899849546297
Validation loss: 2.545928681758157

Epoch: 5| Step: 7
Training loss: 2.453693008266254
Validation loss: 2.5307303786184914

Epoch: 5| Step: 8
Training loss: 2.39417168311888
Validation loss: 2.5175758166483853

Epoch: 5| Step: 9
Training loss: 2.439514892382551
Validation loss: 2.521810906914201

Epoch: 5| Step: 10
Training loss: 2.5235324522879123
Validation loss: 2.5336371966336353

Epoch: 5| Step: 11
Training loss: 1.8538434107596093
Validation loss: 2.5391738867169313

Epoch: 377| Step: 0
Training loss: 2.6059850727335916
Validation loss: 2.5513351991710747

Epoch: 5| Step: 1
Training loss: 1.944593794703075
Validation loss: 2.5594420601641605

Epoch: 5| Step: 2
Training loss: 2.2811930401105425
Validation loss: 2.547451698992105

Epoch: 5| Step: 3
Training loss: 1.8735983377858125
Validation loss: 2.5592021383830987

Epoch: 5| Step: 4
Training loss: 1.892901917465265
Validation loss: 2.557344495664012

Epoch: 5| Step: 5
Training loss: 2.144153888346548
Validation loss: 2.5528968675649946

Epoch: 5| Step: 6
Training loss: 1.9241858754852006
Validation loss: 2.5440596131989115

Epoch: 5| Step: 7
Training loss: 2.6211576041844795
Validation loss: 2.5779392984729737

Epoch: 5| Step: 8
Training loss: 2.1853679621251
Validation loss: 2.5813533260425725

Epoch: 5| Step: 9
Training loss: 2.4404870339838345
Validation loss: 2.5533528005697823

Epoch: 5| Step: 10
Training loss: 1.983238435392949
Validation loss: 2.5630046417359504

Epoch: 5| Step: 11
Training loss: 2.3002803755990198
Validation loss: 2.5689941666107354

Epoch: 378| Step: 0
Training loss: 2.642738354344123
Validation loss: 2.589354590187353

Epoch: 5| Step: 1
Training loss: 2.072011344186371
Validation loss: 2.6087246425098765

Epoch: 5| Step: 2
Training loss: 2.556903776026943
Validation loss: 2.617937047104831

Epoch: 5| Step: 3
Training loss: 1.9420708913622118
Validation loss: 2.585858169983042

Epoch: 5| Step: 4
Training loss: 2.262311103480391
Validation loss: 2.576132509182894

Epoch: 5| Step: 5
Training loss: 2.162931952582014
Validation loss: 2.5618013770965375

Epoch: 5| Step: 6
Training loss: 2.235146769370513
Validation loss: 2.543972616116274

Epoch: 5| Step: 7
Training loss: 1.9934645804231108
Validation loss: 2.547267009935771

Epoch: 5| Step: 8
Training loss: 2.9608154271711054
Validation loss: 2.53314895591574

Epoch: 5| Step: 9
Training loss: 1.8773718772682895
Validation loss: 2.54218266413783

Epoch: 5| Step: 10
Training loss: 2.0456514851329657
Validation loss: 2.544703661838311

Epoch: 5| Step: 11
Training loss: 2.6047799774211113
Validation loss: 2.548304805891169

Epoch: 379| Step: 0
Training loss: 1.9798881085887474
Validation loss: 2.5559496974440257

Epoch: 5| Step: 1
Training loss: 1.8393638940774648
Validation loss: 2.564679281349318

Epoch: 5| Step: 2
Training loss: 1.8054970911129866
Validation loss: 2.5861918909155492

Epoch: 5| Step: 3
Training loss: 2.789174139101907
Validation loss: 2.585722385152693

Epoch: 5| Step: 4
Training loss: 1.9247086886654732
Validation loss: 2.5759875559622256

Epoch: 5| Step: 5
Training loss: 2.684374921840893
Validation loss: 2.6004411611965588

Epoch: 5| Step: 6
Training loss: 2.1181915267352727
Validation loss: 2.614820915360289

Epoch: 5| Step: 7
Training loss: 2.558720755882848
Validation loss: 2.5784801739422445

Epoch: 5| Step: 8
Training loss: 2.6548621647288013
Validation loss: 2.547356873934951

Epoch: 5| Step: 9
Training loss: 2.1538689777192
Validation loss: 2.551275418653494

Epoch: 5| Step: 10
Training loss: 1.918085471523132
Validation loss: 2.5459711464158143

Epoch: 5| Step: 11
Training loss: 1.9177665526175873
Validation loss: 2.5352021199971366

Epoch: 380| Step: 0
Training loss: 2.6816567172507417
Validation loss: 2.522582307820531

Epoch: 5| Step: 1
Training loss: 2.296001865226706
Validation loss: 2.5095251658390643

Epoch: 5| Step: 2
Training loss: 1.9467813239668053
Validation loss: 2.504195263588777

Epoch: 5| Step: 3
Training loss: 2.1079470852357876
Validation loss: 2.513375755638413

Epoch: 5| Step: 4
Training loss: 2.2512152886560863
Validation loss: 2.5024379168230246

Epoch: 5| Step: 5
Training loss: 1.8715615852367735
Validation loss: 2.515213843918119

Epoch: 5| Step: 6
Training loss: 2.2948281646425763
Validation loss: 2.498450864207819

Epoch: 5| Step: 7
Training loss: 2.0263070633023066
Validation loss: 2.5050270876812664

Epoch: 5| Step: 8
Training loss: 2.7983968845744864
Validation loss: 2.5170254057447092

Epoch: 5| Step: 9
Training loss: 2.10882821237074
Validation loss: 2.5184366061201984

Epoch: 5| Step: 10
Training loss: 2.2397975612171686
Validation loss: 2.548157503614539

Epoch: 5| Step: 11
Training loss: 2.5473328161364726
Validation loss: 2.5274213437998223

Epoch: 381| Step: 0
Training loss: 2.2536481316130623
Validation loss: 2.5945436152104473

Epoch: 5| Step: 1
Training loss: 2.274067270416251
Validation loss: 2.60107824421805

Epoch: 5| Step: 2
Training loss: 2.3332371237765446
Validation loss: 2.581589176655996

Epoch: 5| Step: 3
Training loss: 1.751135457749611
Validation loss: 2.5778014856674236

Epoch: 5| Step: 4
Training loss: 2.3873868466071397
Validation loss: 2.562891259600578

Epoch: 5| Step: 5
Training loss: 2.002698151194069
Validation loss: 2.5760577805371576

Epoch: 5| Step: 6
Training loss: 2.8571378367243665
Validation loss: 2.5787152587589377

Epoch: 5| Step: 7
Training loss: 2.806153320822107
Validation loss: 2.573950009169807

Epoch: 5| Step: 8
Training loss: 2.1108976166950746
Validation loss: 2.5616427864119027

Epoch: 5| Step: 9
Training loss: 1.4216293290405317
Validation loss: 2.5848075380194446

Epoch: 5| Step: 10
Training loss: 1.5841892923621956
Validation loss: 2.6037148630497353

Epoch: 5| Step: 11
Training loss: 3.1312918837253076
Validation loss: 2.58837549429693

Epoch: 382| Step: 0
Training loss: 2.1641398391950806
Validation loss: 2.6082025814089156

Epoch: 5| Step: 1
Training loss: 1.992111862841107
Validation loss: 2.624787163053233

Epoch: 5| Step: 2
Training loss: 2.4831438192810915
Validation loss: 2.6463466594379095

Epoch: 5| Step: 3
Training loss: 2.7795084955175176
Validation loss: 2.6449638212009603

Epoch: 5| Step: 4
Training loss: 2.4417672584652577
Validation loss: 2.660726164099127

Epoch: 5| Step: 5
Training loss: 2.26286221128642
Validation loss: 2.594116495276126

Epoch: 5| Step: 6
Training loss: 2.0833793126436584
Validation loss: 2.585142841383114

Epoch: 5| Step: 7
Training loss: 2.3129801896001854
Validation loss: 2.5576183760422855

Epoch: 5| Step: 8
Training loss: 1.4728036498110013
Validation loss: 2.53371029661337

Epoch: 5| Step: 9
Training loss: 2.3055052260250903
Validation loss: 2.5223803495637753

Epoch: 5| Step: 10
Training loss: 2.0712084864690437
Validation loss: 2.486636468067538

Epoch: 5| Step: 11
Training loss: 0.9420859388078926
Validation loss: 2.500083830540543

Epoch: 383| Step: 0
Training loss: 2.129928035684498
Validation loss: 2.5101158857538355

Epoch: 5| Step: 1
Training loss: 2.7374020632987666
Validation loss: 2.4935151951257195

Epoch: 5| Step: 2
Training loss: 2.000770182133947
Validation loss: 2.510115642359639

Epoch: 5| Step: 3
Training loss: 2.1007969252404797
Validation loss: 2.5074010176691734

Epoch: 5| Step: 4
Training loss: 2.271975332193379
Validation loss: 2.488863678722437

Epoch: 5| Step: 5
Training loss: 1.6696718619954947
Validation loss: 2.4804386087023067

Epoch: 5| Step: 6
Training loss: 2.084862478464147
Validation loss: 2.511395164121458

Epoch: 5| Step: 7
Training loss: 2.746802985904082
Validation loss: 2.5128649701157384

Epoch: 5| Step: 8
Training loss: 2.1799084404432723
Validation loss: 2.499690370459088

Epoch: 5| Step: 9
Training loss: 2.579379429666659
Validation loss: 2.497765698986565

Epoch: 5| Step: 10
Training loss: 2.002376693948717
Validation loss: 2.517384871155138

Epoch: 5| Step: 11
Training loss: 1.5458658953559201
Validation loss: 2.547803545697134

Epoch: 384| Step: 0
Training loss: 2.657404929009893
Validation loss: 2.5743990011594384

Epoch: 5| Step: 1
Training loss: 1.8012423307743974
Validation loss: 2.587300850703231

Epoch: 5| Step: 2
Training loss: 1.888124246505592
Validation loss: 2.5519623331981816

Epoch: 5| Step: 3
Training loss: 2.3948540275543846
Validation loss: 2.5670967276389423

Epoch: 5| Step: 4
Training loss: 1.5584410781467408
Validation loss: 2.583676224430241

Epoch: 5| Step: 5
Training loss: 1.7078805726664066
Validation loss: 2.5822090206998363

Epoch: 5| Step: 6
Training loss: 2.657200093612428
Validation loss: 2.5788496058808255

Epoch: 5| Step: 7
Training loss: 2.4840010835457864
Validation loss: 2.5871842347540817

Epoch: 5| Step: 8
Training loss: 2.1573534367398364
Validation loss: 2.5712705563947638

Epoch: 5| Step: 9
Training loss: 2.1267004502262834
Validation loss: 2.5858232601628095

Epoch: 5| Step: 10
Training loss: 2.139652894649625
Validation loss: 2.606561392577431

Epoch: 5| Step: 11
Training loss: 2.0328362946580096
Validation loss: 2.6057007823076486

Epoch: 385| Step: 0
Training loss: 2.324494879211706
Validation loss: 2.562586779016683

Epoch: 5| Step: 1
Training loss: 2.113440995868486
Validation loss: 2.577805994507856

Epoch: 5| Step: 2
Training loss: 1.3767252415595024
Validation loss: 2.5698565858501943

Epoch: 5| Step: 3
Training loss: 1.5425374261158196
Validation loss: 2.545495742187356

Epoch: 5| Step: 4
Training loss: 1.8509259638764137
Validation loss: 2.540328624685272

Epoch: 5| Step: 5
Training loss: 2.1749786595141667
Validation loss: 2.5578209872406945

Epoch: 5| Step: 6
Training loss: 2.8584186226119375
Validation loss: 2.545268478465612

Epoch: 5| Step: 7
Training loss: 2.178662021281046
Validation loss: 2.5640151925132804

Epoch: 5| Step: 8
Training loss: 2.4462778544216794
Validation loss: 2.5485551670897393

Epoch: 5| Step: 9
Training loss: 2.8600691489550036
Validation loss: 2.547379693340449

Epoch: 5| Step: 10
Training loss: 1.7903624896412946
Validation loss: 2.5669133436783387

Epoch: 5| Step: 11
Training loss: 2.28223450201871
Validation loss: 2.558690064925158

Epoch: 386| Step: 0
Training loss: 1.5688032042459448
Validation loss: 2.5569792489975307

Epoch: 5| Step: 1
Training loss: 2.037371405539527
Validation loss: 2.546740290427835

Epoch: 5| Step: 2
Training loss: 1.824398252489942
Validation loss: 2.533334058575359

Epoch: 5| Step: 3
Training loss: 2.5108434121830316
Validation loss: 2.5414432651542036

Epoch: 5| Step: 4
Training loss: 2.038391938426247
Validation loss: 2.5236589828624987

Epoch: 5| Step: 5
Training loss: 2.0016612068036164
Validation loss: 2.513265557635892

Epoch: 5| Step: 6
Training loss: 2.2937584318167143
Validation loss: 2.5470536448227783

Epoch: 5| Step: 7
Training loss: 2.786256805452684
Validation loss: 2.527891808133949

Epoch: 5| Step: 8
Training loss: 2.1788844881991882
Validation loss: 2.550779555876609

Epoch: 5| Step: 9
Training loss: 1.6384953800493656
Validation loss: 2.559637366460454

Epoch: 5| Step: 10
Training loss: 2.395456555358928
Validation loss: 2.5714619046370615

Epoch: 5| Step: 11
Training loss: 4.001653806217431
Validation loss: 2.5784336791539766

Epoch: 387| Step: 0
Training loss: 2.36849919101024
Validation loss: 2.599303502928394

Epoch: 5| Step: 1
Training loss: 1.947085021127298
Validation loss: 2.63152538347526

Epoch: 5| Step: 2
Training loss: 1.74633801008427
Validation loss: 2.628323090232365

Epoch: 5| Step: 3
Training loss: 2.1559354027393565
Validation loss: 2.673385984815137

Epoch: 5| Step: 4
Training loss: 2.6224141781622086
Validation loss: 2.610732808394356

Epoch: 5| Step: 5
Training loss: 2.0616625617358273
Validation loss: 2.554257394590835

Epoch: 5| Step: 6
Training loss: 2.894738317334105
Validation loss: 2.5337427016098077

Epoch: 5| Step: 7
Training loss: 2.897875132332788
Validation loss: 2.534997120992918

Epoch: 5| Step: 8
Training loss: 1.9506202811612172
Validation loss: 2.542658547165757

Epoch: 5| Step: 9
Training loss: 2.1051351251068176
Validation loss: 2.5379406568322036

Epoch: 5| Step: 10
Training loss: 1.4187461886585817
Validation loss: 2.5209917768753844

Epoch: 5| Step: 11
Training loss: 2.6209854126327454
Validation loss: 2.548193284212103

Epoch: 388| Step: 0
Training loss: 1.8497386593131389
Validation loss: 2.532340525181031

Epoch: 5| Step: 1
Training loss: 2.4431598194575534
Validation loss: 2.5304767424396464

Epoch: 5| Step: 2
Training loss: 1.8281305427141201
Validation loss: 2.56178398518489

Epoch: 5| Step: 3
Training loss: 1.7826044387503612
Validation loss: 2.5559995200530325

Epoch: 5| Step: 4
Training loss: 2.558564210677526
Validation loss: 2.5506957479403725

Epoch: 5| Step: 5
Training loss: 2.6396294697917297
Validation loss: 2.543818033637954

Epoch: 5| Step: 6
Training loss: 1.7482067184251064
Validation loss: 2.5537944986689776

Epoch: 5| Step: 7
Training loss: 1.9397124302477147
Validation loss: 2.5812047115413965

Epoch: 5| Step: 8
Training loss: 1.8150553612370806
Validation loss: 2.607250753780998

Epoch: 5| Step: 9
Training loss: 2.5170549392130086
Validation loss: 2.566669079053868

Epoch: 5| Step: 10
Training loss: 2.0488052003230686
Validation loss: 2.5791392903166614

Epoch: 5| Step: 11
Training loss: 3.4616728748406063
Validation loss: 2.599219992595009

Epoch: 389| Step: 0
Training loss: 1.7305022294571035
Validation loss: 2.5741447781560147

Epoch: 5| Step: 1
Training loss: 2.4546907129879814
Validation loss: 2.5605516586433614

Epoch: 5| Step: 2
Training loss: 2.371816006656839
Validation loss: 2.543212699224868

Epoch: 5| Step: 3
Training loss: 2.1091341234356977
Validation loss: 2.5570306055534555

Epoch: 5| Step: 4
Training loss: 2.3048084291962727
Validation loss: 2.532409598584428

Epoch: 5| Step: 5
Training loss: 2.1297367260981943
Validation loss: 2.5429115699164027

Epoch: 5| Step: 6
Training loss: 2.310656457077572
Validation loss: 2.543818603796475

Epoch: 5| Step: 7
Training loss: 2.3232761555353574
Validation loss: 2.5309490998308424

Epoch: 5| Step: 8
Training loss: 1.786811712104255
Validation loss: 2.531211444576801

Epoch: 5| Step: 9
Training loss: 2.1532657261717847
Validation loss: 2.543848247958306

Epoch: 5| Step: 10
Training loss: 1.9728073817609248
Validation loss: 2.526007617970037

Epoch: 5| Step: 11
Training loss: 3.218895177437451
Validation loss: 2.5366109114128323

Epoch: 390| Step: 0
Training loss: 1.7012550517616132
Validation loss: 2.579198502039573

Epoch: 5| Step: 1
Training loss: 2.309190392245551
Validation loss: 2.5694112579390556

Epoch: 5| Step: 2
Training loss: 2.662480217228855
Validation loss: 2.591186474556468

Epoch: 5| Step: 3
Training loss: 2.0774518980845214
Validation loss: 2.5878210247924955

Epoch: 5| Step: 4
Training loss: 1.713162164685102
Validation loss: 2.6038523916707543

Epoch: 5| Step: 5
Training loss: 2.1222480457237145
Validation loss: 2.5994959767574564

Epoch: 5| Step: 6
Training loss: 2.6443927677921755
Validation loss: 2.6058523952745385

Epoch: 5| Step: 7
Training loss: 2.0610054843613064
Validation loss: 2.578906220262079

Epoch: 5| Step: 8
Training loss: 2.32274605391055
Validation loss: 2.5807714462024776

Epoch: 5| Step: 9
Training loss: 2.260052371810803
Validation loss: 2.547283303700058

Epoch: 5| Step: 10
Training loss: 2.00192335153165
Validation loss: 2.544605164181005

Epoch: 5| Step: 11
Training loss: 1.9905353352280954
Validation loss: 2.547542016615947

Epoch: 391| Step: 0
Training loss: 2.415210833458676
Validation loss: 2.5445598853279003

Epoch: 5| Step: 1
Training loss: 1.9073584413810296
Validation loss: 2.533305944249726

Epoch: 5| Step: 2
Training loss: 1.7143503230839894
Validation loss: 2.547655356589399

Epoch: 5| Step: 3
Training loss: 1.8445259013375106
Validation loss: 2.5361464123905346

Epoch: 5| Step: 4
Training loss: 1.9213066191015091
Validation loss: 2.546309589743031

Epoch: 5| Step: 5
Training loss: 2.2490389148810683
Validation loss: 2.5487450441190997

Epoch: 5| Step: 6
Training loss: 1.7055958314765962
Validation loss: 2.523538951586261

Epoch: 5| Step: 7
Training loss: 2.526287630566301
Validation loss: 2.5501546357833416

Epoch: 5| Step: 8
Training loss: 2.2046303442258517
Validation loss: 2.55006786611416

Epoch: 5| Step: 9
Training loss: 2.2744479211667725
Validation loss: 2.5412964916088896

Epoch: 5| Step: 10
Training loss: 2.9211819892772066
Validation loss: 2.5388444581921745

Epoch: 5| Step: 11
Training loss: 2.4778565115838105
Validation loss: 2.543681160653782

Epoch: 392| Step: 0
Training loss: 1.617845336981663
Validation loss: 2.5565300770156747

Epoch: 5| Step: 1
Training loss: 2.5007702594528682
Validation loss: 2.553565376757597

Epoch: 5| Step: 2
Training loss: 2.3875051847870936
Validation loss: 2.5310208919433568

Epoch: 5| Step: 3
Training loss: 2.0593699199052358
Validation loss: 2.5784403521399835

Epoch: 5| Step: 4
Training loss: 2.224585796763767
Validation loss: 2.5555233302595486

Epoch: 5| Step: 5
Training loss: 2.3076616138471078
Validation loss: 2.517474945534643

Epoch: 5| Step: 6
Training loss: 1.5133492599747145
Validation loss: 2.5060211113588253

Epoch: 5| Step: 7
Training loss: 2.2083261117877084
Validation loss: 2.5244153099622664

Epoch: 5| Step: 8
Training loss: 2.022985341575718
Validation loss: 2.5111750186734776

Epoch: 5| Step: 9
Training loss: 2.5737173608060013
Validation loss: 2.5273069981414036

Epoch: 5| Step: 10
Training loss: 2.509746435663508
Validation loss: 2.524827285090629

Epoch: 5| Step: 11
Training loss: 2.1953583301905435
Validation loss: 2.5195942636737163

Epoch: 393| Step: 0
Training loss: 2.6145642243151817
Validation loss: 2.5254739942800866

Epoch: 5| Step: 1
Training loss: 2.7709273033173885
Validation loss: 2.5372338855429764

Epoch: 5| Step: 2
Training loss: 2.69990956896764
Validation loss: 2.525458460597654

Epoch: 5| Step: 3
Training loss: 2.369925649579263
Validation loss: 2.567371823517198

Epoch: 5| Step: 4
Training loss: 2.218251131953193
Validation loss: 2.5760740580195334

Epoch: 5| Step: 5
Training loss: 1.94061815933275
Validation loss: 2.587569606231767

Epoch: 5| Step: 6
Training loss: 1.4609044525162191
Validation loss: 2.5696357485433228

Epoch: 5| Step: 7
Training loss: 1.7825904620998785
Validation loss: 2.5371493717415126

Epoch: 5| Step: 8
Training loss: 2.1367879294959637
Validation loss: 2.547721129364047

Epoch: 5| Step: 9
Training loss: 1.9836632360703172
Validation loss: 2.543388425824869

Epoch: 5| Step: 10
Training loss: 1.921971140371938
Validation loss: 2.559705185153618

Epoch: 5| Step: 11
Training loss: 2.105215761629942
Validation loss: 2.5245690225033046

Epoch: 394| Step: 0
Training loss: 1.7021051555652509
Validation loss: 2.5343729659643452

Epoch: 5| Step: 1
Training loss: 2.2471340788771212
Validation loss: 2.545458561636855

Epoch: 5| Step: 2
Training loss: 1.957689186103503
Validation loss: 2.5337503293681296

Epoch: 5| Step: 3
Training loss: 2.4927799871858247
Validation loss: 2.542004794679267

Epoch: 5| Step: 4
Training loss: 2.3600166913428278
Validation loss: 2.5409824448339013

Epoch: 5| Step: 5
Training loss: 1.44902378631929
Validation loss: 2.5526902288128364

Epoch: 5| Step: 6
Training loss: 2.303975451113465
Validation loss: 2.5417121247359034

Epoch: 5| Step: 7
Training loss: 1.9957703927560921
Validation loss: 2.5475460759788784

Epoch: 5| Step: 8
Training loss: 1.5586884357497461
Validation loss: 2.5690956520497044

Epoch: 5| Step: 9
Training loss: 2.6480194932214363
Validation loss: 2.5747824376363697

Epoch: 5| Step: 10
Training loss: 2.5236152137560177
Validation loss: 2.5947035143709996

Epoch: 5| Step: 11
Training loss: 2.9491126843510065
Validation loss: 2.5963150003604434

Epoch: 395| Step: 0
Training loss: 2.5927882422187967
Validation loss: 2.611334858488362

Epoch: 5| Step: 1
Training loss: 2.049806315878939
Validation loss: 2.6532651642558003

Epoch: 5| Step: 2
Training loss: 1.902283277862482
Validation loss: 2.6028337742386456

Epoch: 5| Step: 3
Training loss: 1.6508333413696803
Validation loss: 2.608149688144349

Epoch: 5| Step: 4
Training loss: 2.6776748082987605
Validation loss: 2.5723077359779847

Epoch: 5| Step: 5
Training loss: 2.4519091466217406
Validation loss: 2.549288809153901

Epoch: 5| Step: 6
Training loss: 2.333947396085197
Validation loss: 2.5347214312675552

Epoch: 5| Step: 7
Training loss: 1.7821140535977258
Validation loss: 2.5221671340568204

Epoch: 5| Step: 8
Training loss: 2.020480318467783
Validation loss: 2.531397422767445

Epoch: 5| Step: 9
Training loss: 1.9149425741006625
Validation loss: 2.522340394321325

Epoch: 5| Step: 10
Training loss: 2.7386766004106735
Validation loss: 2.5290174450182774

Epoch: 5| Step: 11
Training loss: 4.088623564400027
Validation loss: 2.5331820818228756

Epoch: 396| Step: 0
Training loss: 1.6073822721142832
Validation loss: 2.5360846051577375

Epoch: 5| Step: 1
Training loss: 2.0692119624259804
Validation loss: 2.5354959429809565

Epoch: 5| Step: 2
Training loss: 1.7142812027758316
Validation loss: 2.5306990852041475

Epoch: 5| Step: 3
Training loss: 1.8472048831148231
Validation loss: 2.554390926042313

Epoch: 5| Step: 4
Training loss: 2.1452702150671596
Validation loss: 2.5563560931722575

Epoch: 5| Step: 5
Training loss: 2.2708830755076215
Validation loss: 2.5742784743068983

Epoch: 5| Step: 6
Training loss: 2.507965178313352
Validation loss: 2.57787767630399

Epoch: 5| Step: 7
Training loss: 2.4689692146418354
Validation loss: 2.59152810553265

Epoch: 5| Step: 8
Training loss: 2.0254742008280964
Validation loss: 2.5669309523888284

Epoch: 5| Step: 9
Training loss: 2.4812708241239863
Validation loss: 2.601013381482375

Epoch: 5| Step: 10
Training loss: 2.1486112767078174
Validation loss: 2.629340617253768

Epoch: 5| Step: 11
Training loss: 3.3208807245859147
Validation loss: 2.6235992122791165

Epoch: 397| Step: 0
Training loss: 2.426087585861995
Validation loss: 2.613127859315218

Epoch: 5| Step: 1
Training loss: 2.690107189864866
Validation loss: 2.5781100147466858

Epoch: 5| Step: 2
Training loss: 1.4911556171181097
Validation loss: 2.5673355092377292

Epoch: 5| Step: 3
Training loss: 2.1246374606369542
Validation loss: 2.544061284463443

Epoch: 5| Step: 4
Training loss: 2.3110695616133503
Validation loss: 2.509408967519421

Epoch: 5| Step: 5
Training loss: 2.4540736799861036
Validation loss: 2.517077778769733

Epoch: 5| Step: 6
Training loss: 2.436269400584451
Validation loss: 2.50489504726265

Epoch: 5| Step: 7
Training loss: 2.705501415860721
Validation loss: 2.499410778386403

Epoch: 5| Step: 8
Training loss: 1.7863165425638947
Validation loss: 2.522680631653442

Epoch: 5| Step: 9
Training loss: 1.7969804815761832
Validation loss: 2.5202373766990864

Epoch: 5| Step: 10
Training loss: 1.857106467823213
Validation loss: 2.515549865927494

Epoch: 5| Step: 11
Training loss: 1.3621745604574138
Validation loss: 2.518116816657858

Epoch: 398| Step: 0
Training loss: 2.036002717104375
Validation loss: 2.5495873481208506

Epoch: 5| Step: 1
Training loss: 2.0463058029703234
Validation loss: 2.534660388825214

Epoch: 5| Step: 2
Training loss: 1.6996791873482435
Validation loss: 2.528857525110689

Epoch: 5| Step: 3
Training loss: 2.2074154679734153
Validation loss: 2.532998713292848

Epoch: 5| Step: 4
Training loss: 2.206462091296188
Validation loss: 2.5348673823928287

Epoch: 5| Step: 5
Training loss: 1.780758036888674
Validation loss: 2.544950920792142

Epoch: 5| Step: 6
Training loss: 2.6154537094707444
Validation loss: 2.532166656479913

Epoch: 5| Step: 7
Training loss: 2.1061431993523088
Validation loss: 2.5563659481560888

Epoch: 5| Step: 8
Training loss: 2.0962798364070707
Validation loss: 2.5839964620548272

Epoch: 5| Step: 9
Training loss: 2.429190532726305
Validation loss: 2.5690965839416187

Epoch: 5| Step: 10
Training loss: 2.1047930650638134
Validation loss: 2.5617645417797754

Epoch: 5| Step: 11
Training loss: 2.945130036467263
Validation loss: 2.5703025071743135

Epoch: 399| Step: 0
Training loss: 1.6514348986801923
Validation loss: 2.5620737070124147

Epoch: 5| Step: 1
Training loss: 2.452656889552857
Validation loss: 2.551695118136497

Epoch: 5| Step: 2
Training loss: 2.6424289838907695
Validation loss: 2.582909092882546

Epoch: 5| Step: 3
Training loss: 2.147136280313337
Validation loss: 2.5825398339088776

Epoch: 5| Step: 4
Training loss: 2.239164540959797
Validation loss: 2.564691796373373

Epoch: 5| Step: 5
Training loss: 1.5861112753086186
Validation loss: 2.5512891052566

Epoch: 5| Step: 6
Training loss: 1.613773446359661
Validation loss: 2.578154918227333

Epoch: 5| Step: 7
Training loss: 2.546968610482509
Validation loss: 2.5599633741863173

Epoch: 5| Step: 8
Training loss: 2.5544461477520204
Validation loss: 2.547367407193583

Epoch: 5| Step: 9
Training loss: 2.064523917638215
Validation loss: 2.5779910004596562

Epoch: 5| Step: 10
Training loss: 1.655225112794779
Validation loss: 2.5699129112865458

Epoch: 5| Step: 11
Training loss: 2.6299192565591265
Validation loss: 2.605129183594284

Epoch: 400| Step: 0
Training loss: 1.7957161525131773
Validation loss: 2.613378981970906

Epoch: 5| Step: 1
Training loss: 2.8631548469818062
Validation loss: 2.601897686815039

Epoch: 5| Step: 2
Training loss: 2.487242285638752
Validation loss: 2.605593665472833

Epoch: 5| Step: 3
Training loss: 2.01241940639073
Validation loss: 2.6011140072109513

Epoch: 5| Step: 4
Training loss: 2.2685635156414534
Validation loss: 2.605262481287396

Epoch: 5| Step: 5
Training loss: 2.1901363290306817
Validation loss: 2.613645245985536

Epoch: 5| Step: 6
Training loss: 1.649938541770533
Validation loss: 2.580393094077764

Epoch: 5| Step: 7
Training loss: 1.707809934064468
Validation loss: 2.5869114320040087

Epoch: 5| Step: 8
Training loss: 2.267718275472154
Validation loss: 2.589449273739238

Epoch: 5| Step: 9
Training loss: 2.2204716409969483
Validation loss: 2.573650449810246

Epoch: 5| Step: 10
Training loss: 2.1341528401292487
Validation loss: 2.5585308542844447

Epoch: 5| Step: 11
Training loss: 1.2417048830299926
Validation loss: 2.5590292872943907

Epoch: 401| Step: 0
Training loss: 2.448583785253378
Validation loss: 2.5519901018564854

Epoch: 5| Step: 1
Training loss: 1.9867357044044065
Validation loss: 2.566205303777171

Epoch: 5| Step: 2
Training loss: 1.7945817992581212
Validation loss: 2.571656784805856

Epoch: 5| Step: 3
Training loss: 2.116989408002546
Validation loss: 2.582341024079185

Epoch: 5| Step: 4
Training loss: 2.4584605512729967
Validation loss: 2.5984506066519937

Epoch: 5| Step: 5
Training loss: 1.8148878744921846
Validation loss: 2.592203452850853

Epoch: 5| Step: 6
Training loss: 2.5769016021902362
Validation loss: 2.604736053526851

Epoch: 5| Step: 7
Training loss: 2.421898429511166
Validation loss: 2.6266199820100566

Epoch: 5| Step: 8
Training loss: 2.1688858429417475
Validation loss: 2.607350635865043

Epoch: 5| Step: 9
Training loss: 1.8269804933923306
Validation loss: 2.5913183771445554

Epoch: 5| Step: 10
Training loss: 2.147015354060727
Validation loss: 2.5756632949005125

Epoch: 5| Step: 11
Training loss: 2.4054932828756685
Validation loss: 2.5452110846391856

Epoch: 402| Step: 0
Training loss: 1.5292293684713434
Validation loss: 2.5312282459281836

Epoch: 5| Step: 1
Training loss: 2.1979656003111985
Validation loss: 2.543506799783273

Epoch: 5| Step: 2
Training loss: 2.187796981270452
Validation loss: 2.5292131604022328

Epoch: 5| Step: 3
Training loss: 2.545673297486663
Validation loss: 2.553992438376596

Epoch: 5| Step: 4
Training loss: 2.408163028578151
Validation loss: 2.53978607431411

Epoch: 5| Step: 5
Training loss: 1.9557251978874997
Validation loss: 2.5296956969126994

Epoch: 5| Step: 6
Training loss: 1.687242912206375
Validation loss: 2.5354261484859544

Epoch: 5| Step: 7
Training loss: 2.733598958653985
Validation loss: 2.5483578166436294

Epoch: 5| Step: 8
Training loss: 1.8948435103286614
Validation loss: 2.562194790535691

Epoch: 5| Step: 9
Training loss: 2.012221071804782
Validation loss: 2.584225574864736

Epoch: 5| Step: 10
Training loss: 2.3049958620841067
Validation loss: 2.565885499699793

Epoch: 5| Step: 11
Training loss: 2.199960261766296
Validation loss: 2.5850255919910694

Epoch: 403| Step: 0
Training loss: 1.9822230648077945
Validation loss: 2.5925932798277485

Epoch: 5| Step: 1
Training loss: 1.918314294706779
Validation loss: 2.602293520873757

Epoch: 5| Step: 2
Training loss: 1.4841840119216676
Validation loss: 2.606253914102105

Epoch: 5| Step: 3
Training loss: 1.6025110180694726
Validation loss: 2.5876797188282215

Epoch: 5| Step: 4
Training loss: 2.0052062459827473
Validation loss: 2.6020015846240776

Epoch: 5| Step: 5
Training loss: 2.6464089696072532
Validation loss: 2.5895208173731303

Epoch: 5| Step: 6
Training loss: 2.697932200344147
Validation loss: 2.5611209686516663

Epoch: 5| Step: 7
Training loss: 1.9690645360217203
Validation loss: 2.569746590940464

Epoch: 5| Step: 8
Training loss: 2.1126423714419382
Validation loss: 2.511898242001002

Epoch: 5| Step: 9
Training loss: 1.932081459586912
Validation loss: 2.553450593144091

Epoch: 5| Step: 10
Training loss: 2.8437563717948877
Validation loss: 2.566023621469497

Epoch: 5| Step: 11
Training loss: 2.0239569391261187
Validation loss: 2.5740794026888616

Epoch: 404| Step: 0
Training loss: 2.037109375
Validation loss: 2.5617102747423406

Epoch: 5| Step: 1
Training loss: 2.396647826250254
Validation loss: 2.5659787321775247

Epoch: 5| Step: 2
Training loss: 1.6150791596419631
Validation loss: 2.573777337981266

Epoch: 5| Step: 3
Training loss: 2.57780362062362
Validation loss: 2.555849246685644

Epoch: 5| Step: 4
Training loss: 2.331518273347618
Validation loss: 2.5673247870437805

Epoch: 5| Step: 5
Training loss: 2.4592641803053032
Validation loss: 2.5623123480155536

Epoch: 5| Step: 6
Training loss: 1.7594503274785855
Validation loss: 2.5464959067235555

Epoch: 5| Step: 7
Training loss: 2.1492091787077294
Validation loss: 2.57059675073007

Epoch: 5| Step: 8
Training loss: 2.2380228209640225
Validation loss: 2.580660415231482

Epoch: 5| Step: 9
Training loss: 2.2510541989390838
Validation loss: 2.596613865563633

Epoch: 5| Step: 10
Training loss: 1.798136260176729
Validation loss: 2.582967256685545

Epoch: 5| Step: 11
Training loss: 1.2116053554619315
Validation loss: 2.5890132057532886

Epoch: 405| Step: 0
Training loss: 1.7027586096631497
Validation loss: 2.5971786174638343

Epoch: 5| Step: 1
Training loss: 2.1223677994138455
Validation loss: 2.5769092043551782

Epoch: 5| Step: 2
Training loss: 2.0972049732074347
Validation loss: 2.5976051000468563

Epoch: 5| Step: 3
Training loss: 2.300790576235873
Validation loss: 2.6134874103844514

Epoch: 5| Step: 4
Training loss: 2.3415196296802594
Validation loss: 2.5939699370807103

Epoch: 5| Step: 5
Training loss: 2.2102964300830537
Validation loss: 2.56858554322926

Epoch: 5| Step: 6
Training loss: 1.9343391600017144
Validation loss: 2.561656642547565

Epoch: 5| Step: 7
Training loss: 2.4433338093811376
Validation loss: 2.5491875756777866

Epoch: 5| Step: 8
Training loss: 2.901184589876372
Validation loss: 2.52268296289935

Epoch: 5| Step: 9
Training loss: 2.0430745959898413
Validation loss: 2.5303963371610547

Epoch: 5| Step: 10
Training loss: 2.0469328893963836
Validation loss: 2.5394015648225614

Epoch: 5| Step: 11
Training loss: 0.9485205449004284
Validation loss: 2.509484764444299

Epoch: 406| Step: 0
Training loss: 2.5312180693696402
Validation loss: 2.544840446646936

Epoch: 5| Step: 1
Training loss: 1.8710882708443393
Validation loss: 2.5364607015255336

Epoch: 5| Step: 2
Training loss: 1.728639139191379
Validation loss: 2.5654788806982523

Epoch: 5| Step: 3
Training loss: 2.525180840389924
Validation loss: 2.574244513066776

Epoch: 5| Step: 4
Training loss: 2.175792646121412
Validation loss: 2.6117208067178117

Epoch: 5| Step: 5
Training loss: 2.4302844329268862
Validation loss: 2.610220678806047

Epoch: 5| Step: 6
Training loss: 2.2312542656181873
Validation loss: 2.5917635093597644

Epoch: 5| Step: 7
Training loss: 1.786726046448468
Validation loss: 2.6243317336237437

Epoch: 5| Step: 8
Training loss: 2.1397988611689103
Validation loss: 2.5878356044846376

Epoch: 5| Step: 9
Training loss: 1.7038294184108445
Validation loss: 2.5940017195048597

Epoch: 5| Step: 10
Training loss: 2.096479657762941
Validation loss: 2.5686888199425235

Epoch: 5| Step: 11
Training loss: 3.133486553936942
Validation loss: 2.5509568874923554

Epoch: 407| Step: 0
Training loss: 1.73828111284234
Validation loss: 2.561848604169124

Epoch: 5| Step: 1
Training loss: 1.5803130438488566
Validation loss: 2.5712605421795653

Epoch: 5| Step: 2
Training loss: 2.369904724330661
Validation loss: 2.5531627915261232

Epoch: 5| Step: 3
Training loss: 2.085113248242312
Validation loss: 2.556424632321413

Epoch: 5| Step: 4
Training loss: 2.4935980843757855
Validation loss: 2.564572027684033

Epoch: 5| Step: 5
Training loss: 2.3619309279882947
Validation loss: 2.5435830510596342

Epoch: 5| Step: 6
Training loss: 1.8978722755218107
Validation loss: 2.5455703787372292

Epoch: 5| Step: 7
Training loss: 1.945170692269501
Validation loss: 2.559787768660093

Epoch: 5| Step: 8
Training loss: 1.717544549089394
Validation loss: 2.5721892179216836

Epoch: 5| Step: 9
Training loss: 2.9351573287153663
Validation loss: 2.5506133121122048

Epoch: 5| Step: 10
Training loss: 2.168149868384592
Validation loss: 2.565571227693066

Epoch: 5| Step: 11
Training loss: 1.905960436231235
Validation loss: 2.582742017063881

Epoch: 408| Step: 0
Training loss: 1.6935585195264642
Validation loss: 2.6378678669440423

Epoch: 5| Step: 1
Training loss: 2.2036798738864647
Validation loss: 2.612184728797501

Epoch: 5| Step: 2
Training loss: 2.324266141520513
Validation loss: 2.6371570062816194

Epoch: 5| Step: 3
Training loss: 1.8100055103323502
Validation loss: 2.5988830346543548

Epoch: 5| Step: 4
Training loss: 2.3207312825730355
Validation loss: 2.605811093252454

Epoch: 5| Step: 5
Training loss: 2.0737106361815054
Validation loss: 2.5663794056936626

Epoch: 5| Step: 6
Training loss: 1.9159968352879009
Validation loss: 2.533524547019576

Epoch: 5| Step: 7
Training loss: 2.3737864154354655
Validation loss: 2.5294805197404564

Epoch: 5| Step: 8
Training loss: 2.318295202355315
Validation loss: 2.5222439772927565

Epoch: 5| Step: 9
Training loss: 3.0466814028538667
Validation loss: 2.519369517416364

Epoch: 5| Step: 10
Training loss: 1.4994064587262017
Validation loss: 2.5207256196919516

Epoch: 5| Step: 11
Training loss: 2.1181028294802973
Validation loss: 2.5080113515320672

Epoch: 409| Step: 0
Training loss: 1.911921646831066
Validation loss: 2.5114497490104206

Epoch: 5| Step: 1
Training loss: 1.9979895977860667
Validation loss: 2.5220002922816236

Epoch: 5| Step: 2
Training loss: 2.63211521231029
Validation loss: 2.5074719309669953

Epoch: 5| Step: 3
Training loss: 2.8171267282338732
Validation loss: 2.540812389193206

Epoch: 5| Step: 4
Training loss: 1.9729355416071428
Validation loss: 2.5785584865614375

Epoch: 5| Step: 5
Training loss: 1.9825775536356225
Validation loss: 2.5778325425545505

Epoch: 5| Step: 6
Training loss: 1.3893447297471466
Validation loss: 2.6140153250168434

Epoch: 5| Step: 7
Training loss: 2.7918333506759994
Validation loss: 2.617563351645121

Epoch: 5| Step: 8
Training loss: 2.5110022678342214
Validation loss: 2.6540694842270436

Epoch: 5| Step: 9
Training loss: 1.9170918062262319
Validation loss: 2.6049888870498883

Epoch: 5| Step: 10
Training loss: 1.8222281400008111
Validation loss: 2.5828879315945588

Epoch: 5| Step: 11
Training loss: 2.329234223816268
Validation loss: 2.536426228053091

Epoch: 410| Step: 0
Training loss: 2.3189433261448684
Validation loss: 2.543154165263676

Epoch: 5| Step: 1
Training loss: 2.13291992364113
Validation loss: 2.5369416891885455

Epoch: 5| Step: 2
Training loss: 1.9968209033975384
Validation loss: 2.528734994580735

Epoch: 5| Step: 3
Training loss: 2.0944117169418903
Validation loss: 2.5463459971101736

Epoch: 5| Step: 4
Training loss: 1.7484794550303089
Validation loss: 2.5305809895111637

Epoch: 5| Step: 5
Training loss: 2.362306403245811
Validation loss: 2.5581081793510365

Epoch: 5| Step: 6
Training loss: 2.5563095496220267
Validation loss: 2.547569453260079

Epoch: 5| Step: 7
Training loss: 2.1898233337212747
Validation loss: 2.536213983806779

Epoch: 5| Step: 8
Training loss: 2.5656319064048523
Validation loss: 2.528404504565975

Epoch: 5| Step: 9
Training loss: 1.8209613740481005
Validation loss: 2.5249661007421675

Epoch: 5| Step: 10
Training loss: 2.751750908834232
Validation loss: 2.5060766516879402

Epoch: 5| Step: 11
Training loss: 1.5651880412125754
Validation loss: 2.525532060848513

Epoch: 411| Step: 0
Training loss: 2.513554449532407
Validation loss: 2.529509872442644

Epoch: 5| Step: 1
Training loss: 1.9424509350092252
Validation loss: 2.5552836198027298

Epoch: 5| Step: 2
Training loss: 1.7864114367795871
Validation loss: 2.6066454508857904

Epoch: 5| Step: 3
Training loss: 2.1555328282188264
Validation loss: 2.64142497207519

Epoch: 5| Step: 4
Training loss: 2.5832943964659267
Validation loss: 2.6353424172377156

Epoch: 5| Step: 5
Training loss: 2.6722109399382443
Validation loss: 2.6081762282271237

Epoch: 5| Step: 6
Training loss: 2.2488839242442284
Validation loss: 2.5571831306582733

Epoch: 5| Step: 7
Training loss: 1.5687817756504685
Validation loss: 2.5187126939407207

Epoch: 5| Step: 8
Training loss: 2.4794555517121615
Validation loss: 2.520391095727994

Epoch: 5| Step: 9
Training loss: 1.6408317072395158
Validation loss: 2.5192147640203126

Epoch: 5| Step: 10
Training loss: 2.204778497171118
Validation loss: 2.5018310040606315

Epoch: 5| Step: 11
Training loss: 2.907154557755859
Validation loss: 2.494259119766354

Epoch: 412| Step: 0
Training loss: 2.441585735589852
Validation loss: 2.509055391150251

Epoch: 5| Step: 1
Training loss: 1.7863467731249048
Validation loss: 2.5066642429990242

Epoch: 5| Step: 2
Training loss: 2.1937402273976594
Validation loss: 2.5096221566167443

Epoch: 5| Step: 3
Training loss: 2.106009164505859
Validation loss: 2.5117817223675307

Epoch: 5| Step: 4
Training loss: 1.9379542648855483
Validation loss: 2.517313731979055

Epoch: 5| Step: 5
Training loss: 2.4517272076975356
Validation loss: 2.5068346832712125

Epoch: 5| Step: 6
Training loss: 2.1407069726549306
Validation loss: 2.5006431626474916

Epoch: 5| Step: 7
Training loss: 2.5298038637330644
Validation loss: 2.4864781991915863

Epoch: 5| Step: 8
Training loss: 2.903761095345196
Validation loss: 2.4744173380367642

Epoch: 5| Step: 9
Training loss: 1.732112887071264
Validation loss: 2.4992736615604434

Epoch: 5| Step: 10
Training loss: 2.131853384033054
Validation loss: 2.551435261139241

Epoch: 5| Step: 11
Training loss: 3.0718690454962796
Validation loss: 2.5537648999437224

Epoch: 413| Step: 0
Training loss: 2.5145033711190647
Validation loss: 2.560262474640059

Epoch: 5| Step: 1
Training loss: 1.9454574837334289
Validation loss: 2.6133195221383527

Epoch: 5| Step: 2
Training loss: 1.8708721499533172
Validation loss: 2.5911012207995827

Epoch: 5| Step: 3
Training loss: 2.2064169239731233
Validation loss: 2.55980418452876

Epoch: 5| Step: 4
Training loss: 1.923817838844646
Validation loss: 2.55003466738404

Epoch: 5| Step: 5
Training loss: 2.6289710026966864
Validation loss: 2.5131355628406937

Epoch: 5| Step: 6
Training loss: 2.1576734626498375
Validation loss: 2.4956581917725815

Epoch: 5| Step: 7
Training loss: 2.264443767028814
Validation loss: 2.480574898438496

Epoch: 5| Step: 8
Training loss: 2.03975434825091
Validation loss: 2.5040210731272663

Epoch: 5| Step: 9
Training loss: 2.3235252050843154
Validation loss: 2.5016991642495876

Epoch: 5| Step: 10
Training loss: 2.4762068532220503
Validation loss: 2.4846926152234188

Epoch: 5| Step: 11
Training loss: 3.4032048603982656
Validation loss: 2.4842016851402615

Epoch: 414| Step: 0
Training loss: 2.3954534699426238
Validation loss: 2.4949532591239083

Epoch: 5| Step: 1
Training loss: 2.5633802065224187
Validation loss: 2.5044962544445264

Epoch: 5| Step: 2
Training loss: 2.503586104423649
Validation loss: 2.486092307790997

Epoch: 5| Step: 3
Training loss: 1.8404543889867724
Validation loss: 2.5331510147778085

Epoch: 5| Step: 4
Training loss: 2.079263705000316
Validation loss: 2.55842392918431

Epoch: 5| Step: 5
Training loss: 1.9495651151432705
Validation loss: 2.540866570837619

Epoch: 5| Step: 6
Training loss: 2.3452030001294997
Validation loss: 2.5628910968029857

Epoch: 5| Step: 7
Training loss: 2.191782764313928
Validation loss: 2.5692515633045567

Epoch: 5| Step: 8
Training loss: 1.9832631998992123
Validation loss: 2.536287743917558

Epoch: 5| Step: 9
Training loss: 2.4145718626639097
Validation loss: 2.55373993195217

Epoch: 5| Step: 10
Training loss: 1.8233065887502848
Validation loss: 2.53827372501221

Epoch: 5| Step: 11
Training loss: 1.1247241953687528
Validation loss: 2.530900224608292

Epoch: 415| Step: 0
Training loss: 1.917154111936757
Validation loss: 2.559608190421907

Epoch: 5| Step: 1
Training loss: 2.042829052906335
Validation loss: 2.5343714411812854

Epoch: 5| Step: 2
Training loss: 2.342612639073222
Validation loss: 2.5488900207565335

Epoch: 5| Step: 3
Training loss: 2.278584634594844
Validation loss: 2.5313159125580644

Epoch: 5| Step: 4
Training loss: 2.520061111920205
Validation loss: 2.522448693419388

Epoch: 5| Step: 5
Training loss: 2.072430027975785
Validation loss: 2.5455441908260297

Epoch: 5| Step: 6
Training loss: 1.88322817697342
Validation loss: 2.5387836655319673

Epoch: 5| Step: 7
Training loss: 2.178316402919192
Validation loss: 2.567398645838991

Epoch: 5| Step: 8
Training loss: 2.256509688799712
Validation loss: 2.5459607419963803

Epoch: 5| Step: 9
Training loss: 2.0790066103846203
Validation loss: 2.5548379914018584

Epoch: 5| Step: 10
Training loss: 1.9510502896692856
Validation loss: 2.5649974484520826

Epoch: 5| Step: 11
Training loss: 1.401918054430608
Validation loss: 2.5709852943971696

Epoch: 416| Step: 0
Training loss: 2.2380513710623715
Validation loss: 2.5797195108338813

Epoch: 5| Step: 1
Training loss: 1.9276273904504457
Validation loss: 2.5720095843749093

Epoch: 5| Step: 2
Training loss: 2.169270112830169
Validation loss: 2.563192929032282

Epoch: 5| Step: 3
Training loss: 2.1671575454809036
Validation loss: 2.543033839270261

Epoch: 5| Step: 4
Training loss: 1.5008218421192525
Validation loss: 2.5663690782058484

Epoch: 5| Step: 5
Training loss: 1.955366999333194
Validation loss: 2.5639885401437432

Epoch: 5| Step: 6
Training loss: 2.1511293505761473
Validation loss: 2.5673081716176

Epoch: 5| Step: 7
Training loss: 2.2597669965761287
Validation loss: 2.562480920627556

Epoch: 5| Step: 8
Training loss: 2.6611280640725985
Validation loss: 2.557932027029234

Epoch: 5| Step: 9
Training loss: 1.8064129660192572
Validation loss: 2.556698135261474

Epoch: 5| Step: 10
Training loss: 2.3214851267706065
Validation loss: 2.55120446129764

Epoch: 5| Step: 11
Training loss: 1.706553167440913
Validation loss: 2.5664690688373946

Epoch: 417| Step: 0
Training loss: 2.548761803944388
Validation loss: 2.548915314918702

Epoch: 5| Step: 1
Training loss: 1.6268149290890712
Validation loss: 2.5654701333305834

Epoch: 5| Step: 2
Training loss: 2.6613980838254165
Validation loss: 2.5730061277417127

Epoch: 5| Step: 3
Training loss: 1.507673820482569
Validation loss: 2.548676963016611

Epoch: 5| Step: 4
Training loss: 2.1916723514768415
Validation loss: 2.5777780318625463

Epoch: 5| Step: 5
Training loss: 2.071677164842435
Validation loss: 2.5943468395332343

Epoch: 5| Step: 6
Training loss: 2.0745550482878166
Validation loss: 2.5896088966914457

Epoch: 5| Step: 7
Training loss: 1.831880152476108
Validation loss: 2.5844386041049434

Epoch: 5| Step: 8
Training loss: 2.2414167721043654
Validation loss: 2.5989314532116246

Epoch: 5| Step: 9
Training loss: 2.0914293780239674
Validation loss: 2.588275198522069

Epoch: 5| Step: 10
Training loss: 2.266963168928279
Validation loss: 2.6011906187168234

Epoch: 5| Step: 11
Training loss: 1.2291489077217275
Validation loss: 2.5714423451105213

Epoch: 418| Step: 0
Training loss: 2.4760892879243435
Validation loss: 2.578450211329619

Epoch: 5| Step: 1
Training loss: 1.823982435844581
Validation loss: 2.586576503850791

Epoch: 5| Step: 2
Training loss: 1.9405439522691768
Validation loss: 2.5743332732701676

Epoch: 5| Step: 3
Training loss: 1.9478168223966672
Validation loss: 2.543660518547038

Epoch: 5| Step: 4
Training loss: 1.5548176926583914
Validation loss: 2.5904528331722028

Epoch: 5| Step: 5
Training loss: 2.467198620820062
Validation loss: 2.5966273055400815

Epoch: 5| Step: 6
Training loss: 1.7558804893709286
Validation loss: 2.613162883364418

Epoch: 5| Step: 7
Training loss: 1.8319635765086315
Validation loss: 2.589438259473204

Epoch: 5| Step: 8
Training loss: 2.0894267298952673
Validation loss: 2.6186593694792397

Epoch: 5| Step: 9
Training loss: 2.263579504121353
Validation loss: 2.591260561807285

Epoch: 5| Step: 10
Training loss: 2.314602900942253
Validation loss: 2.5893929167261227

Epoch: 5| Step: 11
Training loss: 3.48811625296544
Validation loss: 2.5532883595343763

Epoch: 419| Step: 0
Training loss: 2.0125061272000693
Validation loss: 2.5531812460099377

Epoch: 5| Step: 1
Training loss: 1.6909713362165564
Validation loss: 2.5676637314229933

Epoch: 5| Step: 2
Training loss: 1.8465151983359214
Validation loss: 2.5518263758837603

Epoch: 5| Step: 3
Training loss: 1.9554082113565883
Validation loss: 2.5453295318989104

Epoch: 5| Step: 4
Training loss: 2.5044441776036677
Validation loss: 2.548982275032083

Epoch: 5| Step: 5
Training loss: 2.128970979878895
Validation loss: 2.5712476225480194

Epoch: 5| Step: 6
Training loss: 2.572313822393937
Validation loss: 2.5294042812406095

Epoch: 5| Step: 7
Training loss: 1.9660604967877817
Validation loss: 2.530264485975337

Epoch: 5| Step: 8
Training loss: 2.4642412564707974
Validation loss: 2.5227222314678

Epoch: 5| Step: 9
Training loss: 1.673121620377158
Validation loss: 2.5805359289125347

Epoch: 5| Step: 10
Training loss: 2.194289434031047
Validation loss: 2.611189742262732

Epoch: 5| Step: 11
Training loss: 1.7956310444460244
Validation loss: 2.6192906711505013

Epoch: 420| Step: 0
Training loss: 2.183236790723557
Validation loss: 2.6434498975070504

Epoch: 5| Step: 1
Training loss: 2.3118144900861455
Validation loss: 2.6263622352067553

Epoch: 5| Step: 2
Training loss: 2.3688123307293325
Validation loss: 2.6199459020414273

Epoch: 5| Step: 3
Training loss: 1.9454893468419552
Validation loss: 2.608327000328964

Epoch: 5| Step: 4
Training loss: 2.3729809661629155
Validation loss: 2.589449177829774

Epoch: 5| Step: 5
Training loss: 2.3162121233079436
Validation loss: 2.5635714965680307

Epoch: 5| Step: 6
Training loss: 1.4444714547753752
Validation loss: 2.5548264040888973

Epoch: 5| Step: 7
Training loss: 2.1398834280546315
Validation loss: 2.5496389061692457

Epoch: 5| Step: 8
Training loss: 2.3822505100588773
Validation loss: 2.530884261062169

Epoch: 5| Step: 9
Training loss: 1.9137655222417123
Validation loss: 2.534773634617073

Epoch: 5| Step: 10
Training loss: 1.7417816921136178
Validation loss: 2.552967386816397

Epoch: 5| Step: 11
Training loss: 0.9500789433856831
Validation loss: 2.551092225260818

Epoch: 421| Step: 0
Training loss: 2.049377309618152
Validation loss: 2.53829687068129

Epoch: 5| Step: 1
Training loss: 1.7187097024528435
Validation loss: 2.5336536603884947

Epoch: 5| Step: 2
Training loss: 2.5691091393154855
Validation loss: 2.5164878897504073

Epoch: 5| Step: 3
Training loss: 2.1589327722342015
Validation loss: 2.5445367224508253

Epoch: 5| Step: 4
Training loss: 2.323788694456614
Validation loss: 2.552559754932869

Epoch: 5| Step: 5
Training loss: 2.194554642701673
Validation loss: 2.5309492843082912

Epoch: 5| Step: 6
Training loss: 2.2308571605908507
Validation loss: 2.5691109682884496

Epoch: 5| Step: 7
Training loss: 2.337909185324717
Validation loss: 2.5631107284841876

Epoch: 5| Step: 8
Training loss: 2.2878300079605363
Validation loss: 2.5540385146193145

Epoch: 5| Step: 9
Training loss: 1.6636845692322475
Validation loss: 2.5520873569275153

Epoch: 5| Step: 10
Training loss: 1.7519493145513187
Validation loss: 2.5312108519552696

Epoch: 5| Step: 11
Training loss: 2.3696956629048462
Validation loss: 2.5534746555502017

Epoch: 422| Step: 0
Training loss: 2.497580883713462
Validation loss: 2.5366888914082923

Epoch: 5| Step: 1
Training loss: 1.684043877208961
Validation loss: 2.53784895237337

Epoch: 5| Step: 2
Training loss: 2.805595909642571
Validation loss: 2.535792246991418

Epoch: 5| Step: 3
Training loss: 2.207944751836115
Validation loss: 2.5441277397677178

Epoch: 5| Step: 4
Training loss: 1.8684686710547584
Validation loss: 2.544952532919531

Epoch: 5| Step: 5
Training loss: 1.9592143234737147
Validation loss: 2.529815459632859

Epoch: 5| Step: 6
Training loss: 1.997614033371928
Validation loss: 2.498137630735802

Epoch: 5| Step: 7
Training loss: 2.2174957383726643
Validation loss: 2.5354925519379607

Epoch: 5| Step: 8
Training loss: 2.0779716033537325
Validation loss: 2.5275759975944885

Epoch: 5| Step: 9
Training loss: 2.1546249900641268
Validation loss: 2.497659708401908

Epoch: 5| Step: 10
Training loss: 2.316761317709458
Validation loss: 2.510589135974018

Epoch: 5| Step: 11
Training loss: 3.072206490560504
Validation loss: 2.5404217607850548

Epoch: 423| Step: 0
Training loss: 1.7796848179878209
Validation loss: 2.557023119114669

Epoch: 5| Step: 1
Training loss: 2.1121659641152823
Validation loss: 2.57004113586199

Epoch: 5| Step: 2
Training loss: 2.1940350600008514
Validation loss: 2.611564570364459

Epoch: 5| Step: 3
Training loss: 1.821955581898274
Validation loss: 2.6059586590061414

Epoch: 5| Step: 4
Training loss: 3.147364734170074
Validation loss: 2.5511409005526837

Epoch: 5| Step: 5
Training loss: 1.430201703764944
Validation loss: 2.5552467371815872

Epoch: 5| Step: 6
Training loss: 2.1765946078482465
Validation loss: 2.521289907570501

Epoch: 5| Step: 7
Training loss: 2.1704954527495546
Validation loss: 2.5071745127329224

Epoch: 5| Step: 8
Training loss: 2.324108063442374
Validation loss: 2.4894907141393103

Epoch: 5| Step: 9
Training loss: 1.8745861232465761
Validation loss: 2.486803619154152

Epoch: 5| Step: 10
Training loss: 2.0400224669472182
Validation loss: 2.4982423444898036

Epoch: 5| Step: 11
Training loss: 2.890367156204979
Validation loss: 2.487793935089872

Epoch: 424| Step: 0
Training loss: 2.3196452301996606
Validation loss: 2.4892571819549554

Epoch: 5| Step: 1
Training loss: 2.22677750469595
Validation loss: 2.5092116520068215

Epoch: 5| Step: 2
Training loss: 2.2068841125593996
Validation loss: 2.4912861675974534

Epoch: 5| Step: 3
Training loss: 1.7016299624069804
Validation loss: 2.501657643713829

Epoch: 5| Step: 4
Training loss: 2.278227384383221
Validation loss: 2.501406913492105

Epoch: 5| Step: 5
Training loss: 1.9688027995462056
Validation loss: 2.5114459635681636

Epoch: 5| Step: 6
Training loss: 2.3607110289152793
Validation loss: 2.5090187237885884

Epoch: 5| Step: 7
Training loss: 1.8764288226563142
Validation loss: 2.532580655810371

Epoch: 5| Step: 8
Training loss: 2.4630240178116196
Validation loss: 2.5584676696929383

Epoch: 5| Step: 9
Training loss: 1.3074114112674624
Validation loss: 2.552536481732964

Epoch: 5| Step: 10
Training loss: 2.3038511666135237
Validation loss: 2.6166026054931315

Epoch: 5| Step: 11
Training loss: 2.087194856738373
Validation loss: 2.6008978807129157

Epoch: 425| Step: 0
Training loss: 1.8765630564819833
Validation loss: 2.5739010936609996

Epoch: 5| Step: 1
Training loss: 1.9194527224546072
Validation loss: 2.5307426768401116

Epoch: 5| Step: 2
Training loss: 1.732027131429756
Validation loss: 2.5519493937215714

Epoch: 5| Step: 3
Training loss: 1.712619877538558
Validation loss: 2.529433784068846

Epoch: 5| Step: 4
Training loss: 2.2906374151666236
Validation loss: 2.5429152655458305

Epoch: 5| Step: 5
Training loss: 2.7310205428678866
Validation loss: 2.540036938822972

Epoch: 5| Step: 6
Training loss: 1.7681977424207622
Validation loss: 2.53706660147759

Epoch: 5| Step: 7
Training loss: 2.7730693734010377
Validation loss: 2.5480327432121554

Epoch: 5| Step: 8
Training loss: 1.7538872188903465
Validation loss: 2.53300968667879

Epoch: 5| Step: 9
Training loss: 2.4309185871095194
Validation loss: 2.5401346339503355

Epoch: 5| Step: 10
Training loss: 1.7756634828827673
Validation loss: 2.5454458818014722

Epoch: 5| Step: 11
Training loss: 1.1654509386286245
Validation loss: 2.5553317448551955

Epoch: 426| Step: 0
Training loss: 1.8120620461508326
Validation loss: 2.5581033134706215

Epoch: 5| Step: 1
Training loss: 2.271251558293851
Validation loss: 2.577023858628154

Epoch: 5| Step: 2
Training loss: 2.2316428599988263
Validation loss: 2.6265728529908188

Epoch: 5| Step: 3
Training loss: 1.879684509122757
Validation loss: 2.55156524939933

Epoch: 5| Step: 4
Training loss: 2.4192121079088906
Validation loss: 2.5499736058358913

Epoch: 5| Step: 5
Training loss: 1.6280936357109366
Validation loss: 2.5631459398956076

Epoch: 5| Step: 6
Training loss: 1.730628494914925
Validation loss: 2.5408491939741102

Epoch: 5| Step: 7
Training loss: 2.1755110129391286
Validation loss: 2.5432771104153695

Epoch: 5| Step: 8
Training loss: 2.282165343704496
Validation loss: 2.5460430768005478

Epoch: 5| Step: 9
Training loss: 2.577929957554772
Validation loss: 2.5368028024326157

Epoch: 5| Step: 10
Training loss: 2.4319302428556053
Validation loss: 2.559779498592762

Epoch: 5| Step: 11
Training loss: 2.7915627094859308
Validation loss: 2.5535947385455104

Epoch: 427| Step: 0
Training loss: 2.3322927561580356
Validation loss: 2.5676460658345617

Epoch: 5| Step: 1
Training loss: 1.979291878470541
Validation loss: 2.571988163463514

Epoch: 5| Step: 2
Training loss: 1.6699275858820477
Validation loss: 2.571322732452152

Epoch: 5| Step: 3
Training loss: 2.1886775525802564
Validation loss: 2.585966676699181

Epoch: 5| Step: 4
Training loss: 2.375388966882695
Validation loss: 2.613320362233633

Epoch: 5| Step: 5
Training loss: 1.9982677348836666
Validation loss: 2.597335742117387

Epoch: 5| Step: 6
Training loss: 1.4100607630981608
Validation loss: 2.6008283860455848

Epoch: 5| Step: 7
Training loss: 2.6673794230958916
Validation loss: 2.596847423555474

Epoch: 5| Step: 8
Training loss: 1.9080724915502725
Validation loss: 2.5697572063851326

Epoch: 5| Step: 9
Training loss: 1.8031998484925391
Validation loss: 2.601861518423582

Epoch: 5| Step: 10
Training loss: 2.1758904968996697
Validation loss: 2.5681627901796356

Epoch: 5| Step: 11
Training loss: 3.133667180017238
Validation loss: 2.560840359998953

Epoch: 428| Step: 0
Training loss: 1.8467582472093806
Validation loss: 2.5445073713119757

Epoch: 5| Step: 1
Training loss: 2.8549934544797244
Validation loss: 2.5550878057552584

Epoch: 5| Step: 2
Training loss: 2.10386083917236
Validation loss: 2.584327888289994

Epoch: 5| Step: 3
Training loss: 2.369245182507029
Validation loss: 2.5627128233571916

Epoch: 5| Step: 4
Training loss: 2.1049511897936193
Validation loss: 2.5898815131179265

Epoch: 5| Step: 5
Training loss: 2.0473123330733034
Validation loss: 2.5431758349001905

Epoch: 5| Step: 6
Training loss: 1.869839496762314
Validation loss: 2.5518091923878963

Epoch: 5| Step: 7
Training loss: 1.5140370968162864
Validation loss: 2.5097709962463295

Epoch: 5| Step: 8
Training loss: 1.6132078731374064
Validation loss: 2.5031241526068477

Epoch: 5| Step: 9
Training loss: 2.783566057065841
Validation loss: 2.4971033003876726

Epoch: 5| Step: 10
Training loss: 2.1338936437472014
Validation loss: 2.4968421741312357

Epoch: 5| Step: 11
Training loss: 2.09656961096119
Validation loss: 2.4762090717600365

Epoch: 429| Step: 0
Training loss: 2.3001358862831194
Validation loss: 2.4943433822071888

Epoch: 5| Step: 1
Training loss: 2.203731805008995
Validation loss: 2.4831757760043307

Epoch: 5| Step: 2
Training loss: 2.0790412431803094
Validation loss: 2.504056314066959

Epoch: 5| Step: 3
Training loss: 1.914915120706369
Validation loss: 2.479645031102825

Epoch: 5| Step: 4
Training loss: 2.717726942480925
Validation loss: 2.5071199516533005

Epoch: 5| Step: 5
Training loss: 1.7677962194957115
Validation loss: 2.491026612962888

Epoch: 5| Step: 6
Training loss: 2.294005801206003
Validation loss: 2.461821983478675

Epoch: 5| Step: 7
Training loss: 1.9857664861512196
Validation loss: 2.4810466383545924

Epoch: 5| Step: 8
Training loss: 2.2258308145367667
Validation loss: 2.5100648535877337

Epoch: 5| Step: 9
Training loss: 2.6933300744247863
Validation loss: 2.54523477219029

Epoch: 5| Step: 10
Training loss: 2.0053005312906786
Validation loss: 2.5653248080454287

Epoch: 5| Step: 11
Training loss: 2.1168557220292987
Validation loss: 2.550702096237705

Epoch: 430| Step: 0
Training loss: 2.019155559606332
Validation loss: 2.545258998132921

Epoch: 5| Step: 1
Training loss: 1.6577852439257708
Validation loss: 2.545179344770503

Epoch: 5| Step: 2
Training loss: 2.8150490124028433
Validation loss: 2.5440222359398774

Epoch: 5| Step: 3
Training loss: 1.804781560386988
Validation loss: 2.535324792495557

Epoch: 5| Step: 4
Training loss: 1.5649392733507306
Validation loss: 2.559402481664377

Epoch: 5| Step: 5
Training loss: 1.9251265892912452
Validation loss: 2.5317273612110305

Epoch: 5| Step: 6
Training loss: 2.6013830541176532
Validation loss: 2.5337203259354397

Epoch: 5| Step: 7
Training loss: 1.8539226957251624
Validation loss: 2.538715014032725

Epoch: 5| Step: 8
Training loss: 2.097022957279131
Validation loss: 2.5570561591253216

Epoch: 5| Step: 9
Training loss: 2.2904046716411246
Validation loss: 2.543523287531108

Epoch: 5| Step: 10
Training loss: 2.4521949122562243
Validation loss: 2.5409801069196796

Epoch: 5| Step: 11
Training loss: 0.8542236603741752
Validation loss: 2.5577316617843042

Epoch: 431| Step: 0
Training loss: 2.1114431909194775
Validation loss: 2.5296975111846716

Epoch: 5| Step: 1
Training loss: 2.034710796904212
Validation loss: 2.5477948624157816

Epoch: 5| Step: 2
Training loss: 2.5531240923166703
Validation loss: 2.5151508231913278

Epoch: 5| Step: 3
Training loss: 2.274526748060533
Validation loss: 2.5254898307493345

Epoch: 5| Step: 4
Training loss: 2.4572276414456935
Validation loss: 2.540642451202529

Epoch: 5| Step: 5
Training loss: 1.6330508555513563
Validation loss: 2.4834225886314742

Epoch: 5| Step: 6
Training loss: 1.7970945141264125
Validation loss: 2.4932374725511575

Epoch: 5| Step: 7
Training loss: 1.8018866929684771
Validation loss: 2.54156137206636

Epoch: 5| Step: 8
Training loss: 2.6701285917769497
Validation loss: 2.5146250899629123

Epoch: 5| Step: 9
Training loss: 1.5387628718689197
Validation loss: 2.5090957915402976

Epoch: 5| Step: 10
Training loss: 2.126016373758791
Validation loss: 2.4954637260689783

Epoch: 5| Step: 11
Training loss: 2.7109012656305045
Validation loss: 2.4935493495275782

Epoch: 432| Step: 0
Training loss: 1.8272926196202144
Validation loss: 2.452975444729893

Epoch: 5| Step: 1
Training loss: 1.646054973245143
Validation loss: 2.4748820109773266

Epoch: 5| Step: 2
Training loss: 2.516867194702383
Validation loss: 2.463101137276843

Epoch: 5| Step: 3
Training loss: 1.7929279264568876
Validation loss: 2.488952961259703

Epoch: 5| Step: 4
Training loss: 1.987826612014945
Validation loss: 2.4492142680815148

Epoch: 5| Step: 5
Training loss: 2.201139813708386
Validation loss: 2.4475070157435974

Epoch: 5| Step: 6
Training loss: 2.066863328539133
Validation loss: 2.483297710248537

Epoch: 5| Step: 7
Training loss: 2.217796873156118
Validation loss: 2.464042073747518

Epoch: 5| Step: 8
Training loss: 2.487040978640532
Validation loss: 2.486198599718612

Epoch: 5| Step: 9
Training loss: 1.989512244214433
Validation loss: 2.4596102167834135

Epoch: 5| Step: 10
Training loss: 2.5441802577149164
Validation loss: 2.4904572550445736

Epoch: 5| Step: 11
Training loss: 2.532238802455474
Validation loss: 2.5079855378883344

Epoch: 433| Step: 0
Training loss: 2.846457565304908
Validation loss: 2.5580910691192593

Epoch: 5| Step: 1
Training loss: 2.007100494841457
Validation loss: 2.5989417086409095

Epoch: 5| Step: 2
Training loss: 2.140080292166952
Validation loss: 2.5670936395501927

Epoch: 5| Step: 3
Training loss: 2.175618410437472
Validation loss: 2.548771154319951

Epoch: 5| Step: 4
Training loss: 1.6329275574369226
Validation loss: 2.5654444234865514

Epoch: 5| Step: 5
Training loss: 1.882143083656651
Validation loss: 2.5249036381844268

Epoch: 5| Step: 6
Training loss: 1.3754856812408867
Validation loss: 2.5262289915071694

Epoch: 5| Step: 7
Training loss: 2.114018168974927
Validation loss: 2.5342942953685084

Epoch: 5| Step: 8
Training loss: 2.3422373658840194
Validation loss: 2.525453327263008

Epoch: 5| Step: 9
Training loss: 2.266255258174294
Validation loss: 2.5102180696551306

Epoch: 5| Step: 10
Training loss: 2.411664444510019
Validation loss: 2.5343394401241235

Epoch: 5| Step: 11
Training loss: 2.571209875525338
Validation loss: 2.514625621309441

Epoch: 434| Step: 0
Training loss: 2.891626957630802
Validation loss: 2.544530405620856

Epoch: 5| Step: 1
Training loss: 2.2128844837665778
Validation loss: 2.541065806881223

Epoch: 5| Step: 2
Training loss: 1.4440088939974032
Validation loss: 2.551147582624253

Epoch: 5| Step: 3
Training loss: 1.7388948536256994
Validation loss: 2.5677943856841976

Epoch: 5| Step: 4
Training loss: 1.5712251810254714
Validation loss: 2.590637244658452

Epoch: 5| Step: 5
Training loss: 2.103666365667225
Validation loss: 2.6086017049093284

Epoch: 5| Step: 6
Training loss: 2.6422966174892104
Validation loss: 2.602338081505621

Epoch: 5| Step: 7
Training loss: 2.4691001547194564
Validation loss: 2.6162314723282694

Epoch: 5| Step: 8
Training loss: 2.2368895779582574
Validation loss: 2.5779179114196973

Epoch: 5| Step: 9
Training loss: 1.80711650457613
Validation loss: 2.5854355285493402

Epoch: 5| Step: 10
Training loss: 1.9151906950900661
Validation loss: 2.584734426502967

Epoch: 5| Step: 11
Training loss: 1.5784231225361323
Validation loss: 2.5861357452527294

Epoch: 435| Step: 0
Training loss: 2.1730353459846623
Validation loss: 2.5802119699472286

Epoch: 5| Step: 1
Training loss: 1.963094793680588
Validation loss: 2.581048236809515

Epoch: 5| Step: 2
Training loss: 1.6556941125196338
Validation loss: 2.5753645134297463

Epoch: 5| Step: 3
Training loss: 2.221767469076255
Validation loss: 2.5576061992838905

Epoch: 5| Step: 4
Training loss: 2.2968068015425374
Validation loss: 2.567332723251547

Epoch: 5| Step: 5
Training loss: 2.168996646278782
Validation loss: 2.587621054374584

Epoch: 5| Step: 6
Training loss: 1.8667713802917179
Validation loss: 2.5468721721298024

Epoch: 5| Step: 7
Training loss: 2.251331147505844
Validation loss: 2.5460655548728877

Epoch: 5| Step: 8
Training loss: 1.9554335112069392
Validation loss: 2.570301929363247

Epoch: 5| Step: 9
Training loss: 1.7149054792064502
Validation loss: 2.5920828206619255

Epoch: 5| Step: 10
Training loss: 2.4412876924338525
Validation loss: 2.6096454183287032

Epoch: 5| Step: 11
Training loss: 1.5979800467456917
Validation loss: 2.586479575819789

Epoch: 436| Step: 0
Training loss: 2.046757818464082
Validation loss: 2.5419916950918533

Epoch: 5| Step: 1
Training loss: 2.4582742479195887
Validation loss: 2.5267051860943868

Epoch: 5| Step: 2
Training loss: 1.7783736713747937
Validation loss: 2.5325338106386948

Epoch: 5| Step: 3
Training loss: 2.201786906472207
Validation loss: 2.531063999202365

Epoch: 5| Step: 4
Training loss: 2.036156933685061
Validation loss: 2.537500493749561

Epoch: 5| Step: 5
Training loss: 2.2241436585538934
Validation loss: 2.5185990651976238

Epoch: 5| Step: 6
Training loss: 1.385949923729503
Validation loss: 2.5374987633550226

Epoch: 5| Step: 7
Training loss: 2.2070330864552647
Validation loss: 2.533187332829584

Epoch: 5| Step: 8
Training loss: 2.1290367156482692
Validation loss: 2.510911225373519

Epoch: 5| Step: 9
Training loss: 2.689805838090318
Validation loss: 2.512084032612147

Epoch: 5| Step: 10
Training loss: 2.01073839317879
Validation loss: 2.5235868002360253

Epoch: 5| Step: 11
Training loss: 2.117574396008753
Validation loss: 2.50949494600544

Epoch: 437| Step: 0
Training loss: 2.425555478215077
Validation loss: 2.508681133993244

Epoch: 5| Step: 1
Training loss: 2.214357998982154
Validation loss: 2.5197886687869757

Epoch: 5| Step: 2
Training loss: 2.4358767459675397
Validation loss: 2.558253669948127

Epoch: 5| Step: 3
Training loss: 2.4980157607156306
Validation loss: 2.545272994198328

Epoch: 5| Step: 4
Training loss: 1.5581297219545722
Validation loss: 2.534170353847164

Epoch: 5| Step: 5
Training loss: 1.8999436294826728
Validation loss: 2.5644411550156785

Epoch: 5| Step: 6
Training loss: 2.7222525298665343
Validation loss: 2.5578343980240588

Epoch: 5| Step: 7
Training loss: 1.4832508046340753
Validation loss: 2.5532420324165574

Epoch: 5| Step: 8
Training loss: 2.13695874862592
Validation loss: 2.5717906392670415

Epoch: 5| Step: 9
Training loss: 1.9418255911472395
Validation loss: 2.5814661936090877

Epoch: 5| Step: 10
Training loss: 1.8414754900661932
Validation loss: 2.589034681491126

Epoch: 5| Step: 11
Training loss: 1.5435720302529927
Validation loss: 2.57093631088868

Epoch: 438| Step: 0
Training loss: 2.1933526355779143
Validation loss: 2.5953029709713196

Epoch: 5| Step: 1
Training loss: 1.989470600176508
Validation loss: 2.6196221258212575

Epoch: 5| Step: 2
Training loss: 1.9898052857376614
Validation loss: 2.570704212892769

Epoch: 5| Step: 3
Training loss: 2.3674370662457487
Validation loss: 2.5501000048157243

Epoch: 5| Step: 4
Training loss: 2.6385001035585107
Validation loss: 2.5865939210915316

Epoch: 5| Step: 5
Training loss: 2.1834784461954277
Validation loss: 2.5906448007646756

Epoch: 5| Step: 6
Training loss: 2.1114160905805033
Validation loss: 2.565810972064477

Epoch: 5| Step: 7
Training loss: 2.315877252550976
Validation loss: 2.5649153793237374

Epoch: 5| Step: 8
Training loss: 1.7986894154369608
Validation loss: 2.5738468586520766

Epoch: 5| Step: 9
Training loss: 2.1581604828225123
Validation loss: 2.5535331066058973

Epoch: 5| Step: 10
Training loss: 1.8618305564920903
Validation loss: 2.5650972485650714

Epoch: 5| Step: 11
Training loss: 1.8146605932501727
Validation loss: 2.570727070436672

Epoch: 439| Step: 0
Training loss: 2.426012602506832
Validation loss: 2.5401602382127626

Epoch: 5| Step: 1
Training loss: 1.8706094835876061
Validation loss: 2.5528580300721977

Epoch: 5| Step: 2
Training loss: 2.01742910626917
Validation loss: 2.5232095881190726

Epoch: 5| Step: 3
Training loss: 2.360252772873166
Validation loss: 2.5478279421671464

Epoch: 5| Step: 4
Training loss: 2.3767444829342095
Validation loss: 2.5481687586899677

Epoch: 5| Step: 5
Training loss: 1.7889023754975197
Validation loss: 2.5365178037926346

Epoch: 5| Step: 6
Training loss: 1.3747500279092377
Validation loss: 2.5275920724307586

Epoch: 5| Step: 7
Training loss: 1.6798859944716478
Validation loss: 2.4866983997512198

Epoch: 5| Step: 8
Training loss: 2.2267467757146338
Validation loss: 2.526073795127393

Epoch: 5| Step: 9
Training loss: 2.216913242058638
Validation loss: 2.5408700153092187

Epoch: 5| Step: 10
Training loss: 2.4171882811867476
Validation loss: 2.5669873420201146

Epoch: 5| Step: 11
Training loss: 1.2954780224371762
Validation loss: 2.5616699479350324

Epoch: 440| Step: 0
Training loss: 2.052043185026897
Validation loss: 2.5790121844673046

Epoch: 5| Step: 1
Training loss: 2.058824095605724
Validation loss: 2.5673093595428824

Epoch: 5| Step: 2
Training loss: 2.1091080108086744
Validation loss: 2.584480078550994

Epoch: 5| Step: 3
Training loss: 2.045392730048559
Validation loss: 2.5896092879779005

Epoch: 5| Step: 4
Training loss: 2.585757799617921
Validation loss: 2.564124898637493

Epoch: 5| Step: 5
Training loss: 2.363135971774318
Validation loss: 2.5629467652245075

Epoch: 5| Step: 6
Training loss: 2.04765782419877
Validation loss: 2.5724894494549964

Epoch: 5| Step: 7
Training loss: 1.7899278438665562
Validation loss: 2.529845574168051

Epoch: 5| Step: 8
Training loss: 1.7408550966447605
Validation loss: 2.5450826629724057

Epoch: 5| Step: 9
Training loss: 1.8509542375510142
Validation loss: 2.53853329743352

Epoch: 5| Step: 10
Training loss: 2.0890075722023482
Validation loss: 2.544897942517108

Epoch: 5| Step: 11
Training loss: 1.4178349875839613
Validation loss: 2.559117713450911

Epoch: 441| Step: 0
Training loss: 2.4521707027127864
Validation loss: 2.535877891148641

Epoch: 5| Step: 1
Training loss: 2.1462454415541212
Validation loss: 2.5623740770057397

Epoch: 5| Step: 2
Training loss: 2.2563525697002063
Validation loss: 2.5575110554386264

Epoch: 5| Step: 3
Training loss: 1.951373604397479
Validation loss: 2.563692889092805

Epoch: 5| Step: 4
Training loss: 2.03487378171857
Validation loss: 2.561970248940004

Epoch: 5| Step: 5
Training loss: 2.0552728203621498
Validation loss: 2.5660374500780665

Epoch: 5| Step: 6
Training loss: 2.3639020120286593
Validation loss: 2.546257102059379

Epoch: 5| Step: 7
Training loss: 1.338806418076909
Validation loss: 2.55517586289458

Epoch: 5| Step: 8
Training loss: 1.8401766271403097
Validation loss: 2.592613882937383

Epoch: 5| Step: 9
Training loss: 1.8575153186931428
Validation loss: 2.5580392173502804

Epoch: 5| Step: 10
Training loss: 1.7281989028332088
Validation loss: 2.5615722015583096

Epoch: 5| Step: 11
Training loss: 2.3276880865588727
Validation loss: 2.551607267910139

Epoch: 442| Step: 0
Training loss: 1.7679814505531788
Validation loss: 2.577749810709962

Epoch: 5| Step: 1
Training loss: 2.2840859539473404
Validation loss: 2.5799440343772475

Epoch: 5| Step: 2
Training loss: 2.2624957342792573
Validation loss: 2.592169138188217

Epoch: 5| Step: 3
Training loss: 2.143510196719377
Validation loss: 2.569946344145764

Epoch: 5| Step: 4
Training loss: 1.6334177747943606
Validation loss: 2.57474358109078

Epoch: 5| Step: 5
Training loss: 1.7606683885931116
Validation loss: 2.5865435778402084

Epoch: 5| Step: 6
Training loss: 2.7252356681058445
Validation loss: 2.5483774110659136

Epoch: 5| Step: 7
Training loss: 2.115912134246381
Validation loss: 2.5651850066380026

Epoch: 5| Step: 8
Training loss: 2.093488420686297
Validation loss: 2.542394964954897

Epoch: 5| Step: 9
Training loss: 1.4420113469390343
Validation loss: 2.557103468009848

Epoch: 5| Step: 10
Training loss: 1.899348413269407
Validation loss: 2.5730820241036625

Epoch: 5| Step: 11
Training loss: 3.5300804159282153
Validation loss: 2.5846279973741155

Epoch: 443| Step: 0
Training loss: 1.5443767063157687
Validation loss: 2.5675689061027067

Epoch: 5| Step: 1
Training loss: 2.003428857761201
Validation loss: 2.5672941447709885

Epoch: 5| Step: 2
Training loss: 1.4790641140198582
Validation loss: 2.5516921982794942

Epoch: 5| Step: 3
Training loss: 2.335116238855896
Validation loss: 2.5583970865471812

Epoch: 5| Step: 4
Training loss: 2.5712820155144605
Validation loss: 2.5683680815845276

Epoch: 5| Step: 5
Training loss: 2.3161445971663577
Validation loss: 2.5634747256317825

Epoch: 5| Step: 6
Training loss: 1.7630681792700584
Validation loss: 2.595272446594507

Epoch: 5| Step: 7
Training loss: 1.478363956548539
Validation loss: 2.621879228748402

Epoch: 5| Step: 8
Training loss: 1.9434167901380366
Validation loss: 2.6276290799117072

Epoch: 5| Step: 9
Training loss: 2.615101452640983
Validation loss: 2.6483707325789156

Epoch: 5| Step: 10
Training loss: 2.662870615922744
Validation loss: 2.6345486335956894

Epoch: 5| Step: 11
Training loss: 2.017842809961393
Validation loss: 2.6584387531623594

Epoch: 444| Step: 0
Training loss: 2.041153226895645
Validation loss: 2.593955629309712

Epoch: 5| Step: 1
Training loss: 2.1148750091485997
Validation loss: 2.561776233434166

Epoch: 5| Step: 2
Training loss: 1.4867116105053055
Validation loss: 2.5576455958399267

Epoch: 5| Step: 3
Training loss: 1.982200211783852
Validation loss: 2.5456693053797763

Epoch: 5| Step: 4
Training loss: 2.274454629944941
Validation loss: 2.5391660502910542

Epoch: 5| Step: 5
Training loss: 1.9139590488425717
Validation loss: 2.5493236815148994

Epoch: 5| Step: 6
Training loss: 2.6041227006379764
Validation loss: 2.5450633573983366

Epoch: 5| Step: 7
Training loss: 1.4745417901523719
Validation loss: 2.556095785045391

Epoch: 5| Step: 8
Training loss: 1.8518675218908163
Validation loss: 2.5422263558452056

Epoch: 5| Step: 9
Training loss: 2.4179332527180333
Validation loss: 2.5437780675503365

Epoch: 5| Step: 10
Training loss: 2.073918265149333
Validation loss: 2.5485122504421054

Epoch: 5| Step: 11
Training loss: 2.360694566771705
Validation loss: 2.5475368731871493

Epoch: 445| Step: 0
Training loss: 2.155199541381583
Validation loss: 2.531099899770886

Epoch: 5| Step: 1
Training loss: 2.1692789053948016
Validation loss: 2.513487976350262

Epoch: 5| Step: 2
Training loss: 1.3861821385551718
Validation loss: 2.603145392751327

Epoch: 5| Step: 3
Training loss: 2.3045014904412193
Validation loss: 2.6337469123746193

Epoch: 5| Step: 4
Training loss: 1.9403755629679424
Validation loss: 2.6121514372274475

Epoch: 5| Step: 5
Training loss: 2.2288899353906406
Validation loss: 2.612870051445121

Epoch: 5| Step: 6
Training loss: 2.4919634392445924
Validation loss: 2.578811565649825

Epoch: 5| Step: 7
Training loss: 2.3861074211004243
Validation loss: 2.581798956613135

Epoch: 5| Step: 8
Training loss: 1.7901286983575648
Validation loss: 2.5835704592091466

Epoch: 5| Step: 9
Training loss: 2.614769937814368
Validation loss: 2.5727981985414323

Epoch: 5| Step: 10
Training loss: 1.7284760379029662
Validation loss: 2.590512085414523

Epoch: 5| Step: 11
Training loss: 1.0847797946464666
Validation loss: 2.57724940140884

Epoch: 446| Step: 0
Training loss: 1.8475541778177775
Validation loss: 2.564621911325566

Epoch: 5| Step: 1
Training loss: 1.6574189001987651
Validation loss: 2.5515322862351955

Epoch: 5| Step: 2
Training loss: 1.973735974620153
Validation loss: 2.538241577464597

Epoch: 5| Step: 3
Training loss: 2.21952161669361
Validation loss: 2.5715643395774914

Epoch: 5| Step: 4
Training loss: 1.961010084290669
Validation loss: 2.5741965216225418

Epoch: 5| Step: 5
Training loss: 2.2532264041170937
Validation loss: 2.549900364331733

Epoch: 5| Step: 6
Training loss: 1.900219367564425
Validation loss: 2.57450802942687

Epoch: 5| Step: 7
Training loss: 2.3711860550788275
Validation loss: 2.5719804733668767

Epoch: 5| Step: 8
Training loss: 1.7590433516199702
Validation loss: 2.603149033397723

Epoch: 5| Step: 9
Training loss: 1.7267828753235719
Validation loss: 2.5655662869090445

Epoch: 5| Step: 10
Training loss: 2.2885612485797657
Validation loss: 2.585521055573776

Epoch: 5| Step: 11
Training loss: 3.2706907852761966
Validation loss: 2.552005538273724

Epoch: 447| Step: 0
Training loss: 1.8845337403906184
Validation loss: 2.5996897145502724

Epoch: 5| Step: 1
Training loss: 2.3941468868463143
Validation loss: 2.5869585405181166

Epoch: 5| Step: 2
Training loss: 2.1987020044689016
Validation loss: 2.601191898102178

Epoch: 5| Step: 3
Training loss: 1.920093858530782
Validation loss: 2.6343284114098364

Epoch: 5| Step: 4
Training loss: 1.7973536641662367
Validation loss: 2.6036319272658863

Epoch: 5| Step: 5
Training loss: 1.8204141351052556
Validation loss: 2.606480609287482

Epoch: 5| Step: 6
Training loss: 1.3825843321066016
Validation loss: 2.5828561970298445

Epoch: 5| Step: 7
Training loss: 2.800347585902092
Validation loss: 2.5880533150451255

Epoch: 5| Step: 8
Training loss: 1.8147372545844977
Validation loss: 2.552086228090059

Epoch: 5| Step: 9
Training loss: 2.091531289672988
Validation loss: 2.5779661148896027

Epoch: 5| Step: 10
Training loss: 2.3024867007920413
Validation loss: 2.54398445397039

Epoch: 5| Step: 11
Training loss: 1.982197685907141
Validation loss: 2.5344276654799582

Epoch: 448| Step: 0
Training loss: 1.7757084628089594
Validation loss: 2.5510343939128575

Epoch: 5| Step: 1
Training loss: 2.6590403542384893
Validation loss: 2.550205767501198

Epoch: 5| Step: 2
Training loss: 1.8415189919736594
Validation loss: 2.604251773715098

Epoch: 5| Step: 3
Training loss: 1.7206939108143973
Validation loss: 2.552490619675814

Epoch: 5| Step: 4
Training loss: 2.1172395256378858
Validation loss: 2.584849417768892

Epoch: 5| Step: 5
Training loss: 2.12197211468897
Validation loss: 2.5726903025604124

Epoch: 5| Step: 6
Training loss: 1.5612875239533532
Validation loss: 2.5729761168269305

Epoch: 5| Step: 7
Training loss: 1.6817557442812114
Validation loss: 2.567575448694135

Epoch: 5| Step: 8
Training loss: 2.4238279282710438
Validation loss: 2.5749208479817636

Epoch: 5| Step: 9
Training loss: 1.7349716397476818
Validation loss: 2.6026333083884667

Epoch: 5| Step: 10
Training loss: 2.7336773663619076
Validation loss: 2.598592515833934

Epoch: 5| Step: 11
Training loss: 1.820637424268147
Validation loss: 2.6186290851133656

Epoch: 449| Step: 0
Training loss: 1.838141559006116
Validation loss: 2.6083320276929456

Epoch: 5| Step: 1
Training loss: 1.7454618466921747
Validation loss: 2.596301665902411

Epoch: 5| Step: 2
Training loss: 2.1145910128248855
Validation loss: 2.582740024658284

Epoch: 5| Step: 3
Training loss: 2.713677244893564
Validation loss: 2.589113223542643

Epoch: 5| Step: 4
Training loss: 2.1759882337097802
Validation loss: 2.564514988397342

Epoch: 5| Step: 5
Training loss: 2.353601325916303
Validation loss: 2.546208729410273

Epoch: 5| Step: 6
Training loss: 1.5800370822852494
Validation loss: 2.5696312272998334

Epoch: 5| Step: 7
Training loss: 2.158071660659466
Validation loss: 2.568219268806574

Epoch: 5| Step: 8
Training loss: 1.8306783467415886
Validation loss: 2.5570282784271923

Epoch: 5| Step: 9
Training loss: 2.079553099086182
Validation loss: 2.567849197289503

Epoch: 5| Step: 10
Training loss: 2.0415798739714837
Validation loss: 2.577484033842244

Epoch: 5| Step: 11
Training loss: 1.126935195119093
Validation loss: 2.559524122372267

Epoch: 450| Step: 0
Training loss: 2.0874021724232388
Validation loss: 2.5662073825717004

Epoch: 5| Step: 1
Training loss: 1.797079323471458
Validation loss: 2.571596599789605

Epoch: 5| Step: 2
Training loss: 2.2131848455318734
Validation loss: 2.5800731234390097

Epoch: 5| Step: 3
Training loss: 1.9366104791252334
Validation loss: 2.5628011301705795

Epoch: 5| Step: 4
Training loss: 1.8748671166697861
Validation loss: 2.5490152497374776

Epoch: 5| Step: 5
Training loss: 1.35876652922486
Validation loss: 2.5508001617930085

Epoch: 5| Step: 6
Training loss: 1.7341656257788807
Validation loss: 2.5727903525560167

Epoch: 5| Step: 7
Training loss: 2.3856469477702515
Validation loss: 2.5706309804360665

Epoch: 5| Step: 8
Training loss: 2.2529652447616684
Validation loss: 2.57258391577398

Epoch: 5| Step: 9
Training loss: 2.7346495572259677
Validation loss: 2.599087623382116

Epoch: 5| Step: 10
Training loss: 2.3613390295188665
Validation loss: 2.5556849050151764

Epoch: 5| Step: 11
Training loss: 1.1430864817124586
Validation loss: 2.577460571367354

Epoch: 451| Step: 0
Training loss: 1.753261388141456
Validation loss: 2.560744440180888

Epoch: 5| Step: 1
Training loss: 1.7021817736444436
Validation loss: 2.57658074879319

Epoch: 5| Step: 2
Training loss: 1.4088220598531014
Validation loss: 2.594607552318912

Epoch: 5| Step: 3
Training loss: 2.551416198311125
Validation loss: 2.6105177332063856

Epoch: 5| Step: 4
Training loss: 1.7567762923492773
Validation loss: 2.6027669132921476

Epoch: 5| Step: 5
Training loss: 2.0768091151497394
Validation loss: 2.5950051989469594

Epoch: 5| Step: 6
Training loss: 1.7317764473348463
Validation loss: 2.610779816214662

Epoch: 5| Step: 7
Training loss: 2.840361871901975
Validation loss: 2.583239620313776

Epoch: 5| Step: 8
Training loss: 1.5821572336025331
Validation loss: 2.5655622095934345

Epoch: 5| Step: 9
Training loss: 2.2736231148051496
Validation loss: 2.5712875209735637

Epoch: 5| Step: 10
Training loss: 2.1764049902978106
Validation loss: 2.5599114594446672

Epoch: 5| Step: 11
Training loss: 1.3508878137441949
Validation loss: 2.542343187713264

Epoch: 452| Step: 0
Training loss: 2.04972966435331
Validation loss: 2.5594293642150667

Epoch: 5| Step: 1
Training loss: 1.9778220645301388
Validation loss: 2.523861454799352

Epoch: 5| Step: 2
Training loss: 1.6117336433377105
Validation loss: 2.5781775112776857

Epoch: 5| Step: 3
Training loss: 1.8959486231140434
Validation loss: 2.5402142890700383

Epoch: 5| Step: 4
Training loss: 1.8599479497784366
Validation loss: 2.537254820725091

Epoch: 5| Step: 5
Training loss: 2.2996805922928956
Validation loss: 2.537210953352656

Epoch: 5| Step: 6
Training loss: 1.6326704191603763
Validation loss: 2.5445833798359523

Epoch: 5| Step: 7
Training loss: 2.306251745042425
Validation loss: 2.5694710611276443

Epoch: 5| Step: 8
Training loss: 2.038564570055759
Validation loss: 2.5567311347888846

Epoch: 5| Step: 9
Training loss: 2.482226228244971
Validation loss: 2.5857882077242995

Epoch: 5| Step: 10
Training loss: 1.6894905218494685
Validation loss: 2.5893609741467003

Epoch: 5| Step: 11
Training loss: 2.099421548648156
Validation loss: 2.5835097519306798

Epoch: 453| Step: 0
Training loss: 1.6455627975559224
Validation loss: 2.5833484177507926

Epoch: 5| Step: 1
Training loss: 2.598046570328927
Validation loss: 2.551758349740125

Epoch: 5| Step: 2
Training loss: 2.149385111508513
Validation loss: 2.5564028496035025

Epoch: 5| Step: 3
Training loss: 1.5621427509074344
Validation loss: 2.541206077106036

Epoch: 5| Step: 4
Training loss: 1.7261762230070126
Validation loss: 2.553108898066931

Epoch: 5| Step: 5
Training loss: 2.5410274473086814
Validation loss: 2.5742466509729542

Epoch: 5| Step: 6
Training loss: 1.8009007346011163
Validation loss: 2.56406906595112

Epoch: 5| Step: 7
Training loss: 2.262123506528559
Validation loss: 2.5913771304055753

Epoch: 5| Step: 8
Training loss: 1.8298276487600875
Validation loss: 2.522365405313818

Epoch: 5| Step: 9
Training loss: 1.876616035860286
Validation loss: 2.5560906782609263

Epoch: 5| Step: 10
Training loss: 2.003297352629044
Validation loss: 2.5277174212046805

Epoch: 5| Step: 11
Training loss: 2.2413013581297143
Validation loss: 2.5652862458386765

Epoch: 454| Step: 0
Training loss: 1.6685641295969529
Validation loss: 2.5534060469433797

Epoch: 5| Step: 1
Training loss: 1.9918325669000392
Validation loss: 2.544148610412601

Epoch: 5| Step: 2
Training loss: 2.1069644293622756
Validation loss: 2.555156415859508

Epoch: 5| Step: 3
Training loss: 1.6163161136944801
Validation loss: 2.532275553350889

Epoch: 5| Step: 4
Training loss: 2.210557669104124
Validation loss: 2.5589994502012936

Epoch: 5| Step: 5
Training loss: 2.312217179608146
Validation loss: 2.5578003252532358

Epoch: 5| Step: 6
Training loss: 1.7263092960059865
Validation loss: 2.5336270846435265

Epoch: 5| Step: 7
Training loss: 1.789100346727142
Validation loss: 2.5298682197168194

Epoch: 5| Step: 8
Training loss: 2.738524073828052
Validation loss: 2.534346256649713

Epoch: 5| Step: 9
Training loss: 1.7941163489760998
Validation loss: 2.5210296669999583

Epoch: 5| Step: 10
Training loss: 2.0984944350755304
Validation loss: 2.5238778052010957

Epoch: 5| Step: 11
Training loss: 1.5772716367806234
Validation loss: 2.5583171549377672

Epoch: 455| Step: 0
Training loss: 1.8230260180417819
Validation loss: 2.554371313579809

Epoch: 5| Step: 1
Training loss: 2.4233148048178785
Validation loss: 2.5785092655067436

Epoch: 5| Step: 2
Training loss: 2.7416930880524735
Validation loss: 2.6078826763812497

Epoch: 5| Step: 3
Training loss: 2.136711050853074
Validation loss: 2.6178501030547183

Epoch: 5| Step: 4
Training loss: 1.7573887971341466
Validation loss: 2.582556778313468

Epoch: 5| Step: 5
Training loss: 1.9807767308800417
Validation loss: 2.563936137344607

Epoch: 5| Step: 6
Training loss: 2.4455009607201257
Validation loss: 2.5755416912986684

Epoch: 5| Step: 7
Training loss: 1.4181699163486554
Validation loss: 2.546790774928345

Epoch: 5| Step: 8
Training loss: 1.4816637676512452
Validation loss: 2.5195972700118916

Epoch: 5| Step: 9
Training loss: 1.4982911548611328
Validation loss: 2.54220654793676

Epoch: 5| Step: 10
Training loss: 2.064095544658839
Validation loss: 2.5503532514045717

Epoch: 5| Step: 11
Training loss: 1.9467723837761308
Validation loss: 2.5321952561908536

Epoch: 456| Step: 0
Training loss: 1.9955207017069911
Validation loss: 2.539168816321322

Epoch: 5| Step: 1
Training loss: 2.1259680394294014
Validation loss: 2.5250378151066886

Epoch: 5| Step: 2
Training loss: 1.763183864190993
Validation loss: 2.535062653979301

Epoch: 5| Step: 3
Training loss: 1.795790900889298
Validation loss: 2.5509396241479183

Epoch: 5| Step: 4
Training loss: 1.5008212066843918
Validation loss: 2.525083514837347

Epoch: 5| Step: 5
Training loss: 2.224721153873873
Validation loss: 2.540511448517357

Epoch: 5| Step: 6
Training loss: 1.1966068017130287
Validation loss: 2.5746935347245468

Epoch: 5| Step: 7
Training loss: 2.0300993961748794
Validation loss: 2.5802472713911757

Epoch: 5| Step: 8
Training loss: 2.1834269069197916
Validation loss: 2.5677242252768537

Epoch: 5| Step: 9
Training loss: 2.475352764998909
Validation loss: 2.5392199227853802

Epoch: 5| Step: 10
Training loss: 2.0222232666059505
Validation loss: 2.5377483586194014

Epoch: 5| Step: 11
Training loss: 2.8818663825272544
Validation loss: 2.5620774564263606

Epoch: 457| Step: 0
Training loss: 2.110188080237937
Validation loss: 2.559478393285881

Epoch: 5| Step: 1
Training loss: 1.7153754659094869
Validation loss: 2.5513488270484586

Epoch: 5| Step: 2
Training loss: 2.103704105812705
Validation loss: 2.5386873603892828

Epoch: 5| Step: 3
Training loss: 1.7372198057318837
Validation loss: 2.577832322895538

Epoch: 5| Step: 4
Training loss: 2.1982763517377926
Validation loss: 2.5982019295864474

Epoch: 5| Step: 5
Training loss: 2.132902262269485
Validation loss: 2.613157515549716

Epoch: 5| Step: 6
Training loss: 1.717456191946535
Validation loss: 2.600325713327134

Epoch: 5| Step: 7
Training loss: 1.799969537795114
Validation loss: 2.5697155445722144

Epoch: 5| Step: 8
Training loss: 2.3729573550823257
Validation loss: 2.600339057712475

Epoch: 5| Step: 9
Training loss: 1.9769738413884748
Validation loss: 2.557965632014166

Epoch: 5| Step: 10
Training loss: 1.766491837518029
Validation loss: 2.5650002679583017

Epoch: 5| Step: 11
Training loss: 1.65324265578753
Validation loss: 2.5634164760753184

Epoch: 458| Step: 0
Training loss: 1.809786771786189
Validation loss: 2.5458520578506407

Epoch: 5| Step: 1
Training loss: 2.292183164710773
Validation loss: 2.572618829551753

Epoch: 5| Step: 2
Training loss: 1.5995525867037368
Validation loss: 2.543480375811001

Epoch: 5| Step: 3
Training loss: 2.578822093701055
Validation loss: 2.568384431008465

Epoch: 5| Step: 4
Training loss: 1.7318496877361687
Validation loss: 2.542384332947165

Epoch: 5| Step: 5
Training loss: 1.6426430778951377
Validation loss: 2.5170826095047896

Epoch: 5| Step: 6
Training loss: 2.0925186863729137
Validation loss: 2.542615866995098

Epoch: 5| Step: 7
Training loss: 2.8640542021369497
Validation loss: 2.561650852685272

Epoch: 5| Step: 8
Training loss: 1.686151460181909
Validation loss: 2.5379185921684613

Epoch: 5| Step: 9
Training loss: 1.4087174702419807
Validation loss: 2.5567948168833334

Epoch: 5| Step: 10
Training loss: 1.6778098323670791
Validation loss: 2.588610747328299

Epoch: 5| Step: 11
Training loss: 0.7328041401530629
Validation loss: 2.5693941359850117

Epoch: 459| Step: 0
Training loss: 1.8758443202958517
Validation loss: 2.563171771625112

Epoch: 5| Step: 1
Training loss: 1.9272805465274623
Validation loss: 2.5521477918204893

Epoch: 5| Step: 2
Training loss: 1.896724728911822
Validation loss: 2.575704652239151

Epoch: 5| Step: 3
Training loss: 2.1914939386839687
Validation loss: 2.6202214054779365

Epoch: 5| Step: 4
Training loss: 2.5098201523137966
Validation loss: 2.6296226126269273

Epoch: 5| Step: 5
Training loss: 1.831903579265122
Validation loss: 2.6237649964244314

Epoch: 5| Step: 6
Training loss: 1.6572283608241938
Validation loss: 2.615331551586542

Epoch: 5| Step: 7
Training loss: 1.668814308556123
Validation loss: 2.603436265877298

Epoch: 5| Step: 8
Training loss: 1.6597127164872634
Validation loss: 2.606808147995393

Epoch: 5| Step: 9
Training loss: 1.8620102744182656
Validation loss: 2.5919409421748734

Epoch: 5| Step: 10
Training loss: 2.4268871004292683
Validation loss: 2.5513967907573885

Epoch: 5| Step: 11
Training loss: 1.2553023412595874
Validation loss: 2.5382367048095387

Epoch: 460| Step: 0
Training loss: 2.023797198399643
Validation loss: 2.557513797743921

Epoch: 5| Step: 1
Training loss: 1.6744516784721524
Validation loss: 2.5463739772147465

Epoch: 5| Step: 2
Training loss: 2.1376602915844223
Validation loss: 2.5322000855477507

Epoch: 5| Step: 3
Training loss: 2.2333683333809558
Validation loss: 2.5283576625650053

Epoch: 5| Step: 4
Training loss: 1.8825523228358678
Validation loss: 2.5403468439188974

Epoch: 5| Step: 5
Training loss: 1.8444899028068429
Validation loss: 2.5445377648433856

Epoch: 5| Step: 6
Training loss: 1.6719692595818179
Validation loss: 2.5547413912658357

Epoch: 5| Step: 7
Training loss: 2.2197823070637295
Validation loss: 2.5776092051864485

Epoch: 5| Step: 8
Training loss: 1.7247336527542783
Validation loss: 2.5925670745201805

Epoch: 5| Step: 9
Training loss: 2.00902143960073
Validation loss: 2.6070609367950657

Epoch: 5| Step: 10
Training loss: 2.134879427683411
Validation loss: 2.6018456313569343

Epoch: 5| Step: 11
Training loss: 2.2422268428740177
Validation loss: 2.619571837093643

Epoch: 461| Step: 0
Training loss: 2.0616851121616473
Validation loss: 2.5663367600228786

Epoch: 5| Step: 1
Training loss: 1.7964873185935128
Validation loss: 2.5616275341053854

Epoch: 5| Step: 2
Training loss: 1.3950440561864603
Validation loss: 2.525553887585525

Epoch: 5| Step: 3
Training loss: 2.785576188154294
Validation loss: 2.552129080745144

Epoch: 5| Step: 4
Training loss: 2.7788717838838606
Validation loss: 2.5539113186762314

Epoch: 5| Step: 5
Training loss: 2.2030847424014692
Validation loss: 2.530833543654571

Epoch: 5| Step: 6
Training loss: 1.825606739092599
Validation loss: 2.516011328876888

Epoch: 5| Step: 7
Training loss: 2.5435854022035946
Validation loss: 2.5214039764863685

Epoch: 5| Step: 8
Training loss: 2.4947800499971473
Validation loss: 2.5043921889300793

Epoch: 5| Step: 9
Training loss: 1.7639685093021622
Validation loss: 2.517167986481021

Epoch: 5| Step: 10
Training loss: 1.9189469276790276
Validation loss: 2.5433846058954015

Epoch: 5| Step: 11
Training loss: 2.3326757617077933
Validation loss: 2.5627821286278

Epoch: 462| Step: 0
Training loss: 1.2962784831523622
Validation loss: 2.5949604817690783

Epoch: 5| Step: 1
Training loss: 2.0135328687017466
Validation loss: 2.5798315777007343

Epoch: 5| Step: 2
Training loss: 2.275225273967887
Validation loss: 2.5268169838743524

Epoch: 5| Step: 3
Training loss: 1.7912162244105407
Validation loss: 2.52277716981552

Epoch: 5| Step: 4
Training loss: 2.651976704657701
Validation loss: 2.5093716560807042

Epoch: 5| Step: 5
Training loss: 2.0513959272271505
Validation loss: 2.5330627292697363

Epoch: 5| Step: 6
Training loss: 1.7955876258282657
Validation loss: 2.538937007052507

Epoch: 5| Step: 7
Training loss: 1.7526376465031743
Validation loss: 2.5440234034994242

Epoch: 5| Step: 8
Training loss: 1.7408583150811716
Validation loss: 2.5530259409270277

Epoch: 5| Step: 9
Training loss: 2.027920032835717
Validation loss: 2.5751114311921808

Epoch: 5| Step: 10
Training loss: 2.3167923964085864
Validation loss: 2.5322949760307636

Epoch: 5| Step: 11
Training loss: 1.4515615276419644
Validation loss: 2.556589730778347

Epoch: 463| Step: 0
Training loss: 1.6530919466518137
Validation loss: 2.5334691888579255

Epoch: 5| Step: 1
Training loss: 2.3983034972490436
Validation loss: 2.550556069716805

Epoch: 5| Step: 2
Training loss: 1.608647895187041
Validation loss: 2.557145205160442

Epoch: 5| Step: 3
Training loss: 1.7583801031295563
Validation loss: 2.553641335467001

Epoch: 5| Step: 4
Training loss: 1.9839421198116072
Validation loss: 2.584529591402952

Epoch: 5| Step: 5
Training loss: 2.242381124078005
Validation loss: 2.6051835033133903

Epoch: 5| Step: 6
Training loss: 1.8053137283096505
Validation loss: 2.6035641634461792

Epoch: 5| Step: 7
Training loss: 2.3131436663587976
Validation loss: 2.603610839018455

Epoch: 5| Step: 8
Training loss: 1.9448259350278017
Validation loss: 2.6126228989588323

Epoch: 5| Step: 9
Training loss: 1.9316733948615366
Validation loss: 2.6420966454783024

Epoch: 5| Step: 10
Training loss: 1.7170205865602284
Validation loss: 2.604114990993229

Epoch: 5| Step: 11
Training loss: 2.1266813919051866
Validation loss: 2.6061514055918855

Epoch: 464| Step: 0
Training loss: 1.9658022414019742
Validation loss: 2.5917738487295923

Epoch: 5| Step: 1
Training loss: 1.3663822963702306
Validation loss: 2.5813066367031214

Epoch: 5| Step: 2
Training loss: 2.0591549189917
Validation loss: 2.614429257831715

Epoch: 5| Step: 3
Training loss: 1.7627056597038755
Validation loss: 2.5785643270688126

Epoch: 5| Step: 4
Training loss: 2.323300579374697
Validation loss: 2.589359992000133

Epoch: 5| Step: 5
Training loss: 1.4308123723255277
Validation loss: 2.57073090383749

Epoch: 5| Step: 6
Training loss: 1.8919519859052516
Validation loss: 2.562323540915446

Epoch: 5| Step: 7
Training loss: 1.7664912301652138
Validation loss: 2.5824003027997464

Epoch: 5| Step: 8
Training loss: 1.7276842434755861
Validation loss: 2.5892093355129187

Epoch: 5| Step: 9
Training loss: 2.884503951243397
Validation loss: 2.5843877383821114

Epoch: 5| Step: 10
Training loss: 1.749023914603334
Validation loss: 2.5884281737368995

Epoch: 5| Step: 11
Training loss: 2.6741069372474087
Validation loss: 2.6030660872187052

Epoch: 465| Step: 0
Training loss: 2.1819782866631003
Validation loss: 2.6053115210116258

Epoch: 5| Step: 1
Training loss: 2.291054233443598
Validation loss: 2.5784419414022914

Epoch: 5| Step: 2
Training loss: 1.9756741544117038
Validation loss: 2.6099823303952134

Epoch: 5| Step: 3
Training loss: 2.003181192499603
Validation loss: 2.6417414846164218

Epoch: 5| Step: 4
Training loss: 1.6148569018857724
Validation loss: 2.620817330002758

Epoch: 5| Step: 5
Training loss: 1.8457737823363682
Validation loss: 2.648684239779609

Epoch: 5| Step: 6
Training loss: 1.6796240506275604
Validation loss: 2.6311626981627696

Epoch: 5| Step: 7
Training loss: 1.9638295523339384
Validation loss: 2.6317726972220927

Epoch: 5| Step: 8
Training loss: 1.8196331934135483
Validation loss: 2.6415370442049806

Epoch: 5| Step: 9
Training loss: 2.174853909727273
Validation loss: 2.6375379744955287

Epoch: 5| Step: 10
Training loss: 1.9839093720825463
Validation loss: 2.603224848511057

Epoch: 5| Step: 11
Training loss: 1.6042460962753036
Validation loss: 2.607327733620369

Epoch: 466| Step: 0
Training loss: 1.8283338508964555
Validation loss: 2.586754353903352

Epoch: 5| Step: 1
Training loss: 1.3529432883941284
Validation loss: 2.565462384973355

Epoch: 5| Step: 2
Training loss: 1.9003436405219303
Validation loss: 2.5515567443869953

Epoch: 5| Step: 3
Training loss: 2.8967586292320378
Validation loss: 2.55715677613892

Epoch: 5| Step: 4
Training loss: 1.8274475537874875
Validation loss: 2.557176860607095

Epoch: 5| Step: 5
Training loss: 1.8899729841814323
Validation loss: 2.56170096577851

Epoch: 5| Step: 6
Training loss: 2.2846128159918346
Validation loss: 2.5421561345699812

Epoch: 5| Step: 7
Training loss: 1.990126557279526
Validation loss: 2.5850422587835795

Epoch: 5| Step: 8
Training loss: 1.4902930091931996
Validation loss: 2.586531806104012

Epoch: 5| Step: 9
Training loss: 2.5622972547759315
Validation loss: 2.598179485810233

Epoch: 5| Step: 10
Training loss: 1.3007354270035132
Validation loss: 2.5858008241981554

Epoch: 5| Step: 11
Training loss: 1.033525557225536
Validation loss: 2.619507128897132

Epoch: 467| Step: 0
Training loss: 2.5893131592898024
Validation loss: 2.6335488901662147

Epoch: 5| Step: 1
Training loss: 2.041264890206498
Validation loss: 2.6528328363642157

Epoch: 5| Step: 2
Training loss: 1.589534420129136
Validation loss: 2.673698189928821

Epoch: 5| Step: 3
Training loss: 2.0255876700949584
Validation loss: 2.6343940150433314

Epoch: 5| Step: 4
Training loss: 1.805413236470254
Validation loss: 2.6848058466565097

Epoch: 5| Step: 5
Training loss: 1.8135219192379222
Validation loss: 2.6282749712319675

Epoch: 5| Step: 6
Training loss: 1.09603153413808
Validation loss: 2.5854720612052096

Epoch: 5| Step: 7
Training loss: 2.3223924145042805
Validation loss: 2.5768263233554882

Epoch: 5| Step: 8
Training loss: 1.9781149094069626
Validation loss: 2.602993618296996

Epoch: 5| Step: 9
Training loss: 2.138601195678548
Validation loss: 2.570709874163068

Epoch: 5| Step: 10
Training loss: 1.6953812686315168
Validation loss: 2.5933930714459748

Epoch: 5| Step: 11
Training loss: 1.5971452040232206
Validation loss: 2.6060677354111412

Epoch: 468| Step: 0
Training loss: 2.1648462301712943
Validation loss: 2.6000568512056312

Epoch: 5| Step: 1
Training loss: 1.598356433949421
Validation loss: 2.582675718749965

Epoch: 5| Step: 2
Training loss: 1.8775749327720128
Validation loss: 2.601059885130542

Epoch: 5| Step: 3
Training loss: 1.4205828653809465
Validation loss: 2.5713724696792077

Epoch: 5| Step: 4
Training loss: 1.3977763141985942
Validation loss: 2.5874901765216105

Epoch: 5| Step: 5
Training loss: 1.7848303432674062
Validation loss: 2.58414357820161

Epoch: 5| Step: 6
Training loss: 2.648069463043505
Validation loss: 2.5711428104102567

Epoch: 5| Step: 7
Training loss: 1.6129283750019257
Validation loss: 2.584105712010174

Epoch: 5| Step: 8
Training loss: 2.0969356385970013
Validation loss: 2.592299044038896

Epoch: 5| Step: 9
Training loss: 1.9715048271737343
Validation loss: 2.549797906456293

Epoch: 5| Step: 10
Training loss: 1.9934091450022653
Validation loss: 2.6140139949027987

Epoch: 5| Step: 11
Training loss: 2.2034569889213556
Validation loss: 2.595622964410116

Epoch: 469| Step: 0
Training loss: 1.651119635472827
Validation loss: 2.6049690148609144

Epoch: 5| Step: 1
Training loss: 1.3701793958336141
Validation loss: 2.6114324312532093

Epoch: 5| Step: 2
Training loss: 2.0916814122180525
Validation loss: 2.602434495229173

Epoch: 5| Step: 3
Training loss: 1.9489207680237233
Validation loss: 2.5769601444497465

Epoch: 5| Step: 4
Training loss: 2.3304461486723036
Validation loss: 2.593456964140515

Epoch: 5| Step: 5
Training loss: 1.7598874201314314
Validation loss: 2.5901588950149703

Epoch: 5| Step: 6
Training loss: 1.6940623653420959
Validation loss: 2.6163292801459836

Epoch: 5| Step: 7
Training loss: 1.900998432939376
Validation loss: 2.576513950714822

Epoch: 5| Step: 8
Training loss: 1.6921457695856859
Validation loss: 2.59041092896579

Epoch: 5| Step: 9
Training loss: 2.102806432213251
Validation loss: 2.574134570584724

Epoch: 5| Step: 10
Training loss: 2.191269596619357
Validation loss: 2.5693538350518974

Epoch: 5| Step: 11
Training loss: 2.6916902389517747
Validation loss: 2.5441957278507235

Epoch: 470| Step: 0
Training loss: 1.8775979164079468
Validation loss: 2.548480111207742

Epoch: 5| Step: 1
Training loss: 1.444754993034695
Validation loss: 2.5592342555371745

Epoch: 5| Step: 2
Training loss: 1.838332282256549
Validation loss: 2.5406157217759575

Epoch: 5| Step: 3
Training loss: 1.9305671200607903
Validation loss: 2.564587026191075

Epoch: 5| Step: 4
Training loss: 1.7672522144290261
Validation loss: 2.5508227498299063

Epoch: 5| Step: 5
Training loss: 2.0272040346546563
Validation loss: 2.5606544757177243

Epoch: 5| Step: 6
Training loss: 2.096818753211536
Validation loss: 2.5775959512442577

Epoch: 5| Step: 7
Training loss: 1.6205069709399555
Validation loss: 2.580933645842674

Epoch: 5| Step: 8
Training loss: 1.9533647313811393
Validation loss: 2.599557904260081

Epoch: 5| Step: 9
Training loss: 2.0833464685661762
Validation loss: 2.5826707126033166

Epoch: 5| Step: 10
Training loss: 2.378992840172864
Validation loss: 2.602959651969668

Epoch: 5| Step: 11
Training loss: 1.0388299782234343
Validation loss: 2.6036664227987063

Epoch: 471| Step: 0
Training loss: 1.7710691257644586
Validation loss: 2.6109942762775282

Epoch: 5| Step: 1
Training loss: 1.6571631883092799
Validation loss: 2.6119149993489366

Epoch: 5| Step: 2
Training loss: 2.0428914918022034
Validation loss: 2.5897012501633867

Epoch: 5| Step: 3
Training loss: 1.4068666589558312
Validation loss: 2.5936029882783775

Epoch: 5| Step: 4
Training loss: 1.3404254151211874
Validation loss: 2.615953342333721

Epoch: 5| Step: 5
Training loss: 1.764317931746494
Validation loss: 2.601000590541762

Epoch: 5| Step: 6
Training loss: 1.850695250007815
Validation loss: 2.6063875849669724

Epoch: 5| Step: 7
Training loss: 2.8025592177682705
Validation loss: 2.573999305830227

Epoch: 5| Step: 8
Training loss: 1.7709303287046547
Validation loss: 2.5784161836739115

Epoch: 5| Step: 9
Training loss: 2.1362566404646803
Validation loss: 2.5801292951477977

Epoch: 5| Step: 10
Training loss: 2.0186353574153197
Validation loss: 2.578507069492271

Epoch: 5| Step: 11
Training loss: 2.52548607028525
Validation loss: 2.585614917069409

Epoch: 472| Step: 0
Training loss: 2.4148703399349434
Validation loss: 2.5772432110123127

Epoch: 5| Step: 1
Training loss: 1.6197817721376435
Validation loss: 2.5594083620038797

Epoch: 5| Step: 2
Training loss: 1.6198499940958089
Validation loss: 2.555929692726697

Epoch: 5| Step: 3
Training loss: 1.5724437162578984
Validation loss: 2.569441569530036

Epoch: 5| Step: 4
Training loss: 2.4998205120504675
Validation loss: 2.5831010865338997

Epoch: 5| Step: 5
Training loss: 1.8944450437458442
Validation loss: 2.571035273847202

Epoch: 5| Step: 6
Training loss: 2.2769679811326444
Validation loss: 2.554306102906557

Epoch: 5| Step: 7
Training loss: 2.0905411456843694
Validation loss: 2.5588109048025127

Epoch: 5| Step: 8
Training loss: 1.5919947214566235
Validation loss: 2.570087392084323

Epoch: 5| Step: 9
Training loss: 1.3697251665148222
Validation loss: 2.5709368653731537

Epoch: 5| Step: 10
Training loss: 2.236235477577336
Validation loss: 2.577532856303533

Epoch: 5| Step: 11
Training loss: 1.8323489566396232
Validation loss: 2.5872112202861515

Epoch: 473| Step: 0
Training loss: 1.8727802488598093
Validation loss: 2.589646513626723

Epoch: 5| Step: 1
Training loss: 1.91864119976118
Validation loss: 2.595357427451236

Epoch: 5| Step: 2
Training loss: 2.1198194972155404
Validation loss: 2.5472212343521403

Epoch: 5| Step: 3
Training loss: 1.550772332999395
Validation loss: 2.5424795876649147

Epoch: 5| Step: 4
Training loss: 1.5977830160350173
Validation loss: 2.5490356984392997

Epoch: 5| Step: 5
Training loss: 2.1687595334242014
Validation loss: 2.557125635189314

Epoch: 5| Step: 6
Training loss: 1.8632381282271056
Validation loss: 2.5255754938633177

Epoch: 5| Step: 7
Training loss: 2.0970285282695764
Validation loss: 2.58792695793702

Epoch: 5| Step: 8
Training loss: 2.189376353296923
Validation loss: 2.5774893082928223

Epoch: 5| Step: 9
Training loss: 1.4482941261284594
Validation loss: 2.578695734987541

Epoch: 5| Step: 10
Training loss: 2.0113906740978136
Validation loss: 2.549867736122622

Epoch: 5| Step: 11
Training loss: 1.8733459806637542
Validation loss: 2.548732805479383

Epoch: 474| Step: 0
Training loss: 1.7868408001311777
Validation loss: 2.5449171400477484

Epoch: 5| Step: 1
Training loss: 1.5566446837943086
Validation loss: 2.583997242482951

Epoch: 5| Step: 2
Training loss: 1.8060579587226715
Validation loss: 2.517197739280178

Epoch: 5| Step: 3
Training loss: 2.287320773081407
Validation loss: 2.5918980693442055

Epoch: 5| Step: 4
Training loss: 2.2872459312216815
Validation loss: 2.5096802099514135

Epoch: 5| Step: 5
Training loss: 1.8568003163041187
Validation loss: 2.5543153785385

Epoch: 5| Step: 6
Training loss: 1.6560768900679885
Validation loss: 2.5323396660667528

Epoch: 5| Step: 7
Training loss: 1.623178488195619
Validation loss: 2.5643416392838407

Epoch: 5| Step: 8
Training loss: 1.819616422056071
Validation loss: 2.556495936345184

Epoch: 5| Step: 9
Training loss: 1.9378640847982924
Validation loss: 2.5700634794181956

Epoch: 5| Step: 10
Training loss: 2.000495849177929
Validation loss: 2.571534806313832

Epoch: 5| Step: 11
Training loss: 1.8240134146096694
Validation loss: 2.563564021480537

Epoch: 475| Step: 0
Training loss: 1.6202182841705606
Validation loss: 2.5768701794135365

Epoch: 5| Step: 1
Training loss: 1.8192307036879536
Validation loss: 2.567187569189274

Epoch: 5| Step: 2
Training loss: 1.121762172795309
Validation loss: 2.5441260958799017

Epoch: 5| Step: 3
Training loss: 2.484782155579691
Validation loss: 2.5849305773082127

Epoch: 5| Step: 4
Training loss: 2.088231343516079
Validation loss: 2.5512950354461856

Epoch: 5| Step: 5
Training loss: 1.6319899243810454
Validation loss: 2.5422936796973197

Epoch: 5| Step: 6
Training loss: 2.31074560476461
Validation loss: 2.5724776616777865

Epoch: 5| Step: 7
Training loss: 2.287591871907708
Validation loss: 2.5873536057761286

Epoch: 5| Step: 8
Training loss: 1.5645396081306302
Validation loss: 2.5944712892193413

Epoch: 5| Step: 9
Training loss: 1.8391846207072362
Validation loss: 2.6410605129773073

Epoch: 5| Step: 10
Training loss: 1.9545783777065013
Validation loss: 2.567598661024018

Epoch: 5| Step: 11
Training loss: 1.3008371518698312
Validation loss: 2.569382032432573

Epoch: 476| Step: 0
Training loss: 2.145206866125997
Validation loss: 2.5773209541440485

Epoch: 5| Step: 1
Training loss: 1.5719542769657295
Validation loss: 2.5522421274932214

Epoch: 5| Step: 2
Training loss: 1.3189313085946048
Validation loss: 2.5673010595322614

Epoch: 5| Step: 3
Training loss: 1.8286746250349803
Validation loss: 2.5531642506141403

Epoch: 5| Step: 4
Training loss: 1.6188893232444634
Validation loss: 2.572667396815502

Epoch: 5| Step: 5
Training loss: 2.4934941516698252
Validation loss: 2.533488092641564

Epoch: 5| Step: 6
Training loss: 2.3779511437045344
Validation loss: 2.540234237656034

Epoch: 5| Step: 7
Training loss: 1.8646841465923214
Validation loss: 2.579986351165598

Epoch: 5| Step: 8
Training loss: 1.7673973707648554
Validation loss: 2.5435556807720254

Epoch: 5| Step: 9
Training loss: 1.7432241050146005
Validation loss: 2.5636592041830886

Epoch: 5| Step: 10
Training loss: 1.47638535824618
Validation loss: 2.5852621374024554

Epoch: 5| Step: 11
Training loss: 1.4953537348340373
Validation loss: 2.5864024018103646

Epoch: 477| Step: 0
Training loss: 1.3728729615420814
Validation loss: 2.5798440115184973

Epoch: 5| Step: 1
Training loss: 1.8665329811499338
Validation loss: 2.6039158941960734

Epoch: 5| Step: 2
Training loss: 1.4644266984437104
Validation loss: 2.552939755253531

Epoch: 5| Step: 3
Training loss: 1.8601887949628322
Validation loss: 2.5581935152145263

Epoch: 5| Step: 4
Training loss: 1.5651478266748777
Validation loss: 2.5855400033488625

Epoch: 5| Step: 5
Training loss: 2.309610365667493
Validation loss: 2.584784678161755

Epoch: 5| Step: 6
Training loss: 2.056750983803095
Validation loss: 2.5784745104687943

Epoch: 5| Step: 7
Training loss: 2.0002238625171698
Validation loss: 2.558254565016273

Epoch: 5| Step: 8
Training loss: 1.2016225574103105
Validation loss: 2.5992434860595

Epoch: 5| Step: 9
Training loss: 2.258413056752929
Validation loss: 2.5801076836809536

Epoch: 5| Step: 10
Training loss: 2.2648217191279305
Validation loss: 2.5883088624423407

Epoch: 5| Step: 11
Training loss: 2.579435905327202
Validation loss: 2.5785375245787296

Epoch: 478| Step: 0
Training loss: 1.6391709196381052
Validation loss: 2.582255116663503

Epoch: 5| Step: 1
Training loss: 1.6257219178180802
Validation loss: 2.582471758979479

Epoch: 5| Step: 2
Training loss: 1.3744729072145916
Validation loss: 2.6490051913920367

Epoch: 5| Step: 3
Training loss: 1.7880330684727357
Validation loss: 2.653002556475488

Epoch: 5| Step: 4
Training loss: 2.2789157787459877
Validation loss: 2.616186954682169

Epoch: 5| Step: 5
Training loss: 1.6266999522826788
Validation loss: 2.602410603037404

Epoch: 5| Step: 6
Training loss: 1.855066581106987
Validation loss: 2.5693526519382512

Epoch: 5| Step: 7
Training loss: 2.581407434128309
Validation loss: 2.568775211993242

Epoch: 5| Step: 8
Training loss: 2.0525272747648358
Validation loss: 2.6089644308937117

Epoch: 5| Step: 9
Training loss: 1.7651600858584713
Validation loss: 2.5623573092918686

Epoch: 5| Step: 10
Training loss: 1.9076274835225306
Validation loss: 2.536870164486767

Epoch: 5| Step: 11
Training loss: 1.5154974972293014
Validation loss: 2.5512968499334825

Epoch: 479| Step: 0
Training loss: 3.190343448721592
Validation loss: 2.503932750400988

Epoch: 5| Step: 1
Training loss: 1.7268089705389078
Validation loss: 2.5088022958563134

Epoch: 5| Step: 2
Training loss: 1.8345807195721797
Validation loss: 2.52302167161007

Epoch: 5| Step: 3
Training loss: 1.8795284264178849
Validation loss: 2.5298297315875944

Epoch: 5| Step: 4
Training loss: 1.9271749594960668
Validation loss: 2.542329804623295

Epoch: 5| Step: 5
Training loss: 1.8810307473200116
Validation loss: 2.5409108247092926

Epoch: 5| Step: 6
Training loss: 1.8266087300215508
Validation loss: 2.5650837092221224

Epoch: 5| Step: 7
Training loss: 1.9287662546458098
Validation loss: 2.5488813294841637

Epoch: 5| Step: 8
Training loss: 1.1497092957645667
Validation loss: 2.5418997381523067

Epoch: 5| Step: 9
Training loss: 1.5053008511983272
Validation loss: 2.54944504717296

Epoch: 5| Step: 10
Training loss: 2.3458554792516337
Validation loss: 2.5440533068987947

Epoch: 5| Step: 11
Training loss: 1.0251087782289978
Validation loss: 2.5787042140548

Epoch: 480| Step: 0
Training loss: 2.4551870827179383
Validation loss: 2.547305958021058

Epoch: 5| Step: 1
Training loss: 1.4240916653179414
Validation loss: 2.569100622780467

Epoch: 5| Step: 2
Training loss: 1.7811393034151388
Validation loss: 2.5455604780564802

Epoch: 5| Step: 3
Training loss: 1.9176501225041256
Validation loss: 2.5771080284713777

Epoch: 5| Step: 4
Training loss: 1.8912136958357324
Validation loss: 2.548042427654441

Epoch: 5| Step: 5
Training loss: 1.7179620497201225
Validation loss: 2.5925332129928127

Epoch: 5| Step: 6
Training loss: 1.9432168726215655
Validation loss: 2.6305605674545074

Epoch: 5| Step: 7
Training loss: 1.4619158564513877
Validation loss: 2.623876906632408

Epoch: 5| Step: 8
Training loss: 2.5155575192327366
Validation loss: 2.5932624657438965

Epoch: 5| Step: 9
Training loss: 1.5702305862545791
Validation loss: 2.573627498571333

Epoch: 5| Step: 10
Training loss: 2.0487510877586583
Validation loss: 2.5763238182887505

Epoch: 5| Step: 11
Training loss: 1.2555456644745142
Validation loss: 2.5616942007135854

Epoch: 481| Step: 0
Training loss: 2.8539524044353346
Validation loss: 2.551130608726396

Epoch: 5| Step: 1
Training loss: 1.8968888233567247
Validation loss: 2.579401249429634

Epoch: 5| Step: 2
Training loss: 2.137180759616201
Validation loss: 2.5768906036837156

Epoch: 5| Step: 3
Training loss: 1.564076353272815
Validation loss: 2.566176436618376

Epoch: 5| Step: 4
Training loss: 1.9684412275110377
Validation loss: 2.575938467037685

Epoch: 5| Step: 5
Training loss: 1.8468569423870682
Validation loss: 2.536682335729574

Epoch: 5| Step: 6
Training loss: 1.6584906626436495
Validation loss: 2.5572849682773935

Epoch: 5| Step: 7
Training loss: 1.9405902705870497
Validation loss: 2.556884579133539

Epoch: 5| Step: 8
Training loss: 1.459383949399378
Validation loss: 2.564521701473997

Epoch: 5| Step: 9
Training loss: 1.3240468411558437
Validation loss: 2.565434795055574

Epoch: 5| Step: 10
Training loss: 1.3414505646305857
Validation loss: 2.629820768047276

Epoch: 5| Step: 11
Training loss: 2.3739599661147053
Validation loss: 2.5930827864438655

Epoch: 482| Step: 0
Training loss: 1.6042102791278405
Validation loss: 2.6180017390876795

Epoch: 5| Step: 1
Training loss: 2.048864198845316
Validation loss: 2.6596222694933846

Epoch: 5| Step: 2
Training loss: 1.639557045803
Validation loss: 2.6067135652443563

Epoch: 5| Step: 3
Training loss: 2.63926183061838
Validation loss: 2.560570649580544

Epoch: 5| Step: 4
Training loss: 2.04721113167733
Validation loss: 2.567321211679365

Epoch: 5| Step: 5
Training loss: 1.7529719865631193
Validation loss: 2.574575757367784

Epoch: 5| Step: 6
Training loss: 2.2258803008491936
Validation loss: 2.561896485692032

Epoch: 5| Step: 7
Training loss: 1.5424644708483064
Validation loss: 2.5695352664280917

Epoch: 5| Step: 8
Training loss: 1.2631413143412449
Validation loss: 2.5629544707985032

Epoch: 5| Step: 9
Training loss: 1.7022191009473502
Validation loss: 2.5506967800265974

Epoch: 5| Step: 10
Training loss: 1.4744820445077673
Validation loss: 2.5701883589459102

Epoch: 5| Step: 11
Training loss: 3.0881064989176177
Validation loss: 2.570395536926937

Epoch: 483| Step: 0
Training loss: 1.8661229758140823
Validation loss: 2.5934316370808492

Epoch: 5| Step: 1
Training loss: 2.42089114970918
Validation loss: 2.5817108109354865

Epoch: 5| Step: 2
Training loss: 1.3695133588876796
Validation loss: 2.6124422962867464

Epoch: 5| Step: 3
Training loss: 1.9011222787426614
Validation loss: 2.627200755722686

Epoch: 5| Step: 4
Training loss: 1.741183688837897
Validation loss: 2.6472348583711964

Epoch: 5| Step: 5
Training loss: 1.8549850315199543
Validation loss: 2.6805330764462645

Epoch: 5| Step: 6
Training loss: 1.925170244392534
Validation loss: 2.653819086310856

Epoch: 5| Step: 7
Training loss: 1.4968986238594464
Validation loss: 2.6733896189893827

Epoch: 5| Step: 8
Training loss: 1.7914273153897322
Validation loss: 2.665758214128495

Epoch: 5| Step: 9
Training loss: 2.0455519498887345
Validation loss: 2.6134439331265007

Epoch: 5| Step: 10
Training loss: 2.110546323729222
Validation loss: 2.5739163349903253

Epoch: 5| Step: 11
Training loss: 1.415396214201617
Validation loss: 2.5840672724529776

Epoch: 484| Step: 0
Training loss: 1.5695483877519518
Validation loss: 2.5451730802759664

Epoch: 5| Step: 1
Training loss: 2.006070342293909
Validation loss: 2.5242306749051764

Epoch: 5| Step: 2
Training loss: 2.343352220476347
Validation loss: 2.5368283345924856

Epoch: 5| Step: 3
Training loss: 1.682050807784251
Validation loss: 2.5744724447749263

Epoch: 5| Step: 4
Training loss: 1.2897771068341288
Validation loss: 2.5648440169397113

Epoch: 5| Step: 5
Training loss: 1.7084963728475766
Validation loss: 2.5448992502022176

Epoch: 5| Step: 6
Training loss: 1.700310157082978
Validation loss: 2.598889846256133

Epoch: 5| Step: 7
Training loss: 2.3132315844531797
Validation loss: 2.5616666361370926

Epoch: 5| Step: 8
Training loss: 1.7987843196476418
Validation loss: 2.526148089235007

Epoch: 5| Step: 9
Training loss: 1.6331802757068075
Validation loss: 2.5620674566845185

Epoch: 5| Step: 10
Training loss: 1.8724653277987804
Validation loss: 2.5569437856038486

Epoch: 5| Step: 11
Training loss: 1.6077916031824262
Validation loss: 2.566091896596428

Epoch: 485| Step: 0
Training loss: 2.2133807912970407
Validation loss: 2.5912509660462932

Epoch: 5| Step: 1
Training loss: 1.3139981393554148
Validation loss: 2.5842845547281685

Epoch: 5| Step: 2
Training loss: 1.687476546513088
Validation loss: 2.655653452736892

Epoch: 5| Step: 3
Training loss: 1.7606666282144408
Validation loss: 2.559100788535134

Epoch: 5| Step: 4
Training loss: 1.5886144736026253
Validation loss: 2.561776279968007

Epoch: 5| Step: 5
Training loss: 1.9374616065374406
Validation loss: 2.5039094913995306

Epoch: 5| Step: 6
Training loss: 2.578827733298086
Validation loss: 2.5137430540103005

Epoch: 5| Step: 7
Training loss: 1.4127471032518815
Validation loss: 2.5153620090794635

Epoch: 5| Step: 8
Training loss: 2.2072607950665333
Validation loss: 2.499199759039631

Epoch: 5| Step: 9
Training loss: 1.6789025180184063
Validation loss: 2.525240341714647

Epoch: 5| Step: 10
Training loss: 1.9161890167267155
Validation loss: 2.524670161053026

Epoch: 5| Step: 11
Training loss: 2.1724038337871767
Validation loss: 2.5492192968160823

Epoch: 486| Step: 0
Training loss: 1.9994057726243355
Validation loss: 2.496959426719316

Epoch: 5| Step: 1
Training loss: 1.807439777853643
Validation loss: 2.5549617390713486

Epoch: 5| Step: 2
Training loss: 2.410718756373867
Validation loss: 2.5612529263247743

Epoch: 5| Step: 3
Training loss: 1.6451579370018108
Validation loss: 2.566299443995741

Epoch: 5| Step: 4
Training loss: 2.3234544026132617
Validation loss: 2.5917580090665147

Epoch: 5| Step: 5
Training loss: 1.7591534056616207
Validation loss: 2.5844459111895692

Epoch: 5| Step: 6
Training loss: 2.007796350555189
Validation loss: 2.5788091811346305

Epoch: 5| Step: 7
Training loss: 1.5724633513093198
Validation loss: 2.5581444537512517

Epoch: 5| Step: 8
Training loss: 1.833315141183007
Validation loss: 2.5547372966738835

Epoch: 5| Step: 9
Training loss: 1.3964967953856535
Validation loss: 2.5707957848249463

Epoch: 5| Step: 10
Training loss: 1.4459881826949377
Validation loss: 2.547856837859711

Epoch: 5| Step: 11
Training loss: 1.0068831779578828
Validation loss: 2.5560469281679845

Epoch: 487| Step: 0
Training loss: 1.5385476427558364
Validation loss: 2.5563339426361833

Epoch: 5| Step: 1
Training loss: 1.5473670562187702
Validation loss: 2.5710223260365406

Epoch: 5| Step: 2
Training loss: 1.7967665929849508
Validation loss: 2.5441118553155793

Epoch: 5| Step: 3
Training loss: 2.1040882687709517
Validation loss: 2.5701606535577666

Epoch: 5| Step: 4
Training loss: 2.0187314956809024
Validation loss: 2.5685076729975034

Epoch: 5| Step: 5
Training loss: 2.3823346768927807
Validation loss: 2.5430701939222686

Epoch: 5| Step: 6
Training loss: 2.2520081777203944
Validation loss: 2.552774737894404

Epoch: 5| Step: 7
Training loss: 1.3262965013152
Validation loss: 2.589287385016092

Epoch: 5| Step: 8
Training loss: 1.6605187592496347
Validation loss: 2.601974416509279

Epoch: 5| Step: 9
Training loss: 1.7609313423164161
Validation loss: 2.6554432560130046

Epoch: 5| Step: 10
Training loss: 1.8657080882626094
Validation loss: 2.639444264032962

Epoch: 5| Step: 11
Training loss: 0.6905881060588835
Validation loss: 2.6526824667475952

Epoch: 488| Step: 0
Training loss: 1.811247096615525
Validation loss: 2.6383479192667543

Epoch: 5| Step: 1
Training loss: 1.6105221113826538
Validation loss: 2.6362026095603697

Epoch: 5| Step: 2
Training loss: 1.7258548580996596
Validation loss: 2.6085326887282476

Epoch: 5| Step: 3
Training loss: 1.4962634595426532
Validation loss: 2.607432074175638

Epoch: 5| Step: 4
Training loss: 1.4631688829935259
Validation loss: 2.619070448043131

Epoch: 5| Step: 5
Training loss: 1.7354624320502767
Validation loss: 2.592236084700229

Epoch: 5| Step: 6
Training loss: 1.9038760302199418
Validation loss: 2.57605462992042

Epoch: 5| Step: 7
Training loss: 2.0498647040403926
Validation loss: 2.5398614575181315

Epoch: 5| Step: 8
Training loss: 2.260510690260064
Validation loss: 2.5596416433855453

Epoch: 5| Step: 9
Training loss: 2.320860724113453
Validation loss: 2.57761327886188

Epoch: 5| Step: 10
Training loss: 1.5262151973171176
Validation loss: 2.5922248906617216

Epoch: 5| Step: 11
Training loss: 1.2803611463448819
Validation loss: 2.574015851049071

Epoch: 489| Step: 0
Training loss: 2.185439310844453
Validation loss: 2.580014805831368

Epoch: 5| Step: 1
Training loss: 1.8746542293892081
Validation loss: 2.5213504995061857

Epoch: 5| Step: 2
Training loss: 1.527191935065043
Validation loss: 2.570988223254516

Epoch: 5| Step: 3
Training loss: 1.4035921198582666
Validation loss: 2.5572888917512984

Epoch: 5| Step: 4
Training loss: 1.6839623280114866
Validation loss: 2.527175182320215

Epoch: 5| Step: 5
Training loss: 1.8987267042367082
Validation loss: 2.5267735839942844

Epoch: 5| Step: 6
Training loss: 2.0097553041599063
Validation loss: 2.5530425870458537

Epoch: 5| Step: 7
Training loss: 1.5107540236183885
Validation loss: 2.5507629066730733

Epoch: 5| Step: 8
Training loss: 2.080127411021148
Validation loss: 2.552276975071348

Epoch: 5| Step: 9
Training loss: 1.6822515036057084
Validation loss: 2.5957899842130345

Epoch: 5| Step: 10
Training loss: 1.8407628705601746
Validation loss: 2.638035281192923

Epoch: 5| Step: 11
Training loss: 2.9301139012613886
Validation loss: 2.6486390636340227

Epoch: 490| Step: 0
Training loss: 1.414524150541089
Validation loss: 2.640729890805484

Epoch: 5| Step: 1
Training loss: 2.3991876975919095
Validation loss: 2.6061527168480545

Epoch: 5| Step: 2
Training loss: 2.1843561741968625
Validation loss: 2.5960520693241453

Epoch: 5| Step: 3
Training loss: 2.1115474110654597
Validation loss: 2.5891454991458716

Epoch: 5| Step: 4
Training loss: 1.4419996905968027
Validation loss: 2.581361984951865

Epoch: 5| Step: 5
Training loss: 2.0383112316331755
Validation loss: 2.5967308518561385

Epoch: 5| Step: 6
Training loss: 1.3632653790181337
Validation loss: 2.564552365252157

Epoch: 5| Step: 7
Training loss: 2.0125683222007344
Validation loss: 2.5926002765502543

Epoch: 5| Step: 8
Training loss: 1.7325588030283208
Validation loss: 2.616325684418831

Epoch: 5| Step: 9
Training loss: 1.6933481816644542
Validation loss: 2.5736099240988297

Epoch: 5| Step: 10
Training loss: 1.3935752177447067
Validation loss: 2.6091615433481707

Epoch: 5| Step: 11
Training loss: 1.2047850810506482
Validation loss: 2.593045755706215

Epoch: 491| Step: 0
Training loss: 1.5811679321221808
Validation loss: 2.598451841509389

Epoch: 5| Step: 1
Training loss: 1.2103907181305131
Validation loss: 2.5917775187647556

Epoch: 5| Step: 2
Training loss: 1.8182385462884418
Validation loss: 2.5815535241431857

Epoch: 5| Step: 3
Training loss: 1.248449556103909
Validation loss: 2.572775977196838

Epoch: 5| Step: 4
Training loss: 1.722788695349625
Validation loss: 2.563840034995708

Epoch: 5| Step: 5
Training loss: 2.0609261258659552
Validation loss: 2.558627276407203

Epoch: 5| Step: 6
Training loss: 1.9017598158712297
Validation loss: 2.5608018543999496

Epoch: 5| Step: 7
Training loss: 2.09910490851009
Validation loss: 2.561562002058711

Epoch: 5| Step: 8
Training loss: 1.9907598428852933
Validation loss: 2.5543791325262477

Epoch: 5| Step: 9
Training loss: 2.64094478318638
Validation loss: 2.593357485443789

Epoch: 5| Step: 10
Training loss: 1.6003247944665557
Validation loss: 2.6170272512388473

Epoch: 5| Step: 11
Training loss: 1.7364924796106618
Validation loss: 2.6862566903446528

Epoch: 492| Step: 0
Training loss: 2.221576877772304
Validation loss: 2.6953721339313685

Epoch: 5| Step: 1
Training loss: 2.001952648627992
Validation loss: 2.657997547564967

Epoch: 5| Step: 2
Training loss: 1.3752311598931921
Validation loss: 2.6415355060659853

Epoch: 5| Step: 3
Training loss: 2.0187600764445333
Validation loss: 2.6027851496539713

Epoch: 5| Step: 4
Training loss: 1.4671031566097863
Validation loss: 2.57642538902245

Epoch: 5| Step: 5
Training loss: 0.972200371103112
Validation loss: 2.5753284738652638

Epoch: 5| Step: 6
Training loss: 2.14130541157996
Validation loss: 2.5556069565581754

Epoch: 5| Step: 7
Training loss: 2.1144111701020787
Validation loss: 2.5998086067204365

Epoch: 5| Step: 8
Training loss: 1.615852578992698
Validation loss: 2.5846512698721082

Epoch: 5| Step: 9
Training loss: 1.883239064628343
Validation loss: 2.618424334946907

Epoch: 5| Step: 10
Training loss: 2.232233795493411
Validation loss: 2.57947815150173

Epoch: 5| Step: 11
Training loss: 1.4574635046026145
Validation loss: 2.5770510623446072

Epoch: 493| Step: 0
Training loss: 1.4242496154420377
Validation loss: 2.5545534298992996

Epoch: 5| Step: 1
Training loss: 1.4668456372969947
Validation loss: 2.541159115335904

Epoch: 5| Step: 2
Training loss: 1.2476607368593984
Validation loss: 2.5400367491390257

Epoch: 5| Step: 3
Training loss: 2.418739405566924
Validation loss: 2.5211516775673894

Epoch: 5| Step: 4
Training loss: 1.5383354057361425
Validation loss: 2.5377735798499104

Epoch: 5| Step: 5
Training loss: 1.7775381128702414
Validation loss: 2.5709200240614223

Epoch: 5| Step: 6
Training loss: 2.0175452732834858
Validation loss: 2.5371534164087057

Epoch: 5| Step: 7
Training loss: 2.1758257383664237
Validation loss: 2.594382300921455

Epoch: 5| Step: 8
Training loss: 1.7951441514089526
Validation loss: 2.597014536744822

Epoch: 5| Step: 9
Training loss: 1.6702943977538351
Validation loss: 2.624403802589945

Epoch: 5| Step: 10
Training loss: 1.9656728887258434
Validation loss: 2.678252797173054

Epoch: 5| Step: 11
Training loss: 2.2662306403602472
Validation loss: 2.6554261107920034

Epoch: 494| Step: 0
Training loss: 1.8151753510610174
Validation loss: 2.5913232017399093

Epoch: 5| Step: 1
Training loss: 1.6833152452132834
Validation loss: 2.577032046371803

Epoch: 5| Step: 2
Training loss: 2.4111755293147996
Validation loss: 2.5497868864912965

Epoch: 5| Step: 3
Training loss: 2.512976822278284
Validation loss: 2.5531186177280176

Epoch: 5| Step: 4
Training loss: 2.1777669998256894
Validation loss: 2.5761048272320193

Epoch: 5| Step: 5
Training loss: 2.1938514055686578
Validation loss: 2.52495076065398

Epoch: 5| Step: 6
Training loss: 2.062314343043738
Validation loss: 2.611976301521918

Epoch: 5| Step: 7
Training loss: 1.4622427265770934
Validation loss: 2.6025635718741653

Epoch: 5| Step: 8
Training loss: 1.727990297996694
Validation loss: 2.6265154997557514

Epoch: 5| Step: 9
Training loss: 1.7529502251147169
Validation loss: 2.6973603434762077

Epoch: 5| Step: 10
Training loss: 1.814637929253458
Validation loss: 2.6552312468094668

Epoch: 5| Step: 11
Training loss: 1.825077810327047
Validation loss: 2.6632925955203524

Epoch: 495| Step: 0
Training loss: 2.206990415482306
Validation loss: 2.6400877802998712

Epoch: 5| Step: 1
Training loss: 1.9927998517947945
Validation loss: 2.6213809262056924

Epoch: 5| Step: 2
Training loss: 1.518154668097984
Validation loss: 2.5739928220205694

Epoch: 5| Step: 3
Training loss: 1.693991854246117
Validation loss: 2.608392465751931

Epoch: 5| Step: 4
Training loss: 1.9441351947398169
Validation loss: 2.5900970841405613

Epoch: 5| Step: 5
Training loss: 1.862886718950678
Validation loss: 2.5690010922638624

Epoch: 5| Step: 6
Training loss: 1.9559949617223464
Validation loss: 2.602633235866516

Epoch: 5| Step: 7
Training loss: 1.416418820560514
Validation loss: 2.5798830222809057

Epoch: 5| Step: 8
Training loss: 2.065267844205818
Validation loss: 2.5680332919633657

Epoch: 5| Step: 9
Training loss: 2.2108789442955366
Validation loss: 2.5371896262687965

Epoch: 5| Step: 10
Training loss: 1.5404375778621062
Validation loss: 2.5713052233593663

Epoch: 5| Step: 11
Training loss: 1.2299961696348019
Validation loss: 2.5512984230072613

Epoch: 496| Step: 0
Training loss: 1.0944192746028056
Validation loss: 2.610348700642994

Epoch: 5| Step: 1
Training loss: 1.817726951292453
Validation loss: 2.601308476109901

Epoch: 5| Step: 2
Training loss: 1.8434098140010393
Validation loss: 2.617433456706344

Epoch: 5| Step: 3
Training loss: 2.086109740043333
Validation loss: 2.580243167223682

Epoch: 5| Step: 4
Training loss: 1.9374460397404951
Validation loss: 2.6170964125539378

Epoch: 5| Step: 5
Training loss: 1.6086102492684526
Validation loss: 2.5698826671044177

Epoch: 5| Step: 6
Training loss: 2.260535792245653
Validation loss: 2.581254135202416

Epoch: 5| Step: 7
Training loss: 1.6300418106520693
Validation loss: 2.5551703227207367

Epoch: 5| Step: 8
Training loss: 1.4771404447216985
Validation loss: 2.5853447979188733

Epoch: 5| Step: 9
Training loss: 2.075350178044956
Validation loss: 2.5782182079381952

Epoch: 5| Step: 10
Training loss: 1.7219093416254463
Validation loss: 2.562994269641836

Epoch: 5| Step: 11
Training loss: 2.7852663336743064
Validation loss: 2.6010405443581472

Epoch: 497| Step: 0
Training loss: 1.2998503140323796
Validation loss: 2.5582813489604788

Epoch: 5| Step: 1
Training loss: 1.787039600114992
Validation loss: 2.578280569449842

Epoch: 5| Step: 2
Training loss: 2.0520413260509156
Validation loss: 2.6165444869979515

Epoch: 5| Step: 3
Training loss: 1.6912919990416613
Validation loss: 2.5891888089047117

Epoch: 5| Step: 4
Training loss: 1.6529803120801632
Validation loss: 2.571062529335807

Epoch: 5| Step: 5
Training loss: 1.9491219964792927
Validation loss: 2.5724590830272125

Epoch: 5| Step: 6
Training loss: 1.0146165976792687
Validation loss: 2.578668225018518

Epoch: 5| Step: 7
Training loss: 2.41052886209417
Validation loss: 2.5198749790766595

Epoch: 5| Step: 8
Training loss: 2.1603640685733874
Validation loss: 2.5373551090886

Epoch: 5| Step: 9
Training loss: 1.651430423186806
Validation loss: 2.5252187050315102

Epoch: 5| Step: 10
Training loss: 1.9076524797043468
Validation loss: 2.5464708791633512

Epoch: 5| Step: 11
Training loss: 1.7109034983422204
Validation loss: 2.576427891416907

Epoch: 498| Step: 0
Training loss: 1.83405873368293
Validation loss: 2.597751560231394

Epoch: 5| Step: 1
Training loss: 2.090236619760288
Validation loss: 2.5727320552083097

Epoch: 5| Step: 2
Training loss: 1.6941627084085684
Validation loss: 2.5435519040553918

Epoch: 5| Step: 3
Training loss: 2.3329530360616433
Validation loss: 2.55407758503491

Epoch: 5| Step: 4
Training loss: 1.7071526176552116
Validation loss: 2.558252982628774

Epoch: 5| Step: 5
Training loss: 1.688522523571069
Validation loss: 2.5661853790074995

Epoch: 5| Step: 6
Training loss: 1.6594660502308858
Validation loss: 2.5692359617784595

Epoch: 5| Step: 7
Training loss: 1.7155313351603678
Validation loss: 2.5559830136764496

Epoch: 5| Step: 8
Training loss: 1.4654409589897055
Validation loss: 2.5668762875908144

Epoch: 5| Step: 9
Training loss: 2.1392411262601883
Validation loss: 2.5917095714852807

Epoch: 5| Step: 10
Training loss: 1.4658326739985097
Validation loss: 2.5983212224589587

Epoch: 5| Step: 11
Training loss: 1.2684705793000983
Validation loss: 2.5833207650545447

Epoch: 499| Step: 0
Training loss: 1.7051652359531249
Validation loss: 2.5646718675922435

Epoch: 5| Step: 1
Training loss: 1.7841442085835144
Validation loss: 2.5928750534882723

Epoch: 5| Step: 2
Training loss: 1.4983070674768
Validation loss: 2.5863538792924827

Epoch: 5| Step: 3
Training loss: 1.5347945779781693
Validation loss: 2.5305888996295653

Epoch: 5| Step: 4
Training loss: 2.0691746301865193
Validation loss: 2.5356423372900356

Epoch: 5| Step: 5
Training loss: 1.1789484803944736
Validation loss: 2.547356678946413

Epoch: 5| Step: 6
Training loss: 1.8446735719791194
Validation loss: 2.555493265639067

Epoch: 5| Step: 7
Training loss: 1.9921700869528514
Validation loss: 2.560452166332683

Epoch: 5| Step: 8
Training loss: 1.4045488028109023
Validation loss: 2.530395909236864

Epoch: 5| Step: 9
Training loss: 2.0622447462788425
Validation loss: 2.50754081783497

Epoch: 5| Step: 10
Training loss: 2.1579077056720313
Validation loss: 2.5438883632892306

Epoch: 5| Step: 11
Training loss: 2.6141949754016593
Validation loss: 2.535758904455342

Epoch: 500| Step: 0
Training loss: 1.7868174496883396
Validation loss: 2.6460778631516737

Epoch: 5| Step: 1
Training loss: 1.7694798476814333
Validation loss: 2.641568205429505

Epoch: 5| Step: 2
Training loss: 2.10868100653247
Validation loss: 2.6638436474591978

Epoch: 5| Step: 3
Training loss: 1.6426717434398013
Validation loss: 2.653994661164346

Epoch: 5| Step: 4
Training loss: 2.0143771781755744
Validation loss: 2.618701034094181

Epoch: 5| Step: 5
Training loss: 1.584011468055903
Validation loss: 2.6228108663230794

Epoch: 5| Step: 6
Training loss: 2.112857120281416
Validation loss: 2.5896315912080974

Epoch: 5| Step: 7
Training loss: 2.1445093483840068
Validation loss: 2.581503348121341

Epoch: 5| Step: 8
Training loss: 1.2564869405763792
Validation loss: 2.560526576423642

Epoch: 5| Step: 9
Training loss: 1.8389193081268569
Validation loss: 2.555987728129235

Epoch: 5| Step: 10
Training loss: 1.515175506950932
Validation loss: 2.559732910565035

Epoch: 5| Step: 11
Training loss: 2.317593712419139
Validation loss: 2.5665399467213996

Testing loss: 2.2149415227346303
