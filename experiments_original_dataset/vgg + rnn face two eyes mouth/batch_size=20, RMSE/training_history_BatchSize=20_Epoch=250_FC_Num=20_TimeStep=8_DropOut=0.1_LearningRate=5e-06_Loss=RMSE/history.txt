Epoch: 1| Step: 0
Training loss: 6.387618796481218
Validation loss: 5.87661138039366

Epoch: 5| Step: 1
Training loss: 5.457179095505289
Validation loss: 5.874728812052789

Epoch: 5| Step: 2
Training loss: 6.256956577700885
Validation loss: 5.872863272750902

Epoch: 5| Step: 3
Training loss: 5.9528673972316435
Validation loss: 5.871129499247483

Epoch: 5| Step: 4
Training loss: 5.645421575004074
Validation loss: 5.869206026699872

Epoch: 5| Step: 5
Training loss: 5.491147807051965
Validation loss: 5.86725448116397

Epoch: 5| Step: 6
Training loss: 5.689080322707079
Validation loss: 5.865453742454947

Epoch: 5| Step: 7
Training loss: 6.276138275373746
Validation loss: 5.8634183504636015

Epoch: 5| Step: 8
Training loss: 5.625219213664675
Validation loss: 5.8613081121055375

Epoch: 5| Step: 9
Training loss: 6.351280816132372
Validation loss: 5.859075465705371

Epoch: 5| Step: 10
Training loss: 6.224184661538227
Validation loss: 5.856952468228932

Epoch: 5| Step: 11
Training loss: 7.551372064880385
Validation loss: 5.854626039104862

Epoch: 2| Step: 0
Training loss: 6.500573353055639
Validation loss: 5.852268504056784

Epoch: 5| Step: 1
Training loss: 5.589847332775319
Validation loss: 5.8497180213242705

Epoch: 5| Step: 2
Training loss: 6.243172540394877
Validation loss: 5.847134974843847

Epoch: 5| Step: 3
Training loss: 5.607068791130246
Validation loss: 5.844355954663507

Epoch: 5| Step: 4
Training loss: 5.192662255769215
Validation loss: 5.8415478791781235

Epoch: 5| Step: 5
Training loss: 6.0680884333624725
Validation loss: 5.838613295874302

Epoch: 5| Step: 6
Training loss: 5.930398649611217
Validation loss: 5.835715061971888

Epoch: 5| Step: 7
Training loss: 6.062800449123216
Validation loss: 5.832369474979943

Epoch: 5| Step: 8
Training loss: 6.195298953721004
Validation loss: 5.829138387302882

Epoch: 5| Step: 9
Training loss: 6.186370129932534
Validation loss: 5.8257199831604005

Epoch: 5| Step: 10
Training loss: 5.961634044022957
Validation loss: 5.821787520533072

Epoch: 5| Step: 11
Training loss: 5.126115258917329
Validation loss: 5.817984901987372

Epoch: 3| Step: 0
Training loss: 6.14425932130325
Validation loss: 5.813945105239828

Epoch: 5| Step: 1
Training loss: 5.8596816326016565
Validation loss: 5.809538739793459

Epoch: 5| Step: 2
Training loss: 5.996677432401336
Validation loss: 5.805188232292157

Epoch: 5| Step: 3
Training loss: 6.383768371949987
Validation loss: 5.800662336404354

Epoch: 5| Step: 4
Training loss: 6.21302293998134
Validation loss: 5.795455361205852

Epoch: 5| Step: 5
Training loss: 6.07060565019711
Validation loss: 5.790389889924221

Epoch: 5| Step: 6
Training loss: 6.435822203423742
Validation loss: 5.7846706202865255

Epoch: 5| Step: 7
Training loss: 6.068883307865804
Validation loss: 5.778992261870084

Epoch: 5| Step: 8
Training loss: 5.256188877398964
Validation loss: 5.7729420946218095

Epoch: 5| Step: 9
Training loss: 5.082287018868876
Validation loss: 5.766684464976604

Epoch: 5| Step: 10
Training loss: 5.220255925712038
Validation loss: 5.76015156095062

Epoch: 5| Step: 11
Training loss: 6.087858041499265
Validation loss: 5.753828874746709

Epoch: 4| Step: 0
Training loss: 4.37654195587991
Validation loss: 5.746878827280274

Epoch: 5| Step: 1
Training loss: 6.4558761680478325
Validation loss: 5.739971960056859

Epoch: 5| Step: 2
Training loss: 5.626096152418635
Validation loss: 5.73252644830706

Epoch: 5| Step: 3
Training loss: 6.097655624399391
Validation loss: 5.725452768337699

Epoch: 5| Step: 4
Training loss: 5.718389114082618
Validation loss: 5.71733341147265

Epoch: 5| Step: 5
Training loss: 5.628875584091952
Validation loss: 5.709568372714867

Epoch: 5| Step: 6
Training loss: 5.937930764082148
Validation loss: 5.7014882774327305

Epoch: 5| Step: 7
Training loss: 5.81424088198033
Validation loss: 5.693010252973217

Epoch: 5| Step: 8
Training loss: 6.665306270399182
Validation loss: 5.684427828942599

Epoch: 5| Step: 9
Training loss: 5.740274912667341
Validation loss: 5.675958233791436

Epoch: 5| Step: 10
Training loss: 5.460460199936702
Validation loss: 5.667231498879114

Epoch: 5| Step: 11
Training loss: 6.891073406966096
Validation loss: 5.658712851990383

Epoch: 5| Step: 0
Training loss: 6.1515540787859875
Validation loss: 5.64986012378492

Epoch: 5| Step: 1
Training loss: 5.858242403557392
Validation loss: 5.641018143159267

Epoch: 5| Step: 2
Training loss: 5.537364274335711
Validation loss: 5.632184082192766

Epoch: 5| Step: 3
Training loss: 5.2500504990828345
Validation loss: 5.623072456424458

Epoch: 5| Step: 4
Training loss: 6.6997719227701085
Validation loss: 5.614717693054113

Epoch: 5| Step: 5
Training loss: 5.982116751217357
Validation loss: 5.605925935007152

Epoch: 5| Step: 6
Training loss: 5.748509089362935
Validation loss: 5.597081085846799

Epoch: 5| Step: 7
Training loss: 5.491885528293883
Validation loss: 5.588351367034318

Epoch: 5| Step: 8
Training loss: 5.364295946836735
Validation loss: 5.579490352050815

Epoch: 5| Step: 9
Training loss: 5.717888105303008
Validation loss: 5.570828721076161

Epoch: 5| Step: 10
Training loss: 4.997538532911923
Validation loss: 5.561712109204136

Epoch: 5| Step: 11
Training loss: 5.595753231123832
Validation loss: 5.552828528211701

Epoch: 6| Step: 0
Training loss: 6.2820549444390545
Validation loss: 5.543732783804406

Epoch: 5| Step: 1
Training loss: 6.0398498258805615
Validation loss: 5.534857240011483

Epoch: 5| Step: 2
Training loss: 5.185528300049123
Validation loss: 5.525768192965639

Epoch: 5| Step: 3
Training loss: 4.803232955960353
Validation loss: 5.516957792896339

Epoch: 5| Step: 4
Training loss: 5.356837614536736
Validation loss: 5.508057241210255

Epoch: 5| Step: 5
Training loss: 5.852324208288192
Validation loss: 5.499964439392727

Epoch: 5| Step: 6
Training loss: 6.4634292023060524
Validation loss: 5.491373977714643

Epoch: 5| Step: 7
Training loss: 5.048755779522778
Validation loss: 5.48327830073482

Epoch: 5| Step: 8
Training loss: 5.633439070181401
Validation loss: 5.474638096070253

Epoch: 5| Step: 9
Training loss: 5.702097510182108
Validation loss: 5.466346452316979

Epoch: 5| Step: 10
Training loss: 4.888857781186019
Validation loss: 5.457783688348047

Epoch: 5| Step: 11
Training loss: 6.885065928734276
Validation loss: 5.449539689214637

Epoch: 7| Step: 0
Training loss: 5.050295400005759
Validation loss: 5.441101547659345

Epoch: 5| Step: 1
Training loss: 5.447661277761017
Validation loss: 5.4327198809501125

Epoch: 5| Step: 2
Training loss: 6.590818214387909
Validation loss: 5.423956868016608

Epoch: 5| Step: 3
Training loss: 5.317716662642942
Validation loss: 5.415517555516655

Epoch: 5| Step: 4
Training loss: 5.501657409629364
Validation loss: 5.407110943165851

Epoch: 5| Step: 5
Training loss: 5.423706800610112
Validation loss: 5.39909498642971

Epoch: 5| Step: 6
Training loss: 5.418191587545212
Validation loss: 5.390671491192088

Epoch: 5| Step: 7
Training loss: 5.7040486463101505
Validation loss: 5.38271150461946

Epoch: 5| Step: 8
Training loss: 5.3269927759968345
Validation loss: 5.374915883788539

Epoch: 5| Step: 9
Training loss: 5.547091455668792
Validation loss: 5.366924036954856

Epoch: 5| Step: 10
Training loss: 5.5297956548258504
Validation loss: 5.359061748221266

Epoch: 5| Step: 11
Training loss: 3.9810197652840196
Validation loss: 5.351568016921863

Epoch: 8| Step: 0
Training loss: 5.5468626210249194
Validation loss: 5.343915784320242

Epoch: 5| Step: 1
Training loss: 5.828730738356652
Validation loss: 5.336644868148961

Epoch: 5| Step: 2
Training loss: 4.737671966249883
Validation loss: 5.329211350831018

Epoch: 5| Step: 3
Training loss: 4.985682396741859
Validation loss: 5.321631762354967

Epoch: 5| Step: 4
Training loss: 5.9229857678787425
Validation loss: 5.314574476130258

Epoch: 5| Step: 5
Training loss: 5.34098771293811
Validation loss: 5.307120423054698

Epoch: 5| Step: 6
Training loss: 5.275531991464818
Validation loss: 5.300430964696097

Epoch: 5| Step: 7
Training loss: 5.417684293181538
Validation loss: 5.293137566195748

Epoch: 5| Step: 8
Training loss: 5.76861478206911
Validation loss: 5.285937664781088

Epoch: 5| Step: 9
Training loss: 4.985062793883339
Validation loss: 5.278689243293102

Epoch: 5| Step: 10
Training loss: 5.526140514739692
Validation loss: 5.27190269458418

Epoch: 5| Step: 11
Training loss: 6.545582500324527
Validation loss: 5.2652768285029286

Epoch: 9| Step: 0
Training loss: 5.452399700209507
Validation loss: 5.258206372106188

Epoch: 5| Step: 1
Training loss: 4.933965262758883
Validation loss: 5.251580530249362

Epoch: 5| Step: 2
Training loss: 5.743937738150205
Validation loss: 5.245125149754146

Epoch: 5| Step: 3
Training loss: 5.155318852358447
Validation loss: 5.238369858703729

Epoch: 5| Step: 4
Training loss: 4.398705699596762
Validation loss: 5.231989978576049

Epoch: 5| Step: 5
Training loss: 5.538733640735721
Validation loss: 5.225781118604236

Epoch: 5| Step: 6
Training loss: 6.043225983839099
Validation loss: 5.219247059554921

Epoch: 5| Step: 7
Training loss: 5.300927156648426
Validation loss: 5.213119637108833

Epoch: 5| Step: 8
Training loss: 5.347898423456398
Validation loss: 5.206574839959776

Epoch: 5| Step: 9
Training loss: 5.294557857910951
Validation loss: 5.200283362847577

Epoch: 5| Step: 10
Training loss: 5.638973765786252
Validation loss: 5.193825920642625

Epoch: 5| Step: 11
Training loss: 4.2698535570677025
Validation loss: 5.1873894721822635

Epoch: 10| Step: 0
Training loss: 4.748765283024298
Validation loss: 5.18114728193078

Epoch: 5| Step: 1
Training loss: 5.463992419951111
Validation loss: 5.175582102657033

Epoch: 5| Step: 2
Training loss: 5.484956802851814
Validation loss: 5.169241650656731

Epoch: 5| Step: 3
Training loss: 5.599468355828071
Validation loss: 5.162776430994302

Epoch: 5| Step: 4
Training loss: 5.598620292453949
Validation loss: 5.1564036182678015

Epoch: 5| Step: 5
Training loss: 4.785167012105244
Validation loss: 5.1490372967811755

Epoch: 5| Step: 6
Training loss: 4.5842460879433835
Validation loss: 5.142795046741776

Epoch: 5| Step: 7
Training loss: 5.301647095886455
Validation loss: 5.13595228774299

Epoch: 5| Step: 8
Training loss: 5.969149431374794
Validation loss: 5.129945020808621

Epoch: 5| Step: 9
Training loss: 5.108340097311913
Validation loss: 5.122857638475732

Epoch: 5| Step: 10
Training loss: 5.396385056654825
Validation loss: 5.116567299413305

Epoch: 5| Step: 11
Training loss: 4.058135284876102
Validation loss: 5.110258175797108

Epoch: 11| Step: 0
Training loss: 5.318101868995523
Validation loss: 5.104138240605303

Epoch: 5| Step: 1
Training loss: 5.176361995720758
Validation loss: 5.0978104725159445

Epoch: 5| Step: 2
Training loss: 4.724986622301974
Validation loss: 5.092140302256946

Epoch: 5| Step: 3
Training loss: 5.6911197084911995
Validation loss: 5.086280139294109

Epoch: 5| Step: 4
Training loss: 5.835786503443176
Validation loss: 5.080584269976003

Epoch: 5| Step: 5
Training loss: 5.001077345175413
Validation loss: 5.074602934301494

Epoch: 5| Step: 6
Training loss: 5.489308455918537
Validation loss: 5.069301408407476

Epoch: 5| Step: 7
Training loss: 4.500888736701454
Validation loss: 5.063135978405235

Epoch: 5| Step: 8
Training loss: 4.332489127064581
Validation loss: 5.057074932740866

Epoch: 5| Step: 9
Training loss: 5.6783161842856815
Validation loss: 5.051607863347106

Epoch: 5| Step: 10
Training loss: 5.078441433951099
Validation loss: 5.045232090093148

Epoch: 5| Step: 11
Training loss: 5.7736231628215515
Validation loss: 5.04031192558557

Epoch: 12| Step: 0
Training loss: 5.191892120380859
Validation loss: 5.033309783417301

Epoch: 5| Step: 1
Training loss: 5.245027639718045
Validation loss: 5.027999270052415

Epoch: 5| Step: 2
Training loss: 4.429696757527253
Validation loss: 5.0207787691478085

Epoch: 5| Step: 3
Training loss: 4.783062360755398
Validation loss: 5.014039372269661

Epoch: 5| Step: 4
Training loss: 5.984492288341489
Validation loss: 5.00634644979402

Epoch: 5| Step: 5
Training loss: 4.936202252935425
Validation loss: 4.996051556506233

Epoch: 5| Step: 6
Training loss: 4.68902685094017
Validation loss: 4.986532328401757

Epoch: 5| Step: 7
Training loss: 5.22134042739646
Validation loss: 4.977807305003382

Epoch: 5| Step: 8
Training loss: 4.922701908463465
Validation loss: 4.970669237782021

Epoch: 5| Step: 9
Training loss: 5.253321550585189
Validation loss: 4.964483512657148

Epoch: 5| Step: 10
Training loss: 5.328155070021452
Validation loss: 4.958047220112187

Epoch: 5| Step: 11
Training loss: 5.903046884822622
Validation loss: 4.950385385981765

Epoch: 13| Step: 0
Training loss: 5.67165304963462
Validation loss: 4.945442893030256

Epoch: 5| Step: 1
Training loss: 4.5836200740013435
Validation loss: 4.938188770395657

Epoch: 5| Step: 2
Training loss: 6.052712946678752
Validation loss: 4.933315507860885

Epoch: 5| Step: 3
Training loss: 4.593725502831153
Validation loss: 4.9226035250033915

Epoch: 5| Step: 4
Training loss: 5.086706428589074
Validation loss: 4.915166652980616

Epoch: 5| Step: 5
Training loss: 4.208617298378291
Validation loss: 4.90854140954064

Epoch: 5| Step: 6
Training loss: 5.447705568073673
Validation loss: 4.902745487525854

Epoch: 5| Step: 7
Training loss: 4.421091178735558
Validation loss: 4.89720419771442

Epoch: 5| Step: 8
Training loss: 5.382343687063641
Validation loss: 4.891233599315443

Epoch: 5| Step: 9
Training loss: 4.593312560552642
Validation loss: 4.884647401001593

Epoch: 5| Step: 10
Training loss: 5.020744396809671
Validation loss: 4.878670956812436

Epoch: 5| Step: 11
Training loss: 5.017461422713479
Validation loss: 4.872894199097195

Epoch: 14| Step: 0
Training loss: 3.719551320653815
Validation loss: 4.867985920658193

Epoch: 5| Step: 1
Training loss: 4.928174640644981
Validation loss: 4.863226906346412

Epoch: 5| Step: 2
Training loss: 5.22005533123288
Validation loss: 4.858932368653425

Epoch: 5| Step: 3
Training loss: 4.671049625630468
Validation loss: 4.8528887112932635

Epoch: 5| Step: 4
Training loss: 5.54557643250456
Validation loss: 4.847521136314685

Epoch: 5| Step: 5
Training loss: 5.424039293298771
Validation loss: 4.842313327818269

Epoch: 5| Step: 6
Training loss: 6.114088966708144
Validation loss: 4.836763943014477

Epoch: 5| Step: 7
Training loss: 4.032279895846426
Validation loss: 4.8317960179727875

Epoch: 5| Step: 8
Training loss: 4.441395728535801
Validation loss: 4.8266135507281405

Epoch: 5| Step: 9
Training loss: 4.97685492358577
Validation loss: 4.82183143759214

Epoch: 5| Step: 10
Training loss: 4.946721989475668
Validation loss: 4.816838550580685

Epoch: 5| Step: 11
Training loss: 5.671057776223897
Validation loss: 4.811679266430953

Epoch: 15| Step: 0
Training loss: 5.345264064164596
Validation loss: 4.806441609730511

Epoch: 5| Step: 1
Training loss: 4.519085360121607
Validation loss: 4.801742916770673

Epoch: 5| Step: 2
Training loss: 4.693210632786597
Validation loss: 4.796856792137887

Epoch: 5| Step: 3
Training loss: 4.2422396549510335
Validation loss: 4.791568011498375

Epoch: 5| Step: 4
Training loss: 5.085035862378916
Validation loss: 4.787145117744683

Epoch: 5| Step: 5
Training loss: 4.5387471232277745
Validation loss: 4.781644459993411

Epoch: 5| Step: 6
Training loss: 5.17027806639193
Validation loss: 4.7773661411495745

Epoch: 5| Step: 7
Training loss: 4.983133286933702
Validation loss: 4.771478362254663

Epoch: 5| Step: 8
Training loss: 4.845574213886345
Validation loss: 4.766620252734519

Epoch: 5| Step: 9
Training loss: 4.914068128039802
Validation loss: 4.762221700191445

Epoch: 5| Step: 10
Training loss: 5.236898514252877
Validation loss: 4.757251716893179

Epoch: 5| Step: 11
Training loss: 6.158525540144596
Validation loss: 4.752458617886238

Epoch: 16| Step: 0
Training loss: 4.9748156489428625
Validation loss: 4.74803384444074

Epoch: 5| Step: 1
Training loss: 4.787052996212785
Validation loss: 4.742754974013014

Epoch: 5| Step: 2
Training loss: 4.710350594724317
Validation loss: 4.737783382264147

Epoch: 5| Step: 3
Training loss: 4.971489301163388
Validation loss: 4.733075759935815

Epoch: 5| Step: 4
Training loss: 5.13811062713235
Validation loss: 4.7276888595559

Epoch: 5| Step: 5
Training loss: 4.640631576173791
Validation loss: 4.723350581140105

Epoch: 5| Step: 6
Training loss: 4.74585382302505
Validation loss: 4.718532868835978

Epoch: 5| Step: 7
Training loss: 4.397455190459547
Validation loss: 4.71489410668477

Epoch: 5| Step: 8
Training loss: 4.7172913981188005
Validation loss: 4.710181753967216

Epoch: 5| Step: 9
Training loss: 4.70635733311059
Validation loss: 4.705529123377408

Epoch: 5| Step: 10
Training loss: 5.477913117214527
Validation loss: 4.700944088577462

Epoch: 5| Step: 11
Training loss: 4.843386138047075
Validation loss: 4.696308269475999

Epoch: 17| Step: 0
Training loss: 4.294600561039622
Validation loss: 4.692020186571349

Epoch: 5| Step: 1
Training loss: 4.6976083229978665
Validation loss: 4.68727441032958

Epoch: 5| Step: 2
Training loss: 4.501839579641869
Validation loss: 4.6830205664722415

Epoch: 5| Step: 3
Training loss: 5.444459517235338
Validation loss: 4.678317201072639

Epoch: 5| Step: 4
Training loss: 5.01238395575617
Validation loss: 4.674077929718074

Epoch: 5| Step: 5
Training loss: 4.815397901087799
Validation loss: 4.66941315291676

Epoch: 5| Step: 6
Training loss: 4.288140758979728
Validation loss: 4.664407773765517

Epoch: 5| Step: 7
Training loss: 4.71352435648007
Validation loss: 4.660720164353244

Epoch: 5| Step: 8
Training loss: 5.501212766625785
Validation loss: 4.655812091418199

Epoch: 5| Step: 9
Training loss: 4.322405068638591
Validation loss: 4.6518189256725675

Epoch: 5| Step: 10
Training loss: 5.156170098812744
Validation loss: 4.648027785594594

Epoch: 5| Step: 11
Training loss: 3.7177259814412755
Validation loss: 4.6424854458149545

Epoch: 18| Step: 0
Training loss: 4.397102112587947
Validation loss: 4.638466826608359

Epoch: 5| Step: 1
Training loss: 5.582518314070157
Validation loss: 4.634648148625527

Epoch: 5| Step: 2
Training loss: 4.569959212774322
Validation loss: 4.6306723529146625

Epoch: 5| Step: 3
Training loss: 5.005003904785096
Validation loss: 4.626530883639809

Epoch: 5| Step: 4
Training loss: 5.008244583604529
Validation loss: 4.622287401530437

Epoch: 5| Step: 5
Training loss: 3.3583146661913266
Validation loss: 4.6181517582228855

Epoch: 5| Step: 6
Training loss: 4.718282714342257
Validation loss: 4.613682435776993

Epoch: 5| Step: 7
Training loss: 4.821489533538519
Validation loss: 4.609358629100629

Epoch: 5| Step: 8
Training loss: 5.166405496866911
Validation loss: 4.605582061400384

Epoch: 5| Step: 9
Training loss: 4.324781979043541
Validation loss: 4.601457660475978

Epoch: 5| Step: 10
Training loss: 4.7985481053197105
Validation loss: 4.596918557360702

Epoch: 5| Step: 11
Training loss: 5.256966101891427
Validation loss: 4.592737877862419

Epoch: 19| Step: 0
Training loss: 4.944885524740002
Validation loss: 4.588541776359057

Epoch: 5| Step: 1
Training loss: 4.594046654497132
Validation loss: 4.584978227511662

Epoch: 5| Step: 2
Training loss: 4.77580739330373
Validation loss: 4.580955394242639

Epoch: 5| Step: 3
Training loss: 4.545837493717424
Validation loss: 4.577586518821967

Epoch: 5| Step: 4
Training loss: 5.643516919296316
Validation loss: 4.573331925546709

Epoch: 5| Step: 5
Training loss: 4.528628939538046
Validation loss: 4.56899327205798

Epoch: 5| Step: 6
Training loss: 4.121809447998579
Validation loss: 4.564938664269754

Epoch: 5| Step: 7
Training loss: 4.92720871403576
Validation loss: 4.56088559229082

Epoch: 5| Step: 8
Training loss: 4.938657021464356
Validation loss: 4.556003182052839

Epoch: 5| Step: 9
Training loss: 4.602709071991364
Validation loss: 4.551975985148035

Epoch: 5| Step: 10
Training loss: 3.897445399579088
Validation loss: 4.547924790118109

Epoch: 5| Step: 11
Training loss: 4.283931588475279
Validation loss: 4.543619045380127

Epoch: 20| Step: 0
Training loss: 4.946399249914101
Validation loss: 4.539727797477423

Epoch: 5| Step: 1
Training loss: 5.253701857664605
Validation loss: 4.535424451539498

Epoch: 5| Step: 2
Training loss: 4.6271687139780395
Validation loss: 4.531172600446852

Epoch: 5| Step: 3
Training loss: 4.194723247724455
Validation loss: 4.527043786587865

Epoch: 5| Step: 4
Training loss: 5.2878791691166445
Validation loss: 4.523278461443009

Epoch: 5| Step: 5
Training loss: 4.28401551411417
Validation loss: 4.5186518432030365

Epoch: 5| Step: 6
Training loss: 4.091328844056058
Validation loss: 4.515049229998078

Epoch: 5| Step: 7
Training loss: 4.879923168578127
Validation loss: 4.511626174659559

Epoch: 5| Step: 8
Training loss: 4.348534014744805
Validation loss: 4.507132952247924

Epoch: 5| Step: 9
Training loss: 3.9585153370558075
Validation loss: 4.50307805259458

Epoch: 5| Step: 10
Training loss: 4.746353757667029
Validation loss: 4.498953989104411

Epoch: 5| Step: 11
Training loss: 5.885836407932798
Validation loss: 4.4949626809035985

Epoch: 21| Step: 0
Training loss: 4.893094252965929
Validation loss: 4.4906769310822785

Epoch: 5| Step: 1
Training loss: 4.7410493141543215
Validation loss: 4.486231101878375

Epoch: 5| Step: 2
Training loss: 4.215792601288645
Validation loss: 4.48230488277505

Epoch: 5| Step: 3
Training loss: 4.270682553986975
Validation loss: 4.478195895485446

Epoch: 5| Step: 4
Training loss: 4.3115644684132
Validation loss: 4.473910404373436

Epoch: 5| Step: 5
Training loss: 4.2643775093913225
Validation loss: 4.46996169568831

Epoch: 5| Step: 6
Training loss: 4.492644762732897
Validation loss: 4.465796635120988

Epoch: 5| Step: 7
Training loss: 4.334679663415029
Validation loss: 4.461875273592352

Epoch: 5| Step: 8
Training loss: 4.88430094501102
Validation loss: 4.458254040996347

Epoch: 5| Step: 9
Training loss: 5.103092542499543
Validation loss: 4.4543995778798395

Epoch: 5| Step: 10
Training loss: 5.024897195703866
Validation loss: 4.450330792322882

Epoch: 5| Step: 11
Training loss: 4.182358275279373
Validation loss: 4.446042108802827

Epoch: 22| Step: 0
Training loss: 5.460347024977324
Validation loss: 4.4417515477604175

Epoch: 5| Step: 1
Training loss: 4.412957679419403
Validation loss: 4.437683710584793

Epoch: 5| Step: 2
Training loss: 4.181202266403543
Validation loss: 4.433243241087859

Epoch: 5| Step: 3
Training loss: 4.5853106770563485
Validation loss: 4.429107215365121

Epoch: 5| Step: 4
Training loss: 3.9689514829900117
Validation loss: 4.424814884710338

Epoch: 5| Step: 5
Training loss: 5.157527326103744
Validation loss: 4.4207325235654285

Epoch: 5| Step: 6
Training loss: 4.897411573623352
Validation loss: 4.416675480647859

Epoch: 5| Step: 7
Training loss: 4.79860991376588
Validation loss: 4.412604338121071

Epoch: 5| Step: 8
Training loss: 4.5871387058773365
Validation loss: 4.408287893732939

Epoch: 5| Step: 9
Training loss: 3.890560287488929
Validation loss: 4.4036232985136685

Epoch: 5| Step: 10
Training loss: 4.050104097512013
Validation loss: 4.399707166001591

Epoch: 5| Step: 11
Training loss: 3.3236394751780636
Validation loss: 4.3956533850166455

Epoch: 23| Step: 0
Training loss: 4.522267244590277
Validation loss: 4.391518123015857

Epoch: 5| Step: 1
Training loss: 3.9025619797119386
Validation loss: 4.387135033856113

Epoch: 5| Step: 2
Training loss: 4.639519042706025
Validation loss: 4.383408413571576

Epoch: 5| Step: 3
Training loss: 4.835908510678963
Validation loss: 4.379553319132397

Epoch: 5| Step: 4
Training loss: 3.9845266275912734
Validation loss: 4.375612724630981

Epoch: 5| Step: 5
Training loss: 4.734981284018952
Validation loss: 4.371351841820245

Epoch: 5| Step: 6
Training loss: 5.3073547579153955
Validation loss: 4.367385395732181

Epoch: 5| Step: 7
Training loss: 4.857788415691442
Validation loss: 4.363072416794409

Epoch: 5| Step: 8
Training loss: 4.230421634880181
Validation loss: 4.358667309378441

Epoch: 5| Step: 9
Training loss: 3.8024452072098303
Validation loss: 4.3545364864697085

Epoch: 5| Step: 10
Training loss: 4.57056623227295
Validation loss: 4.3507972377694095

Epoch: 5| Step: 11
Training loss: 3.877319872058377
Validation loss: 4.345822861982819

Epoch: 24| Step: 0
Training loss: 4.776159631013483
Validation loss: 4.3410476447681186

Epoch: 5| Step: 1
Training loss: 4.76032460107682
Validation loss: 4.336538178130888

Epoch: 5| Step: 2
Training loss: 3.3031000603751166
Validation loss: 4.3315793699798295

Epoch: 5| Step: 3
Training loss: 4.672252014665926
Validation loss: 4.327210220633932

Epoch: 5| Step: 4
Training loss: 4.275751076913682
Validation loss: 4.323013013509081

Epoch: 5| Step: 5
Training loss: 4.130601258927555
Validation loss: 4.318609277886458

Epoch: 5| Step: 6
Training loss: 4.193035509442684
Validation loss: 4.314095354075992

Epoch: 5| Step: 7
Training loss: 4.334720365135553
Validation loss: 4.30962837365113

Epoch: 5| Step: 8
Training loss: 4.546674061952843
Validation loss: 4.305489379449451

Epoch: 5| Step: 9
Training loss: 5.070157511594962
Validation loss: 4.300850295119804

Epoch: 5| Step: 10
Training loss: 4.206598711225633
Validation loss: 4.296582049006893

Epoch: 5| Step: 11
Training loss: 6.133337768608369
Validation loss: 4.292342959823018

Epoch: 25| Step: 0
Training loss: 4.209257622365886
Validation loss: 4.2875575498271905

Epoch: 5| Step: 1
Training loss: 4.942903676274674
Validation loss: 4.283337165531468

Epoch: 5| Step: 2
Training loss: 4.427239173689378
Validation loss: 4.2785804760569865

Epoch: 5| Step: 3
Training loss: 4.186808059232416
Validation loss: 4.274041881049943

Epoch: 5| Step: 4
Training loss: 4.425488616346019
Validation loss: 4.2693597980776445

Epoch: 5| Step: 5
Training loss: 4.273678286392303
Validation loss: 4.265022225927628

Epoch: 5| Step: 6
Training loss: 3.641929687382687
Validation loss: 4.260129576930144

Epoch: 5| Step: 7
Training loss: 4.542972528615152
Validation loss: 4.255791691450067

Epoch: 5| Step: 8
Training loss: 4.542177270773441
Validation loss: 4.251487144504315

Epoch: 5| Step: 9
Training loss: 4.294765995210133
Validation loss: 4.2467765738688685

Epoch: 5| Step: 10
Training loss: 4.695248113054267
Validation loss: 4.242354875029461

Epoch: 5| Step: 11
Training loss: 4.592518751742602
Validation loss: 4.237994646967624

Epoch: 26| Step: 0
Training loss: 5.102640642679074
Validation loss: 4.233202416480733

Epoch: 5| Step: 1
Training loss: 4.463782049922351
Validation loss: 4.228089137370476

Epoch: 5| Step: 2
Training loss: 3.633398390254596
Validation loss: 4.223098237710917

Epoch: 5| Step: 3
Training loss: 4.637912766834201
Validation loss: 4.218566160552753

Epoch: 5| Step: 4
Training loss: 4.012226492333309
Validation loss: 4.2139030776221205

Epoch: 5| Step: 5
Training loss: 3.6877544767859325
Validation loss: 4.209466690314712

Epoch: 5| Step: 6
Training loss: 4.0261771050586965
Validation loss: 4.205362364970435

Epoch: 5| Step: 7
Training loss: 4.960121195758359
Validation loss: 4.200797257745555

Epoch: 5| Step: 8
Training loss: 4.310495104044567
Validation loss: 4.1964700665881445

Epoch: 5| Step: 9
Training loss: 4.038716579949524
Validation loss: 4.191680690648386

Epoch: 5| Step: 10
Training loss: 4.5145651025525755
Validation loss: 4.187659379194006

Epoch: 5| Step: 11
Training loss: 4.817002605264096
Validation loss: 4.183076248906984

Epoch: 27| Step: 0
Training loss: 3.7455695365263346
Validation loss: 4.178310997112896

Epoch: 5| Step: 1
Training loss: 4.3176992283607385
Validation loss: 4.173754588937003

Epoch: 5| Step: 2
Training loss: 5.076449167589788
Validation loss: 4.169484280950746

Epoch: 5| Step: 3
Training loss: 4.758232010510283
Validation loss: 4.164831408995987

Epoch: 5| Step: 4
Training loss: 4.025711868549957
Validation loss: 4.160231420945222

Epoch: 5| Step: 5
Training loss: 4.6572514423546485
Validation loss: 4.1551985498203035

Epoch: 5| Step: 6
Training loss: 4.320191310955666
Validation loss: 4.150771189277222

Epoch: 5| Step: 7
Training loss: 3.7725999743825778
Validation loss: 4.146939353759745

Epoch: 5| Step: 8
Training loss: 4.807429032379697
Validation loss: 4.143028396674865

Epoch: 5| Step: 9
Training loss: 3.8437218393674346
Validation loss: 4.139028987746454

Epoch: 5| Step: 10
Training loss: 3.5132758536031217
Validation loss: 4.132359764141269

Epoch: 5| Step: 11
Training loss: 4.3545498960700035
Validation loss: 4.128338267352025

Epoch: 28| Step: 0
Training loss: 4.367987544115353
Validation loss: 4.123641869425379

Epoch: 5| Step: 1
Training loss: 4.717025138433779
Validation loss: 4.119052761220623

Epoch: 5| Step: 2
Training loss: 3.9312876785971347
Validation loss: 4.114407734403388

Epoch: 5| Step: 3
Training loss: 3.7435980509648066
Validation loss: 4.10992299379788

Epoch: 5| Step: 4
Training loss: 3.6993359201761034
Validation loss: 4.105483742591881

Epoch: 5| Step: 5
Training loss: 4.768844367577207
Validation loss: 4.100835036902929

Epoch: 5| Step: 6
Training loss: 4.374330305886834
Validation loss: 4.096673979241839

Epoch: 5| Step: 7
Training loss: 4.558363620208788
Validation loss: 4.092490577616998

Epoch: 5| Step: 8
Training loss: 3.56171636160879
Validation loss: 4.087767493296196

Epoch: 5| Step: 9
Training loss: 4.5661857036133355
Validation loss: 4.083474427659537

Epoch: 5| Step: 10
Training loss: 4.024231471265808
Validation loss: 4.0789084869419545

Epoch: 5| Step: 11
Training loss: 4.3924521991732
Validation loss: 4.074362586784149

Epoch: 29| Step: 0
Training loss: 4.409119882104094
Validation loss: 4.069953263160489

Epoch: 5| Step: 1
Training loss: 4.732050460365807
Validation loss: 4.065353530902324

Epoch: 5| Step: 2
Training loss: 3.955559866494486
Validation loss: 4.060660190172427

Epoch: 5| Step: 3
Training loss: 4.3020197361023875
Validation loss: 4.055926692795511

Epoch: 5| Step: 4
Training loss: 4.326605685078129
Validation loss: 4.0511615296327586

Epoch: 5| Step: 5
Training loss: 4.7198616385789425
Validation loss: 4.046900819084844

Epoch: 5| Step: 6
Training loss: 4.197257445315436
Validation loss: 4.042286931778471

Epoch: 5| Step: 7
Training loss: 3.971809229392507
Validation loss: 4.037412772599501

Epoch: 5| Step: 8
Training loss: 4.012531677311194
Validation loss: 4.033478729462132

Epoch: 5| Step: 9
Training loss: 3.942340479243855
Validation loss: 4.02849930059269

Epoch: 5| Step: 10
Training loss: 3.486723924924039
Validation loss: 4.025092101376135

Epoch: 5| Step: 11
Training loss: 2.873831801874262
Validation loss: 4.02038356591187

Epoch: 30| Step: 0
Training loss: 4.165493660163382
Validation loss: 4.015402385710948

Epoch: 5| Step: 1
Training loss: 4.2650595489316
Validation loss: 4.011028231605207

Epoch: 5| Step: 2
Training loss: 4.305650440660863
Validation loss: 4.006947975039602

Epoch: 5| Step: 3
Training loss: 4.566824966434322
Validation loss: 4.0032279480544535

Epoch: 5| Step: 4
Training loss: 3.836515985132188
Validation loss: 3.999027451857468

Epoch: 5| Step: 5
Training loss: 3.7012205739705135
Validation loss: 3.9953204239801634

Epoch: 5| Step: 6
Training loss: 4.2263734108869215
Validation loss: 3.9909212974773234

Epoch: 5| Step: 7
Training loss: 4.685172965684809
Validation loss: 3.986673028987626

Epoch: 5| Step: 8
Training loss: 3.9562149938206774
Validation loss: 3.982250450028082

Epoch: 5| Step: 9
Training loss: 4.166458328124739
Validation loss: 3.977766892585802

Epoch: 5| Step: 10
Training loss: 3.56638592717375
Validation loss: 3.9732766956307892

Epoch: 5| Step: 11
Training loss: 3.1985026432591153
Validation loss: 3.968894370149003

Epoch: 31| Step: 0
Training loss: 4.375283804271435
Validation loss: 3.964606099139366

Epoch: 5| Step: 1
Training loss: 4.177166386997076
Validation loss: 3.9604523842592427

Epoch: 5| Step: 2
Training loss: 3.6781920291623647
Validation loss: 3.9561140598527254

Epoch: 5| Step: 3
Training loss: 4.371907040067548
Validation loss: 3.9518690564281167

Epoch: 5| Step: 4
Training loss: 3.7742454027242784
Validation loss: 3.947761903344624

Epoch: 5| Step: 5
Training loss: 4.15316795860789
Validation loss: 3.9433281116150063

Epoch: 5| Step: 6
Training loss: 3.9591537160841592
Validation loss: 3.939208427045365

Epoch: 5| Step: 7
Training loss: 3.528628025737277
Validation loss: 3.934429970039872

Epoch: 5| Step: 8
Training loss: 4.623037592077182
Validation loss: 3.930368342994064

Epoch: 5| Step: 9
Training loss: 4.355195479095377
Validation loss: 3.925911749699894

Epoch: 5| Step: 10
Training loss: 3.8713782828548235
Validation loss: 3.921103879139367

Epoch: 5| Step: 11
Training loss: 3.1943884821610817
Validation loss: 3.9167578852291625

Epoch: 32| Step: 0
Training loss: 3.1688052200832963
Validation loss: 3.9125347747313577

Epoch: 5| Step: 1
Training loss: 4.05111578182589
Validation loss: 3.9085310112605103

Epoch: 5| Step: 2
Training loss: 3.94599736378616
Validation loss: 3.9045130059355415

Epoch: 5| Step: 3
Training loss: 3.46538235887304
Validation loss: 3.900410547207183

Epoch: 5| Step: 4
Training loss: 3.951497945563675
Validation loss: 3.8963133096390647

Epoch: 5| Step: 5
Training loss: 4.2244071047855805
Validation loss: 3.8921231113796018

Epoch: 5| Step: 6
Training loss: 4.2907713662984515
Validation loss: 3.887992678227549

Epoch: 5| Step: 7
Training loss: 4.285287999342015
Validation loss: 3.883886008507037

Epoch: 5| Step: 8
Training loss: 3.757901196612734
Validation loss: 3.879416481821815

Epoch: 5| Step: 9
Training loss: 4.1190315763926035
Validation loss: 3.875110132436649

Epoch: 5| Step: 10
Training loss: 4.721532140436389
Validation loss: 3.870770915376463

Epoch: 5| Step: 11
Training loss: 4.345361204947737
Validation loss: 3.866272306200108

Epoch: 33| Step: 0
Training loss: 3.9798144999842227
Validation loss: 3.8614950753374484

Epoch: 5| Step: 1
Training loss: 3.840471932299566
Validation loss: 3.857017188110639

Epoch: 5| Step: 2
Training loss: 3.835189218043329
Validation loss: 3.852612247263457

Epoch: 5| Step: 3
Training loss: 3.7471970573267144
Validation loss: 3.848057486176426

Epoch: 5| Step: 4
Training loss: 4.264079837617052
Validation loss: 3.843667802216071

Epoch: 5| Step: 5
Training loss: 4.7328990486319285
Validation loss: 3.8392279885684832

Epoch: 5| Step: 6
Training loss: 3.6919691514434354
Validation loss: 3.8348922237635015

Epoch: 5| Step: 7
Training loss: 3.7589317764460137
Validation loss: 3.8302783826173914

Epoch: 5| Step: 8
Training loss: 3.3336797216364675
Validation loss: 3.8257621375685353

Epoch: 5| Step: 9
Training loss: 3.9397280005661335
Validation loss: 3.8212324671685716

Epoch: 5| Step: 10
Training loss: 4.1180185134419665
Validation loss: 3.81679707572285

Epoch: 5| Step: 11
Training loss: 5.248653420824582
Validation loss: 3.812295819636102

Epoch: 34| Step: 0
Training loss: 3.5426508414944324
Validation loss: 3.8075101696654223

Epoch: 5| Step: 1
Training loss: 4.166543246666566
Validation loss: 3.8025925839581296

Epoch: 5| Step: 2
Training loss: 3.801915594433262
Validation loss: 3.797885833478363

Epoch: 5| Step: 3
Training loss: 3.4979266428772053
Validation loss: 3.793104091420513

Epoch: 5| Step: 4
Training loss: 3.418239107611075
Validation loss: 3.788394410267142

Epoch: 5| Step: 5
Training loss: 4.058067838429864
Validation loss: 3.7837887692909584

Epoch: 5| Step: 6
Training loss: 4.238620333138038
Validation loss: 3.7787700013104466

Epoch: 5| Step: 7
Training loss: 3.670326718123802
Validation loss: 3.7739772844939923

Epoch: 5| Step: 8
Training loss: 3.948091581926922
Validation loss: 3.76846194476483

Epoch: 5| Step: 9
Training loss: 4.221617225892599
Validation loss: 3.763414449025941

Epoch: 5| Step: 10
Training loss: 4.252035663243447
Validation loss: 3.7583967033648795

Epoch: 5| Step: 11
Training loss: 4.581043758147536
Validation loss: 3.753598468189328

Epoch: 35| Step: 0
Training loss: 3.9544169007455885
Validation loss: 3.7486970810283626

Epoch: 5| Step: 1
Training loss: 3.6703090493943975
Validation loss: 3.7441322142165436

Epoch: 5| Step: 2
Training loss: 3.995946141236099
Validation loss: 3.739998131205862

Epoch: 5| Step: 3
Training loss: 4.202889701751971
Validation loss: 3.734974034996629

Epoch: 5| Step: 4
Training loss: 2.9992806843838844
Validation loss: 3.730278795875176

Epoch: 5| Step: 5
Training loss: 3.783243709852651
Validation loss: 3.7257625539636803

Epoch: 5| Step: 6
Training loss: 3.6650553254951594
Validation loss: 3.721229140911215

Epoch: 5| Step: 7
Training loss: 4.186262716579857
Validation loss: 3.7169044360127437

Epoch: 5| Step: 8
Training loss: 4.466377962565661
Validation loss: 3.712404232952041

Epoch: 5| Step: 9
Training loss: 3.337326582500088
Validation loss: 3.7080354338728903

Epoch: 5| Step: 10
Training loss: 3.6330015071799617
Validation loss: 3.703345913206126

Epoch: 5| Step: 11
Training loss: 5.331678173406136
Validation loss: 3.6989323882161047

Epoch: 36| Step: 0
Training loss: 4.320212944221946
Validation loss: 3.69427960230426

Epoch: 5| Step: 1
Training loss: 3.942351485934183
Validation loss: 3.689442063909576

Epoch: 5| Step: 2
Training loss: 3.77755115022496
Validation loss: 3.6846662020715493

Epoch: 5| Step: 3
Training loss: 3.9004497953386132
Validation loss: 3.6798002329712265

Epoch: 5| Step: 4
Training loss: 3.7437129405739564
Validation loss: 3.67500266120451

Epoch: 5| Step: 5
Training loss: 2.918317454796132
Validation loss: 3.6703629755625773

Epoch: 5| Step: 6
Training loss: 4.0867174618558
Validation loss: 3.6659175566351734

Epoch: 5| Step: 7
Training loss: 3.9914918058211644
Validation loss: 3.661366911497873

Epoch: 5| Step: 8
Training loss: 3.422012535362092
Validation loss: 3.6569025756043114

Epoch: 5| Step: 9
Training loss: 3.8213508302652284
Validation loss: 3.652507507678564

Epoch: 5| Step: 10
Training loss: 3.6540831315262237
Validation loss: 3.6483030600763606

Epoch: 5| Step: 11
Training loss: 4.441003410435969
Validation loss: 3.643797129636504

Epoch: 37| Step: 0
Training loss: 3.089830478104398
Validation loss: 3.6393596540404074

Epoch: 5| Step: 1
Training loss: 3.8214702451137246
Validation loss: 3.6350477335654166

Epoch: 5| Step: 2
Training loss: 3.264196055863263
Validation loss: 3.6306094856037983

Epoch: 5| Step: 3
Training loss: 3.6828597015994293
Validation loss: 3.626220311373488

Epoch: 5| Step: 4
Training loss: 3.5781801710914434
Validation loss: 3.6218577501107285

Epoch: 5| Step: 5
Training loss: 4.031791236680276
Validation loss: 3.6175520008130957

Epoch: 5| Step: 6
Training loss: 3.529079614231448
Validation loss: 3.612998442708544

Epoch: 5| Step: 7
Training loss: 2.854293059360475
Validation loss: 3.6080896365015667

Epoch: 5| Step: 8
Training loss: 4.040152721728793
Validation loss: 3.6036947838166213

Epoch: 5| Step: 9
Training loss: 3.8297246587997993
Validation loss: 3.5989407025065

Epoch: 5| Step: 10
Training loss: 4.634725294809781
Validation loss: 3.5940138125684014

Epoch: 5| Step: 11
Training loss: 5.993004853805341
Validation loss: 3.5896086617563445

Epoch: 38| Step: 0
Training loss: 3.3521109178987496
Validation loss: 3.584848946519629

Epoch: 5| Step: 1
Training loss: 3.4228639610599267
Validation loss: 3.579141369746157

Epoch: 5| Step: 2
Training loss: 3.9448574294713086
Validation loss: 3.5741107917421138

Epoch: 5| Step: 3
Training loss: 3.6160964803483866
Validation loss: 3.5695898714551513

Epoch: 5| Step: 4
Training loss: 4.002134468881179
Validation loss: 3.5648306813008515

Epoch: 5| Step: 5
Training loss: 3.5759826643436115
Validation loss: 3.560510313983641

Epoch: 5| Step: 6
Training loss: 3.0801155895985604
Validation loss: 3.5558843086086775

Epoch: 5| Step: 7
Training loss: 4.157888448050951
Validation loss: 3.551784361099482

Epoch: 5| Step: 8
Training loss: 3.9738998042138234
Validation loss: 3.547257799057942

Epoch: 5| Step: 9
Training loss: 3.8750702636255085
Validation loss: 3.5428658736496024

Epoch: 5| Step: 10
Training loss: 3.296605826865288
Validation loss: 3.538133483842405

Epoch: 5| Step: 11
Training loss: 4.6181631332270685
Validation loss: 3.5336989685177276

Epoch: 39| Step: 0
Training loss: 3.7826036284497135
Validation loss: 3.529282542236363

Epoch: 5| Step: 1
Training loss: 3.696791758047532
Validation loss: 3.5243965811580837

Epoch: 5| Step: 2
Training loss: 3.5642242274535554
Validation loss: 3.5197767199608845

Epoch: 5| Step: 3
Training loss: 4.244399700517026
Validation loss: 3.5152569387410972

Epoch: 5| Step: 4
Training loss: 3.776471862841687
Validation loss: 3.510630935936486

Epoch: 5| Step: 5
Training loss: 3.971535133449425
Validation loss: 3.5059717866945106

Epoch: 5| Step: 6
Training loss: 3.464365895035843
Validation loss: 3.5014073602074087

Epoch: 5| Step: 7
Training loss: 2.881861915070564
Validation loss: 3.497014520820255

Epoch: 5| Step: 8
Training loss: 3.6596791415460705
Validation loss: 3.492633361573027

Epoch: 5| Step: 9
Training loss: 3.540593437195551
Validation loss: 3.488379072332054

Epoch: 5| Step: 10
Training loss: 3.378775286479324
Validation loss: 3.484018920585741

Epoch: 5| Step: 11
Training loss: 3.520567543486003
Validation loss: 3.4796743974237714

Epoch: 40| Step: 0
Training loss: 3.592375782814712
Validation loss: 3.4754892128381996

Epoch: 5| Step: 1
Training loss: 3.5011156211486885
Validation loss: 3.471369587586652

Epoch: 5| Step: 2
Training loss: 3.3779829053609984
Validation loss: 3.4671680291161904

Epoch: 5| Step: 3
Training loss: 3.6058426122778906
Validation loss: 3.462860365475608

Epoch: 5| Step: 4
Training loss: 3.993578882984121
Validation loss: 3.4588189971350514

Epoch: 5| Step: 5
Training loss: 3.9971604997613057
Validation loss: 3.4546186315192977

Epoch: 5| Step: 6
Training loss: 3.294155065540357
Validation loss: 3.4504294425329514

Epoch: 5| Step: 7
Training loss: 3.57484852396564
Validation loss: 3.4463811242164453

Epoch: 5| Step: 8
Training loss: 3.381567040773422
Validation loss: 3.442381848634986

Epoch: 5| Step: 9
Training loss: 3.2905535365040213
Validation loss: 3.438482901182637

Epoch: 5| Step: 10
Training loss: 3.8000778692197597
Validation loss: 3.4344420442987937

Epoch: 5| Step: 11
Training loss: 3.717219061635332
Validation loss: 3.430426272548677

Epoch: 41| Step: 0
Training loss: 3.445726988203489
Validation loss: 3.426182861449685

Epoch: 5| Step: 1
Training loss: 3.6987894810164486
Validation loss: 3.422043080607364

Epoch: 5| Step: 2
Training loss: 3.021290886964912
Validation loss: 3.418004208335421

Epoch: 5| Step: 3
Training loss: 4.400447840007532
Validation loss: 3.414091644046325

Epoch: 5| Step: 4
Training loss: 3.6759805007101933
Validation loss: 3.4096807065992856

Epoch: 5| Step: 5
Training loss: 3.441609648323811
Validation loss: 3.4056109432631136

Epoch: 5| Step: 6
Training loss: 3.405091394886742
Validation loss: 3.401472223123868

Epoch: 5| Step: 7
Training loss: 3.7070573618926903
Validation loss: 3.3975311064448186

Epoch: 5| Step: 8
Training loss: 3.566459062066189
Validation loss: 3.3933269148024565

Epoch: 5| Step: 9
Training loss: 2.7395974123826283
Validation loss: 3.389120280768548

Epoch: 5| Step: 10
Training loss: 3.6966854714367363
Validation loss: 3.385184057998802

Epoch: 5| Step: 11
Training loss: 3.2942630491302958
Validation loss: 3.3810453020374367

Epoch: 42| Step: 0
Training loss: 2.6882113025526158
Validation loss: 3.3769799770672466

Epoch: 5| Step: 1
Training loss: 3.681978650347692
Validation loss: 3.3732074404081622

Epoch: 5| Step: 2
Training loss: 3.6569151966087468
Validation loss: 3.369095228690991

Epoch: 5| Step: 3
Training loss: 3.63059263598779
Validation loss: 3.365139160462379

Epoch: 5| Step: 4
Training loss: 3.310033203603849
Validation loss: 3.3611909320029993

Epoch: 5| Step: 5
Training loss: 3.5622914571122672
Validation loss: 3.3569576466941315

Epoch: 5| Step: 6
Training loss: 4.019040091620964
Validation loss: 3.352973421669719

Epoch: 5| Step: 7
Training loss: 3.0837014124660507
Validation loss: 3.3488209440646095

Epoch: 5| Step: 8
Training loss: 3.344645870377009
Validation loss: 3.3448671007911672

Epoch: 5| Step: 9
Training loss: 3.6025571959678486
Validation loss: 3.3410301495706176

Epoch: 5| Step: 10
Training loss: 3.707020959548415
Validation loss: 3.337083198414631

Epoch: 5| Step: 11
Training loss: 3.4765788217225713
Validation loss: 3.3331248198301195

Epoch: 43| Step: 0
Training loss: 3.2875802149976425
Validation loss: 3.3294017653036603

Epoch: 5| Step: 1
Training loss: 3.4962795101662008
Validation loss: 3.325774101265771

Epoch: 5| Step: 2
Training loss: 3.6185118390973243
Validation loss: 3.3218373466073055

Epoch: 5| Step: 3
Training loss: 3.666307489547236
Validation loss: 3.318100770809283

Epoch: 5| Step: 4
Training loss: 3.4584643480846604
Validation loss: 3.314449306554024

Epoch: 5| Step: 5
Training loss: 3.485656502622205
Validation loss: 3.3104419192740786

Epoch: 5| Step: 6
Training loss: 3.337638903524074
Validation loss: 3.3066323031061446

Epoch: 5| Step: 7
Training loss: 3.1385222270543753
Validation loss: 3.3029763290838274

Epoch: 5| Step: 8
Training loss: 3.941229129134697
Validation loss: 3.2993109142556407

Epoch: 5| Step: 9
Training loss: 3.169773702396096
Validation loss: 3.2955336893078915

Epoch: 5| Step: 10
Training loss: 2.809906590358353
Validation loss: 3.2918352413872736

Epoch: 5| Step: 11
Training loss: 5.1147876499281395
Validation loss: 3.2881177691648613

Epoch: 44| Step: 0
Training loss: 3.7258001863362744
Validation loss: 3.2840960133994774

Epoch: 5| Step: 1
Training loss: 2.7497999812124565
Validation loss: 3.2799552391407656

Epoch: 5| Step: 2
Training loss: 3.9449837424906615
Validation loss: 3.2761422380900673

Epoch: 5| Step: 3
Training loss: 3.072664946682725
Validation loss: 3.2720848633149604

Epoch: 5| Step: 4
Training loss: 3.290554550880343
Validation loss: 3.2683459388976788

Epoch: 5| Step: 5
Training loss: 3.539127172422337
Validation loss: 3.264285109303172

Epoch: 5| Step: 6
Training loss: 3.766779679034948
Validation loss: 3.260323326107247

Epoch: 5| Step: 7
Training loss: 3.300610636076889
Validation loss: 3.256640939436828

Epoch: 5| Step: 8
Training loss: 3.3709158027157877
Validation loss: 3.2528940758291847

Epoch: 5| Step: 9
Training loss: 3.297407929795911
Validation loss: 3.2491444721003626

Epoch: 5| Step: 10
Training loss: 3.52032021539878
Validation loss: 3.2454993434034187

Epoch: 5| Step: 11
Training loss: 1.3963027515879578
Validation loss: 3.241699945030585

Epoch: 45| Step: 0
Training loss: 3.251256846443075
Validation loss: 3.2382262209521797

Epoch: 5| Step: 1
Training loss: 3.613742184493627
Validation loss: 3.23478970042102

Epoch: 5| Step: 2
Training loss: 3.682628064075028
Validation loss: 3.2315863967305587

Epoch: 5| Step: 3
Training loss: 4.104240894453218
Validation loss: 3.227936299050422

Epoch: 5| Step: 4
Training loss: 3.646427098924172
Validation loss: 3.2242651758963996

Epoch: 5| Step: 5
Training loss: 3.0471393177118453
Validation loss: 3.2204746360380154

Epoch: 5| Step: 6
Training loss: 2.9593069775668064
Validation loss: 3.2169105341398736

Epoch: 5| Step: 7
Training loss: 2.98856957733818
Validation loss: 3.2131098864717527

Epoch: 5| Step: 8
Training loss: 3.3934155771847307
Validation loss: 3.2098629120939637

Epoch: 5| Step: 9
Training loss: 2.8286897717114474
Validation loss: 3.2064456195904345

Epoch: 5| Step: 10
Training loss: 3.0529124378251242
Validation loss: 3.2033583703354385

Epoch: 5| Step: 11
Training loss: 4.213593899560688
Validation loss: 3.1998716005751606

Epoch: 46| Step: 0
Training loss: 4.0877030535084256
Validation loss: 3.1965301046713592

Epoch: 5| Step: 1
Training loss: 2.97993402446449
Validation loss: 3.1926740527322144

Epoch: 5| Step: 2
Training loss: 3.649433008338231
Validation loss: 3.1895554217199718

Epoch: 5| Step: 3
Training loss: 3.4558682829340093
Validation loss: 3.1860018307244964

Epoch: 5| Step: 4
Training loss: 2.9696212293264783
Validation loss: 3.1826932979354363

Epoch: 5| Step: 5
Training loss: 3.0863297997776593
Validation loss: 3.1792844162246254

Epoch: 5| Step: 6
Training loss: 2.6655708584759843
Validation loss: 3.175874722001791

Epoch: 5| Step: 7
Training loss: 3.5256164985639447
Validation loss: 3.1726346445181632

Epoch: 5| Step: 8
Training loss: 2.74941455504764
Validation loss: 3.1692479095424004

Epoch: 5| Step: 9
Training loss: 3.5067446980176924
Validation loss: 3.1659646929300203

Epoch: 5| Step: 10
Training loss: 3.293425576955524
Validation loss: 3.1627708530162226

Epoch: 5| Step: 11
Training loss: 4.505643908074315
Validation loss: 3.1595919136220285

Epoch: 47| Step: 0
Training loss: 3.6925741941608057
Validation loss: 3.1559337104975813

Epoch: 5| Step: 1
Training loss: 2.719401840466775
Validation loss: 3.1525539941018357

Epoch: 5| Step: 2
Training loss: 3.2431442136079593
Validation loss: 3.1489499655530477

Epoch: 5| Step: 3
Training loss: 3.280778251523401
Validation loss: 3.1474280557346006

Epoch: 5| Step: 4
Training loss: 3.144315155375759
Validation loss: 3.1440263488933753

Epoch: 5| Step: 5
Training loss: 3.640867429855785
Validation loss: 3.13891869622728

Epoch: 5| Step: 6
Training loss: 3.4027608096852306
Validation loss: 3.1352334629072183

Epoch: 5| Step: 7
Training loss: 3.828501904675828
Validation loss: 3.1316606650786443

Epoch: 5| Step: 8
Training loss: 2.7976586293644763
Validation loss: 3.1284106461739096

Epoch: 5| Step: 9
Training loss: 2.4647814565969495
Validation loss: 3.1254220168940896

Epoch: 5| Step: 10
Training loss: 3.5913513139560584
Validation loss: 3.122932535368285

Epoch: 5| Step: 11
Training loss: 3.2069821836037926
Validation loss: 3.119771948843893

Epoch: 48| Step: 0
Training loss: 3.585621938346738
Validation loss: 3.11649716412718

Epoch: 5| Step: 1
Training loss: 3.009384576736693
Validation loss: 3.1130466285025316

Epoch: 5| Step: 2
Training loss: 3.2516643957315554
Validation loss: 3.109707391247394

Epoch: 5| Step: 3
Training loss: 2.9715611048370305
Validation loss: 3.1062535092124843

Epoch: 5| Step: 4
Training loss: 3.024622643003315
Validation loss: 3.102606087740016

Epoch: 5| Step: 5
Training loss: 3.222846082240356
Validation loss: 3.0993477403052623

Epoch: 5| Step: 6
Training loss: 3.2289985530940997
Validation loss: 3.096320779597421

Epoch: 5| Step: 7
Training loss: 3.1620995731684864
Validation loss: 3.093282002716479

Epoch: 5| Step: 8
Training loss: 3.715806068262777
Validation loss: 3.0905287699026567

Epoch: 5| Step: 9
Training loss: 3.009809668216846
Validation loss: 3.0875322623375516

Epoch: 5| Step: 10
Training loss: 3.219672802241124
Validation loss: 3.084632491366265

Epoch: 5| Step: 11
Training loss: 4.046158303679259
Validation loss: 3.0814253514078893

Epoch: 49| Step: 0
Training loss: 2.4420614355233994
Validation loss: 3.07817593320995

Epoch: 5| Step: 1
Training loss: 2.785408511514835
Validation loss: 3.0753952579987494

Epoch: 5| Step: 2
Training loss: 3.4922654657386683
Validation loss: 3.0726684901134895

Epoch: 5| Step: 3
Training loss: 2.918702386961923
Validation loss: 3.0693506962041766

Epoch: 5| Step: 4
Training loss: 3.4540724339226268
Validation loss: 3.0661466322575395

Epoch: 5| Step: 5
Training loss: 3.4964345755220076
Validation loss: 3.0634840078590724

Epoch: 5| Step: 6
Training loss: 3.721823440053693
Validation loss: 3.060511579312055

Epoch: 5| Step: 7
Training loss: 3.3135670796562784
Validation loss: 3.0578796248101145

Epoch: 5| Step: 8
Training loss: 2.785933676314284
Validation loss: 3.0547253735626168

Epoch: 5| Step: 9
Training loss: 3.630047276927265
Validation loss: 3.051078947930672

Epoch: 5| Step: 10
Training loss: 2.8160050486010033
Validation loss: 3.04898464168506

Epoch: 5| Step: 11
Training loss: 3.6820809584155225
Validation loss: 3.046049315904752

Epoch: 50| Step: 0
Training loss: 3.312410173457774
Validation loss: 3.042401666977294

Epoch: 5| Step: 1
Training loss: 3.4740398040933274
Validation loss: 3.0400581069253367

Epoch: 5| Step: 2
Training loss: 3.0707737234084793
Validation loss: 3.0423583763969586

Epoch: 5| Step: 3
Training loss: 2.908751037099118
Validation loss: 3.03473975008964

Epoch: 5| Step: 4
Training loss: 3.0306342374535378
Validation loss: 3.0304495026489495

Epoch: 5| Step: 5
Training loss: 3.231638759933887
Validation loss: 3.0278013609532546

Epoch: 5| Step: 6
Training loss: 2.7900472660231164
Validation loss: 3.0248536006190982

Epoch: 5| Step: 7
Training loss: 3.2657539305719876
Validation loss: 3.022306278279601

Epoch: 5| Step: 8
Training loss: 3.4949047602827843
Validation loss: 3.0195074207966206

Epoch: 5| Step: 9
Training loss: 2.9251458938600328
Validation loss: 3.016019383601763

Epoch: 5| Step: 10
Training loss: 3.4567768930084437
Validation loss: 3.0134697626112867

Epoch: 5| Step: 11
Training loss: 1.9678088163693042
Validation loss: 3.0104187940086233

Epoch: 51| Step: 0
Training loss: 2.955864014539358
Validation loss: 3.0079331840314922

Epoch: 5| Step: 1
Training loss: 2.525142601443192
Validation loss: 3.0051363380486613

Epoch: 5| Step: 2
Training loss: 3.8320618607817907
Validation loss: 3.0024095600693492

Epoch: 5| Step: 3
Training loss: 3.2308305124961407
Validation loss: 2.9994521435536368

Epoch: 5| Step: 4
Training loss: 2.9318927247327484
Validation loss: 2.996464981097896

Epoch: 5| Step: 5
Training loss: 3.0717667491695573
Validation loss: 2.9941050972586067

Epoch: 5| Step: 6
Training loss: 3.185485053383486
Validation loss: 2.9912015454174634

Epoch: 5| Step: 7
Training loss: 2.5268783494586056
Validation loss: 2.988411212829329

Epoch: 5| Step: 8
Training loss: 3.075619990176714
Validation loss: 2.9858550151648493

Epoch: 5| Step: 9
Training loss: 2.924979289706996
Validation loss: 2.9828586554149354

Epoch: 5| Step: 10
Training loss: 3.917358472613159
Validation loss: 2.9806638647953068

Epoch: 5| Step: 11
Training loss: 3.1994998421803844
Validation loss: 2.978708653266439

Epoch: 52| Step: 0
Training loss: 2.999300716280735
Validation loss: 2.9760123117343484

Epoch: 5| Step: 1
Training loss: 2.560716240793391
Validation loss: 2.973556809897385

Epoch: 5| Step: 2
Training loss: 3.167387094028447
Validation loss: 2.971721136159474

Epoch: 5| Step: 3
Training loss: 3.113733198992694
Validation loss: 2.969122465091766

Epoch: 5| Step: 4
Training loss: 3.138884256485153
Validation loss: 2.9647538913249107

Epoch: 5| Step: 5
Training loss: 2.9746718922969118
Validation loss: 2.9621492521605144

Epoch: 5| Step: 6
Training loss: 3.3689031279516573
Validation loss: 2.960386303784669

Epoch: 5| Step: 7
Training loss: 2.817879004724318
Validation loss: 2.9583024988224125

Epoch: 5| Step: 8
Training loss: 3.2171706982433714
Validation loss: 2.9569819323224587

Epoch: 5| Step: 9
Training loss: 3.4652001714754594
Validation loss: 2.9542421821354568

Epoch: 5| Step: 10
Training loss: 3.3779682246554996
Validation loss: 2.951709576306879

Epoch: 5| Step: 11
Training loss: 2.0929763275499145
Validation loss: 2.9483761154170325

Epoch: 53| Step: 0
Training loss: 2.9052251834228002
Validation loss: 2.9463365159234587

Epoch: 5| Step: 1
Training loss: 3.038837650091041
Validation loss: 2.9429726349734353

Epoch: 5| Step: 2
Training loss: 3.3835242670112624
Validation loss: 2.940494181486212

Epoch: 5| Step: 3
Training loss: 2.459080458650737
Validation loss: 2.938195839434795

Epoch: 5| Step: 4
Training loss: 2.9371962694641303
Validation loss: 2.9359120649204056

Epoch: 5| Step: 5
Training loss: 2.709830022175648
Validation loss: 2.9339483887404727

Epoch: 5| Step: 6
Training loss: 3.087773416744943
Validation loss: 2.931535153458141

Epoch: 5| Step: 7
Training loss: 3.8121185111870486
Validation loss: 2.9290147339517674

Epoch: 5| Step: 8
Training loss: 2.792240415988554
Validation loss: 2.9263657451640426

Epoch: 5| Step: 9
Training loss: 3.305104907934635
Validation loss: 2.923889584214971

Epoch: 5| Step: 10
Training loss: 3.0306524887301562
Validation loss: 2.921459263619143

Epoch: 5| Step: 11
Training loss: 3.7790951224007094
Validation loss: 2.919205539232924

Epoch: 54| Step: 0
Training loss: 2.6553143816951708
Validation loss: 2.915446023739168

Epoch: 5| Step: 1
Training loss: 2.9504126955143986
Validation loss: 2.9147747284163925

Epoch: 5| Step: 2
Training loss: 3.3569277343698865
Validation loss: 2.9241144128901118

Epoch: 5| Step: 3
Training loss: 3.0268782719262237
Validation loss: 2.908317924028762

Epoch: 5| Step: 4
Training loss: 3.2405707683090252
Validation loss: 2.9064906987972674

Epoch: 5| Step: 5
Training loss: 3.054090514714702
Validation loss: 2.904428451283747

Epoch: 5| Step: 6
Training loss: 2.6675815105765874
Validation loss: 2.903093986359261

Epoch: 5| Step: 7
Training loss: 3.0789321383375428
Validation loss: 2.9021304579717695

Epoch: 5| Step: 8
Training loss: 3.3697492939772618
Validation loss: 2.9020024711222416

Epoch: 5| Step: 9
Training loss: 2.857560879917361
Validation loss: 2.901800009723705

Epoch: 5| Step: 10
Training loss: 3.1156059976225934
Validation loss: 2.8991137398613356

Epoch: 5| Step: 11
Training loss: 3.4803113291682704
Validation loss: 2.893200481328674

Epoch: 55| Step: 0
Training loss: 2.8107018550640164
Validation loss: 2.890461599182107

Epoch: 5| Step: 1
Training loss: 2.964690152940421
Validation loss: 2.8908109965927196

Epoch: 5| Step: 2
Training loss: 2.921340485502977
Validation loss: 2.886412990208875

Epoch: 5| Step: 3
Training loss: 3.1396198846874293
Validation loss: 2.882811562693925

Epoch: 5| Step: 4
Training loss: 3.3898716806077376
Validation loss: 2.8786477706587013

Epoch: 5| Step: 5
Training loss: 2.965046067804698
Validation loss: 2.8804108868656875

Epoch: 5| Step: 6
Training loss: 3.247003788087337
Validation loss: 2.875856800532608

Epoch: 5| Step: 7
Training loss: 3.2994163806283665
Validation loss: 2.873535436275342

Epoch: 5| Step: 8
Training loss: 2.9981936738795425
Validation loss: 2.872428002729257

Epoch: 5| Step: 9
Training loss: 2.8376461377931745
Validation loss: 2.8720285809738693

Epoch: 5| Step: 10
Training loss: 2.6208009286240737
Validation loss: 2.8712679371144123

Epoch: 5| Step: 11
Training loss: 2.840940659781098
Validation loss: 2.8668171524777106

Epoch: 56| Step: 0
Training loss: 2.5107532027665793
Validation loss: 2.869116121502991

Epoch: 5| Step: 1
Training loss: 3.10336136239489
Validation loss: 2.865294227243669

Epoch: 5| Step: 2
Training loss: 2.892424811834226
Validation loss: 2.8612221586462465

Epoch: 5| Step: 3
Training loss: 2.627843134548735
Validation loss: 2.856603404829852

Epoch: 5| Step: 4
Training loss: 2.8602493700270673
Validation loss: 2.8534355996582024

Epoch: 5| Step: 5
Training loss: 3.338103473410364
Validation loss: 2.8516385002982156

Epoch: 5| Step: 6
Training loss: 3.0057162820269636
Validation loss: 2.84882962681762

Epoch: 5| Step: 7
Training loss: 3.5687642486341264
Validation loss: 2.8474749423245482

Epoch: 5| Step: 8
Training loss: 3.357330267756575
Validation loss: 2.8457456021355765

Epoch: 5| Step: 9
Training loss: 2.8601108292133195
Validation loss: 2.8434560260503883

Epoch: 5| Step: 10
Training loss: 2.6724571798407313
Validation loss: 2.841273875138297

Epoch: 5| Step: 11
Training loss: 2.742154113044615
Validation loss: 2.8390112438904143

Epoch: 57| Step: 0
Training loss: 2.973972264851253
Validation loss: 2.8374424418802806

Epoch: 5| Step: 1
Training loss: 2.552006519225592
Validation loss: 2.834949146035543

Epoch: 5| Step: 2
Training loss: 2.8264868612802263
Validation loss: 2.8313460930916334

Epoch: 5| Step: 3
Training loss: 3.055488188800509
Validation loss: 2.8303457361329265

Epoch: 5| Step: 4
Training loss: 3.163234574116537
Validation loss: 2.830124129155526

Epoch: 5| Step: 5
Training loss: 2.932659137437224
Validation loss: 2.829420372641491

Epoch: 5| Step: 6
Training loss: 3.296454958801979
Validation loss: 2.8255133644860813

Epoch: 5| Step: 7
Training loss: 2.8774320847279227
Validation loss: 2.8217045913843246

Epoch: 5| Step: 8
Training loss: 2.6533570636314296
Validation loss: 2.819576033422161

Epoch: 5| Step: 9
Training loss: 2.9495629520271627
Validation loss: 2.818313386770581

Epoch: 5| Step: 10
Training loss: 3.2013765354612316
Validation loss: 2.8163933896967315

Epoch: 5| Step: 11
Training loss: 3.379665681907008
Validation loss: 2.816111012582114

Epoch: 58| Step: 0
Training loss: 2.6068162993519306
Validation loss: 2.813905742571151

Epoch: 5| Step: 1
Training loss: 2.840530081695938
Validation loss: 2.8144432030634605

Epoch: 5| Step: 2
Training loss: 2.5950350967415283
Validation loss: 2.812400017833226

Epoch: 5| Step: 3
Training loss: 3.032045712199389
Validation loss: 2.8124995832089716

Epoch: 5| Step: 4
Training loss: 3.09132598549098
Validation loss: 2.8087988519034885

Epoch: 5| Step: 5
Training loss: 3.280604853103993
Validation loss: 2.805452088508644

Epoch: 5| Step: 6
Training loss: 2.8978326788514104
Validation loss: 2.8040663722969597

Epoch: 5| Step: 7
Training loss: 3.320681562668937
Validation loss: 2.802271493930785

Epoch: 5| Step: 8
Training loss: 2.9238353008011475
Validation loss: 2.798445827003868

Epoch: 5| Step: 9
Training loss: 3.0309270313104566
Validation loss: 2.796992628014398

Epoch: 5| Step: 10
Training loss: 2.6254472805608096
Validation loss: 2.79506693103064

Epoch: 5| Step: 11
Training loss: 3.2553482066303037
Validation loss: 2.792771894013141

Epoch: 59| Step: 0
Training loss: 3.2208963293418305
Validation loss: 2.79169707257997

Epoch: 5| Step: 1
Training loss: 2.619133342644611
Validation loss: 2.7890202316942294

Epoch: 5| Step: 2
Training loss: 3.068455413539185
Validation loss: 2.7859980277266487

Epoch: 5| Step: 3
Training loss: 2.4704742204980623
Validation loss: 2.7854646259668994

Epoch: 5| Step: 4
Training loss: 3.1591095010074386
Validation loss: 2.7924795865024543

Epoch: 5| Step: 5
Training loss: 2.7696564165893554
Validation loss: 2.8226044764919025

Epoch: 5| Step: 6
Training loss: 3.4226276841459438
Validation loss: 2.8068433850731336

Epoch: 5| Step: 7
Training loss: 2.244790510161088
Validation loss: 2.779657025569544

Epoch: 5| Step: 8
Training loss: 2.8785776186243983
Validation loss: 2.7773865465317646

Epoch: 5| Step: 9
Training loss: 2.9796579840587967
Validation loss: 2.7758628735153383

Epoch: 5| Step: 10
Training loss: 3.3234508089086923
Validation loss: 2.7755237988550214

Epoch: 5| Step: 11
Training loss: 1.6360883932833814
Validation loss: 2.7757179269493775

Epoch: 60| Step: 0
Training loss: 2.797656413623983
Validation loss: 2.774399528747324

Epoch: 5| Step: 1
Training loss: 2.896214046197484
Validation loss: 2.77273551760967

Epoch: 5| Step: 2
Training loss: 3.2443071537349666
Validation loss: 2.7716970292693697

Epoch: 5| Step: 3
Training loss: 2.440473845388812
Validation loss: 2.7701790558212993

Epoch: 5| Step: 4
Training loss: 3.003687499654559
Validation loss: 2.768179706742897

Epoch: 5| Step: 5
Training loss: 2.863607806934468
Validation loss: 2.766029511519086

Epoch: 5| Step: 6
Training loss: 3.1594703788207914
Validation loss: 2.7637391566341756

Epoch: 5| Step: 7
Training loss: 3.0479042857803655
Validation loss: 2.762072233449289

Epoch: 5| Step: 8
Training loss: 3.041268222439098
Validation loss: 2.758756726280808

Epoch: 5| Step: 9
Training loss: 2.3957911501501834
Validation loss: 2.7576531750527162

Epoch: 5| Step: 10
Training loss: 2.9399637482153267
Validation loss: 2.7559546822068772

Epoch: 5| Step: 11
Training loss: 3.0947706292223915
Validation loss: 2.754122577223925

Epoch: 61| Step: 0
Training loss: 3.156856365311234
Validation loss: 2.7531704111211375

Epoch: 5| Step: 1
Training loss: 2.783833964280185
Validation loss: 2.765254665802722

Epoch: 5| Step: 2
Training loss: 3.0565925764993502
Validation loss: 2.771635507088091

Epoch: 5| Step: 3
Training loss: 2.71340047770409
Validation loss: 2.7560594730742505

Epoch: 5| Step: 4
Training loss: 2.772246628957304
Validation loss: 2.7483201278541225

Epoch: 5| Step: 5
Training loss: 3.1867407100114433
Validation loss: 2.7485221048807515

Epoch: 5| Step: 6
Training loss: 2.5360405882767263
Validation loss: 2.749452102873828

Epoch: 5| Step: 7
Training loss: 2.914155114877953
Validation loss: 2.7478396534822664

Epoch: 5| Step: 8
Training loss: 2.4056505719929544
Validation loss: 2.7468395170105118

Epoch: 5| Step: 9
Training loss: 2.8124644807056165
Validation loss: 2.7468485764761277

Epoch: 5| Step: 10
Training loss: 3.405667176387147
Validation loss: 2.7456663621217885

Epoch: 5| Step: 11
Training loss: 2.381922020789631
Validation loss: 2.744989664270228

Epoch: 62| Step: 0
Training loss: 3.0317366691114453
Validation loss: 2.743196448531818

Epoch: 5| Step: 1
Training loss: 2.622040851789802
Validation loss: 2.741342321929485

Epoch: 5| Step: 2
Training loss: 2.667605820820816
Validation loss: 2.7373326463799126

Epoch: 5| Step: 3
Training loss: 2.6013603246446375
Validation loss: 2.7344490368220358

Epoch: 5| Step: 4
Training loss: 2.797072931031
Validation loss: 2.7332449149062343

Epoch: 5| Step: 5
Training loss: 2.964975467213717
Validation loss: 2.730635292748043

Epoch: 5| Step: 6
Training loss: 3.442255233673122
Validation loss: 2.729420658600578

Epoch: 5| Step: 7
Training loss: 2.467400193906215
Validation loss: 2.7284512504278045

Epoch: 5| Step: 8
Training loss: 3.041784327770048
Validation loss: 2.726958001134287

Epoch: 5| Step: 9
Training loss: 2.605344755090427
Validation loss: 2.7268188632943096

Epoch: 5| Step: 10
Training loss: 2.9943739270753955
Validation loss: 2.7240972112746182

Epoch: 5| Step: 11
Training loss: 3.8473497607547444
Validation loss: 2.721058515827501

Epoch: 63| Step: 0
Training loss: 2.427093003762644
Validation loss: 2.7213958347665375

Epoch: 5| Step: 1
Training loss: 2.738403578786158
Validation loss: 2.719987631412041

Epoch: 5| Step: 2
Training loss: 2.6382825043200584
Validation loss: 2.7194825095455704

Epoch: 5| Step: 3
Training loss: 3.3358114249997977
Validation loss: 2.718975339152431

Epoch: 5| Step: 4
Training loss: 2.795332669845831
Validation loss: 2.7183709190895713

Epoch: 5| Step: 5
Training loss: 2.422468937063507
Validation loss: 2.7184670472796775

Epoch: 5| Step: 6
Training loss: 3.020604741008629
Validation loss: 2.71869722585503

Epoch: 5| Step: 7
Training loss: 2.6235042125042116
Validation loss: 2.7181598051954747

Epoch: 5| Step: 8
Training loss: 2.7414501100794606
Validation loss: 2.71526288060695

Epoch: 5| Step: 9
Training loss: 2.976199791303317
Validation loss: 2.7130972168167817

Epoch: 5| Step: 10
Training loss: 3.367435879850903
Validation loss: 2.7109463313212636

Epoch: 5| Step: 11
Training loss: 3.5842222545374995
Validation loss: 2.7093628002744197

Epoch: 64| Step: 0
Training loss: 2.349381255811038
Validation loss: 2.707234575453175

Epoch: 5| Step: 1
Training loss: 3.0500262274943344
Validation loss: 2.7055477280985483

Epoch: 5| Step: 2
Training loss: 2.692806770891459
Validation loss: 2.703213629620188

Epoch: 5| Step: 3
Training loss: 3.161246546648763
Validation loss: 2.7027774249226137

Epoch: 5| Step: 4
Training loss: 2.6552837633982285
Validation loss: 2.6997100964369714

Epoch: 5| Step: 5
Training loss: 2.799489764999318
Validation loss: 2.6991477769279224

Epoch: 5| Step: 6
Training loss: 3.2292454535604476
Validation loss: 2.696050168877803

Epoch: 5| Step: 7
Training loss: 3.2626884435257684
Validation loss: 2.6948613328239013

Epoch: 5| Step: 8
Training loss: 2.4519112858553496
Validation loss: 2.694026323175955

Epoch: 5| Step: 9
Training loss: 2.7546107047244477
Validation loss: 2.6919419632562827

Epoch: 5| Step: 10
Training loss: 2.780804716318694
Validation loss: 2.690083817844787

Epoch: 5| Step: 11
Training loss: 2.181568714893091
Validation loss: 2.68949176480773

Epoch: 65| Step: 0
Training loss: 2.349505262850793
Validation loss: 2.687593835478882

Epoch: 5| Step: 1
Training loss: 2.8918190629214306
Validation loss: 2.6846727684936194

Epoch: 5| Step: 2
Training loss: 2.6564783334765725
Validation loss: 2.684649460172665

Epoch: 5| Step: 3
Training loss: 2.7457117110674547
Validation loss: 2.6812261792290384

Epoch: 5| Step: 4
Training loss: 3.1110028936850256
Validation loss: 2.6803213135477026

Epoch: 5| Step: 5
Training loss: 2.806576998207763
Validation loss: 2.679653338037537

Epoch: 5| Step: 6
Training loss: 3.095970666918917
Validation loss: 2.6756427701214283

Epoch: 5| Step: 7
Training loss: 2.522041241580113
Validation loss: 2.6752766525551723

Epoch: 5| Step: 8
Training loss: 2.8514581530565746
Validation loss: 2.674240444614304

Epoch: 5| Step: 9
Training loss: 2.950595155583999
Validation loss: 2.6744981199866364

Epoch: 5| Step: 10
Training loss: 2.835784319479181
Validation loss: 2.6722277767194607

Epoch: 5| Step: 11
Training loss: 3.2762741871581014
Validation loss: 2.672884187230959

Epoch: 66| Step: 0
Training loss: 2.9402778963851683
Validation loss: 2.6701557212357465

Epoch: 5| Step: 1
Training loss: 2.4967013531436937
Validation loss: 2.6693320116925214

Epoch: 5| Step: 2
Training loss: 2.869810811629132
Validation loss: 2.669495082212411

Epoch: 5| Step: 3
Training loss: 3.163288841323242
Validation loss: 2.666589897262684

Epoch: 5| Step: 4
Training loss: 2.2885879180869315
Validation loss: 2.6655403132698763

Epoch: 5| Step: 5
Training loss: 2.6626722897944757
Validation loss: 2.666001834298075

Epoch: 5| Step: 6
Training loss: 3.1551310755952775
Validation loss: 2.6645698362599672

Epoch: 5| Step: 7
Training loss: 2.5981666923886904
Validation loss: 2.66152750337202

Epoch: 5| Step: 8
Training loss: 2.3559145782282616
Validation loss: 2.6610228797533937

Epoch: 5| Step: 9
Training loss: 3.2438087178760933
Validation loss: 2.6592379351272255

Epoch: 5| Step: 10
Training loss: 2.786371979608311
Validation loss: 2.656763408635308

Epoch: 5| Step: 11
Training loss: 3.207364584248873
Validation loss: 2.6549428827831423

Epoch: 67| Step: 0
Training loss: 3.0862462142853135
Validation loss: 2.6581452396320993

Epoch: 5| Step: 1
Training loss: 2.0427934560461423
Validation loss: 2.6586283676011586

Epoch: 5| Step: 2
Training loss: 3.0462348461126396
Validation loss: 2.66448297473171

Epoch: 5| Step: 3
Training loss: 3.144878486748118
Validation loss: 2.668179426909231

Epoch: 5| Step: 4
Training loss: 2.742268183464021
Validation loss: 2.6781670359721783

Epoch: 5| Step: 5
Training loss: 2.9554200311850733
Validation loss: 2.6747970404532455

Epoch: 5| Step: 6
Training loss: 2.680605005610852
Validation loss: 2.6635516805886987

Epoch: 5| Step: 7
Training loss: 2.8693344019612494
Validation loss: 2.652768523819801

Epoch: 5| Step: 8
Training loss: 2.4321286611780892
Validation loss: 2.6437707029934363

Epoch: 5| Step: 9
Training loss: 2.7521827878074636
Validation loss: 2.644565178237013

Epoch: 5| Step: 10
Training loss: 2.756135338714349
Validation loss: 2.64508179005731

Epoch: 5| Step: 11
Training loss: 2.5584774544180813
Validation loss: 2.6491396150550783

Epoch: 68| Step: 0
Training loss: 2.683402997251885
Validation loss: 2.6514669663006045

Epoch: 5| Step: 1
Training loss: 2.6923821040758953
Validation loss: 2.6535077282148687

Epoch: 5| Step: 2
Training loss: 2.734513546294731
Validation loss: 2.6555036094527034

Epoch: 5| Step: 3
Training loss: 3.247301448540445
Validation loss: 2.6554620920598917

Epoch: 5| Step: 4
Training loss: 3.054891359985405
Validation loss: 2.656465401984987

Epoch: 5| Step: 5
Training loss: 2.9572908597440963
Validation loss: 2.647883692090129

Epoch: 5| Step: 6
Training loss: 2.8850775196893235
Validation loss: 2.6448173236741788

Epoch: 5| Step: 7
Training loss: 2.547523649965069
Validation loss: 2.6413935684611243

Epoch: 5| Step: 8
Training loss: 2.283576197365883
Validation loss: 2.640034193801276

Epoch: 5| Step: 9
Training loss: 2.809214813791504
Validation loss: 2.6354627919338465

Epoch: 5| Step: 10
Training loss: 2.574458526419517
Validation loss: 2.631362878185931

Epoch: 5| Step: 11
Training loss: 3.3017167971979253
Validation loss: 2.629815098036773

Epoch: 69| Step: 0
Training loss: 2.95291395291049
Validation loss: 2.6285810755994192

Epoch: 5| Step: 1
Training loss: 2.864890527148279
Validation loss: 2.6282727714419813

Epoch: 5| Step: 2
Training loss: 2.7161113167480897
Validation loss: 2.626688886964391

Epoch: 5| Step: 3
Training loss: 2.575233363715606
Validation loss: 2.628283706118708

Epoch: 5| Step: 4
Training loss: 2.318415524607004
Validation loss: 2.632431361138926

Epoch: 5| Step: 5
Training loss: 2.8751937137524424
Validation loss: 2.632708738944364

Epoch: 5| Step: 6
Training loss: 2.649864779927118
Validation loss: 2.625687444831643

Epoch: 5| Step: 7
Training loss: 2.4648454910973445
Validation loss: 2.61942638836199

Epoch: 5| Step: 8
Training loss: 3.103519619746485
Validation loss: 2.618839327184706

Epoch: 5| Step: 9
Training loss: 3.1770826162535477
Validation loss: 2.620234659911999

Epoch: 5| Step: 10
Training loss: 2.366381718938807
Validation loss: 2.6178981328653537

Epoch: 5| Step: 11
Training loss: 3.655263653598648
Validation loss: 2.620688663415662

Epoch: 70| Step: 0
Training loss: 2.3583152361423694
Validation loss: 2.6193767254392206

Epoch: 5| Step: 1
Training loss: 2.9956675080805826
Validation loss: 2.618618576739713

Epoch: 5| Step: 2
Training loss: 2.6476160986842414
Validation loss: 2.61848218408744

Epoch: 5| Step: 3
Training loss: 2.694523615728122
Validation loss: 2.6189549224052846

Epoch: 5| Step: 4
Training loss: 2.6553318905332826
Validation loss: 2.615915568234783

Epoch: 5| Step: 5
Training loss: 3.1210990972556667
Validation loss: 2.614881549155874

Epoch: 5| Step: 6
Training loss: 2.5977304089508384
Validation loss: 2.615139842491222

Epoch: 5| Step: 7
Training loss: 2.674265634146376
Validation loss: 2.6111504116944735

Epoch: 5| Step: 8
Training loss: 2.9735834227220206
Validation loss: 2.611396946519664

Epoch: 5| Step: 9
Training loss: 2.931503994151229
Validation loss: 2.6113849596616348

Epoch: 5| Step: 10
Training loss: 2.755158441352654
Validation loss: 2.6080700472306333

Epoch: 5| Step: 11
Training loss: 1.5405947421122235
Validation loss: 2.6076817453257193

Epoch: 71| Step: 0
Training loss: 2.6448334333906285
Validation loss: 2.605718544457944

Epoch: 5| Step: 1
Training loss: 2.74768332955317
Validation loss: 2.6076293177005025

Epoch: 5| Step: 2
Training loss: 2.9103140359385207
Validation loss: 2.607545633986516

Epoch: 5| Step: 3
Training loss: 3.248617318274164
Validation loss: 2.6057581628811084

Epoch: 5| Step: 4
Training loss: 2.305517325282227
Validation loss: 2.602911731979295

Epoch: 5| Step: 5
Training loss: 2.44520154219856
Validation loss: 2.601465135571914

Epoch: 5| Step: 6
Training loss: 2.7350212859279104
Validation loss: 2.602896097490834

Epoch: 5| Step: 7
Training loss: 3.0342139471432423
Validation loss: 2.6027863137539353

Epoch: 5| Step: 8
Training loss: 2.622803722936406
Validation loss: 2.601596610577854

Epoch: 5| Step: 9
Training loss: 2.5739494958589737
Validation loss: 2.599105113489948

Epoch: 5| Step: 10
Training loss: 2.615617241158594
Validation loss: 2.6028330414415994

Epoch: 5| Step: 11
Training loss: 3.311762745702911
Validation loss: 2.6081127722988535

Epoch: 72| Step: 0
Training loss: 2.544917378161798
Validation loss: 2.6186659399605863

Epoch: 5| Step: 1
Training loss: 3.0231198481590185
Validation loss: 2.6172215720468768

Epoch: 5| Step: 2
Training loss: 2.504461694011314
Validation loss: 2.6149570924911196

Epoch: 5| Step: 3
Training loss: 3.385820069364918
Validation loss: 2.61519783266086

Epoch: 5| Step: 4
Training loss: 2.646571399341791
Validation loss: 2.599053659519224

Epoch: 5| Step: 5
Training loss: 2.7384182056346718
Validation loss: 2.5919709443025796

Epoch: 5| Step: 6
Training loss: 2.4697946197436336
Validation loss: 2.594095279891046

Epoch: 5| Step: 7
Training loss: 2.7754017925641787
Validation loss: 2.5954924020226717

Epoch: 5| Step: 8
Training loss: 2.7731346287365675
Validation loss: 2.597179673152913

Epoch: 5| Step: 9
Training loss: 2.4183583970176508
Validation loss: 2.596474296879683

Epoch: 5| Step: 10
Training loss: 2.8083415335998647
Validation loss: 2.5975245965852305

Epoch: 5| Step: 11
Training loss: 2.353046544604815
Validation loss: 2.5961658188823664

Epoch: 73| Step: 0
Training loss: 2.7811318704613766
Validation loss: 2.5937218530498822

Epoch: 5| Step: 1
Training loss: 2.728488624346317
Validation loss: 2.592522476225156

Epoch: 5| Step: 2
Training loss: 2.7920229290673793
Validation loss: 2.588972697967276

Epoch: 5| Step: 3
Training loss: 2.851626209958241
Validation loss: 2.5894197334564635

Epoch: 5| Step: 4
Training loss: 2.119688014340131
Validation loss: 2.586947087477556

Epoch: 5| Step: 5
Training loss: 2.582209547757318
Validation loss: 2.5862917662220015

Epoch: 5| Step: 6
Training loss: 2.4185842491745504
Validation loss: 2.585117325269253

Epoch: 5| Step: 7
Training loss: 3.078731419038324
Validation loss: 2.5853112375760534

Epoch: 5| Step: 8
Training loss: 3.242123669834778
Validation loss: 2.586105402694213

Epoch: 5| Step: 9
Training loss: 2.5777016031951305
Validation loss: 2.5823789546155878

Epoch: 5| Step: 10
Training loss: 2.619981873864524
Validation loss: 2.5786642955493315

Epoch: 5| Step: 11
Training loss: 2.6958461951804384
Validation loss: 2.5799016437338533

Epoch: 74| Step: 0
Training loss: 2.3628450858163874
Validation loss: 2.5781907583770662

Epoch: 5| Step: 1
Training loss: 2.3610554956605463
Validation loss: 2.5790246491986686

Epoch: 5| Step: 2
Training loss: 2.7025686584559168
Validation loss: 2.5819879240632186

Epoch: 5| Step: 3
Training loss: 2.5437981678294257
Validation loss: 2.579110567923841

Epoch: 5| Step: 4
Training loss: 2.8468277593350817
Validation loss: 2.576023971943153

Epoch: 5| Step: 5
Training loss: 2.953010516495779
Validation loss: 2.577111482325164

Epoch: 5| Step: 6
Training loss: 2.9959608543395326
Validation loss: 2.570242114586532

Epoch: 5| Step: 7
Training loss: 2.6512730365707378
Validation loss: 2.573429177600256

Epoch: 5| Step: 8
Training loss: 3.104819329452598
Validation loss: 2.5741050397951506

Epoch: 5| Step: 9
Training loss: 2.573990529526818
Validation loss: 2.572150310614721

Epoch: 5| Step: 10
Training loss: 2.7350638257656734
Validation loss: 2.5735204904465756

Epoch: 5| Step: 11
Training loss: 1.7452300322881755
Validation loss: 2.5734171837423787

Epoch: 75| Step: 0
Training loss: 2.8529103059411307
Validation loss: 2.572901916204222

Epoch: 5| Step: 1
Training loss: 2.4409207525082897
Validation loss: 2.5704577442629457

Epoch: 5| Step: 2
Training loss: 2.4774238700987383
Validation loss: 2.5713559576755527

Epoch: 5| Step: 3
Training loss: 2.683847029503936
Validation loss: 2.571860051410998

Epoch: 5| Step: 4
Training loss: 2.688225049531968
Validation loss: 2.572202213927938

Epoch: 5| Step: 5
Training loss: 2.6773757972725005
Validation loss: 2.568085030914441

Epoch: 5| Step: 6
Training loss: 3.188584535882381
Validation loss: 2.5719340812413987

Epoch: 5| Step: 7
Training loss: 2.8438475875039697
Validation loss: 2.571902833388597

Epoch: 5| Step: 8
Training loss: 2.5956056689932527
Validation loss: 2.5693263081865902

Epoch: 5| Step: 9
Training loss: 2.608155199575835
Validation loss: 2.5662668152530914

Epoch: 5| Step: 10
Training loss: 2.669329049320702
Validation loss: 2.5637248376175377

Epoch: 5| Step: 11
Training loss: 2.260144359400432
Validation loss: 2.5613253467523998

Epoch: 76| Step: 0
Training loss: 2.9641585330960574
Validation loss: 2.560101487574469

Epoch: 5| Step: 1
Training loss: 2.975858670221803
Validation loss: 2.560449264221606

Epoch: 5| Step: 2
Training loss: 2.5192899366633337
Validation loss: 2.559479580963881

Epoch: 5| Step: 3
Training loss: 2.4046445172231645
Validation loss: 2.561725925979576

Epoch: 5| Step: 4
Training loss: 2.9350921826938663
Validation loss: 2.562681222725784

Epoch: 5| Step: 5
Training loss: 2.54887583019293
Validation loss: 2.5589681725107236

Epoch: 5| Step: 6
Training loss: 2.5193330908629936
Validation loss: 2.559889033099301

Epoch: 5| Step: 7
Training loss: 2.4615638541324074
Validation loss: 2.5588898057951392

Epoch: 5| Step: 8
Training loss: 3.0114087292810385
Validation loss: 2.5608737251016764

Epoch: 5| Step: 9
Training loss: 2.7158782524833494
Validation loss: 2.5581801800959214

Epoch: 5| Step: 10
Training loss: 2.5702162147737755
Validation loss: 2.554150914838011

Epoch: 5| Step: 11
Training loss: 2.2099556511964504
Validation loss: 2.560791903987307

Epoch: 77| Step: 0
Training loss: 2.1196846399930487
Validation loss: 2.561185111767103

Epoch: 5| Step: 1
Training loss: 2.7918510281242668
Validation loss: 2.563793731929002

Epoch: 5| Step: 2
Training loss: 2.48434486610803
Validation loss: 2.577917633964867

Epoch: 5| Step: 3
Training loss: 3.2629056130312413
Validation loss: 2.5802803316467706

Epoch: 5| Step: 4
Training loss: 2.656537029241628
Validation loss: 2.5777069639122496

Epoch: 5| Step: 5
Training loss: 3.07572262344511
Validation loss: 2.5560876351721813

Epoch: 5| Step: 6
Training loss: 2.7621850641168444
Validation loss: 2.55430392886468

Epoch: 5| Step: 7
Training loss: 2.3586098143822443
Validation loss: 2.5484217489080505

Epoch: 5| Step: 8
Training loss: 2.601875721631029
Validation loss: 2.548598090810429

Epoch: 5| Step: 9
Training loss: 2.417056501669579
Validation loss: 2.544873713137406

Epoch: 5| Step: 10
Training loss: 2.9504639276918536
Validation loss: 2.546343636811217

Epoch: 5| Step: 11
Training loss: 2.7930380645900663
Validation loss: 2.5487373813343597

Epoch: 78| Step: 0
Training loss: 2.8709769919392647
Validation loss: 2.5480092727122114

Epoch: 5| Step: 1
Training loss: 2.554379319200628
Validation loss: 2.546565027232954

Epoch: 5| Step: 2
Training loss: 2.603315432979897
Validation loss: 2.5451841612000545

Epoch: 5| Step: 3
Training loss: 2.469822710910165
Validation loss: 2.5450203584482534

Epoch: 5| Step: 4
Training loss: 2.8951016789370763
Validation loss: 2.5450750945490728

Epoch: 5| Step: 5
Training loss: 2.919243591526319
Validation loss: 2.54531950538878

Epoch: 5| Step: 6
Training loss: 2.6236440698794907
Validation loss: 2.545585727252905

Epoch: 5| Step: 7
Training loss: 2.8249796031114287
Validation loss: 2.545007680333008

Epoch: 5| Step: 8
Training loss: 2.431117578347155
Validation loss: 2.545270289443221

Epoch: 5| Step: 9
Training loss: 2.415570525706224
Validation loss: 2.5479653760590177

Epoch: 5| Step: 10
Training loss: 2.9502900255816185
Validation loss: 2.544988709882514

Epoch: 5| Step: 11
Training loss: 1.6671645930681975
Validation loss: 2.5426336556959575

Epoch: 79| Step: 0
Training loss: 2.5079290535244825
Validation loss: 2.546261067885282

Epoch: 5| Step: 1
Training loss: 2.3935565800622363
Validation loss: 2.545236684670381

Epoch: 5| Step: 2
Training loss: 3.0158186934334426
Validation loss: 2.5460426398008202

Epoch: 5| Step: 3
Training loss: 2.5244627012661978
Validation loss: 2.546107755834936

Epoch: 5| Step: 4
Training loss: 2.8230709207391422
Validation loss: 2.544441004007652

Epoch: 5| Step: 5
Training loss: 2.6165552998389847
Validation loss: 2.543117184855485

Epoch: 5| Step: 6
Training loss: 2.56712955866859
Validation loss: 2.5440197055748723

Epoch: 5| Step: 7
Training loss: 2.6989832553181565
Validation loss: 2.539580353966442

Epoch: 5| Step: 8
Training loss: 2.898297987713813
Validation loss: 2.539189203475511

Epoch: 5| Step: 9
Training loss: 2.458889935947124
Validation loss: 2.53482623663449

Epoch: 5| Step: 10
Training loss: 2.6409752968929543
Validation loss: 2.538683631213523

Epoch: 5| Step: 11
Training loss: 3.542151040258503
Validation loss: 2.5343263048353584

Epoch: 80| Step: 0
Training loss: 2.8994640578587867
Validation loss: 2.535565708129441

Epoch: 5| Step: 1
Training loss: 2.4351293332885895
Validation loss: 2.5382610601638014

Epoch: 5| Step: 2
Training loss: 3.067100650375878
Validation loss: 2.5396649081298386

Epoch: 5| Step: 3
Training loss: 2.75757154757521
Validation loss: 2.537706590175904

Epoch: 5| Step: 4
Training loss: 2.623741211388032
Validation loss: 2.5364626206212297

Epoch: 5| Step: 5
Training loss: 2.268761404129665
Validation loss: 2.5391432020615756

Epoch: 5| Step: 6
Training loss: 2.5189899188328724
Validation loss: 2.539162032303954

Epoch: 5| Step: 7
Training loss: 2.9985454529953683
Validation loss: 2.541262505921632

Epoch: 5| Step: 8
Training loss: 2.78274050431503
Validation loss: 2.5402184970184867

Epoch: 5| Step: 9
Training loss: 2.196832639630386
Validation loss: 2.5390327060614237

Epoch: 5| Step: 10
Training loss: 2.9154831437807904
Validation loss: 2.5407641181534784

Epoch: 5| Step: 11
Training loss: 1.2278434721937737
Validation loss: 2.5366242855126595

Epoch: 81| Step: 0
Training loss: 2.9427096656638763
Validation loss: 2.539133847530221

Epoch: 5| Step: 1
Training loss: 2.2087797277551666
Validation loss: 2.53746897846045

Epoch: 5| Step: 2
Training loss: 2.297237237924531
Validation loss: 2.5349731927817403

Epoch: 5| Step: 3
Training loss: 2.916124202600128
Validation loss: 2.532874892711802

Epoch: 5| Step: 4
Training loss: 2.602411904726612
Validation loss: 2.5379132570080882

Epoch: 5| Step: 5
Training loss: 2.3863145451636236
Validation loss: 2.534949722851099

Epoch: 5| Step: 6
Training loss: 2.6387943038943718
Validation loss: 2.53448431576534

Epoch: 5| Step: 7
Training loss: 2.6669338112374907
Validation loss: 2.5317972714042267

Epoch: 5| Step: 8
Training loss: 3.0844384524109776
Validation loss: 2.530942160328948

Epoch: 5| Step: 9
Training loss: 3.0380456002726386
Validation loss: 2.528967554360675

Epoch: 5| Step: 10
Training loss: 2.4796803580687854
Validation loss: 2.533101652608631

Epoch: 5| Step: 11
Training loss: 2.0480136179620265
Validation loss: 2.529845146150698

Epoch: 82| Step: 0
Training loss: 3.1709867088595107
Validation loss: 2.5286654593704276

Epoch: 5| Step: 1
Training loss: 2.0733562623173865
Validation loss: 2.527420648095773

Epoch: 5| Step: 2
Training loss: 2.2841188341950085
Validation loss: 2.525985702733685

Epoch: 5| Step: 3
Training loss: 2.905925281391081
Validation loss: 2.527253569419409

Epoch: 5| Step: 4
Training loss: 3.040148386596354
Validation loss: 2.529517365692293

Epoch: 5| Step: 5
Training loss: 2.27001317696801
Validation loss: 2.5263223210319707

Epoch: 5| Step: 6
Training loss: 2.9132830111640726
Validation loss: 2.5267761041091648

Epoch: 5| Step: 7
Training loss: 2.5846816410316067
Validation loss: 2.52822332784331

Epoch: 5| Step: 8
Training loss: 2.8846753725514565
Validation loss: 2.5287676204709246

Epoch: 5| Step: 9
Training loss: 1.7650476372533637
Validation loss: 2.5269536499016603

Epoch: 5| Step: 10
Training loss: 2.8909639726819867
Validation loss: 2.518491722760544

Epoch: 5| Step: 11
Training loss: 2.8044971624622894
Validation loss: 2.5244446664673057

Epoch: 83| Step: 0
Training loss: 2.779799007861699
Validation loss: 2.5255976348945124

Epoch: 5| Step: 1
Training loss: 2.996131787313549
Validation loss: 2.522910146654956

Epoch: 5| Step: 2
Training loss: 2.6758542238851746
Validation loss: 2.5245169426166973

Epoch: 5| Step: 3
Training loss: 2.403208209557867
Validation loss: 2.524224862166364

Epoch: 5| Step: 4
Training loss: 2.731128967536483
Validation loss: 2.5276667699496476

Epoch: 5| Step: 5
Training loss: 2.610076353191325
Validation loss: 2.526805378145579

Epoch: 5| Step: 6
Training loss: 2.4554193543318505
Validation loss: 2.523494755240066

Epoch: 5| Step: 7
Training loss: 2.3659703112276875
Validation loss: 2.5276341219896326

Epoch: 5| Step: 8
Training loss: 2.8022858689485255
Validation loss: 2.5240482539963947

Epoch: 5| Step: 9
Training loss: 2.5832744612189553
Validation loss: 2.5235311020378814

Epoch: 5| Step: 10
Training loss: 2.8830409179176084
Validation loss: 2.522301921294824

Epoch: 5| Step: 11
Training loss: 1.6271896281996778
Validation loss: 2.521270498615756

Epoch: 84| Step: 0
Training loss: 2.688470532139986
Validation loss: 2.525578054507692

Epoch: 5| Step: 1
Training loss: 2.3199150181694845
Validation loss: 2.525221006396618

Epoch: 5| Step: 2
Training loss: 2.7868546153604354
Validation loss: 2.5240606398766685

Epoch: 5| Step: 3
Training loss: 2.670213863365787
Validation loss: 2.5239302997446575

Epoch: 5| Step: 4
Training loss: 2.808176235102601
Validation loss: 2.524838608755156

Epoch: 5| Step: 5
Training loss: 2.8649785734377358
Validation loss: 2.52072878823093

Epoch: 5| Step: 6
Training loss: 2.40436777588265
Validation loss: 2.522492833267531

Epoch: 5| Step: 7
Training loss: 2.785070474167852
Validation loss: 2.522928011296725

Epoch: 5| Step: 8
Training loss: 2.538657851619937
Validation loss: 2.5224933097909426

Epoch: 5| Step: 9
Training loss: 2.3019504652618057
Validation loss: 2.5185248560653006

Epoch: 5| Step: 10
Training loss: 2.689944286833069
Validation loss: 2.5218034616728593

Epoch: 5| Step: 11
Training loss: 3.5958462116339414
Validation loss: 2.517473157968778

Epoch: 85| Step: 0
Training loss: 2.5124645401459347
Validation loss: 2.5178231652024357

Epoch: 5| Step: 1
Training loss: 2.5259814592769847
Validation loss: 2.5168648067584027

Epoch: 5| Step: 2
Training loss: 2.7115650165296032
Validation loss: 2.5181099877596824

Epoch: 5| Step: 3
Training loss: 2.398633321416158
Validation loss: 2.516775918372333

Epoch: 5| Step: 4
Training loss: 2.138263820232899
Validation loss: 2.518035310517855

Epoch: 5| Step: 5
Training loss: 2.67634173460973
Validation loss: 2.5221881076479744

Epoch: 5| Step: 6
Training loss: 2.5260004308946353
Validation loss: 2.5287569665239293

Epoch: 5| Step: 7
Training loss: 3.3122300811774443
Validation loss: 2.5226919098231066

Epoch: 5| Step: 8
Training loss: 2.597682683136188
Validation loss: 2.513396012098463

Epoch: 5| Step: 9
Training loss: 2.93274856359492
Validation loss: 2.514487036799858

Epoch: 5| Step: 10
Training loss: 2.738796909336214
Validation loss: 2.5156408826749157

Epoch: 5| Step: 11
Training loss: 1.8421105676947491
Validation loss: 2.512723876854022

Epoch: 86| Step: 0
Training loss: 2.19700247990256
Validation loss: 2.5068792327760163

Epoch: 5| Step: 1
Training loss: 2.8471222050992195
Validation loss: 2.5188269564765102

Epoch: 5| Step: 2
Training loss: 2.9043132932874864
Validation loss: 2.527746935861208

Epoch: 5| Step: 3
Training loss: 2.7094367982708993
Validation loss: 2.5260076671291687

Epoch: 5| Step: 4
Training loss: 2.8362295457515154
Validation loss: 2.5334619131574967

Epoch: 5| Step: 5
Training loss: 2.728136193251397
Validation loss: 2.5600603477001034

Epoch: 5| Step: 6
Training loss: 3.324194651425576
Validation loss: 2.539724762451814

Epoch: 5| Step: 7
Training loss: 2.491868145131714
Validation loss: 2.516532090727828

Epoch: 5| Step: 8
Training loss: 2.1004916160614133
Validation loss: 2.5127357769250693

Epoch: 5| Step: 9
Training loss: 2.5380399082614393
Validation loss: 2.5132350309859572

Epoch: 5| Step: 10
Training loss: 2.551511230701187
Validation loss: 2.517480225357535

Epoch: 5| Step: 11
Training loss: 2.1017902917322466
Validation loss: 2.5259631757569028

Epoch: 87| Step: 0
Training loss: 2.386099527449561
Validation loss: 2.5722391006002017

Epoch: 5| Step: 1
Training loss: 2.801318937693445
Validation loss: 2.6001183565417185

Epoch: 5| Step: 2
Training loss: 3.0317841678586746
Validation loss: 2.6240621246147424

Epoch: 5| Step: 3
Training loss: 2.750815270692109
Validation loss: 2.6385532167053634

Epoch: 5| Step: 4
Training loss: 2.9528411244387596
Validation loss: 2.6693198905096467

Epoch: 5| Step: 5
Training loss: 2.6004436481210704
Validation loss: 2.6729391072303263

Epoch: 5| Step: 6
Training loss: 3.4541986099686532
Validation loss: 2.669372420199943

Epoch: 5| Step: 7
Training loss: 2.6637412853626494
Validation loss: 2.660259773230467

Epoch: 5| Step: 8
Training loss: 2.296928768436877
Validation loss: 2.6306530957252185

Epoch: 5| Step: 9
Training loss: 2.42553925958086
Validation loss: 2.6122033899934958

Epoch: 5| Step: 10
Training loss: 2.673204860676101
Validation loss: 2.556449084468941

Epoch: 5| Step: 11
Training loss: 3.1221211715340598
Validation loss: 2.522965571126134

Epoch: 88| Step: 0
Training loss: 3.1452570675827434
Validation loss: 2.510123870257676

Epoch: 5| Step: 1
Training loss: 2.7824324762286197
Validation loss: 2.509629475701757

Epoch: 5| Step: 2
Training loss: 2.3785015194117993
Validation loss: 2.509904102112073

Epoch: 5| Step: 3
Training loss: 2.4400425879091836
Validation loss: 2.5043117117542684

Epoch: 5| Step: 4
Training loss: 2.4676014606676184
Validation loss: 2.507797847241528

Epoch: 5| Step: 5
Training loss: 2.494503941731446
Validation loss: 2.523300879749322

Epoch: 5| Step: 6
Training loss: 2.583180874253227
Validation loss: 2.5280984639023507

Epoch: 5| Step: 7
Training loss: 2.237557658725926
Validation loss: 2.521127614007731

Epoch: 5| Step: 8
Training loss: 2.932099592965984
Validation loss: 2.524817661116226

Epoch: 5| Step: 9
Training loss: 2.7174172478142293
Validation loss: 2.509073275252629

Epoch: 5| Step: 10
Training loss: 2.819193187306602
Validation loss: 2.504737926157199

Epoch: 5| Step: 11
Training loss: 2.6445914730725884
Validation loss: 2.5013522424919366

Epoch: 89| Step: 0
Training loss: 2.485199605497031
Validation loss: 2.5049868080606514

Epoch: 5| Step: 1
Training loss: 2.6000835808744607
Validation loss: 2.5032643463933635

Epoch: 5| Step: 2
Training loss: 2.650830833180446
Validation loss: 2.5039646342230757

Epoch: 5| Step: 3
Training loss: 2.688203675166007
Validation loss: 2.508005025887004

Epoch: 5| Step: 4
Training loss: 2.1890233866146787
Validation loss: 2.5131564892669185

Epoch: 5| Step: 5
Training loss: 2.739345370982534
Validation loss: 2.514656318726272

Epoch: 5| Step: 6
Training loss: 2.6593925287227105
Validation loss: 2.5156642089378685

Epoch: 5| Step: 7
Training loss: 2.956405996840058
Validation loss: 2.5182411656427504

Epoch: 5| Step: 8
Training loss: 2.5678140387658734
Validation loss: 2.5187030505465766

Epoch: 5| Step: 9
Training loss: 2.510838284576764
Validation loss: 2.5184183191046383

Epoch: 5| Step: 10
Training loss: 2.743285043723259
Validation loss: 2.5195135229310157

Epoch: 5| Step: 11
Training loss: 3.4497376825978163
Validation loss: 2.517428286887509

Epoch: 90| Step: 0
Training loss: 2.4171947910664926
Validation loss: 2.518550041029767

Epoch: 5| Step: 1
Training loss: 2.308609757472792
Validation loss: 2.5148173866181835

Epoch: 5| Step: 2
Training loss: 2.8095067520562846
Validation loss: 2.5151542515342014

Epoch: 5| Step: 3
Training loss: 2.5182531619317676
Validation loss: 2.515630050717293

Epoch: 5| Step: 4
Training loss: 3.240249826901448
Validation loss: 2.5130495428840285

Epoch: 5| Step: 5
Training loss: 2.741147618501867
Validation loss: 2.5133006452358106

Epoch: 5| Step: 6
Training loss: 2.9802173993478207
Validation loss: 2.5121422307313654

Epoch: 5| Step: 7
Training loss: 2.469540433254141
Validation loss: 2.511084662925734

Epoch: 5| Step: 8
Training loss: 2.5315863303454504
Validation loss: 2.5064849310565984

Epoch: 5| Step: 9
Training loss: 2.286616975209162
Validation loss: 2.5060694054711563

Epoch: 5| Step: 10
Training loss: 2.4716793981195506
Validation loss: 2.5065092104954316

Epoch: 5| Step: 11
Training loss: 3.005100682455471
Validation loss: 2.504387522133732

Epoch: 91| Step: 0
Training loss: 2.617987302727504
Validation loss: 2.5005658542484355

Epoch: 5| Step: 1
Training loss: 2.6567909138757027
Validation loss: 2.4972104165172144

Epoch: 5| Step: 2
Training loss: 2.726158571244987
Validation loss: 2.497761972349739

Epoch: 5| Step: 3
Training loss: 2.815801166607718
Validation loss: 2.497706982929924

Epoch: 5| Step: 4
Training loss: 2.4786828047069873
Validation loss: 2.499951620428541

Epoch: 5| Step: 5
Training loss: 2.6183945334906875
Validation loss: 2.498894542427428

Epoch: 5| Step: 6
Training loss: 2.4467182445373346
Validation loss: 2.4985265124704927

Epoch: 5| Step: 7
Training loss: 2.5540444034190615
Validation loss: 2.4999334525152164

Epoch: 5| Step: 8
Training loss: 3.083967212438391
Validation loss: 2.4954529100317875

Epoch: 5| Step: 9
Training loss: 2.074675371445158
Validation loss: 2.504570621421623

Epoch: 5| Step: 10
Training loss: 2.67627821713663
Validation loss: 2.509563741715685

Epoch: 5| Step: 11
Training loss: 2.399802946902091
Validation loss: 2.5040229417069355

Epoch: 92| Step: 0
Training loss: 2.2948489433225134
Validation loss: 2.5034379605508836

Epoch: 5| Step: 1
Training loss: 2.3403924925849817
Validation loss: 2.4984214567488836

Epoch: 5| Step: 2
Training loss: 2.1096080510002837
Validation loss: 2.49315222839344

Epoch: 5| Step: 3
Training loss: 2.3707781963495913
Validation loss: 2.4907010228366033

Epoch: 5| Step: 4
Training loss: 3.3593518633378414
Validation loss: 2.492258666805178

Epoch: 5| Step: 5
Training loss: 2.7142713643175127
Validation loss: 2.4920771184730137

Epoch: 5| Step: 6
Training loss: 2.9803469971752916
Validation loss: 2.493914046982692

Epoch: 5| Step: 7
Training loss: 2.7385642957036596
Validation loss: 2.4963411398620106

Epoch: 5| Step: 8
Training loss: 2.7927818822703028
Validation loss: 2.4977968999059814

Epoch: 5| Step: 9
Training loss: 2.45710295798456
Validation loss: 2.4978609987747276

Epoch: 5| Step: 10
Training loss: 2.5230945082422047
Validation loss: 2.5009880855105675

Epoch: 5| Step: 11
Training loss: 2.8608948050729444
Validation loss: 2.498790635215381

Epoch: 93| Step: 0
Training loss: 3.2150285558782064
Validation loss: 2.5001358233749165

Epoch: 5| Step: 1
Training loss: 2.617246803636646
Validation loss: 2.5002856369555704

Epoch: 5| Step: 2
Training loss: 2.824829626431562
Validation loss: 2.50025003295518

Epoch: 5| Step: 3
Training loss: 2.4365971189072155
Validation loss: 2.498665978229405

Epoch: 5| Step: 4
Training loss: 2.343515816750938
Validation loss: 2.496545101106258

Epoch: 5| Step: 5
Training loss: 2.2998617047735683
Validation loss: 2.4945672053035617

Epoch: 5| Step: 6
Training loss: 2.5625642907986363
Validation loss: 2.494477526345772

Epoch: 5| Step: 7
Training loss: 2.442202799743642
Validation loss: 2.4925808451648197

Epoch: 5| Step: 8
Training loss: 2.586225142140538
Validation loss: 2.4924948571552874

Epoch: 5| Step: 9
Training loss: 2.729353386313167
Validation loss: 2.4910788147753835

Epoch: 5| Step: 10
Training loss: 2.8212275407579157
Validation loss: 2.4893514686147182

Epoch: 5| Step: 11
Training loss: 1.722173644819821
Validation loss: 2.488619435562764

Epoch: 94| Step: 0
Training loss: 2.7202946451423937
Validation loss: 2.4863990959352704

Epoch: 5| Step: 1
Training loss: 2.849831251536035
Validation loss: 2.4903199184908944

Epoch: 5| Step: 2
Training loss: 2.4261407508997226
Validation loss: 2.488446176793171

Epoch: 5| Step: 3
Training loss: 2.5542173740483367
Validation loss: 2.4916205284435637

Epoch: 5| Step: 4
Training loss: 2.5199390643185042
Validation loss: 2.49392866978079

Epoch: 5| Step: 5
Training loss: 2.7870794346784447
Validation loss: 2.493878830025516

Epoch: 5| Step: 6
Training loss: 2.699182888295147
Validation loss: 2.489678234754875

Epoch: 5| Step: 7
Training loss: 2.573835468846235
Validation loss: 2.484831084366826

Epoch: 5| Step: 8
Training loss: 2.1701862163893106
Validation loss: 2.4916871344853715

Epoch: 5| Step: 9
Training loss: 2.6642154414779635
Validation loss: 2.490012731723842

Epoch: 5| Step: 10
Training loss: 2.786532154472023
Validation loss: 2.483897497164862

Epoch: 5| Step: 11
Training loss: 2.3015012278432345
Validation loss: 2.4905735438131673

Epoch: 95| Step: 0
Training loss: 2.216860221596289
Validation loss: 2.487521252629212

Epoch: 5| Step: 1
Training loss: 2.8564424746246586
Validation loss: 2.4881501934325487

Epoch: 5| Step: 2
Training loss: 2.500036143995314
Validation loss: 2.4893416097171723

Epoch: 5| Step: 3
Training loss: 2.9649351002890065
Validation loss: 2.4866927669380936

Epoch: 5| Step: 4
Training loss: 2.4117980014741183
Validation loss: 2.48587481893036

Epoch: 5| Step: 5
Training loss: 2.5407766336795916
Validation loss: 2.4869812584247413

Epoch: 5| Step: 6
Training loss: 2.39850221229755
Validation loss: 2.4870680841391812

Epoch: 5| Step: 7
Training loss: 2.832008351200528
Validation loss: 2.4911729148516204

Epoch: 5| Step: 8
Training loss: 2.5900144218720813
Validation loss: 2.4847626053843195

Epoch: 5| Step: 9
Training loss: 2.816501060297377
Validation loss: 2.485360683781662

Epoch: 5| Step: 10
Training loss: 2.502251755389748
Validation loss: 2.4839069197408

Epoch: 5| Step: 11
Training loss: 2.3206271077091785
Validation loss: 2.4826276660360227

Epoch: 96| Step: 0
Training loss: 2.2270987952337653
Validation loss: 2.485768437226352

Epoch: 5| Step: 1
Training loss: 2.3426204757080877
Validation loss: 2.4813824870485814

Epoch: 5| Step: 2
Training loss: 2.1443409096996957
Validation loss: 2.477454032035242

Epoch: 5| Step: 3
Training loss: 2.201965134936258
Validation loss: 2.48020574421903

Epoch: 5| Step: 4
Training loss: 2.5995163761187334
Validation loss: 2.4761088704923155

Epoch: 5| Step: 5
Training loss: 2.565200034478486
Validation loss: 2.480083005051872

Epoch: 5| Step: 6
Training loss: 3.133272741286507
Validation loss: 2.481155492678722

Epoch: 5| Step: 7
Training loss: 2.9537209207247144
Validation loss: 2.47995658252637

Epoch: 5| Step: 8
Training loss: 2.7603169165288417
Validation loss: 2.4841507304628556

Epoch: 5| Step: 9
Training loss: 2.6281129453475582
Validation loss: 2.4849959503156183

Epoch: 5| Step: 10
Training loss: 2.8831518950366655
Validation loss: 2.4821890524975765

Epoch: 5| Step: 11
Training loss: 2.458509428107458
Validation loss: 2.486697049475193

Epoch: 97| Step: 0
Training loss: 2.4088889179644206
Validation loss: 2.4884384041768226

Epoch: 5| Step: 1
Training loss: 2.3472997613723665
Validation loss: 2.4871053627045305

Epoch: 5| Step: 2
Training loss: 2.606617549895289
Validation loss: 2.4902333896610083

Epoch: 5| Step: 3
Training loss: 2.0544468263720375
Validation loss: 2.485723849070291

Epoch: 5| Step: 4
Training loss: 2.5754296286968095
Validation loss: 2.4869334884096963

Epoch: 5| Step: 5
Training loss: 2.9278736246800627
Validation loss: 2.487066610240351

Epoch: 5| Step: 6
Training loss: 2.746134034644061
Validation loss: 2.4847398765895843

Epoch: 5| Step: 7
Training loss: 2.8148500584836853
Validation loss: 2.483644178049941

Epoch: 5| Step: 8
Training loss: 3.0613553769163118
Validation loss: 2.4803075542787543

Epoch: 5| Step: 9
Training loss: 2.7323923825137273
Validation loss: 2.482874003009282

Epoch: 5| Step: 10
Training loss: 2.3314889248481223
Validation loss: 2.477062343372662

Epoch: 5| Step: 11
Training loss: 1.3185572496902644
Validation loss: 2.478698996235403

Epoch: 98| Step: 0
Training loss: 2.896920601528046
Validation loss: 2.479990186607777

Epoch: 5| Step: 1
Training loss: 2.934299917347211
Validation loss: 2.4802095653259046

Epoch: 5| Step: 2
Training loss: 2.527513265452301
Validation loss: 2.4832866292013662

Epoch: 5| Step: 3
Training loss: 2.162582387071434
Validation loss: 2.476835887592743

Epoch: 5| Step: 4
Training loss: 2.314677476270254
Validation loss: 2.48281386247153

Epoch: 5| Step: 5
Training loss: 3.151517889854157
Validation loss: 2.4770470515214997

Epoch: 5| Step: 6
Training loss: 1.980504985530504
Validation loss: 2.48208238474766

Epoch: 5| Step: 7
Training loss: 2.5887097944363697
Validation loss: 2.478594863622978

Epoch: 5| Step: 8
Training loss: 2.8571640388521042
Validation loss: 2.482105069838267

Epoch: 5| Step: 9
Training loss: 2.359179659203214
Validation loss: 2.4829251879371785

Epoch: 5| Step: 10
Training loss: 2.420113889205393
Validation loss: 2.482311911639793

Epoch: 5| Step: 11
Training loss: 2.6861661217873123
Validation loss: 2.483630430661267

Epoch: 99| Step: 0
Training loss: 2.3362121420579456
Validation loss: 2.4827879308913734

Epoch: 5| Step: 1
Training loss: 2.765066144265907
Validation loss: 2.4862711885679993

Epoch: 5| Step: 2
Training loss: 2.664727002273041
Validation loss: 2.4884226951939574

Epoch: 5| Step: 3
Training loss: 2.448409194636612
Validation loss: 2.4871168021951

Epoch: 5| Step: 4
Training loss: 2.4327943814680353
Validation loss: 2.487266485317509

Epoch: 5| Step: 5
Training loss: 2.451063516964988
Validation loss: 2.489088226044925

Epoch: 5| Step: 6
Training loss: 2.869300001689406
Validation loss: 2.4862275104486877

Epoch: 5| Step: 7
Training loss: 2.777972229403387
Validation loss: 2.48974973662487

Epoch: 5| Step: 8
Training loss: 2.251531821259645
Validation loss: 2.4854831863054097

Epoch: 5| Step: 9
Training loss: 3.0274596751998097
Validation loss: 2.484649571055023

Epoch: 5| Step: 10
Training loss: 2.540505149050778
Validation loss: 2.486920338412569

Epoch: 5| Step: 11
Training loss: 2.4262382334876365
Validation loss: 2.486235495752445

Epoch: 100| Step: 0
Training loss: 2.724625738498129
Validation loss: 2.485948995695103

Epoch: 5| Step: 1
Training loss: 2.8047205675986318
Validation loss: 2.486205040781079

Epoch: 5| Step: 2
Training loss: 2.244693113731854
Validation loss: 2.4839107071583233

Epoch: 5| Step: 3
Training loss: 2.867708330377278
Validation loss: 2.481019407010134

Epoch: 5| Step: 4
Training loss: 2.141409180398054
Validation loss: 2.483434911118294

Epoch: 5| Step: 5
Training loss: 2.7588412605681363
Validation loss: 2.4833077351533035

Epoch: 5| Step: 6
Training loss: 2.486609647504509
Validation loss: 2.47638992205665

Epoch: 5| Step: 7
Training loss: 2.3690708838856542
Validation loss: 2.4813409868688923

Epoch: 5| Step: 8
Training loss: 2.6046587873225286
Validation loss: 2.4804398342259386

Epoch: 5| Step: 9
Training loss: 2.754649306891002
Validation loss: 2.4831703312286484

Epoch: 5| Step: 10
Training loss: 2.5491501644914347
Validation loss: 2.4803592447454217

Epoch: 5| Step: 11
Training loss: 3.5010979156530646
Validation loss: 2.4794887138543693

Epoch: 101| Step: 0
Training loss: 2.592165543438506
Validation loss: 2.4808589197910305

Epoch: 5| Step: 1
Training loss: 2.5110134718581802
Validation loss: 2.477734141174623

Epoch: 5| Step: 2
Training loss: 2.825315059546362
Validation loss: 2.4808874142379227

Epoch: 5| Step: 3
Training loss: 3.121441608088724
Validation loss: 2.4813625857852797

Epoch: 5| Step: 4
Training loss: 2.2842852114292866
Validation loss: 2.4780507474649127

Epoch: 5| Step: 5
Training loss: 2.1759502132975173
Validation loss: 2.4723016967809994

Epoch: 5| Step: 6
Training loss: 2.6552057345290176
Validation loss: 2.4771685575727695

Epoch: 5| Step: 7
Training loss: 2.600255872900439
Validation loss: 2.472094997931648

Epoch: 5| Step: 8
Training loss: 2.286375688755156
Validation loss: 2.476683937569166

Epoch: 5| Step: 9
Training loss: 2.591636164036994
Validation loss: 2.472198729248673

Epoch: 5| Step: 10
Training loss: 2.6796772681394034
Validation loss: 2.4781947608355157

Epoch: 5| Step: 11
Training loss: 2.006142482075047
Validation loss: 2.4764124587182947

Epoch: 102| Step: 0
Training loss: 2.3317335184733
Validation loss: 2.47939540438265

Epoch: 5| Step: 1
Training loss: 2.93167429376694
Validation loss: 2.476482225595243

Epoch: 5| Step: 2
Training loss: 2.7475271377403407
Validation loss: 2.4755011409203935

Epoch: 5| Step: 3
Training loss: 2.2892268515684275
Validation loss: 2.4745078363338817

Epoch: 5| Step: 4
Training loss: 2.4049344120083633
Validation loss: 2.4833413258899704

Epoch: 5| Step: 5
Training loss: 2.1575629618310415
Validation loss: 2.4838880705537614

Epoch: 5| Step: 6
Training loss: 3.132474581409054
Validation loss: 2.4839642183114194

Epoch: 5| Step: 7
Training loss: 2.5644734854663467
Validation loss: 2.4834811083991153

Epoch: 5| Step: 8
Training loss: 2.470653138390093
Validation loss: 2.4812098399771

Epoch: 5| Step: 9
Training loss: 2.574357765623501
Validation loss: 2.4843906266142866

Epoch: 5| Step: 10
Training loss: 2.9660624335232906
Validation loss: 2.4842846772031324

Epoch: 5| Step: 11
Training loss: 2.5463057741958495
Validation loss: 2.484369625829486

Epoch: 103| Step: 0
Training loss: 3.0418155233111106
Validation loss: 2.4846186568377266

Epoch: 5| Step: 1
Training loss: 2.835654168385684
Validation loss: 2.483340577833972

Epoch: 5| Step: 2
Training loss: 2.644294130859971
Validation loss: 2.484780684322897

Epoch: 5| Step: 3
Training loss: 2.883368379089583
Validation loss: 2.4843053308151073

Epoch: 5| Step: 4
Training loss: 2.4045215690725783
Validation loss: 2.4838420348225427

Epoch: 5| Step: 5
Training loss: 2.5086593386505633
Validation loss: 2.4832273987655866

Epoch: 5| Step: 6
Training loss: 2.6121333727412397
Validation loss: 2.4819238875041267

Epoch: 5| Step: 7
Training loss: 2.69004851754832
Validation loss: 2.4786478322477885

Epoch: 5| Step: 8
Training loss: 1.9515673720556304
Validation loss: 2.4804362177279877

Epoch: 5| Step: 9
Training loss: 2.44364331102777
Validation loss: 2.4778626135081434

Epoch: 5| Step: 10
Training loss: 2.5292706698087466
Validation loss: 2.477863703995009

Epoch: 5| Step: 11
Training loss: 2.1843799683783134
Validation loss: 2.4809026664008353

Epoch: 104| Step: 0
Training loss: 2.401567932400736
Validation loss: 2.481438106449838

Epoch: 5| Step: 1
Training loss: 2.4992651813149407
Validation loss: 2.484088759256913

Epoch: 5| Step: 2
Training loss: 2.505919315278339
Validation loss: 2.4817839092111647

Epoch: 5| Step: 3
Training loss: 2.1253914192084644
Validation loss: 2.4832964581326884

Epoch: 5| Step: 4
Training loss: 2.542959749408035
Validation loss: 2.4813350096008007

Epoch: 5| Step: 5
Training loss: 2.980494347858621
Validation loss: 2.485128608301251

Epoch: 5| Step: 6
Training loss: 2.122751954202333
Validation loss: 2.4844460027373154

Epoch: 5| Step: 7
Training loss: 2.4981158786098465
Validation loss: 2.4792708981398586

Epoch: 5| Step: 8
Training loss: 2.550338075703792
Validation loss: 2.4818937438651547

Epoch: 5| Step: 9
Training loss: 2.6292832261579795
Validation loss: 2.479132493101466

Epoch: 5| Step: 10
Training loss: 3.2136723735489463
Validation loss: 2.4859554693730272

Epoch: 5| Step: 11
Training loss: 2.8556020055902493
Validation loss: 2.4810405843012036

Epoch: 105| Step: 0
Training loss: 1.9357115582138738
Validation loss: 2.503632824629007

Epoch: 5| Step: 1
Training loss: 2.8611208062691804
Validation loss: 2.5221122277171446

Epoch: 5| Step: 2
Training loss: 2.9638871369798134
Validation loss: 2.4907054779630955

Epoch: 5| Step: 3
Training loss: 2.181269901917176
Validation loss: 2.4751099840605844

Epoch: 5| Step: 4
Training loss: 2.850361944940166
Validation loss: 2.475467784903636

Epoch: 5| Step: 5
Training loss: 2.5258624350812515
Validation loss: 2.4795001083554005

Epoch: 5| Step: 6
Training loss: 2.679110628988586
Validation loss: 2.4781208931438705

Epoch: 5| Step: 7
Training loss: 2.7599061793814728
Validation loss: 2.475390035388313

Epoch: 5| Step: 8
Training loss: 2.5676060489196413
Validation loss: 2.4825616812686357

Epoch: 5| Step: 9
Training loss: 2.315951272112564
Validation loss: 2.476094387190208

Epoch: 5| Step: 10
Training loss: 2.6680321972118115
Validation loss: 2.4787370158528885

Epoch: 5| Step: 11
Training loss: 2.9689041900748077
Validation loss: 2.4790152308483577

Epoch: 106| Step: 0
Training loss: 2.7992058104488295
Validation loss: 2.47568898484988

Epoch: 5| Step: 1
Training loss: 3.1341581807777716
Validation loss: 2.4791732528876858

Epoch: 5| Step: 2
Training loss: 2.62574521340518
Validation loss: 2.4822701068368236

Epoch: 5| Step: 3
Training loss: 2.53151343587813
Validation loss: 2.479234178943499

Epoch: 5| Step: 4
Training loss: 2.364845955894608
Validation loss: 2.483394045268985

Epoch: 5| Step: 5
Training loss: 2.460783550957269
Validation loss: 2.480147309389007

Epoch: 5| Step: 6
Training loss: 2.419695753566022
Validation loss: 2.480541158104902

Epoch: 5| Step: 7
Training loss: 2.75860471936651
Validation loss: 2.48399933587888

Epoch: 5| Step: 8
Training loss: 2.2463944474330977
Validation loss: 2.4816859545341385

Epoch: 5| Step: 9
Training loss: 2.3776740028734866
Validation loss: 2.4845795777099653

Epoch: 5| Step: 10
Training loss: 2.6192365681415906
Validation loss: 2.482579768231993

Epoch: 5| Step: 11
Training loss: 2.7322498019219505
Validation loss: 2.4794650312341115

Epoch: 107| Step: 0
Training loss: 2.7501946293708315
Validation loss: 2.4738153449782083

Epoch: 5| Step: 1
Training loss: 2.9175936905985402
Validation loss: 2.4627801324319325

Epoch: 5| Step: 2
Training loss: 2.4359637578952302
Validation loss: 2.4674649495498984

Epoch: 5| Step: 3
Training loss: 2.660255643133289
Validation loss: 2.469034190660783

Epoch: 5| Step: 4
Training loss: 2.7898496911362987
Validation loss: 2.4666558771821054

Epoch: 5| Step: 5
Training loss: 2.0644758759167985
Validation loss: 2.471412060417591

Epoch: 5| Step: 6
Training loss: 2.3778659193195124
Validation loss: 2.470970414772545

Epoch: 5| Step: 7
Training loss: 2.4158135146869553
Validation loss: 2.4682466661828766

Epoch: 5| Step: 8
Training loss: 2.3113072386483418
Validation loss: 2.467360391129694

Epoch: 5| Step: 9
Training loss: 3.1894462477918815
Validation loss: 2.4672449087140085

Epoch: 5| Step: 10
Training loss: 2.4808666480811747
Validation loss: 2.464249339223549

Epoch: 5| Step: 11
Training loss: 2.8733331575268237
Validation loss: 2.4643635470970477

Epoch: 108| Step: 0
Training loss: 2.7392968921287664
Validation loss: 2.4667618306807584

Epoch: 5| Step: 1
Training loss: 1.9474401520138325
Validation loss: 2.4609432644246723

Epoch: 5| Step: 2
Training loss: 2.9024331244650905
Validation loss: 2.460879552249764

Epoch: 5| Step: 3
Training loss: 3.032144316265815
Validation loss: 2.461487852853985

Epoch: 5| Step: 4
Training loss: 2.555625999788204
Validation loss: 2.4683141202863603

Epoch: 5| Step: 5
Training loss: 2.6021382379249647
Validation loss: 2.466234901750652

Epoch: 5| Step: 6
Training loss: 2.475993286567424
Validation loss: 2.4696235197811687

Epoch: 5| Step: 7
Training loss: 2.4792257243155884
Validation loss: 2.4681463549802523

Epoch: 5| Step: 8
Training loss: 2.7499521424724236
Validation loss: 2.466497931207789

Epoch: 5| Step: 9
Training loss: 2.2729636416197883
Validation loss: 2.4661437171892047

Epoch: 5| Step: 10
Training loss: 2.390231829456583
Validation loss: 2.4662629085949903

Epoch: 5| Step: 11
Training loss: 2.1784510233033463
Validation loss: 2.4683976706655018

Epoch: 109| Step: 0
Training loss: 2.6635555556890846
Validation loss: 2.4690406805240412

Epoch: 5| Step: 1
Training loss: 2.5486525434913774
Validation loss: 2.4724054073718658

Epoch: 5| Step: 2
Training loss: 2.454933714583607
Validation loss: 2.473178740023493

Epoch: 5| Step: 3
Training loss: 2.0894525179574157
Validation loss: 2.4726883221756455

Epoch: 5| Step: 4
Training loss: 3.0848029646558484
Validation loss: 2.4724355381172964

Epoch: 5| Step: 5
Training loss: 2.600331424717161
Validation loss: 2.4787253793829698

Epoch: 5| Step: 6
Training loss: 2.959564293161898
Validation loss: 2.4760986038057404

Epoch: 5| Step: 7
Training loss: 2.419085760740235
Validation loss: 2.4759704050527818

Epoch: 5| Step: 8
Training loss: 2.677690657266437
Validation loss: 2.4741640681335264

Epoch: 5| Step: 9
Training loss: 1.9087236332899058
Validation loss: 2.474856955636348

Epoch: 5| Step: 10
Training loss: 2.7007345754459613
Validation loss: 2.475212619780886

Epoch: 5| Step: 11
Training loss: 2.52102072993906
Validation loss: 2.4717807475308953

Epoch: 110| Step: 0
Training loss: 2.292183164710773
Validation loss: 2.4725203594774805

Epoch: 5| Step: 1
Training loss: 2.6496620610524584
Validation loss: 2.4708096065368403

Epoch: 5| Step: 2
Training loss: 2.4514039435087986
Validation loss: 2.467037625116217

Epoch: 5| Step: 3
Training loss: 2.6947276489848413
Validation loss: 2.4685332247369485

Epoch: 5| Step: 4
Training loss: 2.5876413131678033
Validation loss: 2.4635975625039355

Epoch: 5| Step: 5
Training loss: 2.993180949177487
Validation loss: 2.4651702326090135

Epoch: 5| Step: 6
Training loss: 2.5785034826646105
Validation loss: 2.4630946761288266

Epoch: 5| Step: 7
Training loss: 2.6484041915194356
Validation loss: 2.4640101268994212

Epoch: 5| Step: 8
Training loss: 2.479310926412886
Validation loss: 2.4657539464498757

Epoch: 5| Step: 9
Training loss: 2.4876089100981305
Validation loss: 2.4734044723249555

Epoch: 5| Step: 10
Training loss: 2.6174245243066503
Validation loss: 2.466773269874632

Epoch: 5| Step: 11
Training loss: 1.4595391420118953
Validation loss: 2.469717948620005

Epoch: 111| Step: 0
Training loss: 2.6150882329697867
Validation loss: 2.466981677021719

Epoch: 5| Step: 1
Training loss: 2.6926325203843806
Validation loss: 2.460737278780974

Epoch: 5| Step: 2
Training loss: 2.7627419137108884
Validation loss: 2.4689632416226988

Epoch: 5| Step: 3
Training loss: 2.5842919775694058
Validation loss: 2.461323513052314

Epoch: 5| Step: 4
Training loss: 2.7141263384385517
Validation loss: 2.467549784762647

Epoch: 5| Step: 5
Training loss: 2.579330902129357
Validation loss: 2.4664516776276204

Epoch: 5| Step: 6
Training loss: 2.3215241527792156
Validation loss: 2.471243146701302

Epoch: 5| Step: 7
Training loss: 2.4291718846609127
Validation loss: 2.4633956580951923

Epoch: 5| Step: 8
Training loss: 2.4345910736679963
Validation loss: 2.4696613915069103

Epoch: 5| Step: 9
Training loss: 2.685649589655044
Validation loss: 2.4687277032352313

Epoch: 5| Step: 10
Training loss: 2.498371929288773
Validation loss: 2.466136476498302

Epoch: 5| Step: 11
Training loss: 1.6333140647815585
Validation loss: 2.469853914898415

Epoch: 112| Step: 0
Training loss: 2.3361212106376277
Validation loss: 2.4745094983690743

Epoch: 5| Step: 1
Training loss: 2.3824836879303906
Validation loss: 2.470772807831111

Epoch: 5| Step: 2
Training loss: 3.103646066179868
Validation loss: 2.472674903578301

Epoch: 5| Step: 3
Training loss: 2.9928116508483478
Validation loss: 2.4669863743104874

Epoch: 5| Step: 4
Training loss: 2.26145150775017
Validation loss: 2.4692588716281736

Epoch: 5| Step: 5
Training loss: 2.121089928274066
Validation loss: 2.4563640665062674

Epoch: 5| Step: 6
Training loss: 2.3978144429742247
Validation loss: 2.46145479124258

Epoch: 5| Step: 7
Training loss: 2.3155854750746534
Validation loss: 2.46037563792578

Epoch: 5| Step: 8
Training loss: 3.0471242949395805
Validation loss: 2.464890952648264

Epoch: 5| Step: 9
Training loss: 2.262308363412148
Validation loss: 2.4687828673416194

Epoch: 5| Step: 10
Training loss: 2.7251809891257555
Validation loss: 2.4639157071088227

Epoch: 5| Step: 11
Training loss: 2.83875128762381
Validation loss: 2.466449037474162

Epoch: 113| Step: 0
Training loss: 2.507291745697092
Validation loss: 2.4640896545926476

Epoch: 5| Step: 1
Training loss: 2.7950041923423266
Validation loss: 2.468673547937158

Epoch: 5| Step: 2
Training loss: 2.5147136672364976
Validation loss: 2.469942243617651

Epoch: 5| Step: 3
Training loss: 2.4513671797192456
Validation loss: 2.46430572425295

Epoch: 5| Step: 4
Training loss: 2.3135126319608
Validation loss: 2.457492698110118

Epoch: 5| Step: 5
Training loss: 2.705015106017968
Validation loss: 2.463965479638629

Epoch: 5| Step: 6
Training loss: 2.6930975174669087
Validation loss: 2.461354558411565

Epoch: 5| Step: 7
Training loss: 1.9775929535480996
Validation loss: 2.4639304918121576

Epoch: 5| Step: 8
Training loss: 2.4699559224014416
Validation loss: 2.462581997359835

Epoch: 5| Step: 9
Training loss: 2.646301578529013
Validation loss: 2.4668767840122303

Epoch: 5| Step: 10
Training loss: 2.954546228155288
Validation loss: 2.470993085288821

Epoch: 5| Step: 11
Training loss: 2.212702717088083
Validation loss: 2.4685838860747453

Epoch: 114| Step: 0
Training loss: 2.794761242572363
Validation loss: 2.467542823972581

Epoch: 5| Step: 1
Training loss: 2.899325910688407
Validation loss: 2.4655141306722137

Epoch: 5| Step: 2
Training loss: 2.297068166070919
Validation loss: 2.4649976913010603

Epoch: 5| Step: 3
Training loss: 2.8099582631008335
Validation loss: 2.4598221486691974

Epoch: 5| Step: 4
Training loss: 2.6341080463584134
Validation loss: 2.460463301571707

Epoch: 5| Step: 5
Training loss: 2.8080322383431975
Validation loss: 2.4618152768568304

Epoch: 5| Step: 6
Training loss: 2.379994611653872
Validation loss: 2.4609970408508004

Epoch: 5| Step: 7
Training loss: 2.0939278598225664
Validation loss: 2.45754701894729

Epoch: 5| Step: 8
Training loss: 2.492768796853541
Validation loss: 2.4585668922996216

Epoch: 5| Step: 9
Training loss: 2.4380228508871187
Validation loss: 2.4654268682347342

Epoch: 5| Step: 10
Training loss: 2.4669605964943506
Validation loss: 2.4596638244528566

Epoch: 5| Step: 11
Training loss: 2.8013997904583747
Validation loss: 2.463385584418599

Epoch: 115| Step: 0
Training loss: 2.607035061722285
Validation loss: 2.4677087664385753

Epoch: 5| Step: 1
Training loss: 2.6021140490496326
Validation loss: 2.4700133032897402

Epoch: 5| Step: 2
Training loss: 2.9255928416889794
Validation loss: 2.4688491801366634

Epoch: 5| Step: 3
Training loss: 2.0444790161130686
Validation loss: 2.472661613470591

Epoch: 5| Step: 4
Training loss: 2.3588719115822006
Validation loss: 2.4764417584786855

Epoch: 5| Step: 5
Training loss: 2.7542842091588473
Validation loss: 2.4795124403196653

Epoch: 5| Step: 6
Training loss: 2.9434044118775713
Validation loss: 2.4791320403002346

Epoch: 5| Step: 7
Training loss: 2.451397913507042
Validation loss: 2.4771081782560977

Epoch: 5| Step: 8
Training loss: 2.316561457305554
Validation loss: 2.479055271263969

Epoch: 5| Step: 9
Training loss: 2.8336641642085993
Validation loss: 2.4814017756282256

Epoch: 5| Step: 10
Training loss: 2.325637820135968
Validation loss: 2.476725656167139

Epoch: 5| Step: 11
Training loss: 2.5586832045430983
Validation loss: 2.4756064229164028

Epoch: 116| Step: 0
Training loss: 2.85056218408226
Validation loss: 2.47882116271706

Epoch: 5| Step: 1
Training loss: 2.4966600996405592
Validation loss: 2.4759667057945416

Epoch: 5| Step: 2
Training loss: 2.4887599993533134
Validation loss: 2.474849324986279

Epoch: 5| Step: 3
Training loss: 2.3217108523437773
Validation loss: 2.4771379229532906

Epoch: 5| Step: 4
Training loss: 2.5632821726891817
Validation loss: 2.4739592234292016

Epoch: 5| Step: 5
Training loss: 2.4155860216714458
Validation loss: 2.4708946023155987

Epoch: 5| Step: 6
Training loss: 2.274680725163033
Validation loss: 2.471430345546323

Epoch: 5| Step: 7
Training loss: 2.744425846359448
Validation loss: 2.47136708059578

Epoch: 5| Step: 8
Training loss: 2.623080596366219
Validation loss: 2.47230513632484

Epoch: 5| Step: 9
Training loss: 2.676170599239314
Validation loss: 2.469210963933846

Epoch: 5| Step: 10
Training loss: 2.5984452734376173
Validation loss: 2.465285824298413

Epoch: 5| Step: 11
Training loss: 2.8091052442467146
Validation loss: 2.464679009221528

Epoch: 117| Step: 0
Training loss: 2.5686524198612077
Validation loss: 2.471280700159734

Epoch: 5| Step: 1
Training loss: 2.850690650911604
Validation loss: 2.4716414045837913

Epoch: 5| Step: 2
Training loss: 2.5120849342444433
Validation loss: 2.4708589768539824

Epoch: 5| Step: 3
Training loss: 2.1193087040919134
Validation loss: 2.486730366722759

Epoch: 5| Step: 4
Training loss: 2.7818234313285197
Validation loss: 2.4871195502213093

Epoch: 5| Step: 5
Training loss: 2.035572090058636
Validation loss: 2.487802136984251

Epoch: 5| Step: 6
Training loss: 2.825588036835209
Validation loss: 2.474510975732753

Epoch: 5| Step: 7
Training loss: 2.952082212704105
Validation loss: 2.4819228348244575

Epoch: 5| Step: 8
Training loss: 2.592115231748833
Validation loss: 2.4778056830125865

Epoch: 5| Step: 9
Training loss: 2.62876785163423
Validation loss: 2.4732545125895653

Epoch: 5| Step: 10
Training loss: 2.526326229676207
Validation loss: 2.4737055251133055

Epoch: 5| Step: 11
Training loss: 1.7276992852936106
Validation loss: 2.4744986469452406

Epoch: 118| Step: 0
Training loss: 2.763185103719878
Validation loss: 2.4852552673830974

Epoch: 5| Step: 1
Training loss: 2.6395836757628577
Validation loss: 2.488484213160364

Epoch: 5| Step: 2
Training loss: 2.2313001055394195
Validation loss: 2.487708504403167

Epoch: 5| Step: 3
Training loss: 2.675246314714006
Validation loss: 2.4867765866735576

Epoch: 5| Step: 4
Training loss: 3.1398856588064508
Validation loss: 2.4894422600225385

Epoch: 5| Step: 5
Training loss: 2.474633365024056
Validation loss: 2.4875182135153193

Epoch: 5| Step: 6
Training loss: 2.5477765131841554
Validation loss: 2.4851475680008828

Epoch: 5| Step: 7
Training loss: 2.3170922535660172
Validation loss: 2.4876482491270417

Epoch: 5| Step: 8
Training loss: 2.7786257932894274
Validation loss: 2.4862030669088706

Epoch: 5| Step: 9
Training loss: 2.4987699343566967
Validation loss: 2.484415877703687

Epoch: 5| Step: 10
Training loss: 2.2100262061243963
Validation loss: 2.4746879037281158

Epoch: 5| Step: 11
Training loss: 2.7715033005652265
Validation loss: 2.480093127067256

Epoch: 119| Step: 0
Training loss: 2.913918335649353
Validation loss: 2.4774373431707932

Epoch: 5| Step: 1
Training loss: 2.6851026798839137
Validation loss: 2.46997259344245

Epoch: 5| Step: 2
Training loss: 2.4113819832521
Validation loss: 2.472471108719392

Epoch: 5| Step: 3
Training loss: 2.448546784377551
Validation loss: 2.468102494967392

Epoch: 5| Step: 4
Training loss: 2.7268480736126355
Validation loss: 2.4710792144692006

Epoch: 5| Step: 5
Training loss: 2.289230496748292
Validation loss: 2.4702777843219637

Epoch: 5| Step: 6
Training loss: 2.1719162751810863
Validation loss: 2.4678595925012634

Epoch: 5| Step: 7
Training loss: 2.3597395659461653
Validation loss: 2.4661455137634607

Epoch: 5| Step: 8
Training loss: 2.732149886363557
Validation loss: 2.466167666705495

Epoch: 5| Step: 9
Training loss: 2.4104733745352305
Validation loss: 2.468415414695525

Epoch: 5| Step: 10
Training loss: 2.8391797576354674
Validation loss: 2.4691685450546

Epoch: 5| Step: 11
Training loss: 3.0132550824675635
Validation loss: 2.4668673648463177

Epoch: 120| Step: 0
Training loss: 2.573568861202204
Validation loss: 2.471133019562136

Epoch: 5| Step: 1
Training loss: 2.69461775961877
Validation loss: 2.466523675597318

Epoch: 5| Step: 2
Training loss: 2.834901394483214
Validation loss: 2.468484031257029

Epoch: 5| Step: 3
Training loss: 3.1963303863716552
Validation loss: 2.471657551807369

Epoch: 5| Step: 4
Training loss: 2.6199248161885236
Validation loss: 2.4736314430438844

Epoch: 5| Step: 5
Training loss: 2.3196778119745827
Validation loss: 2.476812468387622

Epoch: 5| Step: 6
Training loss: 2.3873146424565412
Validation loss: 2.4685828156338445

Epoch: 5| Step: 7
Training loss: 2.356760964276355
Validation loss: 2.4776882296635385

Epoch: 5| Step: 8
Training loss: 2.134625233940089
Validation loss: 2.478257618995822

Epoch: 5| Step: 9
Training loss: 2.4889191149776
Validation loss: 2.4713143739756003

Epoch: 5| Step: 10
Training loss: 2.278353380600141
Validation loss: 2.474287096899787

Epoch: 5| Step: 11
Training loss: 2.8837700470821597
Validation loss: 2.4710092387590814

Epoch: 121| Step: 0
Training loss: 2.3847453298494004
Validation loss: 2.4676320586863234

Epoch: 5| Step: 1
Training loss: 2.5057450087770765
Validation loss: 2.4663883695537305

Epoch: 5| Step: 2
Training loss: 3.23945167658309
Validation loss: 2.471308396575146

Epoch: 5| Step: 3
Training loss: 2.5315381109844948
Validation loss: 2.4737656180293706

Epoch: 5| Step: 4
Training loss: 2.8284409488787183
Validation loss: 2.4763664825877316

Epoch: 5| Step: 5
Training loss: 2.342260268736996
Validation loss: 2.479260576430314

Epoch: 5| Step: 6
Training loss: 2.6148196312459056
Validation loss: 2.4760704594661758

Epoch: 5| Step: 7
Training loss: 2.4540960248830777
Validation loss: 2.4748039259452934

Epoch: 5| Step: 8
Training loss: 1.9252852909671283
Validation loss: 2.475685626248038

Epoch: 5| Step: 9
Training loss: 2.7046220635972364
Validation loss: 2.470367517407576

Epoch: 5| Step: 10
Training loss: 2.3862759792858004
Validation loss: 2.474493347675464

Epoch: 5| Step: 11
Training loss: 2.6640367254984847
Validation loss: 2.4688724233959496

Epoch: 122| Step: 0
Training loss: 2.3479765357773563
Validation loss: 2.4670021171089123

Epoch: 5| Step: 1
Training loss: 2.22225567739523
Validation loss: 2.460761218342182

Epoch: 5| Step: 2
Training loss: 2.660599054125357
Validation loss: 2.461203848336843

Epoch: 5| Step: 3
Training loss: 2.549558197344777
Validation loss: 2.460309201724513

Epoch: 5| Step: 4
Training loss: 2.871521213395348
Validation loss: 2.4709826204531904

Epoch: 5| Step: 5
Training loss: 2.1775180315744875
Validation loss: 2.461952411938521

Epoch: 5| Step: 6
Training loss: 1.9670117894388075
Validation loss: 2.464685591164152

Epoch: 5| Step: 7
Training loss: 2.5711240096095187
Validation loss: 2.469574561217473

Epoch: 5| Step: 8
Training loss: 2.7756352702695746
Validation loss: 2.4620717699359624

Epoch: 5| Step: 9
Training loss: 2.947855127633586
Validation loss: 2.465069139335034

Epoch: 5| Step: 10
Training loss: 2.7387643515812803
Validation loss: 2.464530852418206

Epoch: 5| Step: 11
Training loss: 2.914607510978828
Validation loss: 2.467480006885791

Epoch: 123| Step: 0
Training loss: 1.9866573394752722
Validation loss: 2.4709357311737277

Epoch: 5| Step: 1
Training loss: 2.658700059888924
Validation loss: 2.475280112814094

Epoch: 5| Step: 2
Training loss: 1.9967190533846804
Validation loss: 2.4790843835099885

Epoch: 5| Step: 3
Training loss: 2.7197761791367334
Validation loss: 2.486285221022349

Epoch: 5| Step: 4
Training loss: 2.5457718221056362
Validation loss: 2.4873379846267984

Epoch: 5| Step: 5
Training loss: 3.2876945060947
Validation loss: 2.4891753773578897

Epoch: 5| Step: 6
Training loss: 2.0599739326753634
Validation loss: 2.481248920129754

Epoch: 5| Step: 7
Training loss: 2.9637955935030944
Validation loss: 2.4808684660277938

Epoch: 5| Step: 8
Training loss: 2.3996353388950733
Validation loss: 2.486418753123689

Epoch: 5| Step: 9
Training loss: 2.712123644336742
Validation loss: 2.4818899693802545

Epoch: 5| Step: 10
Training loss: 2.9201050971988187
Validation loss: 2.4858641889573025

Epoch: 5| Step: 11
Training loss: 1.7876125273597836
Validation loss: 2.4834439194354965

Epoch: 124| Step: 0
Training loss: 3.0749361977509806
Validation loss: 2.484569050150052

Epoch: 5| Step: 1
Training loss: 2.959988001464032
Validation loss: 2.487576598996029

Epoch: 5| Step: 2
Training loss: 2.434775957770771
Validation loss: 2.4859768044181654

Epoch: 5| Step: 3
Training loss: 2.1266321758036413
Validation loss: 2.4844182408566398

Epoch: 5| Step: 4
Training loss: 2.580879635599252
Validation loss: 2.4854443525918413

Epoch: 5| Step: 5
Training loss: 2.883282878926747
Validation loss: 2.4808530935252904

Epoch: 5| Step: 6
Training loss: 2.1498042527624026
Validation loss: 2.4807374263041

Epoch: 5| Step: 7
Training loss: 2.9562084106358704
Validation loss: 2.4786182740029954

Epoch: 5| Step: 8
Training loss: 2.2098349258429004
Validation loss: 2.482146131005959

Epoch: 5| Step: 9
Training loss: 1.9973359246120441
Validation loss: 2.4787620780626196

Epoch: 5| Step: 10
Training loss: 2.6310697951416526
Validation loss: 2.4812517267024186

Epoch: 5| Step: 11
Training loss: 2.682210818556794
Validation loss: 2.4732236527555242

Epoch: 125| Step: 0
Training loss: 2.9340628135941826
Validation loss: 2.4703583327241376

Epoch: 5| Step: 1
Training loss: 2.297666452249642
Validation loss: 2.462147809676357

Epoch: 5| Step: 2
Training loss: 2.666873824497247
Validation loss: 2.4621894598663103

Epoch: 5| Step: 3
Training loss: 2.4439401889169003
Validation loss: 2.4558324957286217

Epoch: 5| Step: 4
Training loss: 2.6204601266728287
Validation loss: 2.456962721960143

Epoch: 5| Step: 5
Training loss: 2.4375166281108513
Validation loss: 2.460003155745702

Epoch: 5| Step: 6
Training loss: 2.4873191614407593
Validation loss: 2.4533705639076615

Epoch: 5| Step: 7
Training loss: 2.519566640679252
Validation loss: 2.4605724810801957

Epoch: 5| Step: 8
Training loss: 2.4736027405149965
Validation loss: 2.4573781062294957

Epoch: 5| Step: 9
Training loss: 2.4695482532817343
Validation loss: 2.4589779636338864

Epoch: 5| Step: 10
Training loss: 2.639464715963524
Validation loss: 2.4600494275968385

Epoch: 5| Step: 11
Training loss: 2.457999761762988
Validation loss: 2.4551994619477626

Epoch: 126| Step: 0
Training loss: 2.4013706624555478
Validation loss: 2.460664788530774

Epoch: 5| Step: 1
Training loss: 2.9622392435038725
Validation loss: 2.459242136855147

Epoch: 5| Step: 2
Training loss: 2.3409816414212203
Validation loss: 2.454859189448368

Epoch: 5| Step: 3
Training loss: 2.703532634715219
Validation loss: 2.4597009004216477

Epoch: 5| Step: 4
Training loss: 2.491698596796537
Validation loss: 2.465705483158076

Epoch: 5| Step: 5
Training loss: 2.0994538005588863
Validation loss: 2.4579559813773573

Epoch: 5| Step: 6
Training loss: 2.5946503880366842
Validation loss: 2.4622736780047623

Epoch: 5| Step: 7
Training loss: 2.515894241614988
Validation loss: 2.4569628270845665

Epoch: 5| Step: 8
Training loss: 2.6971827113772338
Validation loss: 2.4535127240225414

Epoch: 5| Step: 9
Training loss: 2.3578208200195423
Validation loss: 2.4572047913704727

Epoch: 5| Step: 10
Training loss: 2.666474712933606
Validation loss: 2.45245963385179

Epoch: 5| Step: 11
Training loss: 3.0504620686704924
Validation loss: 2.454574282386716

Epoch: 127| Step: 0
Training loss: 2.787599324051984
Validation loss: 2.452601974355631

Epoch: 5| Step: 1
Training loss: 2.5963116600564384
Validation loss: 2.4585419555548382

Epoch: 5| Step: 2
Training loss: 2.433973451142033
Validation loss: 2.4631513537739638

Epoch: 5| Step: 3
Training loss: 2.3520832689103375
Validation loss: 2.4623966553588494

Epoch: 5| Step: 4
Training loss: 2.1171282657909596
Validation loss: 2.456503972746338

Epoch: 5| Step: 5
Training loss: 2.5042487280713788
Validation loss: 2.4593721487504587

Epoch: 5| Step: 6
Training loss: 2.9900412568783183
Validation loss: 2.4620539842221603

Epoch: 5| Step: 7
Training loss: 2.5935869280556894
Validation loss: 2.452606231360229

Epoch: 5| Step: 8
Training loss: 2.4292028992591463
Validation loss: 2.4607385423757773

Epoch: 5| Step: 9
Training loss: 2.6943647846974206
Validation loss: 2.4649399719963565

Epoch: 5| Step: 10
Training loss: 2.561467963085919
Validation loss: 2.4702421620292254

Epoch: 5| Step: 11
Training loss: 1.816090939954566
Validation loss: 2.474311395180789

Epoch: 128| Step: 0
Training loss: 2.5881981317891745
Validation loss: 2.473801137380539

Epoch: 5| Step: 1
Training loss: 2.591373411884238
Validation loss: 2.473529607198894

Epoch: 5| Step: 2
Training loss: 2.557037765629827
Validation loss: 2.4676801520225644

Epoch: 5| Step: 3
Training loss: 2.4884092576473273
Validation loss: 2.4628104212722746

Epoch: 5| Step: 4
Training loss: 2.8101123423535843
Validation loss: 2.454957573155688

Epoch: 5| Step: 5
Training loss: 2.329875723017129
Validation loss: 2.45342430588987

Epoch: 5| Step: 6
Training loss: 2.4447369858020584
Validation loss: 2.455872899956643

Epoch: 5| Step: 7
Training loss: 2.5910220220433056
Validation loss: 2.464238902187703

Epoch: 5| Step: 8
Training loss: 2.3411284981079787
Validation loss: 2.4577436925363285

Epoch: 5| Step: 9
Training loss: 3.003159131224327
Validation loss: 2.466154673854903

Epoch: 5| Step: 10
Training loss: 2.5672508487326677
Validation loss: 2.463252090199237

Epoch: 5| Step: 11
Training loss: 1.7831111353600262
Validation loss: 2.4656116560980617

Epoch: 129| Step: 0
Training loss: 1.9663256295628733
Validation loss: 2.472328449555435

Epoch: 5| Step: 1
Training loss: 2.2303180276215087
Validation loss: 2.472376967854296

Epoch: 5| Step: 2
Training loss: 2.4801097219560013
Validation loss: 2.4720852410005683

Epoch: 5| Step: 3
Training loss: 3.313599601909884
Validation loss: 2.471926279576974

Epoch: 5| Step: 4
Training loss: 2.390571743241043
Validation loss: 2.475073183066258

Epoch: 5| Step: 5
Training loss: 2.6962198250629075
Validation loss: 2.4706102718149414

Epoch: 5| Step: 6
Training loss: 2.417408916883828
Validation loss: 2.4706904756526282

Epoch: 5| Step: 7
Training loss: 2.326529858874504
Validation loss: 2.4738459886172675

Epoch: 5| Step: 8
Training loss: 2.3139742714021123
Validation loss: 2.4700455867431876

Epoch: 5| Step: 9
Training loss: 3.1527144770679083
Validation loss: 2.4639505540329267

Epoch: 5| Step: 10
Training loss: 2.3660355084512568
Validation loss: 2.465402123773295

Epoch: 5| Step: 11
Training loss: 3.1840152016856687
Validation loss: 2.463466713042664

Epoch: 130| Step: 0
Training loss: 2.6768887420664953
Validation loss: 2.460025162090024

Epoch: 5| Step: 1
Training loss: 3.043053680919227
Validation loss: 2.4614207161703265

Epoch: 5| Step: 2
Training loss: 2.6977535085548348
Validation loss: 2.463272174076839

Epoch: 5| Step: 3
Training loss: 2.521082012006152
Validation loss: 2.4574489592215456

Epoch: 5| Step: 4
Training loss: 2.367438979686759
Validation loss: 2.462884566652297

Epoch: 5| Step: 5
Training loss: 2.454167332889313
Validation loss: 2.461243371271649

Epoch: 5| Step: 6
Training loss: 2.241544518339476
Validation loss: 2.4619776651856555

Epoch: 5| Step: 7
Training loss: 2.322508212958885
Validation loss: 2.4645154223486765

Epoch: 5| Step: 8
Training loss: 2.4785730522122176
Validation loss: 2.4669952030952205

Epoch: 5| Step: 9
Training loss: 2.7536265995534084
Validation loss: 2.468065533134525

Epoch: 5| Step: 10
Training loss: 2.2398941060989612
Validation loss: 2.4594176104940844

Epoch: 5| Step: 11
Training loss: 3.0234160508767594
Validation loss: 2.460381936633817

Epoch: 131| Step: 0
Training loss: 3.048045085323228
Validation loss: 2.4668046694944765

Epoch: 5| Step: 1
Training loss: 2.9323378311417025
Validation loss: 2.4620130459271703

Epoch: 5| Step: 2
Training loss: 2.717607894061069
Validation loss: 2.468233404553691

Epoch: 5| Step: 3
Training loss: 2.7742372031472313
Validation loss: 2.4605730907147634

Epoch: 5| Step: 4
Training loss: 2.3477761845729463
Validation loss: 2.463489615930194

Epoch: 5| Step: 5
Training loss: 2.2410178506490057
Validation loss: 2.4655360173170937

Epoch: 5| Step: 6
Training loss: 2.198742559180755
Validation loss: 2.4592598015231606

Epoch: 5| Step: 7
Training loss: 2.2037184977754634
Validation loss: 2.466640295282933

Epoch: 5| Step: 8
Training loss: 2.329894961171068
Validation loss: 2.4615847589153828

Epoch: 5| Step: 9
Training loss: 2.5495578232900145
Validation loss: 2.4591848762826483

Epoch: 5| Step: 10
Training loss: 2.489569457798894
Validation loss: 2.4609767607932853

Epoch: 5| Step: 11
Training loss: 1.7420265568177207
Validation loss: 2.459600987890972

Epoch: 132| Step: 0
Training loss: 2.877858772349058
Validation loss: 2.4561246120037046

Epoch: 5| Step: 1
Training loss: 2.190892450002516
Validation loss: 2.4585657346648766

Epoch: 5| Step: 2
Training loss: 2.9020167868698508
Validation loss: 2.4632282716373575

Epoch: 5| Step: 3
Training loss: 2.039809400779889
Validation loss: 2.456944434285336

Epoch: 5| Step: 4
Training loss: 2.316618988406395
Validation loss: 2.459223991356303

Epoch: 5| Step: 5
Training loss: 2.388783063195621
Validation loss: 2.4594930032374793

Epoch: 5| Step: 6
Training loss: 2.691592183770441
Validation loss: 2.4529712734123983

Epoch: 5| Step: 7
Training loss: 2.1886913869908184
Validation loss: 2.4515400036374717

Epoch: 5| Step: 8
Training loss: 2.8407942953324787
Validation loss: 2.449201718666123

Epoch: 5| Step: 9
Training loss: 2.3131353175735323
Validation loss: 2.4529617239035035

Epoch: 5| Step: 10
Training loss: 3.079353668219526
Validation loss: 2.4519839903273564

Epoch: 5| Step: 11
Training loss: 1.7742162666656167
Validation loss: 2.4528155323997556

Epoch: 133| Step: 0
Training loss: 2.7104501423587646
Validation loss: 2.4574238959216053

Epoch: 5| Step: 1
Training loss: 2.2400063994861195
Validation loss: 2.4517808499663563

Epoch: 5| Step: 2
Training loss: 2.7601030471472585
Validation loss: 2.468408347685016

Epoch: 5| Step: 3
Training loss: 2.1067644707796256
Validation loss: 2.471820716245784

Epoch: 5| Step: 4
Training loss: 2.9155740780487545
Validation loss: 2.4734306669512356

Epoch: 5| Step: 5
Training loss: 2.2317524704832428
Validation loss: 2.4570555349664995

Epoch: 5| Step: 6
Training loss: 2.55733509117493
Validation loss: 2.452779822554503

Epoch: 5| Step: 7
Training loss: 2.64897613899426
Validation loss: 2.456223262515154

Epoch: 5| Step: 8
Training loss: 3.0793858767999285
Validation loss: 2.469189834044018

Epoch: 5| Step: 9
Training loss: 2.5933072734919196
Validation loss: 2.47250849084968

Epoch: 5| Step: 10
Training loss: 2.468298665571028
Validation loss: 2.4726144426536765

Epoch: 5| Step: 11
Training loss: 2.830494936201495
Validation loss: 2.474467706275715

Epoch: 134| Step: 0
Training loss: 2.6741360918220765
Validation loss: 2.47845652504539

Epoch: 5| Step: 1
Training loss: 2.4487304200679207
Validation loss: 2.474239559585947

Epoch: 5| Step: 2
Training loss: 2.142888563924849
Validation loss: 2.476121215334188

Epoch: 5| Step: 3
Training loss: 2.8622990233652588
Validation loss: 2.4763631690320396

Epoch: 5| Step: 4
Training loss: 2.5453185023453053
Validation loss: 2.4762316241088804

Epoch: 5| Step: 5
Training loss: 2.2905871420694344
Validation loss: 2.475236896936259

Epoch: 5| Step: 6
Training loss: 3.0705028989349876
Validation loss: 2.4721210698056657

Epoch: 5| Step: 7
Training loss: 2.5197419780759063
Validation loss: 2.469285078047179

Epoch: 5| Step: 8
Training loss: 2.1491771187835664
Validation loss: 2.471674197304028

Epoch: 5| Step: 9
Training loss: 2.7498728115840043
Validation loss: 2.4679352747881005

Epoch: 5| Step: 10
Training loss: 2.7923089802022214
Validation loss: 2.4714408084861486

Epoch: 5| Step: 11
Training loss: 2.6333498081062126
Validation loss: 2.468077785381336

Epoch: 135| Step: 0
Training loss: 2.700170942475922
Validation loss: 2.4671958183935923

Epoch: 5| Step: 1
Training loss: 2.668231643972464
Validation loss: 2.4660224494293805

Epoch: 5| Step: 2
Training loss: 2.0933543728218598
Validation loss: 2.466753999806135

Epoch: 5| Step: 3
Training loss: 2.4387217663059864
Validation loss: 2.4621109924682294

Epoch: 5| Step: 4
Training loss: 2.5591557708114103
Validation loss: 2.4639829330482854

Epoch: 5| Step: 5
Training loss: 2.6276662092694396
Validation loss: 2.4588547829760072

Epoch: 5| Step: 6
Training loss: 2.7335820383419005
Validation loss: 2.461496465266276

Epoch: 5| Step: 7
Training loss: 3.172382783881198
Validation loss: 2.4578379614162538

Epoch: 5| Step: 8
Training loss: 2.042115013044433
Validation loss: 2.4684236890283575

Epoch: 5| Step: 9
Training loss: 2.56548972290098
Validation loss: 2.4603945945656283

Epoch: 5| Step: 10
Training loss: 2.360387824730501
Validation loss: 2.4529303941255627

Epoch: 5| Step: 11
Training loss: 2.9573011791635673
Validation loss: 2.4579983593477692

Epoch: 136| Step: 0
Training loss: 2.975415587048205
Validation loss: 2.4613945228828267

Epoch: 5| Step: 1
Training loss: 2.422487931984209
Validation loss: 2.464450419903106

Epoch: 5| Step: 2
Training loss: 2.7222476253059504
Validation loss: 2.4679051575292243

Epoch: 5| Step: 3
Training loss: 2.4696284795420813
Validation loss: 2.458777922229507

Epoch: 5| Step: 4
Training loss: 2.1972813584506152
Validation loss: 2.4746628303645397

Epoch: 5| Step: 5
Training loss: 2.737900646276825
Validation loss: 2.4775315203042534

Epoch: 5| Step: 6
Training loss: 2.6248360537240116
Validation loss: 2.47719267520145

Epoch: 5| Step: 7
Training loss: 2.7260394537429273
Validation loss: 2.4709718540489582

Epoch: 5| Step: 8
Training loss: 2.706241024434136
Validation loss: 2.472369876005016

Epoch: 5| Step: 9
Training loss: 2.162372907310623
Validation loss: 2.4705226505592024

Epoch: 5| Step: 10
Training loss: 2.3725224672947998
Validation loss: 2.470576475815119

Epoch: 5| Step: 11
Training loss: 2.1662105544824857
Validation loss: 2.4731789950862515

Epoch: 137| Step: 0
Training loss: 2.389576900332726
Validation loss: 2.4662851390278444

Epoch: 5| Step: 1
Training loss: 1.9343700969677045
Validation loss: 2.4732284044640185

Epoch: 5| Step: 2
Training loss: 2.430644837208019
Validation loss: 2.4663007110870514

Epoch: 5| Step: 3
Training loss: 3.3089805476013754
Validation loss: 2.4712467384638446

Epoch: 5| Step: 4
Training loss: 2.374462066765091
Validation loss: 2.4716529317226845

Epoch: 5| Step: 5
Training loss: 2.304493213804967
Validation loss: 2.470484820184097

Epoch: 5| Step: 6
Training loss: 2.8518870547857245
Validation loss: 2.469733513112995

Epoch: 5| Step: 7
Training loss: 2.5885669443494055
Validation loss: 2.4686419789306324

Epoch: 5| Step: 8
Training loss: 2.3659816981983854
Validation loss: 2.4688377646446784

Epoch: 5| Step: 9
Training loss: 2.2969374875242554
Validation loss: 2.4741831078394774

Epoch: 5| Step: 10
Training loss: 2.7549237475080397
Validation loss: 2.46380735312842

Epoch: 5| Step: 11
Training loss: 3.2923148921295464
Validation loss: 2.464464233973206

Epoch: 138| Step: 0
Training loss: 2.591459986877364
Validation loss: 2.4672071408212157

Epoch: 5| Step: 1
Training loss: 2.2409275249726788
Validation loss: 2.473140526505015

Epoch: 5| Step: 2
Training loss: 2.8679853363513503
Validation loss: 2.47884937601441

Epoch: 5| Step: 3
Training loss: 2.4164303521558548
Validation loss: 2.4798339872592887

Epoch: 5| Step: 4
Training loss: 2.7531999696879264
Validation loss: 2.4802228750683493

Epoch: 5| Step: 5
Training loss: 2.5297435469188354
Validation loss: 2.481056996677552

Epoch: 5| Step: 6
Training loss: 2.772255057134289
Validation loss: 2.483178188344185

Epoch: 5| Step: 7
Training loss: 2.544387913602978
Validation loss: 2.4747964998513767

Epoch: 5| Step: 8
Training loss: 2.5059089447613245
Validation loss: 2.4738018361167584

Epoch: 5| Step: 9
Training loss: 2.1916867108993725
Validation loss: 2.467037476127007

Epoch: 5| Step: 10
Training loss: 2.528025610329277
Validation loss: 2.46952278982932

Epoch: 5| Step: 11
Training loss: 2.8366099839723957
Validation loss: 2.4642776871024603

Epoch: 139| Step: 0
Training loss: 2.616154800046277
Validation loss: 2.4625996300024475

Epoch: 5| Step: 1
Training loss: 2.303566766863021
Validation loss: 2.4654535022008393

Epoch: 5| Step: 2
Training loss: 2.400264479051626
Validation loss: 2.458382995287038

Epoch: 5| Step: 3
Training loss: 2.3731817010952985
Validation loss: 2.4635202367924496

Epoch: 5| Step: 4
Training loss: 2.442712736363025
Validation loss: 2.454490569058425

Epoch: 5| Step: 5
Training loss: 2.8106941359527022
Validation loss: 2.453719263523944

Epoch: 5| Step: 6
Training loss: 2.9996431456357717
Validation loss: 2.4613544978710737

Epoch: 5| Step: 7
Training loss: 2.674006008252717
Validation loss: 2.4632796349133503

Epoch: 5| Step: 8
Training loss: 2.2046670048962103
Validation loss: 2.4581641722253584

Epoch: 5| Step: 9
Training loss: 2.534960629008861
Validation loss: 2.4678861015917835

Epoch: 5| Step: 10
Training loss: 2.526658308657844
Validation loss: 2.45861174871101

Epoch: 5| Step: 11
Training loss: 1.7114344880975025
Validation loss: 2.463629944142441

Epoch: 140| Step: 0
Training loss: 2.52900275799596
Validation loss: 2.463779515941682

Epoch: 5| Step: 1
Training loss: 2.562011951397812
Validation loss: 2.463248863858252

Epoch: 5| Step: 2
Training loss: 2.3644998230380505
Validation loss: 2.460780390008336

Epoch: 5| Step: 3
Training loss: 1.8941414028865502
Validation loss: 2.456304651967614

Epoch: 5| Step: 4
Training loss: 2.246476062911179
Validation loss: 2.4567470012126456

Epoch: 5| Step: 5
Training loss: 2.6348392824095397
Validation loss: 2.4544057681560396

Epoch: 5| Step: 6
Training loss: 2.8888811779734413
Validation loss: 2.4518123402960814

Epoch: 5| Step: 7
Training loss: 2.805288181426869
Validation loss: 2.455501502693797

Epoch: 5| Step: 8
Training loss: 2.6613292824549353
Validation loss: 2.456773280442484

Epoch: 5| Step: 9
Training loss: 2.75953313735112
Validation loss: 2.4455639442785935

Epoch: 5| Step: 10
Training loss: 2.3802594625266704
Validation loss: 2.449400883361274

Epoch: 5| Step: 11
Training loss: 1.6237105608959947
Validation loss: 2.4564559780594095

Epoch: 141| Step: 0
Training loss: 2.375155594396968
Validation loss: 2.4560016563155735

Epoch: 5| Step: 1
Training loss: 2.611922066020976
Validation loss: 2.4513101931347676

Epoch: 5| Step: 2
Training loss: 2.5106867305962117
Validation loss: 2.4528702443661627

Epoch: 5| Step: 3
Training loss: 2.627795774180014
Validation loss: 2.4488716224259113

Epoch: 5| Step: 4
Training loss: 2.4143884926344144
Validation loss: 2.4530520863641017

Epoch: 5| Step: 5
Training loss: 2.103259454428198
Validation loss: 2.4502556454997246

Epoch: 5| Step: 6
Training loss: 2.5723533991941037
Validation loss: 2.450866684272192

Epoch: 5| Step: 7
Training loss: 2.6484300281340487
Validation loss: 2.453786857880056

Epoch: 5| Step: 8
Training loss: 2.879883143650371
Validation loss: 2.450480155053168

Epoch: 5| Step: 9
Training loss: 2.55525168625612
Validation loss: 2.4516297296528897

Epoch: 5| Step: 10
Training loss: 2.3268070458780117
Validation loss: 2.4530084545854445

Epoch: 5| Step: 11
Training loss: 2.6407365944661234
Validation loss: 2.454397612511992

Epoch: 142| Step: 0
Training loss: 2.5877238669739366
Validation loss: 2.4538147537741755

Epoch: 5| Step: 1
Training loss: 1.946018320748163
Validation loss: 2.452372087159162

Epoch: 5| Step: 2
Training loss: 2.879736605891505
Validation loss: 2.457291597886763

Epoch: 5| Step: 3
Training loss: 2.82967945184095
Validation loss: 2.4509648837248705

Epoch: 5| Step: 4
Training loss: 2.2333469826959687
Validation loss: 2.4518944393401556

Epoch: 5| Step: 5
Training loss: 2.6414870260231607
Validation loss: 2.4511037059692056

Epoch: 5| Step: 6
Training loss: 2.244359788410219
Validation loss: 2.451764853437055

Epoch: 5| Step: 7
Training loss: 2.8877177697173773
Validation loss: 2.449870637800098

Epoch: 5| Step: 8
Training loss: 2.6863537495256153
Validation loss: 2.4530447017380985

Epoch: 5| Step: 9
Training loss: 2.5351502311176626
Validation loss: 2.4490723918562347

Epoch: 5| Step: 10
Training loss: 2.1101335080110117
Validation loss: 2.4447354254303275

Epoch: 5| Step: 11
Training loss: 2.0708951310186516
Validation loss: 2.4531151514199863

Epoch: 143| Step: 0
Training loss: 2.4440593006662787
Validation loss: 2.4520545899989563

Epoch: 5| Step: 1
Training loss: 2.4692554197948082
Validation loss: 2.4578950290521853

Epoch: 5| Step: 2
Training loss: 2.4279655414002588
Validation loss: 2.454579992953076

Epoch: 5| Step: 3
Training loss: 2.982344490851011
Validation loss: 2.4604833516885383

Epoch: 5| Step: 4
Training loss: 1.9534682315599265
Validation loss: 2.458543878903469

Epoch: 5| Step: 5
Training loss: 2.9650973687740905
Validation loss: 2.4580674081498093

Epoch: 5| Step: 6
Training loss: 2.122769924653903
Validation loss: 2.4540316046405364

Epoch: 5| Step: 7
Training loss: 2.5137069687842595
Validation loss: 2.457275641274412

Epoch: 5| Step: 8
Training loss: 2.4362764466495817
Validation loss: 2.4550958560454044

Epoch: 5| Step: 9
Training loss: 2.2464505915588133
Validation loss: 2.454894721343514

Epoch: 5| Step: 10
Training loss: 2.766807777375765
Validation loss: 2.461535713108489

Epoch: 5| Step: 11
Training loss: 2.9625410503649827
Validation loss: 2.4651340609882477

Epoch: 144| Step: 0
Training loss: 2.260016504075545
Validation loss: 2.460354189896448

Epoch: 5| Step: 1
Training loss: 2.455950233862343
Validation loss: 2.4669039499900296

Epoch: 5| Step: 2
Training loss: 1.926929990148948
Validation loss: 2.458359093180894

Epoch: 5| Step: 3
Training loss: 2.503839215171311
Validation loss: 2.4651686408431943

Epoch: 5| Step: 4
Training loss: 2.6437331647765263
Validation loss: 2.469114598581286

Epoch: 5| Step: 5
Training loss: 2.7899735189022024
Validation loss: 2.462222229190204

Epoch: 5| Step: 6
Training loss: 3.0558143352011267
Validation loss: 2.467852485657733

Epoch: 5| Step: 7
Training loss: 2.7428162117583406
Validation loss: 2.454643747225906

Epoch: 5| Step: 8
Training loss: 2.565393349601088
Validation loss: 2.4690258379040433

Epoch: 5| Step: 9
Training loss: 2.4560425532441306
Validation loss: 2.4639347735940476

Epoch: 5| Step: 10
Training loss: 2.347252631758534
Validation loss: 2.467894655447555

Epoch: 5| Step: 11
Training loss: 1.8830709319609134
Validation loss: 2.4635928809317913

Epoch: 145| Step: 0
Training loss: 2.5118895097414558
Validation loss: 2.4722070230654953

Epoch: 5| Step: 1
Training loss: 2.6789252528876357
Validation loss: 2.4677019510204077

Epoch: 5| Step: 2
Training loss: 1.9539605756587408
Validation loss: 2.47082019473266

Epoch: 5| Step: 3
Training loss: 2.10539016152322
Validation loss: 2.471238367056203

Epoch: 5| Step: 4
Training loss: 2.7258238570692837
Validation loss: 2.4644829938965707

Epoch: 5| Step: 5
Training loss: 2.9658489307559006
Validation loss: 2.459976208356621

Epoch: 5| Step: 6
Training loss: 2.3856001759757395
Validation loss: 2.4615428684574194

Epoch: 5| Step: 7
Training loss: 2.1373171901049606
Validation loss: 2.455547254559375

Epoch: 5| Step: 8
Training loss: 2.3355202190526025
Validation loss: 2.4590285269217715

Epoch: 5| Step: 9
Training loss: 2.7805774175508757
Validation loss: 2.447308246944662

Epoch: 5| Step: 10
Training loss: 2.784110751815603
Validation loss: 2.4533246236517834

Epoch: 5| Step: 11
Training loss: 3.0697816190802194
Validation loss: 2.452798027876855

Epoch: 146| Step: 0
Training loss: 2.427247812703701
Validation loss: 2.4572631087725023

Epoch: 5| Step: 1
Training loss: 3.0165056118905835
Validation loss: 2.4578718517369764

Epoch: 5| Step: 2
Training loss: 2.711381419660624
Validation loss: 2.4621892460291033

Epoch: 5| Step: 3
Training loss: 2.2855472588819965
Validation loss: 2.464669904104746

Epoch: 5| Step: 4
Training loss: 2.2973369730660242
Validation loss: 2.4655406428202657

Epoch: 5| Step: 5
Training loss: 2.474279271774689
Validation loss: 2.4553922999948985

Epoch: 5| Step: 6
Training loss: 2.4529346951089503
Validation loss: 2.4574693775371124

Epoch: 5| Step: 7
Training loss: 2.3923646668172567
Validation loss: 2.46288330819205

Epoch: 5| Step: 8
Training loss: 2.2816854609998796
Validation loss: 2.463290402675393

Epoch: 5| Step: 9
Training loss: 2.656498706618428
Validation loss: 2.465298116552303

Epoch: 5| Step: 10
Training loss: 2.548498373514951
Validation loss: 2.468784448729369

Epoch: 5| Step: 11
Training loss: 2.9488106350488077
Validation loss: 2.4700889376858832

Epoch: 147| Step: 0
Training loss: 2.4410660895840244
Validation loss: 2.4719256847986855

Epoch: 5| Step: 1
Training loss: 2.73402158360588
Validation loss: 2.478140752292515

Epoch: 5| Step: 2
Training loss: 2.739334056425552
Validation loss: 2.4774999318474107

Epoch: 5| Step: 3
Training loss: 2.3559928045373435
Validation loss: 2.4751648112694173

Epoch: 5| Step: 4
Training loss: 2.611592247330103
Validation loss: 2.4711203442747625

Epoch: 5| Step: 5
Training loss: 2.3495399674131274
Validation loss: 2.4691487565701546

Epoch: 5| Step: 6
Training loss: 2.3091780024892357
Validation loss: 2.461932749048717

Epoch: 5| Step: 7
Training loss: 2.228965880956462
Validation loss: 2.4623981561271524

Epoch: 5| Step: 8
Training loss: 2.2912830609705828
Validation loss: 2.464969053473958

Epoch: 5| Step: 9
Training loss: 2.9660146861211145
Validation loss: 2.456596408809412

Epoch: 5| Step: 10
Training loss: 2.707541061329523
Validation loss: 2.4610052210456486

Epoch: 5| Step: 11
Training loss: 1.8760320366318033
Validation loss: 2.463764468246859

Epoch: 148| Step: 0
Training loss: 2.8804407468613547
Validation loss: 2.493641758882541

Epoch: 5| Step: 1
Training loss: 2.6623545790525442
Validation loss: 2.505883141174757

Epoch: 5| Step: 2
Training loss: 2.6584724553295356
Validation loss: 2.4949012618126405

Epoch: 5| Step: 3
Training loss: 2.4918097804719492
Validation loss: 2.4954729019489412

Epoch: 5| Step: 4
Training loss: 2.5097932687862317
Validation loss: 2.4751447235526793

Epoch: 5| Step: 5
Training loss: 2.4506927873127764
Validation loss: 2.4625737518071307

Epoch: 5| Step: 6
Training loss: 2.1108901622103655
Validation loss: 2.45603154539982

Epoch: 5| Step: 7
Training loss: 2.6656934829984285
Validation loss: 2.461759484479773

Epoch: 5| Step: 8
Training loss: 2.6178231904930764
Validation loss: 2.4605085897326107

Epoch: 5| Step: 9
Training loss: 2.385707409949139
Validation loss: 2.4639443229084947

Epoch: 5| Step: 10
Training loss: 2.518345658856804
Validation loss: 2.459011870562019

Epoch: 5| Step: 11
Training loss: 2.0591001521130257
Validation loss: 2.4617229600856447

Epoch: 149| Step: 0
Training loss: 2.822018685806884
Validation loss: 2.466233278447607

Epoch: 5| Step: 1
Training loss: 2.1569475897592554
Validation loss: 2.472206990918972

Epoch: 5| Step: 2
Training loss: 1.820142549759079
Validation loss: 2.4702473779242395

Epoch: 5| Step: 3
Training loss: 2.427447595944079
Validation loss: 2.4721997097207162

Epoch: 5| Step: 4
Training loss: 2.680954347329208
Validation loss: 2.4725552378065117

Epoch: 5| Step: 5
Training loss: 2.4447676078957303
Validation loss: 2.4723599333186153

Epoch: 5| Step: 6
Training loss: 2.2538436272712903
Validation loss: 2.4713071062265466

Epoch: 5| Step: 7
Training loss: 2.2187325920174272
Validation loss: 2.4677056827963018

Epoch: 5| Step: 8
Training loss: 2.688053695062936
Validation loss: 2.4611934064587597

Epoch: 5| Step: 9
Training loss: 2.847607689379333
Validation loss: 2.4610592806924267

Epoch: 5| Step: 10
Training loss: 2.967434882949565
Validation loss: 2.4590390668689666

Epoch: 5| Step: 11
Training loss: 3.6956428235025975
Validation loss: 2.455595384326793

Epoch: 150| Step: 0
Training loss: 2.431448246343318
Validation loss: 2.4535486256445482

Epoch: 5| Step: 1
Training loss: 2.55468274037329
Validation loss: 2.45111686979182

Epoch: 5| Step: 2
Training loss: 2.4939210417178406
Validation loss: 2.4510728610888513

Epoch: 5| Step: 3
Training loss: 2.688605945936599
Validation loss: 2.451802052905261

Epoch: 5| Step: 4
Training loss: 2.731940619056539
Validation loss: 2.460287720813749

Epoch: 5| Step: 5
Training loss: 2.5250644222388265
Validation loss: 2.454975649025981

Epoch: 5| Step: 6
Training loss: 2.300141379945332
Validation loss: 2.456477642106918

Epoch: 5| Step: 7
Training loss: 3.170291599375875
Validation loss: 2.452303844142208

Epoch: 5| Step: 8
Training loss: 2.1671439036499622
Validation loss: 2.4525002941516383

Epoch: 5| Step: 9
Training loss: 2.101584735738547
Validation loss: 2.449214138288278

Epoch: 5| Step: 10
Training loss: 2.5051684359878235
Validation loss: 2.4544014454656966

Epoch: 5| Step: 11
Training loss: 1.4326614549866594
Validation loss: 2.456017524129661

Epoch: 151| Step: 0
Training loss: 2.6303931646587726
Validation loss: 2.455548791878458

Epoch: 5| Step: 1
Training loss: 2.167166896686377
Validation loss: 2.4640770156423124

Epoch: 5| Step: 2
Training loss: 2.154764078064394
Validation loss: 2.467540199077302

Epoch: 5| Step: 3
Training loss: 2.5279302609276564
Validation loss: 2.4676995114745397

Epoch: 5| Step: 4
Training loss: 2.272828115480159
Validation loss: 2.468395903902071

Epoch: 5| Step: 5
Training loss: 2.5845366310952422
Validation loss: 2.468999262591664

Epoch: 5| Step: 6
Training loss: 2.647068986686195
Validation loss: 2.4675918993379997

Epoch: 5| Step: 7
Training loss: 2.904453009158466
Validation loss: 2.4678685147711747

Epoch: 5| Step: 8
Training loss: 2.365150406069106
Validation loss: 2.46168439722703

Epoch: 5| Step: 9
Training loss: 2.3597370400455304
Validation loss: 2.4627197754924373

Epoch: 5| Step: 10
Training loss: 2.8574008484573263
Validation loss: 2.457368881081879

Epoch: 5| Step: 11
Training loss: 2.0229676632750446
Validation loss: 2.464457409582335

Epoch: 152| Step: 0
Training loss: 2.675856807783578
Validation loss: 2.4649180155758708

Epoch: 5| Step: 1
Training loss: 2.720064568875176
Validation loss: 2.4636632547892545

Epoch: 5| Step: 2
Training loss: 2.3841719954679
Validation loss: 2.4660089824749596

Epoch: 5| Step: 3
Training loss: 2.6140645539617138
Validation loss: 2.4588596594151935

Epoch: 5| Step: 4
Training loss: 2.369049850448211
Validation loss: 2.4595291023171506

Epoch: 5| Step: 5
Training loss: 2.3963073814339215
Validation loss: 2.467972451907935

Epoch: 5| Step: 6
Training loss: 2.8179424609339994
Validation loss: 2.4580381156903455

Epoch: 5| Step: 7
Training loss: 2.588744884064103
Validation loss: 2.4565457995049695

Epoch: 5| Step: 8
Training loss: 3.0366193271747757
Validation loss: 2.4643281134320465

Epoch: 5| Step: 9
Training loss: 1.743258980696585
Validation loss: 2.458177928673184

Epoch: 5| Step: 10
Training loss: 1.8602545445092808
Validation loss: 2.4624952643812055

Epoch: 5| Step: 11
Training loss: 2.6434061426507394
Validation loss: 2.4601356330234627

Epoch: 153| Step: 0
Training loss: 2.3414922393598534
Validation loss: 2.4591516140440812

Epoch: 5| Step: 1
Training loss: 3.033015415453073
Validation loss: 2.454353571565834

Epoch: 5| Step: 2
Training loss: 2.6762889965054524
Validation loss: 2.459175682150451

Epoch: 5| Step: 3
Training loss: 2.480272468550484
Validation loss: 2.4650850273650415

Epoch: 5| Step: 4
Training loss: 2.535335869443382
Validation loss: 2.4590597305285486

Epoch: 5| Step: 5
Training loss: 2.2156980774184643
Validation loss: 2.456757769301579

Epoch: 5| Step: 6
Training loss: 2.222683924819469
Validation loss: 2.4556616770159985

Epoch: 5| Step: 7
Training loss: 2.947679453944748
Validation loss: 2.4599699671651383

Epoch: 5| Step: 8
Training loss: 2.0686486810034905
Validation loss: 2.4602443162845784

Epoch: 5| Step: 9
Training loss: 2.5516898857503767
Validation loss: 2.463402037800216

Epoch: 5| Step: 10
Training loss: 2.3503385381140087
Validation loss: 2.4603601616086377

Epoch: 5| Step: 11
Training loss: 2.6831837969828145
Validation loss: 2.4588495105930153

Epoch: 154| Step: 0
Training loss: 2.720692609231293
Validation loss: 2.4571487871691367

Epoch: 5| Step: 1
Training loss: 2.791073883281493
Validation loss: 2.46445598262521

Epoch: 5| Step: 2
Training loss: 2.6550979808824264
Validation loss: 2.465656362188258

Epoch: 5| Step: 3
Training loss: 2.395186616161466
Validation loss: 2.4629148259739804

Epoch: 5| Step: 4
Training loss: 2.053212263555
Validation loss: 2.463053936627294

Epoch: 5| Step: 5
Training loss: 2.4860591338375793
Validation loss: 2.4696788127079783

Epoch: 5| Step: 6
Training loss: 1.976061007241325
Validation loss: 2.467557550710576

Epoch: 5| Step: 7
Training loss: 2.85907747982536
Validation loss: 2.468117838211855

Epoch: 5| Step: 8
Training loss: 2.4277334911439965
Validation loss: 2.4706016509637285

Epoch: 5| Step: 9
Training loss: 2.6943329288788025
Validation loss: 2.469447174298418

Epoch: 5| Step: 10
Training loss: 2.5605042291810043
Validation loss: 2.465822657215779

Epoch: 5| Step: 11
Training loss: 1.4628461314057268
Validation loss: 2.4709628404660973

Epoch: 155| Step: 0
Training loss: 3.1960687092257256
Validation loss: 2.4641952185405946

Epoch: 5| Step: 1
Training loss: 2.416466167507523
Validation loss: 2.466342230727103

Epoch: 5| Step: 2
Training loss: 2.3328939659984114
Validation loss: 2.460860631640412

Epoch: 5| Step: 3
Training loss: 2.1570209838667096
Validation loss: 2.4554722807669997

Epoch: 5| Step: 4
Training loss: 2.3426864245317387
Validation loss: 2.4568624190813266

Epoch: 5| Step: 5
Training loss: 2.5793126000781914
Validation loss: 2.4601201350061896

Epoch: 5| Step: 6
Training loss: 2.8913946003590296
Validation loss: 2.4630134061842672

Epoch: 5| Step: 7
Training loss: 1.9024106117733794
Validation loss: 2.4629119501040226

Epoch: 5| Step: 8
Training loss: 1.906038991787448
Validation loss: 2.469147786956492

Epoch: 5| Step: 9
Training loss: 2.721280027897602
Validation loss: 2.4608475522350606

Epoch: 5| Step: 10
Training loss: 2.5010230832016562
Validation loss: 2.465233463163675

Epoch: 5| Step: 11
Training loss: 3.170390867089115
Validation loss: 2.4662466434765915

Epoch: 156| Step: 0
Training loss: 2.8343780685795132
Validation loss: 2.456932356986596

Epoch: 5| Step: 1
Training loss: 2.398334016338125
Validation loss: 2.4655309163601538

Epoch: 5| Step: 2
Training loss: 2.7872272511973066
Validation loss: 2.4694730287386752

Epoch: 5| Step: 3
Training loss: 2.416484124316005
Validation loss: 2.4653154940399005

Epoch: 5| Step: 4
Training loss: 2.7487369584576062
Validation loss: 2.466747759654509

Epoch: 5| Step: 5
Training loss: 2.1474411752302363
Validation loss: 2.4753411788380317

Epoch: 5| Step: 6
Training loss: 2.272621663847669
Validation loss: 2.4753138967666697

Epoch: 5| Step: 7
Training loss: 2.816968462273557
Validation loss: 2.4784452540089927

Epoch: 5| Step: 8
Training loss: 2.780043007909046
Validation loss: 2.475880770710861

Epoch: 5| Step: 9
Training loss: 2.48167282076402
Validation loss: 2.4783476944735843

Epoch: 5| Step: 10
Training loss: 2.3032285048519925
Validation loss: 2.4699841967423355

Epoch: 5| Step: 11
Training loss: 2.388694831694162
Validation loss: 2.4758995725252966

Epoch: 157| Step: 0
Training loss: 2.136727453350076
Validation loss: 2.4761593487517963

Epoch: 5| Step: 1
Training loss: 2.8434768377883044
Validation loss: 2.47362193313417

Epoch: 5| Step: 2
Training loss: 2.692788974481678
Validation loss: 2.4606503233294084

Epoch: 5| Step: 3
Training loss: 2.3259742582410494
Validation loss: 2.4580506159506372

Epoch: 5| Step: 4
Training loss: 2.6831239069686075
Validation loss: 2.458669628697319

Epoch: 5| Step: 5
Training loss: 2.3688646676282707
Validation loss: 2.464447614351542

Epoch: 5| Step: 6
Training loss: 2.6597702037532645
Validation loss: 2.4589740327754446

Epoch: 5| Step: 7
Training loss: 2.3017352317120006
Validation loss: 2.4554958792294377

Epoch: 5| Step: 8
Training loss: 2.0699074402907125
Validation loss: 2.4569045146850406

Epoch: 5| Step: 9
Training loss: 2.6835134347060845
Validation loss: 2.4610119924422307

Epoch: 5| Step: 10
Training loss: 2.6901168502897583
Validation loss: 2.4619907083248216

Epoch: 5| Step: 11
Training loss: 2.7806080280865504
Validation loss: 2.4507541498127474

Epoch: 158| Step: 0
Training loss: 2.879070220377111
Validation loss: 2.468081585014509

Epoch: 5| Step: 1
Training loss: 2.568729643729457
Validation loss: 2.4787005071721393

Epoch: 5| Step: 2
Training loss: 2.6027145813234105
Validation loss: 2.4745872875935033

Epoch: 5| Step: 3
Training loss: 2.622705546743327
Validation loss: 2.4589023308755964

Epoch: 5| Step: 4
Training loss: 2.2642063303161875
Validation loss: 2.4692867476207896

Epoch: 5| Step: 5
Training loss: 2.094664189048061
Validation loss: 2.4584135403452954

Epoch: 5| Step: 6
Training loss: 2.1437321965226244
Validation loss: 2.4568067204470023

Epoch: 5| Step: 7
Training loss: 2.4395146969186174
Validation loss: 2.4540098097003296

Epoch: 5| Step: 8
Training loss: 2.857762783779811
Validation loss: 2.4485584608108093

Epoch: 5| Step: 9
Training loss: 2.7044605638136314
Validation loss: 2.455569225994116

Epoch: 5| Step: 10
Training loss: 2.2715403188309167
Validation loss: 2.453024775083574

Epoch: 5| Step: 11
Training loss: 3.408225790128791
Validation loss: 2.4588637722619353

Epoch: 159| Step: 0
Training loss: 2.464054906394351
Validation loss: 2.4584509341888454

Epoch: 5| Step: 1
Training loss: 2.7944891785954566
Validation loss: 2.4548424582617296

Epoch: 5| Step: 2
Training loss: 2.1124124768426635
Validation loss: 2.456877470637111

Epoch: 5| Step: 3
Training loss: 2.6388713724547714
Validation loss: 2.457277157298535

Epoch: 5| Step: 4
Training loss: 2.22833524035779
Validation loss: 2.454318361716004

Epoch: 5| Step: 5
Training loss: 2.415893748978576
Validation loss: 2.46091884626151

Epoch: 5| Step: 6
Training loss: 2.8386184168714124
Validation loss: 2.460821833238644

Epoch: 5| Step: 7
Training loss: 2.257041931655236
Validation loss: 2.4638352141924598

Epoch: 5| Step: 8
Training loss: 2.2135212497143577
Validation loss: 2.464483594501986

Epoch: 5| Step: 9
Training loss: 2.823666424909748
Validation loss: 2.4630908607363327

Epoch: 5| Step: 10
Training loss: 2.4886474339930547
Validation loss: 2.466149344571013

Epoch: 5| Step: 11
Training loss: 2.3536446816923515
Validation loss: 2.4717247661296553

Epoch: 160| Step: 0
Training loss: 2.4221661792575184
Validation loss: 2.46874804033934

Epoch: 5| Step: 1
Training loss: 2.7930436984589884
Validation loss: 2.477992534424284

Epoch: 5| Step: 2
Training loss: 2.713129394218368
Validation loss: 2.4786583128153605

Epoch: 5| Step: 3
Training loss: 2.6928464360980113
Validation loss: 2.4808053496651947

Epoch: 5| Step: 4
Training loss: 2.312716293529734
Validation loss: 2.4675158522353384

Epoch: 5| Step: 5
Training loss: 2.1508741952452666
Validation loss: 2.4730251171709696

Epoch: 5| Step: 6
Training loss: 2.1264107453114223
Validation loss: 2.4692219633136907

Epoch: 5| Step: 7
Training loss: 2.729713346362234
Validation loss: 2.460019831642084

Epoch: 5| Step: 8
Training loss: 2.4167155776061926
Validation loss: 2.4742153288553905

Epoch: 5| Step: 9
Training loss: 2.5282460979415338
Validation loss: 2.4619121982759578

Epoch: 5| Step: 10
Training loss: 2.4063465049514563
Validation loss: 2.461239803254985

Epoch: 5| Step: 11
Training loss: 2.075720981215421
Validation loss: 2.46187689073588

Epoch: 161| Step: 0
Training loss: 2.728888189265313
Validation loss: 2.4674938362029137

Epoch: 5| Step: 1
Training loss: 1.7374164616104077
Validation loss: 2.463334941188131

Epoch: 5| Step: 2
Training loss: 2.4360047669387552
Validation loss: 2.4590725204994652

Epoch: 5| Step: 3
Training loss: 1.9693282958327638
Validation loss: 2.465844875502917

Epoch: 5| Step: 4
Training loss: 2.8627975908867045
Validation loss: 2.459316935130492

Epoch: 5| Step: 5
Training loss: 2.5582239713706287
Validation loss: 2.46744644581022

Epoch: 5| Step: 6
Training loss: 2.5759272600234433
Validation loss: 2.4617220198305803

Epoch: 5| Step: 7
Training loss: 2.485356742688609
Validation loss: 2.4658749252667143

Epoch: 5| Step: 8
Training loss: 2.237492980093573
Validation loss: 2.4645880129703346

Epoch: 5| Step: 9
Training loss: 2.830221337064022
Validation loss: 2.467627064719442

Epoch: 5| Step: 10
Training loss: 2.654029097253111
Validation loss: 2.462236830402021

Epoch: 5| Step: 11
Training loss: 2.6324469881434918
Validation loss: 2.4737934291825376

Epoch: 162| Step: 0
Training loss: 3.064506185058885
Validation loss: 2.476900813664233

Epoch: 5| Step: 1
Training loss: 2.782320138168382
Validation loss: 2.4752678922044997

Epoch: 5| Step: 2
Training loss: 2.1460984692766414
Validation loss: 2.4664376773308145

Epoch: 5| Step: 3
Training loss: 1.693998046954942
Validation loss: 2.4681155963009203

Epoch: 5| Step: 4
Training loss: 2.420643942729526
Validation loss: 2.466123012180672

Epoch: 5| Step: 5
Training loss: 2.4379062803059464
Validation loss: 2.459474865648152

Epoch: 5| Step: 6
Training loss: 2.5255927457121037
Validation loss: 2.4676508126426095

Epoch: 5| Step: 7
Training loss: 2.4334904876893018
Validation loss: 2.4601886074005295

Epoch: 5| Step: 8
Training loss: 2.728264919332845
Validation loss: 2.4723910349693585

Epoch: 5| Step: 9
Training loss: 2.8092752407128563
Validation loss: 2.4689768413353965

Epoch: 5| Step: 10
Training loss: 2.264559054368836
Validation loss: 2.472679937569612

Epoch: 5| Step: 11
Training loss: 0.7287799672660631
Validation loss: 2.479495460815593

Epoch: 163| Step: 0
Training loss: 2.6929136354158922
Validation loss: 2.490840312564687

Epoch: 5| Step: 1
Training loss: 1.9791111854673902
Validation loss: 2.492440536711827

Epoch: 5| Step: 2
Training loss: 2.6692879628197836
Validation loss: 2.479945190122682

Epoch: 5| Step: 3
Training loss: 2.718715799050776
Validation loss: 2.4954462579664938

Epoch: 5| Step: 4
Training loss: 2.511832179805334
Validation loss: 2.483666302906295

Epoch: 5| Step: 5
Training loss: 2.2031659061611317
Validation loss: 2.4936156371336677

Epoch: 5| Step: 6
Training loss: 2.4098007953987897
Validation loss: 2.480757973297006

Epoch: 5| Step: 7
Training loss: 2.574626514051918
Validation loss: 2.4762539756649273

Epoch: 5| Step: 8
Training loss: 1.8335712524126109
Validation loss: 2.48542182588215

Epoch: 5| Step: 9
Training loss: 2.290507202450217
Validation loss: 2.4862724511724874

Epoch: 5| Step: 10
Training loss: 2.849714793607814
Validation loss: 2.4796941273566055

Epoch: 5| Step: 11
Training loss: 3.5780181202480295
Validation loss: 2.477152861337778

Epoch: 164| Step: 0
Training loss: 1.9957801288794816
Validation loss: 2.478392525560138

Epoch: 5| Step: 1
Training loss: 2.3091966903461927
Validation loss: 2.4844901280148473

Epoch: 5| Step: 2
Training loss: 3.0024108736275834
Validation loss: 2.480719450048532

Epoch: 5| Step: 3
Training loss: 1.8096926421861639
Validation loss: 2.4866121843542426

Epoch: 5| Step: 4
Training loss: 2.513875791493317
Validation loss: 2.4763761023041964

Epoch: 5| Step: 5
Training loss: 2.3822054730762816
Validation loss: 2.4811384243225056

Epoch: 5| Step: 6
Training loss: 1.9302338973313526
Validation loss: 2.4710308274780552

Epoch: 5| Step: 7
Training loss: 2.6643501193598254
Validation loss: 2.4776088297293977

Epoch: 5| Step: 8
Training loss: 3.0106210254265204
Validation loss: 2.477805462504603

Epoch: 5| Step: 9
Training loss: 2.229654514253203
Validation loss: 2.4652328748300003

Epoch: 5| Step: 10
Training loss: 2.8686182261933926
Validation loss: 2.476670857494842

Epoch: 5| Step: 11
Training loss: 2.3361911189464752
Validation loss: 2.4887758738528185

Epoch: 165| Step: 0
Training loss: 2.821915358617039
Validation loss: 2.4861126906521953

Epoch: 5| Step: 1
Training loss: 2.3900724283520267
Validation loss: 2.4906940709088876

Epoch: 5| Step: 2
Training loss: 2.415998454175543
Validation loss: 2.482366151581952

Epoch: 5| Step: 3
Training loss: 3.002960810306199
Validation loss: 2.4848439875572246

Epoch: 5| Step: 4
Training loss: 2.3148601962692013
Validation loss: 2.47949682703294

Epoch: 5| Step: 5
Training loss: 2.1043268904413868
Validation loss: 2.48641071846647

Epoch: 5| Step: 6
Training loss: 2.7295793604706606
Validation loss: 2.485695493991959

Epoch: 5| Step: 7
Training loss: 2.7895874897073822
Validation loss: 2.478710654871926

Epoch: 5| Step: 8
Training loss: 1.9606552832821125
Validation loss: 2.4848068029994343

Epoch: 5| Step: 9
Training loss: 1.8758787003528505
Validation loss: 2.4846307794788665

Epoch: 5| Step: 10
Training loss: 2.4821664842380846
Validation loss: 2.4800209301980556

Epoch: 5| Step: 11
Training loss: 2.308803387465077
Validation loss: 2.473219852988824

Epoch: 166| Step: 0
Training loss: 2.3813241781861136
Validation loss: 2.4814824233269475

Epoch: 5| Step: 1
Training loss: 2.6787921978025038
Validation loss: 2.480604785783326

Epoch: 5| Step: 2
Training loss: 2.2922441159610822
Validation loss: 2.4878821419708865

Epoch: 5| Step: 3
Training loss: 2.3624383100902198
Validation loss: 2.4867378930032067

Epoch: 5| Step: 4
Training loss: 2.6631156603585167
Validation loss: 2.4890620245796384

Epoch: 5| Step: 5
Training loss: 2.8940491886242636
Validation loss: 2.48507761266716

Epoch: 5| Step: 6
Training loss: 2.4176415636495094
Validation loss: 2.4894291472206795

Epoch: 5| Step: 7
Training loss: 2.299783227905453
Validation loss: 2.482627650030228

Epoch: 5| Step: 8
Training loss: 2.356612147825157
Validation loss: 2.485650882546225

Epoch: 5| Step: 9
Training loss: 2.3728663246322945
Validation loss: 2.4843088976945022

Epoch: 5| Step: 10
Training loss: 2.3000161626496687
Validation loss: 2.476328103638883

Epoch: 5| Step: 11
Training loss: 2.835984074654139
Validation loss: 2.4708605528924856

Epoch: 167| Step: 0
Training loss: 2.068317531778417
Validation loss: 2.484333429848465

Epoch: 5| Step: 1
Training loss: 2.042055936280741
Validation loss: 2.495869164270689

Epoch: 5| Step: 2
Training loss: 2.1406535125838326
Validation loss: 2.4864585704401163

Epoch: 5| Step: 3
Training loss: 1.592409580005268
Validation loss: 2.4950022014641333

Epoch: 5| Step: 4
Training loss: 2.547689857483504
Validation loss: 2.4919046662019593

Epoch: 5| Step: 5
Training loss: 2.8146424504492304
Validation loss: 2.4973154277142635

Epoch: 5| Step: 6
Training loss: 2.2959558633090986
Validation loss: 2.502042659097528

Epoch: 5| Step: 7
Training loss: 2.3691706140543225
Validation loss: 2.4952460666922716

Epoch: 5| Step: 8
Training loss: 3.3890441865896683
Validation loss: 2.4874261198142693

Epoch: 5| Step: 9
Training loss: 2.5599484650073823
Validation loss: 2.4864009378044427

Epoch: 5| Step: 10
Training loss: 2.5289306375472513
Validation loss: 2.4871188712034877

Epoch: 5| Step: 11
Training loss: 3.3584552304190396
Validation loss: 2.4836092914528223

Epoch: 168| Step: 0
Training loss: 2.2403467577521794
Validation loss: 2.4836420861478734

Epoch: 5| Step: 1
Training loss: 2.05048012112086
Validation loss: 2.487111453920269

Epoch: 5| Step: 2
Training loss: 2.3985841190616184
Validation loss: 2.484559102304632

Epoch: 5| Step: 3
Training loss: 2.9977771153067136
Validation loss: 2.497365958652009

Epoch: 5| Step: 4
Training loss: 2.569636850341514
Validation loss: 2.495224217696627

Epoch: 5| Step: 5
Training loss: 2.7868438358964123
Validation loss: 2.493710952108894

Epoch: 5| Step: 6
Training loss: 2.489550687397642
Validation loss: 2.5056783680645354

Epoch: 5| Step: 7
Training loss: 2.5004745033091655
Validation loss: 2.501153485108766

Epoch: 5| Step: 8
Training loss: 2.001388306374619
Validation loss: 2.4896589544348506

Epoch: 5| Step: 9
Training loss: 2.591654655044376
Validation loss: 2.5023832881970685

Epoch: 5| Step: 10
Training loss: 2.2952545054817084
Validation loss: 2.502796766403381

Epoch: 5| Step: 11
Training loss: 1.3183572500706255
Validation loss: 2.495195500786559

Epoch: 169| Step: 0
Training loss: 2.2325093409907795
Validation loss: 2.490826210053478

Epoch: 5| Step: 1
Training loss: 2.2639530721458025
Validation loss: 2.49372905381408

Epoch: 5| Step: 2
Training loss: 1.8743834435507136
Validation loss: 2.4818689234196563

Epoch: 5| Step: 3
Training loss: 2.6821667293351914
Validation loss: 2.4918619678712424

Epoch: 5| Step: 4
Training loss: 2.3450031236574884
Validation loss: 2.4923215369649916

Epoch: 5| Step: 5
Training loss: 2.1784337310692745
Validation loss: 2.4941174539173296

Epoch: 5| Step: 6
Training loss: 2.494722326877325
Validation loss: 2.485612842788106

Epoch: 5| Step: 7
Training loss: 2.4599931146168688
Validation loss: 2.49718831419658

Epoch: 5| Step: 8
Training loss: 2.429787980237422
Validation loss: 2.4976763337375583

Epoch: 5| Step: 9
Training loss: 2.9439760611327923
Validation loss: 2.48828645602829

Epoch: 5| Step: 10
Training loss: 2.711482716022197
Validation loss: 2.4938761332648283

Epoch: 5| Step: 11
Training loss: 3.047882539493335
Validation loss: 2.479090532501567

Epoch: 170| Step: 0
Training loss: 2.6113398115856667
Validation loss: 2.4829291488936307

Epoch: 5| Step: 1
Training loss: 2.339033238005581
Validation loss: 2.4790865153224164

Epoch: 5| Step: 2
Training loss: 2.5865011378871468
Validation loss: 2.481787719882597

Epoch: 5| Step: 3
Training loss: 2.4034594914431273
Validation loss: 2.4881713220097637

Epoch: 5| Step: 4
Training loss: 2.626417413138961
Validation loss: 2.4826789620788072

Epoch: 5| Step: 5
Training loss: 2.4746271025904085
Validation loss: 2.4771832792193935

Epoch: 5| Step: 6
Training loss: 2.3165555909055184
Validation loss: 2.490558785643667

Epoch: 5| Step: 7
Training loss: 2.3932094192658715
Validation loss: 2.491374781160532

Epoch: 5| Step: 8
Training loss: 1.8100427215761135
Validation loss: 2.4805798242885695

Epoch: 5| Step: 9
Training loss: 2.941318059766903
Validation loss: 2.4907131398047917

Epoch: 5| Step: 10
Training loss: 2.5601785891049813
Validation loss: 2.497810404274854

Epoch: 5| Step: 11
Training loss: 1.848902985366754
Validation loss: 2.4925583371184667

Epoch: 171| Step: 0
Training loss: 1.973723230645466
Validation loss: 2.4928800563322624

Epoch: 5| Step: 1
Training loss: 2.573735332104469
Validation loss: 2.4845669990099433

Epoch: 5| Step: 2
Training loss: 2.7040045745968917
Validation loss: 2.4930191007857374

Epoch: 5| Step: 3
Training loss: 2.821443875014344
Validation loss: 2.491633131339516

Epoch: 5| Step: 4
Training loss: 2.476846768884669
Validation loss: 2.4977788077950853

Epoch: 5| Step: 5
Training loss: 2.2451917346393757
Validation loss: 2.5011180602808034

Epoch: 5| Step: 6
Training loss: 2.699458816827469
Validation loss: 2.497729462477404

Epoch: 5| Step: 7
Training loss: 2.858567420856986
Validation loss: 2.5039453091800947

Epoch: 5| Step: 8
Training loss: 1.8786708501918572
Validation loss: 2.5011158479500897

Epoch: 5| Step: 9
Training loss: 2.0839090950408665
Validation loss: 2.5027152316998302

Epoch: 5| Step: 10
Training loss: 2.3275875008726845
Validation loss: 2.5028947244068362

Epoch: 5| Step: 11
Training loss: 1.6966352093121795
Validation loss: 2.498142227687355

Epoch: 172| Step: 0
Training loss: 2.8586603324248228
Validation loss: 2.505436533304565

Epoch: 5| Step: 1
Training loss: 2.256175995772796
Validation loss: 2.5006311772213072

Epoch: 5| Step: 2
Training loss: 2.502831762618138
Validation loss: 2.5062429997194977

Epoch: 5| Step: 3
Training loss: 2.684666315154337
Validation loss: 2.5075881120826535

Epoch: 5| Step: 4
Training loss: 1.5445421912153567
Validation loss: 2.5027183734240754

Epoch: 5| Step: 5
Training loss: 3.023270634425488
Validation loss: 2.511240579939663

Epoch: 5| Step: 6
Training loss: 2.637394752029633
Validation loss: 2.5014325448281083

Epoch: 5| Step: 7
Training loss: 2.0308176607579367
Validation loss: 2.502052553312064

Epoch: 5| Step: 8
Training loss: 2.515927314363368
Validation loss: 2.48934193695099

Epoch: 5| Step: 9
Training loss: 2.446450258224515
Validation loss: 2.492747384443088

Epoch: 5| Step: 10
Training loss: 2.1885032533024886
Validation loss: 2.4872006236167596

Epoch: 5| Step: 11
Training loss: 1.3223061491984172
Validation loss: 2.479066130792827

Epoch: 173| Step: 0
Training loss: 2.1637969697628705
Validation loss: 2.4864898293435025

Epoch: 5| Step: 1
Training loss: 2.2374621851618626
Validation loss: 2.489626969203779

Epoch: 5| Step: 2
Training loss: 2.6207569889498328
Validation loss: 2.4848489629135937

Epoch: 5| Step: 3
Training loss: 2.920528979005672
Validation loss: 2.4855055565831727

Epoch: 5| Step: 4
Training loss: 2.637241249589961
Validation loss: 2.4912534256774554

Epoch: 5| Step: 5
Training loss: 2.47840846245628
Validation loss: 2.4884452965366064

Epoch: 5| Step: 6
Training loss: 2.5278438680576882
Validation loss: 2.4981439376239227

Epoch: 5| Step: 7
Training loss: 2.5250886882654155
Validation loss: 2.495585195267093

Epoch: 5| Step: 8
Training loss: 2.406788357047141
Validation loss: 2.484763852763342

Epoch: 5| Step: 9
Training loss: 2.0952756646635775
Validation loss: 2.499789264857001

Epoch: 5| Step: 10
Training loss: 2.588424178488372
Validation loss: 2.503585723500306

Epoch: 5| Step: 11
Training loss: 1.5741088677385964
Validation loss: 2.5003598947558077

Epoch: 174| Step: 0
Training loss: 2.6732966338545605
Validation loss: 2.5019227819416825

Epoch: 5| Step: 1
Training loss: 2.8815551331445253
Validation loss: 2.494972122265341

Epoch: 5| Step: 2
Training loss: 2.63652686657122
Validation loss: 2.497715476420378

Epoch: 5| Step: 3
Training loss: 2.405636597761749
Validation loss: 2.4942413086709316

Epoch: 5| Step: 4
Training loss: 2.287811770846112
Validation loss: 2.498455552033335

Epoch: 5| Step: 5
Training loss: 2.1634141522296146
Validation loss: 2.4914001129830807

Epoch: 5| Step: 6
Training loss: 2.063777990030073
Validation loss: 2.4882883404162124

Epoch: 5| Step: 7
Training loss: 2.8263025471097523
Validation loss: 2.487149203148185

Epoch: 5| Step: 8
Training loss: 2.5670767130428676
Validation loss: 2.495902848642186

Epoch: 5| Step: 9
Training loss: 2.6262615442181145
Validation loss: 2.486772847563408

Epoch: 5| Step: 10
Training loss: 1.7040067717413152
Validation loss: 2.4891528884047456

Epoch: 5| Step: 11
Training loss: 1.923764052510137
Validation loss: 2.4984313315068274

Epoch: 175| Step: 0
Training loss: 2.2407677172720413
Validation loss: 2.4885077620429876

Epoch: 5| Step: 1
Training loss: 2.9188984279753405
Validation loss: 2.5003570778468607

Epoch: 5| Step: 2
Training loss: 2.4192567516255163
Validation loss: 2.4989971056643205

Epoch: 5| Step: 3
Training loss: 2.2074834039740368
Validation loss: 2.4933047246842905

Epoch: 5| Step: 4
Training loss: 2.4926890284142362
Validation loss: 2.488538955286741

Epoch: 5| Step: 5
Training loss: 2.887267105816854
Validation loss: 2.4995388320909915

Epoch: 5| Step: 6
Training loss: 2.0737895054471736
Validation loss: 2.493428605863756

Epoch: 5| Step: 7
Training loss: 2.707767270916174
Validation loss: 2.4949111246220124

Epoch: 5| Step: 8
Training loss: 2.184581007950461
Validation loss: 2.4926132269024075

Epoch: 5| Step: 9
Training loss: 1.922487548966387
Validation loss: 2.4879197197876595

Epoch: 5| Step: 10
Training loss: 2.735662364360292
Validation loss: 2.492560822080533

Epoch: 5| Step: 11
Training loss: 1.1882401719476428
Validation loss: 2.4873314466511034

Epoch: 176| Step: 0
Training loss: 2.8012921281035825
Validation loss: 2.4830936870429716

Epoch: 5| Step: 1
Training loss: 2.3100444024842846
Validation loss: 2.489982402744439

Epoch: 5| Step: 2
Training loss: 2.1481755877285473
Validation loss: 2.492176303021222

Epoch: 5| Step: 3
Training loss: 2.5094728291635393
Validation loss: 2.4931549139834925

Epoch: 5| Step: 4
Training loss: 3.067545568598727
Validation loss: 2.485564121232668

Epoch: 5| Step: 5
Training loss: 2.115874499170552
Validation loss: 2.499936395074443

Epoch: 5| Step: 6
Training loss: 2.106810642867532
Validation loss: 2.5017568653724447

Epoch: 5| Step: 7
Training loss: 2.5193412295107804
Validation loss: 2.4939915376742445

Epoch: 5| Step: 8
Training loss: 2.691105309480223
Validation loss: 2.483858658657277

Epoch: 5| Step: 9
Training loss: 1.8712080440774004
Validation loss: 2.489195862681762

Epoch: 5| Step: 10
Training loss: 2.4386310398606383
Validation loss: 2.4896336487882267

Epoch: 5| Step: 11
Training loss: 1.9316732097226375
Validation loss: 2.487924493339629

Epoch: 177| Step: 0
Training loss: 2.204256457090574
Validation loss: 2.4913560203735363

Epoch: 5| Step: 1
Training loss: 2.3638087164789385
Validation loss: 2.5042379301428395

Epoch: 5| Step: 2
Training loss: 2.083969387869317
Validation loss: 2.48980222056346

Epoch: 5| Step: 3
Training loss: 2.2658142010843365
Validation loss: 2.492916112280513

Epoch: 5| Step: 4
Training loss: 3.215640000733734
Validation loss: 2.4849144212044485

Epoch: 5| Step: 5
Training loss: 2.4616385293986944
Validation loss: 2.4870875043722735

Epoch: 5| Step: 6
Training loss: 2.1606562830718543
Validation loss: 2.4850407474127003

Epoch: 5| Step: 7
Training loss: 2.6474076240712767
Validation loss: 2.4805497504197596

Epoch: 5| Step: 8
Training loss: 2.47511051586285
Validation loss: 2.4822175516858507

Epoch: 5| Step: 9
Training loss: 2.835699402453338
Validation loss: 2.4858840621744953

Epoch: 5| Step: 10
Training loss: 2.211251819495557
Validation loss: 2.4869272569494947

Epoch: 5| Step: 11
Training loss: 1.9191135323054573
Validation loss: 2.5147055136119674

Epoch: 178| Step: 0
Training loss: 2.961911003697316
Validation loss: 2.5170501557855602

Epoch: 5| Step: 1
Training loss: 2.5264665593678948
Validation loss: 2.5334740785246743

Epoch: 5| Step: 2
Training loss: 1.9442418227512448
Validation loss: 2.5511539959946656

Epoch: 5| Step: 3
Training loss: 2.1624218612401322
Validation loss: 2.5493775653693715

Epoch: 5| Step: 4
Training loss: 2.5603703278667154
Validation loss: 2.5666896212674306

Epoch: 5| Step: 5
Training loss: 3.064227492788921
Validation loss: 2.5568138240687164

Epoch: 5| Step: 6
Training loss: 1.4448964937883408
Validation loss: 2.530396401938564

Epoch: 5| Step: 7
Training loss: 2.2001867518489138
Validation loss: 2.5104150508279206

Epoch: 5| Step: 8
Training loss: 2.8434069080679665
Validation loss: 2.5072692567917105

Epoch: 5| Step: 9
Training loss: 2.291861531613621
Validation loss: 2.4977251471517974

Epoch: 5| Step: 10
Training loss: 2.326648320651297
Validation loss: 2.4983901363906815

Epoch: 5| Step: 11
Training loss: 2.944498369534845
Validation loss: 2.4873745522424158

Epoch: 179| Step: 0
Training loss: 2.1380321085760725
Validation loss: 2.4973175757872155

Epoch: 5| Step: 1
Training loss: 2.9422813623400024
Validation loss: 2.493074679736711

Epoch: 5| Step: 2
Training loss: 2.8423339336268323
Validation loss: 2.495523935945478

Epoch: 5| Step: 3
Training loss: 2.1404848818620468
Validation loss: 2.4950885211171263

Epoch: 5| Step: 4
Training loss: 2.2263553991540266
Validation loss: 2.5003134411777994

Epoch: 5| Step: 5
Training loss: 2.548868721240401
Validation loss: 2.5002164468844725

Epoch: 5| Step: 6
Training loss: 2.2172988659322086
Validation loss: 2.4956902370338043

Epoch: 5| Step: 7
Training loss: 2.6896024951995856
Validation loss: 2.496979056471018

Epoch: 5| Step: 8
Training loss: 2.2487990035039593
Validation loss: 2.496207002350003

Epoch: 5| Step: 9
Training loss: 2.223385441506417
Validation loss: 2.5017664668753254

Epoch: 5| Step: 10
Training loss: 2.380894323504007
Validation loss: 2.509489582085493

Epoch: 5| Step: 11
Training loss: 3.3968283164879463
Validation loss: 2.5063348062932613

Epoch: 180| Step: 0
Training loss: 3.1134069936671196
Validation loss: 2.5087780227705316

Epoch: 5| Step: 1
Training loss: 2.6337792859940907
Validation loss: 2.4978441121814043

Epoch: 5| Step: 2
Training loss: 3.0166545158127467
Validation loss: 2.502166139427239

Epoch: 5| Step: 3
Training loss: 2.4623319035972586
Validation loss: 2.5029434717706436

Epoch: 5| Step: 4
Training loss: 1.6516485532863818
Validation loss: 2.5022027920726972

Epoch: 5| Step: 5
Training loss: 2.021282683552356
Validation loss: 2.4978454325691697

Epoch: 5| Step: 6
Training loss: 2.1218643615186297
Validation loss: 2.5112806722256193

Epoch: 5| Step: 7
Training loss: 2.1285453840511206
Validation loss: 2.513603371549022

Epoch: 5| Step: 8
Training loss: 2.31400435720444
Validation loss: 2.506809737263386

Epoch: 5| Step: 9
Training loss: 2.5371101267801044
Validation loss: 2.5182867382191967

Epoch: 5| Step: 10
Training loss: 2.0635877110830565
Validation loss: 2.512130875540684

Epoch: 5| Step: 11
Training loss: 2.917102853765743
Validation loss: 2.497094098672672

Epoch: 181| Step: 0
Training loss: 2.134637184851259
Validation loss: 2.5236561407868954

Epoch: 5| Step: 1
Training loss: 2.629536206068876
Validation loss: 2.5403935860771067

Epoch: 5| Step: 2
Training loss: 3.08975979658386
Validation loss: 2.5745405228547695

Epoch: 5| Step: 3
Training loss: 2.918096700413869
Validation loss: 2.5661177064130865

Epoch: 5| Step: 4
Training loss: 2.395969773982325
Validation loss: 2.5864493486788898

Epoch: 5| Step: 5
Training loss: 2.570641400938536
Validation loss: 2.5575039510674658

Epoch: 5| Step: 6
Training loss: 2.689050094336488
Validation loss: 2.5390500307999613

Epoch: 5| Step: 7
Training loss: 2.0131597302392046
Validation loss: 2.5152345358266994

Epoch: 5| Step: 8
Training loss: 2.1921769417191057
Validation loss: 2.5149146631044674

Epoch: 5| Step: 9
Training loss: 2.076143165885114
Validation loss: 2.5032476232419554

Epoch: 5| Step: 10
Training loss: 2.5354690241259594
Validation loss: 2.4947438437882883

Epoch: 5| Step: 11
Training loss: 2.353147460506084
Validation loss: 2.4855045134140736

Epoch: 182| Step: 0
Training loss: 2.2516301925193547
Validation loss: 2.4803950821958245

Epoch: 5| Step: 1
Training loss: 3.0670311552243317
Validation loss: 2.479179712202439

Epoch: 5| Step: 2
Training loss: 2.2794042985276306
Validation loss: 2.475185781788784

Epoch: 5| Step: 3
Training loss: 2.877658112769698
Validation loss: 2.4749544179617144

Epoch: 5| Step: 4
Training loss: 2.2653910549003045
Validation loss: 2.4810800114591274

Epoch: 5| Step: 5
Training loss: 2.6492334480744124
Validation loss: 2.487476925527238

Epoch: 5| Step: 6
Training loss: 2.632498340370691
Validation loss: 2.485512451080576

Epoch: 5| Step: 7
Training loss: 1.7533926774752855
Validation loss: 2.482572497448624

Epoch: 5| Step: 8
Training loss: 2.7149911085794605
Validation loss: 2.4861761237961066

Epoch: 5| Step: 9
Training loss: 2.0792391665654497
Validation loss: 2.48828300663653

Epoch: 5| Step: 10
Training loss: 2.1735700400971125
Validation loss: 2.48972744039154

Epoch: 5| Step: 11
Training loss: 2.304486489016124
Validation loss: 2.4946906454913944

Epoch: 183| Step: 0
Training loss: 2.6569194174575634
Validation loss: 2.499722874699467

Epoch: 5| Step: 1
Training loss: 2.4899189827848858
Validation loss: 2.5039091978090484

Epoch: 5| Step: 2
Training loss: 2.031107501386852
Validation loss: 2.5008206133300237

Epoch: 5| Step: 3
Training loss: 2.9835253399769655
Validation loss: 2.499122322514205

Epoch: 5| Step: 4
Training loss: 2.8308790085949824
Validation loss: 2.5065933108143295

Epoch: 5| Step: 5
Training loss: 2.1362511717746795
Validation loss: 2.498900402161395

Epoch: 5| Step: 6
Training loss: 2.3290574427490527
Validation loss: 2.4994340295697817

Epoch: 5| Step: 7
Training loss: 2.25995890352136
Validation loss: 2.487992723585801

Epoch: 5| Step: 8
Training loss: 2.1502602353180054
Validation loss: 2.4979430538233496

Epoch: 5| Step: 9
Training loss: 2.1505057072833136
Validation loss: 2.4765888357116004

Epoch: 5| Step: 10
Training loss: 2.6433854882128776
Validation loss: 2.487726002878461

Epoch: 5| Step: 11
Training loss: 2.3923576907382746
Validation loss: 2.497529577519874

Epoch: 184| Step: 0
Training loss: 2.6579876769664983
Validation loss: 2.502534467750038

Epoch: 5| Step: 1
Training loss: 2.781059087137251
Validation loss: 2.5013287351036646

Epoch: 5| Step: 2
Training loss: 2.4770320603625553
Validation loss: 2.49948618695041

Epoch: 5| Step: 3
Training loss: 2.1368214026415755
Validation loss: 2.4981527040128992

Epoch: 5| Step: 4
Training loss: 2.7057565217139112
Validation loss: 2.4954443750028403

Epoch: 5| Step: 5
Training loss: 2.2613213013667774
Validation loss: 2.4922712864040255

Epoch: 5| Step: 6
Training loss: 2.3030507628278865
Validation loss: 2.498376800168739

Epoch: 5| Step: 7
Training loss: 2.6277605709008114
Validation loss: 2.484147271329385

Epoch: 5| Step: 8
Training loss: 2.385845417876378
Validation loss: 2.4878885247693883

Epoch: 5| Step: 9
Training loss: 2.2486373165751163
Validation loss: 2.4802731414321326

Epoch: 5| Step: 10
Training loss: 2.185674614194556
Validation loss: 2.4856586498911177

Epoch: 5| Step: 11
Training loss: 0.817791835303725
Validation loss: 2.4819255085498924

Epoch: 185| Step: 0
Training loss: 2.2936430529366745
Validation loss: 2.491350739017049

Epoch: 5| Step: 1
Training loss: 2.1748681609436864
Validation loss: 2.498567258047003

Epoch: 5| Step: 2
Training loss: 2.0640548856076433
Validation loss: 2.509896764038023

Epoch: 5| Step: 3
Training loss: 2.588341831243271
Validation loss: 2.4981012922518375

Epoch: 5| Step: 4
Training loss: 2.672170254639755
Validation loss: 2.5105226159327185

Epoch: 5| Step: 5
Training loss: 2.819171791068244
Validation loss: 2.522351309707417

Epoch: 5| Step: 6
Training loss: 2.0195180276404674
Validation loss: 2.518165419257238

Epoch: 5| Step: 7
Training loss: 2.33898736887861
Validation loss: 2.502622278143333

Epoch: 5| Step: 8
Training loss: 2.405803886773352
Validation loss: 2.496020607033357

Epoch: 5| Step: 9
Training loss: 2.654335858168937
Validation loss: 2.4863008955637893

Epoch: 5| Step: 10
Training loss: 2.7325205590817507
Validation loss: 2.4890269844281625

Epoch: 5| Step: 11
Training loss: 2.1309863646208416
Validation loss: 2.4863150676934813

Epoch: 186| Step: 0
Training loss: 2.6413737482634176
Validation loss: 2.4778632429436356

Epoch: 5| Step: 1
Training loss: 2.543951310573543
Validation loss: 2.490743719132917

Epoch: 5| Step: 2
Training loss: 2.152190215074586
Validation loss: 2.48755198700732

Epoch: 5| Step: 3
Training loss: 2.3012692722423203
Validation loss: 2.482750151363311

Epoch: 5| Step: 4
Training loss: 2.5180228042600086
Validation loss: 2.485429599938286

Epoch: 5| Step: 5
Training loss: 2.682035168479059
Validation loss: 2.4858241343309375

Epoch: 5| Step: 6
Training loss: 2.3363381747061696
Validation loss: 2.4885884149779662

Epoch: 5| Step: 7
Training loss: 2.7398918954726943
Validation loss: 2.488786443491081

Epoch: 5| Step: 8
Training loss: 1.9555663452910415
Validation loss: 2.4887834817616232

Epoch: 5| Step: 9
Training loss: 2.3644207689865486
Validation loss: 2.483833187929491

Epoch: 5| Step: 10
Training loss: 2.1122634890732095
Validation loss: 2.488704363961593

Epoch: 5| Step: 11
Training loss: 3.2488112109451346
Validation loss: 2.4860112422073595

Epoch: 187| Step: 0
Training loss: 2.568047635845789
Validation loss: 2.493303342127152

Epoch: 5| Step: 1
Training loss: 3.0523785306239244
Validation loss: 2.4849260266933033

Epoch: 5| Step: 2
Training loss: 2.234995829089751
Validation loss: 2.488855386527565

Epoch: 5| Step: 3
Training loss: 2.7185558381301895
Validation loss: 2.489735220953769

Epoch: 5| Step: 4
Training loss: 2.186620699042688
Validation loss: 2.4963147896814686

Epoch: 5| Step: 5
Training loss: 2.6371637717620495
Validation loss: 2.514727730596529

Epoch: 5| Step: 6
Training loss: 2.3798531587965845
Validation loss: 2.500535895608071

Epoch: 5| Step: 7
Training loss: 2.4075129773829027
Validation loss: 2.49769839594393

Epoch: 5| Step: 8
Training loss: 1.9421781851191424
Validation loss: 2.5005529427977926

Epoch: 5| Step: 9
Training loss: 2.2551800121851957
Validation loss: 2.4975893478016515

Epoch: 5| Step: 10
Training loss: 2.1216087207937164
Validation loss: 2.5104199102124882

Epoch: 5| Step: 11
Training loss: 1.4562302092815944
Validation loss: 2.497540159831751

Epoch: 188| Step: 0
Training loss: 2.5401579855798975
Validation loss: 2.4982632087763736

Epoch: 5| Step: 1
Training loss: 1.8448951527027064
Validation loss: 2.499561795930766

Epoch: 5| Step: 2
Training loss: 2.136173715763982
Validation loss: 2.4907483297307516

Epoch: 5| Step: 3
Training loss: 2.6630852212824485
Validation loss: 2.498496521424992

Epoch: 5| Step: 4
Training loss: 2.3623160921399466
Validation loss: 2.4863470276071333

Epoch: 5| Step: 5
Training loss: 2.422315692799408
Validation loss: 2.492473821027451

Epoch: 5| Step: 6
Training loss: 2.2161712704792595
Validation loss: 2.496274138664857

Epoch: 5| Step: 7
Training loss: 2.7624065400621474
Validation loss: 2.4912365620849295

Epoch: 5| Step: 8
Training loss: 2.524242733245512
Validation loss: 2.4976684943885314

Epoch: 5| Step: 9
Training loss: 2.514326909814578
Validation loss: 2.501293817149372

Epoch: 5| Step: 10
Training loss: 2.328690018672293
Validation loss: 2.5023649850977097

Epoch: 5| Step: 11
Training loss: 2.7120193829139168
Validation loss: 2.519525998132244

Epoch: 189| Step: 0
Training loss: 2.636079928400506
Validation loss: 2.530688137128256

Epoch: 5| Step: 1
Training loss: 2.4169817313536455
Validation loss: 2.54511386930743

Epoch: 5| Step: 2
Training loss: 2.718449718510591
Validation loss: 2.537339154831731

Epoch: 5| Step: 3
Training loss: 2.3215630754343537
Validation loss: 2.528270588829491

Epoch: 5| Step: 4
Training loss: 2.197928285492715
Validation loss: 2.5151724951373233

Epoch: 5| Step: 5
Training loss: 2.113247516807073
Validation loss: 2.5107244102455026

Epoch: 5| Step: 6
Training loss: 2.3489293155160653
Validation loss: 2.508440412462089

Epoch: 5| Step: 7
Training loss: 2.274336280000468
Validation loss: 2.504410998827702

Epoch: 5| Step: 8
Training loss: 2.3395680056506083
Validation loss: 2.5068962586252135

Epoch: 5| Step: 9
Training loss: 2.578966500480727
Validation loss: 2.500596785840255

Epoch: 5| Step: 10
Training loss: 2.7470516525594917
Validation loss: 2.504300063214563

Epoch: 5| Step: 11
Training loss: 1.5324548146492445
Validation loss: 2.503413472755323

Epoch: 190| Step: 0
Training loss: 2.3994780529216424
Validation loss: 2.5126986493077257

Epoch: 5| Step: 1
Training loss: 2.003023008704812
Validation loss: 2.5104377806370506

Epoch: 5| Step: 2
Training loss: 2.922011754716628
Validation loss: 2.506896432984528

Epoch: 5| Step: 3
Training loss: 2.3887738808836008
Validation loss: 2.511332081190205

Epoch: 5| Step: 4
Training loss: 2.534431342123079
Validation loss: 2.5067437490213678

Epoch: 5| Step: 5
Training loss: 2.2906932034818692
Validation loss: 2.508539027248118

Epoch: 5| Step: 6
Training loss: 2.0343550204982095
Validation loss: 2.5163870835899305

Epoch: 5| Step: 7
Training loss: 2.9914546696631414
Validation loss: 2.5234674682254905

Epoch: 5| Step: 8
Training loss: 2.3971546233797922
Validation loss: 2.5357640952796325

Epoch: 5| Step: 9
Training loss: 2.2996659741208716
Validation loss: 2.5414967493157414

Epoch: 5| Step: 10
Training loss: 2.081765564075247
Validation loss: 2.529930767813359

Epoch: 5| Step: 11
Training loss: 2.269409701692165
Validation loss: 2.531453352087053

Epoch: 191| Step: 0
Training loss: 2.1266039236772474
Validation loss: 2.5254239195447994

Epoch: 5| Step: 1
Training loss: 2.2893822352289566
Validation loss: 2.5399054746735943

Epoch: 5| Step: 2
Training loss: 1.75973398940158
Validation loss: 2.519661612674378

Epoch: 5| Step: 3
Training loss: 3.0346159190151134
Validation loss: 2.516085106768238

Epoch: 5| Step: 4
Training loss: 2.7185904795885
Validation loss: 2.5195222208812496

Epoch: 5| Step: 5
Training loss: 1.9350277910035754
Validation loss: 2.512568174452611

Epoch: 5| Step: 6
Training loss: 2.5523761711011432
Validation loss: 2.5127793243790095

Epoch: 5| Step: 7
Training loss: 2.1323910251334826
Validation loss: 2.5031560169636617

Epoch: 5| Step: 8
Training loss: 2.7761625415091715
Validation loss: 2.4980703178301944

Epoch: 5| Step: 9
Training loss: 2.1716656481061505
Validation loss: 2.5016076561408163

Epoch: 5| Step: 10
Training loss: 2.551359663105867
Validation loss: 2.4918210109911803

Epoch: 5| Step: 11
Training loss: 2.6967978986944106
Validation loss: 2.490435990293745

Epoch: 192| Step: 0
Training loss: 2.6249123513257224
Validation loss: 2.4983595075078124

Epoch: 5| Step: 1
Training loss: 2.6861673643982247
Validation loss: 2.48862448919495

Epoch: 5| Step: 2
Training loss: 2.251201097125645
Validation loss: 2.495703820470145

Epoch: 5| Step: 3
Training loss: 2.840182739342468
Validation loss: 2.4930405945419007

Epoch: 5| Step: 4
Training loss: 1.975587144324273
Validation loss: 2.500669953859786

Epoch: 5| Step: 5
Training loss: 2.0321957073958106
Validation loss: 2.49518346530506

Epoch: 5| Step: 6
Training loss: 2.345552488853385
Validation loss: 2.4978948630897113

Epoch: 5| Step: 7
Training loss: 2.7009327548884743
Validation loss: 2.50597322462548

Epoch: 5| Step: 8
Training loss: 1.9097868829434712
Validation loss: 2.5057583335352978

Epoch: 5| Step: 9
Training loss: 2.2890758318724393
Validation loss: 2.5055588948172822

Epoch: 5| Step: 10
Training loss: 2.3154378220742284
Validation loss: 2.511804495178942

Epoch: 5| Step: 11
Training loss: 3.4737991837969195
Validation loss: 2.519287890132765

Epoch: 193| Step: 0
Training loss: 2.19960530815365
Validation loss: 2.5469538709601713

Epoch: 5| Step: 1
Training loss: 2.731601987456664
Validation loss: 2.550955800991605

Epoch: 5| Step: 2
Training loss: 2.5520209998997743
Validation loss: 2.5747578605825465

Epoch: 5| Step: 3
Training loss: 2.9080583422342783
Validation loss: 2.584750288068969

Epoch: 5| Step: 4
Training loss: 2.6587092067098097
Validation loss: 2.5789965148740515

Epoch: 5| Step: 5
Training loss: 1.980106298020839
Validation loss: 2.5359026256395403

Epoch: 5| Step: 6
Training loss: 2.1418602713664834
Validation loss: 2.520482390909976

Epoch: 5| Step: 7
Training loss: 2.060030180885923
Validation loss: 2.513512338329401

Epoch: 5| Step: 8
Training loss: 2.6805642698296754
Validation loss: 2.4990484055800644

Epoch: 5| Step: 9
Training loss: 2.299230185508482
Validation loss: 2.5077368268314233

Epoch: 5| Step: 10
Training loss: 2.2863426324047462
Validation loss: 2.500628738019152

Epoch: 5| Step: 11
Training loss: 2.3488468952910297
Validation loss: 2.4946965589027927

Epoch: 194| Step: 0
Training loss: 2.373543242358552
Validation loss: 2.4938442658571387

Epoch: 5| Step: 1
Training loss: 2.0691778564560246
Validation loss: 2.48472643511833

Epoch: 5| Step: 2
Training loss: 2.246534964307414
Validation loss: 2.4869584460502097

Epoch: 5| Step: 3
Training loss: 2.3180796350816073
Validation loss: 2.487125114166241

Epoch: 5| Step: 4
Training loss: 2.5913212446842353
Validation loss: 2.4880480335120425

Epoch: 5| Step: 5
Training loss: 2.98320679493931
Validation loss: 2.4990835059617456

Epoch: 5| Step: 6
Training loss: 2.149566686567886
Validation loss: 2.5025213878224477

Epoch: 5| Step: 7
Training loss: 2.6401927526505866
Validation loss: 2.5186152564924664

Epoch: 5| Step: 8
Training loss: 2.5214865497606325
Validation loss: 2.524236121630007

Epoch: 5| Step: 9
Training loss: 2.414755613704972
Validation loss: 2.5342162220893267

Epoch: 5| Step: 10
Training loss: 2.3709795200037775
Validation loss: 2.53976824220007

Epoch: 5| Step: 11
Training loss: 1.5981799622036799
Validation loss: 2.547919486307584

Epoch: 195| Step: 0
Training loss: 2.8203518936068903
Validation loss: 2.5626414384032628

Epoch: 5| Step: 1
Training loss: 2.3258871293370036
Validation loss: 2.5683282345043104

Epoch: 5| Step: 2
Training loss: 2.272004714893768
Validation loss: 2.56649280404076

Epoch: 5| Step: 3
Training loss: 2.3822891411033313
Validation loss: 2.5262099547549246

Epoch: 5| Step: 4
Training loss: 2.4583519326061394
Validation loss: 2.512709248782494

Epoch: 5| Step: 5
Training loss: 2.2669890408244724
Validation loss: 2.5031294031695794

Epoch: 5| Step: 6
Training loss: 2.9774975847287317
Validation loss: 2.501995744424093

Epoch: 5| Step: 7
Training loss: 2.1436125241343147
Validation loss: 2.4894135522343315

Epoch: 5| Step: 8
Training loss: 2.3386371029507966
Validation loss: 2.498392856112356

Epoch: 5| Step: 9
Training loss: 1.6873856964959177
Validation loss: 2.497297459409443

Epoch: 5| Step: 10
Training loss: 2.3577857317457265
Validation loss: 2.494399337872847

Epoch: 5| Step: 11
Training loss: 3.391370559501068
Validation loss: 2.4897206054468124

Epoch: 196| Step: 0
Training loss: 2.120703786054822
Validation loss: 2.486546125541449

Epoch: 5| Step: 1
Training loss: 2.234272561025876
Validation loss: 2.493868465207057

Epoch: 5| Step: 2
Training loss: 2.147671427695664
Validation loss: 2.4828985013285023

Epoch: 5| Step: 3
Training loss: 2.188537133811482
Validation loss: 2.4972297021836094

Epoch: 5| Step: 4
Training loss: 2.542194113696404
Validation loss: 2.502757058185454

Epoch: 5| Step: 5
Training loss: 2.5890167434875893
Validation loss: 2.496589563643017

Epoch: 5| Step: 6
Training loss: 2.584153127313955
Validation loss: 2.500271230130644

Epoch: 5| Step: 7
Training loss: 2.641836215894878
Validation loss: 2.498090062129737

Epoch: 5| Step: 8
Training loss: 2.1527469208943075
Validation loss: 2.5036569353183777

Epoch: 5| Step: 9
Training loss: 2.5604065508186102
Validation loss: 2.5073601858499286

Epoch: 5| Step: 10
Training loss: 2.524278813470732
Validation loss: 2.5061238506846686

Epoch: 5| Step: 11
Training loss: 2.2672107277330342
Validation loss: 2.5158791857893226

Epoch: 197| Step: 0
Training loss: 2.2524553253451622
Validation loss: 2.496697147450282

Epoch: 5| Step: 1
Training loss: 2.4141887150333616
Validation loss: 2.506666961669482

Epoch: 5| Step: 2
Training loss: 2.7667686554674567
Validation loss: 2.4979671756854516

Epoch: 5| Step: 3
Training loss: 2.444853230695273
Validation loss: 2.4876152556601525

Epoch: 5| Step: 4
Training loss: 2.3841634954035644
Validation loss: 2.4953824115690177

Epoch: 5| Step: 5
Training loss: 2.545231950303777
Validation loss: 2.4864908481278363

Epoch: 5| Step: 6
Training loss: 2.6686792726100665
Validation loss: 2.485119334265195

Epoch: 5| Step: 7
Training loss: 2.2790891263372246
Validation loss: 2.482693737079206

Epoch: 5| Step: 8
Training loss: 2.7186461680962983
Validation loss: 2.4787410776834093

Epoch: 5| Step: 9
Training loss: 1.7115834728082235
Validation loss: 2.4844235669393173

Epoch: 5| Step: 10
Training loss: 2.451965057796159
Validation loss: 2.5003007032429756

Epoch: 5| Step: 11
Training loss: 2.2813331902372194
Validation loss: 2.4946300212653276

Epoch: 198| Step: 0
Training loss: 2.829208419409313
Validation loss: 2.500069833813288

Epoch: 5| Step: 1
Training loss: 2.0314478851175903
Validation loss: 2.531074239178102

Epoch: 5| Step: 2
Training loss: 1.882181465485064
Validation loss: 2.5295746561147796

Epoch: 5| Step: 3
Training loss: 2.011533147157117
Validation loss: 2.549082035751966

Epoch: 5| Step: 4
Training loss: 2.231036486414092
Validation loss: 2.590374605941724

Epoch: 5| Step: 5
Training loss: 2.6593136342159704
Validation loss: 2.588710746129836

Epoch: 5| Step: 6
Training loss: 3.0172796107909563
Validation loss: 2.615150851073771

Epoch: 5| Step: 7
Training loss: 2.7867881413347226
Validation loss: 2.544747421519179

Epoch: 5| Step: 8
Training loss: 2.2924698086979256
Validation loss: 2.520374135420401

Epoch: 5| Step: 9
Training loss: 3.102074107678804
Validation loss: 2.510876436723422

Epoch: 5| Step: 10
Training loss: 2.1140046353537447
Validation loss: 2.504651141839815

Epoch: 5| Step: 11
Training loss: 2.258960471636135
Validation loss: 2.4952557688908414

Epoch: 199| Step: 0
Training loss: 2.9042536944608592
Validation loss: 2.498446808575595

Epoch: 5| Step: 1
Training loss: 1.921185129295298
Validation loss: 2.49424914286028

Epoch: 5| Step: 2
Training loss: 2.492715331239252
Validation loss: 2.4869326136094947

Epoch: 5| Step: 3
Training loss: 2.067365283198004
Validation loss: 2.488551849231563

Epoch: 5| Step: 4
Training loss: 2.9281538954767563
Validation loss: 2.489268507796675

Epoch: 5| Step: 5
Training loss: 2.392727394897192
Validation loss: 2.4964173355456496

Epoch: 5| Step: 6
Training loss: 2.753283361238532
Validation loss: 2.5050542325363034

Epoch: 5| Step: 7
Training loss: 2.331785665133603
Validation loss: 2.4958369242833904

Epoch: 5| Step: 8
Training loss: 2.1187742698877297
Validation loss: 2.4776111652937534

Epoch: 5| Step: 9
Training loss: 2.532620565212572
Validation loss: 2.487709574600991

Epoch: 5| Step: 10
Training loss: 2.512982230145267
Validation loss: 2.4866874297360115

Epoch: 5| Step: 11
Training loss: 2.8722514407034505
Validation loss: 2.48208531444992

Epoch: 200| Step: 0
Training loss: 2.2617648157887014
Validation loss: 2.483981991118009

Epoch: 5| Step: 1
Training loss: 2.041644803403712
Validation loss: 2.4795819677320194

Epoch: 5| Step: 2
Training loss: 2.350050937831006
Validation loss: 2.4863115236697517

Epoch: 5| Step: 3
Training loss: 2.4851994136262547
Validation loss: 2.4876441319560256

Epoch: 5| Step: 4
Training loss: 2.5559552048353185
Validation loss: 2.485737636835053

Epoch: 5| Step: 5
Training loss: 2.6730362002928754
Validation loss: 2.4965349861068074

Epoch: 5| Step: 6
Training loss: 2.559241758797782
Validation loss: 2.490719509365814

Epoch: 5| Step: 7
Training loss: 2.6117935393611296
Validation loss: 2.4958865299085584

Epoch: 5| Step: 8
Training loss: 2.8034524987831255
Validation loss: 2.4860094080414754

Epoch: 5| Step: 9
Training loss: 2.1982196279662047
Validation loss: 2.486453752123274

Epoch: 5| Step: 10
Training loss: 1.8308042797526167
Validation loss: 2.4950476868785847

Epoch: 5| Step: 11
Training loss: 3.118366372283268
Validation loss: 2.497048531184793

Epoch: 201| Step: 0
Training loss: 2.2471610278502765
Validation loss: 2.4925997720924324

Epoch: 5| Step: 1
Training loss: 2.035921564281336
Validation loss: 2.5046631635569137

Epoch: 5| Step: 2
Training loss: 2.4203372133986827
Validation loss: 2.507476665315988

Epoch: 5| Step: 3
Training loss: 2.563323842176998
Validation loss: 2.5078778045486

Epoch: 5| Step: 4
Training loss: 2.365431634818526
Validation loss: 2.5040341888608406

Epoch: 5| Step: 5
Training loss: 2.0783454950135374
Validation loss: 2.517209547164537

Epoch: 5| Step: 6
Training loss: 2.3751294954031628
Validation loss: 2.507201915656573

Epoch: 5| Step: 7
Training loss: 2.6279277822770406
Validation loss: 2.50709612587984

Epoch: 5| Step: 8
Training loss: 2.4314536394284176
Validation loss: 2.5005413383263444

Epoch: 5| Step: 9
Training loss: 2.8370930652971587
Validation loss: 2.493035888564785

Epoch: 5| Step: 10
Training loss: 2.445678975976597
Validation loss: 2.510873823499889

Epoch: 5| Step: 11
Training loss: 2.5366221746418534
Validation loss: 2.489749716674858

Epoch: 202| Step: 0
Training loss: 2.3258285973816286
Validation loss: 2.5018015608887443

Epoch: 5| Step: 1
Training loss: 2.116753565388681
Validation loss: 2.4894787129295697

Epoch: 5| Step: 2
Training loss: 1.8962554322015936
Validation loss: 2.502612019002916

Epoch: 5| Step: 3
Training loss: 2.7536356042208125
Validation loss: 2.4899575631867394

Epoch: 5| Step: 4
Training loss: 2.261917975155281
Validation loss: 2.4976489197726166

Epoch: 5| Step: 5
Training loss: 2.7008500421186303
Validation loss: 2.4962983403263403

Epoch: 5| Step: 6
Training loss: 2.4183735793603405
Validation loss: 2.501924076353412

Epoch: 5| Step: 7
Training loss: 2.270142149654658
Validation loss: 2.4915216447309914

Epoch: 5| Step: 8
Training loss: 2.809383954976951
Validation loss: 2.4984284786262685

Epoch: 5| Step: 9
Training loss: 2.2009652014498466
Validation loss: 2.492224945137829

Epoch: 5| Step: 10
Training loss: 2.4948506729910074
Validation loss: 2.496693685805167

Epoch: 5| Step: 11
Training loss: 1.8257498676833317
Validation loss: 2.4915832436724865

Epoch: 203| Step: 0
Training loss: 2.3536444790971247
Validation loss: 2.496478710228817

Epoch: 5| Step: 1
Training loss: 2.3839818867884977
Validation loss: 2.5048237278682817

Epoch: 5| Step: 2
Training loss: 2.020422143166294
Validation loss: 2.5054640662563163

Epoch: 5| Step: 3
Training loss: 2.1381670351643884
Validation loss: 2.5113225320823087

Epoch: 5| Step: 4
Training loss: 2.668079111433344
Validation loss: 2.5145773117722348

Epoch: 5| Step: 5
Training loss: 2.2942393225340028
Validation loss: 2.5232890413152083

Epoch: 5| Step: 6
Training loss: 2.5618791525910174
Validation loss: 2.5222977307183387

Epoch: 5| Step: 7
Training loss: 2.3828435176644085
Validation loss: 2.5366588776962193

Epoch: 5| Step: 8
Training loss: 2.8033182100968395
Validation loss: 2.5299343135596954

Epoch: 5| Step: 9
Training loss: 2.337251835669632
Validation loss: 2.5298950195018

Epoch: 5| Step: 10
Training loss: 2.4060476639133626
Validation loss: 2.5142342215799616

Epoch: 5| Step: 11
Training loss: 2.405862256801073
Validation loss: 2.5088489605009707

Epoch: 204| Step: 0
Training loss: 1.9727368026754113
Validation loss: 2.509473244821037

Epoch: 5| Step: 1
Training loss: 2.070052105344586
Validation loss: 2.5098073201358826

Epoch: 5| Step: 2
Training loss: 2.2378386214625103
Validation loss: 2.507643934627633

Epoch: 5| Step: 3
Training loss: 2.975875815333384
Validation loss: 2.512431148990093

Epoch: 5| Step: 4
Training loss: 2.4464329111898073
Validation loss: 2.5138016681808457

Epoch: 5| Step: 5
Training loss: 2.3327653965726554
Validation loss: 2.5149153662181383

Epoch: 5| Step: 6
Training loss: 2.8927238474013066
Validation loss: 2.509831662428668

Epoch: 5| Step: 7
Training loss: 2.136970351781538
Validation loss: 2.5071717886694174

Epoch: 5| Step: 8
Training loss: 2.0519106125798516
Validation loss: 2.510158534780603

Epoch: 5| Step: 9
Training loss: 2.0540966736460673
Validation loss: 2.5176306719804384

Epoch: 5| Step: 10
Training loss: 2.7267866069868254
Validation loss: 2.515807662476784

Epoch: 5| Step: 11
Training loss: 2.844073434399391
Validation loss: 2.511623952291871

Epoch: 205| Step: 0
Training loss: 2.387767505139446
Validation loss: 2.5483516125889363

Epoch: 5| Step: 1
Training loss: 2.3022429351946787
Validation loss: 2.534348639881476

Epoch: 5| Step: 2
Training loss: 2.7016998238463477
Validation loss: 2.5542256776818384

Epoch: 5| Step: 3
Training loss: 1.8466813013320884
Validation loss: 2.5482969039843795

Epoch: 5| Step: 4
Training loss: 2.253409980602716
Validation loss: 2.529788211343797

Epoch: 5| Step: 5
Training loss: 2.7894524480661027
Validation loss: 2.541744126770692

Epoch: 5| Step: 6
Training loss: 2.241005083989884
Validation loss: 2.5428623464329814

Epoch: 5| Step: 7
Training loss: 1.6878479492894656
Validation loss: 2.555585328190138

Epoch: 5| Step: 8
Training loss: 2.7572385714878025
Validation loss: 2.5393500140825602

Epoch: 5| Step: 9
Training loss: 2.0415628238142274
Validation loss: 2.5393715616563295

Epoch: 5| Step: 10
Training loss: 2.636230242651986
Validation loss: 2.5320530704608357

Epoch: 5| Step: 11
Training loss: 3.2213303676374734
Validation loss: 2.53228453307335

Epoch: 206| Step: 0
Training loss: 2.1728410287666016
Validation loss: 2.506355702302881

Epoch: 5| Step: 1
Training loss: 2.3040847248685448
Validation loss: 2.4990658365786818

Epoch: 5| Step: 2
Training loss: 2.209483716736819
Validation loss: 2.5005411436599823

Epoch: 5| Step: 3
Training loss: 2.7646271365580413
Validation loss: 2.4960080422107316

Epoch: 5| Step: 4
Training loss: 2.2298138353448724
Validation loss: 2.5003428661153864

Epoch: 5| Step: 5
Training loss: 2.2673185135827105
Validation loss: 2.505010828386914

Epoch: 5| Step: 6
Training loss: 1.8737361463119864
Validation loss: 2.5089479254800486

Epoch: 5| Step: 7
Training loss: 2.6800981657354486
Validation loss: 2.5198441796562525

Epoch: 5| Step: 8
Training loss: 2.587283058102012
Validation loss: 2.5097057488766423

Epoch: 5| Step: 9
Training loss: 2.397854314723109
Validation loss: 2.5157327846079722

Epoch: 5| Step: 10
Training loss: 2.6834769188826697
Validation loss: 2.513256051448391

Epoch: 5| Step: 11
Training loss: 2.0111869034907484
Validation loss: 2.5221859039520895

Epoch: 207| Step: 0
Training loss: 2.483520168811609
Validation loss: 2.5226624699139144

Epoch: 5| Step: 1
Training loss: 2.4978019588328686
Validation loss: 2.5088268300449883

Epoch: 5| Step: 2
Training loss: 2.7052057449588918
Validation loss: 2.517685001335151

Epoch: 5| Step: 3
Training loss: 2.8173774811745487
Validation loss: 2.5066432148156785

Epoch: 5| Step: 4
Training loss: 2.697117563171218
Validation loss: 2.5046631159619746

Epoch: 5| Step: 5
Training loss: 2.45497110478009
Validation loss: 2.512878929176985

Epoch: 5| Step: 6
Training loss: 2.366448113822705
Validation loss: 2.50205161630145

Epoch: 5| Step: 7
Training loss: 2.3578839169272827
Validation loss: 2.513769472446073

Epoch: 5| Step: 8
Training loss: 1.5134311804599114
Validation loss: 2.504487024360584

Epoch: 5| Step: 9
Training loss: 2.272654605050539
Validation loss: 2.5076248716713065

Epoch: 5| Step: 10
Training loss: 2.005854382829109
Validation loss: 2.5039405086433146

Epoch: 5| Step: 11
Training loss: 0.9466440894956094
Validation loss: 2.5061164301907866

Epoch: 208| Step: 0
Training loss: 2.1101346378850905
Validation loss: 2.507813648766307

Epoch: 5| Step: 1
Training loss: 2.845603925432957
Validation loss: 2.510175758030353

Epoch: 5| Step: 2
Training loss: 1.9641175037047491
Validation loss: 2.5065353128096817

Epoch: 5| Step: 3
Training loss: 2.4129841689259597
Validation loss: 2.5053918629842817

Epoch: 5| Step: 4
Training loss: 2.446772812698484
Validation loss: 2.511315597682524

Epoch: 5| Step: 5
Training loss: 1.97710733858039
Validation loss: 2.5081140964694697

Epoch: 5| Step: 6
Training loss: 2.3817738755239586
Validation loss: 2.4993475777947736

Epoch: 5| Step: 7
Training loss: 2.36014963532335
Validation loss: 2.5111509742346088

Epoch: 5| Step: 8
Training loss: 2.866174170601065
Validation loss: 2.5164177318849124

Epoch: 5| Step: 9
Training loss: 1.988929328146234
Validation loss: 2.5163947244794933

Epoch: 5| Step: 10
Training loss: 2.2371938570595398
Validation loss: 2.5391547357483177

Epoch: 5| Step: 11
Training loss: 3.2678337840809557
Validation loss: 2.5242553464282507

Epoch: 209| Step: 0
Training loss: 2.819802277714963
Validation loss: 2.5395461575481244

Epoch: 5| Step: 1
Training loss: 2.271110891009123
Validation loss: 2.542095356627099

Epoch: 5| Step: 2
Training loss: 2.268936893552266
Validation loss: 2.549764688626863

Epoch: 5| Step: 3
Training loss: 2.137337938377923
Validation loss: 2.560183982632951

Epoch: 5| Step: 4
Training loss: 2.629670665412822
Validation loss: 2.555044143467117

Epoch: 5| Step: 5
Training loss: 2.191835956296448
Validation loss: 2.530683293109682

Epoch: 5| Step: 6
Training loss: 2.120190507138464
Validation loss: 2.5377350648201205

Epoch: 5| Step: 7
Training loss: 2.2570303119724815
Validation loss: 2.524536196756621

Epoch: 5| Step: 8
Training loss: 1.7233739210006291
Validation loss: 2.5158447540843607

Epoch: 5| Step: 9
Training loss: 2.7860133496120056
Validation loss: 2.503646789533669

Epoch: 5| Step: 10
Training loss: 2.7439169795987226
Validation loss: 2.5109768568276647

Epoch: 5| Step: 11
Training loss: 1.3709644571840434
Validation loss: 2.510266759889367

Epoch: 210| Step: 0
Training loss: 2.598487113070687
Validation loss: 2.5028210419288275

Epoch: 5| Step: 1
Training loss: 2.8792456086557427
Validation loss: 2.5190690318927853

Epoch: 5| Step: 2
Training loss: 2.0807276898037887
Validation loss: 2.5239470767500802

Epoch: 5| Step: 3
Training loss: 2.094410009407447
Validation loss: 2.5322858355031466

Epoch: 5| Step: 4
Training loss: 2.1960632560944293
Validation loss: 2.5364117092623

Epoch: 5| Step: 5
Training loss: 2.2379248103924794
Validation loss: 2.5435672999012713

Epoch: 5| Step: 6
Training loss: 2.6500493099015476
Validation loss: 2.5600811233804843

Epoch: 5| Step: 7
Training loss: 2.676839399294754
Validation loss: 2.5642571433710004

Epoch: 5| Step: 8
Training loss: 1.8901894438122189
Validation loss: 2.5601294221113617

Epoch: 5| Step: 9
Training loss: 2.4067852861578185
Validation loss: 2.5764925788196575

Epoch: 5| Step: 10
Training loss: 2.1179044853769224
Validation loss: 2.567604946250002

Epoch: 5| Step: 11
Training loss: 2.466162665745063
Validation loss: 2.561887082402343

Epoch: 211| Step: 0
Training loss: 1.9227588761030163
Validation loss: 2.543852844314999

Epoch: 5| Step: 1
Training loss: 2.114377342175464
Validation loss: 2.525844087771841

Epoch: 5| Step: 2
Training loss: 2.484538810655622
Validation loss: 2.5212564284091865

Epoch: 5| Step: 3
Training loss: 2.246453775493653
Validation loss: 2.5119251109099423

Epoch: 5| Step: 4
Training loss: 2.345613476313016
Validation loss: 2.511096685491422

Epoch: 5| Step: 5
Training loss: 2.45878715421127
Validation loss: 2.5089398956592746

Epoch: 5| Step: 6
Training loss: 2.4796585321687394
Validation loss: 2.5097085948753093

Epoch: 5| Step: 7
Training loss: 2.5546397166785084
Validation loss: 2.5119934327344433

Epoch: 5| Step: 8
Training loss: 2.1260848922359945
Validation loss: 2.5097488066311384

Epoch: 5| Step: 9
Training loss: 2.396652004407547
Validation loss: 2.5192024588137505

Epoch: 5| Step: 10
Training loss: 2.92419618826664
Validation loss: 2.5214486133138356

Epoch: 5| Step: 11
Training loss: 1.3687992731570662
Validation loss: 2.5240325698504313

Epoch: 212| Step: 0
Training loss: 2.4149164461012704
Validation loss: 2.535418523810236

Epoch: 5| Step: 1
Training loss: 2.514148255018321
Validation loss: 2.5280972654112563

Epoch: 5| Step: 2
Training loss: 2.1982630114795545
Validation loss: 2.5445919257240104

Epoch: 5| Step: 3
Training loss: 2.19905103243827
Validation loss: 2.5430231044603255

Epoch: 5| Step: 4
Training loss: 3.112335942245795
Validation loss: 2.5389846789831934

Epoch: 5| Step: 5
Training loss: 2.5514459138340957
Validation loss: 2.550303637902038

Epoch: 5| Step: 6
Training loss: 2.2952717485958702
Validation loss: 2.5494940149786

Epoch: 5| Step: 7
Training loss: 2.2469832010969646
Validation loss: 2.5459794184159263

Epoch: 5| Step: 8
Training loss: 1.8613297901766555
Validation loss: 2.552087909668433

Epoch: 5| Step: 9
Training loss: 2.383335143757735
Validation loss: 2.551274573702902

Epoch: 5| Step: 10
Training loss: 1.9766772089908107
Validation loss: 2.5603929944311097

Epoch: 5| Step: 11
Training loss: 1.9073495664060216
Validation loss: 2.5596755596918306

Epoch: 213| Step: 0
Training loss: 2.185308830381433
Validation loss: 2.5680817699406777

Epoch: 5| Step: 1
Training loss: 1.6176205115256395
Validation loss: 2.5670052327272517

Epoch: 5| Step: 2
Training loss: 2.833693780597986
Validation loss: 2.560882364036032

Epoch: 5| Step: 3
Training loss: 2.5928492073439067
Validation loss: 2.5571212180852876

Epoch: 5| Step: 4
Training loss: 2.7331403288115887
Validation loss: 2.5440928977090866

Epoch: 5| Step: 5
Training loss: 2.7443973516198197
Validation loss: 2.542610951931274

Epoch: 5| Step: 6
Training loss: 1.7200950214841535
Validation loss: 2.5313985608307497

Epoch: 5| Step: 7
Training loss: 2.3607879853889435
Validation loss: 2.5366829779831956

Epoch: 5| Step: 8
Training loss: 2.0566306553206837
Validation loss: 2.5334933116451395

Epoch: 5| Step: 9
Training loss: 2.082142324150782
Validation loss: 2.5303187442925648

Epoch: 5| Step: 10
Training loss: 2.404334556848294
Validation loss: 2.5192944989615276

Epoch: 5| Step: 11
Training loss: 2.700767591649908
Validation loss: 2.524009604306545

Epoch: 214| Step: 0
Training loss: 2.108888471089947
Validation loss: 2.534946203714363

Epoch: 5| Step: 1
Training loss: 2.097508601101687
Validation loss: 2.533473804044834

Epoch: 5| Step: 2
Training loss: 3.087076097801634
Validation loss: 2.5305365314378045

Epoch: 5| Step: 3
Training loss: 1.9341771334269464
Validation loss: 2.523620185498658

Epoch: 5| Step: 4
Training loss: 2.4286340717442916
Validation loss: 2.5284423445053

Epoch: 5| Step: 5
Training loss: 2.7235375706052847
Validation loss: 2.515598462835574

Epoch: 5| Step: 6
Training loss: 1.8871642035082181
Validation loss: 2.5177932185703273

Epoch: 5| Step: 7
Training loss: 2.659059542135265
Validation loss: 2.5192142375850506

Epoch: 5| Step: 8
Training loss: 2.363557455773124
Validation loss: 2.522888513613262

Epoch: 5| Step: 9
Training loss: 1.9102554763577657
Validation loss: 2.542813817396163

Epoch: 5| Step: 10
Training loss: 2.3458695046960187
Validation loss: 2.5411589159625163

Epoch: 5| Step: 11
Training loss: 1.5683168094317212
Validation loss: 2.539758929085258

Epoch: 215| Step: 0
Training loss: 2.9579354318583375
Validation loss: 2.5538493151156474

Epoch: 5| Step: 1
Training loss: 2.3550211163199766
Validation loss: 2.5784174936236783

Epoch: 5| Step: 2
Training loss: 2.220665870159414
Validation loss: 2.569968153160032

Epoch: 5| Step: 3
Training loss: 2.282059826226314
Validation loss: 2.56777737094594

Epoch: 5| Step: 4
Training loss: 2.5741654015716313
Validation loss: 2.561547012986556

Epoch: 5| Step: 5
Training loss: 2.5779847078010385
Validation loss: 2.566315102083573

Epoch: 5| Step: 6
Training loss: 2.1464584946048406
Validation loss: 2.562726642696329

Epoch: 5| Step: 7
Training loss: 2.2308922146861696
Validation loss: 2.5398147759710743

Epoch: 5| Step: 8
Training loss: 1.9607098815852624
Validation loss: 2.5047140023679026

Epoch: 5| Step: 9
Training loss: 1.6356342519193083
Validation loss: 2.518982437647775

Epoch: 5| Step: 10
Training loss: 2.6393431311599986
Validation loss: 2.517024679539867

Epoch: 5| Step: 11
Training loss: 2.666645665880797
Validation loss: 2.5239965333355583

Epoch: 216| Step: 0
Training loss: 2.1480983397067233
Validation loss: 2.516730876970835

Epoch: 5| Step: 1
Training loss: 2.344197751826925
Validation loss: 2.5300438954826254

Epoch: 5| Step: 2
Training loss: 2.5039818524687187
Validation loss: 2.523970312472412

Epoch: 5| Step: 3
Training loss: 2.417921715989188
Validation loss: 2.534536320184844

Epoch: 5| Step: 4
Training loss: 2.424887180653505
Validation loss: 2.5148325278047676

Epoch: 5| Step: 5
Training loss: 2.664574537543562
Validation loss: 2.5425092337636648

Epoch: 5| Step: 6
Training loss: 2.2818065643705623
Validation loss: 2.54983491659295

Epoch: 5| Step: 7
Training loss: 2.269583985443143
Validation loss: 2.551673838142103

Epoch: 5| Step: 8
Training loss: 1.9427694220734868
Validation loss: 2.5670499647543696

Epoch: 5| Step: 9
Training loss: 2.274201150168877
Validation loss: 2.5651675776407163

Epoch: 5| Step: 10
Training loss: 2.6867236413270574
Validation loss: 2.550116381763135

Epoch: 5| Step: 11
Training loss: 2.85808062831154
Validation loss: 2.5414111850619077

Epoch: 217| Step: 0
Training loss: 2.4120843677537205
Validation loss: 2.5234211506820787

Epoch: 5| Step: 1
Training loss: 1.7811757122409897
Validation loss: 2.520676495005325

Epoch: 5| Step: 2
Training loss: 2.379759486732044
Validation loss: 2.515426169805019

Epoch: 5| Step: 3
Training loss: 2.801034402512768
Validation loss: 2.5186187550606487

Epoch: 5| Step: 4
Training loss: 2.361695115163277
Validation loss: 2.526549499956389

Epoch: 5| Step: 5
Training loss: 2.930285908937501
Validation loss: 2.5072512052974782

Epoch: 5| Step: 6
Training loss: 1.8255211961195328
Validation loss: 2.5178248045631197

Epoch: 5| Step: 7
Training loss: 1.9210026319566178
Validation loss: 2.5279061636500373

Epoch: 5| Step: 8
Training loss: 2.468422686934077
Validation loss: 2.535409194717953

Epoch: 5| Step: 9
Training loss: 2.3538060432524404
Validation loss: 2.5411296196324074

Epoch: 5| Step: 10
Training loss: 2.425918354085161
Validation loss: 2.5437213391525657

Epoch: 5| Step: 11
Training loss: 1.4102411218183508
Validation loss: 2.544389986796647

Epoch: 218| Step: 0
Training loss: 2.8937227713372886
Validation loss: 2.5511087710702203

Epoch: 5| Step: 1
Training loss: 2.386060158724982
Validation loss: 2.5548980618339083

Epoch: 5| Step: 2
Training loss: 1.9048047449766592
Validation loss: 2.553595255947955

Epoch: 5| Step: 3
Training loss: 2.131878547050413
Validation loss: 2.537702589451049

Epoch: 5| Step: 4
Training loss: 2.0229446812532084
Validation loss: 2.5436767944062164

Epoch: 5| Step: 5
Training loss: 2.2660257971524937
Validation loss: 2.5332369050906256

Epoch: 5| Step: 6
Training loss: 2.3904503652577658
Validation loss: 2.511940510770278

Epoch: 5| Step: 7
Training loss: 2.6945901538563377
Validation loss: 2.5299572488819146

Epoch: 5| Step: 8
Training loss: 1.7415481557482937
Validation loss: 2.5288775750672348

Epoch: 5| Step: 9
Training loss: 2.4778849924476156
Validation loss: 2.5311263018865713

Epoch: 5| Step: 10
Training loss: 2.2654430447880314
Validation loss: 2.5325597545569702

Epoch: 5| Step: 11
Training loss: 2.921111797675927
Validation loss: 2.532347649149391

Epoch: 219| Step: 0
Training loss: 2.11526638580926
Validation loss: 2.531905874200461

Epoch: 5| Step: 1
Training loss: 1.8355309218813218
Validation loss: 2.528804795008903

Epoch: 5| Step: 2
Training loss: 2.7318936669753295
Validation loss: 2.527628790667798

Epoch: 5| Step: 3
Training loss: 2.552626031796104
Validation loss: 2.5201448250366005

Epoch: 5| Step: 4
Training loss: 2.327852783673937
Validation loss: 2.530941493068148

Epoch: 5| Step: 5
Training loss: 2.371242160331705
Validation loss: 2.5569352110657397

Epoch: 5| Step: 6
Training loss: 2.2740021623787374
Validation loss: 2.543630065714963

Epoch: 5| Step: 7
Training loss: 2.75266483544384
Validation loss: 2.5611909763776763

Epoch: 5| Step: 8
Training loss: 2.3405526286244536
Validation loss: 2.57084158695654

Epoch: 5| Step: 9
Training loss: 2.4858070900384646
Validation loss: 2.5501038263725655

Epoch: 5| Step: 10
Training loss: 1.7603046298820357
Validation loss: 2.5656347116618745

Epoch: 5| Step: 11
Training loss: 1.443955150082096
Validation loss: 2.5717598068501744

Epoch: 220| Step: 0
Training loss: 2.2812681850596888
Validation loss: 2.587119446057648

Epoch: 5| Step: 1
Training loss: 1.5812638293479524
Validation loss: 2.600596518739133

Epoch: 5| Step: 2
Training loss: 2.6820882380604005
Validation loss: 2.6077275510147238

Epoch: 5| Step: 3
Training loss: 1.959292386639001
Validation loss: 2.5888027977943233

Epoch: 5| Step: 4
Training loss: 2.898271334838524
Validation loss: 2.5870648104122886

Epoch: 5| Step: 5
Training loss: 2.7164347645204034
Validation loss: 2.5703293008458137

Epoch: 5| Step: 6
Training loss: 2.25211351523229
Validation loss: 2.5592135739062094

Epoch: 5| Step: 7
Training loss: 1.7326282262208592
Validation loss: 2.535624476034618

Epoch: 5| Step: 8
Training loss: 2.86176104606762
Validation loss: 2.5392216637438003

Epoch: 5| Step: 9
Training loss: 2.6089308126508404
Validation loss: 2.5268710724722028

Epoch: 5| Step: 10
Training loss: 1.7303653453647674
Validation loss: 2.531034774421311

Epoch: 5| Step: 11
Training loss: 2.7865957255969227
Validation loss: 2.525807644467897

Epoch: 221| Step: 0
Training loss: 1.829346338483516
Validation loss: 2.5270729175320477

Epoch: 5| Step: 1
Training loss: 2.9906594779678914
Validation loss: 2.521355737723623

Epoch: 5| Step: 2
Training loss: 2.5883635696967118
Validation loss: 2.5303641641267314

Epoch: 5| Step: 3
Training loss: 1.9981020624289778
Validation loss: 2.5441648538643205

Epoch: 5| Step: 4
Training loss: 2.446511556592224
Validation loss: 2.5402972578899994

Epoch: 5| Step: 5
Training loss: 2.7475361623978825
Validation loss: 2.5555788015492373

Epoch: 5| Step: 6
Training loss: 2.2271841151882295
Validation loss: 2.544921800833462

Epoch: 5| Step: 7
Training loss: 1.9631716095335103
Validation loss: 2.539728071570016

Epoch: 5| Step: 8
Training loss: 1.7855659532247554
Validation loss: 2.529238879153802

Epoch: 5| Step: 9
Training loss: 2.301396907694456
Validation loss: 2.5235466160916356

Epoch: 5| Step: 10
Training loss: 2.4450444571230907
Validation loss: 2.525160863366327

Epoch: 5| Step: 11
Training loss: 1.758361052645668
Validation loss: 2.5404086413034346

Epoch: 222| Step: 0
Training loss: 2.066654644695304
Validation loss: 2.5297094688537594

Epoch: 5| Step: 1
Training loss: 2.0714370840113823
Validation loss: 2.5311781712140378

Epoch: 5| Step: 2
Training loss: 2.216096069876952
Validation loss: 2.5381312418239945

Epoch: 5| Step: 3
Training loss: 2.333958837138005
Validation loss: 2.5371339056264643

Epoch: 5| Step: 4
Training loss: 2.391111835450477
Validation loss: 2.5385580060514155

Epoch: 5| Step: 5
Training loss: 2.2674315517739405
Validation loss: 2.5652215624181856

Epoch: 5| Step: 6
Training loss: 2.5639170008539796
Validation loss: 2.582279895500713

Epoch: 5| Step: 7
Training loss: 2.6481326667651253
Validation loss: 2.586716879249971

Epoch: 5| Step: 8
Training loss: 1.7560741051393842
Validation loss: 2.5897580339258233

Epoch: 5| Step: 9
Training loss: 2.136821960522893
Validation loss: 2.5916619341174356

Epoch: 5| Step: 10
Training loss: 2.8368491817021435
Validation loss: 2.5752269948824225

Epoch: 5| Step: 11
Training loss: 2.9781224125693773
Validation loss: 2.56419141121067

Epoch: 223| Step: 0
Training loss: 2.841940335457501
Validation loss: 2.53789416894151

Epoch: 5| Step: 1
Training loss: 2.3781506570843085
Validation loss: 2.518986361624806

Epoch: 5| Step: 2
Training loss: 2.895983209550774
Validation loss: 2.517968898421664

Epoch: 5| Step: 3
Training loss: 2.0417386905136947
Validation loss: 2.5145721009158186

Epoch: 5| Step: 4
Training loss: 2.6750814371992853
Validation loss: 2.511228000284369

Epoch: 5| Step: 5
Training loss: 2.312746189518813
Validation loss: 2.5140212694781683

Epoch: 5| Step: 6
Training loss: 2.1253813233160614
Validation loss: 2.5115541490219235

Epoch: 5| Step: 7
Training loss: 2.3035136708805517
Validation loss: 2.5091830912199957

Epoch: 5| Step: 8
Training loss: 2.1269052603444076
Validation loss: 2.5051121141404225

Epoch: 5| Step: 9
Training loss: 1.988982670838444
Validation loss: 2.5221437182640214

Epoch: 5| Step: 10
Training loss: 2.417972102494142
Validation loss: 2.5251504145096253

Epoch: 5| Step: 11
Training loss: 1.0967305036611446
Validation loss: 2.5544699674456055

Epoch: 224| Step: 0
Training loss: 2.196598097387534
Validation loss: 2.562990703740292

Epoch: 5| Step: 1
Training loss: 2.6025702097104255
Validation loss: 2.5808397160989944

Epoch: 5| Step: 2
Training loss: 2.318915771974788
Validation loss: 2.576285362877039

Epoch: 5| Step: 3
Training loss: 2.563866692783671
Validation loss: 2.5678678866652485

Epoch: 5| Step: 4
Training loss: 2.420515109324917
Validation loss: 2.531615650783875

Epoch: 5| Step: 5
Training loss: 1.9219709542984436
Validation loss: 2.5293257192491394

Epoch: 5| Step: 6
Training loss: 1.7930453415013485
Validation loss: 2.526339638560678

Epoch: 5| Step: 7
Training loss: 2.1972710503405244
Validation loss: 2.5195002551476424

Epoch: 5| Step: 8
Training loss: 2.959848168319516
Validation loss: 2.5156265993290905

Epoch: 5| Step: 9
Training loss: 2.454628744703058
Validation loss: 2.5285838021639377

Epoch: 5| Step: 10
Training loss: 2.4913162095554333
Validation loss: 2.528767824749706

Epoch: 5| Step: 11
Training loss: 1.3183029953945795
Validation loss: 2.513693800768586

Epoch: 225| Step: 0
Training loss: 2.035108217928275
Validation loss: 2.51409123342851

Epoch: 5| Step: 1
Training loss: 3.1557675738887543
Validation loss: 2.51356630614928

Epoch: 5| Step: 2
Training loss: 2.8381068652022434
Validation loss: 2.522690399638158

Epoch: 5| Step: 3
Training loss: 2.487077598554514
Validation loss: 2.507119670325848

Epoch: 5| Step: 4
Training loss: 2.2107115721097164
Validation loss: 2.5140239841442

Epoch: 5| Step: 5
Training loss: 2.5638427007869775
Validation loss: 2.514395162425858

Epoch: 5| Step: 6
Training loss: 1.6764749722772836
Validation loss: 2.516919653905069

Epoch: 5| Step: 7
Training loss: 2.3256239802320624
Validation loss: 2.522058107960097

Epoch: 5| Step: 8
Training loss: 2.123291675312685
Validation loss: 2.5222519568815924

Epoch: 5| Step: 9
Training loss: 2.2097110649171943
Validation loss: 2.5362997194759043

Epoch: 5| Step: 10
Training loss: 1.7296198362160486
Validation loss: 2.5561675082500472

Epoch: 5| Step: 11
Training loss: 2.3860552625691502
Validation loss: 2.545282177854754

Epoch: 226| Step: 0
Training loss: 2.5016129059153975
Validation loss: 2.558611214070984

Epoch: 5| Step: 1
Training loss: 1.904374184628629
Validation loss: 2.552329488807258

Epoch: 5| Step: 2
Training loss: 1.8371662978694177
Validation loss: 2.562639806391655

Epoch: 5| Step: 3
Training loss: 2.5118359765303033
Validation loss: 2.566371915559527

Epoch: 5| Step: 4
Training loss: 2.784607393133334
Validation loss: 2.5648048587716263

Epoch: 5| Step: 5
Training loss: 1.94680189849623
Validation loss: 2.569170747533678

Epoch: 5| Step: 6
Training loss: 2.2596481938953596
Validation loss: 2.562948745884824

Epoch: 5| Step: 7
Training loss: 2.352623988257995
Validation loss: 2.557252546944815

Epoch: 5| Step: 8
Training loss: 2.2999899366407415
Validation loss: 2.563062671975441

Epoch: 5| Step: 9
Training loss: 2.467993028695819
Validation loss: 2.541329440951577

Epoch: 5| Step: 10
Training loss: 2.1749942253299217
Validation loss: 2.5310230388851283

Epoch: 5| Step: 11
Training loss: 3.3037592889696317
Validation loss: 2.5309835929549824

Epoch: 227| Step: 0
Training loss: 2.27859583045955
Validation loss: 2.5265856239111515

Epoch: 5| Step: 1
Training loss: 2.238746687877597
Validation loss: 2.5300209609458815

Epoch: 5| Step: 2
Training loss: 2.533249336238824
Validation loss: 2.5325510229322603

Epoch: 5| Step: 3
Training loss: 2.3260263290161545
Validation loss: 2.5281983610495176

Epoch: 5| Step: 4
Training loss: 2.9362488374996034
Validation loss: 2.545821664401552

Epoch: 5| Step: 5
Training loss: 2.0970442179182336
Validation loss: 2.542813903344398

Epoch: 5| Step: 6
Training loss: 2.554062513143506
Validation loss: 2.564651938656257

Epoch: 5| Step: 7
Training loss: 1.711700826574564
Validation loss: 2.5725750265188045

Epoch: 5| Step: 8
Training loss: 2.406541880950354
Validation loss: 2.58307816927012

Epoch: 5| Step: 9
Training loss: 2.0675322668286076
Validation loss: 2.597148545444717

Epoch: 5| Step: 10
Training loss: 2.189283896991986
Validation loss: 2.5715214940215616

Epoch: 5| Step: 11
Training loss: 2.261285664628789
Validation loss: 2.5811724367103297

Epoch: 228| Step: 0
Training loss: 2.991754963739765
Validation loss: 2.5286743261982436

Epoch: 5| Step: 1
Training loss: 2.482967145747763
Validation loss: 2.5157115518595785

Epoch: 5| Step: 2
Training loss: 2.275356466012373
Validation loss: 2.4970810698137145

Epoch: 5| Step: 3
Training loss: 1.6688439532059245
Validation loss: 2.5070594021254817

Epoch: 5| Step: 4
Training loss: 2.3804166161512517
Validation loss: 2.492667264609339

Epoch: 5| Step: 5
Training loss: 1.9702262792999912
Validation loss: 2.495541566714671

Epoch: 5| Step: 6
Training loss: 2.783168002793741
Validation loss: 2.4778864156803913

Epoch: 5| Step: 7
Training loss: 2.2790753175978393
Validation loss: 2.489793821771256

Epoch: 5| Step: 8
Training loss: 2.7311702585691586
Validation loss: 2.5060050368992877

Epoch: 5| Step: 9
Training loss: 2.3288913975868755
Validation loss: 2.498892351980605

Epoch: 5| Step: 10
Training loss: 2.062568201035626
Validation loss: 2.4941149944042973

Epoch: 5| Step: 11
Training loss: 1.0574341225452057
Validation loss: 2.5102183367842

Epoch: 229| Step: 0
Training loss: 2.136230970982084
Validation loss: 2.514761272972864

Epoch: 5| Step: 1
Training loss: 2.1714387084968116
Validation loss: 2.530644418936027

Epoch: 5| Step: 2
Training loss: 2.39187170693814
Validation loss: 2.5456702575544212

Epoch: 5| Step: 3
Training loss: 2.468767576517237
Validation loss: 2.5596178834626246

Epoch: 5| Step: 4
Training loss: 2.331084961968257
Validation loss: 2.54853218864758

Epoch: 5| Step: 5
Training loss: 2.410741305325985
Validation loss: 2.55836948256369

Epoch: 5| Step: 6
Training loss: 2.1653908739235366
Validation loss: 2.536260257692057

Epoch: 5| Step: 7
Training loss: 2.2998033398018873
Validation loss: 2.5406551667409203

Epoch: 5| Step: 8
Training loss: 2.4594518627675956
Validation loss: 2.5425481062595034

Epoch: 5| Step: 9
Training loss: 2.413121506086506
Validation loss: 2.54100399029331

Epoch: 5| Step: 10
Training loss: 2.394107451281427
Validation loss: 2.5330363198849204

Epoch: 5| Step: 11
Training loss: 1.5656129726168742
Validation loss: 2.5484704557151643

Epoch: 230| Step: 0
Training loss: 2.5730354703792626
Validation loss: 2.53909489146381

Epoch: 5| Step: 1
Training loss: 1.8800340467778947
Validation loss: 2.552214791681473

Epoch: 5| Step: 2
Training loss: 2.4138853137720595
Validation loss: 2.5591614692740383

Epoch: 5| Step: 3
Training loss: 2.5451522336444903
Validation loss: 2.5659279496143697

Epoch: 5| Step: 4
Training loss: 2.3839026786985973
Validation loss: 2.567122887239226

Epoch: 5| Step: 5
Training loss: 2.235248101649509
Validation loss: 2.566206271558819

Epoch: 5| Step: 6
Training loss: 2.3627462995397472
Validation loss: 2.553847393525793

Epoch: 5| Step: 7
Training loss: 1.8465379229859837
Validation loss: 2.5449774524536792

Epoch: 5| Step: 8
Training loss: 2.943828178388146
Validation loss: 2.5256395858932525

Epoch: 5| Step: 9
Training loss: 1.329787795411661
Validation loss: 2.505658495238176

Epoch: 5| Step: 10
Training loss: 2.509051055711062
Validation loss: 2.507686100801777

Epoch: 5| Step: 11
Training loss: 2.702901136356541
Validation loss: 2.5143876873242754

Epoch: 231| Step: 0
Training loss: 1.8521382527170411
Validation loss: 2.5078688325031475

Epoch: 5| Step: 1
Training loss: 2.775432975601624
Validation loss: 2.511932601249284

Epoch: 5| Step: 2
Training loss: 2.518072513308839
Validation loss: 2.5290832507870156

Epoch: 5| Step: 3
Training loss: 1.7997134139481683
Validation loss: 2.58628938476236

Epoch: 5| Step: 4
Training loss: 2.404748522484291
Validation loss: 2.624305402349655

Epoch: 5| Step: 5
Training loss: 2.361035703564404
Validation loss: 2.6409667995833104

Epoch: 5| Step: 6
Training loss: 2.120341636553101
Validation loss: 2.6458005089613548

Epoch: 5| Step: 7
Training loss: 2.1480355181465782
Validation loss: 2.578309717207867

Epoch: 5| Step: 8
Training loss: 2.463915376498135
Validation loss: 2.547420486198834

Epoch: 5| Step: 9
Training loss: 2.4495559289935755
Validation loss: 2.5331124922108437

Epoch: 5| Step: 10
Training loss: 2.5195041862039673
Validation loss: 2.5228628325027884

Epoch: 5| Step: 11
Training loss: 3.1194787651326115
Validation loss: 2.519736691164707

Epoch: 232| Step: 0
Training loss: 2.157602411272896
Validation loss: 2.5212888476862485

Epoch: 5| Step: 1
Training loss: 2.4191587906027148
Validation loss: 2.497582247992774

Epoch: 5| Step: 2
Training loss: 2.9986604242911468
Validation loss: 2.5218980264223037

Epoch: 5| Step: 3
Training loss: 1.8622399065325665
Validation loss: 2.5042921652635797

Epoch: 5| Step: 4
Training loss: 2.1089080293660185
Validation loss: 2.5229234713193027

Epoch: 5| Step: 5
Training loss: 1.8642361990873229
Validation loss: 2.5236515863737488

Epoch: 5| Step: 6
Training loss: 2.288389764559039
Validation loss: 2.5261894471242736

Epoch: 5| Step: 7
Training loss: 2.272147110669376
Validation loss: 2.554925660553003

Epoch: 5| Step: 8
Training loss: 2.8274816972189067
Validation loss: 2.563185080774673

Epoch: 5| Step: 9
Training loss: 2.024655479982229
Validation loss: 2.5942200728814404

Epoch: 5| Step: 10
Training loss: 2.650359859864276
Validation loss: 2.6163396382426187

Epoch: 5| Step: 11
Training loss: 1.6799009675401069
Validation loss: 2.5673552432199696

Epoch: 233| Step: 0
Training loss: 2.2037709689211065
Validation loss: 2.528540102591063

Epoch: 5| Step: 1
Training loss: 2.3955770825441296
Validation loss: 2.515358332208789

Epoch: 5| Step: 2
Training loss: 2.954797664628088
Validation loss: 2.5105649434748174

Epoch: 5| Step: 3
Training loss: 1.9738550150730865
Validation loss: 2.517016361716748

Epoch: 5| Step: 4
Training loss: 2.6376213732810596
Validation loss: 2.5138400361692685

Epoch: 5| Step: 5
Training loss: 2.4727004109035366
Validation loss: 2.497754133269494

Epoch: 5| Step: 6
Training loss: 2.5214452289878606
Validation loss: 2.523062391716231

Epoch: 5| Step: 7
Training loss: 1.872368746487747
Validation loss: 2.5034223615631257

Epoch: 5| Step: 8
Training loss: 2.1477028440303614
Validation loss: 2.514097508197999

Epoch: 5| Step: 9
Training loss: 2.5787602422291713
Validation loss: 2.50899501107167

Epoch: 5| Step: 10
Training loss: 1.9216905210701207
Validation loss: 2.5110996228814955

Epoch: 5| Step: 11
Training loss: 1.4838168249210626
Validation loss: 2.521081803164188

Epoch: 234| Step: 0
Training loss: 2.2856603343590884
Validation loss: 2.5373256866202376

Epoch: 5| Step: 1
Training loss: 2.8015516171347725
Validation loss: 2.594972881378792

Epoch: 5| Step: 2
Training loss: 2.0350655738706833
Validation loss: 2.611377705132127

Epoch: 5| Step: 3
Training loss: 2.301533237745178
Validation loss: 2.637139162055376

Epoch: 5| Step: 4
Training loss: 2.6177484167460525
Validation loss: 2.6338576667515468

Epoch: 5| Step: 5
Training loss: 2.005863535132918
Validation loss: 2.6169036217833996

Epoch: 5| Step: 6
Training loss: 2.0751907169066763
Validation loss: 2.5588901299583444

Epoch: 5| Step: 7
Training loss: 2.0723469652612447
Validation loss: 2.5197065188931913

Epoch: 5| Step: 8
Training loss: 2.738496475359543
Validation loss: 2.5092590968759017

Epoch: 5| Step: 9
Training loss: 2.1906406200684643
Validation loss: 2.511030776280003

Epoch: 5| Step: 10
Training loss: 2.781888567022161
Validation loss: 2.4994308380098964

Epoch: 5| Step: 11
Training loss: 1.7759061595722934
Validation loss: 2.511031225307194

Epoch: 235| Step: 0
Training loss: 2.487040115861188
Validation loss: 2.503404671217213

Epoch: 5| Step: 1
Training loss: 2.128406935066176
Validation loss: 2.5021187426951657

Epoch: 5| Step: 2
Training loss: 2.4404146423730917
Validation loss: 2.5133857198609193

Epoch: 5| Step: 3
Training loss: 2.1954945118886995
Validation loss: 2.5024966409681646

Epoch: 5| Step: 4
Training loss: 2.068522129013314
Validation loss: 2.5080222678863997

Epoch: 5| Step: 5
Training loss: 2.7218857144167887
Validation loss: 2.51979970758571

Epoch: 5| Step: 6
Training loss: 1.981100248820608
Validation loss: 2.52650491589485

Epoch: 5| Step: 7
Training loss: 2.9480527884572
Validation loss: 2.5275613218478483

Epoch: 5| Step: 8
Training loss: 2.6025313672494113
Validation loss: 2.5459636391622604

Epoch: 5| Step: 9
Training loss: 1.9098932440117506
Validation loss: 2.5455915107275597

Epoch: 5| Step: 10
Training loss: 1.7956294511208102
Validation loss: 2.554560106933345

Epoch: 5| Step: 11
Training loss: 1.3404314181474921
Validation loss: 2.5579875975440634

Epoch: 236| Step: 0
Training loss: 2.290924772914866
Validation loss: 2.5713102806095764

Epoch: 5| Step: 1
Training loss: 2.6550241671107053
Validation loss: 2.590361396222819

Epoch: 5| Step: 2
Training loss: 2.529822429712984
Validation loss: 2.5898289706430337

Epoch: 5| Step: 3
Training loss: 1.7391282664679404
Validation loss: 2.5743426388154935

Epoch: 5| Step: 4
Training loss: 2.921477591675923
Validation loss: 2.550333713062627

Epoch: 5| Step: 5
Training loss: 2.0051767586207925
Validation loss: 2.554108716474304

Epoch: 5| Step: 6
Training loss: 1.8739079792183626
Validation loss: 2.554435464790359

Epoch: 5| Step: 7
Training loss: 2.229651734052557
Validation loss: 2.561793028218123

Epoch: 5| Step: 8
Training loss: 2.271040764063599
Validation loss: 2.545461730610163

Epoch: 5| Step: 9
Training loss: 2.512353796050051
Validation loss: 2.5782915389091463

Epoch: 5| Step: 10
Training loss: 2.0864625191483874
Validation loss: 2.5569567503130246

Epoch: 5| Step: 11
Training loss: 2.396503277418831
Validation loss: 2.543082059415048

Epoch: 237| Step: 0
Training loss: 2.2160628258788577
Validation loss: 2.5569506118014407

Epoch: 5| Step: 1
Training loss: 2.1433348940561325
Validation loss: 2.581489567727138

Epoch: 5| Step: 2
Training loss: 2.7007540850698053
Validation loss: 2.599839866884874

Epoch: 5| Step: 3
Training loss: 2.0243002918917266
Validation loss: 2.62828357004973

Epoch: 5| Step: 4
Training loss: 2.5261064239276507
Validation loss: 2.617437041423292

Epoch: 5| Step: 5
Training loss: 2.1018453074481123
Validation loss: 2.629548110184016

Epoch: 5| Step: 6
Training loss: 2.0761393762522893
Validation loss: 2.6010378173893343

Epoch: 5| Step: 7
Training loss: 2.8099034509328704
Validation loss: 2.5772866591102535

Epoch: 5| Step: 8
Training loss: 2.2681513939775266
Validation loss: 2.5701862408547926

Epoch: 5| Step: 9
Training loss: 1.623620474731896
Validation loss: 2.567546144254674

Epoch: 5| Step: 10
Training loss: 2.4331180603571183
Validation loss: 2.5534112485791183

Epoch: 5| Step: 11
Training loss: 1.8438107755310347
Validation loss: 2.540523859711208

Epoch: 238| Step: 0
Training loss: 2.087015280725664
Validation loss: 2.5278558895131487

Epoch: 5| Step: 1
Training loss: 2.497356352164189
Validation loss: 2.506216339430696

Epoch: 5| Step: 2
Training loss: 2.046784377093962
Validation loss: 2.502844880614966

Epoch: 5| Step: 3
Training loss: 2.2097863749136266
Validation loss: 2.494984658461032

Epoch: 5| Step: 4
Training loss: 2.5330109299078667
Validation loss: 2.4795833459207874

Epoch: 5| Step: 5
Training loss: 2.884470062507827
Validation loss: 2.491625308859877

Epoch: 5| Step: 6
Training loss: 2.6756614936704786
Validation loss: 2.501655582758802

Epoch: 5| Step: 7
Training loss: 2.8233888707409016
Validation loss: 2.4913141221016546

Epoch: 5| Step: 8
Training loss: 1.9955779900466233
Validation loss: 2.49274077696569

Epoch: 5| Step: 9
Training loss: 2.10729810406061
Validation loss: 2.5028858376942313

Epoch: 5| Step: 10
Training loss: 1.9471614890151225
Validation loss: 2.5246478426894425

Epoch: 5| Step: 11
Training loss: 2.069117247838492
Validation loss: 2.5595789092597645

Epoch: 239| Step: 0
Training loss: 2.2524610411464
Validation loss: 2.584885466784975

Epoch: 5| Step: 1
Training loss: 2.213628849481786
Validation loss: 2.6034818066639644

Epoch: 5| Step: 2
Training loss: 2.7614267672405366
Validation loss: 2.6199764479787033

Epoch: 5| Step: 3
Training loss: 2.476933400391865
Validation loss: 2.6063174152879376

Epoch: 5| Step: 4
Training loss: 2.4360092690828616
Validation loss: 2.6191622747161323

Epoch: 5| Step: 5
Training loss: 2.372842210020718
Validation loss: 2.601423032609756

Epoch: 5| Step: 6
Training loss: 2.2209063514982446
Validation loss: 2.5717543873831548

Epoch: 5| Step: 7
Training loss: 2.799194908200256
Validation loss: 2.547815703021124

Epoch: 5| Step: 8
Training loss: 2.334915192593513
Validation loss: 2.5413138400051043

Epoch: 5| Step: 9
Training loss: 1.8818860445740526
Validation loss: 2.524764126597203

Epoch: 5| Step: 10
Training loss: 1.4087659158289931
Validation loss: 2.527750158479268

Epoch: 5| Step: 11
Training loss: 1.7079563034953962
Validation loss: 2.5207527255471978

Epoch: 240| Step: 0
Training loss: 2.7957995174388715
Validation loss: 2.5133875854309133

Epoch: 5| Step: 1
Training loss: 2.2149885288397875
Validation loss: 2.5153395646820442

Epoch: 5| Step: 2
Training loss: 2.6611270785488683
Validation loss: 2.519620301400364

Epoch: 5| Step: 3
Training loss: 2.211720466141488
Validation loss: 2.525303507966945

Epoch: 5| Step: 4
Training loss: 2.0891935959327994
Validation loss: 2.528732205352048

Epoch: 5| Step: 5
Training loss: 2.5734300809010957
Validation loss: 2.5332678455956628

Epoch: 5| Step: 6
Training loss: 2.0506478983801935
Validation loss: 2.551641958696583

Epoch: 5| Step: 7
Training loss: 1.7917019892323036
Validation loss: 2.5626545681120376

Epoch: 5| Step: 8
Training loss: 2.0515403868390667
Validation loss: 2.5795581956970643

Epoch: 5| Step: 9
Training loss: 2.488052812806916
Validation loss: 2.6109159149489134

Epoch: 5| Step: 10
Training loss: 2.3713103294440043
Validation loss: 2.6231099090614713

Epoch: 5| Step: 11
Training loss: 2.5616097183036044
Validation loss: 2.611538616285899

Epoch: 241| Step: 0
Training loss: 1.9612134154234189
Validation loss: 2.5573020567103457

Epoch: 5| Step: 1
Training loss: 2.0052955377285495
Validation loss: 2.545330452977658

Epoch: 5| Step: 2
Training loss: 2.0907932869502197
Validation loss: 2.542809611789188

Epoch: 5| Step: 3
Training loss: 2.2459084077741993
Validation loss: 2.5342595258716063

Epoch: 5| Step: 4
Training loss: 2.547104339571231
Validation loss: 2.540250259765065

Epoch: 5| Step: 5
Training loss: 2.0960095866763027
Validation loss: 2.520121747196845

Epoch: 5| Step: 6
Training loss: 2.7547007179051324
Validation loss: 2.523447499289843

Epoch: 5| Step: 7
Training loss: 2.61792364443061
Validation loss: 2.5218989048502

Epoch: 5| Step: 8
Training loss: 1.8403029466103493
Validation loss: 2.5319664808458167

Epoch: 5| Step: 9
Training loss: 2.142221899333752
Validation loss: 2.5261561430065727

Epoch: 5| Step: 10
Training loss: 2.6735054083291994
Validation loss: 2.539987710474976

Epoch: 5| Step: 11
Training loss: 1.7156479325003853
Validation loss: 2.5372471330267987

Epoch: 242| Step: 0
Training loss: 1.9757429391473416
Validation loss: 2.549316094508137

Epoch: 5| Step: 1
Training loss: 2.0753316821001793
Validation loss: 2.544538561277863

Epoch: 5| Step: 2
Training loss: 2.2715925878068997
Validation loss: 2.5411810580407543

Epoch: 5| Step: 3
Training loss: 1.894008477829486
Validation loss: 2.547989373301709

Epoch: 5| Step: 4
Training loss: 2.5202977160536344
Validation loss: 2.5517312579033047

Epoch: 5| Step: 5
Training loss: 2.4210132665510957
Validation loss: 2.567665344765683

Epoch: 5| Step: 6
Training loss: 1.9972456204572508
Validation loss: 2.57391522730496

Epoch: 5| Step: 7
Training loss: 3.107285147103915
Validation loss: 2.568397949083794

Epoch: 5| Step: 8
Training loss: 2.9403450357293415
Validation loss: 2.5617984610027564

Epoch: 5| Step: 9
Training loss: 1.496510659238183
Validation loss: 2.559449974238136

Epoch: 5| Step: 10
Training loss: 2.153109045758539
Validation loss: 2.5487303324095385

Epoch: 5| Step: 11
Training loss: 1.475683525892767
Validation loss: 2.5572586420002494

Epoch: 243| Step: 0
Training loss: 2.422042053367875
Validation loss: 2.5520533203124827

Epoch: 5| Step: 1
Training loss: 1.800402024196393
Validation loss: 2.5443219023895494

Epoch: 5| Step: 2
Training loss: 1.8980465082112092
Validation loss: 2.540402490178886

Epoch: 5| Step: 3
Training loss: 2.815620302118072
Validation loss: 2.527709682884182

Epoch: 5| Step: 4
Training loss: 1.9535315738935408
Validation loss: 2.5346129922251435

Epoch: 5| Step: 5
Training loss: 2.7081651390863786
Validation loss: 2.532671411574688

Epoch: 5| Step: 6
Training loss: 2.448040595197985
Validation loss: 2.540152717696284

Epoch: 5| Step: 7
Training loss: 1.8519997382277105
Validation loss: 2.5424773351333636

Epoch: 5| Step: 8
Training loss: 2.256470066655582
Validation loss: 2.5570866987566667

Epoch: 5| Step: 9
Training loss: 2.598662446837557
Validation loss: 2.588044191038705

Epoch: 5| Step: 10
Training loss: 2.341784352323951
Validation loss: 2.587339353565537

Epoch: 5| Step: 11
Training loss: 2.442374417406104
Validation loss: 2.5870906759464973

Epoch: 244| Step: 0
Training loss: 1.8729097795483585
Validation loss: 2.598613526297699

Epoch: 5| Step: 1
Training loss: 2.345684219779666
Validation loss: 2.626881235644569

Epoch: 5| Step: 2
Training loss: 2.0324405409032584
Validation loss: 2.607968714754827

Epoch: 5| Step: 3
Training loss: 1.79435985180112
Validation loss: 2.5879344394261703

Epoch: 5| Step: 4
Training loss: 2.032142912404727
Validation loss: 2.55509865317151

Epoch: 5| Step: 5
Training loss: 2.238914732971882
Validation loss: 2.546007466929445

Epoch: 5| Step: 6
Training loss: 2.621523053050608
Validation loss: 2.545571561196723

Epoch: 5| Step: 7
Training loss: 2.2436492089715587
Validation loss: 2.5450109786787976

Epoch: 5| Step: 8
Training loss: 2.709391128157645
Validation loss: 2.5326994133126166

Epoch: 5| Step: 9
Training loss: 2.7389019794508074
Validation loss: 2.5339748625647576

Epoch: 5| Step: 10
Training loss: 2.5163935085709523
Validation loss: 2.5280021269825546

Epoch: 5| Step: 11
Training loss: 2.0026901749163657
Validation loss: 2.542941955175224

Epoch: 245| Step: 0
Training loss: 2.1178069950306337
Validation loss: 2.5348693830339246

Epoch: 5| Step: 1
Training loss: 2.4667192629627976
Validation loss: 2.5395026857329728

Epoch: 5| Step: 2
Training loss: 2.26704719892788
Validation loss: 2.5302102539779727

Epoch: 5| Step: 3
Training loss: 1.9240429443634466
Validation loss: 2.5502926532322285

Epoch: 5| Step: 4
Training loss: 2.279934438465539
Validation loss: 2.55958745165475

Epoch: 5| Step: 5
Training loss: 2.7050600567706597
Validation loss: 2.541634496240316

Epoch: 5| Step: 6
Training loss: 2.2273107509516787
Validation loss: 2.5535522956271097

Epoch: 5| Step: 7
Training loss: 2.0272123849163783
Validation loss: 2.552039108412188

Epoch: 5| Step: 8
Training loss: 2.1586726855916085
Validation loss: 2.5500693815117326

Epoch: 5| Step: 9
Training loss: 2.394415847959624
Validation loss: 2.5502005788043602

Epoch: 5| Step: 10
Training loss: 2.1731488999508115
Validation loss: 2.55920347369461

Epoch: 5| Step: 11
Training loss: 2.844946640935557
Validation loss: 2.5618541337784575

Epoch: 246| Step: 0
Training loss: 2.4853341991964695
Validation loss: 2.564868154495831

Epoch: 5| Step: 1
Training loss: 2.272630790916666
Validation loss: 2.5871568937611205

Epoch: 5| Step: 2
Training loss: 2.4400138607569497
Validation loss: 2.5783170878973873

Epoch: 5| Step: 3
Training loss: 1.9561766930638151
Validation loss: 2.577426966179138

Epoch: 5| Step: 4
Training loss: 2.3773054678320227
Validation loss: 2.571446161992089

Epoch: 5| Step: 5
Training loss: 1.5993406934140797
Validation loss: 2.566833054167542

Epoch: 5| Step: 6
Training loss: 2.357309207578479
Validation loss: 2.5488086295326213

Epoch: 5| Step: 7
Training loss: 2.842632367517029
Validation loss: 2.5461757222601133

Epoch: 5| Step: 8
Training loss: 2.139972670906468
Validation loss: 2.544586873932528

Epoch: 5| Step: 9
Training loss: 2.0786618564656902
Validation loss: 2.553790274190605

Epoch: 5| Step: 10
Training loss: 2.026574725817859
Validation loss: 2.552913864740829

Epoch: 5| Step: 11
Training loss: 2.4518798778289965
Validation loss: 2.569093583325783

Epoch: 247| Step: 0
Training loss: 2.0733047454351343
Validation loss: 2.566775151742664

Epoch: 5| Step: 1
Training loss: 2.573723196859984
Validation loss: 2.5742812276927323

Epoch: 5| Step: 2
Training loss: 2.0336418741154407
Validation loss: 2.5826067492347597

Epoch: 5| Step: 3
Training loss: 2.156530721331064
Validation loss: 2.5588862516437736

Epoch: 5| Step: 4
Training loss: 2.523065403765278
Validation loss: 2.575738098628476

Epoch: 5| Step: 5
Training loss: 2.2305291429884853
Validation loss: 2.5428631453455375

Epoch: 5| Step: 6
Training loss: 2.6572055668616508
Validation loss: 2.5359497082554103

Epoch: 5| Step: 7
Training loss: 2.580709652998538
Validation loss: 2.5240747810377653

Epoch: 5| Step: 8
Training loss: 1.980884636244159
Validation loss: 2.5020205796117323

Epoch: 5| Step: 9
Training loss: 1.9653544738625444
Validation loss: 2.5264749581405566

Epoch: 5| Step: 10
Training loss: 2.128213808332483
Validation loss: 2.532831090678085

Epoch: 5| Step: 11
Training loss: 2.0928477150840945
Validation loss: 2.5379786872978447

Epoch: 248| Step: 0
Training loss: 1.513479070382004
Validation loss: 2.571488379105872

Epoch: 5| Step: 1
Training loss: 2.2689317446547075
Validation loss: 2.566197089231849

Epoch: 5| Step: 2
Training loss: 2.641029733192193
Validation loss: 2.5574653525070454

Epoch: 5| Step: 3
Training loss: 1.6242073766944125
Validation loss: 2.585753773350369

Epoch: 5| Step: 4
Training loss: 2.1790253101645347
Validation loss: 2.6112938105692725

Epoch: 5| Step: 5
Training loss: 2.0165055591554863
Validation loss: 2.6283729771890076

Epoch: 5| Step: 6
Training loss: 2.4939989544117562
Validation loss: 2.683594912362622

Epoch: 5| Step: 7
Training loss: 2.282964924052033
Validation loss: 2.6954210747858545

Epoch: 5| Step: 8
Training loss: 2.8982111181808126
Validation loss: 2.692738617087882

Epoch: 5| Step: 9
Training loss: 2.268244419564877
Validation loss: 2.6669614909531103

Epoch: 5| Step: 10
Training loss: 2.5889809208266756
Validation loss: 2.6259061974872044

Epoch: 5| Step: 11
Training loss: 2.0935837409210607
Validation loss: 2.5628186702293503

Epoch: 249| Step: 0
Training loss: 1.5575303199964134
Validation loss: 2.5343255757484013

Epoch: 5| Step: 1
Training loss: 2.2537058934589105
Validation loss: 2.521276132980576

Epoch: 5| Step: 2
Training loss: 2.1078890617610537
Validation loss: 2.51275999991883

Epoch: 5| Step: 3
Training loss: 2.038692630823699
Validation loss: 2.5025219356326227

Epoch: 5| Step: 4
Training loss: 2.1797760976197518
Validation loss: 2.51122345893421

Epoch: 5| Step: 5
Training loss: 2.4028816923433167
Validation loss: 2.502413800343158

Epoch: 5| Step: 6
Training loss: 2.922329953927027
Validation loss: 2.5179572420471743

Epoch: 5| Step: 7
Training loss: 2.607884329600281
Validation loss: 2.517300105323992

Epoch: 5| Step: 8
Training loss: 2.258836349078105
Validation loss: 2.504464089814792

Epoch: 5| Step: 9
Training loss: 2.6092668156839935
Validation loss: 2.5206995815597226

Epoch: 5| Step: 10
Training loss: 2.172598409585793
Validation loss: 2.533783649327157

Epoch: 5| Step: 11
Training loss: 2.5458914138819977
Validation loss: 2.5551279526290926

Epoch: 250| Step: 0
Training loss: 2.670547601786608
Validation loss: 2.59772957528628

Epoch: 5| Step: 1
Training loss: 2.4138963759461904
Validation loss: 2.623782730940351

Epoch: 5| Step: 2
Training loss: 2.264395860517472
Validation loss: 2.6437036523746915

Epoch: 5| Step: 3
Training loss: 2.048707331177589
Validation loss: 2.6631980604743752

Epoch: 5| Step: 4
Training loss: 2.3366308299684575
Validation loss: 2.6554568022679623

Epoch: 5| Step: 5
Training loss: 2.4045525050055807
Validation loss: 2.667748959276789

Epoch: 5| Step: 6
Training loss: 2.4914543006069647
Validation loss: 2.591354098488619

Epoch: 5| Step: 7
Training loss: 2.218820382734624
Validation loss: 2.5683302651654563

Epoch: 5| Step: 8
Training loss: 2.0784675487915116
Validation loss: 2.5598613249017044

Epoch: 5| Step: 9
Training loss: 1.5873379842430229
Validation loss: 2.5691689147366086

Epoch: 5| Step: 10
Training loss: 2.364416029692851
Validation loss: 2.55977494247668

Epoch: 5| Step: 11
Training loss: 1.8030144007991549
Validation loss: 2.548771551875801

Testing loss: 2.0843177974113405
