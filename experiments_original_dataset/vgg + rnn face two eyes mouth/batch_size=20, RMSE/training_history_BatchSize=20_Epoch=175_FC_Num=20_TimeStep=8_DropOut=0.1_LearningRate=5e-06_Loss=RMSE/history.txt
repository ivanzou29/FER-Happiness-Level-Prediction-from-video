Epoch: 1| Step: 0
Training loss: 6.161897034772544
Validation loss: 5.854518508745912

Epoch: 5| Step: 1
Training loss: 6.159317723921924
Validation loss: 5.852602646807613

Epoch: 5| Step: 2
Training loss: 4.8330761852041295
Validation loss: 5.85077173978746

Epoch: 5| Step: 3
Training loss: 5.4459587162511
Validation loss: 5.848970281283596

Epoch: 5| Step: 4
Training loss: 6.128431020951811
Validation loss: 5.847274465420652

Epoch: 5| Step: 5
Training loss: 6.218884950640016
Validation loss: 5.8454366891532406

Epoch: 5| Step: 6
Training loss: 6.867172779332203
Validation loss: 5.843699279945837

Epoch: 5| Step: 7
Training loss: 5.918729968575858
Validation loss: 5.8419211206601425

Epoch: 5| Step: 8
Training loss: 6.321351445722805
Validation loss: 5.840102051600983

Epoch: 5| Step: 9
Training loss: 5.933123772738668
Validation loss: 5.838269688183763

Epoch: 5| Step: 10
Training loss: 5.7965110808527935
Validation loss: 5.836495627695384

Epoch: 5| Step: 11
Training loss: 3.239963586861657
Validation loss: 5.834580869333864

Epoch: 2| Step: 0
Training loss: 6.28375649616732
Validation loss: 5.832742125206438

Epoch: 5| Step: 1
Training loss: 6.268613031475057
Validation loss: 5.830870533078919

Epoch: 5| Step: 2
Training loss: 5.886161752534664
Validation loss: 5.8288321249314725

Epoch: 5| Step: 3
Training loss: 5.599008997015206
Validation loss: 5.826729819692442

Epoch: 5| Step: 4
Training loss: 5.790363119331199
Validation loss: 5.824557408175684

Epoch: 5| Step: 5
Training loss: 5.395060696264856
Validation loss: 5.822311870395983

Epoch: 5| Step: 6
Training loss: 6.542052174606485
Validation loss: 5.820101269466879

Epoch: 5| Step: 7
Training loss: 6.083700020943194
Validation loss: 5.817597570591511

Epoch: 5| Step: 8
Training loss: 5.6267678767558555
Validation loss: 5.815079304741207

Epoch: 5| Step: 9
Training loss: 5.771576247153717
Validation loss: 5.8124800992782255

Epoch: 5| Step: 10
Training loss: 5.947658161306832
Validation loss: 5.809692340491988

Epoch: 5| Step: 11
Training loss: 6.09795809480726
Validation loss: 5.806784920471916

Epoch: 3| Step: 0
Training loss: 5.8997389008243735
Validation loss: 5.803677662306805

Epoch: 5| Step: 1
Training loss: 5.697601067858893
Validation loss: 5.800498577042226

Epoch: 5| Step: 2
Training loss: 5.892751294791392
Validation loss: 5.797390088060321

Epoch: 5| Step: 3
Training loss: 5.597533241299347
Validation loss: 5.794012818038873

Epoch: 5| Step: 4
Training loss: 5.726294372026941
Validation loss: 5.790419508308452

Epoch: 5| Step: 5
Training loss: 6.504090415936103
Validation loss: 5.786605698030668

Epoch: 5| Step: 6
Training loss: 5.437909691821504
Validation loss: 5.782855098017409

Epoch: 5| Step: 7
Training loss: 6.577830980847536
Validation loss: 5.778638844588255

Epoch: 5| Step: 8
Training loss: 5.89333679757225
Validation loss: 5.774372814849826

Epoch: 5| Step: 9
Training loss: 5.815369256744162
Validation loss: 5.769804882395532

Epoch: 5| Step: 10
Training loss: 5.841567667268718
Validation loss: 5.765148546334844

Epoch: 5| Step: 11
Training loss: 5.565235965246842
Validation loss: 5.760283507129607

Epoch: 4| Step: 0
Training loss: 6.211162903732216
Validation loss: 5.755493967094151

Epoch: 5| Step: 1
Training loss: 5.605779914327353
Validation loss: 5.750092588591445

Epoch: 5| Step: 2
Training loss: 6.275315855063436
Validation loss: 5.744568235652758

Epoch: 5| Step: 3
Training loss: 6.239724830037767
Validation loss: 5.738906497360023

Epoch: 5| Step: 4
Training loss: 5.955130652236362
Validation loss: 5.732990718000745

Epoch: 5| Step: 5
Training loss: 5.691689425972618
Validation loss: 5.726798149419494

Epoch: 5| Step: 6
Training loss: 5.857999838628796
Validation loss: 5.7206087270693

Epoch: 5| Step: 7
Training loss: 5.12240218404723
Validation loss: 5.7141440070269836

Epoch: 5| Step: 8
Training loss: 6.270918971223623
Validation loss: 5.707646115092919

Epoch: 5| Step: 9
Training loss: 5.198331807388974
Validation loss: 5.700750760779363

Epoch: 5| Step: 10
Training loss: 5.922573239673518
Validation loss: 5.693968458622249

Epoch: 5| Step: 11
Training loss: 4.5729922532400336
Validation loss: 5.6867218603129235

Epoch: 5| Step: 0
Training loss: 5.616319528298342
Validation loss: 5.679628010700191

Epoch: 5| Step: 1
Training loss: 5.548274505722002
Validation loss: 5.67221452942062

Epoch: 5| Step: 2
Training loss: 6.320075899465132
Validation loss: 5.664874546113044

Epoch: 5| Step: 3
Training loss: 5.981908225071963
Validation loss: 5.657061214830384

Epoch: 5| Step: 4
Training loss: 5.875060385535744
Validation loss: 5.6494198160848335

Epoch: 5| Step: 5
Training loss: 4.721137447050796
Validation loss: 5.641619276789651

Epoch: 5| Step: 6
Training loss: 4.982258601487354
Validation loss: 5.633737630086415

Epoch: 5| Step: 7
Training loss: 5.758135472094264
Validation loss: 5.625779225100478

Epoch: 5| Step: 8
Training loss: 5.825241398209357
Validation loss: 5.617523147960868

Epoch: 5| Step: 9
Training loss: 5.952406311707745
Validation loss: 5.609622733791858

Epoch: 5| Step: 10
Training loss: 6.476082446963077
Validation loss: 5.601398531235493

Epoch: 5| Step: 11
Training loss: 5.957768909245856
Validation loss: 5.593229656774195

Epoch: 6| Step: 0
Training loss: 5.8862819699439735
Validation loss: 5.585196770059348

Epoch: 5| Step: 1
Training loss: 5.707014873671747
Validation loss: 5.5770458741248765

Epoch: 5| Step: 2
Training loss: 5.343377351315803
Validation loss: 5.569090657031099

Epoch: 5| Step: 3
Training loss: 5.768261314514912
Validation loss: 5.561080237087063

Epoch: 5| Step: 4
Training loss: 5.224108474820317
Validation loss: 5.553213776190272

Epoch: 5| Step: 5
Training loss: 5.451404726473837
Validation loss: 5.545558905839444

Epoch: 5| Step: 6
Training loss: 6.047698208863293
Validation loss: 5.537898922020879

Epoch: 5| Step: 7
Training loss: 5.540011089327624
Validation loss: 5.530477954842292

Epoch: 5| Step: 8
Training loss: 5.22266209330264
Validation loss: 5.522927238639384

Epoch: 5| Step: 9
Training loss: 6.378283085375523
Validation loss: 5.51590385848759

Epoch: 5| Step: 10
Training loss: 5.901068458148398
Validation loss: 5.508582412620776

Epoch: 5| Step: 11
Training loss: 4.063443118441138
Validation loss: 5.501360681586645

Epoch: 7| Step: 0
Training loss: 5.498759216453492
Validation loss: 5.494429961197119

Epoch: 5| Step: 1
Training loss: 5.024647426097855
Validation loss: 5.487447148085197

Epoch: 5| Step: 2
Training loss: 5.434868186608627
Validation loss: 5.480939160199614

Epoch: 5| Step: 3
Training loss: 5.334581864764567
Validation loss: 5.47438513933603

Epoch: 5| Step: 4
Training loss: 5.599628109163813
Validation loss: 5.467771286352795

Epoch: 5| Step: 5
Training loss: 5.928462167018651
Validation loss: 5.4614658200202175

Epoch: 5| Step: 6
Training loss: 5.936126550132625
Validation loss: 5.455060649934435

Epoch: 5| Step: 7
Training loss: 5.274881710516031
Validation loss: 5.448467761649367

Epoch: 5| Step: 8
Training loss: 5.126225022704177
Validation loss: 5.442311332375146

Epoch: 5| Step: 9
Training loss: 6.673353973773408
Validation loss: 5.435643321241773

Epoch: 5| Step: 10
Training loss: 5.626323120482781
Validation loss: 5.42887142644343

Epoch: 5| Step: 11
Training loss: 4.136388374658591
Validation loss: 5.42243081064668

Epoch: 8| Step: 0
Training loss: 5.144602063270229
Validation loss: 5.415902541133618

Epoch: 5| Step: 1
Training loss: 5.4718256557642695
Validation loss: 5.409548119107628

Epoch: 5| Step: 2
Training loss: 5.85570067085739
Validation loss: 5.403178001895462

Epoch: 5| Step: 3
Training loss: 5.9307405242940705
Validation loss: 5.396868229699614

Epoch: 5| Step: 4
Training loss: 5.649542609411548
Validation loss: 5.39050696792013

Epoch: 5| Step: 5
Training loss: 6.01246936814085
Validation loss: 5.3842915356366765

Epoch: 5| Step: 6
Training loss: 5.168243700759422
Validation loss: 5.3781112641168916

Epoch: 5| Step: 7
Training loss: 5.217492962966363
Validation loss: 5.372266976504199

Epoch: 5| Step: 8
Training loss: 5.443502861570908
Validation loss: 5.366436760975286

Epoch: 5| Step: 9
Training loss: 5.209632813150228
Validation loss: 5.36072971731097

Epoch: 5| Step: 10
Training loss: 5.7212055541786
Validation loss: 5.355183830074083

Epoch: 5| Step: 11
Training loss: 3.3428262165348404
Validation loss: 5.350055551091979

Epoch: 9| Step: 0
Training loss: 5.334339801871097
Validation loss: 5.344977224912257

Epoch: 5| Step: 1
Training loss: 4.292667284612428
Validation loss: 5.3395097354138485

Epoch: 5| Step: 2
Training loss: 6.187566891703607
Validation loss: 5.334619414218857

Epoch: 5| Step: 3
Training loss: 6.125167532984621
Validation loss: 5.329599871810213

Epoch: 5| Step: 4
Training loss: 5.65397707968709
Validation loss: 5.324399658174685

Epoch: 5| Step: 5
Training loss: 5.032516414882762
Validation loss: 5.319017608401146

Epoch: 5| Step: 6
Training loss: 5.114401115491588
Validation loss: 5.313829046316677

Epoch: 5| Step: 7
Training loss: 5.402493798191901
Validation loss: 5.308386904607365

Epoch: 5| Step: 8
Training loss: 5.833583535777685
Validation loss: 5.302901299216244

Epoch: 5| Step: 9
Training loss: 5.041900356120676
Validation loss: 5.297460623056683

Epoch: 5| Step: 10
Training loss: 5.657229512584463
Validation loss: 5.291777221646195

Epoch: 5| Step: 11
Training loss: 4.906661484100535
Validation loss: 5.28606787180738

Epoch: 10| Step: 0
Training loss: 4.654483536896361
Validation loss: 5.280119607550849

Epoch: 5| Step: 1
Training loss: 5.060600395317139
Validation loss: 5.274490492441845

Epoch: 5| Step: 2
Training loss: 5.655742474964294
Validation loss: 5.269112485737473

Epoch: 5| Step: 3
Training loss: 5.635547328522457
Validation loss: 5.263602542833428

Epoch: 5| Step: 4
Training loss: 6.13184550248597
Validation loss: 5.257913166233108

Epoch: 5| Step: 5
Training loss: 5.412231311780456
Validation loss: 5.252251596364406

Epoch: 5| Step: 6
Training loss: 5.236858450625219
Validation loss: 5.246602540991594

Epoch: 5| Step: 7
Training loss: 5.041113620826844
Validation loss: 5.241084362226669

Epoch: 5| Step: 8
Training loss: 5.230809150086057
Validation loss: 5.235561285767787

Epoch: 5| Step: 9
Training loss: 5.377759180921307
Validation loss: 5.230000321805809

Epoch: 5| Step: 10
Training loss: 5.412868439642058
Validation loss: 5.22425787673232

Epoch: 5| Step: 11
Training loss: 5.996005317955381
Validation loss: 5.21844193697144

Epoch: 11| Step: 0
Training loss: 4.921221589812347
Validation loss: 5.2130622783101765

Epoch: 5| Step: 1
Training loss: 5.265370348650441
Validation loss: 5.207335966618369

Epoch: 5| Step: 2
Training loss: 4.5549031594259
Validation loss: 5.201645779289168

Epoch: 5| Step: 3
Training loss: 5.644581598499498
Validation loss: 5.196414083080791

Epoch: 5| Step: 4
Training loss: 5.000383553098761
Validation loss: 5.191011221011615

Epoch: 5| Step: 5
Training loss: 4.903884414592637
Validation loss: 5.185461946164315

Epoch: 5| Step: 6
Training loss: 5.889158030823397
Validation loss: 5.180124202095971

Epoch: 5| Step: 7
Training loss: 5.941353601426825
Validation loss: 5.17450303134749

Epoch: 5| Step: 8
Training loss: 4.537583548457099
Validation loss: 5.168797179333133

Epoch: 5| Step: 9
Training loss: 6.028614792767911
Validation loss: 5.1632099996522145

Epoch: 5| Step: 10
Training loss: 5.27769124590336
Validation loss: 5.157681075822255

Epoch: 5| Step: 11
Training loss: 5.984663754660545
Validation loss: 5.151838908842114

Epoch: 12| Step: 0
Training loss: 5.933559997743865
Validation loss: 5.146035235481397

Epoch: 5| Step: 1
Training loss: 5.379719813258404
Validation loss: 5.140045759502028

Epoch: 5| Step: 2
Training loss: 5.006178662271652
Validation loss: 5.1341022978585755

Epoch: 5| Step: 3
Training loss: 5.168156603846749
Validation loss: 5.128530116160885

Epoch: 5| Step: 4
Training loss: 4.503854795957713
Validation loss: 5.122917845566738

Epoch: 5| Step: 5
Training loss: 5.244016961996317
Validation loss: 5.117226652427549

Epoch: 5| Step: 6
Training loss: 4.891490725592218
Validation loss: 5.111485923048425

Epoch: 5| Step: 7
Training loss: 4.975876789370698
Validation loss: 5.105345051518785

Epoch: 5| Step: 8
Training loss: 4.7729158256904105
Validation loss: 5.099685495004011

Epoch: 5| Step: 9
Training loss: 6.434898665666954
Validation loss: 5.094363731434527

Epoch: 5| Step: 10
Training loss: 5.2447690789633805
Validation loss: 5.088785463061352

Epoch: 5| Step: 11
Training loss: 4.234225900425021
Validation loss: 5.082762493329649

Epoch: 13| Step: 0
Training loss: 5.888151666491567
Validation loss: 5.076456353324458

Epoch: 5| Step: 1
Training loss: 4.341888907242666
Validation loss: 5.070151296599054

Epoch: 5| Step: 2
Training loss: 4.716570015895423
Validation loss: 5.064640895443685

Epoch: 5| Step: 3
Training loss: 4.006906983398591
Validation loss: 5.058399234993928

Epoch: 5| Step: 4
Training loss: 5.42039957776561
Validation loss: 5.052704812852917

Epoch: 5| Step: 5
Training loss: 5.4880056508872075
Validation loss: 5.046697103634507

Epoch: 5| Step: 6
Training loss: 5.68677558058222
Validation loss: 5.040962582545244

Epoch: 5| Step: 7
Training loss: 5.184139220134366
Validation loss: 5.034495615920226

Epoch: 5| Step: 8
Training loss: 5.387361196336295
Validation loss: 5.027601850474795

Epoch: 5| Step: 9
Training loss: 5.6522114704632145
Validation loss: 5.0211260803900695

Epoch: 5| Step: 10
Training loss: 4.670888739242232
Validation loss: 5.014956809086411

Epoch: 5| Step: 11
Training loss: 5.499908099707177
Validation loss: 5.008131480261782

Epoch: 14| Step: 0
Training loss: 5.467570150350064
Validation loss: 5.001293261486385

Epoch: 5| Step: 1
Training loss: 5.515809312718087
Validation loss: 4.994405748125229

Epoch: 5| Step: 2
Training loss: 3.9621004883964472
Validation loss: 4.987967381452024

Epoch: 5| Step: 3
Training loss: 4.186023508792337
Validation loss: 4.980967713338238

Epoch: 5| Step: 4
Training loss: 4.708281367642512
Validation loss: 4.975156464664224

Epoch: 5| Step: 5
Training loss: 5.787305145608677
Validation loss: 4.968766370382472

Epoch: 5| Step: 6
Training loss: 5.221818216176056
Validation loss: 4.962265325549729

Epoch: 5| Step: 7
Training loss: 5.0247241044100575
Validation loss: 4.956030698320431

Epoch: 5| Step: 8
Training loss: 5.465614858872006
Validation loss: 4.949804827827312

Epoch: 5| Step: 9
Training loss: 4.9801895601894435
Validation loss: 4.943084946310662

Epoch: 5| Step: 10
Training loss: 5.482842299129533
Validation loss: 4.937448002344275

Epoch: 5| Step: 11
Training loss: 4.542229130530863
Validation loss: 4.931835184319684

Epoch: 15| Step: 0
Training loss: 4.903703356658865
Validation loss: 4.926477772744031

Epoch: 5| Step: 1
Training loss: 5.776802290380764
Validation loss: 4.920511765380599

Epoch: 5| Step: 2
Training loss: 4.546099095161942
Validation loss: 4.915448557829009

Epoch: 5| Step: 3
Training loss: 4.926326034876731
Validation loss: 4.909763786839011

Epoch: 5| Step: 4
Training loss: 4.691553829771804
Validation loss: 4.904215688576571

Epoch: 5| Step: 5
Training loss: 4.543025218976754
Validation loss: 4.898842542857412

Epoch: 5| Step: 6
Training loss: 5.771090101274736
Validation loss: 4.893787689843352

Epoch: 5| Step: 7
Training loss: 5.39023524547741
Validation loss: 4.888227738513343

Epoch: 5| Step: 8
Training loss: 4.836508573914335
Validation loss: 4.882513239527297

Epoch: 5| Step: 9
Training loss: 5.209585034324557
Validation loss: 4.876844130685647

Epoch: 5| Step: 10
Training loss: 4.8671526226428945
Validation loss: 4.871016080880031

Epoch: 5| Step: 11
Training loss: 2.4581661059727478
Validation loss: 4.86645689287922

Epoch: 16| Step: 0
Training loss: 4.459963610376635
Validation loss: 4.861063967279379

Epoch: 5| Step: 1
Training loss: 4.409774993554026
Validation loss: 4.855916475996435

Epoch: 5| Step: 2
Training loss: 5.316161744985995
Validation loss: 4.851385525942739

Epoch: 5| Step: 3
Training loss: 4.816660086199391
Validation loss: 4.8455730494064575

Epoch: 5| Step: 4
Training loss: 5.460869915589031
Validation loss: 4.840523619438753

Epoch: 5| Step: 5
Training loss: 4.5960170834774114
Validation loss: 4.835446679469885

Epoch: 5| Step: 6
Training loss: 4.481083848498641
Validation loss: 4.830125692534129

Epoch: 5| Step: 7
Training loss: 5.181485285553197
Validation loss: 4.824566967297803

Epoch: 5| Step: 8
Training loss: 5.377891649839378
Validation loss: 4.819578464206916

Epoch: 5| Step: 9
Training loss: 4.962391749818036
Validation loss: 4.814915525607143

Epoch: 5| Step: 10
Training loss: 5.015861909684265
Validation loss: 4.809517452252875

Epoch: 5| Step: 11
Training loss: 6.401235413522607
Validation loss: 4.80370484101173

Epoch: 17| Step: 0
Training loss: 4.742435254030557
Validation loss: 4.799101827286895

Epoch: 5| Step: 1
Training loss: 4.624093044123668
Validation loss: 4.793268610438177

Epoch: 5| Step: 2
Training loss: 6.0522030563024565
Validation loss: 4.787683484418395

Epoch: 5| Step: 3
Training loss: 4.785658057234291
Validation loss: 4.781557875218125

Epoch: 5| Step: 4
Training loss: 4.185157690142323
Validation loss: 4.776081824125183

Epoch: 5| Step: 5
Training loss: 5.021228737780164
Validation loss: 4.769944635712383

Epoch: 5| Step: 6
Training loss: 4.7263877647195045
Validation loss: 4.764937462744903

Epoch: 5| Step: 7
Training loss: 5.360831460373773
Validation loss: 4.758885455236553

Epoch: 5| Step: 8
Training loss: 4.57612790238423
Validation loss: 4.753571907349962

Epoch: 5| Step: 9
Training loss: 4.1552058464317625
Validation loss: 4.748930802390636

Epoch: 5| Step: 10
Training loss: 5.552687315686095
Validation loss: 4.743362122075495

Epoch: 5| Step: 11
Training loss: 3.4690065031323325
Validation loss: 4.737621054868325

Epoch: 18| Step: 0
Training loss: 4.9254422294242275
Validation loss: 4.731780588758956

Epoch: 5| Step: 1
Training loss: 5.404616974731391
Validation loss: 4.726295366961541

Epoch: 5| Step: 2
Training loss: 4.470982134150894
Validation loss: 4.721533554324724

Epoch: 5| Step: 3
Training loss: 4.969332295012274
Validation loss: 4.716452630896397

Epoch: 5| Step: 4
Training loss: 4.63706695097633
Validation loss: 4.710125956055912

Epoch: 5| Step: 5
Training loss: 4.309591003271484
Validation loss: 4.704835008436977

Epoch: 5| Step: 6
Training loss: 4.645213315272482
Validation loss: 4.6994281573104235

Epoch: 5| Step: 7
Training loss: 5.148594577459646
Validation loss: 4.694195166420671

Epoch: 5| Step: 8
Training loss: 5.109806520863981
Validation loss: 4.688929636487184

Epoch: 5| Step: 9
Training loss: 4.616566159546373
Validation loss: 4.682648271411755

Epoch: 5| Step: 10
Training loss: 4.517520915723471
Validation loss: 4.677758882441129

Epoch: 5| Step: 11
Training loss: 6.0531726935717876
Validation loss: 4.672247464611637

Epoch: 19| Step: 0
Training loss: 4.5479571441000095
Validation loss: 4.666237601355625

Epoch: 5| Step: 1
Training loss: 5.448742348686809
Validation loss: 4.6616379545189295

Epoch: 5| Step: 2
Training loss: 5.021595476272391
Validation loss: 4.656300845284601

Epoch: 5| Step: 3
Training loss: 5.30631353657025
Validation loss: 4.651314417355302

Epoch: 5| Step: 4
Training loss: 4.302387266837756
Validation loss: 4.64717493515192

Epoch: 5| Step: 5
Training loss: 4.536984097495575
Validation loss: 4.641074247696083

Epoch: 5| Step: 6
Training loss: 4.687800079913114
Validation loss: 4.634999882966568

Epoch: 5| Step: 7
Training loss: 4.249679104527197
Validation loss: 4.630358315589354

Epoch: 5| Step: 8
Training loss: 4.66313226007751
Validation loss: 4.624460644245772

Epoch: 5| Step: 9
Training loss: 4.391470722457474
Validation loss: 4.619380707580484

Epoch: 5| Step: 10
Training loss: 5.054482976204221
Validation loss: 4.613841755727248

Epoch: 5| Step: 11
Training loss: 5.057126808294981
Validation loss: 4.608975262738917

Epoch: 20| Step: 0
Training loss: 4.0796059444344905
Validation loss: 4.604131709983078

Epoch: 5| Step: 1
Training loss: 5.436609304855608
Validation loss: 4.599104150668728

Epoch: 5| Step: 2
Training loss: 4.47821238206899
Validation loss: 4.593582236758037

Epoch: 5| Step: 3
Training loss: 4.591058890012998
Validation loss: 4.587523489951715

Epoch: 5| Step: 4
Training loss: 4.656029203159472
Validation loss: 4.582201569435928

Epoch: 5| Step: 5
Training loss: 4.664098691560274
Validation loss: 4.577142725081556

Epoch: 5| Step: 6
Training loss: 4.958494338725994
Validation loss: 4.572072707946959

Epoch: 5| Step: 7
Training loss: 4.63350246495817
Validation loss: 4.5676790828775955

Epoch: 5| Step: 8
Training loss: 5.022601163309576
Validation loss: 4.5615365914217945

Epoch: 5| Step: 9
Training loss: 4.958130626648827
Validation loss: 4.556014071174597

Epoch: 5| Step: 10
Training loss: 4.026736549461552
Validation loss: 4.550729994150951

Epoch: 5| Step: 11
Training loss: 5.024203466037144
Validation loss: 4.54575673233141

Epoch: 21| Step: 0
Training loss: 4.259318738021439
Validation loss: 4.539949511003603

Epoch: 5| Step: 1
Training loss: 4.313618169476308
Validation loss: 4.535616373557948

Epoch: 5| Step: 2
Training loss: 4.4408427797802705
Validation loss: 4.53157714013609

Epoch: 5| Step: 3
Training loss: 4.729039575602766
Validation loss: 4.524913083782014

Epoch: 5| Step: 4
Training loss: 5.00532343715881
Validation loss: 4.519680010853943

Epoch: 5| Step: 5
Training loss: 4.618669043052127
Validation loss: 4.515680482164943

Epoch: 5| Step: 6
Training loss: 4.8598522675591695
Validation loss: 4.5114615495039505

Epoch: 5| Step: 7
Training loss: 4.699807045404959
Validation loss: 4.509500179901666

Epoch: 5| Step: 8
Training loss: 4.917143760852694
Validation loss: 4.499684022476933

Epoch: 5| Step: 9
Training loss: 4.430080820211794
Validation loss: 4.49612820918944

Epoch: 5| Step: 10
Training loss: 4.808071328114864
Validation loss: 4.494656215614459

Epoch: 5| Step: 11
Training loss: 4.275099296978193
Validation loss: 4.492364295023622

Epoch: 22| Step: 0
Training loss: 3.66637433938609
Validation loss: 4.487100612467662

Epoch: 5| Step: 1
Training loss: 4.371801896809961
Validation loss: 4.47810280460058

Epoch: 5| Step: 2
Training loss: 4.803354664600101
Validation loss: 4.4695261123468555

Epoch: 5| Step: 3
Training loss: 4.450031906184994
Validation loss: 4.463776419426182

Epoch: 5| Step: 4
Training loss: 5.535570773888146
Validation loss: 4.45857053939725

Epoch: 5| Step: 5
Training loss: 4.920681278852236
Validation loss: 4.4532019446791535

Epoch: 5| Step: 6
Training loss: 4.5843879642316265
Validation loss: 4.448400603626961

Epoch: 5| Step: 7
Training loss: 4.313949120346629
Validation loss: 4.441867004848227

Epoch: 5| Step: 8
Training loss: 4.45686178194471
Validation loss: 4.436094307666936

Epoch: 5| Step: 9
Training loss: 4.401395463736273
Validation loss: 4.430879866364239

Epoch: 5| Step: 10
Training loss: 4.62025600136924
Validation loss: 4.424584563917595

Epoch: 5| Step: 11
Training loss: 4.806174344383824
Validation loss: 4.420096436235336

Epoch: 23| Step: 0
Training loss: 4.069226140114915
Validation loss: 4.413600368558041

Epoch: 5| Step: 1
Training loss: 4.003162087857567
Validation loss: 4.410479321738259

Epoch: 5| Step: 2
Training loss: 4.907947028112846
Validation loss: 4.4055146309383035

Epoch: 5| Step: 3
Training loss: 4.36615076196371
Validation loss: 4.398968517169129

Epoch: 5| Step: 4
Training loss: 4.882687889034944
Validation loss: 4.394701222841345

Epoch: 5| Step: 5
Training loss: 5.0640328053019
Validation loss: 4.390771399576611

Epoch: 5| Step: 6
Training loss: 5.3177932398708965
Validation loss: 4.385403670097658

Epoch: 5| Step: 7
Training loss: 4.728602550768026
Validation loss: 4.379483704685695

Epoch: 5| Step: 8
Training loss: 4.187701320079001
Validation loss: 4.373667123392207

Epoch: 5| Step: 9
Training loss: 3.787138334323908
Validation loss: 4.368839831649745

Epoch: 5| Step: 10
Training loss: 4.5258114503432
Validation loss: 4.363980047492112

Epoch: 5| Step: 11
Training loss: 1.677396977952168
Validation loss: 4.359038363895902

Epoch: 24| Step: 0
Training loss: 4.874366132168334
Validation loss: 4.354296730994919

Epoch: 5| Step: 1
Training loss: 3.9787989474781362
Validation loss: 4.349218836613567

Epoch: 5| Step: 2
Training loss: 3.855813301869279
Validation loss: 4.343724321614209

Epoch: 5| Step: 3
Training loss: 5.089596792862477
Validation loss: 4.339189573393193

Epoch: 5| Step: 4
Training loss: 4.645695135458845
Validation loss: 4.334039936165094

Epoch: 5| Step: 5
Training loss: 3.994841706693226
Validation loss: 4.329112090695968

Epoch: 5| Step: 6
Training loss: 3.926636256395423
Validation loss: 4.323754914909482

Epoch: 5| Step: 7
Training loss: 4.487657787556098
Validation loss: 4.318936681324071

Epoch: 5| Step: 8
Training loss: 4.883338643527914
Validation loss: 4.314051243151263

Epoch: 5| Step: 9
Training loss: 4.247755916759948
Validation loss: 4.30866007841719

Epoch: 5| Step: 10
Training loss: 4.400880396068274
Validation loss: 4.303496965202418

Epoch: 5| Step: 11
Training loss: 6.253383483577173
Validation loss: 4.297467564269388

Epoch: 25| Step: 0
Training loss: 3.306280955871003
Validation loss: 4.293086824653251

Epoch: 5| Step: 1
Training loss: 5.452647540769293
Validation loss: 4.288111277231516

Epoch: 5| Step: 2
Training loss: 4.143881154466048
Validation loss: 4.282828214130152

Epoch: 5| Step: 3
Training loss: 4.507666309438951
Validation loss: 4.277825993449207

Epoch: 5| Step: 4
Training loss: 5.494741874095584
Validation loss: 4.272124996093145

Epoch: 5| Step: 5
Training loss: 4.146313944551501
Validation loss: 4.266184307873874

Epoch: 5| Step: 6
Training loss: 3.9652240138613277
Validation loss: 4.2604997093607375

Epoch: 5| Step: 7
Training loss: 3.747045115728419
Validation loss: 4.255499381201467

Epoch: 5| Step: 8
Training loss: 3.620198588746265
Validation loss: 4.249612673706079

Epoch: 5| Step: 9
Training loss: 5.064731812376528
Validation loss: 4.244308732845402

Epoch: 5| Step: 10
Training loss: 4.657117110038283
Validation loss: 4.238881508412622

Epoch: 5| Step: 11
Training loss: 2.027027965493887
Validation loss: 4.233897427399554

Epoch: 26| Step: 0
Training loss: 3.9970522986629873
Validation loss: 4.228663802982844

Epoch: 5| Step: 1
Training loss: 5.0003814551757575
Validation loss: 4.223870539507388

Epoch: 5| Step: 2
Training loss: 4.445929888338489
Validation loss: 4.218759155263504

Epoch: 5| Step: 3
Training loss: 4.705382961534297
Validation loss: 4.212767925665675

Epoch: 5| Step: 4
Training loss: 4.183365104118974
Validation loss: 4.207714302814377

Epoch: 5| Step: 5
Training loss: 4.135462353099272
Validation loss: 4.204280580969127

Epoch: 5| Step: 6
Training loss: 3.8404908047379642
Validation loss: 4.199582338191398

Epoch: 5| Step: 7
Training loss: 4.636281456448498
Validation loss: 4.192448519915931

Epoch: 5| Step: 8
Training loss: 3.81990145790861
Validation loss: 4.187702596327853

Epoch: 5| Step: 9
Training loss: 3.834348019082946
Validation loss: 4.182909347064697

Epoch: 5| Step: 10
Training loss: 4.952546961415843
Validation loss: 4.177847973796614

Epoch: 5| Step: 11
Training loss: 3.8199526377433073
Validation loss: 4.1729947610226965

Epoch: 27| Step: 0
Training loss: 4.921548111974671
Validation loss: 4.168006965917244

Epoch: 5| Step: 1
Training loss: 4.438448737364651
Validation loss: 4.162357131407805

Epoch: 5| Step: 2
Training loss: 3.770731901768171
Validation loss: 4.157751830245058

Epoch: 5| Step: 3
Training loss: 4.050266097004364
Validation loss: 4.152474526624423

Epoch: 5| Step: 4
Training loss: 4.414843032828755
Validation loss: 4.147215146466608

Epoch: 5| Step: 5
Training loss: 4.2294997411399295
Validation loss: 4.141954767477829

Epoch: 5| Step: 6
Training loss: 4.216439525733758
Validation loss: 4.136964031244464

Epoch: 5| Step: 7
Training loss: 4.138125258853215
Validation loss: 4.1317535947575275

Epoch: 5| Step: 8
Training loss: 3.867402904946291
Validation loss: 4.126140258671787

Epoch: 5| Step: 9
Training loss: 3.8112914874657906
Validation loss: 4.1206963321886425

Epoch: 5| Step: 10
Training loss: 5.13071662463202
Validation loss: 4.116024994487271

Epoch: 5| Step: 11
Training loss: 3.078365878057222
Validation loss: 4.110638191039964

Epoch: 28| Step: 0
Training loss: 4.173221213771475
Validation loss: 4.105713033380313

Epoch: 5| Step: 1
Training loss: 4.320211840486492
Validation loss: 4.100249617429023

Epoch: 5| Step: 2
Training loss: 4.2719027537160805
Validation loss: 4.095264411924353

Epoch: 5| Step: 3
Training loss: 3.8257319230055966
Validation loss: 4.089963477033035

Epoch: 5| Step: 4
Training loss: 3.5791411310483294
Validation loss: 4.085059422317981

Epoch: 5| Step: 5
Training loss: 4.347601191882395
Validation loss: 4.080545766572151

Epoch: 5| Step: 6
Training loss: 3.9910705556652153
Validation loss: 4.07577991413672

Epoch: 5| Step: 7
Training loss: 4.29320111049395
Validation loss: 4.07026787536331

Epoch: 5| Step: 8
Training loss: 3.995988383913006
Validation loss: 4.066204494781059

Epoch: 5| Step: 9
Training loss: 4.88585881534919
Validation loss: 4.061049466499488

Epoch: 5| Step: 10
Training loss: 4.440747858934445
Validation loss: 4.056472747909302

Epoch: 5| Step: 11
Training loss: 4.5401465062100765
Validation loss: 4.0509725713718625

Epoch: 29| Step: 0
Training loss: 4.2128994534417235
Validation loss: 4.045613198948949

Epoch: 5| Step: 1
Training loss: 4.262584454994635
Validation loss: 4.0408729612851735

Epoch: 5| Step: 2
Training loss: 3.828963954625365
Validation loss: 4.035583527633365

Epoch: 5| Step: 3
Training loss: 3.7797576229155596
Validation loss: 4.030395003145247

Epoch: 5| Step: 4
Training loss: 4.113637128108522
Validation loss: 4.0255938482833775

Epoch: 5| Step: 5
Training loss: 4.58908570867897
Validation loss: 4.020829362159046

Epoch: 5| Step: 6
Training loss: 4.170400294569259
Validation loss: 4.0149246574860795

Epoch: 5| Step: 7
Training loss: 4.1498662352547955
Validation loss: 4.0100720872685995

Epoch: 5| Step: 8
Training loss: 4.05560986092032
Validation loss: 4.004835186637691

Epoch: 5| Step: 9
Training loss: 4.540588017501449
Validation loss: 3.999775299079045

Epoch: 5| Step: 10
Training loss: 4.135125419808791
Validation loss: 3.9943396981146244

Epoch: 5| Step: 11
Training loss: 2.7398234988536405
Validation loss: 3.9891690005031366

Epoch: 30| Step: 0
Training loss: 4.052988743899829
Validation loss: 3.984075397870828

Epoch: 5| Step: 1
Training loss: 4.378889915851003
Validation loss: 3.979258309885155

Epoch: 5| Step: 2
Training loss: 3.8512958178941163
Validation loss: 3.9748248117656715

Epoch: 5| Step: 3
Training loss: 4.093943584029202
Validation loss: 3.969308553524042

Epoch: 5| Step: 4
Training loss: 4.4107013699997175
Validation loss: 3.9647636518233136

Epoch: 5| Step: 5
Training loss: 4.335935080587726
Validation loss: 3.9593627979679655

Epoch: 5| Step: 6
Training loss: 4.3123688608769015
Validation loss: 3.9544045786070163

Epoch: 5| Step: 7
Training loss: 3.3888767499306764
Validation loss: 3.949712222517141

Epoch: 5| Step: 8
Training loss: 4.16484958445767
Validation loss: 3.9440470966972985

Epoch: 5| Step: 9
Training loss: 3.6048632409851633
Validation loss: 3.9387368878310047

Epoch: 5| Step: 10
Training loss: 4.153295858182475
Validation loss: 3.933760784988157

Epoch: 5| Step: 11
Training loss: 4.765118281206325
Validation loss: 3.9295300653772296

Epoch: 31| Step: 0
Training loss: 3.8832235137953703
Validation loss: 3.923791961477956

Epoch: 5| Step: 1
Training loss: 4.388546706325855
Validation loss: 3.918905478987263

Epoch: 5| Step: 2
Training loss: 3.7394916803007563
Validation loss: 3.913854602360917

Epoch: 5| Step: 3
Training loss: 4.277982035352627
Validation loss: 3.9086438943555337

Epoch: 5| Step: 4
Training loss: 3.8413274310445233
Validation loss: 3.9039611264938836

Epoch: 5| Step: 5
Training loss: 3.050341077400454
Validation loss: 3.8990665150027293

Epoch: 5| Step: 6
Training loss: 4.094401300468403
Validation loss: 3.89403024892613

Epoch: 5| Step: 7
Training loss: 4.490062336988102
Validation loss: 3.889169714453559

Epoch: 5| Step: 8
Training loss: 3.9765730522330522
Validation loss: 3.8845756769450936

Epoch: 5| Step: 9
Training loss: 4.5001824659865575
Validation loss: 3.8782196154286446

Epoch: 5| Step: 10
Training loss: 3.9264199719441044
Validation loss: 3.872875518265592

Epoch: 5| Step: 11
Training loss: 3.9330713707495404
Validation loss: 3.8679778964276683

Epoch: 32| Step: 0
Training loss: 3.7941460240907996
Validation loss: 3.8629669226151035

Epoch: 5| Step: 1
Training loss: 4.0858406361755755
Validation loss: 3.8581615862236096

Epoch: 5| Step: 2
Training loss: 4.0661255137692915
Validation loss: 3.8533025013345736

Epoch: 5| Step: 3
Training loss: 4.172574216846571
Validation loss: 3.8478723765441956

Epoch: 5| Step: 4
Training loss: 2.948092092589572
Validation loss: 3.843053268720226

Epoch: 5| Step: 5
Training loss: 4.06130541330694
Validation loss: 3.837687956010378

Epoch: 5| Step: 6
Training loss: 3.605443357169519
Validation loss: 3.83298991399583

Epoch: 5| Step: 7
Training loss: 4.049797740642402
Validation loss: 3.8280442728885866

Epoch: 5| Step: 8
Training loss: 3.9691024984175374
Validation loss: 3.8227618997759647

Epoch: 5| Step: 9
Training loss: 4.2918685322417405
Validation loss: 3.818106401133524

Epoch: 5| Step: 10
Training loss: 4.3809070491025
Validation loss: 3.812878454424934

Epoch: 5| Step: 11
Training loss: 4.31429419304656
Validation loss: 3.8075146781569997

Epoch: 33| Step: 0
Training loss: 4.172777856862813
Validation loss: 3.802407946729512

Epoch: 5| Step: 1
Training loss: 3.869330781349096
Validation loss: 3.7971588258924514

Epoch: 5| Step: 2
Training loss: 3.506288736982778
Validation loss: 3.792728787082139

Epoch: 5| Step: 3
Training loss: 3.898946296958
Validation loss: 3.7872507883090765

Epoch: 5| Step: 4
Training loss: 4.2253892437104845
Validation loss: 3.7817496082652617

Epoch: 5| Step: 5
Training loss: 4.117309800128522
Validation loss: 3.776557380274021

Epoch: 5| Step: 6
Training loss: 4.267657009067844
Validation loss: 3.7713939011223543

Epoch: 5| Step: 7
Training loss: 3.7870723571069864
Validation loss: 3.7660976498447294

Epoch: 5| Step: 8
Training loss: 3.9247981268606527
Validation loss: 3.760913193522063

Epoch: 5| Step: 9
Training loss: 3.541549650764903
Validation loss: 3.7560435498078943

Epoch: 5| Step: 10
Training loss: 3.863187690427392
Validation loss: 3.751278463296127

Epoch: 5| Step: 11
Training loss: 2.590442064772417
Validation loss: 3.7464463986497294

Epoch: 34| Step: 0
Training loss: 3.9547339018801475
Validation loss: 3.7418171348279494

Epoch: 5| Step: 1
Training loss: 3.684253621387119
Validation loss: 3.7371964483416873

Epoch: 5| Step: 2
Training loss: 3.7060157019935644
Validation loss: 3.7323826325844007

Epoch: 5| Step: 3
Training loss: 3.5679026010160246
Validation loss: 3.7279846921761344

Epoch: 5| Step: 4
Training loss: 4.663756598532085
Validation loss: 3.7231335062165996

Epoch: 5| Step: 5
Training loss: 4.133531706161781
Validation loss: 3.7187204333072965

Epoch: 5| Step: 6
Training loss: 3.6931750061399153
Validation loss: 3.7140356522658173

Epoch: 5| Step: 7
Training loss: 3.9150318765134227
Validation loss: 3.709086709521631

Epoch: 5| Step: 8
Training loss: 3.346920328697041
Validation loss: 3.70502769102078

Epoch: 5| Step: 9
Training loss: 3.98146687011272
Validation loss: 3.699670148443031

Epoch: 5| Step: 10
Training loss: 3.6385384666733858
Validation loss: 3.6949703550117405

Epoch: 5| Step: 11
Training loss: 3.5685635546401384
Validation loss: 3.6899777778655887

Epoch: 35| Step: 0
Training loss: 4.273447542335664
Validation loss: 3.685747322759635

Epoch: 5| Step: 1
Training loss: 3.6044486639288453
Validation loss: 3.680603199576456

Epoch: 5| Step: 2
Training loss: 3.8228243505711617
Validation loss: 3.675779104147706

Epoch: 5| Step: 3
Training loss: 3.548420976661634
Validation loss: 3.6707934795616444

Epoch: 5| Step: 4
Training loss: 3.70363423511912
Validation loss: 3.6665472350754724

Epoch: 5| Step: 5
Training loss: 3.69345529997555
Validation loss: 3.661407148384185

Epoch: 5| Step: 6
Training loss: 4.481321351828009
Validation loss: 3.656994904064035

Epoch: 5| Step: 7
Training loss: 3.7137996517985097
Validation loss: 3.6524064437734864

Epoch: 5| Step: 8
Training loss: 3.6702630583322495
Validation loss: 3.6471138567311647

Epoch: 5| Step: 9
Training loss: 3.9948579400577784
Validation loss: 3.642408575317032

Epoch: 5| Step: 10
Training loss: 3.3991269168710176
Validation loss: 3.6380509757793638

Epoch: 5| Step: 11
Training loss: 2.2568830537190143
Validation loss: 3.633300239881822

Epoch: 36| Step: 0
Training loss: 3.2602772708299566
Validation loss: 3.6294550321625576

Epoch: 5| Step: 1
Training loss: 4.33993296698912
Validation loss: 3.62502796885783

Epoch: 5| Step: 2
Training loss: 3.919669089460745
Validation loss: 3.6208993200443063

Epoch: 5| Step: 3
Training loss: 2.4822445737848784
Validation loss: 3.6166035707451734

Epoch: 5| Step: 4
Training loss: 4.0761302293332555
Validation loss: 3.612875101443344

Epoch: 5| Step: 5
Training loss: 3.423957643817352
Validation loss: 3.6087356815862295

Epoch: 5| Step: 6
Training loss: 3.7879142358450615
Validation loss: 3.605209346764852

Epoch: 5| Step: 7
Training loss: 4.11920082044684
Validation loss: 3.600835488202587

Epoch: 5| Step: 8
Training loss: 3.8026062209562634
Validation loss: 3.5970735357592916

Epoch: 5| Step: 9
Training loss: 3.3820052736535624
Validation loss: 3.5922926007006537

Epoch: 5| Step: 10
Training loss: 4.142132178893711
Validation loss: 3.5877961305687265

Epoch: 5| Step: 11
Training loss: 4.04067341243716
Validation loss: 3.5837969239818284

Epoch: 37| Step: 0
Training loss: 4.076319737076196
Validation loss: 3.578625151259337

Epoch: 5| Step: 1
Training loss: 3.7509975378139777
Validation loss: 3.574305582294588

Epoch: 5| Step: 2
Training loss: 3.328788010727227
Validation loss: 3.5698020731575126

Epoch: 5| Step: 3
Training loss: 3.8837958151893144
Validation loss: 3.5652915936902314

Epoch: 5| Step: 4
Training loss: 3.7441078944758086
Validation loss: 3.5605922018804597

Epoch: 5| Step: 5
Training loss: 4.127308286376958
Validation loss: 3.556254210019874

Epoch: 5| Step: 6
Training loss: 3.1382686448550374
Validation loss: 3.55147454236356

Epoch: 5| Step: 7
Training loss: 3.3067238307698084
Validation loss: 3.5469562560421304

Epoch: 5| Step: 8
Training loss: 3.5620732637439247
Validation loss: 3.5431083418976654

Epoch: 5| Step: 9
Training loss: 4.286579907509808
Validation loss: 3.539001565370755

Epoch: 5| Step: 10
Training loss: 3.359736081612057
Validation loss: 3.5345815286238644

Epoch: 5| Step: 11
Training loss: 2.9410419618478922
Validation loss: 3.5291699216182852

Epoch: 38| Step: 0
Training loss: 3.6746195174497265
Validation loss: 3.524811239351488

Epoch: 5| Step: 1
Training loss: 4.1493636137422145
Validation loss: 3.519852906155638

Epoch: 5| Step: 2
Training loss: 4.408041515438693
Validation loss: 3.515037227522106

Epoch: 5| Step: 3
Training loss: 3.633878161909872
Validation loss: 3.5102531251629228

Epoch: 5| Step: 4
Training loss: 3.7074205939753213
Validation loss: 3.5060461194696577

Epoch: 5| Step: 5
Training loss: 3.3181150816860616
Validation loss: 3.501743047242216

Epoch: 5| Step: 6
Training loss: 2.7748949116921633
Validation loss: 3.4973880126744494

Epoch: 5| Step: 7
Training loss: 4.192122910976302
Validation loss: 3.4932519768172607

Epoch: 5| Step: 8
Training loss: 3.0557528538054317
Validation loss: 3.4890043072446586

Epoch: 5| Step: 9
Training loss: 3.6848296502126696
Validation loss: 3.4843119685426323

Epoch: 5| Step: 10
Training loss: 3.0706159524223327
Validation loss: 3.479849837761178

Epoch: 5| Step: 11
Training loss: 3.8024680304453047
Validation loss: 3.4758923516894833

Epoch: 39| Step: 0
Training loss: 3.3418772078578685
Validation loss: 3.471656354994774

Epoch: 5| Step: 1
Training loss: 3.6528941346666524
Validation loss: 3.4672572443650305

Epoch: 5| Step: 2
Training loss: 3.511907213901406
Validation loss: 3.462724848445979

Epoch: 5| Step: 3
Training loss: 3.6214095125102608
Validation loss: 3.4588505270112164

Epoch: 5| Step: 4
Training loss: 3.367899879100044
Validation loss: 3.4545900910538045

Epoch: 5| Step: 5
Training loss: 3.724727666743738
Validation loss: 3.4501798103762384

Epoch: 5| Step: 6
Training loss: 3.992939439642473
Validation loss: 3.4458832156358232

Epoch: 5| Step: 7
Training loss: 3.9595767962569615
Validation loss: 3.4417225075010216

Epoch: 5| Step: 8
Training loss: 3.509037611004524
Validation loss: 3.4370625622169837

Epoch: 5| Step: 9
Training loss: 3.200644970507333
Validation loss: 3.4326370694492225

Epoch: 5| Step: 10
Training loss: 3.4892180446148977
Validation loss: 3.4286212002172927

Epoch: 5| Step: 11
Training loss: 3.708538235493361
Validation loss: 3.42440614610379

Epoch: 40| Step: 0
Training loss: 3.2259358312441195
Validation loss: 3.42017612641401

Epoch: 5| Step: 1
Training loss: 4.376446076233399
Validation loss: 3.4159608534472756

Epoch: 5| Step: 2
Training loss: 3.42281631691019
Validation loss: 3.4116786778854635

Epoch: 5| Step: 3
Training loss: 4.362332779704431
Validation loss: 3.4074912361579006

Epoch: 5| Step: 4
Training loss: 3.332434930530999
Validation loss: 3.4032713526702745

Epoch: 5| Step: 5
Training loss: 3.7530586484559496
Validation loss: 3.3990945962723975

Epoch: 5| Step: 6
Training loss: 3.53340569248122
Validation loss: 3.394875916080063

Epoch: 5| Step: 7
Training loss: 3.301816879416573
Validation loss: 3.390130330696518

Epoch: 5| Step: 8
Training loss: 2.9554503635658413
Validation loss: 3.3859770775608866

Epoch: 5| Step: 9
Training loss: 2.9382923761961974
Validation loss: 3.3817724283812804

Epoch: 5| Step: 10
Training loss: 3.356842079718518
Validation loss: 3.377572456785521

Epoch: 5| Step: 11
Training loss: 3.7995204422164006
Validation loss: 3.3737549840158416

Epoch: 41| Step: 0
Training loss: 3.2168560196350118
Validation loss: 3.3699457093081318

Epoch: 5| Step: 1
Training loss: 3.6173615053314627
Validation loss: 3.365736717417222

Epoch: 5| Step: 2
Training loss: 3.806157448932192
Validation loss: 3.362185185524975

Epoch: 5| Step: 3
Training loss: 2.8949809477974724
Validation loss: 3.3578807257621324

Epoch: 5| Step: 4
Training loss: 3.6508193154680137
Validation loss: 3.354014260914768

Epoch: 5| Step: 5
Training loss: 3.643171606729376
Validation loss: 3.35003451808777

Epoch: 5| Step: 6
Training loss: 3.0940983123448222
Validation loss: 3.3463702497083445

Epoch: 5| Step: 7
Training loss: 4.085012648526691
Validation loss: 3.342537680969653

Epoch: 5| Step: 8
Training loss: 3.6044842501097922
Validation loss: 3.338681512166138

Epoch: 5| Step: 9
Training loss: 3.068167288903151
Validation loss: 3.3347203299621935

Epoch: 5| Step: 10
Training loss: 3.5106945135410497
Validation loss: 3.3305293846710597

Epoch: 5| Step: 11
Training loss: 3.5417402970383134
Validation loss: 3.326582740828425

Epoch: 42| Step: 0
Training loss: 3.662125911420998
Validation loss: 3.3225979946162187

Epoch: 5| Step: 1
Training loss: 3.876641325819965
Validation loss: 3.3186632136643306

Epoch: 5| Step: 2
Training loss: 3.0575134786088842
Validation loss: 3.3149701151548427

Epoch: 5| Step: 3
Training loss: 3.6615585523250194
Validation loss: 3.3110387806135844

Epoch: 5| Step: 4
Training loss: 3.3749522453037843
Validation loss: 3.3071423514394307

Epoch: 5| Step: 5
Training loss: 3.4181026759476247
Validation loss: 3.303649571008847

Epoch: 5| Step: 6
Training loss: 3.1589002907266526
Validation loss: 3.2999620974897543

Epoch: 5| Step: 7
Training loss: 3.53057152635864
Validation loss: 3.2961658992798912

Epoch: 5| Step: 8
Training loss: 2.4575487813832746
Validation loss: 3.292437563733591

Epoch: 5| Step: 9
Training loss: 3.478654347844486
Validation loss: 3.288920386620176

Epoch: 5| Step: 10
Training loss: 3.9525602035232286
Validation loss: 3.285365451436939

Epoch: 5| Step: 11
Training loss: 3.4072401375034103
Validation loss: 3.2815475571151733

Epoch: 43| Step: 0
Training loss: 3.340294879984985
Validation loss: 3.277622112566724

Epoch: 5| Step: 1
Training loss: 2.8190385049150364
Validation loss: 3.273833834281264

Epoch: 5| Step: 2
Training loss: 3.782560641552101
Validation loss: 3.270500996384077

Epoch: 5| Step: 3
Training loss: 3.489420842425252
Validation loss: 3.2662709219440464

Epoch: 5| Step: 4
Training loss: 3.850083506285428
Validation loss: 3.2627008661281676

Epoch: 5| Step: 5
Training loss: 3.7684272691192544
Validation loss: 3.2586701146313453

Epoch: 5| Step: 6
Training loss: 3.0164942303967037
Validation loss: 3.254715774908999

Epoch: 5| Step: 7
Training loss: 3.5551674319728392
Validation loss: 3.2515165018680383

Epoch: 5| Step: 8
Training loss: 3.4060794892636634
Validation loss: 3.247285369405532

Epoch: 5| Step: 9
Training loss: 3.2414370484083053
Validation loss: 3.244581235100562

Epoch: 5| Step: 10
Training loss: 3.0626491588157982
Validation loss: 3.2415425896291317

Epoch: 5| Step: 11
Training loss: 2.9265507296087714
Validation loss: 3.236232936505218

Epoch: 44| Step: 0
Training loss: 3.4424790822088247
Validation loss: 3.23296585038876

Epoch: 5| Step: 1
Training loss: 3.71066919260308
Validation loss: 3.2299330765795577

Epoch: 5| Step: 2
Training loss: 3.0108728470168447
Validation loss: 3.226150335506415

Epoch: 5| Step: 3
Training loss: 3.249969482278593
Validation loss: 3.2230350526068814

Epoch: 5| Step: 4
Training loss: 3.6198076353018203
Validation loss: 3.219682583071276

Epoch: 5| Step: 5
Training loss: 2.927195880576939
Validation loss: 3.2159062078785516

Epoch: 5| Step: 6
Training loss: 3.076444370371299
Validation loss: 3.212839424938935

Epoch: 5| Step: 7
Training loss: 3.362572004830662
Validation loss: 3.2097076077754183

Epoch: 5| Step: 8
Training loss: 3.394840134240247
Validation loss: 3.2064088255352337

Epoch: 5| Step: 9
Training loss: 3.479731728966849
Validation loss: 3.203025261171261

Epoch: 5| Step: 10
Training loss: 3.7222807976081915
Validation loss: 3.20005230413845

Epoch: 5| Step: 11
Training loss: 2.3180906401942107
Validation loss: 3.1963928404721615

Epoch: 45| Step: 0
Training loss: 3.196873066921153
Validation loss: 3.1938913506907034

Epoch: 5| Step: 1
Training loss: 4.104706291443234
Validation loss: 3.1897278710391066

Epoch: 5| Step: 2
Training loss: 3.4421362389528114
Validation loss: 3.1861989975233573

Epoch: 5| Step: 3
Training loss: 3.6031691800772814
Validation loss: 3.182558286811849

Epoch: 5| Step: 4
Training loss: 3.338887895473587
Validation loss: 3.1794554792101555

Epoch: 5| Step: 5
Training loss: 3.1882523789392088
Validation loss: 3.17541664473587

Epoch: 5| Step: 6
Training loss: 3.2474509292900753
Validation loss: 3.1721485752832526

Epoch: 5| Step: 7
Training loss: 3.6112042700333675
Validation loss: 3.1687374319144563

Epoch: 5| Step: 8
Training loss: 3.3102472670473033
Validation loss: 3.1652901924625962

Epoch: 5| Step: 9
Training loss: 2.4652714426260727
Validation loss: 3.1616090909320103

Epoch: 5| Step: 10
Training loss: 2.955225606138846
Validation loss: 3.158470156674314

Epoch: 5| Step: 11
Training loss: 2.0886967729033725
Validation loss: 3.1555225648231873

Epoch: 46| Step: 0
Training loss: 2.8644860453413066
Validation loss: 3.1524158077205713

Epoch: 5| Step: 1
Training loss: 3.6613949824026206
Validation loss: 3.149653689708925

Epoch: 5| Step: 2
Training loss: 2.9218306104582683
Validation loss: 3.1463765892101683

Epoch: 5| Step: 3
Training loss: 2.9530097091210328
Validation loss: 3.1435576991224523

Epoch: 5| Step: 4
Training loss: 3.2336719873055113
Validation loss: 3.140509519462489

Epoch: 5| Step: 5
Training loss: 3.494075119914212
Validation loss: 3.1378068885313617

Epoch: 5| Step: 6
Training loss: 3.415255619608234
Validation loss: 3.1346046097423077

Epoch: 5| Step: 7
Training loss: 3.2177518018999494
Validation loss: 3.1315375545644963

Epoch: 5| Step: 8
Training loss: 3.889365854229565
Validation loss: 3.128091700551638

Epoch: 5| Step: 9
Training loss: 3.2430565829732623
Validation loss: 3.125547071890383

Epoch: 5| Step: 10
Training loss: 3.1791643841803188
Validation loss: 3.1224580758036478

Epoch: 5| Step: 11
Training loss: 2.385268349735569
Validation loss: 3.118129804506447

Epoch: 47| Step: 0
Training loss: 3.681060858694156
Validation loss: 3.116191440363083

Epoch: 5| Step: 1
Training loss: 3.2329332759637177
Validation loss: 3.114300451328707

Epoch: 5| Step: 2
Training loss: 3.759725294020698
Validation loss: 3.119383975834978

Epoch: 5| Step: 3
Training loss: 3.2785493908737195
Validation loss: 3.109934387496182

Epoch: 5| Step: 4
Training loss: 3.47365518798142
Validation loss: 3.1067633851253293

Epoch: 5| Step: 5
Training loss: 2.8925342749672565
Validation loss: 3.1056699131843617

Epoch: 5| Step: 6
Training loss: 3.227564473708589
Validation loss: 3.104734648301892

Epoch: 5| Step: 7
Training loss: 2.6299353933195144
Validation loss: 3.102702311718698

Epoch: 5| Step: 8
Training loss: 3.284571682950746
Validation loss: 3.099443341082703

Epoch: 5| Step: 9
Training loss: 3.268335559020062
Validation loss: 3.0942232848844373

Epoch: 5| Step: 10
Training loss: 2.6633342743236548
Validation loss: 3.0904624052770298

Epoch: 5| Step: 11
Training loss: 3.8606592427742648
Validation loss: 3.08778367972278

Epoch: 48| Step: 0
Training loss: 3.457718361712084
Validation loss: 3.083142053410165

Epoch: 5| Step: 1
Training loss: 3.166197256800297
Validation loss: 3.0797324654883336

Epoch: 5| Step: 2
Training loss: 2.907039084010037
Validation loss: 3.076081044304267

Epoch: 5| Step: 3
Training loss: 3.1501059075368767
Validation loss: 3.072631904640746

Epoch: 5| Step: 4
Training loss: 2.870787810549265
Validation loss: 3.069506810467146

Epoch: 5| Step: 5
Training loss: 3.4126065639303724
Validation loss: 3.0663387736612866

Epoch: 5| Step: 6
Training loss: 3.07229526939568
Validation loss: 3.063733640663675

Epoch: 5| Step: 7
Training loss: 2.9963480656203276
Validation loss: 3.060186095843295

Epoch: 5| Step: 8
Training loss: 3.3971856979717647
Validation loss: 3.057273784543997

Epoch: 5| Step: 9
Training loss: 3.0334936274280326
Validation loss: 3.053571967287157

Epoch: 5| Step: 10
Training loss: 3.550865449316258
Validation loss: 3.0508159418938035

Epoch: 5| Step: 11
Training loss: 3.999449453613189
Validation loss: 3.047157189758945

Epoch: 49| Step: 0
Training loss: 2.9400381931756505
Validation loss: 3.0437485328686447

Epoch: 5| Step: 1
Training loss: 3.2242591894195853
Validation loss: 3.0407503764122943

Epoch: 5| Step: 2
Training loss: 3.5687722654700296
Validation loss: 3.0373401942555196

Epoch: 5| Step: 3
Training loss: 3.23732221549742
Validation loss: 3.034269241731927

Epoch: 5| Step: 4
Training loss: 3.333659839533754
Validation loss: 3.0312091162634767

Epoch: 5| Step: 5
Training loss: 3.373519855464017
Validation loss: 3.027477263100903

Epoch: 5| Step: 6
Training loss: 3.069343083828779
Validation loss: 3.0246397613111795

Epoch: 5| Step: 7
Training loss: 3.340307727731441
Validation loss: 3.0220071331750384

Epoch: 5| Step: 8
Training loss: 2.5687048618035555
Validation loss: 3.0185793897543016

Epoch: 5| Step: 9
Training loss: 3.354909084128593
Validation loss: 3.0162392288860937

Epoch: 5| Step: 10
Training loss: 2.806523988937593
Validation loss: 3.013153644734995

Epoch: 5| Step: 11
Training loss: 2.8431620566451503
Validation loss: 3.0103040011925617

Epoch: 50| Step: 0
Training loss: 3.3754903649028902
Validation loss: 3.0077146968380974

Epoch: 5| Step: 1
Training loss: 3.5110897396204455
Validation loss: 3.0047980920491546

Epoch: 5| Step: 2
Training loss: 3.0361942200387766
Validation loss: 3.002455554117579

Epoch: 5| Step: 3
Training loss: 2.8805220273881877
Validation loss: 2.9997615454531834

Epoch: 5| Step: 4
Training loss: 3.044703565678676
Validation loss: 2.9969414345302683

Epoch: 5| Step: 5
Training loss: 3.3391072492943437
Validation loss: 2.9944527918058963

Epoch: 5| Step: 6
Training loss: 3.2511477277803853
Validation loss: 2.9916551015058315

Epoch: 5| Step: 7
Training loss: 3.285430134753914
Validation loss: 2.9888168320415596

Epoch: 5| Step: 8
Training loss: 3.09150182553601
Validation loss: 2.9861208617374015

Epoch: 5| Step: 9
Training loss: 2.524712113691191
Validation loss: 2.9825593474922036

Epoch: 5| Step: 10
Training loss: 3.0905038777098546
Validation loss: 2.980322724677764

Epoch: 5| Step: 11
Training loss: 2.90796061389177
Validation loss: 2.977293003316785

Epoch: 51| Step: 0
Training loss: 3.053647852222535
Validation loss: 2.9760485394783136

Epoch: 5| Step: 1
Training loss: 2.966325593122586
Validation loss: 2.972386224674469

Epoch: 5| Step: 2
Training loss: 3.257051008406578
Validation loss: 2.9695294745578025

Epoch: 5| Step: 3
Training loss: 3.0317693835601633
Validation loss: 2.9675396543379855

Epoch: 5| Step: 4
Training loss: 2.7388145808967637
Validation loss: 2.965406516052714

Epoch: 5| Step: 5
Training loss: 3.3872931498192624
Validation loss: 2.963327277171623

Epoch: 5| Step: 6
Training loss: 3.4157255473785724
Validation loss: 2.9614293705645154

Epoch: 5| Step: 7
Training loss: 2.7834363766020505
Validation loss: 2.9588893090347805

Epoch: 5| Step: 8
Training loss: 2.916081524236531
Validation loss: 2.956809401326402

Epoch: 5| Step: 9
Training loss: 2.8900220087394723
Validation loss: 2.954731563089608

Epoch: 5| Step: 10
Training loss: 3.602016196977545
Validation loss: 2.9523707373540513

Epoch: 5| Step: 11
Training loss: 3.0378170648561524
Validation loss: 2.94959511955318

Epoch: 52| Step: 0
Training loss: 3.1968421911978018
Validation loss: 2.9469290899960496

Epoch: 5| Step: 1
Training loss: 3.1097916367085876
Validation loss: 2.944774598804332

Epoch: 5| Step: 2
Training loss: 3.412712755662441
Validation loss: 2.9416072282018306

Epoch: 5| Step: 3
Training loss: 2.3713174679840034
Validation loss: 2.938821170842364

Epoch: 5| Step: 4
Training loss: 2.7406601524056002
Validation loss: 2.936014872031047

Epoch: 5| Step: 5
Training loss: 3.3678793495115307
Validation loss: 2.933464304797921

Epoch: 5| Step: 6
Training loss: 2.8850200026957507
Validation loss: 2.930630022813307

Epoch: 5| Step: 7
Training loss: 3.3857961275718402
Validation loss: 2.928460171792605

Epoch: 5| Step: 8
Training loss: 2.9917444443930434
Validation loss: 2.925636532391411

Epoch: 5| Step: 9
Training loss: 2.7976136324442638
Validation loss: 2.9236850334017954

Epoch: 5| Step: 10
Training loss: 3.2979545091460816
Validation loss: 2.921653586173566

Epoch: 5| Step: 11
Training loss: 3.5694456154062317
Validation loss: 2.9184196699113625

Epoch: 53| Step: 0
Training loss: 3.5676899633375534
Validation loss: 2.9155085489636976

Epoch: 5| Step: 1
Training loss: 2.220949291854392
Validation loss: 2.913234296416748

Epoch: 5| Step: 2
Training loss: 3.0199997552025297
Validation loss: 2.910957895078825

Epoch: 5| Step: 3
Training loss: 2.7217351376045467
Validation loss: 2.908597958220427

Epoch: 5| Step: 4
Training loss: 3.331849499091267
Validation loss: 2.907391751155648

Epoch: 5| Step: 5
Training loss: 3.6138842930049018
Validation loss: 2.9049912225335692

Epoch: 5| Step: 6
Training loss: 3.1391674094473094
Validation loss: 2.902657106442567

Epoch: 5| Step: 7
Training loss: 2.344538644984276
Validation loss: 2.899950809719279

Epoch: 5| Step: 8
Training loss: 3.3490874570610942
Validation loss: 2.896773238385403

Epoch: 5| Step: 9
Training loss: 3.152412271995748
Validation loss: 2.894101140528722

Epoch: 5| Step: 10
Training loss: 2.717836686994204
Validation loss: 2.890695608840345

Epoch: 5| Step: 11
Training loss: 2.9600756354591957
Validation loss: 2.888660880534941

Epoch: 54| Step: 0
Training loss: 3.158376147567982
Validation loss: 2.8855796944642864

Epoch: 5| Step: 1
Training loss: 3.1532769127839515
Validation loss: 2.8836898295752085

Epoch: 5| Step: 2
Training loss: 3.008172348096846
Validation loss: 2.882138267316364

Epoch: 5| Step: 3
Training loss: 3.245097497495185
Validation loss: 2.8786103274646906

Epoch: 5| Step: 4
Training loss: 3.410133597701827
Validation loss: 2.877418060958931

Epoch: 5| Step: 5
Training loss: 2.750103515063914
Validation loss: 2.8755514334775705

Epoch: 5| Step: 6
Training loss: 3.1883163902628837
Validation loss: 2.872942889985776

Epoch: 5| Step: 7
Training loss: 2.907227546607156
Validation loss: 2.8706631188298366

Epoch: 5| Step: 8
Training loss: 2.8415262099947984
Validation loss: 2.8683679768186012

Epoch: 5| Step: 9
Training loss: 2.891176243363664
Validation loss: 2.866312532720172

Epoch: 5| Step: 10
Training loss: 2.772807304887345
Validation loss: 2.863504176462781

Epoch: 5| Step: 11
Training loss: 1.7300829317358153
Validation loss: 2.861557747542303

Epoch: 55| Step: 0
Training loss: 3.061396497318494
Validation loss: 2.861658459582934

Epoch: 5| Step: 1
Training loss: 2.9258337283552946
Validation loss: 2.8611368855351405

Epoch: 5| Step: 2
Training loss: 2.5253859989746394
Validation loss: 2.8638106407950445

Epoch: 5| Step: 3
Training loss: 3.0949898749510965
Validation loss: 2.8624946724676894

Epoch: 5| Step: 4
Training loss: 3.498469426774818
Validation loss: 2.856993557301744

Epoch: 5| Step: 5
Training loss: 3.0133606310539145
Validation loss: 2.8503516043059323

Epoch: 5| Step: 6
Training loss: 2.8082439857404244
Validation loss: 2.8491961062073448

Epoch: 5| Step: 7
Training loss: 2.9970361055701047
Validation loss: 2.8487997946600485

Epoch: 5| Step: 8
Training loss: 2.6509492829319634
Validation loss: 2.8477334115415354

Epoch: 5| Step: 9
Training loss: 3.211901740389483
Validation loss: 2.847282053672875

Epoch: 5| Step: 10
Training loss: 3.130196180441692
Validation loss: 2.8449392207591697

Epoch: 5| Step: 11
Training loss: 2.6322508985539796
Validation loss: 2.843831850627584

Epoch: 56| Step: 0
Training loss: 3.0686574265449145
Validation loss: 2.8431419274388143

Epoch: 5| Step: 1
Training loss: 2.504169230108065
Validation loss: 2.840742323228796

Epoch: 5| Step: 2
Training loss: 3.2299228562156856
Validation loss: 2.8366151740880174

Epoch: 5| Step: 3
Training loss: 2.769372158027556
Validation loss: 2.834226601868055

Epoch: 5| Step: 4
Training loss: 3.1249284354598594
Validation loss: 2.8318919671545992

Epoch: 5| Step: 5
Training loss: 2.9655001872321023
Validation loss: 2.829724198652288

Epoch: 5| Step: 6
Training loss: 3.151294708600594
Validation loss: 2.827179141144174

Epoch: 5| Step: 7
Training loss: 2.6762374154961592
Validation loss: 2.826151596660928

Epoch: 5| Step: 8
Training loss: 2.399237980667699
Validation loss: 2.8237104613626403

Epoch: 5| Step: 9
Training loss: 3.5069992380089716
Validation loss: 2.820904820131306

Epoch: 5| Step: 10
Training loss: 3.2071961373282827
Validation loss: 2.819568053220536

Epoch: 5| Step: 11
Training loss: 2.450587132226287
Validation loss: 2.816079941327873

Epoch: 57| Step: 0
Training loss: 2.5867214339970217
Validation loss: 2.817325884565086

Epoch: 5| Step: 1
Training loss: 3.1710018966991536
Validation loss: 2.8139946498171553

Epoch: 5| Step: 2
Training loss: 3.3497542903236934
Validation loss: 2.8140622215405005

Epoch: 5| Step: 3
Training loss: 3.016256948084443
Validation loss: 2.8150962820069134

Epoch: 5| Step: 4
Training loss: 3.0595735853696984
Validation loss: 2.8104935058446783

Epoch: 5| Step: 5
Training loss: 2.7448645237633675
Validation loss: 2.8047894607188075

Epoch: 5| Step: 6
Training loss: 2.4423105747014118
Validation loss: 2.802744760172851

Epoch: 5| Step: 7
Training loss: 2.6085737448693824
Validation loss: 2.8023073692998266

Epoch: 5| Step: 8
Training loss: 3.570444183926172
Validation loss: 2.8016624039983085

Epoch: 5| Step: 9
Training loss: 2.9848506208962857
Validation loss: 2.800198908109951

Epoch: 5| Step: 10
Training loss: 2.8598767450089637
Validation loss: 2.8001180987202305

Epoch: 5| Step: 11
Training loss: 2.1242849605521217
Validation loss: 2.797261820492561

Epoch: 58| Step: 0
Training loss: 2.742883925292978
Validation loss: 2.7971745726624375

Epoch: 5| Step: 1
Training loss: 2.568741338487859
Validation loss: 2.7965473945736306

Epoch: 5| Step: 2
Training loss: 3.142380105389163
Validation loss: 2.794863202865168

Epoch: 5| Step: 3
Training loss: 2.8242707518120524
Validation loss: 2.792314718714322

Epoch: 5| Step: 4
Training loss: 2.7923802749527273
Validation loss: 2.7904340753462726

Epoch: 5| Step: 5
Training loss: 3.1274105692883505
Validation loss: 2.7890458769886153

Epoch: 5| Step: 6
Training loss: 2.7468296329366972
Validation loss: 2.786188723393913

Epoch: 5| Step: 7
Training loss: 3.059631561338341
Validation loss: 2.7840697571098985

Epoch: 5| Step: 8
Training loss: 3.038883939464319
Validation loss: 2.7822480821831688

Epoch: 5| Step: 9
Training loss: 2.9957135094743568
Validation loss: 2.7800360219723403

Epoch: 5| Step: 10
Training loss: 3.282845245590194
Validation loss: 2.777742023767734

Epoch: 5| Step: 11
Training loss: 1.9355506319534994
Validation loss: 2.7762095285494652

Epoch: 59| Step: 0
Training loss: 3.0628102982249157
Validation loss: 2.7734059470804078

Epoch: 5| Step: 1
Training loss: 2.894451186582491
Validation loss: 2.771440981918839

Epoch: 5| Step: 2
Training loss: 3.0251095901688814
Validation loss: 2.769437493305247

Epoch: 5| Step: 3
Training loss: 2.758890692265222
Validation loss: 2.7675684047286886

Epoch: 5| Step: 4
Training loss: 2.64293159100162
Validation loss: 2.765409288776352

Epoch: 5| Step: 5
Training loss: 2.531822422435578
Validation loss: 2.768449623226909

Epoch: 5| Step: 6
Training loss: 2.7359062049247953
Validation loss: 2.7669111411439475

Epoch: 5| Step: 7
Training loss: 3.2016677146590857
Validation loss: 2.76993533810681

Epoch: 5| Step: 8
Training loss: 3.3160308158096066
Validation loss: 2.764008730431325

Epoch: 5| Step: 9
Training loss: 2.7650534691219395
Validation loss: 2.7586250621020056

Epoch: 5| Step: 10
Training loss: 2.911755996437216
Validation loss: 2.7553675857315207

Epoch: 5| Step: 11
Training loss: 3.1770878692761335
Validation loss: 2.755913362395546

Epoch: 60| Step: 0
Training loss: 3.1430798705557694
Validation loss: 2.7542439824061913

Epoch: 5| Step: 1
Training loss: 3.6092431510854497
Validation loss: 2.753806734203387

Epoch: 5| Step: 2
Training loss: 3.304434692236163
Validation loss: 2.75214128503034

Epoch: 5| Step: 3
Training loss: 2.3630921847797413
Validation loss: 2.7506047869824255

Epoch: 5| Step: 4
Training loss: 2.705277396343712
Validation loss: 2.7485585589239045

Epoch: 5| Step: 5
Training loss: 2.652454222231082
Validation loss: 2.748257110007922

Epoch: 5| Step: 6
Training loss: 2.3091931799315604
Validation loss: 2.746773539330402

Epoch: 5| Step: 7
Training loss: 2.4378049610785677
Validation loss: 2.745179372739272

Epoch: 5| Step: 8
Training loss: 2.693120535038779
Validation loss: 2.7438216090723935

Epoch: 5| Step: 9
Training loss: 3.0344231111619404
Validation loss: 2.7417923442438825

Epoch: 5| Step: 10
Training loss: 3.2388541493662073
Validation loss: 2.740116471219033

Epoch: 5| Step: 11
Training loss: 2.77450772979644
Validation loss: 2.738083749306706

Epoch: 61| Step: 0
Training loss: 2.9508286686188625
Validation loss: 2.7367856180782906

Epoch: 5| Step: 1
Training loss: 3.146887006992439
Validation loss: 2.7351580343319637

Epoch: 5| Step: 2
Training loss: 2.593372271506145
Validation loss: 2.735813783222737

Epoch: 5| Step: 3
Training loss: 2.5794227801612317
Validation loss: 2.7334324511044583

Epoch: 5| Step: 4
Training loss: 2.913232925599391
Validation loss: 2.732390966415555

Epoch: 5| Step: 5
Training loss: 3.315267162805859
Validation loss: 2.729605909968562

Epoch: 5| Step: 6
Training loss: 3.0314052581352913
Validation loss: 2.7288651093502394

Epoch: 5| Step: 7
Training loss: 2.812877290638744
Validation loss: 2.7276933978984967

Epoch: 5| Step: 8
Training loss: 2.7510680812119825
Validation loss: 2.7248745222979207

Epoch: 5| Step: 9
Training loss: 2.689541241124129
Validation loss: 2.7231660289940707

Epoch: 5| Step: 10
Training loss: 2.768165757513769
Validation loss: 2.7217509672487252

Epoch: 5| Step: 11
Training loss: 2.6152633653989703
Validation loss: 2.7219935577126213

Epoch: 62| Step: 0
Training loss: 2.203798880897776
Validation loss: 2.7189342429043037

Epoch: 5| Step: 1
Training loss: 3.1454368661472856
Validation loss: 2.717152381890856

Epoch: 5| Step: 2
Training loss: 2.830875976648574
Validation loss: 2.717109163108196

Epoch: 5| Step: 3
Training loss: 2.8191708607933275
Validation loss: 2.714947010153099

Epoch: 5| Step: 4
Training loss: 3.3308403865487253
Validation loss: 2.713389691998482

Epoch: 5| Step: 5
Training loss: 3.196076318156676
Validation loss: 2.7120545950350734

Epoch: 5| Step: 6
Training loss: 2.766091603718567
Validation loss: 2.710549476110289

Epoch: 5| Step: 7
Training loss: 2.7929971760190244
Validation loss: 2.7096517703827523

Epoch: 5| Step: 8
Training loss: 2.764901017940347
Validation loss: 2.706891271395043

Epoch: 5| Step: 9
Training loss: 2.636831866063226
Validation loss: 2.705707525485559

Epoch: 5| Step: 10
Training loss: 2.7323883687187966
Validation loss: 2.704429230974594

Epoch: 5| Step: 11
Training loss: 2.899007489281909
Validation loss: 2.701708516222923

Epoch: 63| Step: 0
Training loss: 3.1779708539851805
Validation loss: 2.7010799345421272

Epoch: 5| Step: 1
Training loss: 2.886119403486564
Validation loss: 2.700273954362633

Epoch: 5| Step: 2
Training loss: 2.8925713662037005
Validation loss: 2.7024966301545605

Epoch: 5| Step: 3
Training loss: 2.8140835013021603
Validation loss: 2.698232773386911

Epoch: 5| Step: 4
Training loss: 2.979393601388482
Validation loss: 2.699171997931471

Epoch: 5| Step: 5
Training loss: 3.0146430595999973
Validation loss: 2.696501299242098

Epoch: 5| Step: 6
Training loss: 2.576474117801246
Validation loss: 2.6939902761943952

Epoch: 5| Step: 7
Training loss: 2.5184836878684704
Validation loss: 2.6913655374416234

Epoch: 5| Step: 8
Training loss: 3.002993520663014
Validation loss: 2.6912735240526526

Epoch: 5| Step: 9
Training loss: 2.914737572087021
Validation loss: 2.6892923987183774

Epoch: 5| Step: 10
Training loss: 2.487581786531618
Validation loss: 2.68516377993769

Epoch: 5| Step: 11
Training loss: 2.1641616523145015
Validation loss: 2.685096634547179

Epoch: 64| Step: 0
Training loss: 2.488296484788281
Validation loss: 2.6838448456515316

Epoch: 5| Step: 1
Training loss: 2.558407655893433
Validation loss: 2.6811180855905845

Epoch: 5| Step: 2
Training loss: 2.592126820999744
Validation loss: 2.6830440552393457

Epoch: 5| Step: 3
Training loss: 2.9802373993802975
Validation loss: 2.6839625231525512

Epoch: 5| Step: 4
Training loss: 3.049317305406693
Validation loss: 2.6855204854882397

Epoch: 5| Step: 5
Training loss: 2.6368846699821487
Validation loss: 2.6839229265245566

Epoch: 5| Step: 6
Training loss: 2.569800885424542
Validation loss: 2.6827920514858405

Epoch: 5| Step: 7
Training loss: 3.2749672458554118
Validation loss: 2.6768609089361375

Epoch: 5| Step: 8
Training loss: 3.1152721821275575
Validation loss: 2.6716744271409794

Epoch: 5| Step: 9
Training loss: 2.876277142346502
Validation loss: 2.671364183283785

Epoch: 5| Step: 10
Training loss: 2.8084468033805114
Validation loss: 2.6707456890272447

Epoch: 5| Step: 11
Training loss: 2.5433349345724214
Validation loss: 2.6706643587201806

Epoch: 65| Step: 0
Training loss: 2.586581792405748
Validation loss: 2.6700933773878566

Epoch: 5| Step: 1
Training loss: 2.5995012428499376
Validation loss: 2.672044250451896

Epoch: 5| Step: 2
Training loss: 2.786082666094898
Validation loss: 2.6728048584155824

Epoch: 5| Step: 3
Training loss: 3.2401853699108445
Validation loss: 2.6783187009779246

Epoch: 5| Step: 4
Training loss: 2.594302382880762
Validation loss: 2.6743361977483375

Epoch: 5| Step: 5
Training loss: 2.2624483134230147
Validation loss: 2.6686210449295222

Epoch: 5| Step: 6
Training loss: 2.874557958703699
Validation loss: 2.669219264330918

Epoch: 5| Step: 7
Training loss: 3.3583840971360743
Validation loss: 2.6681458399073374

Epoch: 5| Step: 8
Training loss: 2.9256265800551673
Validation loss: 2.6656647093760415

Epoch: 5| Step: 9
Training loss: 2.4894586529229676
Validation loss: 2.6652480290802227

Epoch: 5| Step: 10
Training loss: 3.079251775395584
Validation loss: 2.6629712208668113

Epoch: 5| Step: 11
Training loss: 2.3677419888048012
Validation loss: 2.6623020079100663

Epoch: 66| Step: 0
Training loss: 3.192550547415457
Validation loss: 2.6604516551067716

Epoch: 5| Step: 1
Training loss: 3.092275865553803
Validation loss: 2.65716802777214

Epoch: 5| Step: 2
Training loss: 2.6839713062850405
Validation loss: 2.6556118853155346

Epoch: 5| Step: 3
Training loss: 2.9663260753728697
Validation loss: 2.6543549415986796

Epoch: 5| Step: 4
Training loss: 2.6361737175400775
Validation loss: 2.6531369236355036

Epoch: 5| Step: 5
Training loss: 2.969926460460257
Validation loss: 2.651543303109046

Epoch: 5| Step: 6
Training loss: 2.5190898656500336
Validation loss: 2.6514005524261264

Epoch: 5| Step: 7
Training loss: 2.790361972557813
Validation loss: 2.648568580556909

Epoch: 5| Step: 8
Training loss: 2.67862584739991
Validation loss: 2.646460809168698

Epoch: 5| Step: 9
Training loss: 2.1176868708458483
Validation loss: 2.645544950032818

Epoch: 5| Step: 10
Training loss: 2.7379060452811133
Validation loss: 2.6440559422112178

Epoch: 5| Step: 11
Training loss: 3.41338070973161
Validation loss: 2.6433598841523924

Epoch: 67| Step: 0
Training loss: 2.6851827700617465
Validation loss: 2.6443958069353832

Epoch: 5| Step: 1
Training loss: 2.6608450245762176
Validation loss: 2.6497821188971953

Epoch: 5| Step: 2
Training loss: 3.017234570349917
Validation loss: 2.6600071085211057

Epoch: 5| Step: 3
Training loss: 2.70020979313477
Validation loss: 2.669757792396484

Epoch: 5| Step: 4
Training loss: 2.9177744441978986
Validation loss: 2.670441129356836

Epoch: 5| Step: 5
Training loss: 2.862824407460517
Validation loss: 2.6537336135935727

Epoch: 5| Step: 6
Training loss: 2.690072181612448
Validation loss: 2.6505334937903364

Epoch: 5| Step: 7
Training loss: 2.4823401412894417
Validation loss: 2.6394738090050573

Epoch: 5| Step: 8
Training loss: 2.779498802672017
Validation loss: 2.636318125488924

Epoch: 5| Step: 9
Training loss: 3.199687620651581
Validation loss: 2.637160200675433

Epoch: 5| Step: 10
Training loss: 2.7609478901191027
Validation loss: 2.6405376103855263

Epoch: 5| Step: 11
Training loss: 1.9089269758618252
Validation loss: 2.643229977211413

Epoch: 68| Step: 0
Training loss: 3.1569654201562773
Validation loss: 2.654537479142516

Epoch: 5| Step: 1
Training loss: 2.9768397885421964
Validation loss: 2.66075961327948

Epoch: 5| Step: 2
Training loss: 2.7662304576488594
Validation loss: 2.6626740470377865

Epoch: 5| Step: 3
Training loss: 2.2234504232882184
Validation loss: 2.6513466924972335

Epoch: 5| Step: 4
Training loss: 2.969877490718344
Validation loss: 2.6433647020790914

Epoch: 5| Step: 5
Training loss: 2.9381445319640846
Validation loss: 2.639301894031591

Epoch: 5| Step: 6
Training loss: 2.693122659727803
Validation loss: 2.640345188040412

Epoch: 5| Step: 7
Training loss: 2.536782799450543
Validation loss: 2.6375098353318553

Epoch: 5| Step: 8
Training loss: 2.6333625739522337
Validation loss: 2.6338697550058803

Epoch: 5| Step: 9
Training loss: 3.1172031029332246
Validation loss: 2.629179446727888

Epoch: 5| Step: 10
Training loss: 2.6169143761988005
Validation loss: 2.6275852355174245

Epoch: 5| Step: 11
Training loss: 1.8515125380587805
Validation loss: 2.6253803636088997

Epoch: 69| Step: 0
Training loss: 2.6106331356214976
Validation loss: 2.6243506604833184

Epoch: 5| Step: 1
Training loss: 2.964253443478282
Validation loss: 2.620977892828406

Epoch: 5| Step: 2
Training loss: 2.969337967320723
Validation loss: 2.624552268491251

Epoch: 5| Step: 3
Training loss: 2.9276552195979066
Validation loss: 2.6234025484460126

Epoch: 5| Step: 4
Training loss: 2.5327315527602146
Validation loss: 2.6214354131790483

Epoch: 5| Step: 5
Training loss: 2.801092282187011
Validation loss: 2.6192903487734567

Epoch: 5| Step: 6
Training loss: 2.57916969171777
Validation loss: 2.619571078640772

Epoch: 5| Step: 7
Training loss: 2.6901730395963734
Validation loss: 2.6153608371811994

Epoch: 5| Step: 8
Training loss: 2.569565684806036
Validation loss: 2.6157741127367204

Epoch: 5| Step: 9
Training loss: 2.860026801190477
Validation loss: 2.613487064485009

Epoch: 5| Step: 10
Training loss: 2.727828903996726
Validation loss: 2.611612700556181

Epoch: 5| Step: 11
Training loss: 3.2435758628482483
Validation loss: 2.611063846595488

Epoch: 70| Step: 0
Training loss: 2.531970451399513
Validation loss: 2.6106649130571644

Epoch: 5| Step: 1
Training loss: 2.6759010009699886
Validation loss: 2.6102029320687894

Epoch: 5| Step: 2
Training loss: 2.799934631674531
Validation loss: 2.6102490017854953

Epoch: 5| Step: 3
Training loss: 2.1488082288449584
Validation loss: 2.6099704664515477

Epoch: 5| Step: 4
Training loss: 2.9750812679699004
Validation loss: 2.6119863345858243

Epoch: 5| Step: 5
Training loss: 3.049185322004828
Validation loss: 2.6074951580669525

Epoch: 5| Step: 6
Training loss: 2.6733496093571634
Validation loss: 2.6048052704137614

Epoch: 5| Step: 7
Training loss: 3.021767482797572
Validation loss: 2.6028717076539776

Epoch: 5| Step: 8
Training loss: 2.650089345181605
Validation loss: 2.6042157562715325

Epoch: 5| Step: 9
Training loss: 2.5545335075792637
Validation loss: 2.6011884303935497

Epoch: 5| Step: 10
Training loss: 2.874248572296189
Validation loss: 2.6008394437455555

Epoch: 5| Step: 11
Training loss: 3.2195263268984595
Validation loss: 2.601730837640481

Epoch: 71| Step: 0
Training loss: 2.859687162775906
Validation loss: 2.5985891019998153

Epoch: 5| Step: 1
Training loss: 2.868522645006832
Validation loss: 2.6012426490930354

Epoch: 5| Step: 2
Training loss: 2.7018540762824195
Validation loss: 2.601407310889952

Epoch: 5| Step: 3
Training loss: 2.6748384694323004
Validation loss: 2.603359560189238

Epoch: 5| Step: 4
Training loss: 2.7475341665627098
Validation loss: 2.604919665507979

Epoch: 5| Step: 5
Training loss: 2.529801224902524
Validation loss: 2.60756315879612

Epoch: 5| Step: 6
Training loss: 2.9099638804917496
Validation loss: 2.6129001440276975

Epoch: 5| Step: 7
Training loss: 2.5898295728660794
Validation loss: 2.6153870723894066

Epoch: 5| Step: 8
Training loss: 2.786770346217092
Validation loss: 2.618532353372305

Epoch: 5| Step: 9
Training loss: 2.8225249597005027
Validation loss: 2.6116098895308846

Epoch: 5| Step: 10
Training loss: 2.7338596403290385
Validation loss: 2.606127212034829

Epoch: 5| Step: 11
Training loss: 2.7783712855056053
Validation loss: 2.601766018930557

Epoch: 72| Step: 0
Training loss: 2.58820854105612
Validation loss: 2.598552604659816

Epoch: 5| Step: 1
Training loss: 2.6971880150967857
Validation loss: 2.5949558802316592

Epoch: 5| Step: 2
Training loss: 2.691437874706481
Validation loss: 2.592025880870317

Epoch: 5| Step: 3
Training loss: 2.7731993667022983
Validation loss: 2.5894045104882553

Epoch: 5| Step: 4
Training loss: 2.740473284811962
Validation loss: 2.587895039488668

Epoch: 5| Step: 5
Training loss: 2.559659826058998
Validation loss: 2.5865424141114146

Epoch: 5| Step: 6
Training loss: 3.0476553675638782
Validation loss: 2.5847752197788565

Epoch: 5| Step: 7
Training loss: 2.5761814999346355
Validation loss: 2.5853579160750515

Epoch: 5| Step: 8
Training loss: 2.763703104119052
Validation loss: 2.5829764217014866

Epoch: 5| Step: 9
Training loss: 2.610292376222954
Validation loss: 2.5801690793327268

Epoch: 5| Step: 10
Training loss: 2.6768429619802183
Validation loss: 2.5776727877043957

Epoch: 5| Step: 11
Training loss: 3.751422230911583
Validation loss: 2.5762228798028772

Epoch: 73| Step: 0
Training loss: 2.3963717532878857
Validation loss: 2.5780753005660824

Epoch: 5| Step: 1
Training loss: 2.511171367319913
Validation loss: 2.5806232177871116

Epoch: 5| Step: 2
Training loss: 2.753169487410812
Validation loss: 2.5797228629948012

Epoch: 5| Step: 3
Training loss: 2.96011043059064
Validation loss: 2.5828422276977863

Epoch: 5| Step: 4
Training loss: 2.6209101832958352
Validation loss: 2.583735005366433

Epoch: 5| Step: 5
Training loss: 2.7935614537187337
Validation loss: 2.58373082215196

Epoch: 5| Step: 6
Training loss: 2.5530296802820134
Validation loss: 2.5834879687901338

Epoch: 5| Step: 7
Training loss: 3.1737931187973314
Validation loss: 2.582934342356832

Epoch: 5| Step: 8
Training loss: 2.541218848462054
Validation loss: 2.5821681637997753

Epoch: 5| Step: 9
Training loss: 2.8132135969447667
Validation loss: 2.581855506321651

Epoch: 5| Step: 10
Training loss: 2.9181298718275954
Validation loss: 2.579700943903913

Epoch: 5| Step: 11
Training loss: 1.3928455668446946
Validation loss: 2.5781515755873117

Epoch: 74| Step: 0
Training loss: 2.850322464217762
Validation loss: 2.5768775850613514

Epoch: 5| Step: 1
Training loss: 2.7934367608046884
Validation loss: 2.57620211475778

Epoch: 5| Step: 2
Training loss: 2.8064777749107717
Validation loss: 2.576331653513315

Epoch: 5| Step: 3
Training loss: 2.2904799307439627
Validation loss: 2.5740625877267664

Epoch: 5| Step: 4
Training loss: 2.560120943610017
Validation loss: 2.5721629592230904

Epoch: 5| Step: 5
Training loss: 2.949362158920165
Validation loss: 2.5703372471013246

Epoch: 5| Step: 6
Training loss: 2.487444055589492
Validation loss: 2.5689574692315067

Epoch: 5| Step: 7
Training loss: 2.7189613347841615
Validation loss: 2.5660124795520534

Epoch: 5| Step: 8
Training loss: 2.861663069666307
Validation loss: 2.5630943221654885

Epoch: 5| Step: 9
Training loss: 2.6866953332695274
Validation loss: 2.5623391806528026

Epoch: 5| Step: 10
Training loss: 2.6088650142245897
Validation loss: 2.5572872369006623

Epoch: 5| Step: 11
Training loss: 2.9734779054479303
Validation loss: 2.5591766159433957

Epoch: 75| Step: 0
Training loss: 3.253340691443497
Validation loss: 2.565926122244122

Epoch: 5| Step: 1
Training loss: 3.05778373817792
Validation loss: 2.566235850661053

Epoch: 5| Step: 2
Training loss: 2.3699756481030176
Validation loss: 2.565834492669417

Epoch: 5| Step: 3
Training loss: 2.675234729058425
Validation loss: 2.5625005311112514

Epoch: 5| Step: 4
Training loss: 2.2527914744801025
Validation loss: 2.554371684985168

Epoch: 5| Step: 5
Training loss: 2.6973895487123176
Validation loss: 2.553698866592578

Epoch: 5| Step: 6
Training loss: 2.874003859727746
Validation loss: 2.558710133475392

Epoch: 5| Step: 7
Training loss: 2.5420602795936786
Validation loss: 2.5546441847369272

Epoch: 5| Step: 8
Training loss: 2.7299585043020675
Validation loss: 2.5571377948118226

Epoch: 5| Step: 9
Training loss: 2.6704759113630225
Validation loss: 2.5553307379666204

Epoch: 5| Step: 10
Training loss: 2.493018224136206
Validation loss: 2.553710369550108

Epoch: 5| Step: 11
Training loss: 2.032205210348545
Validation loss: 2.5535678179128185

Epoch: 76| Step: 0
Training loss: 2.6918408135766883
Validation loss: 2.555125853156842

Epoch: 5| Step: 1
Training loss: 2.9024360816613832
Validation loss: 2.5546693130452414

Epoch: 5| Step: 2
Training loss: 2.7579859173852945
Validation loss: 2.5520814519343284

Epoch: 5| Step: 3
Training loss: 3.0820971579811287
Validation loss: 2.550521541380101

Epoch: 5| Step: 4
Training loss: 2.807158420398962
Validation loss: 2.5527973629400003

Epoch: 5| Step: 5
Training loss: 2.1079379237406966
Validation loss: 2.5530544703938785

Epoch: 5| Step: 6
Training loss: 2.8210326567135198
Validation loss: 2.556933800751553

Epoch: 5| Step: 7
Training loss: 2.8589290417047657
Validation loss: 2.5540712567961124

Epoch: 5| Step: 8
Training loss: 2.542458666200089
Validation loss: 2.566047918269708

Epoch: 5| Step: 9
Training loss: 2.3903779544214614
Validation loss: 2.5577975249973557

Epoch: 5| Step: 10
Training loss: 2.6167339786043815
Validation loss: 2.5506638387439877

Epoch: 5| Step: 11
Training loss: 2.537208420110109
Validation loss: 2.546784974673859

Epoch: 77| Step: 0
Training loss: 2.806767704369042
Validation loss: 2.5507507789742982

Epoch: 5| Step: 1
Training loss: 2.6168927838085883
Validation loss: 2.5473338261863985

Epoch: 5| Step: 2
Training loss: 3.333660697756464
Validation loss: 2.5497581139699816

Epoch: 5| Step: 3
Training loss: 2.657563187860854
Validation loss: 2.550742569182732

Epoch: 5| Step: 4
Training loss: 2.8977706429946894
Validation loss: 2.553013991297012

Epoch: 5| Step: 5
Training loss: 2.4297733598361964
Validation loss: 2.554686142885118

Epoch: 5| Step: 6
Training loss: 2.40077954983364
Validation loss: 2.5546427459374192

Epoch: 5| Step: 7
Training loss: 2.5644040360876703
Validation loss: 2.5549442033964613

Epoch: 5| Step: 8
Training loss: 2.3442331451887344
Validation loss: 2.555580795694414

Epoch: 5| Step: 9
Training loss: 2.7854775862688173
Validation loss: 2.555579124188816

Epoch: 5| Step: 10
Training loss: 2.5667323075194957
Validation loss: 2.5547651693220583

Epoch: 5| Step: 11
Training loss: 2.661627498458745
Validation loss: 2.556218826707006

Epoch: 78| Step: 0
Training loss: 3.0221819969224177
Validation loss: 2.5519884533015533

Epoch: 5| Step: 1
Training loss: 2.8840289766969636
Validation loss: 2.5489067562441607

Epoch: 5| Step: 2
Training loss: 2.4347738034817716
Validation loss: 2.54621886556271

Epoch: 5| Step: 3
Training loss: 2.9052527572793387
Validation loss: 2.5442719370053157

Epoch: 5| Step: 4
Training loss: 2.621497405987114
Validation loss: 2.5400830374683614

Epoch: 5| Step: 5
Training loss: 2.5031830551139618
Validation loss: 2.5387748516199333

Epoch: 5| Step: 6
Training loss: 2.4916980226855103
Validation loss: 2.537325142409026

Epoch: 5| Step: 7
Training loss: 2.3814019702867664
Validation loss: 2.5387065735794647

Epoch: 5| Step: 8
Training loss: 2.2826030324387836
Validation loss: 2.5393583389475496

Epoch: 5| Step: 9
Training loss: 2.7211395811809758
Validation loss: 2.5321727452245875

Epoch: 5| Step: 10
Training loss: 2.8301862928992234
Validation loss: 2.537153412493252

Epoch: 5| Step: 11
Training loss: 3.4986740052807224
Validation loss: 2.5360151461162497

Epoch: 79| Step: 0
Training loss: 2.761378503367672
Validation loss: 2.5374140156426552

Epoch: 5| Step: 1
Training loss: 2.6484200356056737
Validation loss: 2.5438396956667413

Epoch: 5| Step: 2
Training loss: 2.2760110557703292
Validation loss: 2.539887576906781

Epoch: 5| Step: 3
Training loss: 2.339512159896005
Validation loss: 2.5421571974774197

Epoch: 5| Step: 4
Training loss: 2.539021653066872
Validation loss: 2.536475458942436

Epoch: 5| Step: 5
Training loss: 2.4063181681699626
Validation loss: 2.534830680831818

Epoch: 5| Step: 6
Training loss: 3.206952446028607
Validation loss: 2.5328876903872235

Epoch: 5| Step: 7
Training loss: 2.758471963938764
Validation loss: 2.531995608557478

Epoch: 5| Step: 8
Training loss: 2.8502053571633974
Validation loss: 2.5314452563042686

Epoch: 5| Step: 9
Training loss: 2.7614496469570913
Validation loss: 2.531446829941243

Epoch: 5| Step: 10
Training loss: 2.715022458568438
Validation loss: 2.5282306461241624

Epoch: 5| Step: 11
Training loss: 2.0933731650958713
Validation loss: 2.532907406446503

Epoch: 80| Step: 0
Training loss: 2.572311875978219
Validation loss: 2.529621067160493

Epoch: 5| Step: 1
Training loss: 2.4425501226555353
Validation loss: 2.529712166684586

Epoch: 5| Step: 2
Training loss: 2.888358552459074
Validation loss: 2.531796851564298

Epoch: 5| Step: 3
Training loss: 2.3866042688762334
Validation loss: 2.5258052059807015

Epoch: 5| Step: 4
Training loss: 2.1113021524333337
Validation loss: 2.5278927355664145

Epoch: 5| Step: 5
Training loss: 2.289837702701201
Validation loss: 2.5288989722495114

Epoch: 5| Step: 6
Training loss: 2.816028077532852
Validation loss: 2.529039764100988

Epoch: 5| Step: 7
Training loss: 2.62252472930391
Validation loss: 2.527655065938317

Epoch: 5| Step: 8
Training loss: 2.9335888736851947
Validation loss: 2.5283800228332596

Epoch: 5| Step: 9
Training loss: 3.1744040943726928
Validation loss: 2.526749023554315

Epoch: 5| Step: 10
Training loss: 2.786735012305367
Validation loss: 2.524861743811813

Epoch: 5| Step: 11
Training loss: 2.7492456268445045
Validation loss: 2.5257225320057404

Epoch: 81| Step: 0
Training loss: 2.8917837758677725
Validation loss: 2.5230874526422635

Epoch: 5| Step: 1
Training loss: 2.9331267247986452
Validation loss: 2.526454238365061

Epoch: 5| Step: 2
Training loss: 2.6526112484770312
Validation loss: 2.525381892189923

Epoch: 5| Step: 3
Training loss: 2.8047362936976907
Validation loss: 2.5260647146740025

Epoch: 5| Step: 4
Training loss: 2.591194640551375
Validation loss: 2.523040905662051

Epoch: 5| Step: 5
Training loss: 2.3700230300363816
Validation loss: 2.52349092881651

Epoch: 5| Step: 6
Training loss: 2.138332280758098
Validation loss: 2.524383957939754

Epoch: 5| Step: 7
Training loss: 2.5457751936030695
Validation loss: 2.5223815330484913

Epoch: 5| Step: 8
Training loss: 2.2890797897571225
Validation loss: 2.5182716276631893

Epoch: 5| Step: 9
Training loss: 2.8810334957973414
Validation loss: 2.5208525157755584

Epoch: 5| Step: 10
Training loss: 2.83955761754871
Validation loss: 2.5206051413184714

Epoch: 5| Step: 11
Training loss: 3.043983848408621
Validation loss: 2.518642866255772

Epoch: 82| Step: 0
Training loss: 2.9859017665926673
Validation loss: 2.523361905661425

Epoch: 5| Step: 1
Training loss: 2.1355391180394037
Validation loss: 2.522169150680112

Epoch: 5| Step: 2
Training loss: 2.700541502022194
Validation loss: 2.525208280018

Epoch: 5| Step: 3
Training loss: 2.6055943860556607
Validation loss: 2.526042565938783

Epoch: 5| Step: 4
Training loss: 2.6574738319809614
Validation loss: 2.533246722565569

Epoch: 5| Step: 5
Training loss: 2.5690477036278687
Validation loss: 2.532137909325595

Epoch: 5| Step: 6
Training loss: 2.354277504081272
Validation loss: 2.5350206375097124

Epoch: 5| Step: 7
Training loss: 2.9722739737056654
Validation loss: 2.5253431724344413

Epoch: 5| Step: 8
Training loss: 2.612673747294569
Validation loss: 2.520115690436105

Epoch: 5| Step: 9
Training loss: 2.848707802942487
Validation loss: 2.5180558174901386

Epoch: 5| Step: 10
Training loss: 2.7763138590496963
Validation loss: 2.518968910725326

Epoch: 5| Step: 11
Training loss: 1.9822234256429017
Validation loss: 2.5162972643879673

Epoch: 83| Step: 0
Training loss: 2.696691541741708
Validation loss: 2.5176779660871573

Epoch: 5| Step: 1
Training loss: 2.643700789045446
Validation loss: 2.5189042407785953

Epoch: 5| Step: 2
Training loss: 2.556758496136927
Validation loss: 2.5226903937313048

Epoch: 5| Step: 3
Training loss: 2.3663993505388032
Validation loss: 2.5249581139933404

Epoch: 5| Step: 4
Training loss: 2.7788130123872135
Validation loss: 2.5257030233848674

Epoch: 5| Step: 5
Training loss: 2.775353771719386
Validation loss: 2.5287722795944054

Epoch: 5| Step: 6
Training loss: 2.949326105248054
Validation loss: 2.5281205474726285

Epoch: 5| Step: 7
Training loss: 2.334209708983993
Validation loss: 2.5271934649335477

Epoch: 5| Step: 8
Training loss: 2.6479950931999174
Validation loss: 2.526692121204733

Epoch: 5| Step: 9
Training loss: 2.6184357811958234
Validation loss: 2.5265697805488103

Epoch: 5| Step: 10
Training loss: 2.760304910568813
Validation loss: 2.5252218167913534

Epoch: 5| Step: 11
Training loss: 2.8180699612912696
Validation loss: 2.520614068029439

Epoch: 84| Step: 0
Training loss: 2.6798665957199646
Validation loss: 2.5214100971308016

Epoch: 5| Step: 1
Training loss: 2.954814931944716
Validation loss: 2.5165630076599053

Epoch: 5| Step: 2
Training loss: 2.5426582111657465
Validation loss: 2.5168232601175458

Epoch: 5| Step: 3
Training loss: 2.6041401874467596
Validation loss: 2.5152859903636

Epoch: 5| Step: 4
Training loss: 3.185685782149252
Validation loss: 2.515782499417883

Epoch: 5| Step: 5
Training loss: 2.5166850255671287
Validation loss: 2.513365241977231

Epoch: 5| Step: 6
Training loss: 2.6844299879204128
Validation loss: 2.513100627100137

Epoch: 5| Step: 7
Training loss: 2.3218477352795452
Validation loss: 2.509899526702724

Epoch: 5| Step: 8
Training loss: 2.3624914946226383
Validation loss: 2.5085284873752003

Epoch: 5| Step: 9
Training loss: 2.5811743995365277
Validation loss: 2.505792297274229

Epoch: 5| Step: 10
Training loss: 2.5703479335394817
Validation loss: 2.5105821797640737

Epoch: 5| Step: 11
Training loss: 2.6049333791579152
Validation loss: 2.5099281941169673

Epoch: 85| Step: 0
Training loss: 2.673601451597613
Validation loss: 2.5076497382628262

Epoch: 5| Step: 1
Training loss: 2.452145131730647
Validation loss: 2.510262489860683

Epoch: 5| Step: 2
Training loss: 2.6405703747759284
Validation loss: 2.5121542403269523

Epoch: 5| Step: 3
Training loss: 2.7623211798465186
Validation loss: 2.509253530543353

Epoch: 5| Step: 4
Training loss: 2.580852291327828
Validation loss: 2.506470207123028

Epoch: 5| Step: 5
Training loss: 2.9051726610672888
Validation loss: 2.5062647447287096

Epoch: 5| Step: 6
Training loss: 2.984623284522302
Validation loss: 2.512129651636691

Epoch: 5| Step: 7
Training loss: 2.627191083262897
Validation loss: 2.5085064451758217

Epoch: 5| Step: 8
Training loss: 2.563270453023683
Validation loss: 2.507468872453939

Epoch: 5| Step: 9
Training loss: 2.3262744691966977
Validation loss: 2.508833810920225

Epoch: 5| Step: 10
Training loss: 2.443367181242526
Validation loss: 2.5100482865611835

Epoch: 5| Step: 11
Training loss: 2.578301810935152
Validation loss: 2.505755193640307

Epoch: 86| Step: 0
Training loss: 1.9222992219490842
Validation loss: 2.506198014776925

Epoch: 5| Step: 1
Training loss: 2.5514580615897393
Validation loss: 2.50642795707841

Epoch: 5| Step: 2
Training loss: 2.974735370054047
Validation loss: 2.5035930007133196

Epoch: 5| Step: 3
Training loss: 2.5405061813666694
Validation loss: 2.5026740753433883

Epoch: 5| Step: 4
Training loss: 2.518519093268252
Validation loss: 2.5079788121170594

Epoch: 5| Step: 5
Training loss: 3.1473604920657885
Validation loss: 2.505077645481067

Epoch: 5| Step: 6
Training loss: 3.0311869191950405
Validation loss: 2.504491875414529

Epoch: 5| Step: 7
Training loss: 2.646825969651773
Validation loss: 2.5045064761179043

Epoch: 5| Step: 8
Training loss: 2.3451822609418085
Validation loss: 2.5032527425858846

Epoch: 5| Step: 9
Training loss: 2.665027164084606
Validation loss: 2.5066987294719225

Epoch: 5| Step: 10
Training loss: 2.3462454163430855
Validation loss: 2.5019324423664444

Epoch: 5| Step: 11
Training loss: 2.36520675529652
Validation loss: 2.5013036348946063

Epoch: 87| Step: 0
Training loss: 2.8326137601359154
Validation loss: 2.5024913970171867

Epoch: 5| Step: 1
Training loss: 2.7601584163757686
Validation loss: 2.5037492533247963

Epoch: 5| Step: 2
Training loss: 2.1787790025366345
Validation loss: 2.5000596992994057

Epoch: 5| Step: 3
Training loss: 2.9381404746629354
Validation loss: 2.5047991901639968

Epoch: 5| Step: 4
Training loss: 2.6065803227022815
Validation loss: 2.501225973570226

Epoch: 5| Step: 5
Training loss: 2.544651020008274
Validation loss: 2.5029339978214082

Epoch: 5| Step: 6
Training loss: 2.3059555444658897
Validation loss: 2.50154524175126

Epoch: 5| Step: 7
Training loss: 2.658489136230817
Validation loss: 2.50264435629011

Epoch: 5| Step: 8
Training loss: 2.767368435235079
Validation loss: 2.5029421342274083

Epoch: 5| Step: 9
Training loss: 2.5865859402844227
Validation loss: 2.5004509161563657

Epoch: 5| Step: 10
Training loss: 2.51335942387214
Validation loss: 2.5010746315135854

Epoch: 5| Step: 11
Training loss: 2.9614812910219026
Validation loss: 2.4988222328153538

Epoch: 88| Step: 0
Training loss: 2.55976712642901
Validation loss: 2.4969685294689246

Epoch: 5| Step: 1
Training loss: 2.4354780565219736
Validation loss: 2.4990843725334493

Epoch: 5| Step: 2
Training loss: 3.1947585094328725
Validation loss: 2.503744400832006

Epoch: 5| Step: 3
Training loss: 2.6306761272135923
Validation loss: 2.5047055345926337

Epoch: 5| Step: 4
Training loss: 2.764407908420348
Validation loss: 2.50142845034505

Epoch: 5| Step: 5
Training loss: 2.142639548743522
Validation loss: 2.504049914955357

Epoch: 5| Step: 6
Training loss: 1.7097527569501625
Validation loss: 2.5079588802790593

Epoch: 5| Step: 7
Training loss: 2.4184603337758848
Validation loss: 2.496938336698593

Epoch: 5| Step: 8
Training loss: 2.991095042186323
Validation loss: 2.4969126830999313

Epoch: 5| Step: 9
Training loss: 2.7813871542726885
Validation loss: 2.502043743016197

Epoch: 5| Step: 10
Training loss: 2.809803666284605
Validation loss: 2.5000182469019974

Epoch: 5| Step: 11
Training loss: 3.105401956091824
Validation loss: 2.4947272247932384

Epoch: 89| Step: 0
Training loss: 2.345544763662012
Validation loss: 2.497758691154761

Epoch: 5| Step: 1
Training loss: 2.3891314659368454
Validation loss: 2.4959641145842864

Epoch: 5| Step: 2
Training loss: 3.135840267998574
Validation loss: 2.4960976383216753

Epoch: 5| Step: 3
Training loss: 2.539031700534351
Validation loss: 2.5024082187839984

Epoch: 5| Step: 4
Training loss: 2.709396407978878
Validation loss: 2.5038775969565434

Epoch: 5| Step: 5
Training loss: 2.243140041569797
Validation loss: 2.510507009524171

Epoch: 5| Step: 6
Training loss: 2.411605522876312
Validation loss: 2.512744233452931

Epoch: 5| Step: 7
Training loss: 2.926549263194588
Validation loss: 2.5118153831834116

Epoch: 5| Step: 8
Training loss: 2.91119996882452
Validation loss: 2.515433689211697

Epoch: 5| Step: 9
Training loss: 2.771465277253175
Validation loss: 2.5105163797121377

Epoch: 5| Step: 10
Training loss: 2.568405232183298
Validation loss: 2.508002463144607

Epoch: 5| Step: 11
Training loss: 1.8615395905175396
Validation loss: 2.507574682159965

Epoch: 90| Step: 0
Training loss: 2.663749161804726
Validation loss: 2.5007648887365215

Epoch: 5| Step: 1
Training loss: 2.8611644711091504
Validation loss: 2.5051153103588515

Epoch: 5| Step: 2
Training loss: 3.1231113066954226
Validation loss: 2.4990118338765326

Epoch: 5| Step: 3
Training loss: 2.6055656540907006
Validation loss: 2.498352282647137

Epoch: 5| Step: 4
Training loss: 2.640875900357237
Validation loss: 2.4966652185656986

Epoch: 5| Step: 5
Training loss: 2.3249593628644236
Validation loss: 2.4951722339945723

Epoch: 5| Step: 6
Training loss: 1.9860465751365073
Validation loss: 2.4938821163252185

Epoch: 5| Step: 7
Training loss: 2.8154196102241174
Validation loss: 2.4969553388259906

Epoch: 5| Step: 8
Training loss: 2.3974671031616235
Validation loss: 2.48941719958636

Epoch: 5| Step: 9
Training loss: 2.454811828300842
Validation loss: 2.4907298912766374

Epoch: 5| Step: 10
Training loss: 2.8341347925924425
Validation loss: 2.493995238079337

Epoch: 5| Step: 11
Training loss: 1.9382727527854984
Validation loss: 2.4911865089621448

Epoch: 91| Step: 0
Training loss: 2.137233971889401
Validation loss: 2.500286638199005

Epoch: 5| Step: 1
Training loss: 2.7500034679044183
Validation loss: 2.5119313752713004

Epoch: 5| Step: 2
Training loss: 3.2750071401736633
Validation loss: 2.524792377352106

Epoch: 5| Step: 3
Training loss: 2.7376080391523354
Validation loss: 2.5211165692022015

Epoch: 5| Step: 4
Training loss: 2.8938414128738583
Validation loss: 2.508116777921309

Epoch: 5| Step: 5
Training loss: 2.7650037164645886
Validation loss: 2.4971808194127707

Epoch: 5| Step: 6
Training loss: 2.0003381681650287
Validation loss: 2.4922088135831344

Epoch: 5| Step: 7
Training loss: 2.1092309973270944
Validation loss: 2.489603774067961

Epoch: 5| Step: 8
Training loss: 2.898521237050593
Validation loss: 2.4923029905722722

Epoch: 5| Step: 9
Training loss: 3.082787714615424
Validation loss: 2.493708769059865

Epoch: 5| Step: 10
Training loss: 2.312523712861424
Validation loss: 2.493257693405162

Epoch: 5| Step: 11
Training loss: 2.0500024097707588
Validation loss: 2.492543377474915

Epoch: 92| Step: 0
Training loss: 2.5225573442668745
Validation loss: 2.4932521072861253

Epoch: 5| Step: 1
Training loss: 2.41934386855889
Validation loss: 2.493461394918419

Epoch: 5| Step: 2
Training loss: 2.6509787821228183
Validation loss: 2.49384197935498

Epoch: 5| Step: 3
Training loss: 2.8014715346946844
Validation loss: 2.494439625174897

Epoch: 5| Step: 4
Training loss: 2.4905507802973026
Validation loss: 2.487192136157334

Epoch: 5| Step: 5
Training loss: 2.4900575343153095
Validation loss: 2.491052598356328

Epoch: 5| Step: 6
Training loss: 2.6500005470131365
Validation loss: 2.4867779289168555

Epoch: 5| Step: 7
Training loss: 2.097960494441345
Validation loss: 2.4878065973020247

Epoch: 5| Step: 8
Training loss: 2.513228512946758
Validation loss: 2.4856935077255824

Epoch: 5| Step: 9
Training loss: 3.1318132514476913
Validation loss: 2.4822369938596527

Epoch: 5| Step: 10
Training loss: 2.9004151211612856
Validation loss: 2.485479001598256

Epoch: 5| Step: 11
Training loss: 2.78901394499927
Validation loss: 2.487146023783399

Epoch: 93| Step: 0
Training loss: 2.163016055939473
Validation loss: 2.48268487008884

Epoch: 5| Step: 1
Training loss: 2.8262328673176236
Validation loss: 2.4837161576068145

Epoch: 5| Step: 2
Training loss: 2.4067751819136816
Validation loss: 2.48231418475077

Epoch: 5| Step: 3
Training loss: 2.5389002351996575
Validation loss: 2.4853867763780113

Epoch: 5| Step: 4
Training loss: 3.052588012076338
Validation loss: 2.4888950750568783

Epoch: 5| Step: 5
Training loss: 2.8304893768763493
Validation loss: 2.4860841561980793

Epoch: 5| Step: 6
Training loss: 2.6274390015930504
Validation loss: 2.488615435761294

Epoch: 5| Step: 7
Training loss: 2.392790966298234
Validation loss: 2.4896640897499087

Epoch: 5| Step: 8
Training loss: 2.3305203193281256
Validation loss: 2.489971072170635

Epoch: 5| Step: 9
Training loss: 2.6940877149557036
Validation loss: 2.4912517169927972

Epoch: 5| Step: 10
Training loss: 2.800702933223375
Validation loss: 2.4888188027502887

Epoch: 5| Step: 11
Training loss: 1.896777899329161
Validation loss: 2.4906898151868213

Epoch: 94| Step: 0
Training loss: 2.4493901681004515
Validation loss: 2.492024957504331

Epoch: 5| Step: 1
Training loss: 2.717849757787984
Validation loss: 2.488873381852574

Epoch: 5| Step: 2
Training loss: 2.7665196065616433
Validation loss: 2.489946739190169

Epoch: 5| Step: 3
Training loss: 2.9461547294947885
Validation loss: 2.4855974616594763

Epoch: 5| Step: 4
Training loss: 2.60350710845264
Validation loss: 2.4879289993566522

Epoch: 5| Step: 5
Training loss: 2.2252803925848443
Validation loss: 2.4843320303025953

Epoch: 5| Step: 6
Training loss: 2.4874408925764
Validation loss: 2.484099406825095

Epoch: 5| Step: 7
Training loss: 2.1974081984994323
Validation loss: 2.4831696791349485

Epoch: 5| Step: 8
Training loss: 2.7519209828066598
Validation loss: 2.482510494848338

Epoch: 5| Step: 9
Training loss: 2.702976818102445
Validation loss: 2.4812873070424093

Epoch: 5| Step: 10
Training loss: 2.6739786355100263
Validation loss: 2.483003225617113

Epoch: 5| Step: 11
Training loss: 2.327624068676948
Validation loss: 2.484917635406582

Epoch: 95| Step: 0
Training loss: 2.5963689611709153
Validation loss: 2.4860879163234277

Epoch: 5| Step: 1
Training loss: 2.4974640381813864
Validation loss: 2.483076039902247

Epoch: 5| Step: 2
Training loss: 2.432212572356978
Validation loss: 2.47850847055351

Epoch: 5| Step: 3
Training loss: 2.8922579715001313
Validation loss: 2.4886567667331527

Epoch: 5| Step: 4
Training loss: 2.598252123415331
Validation loss: 2.4849888425099387

Epoch: 5| Step: 5
Training loss: 2.445605568188339
Validation loss: 2.483232727402404

Epoch: 5| Step: 6
Training loss: 3.0608070520992765
Validation loss: 2.48630753214205

Epoch: 5| Step: 7
Training loss: 2.622917984489209
Validation loss: 2.4841411528502952

Epoch: 5| Step: 8
Training loss: 2.4607461521901843
Validation loss: 2.481736027145618

Epoch: 5| Step: 9
Training loss: 2.4566505513208288
Validation loss: 2.4867450557319675

Epoch: 5| Step: 10
Training loss: 2.4906534956734254
Validation loss: 2.488539390408569

Epoch: 5| Step: 11
Training loss: 3.1650615104013418
Validation loss: 2.4843173550169952

Epoch: 96| Step: 0
Training loss: 2.386442427552354
Validation loss: 2.4840488059749033

Epoch: 5| Step: 1
Training loss: 2.7975011369772775
Validation loss: 2.4843273118278524

Epoch: 5| Step: 2
Training loss: 2.8629942954456604
Validation loss: 2.490072423119163

Epoch: 5| Step: 3
Training loss: 2.479288039455414
Validation loss: 2.485651923655606

Epoch: 5| Step: 4
Training loss: 2.3850262473719397
Validation loss: 2.4852930088302974

Epoch: 5| Step: 5
Training loss: 2.352912895299142
Validation loss: 2.4868288816943913

Epoch: 5| Step: 6
Training loss: 2.3683579575907023
Validation loss: 2.4826983306159143

Epoch: 5| Step: 7
Training loss: 2.952371975596503
Validation loss: 2.486847191283068

Epoch: 5| Step: 8
Training loss: 2.587923514678973
Validation loss: 2.485206033159464

Epoch: 5| Step: 9
Training loss: 2.6741856627851046
Validation loss: 2.4855837970145367

Epoch: 5| Step: 10
Training loss: 2.611065619548115
Validation loss: 2.487447546081594

Epoch: 5| Step: 11
Training loss: 2.824805740834174
Validation loss: 2.4784099615453625

Epoch: 97| Step: 0
Training loss: 2.4128385237135355
Validation loss: 2.4808841147290672

Epoch: 5| Step: 1
Training loss: 2.76622244206219
Validation loss: 2.4791723272649

Epoch: 5| Step: 2
Training loss: 2.4053960498653364
Validation loss: 2.482502081390922

Epoch: 5| Step: 3
Training loss: 2.562635650765957
Validation loss: 2.482385270443852

Epoch: 5| Step: 4
Training loss: 2.916131724392571
Validation loss: 2.4820950180633785

Epoch: 5| Step: 5
Training loss: 2.71202588838132
Validation loss: 2.4782192092055593

Epoch: 5| Step: 6
Training loss: 2.5744109248437463
Validation loss: 2.481535494448113

Epoch: 5| Step: 7
Training loss: 2.432008671004749
Validation loss: 2.482588759644608

Epoch: 5| Step: 8
Training loss: 2.8052036161178853
Validation loss: 2.4849172995946134

Epoch: 5| Step: 9
Training loss: 2.35823516596457
Validation loss: 2.481914565469778

Epoch: 5| Step: 10
Training loss: 2.586428131857177
Validation loss: 2.486399966927804

Epoch: 5| Step: 11
Training loss: 1.8925378123931609
Validation loss: 2.4767291697868017

Epoch: 98| Step: 0
Training loss: 2.4057741561639383
Validation loss: 2.4759217645813645

Epoch: 5| Step: 1
Training loss: 2.854803046867046
Validation loss: 2.4791762260979318

Epoch: 5| Step: 2
Training loss: 2.426925315679187
Validation loss: 2.4811964594575953

Epoch: 5| Step: 3
Training loss: 2.494572661044466
Validation loss: 2.474743677603082

Epoch: 5| Step: 4
Training loss: 2.4034182246854674
Validation loss: 2.4775704018617177

Epoch: 5| Step: 5
Training loss: 2.4973132955511357
Validation loss: 2.478790929247677

Epoch: 5| Step: 6
Training loss: 2.6506396115545012
Validation loss: 2.4828993975550975

Epoch: 5| Step: 7
Training loss: 2.6959531160969985
Validation loss: 2.4801229681464245

Epoch: 5| Step: 8
Training loss: 2.4692150595389433
Validation loss: 2.4805041333175453

Epoch: 5| Step: 9
Training loss: 2.802589162859513
Validation loss: 2.4816784049265266

Epoch: 5| Step: 10
Training loss: 2.704439934871567
Validation loss: 2.4798575461784647

Epoch: 5| Step: 11
Training loss: 1.948718417672115
Validation loss: 2.4830480546645135

Epoch: 99| Step: 0
Training loss: 2.9290316648741523
Validation loss: 2.479937979713557

Epoch: 5| Step: 1
Training loss: 2.4592680581870376
Validation loss: 2.477110484214789

Epoch: 5| Step: 2
Training loss: 2.707777748831438
Validation loss: 2.481534621748201

Epoch: 5| Step: 3
Training loss: 2.836950368205725
Validation loss: 2.4754168631397273

Epoch: 5| Step: 4
Training loss: 2.4786193200702855
Validation loss: 2.4772019187597767

Epoch: 5| Step: 5
Training loss: 2.361788191359663
Validation loss: 2.475826627428425

Epoch: 5| Step: 6
Training loss: 2.27388924112055
Validation loss: 2.477762940180144

Epoch: 5| Step: 7
Training loss: 2.4740460724915847
Validation loss: 2.477744757915042

Epoch: 5| Step: 8
Training loss: 2.844610230843143
Validation loss: 2.479403061108162

Epoch: 5| Step: 9
Training loss: 2.2925347042472928
Validation loss: 2.4724567768779013

Epoch: 5| Step: 10
Training loss: 2.4638164815927874
Validation loss: 2.4759622722944674

Epoch: 5| Step: 11
Training loss: 3.266149305389332
Validation loss: 2.473126473695105

Epoch: 100| Step: 0
Training loss: 2.7250720653279004
Validation loss: 2.474457300296029

Epoch: 5| Step: 1
Training loss: 2.6533576926194686
Validation loss: 2.4758298654659314

Epoch: 5| Step: 2
Training loss: 2.567596113268752
Validation loss: 2.476533654944492

Epoch: 5| Step: 3
Training loss: 2.394205142742252
Validation loss: 2.475101641773861

Epoch: 5| Step: 4
Training loss: 2.3455848124044922
Validation loss: 2.4796168549026603

Epoch: 5| Step: 5
Training loss: 2.816859702167567
Validation loss: 2.479204836052025

Epoch: 5| Step: 6
Training loss: 2.2302560253885066
Validation loss: 2.4778035220335015

Epoch: 5| Step: 7
Training loss: 2.776358256558798
Validation loss: 2.4816679291073998

Epoch: 5| Step: 8
Training loss: 2.499991035445353
Validation loss: 2.480034297031723

Epoch: 5| Step: 9
Training loss: 2.3863325290386395
Validation loss: 2.4791356587006854

Epoch: 5| Step: 10
Training loss: 3.0932569014489917
Validation loss: 2.4797799783635406

Epoch: 5| Step: 11
Training loss: 1.8711526817645672
Validation loss: 2.481232032582708

Epoch: 101| Step: 0
Training loss: 2.729384134573006
Validation loss: 2.4808818543227127

Epoch: 5| Step: 1
Training loss: 2.567648298220711
Validation loss: 2.4766420177124764

Epoch: 5| Step: 2
Training loss: 2.5154114626652175
Validation loss: 2.469107787043603

Epoch: 5| Step: 3
Training loss: 2.6667786117739674
Validation loss: 2.471401108971581

Epoch: 5| Step: 4
Training loss: 2.4350789101600085
Validation loss: 2.4710181958892146

Epoch: 5| Step: 5
Training loss: 2.382485088930172
Validation loss: 2.4710280494989063

Epoch: 5| Step: 6
Training loss: 2.6837159952142384
Validation loss: 2.4776602878165974

Epoch: 5| Step: 7
Training loss: 2.80234117042544
Validation loss: 2.4728501350839207

Epoch: 5| Step: 8
Training loss: 2.621276394297773
Validation loss: 2.477187028793971

Epoch: 5| Step: 9
Training loss: 2.728715106987411
Validation loss: 2.468523809879374

Epoch: 5| Step: 10
Training loss: 2.5148545501088377
Validation loss: 2.4743290245343763

Epoch: 5| Step: 11
Training loss: 2.0706591046095544
Validation loss: 2.4767994972854215

Epoch: 102| Step: 0
Training loss: 2.552768744986678
Validation loss: 2.4784549217716467

Epoch: 5| Step: 1
Training loss: 2.481639291506853
Validation loss: 2.480921069778434

Epoch: 5| Step: 2
Training loss: 3.0713752285707026
Validation loss: 2.481477058905155

Epoch: 5| Step: 3
Training loss: 2.143695049860608
Validation loss: 2.483352986733755

Epoch: 5| Step: 4
Training loss: 2.518874634340294
Validation loss: 2.482675234803477

Epoch: 5| Step: 5
Training loss: 2.639589908133018
Validation loss: 2.482897983197354

Epoch: 5| Step: 6
Training loss: 2.7976473802022723
Validation loss: 2.484976465764913

Epoch: 5| Step: 7
Training loss: 2.465670342747632
Validation loss: 2.488672502180619

Epoch: 5| Step: 8
Training loss: 2.3954888026979626
Validation loss: 2.4863098655283915

Epoch: 5| Step: 9
Training loss: 2.788957609880999
Validation loss: 2.4880823168638524

Epoch: 5| Step: 10
Training loss: 2.8365820790584135
Validation loss: 2.48450486425552

Epoch: 5| Step: 11
Training loss: 1.2099185717588044
Validation loss: 2.4835787282791233

Epoch: 103| Step: 0
Training loss: 2.6655598568754626
Validation loss: 2.4814332243389616

Epoch: 5| Step: 1
Training loss: 2.062101036556415
Validation loss: 2.480918467046201

Epoch: 5| Step: 2
Training loss: 2.753027376658885
Validation loss: 2.4799541550354567

Epoch: 5| Step: 3
Training loss: 2.3622318176157586
Validation loss: 2.4832287749311455

Epoch: 5| Step: 4
Training loss: 2.096423477701408
Validation loss: 2.480230949797538

Epoch: 5| Step: 5
Training loss: 2.77585567306955
Validation loss: 2.479877155072472

Epoch: 5| Step: 6
Training loss: 3.1097063817702715
Validation loss: 2.4780584805040426

Epoch: 5| Step: 7
Training loss: 3.0972539921961992
Validation loss: 2.4714732421122627

Epoch: 5| Step: 8
Training loss: 2.6015326237609777
Validation loss: 2.4733344258407106

Epoch: 5| Step: 9
Training loss: 2.6975482900290357
Validation loss: 2.470555904460269

Epoch: 5| Step: 10
Training loss: 2.284609685237151
Validation loss: 2.469774375725216

Epoch: 5| Step: 11
Training loss: 1.3456078926129378
Validation loss: 2.4675053102499915

Epoch: 104| Step: 0
Training loss: 2.08298286033168
Validation loss: 2.466702718943816

Epoch: 5| Step: 1
Training loss: 2.5859642373169294
Validation loss: 2.4661219688692215

Epoch: 5| Step: 2
Training loss: 2.7693501185920324
Validation loss: 2.470703432588219

Epoch: 5| Step: 3
Training loss: 2.366229779478995
Validation loss: 2.464454664503064

Epoch: 5| Step: 4
Training loss: 2.0970995855229053
Validation loss: 2.4673942492980507

Epoch: 5| Step: 5
Training loss: 2.675020385379301
Validation loss: 2.465274335891637

Epoch: 5| Step: 6
Training loss: 2.2368314884512537
Validation loss: 2.46290106774944

Epoch: 5| Step: 7
Training loss: 3.211596493260394
Validation loss: 2.463052315261048

Epoch: 5| Step: 8
Training loss: 3.031278472452056
Validation loss: 2.4673332019936605

Epoch: 5| Step: 9
Training loss: 2.4964618441299633
Validation loss: 2.4623198325509716

Epoch: 5| Step: 10
Training loss: 2.745340908817599
Validation loss: 2.4675109143967497

Epoch: 5| Step: 11
Training loss: 1.7521692183132576
Validation loss: 2.4639347090851476

Epoch: 105| Step: 0
Training loss: 2.7271260987948516
Validation loss: 2.465923409399762

Epoch: 5| Step: 1
Training loss: 2.316884395147085
Validation loss: 2.470435569057337

Epoch: 5| Step: 2
Training loss: 2.636690718890352
Validation loss: 2.472776188083434

Epoch: 5| Step: 3
Training loss: 2.8906819105989783
Validation loss: 2.4764144243483366

Epoch: 5| Step: 4
Training loss: 2.501705636880049
Validation loss: 2.480370066524511

Epoch: 5| Step: 5
Training loss: 2.46241129991369
Validation loss: 2.480057141052067

Epoch: 5| Step: 6
Training loss: 2.5770858057411647
Validation loss: 2.4749367248268834

Epoch: 5| Step: 7
Training loss: 2.718713255886084
Validation loss: 2.476588372417289

Epoch: 5| Step: 8
Training loss: 2.604986463573819
Validation loss: 2.475442193728049

Epoch: 5| Step: 9
Training loss: 2.2665931474692993
Validation loss: 2.4725647236947816

Epoch: 5| Step: 10
Training loss: 2.67358655932054
Validation loss: 2.474876154585033

Epoch: 5| Step: 11
Training loss: 2.671538928574167
Validation loss: 2.474216838515129

Epoch: 106| Step: 0
Training loss: 2.4778541060904566
Validation loss: 2.4701798881374426

Epoch: 5| Step: 1
Training loss: 2.3622740057174525
Validation loss: 2.473455620267759

Epoch: 5| Step: 2
Training loss: 2.3008401082772836
Validation loss: 2.470797140672289

Epoch: 5| Step: 3
Training loss: 3.1714036713485507
Validation loss: 2.4697397235978737

Epoch: 5| Step: 4
Training loss: 2.5934371759598562
Validation loss: 2.471550122053723

Epoch: 5| Step: 5
Training loss: 2.4362169459034893
Validation loss: 2.4696049678539875

Epoch: 5| Step: 6
Training loss: 2.7088535885088088
Validation loss: 2.4687601161701234

Epoch: 5| Step: 7
Training loss: 2.563540642800269
Validation loss: 2.4751207344713637

Epoch: 5| Step: 8
Training loss: 2.589592416572957
Validation loss: 2.4682687137352457

Epoch: 5| Step: 9
Training loss: 2.5514970274617683
Validation loss: 2.4719379500625416

Epoch: 5| Step: 10
Training loss: 2.3192508208065834
Validation loss: 2.468558939852069

Epoch: 5| Step: 11
Training loss: 3.2754986448906775
Validation loss: 2.4698395799365254

Epoch: 107| Step: 0
Training loss: 2.266371715746728
Validation loss: 2.4635926026985415

Epoch: 5| Step: 1
Training loss: 2.835634662022314
Validation loss: 2.4645371183370948

Epoch: 5| Step: 2
Training loss: 2.569582386151725
Validation loss: 2.4662542765754787

Epoch: 5| Step: 3
Training loss: 2.2555365789749984
Validation loss: 2.4677580075774768

Epoch: 5| Step: 4
Training loss: 3.0125025262465903
Validation loss: 2.471323840508273

Epoch: 5| Step: 5
Training loss: 2.281144335664242
Validation loss: 2.4636538737405385

Epoch: 5| Step: 6
Training loss: 2.4380040747942524
Validation loss: 2.4613377119534596

Epoch: 5| Step: 7
Training loss: 3.1812151114418707
Validation loss: 2.463983856313683

Epoch: 5| Step: 8
Training loss: 2.33440325820753
Validation loss: 2.4630746109699793

Epoch: 5| Step: 9
Training loss: 2.1005686852789904
Validation loss: 2.470128443128694

Epoch: 5| Step: 10
Training loss: 2.8513325637710505
Validation loss: 2.4631961650129583

Epoch: 5| Step: 11
Training loss: 2.011633654526085
Validation loss: 2.4715728113687088

Epoch: 108| Step: 0
Training loss: 2.792240672146906
Validation loss: 2.464205837172788

Epoch: 5| Step: 1
Training loss: 2.6759326307258466
Validation loss: 2.4666856754275064

Epoch: 5| Step: 2
Training loss: 2.353561514885856
Validation loss: 2.472040566784355

Epoch: 5| Step: 3
Training loss: 2.5121844914410376
Validation loss: 2.4691393420479564

Epoch: 5| Step: 4
Training loss: 2.2255212323305744
Validation loss: 2.467240479673349

Epoch: 5| Step: 5
Training loss: 2.5893865443549418
Validation loss: 2.469222417932213

Epoch: 5| Step: 6
Training loss: 2.4914677935009006
Validation loss: 2.4683424919135803

Epoch: 5| Step: 7
Training loss: 2.6186237095354334
Validation loss: 2.4648002947136995

Epoch: 5| Step: 8
Training loss: 2.5865732201020752
Validation loss: 2.468153237594827

Epoch: 5| Step: 9
Training loss: 2.6124868511252353
Validation loss: 2.464503325719299

Epoch: 5| Step: 10
Training loss: 2.8175478247278973
Validation loss: 2.4664995503090412

Epoch: 5| Step: 11
Training loss: 2.399010704706756
Validation loss: 2.4645662871991525

Epoch: 109| Step: 0
Training loss: 2.287647838713854
Validation loss: 2.464345965371207

Epoch: 5| Step: 1
Training loss: 2.2753198964664514
Validation loss: 2.4636611237439285

Epoch: 5| Step: 2
Training loss: 2.8205805516391322
Validation loss: 2.4648369709935296

Epoch: 5| Step: 3
Training loss: 2.29713262034469
Validation loss: 2.4624588557903184

Epoch: 5| Step: 4
Training loss: 2.4400326213844785
Validation loss: 2.4640471777865907

Epoch: 5| Step: 5
Training loss: 2.966939112836626
Validation loss: 2.461899055859916

Epoch: 5| Step: 6
Training loss: 2.6782732643207345
Validation loss: 2.4655810551661586

Epoch: 5| Step: 7
Training loss: 2.116047344565078
Validation loss: 2.463778020046873

Epoch: 5| Step: 8
Training loss: 2.465907814815017
Validation loss: 2.45894552275385

Epoch: 5| Step: 9
Training loss: 3.0831140663607317
Validation loss: 2.4610401313815915

Epoch: 5| Step: 10
Training loss: 2.613998793551364
Validation loss: 2.459413435965638

Epoch: 5| Step: 11
Training loss: 2.3834365777903805
Validation loss: 2.4578946794439447

Epoch: 110| Step: 0
Training loss: 2.416104536340198
Validation loss: 2.46273542253471

Epoch: 5| Step: 1
Training loss: 1.7703204889613842
Validation loss: 2.454258051683634

Epoch: 5| Step: 2
Training loss: 2.510774853322119
Validation loss: 2.459209768132372

Epoch: 5| Step: 3
Training loss: 2.921112613867029
Validation loss: 2.4591883664890335

Epoch: 5| Step: 4
Training loss: 2.6730253186123902
Validation loss: 2.453747036705877

Epoch: 5| Step: 5
Training loss: 2.5498626597201386
Validation loss: 2.4546373852284935

Epoch: 5| Step: 6
Training loss: 2.3431755887907304
Validation loss: 2.4591324943146864

Epoch: 5| Step: 7
Training loss: 2.630526130034575
Validation loss: 2.4609398856984033

Epoch: 5| Step: 8
Training loss: 2.8366720125870435
Validation loss: 2.4603328123400474

Epoch: 5| Step: 9
Training loss: 2.7123376929598266
Validation loss: 2.471987916719997

Epoch: 5| Step: 10
Training loss: 2.766646374394405
Validation loss: 2.468080188327995

Epoch: 5| Step: 11
Training loss: 1.9063451149146142
Validation loss: 2.4742724824849924

Epoch: 111| Step: 0
Training loss: 2.6565171051365004
Validation loss: 2.486188142945809

Epoch: 5| Step: 1
Training loss: 2.3387376211828643
Validation loss: 2.48570490975222

Epoch: 5| Step: 2
Training loss: 2.7047013113285168
Validation loss: 2.4783912749744146

Epoch: 5| Step: 3
Training loss: 2.626311655678024
Validation loss: 2.472063701675351

Epoch: 5| Step: 4
Training loss: 2.7549855383131683
Validation loss: 2.4755180996660973

Epoch: 5| Step: 5
Training loss: 2.7400564406491914
Validation loss: 2.4669704059082913

Epoch: 5| Step: 6
Training loss: 2.5787401794749556
Validation loss: 2.469291728173432

Epoch: 5| Step: 7
Training loss: 2.2713750024049952
Validation loss: 2.467035205047122

Epoch: 5| Step: 8
Training loss: 2.4287762174894447
Validation loss: 2.465135064419377

Epoch: 5| Step: 9
Training loss: 2.4107425910054956
Validation loss: 2.4679576753176855

Epoch: 5| Step: 10
Training loss: 2.6869600330215513
Validation loss: 2.4662725999444044

Epoch: 5| Step: 11
Training loss: 2.692450997447721
Validation loss: 2.464938293433303

Epoch: 112| Step: 0
Training loss: 2.418042898196707
Validation loss: 2.461766060104481

Epoch: 5| Step: 1
Training loss: 3.059227265170232
Validation loss: 2.4603450889630434

Epoch: 5| Step: 2
Training loss: 2.0450976860013523
Validation loss: 2.4587681508359944

Epoch: 5| Step: 3
Training loss: 2.7376807584264813
Validation loss: 2.46186976863928

Epoch: 5| Step: 4
Training loss: 2.312173253250209
Validation loss: 2.4602832267573786

Epoch: 5| Step: 5
Training loss: 2.0725737117087797
Validation loss: 2.4628796417128567

Epoch: 5| Step: 6
Training loss: 2.820714694692638
Validation loss: 2.4606168023307893

Epoch: 5| Step: 7
Training loss: 2.4219455831763503
Validation loss: 2.462422729060855

Epoch: 5| Step: 8
Training loss: 2.553717472804735
Validation loss: 2.4636280066191034

Epoch: 5| Step: 9
Training loss: 2.6171262819332846
Validation loss: 2.4618749134986633

Epoch: 5| Step: 10
Training loss: 2.9563118022886345
Validation loss: 2.467180668726993

Epoch: 5| Step: 11
Training loss: 2.2357615190371543
Validation loss: 2.4645706283379445

Epoch: 113| Step: 0
Training loss: 2.569085845896872
Validation loss: 2.461831684239919

Epoch: 5| Step: 1
Training loss: 2.1501237390085475
Validation loss: 2.4645797620367476

Epoch: 5| Step: 2
Training loss: 2.4714795245959102
Validation loss: 2.463908022414782

Epoch: 5| Step: 3
Training loss: 2.1512581359957683
Validation loss: 2.4556101463064754

Epoch: 5| Step: 4
Training loss: 2.710377660104637
Validation loss: 2.4621543540035606

Epoch: 5| Step: 5
Training loss: 2.877938634614528
Validation loss: 2.460178627598039

Epoch: 5| Step: 6
Training loss: 2.4519447354472033
Validation loss: 2.459028046179523

Epoch: 5| Step: 7
Training loss: 2.843700701946493
Validation loss: 2.4512836689171094

Epoch: 5| Step: 8
Training loss: 3.0147199310238104
Validation loss: 2.458231359457368

Epoch: 5| Step: 9
Training loss: 2.2860247665091604
Validation loss: 2.4517610325687436

Epoch: 5| Step: 10
Training loss: 2.567727037920088
Validation loss: 2.454480829164802

Epoch: 5| Step: 11
Training loss: 1.2708660444625288
Validation loss: 2.454540961715812

Epoch: 114| Step: 0
Training loss: 2.5742104143809463
Validation loss: 2.451950071295562

Epoch: 5| Step: 1
Training loss: 2.535381477590297
Validation loss: 2.456033209826258

Epoch: 5| Step: 2
Training loss: 2.1310453255110096
Validation loss: 2.4477679870310047

Epoch: 5| Step: 3
Training loss: 2.3514366749910405
Validation loss: 2.4518787514758933

Epoch: 5| Step: 4
Training loss: 2.7086206039272622
Validation loss: 2.46147794491035

Epoch: 5| Step: 5
Training loss: 2.5680377947441455
Validation loss: 2.452458503714281

Epoch: 5| Step: 6
Training loss: 2.3590758683511472
Validation loss: 2.4565143294141323

Epoch: 5| Step: 7
Training loss: 2.5979555344803273
Validation loss: 2.450646725919644

Epoch: 5| Step: 8
Training loss: 2.8171752218527937
Validation loss: 2.4581904059957536

Epoch: 5| Step: 9
Training loss: 2.5718293048048464
Validation loss: 2.455148299859901

Epoch: 5| Step: 10
Training loss: 2.7787421417468416
Validation loss: 2.45575372407891

Epoch: 5| Step: 11
Training loss: 2.3721322263173485
Validation loss: 2.4654873422342756

Epoch: 115| Step: 0
Training loss: 2.0058662689298523
Validation loss: 2.4596475722398106

Epoch: 5| Step: 1
Training loss: 2.451179461828398
Validation loss: 2.4607186558212915

Epoch: 5| Step: 2
Training loss: 2.3542277797992415
Validation loss: 2.4646994200383934

Epoch: 5| Step: 3
Training loss: 2.7454947066484428
Validation loss: 2.4639098206192083

Epoch: 5| Step: 4
Training loss: 2.47824222628974
Validation loss: 2.4657840013505803

Epoch: 5| Step: 5
Training loss: 2.749260542894188
Validation loss: 2.463913824240044

Epoch: 5| Step: 6
Training loss: 2.6587531468812644
Validation loss: 2.4639974835094485

Epoch: 5| Step: 7
Training loss: 2.1218689683876213
Validation loss: 2.461340000398595

Epoch: 5| Step: 8
Training loss: 3.0047338013000093
Validation loss: 2.458023962392937

Epoch: 5| Step: 9
Training loss: 2.4794042030039756
Validation loss: 2.4580610267234935

Epoch: 5| Step: 10
Training loss: 2.7894267210373807
Validation loss: 2.4545026118279565

Epoch: 5| Step: 11
Training loss: 3.3240182101121567
Validation loss: 2.451594760278113

Epoch: 116| Step: 0
Training loss: 2.7112257746471133
Validation loss: 2.454205520033041

Epoch: 5| Step: 1
Training loss: 2.46290630725826
Validation loss: 2.4564674713113193

Epoch: 5| Step: 2
Training loss: 2.5794723226915024
Validation loss: 2.4535775263317823

Epoch: 5| Step: 3
Training loss: 2.8099450268238297
Validation loss: 2.4573726245070415

Epoch: 5| Step: 4
Training loss: 2.527020912835644
Validation loss: 2.4570566609680307

Epoch: 5| Step: 5
Training loss: 2.68109787729518
Validation loss: 2.4552997174504183

Epoch: 5| Step: 6
Training loss: 2.6644641204325246
Validation loss: 2.458218035715101

Epoch: 5| Step: 7
Training loss: 2.382571248833458
Validation loss: 2.4569629160359976

Epoch: 5| Step: 8
Training loss: 1.7673473903054286
Validation loss: 2.4619404923643082

Epoch: 5| Step: 9
Training loss: 2.737784129686886
Validation loss: 2.4568586991392927

Epoch: 5| Step: 10
Training loss: 2.5346435592731176
Validation loss: 2.4548327420214306

Epoch: 5| Step: 11
Training loss: 2.7404796357354337
Validation loss: 2.4517087533350037

Epoch: 117| Step: 0
Training loss: 1.9847211761092192
Validation loss: 2.4493355284639313

Epoch: 5| Step: 1
Training loss: 2.2355591097264806
Validation loss: 2.4514714355607055

Epoch: 5| Step: 2
Training loss: 2.3825760520813213
Validation loss: 2.4565330610819176

Epoch: 5| Step: 3
Training loss: 2.4607685333859304
Validation loss: 2.4494832497871677

Epoch: 5| Step: 4
Training loss: 2.63547297682683
Validation loss: 2.448964192426567

Epoch: 5| Step: 5
Training loss: 2.8810329992701056
Validation loss: 2.4530826492055486

Epoch: 5| Step: 6
Training loss: 2.754904967675003
Validation loss: 2.451403979980538

Epoch: 5| Step: 7
Training loss: 2.829448748437006
Validation loss: 2.4584199006523235

Epoch: 5| Step: 8
Training loss: 2.664043437632268
Validation loss: 2.4596647816499284

Epoch: 5| Step: 9
Training loss: 2.1007224747510254
Validation loss: 2.4597223985732843

Epoch: 5| Step: 10
Training loss: 2.839470966118802
Validation loss: 2.4610108137563556

Epoch: 5| Step: 11
Training loss: 3.005346302763815
Validation loss: 2.463804736349491

Epoch: 118| Step: 0
Training loss: 2.6237790129112915
Validation loss: 2.457527151032182

Epoch: 5| Step: 1
Training loss: 2.5411133919628592
Validation loss: 2.4608724958927293

Epoch: 5| Step: 2
Training loss: 2.2208427982474555
Validation loss: 2.461945976021224

Epoch: 5| Step: 3
Training loss: 2.6385798011149495
Validation loss: 2.4607528496148

Epoch: 5| Step: 4
Training loss: 2.1918459636417245
Validation loss: 2.4551004728940415

Epoch: 5| Step: 5
Training loss: 2.870169686807192
Validation loss: 2.4557080246037852

Epoch: 5| Step: 6
Training loss: 2.6030249165395034
Validation loss: 2.451542135088823

Epoch: 5| Step: 7
Training loss: 2.3593048691589664
Validation loss: 2.4536955346132108

Epoch: 5| Step: 8
Training loss: 2.5783836466198147
Validation loss: 2.45646185814645

Epoch: 5| Step: 9
Training loss: 2.8956617857986067
Validation loss: 2.4501406218921082

Epoch: 5| Step: 10
Training loss: 2.3325286794782136
Validation loss: 2.456809637833307

Epoch: 5| Step: 11
Training loss: 3.1428530556788434
Validation loss: 2.455063088714189

Epoch: 119| Step: 0
Training loss: 2.5403021500562333
Validation loss: 2.452339840428417

Epoch: 5| Step: 1
Training loss: 2.5484172621437384
Validation loss: 2.4564163376555515

Epoch: 5| Step: 2
Training loss: 2.56622713297129
Validation loss: 2.4513464674252403

Epoch: 5| Step: 3
Training loss: 2.8756073020053834
Validation loss: 2.456304821829483

Epoch: 5| Step: 4
Training loss: 2.5771155028210067
Validation loss: 2.455213937009864

Epoch: 5| Step: 5
Training loss: 2.5140262997085414
Validation loss: 2.451308458633964

Epoch: 5| Step: 6
Training loss: 1.9539780241707583
Validation loss: 2.458669261017239

Epoch: 5| Step: 7
Training loss: 2.7682100273229078
Validation loss: 2.4623398070343456

Epoch: 5| Step: 8
Training loss: 2.5828131387828632
Validation loss: 2.457952131737722

Epoch: 5| Step: 9
Training loss: 2.402354468344992
Validation loss: 2.455065726949685

Epoch: 5| Step: 10
Training loss: 2.5965981529837485
Validation loss: 2.454019027234881

Epoch: 5| Step: 11
Training loss: 2.3628068432023155
Validation loss: 2.4546684463509374

Epoch: 120| Step: 0
Training loss: 3.1869012606897225
Validation loss: 2.455741157515948

Epoch: 5| Step: 1
Training loss: 3.099759209418059
Validation loss: 2.4539054430960587

Epoch: 5| Step: 2
Training loss: 1.9930284109124239
Validation loss: 2.4581563685187646

Epoch: 5| Step: 3
Training loss: 2.333588302396502
Validation loss: 2.4532211835596685

Epoch: 5| Step: 4
Training loss: 2.79166792874284
Validation loss: 2.4556763698259663

Epoch: 5| Step: 5
Training loss: 2.4016339501776187
Validation loss: 2.455845440039831

Epoch: 5| Step: 6
Training loss: 2.310277850627675
Validation loss: 2.455318502890002

Epoch: 5| Step: 7
Training loss: 2.46933430384472
Validation loss: 2.44897667004335

Epoch: 5| Step: 8
Training loss: 2.156002970380276
Validation loss: 2.4547217774825745

Epoch: 5| Step: 9
Training loss: 2.3831807836871284
Validation loss: 2.4515937391486657

Epoch: 5| Step: 10
Training loss: 2.713784078263689
Validation loss: 2.452364832137432

Epoch: 5| Step: 11
Training loss: 2.51047144364445
Validation loss: 2.4530279055289923

Epoch: 121| Step: 0
Training loss: 2.957682488713169
Validation loss: 2.4592122362978337

Epoch: 5| Step: 1
Training loss: 2.8134083446638996
Validation loss: 2.45845553665524

Epoch: 5| Step: 2
Training loss: 1.9377320058413114
Validation loss: 2.4570821646634275

Epoch: 5| Step: 3
Training loss: 2.2564816892233024
Validation loss: 2.46508926885732

Epoch: 5| Step: 4
Training loss: 2.519642057126134
Validation loss: 2.4644927527087064

Epoch: 5| Step: 5
Training loss: 3.1475597132926127
Validation loss: 2.4653783703072616

Epoch: 5| Step: 6
Training loss: 2.578637921721767
Validation loss: 2.4670177249101606

Epoch: 5| Step: 7
Training loss: 2.3770054832591043
Validation loss: 2.46218612521416

Epoch: 5| Step: 8
Training loss: 2.1465632360826143
Validation loss: 2.4647036400262445

Epoch: 5| Step: 9
Training loss: 2.617727468784724
Validation loss: 2.4617497995755575

Epoch: 5| Step: 10
Training loss: 2.4516918102075493
Validation loss: 2.462248663815774

Epoch: 5| Step: 11
Training loss: 2.52849749448568
Validation loss: 2.458731782002422

Epoch: 122| Step: 0
Training loss: 2.416352701071713
Validation loss: 2.463994866932439

Epoch: 5| Step: 1
Training loss: 2.7195409742278476
Validation loss: 2.4566288726229524

Epoch: 5| Step: 2
Training loss: 3.0937315044428195
Validation loss: 2.462300120146957

Epoch: 5| Step: 3
Training loss: 2.621773598930051
Validation loss: 2.4544859915358392

Epoch: 5| Step: 4
Training loss: 2.341291842435513
Validation loss: 2.457480898388669

Epoch: 5| Step: 5
Training loss: 2.654073384400883
Validation loss: 2.4537219760788886

Epoch: 5| Step: 6
Training loss: 2.2432802308907864
Validation loss: 2.4550738277716344

Epoch: 5| Step: 7
Training loss: 2.7358807586764087
Validation loss: 2.451024632381891

Epoch: 5| Step: 8
Training loss: 2.3018300073863083
Validation loss: 2.448842004965969

Epoch: 5| Step: 9
Training loss: 2.21971786235509
Validation loss: 2.4493308845253225

Epoch: 5| Step: 10
Training loss: 2.6634819763043533
Validation loss: 2.445187968697734

Epoch: 5| Step: 11
Training loss: 1.4250432861178535
Validation loss: 2.4519903004633625

Epoch: 123| Step: 0
Training loss: 2.097426758898067
Validation loss: 2.4468019517604946

Epoch: 5| Step: 1
Training loss: 2.4611286391855636
Validation loss: 2.4475693246597845

Epoch: 5| Step: 2
Training loss: 3.026958140764008
Validation loss: 2.4546526102864177

Epoch: 5| Step: 3
Training loss: 2.581205712185564
Validation loss: 2.455370820572974

Epoch: 5| Step: 4
Training loss: 2.1211987323668717
Validation loss: 2.453281709399552

Epoch: 5| Step: 5
Training loss: 2.877214988294616
Validation loss: 2.4567031964799986

Epoch: 5| Step: 6
Training loss: 2.236749094691615
Validation loss: 2.4629593228775613

Epoch: 5| Step: 7
Training loss: 2.750917455047029
Validation loss: 2.4561982231086286

Epoch: 5| Step: 8
Training loss: 2.478075305493367
Validation loss: 2.4559101160777175

Epoch: 5| Step: 9
Training loss: 2.7202548542959275
Validation loss: 2.458729697187128

Epoch: 5| Step: 10
Training loss: 2.337811690984208
Validation loss: 2.4540612242369204

Epoch: 5| Step: 11
Training loss: 3.0278504175305527
Validation loss: 2.4511555340590765

Epoch: 124| Step: 0
Training loss: 2.8305550772937207
Validation loss: 2.453306600405162

Epoch: 5| Step: 1
Training loss: 2.774145073692538
Validation loss: 2.449931282909273

Epoch: 5| Step: 2
Training loss: 2.7312202783708925
Validation loss: 2.4544846316335853

Epoch: 5| Step: 3
Training loss: 2.1009222140104353
Validation loss: 2.454969291935215

Epoch: 5| Step: 4
Training loss: 2.5436674174932246
Validation loss: 2.452137924651866

Epoch: 5| Step: 5
Training loss: 2.285165640004746
Validation loss: 2.4533010205010237

Epoch: 5| Step: 6
Training loss: 2.050106845955592
Validation loss: 2.4465378077088444

Epoch: 5| Step: 7
Training loss: 2.611469638730504
Validation loss: 2.4519020198811576

Epoch: 5| Step: 8
Training loss: 2.6787694131251887
Validation loss: 2.4499240733727525

Epoch: 5| Step: 9
Training loss: 2.6013083577243497
Validation loss: 2.453086787936572

Epoch: 5| Step: 10
Training loss: 2.515460749411494
Validation loss: 2.442706426661763

Epoch: 5| Step: 11
Training loss: 2.237340599647668
Validation loss: 2.4487990689517543

Epoch: 125| Step: 0
Training loss: 2.3112080032056896
Validation loss: 2.4437973560970914

Epoch: 5| Step: 1
Training loss: 2.547470865579059
Validation loss: 2.4495673451229285

Epoch: 5| Step: 2
Training loss: 2.585143183389556
Validation loss: 2.4516709953047737

Epoch: 5| Step: 3
Training loss: 2.942305347677594
Validation loss: 2.4522180905635222

Epoch: 5| Step: 4
Training loss: 2.8738510489732363
Validation loss: 2.4474020450824674

Epoch: 5| Step: 5
Training loss: 2.450653386086615
Validation loss: 2.44456008450359

Epoch: 5| Step: 6
Training loss: 2.779647022314983
Validation loss: 2.4453410389690227

Epoch: 5| Step: 7
Training loss: 2.4073870065699565
Validation loss: 2.447674014192113

Epoch: 5| Step: 8
Training loss: 2.771170363806906
Validation loss: 2.448755385733876

Epoch: 5| Step: 9
Training loss: 2.1992627642548292
Validation loss: 2.454260039104959

Epoch: 5| Step: 10
Training loss: 2.2881613770640814
Validation loss: 2.454549651116927

Epoch: 5| Step: 11
Training loss: 0.4695751398173365
Validation loss: 2.455728372443601

Epoch: 126| Step: 0
Training loss: 2.9063458170528813
Validation loss: 2.453160599533265

Epoch: 5| Step: 1
Training loss: 2.3137641750501197
Validation loss: 2.45529216358356

Epoch: 5| Step: 2
Training loss: 2.954079125689588
Validation loss: 2.462580307104461

Epoch: 5| Step: 3
Training loss: 2.7487149270436517
Validation loss: 2.4631544027870023

Epoch: 5| Step: 4
Training loss: 2.6304622313574746
Validation loss: 2.461310218157033

Epoch: 5| Step: 5
Training loss: 2.5008541555363006
Validation loss: 2.4625620611474126

Epoch: 5| Step: 6
Training loss: 2.5364204628458706
Validation loss: 2.454889545668676

Epoch: 5| Step: 7
Training loss: 2.318745298972081
Validation loss: 2.455214758373513

Epoch: 5| Step: 8
Training loss: 2.430190938818386
Validation loss: 2.4502386173188495

Epoch: 5| Step: 9
Training loss: 2.2964683743688523
Validation loss: 2.4515754965183807

Epoch: 5| Step: 10
Training loss: 2.3155251382358175
Validation loss: 2.455966445824111

Epoch: 5| Step: 11
Training loss: 1.6687255857589067
Validation loss: 2.45101762263454

Epoch: 127| Step: 0
Training loss: 2.4161330543789186
Validation loss: 2.4485982527683436

Epoch: 5| Step: 1
Training loss: 2.2322753430966937
Validation loss: 2.451117453407935

Epoch: 5| Step: 2
Training loss: 2.727891046339546
Validation loss: 2.4442735238056725

Epoch: 5| Step: 3
Training loss: 2.1288104954454727
Validation loss: 2.4464735741995858

Epoch: 5| Step: 4
Training loss: 2.898481260725074
Validation loss: 2.453426192759698

Epoch: 5| Step: 5
Training loss: 2.535039819709388
Validation loss: 2.4467842174528127

Epoch: 5| Step: 6
Training loss: 2.3692311948114675
Validation loss: 2.456387021462848

Epoch: 5| Step: 7
Training loss: 1.7570692059126343
Validation loss: 2.4545923975039656

Epoch: 5| Step: 8
Training loss: 2.9103223919646597
Validation loss: 2.4598035147425663

Epoch: 5| Step: 9
Training loss: 2.7808090031784283
Validation loss: 2.4581875690521846

Epoch: 5| Step: 10
Training loss: 2.749373884883723
Validation loss: 2.453554856852608

Epoch: 5| Step: 11
Training loss: 3.28972932484752
Validation loss: 2.4553496524977274

Epoch: 128| Step: 0
Training loss: 2.3419375723345834
Validation loss: 2.457036376689016

Epoch: 5| Step: 1
Training loss: 2.4512413227836163
Validation loss: 2.449803466601928

Epoch: 5| Step: 2
Training loss: 2.4018578014606735
Validation loss: 2.456026370098259

Epoch: 5| Step: 3
Training loss: 2.0836151568211005
Validation loss: 2.4612516454985314

Epoch: 5| Step: 4
Training loss: 2.8207167232720796
Validation loss: 2.4565966150457546

Epoch: 5| Step: 5
Training loss: 2.687076091601819
Validation loss: 2.4605784643745197

Epoch: 5| Step: 6
Training loss: 2.884330370589774
Validation loss: 2.464044839444568

Epoch: 5| Step: 7
Training loss: 2.5762700661549185
Validation loss: 2.4646388037709164

Epoch: 5| Step: 8
Training loss: 2.4518798778289965
Validation loss: 2.4662801080958245

Epoch: 5| Step: 9
Training loss: 2.54829451430572
Validation loss: 2.465536992380331

Epoch: 5| Step: 10
Training loss: 2.7330323328812747
Validation loss: 2.4648966997668986

Epoch: 5| Step: 11
Training loss: 2.1650433572563967
Validation loss: 2.4619775703628903

Epoch: 129| Step: 0
Training loss: 2.850762743692501
Validation loss: 2.4639709910428373

Epoch: 5| Step: 1
Training loss: 2.7493748387750543
Validation loss: 2.457233733954639

Epoch: 5| Step: 2
Training loss: 2.297580532783664
Validation loss: 2.4514640644086785

Epoch: 5| Step: 3
Training loss: 2.0858034240837937
Validation loss: 2.4546373285694094

Epoch: 5| Step: 4
Training loss: 2.9108807167661834
Validation loss: 2.446671275966921

Epoch: 5| Step: 5
Training loss: 2.545102772464406
Validation loss: 2.445679471528548

Epoch: 5| Step: 6
Training loss: 2.912073678834709
Validation loss: 2.447923276094212

Epoch: 5| Step: 7
Training loss: 2.3253085106055558
Validation loss: 2.44691517140431

Epoch: 5| Step: 8
Training loss: 2.0265587258873636
Validation loss: 2.4486263396263857

Epoch: 5| Step: 9
Training loss: 2.601150984192559
Validation loss: 2.443469172388442

Epoch: 5| Step: 10
Training loss: 2.153927422918582
Validation loss: 2.4493366255677933

Epoch: 5| Step: 11
Training loss: 3.0991956774865113
Validation loss: 2.4570394696783984

Epoch: 130| Step: 0
Training loss: 2.9043958758660224
Validation loss: 2.4552188651876348

Epoch: 5| Step: 1
Training loss: 2.2396351179893026
Validation loss: 2.4496497911134196

Epoch: 5| Step: 2
Training loss: 2.0983144626066834
Validation loss: 2.4536432621833826

Epoch: 5| Step: 3
Training loss: 2.0610834516855476
Validation loss: 2.4461286440171452

Epoch: 5| Step: 4
Training loss: 3.4902319158322337
Validation loss: 2.4483885871563564

Epoch: 5| Step: 5
Training loss: 2.4124819819118475
Validation loss: 2.445920204480627

Epoch: 5| Step: 6
Training loss: 1.83283773861782
Validation loss: 2.4470400532496184

Epoch: 5| Step: 7
Training loss: 2.1604782885374476
Validation loss: 2.449283179206857

Epoch: 5| Step: 8
Training loss: 2.681063018183404
Validation loss: 2.448012570606007

Epoch: 5| Step: 9
Training loss: 3.122197076719608
Validation loss: 2.4466332676316016

Epoch: 5| Step: 10
Training loss: 2.3101801190192965
Validation loss: 2.452057626476596

Epoch: 5| Step: 11
Training loss: 2.055639590301185
Validation loss: 2.4560891039682415

Epoch: 131| Step: 0
Training loss: 2.5793467083417645
Validation loss: 2.4588324732443994

Epoch: 5| Step: 1
Training loss: 2.2803560360441626
Validation loss: 2.4547903680807397

Epoch: 5| Step: 2
Training loss: 2.1499561837632997
Validation loss: 2.4542238604989715

Epoch: 5| Step: 3
Training loss: 2.6083701934484984
Validation loss: 2.454190579596328

Epoch: 5| Step: 4
Training loss: 2.7282811735181696
Validation loss: 2.456030548361329

Epoch: 5| Step: 5
Training loss: 2.438974179239516
Validation loss: 2.453084933202789

Epoch: 5| Step: 6
Training loss: 2.328233754734909
Validation loss: 2.4514417542804985

Epoch: 5| Step: 7
Training loss: 2.580171454890799
Validation loss: 2.4517638789743876

Epoch: 5| Step: 8
Training loss: 2.845545275413609
Validation loss: 2.4487405337490995

Epoch: 5| Step: 9
Training loss: 2.679275614499361
Validation loss: 2.4479033990595127

Epoch: 5| Step: 10
Training loss: 2.5329337465798405
Validation loss: 2.449300814302756

Epoch: 5| Step: 11
Training loss: 1.6217606608929978
Validation loss: 2.4489595599531775

Epoch: 132| Step: 0
Training loss: 2.308305906369247
Validation loss: 2.452114293873412

Epoch: 5| Step: 1
Training loss: 2.3288730725187303
Validation loss: 2.450896370490087

Epoch: 5| Step: 2
Training loss: 2.8222465329695927
Validation loss: 2.460564152084184

Epoch: 5| Step: 3
Training loss: 2.7732034074017116
Validation loss: 2.4641766660597293

Epoch: 5| Step: 4
Training loss: 2.3692364276281084
Validation loss: 2.460927783603762

Epoch: 5| Step: 5
Training loss: 2.556202663738826
Validation loss: 2.466787749510433

Epoch: 5| Step: 6
Training loss: 3.0894313686567996
Validation loss: 2.454770943243042

Epoch: 5| Step: 7
Training loss: 2.21671911430934
Validation loss: 2.456953875319506

Epoch: 5| Step: 8
Training loss: 2.3495512310644004
Validation loss: 2.4548514420065475

Epoch: 5| Step: 9
Training loss: 2.480543528954016
Validation loss: 2.45066585915647

Epoch: 5| Step: 10
Training loss: 2.319796007001288
Validation loss: 2.452465100226402

Epoch: 5| Step: 11
Training loss: 2.829012736729051
Validation loss: 2.450611772920688

Epoch: 133| Step: 0
Training loss: 2.5885728390285916
Validation loss: 2.466845912853681

Epoch: 5| Step: 1
Training loss: 2.5204835023708996
Validation loss: 2.4707713483354983

Epoch: 5| Step: 2
Training loss: 2.4100432779058956
Validation loss: 2.476239126134391

Epoch: 5| Step: 3
Training loss: 2.4569174250450483
Validation loss: 2.478875452991043

Epoch: 5| Step: 4
Training loss: 2.1854683296877946
Validation loss: 2.4818584884315897

Epoch: 5| Step: 5
Training loss: 2.5645545538478736
Validation loss: 2.482103582986613

Epoch: 5| Step: 6
Training loss: 2.3592676807778696
Validation loss: 2.4926446397749666

Epoch: 5| Step: 7
Training loss: 3.2270724653270753
Validation loss: 2.491875576162419

Epoch: 5| Step: 8
Training loss: 2.9732508221397973
Validation loss: 2.49862118686522

Epoch: 5| Step: 9
Training loss: 2.7980461865117645
Validation loss: 2.501528078216086

Epoch: 5| Step: 10
Training loss: 2.369396324856689
Validation loss: 2.5021225462187773

Epoch: 5| Step: 11
Training loss: 3.002327492972916
Validation loss: 2.5006918307533814

Epoch: 134| Step: 0
Training loss: 2.9968394479243865
Validation loss: 2.494150705897173

Epoch: 5| Step: 1
Training loss: 2.7403752351257977
Validation loss: 2.493994891540019

Epoch: 5| Step: 2
Training loss: 2.862858385864066
Validation loss: 2.491128582940872

Epoch: 5| Step: 3
Training loss: 2.209443359180764
Validation loss: 2.493583842090382

Epoch: 5| Step: 4
Training loss: 2.084982549836756
Validation loss: 2.4913301577690303

Epoch: 5| Step: 5
Training loss: 2.998740408636785
Validation loss: 2.488693087444555

Epoch: 5| Step: 6
Training loss: 2.3680576449994377
Validation loss: 2.4916638229719625

Epoch: 5| Step: 7
Training loss: 2.178186809259365
Validation loss: 2.4872523485639704

Epoch: 5| Step: 8
Training loss: 2.380150280222934
Validation loss: 2.485674056618661

Epoch: 5| Step: 9
Training loss: 3.007302297941804
Validation loss: 2.480665692698622

Epoch: 5| Step: 10
Training loss: 2.6685418648597734
Validation loss: 2.481761117110925

Epoch: 5| Step: 11
Training loss: 2.2389557306531236
Validation loss: 2.478705849548493

Epoch: 135| Step: 0
Training loss: 2.6934013335768174
Validation loss: 2.4786835742077615

Epoch: 5| Step: 1
Training loss: 1.8537711961168482
Validation loss: 2.4792072803045038

Epoch: 5| Step: 2
Training loss: 2.857845042999169
Validation loss: 2.476817185135216

Epoch: 5| Step: 3
Training loss: 2.665128164734381
Validation loss: 2.4733526164285986

Epoch: 5| Step: 4
Training loss: 2.4976488501684058
Validation loss: 2.4721679004375585

Epoch: 5| Step: 5
Training loss: 2.5695693034401477
Validation loss: 2.4705537009508047

Epoch: 5| Step: 6
Training loss: 2.738671289981752
Validation loss: 2.470088322356367

Epoch: 5| Step: 7
Training loss: 2.782372237542905
Validation loss: 2.4690463013031714

Epoch: 5| Step: 8
Training loss: 2.304602669916557
Validation loss: 2.461195701092511

Epoch: 5| Step: 9
Training loss: 2.4483242804782113
Validation loss: 2.460950074340343

Epoch: 5| Step: 10
Training loss: 2.6218971806202904
Validation loss: 2.452052272631237

Epoch: 5| Step: 11
Training loss: 2.725567917745431
Validation loss: 2.4480633400878253

Epoch: 136| Step: 0
Training loss: 2.9788210652815055
Validation loss: 2.4538769349107468

Epoch: 5| Step: 1
Training loss: 2.2028963227328053
Validation loss: 2.4524810415553335

Epoch: 5| Step: 2
Training loss: 2.301751597626315
Validation loss: 2.4591290323068002

Epoch: 5| Step: 3
Training loss: 2.4836383423187423
Validation loss: 2.449920123932616

Epoch: 5| Step: 4
Training loss: 2.863884876526732
Validation loss: 2.4576052918487687

Epoch: 5| Step: 5
Training loss: 2.291618924655101
Validation loss: 2.4549543197276944

Epoch: 5| Step: 6
Training loss: 2.9784928918189837
Validation loss: 2.453634025017904

Epoch: 5| Step: 7
Training loss: 2.19980148806979
Validation loss: 2.4509876643007518

Epoch: 5| Step: 8
Training loss: 2.718073442838074
Validation loss: 2.452400011298518

Epoch: 5| Step: 9
Training loss: 2.3665950021057043
Validation loss: 2.447073455759001

Epoch: 5| Step: 10
Training loss: 2.4060468711822063
Validation loss: 2.452980450301523

Epoch: 5| Step: 11
Training loss: 2.624785641591831
Validation loss: 2.4555511989945633

Epoch: 137| Step: 0
Training loss: 2.6579285647320368
Validation loss: 2.4561335425234727

Epoch: 5| Step: 1
Training loss: 2.322471564604397
Validation loss: 2.449936606923468

Epoch: 5| Step: 2
Training loss: 2.3321587353593327
Validation loss: 2.456092833165245

Epoch: 5| Step: 3
Training loss: 3.1274041655301277
Validation loss: 2.4531999179714687

Epoch: 5| Step: 4
Training loss: 2.3388803374173652
Validation loss: 2.449081441385712

Epoch: 5| Step: 5
Training loss: 2.57567058831136
Validation loss: 2.4477547341753785

Epoch: 5| Step: 6
Training loss: 2.124239617231544
Validation loss: 2.447698937871892

Epoch: 5| Step: 7
Training loss: 2.2867150883047427
Validation loss: 2.4394943115732035

Epoch: 5| Step: 8
Training loss: 2.733781761120983
Validation loss: 2.447804530936878

Epoch: 5| Step: 9
Training loss: 2.571018852411068
Validation loss: 2.4521349753746216

Epoch: 5| Step: 10
Training loss: 2.5828735085889996
Validation loss: 2.450087868159315

Epoch: 5| Step: 11
Training loss: 2.20932217417454
Validation loss: 2.4470704557224074

Epoch: 138| Step: 0
Training loss: 2.532633085679741
Validation loss: 2.4457000307531582

Epoch: 5| Step: 1
Training loss: 2.4366557297502465
Validation loss: 2.4541037767336786

Epoch: 5| Step: 2
Training loss: 2.188934836521265
Validation loss: 2.4427594923072413

Epoch: 5| Step: 3
Training loss: 2.744221077279286
Validation loss: 2.451242615589598

Epoch: 5| Step: 4
Training loss: 2.5152566770467426
Validation loss: 2.455078084536491

Epoch: 5| Step: 5
Training loss: 2.406679288543967
Validation loss: 2.450852554414104

Epoch: 5| Step: 6
Training loss: 2.6817508683184133
Validation loss: 2.4514752285142993

Epoch: 5| Step: 7
Training loss: 2.5856301854012225
Validation loss: 2.4547469614501387

Epoch: 5| Step: 8
Training loss: 2.3991711019581214
Validation loss: 2.4550457984902194

Epoch: 5| Step: 9
Training loss: 3.0277770292259794
Validation loss: 2.453897670377436

Epoch: 5| Step: 10
Training loss: 2.2411377473071092
Validation loss: 2.4530250990625864

Epoch: 5| Step: 11
Training loss: 2.207413847852486
Validation loss: 2.4500515022508798

Epoch: 139| Step: 0
Training loss: 2.3356265878608173
Validation loss: 2.4496428524554927

Epoch: 5| Step: 1
Training loss: 2.6926050713597975
Validation loss: 2.455335123615698

Epoch: 5| Step: 2
Training loss: 2.4669494823329012
Validation loss: 2.454923051798761

Epoch: 5| Step: 3
Training loss: 2.426666540505682
Validation loss: 2.4488671033625913

Epoch: 5| Step: 4
Training loss: 2.6678969902787713
Validation loss: 2.4518335227041366

Epoch: 5| Step: 5
Training loss: 2.181591883757783
Validation loss: 2.449199467552165

Epoch: 5| Step: 6
Training loss: 2.7333422645174825
Validation loss: 2.442167247933122

Epoch: 5| Step: 7
Training loss: 2.082292894595536
Validation loss: 2.448744219370223

Epoch: 5| Step: 8
Training loss: 2.7611233556396195
Validation loss: 2.4511292716043607

Epoch: 5| Step: 9
Training loss: 2.4027662944580546
Validation loss: 2.452894617103299

Epoch: 5| Step: 10
Training loss: 2.841618504120746
Validation loss: 2.44943784294552

Epoch: 5| Step: 11
Training loss: 1.1888881901464656
Validation loss: 2.443231784122789

Epoch: 140| Step: 0
Training loss: 2.3390407808425615
Validation loss: 2.4472945998846924

Epoch: 5| Step: 1
Training loss: 2.3819470444180975
Validation loss: 2.447157524301038

Epoch: 5| Step: 2
Training loss: 2.461224445386655
Validation loss: 2.4522251454920077

Epoch: 5| Step: 3
Training loss: 2.660011141904284
Validation loss: 2.450564479675663

Epoch: 5| Step: 4
Training loss: 2.5373286034337332
Validation loss: 2.453340812471727

Epoch: 5| Step: 5
Training loss: 2.0688787137928735
Validation loss: 2.4434996518149847

Epoch: 5| Step: 6
Training loss: 3.1647565669112083
Validation loss: 2.440760530656106

Epoch: 5| Step: 7
Training loss: 2.9420214005968455
Validation loss: 2.448626875151966

Epoch: 5| Step: 8
Training loss: 2.3147682200793254
Validation loss: 2.4410886267997927

Epoch: 5| Step: 9
Training loss: 2.4416767428280273
Validation loss: 2.448778829860859

Epoch: 5| Step: 10
Training loss: 2.3601435742105714
Validation loss: 2.4499747282301287

Epoch: 5| Step: 11
Training loss: 2.0418408637437944
Validation loss: 2.455447496675598

Epoch: 141| Step: 0
Training loss: 2.5656149005574953
Validation loss: 2.449042626740355

Epoch: 5| Step: 1
Training loss: 2.265885857659248
Validation loss: 2.455146058244579

Epoch: 5| Step: 2
Training loss: 2.170864721011508
Validation loss: 2.4554792879116984

Epoch: 5| Step: 3
Training loss: 2.411457322671787
Validation loss: 2.4517782406105444

Epoch: 5| Step: 4
Training loss: 3.042570075777323
Validation loss: 2.45736630191522

Epoch: 5| Step: 5
Training loss: 2.3482622579950942
Validation loss: 2.452340107785757

Epoch: 5| Step: 6
Training loss: 3.101123692294009
Validation loss: 2.460127803266126

Epoch: 5| Step: 7
Training loss: 2.642750443326173
Validation loss: 2.4579854587068417

Epoch: 5| Step: 8
Training loss: 2.5761736334042045
Validation loss: 2.45510057405189

Epoch: 5| Step: 9
Training loss: 2.2608870853268317
Validation loss: 2.456615247012549

Epoch: 5| Step: 10
Training loss: 2.1692021890673177
Validation loss: 2.4562155921765054

Epoch: 5| Step: 11
Training loss: 2.5299522935191705
Validation loss: 2.4500816159699745

Epoch: 142| Step: 0
Training loss: 2.38849999221888
Validation loss: 2.4556244328570114

Epoch: 5| Step: 1
Training loss: 1.9670372430623886
Validation loss: 2.457384671344131

Epoch: 5| Step: 2
Training loss: 2.0918860038055325
Validation loss: 2.4553988340066755

Epoch: 5| Step: 3
Training loss: 1.8555672388540183
Validation loss: 2.459505869717078

Epoch: 5| Step: 4
Training loss: 2.6447796162624613
Validation loss: 2.4567653429235414

Epoch: 5| Step: 5
Training loss: 2.8161822479943406
Validation loss: 2.457549363471946

Epoch: 5| Step: 6
Training loss: 2.4568102908583183
Validation loss: 2.452739549633306

Epoch: 5| Step: 7
Training loss: 2.4061270347981774
Validation loss: 2.4598581157062025

Epoch: 5| Step: 8
Training loss: 2.497035366823815
Validation loss: 2.4624659035673244

Epoch: 5| Step: 9
Training loss: 3.1162646464444714
Validation loss: 2.4584424121277944

Epoch: 5| Step: 10
Training loss: 3.27076470045906
Validation loss: 2.457271376188195

Epoch: 5| Step: 11
Training loss: 2.7302647679529177
Validation loss: 2.4567907687724806

Epoch: 143| Step: 0
Training loss: 2.710124924655461
Validation loss: 2.456142193933533

Epoch: 5| Step: 1
Training loss: 2.823569237612831
Validation loss: 2.4517570009992222

Epoch: 5| Step: 2
Training loss: 1.971984507184559
Validation loss: 2.4532885122372914

Epoch: 5| Step: 3
Training loss: 2.5366725530902805
Validation loss: 2.458888093670805

Epoch: 5| Step: 4
Training loss: 2.19790821766849
Validation loss: 2.451945533596861

Epoch: 5| Step: 5
Training loss: 3.0379269397983775
Validation loss: 2.4531738333083495

Epoch: 5| Step: 6
Training loss: 2.5631507419427426
Validation loss: 2.4620519223944863

Epoch: 5| Step: 7
Training loss: 2.647994372900663
Validation loss: 2.4594467532311235

Epoch: 5| Step: 8
Training loss: 2.2758157881352963
Validation loss: 2.4531288997351877

Epoch: 5| Step: 9
Training loss: 1.9997652631335254
Validation loss: 2.4629861509113424

Epoch: 5| Step: 10
Training loss: 2.4225559384842796
Validation loss: 2.462531821695613

Epoch: 5| Step: 11
Training loss: 3.4674230563449226
Validation loss: 2.4509651735244695

Epoch: 144| Step: 0
Training loss: 2.4039400581211567
Validation loss: 2.455313698314083

Epoch: 5| Step: 1
Training loss: 2.573338174205964
Validation loss: 2.4550958783001735

Epoch: 5| Step: 2
Training loss: 2.795691724697746
Validation loss: 2.4520555765001095

Epoch: 5| Step: 3
Training loss: 2.3048805285292895
Validation loss: 2.45455957893253

Epoch: 5| Step: 4
Training loss: 2.7327285605397402
Validation loss: 2.4545733839122734

Epoch: 5| Step: 5
Training loss: 2.4828854299868857
Validation loss: 2.44981716456654

Epoch: 5| Step: 6
Training loss: 2.527293279931006
Validation loss: 2.4490234240329025

Epoch: 5| Step: 7
Training loss: 2.566385626165706
Validation loss: 2.4522599033274095

Epoch: 5| Step: 8
Training loss: 2.569758300399698
Validation loss: 2.4487965050994225

Epoch: 5| Step: 9
Training loss: 2.186946798946449
Validation loss: 2.453097936557906

Epoch: 5| Step: 10
Training loss: 2.461945633040833
Validation loss: 2.4559012454204137

Epoch: 5| Step: 11
Training loss: 2.0312687799612617
Validation loss: 2.4492274603113353

Epoch: 145| Step: 0
Training loss: 2.857438896373602
Validation loss: 2.4499842346423755

Epoch: 5| Step: 1
Training loss: 2.6965670554582024
Validation loss: 2.450261832376134

Epoch: 5| Step: 2
Training loss: 2.426207770599658
Validation loss: 2.45238545278929

Epoch: 5| Step: 3
Training loss: 2.5198292164227607
Validation loss: 2.4461477658905095

Epoch: 5| Step: 4
Training loss: 2.189620053327926
Validation loss: 2.4524708622864875

Epoch: 5| Step: 5
Training loss: 2.422784351552907
Validation loss: 2.4484718518341584

Epoch: 5| Step: 6
Training loss: 2.672958422062382
Validation loss: 2.454089244523704

Epoch: 5| Step: 7
Training loss: 2.386351611780034
Validation loss: 2.4518947958813584

Epoch: 5| Step: 8
Training loss: 2.7291724712125673
Validation loss: 2.449909901584174

Epoch: 5| Step: 9
Training loss: 2.3005882920598784
Validation loss: 2.4529468670130616

Epoch: 5| Step: 10
Training loss: 2.303395571919006
Validation loss: 2.4536774938477763

Epoch: 5| Step: 11
Training loss: 1.5611816948394437
Validation loss: 2.44897006210662

Epoch: 146| Step: 0
Training loss: 2.982510128851396
Validation loss: 2.450417974882831

Epoch: 5| Step: 1
Training loss: 2.7831695447535623
Validation loss: 2.4540246986124536

Epoch: 5| Step: 2
Training loss: 1.7241044304322557
Validation loss: 2.4569369056916175

Epoch: 5| Step: 3
Training loss: 2.478536979998132
Validation loss: 2.4577464410691876

Epoch: 5| Step: 4
Training loss: 2.2185774185328593
Validation loss: 2.45968154667411

Epoch: 5| Step: 5
Training loss: 2.1909647070071836
Validation loss: 2.459552993053065

Epoch: 5| Step: 6
Training loss: 2.340513716167117
Validation loss: 2.4611254262065363

Epoch: 5| Step: 7
Training loss: 3.0009184067339305
Validation loss: 2.454422686477622

Epoch: 5| Step: 8
Training loss: 3.020630788041798
Validation loss: 2.4568672792579758

Epoch: 5| Step: 9
Training loss: 2.366970946223488
Validation loss: 2.457780837889593

Epoch: 5| Step: 10
Training loss: 1.88576601982367
Validation loss: 2.4570747759773894

Epoch: 5| Step: 11
Training loss: 3.084363936971595
Validation loss: 2.457606641939848

Epoch: 147| Step: 0
Training loss: 2.9206284092418544
Validation loss: 2.4569271856041683

Epoch: 5| Step: 1
Training loss: 2.5156975018970433
Validation loss: 2.458139352634512

Epoch: 5| Step: 2
Training loss: 2.594951305483791
Validation loss: 2.449542927113246

Epoch: 5| Step: 3
Training loss: 2.9425887812182596
Validation loss: 2.4580367739192166

Epoch: 5| Step: 4
Training loss: 2.6678801001011316
Validation loss: 2.4534909973544274

Epoch: 5| Step: 5
Training loss: 2.7132819424229337
Validation loss: 2.44741215613497

Epoch: 5| Step: 6
Training loss: 2.1862605261835535
Validation loss: 2.453289613647341

Epoch: 5| Step: 7
Training loss: 1.7721565762914246
Validation loss: 2.454341076761437

Epoch: 5| Step: 8
Training loss: 2.7546806382966333
Validation loss: 2.4543555305770166

Epoch: 5| Step: 9
Training loss: 2.0449625646993463
Validation loss: 2.4527428485262064

Epoch: 5| Step: 10
Training loss: 2.203476789808851
Validation loss: 2.4566595264317677

Epoch: 5| Step: 11
Training loss: 1.826915569135552
Validation loss: 2.456244685949477

Epoch: 148| Step: 0
Training loss: 2.2307486817756716
Validation loss: 2.453104930236746

Epoch: 5| Step: 1
Training loss: 2.5895800794323716
Validation loss: 2.454120344967254

Epoch: 5| Step: 2
Training loss: 2.5883435813797546
Validation loss: 2.4568742985976306

Epoch: 5| Step: 3
Training loss: 2.591564866629191
Validation loss: 2.4570652990200634

Epoch: 5| Step: 4
Training loss: 2.2047335116358897
Validation loss: 2.4569104947819342

Epoch: 5| Step: 5
Training loss: 2.891330612252875
Validation loss: 2.4628879507777848

Epoch: 5| Step: 6
Training loss: 2.7796209472099713
Validation loss: 2.466167306185529

Epoch: 5| Step: 7
Training loss: 2.567255770796511
Validation loss: 2.458043013957045

Epoch: 5| Step: 8
Training loss: 2.435896419352475
Validation loss: 2.4599536806297104

Epoch: 5| Step: 9
Training loss: 1.879750845104159
Validation loss: 2.456021763079723

Epoch: 5| Step: 10
Training loss: 2.6298693044990538
Validation loss: 2.4544754603683523

Epoch: 5| Step: 11
Training loss: 2.907390575760672
Validation loss: 2.459952267213418

Epoch: 149| Step: 0
Training loss: 3.0734912055035424
Validation loss: 2.448410935248678

Epoch: 5| Step: 1
Training loss: 2.3767187023307037
Validation loss: 2.4528173832871696

Epoch: 5| Step: 2
Training loss: 2.773694695380801
Validation loss: 2.460905952856917

Epoch: 5| Step: 3
Training loss: 2.5713283769070037
Validation loss: 2.4610792250417846

Epoch: 5| Step: 4
Training loss: 2.331350869458709
Validation loss: 2.467953968074269

Epoch: 5| Step: 5
Training loss: 2.5026687682537077
Validation loss: 2.4531352008518397

Epoch: 5| Step: 6
Training loss: 2.588458811446434
Validation loss: 2.4529653930576294

Epoch: 5| Step: 7
Training loss: 2.4275259724886435
Validation loss: 2.4544997605037255

Epoch: 5| Step: 8
Training loss: 2.460794692967103
Validation loss: 2.45715769577338

Epoch: 5| Step: 9
Training loss: 2.290633668141533
Validation loss: 2.456952828114507

Epoch: 5| Step: 10
Training loss: 1.7291895010792484
Validation loss: 2.450932326649612

Epoch: 5| Step: 11
Training loss: 3.0221120999724356
Validation loss: 2.4541362532807445

Epoch: 150| Step: 0
Training loss: 2.830126480942561
Validation loss: 2.4601895038242625

Epoch: 5| Step: 1
Training loss: 2.861514265756409
Validation loss: 2.4537362837444516

Epoch: 5| Step: 2
Training loss: 2.3924957136635965
Validation loss: 2.4648531446565034

Epoch: 5| Step: 3
Training loss: 2.1531403827532976
Validation loss: 2.4541207376164365

Epoch: 5| Step: 4
Training loss: 2.351709506993932
Validation loss: 2.4562337619222103

Epoch: 5| Step: 5
Training loss: 2.616885495197833
Validation loss: 2.4644966908883688

Epoch: 5| Step: 6
Training loss: 2.2170853078463324
Validation loss: 2.4563278218269335

Epoch: 5| Step: 7
Training loss: 2.8304716880418783
Validation loss: 2.452099628334924

Epoch: 5| Step: 8
Training loss: 2.979613335121028
Validation loss: 2.4538287916794586

Epoch: 5| Step: 9
Training loss: 1.928728305400441
Validation loss: 2.4549374940947084

Epoch: 5| Step: 10
Training loss: 2.0805247512368203
Validation loss: 2.4533076896592787

Epoch: 5| Step: 11
Training loss: 2.103024566202165
Validation loss: 2.455551656144078

Epoch: 151| Step: 0
Training loss: 2.3383800787772433
Validation loss: 2.457433468515366

Epoch: 5| Step: 1
Training loss: 2.2637239043713278
Validation loss: 2.454326885954062

Epoch: 5| Step: 2
Training loss: 2.350749030356738
Validation loss: 2.4558462672598997

Epoch: 5| Step: 3
Training loss: 2.2491810685844222
Validation loss: 2.4576546626611653

Epoch: 5| Step: 4
Training loss: 2.041342443555905
Validation loss: 2.4529704674968413

Epoch: 5| Step: 5
Training loss: 2.332489428726233
Validation loss: 2.455805911135524

Epoch: 5| Step: 6
Training loss: 2.264123037304236
Validation loss: 2.4552004229084083

Epoch: 5| Step: 7
Training loss: 3.1438445484663955
Validation loss: 2.452067657562122

Epoch: 5| Step: 8
Training loss: 2.6448163057801954
Validation loss: 2.455811562205951

Epoch: 5| Step: 9
Training loss: 2.5672982115970258
Validation loss: 2.44942491344079

Epoch: 5| Step: 10
Training loss: 2.804342519641326
Validation loss: 2.4593676207066966

Epoch: 5| Step: 11
Training loss: 2.858235283181039
Validation loss: 2.4522998094141313

Epoch: 152| Step: 0
Training loss: 2.318278747544902
Validation loss: 2.452241147120783

Epoch: 5| Step: 1
Training loss: 2.519450057739749
Validation loss: 2.452317912976432

Epoch: 5| Step: 2
Training loss: 2.635097429041433
Validation loss: 2.4520006721444063

Epoch: 5| Step: 3
Training loss: 2.462992557893848
Validation loss: 2.455665366408265

Epoch: 5| Step: 4
Training loss: 2.1699608800148167
Validation loss: 2.4614183551535302

Epoch: 5| Step: 5
Training loss: 2.687539920953955
Validation loss: 2.466631112830503

Epoch: 5| Step: 6
Training loss: 2.397968457610285
Validation loss: 2.4843170950997115

Epoch: 5| Step: 7
Training loss: 1.9940826377694738
Validation loss: 2.4948275980953456

Epoch: 5| Step: 8
Training loss: 2.2091003981121387
Validation loss: 2.4703326725322126

Epoch: 5| Step: 9
Training loss: 3.2519449136532965
Validation loss: 2.462023113114867

Epoch: 5| Step: 10
Training loss: 2.7228232377671446
Validation loss: 2.4469800814479292

Epoch: 5| Step: 11
Training loss: 1.4365058446619863
Validation loss: 2.4598180939646253

Epoch: 153| Step: 0
Training loss: 2.1649192463745046
Validation loss: 2.4687920176475475

Epoch: 5| Step: 1
Training loss: 2.7061378579108024
Validation loss: 2.462553133770511

Epoch: 5| Step: 2
Training loss: 2.467768123788551
Validation loss: 2.461249599143545

Epoch: 5| Step: 3
Training loss: 2.9024429817743487
Validation loss: 2.4658300982491985

Epoch: 5| Step: 4
Training loss: 2.5018186629863965
Validation loss: 2.4659733609584493

Epoch: 5| Step: 5
Training loss: 3.049068502545545
Validation loss: 2.4709961206055007

Epoch: 5| Step: 6
Training loss: 2.2788355343282434
Validation loss: 2.4684571804754833

Epoch: 5| Step: 7
Training loss: 2.724505766399216
Validation loss: 2.4705087979858824

Epoch: 5| Step: 8
Training loss: 2.5629206986618596
Validation loss: 2.47113158841972

Epoch: 5| Step: 9
Training loss: 2.144839294211094
Validation loss: 2.473499168483506

Epoch: 5| Step: 10
Training loss: 2.453450952730381
Validation loss: 2.470875070893762

Epoch: 5| Step: 11
Training loss: 2.487895654238126
Validation loss: 2.4711259241428665

Epoch: 154| Step: 0
Training loss: 2.513733715609743
Validation loss: 2.468597431538672

Epoch: 5| Step: 1
Training loss: 2.309312840762115
Validation loss: 2.464293943044891

Epoch: 5| Step: 2
Training loss: 2.7415497736568613
Validation loss: 2.465947943176141

Epoch: 5| Step: 3
Training loss: 2.9557902908166764
Validation loss: 2.46208857707534

Epoch: 5| Step: 4
Training loss: 2.381916015079681
Validation loss: 2.463930632925615

Epoch: 5| Step: 5
Training loss: 2.3104434792350466
Validation loss: 2.462039757172574

Epoch: 5| Step: 6
Training loss: 2.7220791132499262
Validation loss: 2.4596699917034077

Epoch: 5| Step: 7
Training loss: 2.132414392897377
Validation loss: 2.456336286515933

Epoch: 5| Step: 8
Training loss: 2.6106441860393526
Validation loss: 2.4563145929115078

Epoch: 5| Step: 9
Training loss: 2.647919910908134
Validation loss: 2.4599413233054945

Epoch: 5| Step: 10
Training loss: 2.437025464156162
Validation loss: 2.450075011013322

Epoch: 5| Step: 11
Training loss: 2.945117731509831
Validation loss: 2.4478574475098664

Epoch: 155| Step: 0
Training loss: 2.4227846467734424
Validation loss: 2.445977426299481

Epoch: 5| Step: 1
Training loss: 2.3397439925846975
Validation loss: 2.4469449664587715

Epoch: 5| Step: 2
Training loss: 2.5234266345850154
Validation loss: 2.4491342695269083

Epoch: 5| Step: 3
Training loss: 2.651660949282074
Validation loss: 2.4494666461325822

Epoch: 5| Step: 4
Training loss: 2.5555969859188
Validation loss: 2.4514601458158127

Epoch: 5| Step: 5
Training loss: 2.143708062387317
Validation loss: 2.448084956667735

Epoch: 5| Step: 6
Training loss: 2.807810879867672
Validation loss: 2.4477871853828552

Epoch: 5| Step: 7
Training loss: 2.9810659227782446
Validation loss: 2.4496641468950098

Epoch: 5| Step: 8
Training loss: 1.9819973495765926
Validation loss: 2.45411172690907

Epoch: 5| Step: 9
Training loss: 2.332167424965731
Validation loss: 2.4538804124251006

Epoch: 5| Step: 10
Training loss: 2.19996925679314
Validation loss: 2.448806736152363

Epoch: 5| Step: 11
Training loss: 3.86463575850279
Validation loss: 2.45386595581097

Epoch: 156| Step: 0
Training loss: 2.732284880578915
Validation loss: 2.4534892765422636

Epoch: 5| Step: 1
Training loss: 2.0557812002700553
Validation loss: 2.4491060546387295

Epoch: 5| Step: 2
Training loss: 2.415078452437312
Validation loss: 2.451037646667409

Epoch: 5| Step: 3
Training loss: 2.695377868744225
Validation loss: 2.451384414840472

Epoch: 5| Step: 4
Training loss: 1.8708413099134469
Validation loss: 2.4496051538279264

Epoch: 5| Step: 5
Training loss: 2.513513093214989
Validation loss: 2.4518648746011404

Epoch: 5| Step: 6
Training loss: 2.3674473383846184
Validation loss: 2.4526876152803307

Epoch: 5| Step: 7
Training loss: 2.3359920023297875
Validation loss: 2.4638687841385285

Epoch: 5| Step: 8
Training loss: 2.1470967496155065
Validation loss: 2.458798022451723

Epoch: 5| Step: 9
Training loss: 2.5217602709608973
Validation loss: 2.4714744037499177

Epoch: 5| Step: 10
Training loss: 3.2038528731875666
Validation loss: 2.4569172350089223

Epoch: 5| Step: 11
Training loss: 3.0009271460603495
Validation loss: 2.461639945882339

Epoch: 157| Step: 0
Training loss: 2.307319095583442
Validation loss: 2.471425656703941

Epoch: 5| Step: 1
Training loss: 2.289426078174514
Validation loss: 2.4756799483146077

Epoch: 5| Step: 2
Training loss: 2.4296138053094856
Validation loss: 2.466694587848054

Epoch: 5| Step: 3
Training loss: 2.765123828370868
Validation loss: 2.4840294979576396

Epoch: 5| Step: 4
Training loss: 2.746420872007998
Validation loss: 2.4758364097394634

Epoch: 5| Step: 5
Training loss: 2.171208011658237
Validation loss: 2.463474024085272

Epoch: 5| Step: 6
Training loss: 2.5756944701340267
Validation loss: 2.460676480130133

Epoch: 5| Step: 7
Training loss: 2.162293299680405
Validation loss: 2.4598197497710848

Epoch: 5| Step: 8
Training loss: 2.4670517307296067
Validation loss: 2.4618814181996074

Epoch: 5| Step: 9
Training loss: 2.5700833760552375
Validation loss: 2.45609530446296

Epoch: 5| Step: 10
Training loss: 2.7563338597833416
Validation loss: 2.4598788532546294

Epoch: 5| Step: 11
Training loss: 1.7468523600685884
Validation loss: 2.4599885473333654

Epoch: 158| Step: 0
Training loss: 2.6346642748298033
Validation loss: 2.4611463791135995

Epoch: 5| Step: 1
Training loss: 2.581734459883529
Validation loss: 2.4627856263203616

Epoch: 5| Step: 2
Training loss: 2.444799399854676
Validation loss: 2.468285259332033

Epoch: 5| Step: 3
Training loss: 2.8288416507722807
Validation loss: 2.462944483943312

Epoch: 5| Step: 4
Training loss: 1.9373218085271537
Validation loss: 2.4680886449106136

Epoch: 5| Step: 5
Training loss: 2.228495297686105
Validation loss: 2.465844593495087

Epoch: 5| Step: 6
Training loss: 2.6467974150364997
Validation loss: 2.4648246502425954

Epoch: 5| Step: 7
Training loss: 2.8617802077267265
Validation loss: 2.4607051517660583

Epoch: 5| Step: 8
Training loss: 2.483218229643036
Validation loss: 2.4599083014845378

Epoch: 5| Step: 9
Training loss: 2.1909519751476902
Validation loss: 2.456347258618369

Epoch: 5| Step: 10
Training loss: 2.4686431861658393
Validation loss: 2.461241082736669

Epoch: 5| Step: 11
Training loss: 2.58687922453184
Validation loss: 2.4634528752321834

Epoch: 159| Step: 0
Training loss: 2.894033041638217
Validation loss: 2.4589257105787503

Epoch: 5| Step: 1
Training loss: 2.5260161932745606
Validation loss: 2.47344429832901

Epoch: 5| Step: 2
Training loss: 1.9562645664830585
Validation loss: 2.4762214762793837

Epoch: 5| Step: 3
Training loss: 2.623194209638454
Validation loss: 2.466285392789556

Epoch: 5| Step: 4
Training loss: 2.371666124316556
Validation loss: 2.456346910811967

Epoch: 5| Step: 5
Training loss: 2.36287071508469
Validation loss: 2.4642441952902017

Epoch: 5| Step: 6
Training loss: 2.607313060990232
Validation loss: 2.462667777305138

Epoch: 5| Step: 7
Training loss: 2.5855950535032903
Validation loss: 2.4602766491883763

Epoch: 5| Step: 8
Training loss: 2.1906346341300833
Validation loss: 2.460444325273587

Epoch: 5| Step: 9
Training loss: 2.5840854985409307
Validation loss: 2.4610622434940734

Epoch: 5| Step: 10
Training loss: 2.028885389359571
Validation loss: 2.4588491873814293

Epoch: 5| Step: 11
Training loss: 3.331612349336645
Validation loss: 2.4588725635497815

Epoch: 160| Step: 0
Training loss: 2.541204587696701
Validation loss: 2.460972163042039

Epoch: 5| Step: 1
Training loss: 1.7387634294376577
Validation loss: 2.4607609115297175

Epoch: 5| Step: 2
Training loss: 2.256306816083137
Validation loss: 2.46391344121517

Epoch: 5| Step: 3
Training loss: 2.3857801624075514
Validation loss: 2.4571692989444545

Epoch: 5| Step: 4
Training loss: 3.004114825841519
Validation loss: 2.4580041427898127

Epoch: 5| Step: 5
Training loss: 2.288793762888672
Validation loss: 2.4684704046828707

Epoch: 5| Step: 6
Training loss: 2.6042298169426457
Validation loss: 2.465042593905885

Epoch: 5| Step: 7
Training loss: 2.3596729823016878
Validation loss: 2.463295387286378

Epoch: 5| Step: 8
Training loss: 3.0094573044341257
Validation loss: 2.4743848064986596

Epoch: 5| Step: 9
Training loss: 2.1792511315202243
Validation loss: 2.4881448952899077

Epoch: 5| Step: 10
Training loss: 2.6725104396177244
Validation loss: 2.477639458526379

Epoch: 5| Step: 11
Training loss: 2.1862581270131183
Validation loss: 2.4724267307684267

Epoch: 161| Step: 0
Training loss: 2.255256446753894
Validation loss: 2.459634474267303

Epoch: 5| Step: 1
Training loss: 2.0137472943335744
Validation loss: 2.465382073364777

Epoch: 5| Step: 2
Training loss: 2.488192905552481
Validation loss: 2.465524687215171

Epoch: 5| Step: 3
Training loss: 2.5324430126771413
Validation loss: 2.4592269705073853

Epoch: 5| Step: 4
Training loss: 2.5001523925110662
Validation loss: 2.4633474911922555

Epoch: 5| Step: 5
Training loss: 2.3974999201260454
Validation loss: 2.4606983492467887

Epoch: 5| Step: 6
Training loss: 2.650927967763552
Validation loss: 2.4596519099433607

Epoch: 5| Step: 7
Training loss: 2.8073174092676005
Validation loss: 2.4624897194178192

Epoch: 5| Step: 8
Training loss: 2.4994057902838414
Validation loss: 2.4543519970701757

Epoch: 5| Step: 9
Training loss: 2.580058349718405
Validation loss: 2.4595455794775987

Epoch: 5| Step: 10
Training loss: 2.5301463228816727
Validation loss: 2.459861600918871

Epoch: 5| Step: 11
Training loss: 2.2261041537558706
Validation loss: 2.4571525976380313

Epoch: 162| Step: 0
Training loss: 2.758758209866198
Validation loss: 2.452503080965596

Epoch: 5| Step: 1
Training loss: 2.042194635543674
Validation loss: 2.464506072759805

Epoch: 5| Step: 2
Training loss: 2.0006706782199837
Validation loss: 2.452769494669738

Epoch: 5| Step: 3
Training loss: 2.174396944299871
Validation loss: 2.4488334575787096

Epoch: 5| Step: 4
Training loss: 2.6076191916796283
Validation loss: 2.455643161199386

Epoch: 5| Step: 5
Training loss: 2.438807992406972
Validation loss: 2.4575535512724906

Epoch: 5| Step: 6
Training loss: 2.481757842780769
Validation loss: 2.4565117655262108

Epoch: 5| Step: 7
Training loss: 2.533044720405171
Validation loss: 2.4568002063536447

Epoch: 5| Step: 8
Training loss: 2.7301201550098515
Validation loss: 2.4582107373288515

Epoch: 5| Step: 9
Training loss: 2.7154466577051894
Validation loss: 2.464237511385846

Epoch: 5| Step: 10
Training loss: 2.429982256412481
Validation loss: 2.4561468533058486

Epoch: 5| Step: 11
Training loss: 3.0340384016731146
Validation loss: 2.459000655835677

Epoch: 163| Step: 0
Training loss: 2.664466536415036
Validation loss: 2.466551912759378

Epoch: 5| Step: 1
Training loss: 2.035449572492083
Validation loss: 2.468596505974578

Epoch: 5| Step: 2
Training loss: 2.37125854925003
Validation loss: 2.4612408445997493

Epoch: 5| Step: 3
Training loss: 2.5491830863644136
Validation loss: 2.4637420053995873

Epoch: 5| Step: 4
Training loss: 2.2769898651661444
Validation loss: 2.463491468879211

Epoch: 5| Step: 5
Training loss: 2.5454894433477953
Validation loss: 2.4612226532927535

Epoch: 5| Step: 6
Training loss: 2.4803822419708177
Validation loss: 2.475711784700359

Epoch: 5| Step: 7
Training loss: 2.974559039606129
Validation loss: 2.462132013648466

Epoch: 5| Step: 8
Training loss: 2.2669089000892186
Validation loss: 2.4709726259510467

Epoch: 5| Step: 9
Training loss: 2.509031100716285
Validation loss: 2.467370054011254

Epoch: 5| Step: 10
Training loss: 2.4731978897409013
Validation loss: 2.4820625931575186

Epoch: 5| Step: 11
Training loss: 1.6996030175684793
Validation loss: 2.4720232305438246

Epoch: 164| Step: 0
Training loss: 3.1073951744021007
Validation loss: 2.4678787009731153

Epoch: 5| Step: 1
Training loss: 2.8699520410126023
Validation loss: 2.4682644314221207

Epoch: 5| Step: 2
Training loss: 2.0194521506662557
Validation loss: 2.4743514956554122

Epoch: 5| Step: 3
Training loss: 2.1003334961341045
Validation loss: 2.4657442933504226

Epoch: 5| Step: 4
Training loss: 1.841364659133846
Validation loss: 2.46281436214208

Epoch: 5| Step: 5
Training loss: 2.1143361841349253
Validation loss: 2.4698732774224825

Epoch: 5| Step: 6
Training loss: 2.244598156110748
Validation loss: 2.467201475587431

Epoch: 5| Step: 7
Training loss: 2.7916772377231545
Validation loss: 2.4800687732761553

Epoch: 5| Step: 8
Training loss: 2.9798733777788637
Validation loss: 2.460044698890623

Epoch: 5| Step: 9
Training loss: 2.4503825219931183
Validation loss: 2.459147867267495

Epoch: 5| Step: 10
Training loss: 1.995355757062951
Validation loss: 2.4638379236742085

Epoch: 5| Step: 11
Training loss: 2.677745504655253
Validation loss: 2.46208163110667

Epoch: 165| Step: 0
Training loss: 2.632121552944757
Validation loss: 2.463002734011218

Epoch: 5| Step: 1
Training loss: 2.5908446068169284
Validation loss: 2.455950347119932

Epoch: 5| Step: 2
Training loss: 2.4131905669281055
Validation loss: 2.459371300500255

Epoch: 5| Step: 3
Training loss: 2.342285003566677
Validation loss: 2.464214702123389

Epoch: 5| Step: 4
Training loss: 2.8561987406932823
Validation loss: 2.47042359792563

Epoch: 5| Step: 5
Training loss: 2.5070484934659896
Validation loss: 2.473086749020358

Epoch: 5| Step: 6
Training loss: 2.4710478892670262
Validation loss: 2.4663296435992295

Epoch: 5| Step: 7
Training loss: 2.5479833145553448
Validation loss: 2.4543850835281056

Epoch: 5| Step: 8
Training loss: 2.2761896523232648
Validation loss: 2.4660069763234964

Epoch: 5| Step: 9
Training loss: 2.634586268740138
Validation loss: 2.4647791632862135

Epoch: 5| Step: 10
Training loss: 2.249707202933725
Validation loss: 2.4590429814641426

Epoch: 5| Step: 11
Training loss: 2.264026472543483
Validation loss: 2.453999742024218

Epoch: 166| Step: 0
Training loss: 2.397562768331286
Validation loss: 2.4554339474477165

Epoch: 5| Step: 1
Training loss: 2.637458211558717
Validation loss: 2.455422247068946

Epoch: 5| Step: 2
Training loss: 2.0846265466625655
Validation loss: 2.4526595101249073

Epoch: 5| Step: 3
Training loss: 3.285729103173437
Validation loss: 2.463751839724647

Epoch: 5| Step: 4
Training loss: 2.56481549854272
Validation loss: 2.4663244395583113

Epoch: 5| Step: 5
Training loss: 2.669899907611257
Validation loss: 2.4693603203846552

Epoch: 5| Step: 6
Training loss: 2.526254882203773
Validation loss: 2.4796629430351738

Epoch: 5| Step: 7
Training loss: 2.237853750043933
Validation loss: 2.4710504782746625

Epoch: 5| Step: 8
Training loss: 2.6589157192018793
Validation loss: 2.4714362663778733

Epoch: 5| Step: 9
Training loss: 1.9987142125230597
Validation loss: 2.463713195722006

Epoch: 5| Step: 10
Training loss: 2.3230255397947777
Validation loss: 2.4628011317660925

Epoch: 5| Step: 11
Training loss: 2.080663063294724
Validation loss: 2.4582747692201425

Epoch: 167| Step: 0
Training loss: 2.690677450025492
Validation loss: 2.4617749439291754

Epoch: 5| Step: 1
Training loss: 2.2298151184215493
Validation loss: 2.4609010966197027

Epoch: 5| Step: 2
Training loss: 2.4589112674671396
Validation loss: 2.4607547066431112

Epoch: 5| Step: 3
Training loss: 3.0442164633502036
Validation loss: 2.459231650292002

Epoch: 5| Step: 4
Training loss: 2.278865142441049
Validation loss: 2.4594172186905547

Epoch: 5| Step: 5
Training loss: 2.408949786513636
Validation loss: 2.458949013299971

Epoch: 5| Step: 6
Training loss: 2.3885051828207984
Validation loss: 2.4582772100367687

Epoch: 5| Step: 7
Training loss: 2.529494724857088
Validation loss: 2.4629128576369808

Epoch: 5| Step: 8
Training loss: 2.1870151527413597
Validation loss: 2.459617922983045

Epoch: 5| Step: 9
Training loss: 2.778658055591725
Validation loss: 2.4614937128491294

Epoch: 5| Step: 10
Training loss: 2.3110303590597
Validation loss: 2.45801407281894

Epoch: 5| Step: 11
Training loss: 2.04968918560812
Validation loss: 2.4600382539442016

Epoch: 168| Step: 0
Training loss: 2.2250060949349235
Validation loss: 2.4616654464840906

Epoch: 5| Step: 1
Training loss: 2.618571265774141
Validation loss: 2.466734365122783

Epoch: 5| Step: 2
Training loss: 2.2874874385634762
Validation loss: 2.4619572055763346

Epoch: 5| Step: 3
Training loss: 2.522879335067919
Validation loss: 2.461266258522504

Epoch: 5| Step: 4
Training loss: 2.6214553879152853
Validation loss: 2.469829789962439

Epoch: 5| Step: 5
Training loss: 2.0055671932250307
Validation loss: 2.4549845068417455

Epoch: 5| Step: 6
Training loss: 2.9284937346516626
Validation loss: 2.4642853827374265

Epoch: 5| Step: 7
Training loss: 2.394642166132719
Validation loss: 2.4622970942830045

Epoch: 5| Step: 8
Training loss: 2.4797197788111065
Validation loss: 2.470523024517289

Epoch: 5| Step: 9
Training loss: 2.051335723034187
Validation loss: 2.4634476872934017

Epoch: 5| Step: 10
Training loss: 2.771943627575566
Validation loss: 2.475824019340613

Epoch: 5| Step: 11
Training loss: 2.6977356564003756
Validation loss: 2.4705452608480156

Epoch: 169| Step: 0
Training loss: 2.3600024469007317
Validation loss: 2.4743993319254285

Epoch: 5| Step: 1
Training loss: 2.337937127513704
Validation loss: 2.4787149672309785

Epoch: 5| Step: 2
Training loss: 2.7975905371530185
Validation loss: 2.4790225641594006

Epoch: 5| Step: 3
Training loss: 2.606046095082515
Validation loss: 2.473276129908946

Epoch: 5| Step: 4
Training loss: 1.9326548136575403
Validation loss: 2.47386739998726

Epoch: 5| Step: 5
Training loss: 2.3594965619229704
Validation loss: 2.470345609227089

Epoch: 5| Step: 6
Training loss: 2.0735025264889253
Validation loss: 2.4764267034835474

Epoch: 5| Step: 7
Training loss: 2.913763035990955
Validation loss: 2.4784108153042474

Epoch: 5| Step: 8
Training loss: 2.6189996167940413
Validation loss: 2.4726141373120103

Epoch: 5| Step: 9
Training loss: 2.319856027213653
Validation loss: 2.4699217031787413

Epoch: 5| Step: 10
Training loss: 2.4722445900104004
Validation loss: 2.4718385683277373

Epoch: 5| Step: 11
Training loss: 3.0594733716289384
Validation loss: 2.477288650129314

Epoch: 170| Step: 0
Training loss: 2.274456936082866
Validation loss: 2.4778213911489964

Epoch: 5| Step: 1
Training loss: 2.573998958483695
Validation loss: 2.475217716839372

Epoch: 5| Step: 2
Training loss: 2.760441205377493
Validation loss: 2.4737576788124027

Epoch: 5| Step: 3
Training loss: 2.20821544644454
Validation loss: 2.476926193247305

Epoch: 5| Step: 4
Training loss: 2.387420301455272
Validation loss: 2.4870836459011763

Epoch: 5| Step: 5
Training loss: 2.8477141867605917
Validation loss: 2.4746777756613083

Epoch: 5| Step: 6
Training loss: 2.1704169119868144
Validation loss: 2.487274139779855

Epoch: 5| Step: 7
Training loss: 2.2053500363448877
Validation loss: 2.4783295465614446

Epoch: 5| Step: 8
Training loss: 2.0213802292390333
Validation loss: 2.4799932469640074

Epoch: 5| Step: 9
Training loss: 2.6122590533397276
Validation loss: 2.4795153810714177

Epoch: 5| Step: 10
Training loss: 2.3679334012989175
Validation loss: 2.4834405953222514

Epoch: 5| Step: 11
Training loss: 3.895848333700476
Validation loss: 2.484794961074185

Epoch: 171| Step: 0
Training loss: 2.653259029530137
Validation loss: 2.4843883314114885

Epoch: 5| Step: 1
Training loss: 2.4962207839471
Validation loss: 2.4757700393308983

Epoch: 5| Step: 2
Training loss: 2.374673720584754
Validation loss: 2.4860033061334685

Epoch: 5| Step: 3
Training loss: 2.142598599776828
Validation loss: 2.484186953099531

Epoch: 5| Step: 4
Training loss: 2.6044087005038694
Validation loss: 2.475555901279355

Epoch: 5| Step: 5
Training loss: 2.831095279061794
Validation loss: 2.476162409830766

Epoch: 5| Step: 6
Training loss: 2.9441678279122563
Validation loss: 2.470010990705246

Epoch: 5| Step: 7
Training loss: 1.7012961130948847
Validation loss: 2.4743366728484366

Epoch: 5| Step: 8
Training loss: 2.69968649845522
Validation loss: 2.4709689594139785

Epoch: 5| Step: 9
Training loss: 1.9415211940947594
Validation loss: 2.473081603384079

Epoch: 5| Step: 10
Training loss: 2.30817462453582
Validation loss: 2.4733403802706624

Epoch: 5| Step: 11
Training loss: 2.3468995358420117
Validation loss: 2.4867108198593337

Epoch: 172| Step: 0
Training loss: 2.258288270657914
Validation loss: 2.483773868537616

Epoch: 5| Step: 1
Training loss: 3.068267374098137
Validation loss: 2.488703206374587

Epoch: 5| Step: 2
Training loss: 1.943940686259001
Validation loss: 2.481654206798249

Epoch: 5| Step: 3
Training loss: 2.3340605783192863
Validation loss: 2.486273637860298

Epoch: 5| Step: 4
Training loss: 2.2573889100717
Validation loss: 2.482725967682204

Epoch: 5| Step: 5
Training loss: 2.244395375213726
Validation loss: 2.483483384440007

Epoch: 5| Step: 6
Training loss: 2.636075044400192
Validation loss: 2.47665288381177

Epoch: 5| Step: 7
Training loss: 2.182325728582313
Validation loss: 2.4786263780070135

Epoch: 5| Step: 8
Training loss: 2.503539536115382
Validation loss: 2.4754984542366976

Epoch: 5| Step: 9
Training loss: 3.1259912063269932
Validation loss: 2.479502588375233

Epoch: 5| Step: 10
Training loss: 2.220727388623493
Validation loss: 2.469210396663842

Epoch: 5| Step: 11
Training loss: 1.608710587025403
Validation loss: 2.4738975691443774

Epoch: 173| Step: 0
Training loss: 2.0938155889913337
Validation loss: 2.4744159409117445

Epoch: 5| Step: 1
Training loss: 2.3144110953462262
Validation loss: 2.4758377739635264

Epoch: 5| Step: 2
Training loss: 2.5077507035196738
Validation loss: 2.4905516059620187

Epoch: 5| Step: 3
Training loss: 1.7881938041348426
Validation loss: 2.4776224461388305

Epoch: 5| Step: 4
Training loss: 2.865261002347302
Validation loss: 2.478006293046107

Epoch: 5| Step: 5
Training loss: 2.9896862442079355
Validation loss: 2.4814002102883115

Epoch: 5| Step: 6
Training loss: 2.9658682238062917
Validation loss: 2.4799656675702835

Epoch: 5| Step: 7
Training loss: 2.0810449493481094
Validation loss: 2.4779572194768034

Epoch: 5| Step: 8
Training loss: 2.415636062103249
Validation loss: 2.483313523657298

Epoch: 5| Step: 9
Training loss: 2.36202480239831
Validation loss: 2.485390501585413

Epoch: 5| Step: 10
Training loss: 2.2951223732230157
Validation loss: 2.4865293818405685

Epoch: 5| Step: 11
Training loss: 1.9288753391166935
Validation loss: 2.482673618248615

Epoch: 174| Step: 0
Training loss: 2.2278236431475094
Validation loss: 2.465760175015691

Epoch: 5| Step: 1
Training loss: 2.521487117089185
Validation loss: 2.467926300430838

Epoch: 5| Step: 2
Training loss: 2.5192997789142915
Validation loss: 2.4656427280447843

Epoch: 5| Step: 3
Training loss: 2.550509054198176
Validation loss: 2.4722276047911134

Epoch: 5| Step: 4
Training loss: 2.6765498261783547
Validation loss: 2.4745404264724695

Epoch: 5| Step: 5
Training loss: 2.031043761127031
Validation loss: 2.4741472707512586

Epoch: 5| Step: 6
Training loss: 2.4553879911788568
Validation loss: 2.4740664341381216

Epoch: 5| Step: 7
Training loss: 2.739918087618966
Validation loss: 2.475251927061069

Epoch: 5| Step: 8
Training loss: 2.490750942133176
Validation loss: 2.477342703313896

Epoch: 5| Step: 9
Training loss: 2.3378781833811595
Validation loss: 2.4801775062970495

Epoch: 5| Step: 10
Training loss: 2.4546296188746957
Validation loss: 2.4755310373532713

Epoch: 5| Step: 11
Training loss: 1.7192895215889064
Validation loss: 2.477368625727303

Epoch: 175| Step: 0
Training loss: 2.341346321955536
Validation loss: 2.4698132748237107

Epoch: 5| Step: 1
Training loss: 2.185705266127155
Validation loss: 2.4729172627599096

Epoch: 5| Step: 2
Training loss: 1.9201763058221175
Validation loss: 2.4747393502954482

Epoch: 5| Step: 3
Training loss: 2.257998871288575
Validation loss: 2.4699279574326822

Epoch: 5| Step: 4
Training loss: 2.2359061163639784
Validation loss: 2.4739799712723904

Epoch: 5| Step: 5
Training loss: 2.521087875335724
Validation loss: 2.4725054131934936

Epoch: 5| Step: 6
Training loss: 2.5887262801737285
Validation loss: 2.4709250449731925

Epoch: 5| Step: 7
Training loss: 2.660195416177578
Validation loss: 2.470102149135579

Epoch: 5| Step: 8
Training loss: 2.4445629982183523
Validation loss: 2.4725825945112208

Epoch: 5| Step: 9
Training loss: 3.2125188270343714
Validation loss: 2.477591067339596

Epoch: 5| Step: 10
Training loss: 2.2797664887494724
Validation loss: 2.4853270923581507

Epoch: 5| Step: 11
Training loss: 2.225471095243468
Validation loss: 2.4824385743738753

Testing loss: 1.9872859452071348
