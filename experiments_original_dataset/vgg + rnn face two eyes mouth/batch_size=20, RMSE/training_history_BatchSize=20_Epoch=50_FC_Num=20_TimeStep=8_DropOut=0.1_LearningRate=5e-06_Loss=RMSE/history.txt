Epoch: 1| Step: 0
Training loss: 6.337388028993435
Validation loss: 5.866530515795967

Epoch: 5| Step: 1
Training loss: 6.171261527560855
Validation loss: 5.864232598810891

Epoch: 5| Step: 2
Training loss: 5.818855010989362
Validation loss: 5.86200945143218

Epoch: 5| Step: 3
Training loss: 5.701251163695822
Validation loss: 5.859968686014731

Epoch: 5| Step: 4
Training loss: 5.986738808812475
Validation loss: 5.857958141682682

Epoch: 5| Step: 5
Training loss: 5.340221824182
Validation loss: 5.855899386934782

Epoch: 5| Step: 6
Training loss: 6.143774103561727
Validation loss: 5.853828924986868

Epoch: 5| Step: 7
Training loss: 6.8182807683989335
Validation loss: 5.85173293146902

Epoch: 5| Step: 8
Training loss: 6.187819347425003
Validation loss: 5.849638761468862

Epoch: 5| Step: 9
Training loss: 5.816752201242055
Validation loss: 5.847255294668017

Epoch: 5| Step: 10
Training loss: 5.384811141050378
Validation loss: 5.845021141912482

Epoch: 5| Step: 11
Training loss: 5.133697758574379
Validation loss: 5.8426688991101585

Epoch: 2| Step: 0
Training loss: 5.40880687425411
Validation loss: 5.840169914943971

Epoch: 5| Step: 1
Training loss: 6.114852907995889
Validation loss: 5.837460803785932

Epoch: 5| Step: 2
Training loss: 6.212541864818228
Validation loss: 5.83466674233282

Epoch: 5| Step: 3
Training loss: 6.013913552711115
Validation loss: 5.8318515348754465

Epoch: 5| Step: 4
Training loss: 5.427628600197298
Validation loss: 5.828765833909046

Epoch: 5| Step: 5
Training loss: 6.0937931939574925
Validation loss: 5.825672564337424

Epoch: 5| Step: 6
Training loss: 5.719224920512066
Validation loss: 5.822232646948984

Epoch: 5| Step: 7
Training loss: 6.774807871666772
Validation loss: 5.818673782586998

Epoch: 5| Step: 8
Training loss: 5.910077504845537
Validation loss: 5.815181168488995

Epoch: 5| Step: 9
Training loss: 5.901965004807192
Validation loss: 5.81126026892512

Epoch: 5| Step: 10
Training loss: 5.735018244533902
Validation loss: 5.807195546904284

Epoch: 5| Step: 11
Training loss: 5.506818879235195
Validation loss: 5.802807318161458

Epoch: 3| Step: 0
Training loss: 6.355067788519623
Validation loss: 5.798090235855489

Epoch: 5| Step: 1
Training loss: 6.712638026688445
Validation loss: 5.793497361124375

Epoch: 5| Step: 2
Training loss: 5.7073226739419765
Validation loss: 5.788332002018846

Epoch: 5| Step: 3
Training loss: 5.329073376866777
Validation loss: 5.78300344321478

Epoch: 5| Step: 4
Training loss: 5.467321590797203
Validation loss: 5.777320653711475

Epoch: 5| Step: 5
Training loss: 6.279549287792277
Validation loss: 5.7713744831327185

Epoch: 5| Step: 6
Training loss: 5.0446988070118515
Validation loss: 5.765174572450082

Epoch: 5| Step: 7
Training loss: 6.329986825841901
Validation loss: 5.758943533781152

Epoch: 5| Step: 8
Training loss: 5.643259210041547
Validation loss: 5.752109693415931

Epoch: 5| Step: 9
Training loss: 6.013455244859946
Validation loss: 5.744870323364344

Epoch: 5| Step: 10
Training loss: 5.835315839755979
Validation loss: 5.737191515949417

Epoch: 5| Step: 11
Training loss: 4.822565031587104
Validation loss: 5.729388342527956

Epoch: 4| Step: 0
Training loss: 5.843268226714904
Validation loss: 5.721036874142079

Epoch: 5| Step: 1
Training loss: 5.960417198582021
Validation loss: 5.712664793936101

Epoch: 5| Step: 2
Training loss: 6.347697415731901
Validation loss: 5.703460829788824

Epoch: 5| Step: 3
Training loss: 5.80965099448619
Validation loss: 5.694181332544419

Epoch: 5| Step: 4
Training loss: 5.909482041332064
Validation loss: 5.6843692141282025

Epoch: 5| Step: 5
Training loss: 6.174041908470401
Validation loss: 5.6744423372410715

Epoch: 5| Step: 6
Training loss: 5.729538044307924
Validation loss: 5.664451455978724

Epoch: 5| Step: 7
Training loss: 5.638118451149236
Validation loss: 5.653244948498463

Epoch: 5| Step: 8
Training loss: 5.843638373140073
Validation loss: 5.642491821600886

Epoch: 5| Step: 9
Training loss: 5.981503268214125
Validation loss: 5.631006036710363

Epoch: 5| Step: 10
Training loss: 4.322534579507726
Validation loss: 5.618998865507968

Epoch: 5| Step: 11
Training loss: 5.188182923738416
Validation loss: 5.60758468974415

Epoch: 5| Step: 0
Training loss: 4.92081093563675
Validation loss: 5.595730045735399

Epoch: 5| Step: 1
Training loss: 4.98151911411832
Validation loss: 5.583780650349424

Epoch: 5| Step: 2
Training loss: 5.785142402709626
Validation loss: 5.571791421773688

Epoch: 5| Step: 3
Training loss: 5.628618390507738
Validation loss: 5.559880893755696

Epoch: 5| Step: 4
Training loss: 6.4590587905828105
Validation loss: 5.54787054306532

Epoch: 5| Step: 5
Training loss: 6.314777529943992
Validation loss: 5.535573925196015

Epoch: 5| Step: 6
Training loss: 5.692562323603095
Validation loss: 5.523300600850818

Epoch: 5| Step: 7
Training loss: 4.470930301198925
Validation loss: 5.510869527379014

Epoch: 5| Step: 8
Training loss: 6.2412698426896736
Validation loss: 5.499287212307139

Epoch: 5| Step: 9
Training loss: 6.014132703498732
Validation loss: 5.486952948330336

Epoch: 5| Step: 10
Training loss: 4.921814158230103
Validation loss: 5.475157096211504

Epoch: 5| Step: 11
Training loss: 7.085433050366821
Validation loss: 5.463781115797429

Epoch: 6| Step: 0
Training loss: 5.50929220897938
Validation loss: 5.45217549128684

Epoch: 5| Step: 1
Training loss: 5.046875944816572
Validation loss: 5.440616291995221

Epoch: 5| Step: 2
Training loss: 6.564582131096252
Validation loss: 5.429779886241901

Epoch: 5| Step: 3
Training loss: 5.325298734353541
Validation loss: 5.418524887999812

Epoch: 5| Step: 4
Training loss: 5.302376289992885
Validation loss: 5.407963703477162

Epoch: 5| Step: 5
Training loss: 5.732499733287274
Validation loss: 5.397509092517925

Epoch: 5| Step: 6
Training loss: 5.953803877281386
Validation loss: 5.387539777734277

Epoch: 5| Step: 7
Training loss: 6.618147274883718
Validation loss: 5.377467217598905

Epoch: 5| Step: 8
Training loss: 4.027893561675811
Validation loss: 5.3676597169075695

Epoch: 5| Step: 9
Training loss: 5.127412925810401
Validation loss: 5.358308001923592

Epoch: 5| Step: 10
Training loss: 5.164964005676287
Validation loss: 5.349049474230054

Epoch: 5| Step: 11
Training loss: 4.736443096220555
Validation loss: 5.340339836660639

Epoch: 7| Step: 0
Training loss: 5.3201278676893144
Validation loss: 5.3319059438735

Epoch: 5| Step: 1
Training loss: 5.309989066534765
Validation loss: 5.323563555721719

Epoch: 5| Step: 2
Training loss: 5.590270595927657
Validation loss: 5.315374337307122

Epoch: 5| Step: 3
Training loss: 5.977769996483587
Validation loss: 5.3072225536854045

Epoch: 5| Step: 4
Training loss: 5.8802521948675075
Validation loss: 5.299121721539713

Epoch: 5| Step: 5
Training loss: 5.406194609429936
Validation loss: 5.29154459244301

Epoch: 5| Step: 6
Training loss: 5.9476982472985265
Validation loss: 5.283764633640962

Epoch: 5| Step: 7
Training loss: 4.9424701254081205
Validation loss: 5.276295521821512

Epoch: 5| Step: 8
Training loss: 4.796879970287022
Validation loss: 5.268932892026015

Epoch: 5| Step: 9
Training loss: 5.103208781557351
Validation loss: 5.261787208313802

Epoch: 5| Step: 10
Training loss: 5.397816513272929
Validation loss: 5.2548392411652625

Epoch: 5| Step: 11
Training loss: 3.9985988070114753
Validation loss: 5.2478694907088785

Epoch: 8| Step: 0
Training loss: 5.2003334965501775
Validation loss: 5.241369070794124

Epoch: 5| Step: 1
Training loss: 5.028796053644004
Validation loss: 5.234088020618549

Epoch: 5| Step: 2
Training loss: 5.725567199062165
Validation loss: 5.2275315219409775

Epoch: 5| Step: 3
Training loss: 5.862093444912386
Validation loss: 5.221029921917871

Epoch: 5| Step: 4
Training loss: 5.863546041447597
Validation loss: 5.214293543522948

Epoch: 5| Step: 5
Training loss: 4.893942003636837
Validation loss: 5.20686776204305

Epoch: 5| Step: 6
Training loss: 5.040975896419388
Validation loss: 5.1998688644600035

Epoch: 5| Step: 7
Training loss: 4.867482575952097
Validation loss: 5.192647433011507

Epoch: 5| Step: 8
Training loss: 4.852242193355409
Validation loss: 5.185884017185823

Epoch: 5| Step: 9
Training loss: 6.000902743774004
Validation loss: 5.178643805682392

Epoch: 5| Step: 10
Training loss: 5.338971059014475
Validation loss: 5.171472070831423

Epoch: 5| Step: 11
Training loss: 4.050850230322145
Validation loss: 5.163888332952194

Epoch: 9| Step: 0
Training loss: 5.5344473870151365
Validation loss: 5.156890413221738

Epoch: 5| Step: 1
Training loss: 5.057614453350535
Validation loss: 5.149530907287996

Epoch: 5| Step: 2
Training loss: 5.459286245007825
Validation loss: 5.142264300916231

Epoch: 5| Step: 3
Training loss: 5.0733065706634095
Validation loss: 5.135269498231635

Epoch: 5| Step: 4
Training loss: 5.177708588675887
Validation loss: 5.1274723741892885

Epoch: 5| Step: 5
Training loss: 4.869410905555073
Validation loss: 5.120079345485674

Epoch: 5| Step: 6
Training loss: 5.233764612848487
Validation loss: 5.113161680622099

Epoch: 5| Step: 7
Training loss: 4.1858439800641705
Validation loss: 5.105881199305991

Epoch: 5| Step: 8
Training loss: 4.949580997496783
Validation loss: 5.099536183714822

Epoch: 5| Step: 9
Training loss: 6.348171253146637
Validation loss: 5.092442896726769

Epoch: 5| Step: 10
Training loss: 5.674855691696664
Validation loss: 5.085523605107869

Epoch: 5| Step: 11
Training loss: 4.400064441902585
Validation loss: 5.078490587426143

Epoch: 10| Step: 0
Training loss: 5.557561160569157
Validation loss: 5.072140740722812

Epoch: 5| Step: 1
Training loss: 5.188918689548724
Validation loss: 5.065911787772333

Epoch: 5| Step: 2
Training loss: 4.446941378990039
Validation loss: 5.059201724168113

Epoch: 5| Step: 3
Training loss: 4.686927251792866
Validation loss: 5.053262264956433

Epoch: 5| Step: 4
Training loss: 5.799440212201721
Validation loss: 5.047165420411815

Epoch: 5| Step: 5
Training loss: 4.8240048503946245
Validation loss: 5.041027645986995

Epoch: 5| Step: 6
Training loss: 4.724980970879237
Validation loss: 5.035268395129185

Epoch: 5| Step: 7
Training loss: 4.474629409192383
Validation loss: 5.029104292555726

Epoch: 5| Step: 8
Training loss: 6.106473345854611
Validation loss: 5.023971798149962

Epoch: 5| Step: 9
Training loss: 4.890995876886895
Validation loss: 5.018365881548362

Epoch: 5| Step: 10
Training loss: 5.531629818736796
Validation loss: 5.012451387900583

Epoch: 5| Step: 11
Training loss: 6.434999739640237
Validation loss: 5.0064400524524055

Epoch: 11| Step: 0
Training loss: 5.499038959116125
Validation loss: 5.000416046952884

Epoch: 5| Step: 1
Training loss: 5.496634060261938
Validation loss: 4.994702540912825

Epoch: 5| Step: 2
Training loss: 4.330180977790079
Validation loss: 4.989101532654876

Epoch: 5| Step: 3
Training loss: 5.16947544823574
Validation loss: 4.983381022774784

Epoch: 5| Step: 4
Training loss: 5.186503670851761
Validation loss: 4.977670694882997

Epoch: 5| Step: 5
Training loss: 5.122259756535951
Validation loss: 4.972120121784315

Epoch: 5| Step: 6
Training loss: 5.179861304587761
Validation loss: 4.965973044078139

Epoch: 5| Step: 7
Training loss: 4.542902833652274
Validation loss: 4.960425915710124

Epoch: 5| Step: 8
Training loss: 5.218591013788056
Validation loss: 4.954869393360559

Epoch: 5| Step: 9
Training loss: 4.035730282333442
Validation loss: 4.949251884865383

Epoch: 5| Step: 10
Training loss: 6.040580844865779
Validation loss: 4.943626176559022

Epoch: 5| Step: 11
Training loss: 4.710318807839271
Validation loss: 4.937609393682525

Epoch: 12| Step: 0
Training loss: 4.743899594085508
Validation loss: 4.932532221706124

Epoch: 5| Step: 1
Training loss: 5.382213276810951
Validation loss: 4.92698039726279

Epoch: 5| Step: 2
Training loss: 5.328988729592788
Validation loss: 4.921569952013985

Epoch: 5| Step: 3
Training loss: 5.9930869649646255
Validation loss: 4.916358714508111

Epoch: 5| Step: 4
Training loss: 4.206903850641814
Validation loss: 4.911422910053534

Epoch: 5| Step: 5
Training loss: 5.3354490176640965
Validation loss: 4.905838538084428

Epoch: 5| Step: 6
Training loss: 4.496205955715976
Validation loss: 4.900306122163895

Epoch: 5| Step: 7
Training loss: 5.129723767731313
Validation loss: 4.895114726903209

Epoch: 5| Step: 8
Training loss: 4.387397421482718
Validation loss: 4.889986051313325

Epoch: 5| Step: 9
Training loss: 4.647208222766339
Validation loss: 4.8849430329102965

Epoch: 5| Step: 10
Training loss: 5.174230678705297
Validation loss: 4.879616621766731

Epoch: 5| Step: 11
Training loss: 6.121128960990781
Validation loss: 4.874159683446023

Epoch: 13| Step: 0
Training loss: 4.945840286125732
Validation loss: 4.868975462486001

Epoch: 5| Step: 1
Training loss: 5.032177573050158
Validation loss: 4.863475610814566

Epoch: 5| Step: 2
Training loss: 5.571690200419718
Validation loss: 4.858458249540221

Epoch: 5| Step: 3
Training loss: 4.224336894891088
Validation loss: 4.853248864153206

Epoch: 5| Step: 4
Training loss: 4.685382822654326
Validation loss: 4.848228164695806

Epoch: 5| Step: 5
Training loss: 5.4549793489871234
Validation loss: 4.843436413530254

Epoch: 5| Step: 6
Training loss: 5.043338824107595
Validation loss: 4.837734539710711

Epoch: 5| Step: 7
Training loss: 5.144126928338608
Validation loss: 4.832516916425988

Epoch: 5| Step: 8
Training loss: 4.768899361807384
Validation loss: 4.82726567428462

Epoch: 5| Step: 9
Training loss: 5.241063823309157
Validation loss: 4.822127105260196

Epoch: 5| Step: 10
Training loss: 4.631348454179228
Validation loss: 4.816584967159027

Epoch: 5| Step: 11
Training loss: 3.665745980818397
Validation loss: 4.81147757729597

Epoch: 14| Step: 0
Training loss: 5.441446560219498
Validation loss: 4.805945209583228

Epoch: 5| Step: 1
Training loss: 4.495563015074949
Validation loss: 4.800524703460863

Epoch: 5| Step: 2
Training loss: 5.251746840733128
Validation loss: 4.795590082601013

Epoch: 5| Step: 3
Training loss: 4.664897901392904
Validation loss: 4.790299857814286

Epoch: 5| Step: 4
Training loss: 5.598611264376158
Validation loss: 4.784392992247859

Epoch: 5| Step: 5
Training loss: 5.0821432794747485
Validation loss: 4.7779577884227935

Epoch: 5| Step: 6
Training loss: 5.068579708300878
Validation loss: 4.771836856871962

Epoch: 5| Step: 7
Training loss: 5.146307034124328
Validation loss: 4.765390659261419

Epoch: 5| Step: 8
Training loss: 4.993817321552726
Validation loss: 4.7599130888625885

Epoch: 5| Step: 9
Training loss: 4.2473225855246515
Validation loss: 4.7541008321475955

Epoch: 5| Step: 10
Training loss: 3.8675495016805175
Validation loss: 4.7486652289115305

Epoch: 5| Step: 11
Training loss: 3.9991114344713905
Validation loss: 4.7437628570369

Epoch: 15| Step: 0
Training loss: 5.37120347899278
Validation loss: 4.739225028890362

Epoch: 5| Step: 1
Training loss: 4.578371217115207
Validation loss: 4.734083110007265

Epoch: 5| Step: 2
Training loss: 5.911409254052411
Validation loss: 4.728391998410251

Epoch: 5| Step: 3
Training loss: 4.338080129387236
Validation loss: 4.723504700447146

Epoch: 5| Step: 4
Training loss: 4.859079431701439
Validation loss: 4.718805207525333

Epoch: 5| Step: 5
Training loss: 4.519349143168344
Validation loss: 4.713412071961511

Epoch: 5| Step: 6
Training loss: 5.048513801869419
Validation loss: 4.7083264016069455

Epoch: 5| Step: 7
Training loss: 3.9178544671533495
Validation loss: 4.7035099602825605

Epoch: 5| Step: 8
Training loss: 5.032855233902513
Validation loss: 4.698902938686514

Epoch: 5| Step: 9
Training loss: 3.7259192081441697
Validation loss: 4.694177745388634

Epoch: 5| Step: 10
Training loss: 5.592661831679561
Validation loss: 4.689038850596914

Epoch: 5| Step: 11
Training loss: 4.26492046644284
Validation loss: 4.684439113280837

Epoch: 16| Step: 0
Training loss: 5.543479374383813
Validation loss: 4.679081533149522

Epoch: 5| Step: 1
Training loss: 4.250657647804958
Validation loss: 4.674541966716869

Epoch: 5| Step: 2
Training loss: 4.327392295762068
Validation loss: 4.669269328446012

Epoch: 5| Step: 3
Training loss: 4.8538559362584275
Validation loss: 4.664435605493641

Epoch: 5| Step: 4
Training loss: 4.285586868390204
Validation loss: 4.659106366272158

Epoch: 5| Step: 5
Training loss: 5.872004617881518
Validation loss: 4.654230076498203

Epoch: 5| Step: 6
Training loss: 4.9239578926027585
Validation loss: 4.6489599965399035

Epoch: 5| Step: 7
Training loss: 4.588925689434761
Validation loss: 4.643883191778959

Epoch: 5| Step: 8
Training loss: 4.432582225607053
Validation loss: 4.639142879733228

Epoch: 5| Step: 9
Training loss: 4.648044191278429
Validation loss: 4.633875852950493

Epoch: 5| Step: 10
Training loss: 4.832297488181188
Validation loss: 4.628766115967333

Epoch: 5| Step: 11
Training loss: 3.396436922379127
Validation loss: 4.623484629598927

Epoch: 17| Step: 0
Training loss: 4.212994075065628
Validation loss: 4.618836032752714

Epoch: 5| Step: 1
Training loss: 4.930106506435223
Validation loss: 4.61418327796118

Epoch: 5| Step: 2
Training loss: 4.539369451284924
Validation loss: 4.610100235432

Epoch: 5| Step: 3
Training loss: 5.0705637818125995
Validation loss: 4.604785772560106

Epoch: 5| Step: 4
Training loss: 4.606098419966615
Validation loss: 4.599886456760637

Epoch: 5| Step: 5
Training loss: 4.617301926590769
Validation loss: 4.594613519589425

Epoch: 5| Step: 6
Training loss: 4.669439491109486
Validation loss: 4.58982613201683

Epoch: 5| Step: 7
Training loss: 4.616407506028768
Validation loss: 4.584793923030567

Epoch: 5| Step: 8
Training loss: 4.660801857980082
Validation loss: 4.580417766327427

Epoch: 5| Step: 9
Training loss: 5.37477945274496
Validation loss: 4.574367408932039

Epoch: 5| Step: 10
Training loss: 4.515244200598683
Validation loss: 4.569522974227774

Epoch: 5| Step: 11
Training loss: 4.859854622381579
Validation loss: 4.565331995389719

Epoch: 18| Step: 0
Training loss: 3.9212728699250397
Validation loss: 4.560651875171412

Epoch: 5| Step: 1
Training loss: 5.041005787475871
Validation loss: 4.555601670579701

Epoch: 5| Step: 2
Training loss: 4.400439821282361
Validation loss: 4.549140156206707

Epoch: 5| Step: 3
Training loss: 4.351098958774421
Validation loss: 4.543574530332384

Epoch: 5| Step: 4
Training loss: 4.5874827704248995
Validation loss: 4.538895464399149

Epoch: 5| Step: 5
Training loss: 5.158734272220448
Validation loss: 4.534052839167877

Epoch: 5| Step: 6
Training loss: 4.992665633585347
Validation loss: 4.528615409247271

Epoch: 5| Step: 7
Training loss: 4.509742151912168
Validation loss: 4.523867580631649

Epoch: 5| Step: 8
Training loss: 4.562851147660104
Validation loss: 4.518489153708099

Epoch: 5| Step: 9
Training loss: 4.7179196871414
Validation loss: 4.515417646423405

Epoch: 5| Step: 10
Training loss: 4.96228720259175
Validation loss: 4.508330925231592

Epoch: 5| Step: 11
Training loss: 4.279659671978484
Validation loss: 4.502246366647205

Epoch: 19| Step: 0
Training loss: 4.736097167371482
Validation loss: 4.497766792741677

Epoch: 5| Step: 1
Training loss: 5.444326040489884
Validation loss: 4.493037241302747

Epoch: 5| Step: 2
Training loss: 4.777635591939305
Validation loss: 4.48715234718569

Epoch: 5| Step: 3
Training loss: 4.654983655530055
Validation loss: 4.481778907510007

Epoch: 5| Step: 4
Training loss: 3.9939940185502087
Validation loss: 4.476876958484214

Epoch: 5| Step: 5
Training loss: 4.071468137964721
Validation loss: 4.471610667522253

Epoch: 5| Step: 6
Training loss: 4.5995770301410515
Validation loss: 4.46590774242561

Epoch: 5| Step: 7
Training loss: 4.693387212841391
Validation loss: 4.460819498918758

Epoch: 5| Step: 8
Training loss: 3.622527627675052
Validation loss: 4.454879968170008

Epoch: 5| Step: 9
Training loss: 4.958505109274485
Validation loss: 4.4512486838274805

Epoch: 5| Step: 10
Training loss: 4.70361933850857
Validation loss: 4.445622938922469

Epoch: 5| Step: 11
Training loss: 4.99609375
Validation loss: 4.439654373550513

Epoch: 20| Step: 0
Training loss: 4.222499960972192
Validation loss: 4.435453162245474

Epoch: 5| Step: 1
Training loss: 4.446412927421673
Validation loss: 4.430679210277927

Epoch: 5| Step: 2
Training loss: 4.9702422582273345
Validation loss: 4.425480122210801

Epoch: 5| Step: 3
Training loss: 4.480657332425147
Validation loss: 4.419725702269865

Epoch: 5| Step: 4
Training loss: 4.805450626959912
Validation loss: 4.414659595895918

Epoch: 5| Step: 5
Training loss: 4.483051383832557
Validation loss: 4.409982250420106

Epoch: 5| Step: 6
Training loss: 5.231590691960992
Validation loss: 4.40477743409953

Epoch: 5| Step: 7
Training loss: 3.936737471117919
Validation loss: 4.399304256557777

Epoch: 5| Step: 8
Training loss: 4.696128736183828
Validation loss: 4.393729581826141

Epoch: 5| Step: 9
Training loss: 4.491338447275337
Validation loss: 4.38874934305932

Epoch: 5| Step: 10
Training loss: 4.1938430798543695
Validation loss: 4.383639406655271

Epoch: 5| Step: 11
Training loss: 3.560848455583699
Validation loss: 4.379365622988265

Epoch: 21| Step: 0
Training loss: 5.113612106728097
Validation loss: 4.373471233659859

Epoch: 5| Step: 1
Training loss: 5.117025917355862
Validation loss: 4.367303490733351

Epoch: 5| Step: 2
Training loss: 4.1904470976319175
Validation loss: 4.361878513674203

Epoch: 5| Step: 3
Training loss: 4.4857794393332275
Validation loss: 4.357133241102342

Epoch: 5| Step: 4
Training loss: 3.5009531358177153
Validation loss: 4.354476126787866

Epoch: 5| Step: 5
Training loss: 4.274896515603181
Validation loss: 4.34678933273794

Epoch: 5| Step: 6
Training loss: 4.540774523169332
Validation loss: 4.340979042197716

Epoch: 5| Step: 7
Training loss: 4.769865157102804
Validation loss: 4.335636584404975

Epoch: 5| Step: 8
Training loss: 4.03581629743544
Validation loss: 4.331388888533615

Epoch: 5| Step: 9
Training loss: 4.137013368138215
Validation loss: 4.326787376965764

Epoch: 5| Step: 10
Training loss: 4.660224600687978
Validation loss: 4.321627420803066

Epoch: 5| Step: 11
Training loss: 5.271025200569531
Validation loss: 4.31597501001586

Epoch: 22| Step: 0
Training loss: 4.805061040484627
Validation loss: 4.309799920097224

Epoch: 5| Step: 1
Training loss: 4.024258013270651
Validation loss: 4.3038037380054845

Epoch: 5| Step: 2
Training loss: 3.552843223275866
Validation loss: 4.2996051969334905

Epoch: 5| Step: 3
Training loss: 4.788325640447279
Validation loss: 4.2959539085114224

Epoch: 5| Step: 4
Training loss: 4.500530635489171
Validation loss: 4.291193300208372

Epoch: 5| Step: 5
Training loss: 4.9981254878538195
Validation loss: 4.2830777686996875

Epoch: 5| Step: 6
Training loss: 4.565924626413778
Validation loss: 4.279847093893063

Epoch: 5| Step: 7
Training loss: 4.321782612175144
Validation loss: 4.273975777766699

Epoch: 5| Step: 8
Training loss: 4.974174561385906
Validation loss: 4.268551638766558

Epoch: 5| Step: 9
Training loss: 3.6625169044078474
Validation loss: 4.262816439579403

Epoch: 5| Step: 10
Training loss: 4.39552224069366
Validation loss: 4.2580112189253665

Epoch: 5| Step: 11
Training loss: 2.4355108507760845
Validation loss: 4.252874757840473

Epoch: 23| Step: 0
Training loss: 3.636347406524506
Validation loss: 4.2472164163715425

Epoch: 5| Step: 1
Training loss: 4.639961375042862
Validation loss: 4.242413799884049

Epoch: 5| Step: 2
Training loss: 4.123907927246585
Validation loss: 4.237961229937606

Epoch: 5| Step: 3
Training loss: 4.049890992381264
Validation loss: 4.233422884344361

Epoch: 5| Step: 4
Training loss: 4.401177049469422
Validation loss: 4.228006126948837

Epoch: 5| Step: 5
Training loss: 5.046170684516182
Validation loss: 4.222688047258167

Epoch: 5| Step: 6
Training loss: 4.68486783194395
Validation loss: 4.217026582191614

Epoch: 5| Step: 7
Training loss: 4.137427365682548
Validation loss: 4.212179473809686

Epoch: 5| Step: 8
Training loss: 4.8771517968644575
Validation loss: 4.207502881187198

Epoch: 5| Step: 9
Training loss: 4.263704978685049
Validation loss: 4.202037126888833

Epoch: 5| Step: 10
Training loss: 3.831202301674369
Validation loss: 4.1968858398236915

Epoch: 5| Step: 11
Training loss: 4.196792767614546
Validation loss: 4.191037671704389

Epoch: 24| Step: 0
Training loss: 4.190506041201665
Validation loss: 4.186908632720298

Epoch: 5| Step: 1
Training loss: 4.222079623195717
Validation loss: 4.181241943701342

Epoch: 5| Step: 2
Training loss: 4.203326933026767
Validation loss: 4.176299892912673

Epoch: 5| Step: 3
Training loss: 4.794924659495118
Validation loss: 4.170910160539759

Epoch: 5| Step: 4
Training loss: 4.78632917703816
Validation loss: 4.165802850191401

Epoch: 5| Step: 5
Training loss: 3.830166517577031
Validation loss: 4.160421997561006

Epoch: 5| Step: 6
Training loss: 4.774546193233276
Validation loss: 4.155238355883722

Epoch: 5| Step: 7
Training loss: 4.06226782502116
Validation loss: 4.150814756974628

Epoch: 5| Step: 8
Training loss: 4.417920396508159
Validation loss: 4.145765843952318

Epoch: 5| Step: 9
Training loss: 4.0348118859441335
Validation loss: 4.139989379463763

Epoch: 5| Step: 10
Training loss: 3.9794693011228395
Validation loss: 4.134370775669945

Epoch: 5| Step: 11
Training loss: 3.0255015816483457
Validation loss: 4.1290934462203115

Epoch: 25| Step: 0
Training loss: 3.7558616602469646
Validation loss: 4.124255074564299

Epoch: 5| Step: 1
Training loss: 3.7496419099862055
Validation loss: 4.119396179481233

Epoch: 5| Step: 2
Training loss: 4.123563342904331
Validation loss: 4.115074571024203

Epoch: 5| Step: 3
Training loss: 4.25344148309028
Validation loss: 4.109752811716114

Epoch: 5| Step: 4
Training loss: 4.127125510331294
Validation loss: 4.105205402826545

Epoch: 5| Step: 5
Training loss: 3.940502777745304
Validation loss: 4.099512451344344

Epoch: 5| Step: 6
Training loss: 4.770423949333232
Validation loss: 4.095624853528351

Epoch: 5| Step: 7
Training loss: 4.4284752426601095
Validation loss: 4.09003603245502

Epoch: 5| Step: 8
Training loss: 4.651903210079951
Validation loss: 4.084852878212249

Epoch: 5| Step: 9
Training loss: 3.9168719109400842
Validation loss: 4.079584121319608

Epoch: 5| Step: 10
Training loss: 4.32184792908019
Validation loss: 4.074526074511

Epoch: 5| Step: 11
Training loss: 5.741517153686316
Validation loss: 4.069408313878703

Epoch: 26| Step: 0
Training loss: 4.626122621948716
Validation loss: 4.064719151558199

Epoch: 5| Step: 1
Training loss: 4.752782307948476
Validation loss: 4.058645322127512

Epoch: 5| Step: 2
Training loss: 4.422033516027453
Validation loss: 4.0522574491119965

Epoch: 5| Step: 3
Training loss: 4.001868050202974
Validation loss: 4.0473675716507955

Epoch: 5| Step: 4
Training loss: 4.0727988353702855
Validation loss: 4.041642639573768

Epoch: 5| Step: 5
Training loss: 3.9432625156427195
Validation loss: 4.035791101580648

Epoch: 5| Step: 6
Training loss: 4.328891066638348
Validation loss: 4.030599280383894

Epoch: 5| Step: 7
Training loss: 4.213304410022337
Validation loss: 4.025236178314441

Epoch: 5| Step: 8
Training loss: 3.554141629404038
Validation loss: 4.019931374157055

Epoch: 5| Step: 9
Training loss: 3.716731701839269
Validation loss: 4.01454153423526

Epoch: 5| Step: 10
Training loss: 3.979631060652011
Validation loss: 4.009489827581884

Epoch: 5| Step: 11
Training loss: 4.679409521950509
Validation loss: 4.0046899044145245

Epoch: 27| Step: 0
Training loss: 3.305194067400756
Validation loss: 3.998997493127201

Epoch: 5| Step: 1
Training loss: 4.1655630303113975
Validation loss: 3.994479582067119

Epoch: 5| Step: 2
Training loss: 3.8909811446714153
Validation loss: 3.989318707739464

Epoch: 5| Step: 3
Training loss: 4.158285460008601
Validation loss: 3.983921354311346

Epoch: 5| Step: 4
Training loss: 3.8015271481125734
Validation loss: 3.979785025651867

Epoch: 5| Step: 5
Training loss: 4.732806156691956
Validation loss: 3.974905856835052

Epoch: 5| Step: 6
Training loss: 3.2465793508058756
Validation loss: 3.969200674385586

Epoch: 5| Step: 7
Training loss: 4.299173302248198
Validation loss: 3.964595001385281

Epoch: 5| Step: 8
Training loss: 4.2994405959224755
Validation loss: 3.9602864248875793

Epoch: 5| Step: 9
Training loss: 4.386704401551556
Validation loss: 3.9551950897378183

Epoch: 5| Step: 10
Training loss: 4.635372181653937
Validation loss: 3.9494926843114637

Epoch: 5| Step: 11
Training loss: 3.8963008062962143
Validation loss: 3.944402719479967

Epoch: 28| Step: 0
Training loss: 4.003969130603797
Validation loss: 3.9390686281250624

Epoch: 5| Step: 1
Training loss: 3.3111595464601606
Validation loss: 3.9334604694676423

Epoch: 5| Step: 2
Training loss: 4.204441247346974
Validation loss: 3.928846695264586

Epoch: 5| Step: 3
Training loss: 4.008305272078813
Validation loss: 3.9241326864076522

Epoch: 5| Step: 4
Training loss: 4.293819270345645
Validation loss: 3.918685335379183

Epoch: 5| Step: 5
Training loss: 4.00930728513246
Validation loss: 3.9135448699821636

Epoch: 5| Step: 6
Training loss: 3.5270203772730344
Validation loss: 3.9077137658662973

Epoch: 5| Step: 7
Training loss: 4.390509444375715
Validation loss: 3.903158714366691

Epoch: 5| Step: 8
Training loss: 4.0425748034216715
Validation loss: 3.897779303406579

Epoch: 5| Step: 9
Training loss: 4.230860529094571
Validation loss: 3.8928405142454383

Epoch: 5| Step: 10
Training loss: 4.299493609041587
Validation loss: 3.8879066734988186

Epoch: 5| Step: 11
Training loss: 4.308809774729523
Validation loss: 3.882737228718054

Epoch: 29| Step: 0
Training loss: 3.691896694643345
Validation loss: 3.8772814556392734

Epoch: 5| Step: 1
Training loss: 3.9935422267207294
Validation loss: 3.871829073728242

Epoch: 5| Step: 2
Training loss: 4.138069947969356
Validation loss: 3.8669732699154755

Epoch: 5| Step: 3
Training loss: 4.3105829373066715
Validation loss: 3.8614373147435486

Epoch: 5| Step: 4
Training loss: 3.410627579425034
Validation loss: 3.856487584021261

Epoch: 5| Step: 5
Training loss: 3.802901645894188
Validation loss: 3.8516531540916867

Epoch: 5| Step: 6
Training loss: 3.426228579955589
Validation loss: 3.8465461949904642

Epoch: 5| Step: 7
Training loss: 4.499898485522188
Validation loss: 3.8415043015967987

Epoch: 5| Step: 8
Training loss: 4.170010839580837
Validation loss: 3.836267735496303

Epoch: 5| Step: 9
Training loss: 4.528284404678907
Validation loss: 3.8311164378397518

Epoch: 5| Step: 10
Training loss: 3.7984522930251075
Validation loss: 3.825757993337

Epoch: 5| Step: 11
Training loss: 3.3259333168267995
Validation loss: 3.8214117443663245

Epoch: 30| Step: 0
Training loss: 3.100905649117135
Validation loss: 3.8155825509207677

Epoch: 5| Step: 1
Training loss: 4.338641558989701
Validation loss: 3.8117720060022067

Epoch: 5| Step: 2
Training loss: 4.250697583561951
Validation loss: 3.8061885261895694

Epoch: 5| Step: 3
Training loss: 3.3572068425721815
Validation loss: 3.8006136034917133

Epoch: 5| Step: 4
Training loss: 4.281536454690278
Validation loss: 3.7964783658886994

Epoch: 5| Step: 5
Training loss: 4.268002472824053
Validation loss: 3.7912439313270436

Epoch: 5| Step: 6
Training loss: 3.61459818167298
Validation loss: 3.786758529887527

Epoch: 5| Step: 7
Training loss: 3.9522570233878334
Validation loss: 3.7821020789902544

Epoch: 5| Step: 8
Training loss: 3.618417748992726
Validation loss: 3.7774134737645757

Epoch: 5| Step: 9
Training loss: 4.224599893800041
Validation loss: 3.772456829514169

Epoch: 5| Step: 10
Training loss: 4.0823020151676666
Validation loss: 3.7670264795215043

Epoch: 5| Step: 11
Training loss: 3.110145971668836
Validation loss: 3.7621673496075427

Epoch: 31| Step: 0
Training loss: 3.78461741419959
Validation loss: 3.7571557595286835

Epoch: 5| Step: 1
Training loss: 4.483928804429588
Validation loss: 3.752404843220298

Epoch: 5| Step: 2
Training loss: 4.079038320411414
Validation loss: 3.7468441346556687

Epoch: 5| Step: 3
Training loss: 4.059861955221998
Validation loss: 3.7420324454043556

Epoch: 5| Step: 4
Training loss: 3.532684439928341
Validation loss: 3.7362520350066437

Epoch: 5| Step: 5
Training loss: 3.3610128978605482
Validation loss: 3.7305767902487283

Epoch: 5| Step: 6
Training loss: 3.4902301397655475
Validation loss: 3.725864870254623

Epoch: 5| Step: 7
Training loss: 3.904177917225416
Validation loss: 3.720830613135653

Epoch: 5| Step: 8
Training loss: 3.7569539760829866
Validation loss: 3.715846699484373

Epoch: 5| Step: 9
Training loss: 3.877369802073469
Validation loss: 3.71063273466706

Epoch: 5| Step: 10
Training loss: 4.255075005162723
Validation loss: 3.705969751965416

Epoch: 5| Step: 11
Training loss: 2.7543873035354336
Validation loss: 3.7010132929262505

Epoch: 32| Step: 0
Training loss: 3.3960898522845415
Validation loss: 3.69604180137623

Epoch: 5| Step: 1
Training loss: 3.7451217711021494
Validation loss: 3.69172979211907

Epoch: 5| Step: 2
Training loss: 3.3279666773429946
Validation loss: 3.686821056082773

Epoch: 5| Step: 3
Training loss: 4.3688688641314855
Validation loss: 3.682377349777488

Epoch: 5| Step: 4
Training loss: 3.7388492100956037
Validation loss: 3.6774387818200065

Epoch: 5| Step: 5
Training loss: 3.912521576745741
Validation loss: 3.6727102858184613

Epoch: 5| Step: 6
Training loss: 3.988373429356824
Validation loss: 3.6681986538001943

Epoch: 5| Step: 7
Training loss: 3.687491336101117
Validation loss: 3.663939798628192

Epoch: 5| Step: 8
Training loss: 3.865673038366124
Validation loss: 3.658809662499602

Epoch: 5| Step: 9
Training loss: 3.4944886001791775
Validation loss: 3.6537905406323237

Epoch: 5| Step: 10
Training loss: 4.283428445395834
Validation loss: 3.649128485627468

Epoch: 5| Step: 11
Training loss: 3.463751826208398
Validation loss: 3.644234702804535

Epoch: 33| Step: 0
Training loss: 3.421681159116214
Validation loss: 3.6393695079935195

Epoch: 5| Step: 1
Training loss: 3.7751665596501285
Validation loss: 3.6350045867814025

Epoch: 5| Step: 2
Training loss: 3.697957614439148
Validation loss: 3.630436739128176

Epoch: 5| Step: 3
Training loss: 3.9527517753193204
Validation loss: 3.626310084372368

Epoch: 5| Step: 4
Training loss: 4.2288983389884205
Validation loss: 3.621010135698956

Epoch: 5| Step: 5
Training loss: 4.358078630540709
Validation loss: 3.6156699867713926

Epoch: 5| Step: 6
Training loss: 3.351360181557381
Validation loss: 3.610508849384553

Epoch: 5| Step: 7
Training loss: 3.2151135392852934
Validation loss: 3.605781351509263

Epoch: 5| Step: 8
Training loss: 3.832930059919993
Validation loss: 3.6012794179265435

Epoch: 5| Step: 9
Training loss: 3.588704157649099
Validation loss: 3.5961800085829365

Epoch: 5| Step: 10
Training loss: 3.720700305527147
Validation loss: 3.591623357052939

Epoch: 5| Step: 11
Training loss: 3.550066751201769
Validation loss: 3.5869613382623773

Epoch: 34| Step: 0
Training loss: 3.5111117405897563
Validation loss: 3.582106810992717

Epoch: 5| Step: 1
Training loss: 3.3885376301759087
Validation loss: 3.577007202392869

Epoch: 5| Step: 2
Training loss: 3.039501482092673
Validation loss: 3.5720424231280834

Epoch: 5| Step: 3
Training loss: 3.886648696958203
Validation loss: 3.567419069170138

Epoch: 5| Step: 4
Training loss: 3.804465536109099
Validation loss: 3.5629947134814364

Epoch: 5| Step: 5
Training loss: 3.4386313224012435
Validation loss: 3.558374676624291

Epoch: 5| Step: 6
Training loss: 3.768978920432049
Validation loss: 3.5540621252810793

Epoch: 5| Step: 7
Training loss: 4.025132142735129
Validation loss: 3.549374656043574

Epoch: 5| Step: 8
Training loss: 3.865589405040874
Validation loss: 3.5446057055167777

Epoch: 5| Step: 9
Training loss: 3.9434055667645014
Validation loss: 3.5398205527030533

Epoch: 5| Step: 10
Training loss: 3.574280251562743
Validation loss: 3.535204555118222

Epoch: 5| Step: 11
Training loss: 4.900138596112195
Validation loss: 3.5302994610612983

Epoch: 35| Step: 0
Training loss: 3.6822507317339186
Validation loss: 3.525435299295296

Epoch: 5| Step: 1
Training loss: 3.021866737835703
Validation loss: 3.5204348065852593

Epoch: 5| Step: 2
Training loss: 3.598547478211437
Validation loss: 3.5156368227159422

Epoch: 5| Step: 3
Training loss: 4.582327622554905
Validation loss: 3.510658253960527

Epoch: 5| Step: 4
Training loss: 3.8146372573405105
Validation loss: 3.506200837885994

Epoch: 5| Step: 5
Training loss: 3.334876434461985
Validation loss: 3.500734405442526

Epoch: 5| Step: 6
Training loss: 3.870789855669058
Validation loss: 3.496321163914838

Epoch: 5| Step: 7
Training loss: 4.276953107161613
Validation loss: 3.49140789481217

Epoch: 5| Step: 8
Training loss: 3.133686352856816
Validation loss: 3.4862792851351134

Epoch: 5| Step: 9
Training loss: 3.7186168999454043
Validation loss: 3.481931040275271

Epoch: 5| Step: 10
Training loss: 2.8691840015973136
Validation loss: 3.4771766777300988

Epoch: 5| Step: 11
Training loss: 2.265732650830155
Validation loss: 3.4724105330372033

Epoch: 36| Step: 0
Training loss: 3.7248103663159347
Validation loss: 3.46861383669177

Epoch: 5| Step: 1
Training loss: 3.7994258145653723
Validation loss: 3.4640996478745474

Epoch: 5| Step: 2
Training loss: 3.180082629347857
Validation loss: 3.4600684091571017

Epoch: 5| Step: 3
Training loss: 3.2641526695057186
Validation loss: 3.455805967618279

Epoch: 5| Step: 4
Training loss: 3.3533549461906955
Validation loss: 3.452084124090595

Epoch: 5| Step: 5
Training loss: 3.7303896271468355
Validation loss: 3.447673072546268

Epoch: 5| Step: 6
Training loss: 3.10389648558864
Validation loss: 3.4443543789395763

Epoch: 5| Step: 7
Training loss: 4.019799582196888
Validation loss: 3.4400152772002355

Epoch: 5| Step: 8
Training loss: 3.7912880565268945
Validation loss: 3.435687355926931

Epoch: 5| Step: 9
Training loss: 3.0957904598780854
Validation loss: 3.431895079249763

Epoch: 5| Step: 10
Training loss: 4.166017456340432
Validation loss: 3.427747364508641

Epoch: 5| Step: 11
Training loss: 3.681126404324396
Validation loss: 3.4235899589062257

Epoch: 37| Step: 0
Training loss: 3.260469592622588
Validation loss: 3.4195489220746844

Epoch: 5| Step: 1
Training loss: 3.1514944376520417
Validation loss: 3.415127542258745

Epoch: 5| Step: 2
Training loss: 3.7422643347001885
Validation loss: 3.4106184685124754

Epoch: 5| Step: 3
Training loss: 2.9139595729455876
Validation loss: 3.4066802170204666

Epoch: 5| Step: 4
Training loss: 3.9641602175963984
Validation loss: 3.402553284737269

Epoch: 5| Step: 5
Training loss: 3.2938765499697205
Validation loss: 3.398192877022269

Epoch: 5| Step: 6
Training loss: 3.6232586328362433
Validation loss: 3.3939186160852794

Epoch: 5| Step: 7
Training loss: 4.320254444470351
Validation loss: 3.3903528505673113

Epoch: 5| Step: 8
Training loss: 3.406877932283955
Validation loss: 3.3857582780682876

Epoch: 5| Step: 9
Training loss: 3.478030736970565
Validation loss: 3.3815122635456496

Epoch: 5| Step: 10
Training loss: 3.6518925189176312
Validation loss: 3.377374837830677

Epoch: 5| Step: 11
Training loss: 2.906454427769037
Validation loss: 3.373101854492907

Epoch: 38| Step: 0
Training loss: 4.314652721093286
Validation loss: 3.369381000586811

Epoch: 5| Step: 1
Training loss: 3.330100462718336
Validation loss: 3.3648272485965376

Epoch: 5| Step: 2
Training loss: 3.285131429426524
Validation loss: 3.3603333104377078

Epoch: 5| Step: 3
Training loss: 3.2842864020073153
Validation loss: 3.3558530576315886

Epoch: 5| Step: 4
Training loss: 3.160123657511161
Validation loss: 3.351991787488811

Epoch: 5| Step: 5
Training loss: 3.3739454246588902
Validation loss: 3.3479553350190914

Epoch: 5| Step: 6
Training loss: 3.347603547116503
Validation loss: 3.343852412951998

Epoch: 5| Step: 7
Training loss: 3.840834093105522
Validation loss: 3.340239110675706

Epoch: 5| Step: 8
Training loss: 3.5201892301240494
Validation loss: 3.335797645680673

Epoch: 5| Step: 9
Training loss: 3.3379319100815
Validation loss: 3.331909958605871

Epoch: 5| Step: 10
Training loss: 3.4703144291610886
Validation loss: 3.3280682536557236

Epoch: 5| Step: 11
Training loss: 3.248267372157118
Validation loss: 3.323933255539251

Epoch: 39| Step: 0
Training loss: 3.4331022394669954
Validation loss: 3.3210733177808662

Epoch: 5| Step: 1
Training loss: 3.2644066979280537
Validation loss: 3.3150822513132625

Epoch: 5| Step: 2
Training loss: 3.176709179135111
Validation loss: 3.311406482883783

Epoch: 5| Step: 3
Training loss: 3.555720118515835
Validation loss: 3.3075540523624807

Epoch: 5| Step: 4
Training loss: 3.9685301231691534
Validation loss: 3.3032348241626557

Epoch: 5| Step: 5
Training loss: 2.7349020313799794
Validation loss: 3.299284947597112

Epoch: 5| Step: 6
Training loss: 3.4729638151199924
Validation loss: 3.295491016967396

Epoch: 5| Step: 7
Training loss: 3.5334684442082995
Validation loss: 3.29118096514532

Epoch: 5| Step: 8
Training loss: 2.770853219403107
Validation loss: 3.287092861981015

Epoch: 5| Step: 9
Training loss: 3.938821964266286
Validation loss: 3.2833215804462537

Epoch: 5| Step: 10
Training loss: 3.879897437558957
Validation loss: 3.2790211085805105

Epoch: 5| Step: 11
Training loss: 2.5333523908534072
Validation loss: 3.274666566837363

Epoch: 40| Step: 0
Training loss: 3.6469926280686407
Validation loss: 3.2702582799381252

Epoch: 5| Step: 1
Training loss: 3.7197866838062716
Validation loss: 3.266197276127242

Epoch: 5| Step: 2
Training loss: 2.7641121557421444
Validation loss: 3.262084172959674

Epoch: 5| Step: 3
Training loss: 3.6091737897531497
Validation loss: 3.2583357576001863

Epoch: 5| Step: 4
Training loss: 3.2717441011639306
Validation loss: 3.253930011248832

Epoch: 5| Step: 5
Training loss: 3.021110013371017
Validation loss: 3.2500094694831025

Epoch: 5| Step: 6
Training loss: 4.006776791126035
Validation loss: 3.2466453270305515

Epoch: 5| Step: 7
Training loss: 2.9410087245901253
Validation loss: 3.2427415611818606

Epoch: 5| Step: 8
Training loss: 3.424283229700346
Validation loss: 3.238902150178402

Epoch: 5| Step: 9
Training loss: 3.7178568047850136
Validation loss: 3.2349779546793287

Epoch: 5| Step: 10
Training loss: 2.924995754923552
Validation loss: 3.2308299036887593

Epoch: 5| Step: 11
Training loss: 3.458983961435958
Validation loss: 3.2268446336354635

Epoch: 41| Step: 0
Training loss: 3.368875102761723
Validation loss: 3.222943928526619

Epoch: 5| Step: 1
Training loss: 3.006190905713854
Validation loss: 3.219257999812818

Epoch: 5| Step: 2
Training loss: 3.1775449990628513
Validation loss: 3.2155816307887526

Epoch: 5| Step: 3
Training loss: 3.1040994180311756
Validation loss: 3.212235110428872

Epoch: 5| Step: 4
Training loss: 2.771094823750497
Validation loss: 3.209108523232815

Epoch: 5| Step: 5
Training loss: 3.9233505087460054
Validation loss: 3.2053976850808366

Epoch: 5| Step: 6
Training loss: 3.6534086745445418
Validation loss: 3.2020164494343115

Epoch: 5| Step: 7
Training loss: 3.704341640280367
Validation loss: 3.198380139508509

Epoch: 5| Step: 8
Training loss: 2.8715235381970876
Validation loss: 3.1943984150449753

Epoch: 5| Step: 9
Training loss: 3.3977593106980164
Validation loss: 3.190739814592999

Epoch: 5| Step: 10
Training loss: 3.3646984415274117
Validation loss: 3.1866691603577673

Epoch: 5| Step: 11
Training loss: 4.420554027788559
Validation loss: 3.18308581959472

Epoch: 42| Step: 0
Training loss: 3.2732849813905562
Validation loss: 3.178959309318025

Epoch: 5| Step: 1
Training loss: 3.4414864746164935
Validation loss: 3.17452950733671

Epoch: 5| Step: 2
Training loss: 3.861357639105401
Validation loss: 3.17117829336599

Epoch: 5| Step: 3
Training loss: 3.2309171464616364
Validation loss: 3.166927004870793

Epoch: 5| Step: 4
Training loss: 3.5871177177244946
Validation loss: 3.1628872607904506

Epoch: 5| Step: 5
Training loss: 2.665148829586069
Validation loss: 3.1589107408774826

Epoch: 5| Step: 6
Training loss: 3.3496016877645025
Validation loss: 3.1549254618795626

Epoch: 5| Step: 7
Training loss: 2.881319481266352
Validation loss: 3.151187988961344

Epoch: 5| Step: 8
Training loss: 3.3626916880371214
Validation loss: 3.1474954538309983

Epoch: 5| Step: 9
Training loss: 3.278483359765425
Validation loss: 3.1441112798616073

Epoch: 5| Step: 10
Training loss: 3.1590640676292447
Validation loss: 3.1407796369348286

Epoch: 5| Step: 11
Training loss: 3.620828530352662
Validation loss: 3.1368571338396865

Epoch: 43| Step: 0
Training loss: 3.06688547459507
Validation loss: 3.1331067823033476

Epoch: 5| Step: 1
Training loss: 3.289585244144193
Validation loss: 3.1297004253789025

Epoch: 5| Step: 2
Training loss: 2.9521755730848476
Validation loss: 3.126228733094635

Epoch: 5| Step: 3
Training loss: 3.1065025672085387
Validation loss: 3.122830152596266

Epoch: 5| Step: 4
Training loss: 3.5712372565117207
Validation loss: 3.119308702832739

Epoch: 5| Step: 5
Training loss: 3.4782433721890076
Validation loss: 3.1156458727393472

Epoch: 5| Step: 6
Training loss: 3.3120699909296745
Validation loss: 3.1121670473383474

Epoch: 5| Step: 7
Training loss: 3.408141704541474
Validation loss: 3.108413522076316

Epoch: 5| Step: 8
Training loss: 2.976085874989991
Validation loss: 3.105292955457147

Epoch: 5| Step: 9
Training loss: 3.110180774353432
Validation loss: 3.1015410690784324

Epoch: 5| Step: 10
Training loss: 3.5700381651475874
Validation loss: 3.0981082658621664

Epoch: 5| Step: 11
Training loss: 2.724955875144472
Validation loss: 3.0948373155406133

Epoch: 44| Step: 0
Training loss: 2.7325987359834216
Validation loss: 3.0915244410790486

Epoch: 5| Step: 1
Training loss: 2.760081451983262
Validation loss: 3.088390453854811

Epoch: 5| Step: 2
Training loss: 3.0262186039174845
Validation loss: 3.085190301885768

Epoch: 5| Step: 3
Training loss: 3.029173306786257
Validation loss: 3.0823016029980717

Epoch: 5| Step: 4
Training loss: 3.6072986790347183
Validation loss: 3.079504462379542

Epoch: 5| Step: 5
Training loss: 3.5096016380113197
Validation loss: 3.076075890067898

Epoch: 5| Step: 6
Training loss: 3.571306687046339
Validation loss: 3.073050652293099

Epoch: 5| Step: 7
Training loss: 3.249617480728636
Validation loss: 3.0697674287672556

Epoch: 5| Step: 8
Training loss: 3.5517780847733946
Validation loss: 3.066088575361287

Epoch: 5| Step: 9
Training loss: 3.2661382098507663
Validation loss: 3.063408930831197

Epoch: 5| Step: 10
Training loss: 3.0842946761937595
Validation loss: 3.0596224961719747

Epoch: 5| Step: 11
Training loss: 2.3736224948090987
Validation loss: 3.0564251613543796

Epoch: 45| Step: 0
Training loss: 2.970786430199078
Validation loss: 3.0539792240558654

Epoch: 5| Step: 1
Training loss: 3.2797351064947935
Validation loss: 3.0512250934778775

Epoch: 5| Step: 2
Training loss: 3.6220135719049256
Validation loss: 3.048559160279894

Epoch: 5| Step: 3
Training loss: 3.189540733353578
Validation loss: 3.0455360926826134

Epoch: 5| Step: 4
Training loss: 3.158833871866913
Validation loss: 3.042656526230066

Epoch: 5| Step: 5
Training loss: 3.0791876648086687
Validation loss: 3.0397927551776522

Epoch: 5| Step: 6
Training loss: 3.284054384271451
Validation loss: 3.036761893033075

Epoch: 5| Step: 7
Training loss: 3.3470907189868533
Validation loss: 3.034345206714515

Epoch: 5| Step: 8
Training loss: 3.3119532295831546
Validation loss: 3.031647937911492

Epoch: 5| Step: 9
Training loss: 3.1427052758420833
Validation loss: 3.0282952402851055

Epoch: 5| Step: 10
Training loss: 2.7169817732001995
Validation loss: 3.0252863630204643

Epoch: 5| Step: 11
Training loss: 2.149444122312238
Validation loss: 3.0225950343839187

Epoch: 46| Step: 0
Training loss: 3.20310371205769
Validation loss: 3.019905192195425

Epoch: 5| Step: 1
Training loss: 2.8854804370503184
Validation loss: 3.0171435293177145

Epoch: 5| Step: 2
Training loss: 2.5360308109962917
Validation loss: 3.014486341667057

Epoch: 5| Step: 3
Training loss: 3.6435778516668513
Validation loss: 3.0121241262479788

Epoch: 5| Step: 4
Training loss: 3.1342494646607304
Validation loss: 3.009281519715119

Epoch: 5| Step: 5
Training loss: 3.2094289386974792
Validation loss: 3.0065701548821844

Epoch: 5| Step: 6
Training loss: 2.569368971899
Validation loss: 3.003633758792296

Epoch: 5| Step: 7
Training loss: 3.5467279210453757
Validation loss: 3.0009188238387243

Epoch: 5| Step: 8
Training loss: 3.496773867810868
Validation loss: 2.9979168427771934

Epoch: 5| Step: 9
Training loss: 3.118034534529807
Validation loss: 2.9951651110907664

Epoch: 5| Step: 10
Training loss: 3.1779513481358026
Validation loss: 2.99234187671634

Epoch: 5| Step: 11
Training loss: 2.630285663538081
Validation loss: 2.9894275303470272

Epoch: 47| Step: 0
Training loss: 3.357485643527993
Validation loss: 2.9868250371693845

Epoch: 5| Step: 1
Training loss: 3.355648511128187
Validation loss: 2.983883003303713

Epoch: 5| Step: 2
Training loss: 2.8818630733007415
Validation loss: 2.980796266011957

Epoch: 5| Step: 3
Training loss: 2.953969198997425
Validation loss: 2.9785547572832796

Epoch: 5| Step: 4
Training loss: 3.329781563270215
Validation loss: 2.975886347376899

Epoch: 5| Step: 5
Training loss: 3.1780019130520976
Validation loss: 2.973222879885321

Epoch: 5| Step: 6
Training loss: 2.9703931577789136
Validation loss: 2.9699096054605745

Epoch: 5| Step: 7
Training loss: 2.818658655551628
Validation loss: 2.9671057179774465

Epoch: 5| Step: 8
Training loss: 3.5981030181589673
Validation loss: 2.964861407790711

Epoch: 5| Step: 9
Training loss: 3.003798305521512
Validation loss: 2.9621529613307955

Epoch: 5| Step: 10
Training loss: 2.6015923758959287
Validation loss: 2.9595110903918442

Epoch: 5| Step: 11
Training loss: 3.539643700982802
Validation loss: 2.956572557128557

Epoch: 48| Step: 0
Training loss: 2.848737932475075
Validation loss: 2.9539658494781933

Epoch: 5| Step: 1
Training loss: 2.621358798365471
Validation loss: 2.9513242805490183

Epoch: 5| Step: 2
Training loss: 3.1293084008787084
Validation loss: 2.9488433565295598

Epoch: 5| Step: 3
Training loss: 2.8099003115038794
Validation loss: 2.9460116904804345

Epoch: 5| Step: 4
Training loss: 3.1105595924838916
Validation loss: 2.943797893296553

Epoch: 5| Step: 5
Training loss: 2.90618272929117
Validation loss: 2.9456803676453074

Epoch: 5| Step: 6
Training loss: 3.1281741996806
Validation loss: 2.9397982473955095

Epoch: 5| Step: 7
Training loss: 3.1798903941812755
Validation loss: 2.9369565176909327

Epoch: 5| Step: 8
Training loss: 3.258813791064028
Validation loss: 2.9338905296101583

Epoch: 5| Step: 9
Training loss: 3.652246353564341
Validation loss: 2.9329045481286267

Epoch: 5| Step: 10
Training loss: 2.912147035617478
Validation loss: 2.929472058321976

Epoch: 5| Step: 11
Training loss: 4.087784708822566
Validation loss: 2.926886525896789

Epoch: 49| Step: 0
Training loss: 3.0236959815118385
Validation loss: 2.9246733553721307

Epoch: 5| Step: 1
Training loss: 3.165272573150898
Validation loss: 2.9214510924651194

Epoch: 5| Step: 2
Training loss: 3.191525329833564
Validation loss: 2.918938315263931

Epoch: 5| Step: 3
Training loss: 3.8229790179220404
Validation loss: 2.9157622887989874

Epoch: 5| Step: 4
Training loss: 2.7824501277159164
Validation loss: 2.9133652849285685

Epoch: 5| Step: 5
Training loss: 2.9131144190696165
Validation loss: 2.9103964072860133

Epoch: 5| Step: 6
Training loss: 3.3222959092075772
Validation loss: 2.9069802347853497

Epoch: 5| Step: 7
Training loss: 2.913611655860223
Validation loss: 2.903664710606451

Epoch: 5| Step: 8
Training loss: 2.5663259833338348
Validation loss: 2.900744035384336

Epoch: 5| Step: 9
Training loss: 2.9283821961942236
Validation loss: 2.8974230757072674

Epoch: 5| Step: 10
Training loss: 2.794475015869501
Validation loss: 2.8948397795879415

Epoch: 5| Step: 11
Training loss: 2.8878163482306833
Validation loss: 2.892356656302484

Epoch: 50| Step: 0
Training loss: 2.955676717194792
Validation loss: 2.888634059642152

Epoch: 5| Step: 1
Training loss: 3.027794510292536
Validation loss: 2.8868850192105158

Epoch: 5| Step: 2
Training loss: 2.9933104636402623
Validation loss: 2.8846112319516997

Epoch: 5| Step: 3
Training loss: 3.15503117662312
Validation loss: 2.8809863873947656

Epoch: 5| Step: 4
Training loss: 2.7347553969498333
Validation loss: 2.8795896570449684

Epoch: 5| Step: 5
Training loss: 2.9684708313436543
Validation loss: 2.8759616300910893

Epoch: 5| Step: 6
Training loss: 3.303894380668559
Validation loss: 2.8745104054968054

Epoch: 5| Step: 7
Training loss: 3.041866156598716
Validation loss: 2.871160434631843

Epoch: 5| Step: 8
Training loss: 2.8024764417462937
Validation loss: 2.86797649327425

Epoch: 5| Step: 9
Training loss: 2.7655447393290733
Validation loss: 2.8664467432435763

Epoch: 5| Step: 10
Training loss: 3.2340388468884527
Validation loss: 2.864257489948014

Epoch: 5| Step: 11
Training loss: 3.8141865986314416
Validation loss: 2.8622091071956377

Testing loss: 2.421123840885658
