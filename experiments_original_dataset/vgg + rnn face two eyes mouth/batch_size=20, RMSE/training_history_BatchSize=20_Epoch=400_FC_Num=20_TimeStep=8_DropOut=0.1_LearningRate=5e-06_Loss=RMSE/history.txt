Epoch: 1| Step: 0
Training loss: 5.736216735277881
Validation loss: 5.9307124776971945

Epoch: 5| Step: 1
Training loss: 5.682465725152181
Validation loss: 5.928745642283843

Epoch: 5| Step: 2
Training loss: 7.0730975825038
Validation loss: 5.926833432990533

Epoch: 5| Step: 3
Training loss: 6.261639552290798
Validation loss: 5.92489874950444

Epoch: 5| Step: 4
Training loss: 6.477059302700058
Validation loss: 5.923002164288246

Epoch: 5| Step: 5
Training loss: 4.787136070024507
Validation loss: 5.921145626568501

Epoch: 5| Step: 6
Training loss: 6.2568825019972065
Validation loss: 5.9192902183858624

Epoch: 5| Step: 7
Training loss: 5.644144666692615
Validation loss: 5.9173680503154

Epoch: 5| Step: 8
Training loss: 5.453330661863188
Validation loss: 5.915439017183909

Epoch: 5| Step: 9
Training loss: 6.457439172024804
Validation loss: 5.913476804944583

Epoch: 5| Step: 10
Training loss: 6.423544562284311
Validation loss: 5.9114532291429525

Epoch: 5| Step: 11
Training loss: 5.15907441435634
Validation loss: 5.90941555897555

Epoch: 2| Step: 0
Training loss: 6.325409935494362
Validation loss: 5.907352452264455

Epoch: 5| Step: 1
Training loss: 6.580297550790055
Validation loss: 5.905088899240945

Epoch: 5| Step: 2
Training loss: 5.814848722686138
Validation loss: 5.902826383303316

Epoch: 5| Step: 3
Training loss: 5.541123193847042
Validation loss: 5.90041772473571

Epoch: 5| Step: 4
Training loss: 6.626340910326247
Validation loss: 5.897851957853054

Epoch: 5| Step: 5
Training loss: 5.087196299792938
Validation loss: 5.895282823002789

Epoch: 5| Step: 6
Training loss: 6.224288237911505
Validation loss: 5.892735394132546

Epoch: 5| Step: 7
Training loss: 6.529608269197312
Validation loss: 5.889851742828541

Epoch: 5| Step: 8
Training loss: 6.447430996534831
Validation loss: 5.886927239215645

Epoch: 5| Step: 9
Training loss: 4.960691815397679
Validation loss: 5.88401807072914

Epoch: 5| Step: 10
Training loss: 5.598469538680827
Validation loss: 5.88075768264489

Epoch: 5| Step: 11
Training loss: 6.404989872253654
Validation loss: 5.877482241570329

Epoch: 3| Step: 0
Training loss: 6.238116143322287
Validation loss: 5.873919773217648

Epoch: 5| Step: 1
Training loss: 5.6913117431669615
Validation loss: 5.870333536269621

Epoch: 5| Step: 2
Training loss: 5.762039517024502
Validation loss: 5.866548451764273

Epoch: 5| Step: 3
Training loss: 6.069638169390678
Validation loss: 5.8626732389207765

Epoch: 5| Step: 4
Training loss: 5.960817188333691
Validation loss: 5.858505862731075

Epoch: 5| Step: 5
Training loss: 6.01874506901651
Validation loss: 5.854122191109731

Epoch: 5| Step: 6
Training loss: 6.03096727093959
Validation loss: 5.849564962160106

Epoch: 5| Step: 7
Training loss: 6.015545733041067
Validation loss: 5.844766898933581

Epoch: 5| Step: 8
Training loss: 5.979912191913694
Validation loss: 5.839821227507607

Epoch: 5| Step: 9
Training loss: 6.536713427749715
Validation loss: 5.8346653325793

Epoch: 5| Step: 10
Training loss: 5.565811029031499
Validation loss: 5.829437169508012

Epoch: 5| Step: 11
Training loss: 4.358805738901703
Validation loss: 5.823599018476887

Epoch: 4| Step: 0
Training loss: 5.627065321794495
Validation loss: 5.818123670850974

Epoch: 5| Step: 1
Training loss: 5.900179857001878
Validation loss: 5.812214341886427

Epoch: 5| Step: 2
Training loss: 5.9453991195644695
Validation loss: 5.805964805571259

Epoch: 5| Step: 3
Training loss: 6.790742058409922
Validation loss: 5.799666165467591

Epoch: 5| Step: 4
Training loss: 5.253440637767396
Validation loss: 5.793250548869058

Epoch: 5| Step: 5
Training loss: 6.112892172622655
Validation loss: 5.786602436220467

Epoch: 5| Step: 6
Training loss: 5.7241099102949375
Validation loss: 5.779543299963181

Epoch: 5| Step: 7
Training loss: 6.255394095638423
Validation loss: 5.772562389959042

Epoch: 5| Step: 8
Training loss: 6.079087051313001
Validation loss: 5.765156741541113

Epoch: 5| Step: 9
Training loss: 5.7935580817475225
Validation loss: 5.758087965967875

Epoch: 5| Step: 10
Training loss: 5.604703270087324
Validation loss: 5.750131363681185

Epoch: 5| Step: 11
Training loss: 4.025011306652039
Validation loss: 5.7423654610873704

Epoch: 5| Step: 0
Training loss: 5.935382666266728
Validation loss: 5.734593414110782

Epoch: 5| Step: 1
Training loss: 6.352389461271701
Validation loss: 5.72667278688405

Epoch: 5| Step: 2
Training loss: 4.923939299245702
Validation loss: 5.718489948467664

Epoch: 5| Step: 3
Training loss: 5.578653262472977
Validation loss: 5.710008746606437

Epoch: 5| Step: 4
Training loss: 5.662727482754694
Validation loss: 5.701518768842564

Epoch: 5| Step: 5
Training loss: 5.188975848100745
Validation loss: 5.6925907338086805

Epoch: 5| Step: 6
Training loss: 5.857238217152407
Validation loss: 5.68344439717766

Epoch: 5| Step: 7
Training loss: 6.292018787896782
Validation loss: 5.674661524589409

Epoch: 5| Step: 8
Training loss: 6.189030621722686
Validation loss: 5.6648908829287885

Epoch: 5| Step: 9
Training loss: 5.219541935024051
Validation loss: 5.655165840626823

Epoch: 5| Step: 10
Training loss: 6.322835788701829
Validation loss: 5.645105915669626

Epoch: 5| Step: 11
Training loss: 6.41959535553516
Validation loss: 5.635232752010052

Epoch: 6| Step: 0
Training loss: 5.989907996182778
Validation loss: 5.624395768950001

Epoch: 5| Step: 1
Training loss: 6.63403567840302
Validation loss: 5.613871359993075

Epoch: 5| Step: 2
Training loss: 5.501433272443415
Validation loss: 5.602823637761678

Epoch: 5| Step: 3
Training loss: 5.722859558035309
Validation loss: 5.592677484196216

Epoch: 5| Step: 4
Training loss: 5.124868065601234
Validation loss: 5.581892790877964

Epoch: 5| Step: 5
Training loss: 5.565183185259767
Validation loss: 5.571095900623657

Epoch: 5| Step: 6
Training loss: 5.884493036853834
Validation loss: 5.560363137635572

Epoch: 5| Step: 7
Training loss: 5.476180777531283
Validation loss: 5.549841618497532

Epoch: 5| Step: 8
Training loss: 5.821166437985644
Validation loss: 5.538867044878737

Epoch: 5| Step: 9
Training loss: 4.914168073190263
Validation loss: 5.528542684011177

Epoch: 5| Step: 10
Training loss: 5.79453545012572
Validation loss: 5.518030544401098

Epoch: 5| Step: 11
Training loss: 5.5325781310675755
Validation loss: 5.507078528592509

Epoch: 7| Step: 0
Training loss: 5.603733636890477
Validation loss: 5.496521507233367

Epoch: 5| Step: 1
Training loss: 5.744797052661611
Validation loss: 5.485394795112553

Epoch: 5| Step: 2
Training loss: 5.104880312899922
Validation loss: 5.474182373553177

Epoch: 5| Step: 3
Training loss: 5.450423568924573
Validation loss: 5.464171194846774

Epoch: 5| Step: 4
Training loss: 6.181604215927533
Validation loss: 5.453577789774965

Epoch: 5| Step: 5
Training loss: 5.9951186987139735
Validation loss: 5.443675630268032

Epoch: 5| Step: 6
Training loss: 5.461280822876476
Validation loss: 5.433356639406423

Epoch: 5| Step: 7
Training loss: 5.802548986225694
Validation loss: 5.42306446143205

Epoch: 5| Step: 8
Training loss: 5.360232448661767
Validation loss: 5.412970465343143

Epoch: 5| Step: 9
Training loss: 5.049894108936801
Validation loss: 5.403818837042921

Epoch: 5| Step: 10
Training loss: 5.230513056139363
Validation loss: 5.394788068863584

Epoch: 5| Step: 11
Training loss: 6.026026860655518
Validation loss: 5.386086142546972

Epoch: 8| Step: 0
Training loss: 5.681897768330213
Validation loss: 5.37753042643115

Epoch: 5| Step: 1
Training loss: 5.10455318726107
Validation loss: 5.368874748773108

Epoch: 5| Step: 2
Training loss: 6.735937658569646
Validation loss: 5.36053907173358

Epoch: 5| Step: 3
Training loss: 5.018947938505024
Validation loss: 5.352409886007385

Epoch: 5| Step: 4
Training loss: 4.913617476309202
Validation loss: 5.344873031485596

Epoch: 5| Step: 5
Training loss: 5.634806921425795
Validation loss: 5.3368647055104645

Epoch: 5| Step: 6
Training loss: 5.587110105561286
Validation loss: 5.3289734210583175

Epoch: 5| Step: 7
Training loss: 5.843261045511838
Validation loss: 5.322537024808045

Epoch: 5| Step: 8
Training loss: 4.917378821225343
Validation loss: 5.315164436423516

Epoch: 5| Step: 9
Training loss: 5.466303338018074
Validation loss: 5.30804847759445

Epoch: 5| Step: 10
Training loss: 4.878150508796813
Validation loss: 5.301587277073539

Epoch: 5| Step: 11
Training loss: 5.443122149589477
Validation loss: 5.294767510014235

Epoch: 9| Step: 0
Training loss: 5.412907905272987
Validation loss: 5.2881744029828015

Epoch: 5| Step: 1
Training loss: 5.168251819888355
Validation loss: 5.281186647053985

Epoch: 5| Step: 2
Training loss: 5.199219300279366
Validation loss: 5.274610698791788

Epoch: 5| Step: 3
Training loss: 5.633854826465488
Validation loss: 5.26843273645111

Epoch: 5| Step: 4
Training loss: 5.5547347140552334
Validation loss: 5.2615312232773395

Epoch: 5| Step: 5
Training loss: 5.584544700430681
Validation loss: 5.254686882328296

Epoch: 5| Step: 6
Training loss: 6.185869714992337
Validation loss: 5.248780404075727

Epoch: 5| Step: 7
Training loss: 4.784066561194407
Validation loss: 5.241013631891143

Epoch: 5| Step: 8
Training loss: 4.716552626957673
Validation loss: 5.234096295732404

Epoch: 5| Step: 9
Training loss: 5.038399302288067
Validation loss: 5.228070135260027

Epoch: 5| Step: 10
Training loss: 5.890300549544551
Validation loss: 5.221715286463613

Epoch: 5| Step: 11
Training loss: 4.259065720097011
Validation loss: 5.214860010776575

Epoch: 10| Step: 0
Training loss: 5.556357088548124
Validation loss: 5.20836023196586

Epoch: 5| Step: 1
Training loss: 4.683246564683533
Validation loss: 5.202048403197827

Epoch: 5| Step: 2
Training loss: 5.378776288315142
Validation loss: 5.195743606004726

Epoch: 5| Step: 3
Training loss: 5.07987743950728
Validation loss: 5.189550523055697

Epoch: 5| Step: 4
Training loss: 5.569627631460204
Validation loss: 5.183529586797337

Epoch: 5| Step: 5
Training loss: 5.202049533712294
Validation loss: 5.177918766498434

Epoch: 5| Step: 6
Training loss: 5.216291385269811
Validation loss: 5.170955779874648

Epoch: 5| Step: 7
Training loss: 4.328434791908356
Validation loss: 5.1641728037847505

Epoch: 5| Step: 8
Training loss: 6.022588806130996
Validation loss: 5.1579759964968055

Epoch: 5| Step: 9
Training loss: 4.9820687151273795
Validation loss: 5.150559439102805

Epoch: 5| Step: 10
Training loss: 5.770865025989895
Validation loss: 5.1442712763021765

Epoch: 5| Step: 11
Training loss: 6.546131756457426
Validation loss: 5.137192326944568

Epoch: 11| Step: 0
Training loss: 4.79588919086998
Validation loss: 5.129619369650867

Epoch: 5| Step: 1
Training loss: 4.4188584461420595
Validation loss: 5.122680255367645

Epoch: 5| Step: 2
Training loss: 5.647382160120844
Validation loss: 5.1158501272779775

Epoch: 5| Step: 3
Training loss: 5.691229970030849
Validation loss: 5.108137877284041

Epoch: 5| Step: 4
Training loss: 4.860777232496371
Validation loss: 5.102063935714033

Epoch: 5| Step: 5
Training loss: 5.6668588194337906
Validation loss: 5.094276112415041

Epoch: 5| Step: 6
Training loss: 4.707654628391905
Validation loss: 5.087383222997109

Epoch: 5| Step: 7
Training loss: 5.938806972210314
Validation loss: 5.081642356886143

Epoch: 5| Step: 8
Training loss: 5.208860975877128
Validation loss: 5.075331709032506

Epoch: 5| Step: 9
Training loss: 4.9081285124153755
Validation loss: 5.069311089118891

Epoch: 5| Step: 10
Training loss: 4.9218924385851786
Validation loss: 5.063018528948528

Epoch: 5| Step: 11
Training loss: 6.927148192443852
Validation loss: 5.056809111286013

Epoch: 12| Step: 0
Training loss: 5.144180691418403
Validation loss: 5.050702512618584

Epoch: 5| Step: 1
Training loss: 4.682143953374572
Validation loss: 5.044726391730424

Epoch: 5| Step: 2
Training loss: 5.391436794909217
Validation loss: 5.038979226540611

Epoch: 5| Step: 3
Training loss: 5.455564985938294
Validation loss: 5.033633597472457

Epoch: 5| Step: 4
Training loss: 5.8907788001100645
Validation loss: 5.0270239257253255

Epoch: 5| Step: 5
Training loss: 4.572847103670198
Validation loss: 5.021725217923317

Epoch: 5| Step: 6
Training loss: 4.846699856238259
Validation loss: 5.015458465695244

Epoch: 5| Step: 7
Training loss: 4.579004196788217
Validation loss: 5.010530540562805

Epoch: 5| Step: 8
Training loss: 5.635446638872564
Validation loss: 5.0046872262342275

Epoch: 5| Step: 9
Training loss: 4.750988907518648
Validation loss: 5.000100659310867

Epoch: 5| Step: 10
Training loss: 5.360446478054957
Validation loss: 4.9940378006688615

Epoch: 5| Step: 11
Training loss: 5.653310443963791
Validation loss: 4.988577590699391

Epoch: 13| Step: 0
Training loss: 5.0196568336065415
Validation loss: 4.982731539241085

Epoch: 5| Step: 1
Training loss: 5.374595804320029
Validation loss: 4.977376778426703

Epoch: 5| Step: 2
Training loss: 4.64034755917816
Validation loss: 4.972105728444655

Epoch: 5| Step: 3
Training loss: 5.387794171508958
Validation loss: 4.965835300199133

Epoch: 5| Step: 4
Training loss: 4.7363589319230055
Validation loss: 4.960914271342846

Epoch: 5| Step: 5
Training loss: 5.566656724079565
Validation loss: 4.955459381580593

Epoch: 5| Step: 6
Training loss: 5.1408090297606615
Validation loss: 4.950346760211949

Epoch: 5| Step: 7
Training loss: 4.633889804786082
Validation loss: 4.944562681382206

Epoch: 5| Step: 8
Training loss: 5.127888121588108
Validation loss: 4.938737907230728

Epoch: 5| Step: 9
Training loss: 4.586015690879414
Validation loss: 4.934451308816989

Epoch: 5| Step: 10
Training loss: 5.432523181793846
Validation loss: 4.929546839847906

Epoch: 5| Step: 11
Training loss: 5.6218659889102325
Validation loss: 4.923840149629349

Epoch: 14| Step: 0
Training loss: 4.072704703172471
Validation loss: 4.918607315327044

Epoch: 5| Step: 1
Training loss: 4.226966373234945
Validation loss: 4.914432376269668

Epoch: 5| Step: 2
Training loss: 5.2973828817745625
Validation loss: 4.910120115953936

Epoch: 5| Step: 3
Training loss: 5.271388852645099
Validation loss: 4.904569965893425

Epoch: 5| Step: 4
Training loss: 5.615051457618541
Validation loss: 4.898339846021423

Epoch: 5| Step: 5
Training loss: 5.168944482246532
Validation loss: 4.893133826051923

Epoch: 5| Step: 6
Training loss: 4.743785607728267
Validation loss: 4.88764050859791

Epoch: 5| Step: 7
Training loss: 5.278213621291054
Validation loss: 4.882599295475496

Epoch: 5| Step: 8
Training loss: 4.6436092144866405
Validation loss: 4.878189734730548

Epoch: 5| Step: 9
Training loss: 5.074032868937066
Validation loss: 4.872611512209194

Epoch: 5| Step: 10
Training loss: 5.254840435941148
Validation loss: 4.867171996261862

Epoch: 5| Step: 11
Training loss: 6.379959869736887
Validation loss: 4.862293082756705

Epoch: 15| Step: 0
Training loss: 5.059272773562862
Validation loss: 4.856419963963565

Epoch: 5| Step: 1
Training loss: 4.916291087832649
Validation loss: 4.850235155965749

Epoch: 5| Step: 2
Training loss: 5.783236435546587
Validation loss: 4.845045658863555

Epoch: 5| Step: 3
Training loss: 4.217047906058477
Validation loss: 4.840387288695337

Epoch: 5| Step: 4
Training loss: 4.539973208646665
Validation loss: 4.835552596724082

Epoch: 5| Step: 5
Training loss: 4.300387857377164
Validation loss: 4.828683617135808

Epoch: 5| Step: 6
Training loss: 5.1030133040679155
Validation loss: 4.823903638507274

Epoch: 5| Step: 7
Training loss: 5.45524333044013
Validation loss: 4.818711837868126

Epoch: 5| Step: 8
Training loss: 4.648074557456539
Validation loss: 4.813598969721144

Epoch: 5| Step: 9
Training loss: 5.526558820978331
Validation loss: 4.807955945684814

Epoch: 5| Step: 10
Training loss: 4.810661460140594
Validation loss: 4.802858503862125

Epoch: 5| Step: 11
Training loss: 4.389952475740234
Validation loss: 4.79667760917117

Epoch: 16| Step: 0
Training loss: 5.299387288214852
Validation loss: 4.791716578126885

Epoch: 5| Step: 1
Training loss: 5.10555897102523
Validation loss: 4.786120773992503

Epoch: 5| Step: 2
Training loss: 4.357584705328323
Validation loss: 4.781308915517007

Epoch: 5| Step: 3
Training loss: 4.7027636417707965
Validation loss: 4.776714858517228

Epoch: 5| Step: 4
Training loss: 5.66655454337699
Validation loss: 4.771534421233857

Epoch: 5| Step: 5
Training loss: 4.155279289985597
Validation loss: 4.765460619149933

Epoch: 5| Step: 6
Training loss: 5.185195410935345
Validation loss: 4.75977073421838

Epoch: 5| Step: 7
Training loss: 4.591212603393102
Validation loss: 4.754167652492215

Epoch: 5| Step: 8
Training loss: 4.002518099684955
Validation loss: 4.748410695201067

Epoch: 5| Step: 9
Training loss: 5.5464233214537995
Validation loss: 4.7437484912090895

Epoch: 5| Step: 10
Training loss: 4.839901878371166
Validation loss: 4.738646817866308

Epoch: 5| Step: 11
Training loss: 5.137103976465208
Validation loss: 4.732545010083477

Epoch: 17| Step: 0
Training loss: 4.816847781743807
Validation loss: 4.726418073144763

Epoch: 5| Step: 1
Training loss: 4.697514733194469
Validation loss: 4.722301266825213

Epoch: 5| Step: 2
Training loss: 4.874242870517534
Validation loss: 4.7158266152909665

Epoch: 5| Step: 3
Training loss: 3.967617924745922
Validation loss: 4.709372003592736

Epoch: 5| Step: 4
Training loss: 4.942837691012852
Validation loss: 4.703723408933655

Epoch: 5| Step: 5
Training loss: 4.844476657628119
Validation loss: 4.698861573371101

Epoch: 5| Step: 6
Training loss: 4.000064849327837
Validation loss: 4.692460923300618

Epoch: 5| Step: 7
Training loss: 5.069013385067951
Validation loss: 4.6869777642844355

Epoch: 5| Step: 8
Training loss: 4.928080011040288
Validation loss: 4.682208410194008

Epoch: 5| Step: 9
Training loss: 5.383959909513719
Validation loss: 4.676824968957344

Epoch: 5| Step: 10
Training loss: 5.406318267214843
Validation loss: 4.672608457251902

Epoch: 5| Step: 11
Training loss: 4.395671293095442
Validation loss: 4.666189010334627

Epoch: 18| Step: 0
Training loss: 4.531595572086622
Validation loss: 4.661066359195371

Epoch: 5| Step: 1
Training loss: 4.204678953708567
Validation loss: 4.655827650334486

Epoch: 5| Step: 2
Training loss: 4.163321767342483
Validation loss: 4.65068972866156

Epoch: 5| Step: 3
Training loss: 5.4333292432586315
Validation loss: 4.644561579257423

Epoch: 5| Step: 4
Training loss: 4.800874217214164
Validation loss: 4.640380065139722

Epoch: 5| Step: 5
Training loss: 3.839886468162686
Validation loss: 4.633944694175291

Epoch: 5| Step: 6
Training loss: 5.294909987652646
Validation loss: 4.6286696061005

Epoch: 5| Step: 7
Training loss: 5.0623281944226886
Validation loss: 4.624045960943143

Epoch: 5| Step: 8
Training loss: 5.035458149526691
Validation loss: 4.6187569349320325

Epoch: 5| Step: 9
Training loss: 4.64665472641172
Validation loss: 4.612879077458567

Epoch: 5| Step: 10
Training loss: 4.943554799389346
Validation loss: 4.607380593936815

Epoch: 5| Step: 11
Training loss: 5.460103376478869
Validation loss: 4.6026643946026145

Epoch: 19| Step: 0
Training loss: 5.332375182073881
Validation loss: 4.59657414443964

Epoch: 5| Step: 1
Training loss: 4.761227038611791
Validation loss: 4.591523632214864

Epoch: 5| Step: 2
Training loss: 4.3389908221117635
Validation loss: 4.586763622731732

Epoch: 5| Step: 3
Training loss: 4.4012784574412604
Validation loss: 4.58116037125839

Epoch: 5| Step: 4
Training loss: 3.937695331875279
Validation loss: 4.574605003009347

Epoch: 5| Step: 5
Training loss: 4.19127336986476
Validation loss: 4.56980108024347

Epoch: 5| Step: 6
Training loss: 5.043013379692137
Validation loss: 4.564504492267581

Epoch: 5| Step: 7
Training loss: 4.094888543369305
Validation loss: 4.55968656845838

Epoch: 5| Step: 8
Training loss: 5.3181458037015785
Validation loss: 4.55495472599034

Epoch: 5| Step: 9
Training loss: 5.143018727564589
Validation loss: 4.548991537646277

Epoch: 5| Step: 10
Training loss: 5.0033872574948575
Validation loss: 4.544647483919686

Epoch: 5| Step: 11
Training loss: 3.7764228716074943
Validation loss: 4.5411559643132735

Epoch: 20| Step: 0
Training loss: 5.104706570881884
Validation loss: 4.536837559414276

Epoch: 5| Step: 1
Training loss: 4.580812882494625
Validation loss: 4.529212195276672

Epoch: 5| Step: 2
Training loss: 4.581634322175199
Validation loss: 4.523302303527309

Epoch: 5| Step: 3
Training loss: 4.621584481683516
Validation loss: 4.51680164780629

Epoch: 5| Step: 4
Training loss: 5.268847286099984
Validation loss: 4.513398595086418

Epoch: 5| Step: 5
Training loss: 3.819237306160622
Validation loss: 4.5074177640246065

Epoch: 5| Step: 6
Training loss: 4.438087531940093
Validation loss: 4.501627910173658

Epoch: 5| Step: 7
Training loss: 4.639800027287048
Validation loss: 4.495922386953797

Epoch: 5| Step: 8
Training loss: 4.707543816101723
Validation loss: 4.49067152012935

Epoch: 5| Step: 9
Training loss: 3.927791191005031
Validation loss: 4.486009049739091

Epoch: 5| Step: 10
Training loss: 4.9169255635692375
Validation loss: 4.4807947999672395

Epoch: 5| Step: 11
Training loss: 5.480943437657141
Validation loss: 4.475302118797631

Epoch: 21| Step: 0
Training loss: 5.44975443295536
Validation loss: 4.469569284523633

Epoch: 5| Step: 1
Training loss: 4.802593786067546
Validation loss: 4.464772897749446

Epoch: 5| Step: 2
Training loss: 4.823239320490391
Validation loss: 4.459349626354447

Epoch: 5| Step: 3
Training loss: 3.7495526364827687
Validation loss: 4.454781127288306

Epoch: 5| Step: 4
Training loss: 4.793218256418344
Validation loss: 4.449345775261245

Epoch: 5| Step: 5
Training loss: 4.193067578707084
Validation loss: 4.443213393499694

Epoch: 5| Step: 6
Training loss: 4.897688666969803
Validation loss: 4.437621128417023

Epoch: 5| Step: 7
Training loss: 4.200398181024079
Validation loss: 4.432981384380531

Epoch: 5| Step: 8
Training loss: 4.250169638445788
Validation loss: 4.427849829646065

Epoch: 5| Step: 9
Training loss: 5.06825456749776
Validation loss: 4.422131516347972

Epoch: 5| Step: 10
Training loss: 3.8516985577119063
Validation loss: 4.416476118127927

Epoch: 5| Step: 11
Training loss: 4.123505986473574
Validation loss: 4.4111863119605275

Epoch: 22| Step: 0
Training loss: 4.389180118754317
Validation loss: 4.406858605092072

Epoch: 5| Step: 1
Training loss: 4.9078829046456365
Validation loss: 4.402088003280962

Epoch: 5| Step: 2
Training loss: 4.653958774569305
Validation loss: 4.396356916055797

Epoch: 5| Step: 3
Training loss: 4.860450355793464
Validation loss: 4.390667346103043

Epoch: 5| Step: 4
Training loss: 4.237936288884893
Validation loss: 4.384776477191412

Epoch: 5| Step: 5
Training loss: 4.467850601280366
Validation loss: 4.379651725623843

Epoch: 5| Step: 6
Training loss: 4.156618030287007
Validation loss: 4.375270249330528

Epoch: 5| Step: 7
Training loss: 4.958111584403727
Validation loss: 4.37067157887283

Epoch: 5| Step: 8
Training loss: 4.594852237421812
Validation loss: 4.364622560505388

Epoch: 5| Step: 9
Training loss: 4.977023547986969
Validation loss: 4.3590473430192365

Epoch: 5| Step: 10
Training loss: 3.212744434126566
Validation loss: 4.353795663946629

Epoch: 5| Step: 11
Training loss: 3.98019992268737
Validation loss: 4.348427986502878

Epoch: 23| Step: 0
Training loss: 3.67955959608021
Validation loss: 4.3439339797762

Epoch: 5| Step: 1
Training loss: 3.929902997943103
Validation loss: 4.339298153335591

Epoch: 5| Step: 2
Training loss: 4.88951902711589
Validation loss: 4.333272780704466

Epoch: 5| Step: 3
Training loss: 4.96188167688334
Validation loss: 4.327712065717862

Epoch: 5| Step: 4
Training loss: 5.325785282598499
Validation loss: 4.322308700583609

Epoch: 5| Step: 5
Training loss: 4.645889532778545
Validation loss: 4.317736174244807

Epoch: 5| Step: 6
Training loss: 4.068238416348759
Validation loss: 4.312507468138785

Epoch: 5| Step: 7
Training loss: 4.173253892339496
Validation loss: 4.307098073733312

Epoch: 5| Step: 8
Training loss: 3.4714093710689626
Validation loss: 4.3008546560215075

Epoch: 5| Step: 9
Training loss: 4.876479291221276
Validation loss: 4.296490650904791

Epoch: 5| Step: 10
Training loss: 4.518908933427227
Validation loss: 4.29101533792825

Epoch: 5| Step: 11
Training loss: 4.406381591563394
Validation loss: 4.286299797207153

Epoch: 24| Step: 0
Training loss: 3.9633931931278936
Validation loss: 4.281856150539479

Epoch: 5| Step: 1
Training loss: 4.695904331071095
Validation loss: 4.27702774901148

Epoch: 5| Step: 2
Training loss: 3.5197129282066264
Validation loss: 4.2714326934176405

Epoch: 5| Step: 3
Training loss: 4.631924162894473
Validation loss: 4.266653176872465

Epoch: 5| Step: 4
Training loss: 4.384590753751239
Validation loss: 4.261700381604501

Epoch: 5| Step: 5
Training loss: 4.095219705018651
Validation loss: 4.256161944374263

Epoch: 5| Step: 6
Training loss: 3.764619305172625
Validation loss: 4.250969392884513

Epoch: 5| Step: 7
Training loss: 4.91797534314987
Validation loss: 4.245971682612068

Epoch: 5| Step: 8
Training loss: 4.24473896891017
Validation loss: 4.241352966352395

Epoch: 5| Step: 9
Training loss: 4.964304344714687
Validation loss: 4.2355564341428

Epoch: 5| Step: 10
Training loss: 4.698839028000381
Validation loss: 4.231287305546307

Epoch: 5| Step: 11
Training loss: 4.870995270468527
Validation loss: 4.225720117735298

Epoch: 25| Step: 0
Training loss: 4.450183633165769
Validation loss: 4.220358657254962

Epoch: 5| Step: 1
Training loss: 3.0487227094804403
Validation loss: 4.2144577325700325

Epoch: 5| Step: 2
Training loss: 4.480351467310336
Validation loss: 4.209944533060468

Epoch: 5| Step: 3
Training loss: 4.4085648320257045
Validation loss: 4.204915002333503

Epoch: 5| Step: 4
Training loss: 4.432591261938118
Validation loss: 4.199826606698375

Epoch: 5| Step: 5
Training loss: 3.9321840519947955
Validation loss: 4.194687790299314

Epoch: 5| Step: 6
Training loss: 4.163887979310688
Validation loss: 4.189142379558806

Epoch: 5| Step: 7
Training loss: 4.831286336705404
Validation loss: 4.1847982278521965

Epoch: 5| Step: 8
Training loss: 4.413099227719809
Validation loss: 4.179528767551516

Epoch: 5| Step: 9
Training loss: 4.8737016562847435
Validation loss: 4.174120628426461

Epoch: 5| Step: 10
Training loss: 4.239117770989426
Validation loss: 4.169361743336953

Epoch: 5| Step: 11
Training loss: 4.401715481733105
Validation loss: 4.163658299012257

Epoch: 26| Step: 0
Training loss: 4.455295609279418
Validation loss: 4.159384432313133

Epoch: 5| Step: 1
Training loss: 4.453047045644438
Validation loss: 4.15360023050975

Epoch: 5| Step: 2
Training loss: 3.5937032945334573
Validation loss: 4.148145925233323

Epoch: 5| Step: 3
Training loss: 4.6033163306723095
Validation loss: 4.143193303721658

Epoch: 5| Step: 4
Training loss: 4.175033002711531
Validation loss: 4.13850727747121

Epoch: 5| Step: 5
Training loss: 3.8086876490828656
Validation loss: 4.132956508922982

Epoch: 5| Step: 6
Training loss: 4.402962398301781
Validation loss: 4.12756356140124

Epoch: 5| Step: 7
Training loss: 4.074549485092766
Validation loss: 4.12379233667049

Epoch: 5| Step: 8
Training loss: 4.546223911717147
Validation loss: 4.117784721012739

Epoch: 5| Step: 9
Training loss: 4.544699026954972
Validation loss: 4.112715384844427

Epoch: 5| Step: 10
Training loss: 4.227407882110904
Validation loss: 4.107927519516996

Epoch: 5| Step: 11
Training loss: 3.8002940666454954
Validation loss: 4.102815200603711

Epoch: 27| Step: 0
Training loss: 4.397202313243473
Validation loss: 4.098121303936582

Epoch: 5| Step: 1
Training loss: 4.713471953436762
Validation loss: 4.093282643787659

Epoch: 5| Step: 2
Training loss: 4.162810919436116
Validation loss: 4.08847410628106

Epoch: 5| Step: 3
Training loss: 4.438000717926311
Validation loss: 4.082933049466745

Epoch: 5| Step: 4
Training loss: 4.669811596878593
Validation loss: 4.077884525697172

Epoch: 5| Step: 5
Training loss: 3.2703545740358173
Validation loss: 4.071720365494718

Epoch: 5| Step: 6
Training loss: 4.069483462086234
Validation loss: 4.067220713181454

Epoch: 5| Step: 7
Training loss: 3.8570309829634555
Validation loss: 4.062263442757129

Epoch: 5| Step: 8
Training loss: 4.274394763243214
Validation loss: 4.056460370886496

Epoch: 5| Step: 9
Training loss: 4.489550431817643
Validation loss: 4.050858293644898

Epoch: 5| Step: 10
Training loss: 3.8114512517584753
Validation loss: 4.046259908191647

Epoch: 5| Step: 11
Training loss: 3.6311218921958384
Validation loss: 4.041259905740743

Epoch: 28| Step: 0
Training loss: 4.79715710534218
Validation loss: 4.03700709724763

Epoch: 5| Step: 1
Training loss: 4.512703871414465
Validation loss: 4.032788522760646

Epoch: 5| Step: 2
Training loss: 4.571268095878269
Validation loss: 4.026934277610672

Epoch: 5| Step: 3
Training loss: 3.983759694178899
Validation loss: 4.022103319897271

Epoch: 5| Step: 4
Training loss: 3.6370766829261867
Validation loss: 4.016526290543162

Epoch: 5| Step: 5
Training loss: 4.538118615555091
Validation loss: 4.012896505117773

Epoch: 5| Step: 6
Training loss: 4.161477838055954
Validation loss: 4.007081171425036

Epoch: 5| Step: 7
Training loss: 4.1858922804283445
Validation loss: 4.002171587562536

Epoch: 5| Step: 8
Training loss: 3.7219310586520655
Validation loss: 3.997079771720206

Epoch: 5| Step: 9
Training loss: 4.034422106951694
Validation loss: 3.992075142769228

Epoch: 5| Step: 10
Training loss: 3.48809315002369
Validation loss: 3.9873996349287926

Epoch: 5| Step: 11
Training loss: 2.7448355124130583
Validation loss: 3.9832295335761687

Epoch: 29| Step: 0
Training loss: 4.760858872768746
Validation loss: 3.978591041805219

Epoch: 5| Step: 1
Training loss: 4.548011873617249
Validation loss: 3.972026398677311

Epoch: 5| Step: 2
Training loss: 4.675232564271996
Validation loss: 3.967738300443

Epoch: 5| Step: 3
Training loss: 3.294134944882376
Validation loss: 3.962205878131212

Epoch: 5| Step: 4
Training loss: 4.252072446074964
Validation loss: 3.9576141139029204

Epoch: 5| Step: 5
Training loss: 3.4465542931994673
Validation loss: 3.9529777821103744

Epoch: 5| Step: 6
Training loss: 3.2027565348761518
Validation loss: 3.9478917620166074

Epoch: 5| Step: 7
Training loss: 4.013372004461012
Validation loss: 3.9426318992284353

Epoch: 5| Step: 8
Training loss: 3.855902835793084
Validation loss: 3.9383104792053008

Epoch: 5| Step: 9
Training loss: 4.663583395422405
Validation loss: 3.932955703078206

Epoch: 5| Step: 10
Training loss: 3.8641500855672084
Validation loss: 3.92854443123859

Epoch: 5| Step: 11
Training loss: 3.95492645349613
Validation loss: 3.9236918948398998

Epoch: 30| Step: 0
Training loss: 4.3637679741258975
Validation loss: 3.9182345806292154

Epoch: 5| Step: 1
Training loss: 3.8671030362856267
Validation loss: 3.9132219783909092

Epoch: 5| Step: 2
Training loss: 4.307449257984059
Validation loss: 3.9078303230303226

Epoch: 5| Step: 3
Training loss: 3.5044389912991485
Validation loss: 3.9021171017781207

Epoch: 5| Step: 4
Training loss: 4.279802732110587
Validation loss: 3.8973492369244656

Epoch: 5| Step: 5
Training loss: 3.877883576556315
Validation loss: 3.893069891930259

Epoch: 5| Step: 6
Training loss: 3.5984276887774005
Validation loss: 3.8886247622773227

Epoch: 5| Step: 7
Training loss: 4.096036781905845
Validation loss: 3.883491768831649

Epoch: 5| Step: 8
Training loss: 4.308865107190394
Validation loss: 3.878617070057557

Epoch: 5| Step: 9
Training loss: 3.8315102070350497
Validation loss: 3.8737138439032686

Epoch: 5| Step: 10
Training loss: 4.051685670038932
Validation loss: 3.869021885510337

Epoch: 5| Step: 11
Training loss: 4.532663269637175
Validation loss: 3.8641103556181737

Epoch: 31| Step: 0
Training loss: 4.1740623197778985
Validation loss: 3.8594604256219465

Epoch: 5| Step: 1
Training loss: 4.3461679000055975
Validation loss: 3.8545355628863676

Epoch: 5| Step: 2
Training loss: 4.305966500527159
Validation loss: 3.8488622437468356

Epoch: 5| Step: 3
Training loss: 3.487333675233064
Validation loss: 3.844204413165765

Epoch: 5| Step: 4
Training loss: 3.8295029009339734
Validation loss: 3.8389672811600604

Epoch: 5| Step: 5
Training loss: 4.310851957019275
Validation loss: 3.8342998709724236

Epoch: 5| Step: 6
Training loss: 4.230892086245994
Validation loss: 3.829760351360984

Epoch: 5| Step: 7
Training loss: 3.680368931355419
Validation loss: 3.8240851228595596

Epoch: 5| Step: 8
Training loss: 3.852534235381957
Validation loss: 3.8192761529586927

Epoch: 5| Step: 9
Training loss: 2.974193361062259
Validation loss: 3.814672929609874

Epoch: 5| Step: 10
Training loss: 4.377986433625931
Validation loss: 3.8103401392612093

Epoch: 5| Step: 11
Training loss: 3.1230555779369826
Validation loss: 3.8049072787015175

Epoch: 32| Step: 0
Training loss: 3.7979646853733082
Validation loss: 3.800467781085905

Epoch: 5| Step: 1
Training loss: 3.51171114605684
Validation loss: 3.795896820154378

Epoch: 5| Step: 2
Training loss: 3.7746641957059226
Validation loss: 3.7912605490843267

Epoch: 5| Step: 3
Training loss: 5.105680570754125
Validation loss: 3.7869646275233837

Epoch: 5| Step: 4
Training loss: 4.1309193996821
Validation loss: 3.7817365422664526

Epoch: 5| Step: 5
Training loss: 3.848579783874077
Validation loss: 3.7768351210128466

Epoch: 5| Step: 6
Training loss: 3.786299683379328
Validation loss: 3.7722688791114107

Epoch: 5| Step: 7
Training loss: 3.7462349110281323
Validation loss: 3.7680792454666445

Epoch: 5| Step: 8
Training loss: 3.7194072238793505
Validation loss: 3.763162865867696

Epoch: 5| Step: 9
Training loss: 3.0048891599908583
Validation loss: 3.7583717992693284

Epoch: 5| Step: 10
Training loss: 4.219109413943442
Validation loss: 3.753581080278034

Epoch: 5| Step: 11
Training loss: 4.157962532304007
Validation loss: 3.749218196965568

Epoch: 33| Step: 0
Training loss: 4.192735274644937
Validation loss: 3.7443408756635765

Epoch: 5| Step: 1
Training loss: 3.614336443264498
Validation loss: 3.7394643922271626

Epoch: 5| Step: 2
Training loss: 3.1088825391762582
Validation loss: 3.7346948196747545

Epoch: 5| Step: 3
Training loss: 3.512588342390572
Validation loss: 3.7298241609302365

Epoch: 5| Step: 4
Training loss: 3.2176437699120317
Validation loss: 3.7255223580031136

Epoch: 5| Step: 5
Training loss: 3.833488350650138
Validation loss: 3.7214551644560108

Epoch: 5| Step: 6
Training loss: 4.180846436872675
Validation loss: 3.7168141249555235

Epoch: 5| Step: 7
Training loss: 4.534275071182005
Validation loss: 3.712281818165246

Epoch: 5| Step: 8
Training loss: 4.1739741269942465
Validation loss: 3.707647515575656

Epoch: 5| Step: 9
Training loss: 3.650215320245543
Validation loss: 3.7027566139059616

Epoch: 5| Step: 10
Training loss: 3.596909436177874
Validation loss: 3.6979457030253293

Epoch: 5| Step: 11
Training loss: 5.946731939313949
Validation loss: 3.693571926801083

Epoch: 34| Step: 0
Training loss: 3.863461327285314
Validation loss: 3.688409547648966

Epoch: 5| Step: 1
Training loss: 3.859267013212802
Validation loss: 3.6834354144114987

Epoch: 5| Step: 2
Training loss: 3.726921400145671
Validation loss: 3.6783711967080874

Epoch: 5| Step: 3
Training loss: 3.7247731133303374
Validation loss: 3.673437949239665

Epoch: 5| Step: 4
Training loss: 3.6275853112966017
Validation loss: 3.6685981684411093

Epoch: 5| Step: 5
Training loss: 3.940018469094301
Validation loss: 3.6635371809689623

Epoch: 5| Step: 6
Training loss: 3.795748194142035
Validation loss: 3.658700165499894

Epoch: 5| Step: 7
Training loss: 4.297295123282425
Validation loss: 3.65373142148529

Epoch: 5| Step: 8
Training loss: 3.621756319170192
Validation loss: 3.648941609682525

Epoch: 5| Step: 9
Training loss: 3.356016387481145
Validation loss: 3.6441700801721426

Epoch: 5| Step: 10
Training loss: 3.98555053124526
Validation loss: 3.63920293165487

Epoch: 5| Step: 11
Training loss: 3.4786672328871995
Validation loss: 3.63469315937826

Epoch: 35| Step: 0
Training loss: 3.8759880036915417
Validation loss: 3.63015296963143

Epoch: 5| Step: 1
Training loss: 3.739428432872815
Validation loss: 3.6256165035020893

Epoch: 5| Step: 2
Training loss: 3.385211331913969
Validation loss: 3.6212529185516744

Epoch: 5| Step: 3
Training loss: 3.8973371217961343
Validation loss: 3.6164531800037985

Epoch: 5| Step: 4
Training loss: 3.183400228972516
Validation loss: 3.61205059366852

Epoch: 5| Step: 5
Training loss: 3.527886873762732
Validation loss: 3.607768919339975

Epoch: 5| Step: 6
Training loss: 3.912196401693658
Validation loss: 3.6033933872073085

Epoch: 5| Step: 7
Training loss: 3.772547014574219
Validation loss: 3.599381504307981

Epoch: 5| Step: 8
Training loss: 4.049884634376369
Validation loss: 3.594985199549861

Epoch: 5| Step: 9
Training loss: 3.761484869700767
Validation loss: 3.5904371222957012

Epoch: 5| Step: 10
Training loss: 4.098381160184503
Validation loss: 3.5862020313258816

Epoch: 5| Step: 11
Training loss: 3.077108612335511
Validation loss: 3.5815003284844913

Epoch: 36| Step: 0
Training loss: 3.797099040136492
Validation loss: 3.5770048306530025

Epoch: 5| Step: 1
Training loss: 3.839615870376027
Validation loss: 3.572884215642219

Epoch: 5| Step: 2
Training loss: 3.5866233153246347
Validation loss: 3.568392542737277

Epoch: 5| Step: 3
Training loss: 3.4177227869089584
Validation loss: 3.5637463904551736

Epoch: 5| Step: 4
Training loss: 3.8255535597815546
Validation loss: 3.5593265207509703

Epoch: 5| Step: 5
Training loss: 3.043350293744874
Validation loss: 3.555198470619009

Epoch: 5| Step: 6
Training loss: 3.567812522239314
Validation loss: 3.550924406673462

Epoch: 5| Step: 7
Training loss: 3.6675763880101595
Validation loss: 3.546281577278853

Epoch: 5| Step: 8
Training loss: 4.085392231781423
Validation loss: 3.5421670261055547

Epoch: 5| Step: 9
Training loss: 3.6429807711441162
Validation loss: 3.5379433957224875

Epoch: 5| Step: 10
Training loss: 3.990045319875839
Validation loss: 3.5334355446738757

Epoch: 5| Step: 11
Training loss: 3.8704930829704716
Validation loss: 3.5286079920842934

Epoch: 37| Step: 0
Training loss: 3.4470075040580093
Validation loss: 3.5242281193778857

Epoch: 5| Step: 1
Training loss: 3.397319039640595
Validation loss: 3.520147497580042

Epoch: 5| Step: 2
Training loss: 4.350247799184161
Validation loss: 3.515660321093544

Epoch: 5| Step: 3
Training loss: 4.017960993317785
Validation loss: 3.5110099849510052

Epoch: 5| Step: 4
Training loss: 3.2477793809913833
Validation loss: 3.506720341025681

Epoch: 5| Step: 5
Training loss: 3.1892828349843603
Validation loss: 3.5019555362225763

Epoch: 5| Step: 6
Training loss: 3.6045107080091787
Validation loss: 3.497549368451059

Epoch: 5| Step: 7
Training loss: 3.6873026649562095
Validation loss: 3.493058314405548

Epoch: 5| Step: 8
Training loss: 3.360031986311387
Validation loss: 3.488939867428442

Epoch: 5| Step: 9
Training loss: 3.7942427942011903
Validation loss: 3.4846575099304653

Epoch: 5| Step: 10
Training loss: 3.8785623972325203
Validation loss: 3.479960594657526

Epoch: 5| Step: 11
Training loss: 3.0519918660246725
Validation loss: 3.4759526492937067

Epoch: 38| Step: 0
Training loss: 3.6647997929741
Validation loss: 3.47150413759668

Epoch: 5| Step: 1
Training loss: 2.8504064437429357
Validation loss: 3.467374895649369

Epoch: 5| Step: 2
Training loss: 3.0399325579139154
Validation loss: 3.4631068059460204

Epoch: 5| Step: 3
Training loss: 3.5324197367778
Validation loss: 3.4587907412047767

Epoch: 5| Step: 4
Training loss: 3.451710683215643
Validation loss: 3.4549500143517724

Epoch: 5| Step: 5
Training loss: 3.944458398809211
Validation loss: 3.450567590168786

Epoch: 5| Step: 6
Training loss: 3.823796530493772
Validation loss: 3.4464216688714315

Epoch: 5| Step: 7
Training loss: 4.007861042286439
Validation loss: 3.4419273475557786

Epoch: 5| Step: 8
Training loss: 4.096319658829674
Validation loss: 3.4375840494688825

Epoch: 5| Step: 9
Training loss: 3.2633051320910575
Validation loss: 3.4331739282561946

Epoch: 5| Step: 10
Training loss: 3.457178282978454
Validation loss: 3.4289666289382477

Epoch: 5| Step: 11
Training loss: 4.13800011692259
Validation loss: 3.424846317156812

Epoch: 39| Step: 0
Training loss: 3.264239003406813
Validation loss: 3.4207656490461713

Epoch: 5| Step: 1
Training loss: 3.564861652530792
Validation loss: 3.4169384229946878

Epoch: 5| Step: 2
Training loss: 3.50692241565261
Validation loss: 3.4119577532458156

Epoch: 5| Step: 3
Training loss: 3.966752157705856
Validation loss: 3.4078072071107215

Epoch: 5| Step: 4
Training loss: 3.297240901366703
Validation loss: 3.4034368931976995

Epoch: 5| Step: 5
Training loss: 3.514171248907826
Validation loss: 3.399040943224812

Epoch: 5| Step: 6
Training loss: 3.393147317050935
Validation loss: 3.394754774828216

Epoch: 5| Step: 7
Training loss: 4.174120123881648
Validation loss: 3.390591189073782

Epoch: 5| Step: 8
Training loss: 3.1250570673500246
Validation loss: 3.386626110694506

Epoch: 5| Step: 9
Training loss: 3.8637943062144062
Validation loss: 3.382493154533397

Epoch: 5| Step: 10
Training loss: 3.0190460881256125
Validation loss: 3.3781904517134156

Epoch: 5| Step: 11
Training loss: 3.8306561257119633
Validation loss: 3.3742861993679427

Epoch: 40| Step: 0
Training loss: 3.7370946709020725
Validation loss: 3.3699995307940904

Epoch: 5| Step: 1
Training loss: 3.6765010181738424
Validation loss: 3.3660215821260864

Epoch: 5| Step: 2
Training loss: 3.9002528426543455
Validation loss: 3.362062677261741

Epoch: 5| Step: 3
Training loss: 3.166635931434717
Validation loss: 3.3575709030455134

Epoch: 5| Step: 4
Training loss: 3.39425029404046
Validation loss: 3.353687030941851

Epoch: 5| Step: 5
Training loss: 3.044611633038394
Validation loss: 3.349340937083478

Epoch: 5| Step: 6
Training loss: 3.5147600932615006
Validation loss: 3.3452723118664895

Epoch: 5| Step: 7
Training loss: 3.750124357068902
Validation loss: 3.3415330299251145

Epoch: 5| Step: 8
Training loss: 3.218287906994514
Validation loss: 3.337313997131378

Epoch: 5| Step: 9
Training loss: 2.985356833441127
Validation loss: 3.3333350876962498

Epoch: 5| Step: 10
Training loss: 3.89322572365633
Validation loss: 3.3294215355823034

Epoch: 5| Step: 11
Training loss: 3.2096223759982716
Validation loss: 3.325356799296844

Epoch: 41| Step: 0
Training loss: 3.3221437677442576
Validation loss: 3.321473706212698

Epoch: 5| Step: 1
Training loss: 3.720594701914344
Validation loss: 3.31753250726116

Epoch: 5| Step: 2
Training loss: 3.677592529543545
Validation loss: 3.313666447210028

Epoch: 5| Step: 3
Training loss: 3.4993181926942145
Validation loss: 3.309638947073204

Epoch: 5| Step: 4
Training loss: 3.414395034622329
Validation loss: 3.305443078397226

Epoch: 5| Step: 5
Training loss: 3.0795634824883513
Validation loss: 3.3017611822791637

Epoch: 5| Step: 6
Training loss: 3.095496407234573
Validation loss: 3.2976634090791417

Epoch: 5| Step: 7
Training loss: 3.445757571167451
Validation loss: 3.2939239600784735

Epoch: 5| Step: 8
Training loss: 3.4367437744617026
Validation loss: 3.290038965877608

Epoch: 5| Step: 9
Training loss: 3.392310220333843
Validation loss: 3.2862368668760165

Epoch: 5| Step: 10
Training loss: 3.8351259324784563
Validation loss: 3.2822542258431144

Epoch: 5| Step: 11
Training loss: 2.6636824798260994
Validation loss: 3.2782553495050584

Epoch: 42| Step: 0
Training loss: 3.6942542337069493
Validation loss: 3.2745452014220398

Epoch: 5| Step: 1
Training loss: 3.051983585398518
Validation loss: 3.2705844290396797

Epoch: 5| Step: 2
Training loss: 3.240058070945733
Validation loss: 3.266726863113444

Epoch: 5| Step: 3
Training loss: 3.3690743879358487
Validation loss: 3.2629270283864096

Epoch: 5| Step: 4
Training loss: 3.7408321211732116
Validation loss: 3.2590864939539013

Epoch: 5| Step: 5
Training loss: 3.121865798890814
Validation loss: 3.2552934599871906

Epoch: 5| Step: 6
Training loss: 3.4742388214087403
Validation loss: 3.2517913686485147

Epoch: 5| Step: 7
Training loss: 2.9564555122928864
Validation loss: 3.2478673307641017

Epoch: 5| Step: 8
Training loss: 3.1553635060458003
Validation loss: 3.2439175474914186

Epoch: 5| Step: 9
Training loss: 3.552689546257168
Validation loss: 3.240783522237733

Epoch: 5| Step: 10
Training loss: 3.764769270920735
Validation loss: 3.237150509453523

Epoch: 5| Step: 11
Training loss: 3.895557876613303
Validation loss: 3.23308696070353

Epoch: 43| Step: 0
Training loss: 2.735245658679303
Validation loss: 3.2290587602039507

Epoch: 5| Step: 1
Training loss: 3.2975046722633516
Validation loss: 3.2252251391226263

Epoch: 5| Step: 2
Training loss: 3.3461856705613506
Validation loss: 3.2216388491281314

Epoch: 5| Step: 3
Training loss: 3.219258684868698
Validation loss: 3.217623226381796

Epoch: 5| Step: 4
Training loss: 3.603081835763651
Validation loss: 3.214031748855598

Epoch: 5| Step: 5
Training loss: 3.477164021434423
Validation loss: 3.210555964292006

Epoch: 5| Step: 6
Training loss: 3.74499712059002
Validation loss: 3.207439549947589

Epoch: 5| Step: 7
Training loss: 3.5264085647323227
Validation loss: 3.2034791890149057

Epoch: 5| Step: 8
Training loss: 3.7114682751584076
Validation loss: 3.1997857590821233

Epoch: 5| Step: 9
Training loss: 3.1439244792594208
Validation loss: 3.1953294375840438

Epoch: 5| Step: 10
Training loss: 2.865479170854514
Validation loss: 3.191328862534823

Epoch: 5| Step: 11
Training loss: 3.5105331507221713
Validation loss: 3.187569368143665

Epoch: 44| Step: 0
Training loss: 3.2018358567224454
Validation loss: 3.1835311477840507

Epoch: 5| Step: 1
Training loss: 3.4510909083421146
Validation loss: 3.1799198412539007

Epoch: 5| Step: 2
Training loss: 2.847211805701908
Validation loss: 3.1763692251320608

Epoch: 5| Step: 3
Training loss: 3.187032029449701
Validation loss: 3.1725648840703915

Epoch: 5| Step: 4
Training loss: 2.709147893237666
Validation loss: 3.169119685802218

Epoch: 5| Step: 5
Training loss: 3.0921964501650883
Validation loss: 3.1655234523601976

Epoch: 5| Step: 6
Training loss: 3.7289761258397083
Validation loss: 3.162177138754062

Epoch: 5| Step: 7
Training loss: 3.094051770221617
Validation loss: 3.1591378776696266

Epoch: 5| Step: 8
Training loss: 3.3151070753845415
Validation loss: 3.1556462758601795

Epoch: 5| Step: 9
Training loss: 3.6980743088051686
Validation loss: 3.1523316015602685

Epoch: 5| Step: 10
Training loss: 3.618786320479364
Validation loss: 3.148363281334411

Epoch: 5| Step: 11
Training loss: 4.3127746494573485
Validation loss: 3.144541760539621

Epoch: 45| Step: 0
Training loss: 2.4403002377569707
Validation loss: 3.1402797287767092

Epoch: 5| Step: 1
Training loss: 3.4406227492932295
Validation loss: 3.1357413606455475

Epoch: 5| Step: 2
Training loss: 3.215311973468664
Validation loss: 3.1323256649451063

Epoch: 5| Step: 3
Training loss: 2.9145738086631154
Validation loss: 3.128804250031692

Epoch: 5| Step: 4
Training loss: 3.4296165928212563
Validation loss: 3.124762233589833

Epoch: 5| Step: 5
Training loss: 3.350908691373485
Validation loss: 3.121366181019746

Epoch: 5| Step: 6
Training loss: 3.022372588066566
Validation loss: 3.1172630441127436

Epoch: 5| Step: 7
Training loss: 3.300105099015906
Validation loss: 3.1144038991794925

Epoch: 5| Step: 8
Training loss: 3.167131456764735
Validation loss: 3.1106025023665893

Epoch: 5| Step: 9
Training loss: 3.8679769307487084
Validation loss: 3.106930083003527

Epoch: 5| Step: 10
Training loss: 3.6777704189517597
Validation loss: 3.1031767186173247

Epoch: 5| Step: 11
Training loss: 2.1663969923578907
Validation loss: 3.0987899328471977

Epoch: 46| Step: 0
Training loss: 3.4957301115877817
Validation loss: 3.0950903124515188

Epoch: 5| Step: 1
Training loss: 3.1702955099809653
Validation loss: 3.0919479297873464

Epoch: 5| Step: 2
Training loss: 3.5809391066533207
Validation loss: 3.088983547042355

Epoch: 5| Step: 3
Training loss: 3.3980914761880663
Validation loss: 3.0855863411608895

Epoch: 5| Step: 4
Training loss: 2.999271781275672
Validation loss: 3.0814503298330926

Epoch: 5| Step: 5
Training loss: 2.861826361805005
Validation loss: 3.0784823537802715

Epoch: 5| Step: 6
Training loss: 2.9690411876623815
Validation loss: 3.0751997736776038

Epoch: 5| Step: 7
Training loss: 3.9254255902326216
Validation loss: 3.071672178954465

Epoch: 5| Step: 8
Training loss: 2.5947522904021807
Validation loss: 3.068583758086199

Epoch: 5| Step: 9
Training loss: 3.093816583090324
Validation loss: 3.065486470345003

Epoch: 5| Step: 10
Training loss: 3.2214735045515033
Validation loss: 3.062422699504158

Epoch: 5| Step: 11
Training loss: 2.6838006574223274
Validation loss: 3.058927992757934

Epoch: 47| Step: 0
Training loss: 3.2470397672435483
Validation loss: 3.055819864955114

Epoch: 5| Step: 1
Training loss: 3.0603010106852198
Validation loss: 3.0528888463992816

Epoch: 5| Step: 2
Training loss: 3.073570018213405
Validation loss: 3.0492398336145707

Epoch: 5| Step: 3
Training loss: 3.5902007779477407
Validation loss: 3.045275354656305

Epoch: 5| Step: 4
Training loss: 3.4118212014292983
Validation loss: 3.0435919656008537

Epoch: 5| Step: 5
Training loss: 3.3361883493489306
Validation loss: 3.040942221204601

Epoch: 5| Step: 6
Training loss: 3.0865884215102715
Validation loss: 3.0362796414612636

Epoch: 5| Step: 7
Training loss: 2.7099194112809344
Validation loss: 3.033393573861475

Epoch: 5| Step: 8
Training loss: 3.409357315982652
Validation loss: 3.0308479127611037

Epoch: 5| Step: 9
Training loss: 3.1755477612987577
Validation loss: 3.0267963201597166

Epoch: 5| Step: 10
Training loss: 2.5277684133540186
Validation loss: 3.0251686929267203

Epoch: 5| Step: 11
Training loss: 4.143280214402424
Validation loss: 3.0218558038984837

Epoch: 48| Step: 0
Training loss: 2.84597255502149
Validation loss: 3.018741473126002

Epoch: 5| Step: 1
Training loss: 3.439197745257089
Validation loss: 3.01628660280731

Epoch: 5| Step: 2
Training loss: 3.159164291886752
Validation loss: 3.013257677050164

Epoch: 5| Step: 3
Training loss: 2.550623469708635
Validation loss: 3.010569770949978

Epoch: 5| Step: 4
Training loss: 3.428501210742529
Validation loss: 3.007577426195974

Epoch: 5| Step: 5
Training loss: 2.6084624196570636
Validation loss: 3.0045994527992117

Epoch: 5| Step: 6
Training loss: 3.0661938247480136
Validation loss: 3.0016381572751207

Epoch: 5| Step: 7
Training loss: 3.403154699162691
Validation loss: 2.997589079689472

Epoch: 5| Step: 8
Training loss: 3.1818225637628674
Validation loss: 2.9956465697843413

Epoch: 5| Step: 9
Training loss: 3.2054100259956475
Validation loss: 2.9924233678111185

Epoch: 5| Step: 10
Training loss: 3.45927303063992
Validation loss: 2.9888659567989224

Epoch: 5| Step: 11
Training loss: 3.462979026737532
Validation loss: 2.986559981731947

Epoch: 49| Step: 0
Training loss: 3.4670734649787938
Validation loss: 2.9831859789762647

Epoch: 5| Step: 1
Training loss: 3.561428645143098
Validation loss: 2.9793426932948064

Epoch: 5| Step: 2
Training loss: 2.980204759258077
Validation loss: 2.9769139520410133

Epoch: 5| Step: 3
Training loss: 3.5093577492375707
Validation loss: 2.9738656256144496

Epoch: 5| Step: 4
Training loss: 2.572827624634807
Validation loss: 2.969955266600648

Epoch: 5| Step: 5
Training loss: 2.933269945095538
Validation loss: 2.9670073531031522

Epoch: 5| Step: 6
Training loss: 3.201803837435318
Validation loss: 2.9641972885358974

Epoch: 5| Step: 7
Training loss: 2.950806206922608
Validation loss: 2.961067887977427

Epoch: 5| Step: 8
Training loss: 3.0430378544885204
Validation loss: 2.957958242429859

Epoch: 5| Step: 9
Training loss: 2.9614893416638486
Validation loss: 2.9549932541208137

Epoch: 5| Step: 10
Training loss: 2.9517143957614715
Validation loss: 2.9521510925180077

Epoch: 5| Step: 11
Training loss: 2.7645701320153813
Validation loss: 2.9488251345534193

Epoch: 50| Step: 0
Training loss: 2.6211787066498964
Validation loss: 2.9455185302933304

Epoch: 5| Step: 1
Training loss: 3.368095116311951
Validation loss: 2.9433168924156177

Epoch: 5| Step: 2
Training loss: 3.513712858901474
Validation loss: 2.9402497826808522

Epoch: 5| Step: 3
Training loss: 2.6750735941237713
Validation loss: 2.9379028152343434

Epoch: 5| Step: 4
Training loss: 3.534792718057361
Validation loss: 2.935392513180288

Epoch: 5| Step: 5
Training loss: 2.687636261080543
Validation loss: 2.9323436479495117

Epoch: 5| Step: 6
Training loss: 2.9912633838346174
Validation loss: 2.9295206183481497

Epoch: 5| Step: 7
Training loss: 3.443592844733223
Validation loss: 2.9266437639398992

Epoch: 5| Step: 8
Training loss: 2.8003035687326623
Validation loss: 2.9246955184644547

Epoch: 5| Step: 9
Training loss: 3.2660703218531655
Validation loss: 2.921290742119114

Epoch: 5| Step: 10
Training loss: 2.6431511527639544
Validation loss: 2.9188554600431114

Epoch: 5| Step: 11
Training loss: 3.2062449077840895
Validation loss: 2.9159877304783595

Epoch: 51| Step: 0
Training loss: 3.1095548798177117
Validation loss: 2.9131948800453547

Epoch: 5| Step: 1
Training loss: 2.9982180071271864
Validation loss: 2.9105382271795492

Epoch: 5| Step: 2
Training loss: 2.747610007280093
Validation loss: 2.907736978945755

Epoch: 5| Step: 3
Training loss: 3.3911877705664217
Validation loss: 2.9052406698136797

Epoch: 5| Step: 4
Training loss: 3.547156503404319
Validation loss: 2.902094553487374

Epoch: 5| Step: 5
Training loss: 3.1603877073573474
Validation loss: 2.899793747988573

Epoch: 5| Step: 6
Training loss: 2.6166700164708687
Validation loss: 2.897216076817451

Epoch: 5| Step: 7
Training loss: 2.520990939507248
Validation loss: 2.8936545365188473

Epoch: 5| Step: 8
Training loss: 3.2639063643039528
Validation loss: 2.891362135780042

Epoch: 5| Step: 9
Training loss: 3.30612346212324
Validation loss: 2.888833908684758

Epoch: 5| Step: 10
Training loss: 2.758852927219851
Validation loss: 2.8856954210410923

Epoch: 5| Step: 11
Training loss: 2.1806325743640174
Validation loss: 2.883074141210301

Epoch: 52| Step: 0
Training loss: 3.2329800311155337
Validation loss: 2.880240677599635

Epoch: 5| Step: 1
Training loss: 2.8130564668956795
Validation loss: 2.8779422659200504

Epoch: 5| Step: 2
Training loss: 3.062311594870311
Validation loss: 2.8743309403485147

Epoch: 5| Step: 3
Training loss: 3.5386604265945176
Validation loss: 2.8723275645430046

Epoch: 5| Step: 4
Training loss: 2.5310477658711497
Validation loss: 2.868807169746979

Epoch: 5| Step: 5
Training loss: 3.1181489231448167
Validation loss: 2.8659129865753865

Epoch: 5| Step: 6
Training loss: 2.7564090259028347
Validation loss: 2.863374875954864

Epoch: 5| Step: 7
Training loss: 2.945865164391008
Validation loss: 2.8615882104358317

Epoch: 5| Step: 8
Training loss: 3.0371216212574645
Validation loss: 2.858865404144587

Epoch: 5| Step: 9
Training loss: 2.8709838015724856
Validation loss: 2.8569733725528548

Epoch: 5| Step: 10
Training loss: 3.2725910558192157
Validation loss: 2.8543389516655835

Epoch: 5| Step: 11
Training loss: 1.968936245298287
Validation loss: 2.852437422492523

Epoch: 53| Step: 0
Training loss: 2.447828661912646
Validation loss: 2.8516227088738093

Epoch: 5| Step: 1
Training loss: 2.68734572211725
Validation loss: 2.8493234178476627

Epoch: 5| Step: 2
Training loss: 2.9760698526552263
Validation loss: 2.846851463653274

Epoch: 5| Step: 3
Training loss: 2.9874449912397707
Validation loss: 2.84442809687162

Epoch: 5| Step: 4
Training loss: 3.6358713705477737
Validation loss: 2.8430244966572644

Epoch: 5| Step: 5
Training loss: 2.5671980984748224
Validation loss: 2.839660260806706

Epoch: 5| Step: 6
Training loss: 2.896592367760901
Validation loss: 2.8373570668075216

Epoch: 5| Step: 7
Training loss: 3.1567587867300944
Validation loss: 2.8349909818596686

Epoch: 5| Step: 8
Training loss: 2.9744134789607246
Validation loss: 2.8339388576631883

Epoch: 5| Step: 9
Training loss: 3.163626935201405
Validation loss: 2.83069757036241

Epoch: 5| Step: 10
Training loss: 2.992740589945693
Validation loss: 2.8285805105300477

Epoch: 5| Step: 11
Training loss: 3.626045076404617
Validation loss: 2.825739010358136

Epoch: 54| Step: 0
Training loss: 3.312181277506332
Validation loss: 2.8240915307621255

Epoch: 5| Step: 1
Training loss: 2.7988154323846444
Validation loss: 2.821120180837056

Epoch: 5| Step: 2
Training loss: 3.105433433859723
Validation loss: 2.8199468571139814

Epoch: 5| Step: 3
Training loss: 2.6621556771296606
Validation loss: 2.817272227743341

Epoch: 5| Step: 4
Training loss: 2.870492469989021
Validation loss: 2.8169005194388923

Epoch: 5| Step: 5
Training loss: 2.945284977387156
Validation loss: 2.8162227329210223

Epoch: 5| Step: 6
Training loss: 2.720472995640156
Validation loss: 2.8148007448447316

Epoch: 5| Step: 7
Training loss: 3.229472845185122
Validation loss: 2.8132049701338597

Epoch: 5| Step: 8
Training loss: 3.5316402253449337
Validation loss: 2.811939395558052

Epoch: 5| Step: 9
Training loss: 2.465223570273967
Validation loss: 2.8096047864382756

Epoch: 5| Step: 10
Training loss: 2.731334980007076
Validation loss: 2.8072445581809022

Epoch: 5| Step: 11
Training loss: 2.806144909494568
Validation loss: 2.8052904371751204

Epoch: 55| Step: 0
Training loss: 3.3497776356244726
Validation loss: 2.8034309292559896

Epoch: 5| Step: 1
Training loss: 3.104102643950765
Validation loss: 2.8009864877354227

Epoch: 5| Step: 2
Training loss: 2.7496296026301716
Validation loss: 2.7986273577092073

Epoch: 5| Step: 3
Training loss: 3.221629660114761
Validation loss: 2.7953552898147707

Epoch: 5| Step: 4
Training loss: 2.8397341028845373
Validation loss: 2.794100825863901

Epoch: 5| Step: 5
Training loss: 2.448601409158174
Validation loss: 2.790379103947517

Epoch: 5| Step: 6
Training loss: 3.109246486135805
Validation loss: 2.7885875600278482

Epoch: 5| Step: 7
Training loss: 3.0387345556308403
Validation loss: 2.7877454559813226

Epoch: 5| Step: 8
Training loss: 2.826669645202915
Validation loss: 2.7859576420136998

Epoch: 5| Step: 9
Training loss: 2.5838731898970013
Validation loss: 2.783238507319184

Epoch: 5| Step: 10
Training loss: 2.9603615555453326
Validation loss: 2.782419144711522

Epoch: 5| Step: 11
Training loss: 2.4578006188747517
Validation loss: 2.7788183962512156

Epoch: 56| Step: 0
Training loss: 2.9812468266820114
Validation loss: 2.7768022999336064

Epoch: 5| Step: 1
Training loss: 2.9525428480742417
Validation loss: 2.7755361505879033

Epoch: 5| Step: 2
Training loss: 2.984933691007134
Validation loss: 2.7739517487349783

Epoch: 5| Step: 3
Training loss: 3.069093729257829
Validation loss: 2.7709603866091452

Epoch: 5| Step: 4
Training loss: 2.5171695493108976
Validation loss: 2.7700012805341294

Epoch: 5| Step: 5
Training loss: 3.1257546085975694
Validation loss: 2.767807417304239

Epoch: 5| Step: 6
Training loss: 2.8726445376002054
Validation loss: 2.7654042416269924

Epoch: 5| Step: 7
Training loss: 2.903229322909888
Validation loss: 2.764609407207585

Epoch: 5| Step: 8
Training loss: 3.133391138990986
Validation loss: 2.7608071189021173

Epoch: 5| Step: 9
Training loss: 2.628860087790055
Validation loss: 2.760401478611651

Epoch: 5| Step: 10
Training loss: 2.7948474887463113
Validation loss: 2.760156116544978

Epoch: 5| Step: 11
Training loss: 2.8354061248904725
Validation loss: 2.76174609842028

Epoch: 57| Step: 0
Training loss: 3.181959685362154
Validation loss: 2.753933113273743

Epoch: 5| Step: 1
Training loss: 3.346127244352849
Validation loss: 2.752587719269368

Epoch: 5| Step: 2
Training loss: 2.8806776293306364
Validation loss: 2.75453111129265

Epoch: 5| Step: 3
Training loss: 2.8828454157906584
Validation loss: 2.7539671257631486

Epoch: 5| Step: 4
Training loss: 2.8249673655827716
Validation loss: 2.756076190511274

Epoch: 5| Step: 5
Training loss: 2.303380045750669
Validation loss: 2.758562164428312

Epoch: 5| Step: 6
Training loss: 2.8057551570009807
Validation loss: 2.754830348306219

Epoch: 5| Step: 7
Training loss: 2.828578680753012
Validation loss: 2.749667830346473

Epoch: 5| Step: 8
Training loss: 2.667191354472812
Validation loss: 2.7480799770824236

Epoch: 5| Step: 9
Training loss: 2.8685334499962796
Validation loss: 2.7444096190179526

Epoch: 5| Step: 10
Training loss: 3.025873193740069
Validation loss: 2.7426574029092237

Epoch: 5| Step: 11
Training loss: 3.2296804368043834
Validation loss: 2.7409200755243845

Epoch: 58| Step: 0
Training loss: 2.8019106408736376
Validation loss: 2.7366518659129486

Epoch: 5| Step: 1
Training loss: 3.0443574334524497
Validation loss: 2.7360068873958734

Epoch: 5| Step: 2
Training loss: 2.9299322814406694
Validation loss: 2.733601146367102

Epoch: 5| Step: 3
Training loss: 2.562601785266504
Validation loss: 2.7309242818128157

Epoch: 5| Step: 4
Training loss: 3.1445931185683875
Validation loss: 2.7304185236002776

Epoch: 5| Step: 5
Training loss: 3.0202272706061843
Validation loss: 2.7278570619660005

Epoch: 5| Step: 6
Training loss: 2.709463284823967
Validation loss: 2.7268255483972674

Epoch: 5| Step: 7
Training loss: 2.795154063392239
Validation loss: 2.7268959650339335

Epoch: 5| Step: 8
Training loss: 2.9141189528818843
Validation loss: 2.72376093079263

Epoch: 5| Step: 9
Training loss: 3.0843101363236496
Validation loss: 2.723796363133693

Epoch: 5| Step: 10
Training loss: 2.459309163357491
Validation loss: 2.721184948248952

Epoch: 5| Step: 11
Training loss: 3.011210159918644
Validation loss: 2.715776992044494

Epoch: 59| Step: 0
Training loss: 2.8597872077368196
Validation loss: 2.7151119547945117

Epoch: 5| Step: 1
Training loss: 3.1399489856633593
Validation loss: 2.713919759073933

Epoch: 5| Step: 2
Training loss: 2.6527953177821457
Validation loss: 2.7129922494879537

Epoch: 5| Step: 3
Training loss: 3.140622722567971
Validation loss: 2.710998772653358

Epoch: 5| Step: 4
Training loss: 2.319251026406225
Validation loss: 2.710808346884639

Epoch: 5| Step: 5
Training loss: 2.766783132361439
Validation loss: 2.7088815953331062

Epoch: 5| Step: 6
Training loss: 2.9114166602539893
Validation loss: 2.7076039554790223

Epoch: 5| Step: 7
Training loss: 2.8739520941280947
Validation loss: 2.7067714913324425

Epoch: 5| Step: 8
Training loss: 2.458974582207218
Validation loss: 2.705364688609174

Epoch: 5| Step: 9
Training loss: 3.0116361020396205
Validation loss: 2.703351490917758

Epoch: 5| Step: 10
Training loss: 3.1969914956741885
Validation loss: 2.7015830881081855

Epoch: 5| Step: 11
Training loss: 2.1235761921369893
Validation loss: 2.6995518355120023

Epoch: 60| Step: 0
Training loss: 3.0306159860670046
Validation loss: 2.7033562607229995

Epoch: 5| Step: 1
Training loss: 2.921842850288952
Validation loss: 2.6989749811253607

Epoch: 5| Step: 2
Training loss: 2.9551475098224067
Validation loss: 2.6949420250487996

Epoch: 5| Step: 3
Training loss: 3.3470052399926247
Validation loss: 2.693991834165568

Epoch: 5| Step: 4
Training loss: 2.301705814206361
Validation loss: 2.6928586690367644

Epoch: 5| Step: 5
Training loss: 3.125271899792374
Validation loss: 2.692826917141277

Epoch: 5| Step: 6
Training loss: 2.2368754021259725
Validation loss: 2.691144479276655

Epoch: 5| Step: 7
Training loss: 2.7719249630524736
Validation loss: 2.6892612326947933

Epoch: 5| Step: 8
Training loss: 2.919633301218909
Validation loss: 2.687942971088179

Epoch: 5| Step: 9
Training loss: 2.7515748456410467
Validation loss: 2.688483985884164

Epoch: 5| Step: 10
Training loss: 2.4829459248744885
Validation loss: 2.687811382500296

Epoch: 5| Step: 11
Training loss: 3.5011306026519735
Validation loss: 2.6876576029970742

Epoch: 61| Step: 0
Training loss: 2.539784584072041
Validation loss: 2.6836942480852892

Epoch: 5| Step: 1
Training loss: 2.7844751924412177
Validation loss: 2.682337552514528

Epoch: 5| Step: 2
Training loss: 2.7466516050215897
Validation loss: 2.6810944277157835

Epoch: 5| Step: 3
Training loss: 3.0132848326681776
Validation loss: 2.6786415831900343

Epoch: 5| Step: 4
Training loss: 2.4070718525969377
Validation loss: 2.676449735351571

Epoch: 5| Step: 5
Training loss: 2.894541793165684
Validation loss: 2.67264514182231

Epoch: 5| Step: 6
Training loss: 3.090299589577801
Validation loss: 2.6729446262989467

Epoch: 5| Step: 7
Training loss: 3.03337761843147
Validation loss: 2.6699970963101545

Epoch: 5| Step: 8
Training loss: 2.492391643713294
Validation loss: 2.6691347834953376

Epoch: 5| Step: 9
Training loss: 3.1974246032749436
Validation loss: 2.6703069484080815

Epoch: 5| Step: 10
Training loss: 2.714058434500364
Validation loss: 2.6691754071305636

Epoch: 5| Step: 11
Training loss: 2.4821970287813904
Validation loss: 2.6639814541627476

Epoch: 62| Step: 0
Training loss: 2.662881180963477
Validation loss: 2.6633764970390614

Epoch: 5| Step: 1
Training loss: 2.5482897427383637
Validation loss: 2.6635708695532525

Epoch: 5| Step: 2
Training loss: 3.323785379314028
Validation loss: 2.666684487154147

Epoch: 5| Step: 3
Training loss: 3.036223431373213
Validation loss: 2.665906817739196

Epoch: 5| Step: 4
Training loss: 2.9791744916764222
Validation loss: 2.6673807750145815

Epoch: 5| Step: 5
Training loss: 2.7004241680819394
Validation loss: 2.6686190198549915

Epoch: 5| Step: 6
Training loss: 2.593816733363569
Validation loss: 2.668202901444486

Epoch: 5| Step: 7
Training loss: 2.7109358290081755
Validation loss: 2.6698465138989587

Epoch: 5| Step: 8
Training loss: 2.400525504436212
Validation loss: 2.6684629169758685

Epoch: 5| Step: 9
Training loss: 2.876157776283691
Validation loss: 2.6668605448358873

Epoch: 5| Step: 10
Training loss: 2.956643244131982
Validation loss: 2.66275947154183

Epoch: 5| Step: 11
Training loss: 2.481217783375252
Validation loss: 2.660599703804039

Epoch: 63| Step: 0
Training loss: 3.095365622621586
Validation loss: 2.6600178193807684

Epoch: 5| Step: 1
Training loss: 2.6490786516228866
Validation loss: 2.6566309038704294

Epoch: 5| Step: 2
Training loss: 2.952269253544189
Validation loss: 2.654767445480695

Epoch: 5| Step: 3
Training loss: 2.95540615563052
Validation loss: 2.653740359274

Epoch: 5| Step: 4
Training loss: 2.9466368432355363
Validation loss: 2.6521910004038145

Epoch: 5| Step: 5
Training loss: 2.8379334711042072
Validation loss: 2.650677497947737

Epoch: 5| Step: 6
Training loss: 2.813977086763558
Validation loss: 2.6500739384178935

Epoch: 5| Step: 7
Training loss: 2.374819798911283
Validation loss: 2.6474904680545763

Epoch: 5| Step: 8
Training loss: 2.4910331133246078
Validation loss: 2.646059831301069

Epoch: 5| Step: 9
Training loss: 2.5990744483914363
Validation loss: 2.645189125502247

Epoch: 5| Step: 10
Training loss: 2.882365535832213
Validation loss: 2.6419272663284974

Epoch: 5| Step: 11
Training loss: 2.6627639782919843
Validation loss: 2.6421717603603048

Epoch: 64| Step: 0
Training loss: 3.063818511508141
Validation loss: 2.6415615828538943

Epoch: 5| Step: 1
Training loss: 2.5370313766036836
Validation loss: 2.63515217148644

Epoch: 5| Step: 2
Training loss: 2.836935240884804
Validation loss: 2.640597371515504

Epoch: 5| Step: 3
Training loss: 2.8264033520011127
Validation loss: 2.656883949474696

Epoch: 5| Step: 4
Training loss: 2.9585832481308696
Validation loss: 2.6655319501729067

Epoch: 5| Step: 5
Training loss: 3.297960870912039
Validation loss: 2.6418828545345243

Epoch: 5| Step: 6
Training loss: 2.2468111965580277
Validation loss: 2.6305640002200947

Epoch: 5| Step: 7
Training loss: 2.6148468938466123
Validation loss: 2.6303645336238564

Epoch: 5| Step: 8
Training loss: 2.462282328013565
Validation loss: 2.6352104752185794

Epoch: 5| Step: 9
Training loss: 2.6604432162695426
Validation loss: 2.6443633003189424

Epoch: 5| Step: 10
Training loss: 2.8415406416376685
Validation loss: 2.654240498845828

Epoch: 5| Step: 11
Training loss: 3.4824472063804572
Validation loss: 2.6609506788541557

Epoch: 65| Step: 0
Training loss: 2.6918358536055553
Validation loss: 2.668902567448936

Epoch: 5| Step: 1
Training loss: 2.921543857352994
Validation loss: 2.6646546929661223

Epoch: 5| Step: 2
Training loss: 2.374714282065898
Validation loss: 2.646620071517047

Epoch: 5| Step: 3
Training loss: 2.677143368375636
Validation loss: 2.6338621022609847

Epoch: 5| Step: 4
Training loss: 2.4878162087205724
Validation loss: 2.6312395032188554

Epoch: 5| Step: 5
Training loss: 2.7564729457657524
Validation loss: 2.6235889358541464

Epoch: 5| Step: 6
Training loss: 2.7445766550549124
Validation loss: 2.6223155706725443

Epoch: 5| Step: 7
Training loss: 2.941944088340378
Validation loss: 2.6201066813031395

Epoch: 5| Step: 8
Training loss: 2.5363121747799524
Validation loss: 2.618668595462226

Epoch: 5| Step: 9
Training loss: 3.1353823806729966
Validation loss: 2.614712135718937

Epoch: 5| Step: 10
Training loss: 3.130205320503871
Validation loss: 2.6140126913903785

Epoch: 5| Step: 11
Training loss: 2.478646253145047
Validation loss: 2.6107367504781753

Epoch: 66| Step: 0
Training loss: 2.8573504508759675
Validation loss: 2.607599811935603

Epoch: 5| Step: 1
Training loss: 2.9122675463206567
Validation loss: 2.6057759551390034

Epoch: 5| Step: 2
Training loss: 2.50225947318836
Validation loss: 2.603972791448545

Epoch: 5| Step: 3
Training loss: 2.9366366152429126
Validation loss: 2.6093009968693313

Epoch: 5| Step: 4
Training loss: 2.84260317974993
Validation loss: 2.630359918487888

Epoch: 5| Step: 5
Training loss: 2.726399239185612
Validation loss: 2.631533171366457

Epoch: 5| Step: 6
Training loss: 2.6811331805765497
Validation loss: 2.611190560216608

Epoch: 5| Step: 7
Training loss: 2.458119065165781
Validation loss: 2.603120194301314

Epoch: 5| Step: 8
Training loss: 2.5046439906557536
Validation loss: 2.595763018978879

Epoch: 5| Step: 9
Training loss: 2.824082325110921
Validation loss: 2.59755306947238

Epoch: 5| Step: 10
Training loss: 2.897000925892849
Validation loss: 2.5998485100763316

Epoch: 5| Step: 11
Training loss: 2.764817631865723
Validation loss: 2.5966268694018866

Epoch: 67| Step: 0
Training loss: 2.9330626716876274
Validation loss: 2.5983666693812544

Epoch: 5| Step: 1
Training loss: 2.6980381549204404
Validation loss: 2.5955070304807233

Epoch: 5| Step: 2
Training loss: 2.7521262185516413
Validation loss: 2.5986459056281177

Epoch: 5| Step: 3
Training loss: 2.899901151616715
Validation loss: 2.598766210229325

Epoch: 5| Step: 4
Training loss: 2.583796418635354
Validation loss: 2.60001225147662

Epoch: 5| Step: 5
Training loss: 2.6125011790879795
Validation loss: 2.599560369100839

Epoch: 5| Step: 6
Training loss: 2.68554208096163
Validation loss: 2.59674108919712

Epoch: 5| Step: 7
Training loss: 2.8737797013216784
Validation loss: 2.593932593479401

Epoch: 5| Step: 8
Training loss: 2.6515310219293884
Validation loss: 2.593962404064436

Epoch: 5| Step: 9
Training loss: 2.745014179241754
Validation loss: 2.590568951106653

Epoch: 5| Step: 10
Training loss: 2.472089126899892
Validation loss: 2.5923250872746664

Epoch: 5| Step: 11
Training loss: 3.274094836530578
Validation loss: 2.588286732043091

Epoch: 68| Step: 0
Training loss: 2.487750944581886
Validation loss: 2.589103769461896

Epoch: 5| Step: 1
Training loss: 2.4262067879194844
Validation loss: 2.5879346889367234

Epoch: 5| Step: 2
Training loss: 3.094371078263743
Validation loss: 2.587124935093562

Epoch: 5| Step: 3
Training loss: 2.983269451743188
Validation loss: 2.586281679573075

Epoch: 5| Step: 4
Training loss: 2.3602563083605994
Validation loss: 2.5844391038010257

Epoch: 5| Step: 5
Training loss: 2.8121474998826415
Validation loss: 2.581765296308808

Epoch: 5| Step: 6
Training loss: 2.8105050535185434
Validation loss: 2.5767026773278836

Epoch: 5| Step: 7
Training loss: 2.5386231966718054
Validation loss: 2.577901853672265

Epoch: 5| Step: 8
Training loss: 3.026849443011525
Validation loss: 2.5763875944734687

Epoch: 5| Step: 9
Training loss: 2.7989650993610846
Validation loss: 2.5746663176738647

Epoch: 5| Step: 10
Training loss: 2.5758075818054285
Validation loss: 2.574830580202612

Epoch: 5| Step: 11
Training loss: 1.8665067956219787
Validation loss: 2.572616719253914

Epoch: 69| Step: 0
Training loss: 2.6283350149603644
Validation loss: 2.5789420596008177

Epoch: 5| Step: 1
Training loss: 2.5174656170312577
Validation loss: 2.5830464793473795

Epoch: 5| Step: 2
Training loss: 2.670532335369514
Validation loss: 2.5807112312399374

Epoch: 5| Step: 3
Training loss: 2.3843346908581826
Validation loss: 2.570610203068553

Epoch: 5| Step: 4
Training loss: 2.527840566961516
Validation loss: 2.5675751353001295

Epoch: 5| Step: 5
Training loss: 2.8642028740895555
Validation loss: 2.5700074723119

Epoch: 5| Step: 6
Training loss: 2.809260558448416
Validation loss: 2.5672202674909004

Epoch: 5| Step: 7
Training loss: 2.912692568720209
Validation loss: 2.567666478360779

Epoch: 5| Step: 8
Training loss: 2.7449520771172247
Validation loss: 2.567258046086985

Epoch: 5| Step: 9
Training loss: 2.6360153503318333
Validation loss: 2.567491914296256

Epoch: 5| Step: 10
Training loss: 3.030995938380486
Validation loss: 2.568561235625024

Epoch: 5| Step: 11
Training loss: 2.7690846845820665
Validation loss: 2.566550530917012

Epoch: 70| Step: 0
Training loss: 2.2537158376566238
Validation loss: 2.568489966801335

Epoch: 5| Step: 1
Training loss: 2.829424143457736
Validation loss: 2.564832889263929

Epoch: 5| Step: 2
Training loss: 2.879053658136761
Validation loss: 2.5580249377353135

Epoch: 5| Step: 3
Training loss: 2.67035306003541
Validation loss: 2.553668333127321

Epoch: 5| Step: 4
Training loss: 3.201651034008375
Validation loss: 2.5642853851738123

Epoch: 5| Step: 5
Training loss: 2.7720224988500473
Validation loss: 2.5602142987049987

Epoch: 5| Step: 6
Training loss: 2.5438695856051456
Validation loss: 2.5650775320668022

Epoch: 5| Step: 7
Training loss: 2.5518957159923863
Validation loss: 2.5880631030684165

Epoch: 5| Step: 8
Training loss: 2.269566337064727
Validation loss: 2.599538185449879

Epoch: 5| Step: 9
Training loss: 2.910988339253026
Validation loss: 2.58273016261258

Epoch: 5| Step: 10
Training loss: 2.7209465536849953
Validation loss: 2.5665552724057354

Epoch: 5| Step: 11
Training loss: 3.0405901915703355
Validation loss: 2.5557149518332056

Epoch: 71| Step: 0
Training loss: 2.6717022399374373
Validation loss: 2.561958984700838

Epoch: 5| Step: 1
Training loss: 2.4121087819457774
Validation loss: 2.572272066819359

Epoch: 5| Step: 2
Training loss: 2.8962970243479984
Validation loss: 2.5949515504914125

Epoch: 5| Step: 3
Training loss: 2.7778815970622945
Validation loss: 2.6108416244646304

Epoch: 5| Step: 4
Training loss: 2.7067312539511055
Validation loss: 2.627312595206537

Epoch: 5| Step: 5
Training loss: 3.079782881824972
Validation loss: 2.6389603907674823

Epoch: 5| Step: 6
Training loss: 2.6671527379814917
Validation loss: 2.6356932239900743

Epoch: 5| Step: 7
Training loss: 2.3229784308691297
Validation loss: 2.6161271333769753

Epoch: 5| Step: 8
Training loss: 2.7151231800328075
Validation loss: 2.6003432485917655

Epoch: 5| Step: 9
Training loss: 2.829024198275566
Validation loss: 2.5816832253528648

Epoch: 5| Step: 10
Training loss: 3.0223607553570537
Validation loss: 2.576169821598834

Epoch: 5| Step: 11
Training loss: 2.2375606422091616
Validation loss: 2.5693460674755566

Epoch: 72| Step: 0
Training loss: 2.955223831245483
Validation loss: 2.5656573839889076

Epoch: 5| Step: 1
Training loss: 2.6532221871807757
Validation loss: 2.564329649409323

Epoch: 5| Step: 2
Training loss: 2.7352314506942896
Validation loss: 2.562053827659836

Epoch: 5| Step: 3
Training loss: 2.767760750634691
Validation loss: 2.5608480156623354

Epoch: 5| Step: 4
Training loss: 2.8435035011856207
Validation loss: 2.5610021947261457

Epoch: 5| Step: 5
Training loss: 2.7258103871776744
Validation loss: 2.56076991983914

Epoch: 5| Step: 6
Training loss: 2.4285810594608175
Validation loss: 2.558292241082303

Epoch: 5| Step: 7
Training loss: 2.91927364643017
Validation loss: 2.5598540951083724

Epoch: 5| Step: 8
Training loss: 2.49471793069095
Validation loss: 2.5572915760255217

Epoch: 5| Step: 9
Training loss: 2.175154042543922
Validation loss: 2.55235241360221

Epoch: 5| Step: 10
Training loss: 2.8197705707153142
Validation loss: 2.553052353652241

Epoch: 5| Step: 11
Training loss: 2.9686051182780444
Validation loss: 2.5499647507381686

Epoch: 73| Step: 0
Training loss: 2.605210779049862
Validation loss: 2.550540696582771

Epoch: 5| Step: 1
Training loss: 2.662157916090373
Validation loss: 2.547349370765253

Epoch: 5| Step: 2
Training loss: 2.5835132126068867
Validation loss: 2.5466272666597884

Epoch: 5| Step: 3
Training loss: 2.4871233247581737
Validation loss: 2.5462853386832647

Epoch: 5| Step: 4
Training loss: 3.0303289842939094
Validation loss: 2.543108196507719

Epoch: 5| Step: 5
Training loss: 2.6044446771362657
Validation loss: 2.542324193473226

Epoch: 5| Step: 6
Training loss: 2.9583817778010157
Validation loss: 2.543237803768252

Epoch: 5| Step: 7
Training loss: 2.423820649288431
Validation loss: 2.546431656925847

Epoch: 5| Step: 8
Training loss: 2.6567617484403967
Validation loss: 2.538922068306973

Epoch: 5| Step: 9
Training loss: 2.4622994665606583
Validation loss: 2.547581833968488

Epoch: 5| Step: 10
Training loss: 2.95548424511245
Validation loss: 2.5393789319173745

Epoch: 5| Step: 11
Training loss: 2.781683384422439
Validation loss: 2.5377473369252836

Epoch: 74| Step: 0
Training loss: 2.8304696664537574
Validation loss: 2.5398534824071834

Epoch: 5| Step: 1
Training loss: 2.269510449627681
Validation loss: 2.540202271349889

Epoch: 5| Step: 2
Training loss: 2.495216370643661
Validation loss: 2.5414158249150978

Epoch: 5| Step: 3
Training loss: 2.6143583122375604
Validation loss: 2.5375686437345264

Epoch: 5| Step: 4
Training loss: 2.8979559238680856
Validation loss: 2.5404991115585283

Epoch: 5| Step: 5
Training loss: 2.542958061793495
Validation loss: 2.537229825342717

Epoch: 5| Step: 6
Training loss: 2.9196566560151678
Validation loss: 2.5401844890869385

Epoch: 5| Step: 7
Training loss: 2.8530212851451373
Validation loss: 2.545385666356278

Epoch: 5| Step: 8
Training loss: 2.4810140656115207
Validation loss: 2.5345635918981357

Epoch: 5| Step: 9
Training loss: 2.5724529409599253
Validation loss: 2.5397620777902232

Epoch: 5| Step: 10
Training loss: 2.677634206020991
Validation loss: 2.5351199679920615

Epoch: 5| Step: 11
Training loss: 3.482368883894707
Validation loss: 2.534210465574452

Epoch: 75| Step: 0
Training loss: 1.9698323498953751
Validation loss: 2.5366121881235033

Epoch: 5| Step: 1
Training loss: 2.281948766422442
Validation loss: 2.5317641156066992

Epoch: 5| Step: 2
Training loss: 2.6362673224670923
Validation loss: 2.531268072652466

Epoch: 5| Step: 3
Training loss: 2.9031646101664896
Validation loss: 2.5330185422214906

Epoch: 5| Step: 4
Training loss: 2.498069971856183
Validation loss: 2.5345401456110137

Epoch: 5| Step: 5
Training loss: 3.049375319999839
Validation loss: 2.5354536378767083

Epoch: 5| Step: 6
Training loss: 3.146999437737574
Validation loss: 2.5320287652470865

Epoch: 5| Step: 7
Training loss: 2.891169481290133
Validation loss: 2.532086903165362

Epoch: 5| Step: 8
Training loss: 2.5691580455271197
Validation loss: 2.53111879770094

Epoch: 5| Step: 9
Training loss: 2.8429869581762683
Validation loss: 2.532319572909041

Epoch: 5| Step: 10
Training loss: 2.290318479755271
Validation loss: 2.532935174179004

Epoch: 5| Step: 11
Training loss: 2.830361340912039
Validation loss: 2.5302784668295675

Epoch: 76| Step: 0
Training loss: 2.6855103868259835
Validation loss: 2.5268437609808276

Epoch: 5| Step: 1
Training loss: 2.567383834008688
Validation loss: 2.5258602680212072

Epoch: 5| Step: 2
Training loss: 2.6957000011585746
Validation loss: 2.51948361216219

Epoch: 5| Step: 3
Training loss: 2.848282105543408
Validation loss: 2.522315808437434

Epoch: 5| Step: 4
Training loss: 3.1709764833423404
Validation loss: 2.5220844747466282

Epoch: 5| Step: 5
Training loss: 2.4923445792606644
Validation loss: 2.5237092776238472

Epoch: 5| Step: 6
Training loss: 2.5766999901429894
Validation loss: 2.5211407589576003

Epoch: 5| Step: 7
Training loss: 2.6256291679961263
Validation loss: 2.5207690448812703

Epoch: 5| Step: 8
Training loss: 2.50507802221196
Validation loss: 2.520628267937637

Epoch: 5| Step: 9
Training loss: 2.326772309649341
Validation loss: 2.5207198146344605

Epoch: 5| Step: 10
Training loss: 2.74637937620416
Validation loss: 2.522194110198582

Epoch: 5| Step: 11
Training loss: 1.8867025749824249
Validation loss: 2.5162220122083188

Epoch: 77| Step: 0
Training loss: 2.6936327136498996
Validation loss: 2.5176081925661595

Epoch: 5| Step: 1
Training loss: 2.367034504292859
Validation loss: 2.5133347007278077

Epoch: 5| Step: 2
Training loss: 2.4744253474020432
Validation loss: 2.521252669511251

Epoch: 5| Step: 3
Training loss: 2.314208971497026
Validation loss: 2.5177751715083025

Epoch: 5| Step: 4
Training loss: 3.2704623228584695
Validation loss: 2.517713635341337

Epoch: 5| Step: 5
Training loss: 2.6351323533522635
Validation loss: 2.5134040158254862

Epoch: 5| Step: 6
Training loss: 2.062770478979713
Validation loss: 2.512642377643472

Epoch: 5| Step: 7
Training loss: 2.82750893305574
Validation loss: 2.515307653246072

Epoch: 5| Step: 8
Training loss: 2.7222902771710316
Validation loss: 2.5182626571453324

Epoch: 5| Step: 9
Training loss: 2.6383817274611774
Validation loss: 2.519119465615303

Epoch: 5| Step: 10
Training loss: 2.8322531567156184
Validation loss: 2.5243922691953995

Epoch: 5| Step: 11
Training loss: 3.190296218177365
Validation loss: 2.5254024142457023

Epoch: 78| Step: 0
Training loss: 2.5993797149211866
Validation loss: 2.5247858458686205

Epoch: 5| Step: 1
Training loss: 2.704775444200913
Validation loss: 2.526239797680724

Epoch: 5| Step: 2
Training loss: 2.8839196867639343
Validation loss: 2.526043218762947

Epoch: 5| Step: 3
Training loss: 2.7079401953557865
Validation loss: 2.529357929057447

Epoch: 5| Step: 4
Training loss: 2.440122807179473
Validation loss: 2.5301020574151916

Epoch: 5| Step: 5
Training loss: 2.956705012397157
Validation loss: 2.526577848703556

Epoch: 5| Step: 6
Training loss: 3.079143839653861
Validation loss: 2.532928848026045

Epoch: 5| Step: 7
Training loss: 2.5597656361768943
Validation loss: 2.5310005331929366

Epoch: 5| Step: 8
Training loss: 2.7713519784543186
Validation loss: 2.5272475847818945

Epoch: 5| Step: 9
Training loss: 2.4253819823514275
Validation loss: 2.518262491462644

Epoch: 5| Step: 10
Training loss: 2.204560914383141
Validation loss: 2.5148471869778697

Epoch: 5| Step: 11
Training loss: 1.4714591019831995
Validation loss: 2.512334472270912

Epoch: 79| Step: 0
Training loss: 2.434219696222997
Validation loss: 2.51257684109347

Epoch: 5| Step: 1
Training loss: 2.7159465498461293
Validation loss: 2.511349953035251

Epoch: 5| Step: 2
Training loss: 2.52333942612484
Validation loss: 2.5128309596512395

Epoch: 5| Step: 3
Training loss: 2.636720739293231
Validation loss: 2.511449851854122

Epoch: 5| Step: 4
Training loss: 2.4307711720574936
Validation loss: 2.510208799269429

Epoch: 5| Step: 5
Training loss: 2.8409342816709855
Validation loss: 2.511485680761267

Epoch: 5| Step: 6
Training loss: 2.4934292273856906
Validation loss: 2.5100860826516027

Epoch: 5| Step: 7
Training loss: 2.541569806947597
Validation loss: 2.51087735461507

Epoch: 5| Step: 8
Training loss: 2.75388148952743
Validation loss: 2.5080226045656584

Epoch: 5| Step: 9
Training loss: 2.508081534622422
Validation loss: 2.508211050717626

Epoch: 5| Step: 10
Training loss: 2.9737856269745127
Validation loss: 2.511302970933912

Epoch: 5| Step: 11
Training loss: 3.204326422933068
Validation loss: 2.507687459583458

Epoch: 80| Step: 0
Training loss: 2.517121053774138
Validation loss: 2.505839723632381

Epoch: 5| Step: 1
Training loss: 2.866815943121113
Validation loss: 2.5033148921735147

Epoch: 5| Step: 2
Training loss: 2.630749355357772
Validation loss: 2.4977728579317833

Epoch: 5| Step: 3
Training loss: 2.5214014490321444
Validation loss: 2.50304153912832

Epoch: 5| Step: 4
Training loss: 2.417579138800735
Validation loss: 2.504088519638906

Epoch: 5| Step: 5
Training loss: 3.061887407341958
Validation loss: 2.4997343637484994

Epoch: 5| Step: 6
Training loss: 2.2582842588078016
Validation loss: 2.5013393867301827

Epoch: 5| Step: 7
Training loss: 2.716828730689182
Validation loss: 2.502231091104974

Epoch: 5| Step: 8
Training loss: 3.142427904368734
Validation loss: 2.502845646656226

Epoch: 5| Step: 9
Training loss: 2.5324005526177973
Validation loss: 2.4985527101076146

Epoch: 5| Step: 10
Training loss: 2.1641059072389646
Validation loss: 2.501752656265271

Epoch: 5| Step: 11
Training loss: 2.0926415085428194
Validation loss: 2.500875641537922

Epoch: 81| Step: 0
Training loss: 2.5693444745202147
Validation loss: 2.499943009362722

Epoch: 5| Step: 1
Training loss: 2.0257045462107297
Validation loss: 2.4989790381437413

Epoch: 5| Step: 2
Training loss: 2.965201736972104
Validation loss: 2.4988757029318314

Epoch: 5| Step: 3
Training loss: 2.789357231232266
Validation loss: 2.5073186718942213

Epoch: 5| Step: 4
Training loss: 2.77707478740624
Validation loss: 2.5099224946985452

Epoch: 5| Step: 5
Training loss: 2.877675014446477
Validation loss: 2.5176481952884435

Epoch: 5| Step: 6
Training loss: 2.9282156133320547
Validation loss: 2.5018373492868156

Epoch: 5| Step: 7
Training loss: 3.027646469239795
Validation loss: 2.4991622395320943

Epoch: 5| Step: 8
Training loss: 2.3102018948465073
Validation loss: 2.4941599622836645

Epoch: 5| Step: 9
Training loss: 2.360817373616567
Validation loss: 2.494600218327127

Epoch: 5| Step: 10
Training loss: 2.242356988435701
Validation loss: 2.4968629148443053

Epoch: 5| Step: 11
Training loss: 2.11926134178778
Validation loss: 2.498420244021742

Epoch: 82| Step: 0
Training loss: 2.1302929203117973
Validation loss: 2.494441309772109

Epoch: 5| Step: 1
Training loss: 2.852299843133888
Validation loss: 2.4946625277252803

Epoch: 5| Step: 2
Training loss: 2.752844120034141
Validation loss: 2.495672816292878

Epoch: 5| Step: 3
Training loss: 2.6085601265229257
Validation loss: 2.4951883344466452

Epoch: 5| Step: 4
Training loss: 2.465565329483568
Validation loss: 2.5003063332115665

Epoch: 5| Step: 5
Training loss: 2.4954031644150034
Validation loss: 2.497676763290219

Epoch: 5| Step: 6
Training loss: 2.5319818451277247
Validation loss: 2.4918422240560747

Epoch: 5| Step: 7
Training loss: 2.6250154403959027
Validation loss: 2.4922296805484416

Epoch: 5| Step: 8
Training loss: 2.609677051719239
Validation loss: 2.494273603136032

Epoch: 5| Step: 9
Training loss: 2.862320846881629
Validation loss: 2.4932218814634775

Epoch: 5| Step: 10
Training loss: 2.799804261722805
Validation loss: 2.491824272098038

Epoch: 5| Step: 11
Training loss: 2.7470650182972003
Validation loss: 2.4900956856996017

Epoch: 83| Step: 0
Training loss: 2.7489606453752256
Validation loss: 2.4906042086165403

Epoch: 5| Step: 1
Training loss: 2.5715984617605163
Validation loss: 2.489987836614006

Epoch: 5| Step: 2
Training loss: 2.7990507049329065
Validation loss: 2.494198851477039

Epoch: 5| Step: 3
Training loss: 2.5846735236419933
Validation loss: 2.496821114949727

Epoch: 5| Step: 4
Training loss: 2.4716027111062675
Validation loss: 2.4989477685024184

Epoch: 5| Step: 5
Training loss: 2.3717780092132976
Validation loss: 2.502813974822146

Epoch: 5| Step: 6
Training loss: 2.5442542886082196
Validation loss: 2.5076308536204195

Epoch: 5| Step: 7
Training loss: 3.226164934174184
Validation loss: 2.508379399762691

Epoch: 5| Step: 8
Training loss: 2.5445619154368595
Validation loss: 2.509255660478603

Epoch: 5| Step: 9
Training loss: 2.740074104086645
Validation loss: 2.5085790617291135

Epoch: 5| Step: 10
Training loss: 2.4492774481789437
Validation loss: 2.505296326253133

Epoch: 5| Step: 11
Training loss: 1.437020678011062
Validation loss: 2.4993086733216674

Epoch: 84| Step: 0
Training loss: 2.666387354607502
Validation loss: 2.498596146926142

Epoch: 5| Step: 1
Training loss: 2.378711210126021
Validation loss: 2.4988238826538987

Epoch: 5| Step: 2
Training loss: 2.627838598151913
Validation loss: 2.498347638366832

Epoch: 5| Step: 3
Training loss: 2.6288484790910425
Validation loss: 2.5000373201763564

Epoch: 5| Step: 4
Training loss: 2.3936817846712812
Validation loss: 2.50376600089938

Epoch: 5| Step: 5
Training loss: 2.3399773306441385
Validation loss: 2.504630866216575

Epoch: 5| Step: 6
Training loss: 2.452480839023536
Validation loss: 2.499667219027334

Epoch: 5| Step: 7
Training loss: 2.9377665297343727
Validation loss: 2.496829535858563

Epoch: 5| Step: 8
Training loss: 3.2795362084156916
Validation loss: 2.4931257229785855

Epoch: 5| Step: 9
Training loss: 2.8851219788785034
Validation loss: 2.4933965375121825

Epoch: 5| Step: 10
Training loss: 2.3903774557166364
Validation loss: 2.5032610922530547

Epoch: 5| Step: 11
Training loss: 0.9591359875200178
Validation loss: 2.487082603393983

Epoch: 85| Step: 0
Training loss: 2.6994055588112658
Validation loss: 2.4995049582537323

Epoch: 5| Step: 1
Training loss: 2.3799215821562556
Validation loss: 2.498811049664165

Epoch: 5| Step: 2
Training loss: 2.1339472731678835
Validation loss: 2.498906333438501

Epoch: 5| Step: 3
Training loss: 3.1451174361434884
Validation loss: 2.497189833836839

Epoch: 5| Step: 4
Training loss: 2.5218407270520493
Validation loss: 2.4853456928056454

Epoch: 5| Step: 5
Training loss: 2.5878026407507986
Validation loss: 2.4883596187369186

Epoch: 5| Step: 6
Training loss: 2.683732785728052
Validation loss: 2.4879752768970143

Epoch: 5| Step: 7
Training loss: 3.1943492230215162
Validation loss: 2.48697458769425

Epoch: 5| Step: 8
Training loss: 2.445719432182398
Validation loss: 2.4871605545656816

Epoch: 5| Step: 9
Training loss: 2.5289203613943445
Validation loss: 2.4924017675562995

Epoch: 5| Step: 10
Training loss: 2.2529656680590224
Validation loss: 2.4914672312984454

Epoch: 5| Step: 11
Training loss: 3.451593672273578
Validation loss: 2.4918880581710967

Epoch: 86| Step: 0
Training loss: 2.0063625696277385
Validation loss: 2.494862156604153

Epoch: 5| Step: 1
Training loss: 2.750839365394294
Validation loss: 2.5020091367949107

Epoch: 5| Step: 2
Training loss: 2.2706927218052053
Validation loss: 2.5023347879662774

Epoch: 5| Step: 3
Training loss: 2.705207683889737
Validation loss: 2.5041721141351827

Epoch: 5| Step: 4
Training loss: 2.745817124391759
Validation loss: 2.506962086329873

Epoch: 5| Step: 5
Training loss: 3.245677274021872
Validation loss: 2.5003708127311612

Epoch: 5| Step: 6
Training loss: 2.4577319384817184
Validation loss: 2.5032950184421634

Epoch: 5| Step: 7
Training loss: 2.6668648844800433
Validation loss: 2.4977150210220675

Epoch: 5| Step: 8
Training loss: 2.476313244523734
Validation loss: 2.4912840282804165

Epoch: 5| Step: 9
Training loss: 2.7569753440664875
Validation loss: 2.484433059493798

Epoch: 5| Step: 10
Training loss: 2.7017891289616753
Validation loss: 2.4828189879377263

Epoch: 5| Step: 11
Training loss: 2.424288820415183
Validation loss: 2.4847745274236006

Epoch: 87| Step: 0
Training loss: 2.7300638272436
Validation loss: 2.4834340910877963

Epoch: 5| Step: 1
Training loss: 2.823577259280067
Validation loss: 2.484082994554477

Epoch: 5| Step: 2
Training loss: 2.4847122059504048
Validation loss: 2.4828708541795304

Epoch: 5| Step: 3
Training loss: 2.965052500576804
Validation loss: 2.4807242674895664

Epoch: 5| Step: 4
Training loss: 2.268951814781238
Validation loss: 2.4811778018802593

Epoch: 5| Step: 5
Training loss: 2.0489517043730014
Validation loss: 2.4819549733737745

Epoch: 5| Step: 6
Training loss: 2.464395473239421
Validation loss: 2.484819402474072

Epoch: 5| Step: 7
Training loss: 2.9956880416619724
Validation loss: 2.489609316500074

Epoch: 5| Step: 8
Training loss: 2.8788496035174975
Validation loss: 2.48171594458315

Epoch: 5| Step: 9
Training loss: 2.307616360955205
Validation loss: 2.4821785428140384

Epoch: 5| Step: 10
Training loss: 2.620324466794007
Validation loss: 2.490448798628173

Epoch: 5| Step: 11
Training loss: 2.1248734380394394
Validation loss: 2.4888812089900423

Epoch: 88| Step: 0
Training loss: 2.961382427354238
Validation loss: 2.476919407202207

Epoch: 5| Step: 1
Training loss: 2.387593360393672
Validation loss: 2.480053079374193

Epoch: 5| Step: 2
Training loss: 2.7945867800081095
Validation loss: 2.4839698293169747

Epoch: 5| Step: 3
Training loss: 2.0641789394111867
Validation loss: 2.484762881247042

Epoch: 5| Step: 4
Training loss: 2.8818389158320765
Validation loss: 2.4785074204313347

Epoch: 5| Step: 5
Training loss: 2.7798478953513017
Validation loss: 2.4817599002454545

Epoch: 5| Step: 6
Training loss: 2.895308376089042
Validation loss: 2.487698006057569

Epoch: 5| Step: 7
Training loss: 2.698939793438519
Validation loss: 2.482953454624415

Epoch: 5| Step: 8
Training loss: 1.9573440758586182
Validation loss: 2.4823071493054685

Epoch: 5| Step: 9
Training loss: 2.6438959392551484
Validation loss: 2.481762065785236

Epoch: 5| Step: 10
Training loss: 2.4243077027317335
Validation loss: 2.481523156524525

Epoch: 5| Step: 11
Training loss: 1.7546694991563314
Validation loss: 2.4811143810834158

Epoch: 89| Step: 0
Training loss: 2.89008388093965
Validation loss: 2.481016896474137

Epoch: 5| Step: 1
Training loss: 3.3330138212295677
Validation loss: 2.484529846292089

Epoch: 5| Step: 2
Training loss: 2.309369210325012
Validation loss: 2.478709115886953

Epoch: 5| Step: 3
Training loss: 2.439269963787894
Validation loss: 2.47830596910859

Epoch: 5| Step: 4
Training loss: 2.950113042184981
Validation loss: 2.4786565192988137

Epoch: 5| Step: 5
Training loss: 2.7256025575563676
Validation loss: 2.4839091034056735

Epoch: 5| Step: 6
Training loss: 2.582714734820464
Validation loss: 2.4752403243746226

Epoch: 5| Step: 7
Training loss: 1.7117632262503246
Validation loss: 2.4832696234981486

Epoch: 5| Step: 8
Training loss: 2.45114055476753
Validation loss: 2.483385008769268

Epoch: 5| Step: 9
Training loss: 2.4724224154774643
Validation loss: 2.4810652608825587

Epoch: 5| Step: 10
Training loss: 2.565686175677569
Validation loss: 2.4814936445389124

Epoch: 5| Step: 11
Training loss: 1.5117963430910257
Validation loss: 2.481068175770006

Epoch: 90| Step: 0
Training loss: 2.85649105198422
Validation loss: 2.4738566842863388

Epoch: 5| Step: 1
Training loss: 1.9195198577306805
Validation loss: 2.4708262456842656

Epoch: 5| Step: 2
Training loss: 2.4569346010154587
Validation loss: 2.4742461642758213

Epoch: 5| Step: 3
Training loss: 2.939184801395266
Validation loss: 2.482091237881083

Epoch: 5| Step: 4
Training loss: 2.651526975646634
Validation loss: 2.4818125771650736

Epoch: 5| Step: 5
Training loss: 3.1378641471947124
Validation loss: 2.47993149032742

Epoch: 5| Step: 6
Training loss: 2.554172755654707
Validation loss: 2.4746612286472827

Epoch: 5| Step: 7
Training loss: 2.58730268601422
Validation loss: 2.4825198906757593

Epoch: 5| Step: 8
Training loss: 2.011978991814024
Validation loss: 2.4736419167534933

Epoch: 5| Step: 9
Training loss: 2.8424574041739756
Validation loss: 2.481690794116757

Epoch: 5| Step: 10
Training loss: 2.5620920740477766
Validation loss: 2.479866355177814

Epoch: 5| Step: 11
Training loss: 1.6412040052048493
Validation loss: 2.4801975172037443

Epoch: 91| Step: 0
Training loss: 2.629576009652421
Validation loss: 2.4840944459637955

Epoch: 5| Step: 1
Training loss: 3.1408298103013848
Validation loss: 2.4783958303902076

Epoch: 5| Step: 2
Training loss: 2.5072410621708174
Validation loss: 2.4809726914050034

Epoch: 5| Step: 3
Training loss: 2.131312586964491
Validation loss: 2.4747698580543136

Epoch: 5| Step: 4
Training loss: 2.3793133166579143
Validation loss: 2.478432483846786

Epoch: 5| Step: 5
Training loss: 2.1775255864388705
Validation loss: 2.476926297524449

Epoch: 5| Step: 6
Training loss: 2.9771080818687
Validation loss: 2.4797959744452522

Epoch: 5| Step: 7
Training loss: 2.979040040924205
Validation loss: 2.4826602616238596

Epoch: 5| Step: 8
Training loss: 2.5480732351644595
Validation loss: 2.4791547804368537

Epoch: 5| Step: 9
Training loss: 2.6283640422813055
Validation loss: 2.4754665850096726

Epoch: 5| Step: 10
Training loss: 2.2479223619541524
Validation loss: 2.4809695081291347

Epoch: 5| Step: 11
Training loss: 2.9898827344168475
Validation loss: 2.478167698585719

Epoch: 92| Step: 0
Training loss: 2.775726663110181
Validation loss: 2.474504680872691

Epoch: 5| Step: 1
Training loss: 2.4255966632291646
Validation loss: 2.480532403564723

Epoch: 5| Step: 2
Training loss: 2.8544029824840034
Validation loss: 2.471896134586384

Epoch: 5| Step: 3
Training loss: 2.6475762061083112
Validation loss: 2.474448407805718

Epoch: 5| Step: 4
Training loss: 2.4769757524704223
Validation loss: 2.472483081991174

Epoch: 5| Step: 5
Training loss: 1.926862679985619
Validation loss: 2.4697833494005863

Epoch: 5| Step: 6
Training loss: 2.5841342135789045
Validation loss: 2.4727158903348814

Epoch: 5| Step: 7
Training loss: 2.2143222524555286
Validation loss: 2.473547017220658

Epoch: 5| Step: 8
Training loss: 3.0231173244755065
Validation loss: 2.468343306896281

Epoch: 5| Step: 9
Training loss: 2.653106624687913
Validation loss: 2.471836992912815

Epoch: 5| Step: 10
Training loss: 2.725773738239551
Validation loss: 2.466766280716716

Epoch: 5| Step: 11
Training loss: 2.408484474200193
Validation loss: 2.475423962312058

Epoch: 93| Step: 0
Training loss: 2.48813962907666
Validation loss: 2.4727630752862115

Epoch: 5| Step: 1
Training loss: 2.7078246788283713
Validation loss: 2.473940611658704

Epoch: 5| Step: 2
Training loss: 3.0167860256910313
Validation loss: 2.4781406921621074

Epoch: 5| Step: 3
Training loss: 2.61700211053398
Validation loss: 2.4800901469451335

Epoch: 5| Step: 4
Training loss: 2.49323300999577
Validation loss: 2.4734038337220468

Epoch: 5| Step: 5
Training loss: 2.816480913376229
Validation loss: 2.478218904554457

Epoch: 5| Step: 6
Training loss: 2.286944871258869
Validation loss: 2.4792123891850983

Epoch: 5| Step: 7
Training loss: 2.3507338169493828
Validation loss: 2.4752336220024285

Epoch: 5| Step: 8
Training loss: 2.4654141837575985
Validation loss: 2.4738220471772747

Epoch: 5| Step: 9
Training loss: 2.6927422251434607
Validation loss: 2.474574340957701

Epoch: 5| Step: 10
Training loss: 2.5817522830282598
Validation loss: 2.4744248174598784

Epoch: 5| Step: 11
Training loss: 2.191070258890511
Validation loss: 2.4752603210149537

Epoch: 94| Step: 0
Training loss: 2.7592924215849544
Validation loss: 2.471332201577037

Epoch: 5| Step: 1
Training loss: 2.810428280213729
Validation loss: 2.473474123232407

Epoch: 5| Step: 2
Training loss: 2.325392892927092
Validation loss: 2.4751722643528242

Epoch: 5| Step: 3
Training loss: 2.423095690825724
Validation loss: 2.4740559341184856

Epoch: 5| Step: 4
Training loss: 2.229618371374396
Validation loss: 2.4754427675961064

Epoch: 5| Step: 5
Training loss: 2.816673065118087
Validation loss: 2.479087032246582

Epoch: 5| Step: 6
Training loss: 2.3745959088733883
Validation loss: 2.4811198163572636

Epoch: 5| Step: 7
Training loss: 3.143842425040009
Validation loss: 2.480628597685894

Epoch: 5| Step: 8
Training loss: 2.565072326978921
Validation loss: 2.479627275286425

Epoch: 5| Step: 9
Training loss: 2.271813720548316
Validation loss: 2.474861591816773

Epoch: 5| Step: 10
Training loss: 2.735670033729811
Validation loss: 2.4692636229200535

Epoch: 5| Step: 11
Training loss: 1.6957987426429224
Validation loss: 2.4741053781812687

Epoch: 95| Step: 0
Training loss: 2.3872963663708475
Validation loss: 2.4708388501106247

Epoch: 5| Step: 1
Training loss: 2.579337464954455
Validation loss: 2.4736765142175474

Epoch: 5| Step: 2
Training loss: 2.8309098331991454
Validation loss: 2.476864769236102

Epoch: 5| Step: 3
Training loss: 2.516763465063972
Validation loss: 2.4919116346850636

Epoch: 5| Step: 4
Training loss: 2.9673889252491668
Validation loss: 2.4854950009706736

Epoch: 5| Step: 5
Training loss: 2.2459231635289374
Validation loss: 2.5008095860924167

Epoch: 5| Step: 6
Training loss: 1.9424805767605293
Validation loss: 2.493529818270826

Epoch: 5| Step: 7
Training loss: 2.662567703747376
Validation loss: 2.4798416666663043

Epoch: 5| Step: 8
Training loss: 2.974010424761789
Validation loss: 2.4735088555780425

Epoch: 5| Step: 9
Training loss: 2.8332198812172535
Validation loss: 2.4623731351339577

Epoch: 5| Step: 10
Training loss: 2.6413082164409136
Validation loss: 2.4615624900689697

Epoch: 5| Step: 11
Training loss: 2.1442137102683434
Validation loss: 2.4666466021580895

Epoch: 96| Step: 0
Training loss: 2.662841696147684
Validation loss: 2.4704220296508033

Epoch: 5| Step: 1
Training loss: 2.743785598975797
Validation loss: 2.473864821958901

Epoch: 5| Step: 2
Training loss: 3.10463287812301
Validation loss: 2.47374219385258

Epoch: 5| Step: 3
Training loss: 2.5887383450881694
Validation loss: 2.4732962689510143

Epoch: 5| Step: 4
Training loss: 2.0911393472294595
Validation loss: 2.4754925451274947

Epoch: 5| Step: 5
Training loss: 2.5844400455356875
Validation loss: 2.472911972152852

Epoch: 5| Step: 6
Training loss: 2.5826112496859444
Validation loss: 2.4777890245814826

Epoch: 5| Step: 7
Training loss: 2.386664207322258
Validation loss: 2.474432128242909

Epoch: 5| Step: 8
Training loss: 2.640588613406156
Validation loss: 2.474809569761767

Epoch: 5| Step: 9
Training loss: 2.5043032803034797
Validation loss: 2.4756209532137974

Epoch: 5| Step: 10
Training loss: 2.4926885501784852
Validation loss: 2.472337036258705

Epoch: 5| Step: 11
Training loss: 2.754867234535892
Validation loss: 2.470616459991366

Epoch: 97| Step: 0
Training loss: 2.5811925036513186
Validation loss: 2.474034668932642

Epoch: 5| Step: 1
Training loss: 2.79524140627391
Validation loss: 2.47046128045551

Epoch: 5| Step: 2
Training loss: 2.5839189562946774
Validation loss: 2.4701154168186643

Epoch: 5| Step: 3
Training loss: 2.2629094127505285
Validation loss: 2.4754633023536505

Epoch: 5| Step: 4
Training loss: 2.5265214811733387
Validation loss: 2.4727805670351555

Epoch: 5| Step: 5
Training loss: 2.8322396879113665
Validation loss: 2.468354942002672

Epoch: 5| Step: 6
Training loss: 2.8054431120578216
Validation loss: 2.470539442427826

Epoch: 5| Step: 7
Training loss: 2.293780259600622
Validation loss: 2.46765013631909

Epoch: 5| Step: 8
Training loss: 2.518189065345023
Validation loss: 2.4740048026020554

Epoch: 5| Step: 9
Training loss: 2.6925453023543935
Validation loss: 2.471398478125147

Epoch: 5| Step: 10
Training loss: 2.4914324821557714
Validation loss: 2.4707147610557474

Epoch: 5| Step: 11
Training loss: 2.8524860715400657
Validation loss: 2.4699468970671545

Epoch: 98| Step: 0
Training loss: 1.9992709022985324
Validation loss: 2.4676114124627198

Epoch: 5| Step: 1
Training loss: 2.656881100349898
Validation loss: 2.4671658068639983

Epoch: 5| Step: 2
Training loss: 2.4633134302032946
Validation loss: 2.4654600699878944

Epoch: 5| Step: 3
Training loss: 2.9229435726204405
Validation loss: 2.4622991922157405

Epoch: 5| Step: 4
Training loss: 3.0194112302311678
Validation loss: 2.4609134571979885

Epoch: 5| Step: 5
Training loss: 2.6196537069975836
Validation loss: 2.4629767955172763

Epoch: 5| Step: 6
Training loss: 2.479626802544088
Validation loss: 2.4639769822114816

Epoch: 5| Step: 7
Training loss: 2.516911811341541
Validation loss: 2.4618285750774684

Epoch: 5| Step: 8
Training loss: 2.5959810520062523
Validation loss: 2.4730739873407077

Epoch: 5| Step: 9
Training loss: 2.5971250521546976
Validation loss: 2.46861516608452

Epoch: 5| Step: 10
Training loss: 2.3912842284174167
Validation loss: 2.472034567028267

Epoch: 5| Step: 11
Training loss: 2.401436586373924
Validation loss: 2.459785405693789

Epoch: 99| Step: 0
Training loss: 2.3643538129776376
Validation loss: 2.457776771733563

Epoch: 5| Step: 1
Training loss: 2.7190659438088303
Validation loss: 2.4626215869235835

Epoch: 5| Step: 2
Training loss: 2.767898314912518
Validation loss: 2.4561684310997176

Epoch: 5| Step: 3
Training loss: 2.5860417739727595
Validation loss: 2.4659781447656695

Epoch: 5| Step: 4
Training loss: 2.478882482146043
Validation loss: 2.46308529089799

Epoch: 5| Step: 5
Training loss: 2.765700603249156
Validation loss: 2.4678563621203775

Epoch: 5| Step: 6
Training loss: 2.378147148199621
Validation loss: 2.471208836764665

Epoch: 5| Step: 7
Training loss: 2.8780360569501178
Validation loss: 2.469698031798544

Epoch: 5| Step: 8
Training loss: 2.0789653255035296
Validation loss: 2.4724088065915533

Epoch: 5| Step: 9
Training loss: 2.6720622036140758
Validation loss: 2.46888349067552

Epoch: 5| Step: 10
Training loss: 2.660467950201673
Validation loss: 2.4647238773269837

Epoch: 5| Step: 11
Training loss: 1.8297660830307296
Validation loss: 2.4632107402866046

Epoch: 100| Step: 0
Training loss: 2.3519604114976507
Validation loss: 2.4643752211485905

Epoch: 5| Step: 1
Training loss: 2.535015084637486
Validation loss: 2.458401013644198

Epoch: 5| Step: 2
Training loss: 2.6494435787841653
Validation loss: 2.461708145982346

Epoch: 5| Step: 3
Training loss: 2.495851125850103
Validation loss: 2.464097882978104

Epoch: 5| Step: 4
Training loss: 2.642099363908763
Validation loss: 2.4627052941247234

Epoch: 5| Step: 5
Training loss: 2.4499073672785774
Validation loss: 2.4643891646342286

Epoch: 5| Step: 6
Training loss: 2.468903259155787
Validation loss: 2.464261207317203

Epoch: 5| Step: 7
Training loss: 2.715606099404253
Validation loss: 2.4619815811609143

Epoch: 5| Step: 8
Training loss: 2.8219443379244735
Validation loss: 2.461096125743195

Epoch: 5| Step: 9
Training loss: 2.733813244472244
Validation loss: 2.464428245478105

Epoch: 5| Step: 10
Training loss: 2.191692041267126
Validation loss: 2.469696615914179

Epoch: 5| Step: 11
Training loss: 2.6412221019046003
Validation loss: 2.4629968897063814

Epoch: 101| Step: 0
Training loss: 3.034802586829633
Validation loss: 2.4793677822783997

Epoch: 5| Step: 1
Training loss: 2.0810698101867233
Validation loss: 2.491709863698663

Epoch: 5| Step: 2
Training loss: 2.322787419531066
Validation loss: 2.488646795309818

Epoch: 5| Step: 3
Training loss: 2.3942846074737427
Validation loss: 2.480476954088636

Epoch: 5| Step: 4
Training loss: 2.3763787132692875
Validation loss: 2.4789292531709974

Epoch: 5| Step: 5
Training loss: 2.928322761558537
Validation loss: 2.475647882793826

Epoch: 5| Step: 6
Training loss: 3.1108158932747187
Validation loss: 2.481826334623243

Epoch: 5| Step: 7
Training loss: 2.5997003529347045
Validation loss: 2.4921121137452036

Epoch: 5| Step: 8
Training loss: 2.3333163147260274
Validation loss: 2.4764904328619775

Epoch: 5| Step: 9
Training loss: 2.678914573124738
Validation loss: 2.472066406156898

Epoch: 5| Step: 10
Training loss: 2.306943868654493
Validation loss: 2.46976139983755

Epoch: 5| Step: 11
Training loss: 2.7200181130198837
Validation loss: 2.4632310624458866

Epoch: 102| Step: 0
Training loss: 2.713854888196311
Validation loss: 2.4666880072387944

Epoch: 5| Step: 1
Training loss: 2.289260699443886
Validation loss: 2.461718561464442

Epoch: 5| Step: 2
Training loss: 2.6110521968210296
Validation loss: 2.4679417192380195

Epoch: 5| Step: 3
Training loss: 2.533764002817282
Validation loss: 2.4682585170686093

Epoch: 5| Step: 4
Training loss: 2.6197662857878905
Validation loss: 2.4687318841454626

Epoch: 5| Step: 5
Training loss: 2.920624654138448
Validation loss: 2.469348766451783

Epoch: 5| Step: 6
Training loss: 1.8950513617366669
Validation loss: 2.47377760511445

Epoch: 5| Step: 7
Training loss: 2.490107035653534
Validation loss: 2.4715895599287143

Epoch: 5| Step: 8
Training loss: 2.4992080387745714
Validation loss: 2.4760272493585957

Epoch: 5| Step: 9
Training loss: 2.383773859921822
Validation loss: 2.4735435994844144

Epoch: 5| Step: 10
Training loss: 3.0513524730810806
Validation loss: 2.4767912108252648

Epoch: 5| Step: 11
Training loss: 3.6685409668310074
Validation loss: 2.473343478978453

Epoch: 103| Step: 0
Training loss: 2.4854800088063524
Validation loss: 2.468028570748108

Epoch: 5| Step: 1
Training loss: 2.7505933814993266
Validation loss: 2.467682897539448

Epoch: 5| Step: 2
Training loss: 2.1345204651441936
Validation loss: 2.460562734981232

Epoch: 5| Step: 3
Training loss: 2.6886218191439557
Validation loss: 2.4689937342469856

Epoch: 5| Step: 4
Training loss: 2.9539110863178637
Validation loss: 2.463627502580524

Epoch: 5| Step: 5
Training loss: 1.9387701854724881
Validation loss: 2.4571346509854264

Epoch: 5| Step: 6
Training loss: 2.813691713262399
Validation loss: 2.4667676378754058

Epoch: 5| Step: 7
Training loss: 2.0813276809079633
Validation loss: 2.4585814364286254

Epoch: 5| Step: 8
Training loss: 2.5461265540782385
Validation loss: 2.4626077423472066

Epoch: 5| Step: 9
Training loss: 2.2544780250573098
Validation loss: 2.462054516827071

Epoch: 5| Step: 10
Training loss: 3.3441127687266974
Validation loss: 2.4572231215786

Epoch: 5| Step: 11
Training loss: 3.2236865067192118
Validation loss: 2.457628558584104

Epoch: 104| Step: 0
Training loss: 2.44555458113698
Validation loss: 2.464086534168831

Epoch: 5| Step: 1
Training loss: 2.630959965539384
Validation loss: 2.468105803513483

Epoch: 5| Step: 2
Training loss: 2.866756396404851
Validation loss: 2.464662189517324

Epoch: 5| Step: 3
Training loss: 2.4677020395847338
Validation loss: 2.460038060110965

Epoch: 5| Step: 4
Training loss: 2.5404748363153327
Validation loss: 2.464262275604079

Epoch: 5| Step: 5
Training loss: 2.395849863631125
Validation loss: 2.4660723002883307

Epoch: 5| Step: 6
Training loss: 2.5706306422955607
Validation loss: 2.4605677291552417

Epoch: 5| Step: 7
Training loss: 2.9980840922974967
Validation loss: 2.4628149833226205

Epoch: 5| Step: 8
Training loss: 2.549876030545148
Validation loss: 2.46134291846576

Epoch: 5| Step: 9
Training loss: 2.366154612186869
Validation loss: 2.461775004459327

Epoch: 5| Step: 10
Training loss: 2.6612030523987062
Validation loss: 2.457514797675803

Epoch: 5| Step: 11
Training loss: 1.2905959285389883
Validation loss: 2.45536334581954

Epoch: 105| Step: 0
Training loss: 2.2108373181186987
Validation loss: 2.4558037307977885

Epoch: 5| Step: 1
Training loss: 2.9037804724892116
Validation loss: 2.4550932137959594

Epoch: 5| Step: 2
Training loss: 2.9358472029608933
Validation loss: 2.4542754891258327

Epoch: 5| Step: 3
Training loss: 3.0983225621745367
Validation loss: 2.455724310979698

Epoch: 5| Step: 4
Training loss: 2.278491507980865
Validation loss: 2.451692588179855

Epoch: 5| Step: 5
Training loss: 2.0655552746984216
Validation loss: 2.457795344230401

Epoch: 5| Step: 6
Training loss: 2.530595294441703
Validation loss: 2.456716653791054

Epoch: 5| Step: 7
Training loss: 2.4078906522490753
Validation loss: 2.455845816232855

Epoch: 5| Step: 8
Training loss: 2.829802800509341
Validation loss: 2.4563795720448476

Epoch: 5| Step: 9
Training loss: 2.141201860428972
Validation loss: 2.460256439911475

Epoch: 5| Step: 10
Training loss: 2.4416634630132323
Validation loss: 2.4593054026830474

Epoch: 5| Step: 11
Training loss: 3.0871493121072295
Validation loss: 2.4579627490494276

Epoch: 106| Step: 0
Training loss: 2.6700960003456826
Validation loss: 2.460877368333645

Epoch: 5| Step: 1
Training loss: 2.6589757958121476
Validation loss: 2.464073971802481

Epoch: 5| Step: 2
Training loss: 2.7729101404982153
Validation loss: 2.458653660826028

Epoch: 5| Step: 3
Training loss: 3.0174363778904603
Validation loss: 2.468418183541506

Epoch: 5| Step: 4
Training loss: 2.372766850279933
Validation loss: 2.4651553707149847

Epoch: 5| Step: 5
Training loss: 2.4802851571451203
Validation loss: 2.467153419225417

Epoch: 5| Step: 6
Training loss: 2.0073430443922318
Validation loss: 2.4690273748777805

Epoch: 5| Step: 7
Training loss: 2.852383430098381
Validation loss: 2.470958337682683

Epoch: 5| Step: 8
Training loss: 2.5443700161320284
Validation loss: 2.4737521490544228

Epoch: 5| Step: 9
Training loss: 2.3776036095731707
Validation loss: 2.472890737301754

Epoch: 5| Step: 10
Training loss: 2.525610776246178
Validation loss: 2.4733375305806797

Epoch: 5| Step: 11
Training loss: 2.729628972701836
Validation loss: 2.472620806608242

Epoch: 107| Step: 0
Training loss: 2.7246347515059277
Validation loss: 2.4763400020993105

Epoch: 5| Step: 1
Training loss: 2.303086995570832
Validation loss: 2.478997210045953

Epoch: 5| Step: 2
Training loss: 2.5869119427428555
Validation loss: 2.4839686735228543

Epoch: 5| Step: 3
Training loss: 2.861143972049709
Validation loss: 2.4837634735497103

Epoch: 5| Step: 4
Training loss: 2.365907933840603
Validation loss: 2.485004049511481

Epoch: 5| Step: 5
Training loss: 2.7982347475657097
Validation loss: 2.485378342679679

Epoch: 5| Step: 6
Training loss: 2.570472039833999
Validation loss: 2.4816610919803526

Epoch: 5| Step: 7
Training loss: 2.5606402650005218
Validation loss: 2.483504620721014

Epoch: 5| Step: 8
Training loss: 2.3719570341737963
Validation loss: 2.4847572820273816

Epoch: 5| Step: 9
Training loss: 2.954447132421964
Validation loss: 2.4832700275399664

Epoch: 5| Step: 10
Training loss: 2.3972556715844573
Validation loss: 2.479068695397864

Epoch: 5| Step: 11
Training loss: 1.9184652956005184
Validation loss: 2.4784136290990535

Epoch: 108| Step: 0
Training loss: 2.6056508425288656
Validation loss: 2.474894719180521

Epoch: 5| Step: 1
Training loss: 2.0817339543548465
Validation loss: 2.469542118745721

Epoch: 5| Step: 2
Training loss: 2.7876071071147157
Validation loss: 2.4754152378317227

Epoch: 5| Step: 3
Training loss: 2.4173717347195076
Validation loss: 2.473361518883274

Epoch: 5| Step: 4
Training loss: 2.700268862724554
Validation loss: 2.474841678256532

Epoch: 5| Step: 5
Training loss: 2.8853262509572275
Validation loss: 2.476949386782358

Epoch: 5| Step: 6
Training loss: 2.7834358626648115
Validation loss: 2.4680593989381743

Epoch: 5| Step: 7
Training loss: 2.937240751473515
Validation loss: 2.4710992266915586

Epoch: 5| Step: 8
Training loss: 2.1247123074727945
Validation loss: 2.4615445674966083

Epoch: 5| Step: 9
Training loss: 2.5598805693245383
Validation loss: 2.4676412434527135

Epoch: 5| Step: 10
Training loss: 2.441398632800617
Validation loss: 2.4648797404890455

Epoch: 5| Step: 11
Training loss: 2.0093281884324785
Validation loss: 2.46359806654864

Epoch: 109| Step: 0
Training loss: 2.850121539017312
Validation loss: 2.4596547653920813

Epoch: 5| Step: 1
Training loss: 2.5417155797869073
Validation loss: 2.4570586542118455

Epoch: 5| Step: 2
Training loss: 2.7022607557351095
Validation loss: 2.4528400231317877

Epoch: 5| Step: 3
Training loss: 2.097930606112596
Validation loss: 2.4604165630895047

Epoch: 5| Step: 4
Training loss: 2.651773158232232
Validation loss: 2.456036534630977

Epoch: 5| Step: 5
Training loss: 1.9893626811382867
Validation loss: 2.451686708810116

Epoch: 5| Step: 6
Training loss: 2.648337123172738
Validation loss: 2.4614711889210272

Epoch: 5| Step: 7
Training loss: 2.621559613324362
Validation loss: 2.458721846791195

Epoch: 5| Step: 8
Training loss: 2.995303292178238
Validation loss: 2.462857715327322

Epoch: 5| Step: 9
Training loss: 2.8381199701395263
Validation loss: 2.4679681811564

Epoch: 5| Step: 10
Training loss: 2.2257769353308587
Validation loss: 2.4577201601188885

Epoch: 5| Step: 11
Training loss: 1.625234880345079
Validation loss: 2.4604599746738507

Epoch: 110| Step: 0
Training loss: 2.3978968703720227
Validation loss: 2.4538265083745943

Epoch: 5| Step: 1
Training loss: 2.4363665757685595
Validation loss: 2.454918932349935

Epoch: 5| Step: 2
Training loss: 2.4895977089013295
Validation loss: 2.4617826231758353

Epoch: 5| Step: 3
Training loss: 3.0201429608593564
Validation loss: 2.4588434382482505

Epoch: 5| Step: 4
Training loss: 2.5342442263578553
Validation loss: 2.474028400968176

Epoch: 5| Step: 5
Training loss: 2.6596416586241123
Validation loss: 2.4667001696729924

Epoch: 5| Step: 6
Training loss: 2.046490931696108
Validation loss: 2.467934022928606

Epoch: 5| Step: 7
Training loss: 2.703842067976299
Validation loss: 2.4687290653516136

Epoch: 5| Step: 8
Training loss: 2.643297907995582
Validation loss: 2.4678794718299977

Epoch: 5| Step: 9
Training loss: 2.5939992761897694
Validation loss: 2.4665087735272464

Epoch: 5| Step: 10
Training loss: 2.6901992726878095
Validation loss: 2.4700804678426054

Epoch: 5| Step: 11
Training loss: 2.980636571956479
Validation loss: 2.4748522833210553

Epoch: 111| Step: 0
Training loss: 2.536550176838925
Validation loss: 2.4651885821693718

Epoch: 5| Step: 1
Training loss: 2.0705591594661383
Validation loss: 2.4674431041714215

Epoch: 5| Step: 2
Training loss: 2.9778920005444687
Validation loss: 2.468338533709824

Epoch: 5| Step: 3
Training loss: 2.328485243403436
Validation loss: 2.4628696707979403

Epoch: 5| Step: 4
Training loss: 2.378049198100499
Validation loss: 2.461857584358822

Epoch: 5| Step: 5
Training loss: 2.7343987164150056
Validation loss: 2.4633284685549706

Epoch: 5| Step: 6
Training loss: 3.066322898946794
Validation loss: 2.4712204382798473

Epoch: 5| Step: 7
Training loss: 2.835315142142268
Validation loss: 2.4727418150517733

Epoch: 5| Step: 8
Training loss: 2.2888688666302293
Validation loss: 2.463188707956649

Epoch: 5| Step: 9
Training loss: 2.194072875691232
Validation loss: 2.4667770010418675

Epoch: 5| Step: 10
Training loss: 2.7600201207961703
Validation loss: 2.462185990052725

Epoch: 5| Step: 11
Training loss: 2.8640503728581734
Validation loss: 2.4554817274614247

Epoch: 112| Step: 0
Training loss: 2.57077207775702
Validation loss: 2.451314168703239

Epoch: 5| Step: 1
Training loss: 2.3848354070078015
Validation loss: 2.4569143480753315

Epoch: 5| Step: 2
Training loss: 2.7068741217475054
Validation loss: 2.4611246956164985

Epoch: 5| Step: 3
Training loss: 2.3086856623650314
Validation loss: 2.460231171015619

Epoch: 5| Step: 4
Training loss: 2.3941112355304757
Validation loss: 2.460978839668334

Epoch: 5| Step: 5
Training loss: 3.141612642533694
Validation loss: 2.4620257277524726

Epoch: 5| Step: 6
Training loss: 2.877005996788015
Validation loss: 2.463422588242122

Epoch: 5| Step: 7
Training loss: 2.0333589609542675
Validation loss: 2.4661304925899983

Epoch: 5| Step: 8
Training loss: 2.6127952956358773
Validation loss: 2.4673127888070088

Epoch: 5| Step: 9
Training loss: 2.422291578336208
Validation loss: 2.4692779209947413

Epoch: 5| Step: 10
Training loss: 2.4032058285537117
Validation loss: 2.464426395248931

Epoch: 5| Step: 11
Training loss: 3.3573774209444314
Validation loss: 2.466316971820967

Epoch: 113| Step: 0
Training loss: 2.3579139480354945
Validation loss: 2.459129908918359

Epoch: 5| Step: 1
Training loss: 2.554013971324874
Validation loss: 2.4522617769146833

Epoch: 5| Step: 2
Training loss: 2.7203156797159314
Validation loss: 2.4611327785135426

Epoch: 5| Step: 3
Training loss: 2.6520139239134126
Validation loss: 2.458227364766971

Epoch: 5| Step: 4
Training loss: 2.509126978264392
Validation loss: 2.4682120892031265

Epoch: 5| Step: 5
Training loss: 2.7964790106534227
Validation loss: 2.483712661870796

Epoch: 5| Step: 6
Training loss: 2.3927563908397658
Validation loss: 2.497795352795005

Epoch: 5| Step: 7
Training loss: 2.6070006755422663
Validation loss: 2.4934573789796093

Epoch: 5| Step: 8
Training loss: 2.9584465721557813
Validation loss: 2.501326427642427

Epoch: 5| Step: 9
Training loss: 2.168359119907997
Validation loss: 2.476540125155132

Epoch: 5| Step: 10
Training loss: 2.4641251521590637
Validation loss: 2.47463502697494

Epoch: 5| Step: 11
Training loss: 3.750333516866458
Validation loss: 2.4699920394964807

Epoch: 114| Step: 0
Training loss: 2.3403183291802363
Validation loss: 2.4600070587111205

Epoch: 5| Step: 1
Training loss: 2.551197152457169
Validation loss: 2.4661046192198994

Epoch: 5| Step: 2
Training loss: 2.7895568922374205
Validation loss: 2.465712989007481

Epoch: 5| Step: 3
Training loss: 2.8280393471577203
Validation loss: 2.4585731168498755

Epoch: 5| Step: 4
Training loss: 2.1441117451356546
Validation loss: 2.4674552427533714

Epoch: 5| Step: 5
Training loss: 2.268799970932975
Validation loss: 2.468027999181215

Epoch: 5| Step: 6
Training loss: 2.9218462774323553
Validation loss: 2.4632304292713965

Epoch: 5| Step: 7
Training loss: 2.1733245403408357
Validation loss: 2.459761173930227

Epoch: 5| Step: 8
Training loss: 2.6541105742543305
Validation loss: 2.464252876679318

Epoch: 5| Step: 9
Training loss: 2.6512681805582172
Validation loss: 2.46410966310779

Epoch: 5| Step: 10
Training loss: 2.809248082706768
Validation loss: 2.4672077367370195

Epoch: 5| Step: 11
Training loss: 2.6145182648321876
Validation loss: 2.4642328673113494

Epoch: 115| Step: 0
Training loss: 2.1781682014285764
Validation loss: 2.4636055304305566

Epoch: 5| Step: 1
Training loss: 2.3803118482210466
Validation loss: 2.462457177553095

Epoch: 5| Step: 2
Training loss: 2.6805783228546964
Validation loss: 2.4678268557665515

Epoch: 5| Step: 3
Training loss: 2.092681156461113
Validation loss: 2.4638881493461824

Epoch: 5| Step: 4
Training loss: 2.743032732733144
Validation loss: 2.464117456023685

Epoch: 5| Step: 5
Training loss: 2.2260357149931465
Validation loss: 2.463596195534177

Epoch: 5| Step: 6
Training loss: 3.020401250696662
Validation loss: 2.459508575890062

Epoch: 5| Step: 7
Training loss: 2.7825351274848726
Validation loss: 2.456763203873041

Epoch: 5| Step: 8
Training loss: 2.68794371024866
Validation loss: 2.4573972153536787

Epoch: 5| Step: 9
Training loss: 2.924634476996338
Validation loss: 2.4665123017011603

Epoch: 5| Step: 10
Training loss: 2.5876771543736545
Validation loss: 2.4601432850830127

Epoch: 5| Step: 11
Training loss: 1.7719934440732628
Validation loss: 2.4672499578106617

Epoch: 116| Step: 0
Training loss: 2.2870457849694192
Validation loss: 2.458945429834152

Epoch: 5| Step: 1
Training loss: 1.9607238045172777
Validation loss: 2.454457797693923

Epoch: 5| Step: 2
Training loss: 2.9786997253555128
Validation loss: 2.452099279926037

Epoch: 5| Step: 3
Training loss: 2.6629477039435057
Validation loss: 2.4634068810418595

Epoch: 5| Step: 4
Training loss: 2.6914819006399
Validation loss: 2.4538111769799915

Epoch: 5| Step: 5
Training loss: 2.5011246059085113
Validation loss: 2.4541754407245504

Epoch: 5| Step: 6
Training loss: 2.855080135844226
Validation loss: 2.454356562700048

Epoch: 5| Step: 7
Training loss: 2.350984521345152
Validation loss: 2.45334723452028

Epoch: 5| Step: 8
Training loss: 2.8944627184869627
Validation loss: 2.4551516946488836

Epoch: 5| Step: 9
Training loss: 2.250507933186734
Validation loss: 2.4598712730648926

Epoch: 5| Step: 10
Training loss: 2.5786233131402803
Validation loss: 2.455846778963128

Epoch: 5| Step: 11
Training loss: 3.157710426791116
Validation loss: 2.4593130371289122

Epoch: 117| Step: 0
Training loss: 2.6118812631430184
Validation loss: 2.4639621695647778

Epoch: 5| Step: 1
Training loss: 2.2853374702782654
Validation loss: 2.462148733629896

Epoch: 5| Step: 2
Training loss: 2.6029143615715706
Validation loss: 2.459130571426427

Epoch: 5| Step: 3
Training loss: 2.670290917967248
Validation loss: 2.462400241870829

Epoch: 5| Step: 4
Training loss: 2.637628333418157
Validation loss: 2.4580639446418253

Epoch: 5| Step: 5
Training loss: 2.6511502846361
Validation loss: 2.465068232595927

Epoch: 5| Step: 6
Training loss: 2.6026300296308875
Validation loss: 2.4620917545014698

Epoch: 5| Step: 7
Training loss: 2.510305146290035
Validation loss: 2.456322394380798

Epoch: 5| Step: 8
Training loss: 2.1614988269613007
Validation loss: 2.4600605244737674

Epoch: 5| Step: 9
Training loss: 3.081070937704769
Validation loss: 2.4582016203773818

Epoch: 5| Step: 10
Training loss: 2.4668906247649534
Validation loss: 2.456351945911472

Epoch: 5| Step: 11
Training loss: 1.9630037037935455
Validation loss: 2.457312324752961

Epoch: 118| Step: 0
Training loss: 2.9906561296809997
Validation loss: 2.453810120336909

Epoch: 5| Step: 1
Training loss: 3.0455547895975257
Validation loss: 2.4543499490100444

Epoch: 5| Step: 2
Training loss: 2.529139734048327
Validation loss: 2.4535507998885344

Epoch: 5| Step: 3
Training loss: 2.3993380468155645
Validation loss: 2.454700326592637

Epoch: 5| Step: 4
Training loss: 2.9188352061869587
Validation loss: 2.4501888254281736

Epoch: 5| Step: 5
Training loss: 2.3953258695683433
Validation loss: 2.452460395377846

Epoch: 5| Step: 6
Training loss: 2.698311991553194
Validation loss: 2.452226123822435

Epoch: 5| Step: 7
Training loss: 2.4739347650844214
Validation loss: 2.453755773452338

Epoch: 5| Step: 8
Training loss: 2.378546827001677
Validation loss: 2.4559639784416243

Epoch: 5| Step: 9
Training loss: 2.20613379672234
Validation loss: 2.454055690577011

Epoch: 5| Step: 10
Training loss: 1.970716069975757
Validation loss: 2.456320728128163

Epoch: 5| Step: 11
Training loss: 2.1621380453440118
Validation loss: 2.4627909749841064

Epoch: 119| Step: 0
Training loss: 2.7062072821014156
Validation loss: 2.4519947185617643

Epoch: 5| Step: 1
Training loss: 2.269832308788905
Validation loss: 2.4533130022969614

Epoch: 5| Step: 2
Training loss: 2.2441658038527112
Validation loss: 2.4637197036338425

Epoch: 5| Step: 3
Training loss: 2.859754360027243
Validation loss: 2.4608240656468827

Epoch: 5| Step: 4
Training loss: 1.8872669758227123
Validation loss: 2.4504495678605154

Epoch: 5| Step: 5
Training loss: 2.3784857818390255
Validation loss: 2.458367457934245

Epoch: 5| Step: 6
Training loss: 3.2854588717352358
Validation loss: 2.4579630036703484

Epoch: 5| Step: 7
Training loss: 2.6057283423727013
Validation loss: 2.452038846440193

Epoch: 5| Step: 8
Training loss: 2.3612544172093206
Validation loss: 2.4528805819516606

Epoch: 5| Step: 9
Training loss: 2.558366931442008
Validation loss: 2.454888756569521

Epoch: 5| Step: 10
Training loss: 2.6038896845700665
Validation loss: 2.4497239009181784

Epoch: 5| Step: 11
Training loss: 2.325648891999793
Validation loss: 2.454250858905019

Epoch: 120| Step: 0
Training loss: 2.0214580736891037
Validation loss: 2.4445145293204718

Epoch: 5| Step: 1
Training loss: 2.7639015129307976
Validation loss: 2.453757939415717

Epoch: 5| Step: 2
Training loss: 2.5396997209707637
Validation loss: 2.4692941943076536

Epoch: 5| Step: 3
Training loss: 2.6610081858718697
Validation loss: 2.471465130730996

Epoch: 5| Step: 4
Training loss: 2.575350476459296
Validation loss: 2.4648223650327563

Epoch: 5| Step: 5
Training loss: 2.391330390532042
Validation loss: 2.477803790652526

Epoch: 5| Step: 6
Training loss: 2.9446951221625293
Validation loss: 2.462034794228958

Epoch: 5| Step: 7
Training loss: 2.749698015451511
Validation loss: 2.4517615714614536

Epoch: 5| Step: 8
Training loss: 2.4281955075429082
Validation loss: 2.4580615804007837

Epoch: 5| Step: 9
Training loss: 2.530207195467567
Validation loss: 2.453225293711128

Epoch: 5| Step: 10
Training loss: 2.371603595147872
Validation loss: 2.4564212553327374

Epoch: 5| Step: 11
Training loss: 3.332899796585122
Validation loss: 2.4541130991617885

Epoch: 121| Step: 0
Training loss: 2.6903611854652634
Validation loss: 2.4625800933011925

Epoch: 5| Step: 1
Training loss: 2.2886239630988343
Validation loss: 2.4601967801886024

Epoch: 5| Step: 2
Training loss: 2.805549935271254
Validation loss: 2.4546188758502643

Epoch: 5| Step: 3
Training loss: 2.4385019834978503
Validation loss: 2.458986952469505

Epoch: 5| Step: 4
Training loss: 1.8958181513363568
Validation loss: 2.456842323240539

Epoch: 5| Step: 5
Training loss: 2.3777381772856487
Validation loss: 2.459434797278216

Epoch: 5| Step: 6
Training loss: 2.1706112265376407
Validation loss: 2.4529533366663414

Epoch: 5| Step: 7
Training loss: 2.2852698664663973
Validation loss: 2.4616164628188844

Epoch: 5| Step: 8
Training loss: 3.215252800430895
Validation loss: 2.4546340909052873

Epoch: 5| Step: 9
Training loss: 2.4525120449256455
Validation loss: 2.4560894113643044

Epoch: 5| Step: 10
Training loss: 2.995153008375215
Validation loss: 2.4532635076665326

Epoch: 5| Step: 11
Training loss: 3.408292805276064
Validation loss: 2.458408477141215

Epoch: 122| Step: 0
Training loss: 2.6706049170298045
Validation loss: 2.4551024313092458

Epoch: 5| Step: 1
Training loss: 2.1816911136587325
Validation loss: 2.452276799994611

Epoch: 5| Step: 2
Training loss: 2.4103550759384085
Validation loss: 2.4629363243064146

Epoch: 5| Step: 3
Training loss: 2.6636006690511853
Validation loss: 2.461547069642447

Epoch: 5| Step: 4
Training loss: 2.8548270990557256
Validation loss: 2.463057139024156

Epoch: 5| Step: 5
Training loss: 2.230402155481608
Validation loss: 2.463427451606545

Epoch: 5| Step: 6
Training loss: 2.453042873295597
Validation loss: 2.4613981512146292

Epoch: 5| Step: 7
Training loss: 2.7936251209178273
Validation loss: 2.46413647861736

Epoch: 5| Step: 8
Training loss: 2.027851959799289
Validation loss: 2.4803267310629296

Epoch: 5| Step: 9
Training loss: 3.156081091260847
Validation loss: 2.464122725198066

Epoch: 5| Step: 10
Training loss: 2.521277575060737
Validation loss: 2.4669718032231134

Epoch: 5| Step: 11
Training loss: 3.0326732951413473
Validation loss: 2.457584191526541

Epoch: 123| Step: 0
Training loss: 3.0948814095746955
Validation loss: 2.459107221949014

Epoch: 5| Step: 1
Training loss: 2.3465022902283463
Validation loss: 2.465569052405957

Epoch: 5| Step: 2
Training loss: 2.4282850529416526
Validation loss: 2.458618350936761

Epoch: 5| Step: 3
Training loss: 2.462177944907995
Validation loss: 2.4519763492677322

Epoch: 5| Step: 4
Training loss: 2.2165516453015623
Validation loss: 2.4478893251447778

Epoch: 5| Step: 5
Training loss: 2.0241356311783463
Validation loss: 2.4507683410401837

Epoch: 5| Step: 6
Training loss: 2.6055163331955584
Validation loss: 2.453308645287027

Epoch: 5| Step: 7
Training loss: 2.7490278606480847
Validation loss: 2.4592813196884658

Epoch: 5| Step: 8
Training loss: 2.640168460904176
Validation loss: 2.4468673621489225

Epoch: 5| Step: 9
Training loss: 2.2123766417516393
Validation loss: 2.448240454883264

Epoch: 5| Step: 10
Training loss: 3.0227977460258413
Validation loss: 2.4528047429538566

Epoch: 5| Step: 11
Training loss: 2.9663927859065327
Validation loss: 2.451978622141084

Epoch: 124| Step: 0
Training loss: 2.6362560177006777
Validation loss: 2.4478176090137325

Epoch: 5| Step: 1
Training loss: 2.604709772061675
Validation loss: 2.4458425960874433

Epoch: 5| Step: 2
Training loss: 2.3001166065345484
Validation loss: 2.4524305296069486

Epoch: 5| Step: 3
Training loss: 2.8284127104872705
Validation loss: 2.452660858888102

Epoch: 5| Step: 4
Training loss: 2.4112530504902496
Validation loss: 2.4433851192428295

Epoch: 5| Step: 5
Training loss: 2.9295756814598386
Validation loss: 2.445045919786727

Epoch: 5| Step: 6
Training loss: 2.630537640695105
Validation loss: 2.4541701299538214

Epoch: 5| Step: 7
Training loss: 2.541039832525448
Validation loss: 2.442731010613715

Epoch: 5| Step: 8
Training loss: 1.9886703260419842
Validation loss: 2.4582582411100145

Epoch: 5| Step: 9
Training loss: 2.822627419906004
Validation loss: 2.4465147847029605

Epoch: 5| Step: 10
Training loss: 2.0520097232015666
Validation loss: 2.453738490210635

Epoch: 5| Step: 11
Training loss: 2.8514327346330157
Validation loss: 2.4496158113731146

Epoch: 125| Step: 0
Training loss: 2.802203084851928
Validation loss: 2.459006238965919

Epoch: 5| Step: 1
Training loss: 2.5799091061394317
Validation loss: 2.4488149388134186

Epoch: 5| Step: 2
Training loss: 2.3250878512284596
Validation loss: 2.457884195215335

Epoch: 5| Step: 3
Training loss: 2.3393802852504666
Validation loss: 2.4556438367844

Epoch: 5| Step: 4
Training loss: 2.756925878027198
Validation loss: 2.4555554630230136

Epoch: 5| Step: 5
Training loss: 2.8354145334998595
Validation loss: 2.4474636646219334

Epoch: 5| Step: 6
Training loss: 2.9379692514471167
Validation loss: 2.4553800734568028

Epoch: 5| Step: 7
Training loss: 2.3428934185030883
Validation loss: 2.4535542414253557

Epoch: 5| Step: 8
Training loss: 1.7020572500047408
Validation loss: 2.452765659165773

Epoch: 5| Step: 9
Training loss: 2.4370667488245616
Validation loss: 2.4488305083783666

Epoch: 5| Step: 10
Training loss: 2.678661183261275
Validation loss: 2.463410337037777

Epoch: 5| Step: 11
Training loss: 2.7359159650668574
Validation loss: 2.451213168623424

Epoch: 126| Step: 0
Training loss: 2.6243779489891743
Validation loss: 2.4646201095244904

Epoch: 5| Step: 1
Training loss: 2.9165086067605057
Validation loss: 2.45986690747885

Epoch: 5| Step: 2
Training loss: 1.5006961796413316
Validation loss: 2.4704590527346957

Epoch: 5| Step: 3
Training loss: 2.4394142263837235
Validation loss: 2.4746220003010215

Epoch: 5| Step: 4
Training loss: 2.817190793797688
Validation loss: 2.4883918398281257

Epoch: 5| Step: 5
Training loss: 2.7027474729593015
Validation loss: 2.4663543626436364

Epoch: 5| Step: 6
Training loss: 2.418516821057694
Validation loss: 2.465349744961161

Epoch: 5| Step: 7
Training loss: 2.8110005938333584
Validation loss: 2.4501532516427087

Epoch: 5| Step: 8
Training loss: 2.4366999560307407
Validation loss: 2.4507707487981247

Epoch: 5| Step: 9
Training loss: 2.889861629829876
Validation loss: 2.4507232903990155

Epoch: 5| Step: 10
Training loss: 2.523935747117706
Validation loss: 2.44690667006458

Epoch: 5| Step: 11
Training loss: 1.0677422618902646
Validation loss: 2.4453273037430874

Epoch: 127| Step: 0
Training loss: 2.2252634642557636
Validation loss: 2.4514652801032275

Epoch: 5| Step: 1
Training loss: 2.1290812849131275
Validation loss: 2.447327570677964

Epoch: 5| Step: 2
Training loss: 2.7367607825664364
Validation loss: 2.4492191718272

Epoch: 5| Step: 3
Training loss: 2.9127230186375055
Validation loss: 2.453000926061

Epoch: 5| Step: 4
Training loss: 2.3767508026503683
Validation loss: 2.455627452784066

Epoch: 5| Step: 5
Training loss: 2.5182921682141104
Validation loss: 2.455964835958442

Epoch: 5| Step: 6
Training loss: 3.1241576013020596
Validation loss: 2.4520282622229828

Epoch: 5| Step: 7
Training loss: 2.349627639813672
Validation loss: 2.448611016242543

Epoch: 5| Step: 8
Training loss: 2.5251747977306915
Validation loss: 2.449724497031732

Epoch: 5| Step: 9
Training loss: 2.3175969014901256
Validation loss: 2.4474332102077963

Epoch: 5| Step: 10
Training loss: 2.6454929423204727
Validation loss: 2.4534222388344555

Epoch: 5| Step: 11
Training loss: 1.793229161053016
Validation loss: 2.4441804957093445

Epoch: 128| Step: 0
Training loss: 2.3468347213275407
Validation loss: 2.449538019960186

Epoch: 5| Step: 1
Training loss: 2.5535558591476617
Validation loss: 2.45884590274128

Epoch: 5| Step: 2
Training loss: 2.796539968531339
Validation loss: 2.455525748173605

Epoch: 5| Step: 3
Training loss: 2.150280526068586
Validation loss: 2.453647076071938

Epoch: 5| Step: 4
Training loss: 2.852682149890384
Validation loss: 2.45660689044633

Epoch: 5| Step: 5
Training loss: 2.0174226063912144
Validation loss: 2.4612904976670467

Epoch: 5| Step: 6
Training loss: 2.857589080570115
Validation loss: 2.462665980210731

Epoch: 5| Step: 7
Training loss: 1.9642557587754625
Validation loss: 2.459834555054424

Epoch: 5| Step: 8
Training loss: 2.580615788242624
Validation loss: 2.4654238824726407

Epoch: 5| Step: 9
Training loss: 2.656761658700102
Validation loss: 2.4613267338449187

Epoch: 5| Step: 10
Training loss: 2.899433797613031
Validation loss: 2.465926048101711

Epoch: 5| Step: 11
Training loss: 2.612661154125122
Validation loss: 2.4632626161073174

Epoch: 129| Step: 0
Training loss: 2.8344731188764696
Validation loss: 2.4667789944856224

Epoch: 5| Step: 1
Training loss: 2.4957550248824654
Validation loss: 2.4734931802978846

Epoch: 5| Step: 2
Training loss: 2.778973365554478
Validation loss: 2.4647007783351764

Epoch: 5| Step: 3
Training loss: 2.3256681651184903
Validation loss: 2.475930591595922

Epoch: 5| Step: 4
Training loss: 2.609712407574874
Validation loss: 2.4867421355143113

Epoch: 5| Step: 5
Training loss: 2.668750921959461
Validation loss: 2.475318233103053

Epoch: 5| Step: 6
Training loss: 2.429526369694818
Validation loss: 2.4723599393457154

Epoch: 5| Step: 7
Training loss: 2.8291411708156766
Validation loss: 2.4710275952125835

Epoch: 5| Step: 8
Training loss: 2.638290185661874
Validation loss: 2.4632229037583055

Epoch: 5| Step: 9
Training loss: 1.9187929825830001
Validation loss: 2.463326417876057

Epoch: 5| Step: 10
Training loss: 2.2324640598800256
Validation loss: 2.4585019184486767

Epoch: 5| Step: 11
Training loss: 2.4843108930653828
Validation loss: 2.4608570832530536

Epoch: 130| Step: 0
Training loss: 2.4670522139350313
Validation loss: 2.4548972990602187

Epoch: 5| Step: 1
Training loss: 2.2492765747142136
Validation loss: 2.4457293795947543

Epoch: 5| Step: 2
Training loss: 2.475114850548754
Validation loss: 2.4463622020719145

Epoch: 5| Step: 3
Training loss: 2.061774270660578
Validation loss: 2.446343319431421

Epoch: 5| Step: 4
Training loss: 3.12008646918564
Validation loss: 2.4443281871852114

Epoch: 5| Step: 5
Training loss: 3.0622703310425257
Validation loss: 2.4493524209698467

Epoch: 5| Step: 6
Training loss: 2.522554319796837
Validation loss: 2.452635017590367

Epoch: 5| Step: 7
Training loss: 2.2179952062928225
Validation loss: 2.4506980894047286

Epoch: 5| Step: 8
Training loss: 2.628224436072926
Validation loss: 2.4558529234386253

Epoch: 5| Step: 9
Training loss: 2.4354668965855426
Validation loss: 2.458036903246586

Epoch: 5| Step: 10
Training loss: 2.5021134026653074
Validation loss: 2.4532248077822505

Epoch: 5| Step: 11
Training loss: 1.7191451572114906
Validation loss: 2.4544933293287494

Epoch: 131| Step: 0
Training loss: 2.4859347455520764
Validation loss: 2.4569963049412515

Epoch: 5| Step: 1
Training loss: 2.22954308965107
Validation loss: 2.4523101494042674

Epoch: 5| Step: 2
Training loss: 2.7966060402550212
Validation loss: 2.465134802479563

Epoch: 5| Step: 3
Training loss: 2.8178540448902676
Validation loss: 2.456512295288761

Epoch: 5| Step: 4
Training loss: 2.6496642205895746
Validation loss: 2.4548830952814775

Epoch: 5| Step: 5
Training loss: 2.8520030896249007
Validation loss: 2.4505614839128653

Epoch: 5| Step: 6
Training loss: 2.35539364418247
Validation loss: 2.4597177540514576

Epoch: 5| Step: 7
Training loss: 2.3464635780445433
Validation loss: 2.4511231598692906

Epoch: 5| Step: 8
Training loss: 2.5880051382388207
Validation loss: 2.4547543025098384

Epoch: 5| Step: 9
Training loss: 2.3765417415356866
Validation loss: 2.4592455259929196

Epoch: 5| Step: 10
Training loss: 2.32765213433313
Validation loss: 2.4623544478928907

Epoch: 5| Step: 11
Training loss: 1.5433185422338236
Validation loss: 2.466243197497296

Epoch: 132| Step: 0
Training loss: 2.178352302501755
Validation loss: 2.4638624378974523

Epoch: 5| Step: 1
Training loss: 2.816108000011845
Validation loss: 2.457067191179993

Epoch: 5| Step: 2
Training loss: 2.5393424950786003
Validation loss: 2.4536896236050354

Epoch: 5| Step: 3
Training loss: 2.0358523534739112
Validation loss: 2.4618061248307557

Epoch: 5| Step: 4
Training loss: 2.429327542543401
Validation loss: 2.457581422601078

Epoch: 5| Step: 5
Training loss: 3.1650377065813973
Validation loss: 2.450533678681249

Epoch: 5| Step: 6
Training loss: 2.658078450706424
Validation loss: 2.45396701268319

Epoch: 5| Step: 7
Training loss: 2.066647838178614
Validation loss: 2.448303672283229

Epoch: 5| Step: 8
Training loss: 2.5396465862138045
Validation loss: 2.456691117995313

Epoch: 5| Step: 9
Training loss: 2.6757336688858033
Validation loss: 2.4484770248458982

Epoch: 5| Step: 10
Training loss: 2.4649987028478337
Validation loss: 2.4543183435017886

Epoch: 5| Step: 11
Training loss: 1.3846053231110134
Validation loss: 2.4563631747528327

Epoch: 133| Step: 0
Training loss: 2.456041485426744
Validation loss: 2.4494191178533113

Epoch: 5| Step: 1
Training loss: 2.5230298731695115
Validation loss: 2.451705578660106

Epoch: 5| Step: 2
Training loss: 2.5922511722408634
Validation loss: 2.4469982507551595

Epoch: 5| Step: 3
Training loss: 2.415735251611336
Validation loss: 2.4420940518779934

Epoch: 5| Step: 4
Training loss: 2.7237661280511225
Validation loss: 2.4473297139163708

Epoch: 5| Step: 5
Training loss: 2.5534842454354427
Validation loss: 2.4541856048276416

Epoch: 5| Step: 6
Training loss: 2.3685386503036376
Validation loss: 2.4603404678240337

Epoch: 5| Step: 7
Training loss: 2.1848083284577595
Validation loss: 2.4586182034576156

Epoch: 5| Step: 8
Training loss: 2.8267043112401398
Validation loss: 2.4496003765723007

Epoch: 5| Step: 9
Training loss: 2.5399598399314023
Validation loss: 2.458361958213145

Epoch: 5| Step: 10
Training loss: 2.228512522421975
Validation loss: 2.4550786267474543

Epoch: 5| Step: 11
Training loss: 3.3696380690287135
Validation loss: 2.4576381990970066

Epoch: 134| Step: 0
Training loss: 2.2453992217643832
Validation loss: 2.4519446341591573

Epoch: 5| Step: 1
Training loss: 3.02199076260178
Validation loss: 2.4604058998404215

Epoch: 5| Step: 2
Training loss: 1.9654541280978761
Validation loss: 2.460195758591578

Epoch: 5| Step: 3
Training loss: 2.787692206218055
Validation loss: 2.4643620273701092

Epoch: 5| Step: 4
Training loss: 2.581772968803622
Validation loss: 2.469079937194348

Epoch: 5| Step: 5
Training loss: 2.562467435304228
Validation loss: 2.465604331248607

Epoch: 5| Step: 6
Training loss: 2.1434937348964955
Validation loss: 2.463095636025796

Epoch: 5| Step: 7
Training loss: 2.519646504449633
Validation loss: 2.4573730206791335

Epoch: 5| Step: 8
Training loss: 2.1789783705206385
Validation loss: 2.4667636086825135

Epoch: 5| Step: 9
Training loss: 3.040571686295917
Validation loss: 2.462823123193405

Epoch: 5| Step: 10
Training loss: 2.457417807926614
Validation loss: 2.4593394828277266

Epoch: 5| Step: 11
Training loss: 2.0937537577581136
Validation loss: 2.464410488864131

Epoch: 135| Step: 0
Training loss: 2.4304113750987657
Validation loss: 2.454400854535526

Epoch: 5| Step: 1
Training loss: 2.5605331874455386
Validation loss: 2.4498010477556376

Epoch: 5| Step: 2
Training loss: 2.1059239166224737
Validation loss: 2.4483366599189105

Epoch: 5| Step: 3
Training loss: 2.394202951947885
Validation loss: 2.4600315949561344

Epoch: 5| Step: 4
Training loss: 2.840625765457302
Validation loss: 2.457355273723799

Epoch: 5| Step: 5
Training loss: 2.7954643570755264
Validation loss: 2.459367608588816

Epoch: 5| Step: 6
Training loss: 2.7363868505587154
Validation loss: 2.4560691716782674

Epoch: 5| Step: 7
Training loss: 2.5291786666996026
Validation loss: 2.4545070132623357

Epoch: 5| Step: 8
Training loss: 2.6992967431466766
Validation loss: 2.4534028153119243

Epoch: 5| Step: 9
Training loss: 2.613312086713149
Validation loss: 2.4553047223295867

Epoch: 5| Step: 10
Training loss: 2.2182028727164673
Validation loss: 2.450974001249695

Epoch: 5| Step: 11
Training loss: 1.0036893974052048
Validation loss: 2.459445068899383

Epoch: 136| Step: 0
Training loss: 2.5942570753689402
Validation loss: 2.4564975387304164

Epoch: 5| Step: 1
Training loss: 2.0306872248486654
Validation loss: 2.4508151581315225

Epoch: 5| Step: 2
Training loss: 2.182430168861209
Validation loss: 2.450093937876505

Epoch: 5| Step: 3
Training loss: 2.2164280521583115
Validation loss: 2.450732901326002

Epoch: 5| Step: 4
Training loss: 2.7076683010440927
Validation loss: 2.4475247224904066

Epoch: 5| Step: 5
Training loss: 2.2924450563858345
Validation loss: 2.4501376539926327

Epoch: 5| Step: 6
Training loss: 3.0549832954511946
Validation loss: 2.446513493459177

Epoch: 5| Step: 7
Training loss: 2.4319915150632414
Validation loss: 2.45157238042691

Epoch: 5| Step: 8
Training loss: 2.8681349683045134
Validation loss: 2.448854970001418

Epoch: 5| Step: 9
Training loss: 2.568040022921405
Validation loss: 2.4599394535480905

Epoch: 5| Step: 10
Training loss: 2.7217574750051816
Validation loss: 2.4592230541853177

Epoch: 5| Step: 11
Training loss: 2.555187118158134
Validation loss: 2.4565734517655216

Epoch: 137| Step: 0
Training loss: 1.870492731140909
Validation loss: 2.456397095531278

Epoch: 5| Step: 1
Training loss: 2.6682938339991917
Validation loss: 2.4542110432356696

Epoch: 5| Step: 2
Training loss: 2.164976732512231
Validation loss: 2.4602458587443397

Epoch: 5| Step: 3
Training loss: 2.601962955114388
Validation loss: 2.456034690214316

Epoch: 5| Step: 4
Training loss: 2.528388772791272
Validation loss: 2.454709375608968

Epoch: 5| Step: 5
Training loss: 2.269043546659734
Validation loss: 2.4513833834922814

Epoch: 5| Step: 6
Training loss: 2.751583857022897
Validation loss: 2.4512740500179904

Epoch: 5| Step: 7
Training loss: 2.709100986162893
Validation loss: 2.452165549646584

Epoch: 5| Step: 8
Training loss: 2.557917707979179
Validation loss: 2.4539244578148627

Epoch: 5| Step: 9
Training loss: 2.73311381001235
Validation loss: 2.4485777645349174

Epoch: 5| Step: 10
Training loss: 2.6929146093067224
Validation loss: 2.45510048098667

Epoch: 5| Step: 11
Training loss: 2.199451820395641
Validation loss: 2.455457030448493

Epoch: 138| Step: 0
Training loss: 2.7173252976735163
Validation loss: 2.451571752345575

Epoch: 5| Step: 1
Training loss: 2.250214354582924
Validation loss: 2.4561565239019494

Epoch: 5| Step: 2
Training loss: 1.8826429361940664
Validation loss: 2.4575638711790857

Epoch: 5| Step: 3
Training loss: 2.7991313676878793
Validation loss: 2.45650854246457

Epoch: 5| Step: 4
Training loss: 2.118246791801603
Validation loss: 2.4542372949753273

Epoch: 5| Step: 5
Training loss: 2.6477206449987576
Validation loss: 2.45598303789573

Epoch: 5| Step: 6
Training loss: 2.338139647412708
Validation loss: 2.4546224838443123

Epoch: 5| Step: 7
Training loss: 2.9188659187513135
Validation loss: 2.452968468906114

Epoch: 5| Step: 8
Training loss: 2.6288303403962088
Validation loss: 2.4528264554503543

Epoch: 5| Step: 9
Training loss: 2.573463803905586
Validation loss: 2.4479571575847134

Epoch: 5| Step: 10
Training loss: 2.752252696445283
Validation loss: 2.456261739225541

Epoch: 5| Step: 11
Training loss: 1.8077591026814488
Validation loss: 2.4648704063880476

Epoch: 139| Step: 0
Training loss: 2.60203112714535
Validation loss: 2.457993699443617

Epoch: 5| Step: 1
Training loss: 2.838161804726709
Validation loss: 2.458816906410289

Epoch: 5| Step: 2
Training loss: 2.506944928179477
Validation loss: 2.451923543871034

Epoch: 5| Step: 3
Training loss: 2.468682493421626
Validation loss: 2.45035657963939

Epoch: 5| Step: 4
Training loss: 2.2246820372653597
Validation loss: 2.4457487787602847

Epoch: 5| Step: 5
Training loss: 2.513171593026161
Validation loss: 2.4520802307973555

Epoch: 5| Step: 6
Training loss: 2.8316692252444122
Validation loss: 2.4431213417458473

Epoch: 5| Step: 7
Training loss: 2.5484886440288284
Validation loss: 2.4441222705693484

Epoch: 5| Step: 8
Training loss: 2.3789662821794733
Validation loss: 2.4563224995326256

Epoch: 5| Step: 9
Training loss: 2.1975010724547874
Validation loss: 2.4486495740262604

Epoch: 5| Step: 10
Training loss: 2.5144291280277256
Validation loss: 2.441552909006443

Epoch: 5| Step: 11
Training loss: 3.320268267168603
Validation loss: 2.447463652445114

Epoch: 140| Step: 0
Training loss: 2.659490247082815
Validation loss: 2.455035439673788

Epoch: 5| Step: 1
Training loss: 2.2951045056985175
Validation loss: 2.4492332320162884

Epoch: 5| Step: 2
Training loss: 2.8756437824765935
Validation loss: 2.465661059987369

Epoch: 5| Step: 3
Training loss: 2.442741041364396
Validation loss: 2.4715400494584685

Epoch: 5| Step: 4
Training loss: 3.0812988958289997
Validation loss: 2.480387356441457

Epoch: 5| Step: 5
Training loss: 1.890725251369371
Validation loss: 2.480500128439928

Epoch: 5| Step: 6
Training loss: 2.540918980255213
Validation loss: 2.474024606452823

Epoch: 5| Step: 7
Training loss: 3.1079909728421136
Validation loss: 2.4741051974958155

Epoch: 5| Step: 8
Training loss: 2.239859512215096
Validation loss: 2.476985229450972

Epoch: 5| Step: 9
Training loss: 2.6779279353706618
Validation loss: 2.4724775815255318

Epoch: 5| Step: 10
Training loss: 2.1533266236089488
Validation loss: 2.471421221087036

Epoch: 5| Step: 11
Training loss: 2.5720078462982334
Validation loss: 2.4775925308370232

Epoch: 141| Step: 0
Training loss: 2.5014905300902797
Validation loss: 2.4644168095077887

Epoch: 5| Step: 1
Training loss: 2.856730588051656
Validation loss: 2.4640953713278386

Epoch: 5| Step: 2
Training loss: 2.722523668254611
Validation loss: 2.4643683723246426

Epoch: 5| Step: 3
Training loss: 2.425797368731673
Validation loss: 2.4651137706366133

Epoch: 5| Step: 4
Training loss: 2.4378722469038694
Validation loss: 2.4588849666459986

Epoch: 5| Step: 5
Training loss: 2.7567852581796783
Validation loss: 2.4617768324691984

Epoch: 5| Step: 6
Training loss: 2.6717722019698367
Validation loss: 2.4472449429412655

Epoch: 5| Step: 7
Training loss: 2.492617578975871
Validation loss: 2.4608756284656264

Epoch: 5| Step: 8
Training loss: 2.3448864025589304
Validation loss: 2.465865296812754

Epoch: 5| Step: 9
Training loss: 2.4273035061449573
Validation loss: 2.4560352119902227

Epoch: 5| Step: 10
Training loss: 2.3035166724404625
Validation loss: 2.457677104346588

Epoch: 5| Step: 11
Training loss: 2.2935860889711495
Validation loss: 2.453362362305916

Epoch: 142| Step: 0
Training loss: 2.484008186179415
Validation loss: 2.4560026149399308

Epoch: 5| Step: 1
Training loss: 1.8319427533929613
Validation loss: 2.4572755644624977

Epoch: 5| Step: 2
Training loss: 2.059167423698423
Validation loss: 2.4572285349068093

Epoch: 5| Step: 3
Training loss: 2.943781690163736
Validation loss: 2.4616231659467998

Epoch: 5| Step: 4
Training loss: 2.667913433523591
Validation loss: 2.471042783607372

Epoch: 5| Step: 5
Training loss: 2.5948376500789667
Validation loss: 2.4653175128426916

Epoch: 5| Step: 6
Training loss: 2.6720812980025075
Validation loss: 2.4717409429517025

Epoch: 5| Step: 7
Training loss: 2.9842797708546733
Validation loss: 2.462869578026293

Epoch: 5| Step: 8
Training loss: 2.293678186939951
Validation loss: 2.4687355218132825

Epoch: 5| Step: 9
Training loss: 2.3490334531919905
Validation loss: 2.451651594375848

Epoch: 5| Step: 10
Training loss: 2.772590357389002
Validation loss: 2.458327391719642

Epoch: 5| Step: 11
Training loss: 2.833815440131991
Validation loss: 2.4557136839900746

Epoch: 143| Step: 0
Training loss: 2.5797726077037284
Validation loss: 2.4484783617126453

Epoch: 5| Step: 1
Training loss: 2.472612763274046
Validation loss: 2.4570153280853146

Epoch: 5| Step: 2
Training loss: 2.515073538097559
Validation loss: 2.455176959176523

Epoch: 5| Step: 3
Training loss: 2.5830162120314752
Validation loss: 2.458404179672906

Epoch: 5| Step: 4
Training loss: 2.634993829593274
Validation loss: 2.463229400866623

Epoch: 5| Step: 5
Training loss: 2.557316165555517
Validation loss: 2.453927153949992

Epoch: 5| Step: 6
Training loss: 2.722496695748558
Validation loss: 2.457465351289938

Epoch: 5| Step: 7
Training loss: 2.3027708197921757
Validation loss: 2.457140424331541

Epoch: 5| Step: 8
Training loss: 2.5749376419072156
Validation loss: 2.460039388675968

Epoch: 5| Step: 9
Training loss: 2.634101982042559
Validation loss: 2.4564953387864743

Epoch: 5| Step: 10
Training loss: 2.06300058936787
Validation loss: 2.4570052161199536

Epoch: 5| Step: 11
Training loss: 3.7526736582830234
Validation loss: 2.455204529746509

Epoch: 144| Step: 0
Training loss: 2.4409976220531515
Validation loss: 2.4507714459935848

Epoch: 5| Step: 1
Training loss: 2.70287467370761
Validation loss: 2.454610293942944

Epoch: 5| Step: 2
Training loss: 2.7091267719536702
Validation loss: 2.463372296619653

Epoch: 5| Step: 3
Training loss: 2.981002099948516
Validation loss: 2.460981661284279

Epoch: 5| Step: 4
Training loss: 2.347816906095605
Validation loss: 2.4579646971008784

Epoch: 5| Step: 5
Training loss: 2.444999504167315
Validation loss: 2.450917033895919

Epoch: 5| Step: 6
Training loss: 2.482755697091526
Validation loss: 2.4483450954311397

Epoch: 5| Step: 7
Training loss: 1.928354026509758
Validation loss: 2.4556678260000298

Epoch: 5| Step: 8
Training loss: 2.587697792786239
Validation loss: 2.4493112825459455

Epoch: 5| Step: 9
Training loss: 2.4520735704545804
Validation loss: 2.451122782951443

Epoch: 5| Step: 10
Training loss: 2.696667316878358
Validation loss: 2.4451360019285313

Epoch: 5| Step: 11
Training loss: 1.754381077303687
Validation loss: 2.4457689616902467

Epoch: 145| Step: 0
Training loss: 3.016314808117263
Validation loss: 2.4618587807977086

Epoch: 5| Step: 1
Training loss: 2.6500744107433674
Validation loss: 2.4632492873157474

Epoch: 5| Step: 2
Training loss: 2.366608602411488
Validation loss: 2.464102894176363

Epoch: 5| Step: 3
Training loss: 2.6215448801410495
Validation loss: 2.4733412779524504

Epoch: 5| Step: 4
Training loss: 2.199298647145757
Validation loss: 2.466655144202753

Epoch: 5| Step: 5
Training loss: 1.9914396191177368
Validation loss: 2.4593321433366477

Epoch: 5| Step: 6
Training loss: 2.5915074592908387
Validation loss: 2.4547308102321366

Epoch: 5| Step: 7
Training loss: 2.368935119320143
Validation loss: 2.443256352623791

Epoch: 5| Step: 8
Training loss: 2.5109414993757526
Validation loss: 2.452393157386743

Epoch: 5| Step: 9
Training loss: 2.745490277808237
Validation loss: 2.4609222007962144

Epoch: 5| Step: 10
Training loss: 2.543822723773768
Validation loss: 2.4558883742136257

Epoch: 5| Step: 11
Training loss: 3.148348293507865
Validation loss: 2.455383979725013

Epoch: 146| Step: 0
Training loss: 3.14820879917271
Validation loss: 2.459066994076732

Epoch: 5| Step: 1
Training loss: 2.371056143196929
Validation loss: 2.4580819491720822

Epoch: 5| Step: 2
Training loss: 1.8091506265461896
Validation loss: 2.450218373901287

Epoch: 5| Step: 3
Training loss: 2.8926849448540963
Validation loss: 2.4532328174976343

Epoch: 5| Step: 4
Training loss: 2.563469866062682
Validation loss: 2.4566237208206925

Epoch: 5| Step: 5
Training loss: 2.5840355831270867
Validation loss: 2.459567303149432

Epoch: 5| Step: 6
Training loss: 2.6063246572216503
Validation loss: 2.459283844334153

Epoch: 5| Step: 7
Training loss: 2.2354062774881327
Validation loss: 2.456617428651942

Epoch: 5| Step: 8
Training loss: 2.32312047318045
Validation loss: 2.443358350428817

Epoch: 5| Step: 9
Training loss: 2.550981452410902
Validation loss: 2.448551932888168

Epoch: 5| Step: 10
Training loss: 2.1808420493865572
Validation loss: 2.455937613698265

Epoch: 5| Step: 11
Training loss: 2.4295638565053017
Validation loss: 2.4581100893219054

Epoch: 147| Step: 0
Training loss: 2.6080082951864303
Validation loss: 2.4525554749089364

Epoch: 5| Step: 1
Training loss: 2.78496611857051
Validation loss: 2.4497558556442693

Epoch: 5| Step: 2
Training loss: 2.274251366148479
Validation loss: 2.4511351442054656

Epoch: 5| Step: 3
Training loss: 2.6370545576091384
Validation loss: 2.4503435049782136

Epoch: 5| Step: 4
Training loss: 1.9192033511703002
Validation loss: 2.4502742709506298

Epoch: 5| Step: 5
Training loss: 2.6461417451464113
Validation loss: 2.4560094304651856

Epoch: 5| Step: 6
Training loss: 2.433619417939977
Validation loss: 2.4533188777692936

Epoch: 5| Step: 7
Training loss: 2.9157767073402363
Validation loss: 2.449483493122744

Epoch: 5| Step: 8
Training loss: 2.2232152574441857
Validation loss: 2.446447829971911

Epoch: 5| Step: 9
Training loss: 2.687878959019517
Validation loss: 2.4538649558683945

Epoch: 5| Step: 10
Training loss: 1.9031650407459424
Validation loss: 2.4584105622289147

Epoch: 5| Step: 11
Training loss: 3.334423713363996
Validation loss: 2.4525014890795225

Epoch: 148| Step: 0
Training loss: 2.3615671041639876
Validation loss: 2.4579710626109335

Epoch: 5| Step: 1
Training loss: 2.3319133684022555
Validation loss: 2.4522578494690133

Epoch: 5| Step: 2
Training loss: 2.183322077520734
Validation loss: 2.4545705023163467

Epoch: 5| Step: 3
Training loss: 2.923784091289161
Validation loss: 2.4549363043991224

Epoch: 5| Step: 4
Training loss: 3.07758307164343
Validation loss: 2.4500245852923626

Epoch: 5| Step: 5
Training loss: 2.0141030413303564
Validation loss: 2.4552030670655496

Epoch: 5| Step: 6
Training loss: 2.7040439873734736
Validation loss: 2.4491312639023337

Epoch: 5| Step: 7
Training loss: 2.566194894294693
Validation loss: 2.4533893033816034

Epoch: 5| Step: 8
Training loss: 2.4813903538286213
Validation loss: 2.4448028740275864

Epoch: 5| Step: 9
Training loss: 2.4431204919195264
Validation loss: 2.4386757883967953

Epoch: 5| Step: 10
Training loss: 2.4186389592037143
Validation loss: 2.453721919398667

Epoch: 5| Step: 11
Training loss: 1.2694008628205198
Validation loss: 2.4555718151393773

Epoch: 149| Step: 0
Training loss: 2.0264576645840195
Validation loss: 2.449919888750148

Epoch: 5| Step: 1
Training loss: 2.620304358326974
Validation loss: 2.4547515303922998

Epoch: 5| Step: 2
Training loss: 2.372629789896343
Validation loss: 2.4462018533619854

Epoch: 5| Step: 3
Training loss: 2.493104006816834
Validation loss: 2.444181162269529

Epoch: 5| Step: 4
Training loss: 2.652134658145035
Validation loss: 2.4545393509152067

Epoch: 5| Step: 5
Training loss: 2.497107358201932
Validation loss: 2.4459299073873746

Epoch: 5| Step: 6
Training loss: 1.9913397088350537
Validation loss: 2.457341561182153

Epoch: 5| Step: 7
Training loss: 2.7583707509187243
Validation loss: 2.462513192136641

Epoch: 5| Step: 8
Training loss: 1.8500709803599416
Validation loss: 2.4590058996153834

Epoch: 5| Step: 9
Training loss: 3.0891595557965976
Validation loss: 2.4611567404640637

Epoch: 5| Step: 10
Training loss: 2.7762114930348583
Validation loss: 2.458008000431046

Epoch: 5| Step: 11
Training loss: 2.524967450224819
Validation loss: 2.462014393601176

Epoch: 150| Step: 0
Training loss: 2.7899508731030753
Validation loss: 2.4557093555113836

Epoch: 5| Step: 1
Training loss: 2.170355066001485
Validation loss: 2.455654261806224

Epoch: 5| Step: 2
Training loss: 2.142478196379242
Validation loss: 2.4598977127622628

Epoch: 5| Step: 3
Training loss: 2.51419111815454
Validation loss: 2.45578654691798

Epoch: 5| Step: 4
Training loss: 2.8029887120553427
Validation loss: 2.4534327886945384

Epoch: 5| Step: 5
Training loss: 2.485607105600289
Validation loss: 2.4498370544587345

Epoch: 5| Step: 6
Training loss: 2.3263340148021077
Validation loss: 2.4532923914660802

Epoch: 5| Step: 7
Training loss: 2.665798304157632
Validation loss: 2.4523024708770715

Epoch: 5| Step: 8
Training loss: 1.888865132587614
Validation loss: 2.4470189633166637

Epoch: 5| Step: 9
Training loss: 2.9085871005539423
Validation loss: 2.450914618175238

Epoch: 5| Step: 10
Training loss: 2.464147405909256
Validation loss: 2.4503940599481204

Epoch: 5| Step: 11
Training loss: 3.187620871252988
Validation loss: 2.456254623091653

Epoch: 151| Step: 0
Training loss: 2.933041374531207
Validation loss: 2.4616751861995194

Epoch: 5| Step: 1
Training loss: 2.027373267750853
Validation loss: 2.456632285584905

Epoch: 5| Step: 2
Training loss: 2.196703052981562
Validation loss: 2.4564360163934533

Epoch: 5| Step: 3
Training loss: 2.7497522069091707
Validation loss: 2.4590008012719364

Epoch: 5| Step: 4
Training loss: 2.6295443663059457
Validation loss: 2.45982408313247

Epoch: 5| Step: 5
Training loss: 2.6051896387583846
Validation loss: 2.4609735597259426

Epoch: 5| Step: 6
Training loss: 2.521056667134356
Validation loss: 2.461566138331619

Epoch: 5| Step: 7
Training loss: 2.2515825428226153
Validation loss: 2.454572175827876

Epoch: 5| Step: 8
Training loss: 2.8094368254209763
Validation loss: 2.470092002265897

Epoch: 5| Step: 9
Training loss: 1.6627591899089624
Validation loss: 2.465688211156962

Epoch: 5| Step: 10
Training loss: 2.757711262776434
Validation loss: 2.4524002786492987

Epoch: 5| Step: 11
Training loss: 3.015723666617755
Validation loss: 2.460506284364508

Epoch: 152| Step: 0
Training loss: 2.386067552900461
Validation loss: 2.4621529821978196

Epoch: 5| Step: 1
Training loss: 2.7292842888176767
Validation loss: 2.465090070810859

Epoch: 5| Step: 2
Training loss: 2.5587015609740624
Validation loss: 2.464695812688705

Epoch: 5| Step: 3
Training loss: 2.246014986730426
Validation loss: 2.4527846098181025

Epoch: 5| Step: 4
Training loss: 2.1825727283293497
Validation loss: 2.4544752741905036

Epoch: 5| Step: 5
Training loss: 2.845521647492793
Validation loss: 2.455993505971008

Epoch: 5| Step: 6
Training loss: 2.5214327475228764
Validation loss: 2.455092831418124

Epoch: 5| Step: 7
Training loss: 3.0755632458421016
Validation loss: 2.456463746727128

Epoch: 5| Step: 8
Training loss: 2.3267632924904516
Validation loss: 2.466370208157894

Epoch: 5| Step: 9
Training loss: 2.358877167379364
Validation loss: 2.4593720073754453

Epoch: 5| Step: 10
Training loss: 2.1634055562397547
Validation loss: 2.4640424507049516

Epoch: 5| Step: 11
Training loss: 0.8435027855294028
Validation loss: 2.442001111611434

Epoch: 153| Step: 0
Training loss: 2.4738614247398574
Validation loss: 2.4572155534104327

Epoch: 5| Step: 1
Training loss: 2.5537490287551114
Validation loss: 2.4542594359976397

Epoch: 5| Step: 2
Training loss: 2.934353543366624
Validation loss: 2.4495190685238852

Epoch: 5| Step: 3
Training loss: 1.8490089158853615
Validation loss: 2.4515135143241307

Epoch: 5| Step: 4
Training loss: 2.1220029003040795
Validation loss: 2.4438933701992127

Epoch: 5| Step: 5
Training loss: 2.5860867644503696
Validation loss: 2.4451667205939334

Epoch: 5| Step: 6
Training loss: 2.7625959802584923
Validation loss: 2.442467432947045

Epoch: 5| Step: 7
Training loss: 2.471400130192524
Validation loss: 2.4508875870712097

Epoch: 5| Step: 8
Training loss: 2.548584908175454
Validation loss: 2.4453862293897313

Epoch: 5| Step: 9
Training loss: 2.6431682911645034
Validation loss: 2.4535597478742295

Epoch: 5| Step: 10
Training loss: 2.376270857653716
Validation loss: 2.45836353822245

Epoch: 5| Step: 11
Training loss: 2.189066734554925
Validation loss: 2.4538253140919486

Epoch: 154| Step: 0
Training loss: 2.1592242970855327
Validation loss: 2.4523997398969386

Epoch: 5| Step: 1
Training loss: 2.488431869092312
Validation loss: 2.4519920405590065

Epoch: 5| Step: 2
Training loss: 2.8451911711865945
Validation loss: 2.453351417346142

Epoch: 5| Step: 3
Training loss: 2.792081764067806
Validation loss: 2.4602694901568247

Epoch: 5| Step: 4
Training loss: 2.1399626438053363
Validation loss: 2.462940119771132

Epoch: 5| Step: 5
Training loss: 2.573828984623851
Validation loss: 2.452822838739321

Epoch: 5| Step: 6
Training loss: 2.333975998612061
Validation loss: 2.457235820039167

Epoch: 5| Step: 7
Training loss: 2.725216421229973
Validation loss: 2.454265414444187

Epoch: 5| Step: 8
Training loss: 2.3197435908195625
Validation loss: 2.4451494741483053

Epoch: 5| Step: 9
Training loss: 2.076159013365618
Validation loss: 2.4538513695637127

Epoch: 5| Step: 10
Training loss: 2.62634796773267
Validation loss: 2.4608652941894005

Epoch: 5| Step: 11
Training loss: 1.9268459758125467
Validation loss: 2.460653767048191

Epoch: 155| Step: 0
Training loss: 2.108916508331074
Validation loss: 2.4674555648376515

Epoch: 5| Step: 1
Training loss: 2.183436952806259
Validation loss: 2.471762344423154

Epoch: 5| Step: 2
Training loss: 2.857946820906213
Validation loss: 2.4655813654079273

Epoch: 5| Step: 3
Training loss: 2.3591981531016306
Validation loss: 2.46375895033252

Epoch: 5| Step: 4
Training loss: 2.1818379831138026
Validation loss: 2.4616944536523206

Epoch: 5| Step: 5
Training loss: 2.1617282438466083
Validation loss: 2.465201910549946

Epoch: 5| Step: 6
Training loss: 2.6700367097081203
Validation loss: 2.4549129271685377

Epoch: 5| Step: 7
Training loss: 3.4359901580314323
Validation loss: 2.4627326311645135

Epoch: 5| Step: 8
Training loss: 2.5682160428161267
Validation loss: 2.4599551465434644

Epoch: 5| Step: 9
Training loss: 2.5185943517560565
Validation loss: 2.4506019405897357

Epoch: 5| Step: 10
Training loss: 2.021183599680079
Validation loss: 2.4640908479319776

Epoch: 5| Step: 11
Training loss: 1.9435159131363597
Validation loss: 2.4598407380309903

Epoch: 156| Step: 0
Training loss: 3.309644079751076
Validation loss: 2.4579795297241573

Epoch: 5| Step: 1
Training loss: 2.430829629129127
Validation loss: 2.4537463525015277

Epoch: 5| Step: 2
Training loss: 2.0710825513654236
Validation loss: 2.4567997292188775

Epoch: 5| Step: 3
Training loss: 2.079651694845798
Validation loss: 2.4608117934318914

Epoch: 5| Step: 4
Training loss: 2.674034004839749
Validation loss: 2.456216880342091

Epoch: 5| Step: 5
Training loss: 2.9226998373583344
Validation loss: 2.4696293242692247

Epoch: 5| Step: 6
Training loss: 2.470677552825913
Validation loss: 2.4765743612332307

Epoch: 5| Step: 7
Training loss: 2.1905792362150973
Validation loss: 2.474411103159531

Epoch: 5| Step: 8
Training loss: 2.2636361699419334
Validation loss: 2.4740095247025193

Epoch: 5| Step: 9
Training loss: 2.581000002376611
Validation loss: 2.4634439692302825

Epoch: 5| Step: 10
Training loss: 2.316190301050661
Validation loss: 2.461951342649352

Epoch: 5| Step: 11
Training loss: 1.6766897019964684
Validation loss: 2.455823519617758

Epoch: 157| Step: 0
Training loss: 2.332259123897299
Validation loss: 2.456251108494477

Epoch: 5| Step: 1
Training loss: 2.010258472392039
Validation loss: 2.4580685639985287

Epoch: 5| Step: 2
Training loss: 2.414454357354887
Validation loss: 2.460773133536135

Epoch: 5| Step: 3
Training loss: 2.4625746352605264
Validation loss: 2.4639950443275787

Epoch: 5| Step: 4
Training loss: 1.6111292490906466
Validation loss: 2.460261103605494

Epoch: 5| Step: 5
Training loss: 2.916052581082798
Validation loss: 2.4578024457987384

Epoch: 5| Step: 6
Training loss: 2.732653179290214
Validation loss: 2.4611787385119017

Epoch: 5| Step: 7
Training loss: 2.596056544553591
Validation loss: 2.461318484087012

Epoch: 5| Step: 8
Training loss: 3.045052164066285
Validation loss: 2.4679025611965963

Epoch: 5| Step: 9
Training loss: 2.066607575443419
Validation loss: 2.4648680930086724

Epoch: 5| Step: 10
Training loss: 2.7551507396964157
Validation loss: 2.4695361752708855

Epoch: 5| Step: 11
Training loss: 2.5282514731479164
Validation loss: 2.463946437581736

Epoch: 158| Step: 0
Training loss: 3.2907311925028204
Validation loss: 2.4575698052068113

Epoch: 5| Step: 1
Training loss: 2.1810239570907535
Validation loss: 2.4557323287236934

Epoch: 5| Step: 2
Training loss: 2.446170546655068
Validation loss: 2.462164509376995

Epoch: 5| Step: 3
Training loss: 2.63631697242719
Validation loss: 2.459269338694559

Epoch: 5| Step: 4
Training loss: 2.0493460147037585
Validation loss: 2.4690650867634814

Epoch: 5| Step: 5
Training loss: 2.121176702236713
Validation loss: 2.4606187200203706

Epoch: 5| Step: 6
Training loss: 2.695470302219352
Validation loss: 2.456484452270174

Epoch: 5| Step: 7
Training loss: 1.678261368820845
Validation loss: 2.4545076891600655

Epoch: 5| Step: 8
Training loss: 2.3150350748457598
Validation loss: 2.452950279023256

Epoch: 5| Step: 9
Training loss: 2.8683698747233097
Validation loss: 2.4527331199183084

Epoch: 5| Step: 10
Training loss: 2.7689081736692978
Validation loss: 2.4569364204968163

Epoch: 5| Step: 11
Training loss: 0.9860046460581917
Validation loss: 2.456738420673893

Epoch: 159| Step: 0
Training loss: 2.193758268422252
Validation loss: 2.4525100601384

Epoch: 5| Step: 1
Training loss: 2.4286086456268086
Validation loss: 2.45570571068369

Epoch: 5| Step: 2
Training loss: 2.4474095137081795
Validation loss: 2.449232714875324

Epoch: 5| Step: 3
Training loss: 2.5574089277203957
Validation loss: 2.455001307873659

Epoch: 5| Step: 4
Training loss: 2.23135855274444
Validation loss: 2.4635814088246284

Epoch: 5| Step: 5
Training loss: 2.7350719326678914
Validation loss: 2.456988323667555

Epoch: 5| Step: 6
Training loss: 2.6414155397474635
Validation loss: 2.450044159264188

Epoch: 5| Step: 7
Training loss: 2.442310965181742
Validation loss: 2.4553122397441225

Epoch: 5| Step: 8
Training loss: 2.724208482351555
Validation loss: 2.4578500180979166

Epoch: 5| Step: 9
Training loss: 2.296704240536808
Validation loss: 2.45205305454052

Epoch: 5| Step: 10
Training loss: 2.395531002263673
Validation loss: 2.4534825714367656

Epoch: 5| Step: 11
Training loss: 2.833824526526573
Validation loss: 2.454817898478034

Epoch: 160| Step: 0
Training loss: 2.084114449614756
Validation loss: 2.450184799380584

Epoch: 5| Step: 1
Training loss: 2.528618280409287
Validation loss: 2.4524271877613217

Epoch: 5| Step: 2
Training loss: 2.337185937519064
Validation loss: 2.467794885455371

Epoch: 5| Step: 3
Training loss: 2.4744970330779195
Validation loss: 2.466049528138153

Epoch: 5| Step: 4
Training loss: 2.7371790867656696
Validation loss: 2.4556115743584486

Epoch: 5| Step: 5
Training loss: 2.1822408398617235
Validation loss: 2.4589063628499432

Epoch: 5| Step: 6
Training loss: 2.50432793790325
Validation loss: 2.4536486105328588

Epoch: 5| Step: 7
Training loss: 2.6625293783796757
Validation loss: 2.4668821197785884

Epoch: 5| Step: 8
Training loss: 2.5467943986179544
Validation loss: 2.4615017279438653

Epoch: 5| Step: 9
Training loss: 2.3050936066327883
Validation loss: 2.4592557337729857

Epoch: 5| Step: 10
Training loss: 2.5854984152690728
Validation loss: 2.4586701862779954

Epoch: 5| Step: 11
Training loss: 3.0477905462892774
Validation loss: 2.453433177404694

Epoch: 161| Step: 0
Training loss: 2.5886818881724065
Validation loss: 2.4539060058075446

Epoch: 5| Step: 1
Training loss: 2.1569675965331276
Validation loss: 2.4698610501711027

Epoch: 5| Step: 2
Training loss: 3.106272313979995
Validation loss: 2.461320776586113

Epoch: 5| Step: 3
Training loss: 2.090974818956929
Validation loss: 2.4724348229231663

Epoch: 5| Step: 4
Training loss: 2.4267754966659485
Validation loss: 2.4550080007382586

Epoch: 5| Step: 5
Training loss: 2.888908412655449
Validation loss: 2.4619438656822967

Epoch: 5| Step: 6
Training loss: 2.6001498766029507
Validation loss: 2.4553403873615025

Epoch: 5| Step: 7
Training loss: 2.2204394288798373
Validation loss: 2.461121757108522

Epoch: 5| Step: 8
Training loss: 2.523113218085803
Validation loss: 2.460738845153988

Epoch: 5| Step: 9
Training loss: 2.0541424046360977
Validation loss: 2.451188619082787

Epoch: 5| Step: 10
Training loss: 2.0621469368885545
Validation loss: 2.453468266340658

Epoch: 5| Step: 11
Training loss: 3.1638150342077065
Validation loss: 2.4551853590483677

Epoch: 162| Step: 0
Training loss: 3.1209669409666048
Validation loss: 2.463307864901041

Epoch: 5| Step: 1
Training loss: 2.3247263634560325
Validation loss: 2.4666043385372176

Epoch: 5| Step: 2
Training loss: 2.3921661395932565
Validation loss: 2.46026945381651

Epoch: 5| Step: 3
Training loss: 2.5600866723289712
Validation loss: 2.4585475114422604

Epoch: 5| Step: 4
Training loss: 2.085672768928015
Validation loss: 2.4613929569270705

Epoch: 5| Step: 5
Training loss: 2.775551433589017
Validation loss: 2.4669821803749943

Epoch: 5| Step: 6
Training loss: 2.3097173083506624
Validation loss: 2.4671968934627437

Epoch: 5| Step: 7
Training loss: 2.5512325711288115
Validation loss: 2.471865080963437

Epoch: 5| Step: 8
Training loss: 2.176537319018519
Validation loss: 2.461939414999814

Epoch: 5| Step: 9
Training loss: 2.250038676459306
Validation loss: 2.464328544766413

Epoch: 5| Step: 10
Training loss: 2.592715321264867
Validation loss: 2.45562791396483

Epoch: 5| Step: 11
Training loss: 3.007436119409538
Validation loss: 2.4660038422121207

Epoch: 163| Step: 0
Training loss: 2.300707156894038
Validation loss: 2.466559113969343

Epoch: 5| Step: 1
Training loss: 2.9540689564316245
Validation loss: 2.4845746517930674

Epoch: 5| Step: 2
Training loss: 2.767186817619287
Validation loss: 2.4725556757411637

Epoch: 5| Step: 3
Training loss: 2.433586010377189
Validation loss: 2.4764092776035134

Epoch: 5| Step: 4
Training loss: 2.2096567926551183
Validation loss: 2.4609020815929465

Epoch: 5| Step: 5
Training loss: 2.369508216310783
Validation loss: 2.4602213347309476

Epoch: 5| Step: 6
Training loss: 2.350955517268935
Validation loss: 2.453529514888257

Epoch: 5| Step: 7
Training loss: 2.5024896622633843
Validation loss: 2.4548015049183607

Epoch: 5| Step: 8
Training loss: 2.5773167123385248
Validation loss: 2.4605310942107503

Epoch: 5| Step: 9
Training loss: 2.4618935317469997
Validation loss: 2.4610616723275482

Epoch: 5| Step: 10
Training loss: 2.32168610370475
Validation loss: 2.4508449300936737

Epoch: 5| Step: 11
Training loss: 2.3961945524053956
Validation loss: 2.4533000203281863

Epoch: 164| Step: 0
Training loss: 2.871737079816121
Validation loss: 2.4580276684469933

Epoch: 5| Step: 1
Training loss: 1.8795639441416159
Validation loss: 2.4540446373879505

Epoch: 5| Step: 2
Training loss: 2.535988034951176
Validation loss: 2.4480467917303983

Epoch: 5| Step: 3
Training loss: 2.6787389739179446
Validation loss: 2.454043226640406

Epoch: 5| Step: 4
Training loss: 2.0500232276531007
Validation loss: 2.463506149267155

Epoch: 5| Step: 5
Training loss: 2.3604668118390695
Validation loss: 2.4506224119001994

Epoch: 5| Step: 6
Training loss: 2.3422596579971566
Validation loss: 2.4608237709529637

Epoch: 5| Step: 7
Training loss: 2.668986761592708
Validation loss: 2.468864027842471

Epoch: 5| Step: 8
Training loss: 2.4296264640771117
Validation loss: 2.4845522931254194

Epoch: 5| Step: 9
Training loss: 2.5598589615415572
Validation loss: 2.479299470940098

Epoch: 5| Step: 10
Training loss: 2.7259157829289844
Validation loss: 2.4829768159083296

Epoch: 5| Step: 11
Training loss: 3.4587138935571633
Validation loss: 2.4585902368071726

Epoch: 165| Step: 0
Training loss: 1.9051051219461048
Validation loss: 2.4579204694860017

Epoch: 5| Step: 1
Training loss: 3.140694233145481
Validation loss: 2.4583748407146437

Epoch: 5| Step: 2
Training loss: 2.7899131012102667
Validation loss: 2.4679121213226307

Epoch: 5| Step: 3
Training loss: 2.508919064727288
Validation loss: 2.468935661738649

Epoch: 5| Step: 4
Training loss: 2.1683919957421183
Validation loss: 2.478347748586431

Epoch: 5| Step: 5
Training loss: 2.5690613458183282
Validation loss: 2.480485486552327

Epoch: 5| Step: 6
Training loss: 3.2798139063449785
Validation loss: 2.4812044669584883

Epoch: 5| Step: 7
Training loss: 2.007954514524037
Validation loss: 2.4799911639994447

Epoch: 5| Step: 8
Training loss: 2.4779716838730543
Validation loss: 2.4837412075711987

Epoch: 5| Step: 9
Training loss: 2.509913814934377
Validation loss: 2.481081542967549

Epoch: 5| Step: 10
Training loss: 2.251764982756224
Validation loss: 2.476438557344295

Epoch: 5| Step: 11
Training loss: 3.3510121424952177
Validation loss: 2.4790581684787187

Epoch: 166| Step: 0
Training loss: 2.534731883781054
Validation loss: 2.4684673944313005

Epoch: 5| Step: 1
Training loss: 2.2465497159468124
Validation loss: 2.464962403776105

Epoch: 5| Step: 2
Training loss: 2.477468042254153
Validation loss: 2.459955998630672

Epoch: 5| Step: 3
Training loss: 2.136483299770385
Validation loss: 2.453126271565426

Epoch: 5| Step: 4
Training loss: 1.9399184238350446
Validation loss: 2.4559316878616686

Epoch: 5| Step: 5
Training loss: 2.4568817141685457
Validation loss: 2.447795736423562

Epoch: 5| Step: 6
Training loss: 2.6150766543063226
Validation loss: 2.4551155251360512

Epoch: 5| Step: 7
Training loss: 3.049734954574226
Validation loss: 2.451663458621297

Epoch: 5| Step: 8
Training loss: 2.840814101971984
Validation loss: 2.4551063602738807

Epoch: 5| Step: 9
Training loss: 2.5143113586276025
Validation loss: 2.4421821398929437

Epoch: 5| Step: 10
Training loss: 2.5505026041513776
Validation loss: 2.471787885279418

Epoch: 5| Step: 11
Training loss: 3.1568744910312834
Validation loss: 2.463270121334613

Epoch: 167| Step: 0
Training loss: 1.510937392699308
Validation loss: 2.4696551164655696

Epoch: 5| Step: 1
Training loss: 3.022257098841292
Validation loss: 2.479356711714204

Epoch: 5| Step: 2
Training loss: 2.0655231860486323
Validation loss: 2.4803101656624293

Epoch: 5| Step: 3
Training loss: 2.4359376252806255
Validation loss: 2.472279299447418

Epoch: 5| Step: 4
Training loss: 2.6154719409345453
Validation loss: 2.4520928465065284

Epoch: 5| Step: 5
Training loss: 2.569740765184349
Validation loss: 2.4383196165974934

Epoch: 5| Step: 6
Training loss: 2.725101986997656
Validation loss: 2.432378478750752

Epoch: 5| Step: 7
Training loss: 2.301035531828614
Validation loss: 2.4370811991085213

Epoch: 5| Step: 8
Training loss: 3.1757647336786077
Validation loss: 2.440901654804449

Epoch: 5| Step: 9
Training loss: 2.376180556164018
Validation loss: 2.4444265863158807

Epoch: 5| Step: 10
Training loss: 2.521339985608558
Validation loss: 2.447084806337784

Epoch: 5| Step: 11
Training loss: 2.908402660895295
Validation loss: 2.4416853518850594

Epoch: 168| Step: 0
Training loss: 2.3199171763467423
Validation loss: 2.438456229584842

Epoch: 5| Step: 1
Training loss: 2.16932385682465
Validation loss: 2.4492145844525006

Epoch: 5| Step: 2
Training loss: 2.507048398366679
Validation loss: 2.4549416296986903

Epoch: 5| Step: 3
Training loss: 2.4658852868914867
Validation loss: 2.454469883121459

Epoch: 5| Step: 4
Training loss: 2.476512824201122
Validation loss: 2.4597717874720475

Epoch: 5| Step: 5
Training loss: 2.810358631014592
Validation loss: 2.4666073107880875

Epoch: 5| Step: 6
Training loss: 2.729720071686708
Validation loss: 2.4603450889630434

Epoch: 5| Step: 7
Training loss: 2.6218962712840197
Validation loss: 2.4618734769743016

Epoch: 5| Step: 8
Training loss: 2.3562796795744014
Validation loss: 2.4588466824901998

Epoch: 5| Step: 9
Training loss: 2.8149590656292345
Validation loss: 2.4594659149479425

Epoch: 5| Step: 10
Training loss: 2.4423092080197635
Validation loss: 2.4580804498099496

Epoch: 5| Step: 11
Training loss: 2.1615859641268163
Validation loss: 2.454039121906927

Epoch: 169| Step: 0
Training loss: 2.976745279462331
Validation loss: 2.4536820101245502

Epoch: 5| Step: 1
Training loss: 2.4435101286489105
Validation loss: 2.461906262609485

Epoch: 5| Step: 2
Training loss: 2.7311273961952134
Validation loss: 2.462962041389667

Epoch: 5| Step: 3
Training loss: 2.996035181142008
Validation loss: 2.4557260706785287

Epoch: 5| Step: 4
Training loss: 2.843696342213555
Validation loss: 2.4663671872873305

Epoch: 5| Step: 5
Training loss: 2.0126606041933943
Validation loss: 2.463200347246123

Epoch: 5| Step: 6
Training loss: 1.9837248330301616
Validation loss: 2.4632743195737614

Epoch: 5| Step: 7
Training loss: 2.276505854313606
Validation loss: 2.445356908929186

Epoch: 5| Step: 8
Training loss: 2.2932096546482876
Validation loss: 2.465655886767266

Epoch: 5| Step: 9
Training loss: 2.59864951052743
Validation loss: 2.4428833788285127

Epoch: 5| Step: 10
Training loss: 2.321388996751096
Validation loss: 2.45994003103271

Epoch: 5| Step: 11
Training loss: 1.881655895764339
Validation loss: 2.451507225248232

Epoch: 170| Step: 0
Training loss: 2.735984720795337
Validation loss: 2.4546777868695866

Epoch: 5| Step: 1
Training loss: 2.3040291573282237
Validation loss: 2.4508464176689535

Epoch: 5| Step: 2
Training loss: 2.746847252819542
Validation loss: 2.4452385165039114

Epoch: 5| Step: 3
Training loss: 2.381236170931331
Validation loss: 2.453188338545299

Epoch: 5| Step: 4
Training loss: 2.3042385892582407
Validation loss: 2.4507446727347806

Epoch: 5| Step: 5
Training loss: 1.8181461000185253
Validation loss: 2.4575086088472795

Epoch: 5| Step: 6
Training loss: 2.466138593320011
Validation loss: 2.4459997395624216

Epoch: 5| Step: 7
Training loss: 2.933128187924434
Validation loss: 2.449843583012001

Epoch: 5| Step: 8
Training loss: 2.2518424861359514
Validation loss: 2.458977317244441

Epoch: 5| Step: 9
Training loss: 2.512379513408946
Validation loss: 2.4394040618189616

Epoch: 5| Step: 10
Training loss: 2.688505738609621
Validation loss: 2.447893728324608

Epoch: 5| Step: 11
Training loss: 2.237565010873866
Validation loss: 2.4464468797854533

Epoch: 171| Step: 0
Training loss: 2.7327389427479942
Validation loss: 2.4496844070583093

Epoch: 5| Step: 1
Training loss: 2.2027158966074114
Validation loss: 2.440727676693531

Epoch: 5| Step: 2
Training loss: 2.7153200458988542
Validation loss: 2.4413099712461177

Epoch: 5| Step: 3
Training loss: 2.4411306485066735
Validation loss: 2.4399935895087763

Epoch: 5| Step: 4
Training loss: 2.4720286556669357
Validation loss: 2.448080399631006

Epoch: 5| Step: 5
Training loss: 2.701679791562367
Validation loss: 2.4479837503101676

Epoch: 5| Step: 6
Training loss: 2.484151002394531
Validation loss: 2.4488204153522397

Epoch: 5| Step: 7
Training loss: 2.4351190529296343
Validation loss: 2.453222422679947

Epoch: 5| Step: 8
Training loss: 2.766357324916847
Validation loss: 2.450304795463783

Epoch: 5| Step: 9
Training loss: 2.1502061257136815
Validation loss: 2.4481064411758706

Epoch: 5| Step: 10
Training loss: 2.215417104848613
Validation loss: 2.4469195803969512

Epoch: 5| Step: 11
Training loss: 1.9591826227345048
Validation loss: 2.441206498175974

Epoch: 172| Step: 0
Training loss: 2.700709327488249
Validation loss: 2.443693333852555

Epoch: 5| Step: 1
Training loss: 2.3098866929508124
Validation loss: 2.4461121394277288

Epoch: 5| Step: 2
Training loss: 2.420982245517627
Validation loss: 2.457012950705757

Epoch: 5| Step: 3
Training loss: 2.8150745052688824
Validation loss: 2.4575579492638355

Epoch: 5| Step: 4
Training loss: 2.041090618015209
Validation loss: 2.4445466699923593

Epoch: 5| Step: 5
Training loss: 2.98709350118788
Validation loss: 2.455350655881561

Epoch: 5| Step: 6
Training loss: 2.3686250155446547
Validation loss: 2.461395039486569

Epoch: 5| Step: 7
Training loss: 2.0815297394130092
Validation loss: 2.45132732734311

Epoch: 5| Step: 8
Training loss: 2.726619861950329
Validation loss: 2.449374950889463

Epoch: 5| Step: 9
Training loss: 2.5346463811899764
Validation loss: 2.449760401454052

Epoch: 5| Step: 10
Training loss: 2.163327419329741
Validation loss: 2.455789730475409

Epoch: 5| Step: 11
Training loss: 1.8929805741076622
Validation loss: 2.4540707492272777

Epoch: 173| Step: 0
Training loss: 1.9803540198446326
Validation loss: 2.4672727309603064

Epoch: 5| Step: 1
Training loss: 2.8132000369845014
Validation loss: 2.4562363989002898

Epoch: 5| Step: 2
Training loss: 2.4085376318457916
Validation loss: 2.4649961074839637

Epoch: 5| Step: 3
Training loss: 2.1389543460006113
Validation loss: 2.4544513016508493

Epoch: 5| Step: 4
Training loss: 2.5003400571334597
Validation loss: 2.4591285435048276

Epoch: 5| Step: 5
Training loss: 2.243490339040306
Validation loss: 2.463602352940641

Epoch: 5| Step: 6
Training loss: 2.8151105844787407
Validation loss: 2.4602527735553377

Epoch: 5| Step: 7
Training loss: 2.732559560561153
Validation loss: 2.465136212924385

Epoch: 5| Step: 8
Training loss: 2.640527034951233
Validation loss: 2.4553262589729323

Epoch: 5| Step: 9
Training loss: 2.4216229707574217
Validation loss: 2.47583517391231

Epoch: 5| Step: 10
Training loss: 2.4809610193735168
Validation loss: 2.4694129399801543

Epoch: 5| Step: 11
Training loss: 2.2955386887175147
Validation loss: 2.473098610856178

Epoch: 174| Step: 0
Training loss: 1.893132462233366
Validation loss: 2.471952837487316

Epoch: 5| Step: 1
Training loss: 2.0999815712983008
Validation loss: 2.4914170312912356

Epoch: 5| Step: 2
Training loss: 2.0713486867449618
Validation loss: 2.4952747233028836

Epoch: 5| Step: 3
Training loss: 3.030130081154243
Validation loss: 2.5065545267294476

Epoch: 5| Step: 4
Training loss: 2.4573934557958226
Validation loss: 2.488172084583553

Epoch: 5| Step: 5
Training loss: 2.8444717665029002
Validation loss: 2.467084354936667

Epoch: 5| Step: 6
Training loss: 2.8466639418518223
Validation loss: 2.4685262747686165

Epoch: 5| Step: 7
Training loss: 2.5460860077563803
Validation loss: 2.449808243461517

Epoch: 5| Step: 8
Training loss: 2.779437728390139
Validation loss: 2.4710761712142797

Epoch: 5| Step: 9
Training loss: 2.3187955785009353
Validation loss: 2.4610068377056615

Epoch: 5| Step: 10
Training loss: 2.2976627166874954
Validation loss: 2.4635107483378693

Epoch: 5| Step: 11
Training loss: 1.4349866539470761
Validation loss: 2.4616242595920665

Epoch: 175| Step: 0
Training loss: 2.5354415662468046
Validation loss: 2.472476978844111

Epoch: 5| Step: 1
Training loss: 2.1629592892875906
Validation loss: 2.4704850775355447

Epoch: 5| Step: 2
Training loss: 2.563441964052232
Validation loss: 2.4920473009493858

Epoch: 5| Step: 3
Training loss: 2.6189594703967005
Validation loss: 2.496324746393421

Epoch: 5| Step: 4
Training loss: 2.5147877123142206
Validation loss: 2.502980934597777

Epoch: 5| Step: 5
Training loss: 2.236456801531379
Validation loss: 2.512113201043734

Epoch: 5| Step: 6
Training loss: 2.7477361724397307
Validation loss: 2.5196053940068133

Epoch: 5| Step: 7
Training loss: 3.236597302050734
Validation loss: 2.5229467341875487

Epoch: 5| Step: 8
Training loss: 2.3506514599950696
Validation loss: 2.51438572372361

Epoch: 5| Step: 9
Training loss: 2.065084745132179
Validation loss: 2.485930205949256

Epoch: 5| Step: 10
Training loss: 2.4022098659021545
Validation loss: 2.477152067299742

Epoch: 5| Step: 11
Training loss: 2.9497638931186483
Validation loss: 2.468031682162749

Epoch: 176| Step: 0
Training loss: 2.4229607886126217
Validation loss: 2.4654340566133897

Epoch: 5| Step: 1
Training loss: 2.5733430846265075
Validation loss: 2.463325375396545

Epoch: 5| Step: 2
Training loss: 2.1829225876940175
Validation loss: 2.463940559229132

Epoch: 5| Step: 3
Training loss: 2.1169522425725065
Validation loss: 2.4673661687321755

Epoch: 5| Step: 4
Training loss: 2.6758420171589834
Validation loss: 2.467412701089563

Epoch: 5| Step: 5
Training loss: 2.6870888683869176
Validation loss: 2.463976921735424

Epoch: 5| Step: 6
Training loss: 2.5693862312756233
Validation loss: 2.4614624371832754

Epoch: 5| Step: 7
Training loss: 2.555499119987777
Validation loss: 2.460738344560659

Epoch: 5| Step: 8
Training loss: 2.133793084950442
Validation loss: 2.4476014495699023

Epoch: 5| Step: 9
Training loss: 2.3482983007947227
Validation loss: 2.4495083700022646

Epoch: 5| Step: 10
Training loss: 2.6810101950941423
Validation loss: 2.4466562448594917

Epoch: 5| Step: 11
Training loss: 3.8887054733135438
Validation loss: 2.4458894546629364

Epoch: 177| Step: 0
Training loss: 2.648772812043448
Validation loss: 2.4491471559483555

Epoch: 5| Step: 1
Training loss: 2.154061353852789
Validation loss: 2.463474088606236

Epoch: 5| Step: 2
Training loss: 1.8191611123564513
Validation loss: 2.475627381669443

Epoch: 5| Step: 3
Training loss: 2.741505595135932
Validation loss: 2.469376782231841

Epoch: 5| Step: 4
Training loss: 2.196133063150043
Validation loss: 2.4784330089238047

Epoch: 5| Step: 5
Training loss: 2.228831637390871
Validation loss: 2.469518779211065

Epoch: 5| Step: 6
Training loss: 3.3097496850827364
Validation loss: 2.4619863626369427

Epoch: 5| Step: 7
Training loss: 2.4033476926010438
Validation loss: 2.4535555836234075

Epoch: 5| Step: 8
Training loss: 2.645796908230496
Validation loss: 2.4625065801826254

Epoch: 5| Step: 9
Training loss: 3.060289324627207
Validation loss: 2.4574228367894304

Epoch: 5| Step: 10
Training loss: 2.070848388412471
Validation loss: 2.4717877848044973

Epoch: 5| Step: 11
Training loss: 1.3451137276255052
Validation loss: 2.4674999033635774

Epoch: 178| Step: 0
Training loss: 2.5849155584891053
Validation loss: 2.4730334122333058

Epoch: 5| Step: 1
Training loss: 2.6627793787846126
Validation loss: 2.461144885654735

Epoch: 5| Step: 2
Training loss: 2.4779875593327265
Validation loss: 2.4727463186049774

Epoch: 5| Step: 3
Training loss: 2.152718125477367
Validation loss: 2.472907583390876

Epoch: 5| Step: 4
Training loss: 2.5758495114658766
Validation loss: 2.4686396368926475

Epoch: 5| Step: 5
Training loss: 2.944817053612677
Validation loss: 2.4755127905397902

Epoch: 5| Step: 6
Training loss: 2.3231892333183177
Validation loss: 2.4778309811618806

Epoch: 5| Step: 7
Training loss: 2.4329271704783535
Validation loss: 2.467001879528099

Epoch: 5| Step: 8
Training loss: 2.3221937574297926
Validation loss: 2.478920344663204

Epoch: 5| Step: 9
Training loss: 2.488455055191181
Validation loss: 2.4816453280875455

Epoch: 5| Step: 10
Training loss: 2.153943030175123
Validation loss: 2.4840853700214094

Epoch: 5| Step: 11
Training loss: 2.165685602746587
Validation loss: 2.475035905898664

Epoch: 179| Step: 0
Training loss: 2.7635416923568004
Validation loss: 2.4766853494589824

Epoch: 5| Step: 1
Training loss: 2.1348986361738724
Validation loss: 2.481955119466236

Epoch: 5| Step: 2
Training loss: 2.190300592843758
Validation loss: 2.4740610978048387

Epoch: 5| Step: 3
Training loss: 2.3336817844516724
Validation loss: 2.475651851380988

Epoch: 5| Step: 4
Training loss: 3.0933287362634547
Validation loss: 2.4686311339078846

Epoch: 5| Step: 5
Training loss: 2.747223145660804
Validation loss: 2.472176634368788

Epoch: 5| Step: 6
Training loss: 2.262953241799917
Validation loss: 2.4774920928115485

Epoch: 5| Step: 7
Training loss: 2.41161016943327
Validation loss: 2.4719228595998617

Epoch: 5| Step: 8
Training loss: 1.9545419664734893
Validation loss: 2.473882462526041

Epoch: 5| Step: 9
Training loss: 2.6570334681541206
Validation loss: 2.4646266613943526

Epoch: 5| Step: 10
Training loss: 2.191400701342407
Validation loss: 2.4673319598943277

Epoch: 5| Step: 11
Training loss: 2.5581246215313023
Validation loss: 2.468313834535991

Epoch: 180| Step: 0
Training loss: 2.5843804503525223
Validation loss: 2.4768740942330334

Epoch: 5| Step: 1
Training loss: 2.379025511108976
Validation loss: 2.4899708407710555

Epoch: 5| Step: 2
Training loss: 2.2367276696851053
Validation loss: 2.489832196639257

Epoch: 5| Step: 3
Training loss: 2.218767515301409
Validation loss: 2.4788999467447597

Epoch: 5| Step: 4
Training loss: 1.9990858134427487
Validation loss: 2.4773111064343736

Epoch: 5| Step: 5
Training loss: 2.3123070919921087
Validation loss: 2.471926223314169

Epoch: 5| Step: 6
Training loss: 2.9954936832876498
Validation loss: 2.474726412483617

Epoch: 5| Step: 7
Training loss: 2.7466838956804853
Validation loss: 2.4729867305541013

Epoch: 5| Step: 8
Training loss: 2.678653795701595
Validation loss: 2.4737404208666853

Epoch: 5| Step: 9
Training loss: 1.683098952654561
Validation loss: 2.474387765388806

Epoch: 5| Step: 10
Training loss: 2.868326485814269
Validation loss: 2.467917756747996

Epoch: 5| Step: 11
Training loss: 2.292616237077251
Validation loss: 2.4854619309576877

Epoch: 181| Step: 0
Training loss: 2.8890709901130998
Validation loss: 2.483349534489654

Epoch: 5| Step: 1
Training loss: 1.9245951561221575
Validation loss: 2.491239329492431

Epoch: 5| Step: 2
Training loss: 2.1263184664566777
Validation loss: 2.484610632352432

Epoch: 5| Step: 3
Training loss: 2.8314496304698227
Validation loss: 2.473100151324079

Epoch: 5| Step: 4
Training loss: 2.724547507838144
Validation loss: 2.4888780238549706

Epoch: 5| Step: 5
Training loss: 2.173680933710076
Validation loss: 2.4890025743677064

Epoch: 5| Step: 6
Training loss: 2.3000174065636125
Validation loss: 2.489797105482935

Epoch: 5| Step: 7
Training loss: 2.492411253639593
Validation loss: 2.475762624159945

Epoch: 5| Step: 8
Training loss: 2.185521020813063
Validation loss: 2.4997988341776316

Epoch: 5| Step: 9
Training loss: 2.656385440739301
Validation loss: 2.492633572382035

Epoch: 5| Step: 10
Training loss: 2.2914781550698566
Validation loss: 2.4647282101271943

Epoch: 5| Step: 11
Training loss: 2.5529790642817916
Validation loss: 2.474263966738107

Epoch: 182| Step: 0
Training loss: 2.0884451776477837
Validation loss: 2.4842252106365317

Epoch: 5| Step: 1
Training loss: 2.0913928983744525
Validation loss: 2.4912728531601616

Epoch: 5| Step: 2
Training loss: 2.260209339202686
Validation loss: 2.490612126041518

Epoch: 5| Step: 3
Training loss: 2.569777598276172
Validation loss: 2.479754547866449

Epoch: 5| Step: 4
Training loss: 2.3597675527442568
Validation loss: 2.5005809307656586

Epoch: 5| Step: 5
Training loss: 2.8395445192463926
Validation loss: 2.4934882234548077

Epoch: 5| Step: 6
Training loss: 2.4152978988997793
Validation loss: 2.4937960138433826

Epoch: 5| Step: 7
Training loss: 2.6844143563739453
Validation loss: 2.4996410946712

Epoch: 5| Step: 8
Training loss: 2.293734940731496
Validation loss: 2.4812697951890863

Epoch: 5| Step: 9
Training loss: 2.4533958528506794
Validation loss: 2.477724618946161

Epoch: 5| Step: 10
Training loss: 2.5242629457912322
Validation loss: 2.4785409399512868

Epoch: 5| Step: 11
Training loss: 2.949801557946264
Validation loss: 2.487051475765244

Epoch: 183| Step: 0
Training loss: 2.4322740334981874
Validation loss: 2.4851401568262164

Epoch: 5| Step: 1
Training loss: 2.547553878828365
Validation loss: 2.477711556393858

Epoch: 5| Step: 2
Training loss: 2.245264792682104
Validation loss: 2.485821141097882

Epoch: 5| Step: 3
Training loss: 2.125530625457629
Validation loss: 2.473178055169815

Epoch: 5| Step: 4
Training loss: 2.2655119769087713
Validation loss: 2.484416165600613

Epoch: 5| Step: 5
Training loss: 2.884448075944482
Validation loss: 2.4795480896881967

Epoch: 5| Step: 6
Training loss: 2.5188787990607864
Validation loss: 2.478613107786802

Epoch: 5| Step: 7
Training loss: 2.2881088613875122
Validation loss: 2.475050768668693

Epoch: 5| Step: 8
Training loss: 3.0496822629426865
Validation loss: 2.4751638399989524

Epoch: 5| Step: 9
Training loss: 2.3002133146133663
Validation loss: 2.4706588801466967

Epoch: 5| Step: 10
Training loss: 2.319228821539642
Validation loss: 2.480585342830937

Epoch: 5| Step: 11
Training loss: 2.9762337570676443
Validation loss: 2.4916731882701058

Epoch: 184| Step: 0
Training loss: 2.3642930064049796
Validation loss: 2.4835683644739226

Epoch: 5| Step: 1
Training loss: 2.656541067893371
Validation loss: 2.4991210664017216

Epoch: 5| Step: 2
Training loss: 2.688984039775657
Validation loss: 2.51671607087971

Epoch: 5| Step: 3
Training loss: 2.6389839445249472
Validation loss: 2.50869246321994

Epoch: 5| Step: 4
Training loss: 2.3361669319288576
Validation loss: 2.51941263870871

Epoch: 5| Step: 5
Training loss: 1.8011570205357228
Validation loss: 2.515783287186352

Epoch: 5| Step: 6
Training loss: 2.773714121603261
Validation loss: 2.5181317170836945

Epoch: 5| Step: 7
Training loss: 2.67751969715784
Validation loss: 2.5124015018583656

Epoch: 5| Step: 8
Training loss: 2.58662677349055
Validation loss: 2.5191650873693052

Epoch: 5| Step: 9
Training loss: 2.395295312151671
Validation loss: 2.5042933235783917

Epoch: 5| Step: 10
Training loss: 2.3979789966621095
Validation loss: 2.4892238745827107

Epoch: 5| Step: 11
Training loss: 2.884581645866083
Validation loss: 2.478028570466137

Epoch: 185| Step: 0
Training loss: 2.507042692401435
Validation loss: 2.4786042061586198

Epoch: 5| Step: 1
Training loss: 2.933112906352419
Validation loss: 2.4737414388779944

Epoch: 5| Step: 2
Training loss: 2.220959275368245
Validation loss: 2.473837708326593

Epoch: 5| Step: 3
Training loss: 2.6993546845011007
Validation loss: 2.477570189352028

Epoch: 5| Step: 4
Training loss: 2.2317792847041944
Validation loss: 2.475551005561556

Epoch: 5| Step: 5
Training loss: 2.4563136667634304
Validation loss: 2.4873544393215847

Epoch: 5| Step: 6
Training loss: 2.3093053040679226
Validation loss: 2.48998051564893

Epoch: 5| Step: 7
Training loss: 2.360961582709837
Validation loss: 2.485006320159878

Epoch: 5| Step: 8
Training loss: 2.9207244076373677
Validation loss: 2.480146123775354

Epoch: 5| Step: 9
Training loss: 1.8708393983239955
Validation loss: 2.479927921157807

Epoch: 5| Step: 10
Training loss: 2.256262857923564
Validation loss: 2.471328093401593

Epoch: 5| Step: 11
Training loss: 3.4769472059356565
Validation loss: 2.465885367463826

Epoch: 186| Step: 0
Training loss: 2.465120569031227
Validation loss: 2.4675021297300064

Epoch: 5| Step: 1
Training loss: 2.4627421226170245
Validation loss: 2.4665971737063743

Epoch: 5| Step: 2
Training loss: 2.9333281415835586
Validation loss: 2.466814260051534

Epoch: 5| Step: 3
Training loss: 2.3111426003870315
Validation loss: 2.4597816215157744

Epoch: 5| Step: 4
Training loss: 2.397512748453656
Validation loss: 2.457535073963667

Epoch: 5| Step: 5
Training loss: 2.154918425359158
Validation loss: 2.4654898907445095

Epoch: 5| Step: 6
Training loss: 2.551566734707572
Validation loss: 2.4672329824973134

Epoch: 5| Step: 7
Training loss: 2.1601270014902223
Validation loss: 2.461098252954853

Epoch: 5| Step: 8
Training loss: 3.0252906974902904
Validation loss: 2.4567283803541646

Epoch: 5| Step: 9
Training loss: 2.0127282433774942
Validation loss: 2.4675759328414038

Epoch: 5| Step: 10
Training loss: 2.366194715141203
Validation loss: 2.468501657960214

Epoch: 5| Step: 11
Training loss: 2.532979586230223
Validation loss: 2.4770213723888594

Epoch: 187| Step: 0
Training loss: 2.892472290328359
Validation loss: 2.4719700757633603

Epoch: 5| Step: 1
Training loss: 2.89229836357067
Validation loss: 2.471280056988199

Epoch: 5| Step: 2
Training loss: 2.3142608949046903
Validation loss: 2.4679810336407946

Epoch: 5| Step: 3
Training loss: 2.4060492493748917
Validation loss: 2.473486910961254

Epoch: 5| Step: 4
Training loss: 1.8987189818128334
Validation loss: 2.472299358209908

Epoch: 5| Step: 5
Training loss: 1.9671771715058173
Validation loss: 2.4709373835504977

Epoch: 5| Step: 6
Training loss: 1.9884728000306648
Validation loss: 2.479884489840578

Epoch: 5| Step: 7
Training loss: 2.707467180301484
Validation loss: 2.4843686701536014

Epoch: 5| Step: 8
Training loss: 3.0455294254367615
Validation loss: 2.4749088362078147

Epoch: 5| Step: 9
Training loss: 2.34138980283106
Validation loss: 2.4660721472124885

Epoch: 5| Step: 10
Training loss: 2.2812493729263905
Validation loss: 2.474846009399274

Epoch: 5| Step: 11
Training loss: 2.4259612036651026
Validation loss: 2.4705349167570363

Epoch: 188| Step: 0
Training loss: 2.0435140257695434
Validation loss: 2.469263116008739

Epoch: 5| Step: 1
Training loss: 2.5593243902510077
Validation loss: 2.4693317492446836

Epoch: 5| Step: 2
Training loss: 2.290856917689946
Validation loss: 2.4633264279580622

Epoch: 5| Step: 3
Training loss: 2.307144458859616
Validation loss: 2.4572663591436528

Epoch: 5| Step: 4
Training loss: 2.709708603116976
Validation loss: 2.4622072809132214

Epoch: 5| Step: 5
Training loss: 2.5158894085981576
Validation loss: 2.4670999561776976

Epoch: 5| Step: 6
Training loss: 2.114843217887008
Validation loss: 2.4732606178345486

Epoch: 5| Step: 7
Training loss: 2.683655406349119
Validation loss: 2.4765289938151303

Epoch: 5| Step: 8
Training loss: 2.377362030390252
Validation loss: 2.4796888151527896

Epoch: 5| Step: 9
Training loss: 2.612320385466852
Validation loss: 2.4728411082610275

Epoch: 5| Step: 10
Training loss: 2.4249060583107296
Validation loss: 2.481821261144127

Epoch: 5| Step: 11
Training loss: 2.9120823573004735
Validation loss: 2.465296680007847

Epoch: 189| Step: 0
Training loss: 2.5444166804783537
Validation loss: 2.462251798672419

Epoch: 5| Step: 1
Training loss: 2.6735005035200157
Validation loss: 2.4587980022505773

Epoch: 5| Step: 2
Training loss: 2.4504524786263664
Validation loss: 2.4674246606594754

Epoch: 5| Step: 3
Training loss: 2.3163440818227996
Validation loss: 2.4666580600094354

Epoch: 5| Step: 4
Training loss: 2.761796273056655
Validation loss: 2.4587272123758925

Epoch: 5| Step: 5
Training loss: 2.349544127867184
Validation loss: 2.463817441208543

Epoch: 5| Step: 6
Training loss: 2.656892137887224
Validation loss: 2.4585774443273283

Epoch: 5| Step: 7
Training loss: 1.8276250432727188
Validation loss: 2.4655114230325386

Epoch: 5| Step: 8
Training loss: 2.6559113230494162
Validation loss: 2.4578578591531453

Epoch: 5| Step: 9
Training loss: 2.138262482220341
Validation loss: 2.466072262019371

Epoch: 5| Step: 10
Training loss: 2.452616450571365
Validation loss: 2.4611866012526784

Epoch: 5| Step: 11
Training loss: 1.6507069662615335
Validation loss: 2.462078613043888

Epoch: 190| Step: 0
Training loss: 2.51945270741192
Validation loss: 2.4632394348525026

Epoch: 5| Step: 1
Training loss: 2.248706445786397
Validation loss: 2.4682501717488208

Epoch: 5| Step: 2
Training loss: 2.1945186822408465
Validation loss: 2.4893678361740297

Epoch: 5| Step: 3
Training loss: 2.7860189976862597
Validation loss: 2.4887786320218144

Epoch: 5| Step: 4
Training loss: 2.051536900403461
Validation loss: 2.4712832045073028

Epoch: 5| Step: 5
Training loss: 2.289366509882383
Validation loss: 2.473684305106137

Epoch: 5| Step: 6
Training loss: 2.697851074678248
Validation loss: 2.4662183222578684

Epoch: 5| Step: 7
Training loss: 2.295991896492086
Validation loss: 2.4531336539211015

Epoch: 5| Step: 8
Training loss: 3.05768393361754
Validation loss: 2.4637085909809415

Epoch: 5| Step: 9
Training loss: 2.4336420486090504
Validation loss: 2.452982163371021

Epoch: 5| Step: 10
Training loss: 2.2939173541226734
Validation loss: 2.4674131781851134

Epoch: 5| Step: 11
Training loss: 3.12473845341041
Validation loss: 2.4574129447962725

Epoch: 191| Step: 0
Training loss: 2.1769759837671443
Validation loss: 2.4687168867570417

Epoch: 5| Step: 1
Training loss: 2.634415950434241
Validation loss: 2.465673138849994

Epoch: 5| Step: 2
Training loss: 3.089740814153352
Validation loss: 2.465868753391765

Epoch: 5| Step: 3
Training loss: 1.94796204811584
Validation loss: 2.466315719140051

Epoch: 5| Step: 4
Training loss: 2.256317805489217
Validation loss: 2.459506499811352

Epoch: 5| Step: 5
Training loss: 2.2283356683338895
Validation loss: 2.462366046747683

Epoch: 5| Step: 6
Training loss: 2.258979891555403
Validation loss: 2.4580558051767807

Epoch: 5| Step: 7
Training loss: 2.19104436106412
Validation loss: 2.4582748540830126

Epoch: 5| Step: 8
Training loss: 2.398105561090881
Validation loss: 2.457991549337421

Epoch: 5| Step: 9
Training loss: 2.7724577556724874
Validation loss: 2.4742123577138533

Epoch: 5| Step: 10
Training loss: 2.634318478522094
Validation loss: 2.47142356048906

Epoch: 5| Step: 11
Training loss: 2.5033070625453937
Validation loss: 2.478236778691948

Epoch: 192| Step: 0
Training loss: 2.1419836034921915
Validation loss: 2.5106640643707583

Epoch: 5| Step: 1
Training loss: 2.134245338802156
Validation loss: 2.501890155397868

Epoch: 5| Step: 2
Training loss: 2.545327307258188
Validation loss: 2.502121658862794

Epoch: 5| Step: 3
Training loss: 2.844418457611241
Validation loss: 2.519975990649042

Epoch: 5| Step: 4
Training loss: 2.716917187503819
Validation loss: 2.5330945974301726

Epoch: 5| Step: 5
Training loss: 2.2766424182067806
Validation loss: 2.5273544924476767

Epoch: 5| Step: 6
Training loss: 2.68401234567364
Validation loss: 2.5232071077500984

Epoch: 5| Step: 7
Training loss: 1.9703229040223615
Validation loss: 2.514305803480077

Epoch: 5| Step: 8
Training loss: 2.3911250968892004
Validation loss: 2.5011362593076765

Epoch: 5| Step: 9
Training loss: 2.545593500989078
Validation loss: 2.4821218273752637

Epoch: 5| Step: 10
Training loss: 2.2543692022449466
Validation loss: 2.4781999499711116

Epoch: 5| Step: 11
Training loss: 2.6977356564003756
Validation loss: 2.481182478299085

Epoch: 193| Step: 0
Training loss: 2.060533453007234
Validation loss: 2.4820266637138375

Epoch: 5| Step: 1
Training loss: 2.754899082724021
Validation loss: 2.476186577377726

Epoch: 5| Step: 2
Training loss: 2.6670572670336883
Validation loss: 2.476861388164026

Epoch: 5| Step: 3
Training loss: 2.729499874206529
Validation loss: 2.4820674560198723

Epoch: 5| Step: 4
Training loss: 2.7467377126017354
Validation loss: 2.4856971965047325

Epoch: 5| Step: 5
Training loss: 2.1826945246365597
Validation loss: 2.4936374245316766

Epoch: 5| Step: 6
Training loss: 2.8611989691946977
Validation loss: 2.4826820991478558

Epoch: 5| Step: 7
Training loss: 2.2029359344088104
Validation loss: 2.4884591390839454

Epoch: 5| Step: 8
Training loss: 2.6399160483045567
Validation loss: 2.4931815306543035

Epoch: 5| Step: 9
Training loss: 2.64743265990293
Validation loss: 2.4905614102110145

Epoch: 5| Step: 10
Training loss: 2.1583278430098094
Validation loss: 2.491221317362847

Epoch: 5| Step: 11
Training loss: 1.0708964627331383
Validation loss: 2.4865340841511516

Epoch: 194| Step: 0
Training loss: 1.9110863416320911
Validation loss: 2.4961628095916644

Epoch: 5| Step: 1
Training loss: 2.9795691656210512
Validation loss: 2.478044325295878

Epoch: 5| Step: 2
Training loss: 2.3305585802331676
Validation loss: 2.4826664037595063

Epoch: 5| Step: 3
Training loss: 2.5399385320179393
Validation loss: 2.49582858162132

Epoch: 5| Step: 4
Training loss: 2.5981669676811503
Validation loss: 2.50559464540695

Epoch: 5| Step: 5
Training loss: 2.1675761099259647
Validation loss: 2.505887569309513

Epoch: 5| Step: 6
Training loss: 2.357723946801251
Validation loss: 2.5048828561248677

Epoch: 5| Step: 7
Training loss: 3.016008738082653
Validation loss: 2.5151627591759382

Epoch: 5| Step: 8
Training loss: 2.4725472906853154
Validation loss: 2.5269419386561025

Epoch: 5| Step: 9
Training loss: 2.4572134753943677
Validation loss: 2.514250492348139

Epoch: 5| Step: 10
Training loss: 2.204765628806452
Validation loss: 2.532572424381161

Epoch: 5| Step: 11
Training loss: 2.6038037059883847
Validation loss: 2.5216937225686324

Epoch: 195| Step: 0
Training loss: 2.086758455607831
Validation loss: 2.5000050147324178

Epoch: 5| Step: 1
Training loss: 2.2467811660379264
Validation loss: 2.4959508848024456

Epoch: 5| Step: 2
Training loss: 3.027572445998854
Validation loss: 2.4847150965690847

Epoch: 5| Step: 3
Training loss: 2.855542559002477
Validation loss: 2.4760333437546365

Epoch: 5| Step: 4
Training loss: 2.377222125865727
Validation loss: 2.471411033407557

Epoch: 5| Step: 5
Training loss: 2.563595142346686
Validation loss: 2.4725527387650867

Epoch: 5| Step: 6
Training loss: 2.4106746468489284
Validation loss: 2.4691885586812106

Epoch: 5| Step: 7
Training loss: 2.1568450106777375
Validation loss: 2.472171133221314

Epoch: 5| Step: 8
Training loss: 2.3775189744130008
Validation loss: 2.473755160906707

Epoch: 5| Step: 9
Training loss: 2.1949930739239187
Validation loss: 2.4768320372162913

Epoch: 5| Step: 10
Training loss: 2.458531053857067
Validation loss: 2.4757536922199903

Epoch: 5| Step: 11
Training loss: 2.345243664671048
Validation loss: 2.4750218136786226

Epoch: 196| Step: 0
Training loss: 2.4322026717727225
Validation loss: 2.4783606234020445

Epoch: 5| Step: 1
Training loss: 2.7062523892504426
Validation loss: 2.4771378186850557

Epoch: 5| Step: 2
Training loss: 2.7585247730154325
Validation loss: 2.482331299048539

Epoch: 5| Step: 3
Training loss: 2.1585020384771156
Validation loss: 2.4756015353241256

Epoch: 5| Step: 4
Training loss: 2.236842253776522
Validation loss: 2.47452831060263

Epoch: 5| Step: 5
Training loss: 2.386922225145349
Validation loss: 2.473974964019023

Epoch: 5| Step: 6
Training loss: 2.732010434785634
Validation loss: 2.474710219048894

Epoch: 5| Step: 7
Training loss: 2.5196172655193823
Validation loss: 2.472794943199661

Epoch: 5| Step: 8
Training loss: 2.194701629032638
Validation loss: 2.4782096006521024

Epoch: 5| Step: 9
Training loss: 2.577351032025936
Validation loss: 2.4776858560822443

Epoch: 5| Step: 10
Training loss: 2.415839174159835
Validation loss: 2.480619298816735

Epoch: 5| Step: 11
Training loss: 1.5052366243055464
Validation loss: 2.472875248921823

Epoch: 197| Step: 0
Training loss: 2.1491867700913283
Validation loss: 2.485545096765714

Epoch: 5| Step: 1
Training loss: 2.7374866328500964
Validation loss: 2.4826301709417

Epoch: 5| Step: 2
Training loss: 2.1801015809216797
Validation loss: 2.490652925310052

Epoch: 5| Step: 3
Training loss: 2.566969532457759
Validation loss: 2.491254191295405

Epoch: 5| Step: 4
Training loss: 1.8734242493683426
Validation loss: 2.5025363652270274

Epoch: 5| Step: 5
Training loss: 2.4553828448647184
Validation loss: 2.4988557064348433

Epoch: 5| Step: 6
Training loss: 2.609162099227717
Validation loss: 2.496808319410923

Epoch: 5| Step: 7
Training loss: 2.471613225567078
Validation loss: 2.4902396048696613

Epoch: 5| Step: 8
Training loss: 2.4987632553413093
Validation loss: 2.5006266563528903

Epoch: 5| Step: 9
Training loss: 2.697052501791208
Validation loss: 2.4841501885989135

Epoch: 5| Step: 10
Training loss: 2.429524603286337
Validation loss: 2.493769224470414

Epoch: 5| Step: 11
Training loss: 1.8795685106574016
Validation loss: 2.495138740819718

Epoch: 198| Step: 0
Training loss: 2.0440893655564825
Validation loss: 2.493211197149163

Epoch: 5| Step: 1
Training loss: 2.22556322662831
Validation loss: 2.495772860998603

Epoch: 5| Step: 2
Training loss: 2.4714397794782794
Validation loss: 2.5071879051766373

Epoch: 5| Step: 3
Training loss: 2.205831177809752
Validation loss: 2.508525905366891

Epoch: 5| Step: 4
Training loss: 2.9334776915083483
Validation loss: 2.4994168773715857

Epoch: 5| Step: 5
Training loss: 2.4715279510356027
Validation loss: 2.507271305208109

Epoch: 5| Step: 6
Training loss: 2.5402478077671327
Validation loss: 2.5145098819029004

Epoch: 5| Step: 7
Training loss: 2.445504275470897
Validation loss: 2.5031015667272896

Epoch: 5| Step: 8
Training loss: 2.5201858025127852
Validation loss: 2.5019941959390017

Epoch: 5| Step: 9
Training loss: 2.513988460116732
Validation loss: 2.511880120946646

Epoch: 5| Step: 10
Training loss: 2.4288039977647653
Validation loss: 2.5206130039198573

Epoch: 5| Step: 11
Training loss: 2.5512560275509855
Validation loss: 2.520455284118153

Epoch: 199| Step: 0
Training loss: 2.1940713543829378
Validation loss: 2.5128556679851415

Epoch: 5| Step: 1
Training loss: 2.1906067720925506
Validation loss: 2.5237875342321523

Epoch: 5| Step: 2
Training loss: 2.713276055064941
Validation loss: 2.5387561750250804

Epoch: 5| Step: 3
Training loss: 2.3515120085811736
Validation loss: 2.5417031978629234

Epoch: 5| Step: 4
Training loss: 2.8810185999430433
Validation loss: 2.542972144746248

Epoch: 5| Step: 5
Training loss: 2.287743614857346
Validation loss: 2.5430464920684774

Epoch: 5| Step: 6
Training loss: 2.4302161521693186
Validation loss: 2.548972473344347

Epoch: 5| Step: 7
Training loss: 2.2812321283345867
Validation loss: 2.5548622584866743

Epoch: 5| Step: 8
Training loss: 2.6468219161762523
Validation loss: 2.5440336615999017

Epoch: 5| Step: 9
Training loss: 2.396052762362894
Validation loss: 2.5262849487398915

Epoch: 5| Step: 10
Training loss: 2.4129408912801846
Validation loss: 2.50748124514634

Epoch: 5| Step: 11
Training loss: 2.848435785792134
Validation loss: 2.4925936265359887

Epoch: 200| Step: 0
Training loss: 2.7740641141274205
Validation loss: 2.4822080786736174

Epoch: 5| Step: 1
Training loss: 2.1444801088221332
Validation loss: 2.4850853078502646

Epoch: 5| Step: 2
Training loss: 2.088423601144505
Validation loss: 2.4855320393424667

Epoch: 5| Step: 3
Training loss: 2.419749256101207
Validation loss: 2.487937540203033

Epoch: 5| Step: 4
Training loss: 2.77224955302161
Validation loss: 2.4886381930290034

Epoch: 5| Step: 5
Training loss: 2.5337080147214133
Validation loss: 2.493262373065149

Epoch: 5| Step: 6
Training loss: 2.4588026687108644
Validation loss: 2.4861105408895776

Epoch: 5| Step: 7
Training loss: 2.629975009552905
Validation loss: 2.497570188215135

Epoch: 5| Step: 8
Training loss: 2.9022665308746802
Validation loss: 2.4755456001963134

Epoch: 5| Step: 9
Training loss: 1.982231003164981
Validation loss: 2.484647408031899

Epoch: 5| Step: 10
Training loss: 2.675715669816792
Validation loss: 2.4759202158382925

Epoch: 5| Step: 11
Training loss: 1.852250820292053
Validation loss: 2.4707354919163063

Epoch: 201| Step: 0
Training loss: 2.3224651998452392
Validation loss: 2.4727447718904845

Epoch: 5| Step: 1
Training loss: 2.1447788227642217
Validation loss: 2.470199340602758

Epoch: 5| Step: 2
Training loss: 2.7108704836254534
Validation loss: 2.4721270934624866

Epoch: 5| Step: 3
Training loss: 2.4627932378768094
Validation loss: 2.4830822530223204

Epoch: 5| Step: 4
Training loss: 2.358044786178381
Validation loss: 2.47468331539383

Epoch: 5| Step: 5
Training loss: 2.3929183033038592
Validation loss: 2.4989502769256604

Epoch: 5| Step: 6
Training loss: 2.7868515355178265
Validation loss: 2.506297215233407

Epoch: 5| Step: 7
Training loss: 2.3874001287372892
Validation loss: 2.514353019867349

Epoch: 5| Step: 8
Training loss: 2.440233507395896
Validation loss: 2.50030362749077

Epoch: 5| Step: 9
Training loss: 2.9744008142064926
Validation loss: 2.4900774658235445

Epoch: 5| Step: 10
Training loss: 2.2537752903488864
Validation loss: 2.485695793730208

Epoch: 5| Step: 11
Training loss: 1.709226754575448
Validation loss: 2.485121428921192

Epoch: 202| Step: 0
Training loss: 2.6979290189914398
Validation loss: 2.480816962363554

Epoch: 5| Step: 1
Training loss: 2.0040334322837983
Validation loss: 2.484468118453963

Epoch: 5| Step: 2
Training loss: 2.5143952770017663
Validation loss: 2.4844978949901977

Epoch: 5| Step: 3
Training loss: 1.8667190794171364
Validation loss: 2.489266272962362

Epoch: 5| Step: 4
Training loss: 2.133582231287277
Validation loss: 2.4868876388777017

Epoch: 5| Step: 5
Training loss: 2.1679358677475355
Validation loss: 2.4853995827543107

Epoch: 5| Step: 6
Training loss: 2.32213934193279
Validation loss: 2.4909039044861463

Epoch: 5| Step: 7
Training loss: 2.762189552504028
Validation loss: 2.4780927316842534

Epoch: 5| Step: 8
Training loss: 2.934556988322497
Validation loss: 2.4875230657124727

Epoch: 5| Step: 9
Training loss: 2.8842743266050963
Validation loss: 2.4849255789455134

Epoch: 5| Step: 10
Training loss: 2.156829203338045
Validation loss: 2.5001470860286954

Epoch: 5| Step: 11
Training loss: 1.8581960450623545
Validation loss: 2.490144220851987

Epoch: 203| Step: 0
Training loss: 2.2014562902016603
Validation loss: 2.49623390086864

Epoch: 5| Step: 1
Training loss: 2.313325683002116
Validation loss: 2.496045676789786

Epoch: 5| Step: 2
Training loss: 2.6091557027983807
Validation loss: 2.500871657366316

Epoch: 5| Step: 3
Training loss: 2.5139421793404266
Validation loss: 2.4932147174196304

Epoch: 5| Step: 4
Training loss: 2.401274553259801
Validation loss: 2.495236573470492

Epoch: 5| Step: 5
Training loss: 1.943169942086416
Validation loss: 2.493384102896896

Epoch: 5| Step: 6
Training loss: 2.6096020445583528
Validation loss: 2.4953478124926978

Epoch: 5| Step: 7
Training loss: 2.0717646274540513
Validation loss: 2.4948077642655453

Epoch: 5| Step: 8
Training loss: 2.4774924857663665
Validation loss: 2.5011459148266577

Epoch: 5| Step: 9
Training loss: 2.4514051106041994
Validation loss: 2.497982124720242

Epoch: 5| Step: 10
Training loss: 2.725930564247937
Validation loss: 2.511811542922784

Epoch: 5| Step: 11
Training loss: 2.3927444337926183
Validation loss: 2.5187679741330906

Epoch: 204| Step: 0
Training loss: 2.29853324975956
Validation loss: 2.5012992105594933

Epoch: 5| Step: 1
Training loss: 1.6125857722218118
Validation loss: 2.493958652024592

Epoch: 5| Step: 2
Training loss: 2.5197080091824304
Validation loss: 2.475216099427462

Epoch: 5| Step: 3
Training loss: 2.014967227035068
Validation loss: 2.487632589065356

Epoch: 5| Step: 4
Training loss: 2.395779606313483
Validation loss: 2.490870004949569

Epoch: 5| Step: 5
Training loss: 2.2238884110071298
Validation loss: 2.497830617937507

Epoch: 5| Step: 6
Training loss: 2.818932108272312
Validation loss: 2.495356180648339

Epoch: 5| Step: 7
Training loss: 2.476210800854268
Validation loss: 2.4991384968935444

Epoch: 5| Step: 8
Training loss: 3.070427424097562
Validation loss: 2.498079436415318

Epoch: 5| Step: 9
Training loss: 2.4682042931159796
Validation loss: 2.5169346324625224

Epoch: 5| Step: 10
Training loss: 2.345593248981321
Validation loss: 2.499756022310269

Epoch: 5| Step: 11
Training loss: 2.298107413441726
Validation loss: 2.5096490736441956

Epoch: 205| Step: 0
Training loss: 2.5199439841811255
Validation loss: 2.508670860031265

Epoch: 5| Step: 1
Training loss: 2.4913631020389566
Validation loss: 2.5154331126193332

Epoch: 5| Step: 2
Training loss: 2.1896930056132953
Validation loss: 2.503383881527995

Epoch: 5| Step: 3
Training loss: 2.8795263070390047
Validation loss: 2.499082553925055

Epoch: 5| Step: 4
Training loss: 2.7221275483966565
Validation loss: 2.5001535209566326

Epoch: 5| Step: 5
Training loss: 1.868758111636313
Validation loss: 2.5002265152038197

Epoch: 5| Step: 6
Training loss: 2.228775798243935
Validation loss: 2.487191161595433

Epoch: 5| Step: 7
Training loss: 2.5934683405523318
Validation loss: 2.4856102469670454

Epoch: 5| Step: 8
Training loss: 2.248789779709886
Validation loss: 2.491333846177237

Epoch: 5| Step: 9
Training loss: 1.9975574001997778
Validation loss: 2.479165687614269

Epoch: 5| Step: 10
Training loss: 2.4983657263584975
Validation loss: 2.4786093323140075

Epoch: 5| Step: 11
Training loss: 3.078527124153755
Validation loss: 2.4987899315400735

Epoch: 206| Step: 0
Training loss: 2.8242780117291253
Validation loss: 2.4998258410826297

Epoch: 5| Step: 1
Training loss: 2.2495310612603134
Validation loss: 2.5182454063630897

Epoch: 5| Step: 2
Training loss: 2.5195020097322165
Validation loss: 2.5388872721924516

Epoch: 5| Step: 3
Training loss: 2.3049997926327164
Validation loss: 2.5437331957500247

Epoch: 5| Step: 4
Training loss: 2.048946235387008
Validation loss: 2.5338493038704537

Epoch: 5| Step: 5
Training loss: 2.8007109352553483
Validation loss: 2.5188553172038772

Epoch: 5| Step: 6
Training loss: 2.0340057459837286
Validation loss: 2.5271084227316285

Epoch: 5| Step: 7
Training loss: 3.154968303636067
Validation loss: 2.514717471462154

Epoch: 5| Step: 8
Training loss: 2.0384515892195716
Validation loss: 2.5040499328078303

Epoch: 5| Step: 9
Training loss: 2.231497238523299
Validation loss: 2.5126278044488854

Epoch: 5| Step: 10
Training loss: 2.493229758700387
Validation loss: 2.5037293949444246

Epoch: 5| Step: 11
Training loss: 1.0057954341972155
Validation loss: 2.5049832468303834

Epoch: 207| Step: 0
Training loss: 2.782845628767177
Validation loss: 2.494980895817202

Epoch: 5| Step: 1
Training loss: 2.5894020129614876
Validation loss: 2.505912809924632

Epoch: 5| Step: 2
Training loss: 2.3600554842811423
Validation loss: 2.5049695649966286

Epoch: 5| Step: 3
Training loss: 2.139676183105421
Validation loss: 2.5036889754127474

Epoch: 5| Step: 4
Training loss: 2.838998534973132
Validation loss: 2.499342359034153

Epoch: 5| Step: 5
Training loss: 2.6052949724480596
Validation loss: 2.50709545623484

Epoch: 5| Step: 6
Training loss: 1.9850808637853021
Validation loss: 2.5081707073691755

Epoch: 5| Step: 7
Training loss: 2.239838223405612
Validation loss: 2.5172323379611754

Epoch: 5| Step: 8
Training loss: 2.299223756412055
Validation loss: 2.517496001623338

Epoch: 5| Step: 9
Training loss: 2.2260743794040576
Validation loss: 2.506625206370681

Epoch: 5| Step: 10
Training loss: 2.099303893111315
Validation loss: 2.5206051689065894

Epoch: 5| Step: 11
Training loss: 3.684918162499521
Validation loss: 2.5332332110278895

Epoch: 208| Step: 0
Training loss: 2.691689973224403
Validation loss: 2.52499620623036

Epoch: 5| Step: 1
Training loss: 2.2748454869377213
Validation loss: 2.526928816021069

Epoch: 5| Step: 2
Training loss: 2.4107125257051694
Validation loss: 2.5341410276861085

Epoch: 5| Step: 3
Training loss: 1.7651586000977775
Validation loss: 2.51454745290505

Epoch: 5| Step: 4
Training loss: 2.520012198978749
Validation loss: 2.521847396157483

Epoch: 5| Step: 5
Training loss: 2.789187901346436
Validation loss: 2.517361564782347

Epoch: 5| Step: 6
Training loss: 1.4882492102030231
Validation loss: 2.515717356627264

Epoch: 5| Step: 7
Training loss: 2.5654612852545906
Validation loss: 2.5105325598234662

Epoch: 5| Step: 8
Training loss: 2.431270267823768
Validation loss: 2.503525140079299

Epoch: 5| Step: 9
Training loss: 2.741111522539315
Validation loss: 2.50154864505741

Epoch: 5| Step: 10
Training loss: 2.439072321909276
Validation loss: 2.499076318970164

Epoch: 5| Step: 11
Training loss: 2.020695540721619
Validation loss: 2.505083558166757

Epoch: 209| Step: 0
Training loss: 2.014257159122482
Validation loss: 2.50400404558119

Epoch: 5| Step: 1
Training loss: 2.528994838988384
Validation loss: 2.5051179831239856

Epoch: 5| Step: 2
Training loss: 2.5345384876657495
Validation loss: 2.502533284803405

Epoch: 5| Step: 3
Training loss: 2.7119947674906166
Validation loss: 2.499924853308105

Epoch: 5| Step: 4
Training loss: 2.2940462300532083
Validation loss: 2.5098918165649855

Epoch: 5| Step: 5
Training loss: 2.550674786762979
Validation loss: 2.5047110793030476

Epoch: 5| Step: 6
Training loss: 2.1795427828092633
Validation loss: 2.5041900291453265

Epoch: 5| Step: 7
Training loss: 2.382036927123544
Validation loss: 2.49123146589996

Epoch: 5| Step: 8
Training loss: 2.906406521427767
Validation loss: 2.4904889184845267

Epoch: 5| Step: 9
Training loss: 1.9706497714454485
Validation loss: 2.4928555126447702

Epoch: 5| Step: 10
Training loss: 2.1580979541682432
Validation loss: 2.4941572817587523

Epoch: 5| Step: 11
Training loss: 1.8468212474868995
Validation loss: 2.491067979699225

Epoch: 210| Step: 0
Training loss: 2.124696373284875
Validation loss: 2.498414240019682

Epoch: 5| Step: 1
Training loss: 2.652016531039768
Validation loss: 2.508327367898009

Epoch: 5| Step: 2
Training loss: 2.100656647425351
Validation loss: 2.5021961658922134

Epoch: 5| Step: 3
Training loss: 2.5950418954749113
Validation loss: 2.5289175527290784

Epoch: 5| Step: 4
Training loss: 3.1271981709788923
Validation loss: 2.549052413484615

Epoch: 5| Step: 5
Training loss: 2.559487409533508
Validation loss: 2.5633051681139003

Epoch: 5| Step: 6
Training loss: 2.3738852444609932
Validation loss: 2.550699436186206

Epoch: 5| Step: 7
Training loss: 2.2823895260334863
Validation loss: 2.5612266214401247

Epoch: 5| Step: 8
Training loss: 2.495441381366369
Validation loss: 2.540957157714379

Epoch: 5| Step: 9
Training loss: 1.7872289065216689
Validation loss: 2.5381639935089906

Epoch: 5| Step: 10
Training loss: 2.2445198714714416
Validation loss: 2.546037212414023

Epoch: 5| Step: 11
Training loss: 1.404380530570141
Validation loss: 2.5203504940668497

Epoch: 211| Step: 0
Training loss: 2.5843170713046457
Validation loss: 2.5227384435534974

Epoch: 5| Step: 1
Training loss: 2.428221821664973
Validation loss: 2.5034514801240744

Epoch: 5| Step: 2
Training loss: 2.2348648281312924
Validation loss: 2.499907889258729

Epoch: 5| Step: 3
Training loss: 2.508771101136317
Validation loss: 2.4820974234490096

Epoch: 5| Step: 4
Training loss: 1.9673692614731428
Validation loss: 2.48609286721306

Epoch: 5| Step: 5
Training loss: 2.4541089459697925
Validation loss: 2.483159825698258

Epoch: 5| Step: 6
Training loss: 2.681000146139469
Validation loss: 2.489005230509993

Epoch: 5| Step: 7
Training loss: 2.1927768820394697
Validation loss: 2.484224492838266

Epoch: 5| Step: 8
Training loss: 2.03315985465934
Validation loss: 2.4994575150326983

Epoch: 5| Step: 9
Training loss: 2.2616835411902176
Validation loss: 2.5066203455743463

Epoch: 5| Step: 10
Training loss: 2.7302812722040013
Validation loss: 2.512427566679875

Epoch: 5| Step: 11
Training loss: 3.206248625816363
Validation loss: 2.5303701983194298

Epoch: 212| Step: 0
Training loss: 2.1927344772942843
Validation loss: 2.5371291443933335

Epoch: 5| Step: 1
Training loss: 2.3528730726203264
Validation loss: 2.542834167513169

Epoch: 5| Step: 2
Training loss: 2.822371980451694
Validation loss: 2.525848437649748

Epoch: 5| Step: 3
Training loss: 2.261850514633829
Validation loss: 2.538209030299642

Epoch: 5| Step: 4
Training loss: 1.9054687024531372
Validation loss: 2.5399720230651845

Epoch: 5| Step: 5
Training loss: 2.787881382053912
Validation loss: 2.534078030761515

Epoch: 5| Step: 6
Training loss: 2.493363153955894
Validation loss: 2.515998923112955

Epoch: 5| Step: 7
Training loss: 2.2168211813783087
Validation loss: 2.5046100311768678

Epoch: 5| Step: 8
Training loss: 1.8797848366310965
Validation loss: 2.504374971522258

Epoch: 5| Step: 9
Training loss: 2.580637407002797
Validation loss: 2.501143797844403

Epoch: 5| Step: 10
Training loss: 2.6919409853232548
Validation loss: 2.493649100968883

Epoch: 5| Step: 11
Training loss: 2.6432620993881804
Validation loss: 2.512315875909311

Epoch: 213| Step: 0
Training loss: 2.3020874874946315
Validation loss: 2.5094870446108812

Epoch: 5| Step: 1
Training loss: 2.0410089666084574
Validation loss: 2.5049517388431477

Epoch: 5| Step: 2
Training loss: 2.6086086586945747
Validation loss: 2.5057326631925347

Epoch: 5| Step: 3
Training loss: 2.7745332514381915
Validation loss: 2.504344356334472

Epoch: 5| Step: 4
Training loss: 3.2169333951847956
Validation loss: 2.5108825256621783

Epoch: 5| Step: 5
Training loss: 2.2315094185266493
Validation loss: 2.511066745675123

Epoch: 5| Step: 6
Training loss: 2.252805444328275
Validation loss: 2.511118087810438

Epoch: 5| Step: 7
Training loss: 2.170855385734832
Validation loss: 2.5104363679442567

Epoch: 5| Step: 8
Training loss: 1.5340299478614063
Validation loss: 2.512238643979938

Epoch: 5| Step: 9
Training loss: 2.354267883375449
Validation loss: 2.5218883715735574

Epoch: 5| Step: 10
Training loss: 2.507467466012098
Validation loss: 2.519767249437049

Epoch: 5| Step: 11
Training loss: 2.590558397934768
Validation loss: 2.5237047744787438

Epoch: 214| Step: 0
Training loss: 2.6091182376830777
Validation loss: 2.531858296555441

Epoch: 5| Step: 1
Training loss: 2.2767114301258458
Validation loss: 2.5305015532787745

Epoch: 5| Step: 2
Training loss: 2.269725902830717
Validation loss: 2.5396051580123946

Epoch: 5| Step: 3
Training loss: 2.767323807343026
Validation loss: 2.536145209868591

Epoch: 5| Step: 4
Training loss: 2.234864721449858
Validation loss: 2.5395540593008827

Epoch: 5| Step: 5
Training loss: 2.1218612153584484
Validation loss: 2.5424540516937784

Epoch: 5| Step: 6
Training loss: 2.057289825309863
Validation loss: 2.536307188748913

Epoch: 5| Step: 7
Training loss: 2.5874235832982504
Validation loss: 2.5353384359029874

Epoch: 5| Step: 8
Training loss: 2.445028172742173
Validation loss: 2.528995027536472

Epoch: 5| Step: 9
Training loss: 2.609840305894544
Validation loss: 2.524216947847111

Epoch: 5| Step: 10
Training loss: 2.255618709260535
Validation loss: 2.508415258665494

Epoch: 5| Step: 11
Training loss: 3.405981210725112
Validation loss: 2.5128951533750317

Epoch: 215| Step: 0
Training loss: 2.6590480652790682
Validation loss: 2.5036226291479253

Epoch: 5| Step: 1
Training loss: 1.77648066430342
Validation loss: 2.5089008112879325

Epoch: 5| Step: 2
Training loss: 2.321158001401081
Validation loss: 2.5077728751628117

Epoch: 5| Step: 3
Training loss: 2.8667555647380443
Validation loss: 2.5087265377091144

Epoch: 5| Step: 4
Training loss: 2.2011100266169525
Validation loss: 2.4997835621921127

Epoch: 5| Step: 5
Training loss: 2.9378952409778756
Validation loss: 2.4967024871279326

Epoch: 5| Step: 6
Training loss: 1.9453663033394768
Validation loss: 2.5073111380558104

Epoch: 5| Step: 7
Training loss: 2.3118955492363
Validation loss: 2.497319365846597

Epoch: 5| Step: 8
Training loss: 2.213435618534282
Validation loss: 2.5205572321255634

Epoch: 5| Step: 9
Training loss: 2.463987561466974
Validation loss: 2.5138986243685304

Epoch: 5| Step: 10
Training loss: 2.5871505427609356
Validation loss: 2.5057930306987886

Epoch: 5| Step: 11
Training loss: 1.783701230660906
Validation loss: 2.5189152519027833

Epoch: 216| Step: 0
Training loss: 2.5304234414962896
Validation loss: 2.5208353260652427

Epoch: 5| Step: 1
Training loss: 2.1574845028140555
Validation loss: 2.5246800098732254

Epoch: 5| Step: 2
Training loss: 2.6983948704765504
Validation loss: 2.525844551864054

Epoch: 5| Step: 3
Training loss: 2.499286549809093
Validation loss: 2.5139982440925155

Epoch: 5| Step: 4
Training loss: 2.705717838815591
Validation loss: 2.522587411554989

Epoch: 5| Step: 5
Training loss: 2.3527142818529647
Validation loss: 2.507840715924989

Epoch: 5| Step: 6
Training loss: 1.7265245252204626
Validation loss: 2.5049050709985354

Epoch: 5| Step: 7
Training loss: 2.5934699952989844
Validation loss: 2.5014979801915787

Epoch: 5| Step: 8
Training loss: 2.0818694375661555
Validation loss: 2.4944276218890167

Epoch: 5| Step: 9
Training loss: 2.6385892887589417
Validation loss: 2.506862416837756

Epoch: 5| Step: 10
Training loss: 2.21336743435768
Validation loss: 2.494513865847475

Epoch: 5| Step: 11
Training loss: 2.4045422922255533
Validation loss: 2.4900094881923835

Epoch: 217| Step: 0
Training loss: 2.2969318824004543
Validation loss: 2.495233529819294

Epoch: 5| Step: 1
Training loss: 1.8478076058266009
Validation loss: 2.492605064751467

Epoch: 5| Step: 2
Training loss: 2.656346756911933
Validation loss: 2.4961503947262655

Epoch: 5| Step: 3
Training loss: 2.43176867289613
Validation loss: 2.50287739151741

Epoch: 5| Step: 4
Training loss: 2.0907108397601815
Validation loss: 2.4957037667336195

Epoch: 5| Step: 5
Training loss: 2.607382647615736
Validation loss: 2.497771382395309

Epoch: 5| Step: 6
Training loss: 2.8048439088525665
Validation loss: 2.5096060656381924

Epoch: 5| Step: 7
Training loss: 2.733083714352827
Validation loss: 2.498642855076152

Epoch: 5| Step: 8
Training loss: 2.5863780772898037
Validation loss: 2.5065844808097513

Epoch: 5| Step: 9
Training loss: 2.4519372482235497
Validation loss: 2.480284768637978

Epoch: 5| Step: 10
Training loss: 2.5678474641341253
Validation loss: 2.490089992750678

Epoch: 5| Step: 11
Training loss: 1.560341985092728
Validation loss: 2.4877401928455836

Epoch: 218| Step: 0
Training loss: 1.9439925039445127
Validation loss: 2.4905154200514783

Epoch: 5| Step: 1
Training loss: 2.2775596136839704
Validation loss: 2.4815169635202885

Epoch: 5| Step: 2
Training loss: 3.4362574325597706
Validation loss: 2.4921820111348807

Epoch: 5| Step: 3
Training loss: 2.641652375753197
Validation loss: 2.5030892596985286

Epoch: 5| Step: 4
Training loss: 2.7315050158830814
Validation loss: 2.511062298980628

Epoch: 5| Step: 5
Training loss: 2.267141111124101
Validation loss: 2.504231416454395

Epoch: 5| Step: 6
Training loss: 2.426387201328148
Validation loss: 2.501984698542809

Epoch: 5| Step: 7
Training loss: 1.983719725062318
Validation loss: 2.496914393878516

Epoch: 5| Step: 8
Training loss: 1.7182720560173206
Validation loss: 2.4967218682315626

Epoch: 5| Step: 9
Training loss: 2.5020415553263855
Validation loss: 2.489231708599756

Epoch: 5| Step: 10
Training loss: 2.863808618459275
Validation loss: 2.4832718677295906

Epoch: 5| Step: 11
Training loss: 2.578599181061738
Validation loss: 2.475535563922643

Epoch: 219| Step: 0
Training loss: 2.3147191920839782
Validation loss: 2.4695279509262775

Epoch: 5| Step: 1
Training loss: 2.2407216454256544
Validation loss: 2.4734548009450905

Epoch: 5| Step: 2
Training loss: 2.229272631922292
Validation loss: 2.4770616174830944

Epoch: 5| Step: 3
Training loss: 2.229040540412947
Validation loss: 2.4782973549849485

Epoch: 5| Step: 4
Training loss: 2.5216557971176328
Validation loss: 2.4774784075196714

Epoch: 5| Step: 5
Training loss: 2.391124398920575
Validation loss: 2.473131641330499

Epoch: 5| Step: 6
Training loss: 2.851440928754833
Validation loss: 2.4756960391027145

Epoch: 5| Step: 7
Training loss: 2.1680118590871635
Validation loss: 2.4819945060804685

Epoch: 5| Step: 8
Training loss: 2.792885860466902
Validation loss: 2.496528328966396

Epoch: 5| Step: 9
Training loss: 2.6881762696099636
Validation loss: 2.5029329063502983

Epoch: 5| Step: 10
Training loss: 2.1103149580351586
Validation loss: 2.5038666307922273

Epoch: 5| Step: 11
Training loss: 2.6992592925851304
Validation loss: 2.5046926206844575

Epoch: 220| Step: 0
Training loss: 2.6864278562093253
Validation loss: 2.516995982440586

Epoch: 5| Step: 1
Training loss: 1.8506478412510767
Validation loss: 2.5315829654581035

Epoch: 5| Step: 2
Training loss: 2.0432583838817897
Validation loss: 2.5344477144872277

Epoch: 5| Step: 3
Training loss: 2.5812985394880963
Validation loss: 2.542505803234438

Epoch: 5| Step: 4
Training loss: 2.1538915590069583
Validation loss: 2.544099375720685

Epoch: 5| Step: 5
Training loss: 2.6309492723133845
Validation loss: 2.5459276321311672

Epoch: 5| Step: 6
Training loss: 1.955483317425701
Validation loss: 2.5388395553913634

Epoch: 5| Step: 7
Training loss: 2.4221334996243375
Validation loss: 2.5240388631995025

Epoch: 5| Step: 8
Training loss: 2.1174517814974094
Validation loss: 2.517383213750045

Epoch: 5| Step: 9
Training loss: 2.72498544811598
Validation loss: 2.5171744883994447

Epoch: 5| Step: 10
Training loss: 3.059004365097977
Validation loss: 2.526067054594737

Epoch: 5| Step: 11
Training loss: 1.9704282359074456
Validation loss: 2.5179810735448482

Epoch: 221| Step: 0
Training loss: 2.448843359888405
Validation loss: 2.5107015128929313

Epoch: 5| Step: 1
Training loss: 2.8196386657700256
Validation loss: 2.5085563744796353

Epoch: 5| Step: 2
Training loss: 2.6751433788627375
Validation loss: 2.521321589629748

Epoch: 5| Step: 3
Training loss: 2.605902365500152
Validation loss: 2.5306249168536046

Epoch: 5| Step: 4
Training loss: 2.1304639244794314
Validation loss: 2.542393062059316

Epoch: 5| Step: 5
Training loss: 2.080580902228162
Validation loss: 2.5346931892776086

Epoch: 5| Step: 6
Training loss: 2.3772554228862512
Validation loss: 2.5511081129781794

Epoch: 5| Step: 7
Training loss: 2.0364223649408775
Validation loss: 2.537909417094818

Epoch: 5| Step: 8
Training loss: 2.745273863814193
Validation loss: 2.5311761185966564

Epoch: 5| Step: 9
Training loss: 1.9631139220198728
Validation loss: 2.5323286348566025

Epoch: 5| Step: 10
Training loss: 2.388884565314981
Validation loss: 2.516870703594468

Epoch: 5| Step: 11
Training loss: 2.9234941045846177
Validation loss: 2.514122725659

Epoch: 222| Step: 0
Training loss: 3.0013483514205257
Validation loss: 2.5110983707823085

Epoch: 5| Step: 1
Training loss: 2.061765944738289
Validation loss: 2.5093221943114323

Epoch: 5| Step: 2
Training loss: 2.0095911126325983
Validation loss: 2.5101303805282558

Epoch: 5| Step: 3
Training loss: 2.6756348507224663
Validation loss: 2.497940713407714

Epoch: 5| Step: 4
Training loss: 3.0101176358678567
Validation loss: 2.498376354831537

Epoch: 5| Step: 5
Training loss: 2.312528558503186
Validation loss: 2.506303580861644

Epoch: 5| Step: 6
Training loss: 2.30862369937479
Validation loss: 2.5028755379588143

Epoch: 5| Step: 7
Training loss: 1.8473112336641073
Validation loss: 2.506271869487904

Epoch: 5| Step: 8
Training loss: 1.9347035315454317
Validation loss: 2.508599451962064

Epoch: 5| Step: 9
Training loss: 2.8523473208302423
Validation loss: 2.511103845991842

Epoch: 5| Step: 10
Training loss: 2.2000800118201713
Validation loss: 2.523460238485175

Epoch: 5| Step: 11
Training loss: 2.0212645185393847
Validation loss: 2.5283248860069922

Epoch: 223| Step: 0
Training loss: 1.9328619911315097
Validation loss: 2.5386682840128096

Epoch: 5| Step: 1
Training loss: 2.696949514197273
Validation loss: 2.54175231090981

Epoch: 5| Step: 2
Training loss: 2.7951024581609585
Validation loss: 2.542998786901229

Epoch: 5| Step: 3
Training loss: 2.1321950165337817
Validation loss: 2.5616208134441703

Epoch: 5| Step: 4
Training loss: 2.656027840692459
Validation loss: 2.565798069517595

Epoch: 5| Step: 5
Training loss: 2.4631726967859753
Validation loss: 2.564440976821315

Epoch: 5| Step: 6
Training loss: 2.521533732149091
Validation loss: 2.555443440934651

Epoch: 5| Step: 7
Training loss: 1.942132641239262
Validation loss: 2.5545572681265942

Epoch: 5| Step: 8
Training loss: 2.617364587059242
Validation loss: 2.5265504357453525

Epoch: 5| Step: 9
Training loss: 2.1040816966611264
Validation loss: 2.536540585593542

Epoch: 5| Step: 10
Training loss: 2.3332641000921455
Validation loss: 2.519600055553504

Epoch: 5| Step: 11
Training loss: 1.6286361799776454
Validation loss: 2.511977566544473

Epoch: 224| Step: 0
Training loss: 2.8302085325156545
Validation loss: 2.5075686525370613

Epoch: 5| Step: 1
Training loss: 1.8021215387017284
Validation loss: 2.5011071376236096

Epoch: 5| Step: 2
Training loss: 2.393880982961245
Validation loss: 2.5013310783065292

Epoch: 5| Step: 3
Training loss: 2.2535404324963855
Validation loss: 2.4988774203173514

Epoch: 5| Step: 4
Training loss: 2.191537346548011
Validation loss: 2.492472166985619

Epoch: 5| Step: 5
Training loss: 3.231742487846373
Validation loss: 2.5020291239710115

Epoch: 5| Step: 6
Training loss: 1.9502379174466398
Validation loss: 2.5059754762738407

Epoch: 5| Step: 7
Training loss: 1.9177662418151618
Validation loss: 2.5164287144122977

Epoch: 5| Step: 8
Training loss: 2.0090686712913413
Validation loss: 2.4905315386420432

Epoch: 5| Step: 9
Training loss: 2.796556763685198
Validation loss: 2.517970841474273

Epoch: 5| Step: 10
Training loss: 2.3249848970312343
Validation loss: 2.5233361427572008

Epoch: 5| Step: 11
Training loss: 2.55072563543052
Validation loss: 2.5322017156007415

Epoch: 225| Step: 0
Training loss: 2.4762600013034124
Validation loss: 2.5350305342888757

Epoch: 5| Step: 1
Training loss: 2.5755252561669453
Validation loss: 2.532235805241078

Epoch: 5| Step: 2
Training loss: 2.26251322705528
Validation loss: 2.54431308228403

Epoch: 5| Step: 3
Training loss: 2.6121163958133833
Validation loss: 2.5588117045590772

Epoch: 5| Step: 4
Training loss: 2.3052155487825594
Validation loss: 2.5462562378869533

Epoch: 5| Step: 5
Training loss: 2.187462179674452
Validation loss: 2.5412202244965827

Epoch: 5| Step: 6
Training loss: 2.78724281937898
Validation loss: 2.555998925405574

Epoch: 5| Step: 7
Training loss: 2.2532373027352763
Validation loss: 2.5401418220983323

Epoch: 5| Step: 8
Training loss: 2.7752225047767407
Validation loss: 2.5268329338014874

Epoch: 5| Step: 9
Training loss: 2.137855464535349
Validation loss: 2.522834264815014

Epoch: 5| Step: 10
Training loss: 1.7430311820195041
Validation loss: 2.515131382660984

Epoch: 5| Step: 11
Training loss: 1.8603224063701163
Validation loss: 2.5257860401759853

Epoch: 226| Step: 0
Training loss: 2.5042845251325985
Validation loss: 2.5074939466043964

Epoch: 5| Step: 1
Training loss: 2.164726733786557
Validation loss: 2.520755417200253

Epoch: 5| Step: 2
Training loss: 2.2999651615987298
Validation loss: 2.5425582452839737

Epoch: 5| Step: 3
Training loss: 2.783572909234053
Validation loss: 2.5519757475201326

Epoch: 5| Step: 4
Training loss: 1.9310853042251173
Validation loss: 2.5413379039656587

Epoch: 5| Step: 5
Training loss: 2.617998959587013
Validation loss: 2.5408217199505767

Epoch: 5| Step: 6
Training loss: 2.091451835491768
Validation loss: 2.5566260072947395

Epoch: 5| Step: 7
Training loss: 2.274146005665474
Validation loss: 2.5459938124124255

Epoch: 5| Step: 8
Training loss: 2.408682547289481
Validation loss: 2.5543133289573174

Epoch: 5| Step: 9
Training loss: 2.4166586535967696
Validation loss: 2.524844990589577

Epoch: 5| Step: 10
Training loss: 2.7471310649165592
Validation loss: 2.535887038315849

Epoch: 5| Step: 11
Training loss: 0.9855895648167008
Validation loss: 2.5192684618108214

Epoch: 227| Step: 0
Training loss: 2.8409931947223135
Validation loss: 2.5143524608064887

Epoch: 5| Step: 1
Training loss: 2.0521464717336757
Validation loss: 2.5203485705858486

Epoch: 5| Step: 2
Training loss: 2.0568477747276535
Validation loss: 2.5280234018979977

Epoch: 5| Step: 3
Training loss: 1.9276858925640934
Validation loss: 2.5189916658855487

Epoch: 5| Step: 4
Training loss: 2.733607157118049
Validation loss: 2.5330620194279776

Epoch: 5| Step: 5
Training loss: 2.35433016409029
Validation loss: 2.53865843663335

Epoch: 5| Step: 6
Training loss: 2.399677266832945
Validation loss: 2.5310822301767666

Epoch: 5| Step: 7
Training loss: 2.453364658190284
Validation loss: 2.5265958446849393

Epoch: 5| Step: 8
Training loss: 2.5383774992452004
Validation loss: 2.5343960335858613

Epoch: 5| Step: 9
Training loss: 2.1882778419650584
Validation loss: 2.526024341851564

Epoch: 5| Step: 10
Training loss: 2.440642458649344
Validation loss: 2.536797872189935

Epoch: 5| Step: 11
Training loss: 1.7112834702556057
Validation loss: 2.5251263693859975

Epoch: 228| Step: 0
Training loss: 2.4499473643974214
Validation loss: 2.5254914985684334

Epoch: 5| Step: 1
Training loss: 2.2871058306841667
Validation loss: 2.528414712093704

Epoch: 5| Step: 2
Training loss: 2.7356203567503825
Validation loss: 2.5278099923182915

Epoch: 5| Step: 3
Training loss: 1.9012052352420663
Validation loss: 2.5369507600784655

Epoch: 5| Step: 4
Training loss: 2.490977791912695
Validation loss: 2.5271348626170953

Epoch: 5| Step: 5
Training loss: 1.8978362210501547
Validation loss: 2.5288893716268723

Epoch: 5| Step: 6
Training loss: 2.7142835738955213
Validation loss: 2.5363406102448796

Epoch: 5| Step: 7
Training loss: 1.871638718405151
Validation loss: 2.541310935583798

Epoch: 5| Step: 8
Training loss: 2.3141050181581426
Validation loss: 2.5334462147480434

Epoch: 5| Step: 9
Training loss: 2.7640231391170045
Validation loss: 2.553637968519749

Epoch: 5| Step: 10
Training loss: 2.4968421064938693
Validation loss: 2.5654042734843556

Epoch: 5| Step: 11
Training loss: 1.6715951845828598
Validation loss: 2.5548909851912462

Epoch: 229| Step: 0
Training loss: 2.2620495173855066
Validation loss: 2.542437316711975

Epoch: 5| Step: 1
Training loss: 2.511348809842242
Validation loss: 2.5441448345761564

Epoch: 5| Step: 2
Training loss: 2.36358691043738
Validation loss: 2.524795926380024

Epoch: 5| Step: 3
Training loss: 2.465823406557465
Validation loss: 2.5109142559552646

Epoch: 5| Step: 4
Training loss: 2.474441631024151
Validation loss: 2.5180062067423994

Epoch: 5| Step: 5
Training loss: 2.417440378268492
Validation loss: 2.5170034813703395

Epoch: 5| Step: 6
Training loss: 2.533115029549524
Validation loss: 2.5124570632542755

Epoch: 5| Step: 7
Training loss: 1.7765658174750523
Validation loss: 2.514754035979335

Epoch: 5| Step: 8
Training loss: 2.291231657413665
Validation loss: 2.513125190478709

Epoch: 5| Step: 9
Training loss: 2.865032664806835
Validation loss: 2.522437626830292

Epoch: 5| Step: 10
Training loss: 1.8956349726715527
Validation loss: 2.5117370660172376

Epoch: 5| Step: 11
Training loss: 1.7016501383985965
Validation loss: 2.5318979878144385

Epoch: 230| Step: 0
Training loss: 2.555059843314336
Validation loss: 2.521368357468666

Epoch: 5| Step: 1
Training loss: 2.335546148172136
Validation loss: 2.5321335957530926

Epoch: 5| Step: 2
Training loss: 2.292167354565423
Validation loss: 2.5331266691169603

Epoch: 5| Step: 3
Training loss: 2.3078397239158916
Validation loss: 2.543575400062833

Epoch: 5| Step: 4
Training loss: 2.826472015366489
Validation loss: 2.554618356218139

Epoch: 5| Step: 5
Training loss: 2.2008774568101286
Validation loss: 2.5376985221714685

Epoch: 5| Step: 6
Training loss: 2.429682986141808
Validation loss: 2.532627758997326

Epoch: 5| Step: 7
Training loss: 1.8736326954305837
Validation loss: 2.522157058793646

Epoch: 5| Step: 8
Training loss: 2.2800111934320175
Validation loss: 2.5092314630408827

Epoch: 5| Step: 9
Training loss: 2.7134046953206923
Validation loss: 2.5088205500124383

Epoch: 5| Step: 10
Training loss: 2.133810068546489
Validation loss: 2.5123492290561162

Epoch: 5| Step: 11
Training loss: 3.261637320044539
Validation loss: 2.5044329203911517

Epoch: 231| Step: 0
Training loss: 2.5046202880827235
Validation loss: 2.5091094310782167

Epoch: 5| Step: 1
Training loss: 1.8613595069249185
Validation loss: 2.51185226678824

Epoch: 5| Step: 2
Training loss: 2.4908100973581013
Validation loss: 2.5171610918638962

Epoch: 5| Step: 3
Training loss: 2.427802529149443
Validation loss: 2.5108841319684467

Epoch: 5| Step: 4
Training loss: 2.5068047420877466
Validation loss: 2.5077908912115925

Epoch: 5| Step: 5
Training loss: 2.5667840456028777
Validation loss: 2.5192882883979966

Epoch: 5| Step: 6
Training loss: 2.269912136242768
Validation loss: 2.51575396189453

Epoch: 5| Step: 7
Training loss: 2.4353723287557467
Validation loss: 2.5111683607842825

Epoch: 5| Step: 8
Training loss: 2.739448940524663
Validation loss: 2.509809750417674

Epoch: 5| Step: 9
Training loss: 1.7448006093569413
Validation loss: 2.516343849258778

Epoch: 5| Step: 10
Training loss: 2.339344512716335
Validation loss: 2.5113497592067153

Epoch: 5| Step: 11
Training loss: 2.3316806548841726
Validation loss: 2.5145830006402994

Epoch: 232| Step: 0
Training loss: 1.8279462547623446
Validation loss: 2.5155276877968995

Epoch: 5| Step: 1
Training loss: 2.466876514203361
Validation loss: 2.5163258470719616

Epoch: 5| Step: 2
Training loss: 2.415371635543248
Validation loss: 2.52354375027006

Epoch: 5| Step: 3
Training loss: 1.8893043382196981
Validation loss: 2.531170219765356

Epoch: 5| Step: 4
Training loss: 2.14263576544789
Validation loss: 2.539632508289716

Epoch: 5| Step: 5
Training loss: 2.748346438479789
Validation loss: 2.534738836422705

Epoch: 5| Step: 6
Training loss: 2.8816352239172645
Validation loss: 2.528100094635222

Epoch: 5| Step: 7
Training loss: 2.1708368248890078
Validation loss: 2.511954660841204

Epoch: 5| Step: 8
Training loss: 2.236943615833327
Validation loss: 2.5189292287045615

Epoch: 5| Step: 9
Training loss: 2.465423467447394
Validation loss: 2.51463485565962

Epoch: 5| Step: 10
Training loss: 2.641378983517949
Validation loss: 2.5198211246885385

Epoch: 5| Step: 11
Training loss: 1.2832405166171517
Validation loss: 2.5125094603365152

Epoch: 233| Step: 0
Training loss: 2.5590710842609545
Validation loss: 2.5123383947688986

Epoch: 5| Step: 1
Training loss: 2.0293397577654435
Validation loss: 2.5103596975001365

Epoch: 5| Step: 2
Training loss: 2.4488772408188586
Validation loss: 2.521779557966368

Epoch: 5| Step: 3
Training loss: 2.8789471606553003
Validation loss: 2.5361286134407224

Epoch: 5| Step: 4
Training loss: 2.1182910253270104
Validation loss: 2.5164259233863366

Epoch: 5| Step: 5
Training loss: 2.366432799841777
Validation loss: 2.503323709900751

Epoch: 5| Step: 6
Training loss: 2.652898401798933
Validation loss: 2.5084106508380586

Epoch: 5| Step: 7
Training loss: 1.4965782078356544
Validation loss: 2.5060975974177664

Epoch: 5| Step: 8
Training loss: 2.6222822561863204
Validation loss: 2.491660587570234

Epoch: 5| Step: 9
Training loss: 2.2679955018686835
Validation loss: 2.503492153480494

Epoch: 5| Step: 10
Training loss: 2.1153690651008614
Validation loss: 2.5034449822461604

Epoch: 5| Step: 11
Training loss: 2.573154814248377
Validation loss: 2.5067023972480387

Epoch: 234| Step: 0
Training loss: 2.2928097619431207
Validation loss: 2.5215154754745726

Epoch: 5| Step: 1
Training loss: 2.5350978474289345
Validation loss: 2.5260486930408614

Epoch: 5| Step: 2
Training loss: 2.2710326804291903
Validation loss: 2.562082915749368

Epoch: 5| Step: 3
Training loss: 2.1211119593054706
Validation loss: 2.5714224647835473

Epoch: 5| Step: 4
Training loss: 2.4459088363127885
Validation loss: 2.5733783451856036

Epoch: 5| Step: 5
Training loss: 2.719927828616653
Validation loss: 2.5736023276281457

Epoch: 5| Step: 6
Training loss: 1.9468454961852637
Validation loss: 2.547618967933976

Epoch: 5| Step: 7
Training loss: 2.4570535680002887
Validation loss: 2.5349355051951745

Epoch: 5| Step: 8
Training loss: 2.331407319761437
Validation loss: 2.5138822999508417

Epoch: 5| Step: 9
Training loss: 2.637400266379773
Validation loss: 2.4899350054938503

Epoch: 5| Step: 10
Training loss: 2.1698759470696447
Validation loss: 2.4890483530125045

Epoch: 5| Step: 11
Training loss: 3.353027877040969
Validation loss: 2.4926648933354683

Epoch: 235| Step: 0
Training loss: 2.398457679290874
Validation loss: 2.4855243695231555

Epoch: 5| Step: 1
Training loss: 2.258406511460747
Validation loss: 2.4889585370712175

Epoch: 5| Step: 2
Training loss: 2.676576103714791
Validation loss: 2.4912088001121924

Epoch: 5| Step: 3
Training loss: 2.244105565367455
Validation loss: 2.4879418964626163

Epoch: 5| Step: 4
Training loss: 2.2927646318658637
Validation loss: 2.482514582517832

Epoch: 5| Step: 5
Training loss: 2.616687966116293
Validation loss: 2.4938181980148557

Epoch: 5| Step: 6
Training loss: 2.2121445020001502
Validation loss: 2.494451708052646

Epoch: 5| Step: 7
Training loss: 2.47176765758604
Validation loss: 2.517339820917944

Epoch: 5| Step: 8
Training loss: 2.0859349854414853
Validation loss: 2.5258410003765572

Epoch: 5| Step: 9
Training loss: 2.198622302521351
Validation loss: 2.5329670772806208

Epoch: 5| Step: 10
Training loss: 2.733495690788416
Validation loss: 2.531402602913524

Epoch: 5| Step: 11
Training loss: 2.108346532948705
Validation loss: 2.533854463321764

Epoch: 236| Step: 0
Training loss: 2.1398144600553373
Validation loss: 2.5500914812819757

Epoch: 5| Step: 1
Training loss: 2.1023172490984643
Validation loss: 2.5480264545429248

Epoch: 5| Step: 2
Training loss: 2.0977309229681964
Validation loss: 2.551162589963621

Epoch: 5| Step: 3
Training loss: 2.770125095420964
Validation loss: 2.565399700251399

Epoch: 5| Step: 4
Training loss: 2.4622982078013713
Validation loss: 2.5713179978228697

Epoch: 5| Step: 5
Training loss: 2.3872227612650345
Validation loss: 2.566952748322079

Epoch: 5| Step: 6
Training loss: 2.3690460261667945
Validation loss: 2.5534548104035224

Epoch: 5| Step: 7
Training loss: 2.043343795865744
Validation loss: 2.5387834874932036

Epoch: 5| Step: 8
Training loss: 2.058472371006535
Validation loss: 2.533413990257205

Epoch: 5| Step: 9
Training loss: 3.042285769089693
Validation loss: 2.5337571710028075

Epoch: 5| Step: 10
Training loss: 2.239504281948022
Validation loss: 2.507463999426726

Epoch: 5| Step: 11
Training loss: 2.4928336426965823
Validation loss: 2.5182059259667056

Epoch: 237| Step: 0
Training loss: 2.4030294292678245
Validation loss: 2.507418759057777

Epoch: 5| Step: 1
Training loss: 2.3778072631152596
Validation loss: 2.4794198489269745

Epoch: 5| Step: 2
Training loss: 3.0408448628898475
Validation loss: 2.5034946930632693

Epoch: 5| Step: 3
Training loss: 1.8989357628024177
Validation loss: 2.4894959196335757

Epoch: 5| Step: 4
Training loss: 2.2919132331216114
Validation loss: 2.496745056921569

Epoch: 5| Step: 5
Training loss: 2.8840114509048322
Validation loss: 2.4889029540138052

Epoch: 5| Step: 6
Training loss: 2.7451054624716247
Validation loss: 2.492084401388811

Epoch: 5| Step: 7
Training loss: 2.1125105547218066
Validation loss: 2.4871355829764803

Epoch: 5| Step: 8
Training loss: 2.764321402526719
Validation loss: 2.483134033752544

Epoch: 5| Step: 9
Training loss: 1.8221642240091953
Validation loss: 2.4857773491666597

Epoch: 5| Step: 10
Training loss: 2.2189336351507607
Validation loss: 2.4887500083855643

Epoch: 5| Step: 11
Training loss: 0.7183256970093356
Validation loss: 2.490104751703869

Epoch: 238| Step: 0
Training loss: 1.5965928546964008
Validation loss: 2.507312788251645

Epoch: 5| Step: 1
Training loss: 2.872705788142435
Validation loss: 2.4977462464379054

Epoch: 5| Step: 2
Training loss: 2.25200807185107
Validation loss: 2.5307190813166

Epoch: 5| Step: 3
Training loss: 2.2766143520631728
Validation loss: 2.5404145186831606

Epoch: 5| Step: 4
Training loss: 2.5265353529868877
Validation loss: 2.5506607969701416

Epoch: 5| Step: 5
Training loss: 2.6543786132442997
Validation loss: 2.534814310941248

Epoch: 5| Step: 6
Training loss: 2.2429699745294465
Validation loss: 2.5400541432935304

Epoch: 5| Step: 7
Training loss: 2.5135197330365755
Validation loss: 2.540155752499165

Epoch: 5| Step: 8
Training loss: 2.522490994122613
Validation loss: 2.5236992400079337

Epoch: 5| Step: 9
Training loss: 2.2969295988275773
Validation loss: 2.5234392046061487

Epoch: 5| Step: 10
Training loss: 2.417434460797938
Validation loss: 2.5004347741042894

Epoch: 5| Step: 11
Training loss: 2.17438137420834
Validation loss: 2.5044260839303143

Epoch: 239| Step: 0
Training loss: 1.9903978873965347
Validation loss: 2.5085215650524555

Epoch: 5| Step: 1
Training loss: 2.3051858654096575
Validation loss: 2.4984604028698163

Epoch: 5| Step: 2
Training loss: 2.7902636252382385
Validation loss: 2.495859705260794

Epoch: 5| Step: 3
Training loss: 2.0159081548477693
Validation loss: 2.4885955923397804

Epoch: 5| Step: 4
Training loss: 2.2027394924655708
Validation loss: 2.511639417282384

Epoch: 5| Step: 5
Training loss: 2.0860700815192583
Validation loss: 2.502730459995422

Epoch: 5| Step: 6
Training loss: 2.4253454139342896
Validation loss: 2.507168791205573

Epoch: 5| Step: 7
Training loss: 2.5768409074280902
Validation loss: 2.5252452591167778

Epoch: 5| Step: 8
Training loss: 3.0170106224553304
Validation loss: 2.504713240864225

Epoch: 5| Step: 9
Training loss: 2.035230521752355
Validation loss: 2.5314077830490023

Epoch: 5| Step: 10
Training loss: 2.4641563073530603
Validation loss: 2.5352656375618534

Epoch: 5| Step: 11
Training loss: 2.913932081479607
Validation loss: 2.5375709456436994

Epoch: 240| Step: 0
Training loss: 2.5567037576059715
Validation loss: 2.523068283910775

Epoch: 5| Step: 1
Training loss: 2.202837877975655
Validation loss: 2.520094376356597

Epoch: 5| Step: 2
Training loss: 1.8601830273478883
Validation loss: 2.504110120705085

Epoch: 5| Step: 3
Training loss: 2.0762735020767438
Validation loss: 2.5071430501144034

Epoch: 5| Step: 4
Training loss: 2.3501502577448683
Validation loss: 2.5134771114005603

Epoch: 5| Step: 5
Training loss: 2.3814755550702116
Validation loss: 2.51723013190001

Epoch: 5| Step: 6
Training loss: 2.0856284151858087
Validation loss: 2.5226008954457306

Epoch: 5| Step: 7
Training loss: 2.230265218931897
Validation loss: 2.5218920546801527

Epoch: 5| Step: 8
Training loss: 2.658029296931689
Validation loss: 2.5174157460448097

Epoch: 5| Step: 9
Training loss: 2.406479168172233
Validation loss: 2.507272141215094

Epoch: 5| Step: 10
Training loss: 2.876307646212272
Validation loss: 2.5206059591089813

Epoch: 5| Step: 11
Training loss: 3.1331750369837192
Validation loss: 2.540585132738088

Epoch: 241| Step: 0
Training loss: 2.555189730771807
Validation loss: 2.5209531414050668

Epoch: 5| Step: 1
Training loss: 2.054187438220172
Validation loss: 2.501555376203545

Epoch: 5| Step: 2
Training loss: 2.0654177978750576
Validation loss: 2.479163678084637

Epoch: 5| Step: 3
Training loss: 2.4878789795147647
Validation loss: 2.4824905265961568

Epoch: 5| Step: 4
Training loss: 2.512734120406928
Validation loss: 2.481241305133437

Epoch: 5| Step: 5
Training loss: 2.528200926896004
Validation loss: 2.4719502835839977

Epoch: 5| Step: 6
Training loss: 1.9232928620658154
Validation loss: 2.4671821927574626

Epoch: 5| Step: 7
Training loss: 2.6076489067534254
Validation loss: 2.482950201871271

Epoch: 5| Step: 8
Training loss: 2.622256798390524
Validation loss: 2.4686164497918797

Epoch: 5| Step: 9
Training loss: 2.0748223469990017
Validation loss: 2.4797774325213338

Epoch: 5| Step: 10
Training loss: 2.5734929869181773
Validation loss: 2.485034031497436

Epoch: 5| Step: 11
Training loss: 2.992727365421086
Validation loss: 2.4740892047732963

Epoch: 242| Step: 0
Training loss: 2.4815831842294234
Validation loss: 2.4926691576414814

Epoch: 5| Step: 1
Training loss: 2.3464553478129058
Validation loss: 2.488850083898938

Epoch: 5| Step: 2
Training loss: 2.6212157265128355
Validation loss: 2.481611370128597

Epoch: 5| Step: 3
Training loss: 1.8555239378100221
Validation loss: 2.504664266172749

Epoch: 5| Step: 4
Training loss: 2.723622833266498
Validation loss: 2.5012144754858823

Epoch: 5| Step: 5
Training loss: 2.067414410997891
Validation loss: 2.4924347853474935

Epoch: 5| Step: 6
Training loss: 1.7145986186289053
Validation loss: 2.5179270129443894

Epoch: 5| Step: 7
Training loss: 2.3699045231254505
Validation loss: 2.5121646839226734

Epoch: 5| Step: 8
Training loss: 3.011973646091708
Validation loss: 2.499071214921556

Epoch: 5| Step: 9
Training loss: 2.498129621839793
Validation loss: 2.4912777977333795

Epoch: 5| Step: 10
Training loss: 2.1048953491075464
Validation loss: 2.4966079588210937

Epoch: 5| Step: 11
Training loss: 2.6141329576262384
Validation loss: 2.4945341440549003

Epoch: 243| Step: 0
Training loss: 2.5084555683789764
Validation loss: 2.487294686692612

Epoch: 5| Step: 1
Training loss: 2.0176258653899217
Validation loss: 2.4877134480743397

Epoch: 5| Step: 2
Training loss: 2.117207882490967
Validation loss: 2.4881385351082943

Epoch: 5| Step: 3
Training loss: 1.7853338040590319
Validation loss: 2.490476788458917

Epoch: 5| Step: 4
Training loss: 2.0618079209206166
Validation loss: 2.478235311566434

Epoch: 5| Step: 5
Training loss: 2.565708756560735
Validation loss: 2.4898787739491466

Epoch: 5| Step: 6
Training loss: 2.1301989069374896
Validation loss: 2.4947267907506716

Epoch: 5| Step: 7
Training loss: 2.2782706048009205
Validation loss: 2.5115813063950196

Epoch: 5| Step: 8
Training loss: 2.4782933104651947
Validation loss: 2.509299790904961

Epoch: 5| Step: 9
Training loss: 3.023625804153027
Validation loss: 2.5171124580322033

Epoch: 5| Step: 10
Training loss: 2.53738225654321
Validation loss: 2.5251615282205804

Epoch: 5| Step: 11
Training loss: 2.717437953714417
Validation loss: 2.5428666789190895

Epoch: 244| Step: 0
Training loss: 1.8882457800845418
Validation loss: 2.5336759778391893

Epoch: 5| Step: 1
Training loss: 2.2384215305967095
Validation loss: 2.5413735499498045

Epoch: 5| Step: 2
Training loss: 1.9157402315066199
Validation loss: 2.5287745345128045

Epoch: 5| Step: 3
Training loss: 2.564132356592862
Validation loss: 2.520433391549818

Epoch: 5| Step: 4
Training loss: 2.3392643027953297
Validation loss: 2.507063170416368

Epoch: 5| Step: 5
Training loss: 1.9376834044250628
Validation loss: 2.491953485039211

Epoch: 5| Step: 6
Training loss: 2.153580049173525
Validation loss: 2.4993188963375004

Epoch: 5| Step: 7
Training loss: 1.9481182776033144
Validation loss: 2.514298916818559

Epoch: 5| Step: 8
Training loss: 3.1554384604594308
Validation loss: 2.507208522664275

Epoch: 5| Step: 9
Training loss: 2.822333037419377
Validation loss: 2.501409268535949

Epoch: 5| Step: 10
Training loss: 2.133406783369364
Validation loss: 2.5068614974760313

Epoch: 5| Step: 11
Training loss: 4.190669895418068
Validation loss: 2.5132063657169796

Epoch: 245| Step: 0
Training loss: 2.1739985561137947
Validation loss: 2.5078027473489826

Epoch: 5| Step: 1
Training loss: 2.4226580922729615
Validation loss: 2.5086325436624612

Epoch: 5| Step: 2
Training loss: 2.3846605482391765
Validation loss: 2.527866728030391

Epoch: 5| Step: 3
Training loss: 2.0680835168896854
Validation loss: 2.5085425854105097

Epoch: 5| Step: 4
Training loss: 2.5263898367026867
Validation loss: 2.516706040897522

Epoch: 5| Step: 5
Training loss: 2.5085409182031615
Validation loss: 2.5271641757379797

Epoch: 5| Step: 6
Training loss: 2.0441594638171416
Validation loss: 2.5312654667448493

Epoch: 5| Step: 7
Training loss: 2.7313036426714734
Validation loss: 2.532848622564375

Epoch: 5| Step: 8
Training loss: 2.5318524620919414
Validation loss: 2.531435017829343

Epoch: 5| Step: 9
Training loss: 2.1338802361814317
Validation loss: 2.536270927122265

Epoch: 5| Step: 10
Training loss: 2.157406151455411
Validation loss: 2.532271175283306

Epoch: 5| Step: 11
Training loss: 2.5797250117642427
Validation loss: 2.5133100089610716

Epoch: 246| Step: 0
Training loss: 1.6546378296627555
Validation loss: 2.5182870202715275

Epoch: 5| Step: 1
Training loss: 2.438155648499208
Validation loss: 2.4939557681363786

Epoch: 5| Step: 2
Training loss: 2.5968922344788083
Validation loss: 2.4901795265290882

Epoch: 5| Step: 3
Training loss: 2.983848005969723
Validation loss: 2.489668594613527

Epoch: 5| Step: 4
Training loss: 2.953548663393114
Validation loss: 2.483215841345086

Epoch: 5| Step: 5
Training loss: 2.1882759897699295
Validation loss: 2.4843969324131487

Epoch: 5| Step: 6
Training loss: 2.3872534220122974
Validation loss: 2.4965257066928253

Epoch: 5| Step: 7
Training loss: 1.9544271172191627
Validation loss: 2.475426434376333

Epoch: 5| Step: 8
Training loss: 2.6480214740251244
Validation loss: 2.4944355231958406

Epoch: 5| Step: 9
Training loss: 2.2879575594853914
Validation loss: 2.4934634407339664

Epoch: 5| Step: 10
Training loss: 2.0974767739575233
Validation loss: 2.5120217598827606

Epoch: 5| Step: 11
Training loss: 1.5331077205836543
Validation loss: 2.5238949072773513

Epoch: 247| Step: 0
Training loss: 2.0289133570461777
Validation loss: 2.5197515898964857

Epoch: 5| Step: 1
Training loss: 2.732737808559096
Validation loss: 2.531255792681812

Epoch: 5| Step: 2
Training loss: 2.572856814863357
Validation loss: 2.5479785735957616

Epoch: 5| Step: 3
Training loss: 2.1465316919972404
Validation loss: 2.5313666320743344

Epoch: 5| Step: 4
Training loss: 2.3646494538281453
Validation loss: 2.5346910376060237

Epoch: 5| Step: 5
Training loss: 2.370797102594898
Validation loss: 2.5368167472530057

Epoch: 5| Step: 6
Training loss: 2.0614253625711654
Validation loss: 2.515449028099742

Epoch: 5| Step: 7
Training loss: 2.7720401306164906
Validation loss: 2.488452687887614

Epoch: 5| Step: 8
Training loss: 1.9106456543090233
Validation loss: 2.492596571781856

Epoch: 5| Step: 9
Training loss: 2.891910411518149
Validation loss: 2.4974862295476914

Epoch: 5| Step: 10
Training loss: 2.4076330000444073
Validation loss: 2.492671327652348

Epoch: 5| Step: 11
Training loss: 1.8045059707301827
Validation loss: 2.4995127878685466

Epoch: 248| Step: 0
Training loss: 2.086434637256685
Validation loss: 2.499664653697994

Epoch: 5| Step: 1
Training loss: 2.8547789944757205
Validation loss: 2.510525104876836

Epoch: 5| Step: 2
Training loss: 2.6780353936213253
Validation loss: 2.5136420389700356

Epoch: 5| Step: 3
Training loss: 2.2201656070146663
Validation loss: 2.512059755645451

Epoch: 5| Step: 4
Training loss: 2.7653254115022783
Validation loss: 2.514905731963707

Epoch: 5| Step: 5
Training loss: 2.1897935015724217
Validation loss: 2.5090018786364663

Epoch: 5| Step: 6
Training loss: 1.86328208171578
Validation loss: 2.510234878943806

Epoch: 5| Step: 7
Training loss: 2.3032329559904587
Validation loss: 2.510772289450287

Epoch: 5| Step: 8
Training loss: 2.513961431488162
Validation loss: 2.5148303314890685

Epoch: 5| Step: 9
Training loss: 2.3888992363560257
Validation loss: 2.5169488965447817

Epoch: 5| Step: 10
Training loss: 2.1648020668380807
Validation loss: 2.525889293099425

Epoch: 5| Step: 11
Training loss: 1.8260990230288001
Validation loss: 2.525147715739159

Epoch: 249| Step: 0
Training loss: 2.60721265546379
Validation loss: 2.532210748546851

Epoch: 5| Step: 1
Training loss: 2.2611694723101414
Validation loss: 2.5376222252183958

Epoch: 5| Step: 2
Training loss: 2.4445419316166634
Validation loss: 2.528328984082261

Epoch: 5| Step: 3
Training loss: 2.5444468525519306
Validation loss: 2.5416471540504593

Epoch: 5| Step: 4
Training loss: 2.564100556495076
Validation loss: 2.5408848604983145

Epoch: 5| Step: 5
Training loss: 2.0226726485641495
Validation loss: 2.5342406905616253

Epoch: 5| Step: 6
Training loss: 2.707917215707534
Validation loss: 2.5322950034915266

Epoch: 5| Step: 7
Training loss: 1.7596812847219405
Validation loss: 2.5305663272660044

Epoch: 5| Step: 8
Training loss: 1.7945499138532053
Validation loss: 2.5285958358164224

Epoch: 5| Step: 9
Training loss: 2.3439093980627543
Validation loss: 2.519445042281224

Epoch: 5| Step: 10
Training loss: 2.266670038650847
Validation loss: 2.5148976500637503

Epoch: 5| Step: 11
Training loss: 3.176666549276995
Validation loss: 2.507883762127494

Epoch: 250| Step: 0
Training loss: 2.5470687698887287
Validation loss: 2.5025822535629545

Epoch: 5| Step: 1
Training loss: 2.1959812869679975
Validation loss: 2.506031017614351

Epoch: 5| Step: 2
Training loss: 2.7012448690596065
Validation loss: 2.500778522070879

Epoch: 5| Step: 3
Training loss: 2.138758381526717
Validation loss: 2.5103379444320906

Epoch: 5| Step: 4
Training loss: 1.64057370060237
Validation loss: 2.5048040525114357

Epoch: 5| Step: 5
Training loss: 2.793497785068588
Validation loss: 2.4979565613789836

Epoch: 5| Step: 6
Training loss: 2.2573993661276153
Validation loss: 2.51067665278675

Epoch: 5| Step: 7
Training loss: 2.392111222778392
Validation loss: 2.4996706070066654

Epoch: 5| Step: 8
Training loss: 2.155556608748206
Validation loss: 2.511997035437098

Epoch: 5| Step: 9
Training loss: 2.5657167481014027
Validation loss: 2.5125777148726645

Epoch: 5| Step: 10
Training loss: 2.4022230660743578
Validation loss: 2.5161499044461335

Epoch: 5| Step: 11
Training loss: 2.6028371443390714
Validation loss: 2.528565957837297

Epoch: 251| Step: 0
Training loss: 1.6353560353437429
Validation loss: 2.523690123456296

Epoch: 5| Step: 1
Training loss: 1.947623416089848
Validation loss: 2.52646002828053

Epoch: 5| Step: 2
Training loss: 2.8149791387459175
Validation loss: 2.545330335891395

Epoch: 5| Step: 3
Training loss: 2.2482147551821425
Validation loss: 2.5302285382178784

Epoch: 5| Step: 4
Training loss: 2.700657506639849
Validation loss: 2.5276848132000964

Epoch: 5| Step: 5
Training loss: 2.8332257717883658
Validation loss: 2.517077640635833

Epoch: 5| Step: 6
Training loss: 3.0111141958686196
Validation loss: 2.5219475921242123

Epoch: 5| Step: 7
Training loss: 1.6239777797719757
Validation loss: 2.5225280721278818

Epoch: 5| Step: 8
Training loss: 1.8435458054052243
Validation loss: 2.522969126661263

Epoch: 5| Step: 9
Training loss: 2.0555796263834765
Validation loss: 2.518698585780628

Epoch: 5| Step: 10
Training loss: 2.56620613606941
Validation loss: 2.529042120909206

Epoch: 5| Step: 11
Training loss: 1.930592066223668
Validation loss: 2.526798580592014

Epoch: 252| Step: 0
Training loss: 1.620015643008965
Validation loss: 2.5454245183410125

Epoch: 5| Step: 1
Training loss: 2.6943230181028603
Validation loss: 2.5352237341724897

Epoch: 5| Step: 2
Training loss: 2.5282124319153074
Validation loss: 2.5348023773537274

Epoch: 5| Step: 3
Training loss: 1.742223970176886
Validation loss: 2.552761985436859

Epoch: 5| Step: 4
Training loss: 2.730078673434315
Validation loss: 2.5224938532638137

Epoch: 5| Step: 5
Training loss: 2.1432967393558338
Validation loss: 2.554583458915744

Epoch: 5| Step: 6
Training loss: 2.3184368117398666
Validation loss: 2.546314774664546

Epoch: 5| Step: 7
Training loss: 2.3123486443552923
Validation loss: 2.5557012189652517

Epoch: 5| Step: 8
Training loss: 2.7933170128150566
Validation loss: 2.5544793533161068

Epoch: 5| Step: 9
Training loss: 2.403691306188625
Validation loss: 2.5537133260002176

Epoch: 5| Step: 10
Training loss: 1.8471179524808905
Validation loss: 2.541817079585606

Epoch: 5| Step: 11
Training loss: 3.4638133618862095
Validation loss: 2.5421044853300434

Epoch: 253| Step: 0
Training loss: 2.127643175518471
Validation loss: 2.5401239103533277

Epoch: 5| Step: 1
Training loss: 1.6595870175305973
Validation loss: 2.561773034230556

Epoch: 5| Step: 2
Training loss: 2.2978716913031465
Validation loss: 2.5540762217616813

Epoch: 5| Step: 3
Training loss: 3.082338963221257
Validation loss: 2.5361623075618693

Epoch: 5| Step: 4
Training loss: 1.8608784087285617
Validation loss: 2.5406718078905928

Epoch: 5| Step: 5
Training loss: 2.9768936093213445
Validation loss: 2.5419043419404965

Epoch: 5| Step: 6
Training loss: 2.0883182269760425
Validation loss: 2.5317437078993494

Epoch: 5| Step: 7
Training loss: 2.6326022191502654
Validation loss: 2.5350674817924204

Epoch: 5| Step: 8
Training loss: 2.123714506987684
Validation loss: 2.5352469978097822

Epoch: 5| Step: 9
Training loss: 2.011899595557636
Validation loss: 2.544197028087534

Epoch: 5| Step: 10
Training loss: 2.3452979507350804
Validation loss: 2.5392096335011294

Epoch: 5| Step: 11
Training loss: 1.4262874175102376
Validation loss: 2.5397543409653207

Epoch: 254| Step: 0
Training loss: 2.430302091431276
Validation loss: 2.5661356689941415

Epoch: 5| Step: 1
Training loss: 2.505773553248316
Validation loss: 2.5770095184494797

Epoch: 5| Step: 2
Training loss: 2.2920891343471963
Validation loss: 2.5986155638754873

Epoch: 5| Step: 3
Training loss: 2.2736046588702323
Validation loss: 2.635471224063077

Epoch: 5| Step: 4
Training loss: 2.15077930787065
Validation loss: 2.632671646742394

Epoch: 5| Step: 5
Training loss: 2.6063801831268942
Validation loss: 2.6112506391793224

Epoch: 5| Step: 6
Training loss: 2.604003677353848
Validation loss: 2.6168651249415813

Epoch: 5| Step: 7
Training loss: 2.8410977581839063
Validation loss: 2.604274924253316

Epoch: 5| Step: 8
Training loss: 2.227727645390283
Validation loss: 2.5548705094763022

Epoch: 5| Step: 9
Training loss: 2.1658210082203095
Validation loss: 2.531503064256381

Epoch: 5| Step: 10
Training loss: 2.097805138672634
Validation loss: 2.5192484142438163

Epoch: 5| Step: 11
Training loss: 3.320402543586039
Validation loss: 2.5271326691313214

Epoch: 255| Step: 0
Training loss: 2.405328053804145
Validation loss: 2.5131179962085906

Epoch: 5| Step: 1
Training loss: 2.9477077630276343
Validation loss: 2.5181371414953553

Epoch: 5| Step: 2
Training loss: 2.3629037098357535
Validation loss: 2.518860702590305

Epoch: 5| Step: 3
Training loss: 1.8632856644872038
Validation loss: 2.505618184138196

Epoch: 5| Step: 4
Training loss: 1.5923774643350486
Validation loss: 2.513793369331986

Epoch: 5| Step: 5
Training loss: 2.222281962492404
Validation loss: 2.521295254266053

Epoch: 5| Step: 6
Training loss: 3.0180022204007324
Validation loss: 2.505423944332537

Epoch: 5| Step: 7
Training loss: 2.324756104997552
Validation loss: 2.5155850638305717

Epoch: 5| Step: 8
Training loss: 2.678597364754222
Validation loss: 2.5195735365993257

Epoch: 5| Step: 9
Training loss: 2.660706584988767
Validation loss: 2.5089896737987605

Epoch: 5| Step: 10
Training loss: 1.9639006336310005
Validation loss: 2.5218744978338954

Epoch: 5| Step: 11
Training loss: 1.7439679682966027
Validation loss: 2.5201396316048825

Epoch: 256| Step: 0
Training loss: 1.6850898627024882
Validation loss: 2.510233062477541

Epoch: 5| Step: 1
Training loss: 2.4422914410887437
Validation loss: 2.515030050117145

Epoch: 5| Step: 2
Training loss: 2.5236108679016964
Validation loss: 2.528070780577806

Epoch: 5| Step: 3
Training loss: 2.3556951663892045
Validation loss: 2.5365854436420987

Epoch: 5| Step: 4
Training loss: 2.1476697625060885
Validation loss: 2.5460220617108593

Epoch: 5| Step: 5
Training loss: 2.682112683494198
Validation loss: 2.5368081947522017

Epoch: 5| Step: 6
Training loss: 2.541100256505209
Validation loss: 2.5534750329216203

Epoch: 5| Step: 7
Training loss: 1.9806869958411866
Validation loss: 2.5681845060318076

Epoch: 5| Step: 8
Training loss: 2.385153998915219
Validation loss: 2.5634467771707103

Epoch: 5| Step: 9
Training loss: 2.054016932149332
Validation loss: 2.5836784160511566

Epoch: 5| Step: 10
Training loss: 2.4286709833175717
Validation loss: 2.5655810085587643

Epoch: 5| Step: 11
Training loss: 4.041236749704611
Validation loss: 2.5433517183307615

Epoch: 257| Step: 0
Training loss: 2.4494168385492303
Validation loss: 2.5228372928871154

Epoch: 5| Step: 1
Training loss: 2.8698963808500833
Validation loss: 2.527652271587772

Epoch: 5| Step: 2
Training loss: 2.1144941589895394
Validation loss: 2.5237527695619053

Epoch: 5| Step: 3
Training loss: 2.6167528389350156
Validation loss: 2.510361699865127

Epoch: 5| Step: 4
Training loss: 1.8195492040486236
Validation loss: 2.497607564585885

Epoch: 5| Step: 5
Training loss: 2.5090920104651366
Validation loss: 2.5047528784094717

Epoch: 5| Step: 6
Training loss: 1.7412644750865638
Validation loss: 2.520262055780061

Epoch: 5| Step: 7
Training loss: 2.2289817115372283
Validation loss: 2.5174880187978452

Epoch: 5| Step: 8
Training loss: 2.1667769721880905
Validation loss: 2.514764176455134

Epoch: 5| Step: 9
Training loss: 2.493783182865116
Validation loss: 2.5320029806716655

Epoch: 5| Step: 10
Training loss: 2.432491340582588
Validation loss: 2.537675351471719

Epoch: 5| Step: 11
Training loss: 2.5292092090864364
Validation loss: 2.5472082434913963

Epoch: 258| Step: 0
Training loss: 2.1829505478084577
Validation loss: 2.5472097196402723

Epoch: 5| Step: 1
Training loss: 2.9175918928121063
Validation loss: 2.5361951943472447

Epoch: 5| Step: 2
Training loss: 1.576116965092562
Validation loss: 2.55782745767087

Epoch: 5| Step: 3
Training loss: 2.5502817035727885
Validation loss: 2.558847545819938

Epoch: 5| Step: 4
Training loss: 1.7392983193582792
Validation loss: 2.563212338348393

Epoch: 5| Step: 5
Training loss: 2.2743364896603766
Validation loss: 2.5827864650022616

Epoch: 5| Step: 6
Training loss: 2.6990881969716622
Validation loss: 2.5896296309559705

Epoch: 5| Step: 7
Training loss: 2.44653903803269
Validation loss: 2.613663839741103

Epoch: 5| Step: 8
Training loss: 2.5568887635324242
Validation loss: 2.587124336080765

Epoch: 5| Step: 9
Training loss: 2.5654857267801634
Validation loss: 2.5974348829592744

Epoch: 5| Step: 10
Training loss: 1.9920425661510515
Validation loss: 2.5898242986149036

Epoch: 5| Step: 11
Training loss: 1.3912089118476847
Validation loss: 2.580433590255137

Epoch: 259| Step: 0
Training loss: 2.351823557813941
Validation loss: 2.56994963754298

Epoch: 5| Step: 1
Training loss: 1.9718193469529155
Validation loss: 2.5505139345669483

Epoch: 5| Step: 2
Training loss: 2.74586340425163
Validation loss: 2.5546502782382925

Epoch: 5| Step: 3
Training loss: 2.034394866799476
Validation loss: 2.550242191310471

Epoch: 5| Step: 4
Training loss: 2.0652810045479484
Validation loss: 2.540858129712105

Epoch: 5| Step: 5
Training loss: 2.2955898919706716
Validation loss: 2.5399299587394784

Epoch: 5| Step: 6
Training loss: 2.512840293500008
Validation loss: 2.534954503853091

Epoch: 5| Step: 7
Training loss: 1.9923599467719735
Validation loss: 2.527794508360479

Epoch: 5| Step: 8
Training loss: 2.482091658123973
Validation loss: 2.531303483688394

Epoch: 5| Step: 9
Training loss: 2.2180027307780787
Validation loss: 2.5347872927484194

Epoch: 5| Step: 10
Training loss: 2.5849905441081718
Validation loss: 2.5430750436439493

Epoch: 5| Step: 11
Training loss: 2.7025938008251074
Validation loss: 2.5445204735647677

Epoch: 260| Step: 0
Training loss: 2.190578256671579
Validation loss: 2.5609012051132836

Epoch: 5| Step: 1
Training loss: 2.2179211424971665
Validation loss: 2.580560668438488

Epoch: 5| Step: 2
Training loss: 2.4249124491509715
Validation loss: 2.5712326088037316

Epoch: 5| Step: 3
Training loss: 2.2060429073321486
Validation loss: 2.5714233262933237

Epoch: 5| Step: 4
Training loss: 2.7549288535234577
Validation loss: 2.5701245603482947

Epoch: 5| Step: 5
Training loss: 2.5637183665719103
Validation loss: 2.5841757582617633

Epoch: 5| Step: 6
Training loss: 2.340777126609349
Validation loss: 2.5651232233001213

Epoch: 5| Step: 7
Training loss: 1.8676906530249404
Validation loss: 2.5695230185606044

Epoch: 5| Step: 8
Training loss: 2.22009279692934
Validation loss: 2.5697569937674065

Epoch: 5| Step: 9
Training loss: 2.496273983461469
Validation loss: 2.558143607186164

Epoch: 5| Step: 10
Training loss: 1.7290494794853457
Validation loss: 2.564779655468287

Epoch: 5| Step: 11
Training loss: 3.0563702643511728
Validation loss: 2.5550060559678145

Epoch: 261| Step: 0
Training loss: 2.79478760296136
Validation loss: 2.5620416642272223

Epoch: 5| Step: 1
Training loss: 2.456235917611557
Validation loss: 2.5498270583878964

Epoch: 5| Step: 2
Training loss: 2.1702912408544144
Validation loss: 2.55512323270202

Epoch: 5| Step: 3
Training loss: 2.0249486751880887
Validation loss: 2.5747335321548133

Epoch: 5| Step: 4
Training loss: 2.346152536504892
Validation loss: 2.574762110461926

Epoch: 5| Step: 5
Training loss: 1.4226338803220544
Validation loss: 2.5785392929275393

Epoch: 5| Step: 6
Training loss: 1.9478383652016134
Validation loss: 2.580310835103015

Epoch: 5| Step: 7
Training loss: 2.6189690291185532
Validation loss: 2.5594779411142103

Epoch: 5| Step: 8
Training loss: 2.521396437455247
Validation loss: 2.5437952232871046

Epoch: 5| Step: 9
Training loss: 2.937874790387872
Validation loss: 2.5408093610393574

Epoch: 5| Step: 10
Training loss: 1.8883378878564052
Validation loss: 2.5479596993427194

Epoch: 5| Step: 11
Training loss: 1.695510922962891
Validation loss: 2.5282531705791365

Epoch: 262| Step: 0
Training loss: 2.189140140918253
Validation loss: 2.5260284554571903

Epoch: 5| Step: 1
Training loss: 2.311968665039338
Validation loss: 2.5384204933153773

Epoch: 5| Step: 2
Training loss: 2.3969034762723864
Validation loss: 2.5340630790523813

Epoch: 5| Step: 3
Training loss: 1.8352822290980522
Validation loss: 2.550071520207546

Epoch: 5| Step: 4
Training loss: 1.9654075465888068
Validation loss: 2.5603193021429633

Epoch: 5| Step: 5
Training loss: 2.848547608909602
Validation loss: 2.5753963634524046

Epoch: 5| Step: 6
Training loss: 2.119655170466888
Validation loss: 2.547079550051104

Epoch: 5| Step: 7
Training loss: 2.50213817713141
Validation loss: 2.5823599047849983

Epoch: 5| Step: 8
Training loss: 2.33183382307232
Validation loss: 2.5740018646149005

Epoch: 5| Step: 9
Training loss: 2.603661134607099
Validation loss: 2.548539132875482

Epoch: 5| Step: 10
Training loss: 2.0312694842064314
Validation loss: 2.5506228192809344

Epoch: 5| Step: 11
Training loss: 1.7201872624988694
Validation loss: 2.5728794872568086

Epoch: 263| Step: 0
Training loss: 2.9059221636540475
Validation loss: 2.5643828228167895

Epoch: 5| Step: 1
Training loss: 1.7924589209325248
Validation loss: 2.5708624725813105

Epoch: 5| Step: 2
Training loss: 2.3511509329222364
Validation loss: 2.571864157368396

Epoch: 5| Step: 3
Training loss: 2.0925203954507103
Validation loss: 2.5812464727111313

Epoch: 5| Step: 4
Training loss: 2.485097720030459
Validation loss: 2.579250024723123

Epoch: 5| Step: 5
Training loss: 1.4796016841442612
Validation loss: 2.586492423207893

Epoch: 5| Step: 6
Training loss: 2.1469843718586707
Validation loss: 2.577907907612789

Epoch: 5| Step: 7
Training loss: 2.1291388428345037
Validation loss: 2.5772303560629344

Epoch: 5| Step: 8
Training loss: 2.3025090671157824
Validation loss: 2.5572397119303525

Epoch: 5| Step: 9
Training loss: 2.7385729146001467
Validation loss: 2.5607521213469453

Epoch: 5| Step: 10
Training loss: 2.2774673873291578
Validation loss: 2.54533622922661

Epoch: 5| Step: 11
Training loss: 2.442272209704554
Validation loss: 2.536932355907929

Epoch: 264| Step: 0
Training loss: 2.2362464590028606
Validation loss: 2.5450624440294978

Epoch: 5| Step: 1
Training loss: 2.534251470412774
Validation loss: 2.5235336883762285

Epoch: 5| Step: 2
Training loss: 1.768136525337355
Validation loss: 2.547490141209676

Epoch: 5| Step: 3
Training loss: 1.982210796375065
Validation loss: 2.527473029751488

Epoch: 5| Step: 4
Training loss: 2.3119127713614183
Validation loss: 2.529371172625027

Epoch: 5| Step: 5
Training loss: 2.207033194481997
Validation loss: 2.5421705541219817

Epoch: 5| Step: 6
Training loss: 2.154563908009579
Validation loss: 2.5577768822397844

Epoch: 5| Step: 7
Training loss: 2.2070004621400683
Validation loss: 2.5665040793466667

Epoch: 5| Step: 8
Training loss: 2.529538364738531
Validation loss: 2.5852842860075445

Epoch: 5| Step: 9
Training loss: 2.5164284696548407
Validation loss: 2.5821997336985336

Epoch: 5| Step: 10
Training loss: 2.248967251591376
Validation loss: 2.5794340528650435

Epoch: 5| Step: 11
Training loss: 3.3271740911562366
Validation loss: 2.5990866678439883

Epoch: 265| Step: 0
Training loss: 2.386063655972997
Validation loss: 2.605877889434837

Epoch: 5| Step: 1
Training loss: 2.166061304572148
Validation loss: 2.5916610065063126

Epoch: 5| Step: 2
Training loss: 1.9350566839939793
Validation loss: 2.619875488810968

Epoch: 5| Step: 3
Training loss: 2.0546516444337626
Validation loss: 2.599382787584112

Epoch: 5| Step: 4
Training loss: 2.8655279278303643
Validation loss: 2.585341608667565

Epoch: 5| Step: 5
Training loss: 2.390553392322667
Validation loss: 2.576247180670032

Epoch: 5| Step: 6
Training loss: 1.965105649811237
Validation loss: 2.560631885179458

Epoch: 5| Step: 7
Training loss: 2.170872408856275
Validation loss: 2.546354217175578

Epoch: 5| Step: 8
Training loss: 2.4927608583822316
Validation loss: 2.53918630836092

Epoch: 5| Step: 9
Training loss: 2.3209574923585845
Validation loss: 2.519756450987847

Epoch: 5| Step: 10
Training loss: 2.2792134012269494
Validation loss: 2.5164927709628357

Epoch: 5| Step: 11
Training loss: 2.8754529181605646
Validation loss: 2.5413086546530295

Epoch: 266| Step: 0
Training loss: 2.3509584582580003
Validation loss: 2.5652871558793566

Epoch: 5| Step: 1
Training loss: 2.5131546116668457
Validation loss: 2.5601136757464675

Epoch: 5| Step: 2
Training loss: 2.225908364026683
Validation loss: 2.581935436415923

Epoch: 5| Step: 3
Training loss: 2.620949117248849
Validation loss: 2.57087091952216

Epoch: 5| Step: 4
Training loss: 2.232780581246827
Validation loss: 2.61319536753186

Epoch: 5| Step: 5
Training loss: 1.6489403847998572
Validation loss: 2.614080933002148

Epoch: 5| Step: 6
Training loss: 2.2050729351134675
Validation loss: 2.5892074133084764

Epoch: 5| Step: 7
Training loss: 2.60380526260136
Validation loss: 2.592000746787713

Epoch: 5| Step: 8
Training loss: 2.571919596808008
Validation loss: 2.582276540888632

Epoch: 5| Step: 9
Training loss: 2.0749232358406293
Validation loss: 2.579557698906572

Epoch: 5| Step: 10
Training loss: 2.1932383883525546
Validation loss: 2.5521943217426477

Epoch: 5| Step: 11
Training loss: 2.016070767575947
Validation loss: 2.5476414515987598

Epoch: 267| Step: 0
Training loss: 2.0036786342388893
Validation loss: 2.5377090837751917

Epoch: 5| Step: 1
Training loss: 1.94906205826082
Validation loss: 2.523103406459534

Epoch: 5| Step: 2
Training loss: 1.8795404137246798
Validation loss: 2.512878213633675

Epoch: 5| Step: 3
Training loss: 2.538578116356524
Validation loss: 2.5114469049848482

Epoch: 5| Step: 4
Training loss: 1.9370320277955997
Validation loss: 2.5252808804918927

Epoch: 5| Step: 5
Training loss: 2.070494561017577
Validation loss: 2.5165288813769333

Epoch: 5| Step: 6
Training loss: 2.5916717660083055
Validation loss: 2.529725400543767

Epoch: 5| Step: 7
Training loss: 3.0162172674749836
Validation loss: 2.540125271337513

Epoch: 5| Step: 8
Training loss: 2.600136122441402
Validation loss: 2.544336543931472

Epoch: 5| Step: 9
Training loss: 2.340352762481854
Validation loss: 2.5552539022565357

Epoch: 5| Step: 10
Training loss: 2.2024912903491174
Validation loss: 2.5790762331324357

Epoch: 5| Step: 11
Training loss: 1.4820245705445487
Validation loss: 2.5744885624991865

Epoch: 268| Step: 0
Training loss: 2.6758402351505017
Validation loss: 2.5854019271180424

Epoch: 5| Step: 1
Training loss: 2.3350182194785187
Validation loss: 2.57928985328225

Epoch: 5| Step: 2
Training loss: 2.3094805000375542
Validation loss: 2.58713119400103

Epoch: 5| Step: 3
Training loss: 1.9777139920701203
Validation loss: 2.5617935129424163

Epoch: 5| Step: 4
Training loss: 2.5239867566300824
Validation loss: 2.589357268076063

Epoch: 5| Step: 5
Training loss: 2.5244264347798846
Validation loss: 2.5730428793423314

Epoch: 5| Step: 6
Training loss: 2.507638515248308
Validation loss: 2.5420418889680896

Epoch: 5| Step: 7
Training loss: 2.3406122184373874
Validation loss: 2.5422770765169798

Epoch: 5| Step: 8
Training loss: 2.089220870412564
Validation loss: 2.5037699586431783

Epoch: 5| Step: 9
Training loss: 2.09285272758684
Validation loss: 2.4956774217650595

Epoch: 5| Step: 10
Training loss: 2.0863225345790224
Validation loss: 2.498786234259778

Epoch: 5| Step: 11
Training loss: 1.8156760440026565
Validation loss: 2.4916668131731514

Epoch: 269| Step: 0
Training loss: 2.516999242504371
Validation loss: 2.489496358578551

Epoch: 5| Step: 1
Training loss: 3.0205594344218754
Validation loss: 2.5039464319489393

Epoch: 5| Step: 2
Training loss: 2.38717262460184
Validation loss: 2.5058543640546485

Epoch: 5| Step: 3
Training loss: 1.3164153961860032
Validation loss: 2.5231182400330416

Epoch: 5| Step: 4
Training loss: 2.567832237075879
Validation loss: 2.5115912421388966

Epoch: 5| Step: 5
Training loss: 2.1693124267205315
Validation loss: 2.52765100214199

Epoch: 5| Step: 6
Training loss: 1.9875818007807684
Validation loss: 2.5360057447914435

Epoch: 5| Step: 7
Training loss: 2.0603468088226635
Validation loss: 2.5466501452644885

Epoch: 5| Step: 8
Training loss: 2.4506792644942084
Validation loss: 2.5381558682498837

Epoch: 5| Step: 9
Training loss: 1.9068414364701962
Validation loss: 2.539314022810843

Epoch: 5| Step: 10
Training loss: 2.593382568071796
Validation loss: 2.529927602945875

Epoch: 5| Step: 11
Training loss: 2.6413651732551306
Validation loss: 2.52824278361816

Epoch: 270| Step: 0
Training loss: 2.395545931177302
Validation loss: 2.518718712662075

Epoch: 5| Step: 1
Training loss: 2.352624596307261
Validation loss: 2.528721912678721

Epoch: 5| Step: 2
Training loss: 1.9569906813020037
Validation loss: 2.54657491230527

Epoch: 5| Step: 3
Training loss: 2.2634948187268016
Validation loss: 2.557618240097934

Epoch: 5| Step: 4
Training loss: 2.8207058196404264
Validation loss: 2.5664682521133457

Epoch: 5| Step: 5
Training loss: 2.1748831794322303
Validation loss: 2.5733906789325403

Epoch: 5| Step: 6
Training loss: 2.077812113906014
Validation loss: 2.565130016112747

Epoch: 5| Step: 7
Training loss: 2.5938529488228874
Validation loss: 2.5803185889217013

Epoch: 5| Step: 8
Training loss: 2.2285102757248465
Validation loss: 2.5806983704691038

Epoch: 5| Step: 9
Training loss: 2.0672306947239196
Validation loss: 2.5731552157582627

Epoch: 5| Step: 10
Training loss: 2.3040586486477923
Validation loss: 2.568716978215113

Epoch: 5| Step: 11
Training loss: 1.4649763937340416
Validation loss: 2.5563864468670827

Epoch: 271| Step: 0
Training loss: 1.7623552411740802
Validation loss: 2.5614359631414136

Epoch: 5| Step: 1
Training loss: 2.729650808785408
Validation loss: 2.5753514948076237

Epoch: 5| Step: 2
Training loss: 2.479695645699345
Validation loss: 2.575350619182381

Epoch: 5| Step: 3
Training loss: 1.657843560908471
Validation loss: 2.569102805568183

Epoch: 5| Step: 4
Training loss: 2.4245596495701505
Validation loss: 2.569402562622018

Epoch: 5| Step: 5
Training loss: 2.464423238972428
Validation loss: 2.5716469671729363

Epoch: 5| Step: 6
Training loss: 2.552462107258495
Validation loss: 2.5884899477074224

Epoch: 5| Step: 7
Training loss: 1.8203613536647771
Validation loss: 2.5835119667639863

Epoch: 5| Step: 8
Training loss: 2.625543992123849
Validation loss: 2.5859644562851942

Epoch: 5| Step: 9
Training loss: 2.029625463088266
Validation loss: 2.589242051136957

Epoch: 5| Step: 10
Training loss: 2.203742732026854
Validation loss: 2.577735073773364

Epoch: 5| Step: 11
Training loss: 2.233825295859794
Validation loss: 2.5542332617731587

Epoch: 272| Step: 0
Training loss: 2.913119984401272
Validation loss: 2.5404249516830086

Epoch: 5| Step: 1
Training loss: 1.9736131216932749
Validation loss: 2.5557489960448434

Epoch: 5| Step: 2
Training loss: 2.2271952482912742
Validation loss: 2.5628869570893036

Epoch: 5| Step: 3
Training loss: 1.9205604337297366
Validation loss: 2.5746656559571846

Epoch: 5| Step: 4
Training loss: 2.750499159853886
Validation loss: 2.558551001737651

Epoch: 5| Step: 5
Training loss: 2.5554187906222117
Validation loss: 2.5262959316267763

Epoch: 5| Step: 6
Training loss: 1.437845603198652
Validation loss: 2.562508048068178

Epoch: 5| Step: 7
Training loss: 1.7214864275084556
Validation loss: 2.5492698822520583

Epoch: 5| Step: 8
Training loss: 2.5323064977561227
Validation loss: 2.548623691900825

Epoch: 5| Step: 9
Training loss: 2.307714304452378
Validation loss: 2.5460798937582525

Epoch: 5| Step: 10
Training loss: 2.4041224400128804
Validation loss: 2.5504112656869604

Epoch: 5| Step: 11
Training loss: 1.599571590885599
Validation loss: 2.5526876058577304

Epoch: 273| Step: 0
Training loss: 2.587369493519643
Validation loss: 2.5641590481468173

Epoch: 5| Step: 1
Training loss: 2.244508293185822
Validation loss: 2.546309605348529

Epoch: 5| Step: 2
Training loss: 1.8711287907323666
Validation loss: 2.567230208465963

Epoch: 5| Step: 3
Training loss: 1.4963221761557057
Validation loss: 2.575973387411175

Epoch: 5| Step: 4
Training loss: 2.3769616508487705
Validation loss: 2.56445212169278

Epoch: 5| Step: 5
Training loss: 1.3555344447505386
Validation loss: 2.553778390376489

Epoch: 5| Step: 6
Training loss: 2.4846177852207476
Validation loss: 2.5633612945314757

Epoch: 5| Step: 7
Training loss: 2.7241208749467782
Validation loss: 2.564942099523145

Epoch: 5| Step: 8
Training loss: 2.4609291682026617
Validation loss: 2.5453284917820427

Epoch: 5| Step: 9
Training loss: 2.7128693570868108
Validation loss: 2.55138914956447

Epoch: 5| Step: 10
Training loss: 2.3724581517989636
Validation loss: 2.561051944257019

Epoch: 5| Step: 11
Training loss: 1.048295892967702
Validation loss: 2.5851622703515194

Epoch: 274| Step: 0
Training loss: 2.4236985755253606
Validation loss: 2.596751819998883

Epoch: 5| Step: 1
Training loss: 2.1934961155756376
Validation loss: 2.5914411782230165

Epoch: 5| Step: 2
Training loss: 2.0187814527015977
Validation loss: 2.5980062492749156

Epoch: 5| Step: 3
Training loss: 2.719387812723439
Validation loss: 2.6162488971883455

Epoch: 5| Step: 4
Training loss: 2.3178045931482325
Validation loss: 2.595038871265752

Epoch: 5| Step: 5
Training loss: 2.2889801114719437
Validation loss: 2.594795728629501

Epoch: 5| Step: 6
Training loss: 2.5235726051656373
Validation loss: 2.6112307575783533

Epoch: 5| Step: 7
Training loss: 2.1371617947541517
Validation loss: 2.587294300398584

Epoch: 5| Step: 8
Training loss: 2.441385449130138
Validation loss: 2.5752460897621092

Epoch: 5| Step: 9
Training loss: 2.2364560552928063
Validation loss: 2.5701533638370955

Epoch: 5| Step: 10
Training loss: 1.8677923268375523
Validation loss: 2.558811861792741

Epoch: 5| Step: 11
Training loss: 1.862217309479213
Validation loss: 2.5291273416188345

Epoch: 275| Step: 0
Training loss: 2.4862568763419177
Validation loss: 2.4936574907600186

Epoch: 5| Step: 1
Training loss: 2.4855251888640235
Validation loss: 2.4986207216923932

Epoch: 5| Step: 2
Training loss: 2.560206899179765
Validation loss: 2.5009778772619033

Epoch: 5| Step: 3
Training loss: 2.9391304523373805
Validation loss: 2.5237757079213408

Epoch: 5| Step: 4
Training loss: 2.3668609494622523
Validation loss: 2.516388933117639

Epoch: 5| Step: 5
Training loss: 2.18501783961645
Validation loss: 2.5084669223857996

Epoch: 5| Step: 6
Training loss: 2.3697916443094664
Validation loss: 2.5132200639775206

Epoch: 5| Step: 7
Training loss: 2.3615920406047186
Validation loss: 2.5032409760161927

Epoch: 5| Step: 8
Training loss: 2.26794882675918
Validation loss: 2.50946033367528

Epoch: 5| Step: 9
Training loss: 1.9207014517149388
Validation loss: 2.505509159534241

Epoch: 5| Step: 10
Training loss: 2.4424354276057496
Validation loss: 2.5169252427527415

Epoch: 5| Step: 11
Training loss: 2.181872185667305
Validation loss: 2.5181648432903674

Epoch: 276| Step: 0
Training loss: 2.4267563388136875
Validation loss: 2.5187090416820883

Epoch: 5| Step: 1
Training loss: 2.512531060173908
Validation loss: 2.5350088577253698

Epoch: 5| Step: 2
Training loss: 2.186268705153887
Validation loss: 2.543151634034965

Epoch: 5| Step: 3
Training loss: 2.428607369405402
Validation loss: 2.5610666957352004

Epoch: 5| Step: 4
Training loss: 2.4449675197823235
Validation loss: 2.549782838487951

Epoch: 5| Step: 5
Training loss: 2.5688261703001616
Validation loss: 2.552739772581753

Epoch: 5| Step: 6
Training loss: 2.405732830006553
Validation loss: 2.5564082899571816

Epoch: 5| Step: 7
Training loss: 1.990093012797382
Validation loss: 2.5775250902505635

Epoch: 5| Step: 8
Training loss: 2.277833653620135
Validation loss: 2.5707067749572543

Epoch: 5| Step: 9
Training loss: 2.2405901279688605
Validation loss: 2.564116146650775

Epoch: 5| Step: 10
Training loss: 2.3104359462290223
Validation loss: 2.564132267484952

Epoch: 5| Step: 11
Training loss: 1.2850466046620894
Validation loss: 2.554965088721497

Epoch: 277| Step: 0
Training loss: 2.3253482926890783
Validation loss: 2.558150057383739

Epoch: 5| Step: 1
Training loss: 2.6111447848409983
Validation loss: 2.549278915120827

Epoch: 5| Step: 2
Training loss: 2.0891751084260486
Validation loss: 2.5358603371135007

Epoch: 5| Step: 3
Training loss: 2.033547144211792
Validation loss: 2.549389645047405

Epoch: 5| Step: 4
Training loss: 1.9065663434802564
Validation loss: 2.521774645624196

Epoch: 5| Step: 5
Training loss: 2.306267148499454
Validation loss: 2.5338128345616906

Epoch: 5| Step: 6
Training loss: 2.6353333853327485
Validation loss: 2.502908199286031

Epoch: 5| Step: 7
Training loss: 2.142700636915875
Validation loss: 2.506733651396987

Epoch: 5| Step: 8
Training loss: 2.8980584320853935
Validation loss: 2.528579559138632

Epoch: 5| Step: 9
Training loss: 2.1567154534003867
Validation loss: 2.5285008143684617

Epoch: 5| Step: 10
Training loss: 2.1450771616681994
Validation loss: 2.526413401881544

Epoch: 5| Step: 11
Training loss: 1.3952381468780164
Validation loss: 2.539030515029159

Epoch: 278| Step: 0
Training loss: 2.0825838139441233
Validation loss: 2.5445830714182587

Epoch: 5| Step: 1
Training loss: 2.6792723220076144
Validation loss: 2.5464969814733798

Epoch: 5| Step: 2
Training loss: 2.1440649307297246
Validation loss: 2.569777663993853

Epoch: 5| Step: 3
Training loss: 1.9059514296548508
Validation loss: 2.559976471063898

Epoch: 5| Step: 4
Training loss: 2.4336225529369946
Validation loss: 2.5717726273400188

Epoch: 5| Step: 5
Training loss: 2.520135662120824
Validation loss: 2.545638273657054

Epoch: 5| Step: 6
Training loss: 2.9476721744223475
Validation loss: 2.5474267763639795

Epoch: 5| Step: 7
Training loss: 2.4457129982281542
Validation loss: 2.528475701016755

Epoch: 5| Step: 8
Training loss: 1.8099605265154115
Validation loss: 2.514397129970043

Epoch: 5| Step: 9
Training loss: 2.1979895725783893
Validation loss: 2.520526955379257

Epoch: 5| Step: 10
Training loss: 1.7117190035006302
Validation loss: 2.5329928265497754

Epoch: 5| Step: 11
Training loss: 2.4960301350828478
Validation loss: 2.522730264673638

Epoch: 279| Step: 0
Training loss: 2.0883960879254335
Validation loss: 2.522312062933727

Epoch: 5| Step: 1
Training loss: 2.4751823743423196
Validation loss: 2.533135175222546

Epoch: 5| Step: 2
Training loss: 2.026197282033567
Validation loss: 2.5309468939505155

Epoch: 5| Step: 3
Training loss: 1.7542982449268198
Validation loss: 2.5118410704606227

Epoch: 5| Step: 4
Training loss: 2.111744094228
Validation loss: 2.505571328483786

Epoch: 5| Step: 5
Training loss: 2.7327818670895163
Validation loss: 2.512416313605944

Epoch: 5| Step: 6
Training loss: 2.086730691924892
Validation loss: 2.5281572285638467

Epoch: 5| Step: 7
Training loss: 2.03152252716561
Validation loss: 2.5397296322519267

Epoch: 5| Step: 8
Training loss: 2.7114765609693245
Validation loss: 2.5512775251880844

Epoch: 5| Step: 9
Training loss: 2.340416839673855
Validation loss: 2.5690569531027774

Epoch: 5| Step: 10
Training loss: 2.4045322777098126
Validation loss: 2.569427422876654

Epoch: 5| Step: 11
Training loss: 2.5300317352174213
Validation loss: 2.5581098220204677

Epoch: 280| Step: 0
Training loss: 2.257197946510821
Validation loss: 2.556113060203354

Epoch: 5| Step: 1
Training loss: 2.500681498145991
Validation loss: 2.5576497867619166

Epoch: 5| Step: 2
Training loss: 2.22009537431826
Validation loss: 2.5211811902817796

Epoch: 5| Step: 3
Training loss: 1.8596763687172444
Validation loss: 2.5092019602209517

Epoch: 5| Step: 4
Training loss: 1.8796994127259146
Validation loss: 2.5070314825193987

Epoch: 5| Step: 5
Training loss: 1.7827316947899143
Validation loss: 2.503056842830106

Epoch: 5| Step: 6
Training loss: 2.6874557314043437
Validation loss: 2.5075197989834863

Epoch: 5| Step: 7
Training loss: 2.587302593864745
Validation loss: 2.4914702017993435

Epoch: 5| Step: 8
Training loss: 2.2427845867663527
Validation loss: 2.5101684603259073

Epoch: 5| Step: 9
Training loss: 2.87390663254403
Validation loss: 2.5031602574443834

Epoch: 5| Step: 10
Training loss: 2.191069932449226
Validation loss: 2.5040165464773185

Epoch: 5| Step: 11
Training loss: 2.0352822995094044
Validation loss: 2.504057893014486

Epoch: 281| Step: 0
Training loss: 2.4491105975984016
Validation loss: 2.4907710236389558

Epoch: 5| Step: 1
Training loss: 1.7371074013412515
Validation loss: 2.5057366356704986

Epoch: 5| Step: 2
Training loss: 2.383603624431571
Validation loss: 2.5083297996137026

Epoch: 5| Step: 3
Training loss: 2.195322600100487
Validation loss: 2.507441953812515

Epoch: 5| Step: 4
Training loss: 2.113823840421079
Validation loss: 2.512260766129694

Epoch: 5| Step: 5
Training loss: 1.822861225556663
Validation loss: 2.517455562412759

Epoch: 5| Step: 6
Training loss: 1.9590255717759766
Validation loss: 2.5185191051015243

Epoch: 5| Step: 7
Training loss: 2.472904138659201
Validation loss: 2.5210771180069145

Epoch: 5| Step: 8
Training loss: 2.4843283594899677
Validation loss: 2.529188069834845

Epoch: 5| Step: 9
Training loss: 2.823512494221195
Validation loss: 2.554139073540732

Epoch: 5| Step: 10
Training loss: 2.3516260689795994
Validation loss: 2.520851392655011

Epoch: 5| Step: 11
Training loss: 3.033478851460933
Validation loss: 2.5426034034999687

Epoch: 282| Step: 0
Training loss: 2.3036760600038395
Validation loss: 2.573008370920949

Epoch: 5| Step: 1
Training loss: 2.1097556441857974
Validation loss: 2.618912393182546

Epoch: 5| Step: 2
Training loss: 2.7626882359510816
Validation loss: 2.6241406101178084

Epoch: 5| Step: 3
Training loss: 2.3073998993459517
Validation loss: 2.6328849801369705

Epoch: 5| Step: 4
Training loss: 2.2988704395532085
Validation loss: 2.6674179804418525

Epoch: 5| Step: 5
Training loss: 2.696442209748827
Validation loss: 2.6543486840153414

Epoch: 5| Step: 6
Training loss: 2.2957380945444705
Validation loss: 2.5950522619777887

Epoch: 5| Step: 7
Training loss: 2.423919602234807
Validation loss: 2.586397005343235

Epoch: 5| Step: 8
Training loss: 1.9191085629509346
Validation loss: 2.5631017056032714

Epoch: 5| Step: 9
Training loss: 2.458518446940957
Validation loss: 2.5190681682523373

Epoch: 5| Step: 10
Training loss: 1.9367534675887168
Validation loss: 2.504278400317097

Epoch: 5| Step: 11
Training loss: 1.5081596963039636
Validation loss: 2.4970335487122965

Epoch: 283| Step: 0
Training loss: 2.9006135488825358
Validation loss: 2.510397904406407

Epoch: 5| Step: 1
Training loss: 1.9198581067940355
Validation loss: 2.498341355850626

Epoch: 5| Step: 2
Training loss: 2.8367173985189393
Validation loss: 2.5016795536654324

Epoch: 5| Step: 3
Training loss: 2.2041688434707862
Validation loss: 2.495536590782042

Epoch: 5| Step: 4
Training loss: 2.485726330873592
Validation loss: 2.5066196777838154

Epoch: 5| Step: 5
Training loss: 2.7254010106671114
Validation loss: 2.4905660929428475

Epoch: 5| Step: 6
Training loss: 1.8968598517578186
Validation loss: 2.5011741324799868

Epoch: 5| Step: 7
Training loss: 1.584885271655429
Validation loss: 2.5079918913094157

Epoch: 5| Step: 8
Training loss: 2.208059425881164
Validation loss: 2.51093655396123

Epoch: 5| Step: 9
Training loss: 2.0783498542004613
Validation loss: 2.517533176870228

Epoch: 5| Step: 10
Training loss: 2.4060653021140364
Validation loss: 2.529639222138167

Epoch: 5| Step: 11
Training loss: 2.1325886926844397
Validation loss: 2.518697305905891

Epoch: 284| Step: 0
Training loss: 2.1843925202503405
Validation loss: 2.52682173701821

Epoch: 5| Step: 1
Training loss: 2.088825640949616
Validation loss: 2.5462204300691718

Epoch: 5| Step: 2
Training loss: 2.261071199736063
Validation loss: 2.5627105789189204

Epoch: 5| Step: 3
Training loss: 2.7252151089380323
Validation loss: 2.569277851758385

Epoch: 5| Step: 4
Training loss: 2.0414941546160006
Validation loss: 2.5884268957185887

Epoch: 5| Step: 5
Training loss: 1.6403520629553567
Validation loss: 2.594696607549617

Epoch: 5| Step: 6
Training loss: 2.900460824855422
Validation loss: 2.59088945062888

Epoch: 5| Step: 7
Training loss: 2.063769441139892
Validation loss: 2.5900548443271365

Epoch: 5| Step: 8
Training loss: 2.0483935598029706
Validation loss: 2.5758597855169745

Epoch: 5| Step: 9
Training loss: 2.261210699124737
Validation loss: 2.5669118943406333

Epoch: 5| Step: 10
Training loss: 2.150499166162538
Validation loss: 2.5307414442728766

Epoch: 5| Step: 11
Training loss: 3.0072598036234344
Validation loss: 2.5199398172788707

Epoch: 285| Step: 0
Training loss: 2.5003667562400618
Validation loss: 2.5084789060149673

Epoch: 5| Step: 1
Training loss: 2.1331279367672016
Validation loss: 2.504751871019152

Epoch: 5| Step: 2
Training loss: 2.4489626225788603
Validation loss: 2.5049401190574554

Epoch: 5| Step: 3
Training loss: 1.7489668657535116
Validation loss: 2.495100469464795

Epoch: 5| Step: 4
Training loss: 1.92242274968739
Validation loss: 2.4862144586072668

Epoch: 5| Step: 5
Training loss: 2.932720110113254
Validation loss: 2.494681239753612

Epoch: 5| Step: 6
Training loss: 1.2412905063531319
Validation loss: 2.5009921052453

Epoch: 5| Step: 7
Training loss: 2.357259850674311
Validation loss: 2.5014206485690123

Epoch: 5| Step: 8
Training loss: 2.065404407535895
Validation loss: 2.5107181230893105

Epoch: 5| Step: 9
Training loss: 2.277341970243462
Validation loss: 2.5350956138095286

Epoch: 5| Step: 10
Training loss: 2.6428291105749984
Validation loss: 2.5522232536314204

Epoch: 5| Step: 11
Training loss: 2.790503207258368
Validation loss: 2.5636955240377435

Epoch: 286| Step: 0
Training loss: 2.53351087031753
Validation loss: 2.5735621215440574

Epoch: 5| Step: 1
Training loss: 2.2276119502884955
Validation loss: 2.564962276013402

Epoch: 5| Step: 2
Training loss: 2.605624124220758
Validation loss: 2.5757666079384918

Epoch: 5| Step: 3
Training loss: 2.296318350051385
Validation loss: 2.5953930702388184

Epoch: 5| Step: 4
Training loss: 2.5086010795303233
Validation loss: 2.561892677848572

Epoch: 5| Step: 5
Training loss: 2.2376789128043106
Validation loss: 2.5581764405030056

Epoch: 5| Step: 6
Training loss: 2.4956168851999925
Validation loss: 2.563997238323581

Epoch: 5| Step: 7
Training loss: 2.4145422400158587
Validation loss: 2.5307488946223593

Epoch: 5| Step: 8
Training loss: 1.833748669250047
Validation loss: 2.5303700452073663

Epoch: 5| Step: 9
Training loss: 2.4087655925790448
Validation loss: 2.5357708296237633

Epoch: 5| Step: 10
Training loss: 2.076830353120666
Validation loss: 2.50308182623972

Epoch: 5| Step: 11
Training loss: 1.6261825660136047
Validation loss: 2.4869246644976704

Epoch: 287| Step: 0
Training loss: 2.4901027270655143
Validation loss: 2.494969854714245

Epoch: 5| Step: 1
Training loss: 2.3930322831076904
Validation loss: 2.4993258203003665

Epoch: 5| Step: 2
Training loss: 2.539641422883107
Validation loss: 2.511393156647037

Epoch: 5| Step: 3
Training loss: 1.7975055417544445
Validation loss: 2.5281327522954293

Epoch: 5| Step: 4
Training loss: 2.7564784813810266
Validation loss: 2.5129547558466205

Epoch: 5| Step: 5
Training loss: 2.3626293449719133
Validation loss: 2.5120675224021336

Epoch: 5| Step: 6
Training loss: 2.3065372608614383
Validation loss: 2.507436833116904

Epoch: 5| Step: 7
Training loss: 1.9234774352203563
Validation loss: 2.497611768746258

Epoch: 5| Step: 8
Training loss: 2.3023644070043257
Validation loss: 2.509444793896044

Epoch: 5| Step: 9
Training loss: 2.8524618324447744
Validation loss: 2.5154033270998157

Epoch: 5| Step: 10
Training loss: 2.345887696995332
Validation loss: 2.5139572270087114

Epoch: 5| Step: 11
Training loss: 1.5056892427552577
Validation loss: 2.507797538261109

Epoch: 288| Step: 0
Training loss: 2.1992003201242647
Validation loss: 2.506985311066482

Epoch: 5| Step: 1
Training loss: 1.726737932639388
Validation loss: 2.52826592485227

Epoch: 5| Step: 2
Training loss: 1.8656789519465695
Validation loss: 2.524513180703418

Epoch: 5| Step: 3
Training loss: 2.0598924510621
Validation loss: 2.545016443384307

Epoch: 5| Step: 4
Training loss: 2.591239541562179
Validation loss: 2.5563136378095064

Epoch: 5| Step: 5
Training loss: 2.4066330245705543
Validation loss: 2.5735932681899407

Epoch: 5| Step: 6
Training loss: 2.3776818242226545
Validation loss: 2.5860376156176694

Epoch: 5| Step: 7
Training loss: 2.1491543770249266
Validation loss: 2.582296027969385

Epoch: 5| Step: 8
Training loss: 2.5359080277080035
Validation loss: 2.5686376887424562

Epoch: 5| Step: 9
Training loss: 2.1983852399241712
Validation loss: 2.5983617144933633

Epoch: 5| Step: 10
Training loss: 2.5027680331807374
Validation loss: 2.5834212877826093

Epoch: 5| Step: 11
Training loss: 2.7111128604688717
Validation loss: 2.5795805319149196

Epoch: 289| Step: 0
Training loss: 2.715834007516711
Validation loss: 2.579955840022404

Epoch: 5| Step: 1
Training loss: 1.5317965719254143
Validation loss: 2.578118349317199

Epoch: 5| Step: 2
Training loss: 2.5690263585586735
Validation loss: 2.5634304195065845

Epoch: 5| Step: 3
Training loss: 1.9804363661907962
Validation loss: 2.560812173305555

Epoch: 5| Step: 4
Training loss: 1.8967260487629167
Validation loss: 2.559714276280808

Epoch: 5| Step: 5
Training loss: 2.654112370852413
Validation loss: 2.521462899138035

Epoch: 5| Step: 6
Training loss: 2.064900128810512
Validation loss: 2.533372309164286

Epoch: 5| Step: 7
Training loss: 2.2683172606665587
Validation loss: 2.5552983307154995

Epoch: 5| Step: 8
Training loss: 2.742244535108427
Validation loss: 2.5616265529597517

Epoch: 5| Step: 9
Training loss: 1.9895920545243726
Validation loss: 2.5661594421219944

Epoch: 5| Step: 10
Training loss: 1.9072174368941308
Validation loss: 2.565757613369288

Epoch: 5| Step: 11
Training loss: 2.622639548459025
Validation loss: 2.5917175422644636

Epoch: 290| Step: 0
Training loss: 2.3177468857434134
Validation loss: 2.5752417693168765

Epoch: 5| Step: 1
Training loss: 2.1355541898282215
Validation loss: 2.581428303537102

Epoch: 5| Step: 2
Training loss: 2.050105217815361
Validation loss: 2.564956851866489

Epoch: 5| Step: 3
Training loss: 2.649317682343195
Validation loss: 2.571534644063441

Epoch: 5| Step: 4
Training loss: 2.354002032529461
Validation loss: 2.5685282913958365

Epoch: 5| Step: 5
Training loss: 2.131918695427566
Validation loss: 2.5801013576819756

Epoch: 5| Step: 6
Training loss: 2.289319958057704
Validation loss: 2.610993273733079

Epoch: 5| Step: 7
Training loss: 1.747879378323056
Validation loss: 2.5704733461028155

Epoch: 5| Step: 8
Training loss: 2.146120465768142
Validation loss: 2.5668801073918766

Epoch: 5| Step: 9
Training loss: 2.6126916331410515
Validation loss: 2.566219181731091

Epoch: 5| Step: 10
Training loss: 1.9944715384104375
Validation loss: 2.559786041689066

Epoch: 5| Step: 11
Training loss: 2.0541012003630708
Validation loss: 2.579497548039008

Epoch: 291| Step: 0
Training loss: 2.2853338188889003
Validation loss: 2.5889607070498997

Epoch: 5| Step: 1
Training loss: 2.3107387949931777
Validation loss: 2.593828483527823

Epoch: 5| Step: 2
Training loss: 2.141862608954745
Validation loss: 2.5772734189273407

Epoch: 5| Step: 3
Training loss: 1.9462007999265245
Validation loss: 2.5876014231186404

Epoch: 5| Step: 4
Training loss: 2.2070258486521297
Validation loss: 2.591099840583476

Epoch: 5| Step: 5
Training loss: 1.6453211103976604
Validation loss: 2.5839814185839

Epoch: 5| Step: 6
Training loss: 2.1793809900838736
Validation loss: 2.5958021234521036

Epoch: 5| Step: 7
Training loss: 2.00873351588248
Validation loss: 2.58085400805159

Epoch: 5| Step: 8
Training loss: 2.156447470648091
Validation loss: 2.5922142139336

Epoch: 5| Step: 9
Training loss: 2.8422743773014347
Validation loss: 2.579335181062404

Epoch: 5| Step: 10
Training loss: 2.25892437547308
Validation loss: 2.580463310403044

Epoch: 5| Step: 11
Training loss: 3.5709146538595578
Validation loss: 2.5729974561560844

Epoch: 292| Step: 0
Training loss: 1.7449140894818407
Validation loss: 2.5540496115338116

Epoch: 5| Step: 1
Training loss: 1.7122102645471882
Validation loss: 2.543991059168363

Epoch: 5| Step: 2
Training loss: 2.4354342975310033
Validation loss: 2.528199689160275

Epoch: 5| Step: 3
Training loss: 2.482231895206326
Validation loss: 2.5193706017666133

Epoch: 5| Step: 4
Training loss: 2.0366970094750325
Validation loss: 2.51933602850779

Epoch: 5| Step: 5
Training loss: 2.5433754310106966
Validation loss: 2.5272504070954733

Epoch: 5| Step: 6
Training loss: 2.7841052711413625
Validation loss: 2.5225247955804893

Epoch: 5| Step: 7
Training loss: 2.4482371235488114
Validation loss: 2.521136936841953

Epoch: 5| Step: 8
Training loss: 2.548058451348885
Validation loss: 2.538665360912303

Epoch: 5| Step: 9
Training loss: 1.757896251802546
Validation loss: 2.5738814484617043

Epoch: 5| Step: 10
Training loss: 2.2964873732891
Validation loss: 2.5708249517538078

Epoch: 5| Step: 11
Training loss: 1.3274563171900804
Validation loss: 2.5789424775437366

Epoch: 293| Step: 0
Training loss: 2.202306500702086
Validation loss: 2.593523042393225

Epoch: 5| Step: 1
Training loss: 2.380753124391636
Validation loss: 2.5994325229437263

Epoch: 5| Step: 2
Training loss: 2.075653327213321
Validation loss: 2.587008309294572

Epoch: 5| Step: 3
Training loss: 2.458969055564373
Validation loss: 2.5944828736894228

Epoch: 5| Step: 4
Training loss: 2.046992174827777
Validation loss: 2.570492984499111

Epoch: 5| Step: 5
Training loss: 2.4079137227580096
Validation loss: 2.5857279405456626

Epoch: 5| Step: 6
Training loss: 1.727868186258921
Validation loss: 2.5760453207316836

Epoch: 5| Step: 7
Training loss: 2.3342767125366515
Validation loss: 2.5869260744243427

Epoch: 5| Step: 8
Training loss: 2.0430102954965457
Validation loss: 2.5926598168985024

Epoch: 5| Step: 9
Training loss: 2.1568226813949014
Validation loss: 2.5848169232622626

Epoch: 5| Step: 10
Training loss: 2.7861824445719483
Validation loss: 2.5931228699165496

Epoch: 5| Step: 11
Training loss: 1.1566003835596659
Validation loss: 2.571510893586323

Epoch: 294| Step: 0
Training loss: 1.93474801800867
Validation loss: 2.5599730212558294

Epoch: 5| Step: 1
Training loss: 2.1171231981485903
Validation loss: 2.5339335082525243

Epoch: 5| Step: 2
Training loss: 2.2288676860587278
Validation loss: 2.5311521601507927

Epoch: 5| Step: 3
Training loss: 1.569983756351874
Validation loss: 2.5557661277866384

Epoch: 5| Step: 4
Training loss: 2.635383052887989
Validation loss: 2.529263222960253

Epoch: 5| Step: 5
Training loss: 3.185952053813236
Validation loss: 2.5452209866790434

Epoch: 5| Step: 6
Training loss: 2.6029599763692723
Validation loss: 2.55358826128048

Epoch: 5| Step: 7
Training loss: 2.266400329518993
Validation loss: 2.572455761948954

Epoch: 5| Step: 8
Training loss: 1.920025004879729
Validation loss: 2.5974533040019883

Epoch: 5| Step: 9
Training loss: 1.6794357465994871
Validation loss: 2.6240828857199396

Epoch: 5| Step: 10
Training loss: 2.1542281471003766
Validation loss: 2.6312481754082206

Epoch: 5| Step: 11
Training loss: 1.863599706022817
Validation loss: 2.632645651702616

Epoch: 295| Step: 0
Training loss: 2.2027110258712725
Validation loss: 2.594838170742939

Epoch: 5| Step: 1
Training loss: 2.7107815656420486
Validation loss: 2.593559815431678

Epoch: 5| Step: 2
Training loss: 2.354977785884461
Validation loss: 2.590368698105088

Epoch: 5| Step: 3
Training loss: 2.3471461803551064
Validation loss: 2.554884394564106

Epoch: 5| Step: 4
Training loss: 1.4996494837348366
Validation loss: 2.561624986228396

Epoch: 5| Step: 5
Training loss: 2.237544019894759
Validation loss: 2.5391238748028386

Epoch: 5| Step: 6
Training loss: 2.033695216364228
Validation loss: 2.524393284488958

Epoch: 5| Step: 7
Training loss: 1.8530065643391906
Validation loss: 2.511895940294231

Epoch: 5| Step: 8
Training loss: 2.8971979415947335
Validation loss: 2.527360325502955

Epoch: 5| Step: 9
Training loss: 2.1195237898844708
Validation loss: 2.528567050029996

Epoch: 5| Step: 10
Training loss: 1.9393434676011232
Validation loss: 2.5308543276698447

Epoch: 5| Step: 11
Training loss: 2.0024338456750406
Validation loss: 2.5596931677399937

Epoch: 296| Step: 0
Training loss: 2.114766894361308
Validation loss: 2.5752366310636456

Epoch: 5| Step: 1
Training loss: 1.5491191883961601
Validation loss: 2.6161838789723997

Epoch: 5| Step: 2
Training loss: 2.4111650479441953
Validation loss: 2.650240615351439

Epoch: 5| Step: 3
Training loss: 2.3651454666273923
Validation loss: 2.6529963518695885

Epoch: 5| Step: 4
Training loss: 2.184369490238603
Validation loss: 2.6489188920501334

Epoch: 5| Step: 5
Training loss: 2.3290258111371096
Validation loss: 2.6599033961883545

Epoch: 5| Step: 6
Training loss: 2.2373450753052
Validation loss: 2.656345156292863

Epoch: 5| Step: 7
Training loss: 2.1089031680773442
Validation loss: 2.61206628204742

Epoch: 5| Step: 8
Training loss: 3.2411869573438765
Validation loss: 2.568723912350244

Epoch: 5| Step: 9
Training loss: 2.1060064474950853
Validation loss: 2.5233272059915075

Epoch: 5| Step: 10
Training loss: 1.599104096999367
Validation loss: 2.485272867072295

Epoch: 5| Step: 11
Training loss: 2.4670118176347695
Validation loss: 2.4864561453017116

Epoch: 297| Step: 0
Training loss: 1.4246261307003216
Validation loss: 2.49769225497799

Epoch: 5| Step: 1
Training loss: 3.264752577188475
Validation loss: 2.501259641404755

Epoch: 5| Step: 2
Training loss: 2.398881007637968
Validation loss: 2.5045774079081746

Epoch: 5| Step: 3
Training loss: 2.036381036278464
Validation loss: 2.5038015628380075

Epoch: 5| Step: 4
Training loss: 2.079882574067974
Validation loss: 2.51608445530858

Epoch: 5| Step: 5
Training loss: 2.042274254938659
Validation loss: 2.4909100801343955

Epoch: 5| Step: 6
Training loss: 2.4278135279106903
Validation loss: 2.483267859314789

Epoch: 5| Step: 7
Training loss: 2.5272331862166277
Validation loss: 2.492595148977453

Epoch: 5| Step: 8
Training loss: 2.8699895902438235
Validation loss: 2.4779855227895466

Epoch: 5| Step: 9
Training loss: 2.2552462979146672
Validation loss: 2.477473926602665

Epoch: 5| Step: 10
Training loss: 1.6141409072960662
Validation loss: 2.4804348400130958

Epoch: 5| Step: 11
Training loss: 2.7797082635405297
Validation loss: 2.4983942875436274

Epoch: 298| Step: 0
Training loss: 2.119465295909316
Validation loss: 2.5163327044990993

Epoch: 5| Step: 1
Training loss: 2.426374623922034
Validation loss: 2.532317450604081

Epoch: 5| Step: 2
Training loss: 2.1206041758105374
Validation loss: 2.5841576519816782

Epoch: 5| Step: 3
Training loss: 2.105904443846237
Validation loss: 2.601707706465779

Epoch: 5| Step: 4
Training loss: 2.574094546480842
Validation loss: 2.6011561858286494

Epoch: 5| Step: 5
Training loss: 2.7227537994204143
Validation loss: 2.6123969535339

Epoch: 5| Step: 6
Training loss: 1.776259005347235
Validation loss: 2.623570556326063

Epoch: 5| Step: 7
Training loss: 2.4271098996347042
Validation loss: 2.6194596936602426

Epoch: 5| Step: 8
Training loss: 2.1530974188423606
Validation loss: 2.5868803036249757

Epoch: 5| Step: 9
Training loss: 1.6611708469062068
Validation loss: 2.566522248238643

Epoch: 5| Step: 10
Training loss: 2.5595227134845877
Validation loss: 2.5671792416972785

Epoch: 5| Step: 11
Training loss: 2.8525562801709925
Validation loss: 2.5279770636921386

Epoch: 299| Step: 0
Training loss: 1.987674043340502
Validation loss: 2.515666169566165

Epoch: 5| Step: 1
Training loss: 2.51943643081028
Validation loss: 2.518528311370555

Epoch: 5| Step: 2
Training loss: 2.52993325729691
Validation loss: 2.5162269038065648

Epoch: 5| Step: 3
Training loss: 2.344491256479534
Validation loss: 2.5199304939579523

Epoch: 5| Step: 4
Training loss: 1.7491114949392208
Validation loss: 2.5011899301756113

Epoch: 5| Step: 5
Training loss: 2.548424933687308
Validation loss: 2.5049602930331853

Epoch: 5| Step: 6
Training loss: 2.51044893573794
Validation loss: 2.530079421812197

Epoch: 5| Step: 7
Training loss: 2.203416629184403
Validation loss: 2.5394310708177033

Epoch: 5| Step: 8
Training loss: 2.0815229815374265
Validation loss: 2.542851353058186

Epoch: 5| Step: 9
Training loss: 2.058306853192253
Validation loss: 2.561804401764771

Epoch: 5| Step: 10
Training loss: 1.9028731907716474
Validation loss: 2.5784590495082123

Epoch: 5| Step: 11
Training loss: 3.3001646289797635
Validation loss: 2.545100414915724

Epoch: 300| Step: 0
Training loss: 1.9337699424538934
Validation loss: 2.577526631900657

Epoch: 5| Step: 1
Training loss: 2.2549308153860808
Validation loss: 2.600175600510364

Epoch: 5| Step: 2
Training loss: 2.0559936549166724
Validation loss: 2.5961429251108754

Epoch: 5| Step: 3
Training loss: 2.192979543650517
Validation loss: 2.604991062646863

Epoch: 5| Step: 4
Training loss: 2.3909698437073743
Validation loss: 2.6113428169166255

Epoch: 5| Step: 5
Training loss: 1.7964951486880345
Validation loss: 2.6081903361060803

Epoch: 5| Step: 6
Training loss: 2.3264315802103233
Validation loss: 2.5885240117986257

Epoch: 5| Step: 7
Training loss: 1.7821062941012642
Validation loss: 2.5668819321479255

Epoch: 5| Step: 8
Training loss: 2.381483464047666
Validation loss: 2.5753214186458533

Epoch: 5| Step: 9
Training loss: 2.3813345906609222
Validation loss: 2.534953598598488

Epoch: 5| Step: 10
Training loss: 2.4332261397209844
Validation loss: 2.5160181555744883

Epoch: 5| Step: 11
Training loss: 4.176725275511858
Validation loss: 2.5075307234203215

Epoch: 301| Step: 0
Training loss: 1.6849366958906604
Validation loss: 2.5342759777437456

Epoch: 5| Step: 1
Training loss: 2.4868880702938605
Validation loss: 2.4992801941320977

Epoch: 5| Step: 2
Training loss: 2.449555636999516
Validation loss: 2.5356426507130037

Epoch: 5| Step: 3
Training loss: 2.042812480019086
Validation loss: 2.5523654697452702

Epoch: 5| Step: 4
Training loss: 2.4024658172112776
Validation loss: 2.552210087774901

Epoch: 5| Step: 5
Training loss: 1.9537230529684075
Validation loss: 2.5803406837121985

Epoch: 5| Step: 6
Training loss: 1.5724986786222743
Validation loss: 2.5594161015192394

Epoch: 5| Step: 7
Training loss: 2.532707454096242
Validation loss: 2.551059573354579

Epoch: 5| Step: 8
Training loss: 2.196942033463987
Validation loss: 2.5674174623120924

Epoch: 5| Step: 9
Training loss: 2.2738037863016793
Validation loss: 2.5505784262247078

Epoch: 5| Step: 10
Training loss: 2.6306648890506534
Validation loss: 2.5552166382045174

Epoch: 5| Step: 11
Training loss: 1.3113789993703666
Validation loss: 2.546614729175251

Epoch: 302| Step: 0
Training loss: 2.0345251821936197
Validation loss: 2.5579845372941348

Epoch: 5| Step: 1
Training loss: 2.7193506388536384
Validation loss: 2.544292216892765

Epoch: 5| Step: 2
Training loss: 1.9416396923674606
Validation loss: 2.559584408842177

Epoch: 5| Step: 3
Training loss: 1.7539218145754607
Validation loss: 2.5499513842741717

Epoch: 5| Step: 4
Training loss: 2.5975718090128934
Validation loss: 2.532661376137725

Epoch: 5| Step: 5
Training loss: 2.4275845077058023
Validation loss: 2.538179402466986

Epoch: 5| Step: 6
Training loss: 2.011213813299724
Validation loss: 2.5169371584818734

Epoch: 5| Step: 7
Training loss: 2.481423021717079
Validation loss: 2.537808207255516

Epoch: 5| Step: 8
Training loss: 2.1598602147258887
Validation loss: 2.521548115983198

Epoch: 5| Step: 9
Training loss: 1.7236885558886257
Validation loss: 2.552837861037427

Epoch: 5| Step: 10
Training loss: 2.1541151452559344
Validation loss: 2.550855805893012

Epoch: 5| Step: 11
Training loss: 2.363042746875217
Validation loss: 2.5813830702366145

Epoch: 303| Step: 0
Training loss: 2.3359630162303087
Validation loss: 2.587731871144045

Epoch: 5| Step: 1
Training loss: 2.270269854802078
Validation loss: 2.6235314037912185

Epoch: 5| Step: 2
Training loss: 2.513794606257387
Validation loss: 2.6117385355338505

Epoch: 5| Step: 3
Training loss: 1.9561785822010311
Validation loss: 2.605272603122421

Epoch: 5| Step: 4
Training loss: 2.081145421972001
Validation loss: 2.592174741082411

Epoch: 5| Step: 5
Training loss: 2.1832112367963568
Validation loss: 2.560632032602473

Epoch: 5| Step: 6
Training loss: 2.700726100633326
Validation loss: 2.566937001243261

Epoch: 5| Step: 7
Training loss: 2.225649890926513
Validation loss: 2.5690448034930085

Epoch: 5| Step: 8
Training loss: 1.9771796910152992
Validation loss: 2.5802848477056317

Epoch: 5| Step: 9
Training loss: 2.230567408849951
Validation loss: 2.5258943075608573

Epoch: 5| Step: 10
Training loss: 1.6097617564239337
Validation loss: 2.5414375543254364

Epoch: 5| Step: 11
Training loss: 2.015765281349649
Validation loss: 2.5328134645385285

Epoch: 304| Step: 0
Training loss: 2.872601047262463
Validation loss: 2.5150135276473597

Epoch: 5| Step: 1
Training loss: 1.6430959350290488
Validation loss: 2.5314017317078794

Epoch: 5| Step: 2
Training loss: 2.4080124382762365
Validation loss: 2.541660892500859

Epoch: 5| Step: 3
Training loss: 1.998505868704136
Validation loss: 2.5414620978989966

Epoch: 5| Step: 4
Training loss: 2.2197509442058987
Validation loss: 2.528527506853381

Epoch: 5| Step: 5
Training loss: 2.044897857204346
Validation loss: 2.549278213691266

Epoch: 5| Step: 6
Training loss: 2.712413199306022
Validation loss: 2.5661010483295343

Epoch: 5| Step: 7
Training loss: 2.088498946693964
Validation loss: 2.5639700975801962

Epoch: 5| Step: 8
Training loss: 2.0720093880591666
Validation loss: 2.587799197327339

Epoch: 5| Step: 9
Training loss: 2.249297880189928
Validation loss: 2.610670023438507

Epoch: 5| Step: 10
Training loss: 1.6943876494945433
Validation loss: 2.6025094952075714

Epoch: 5| Step: 11
Training loss: 2.66316498882832
Validation loss: 2.598562066416012

Epoch: 305| Step: 0
Training loss: 1.825900297319641
Validation loss: 2.5751481180275007

Epoch: 5| Step: 1
Training loss: 2.041263138214271
Validation loss: 2.5678427482433706

Epoch: 5| Step: 2
Training loss: 2.379397086383427
Validation loss: 2.54092687382914

Epoch: 5| Step: 3
Training loss: 1.7597957697412905
Validation loss: 2.515326740914785

Epoch: 5| Step: 4
Training loss: 2.1091387581106074
Validation loss: 2.505727648029225

Epoch: 5| Step: 5
Training loss: 2.3447839109500674
Validation loss: 2.4963161606219826

Epoch: 5| Step: 6
Training loss: 2.1993953437438836
Validation loss: 2.5029211104939755

Epoch: 5| Step: 7
Training loss: 2.9436822320544365
Validation loss: 2.488983067300504

Epoch: 5| Step: 8
Training loss: 2.6933135207866985
Validation loss: 2.496395986264953

Epoch: 5| Step: 9
Training loss: 2.469939705734409
Validation loss: 2.504750867594533

Epoch: 5| Step: 10
Training loss: 1.7557228383240953
Validation loss: 2.5133965298712044

Epoch: 5| Step: 11
Training loss: 1.5712323886852448
Validation loss: 2.5120067006204514

Epoch: 306| Step: 0
Training loss: 2.6847568085002735
Validation loss: 2.519283363311651

Epoch: 5| Step: 1
Training loss: 2.099698399275458
Validation loss: 2.556974979274489

Epoch: 5| Step: 2
Training loss: 2.1001999986869975
Validation loss: 2.550657081405362

Epoch: 5| Step: 3
Training loss: 2.288044361318008
Validation loss: 2.5406884645712933

Epoch: 5| Step: 4
Training loss: 1.8904871614510066
Validation loss: 2.5602528674624865

Epoch: 5| Step: 5
Training loss: 2.082603504773115
Validation loss: 2.552238865738671

Epoch: 5| Step: 6
Training loss: 2.072228117665395
Validation loss: 2.54577095191518

Epoch: 5| Step: 7
Training loss: 2.131023397173132
Validation loss: 2.5376163276698427

Epoch: 5| Step: 8
Training loss: 1.69516588271438
Validation loss: 2.5369962843743825

Epoch: 5| Step: 9
Training loss: 2.5162700513181986
Validation loss: 2.5385616375796722

Epoch: 5| Step: 10
Training loss: 2.7857492465665485
Validation loss: 2.5302477685256215

Epoch: 5| Step: 11
Training loss: 1.523418406831475
Validation loss: 2.5199248033643635

Epoch: 307| Step: 0
Training loss: 1.806294440016473
Validation loss: 2.5229903101443325

Epoch: 5| Step: 1
Training loss: 2.1449174376917544
Validation loss: 2.520088481150756

Epoch: 5| Step: 2
Training loss: 2.6679985078238415
Validation loss: 2.5308054290280304

Epoch: 5| Step: 3
Training loss: 2.2797862543335063
Validation loss: 2.5240853740654883

Epoch: 5| Step: 4
Training loss: 2.028995495207906
Validation loss: 2.568713261696611

Epoch: 5| Step: 5
Training loss: 2.2032029158429567
Validation loss: 2.6028383274990015

Epoch: 5| Step: 6
Training loss: 2.392852941806253
Validation loss: 2.571191592940129

Epoch: 5| Step: 7
Training loss: 2.5407564586680054
Validation loss: 2.5844537217905854

Epoch: 5| Step: 8
Training loss: 2.4408314753098046
Validation loss: 2.5990570765653485

Epoch: 5| Step: 9
Training loss: 2.306276452551177
Validation loss: 2.60515076290085

Epoch: 5| Step: 10
Training loss: 1.7004919434255346
Validation loss: 2.5697409198164007

Epoch: 5| Step: 11
Training loss: 1.541011679756713
Validation loss: 2.55984050474916

Epoch: 308| Step: 0
Training loss: 2.305520427645624
Validation loss: 2.5554431338276635

Epoch: 5| Step: 1
Training loss: 2.4433949907788413
Validation loss: 2.505624170878092

Epoch: 5| Step: 2
Training loss: 2.9379596756361486
Validation loss: 2.5188704853884105

Epoch: 5| Step: 3
Training loss: 1.8074927387645698
Validation loss: 2.545442865013854

Epoch: 5| Step: 4
Training loss: 1.7849942390498525
Validation loss: 2.5663549107449093

Epoch: 5| Step: 5
Training loss: 2.2875049486784222
Validation loss: 2.57965300583339

Epoch: 5| Step: 6
Training loss: 2.431601111156111
Validation loss: 2.6021211805154185

Epoch: 5| Step: 7
Training loss: 2.2438266624168857
Validation loss: 2.6297319087756987

Epoch: 5| Step: 8
Training loss: 1.5222645474479763
Validation loss: 2.6127508867373193

Epoch: 5| Step: 9
Training loss: 1.9479220861131754
Validation loss: 2.613618362343406

Epoch: 5| Step: 10
Training loss: 2.484768050668915
Validation loss: 2.6259517420244403

Epoch: 5| Step: 11
Training loss: 1.689355465927402
Validation loss: 2.5922657844996606

Epoch: 309| Step: 0
Training loss: 1.6380008601278393
Validation loss: 2.579251291882383

Epoch: 5| Step: 1
Training loss: 2.016421729837242
Validation loss: 2.5629052931017906

Epoch: 5| Step: 2
Training loss: 2.286331161635178
Validation loss: 2.5482104842944024

Epoch: 5| Step: 3
Training loss: 2.688680522593877
Validation loss: 2.507835193978974

Epoch: 5| Step: 4
Training loss: 2.46261897695258
Validation loss: 2.5329013665321765

Epoch: 5| Step: 5
Training loss: 2.3771353708957594
Validation loss: 2.5032893832899457

Epoch: 5| Step: 6
Training loss: 2.212713707554396
Validation loss: 2.559381424892312

Epoch: 5| Step: 7
Training loss: 1.9918049762962822
Validation loss: 2.573881135835513

Epoch: 5| Step: 8
Training loss: 2.2205515250309737
Validation loss: 2.568024998160922

Epoch: 5| Step: 9
Training loss: 1.8976291772349025
Validation loss: 2.579398074011833

Epoch: 5| Step: 10
Training loss: 2.4229728917436852
Validation loss: 2.5917754336488095

Epoch: 5| Step: 11
Training loss: 1.2263763675264092
Validation loss: 2.605903146992103

Epoch: 310| Step: 0
Training loss: 1.6901468076651127
Validation loss: 2.6002514488334274

Epoch: 5| Step: 1
Training loss: 2.2438537573666073
Validation loss: 2.6049326469515117

Epoch: 5| Step: 2
Training loss: 1.7680278395666014
Validation loss: 2.5904442161550123

Epoch: 5| Step: 3
Training loss: 2.064410047704248
Validation loss: 2.6366570058115957

Epoch: 5| Step: 4
Training loss: 2.6015744137419587
Validation loss: 2.6060517767821056

Epoch: 5| Step: 5
Training loss: 1.4807774365375905
Validation loss: 2.5868464559839066

Epoch: 5| Step: 6
Training loss: 2.5667070418646
Validation loss: 2.5907231444575816

Epoch: 5| Step: 7
Training loss: 2.467781263126937
Validation loss: 2.609313442547268

Epoch: 5| Step: 8
Training loss: 2.57787372636174
Validation loss: 2.5814727663986083

Epoch: 5| Step: 9
Training loss: 1.9605944207980344
Validation loss: 2.57492272298094

Epoch: 5| Step: 10
Training loss: 2.3505628114774306
Validation loss: 2.555262377468465

Epoch: 5| Step: 11
Training loss: 1.8163151543857332
Validation loss: 2.559127608263813

Epoch: 311| Step: 0
Training loss: 2.2685031893234586
Validation loss: 2.5676663738998187

Epoch: 5| Step: 1
Training loss: 2.6448240582912894
Validation loss: 2.582508429728632

Epoch: 5| Step: 2
Training loss: 2.292570271221
Validation loss: 2.580262779387271

Epoch: 5| Step: 3
Training loss: 2.3141638466370593
Validation loss: 2.6038227324659946

Epoch: 5| Step: 4
Training loss: 1.831208782578452
Validation loss: 2.5703513887472327

Epoch: 5| Step: 5
Training loss: 2.2729016488543867
Validation loss: 2.5952555507602635

Epoch: 5| Step: 6
Training loss: 2.9139263540582148
Validation loss: 2.6025271150029665

Epoch: 5| Step: 7
Training loss: 1.4665899422835864
Validation loss: 2.5810489603961244

Epoch: 5| Step: 8
Training loss: 1.296096890050799
Validation loss: 2.5869477479728067

Epoch: 5| Step: 9
Training loss: 1.4689891701617859
Validation loss: 2.5707279553653923

Epoch: 5| Step: 10
Training loss: 2.546783352004469
Validation loss: 2.585333550987395

Epoch: 5| Step: 11
Training loss: 1.7069728675478217
Validation loss: 2.5764811698642016

Epoch: 312| Step: 0
Training loss: 2.7574525765761866
Validation loss: 2.5709413920485473

Epoch: 5| Step: 1
Training loss: 1.8622593666647158
Validation loss: 2.5972286054008045

Epoch: 5| Step: 2
Training loss: 2.122317809248504
Validation loss: 2.620344271815073

Epoch: 5| Step: 3
Training loss: 1.699502153988377
Validation loss: 2.6164450849777867

Epoch: 5| Step: 4
Training loss: 1.9396241142446455
Validation loss: 2.6107969996942444

Epoch: 5| Step: 5
Training loss: 1.6768017487054545
Validation loss: 2.593693491308677

Epoch: 5| Step: 6
Training loss: 2.8332417604196505
Validation loss: 2.543764871652231

Epoch: 5| Step: 7
Training loss: 2.4410515367317562
Validation loss: 2.5507997840258634

Epoch: 5| Step: 8
Training loss: 1.9032906872012962
Validation loss: 2.5290169736522103

Epoch: 5| Step: 9
Training loss: 2.459460296508923
Validation loss: 2.519769599148233

Epoch: 5| Step: 10
Training loss: 2.253672040542013
Validation loss: 2.5340101828509787

Epoch: 5| Step: 11
Training loss: 1.3259281164768253
Validation loss: 2.5121885604846668

Epoch: 313| Step: 0
Training loss: 1.8174273502359373
Validation loss: 2.5432758175203123

Epoch: 5| Step: 1
Training loss: 1.9506400207312766
Validation loss: 2.519188369169983

Epoch: 5| Step: 2
Training loss: 2.137377761111748
Validation loss: 2.5246698738115882

Epoch: 5| Step: 3
Training loss: 2.2179677954520884
Validation loss: 2.5353443250363528

Epoch: 5| Step: 4
Training loss: 1.897842313927083
Validation loss: 2.555348881338141

Epoch: 5| Step: 5
Training loss: 2.698569985800205
Validation loss: 2.538161386853556

Epoch: 5| Step: 6
Training loss: 1.5366724500871394
Validation loss: 2.5717826820512717

Epoch: 5| Step: 7
Training loss: 2.032847671145886
Validation loss: 2.583822316888028

Epoch: 5| Step: 8
Training loss: 2.4806588648231114
Validation loss: 2.600891450590953

Epoch: 5| Step: 9
Training loss: 2.667457274619439
Validation loss: 2.6301203357340985

Epoch: 5| Step: 10
Training loss: 2.276504178632139
Validation loss: 2.629156855541207

Epoch: 5| Step: 11
Training loss: 1.1847184883397721
Validation loss: 2.6119653251993684

Epoch: 314| Step: 0
Training loss: 2.1456444913366064
Validation loss: 2.6355085595636694

Epoch: 5| Step: 1
Training loss: 2.8122687350664806
Validation loss: 2.6409391859593336

Epoch: 5| Step: 2
Training loss: 1.7550287201968577
Validation loss: 2.6197905391946015

Epoch: 5| Step: 3
Training loss: 2.4270378948973628
Validation loss: 2.6089859251712726

Epoch: 5| Step: 4
Training loss: 1.772905311891778
Validation loss: 2.601391443961996

Epoch: 5| Step: 5
Training loss: 2.4380503302206886
Validation loss: 2.5836695880369738

Epoch: 5| Step: 6
Training loss: 2.1493818947076098
Validation loss: 2.566978789420845

Epoch: 5| Step: 7
Training loss: 2.063513997826541
Validation loss: 2.568073224854555

Epoch: 5| Step: 8
Training loss: 2.25060539578176
Validation loss: 2.5525483907881883

Epoch: 5| Step: 9
Training loss: 1.7912954862666468
Validation loss: 2.543529079600976

Epoch: 5| Step: 10
Training loss: 2.076991295441344
Validation loss: 2.548020976799174

Epoch: 5| Step: 11
Training loss: 2.4337855672172157
Validation loss: 2.532308045358753

Epoch: 315| Step: 0
Training loss: 1.7283422350799853
Validation loss: 2.5702328771067764

Epoch: 5| Step: 1
Training loss: 2.5511202389782346
Validation loss: 2.5922378053817656

Epoch: 5| Step: 2
Training loss: 2.004567414609535
Validation loss: 2.6190922272999373

Epoch: 5| Step: 3
Training loss: 2.2539509945664262
Validation loss: 2.6409707567225

Epoch: 5| Step: 4
Training loss: 2.1248561586053736
Validation loss: 2.651882043428018

Epoch: 5| Step: 5
Training loss: 2.354276693918087
Validation loss: 2.624812115651336

Epoch: 5| Step: 6
Training loss: 1.7599390348799417
Validation loss: 2.6106022672642912

Epoch: 5| Step: 7
Training loss: 2.0156802384252024
Validation loss: 2.5916178032254087

Epoch: 5| Step: 8
Training loss: 2.706221378166251
Validation loss: 2.5580125415512946

Epoch: 5| Step: 9
Training loss: 2.596575932547771
Validation loss: 2.5783320025946304

Epoch: 5| Step: 10
Training loss: 1.6087525284279707
Validation loss: 2.5758577569350574

Epoch: 5| Step: 11
Training loss: 3.0712513349729686
Validation loss: 2.5446788586911673

Epoch: 316| Step: 0
Training loss: 2.4615204620161735
Validation loss: 2.527562422335287

Epoch: 5| Step: 1
Training loss: 2.1559306474901065
Validation loss: 2.5548316261629553

Epoch: 5| Step: 2
Training loss: 1.508010930262044
Validation loss: 2.542738359584736

Epoch: 5| Step: 3
Training loss: 2.2195192534764674
Validation loss: 2.5453464000763497

Epoch: 5| Step: 4
Training loss: 2.171858972723575
Validation loss: 2.557855739395033

Epoch: 5| Step: 5
Training loss: 2.891804222624226
Validation loss: 2.5466183862730256

Epoch: 5| Step: 6
Training loss: 2.8198152140684147
Validation loss: 2.5537673311832654

Epoch: 5| Step: 7
Training loss: 1.988863456937604
Validation loss: 2.5442280773889996

Epoch: 5| Step: 8
Training loss: 1.7268401738236798
Validation loss: 2.552823462825215

Epoch: 5| Step: 9
Training loss: 1.5672029291003877
Validation loss: 2.571478856363932

Epoch: 5| Step: 10
Training loss: 2.1510395730464866
Validation loss: 2.566326521395173

Epoch: 5| Step: 11
Training loss: 1.3323701220515343
Validation loss: 2.576087447049002

Epoch: 317| Step: 0
Training loss: 2.128853165550897
Validation loss: 2.5933938490463837

Epoch: 5| Step: 1
Training loss: 2.1195546110604413
Validation loss: 2.5809776649716962

Epoch: 5| Step: 2
Training loss: 2.358231020843475
Validation loss: 2.6160144359518895

Epoch: 5| Step: 3
Training loss: 2.419166379274392
Validation loss: 2.613975922951581

Epoch: 5| Step: 4
Training loss: 2.101680936631299
Validation loss: 2.6242169620091036

Epoch: 5| Step: 5
Training loss: 2.4063437307358355
Validation loss: 2.5842800149064233

Epoch: 5| Step: 6
Training loss: 2.3642432910799394
Validation loss: 2.6045874687991533

Epoch: 5| Step: 7
Training loss: 2.2955633038113805
Validation loss: 2.5848571925618975

Epoch: 5| Step: 8
Training loss: 1.6346886911827243
Validation loss: 2.560600608031049

Epoch: 5| Step: 9
Training loss: 1.9426956653608074
Validation loss: 2.5794990191890665

Epoch: 5| Step: 10
Training loss: 2.082826387397731
Validation loss: 2.5585905235211945

Epoch: 5| Step: 11
Training loss: 1.5736809277999662
Validation loss: 2.5407640810095256

Epoch: 318| Step: 0
Training loss: 1.9300637438233892
Validation loss: 2.5533949472319857

Epoch: 5| Step: 1
Training loss: 2.5948317696315515
Validation loss: 2.559784050819897

Epoch: 5| Step: 2
Training loss: 1.6424339857146222
Validation loss: 2.5941316867638577

Epoch: 5| Step: 3
Training loss: 2.5344444180728805
Validation loss: 2.5732271853931956

Epoch: 5| Step: 4
Training loss: 2.059765939840911
Validation loss: 2.584784927976356

Epoch: 5| Step: 5
Training loss: 2.1152048434717123
Validation loss: 2.565975325282424

Epoch: 5| Step: 6
Training loss: 2.526414184369112
Validation loss: 2.5681486596912824

Epoch: 5| Step: 7
Training loss: 2.1017855274169337
Validation loss: 2.5576380723603296

Epoch: 5| Step: 8
Training loss: 2.1880015207037795
Validation loss: 2.57679427897054

Epoch: 5| Step: 9
Training loss: 2.241010084273371
Validation loss: 2.5433778643698908

Epoch: 5| Step: 10
Training loss: 2.0024027696261912
Validation loss: 2.5420550390996013

Epoch: 5| Step: 11
Training loss: 1.0664166460473687
Validation loss: 2.541939002960952

Epoch: 319| Step: 0
Training loss: 2.7615937416456613
Validation loss: 2.521219686320585

Epoch: 5| Step: 1
Training loss: 1.9210020734546438
Validation loss: 2.5385017714863354

Epoch: 5| Step: 2
Training loss: 2.268825821883731
Validation loss: 2.513892526928381

Epoch: 5| Step: 3
Training loss: 1.9590403585906324
Validation loss: 2.5340953266505997

Epoch: 5| Step: 4
Training loss: 2.419686688562568
Validation loss: 2.5430182878441965

Epoch: 5| Step: 5
Training loss: 2.374140332889247
Validation loss: 2.523115241827406

Epoch: 5| Step: 6
Training loss: 1.7657979694814065
Validation loss: 2.5364064805972997

Epoch: 5| Step: 7
Training loss: 2.796786599919977
Validation loss: 2.54787471863554

Epoch: 5| Step: 8
Training loss: 2.104738352953476
Validation loss: 2.5654082155194304

Epoch: 5| Step: 9
Training loss: 1.7947843911998944
Validation loss: 2.591977168512455

Epoch: 5| Step: 10
Training loss: 1.7778765540034056
Validation loss: 2.596515020491217

Epoch: 5| Step: 11
Training loss: 1.6482862068641992
Validation loss: 2.5643430571457473

Epoch: 320| Step: 0
Training loss: 1.671824017754543
Validation loss: 2.5821533674409234

Epoch: 5| Step: 1
Training loss: 1.623987322490049
Validation loss: 2.5812288923839897

Epoch: 5| Step: 2
Training loss: 2.332551166590603
Validation loss: 2.5300202620301806

Epoch: 5| Step: 3
Training loss: 1.245692364851664
Validation loss: 2.553954599692414

Epoch: 5| Step: 4
Training loss: 2.5694535974104697
Validation loss: 2.546528045643418

Epoch: 5| Step: 5
Training loss: 2.3972988345783066
Validation loss: 2.5272649863782375

Epoch: 5| Step: 6
Training loss: 2.366422624049646
Validation loss: 2.5291187768630614

Epoch: 5| Step: 7
Training loss: 1.6964382529878774
Validation loss: 2.5441998511219266

Epoch: 5| Step: 8
Training loss: 2.439432796152286
Validation loss: 2.5383562210985615

Epoch: 5| Step: 9
Training loss: 2.480289386662241
Validation loss: 2.555323969643546

Epoch: 5| Step: 10
Training loss: 2.547595899160124
Validation loss: 2.573026837501168

Epoch: 5| Step: 11
Training loss: 2.6910924631689466
Validation loss: 2.6214391042155727

Epoch: 321| Step: 0
Training loss: 2.742040733474469
Validation loss: 2.536324610439168

Epoch: 5| Step: 1
Training loss: 2.1000119980968868
Validation loss: 2.530838014489263

Epoch: 5| Step: 2
Training loss: 2.036919648066522
Validation loss: 2.5309360018975875

Epoch: 5| Step: 3
Training loss: 1.9046996018461035
Validation loss: 2.5148016172499825

Epoch: 5| Step: 4
Training loss: 2.598663272557294
Validation loss: 2.5025127260543196

Epoch: 5| Step: 5
Training loss: 2.9787751231732877
Validation loss: 2.5040721074646037

Epoch: 5| Step: 6
Training loss: 1.8527793909371195
Validation loss: 2.5049271627345613

Epoch: 5| Step: 7
Training loss: 1.8994154432433927
Validation loss: 2.528966265934466

Epoch: 5| Step: 8
Training loss: 1.769221668235948
Validation loss: 2.5189717028773666

Epoch: 5| Step: 9
Training loss: 1.9681523339271396
Validation loss: 2.536341060666346

Epoch: 5| Step: 10
Training loss: 1.7510728953169667
Validation loss: 2.541462422330696

Epoch: 5| Step: 11
Training loss: 4.031910450379921
Validation loss: 2.541873764501765

Epoch: 322| Step: 0
Training loss: 1.9653959010390363
Validation loss: 2.5788887279877875

Epoch: 5| Step: 1
Training loss: 2.1411548710506043
Validation loss: 2.5689984318253387

Epoch: 5| Step: 2
Training loss: 1.829410785498374
Validation loss: 2.5414808015142643

Epoch: 5| Step: 3
Training loss: 2.6195083576206684
Validation loss: 2.5296370583135768

Epoch: 5| Step: 4
Training loss: 2.3495155119123075
Validation loss: 2.5297273640184597

Epoch: 5| Step: 5
Training loss: 1.7149377332232818
Validation loss: 2.540014663573238

Epoch: 5| Step: 6
Training loss: 2.2537062108276005
Validation loss: 2.5180098797465713

Epoch: 5| Step: 7
Training loss: 2.1963253196345867
Validation loss: 2.5172391652938555

Epoch: 5| Step: 8
Training loss: 2.1913189930126977
Validation loss: 2.516536961985695

Epoch: 5| Step: 9
Training loss: 2.810601165650067
Validation loss: 2.5312235363805304

Epoch: 5| Step: 10
Training loss: 1.9891468254967477
Validation loss: 2.5187650279376923

Epoch: 5| Step: 11
Training loss: 1.7032011522539146
Validation loss: 2.5081233983621334

Epoch: 323| Step: 0
Training loss: 2.0698004323245462
Validation loss: 2.530252393514542

Epoch: 5| Step: 1
Training loss: 2.0934008406831572
Validation loss: 2.5185195330715033

Epoch: 5| Step: 2
Training loss: 1.5740254853837963
Validation loss: 2.5549501639841545

Epoch: 5| Step: 3
Training loss: 1.839082467255168
Validation loss: 2.5801173901897028

Epoch: 5| Step: 4
Training loss: 2.6389619002922053
Validation loss: 2.5615722054364385

Epoch: 5| Step: 5
Training loss: 2.300169677280571
Validation loss: 2.572705018196891

Epoch: 5| Step: 6
Training loss: 1.756136760929968
Validation loss: 2.5618111994997057

Epoch: 5| Step: 7
Training loss: 2.424754246322669
Validation loss: 2.5972182016857213

Epoch: 5| Step: 8
Training loss: 2.401529313641831
Validation loss: 2.5860316748244094

Epoch: 5| Step: 9
Training loss: 1.5852789051625333
Validation loss: 2.5802342620047845

Epoch: 5| Step: 10
Training loss: 2.600512226706031
Validation loss: 2.5578348097064203

Epoch: 5| Step: 11
Training loss: 2.0599394422722375
Validation loss: 2.5336539622948844

Epoch: 324| Step: 0
Training loss: 2.00073598194562
Validation loss: 2.544697460586209

Epoch: 5| Step: 1
Training loss: 1.9378023834530405
Validation loss: 2.5381864943918346

Epoch: 5| Step: 2
Training loss: 2.0886621860602608
Validation loss: 2.545817282314449

Epoch: 5| Step: 3
Training loss: 1.8698777486241727
Validation loss: 2.5595937235631316

Epoch: 5| Step: 4
Training loss: 2.4106965039117156
Validation loss: 2.5729839854114536

Epoch: 5| Step: 5
Training loss: 2.9691240576949474
Validation loss: 2.622888306052086

Epoch: 5| Step: 6
Training loss: 1.7579757275560284
Validation loss: 2.667659095529228

Epoch: 5| Step: 7
Training loss: 1.884025025013229
Validation loss: 2.7012465497238622

Epoch: 5| Step: 8
Training loss: 2.2949918955408415
Validation loss: 2.697036059400539

Epoch: 5| Step: 9
Training loss: 2.3262363428107484
Validation loss: 2.705596609726682

Epoch: 5| Step: 10
Training loss: 2.2568667850012103
Validation loss: 2.6951922624831353

Epoch: 5| Step: 11
Training loss: 1.5056143436395228
Validation loss: 2.6360796344562982

Epoch: 325| Step: 0
Training loss: 2.2977128349737646
Validation loss: 2.609607157021106

Epoch: 5| Step: 1
Training loss: 1.8418681999627269
Validation loss: 2.5764890277443104

Epoch: 5| Step: 2
Training loss: 1.800991683216368
Validation loss: 2.5504570794441754

Epoch: 5| Step: 3
Training loss: 2.216631240370426
Validation loss: 2.540507587114339

Epoch: 5| Step: 4
Training loss: 2.233352640647368
Validation loss: 2.5324891671780323

Epoch: 5| Step: 5
Training loss: 2.6637880066443054
Validation loss: 2.55897801743507

Epoch: 5| Step: 6
Training loss: 2.573503177733504
Validation loss: 2.5489936862536626

Epoch: 5| Step: 7
Training loss: 1.8018316486395345
Validation loss: 2.5633548729487208

Epoch: 5| Step: 8
Training loss: 2.0144219171763376
Validation loss: 2.559862186421609

Epoch: 5| Step: 9
Training loss: 2.2483219671091694
Validation loss: 2.579819297851007

Epoch: 5| Step: 10
Training loss: 1.9917222620441621
Validation loss: 2.579680988589286

Epoch: 5| Step: 11
Training loss: 1.8956383685235827
Validation loss: 2.576791094557294

Epoch: 326| Step: 0
Training loss: 2.3341589443410897
Validation loss: 2.5849141749701614

Epoch: 5| Step: 1
Training loss: 2.666347295789488
Validation loss: 2.5559447380610485

Epoch: 5| Step: 2
Training loss: 1.4208413863116995
Validation loss: 2.5586462466845754

Epoch: 5| Step: 3
Training loss: 2.043714573171067
Validation loss: 2.548566970015621

Epoch: 5| Step: 4
Training loss: 2.773059228164836
Validation loss: 2.5453463103107774

Epoch: 5| Step: 5
Training loss: 2.0577140535457468
Validation loss: 2.5688743046109064

Epoch: 5| Step: 6
Training loss: 2.113137852004333
Validation loss: 2.5257580640542594

Epoch: 5| Step: 7
Training loss: 2.302351048525609
Validation loss: 2.537958427417131

Epoch: 5| Step: 8
Training loss: 1.917583170433657
Validation loss: 2.533648637758736

Epoch: 5| Step: 9
Training loss: 1.8119073096056253
Validation loss: 2.535258676568941

Epoch: 5| Step: 10
Training loss: 2.157840971099394
Validation loss: 2.5549626683421143

Epoch: 5| Step: 11
Training loss: 1.3338586348647838
Validation loss: 2.5458953919835734

Epoch: 327| Step: 0
Training loss: 1.5610017077860021
Validation loss: 2.584864901997417

Epoch: 5| Step: 1
Training loss: 1.4997182422498851
Validation loss: 2.6003559166963024

Epoch: 5| Step: 2
Training loss: 1.8574879150202865
Validation loss: 2.616574730948739

Epoch: 5| Step: 3
Training loss: 1.8791496769488787
Validation loss: 2.6007076611683133

Epoch: 5| Step: 4
Training loss: 2.7144971008734995
Validation loss: 2.606253902667178

Epoch: 5| Step: 5
Training loss: 2.1322371716439372
Validation loss: 2.59209103365512

Epoch: 5| Step: 6
Training loss: 1.9480764830063984
Validation loss: 2.6005919118944627

Epoch: 5| Step: 7
Training loss: 1.9213181596130777
Validation loss: 2.534800570654628

Epoch: 5| Step: 8
Training loss: 2.983185695923454
Validation loss: 2.5392949589664564

Epoch: 5| Step: 9
Training loss: 2.307872678970321
Validation loss: 2.5421327817561767

Epoch: 5| Step: 10
Training loss: 2.2189239648665593
Validation loss: 2.5522903604939775

Epoch: 5| Step: 11
Training loss: 1.4130135961230785
Validation loss: 2.566731684395888

Epoch: 328| Step: 0
Training loss: 2.5463947241155322
Validation loss: 2.5550397013804034

Epoch: 5| Step: 1
Training loss: 2.2644884086677775
Validation loss: 2.6120417971849808

Epoch: 5| Step: 2
Training loss: 2.1953431259679803
Validation loss: 2.5925427618580237

Epoch: 5| Step: 3
Training loss: 1.821584298184538
Validation loss: 2.6092214063260855

Epoch: 5| Step: 4
Training loss: 2.1105196637410413
Validation loss: 2.568986386346093

Epoch: 5| Step: 5
Training loss: 1.839329155555747
Validation loss: 2.609932423060247

Epoch: 5| Step: 6
Training loss: 2.2762443283488016
Validation loss: 2.5827811340593674

Epoch: 5| Step: 7
Training loss: 2.315315285587167
Validation loss: 2.597483475754637

Epoch: 5| Step: 8
Training loss: 1.4820277880123969
Validation loss: 2.5943418348473615

Epoch: 5| Step: 9
Training loss: 2.1896763465742106
Validation loss: 2.5884512124993075

Epoch: 5| Step: 10
Training loss: 1.7655598451188697
Validation loss: 2.5733214586318316

Epoch: 5| Step: 11
Training loss: 1.6796654278391723
Validation loss: 2.556297902915198

Epoch: 329| Step: 0
Training loss: 2.135890653776006
Validation loss: 2.535054369869456

Epoch: 5| Step: 1
Training loss: 2.29125569444314
Validation loss: 2.552499205252598

Epoch: 5| Step: 2
Training loss: 1.5969687477259469
Validation loss: 2.537782144755236

Epoch: 5| Step: 3
Training loss: 1.930721422963186
Validation loss: 2.550518209263768

Epoch: 5| Step: 4
Training loss: 2.2974410624618513
Validation loss: 2.544871960431265

Epoch: 5| Step: 5
Training loss: 2.582376384897044
Validation loss: 2.5786008106776004

Epoch: 5| Step: 6
Training loss: 1.7772134251025868
Validation loss: 2.58634801028378

Epoch: 5| Step: 7
Training loss: 1.6290685632279294
Validation loss: 2.5913640043847814

Epoch: 5| Step: 8
Training loss: 1.7622846214778043
Validation loss: 2.595588350497316

Epoch: 5| Step: 9
Training loss: 2.380142667325068
Validation loss: 2.6144830119629843

Epoch: 5| Step: 10
Training loss: 2.3782708583219057
Validation loss: 2.5896003842783477

Epoch: 5| Step: 11
Training loss: 2.0244504536119523
Validation loss: 2.6061778516716223

Epoch: 330| Step: 0
Training loss: 2.4048011678559593
Validation loss: 2.5844658681507813

Epoch: 5| Step: 1
Training loss: 1.880057063758513
Validation loss: 2.5439109951250183

Epoch: 5| Step: 2
Training loss: 2.09476503279068
Validation loss: 2.556278553797791

Epoch: 5| Step: 3
Training loss: 1.896872546525905
Validation loss: 2.536194081937938

Epoch: 5| Step: 4
Training loss: 2.2131531737246366
Validation loss: 2.5371579661621606

Epoch: 5| Step: 5
Training loss: 2.498042007453477
Validation loss: 2.5237276404531666

Epoch: 5| Step: 6
Training loss: 2.014188269216683
Validation loss: 2.5180857235207803

Epoch: 5| Step: 7
Training loss: 1.9754826909540137
Validation loss: 2.515996652796257

Epoch: 5| Step: 8
Training loss: 1.771828682107388
Validation loss: 2.561085358967977

Epoch: 5| Step: 9
Training loss: 2.570983984524532
Validation loss: 2.5723613700918975

Epoch: 5| Step: 10
Training loss: 2.325159116653122
Validation loss: 2.572318603464389

Epoch: 5| Step: 11
Training loss: 1.289049784279732
Validation loss: 2.5789399352170994

Epoch: 331| Step: 0
Training loss: 2.202237105857646
Validation loss: 2.6287291695299597

Epoch: 5| Step: 1
Training loss: 1.922463737810524
Validation loss: 2.5882737400365485

Epoch: 5| Step: 2
Training loss: 1.6794637841569915
Validation loss: 2.636626223600803

Epoch: 5| Step: 3
Training loss: 1.7490616053554584
Validation loss: 2.607062489557998

Epoch: 5| Step: 4
Training loss: 2.567447073891473
Validation loss: 2.5796094185195195

Epoch: 5| Step: 5
Training loss: 2.6053448466017612
Validation loss: 2.5642689979927757

Epoch: 5| Step: 6
Training loss: 2.2115418379895004
Validation loss: 2.5480120388895147

Epoch: 5| Step: 7
Training loss: 2.2883924733980154
Validation loss: 2.5382788245918553

Epoch: 5| Step: 8
Training loss: 2.4317821047885184
Validation loss: 2.5678369104305947

Epoch: 5| Step: 9
Training loss: 1.6057534812284908
Validation loss: 2.539867844629146

Epoch: 5| Step: 10
Training loss: 2.0502960503035608
Validation loss: 2.5065431442436057

Epoch: 5| Step: 11
Training loss: 1.904612478855107
Validation loss: 2.509774815880241

Epoch: 332| Step: 0
Training loss: 1.8579025208244877
Validation loss: 2.5363849822501816

Epoch: 5| Step: 1
Training loss: 2.1020146560666144
Validation loss: 2.5055692905720117

Epoch: 5| Step: 2
Training loss: 2.0997120251069923
Validation loss: 2.530511556060932

Epoch: 5| Step: 3
Training loss: 2.122115814521658
Validation loss: 2.4944184461464576

Epoch: 5| Step: 4
Training loss: 1.6463613588617922
Validation loss: 2.5429203050318496

Epoch: 5| Step: 5
Training loss: 2.3462638089602312
Validation loss: 2.5476667347613993

Epoch: 5| Step: 6
Training loss: 2.2649760402060592
Validation loss: 2.5210923673935093

Epoch: 5| Step: 7
Training loss: 2.32891197472617
Validation loss: 2.5516511058042206

Epoch: 5| Step: 8
Training loss: 2.2939030110310537
Validation loss: 2.5752137749706536

Epoch: 5| Step: 9
Training loss: 2.0951969214414956
Validation loss: 2.5734762974408394

Epoch: 5| Step: 10
Training loss: 2.050700914535136
Validation loss: 2.5909746135838208

Epoch: 5| Step: 11
Training loss: 1.9851873342098847
Validation loss: 2.5570451471308706

Epoch: 333| Step: 0
Training loss: 2.265614581906273
Validation loss: 2.584439130707735

Epoch: 5| Step: 1
Training loss: 2.1229705094936406
Validation loss: 2.560448333062275

Epoch: 5| Step: 2
Training loss: 2.587931437620397
Validation loss: 2.541690083041485

Epoch: 5| Step: 3
Training loss: 1.8470237246044539
Validation loss: 2.5797142024345887

Epoch: 5| Step: 4
Training loss: 1.7709293863014044
Validation loss: 2.6016459561423138

Epoch: 5| Step: 5
Training loss: 2.1518667145901116
Validation loss: 2.6112971279042156

Epoch: 5| Step: 6
Training loss: 2.042765211538677
Validation loss: 2.5941950289859426

Epoch: 5| Step: 7
Training loss: 2.317836583621728
Validation loss: 2.5828574239582083

Epoch: 5| Step: 8
Training loss: 1.3560805904920403
Validation loss: 2.5747711310632733

Epoch: 5| Step: 9
Training loss: 2.1585801291545126
Validation loss: 2.5527057174245393

Epoch: 5| Step: 10
Training loss: 1.8970082872498295
Validation loss: 2.5612333004706342

Epoch: 5| Step: 11
Training loss: 3.4653801572698217
Validation loss: 2.564306217662346

Epoch: 334| Step: 0
Training loss: 1.3811873892147932
Validation loss: 2.5742532306189143

Epoch: 5| Step: 1
Training loss: 2.8429502263819284
Validation loss: 2.5714592235651934

Epoch: 5| Step: 2
Training loss: 1.998698466711973
Validation loss: 2.573054998491273

Epoch: 5| Step: 3
Training loss: 2.0075344976784075
Validation loss: 2.6040609808775126

Epoch: 5| Step: 4
Training loss: 2.7974989211120436
Validation loss: 2.6031491364348107

Epoch: 5| Step: 5
Training loss: 2.145923378052025
Validation loss: 2.628658428480674

Epoch: 5| Step: 6
Training loss: 1.660083078006025
Validation loss: 2.5881916758732277

Epoch: 5| Step: 7
Training loss: 1.708205947158335
Validation loss: 2.5435434132572934

Epoch: 5| Step: 8
Training loss: 2.378144641850246
Validation loss: 2.5089873298296217

Epoch: 5| Step: 9
Training loss: 1.9183174018408222
Validation loss: 2.4693601313061055

Epoch: 5| Step: 10
Training loss: 2.294236308836492
Validation loss: 2.457310849177278

Epoch: 5| Step: 11
Training loss: 3.1546126547140045
Validation loss: 2.4773508576052876

Epoch: 335| Step: 0
Training loss: 1.8075375861432135
Validation loss: 2.4838513116279546

Epoch: 5| Step: 1
Training loss: 1.7676672812891254
Validation loss: 2.5096170938082945

Epoch: 5| Step: 2
Training loss: 2.7529865000567346
Validation loss: 2.508565591570739

Epoch: 5| Step: 3
Training loss: 1.7894458609889266
Validation loss: 2.5100797345312618

Epoch: 5| Step: 4
Training loss: 2.1498390758526527
Validation loss: 2.478720505956228

Epoch: 5| Step: 5
Training loss: 2.3148814131022077
Validation loss: 2.491454085294235

Epoch: 5| Step: 6
Training loss: 2.8060524681933785
Validation loss: 2.4749959891058793

Epoch: 5| Step: 7
Training loss: 2.303382840468693
Validation loss: 2.4481207836894896

Epoch: 5| Step: 8
Training loss: 1.9207174645463296
Validation loss: 2.4636834784587776

Epoch: 5| Step: 9
Training loss: 1.6216005567200604
Validation loss: 2.463495519553982

Epoch: 5| Step: 10
Training loss: 2.4687243110189354
Validation loss: 2.463709732086578

Epoch: 5| Step: 11
Training loss: 1.8755498715601322
Validation loss: 2.533085667640268

Epoch: 336| Step: 0
Training loss: 2.004024033682152
Validation loss: 2.663496164214944

Epoch: 5| Step: 1
Training loss: 2.201271630288666
Validation loss: 2.703892148772949

Epoch: 5| Step: 2
Training loss: 2.5652798716723533
Validation loss: 2.7362712207062514

Epoch: 5| Step: 3
Training loss: 2.733495254682738
Validation loss: 2.7021619738740763

Epoch: 5| Step: 4
Training loss: 1.81029014042842
Validation loss: 2.625815457884794

Epoch: 5| Step: 5
Training loss: 2.205628399909824
Validation loss: 2.577011526850277

Epoch: 5| Step: 6
Training loss: 2.1406117459743075
Validation loss: 2.5133470247812326

Epoch: 5| Step: 7
Training loss: 2.2374990537843886
Validation loss: 2.4882446438079424

Epoch: 5| Step: 8
Training loss: 1.6031927232027041
Validation loss: 2.481006421865916

Epoch: 5| Step: 9
Training loss: 2.476271747645738
Validation loss: 2.4842093750388705

Epoch: 5| Step: 10
Training loss: 2.3822989488853725
Validation loss: 2.48267184563898

Epoch: 5| Step: 11
Training loss: 3.250320858889162
Validation loss: 2.497042871990067

Epoch: 337| Step: 0
Training loss: 1.651077326280198
Validation loss: 2.479161195722255

Epoch: 5| Step: 1
Training loss: 2.4717447972397726
Validation loss: 2.4727388441484477

Epoch: 5| Step: 2
Training loss: 2.073711326013159
Validation loss: 2.482296091850286

Epoch: 5| Step: 3
Training loss: 2.4624891445482198
Validation loss: 2.48625434712087

Epoch: 5| Step: 4
Training loss: 2.3458714357288954
Validation loss: 2.505471056501062

Epoch: 5| Step: 5
Training loss: 2.520555202388909
Validation loss: 2.4754772114751074

Epoch: 5| Step: 6
Training loss: 1.8691775518614304
Validation loss: 2.5305825381690457

Epoch: 5| Step: 7
Training loss: 2.284251498577256
Validation loss: 2.532638118168373

Epoch: 5| Step: 8
Training loss: 2.048674862259422
Validation loss: 2.5619271537483312

Epoch: 5| Step: 9
Training loss: 1.9905676745150718
Validation loss: 2.5552519817229533

Epoch: 5| Step: 10
Training loss: 2.0758482428706584
Validation loss: 2.54981525739887

Epoch: 5| Step: 11
Training loss: 1.791079254850483
Validation loss: 2.562738764114218

Epoch: 338| Step: 0
Training loss: 2.4091479203101693
Validation loss: 2.545808830288991

Epoch: 5| Step: 1
Training loss: 2.182889384592965
Validation loss: 2.555485708611341

Epoch: 5| Step: 2
Training loss: 2.177065786872012
Validation loss: 2.563013674648442

Epoch: 5| Step: 3
Training loss: 2.050728235921918
Validation loss: 2.5331729092017716

Epoch: 5| Step: 4
Training loss: 2.845304630107355
Validation loss: 2.5310118135387327

Epoch: 5| Step: 5
Training loss: 2.040229901654523
Validation loss: 2.509691348628068

Epoch: 5| Step: 6
Training loss: 1.3150912998690516
Validation loss: 2.5281610636423855

Epoch: 5| Step: 7
Training loss: 1.560225624372047
Validation loss: 2.511909074231869

Epoch: 5| Step: 8
Training loss: 1.8924011210684801
Validation loss: 2.5146781707289754

Epoch: 5| Step: 9
Training loss: 2.2532005858209447
Validation loss: 2.543737015156015

Epoch: 5| Step: 10
Training loss: 1.7547122318362594
Validation loss: 2.537645705664107

Epoch: 5| Step: 11
Training loss: 2.0462524399134048
Validation loss: 2.508398116395716

Epoch: 339| Step: 0
Training loss: 1.6681125409149453
Validation loss: 2.5322619758245186

Epoch: 5| Step: 1
Training loss: 2.3460794698030996
Validation loss: 2.536711037258606

Epoch: 5| Step: 2
Training loss: 2.515382837996195
Validation loss: 2.5725598428894014

Epoch: 5| Step: 3
Training loss: 1.4203941263007043
Validation loss: 2.5549330073299967

Epoch: 5| Step: 4
Training loss: 2.1828359745977917
Validation loss: 2.605729135354074

Epoch: 5| Step: 5
Training loss: 1.7723451855066905
Validation loss: 2.6275885077099073

Epoch: 5| Step: 6
Training loss: 2.0263183587866953
Validation loss: 2.6283772027396854

Epoch: 5| Step: 7
Training loss: 1.3986696018707003
Validation loss: 2.633042530157003

Epoch: 5| Step: 8
Training loss: 1.8935284349609691
Validation loss: 2.6269128845990015

Epoch: 5| Step: 9
Training loss: 2.931580605804254
Validation loss: 2.6216445851916808

Epoch: 5| Step: 10
Training loss: 2.2712380168222874
Validation loss: 2.5823630746373145

Epoch: 5| Step: 11
Training loss: 1.71790480206291
Validation loss: 2.5584892581636915

Epoch: 340| Step: 0
Training loss: 2.0351311797430176
Validation loss: 2.5320543063129293

Epoch: 5| Step: 1
Training loss: 2.388837657300259
Validation loss: 2.5549511515818164

Epoch: 5| Step: 2
Training loss: 1.9647926642448712
Validation loss: 2.5367577759208237

Epoch: 5| Step: 3
Training loss: 1.8435996042755622
Validation loss: 2.5276075930008512

Epoch: 5| Step: 4
Training loss: 2.415455141794752
Validation loss: 2.5242585774393365

Epoch: 5| Step: 5
Training loss: 2.6840151882054575
Validation loss: 2.5253578964752132

Epoch: 5| Step: 6
Training loss: 1.995083667176651
Validation loss: 2.544972534143898

Epoch: 5| Step: 7
Training loss: 2.3949784674900965
Validation loss: 2.575763624734754

Epoch: 5| Step: 8
Training loss: 1.6782227983161127
Validation loss: 2.6151728870930593

Epoch: 5| Step: 9
Training loss: 1.9754395442470147
Validation loss: 2.613895433418611

Epoch: 5| Step: 10
Training loss: 1.8163390444556498
Validation loss: 2.6130860583172772

Epoch: 5| Step: 11
Training loss: 1.6438043215518354
Validation loss: 2.6242330391954667

Epoch: 341| Step: 0
Training loss: 1.9823354617673434
Validation loss: 2.6337517554300374

Epoch: 5| Step: 1
Training loss: 2.0923271468766265
Validation loss: 2.58162951939132

Epoch: 5| Step: 2
Training loss: 1.6498696131195973
Validation loss: 2.5887192768181473

Epoch: 5| Step: 3
Training loss: 1.87375873169191
Validation loss: 2.544237850499926

Epoch: 5| Step: 4
Training loss: 2.5771649971936235
Validation loss: 2.542618283499544

Epoch: 5| Step: 5
Training loss: 2.26965814915235
Validation loss: 2.534450767880284

Epoch: 5| Step: 6
Training loss: 2.4048080086953516
Validation loss: 2.5493261910283453

Epoch: 5| Step: 7
Training loss: 2.2298743529909824
Validation loss: 2.566043473939124

Epoch: 5| Step: 8
Training loss: 1.5516249814086902
Validation loss: 2.588257370399267

Epoch: 5| Step: 9
Training loss: 2.0973619648886253
Validation loss: 2.619923125066194

Epoch: 5| Step: 10
Training loss: 1.9505617946369362
Validation loss: 2.6106374260355

Epoch: 5| Step: 11
Training loss: 1.3973270034852936
Validation loss: 2.6282457161424

Epoch: 342| Step: 0
Training loss: 1.6314496645280827
Validation loss: 2.6474579469032333

Epoch: 5| Step: 1
Training loss: 2.1798843787093425
Validation loss: 2.635187355187406

Epoch: 5| Step: 2
Training loss: 1.9460553815161212
Validation loss: 2.605772219041787

Epoch: 5| Step: 3
Training loss: 2.1546028590849864
Validation loss: 2.577487300264316

Epoch: 5| Step: 4
Training loss: 1.6136874595005883
Validation loss: 2.585577764008176

Epoch: 5| Step: 5
Training loss: 2.27622777903906
Validation loss: 2.5506770028450605

Epoch: 5| Step: 6
Training loss: 2.2391108761211367
Validation loss: 2.5383169321777244

Epoch: 5| Step: 7
Training loss: 2.0781596474878383
Validation loss: 2.5247546951814868

Epoch: 5| Step: 8
Training loss: 1.9414877922387535
Validation loss: 2.583908041482282

Epoch: 5| Step: 9
Training loss: 1.7911561933659508
Validation loss: 2.5537189665863265

Epoch: 5| Step: 10
Training loss: 2.7807011437788822
Validation loss: 2.5803586358307893

Epoch: 5| Step: 11
Training loss: 1.8007624494849668
Validation loss: 2.589141819624644

Epoch: 343| Step: 0
Training loss: 2.4400020375790454
Validation loss: 2.5883232091037147

Epoch: 5| Step: 1
Training loss: 2.172661947485001
Validation loss: 2.5890935057596653

Epoch: 5| Step: 2
Training loss: 2.1709032697876944
Validation loss: 2.5717152185506786

Epoch: 5| Step: 3
Training loss: 1.5314329388389452
Validation loss: 2.552526872719472

Epoch: 5| Step: 4
Training loss: 1.4788408413068785
Validation loss: 2.5760237135661965

Epoch: 5| Step: 5
Training loss: 2.563278731205664
Validation loss: 2.566522987532547

Epoch: 5| Step: 6
Training loss: 1.6127781118042988
Validation loss: 2.547687089006756

Epoch: 5| Step: 7
Training loss: 2.092960607406765
Validation loss: 2.563045168469585

Epoch: 5| Step: 8
Training loss: 2.3348502496244565
Validation loss: 2.5928408434978696

Epoch: 5| Step: 9
Training loss: 1.9426395175667028
Validation loss: 2.5808235071660537

Epoch: 5| Step: 10
Training loss: 1.9512880155194638
Validation loss: 2.580213606244704

Epoch: 5| Step: 11
Training loss: 2.2490166528610214
Validation loss: 2.5854719151985672

Epoch: 344| Step: 0
Training loss: 2.015871727798426
Validation loss: 2.553990007351341

Epoch: 5| Step: 1
Training loss: 2.515739106617273
Validation loss: 2.5316176324126043

Epoch: 5| Step: 2
Training loss: 2.3048863212042185
Validation loss: 2.52538563314064

Epoch: 5| Step: 3
Training loss: 1.9262254059624475
Validation loss: 2.4861553938229206

Epoch: 5| Step: 4
Training loss: 2.3482418504181846
Validation loss: 2.5057192709000615

Epoch: 5| Step: 5
Training loss: 2.0148434565389715
Validation loss: 2.527116677854919

Epoch: 5| Step: 6
Training loss: 1.5924328615896666
Validation loss: 2.5455730558559577

Epoch: 5| Step: 7
Training loss: 1.8893248446082478
Validation loss: 2.553719188319457

Epoch: 5| Step: 8
Training loss: 2.3488655720486475
Validation loss: 2.5508100499255004

Epoch: 5| Step: 9
Training loss: 2.02276553038907
Validation loss: 2.564370120337754

Epoch: 5| Step: 10
Training loss: 1.8071086545364496
Validation loss: 2.586885791248229

Epoch: 5| Step: 11
Training loss: 1.2806569564503507
Validation loss: 2.546333302187213

Epoch: 345| Step: 0
Training loss: 2.875350599058293
Validation loss: 2.5657174798836793

Epoch: 5| Step: 1
Training loss: 2.4309078966312767
Validation loss: 2.581778890538041

Epoch: 5| Step: 2
Training loss: 1.9122925963792439
Validation loss: 2.5447042064234675

Epoch: 5| Step: 3
Training loss: 1.9498851913497857
Validation loss: 2.537466222322144

Epoch: 5| Step: 4
Training loss: 2.3335868720408874
Validation loss: 2.522752682695609

Epoch: 5| Step: 5
Training loss: 1.4904371451120182
Validation loss: 2.5394685117400835

Epoch: 5| Step: 6
Training loss: 1.5656620835958714
Validation loss: 2.5774346130456554

Epoch: 5| Step: 7
Training loss: 2.0213435469514445
Validation loss: 2.573058338100175

Epoch: 5| Step: 8
Training loss: 2.024963392703871
Validation loss: 2.590421870067227

Epoch: 5| Step: 9
Training loss: 1.972298829586241
Validation loss: 2.6013725047187606

Epoch: 5| Step: 10
Training loss: 1.6423817266559766
Validation loss: 2.5956536473212704

Epoch: 5| Step: 11
Training loss: 1.5759502571795367
Validation loss: 2.583680711483701

Epoch: 346| Step: 0
Training loss: 2.337994030647065
Validation loss: 2.612540280185199

Epoch: 5| Step: 1
Training loss: 1.6461442661726524
Validation loss: 2.636711391862563

Epoch: 5| Step: 2
Training loss: 1.7680990389404307
Validation loss: 2.6859733215215726

Epoch: 5| Step: 3
Training loss: 1.9773175753666279
Validation loss: 2.6674802825423045

Epoch: 5| Step: 4
Training loss: 2.2741488363094224
Validation loss: 2.6624660239044244

Epoch: 5| Step: 5
Training loss: 1.8986553177070222
Validation loss: 2.5984201823330535

Epoch: 5| Step: 6
Training loss: 1.5137186547710912
Validation loss: 2.564901037290048

Epoch: 5| Step: 7
Training loss: 2.3186257136265302
Validation loss: 2.539076056811014

Epoch: 5| Step: 8
Training loss: 2.278688638920854
Validation loss: 2.5573174008526824

Epoch: 5| Step: 9
Training loss: 2.052030288346342
Validation loss: 2.5377836616173113

Epoch: 5| Step: 10
Training loss: 2.1870889549984964
Validation loss: 2.5305296653928737

Epoch: 5| Step: 11
Training loss: 1.7309194972349822
Validation loss: 2.5585699958766326

Epoch: 347| Step: 0
Training loss: 1.73218088290874
Validation loss: 2.5288377971181952

Epoch: 5| Step: 1
Training loss: 2.403803188233436
Validation loss: 2.53960647624619

Epoch: 5| Step: 2
Training loss: 1.9292339456030378
Validation loss: 2.568504408692664

Epoch: 5| Step: 3
Training loss: 1.8836845183050035
Validation loss: 2.6447194068646054

Epoch: 5| Step: 4
Training loss: 1.8587296592148417
Validation loss: 2.6605079145822206

Epoch: 5| Step: 5
Training loss: 1.9789479452711163
Validation loss: 2.622888548450074

Epoch: 5| Step: 6
Training loss: 2.3609551197457384
Validation loss: 2.6382195277699494

Epoch: 5| Step: 7
Training loss: 2.0575958670881658
Validation loss: 2.5840482812015804

Epoch: 5| Step: 8
Training loss: 1.6726156715342186
Validation loss: 2.540495709597378

Epoch: 5| Step: 9
Training loss: 2.3216152451464867
Validation loss: 2.505897440414332

Epoch: 5| Step: 10
Training loss: 2.6430577916304974
Validation loss: 2.488157741369857

Epoch: 5| Step: 11
Training loss: 1.7259510735553556
Validation loss: 2.4745148778956185

Epoch: 348| Step: 0
Training loss: 2.7409739186306616
Validation loss: 2.4880169499040696

Epoch: 5| Step: 1
Training loss: 1.566240182953899
Validation loss: 2.4878972075052777

Epoch: 5| Step: 2
Training loss: 1.9147178929156363
Validation loss: 2.5110357729392874

Epoch: 5| Step: 3
Training loss: 1.8073405791451311
Validation loss: 2.503038375981194

Epoch: 5| Step: 4
Training loss: 2.2412643393011558
Validation loss: 2.494642268481245

Epoch: 5| Step: 5
Training loss: 2.3469753198224024
Validation loss: 2.527268072033932

Epoch: 5| Step: 6
Training loss: 2.3087835605001694
Validation loss: 2.5171018257928925

Epoch: 5| Step: 7
Training loss: 1.7098309147766204
Validation loss: 2.5247895542581547

Epoch: 5| Step: 8
Training loss: 1.901742765835868
Validation loss: 2.5996485668259397

Epoch: 5| Step: 9
Training loss: 1.8370596844691132
Validation loss: 2.652788940431722

Epoch: 5| Step: 10
Training loss: 1.9252752602691818
Validation loss: 2.6775034427650373

Epoch: 5| Step: 11
Training loss: 2.20530473813419
Validation loss: 2.6826193723518097

Epoch: 349| Step: 0
Training loss: 2.0127629505177222
Validation loss: 2.6741008559078105

Epoch: 5| Step: 1
Training loss: 1.8464395981264643
Validation loss: 2.674699977883237

Epoch: 5| Step: 2
Training loss: 1.8666188160121957
Validation loss: 2.685771948428241

Epoch: 5| Step: 3
Training loss: 1.858715100554
Validation loss: 2.6240431767449897

Epoch: 5| Step: 4
Training loss: 1.890828649728869
Validation loss: 2.625512175320909

Epoch: 5| Step: 5
Training loss: 2.1421518936370028
Validation loss: 2.5506160462544867

Epoch: 5| Step: 6
Training loss: 2.0820534653042064
Validation loss: 2.532885246950052

Epoch: 5| Step: 7
Training loss: 2.154986578065359
Validation loss: 2.5115187759646878

Epoch: 5| Step: 8
Training loss: 2.458906031565727
Validation loss: 2.513956563142892

Epoch: 5| Step: 9
Training loss: 2.0290607098351634
Validation loss: 2.5048472460823756

Epoch: 5| Step: 10
Training loss: 1.7195845225226607
Validation loss: 2.497710252260973

Epoch: 5| Step: 11
Training loss: 1.2673134549498493
Validation loss: 2.5309897905204357

Epoch: 350| Step: 0
Training loss: 2.033248153319834
Validation loss: 2.549404877050147

Epoch: 5| Step: 1
Training loss: 2.5947475123824932
Validation loss: 2.526022131670631

Epoch: 5| Step: 2
Training loss: 1.715097604092823
Validation loss: 2.546842590469067

Epoch: 5| Step: 3
Training loss: 2.106684459397872
Validation loss: 2.560630236368844

Epoch: 5| Step: 4
Training loss: 2.576278672741282
Validation loss: 2.6059572523504255

Epoch: 5| Step: 5
Training loss: 2.3512853921744337
Validation loss: 2.628491779471881

Epoch: 5| Step: 6
Training loss: 1.943599145561167
Validation loss: 2.637562942055168

Epoch: 5| Step: 7
Training loss: 1.77511665068388
Validation loss: 2.6189969957659023

Epoch: 5| Step: 8
Training loss: 1.8098123288730703
Validation loss: 2.5618348072376924

Epoch: 5| Step: 9
Training loss: 1.8898444968541828
Validation loss: 2.5102639461826817

Epoch: 5| Step: 10
Training loss: 2.2590535590791303
Validation loss: 2.4970752336585114

Epoch: 5| Step: 11
Training loss: 1.7460379026216348
Validation loss: 2.4961158938512664

Epoch: 351| Step: 0
Training loss: 2.3550850981221405
Validation loss: 2.5030039382976743

Epoch: 5| Step: 1
Training loss: 1.6209705719626952
Validation loss: 2.4807230180793236

Epoch: 5| Step: 2
Training loss: 2.5609167837127793
Validation loss: 2.4900290929417346

Epoch: 5| Step: 3
Training loss: 1.866068420877073
Validation loss: 2.488578934281993

Epoch: 5| Step: 4
Training loss: 1.9170107187161494
Validation loss: 2.490043914093622

Epoch: 5| Step: 5
Training loss: 2.5545154945260524
Validation loss: 2.482374463452722

Epoch: 5| Step: 6
Training loss: 2.0943525216021324
Validation loss: 2.535344039004243

Epoch: 5| Step: 7
Training loss: 1.5279672428134983
Validation loss: 2.5433882422496574

Epoch: 5| Step: 8
Training loss: 1.7761505481386763
Validation loss: 2.521405022532543

Epoch: 5| Step: 9
Training loss: 1.9854558569238177
Validation loss: 2.5581945054433333

Epoch: 5| Step: 10
Training loss: 2.45949577606949
Validation loss: 2.583180351239618

Epoch: 5| Step: 11
Training loss: 2.067292742598361
Validation loss: 2.5522106891436636

Epoch: 352| Step: 0
Training loss: 1.8773034887167734
Validation loss: 2.4883133922598906

Epoch: 5| Step: 1
Training loss: 2.6492085192569155
Validation loss: 2.4987873613345126

Epoch: 5| Step: 2
Training loss: 2.1170800663903395
Validation loss: 2.5037126748992344

Epoch: 5| Step: 3
Training loss: 2.3254630212265344
Validation loss: 2.5027227793731

Epoch: 5| Step: 4
Training loss: 2.0230493357323565
Validation loss: 2.4880877249381124

Epoch: 5| Step: 5
Training loss: 2.014007155647181
Validation loss: 2.4990769708883946

Epoch: 5| Step: 6
Training loss: 1.9150323395949052
Validation loss: 2.4931485147834387

Epoch: 5| Step: 7
Training loss: 2.41129922582234
Validation loss: 2.4989895328250618

Epoch: 5| Step: 8
Training loss: 2.0471700208206274
Validation loss: 2.5238465842649616

Epoch: 5| Step: 9
Training loss: 1.5247254233893184
Validation loss: 2.5481597569727272

Epoch: 5| Step: 10
Training loss: 2.181630133703512
Validation loss: 2.5480597925002493

Epoch: 5| Step: 11
Training loss: 1.2841886918945247
Validation loss: 2.5369057910144206

Epoch: 353| Step: 0
Training loss: 2.1402498459470034
Validation loss: 2.5560366055708488

Epoch: 5| Step: 1
Training loss: 2.095896403562579
Validation loss: 2.5288131035200263

Epoch: 5| Step: 2
Training loss: 1.967486627089775
Validation loss: 2.5463127225448776

Epoch: 5| Step: 3
Training loss: 1.7084554845666806
Validation loss: 2.557892114467907

Epoch: 5| Step: 4
Training loss: 2.23788251537439
Validation loss: 2.5326520113937288

Epoch: 5| Step: 5
Training loss: 1.7307642561686176
Validation loss: 2.5117208580692476

Epoch: 5| Step: 6
Training loss: 2.2835176249659805
Validation loss: 2.5345738647683755

Epoch: 5| Step: 7
Training loss: 1.6644109083621748
Validation loss: 2.546448443680519

Epoch: 5| Step: 8
Training loss: 1.8582616726639434
Validation loss: 2.5405444745154564

Epoch: 5| Step: 9
Training loss: 2.2265794184527183
Validation loss: 2.5229526325584426

Epoch: 5| Step: 10
Training loss: 2.400128392917811
Validation loss: 2.5509835124575244

Epoch: 5| Step: 11
Training loss: 2.281970602690352
Validation loss: 2.5736838997357507

Epoch: 354| Step: 0
Training loss: 1.6294250393973
Validation loss: 2.575211036083452

Epoch: 5| Step: 1
Training loss: 1.5977909991979302
Validation loss: 2.6018299198269563

Epoch: 5| Step: 2
Training loss: 2.2729544109936666
Validation loss: 2.7047280903368485

Epoch: 5| Step: 3
Training loss: 1.9207356494991594
Validation loss: 2.7283361180648

Epoch: 5| Step: 4
Training loss: 2.473370730570633
Validation loss: 2.7437571301726065

Epoch: 5| Step: 5
Training loss: 1.8264160645771363
Validation loss: 2.725888813010682

Epoch: 5| Step: 6
Training loss: 2.083835986216274
Validation loss: 2.683770878631677

Epoch: 5| Step: 7
Training loss: 1.7115619512741327
Validation loss: 2.628529586373199

Epoch: 5| Step: 8
Training loss: 1.9711610471869476
Validation loss: 2.594337077132062

Epoch: 5| Step: 9
Training loss: 2.2631892297833005
Validation loss: 2.5515068739593443

Epoch: 5| Step: 10
Training loss: 2.1324910910309605
Validation loss: 2.527023741299106

Epoch: 5| Step: 11
Training loss: 3.939912087481151
Validation loss: 2.530931664688688

Epoch: 355| Step: 0
Training loss: 2.101989929523536
Validation loss: 2.5127729810859925

Epoch: 5| Step: 1
Training loss: 2.0451964273294347
Validation loss: 2.532162909854618

Epoch: 5| Step: 2
Training loss: 2.1609416175521714
Validation loss: 2.5288378874697663

Epoch: 5| Step: 3
Training loss: 2.0402009204953298
Validation loss: 2.5468520337026885

Epoch: 5| Step: 4
Training loss: 2.091862069333028
Validation loss: 2.557842907407333

Epoch: 5| Step: 5
Training loss: 2.4634529941937293
Validation loss: 2.585113570843895

Epoch: 5| Step: 6
Training loss: 1.7008134746871835
Validation loss: 2.6411392644129625

Epoch: 5| Step: 7
Training loss: 1.2734351596927787
Validation loss: 2.688972302730059

Epoch: 5| Step: 8
Training loss: 1.8001498689779276
Validation loss: 2.642248726648043

Epoch: 5| Step: 9
Training loss: 1.9325470528543338
Validation loss: 2.7073521683026094

Epoch: 5| Step: 10
Training loss: 2.1490537557220177
Validation loss: 2.697427279346813

Epoch: 5| Step: 11
Training loss: 2.3078558399260687
Validation loss: 2.6750616475010176

Epoch: 356| Step: 0
Training loss: 2.0135595103455177
Validation loss: 2.6069290247785024

Epoch: 5| Step: 1
Training loss: 1.8107405047696379
Validation loss: 2.5786510431777283

Epoch: 5| Step: 2
Training loss: 1.7783083802712671
Validation loss: 2.5624195799575045

Epoch: 5| Step: 3
Training loss: 2.021828029741438
Validation loss: 2.555531019344116

Epoch: 5| Step: 4
Training loss: 2.539095552669481
Validation loss: 2.5433688417904055

Epoch: 5| Step: 5
Training loss: 1.7276902464186659
Validation loss: 2.532256240366775

Epoch: 5| Step: 6
Training loss: 2.214586031012867
Validation loss: 2.5101790546545257

Epoch: 5| Step: 7
Training loss: 2.1568794990167643
Validation loss: 2.5404017862984585

Epoch: 5| Step: 8
Training loss: 1.756906369097856
Validation loss: 2.520624724865063

Epoch: 5| Step: 9
Training loss: 1.964948222907483
Validation loss: 2.532832271240682

Epoch: 5| Step: 10
Training loss: 2.0501989500688174
Validation loss: 2.531009187742478

Epoch: 5| Step: 11
Training loss: 2.452762261074356
Validation loss: 2.5284181028068455

Epoch: 357| Step: 0
Training loss: 2.178925521179961
Validation loss: 2.5725304253178116

Epoch: 5| Step: 1
Training loss: 1.8883068911571685
Validation loss: 2.6016684731101054

Epoch: 5| Step: 2
Training loss: 1.5193522134544881
Validation loss: 2.6588010393464825

Epoch: 5| Step: 3
Training loss: 2.4317656335525224
Validation loss: 2.6714617909745217

Epoch: 5| Step: 4
Training loss: 1.6420494798321148
Validation loss: 2.7013153126352614

Epoch: 5| Step: 5
Training loss: 2.0960213027701458
Validation loss: 2.6764037398987734

Epoch: 5| Step: 6
Training loss: 2.4888540713489933
Validation loss: 2.666782552962742

Epoch: 5| Step: 7
Training loss: 1.8300484214171617
Validation loss: 2.5903478240245676

Epoch: 5| Step: 8
Training loss: 2.4645715433216537
Validation loss: 2.5467767442968055

Epoch: 5| Step: 9
Training loss: 1.7752733852843001
Validation loss: 2.538376023830451

Epoch: 5| Step: 10
Training loss: 1.9399087760556486
Validation loss: 2.5236502086326293

Epoch: 5| Step: 11
Training loss: 1.267800991879635
Validation loss: 2.523343898426885

Epoch: 358| Step: 0
Training loss: 2.451519677764947
Validation loss: 2.5317263468967197

Epoch: 5| Step: 1
Training loss: 2.509107879064868
Validation loss: 2.5143353965498285

Epoch: 5| Step: 2
Training loss: 2.1146473867051396
Validation loss: 2.5458758838134026

Epoch: 5| Step: 3
Training loss: 2.0501733660079764
Validation loss: 2.544845579911049

Epoch: 5| Step: 4
Training loss: 2.2335807615785135
Validation loss: 2.5116101523772283

Epoch: 5| Step: 5
Training loss: 1.5988225806778793
Validation loss: 2.538607023418136

Epoch: 5| Step: 6
Training loss: 1.7257711400728444
Validation loss: 2.5068702254546693

Epoch: 5| Step: 7
Training loss: 2.1273728754275156
Validation loss: 2.5162878722998014

Epoch: 5| Step: 8
Training loss: 1.7091871391990956
Validation loss: 2.500275000705916

Epoch: 5| Step: 9
Training loss: 2.140907213305585
Validation loss: 2.5245748265797756

Epoch: 5| Step: 10
Training loss: 2.213033161471647
Validation loss: 2.5289277621141775

Epoch: 5| Step: 11
Training loss: 0.9623305914775591
Validation loss: 2.5324087394935826

Epoch: 359| Step: 0
Training loss: 2.0464849901280333
Validation loss: 2.5823329031789504

Epoch: 5| Step: 1
Training loss: 1.7151527213336335
Validation loss: 2.5665528532799304

Epoch: 5| Step: 2
Training loss: 1.620213207413962
Validation loss: 2.536544059437933

Epoch: 5| Step: 3
Training loss: 2.1397481640026665
Validation loss: 2.516812030644571

Epoch: 5| Step: 4
Training loss: 2.0488437182884924
Validation loss: 2.5163026730146782

Epoch: 5| Step: 5
Training loss: 2.216507974360307
Validation loss: 2.531125740643332

Epoch: 5| Step: 6
Training loss: 2.2934230893705396
Validation loss: 2.521523284020939

Epoch: 5| Step: 7
Training loss: 1.9723297755445857
Validation loss: 2.507872250994891

Epoch: 5| Step: 8
Training loss: 2.056351252790611
Validation loss: 2.5041603518854414

Epoch: 5| Step: 9
Training loss: 2.0577353727330387
Validation loss: 2.521362715429985

Epoch: 5| Step: 10
Training loss: 2.188628096570744
Validation loss: 2.528556599533753

Epoch: 5| Step: 11
Training loss: 2.0506841727395426
Validation loss: 2.566449761566167

Epoch: 360| Step: 0
Training loss: 2.13301806454849
Validation loss: 2.63439827241645

Epoch: 5| Step: 1
Training loss: 2.332243687651723
Validation loss: 2.641689454671323

Epoch: 5| Step: 2
Training loss: 2.1758279298880594
Validation loss: 2.7173964576741434

Epoch: 5| Step: 3
Training loss: 2.1286732957408003
Validation loss: 2.7610736940704754

Epoch: 5| Step: 4
Training loss: 2.538521576996146
Validation loss: 2.76210497323183

Epoch: 5| Step: 5
Training loss: 2.035719195099458
Validation loss: 2.7026994274644185

Epoch: 5| Step: 6
Training loss: 1.3889323444985717
Validation loss: 2.603220261582004

Epoch: 5| Step: 7
Training loss: 1.768494965731353
Validation loss: 2.535904862465514

Epoch: 5| Step: 8
Training loss: 2.264351532930578
Validation loss: 2.5078901197675525

Epoch: 5| Step: 9
Training loss: 2.34529510430601
Validation loss: 2.5331853288992567

Epoch: 5| Step: 10
Training loss: 1.4800062438472286
Validation loss: 2.511929516529346

Epoch: 5| Step: 11
Training loss: 2.54244244310615
Validation loss: 2.5384466040500957

Epoch: 361| Step: 0
Training loss: 2.055264816113843
Validation loss: 2.526233203089041

Epoch: 5| Step: 1
Training loss: 2.4073003482923414
Validation loss: 2.5303362072140314

Epoch: 5| Step: 2
Training loss: 2.0342918507918175
Validation loss: 2.5253459732738155

Epoch: 5| Step: 3
Training loss: 1.6970881993802887
Validation loss: 2.5120621837481343

Epoch: 5| Step: 4
Training loss: 2.54718277832612
Validation loss: 2.5035174618950022

Epoch: 5| Step: 5
Training loss: 2.345807202624454
Validation loss: 2.518436629787518

Epoch: 5| Step: 6
Training loss: 1.6743882442803486
Validation loss: 2.5502885398117834

Epoch: 5| Step: 7
Training loss: 2.149193648008342
Validation loss: 2.5876110804022034

Epoch: 5| Step: 8
Training loss: 1.6158635714086877
Validation loss: 2.573457890059004

Epoch: 5| Step: 9
Training loss: 1.8749930063753035
Validation loss: 2.6160419671073494

Epoch: 5| Step: 10
Training loss: 2.251672229303491
Validation loss: 2.59263837118894

Epoch: 5| Step: 11
Training loss: 2.290037084387472
Validation loss: 2.600803203343052

Epoch: 362| Step: 0
Training loss: 2.0293055691133537
Validation loss: 2.5826831596776287

Epoch: 5| Step: 1
Training loss: 2.121415986651753
Validation loss: 2.579303999763927

Epoch: 5| Step: 2
Training loss: 2.1093306925323456
Validation loss: 2.5969071037000444

Epoch: 5| Step: 3
Training loss: 1.6796195082986713
Validation loss: 2.561428520605199

Epoch: 5| Step: 4
Training loss: 1.8265892163909736
Validation loss: 2.5653070760080894

Epoch: 5| Step: 5
Training loss: 1.5587991755972062
Validation loss: 2.537964750818823

Epoch: 5| Step: 6
Training loss: 2.265483667635133
Validation loss: 2.502270158568287

Epoch: 5| Step: 7
Training loss: 2.134462493845764
Validation loss: 2.5184905275867626

Epoch: 5| Step: 8
Training loss: 2.475855873935758
Validation loss: 2.5481948553033145

Epoch: 5| Step: 9
Training loss: 1.747022684641111
Validation loss: 2.5311431116526215

Epoch: 5| Step: 10
Training loss: 2.1265436063735796
Validation loss: 2.510556910912082

Epoch: 5| Step: 11
Training loss: 1.8108739464891648
Validation loss: 2.503527401865532

Epoch: 363| Step: 0
Training loss: 2.314218140596172
Validation loss: 2.499953945053592

Epoch: 5| Step: 1
Training loss: 2.2353030324911676
Validation loss: 2.4836907594127706

Epoch: 5| Step: 2
Training loss: 1.7712116136611238
Validation loss: 2.512624135438123

Epoch: 5| Step: 3
Training loss: 1.562949993185361
Validation loss: 2.5295371826386326

Epoch: 5| Step: 4
Training loss: 2.1851552112891928
Validation loss: 2.5284710217022845

Epoch: 5| Step: 5
Training loss: 1.6087610499573843
Validation loss: 2.5131415277200233

Epoch: 5| Step: 6
Training loss: 2.3553457655043655
Validation loss: 2.54735214740859

Epoch: 5| Step: 7
Training loss: 1.5251932053045214
Validation loss: 2.5504430261363344

Epoch: 5| Step: 8
Training loss: 1.816065602508215
Validation loss: 2.533531702948078

Epoch: 5| Step: 9
Training loss: 2.2558334811487373
Validation loss: 2.5152410940874503

Epoch: 5| Step: 10
Training loss: 2.0537179029839083
Validation loss: 2.5308990843583365

Epoch: 5| Step: 11
Training loss: 1.412397637498209
Validation loss: 2.5390402338078677

Epoch: 364| Step: 0
Training loss: 2.4787317637178137
Validation loss: 2.5603411116806147

Epoch: 5| Step: 1
Training loss: 2.723837116138538
Validation loss: 2.548813384538415

Epoch: 5| Step: 2
Training loss: 1.6335724882605778
Validation loss: 2.563390642936365

Epoch: 5| Step: 3
Training loss: 1.9409573993636258
Validation loss: 2.5835631804094334

Epoch: 5| Step: 4
Training loss: 1.9033667850839446
Validation loss: 2.5735474899402337

Epoch: 5| Step: 5
Training loss: 1.884750318712136
Validation loss: 2.578193759964588

Epoch: 5| Step: 6
Training loss: 1.6133956314438227
Validation loss: 2.6071763436181894

Epoch: 5| Step: 7
Training loss: 2.0148376583082714
Validation loss: 2.625162437499334

Epoch: 5| Step: 8
Training loss: 1.9881343524980306
Validation loss: 2.5850169338247193

Epoch: 5| Step: 9
Training loss: 1.9532111187068621
Validation loss: 2.577674375512993

Epoch: 5| Step: 10
Training loss: 1.241348222993232
Validation loss: 2.5534006118646495

Epoch: 5| Step: 11
Training loss: 1.4572293144376993
Validation loss: 2.54953778595338

Epoch: 365| Step: 0
Training loss: 2.764495360281037
Validation loss: 2.5426701313250075

Epoch: 5| Step: 1
Training loss: 1.929888448406816
Validation loss: 2.5602217719321647

Epoch: 5| Step: 2
Training loss: 2.117588019405092
Validation loss: 2.5698867452964658

Epoch: 5| Step: 3
Training loss: 1.890754506112963
Validation loss: 2.5352184246885474

Epoch: 5| Step: 4
Training loss: 1.4913209326246557
Validation loss: 2.5361088832528824

Epoch: 5| Step: 5
Training loss: 1.5525524872585625
Validation loss: 2.515489365295584

Epoch: 5| Step: 6
Training loss: 2.691367715191524
Validation loss: 2.564146606070129

Epoch: 5| Step: 7
Training loss: 1.7274332051813284
Validation loss: 2.544721273936488

Epoch: 5| Step: 8
Training loss: 1.8425730812144436
Validation loss: 2.5893914473607693

Epoch: 5| Step: 9
Training loss: 1.7368273194457882
Validation loss: 2.5956961902212905

Epoch: 5| Step: 10
Training loss: 1.6546386942091085
Validation loss: 2.6454243281266465

Epoch: 5| Step: 11
Training loss: 2.032243925622606
Validation loss: 2.601708874866131

Epoch: 366| Step: 0
Training loss: 1.599078676083415
Validation loss: 2.633596373399914

Epoch: 5| Step: 1
Training loss: 1.8842870233093891
Validation loss: 2.6036392911332937

Epoch: 5| Step: 2
Training loss: 2.3354757101289962
Validation loss: 2.622598495658075

Epoch: 5| Step: 3
Training loss: 2.023992396087838
Validation loss: 2.5879092809616466

Epoch: 5| Step: 4
Training loss: 1.589720625175121
Validation loss: 2.608750281864743

Epoch: 5| Step: 5
Training loss: 2.4029527342009778
Validation loss: 2.5697263495704727

Epoch: 5| Step: 6
Training loss: 1.8699140871681492
Validation loss: 2.5688343725711182

Epoch: 5| Step: 7
Training loss: 1.9105878783049233
Validation loss: 2.598619983081861

Epoch: 5| Step: 8
Training loss: 1.9857547799006898
Validation loss: 2.629162662994754

Epoch: 5| Step: 9
Training loss: 1.876481551712144
Validation loss: 2.646278724328313

Epoch: 5| Step: 10
Training loss: 1.7122172268373725
Validation loss: 2.603725744431442

Epoch: 5| Step: 11
Training loss: 1.258873107329957
Validation loss: 2.550324259349423

Epoch: 367| Step: 0
Training loss: 1.5187597988738757
Validation loss: 2.5752546920555868

Epoch: 5| Step: 1
Training loss: 2.284986701609439
Validation loss: 2.5531291272158434

Epoch: 5| Step: 2
Training loss: 1.9860742457361498
Validation loss: 2.5511042500912975

Epoch: 5| Step: 3
Training loss: 2.4244273856616014
Validation loss: 2.5638530384513234

Epoch: 5| Step: 4
Training loss: 2.120103917723903
Validation loss: 2.585306918581128

Epoch: 5| Step: 5
Training loss: 1.7095417617824726
Validation loss: 2.5812815906725186

Epoch: 5| Step: 6
Training loss: 1.8027410538075428
Validation loss: 2.6000453087636863

Epoch: 5| Step: 7
Training loss: 1.8958372667991439
Validation loss: 2.587944646307477

Epoch: 5| Step: 8
Training loss: 1.9664902812718577
Validation loss: 2.570992624262118

Epoch: 5| Step: 9
Training loss: 1.7322605750374571
Validation loss: 2.622298125511655

Epoch: 5| Step: 10
Training loss: 2.0620569851509356
Validation loss: 2.6208664444487972

Epoch: 5| Step: 11
Training loss: 1.3792097497916291
Validation loss: 2.6193366796369077

Epoch: 368| Step: 0
Training loss: 1.8648284949840148
Validation loss: 2.598975586053515

Epoch: 5| Step: 1
Training loss: 2.2260662395838846
Validation loss: 2.6235432177704427

Epoch: 5| Step: 2
Training loss: 2.3766700494571844
Validation loss: 2.5454371748665445

Epoch: 5| Step: 3
Training loss: 2.082607511605055
Validation loss: 2.518491355925087

Epoch: 5| Step: 4
Training loss: 2.518950639405422
Validation loss: 2.5350428410395582

Epoch: 5| Step: 5
Training loss: 1.36892633216774
Validation loss: 2.5034576704531477

Epoch: 5| Step: 6
Training loss: 1.3322604700909395
Validation loss: 2.5480461821203533

Epoch: 5| Step: 7
Training loss: 2.0711639380891995
Validation loss: 2.575710904186027

Epoch: 5| Step: 8
Training loss: 1.975592635365407
Validation loss: 2.5766772279938293

Epoch: 5| Step: 9
Training loss: 1.9597331448304751
Validation loss: 2.6074805320971244

Epoch: 5| Step: 10
Training loss: 1.7879619961695785
Validation loss: 2.583208805333527

Epoch: 5| Step: 11
Training loss: 1.2249057538893573
Validation loss: 2.570337038396484

Epoch: 369| Step: 0
Training loss: 1.369878986123453
Validation loss: 2.5808831228968216

Epoch: 5| Step: 1
Training loss: 2.395631621341925
Validation loss: 2.5468315284623086

Epoch: 5| Step: 2
Training loss: 1.6168020775050689
Validation loss: 2.5447943170705187

Epoch: 5| Step: 3
Training loss: 1.4028129961399995
Validation loss: 2.5403419127333393

Epoch: 5| Step: 4
Training loss: 2.4063893067299884
Validation loss: 2.545175408483992

Epoch: 5| Step: 5
Training loss: 1.8625631488105
Validation loss: 2.5644367272694577

Epoch: 5| Step: 6
Training loss: 1.896367329718811
Validation loss: 2.5778808786429726

Epoch: 5| Step: 7
Training loss: 1.8861149992767743
Validation loss: 2.5551612892957296

Epoch: 5| Step: 8
Training loss: 1.809201956003141
Validation loss: 2.5902372687453106

Epoch: 5| Step: 9
Training loss: 2.2090093069920926
Validation loss: 2.593245556813977

Epoch: 5| Step: 10
Training loss: 2.2191933202438103
Validation loss: 2.6148866892870557

Epoch: 5| Step: 11
Training loss: 1.3342498917189167
Validation loss: 2.6523252251511393

Epoch: 370| Step: 0
Training loss: 1.7846604207475474
Validation loss: 2.6112446967801977

Epoch: 5| Step: 1
Training loss: 1.8875892794885654
Validation loss: 2.643005990564642

Epoch: 5| Step: 2
Training loss: 1.7290092151455843
Validation loss: 2.650103893432707

Epoch: 5| Step: 3
Training loss: 1.772158930667115
Validation loss: 2.6543261236582074

Epoch: 5| Step: 4
Training loss: 1.6634776202417163
Validation loss: 2.6478574036860203

Epoch: 5| Step: 5
Training loss: 2.472484902084123
Validation loss: 2.5989049448608506

Epoch: 5| Step: 6
Training loss: 1.2865961698546549
Validation loss: 2.560551743996203

Epoch: 5| Step: 7
Training loss: 1.8037351927807084
Validation loss: 2.5604979789016755

Epoch: 5| Step: 8
Training loss: 2.3396434156856114
Validation loss: 2.5490649721053282

Epoch: 5| Step: 9
Training loss: 2.055639706283857
Validation loss: 2.5315054305438585

Epoch: 5| Step: 10
Training loss: 1.6616478535853954
Validation loss: 2.5439538253866285

Epoch: 5| Step: 11
Training loss: 1.6944626466714945
Validation loss: 2.552652277425302

Epoch: 371| Step: 0
Training loss: 1.8822827365524784
Validation loss: 2.5467889533300068

Epoch: 5| Step: 1
Training loss: 1.7066949648423377
Validation loss: 2.540516219052728

Epoch: 5| Step: 2
Training loss: 1.9035737058349336
Validation loss: 2.5801677818227757

Epoch: 5| Step: 3
Training loss: 1.973913596526176
Validation loss: 2.585993686461308

Epoch: 5| Step: 4
Training loss: 1.5478032727335198
Validation loss: 2.558194858819011

Epoch: 5| Step: 5
Training loss: 2.0408440184660708
Validation loss: 2.5714866232926163

Epoch: 5| Step: 6
Training loss: 2.4204982659188503
Validation loss: 2.5874647065917675

Epoch: 5| Step: 7
Training loss: 1.404226839868476
Validation loss: 2.591970534209409

Epoch: 5| Step: 8
Training loss: 2.1464470538156735
Validation loss: 2.6161481321247404

Epoch: 5| Step: 9
Training loss: 1.7684123899864927
Validation loss: 2.5876449333978315

Epoch: 5| Step: 10
Training loss: 2.220428584028597
Validation loss: 2.6138299271938523

Epoch: 5| Step: 11
Training loss: 0.5143093026850223
Validation loss: 2.581826564045455

Epoch: 372| Step: 0
Training loss: 1.8249020328093797
Validation loss: 2.6158380322162498

Epoch: 5| Step: 1
Training loss: 1.9686151488608281
Validation loss: 2.6358200613896368

Epoch: 5| Step: 2
Training loss: 1.443559975937622
Validation loss: 2.630976930374087

Epoch: 5| Step: 3
Training loss: 2.047550701403239
Validation loss: 2.641794400982749

Epoch: 5| Step: 4
Training loss: 1.7225581203892357
Validation loss: 2.594000187646138

Epoch: 5| Step: 5
Training loss: 1.8354430486520061
Validation loss: 2.591030380258386

Epoch: 5| Step: 6
Training loss: 1.924745850072634
Validation loss: 2.5744078686813814

Epoch: 5| Step: 7
Training loss: 1.6195385194386192
Validation loss: 2.5287363577660305

Epoch: 5| Step: 8
Training loss: 1.9739252522161699
Validation loss: 2.5109099712021967

Epoch: 5| Step: 9
Training loss: 1.882666237876094
Validation loss: 2.496954740063438

Epoch: 5| Step: 10
Training loss: 2.291233530438008
Validation loss: 2.497564715156996

Epoch: 5| Step: 11
Training loss: 1.3368182039969831
Validation loss: 2.506827465003923

Epoch: 373| Step: 0
Training loss: 2.2542910453999956
Validation loss: 2.479555707881367

Epoch: 5| Step: 1
Training loss: 2.134055533454306
Validation loss: 2.491529479497554

Epoch: 5| Step: 2
Training loss: 2.097882420229715
Validation loss: 2.507879563303416

Epoch: 5| Step: 3
Training loss: 1.8606703277386947
Validation loss: 2.5248923620251573

Epoch: 5| Step: 4
Training loss: 1.7068436648308174
Validation loss: 2.558899268626291

Epoch: 5| Step: 5
Training loss: 1.9768643356069362
Validation loss: 2.5470440775286534

Epoch: 5| Step: 6
Training loss: 2.34041347795699
Validation loss: 2.5380529930185123

Epoch: 5| Step: 7
Training loss: 1.8341419286358085
Validation loss: 2.5609283104964997

Epoch: 5| Step: 8
Training loss: 1.8100248075861138
Validation loss: 2.5462184559037517

Epoch: 5| Step: 9
Training loss: 1.6206028206422323
Validation loss: 2.5527455515228903

Epoch: 5| Step: 10
Training loss: 2.016159223391993
Validation loss: 2.537824941447353

Epoch: 5| Step: 11
Training loss: 2.976622092784362
Validation loss: 2.505997215676137

Epoch: 374| Step: 0
Training loss: 1.9211368538890845
Validation loss: 2.5516206763122233

Epoch: 5| Step: 1
Training loss: 2.6959176531364375
Validation loss: 2.541590467988842

Epoch: 5| Step: 2
Training loss: 1.7146208668243434
Validation loss: 2.5945845222766515

Epoch: 5| Step: 3
Training loss: 1.7783165585490306
Validation loss: 2.587751407357441

Epoch: 5| Step: 4
Training loss: 1.826812925377131
Validation loss: 2.6030231190283843

Epoch: 5| Step: 5
Training loss: 1.810700871935722
Validation loss: 2.5805803494060204

Epoch: 5| Step: 6
Training loss: 1.8358446462972118
Validation loss: 2.5776314966296177

Epoch: 5| Step: 7
Training loss: 1.634370635338639
Validation loss: 2.5722586772402947

Epoch: 5| Step: 8
Training loss: 1.5842922301934215
Validation loss: 2.5929564560486402

Epoch: 5| Step: 9
Training loss: 1.8813616595921554
Validation loss: 2.595596041454692

Epoch: 5| Step: 10
Training loss: 1.910742484471605
Validation loss: 2.5719670050206824

Epoch: 5| Step: 11
Training loss: 2.3116357580244125
Validation loss: 2.576752488052649

Epoch: 375| Step: 0
Training loss: 1.9161196494760964
Validation loss: 2.542018339706721

Epoch: 5| Step: 1
Training loss: 1.8656544796453212
Validation loss: 2.5589595115857877

Epoch: 5| Step: 2
Training loss: 1.8604006462930998
Validation loss: 2.58424517602585

Epoch: 5| Step: 3
Training loss: 2.1425371748593527
Validation loss: 2.558716729778194

Epoch: 5| Step: 4
Training loss: 2.2947927365594194
Validation loss: 2.6067349332661403

Epoch: 5| Step: 5
Training loss: 1.6251601360352705
Validation loss: 2.5890572620953543

Epoch: 5| Step: 6
Training loss: 2.2433019121566526
Validation loss: 2.5772481448289297

Epoch: 5| Step: 7
Training loss: 1.5014986657775988
Validation loss: 2.611120953327144

Epoch: 5| Step: 8
Training loss: 1.7179670457887892
Validation loss: 2.6362982671330606

Epoch: 5| Step: 9
Training loss: 1.4945785778187302
Validation loss: 2.6552213547034254

Epoch: 5| Step: 10
Training loss: 1.8259603612468498
Validation loss: 2.6282289755835535

Epoch: 5| Step: 11
Training loss: 1.813666001523375
Validation loss: 2.610213127989416

Epoch: 376| Step: 0
Training loss: 1.1533871339825525
Validation loss: 2.520441298042559

Epoch: 5| Step: 1
Training loss: 1.4577650416132508
Validation loss: 2.528735136006333

Epoch: 5| Step: 2
Training loss: 1.3404062052563475
Validation loss: 2.5130226227485464

Epoch: 5| Step: 3
Training loss: 2.7539656395967596
Validation loss: 2.556354663108356

Epoch: 5| Step: 4
Training loss: 2.0774190750611043
Validation loss: 2.5457947201045554

Epoch: 5| Step: 5
Training loss: 2.277548726771795
Validation loss: 2.5724235878159187

Epoch: 5| Step: 6
Training loss: 2.077852733243765
Validation loss: 2.5532878770861496

Epoch: 5| Step: 7
Training loss: 1.9703856440254635
Validation loss: 2.524086029363718

Epoch: 5| Step: 8
Training loss: 2.5521662692133615
Validation loss: 2.484860382807995

Epoch: 5| Step: 9
Training loss: 2.00687775579909
Validation loss: 2.4957845951112754

Epoch: 5| Step: 10
Training loss: 2.000065564034592
Validation loss: 2.5215033371160893

Epoch: 5| Step: 11
Training loss: 2.226764442253967
Validation loss: 2.549221069914744

Epoch: 377| Step: 0
Training loss: 1.435907559918076
Validation loss: 2.61461768691353

Epoch: 5| Step: 1
Training loss: 1.5824204707839826
Validation loss: 2.616230056007456

Epoch: 5| Step: 2
Training loss: 2.0588044089543414
Validation loss: 2.6247218113281887

Epoch: 5| Step: 3
Training loss: 1.8956552848069526
Validation loss: 2.594989032556808

Epoch: 5| Step: 4
Training loss: 1.879466903058195
Validation loss: 2.616077297699469

Epoch: 5| Step: 5
Training loss: 1.500831532467544
Validation loss: 2.6024048504031057

Epoch: 5| Step: 6
Training loss: 2.8591940567215266
Validation loss: 2.6187746881369764

Epoch: 5| Step: 7
Training loss: 1.8405931246576765
Validation loss: 2.5833106437322466

Epoch: 5| Step: 8
Training loss: 2.1166836184726447
Validation loss: 2.5887214910317957

Epoch: 5| Step: 9
Training loss: 2.1052484910228193
Validation loss: 2.5877639643544454

Epoch: 5| Step: 10
Training loss: 1.9915173768576688
Validation loss: 2.5661493034383205

Epoch: 5| Step: 11
Training loss: 1.4558381214437954
Validation loss: 2.6084732088745066

Epoch: 378| Step: 0
Training loss: 1.9078558739582818
Validation loss: 2.6074960876647624

Epoch: 5| Step: 1
Training loss: 1.9322041768491562
Validation loss: 2.633085778124837

Epoch: 5| Step: 2
Training loss: 1.5451963159221485
Validation loss: 2.6328995272386484

Epoch: 5| Step: 3
Training loss: 1.9333891789274098
Validation loss: 2.6173096965142566

Epoch: 5| Step: 4
Training loss: 2.2271359424663744
Validation loss: 2.632706312685072

Epoch: 5| Step: 5
Training loss: 2.3069483126243555
Validation loss: 2.6584293288852723

Epoch: 5| Step: 6
Training loss: 1.9045128333074224
Validation loss: 2.6777533732936036

Epoch: 5| Step: 7
Training loss: 1.5435948127861083
Validation loss: 2.6666284362218167

Epoch: 5| Step: 8
Training loss: 1.6683816510398966
Validation loss: 2.631611992739363

Epoch: 5| Step: 9
Training loss: 1.9648223936463618
Validation loss: 2.658418338835576

Epoch: 5| Step: 10
Training loss: 1.2070034480673804
Validation loss: 2.6169001559140246

Epoch: 5| Step: 11
Training loss: 1.3832898366746265
Validation loss: 2.606334327077556

Epoch: 379| Step: 0
Training loss: 1.7817766180746477
Validation loss: 2.6228459807474382

Epoch: 5| Step: 1
Training loss: 1.2524116140767054
Validation loss: 2.627710445486577

Epoch: 5| Step: 2
Training loss: 2.0153461825312085
Validation loss: 2.6620345726708203

Epoch: 5| Step: 3
Training loss: 1.8231445024798796
Validation loss: 2.6393402254615723

Epoch: 5| Step: 4
Training loss: 2.3309892278460818
Validation loss: 2.6219472277289593

Epoch: 5| Step: 5
Training loss: 1.9064818069346294
Validation loss: 2.642032910078242

Epoch: 5| Step: 6
Training loss: 1.8176649757030874
Validation loss: 2.6443325063834067

Epoch: 5| Step: 7
Training loss: 2.1054573129545
Validation loss: 2.6158660171470487

Epoch: 5| Step: 8
Training loss: 1.6204714396407252
Validation loss: 2.6339387758009614

Epoch: 5| Step: 9
Training loss: 1.7842821781848126
Validation loss: 2.639198068163557

Epoch: 5| Step: 10
Training loss: 2.2058125870087757
Validation loss: 2.604935613911603

Epoch: 5| Step: 11
Training loss: 0.5940617947320901
Validation loss: 2.611016448201062

Epoch: 380| Step: 0
Training loss: 1.863309911991293
Validation loss: 2.5714600483620957

Epoch: 5| Step: 1
Training loss: 1.76808157648059
Validation loss: 2.597413161144563

Epoch: 5| Step: 2
Training loss: 1.9874190164057604
Validation loss: 2.6319056797164437

Epoch: 5| Step: 3
Training loss: 2.2142410669352244
Validation loss: 2.603509126937934

Epoch: 5| Step: 4
Training loss: 1.627922364729331
Validation loss: 2.587438720017404

Epoch: 5| Step: 5
Training loss: 2.0109100790458783
Validation loss: 2.554803587038468

Epoch: 5| Step: 6
Training loss: 1.836667504157529
Validation loss: 2.5162909043018304

Epoch: 5| Step: 7
Training loss: 1.8560757898854972
Validation loss: 2.5103072911623237

Epoch: 5| Step: 8
Training loss: 1.9238198217222464
Validation loss: 2.530897006001245

Epoch: 5| Step: 9
Training loss: 1.7658709464478617
Validation loss: 2.5224354962109463

Epoch: 5| Step: 10
Training loss: 1.6536931148788254
Validation loss: 2.5231518736321505

Epoch: 5| Step: 11
Training loss: 1.6534806617088147
Validation loss: 2.5205578390756243

Epoch: 381| Step: 0
Training loss: 2.2267681896836855
Validation loss: 2.5297146720911323

Epoch: 5| Step: 1
Training loss: 1.8023837359175887
Validation loss: 2.5223717106992845

Epoch: 5| Step: 2
Training loss: 2.2207485385569177
Validation loss: 2.5654940597692413

Epoch: 5| Step: 3
Training loss: 1.4335397819318534
Validation loss: 2.5581545814439783

Epoch: 5| Step: 4
Training loss: 1.5219395241972398
Validation loss: 2.5628782783981867

Epoch: 5| Step: 5
Training loss: 1.3589747924993163
Validation loss: 2.5875014947036137

Epoch: 5| Step: 6
Training loss: 2.243915915132693
Validation loss: 2.595373779100124

Epoch: 5| Step: 7
Training loss: 1.8880090822753022
Validation loss: 2.6579376843076896

Epoch: 5| Step: 8
Training loss: 1.457737401272927
Validation loss: 2.647987837676596

Epoch: 5| Step: 9
Training loss: 1.8312839700197558
Validation loss: 2.63694631842514

Epoch: 5| Step: 10
Training loss: 1.8196099362162228
Validation loss: 2.6464578399641727

Epoch: 5| Step: 11
Training loss: 2.8236250510567222
Validation loss: 2.64990850311645

Epoch: 382| Step: 0
Training loss: 1.3743004319734413
Validation loss: 2.62669752690317

Epoch: 5| Step: 1
Training loss: 2.2713536940791887
Validation loss: 2.62573631873936

Epoch: 5| Step: 2
Training loss: 1.8374275816056707
Validation loss: 2.5856306003420464

Epoch: 5| Step: 3
Training loss: 2.0498688911753113
Validation loss: 2.5688471767239225

Epoch: 5| Step: 4
Training loss: 1.846625203701156
Validation loss: 2.5853335164050226

Epoch: 5| Step: 5
Training loss: 1.27751111908495
Validation loss: 2.6252492188419607

Epoch: 5| Step: 6
Training loss: 2.5979670059070687
Validation loss: 2.579079930865835

Epoch: 5| Step: 7
Training loss: 1.6207444883314919
Validation loss: 2.633866217169949

Epoch: 5| Step: 8
Training loss: 1.9644934036637358
Validation loss: 2.6399267202620367

Epoch: 5| Step: 9
Training loss: 1.641445427072546
Validation loss: 2.6394509860136366

Epoch: 5| Step: 10
Training loss: 1.6543289415658742
Validation loss: 2.6440392716963994

Epoch: 5| Step: 11
Training loss: 1.39533105989524
Validation loss: 2.591911230987719

Epoch: 383| Step: 0
Training loss: 1.486772789025658
Validation loss: 2.602023827447851

Epoch: 5| Step: 1
Training loss: 2.0943477403670494
Validation loss: 2.539432885958216

Epoch: 5| Step: 2
Training loss: 2.0915404090415772
Validation loss: 2.553420721987216

Epoch: 5| Step: 3
Training loss: 1.8368130807736458
Validation loss: 2.5699081875893257

Epoch: 5| Step: 4
Training loss: 1.8529329017023417
Validation loss: 2.581401076679454

Epoch: 5| Step: 5
Training loss: 1.886660114901504
Validation loss: 2.5805697284389586

Epoch: 5| Step: 6
Training loss: 2.088304412633421
Validation loss: 2.5932211834739385

Epoch: 5| Step: 7
Training loss: 1.3552250711793823
Validation loss: 2.5718801060344307

Epoch: 5| Step: 8
Training loss: 1.6391869191384592
Validation loss: 2.596941860698572

Epoch: 5| Step: 9
Training loss: 1.8749891280812734
Validation loss: 2.5912551869587217

Epoch: 5| Step: 10
Training loss: 1.654673491824816
Validation loss: 2.5847318860298754

Epoch: 5| Step: 11
Training loss: 0.9586948493801654
Validation loss: 2.606115044652939

Epoch: 384| Step: 0
Training loss: 1.4454216993164937
Validation loss: 2.659278224315327

Epoch: 5| Step: 1
Training loss: 1.8299849739916993
Validation loss: 2.6109663361517534

Epoch: 5| Step: 2
Training loss: 1.80528546619958
Validation loss: 2.5927164898860684

Epoch: 5| Step: 3
Training loss: 1.803170098810126
Validation loss: 2.57958600040775

Epoch: 5| Step: 4
Training loss: 1.8446359607101792
Validation loss: 2.5625834645270267

Epoch: 5| Step: 5
Training loss: 2.0072050251760634
Validation loss: 2.545343152902338

Epoch: 5| Step: 6
Training loss: 2.0844172391943943
Validation loss: 2.5116169554400676

Epoch: 5| Step: 7
Training loss: 1.8910162024446868
Validation loss: 2.5619578989884215

Epoch: 5| Step: 8
Training loss: 1.7532228357551571
Validation loss: 2.50658019658178

Epoch: 5| Step: 9
Training loss: 2.0831932275073104
Validation loss: 2.553164211705137

Epoch: 5| Step: 10
Training loss: 1.7103158875426094
Validation loss: 2.6071724761672677

Epoch: 5| Step: 11
Training loss: 1.3156641557896807
Validation loss: 2.5916796947399154

Epoch: 385| Step: 0
Training loss: 2.039199298347601
Validation loss: 2.6007787346744187

Epoch: 5| Step: 1
Training loss: 1.3566722968326
Validation loss: 2.6215303022415997

Epoch: 5| Step: 2
Training loss: 2.035806797191404
Validation loss: 2.6190442231804436

Epoch: 5| Step: 3
Training loss: 2.1429849132410865
Validation loss: 2.6390753305114627

Epoch: 5| Step: 4
Training loss: 1.860152202347057
Validation loss: 2.6380444337643367

Epoch: 5| Step: 5
Training loss: 1.511534765910635
Validation loss: 2.6369098886040025

Epoch: 5| Step: 6
Training loss: 1.6284684798200597
Validation loss: 2.6442081511359334

Epoch: 5| Step: 7
Training loss: 1.7843043592269232
Validation loss: 2.6031215872251834

Epoch: 5| Step: 8
Training loss: 2.203145236740779
Validation loss: 2.602589592553455

Epoch: 5| Step: 9
Training loss: 1.459188709989381
Validation loss: 2.6079815286567793

Epoch: 5| Step: 10
Training loss: 1.8834875645683964
Validation loss: 2.611619893571952

Epoch: 5| Step: 11
Training loss: 2.2447833940983433
Validation loss: 2.6090438046297493

Epoch: 386| Step: 0
Training loss: 1.6793479398784006
Validation loss: 2.60348064669068

Epoch: 5| Step: 1
Training loss: 1.6220239383469144
Validation loss: 2.6176048629253597

Epoch: 5| Step: 2
Training loss: 1.6685874916985932
Validation loss: 2.6080644175403216

Epoch: 5| Step: 3
Training loss: 1.7599109924091028
Validation loss: 2.6384537176290195

Epoch: 5| Step: 4
Training loss: 1.702468885677991
Validation loss: 2.663867055784468

Epoch: 5| Step: 5
Training loss: 1.8069975629240151
Validation loss: 2.6390628859115206

Epoch: 5| Step: 6
Training loss: 1.5762918230478362
Validation loss: 2.6057405649337837

Epoch: 5| Step: 7
Training loss: 1.5495811450214874
Validation loss: 2.6047245013090397

Epoch: 5| Step: 8
Training loss: 1.9758733822182517
Validation loss: 2.5693899004247513

Epoch: 5| Step: 9
Training loss: 2.4377336634609916
Validation loss: 2.579585963822802

Epoch: 5| Step: 10
Training loss: 2.2051853799203487
Validation loss: 2.5650274558949526

Epoch: 5| Step: 11
Training loss: 1.0836416441571726
Validation loss: 2.5762985811460677

Epoch: 387| Step: 0
Training loss: 2.0062370798996216
Validation loss: 2.5669251241125326

Epoch: 5| Step: 1
Training loss: 1.5021082843854532
Validation loss: 2.575512195928816

Epoch: 5| Step: 2
Training loss: 1.7328346904575533
Validation loss: 2.552949584512953

Epoch: 5| Step: 3
Training loss: 1.941894469861861
Validation loss: 2.5480954614093174

Epoch: 5| Step: 4
Training loss: 2.02903556426321
Validation loss: 2.545216556721157

Epoch: 5| Step: 5
Training loss: 1.2774440714319342
Validation loss: 2.577100746838128

Epoch: 5| Step: 6
Training loss: 2.264030052989815
Validation loss: 2.576525845333429

Epoch: 5| Step: 7
Training loss: 1.7250306251129326
Validation loss: 2.5625136809255227

Epoch: 5| Step: 8
Training loss: 1.526328527506449
Validation loss: 2.5423335304044694

Epoch: 5| Step: 9
Training loss: 2.001657037936812
Validation loss: 2.563789547175493

Epoch: 5| Step: 10
Training loss: 1.7983888965869728
Validation loss: 2.592542436154934

Epoch: 5| Step: 11
Training loss: 1.227837743968109
Validation loss: 2.6081592064972883

Epoch: 388| Step: 0
Training loss: 1.6879202707905532
Validation loss: 2.61249330023921

Epoch: 5| Step: 1
Training loss: 1.5298052608996497
Validation loss: 2.6015230563422227

Epoch: 5| Step: 2
Training loss: 1.3211620238724522
Validation loss: 2.621252552571507

Epoch: 5| Step: 3
Training loss: 2.038844539057198
Validation loss: 2.6029275591077727

Epoch: 5| Step: 4
Training loss: 1.9653827997130633
Validation loss: 2.6096708925644765

Epoch: 5| Step: 5
Training loss: 1.874311002660827
Validation loss: 2.594842050834769

Epoch: 5| Step: 6
Training loss: 1.4185811551490088
Validation loss: 2.59875332795273

Epoch: 5| Step: 7
Training loss: 1.8462536510516658
Validation loss: 2.603392384181357

Epoch: 5| Step: 8
Training loss: 1.7151725297453935
Validation loss: 2.6272084467774937

Epoch: 5| Step: 9
Training loss: 1.2545321319649196
Validation loss: 2.5859776519700723

Epoch: 5| Step: 10
Training loss: 2.721499225942238
Validation loss: 2.590267175551038

Epoch: 5| Step: 11
Training loss: 0.9719261278644137
Validation loss: 2.5943189326383345

Epoch: 389| Step: 0
Training loss: 1.7700214170248576
Validation loss: 2.5818636287234717

Epoch: 5| Step: 1
Training loss: 1.9098031121279244
Validation loss: 2.5715684923636903

Epoch: 5| Step: 2
Training loss: 1.6970286319095362
Validation loss: 2.5650152058674283

Epoch: 5| Step: 3
Training loss: 2.2987242021300633
Validation loss: 2.562935958776878

Epoch: 5| Step: 4
Training loss: 2.1555539541904927
Validation loss: 2.5591620825955537

Epoch: 5| Step: 5
Training loss: 1.679682815900082
Validation loss: 2.5539941031413558

Epoch: 5| Step: 6
Training loss: 1.3197437844727127
Validation loss: 2.5804105973281413

Epoch: 5| Step: 7
Training loss: 1.72896653667961
Validation loss: 2.622137412426814

Epoch: 5| Step: 8
Training loss: 1.942759481648188
Validation loss: 2.573360425439179

Epoch: 5| Step: 9
Training loss: 1.7142900341978593
Validation loss: 2.604015568482317

Epoch: 5| Step: 10
Training loss: 1.4420139923369186
Validation loss: 2.5732904399519567

Epoch: 5| Step: 11
Training loss: 1.0528360576037818
Validation loss: 2.589324853159686

Epoch: 390| Step: 0
Training loss: 1.5382310974407944
Validation loss: 2.606976223125684

Epoch: 5| Step: 1
Training loss: 2.042790654955408
Validation loss: 2.586092710879114

Epoch: 5| Step: 2
Training loss: 1.6610402345509634
Validation loss: 2.5923016077533805

Epoch: 5| Step: 3
Training loss: 1.693688313391969
Validation loss: 2.6601901395322307

Epoch: 5| Step: 4
Training loss: 1.9983580525035696
Validation loss: 2.6477873500237497

Epoch: 5| Step: 5
Training loss: 1.8556019945989548
Validation loss: 2.68169619916401

Epoch: 5| Step: 6
Training loss: 2.2288456504437892
Validation loss: 2.642205185006675

Epoch: 5| Step: 7
Training loss: 1.8534643650503768
Validation loss: 2.612702728083776

Epoch: 5| Step: 8
Training loss: 1.8090389354684695
Validation loss: 2.599238857707092

Epoch: 5| Step: 9
Training loss: 1.8497394971182015
Validation loss: 2.6012255323445634

Epoch: 5| Step: 10
Training loss: 1.5193828912402172
Validation loss: 2.577662212565874

Epoch: 5| Step: 11
Training loss: 3.0371313554268915
Validation loss: 2.574582797267167

Epoch: 391| Step: 0
Training loss: 1.761393582601282
Validation loss: 2.57337302949616

Epoch: 5| Step: 1
Training loss: 1.7341146875180842
Validation loss: 2.580176798925922

Epoch: 5| Step: 2
Training loss: 2.1215190425955885
Validation loss: 2.5781279323060287

Epoch: 5| Step: 3
Training loss: 1.4035003058226292
Validation loss: 2.610509682835199

Epoch: 5| Step: 4
Training loss: 1.933028074807602
Validation loss: 2.631173273479569

Epoch: 5| Step: 5
Training loss: 1.6919586477750097
Validation loss: 2.635110503092827

Epoch: 5| Step: 6
Training loss: 1.5059165300538746
Validation loss: 2.6086532904345936

Epoch: 5| Step: 7
Training loss: 1.40869140625
Validation loss: 2.577243318939652

Epoch: 5| Step: 8
Training loss: 1.5915557865980186
Validation loss: 2.5706646068380574

Epoch: 5| Step: 9
Training loss: 2.2576538875001697
Validation loss: 2.5566867545415066

Epoch: 5| Step: 10
Training loss: 1.7893910335418024
Validation loss: 2.599894362070356

Epoch: 5| Step: 11
Training loss: 2.4571947489135115
Validation loss: 2.587544478772826

Epoch: 392| Step: 0
Training loss: 1.815983745699665
Validation loss: 2.6035623357826974

Epoch: 5| Step: 1
Training loss: 1.721937656820313
Validation loss: 2.6169480551128204

Epoch: 5| Step: 2
Training loss: 1.7834155654962054
Validation loss: 2.637197613971529

Epoch: 5| Step: 3
Training loss: 1.734218762208131
Validation loss: 2.6099699830622596

Epoch: 5| Step: 4
Training loss: 1.768033570682912
Validation loss: 2.6228454353430823

Epoch: 5| Step: 5
Training loss: 1.8142230952605667
Validation loss: 2.5974654469411584

Epoch: 5| Step: 6
Training loss: 1.926086401604698
Validation loss: 2.5620216721800078

Epoch: 5| Step: 7
Training loss: 1.7114392246039412
Validation loss: 2.56024159178725

Epoch: 5| Step: 8
Training loss: 1.426691720882166
Validation loss: 2.54916391316623

Epoch: 5| Step: 9
Training loss: 1.9614835791871668
Validation loss: 2.555895668412256

Epoch: 5| Step: 10
Training loss: 2.083385950059839
Validation loss: 2.550772058880279

Epoch: 5| Step: 11
Training loss: 1.701846351452453
Validation loss: 2.552244676952408

Epoch: 393| Step: 0
Training loss: 1.7828424262327596
Validation loss: 2.6258369163719566

Epoch: 5| Step: 1
Training loss: 2.09893146305223
Validation loss: 2.610293095508682

Epoch: 5| Step: 2
Training loss: 1.844695931579666
Validation loss: 2.667780218356186

Epoch: 5| Step: 3
Training loss: 2.1405255371152956
Validation loss: 2.6999704737579417

Epoch: 5| Step: 4
Training loss: 1.629715167475473
Validation loss: 2.695718869152856

Epoch: 5| Step: 5
Training loss: 1.6588985211617295
Validation loss: 2.65136393154031

Epoch: 5| Step: 6
Training loss: 2.0181296703465335
Validation loss: 2.6136868803070277

Epoch: 5| Step: 7
Training loss: 0.9326040856205018
Validation loss: 2.621555213840794

Epoch: 5| Step: 8
Training loss: 1.930608305755488
Validation loss: 2.5883335871633917

Epoch: 5| Step: 9
Training loss: 2.186249948003211
Validation loss: 2.611848876736072

Epoch: 5| Step: 10
Training loss: 1.7264064528428642
Validation loss: 2.579655395345007

Epoch: 5| Step: 11
Training loss: 2.4301565030409997
Validation loss: 2.6322789278817855

Epoch: 394| Step: 0
Training loss: 1.5237183923236028
Validation loss: 2.582972350715415

Epoch: 5| Step: 1
Training loss: 1.218701141551832
Validation loss: 2.608281144228396

Epoch: 5| Step: 2
Training loss: 1.6686124966437499
Validation loss: 2.572404398610716

Epoch: 5| Step: 3
Training loss: 1.7293603244788849
Validation loss: 2.6095551754084405

Epoch: 5| Step: 4
Training loss: 1.5758957177772632
Validation loss: 2.633998784706542

Epoch: 5| Step: 5
Training loss: 1.8340857724565498
Validation loss: 2.621822405603225

Epoch: 5| Step: 6
Training loss: 2.363029126046315
Validation loss: 2.6120690811720917

Epoch: 5| Step: 7
Training loss: 1.106026983680394
Validation loss: 2.583282498403006

Epoch: 5| Step: 8
Training loss: 1.8597741860551418
Validation loss: 2.5453838593635507

Epoch: 5| Step: 9
Training loss: 1.8411968463339474
Validation loss: 2.5945345829474484

Epoch: 5| Step: 10
Training loss: 2.0022517879352835
Validation loss: 2.5713218438647014

Epoch: 5| Step: 11
Training loss: 1.7590261381114625
Validation loss: 2.546239527894753

Epoch: 395| Step: 0
Training loss: 1.9941159357976712
Validation loss: 2.5554911411991172

Epoch: 5| Step: 1
Training loss: 1.778117520764113
Validation loss: 2.558775152322886

Epoch: 5| Step: 2
Training loss: 1.2929168414157688
Validation loss: 2.600968125943056

Epoch: 5| Step: 3
Training loss: 1.8234211977350063
Validation loss: 2.59031411757104

Epoch: 5| Step: 4
Training loss: 1.4764879803295858
Validation loss: 2.5887977785533183

Epoch: 5| Step: 5
Training loss: 1.7467810453694637
Validation loss: 2.601365949749446

Epoch: 5| Step: 6
Training loss: 2.3268594054079417
Validation loss: 2.5983669102436195

Epoch: 5| Step: 7
Training loss: 1.6875678154776292
Validation loss: 2.6076284757717483

Epoch: 5| Step: 8
Training loss: 1.7726728496556063
Validation loss: 2.583070942925113

Epoch: 5| Step: 9
Training loss: 1.6705038562354502
Validation loss: 2.587456482753218

Epoch: 5| Step: 10
Training loss: 1.4146312602505386
Validation loss: 2.6043849942557444

Epoch: 5| Step: 11
Training loss: 1.1513758845886537
Validation loss: 2.5836943302392

Epoch: 396| Step: 0
Training loss: 1.6183593484821912
Validation loss: 2.5470641130316802

Epoch: 5| Step: 1
Training loss: 1.9332776976944073
Validation loss: 2.5926147105835216

Epoch: 5| Step: 2
Training loss: 1.4850529778788815
Validation loss: 2.600760381112023

Epoch: 5| Step: 3
Training loss: 1.8643773851369805
Validation loss: 2.5881552391800584

Epoch: 5| Step: 4
Training loss: 2.0852824693527126
Validation loss: 2.616321310306911

Epoch: 5| Step: 5
Training loss: 1.6675054188058358
Validation loss: 2.604341666381575

Epoch: 5| Step: 6
Training loss: 1.8675570581137995
Validation loss: 2.616404819649501

Epoch: 5| Step: 7
Training loss: 1.6849175932794394
Validation loss: 2.6291027704163428

Epoch: 5| Step: 8
Training loss: 1.7061520195520126
Validation loss: 2.6507676300829206

Epoch: 5| Step: 9
Training loss: 1.834064648448721
Validation loss: 2.6554044162985035

Epoch: 5| Step: 10
Training loss: 1.4860086385904538
Validation loss: 2.627318569323197

Epoch: 5| Step: 11
Training loss: 0.6478209264329586
Validation loss: 2.6413643533625293

Epoch: 397| Step: 0
Training loss: 1.3011820865758343
Validation loss: 2.617335244179127

Epoch: 5| Step: 1
Training loss: 1.498350985419168
Validation loss: 2.624714059999253

Epoch: 5| Step: 2
Training loss: 2.1089114209561313
Validation loss: 2.579136840625259

Epoch: 5| Step: 3
Training loss: 1.552436387360573
Validation loss: 2.6159152302515425

Epoch: 5| Step: 4
Training loss: 1.613307481603288
Validation loss: 2.592495994307275

Epoch: 5| Step: 5
Training loss: 1.593467612587056
Validation loss: 2.570341293652935

Epoch: 5| Step: 6
Training loss: 1.6518490458833526
Validation loss: 2.58653015844074

Epoch: 5| Step: 7
Training loss: 1.9024727716891068
Validation loss: 2.6031715678934093

Epoch: 5| Step: 8
Training loss: 1.327177540036871
Validation loss: 2.577821732996755

Epoch: 5| Step: 9
Training loss: 2.4962609940975877
Validation loss: 2.5433175726206825

Epoch: 5| Step: 10
Training loss: 1.344283330781178
Validation loss: 2.5794085842639363

Epoch: 5| Step: 11
Training loss: 2.6244012967323203
Validation loss: 2.5991550834860786

Epoch: 398| Step: 0
Training loss: 1.8152576383475436
Validation loss: 2.541294603527077

Epoch: 5| Step: 1
Training loss: 2.2442799019484614
Validation loss: 2.5789432575752707

Epoch: 5| Step: 2
Training loss: 1.4623610145192905
Validation loss: 2.6427553149898735

Epoch: 5| Step: 3
Training loss: 1.4420202751374442
Validation loss: 2.6033756249941225

Epoch: 5| Step: 4
Training loss: 1.3829730958948971
Validation loss: 2.6135765368822836

Epoch: 5| Step: 5
Training loss: 1.616384629427171
Validation loss: 2.638882165336967

Epoch: 5| Step: 6
Training loss: 2.1532050484669147
Validation loss: 2.627243918356882

Epoch: 5| Step: 7
Training loss: 1.1033128400169043
Validation loss: 2.6155758692457987

Epoch: 5| Step: 8
Training loss: 1.83965195225073
Validation loss: 2.634296278344882

Epoch: 5| Step: 9
Training loss: 1.6077957552824755
Validation loss: 2.59292376813407

Epoch: 5| Step: 10
Training loss: 1.7240951652813523
Validation loss: 2.600474946493064

Epoch: 5| Step: 11
Training loss: 1.6893920181777715
Validation loss: 2.628436310602733

Epoch: 399| Step: 0
Training loss: 2.096001055498804
Validation loss: 2.61819331641183

Epoch: 5| Step: 1
Training loss: 1.424899813827769
Validation loss: 2.6010854816425657

Epoch: 5| Step: 2
Training loss: 1.6584321527734511
Validation loss: 2.649346029812103

Epoch: 5| Step: 3
Training loss: 1.4046769987229348
Validation loss: 2.6588067521598022

Epoch: 5| Step: 4
Training loss: 1.2667555292647636
Validation loss: 2.6359826536895814

Epoch: 5| Step: 5
Training loss: 2.1724859242921597
Validation loss: 2.660540589862039

Epoch: 5| Step: 6
Training loss: 1.5365949494568467
Validation loss: 2.6444708715370777

Epoch: 5| Step: 7
Training loss: 1.8031869570237555
Validation loss: 2.6471648745469993

Epoch: 5| Step: 8
Training loss: 1.4882628272010188
Validation loss: 2.6286340225848295

Epoch: 5| Step: 9
Training loss: 1.8311778604404825
Validation loss: 2.59940694072838

Epoch: 5| Step: 10
Training loss: 2.0398254136569345
Validation loss: 2.595153784908337

Epoch: 5| Step: 11
Training loss: 1.8601100975184606
Validation loss: 2.600384328019969

Epoch: 400| Step: 0
Training loss: 1.5371153466618832
Validation loss: 2.627998546774127

Epoch: 5| Step: 1
Training loss: 1.6689323125682258
Validation loss: 2.656764530388039

Epoch: 5| Step: 2
Training loss: 1.6794175041904702
Validation loss: 2.676451620881027

Epoch: 5| Step: 3
Training loss: 1.8937356123676716
Validation loss: 2.682416014273519

Epoch: 5| Step: 4
Training loss: 1.5348411023034496
Validation loss: 2.663525979467411

Epoch: 5| Step: 5
Training loss: 2.1113670832509435
Validation loss: 2.6409587536327765

Epoch: 5| Step: 6
Training loss: 1.6197985519148361
Validation loss: 2.6771368709114056

Epoch: 5| Step: 7
Training loss: 1.6084463162177782
Validation loss: 2.6250632444967548

Epoch: 5| Step: 8
Training loss: 1.580971822281248
Validation loss: 2.6126466217146493

Epoch: 5| Step: 9
Training loss: 1.9791494937620169
Validation loss: 2.585316006137692

Epoch: 5| Step: 10
Training loss: 1.7680914876276101
Validation loss: 2.5923025044780275

Epoch: 5| Step: 11
Training loss: 1.0843753693769633
Validation loss: 2.6034490524827523

Testing loss: 2.175718677481714
