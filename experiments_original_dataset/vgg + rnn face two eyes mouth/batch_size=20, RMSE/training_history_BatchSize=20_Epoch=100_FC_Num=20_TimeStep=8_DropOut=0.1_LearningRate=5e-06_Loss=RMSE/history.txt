Epoch: 1| Step: 0
Training loss: 4.705597997236556
Validation loss: 5.806632981058481

Epoch: 5| Step: 1
Training loss: 6.268110662168733
Validation loss: 5.805163761417064

Epoch: 5| Step: 2
Training loss: 4.8797347722128865
Validation loss: 5.8038807407156945

Epoch: 5| Step: 3
Training loss: 5.02430141014989
Validation loss: 5.802632429711904

Epoch: 5| Step: 4
Training loss: 6.354789561607406
Validation loss: 5.8013680894413024

Epoch: 5| Step: 5
Training loss: 6.05209684999656
Validation loss: 5.800087914951548

Epoch: 5| Step: 6
Training loss: 6.410853671688716
Validation loss: 5.7987582702643525

Epoch: 5| Step: 7
Training loss: 6.0779156881737695
Validation loss: 5.7973344317469975

Epoch: 5| Step: 8
Training loss: 6.799273889706613
Validation loss: 5.796027492595764

Epoch: 5| Step: 9
Training loss: 5.924413132072464
Validation loss: 5.7944790806298485

Epoch: 5| Step: 10
Training loss: 6.103021229976586
Validation loss: 5.792982324784524

Epoch: 5| Step: 11
Training loss: 6.3345366221634
Validation loss: 5.791345994520014

Epoch: 2| Step: 0
Training loss: 5.577228719901291
Validation loss: 5.789678364957889

Epoch: 5| Step: 1
Training loss: 4.965001449661581
Validation loss: 5.787939219221346

Epoch: 5| Step: 2
Training loss: 5.903476608895588
Validation loss: 5.786096483162145

Epoch: 5| Step: 3
Training loss: 5.385566792956567
Validation loss: 5.784280797025389

Epoch: 5| Step: 4
Training loss: 5.567744836309927
Validation loss: 5.782280151414364

Epoch: 5| Step: 5
Training loss: 4.903229773953748
Validation loss: 5.780245066411639

Epoch: 5| Step: 6
Training loss: 5.909452024509588
Validation loss: 5.778150500854535

Epoch: 5| Step: 7
Training loss: 7.004871852881605
Validation loss: 5.775931081811111

Epoch: 5| Step: 8
Training loss: 5.912841348290904
Validation loss: 5.773673177063365

Epoch: 5| Step: 9
Training loss: 6.958499502912337
Validation loss: 5.771164959170887

Epoch: 5| Step: 10
Training loss: 6.486117282876294
Validation loss: 5.768517531053624

Epoch: 5| Step: 11
Training loss: 5.127104164441865
Validation loss: 5.765750011822149

Epoch: 3| Step: 0
Training loss: 6.7872782690316695
Validation loss: 5.762960712609392

Epoch: 5| Step: 1
Training loss: 5.884734833868167
Validation loss: 5.759931432373278

Epoch: 5| Step: 2
Training loss: 6.00236019761348
Validation loss: 5.756891750661554

Epoch: 5| Step: 3
Training loss: 5.32934824753743
Validation loss: 5.753630645981456

Epoch: 5| Step: 4
Training loss: 5.524384456539681
Validation loss: 5.750230141885332

Epoch: 5| Step: 5
Training loss: 5.825123195409623
Validation loss: 5.746713092757298

Epoch: 5| Step: 6
Training loss: 5.938418989838706
Validation loss: 5.742973602532274

Epoch: 5| Step: 7
Training loss: 6.018065277161405
Validation loss: 5.739254544551279

Epoch: 5| Step: 8
Training loss: 5.480488587477462
Validation loss: 5.735188834416475

Epoch: 5| Step: 9
Training loss: 6.076714908633656
Validation loss: 5.730900348409992

Epoch: 5| Step: 10
Training loss: 5.5059374925174
Validation loss: 5.72641834114012

Epoch: 5| Step: 11
Training loss: 5.760384842943947
Validation loss: 5.721796478504952

Epoch: 4| Step: 0
Training loss: 6.920408347545493
Validation loss: 5.716834096523482

Epoch: 5| Step: 1
Training loss: 5.834877500057206
Validation loss: 5.711839569000829

Epoch: 5| Step: 2
Training loss: 6.0964540399786715
Validation loss: 5.706481217779503

Epoch: 5| Step: 3
Training loss: 5.750772838899908
Validation loss: 5.7008612124363545

Epoch: 5| Step: 4
Training loss: 5.854238308324517
Validation loss: 5.694900030297476

Epoch: 5| Step: 5
Training loss: 4.603007635315358
Validation loss: 5.688865812024276

Epoch: 5| Step: 6
Training loss: 5.810615480162216
Validation loss: 5.682704692577004

Epoch: 5| Step: 7
Training loss: 5.7509831127117135
Validation loss: 5.676285548252491

Epoch: 5| Step: 8
Training loss: 6.2376425075114454
Validation loss: 5.669476452943262

Epoch: 5| Step: 9
Training loss: 5.573064308944046
Validation loss: 5.662487952954275

Epoch: 5| Step: 10
Training loss: 5.41990938202389
Validation loss: 5.655020339528997

Epoch: 5| Step: 11
Training loss: 4.180624484271603
Validation loss: 5.647794272704128

Epoch: 5| Step: 0
Training loss: 6.163478886543158
Validation loss: 5.640418276956945

Epoch: 5| Step: 1
Training loss: 6.277795553416665
Validation loss: 5.632900630633607

Epoch: 5| Step: 2
Training loss: 5.770215199918383
Validation loss: 5.625246374597985

Epoch: 5| Step: 3
Training loss: 5.94304005006033
Validation loss: 5.617373297620186

Epoch: 5| Step: 4
Training loss: 6.435147939076671
Validation loss: 5.609126058029206

Epoch: 5| Step: 5
Training loss: 5.2968566354078765
Validation loss: 5.600927149282012

Epoch: 5| Step: 6
Training loss: 4.9151932184187475
Validation loss: 5.59259710383052

Epoch: 5| Step: 7
Training loss: 5.6630666554519555
Validation loss: 5.584235462451299

Epoch: 5| Step: 8
Training loss: 5.757250319718302
Validation loss: 5.576055582752342

Epoch: 5| Step: 9
Training loss: 4.8429107923465775
Validation loss: 5.567816276205732

Epoch: 5| Step: 10
Training loss: 5.797707387382277
Validation loss: 5.559471870594786

Epoch: 5| Step: 11
Training loss: 4.647109718782559
Validation loss: 5.550915517129414

Epoch: 6| Step: 0
Training loss: 6.083646095631676
Validation loss: 5.542777554828296

Epoch: 5| Step: 1
Training loss: 5.074394663521145
Validation loss: 5.534685192465573

Epoch: 5| Step: 2
Training loss: 5.660387075283899
Validation loss: 5.526975096864861

Epoch: 5| Step: 3
Training loss: 5.9754750976656466
Validation loss: 5.51861035439236

Epoch: 5| Step: 4
Training loss: 5.2969210912448945
Validation loss: 5.510493534563962

Epoch: 5| Step: 5
Training loss: 5.7519634045960775
Validation loss: 5.502426999139504

Epoch: 5| Step: 6
Training loss: 5.4300180458064045
Validation loss: 5.494572027315369

Epoch: 5| Step: 7
Training loss: 5.498053119445832
Validation loss: 5.486666252388056

Epoch: 5| Step: 8
Training loss: 5.593702774274721
Validation loss: 5.4790326477988565

Epoch: 5| Step: 9
Training loss: 5.227615957337734
Validation loss: 5.471281174310981

Epoch: 5| Step: 10
Training loss: 5.941737219064802
Validation loss: 5.463534253033268

Epoch: 5| Step: 11
Training loss: 6.576683194500121
Validation loss: 5.4560783717547965

Epoch: 7| Step: 0
Training loss: 5.438555910912212
Validation loss: 5.448015772524076

Epoch: 5| Step: 1
Training loss: 5.699271292702451
Validation loss: 5.440882058509951

Epoch: 5| Step: 2
Training loss: 5.562306947251244
Validation loss: 5.433067605282166

Epoch: 5| Step: 3
Training loss: 6.4046736103548465
Validation loss: 5.42533106958316

Epoch: 5| Step: 4
Training loss: 5.928643618487225
Validation loss: 5.418040969319633

Epoch: 5| Step: 5
Training loss: 6.2350731174369685
Validation loss: 5.410335643378537

Epoch: 5| Step: 6
Training loss: 5.123026025739123
Validation loss: 5.403139193273332

Epoch: 5| Step: 7
Training loss: 5.713929526263298
Validation loss: 5.396123151716103

Epoch: 5| Step: 8
Training loss: 4.842514569640213
Validation loss: 5.388582707038699

Epoch: 5| Step: 9
Training loss: 4.800861106562233
Validation loss: 5.380765676173003

Epoch: 5| Step: 10
Training loss: 5.010927466396448
Validation loss: 5.373724009736507

Epoch: 5| Step: 11
Training loss: 4.651180092979009
Validation loss: 5.3661657820315405

Epoch: 8| Step: 0
Training loss: 4.91021684777643
Validation loss: 5.359670610495958

Epoch: 5| Step: 1
Training loss: 5.022649391728577
Validation loss: 5.352725249338851

Epoch: 5| Step: 2
Training loss: 5.331117388204046
Validation loss: 5.345958736591047

Epoch: 5| Step: 3
Training loss: 5.534917445338185
Validation loss: 5.339042352287272

Epoch: 5| Step: 4
Training loss: 5.312201816941907
Validation loss: 5.331825291495013

Epoch: 5| Step: 5
Training loss: 5.677459909624252
Validation loss: 5.324513640602014

Epoch: 5| Step: 6
Training loss: 5.532107356808161
Validation loss: 5.317855035873611

Epoch: 5| Step: 7
Training loss: 5.271194907993504
Validation loss: 5.309881739451917

Epoch: 5| Step: 8
Training loss: 5.8162455642260245
Validation loss: 5.303214631365637

Epoch: 5| Step: 9
Training loss: 5.7948326769972
Validation loss: 5.296066537560085

Epoch: 5| Step: 10
Training loss: 5.67576982427446
Validation loss: 5.289492748797497

Epoch: 5| Step: 11
Training loss: 5.070377202495485
Validation loss: 5.282808363592346

Epoch: 9| Step: 0
Training loss: 6.831788919730322
Validation loss: 5.275876232489585

Epoch: 5| Step: 1
Training loss: 6.456380470929544
Validation loss: 5.269772760895583

Epoch: 5| Step: 2
Training loss: 6.254051726231944
Validation loss: 5.263462992470923

Epoch: 5| Step: 3
Training loss: 4.827705044058889
Validation loss: 5.257010041094556

Epoch: 5| Step: 4
Training loss: 5.224552606292053
Validation loss: 5.250335955088625

Epoch: 5| Step: 5
Training loss: 4.196273949276077
Validation loss: 5.244264398744461

Epoch: 5| Step: 6
Training loss: 4.6000704718457595
Validation loss: 5.238694059266996

Epoch: 5| Step: 7
Training loss: 5.202690954118118
Validation loss: 5.232758396704675

Epoch: 5| Step: 8
Training loss: 5.004103502589053
Validation loss: 5.2270641760882395

Epoch: 5| Step: 9
Training loss: 5.384295388030036
Validation loss: 5.221791156040137

Epoch: 5| Step: 10
Training loss: 4.634256327698699
Validation loss: 5.215876536306451

Epoch: 5| Step: 11
Training loss: 4.236523072825407
Validation loss: 5.210247888263019

Epoch: 10| Step: 0
Training loss: 5.314541772161253
Validation loss: 5.204903704289633

Epoch: 5| Step: 1
Training loss: 5.846676996121186
Validation loss: 5.198892240639842

Epoch: 5| Step: 2
Training loss: 4.871667358593277
Validation loss: 5.193286999976073

Epoch: 5| Step: 3
Training loss: 5.788010062693382
Validation loss: 5.187251533165011

Epoch: 5| Step: 4
Training loss: 5.773013954990211
Validation loss: 5.181004835708562

Epoch: 5| Step: 5
Training loss: 5.566069411409361
Validation loss: 5.176019604070939

Epoch: 5| Step: 6
Training loss: 4.332299378114505
Validation loss: 5.170409441512074

Epoch: 5| Step: 7
Training loss: 5.667664533531289
Validation loss: 5.16497177606228

Epoch: 5| Step: 8
Training loss: 4.9755246983167085
Validation loss: 5.159865034935665

Epoch: 5| Step: 9
Training loss: 5.614761529004405
Validation loss: 5.154235353785696

Epoch: 5| Step: 10
Training loss: 4.44958612467589
Validation loss: 5.149036733421586

Epoch: 5| Step: 11
Training loss: 4.305395936912653
Validation loss: 5.1435674731538255

Epoch: 11| Step: 0
Training loss: 5.060059135604104
Validation loss: 5.138450100640529

Epoch: 5| Step: 1
Training loss: 5.1228981360056
Validation loss: 5.132956833264089

Epoch: 5| Step: 2
Training loss: 5.43922800252276
Validation loss: 5.127519515465534

Epoch: 5| Step: 3
Training loss: 5.702041313993119
Validation loss: 5.121880915764245

Epoch: 5| Step: 4
Training loss: 5.766734773678357
Validation loss: 5.116438444413637

Epoch: 5| Step: 5
Training loss: 4.224881386079428
Validation loss: 5.110662292329478

Epoch: 5| Step: 6
Training loss: 4.716564758781469
Validation loss: 5.105198941328833

Epoch: 5| Step: 7
Training loss: 5.373496266648517
Validation loss: 5.099874477150735

Epoch: 5| Step: 8
Training loss: 5.244679434319548
Validation loss: 5.094688937468889

Epoch: 5| Step: 9
Training loss: 5.222067868993005
Validation loss: 5.0890641921933355

Epoch: 5| Step: 10
Training loss: 5.495805528101405
Validation loss: 5.083966710805768

Epoch: 5| Step: 11
Training loss: 5.355135027325518
Validation loss: 5.078545029704248

Epoch: 12| Step: 0
Training loss: 5.518908336610173
Validation loss: 5.073175351899239

Epoch: 5| Step: 1
Training loss: 4.732992140243778
Validation loss: 5.067338005353509

Epoch: 5| Step: 2
Training loss: 4.913747707648799
Validation loss: 5.061626413897267

Epoch: 5| Step: 3
Training loss: 4.9324189129064715
Validation loss: 5.056378890800729

Epoch: 5| Step: 4
Training loss: 5.399610908053841
Validation loss: 5.050198030838052

Epoch: 5| Step: 5
Training loss: 5.3737234329592685
Validation loss: 5.044323696580926

Epoch: 5| Step: 6
Training loss: 6.035815472693823
Validation loss: 5.038535007201373

Epoch: 5| Step: 7
Training loss: 4.625374856140252
Validation loss: 5.032541097519609

Epoch: 5| Step: 8
Training loss: 4.610495427914478
Validation loss: 5.026600942641572

Epoch: 5| Step: 9
Training loss: 5.266608715140934
Validation loss: 5.0212441536177135

Epoch: 5| Step: 10
Training loss: 5.419736764856924
Validation loss: 5.016135541337415

Epoch: 5| Step: 11
Training loss: 4.265006778617741
Validation loss: 5.0108665639711285

Epoch: 13| Step: 0
Training loss: 5.553650921597428
Validation loss: 5.005569018951404

Epoch: 5| Step: 1
Training loss: 5.339024467656555
Validation loss: 5.00057719395929

Epoch: 5| Step: 2
Training loss: 4.692228246836481
Validation loss: 4.995459688587745

Epoch: 5| Step: 3
Training loss: 4.981381082186135
Validation loss: 4.989783100543791

Epoch: 5| Step: 4
Training loss: 5.659290824108259
Validation loss: 4.984789752346295

Epoch: 5| Step: 5
Training loss: 5.58769537735612
Validation loss: 4.979037090302039

Epoch: 5| Step: 6
Training loss: 5.042180100876776
Validation loss: 4.973972447027451

Epoch: 5| Step: 7
Training loss: 4.564969583265871
Validation loss: 4.968646058408917

Epoch: 5| Step: 8
Training loss: 4.9425370803391395
Validation loss: 4.96319575136787

Epoch: 5| Step: 9
Training loss: 4.356399888206076
Validation loss: 4.958179321889097

Epoch: 5| Step: 10
Training loss: 5.216394863827528
Validation loss: 4.953176736812165

Epoch: 5| Step: 11
Training loss: 5.2614066322377955
Validation loss: 4.947582517349875

Epoch: 14| Step: 0
Training loss: 5.141245332062372
Validation loss: 4.9423495270626345

Epoch: 5| Step: 1
Training loss: 5.080514386784686
Validation loss: 4.936792202207038

Epoch: 5| Step: 2
Training loss: 4.746117661655299
Validation loss: 4.931449788747853

Epoch: 5| Step: 3
Training loss: 4.863198104208922
Validation loss: 4.925967578756982

Epoch: 5| Step: 4
Training loss: 4.035840872842154
Validation loss: 4.920969497299827

Epoch: 5| Step: 5
Training loss: 5.847328436765983
Validation loss: 4.9160234413089885

Epoch: 5| Step: 6
Training loss: 5.384590110090695
Validation loss: 4.9107883059715265

Epoch: 5| Step: 7
Training loss: 4.902348807890817
Validation loss: 4.905078019037874

Epoch: 5| Step: 8
Training loss: 5.3206790568131765
Validation loss: 4.900454149155033

Epoch: 5| Step: 9
Training loss: 4.190994853994805
Validation loss: 4.894630717296619

Epoch: 5| Step: 10
Training loss: 5.46026179290388
Validation loss: 4.889704925472903

Epoch: 5| Step: 11
Training loss: 5.8813357988477915
Validation loss: 4.884078945462788

Epoch: 15| Step: 0
Training loss: 4.733042513729153
Validation loss: 4.8790100917348225

Epoch: 5| Step: 1
Training loss: 4.62812266739317
Validation loss: 4.874416797346399

Epoch: 5| Step: 2
Training loss: 5.327743024362435
Validation loss: 4.869031700632783

Epoch: 5| Step: 3
Training loss: 4.441670781480172
Validation loss: 4.864095686568437

Epoch: 5| Step: 4
Training loss: 5.131352651036262
Validation loss: 4.858447674321279

Epoch: 5| Step: 5
Training loss: 5.717164200169453
Validation loss: 4.85270848563517

Epoch: 5| Step: 6
Training loss: 4.3014683811187835
Validation loss: 4.848202019153825

Epoch: 5| Step: 7
Training loss: 5.4045760369035305
Validation loss: 4.842870968867785

Epoch: 5| Step: 8
Training loss: 5.194696237827184
Validation loss: 4.836981422925187

Epoch: 5| Step: 9
Training loss: 4.644692228076548
Validation loss: 4.831867532878529

Epoch: 5| Step: 10
Training loss: 5.013659891456753
Validation loss: 4.827822053328513

Epoch: 5| Step: 11
Training loss: 5.071950874066636
Validation loss: 4.822046142296704

Epoch: 16| Step: 0
Training loss: 5.3511829102375446
Validation loss: 4.81725871144536

Epoch: 5| Step: 1
Training loss: 4.956509080924508
Validation loss: 4.811682511953108

Epoch: 5| Step: 2
Training loss: 4.564868469014666
Validation loss: 4.8069551817845

Epoch: 5| Step: 3
Training loss: 5.534224750152913
Validation loss: 4.802418995653486

Epoch: 5| Step: 4
Training loss: 4.890280226964728
Validation loss: 4.797203392360488

Epoch: 5| Step: 5
Training loss: 4.730149804096003
Validation loss: 4.7921466448783345

Epoch: 5| Step: 6
Training loss: 4.167783180689148
Validation loss: 4.787179731342005

Epoch: 5| Step: 7
Training loss: 5.566332750337118
Validation loss: 4.783425835413932

Epoch: 5| Step: 8
Training loss: 3.776402163781329
Validation loss: 4.7780259924860635

Epoch: 5| Step: 9
Training loss: 4.750099984170769
Validation loss: 4.7740911108079676

Epoch: 5| Step: 10
Training loss: 5.176857567923272
Validation loss: 4.769194195059305

Epoch: 5| Step: 11
Training loss: 6.332565595706513
Validation loss: 4.764642053344311

Epoch: 17| Step: 0
Training loss: 4.7992045061240685
Validation loss: 4.759958026698256

Epoch: 5| Step: 1
Training loss: 5.078828451877806
Validation loss: 4.7548673562523165

Epoch: 5| Step: 2
Training loss: 4.7192928178836
Validation loss: 4.750406139143402

Epoch: 5| Step: 3
Training loss: 4.2792650062283215
Validation loss: 4.745300837923135

Epoch: 5| Step: 4
Training loss: 4.706759547072695
Validation loss: 4.740318504019703

Epoch: 5| Step: 5
Training loss: 4.859077272769905
Validation loss: 4.735459005309496

Epoch: 5| Step: 6
Training loss: 5.210853129880608
Validation loss: 4.730457645049371

Epoch: 5| Step: 7
Training loss: 5.325416928298204
Validation loss: 4.726045707424567

Epoch: 5| Step: 8
Training loss: 4.9535121826564215
Validation loss: 4.721720671977201

Epoch: 5| Step: 9
Training loss: 4.981647761796033
Validation loss: 4.716588449447415

Epoch: 5| Step: 10
Training loss: 4.409546829433474
Validation loss: 4.712061581847164

Epoch: 5| Step: 11
Training loss: 5.126641917638151
Validation loss: 4.707527862563613

Epoch: 18| Step: 0
Training loss: 4.553220535564185
Validation loss: 4.703305939059073

Epoch: 5| Step: 1
Training loss: 4.484563418161646
Validation loss: 4.69957943380628

Epoch: 5| Step: 2
Training loss: 4.885098488321457
Validation loss: 4.693938271598153

Epoch: 5| Step: 3
Training loss: 4.9131289324607
Validation loss: 4.689686150979284

Epoch: 5| Step: 4
Training loss: 5.02651299620333
Validation loss: 4.684488503215796

Epoch: 5| Step: 5
Training loss: 4.630285181609995
Validation loss: 4.680517743929839

Epoch: 5| Step: 6
Training loss: 4.91060061632851
Validation loss: 4.676005991987093

Epoch: 5| Step: 7
Training loss: 4.793717827123234
Validation loss: 4.67110332125002

Epoch: 5| Step: 8
Training loss: 4.42904868388943
Validation loss: 4.666785403285151

Epoch: 5| Step: 9
Training loss: 5.429946563907388
Validation loss: 4.662124094668823

Epoch: 5| Step: 10
Training loss: 4.627923196311918
Validation loss: 4.657622363383482

Epoch: 5| Step: 11
Training loss: 5.3080723880526195
Validation loss: 4.653152220479656

Epoch: 19| Step: 0
Training loss: 4.787777901096145
Validation loss: 4.648358615237957

Epoch: 5| Step: 1
Training loss: 5.366393362316651
Validation loss: 4.643903864779736

Epoch: 5| Step: 2
Training loss: 5.143984546157618
Validation loss: 4.63925217381738

Epoch: 5| Step: 3
Training loss: 4.7734602757486515
Validation loss: 4.634724797539088

Epoch: 5| Step: 4
Training loss: 4.6950204158578766
Validation loss: 4.630752929081923

Epoch: 5| Step: 5
Training loss: 4.052778849530066
Validation loss: 4.625655982605248

Epoch: 5| Step: 6
Training loss: 4.501395750813778
Validation loss: 4.621301757568061

Epoch: 5| Step: 7
Training loss: 4.52136478142323
Validation loss: 4.616541705982341

Epoch: 5| Step: 8
Training loss: 4.917845223763906
Validation loss: 4.612336352959344

Epoch: 5| Step: 9
Training loss: 4.250466713804056
Validation loss: 4.609174450320772

Epoch: 5| Step: 10
Training loss: 5.106703500208142
Validation loss: 4.60632349936491

Epoch: 5| Step: 11
Training loss: 4.826721975174742
Validation loss: 4.601479797829053

Epoch: 20| Step: 0
Training loss: 4.818539879320656
Validation loss: 4.595962346336341

Epoch: 5| Step: 1
Training loss: 5.047737166041485
Validation loss: 4.591068488594871

Epoch: 5| Step: 2
Training loss: 4.7847211616612135
Validation loss: 4.5866287810864215

Epoch: 5| Step: 3
Training loss: 4.708690708517238
Validation loss: 4.582121899925733

Epoch: 5| Step: 4
Training loss: 4.496852409724899
Validation loss: 4.577219920261148

Epoch: 5| Step: 5
Training loss: 5.048333397243261
Validation loss: 4.571726970835793

Epoch: 5| Step: 6
Training loss: 4.581865364577642
Validation loss: 4.5667718110661

Epoch: 5| Step: 7
Training loss: 4.779553280629679
Validation loss: 4.562764147075183

Epoch: 5| Step: 8
Training loss: 4.926494452977172
Validation loss: 4.557924920544903

Epoch: 5| Step: 9
Training loss: 4.38389533227035
Validation loss: 4.552515278566612

Epoch: 5| Step: 10
Training loss: 4.337056003679539
Validation loss: 4.5477221247114565

Epoch: 5| Step: 11
Training loss: 3.0842905019454028
Validation loss: 4.542769825965349

Epoch: 21| Step: 0
Training loss: 4.31776659488675
Validation loss: 4.538383901517242

Epoch: 5| Step: 1
Training loss: 4.606149974135505
Validation loss: 4.533412250832313

Epoch: 5| Step: 2
Training loss: 5.132196537491377
Validation loss: 4.528120358826492

Epoch: 5| Step: 3
Training loss: 3.728072078613803
Validation loss: 4.523773690370984

Epoch: 5| Step: 4
Training loss: 4.784279455704727
Validation loss: 4.517641367499169

Epoch: 5| Step: 5
Training loss: 4.642077697051072
Validation loss: 4.513060909855649

Epoch: 5| Step: 6
Training loss: 4.861537439936797
Validation loss: 4.507366596912978

Epoch: 5| Step: 7
Training loss: 4.534374133477368
Validation loss: 4.502282561566476

Epoch: 5| Step: 8
Training loss: 5.454590696089418
Validation loss: 4.497219250836228

Epoch: 5| Step: 9
Training loss: 4.647009981371653
Validation loss: 4.491825263857041

Epoch: 5| Step: 10
Training loss: 4.243512531541138
Validation loss: 4.486466649902987

Epoch: 5| Step: 11
Training loss: 3.9337203034818566
Validation loss: 4.481673141144747

Epoch: 22| Step: 0
Training loss: 4.755005257299748
Validation loss: 4.476267726706499

Epoch: 5| Step: 1
Training loss: 4.826722567921287
Validation loss: 4.470482479287393

Epoch: 5| Step: 2
Training loss: 4.282816134050812
Validation loss: 4.46611689195811

Epoch: 5| Step: 3
Training loss: 4.271654276527855
Validation loss: 4.46034091538888

Epoch: 5| Step: 4
Training loss: 4.121793714622715
Validation loss: 4.454545210634542

Epoch: 5| Step: 5
Training loss: 4.045009109241617
Validation loss: 4.449332678153695

Epoch: 5| Step: 6
Training loss: 4.700301935764714
Validation loss: 4.445312061991388

Epoch: 5| Step: 7
Training loss: 4.636637711881341
Validation loss: 4.44046447127291

Epoch: 5| Step: 8
Training loss: 4.908667873689302
Validation loss: 4.435066119822553

Epoch: 5| Step: 9
Training loss: 4.53768001651185
Validation loss: 4.430636739867299

Epoch: 5| Step: 10
Training loss: 4.615552996962925
Validation loss: 4.425912561626259

Epoch: 5| Step: 11
Training loss: 6.844395715917107
Validation loss: 4.420739413362443

Epoch: 23| Step: 0
Training loss: 4.504281020969844
Validation loss: 4.4157700378254745

Epoch: 5| Step: 1
Training loss: 4.530108288276962
Validation loss: 4.410146262171934

Epoch: 5| Step: 2
Training loss: 5.117054245939141
Validation loss: 4.405480013185388

Epoch: 5| Step: 3
Training loss: 5.530024505892049
Validation loss: 4.399124579691079

Epoch: 5| Step: 4
Training loss: 3.3192237415302226
Validation loss: 4.393778744165373

Epoch: 5| Step: 5
Training loss: 4.310655724724443
Validation loss: 4.389879020770543

Epoch: 5| Step: 6
Training loss: 5.131698139057409
Validation loss: 4.384679395568345

Epoch: 5| Step: 7
Training loss: 3.899214611689474
Validation loss: 4.378662982845228

Epoch: 5| Step: 8
Training loss: 4.014119025426746
Validation loss: 4.372930727653317

Epoch: 5| Step: 9
Training loss: 4.089862637626516
Validation loss: 4.368002909248906

Epoch: 5| Step: 10
Training loss: 4.114822316371935
Validation loss: 4.363621601979256

Epoch: 5| Step: 11
Training loss: 7.15100278424729
Validation loss: 4.358528911926318

Epoch: 24| Step: 0
Training loss: 4.363500686905974
Validation loss: 4.353634918937901

Epoch: 5| Step: 1
Training loss: 4.213941079704102
Validation loss: 4.348096214624286

Epoch: 5| Step: 2
Training loss: 4.053248273141025
Validation loss: 4.343055170961455

Epoch: 5| Step: 3
Training loss: 5.121249245291374
Validation loss: 4.33954358142966

Epoch: 5| Step: 4
Training loss: 4.390765313455252
Validation loss: 4.333580710001352

Epoch: 5| Step: 5
Training loss: 4.367255194997473
Validation loss: 4.328947014448336

Epoch: 5| Step: 6
Training loss: 4.875580190710119
Validation loss: 4.324363763497527

Epoch: 5| Step: 7
Training loss: 4.654197701419277
Validation loss: 4.31944035699916

Epoch: 5| Step: 8
Training loss: 4.5059842479716625
Validation loss: 4.314053195868267

Epoch: 5| Step: 9
Training loss: 4.100963032829101
Validation loss: 4.309255835582434

Epoch: 5| Step: 10
Training loss: 4.299661516573658
Validation loss: 4.305132935746214

Epoch: 5| Step: 11
Training loss: 4.3514106217184
Validation loss: 4.300265640178305

Epoch: 25| Step: 0
Training loss: 3.9535136276826544
Validation loss: 4.296217994167463

Epoch: 5| Step: 1
Training loss: 4.172045300611733
Validation loss: 4.290597234581936

Epoch: 5| Step: 2
Training loss: 3.770496304170148
Validation loss: 4.285382306868813

Epoch: 5| Step: 3
Training loss: 4.772246816322823
Validation loss: 4.280911889380543

Epoch: 5| Step: 4
Training loss: 4.632649873963747
Validation loss: 4.276695004855189

Epoch: 5| Step: 5
Training loss: 5.173247647870367
Validation loss: 4.271442847449025

Epoch: 5| Step: 6
Training loss: 4.972848413534655
Validation loss: 4.267042634773192

Epoch: 5| Step: 7
Training loss: 3.98960551097207
Validation loss: 4.262475962491838

Epoch: 5| Step: 8
Training loss: 3.967511802420221
Validation loss: 4.257673586757918

Epoch: 5| Step: 9
Training loss: 4.233991880082033
Validation loss: 4.2536438439793764

Epoch: 5| Step: 10
Training loss: 4.604155297358818
Validation loss: 4.24883040995991

Epoch: 5| Step: 11
Training loss: 4.032126634486224
Validation loss: 4.2433596888940075

Epoch: 26| Step: 0
Training loss: 3.972742670520188
Validation loss: 4.2388292793322835

Epoch: 5| Step: 1
Training loss: 4.665392202099848
Validation loss: 4.235196126639773

Epoch: 5| Step: 2
Training loss: 4.501545322839602
Validation loss: 4.230560686844867

Epoch: 5| Step: 3
Training loss: 4.445654884387026
Validation loss: 4.2260516334487

Epoch: 5| Step: 4
Training loss: 4.213210927134829
Validation loss: 4.221587284279033

Epoch: 5| Step: 5
Training loss: 3.7490144070205775
Validation loss: 4.218065941064101

Epoch: 5| Step: 6
Training loss: 4.51104609771968
Validation loss: 4.212880636388179

Epoch: 5| Step: 7
Training loss: 4.865488407910327
Validation loss: 4.208744825256689

Epoch: 5| Step: 8
Training loss: 4.1083075583824895
Validation loss: 4.203759099500723

Epoch: 5| Step: 9
Training loss: 4.595553712243949
Validation loss: 4.199528839727187

Epoch: 5| Step: 10
Training loss: 4.3781214886255775
Validation loss: 4.1952069421390075

Epoch: 5| Step: 11
Training loss: 2.354044874523583
Validation loss: 4.190325139843345

Epoch: 27| Step: 0
Training loss: 4.041894860396544
Validation loss: 4.186146693017631

Epoch: 5| Step: 1
Training loss: 4.54911911370689
Validation loss: 4.182016350158833

Epoch: 5| Step: 2
Training loss: 4.58740647555861
Validation loss: 4.177706677483377

Epoch: 5| Step: 3
Training loss: 3.983650889700394
Validation loss: 4.173849460117076

Epoch: 5| Step: 4
Training loss: 4.96037940543112
Validation loss: 4.169167200627669

Epoch: 5| Step: 5
Training loss: 4.357454704184937
Validation loss: 4.164607491295142

Epoch: 5| Step: 6
Training loss: 3.7980125198921244
Validation loss: 4.160542721176665

Epoch: 5| Step: 7
Training loss: 4.781954046535143
Validation loss: 4.155910683646324

Epoch: 5| Step: 8
Training loss: 4.6824716682615675
Validation loss: 4.1518173673627325

Epoch: 5| Step: 9
Training loss: 3.696097228137895
Validation loss: 4.147024077912589

Epoch: 5| Step: 10
Training loss: 3.658880738221835
Validation loss: 4.142604676119141

Epoch: 5| Step: 11
Training loss: 3.833318309478067
Validation loss: 4.138103235415383

Epoch: 28| Step: 0
Training loss: 4.166778766395684
Validation loss: 4.134407788389579

Epoch: 5| Step: 1
Training loss: 4.5769756033015705
Validation loss: 4.129006342785922

Epoch: 5| Step: 2
Training loss: 4.41007796860883
Validation loss: 4.124305522141003

Epoch: 5| Step: 3
Training loss: 5.151063287096258
Validation loss: 4.120396251017759

Epoch: 5| Step: 4
Training loss: 4.78721416207733
Validation loss: 4.116213693614081

Epoch: 5| Step: 5
Training loss: 4.544157389305984
Validation loss: 4.111195706057021

Epoch: 5| Step: 6
Training loss: 4.032271381479238
Validation loss: 4.10617450875032

Epoch: 5| Step: 7
Training loss: 4.278683303727752
Validation loss: 4.102026089097235

Epoch: 5| Step: 8
Training loss: 3.89832814890786
Validation loss: 4.097193684272016

Epoch: 5| Step: 9
Training loss: 3.477087774134856
Validation loss: 4.092833671226715

Epoch: 5| Step: 10
Training loss: 3.2226738576697014
Validation loss: 4.087970585230132

Epoch: 5| Step: 11
Training loss: 2.9143673325711217
Validation loss: 4.083605969662942

Epoch: 29| Step: 0
Training loss: 4.127715170858847
Validation loss: 4.079747273184883

Epoch: 5| Step: 1
Training loss: 3.7103439338205253
Validation loss: 4.075781591034067

Epoch: 5| Step: 2
Training loss: 4.399312936719272
Validation loss: 4.070933826003971

Epoch: 5| Step: 3
Training loss: 4.662100783533139
Validation loss: 4.066600168315029

Epoch: 5| Step: 4
Training loss: 4.048950841196854
Validation loss: 4.062322857246925

Epoch: 5| Step: 5
Training loss: 4.511832469481332
Validation loss: 4.057664732457483

Epoch: 5| Step: 6
Training loss: 4.248854987790875
Validation loss: 4.053150490842654

Epoch: 5| Step: 7
Training loss: 4.1318173571506716
Validation loss: 4.048962097846655

Epoch: 5| Step: 8
Training loss: 4.222837827097418
Validation loss: 4.044082566804423

Epoch: 5| Step: 9
Training loss: 4.063377637697251
Validation loss: 4.039842315105044

Epoch: 5| Step: 10
Training loss: 3.96987214331766
Validation loss: 4.035161375649992

Epoch: 5| Step: 11
Training loss: 3.737501168649548
Validation loss: 4.0310997158692325

Epoch: 30| Step: 0
Training loss: 4.945671948330966
Validation loss: 4.0267099399141415

Epoch: 5| Step: 1
Training loss: 3.472376946286865
Validation loss: 4.022029642739774

Epoch: 5| Step: 2
Training loss: 3.9352742519563173
Validation loss: 4.017905180406765

Epoch: 5| Step: 3
Training loss: 3.868358827698954
Validation loss: 4.012958650728153

Epoch: 5| Step: 4
Training loss: 4.1581726216442245
Validation loss: 4.008352152858869

Epoch: 5| Step: 5
Training loss: 4.368137099423546
Validation loss: 4.003769839064265

Epoch: 5| Step: 6
Training loss: 3.470791190365906
Validation loss: 3.9998980449557577

Epoch: 5| Step: 7
Training loss: 4.460106018927492
Validation loss: 3.995552516068764

Epoch: 5| Step: 8
Training loss: 4.634668502722385
Validation loss: 3.9909064022174174

Epoch: 5| Step: 9
Training loss: 4.285008917390854
Validation loss: 3.9865088340099697

Epoch: 5| Step: 10
Training loss: 3.6167901564462657
Validation loss: 3.9818124346891537

Epoch: 5| Step: 11
Training loss: 4.158975037705542
Validation loss: 3.9774322607816655

Epoch: 31| Step: 0
Training loss: 4.175851134383648
Validation loss: 3.9727347687220087

Epoch: 5| Step: 1
Training loss: 3.9689612144676145
Validation loss: 3.967851396890628

Epoch: 5| Step: 2
Training loss: 3.707373648488487
Validation loss: 3.9634490618454024

Epoch: 5| Step: 3
Training loss: 3.8108969898581058
Validation loss: 3.9587128289993747

Epoch: 5| Step: 4
Training loss: 4.411993085148529
Validation loss: 3.954054988185756

Epoch: 5| Step: 5
Training loss: 3.794276725993122
Validation loss: 3.9504170044758458

Epoch: 5| Step: 6
Training loss: 4.452905910523333
Validation loss: 3.945356302049675

Epoch: 5| Step: 7
Training loss: 3.5756771593401924
Validation loss: 3.94097420649915

Epoch: 5| Step: 8
Training loss: 4.148329451423648
Validation loss: 3.9367795820028553

Epoch: 5| Step: 9
Training loss: 4.4706920325332025
Validation loss: 3.9319368753944652

Epoch: 5| Step: 10
Training loss: 4.07216281532392
Validation loss: 3.927892873010868

Epoch: 5| Step: 11
Training loss: 4.994739435404803
Validation loss: 3.922567146898429

Epoch: 32| Step: 0
Training loss: 3.7235497025949997
Validation loss: 3.918709423457432

Epoch: 5| Step: 1
Training loss: 4.051884323502452
Validation loss: 3.913902822601614

Epoch: 5| Step: 2
Training loss: 3.7813885876188036
Validation loss: 3.90931669273571

Epoch: 5| Step: 3
Training loss: 4.0951081563712
Validation loss: 3.904400135714741

Epoch: 5| Step: 4
Training loss: 4.151404287979654
Validation loss: 3.8998591519867065

Epoch: 5| Step: 5
Training loss: 3.890244553437081
Validation loss: 3.895690510761684

Epoch: 5| Step: 6
Training loss: 4.175296594740634
Validation loss: 3.8906972640959627

Epoch: 5| Step: 7
Training loss: 4.0269274343806565
Validation loss: 3.886264476714395

Epoch: 5| Step: 8
Training loss: 3.6013641633803535
Validation loss: 3.8814745260134336

Epoch: 5| Step: 9
Training loss: 4.661753020393136
Validation loss: 3.8771898737062025

Epoch: 5| Step: 10
Training loss: 3.899862208744353
Validation loss: 3.872371474264047

Epoch: 5| Step: 11
Training loss: 4.752308334828175
Validation loss: 3.867822452398907

Epoch: 33| Step: 0
Training loss: 4.3350431052488085
Validation loss: 3.86331753766767

Epoch: 5| Step: 1
Training loss: 3.9231600536842404
Validation loss: 3.858765166540876

Epoch: 5| Step: 2
Training loss: 2.8602268638532014
Validation loss: 3.8537650165395214

Epoch: 5| Step: 3
Training loss: 3.579944131511162
Validation loss: 3.8493758075422364

Epoch: 5| Step: 4
Training loss: 3.960217653130754
Validation loss: 3.8447187179938864

Epoch: 5| Step: 5
Training loss: 4.939251552826563
Validation loss: 3.8402597196237567

Epoch: 5| Step: 6
Training loss: 3.505367795010375
Validation loss: 3.8356057701480375

Epoch: 5| Step: 7
Training loss: 4.495975390085221
Validation loss: 3.8313265485309085

Epoch: 5| Step: 8
Training loss: 3.34405829888955
Validation loss: 3.8270918846900077

Epoch: 5| Step: 9
Training loss: 4.769341892291985
Validation loss: 3.8222502960069233

Epoch: 5| Step: 10
Training loss: 3.7959030854020295
Validation loss: 3.8178180125442527

Epoch: 5| Step: 11
Training loss: 2.0998897205642715
Validation loss: 3.8131980778031083

Epoch: 34| Step: 0
Training loss: 4.226294433215753
Validation loss: 3.8090822294584243

Epoch: 5| Step: 1
Training loss: 3.317223977145767
Validation loss: 3.804721234202722

Epoch: 5| Step: 2
Training loss: 4.731605046807027
Validation loss: 3.8003591974212165

Epoch: 5| Step: 3
Training loss: 3.405345411664094
Validation loss: 3.7963458609554466

Epoch: 5| Step: 4
Training loss: 3.82859506640427
Validation loss: 3.7919115347270895

Epoch: 5| Step: 5
Training loss: 4.195072216917293
Validation loss: 3.7874588551820145

Epoch: 5| Step: 6
Training loss: 4.277829328174083
Validation loss: 3.7833350924489193

Epoch: 5| Step: 7
Training loss: 4.0755080672806585
Validation loss: 3.7788622912666336

Epoch: 5| Step: 8
Training loss: 3.5856779249732713
Validation loss: 3.7743676186451665

Epoch: 5| Step: 9
Training loss: 3.6522167163319046
Validation loss: 3.769692088436385

Epoch: 5| Step: 10
Training loss: 3.6280701888590974
Validation loss: 3.76541982912268

Epoch: 5| Step: 11
Training loss: 3.876031061636566
Validation loss: 3.76097959530005

Epoch: 35| Step: 0
Training loss: 4.14496152264046
Validation loss: 3.7563542836587542

Epoch: 5| Step: 1
Training loss: 3.7486562228581124
Validation loss: 3.7518513771782223

Epoch: 5| Step: 2
Training loss: 3.891280276103846
Validation loss: 3.747395972949307

Epoch: 5| Step: 3
Training loss: 3.3346832561921707
Validation loss: 3.743346887494892

Epoch: 5| Step: 4
Training loss: 4.1803913415119975
Validation loss: 3.7387939919966096

Epoch: 5| Step: 5
Training loss: 3.6105751585396844
Validation loss: 3.7340278570545533

Epoch: 5| Step: 6
Training loss: 3.3191325166595824
Validation loss: 3.729569267760962

Epoch: 5| Step: 7
Training loss: 4.774448518712597
Validation loss: 3.7251721180230564

Epoch: 5| Step: 8
Training loss: 3.1181455588336826
Validation loss: 3.720768137820226

Epoch: 5| Step: 9
Training loss: 3.666166762750953
Validation loss: 3.716879165708659

Epoch: 5| Step: 10
Training loss: 4.464247349165507
Validation loss: 3.7130662775203938

Epoch: 5| Step: 11
Training loss: 3.784388729105206
Validation loss: 3.708451921017029

Epoch: 36| Step: 0
Training loss: 3.7344325871197217
Validation loss: 3.7038631642417186

Epoch: 5| Step: 1
Training loss: 2.7283538792263196
Validation loss: 3.699311348905173

Epoch: 5| Step: 2
Training loss: 4.031264430766928
Validation loss: 3.695552729405281

Epoch: 5| Step: 3
Training loss: 3.4340304811932234
Validation loss: 3.690740045514208

Epoch: 5| Step: 4
Training loss: 3.7870410049349985
Validation loss: 3.6865851512063346

Epoch: 5| Step: 5
Training loss: 4.393408493726599
Validation loss: 3.682843889467642

Epoch: 5| Step: 6
Training loss: 3.4965348120000637
Validation loss: 3.678018600493584

Epoch: 5| Step: 7
Training loss: 3.769262053211643
Validation loss: 3.6735683297252413

Epoch: 5| Step: 8
Training loss: 3.7408355628131815
Validation loss: 3.6694046855235345

Epoch: 5| Step: 9
Training loss: 4.603120342596719
Validation loss: 3.6649879040676767

Epoch: 5| Step: 10
Training loss: 3.9700387379176045
Validation loss: 3.6608562363318367

Epoch: 5| Step: 11
Training loss: 3.689860994362097
Validation loss: 3.656184187728797

Epoch: 37| Step: 0
Training loss: 4.062185891552637
Validation loss: 3.6518043106099483

Epoch: 5| Step: 1
Training loss: 3.6383341511195253
Validation loss: 3.647362958553023

Epoch: 5| Step: 2
Training loss: 3.9118124458271417
Validation loss: 3.6427083473689175

Epoch: 5| Step: 3
Training loss: 3.4321416533609668
Validation loss: 3.638247372512744

Epoch: 5| Step: 4
Training loss: 4.00511938557699
Validation loss: 3.6339047119742727

Epoch: 5| Step: 5
Training loss: 3.907926154056845
Validation loss: 3.629543553712673

Epoch: 5| Step: 6
Training loss: 3.7719309071819818
Validation loss: 3.625250714500102

Epoch: 5| Step: 7
Training loss: 3.375556476069142
Validation loss: 3.621198941389737

Epoch: 5| Step: 8
Training loss: 3.361873105969297
Validation loss: 3.616559484244271

Epoch: 5| Step: 9
Training loss: 4.122121326643283
Validation loss: 3.6124425076108353

Epoch: 5| Step: 10
Training loss: 3.579441677862586
Validation loss: 3.6082831433588756

Epoch: 5| Step: 11
Training loss: 4.519201637586235
Validation loss: 3.6038900978536277

Epoch: 38| Step: 0
Training loss: 3.5500158443903267
Validation loss: 3.59955180565922

Epoch: 5| Step: 1
Training loss: 3.868027597749044
Validation loss: 3.595524551568421

Epoch: 5| Step: 2
Training loss: 3.638094698083952
Validation loss: 3.5907212860061373

Epoch: 5| Step: 3
Training loss: 3.4240902214463467
Validation loss: 3.585732093307982

Epoch: 5| Step: 4
Training loss: 3.9459200249681725
Validation loss: 3.5817440393438704

Epoch: 5| Step: 5
Training loss: 3.2674138038666363
Validation loss: 3.577418661572423

Epoch: 5| Step: 6
Training loss: 4.3370612810311915
Validation loss: 3.5731589769917984

Epoch: 5| Step: 7
Training loss: 3.0408672867441653
Validation loss: 3.568909807073298

Epoch: 5| Step: 8
Training loss: 3.6612725606414043
Validation loss: 3.5650144091560607

Epoch: 5| Step: 9
Training loss: 3.418999565541769
Validation loss: 3.560761936798296

Epoch: 5| Step: 10
Training loss: 4.498521985939759
Validation loss: 3.5565382111587027

Epoch: 5| Step: 11
Training loss: 3.4662371632241653
Validation loss: 3.552331298645225

Epoch: 39| Step: 0
Training loss: 3.665589492248633
Validation loss: 3.548067819388695

Epoch: 5| Step: 1
Training loss: 4.086125385931722
Validation loss: 3.544078491881669

Epoch: 5| Step: 2
Training loss: 2.9748794723586762
Validation loss: 3.539696642922042

Epoch: 5| Step: 3
Training loss: 4.283201789072979
Validation loss: 3.5357625985755345

Epoch: 5| Step: 4
Training loss: 3.780097344371222
Validation loss: 3.5312983866839565

Epoch: 5| Step: 5
Training loss: 3.5742108787908546
Validation loss: 3.527146979920188

Epoch: 5| Step: 6
Training loss: 3.6190090001108453
Validation loss: 3.5226513083462696

Epoch: 5| Step: 7
Training loss: 3.3411430107138473
Validation loss: 3.518545940754275

Epoch: 5| Step: 8
Training loss: 3.109693654663509
Validation loss: 3.514364686340579

Epoch: 5| Step: 9
Training loss: 3.8023930393000382
Validation loss: 3.5103950028170794

Epoch: 5| Step: 10
Training loss: 3.907921761407991
Validation loss: 3.50666333457809

Epoch: 5| Step: 11
Training loss: 3.477004531019197
Validation loss: 3.5029744724189675

Epoch: 40| Step: 0
Training loss: 3.9578875775902556
Validation loss: 3.498457642588543

Epoch: 5| Step: 1
Training loss: 4.14883518647596
Validation loss: 3.493903322443951

Epoch: 5| Step: 2
Training loss: 3.801183069675415
Validation loss: 3.4895743251323674

Epoch: 5| Step: 3
Training loss: 3.2257961443767154
Validation loss: 3.4853632655882048

Epoch: 5| Step: 4
Training loss: 2.8600881552281336
Validation loss: 3.481372548930613

Epoch: 5| Step: 5
Training loss: 3.5175042449123035
Validation loss: 3.477190076782994

Epoch: 5| Step: 6
Training loss: 3.343009652861256
Validation loss: 3.4734612394738007

Epoch: 5| Step: 7
Training loss: 3.0262669771042057
Validation loss: 3.469563529123483

Epoch: 5| Step: 8
Training loss: 3.794504815163286
Validation loss: 3.4654953668930584

Epoch: 5| Step: 9
Training loss: 3.726861777773939
Validation loss: 3.461600068724661

Epoch: 5| Step: 10
Training loss: 4.102221626726215
Validation loss: 3.4574998958198715

Epoch: 5| Step: 11
Training loss: 3.701296841970113
Validation loss: 3.453373918724418

Epoch: 41| Step: 0
Training loss: 4.020504373062956
Validation loss: 3.4496844255625074

Epoch: 5| Step: 1
Training loss: 3.3097714396506372
Validation loss: 3.4453510792620174

Epoch: 5| Step: 2
Training loss: 3.2994620491593434
Validation loss: 3.441115362348946

Epoch: 5| Step: 3
Training loss: 3.511753374890134
Validation loss: 3.437343975340935

Epoch: 5| Step: 4
Training loss: 3.890392373112571
Validation loss: 3.433645399194842

Epoch: 5| Step: 5
Training loss: 3.5918534291530544
Validation loss: 3.4296563044978

Epoch: 5| Step: 6
Training loss: 3.1960845238462228
Validation loss: 3.425487626069311

Epoch: 5| Step: 7
Training loss: 3.740537403072149
Validation loss: 3.421591765876422

Epoch: 5| Step: 8
Training loss: 3.8736849368436252
Validation loss: 3.4176525035058565

Epoch: 5| Step: 9
Training loss: 3.5940913826050824
Validation loss: 3.4138466179723066

Epoch: 5| Step: 10
Training loss: 3.1345452061817785
Validation loss: 3.4097451526279126

Epoch: 5| Step: 11
Training loss: 3.382946972013322
Validation loss: 3.4058609661558408

Epoch: 42| Step: 0
Training loss: 3.03766040770911
Validation loss: 3.401640610972797

Epoch: 5| Step: 1
Training loss: 3.312927650341016
Validation loss: 3.3980378306896637

Epoch: 5| Step: 2
Training loss: 3.538093484759408
Validation loss: 3.394090952410792

Epoch: 5| Step: 3
Training loss: 3.333769690244846
Validation loss: 3.390194796739095

Epoch: 5| Step: 4
Training loss: 3.969282219711982
Validation loss: 3.3862023199992994

Epoch: 5| Step: 5
Training loss: 3.8605468453562937
Validation loss: 3.382178704588325

Epoch: 5| Step: 6
Training loss: 3.554968921294822
Validation loss: 3.3781530345561586

Epoch: 5| Step: 7
Training loss: 3.297715789467095
Validation loss: 3.3744576571772527

Epoch: 5| Step: 8
Training loss: 3.6694200466004916
Validation loss: 3.3706307002926588

Epoch: 5| Step: 9
Training loss: 3.06762717657244
Validation loss: 3.367021189253332

Epoch: 5| Step: 10
Training loss: 3.9433886379083867
Validation loss: 3.3631744249652855

Epoch: 5| Step: 11
Training loss: 3.510786872759778
Validation loss: 3.3593529870546646

Epoch: 43| Step: 0
Training loss: 2.80118395092986
Validation loss: 3.3551757175329224

Epoch: 5| Step: 1
Training loss: 3.1832989702483765
Validation loss: 3.3515884054586262

Epoch: 5| Step: 2
Training loss: 3.5121673535073707
Validation loss: 3.347598858418883

Epoch: 5| Step: 3
Training loss: 4.0016340256047815
Validation loss: 3.343690001166314

Epoch: 5| Step: 4
Training loss: 3.7309816656958126
Validation loss: 3.339901378944929

Epoch: 5| Step: 5
Training loss: 2.9705800088003156
Validation loss: 3.3354594046630264

Epoch: 5| Step: 6
Training loss: 3.0361582551603625
Validation loss: 3.3320818975847084

Epoch: 5| Step: 7
Training loss: 4.126784198876491
Validation loss: 3.327968044490182

Epoch: 5| Step: 8
Training loss: 3.6445036434260567
Validation loss: 3.3244529399567426

Epoch: 5| Step: 9
Training loss: 3.403177117683376
Validation loss: 3.3206848175138894

Epoch: 5| Step: 10
Training loss: 3.419508163377701
Validation loss: 3.31678696698557

Epoch: 5| Step: 11
Training loss: 4.144336347104874
Validation loss: 3.3130137596940417

Epoch: 44| Step: 0
Training loss: 3.1191835824472243
Validation loss: 3.3092814619889537

Epoch: 5| Step: 1
Training loss: 2.8347303275026157
Validation loss: 3.305358632194268

Epoch: 5| Step: 2
Training loss: 3.3207803553651516
Validation loss: 3.301590152618055

Epoch: 5| Step: 3
Training loss: 3.289085406225907
Validation loss: 3.2977671508408624

Epoch: 5| Step: 4
Training loss: 3.8109087515572075
Validation loss: 3.2943570493892858

Epoch: 5| Step: 5
Training loss: 3.4941746052795035
Validation loss: 3.2906387792517955

Epoch: 5| Step: 6
Training loss: 3.983125977060392
Validation loss: 3.286787265492338

Epoch: 5| Step: 7
Training loss: 3.7528512923196975
Validation loss: 3.282785625489987

Epoch: 5| Step: 8
Training loss: 3.5967423958947573
Validation loss: 3.2789693505631887

Epoch: 5| Step: 9
Training loss: 3.0086104486398764
Validation loss: 3.2748955367805173

Epoch: 5| Step: 10
Training loss: 3.4791835548463075
Validation loss: 3.271203989947535

Epoch: 5| Step: 11
Training loss: 2.689492130481492
Validation loss: 3.2675859747999674

Epoch: 45| Step: 0
Training loss: 4.118196599016299
Validation loss: 3.264029114441229

Epoch: 5| Step: 1
Training loss: 3.24903561882485
Validation loss: 3.260186279655863

Epoch: 5| Step: 2
Training loss: 3.543264425067611
Validation loss: 3.2566183266294417

Epoch: 5| Step: 3
Training loss: 3.7532889883788116
Validation loss: 3.253108268301447

Epoch: 5| Step: 4
Training loss: 3.1906810669638452
Validation loss: 3.2493060178014255

Epoch: 5| Step: 5
Training loss: 3.131524408617173
Validation loss: 3.2457149084096666

Epoch: 5| Step: 6
Training loss: 3.3330809179738976
Validation loss: 3.2421569271254786

Epoch: 5| Step: 7
Training loss: 3.6843185925230375
Validation loss: 3.238565893359695

Epoch: 5| Step: 8
Training loss: 2.930789668980234
Validation loss: 3.234654437539155

Epoch: 5| Step: 9
Training loss: 3.4297792600552413
Validation loss: 3.231116442499597

Epoch: 5| Step: 10
Training loss: 2.9421825017901817
Validation loss: 3.2275375789421545

Epoch: 5| Step: 11
Training loss: 1.9720090503136751
Validation loss: 3.2240322620171473

Epoch: 46| Step: 0
Training loss: 3.3679483001166006
Validation loss: 3.220907722607652

Epoch: 5| Step: 1
Training loss: 3.4717311935788966
Validation loss: 3.218001047052435

Epoch: 5| Step: 2
Training loss: 3.430968720905302
Validation loss: 3.2149576234175288

Epoch: 5| Step: 3
Training loss: 3.801757059947267
Validation loss: 3.212082002215337

Epoch: 5| Step: 4
Training loss: 3.22486799694457
Validation loss: 3.2085823771601287

Epoch: 5| Step: 5
Training loss: 3.6475712730132397
Validation loss: 3.205371589870965

Epoch: 5| Step: 6
Training loss: 3.099815049345513
Validation loss: 3.201975977671322

Epoch: 5| Step: 7
Training loss: 3.3346337801646135
Validation loss: 3.198798338701358

Epoch: 5| Step: 8
Training loss: 3.3121598266977292
Validation loss: 3.1956414548491416

Epoch: 5| Step: 9
Training loss: 2.8644730610285722
Validation loss: 3.192168917783134

Epoch: 5| Step: 10
Training loss: 3.3192014742734206
Validation loss: 3.1888475499222446

Epoch: 5| Step: 11
Training loss: 2.48853697128992
Validation loss: 3.1856671218427355

Epoch: 47| Step: 0
Training loss: 2.8286997174266535
Validation loss: 3.182340260502499

Epoch: 5| Step: 1
Training loss: 3.3828003775223037
Validation loss: 3.1791052507806943

Epoch: 5| Step: 2
Training loss: 3.269460369695401
Validation loss: 3.175687706427136

Epoch: 5| Step: 3
Training loss: 3.683662357277979
Validation loss: 3.172598626287386

Epoch: 5| Step: 4
Training loss: 3.77374215801545
Validation loss: 3.168991463143416

Epoch: 5| Step: 5
Training loss: 3.5386895326375325
Validation loss: 3.1652027728474796

Epoch: 5| Step: 6
Training loss: 3.4477053267294315
Validation loss: 3.162373441242047

Epoch: 5| Step: 7
Training loss: 3.491906481195206
Validation loss: 3.158192814055412

Epoch: 5| Step: 8
Training loss: 3.3650935271417244
Validation loss: 3.1550487492226433

Epoch: 5| Step: 9
Training loss: 2.597443031222351
Validation loss: 3.1514726307301015

Epoch: 5| Step: 10
Training loss: 3.0770351591236973
Validation loss: 3.1482997387705347

Epoch: 5| Step: 11
Training loss: 1.5438447807343627
Validation loss: 3.1453369561634434

Epoch: 48| Step: 0
Training loss: 4.122849568570684
Validation loss: 3.142540355555771

Epoch: 5| Step: 1
Training loss: 2.6071319990435873
Validation loss: 3.139385889920351

Epoch: 5| Step: 2
Training loss: 3.7645982790919263
Validation loss: 3.137129779265296

Epoch: 5| Step: 3
Training loss: 3.0107990448835795
Validation loss: 3.133511187108414

Epoch: 5| Step: 4
Training loss: 3.025355634985687
Validation loss: 3.130699186933026

Epoch: 5| Step: 5
Training loss: 3.0199815974401156
Validation loss: 3.127839514998443

Epoch: 5| Step: 6
Training loss: 3.18542098516384
Validation loss: 3.1247269002472264

Epoch: 5| Step: 7
Training loss: 3.2808860940318727
Validation loss: 3.1217733446180467

Epoch: 5| Step: 8
Training loss: 3.562136982943512
Validation loss: 3.118572720857588

Epoch: 5| Step: 9
Training loss: 3.160576904365436
Validation loss: 3.1149581994037567

Epoch: 5| Step: 10
Training loss: 3.1015143787100543
Validation loss: 3.1117334095894273

Epoch: 5| Step: 11
Training loss: 2.5066552269789555
Validation loss: 3.1087773737554154

Epoch: 49| Step: 0
Training loss: 3.005834469063078
Validation loss: 3.1059697001050464

Epoch: 5| Step: 1
Training loss: 2.762639648912328
Validation loss: 3.102996821219623

Epoch: 5| Step: 2
Training loss: 3.234498542232188
Validation loss: 3.0998460967304684

Epoch: 5| Step: 3
Training loss: 3.4848858240763274
Validation loss: 3.0971888814556197

Epoch: 5| Step: 4
Training loss: 2.9457971796373847
Validation loss: 3.093094843071692

Epoch: 5| Step: 5
Training loss: 2.9154808540324
Validation loss: 3.0912505691554535

Epoch: 5| Step: 6
Training loss: 3.176475158181155
Validation loss: 3.0886386558052465

Epoch: 5| Step: 7
Training loss: 3.1882142407405496
Validation loss: 3.0851042576241676

Epoch: 5| Step: 8
Training loss: 3.7703617426300204
Validation loss: 3.0819241529712342

Epoch: 5| Step: 9
Training loss: 3.405746842765451
Validation loss: 3.079118903817318

Epoch: 5| Step: 10
Training loss: 3.4089904400441635
Validation loss: 3.075725904965921

Epoch: 5| Step: 11
Training loss: 3.7832105613875675
Validation loss: 3.0728584973707935

Epoch: 50| Step: 0
Training loss: 3.1604737074014366
Validation loss: 3.0694905831871444

Epoch: 5| Step: 1
Training loss: 3.635081380486719
Validation loss: 3.0665822393692412

Epoch: 5| Step: 2
Training loss: 2.7878109129897015
Validation loss: 3.0630910264181925

Epoch: 5| Step: 3
Training loss: 3.1102324410568327
Validation loss: 3.0602378015637863

Epoch: 5| Step: 4
Training loss: 3.4092019265333793
Validation loss: 3.0571041807864443

Epoch: 5| Step: 5
Training loss: 2.8478893294530425
Validation loss: 3.0537096687804666

Epoch: 5| Step: 6
Training loss: 3.2861284593210396
Validation loss: 3.0504615476158805

Epoch: 5| Step: 7
Training loss: 3.5903693178674643
Validation loss: 3.047429345719838

Epoch: 5| Step: 8
Training loss: 3.5673813421756484
Validation loss: 3.0444603048752197

Epoch: 5| Step: 9
Training loss: 2.8380005113575684
Validation loss: 3.041113859830534

Epoch: 5| Step: 10
Training loss: 2.6550228201250023
Validation loss: 3.0380310426398034

Epoch: 5| Step: 11
Training loss: 3.570233166771087
Validation loss: 3.033926251036688

Epoch: 51| Step: 0
Training loss: 2.726303394324721
Validation loss: 3.0339455302920344

Epoch: 5| Step: 1
Training loss: 3.0496764777526026
Validation loss: 3.0333858057520957

Epoch: 5| Step: 2
Training loss: 3.4717056466592755
Validation loss: 3.0251399495194797

Epoch: 5| Step: 3
Training loss: 3.408904694759967
Validation loss: 3.0233132191430188

Epoch: 5| Step: 4
Training loss: 3.494210222808118
Validation loss: 3.02266884429193

Epoch: 5| Step: 5
Training loss: 3.530354208965338
Validation loss: 3.023733628890889

Epoch: 5| Step: 6
Training loss: 2.9804092341289072
Validation loss: 3.029403415743679

Epoch: 5| Step: 7
Training loss: 3.0585708324991514
Validation loss: 3.0246133218271725

Epoch: 5| Step: 8
Training loss: 2.7661265979793086
Validation loss: 3.0152691646011482

Epoch: 5| Step: 9
Training loss: 2.877580396919409
Validation loss: 3.007074617314473

Epoch: 5| Step: 10
Training loss: 3.1366479088941617
Validation loss: 3.003425999593833

Epoch: 5| Step: 11
Training loss: 3.8486106347289826
Validation loss: 3.000382508290629

Epoch: 52| Step: 0
Training loss: 3.147332918248563
Validation loss: 2.997231888561514

Epoch: 5| Step: 1
Training loss: 2.4986792890534546
Validation loss: 2.99500993458454

Epoch: 5| Step: 2
Training loss: 2.9976010267526227
Validation loss: 2.9922446468729382

Epoch: 5| Step: 3
Training loss: 2.84874646911804
Validation loss: 2.990894320381584

Epoch: 5| Step: 4
Training loss: 3.0482786417775984
Validation loss: 2.986674496389951

Epoch: 5| Step: 5
Training loss: 3.0593348125432853
Validation loss: 2.9838059367133276

Epoch: 5| Step: 6
Training loss: 3.247703768098289
Validation loss: 2.9806493668597738

Epoch: 5| Step: 7
Training loss: 3.1625558539121124
Validation loss: 2.9787085131948268

Epoch: 5| Step: 8
Training loss: 3.151881301029404
Validation loss: 2.9760409421366893

Epoch: 5| Step: 9
Training loss: 3.366068288925227
Validation loss: 2.9748483362728044

Epoch: 5| Step: 10
Training loss: 3.652809154212967
Validation loss: 2.9727880020118658

Epoch: 5| Step: 11
Training loss: 3.6033838263498934
Validation loss: 2.9710508900006087

Epoch: 53| Step: 0
Training loss: 3.5582868860386303
Validation loss: 2.9679449194433167

Epoch: 5| Step: 1
Training loss: 3.090172442713838
Validation loss: 2.9648923438524917

Epoch: 5| Step: 2
Training loss: 2.466912080395721
Validation loss: 2.9611092268532424

Epoch: 5| Step: 3
Training loss: 3.1839359778192855
Validation loss: 2.9584854024209224

Epoch: 5| Step: 4
Training loss: 2.838786058083514
Validation loss: 2.9556125074490827

Epoch: 5| Step: 5
Training loss: 2.7178608108934013
Validation loss: 2.952780637897204

Epoch: 5| Step: 6
Training loss: 3.0071786187786147
Validation loss: 2.949624999910117

Epoch: 5| Step: 7
Training loss: 3.294651818641706
Validation loss: 2.9463869895588077

Epoch: 5| Step: 8
Training loss: 3.0688137444054115
Validation loss: 2.944343100434168

Epoch: 5| Step: 9
Training loss: 3.5841200800261808
Validation loss: 2.9418230609997207

Epoch: 5| Step: 10
Training loss: 3.0098457895107753
Validation loss: 2.9394451897430613

Epoch: 5| Step: 11
Training loss: 3.2849427288758974
Validation loss: 2.936179046683001

Epoch: 54| Step: 0
Training loss: 2.771971409098385
Validation loss: 2.932534068349555

Epoch: 5| Step: 1
Training loss: 3.1440856997042816
Validation loss: 2.9314911711276452

Epoch: 5| Step: 2
Training loss: 2.91623473829322
Validation loss: 2.9300423369099287

Epoch: 5| Step: 3
Training loss: 2.580665492642976
Validation loss: 2.9271107408772177

Epoch: 5| Step: 4
Training loss: 3.313832141112862
Validation loss: 2.924927305475676

Epoch: 5| Step: 5
Training loss: 3.0912462371914335
Validation loss: 2.9228362713826006

Epoch: 5| Step: 6
Training loss: 3.481364775979411
Validation loss: 2.919372251701654

Epoch: 5| Step: 7
Training loss: 3.0538831661637165
Validation loss: 2.915731839958113

Epoch: 5| Step: 8
Training loss: 3.2371774225550407
Validation loss: 2.9137319082415525

Epoch: 5| Step: 9
Training loss: 2.821315259537858
Validation loss: 2.91192607955198

Epoch: 5| Step: 10
Training loss: 3.1047405420772547
Validation loss: 2.909273748551505

Epoch: 5| Step: 11
Training loss: 3.463593920932576
Validation loss: 2.9070368662076556

Epoch: 55| Step: 0
Training loss: 3.048094207188885
Validation loss: 2.9050912871547117

Epoch: 5| Step: 1
Training loss: 3.711951316078514
Validation loss: 2.902599434695017

Epoch: 5| Step: 2
Training loss: 3.0046431849123345
Validation loss: 2.8996883274179557

Epoch: 5| Step: 3
Training loss: 2.680086067298026
Validation loss: 2.8977623501919463

Epoch: 5| Step: 4
Training loss: 3.213939145493053
Validation loss: 2.8956253036497768

Epoch: 5| Step: 5
Training loss: 2.888938287981018
Validation loss: 2.8929344780265707

Epoch: 5| Step: 6
Training loss: 3.078716860185098
Validation loss: 2.8893833277287535

Epoch: 5| Step: 7
Training loss: 2.5048717714181614
Validation loss: 2.888739560365761

Epoch: 5| Step: 8
Training loss: 2.928134679625643
Validation loss: 2.8848223068326595

Epoch: 5| Step: 9
Training loss: 2.9509846030195246
Validation loss: 2.8841434669627013

Epoch: 5| Step: 10
Training loss: 3.3952649972948308
Validation loss: 2.8808943372426064

Epoch: 5| Step: 11
Training loss: 1.963431971662268
Validation loss: 2.87915325097263

Epoch: 56| Step: 0
Training loss: 2.581267135600186
Validation loss: 2.8768851726903795

Epoch: 5| Step: 1
Training loss: 3.0055449422326515
Validation loss: 2.875873947687648

Epoch: 5| Step: 2
Training loss: 3.318552210314463
Validation loss: 2.874051531923224

Epoch: 5| Step: 3
Training loss: 2.819819018866959
Validation loss: 2.8734377472604105

Epoch: 5| Step: 4
Training loss: 3.246837250799416
Validation loss: 2.8710132163726936

Epoch: 5| Step: 5
Training loss: 2.8715245345401144
Validation loss: 2.8687654530836895

Epoch: 5| Step: 6
Training loss: 3.3946554251237733
Validation loss: 2.866264970953542

Epoch: 5| Step: 7
Training loss: 3.223775551359305
Validation loss: 2.863136822161818

Epoch: 5| Step: 8
Training loss: 2.6507773176996605
Validation loss: 2.8599583355607545

Epoch: 5| Step: 9
Training loss: 2.683275495423155
Validation loss: 2.8577393298743736

Epoch: 5| Step: 10
Training loss: 3.194404454372557
Validation loss: 2.8557837399941848

Epoch: 5| Step: 11
Training loss: 2.9103969397635203
Validation loss: 2.8534601351064026

Epoch: 57| Step: 0
Training loss: 2.81114062200376
Validation loss: 2.8517009475055066

Epoch: 5| Step: 1
Training loss: 3.118248627445136
Validation loss: 2.8493645893857

Epoch: 5| Step: 2
Training loss: 2.951234888783747
Validation loss: 2.8461938634314174

Epoch: 5| Step: 3
Training loss: 3.183891497771254
Validation loss: 2.8465950571068146

Epoch: 5| Step: 4
Training loss: 3.0137914904567
Validation loss: 2.845867524888793

Epoch: 5| Step: 5
Training loss: 2.8747726018786612
Validation loss: 2.8393944057288754

Epoch: 5| Step: 6
Training loss: 2.9992334658119377
Validation loss: 2.836949464770768

Epoch: 5| Step: 7
Training loss: 3.0431965851605147
Validation loss: 2.8344802440155132

Epoch: 5| Step: 8
Training loss: 3.0645673352482414
Validation loss: 2.8337140154814944

Epoch: 5| Step: 9
Training loss: 2.947520432729005
Validation loss: 2.832499315890807

Epoch: 5| Step: 10
Training loss: 2.829483296163206
Validation loss: 2.830192095012973

Epoch: 5| Step: 11
Training loss: 2.801219783485513
Validation loss: 2.828200766038531

Epoch: 58| Step: 0
Training loss: 2.6419984755529704
Validation loss: 2.827790590048841

Epoch: 5| Step: 1
Training loss: 3.344367567413061
Validation loss: 2.8253721921764186

Epoch: 5| Step: 2
Training loss: 2.919748766816783
Validation loss: 2.8245322412710436

Epoch: 5| Step: 3
Training loss: 3.042338588824441
Validation loss: 2.8218358012842697

Epoch: 5| Step: 4
Training loss: 2.987765957154925
Validation loss: 2.8197906518564886

Epoch: 5| Step: 5
Training loss: 2.938779836200592
Validation loss: 2.8167770818835676

Epoch: 5| Step: 6
Training loss: 2.8411197445537324
Validation loss: 2.813872267474304

Epoch: 5| Step: 7
Training loss: 3.1413456483814355
Validation loss: 2.812183567189485

Epoch: 5| Step: 8
Training loss: 3.2022275086017395
Validation loss: 2.809206227744734

Epoch: 5| Step: 9
Training loss: 2.943909976443209
Validation loss: 2.8071747415193147

Epoch: 5| Step: 10
Training loss: 2.65391527679139
Validation loss: 2.8048990571858274

Epoch: 5| Step: 11
Training loss: 1.6854810292984974
Validation loss: 2.8060993406185317

Epoch: 59| Step: 0
Training loss: 2.582979106202726
Validation loss: 2.806636197080683

Epoch: 5| Step: 1
Training loss: 3.307469705109894
Validation loss: 2.8036880642817024

Epoch: 5| Step: 2
Training loss: 3.0946715552562454
Validation loss: 2.796759082658161

Epoch: 5| Step: 3
Training loss: 2.61856917164381
Validation loss: 2.7933997330781697

Epoch: 5| Step: 4
Training loss: 2.834113256782535
Validation loss: 2.791145362623806

Epoch: 5| Step: 5
Training loss: 2.7803270330110346
Validation loss: 2.7905548939828684

Epoch: 5| Step: 6
Training loss: 2.8761907682325445
Validation loss: 2.7905505295371804

Epoch: 5| Step: 7
Training loss: 3.1065777795652054
Validation loss: 2.7904906832561065

Epoch: 5| Step: 8
Training loss: 2.8977378967416794
Validation loss: 2.7896656093092496

Epoch: 5| Step: 9
Training loss: 3.0911447363800355
Validation loss: 2.7880268311122776

Epoch: 5| Step: 10
Training loss: 3.043944685895829
Validation loss: 2.7854556065027087

Epoch: 5| Step: 11
Training loss: 2.810019946723273
Validation loss: 2.783577213243586

Epoch: 60| Step: 0
Training loss: 2.579908828898744
Validation loss: 2.7818758756804316

Epoch: 5| Step: 1
Training loss: 2.86775405649652
Validation loss: 2.78086267053068

Epoch: 5| Step: 2
Training loss: 2.8268051018044464
Validation loss: 2.778281359854812

Epoch: 5| Step: 3
Training loss: 2.647486693265072
Validation loss: 2.7747656064519024

Epoch: 5| Step: 4
Training loss: 2.632575593245214
Validation loss: 2.7720163527912787

Epoch: 5| Step: 5
Training loss: 3.242515014284265
Validation loss: 2.774034484226766

Epoch: 5| Step: 6
Training loss: 3.1735811201960544
Validation loss: 2.772774741631777

Epoch: 5| Step: 7
Training loss: 3.397561006314085
Validation loss: 2.7675607124809227

Epoch: 5| Step: 8
Training loss: 2.879384884843198
Validation loss: 2.76566468765317

Epoch: 5| Step: 9
Training loss: 2.7541380006930614
Validation loss: 2.7634199622989404

Epoch: 5| Step: 10
Training loss: 3.0212176549819136
Validation loss: 2.7628484786648433

Epoch: 5| Step: 11
Training loss: 2.1020718209058846
Validation loss: 2.760284940107757

Epoch: 61| Step: 0
Training loss: 3.0730446654132773
Validation loss: 2.759809791983638

Epoch: 5| Step: 1
Training loss: 2.7775982660993535
Validation loss: 2.7558651028976193

Epoch: 5| Step: 2
Training loss: 2.7125172698002946
Validation loss: 2.7562702394464655

Epoch: 5| Step: 3
Training loss: 2.4640382638536407
Validation loss: 2.753796849884724

Epoch: 5| Step: 4
Training loss: 3.183290581807237
Validation loss: 2.7529456048049483

Epoch: 5| Step: 5
Training loss: 3.100593626958969
Validation loss: 2.7509695858066263

Epoch: 5| Step: 6
Training loss: 2.649125721500939
Validation loss: 2.7481133534972204

Epoch: 5| Step: 7
Training loss: 3.0758302141613174
Validation loss: 2.7452973811356225

Epoch: 5| Step: 8
Training loss: 2.9509804017861714
Validation loss: 2.7434292234284414

Epoch: 5| Step: 9
Training loss: 2.8892426355711542
Validation loss: 2.741991786004374

Epoch: 5| Step: 10
Training loss: 2.907271995099738
Validation loss: 2.7395148879132467

Epoch: 5| Step: 11
Training loss: 2.744249486969911
Validation loss: 2.7378034805214884

Epoch: 62| Step: 0
Training loss: 3.0821008710648887
Validation loss: 2.7373845531849064

Epoch: 5| Step: 1
Training loss: 2.933962700979224
Validation loss: 2.7361156554488275

Epoch: 5| Step: 2
Training loss: 2.629704936485939
Validation loss: 2.733810093973156

Epoch: 5| Step: 3
Training loss: 3.3339098590731715
Validation loss: 2.7328915413908703

Epoch: 5| Step: 4
Training loss: 2.969413281681544
Validation loss: 2.7297320993496075

Epoch: 5| Step: 5
Training loss: 2.907258545812062
Validation loss: 2.7282306082648176

Epoch: 5| Step: 6
Training loss: 3.034211432687167
Validation loss: 2.7257194709573804

Epoch: 5| Step: 7
Training loss: 2.1316938995140897
Validation loss: 2.7262329769579607

Epoch: 5| Step: 8
Training loss: 2.5031568622823386
Validation loss: 2.7232599159306963

Epoch: 5| Step: 9
Training loss: 2.858284497376763
Validation loss: 2.7234599068953353

Epoch: 5| Step: 10
Training loss: 3.0338598597831954
Validation loss: 2.721460821565317

Epoch: 5| Step: 11
Training loss: 2.533205760286794
Validation loss: 2.7203146827684614

Epoch: 63| Step: 0
Training loss: 3.3336874455868357
Validation loss: 2.7201445061500644

Epoch: 5| Step: 1
Training loss: 2.617607515708328
Validation loss: 2.7253300888309866

Epoch: 5| Step: 2
Training loss: 2.444238396350855
Validation loss: 2.727231181435154

Epoch: 5| Step: 3
Training loss: 3.268862930593571
Validation loss: 2.714170680784404

Epoch: 5| Step: 4
Training loss: 2.9312534877211394
Validation loss: 2.711256570938517

Epoch: 5| Step: 5
Training loss: 3.2316175122692767
Validation loss: 2.7102960785985144

Epoch: 5| Step: 6
Training loss: 2.7767931772043277
Validation loss: 2.710395630577216

Epoch: 5| Step: 7
Training loss: 1.9220059978220834
Validation loss: 2.7123686853901945

Epoch: 5| Step: 8
Training loss: 2.439027454385926
Validation loss: 2.7244951960294426

Epoch: 5| Step: 9
Training loss: 2.700868403336437
Validation loss: 2.721847625723239

Epoch: 5| Step: 10
Training loss: 3.262105404898569
Validation loss: 2.712520968741425

Epoch: 5| Step: 11
Training loss: 3.4507775246010852
Validation loss: 2.7070414225069284

Epoch: 64| Step: 0
Training loss: 3.1111578502625816
Validation loss: 2.703473077902332

Epoch: 5| Step: 1
Training loss: 3.167911251501168
Validation loss: 2.7012824244850195

Epoch: 5| Step: 2
Training loss: 2.834646556425248
Validation loss: 2.698126137946546

Epoch: 5| Step: 3
Training loss: 2.9083547866452677
Validation loss: 2.696526354505742

Epoch: 5| Step: 4
Training loss: 2.9514100277212245
Validation loss: 2.696237005633676

Epoch: 5| Step: 5
Training loss: 2.5853279063695904
Validation loss: 2.6945009087734277

Epoch: 5| Step: 6
Training loss: 2.9980252442216417
Validation loss: 2.6949066814881406

Epoch: 5| Step: 7
Training loss: 2.706206753497556
Validation loss: 2.6926115056723887

Epoch: 5| Step: 8
Training loss: 2.347265633125832
Validation loss: 2.6906065433295976

Epoch: 5| Step: 9
Training loss: 2.4230316353502697
Validation loss: 2.6877124354953588

Epoch: 5| Step: 10
Training loss: 2.6054855872300795
Validation loss: 2.6875380358111363

Epoch: 5| Step: 11
Training loss: 4.37427209520796
Validation loss: 2.6840875459118996

Epoch: 65| Step: 0
Training loss: 2.955330000264171
Validation loss: 2.685213269407165

Epoch: 5| Step: 1
Training loss: 2.473255247629726
Validation loss: 2.687380540395845

Epoch: 5| Step: 2
Training loss: 3.185798939100064
Validation loss: 2.693244498248636

Epoch: 5| Step: 3
Training loss: 2.8777078233003746
Validation loss: 2.734672751791058

Epoch: 5| Step: 4
Training loss: 3.1732260546729374
Validation loss: 2.759191011837775

Epoch: 5| Step: 5
Training loss: 2.911918444549909
Validation loss: 2.7120620417925174

Epoch: 5| Step: 6
Training loss: 2.9496470159352497
Validation loss: 2.696526070834747

Epoch: 5| Step: 7
Training loss: 2.6955988192862366
Validation loss: 2.689307532782555

Epoch: 5| Step: 8
Training loss: 2.217520897217419
Validation loss: 2.683962066043942

Epoch: 5| Step: 9
Training loss: 2.7735954132255607
Validation loss: 2.679930287624019

Epoch: 5| Step: 10
Training loss: 2.969414566344903
Validation loss: 2.675168927524359

Epoch: 5| Step: 11
Training loss: 2.1544551289760006
Validation loss: 2.673043569930421

Epoch: 66| Step: 0
Training loss: 3.3747134616862406
Validation loss: 2.670030853495643

Epoch: 5| Step: 1
Training loss: 2.455845775781995
Validation loss: 2.665816049709578

Epoch: 5| Step: 2
Training loss: 2.862526079750362
Validation loss: 2.665872412108262

Epoch: 5| Step: 3
Training loss: 2.7828099879960853
Validation loss: 2.666934451923162

Epoch: 5| Step: 4
Training loss: 1.9576321895587427
Validation loss: 2.666187684185931

Epoch: 5| Step: 5
Training loss: 2.658027144190851
Validation loss: 2.6625525258932

Epoch: 5| Step: 6
Training loss: 2.811980729380272
Validation loss: 2.658499240381767

Epoch: 5| Step: 7
Training loss: 3.0823935717597104
Validation loss: 2.658027140453452

Epoch: 5| Step: 8
Training loss: 2.7812099668214767
Validation loss: 2.655409283452405

Epoch: 5| Step: 9
Training loss: 2.5088004664736916
Validation loss: 2.654235113050852

Epoch: 5| Step: 10
Training loss: 3.0290251756983877
Validation loss: 2.6563021710826136

Epoch: 5| Step: 11
Training loss: 4.018855476478386
Validation loss: 2.6552344830615744

Epoch: 67| Step: 0
Training loss: 2.9852440652158156
Validation loss: 2.653368370417473

Epoch: 5| Step: 1
Training loss: 2.7720570742083317
Validation loss: 2.650889980021106

Epoch: 5| Step: 2
Training loss: 3.581347085059552
Validation loss: 2.6490484300103025

Epoch: 5| Step: 3
Training loss: 2.752370852732989
Validation loss: 2.647765195242331

Epoch: 5| Step: 4
Training loss: 3.0898111874568164
Validation loss: 2.646684259465102

Epoch: 5| Step: 5
Training loss: 2.514775292613411
Validation loss: 2.6465268515243205

Epoch: 5| Step: 6
Training loss: 2.6359139577631727
Validation loss: 2.6435890453874036

Epoch: 5| Step: 7
Training loss: 2.88472909458717
Validation loss: 2.638675199328215

Epoch: 5| Step: 8
Training loss: 2.073174567608999
Validation loss: 2.6414883573464345

Epoch: 5| Step: 9
Training loss: 2.671114450816886
Validation loss: 2.639006737676473

Epoch: 5| Step: 10
Training loss: 2.344183106141589
Validation loss: 2.638626512372371

Epoch: 5| Step: 11
Training loss: 2.910769322482641
Validation loss: 2.6381742778611006

Epoch: 68| Step: 0
Training loss: 2.992046303069509
Validation loss: 2.6366450509026453

Epoch: 5| Step: 1
Training loss: 3.09053766727004
Validation loss: 2.6381103610895056

Epoch: 5| Step: 2
Training loss: 2.473888024117418
Validation loss: 2.6351925197969965

Epoch: 5| Step: 3
Training loss: 3.162330586716869
Validation loss: 2.634458150188682

Epoch: 5| Step: 4
Training loss: 2.881435985727212
Validation loss: 2.6334663582854736

Epoch: 5| Step: 5
Training loss: 2.1787423439788682
Validation loss: 2.631290576981363

Epoch: 5| Step: 6
Training loss: 2.2492721227982755
Validation loss: 2.6296622562386776

Epoch: 5| Step: 7
Training loss: 2.4844099318249766
Validation loss: 2.6265090283380843

Epoch: 5| Step: 8
Training loss: 3.1400397974881735
Validation loss: 2.6269675404508828

Epoch: 5| Step: 9
Training loss: 2.9529770909966726
Validation loss: 2.626887036783888

Epoch: 5| Step: 10
Training loss: 2.3039338512196696
Validation loss: 2.624259556684633

Epoch: 5| Step: 11
Training loss: 3.7065843608235016
Validation loss: 2.625463664264805

Epoch: 69| Step: 0
Training loss: 3.0928841352150176
Validation loss: 2.622929911066198

Epoch: 5| Step: 1
Training loss: 2.750705715140195
Validation loss: 2.622967925011462

Epoch: 5| Step: 2
Training loss: 2.1917117308805225
Validation loss: 2.61945629185177

Epoch: 5| Step: 3
Training loss: 2.9296368810731215
Validation loss: 2.618981694371271

Epoch: 5| Step: 4
Training loss: 2.930588077728298
Validation loss: 2.620118305984734

Epoch: 5| Step: 5
Training loss: 3.1938277621423103
Validation loss: 2.6128625919288497

Epoch: 5| Step: 6
Training loss: 2.389247123215993
Validation loss: 2.6166525184852243

Epoch: 5| Step: 7
Training loss: 2.565419278742683
Validation loss: 2.6152024213734757

Epoch: 5| Step: 8
Training loss: 2.5404386107143684
Validation loss: 2.616476203330339

Epoch: 5| Step: 9
Training loss: 3.048115795529117
Validation loss: 2.6122515008093172

Epoch: 5| Step: 10
Training loss: 2.4165203335184975
Validation loss: 2.6144983852817014

Epoch: 5| Step: 11
Training loss: 2.838922784167067
Validation loss: 2.611147862681893

Epoch: 70| Step: 0
Training loss: 2.6668008730813555
Validation loss: 2.6139348556993705

Epoch: 5| Step: 1
Training loss: 3.2936123437364313
Validation loss: 2.6126524164374634

Epoch: 5| Step: 2
Training loss: 2.1993014657166197
Validation loss: 2.609771131191755

Epoch: 5| Step: 3
Training loss: 2.8709768258504478
Validation loss: 2.608259446089856

Epoch: 5| Step: 4
Training loss: 2.534610918873112
Validation loss: 2.6066509007097456

Epoch: 5| Step: 5
Training loss: 2.4196272725361005
Validation loss: 2.605985816080397

Epoch: 5| Step: 6
Training loss: 2.7422873976027797
Validation loss: 2.604524009347131

Epoch: 5| Step: 7
Training loss: 2.807389851529869
Validation loss: 2.600452965471482

Epoch: 5| Step: 8
Training loss: 3.1672922486879282
Validation loss: 2.6014022014060267

Epoch: 5| Step: 9
Training loss: 2.3969830504810026
Validation loss: 2.5976959607906087

Epoch: 5| Step: 10
Training loss: 2.9476621448287035
Validation loss: 2.595401988514391

Epoch: 5| Step: 11
Training loss: 2.107325709909136
Validation loss: 2.5976857692790847

Epoch: 71| Step: 0
Training loss: 2.6630955168912327
Validation loss: 2.6088115441654827

Epoch: 5| Step: 1
Training loss: 2.907610995010031
Validation loss: 2.600953837571843

Epoch: 5| Step: 2
Training loss: 2.442889978830286
Validation loss: 2.5961890262183664

Epoch: 5| Step: 3
Training loss: 2.962923133988596
Validation loss: 2.5952400998178207

Epoch: 5| Step: 4
Training loss: 2.834668929264509
Validation loss: 2.591674315010961

Epoch: 5| Step: 5
Training loss: 2.934131070236826
Validation loss: 2.590826934411053

Epoch: 5| Step: 6
Training loss: 2.3347730509151816
Validation loss: 2.5922123859323087

Epoch: 5| Step: 7
Training loss: 2.747583020720122
Validation loss: 2.59352616795898

Epoch: 5| Step: 8
Training loss: 3.1477119613189934
Validation loss: 2.5921913580763243

Epoch: 5| Step: 9
Training loss: 2.329138004169839
Validation loss: 2.589152447633116

Epoch: 5| Step: 10
Training loss: 2.665671749085181
Validation loss: 2.5909271429098197

Epoch: 5| Step: 11
Training loss: 2.1522763998083225
Validation loss: 2.5917972506245213

Epoch: 72| Step: 0
Training loss: 2.921830936854419
Validation loss: 2.5894683021065723

Epoch: 5| Step: 1
Training loss: 2.6956716989195315
Validation loss: 2.58344071816219

Epoch: 5| Step: 2
Training loss: 2.8330778305937274
Validation loss: 2.5843077207646568

Epoch: 5| Step: 3
Training loss: 2.3509433476199
Validation loss: 2.5854796881196616

Epoch: 5| Step: 4
Training loss: 2.8648765460140453
Validation loss: 2.5811402384502626

Epoch: 5| Step: 5
Training loss: 2.82196579762799
Validation loss: 2.581604522669672

Epoch: 5| Step: 6
Training loss: 2.939497086205736
Validation loss: 2.582481587391418

Epoch: 5| Step: 7
Training loss: 2.7088028916430824
Validation loss: 2.5912628006852803

Epoch: 5| Step: 8
Training loss: 2.464262541667908
Validation loss: 2.589245841779467

Epoch: 5| Step: 9
Training loss: 2.6863937762637633
Validation loss: 2.5846352193657762

Epoch: 5| Step: 10
Training loss: 2.545236446586203
Validation loss: 2.5771249584782616

Epoch: 5| Step: 11
Training loss: 2.9589305507687165
Validation loss: 2.5800089108512827

Epoch: 73| Step: 0
Training loss: 2.9343085300769953
Validation loss: 2.58031515476059

Epoch: 5| Step: 1
Training loss: 2.318899630014113
Validation loss: 2.5816485746113798

Epoch: 5| Step: 2
Training loss: 2.713371305676439
Validation loss: 2.5843036634077974

Epoch: 5| Step: 3
Training loss: 2.88221432649068
Validation loss: 2.586840108061808

Epoch: 5| Step: 4
Training loss: 2.856588705001302
Validation loss: 2.5893769493221526

Epoch: 5| Step: 5
Training loss: 2.4390607874178203
Validation loss: 2.591057260555381

Epoch: 5| Step: 6
Training loss: 2.689104444053643
Validation loss: 2.5940994961754336

Epoch: 5| Step: 7
Training loss: 2.6772546874149645
Validation loss: 2.588608275899071

Epoch: 5| Step: 8
Training loss: 2.6594432709982208
Validation loss: 2.584972539610767

Epoch: 5| Step: 9
Training loss: 2.831101679337922
Validation loss: 2.5780599142779246

Epoch: 5| Step: 10
Training loss: 2.864016575088701
Validation loss: 2.5773351210686486

Epoch: 5| Step: 11
Training loss: 2.595755847082613
Validation loss: 2.5744410425123982

Epoch: 74| Step: 0
Training loss: 2.771422263827892
Validation loss: 2.571553963377267

Epoch: 5| Step: 1
Training loss: 2.7869991930305837
Validation loss: 2.5688639214121665

Epoch: 5| Step: 2
Training loss: 2.2819668414342207
Validation loss: 2.5656107729828266

Epoch: 5| Step: 3
Training loss: 2.7523067509776324
Validation loss: 2.56274683856704

Epoch: 5| Step: 4
Training loss: 3.0808746914043326
Validation loss: 2.5648836005534386

Epoch: 5| Step: 5
Training loss: 2.7796669215726646
Validation loss: 2.561050365537387

Epoch: 5| Step: 6
Training loss: 3.0319802889120298
Validation loss: 2.561667725850939

Epoch: 5| Step: 7
Training loss: 2.587466061871709
Validation loss: 2.561161680341775

Epoch: 5| Step: 8
Training loss: 2.575765651462427
Validation loss: 2.561326165116354

Epoch: 5| Step: 9
Training loss: 2.4660838736001782
Validation loss: 2.560631388596608

Epoch: 5| Step: 10
Training loss: 2.5225811618416984
Validation loss: 2.559557198019438

Epoch: 5| Step: 11
Training loss: 2.1696416775242167
Validation loss: 2.568555832614759

Epoch: 75| Step: 0
Training loss: 2.8054222908305473
Validation loss: 2.5706594246561814

Epoch: 5| Step: 1
Training loss: 2.2416284375907565
Validation loss: 2.5757742288802516

Epoch: 5| Step: 2
Training loss: 2.665643038582448
Validation loss: 2.57626127445099

Epoch: 5| Step: 3
Training loss: 2.763830346190886
Validation loss: 2.572854590857599

Epoch: 5| Step: 4
Training loss: 2.542374173692062
Validation loss: 2.567650542211765

Epoch: 5| Step: 5
Training loss: 3.0501150265875285
Validation loss: 2.561646904868114

Epoch: 5| Step: 6
Training loss: 2.5668920698729165
Validation loss: 2.5549878635043597

Epoch: 5| Step: 7
Training loss: 2.9591985341745226
Validation loss: 2.554604034149147

Epoch: 5| Step: 8
Training loss: 2.9987429528354337
Validation loss: 2.556069244423376

Epoch: 5| Step: 9
Training loss: 2.3942585178401776
Validation loss: 2.559687998274892

Epoch: 5| Step: 10
Training loss: 2.2671712926052647
Validation loss: 2.5564227379259665

Epoch: 5| Step: 11
Training loss: 3.570747332314409
Validation loss: 2.5603187356589907

Epoch: 76| Step: 0
Training loss: 2.321434494681714
Validation loss: 2.560917086284242

Epoch: 5| Step: 1
Training loss: 2.4930600160672785
Validation loss: 2.5690937843980874

Epoch: 5| Step: 2
Training loss: 2.7663076818962073
Validation loss: 2.5708952207447857

Epoch: 5| Step: 3
Training loss: 2.8712362448695403
Validation loss: 2.580349026477247

Epoch: 5| Step: 4
Training loss: 2.5584197705936953
Validation loss: 2.581450615877161

Epoch: 5| Step: 5
Training loss: 2.4682423516333407
Validation loss: 2.5773518915540197

Epoch: 5| Step: 6
Training loss: 3.100762482670672
Validation loss: 2.5678519943212725

Epoch: 5| Step: 7
Training loss: 2.6565287724234006
Validation loss: 2.5661857003135418

Epoch: 5| Step: 8
Training loss: 3.2822376036522116
Validation loss: 2.564656854087509

Epoch: 5| Step: 9
Training loss: 2.442611811722967
Validation loss: 2.5614233740341588

Epoch: 5| Step: 10
Training loss: 2.6746478945294263
Validation loss: 2.556774811007577

Epoch: 5| Step: 11
Training loss: 2.0291673987959755
Validation loss: 2.5556904635087903

Epoch: 77| Step: 0
Training loss: 2.8455689031382327
Validation loss: 2.5498932075889544

Epoch: 5| Step: 1
Training loss: 2.237116165910168
Validation loss: 2.54493562700016

Epoch: 5| Step: 2
Training loss: 2.569042692192771
Validation loss: 2.543794895247696

Epoch: 5| Step: 3
Training loss: 2.5672484341318604
Validation loss: 2.542479167635332

Epoch: 5| Step: 4
Training loss: 2.9420969280092164
Validation loss: 2.539989139976088

Epoch: 5| Step: 5
Training loss: 2.910682661334395
Validation loss: 2.542971191561338

Epoch: 5| Step: 6
Training loss: 2.671674575873281
Validation loss: 2.543295589758997

Epoch: 5| Step: 7
Training loss: 2.6331046194233556
Validation loss: 2.5459794067102846

Epoch: 5| Step: 8
Training loss: 2.621960105924212
Validation loss: 2.5420238499251653

Epoch: 5| Step: 9
Training loss: 2.5110450897239884
Validation loss: 2.54104681482117

Epoch: 5| Step: 10
Training loss: 2.753169227617227
Validation loss: 2.538011213931908

Epoch: 5| Step: 11
Training loss: 2.9538106778273345
Validation loss: 2.5450245155135485

Epoch: 78| Step: 0
Training loss: 2.7364552459486404
Validation loss: 2.539699189002852

Epoch: 5| Step: 1
Training loss: 2.2113317131440593
Validation loss: 2.5362197690678343

Epoch: 5| Step: 2
Training loss: 2.3104727854905964
Validation loss: 2.5376725916428997

Epoch: 5| Step: 3
Training loss: 2.379325742018797
Validation loss: 2.5377952425847172

Epoch: 5| Step: 4
Training loss: 2.6440869272228813
Validation loss: 2.5439190551418034

Epoch: 5| Step: 5
Training loss: 2.4262382334876365
Validation loss: 2.5435307863648338

Epoch: 5| Step: 6
Training loss: 2.8994528747612756
Validation loss: 2.5430823055135714

Epoch: 5| Step: 7
Training loss: 2.8309295405570647
Validation loss: 2.542649193846557

Epoch: 5| Step: 8
Training loss: 3.068576778332105
Validation loss: 2.5459525928461213

Epoch: 5| Step: 9
Training loss: 3.1670777070823117
Validation loss: 2.543364818725166

Epoch: 5| Step: 10
Training loss: 2.5922803276966944
Validation loss: 2.541454983844098

Epoch: 5| Step: 11
Training loss: 2.4646239749484353
Validation loss: 2.5375232549832605

Epoch: 79| Step: 0
Training loss: 2.5228374700823792
Validation loss: 2.542077575882992

Epoch: 5| Step: 1
Training loss: 2.5331446773989286
Validation loss: 2.536491775031139

Epoch: 5| Step: 2
Training loss: 2.7376217122651063
Validation loss: 2.5311190449626415

Epoch: 5| Step: 3
Training loss: 2.4184532358042348
Validation loss: 2.5317475257736635

Epoch: 5| Step: 4
Training loss: 2.4132531052983093
Validation loss: 2.534897715155898

Epoch: 5| Step: 5
Training loss: 2.1767284584718847
Validation loss: 2.5285667121574846

Epoch: 5| Step: 6
Training loss: 2.8981862743317754
Validation loss: 2.528114075670503

Epoch: 5| Step: 7
Training loss: 3.028952288136304
Validation loss: 2.5360321820114455

Epoch: 5| Step: 8
Training loss: 2.0681494587396974
Validation loss: 2.542669474955843

Epoch: 5| Step: 9
Training loss: 3.0419158485104325
Validation loss: 2.5341000151804307

Epoch: 5| Step: 10
Training loss: 3.0460366685229396
Validation loss: 2.5310122374338366

Epoch: 5| Step: 11
Training loss: 3.599466305485602
Validation loss: 2.53806531055499

Epoch: 80| Step: 0
Training loss: 2.4523751637517903
Validation loss: 2.52954222914099

Epoch: 5| Step: 1
Training loss: 3.0350798961800476
Validation loss: 2.5258271247496316

Epoch: 5| Step: 2
Training loss: 2.7478238078274826
Validation loss: 2.5244458470166684

Epoch: 5| Step: 3
Training loss: 2.389562033902277
Validation loss: 2.5297513339946454

Epoch: 5| Step: 4
Training loss: 2.6201262870229614
Validation loss: 2.520093388895798

Epoch: 5| Step: 5
Training loss: 2.467807348370836
Validation loss: 2.525240609221569

Epoch: 5| Step: 6
Training loss: 2.760821724209115
Validation loss: 2.5242504349686428

Epoch: 5| Step: 7
Training loss: 2.7459070785259514
Validation loss: 2.5230113162665004

Epoch: 5| Step: 8
Training loss: 2.5597864064875373
Validation loss: 2.5246628501580526

Epoch: 5| Step: 9
Training loss: 2.903839916819143
Validation loss: 2.5249117510075734

Epoch: 5| Step: 10
Training loss: 2.490088365051606
Validation loss: 2.5218102608729662

Epoch: 5| Step: 11
Training loss: 2.35374425513589
Validation loss: 2.5220898158189002

Epoch: 81| Step: 0
Training loss: 2.388385396826059
Validation loss: 2.5248532806549626

Epoch: 5| Step: 1
Training loss: 2.466663879530423
Validation loss: 2.5226639820845547

Epoch: 5| Step: 2
Training loss: 2.560626298616847
Validation loss: 2.5258979612288397

Epoch: 5| Step: 3
Training loss: 2.9660730439527256
Validation loss: 2.523860415675392

Epoch: 5| Step: 4
Training loss: 2.6334532911606487
Validation loss: 2.5270005847584036

Epoch: 5| Step: 5
Training loss: 2.2114458881254992
Validation loss: 2.5282106440827516

Epoch: 5| Step: 6
Training loss: 2.9118051248466146
Validation loss: 2.5263941581160356

Epoch: 5| Step: 7
Training loss: 2.5777441494856546
Validation loss: 2.5248026506332075

Epoch: 5| Step: 8
Training loss: 3.0775728456628495
Validation loss: 2.5305822849664907

Epoch: 5| Step: 9
Training loss: 2.6127965731409684
Validation loss: 2.524513487637975

Epoch: 5| Step: 10
Training loss: 2.525966923712328
Validation loss: 2.5246690396307905

Epoch: 5| Step: 11
Training loss: 2.8123441864934
Validation loss: 2.5268730342334313

Epoch: 82| Step: 0
Training loss: 2.6486281604837103
Validation loss: 2.5238650877937747

Epoch: 5| Step: 1
Training loss: 2.7557039061557576
Validation loss: 2.5204094098153194

Epoch: 5| Step: 2
Training loss: 2.576847939211557
Validation loss: 2.522100832729445

Epoch: 5| Step: 3
Training loss: 2.5437942313582873
Validation loss: 2.521473682399607

Epoch: 5| Step: 4
Training loss: 2.3448244810809222
Validation loss: 2.5243780747190514

Epoch: 5| Step: 5
Training loss: 2.845228376826083
Validation loss: 2.523317304648064

Epoch: 5| Step: 6
Training loss: 2.349666198398505
Validation loss: 2.5182963062844657

Epoch: 5| Step: 7
Training loss: 2.478284748407546
Validation loss: 2.523562031636471

Epoch: 5| Step: 8
Training loss: 2.804094427197598
Validation loss: 2.522975627410764

Epoch: 5| Step: 9
Training loss: 2.9695351616427965
Validation loss: 2.5193130319807344

Epoch: 5| Step: 10
Training loss: 2.727682064144243
Validation loss: 2.517589047223043

Epoch: 5| Step: 11
Training loss: 1.7678330379895946
Validation loss: 2.5175680550471773

Epoch: 83| Step: 0
Training loss: 2.885695920208623
Validation loss: 2.5179361700888876

Epoch: 5| Step: 1
Training loss: 2.837024490912289
Validation loss: 2.5167449290588673

Epoch: 5| Step: 2
Training loss: 2.4322921676689684
Validation loss: 2.5149752447112004

Epoch: 5| Step: 3
Training loss: 2.688250503430727
Validation loss: 2.5133954982780797

Epoch: 5| Step: 4
Training loss: 2.5590231032884527
Validation loss: 2.512964073423002

Epoch: 5| Step: 5
Training loss: 2.657851331136731
Validation loss: 2.511231390468115

Epoch: 5| Step: 6
Training loss: 2.662342758191959
Validation loss: 2.511773883536816

Epoch: 5| Step: 7
Training loss: 2.523210922792797
Validation loss: 2.5103488427546155

Epoch: 5| Step: 8
Training loss: 2.4428989577319786
Validation loss: 2.5130385100116888

Epoch: 5| Step: 9
Training loss: 2.855053413546174
Validation loss: 2.5160127186976813

Epoch: 5| Step: 10
Training loss: 2.419418762962239
Validation loss: 2.5169814226126483

Epoch: 5| Step: 11
Training loss: 2.5046371369227494
Validation loss: 2.5146327105280353

Epoch: 84| Step: 0
Training loss: 2.5746739264388667
Validation loss: 2.513659975408543

Epoch: 5| Step: 1
Training loss: 2.6227587259707597
Validation loss: 2.511626535070567

Epoch: 5| Step: 2
Training loss: 2.655482551559042
Validation loss: 2.5149324304896523

Epoch: 5| Step: 3
Training loss: 2.9710225291596855
Validation loss: 2.523502813543126

Epoch: 5| Step: 4
Training loss: 2.512700720972852
Validation loss: 2.538476322686033

Epoch: 5| Step: 5
Training loss: 2.4069336749750208
Validation loss: 2.5560460692486533

Epoch: 5| Step: 6
Training loss: 3.0773413575573016
Validation loss: 2.5674285265505725

Epoch: 5| Step: 7
Training loss: 2.790206546316232
Validation loss: 2.568794401238329

Epoch: 5| Step: 8
Training loss: 1.8911904994684012
Validation loss: 2.554963550954621

Epoch: 5| Step: 9
Training loss: 2.5354712809247206
Validation loss: 2.538663662616755

Epoch: 5| Step: 10
Training loss: 2.992937038953647
Validation loss: 2.5358104557251036

Epoch: 5| Step: 11
Training loss: 2.9584433485895865
Validation loss: 2.5225413279240136

Epoch: 85| Step: 0
Training loss: 2.530660207347579
Validation loss: 2.519321170693321

Epoch: 5| Step: 1
Training loss: 2.0330677995160906
Validation loss: 2.515163636006459

Epoch: 5| Step: 2
Training loss: 2.738774885014936
Validation loss: 2.512348438233812

Epoch: 5| Step: 3
Training loss: 2.9463395571783386
Validation loss: 2.5084070746670557

Epoch: 5| Step: 4
Training loss: 3.23255286743643
Validation loss: 2.504056825836493

Epoch: 5| Step: 5
Training loss: 2.8513382496904764
Validation loss: 2.506214405101949

Epoch: 5| Step: 6
Training loss: 2.6664822236489116
Validation loss: 2.5027307299083357

Epoch: 5| Step: 7
Training loss: 2.4375459715591736
Validation loss: 2.5049239543785644

Epoch: 5| Step: 8
Training loss: 2.235924137056887
Validation loss: 2.5067376856960655

Epoch: 5| Step: 9
Training loss: 2.9442117187208736
Validation loss: 2.5023017737656894

Epoch: 5| Step: 10
Training loss: 2.125689226462796
Validation loss: 2.4996103300949333

Epoch: 5| Step: 11
Training loss: 2.1400538886941356
Validation loss: 2.5025413709073265

Epoch: 86| Step: 0
Training loss: 2.597973154570951
Validation loss: 2.517053380258692

Epoch: 5| Step: 1
Training loss: 3.1156459428854326
Validation loss: 2.517807189764097

Epoch: 5| Step: 2
Training loss: 2.8472931974501843
Validation loss: 2.5174274187380448

Epoch: 5| Step: 3
Training loss: 2.275677393577546
Validation loss: 2.5149905903452496

Epoch: 5| Step: 4
Training loss: 2.451426896283025
Validation loss: 2.5167721251524453

Epoch: 5| Step: 5
Training loss: 2.9267768744687057
Validation loss: 2.505571328483786

Epoch: 5| Step: 6
Training loss: 2.5692312639026
Validation loss: 2.504944334706072

Epoch: 5| Step: 7
Training loss: 2.5206466689763913
Validation loss: 2.500650293491963

Epoch: 5| Step: 8
Training loss: 2.438710621213299
Validation loss: 2.4983499565317966

Epoch: 5| Step: 9
Training loss: 2.960738122513124
Validation loss: 2.49943364006456

Epoch: 5| Step: 10
Training loss: 2.2313400677793136
Validation loss: 2.5003188486220878

Epoch: 5| Step: 11
Training loss: 2.5892113191036312
Validation loss: 2.5045361492764244

Epoch: 87| Step: 0
Training loss: 3.0510313197766115
Validation loss: 2.4963660651298207

Epoch: 5| Step: 1
Training loss: 2.6806149671050625
Validation loss: 2.50074285358355

Epoch: 5| Step: 2
Training loss: 2.1770025965368918
Validation loss: 2.504271962104343

Epoch: 5| Step: 3
Training loss: 2.5822360466838536
Validation loss: 2.50134194041317

Epoch: 5| Step: 4
Training loss: 2.6526023502719385
Validation loss: 2.5051586056305655

Epoch: 5| Step: 5
Training loss: 2.871608890329349
Validation loss: 2.503163053340003

Epoch: 5| Step: 6
Training loss: 2.7861726038003685
Validation loss: 2.499185401604179

Epoch: 5| Step: 7
Training loss: 2.3608937207043916
Validation loss: 2.501789469829728

Epoch: 5| Step: 8
Training loss: 2.295357131264411
Validation loss: 2.499738433188

Epoch: 5| Step: 9
Training loss: 2.5270824267791188
Validation loss: 2.5004296410449713

Epoch: 5| Step: 10
Training loss: 2.728768666684535
Validation loss: 2.493284093824072

Epoch: 5| Step: 11
Training loss: 2.353031447375935
Validation loss: 2.499911517325816

Epoch: 88| Step: 0
Training loss: 2.799829297311837
Validation loss: 2.498269885152219

Epoch: 5| Step: 1
Training loss: 2.669118340330972
Validation loss: 2.4963906698080383

Epoch: 5| Step: 2
Training loss: 2.554874891588612
Validation loss: 2.4963771040369576

Epoch: 5| Step: 3
Training loss: 2.9477810418480392
Validation loss: 2.4990273928166866

Epoch: 5| Step: 4
Training loss: 2.3403574486316665
Validation loss: 2.4956514407402883

Epoch: 5| Step: 5
Training loss: 2.118678395009373
Validation loss: 2.4968799433462316

Epoch: 5| Step: 6
Training loss: 2.6892548088363375
Validation loss: 2.4960646252034904

Epoch: 5| Step: 7
Training loss: 2.3241386335653487
Validation loss: 2.4985387028150923

Epoch: 5| Step: 8
Training loss: 2.293411342140575
Validation loss: 2.4978372755841907

Epoch: 5| Step: 9
Training loss: 2.943038102748749
Validation loss: 2.493321948811691

Epoch: 5| Step: 10
Training loss: 2.8880394171669237
Validation loss: 2.500408532618297

Epoch: 5| Step: 11
Training loss: 2.0413639337217413
Validation loss: 2.5019916627741448

Epoch: 89| Step: 0
Training loss: 2.7147577724976095
Validation loss: 2.4966842756766607

Epoch: 5| Step: 1
Training loss: 2.865392471247565
Validation loss: 2.493701632308691

Epoch: 5| Step: 2
Training loss: 2.0907996727656535
Validation loss: 2.4983988243800987

Epoch: 5| Step: 3
Training loss: 2.332598082186213
Validation loss: 2.496708964754343

Epoch: 5| Step: 4
Training loss: 3.06840568522102
Validation loss: 2.489218107804536

Epoch: 5| Step: 5
Training loss: 2.9570496330546487
Validation loss: 2.4877723640584413

Epoch: 5| Step: 6
Training loss: 3.0035520823500232
Validation loss: 2.488131492176352

Epoch: 5| Step: 7
Training loss: 2.188273483856377
Validation loss: 2.489812694076989

Epoch: 5| Step: 8
Training loss: 2.394391651658258
Validation loss: 2.494280025337526

Epoch: 5| Step: 9
Training loss: 2.3175733434106034
Validation loss: 2.4968145381464613

Epoch: 5| Step: 10
Training loss: 2.6667083399218483
Validation loss: 2.4944940653649

Epoch: 5| Step: 11
Training loss: 2.780282270111321
Validation loss: 2.4972062037249696

Epoch: 90| Step: 0
Training loss: 3.1622864059269444
Validation loss: 2.4919218960200182

Epoch: 5| Step: 1
Training loss: 2.947003352261369
Validation loss: 2.4944591015183573

Epoch: 5| Step: 2
Training loss: 2.456059541185562
Validation loss: 2.4942968285263363

Epoch: 5| Step: 3
Training loss: 2.5577733246000123
Validation loss: 2.4939278651507073

Epoch: 5| Step: 4
Training loss: 2.2850421061903843
Validation loss: 2.4933704729573782

Epoch: 5| Step: 5
Training loss: 2.680301962822092
Validation loss: 2.4881122238264277

Epoch: 5| Step: 6
Training loss: 2.407772226758018
Validation loss: 2.496267870828062

Epoch: 5| Step: 7
Training loss: 2.281958274105445
Validation loss: 2.5044542566928696

Epoch: 5| Step: 8
Training loss: 2.7099876828635168
Validation loss: 2.497538145198497

Epoch: 5| Step: 9
Training loss: 2.781777578313683
Validation loss: 2.495019023678764

Epoch: 5| Step: 10
Training loss: 2.278378076716291
Validation loss: 2.4920230958737304

Epoch: 5| Step: 11
Training loss: 2.2273320524563496
Validation loss: 2.495967135454241

Epoch: 91| Step: 0
Training loss: 2.562455804955444
Validation loss: 2.4912330609511493

Epoch: 5| Step: 1
Training loss: 2.6007944983903797
Validation loss: 2.50140823994203

Epoch: 5| Step: 2
Training loss: 2.7554781708909157
Validation loss: 2.491562022421993

Epoch: 5| Step: 3
Training loss: 2.3283393300369943
Validation loss: 2.4938461579958418

Epoch: 5| Step: 4
Training loss: 2.665711370859931
Validation loss: 2.4895988541016867

Epoch: 5| Step: 5
Training loss: 2.069248257013066
Validation loss: 2.509495353742059

Epoch: 5| Step: 6
Training loss: 2.8249022947986524
Validation loss: 2.510822490217579

Epoch: 5| Step: 7
Training loss: 2.5421570685217616
Validation loss: 2.497201851692279

Epoch: 5| Step: 8
Training loss: 2.6092159199906337
Validation loss: 2.499270436009944

Epoch: 5| Step: 9
Training loss: 2.9900860690484117
Validation loss: 2.500542615575668

Epoch: 5| Step: 10
Training loss: 2.361250277388452
Validation loss: 2.4874948110158908

Epoch: 5| Step: 11
Training loss: 3.7057775341030905
Validation loss: 2.488456041234329

Epoch: 92| Step: 0
Training loss: 2.7550732892598546
Validation loss: 2.4827886351008

Epoch: 5| Step: 1
Training loss: 2.477853721211303
Validation loss: 2.489762049741876

Epoch: 5| Step: 2
Training loss: 2.8443916351495773
Validation loss: 2.4904635654271603

Epoch: 5| Step: 3
Training loss: 3.4226831326694787
Validation loss: 2.494601245745941

Epoch: 5| Step: 4
Training loss: 2.5600839715835177
Validation loss: 2.497161585084929

Epoch: 5| Step: 5
Training loss: 2.49567754914187
Validation loss: 2.4997575085973516

Epoch: 5| Step: 6
Training loss: 2.6247529413127033
Validation loss: 2.509724190415713

Epoch: 5| Step: 7
Training loss: 2.5778630903895903
Validation loss: 2.513645779608349

Epoch: 5| Step: 8
Training loss: 1.8562173397389143
Validation loss: 2.5164867054677598

Epoch: 5| Step: 9
Training loss: 2.5270767660493316
Validation loss: 2.5187312706818132

Epoch: 5| Step: 10
Training loss: 2.194698478652803
Validation loss: 2.5164119563669165

Epoch: 5| Step: 11
Training loss: 3.469878966669437
Validation loss: 2.517346324365677

Epoch: 93| Step: 0
Training loss: 2.801657822833455
Validation loss: 2.507834714670317

Epoch: 5| Step: 1
Training loss: 3.172903561246728
Validation loss: 2.50484218552072

Epoch: 5| Step: 2
Training loss: 3.293322488738621
Validation loss: 2.503480149948917

Epoch: 5| Step: 3
Training loss: 2.5144073192957186
Validation loss: 2.4983602470906106

Epoch: 5| Step: 4
Training loss: 2.6446500720513244
Validation loss: 2.49675703712985

Epoch: 5| Step: 5
Training loss: 2.6300678379317146
Validation loss: 2.4955026586377413

Epoch: 5| Step: 6
Training loss: 2.017452742012477
Validation loss: 2.489434813747304

Epoch: 5| Step: 7
Training loss: 2.3128972099015894
Validation loss: 2.491426242011694

Epoch: 5| Step: 8
Training loss: 2.691523888484952
Validation loss: 2.48759706154472

Epoch: 5| Step: 9
Training loss: 2.000628491833305
Validation loss: 2.4847074602109216

Epoch: 5| Step: 10
Training loss: 2.4856977480227047
Validation loss: 2.486412400512721

Epoch: 5| Step: 11
Training loss: 2.5572862385512867
Validation loss: 2.485909561841019

Epoch: 94| Step: 0
Training loss: 2.6363978211808434
Validation loss: 2.4861715047191293

Epoch: 5| Step: 1
Training loss: 2.541305068095367
Validation loss: 2.48877129153346

Epoch: 5| Step: 2
Training loss: 2.692093848549525
Validation loss: 2.4852964743633894

Epoch: 5| Step: 3
Training loss: 2.481244496067967
Validation loss: 2.483832554007599

Epoch: 5| Step: 4
Training loss: 2.1839981387064062
Validation loss: 2.4834094980473336

Epoch: 5| Step: 5
Training loss: 2.6616275880349822
Validation loss: 2.4895157698450854

Epoch: 5| Step: 6
Training loss: 2.4402692664985923
Validation loss: 2.4883048447189444

Epoch: 5| Step: 7
Training loss: 2.5521203070836243
Validation loss: 2.4812185881233435

Epoch: 5| Step: 8
Training loss: 2.800467969752444
Validation loss: 2.4872812430519113

Epoch: 5| Step: 9
Training loss: 2.3315622442756885
Validation loss: 2.488518500483038

Epoch: 5| Step: 10
Training loss: 3.030234255154753
Validation loss: 2.487272759861564

Epoch: 5| Step: 11
Training loss: 2.879013080245233
Validation loss: 2.487938338784646

Epoch: 95| Step: 0
Training loss: 3.07782848498473
Validation loss: 2.4811219123878647

Epoch: 5| Step: 1
Training loss: 2.9904247699223983
Validation loss: 2.4883364197719753

Epoch: 5| Step: 2
Training loss: 2.2117743643799255
Validation loss: 2.489200144903301

Epoch: 5| Step: 3
Training loss: 2.4719898838589285
Validation loss: 2.4907784659195413

Epoch: 5| Step: 4
Training loss: 2.24745542963662
Validation loss: 2.4810551908810297

Epoch: 5| Step: 5
Training loss: 2.806615989964518
Validation loss: 2.490203761492281

Epoch: 5| Step: 6
Training loss: 2.428386867546623
Validation loss: 2.4942108240009397

Epoch: 5| Step: 7
Training loss: 2.480505851408061
Validation loss: 2.490115900150994

Epoch: 5| Step: 8
Training loss: 2.8839492830851285
Validation loss: 2.4791256930601087

Epoch: 5| Step: 9
Training loss: 2.2676162913656586
Validation loss: 2.4887502638482837

Epoch: 5| Step: 10
Training loss: 2.490769990651844
Validation loss: 2.479503057134761

Epoch: 5| Step: 11
Training loss: 2.168590229756356
Validation loss: 2.481963116514441

Epoch: 96| Step: 0
Training loss: 2.6143001286498633
Validation loss: 2.4899264475607796

Epoch: 5| Step: 1
Training loss: 2.728554072071644
Validation loss: 2.4815126720435163

Epoch: 5| Step: 2
Training loss: 2.4505230170202035
Validation loss: 2.4863498923524276

Epoch: 5| Step: 3
Training loss: 2.940667250813135
Validation loss: 2.480531864915199

Epoch: 5| Step: 4
Training loss: 2.9076524857529438
Validation loss: 2.4814195707913353

Epoch: 5| Step: 5
Training loss: 2.6318768839579127
Validation loss: 2.4832899895241436

Epoch: 5| Step: 6
Training loss: 2.30246133131926
Validation loss: 2.4835482087289282

Epoch: 5| Step: 7
Training loss: 2.374568498463256
Validation loss: 2.48473846128045

Epoch: 5| Step: 8
Training loss: 2.570022520270923
Validation loss: 2.4813860821501366

Epoch: 5| Step: 9
Training loss: 2.4797214133161596
Validation loss: 2.4846406710624143

Epoch: 5| Step: 10
Training loss: 2.5347252995256064
Validation loss: 2.483622750969642

Epoch: 5| Step: 11
Training loss: 2.765353431946206
Validation loss: 2.485332156682026

Epoch: 97| Step: 0
Training loss: 2.305648861826481
Validation loss: 2.4815775358023746

Epoch: 5| Step: 1
Training loss: 2.29005447089699
Validation loss: 2.4785750522007266

Epoch: 5| Step: 2
Training loss: 2.693852214245849
Validation loss: 2.4839536121565313

Epoch: 5| Step: 3
Training loss: 2.4559036360111035
Validation loss: 2.4805080821205445

Epoch: 5| Step: 4
Training loss: 2.7995900875857345
Validation loss: 2.4765418861084805

Epoch: 5| Step: 5
Training loss: 2.5110297081092696
Validation loss: 2.4760259333843413

Epoch: 5| Step: 6
Training loss: 3.0052726822458755
Validation loss: 2.471500715299494

Epoch: 5| Step: 7
Training loss: 2.455741701603138
Validation loss: 2.478358619232154

Epoch: 5| Step: 8
Training loss: 2.7114883434868817
Validation loss: 2.4720317138236787

Epoch: 5| Step: 9
Training loss: 2.550643473200512
Validation loss: 2.4767065156765993

Epoch: 5| Step: 10
Training loss: 2.5694258531694008
Validation loss: 2.485125606235609

Epoch: 5| Step: 11
Training loss: 2.845691060372504
Validation loss: 2.4829294849744934

Epoch: 98| Step: 0
Training loss: 2.483604071620578
Validation loss: 2.4875795881200506

Epoch: 5| Step: 1
Training loss: 2.5357586302228197
Validation loss: 2.482522605775144

Epoch: 5| Step: 2
Training loss: 2.8502107107336916
Validation loss: 2.4770960629143866

Epoch: 5| Step: 3
Training loss: 2.724393052568372
Validation loss: 2.4825214092910355

Epoch: 5| Step: 4
Training loss: 1.877999894074101
Validation loss: 2.4782504477704306

Epoch: 5| Step: 5
Training loss: 3.1231957376869226
Validation loss: 2.491325751609365

Epoch: 5| Step: 6
Training loss: 2.748447066437347
Validation loss: 2.473767384973535

Epoch: 5| Step: 7
Training loss: 3.162728035285852
Validation loss: 2.472951629335812

Epoch: 5| Step: 8
Training loss: 2.5321997285444287
Validation loss: 2.474973254910213

Epoch: 5| Step: 9
Training loss: 2.282708838143838
Validation loss: 2.4787474459469694

Epoch: 5| Step: 10
Training loss: 2.1573600675924904
Validation loss: 2.475490309895413

Epoch: 5| Step: 11
Training loss: 2.3658150197236574
Validation loss: 2.479881128909114

Epoch: 99| Step: 0
Training loss: 3.0138387973761676
Validation loss: 2.4769380928453315

Epoch: 5| Step: 1
Training loss: 2.498473082593807
Validation loss: 2.484327835658965

Epoch: 5| Step: 2
Training loss: 2.59080098731249
Validation loss: 2.474913733195913

Epoch: 5| Step: 3
Training loss: 2.4530016631203577
Validation loss: 2.477847587191728

Epoch: 5| Step: 4
Training loss: 2.419858622243859
Validation loss: 2.4759159507714052

Epoch: 5| Step: 5
Training loss: 2.1917064005606557
Validation loss: 2.475164365769375

Epoch: 5| Step: 6
Training loss: 2.6109178744388357
Validation loss: 2.4762879348806957

Epoch: 5| Step: 7
Training loss: 2.823966156148869
Validation loss: 2.476374192805485

Epoch: 5| Step: 8
Training loss: 2.647711460216634
Validation loss: 2.478200513179072

Epoch: 5| Step: 9
Training loss: 2.4581309951875943
Validation loss: 2.4727507458187765

Epoch: 5| Step: 10
Training loss: 2.6722474312689197
Validation loss: 2.4770413526459234

Epoch: 5| Step: 11
Training loss: 2.6747865039086203
Validation loss: 2.469730126300542

Epoch: 100| Step: 0
Training loss: 2.077944181219426
Validation loss: 2.4767612734506894

Epoch: 5| Step: 1
Training loss: 2.1667283367281334
Validation loss: 2.474695695446902

Epoch: 5| Step: 2
Training loss: 2.511804748296908
Validation loss: 2.471493616916369

Epoch: 5| Step: 3
Training loss: 3.015822804342925
Validation loss: 2.472986943457659

Epoch: 5| Step: 4
Training loss: 2.3576825873985587
Validation loss: 2.4742187296035554

Epoch: 5| Step: 5
Training loss: 2.7074502727982455
Validation loss: 2.4675507590301353

Epoch: 5| Step: 6
Training loss: 2.7525576921700234
Validation loss: 2.4712171459635064

Epoch: 5| Step: 7
Training loss: 2.534264359134615
Validation loss: 2.467675244705452

Epoch: 5| Step: 8
Training loss: 2.817069008737236
Validation loss: 2.4791524964149336

Epoch: 5| Step: 9
Training loss: 2.7626746005983955
Validation loss: 2.4734725689405064

Epoch: 5| Step: 10
Training loss: 2.477944358601244
Validation loss: 2.474086205373453

Epoch: 5| Step: 11
Training loss: 2.769252660860438
Validation loss: 2.4675446980333766

Testing loss: 2.0558835107590245
