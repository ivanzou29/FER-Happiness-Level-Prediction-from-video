Epoch: 1| Step: 0
Training loss: 6.440115980442645
Validation loss: 5.862372849637049

Epoch: 5| Step: 1
Training loss: 5.478253983558449
Validation loss: 5.860280366251203

Epoch: 5| Step: 2
Training loss: 6.137759250984587
Validation loss: 5.858245856100909

Epoch: 5| Step: 3
Training loss: 6.538336746612962
Validation loss: 5.856281830583429

Epoch: 5| Step: 4
Training loss: 5.779550663467017
Validation loss: 5.854220368579074

Epoch: 5| Step: 5
Training loss: 5.973321093024474
Validation loss: 5.8522215176278065

Epoch: 5| Step: 6
Training loss: 5.91582024479287
Validation loss: 5.850117802588561

Epoch: 5| Step: 7
Training loss: 6.430526956705646
Validation loss: 5.84819477789401

Epoch: 5| Step: 8
Training loss: 5.617301080269029
Validation loss: 5.846013968466794

Epoch: 5| Step: 9
Training loss: 5.322918896260949
Validation loss: 5.843945124287357

Epoch: 5| Step: 10
Training loss: 5.810347620007948
Validation loss: 5.84177623742158

Epoch: 5| Step: 11
Training loss: 6.371858308853507
Validation loss: 5.839562001656057

Epoch: 2| Step: 0
Training loss: 5.079554523850158
Validation loss: 5.837388116661528

Epoch: 5| Step: 1
Training loss: 5.184040800593374
Validation loss: 5.835086595360695

Epoch: 5| Step: 2
Training loss: 5.419272905966787
Validation loss: 5.832723410827237

Epoch: 5| Step: 3
Training loss: 6.330988935264182
Validation loss: 5.830152211871356

Epoch: 5| Step: 4
Training loss: 6.718398541861383
Validation loss: 5.827645617039971

Epoch: 5| Step: 5
Training loss: 5.71052969378016
Validation loss: 5.824830788704597

Epoch: 5| Step: 6
Training loss: 5.822553574416737
Validation loss: 5.821845557206122

Epoch: 5| Step: 7
Training loss: 6.426405447931306
Validation loss: 5.818615024529499

Epoch: 5| Step: 8
Training loss: 6.190400955944722
Validation loss: 5.815308545204349

Epoch: 5| Step: 9
Training loss: 5.767862521560907
Validation loss: 5.81189516126841

Epoch: 5| Step: 10
Training loss: 6.435026415790679
Validation loss: 5.808104736704364

Epoch: 5| Step: 11
Training loss: 5.932796824055041
Validation loss: 5.804230279658326

Epoch: 3| Step: 0
Training loss: 5.281195465348058
Validation loss: 5.800307670467801

Epoch: 5| Step: 1
Training loss: 5.85096662311491
Validation loss: 5.795822164477682

Epoch: 5| Step: 2
Training loss: 6.3392287806327925
Validation loss: 5.791284447917533

Epoch: 5| Step: 3
Training loss: 5.350989362557463
Validation loss: 5.786362636632092

Epoch: 5| Step: 4
Training loss: 6.172398489468496
Validation loss: 5.781344858027129

Epoch: 5| Step: 5
Training loss: 5.998784259969369
Validation loss: 5.775747275066582

Epoch: 5| Step: 6
Training loss: 5.351844769015692
Validation loss: 5.770198934046774

Epoch: 5| Step: 7
Training loss: 6.026764936461786
Validation loss: 5.764372926582273

Epoch: 5| Step: 8
Training loss: 5.344868682304468
Validation loss: 5.757852458427006

Epoch: 5| Step: 9
Training loss: 5.89571737258515
Validation loss: 5.751097035453849

Epoch: 5| Step: 10
Training loss: 6.756532686796824
Validation loss: 5.744277885013709

Epoch: 5| Step: 11
Training loss: 6.853486959811099
Validation loss: 5.736965734114285

Epoch: 4| Step: 0
Training loss: 6.32755561433404
Validation loss: 5.72933493858367

Epoch: 5| Step: 1
Training loss: 5.999964396053217
Validation loss: 5.721146329896605

Epoch: 5| Step: 2
Training loss: 6.109080900250117
Validation loss: 5.712582533481522

Epoch: 5| Step: 3
Training loss: 6.0823762044918555
Validation loss: 5.704013570603077

Epoch: 5| Step: 4
Training loss: 5.549630697524498
Validation loss: 5.695117955838072

Epoch: 5| Step: 5
Training loss: 5.282457202425684
Validation loss: 5.685445043992285

Epoch: 5| Step: 6
Training loss: 5.58217253883252
Validation loss: 5.676173183266084

Epoch: 5| Step: 7
Training loss: 5.094006490978094
Validation loss: 5.666587550882543

Epoch: 5| Step: 8
Training loss: 4.76586553248008
Validation loss: 5.656499825540232

Epoch: 5| Step: 9
Training loss: 6.688912786115088
Validation loss: 5.64717938563849

Epoch: 5| Step: 10
Training loss: 5.720852824838009
Validation loss: 5.636450775466653

Epoch: 5| Step: 11
Training loss: 7.191681814638217
Validation loss: 5.625843140319464

Epoch: 5| Step: 0
Training loss: 6.553004779722536
Validation loss: 5.615059150062677

Epoch: 5| Step: 1
Training loss: 5.196798791745238
Validation loss: 5.603997808226366

Epoch: 5| Step: 2
Training loss: 6.39409276615894
Validation loss: 5.593251914752974

Epoch: 5| Step: 3
Training loss: 6.235423982180268
Validation loss: 5.581774133304742

Epoch: 5| Step: 4
Training loss: 4.960370369280851
Validation loss: 5.570159646068634

Epoch: 5| Step: 5
Training loss: 5.831700923121682
Validation loss: 5.559008041602015

Epoch: 5| Step: 6
Training loss: 5.914205370529072
Validation loss: 5.547300861469597

Epoch: 5| Step: 7
Training loss: 5.393027303820727
Validation loss: 5.535963898259437

Epoch: 5| Step: 8
Training loss: 6.09793338475761
Validation loss: 5.524798673813781

Epoch: 5| Step: 9
Training loss: 5.014284329070668
Validation loss: 5.512904395842613

Epoch: 5| Step: 10
Training loss: 4.56809737818889
Validation loss: 5.501862745137411

Epoch: 5| Step: 11
Training loss: 5.178487647370113
Validation loss: 5.490063918308496

Epoch: 6| Step: 0
Training loss: 6.025200374326255
Validation loss: 5.4791441096239195

Epoch: 5| Step: 1
Training loss: 5.108268407976395
Validation loss: 5.467628974457342

Epoch: 5| Step: 2
Training loss: 5.75967488907845
Validation loss: 5.456641774715973

Epoch: 5| Step: 3
Training loss: 5.98679743011556
Validation loss: 5.445717860804531

Epoch: 5| Step: 4
Training loss: 6.323459289829952
Validation loss: 5.434616325391558

Epoch: 5| Step: 5
Training loss: 5.287820374362525
Validation loss: 5.4233721334331255

Epoch: 5| Step: 6
Training loss: 4.7540358413674015
Validation loss: 5.412241076589272

Epoch: 5| Step: 7
Training loss: 6.165103645536308
Validation loss: 5.401713575641855

Epoch: 5| Step: 8
Training loss: 5.066918787622929
Validation loss: 5.39071095715973

Epoch: 5| Step: 9
Training loss: 5.427673229684376
Validation loss: 5.38005425625544

Epoch: 5| Step: 10
Training loss: 5.0440482617458455
Validation loss: 5.369540798519737

Epoch: 5| Step: 11
Training loss: 4.350155943782877
Validation loss: 5.359048861264302

Epoch: 7| Step: 0
Training loss: 5.392731097579027
Validation loss: 5.349313238219483

Epoch: 5| Step: 1
Training loss: 5.307609551081213
Validation loss: 5.3399222795376415

Epoch: 5| Step: 2
Training loss: 5.868150979895759
Validation loss: 5.330312330245186

Epoch: 5| Step: 3
Training loss: 5.57531445219413
Validation loss: 5.320918253631952

Epoch: 5| Step: 4
Training loss: 5.073269350715298
Validation loss: 5.312051477384856

Epoch: 5| Step: 5
Training loss: 5.550710292418999
Validation loss: 5.303157879876027

Epoch: 5| Step: 6
Training loss: 5.112341716526594
Validation loss: 5.294237123286051

Epoch: 5| Step: 7
Training loss: 5.236606406956413
Validation loss: 5.285223224344292

Epoch: 5| Step: 8
Training loss: 5.034847702859661
Validation loss: 5.27666084394457

Epoch: 5| Step: 9
Training loss: 5.552790879999609
Validation loss: 5.2680208696441

Epoch: 5| Step: 10
Training loss: 5.657881864908954
Validation loss: 5.259862008140109

Epoch: 5| Step: 11
Training loss: 6.527378230571705
Validation loss: 5.2506867292641495

Epoch: 8| Step: 0
Training loss: 5.836480989899563
Validation loss: 5.241827075466728

Epoch: 5| Step: 1
Training loss: 5.241650799766182
Validation loss: 5.2331068106340926

Epoch: 5| Step: 2
Training loss: 5.069240086354225
Validation loss: 5.224227330390125

Epoch: 5| Step: 3
Training loss: 5.549367253430985
Validation loss: 5.215386652695411

Epoch: 5| Step: 4
Training loss: 4.783404295037194
Validation loss: 5.207037667921327

Epoch: 5| Step: 5
Training loss: 5.477312458402183
Validation loss: 5.198765781540981

Epoch: 5| Step: 6
Training loss: 4.715636381890153
Validation loss: 5.189953403863986

Epoch: 5| Step: 7
Training loss: 5.356103727286391
Validation loss: 5.182572372220716

Epoch: 5| Step: 8
Training loss: 5.5756115633551735
Validation loss: 5.1746765877227965

Epoch: 5| Step: 9
Training loss: 5.271665283807571
Validation loss: 5.1673452818675845

Epoch: 5| Step: 10
Training loss: 5.3555396233229775
Validation loss: 5.1594106600950225

Epoch: 5| Step: 11
Training loss: 6.260927946399
Validation loss: 5.152170374539064

Epoch: 9| Step: 0
Training loss: 5.900518633790176
Validation loss: 5.14494581973134

Epoch: 5| Step: 1
Training loss: 4.739642042977153
Validation loss: 5.137100719952911

Epoch: 5| Step: 2
Training loss: 5.533843558506989
Validation loss: 5.130376314101434

Epoch: 5| Step: 3
Training loss: 5.01120722740305
Validation loss: 5.12346553703688

Epoch: 5| Step: 4
Training loss: 5.83585677288962
Validation loss: 5.1171960029822605

Epoch: 5| Step: 5
Training loss: 4.546874580514371
Validation loss: 5.110343343605543

Epoch: 5| Step: 6
Training loss: 5.239342908354837
Validation loss: 5.104228562998295

Epoch: 5| Step: 7
Training loss: 4.576879546754322
Validation loss: 5.09783438691635

Epoch: 5| Step: 8
Training loss: 5.641325085590572
Validation loss: 5.0914625168542305

Epoch: 5| Step: 9
Training loss: 5.196588849913838
Validation loss: 5.085764001561982

Epoch: 5| Step: 10
Training loss: 5.091661083428567
Validation loss: 5.079832015088566

Epoch: 5| Step: 11
Training loss: 5.549077673902741
Validation loss: 5.073879583984112

Epoch: 10| Step: 0
Training loss: 5.739451809003286
Validation loss: 5.067604176260193

Epoch: 5| Step: 1
Training loss: 5.568804308008896
Validation loss: 5.061785203996281

Epoch: 5| Step: 2
Training loss: 5.006624982603617
Validation loss: 5.056080794676238

Epoch: 5| Step: 3
Training loss: 4.987044142921462
Validation loss: 5.050542123104591

Epoch: 5| Step: 4
Training loss: 5.848632404851589
Validation loss: 5.045457725604609

Epoch: 5| Step: 5
Training loss: 5.451096471677077
Validation loss: 5.039281535747944

Epoch: 5| Step: 6
Training loss: 4.381112107135366
Validation loss: 5.0333308622004695

Epoch: 5| Step: 7
Training loss: 4.723214771951666
Validation loss: 5.028140100077511

Epoch: 5| Step: 8
Training loss: 5.1128998243313415
Validation loss: 5.021892058733817

Epoch: 5| Step: 9
Training loss: 5.180313831970518
Validation loss: 5.017217508070077

Epoch: 5| Step: 10
Training loss: 4.799767830320086
Validation loss: 5.011965152176872

Epoch: 5| Step: 11
Training loss: 4.213483674067203
Validation loss: 5.006555313153767

Epoch: 11| Step: 0
Training loss: 4.505993137102111
Validation loss: 5.00131482479661

Epoch: 5| Step: 1
Training loss: 4.92471318837889
Validation loss: 4.9963934527378004

Epoch: 5| Step: 2
Training loss: 5.039546594358364
Validation loss: 4.990456489452298

Epoch: 5| Step: 3
Training loss: 5.258668554938895
Validation loss: 4.984990766510978

Epoch: 5| Step: 4
Training loss: 5.125679715370017
Validation loss: 4.980195735853495

Epoch: 5| Step: 5
Training loss: 4.681457694199332
Validation loss: 4.975309923956146

Epoch: 5| Step: 6
Training loss: 6.015537489217375
Validation loss: 4.970664601154847

Epoch: 5| Step: 7
Training loss: 4.926270087819933
Validation loss: 4.964688630560854

Epoch: 5| Step: 8
Training loss: 5.503349844624554
Validation loss: 4.959049127773729

Epoch: 5| Step: 9
Training loss: 4.849819785633792
Validation loss: 4.953599552080993

Epoch: 5| Step: 10
Training loss: 5.105699996556201
Validation loss: 4.948328433387174

Epoch: 5| Step: 11
Training loss: 5.11642147474926
Validation loss: 4.943764265950514

Epoch: 12| Step: 0
Training loss: 4.6892635842578185
Validation loss: 4.939310080077371

Epoch: 5| Step: 1
Training loss: 5.918574638951167
Validation loss: 4.934576496941009

Epoch: 5| Step: 2
Training loss: 4.844334524017806
Validation loss: 4.9288144313345885

Epoch: 5| Step: 3
Training loss: 4.716430902598317
Validation loss: 4.923279811053382

Epoch: 5| Step: 4
Training loss: 5.231911697377477
Validation loss: 4.916949072771604

Epoch: 5| Step: 5
Training loss: 4.615438527012451
Validation loss: 4.912179275733283

Epoch: 5| Step: 6
Training loss: 5.4466509056719286
Validation loss: 4.907370186344013

Epoch: 5| Step: 7
Training loss: 4.830814143527635
Validation loss: 4.902082937326779

Epoch: 5| Step: 8
Training loss: 4.522715983718717
Validation loss: 4.897140834257305

Epoch: 5| Step: 9
Training loss: 5.439110528371689
Validation loss: 4.890953800414008

Epoch: 5| Step: 10
Training loss: 5.3789853247410235
Validation loss: 4.885945275941685

Epoch: 5| Step: 11
Training loss: 2.274389637823716
Validation loss: 4.880050366212112

Epoch: 13| Step: 0
Training loss: 5.333828108407606
Validation loss: 4.875141883480809

Epoch: 5| Step: 1
Training loss: 5.270274297246102
Validation loss: 4.870186434433818

Epoch: 5| Step: 2
Training loss: 4.620951762400218
Validation loss: 4.864899025366102

Epoch: 5| Step: 3
Training loss: 4.735492033162191
Validation loss: 4.859894032781718

Epoch: 5| Step: 4
Training loss: 5.098805919807237
Validation loss: 4.854694283207187

Epoch: 5| Step: 5
Training loss: 5.391117858470172
Validation loss: 4.849565267906406

Epoch: 5| Step: 6
Training loss: 4.713859803087494
Validation loss: 4.8444999606459

Epoch: 5| Step: 7
Training loss: 5.685429122685642
Validation loss: 4.839897050787262

Epoch: 5| Step: 8
Training loss: 5.365112258860098
Validation loss: 4.834093900011334

Epoch: 5| Step: 9
Training loss: 4.036186803073138
Validation loss: 4.828403592430807

Epoch: 5| Step: 10
Training loss: 4.575823416897439
Validation loss: 4.8227709946627835

Epoch: 5| Step: 11
Training loss: 2.999543473157754
Validation loss: 4.818095525355427

Epoch: 14| Step: 0
Training loss: 4.6180396415162175
Validation loss: 4.813022279678963

Epoch: 5| Step: 1
Training loss: 5.575750620307404
Validation loss: 4.8075247804846475

Epoch: 5| Step: 2
Training loss: 4.42138410343828
Validation loss: 4.802045779243416

Epoch: 5| Step: 3
Training loss: 5.393891956145424
Validation loss: 4.796974876929669

Epoch: 5| Step: 4
Training loss: 5.392498895877589
Validation loss: 4.791291540085059

Epoch: 5| Step: 5
Training loss: 4.338833228576594
Validation loss: 4.785801144694867

Epoch: 5| Step: 6
Training loss: 4.608442619550074
Validation loss: 4.780717624786549

Epoch: 5| Step: 7
Training loss: 5.019752016667546
Validation loss: 4.7743562520736

Epoch: 5| Step: 8
Training loss: 5.406474026134193
Validation loss: 4.769183380246086

Epoch: 5| Step: 9
Training loss: 3.9599299908238987
Validation loss: 4.763139320375033

Epoch: 5| Step: 10
Training loss: 5.1178563270572
Validation loss: 4.7574249093000915

Epoch: 5| Step: 11
Training loss: 4.377219808642677
Validation loss: 4.752380903739375

Epoch: 15| Step: 0
Training loss: 4.206101281993191
Validation loss: 4.747261797389876

Epoch: 5| Step: 1
Training loss: 4.689201554775981
Validation loss: 4.741578969608175

Epoch: 5| Step: 2
Training loss: 4.725989844570799
Validation loss: 4.735619518848617

Epoch: 5| Step: 3
Training loss: 4.721318436445514
Validation loss: 4.731127179935626

Epoch: 5| Step: 4
Training loss: 4.812626626466712
Validation loss: 4.7265106870895695

Epoch: 5| Step: 5
Training loss: 5.20265759267428
Validation loss: 4.721349762123552

Epoch: 5| Step: 6
Training loss: 4.6048603254543305
Validation loss: 4.715995822699457

Epoch: 5| Step: 7
Training loss: 4.892942226970865
Validation loss: 4.710690122301594

Epoch: 5| Step: 8
Training loss: 5.200608753371056
Validation loss: 4.70541533489924

Epoch: 5| Step: 9
Training loss: 4.840389144007916
Validation loss: 4.699739363389866

Epoch: 5| Step: 10
Training loss: 5.229936864701585
Validation loss: 4.693809890872925

Epoch: 5| Step: 11
Training loss: 5.309839457583216
Validation loss: 4.688011387374488

Epoch: 16| Step: 0
Training loss: 5.031463239427663
Validation loss: 4.683057400639667

Epoch: 5| Step: 1
Training loss: 4.588715369941558
Validation loss: 4.6776703789673

Epoch: 5| Step: 2
Training loss: 5.622859293176326
Validation loss: 4.6729750725538235

Epoch: 5| Step: 3
Training loss: 4.355480354875235
Validation loss: 4.666685413708951

Epoch: 5| Step: 4
Training loss: 4.922792185747102
Validation loss: 4.661452491230918

Epoch: 5| Step: 5
Training loss: 5.2371439883338144
Validation loss: 4.656246176767167

Epoch: 5| Step: 6
Training loss: 4.634993813190631
Validation loss: 4.650410952918152

Epoch: 5| Step: 7
Training loss: 5.056633269657165
Validation loss: 4.644248451155305

Epoch: 5| Step: 8
Training loss: 4.715837805252035
Validation loss: 4.639767979734751

Epoch: 5| Step: 9
Training loss: 4.642645296566543
Validation loss: 4.634387884381476

Epoch: 5| Step: 10
Training loss: 3.755591356669873
Validation loss: 4.628968915769998

Epoch: 5| Step: 11
Training loss: 3.7652733349716248
Validation loss: 4.6239795590084185

Epoch: 17| Step: 0
Training loss: 4.780095578119951
Validation loss: 4.619175869549847

Epoch: 5| Step: 1
Training loss: 4.271374973593288
Validation loss: 4.613610566239781

Epoch: 5| Step: 2
Training loss: 4.564556546686163
Validation loss: 4.608620973109901

Epoch: 5| Step: 3
Training loss: 4.863482245156262
Validation loss: 4.603173695445037

Epoch: 5| Step: 4
Training loss: 5.480503030507987
Validation loss: 4.597568602956767

Epoch: 5| Step: 5
Training loss: 5.08581186540775
Validation loss: 4.592682409469291

Epoch: 5| Step: 6
Training loss: 4.353648153335544
Validation loss: 4.587319243366812

Epoch: 5| Step: 7
Training loss: 4.448026395184257
Validation loss: 4.582159397753897

Epoch: 5| Step: 8
Training loss: 4.479831214518164
Validation loss: 4.576781222143127

Epoch: 5| Step: 9
Training loss: 4.837531842267415
Validation loss: 4.57163389399778

Epoch: 5| Step: 10
Training loss: 4.807678185075411
Validation loss: 4.565209041710241

Epoch: 5| Step: 11
Training loss: 3.7248252161994597
Validation loss: 4.560625509908817

Epoch: 18| Step: 0
Training loss: 5.214808271766019
Validation loss: 4.554860468917693

Epoch: 5| Step: 1
Training loss: 5.005023149709298
Validation loss: 4.549076984739984

Epoch: 5| Step: 2
Training loss: 3.861472606126607
Validation loss: 4.543204662509538

Epoch: 5| Step: 3
Training loss: 4.644390184267017
Validation loss: 4.537550962878276

Epoch: 5| Step: 4
Training loss: 4.931049817643008
Validation loss: 4.532928690779408

Epoch: 5| Step: 5
Training loss: 4.177117300807119
Validation loss: 4.526250295216753

Epoch: 5| Step: 6
Training loss: 5.112715349581825
Validation loss: 4.521207682613927

Epoch: 5| Step: 7
Training loss: 4.530250807465304
Validation loss: 4.516160574614629

Epoch: 5| Step: 8
Training loss: 4.007638551978666
Validation loss: 4.510123186790357

Epoch: 5| Step: 9
Training loss: 4.447792903181838
Validation loss: 4.504634880952096

Epoch: 5| Step: 10
Training loss: 4.976246103622034
Validation loss: 4.49948170114275

Epoch: 5| Step: 11
Training loss: 5.018965419834854
Validation loss: 4.494004105062835

Epoch: 19| Step: 0
Training loss: 4.838853292897559
Validation loss: 4.488856301737574

Epoch: 5| Step: 1
Training loss: 4.8660701246747315
Validation loss: 4.482977752458456

Epoch: 5| Step: 2
Training loss: 3.8173294746769377
Validation loss: 4.477134042307432

Epoch: 5| Step: 3
Training loss: 4.589714509483619
Validation loss: 4.471417429022325

Epoch: 5| Step: 4
Training loss: 4.144130849237928
Validation loss: 4.4661155707072675

Epoch: 5| Step: 5
Training loss: 5.37941117365045
Validation loss: 4.460578837231344

Epoch: 5| Step: 6
Training loss: 5.122618703514034
Validation loss: 4.454380282331154

Epoch: 5| Step: 7
Training loss: 4.655563611125021
Validation loss: 4.447549615704385

Epoch: 5| Step: 8
Training loss: 4.425836197460648
Validation loss: 4.441194876520128

Epoch: 5| Step: 9
Training loss: 3.8431852592623894
Validation loss: 4.4359943987762565

Epoch: 5| Step: 10
Training loss: 4.506274828796132
Validation loss: 4.4311665796588935

Epoch: 5| Step: 11
Training loss: 4.683179160914373
Validation loss: 4.424464973605066

Epoch: 20| Step: 0
Training loss: 4.810004441859996
Validation loss: 4.4195593037489544

Epoch: 5| Step: 1
Training loss: 5.33899963895629
Validation loss: 4.412922516748911

Epoch: 5| Step: 2
Training loss: 3.920853196734639
Validation loss: 4.4071939868541605

Epoch: 5| Step: 3
Training loss: 3.6192522191291654
Validation loss: 4.402122422041918

Epoch: 5| Step: 4
Training loss: 5.037589492192243
Validation loss: 4.399035917310499

Epoch: 5| Step: 5
Training loss: 4.5404193576943515
Validation loss: 4.391773422121136

Epoch: 5| Step: 6
Training loss: 4.962316414538481
Validation loss: 4.386185950841377

Epoch: 5| Step: 7
Training loss: 4.673063095231713
Validation loss: 4.381027533650959

Epoch: 5| Step: 8
Training loss: 3.9647487384705857
Validation loss: 4.374469961120437

Epoch: 5| Step: 9
Training loss: 4.1291533859044485
Validation loss: 4.368524050019952

Epoch: 5| Step: 10
Training loss: 4.459853272697349
Validation loss: 4.362441357470771

Epoch: 5| Step: 11
Training loss: 4.342247572761633
Validation loss: 4.3566537245816255

Epoch: 21| Step: 0
Training loss: 5.092861168198093
Validation loss: 4.350890901653888

Epoch: 5| Step: 1
Training loss: 3.2178838360708872
Validation loss: 4.344793766045305

Epoch: 5| Step: 2
Training loss: 4.0331142166350595
Validation loss: 4.33790191964951

Epoch: 5| Step: 3
Training loss: 4.379630336054992
Validation loss: 4.331769966888922

Epoch: 5| Step: 4
Training loss: 4.7418162469227
Validation loss: 4.3257073674716855

Epoch: 5| Step: 5
Training loss: 5.0554083615255285
Validation loss: 4.3214967333647305

Epoch: 5| Step: 6
Training loss: 4.766504825610006
Validation loss: 4.314925295019913

Epoch: 5| Step: 7
Training loss: 4.710776761224395
Validation loss: 4.308527300666078

Epoch: 5| Step: 8
Training loss: 3.6113796199512747
Validation loss: 4.303361170282509

Epoch: 5| Step: 9
Training loss: 3.839555265779756
Validation loss: 4.298422743895502

Epoch: 5| Step: 10
Training loss: 4.844402638428991
Validation loss: 4.292959225394988

Epoch: 5| Step: 11
Training loss: 5.419642975650749
Validation loss: 4.28748653435701

Epoch: 22| Step: 0
Training loss: 4.113721977887244
Validation loss: 4.281794330121178

Epoch: 5| Step: 1
Training loss: 4.514325968130038
Validation loss: 4.276134613860706

Epoch: 5| Step: 2
Training loss: 3.853811354196693
Validation loss: 4.270538969672826

Epoch: 5| Step: 3
Training loss: 4.799503364301906
Validation loss: 4.265746314031916

Epoch: 5| Step: 4
Training loss: 4.391061564289091
Validation loss: 4.26053183041645

Epoch: 5| Step: 5
Training loss: 4.61959172116845
Validation loss: 4.254208453898205

Epoch: 5| Step: 6
Training loss: 3.8798404118073915
Validation loss: 4.2495480418648155

Epoch: 5| Step: 7
Training loss: 4.7809011294672485
Validation loss: 4.245392335233015

Epoch: 5| Step: 8
Training loss: 4.354672099929039
Validation loss: 4.2398352192777145

Epoch: 5| Step: 9
Training loss: 4.560120471567606
Validation loss: 4.233618641735749

Epoch: 5| Step: 10
Training loss: 4.400336443435853
Validation loss: 4.228348820474661

Epoch: 5| Step: 11
Training loss: 3.545466878731713
Validation loss: 4.223201061371323

Epoch: 23| Step: 0
Training loss: 4.587572992144316
Validation loss: 4.218229242844429

Epoch: 5| Step: 1
Training loss: 4.249740143853881
Validation loss: 4.212228967416427

Epoch: 5| Step: 2
Training loss: 4.469760593770655
Validation loss: 4.207117356670957

Epoch: 5| Step: 3
Training loss: 4.956404794438013
Validation loss: 4.201959133944758

Epoch: 5| Step: 4
Training loss: 4.817895416201464
Validation loss: 4.196490955178958

Epoch: 5| Step: 5
Training loss: 4.678752824933817
Validation loss: 4.191124405617887

Epoch: 5| Step: 6
Training loss: 3.760447508173855
Validation loss: 4.185720815410137

Epoch: 5| Step: 7
Training loss: 4.3158850169593554
Validation loss: 4.179991457335703

Epoch: 5| Step: 8
Training loss: 4.372806980356116
Validation loss: 4.174859335617901

Epoch: 5| Step: 9
Training loss: 3.4298307002244512
Validation loss: 4.170112318444319

Epoch: 5| Step: 10
Training loss: 3.850291322857794
Validation loss: 4.164216454423116

Epoch: 5| Step: 11
Training loss: 3.3298696324028705
Validation loss: 4.159280795304257

Epoch: 24| Step: 0
Training loss: 4.08343604341421
Validation loss: 4.154500200980841

Epoch: 5| Step: 1
Training loss: 4.448293748843592
Validation loss: 4.14979568824948

Epoch: 5| Step: 2
Training loss: 3.6470546021156562
Validation loss: 4.145440766743792

Epoch: 5| Step: 3
Training loss: 4.839035594792716
Validation loss: 4.141114811746502

Epoch: 5| Step: 4
Training loss: 3.490853893455947
Validation loss: 4.135702275455535

Epoch: 5| Step: 5
Training loss: 3.6994056533597868
Validation loss: 4.131273763206418

Epoch: 5| Step: 6
Training loss: 4.551750165093608
Validation loss: 4.126481921906528

Epoch: 5| Step: 7
Training loss: 3.8552612125151304
Validation loss: 4.121695827959937

Epoch: 5| Step: 8
Training loss: 4.502912638393499
Validation loss: 4.1169215001191

Epoch: 5| Step: 9
Training loss: 4.939407173446795
Validation loss: 4.112411827371236

Epoch: 5| Step: 10
Training loss: 4.609964417094766
Validation loss: 4.107327530146667

Epoch: 5| Step: 11
Training loss: 3.7537026245908005
Validation loss: 4.101870870956737

Epoch: 25| Step: 0
Training loss: 3.9727407500846077
Validation loss: 4.0967955338379936

Epoch: 5| Step: 1
Training loss: 4.105319382466566
Validation loss: 4.092137803082655

Epoch: 5| Step: 2
Training loss: 5.171185127646239
Validation loss: 4.087028523083865

Epoch: 5| Step: 3
Training loss: 4.27968774957785
Validation loss: 4.082205644255875

Epoch: 5| Step: 4
Training loss: 3.5439910591391595
Validation loss: 4.077631285928018

Epoch: 5| Step: 5
Training loss: 4.34308031806573
Validation loss: 4.072517105497496

Epoch: 5| Step: 6
Training loss: 4.047010264842459
Validation loss: 4.0669714357479645

Epoch: 5| Step: 7
Training loss: 3.690837061358978
Validation loss: 4.062139500003929

Epoch: 5| Step: 8
Training loss: 4.542748745210258
Validation loss: 4.057408560887751

Epoch: 5| Step: 9
Training loss: 3.9455232771666755
Validation loss: 4.052290416744335

Epoch: 5| Step: 10
Training loss: 4.164953998801642
Validation loss: 4.047743086824311

Epoch: 5| Step: 11
Training loss: 5.189698270578786
Validation loss: 4.0428312072454755

Epoch: 26| Step: 0
Training loss: 4.406182904104621
Validation loss: 4.037374245699833

Epoch: 5| Step: 1
Training loss: 4.148052190498289
Validation loss: 4.031918290410001

Epoch: 5| Step: 2
Training loss: 4.081581025186335
Validation loss: 4.026905888244524

Epoch: 5| Step: 3
Training loss: 3.9505447591494227
Validation loss: 4.022003876410282

Epoch: 5| Step: 4
Training loss: 4.522678660780219
Validation loss: 4.017197890919229

Epoch: 5| Step: 5
Training loss: 4.528536490520053
Validation loss: 4.012502601757374

Epoch: 5| Step: 6
Training loss: 3.530379466552632
Validation loss: 4.007522760914787

Epoch: 5| Step: 7
Training loss: 4.183022225857353
Validation loss: 4.002572533758183

Epoch: 5| Step: 8
Training loss: 3.7885798510659416
Validation loss: 3.997207928775495

Epoch: 5| Step: 9
Training loss: 4.095344989855861
Validation loss: 3.9927045135254193

Epoch: 5| Step: 10
Training loss: 4.093346961761882
Validation loss: 3.987778430493554

Epoch: 5| Step: 11
Training loss: 4.878894130914692
Validation loss: 3.9832659405762625

Epoch: 27| Step: 0
Training loss: 4.079300166677308
Validation loss: 3.9779468817139567

Epoch: 5| Step: 1
Training loss: 4.587984372379258
Validation loss: 3.9732287009168026

Epoch: 5| Step: 2
Training loss: 3.9999821185665994
Validation loss: 3.968404324313253

Epoch: 5| Step: 3
Training loss: 4.476066734995993
Validation loss: 3.963381242283381

Epoch: 5| Step: 4
Training loss: 4.0096414716836355
Validation loss: 3.958636044756319

Epoch: 5| Step: 5
Training loss: 4.100404877559301
Validation loss: 3.9537601387922274

Epoch: 5| Step: 6
Training loss: 4.299981786999832
Validation loss: 3.949084507603486

Epoch: 5| Step: 7
Training loss: 3.3273744408400545
Validation loss: 3.9445491795149055

Epoch: 5| Step: 8
Training loss: 4.253392828721552
Validation loss: 3.939499065009633

Epoch: 5| Step: 9
Training loss: 4.257232570525822
Validation loss: 3.9347196178081303

Epoch: 5| Step: 10
Training loss: 3.797566919898634
Validation loss: 3.9299133519010976

Epoch: 5| Step: 11
Training loss: 1.4386787557320864
Validation loss: 3.925042690563281

Epoch: 28| Step: 0
Training loss: 4.7230475857558805
Validation loss: 3.921134574876744

Epoch: 5| Step: 1
Training loss: 4.203028340983132
Validation loss: 3.9168069016261784

Epoch: 5| Step: 2
Training loss: 3.3313811943744063
Validation loss: 3.912506545511281

Epoch: 5| Step: 3
Training loss: 3.0967797750697033
Validation loss: 3.9080918610948827

Epoch: 5| Step: 4
Training loss: 4.1400279640322175
Validation loss: 3.9035766354518935

Epoch: 5| Step: 5
Training loss: 4.488943079399958
Validation loss: 3.8994959513664464

Epoch: 5| Step: 6
Training loss: 4.532410361260477
Validation loss: 3.8952739011318798

Epoch: 5| Step: 7
Training loss: 4.309087315196831
Validation loss: 3.89074323339196

Epoch: 5| Step: 8
Training loss: 3.6429239635590065
Validation loss: 3.8861436274594134

Epoch: 5| Step: 9
Training loss: 3.5096770430877746
Validation loss: 3.881858519162568

Epoch: 5| Step: 10
Training loss: 4.051232543644053
Validation loss: 3.8776061820423564

Epoch: 5| Step: 11
Training loss: 4.0326814697451345
Validation loss: 3.8732120480619203

Epoch: 29| Step: 0
Training loss: 4.264150735033749
Validation loss: 3.868689066356201

Epoch: 5| Step: 1
Training loss: 3.6102231833240785
Validation loss: 3.864552195270191

Epoch: 5| Step: 2
Training loss: 3.8404593920096075
Validation loss: 3.8600917155812207

Epoch: 5| Step: 3
Training loss: 3.8965429927843345
Validation loss: 3.856069170866308

Epoch: 5| Step: 4
Training loss: 3.5287142400926177
Validation loss: 3.852082156189236

Epoch: 5| Step: 5
Training loss: 4.471075346630721
Validation loss: 3.8476031252942087

Epoch: 5| Step: 6
Training loss: 3.594572288313741
Validation loss: 3.8432330582521423

Epoch: 5| Step: 7
Training loss: 4.707371818916402
Validation loss: 3.8389589746241826

Epoch: 5| Step: 8
Training loss: 3.348039816534168
Validation loss: 3.8350621588857323

Epoch: 5| Step: 9
Training loss: 3.728636606290892
Validation loss: 3.8307055436509607

Epoch: 5| Step: 10
Training loss: 4.411581074502009
Validation loss: 3.8265774278101645

Epoch: 5| Step: 11
Training loss: 4.66878956237944
Validation loss: 3.8219389986266696

Epoch: 30| Step: 0
Training loss: 3.5110047222334946
Validation loss: 3.8176066379437983

Epoch: 5| Step: 1
Training loss: 4.254392485769694
Validation loss: 3.8128520146437386

Epoch: 5| Step: 2
Training loss: 3.3836744941373116
Validation loss: 3.8085561323345902

Epoch: 5| Step: 3
Training loss: 4.138595371520381
Validation loss: 3.8041610666897445

Epoch: 5| Step: 4
Training loss: 3.831793945928614
Validation loss: 3.7999140033276873

Epoch: 5| Step: 5
Training loss: 4.022587421574451
Validation loss: 3.795106462854129

Epoch: 5| Step: 6
Training loss: 4.232080717820542
Validation loss: 3.790462735931076

Epoch: 5| Step: 7
Training loss: 3.9722397247379386
Validation loss: 3.7862995416996252

Epoch: 5| Step: 8
Training loss: 4.025583705870943
Validation loss: 3.782021141761069

Epoch: 5| Step: 9
Training loss: 3.960080266582161
Validation loss: 3.7775263198130857

Epoch: 5| Step: 10
Training loss: 3.9645375401305625
Validation loss: 3.772932778374436

Epoch: 5| Step: 11
Training loss: 3.0338303113444276
Validation loss: 3.7687927313259415

Epoch: 31| Step: 0
Training loss: 3.977364989362424
Validation loss: 3.7640802056009757

Epoch: 5| Step: 1
Training loss: 4.0347743042856115
Validation loss: 3.7603038901257393

Epoch: 5| Step: 2
Training loss: 3.3851807653937906
Validation loss: 3.755683671316628

Epoch: 5| Step: 3
Training loss: 3.552675587491216
Validation loss: 3.751642667418806

Epoch: 5| Step: 4
Training loss: 3.7361652759531774
Validation loss: 3.747396699305742

Epoch: 5| Step: 5
Training loss: 3.6784484461782805
Validation loss: 3.74337642421248

Epoch: 5| Step: 6
Training loss: 3.5139941692705583
Validation loss: 3.739334694115252

Epoch: 5| Step: 7
Training loss: 4.359219456020432
Validation loss: 3.7350714604692246

Epoch: 5| Step: 8
Training loss: 3.9099611277489466
Validation loss: 3.73088753631415

Epoch: 5| Step: 9
Training loss: 4.268537819365836
Validation loss: 3.7266893611829977

Epoch: 5| Step: 10
Training loss: 4.2409648222180545
Validation loss: 3.7224873747653153

Epoch: 5| Step: 11
Training loss: 3.14276171824263
Validation loss: 3.7179582805556946

Epoch: 32| Step: 0
Training loss: 3.271065155042797
Validation loss: 3.7138764371847874

Epoch: 5| Step: 1
Training loss: 3.416730383922392
Validation loss: 3.7095518771140465

Epoch: 5| Step: 2
Training loss: 3.994996159710429
Validation loss: 3.7053748591618323

Epoch: 5| Step: 3
Training loss: 3.872935452688428
Validation loss: 3.7012127903376935

Epoch: 5| Step: 4
Training loss: 4.082157640462567
Validation loss: 3.697005558153851

Epoch: 5| Step: 5
Training loss: 4.485535581116584
Validation loss: 3.6930699496454773

Epoch: 5| Step: 6
Training loss: 3.960198508402344
Validation loss: 3.6886333297260894

Epoch: 5| Step: 7
Training loss: 3.4875841629647026
Validation loss: 3.6843834492697347

Epoch: 5| Step: 8
Training loss: 3.735277138760219
Validation loss: 3.6799388240829383

Epoch: 5| Step: 9
Training loss: 3.6488964764165988
Validation loss: 3.6758706125551095

Epoch: 5| Step: 10
Training loss: 3.98587426793791
Validation loss: 3.671792068627103

Epoch: 5| Step: 11
Training loss: 3.9252464119894976
Validation loss: 3.6673271747477996

Epoch: 33| Step: 0
Training loss: 4.245102922070291
Validation loss: 3.663063379426912

Epoch: 5| Step: 1
Training loss: 2.9592902198579103
Validation loss: 3.6586299388593715

Epoch: 5| Step: 2
Training loss: 3.622159963461487
Validation loss: 3.6543556533509265

Epoch: 5| Step: 3
Training loss: 3.3057180110073423
Validation loss: 3.650232814087454

Epoch: 5| Step: 4
Training loss: 4.252417381780296
Validation loss: 3.6462146922884466

Epoch: 5| Step: 5
Training loss: 3.5656236038405873
Validation loss: 3.6418531090055715

Epoch: 5| Step: 6
Training loss: 4.165772965272274
Validation loss: 3.6380368257178817

Epoch: 5| Step: 7
Training loss: 4.293851031096223
Validation loss: 3.6336709160253386

Epoch: 5| Step: 8
Training loss: 4.24645534123319
Validation loss: 3.6295208802271386

Epoch: 5| Step: 9
Training loss: 2.9283895236685202
Validation loss: 3.62524907034738

Epoch: 5| Step: 10
Training loss: 3.71635706229274
Validation loss: 3.620602170737358

Epoch: 5| Step: 11
Training loss: 3.2058335180623816
Validation loss: 3.616706942555234

Epoch: 34| Step: 0
Training loss: 3.7552268159634585
Validation loss: 3.612126761540002

Epoch: 5| Step: 1
Training loss: 3.9182367356785996
Validation loss: 3.607921830750104

Epoch: 5| Step: 2
Training loss: 3.907685283190157
Validation loss: 3.603978784254207

Epoch: 5| Step: 3
Training loss: 3.7009480833974715
Validation loss: 3.599404605002514

Epoch: 5| Step: 4
Training loss: 3.654412614874437
Validation loss: 3.5952660113438504

Epoch: 5| Step: 5
Training loss: 3.844659341074782
Validation loss: 3.590834399636524

Epoch: 5| Step: 6
Training loss: 3.240187577363234
Validation loss: 3.586272568240001

Epoch: 5| Step: 7
Training loss: 4.111183145825604
Validation loss: 3.581993879361109

Epoch: 5| Step: 8
Training loss: 4.043075132582866
Validation loss: 3.577908927246006

Epoch: 5| Step: 9
Training loss: 3.0315367572864442
Validation loss: 3.573788687536728

Epoch: 5| Step: 10
Training loss: 3.7221455178652745
Validation loss: 3.569836020586036

Epoch: 5| Step: 11
Training loss: 3.4987368347857934
Validation loss: 3.565894801558062

Epoch: 35| Step: 0
Training loss: 3.5000444136935105
Validation loss: 3.561849060597805

Epoch: 5| Step: 1
Training loss: 3.9460501708269744
Validation loss: 3.5581367162898756

Epoch: 5| Step: 2
Training loss: 3.3833376716874093
Validation loss: 3.5542844271334446

Epoch: 5| Step: 3
Training loss: 2.7611620394510474
Validation loss: 3.5500534649077915

Epoch: 5| Step: 4
Training loss: 3.7390189564038927
Validation loss: 3.5465722648048543

Epoch: 5| Step: 5
Training loss: 3.7533358677459705
Validation loss: 3.542491096955614

Epoch: 5| Step: 6
Training loss: 3.785249344790101
Validation loss: 3.5385808638021685

Epoch: 5| Step: 7
Training loss: 3.121274023853468
Validation loss: 3.534732173542603

Epoch: 5| Step: 8
Training loss: 4.185493330050062
Validation loss: 3.530698384324621

Epoch: 5| Step: 9
Training loss: 3.998815957300832
Validation loss: 3.5267417453142773

Epoch: 5| Step: 10
Training loss: 3.93129143867425
Validation loss: 3.5231389428837825

Epoch: 5| Step: 11
Training loss: 4.247616267687034
Validation loss: 3.5189285524372185

Epoch: 36| Step: 0
Training loss: 3.4074170274491196
Validation loss: 3.5144562481009167

Epoch: 5| Step: 1
Training loss: 2.742059340565966
Validation loss: 3.5103621190905208

Epoch: 5| Step: 2
Training loss: 4.218197934798541
Validation loss: 3.5062171179713624

Epoch: 5| Step: 3
Training loss: 4.028975917294452
Validation loss: 3.5021047394457785

Epoch: 5| Step: 4
Training loss: 3.5920122008424435
Validation loss: 3.4983059950262105

Epoch: 5| Step: 5
Training loss: 3.7906269422559173
Validation loss: 3.4940808459719954

Epoch: 5| Step: 6
Training loss: 3.7942551102200106
Validation loss: 3.489931041797746

Epoch: 5| Step: 7
Training loss: 4.351966606292511
Validation loss: 3.4852292164165823

Epoch: 5| Step: 8
Training loss: 2.994621223354016
Validation loss: 3.4804227107378525

Epoch: 5| Step: 9
Training loss: 3.203415871415895
Validation loss: 3.4763061028847675

Epoch: 5| Step: 10
Training loss: 3.2311919393432746
Validation loss: 3.4722701016409854

Epoch: 5| Step: 11
Training loss: 4.659619641805415
Validation loss: 3.468521846679709

Epoch: 37| Step: 0
Training loss: 3.4833837904005907
Validation loss: 3.464141120758334

Epoch: 5| Step: 1
Training loss: 2.923022855613845
Validation loss: 3.460051199905385

Epoch: 5| Step: 2
Training loss: 3.817079264120873
Validation loss: 3.4557331298866725

Epoch: 5| Step: 3
Training loss: 2.970550794037782
Validation loss: 3.451428993720405

Epoch: 5| Step: 4
Training loss: 4.098238282737441
Validation loss: 3.4482499486878546

Epoch: 5| Step: 5
Training loss: 3.448942663736482
Validation loss: 3.444296008589648

Epoch: 5| Step: 6
Training loss: 3.7369701354375118
Validation loss: 3.4399315816983993

Epoch: 5| Step: 7
Training loss: 3.00690270077512
Validation loss: 3.4356559084068157

Epoch: 5| Step: 8
Training loss: 3.9615015835858163
Validation loss: 3.4316455173041422

Epoch: 5| Step: 9
Training loss: 3.6717534471237094
Validation loss: 3.427971841641586

Epoch: 5| Step: 10
Training loss: 3.7018872216438496
Validation loss: 3.4250784848727256

Epoch: 5| Step: 11
Training loss: 5.034837095623629
Validation loss: 3.4223223296574656

Epoch: 38| Step: 0
Training loss: 3.6394019958239063
Validation loss: 3.4178159261779735

Epoch: 5| Step: 1
Training loss: 3.707136982735417
Validation loss: 3.4127746527398055

Epoch: 5| Step: 2
Training loss: 2.9513189050692143
Validation loss: 3.4074909212976174

Epoch: 5| Step: 3
Training loss: 3.6920233962453235
Validation loss: 3.40322809591558

Epoch: 5| Step: 4
Training loss: 4.070056167702352
Validation loss: 3.3994021278061526

Epoch: 5| Step: 5
Training loss: 3.2414904477062403
Validation loss: 3.3959050356232092

Epoch: 5| Step: 6
Training loss: 3.5447556133531175
Validation loss: 3.391877378171555

Epoch: 5| Step: 7
Training loss: 3.401018938083072
Validation loss: 3.387279178136428

Epoch: 5| Step: 8
Training loss: 3.7508669804677925
Validation loss: 3.383861910506955

Epoch: 5| Step: 9
Training loss: 3.0968111865015775
Validation loss: 3.379309328472464

Epoch: 5| Step: 10
Training loss: 3.7401316177953707
Validation loss: 3.3749668449374557

Epoch: 5| Step: 11
Training loss: 3.0032277227610864
Validation loss: 3.3714076927757026

Epoch: 39| Step: 0
Training loss: 3.4040279315022177
Validation loss: 3.3675874028595962

Epoch: 5| Step: 1
Training loss: 3.26619967282075
Validation loss: 3.3635271184107896

Epoch: 5| Step: 2
Training loss: 3.0155886316824163
Validation loss: 3.3599241236698703

Epoch: 5| Step: 3
Training loss: 4.042379231250226
Validation loss: 3.3565263276861645

Epoch: 5| Step: 4
Training loss: 3.3365157829973513
Validation loss: 3.3523726088177295

Epoch: 5| Step: 5
Training loss: 3.55297179684449
Validation loss: 3.3484480406286274

Epoch: 5| Step: 6
Training loss: 4.185662165205223
Validation loss: 3.3445803333254918

Epoch: 5| Step: 7
Training loss: 3.471114718665564
Validation loss: 3.3409559632502615

Epoch: 5| Step: 8
Training loss: 3.7026308913086314
Validation loss: 3.3368183197049044

Epoch: 5| Step: 9
Training loss: 3.1313799010721883
Validation loss: 3.333011281827322

Epoch: 5| Step: 10
Training loss: 3.3667596602737158
Validation loss: 3.3291976047999197

Epoch: 5| Step: 11
Training loss: 1.4908990540082028
Validation loss: 3.3255391649394666

Epoch: 40| Step: 0
Training loss: 3.843803963631293
Validation loss: 3.321935195832004

Epoch: 5| Step: 1
Training loss: 3.0599617852212075
Validation loss: 3.3184781411576476

Epoch: 5| Step: 2
Training loss: 2.8098624683811555
Validation loss: 3.314928172499914

Epoch: 5| Step: 3
Training loss: 3.257484913554648
Validation loss: 3.3114772033313757

Epoch: 5| Step: 4
Training loss: 3.5088354033869305
Validation loss: 3.308360413209089

Epoch: 5| Step: 5
Training loss: 3.7603385825605073
Validation loss: 3.304832617637386

Epoch: 5| Step: 6
Training loss: 3.79716308505532
Validation loss: 3.301367746347949

Epoch: 5| Step: 7
Training loss: 3.8107017904023897
Validation loss: 3.298210512341486

Epoch: 5| Step: 8
Training loss: 3.8047208373314874
Validation loss: 3.2945694296788597

Epoch: 5| Step: 9
Training loss: 3.3074743185394277
Validation loss: 3.290723651495238

Epoch: 5| Step: 10
Training loss: 2.7060082554490386
Validation loss: 3.2870878240430783

Epoch: 5| Step: 11
Training loss: 3.2759868736516466
Validation loss: 3.283346463111018

Epoch: 41| Step: 0
Training loss: 3.536624565581014
Validation loss: 3.2801773891562203

Epoch: 5| Step: 1
Training loss: 3.5972681488548535
Validation loss: 3.276581225010466

Epoch: 5| Step: 2
Training loss: 2.994357843351888
Validation loss: 3.273015094412638

Epoch: 5| Step: 3
Training loss: 3.0495313753414464
Validation loss: 3.2700660903135295

Epoch: 5| Step: 4
Training loss: 3.474888087604335
Validation loss: 3.2668825858308868

Epoch: 5| Step: 5
Training loss: 3.551271108949275
Validation loss: 3.2635968372995583

Epoch: 5| Step: 6
Training loss: 3.5081585753733853
Validation loss: 3.260468556699087

Epoch: 5| Step: 7
Training loss: 3.2669035676444578
Validation loss: 3.257218694809866

Epoch: 5| Step: 8
Training loss: 3.280345247055616
Validation loss: 3.2538884755076913

Epoch: 5| Step: 9
Training loss: 3.3958904675004966
Validation loss: 3.2503387262429175

Epoch: 5| Step: 10
Training loss: 3.6141546400094526
Validation loss: 3.247125093767608

Epoch: 5| Step: 11
Training loss: 3.8439906595456015
Validation loss: 3.2435385864835804

Epoch: 42| Step: 0
Training loss: 3.077986351027538
Validation loss: 3.2398740366107366

Epoch: 5| Step: 1
Training loss: 3.5086685189685527
Validation loss: 3.2361467886573885

Epoch: 5| Step: 2
Training loss: 3.7031727719344105
Validation loss: 3.2328383869838913

Epoch: 5| Step: 3
Training loss: 3.5457101665282758
Validation loss: 3.228826558240101

Epoch: 5| Step: 4
Training loss: 3.3441448513307748
Validation loss: 3.2254258648425385

Epoch: 5| Step: 5
Training loss: 2.954370952334697
Validation loss: 3.222033384606775

Epoch: 5| Step: 6
Training loss: 3.9295542639409926
Validation loss: 3.2182075944679527

Epoch: 5| Step: 7
Training loss: 3.252198722660909
Validation loss: 3.2145284665745475

Epoch: 5| Step: 8
Training loss: 3.5135384704472767
Validation loss: 3.210829755424831

Epoch: 5| Step: 9
Training loss: 2.891156286954779
Validation loss: 3.207395556903326

Epoch: 5| Step: 10
Training loss: 3.267140598042565
Validation loss: 3.203929353531624

Epoch: 5| Step: 11
Training loss: 2.612252573224331
Validation loss: 3.200350159620084

Epoch: 43| Step: 0
Training loss: 3.7190542657580075
Validation loss: 3.1970552698782373

Epoch: 5| Step: 1
Training loss: 3.157107699345804
Validation loss: 3.194242837782063

Epoch: 5| Step: 2
Training loss: 3.7041545997883647
Validation loss: 3.191184681703195

Epoch: 5| Step: 3
Training loss: 2.785486316784933
Validation loss: 3.1881255115777094

Epoch: 5| Step: 4
Training loss: 2.808291698867868
Validation loss: 3.1849507254078135

Epoch: 5| Step: 5
Training loss: 3.365200934794677
Validation loss: 3.1818190170055796

Epoch: 5| Step: 6
Training loss: 3.13660367039638
Validation loss: 3.178461780539742

Epoch: 5| Step: 7
Training loss: 3.5857977413958677
Validation loss: 3.175568057728882

Epoch: 5| Step: 8
Training loss: 3.124812921646364
Validation loss: 3.1723897481828764

Epoch: 5| Step: 9
Training loss: 2.9403646582916325
Validation loss: 3.1688222742710486

Epoch: 5| Step: 10
Training loss: 4.036691940274698
Validation loss: 3.1659943448323653

Epoch: 5| Step: 11
Training loss: 3.028592075035893
Validation loss: 3.1624388559434107

Epoch: 44| Step: 0
Training loss: 3.564560411484707
Validation loss: 3.1600596912597116

Epoch: 5| Step: 1
Training loss: 3.6699147287799634
Validation loss: 3.156759387794183

Epoch: 5| Step: 2
Training loss: 3.308004820021009
Validation loss: 3.1539258173739606

Epoch: 5| Step: 3
Training loss: 3.1861166850799463
Validation loss: 3.1503031387999805

Epoch: 5| Step: 4
Training loss: 3.3686821755568674
Validation loss: 3.148155262856973

Epoch: 5| Step: 5
Training loss: 2.7769260011840875
Validation loss: 3.144363661065531

Epoch: 5| Step: 6
Training loss: 3.0458102982498443
Validation loss: 3.141374950795348

Epoch: 5| Step: 7
Training loss: 3.051530460281269
Validation loss: 3.138177667816678

Epoch: 5| Step: 8
Training loss: 3.092387968854256
Validation loss: 3.135388603380573

Epoch: 5| Step: 9
Training loss: 3.3745516726513527
Validation loss: 3.1326180046507477

Epoch: 5| Step: 10
Training loss: 3.551426190010608
Validation loss: 3.129670956523947

Epoch: 5| Step: 11
Training loss: 3.5354311335636135
Validation loss: 3.127381574389452

Epoch: 45| Step: 0
Training loss: 3.7084979902994655
Validation loss: 3.123762696413247

Epoch: 5| Step: 1
Training loss: 2.9501400348594915
Validation loss: 3.12044193685124

Epoch: 5| Step: 2
Training loss: 2.8991290395966205
Validation loss: 3.1171748034378806

Epoch: 5| Step: 3
Training loss: 2.524686805261327
Validation loss: 3.1139597326950885

Epoch: 5| Step: 4
Training loss: 3.2111750976570086
Validation loss: 3.1107704922476995

Epoch: 5| Step: 5
Training loss: 3.32468548197828
Validation loss: 3.107615607308827

Epoch: 5| Step: 6
Training loss: 3.067184446686028
Validation loss: 3.104431958137787

Epoch: 5| Step: 7
Training loss: 3.896168386701758
Validation loss: 3.1011447897463165

Epoch: 5| Step: 8
Training loss: 3.4789659057683413
Validation loss: 3.0985548328390182

Epoch: 5| Step: 9
Training loss: 3.6181685433508015
Validation loss: 3.0952782853848153

Epoch: 5| Step: 10
Training loss: 2.9061257940843648
Validation loss: 3.0922789913686066

Epoch: 5| Step: 11
Training loss: 2.7348088383512694
Validation loss: 3.089001688328894

Epoch: 46| Step: 0
Training loss: 3.0980084328484323
Validation loss: 3.085798049544416

Epoch: 5| Step: 1
Training loss: 3.621313259216125
Validation loss: 3.0832915603969733

Epoch: 5| Step: 2
Training loss: 2.9304473298524836
Validation loss: 3.07975951558449

Epoch: 5| Step: 3
Training loss: 2.997156384954583
Validation loss: 3.0763748860859756

Epoch: 5| Step: 4
Training loss: 3.4114633962967362
Validation loss: 3.07342242373124

Epoch: 5| Step: 5
Training loss: 3.353834969051666
Validation loss: 3.070384952508898

Epoch: 5| Step: 6
Training loss: 3.4858310548132128
Validation loss: 3.067053536618139

Epoch: 5| Step: 7
Training loss: 3.2659903144015368
Validation loss: 3.064105187351672

Epoch: 5| Step: 8
Training loss: 2.820958958978699
Validation loss: 3.0614395284232003

Epoch: 5| Step: 9
Training loss: 2.8122809430750695
Validation loss: 3.058815825850095

Epoch: 5| Step: 10
Training loss: 3.185780379240832
Validation loss: 3.056943799990857

Epoch: 5| Step: 11
Training loss: 4.240136987524535
Validation loss: 3.0525977131978688

Epoch: 47| Step: 0
Training loss: 2.818585403271845
Validation loss: 3.0487884447218794

Epoch: 5| Step: 1
Training loss: 3.376281777450909
Validation loss: 3.0459045560122435

Epoch: 5| Step: 2
Training loss: 2.868136298331316
Validation loss: 3.0427872322472242

Epoch: 5| Step: 3
Training loss: 2.881707535368045
Validation loss: 3.0406176094887996

Epoch: 5| Step: 4
Training loss: 3.197315138781238
Validation loss: 3.037893238698443

Epoch: 5| Step: 5
Training loss: 3.222036813100618
Validation loss: 3.035403224825415

Epoch: 5| Step: 6
Training loss: 3.2497608390255825
Validation loss: 3.0325048674198176

Epoch: 5| Step: 7
Training loss: 3.6083006477784387
Validation loss: 3.0296528662593456

Epoch: 5| Step: 8
Training loss: 3.4016364815428877
Validation loss: 3.0266222744226527

Epoch: 5| Step: 9
Training loss: 3.1076426832198427
Validation loss: 3.023686447211603

Epoch: 5| Step: 10
Training loss: 3.0465912515612192
Validation loss: 3.020437659735619

Epoch: 5| Step: 11
Training loss: 3.452283109333907
Validation loss: 3.018137779311479

Epoch: 48| Step: 0
Training loss: 3.137726618268974
Validation loss: 3.0144680386482032

Epoch: 5| Step: 1
Training loss: 2.9181248062666425
Validation loss: 3.011635633641938

Epoch: 5| Step: 2
Training loss: 3.181658759396217
Validation loss: 3.008654346976812

Epoch: 5| Step: 3
Training loss: 3.2956900975818884
Validation loss: 3.0057782547852816

Epoch: 5| Step: 4
Training loss: 3.136640611865333
Validation loss: 3.0025448601659153

Epoch: 5| Step: 5
Training loss: 3.23214069537999
Validation loss: 2.999602569639919

Epoch: 5| Step: 6
Training loss: 3.029421067781831
Validation loss: 2.996624832796604

Epoch: 5| Step: 7
Training loss: 3.240736156238361
Validation loss: 2.9935123973152415

Epoch: 5| Step: 8
Training loss: 3.3585857085127038
Validation loss: 2.991026936317416

Epoch: 5| Step: 9
Training loss: 3.424272925061263
Validation loss: 2.9875215316805233

Epoch: 5| Step: 10
Training loss: 2.457264899711367
Validation loss: 2.9848650950975406

Epoch: 5| Step: 11
Training loss: 3.352408349066623
Validation loss: 2.981875439714922

Epoch: 49| Step: 0
Training loss: 3.2613314644232965
Validation loss: 2.9794757367028675

Epoch: 5| Step: 1
Training loss: 3.6075902712624695
Validation loss: 2.977459622986685

Epoch: 5| Step: 2
Training loss: 3.647186522265929
Validation loss: 2.974597185309872

Epoch: 5| Step: 3
Training loss: 2.8848509159277027
Validation loss: 2.97194090902821

Epoch: 5| Step: 4
Training loss: 3.110864943650212
Validation loss: 2.9697602544109167

Epoch: 5| Step: 5
Training loss: 3.0187835754675585
Validation loss: 2.9668002435172443

Epoch: 5| Step: 6
Training loss: 2.744032453801053
Validation loss: 2.9646128554939515

Epoch: 5| Step: 7
Training loss: 3.2997987628035745
Validation loss: 2.9623470792723676

Epoch: 5| Step: 8
Training loss: 2.7899683061118967
Validation loss: 2.9587803937143002

Epoch: 5| Step: 9
Training loss: 3.3553832002154516
Validation loss: 2.9573076993250798

Epoch: 5| Step: 10
Training loss: 2.4225844789937314
Validation loss: 2.954294521450726

Epoch: 5| Step: 11
Training loss: 2.2910899274635854
Validation loss: 2.952732033124509

Epoch: 50| Step: 0
Training loss: 2.9287749229735076
Validation loss: 2.950917554256919

Epoch: 5| Step: 1
Training loss: 2.8977592888081687
Validation loss: 2.9474753239283316

Epoch: 5| Step: 2
Training loss: 3.181794988869693
Validation loss: 2.9457612003647773

Epoch: 5| Step: 3
Training loss: 2.984320994582529
Validation loss: 2.9441119849551516

Epoch: 5| Step: 4
Training loss: 3.356880290769997
Validation loss: 2.941600136279218

Epoch: 5| Step: 5
Training loss: 2.9906951927948215
Validation loss: 2.9388904831480747

Epoch: 5| Step: 6
Training loss: 2.680709599453847
Validation loss: 2.9366059532196807

Epoch: 5| Step: 7
Training loss: 2.90918788287701
Validation loss: 2.9342121703362585

Epoch: 5| Step: 8
Training loss: 3.428711632859158
Validation loss: 2.9319841258619803

Epoch: 5| Step: 9
Training loss: 3.045380837313275
Validation loss: 2.929557556661433

Epoch: 5| Step: 10
Training loss: 3.273776890315447
Validation loss: 2.9272513132099176

Epoch: 5| Step: 11
Training loss: 3.7613470700011
Validation loss: 2.924210242489122

Epoch: 51| Step: 0
Training loss: 3.307702098620396
Validation loss: 2.922010935376928

Epoch: 5| Step: 1
Training loss: 2.9159420384846055
Validation loss: 2.9189926148733174

Epoch: 5| Step: 2
Training loss: 2.4287492222178533
Validation loss: 2.917364375359729

Epoch: 5| Step: 3
Training loss: 3.310382526110426
Validation loss: 2.9165214718146477

Epoch: 5| Step: 4
Training loss: 3.3358290071734937
Validation loss: 2.915552268121103

Epoch: 5| Step: 5
Training loss: 2.824442283468806
Validation loss: 2.9163467038719006

Epoch: 5| Step: 6
Training loss: 3.146139740495268
Validation loss: 2.9083186515849238

Epoch: 5| Step: 7
Training loss: 3.492999978673516
Validation loss: 2.906320010473399

Epoch: 5| Step: 8
Training loss: 2.727527174495217
Validation loss: 2.9056022188734048

Epoch: 5| Step: 9
Training loss: 3.246923751391627
Validation loss: 2.904491111076764

Epoch: 5| Step: 10
Training loss: 2.9773830774573162
Validation loss: 2.9031241673912165

Epoch: 5| Step: 11
Training loss: 1.0436946328833903
Validation loss: 2.9018839783851074

Epoch: 52| Step: 0
Training loss: 3.2134601865029007
Validation loss: 2.9002982042446197

Epoch: 5| Step: 1
Training loss: 3.3950211815601663
Validation loss: 2.897413269892004

Epoch: 5| Step: 2
Training loss: 3.1878187730748215
Validation loss: 2.8945016314612366

Epoch: 5| Step: 3
Training loss: 3.1528329008850626
Validation loss: 2.8908408625653035

Epoch: 5| Step: 4
Training loss: 2.7791019674278465
Validation loss: 2.888591363733611

Epoch: 5| Step: 5
Training loss: 3.417190759672085
Validation loss: 2.886077916409595

Epoch: 5| Step: 6
Training loss: 2.610941707806304
Validation loss: 2.882834530050982

Epoch: 5| Step: 7
Training loss: 2.909038559485964
Validation loss: 2.8805864866505435

Epoch: 5| Step: 8
Training loss: 3.1595462922431046
Validation loss: 2.8777993609248282

Epoch: 5| Step: 9
Training loss: 2.9349477515695845
Validation loss: 2.875736024876278

Epoch: 5| Step: 10
Training loss: 2.5555774876671595
Validation loss: 2.8736345047631286

Epoch: 5| Step: 11
Training loss: 2.3182682575423024
Validation loss: 2.8708715685903656

Epoch: 53| Step: 0
Training loss: 2.4512290674353627
Validation loss: 2.8689982545766908

Epoch: 5| Step: 1
Training loss: 2.4749746918588476
Validation loss: 2.867293034550684

Epoch: 5| Step: 2
Training loss: 3.0864693098916955
Validation loss: 2.8667574741060617

Epoch: 5| Step: 3
Training loss: 3.4596716501188003
Validation loss: 2.86433291409942

Epoch: 5| Step: 4
Training loss: 2.999847885090042
Validation loss: 2.8616617470452557

Epoch: 5| Step: 5
Training loss: 3.258628834416888
Validation loss: 2.859669984565091

Epoch: 5| Step: 6
Training loss: 2.8798866207269667
Validation loss: 2.856655620429702

Epoch: 5| Step: 7
Training loss: 3.0898977629405158
Validation loss: 2.8546846133285206

Epoch: 5| Step: 8
Training loss: 3.161419704312283
Validation loss: 2.8525361476048796

Epoch: 5| Step: 9
Training loss: 2.771061613005696
Validation loss: 2.851233305719858

Epoch: 5| Step: 10
Training loss: 3.31620121154671
Validation loss: 2.848831666760876

Epoch: 5| Step: 11
Training loss: 2.358779326773607
Validation loss: 2.848865941076212

Epoch: 54| Step: 0
Training loss: 3.3496443944051326
Validation loss: 2.849606073633399

Epoch: 5| Step: 1
Training loss: 2.760024526321238
Validation loss: 2.847341121475666

Epoch: 5| Step: 2
Training loss: 3.31157253884823
Validation loss: 2.8425272209555033

Epoch: 5| Step: 3
Training loss: 2.8328588499810605
Validation loss: 2.83839905873478

Epoch: 5| Step: 4
Training loss: 3.189488706839949
Validation loss: 2.8375237147422756

Epoch: 5| Step: 5
Training loss: 2.812594433364725
Validation loss: 2.8355201855517636

Epoch: 5| Step: 6
Training loss: 2.6824452081579016
Validation loss: 2.833755571561524

Epoch: 5| Step: 7
Training loss: 3.013715861129907
Validation loss: 2.832385642141259

Epoch: 5| Step: 8
Training loss: 3.001374724440657
Validation loss: 2.830261006928079

Epoch: 5| Step: 9
Training loss: 2.790274476937122
Validation loss: 2.8281779064758643

Epoch: 5| Step: 10
Training loss: 3.0497458993093187
Validation loss: 2.8268720053556353

Epoch: 5| Step: 11
Training loss: 2.4111466559950907
Validation loss: 2.824257783105605

Epoch: 55| Step: 0
Training loss: 3.3786361321763345
Validation loss: 2.822138500760482

Epoch: 5| Step: 1
Training loss: 2.9647967871362906
Validation loss: 2.8200263937601013

Epoch: 5| Step: 2
Training loss: 2.839850970105591
Validation loss: 2.8177560366237393

Epoch: 5| Step: 3
Training loss: 3.0374707758247252
Validation loss: 2.8161434028003085

Epoch: 5| Step: 4
Training loss: 2.9310703116774715
Validation loss: 2.813178708164743

Epoch: 5| Step: 5
Training loss: 2.3058633164842752
Validation loss: 2.8116957397593456

Epoch: 5| Step: 6
Training loss: 3.1661718048789225
Validation loss: 2.810210730320014

Epoch: 5| Step: 7
Training loss: 2.2868051693105063
Validation loss: 2.8076707068608253

Epoch: 5| Step: 8
Training loss: 3.249513002735002
Validation loss: 2.8070423756297638

Epoch: 5| Step: 9
Training loss: 2.8216426174928766
Validation loss: 2.803131362499556

Epoch: 5| Step: 10
Training loss: 2.993671099234287
Validation loss: 2.8010987261919484

Epoch: 5| Step: 11
Training loss: 4.2818861440018825
Validation loss: 2.8004707543836433

Epoch: 56| Step: 0
Training loss: 3.030175402005459
Validation loss: 2.798207432703747

Epoch: 5| Step: 1
Training loss: 3.234259709316735
Validation loss: 2.7970877980238704

Epoch: 5| Step: 2
Training loss: 3.086360545073205
Validation loss: 2.795754298719451

Epoch: 5| Step: 3
Training loss: 2.959887154722113
Validation loss: 2.794301783285721

Epoch: 5| Step: 4
Training loss: 2.764547968055878
Validation loss: 2.7916573386724455

Epoch: 5| Step: 5
Training loss: 2.631984501256791
Validation loss: 2.7900623217752463

Epoch: 5| Step: 6
Training loss: 3.0406988685785707
Validation loss: 2.7882111511796173

Epoch: 5| Step: 7
Training loss: 2.9751431342561525
Validation loss: 2.787311349708939

Epoch: 5| Step: 8
Training loss: 2.7162333273518575
Validation loss: 2.784493630133725

Epoch: 5| Step: 9
Training loss: 2.868534779838322
Validation loss: 2.783438889182743

Epoch: 5| Step: 10
Training loss: 2.8520659537908566
Validation loss: 2.7813986049198656

Epoch: 5| Step: 11
Training loss: 3.0607978605906005
Validation loss: 2.78013800418572

Epoch: 57| Step: 0
Training loss: 3.0657991039055075
Validation loss: 2.778032831694896

Epoch: 5| Step: 1
Training loss: 2.4843310466213118
Validation loss: 2.7761846198991793

Epoch: 5| Step: 2
Training loss: 3.110867702710858
Validation loss: 2.7752207472065638

Epoch: 5| Step: 3
Training loss: 3.2081279110890657
Validation loss: 2.7716250089342793

Epoch: 5| Step: 4
Training loss: 2.849944191101822
Validation loss: 2.7700098625815452

Epoch: 5| Step: 5
Training loss: 2.9281073212471584
Validation loss: 2.7666828553365757

Epoch: 5| Step: 6
Training loss: 2.9132499482408463
Validation loss: 2.7659069679042476

Epoch: 5| Step: 7
Training loss: 2.851221184357058
Validation loss: 2.7634323789169564

Epoch: 5| Step: 8
Training loss: 2.8343180086069335
Validation loss: 2.7716327006548274

Epoch: 5| Step: 9
Training loss: 2.865832931312946
Validation loss: 2.763547296490754

Epoch: 5| Step: 10
Training loss: 2.947927108764127
Validation loss: 2.7573518125120358

Epoch: 5| Step: 11
Training loss: 2.5331893838172994
Validation loss: 2.7560627567357954

Epoch: 58| Step: 0
Training loss: 3.1207588407609292
Validation loss: 2.7554475407639942

Epoch: 5| Step: 1
Training loss: 2.543651389570237
Validation loss: 2.754701904357305

Epoch: 5| Step: 2
Training loss: 2.9140363185821183
Validation loss: 2.756384947451045

Epoch: 5| Step: 3
Training loss: 2.9902053522636294
Validation loss: 2.7559977784380845

Epoch: 5| Step: 4
Training loss: 3.0437242698756855
Validation loss: 2.7563298700399073

Epoch: 5| Step: 5
Training loss: 2.809772610135294
Validation loss: 2.7542698541222093

Epoch: 5| Step: 6
Training loss: 2.924898755530273
Validation loss: 2.7522868271549505

Epoch: 5| Step: 7
Training loss: 3.1783354412912685
Validation loss: 2.7486161882883597

Epoch: 5| Step: 8
Training loss: 2.814321224978937
Validation loss: 2.745674600533079

Epoch: 5| Step: 9
Training loss: 2.561069554478835
Validation loss: 2.74368802611065

Epoch: 5| Step: 10
Training loss: 3.096568047548076
Validation loss: 2.7426143180032136

Epoch: 5| Step: 11
Training loss: 1.1062477521280845
Validation loss: 2.739965743340334

Epoch: 59| Step: 0
Training loss: 2.6596096558373636
Validation loss: 2.740598422841937

Epoch: 5| Step: 1
Training loss: 2.398949186434902
Validation loss: 2.736587207190843

Epoch: 5| Step: 2
Training loss: 3.3035641467629087
Validation loss: 2.734688419363246

Epoch: 5| Step: 3
Training loss: 2.896604549618418
Validation loss: 2.7318640524223676

Epoch: 5| Step: 4
Training loss: 2.5261838158531282
Validation loss: 2.731581250725611

Epoch: 5| Step: 5
Training loss: 3.2445850745369897
Validation loss: 2.730448885123666

Epoch: 5| Step: 6
Training loss: 2.7656918964808366
Validation loss: 2.7309569875988955

Epoch: 5| Step: 7
Training loss: 2.631388746214366
Validation loss: 2.7289122591517674

Epoch: 5| Step: 8
Training loss: 3.3875994565658143
Validation loss: 2.729369000707156

Epoch: 5| Step: 9
Training loss: 2.8278601085050026
Validation loss: 2.7281436616565915

Epoch: 5| Step: 10
Training loss: 2.8513016254813617
Validation loss: 2.725969375761589

Epoch: 5| Step: 11
Training loss: 2.7271016197281193
Validation loss: 2.724509824622732

Epoch: 60| Step: 0
Training loss: 2.750933402050935
Validation loss: 2.7218553632165823

Epoch: 5| Step: 1
Training loss: 2.5287571629466625
Validation loss: 2.722344857300516

Epoch: 5| Step: 2
Training loss: 2.9370771063092236
Validation loss: 2.7221466492415334

Epoch: 5| Step: 3
Training loss: 3.0696416612177537
Validation loss: 2.723212471275708

Epoch: 5| Step: 4
Training loss: 3.091597453642478
Validation loss: 2.7158533208844475

Epoch: 5| Step: 5
Training loss: 2.7819866962073627
Validation loss: 2.7175653112717226

Epoch: 5| Step: 6
Training loss: 3.143954054654476
Validation loss: 2.7155197765536516

Epoch: 5| Step: 7
Training loss: 2.815778135820071
Validation loss: 2.7139923443874854

Epoch: 5| Step: 8
Training loss: 2.7803341504171892
Validation loss: 2.7134954054410296

Epoch: 5| Step: 9
Training loss: 2.348411502047028
Validation loss: 2.713774125044514

Epoch: 5| Step: 10
Training loss: 3.1205076352432353
Validation loss: 2.7113812144847547

Epoch: 5| Step: 11
Training loss: 2.8121294413276026
Validation loss: 2.7075899473297396

Epoch: 61| Step: 0
Training loss: 2.897174076579604
Validation loss: 2.705634292001469

Epoch: 5| Step: 1
Training loss: 2.9121480180618504
Validation loss: 2.7054160778041685

Epoch: 5| Step: 2
Training loss: 2.837669327174712
Validation loss: 2.710023801148918

Epoch: 5| Step: 3
Training loss: 2.4201536891149638
Validation loss: 2.7086919045889375

Epoch: 5| Step: 4
Training loss: 2.7045756069510425
Validation loss: 2.7143028360767327

Epoch: 5| Step: 5
Training loss: 3.2668664936008205
Validation loss: 2.697562530772121

Epoch: 5| Step: 6
Training loss: 2.5142899281757516
Validation loss: 2.696664340329041

Epoch: 5| Step: 7
Training loss: 2.391100269022819
Validation loss: 2.698814751974788

Epoch: 5| Step: 8
Training loss: 2.917796179636
Validation loss: 2.699381781520452

Epoch: 5| Step: 9
Training loss: 3.262801852823143
Validation loss: 2.701652585217841

Epoch: 5| Step: 10
Training loss: 3.011257982445347
Validation loss: 2.704921353384381

Epoch: 5| Step: 11
Training loss: 2.901422736972433
Validation loss: 2.704275272365203

Epoch: 62| Step: 0
Training loss: 2.6204292830919034
Validation loss: 2.702933251373311

Epoch: 5| Step: 1
Training loss: 2.8736932521425573
Validation loss: 2.696978182419292

Epoch: 5| Step: 2
Training loss: 2.5748327330547998
Validation loss: 2.6946219070946986

Epoch: 5| Step: 3
Training loss: 2.4978473932641725
Validation loss: 2.689631954574098

Epoch: 5| Step: 4
Training loss: 3.099338916307742
Validation loss: 2.685270896834099

Epoch: 5| Step: 5
Training loss: 3.0012609692761947
Validation loss: 2.683197440137999

Epoch: 5| Step: 6
Training loss: 2.7076267396634144
Validation loss: 2.680801326940892

Epoch: 5| Step: 7
Training loss: 2.7448177058934946
Validation loss: 2.67797685745359

Epoch: 5| Step: 8
Training loss: 2.8904849456674864
Validation loss: 2.6804359880989663

Epoch: 5| Step: 9
Training loss: 3.036192492477938
Validation loss: 2.6791264397986256

Epoch: 5| Step: 10
Training loss: 3.004916295363096
Validation loss: 2.6789057845379194

Epoch: 5| Step: 11
Training loss: 2.6789483032307766
Validation loss: 2.6748820220920697

Epoch: 63| Step: 0
Training loss: 2.5143867430577482
Validation loss: 2.6722807734111704

Epoch: 5| Step: 1
Training loss: 2.882224914711615
Validation loss: 2.6725659192819897

Epoch: 5| Step: 2
Training loss: 2.8176755967885643
Validation loss: 2.671954925263756

Epoch: 5| Step: 3
Training loss: 2.696894526935843
Validation loss: 2.674710607620889

Epoch: 5| Step: 4
Training loss: 2.619702761729745
Validation loss: 2.676728905446671

Epoch: 5| Step: 5
Training loss: 2.899306997170664
Validation loss: 2.675659284573254

Epoch: 5| Step: 6
Training loss: 2.6032574605040826
Validation loss: 2.673591594019301

Epoch: 5| Step: 7
Training loss: 2.811182179597617
Validation loss: 2.671646011682802

Epoch: 5| Step: 8
Training loss: 2.772158905593936
Validation loss: 2.6703373051639505

Epoch: 5| Step: 9
Training loss: 3.1818068281194076
Validation loss: 2.6682397901144963

Epoch: 5| Step: 10
Training loss: 2.9099569982123983
Validation loss: 2.6663166328017165

Epoch: 5| Step: 11
Training loss: 3.5531045260548257
Validation loss: 2.6627589268513114

Epoch: 64| Step: 0
Training loss: 2.6910812115217957
Validation loss: 2.6619849545609893

Epoch: 5| Step: 1
Training loss: 2.7812092810232483
Validation loss: 2.6671252800049983

Epoch: 5| Step: 2
Training loss: 2.5612502423235592
Validation loss: 2.6710139591914372

Epoch: 5| Step: 3
Training loss: 2.866364321917986
Validation loss: 2.670787742501368

Epoch: 5| Step: 4
Training loss: 2.6577417111935406
Validation loss: 2.6653061552714297

Epoch: 5| Step: 5
Training loss: 3.067181959258957
Validation loss: 2.6588067297419844

Epoch: 5| Step: 6
Training loss: 3.0672587576394528
Validation loss: 2.653786343244655

Epoch: 5| Step: 7
Training loss: 2.907970124512312
Validation loss: 2.653493292220518

Epoch: 5| Step: 8
Training loss: 2.8523083691164492
Validation loss: 2.6542757289363212

Epoch: 5| Step: 9
Training loss: 3.07499977670064
Validation loss: 2.6551980235539534

Epoch: 5| Step: 10
Training loss: 2.4156260935792013
Validation loss: 2.6553726093590524

Epoch: 5| Step: 11
Training loss: 1.5699645458761888
Validation loss: 2.6580239673999717

Epoch: 65| Step: 0
Training loss: 2.7032498898623887
Validation loss: 2.6564230095861743

Epoch: 5| Step: 1
Training loss: 2.5291900730045027
Validation loss: 2.6587985995343066

Epoch: 5| Step: 2
Training loss: 2.36151622089321
Validation loss: 2.650454983999232

Epoch: 5| Step: 3
Training loss: 2.680117558705029
Validation loss: 2.6490889304176335

Epoch: 5| Step: 4
Training loss: 2.634418574976257
Validation loss: 2.6444922500206367

Epoch: 5| Step: 5
Training loss: 2.714325209021946
Validation loss: 2.642016542642558

Epoch: 5| Step: 6
Training loss: 2.593445541713192
Validation loss: 2.638784414169671

Epoch: 5| Step: 7
Training loss: 3.4130683341820722
Validation loss: 2.6383027167440503

Epoch: 5| Step: 8
Training loss: 3.4078001642156948
Validation loss: 2.6367697628408227

Epoch: 5| Step: 9
Training loss: 2.7226621170746954
Validation loss: 2.6366250179255024

Epoch: 5| Step: 10
Training loss: 2.6411970072032442
Validation loss: 2.6337782166865553

Epoch: 5| Step: 11
Training loss: 2.856306587176224
Validation loss: 2.6313252195901344

Epoch: 66| Step: 0
Training loss: 2.1865135148348434
Validation loss: 2.6314123262183817

Epoch: 5| Step: 1
Training loss: 3.024919802020342
Validation loss: 2.6315802983753183

Epoch: 5| Step: 2
Training loss: 2.7140247015113586
Validation loss: 2.6317272383230192

Epoch: 5| Step: 3
Training loss: 2.778340049633321
Validation loss: 2.628260642326331

Epoch: 5| Step: 4
Training loss: 2.8623981441050397
Validation loss: 2.627146479074362

Epoch: 5| Step: 5
Training loss: 2.967857628268641
Validation loss: 2.628751730380938

Epoch: 5| Step: 6
Training loss: 2.879139780746186
Validation loss: 2.6251117099728107

Epoch: 5| Step: 7
Training loss: 2.7178663374292533
Validation loss: 2.622480795783612

Epoch: 5| Step: 8
Training loss: 2.6963569718222824
Validation loss: 2.6234864477059956

Epoch: 5| Step: 9
Training loss: 2.873979138451919
Validation loss: 2.62290781144356

Epoch: 5| Step: 10
Training loss: 2.526475241244767
Validation loss: 2.622278539818144

Epoch: 5| Step: 11
Training loss: 3.46986137662911
Validation loss: 2.6193262347839372

Epoch: 67| Step: 0
Training loss: 2.816578006665723
Validation loss: 2.619524907408682

Epoch: 5| Step: 1
Training loss: 2.58250222116469
Validation loss: 2.619001035410203

Epoch: 5| Step: 2
Training loss: 2.7470336000313007
Validation loss: 2.61965135586645

Epoch: 5| Step: 3
Training loss: 2.524895686648181
Validation loss: 2.61695248511806

Epoch: 5| Step: 4
Training loss: 2.7358536564187053
Validation loss: 2.6170282192061975

Epoch: 5| Step: 5
Training loss: 2.9738548960070132
Validation loss: 2.61471524355439

Epoch: 5| Step: 6
Training loss: 2.835168991838101
Validation loss: 2.6164091290753966

Epoch: 5| Step: 7
Training loss: 2.5576560595377913
Validation loss: 2.6113767236577883

Epoch: 5| Step: 8
Training loss: 3.1560029792433144
Validation loss: 2.614842673024994

Epoch: 5| Step: 9
Training loss: 2.4570486192438032
Validation loss: 2.6130636188262866

Epoch: 5| Step: 10
Training loss: 2.786082494945212
Validation loss: 2.612018521520474

Epoch: 5| Step: 11
Training loss: 3.0524566387374072
Validation loss: 2.608323629704505

Epoch: 68| Step: 0
Training loss: 2.665246426352279
Validation loss: 2.607153531290314

Epoch: 5| Step: 1
Training loss: 2.500838425235041
Validation loss: 2.6089517665119275

Epoch: 5| Step: 2
Training loss: 2.798139233138656
Validation loss: 2.6113969693444763

Epoch: 5| Step: 3
Training loss: 2.854884723266789
Validation loss: 2.618022910627653

Epoch: 5| Step: 4
Training loss: 3.1164448936287026
Validation loss: 2.620559118619253

Epoch: 5| Step: 5
Training loss: 2.5952954571352103
Validation loss: 2.6224969858904386

Epoch: 5| Step: 6
Training loss: 2.700645235458589
Validation loss: 2.6215570820117207

Epoch: 5| Step: 7
Training loss: 2.6817679378464008
Validation loss: 2.6188054980980433

Epoch: 5| Step: 8
Training loss: 2.6270763722830948
Validation loss: 2.6127439287678644

Epoch: 5| Step: 9
Training loss: 2.8866670472260094
Validation loss: 2.608776488353207

Epoch: 5| Step: 10
Training loss: 2.7162899419215143
Validation loss: 2.6068089177833085

Epoch: 5| Step: 11
Training loss: 3.1759668274883857
Validation loss: 2.602248039459136

Epoch: 69| Step: 0
Training loss: 2.42857899784864
Validation loss: 2.6013912148359735

Epoch: 5| Step: 1
Training loss: 3.0521413821449297
Validation loss: 2.601347130613807

Epoch: 5| Step: 2
Training loss: 2.8033061331549365
Validation loss: 2.59867394954859

Epoch: 5| Step: 3
Training loss: 2.5998527705248544
Validation loss: 2.59962524516217

Epoch: 5| Step: 4
Training loss: 3.1627268291442077
Validation loss: 2.5991153644119036

Epoch: 5| Step: 5
Training loss: 2.804995719104023
Validation loss: 2.5978543122391753

Epoch: 5| Step: 6
Training loss: 2.064361310377012
Validation loss: 2.5947848404271707

Epoch: 5| Step: 7
Training loss: 2.4700453052149576
Validation loss: 2.59629516891641

Epoch: 5| Step: 8
Training loss: 2.456734498362975
Validation loss: 2.5975080175340297

Epoch: 5| Step: 9
Training loss: 2.874477504852546
Validation loss: 2.5976079415248807

Epoch: 5| Step: 10
Training loss: 3.1706620325910726
Validation loss: 2.598968526225211

Epoch: 5| Step: 11
Training loss: 3.0318900150390444
Validation loss: 2.5988755502811993

Epoch: 70| Step: 0
Training loss: 2.5124789640390564
Validation loss: 2.6024112290698316

Epoch: 5| Step: 1
Training loss: 2.852205386916032
Validation loss: 2.600392484232088

Epoch: 5| Step: 2
Training loss: 3.0876474013258948
Validation loss: 2.6007564239065704

Epoch: 5| Step: 3
Training loss: 2.6085766696056565
Validation loss: 2.5983947201386353

Epoch: 5| Step: 4
Training loss: 2.5934744998817445
Validation loss: 2.59681361019134

Epoch: 5| Step: 5
Training loss: 3.1482775626250183
Validation loss: 2.5967543028055227

Epoch: 5| Step: 6
Training loss: 2.7522178722900437
Validation loss: 2.5959074630276167

Epoch: 5| Step: 7
Training loss: 2.4569840904282785
Validation loss: 2.594147353012075

Epoch: 5| Step: 8
Training loss: 3.1204145740514413
Validation loss: 2.5917028636694246

Epoch: 5| Step: 9
Training loss: 2.252339524322367
Validation loss: 2.588828722709896

Epoch: 5| Step: 10
Training loss: 2.5748072690964547
Validation loss: 2.588596003145688

Epoch: 5| Step: 11
Training loss: 2.3866333392105497
Validation loss: 2.585926916402343

Epoch: 71| Step: 0
Training loss: 2.264096922050053
Validation loss: 2.5820915111256095

Epoch: 5| Step: 1
Training loss: 2.89783004605689
Validation loss: 2.584749234990065

Epoch: 5| Step: 2
Training loss: 2.8827645315919392
Validation loss: 2.584514145524422

Epoch: 5| Step: 3
Training loss: 2.6960984120844036
Validation loss: 2.6002513877063698

Epoch: 5| Step: 4
Training loss: 2.662837219374246
Validation loss: 2.6107452891026415

Epoch: 5| Step: 5
Training loss: 2.9727727037595346
Validation loss: 2.594739606425145

Epoch: 5| Step: 6
Training loss: 2.9372392903963154
Validation loss: 2.5830728389292448

Epoch: 5| Step: 7
Training loss: 2.9065973217884573
Validation loss: 2.5798252664274757

Epoch: 5| Step: 8
Training loss: 2.792018147068018
Validation loss: 2.575634421893145

Epoch: 5| Step: 9
Training loss: 2.578025122355122
Validation loss: 2.571313502717968

Epoch: 5| Step: 10
Training loss: 2.5640010624137974
Validation loss: 2.572716988345538

Epoch: 5| Step: 11
Training loss: 0.4161834736377356
Validation loss: 2.5746881484413495

Epoch: 72| Step: 0
Training loss: 2.593045977907542
Validation loss: 2.574813808727971

Epoch: 5| Step: 1
Training loss: 2.6937747715211526
Validation loss: 2.5744623812751395

Epoch: 5| Step: 2
Training loss: 2.5798443234221056
Validation loss: 2.580286653356963

Epoch: 5| Step: 3
Training loss: 2.8035722390643154
Validation loss: 2.591547808625255

Epoch: 5| Step: 4
Training loss: 2.3100236572771666
Validation loss: 2.583745586408104

Epoch: 5| Step: 5
Training loss: 2.770001757514479
Validation loss: 2.5815339217855096

Epoch: 5| Step: 6
Training loss: 2.951418428958837
Validation loss: 2.582053364761455

Epoch: 5| Step: 7
Training loss: 2.750705108412173
Validation loss: 2.5790769996421905

Epoch: 5| Step: 8
Training loss: 2.623214386841044
Validation loss: 2.577762848049901

Epoch: 5| Step: 9
Training loss: 2.8909011296532894
Validation loss: 2.575134785837393

Epoch: 5| Step: 10
Training loss: 2.9085461149738863
Validation loss: 2.5726191288161733

Epoch: 5| Step: 11
Training loss: 2.359993960809254
Validation loss: 2.5667548946805687

Epoch: 73| Step: 0
Training loss: 2.8121154522263825
Validation loss: 2.5669597955826373

Epoch: 5| Step: 1
Training loss: 3.2124417904578566
Validation loss: 2.564135607092337

Epoch: 5| Step: 2
Training loss: 2.792030699798873
Validation loss: 2.562956687890955

Epoch: 5| Step: 3
Training loss: 2.203104546634612
Validation loss: 2.565362111142926

Epoch: 5| Step: 4
Training loss: 3.034743508022525
Validation loss: 2.5614089193667433

Epoch: 5| Step: 5
Training loss: 2.8066992385254874
Validation loss: 2.5613887478525554

Epoch: 5| Step: 6
Training loss: 2.5778863044982567
Validation loss: 2.559594274683059

Epoch: 5| Step: 7
Training loss: 2.5989895948060107
Validation loss: 2.557706155743166

Epoch: 5| Step: 8
Training loss: 2.3563194446802873
Validation loss: 2.5591651220284906

Epoch: 5| Step: 9
Training loss: 2.1712804845098503
Validation loss: 2.5593876080324716

Epoch: 5| Step: 10
Training loss: 2.9696576788809055
Validation loss: 2.563214477704914

Epoch: 5| Step: 11
Training loss: 2.1442476234418417
Validation loss: 2.561708545189445

Epoch: 74| Step: 0
Training loss: 2.566841448575514
Validation loss: 2.5601900978710623

Epoch: 5| Step: 1
Training loss: 2.969065117424808
Validation loss: 2.5551690552827866

Epoch: 5| Step: 2
Training loss: 2.6093274871703502
Validation loss: 2.5559780660179667

Epoch: 5| Step: 3
Training loss: 2.73665850521579
Validation loss: 2.5575329238820808

Epoch: 5| Step: 4
Training loss: 2.6241232906603646
Validation loss: 2.5507890857928635

Epoch: 5| Step: 5
Training loss: 2.662825042512416
Validation loss: 2.5521590487608257

Epoch: 5| Step: 6
Training loss: 2.3076192538606914
Validation loss: 2.554609874980897

Epoch: 5| Step: 7
Training loss: 2.5601701146467155
Validation loss: 2.552997422814827

Epoch: 5| Step: 8
Training loss: 2.4603075947004616
Validation loss: 2.5558905845484485

Epoch: 5| Step: 9
Training loss: 3.0964357682435315
Validation loss: 2.5576880252093326

Epoch: 5| Step: 10
Training loss: 2.773263071512015
Validation loss: 2.553107847500867

Epoch: 5| Step: 11
Training loss: 3.488007572113357
Validation loss: 2.55025141355492

Epoch: 75| Step: 0
Training loss: 2.505287586843424
Validation loss: 2.547482981595342

Epoch: 5| Step: 1
Training loss: 2.494594834327044
Validation loss: 2.548441200557714

Epoch: 5| Step: 2
Training loss: 2.410948884236226
Validation loss: 2.5546185856505756

Epoch: 5| Step: 3
Training loss: 2.8914495168570236
Validation loss: 2.5617186394020854

Epoch: 5| Step: 4
Training loss: 3.062368896169367
Validation loss: 2.580892530108708

Epoch: 5| Step: 5
Training loss: 2.9446713182226776
Validation loss: 2.5753508332669943

Epoch: 5| Step: 6
Training loss: 2.850766089020901
Validation loss: 2.5572972087191466

Epoch: 5| Step: 7
Training loss: 2.1675684103900164
Validation loss: 2.546961652221677

Epoch: 5| Step: 8
Training loss: 2.786747161061631
Validation loss: 2.5435535365974995

Epoch: 5| Step: 9
Training loss: 2.605406524509944
Validation loss: 2.545778038300556

Epoch: 5| Step: 10
Training loss: 2.8104625527547973
Validation loss: 2.5420613777122467

Epoch: 5| Step: 11
Training loss: 2.2528693658618275
Validation loss: 2.544021423724224

Epoch: 76| Step: 0
Training loss: 2.276268942605918
Validation loss: 2.542710298451236

Epoch: 5| Step: 1
Training loss: 3.086301526195343
Validation loss: 2.542526300382415

Epoch: 5| Step: 2
Training loss: 2.259204897142565
Validation loss: 2.543045999864475

Epoch: 5| Step: 3
Training loss: 2.205243978691292
Validation loss: 2.542142058820008

Epoch: 5| Step: 4
Training loss: 3.1304073090660736
Validation loss: 2.542305839924415

Epoch: 5| Step: 5
Training loss: 2.847986775121094
Validation loss: 2.5389633354971815

Epoch: 5| Step: 6
Training loss: 2.6001967319005272
Validation loss: 2.5400482689909287

Epoch: 5| Step: 7
Training loss: 2.6391274082294087
Validation loss: 2.5396873918034735

Epoch: 5| Step: 8
Training loss: 2.6987561327682155
Validation loss: 2.537786863661245

Epoch: 5| Step: 9
Training loss: 3.105468903547559
Validation loss: 2.536537616960631

Epoch: 5| Step: 10
Training loss: 2.250954531481125
Validation loss: 2.538456148959376

Epoch: 5| Step: 11
Training loss: 3.0384935174910215
Validation loss: 2.534032124735475

Epoch: 77| Step: 0
Training loss: 2.8936908032024733
Validation loss: 2.5363214339663447

Epoch: 5| Step: 1
Training loss: 2.6822306406924414
Validation loss: 2.538613715001834

Epoch: 5| Step: 2
Training loss: 2.724971449116217
Validation loss: 2.532731078163089

Epoch: 5| Step: 3
Training loss: 2.504594871821458
Validation loss: 2.5321324854826734

Epoch: 5| Step: 4
Training loss: 2.3566407787766193
Validation loss: 2.5348826663885804

Epoch: 5| Step: 5
Training loss: 2.9680526717517126
Validation loss: 2.5332446931925015

Epoch: 5| Step: 6
Training loss: 2.664432354532782
Validation loss: 2.5344190147644987

Epoch: 5| Step: 7
Training loss: 2.4915510459109367
Validation loss: 2.529693395691399

Epoch: 5| Step: 8
Training loss: 2.2978038337053315
Validation loss: 2.532284842988935

Epoch: 5| Step: 9
Training loss: 2.7302069586253475
Validation loss: 2.5303160942208835

Epoch: 5| Step: 10
Training loss: 2.893673171141952
Validation loss: 2.5274061050859307

Epoch: 5| Step: 11
Training loss: 2.935188357858139
Validation loss: 2.5323360177699943

Epoch: 78| Step: 0
Training loss: 2.9941289992333817
Validation loss: 2.53254431532949

Epoch: 5| Step: 1
Training loss: 2.5628885114207867
Validation loss: 2.530886262889309

Epoch: 5| Step: 2
Training loss: 2.5951017970586756
Validation loss: 2.5311623075389127

Epoch: 5| Step: 3
Training loss: 2.1710209985646145
Validation loss: 2.530819432408108

Epoch: 5| Step: 4
Training loss: 2.775480479665705
Validation loss: 2.5291047837062104

Epoch: 5| Step: 5
Training loss: 2.2953281513716615
Validation loss: 2.527874847063262

Epoch: 5| Step: 6
Training loss: 3.0657751515176526
Validation loss: 2.525164329261429

Epoch: 5| Step: 7
Training loss: 2.7935303023486933
Validation loss: 2.529480115225323

Epoch: 5| Step: 8
Training loss: 2.3637191492868443
Validation loss: 2.530885320853205

Epoch: 5| Step: 9
Training loss: 2.5539236064051556
Validation loss: 2.5306261455520422

Epoch: 5| Step: 10
Training loss: 2.680164617208371
Validation loss: 2.54408959426825

Epoch: 5| Step: 11
Training loss: 3.7081946586368377
Validation loss: 2.547342316049676

Epoch: 79| Step: 0
Training loss: 2.7302875595115053
Validation loss: 2.536233881602577

Epoch: 5| Step: 1
Training loss: 2.9705121081133874
Validation loss: 2.533495166329771

Epoch: 5| Step: 2
Training loss: 2.79421188325491
Validation loss: 2.533515156058081

Epoch: 5| Step: 3
Training loss: 2.5961312083808767
Validation loss: 2.535576184587768

Epoch: 5| Step: 4
Training loss: 2.035885612429685
Validation loss: 2.5406430142535465

Epoch: 5| Step: 5
Training loss: 2.679806542602269
Validation loss: 2.5485160353998513

Epoch: 5| Step: 6
Training loss: 2.7788898869703798
Validation loss: 2.5485007357163143

Epoch: 5| Step: 7
Training loss: 2.921967367252428
Validation loss: 2.5591010098019566

Epoch: 5| Step: 8
Training loss: 3.0694496553663515
Validation loss: 2.561562878519207

Epoch: 5| Step: 9
Training loss: 2.3195374090126424
Validation loss: 2.559114398350076

Epoch: 5| Step: 10
Training loss: 2.318211178755167
Validation loss: 2.550871476996626

Epoch: 5| Step: 11
Training loss: 2.8186730351058826
Validation loss: 2.5462468119510646

Epoch: 80| Step: 0
Training loss: 2.4903260935928047
Validation loss: 2.5418345612172444

Epoch: 5| Step: 1
Training loss: 2.4887815538414975
Validation loss: 2.536671225499415

Epoch: 5| Step: 2
Training loss: 2.737678145791402
Validation loss: 2.5329387510173302

Epoch: 5| Step: 3
Training loss: 2.766799418776626
Validation loss: 2.5317108103758637

Epoch: 5| Step: 4
Training loss: 2.5591471066395597
Validation loss: 2.527916259226953

Epoch: 5| Step: 5
Training loss: 2.7908927831718375
Validation loss: 2.52519066361434

Epoch: 5| Step: 6
Training loss: 2.638335731040972
Validation loss: 2.5236239054422085

Epoch: 5| Step: 7
Training loss: 3.1008436777717527
Validation loss: 2.5218655755845027

Epoch: 5| Step: 8
Training loss: 2.4063433344190575
Validation loss: 2.5214999686226083

Epoch: 5| Step: 9
Training loss: 2.5797575434528164
Validation loss: 2.5245247143340137

Epoch: 5| Step: 10
Training loss: 2.7705324243817797
Validation loss: 2.51687040756889

Epoch: 5| Step: 11
Training loss: 1.7338474605480652
Validation loss: 2.517846534375559

Epoch: 81| Step: 0
Training loss: 2.8176328657177643
Validation loss: 2.5152276872543116

Epoch: 5| Step: 1
Training loss: 3.0534974729016238
Validation loss: 2.518948332311573

Epoch: 5| Step: 2
Training loss: 2.33262874546428
Validation loss: 2.5243085257471782

Epoch: 5| Step: 3
Training loss: 2.37613510311583
Validation loss: 2.5199144136121947

Epoch: 5| Step: 4
Training loss: 3.2179923045349095
Validation loss: 2.513206227370294

Epoch: 5| Step: 5
Training loss: 2.903646143526936
Validation loss: 2.511556395666901

Epoch: 5| Step: 6
Training loss: 2.592066758685419
Validation loss: 2.510200286710079

Epoch: 5| Step: 7
Training loss: 2.3462203167931315
Validation loss: 2.5111635582317415

Epoch: 5| Step: 8
Training loss: 2.890248866998064
Validation loss: 2.5172077238918917

Epoch: 5| Step: 9
Training loss: 2.0485836206807937
Validation loss: 2.520466593923008

Epoch: 5| Step: 10
Training loss: 2.3505417138548674
Validation loss: 2.519414902004144

Epoch: 5| Step: 11
Training loss: 2.881333051630607
Validation loss: 2.5196336986600207

Epoch: 82| Step: 0
Training loss: 2.7094815876728133
Validation loss: 2.526409033315843

Epoch: 5| Step: 1
Training loss: 2.61671174692898
Validation loss: 2.5321250470506316

Epoch: 5| Step: 2
Training loss: 3.090106861278997
Validation loss: 2.5436692881920795

Epoch: 5| Step: 3
Training loss: 2.670519479371639
Validation loss: 2.554967874585049

Epoch: 5| Step: 4
Training loss: 2.601479927104322
Validation loss: 2.5617455829604494

Epoch: 5| Step: 5
Training loss: 2.7131213975033135
Validation loss: 2.5661900282632986

Epoch: 5| Step: 6
Training loss: 3.0409381638536876
Validation loss: 2.567926220937725

Epoch: 5| Step: 7
Training loss: 2.2502531333098834
Validation loss: 2.5661355451147028

Epoch: 5| Step: 8
Training loss: 2.7553715696576098
Validation loss: 2.5614197923714204

Epoch: 5| Step: 9
Training loss: 2.572610123837983
Validation loss: 2.555328440393135

Epoch: 5| Step: 10
Training loss: 2.512430377963491
Validation loss: 2.5374627849750047

Epoch: 5| Step: 11
Training loss: 1.9446938385048682
Validation loss: 2.535362732897949

Epoch: 83| Step: 0
Training loss: 2.7575239079148828
Validation loss: 2.5302128531199815

Epoch: 5| Step: 1
Training loss: 2.924420721614254
Validation loss: 2.526912202305685

Epoch: 5| Step: 2
Training loss: 2.7147163196543227
Validation loss: 2.5237924269116823

Epoch: 5| Step: 3
Training loss: 2.583194903284635
Validation loss: 2.519915891951771

Epoch: 5| Step: 4
Training loss: 2.2500737496051344
Validation loss: 2.5230077056671334

Epoch: 5| Step: 5
Training loss: 2.02242981551984
Validation loss: 2.520598803925669

Epoch: 5| Step: 6
Training loss: 2.3826526025372314
Validation loss: 2.5180285445217163

Epoch: 5| Step: 7
Training loss: 2.7101806111696525
Validation loss: 2.5172095668969177

Epoch: 5| Step: 8
Training loss: 2.3362917424162535
Validation loss: 2.5154702670132685

Epoch: 5| Step: 9
Training loss: 3.5144739597911796
Validation loss: 2.512498116690213

Epoch: 5| Step: 10
Training loss: 2.725171278024167
Validation loss: 2.514750227858657

Epoch: 5| Step: 11
Training loss: 2.215445623413659
Validation loss: 2.510901093075616

Epoch: 84| Step: 0
Training loss: 2.6960594137476415
Validation loss: 2.510126878044358

Epoch: 5| Step: 1
Training loss: 2.9015463225160723
Validation loss: 2.512290229074651

Epoch: 5| Step: 2
Training loss: 2.4825972428344865
Validation loss: 2.5071330115521278

Epoch: 5| Step: 3
Training loss: 2.778684225535179
Validation loss: 2.5086671872132946

Epoch: 5| Step: 4
Training loss: 2.4779241531008385
Validation loss: 2.515754372565489

Epoch: 5| Step: 5
Training loss: 2.4773469759493936
Validation loss: 2.508705019950743

Epoch: 5| Step: 6
Training loss: 2.976318028941029
Validation loss: 2.5061580591944623

Epoch: 5| Step: 7
Training loss: 2.5238483673167202
Validation loss: 2.5078038802746465

Epoch: 5| Step: 8
Training loss: 2.6354537076696634
Validation loss: 2.500673135893066

Epoch: 5| Step: 9
Training loss: 2.7615200980258203
Validation loss: 2.5046809679669235

Epoch: 5| Step: 10
Training loss: 2.4631301073719767
Validation loss: 2.5043627223186786

Epoch: 5| Step: 11
Training loss: 1.5260149158133782
Validation loss: 2.506139670692022

Epoch: 85| Step: 0
Training loss: 2.246684280386834
Validation loss: 2.507740756520845

Epoch: 5| Step: 1
Training loss: 2.663534967988181
Validation loss: 2.5081881423025045

Epoch: 5| Step: 2
Training loss: 2.1993879724040317
Validation loss: 2.5068450242004046

Epoch: 5| Step: 3
Training loss: 2.8161716654482696
Validation loss: 2.507334385312377

Epoch: 5| Step: 4
Training loss: 2.3842770937595867
Validation loss: 2.508050556708344

Epoch: 5| Step: 5
Training loss: 2.6819303596381796
Validation loss: 2.509601845945069

Epoch: 5| Step: 6
Training loss: 2.6187104761605244
Validation loss: 2.509533617351728

Epoch: 5| Step: 7
Training loss: 2.5680976763358156
Validation loss: 2.5087634073294214

Epoch: 5| Step: 8
Training loss: 2.7723952363208446
Validation loss: 2.50960374995382

Epoch: 5| Step: 9
Training loss: 3.243300501966651
Validation loss: 2.5072010717017115

Epoch: 5| Step: 10
Training loss: 2.6816726315915864
Validation loss: 2.507468274221027

Epoch: 5| Step: 11
Training loss: 2.627163858008977
Validation loss: 2.507758194443364

Epoch: 86| Step: 0
Training loss: 2.6650994483757384
Validation loss: 2.5074389606334875

Epoch: 5| Step: 1
Training loss: 2.992519589314603
Validation loss: 2.5052582199829248

Epoch: 5| Step: 2
Training loss: 2.8509311761005063
Validation loss: 2.503720384226777

Epoch: 5| Step: 3
Training loss: 2.6089201205194965
Validation loss: 2.4983560362372392

Epoch: 5| Step: 4
Training loss: 2.795759351483942
Validation loss: 2.499433103501144

Epoch: 5| Step: 5
Training loss: 2.6670224925903168
Validation loss: 2.493866174743669

Epoch: 5| Step: 6
Training loss: 2.725108898681679
Validation loss: 2.49357528472845

Epoch: 5| Step: 7
Training loss: 2.761684476863669
Validation loss: 2.4993975668484025

Epoch: 5| Step: 8
Training loss: 2.5171564783402314
Validation loss: 2.496047384182677

Epoch: 5| Step: 9
Training loss: 2.0931127916574046
Validation loss: 2.493549162283212

Epoch: 5| Step: 10
Training loss: 2.2383709368620672
Validation loss: 2.493499665534583

Epoch: 5| Step: 11
Training loss: 2.2804007843856655
Validation loss: 2.4933021010125263

Epoch: 87| Step: 0
Training loss: 2.3978145424058446
Validation loss: 2.4971596676112404

Epoch: 5| Step: 1
Training loss: 2.4944298680291883
Validation loss: 2.4947826860514426

Epoch: 5| Step: 2
Training loss: 2.5232306711569086
Validation loss: 2.497897217467765

Epoch: 5| Step: 3
Training loss: 2.756551913725545
Validation loss: 2.487951623152178

Epoch: 5| Step: 4
Training loss: 2.5237718484659286
Validation loss: 2.4923255148752204

Epoch: 5| Step: 5
Training loss: 2.305810790379708
Validation loss: 2.4898046145132935

Epoch: 5| Step: 6
Training loss: 2.619416338285609
Validation loss: 2.491116900671137

Epoch: 5| Step: 7
Training loss: 2.7115830414141144
Validation loss: 2.4937039129640217

Epoch: 5| Step: 8
Training loss: 2.697520183950857
Validation loss: 2.488201840748998

Epoch: 5| Step: 9
Training loss: 2.891813126811688
Validation loss: 2.4901449548960186

Epoch: 5| Step: 10
Training loss: 2.6733802882928046
Validation loss: 2.4824009776142484

Epoch: 5| Step: 11
Training loss: 3.448004745480133
Validation loss: 2.4893796423791263

Epoch: 88| Step: 0
Training loss: 2.8730496964742263
Validation loss: 2.4921754898531283

Epoch: 5| Step: 1
Training loss: 2.201934601071576
Validation loss: 2.4912484092790264

Epoch: 5| Step: 2
Training loss: 2.4328351499352054
Validation loss: 2.4899192979736307

Epoch: 5| Step: 3
Training loss: 2.414308998337438
Validation loss: 2.4873357081191907

Epoch: 5| Step: 4
Training loss: 2.7604971723992877
Validation loss: 2.4889927939125087

Epoch: 5| Step: 5
Training loss: 2.9517053491810104
Validation loss: 2.4885392985938775

Epoch: 5| Step: 6
Training loss: 2.4440967596725973
Validation loss: 2.4895084614581515

Epoch: 5| Step: 7
Training loss: 2.775444916120995
Validation loss: 2.4865372523129112

Epoch: 5| Step: 8
Training loss: 2.6379599581463875
Validation loss: 2.488935455445316

Epoch: 5| Step: 9
Training loss: 2.2236711970364
Validation loss: 2.490282233283227

Epoch: 5| Step: 10
Training loss: 2.764834533486334
Validation loss: 2.4909587529592283

Epoch: 5| Step: 11
Training loss: 3.6514442356139494
Validation loss: 2.4925820049364695

Epoch: 89| Step: 0
Training loss: 2.6985175054073203
Validation loss: 2.493074496441375

Epoch: 5| Step: 1
Training loss: 2.451837675698796
Validation loss: 2.4930612832029873

Epoch: 5| Step: 2
Training loss: 2.795801564096283
Validation loss: 2.4915047191588195

Epoch: 5| Step: 3
Training loss: 2.276256897364415
Validation loss: 2.495729534260011

Epoch: 5| Step: 4
Training loss: 2.7123645027879064
Validation loss: 2.492685844159465

Epoch: 5| Step: 5
Training loss: 2.9615716179698
Validation loss: 2.493232161312458

Epoch: 5| Step: 6
Training loss: 2.406872755439403
Validation loss: 2.495105585617494

Epoch: 5| Step: 7
Training loss: 1.9852063697754256
Validation loss: 2.4982354891001326

Epoch: 5| Step: 8
Training loss: 2.613465352551439
Validation loss: 2.486497076686509

Epoch: 5| Step: 9
Training loss: 2.837082812859703
Validation loss: 2.487056376804875

Epoch: 5| Step: 10
Training loss: 2.7108331929568483
Validation loss: 2.489643281084543

Epoch: 5| Step: 11
Training loss: 3.5461048516845386
Validation loss: 2.4924278183270454

Epoch: 90| Step: 0
Training loss: 2.265191293179462
Validation loss: 2.494958799626575

Epoch: 5| Step: 1
Training loss: 2.4285277514977923
Validation loss: 2.4892840597934676

Epoch: 5| Step: 2
Training loss: 2.2785436174990603
Validation loss: 2.493699052875039

Epoch: 5| Step: 3
Training loss: 2.590289553654425
Validation loss: 2.493752075137085

Epoch: 5| Step: 4
Training loss: 2.8982810417782723
Validation loss: 2.488764617617699

Epoch: 5| Step: 5
Training loss: 2.214075133422904
Validation loss: 2.488448607976351

Epoch: 5| Step: 6
Training loss: 2.6682981229131237
Validation loss: 2.4913826861682202

Epoch: 5| Step: 7
Training loss: 3.1062500552632195
Validation loss: 2.4899510999139456

Epoch: 5| Step: 8
Training loss: 2.243112300263957
Validation loss: 2.4845582506584583

Epoch: 5| Step: 9
Training loss: 3.0176177877146624
Validation loss: 2.482413083072663

Epoch: 5| Step: 10
Training loss: 2.6767778531548676
Validation loss: 2.4846621333443313

Epoch: 5| Step: 11
Training loss: 3.2344190806457975
Validation loss: 2.486315499208991

Epoch: 91| Step: 0
Training loss: 2.055879776389724
Validation loss: 2.485250023027351

Epoch: 5| Step: 1
Training loss: 2.6302822190787727
Validation loss: 2.482752588124204

Epoch: 5| Step: 2
Training loss: 2.5385067375533996
Validation loss: 2.4850456764032476

Epoch: 5| Step: 3
Training loss: 2.678713340633036
Validation loss: 2.486136297960286

Epoch: 5| Step: 4
Training loss: 2.643376468757073
Validation loss: 2.485017665375539

Epoch: 5| Step: 5
Training loss: 2.129559505923706
Validation loss: 2.4837738605384114

Epoch: 5| Step: 6
Training loss: 2.9010003370608977
Validation loss: 2.484015040841486

Epoch: 5| Step: 7
Training loss: 2.6673755796208316
Validation loss: 2.4827235048867706

Epoch: 5| Step: 8
Training loss: 3.063479519892181
Validation loss: 2.4825491243568414

Epoch: 5| Step: 9
Training loss: 2.379434861957474
Validation loss: 2.4852750735201092

Epoch: 5| Step: 10
Training loss: 2.5371670734754592
Validation loss: 2.4812046551344484

Epoch: 5| Step: 11
Training loss: 3.517251820867952
Validation loss: 2.4844601294689266

Epoch: 92| Step: 0
Training loss: 2.2819110487402425
Validation loss: 2.4862577353974546

Epoch: 5| Step: 1
Training loss: 2.599408790421949
Validation loss: 2.480196231479805

Epoch: 5| Step: 2
Training loss: 3.030203255108962
Validation loss: 2.481768262180679

Epoch: 5| Step: 3
Training loss: 1.9968622150519297
Validation loss: 2.477460946934243

Epoch: 5| Step: 4
Training loss: 3.1727128449112203
Validation loss: 2.4814512374589013

Epoch: 5| Step: 5
Training loss: 2.5528603648913224
Validation loss: 2.478623167670312

Epoch: 5| Step: 6
Training loss: 3.1786516831554774
Validation loss: 2.4826524548875004

Epoch: 5| Step: 7
Training loss: 2.581762348895009
Validation loss: 2.4782381496117254

Epoch: 5| Step: 8
Training loss: 1.9302988666919425
Validation loss: 2.473940808418175

Epoch: 5| Step: 9
Training loss: 2.433634407107961
Validation loss: 2.4761217489252503

Epoch: 5| Step: 10
Training loss: 2.5335950937893927
Validation loss: 2.4780942309643326

Epoch: 5| Step: 11
Training loss: 2.9386589523613416
Validation loss: 2.4812016483211212

Epoch: 93| Step: 0
Training loss: 2.1894918909647934
Validation loss: 2.478293494853751

Epoch: 5| Step: 1
Training loss: 2.590613433480757
Validation loss: 2.482093583235731

Epoch: 5| Step: 2
Training loss: 2.004062341630276
Validation loss: 2.4831490840875277

Epoch: 5| Step: 3
Training loss: 3.0654523981716864
Validation loss: 2.486836036171727

Epoch: 5| Step: 4
Training loss: 2.781756322827991
Validation loss: 2.485507950674583

Epoch: 5| Step: 5
Training loss: 2.6309654933764612
Validation loss: 2.490565486661198

Epoch: 5| Step: 6
Training loss: 2.8213783849491634
Validation loss: 2.487481044971828

Epoch: 5| Step: 7
Training loss: 2.56612354039447
Validation loss: 2.487910476120625

Epoch: 5| Step: 8
Training loss: 2.9199195887323826
Validation loss: 2.486157871199666

Epoch: 5| Step: 9
Training loss: 2.4860071542933078
Validation loss: 2.484106369210259

Epoch: 5| Step: 10
Training loss: 2.5933411057591926
Validation loss: 2.4845815008940253

Epoch: 5| Step: 11
Training loss: 2.193414811395937
Validation loss: 2.4813628380050647

Epoch: 94| Step: 0
Training loss: 2.0637986689558376
Validation loss: 2.4832684073718854

Epoch: 5| Step: 1
Training loss: 2.670831309142712
Validation loss: 2.4777912577398786

Epoch: 5| Step: 2
Training loss: 2.441412304679992
Validation loss: 2.4772489861832008

Epoch: 5| Step: 3
Training loss: 2.9209065999969535
Validation loss: 2.4868575833677355

Epoch: 5| Step: 4
Training loss: 2.4523092480748345
Validation loss: 2.4865011078620927

Epoch: 5| Step: 5
Training loss: 2.621967744153119
Validation loss: 2.4920993976705614

Epoch: 5| Step: 6
Training loss: 2.390679452313375
Validation loss: 2.4889849192312012

Epoch: 5| Step: 7
Training loss: 2.2606503297010554
Validation loss: 2.484494076480254

Epoch: 5| Step: 8
Training loss: 2.7053040117498792
Validation loss: 2.484531873472578

Epoch: 5| Step: 9
Training loss: 2.7156391981870907
Validation loss: 2.4926934520905846

Epoch: 5| Step: 10
Training loss: 3.157155577418835
Validation loss: 2.4898132127641333

Epoch: 5| Step: 11
Training loss: 3.2695175407605355
Validation loss: 2.4918292913238473

Epoch: 95| Step: 0
Training loss: 2.930538125209789
Validation loss: 2.4890256414021192

Epoch: 5| Step: 1
Training loss: 2.4740936777671108
Validation loss: 2.489265925764708

Epoch: 5| Step: 2
Training loss: 2.1954712725475463
Validation loss: 2.495575442600309

Epoch: 5| Step: 3
Training loss: 2.5023862894082636
Validation loss: 2.4905248654544954

Epoch: 5| Step: 4
Training loss: 2.7010628656883635
Validation loss: 2.489914101343972

Epoch: 5| Step: 5
Training loss: 2.721946240619478
Validation loss: 2.49171470773328

Epoch: 5| Step: 6
Training loss: 2.2359542067654687
Validation loss: 2.491023697764485

Epoch: 5| Step: 7
Training loss: 2.854294897015874
Validation loss: 2.4882586371863007

Epoch: 5| Step: 8
Training loss: 2.8967899050760293
Validation loss: 2.4856527949099547

Epoch: 5| Step: 9
Training loss: 2.312581138218399
Validation loss: 2.488465346747794

Epoch: 5| Step: 10
Training loss: 2.570971558088973
Validation loss: 2.479208618631889

Epoch: 5| Step: 11
Training loss: 2.5774647185078186
Validation loss: 2.4755268277968443

Epoch: 96| Step: 0
Training loss: 2.6054318724257226
Validation loss: 2.4794049161877605

Epoch: 5| Step: 1
Training loss: 2.7081928705813363
Validation loss: 2.482555014668817

Epoch: 5| Step: 2
Training loss: 2.583808967939851
Validation loss: 2.4763137479860333

Epoch: 5| Step: 3
Training loss: 2.6732916394769326
Validation loss: 2.480439445743023

Epoch: 5| Step: 4
Training loss: 2.5858676128797335
Validation loss: 2.484963825110918

Epoch: 5| Step: 5
Training loss: 2.2103148753044084
Validation loss: 2.4782026898463574

Epoch: 5| Step: 6
Training loss: 2.4100683063308432
Validation loss: 2.480373070340831

Epoch: 5| Step: 7
Training loss: 2.888276006618009
Validation loss: 2.4725108412764327

Epoch: 5| Step: 8
Training loss: 2.540738441778061
Validation loss: 2.475307162487425

Epoch: 5| Step: 9
Training loss: 2.608903671001095
Validation loss: 2.4725883840173535

Epoch: 5| Step: 10
Training loss: 2.748529214288412
Validation loss: 2.473157682192433

Epoch: 5| Step: 11
Training loss: 2.222746031008824
Validation loss: 2.4769452799021248

Epoch: 97| Step: 0
Training loss: 2.7884165980312243
Validation loss: 2.4774386944837983

Epoch: 5| Step: 1
Training loss: 2.5090043037593537
Validation loss: 2.4727953951526183

Epoch: 5| Step: 2
Training loss: 2.4659701764483715
Validation loss: 2.480334933618741

Epoch: 5| Step: 3
Training loss: 2.3636644793552186
Validation loss: 2.4847706613628042

Epoch: 5| Step: 4
Training loss: 1.8042206263530354
Validation loss: 2.476159914429846

Epoch: 5| Step: 5
Training loss: 2.736594209660462
Validation loss: 2.480459126130906

Epoch: 5| Step: 6
Training loss: 2.5714585552283986
Validation loss: 2.474585448974623

Epoch: 5| Step: 7
Training loss: 2.9337291457707253
Validation loss: 2.478292188099772

Epoch: 5| Step: 8
Training loss: 2.541790432861006
Validation loss: 2.483992065251414

Epoch: 5| Step: 9
Training loss: 2.4975823156100962
Validation loss: 2.473523341970767

Epoch: 5| Step: 10
Training loss: 2.9888307552364464
Validation loss: 2.4782163510957202

Epoch: 5| Step: 11
Training loss: 3.353623119091104
Validation loss: 2.4754019182920874

Epoch: 98| Step: 0
Training loss: 2.436527449426807
Validation loss: 2.4834037597695224

Epoch: 5| Step: 1
Training loss: 2.517108835024743
Validation loss: 2.482641871138577

Epoch: 5| Step: 2
Training loss: 2.6499226324915446
Validation loss: 2.4846156821436596

Epoch: 5| Step: 3
Training loss: 2.495457336770379
Validation loss: 2.4838132123129815

Epoch: 5| Step: 4
Training loss: 2.8015719565185666
Validation loss: 2.4823742213403657

Epoch: 5| Step: 5
Training loss: 2.614141074742292
Validation loss: 2.4841210937308045

Epoch: 5| Step: 6
Training loss: 2.61526500635534
Validation loss: 2.482654723685272

Epoch: 5| Step: 7
Training loss: 2.653580075473409
Validation loss: 2.4826797723553122

Epoch: 5| Step: 8
Training loss: 3.1194228186178092
Validation loss: 2.4817574064699457

Epoch: 5| Step: 9
Training loss: 2.711553498126021
Validation loss: 2.482978780342634

Epoch: 5| Step: 10
Training loss: 1.9522096243615723
Validation loss: 2.4822583048365217

Epoch: 5| Step: 11
Training loss: 2.4635722270680347
Validation loss: 2.481885034122515

Epoch: 99| Step: 0
Training loss: 2.6420694948596117
Validation loss: 2.4820540120833448

Epoch: 5| Step: 1
Training loss: 2.5559763792256898
Validation loss: 2.481198084982367

Epoch: 5| Step: 2
Training loss: 2.6555423467122274
Validation loss: 2.4795135240712276

Epoch: 5| Step: 3
Training loss: 3.048174771592237
Validation loss: 2.4784347364664936

Epoch: 5| Step: 4
Training loss: 2.672606072600172
Validation loss: 2.475068729904137

Epoch: 5| Step: 5
Training loss: 2.28983957686576
Validation loss: 2.476882552877303

Epoch: 5| Step: 6
Training loss: 2.6530332947103767
Validation loss: 2.4772086879901565

Epoch: 5| Step: 7
Training loss: 2.475584396572499
Validation loss: 2.4737563295044063

Epoch: 5| Step: 8
Training loss: 2.554131683641067
Validation loss: 2.477080731167294

Epoch: 5| Step: 9
Training loss: 2.3560229609460266
Validation loss: 2.472373584663013

Epoch: 5| Step: 10
Training loss: 2.555488297595579
Validation loss: 2.4774881792989403

Epoch: 5| Step: 11
Training loss: 2.5676103203091407
Validation loss: 2.475483006250482

Epoch: 100| Step: 0
Training loss: 3.21143450452337
Validation loss: 2.4702488578369333

Epoch: 5| Step: 1
Training loss: 2.136060986580466
Validation loss: 2.474113725834831

Epoch: 5| Step: 2
Training loss: 2.8095921212928765
Validation loss: 2.4710310445703607

Epoch: 5| Step: 3
Training loss: 2.786946239121271
Validation loss: 2.4726604885488848

Epoch: 5| Step: 4
Training loss: 2.5676001061050386
Validation loss: 2.4809082162588485

Epoch: 5| Step: 5
Training loss: 2.6689213717824893
Validation loss: 2.4854540690709137

Epoch: 5| Step: 6
Training loss: 2.327052643885774
Validation loss: 2.4759319838539815

Epoch: 5| Step: 7
Training loss: 2.6488462599670917
Validation loss: 2.47387859550604

Epoch: 5| Step: 8
Training loss: 2.645339819670744
Validation loss: 2.4764075486478636

Epoch: 5| Step: 9
Training loss: 2.4493159954715127
Validation loss: 2.4708327328508064

Epoch: 5| Step: 10
Training loss: 2.3267800971675325
Validation loss: 2.474528286515355

Epoch: 5| Step: 11
Training loss: 1.3980626717437348
Validation loss: 2.47414981034129

Epoch: 101| Step: 0
Training loss: 2.5015930822005354
Validation loss: 2.4736577758252323

Epoch: 5| Step: 1
Training loss: 2.5604686594175243
Validation loss: 2.476660897980702

Epoch: 5| Step: 2
Training loss: 2.5250988855922145
Validation loss: 2.4778195208516065

Epoch: 5| Step: 3
Training loss: 2.2638375433135365
Validation loss: 2.47302371925942

Epoch: 5| Step: 4
Training loss: 2.5729293719967696
Validation loss: 2.475302097719451

Epoch: 5| Step: 5
Training loss: 2.338416783680621
Validation loss: 2.4745345050391876

Epoch: 5| Step: 6
Training loss: 2.723063412491473
Validation loss: 2.473624298566987

Epoch: 5| Step: 7
Training loss: 2.758896223029384
Validation loss: 2.4748232938962027

Epoch: 5| Step: 8
Training loss: 2.772425421218223
Validation loss: 2.474446083307497

Epoch: 5| Step: 9
Training loss: 2.526188629175054
Validation loss: 2.4786742199477785

Epoch: 5| Step: 10
Training loss: 2.7074118782841885
Validation loss: 2.475184690122112

Epoch: 5| Step: 11
Training loss: 3.494376296682975
Validation loss: 2.4729708671789736

Epoch: 102| Step: 0
Training loss: 2.4131415625860666
Validation loss: 2.4709009405464215

Epoch: 5| Step: 1
Training loss: 2.1880322490038084
Validation loss: 2.471448594363835

Epoch: 5| Step: 2
Training loss: 2.747688882876393
Validation loss: 2.4697411917477807

Epoch: 5| Step: 3
Training loss: 2.733386836652544
Validation loss: 2.4699817594505906

Epoch: 5| Step: 4
Training loss: 2.8891502123608874
Validation loss: 2.476197682174129

Epoch: 5| Step: 5
Training loss: 2.417925364362381
Validation loss: 2.4761508836251127

Epoch: 5| Step: 6
Training loss: 2.4792806348062917
Validation loss: 2.4796503554191998

Epoch: 5| Step: 7
Training loss: 2.728181724351889
Validation loss: 2.4811627355839825

Epoch: 5| Step: 8
Training loss: 2.7787473755968666
Validation loss: 2.4754137168635117

Epoch: 5| Step: 9
Training loss: 2.6245884345619186
Validation loss: 2.4906958258437046

Epoch: 5| Step: 10
Training loss: 2.685172115186937
Validation loss: 2.4795085259893743

Epoch: 5| Step: 11
Training loss: 1.860512906184305
Validation loss: 2.4760736089199273

Epoch: 103| Step: 0
Training loss: 2.543807165454868
Validation loss: 2.4664482339486353

Epoch: 5| Step: 1
Training loss: 2.0028838585307285
Validation loss: 2.4771566510612613

Epoch: 5| Step: 2
Training loss: 2.605861285378647
Validation loss: 2.4731460736976927

Epoch: 5| Step: 3
Training loss: 2.1129195208697285
Validation loss: 2.4882629609446405

Epoch: 5| Step: 4
Training loss: 2.8020777554556955
Validation loss: 2.5020112014291573

Epoch: 5| Step: 5
Training loss: 2.9667104039200622
Validation loss: 2.5064669175109744

Epoch: 5| Step: 6
Training loss: 3.1487246398994873
Validation loss: 2.5058473312710907

Epoch: 5| Step: 7
Training loss: 2.7648053867495124
Validation loss: 2.5126150340542455

Epoch: 5| Step: 8
Training loss: 2.6307866936763444
Validation loss: 2.5096872201193525

Epoch: 5| Step: 9
Training loss: 2.4262499272043336
Validation loss: 2.518270450136612

Epoch: 5| Step: 10
Training loss: 2.538812149616919
Validation loss: 2.5163783530901966

Epoch: 5| Step: 11
Training loss: 2.626339343665151
Validation loss: 2.511612141879488

Epoch: 104| Step: 0
Training loss: 2.97350003552088
Validation loss: 2.5064279887860277

Epoch: 5| Step: 1
Training loss: 2.388310327873872
Validation loss: 2.4917213857079497

Epoch: 5| Step: 2
Training loss: 2.1773291514454427
Validation loss: 2.481085196562253

Epoch: 5| Step: 3
Training loss: 2.5445889001159423
Validation loss: 2.4773802665650493

Epoch: 5| Step: 4
Training loss: 2.828916154500146
Validation loss: 2.4722964169111674

Epoch: 5| Step: 5
Training loss: 2.497866674012562
Validation loss: 2.4712837069844387

Epoch: 5| Step: 6
Training loss: 2.69374228916702
Validation loss: 2.4742709166497163

Epoch: 5| Step: 7
Training loss: 2.292373293970398
Validation loss: 2.4705440505212404

Epoch: 5| Step: 8
Training loss: 2.244646485155904
Validation loss: 2.4736412500999854

Epoch: 5| Step: 9
Training loss: 2.5948635606416666
Validation loss: 2.468146258382016

Epoch: 5| Step: 10
Training loss: 3.217588048291879
Validation loss: 2.478712270003565

Epoch: 5| Step: 11
Training loss: 1.8081443013948715
Validation loss: 2.468837539311912

Epoch: 105| Step: 0
Training loss: 2.6915974099271356
Validation loss: 2.4737035131560163

Epoch: 5| Step: 1
Training loss: 2.7524780032797387
Validation loss: 2.471273834294956

Epoch: 5| Step: 2
Training loss: 2.7506521492077405
Validation loss: 2.4753147395536046

Epoch: 5| Step: 3
Training loss: 2.6160057018696183
Validation loss: 2.4725224045399563

Epoch: 5| Step: 4
Training loss: 2.3016883085404136
Validation loss: 2.4698378906257723

Epoch: 5| Step: 5
Training loss: 2.683592150825124
Validation loss: 2.473448162011698

Epoch: 5| Step: 6
Training loss: 2.462294915658656
Validation loss: 2.4702701716985893

Epoch: 5| Step: 7
Training loss: 2.469255806014166
Validation loss: 2.468140941448286

Epoch: 5| Step: 8
Training loss: 2.5436877568758276
Validation loss: 2.472747768900026

Epoch: 5| Step: 9
Training loss: 2.489773433136447
Validation loss: 2.475524684893111

Epoch: 5| Step: 10
Training loss: 2.7527065829469213
Validation loss: 2.476317183963056

Epoch: 5| Step: 11
Training loss: 1.8582948384196714
Validation loss: 2.4775139257679286

Epoch: 106| Step: 0
Training loss: 1.9786172070649506
Validation loss: 2.4733360725984888

Epoch: 5| Step: 1
Training loss: 2.4936044903898025
Validation loss: 2.473107974154737

Epoch: 5| Step: 2
Training loss: 2.6890370608804965
Validation loss: 2.4698483241122884

Epoch: 5| Step: 3
Training loss: 2.8496912002581287
Validation loss: 2.4747990126834885

Epoch: 5| Step: 4
Training loss: 2.2844051333004214
Validation loss: 2.4728905525103464

Epoch: 5| Step: 5
Training loss: 2.8545912452342743
Validation loss: 2.470626930398828

Epoch: 5| Step: 6
Training loss: 2.560484861412952
Validation loss: 2.4690052978883155

Epoch: 5| Step: 7
Training loss: 2.8395114373676846
Validation loss: 2.4693248819839266

Epoch: 5| Step: 8
Training loss: 2.311094630266179
Validation loss: 2.4674742013677027

Epoch: 5| Step: 9
Training loss: 2.7148376025672305
Validation loss: 2.472861865485443

Epoch: 5| Step: 10
Training loss: 2.655451216924594
Validation loss: 2.464735025707275

Epoch: 5| Step: 11
Training loss: 3.1528418240831537
Validation loss: 2.4664598357040872

Epoch: 107| Step: 0
Training loss: 2.7821916850492485
Validation loss: 2.469320525065178

Epoch: 5| Step: 1
Training loss: 2.2538204606520367
Validation loss: 2.4697893988702004

Epoch: 5| Step: 2
Training loss: 2.2382733676099207
Validation loss: 2.4721314735639672

Epoch: 5| Step: 3
Training loss: 2.722982247537441
Validation loss: 2.4673279114916764

Epoch: 5| Step: 4
Training loss: 2.5644354605375055
Validation loss: 2.4693910072391647

Epoch: 5| Step: 5
Training loss: 2.8713737506960886
Validation loss: 2.47283609468428

Epoch: 5| Step: 6
Training loss: 2.9349492137875584
Validation loss: 2.4683334506183146

Epoch: 5| Step: 7
Training loss: 2.3522256822199723
Validation loss: 2.469712528476987

Epoch: 5| Step: 8
Training loss: 2.431321162185071
Validation loss: 2.4702422384379448

Epoch: 5| Step: 9
Training loss: 2.651390567346273
Validation loss: 2.4666916640299505

Epoch: 5| Step: 10
Training loss: 2.5567070214353915
Validation loss: 2.463193422561126

Epoch: 5| Step: 11
Training loss: 2.308397520345765
Validation loss: 2.4708156715863994

Epoch: 108| Step: 0
Training loss: 2.4059112112162624
Validation loss: 2.466813603634163

Epoch: 5| Step: 1
Training loss: 2.032824683537723
Validation loss: 2.4669351365341767

Epoch: 5| Step: 2
Training loss: 2.9546577472288185
Validation loss: 2.4637567709847974

Epoch: 5| Step: 3
Training loss: 2.689997466274047
Validation loss: 2.467571613093227

Epoch: 5| Step: 4
Training loss: 2.7072641952273533
Validation loss: 2.4644138386460477

Epoch: 5| Step: 5
Training loss: 2.5484537485471237
Validation loss: 2.467867906938787

Epoch: 5| Step: 6
Training loss: 3.111257165553423
Validation loss: 2.4623907228773425

Epoch: 5| Step: 7
Training loss: 2.213581674251656
Validation loss: 2.4709397113494735

Epoch: 5| Step: 8
Training loss: 2.3688504763910894
Validation loss: 2.47146615972831

Epoch: 5| Step: 9
Training loss: 2.303526298106209
Validation loss: 2.465750030422433

Epoch: 5| Step: 10
Training loss: 2.56477933785938
Validation loss: 2.461313241198121

Epoch: 5| Step: 11
Training loss: 3.5302080625862446
Validation loss: 2.460689960119977

Epoch: 109| Step: 0
Training loss: 2.798603482757933
Validation loss: 2.4648486750453262

Epoch: 5| Step: 1
Training loss: 2.5863294045163254
Validation loss: 2.4691795747977237

Epoch: 5| Step: 2
Training loss: 2.549991035445668
Validation loss: 2.4710814255503464

Epoch: 5| Step: 3
Training loss: 2.366468364395315
Validation loss: 2.465294838489606

Epoch: 5| Step: 4
Training loss: 2.540481593365086
Validation loss: 2.4700260365422766

Epoch: 5| Step: 5
Training loss: 2.4253734301097176
Validation loss: 2.4662057425537727

Epoch: 5| Step: 6
Training loss: 2.7005467108599737
Validation loss: 2.471915931218096

Epoch: 5| Step: 7
Training loss: 2.269224162508661
Validation loss: 2.471966921081428

Epoch: 5| Step: 8
Training loss: 2.6975330880356894
Validation loss: 2.4653337035006935

Epoch: 5| Step: 9
Training loss: 2.595835571124815
Validation loss: 2.459215601239555

Epoch: 5| Step: 10
Training loss: 2.735602141631898
Validation loss: 2.465134532480034

Epoch: 5| Step: 11
Training loss: 2.554827205092759
Validation loss: 2.4652003026856355

Epoch: 110| Step: 0
Training loss: 2.552100221746709
Validation loss: 2.460634404646426

Epoch: 5| Step: 1
Training loss: 2.5888089835733683
Validation loss: 2.457997066053487

Epoch: 5| Step: 2
Training loss: 1.9401489730542427
Validation loss: 2.456273328429299

Epoch: 5| Step: 3
Training loss: 2.9630773054241972
Validation loss: 2.459288978445628

Epoch: 5| Step: 4
Training loss: 2.2075601939789284
Validation loss: 2.4561682814511907

Epoch: 5| Step: 5
Training loss: 2.8636236259320276
Validation loss: 2.45998328545689

Epoch: 5| Step: 6
Training loss: 2.2631032655815853
Validation loss: 2.46244602491153

Epoch: 5| Step: 7
Training loss: 2.7970754881878133
Validation loss: 2.4635021389350045

Epoch: 5| Step: 8
Training loss: 2.269762982669679
Validation loss: 2.4656905076511375

Epoch: 5| Step: 9
Training loss: 2.831797370461219
Validation loss: 2.4579525439828847

Epoch: 5| Step: 10
Training loss: 2.5980774043286425
Validation loss: 2.467182522930386

Epoch: 5| Step: 11
Training loss: 3.1985676420762936
Validation loss: 2.46186454710041

Epoch: 111| Step: 0
Training loss: 2.6749851796818116
Validation loss: 2.4569214077136636

Epoch: 5| Step: 1
Training loss: 2.179095006558324
Validation loss: 2.4550163890488395

Epoch: 5| Step: 2
Training loss: 2.2301747784739887
Validation loss: 2.4555714874508308

Epoch: 5| Step: 3
Training loss: 3.0323449742881863
Validation loss: 2.4642084535257824

Epoch: 5| Step: 4
Training loss: 2.7327980944088583
Validation loss: 2.461112840652815

Epoch: 5| Step: 5
Training loss: 2.21652948724678
Validation loss: 2.466909358182634

Epoch: 5| Step: 6
Training loss: 2.8938597030113415
Validation loss: 2.457848272045099

Epoch: 5| Step: 7
Training loss: 2.2693955188812205
Validation loss: 2.454477872584418

Epoch: 5| Step: 8
Training loss: 2.615780398037893
Validation loss: 2.4596419138273125

Epoch: 5| Step: 9
Training loss: 2.995742001332859
Validation loss: 2.4618746713878745

Epoch: 5| Step: 10
Training loss: 2.124367675948193
Validation loss: 2.4647972396758777

Epoch: 5| Step: 11
Training loss: 2.511290897930692
Validation loss: 2.4612169985014143

Epoch: 112| Step: 0
Training loss: 2.4712550334657264
Validation loss: 2.4722042745362587

Epoch: 5| Step: 1
Training loss: 1.8997359995887704
Validation loss: 2.4718068387953953

Epoch: 5| Step: 2
Training loss: 2.148765067357822
Validation loss: 2.4716053517835443

Epoch: 5| Step: 3
Training loss: 3.146597274753295
Validation loss: 2.4702157928370467

Epoch: 5| Step: 4
Training loss: 2.943436326082269
Validation loss: 2.4737437760858048

Epoch: 5| Step: 5
Training loss: 2.5777781860124698
Validation loss: 2.4737203035119024

Epoch: 5| Step: 6
Training loss: 2.6572397519828397
Validation loss: 2.4695723890132104

Epoch: 5| Step: 7
Training loss: 2.3397339045193837
Validation loss: 2.468780702488554

Epoch: 5| Step: 8
Training loss: 2.397712921139073
Validation loss: 2.4678983909573864

Epoch: 5| Step: 9
Training loss: 2.8405710414549983
Validation loss: 2.4652625754310016

Epoch: 5| Step: 10
Training loss: 2.49449409722421
Validation loss: 2.4677831430449375

Epoch: 5| Step: 11
Training loss: 2.5090988520294237
Validation loss: 2.465567529392932

Epoch: 113| Step: 0
Training loss: 2.6253737229023235
Validation loss: 2.4686195001032414

Epoch: 5| Step: 1
Training loss: 2.1127696660843722
Validation loss: 2.4640675938371586

Epoch: 5| Step: 2
Training loss: 2.671017068463471
Validation loss: 2.46174202337697

Epoch: 5| Step: 3
Training loss: 2.477754901510484
Validation loss: 2.46651796046271

Epoch: 5| Step: 4
Training loss: 2.6344530557854333
Validation loss: 2.4658962809628555

Epoch: 5| Step: 5
Training loss: 2.7907958214434254
Validation loss: 2.466494991046081

Epoch: 5| Step: 6
Training loss: 2.8511017727651446
Validation loss: 2.4580892721890852

Epoch: 5| Step: 7
Training loss: 2.773760709600072
Validation loss: 2.460586696427074

Epoch: 5| Step: 8
Training loss: 2.212344635072094
Validation loss: 2.454818580360334

Epoch: 5| Step: 9
Training loss: 2.2448437206018457
Validation loss: 2.4492816176754566

Epoch: 5| Step: 10
Training loss: 2.4817466988178922
Validation loss: 2.4599814318845223

Epoch: 5| Step: 11
Training loss: 3.060760003746963
Validation loss: 2.4583697006531313

Epoch: 114| Step: 0
Training loss: 2.487294814498711
Validation loss: 2.468573133354086

Epoch: 5| Step: 1
Training loss: 2.668382827550739
Validation loss: 2.4663853446776116

Epoch: 5| Step: 2
Training loss: 2.5641617387888105
Validation loss: 2.46832275315163

Epoch: 5| Step: 3
Training loss: 2.491166243382153
Validation loss: 2.470092364223915

Epoch: 5| Step: 4
Training loss: 2.4658694302038713
Validation loss: 2.472086904664522

Epoch: 5| Step: 5
Training loss: 2.7491386972118317
Validation loss: 2.4706222340003543

Epoch: 5| Step: 6
Training loss: 2.3299174737026926
Validation loss: 2.464899045361257

Epoch: 5| Step: 7
Training loss: 2.685489345974724
Validation loss: 2.4594639842420922

Epoch: 5| Step: 8
Training loss: 2.54289580678554
Validation loss: 2.4589244218122386

Epoch: 5| Step: 9
Training loss: 2.454892439030075
Validation loss: 2.459797497254529

Epoch: 5| Step: 10
Training loss: 2.5760366593767414
Validation loss: 2.4538341234309478

Epoch: 5| Step: 11
Training loss: 2.5973474763619646
Validation loss: 2.4540774628457402

Epoch: 115| Step: 0
Training loss: 2.9237555505668076
Validation loss: 2.4567111240905803

Epoch: 5| Step: 1
Training loss: 2.3539335647451662
Validation loss: 2.451046672728928

Epoch: 5| Step: 2
Training loss: 2.5813941342658464
Validation loss: 2.4520849059906626

Epoch: 5| Step: 3
Training loss: 2.764534600601404
Validation loss: 2.451600781691521

Epoch: 5| Step: 4
Training loss: 2.811669290568136
Validation loss: 2.4596048531249752

Epoch: 5| Step: 5
Training loss: 2.4234466375477517
Validation loss: 2.461651197011229

Epoch: 5| Step: 6
Training loss: 1.8745702886908326
Validation loss: 2.46243038208174

Epoch: 5| Step: 7
Training loss: 2.7431598906385153
Validation loss: 2.455925911674078

Epoch: 5| Step: 8
Training loss: 2.395402709297431
Validation loss: 2.4700209086610414

Epoch: 5| Step: 9
Training loss: 2.384817111922446
Validation loss: 2.464305252602589

Epoch: 5| Step: 10
Training loss: 2.7081546626699367
Validation loss: 2.4606863832266055

Epoch: 5| Step: 11
Training loss: 2.806957293374121
Validation loss: 2.458958567836636

Epoch: 116| Step: 0
Training loss: 2.589473830281434
Validation loss: 2.4633289343431586

Epoch: 5| Step: 1
Training loss: 2.8082790490251504
Validation loss: 2.4598160504556046

Epoch: 5| Step: 2
Training loss: 2.5550393145199695
Validation loss: 2.452123575250378

Epoch: 5| Step: 3
Training loss: 2.628361502403521
Validation loss: 2.458183533878235

Epoch: 5| Step: 4
Training loss: 2.508189520615554
Validation loss: 2.4585946369846337

Epoch: 5| Step: 5
Training loss: 2.758076684849738
Validation loss: 2.4673649890555556

Epoch: 5| Step: 6
Training loss: 2.5488967827797846
Validation loss: 2.4656004109544534

Epoch: 5| Step: 7
Training loss: 2.32121243990336
Validation loss: 2.4597150157988277

Epoch: 5| Step: 8
Training loss: 2.602311401715837
Validation loss: 2.474367558949173

Epoch: 5| Step: 9
Training loss: 2.509626641488568
Validation loss: 2.470639797198227

Epoch: 5| Step: 10
Training loss: 2.6683242136576832
Validation loss: 2.4627399484201256

Epoch: 5| Step: 11
Training loss: 1.8121765111125292
Validation loss: 2.4595583649025574

Epoch: 117| Step: 0
Training loss: 2.298000552968356
Validation loss: 2.4631210812254607

Epoch: 5| Step: 1
Training loss: 2.5568579923054315
Validation loss: 2.459762341098977

Epoch: 5| Step: 2
Training loss: 2.356327539276124
Validation loss: 2.468493564984951

Epoch: 5| Step: 3
Training loss: 2.672018214620536
Validation loss: 2.4603847306709374

Epoch: 5| Step: 4
Training loss: 2.7194172709008684
Validation loss: 2.4565230644065204

Epoch: 5| Step: 5
Training loss: 2.6625194387666546
Validation loss: 2.454174610917381

Epoch: 5| Step: 6
Training loss: 2.0491318236692155
Validation loss: 2.4568869543840055

Epoch: 5| Step: 7
Training loss: 3.0288589328221485
Validation loss: 2.4566478217806997

Epoch: 5| Step: 8
Training loss: 2.3447649983183534
Validation loss: 2.460364853369643

Epoch: 5| Step: 9
Training loss: 2.84408030844829
Validation loss: 2.4635269145779275

Epoch: 5| Step: 10
Training loss: 2.478997991471056
Validation loss: 2.465033792382745

Epoch: 5| Step: 11
Training loss: 2.3969666385167128
Validation loss: 2.457102024047603

Epoch: 118| Step: 0
Training loss: 3.0970977241191697
Validation loss: 2.4679917285634776

Epoch: 5| Step: 1
Training loss: 2.792761308128951
Validation loss: 2.4622882627734826

Epoch: 5| Step: 2
Training loss: 2.080881799885326
Validation loss: 2.465477073625244

Epoch: 5| Step: 3
Training loss: 2.678603061307589
Validation loss: 2.462194535468538

Epoch: 5| Step: 4
Training loss: 2.055046253287116
Validation loss: 2.4565062090785346

Epoch: 5| Step: 5
Training loss: 2.477060454455166
Validation loss: 2.463476504108587

Epoch: 5| Step: 6
Training loss: 2.4947976342583136
Validation loss: 2.4677177939200754

Epoch: 5| Step: 7
Training loss: 2.7351278086199344
Validation loss: 2.4640516690097

Epoch: 5| Step: 8
Training loss: 2.424950400562954
Validation loss: 2.464202676582415

Epoch: 5| Step: 9
Training loss: 2.544212306796436
Validation loss: 2.4564936847832057

Epoch: 5| Step: 10
Training loss: 2.4016982785363084
Validation loss: 2.458363760474317

Epoch: 5| Step: 11
Training loss: 3.2463258368822103
Validation loss: 2.463393444148184

Epoch: 119| Step: 0
Training loss: 2.266272090713723
Validation loss: 2.4610048597694205

Epoch: 5| Step: 1
Training loss: 2.4661006956927745
Validation loss: 2.465677389402987

Epoch: 5| Step: 2
Training loss: 2.499448524685249
Validation loss: 2.464707928526076

Epoch: 5| Step: 3
Training loss: 2.3543249994107316
Validation loss: 2.455339116942718

Epoch: 5| Step: 4
Training loss: 2.8072451349953966
Validation loss: 2.4595179182225695

Epoch: 5| Step: 5
Training loss: 2.5143926220000647
Validation loss: 2.4556911515455218

Epoch: 5| Step: 6
Training loss: 2.3978622691073994
Validation loss: 2.4587659286819568

Epoch: 5| Step: 7
Training loss: 2.865787174540486
Validation loss: 2.4613387128962145

Epoch: 5| Step: 8
Training loss: 2.6292445969757776
Validation loss: 2.4732920073923688

Epoch: 5| Step: 9
Training loss: 2.193371223288624
Validation loss: 2.465982995033158

Epoch: 5| Step: 10
Training loss: 3.0867058292428418
Validation loss: 2.460357872252128

Epoch: 5| Step: 11
Training loss: 2.676614227953061
Validation loss: 2.4740477990821947

Epoch: 120| Step: 0
Training loss: 2.2715517593320884
Validation loss: 2.4725905013420264

Epoch: 5| Step: 1
Training loss: 2.791203721410622
Validation loss: 2.471849881545708

Epoch: 5| Step: 2
Training loss: 2.536645766166706
Validation loss: 2.467157171963711

Epoch: 5| Step: 3
Training loss: 2.655504099517169
Validation loss: 2.467581359690465

Epoch: 5| Step: 4
Training loss: 3.035664126839299
Validation loss: 2.4732455615501845

Epoch: 5| Step: 5
Training loss: 2.0298186908050444
Validation loss: 2.464456147894298

Epoch: 5| Step: 6
Training loss: 2.3441546281581624
Validation loss: 2.471125855801619

Epoch: 5| Step: 7
Training loss: 3.0781096637169503
Validation loss: 2.46023984435716

Epoch: 5| Step: 8
Training loss: 2.614059446416281
Validation loss: 2.457050236485581

Epoch: 5| Step: 9
Training loss: 2.1652057808920606
Validation loss: 2.450832153933113

Epoch: 5| Step: 10
Training loss: 2.5024906149887336
Validation loss: 2.458553388547326

Epoch: 5| Step: 11
Training loss: 2.391227696060996
Validation loss: 2.457034124666846

Epoch: 121| Step: 0
Training loss: 2.0533726187246497
Validation loss: 2.4526647310089467

Epoch: 5| Step: 1
Training loss: 2.3084258197567937
Validation loss: 2.453087524970131

Epoch: 5| Step: 2
Training loss: 2.855299750257118
Validation loss: 2.4489621358041735

Epoch: 5| Step: 3
Training loss: 2.4295661135461106
Validation loss: 2.4544779656732456

Epoch: 5| Step: 4
Training loss: 2.6049940600483072
Validation loss: 2.453007093864071

Epoch: 5| Step: 5
Training loss: 2.664273250891098
Validation loss: 2.446839119090689

Epoch: 5| Step: 6
Training loss: 2.5169609739834393
Validation loss: 2.453415543668478

Epoch: 5| Step: 7
Training loss: 2.3199084408549826
Validation loss: 2.4464078852767077

Epoch: 5| Step: 8
Training loss: 2.1795582066407984
Validation loss: 2.461265312038701

Epoch: 5| Step: 9
Training loss: 3.1869012606897225
Validation loss: 2.4514454966256807

Epoch: 5| Step: 10
Training loss: 2.689740156649063
Validation loss: 2.443693260678915

Epoch: 5| Step: 11
Training loss: 2.7388220673363066
Validation loss: 2.453596883690543

Epoch: 122| Step: 0
Training loss: 2.510236477749627
Validation loss: 2.452232720959658

Epoch: 5| Step: 1
Training loss: 2.5622422623693835
Validation loss: 2.4543472209589146

Epoch: 5| Step: 2
Training loss: 2.957224750108833
Validation loss: 2.454495357032685

Epoch: 5| Step: 3
Training loss: 2.742237318841661
Validation loss: 2.456491889238054

Epoch: 5| Step: 4
Training loss: 2.22811610579889
Validation loss: 2.4465108175775945

Epoch: 5| Step: 5
Training loss: 2.345353963689988
Validation loss: 2.4517327587685416

Epoch: 5| Step: 6
Training loss: 2.6681126210865367
Validation loss: 2.4537797284961

Epoch: 5| Step: 7
Training loss: 2.5527097179853557
Validation loss: 2.462877314362946

Epoch: 5| Step: 8
Training loss: 2.6918425849927354
Validation loss: 2.4531076799174074

Epoch: 5| Step: 9
Training loss: 2.0456949574378673
Validation loss: 2.457399402362646

Epoch: 5| Step: 10
Training loss: 2.4536140100278767
Validation loss: 2.458565346766201

Epoch: 5| Step: 11
Training loss: 3.1220386970071896
Validation loss: 2.4530341502089548

Epoch: 123| Step: 0
Training loss: 2.777769761603763
Validation loss: 2.461985410377478

Epoch: 5| Step: 1
Training loss: 2.718638889190794
Validation loss: 2.456215687221713

Epoch: 5| Step: 2
Training loss: 2.3501542142224285
Validation loss: 2.457694089073851

Epoch: 5| Step: 3
Training loss: 2.272311741382422
Validation loss: 2.459024070962705

Epoch: 5| Step: 4
Training loss: 2.86011833159531
Validation loss: 2.4526123434500096

Epoch: 5| Step: 5
Training loss: 2.2954659843674845
Validation loss: 2.4610760523631408

Epoch: 5| Step: 6
Training loss: 2.189922952733706
Validation loss: 2.459103824541178

Epoch: 5| Step: 7
Training loss: 2.7146543148555433
Validation loss: 2.4551526900211638

Epoch: 5| Step: 8
Training loss: 2.1418514775592183
Validation loss: 2.455851022252984

Epoch: 5| Step: 9
Training loss: 2.554744988124197
Validation loss: 2.4608029323701888

Epoch: 5| Step: 10
Training loss: 2.846115469921669
Validation loss: 2.449910384115663

Epoch: 5| Step: 11
Training loss: 2.5953244865273883
Validation loss: 2.4607485300000462

Epoch: 124| Step: 0
Training loss: 2.5281698064994775
Validation loss: 2.460869226063673

Epoch: 5| Step: 1
Training loss: 2.2306822024957955
Validation loss: 2.464804744260692

Epoch: 5| Step: 2
Training loss: 2.7533754094151637
Validation loss: 2.4610540735800734

Epoch: 5| Step: 3
Training loss: 2.330852063453475
Validation loss: 2.45660827343675

Epoch: 5| Step: 4
Training loss: 2.5883591483311412
Validation loss: 2.4562922398863973

Epoch: 5| Step: 5
Training loss: 2.670068855397912
Validation loss: 2.4525700931662406

Epoch: 5| Step: 6
Training loss: 2.4775152930779867
Validation loss: 2.4574228529593904

Epoch: 5| Step: 7
Training loss: 2.8193251976598783
Validation loss: 2.4578967285921145

Epoch: 5| Step: 8
Training loss: 2.5352880975561463
Validation loss: 2.4613478989486155

Epoch: 5| Step: 9
Training loss: 2.4350641257049404
Validation loss: 2.455924766951815

Epoch: 5| Step: 10
Training loss: 2.4890857875043504
Validation loss: 2.4615459880700414

Epoch: 5| Step: 11
Training loss: 2.295248272998934
Validation loss: 2.4571475480074216

Epoch: 125| Step: 0
Training loss: 2.4156016162367253
Validation loss: 2.462172687710452

Epoch: 5| Step: 1
Training loss: 2.0572847261593434
Validation loss: 2.463341647705359

Epoch: 5| Step: 2
Training loss: 2.3317070357032206
Validation loss: 2.4675486736141328

Epoch: 5| Step: 3
Training loss: 2.457416061566701
Validation loss: 2.47452171469494

Epoch: 5| Step: 4
Training loss: 2.3217702069258084
Validation loss: 2.469721132319987

Epoch: 5| Step: 5
Training loss: 2.3520186986115066
Validation loss: 2.465810981959451

Epoch: 5| Step: 6
Training loss: 2.8326408624596713
Validation loss: 2.468068109170442

Epoch: 5| Step: 7
Training loss: 3.224151227580007
Validation loss: 2.461352665511505

Epoch: 5| Step: 8
Training loss: 2.4105845461856514
Validation loss: 2.4548697938335367

Epoch: 5| Step: 9
Training loss: 2.4906963802433104
Validation loss: 2.4517202627632653

Epoch: 5| Step: 10
Training loss: 2.7633912284347977
Validation loss: 2.448855683968836

Epoch: 5| Step: 11
Training loss: 2.893573968200613
Validation loss: 2.4517143267332573

Epoch: 126| Step: 0
Training loss: 2.0691054946310974
Validation loss: 2.4483934195225805

Epoch: 5| Step: 1
Training loss: 2.563271197131022
Validation loss: 2.4502536467217664

Epoch: 5| Step: 2
Training loss: 2.6232860964537696
Validation loss: 2.4544901198059232

Epoch: 5| Step: 3
Training loss: 2.120547173261156
Validation loss: 2.4553682150322764

Epoch: 5| Step: 4
Training loss: 2.466031763056305
Validation loss: 2.4578528291595103

Epoch: 5| Step: 5
Training loss: 2.8627546172197653
Validation loss: 2.458738412188149

Epoch: 5| Step: 6
Training loss: 2.673020323727826
Validation loss: 2.468075978138505

Epoch: 5| Step: 7
Training loss: 2.667654172523059
Validation loss: 2.4696644968419843

Epoch: 5| Step: 8
Training loss: 2.943045879798367
Validation loss: 2.4698386488046697

Epoch: 5| Step: 9
Training loss: 2.025426998565926
Validation loss: 2.4684401329751853

Epoch: 5| Step: 10
Training loss: 2.6658901534405315
Validation loss: 2.468777040743918

Epoch: 5| Step: 11
Training loss: 1.9852588517458016
Validation loss: 2.471660154243613

Epoch: 127| Step: 0
Training loss: 2.663237144617516
Validation loss: 2.4814682916535307

Epoch: 5| Step: 1
Training loss: 2.203155517366764
Validation loss: 2.4659522375690393

Epoch: 5| Step: 2
Training loss: 2.2983404142931363
Validation loss: 2.479760516925894

Epoch: 5| Step: 3
Training loss: 2.3042766657458964
Validation loss: 2.4763437328927282

Epoch: 5| Step: 4
Training loss: 2.948041789676116
Validation loss: 2.477089582124683

Epoch: 5| Step: 5
Training loss: 2.928616666278284
Validation loss: 2.479764595107239

Epoch: 5| Step: 6
Training loss: 2.0492862156572618
Validation loss: 2.4809592775733718

Epoch: 5| Step: 7
Training loss: 3.4171428968800464
Validation loss: 2.4775086048796697

Epoch: 5| Step: 8
Training loss: 2.092994439742371
Validation loss: 2.4694142594785355

Epoch: 5| Step: 9
Training loss: 2.3752447303365813
Validation loss: 2.471144790275062

Epoch: 5| Step: 10
Training loss: 2.648086209475617
Validation loss: 2.466555485174332

Epoch: 5| Step: 11
Training loss: 2.5963953155858492
Validation loss: 2.4596519341763203

Epoch: 128| Step: 0
Training loss: 2.4895993369211915
Validation loss: 2.4665371276589276

Epoch: 5| Step: 1
Training loss: 2.0808717171954814
Validation loss: 2.4575234725195956

Epoch: 5| Step: 2
Training loss: 2.5326476771235296
Validation loss: 2.448715121676577

Epoch: 5| Step: 3
Training loss: 2.7876266929676405
Validation loss: 2.4575545638621876

Epoch: 5| Step: 4
Training loss: 2.851953934231925
Validation loss: 2.4479268594624304

Epoch: 5| Step: 5
Training loss: 2.3076192538606914
Validation loss: 2.4436652614376726

Epoch: 5| Step: 6
Training loss: 2.3583495077740007
Validation loss: 2.448969039882771

Epoch: 5| Step: 7
Training loss: 2.935590082537143
Validation loss: 2.450548724516766

Epoch: 5| Step: 8
Training loss: 2.2903733389757375
Validation loss: 2.450317071651668

Epoch: 5| Step: 9
Training loss: 2.5508928493604857
Validation loss: 2.446035044788152

Epoch: 5| Step: 10
Training loss: 2.682856607046789
Validation loss: 2.456045481650035

Epoch: 5| Step: 11
Training loss: 1.6068402671546977
Validation loss: 2.4595107973731216

Epoch: 129| Step: 0
Training loss: 2.86883431105044
Validation loss: 2.459147675383904

Epoch: 5| Step: 1
Training loss: 2.3925821109660674
Validation loss: 2.453277129621378

Epoch: 5| Step: 2
Training loss: 2.4397862789483384
Validation loss: 2.4524391900293323

Epoch: 5| Step: 3
Training loss: 2.2501752573210085
Validation loss: 2.45131430649041

Epoch: 5| Step: 4
Training loss: 2.519377569198718
Validation loss: 2.4519428190766597

Epoch: 5| Step: 5
Training loss: 2.359037665699918
Validation loss: 2.4497980611969488

Epoch: 5| Step: 6
Training loss: 2.6716010416133087
Validation loss: 2.4527725484880363

Epoch: 5| Step: 7
Training loss: 2.7905677131676416
Validation loss: 2.4575485145925873

Epoch: 5| Step: 8
Training loss: 2.6657560899885486
Validation loss: 2.4573670336226505

Epoch: 5| Step: 9
Training loss: 2.53239528036562
Validation loss: 2.4642589639132555

Epoch: 5| Step: 10
Training loss: 2.5210539245769814
Validation loss: 2.467449127170128

Epoch: 5| Step: 11
Training loss: 1.9359051077459606
Validation loss: 2.4619034945099627

Epoch: 130| Step: 0
Training loss: 2.607256366177321
Validation loss: 2.457795243183464

Epoch: 5| Step: 1
Training loss: 2.689786160417894
Validation loss: 2.4593282049655913

Epoch: 5| Step: 2
Training loss: 2.4065614969340365
Validation loss: 2.45004349835376

Epoch: 5| Step: 3
Training loss: 2.633087777708367
Validation loss: 2.4480174077725065

Epoch: 5| Step: 4
Training loss: 2.0815487529791494
Validation loss: 2.4512951215786125

Epoch: 5| Step: 5
Training loss: 2.3722870037912642
Validation loss: 2.4475234683090026

Epoch: 5| Step: 6
Training loss: 2.8035121144345445
Validation loss: 2.445991507153649

Epoch: 5| Step: 7
Training loss: 2.5577064897663626
Validation loss: 2.4492159513369303

Epoch: 5| Step: 8
Training loss: 2.9515761092898596
Validation loss: 2.4515755208311725

Epoch: 5| Step: 9
Training loss: 2.641935847032707
Validation loss: 2.4429038009573696

Epoch: 5| Step: 10
Training loss: 2.1669622610878583
Validation loss: 2.441420719358164

Epoch: 5| Step: 11
Training loss: 2.0036399619764533
Validation loss: 2.4417112236275558

Epoch: 131| Step: 0
Training loss: 2.3803000289872758
Validation loss: 2.442093138642264

Epoch: 5| Step: 1
Training loss: 2.6497685961185504
Validation loss: 2.4488043629737875

Epoch: 5| Step: 2
Training loss: 2.004406604428469
Validation loss: 2.4504258397196663

Epoch: 5| Step: 3
Training loss: 2.059389138064674
Validation loss: 2.4447537577035523

Epoch: 5| Step: 4
Training loss: 3.05458275500762
Validation loss: 2.452079432691541

Epoch: 5| Step: 5
Training loss: 3.2604921147368584
Validation loss: 2.4596859650931604

Epoch: 5| Step: 6
Training loss: 2.456395975293675
Validation loss: 2.451621360145154

Epoch: 5| Step: 7
Training loss: 2.5607027403576343
Validation loss: 2.459590977431726

Epoch: 5| Step: 8
Training loss: 2.5169642893486195
Validation loss: 2.455104001277331

Epoch: 5| Step: 9
Training loss: 2.2599979370242806
Validation loss: 2.45566350553128

Epoch: 5| Step: 10
Training loss: 2.186731694037699
Validation loss: 2.4557925904148408

Epoch: 5| Step: 11
Training loss: 3.5387587932772515
Validation loss: 2.4544109327086785

Epoch: 132| Step: 0
Training loss: 2.43593782103159
Validation loss: 2.4579512668309795

Epoch: 5| Step: 1
Training loss: 1.9376901102625836
Validation loss: 2.4495470515475115

Epoch: 5| Step: 2
Training loss: 2.097049106697814
Validation loss: 2.457693931434133

Epoch: 5| Step: 3
Training loss: 2.561714796393049
Validation loss: 2.454718438756245

Epoch: 5| Step: 4
Training loss: 2.8828379725542983
Validation loss: 2.4534054128171214

Epoch: 5| Step: 5
Training loss: 2.932876519554664
Validation loss: 2.4622362816981966

Epoch: 5| Step: 6
Training loss: 2.510008993854595
Validation loss: 2.4582265908833563

Epoch: 5| Step: 7
Training loss: 2.5299980929522055
Validation loss: 2.4619085384207557

Epoch: 5| Step: 8
Training loss: 2.4224645081745737
Validation loss: 2.4671336930962515

Epoch: 5| Step: 9
Training loss: 2.6532774505129755
Validation loss: 2.4683539640280094

Epoch: 5| Step: 10
Training loss: 2.5951716192455176
Validation loss: 2.466815891026455

Epoch: 5| Step: 11
Training loss: 3.155149362356606
Validation loss: 2.451213427998191

Epoch: 133| Step: 0
Training loss: 2.478768506387407
Validation loss: 2.4604235278902524

Epoch: 5| Step: 1
Training loss: 2.1492720768926055
Validation loss: 2.4557553866710276

Epoch: 5| Step: 2
Training loss: 2.4136560585552043
Validation loss: 2.457509324342948

Epoch: 5| Step: 3
Training loss: 2.1785291649785994
Validation loss: 2.4498927736822145

Epoch: 5| Step: 4
Training loss: 2.63158118549051
Validation loss: 2.4527090716222504

Epoch: 5| Step: 5
Training loss: 2.788316557477097
Validation loss: 2.459946985067628

Epoch: 5| Step: 6
Training loss: 2.8747528633377435
Validation loss: 2.4576351877039557

Epoch: 5| Step: 7
Training loss: 2.8017581528842594
Validation loss: 2.445576012726248

Epoch: 5| Step: 8
Training loss: 2.820625097645429
Validation loss: 2.455644233235399

Epoch: 5| Step: 9
Training loss: 2.3590603043827336
Validation loss: 2.4563808055276732

Epoch: 5| Step: 10
Training loss: 2.255186038241111
Validation loss: 2.454617250935901

Epoch: 5| Step: 11
Training loss: 1.045516940938777
Validation loss: 2.450669592552424

Epoch: 134| Step: 0
Training loss: 2.5872279517122365
Validation loss: 2.456711995499415

Epoch: 5| Step: 1
Training loss: 2.449475921319402
Validation loss: 2.4506244144310902

Epoch: 5| Step: 2
Training loss: 2.586251968670663
Validation loss: 2.4481030751670785

Epoch: 5| Step: 3
Training loss: 2.0567356823058516
Validation loss: 2.4541665435579416

Epoch: 5| Step: 4
Training loss: 2.660804165486042
Validation loss: 2.4577459479502832

Epoch: 5| Step: 5
Training loss: 2.484659046753353
Validation loss: 2.4537155307195504

Epoch: 5| Step: 6
Training loss: 1.9947265003472892
Validation loss: 2.4529542883822857

Epoch: 5| Step: 7
Training loss: 2.902190952719997
Validation loss: 2.4487250447490507

Epoch: 5| Step: 8
Training loss: 2.913488091112724
Validation loss: 2.4500562502443635

Epoch: 5| Step: 9
Training loss: 2.526881085694425
Validation loss: 2.4437318066231137

Epoch: 5| Step: 10
Training loss: 2.1127779038599437
Validation loss: 2.4573728589762465

Epoch: 5| Step: 11
Training loss: 3.3838662847429446
Validation loss: 2.456661307701294

Epoch: 135| Step: 0
Training loss: 2.597394841170187
Validation loss: 2.4575742840138894

Epoch: 5| Step: 1
Training loss: 2.303393398261739
Validation loss: 2.459095316861958

Epoch: 5| Step: 2
Training loss: 2.5560282417492237
Validation loss: 2.4637293445050967

Epoch: 5| Step: 3
Training loss: 2.1775642362770364
Validation loss: 2.4598503335275317

Epoch: 5| Step: 4
Training loss: 2.507729407149021
Validation loss: 2.463110885431257

Epoch: 5| Step: 5
Training loss: 2.8146203419595612
Validation loss: 2.462033829883469

Epoch: 5| Step: 6
Training loss: 2.277271616400218
Validation loss: 2.461141608114807

Epoch: 5| Step: 7
Training loss: 2.520397421818613
Validation loss: 2.4628785849268615

Epoch: 5| Step: 8
Training loss: 2.8573611312323375
Validation loss: 2.4611789201463403

Epoch: 5| Step: 9
Training loss: 2.6148704178689415
Validation loss: 2.462630332524958

Epoch: 5| Step: 10
Training loss: 2.5688606034202572
Validation loss: 2.458648153664181

Epoch: 5| Step: 11
Training loss: 1.8299212637884283
Validation loss: 2.461109873875646

Epoch: 136| Step: 0
Training loss: 2.8967125378990715
Validation loss: 2.4605507925256433

Epoch: 5| Step: 1
Training loss: 2.84758977197567
Validation loss: 2.4693918440017497

Epoch: 5| Step: 2
Training loss: 2.8584326353330956
Validation loss: 2.4648167628338875

Epoch: 5| Step: 3
Training loss: 2.6680675840153554
Validation loss: 2.461473574102171

Epoch: 5| Step: 4
Training loss: 2.2061392002542446
Validation loss: 2.4554543299246006

Epoch: 5| Step: 5
Training loss: 2.3006908871792424
Validation loss: 2.4579139300525843

Epoch: 5| Step: 6
Training loss: 2.5433352157999107
Validation loss: 2.4607720697900115

Epoch: 5| Step: 7
Training loss: 2.370706190332608
Validation loss: 2.4533340502712853

Epoch: 5| Step: 8
Training loss: 2.0460865161909165
Validation loss: 2.4507874611672587

Epoch: 5| Step: 9
Training loss: 2.6492010495655642
Validation loss: 2.4472927285835047

Epoch: 5| Step: 10
Training loss: 1.9213184698409267
Validation loss: 2.453454969369281

Epoch: 5| Step: 11
Training loss: 3.381423347810312
Validation loss: 2.45163300775295

Epoch: 137| Step: 0
Training loss: 2.4718235053909043
Validation loss: 2.4531631304780235

Epoch: 5| Step: 1
Training loss: 2.092237922909823
Validation loss: 2.462054302978143

Epoch: 5| Step: 2
Training loss: 1.9002246372541294
Validation loss: 2.4725406332441056

Epoch: 5| Step: 3
Training loss: 1.5763102757835372
Validation loss: 2.4698868399476126

Epoch: 5| Step: 4
Training loss: 2.9798607362298357
Validation loss: 2.471270071728649

Epoch: 5| Step: 5
Training loss: 2.583934457632692
Validation loss: 2.461806163166033

Epoch: 5| Step: 6
Training loss: 2.803416864856895
Validation loss: 2.4673934460803393

Epoch: 5| Step: 7
Training loss: 2.804264472362946
Validation loss: 2.46291471707013

Epoch: 5| Step: 8
Training loss: 2.941736291452255
Validation loss: 2.4598677636350956

Epoch: 5| Step: 9
Training loss: 2.791878355360267
Validation loss: 2.4534438750079293

Epoch: 5| Step: 10
Training loss: 2.5558200390642765
Validation loss: 2.4597326932256185

Epoch: 5| Step: 11
Training loss: 3.1355273120574476
Validation loss: 2.461335358929171

Epoch: 138| Step: 0
Training loss: 2.961623623144652
Validation loss: 2.464861684855862

Epoch: 5| Step: 1
Training loss: 2.1071348374886107
Validation loss: 2.4480092795417927

Epoch: 5| Step: 2
Training loss: 2.232423049779601
Validation loss: 2.4551299460684484

Epoch: 5| Step: 3
Training loss: 2.7899099392865416
Validation loss: 2.454941269553415

Epoch: 5| Step: 4
Training loss: 2.6717257987855874
Validation loss: 2.455923181328577

Epoch: 5| Step: 5
Training loss: 2.857269178731504
Validation loss: 2.4560856659833417

Epoch: 5| Step: 6
Training loss: 2.5836709222379164
Validation loss: 2.456839654565214

Epoch: 5| Step: 7
Training loss: 2.459774747785856
Validation loss: 2.455336046086954

Epoch: 5| Step: 8
Training loss: 1.9952446910355914
Validation loss: 2.4435516330570928

Epoch: 5| Step: 9
Training loss: 2.3818745752683053
Validation loss: 2.453599721893245

Epoch: 5| Step: 10
Training loss: 2.563678563469772
Validation loss: 2.4611310569898803

Epoch: 5| Step: 11
Training loss: 3.0888179421758135
Validation loss: 2.4592825032426866

Epoch: 139| Step: 0
Training loss: 2.371845660323467
Validation loss: 2.456614407919959

Epoch: 5| Step: 1
Training loss: 2.2461877952458096
Validation loss: 2.4589781333110876

Epoch: 5| Step: 2
Training loss: 2.563375370026538
Validation loss: 2.4562485079319947

Epoch: 5| Step: 3
Training loss: 2.365138208653506
Validation loss: 2.458414251536733

Epoch: 5| Step: 4
Training loss: 2.541143415611093
Validation loss: 2.4517655766866433

Epoch: 5| Step: 5
Training loss: 3.113179854939978
Validation loss: 2.4515910850205342

Epoch: 5| Step: 6
Training loss: 2.4140192416861463
Validation loss: 2.455500021984287

Epoch: 5| Step: 7
Training loss: 2.5342696274983925
Validation loss: 2.451941956101697

Epoch: 5| Step: 8
Training loss: 2.3625068341514597
Validation loss: 2.4513296352648113

Epoch: 5| Step: 9
Training loss: 2.685083944475367
Validation loss: 2.45415046138195

Epoch: 5| Step: 10
Training loss: 2.3217986514039355
Validation loss: 2.4515466897429143

Epoch: 5| Step: 11
Training loss: 3.111499463169126
Validation loss: 2.4544325460007217

Epoch: 140| Step: 0
Training loss: 1.9449677066034348
Validation loss: 2.4533160817588873

Epoch: 5| Step: 1
Training loss: 2.019709625335436
Validation loss: 2.4550197961595686

Epoch: 5| Step: 2
Training loss: 2.904502753609908
Validation loss: 2.4542390516926194

Epoch: 5| Step: 3
Training loss: 2.7762150140762376
Validation loss: 2.4530631420006332

Epoch: 5| Step: 4
Training loss: 2.6574514925415254
Validation loss: 2.453718838421778

Epoch: 5| Step: 5
Training loss: 2.252905982347113
Validation loss: 2.4513890265217695

Epoch: 5| Step: 6
Training loss: 2.5642637370268693
Validation loss: 2.4528668241446407

Epoch: 5| Step: 7
Training loss: 2.4097964421647067
Validation loss: 2.445477083007675

Epoch: 5| Step: 8
Training loss: 2.794568778605335
Validation loss: 2.451280706454203

Epoch: 5| Step: 9
Training loss: 2.6404612112318597
Validation loss: 2.4558229452102673

Epoch: 5| Step: 10
Training loss: 2.431381567212028
Validation loss: 2.4496169063237607

Epoch: 5| Step: 11
Training loss: 2.9247262679908665
Validation loss: 2.4500712422470814

Epoch: 141| Step: 0
Training loss: 2.081403626966574
Validation loss: 2.450315737815209

Epoch: 5| Step: 1
Training loss: 2.6411286725812158
Validation loss: 2.4494635273583323

Epoch: 5| Step: 2
Training loss: 2.6312773895650343
Validation loss: 2.4549093863707347

Epoch: 5| Step: 3
Training loss: 2.835280160937084
Validation loss: 2.4464382671811125

Epoch: 5| Step: 4
Training loss: 2.7468167000443584
Validation loss: 2.448111888865647

Epoch: 5| Step: 5
Training loss: 2.6153863431096305
Validation loss: 2.4530488952040708

Epoch: 5| Step: 6
Training loss: 2.717920812681331
Validation loss: 2.448502707165891

Epoch: 5| Step: 7
Training loss: 2.0382610514507418
Validation loss: 2.4567886014393823

Epoch: 5| Step: 8
Training loss: 2.3823518901952836
Validation loss: 2.4589433371200182

Epoch: 5| Step: 9
Training loss: 2.42354934404783
Validation loss: 2.4611282960912697

Epoch: 5| Step: 10
Training loss: 2.6508570958447253
Validation loss: 2.4638436127697902

Epoch: 5| Step: 11
Training loss: 1.804239258689669
Validation loss: 2.459521872446003

Epoch: 142| Step: 0
Training loss: 2.327023648891433
Validation loss: 2.463707330925516

Epoch: 5| Step: 1
Training loss: 2.4353334628582965
Validation loss: 2.461145176273828

Epoch: 5| Step: 2
Training loss: 3.0278745124443898
Validation loss: 2.4631575445570713

Epoch: 5| Step: 3
Training loss: 2.727858708025569
Validation loss: 2.455534017393131

Epoch: 5| Step: 4
Training loss: 2.2064804605171657
Validation loss: 2.459380166720077

Epoch: 5| Step: 5
Training loss: 2.1722806922130755
Validation loss: 2.454155749931947

Epoch: 5| Step: 6
Training loss: 2.4715415527135187
Validation loss: 2.449217995578096

Epoch: 5| Step: 7
Training loss: 2.551336301085008
Validation loss: 2.440119859664649

Epoch: 5| Step: 8
Training loss: 2.1181292814615023
Validation loss: 2.4486872995361364

Epoch: 5| Step: 9
Training loss: 2.862184572123598
Validation loss: 2.444562705627906

Epoch: 5| Step: 10
Training loss: 2.674642456973276
Validation loss: 2.4564802262506613

Epoch: 5| Step: 11
Training loss: 2.0343427148650886
Validation loss: 2.4599810119027894

Epoch: 143| Step: 0
Training loss: 2.1216396240564643
Validation loss: 2.4594098511568907

Epoch: 5| Step: 1
Training loss: 2.8418670121284744
Validation loss: 2.4640191336625294

Epoch: 5| Step: 2
Training loss: 2.2932621574815673
Validation loss: 2.451071136552515

Epoch: 5| Step: 3
Training loss: 2.417358518640047
Validation loss: 2.4461331925064655

Epoch: 5| Step: 4
Training loss: 2.831869607455967
Validation loss: 2.449527033579388

Epoch: 5| Step: 5
Training loss: 2.8444343833281813
Validation loss: 2.45790153822312

Epoch: 5| Step: 6
Training loss: 2.3517447873050976
Validation loss: 2.4462541304865164

Epoch: 5| Step: 7
Training loss: 2.7639621541734916
Validation loss: 2.441912305137034

Epoch: 5| Step: 8
Training loss: 2.583946729459335
Validation loss: 2.4529114000503545

Epoch: 5| Step: 9
Training loss: 2.015340149143079
Validation loss: 2.443965248228417

Epoch: 5| Step: 10
Training loss: 2.5829268617690846
Validation loss: 2.444757250226772

Epoch: 5| Step: 11
Training loss: 2.024807852588681
Validation loss: 2.4480737486957462

Epoch: 144| Step: 0
Training loss: 2.168187255845286
Validation loss: 2.4428307449045326

Epoch: 5| Step: 1
Training loss: 2.35549547170788
Validation loss: 2.447770347009865

Epoch: 5| Step: 2
Training loss: 2.657858417704147
Validation loss: 2.4577736796720395

Epoch: 5| Step: 3
Training loss: 2.4423075484767343
Validation loss: 2.452357583170498

Epoch: 5| Step: 4
Training loss: 2.673792903604078
Validation loss: 2.446668283557704

Epoch: 5| Step: 5
Training loss: 2.28507507701716
Validation loss: 2.444968364903569

Epoch: 5| Step: 6
Training loss: 2.49343343460702
Validation loss: 2.450642639819202

Epoch: 5| Step: 7
Training loss: 2.59938796982828
Validation loss: 2.4491646419472213

Epoch: 5| Step: 8
Training loss: 2.693787339520383
Validation loss: 2.44539894869321

Epoch: 5| Step: 9
Training loss: 2.290813934736198
Validation loss: 2.4425984312492814

Epoch: 5| Step: 10
Training loss: 2.762095985385539
Validation loss: 2.4400405400522427

Epoch: 5| Step: 11
Training loss: 3.253703135073408
Validation loss: 2.4428226482155675

Epoch: 145| Step: 0
Training loss: 2.1860520066324827
Validation loss: 2.458792891355339

Epoch: 5| Step: 1
Training loss: 2.7932980643377303
Validation loss: 2.462871324552802

Epoch: 5| Step: 2
Training loss: 2.538118063535138
Validation loss: 2.460056001735211

Epoch: 5| Step: 3
Training loss: 2.8299771982629096
Validation loss: 2.4673370067997182

Epoch: 5| Step: 4
Training loss: 2.7960022145263896
Validation loss: 2.467046302715502

Epoch: 5| Step: 5
Training loss: 2.226717117027373
Validation loss: 2.467340290201711

Epoch: 5| Step: 6
Training loss: 2.425314644919618
Validation loss: 2.465938725917352

Epoch: 5| Step: 7
Training loss: 2.58833077772235
Validation loss: 2.4690145278401276

Epoch: 5| Step: 8
Training loss: 1.951996378011939
Validation loss: 2.476612744388271

Epoch: 5| Step: 9
Training loss: 2.706143055976605
Validation loss: 2.4768517181921976

Epoch: 5| Step: 10
Training loss: 2.446165868280228
Validation loss: 2.4738241955715745

Epoch: 5| Step: 11
Training loss: 3.5722225096923124
Validation loss: 2.4693059536707294

Epoch: 146| Step: 0
Training loss: 2.139861590285651
Validation loss: 2.465085214756541

Epoch: 5| Step: 1
Training loss: 2.3964622888270157
Validation loss: 2.469987828543889

Epoch: 5| Step: 2
Training loss: 2.328014601579736
Validation loss: 2.468021208795389

Epoch: 5| Step: 3
Training loss: 2.218821349810085
Validation loss: 2.460666702145797

Epoch: 5| Step: 4
Training loss: 2.602465315412681
Validation loss: 2.459634215780557

Epoch: 5| Step: 5
Training loss: 2.72592417942769
Validation loss: 2.4537912767921943

Epoch: 5| Step: 6
Training loss: 2.9727630796548166
Validation loss: 2.4516428379748105

Epoch: 5| Step: 7
Training loss: 2.679530191947937
Validation loss: 2.444380195512666

Epoch: 5| Step: 8
Training loss: 2.628135806321143
Validation loss: 2.442748341236118

Epoch: 5| Step: 9
Training loss: 2.829421109952325
Validation loss: 2.4394389697545593

Epoch: 5| Step: 10
Training loss: 2.21695389380581
Validation loss: 2.4303834578727557

Epoch: 5| Step: 11
Training loss: 2.494808146529164
Validation loss: 2.4462349018286598

Epoch: 147| Step: 0
Training loss: 2.500777886485847
Validation loss: 2.435584322170656

Epoch: 5| Step: 1
Training loss: 2.7134054861230754
Validation loss: 2.4397048596334225

Epoch: 5| Step: 2
Training loss: 2.475451102713659
Validation loss: 2.4496361368216233

Epoch: 5| Step: 3
Training loss: 2.3691462605559517
Validation loss: 2.44515112566833

Epoch: 5| Step: 4
Training loss: 2.340423970572432
Validation loss: 2.447470443041866

Epoch: 5| Step: 5
Training loss: 2.732937854751207
Validation loss: 2.451156081190558

Epoch: 5| Step: 6
Training loss: 2.51147250901004
Validation loss: 2.4587646539726893

Epoch: 5| Step: 7
Training loss: 2.2965915011917004
Validation loss: 2.4660805099735486

Epoch: 5| Step: 8
Training loss: 2.946666942383536
Validation loss: 2.4703405905857054

Epoch: 5| Step: 9
Training loss: 2.412521710075769
Validation loss: 2.4744187913671265

Epoch: 5| Step: 10
Training loss: 2.4543032398229383
Validation loss: 2.469496549728392

Epoch: 5| Step: 11
Training loss: 2.6501235321330183
Validation loss: 2.4724136723695214

Epoch: 148| Step: 0
Training loss: 2.731403938337432
Validation loss: 2.4761256124420696

Epoch: 5| Step: 1
Training loss: 2.645723736112595
Validation loss: 2.471263595759764

Epoch: 5| Step: 2
Training loss: 2.2481989539811926
Validation loss: 2.4677043643971563

Epoch: 5| Step: 3
Training loss: 2.42822555274875
Validation loss: 2.464285668954921

Epoch: 5| Step: 4
Training loss: 2.6649274121216586
Validation loss: 2.461668957386574

Epoch: 5| Step: 5
Training loss: 2.322273016966789
Validation loss: 2.4656651010544004

Epoch: 5| Step: 6
Training loss: 2.5726812978313465
Validation loss: 2.4590199907029877

Epoch: 5| Step: 7
Training loss: 2.4191564252975857
Validation loss: 2.4592868981421128

Epoch: 5| Step: 8
Training loss: 2.13512275968235
Validation loss: 2.4585981704547724

Epoch: 5| Step: 9
Training loss: 3.2528757430419026
Validation loss: 2.453509988967098

Epoch: 5| Step: 10
Training loss: 2.413968278842397
Validation loss: 2.449795340242142

Epoch: 5| Step: 11
Training loss: 2.415003028536017
Validation loss: 2.4454675732923934

Epoch: 149| Step: 0
Training loss: 2.7429223448093714
Validation loss: 2.449310696471521

Epoch: 5| Step: 1
Training loss: 2.756138279871574
Validation loss: 2.452463352365078

Epoch: 5| Step: 2
Training loss: 2.151126468886486
Validation loss: 2.4500061221597695

Epoch: 5| Step: 3
Training loss: 2.45134646337273
Validation loss: 2.442768024346979

Epoch: 5| Step: 4
Training loss: 2.476392481410179
Validation loss: 2.444049159484543

Epoch: 5| Step: 5
Training loss: 3.0318068160059406
Validation loss: 2.441792165137056

Epoch: 5| Step: 6
Training loss: 2.395898724092059
Validation loss: 2.4483738790140683

Epoch: 5| Step: 7
Training loss: 2.510996665803495
Validation loss: 2.448084469718534

Epoch: 5| Step: 8
Training loss: 2.2819458409735485
Validation loss: 2.438972460404252

Epoch: 5| Step: 9
Training loss: 2.211483945142723
Validation loss: 2.443990612136086

Epoch: 5| Step: 10
Training loss: 2.4587518583600034
Validation loss: 2.446709762814314

Epoch: 5| Step: 11
Training loss: 2.966502252230359
Validation loss: 2.446144072296163

Epoch: 150| Step: 0
Training loss: 2.826687610866519
Validation loss: 2.45433788120601

Epoch: 5| Step: 1
Training loss: 2.821316780648713
Validation loss: 2.4641548600643413

Epoch: 5| Step: 2
Training loss: 2.1563473002276834
Validation loss: 2.4542579828726834

Epoch: 5| Step: 3
Training loss: 2.8816170216643813
Validation loss: 2.4562634479843735

Epoch: 5| Step: 4
Training loss: 2.242178993341877
Validation loss: 2.4553286460775103

Epoch: 5| Step: 5
Training loss: 2.2315676465714334
Validation loss: 2.4513300101245843

Epoch: 5| Step: 6
Training loss: 2.7789884652155403
Validation loss: 2.4521427415269907

Epoch: 5| Step: 7
Training loss: 2.5372191325373676
Validation loss: 2.450833203753386

Epoch: 5| Step: 8
Training loss: 2.28176518723771
Validation loss: 2.4613430556915166

Epoch: 5| Step: 9
Training loss: 2.439588874356704
Validation loss: 2.454638846222996

Epoch: 5| Step: 10
Training loss: 2.3907162518008604
Validation loss: 2.4572401438075646

Epoch: 5| Step: 11
Training loss: 1.7777482798566289
Validation loss: 2.45478547951106

Epoch: 151| Step: 0
Training loss: 2.305295495478219
Validation loss: 2.4482393025098617

Epoch: 5| Step: 1
Training loss: 2.2316330311153725
Validation loss: 2.4513486314649278

Epoch: 5| Step: 2
Training loss: 2.485598856496164
Validation loss: 2.451725068303311

Epoch: 5| Step: 3
Training loss: 2.7889501725345274
Validation loss: 2.4556913174044865

Epoch: 5| Step: 4
Training loss: 2.3407001233746105
Validation loss: 2.4493981295193836

Epoch: 5| Step: 5
Training loss: 2.7932696413807294
Validation loss: 2.459394940316045

Epoch: 5| Step: 6
Training loss: 2.148572106046048
Validation loss: 2.455786567143898

Epoch: 5| Step: 7
Training loss: 2.2354284617411166
Validation loss: 2.4500874180995256

Epoch: 5| Step: 8
Training loss: 1.943446355818847
Validation loss: 2.4585135940691583

Epoch: 5| Step: 9
Training loss: 3.3003932025044675
Validation loss: 2.4550302096688097

Epoch: 5| Step: 10
Training loss: 2.624240311184543
Validation loss: 2.454095397447624

Epoch: 5| Step: 11
Training loss: 3.1032169263117986
Validation loss: 2.456135856040508

Epoch: 152| Step: 0
Training loss: 1.9823731064082928
Validation loss: 2.4577151722845336

Epoch: 5| Step: 1
Training loss: 2.4708551051020646
Validation loss: 2.4529653525592696

Epoch: 5| Step: 2
Training loss: 2.8213289495060305
Validation loss: 2.4585153174256438

Epoch: 5| Step: 3
Training loss: 2.8820942136360523
Validation loss: 2.458172317393466

Epoch: 5| Step: 4
Training loss: 3.097180093004509
Validation loss: 2.4612078260874055

Epoch: 5| Step: 5
Training loss: 2.5622387264382227
Validation loss: 2.466755628807301

Epoch: 5| Step: 6
Training loss: 1.9192658988927163
Validation loss: 2.4595808316271417

Epoch: 5| Step: 7
Training loss: 2.170607711674815
Validation loss: 2.456378613567601

Epoch: 5| Step: 8
Training loss: 1.955712824184712
Validation loss: 2.4566668637981706

Epoch: 5| Step: 9
Training loss: 2.603492914145131
Validation loss: 2.454353437996833

Epoch: 5| Step: 10
Training loss: 2.7950586142902467
Validation loss: 2.4591089832668063

Epoch: 5| Step: 11
Training loss: 2.979964107322875
Validation loss: 2.446996813616791

Epoch: 153| Step: 0
Training loss: 2.6708928137795
Validation loss: 2.4572465738576703

Epoch: 5| Step: 1
Training loss: 2.553637740944298
Validation loss: 2.4490923526968245

Epoch: 5| Step: 2
Training loss: 2.0341174500275523
Validation loss: 2.450734178186093

Epoch: 5| Step: 3
Training loss: 2.3638997931502224
Validation loss: 2.451060558288979

Epoch: 5| Step: 4
Training loss: 2.9072295148204694
Validation loss: 2.4438876387265887

Epoch: 5| Step: 5
Training loss: 2.3900100814734397
Validation loss: 2.447646330387078

Epoch: 5| Step: 6
Training loss: 1.984063912585079
Validation loss: 2.4451587352406503

Epoch: 5| Step: 7
Training loss: 2.9345448015218087
Validation loss: 2.446888193555318

Epoch: 5| Step: 8
Training loss: 2.2031143945749836
Validation loss: 2.4476190927239814

Epoch: 5| Step: 9
Training loss: 2.8131317276907044
Validation loss: 2.4446452553826323

Epoch: 5| Step: 10
Training loss: 2.385541410113531
Validation loss: 2.439605304989361

Epoch: 5| Step: 11
Training loss: 2.4807331575058167
Validation loss: 2.4425141773183348

Epoch: 154| Step: 0
Training loss: 2.5666623619175604
Validation loss: 2.4489196440575993

Epoch: 5| Step: 1
Training loss: 2.155132501692997
Validation loss: 2.4429143535436717

Epoch: 5| Step: 2
Training loss: 2.0134858601416794
Validation loss: 2.454850802623994

Epoch: 5| Step: 3
Training loss: 2.7540902150710758
Validation loss: 2.450611600637348

Epoch: 5| Step: 4
Training loss: 2.520791760146494
Validation loss: 2.4524810739604197

Epoch: 5| Step: 5
Training loss: 2.3928775522138435
Validation loss: 2.444302046456154

Epoch: 5| Step: 6
Training loss: 1.9341240049842963
Validation loss: 2.4528109720016116

Epoch: 5| Step: 7
Training loss: 3.060001677718357
Validation loss: 2.4543107845906538

Epoch: 5| Step: 8
Training loss: 2.4851919306544397
Validation loss: 2.442055750600352

Epoch: 5| Step: 9
Training loss: 2.7427993483074338
Validation loss: 2.447402414455253

Epoch: 5| Step: 10
Training loss: 2.8569300470116636
Validation loss: 2.441080915009581

Epoch: 5| Step: 11
Training loss: 1.366362535356491
Validation loss: 2.442431974469138

Epoch: 155| Step: 0
Training loss: 2.307000399446887
Validation loss: 2.4451807736148092

Epoch: 5| Step: 1
Training loss: 2.7949828668386556
Validation loss: 2.444119386812882

Epoch: 5| Step: 2
Training loss: 2.656930185631911
Validation loss: 2.4460773876434465

Epoch: 5| Step: 3
Training loss: 2.6581797153807103
Validation loss: 2.4414595005585875

Epoch: 5| Step: 4
Training loss: 2.1992306751314117
Validation loss: 2.4396540913037756

Epoch: 5| Step: 5
Training loss: 2.456948768674693
Validation loss: 2.445189861923263

Epoch: 5| Step: 6
Training loss: 2.0698791050276175
Validation loss: 2.446271320413196

Epoch: 5| Step: 7
Training loss: 3.260353615895612
Validation loss: 2.445034145319625

Epoch: 5| Step: 8
Training loss: 2.4667263187034507
Validation loss: 2.4476123715374234

Epoch: 5| Step: 9
Training loss: 2.0675331893526416
Validation loss: 2.453296270688736

Epoch: 5| Step: 10
Training loss: 2.286925480304468
Validation loss: 2.4465179437807896

Epoch: 5| Step: 11
Training loss: 2.880280331107825
Validation loss: 2.457123468120963

Epoch: 156| Step: 0
Training loss: 2.2970219779185865
Validation loss: 2.45108815692325

Epoch: 5| Step: 1
Training loss: 2.1122508472030517
Validation loss: 2.449590392159067

Epoch: 5| Step: 2
Training loss: 2.143012059379393
Validation loss: 2.453839592816224

Epoch: 5| Step: 3
Training loss: 1.9975272031418922
Validation loss: 2.449416992665943

Epoch: 5| Step: 4
Training loss: 2.464674083837166
Validation loss: 2.4515614983885037

Epoch: 5| Step: 5
Training loss: 2.7659513636551813
Validation loss: 2.452273506551232

Epoch: 5| Step: 6
Training loss: 2.597795296296215
Validation loss: 2.447210860800329

Epoch: 5| Step: 7
Training loss: 2.329773799083297
Validation loss: 2.4506585707080215

Epoch: 5| Step: 8
Training loss: 2.4451843813157264
Validation loss: 2.447303578863111

Epoch: 5| Step: 9
Training loss: 2.509720881319301
Validation loss: 2.4373474358635674

Epoch: 5| Step: 10
Training loss: 3.3882156460712807
Validation loss: 2.4545730844207196

Epoch: 5| Step: 11
Training loss: 2.5282394967952535
Validation loss: 2.447149510938578

Epoch: 157| Step: 0
Training loss: 2.86687349268273
Validation loss: 2.4477491578490373

Epoch: 5| Step: 1
Training loss: 2.3795102109134882
Validation loss: 2.4400931445958136

Epoch: 5| Step: 2
Training loss: 3.013074834279795
Validation loss: 2.4607673929349003

Epoch: 5| Step: 3
Training loss: 2.7788764169124924
Validation loss: 2.4743038592060773

Epoch: 5| Step: 4
Training loss: 2.2594519342221693
Validation loss: 2.465511769546115

Epoch: 5| Step: 5
Training loss: 2.350057938044147
Validation loss: 2.473769951056108

Epoch: 5| Step: 6
Training loss: 2.7849388947281026
Validation loss: 2.47500836759495

Epoch: 5| Step: 7
Training loss: 2.6635922551090756
Validation loss: 2.475254796620584

Epoch: 5| Step: 8
Training loss: 2.303249621804597
Validation loss: 2.46566301605803

Epoch: 5| Step: 9
Training loss: 2.6247270533028
Validation loss: 2.468082076068369

Epoch: 5| Step: 10
Training loss: 1.7880498693923388
Validation loss: 2.469402637409097

Epoch: 5| Step: 11
Training loss: 3.150718752285875
Validation loss: 2.474047305197097

Epoch: 158| Step: 0
Training loss: 2.838758510507973
Validation loss: 2.4636179762319865

Epoch: 5| Step: 1
Training loss: 2.2183667778782317
Validation loss: 2.467739644918073

Epoch: 5| Step: 2
Training loss: 2.6322087804085124
Validation loss: 2.46887940659158

Epoch: 5| Step: 3
Training loss: 2.5163535253809757
Validation loss: 2.4695299642741144

Epoch: 5| Step: 4
Training loss: 2.342338238548628
Validation loss: 2.4567056954694158

Epoch: 5| Step: 5
Training loss: 2.651437776022822
Validation loss: 2.4636490834040123

Epoch: 5| Step: 6
Training loss: 2.6899998593241716
Validation loss: 2.462005020392139

Epoch: 5| Step: 7
Training loss: 2.0857082055184266
Validation loss: 2.458278487019336

Epoch: 5| Step: 8
Training loss: 2.8005949035539315
Validation loss: 2.4656486426292856

Epoch: 5| Step: 9
Training loss: 2.2771473402385
Validation loss: 2.4502505694924728

Epoch: 5| Step: 10
Training loss: 2.6767120301744205
Validation loss: 2.4602814299400904

Epoch: 5| Step: 11
Training loss: 2.6233495337419455
Validation loss: 2.458869614270138

Epoch: 159| Step: 0
Training loss: 2.4845960986521534
Validation loss: 2.457414970091125

Epoch: 5| Step: 1
Training loss: 2.304476867361039
Validation loss: 2.45620962049896

Epoch: 5| Step: 2
Training loss: 2.3460576204864574
Validation loss: 2.453509715663833

Epoch: 5| Step: 3
Training loss: 2.3446498923455037
Validation loss: 2.456076747423607

Epoch: 5| Step: 4
Training loss: 2.484462040749967
Validation loss: 2.4573057513596743

Epoch: 5| Step: 5
Training loss: 2.5012591052330486
Validation loss: 2.455163554119202

Epoch: 5| Step: 6
Training loss: 2.5271732797572843
Validation loss: 2.4655581817791563

Epoch: 5| Step: 7
Training loss: 2.283883129764118
Validation loss: 2.4585171013912848

Epoch: 5| Step: 8
Training loss: 2.5829825214380926
Validation loss: 2.4557428909085464

Epoch: 5| Step: 9
Training loss: 2.648396719559512
Validation loss: 2.4537805766550154

Epoch: 5| Step: 10
Training loss: 3.0548990083724505
Validation loss: 2.4614829755677743

Epoch: 5| Step: 11
Training loss: 1.7022750553523092
Validation loss: 2.4573460929592463

Epoch: 160| Step: 0
Training loss: 1.8585286498243758
Validation loss: 2.464518804234774

Epoch: 5| Step: 1
Training loss: 2.639519635048884
Validation loss: 2.4646601903308554

Epoch: 5| Step: 2
Training loss: 2.709226832578806
Validation loss: 2.463864074858278

Epoch: 5| Step: 3
Training loss: 2.460765529860665
Validation loss: 2.4593381579239675

Epoch: 5| Step: 4
Training loss: 2.735845551832904
Validation loss: 2.4665927797497886

Epoch: 5| Step: 5
Training loss: 2.571351928174242
Validation loss: 2.4638026558268185

Epoch: 5| Step: 6
Training loss: 2.5242929809574277
Validation loss: 2.4550028880226

Epoch: 5| Step: 7
Training loss: 2.003958361210221
Validation loss: 2.4502738209250783

Epoch: 5| Step: 8
Training loss: 2.398320595939626
Validation loss: 2.465492368740076

Epoch: 5| Step: 9
Training loss: 1.9677974273506638
Validation loss: 2.4589989489789303

Epoch: 5| Step: 10
Training loss: 3.343530522924391
Validation loss: 2.468571616218696

Epoch: 5| Step: 11
Training loss: 1.480185771056998
Validation loss: 2.4617776879612108

Epoch: 161| Step: 0
Training loss: 2.2116376758889826
Validation loss: 2.464253231432437

Epoch: 5| Step: 1
Training loss: 2.2995963032582445
Validation loss: 2.466178198296211

Epoch: 5| Step: 2
Training loss: 2.349674721789757
Validation loss: 2.4704933529787367

Epoch: 5| Step: 3
Training loss: 2.484443327725879
Validation loss: 2.471548863986407

Epoch: 5| Step: 4
Training loss: 2.702372716399395
Validation loss: 2.4725947841981553

Epoch: 5| Step: 5
Training loss: 2.2778682987968857
Validation loss: 2.471133638651576

Epoch: 5| Step: 6
Training loss: 2.1255723519045766
Validation loss: 2.4661555117155705

Epoch: 5| Step: 7
Training loss: 2.57366224186568
Validation loss: 2.467365786243231

Epoch: 5| Step: 8
Training loss: 2.7433490955584414
Validation loss: 2.4672478197973113

Epoch: 5| Step: 9
Training loss: 2.71441120022555
Validation loss: 2.462413163759876

Epoch: 5| Step: 10
Training loss: 2.5426662751537408
Validation loss: 2.461290915407267

Epoch: 5| Step: 11
Training loss: 3.1630048326279914
Validation loss: 2.473473034826553

Epoch: 162| Step: 0
Training loss: 2.7699061302778
Validation loss: 2.462192667422194

Epoch: 5| Step: 1
Training loss: 2.913319183536389
Validation loss: 2.47012010211561

Epoch: 5| Step: 2
Training loss: 2.69620302388418
Validation loss: 2.4645432875005975

Epoch: 5| Step: 3
Training loss: 2.2684033425893224
Validation loss: 2.4695264102414094

Epoch: 5| Step: 4
Training loss: 2.4052924690934034
Validation loss: 2.470609419381367

Epoch: 5| Step: 5
Training loss: 2.201202744383421
Validation loss: 2.470830133563624

Epoch: 5| Step: 6
Training loss: 2.6291343283944135
Validation loss: 2.4707552335167065

Epoch: 5| Step: 7
Training loss: 1.998089473863156
Validation loss: 2.472351923289396

Epoch: 5| Step: 8
Training loss: 1.8915512086136446
Validation loss: 2.4742578218115527

Epoch: 5| Step: 9
Training loss: 2.47822327388905
Validation loss: 2.4731817987664915

Epoch: 5| Step: 10
Training loss: 2.874981092307901
Validation loss: 2.4733708912276184

Epoch: 5| Step: 11
Training loss: 1.905944862332739
Validation loss: 2.465025357560246

Epoch: 163| Step: 0
Training loss: 2.617391367701114
Validation loss: 2.4670882869660633

Epoch: 5| Step: 1
Training loss: 2.6500511092529577
Validation loss: 2.4606409489614824

Epoch: 5| Step: 2
Training loss: 2.043456856238792
Validation loss: 2.4638848028814513

Epoch: 5| Step: 3
Training loss: 2.250424450999358
Validation loss: 2.4634089498007916

Epoch: 5| Step: 4
Training loss: 1.417096418757574
Validation loss: 2.462022871018652

Epoch: 5| Step: 5
Training loss: 2.527435253910082
Validation loss: 2.460629228932741

Epoch: 5| Step: 6
Training loss: 2.711442619998249
Validation loss: 2.4627767441245885

Epoch: 5| Step: 7
Training loss: 2.4014430396722983
Validation loss: 2.468426453840588

Epoch: 5| Step: 8
Training loss: 2.646568156249952
Validation loss: 2.470941299397603

Epoch: 5| Step: 9
Training loss: 2.978097915125968
Validation loss: 2.463714586819847

Epoch: 5| Step: 10
Training loss: 2.793817905906454
Validation loss: 2.4663284110642145

Epoch: 5| Step: 11
Training loss: 1.5849150570512058
Validation loss: 2.464574143163379

Epoch: 164| Step: 0
Training loss: 2.181451555356364
Validation loss: 2.4706896634545576

Epoch: 5| Step: 1
Training loss: 2.6365596016785067
Validation loss: 2.465555226394755

Epoch: 5| Step: 2
Training loss: 2.5752588234607603
Validation loss: 2.4694112423318093

Epoch: 5| Step: 3
Training loss: 2.2024577327487305
Validation loss: 2.464995273259282

Epoch: 5| Step: 4
Training loss: 2.2230566431775047
Validation loss: 2.4579573939207826

Epoch: 5| Step: 5
Training loss: 2.838443878075946
Validation loss: 2.474342353864313

Epoch: 5| Step: 6
Training loss: 2.252156813343522
Validation loss: 2.468777113174084

Epoch: 5| Step: 7
Training loss: 2.1513954468965024
Validation loss: 2.466618676191308

Epoch: 5| Step: 8
Training loss: 2.8940337007006356
Validation loss: 2.4695691910423467

Epoch: 5| Step: 9
Training loss: 2.4870492229613914
Validation loss: 2.470770881940024

Epoch: 5| Step: 10
Training loss: 2.554204399323866
Validation loss: 2.4706329215106346

Epoch: 5| Step: 11
Training loss: 2.4594475974161423
Validation loss: 2.465312340916465

Epoch: 165| Step: 0
Training loss: 2.5679546080763624
Validation loss: 2.4654618227379235

Epoch: 5| Step: 1
Training loss: 2.5582040271533186
Validation loss: 2.467777233576248

Epoch: 5| Step: 2
Training loss: 2.3647474548474556
Validation loss: 2.4654827327482054

Epoch: 5| Step: 3
Training loss: 2.895374087869064
Validation loss: 2.455376213709764

Epoch: 5| Step: 4
Training loss: 2.2606384121700254
Validation loss: 2.464475706001749

Epoch: 5| Step: 5
Training loss: 2.401118169022276
Validation loss: 2.457621189730503

Epoch: 5| Step: 6
Training loss: 2.5063143143999156
Validation loss: 2.455909968435941

Epoch: 5| Step: 7
Training loss: 2.8251035789473287
Validation loss: 2.4550936265211747

Epoch: 5| Step: 8
Training loss: 2.5758613590166775
Validation loss: 2.457920934278197

Epoch: 5| Step: 9
Training loss: 1.856282844638202
Validation loss: 2.4534158149576872

Epoch: 5| Step: 10
Training loss: 2.4233538634713088
Validation loss: 2.4563908149145814

Epoch: 5| Step: 11
Training loss: 1.57721177673703
Validation loss: 2.4727022428890475

Epoch: 166| Step: 0
Training loss: 2.638473808258334
Validation loss: 2.471738611888222

Epoch: 5| Step: 1
Training loss: 2.0436399097714224
Validation loss: 2.486642190895441

Epoch: 5| Step: 2
Training loss: 2.691212595933519
Validation loss: 2.4760082077849135

Epoch: 5| Step: 3
Training loss: 2.691710699880618
Validation loss: 2.4692816503889032

Epoch: 5| Step: 4
Training loss: 2.67609718852185
Validation loss: 2.458473873700946

Epoch: 5| Step: 5
Training loss: 2.2229627991179264
Validation loss: 2.468428995291893

Epoch: 5| Step: 6
Training loss: 2.2475128202316697
Validation loss: 2.4635069214922543

Epoch: 5| Step: 7
Training loss: 2.2987897508346604
Validation loss: 2.474368454250906

Epoch: 5| Step: 8
Training loss: 2.67369588632204
Validation loss: 2.4718945089728583

Epoch: 5| Step: 9
Training loss: 2.8302183044130653
Validation loss: 2.4777712474462765

Epoch: 5| Step: 10
Training loss: 2.5189305735338254
Validation loss: 2.4735905457550325

Epoch: 5| Step: 11
Training loss: 1.5511835378815042
Validation loss: 2.469753435681785

Epoch: 167| Step: 0
Training loss: 2.326721075327214
Validation loss: 2.469476395789937

Epoch: 5| Step: 1
Training loss: 2.297825104268893
Validation loss: 2.470605860870108

Epoch: 5| Step: 2
Training loss: 2.5679318612527213
Validation loss: 2.470459113052073

Epoch: 5| Step: 3
Training loss: 2.6403217931622947
Validation loss: 2.4696667413693087

Epoch: 5| Step: 4
Training loss: 2.6260484690554766
Validation loss: 2.4692071338529913

Epoch: 5| Step: 5
Training loss: 2.034377990814214
Validation loss: 2.4621778763183833

Epoch: 5| Step: 6
Training loss: 2.7646706006540542
Validation loss: 2.4740509832333464

Epoch: 5| Step: 7
Training loss: 2.0844154090910596
Validation loss: 2.4784399271037545

Epoch: 5| Step: 8
Training loss: 2.3855162243008508
Validation loss: 2.4768200328271193

Epoch: 5| Step: 9
Training loss: 2.7414616768061393
Validation loss: 2.466571981850908

Epoch: 5| Step: 10
Training loss: 2.4659456187220816
Validation loss: 2.4735574912877483

Epoch: 5| Step: 11
Training loss: 2.3849941584677503
Validation loss: 2.463624554960849

Epoch: 168| Step: 0
Training loss: 2.2837054480772867
Validation loss: 2.4691094486903817

Epoch: 5| Step: 1
Training loss: 2.2269282525799237
Validation loss: 2.468683990368627

Epoch: 5| Step: 2
Training loss: 2.986051877245041
Validation loss: 2.4694566660914616

Epoch: 5| Step: 3
Training loss: 2.2643810145576992
Validation loss: 2.4654731430555143

Epoch: 5| Step: 4
Training loss: 2.345413431515622
Validation loss: 2.4576284736989167

Epoch: 5| Step: 5
Training loss: 1.989569346060859
Validation loss: 2.464420433389921

Epoch: 5| Step: 6
Training loss: 2.350722254693944
Validation loss: 2.4657638734710003

Epoch: 5| Step: 7
Training loss: 2.612956165113928
Validation loss: 2.4661291431371124

Epoch: 5| Step: 8
Training loss: 2.509780444387182
Validation loss: 2.4596933964199144

Epoch: 5| Step: 9
Training loss: 2.6481138498604078
Validation loss: 2.464937727195088

Epoch: 5| Step: 10
Training loss: 2.4337918367791747
Validation loss: 2.468942095530093

Epoch: 5| Step: 11
Training loss: 3.598125679793964
Validation loss: 2.46615889739484

Epoch: 169| Step: 0
Training loss: 2.8229247277251477
Validation loss: 2.460001389010743

Epoch: 5| Step: 1
Training loss: 2.7074934219463604
Validation loss: 2.4685675195460606

Epoch: 5| Step: 2
Training loss: 2.7964414974527068
Validation loss: 2.469833039884187

Epoch: 5| Step: 3
Training loss: 2.508360615663236
Validation loss: 2.4658886628702477

Epoch: 5| Step: 4
Training loss: 1.9781383519980056
Validation loss: 2.4677068341305515

Epoch: 5| Step: 5
Training loss: 2.198766631409949
Validation loss: 2.484727336682701

Epoch: 5| Step: 6
Training loss: 1.902370444860506
Validation loss: 2.4745925264454853

Epoch: 5| Step: 7
Training loss: 3.176825657802266
Validation loss: 2.472658833306014

Epoch: 5| Step: 8
Training loss: 2.3389607643727994
Validation loss: 2.4603687214412644

Epoch: 5| Step: 9
Training loss: 2.1065060921125243
Validation loss: 2.4732581034394268

Epoch: 5| Step: 10
Training loss: 2.268344798828717
Validation loss: 2.468894342637164

Epoch: 5| Step: 11
Training loss: 2.831919616603689
Validation loss: 2.465020573918989

Epoch: 170| Step: 0
Training loss: 2.5737030022041565
Validation loss: 2.4685445792609477

Epoch: 5| Step: 1
Training loss: 2.4764876971094214
Validation loss: 2.477278199857946

Epoch: 5| Step: 2
Training loss: 2.170891847999446
Validation loss: 2.4722800066501454

Epoch: 5| Step: 3
Training loss: 2.9508047525622803
Validation loss: 2.4914115068362865

Epoch: 5| Step: 4
Training loss: 2.5632486877884517
Validation loss: 2.4728214636594053

Epoch: 5| Step: 5
Training loss: 2.381788690465179
Validation loss: 2.4696061263478826

Epoch: 5| Step: 6
Training loss: 1.7977048864835181
Validation loss: 2.4749840641150898

Epoch: 5| Step: 7
Training loss: 2.450415214075874
Validation loss: 2.474718528534088

Epoch: 5| Step: 8
Training loss: 2.3360486466620367
Validation loss: 2.473128640769327

Epoch: 5| Step: 9
Training loss: 2.887423830555241
Validation loss: 2.470734213330638

Epoch: 5| Step: 10
Training loss: 2.3434157069538784
Validation loss: 2.476924637110947

Epoch: 5| Step: 11
Training loss: 2.533446689211201
Validation loss: 2.474373512900351

Epoch: 171| Step: 0
Training loss: 2.45770642536095
Validation loss: 2.475677275869349

Epoch: 5| Step: 1
Training loss: 2.135381360266117
Validation loss: 2.4713978028272146

Epoch: 5| Step: 2
Training loss: 2.6883522279299665
Validation loss: 2.4766462253734147

Epoch: 5| Step: 3
Training loss: 2.273276726455168
Validation loss: 2.4772456296963776

Epoch: 5| Step: 4
Training loss: 2.8004859332354726
Validation loss: 2.474385685735043

Epoch: 5| Step: 5
Training loss: 1.938776887551053
Validation loss: 2.4727632982525543

Epoch: 5| Step: 6
Training loss: 2.6477630566676753
Validation loss: 2.4775742190138

Epoch: 5| Step: 7
Training loss: 3.1577578427106605
Validation loss: 2.4683799707779257

Epoch: 5| Step: 8
Training loss: 2.1801413880440856
Validation loss: 2.4766729633072417

Epoch: 5| Step: 9
Training loss: 1.7974002236381095
Validation loss: 2.4777437114785243

Epoch: 5| Step: 10
Training loss: 2.622810267885282
Validation loss: 2.4758115406055223

Epoch: 5| Step: 11
Training loss: 2.1747147910248477
Validation loss: 2.472054157604641

Epoch: 172| Step: 0
Training loss: 2.096356150624223
Validation loss: 2.4722598874572053

Epoch: 5| Step: 1
Training loss: 2.1336791125848698
Validation loss: 2.4818492221894513

Epoch: 5| Step: 2
Training loss: 2.2010139469604355
Validation loss: 2.493105453238625

Epoch: 5| Step: 3
Training loss: 2.2296402924210996
Validation loss: 2.4797058574315094

Epoch: 5| Step: 4
Training loss: 2.8720910656233376
Validation loss: 2.471537850845826

Epoch: 5| Step: 5
Training loss: 2.4495163148148635
Validation loss: 2.4712942067232975

Epoch: 5| Step: 6
Training loss: 2.089319124059473
Validation loss: 2.4620935338583116

Epoch: 5| Step: 7
Training loss: 2.8644394347143183
Validation loss: 2.461268438057382

Epoch: 5| Step: 8
Training loss: 2.442874753660685
Validation loss: 2.4741135331043305

Epoch: 5| Step: 9
Training loss: 3.034751207187562
Validation loss: 2.46615146742395

Epoch: 5| Step: 10
Training loss: 2.5389125368875156
Validation loss: 2.471503850479208

Epoch: 5| Step: 11
Training loss: 2.5345156290758086
Validation loss: 2.469951108089529

Epoch: 173| Step: 0
Training loss: 2.7186293301166145
Validation loss: 2.480907097078524

Epoch: 5| Step: 1
Training loss: 2.3894456934068877
Validation loss: 2.4725784502450363

Epoch: 5| Step: 2
Training loss: 2.283302115716565
Validation loss: 2.4655551236512663

Epoch: 5| Step: 3
Training loss: 2.5164522504939595
Validation loss: 2.4632375917962634

Epoch: 5| Step: 4
Training loss: 2.6106088428029293
Validation loss: 2.4679075767452305

Epoch: 5| Step: 5
Training loss: 2.605684148529321
Validation loss: 2.4698752522787872

Epoch: 5| Step: 6
Training loss: 2.6226408211689174
Validation loss: 2.46895632706549

Epoch: 5| Step: 7
Training loss: 2.6542875333260927
Validation loss: 2.4721771004990556

Epoch: 5| Step: 8
Training loss: 2.3857407884129134
Validation loss: 2.4795190329674104

Epoch: 5| Step: 9
Training loss: 2.0220671619916537
Validation loss: 2.4714014928458075

Epoch: 5| Step: 10
Training loss: 2.0582063082317266
Validation loss: 2.4675104755667516

Epoch: 5| Step: 11
Training loss: 2.829952429381716
Validation loss: 2.475617704871091

Epoch: 174| Step: 0
Training loss: 2.595937243280551
Validation loss: 2.47860760088507

Epoch: 5| Step: 1
Training loss: 2.579065139900427
Validation loss: 2.4680015942564792

Epoch: 5| Step: 2
Training loss: 2.797230532761264
Validation loss: 2.47151130254426

Epoch: 5| Step: 3
Training loss: 2.2631388736985425
Validation loss: 2.4604822373488378

Epoch: 5| Step: 4
Training loss: 2.062393994930631
Validation loss: 2.4621212004726027

Epoch: 5| Step: 5
Training loss: 2.5593128387764703
Validation loss: 2.46022607521131

Epoch: 5| Step: 6
Training loss: 2.316176507631047
Validation loss: 2.4534161064923268

Epoch: 5| Step: 7
Training loss: 2.3024721004357276
Validation loss: 2.4538146950718795

Epoch: 5| Step: 8
Training loss: 2.1196009544668444
Validation loss: 2.455398429424408

Epoch: 5| Step: 9
Training loss: 3.0732386188710614
Validation loss: 2.458485032239499

Epoch: 5| Step: 10
Training loss: 2.1170951569748873
Validation loss: 2.455879742134577

Epoch: 5| Step: 11
Training loss: 3.1182033633112867
Validation loss: 2.4633180356830433

Epoch: 175| Step: 0
Training loss: 2.101337633546473
Validation loss: 2.4639838522819573

Epoch: 5| Step: 1
Training loss: 2.4519030206242634
Validation loss: 2.462453494302487

Epoch: 5| Step: 2
Training loss: 2.775089771090273
Validation loss: 2.4644730334995195

Epoch: 5| Step: 3
Training loss: 2.484395920767358
Validation loss: 2.4720728579207663

Epoch: 5| Step: 4
Training loss: 2.5164970639744335
Validation loss: 2.4825497806151176

Epoch: 5| Step: 5
Training loss: 2.2928572827463487
Validation loss: 2.4938598769543616

Epoch: 5| Step: 6
Training loss: 2.602161418719497
Validation loss: 2.4808036678216157

Epoch: 5| Step: 7
Training loss: 2.655770830804027
Validation loss: 2.484159608216886

Epoch: 5| Step: 8
Training loss: 2.529530918678122
Validation loss: 2.4731663463517854

Epoch: 5| Step: 9
Training loss: 2.292206047622748
Validation loss: 2.4668259668031682

Epoch: 5| Step: 10
Training loss: 2.473419601944384
Validation loss: 2.4632969157370783

Epoch: 5| Step: 11
Training loss: 2.08685465448315
Validation loss: 2.4642974360932914

Epoch: 176| Step: 0
Training loss: 2.8620624524332827
Validation loss: 2.4642661335267904

Epoch: 5| Step: 1
Training loss: 2.088303499285234
Validation loss: 2.4653539436884135

Epoch: 5| Step: 2
Training loss: 2.7111522578502636
Validation loss: 2.4704248927569163

Epoch: 5| Step: 3
Training loss: 2.527631645962461
Validation loss: 2.4725849127259214

Epoch: 5| Step: 4
Training loss: 2.254247259460929
Validation loss: 2.4732556091248075

Epoch: 5| Step: 5
Training loss: 2.5381909561887035
Validation loss: 2.4770298024567574

Epoch: 5| Step: 6
Training loss: 2.334918664336594
Validation loss: 2.48120804630303

Epoch: 5| Step: 7
Training loss: 2.7410233246215516
Validation loss: 2.469106509626735

Epoch: 5| Step: 8
Training loss: 1.8540489788067114
Validation loss: 2.475584292238831

Epoch: 5| Step: 9
Training loss: 2.4142129104323407
Validation loss: 2.4880994513754766

Epoch: 5| Step: 10
Training loss: 2.670912362852181
Validation loss: 2.4820801194290616

Epoch: 5| Step: 11
Training loss: 2.536753476078189
Validation loss: 2.4732017718836796

Epoch: 177| Step: 0
Training loss: 1.5643132941420699
Validation loss: 2.479796647456195

Epoch: 5| Step: 1
Training loss: 2.0995087639411563
Validation loss: 2.482762939329779

Epoch: 5| Step: 2
Training loss: 2.5543515045675917
Validation loss: 2.4700520940581896

Epoch: 5| Step: 3
Training loss: 2.152126848261575
Validation loss: 2.4859578949998586

Epoch: 5| Step: 4
Training loss: 2.6759171277372964
Validation loss: 2.477388543035089

Epoch: 5| Step: 5
Training loss: 2.7182550966412737
Validation loss: 2.488173545849953

Epoch: 5| Step: 6
Training loss: 2.4662881479150287
Validation loss: 2.481720435854003

Epoch: 5| Step: 7
Training loss: 3.156622836309858
Validation loss: 2.4745568056853022

Epoch: 5| Step: 8
Training loss: 2.113671116995336
Validation loss: 2.4665206992180857

Epoch: 5| Step: 9
Training loss: 1.9536694797707579
Validation loss: 2.4664148239713324

Epoch: 5| Step: 10
Training loss: 2.731016614357058
Validation loss: 2.4649600864529413

Epoch: 5| Step: 11
Training loss: 3.596019525816526
Validation loss: 2.467872689086242

Epoch: 178| Step: 0
Training loss: 2.349873084841405
Validation loss: 2.4610597206727336

Epoch: 5| Step: 1
Training loss: 2.492967441693581
Validation loss: 2.454283321362822

Epoch: 5| Step: 2
Training loss: 2.2885557271195283
Validation loss: 2.453560334958123

Epoch: 5| Step: 3
Training loss: 2.8444085668579406
Validation loss: 2.4635752170904635

Epoch: 5| Step: 4
Training loss: 2.530401393727664
Validation loss: 2.457406957837058

Epoch: 5| Step: 5
Training loss: 2.567833072709466
Validation loss: 2.4607761794404244

Epoch: 5| Step: 6
Training loss: 2.556625144684322
Validation loss: 2.4556116350405257

Epoch: 5| Step: 7
Training loss: 2.646766427976121
Validation loss: 2.4567137180978733

Epoch: 5| Step: 8
Training loss: 2.3881436104587186
Validation loss: 2.457174293951229

Epoch: 5| Step: 9
Training loss: 2.1034753878826296
Validation loss: 2.4478970966503755

Epoch: 5| Step: 10
Training loss: 2.707417514210256
Validation loss: 2.4500208691596965

Epoch: 5| Step: 11
Training loss: 2.816334547593035
Validation loss: 2.4490627744128632

Epoch: 179| Step: 0
Training loss: 2.3992599419175864
Validation loss: 2.449154996473145

Epoch: 5| Step: 1
Training loss: 2.44965822210382
Validation loss: 2.4480811868668084

Epoch: 5| Step: 2
Training loss: 2.632491819508477
Validation loss: 2.4597741036251053

Epoch: 5| Step: 3
Training loss: 2.534292958692044
Validation loss: 2.466955623315979

Epoch: 5| Step: 4
Training loss: 1.9476360248077114
Validation loss: 2.480939432977802

Epoch: 5| Step: 5
Training loss: 2.414319466059099
Validation loss: 2.48759455365358

Epoch: 5| Step: 6
Training loss: 2.422656124032567
Validation loss: 2.5153094541992775

Epoch: 5| Step: 7
Training loss: 2.521390385726472
Validation loss: 2.503350976402632

Epoch: 5| Step: 8
Training loss: 2.6447221019401033
Validation loss: 2.5133822772482484

Epoch: 5| Step: 9
Training loss: 2.9343881560041876
Validation loss: 2.4769774168602363

Epoch: 5| Step: 10
Training loss: 2.446416148769752
Validation loss: 2.4684452480425243

Epoch: 5| Step: 11
Training loss: 2.5196268226180534
Validation loss: 2.459278132572049

Epoch: 180| Step: 0
Training loss: 2.106433993942702
Validation loss: 2.4652475105958827

Epoch: 5| Step: 1
Training loss: 2.453197599660936
Validation loss: 2.468065307731255

Epoch: 5| Step: 2
Training loss: 2.079032298341319
Validation loss: 2.4673544605173965

Epoch: 5| Step: 3
Training loss: 3.076480949254835
Validation loss: 2.466922385314207

Epoch: 5| Step: 4
Training loss: 2.514719355796095
Validation loss: 2.4707590049083694

Epoch: 5| Step: 5
Training loss: 2.630381381445099
Validation loss: 2.4729066212767976

Epoch: 5| Step: 6
Training loss: 1.9582532162882802
Validation loss: 2.473541089393096

Epoch: 5| Step: 7
Training loss: 2.4003454317412127
Validation loss: 2.4696940697337193

Epoch: 5| Step: 8
Training loss: 2.008899201677984
Validation loss: 2.4754306320642345

Epoch: 5| Step: 9
Training loss: 2.474983747024345
Validation loss: 2.470319072240925

Epoch: 5| Step: 10
Training loss: 2.6894599510000976
Validation loss: 2.4639174649892954

Epoch: 5| Step: 11
Training loss: 4.039893531529482
Validation loss: 2.4743442027009426

Epoch: 181| Step: 0
Training loss: 2.2250024516917235
Validation loss: 2.468896748812781

Epoch: 5| Step: 1
Training loss: 2.381841543018209
Validation loss: 2.4814608774969336

Epoch: 5| Step: 2
Training loss: 2.5364090890562427
Validation loss: 2.475087686391811

Epoch: 5| Step: 3
Training loss: 2.651665714662558
Validation loss: 2.4689602541018116

Epoch: 5| Step: 4
Training loss: 2.2048699793466224
Validation loss: 2.4808705322386335

Epoch: 5| Step: 5
Training loss: 2.596557568407581
Validation loss: 2.4803856182435347

Epoch: 5| Step: 6
Training loss: 2.14957334144056
Validation loss: 2.4870289356517863

Epoch: 5| Step: 7
Training loss: 2.6256853752940317
Validation loss: 2.4823348787692323

Epoch: 5| Step: 8
Training loss: 2.2938691277193124
Validation loss: 2.4727481304692964

Epoch: 5| Step: 9
Training loss: 2.3974311034294433
Validation loss: 2.485602689295526

Epoch: 5| Step: 10
Training loss: 2.634739744880772
Validation loss: 2.480204458499356

Epoch: 5| Step: 11
Training loss: 3.0154785753190168
Validation loss: 2.4771082143493808

Epoch: 182| Step: 0
Training loss: 2.788028471934055
Validation loss: 2.471359680351857

Epoch: 5| Step: 1
Training loss: 2.2829912412043485
Validation loss: 2.468454067584959

Epoch: 5| Step: 2
Training loss: 2.60414925124385
Validation loss: 2.479255223228628

Epoch: 5| Step: 3
Training loss: 2.129057320650498
Validation loss: 2.470060439322734

Epoch: 5| Step: 4
Training loss: 2.765547756689667
Validation loss: 2.4707133095673344

Epoch: 5| Step: 5
Training loss: 2.5352230210173596
Validation loss: 2.4868459629250053

Epoch: 5| Step: 6
Training loss: 2.6141012185484804
Validation loss: 2.4861236751909037

Epoch: 5| Step: 7
Training loss: 2.4802390164898336
Validation loss: 2.501737555042291

Epoch: 5| Step: 8
Training loss: 2.057262591063987
Validation loss: 2.498848697684409

Epoch: 5| Step: 9
Training loss: 2.1540185189969665
Validation loss: 2.497078444142305

Epoch: 5| Step: 10
Training loss: 2.7359802765609382
Validation loss: 2.497487418862527

Epoch: 5| Step: 11
Training loss: 1.984397287318708
Validation loss: 2.476061159527131

Epoch: 183| Step: 0
Training loss: 2.477714102354053
Validation loss: 2.4774415214121825

Epoch: 5| Step: 1
Training loss: 1.8754217309324748
Validation loss: 2.4727723795943466

Epoch: 5| Step: 2
Training loss: 2.8551344147421704
Validation loss: 2.480273904431638

Epoch: 5| Step: 3
Training loss: 2.5532175670637987
Validation loss: 2.472623657124246

Epoch: 5| Step: 4
Training loss: 1.8274529680913645
Validation loss: 2.4800529151444746

Epoch: 5| Step: 5
Training loss: 1.9344900192551469
Validation loss: 2.4726188982271213

Epoch: 5| Step: 6
Training loss: 2.860772963687973
Validation loss: 2.4783268629439426

Epoch: 5| Step: 7
Training loss: 2.26197932032029
Validation loss: 2.4771924265673007

Epoch: 5| Step: 8
Training loss: 2.832819125319748
Validation loss: 2.4710413041701624

Epoch: 5| Step: 9
Training loss: 2.735251847410437
Validation loss: 2.468442322273597

Epoch: 5| Step: 10
Training loss: 2.407952833201645
Validation loss: 2.474895680521727

Epoch: 5| Step: 11
Training loss: 1.8695842730618484
Validation loss: 2.4782843495656564

Epoch: 184| Step: 0
Training loss: 2.279022174092943
Validation loss: 2.483296418128977

Epoch: 5| Step: 1
Training loss: 1.3393138137776048
Validation loss: 2.4811141128228145

Epoch: 5| Step: 2
Training loss: 2.8653082652793445
Validation loss: 2.478311701151937

Epoch: 5| Step: 3
Training loss: 2.4900743859451837
Validation loss: 2.470754799283608

Epoch: 5| Step: 4
Training loss: 2.019137257377427
Validation loss: 2.485360264091523

Epoch: 5| Step: 5
Training loss: 2.728728387793363
Validation loss: 2.482435268923214

Epoch: 5| Step: 6
Training loss: 2.3685789142111053
Validation loss: 2.4826264495952937

Epoch: 5| Step: 7
Training loss: 2.389954915599077
Validation loss: 2.475424307438063

Epoch: 5| Step: 8
Training loss: 2.8165227307743765
Validation loss: 2.474268897122243

Epoch: 5| Step: 9
Training loss: 2.1649445757037618
Validation loss: 2.471088746224892

Epoch: 5| Step: 10
Training loss: 2.761974015369871
Validation loss: 2.4719411610439126

Epoch: 5| Step: 11
Training loss: 3.013648141210011
Validation loss: 2.473052549016743

Epoch: 185| Step: 0
Training loss: 2.4983543701847015
Validation loss: 2.4861848025230646

Epoch: 5| Step: 1
Training loss: 2.994340963311531
Validation loss: 2.4957430557859506

Epoch: 5| Step: 2
Training loss: 2.607960757457628
Validation loss: 2.503385314073676

Epoch: 5| Step: 3
Training loss: 2.405204545837654
Validation loss: 2.51213523927753

Epoch: 5| Step: 4
Training loss: 2.5701381079231576
Validation loss: 2.4992655827708488

Epoch: 5| Step: 5
Training loss: 2.4216025906841634
Validation loss: 2.5010894527475043

Epoch: 5| Step: 6
Training loss: 1.8109829571920975
Validation loss: 2.504168099505056

Epoch: 5| Step: 7
Training loss: 2.7089254954566955
Validation loss: 2.5011545892718177

Epoch: 5| Step: 8
Training loss: 1.7190999455093199
Validation loss: 2.472967468731867

Epoch: 5| Step: 9
Training loss: 1.9691828297347094
Validation loss: 2.476876372334474

Epoch: 5| Step: 10
Training loss: 2.695122311281273
Validation loss: 2.477634161964791

Epoch: 5| Step: 11
Training loss: 2.9704995872498556
Validation loss: 2.4696120133388435

Epoch: 186| Step: 0
Training loss: 1.9503249582321525
Validation loss: 2.469472373028039

Epoch: 5| Step: 1
Training loss: 2.6657756767306364
Validation loss: 2.4768057101069183

Epoch: 5| Step: 2
Training loss: 2.4674687018143904
Validation loss: 2.479751294923307

Epoch: 5| Step: 3
Training loss: 2.6041545613325416
Validation loss: 2.478540162390134

Epoch: 5| Step: 4
Training loss: 2.852614786043449
Validation loss: 2.482206946071932

Epoch: 5| Step: 5
Training loss: 1.571753452826934
Validation loss: 2.4799159437721787

Epoch: 5| Step: 6
Training loss: 2.373578097691299
Validation loss: 2.4783631727038036

Epoch: 5| Step: 7
Training loss: 1.9666273390614752
Validation loss: 2.479273001743869

Epoch: 5| Step: 8
Training loss: 2.7377499923476147
Validation loss: 2.471880676144056

Epoch: 5| Step: 9
Training loss: 2.9570759173991807
Validation loss: 2.476687491358474

Epoch: 5| Step: 10
Training loss: 2.3734951270957283
Validation loss: 2.4762417357908784

Epoch: 5| Step: 11
Training loss: 2.9018130324199163
Validation loss: 2.4887831664290343

Epoch: 187| Step: 0
Training loss: 2.498507912736829
Validation loss: 2.4938983924075444

Epoch: 5| Step: 1
Training loss: 2.763997089136029
Validation loss: 2.486883887950721

Epoch: 5| Step: 2
Training loss: 3.044355240634174
Validation loss: 2.4922044647819273

Epoch: 5| Step: 3
Training loss: 2.1814782228189444
Validation loss: 2.5166750941440705

Epoch: 5| Step: 4
Training loss: 2.575397320065619
Validation loss: 2.5222616772943

Epoch: 5| Step: 5
Training loss: 2.3776179491181915
Validation loss: 2.5356736637241424

Epoch: 5| Step: 6
Training loss: 2.496815465186325
Validation loss: 2.527679983076628

Epoch: 5| Step: 7
Training loss: 2.5922379280138137
Validation loss: 2.5062029536866315

Epoch: 5| Step: 8
Training loss: 2.1593889249802576
Validation loss: 2.49284561380715

Epoch: 5| Step: 9
Training loss: 2.552874093584584
Validation loss: 2.4813243882040914

Epoch: 5| Step: 10
Training loss: 2.267444169641
Validation loss: 2.477927871486547

Epoch: 5| Step: 11
Training loss: 1.8732766178591518
Validation loss: 2.4826179384949647

Epoch: 188| Step: 0
Training loss: 2.7323019834423765
Validation loss: 2.481706265506566

Epoch: 5| Step: 1
Training loss: 3.191995031797515
Validation loss: 2.4828059281809765

Epoch: 5| Step: 2
Training loss: 2.0324325640425003
Validation loss: 2.480177434199816

Epoch: 5| Step: 3
Training loss: 2.1915559496551187
Validation loss: 2.4740894195896113

Epoch: 5| Step: 4
Training loss: 2.9261798663495537
Validation loss: 2.478001807070287

Epoch: 5| Step: 5
Training loss: 1.9823202473565753
Validation loss: 2.4841942351533848

Epoch: 5| Step: 6
Training loss: 2.9467533543581315
Validation loss: 2.4825738699756785

Epoch: 5| Step: 7
Training loss: 2.3711404057394976
Validation loss: 2.4760950411472264

Epoch: 5| Step: 8
Training loss: 2.2070989817801006
Validation loss: 2.477279266541541

Epoch: 5| Step: 9
Training loss: 2.3650152229319175
Validation loss: 2.480374125680768

Epoch: 5| Step: 10
Training loss: 2.039277865557232
Validation loss: 2.478077722798388

Epoch: 5| Step: 11
Training loss: 2.3763669748024787
Validation loss: 2.4784455706568744

Epoch: 189| Step: 0
Training loss: 2.176384833561405
Validation loss: 2.4732730210753164

Epoch: 5| Step: 1
Training loss: 2.3799393138040594
Validation loss: 2.4763992007034856

Epoch: 5| Step: 2
Training loss: 2.479195335500243
Validation loss: 2.471106587514417

Epoch: 5| Step: 3
Training loss: 2.0787272333583275
Validation loss: 2.471749091608922

Epoch: 5| Step: 4
Training loss: 2.657301571203356
Validation loss: 2.4754206916388104

Epoch: 5| Step: 5
Training loss: 2.313587036329174
Validation loss: 2.467047204700869

Epoch: 5| Step: 6
Training loss: 2.1055089490234242
Validation loss: 2.4736748235111645

Epoch: 5| Step: 7
Training loss: 3.1112452111029176
Validation loss: 2.4788528345257834

Epoch: 5| Step: 8
Training loss: 2.3590823364636604
Validation loss: 2.470502235578606

Epoch: 5| Step: 9
Training loss: 2.3558741990781944
Validation loss: 2.4858164654128654

Epoch: 5| Step: 10
Training loss: 2.425005753500494
Validation loss: 2.4861405275127093

Epoch: 5| Step: 11
Training loss: 3.284642091991965
Validation loss: 2.483833449897165

Epoch: 190| Step: 0
Training loss: 2.9639905825322463
Validation loss: 2.485753918288357

Epoch: 5| Step: 1
Training loss: 2.1795659732096864
Validation loss: 2.4848221110629263

Epoch: 5| Step: 2
Training loss: 2.7920783484267884
Validation loss: 2.4917567926286655

Epoch: 5| Step: 3
Training loss: 2.220811020940044
Validation loss: 2.4778799650216317

Epoch: 5| Step: 4
Training loss: 2.379703081346724
Validation loss: 2.4901495346875913

Epoch: 5| Step: 5
Training loss: 1.9540030985078483
Validation loss: 2.483927968430522

Epoch: 5| Step: 6
Training loss: 2.3450799855985682
Validation loss: 2.496776648578882

Epoch: 5| Step: 7
Training loss: 2.5996561483278082
Validation loss: 2.484356850131932

Epoch: 5| Step: 8
Training loss: 2.2752343905925407
Validation loss: 2.484341619175351

Epoch: 5| Step: 9
Training loss: 2.4496160790277623
Validation loss: 2.4825508250257964

Epoch: 5| Step: 10
Training loss: 2.3059048815693717
Validation loss: 2.474730077467896

Epoch: 5| Step: 11
Training loss: 2.562924047600141
Validation loss: 2.472661476872983

Epoch: 191| Step: 0
Training loss: 2.4695221864267896
Validation loss: 2.4776431352396124

Epoch: 5| Step: 1
Training loss: 2.617754154636648
Validation loss: 2.4820288770498413

Epoch: 5| Step: 2
Training loss: 2.9634078296727604
Validation loss: 2.485642875381382

Epoch: 5| Step: 3
Training loss: 2.3148089042870685
Validation loss: 2.4724912101221648

Epoch: 5| Step: 4
Training loss: 2.7130874771092923
Validation loss: 2.4857338002473206

Epoch: 5| Step: 5
Training loss: 2.276662315636308
Validation loss: 2.4834328150398006

Epoch: 5| Step: 6
Training loss: 2.265661620797787
Validation loss: 2.4779491373383595

Epoch: 5| Step: 7
Training loss: 1.7170485658125716
Validation loss: 2.4856771179700115

Epoch: 5| Step: 8
Training loss: 2.7437716958963003
Validation loss: 2.4896858558666914

Epoch: 5| Step: 9
Training loss: 2.198319083402123
Validation loss: 2.4874901824067335

Epoch: 5| Step: 10
Training loss: 2.257711758065525
Validation loss: 2.493503235197751

Epoch: 5| Step: 11
Training loss: 3.064419981447202
Validation loss: 2.4892147834204588

Epoch: 192| Step: 0
Training loss: 2.447145305333596
Validation loss: 2.4927187545713685

Epoch: 5| Step: 1
Training loss: 2.976861252898151
Validation loss: 2.4976571370332947

Epoch: 5| Step: 2
Training loss: 2.148136742087784
Validation loss: 2.497002644592349

Epoch: 5| Step: 3
Training loss: 2.302879633055015
Validation loss: 2.481571603138718

Epoch: 5| Step: 4
Training loss: 2.6752973801210436
Validation loss: 2.4908004416558023

Epoch: 5| Step: 5
Training loss: 2.3332631804501576
Validation loss: 2.4893089140531357

Epoch: 5| Step: 6
Training loss: 2.362678589706102
Validation loss: 2.4813457050170937

Epoch: 5| Step: 7
Training loss: 2.049202331174693
Validation loss: 2.484373124639735

Epoch: 5| Step: 8
Training loss: 2.8537637653595302
Validation loss: 2.490733612481161

Epoch: 5| Step: 9
Training loss: 2.053452153029501
Validation loss: 2.482302310924517

Epoch: 5| Step: 10
Training loss: 2.4952514373435766
Validation loss: 2.472018516704966

Epoch: 5| Step: 11
Training loss: 1.2808756863043205
Validation loss: 2.4860278615267473

Epoch: 193| Step: 0
Training loss: 2.6235236603048198
Validation loss: 2.4849075230488933

Epoch: 5| Step: 1
Training loss: 1.957351506083023
Validation loss: 2.4809676081719685

Epoch: 5| Step: 2
Training loss: 2.9320781261865316
Validation loss: 2.485330230081736

Epoch: 5| Step: 3
Training loss: 2.393338925595068
Validation loss: 2.486288235672266

Epoch: 5| Step: 4
Training loss: 2.884019056450347
Validation loss: 2.4805531725196266

Epoch: 5| Step: 5
Training loss: 2.5870482488083977
Validation loss: 2.4912736307348258

Epoch: 5| Step: 6
Training loss: 2.558237578083867
Validation loss: 2.492652993093374

Epoch: 5| Step: 7
Training loss: 1.966953850915074
Validation loss: 2.4809295927063384

Epoch: 5| Step: 8
Training loss: 1.6707227782903402
Validation loss: 2.4910881503700084

Epoch: 5| Step: 9
Training loss: 2.254127319707054
Validation loss: 2.494063457588726

Epoch: 5| Step: 10
Training loss: 2.33007607855631
Validation loss: 2.4874620351657817

Epoch: 5| Step: 11
Training loss: 3.168635475752653
Validation loss: 2.4849195903110703

Epoch: 194| Step: 0
Training loss: 2.4119836442433966
Validation loss: 2.474417113212102

Epoch: 5| Step: 1
Training loss: 2.3083148923428785
Validation loss: 2.4735443866485274

Epoch: 5| Step: 2
Training loss: 2.7806531287099783
Validation loss: 2.471193251414082

Epoch: 5| Step: 3
Training loss: 2.57537787914666
Validation loss: 2.47459613944039

Epoch: 5| Step: 4
Training loss: 3.074271176192905
Validation loss: 2.4677278962063705

Epoch: 5| Step: 5
Training loss: 2.218208569295722
Validation loss: 2.4744116170456927

Epoch: 5| Step: 6
Training loss: 2.073538745975293
Validation loss: 2.4722374093795323

Epoch: 5| Step: 7
Training loss: 2.151901836687722
Validation loss: 2.480250103142296

Epoch: 5| Step: 8
Training loss: 2.2683929372557454
Validation loss: 2.4763725881835814

Epoch: 5| Step: 9
Training loss: 2.261578122314708
Validation loss: 2.486534511633491

Epoch: 5| Step: 10
Training loss: 2.393796823705975
Validation loss: 2.4873799758338144

Epoch: 5| Step: 11
Training loss: 2.876168884168026
Validation loss: 2.489142446038261

Epoch: 195| Step: 0
Training loss: 2.3542108672277102
Validation loss: 2.4925015768813306

Epoch: 5| Step: 1
Training loss: 2.40834796157495
Validation loss: 2.502019745820463

Epoch: 5| Step: 2
Training loss: 2.75683714825735
Validation loss: 2.519347747507708

Epoch: 5| Step: 3
Training loss: 2.3242808101286463
Validation loss: 2.5208025620424084

Epoch: 5| Step: 4
Training loss: 2.2731328281606578
Validation loss: 2.522816336506119

Epoch: 5| Step: 5
Training loss: 2.6782758458853397
Validation loss: 2.5178170338656494

Epoch: 5| Step: 6
Training loss: 2.649236957889084
Validation loss: 2.528220644140916

Epoch: 5| Step: 7
Training loss: 2.359249086367499
Validation loss: 2.5193214822036003

Epoch: 5| Step: 8
Training loss: 2.5591626648626793
Validation loss: 2.5034334884012694

Epoch: 5| Step: 9
Training loss: 2.190928034698712
Validation loss: 2.496035862242964

Epoch: 5| Step: 10
Training loss: 2.6744248565141757
Validation loss: 2.486762501064781

Epoch: 5| Step: 11
Training loss: 2.8357036063263257
Validation loss: 2.485850134144948

Epoch: 196| Step: 0
Training loss: 2.6595759494046893
Validation loss: 2.477909874848771

Epoch: 5| Step: 1
Training loss: 2.4029167174322805
Validation loss: 2.4723571708961196

Epoch: 5| Step: 2
Training loss: 2.279251477362273
Validation loss: 2.4811367346969955

Epoch: 5| Step: 3
Training loss: 2.8412597148576455
Validation loss: 2.481504485390472

Epoch: 5| Step: 4
Training loss: 2.3408822380471825
Validation loss: 2.4785408798305877

Epoch: 5| Step: 5
Training loss: 2.6807042631320805
Validation loss: 2.474248826221831

Epoch: 5| Step: 6
Training loss: 2.207169736045096
Validation loss: 2.469081973036213

Epoch: 5| Step: 7
Training loss: 2.538412815017644
Validation loss: 2.466696255147735

Epoch: 5| Step: 8
Training loss: 2.4848716767181074
Validation loss: 2.4636018367997603

Epoch: 5| Step: 9
Training loss: 2.2303057342123083
Validation loss: 2.4723612010183778

Epoch: 5| Step: 10
Training loss: 2.0492100100634483
Validation loss: 2.4844976510855497

Epoch: 5| Step: 11
Training loss: 3.472110804147716
Validation loss: 2.47403085836549

Epoch: 197| Step: 0
Training loss: 1.710721564056996
Validation loss: 2.48786428322495

Epoch: 5| Step: 1
Training loss: 2.159661068992624
Validation loss: 2.4854124530160706

Epoch: 5| Step: 2
Training loss: 2.3353022601519386
Validation loss: 2.4907782425716802

Epoch: 5| Step: 3
Training loss: 3.0238737043013932
Validation loss: 2.5027802187429877

Epoch: 5| Step: 4
Training loss: 2.5932025561500014
Validation loss: 2.49738938400714

Epoch: 5| Step: 5
Training loss: 2.2174655258784686
Validation loss: 2.500358909433998

Epoch: 5| Step: 6
Training loss: 2.288674383492502
Validation loss: 2.4938395653800427

Epoch: 5| Step: 7
Training loss: 2.214096239219212
Validation loss: 2.4870962478213774

Epoch: 5| Step: 8
Training loss: 2.750440822295485
Validation loss: 2.474369867461951

Epoch: 5| Step: 9
Training loss: 2.2644665091058016
Validation loss: 2.4551262356402317

Epoch: 5| Step: 10
Training loss: 2.8367185751815907
Validation loss: 2.4748401047533064

Epoch: 5| Step: 11
Training loss: 2.8290698754481935
Validation loss: 2.4657331616199545

Epoch: 198| Step: 0
Training loss: 2.43523428837476
Validation loss: 2.459286395233523

Epoch: 5| Step: 1
Training loss: 2.4862568763419177
Validation loss: 2.4640850384604067

Epoch: 5| Step: 2
Training loss: 2.5338397494484552
Validation loss: 2.463929695528923

Epoch: 5| Step: 3
Training loss: 2.4225149970284265
Validation loss: 2.466852662177278

Epoch: 5| Step: 4
Training loss: 2.410958278761773
Validation loss: 2.466831773846832

Epoch: 5| Step: 5
Training loss: 2.6656734484510394
Validation loss: 2.4663831334142934

Epoch: 5| Step: 6
Training loss: 2.10908189785835
Validation loss: 2.4635732271029127

Epoch: 5| Step: 7
Training loss: 2.6611660512545723
Validation loss: 2.4686337294742517

Epoch: 5| Step: 8
Training loss: 2.2143638131216816
Validation loss: 2.4692550898990593

Epoch: 5| Step: 9
Training loss: 2.2714295843966985
Validation loss: 2.467219196008876

Epoch: 5| Step: 10
Training loss: 2.748087998592886
Validation loss: 2.4721380798674835

Epoch: 5| Step: 11
Training loss: 2.2404129502578547
Validation loss: 2.4805445281541045

Epoch: 199| Step: 0
Training loss: 2.536775092699619
Validation loss: 2.4729903619632156

Epoch: 5| Step: 1
Training loss: 2.6690847539783515
Validation loss: 2.4702299325822357

Epoch: 5| Step: 2
Training loss: 2.061548418104214
Validation loss: 2.481471538342561

Epoch: 5| Step: 3
Training loss: 2.6530696903569777
Validation loss: 2.4765229848763815

Epoch: 5| Step: 4
Training loss: 2.561651042707752
Validation loss: 2.467673034598003

Epoch: 5| Step: 5
Training loss: 2.0468204869589712
Validation loss: 2.48042668184266

Epoch: 5| Step: 6
Training loss: 2.3115378775425603
Validation loss: 2.4810819453637225

Epoch: 5| Step: 7
Training loss: 2.209347318181815
Validation loss: 2.490019474106589

Epoch: 5| Step: 8
Training loss: 2.4442310806077514
Validation loss: 2.4908537968198794

Epoch: 5| Step: 9
Training loss: 2.3495067849914686
Validation loss: 2.493180012555421

Epoch: 5| Step: 10
Training loss: 2.6409260053455585
Validation loss: 2.48757961208095

Epoch: 5| Step: 11
Training loss: 2.1462573277609964
Validation loss: 2.476574272986186

Epoch: 200| Step: 0
Training loss: 2.5730688279186755
Validation loss: 2.4837352760760356

Epoch: 5| Step: 1
Training loss: 2.5818434284822107
Validation loss: 2.4839340034485016

Epoch: 5| Step: 2
Training loss: 2.6104154054517408
Validation loss: 2.4856700920431627

Epoch: 5| Step: 3
Training loss: 1.999170965985404
Validation loss: 2.48723595510133

Epoch: 5| Step: 4
Training loss: 2.3308464375976428
Validation loss: 2.4843653192871344

Epoch: 5| Step: 5
Training loss: 2.167628466045111
Validation loss: 2.475928240403301

Epoch: 5| Step: 6
Training loss: 2.0808007932580055
Validation loss: 2.48244445294293

Epoch: 5| Step: 7
Training loss: 2.4872701797517935
Validation loss: 2.482289380515248

Epoch: 5| Step: 8
Training loss: 2.9945549824384057
Validation loss: 2.4892283483162996

Epoch: 5| Step: 9
Training loss: 2.7914562051116176
Validation loss: 2.486764728162233

Epoch: 5| Step: 10
Training loss: 1.7343450320292417
Validation loss: 2.5002885651941704

Epoch: 5| Step: 11
Training loss: 1.107715224715205
Validation loss: 2.498188047617956

Epoch: 201| Step: 0
Training loss: 2.7337256832288457
Validation loss: 2.496071717389394

Epoch: 5| Step: 1
Training loss: 2.136979388811021
Validation loss: 2.501450427831228

Epoch: 5| Step: 2
Training loss: 2.4958313518976953
Validation loss: 2.486060104847323

Epoch: 5| Step: 3
Training loss: 2.536704415062621
Validation loss: 2.5086065720704003

Epoch: 5| Step: 4
Training loss: 2.5413986023003012
Validation loss: 2.502294887812411

Epoch: 5| Step: 5
Training loss: 1.9895217113705115
Validation loss: 2.4936199994090704

Epoch: 5| Step: 6
Training loss: 2.2909128047313008
Validation loss: 2.507278476633377

Epoch: 5| Step: 7
Training loss: 1.7244637277692227
Validation loss: 2.493902001333584

Epoch: 5| Step: 8
Training loss: 2.2878490786161265
Validation loss: 2.4886459969555417

Epoch: 5| Step: 9
Training loss: 2.401992499251649
Validation loss: 2.4899191663125144

Epoch: 5| Step: 10
Training loss: 2.766133751923922
Validation loss: 2.494051522197047

Epoch: 5| Step: 11
Training loss: 3.558192543502353
Validation loss: 2.4738622941231894

Epoch: 202| Step: 0
Training loss: 2.3803505107283174
Validation loss: 2.481996385239216

Epoch: 5| Step: 1
Training loss: 2.707258382849256
Validation loss: 2.468730988811577

Epoch: 5| Step: 2
Training loss: 1.9402937896706196
Validation loss: 2.457508499703854

Epoch: 5| Step: 3
Training loss: 2.451377391938316
Validation loss: 2.4645301591151694

Epoch: 5| Step: 4
Training loss: 2.5891942839617306
Validation loss: 2.4707213068156144

Epoch: 5| Step: 5
Training loss: 2.08721359024156
Validation loss: 2.474463450749188

Epoch: 5| Step: 6
Training loss: 2.6044070527072773
Validation loss: 2.465741074299256

Epoch: 5| Step: 7
Training loss: 2.3203793911009982
Validation loss: 2.4634775969310763

Epoch: 5| Step: 8
Training loss: 2.185537711525696
Validation loss: 2.4698341620715203

Epoch: 5| Step: 9
Training loss: 2.950363401885611
Validation loss: 2.4852498131729464

Epoch: 5| Step: 10
Training loss: 2.333385489652911
Validation loss: 2.4967055548511348

Epoch: 5| Step: 11
Training loss: 1.388434753346565
Validation loss: 2.507203496585338

Epoch: 203| Step: 0
Training loss: 2.335759899315633
Validation loss: 2.497698698219066

Epoch: 5| Step: 1
Training loss: 2.7909393406901315
Validation loss: 2.5176753066557067

Epoch: 5| Step: 2
Training loss: 2.2982411376556517
Validation loss: 2.5052940581333973

Epoch: 5| Step: 3
Training loss: 2.2557777819389164
Validation loss: 2.518558462257707

Epoch: 5| Step: 4
Training loss: 2.1768355768551078
Validation loss: 2.5079989458061105

Epoch: 5| Step: 5
Training loss: 3.1451849027051795
Validation loss: 2.5081988321301347

Epoch: 5| Step: 6
Training loss: 2.3206661481468602
Validation loss: 2.493858287566691

Epoch: 5| Step: 7
Training loss: 2.163413160386374
Validation loss: 2.481437025540509

Epoch: 5| Step: 8
Training loss: 2.8785658574312394
Validation loss: 2.4857297438486423

Epoch: 5| Step: 9
Training loss: 2.203424203454122
Validation loss: 2.4895485166618365

Epoch: 5| Step: 10
Training loss: 2.017757500118552
Validation loss: 2.493442829115389

Epoch: 5| Step: 11
Training loss: 2.1413205541242855
Validation loss: 2.4893781000134467

Epoch: 204| Step: 0
Training loss: 2.2567567039720635
Validation loss: 2.4796216544543324

Epoch: 5| Step: 1
Training loss: 2.2246283445813804
Validation loss: 2.482082672915249

Epoch: 5| Step: 2
Training loss: 2.9116203977259985
Validation loss: 2.4799493360984357

Epoch: 5| Step: 3
Training loss: 2.70943776622258
Validation loss: 2.4810322879818254

Epoch: 5| Step: 4
Training loss: 2.3155648824736197
Validation loss: 2.4777794183690958

Epoch: 5| Step: 5
Training loss: 2.564176429760529
Validation loss: 2.4818108920012945

Epoch: 5| Step: 6
Training loss: 2.6542878027979158
Validation loss: 2.4816827921880398

Epoch: 5| Step: 7
Training loss: 2.2192772252324184
Validation loss: 2.4857801466301224

Epoch: 5| Step: 8
Training loss: 2.3288309959786284
Validation loss: 2.48973689676399

Epoch: 5| Step: 9
Training loss: 2.360691031940629
Validation loss: 2.4871082705129868

Epoch: 5| Step: 10
Training loss: 2.206240892256398
Validation loss: 2.4865998596348255

Epoch: 5| Step: 11
Training loss: 2.158525786294636
Validation loss: 2.484648919349548

Epoch: 205| Step: 0
Training loss: 2.5808892429771917
Validation loss: 2.4827252074369204

Epoch: 5| Step: 1
Training loss: 2.095010634147221
Validation loss: 2.4941152851646686

Epoch: 5| Step: 2
Training loss: 2.563167299053222
Validation loss: 2.476555676857006

Epoch: 5| Step: 3
Training loss: 2.781610444104322
Validation loss: 2.476502378678638

Epoch: 5| Step: 4
Training loss: 2.7837924266471816
Validation loss: 2.4805030119524645

Epoch: 5| Step: 5
Training loss: 2.324900602451489
Validation loss: 2.4790747182020754

Epoch: 5| Step: 6
Training loss: 2.0753192747901883
Validation loss: 2.4869034294592764

Epoch: 5| Step: 7
Training loss: 2.4836964190328303
Validation loss: 2.483976740074752

Epoch: 5| Step: 8
Training loss: 2.3683043007767988
Validation loss: 2.4812453648662434

Epoch: 5| Step: 9
Training loss: 2.336873763135862
Validation loss: 2.4791067874847075

Epoch: 5| Step: 10
Training loss: 2.238156513246852
Validation loss: 2.4869127407822935

Epoch: 5| Step: 11
Training loss: 0.9186901098959485
Validation loss: 2.4875828088622214

Epoch: 206| Step: 0
Training loss: 2.060418899684065
Validation loss: 2.491417828757557

Epoch: 5| Step: 1
Training loss: 2.315119419684151
Validation loss: 2.4962165933626745

Epoch: 5| Step: 2
Training loss: 2.2168650612448353
Validation loss: 2.4838937577201063

Epoch: 5| Step: 3
Training loss: 2.178537263535343
Validation loss: 2.4852870530585625

Epoch: 5| Step: 4
Training loss: 2.6180210892634395
Validation loss: 2.4846991681388824

Epoch: 5| Step: 5
Training loss: 2.396010970012535
Validation loss: 2.483118723283617

Epoch: 5| Step: 6
Training loss: 3.2271823980313807
Validation loss: 2.4875363403170594

Epoch: 5| Step: 7
Training loss: 2.545379761427126
Validation loss: 2.488069298708505

Epoch: 5| Step: 8
Training loss: 2.164688845997917
Validation loss: 2.4894209945826336

Epoch: 5| Step: 9
Training loss: 2.3786009544068496
Validation loss: 2.4916169281740133

Epoch: 5| Step: 10
Training loss: 2.144008440727016
Validation loss: 2.4959099651687087

Epoch: 5| Step: 11
Training loss: 2.577076831789895
Validation loss: 2.4832329314265595

Epoch: 207| Step: 0
Training loss: 2.51487104597207
Validation loss: 2.4884802610460026

Epoch: 5| Step: 1
Training loss: 2.3792852591527116
Validation loss: 2.501201424401056

Epoch: 5| Step: 2
Training loss: 2.3979006486407966
Validation loss: 2.48361253134318

Epoch: 5| Step: 3
Training loss: 2.4472391259539004
Validation loss: 2.4853387079112563

Epoch: 5| Step: 4
Training loss: 2.24905778442075
Validation loss: 2.505779674409252

Epoch: 5| Step: 5
Training loss: 2.302762744007291
Validation loss: 2.4942387517009075

Epoch: 5| Step: 6
Training loss: 2.9745250547183932
Validation loss: 2.512098031603413

Epoch: 5| Step: 7
Training loss: 2.1916769203942152
Validation loss: 2.504993863088739

Epoch: 5| Step: 8
Training loss: 2.6586135222321623
Validation loss: 2.498203649465446

Epoch: 5| Step: 9
Training loss: 2.2999774973224625
Validation loss: 2.4900268627796156

Epoch: 5| Step: 10
Training loss: 2.280133326798254
Validation loss: 2.4817197833793303

Epoch: 5| Step: 11
Training loss: 1.0116203584289971
Validation loss: 2.4901176175938597

Epoch: 208| Step: 0
Training loss: 2.182136827558206
Validation loss: 2.480703570046773

Epoch: 5| Step: 1
Training loss: 2.472248736845364
Validation loss: 2.4801042584325996

Epoch: 5| Step: 2
Training loss: 2.3354688703797657
Validation loss: 2.4757783893967122

Epoch: 5| Step: 3
Training loss: 2.462231783129143
Validation loss: 2.479107146122971

Epoch: 5| Step: 4
Training loss: 2.8565386269480224
Validation loss: 2.4852403856953686

Epoch: 5| Step: 5
Training loss: 2.9489375706710597
Validation loss: 2.4803693215775007

Epoch: 5| Step: 6
Training loss: 2.0233175470447535
Validation loss: 2.483205372011893

Epoch: 5| Step: 7
Training loss: 2.3020633564308097
Validation loss: 2.4887781969418143

Epoch: 5| Step: 8
Training loss: 2.9541380421301318
Validation loss: 2.4904626081008687

Epoch: 5| Step: 9
Training loss: 1.6690661641623326
Validation loss: 2.485115112968356

Epoch: 5| Step: 10
Training loss: 2.4703878450334305
Validation loss: 2.4828927038549

Epoch: 5| Step: 11
Training loss: 1.6230377674421064
Validation loss: 2.4864143862048116

Epoch: 209| Step: 0
Training loss: 2.6132861765998965
Validation loss: 2.4881052966065558

Epoch: 5| Step: 1
Training loss: 2.3184670453027856
Validation loss: 2.4823727686657318

Epoch: 5| Step: 2
Training loss: 2.347909110823498
Validation loss: 2.4861974869154966

Epoch: 5| Step: 3
Training loss: 2.764335547244804
Validation loss: 2.4962024456111522

Epoch: 5| Step: 4
Training loss: 2.819514195957966
Validation loss: 2.492056589066527

Epoch: 5| Step: 5
Training loss: 1.7607310840089445
Validation loss: 2.4960915332161497

Epoch: 5| Step: 6
Training loss: 2.30488549368012
Validation loss: 2.50397450497377

Epoch: 5| Step: 7
Training loss: 2.031815552840705
Validation loss: 2.5082707288497605

Epoch: 5| Step: 8
Training loss: 2.546519529659119
Validation loss: 2.5029235752451298

Epoch: 5| Step: 9
Training loss: 2.148022531835206
Validation loss: 2.503886908636511

Epoch: 5| Step: 10
Training loss: 2.5734771447524043
Validation loss: 2.5006802904874386

Epoch: 5| Step: 11
Training loss: 2.2598041343210222
Validation loss: 2.496219916381291

Epoch: 210| Step: 0
Training loss: 2.5047518392903165
Validation loss: 2.5019605340185356

Epoch: 5| Step: 1
Training loss: 2.047667255393868
Validation loss: 2.4893503931367986

Epoch: 5| Step: 2
Training loss: 2.939834803137545
Validation loss: 2.5085563863599036

Epoch: 5| Step: 3
Training loss: 2.465748084492903
Validation loss: 2.4972780549270945

Epoch: 5| Step: 4
Training loss: 1.8894604335578105
Validation loss: 2.5016111348126477

Epoch: 5| Step: 5
Training loss: 2.7854125345028735
Validation loss: 2.5026946089508586

Epoch: 5| Step: 6
Training loss: 2.693894873172953
Validation loss: 2.498972594228561

Epoch: 5| Step: 7
Training loss: 1.724572394072824
Validation loss: 2.511959469790704

Epoch: 5| Step: 8
Training loss: 2.383646734568381
Validation loss: 2.5074491663490193

Epoch: 5| Step: 9
Training loss: 2.612397231129464
Validation loss: 2.4984996704420444

Epoch: 5| Step: 10
Training loss: 2.0169902583933355
Validation loss: 2.514782288578377

Epoch: 5| Step: 11
Training loss: 1.9841139013373765
Validation loss: 2.504167087912458

Epoch: 211| Step: 0
Training loss: 1.873536237925639
Validation loss: 2.511830902364288

Epoch: 5| Step: 1
Training loss: 2.112943216812886
Validation loss: 2.501672360233518

Epoch: 5| Step: 2
Training loss: 2.760043962377297
Validation loss: 2.506275307994483

Epoch: 5| Step: 3
Training loss: 2.4840284381719
Validation loss: 2.5016030893839227

Epoch: 5| Step: 4
Training loss: 2.41691189102732
Validation loss: 2.4965440824456984

Epoch: 5| Step: 5
Training loss: 2.496621232869299
Validation loss: 2.504358458090291

Epoch: 5| Step: 6
Training loss: 2.0623428978474947
Validation loss: 2.5119178103781925

Epoch: 5| Step: 7
Training loss: 2.1409998656000684
Validation loss: 2.513014902427408

Epoch: 5| Step: 8
Training loss: 2.6819689411467156
Validation loss: 2.5148959080672486

Epoch: 5| Step: 9
Training loss: 2.9084497146128623
Validation loss: 2.50580684282716

Epoch: 5| Step: 10
Training loss: 2.1597185846961144
Validation loss: 2.520455148140055

Epoch: 5| Step: 11
Training loss: 2.320971462812278
Validation loss: 2.5044578028090587

Epoch: 212| Step: 0
Training loss: 2.080944242728578
Validation loss: 2.492529013581881

Epoch: 5| Step: 1
Training loss: 2.5972206151983372
Validation loss: 2.5040446663227844

Epoch: 5| Step: 2
Training loss: 2.7926957430491113
Validation loss: 2.493779996023893

Epoch: 5| Step: 3
Training loss: 2.3381877764503636
Validation loss: 2.4956661528721025

Epoch: 5| Step: 4
Training loss: 2.5107182576164173
Validation loss: 2.4952544272267296

Epoch: 5| Step: 5
Training loss: 2.061597915814745
Validation loss: 2.49111098075624

Epoch: 5| Step: 6
Training loss: 2.3948455654039593
Validation loss: 2.4888245624707093

Epoch: 5| Step: 7
Training loss: 2.4076286428907325
Validation loss: 2.4819781059072565

Epoch: 5| Step: 8
Training loss: 2.249213399082403
Validation loss: 2.4866052130050584

Epoch: 5| Step: 9
Training loss: 1.9339736102965537
Validation loss: 2.4858245299649435

Epoch: 5| Step: 10
Training loss: 2.839207637018384
Validation loss: 2.4814809381038656

Epoch: 5| Step: 11
Training loss: 0.9832016748986748
Validation loss: 2.490286637300087

Epoch: 213| Step: 0
Training loss: 2.4914869322322137
Validation loss: 2.495244748910237

Epoch: 5| Step: 1
Training loss: 1.4763892339540743
Validation loss: 2.489891309855472

Epoch: 5| Step: 2
Training loss: 2.696967371555478
Validation loss: 2.5014523658438748

Epoch: 5| Step: 3
Training loss: 2.1839319830423234
Validation loss: 2.5057394504963812

Epoch: 5| Step: 4
Training loss: 2.609983818617898
Validation loss: 2.516478843790656

Epoch: 5| Step: 5
Training loss: 2.3514333290286373
Validation loss: 2.5178732530090717

Epoch: 5| Step: 6
Training loss: 2.1735828737720753
Validation loss: 2.5200686569170823

Epoch: 5| Step: 7
Training loss: 2.5408938332529347
Validation loss: 2.513714983377077

Epoch: 5| Step: 8
Training loss: 2.2396141464124555
Validation loss: 2.5156332789851525

Epoch: 5| Step: 9
Training loss: 2.580608397171962
Validation loss: 2.5018190064566284

Epoch: 5| Step: 10
Training loss: 2.407077696493569
Validation loss: 2.511032845364982

Epoch: 5| Step: 11
Training loss: 3.3655446729221365
Validation loss: 2.5005486879636067

Epoch: 214| Step: 0
Training loss: 2.525784278157499
Validation loss: 2.501446877451706

Epoch: 5| Step: 1
Training loss: 2.401158283791554
Validation loss: 2.5056622676182325

Epoch: 5| Step: 2
Training loss: 2.725535901771111
Validation loss: 2.5071119318273447

Epoch: 5| Step: 3
Training loss: 2.539112548334865
Validation loss: 2.5096940283947116

Epoch: 5| Step: 4
Training loss: 2.5228238614498792
Validation loss: 2.5195699881007876

Epoch: 5| Step: 5
Training loss: 2.766384903987823
Validation loss: 2.5218045843693897

Epoch: 5| Step: 6
Training loss: 2.7852724112620915
Validation loss: 2.5079827414273215

Epoch: 5| Step: 7
Training loss: 2.0465228527665533
Validation loss: 2.5123431080849916

Epoch: 5| Step: 8
Training loss: 2.0916434551435445
Validation loss: 2.507956586840002

Epoch: 5| Step: 9
Training loss: 1.6178275790441166
Validation loss: 2.495176840390703

Epoch: 5| Step: 10
Training loss: 2.1605565284867843
Validation loss: 2.4969056808311825

Epoch: 5| Step: 11
Training loss: 1.574509813837192
Validation loss: 2.4948736361826334

Epoch: 215| Step: 0
Training loss: 2.0988052602630414
Validation loss: 2.489820163161439

Epoch: 5| Step: 1
Training loss: 2.7467540310727414
Validation loss: 2.4860944895363315

Epoch: 5| Step: 2
Training loss: 2.7236758803514958
Validation loss: 2.495872750446007

Epoch: 5| Step: 3
Training loss: 2.6334448714315513
Validation loss: 2.491640495292555

Epoch: 5| Step: 4
Training loss: 2.4647136478577547
Validation loss: 2.4964342875005583

Epoch: 5| Step: 5
Training loss: 2.2050316318310466
Validation loss: 2.49847403685077

Epoch: 5| Step: 6
Training loss: 2.5382258049007023
Validation loss: 2.5098041991598055

Epoch: 5| Step: 7
Training loss: 2.4697188395737295
Validation loss: 2.50188004215497

Epoch: 5| Step: 8
Training loss: 2.1726482304792327
Validation loss: 2.519284857794434

Epoch: 5| Step: 9
Training loss: 2.3515128196968713
Validation loss: 2.5363577771212373

Epoch: 5| Step: 10
Training loss: 1.8947680138580876
Validation loss: 2.514800799547081

Epoch: 5| Step: 11
Training loss: 3.0840616826520093
Validation loss: 2.511685483404685

Epoch: 216| Step: 0
Training loss: 3.0016101648695397
Validation loss: 2.5115704371524803

Epoch: 5| Step: 1
Training loss: 2.844754387522689
Validation loss: 2.4883421925857374

Epoch: 5| Step: 2
Training loss: 2.295503998643454
Validation loss: 2.48594532327402

Epoch: 5| Step: 3
Training loss: 2.2838223729517733
Validation loss: 2.4819616115663967

Epoch: 5| Step: 4
Training loss: 2.6677356802479455
Validation loss: 2.486722033457856

Epoch: 5| Step: 5
Training loss: 2.4418498620408218
Validation loss: 2.478146833473544

Epoch: 5| Step: 6
Training loss: 2.3164418621445697
Validation loss: 2.47417816122393

Epoch: 5| Step: 7
Training loss: 2.503347635071694
Validation loss: 2.4761536037021505

Epoch: 5| Step: 8
Training loss: 2.166566137280252
Validation loss: 2.476206123069873

Epoch: 5| Step: 9
Training loss: 1.9528478196872638
Validation loss: 2.4704975731224033

Epoch: 5| Step: 10
Training loss: 1.395543903500784
Validation loss: 2.476903781580864

Epoch: 5| Step: 11
Training loss: 3.693459043968493
Validation loss: 2.493104935236427

Epoch: 217| Step: 0
Training loss: 2.4498138434862384
Validation loss: 2.4842884040631397

Epoch: 5| Step: 1
Training loss: 1.91541563199856
Validation loss: 2.489480161457706

Epoch: 5| Step: 2
Training loss: 2.24937154682188
Validation loss: 2.4902153183949665

Epoch: 5| Step: 3
Training loss: 2.8434188146885955
Validation loss: 2.507973084502566

Epoch: 5| Step: 4
Training loss: 2.091156449217748
Validation loss: 2.509842871678249

Epoch: 5| Step: 5
Training loss: 2.0260641951562857
Validation loss: 2.5099626713645513

Epoch: 5| Step: 6
Training loss: 2.226064311727379
Validation loss: 2.4911869755231426

Epoch: 5| Step: 7
Training loss: 2.8936413672470978
Validation loss: 2.4918534982820586

Epoch: 5| Step: 8
Training loss: 2.525705080450183
Validation loss: 2.4807025949380694

Epoch: 5| Step: 9
Training loss: 2.5767223819797054
Validation loss: 2.475001889366174

Epoch: 5| Step: 10
Training loss: 2.4703160401137367
Validation loss: 2.468548677983789

Epoch: 5| Step: 11
Training loss: 2.0344725648422854
Validation loss: 2.4790878777579697

Epoch: 218| Step: 0
Training loss: 2.567178874079677
Validation loss: 2.4679161868807946

Epoch: 5| Step: 1
Training loss: 2.8411160521981684
Validation loss: 2.4611228913407253

Epoch: 5| Step: 2
Training loss: 2.5744857533842875
Validation loss: 2.4615226110577906

Epoch: 5| Step: 3
Training loss: 2.3409461988990983
Validation loss: 2.46499445515461

Epoch: 5| Step: 4
Training loss: 2.1081478363980697
Validation loss: 2.4645881923381494

Epoch: 5| Step: 5
Training loss: 1.665204726225253
Validation loss: 2.4753973673995096

Epoch: 5| Step: 6
Training loss: 2.6339664816725947
Validation loss: 2.4771713166349687

Epoch: 5| Step: 7
Training loss: 2.7341210819604007
Validation loss: 2.484272980744591

Epoch: 5| Step: 8
Training loss: 2.4708953420782325
Validation loss: 2.488908346335198

Epoch: 5| Step: 9
Training loss: 2.131982103719981
Validation loss: 2.496597064180835

Epoch: 5| Step: 10
Training loss: 1.9633432654025413
Validation loss: 2.4861195594909256

Epoch: 5| Step: 11
Training loss: 2.749907405334776
Validation loss: 2.4880503692588043

Epoch: 219| Step: 0
Training loss: 2.8172743222720777
Validation loss: 2.5091133111073876

Epoch: 5| Step: 1
Training loss: 2.6933744235099
Validation loss: 2.525264586381334

Epoch: 5| Step: 2
Training loss: 2.4760791776258024
Validation loss: 2.536829102119693

Epoch: 5| Step: 3
Training loss: 2.3894918910398024
Validation loss: 2.5367188891007526

Epoch: 5| Step: 4
Training loss: 2.505552039622086
Validation loss: 2.508938604867147

Epoch: 5| Step: 5
Training loss: 2.7305732674302905
Validation loss: 2.504635086351996

Epoch: 5| Step: 6
Training loss: 2.4106771193772842
Validation loss: 2.501905204081748

Epoch: 5| Step: 7
Training loss: 2.3945119337388716
Validation loss: 2.5130579192961413

Epoch: 5| Step: 8
Training loss: 1.5050794112840824
Validation loss: 2.5017174106710502

Epoch: 5| Step: 9
Training loss: 2.206162219151877
Validation loss: 2.497342910974901

Epoch: 5| Step: 10
Training loss: 2.297542034009557
Validation loss: 2.4880744812241464

Epoch: 5| Step: 11
Training loss: 2.0938463331237656
Validation loss: 2.495595489265055

Epoch: 220| Step: 0
Training loss: 1.7505299583166205
Validation loss: 2.4929222072304054

Epoch: 5| Step: 1
Training loss: 2.2095055138268163
Validation loss: 2.4871566762371

Epoch: 5| Step: 2
Training loss: 2.5251207908216484
Validation loss: 2.478726890303624

Epoch: 5| Step: 3
Training loss: 2.5273986527435945
Validation loss: 2.4833340653369347

Epoch: 5| Step: 4
Training loss: 2.581377232258425
Validation loss: 2.4752271503833128

Epoch: 5| Step: 5
Training loss: 2.4728276824581505
Validation loss: 2.480213114063494

Epoch: 5| Step: 6
Training loss: 2.628868340818333
Validation loss: 2.488272279157292

Epoch: 5| Step: 7
Training loss: 2.578530112140459
Validation loss: 2.4905219815789104

Epoch: 5| Step: 8
Training loss: 2.020852459164856
Validation loss: 2.517849777556175

Epoch: 5| Step: 9
Training loss: 2.1397344588481824
Validation loss: 2.5192144820718525

Epoch: 5| Step: 10
Training loss: 2.424406439116851
Validation loss: 2.526168306197868

Epoch: 5| Step: 11
Training loss: 3.9891302716377512
Validation loss: 2.528033720992724

Epoch: 221| Step: 0
Training loss: 2.117931164978263
Validation loss: 2.492019233085457

Epoch: 5| Step: 1
Training loss: 2.0469795957441947
Validation loss: 2.488632768187902

Epoch: 5| Step: 2
Training loss: 2.2599451888873108
Validation loss: 2.4904758351265475

Epoch: 5| Step: 3
Training loss: 2.9335732694233485
Validation loss: 2.4863579112244243

Epoch: 5| Step: 4
Training loss: 2.8280648072302097
Validation loss: 2.491351211528448

Epoch: 5| Step: 5
Training loss: 2.409168009890122
Validation loss: 2.4968971945325653

Epoch: 5| Step: 6
Training loss: 2.2358644229615066
Validation loss: 2.5089749408077147

Epoch: 5| Step: 7
Training loss: 3.059703250533169
Validation loss: 2.504380707365774

Epoch: 5| Step: 8
Training loss: 2.282533258569752
Validation loss: 2.51526169690738

Epoch: 5| Step: 9
Training loss: 2.572670733066155
Validation loss: 2.506008961376111

Epoch: 5| Step: 10
Training loss: 2.5546220776874904
Validation loss: 2.5123221748836957

Epoch: 5| Step: 11
Training loss: 1.819931776319083
Validation loss: 2.5146384743304853

Epoch: 222| Step: 0
Training loss: 2.3703869641350144
Validation loss: 2.5254989447379073

Epoch: 5| Step: 1
Training loss: 2.626664406038012
Validation loss: 2.512138731052438

Epoch: 5| Step: 2
Training loss: 2.5358402405125666
Validation loss: 2.5291445653118365

Epoch: 5| Step: 3
Training loss: 2.2447934840313724
Validation loss: 2.5292407016088654

Epoch: 5| Step: 4
Training loss: 3.1495668264791603
Validation loss: 2.530656391758388

Epoch: 5| Step: 5
Training loss: 2.5481258199398993
Validation loss: 2.5382362312417612

Epoch: 5| Step: 6
Training loss: 2.330214209471723
Validation loss: 2.5297228146452713

Epoch: 5| Step: 7
Training loss: 2.1162286255101237
Validation loss: 2.5394282972491986

Epoch: 5| Step: 8
Training loss: 2.425355637418262
Validation loss: 2.511159396539574

Epoch: 5| Step: 9
Training loss: 2.661365385479201
Validation loss: 2.5102449981010992

Epoch: 5| Step: 10
Training loss: 2.5961170655821335
Validation loss: 2.5068717491327277

Epoch: 5| Step: 11
Training loss: 2.8816256263800737
Validation loss: 2.4836535295906033

Epoch: 223| Step: 0
Training loss: 2.138744447077772
Validation loss: 2.493092690430054

Epoch: 5| Step: 1
Training loss: 2.6559557583467783
Validation loss: 2.492057226875876

Epoch: 5| Step: 2
Training loss: 2.2671115602253824
Validation loss: 2.4846575554327632

Epoch: 5| Step: 3
Training loss: 2.2938517701234185
Validation loss: 2.481109480318003

Epoch: 5| Step: 4
Training loss: 2.7648391900371236
Validation loss: 2.490551159225588

Epoch: 5| Step: 5
Training loss: 2.6241778039761527
Validation loss: 2.4770406066978334

Epoch: 5| Step: 6
Training loss: 2.6610306746454104
Validation loss: 2.4860969749654975

Epoch: 5| Step: 7
Training loss: 2.6519625899724306
Validation loss: 2.492263318446175

Epoch: 5| Step: 8
Training loss: 1.7381739894049295
Validation loss: 2.48137917218418

Epoch: 5| Step: 9
Training loss: 2.596774716053327
Validation loss: 2.4934005316361034

Epoch: 5| Step: 10
Training loss: 2.284641723090726
Validation loss: 2.4940027344698117

Epoch: 5| Step: 11
Training loss: 2.294277253215928
Validation loss: 2.488443637821009

Epoch: 224| Step: 0
Training loss: 1.8361391646639804
Validation loss: 2.490554920584285

Epoch: 5| Step: 1
Training loss: 2.515374496971747
Validation loss: 2.497170118222803

Epoch: 5| Step: 2
Training loss: 2.212038554547135
Validation loss: 2.4910778138189067

Epoch: 5| Step: 3
Training loss: 2.898995646488938
Validation loss: 2.4790178556151856

Epoch: 5| Step: 4
Training loss: 3.014341723697179
Validation loss: 2.467462288337396

Epoch: 5| Step: 5
Training loss: 1.8165665094373034
Validation loss: 2.481358460186583

Epoch: 5| Step: 6
Training loss: 1.7304409877367053
Validation loss: 2.477271547110422

Epoch: 5| Step: 7
Training loss: 2.7422447959369904
Validation loss: 2.4735248279557966

Epoch: 5| Step: 8
Training loss: 2.0032543884480636
Validation loss: 2.468070133771783

Epoch: 5| Step: 9
Training loss: 2.723552977608179
Validation loss: 2.4641970205668215

Epoch: 5| Step: 10
Training loss: 2.4957153797669758
Validation loss: 2.466120357576539

Epoch: 5| Step: 11
Training loss: 2.0888596543956033
Validation loss: 2.472525257178305

Epoch: 225| Step: 0
Training loss: 1.9163805568386334
Validation loss: 2.469679560879643

Epoch: 5| Step: 1
Training loss: 2.7491916855707297
Validation loss: 2.4767247175966594

Epoch: 5| Step: 2
Training loss: 2.407134946120435
Validation loss: 2.500766847142561

Epoch: 5| Step: 3
Training loss: 2.108745339687514
Validation loss: 2.5226321121089605

Epoch: 5| Step: 4
Training loss: 2.683574737525901
Validation loss: 2.5357998822960526

Epoch: 5| Step: 5
Training loss: 2.6625607192588556
Validation loss: 2.5317815057785533

Epoch: 5| Step: 6
Training loss: 1.60799007639978
Validation loss: 2.532300330873891

Epoch: 5| Step: 7
Training loss: 2.4367077836073965
Validation loss: 2.522061806574351

Epoch: 5| Step: 8
Training loss: 2.18863081994836
Validation loss: 2.5164433583655317

Epoch: 5| Step: 9
Training loss: 2.6638792092372077
Validation loss: 2.5036727272675265

Epoch: 5| Step: 10
Training loss: 2.585798369292262
Validation loss: 2.496473682444135

Epoch: 5| Step: 11
Training loss: 2.8922398361012958
Validation loss: 2.502529815352671

Epoch: 226| Step: 0
Training loss: 2.5684754087976285
Validation loss: 2.4899497873089644

Epoch: 5| Step: 1
Training loss: 2.5977230665748867
Validation loss: 2.473974373748712

Epoch: 5| Step: 2
Training loss: 2.9038850739912587
Validation loss: 2.4714934601568284

Epoch: 5| Step: 3
Training loss: 2.4121075958368943
Validation loss: 2.4675127140015216

Epoch: 5| Step: 4
Training loss: 1.8852312688844213
Validation loss: 2.471310929033055

Epoch: 5| Step: 5
Training loss: 2.269363475907928
Validation loss: 2.4737439447502005

Epoch: 5| Step: 6
Training loss: 2.3068788616982143
Validation loss: 2.4764155957026404

Epoch: 5| Step: 7
Training loss: 1.8618424656622696
Validation loss: 2.469229229153679

Epoch: 5| Step: 8
Training loss: 2.2906961177595027
Validation loss: 2.468279628770436

Epoch: 5| Step: 9
Training loss: 2.858192240918613
Validation loss: 2.4803731904934083

Epoch: 5| Step: 10
Training loss: 2.3221407793396733
Validation loss: 2.4740635953226766

Epoch: 5| Step: 11
Training loss: 2.5694301215336797
Validation loss: 2.4883396315500264

Epoch: 227| Step: 0
Training loss: 2.8357602739259815
Validation loss: 2.486090201965387

Epoch: 5| Step: 1
Training loss: 2.266982625463109
Validation loss: 2.502307820049773

Epoch: 5| Step: 2
Training loss: 1.9421924250349236
Validation loss: 2.534175790968725

Epoch: 5| Step: 3
Training loss: 2.64338593918486
Validation loss: 2.5453710854885254

Epoch: 5| Step: 4
Training loss: 2.4376184483627834
Validation loss: 2.5812602313118322

Epoch: 5| Step: 5
Training loss: 2.696566171302113
Validation loss: 2.5659801259060346

Epoch: 5| Step: 6
Training loss: 2.294081253954108
Validation loss: 2.556217528698909

Epoch: 5| Step: 7
Training loss: 2.7623984270711666
Validation loss: 2.5423029131912678

Epoch: 5| Step: 8
Training loss: 2.755709443315863
Validation loss: 2.511210182954069

Epoch: 5| Step: 9
Training loss: 2.5901819529008576
Validation loss: 2.48754708295062

Epoch: 5| Step: 10
Training loss: 2.3735317912153424
Validation loss: 2.477358155743496

Epoch: 5| Step: 11
Training loss: 2.1247059113694653
Validation loss: 2.473196576277868

Epoch: 228| Step: 0
Training loss: 2.7495139299321822
Validation loss: 2.4784943579965533

Epoch: 5| Step: 1
Training loss: 2.866732277969508
Validation loss: 2.4743322083236268

Epoch: 5| Step: 2
Training loss: 2.471664350289485
Validation loss: 2.4756631852938256

Epoch: 5| Step: 3
Training loss: 1.9210715746753515
Validation loss: 2.4787358996999713

Epoch: 5| Step: 4
Training loss: 1.848575806784167
Validation loss: 2.4825589522065283

Epoch: 5| Step: 5
Training loss: 2.284799609923663
Validation loss: 2.48066918672149

Epoch: 5| Step: 6
Training loss: 2.3353689260874946
Validation loss: 2.491293608339141

Epoch: 5| Step: 7
Training loss: 2.258498671650575
Validation loss: 2.485017237632266

Epoch: 5| Step: 8
Training loss: 2.796992464635721
Validation loss: 2.4828411141457787

Epoch: 5| Step: 9
Training loss: 2.045768963124179
Validation loss: 2.4794137648582777

Epoch: 5| Step: 10
Training loss: 3.111967913023367
Validation loss: 2.4818276715383014

Epoch: 5| Step: 11
Training loss: 1.2510049594869272
Validation loss: 2.4864292528752925

Epoch: 229| Step: 0
Training loss: 2.8236318060129113
Validation loss: 2.4929829267821786

Epoch: 5| Step: 1
Training loss: 2.8507453479215377
Validation loss: 2.4946996808597897

Epoch: 5| Step: 2
Training loss: 2.4364016087716025
Validation loss: 2.493157663323428

Epoch: 5| Step: 3
Training loss: 2.4838131443208202
Validation loss: 2.498768272555727

Epoch: 5| Step: 4
Training loss: 2.3159467424716063
Validation loss: 2.493058633374434

Epoch: 5| Step: 5
Training loss: 2.5173033807792353
Validation loss: 2.4998859001983966

Epoch: 5| Step: 6
Training loss: 2.1026407758505226
Validation loss: 2.5009334768535973

Epoch: 5| Step: 7
Training loss: 2.0438844222445995
Validation loss: 2.502902138576147

Epoch: 5| Step: 8
Training loss: 2.636705457865802
Validation loss: 2.5035722879794813

Epoch: 5| Step: 9
Training loss: 2.0553368532264273
Validation loss: 2.5056249995052027

Epoch: 5| Step: 10
Training loss: 2.02217704957712
Validation loss: 2.5010091016609644

Epoch: 5| Step: 11
Training loss: 1.6778069192925338
Validation loss: 2.4963401509642376

Epoch: 230| Step: 0
Training loss: 2.6124918704841833
Validation loss: 2.4895014782674085

Epoch: 5| Step: 1
Training loss: 1.7335438154265563
Validation loss: 2.481678955336129

Epoch: 5| Step: 2
Training loss: 2.8895038801920685
Validation loss: 2.4870017977711747

Epoch: 5| Step: 3
Training loss: 1.540072501816733
Validation loss: 2.4815935643315052

Epoch: 5| Step: 4
Training loss: 2.653731554697685
Validation loss: 2.4878800137022465

Epoch: 5| Step: 5
Training loss: 2.6844076951759166
Validation loss: 2.475958781659864

Epoch: 5| Step: 6
Training loss: 2.365538069666034
Validation loss: 2.469329138320026

Epoch: 5| Step: 7
Training loss: 2.5303501366342256
Validation loss: 2.4718252737233564

Epoch: 5| Step: 8
Training loss: 2.3836630381988333
Validation loss: 2.4788216356130426

Epoch: 5| Step: 9
Training loss: 2.200145898662821
Validation loss: 2.4703540660973164

Epoch: 5| Step: 10
Training loss: 2.333404290164879
Validation loss: 2.477793841706103

Epoch: 5| Step: 11
Training loss: 2.10878513707146
Validation loss: 2.478720345645975

Epoch: 231| Step: 0
Training loss: 2.2327563418246084
Validation loss: 2.46985184349352

Epoch: 5| Step: 1
Training loss: 1.683064601082209
Validation loss: 2.4734076231651954

Epoch: 5| Step: 2
Training loss: 2.2283386641642857
Validation loss: 2.4792886324674823

Epoch: 5| Step: 3
Training loss: 2.5751030058767057
Validation loss: 2.475154544680512

Epoch: 5| Step: 4
Training loss: 2.2153558694062663
Validation loss: 2.467767036891618

Epoch: 5| Step: 5
Training loss: 2.8432578195410536
Validation loss: 2.478712237941409

Epoch: 5| Step: 6
Training loss: 2.133725819643444
Validation loss: 2.4707806038550597

Epoch: 5| Step: 7
Training loss: 2.726155860111561
Validation loss: 2.4800896182134156

Epoch: 5| Step: 8
Training loss: 2.587887124113198
Validation loss: 2.4818303613771944

Epoch: 5| Step: 9
Training loss: 2.5052106914125845
Validation loss: 2.482476974904263

Epoch: 5| Step: 10
Training loss: 1.9456422824992714
Validation loss: 2.4931756893553763

Epoch: 5| Step: 11
Training loss: 2.6629090259123847
Validation loss: 2.486523812567423

Epoch: 232| Step: 0
Training loss: 2.0687219808012136
Validation loss: 2.4914718126466715

Epoch: 5| Step: 1
Training loss: 2.0605572885548473
Validation loss: 2.5175960393149404

Epoch: 5| Step: 2
Training loss: 2.5195431731185907
Validation loss: 2.5222540325158143

Epoch: 5| Step: 3
Training loss: 2.5738551993081535
Validation loss: 2.5154918611728827

Epoch: 5| Step: 4
Training loss: 2.9855654274577303
Validation loss: 2.5158278342034546

Epoch: 5| Step: 5
Training loss: 2.3622861169950102
Validation loss: 2.5196246975072505

Epoch: 5| Step: 6
Training loss: 2.5564369487720353
Validation loss: 2.5178230902376617

Epoch: 5| Step: 7
Training loss: 2.5430662543711073
Validation loss: 2.502469758160021

Epoch: 5| Step: 8
Training loss: 2.2643014132835217
Validation loss: 2.494468135734215

Epoch: 5| Step: 9
Training loss: 1.9838489826508887
Validation loss: 2.4907926325143803

Epoch: 5| Step: 10
Training loss: 2.342839483782711
Validation loss: 2.4887145227623964

Epoch: 5| Step: 11
Training loss: 2.1371699385096488
Validation loss: 2.4868004872843517

Epoch: 233| Step: 0
Training loss: 2.1780891711053467
Validation loss: 2.487964404347766

Epoch: 5| Step: 1
Training loss: 1.9166348979915546
Validation loss: 2.4811086374974862

Epoch: 5| Step: 2
Training loss: 2.6999530152365363
Validation loss: 2.4809888299501957

Epoch: 5| Step: 3
Training loss: 2.0206053955939467
Validation loss: 2.488183052045662

Epoch: 5| Step: 4
Training loss: 2.6495943046814987
Validation loss: 2.483442699394449

Epoch: 5| Step: 5
Training loss: 2.7257747003898096
Validation loss: 2.4835417687759227

Epoch: 5| Step: 6
Training loss: 2.1827499042074487
Validation loss: 2.4818556745396867

Epoch: 5| Step: 7
Training loss: 2.3545323878321023
Validation loss: 2.493965989194763

Epoch: 5| Step: 8
Training loss: 2.394028279436247
Validation loss: 2.4896864224615074

Epoch: 5| Step: 9
Training loss: 2.293601057741462
Validation loss: 2.485928056028831

Epoch: 5| Step: 10
Training loss: 2.5994618959387537
Validation loss: 2.4927499867801033

Epoch: 5| Step: 11
Training loss: 1.6781963027780626
Validation loss: 2.492999212719859

Epoch: 234| Step: 0
Training loss: 2.218887647200655
Validation loss: 2.493221331609896

Epoch: 5| Step: 1
Training loss: 2.3645232160771177
Validation loss: 2.503474193795025

Epoch: 5| Step: 2
Training loss: 2.7377557399906602
Validation loss: 2.502587282968677

Epoch: 5| Step: 3
Training loss: 2.270745325278771
Validation loss: 2.513120656509776

Epoch: 5| Step: 4
Training loss: 2.364572522198894
Validation loss: 2.5098635920342867

Epoch: 5| Step: 5
Training loss: 2.3053759564941356
Validation loss: 2.5104159055737707

Epoch: 5| Step: 6
Training loss: 2.3177655045105245
Validation loss: 2.5086104904973734

Epoch: 5| Step: 7
Training loss: 1.9802234505269156
Validation loss: 2.5073097929373933

Epoch: 5| Step: 8
Training loss: 2.7984810592013116
Validation loss: 2.4995120843965433

Epoch: 5| Step: 9
Training loss: 2.558505037822762
Validation loss: 2.5123521985916444

Epoch: 5| Step: 10
Training loss: 2.079456333121093
Validation loss: 2.5078336213708896

Epoch: 5| Step: 11
Training loss: 0.865142025120152
Validation loss: 2.5055908273301544

Epoch: 235| Step: 0
Training loss: 2.195201070000635
Validation loss: 2.4977838269869297

Epoch: 5| Step: 1
Training loss: 2.7787841838702305
Validation loss: 2.481248575813916

Epoch: 5| Step: 2
Training loss: 2.620519811155405
Validation loss: 2.480022840894605

Epoch: 5| Step: 3
Training loss: 1.9905633626404977
Validation loss: 2.4784187155661734

Epoch: 5| Step: 4
Training loss: 2.078286645095163
Validation loss: 2.470805033113754

Epoch: 5| Step: 5
Training loss: 2.3801152206227205
Validation loss: 2.4771568174881384

Epoch: 5| Step: 6
Training loss: 2.815523006442087
Validation loss: 2.472959189516709

Epoch: 5| Step: 7
Training loss: 2.587707282715351
Validation loss: 2.482359950676123

Epoch: 5| Step: 8
Training loss: 1.725283187619972
Validation loss: 2.489701231688026

Epoch: 5| Step: 9
Training loss: 2.1964383208161475
Validation loss: 2.4874769115494697

Epoch: 5| Step: 10
Training loss: 2.7342935604501646
Validation loss: 2.494369480404458

Epoch: 5| Step: 11
Training loss: 3.1660641214091076
Validation loss: 2.505540761615552

Epoch: 236| Step: 0
Training loss: 2.382761069821507
Validation loss: 2.502169641143817

Epoch: 5| Step: 1
Training loss: 2.4279922507977827
Validation loss: 2.494563589375278

Epoch: 5| Step: 2
Training loss: 2.682645271968026
Validation loss: 2.489407662188482

Epoch: 5| Step: 3
Training loss: 2.6283073479967003
Validation loss: 2.499336365196629

Epoch: 5| Step: 4
Training loss: 1.897370403523227
Validation loss: 2.5010116477371214

Epoch: 5| Step: 5
Training loss: 2.3718968245918264
Validation loss: 2.51076590349888

Epoch: 5| Step: 6
Training loss: 2.4627719399808283
Validation loss: 2.4853514465851623

Epoch: 5| Step: 7
Training loss: 2.436576864081081
Validation loss: 2.4965898541151925

Epoch: 5| Step: 8
Training loss: 1.4624728534493951
Validation loss: 2.4929404322172393

Epoch: 5| Step: 9
Training loss: 2.6390558580368055
Validation loss: 2.4960881264493393

Epoch: 5| Step: 10
Training loss: 2.3084241672459793
Validation loss: 2.4896816383223546

Epoch: 5| Step: 11
Training loss: 1.8362513497115875
Validation loss: 2.503717612759984

Epoch: 237| Step: 0
Training loss: 2.096417450196473
Validation loss: 2.503602539623533

Epoch: 5| Step: 1
Training loss: 2.568201931961363
Validation loss: 2.50277422520024

Epoch: 5| Step: 2
Training loss: 2.500248610532848
Validation loss: 2.493175681386337

Epoch: 5| Step: 3
Training loss: 2.032257065184348
Validation loss: 2.492201403476434

Epoch: 5| Step: 4
Training loss: 1.9761575276445353
Validation loss: 2.494456236129857

Epoch: 5| Step: 5
Training loss: 2.2024041477783696
Validation loss: 2.4855002288222248

Epoch: 5| Step: 6
Training loss: 2.675850659883283
Validation loss: 2.482020219812968

Epoch: 5| Step: 7
Training loss: 2.6408340100517944
Validation loss: 2.4755941116228155

Epoch: 5| Step: 8
Training loss: 2.504084778608882
Validation loss: 2.4769228684083835

Epoch: 5| Step: 9
Training loss: 2.287457108225782
Validation loss: 2.4777774578311904

Epoch: 5| Step: 10
Training loss: 2.7663936947589103
Validation loss: 2.471028266591456

Epoch: 5| Step: 11
Training loss: 1.6841536650737001
Validation loss: 2.4665602215361244

Epoch: 238| Step: 0
Training loss: 1.8171189089398319
Validation loss: 2.477875017767923

Epoch: 5| Step: 1
Training loss: 2.646696255355955
Validation loss: 2.4875986189917674

Epoch: 5| Step: 2
Training loss: 2.4707754976430816
Validation loss: 2.495918430943129

Epoch: 5| Step: 3
Training loss: 2.3884932044916587
Validation loss: 2.4850330720794878

Epoch: 5| Step: 4
Training loss: 2.8857273159515278
Validation loss: 2.5132447902259014

Epoch: 5| Step: 5
Training loss: 1.7707196217847105
Validation loss: 2.516166980085749

Epoch: 5| Step: 6
Training loss: 2.054228176514012
Validation loss: 2.52348046910852

Epoch: 5| Step: 7
Training loss: 2.8162697006328923
Validation loss: 2.5133089061856158

Epoch: 5| Step: 8
Training loss: 2.2539625243462296
Validation loss: 2.5160069304048864

Epoch: 5| Step: 9
Training loss: 1.8762522012899703
Validation loss: 2.5253798387950606

Epoch: 5| Step: 10
Training loss: 1.9869916589693377
Validation loss: 2.5111265379179586

Epoch: 5| Step: 11
Training loss: 3.6982451530305642
Validation loss: 2.5184211315900034

Epoch: 239| Step: 0
Training loss: 1.88468934532332
Validation loss: 2.5107583265899898

Epoch: 5| Step: 1
Training loss: 2.7010795483701577
Validation loss: 2.501339462188971

Epoch: 5| Step: 2
Training loss: 2.3510933341480182
Validation loss: 2.4901379814689797

Epoch: 5| Step: 3
Training loss: 2.034922170814396
Validation loss: 2.494147985532649

Epoch: 5| Step: 4
Training loss: 2.002203442810897
Validation loss: 2.483881135552707

Epoch: 5| Step: 5
Training loss: 2.8341469064136016
Validation loss: 2.479201550331782

Epoch: 5| Step: 6
Training loss: 2.408612367333477
Validation loss: 2.4765809877750495

Epoch: 5| Step: 7
Training loss: 2.677987763528595
Validation loss: 2.4827868345649367

Epoch: 5| Step: 8
Training loss: 2.7316059151256273
Validation loss: 2.4844945163089234

Epoch: 5| Step: 9
Training loss: 2.4290399700471017
Validation loss: 2.4721431591545326

Epoch: 5| Step: 10
Training loss: 1.9757636344368747
Validation loss: 2.479980020109315

Epoch: 5| Step: 11
Training loss: 2.2560288931166523
Validation loss: 2.4801359579161044

Epoch: 240| Step: 0
Training loss: 2.231653864023504
Validation loss: 2.4818602416087154

Epoch: 5| Step: 1
Training loss: 2.498665835101879
Validation loss: 2.4838026175119463

Epoch: 5| Step: 2
Training loss: 1.62290276393722
Validation loss: 2.4922987794496914

Epoch: 5| Step: 3
Training loss: 2.7330113961812335
Validation loss: 2.50117629511197

Epoch: 5| Step: 4
Training loss: 2.461185697119493
Validation loss: 2.5171025243489695

Epoch: 5| Step: 5
Training loss: 1.8015570634692066
Validation loss: 2.513223481119611

Epoch: 5| Step: 6
Training loss: 2.95968545092968
Validation loss: 2.532962137610989

Epoch: 5| Step: 7
Training loss: 2.019717298308823
Validation loss: 2.538262938760882

Epoch: 5| Step: 8
Training loss: 2.3448772517045584
Validation loss: 2.5348415522305334

Epoch: 5| Step: 9
Training loss: 2.769456009589301
Validation loss: 2.515644930332126

Epoch: 5| Step: 10
Training loss: 2.235293646345886
Validation loss: 2.5168857811178333

Epoch: 5| Step: 11
Training loss: 2.6583342509332906
Validation loss: 2.513669045344699

Epoch: 241| Step: 0
Training loss: 2.4537482958033237
Validation loss: 2.5075866343985163

Epoch: 5| Step: 1
Training loss: 2.606013617098664
Validation loss: 2.5120008240035805

Epoch: 5| Step: 2
Training loss: 1.985320939607964
Validation loss: 2.5273470713983217

Epoch: 5| Step: 3
Training loss: 2.4169116937354045
Validation loss: 2.538941987919051

Epoch: 5| Step: 4
Training loss: 2.153824589301718
Validation loss: 2.534398361894872

Epoch: 5| Step: 5
Training loss: 2.2083822520853773
Validation loss: 2.532245232331457

Epoch: 5| Step: 6
Training loss: 2.7005460045774736
Validation loss: 2.5242223631174654

Epoch: 5| Step: 7
Training loss: 2.3011222547790045
Validation loss: 2.5275603746422055

Epoch: 5| Step: 8
Training loss: 2.5777408198012894
Validation loss: 2.5093777011652527

Epoch: 5| Step: 9
Training loss: 2.4155963851595934
Validation loss: 2.5227752521224986

Epoch: 5| Step: 10
Training loss: 2.290278609706012
Validation loss: 2.511730848632277

Epoch: 5| Step: 11
Training loss: 3.32601876390845
Validation loss: 2.5089704032982874

Epoch: 242| Step: 0
Training loss: 1.9363916980372382
Validation loss: 2.5012057178421383

Epoch: 5| Step: 1
Training loss: 2.4167795045313816
Validation loss: 2.48899027944526

Epoch: 5| Step: 2
Training loss: 1.9614722142173227
Validation loss: 2.4849528754222288

Epoch: 5| Step: 3
Training loss: 2.872971855963133
Validation loss: 2.4754700121300193

Epoch: 5| Step: 4
Training loss: 2.376008171125291
Validation loss: 2.4732361043813924

Epoch: 5| Step: 5
Training loss: 2.554200945609123
Validation loss: 2.475493492191107

Epoch: 5| Step: 6
Training loss: 1.605064099775781
Validation loss: 2.4712866776271785

Epoch: 5| Step: 7
Training loss: 2.7816511572086804
Validation loss: 2.483728272653868

Epoch: 5| Step: 8
Training loss: 2.530793608034544
Validation loss: 2.4708644769023507

Epoch: 5| Step: 9
Training loss: 2.662580329507052
Validation loss: 2.4737161752072683

Epoch: 5| Step: 10
Training loss: 2.1817676094002825
Validation loss: 2.4684259668797064

Epoch: 5| Step: 11
Training loss: 2.785004642421065
Validation loss: 2.4799827740408116

Epoch: 243| Step: 0
Training loss: 2.2791897602294475
Validation loss: 2.486605512633649

Epoch: 5| Step: 1
Training loss: 2.842521318206428
Validation loss: 2.4798800453182013

Epoch: 5| Step: 2
Training loss: 2.5431975043520665
Validation loss: 2.4820517107174553

Epoch: 5| Step: 3
Training loss: 1.6313198878491948
Validation loss: 2.4869479205713465

Epoch: 5| Step: 4
Training loss: 2.152845819143163
Validation loss: 2.498186339699844

Epoch: 5| Step: 5
Training loss: 2.242829872118283
Validation loss: 2.490812669812746

Epoch: 5| Step: 6
Training loss: 2.2296699122247823
Validation loss: 2.4988033669335374

Epoch: 5| Step: 7
Training loss: 2.0142777546162045
Validation loss: 2.5015292536956433

Epoch: 5| Step: 8
Training loss: 2.7927040241402192
Validation loss: 2.5192778112411998

Epoch: 5| Step: 9
Training loss: 2.5234475150367244
Validation loss: 2.5022840874076278

Epoch: 5| Step: 10
Training loss: 2.568797955216194
Validation loss: 2.506360739990821

Epoch: 5| Step: 11
Training loss: 2.1145214453850225
Validation loss: 2.5083955976187013

Epoch: 244| Step: 0
Training loss: 2.767932080427837
Validation loss: 2.5087892921638706

Epoch: 5| Step: 1
Training loss: 2.658887742764912
Validation loss: 2.5107429155219836

Epoch: 5| Step: 2
Training loss: 1.9365358106994086
Validation loss: 2.5069030863684

Epoch: 5| Step: 3
Training loss: 2.468820788177417
Validation loss: 2.5091634104553533

Epoch: 5| Step: 4
Training loss: 2.2942390107723747
Validation loss: 2.5171786934248446

Epoch: 5| Step: 5
Training loss: 2.1009654505202566
Validation loss: 2.505257787764881

Epoch: 5| Step: 6
Training loss: 2.269323342758911
Validation loss: 2.4978958692684414

Epoch: 5| Step: 7
Training loss: 2.8447915988746577
Validation loss: 2.51137384723231

Epoch: 5| Step: 8
Training loss: 2.034377756424544
Validation loss: 2.5146769994206215

Epoch: 5| Step: 9
Training loss: 1.8725279724720882
Validation loss: 2.509708895703909

Epoch: 5| Step: 10
Training loss: 2.0430789137363017
Validation loss: 2.513981070739831

Epoch: 5| Step: 11
Training loss: 3.5579391195611283
Validation loss: 2.5070629247445795

Epoch: 245| Step: 0
Training loss: 2.652329817048502
Validation loss: 2.502059009146844

Epoch: 5| Step: 1
Training loss: 2.3887507253313385
Validation loss: 2.507311548128586

Epoch: 5| Step: 2
Training loss: 2.3788399021561606
Validation loss: 2.5054955975377062

Epoch: 5| Step: 3
Training loss: 2.2944951606278834
Validation loss: 2.5078258494242673

Epoch: 5| Step: 4
Training loss: 1.7250949612339195
Validation loss: 2.5256521567005104

Epoch: 5| Step: 5
Training loss: 2.560720244357208
Validation loss: 2.5234474008718286

Epoch: 5| Step: 6
Training loss: 2.548058170642696
Validation loss: 2.5261370349198247

Epoch: 5| Step: 7
Training loss: 2.1120161687492134
Validation loss: 2.5256107801795262

Epoch: 5| Step: 8
Training loss: 1.7465256534442997
Validation loss: 2.518725011400279

Epoch: 5| Step: 9
Training loss: 2.491062496343128
Validation loss: 2.525496533487333

Epoch: 5| Step: 10
Training loss: 2.624557639496521
Validation loss: 2.5261774374009565

Epoch: 5| Step: 11
Training loss: 2.502156281393821
Validation loss: 2.515885621938778

Epoch: 246| Step: 0
Training loss: 2.3128762841162605
Validation loss: 2.495227338993432

Epoch: 5| Step: 1
Training loss: 2.1647953486460967
Validation loss: 2.4906802308114337

Epoch: 5| Step: 2
Training loss: 2.636152554226339
Validation loss: 2.4907520389425377

Epoch: 5| Step: 3
Training loss: 2.6322195590948514
Validation loss: 2.4858455544249227

Epoch: 5| Step: 4
Training loss: 1.947598932909404
Validation loss: 2.4933877643616675

Epoch: 5| Step: 5
Training loss: 2.7901045191065985
Validation loss: 2.4938717893627884

Epoch: 5| Step: 6
Training loss: 2.6624119811217155
Validation loss: 2.488306353815183

Epoch: 5| Step: 7
Training loss: 1.6204826214172454
Validation loss: 2.4813498266334886

Epoch: 5| Step: 8
Training loss: 2.342381802796205
Validation loss: 2.48445128477685

Epoch: 5| Step: 9
Training loss: 1.8529527812526692
Validation loss: 2.497995824940921

Epoch: 5| Step: 10
Training loss: 2.522371521656102
Validation loss: 2.485277559768741

Epoch: 5| Step: 11
Training loss: 2.015491569893198
Validation loss: 2.4992569574168484

Epoch: 247| Step: 0
Training loss: 2.135787286618028
Validation loss: 2.501905918792715

Epoch: 5| Step: 1
Training loss: 2.24456023566985
Validation loss: 2.499124852624933

Epoch: 5| Step: 2
Training loss: 2.099976802879459
Validation loss: 2.506579732885992

Epoch: 5| Step: 3
Training loss: 1.9075491808629441
Validation loss: 2.514981090678069

Epoch: 5| Step: 4
Training loss: 2.8319785488092113
Validation loss: 2.519233248334775

Epoch: 5| Step: 5
Training loss: 2.306097911585678
Validation loss: 2.5064964921572774

Epoch: 5| Step: 6
Training loss: 2.467852079091724
Validation loss: 2.5002693309346236

Epoch: 5| Step: 7
Training loss: 1.8930614944642237
Validation loss: 2.500264586911483

Epoch: 5| Step: 8
Training loss: 2.262498474120579
Validation loss: 2.4969451757570873

Epoch: 5| Step: 9
Training loss: 2.4189187988996586
Validation loss: 2.483250917490145

Epoch: 5| Step: 10
Training loss: 2.844191799848198
Validation loss: 2.49087223036859

Epoch: 5| Step: 11
Training loss: 2.6589888869530727
Validation loss: 2.488148756107853

Epoch: 248| Step: 0
Training loss: 2.377350497353738
Validation loss: 2.490239720556967

Epoch: 5| Step: 1
Training loss: 2.2689394154570115
Validation loss: 2.4920282861123235

Epoch: 5| Step: 2
Training loss: 1.7484476834052611
Validation loss: 2.501199438533123

Epoch: 5| Step: 3
Training loss: 2.0802577268046427
Validation loss: 2.519313446014713

Epoch: 5| Step: 4
Training loss: 2.6642188420664
Validation loss: 2.5003249990294436

Epoch: 5| Step: 5
Training loss: 3.163964540825416
Validation loss: 2.5138604983300867

Epoch: 5| Step: 6
Training loss: 2.0840446656505502
Validation loss: 2.5059644122568954

Epoch: 5| Step: 7
Training loss: 2.2261073667916125
Validation loss: 2.527076019146538

Epoch: 5| Step: 8
Training loss: 2.400561755717081
Validation loss: 2.529151710065916

Epoch: 5| Step: 9
Training loss: 1.9240351996344487
Validation loss: 2.5164959665432

Epoch: 5| Step: 10
Training loss: 2.2551746204373067
Validation loss: 2.535567144041491

Epoch: 5| Step: 11
Training loss: 2.7425914151753013
Validation loss: 2.5440020398083294

Epoch: 249| Step: 0
Training loss: 2.3850626342674235
Validation loss: 2.532825442796255

Epoch: 5| Step: 1
Training loss: 1.985907976244696
Validation loss: 2.501227149191761

Epoch: 5| Step: 2
Training loss: 2.192780687553426
Validation loss: 2.4854834261164944

Epoch: 5| Step: 3
Training loss: 2.441778291965062
Validation loss: 2.467551664857001

Epoch: 5| Step: 4
Training loss: 2.206395312486722
Validation loss: 2.468035868277163

Epoch: 5| Step: 5
Training loss: 2.289992212007431
Validation loss: 2.4690926672135394

Epoch: 5| Step: 6
Training loss: 2.150184836315768
Validation loss: 2.4633663906841843

Epoch: 5| Step: 7
Training loss: 2.66829633586649
Validation loss: 2.47201391939737

Epoch: 5| Step: 8
Training loss: 2.2171863902696085
Validation loss: 2.4796283529783643

Epoch: 5| Step: 9
Training loss: 1.9626238741321467
Validation loss: 2.476762946006481

Epoch: 5| Step: 10
Training loss: 3.188464897566717
Validation loss: 2.4886832598683926

Epoch: 5| Step: 11
Training loss: 2.5354127915749025
Validation loss: 2.5015289836530914

Epoch: 250| Step: 0
Training loss: 1.920116705725133
Validation loss: 2.5143935504607997

Epoch: 5| Step: 1
Training loss: 2.2233697855457124
Validation loss: 2.5150840841157627

Epoch: 5| Step: 2
Training loss: 2.821413538515076
Validation loss: 2.5441317225793987

Epoch: 5| Step: 3
Training loss: 2.1426180728884723
Validation loss: 2.544248568470945

Epoch: 5| Step: 4
Training loss: 1.9850936549503024
Validation loss: 2.540640668206819

Epoch: 5| Step: 5
Training loss: 2.6799552939372777
Validation loss: 2.525656729139134

Epoch: 5| Step: 6
Training loss: 2.4348688841499677
Validation loss: 2.52746278304644

Epoch: 5| Step: 7
Training loss: 2.300711923795051
Validation loss: 2.537198377168477

Epoch: 5| Step: 8
Training loss: 1.8341403687651565
Validation loss: 2.515254094046099

Epoch: 5| Step: 9
Training loss: 2.5894720809088474
Validation loss: 2.5268448146036464

Epoch: 5| Step: 10
Training loss: 2.766366977622964
Validation loss: 2.5173968952017973

Epoch: 5| Step: 11
Training loss: 1.2037613412039565
Validation loss: 2.5086438750885702

Epoch: 251| Step: 0
Training loss: 2.5355732109078484
Validation loss: 2.5157563114053603

Epoch: 5| Step: 1
Training loss: 1.9054892225678914
Validation loss: 2.5124224423067103

Epoch: 5| Step: 2
Training loss: 2.4914814777087684
Validation loss: 2.508476422961015

Epoch: 5| Step: 3
Training loss: 2.385403484546825
Validation loss: 2.4940553479812437

Epoch: 5| Step: 4
Training loss: 1.9598262115231464
Validation loss: 2.5012650130445855

Epoch: 5| Step: 5
Training loss: 2.047123085887112
Validation loss: 2.494507549781408

Epoch: 5| Step: 6
Training loss: 2.1106104870659563
Validation loss: 2.484801129916696

Epoch: 5| Step: 7
Training loss: 2.492884140945873
Validation loss: 2.500795446449129

Epoch: 5| Step: 8
Training loss: 2.496612733666705
Validation loss: 2.4904561062500687

Epoch: 5| Step: 9
Training loss: 2.6475724239367344
Validation loss: 2.5043114241611426

Epoch: 5| Step: 10
Training loss: 2.429930058481381
Validation loss: 2.5014471157323688

Epoch: 5| Step: 11
Training loss: 2.3949876260139145
Validation loss: 2.506908764912556

Epoch: 252| Step: 0
Training loss: 2.945384057589791
Validation loss: 2.5147127981498705

Epoch: 5| Step: 1
Training loss: 2.5904387514096308
Validation loss: 2.5070977603676248

Epoch: 5| Step: 2
Training loss: 2.501798840901909
Validation loss: 2.5336410351799956

Epoch: 5| Step: 3
Training loss: 1.6758508200976374
Validation loss: 2.53906100737699

Epoch: 5| Step: 4
Training loss: 2.562405468197269
Validation loss: 2.525459589536518

Epoch: 5| Step: 5
Training loss: 2.025370142510342
Validation loss: 2.551940763474616

Epoch: 5| Step: 6
Training loss: 2.5367698295391925
Validation loss: 2.532639647917417

Epoch: 5| Step: 7
Training loss: 2.4776382757221618
Validation loss: 2.5284921433755008

Epoch: 5| Step: 8
Training loss: 2.0328788681983325
Validation loss: 2.523651102196241

Epoch: 5| Step: 9
Training loss: 2.1688973852201365
Validation loss: 2.5139268865810585

Epoch: 5| Step: 10
Training loss: 1.8606004283180797
Validation loss: 2.503117171682879

Epoch: 5| Step: 11
Training loss: 2.2751929987272552
Validation loss: 2.492143353556523

Epoch: 253| Step: 0
Training loss: 2.257732033533143
Validation loss: 2.492778034460519

Epoch: 5| Step: 1
Training loss: 2.1292953835515207
Validation loss: 2.498661620787727

Epoch: 5| Step: 2
Training loss: 2.431342735581261
Validation loss: 2.4972263208378513

Epoch: 5| Step: 3
Training loss: 2.778196394424565
Validation loss: 2.4986918404435543

Epoch: 5| Step: 4
Training loss: 2.005373293213884
Validation loss: 2.4977364405618836

Epoch: 5| Step: 5
Training loss: 2.41555828678445
Validation loss: 2.5005294835145553

Epoch: 5| Step: 6
Training loss: 1.7984194545022791
Validation loss: 2.5002919900767564

Epoch: 5| Step: 7
Training loss: 2.1866476305660245
Validation loss: 2.5032140773904534

Epoch: 5| Step: 8
Training loss: 3.1312771124056225
Validation loss: 2.5013487594885584

Epoch: 5| Step: 9
Training loss: 2.17446339005707
Validation loss: 2.504340925093548

Epoch: 5| Step: 10
Training loss: 2.1189828840341276
Validation loss: 2.5202841804239284

Epoch: 5| Step: 11
Training loss: 1.3619764582046021
Validation loss: 2.508057638766167

Epoch: 254| Step: 0
Training loss: 1.7784043721123413
Validation loss: 2.5140815683562017

Epoch: 5| Step: 1
Training loss: 2.0636513704129333
Validation loss: 2.5162480690385407

Epoch: 5| Step: 2
Training loss: 2.643859687856424
Validation loss: 2.5127058131501014

Epoch: 5| Step: 3
Training loss: 2.0019845653018984
Validation loss: 2.521459601507367

Epoch: 5| Step: 4
Training loss: 2.5030314186309783
Validation loss: 2.5156494044666156

Epoch: 5| Step: 5
Training loss: 1.984399209663312
Validation loss: 2.539809327453068

Epoch: 5| Step: 6
Training loss: 3.0438301718177647
Validation loss: 2.519213784101403

Epoch: 5| Step: 7
Training loss: 1.7670833000405575
Validation loss: 2.51885383035404

Epoch: 5| Step: 8
Training loss: 2.598899784588092
Validation loss: 2.514621834722248

Epoch: 5| Step: 9
Training loss: 2.203153353028438
Validation loss: 2.516271535746828

Epoch: 5| Step: 10
Training loss: 2.387829511182718
Validation loss: 2.505751145865833

Epoch: 5| Step: 11
Training loss: 1.1479297994888205
Validation loss: 2.516733782128053

Epoch: 255| Step: 0
Training loss: 2.4879748097337377
Validation loss: 2.5000232298089657

Epoch: 5| Step: 1
Training loss: 2.6471867041147004
Validation loss: 2.5097534931448737

Epoch: 5| Step: 2
Training loss: 1.8837199576652177
Validation loss: 2.5088776240810637

Epoch: 5| Step: 3
Training loss: 2.742425631103343
Validation loss: 2.5008705491060867

Epoch: 5| Step: 4
Training loss: 2.073563926769184
Validation loss: 2.512549146880076

Epoch: 5| Step: 5
Training loss: 2.0942708975915174
Validation loss: 2.52414113677791

Epoch: 5| Step: 6
Training loss: 1.77351910239537
Validation loss: 2.5124227309483778

Epoch: 5| Step: 7
Training loss: 2.1036558255056454
Validation loss: 2.5260227412402987

Epoch: 5| Step: 8
Training loss: 1.9550641618624442
Validation loss: 2.5278643229682127

Epoch: 5| Step: 9
Training loss: 2.551684092738943
Validation loss: 2.542530156765977

Epoch: 5| Step: 10
Training loss: 2.718777798916114
Validation loss: 2.525485708399289

Epoch: 5| Step: 11
Training loss: 1.6278779880344232
Validation loss: 2.5329199568717744

Epoch: 256| Step: 0
Training loss: 1.9981350548341765
Validation loss: 2.5273522008865625

Epoch: 5| Step: 1
Training loss: 2.1562724457830265
Validation loss: 2.5401824281040533

Epoch: 5| Step: 2
Training loss: 2.379305300261618
Validation loss: 2.520963272707607

Epoch: 5| Step: 3
Training loss: 2.1854733479449338
Validation loss: 2.5113556769038423

Epoch: 5| Step: 4
Training loss: 2.3396099909970345
Validation loss: 2.502574667755093

Epoch: 5| Step: 5
Training loss: 2.3570455204901837
Validation loss: 2.4970308911639747

Epoch: 5| Step: 6
Training loss: 2.458127697463778
Validation loss: 2.4916842439811875

Epoch: 5| Step: 7
Training loss: 2.454969939379967
Validation loss: 2.494070005798708

Epoch: 5| Step: 8
Training loss: 2.2009433197806816
Validation loss: 2.496149266460874

Epoch: 5| Step: 9
Training loss: 1.8121186874752295
Validation loss: 2.510927489980207

Epoch: 5| Step: 10
Training loss: 2.358802978696943
Validation loss: 2.5045953834809467

Epoch: 5| Step: 11
Training loss: 3.7224012129403916
Validation loss: 2.51413678047069

Epoch: 257| Step: 0
Training loss: 2.5995631511198485
Validation loss: 2.5413489820671358

Epoch: 5| Step: 1
Training loss: 2.1434550268688803
Validation loss: 2.5525370888626138

Epoch: 5| Step: 2
Training loss: 2.2419803536989504
Validation loss: 2.570442351024684

Epoch: 5| Step: 3
Training loss: 2.3162421800426842
Validation loss: 2.5856167382088397

Epoch: 5| Step: 4
Training loss: 2.7223874893970432
Validation loss: 2.579941192697255

Epoch: 5| Step: 5
Training loss: 1.6263860513365753
Validation loss: 2.551440420070483

Epoch: 5| Step: 6
Training loss: 2.300040626167078
Validation loss: 2.552161759838796

Epoch: 5| Step: 7
Training loss: 2.674682391554354
Validation loss: 2.5517511787430514

Epoch: 5| Step: 8
Training loss: 2.447949434967403
Validation loss: 2.545274953485225

Epoch: 5| Step: 9
Training loss: 2.194965593072691
Validation loss: 2.5355112055568063

Epoch: 5| Step: 10
Training loss: 2.121465098996391
Validation loss: 2.5426775857914836

Epoch: 5| Step: 11
Training loss: 2.026429310041727
Validation loss: 2.529210096758316

Epoch: 258| Step: 0
Training loss: 2.029545347479175
Validation loss: 2.5011515945262937

Epoch: 5| Step: 1
Training loss: 2.7018133961460022
Validation loss: 2.502448111176231

Epoch: 5| Step: 2
Training loss: 2.875615924703981
Validation loss: 2.507076931960526

Epoch: 5| Step: 3
Training loss: 2.3729380641527356
Validation loss: 2.496306138213658

Epoch: 5| Step: 4
Training loss: 2.3018626341745256
Validation loss: 2.4913655861994783

Epoch: 5| Step: 5
Training loss: 2.631179348321016
Validation loss: 2.484861350288323

Epoch: 5| Step: 6
Training loss: 1.8367653137042177
Validation loss: 2.4948106790241567

Epoch: 5| Step: 7
Training loss: 2.3778300238996466
Validation loss: 2.4894724479359143

Epoch: 5| Step: 8
Training loss: 1.8338329183583857
Validation loss: 2.510570950073901

Epoch: 5| Step: 9
Training loss: 2.253311687041977
Validation loss: 2.528208557621621

Epoch: 5| Step: 10
Training loss: 2.175118090175169
Validation loss: 2.5316209678237946

Epoch: 5| Step: 11
Training loss: 2.781570416113416
Validation loss: 2.535788736859049

Epoch: 259| Step: 0
Training loss: 1.519821335431267
Validation loss: 2.522565110207183

Epoch: 5| Step: 1
Training loss: 1.5424754452721696
Validation loss: 2.5285263026724283

Epoch: 5| Step: 2
Training loss: 2.3652608855799073
Validation loss: 2.513203019701436

Epoch: 5| Step: 3
Training loss: 2.9960609643129565
Validation loss: 2.518378991315451

Epoch: 5| Step: 4
Training loss: 1.9160197313363871
Validation loss: 2.4992257985743755

Epoch: 5| Step: 5
Training loss: 2.096999081438161
Validation loss: 2.4924006515441266

Epoch: 5| Step: 6
Training loss: 2.1312807052951013
Validation loss: 2.5003614442530293

Epoch: 5| Step: 7
Training loss: 2.2674647786728626
Validation loss: 2.4921797270937636

Epoch: 5| Step: 8
Training loss: 3.2407086412162105
Validation loss: 2.482752212006915

Epoch: 5| Step: 9
Training loss: 2.749021009101947
Validation loss: 2.486601881132701

Epoch: 5| Step: 10
Training loss: 2.137677467519167
Validation loss: 2.4919295740542005

Epoch: 5| Step: 11
Training loss: 1.5805594674218248
Validation loss: 2.497336753223299

Epoch: 260| Step: 0
Training loss: 2.235243301803098
Validation loss: 2.5190001211301385

Epoch: 5| Step: 1
Training loss: 2.2826836666487242
Validation loss: 2.531277456252399

Epoch: 5| Step: 2
Training loss: 1.7335982774328977
Validation loss: 2.539834285715713

Epoch: 5| Step: 3
Training loss: 2.3999454094718122
Validation loss: 2.545607787899124

Epoch: 5| Step: 4
Training loss: 2.6613420932615415
Validation loss: 2.5554968420024227

Epoch: 5| Step: 5
Training loss: 2.270266389214452
Validation loss: 2.5461575954563904

Epoch: 5| Step: 6
Training loss: 2.1845041741636653
Validation loss: 2.543896577628198

Epoch: 5| Step: 7
Training loss: 2.3954028088291603
Validation loss: 2.5399982312714435

Epoch: 5| Step: 8
Training loss: 2.4955865049080153
Validation loss: 2.5631751551166855

Epoch: 5| Step: 9
Training loss: 2.1788828468638846
Validation loss: 2.5316897822620823

Epoch: 5| Step: 10
Training loss: 2.5151473829946456
Validation loss: 2.5367303711523457

Epoch: 5| Step: 11
Training loss: 1.1823532099677458
Validation loss: 2.543587046440854

Epoch: 261| Step: 0
Training loss: 1.95893666598186
Validation loss: 2.5376171771682223

Epoch: 5| Step: 1
Training loss: 2.6873490934364845
Validation loss: 2.5338708668570447

Epoch: 5| Step: 2
Training loss: 1.9267536053077483
Validation loss: 2.5490548920877387

Epoch: 5| Step: 3
Training loss: 2.3528959732762456
Validation loss: 2.5412023164435156

Epoch: 5| Step: 4
Training loss: 2.3984762679455365
Validation loss: 2.5661768856741576

Epoch: 5| Step: 5
Training loss: 1.8180843354231562
Validation loss: 2.5520636395583347

Epoch: 5| Step: 6
Training loss: 2.659354964471062
Validation loss: 2.58978071179202

Epoch: 5| Step: 7
Training loss: 2.247117209079841
Validation loss: 2.6019179948047246

Epoch: 5| Step: 8
Training loss: 2.2509672417106374
Validation loss: 2.6084245865878732

Epoch: 5| Step: 9
Training loss: 2.261783473747365
Validation loss: 2.583619487716152

Epoch: 5| Step: 10
Training loss: 2.4476521666998337
Validation loss: 2.5837187723032993

Epoch: 5| Step: 11
Training loss: 2.5797855462539214
Validation loss: 2.5754648182598316

Epoch: 262| Step: 0
Training loss: 2.6523922001454334
Validation loss: 2.5544989746712914

Epoch: 5| Step: 1
Training loss: 2.4414346678033594
Validation loss: 2.5722568041612313

Epoch: 5| Step: 2
Training loss: 2.0897841970924844
Validation loss: 2.577613066892172

Epoch: 5| Step: 3
Training loss: 2.339949922270327
Validation loss: 2.5810007336746152

Epoch: 5| Step: 4
Training loss: 2.0665707730021396
Validation loss: 2.571253734654527

Epoch: 5| Step: 5
Training loss: 1.7948449650704976
Validation loss: 2.5729657077105306

Epoch: 5| Step: 6
Training loss: 2.054907261224673
Validation loss: 2.5778270048295346

Epoch: 5| Step: 7
Training loss: 2.696415948973591
Validation loss: 2.5705038461315697

Epoch: 5| Step: 8
Training loss: 1.8237522353746234
Validation loss: 2.5552928491220674

Epoch: 5| Step: 9
Training loss: 2.8171644737754034
Validation loss: 2.5623275787992665

Epoch: 5| Step: 10
Training loss: 2.1964495012125713
Validation loss: 2.5637426580952916

Epoch: 5| Step: 11
Training loss: 1.1266546796315275
Validation loss: 2.5469389090291403

Epoch: 263| Step: 0
Training loss: 2.348241342764757
Validation loss: 2.5469093047408005

Epoch: 5| Step: 1
Training loss: 2.3360197633273057
Validation loss: 2.524153187674746

Epoch: 5| Step: 2
Training loss: 2.165276142332079
Validation loss: 2.5086778987590326

Epoch: 5| Step: 3
Training loss: 2.477841308826555
Validation loss: 2.511236572653794

Epoch: 5| Step: 4
Training loss: 2.6653957219145967
Validation loss: 2.519587596489961

Epoch: 5| Step: 5
Training loss: 1.7888492640390707
Validation loss: 2.512545329486871

Epoch: 5| Step: 6
Training loss: 2.6145212741087676
Validation loss: 2.528119405968964

Epoch: 5| Step: 7
Training loss: 1.7416619162365439
Validation loss: 2.5046167977250438

Epoch: 5| Step: 8
Training loss: 1.7102875193425724
Validation loss: 2.5340245154666947

Epoch: 5| Step: 9
Training loss: 2.5290240637741914
Validation loss: 2.5199007576557437

Epoch: 5| Step: 10
Training loss: 2.453733915333588
Validation loss: 2.543992566470966

Epoch: 5| Step: 11
Training loss: 2.0486130651547296
Validation loss: 2.5347418110814868

Epoch: 264| Step: 0
Training loss: 2.4099587926863584
Validation loss: 2.548932588075968

Epoch: 5| Step: 1
Training loss: 2.2112150523527703
Validation loss: 2.5640862254010397

Epoch: 5| Step: 2
Training loss: 2.4326763842656844
Validation loss: 2.5580594230440172

Epoch: 5| Step: 3
Training loss: 1.9879307166217173
Validation loss: 2.5591364433017696

Epoch: 5| Step: 4
Training loss: 2.2287779377006256
Validation loss: 2.5574704953900342

Epoch: 5| Step: 5
Training loss: 2.1327008228617546
Validation loss: 2.555087203119672

Epoch: 5| Step: 6
Training loss: 2.9361916733003652
Validation loss: 2.55588961286079

Epoch: 5| Step: 7
Training loss: 1.846453737085834
Validation loss: 2.5497601866932698

Epoch: 5| Step: 8
Training loss: 2.4862684795600036
Validation loss: 2.5434809304223593

Epoch: 5| Step: 9
Training loss: 2.0205738910473254
Validation loss: 2.5333711229714

Epoch: 5| Step: 10
Training loss: 2.2765418811668154
Validation loss: 2.5325121185888944

Epoch: 5| Step: 11
Training loss: 1.5800098456305356
Validation loss: 2.522500392651031

Epoch: 265| Step: 0
Training loss: 1.873309772327453
Validation loss: 2.5365428375225227

Epoch: 5| Step: 1
Training loss: 2.872946129957401
Validation loss: 2.517444706694406

Epoch: 5| Step: 2
Training loss: 2.2323185987771845
Validation loss: 2.497174748780522

Epoch: 5| Step: 3
Training loss: 2.421398288201464
Validation loss: 2.5047545124433017

Epoch: 5| Step: 4
Training loss: 1.9783162414768003
Validation loss: 2.507022432157424

Epoch: 5| Step: 5
Training loss: 2.184385534869591
Validation loss: 2.509243146093366

Epoch: 5| Step: 6
Training loss: 1.751239337766157
Validation loss: 2.5138356398258033

Epoch: 5| Step: 7
Training loss: 2.3677225546878975
Validation loss: 2.504986340104179

Epoch: 5| Step: 8
Training loss: 2.407868868733028
Validation loss: 2.520920516836798

Epoch: 5| Step: 9
Training loss: 2.6093102178698175
Validation loss: 2.525619830798289

Epoch: 5| Step: 10
Training loss: 2.0697916779296546
Validation loss: 2.527909346767391

Epoch: 5| Step: 11
Training loss: 1.525633417752495
Validation loss: 2.541769761720168

Epoch: 266| Step: 0
Training loss: 2.119919481727735
Validation loss: 2.5257250059712906

Epoch: 5| Step: 1
Training loss: 3.0073717463188085
Validation loss: 2.535057065930882

Epoch: 5| Step: 2
Training loss: 2.002995155637142
Validation loss: 2.534156664950165

Epoch: 5| Step: 3
Training loss: 2.480584281573743
Validation loss: 2.515060341688149

Epoch: 5| Step: 4
Training loss: 2.1823497633988755
Validation loss: 2.5031026819371602

Epoch: 5| Step: 5
Training loss: 2.277015099603967
Validation loss: 2.5178303618103492

Epoch: 5| Step: 6
Training loss: 1.7598761080354932
Validation loss: 2.5057644864494266

Epoch: 5| Step: 7
Training loss: 1.6568312434775616
Validation loss: 2.5113048835423006

Epoch: 5| Step: 8
Training loss: 2.5952230659706297
Validation loss: 2.4913062587452606

Epoch: 5| Step: 9
Training loss: 1.6298046241871602
Validation loss: 2.501672169626153

Epoch: 5| Step: 10
Training loss: 2.5729625455855993
Validation loss: 2.4922934084145894

Epoch: 5| Step: 11
Training loss: 2.7315899425699612
Validation loss: 2.5098489987469015

Epoch: 267| Step: 0
Training loss: 1.854522656616799
Validation loss: 2.510523529996743

Epoch: 5| Step: 1
Training loss: 1.7417304974894967
Validation loss: 2.522682041427407

Epoch: 5| Step: 2
Training loss: 2.509421049576742
Validation loss: 2.529634124777102

Epoch: 5| Step: 3
Training loss: 1.8115342296679875
Validation loss: 2.527586404981815

Epoch: 5| Step: 4
Training loss: 2.026954451799648
Validation loss: 2.5403444936881163

Epoch: 5| Step: 5
Training loss: 2.6629243360335453
Validation loss: 2.5425107067799195

Epoch: 5| Step: 6
Training loss: 2.5059242626658302
Validation loss: 2.544694114987833

Epoch: 5| Step: 7
Training loss: 1.684567269585114
Validation loss: 2.531123056093529

Epoch: 5| Step: 8
Training loss: 2.2269254689756814
Validation loss: 2.532266950205531

Epoch: 5| Step: 9
Training loss: 2.993872106048942
Validation loss: 2.542339502974645

Epoch: 5| Step: 10
Training loss: 2.3303880381506668
Validation loss: 2.514013267716262

Epoch: 5| Step: 11
Training loss: 1.3200772318498646
Validation loss: 2.511406400015167

Epoch: 268| Step: 0
Training loss: 2.7664498860866797
Validation loss: 2.508465195724664

Epoch: 5| Step: 1
Training loss: 2.02960102933738
Validation loss: 2.4991851968948544

Epoch: 5| Step: 2
Training loss: 2.689802558488244
Validation loss: 2.51289118430702

Epoch: 5| Step: 3
Training loss: 1.6861727404586677
Validation loss: 2.502147106201764

Epoch: 5| Step: 4
Training loss: 1.896357271785092
Validation loss: 2.5094726153967994

Epoch: 5| Step: 5
Training loss: 1.8811818259423674
Validation loss: 2.516791663528834

Epoch: 5| Step: 6
Training loss: 1.940124026885992
Validation loss: 2.5341238732338036

Epoch: 5| Step: 7
Training loss: 2.2051877584985666
Validation loss: 2.529742863634186

Epoch: 5| Step: 8
Training loss: 2.994398291363281
Validation loss: 2.5131892620561564

Epoch: 5| Step: 9
Training loss: 2.0467592162952988
Validation loss: 2.52396055928089

Epoch: 5| Step: 10
Training loss: 2.209027007456367
Validation loss: 2.5322615639076718

Epoch: 5| Step: 11
Training loss: 1.4578100991510408
Validation loss: 2.5374122440810702

Epoch: 269| Step: 0
Training loss: 2.0862792231648375
Validation loss: 2.5336231676578396

Epoch: 5| Step: 1
Training loss: 2.4099627499056115
Validation loss: 2.515706639515101

Epoch: 5| Step: 2
Training loss: 2.686938826057334
Validation loss: 2.5420066666016696

Epoch: 5| Step: 3
Training loss: 2.4845248962862323
Validation loss: 2.5198465746326817

Epoch: 5| Step: 4
Training loss: 2.6017462404908835
Validation loss: 2.5132394738362205

Epoch: 5| Step: 5
Training loss: 1.8200858306557908
Validation loss: 2.5069907397829683

Epoch: 5| Step: 6
Training loss: 2.339401279702382
Validation loss: 2.4948162417439135

Epoch: 5| Step: 7
Training loss: 1.9379893884634025
Validation loss: 2.4792868934992582

Epoch: 5| Step: 8
Training loss: 2.1292352544657587
Validation loss: 2.469576037510761

Epoch: 5| Step: 9
Training loss: 1.9363898511586364
Validation loss: 2.4886988474559253

Epoch: 5| Step: 10
Training loss: 2.3778241081220157
Validation loss: 2.4756794667931525

Epoch: 5| Step: 11
Training loss: 1.6182777305005644
Validation loss: 2.4767275854497854

Epoch: 270| Step: 0
Training loss: 2.4159614476734284
Validation loss: 2.480390652606061

Epoch: 5| Step: 1
Training loss: 2.1838416980691027
Validation loss: 2.5101781285924702

Epoch: 5| Step: 2
Training loss: 2.534136127545904
Validation loss: 2.506657909991394

Epoch: 5| Step: 3
Training loss: 2.2717738405817305
Validation loss: 2.5230859643491312

Epoch: 5| Step: 4
Training loss: 1.8524684058003595
Validation loss: 2.545129829472726

Epoch: 5| Step: 5
Training loss: 2.3615515566142355
Validation loss: 2.5326329640840233

Epoch: 5| Step: 6
Training loss: 2.0876118658552687
Validation loss: 2.530110322402761

Epoch: 5| Step: 7
Training loss: 2.337725513208033
Validation loss: 2.542817981975501

Epoch: 5| Step: 8
Training loss: 1.8915448433836428
Validation loss: 2.542094418744803

Epoch: 5| Step: 9
Training loss: 1.8054090106213978
Validation loss: 2.5327162087155326

Epoch: 5| Step: 10
Training loss: 2.6426575191325368
Validation loss: 2.5409419219860916

Epoch: 5| Step: 11
Training loss: 2.833101225676845
Validation loss: 2.5164712386852157

Epoch: 271| Step: 0
Training loss: 2.1582906161564672
Validation loss: 2.5195277369275106

Epoch: 5| Step: 1
Training loss: 2.4600090091819475
Validation loss: 2.4994344508712807

Epoch: 5| Step: 2
Training loss: 2.7420777736349122
Validation loss: 2.50036608479281

Epoch: 5| Step: 3
Training loss: 2.504224831344105
Validation loss: 2.5098820838675633

Epoch: 5| Step: 4
Training loss: 1.5779590330571684
Validation loss: 2.515161716458164

Epoch: 5| Step: 5
Training loss: 1.806366506864762
Validation loss: 2.5313516525767397

Epoch: 5| Step: 6
Training loss: 2.244794439917413
Validation loss: 2.511502056355653

Epoch: 5| Step: 7
Training loss: 2.30393509301842
Validation loss: 2.531649212694389

Epoch: 5| Step: 8
Training loss: 2.232165010614815
Validation loss: 2.516334409970304

Epoch: 5| Step: 9
Training loss: 2.3611152748619717
Validation loss: 2.5203122764314543

Epoch: 5| Step: 10
Training loss: 1.9407806309507922
Validation loss: 2.540417639202599

Epoch: 5| Step: 11
Training loss: 1.949023647902772
Validation loss: 2.528216235475748

Epoch: 272| Step: 0
Training loss: 1.4652661337648456
Validation loss: 2.53283746414072

Epoch: 5| Step: 1
Training loss: 2.5329608551386165
Validation loss: 2.518881185095466

Epoch: 5| Step: 2
Training loss: 1.9330724764921097
Validation loss: 2.515617429828508

Epoch: 5| Step: 3
Training loss: 2.2303389797105964
Validation loss: 2.5277292565840366

Epoch: 5| Step: 4
Training loss: 2.479299963778947
Validation loss: 2.51064823132606

Epoch: 5| Step: 5
Training loss: 1.4439890808051905
Validation loss: 2.5312938254687203

Epoch: 5| Step: 6
Training loss: 2.0350251549143152
Validation loss: 2.524562057593925

Epoch: 5| Step: 7
Training loss: 2.303705452350136
Validation loss: 2.517572975597339

Epoch: 5| Step: 8
Training loss: 2.5738037886332386
Validation loss: 2.540784801385819

Epoch: 5| Step: 9
Training loss: 2.210630469688873
Validation loss: 2.542991438850876

Epoch: 5| Step: 10
Training loss: 2.632298631637491
Validation loss: 2.5308085869098558

Epoch: 5| Step: 11
Training loss: 2.952948186516068
Validation loss: 2.5278467132847395

Epoch: 273| Step: 0
Training loss: 1.8641686715445085
Validation loss: 2.5531222674550906

Epoch: 5| Step: 1
Training loss: 1.9741300308587586
Validation loss: 2.534924022851451

Epoch: 5| Step: 2
Training loss: 2.230097591163508
Validation loss: 2.5328044004034287

Epoch: 5| Step: 3
Training loss: 2.1319164587690604
Validation loss: 2.535253757037796

Epoch: 5| Step: 4
Training loss: 1.5833994282763721
Validation loss: 2.536972523816775

Epoch: 5| Step: 5
Training loss: 2.5345559842249314
Validation loss: 2.5105611843969338

Epoch: 5| Step: 6
Training loss: 2.281485767461394
Validation loss: 2.5333297176293454

Epoch: 5| Step: 7
Training loss: 2.1318389571024765
Validation loss: 2.5269428035367842

Epoch: 5| Step: 8
Training loss: 2.361683707524614
Validation loss: 2.516146256363826

Epoch: 5| Step: 9
Training loss: 2.2087624570779165
Validation loss: 2.520287026302022

Epoch: 5| Step: 10
Training loss: 2.8814709030501264
Validation loss: 2.5104898122892134

Epoch: 5| Step: 11
Training loss: 2.0742630028898144
Validation loss: 2.5096277854660642

Epoch: 274| Step: 0
Training loss: 2.439359493611941
Validation loss: 2.518258582137

Epoch: 5| Step: 1
Training loss: 2.339952367640142
Validation loss: 2.51019976432056

Epoch: 5| Step: 2
Training loss: 2.071034546663899
Validation loss: 2.4978016088445463

Epoch: 5| Step: 3
Training loss: 2.1081056519657295
Validation loss: 2.496683881763531

Epoch: 5| Step: 4
Training loss: 1.5527468123027834
Validation loss: 2.504187280016798

Epoch: 5| Step: 5
Training loss: 2.5243696729051788
Validation loss: 2.5106871737498415

Epoch: 5| Step: 6
Training loss: 2.5198216470546257
Validation loss: 2.517845480932781

Epoch: 5| Step: 7
Training loss: 2.6726587049645256
Validation loss: 2.5159079074726307

Epoch: 5| Step: 8
Training loss: 1.565724060214045
Validation loss: 2.534302644680614

Epoch: 5| Step: 9
Training loss: 1.9622169970904477
Validation loss: 2.508265639550231

Epoch: 5| Step: 10
Training loss: 2.5466365585577884
Validation loss: 2.55576460216256

Epoch: 5| Step: 11
Training loss: 2.1095785537274794
Validation loss: 2.5483213386124453

Epoch: 275| Step: 0
Training loss: 2.2937558332571752
Validation loss: 2.575024626746822

Epoch: 5| Step: 1
Training loss: 2.3281141447287825
Validation loss: 2.563564110608199

Epoch: 5| Step: 2
Training loss: 2.2816372895375596
Validation loss: 2.554902844389003

Epoch: 5| Step: 3
Training loss: 2.4100628653910086
Validation loss: 2.5737585911631338

Epoch: 5| Step: 4
Training loss: 1.7240404030740941
Validation loss: 2.5664704468167163

Epoch: 5| Step: 5
Training loss: 2.2350156705848865
Validation loss: 2.5644393614501078

Epoch: 5| Step: 6
Training loss: 2.414433818024651
Validation loss: 2.546262156389295

Epoch: 5| Step: 7
Training loss: 2.3386942948884637
Validation loss: 2.5357202922243327

Epoch: 5| Step: 8
Training loss: 1.8253766781588225
Validation loss: 2.514380334678893

Epoch: 5| Step: 9
Training loss: 2.2965428118628117
Validation loss: 2.5077917112001793

Epoch: 5| Step: 10
Training loss: 1.9617306750325145
Validation loss: 2.5086791164272335

Epoch: 5| Step: 11
Training loss: 4.3481181842706125
Validation loss: 2.507461364818638

Epoch: 276| Step: 0
Training loss: 2.447226363443293
Validation loss: 2.51015150218348

Epoch: 5| Step: 1
Training loss: 2.2889717787123227
Validation loss: 2.4934284664197106

Epoch: 5| Step: 2
Training loss: 2.3901565192457417
Validation loss: 2.4992509156765026

Epoch: 5| Step: 3
Training loss: 2.4072615243721263
Validation loss: 2.5064127135948002

Epoch: 5| Step: 4
Training loss: 2.535314240550832
Validation loss: 2.5047038450003254

Epoch: 5| Step: 5
Training loss: 1.7709046143789788
Validation loss: 2.5114911472155166

Epoch: 5| Step: 6
Training loss: 2.619747629168399
Validation loss: 2.5268413824650144

Epoch: 5| Step: 7
Training loss: 1.6971039338347986
Validation loss: 2.533799100606176

Epoch: 5| Step: 8
Training loss: 2.307926604407997
Validation loss: 2.5164700524209143

Epoch: 5| Step: 9
Training loss: 1.8985784658834444
Validation loss: 2.507852773848057

Epoch: 5| Step: 10
Training loss: 2.2207926628964505
Validation loss: 2.5345655085108136

Epoch: 5| Step: 11
Training loss: 2.7953278935084813
Validation loss: 2.5294817057941645

Epoch: 277| Step: 0
Training loss: 1.7956861460731313
Validation loss: 2.5390299555331173

Epoch: 5| Step: 1
Training loss: 2.659697326419693
Validation loss: 2.529031417054218

Epoch: 5| Step: 2
Training loss: 2.087209135338357
Validation loss: 2.5260175362971453

Epoch: 5| Step: 3
Training loss: 2.1769999681296675
Validation loss: 2.5336174940952607

Epoch: 5| Step: 4
Training loss: 1.8888078263908694
Validation loss: 2.5128806864081716

Epoch: 5| Step: 5
Training loss: 2.371087113548682
Validation loss: 2.5369094738556677

Epoch: 5| Step: 6
Training loss: 1.5285750399242568
Validation loss: 2.529300111353705

Epoch: 5| Step: 7
Training loss: 2.1518096538087113
Validation loss: 2.5130908238179708

Epoch: 5| Step: 8
Training loss: 1.8486965226904637
Validation loss: 2.5316021089587037

Epoch: 5| Step: 9
Training loss: 2.9030522627901005
Validation loss: 2.514830623804578

Epoch: 5| Step: 10
Training loss: 2.45196680803843
Validation loss: 2.5073854869177774

Epoch: 5| Step: 11
Training loss: 2.913389562883273
Validation loss: 2.497316084070084

Epoch: 278| Step: 0
Training loss: 2.384439382021364
Validation loss: 2.5225734195793135

Epoch: 5| Step: 1
Training loss: 2.30119322632685
Validation loss: 2.5096262060644703

Epoch: 5| Step: 2
Training loss: 1.7126304576773732
Validation loss: 2.5185736637847675

Epoch: 5| Step: 3
Training loss: 2.0001929905284466
Validation loss: 2.5161171860124485

Epoch: 5| Step: 4
Training loss: 2.339170636140966
Validation loss: 2.5369437508462793

Epoch: 5| Step: 5
Training loss: 2.168002401554706
Validation loss: 2.5241914534167766

Epoch: 5| Step: 6
Training loss: 1.9826976866130788
Validation loss: 2.536038375073518

Epoch: 5| Step: 7
Training loss: 1.7765554838956252
Validation loss: 2.522311161018754

Epoch: 5| Step: 8
Training loss: 2.0688390706874307
Validation loss: 2.520349138170559

Epoch: 5| Step: 9
Training loss: 3.1196543939838643
Validation loss: 2.513711181586234

Epoch: 5| Step: 10
Training loss: 2.2451032760076286
Validation loss: 2.5121406489561826

Epoch: 5| Step: 11
Training loss: 3.2936795192756385
Validation loss: 2.522543887710251

Epoch: 279| Step: 0
Training loss: 2.333234364817596
Validation loss: 2.507910388846356

Epoch: 5| Step: 1
Training loss: 1.9081148500044476
Validation loss: 2.521412382272645

Epoch: 5| Step: 2
Training loss: 2.057532831534952
Validation loss: 2.5214195568165945

Epoch: 5| Step: 3
Training loss: 2.572635331519163
Validation loss: 2.531551586441998

Epoch: 5| Step: 4
Training loss: 2.3524182559008935
Validation loss: 2.519879788680167

Epoch: 5| Step: 5
Training loss: 2.1834044127020396
Validation loss: 2.504826004345875

Epoch: 5| Step: 6
Training loss: 2.1402180974111222
Validation loss: 2.508255866878019

Epoch: 5| Step: 7
Training loss: 2.291821168257451
Validation loss: 2.5179060946031173

Epoch: 5| Step: 8
Training loss: 2.4641534047118747
Validation loss: 2.503046039759875

Epoch: 5| Step: 9
Training loss: 1.9810175088400432
Validation loss: 2.5126895640080513

Epoch: 5| Step: 10
Training loss: 2.490375589592861
Validation loss: 2.4837929465669046

Epoch: 5| Step: 11
Training loss: 2.583383826305831
Validation loss: 2.491405675343124

Epoch: 280| Step: 0
Training loss: 2.4512665141403835
Validation loss: 2.484369133996336

Epoch: 5| Step: 1
Training loss: 2.3494614247761616
Validation loss: 2.516018420113583

Epoch: 5| Step: 2
Training loss: 1.8583467349038192
Validation loss: 2.530738245090788

Epoch: 5| Step: 3
Training loss: 1.8573344598170194
Validation loss: 2.5442920450961686

Epoch: 5| Step: 4
Training loss: 2.348713413053043
Validation loss: 2.5586659700329943

Epoch: 5| Step: 5
Training loss: 2.5684762442219644
Validation loss: 2.5437310907784236

Epoch: 5| Step: 6
Training loss: 1.5219967803169112
Validation loss: 2.5246386488985473

Epoch: 5| Step: 7
Training loss: 1.9904416681063304
Validation loss: 2.499055870912031

Epoch: 5| Step: 8
Training loss: 2.6752021107124597
Validation loss: 2.479719650614586

Epoch: 5| Step: 9
Training loss: 2.04606297816864
Validation loss: 2.4550391745177196

Epoch: 5| Step: 10
Training loss: 2.7248753790400815
Validation loss: 2.465531238695818

Epoch: 5| Step: 11
Training loss: 2.4506652551646244
Validation loss: 2.468990338372647

Epoch: 281| Step: 0
Training loss: 1.9410212728011702
Validation loss: 2.4794504954180923

Epoch: 5| Step: 1
Training loss: 2.6219761098068664
Validation loss: 2.4848849574911593

Epoch: 5| Step: 2
Training loss: 3.1939787004557254
Validation loss: 2.529098094458896

Epoch: 5| Step: 3
Training loss: 1.7550344937621722
Validation loss: 2.571501119822694

Epoch: 5| Step: 4
Training loss: 2.052429699268814
Validation loss: 2.589556057132401

Epoch: 5| Step: 5
Training loss: 2.235897159279147
Validation loss: 2.581567506220791

Epoch: 5| Step: 6
Training loss: 2.113764737538599
Validation loss: 2.5630338469398897

Epoch: 5| Step: 7
Training loss: 1.5592595640583065
Validation loss: 2.54090330250471

Epoch: 5| Step: 8
Training loss: 2.054418509973938
Validation loss: 2.5159639797507958

Epoch: 5| Step: 9
Training loss: 2.3030408246044884
Validation loss: 2.4891453714218614

Epoch: 5| Step: 10
Training loss: 2.4617255992545943
Validation loss: 2.477881163746935

Epoch: 5| Step: 11
Training loss: 2.174429948139336
Validation loss: 2.4682088572711747

Epoch: 282| Step: 0
Training loss: 2.1202689968248096
Validation loss: 2.4771176106161668

Epoch: 5| Step: 1
Training loss: 2.1958423124512203
Validation loss: 2.47518557710132

Epoch: 5| Step: 2
Training loss: 2.075667685207944
Validation loss: 2.474260887250523

Epoch: 5| Step: 3
Training loss: 2.6123463051591407
Validation loss: 2.48036261704434

Epoch: 5| Step: 4
Training loss: 2.6835686961507896
Validation loss: 2.503459979918151

Epoch: 5| Step: 5
Training loss: 2.1448440740505466
Validation loss: 2.516199034597783

Epoch: 5| Step: 6
Training loss: 1.9107918959110566
Validation loss: 2.5359508481930884

Epoch: 5| Step: 7
Training loss: 2.190150371945588
Validation loss: 2.5465054624234136

Epoch: 5| Step: 8
Training loss: 2.113715671867388
Validation loss: 2.553579998367187

Epoch: 5| Step: 9
Training loss: 2.584048777128746
Validation loss: 2.5576974167486863

Epoch: 5| Step: 10
Training loss: 1.8754841497326598
Validation loss: 2.5538077088711715

Epoch: 5| Step: 11
Training loss: 1.9197856431750309
Validation loss: 2.5374916303587436

Epoch: 283| Step: 0
Training loss: 1.7917696531401408
Validation loss: 2.527631135035917

Epoch: 5| Step: 1
Training loss: 2.0961741747304505
Validation loss: 2.5117499911677625

Epoch: 5| Step: 2
Training loss: 2.6938789425323186
Validation loss: 2.5173134952002743

Epoch: 5| Step: 3
Training loss: 1.7591942675708323
Validation loss: 2.5248588125961247

Epoch: 5| Step: 4
Training loss: 2.133880124451363
Validation loss: 2.5206630757006203

Epoch: 5| Step: 5
Training loss: 1.7432068720671168
Validation loss: 2.5076477060016553

Epoch: 5| Step: 6
Training loss: 1.9593479963811562
Validation loss: 2.515087935178803

Epoch: 5| Step: 7
Training loss: 2.037979013501527
Validation loss: 2.509457841695762

Epoch: 5| Step: 8
Training loss: 2.7968204429036465
Validation loss: 2.5239728944247948

Epoch: 5| Step: 9
Training loss: 2.465845838357979
Validation loss: 2.504238695757969

Epoch: 5| Step: 10
Training loss: 2.451850900407606
Validation loss: 2.5126344110269536

Epoch: 5| Step: 11
Training loss: 1.7169515737504084
Validation loss: 2.5114984292102567

Epoch: 284| Step: 0
Training loss: 1.8292556266036022
Validation loss: 2.5145433086653766

Epoch: 5| Step: 1
Training loss: 2.023150685135238
Validation loss: 2.5173971240803694

Epoch: 5| Step: 2
Training loss: 2.1980450006656307
Validation loss: 2.488175074988463

Epoch: 5| Step: 3
Training loss: 2.268926700825362
Validation loss: 2.514686049886843

Epoch: 5| Step: 4
Training loss: 2.3076394007804653
Validation loss: 2.5332758139889977

Epoch: 5| Step: 5
Training loss: 2.460882567746285
Validation loss: 2.5192460325002335

Epoch: 5| Step: 6
Training loss: 2.354782080317088
Validation loss: 2.5334090965532408

Epoch: 5| Step: 7
Training loss: 1.9098734578060803
Validation loss: 2.5060062855971252

Epoch: 5| Step: 8
Training loss: 2.0688036908791667
Validation loss: 2.540395838501059

Epoch: 5| Step: 9
Training loss: 2.095647151658153
Validation loss: 2.549287398506397

Epoch: 5| Step: 10
Training loss: 2.3181619150323907
Validation loss: 2.538254841214796

Epoch: 5| Step: 11
Training loss: 2.456700337600638
Validation loss: 2.519766283531648

Epoch: 285| Step: 0
Training loss: 2.1773934272762916
Validation loss: 2.5123046183809152

Epoch: 5| Step: 1
Training loss: 2.4263018112507284
Validation loss: 2.5188734630114147

Epoch: 5| Step: 2
Training loss: 1.7530919416986046
Validation loss: 2.4939212767342274

Epoch: 5| Step: 3
Training loss: 2.153466127609731
Validation loss: 2.482361735514109

Epoch: 5| Step: 4
Training loss: 2.361541864583377
Validation loss: 2.4873381883142196

Epoch: 5| Step: 5
Training loss: 2.395763484655353
Validation loss: 2.499222213235522

Epoch: 5| Step: 6
Training loss: 2.233323603461787
Validation loss: 2.489627531821798

Epoch: 5| Step: 7
Training loss: 1.8811958938878268
Validation loss: 2.475709064137892

Epoch: 5| Step: 8
Training loss: 2.6283951555849794
Validation loss: 2.491270572273079

Epoch: 5| Step: 9
Training loss: 1.9532789856290558
Validation loss: 2.498609589325396

Epoch: 5| Step: 10
Training loss: 1.9995938723202222
Validation loss: 2.5182287156355465

Epoch: 5| Step: 11
Training loss: 2.2648202453425257
Validation loss: 2.561594570508763

Epoch: 286| Step: 0
Training loss: 2.394599054817173
Validation loss: 2.5892065423690678

Epoch: 5| Step: 1
Training loss: 2.23062929554379
Validation loss: 2.5888247088930023

Epoch: 5| Step: 2
Training loss: 2.5851562795123146
Validation loss: 2.5958690489816814

Epoch: 5| Step: 3
Training loss: 2.6583912913861414
Validation loss: 2.6001291918446543

Epoch: 5| Step: 4
Training loss: 2.316886864861526
Validation loss: 2.5876282718517922

Epoch: 5| Step: 5
Training loss: 2.0261709242304256
Validation loss: 2.543452566973759

Epoch: 5| Step: 6
Training loss: 2.317559969721784
Validation loss: 2.5382805975054787

Epoch: 5| Step: 7
Training loss: 1.6117599740906865
Validation loss: 2.512979285072951

Epoch: 5| Step: 8
Training loss: 2.4048228800182008
Validation loss: 2.4870142043809507

Epoch: 5| Step: 9
Training loss: 2.582526686051372
Validation loss: 2.4799283617963086

Epoch: 5| Step: 10
Training loss: 1.614979069931412
Validation loss: 2.465675602560039

Epoch: 5| Step: 11
Training loss: 1.5331797992851441
Validation loss: 2.4675017673920263

Epoch: 287| Step: 0
Training loss: 2.855862821217658
Validation loss: 2.479432489799057

Epoch: 5| Step: 1
Training loss: 2.1254010663497316
Validation loss: 2.4818560267766854

Epoch: 5| Step: 2
Training loss: 2.298594240073543
Validation loss: 2.4785999617420305

Epoch: 5| Step: 3
Training loss: 2.4554494548140235
Validation loss: 2.4658420916813557

Epoch: 5| Step: 4
Training loss: 2.3650644179879987
Validation loss: 2.4793660874395287

Epoch: 5| Step: 5
Training loss: 2.557947814009417
Validation loss: 2.463555972411951

Epoch: 5| Step: 6
Training loss: 2.012240266328754
Validation loss: 2.5038704435631973

Epoch: 5| Step: 7
Training loss: 2.3743552286399816
Validation loss: 2.487899491485035

Epoch: 5| Step: 8
Training loss: 1.8167467680020848
Validation loss: 2.5251727913757955

Epoch: 5| Step: 9
Training loss: 1.7697930216059028
Validation loss: 2.527364036010897

Epoch: 5| Step: 10
Training loss: 1.6528739349147166
Validation loss: 2.527528291280438

Epoch: 5| Step: 11
Training loss: 2.6724440654614305
Validation loss: 2.5237939620223715

Epoch: 288| Step: 0
Training loss: 2.4516435754424624
Validation loss: 2.546191277810785

Epoch: 5| Step: 1
Training loss: 2.890217355388546
Validation loss: 2.5580691666128845

Epoch: 5| Step: 2
Training loss: 2.2938541606983165
Validation loss: 2.54449166686913

Epoch: 5| Step: 3
Training loss: 1.9057938702290478
Validation loss: 2.5248738148762646

Epoch: 5| Step: 4
Training loss: 2.1785267572937617
Validation loss: 2.5286297599577585

Epoch: 5| Step: 5
Training loss: 2.5853469035910748
Validation loss: 2.4898305208931792

Epoch: 5| Step: 6
Training loss: 2.2608122120634726
Validation loss: 2.4894998781163715

Epoch: 5| Step: 7
Training loss: 2.283862355709437
Validation loss: 2.4946961547205744

Epoch: 5| Step: 8
Training loss: 1.7511747368289896
Validation loss: 2.4959919390861547

Epoch: 5| Step: 9
Training loss: 1.4551863457291334
Validation loss: 2.4823824291361714

Epoch: 5| Step: 10
Training loss: 1.7929343758406684
Validation loss: 2.4821036150049625

Epoch: 5| Step: 11
Training loss: 3.0456706478926066
Validation loss: 2.4864424214508527

Epoch: 289| Step: 0
Training loss: 2.45112586719148
Validation loss: 2.488050469076993

Epoch: 5| Step: 1
Training loss: 2.137483839899736
Validation loss: 2.4874115706145816

Epoch: 5| Step: 2
Training loss: 1.2909562505552923
Validation loss: 2.4836786561819992

Epoch: 5| Step: 3
Training loss: 2.410318279538866
Validation loss: 2.4973929600438893

Epoch: 5| Step: 4
Training loss: 2.0770041519219045
Validation loss: 2.4892632679052027

Epoch: 5| Step: 5
Training loss: 1.9134916115909115
Validation loss: 2.4924514495204932

Epoch: 5| Step: 6
Training loss: 1.6932183617261094
Validation loss: 2.5236333568296763

Epoch: 5| Step: 7
Training loss: 1.933767661548488
Validation loss: 2.505359456083551

Epoch: 5| Step: 8
Training loss: 2.264867721804461
Validation loss: 2.4758378682554563

Epoch: 5| Step: 9
Training loss: 2.6033688251291904
Validation loss: 2.497142947337407

Epoch: 5| Step: 10
Training loss: 2.730026711413597
Validation loss: 2.4908215198340926

Epoch: 5| Step: 11
Training loss: 2.369357483602109
Validation loss: 2.494514287979946

Epoch: 290| Step: 0
Training loss: 2.6966154183546562
Validation loss: 2.533249073499099

Epoch: 5| Step: 1
Training loss: 2.488975056886121
Validation loss: 2.5338165160175596

Epoch: 5| Step: 2
Training loss: 2.0159088644590777
Validation loss: 2.5374285874238387

Epoch: 5| Step: 3
Training loss: 1.951133750565977
Validation loss: 2.5259831582336276

Epoch: 5| Step: 4
Training loss: 1.8543287770701449
Validation loss: 2.5317554067426706

Epoch: 5| Step: 5
Training loss: 1.7878199764442777
Validation loss: 2.5115294476607337

Epoch: 5| Step: 6
Training loss: 2.640021351092148
Validation loss: 2.5186823279706028

Epoch: 5| Step: 7
Training loss: 2.718769468040481
Validation loss: 2.5330343472096923

Epoch: 5| Step: 8
Training loss: 1.735951162811543
Validation loss: 2.5222808423094527

Epoch: 5| Step: 9
Training loss: 2.0928473733221065
Validation loss: 2.534353026119603

Epoch: 5| Step: 10
Training loss: 1.4844524965635757
Validation loss: 2.4869963653662137

Epoch: 5| Step: 11
Training loss: 1.8097444173655883
Validation loss: 2.4696780001772045

Epoch: 291| Step: 0
Training loss: 2.076077477936932
Validation loss: 2.4758627431435185

Epoch: 5| Step: 1
Training loss: 2.2796802083997614
Validation loss: 2.481585826295777

Epoch: 5| Step: 2
Training loss: 2.0331245575748107
Validation loss: 2.489703117000183

Epoch: 5| Step: 3
Training loss: 2.496747667028304
Validation loss: 2.500037574485698

Epoch: 5| Step: 4
Training loss: 1.9901919074951184
Validation loss: 2.5259442117250983

Epoch: 5| Step: 5
Training loss: 2.2483991650142587
Validation loss: 2.518437935434315

Epoch: 5| Step: 6
Training loss: 1.8303805399605526
Validation loss: 2.5330990211352504

Epoch: 5| Step: 7
Training loss: 2.1904392658896685
Validation loss: 2.5290560888808318

Epoch: 5| Step: 8
Training loss: 2.3182386384552087
Validation loss: 2.5064630353668584

Epoch: 5| Step: 9
Training loss: 1.857545481519057
Validation loss: 2.535046019114489

Epoch: 5| Step: 10
Training loss: 2.3721659968093416
Validation loss: 2.5307849252706345

Epoch: 5| Step: 11
Training loss: 2.3136706095738244
Validation loss: 2.5084618176433633

Epoch: 292| Step: 0
Training loss: 2.146116133143707
Validation loss: 2.5109918866600585

Epoch: 5| Step: 1
Training loss: 1.633038810852781
Validation loss: 2.5027157100042814

Epoch: 5| Step: 2
Training loss: 2.001711470742792
Validation loss: 2.497389972720995

Epoch: 5| Step: 3
Training loss: 2.3651238942508384
Validation loss: 2.488524688038976

Epoch: 5| Step: 4
Training loss: 1.7989083768192051
Validation loss: 2.467164029152094

Epoch: 5| Step: 5
Training loss: 1.8330400044414443
Validation loss: 2.4852032990065798

Epoch: 5| Step: 6
Training loss: 2.229654514253203
Validation loss: 2.475423577055066

Epoch: 5| Step: 7
Training loss: 2.6182884519709835
Validation loss: 2.511722064374494

Epoch: 5| Step: 8
Training loss: 2.330120076699563
Validation loss: 2.4811706591139453

Epoch: 5| Step: 9
Training loss: 2.4579136269263855
Validation loss: 2.4844152339340493

Epoch: 5| Step: 10
Training loss: 2.134847487601539
Validation loss: 2.487073784005299

Epoch: 5| Step: 11
Training loss: 2.4850438015491148
Validation loss: 2.49475772306304

Epoch: 293| Step: 0
Training loss: 2.411806107580276
Validation loss: 2.525893920169486

Epoch: 5| Step: 1
Training loss: 1.9897114045097304
Validation loss: 2.5439860686626994

Epoch: 5| Step: 2
Training loss: 2.3016745317984446
Validation loss: 2.522471322670713

Epoch: 5| Step: 3
Training loss: 2.027367505355164
Validation loss: 2.521056174577576

Epoch: 5| Step: 4
Training loss: 2.247450337609161
Validation loss: 2.4808110979576767

Epoch: 5| Step: 5
Training loss: 1.8578235340352194
Validation loss: 2.4838061051222597

Epoch: 5| Step: 6
Training loss: 2.640559269013636
Validation loss: 2.4478711320145603

Epoch: 5| Step: 7
Training loss: 2.2193107433680086
Validation loss: 2.469286216575812

Epoch: 5| Step: 8
Training loss: 2.336533792484421
Validation loss: 2.4469373522918048

Epoch: 5| Step: 9
Training loss: 1.987238042590291
Validation loss: 2.4431126401609258

Epoch: 5| Step: 10
Training loss: 2.2144202310161663
Validation loss: 2.4460595831022505

Epoch: 5| Step: 11
Training loss: 2.1945320452603467
Validation loss: 2.442117147068935

Epoch: 294| Step: 0
Training loss: 2.2344935459087285
Validation loss: 2.4696652490404367

Epoch: 5| Step: 1
Training loss: 1.9466571373684503
Validation loss: 2.447436920122045

Epoch: 5| Step: 2
Training loss: 2.1200363305415695
Validation loss: 2.493260299193927

Epoch: 5| Step: 3
Training loss: 2.204570972112611
Validation loss: 2.5060890233258313

Epoch: 5| Step: 4
Training loss: 2.289513865681949
Validation loss: 2.5511529368356363

Epoch: 5| Step: 5
Training loss: 1.9283229930252057
Validation loss: 2.550647519837988

Epoch: 5| Step: 6
Training loss: 2.358724036950701
Validation loss: 2.562731267215898

Epoch: 5| Step: 7
Training loss: 2.1957714103446233
Validation loss: 2.5375987484701867

Epoch: 5| Step: 8
Training loss: 1.9397365213194557
Validation loss: 2.503177975313494

Epoch: 5| Step: 9
Training loss: 2.3222173713053404
Validation loss: 2.479870052624789

Epoch: 5| Step: 10
Training loss: 2.1414721963463847
Validation loss: 2.474684138324052

Epoch: 5| Step: 11
Training loss: 2.069424766373008
Validation loss: 2.4736119412639677

Epoch: 295| Step: 0
Training loss: 1.407749647966604
Validation loss: 2.4548789110187363

Epoch: 5| Step: 1
Training loss: 2.5274171420588933
Validation loss: 2.4697842302750757

Epoch: 5| Step: 2
Training loss: 2.449989404460806
Validation loss: 2.470835995525279

Epoch: 5| Step: 3
Training loss: 2.2087243531685954
Validation loss: 2.466493756579881

Epoch: 5| Step: 4
Training loss: 2.2569027027932527
Validation loss: 2.45325391070287

Epoch: 5| Step: 5
Training loss: 2.409335647439751
Validation loss: 2.4641553357749335

Epoch: 5| Step: 6
Training loss: 2.602780535232927
Validation loss: 2.4608960587176023

Epoch: 5| Step: 7
Training loss: 2.6763124258929056
Validation loss: 2.454985607490901

Epoch: 5| Step: 8
Training loss: 1.8837565354485093
Validation loss: 2.454888384276498

Epoch: 5| Step: 9
Training loss: 2.397939027559921
Validation loss: 2.4496366842924653

Epoch: 5| Step: 10
Training loss: 1.93600338384238
Validation loss: 2.4852795023985776

Epoch: 5| Step: 11
Training loss: 2.1271877247011806
Validation loss: 2.5018260366664498

Epoch: 296| Step: 0
Training loss: 2.445444121794613
Validation loss: 2.5339287998124216

Epoch: 5| Step: 1
Training loss: 2.1266460775058333
Validation loss: 2.5826315400842845

Epoch: 5| Step: 2
Training loss: 1.8793513351792526
Validation loss: 2.5786639411263264

Epoch: 5| Step: 3
Training loss: 2.308415388262443
Validation loss: 2.570261486130828

Epoch: 5| Step: 4
Training loss: 2.138071918380606
Validation loss: 2.569489526066784

Epoch: 5| Step: 5
Training loss: 1.7159268862302786
Validation loss: 2.533649692472603

Epoch: 5| Step: 6
Training loss: 2.424738513966919
Validation loss: 2.5090484742405166

Epoch: 5| Step: 7
Training loss: 2.4442871674119844
Validation loss: 2.5083666156596927

Epoch: 5| Step: 8
Training loss: 2.0024258683445266
Validation loss: 2.5006635143018965

Epoch: 5| Step: 9
Training loss: 1.7261645518706747
Validation loss: 2.4951169625498055

Epoch: 5| Step: 10
Training loss: 2.099570879916003
Validation loss: 2.5281418371091777

Epoch: 5| Step: 11
Training loss: 2.49148253033703
Validation loss: 2.518323868263108

Epoch: 297| Step: 0
Training loss: 2.0207050977572285
Validation loss: 2.541561313436411

Epoch: 5| Step: 1
Training loss: 1.8622890685796263
Validation loss: 2.5613223060044197

Epoch: 5| Step: 2
Training loss: 1.633259105293215
Validation loss: 2.564103225889793

Epoch: 5| Step: 3
Training loss: 2.724464636892581
Validation loss: 2.5596167268975325

Epoch: 5| Step: 4
Training loss: 2.3714191144403403
Validation loss: 2.6037860147113165

Epoch: 5| Step: 5
Training loss: 2.2063507921575387
Validation loss: 2.5843148148773323

Epoch: 5| Step: 6
Training loss: 2.0855110103926555
Validation loss: 2.591355421065955

Epoch: 5| Step: 7
Training loss: 2.1341452434417345
Validation loss: 2.6027801421098298

Epoch: 5| Step: 8
Training loss: 2.476742614550258
Validation loss: 2.60732134793119

Epoch: 5| Step: 9
Training loss: 1.7204983921769648
Validation loss: 2.569745918292456

Epoch: 5| Step: 10
Training loss: 2.2509203194234377
Validation loss: 2.513283324821326

Epoch: 5| Step: 11
Training loss: 0.9777654943874684
Validation loss: 2.500853396829597

Epoch: 298| Step: 0
Training loss: 1.9912903804001305
Validation loss: 2.474877282513619

Epoch: 5| Step: 1
Training loss: 2.828803555347832
Validation loss: 2.483599063771209

Epoch: 5| Step: 2
Training loss: 1.8681018458054903
Validation loss: 2.4696444528811834

Epoch: 5| Step: 3
Training loss: 2.400970016590971
Validation loss: 2.4687146695341196

Epoch: 5| Step: 4
Training loss: 2.5993794397571657
Validation loss: 2.474283937142144

Epoch: 5| Step: 5
Training loss: 1.4598372288986674
Validation loss: 2.471618607378145

Epoch: 5| Step: 6
Training loss: 2.2866873543177
Validation loss: 2.491347690618571

Epoch: 5| Step: 7
Training loss: 2.353563034403196
Validation loss: 2.4691385735960556

Epoch: 5| Step: 8
Training loss: 2.0849564777835794
Validation loss: 2.481075082598157

Epoch: 5| Step: 9
Training loss: 1.5165225645223497
Validation loss: 2.505821959170868

Epoch: 5| Step: 10
Training loss: 2.033077181122708
Validation loss: 2.520251614205098

Epoch: 5| Step: 11
Training loss: 3.281154812839948
Validation loss: 2.5247673569571893

Epoch: 299| Step: 0
Training loss: 2.0685157896844957
Validation loss: 2.5128290541344382

Epoch: 5| Step: 1
Training loss: 2.122836638624628
Validation loss: 2.5193838248874703

Epoch: 5| Step: 2
Training loss: 2.130264269056322
Validation loss: 2.512138280245984

Epoch: 5| Step: 3
Training loss: 2.7688142308347534
Validation loss: 2.5055485902108163

Epoch: 5| Step: 4
Training loss: 1.7543085737057047
Validation loss: 2.4972437068733764

Epoch: 5| Step: 5
Training loss: 2.5739856203414124
Validation loss: 2.4803314931945817

Epoch: 5| Step: 6
Training loss: 2.1741719346758166
Validation loss: 2.4868976253436776

Epoch: 5| Step: 7
Training loss: 1.9644520181382346
Validation loss: 2.477725168229387

Epoch: 5| Step: 8
Training loss: 2.1084753307828903
Validation loss: 2.5148364306056297

Epoch: 5| Step: 9
Training loss: 2.1660729719710656
Validation loss: 2.5205354961228315

Epoch: 5| Step: 10
Training loss: 1.587232765473099
Validation loss: 2.52921698602417

Epoch: 5| Step: 11
Training loss: 2.1478530366231188
Validation loss: 2.5384833472535124

Epoch: 300| Step: 0
Training loss: 2.79471372499716
Validation loss: 2.5093111925575644

Epoch: 5| Step: 1
Training loss: 2.148792473338303
Validation loss: 2.473188603100447

Epoch: 5| Step: 2
Training loss: 2.1215697258525474
Validation loss: 2.454312786135922

Epoch: 5| Step: 3
Training loss: 1.929286467235828
Validation loss: 2.465141282459396

Epoch: 5| Step: 4
Training loss: 2.6123751450778667
Validation loss: 2.4658827408042088

Epoch: 5| Step: 5
Training loss: 1.7114744693725246
Validation loss: 2.491229456134007

Epoch: 5| Step: 6
Training loss: 1.7921753833896616
Validation loss: 2.48679843399002

Epoch: 5| Step: 7
Training loss: 1.762987918818857
Validation loss: 2.493767603156376

Epoch: 5| Step: 8
Training loss: 1.6265791775803937
Validation loss: 2.4937927035290124

Epoch: 5| Step: 9
Training loss: 1.5054535275586942
Validation loss: 2.4760065307071426

Epoch: 5| Step: 10
Training loss: 2.9253408510545627
Validation loss: 2.480586163803172

Epoch: 5| Step: 11
Training loss: 2.076227684383363
Validation loss: 2.453455159673582

Epoch: 301| Step: 0
Training loss: 1.9639367499567828
Validation loss: 2.46841555555259

Epoch: 5| Step: 1
Training loss: 2.014371970396637
Validation loss: 2.4432498654250647

Epoch: 5| Step: 2
Training loss: 2.15472778548215
Validation loss: 2.467070056229063

Epoch: 5| Step: 3
Training loss: 2.6152608127981267
Validation loss: 2.4487129877644875

Epoch: 5| Step: 4
Training loss: 2.1458963798470725
Validation loss: 2.4704553733719123

Epoch: 5| Step: 5
Training loss: 1.9668334230211169
Validation loss: 2.489604711773325

Epoch: 5| Step: 6
Training loss: 1.5027790551798137
Validation loss: 2.49875339183415

Epoch: 5| Step: 7
Training loss: 2.6698214129039672
Validation loss: 2.4897734171765893

Epoch: 5| Step: 8
Training loss: 2.3139333664475155
Validation loss: 2.5209208123867812

Epoch: 5| Step: 9
Training loss: 1.9181634683688686
Validation loss: 2.5491383564717482

Epoch: 5| Step: 10
Training loss: 2.1540449726648454
Validation loss: 2.4916946517740017

Epoch: 5| Step: 11
Training loss: 1.2720618745701742
Validation loss: 2.50642785402865

Epoch: 302| Step: 0
Training loss: 2.1558798873155003
Validation loss: 2.5398455854972686

Epoch: 5| Step: 1
Training loss: 2.077861224191426
Validation loss: 2.5084436361217937

Epoch: 5| Step: 2
Training loss: 1.8802234370786477
Validation loss: 2.5172362922913774

Epoch: 5| Step: 3
Training loss: 1.8123983157343502
Validation loss: 2.5175551676585126

Epoch: 5| Step: 4
Training loss: 2.4274745074739785
Validation loss: 2.508766179161696

Epoch: 5| Step: 5
Training loss: 2.420277911850881
Validation loss: 2.5070737105059098

Epoch: 5| Step: 6
Training loss: 1.9922487735675105
Validation loss: 2.5135263728406216

Epoch: 5| Step: 7
Training loss: 1.9235451737115086
Validation loss: 2.5126691555693377

Epoch: 5| Step: 8
Training loss: 1.7091776536910466
Validation loss: 2.517666448440182

Epoch: 5| Step: 9
Training loss: 1.9428520728994783
Validation loss: 2.5060347160982714

Epoch: 5| Step: 10
Training loss: 2.835602207172109
Validation loss: 2.521030837327016

Epoch: 5| Step: 11
Training loss: 2.8383457687861138
Validation loss: 2.521680824748918

Epoch: 303| Step: 0
Training loss: 1.4320751327059351
Validation loss: 2.557865736183455

Epoch: 5| Step: 1
Training loss: 1.8693748016510363
Validation loss: 2.577067171651069

Epoch: 5| Step: 2
Training loss: 2.245568892481125
Validation loss: 2.592002203176096

Epoch: 5| Step: 3
Training loss: 2.312825566649073
Validation loss: 2.6376404646521707

Epoch: 5| Step: 4
Training loss: 2.5455270956587097
Validation loss: 2.650896822876506

Epoch: 5| Step: 5
Training loss: 2.3296661396441745
Validation loss: 2.6215669798849683

Epoch: 5| Step: 6
Training loss: 2.7340020497613686
Validation loss: 2.589463855772773

Epoch: 5| Step: 7
Training loss: 2.4480755585310474
Validation loss: 2.5744988265467956

Epoch: 5| Step: 8
Training loss: 1.706263039787126
Validation loss: 2.538505438315358

Epoch: 5| Step: 9
Training loss: 2.498226490378525
Validation loss: 2.503615435347032

Epoch: 5| Step: 10
Training loss: 1.649937169005799
Validation loss: 2.475761641086371

Epoch: 5| Step: 11
Training loss: 0.7800189810057301
Validation loss: 2.476361632599748

Epoch: 304| Step: 0
Training loss: 2.273882216121624
Validation loss: 2.458080053751875

Epoch: 5| Step: 1
Training loss: 2.2001822006031295
Validation loss: 2.4856314091243705

Epoch: 5| Step: 2
Training loss: 2.5521836449248467
Validation loss: 2.4817200075424273

Epoch: 5| Step: 3
Training loss: 2.7386576221091374
Validation loss: 2.476522355100248

Epoch: 5| Step: 4
Training loss: 2.1766382033087233
Validation loss: 2.48029783766443

Epoch: 5| Step: 5
Training loss: 1.4099136524274565
Validation loss: 2.5107557943542442

Epoch: 5| Step: 6
Training loss: 2.3892928257571016
Validation loss: 2.4928812558146123

Epoch: 5| Step: 7
Training loss: 2.142174821032865
Validation loss: 2.503855672514931

Epoch: 5| Step: 8
Training loss: 2.2737412921556324
Validation loss: 2.5283028749464056

Epoch: 5| Step: 9
Training loss: 1.7496021363435879
Validation loss: 2.539744660122401

Epoch: 5| Step: 10
Training loss: 2.0360694637552452
Validation loss: 2.5646872373636342

Epoch: 5| Step: 11
Training loss: 1.3864422589675964
Validation loss: 2.5674406199659985

Epoch: 305| Step: 0
Training loss: 2.185191762265343
Validation loss: 2.5977660574207646

Epoch: 5| Step: 1
Training loss: 2.0972166826232552
Validation loss: 2.5828528200892067

Epoch: 5| Step: 2
Training loss: 2.2802282684230812
Validation loss: 2.6018734957033725

Epoch: 5| Step: 3
Training loss: 2.272242071204423
Validation loss: 2.576561636815679

Epoch: 5| Step: 4
Training loss: 2.192616609541109
Validation loss: 2.556321717012493

Epoch: 5| Step: 5
Training loss: 1.7738255819786743
Validation loss: 2.542620278041903

Epoch: 5| Step: 6
Training loss: 2.125233356902028
Validation loss: 2.5215558377556637

Epoch: 5| Step: 7
Training loss: 2.4843949611029856
Validation loss: 2.5147177756419423

Epoch: 5| Step: 8
Training loss: 2.4104291616086844
Validation loss: 2.5122464398406223

Epoch: 5| Step: 9
Training loss: 2.1691141487922487
Validation loss: 2.5049371090086177

Epoch: 5| Step: 10
Training loss: 1.7663728598636435
Validation loss: 2.487997393184576

Epoch: 5| Step: 11
Training loss: 1.479369789826695
Validation loss: 2.520057836107318

Epoch: 306| Step: 0
Training loss: 1.9940415076600688
Validation loss: 2.4925787966321336

Epoch: 5| Step: 1
Training loss: 2.736355135428342
Validation loss: 2.4910674493096714

Epoch: 5| Step: 2
Training loss: 1.667440004541977
Validation loss: 2.4934738849248648

Epoch: 5| Step: 3
Training loss: 2.3395003383609327
Validation loss: 2.493241751815518

Epoch: 5| Step: 4
Training loss: 2.221670673058635
Validation loss: 2.4969422455868497

Epoch: 5| Step: 5
Training loss: 1.7901687866421894
Validation loss: 2.5125736227367135

Epoch: 5| Step: 6
Training loss: 2.233528243522301
Validation loss: 2.4986063211710956

Epoch: 5| Step: 7
Training loss: 2.1858817518104563
Validation loss: 2.536228231506156

Epoch: 5| Step: 8
Training loss: 2.153289753184516
Validation loss: 2.526873277979209

Epoch: 5| Step: 9
Training loss: 1.7936818817708908
Validation loss: 2.526484159011145

Epoch: 5| Step: 10
Training loss: 2.1858197980144864
Validation loss: 2.5436772669611

Epoch: 5| Step: 11
Training loss: 1.5312412806671392
Validation loss: 2.5339704345081304

Epoch: 307| Step: 0
Training loss: 2.35621228984739
Validation loss: 2.516541071362025

Epoch: 5| Step: 1
Training loss: 2.0818954337590863
Validation loss: 2.532468726086486

Epoch: 5| Step: 2
Training loss: 1.9499934000734978
Validation loss: 2.50422981381469

Epoch: 5| Step: 3
Training loss: 2.129156983335489
Validation loss: 2.4949377643650013

Epoch: 5| Step: 4
Training loss: 2.0001113383773816
Validation loss: 2.493263849277908

Epoch: 5| Step: 5
Training loss: 2.250820222336473
Validation loss: 2.4712372294269493

Epoch: 5| Step: 6
Training loss: 2.525955691627803
Validation loss: 2.468750450681492

Epoch: 5| Step: 7
Training loss: 1.8481733634846436
Validation loss: 2.492942464513188

Epoch: 5| Step: 8
Training loss: 2.352055190677956
Validation loss: 2.5043333525463654

Epoch: 5| Step: 9
Training loss: 2.040720532271021
Validation loss: 2.5148173471158817

Epoch: 5| Step: 10
Training loss: 1.7611184461315859
Validation loss: 2.50306953498898

Epoch: 5| Step: 11
Training loss: 1.2023511106824725
Validation loss: 2.5390682552957107

Epoch: 308| Step: 0
Training loss: 1.8389412190936105
Validation loss: 2.5227512887123473

Epoch: 5| Step: 1
Training loss: 1.7414040621525133
Validation loss: 2.4859020250603723

Epoch: 5| Step: 2
Training loss: 2.2561931148554186
Validation loss: 2.4539077141826335

Epoch: 5| Step: 3
Training loss: 2.330029623801064
Validation loss: 2.468685398785676

Epoch: 5| Step: 4
Training loss: 2.464837849605408
Validation loss: 2.469696117136539

Epoch: 5| Step: 5
Training loss: 1.4622746024916253
Validation loss: 2.4944724487294088

Epoch: 5| Step: 6
Training loss: 2.0686846397193652
Validation loss: 2.529411173905009

Epoch: 5| Step: 7
Training loss: 2.4539451443013625
Validation loss: 2.5321700892469132

Epoch: 5| Step: 8
Training loss: 2.3696863060190743
Validation loss: 2.525106848290989

Epoch: 5| Step: 9
Training loss: 2.0692211801592
Validation loss: 2.5151495474358168

Epoch: 5| Step: 10
Training loss: 2.2986504576031157
Validation loss: 2.5153126058642843

Epoch: 5| Step: 11
Training loss: 0.665471455948526
Validation loss: 2.5267458271804766

Epoch: 309| Step: 0
Training loss: 2.256313578800905
Validation loss: 2.5225590534058906

Epoch: 5| Step: 1
Training loss: 1.9185315333944621
Validation loss: 2.5150137448930647

Epoch: 5| Step: 2
Training loss: 1.495539868965153
Validation loss: 2.5396434843050306

Epoch: 5| Step: 3
Training loss: 2.2790054357245424
Validation loss: 2.5132361654155524

Epoch: 5| Step: 4
Training loss: 2.223564941013758
Validation loss: 2.4993376728719565

Epoch: 5| Step: 5
Training loss: 1.6310624230354076
Validation loss: 2.4948809706619364

Epoch: 5| Step: 6
Training loss: 2.417674008155503
Validation loss: 2.5116541030023645

Epoch: 5| Step: 7
Training loss: 2.1510754845079867
Validation loss: 2.5042994602578577

Epoch: 5| Step: 8
Training loss: 1.890276411723885
Validation loss: 2.5289231739846882

Epoch: 5| Step: 9
Training loss: 2.6660254621498916
Validation loss: 2.535083991119593

Epoch: 5| Step: 10
Training loss: 1.7818820568147022
Validation loss: 2.536878979142464

Epoch: 5| Step: 11
Training loss: 2.43096958690906
Validation loss: 2.506902844643625

Epoch: 310| Step: 0
Training loss: 2.0740811577113356
Validation loss: 2.496032475299966

Epoch: 5| Step: 1
Training loss: 1.8726712706484252
Validation loss: 2.4658443477453806

Epoch: 5| Step: 2
Training loss: 2.2337912483868383
Validation loss: 2.495291790511015

Epoch: 5| Step: 3
Training loss: 2.2344140536223143
Validation loss: 2.4897740994604196

Epoch: 5| Step: 4
Training loss: 2.4791879305742395
Validation loss: 2.4886974104480997

Epoch: 5| Step: 5
Training loss: 2.0199400379232597
Validation loss: 2.4963747760811508

Epoch: 5| Step: 6
Training loss: 2.4944107518779806
Validation loss: 2.498429194331802

Epoch: 5| Step: 7
Training loss: 2.2181379521761113
Validation loss: 2.4869696785045132

Epoch: 5| Step: 8
Training loss: 1.4229003227639414
Validation loss: 2.5107200935150344

Epoch: 5| Step: 9
Training loss: 2.075294804600295
Validation loss: 2.5138572025819497

Epoch: 5| Step: 10
Training loss: 2.0999360438099157
Validation loss: 2.528704281467674

Epoch: 5| Step: 11
Training loss: 0.9072409178026161
Validation loss: 2.5092747367790413

Epoch: 311| Step: 0
Training loss: 2.2661320612202593
Validation loss: 2.522906921792104

Epoch: 5| Step: 1
Training loss: 2.3616077898000416
Validation loss: 2.5246508567818022

Epoch: 5| Step: 2
Training loss: 1.7608966135526571
Validation loss: 2.5307109282289706

Epoch: 5| Step: 3
Training loss: 2.9105648701169984
Validation loss: 2.5093855118521455

Epoch: 5| Step: 4
Training loss: 1.5303817934625323
Validation loss: 2.5177470412703005

Epoch: 5| Step: 5
Training loss: 2.3815228083173263
Validation loss: 2.505014417337793

Epoch: 5| Step: 6
Training loss: 1.8565320632306863
Validation loss: 2.5205358429544464

Epoch: 5| Step: 7
Training loss: 1.8941913103122017
Validation loss: 2.50753702649169

Epoch: 5| Step: 8
Training loss: 1.7548932736976035
Validation loss: 2.5219536700892706

Epoch: 5| Step: 9
Training loss: 2.1758295735278375
Validation loss: 2.534621124922316

Epoch: 5| Step: 10
Training loss: 1.9878846617999206
Validation loss: 2.5105075397637817

Epoch: 5| Step: 11
Training loss: 1.9892651235214815
Validation loss: 2.524829759933391

Epoch: 312| Step: 0
Training loss: 2.193789459482245
Validation loss: 2.5123259708681656

Epoch: 5| Step: 1
Training loss: 2.455612961954896
Validation loss: 2.524616367637917

Epoch: 5| Step: 2
Training loss: 2.0064695149056226
Validation loss: 2.510920222155114

Epoch: 5| Step: 3
Training loss: 2.4505583341014816
Validation loss: 2.5240394929271264

Epoch: 5| Step: 4
Training loss: 1.7522922217471342
Validation loss: 2.539337714514037

Epoch: 5| Step: 5
Training loss: 2.6288483883978797
Validation loss: 2.5276690730160127

Epoch: 5| Step: 6
Training loss: 1.8068301209741802
Validation loss: 2.5569502543686666

Epoch: 5| Step: 7
Training loss: 1.6834371896690024
Validation loss: 2.5122431933806544

Epoch: 5| Step: 8
Training loss: 2.065027133680256
Validation loss: 2.5101301905631526

Epoch: 5| Step: 9
Training loss: 2.2408734767727982
Validation loss: 2.5222057174524446

Epoch: 5| Step: 10
Training loss: 1.9222434706361842
Validation loss: 2.51233506539096

Epoch: 5| Step: 11
Training loss: 1.2091085095992127
Validation loss: 2.4980487202112354

Epoch: 313| Step: 0
Training loss: 2.5384503844489616
Validation loss: 2.4985866902881244

Epoch: 5| Step: 1
Training loss: 1.6113193211170473
Validation loss: 2.482652242812823

Epoch: 5| Step: 2
Training loss: 2.1798078168797987
Validation loss: 2.5110708640034813

Epoch: 5| Step: 3
Training loss: 2.0018852408460104
Validation loss: 2.495653005102581

Epoch: 5| Step: 4
Training loss: 1.7110839502372528
Validation loss: 2.505058880245321

Epoch: 5| Step: 5
Training loss: 1.8521192011526473
Validation loss: 2.5327063303492356

Epoch: 5| Step: 6
Training loss: 2.2670828502644933
Validation loss: 2.52103164118771

Epoch: 5| Step: 7
Training loss: 2.3228389458990057
Validation loss: 2.5305875217397515

Epoch: 5| Step: 8
Training loss: 1.7388740814493941
Validation loss: 2.550928852509501

Epoch: 5| Step: 9
Training loss: 1.8629274172278238
Validation loss: 2.5533915935767806

Epoch: 5| Step: 10
Training loss: 2.560326096060845
Validation loss: 2.5320608425873012

Epoch: 5| Step: 11
Training loss: 2.186507299516149
Validation loss: 2.523303631675335

Epoch: 314| Step: 0
Training loss: 2.543152317623214
Validation loss: 2.487375978033053

Epoch: 5| Step: 1
Training loss: 1.4995100492755686
Validation loss: 2.481796289869137

Epoch: 5| Step: 2
Training loss: 1.979574449257362
Validation loss: 2.455721337692602

Epoch: 5| Step: 3
Training loss: 1.8679242456256733
Validation loss: 2.4490204344977284

Epoch: 5| Step: 4
Training loss: 2.0065056373560726
Validation loss: 2.4570666837740007

Epoch: 5| Step: 5
Training loss: 2.2887561580089684
Validation loss: 2.4260629028683725

Epoch: 5| Step: 6
Training loss: 1.9772158662399044
Validation loss: 2.465657564841799

Epoch: 5| Step: 7
Training loss: 1.741239554982511
Validation loss: 2.4601740949816775

Epoch: 5| Step: 8
Training loss: 2.5542136403214304
Validation loss: 2.459208887509725

Epoch: 5| Step: 9
Training loss: 1.7407621702869687
Validation loss: 2.469212508838728

Epoch: 5| Step: 10
Training loss: 1.8847000347840799
Validation loss: 2.49643819120908

Epoch: 5| Step: 11
Training loss: 4.082901419289203
Validation loss: 2.526778372603561

Epoch: 315| Step: 0
Training loss: 2.299292401641925
Validation loss: 2.5709283703487777

Epoch: 5| Step: 1
Training loss: 1.783813639456566
Validation loss: 2.6153438963972935

Epoch: 5| Step: 2
Training loss: 2.3365123641056145
Validation loss: 2.6473800213421823

Epoch: 5| Step: 3
Training loss: 1.6433145910952036
Validation loss: 2.625234313376948

Epoch: 5| Step: 4
Training loss: 1.9018913216694397
Validation loss: 2.634238429543678

Epoch: 5| Step: 5
Training loss: 2.1925224412663473
Validation loss: 2.5787376523581327

Epoch: 5| Step: 6
Training loss: 2.0482595871307896
Validation loss: 2.545902429247596

Epoch: 5| Step: 7
Training loss: 2.4840344849433342
Validation loss: 2.4981097506001304

Epoch: 5| Step: 8
Training loss: 1.9022250598641697
Validation loss: 2.4728976227804487

Epoch: 5| Step: 9
Training loss: 2.054032834266976
Validation loss: 2.448511519425938

Epoch: 5| Step: 10
Training loss: 2.193433615972784
Validation loss: 2.421377836491773

Epoch: 5| Step: 11
Training loss: 1.1928029362947485
Validation loss: 2.443578684331261

Epoch: 316| Step: 0
Training loss: 1.8217943569545307
Validation loss: 2.4458982600920494

Epoch: 5| Step: 1
Training loss: 1.4746733190554306
Validation loss: 2.453125931401491

Epoch: 5| Step: 2
Training loss: 1.695274247120276
Validation loss: 2.463797188398397

Epoch: 5| Step: 3
Training loss: 2.1518964077574085
Validation loss: 2.464204039184374

Epoch: 5| Step: 4
Training loss: 1.9106587566155206
Validation loss: 2.485143502650526

Epoch: 5| Step: 5
Training loss: 1.965558568562686
Validation loss: 2.457355229255185

Epoch: 5| Step: 6
Training loss: 1.8864345296968998
Validation loss: 2.467117606862738

Epoch: 5| Step: 7
Training loss: 2.044177775279592
Validation loss: 2.457893541701176

Epoch: 5| Step: 8
Training loss: 2.4531737887639387
Validation loss: 2.4944916420649568

Epoch: 5| Step: 9
Training loss: 3.0450571750728903
Validation loss: 2.4822237789610595

Epoch: 5| Step: 10
Training loss: 2.324055641926419
Validation loss: 2.4986726654563243

Epoch: 5| Step: 11
Training loss: 2.404468520953355
Validation loss: 2.5183976888565023

Epoch: 317| Step: 0
Training loss: 1.883483640473653
Validation loss: 2.4966649857970804

Epoch: 5| Step: 1
Training loss: 2.397210220310799
Validation loss: 2.487976654429242

Epoch: 5| Step: 2
Training loss: 2.197846819835981
Validation loss: 2.5040838701288495

Epoch: 5| Step: 3
Training loss: 2.2702925385177166
Validation loss: 2.5054503117132576

Epoch: 5| Step: 4
Training loss: 2.420836786036784
Validation loss: 2.4765734025492594

Epoch: 5| Step: 5
Training loss: 1.599602742350222
Validation loss: 2.496295950614225

Epoch: 5| Step: 6
Training loss: 1.4270888929421197
Validation loss: 2.491886551243952

Epoch: 5| Step: 7
Training loss: 2.690076701690906
Validation loss: 2.487039093307504

Epoch: 5| Step: 8
Training loss: 1.9318683362763818
Validation loss: 2.466900627751166

Epoch: 5| Step: 9
Training loss: 2.0166862119037545
Validation loss: 2.4802155172689107

Epoch: 5| Step: 10
Training loss: 1.917075638744906
Validation loss: 2.4336877828180996

Epoch: 5| Step: 11
Training loss: 1.1774170101587447
Validation loss: 2.452078594072462

Epoch: 318| Step: 0
Training loss: 2.059828096828147
Validation loss: 2.4646543822012896

Epoch: 5| Step: 1
Training loss: 1.4198974439363559
Validation loss: 2.4637601619764427

Epoch: 5| Step: 2
Training loss: 1.4891808061545748
Validation loss: 2.4740014336830347

Epoch: 5| Step: 3
Training loss: 2.000478568040704
Validation loss: 2.4603038880429935

Epoch: 5| Step: 4
Training loss: 2.155695857838077
Validation loss: 2.5312456280077944

Epoch: 5| Step: 5
Training loss: 2.5735857218504306
Validation loss: 2.5017762351158757

Epoch: 5| Step: 6
Training loss: 2.3419845035017492
Validation loss: 2.519708178712632

Epoch: 5| Step: 7
Training loss: 1.4421338568368598
Validation loss: 2.516475774512612

Epoch: 5| Step: 8
Training loss: 2.2164532231223166
Validation loss: 2.5259220501346484

Epoch: 5| Step: 9
Training loss: 2.1834730957763706
Validation loss: 2.4951596808252186

Epoch: 5| Step: 10
Training loss: 2.2977735357821323
Validation loss: 2.4993388752172088

Epoch: 5| Step: 11
Training loss: 1.6982902708699328
Validation loss: 2.504362244328788

Epoch: 319| Step: 0
Training loss: 1.8699671911737608
Validation loss: 2.5149661814607005

Epoch: 5| Step: 1
Training loss: 1.9429356405384446
Validation loss: 2.4860720086766883

Epoch: 5| Step: 2
Training loss: 2.0199766276678703
Validation loss: 2.4929665052530754

Epoch: 5| Step: 3
Training loss: 1.6188030926455474
Validation loss: 2.5021334406218405

Epoch: 5| Step: 4
Training loss: 2.024348580405013
Validation loss: 2.5224857385715524

Epoch: 5| Step: 5
Training loss: 1.1456468892854832
Validation loss: 2.5169774323604694

Epoch: 5| Step: 6
Training loss: 2.2521921710858708
Validation loss: 2.496999951205382

Epoch: 5| Step: 7
Training loss: 1.9626847951589974
Validation loss: 2.509324625063068

Epoch: 5| Step: 8
Training loss: 2.3603867136397896
Validation loss: 2.488279381576148

Epoch: 5| Step: 9
Training loss: 2.895062808342093
Validation loss: 2.5138635846322783

Epoch: 5| Step: 10
Training loss: 2.095486504415036
Validation loss: 2.519427180543591

Epoch: 5| Step: 11
Training loss: 2.041940112843292
Validation loss: 2.5239285521745125

Epoch: 320| Step: 0
Training loss: 1.7862757671999012
Validation loss: 2.58336717573169

Epoch: 5| Step: 1
Training loss: 1.745447914109132
Validation loss: 2.5960978219154085

Epoch: 5| Step: 2
Training loss: 1.942954353797629
Validation loss: 2.609339156066432

Epoch: 5| Step: 3
Training loss: 1.377255886691966
Validation loss: 2.6373841037266175

Epoch: 5| Step: 4
Training loss: 1.9316116191973511
Validation loss: 2.6320753452211414

Epoch: 5| Step: 5
Training loss: 2.5669244855555604
Validation loss: 2.6247076749762406

Epoch: 5| Step: 6
Training loss: 2.165571987719776
Validation loss: 2.6048487774477764

Epoch: 5| Step: 7
Training loss: 2.371974222271525
Validation loss: 2.5700837896408135

Epoch: 5| Step: 8
Training loss: 2.3729514271571115
Validation loss: 2.5078475094071724

Epoch: 5| Step: 9
Training loss: 2.3677622283113893
Validation loss: 2.478255201866273

Epoch: 5| Step: 10
Training loss: 2.3485304843872457
Validation loss: 2.4749463982669986

Epoch: 5| Step: 11
Training loss: 1.5766863922648735
Validation loss: 2.4736826425165073

Epoch: 321| Step: 0
Training loss: 1.9342886860807136
Validation loss: 2.489218810194841

Epoch: 5| Step: 1
Training loss: 2.17879782400427
Validation loss: 2.4728491468352236

Epoch: 5| Step: 2
Training loss: 2.241062639769601
Validation loss: 2.549634421546848

Epoch: 5| Step: 3
Training loss: 1.9954165151514631
Validation loss: 2.5629929324293386

Epoch: 5| Step: 4
Training loss: 1.450873651062999
Validation loss: 2.5675119604781167

Epoch: 5| Step: 5
Training loss: 1.9667412940376092
Validation loss: 2.580774760428945

Epoch: 5| Step: 6
Training loss: 2.626100763495517
Validation loss: 2.5714635696817285

Epoch: 5| Step: 7
Training loss: 2.5396540964942624
Validation loss: 2.5885219969792055

Epoch: 5| Step: 8
Training loss: 2.0147209801605706
Validation loss: 2.596097408647587

Epoch: 5| Step: 9
Training loss: 1.9111578875862034
Validation loss: 2.581235792907583

Epoch: 5| Step: 10
Training loss: 1.2884070839855026
Validation loss: 2.57525337278195

Epoch: 5| Step: 11
Training loss: 2.0374788294903428
Validation loss: 2.574575871194756

Epoch: 322| Step: 0
Training loss: 1.5266692484427087
Validation loss: 2.524669492134559

Epoch: 5| Step: 1
Training loss: 2.318001877844036
Validation loss: 2.498149353740862

Epoch: 5| Step: 2
Training loss: 2.75634493156143
Validation loss: 2.512263043776737

Epoch: 5| Step: 3
Training loss: 2.4588039292596564
Validation loss: 2.4977300670201195

Epoch: 5| Step: 4
Training loss: 2.0894606194510623
Validation loss: 2.5043209365341736

Epoch: 5| Step: 5
Training loss: 2.111741497497314
Validation loss: 2.5016349731151464

Epoch: 5| Step: 6
Training loss: 2.100934583601487
Validation loss: 2.5223947344776327

Epoch: 5| Step: 7
Training loss: 1.6245035733705848
Validation loss: 2.5352355874083283

Epoch: 5| Step: 8
Training loss: 2.2912957555985702
Validation loss: 2.567316624448572

Epoch: 5| Step: 9
Training loss: 2.0771278914783684
Validation loss: 2.5833693676147895

Epoch: 5| Step: 10
Training loss: 2.402927334001479
Validation loss: 2.588936352846123

Epoch: 5| Step: 11
Training loss: 1.5482022535001427
Validation loss: 2.5457007269550225

Epoch: 323| Step: 0
Training loss: 2.2296833853626845
Validation loss: 2.5424094378553774

Epoch: 5| Step: 1
Training loss: 2.658652531783633
Validation loss: 2.524687907001739

Epoch: 5| Step: 2
Training loss: 1.1938038698993576
Validation loss: 2.5206672611125733

Epoch: 5| Step: 3
Training loss: 2.0481843909836326
Validation loss: 2.521947761503865

Epoch: 5| Step: 4
Training loss: 1.3550968594436787
Validation loss: 2.5289007360260576

Epoch: 5| Step: 5
Training loss: 2.591285545889235
Validation loss: 2.531979408663295

Epoch: 5| Step: 6
Training loss: 2.273976370273503
Validation loss: 2.497762505294941

Epoch: 5| Step: 7
Training loss: 1.9366416875811774
Validation loss: 2.5116233827354146

Epoch: 5| Step: 8
Training loss: 2.193332743291959
Validation loss: 2.5103705561559497

Epoch: 5| Step: 9
Training loss: 2.031300118634997
Validation loss: 2.5002334088402893

Epoch: 5| Step: 10
Training loss: 1.910277380349801
Validation loss: 2.5085065322995206

Epoch: 5| Step: 11
Training loss: 2.7791866406624215
Validation loss: 2.509655038893406

Epoch: 324| Step: 0
Training loss: 2.3321546461215887
Validation loss: 2.6067115416184463

Epoch: 5| Step: 1
Training loss: 2.037950585280029
Validation loss: 2.6925059168061987

Epoch: 5| Step: 2
Training loss: 2.0232939798130074
Validation loss: 2.701958737310765

Epoch: 5| Step: 3
Training loss: 1.8991222637967549
Validation loss: 2.6798219563641883

Epoch: 5| Step: 4
Training loss: 1.9204865689452304
Validation loss: 2.6558195176696358

Epoch: 5| Step: 5
Training loss: 2.203431777697804
Validation loss: 2.655378587686086

Epoch: 5| Step: 6
Training loss: 2.770169161785252
Validation loss: 2.6026889435800515

Epoch: 5| Step: 7
Training loss: 2.27189033009894
Validation loss: 2.5656534578245114

Epoch: 5| Step: 8
Training loss: 2.279383483653367
Validation loss: 2.5528851294080663

Epoch: 5| Step: 9
Training loss: 1.8398301433861908
Validation loss: 2.536796955845124

Epoch: 5| Step: 10
Training loss: 2.0258861439562503
Validation loss: 2.5052927218451093

Epoch: 5| Step: 11
Training loss: 2.3151624662927675
Validation loss: 2.4431440999034346

Epoch: 325| Step: 0
Training loss: 1.1527380834330438
Validation loss: 2.455403765859158

Epoch: 5| Step: 1
Training loss: 2.102166071442751
Validation loss: 2.44119967794697

Epoch: 5| Step: 2
Training loss: 2.033774816810643
Validation loss: 2.4697724289441845

Epoch: 5| Step: 3
Training loss: 1.8389384964433073
Validation loss: 2.4660658066416072

Epoch: 5| Step: 4
Training loss: 2.0301996890165053
Validation loss: 2.464403587734686

Epoch: 5| Step: 5
Training loss: 2.083959892150587
Validation loss: 2.4826819260889845

Epoch: 5| Step: 6
Training loss: 2.5228034483634882
Validation loss: 2.4982390360906406

Epoch: 5| Step: 7
Training loss: 1.8900030705260509
Validation loss: 2.5122647757361265

Epoch: 5| Step: 8
Training loss: 2.42360463061069
Validation loss: 2.4907303260157163

Epoch: 5| Step: 9
Training loss: 2.0228487432242352
Validation loss: 2.4717628066125124

Epoch: 5| Step: 10
Training loss: 2.2017161958000275
Validation loss: 2.462502376600432

Epoch: 5| Step: 11
Training loss: 1.3502966625482853
Validation loss: 2.4800166601664833

Epoch: 326| Step: 0
Training loss: 1.893604484481723
Validation loss: 2.453299601227301

Epoch: 5| Step: 1
Training loss: 1.7732051075322042
Validation loss: 2.478274627023157

Epoch: 5| Step: 2
Training loss: 2.6028986984747378
Validation loss: 2.4723776348487054

Epoch: 5| Step: 3
Training loss: 2.2960612613732683
Validation loss: 2.51129609977242

Epoch: 5| Step: 4
Training loss: 2.0696555192847574
Validation loss: 2.5137600827690667

Epoch: 5| Step: 5
Training loss: 2.6483553983402546
Validation loss: 2.504573746936124

Epoch: 5| Step: 6
Training loss: 2.1155635898078677
Validation loss: 2.5467989467506835

Epoch: 5| Step: 7
Training loss: 1.6921287913894645
Validation loss: 2.51046024115854

Epoch: 5| Step: 8
Training loss: 1.5779004078804628
Validation loss: 2.488530743844955

Epoch: 5| Step: 9
Training loss: 2.0333175700259347
Validation loss: 2.5208815157570568

Epoch: 5| Step: 10
Training loss: 1.5690439138886259
Validation loss: 2.5343839823967005

Epoch: 5| Step: 11
Training loss: 3.0680187092077564
Validation loss: 2.4823119996828624

Epoch: 327| Step: 0
Training loss: 1.9292128747578874
Validation loss: 2.475349056791214

Epoch: 5| Step: 1
Training loss: 1.5344638961865318
Validation loss: 2.4536917653349852

Epoch: 5| Step: 2
Training loss: 1.9410877849257209
Validation loss: 2.436235588974507

Epoch: 5| Step: 3
Training loss: 1.7352481053414421
Validation loss: 2.4493451935061854

Epoch: 5| Step: 4
Training loss: 2.5694046040330187
Validation loss: 2.439799613769225

Epoch: 5| Step: 5
Training loss: 1.9471878755557157
Validation loss: 2.4282113688723284

Epoch: 5| Step: 6
Training loss: 2.6688813509990377
Validation loss: 2.421921965441061

Epoch: 5| Step: 7
Training loss: 1.7469655022012736
Validation loss: 2.4165001694008095

Epoch: 5| Step: 8
Training loss: 2.76889052195915
Validation loss: 2.4632470087102725

Epoch: 5| Step: 9
Training loss: 1.6487945603833891
Validation loss: 2.491082072865991

Epoch: 5| Step: 10
Training loss: 2.393405668428265
Validation loss: 2.5372718404662504

Epoch: 5| Step: 11
Training loss: 2.8197007295065006
Validation loss: 2.5149897766537483

Epoch: 328| Step: 0
Training loss: 1.8319392394688512
Validation loss: 2.531176116634306

Epoch: 5| Step: 1
Training loss: 2.239683660581355
Validation loss: 2.5226953830481627

Epoch: 5| Step: 2
Training loss: 2.1804775323967704
Validation loss: 2.5148009970598837

Epoch: 5| Step: 3
Training loss: 2.0531218042450394
Validation loss: 2.4928745889170334

Epoch: 5| Step: 4
Training loss: 2.040333435820575
Validation loss: 2.4768060349861156

Epoch: 5| Step: 5
Training loss: 2.616924397922752
Validation loss: 2.4755739230554736

Epoch: 5| Step: 6
Training loss: 1.7062187443479964
Validation loss: 2.4811784905315304

Epoch: 5| Step: 7
Training loss: 1.8991058805657375
Validation loss: 2.4502570665366123

Epoch: 5| Step: 8
Training loss: 1.2211111622726372
Validation loss: 2.503600210450391

Epoch: 5| Step: 9
Training loss: 2.3572523661354903
Validation loss: 2.484665875630841

Epoch: 5| Step: 10
Training loss: 2.3060850916677396
Validation loss: 2.497508774723833

Epoch: 5| Step: 11
Training loss: 1.513154996175194
Validation loss: 2.4879669917233236

Epoch: 329| Step: 0
Training loss: 1.8505912196906804
Validation loss: 2.5136626904647588

Epoch: 5| Step: 1
Training loss: 1.9567042399258876
Validation loss: 2.5130424551288946

Epoch: 5| Step: 2
Training loss: 1.5849363427360459
Validation loss: 2.5308695672099795

Epoch: 5| Step: 3
Training loss: 1.888439712535743
Validation loss: 2.534698231393393

Epoch: 5| Step: 4
Training loss: 2.15022031852852
Validation loss: 2.5219921858487746

Epoch: 5| Step: 5
Training loss: 1.9623137124447212
Validation loss: 2.552168585203244

Epoch: 5| Step: 6
Training loss: 1.7664541137635317
Validation loss: 2.5499012603841225

Epoch: 5| Step: 7
Training loss: 2.2480797520809417
Validation loss: 2.5597606531400814

Epoch: 5| Step: 8
Training loss: 2.274898937621538
Validation loss: 2.5355750797426713

Epoch: 5| Step: 9
Training loss: 2.433073279014565
Validation loss: 2.5269896796269493

Epoch: 5| Step: 10
Training loss: 2.064537313688129
Validation loss: 2.5078090140852267

Epoch: 5| Step: 11
Training loss: 1.5808774908906869
Validation loss: 2.4933643472295124

Epoch: 330| Step: 0
Training loss: 1.8164242323118618
Validation loss: 2.4932841217144963

Epoch: 5| Step: 1
Training loss: 2.178624704142837
Validation loss: 2.4813410108900347

Epoch: 5| Step: 2
Training loss: 1.7611292764239619
Validation loss: 2.4948130641861153

Epoch: 5| Step: 3
Training loss: 2.504498249597865
Validation loss: 2.4931783430440344

Epoch: 5| Step: 4
Training loss: 1.883604714018763
Validation loss: 2.5145883655471404

Epoch: 5| Step: 5
Training loss: 1.5846016054038663
Validation loss: 2.5072567523025144

Epoch: 5| Step: 6
Training loss: 2.404379675126594
Validation loss: 2.512116162949312

Epoch: 5| Step: 7
Training loss: 2.04762277703141
Validation loss: 2.5638064798860194

Epoch: 5| Step: 8
Training loss: 1.5891967506675042
Validation loss: 2.565939661013554

Epoch: 5| Step: 9
Training loss: 1.437651004323561
Validation loss: 2.5661363309747913

Epoch: 5| Step: 10
Training loss: 2.347374719886351
Validation loss: 2.561747556793754

Epoch: 5| Step: 11
Training loss: 1.2440418341922175
Validation loss: 2.555753339724787

Epoch: 331| Step: 0
Training loss: 1.63429929948185
Validation loss: 2.580871383079391

Epoch: 5| Step: 1
Training loss: 2.218714431692514
Validation loss: 2.558572441963595

Epoch: 5| Step: 2
Training loss: 1.9777076027715894
Validation loss: 2.57828971066917

Epoch: 5| Step: 3
Training loss: 1.890806961761112
Validation loss: 2.543397081185747

Epoch: 5| Step: 4
Training loss: 2.1803935558402316
Validation loss: 2.561903954012158

Epoch: 5| Step: 5
Training loss: 1.630706889624676
Validation loss: 2.537124790363109

Epoch: 5| Step: 6
Training loss: 2.4117674550488206
Validation loss: 2.484122181470305

Epoch: 5| Step: 7
Training loss: 2.224336388025864
Validation loss: 2.5103418779642683

Epoch: 5| Step: 8
Training loss: 1.565526624927709
Validation loss: 2.496433786106361

Epoch: 5| Step: 9
Training loss: 2.0577875111191557
Validation loss: 2.5369350499735748

Epoch: 5| Step: 10
Training loss: 2.075667225753654
Validation loss: 2.5219763333249805

Epoch: 5| Step: 11
Training loss: 1.9235268913711612
Validation loss: 2.530053303255064

Epoch: 332| Step: 0
Training loss: 1.8844228482220993
Validation loss: 2.565647549206807

Epoch: 5| Step: 1
Training loss: 1.7931311041434557
Validation loss: 2.5866481154205094

Epoch: 5| Step: 2
Training loss: 1.6680543685486773
Validation loss: 2.601861159524325

Epoch: 5| Step: 3
Training loss: 1.6157228775923467
Validation loss: 2.568216882192928

Epoch: 5| Step: 4
Training loss: 1.8324337905434576
Validation loss: 2.551684696178248

Epoch: 5| Step: 5
Training loss: 2.341386340683205
Validation loss: 2.5369362717000756

Epoch: 5| Step: 6
Training loss: 2.289274759183499
Validation loss: 2.521145432175662

Epoch: 5| Step: 7
Training loss: 2.042349902162646
Validation loss: 2.541862930995808

Epoch: 5| Step: 8
Training loss: 2.151836134631347
Validation loss: 2.541348290175832

Epoch: 5| Step: 9
Training loss: 2.0315333242159483
Validation loss: 2.5635295869702066

Epoch: 5| Step: 10
Training loss: 2.011859422228191
Validation loss: 2.542098178087588

Epoch: 5| Step: 11
Training loss: 2.525543184680386
Validation loss: 2.564991867524727

Epoch: 333| Step: 0
Training loss: 2.161792432096619
Validation loss: 2.597140734771748

Epoch: 5| Step: 1
Training loss: 1.9450114679856525
Validation loss: 2.633739327166344

Epoch: 5| Step: 2
Training loss: 1.893114326978428
Validation loss: 2.680410411811013

Epoch: 5| Step: 3
Training loss: 2.9027744964467495
Validation loss: 2.713300940781471

Epoch: 5| Step: 4
Training loss: 1.862651598604313
Validation loss: 2.731713283770236

Epoch: 5| Step: 5
Training loss: 1.9050210837451511
Validation loss: 2.7066845031872493

Epoch: 5| Step: 6
Training loss: 2.1003845770963236
Validation loss: 2.6608937455330275

Epoch: 5| Step: 7
Training loss: 2.133877889848761
Validation loss: 2.5870927264394825

Epoch: 5| Step: 8
Training loss: 1.8901874887225323
Validation loss: 2.5076084469879776

Epoch: 5| Step: 9
Training loss: 2.278485648201467
Validation loss: 2.494641912076364

Epoch: 5| Step: 10
Training loss: 1.4722299135754964
Validation loss: 2.4804319884612367

Epoch: 5| Step: 11
Training loss: 2.27296290736681
Validation loss: 2.505631394594209

Epoch: 334| Step: 0
Training loss: 1.989470899777016
Validation loss: 2.4849633773699384

Epoch: 5| Step: 1
Training loss: 2.160989721278186
Validation loss: 2.4914925821170804

Epoch: 5| Step: 2
Training loss: 1.85181795442428
Validation loss: 2.4828274863454802

Epoch: 5| Step: 3
Training loss: 1.9640333199287026
Validation loss: 2.4999366354859487

Epoch: 5| Step: 4
Training loss: 1.572932396951127
Validation loss: 2.533638196459856

Epoch: 5| Step: 5
Training loss: 1.8139470999300404
Validation loss: 2.5154078530049806

Epoch: 5| Step: 6
Training loss: 2.1918229031687257
Validation loss: 2.5702823300895457

Epoch: 5| Step: 7
Training loss: 2.362774553442005
Validation loss: 2.577261207833723

Epoch: 5| Step: 8
Training loss: 2.5163642318424695
Validation loss: 2.532578947550755

Epoch: 5| Step: 9
Training loss: 2.29151425866309
Validation loss: 2.5130178672232772

Epoch: 5| Step: 10
Training loss: 2.236306589347726
Validation loss: 2.4729183393588965

Epoch: 5| Step: 11
Training loss: 1.463295242723323
Validation loss: 2.46609919314942

Epoch: 335| Step: 0
Training loss: 1.954651564062685
Validation loss: 2.467723061445306

Epoch: 5| Step: 1
Training loss: 2.845063629243353
Validation loss: 2.4589706594232617

Epoch: 5| Step: 2
Training loss: 2.299370687884564
Validation loss: 2.4649814097739684

Epoch: 5| Step: 3
Training loss: 1.8413102122896294
Validation loss: 2.4743882210656034

Epoch: 5| Step: 4
Training loss: 2.4168007144801913
Validation loss: 2.4614732229842797

Epoch: 5| Step: 5
Training loss: 1.6861972725374816
Validation loss: 2.461333671853768

Epoch: 5| Step: 6
Training loss: 2.415706432790932
Validation loss: 2.474806735812856

Epoch: 5| Step: 7
Training loss: 1.2300630415291178
Validation loss: 2.483037476602591

Epoch: 5| Step: 8
Training loss: 1.8027340443653204
Validation loss: 2.4883684854671126

Epoch: 5| Step: 9
Training loss: 1.595800838023414
Validation loss: 2.487335756045688

Epoch: 5| Step: 10
Training loss: 1.508796963470413
Validation loss: 2.51287081308539

Epoch: 5| Step: 11
Training loss: 1.7790649128865186
Validation loss: 2.494577073415974

Epoch: 336| Step: 0
Training loss: 1.516222806405223
Validation loss: 2.5009968717208

Epoch: 5| Step: 1
Training loss: 2.451864514003932
Validation loss: 2.52045898508445

Epoch: 5| Step: 2
Training loss: 2.01619966580116
Validation loss: 2.514353156175455

Epoch: 5| Step: 3
Training loss: 2.5434745133272063
Validation loss: 2.5167115196963668

Epoch: 5| Step: 4
Training loss: 1.868513458489305
Validation loss: 2.5456408258276007

Epoch: 5| Step: 5
Training loss: 1.8291186379258362
Validation loss: 2.518976567445599

Epoch: 5| Step: 6
Training loss: 1.6746715081204653
Validation loss: 2.5648877912681716

Epoch: 5| Step: 7
Training loss: 2.416804463195973
Validation loss: 2.5953707437948093

Epoch: 5| Step: 8
Training loss: 1.967088573534751
Validation loss: 2.598831591576831

Epoch: 5| Step: 9
Training loss: 1.7407613485137037
Validation loss: 2.609473228509252

Epoch: 5| Step: 10
Training loss: 1.8316286209894355
Validation loss: 2.6129611417509104

Epoch: 5| Step: 11
Training loss: 1.3660475856149927
Validation loss: 2.586869524193973

Epoch: 337| Step: 0
Training loss: 2.0783028203849927
Validation loss: 2.579841939861476

Epoch: 5| Step: 1
Training loss: 1.616778483243575
Validation loss: 2.5698158224883025

Epoch: 5| Step: 2
Training loss: 2.78351166738234
Validation loss: 2.5551657739374427

Epoch: 5| Step: 3
Training loss: 1.3744683971997385
Validation loss: 2.5395490874583273

Epoch: 5| Step: 4
Training loss: 1.9180082173375306
Validation loss: 2.529541341585663

Epoch: 5| Step: 5
Training loss: 1.8163600464553757
Validation loss: 2.501664934477523

Epoch: 5| Step: 6
Training loss: 1.6354607092237938
Validation loss: 2.5120035013065114

Epoch: 5| Step: 7
Training loss: 2.376628819129061
Validation loss: 2.488804908317891

Epoch: 5| Step: 8
Training loss: 2.089695891381574
Validation loss: 2.5016405365443553

Epoch: 5| Step: 9
Training loss: 1.6458426205658738
Validation loss: 2.5153927784707415

Epoch: 5| Step: 10
Training loss: 1.6881504924364787
Validation loss: 2.5205177682342246

Epoch: 5| Step: 11
Training loss: 2.62978553521236
Validation loss: 2.5235050495503573

Epoch: 338| Step: 0
Training loss: 2.6914412408998554
Validation loss: 2.537500262769363

Epoch: 5| Step: 1
Training loss: 2.258942212538024
Validation loss: 2.583265478001829

Epoch: 5| Step: 2
Training loss: 2.0346616997106146
Validation loss: 2.582322408676018

Epoch: 5| Step: 3
Training loss: 2.258460245636798
Validation loss: 2.603869056226196

Epoch: 5| Step: 4
Training loss: 1.8717159757745636
Validation loss: 2.5929304536353515

Epoch: 5| Step: 5
Training loss: 1.599506975746028
Validation loss: 2.5624921438050214

Epoch: 5| Step: 6
Training loss: 1.6151649247983024
Validation loss: 2.5412133404072903

Epoch: 5| Step: 7
Training loss: 2.003430166818672
Validation loss: 2.4863793327130526

Epoch: 5| Step: 8
Training loss: 1.67791541014325
Validation loss: 2.519427444724739

Epoch: 5| Step: 9
Training loss: 1.8775070595640295
Validation loss: 2.486153467860584

Epoch: 5| Step: 10
Training loss: 1.625745602262281
Validation loss: 2.4903352365450333

Epoch: 5| Step: 11
Training loss: 1.5488656846407365
Validation loss: 2.483425634757505

Epoch: 339| Step: 0
Training loss: 1.3271708033952856
Validation loss: 2.493807956433191

Epoch: 5| Step: 1
Training loss: 1.7977423523363716
Validation loss: 2.533995709022205

Epoch: 5| Step: 2
Training loss: 1.8886271237709769
Validation loss: 2.5241361306405596

Epoch: 5| Step: 3
Training loss: 1.9558993966845974
Validation loss: 2.5612409530201847

Epoch: 5| Step: 4
Training loss: 1.9857326879168122
Validation loss: 2.592136566814487

Epoch: 5| Step: 5
Training loss: 1.7055741644944145
Validation loss: 2.591784667173419

Epoch: 5| Step: 6
Training loss: 1.9883776568289933
Validation loss: 2.597258722391077

Epoch: 5| Step: 7
Training loss: 1.9381498046980399
Validation loss: 2.602917597989186

Epoch: 5| Step: 8
Training loss: 2.507113160162035
Validation loss: 2.583258652120327

Epoch: 5| Step: 9
Training loss: 1.9333525536118903
Validation loss: 2.560181095738818

Epoch: 5| Step: 10
Training loss: 2.3721769520144784
Validation loss: 2.537999749417364

Epoch: 5| Step: 11
Training loss: 1.3991454479584482
Validation loss: 2.5216840433008207

Epoch: 340| Step: 0
Training loss: 1.9211030976144456
Validation loss: 2.4973833337709013

Epoch: 5| Step: 1
Training loss: 1.561015377450355
Validation loss: 2.495389402188247

Epoch: 5| Step: 2
Training loss: 1.3706620017509143
Validation loss: 2.491437518120075

Epoch: 5| Step: 3
Training loss: 2.092048295099987
Validation loss: 2.5076880399375088

Epoch: 5| Step: 4
Training loss: 1.7906677507286928
Validation loss: 2.4937279125022624

Epoch: 5| Step: 5
Training loss: 2.077394055764877
Validation loss: 2.5029547237752015

Epoch: 5| Step: 6
Training loss: 2.4059879110703264
Validation loss: 2.5024113866974815

Epoch: 5| Step: 7
Training loss: 2.428842084692928
Validation loss: 2.502003808442502

Epoch: 5| Step: 8
Training loss: 2.098837521644003
Validation loss: 2.5547749779488043

Epoch: 5| Step: 9
Training loss: 1.8929228886910627
Validation loss: 2.6010385315957283

Epoch: 5| Step: 10
Training loss: 1.915001276976954
Validation loss: 2.6082803672576205

Epoch: 5| Step: 11
Training loss: 2.6711681836477523
Validation loss: 2.647616327562034

Epoch: 341| Step: 0
Training loss: 1.9378950885213033
Validation loss: 2.6400495537950186

Epoch: 5| Step: 1
Training loss: 2.1605644737110383
Validation loss: 2.6036310039193844

Epoch: 5| Step: 2
Training loss: 1.9991472333583966
Validation loss: 2.5470395337338996

Epoch: 5| Step: 3
Training loss: 1.8694418223027127
Validation loss: 2.518169415516895

Epoch: 5| Step: 4
Training loss: 2.801846566295305
Validation loss: 2.4900649547913805

Epoch: 5| Step: 5
Training loss: 1.8632758118492116
Validation loss: 2.470817722080397

Epoch: 5| Step: 6
Training loss: 1.4722396301743836
Validation loss: 2.4762784793017767

Epoch: 5| Step: 7
Training loss: 2.2906289843515504
Validation loss: 2.4643002942215366

Epoch: 5| Step: 8
Training loss: 1.7579205967196976
Validation loss: 2.477280321194418

Epoch: 5| Step: 9
Training loss: 1.6667510329192254
Validation loss: 2.4854558476900777

Epoch: 5| Step: 10
Training loss: 1.818923420192164
Validation loss: 2.4567548457882973

Epoch: 5| Step: 11
Training loss: 0.9645622553214848
Validation loss: 2.4946419718090294

Epoch: 342| Step: 0
Training loss: 1.9683017523178428
Validation loss: 2.469564017963729

Epoch: 5| Step: 1
Training loss: 2.2046325071141815
Validation loss: 2.46995242730041

Epoch: 5| Step: 2
Training loss: 2.4343515260321222
Validation loss: 2.477892900399664

Epoch: 5| Step: 3
Training loss: 1.4618733718295447
Validation loss: 2.489888102073866

Epoch: 5| Step: 4
Training loss: 2.129657689737429
Validation loss: 2.520276565122145

Epoch: 5| Step: 5
Training loss: 1.6639546104164389
Validation loss: 2.5116658855311296

Epoch: 5| Step: 6
Training loss: 1.5778686012997183
Validation loss: 2.5634202855305785

Epoch: 5| Step: 7
Training loss: 1.7864059648169066
Validation loss: 2.5813268180543605

Epoch: 5| Step: 8
Training loss: 2.410383167435207
Validation loss: 2.566687047452225

Epoch: 5| Step: 9
Training loss: 1.920890431855299
Validation loss: 2.532639312549436

Epoch: 5| Step: 10
Training loss: 1.6843398138274277
Validation loss: 2.534815141783345

Epoch: 5| Step: 11
Training loss: 0.9993146097283947
Validation loss: 2.4961219511394113

Epoch: 343| Step: 0
Training loss: 1.7405863704538318
Validation loss: 2.4774395726363654

Epoch: 5| Step: 1
Training loss: 1.6525502898719997
Validation loss: 2.489946511778015

Epoch: 5| Step: 2
Training loss: 1.8179520131231277
Validation loss: 2.484813601486387

Epoch: 5| Step: 3
Training loss: 2.450147632121267
Validation loss: 2.487013864857682

Epoch: 5| Step: 4
Training loss: 1.9620158965140493
Validation loss: 2.502763837681894

Epoch: 5| Step: 5
Training loss: 2.286661705293454
Validation loss: 2.4894686729703417

Epoch: 5| Step: 6
Training loss: 1.8765671220987714
Validation loss: 2.4771202975488995

Epoch: 5| Step: 7
Training loss: 2.0325116274267656
Validation loss: 2.502412994471588

Epoch: 5| Step: 8
Training loss: 2.0128317707562453
Validation loss: 2.540144188160008

Epoch: 5| Step: 9
Training loss: 1.7232987293529811
Validation loss: 2.559269908444399

Epoch: 5| Step: 10
Training loss: 1.6176957515793056
Validation loss: 2.5970212231908336

Epoch: 5| Step: 11
Training loss: 1.191996443851978
Validation loss: 2.6183561799780484

Epoch: 344| Step: 0
Training loss: 2.219530425026246
Validation loss: 2.6398771005619697

Epoch: 5| Step: 1
Training loss: 2.6598962329042304
Validation loss: 2.6399474582055467

Epoch: 5| Step: 2
Training loss: 2.222102895817845
Validation loss: 2.635864918298756

Epoch: 5| Step: 3
Training loss: 2.511045374567817
Validation loss: 2.586712858315681

Epoch: 5| Step: 4
Training loss: 1.636356796264802
Validation loss: 2.543350366884923

Epoch: 5| Step: 5
Training loss: 1.6590952635644987
Validation loss: 2.511867156917024

Epoch: 5| Step: 6
Training loss: 1.775178768665518
Validation loss: 2.4485908486245607

Epoch: 5| Step: 7
Training loss: 1.554706362509239
Validation loss: 2.440247682458083

Epoch: 5| Step: 8
Training loss: 1.3988540284827147
Validation loss: 2.441404907226193

Epoch: 5| Step: 9
Training loss: 1.9056672002686963
Validation loss: 2.4370057428167353

Epoch: 5| Step: 10
Training loss: 1.900111272966705
Validation loss: 2.4235482004290123

Epoch: 5| Step: 11
Training loss: 2.7125463631179114
Validation loss: 2.428325786659577

Epoch: 345| Step: 0
Training loss: 2.2915778287372026
Validation loss: 2.453471620939745

Epoch: 5| Step: 1
Training loss: 1.9862101922148323
Validation loss: 2.4451567485473316

Epoch: 5| Step: 2
Training loss: 1.7469637280144916
Validation loss: 2.4575040005651014

Epoch: 5| Step: 3
Training loss: 2.5666131294744017
Validation loss: 2.457209052529422

Epoch: 5| Step: 4
Training loss: 1.4343234084082421
Validation loss: 2.4739995183360874

Epoch: 5| Step: 5
Training loss: 2.1188390842490628
Validation loss: 2.5008879475433425

Epoch: 5| Step: 6
Training loss: 1.572906780422375
Validation loss: 2.487537985660227

Epoch: 5| Step: 7
Training loss: 1.7072302660821714
Validation loss: 2.504032540471602

Epoch: 5| Step: 8
Training loss: 1.867993615725633
Validation loss: 2.54010255688529

Epoch: 5| Step: 9
Training loss: 2.1277468262699064
Validation loss: 2.5325230215149075

Epoch: 5| Step: 10
Training loss: 1.5494262771769336
Validation loss: 2.567463471741855

Epoch: 5| Step: 11
Training loss: 1.689738025788222
Validation loss: 2.608515592205645

Epoch: 346| Step: 0
Training loss: 1.7511252464061713
Validation loss: 2.585905046057678

Epoch: 5| Step: 1
Training loss: 1.6368931788905807
Validation loss: 2.5699669510018883

Epoch: 5| Step: 2
Training loss: 2.34340797471847
Validation loss: 2.6001275604390957

Epoch: 5| Step: 3
Training loss: 1.8647783770567294
Validation loss: 2.5416879939659296

Epoch: 5| Step: 4
Training loss: 1.8017785213283135
Validation loss: 2.5485212314243473

Epoch: 5| Step: 5
Training loss: 1.604095837239037
Validation loss: 2.547319673751505

Epoch: 5| Step: 6
Training loss: 1.9485202676895106
Validation loss: 2.539128256704355

Epoch: 5| Step: 7
Training loss: 2.3173893969828496
Validation loss: 2.51254019546936

Epoch: 5| Step: 8
Training loss: 1.758332103650475
Validation loss: 2.5344776838316907

Epoch: 5| Step: 9
Training loss: 2.0675780465871774
Validation loss: 2.5082361451728947

Epoch: 5| Step: 10
Training loss: 1.848134017370193
Validation loss: 2.5357103256601463

Epoch: 5| Step: 11
Training loss: 1.9030815432743713
Validation loss: 2.522005653227032

Epoch: 347| Step: 0
Training loss: 2.0974145959646897
Validation loss: 2.5512034878251577

Epoch: 5| Step: 1
Training loss: 1.3262348862343223
Validation loss: 2.5655875910681316

Epoch: 5| Step: 2
Training loss: 1.7805719256165142
Validation loss: 2.5465949163910486

Epoch: 5| Step: 3
Training loss: 1.8459154763755712
Validation loss: 2.524127039280832

Epoch: 5| Step: 4
Training loss: 2.1916467871205545
Validation loss: 2.525960340206658

Epoch: 5| Step: 5
Training loss: 1.7486933871220267
Validation loss: 2.5091548745536936

Epoch: 5| Step: 6
Training loss: 1.7916783029341048
Validation loss: 2.494457622030474

Epoch: 5| Step: 7
Training loss: 2.2238268727765225
Validation loss: 2.4979181999687556

Epoch: 5| Step: 8
Training loss: 1.6335008986149218
Validation loss: 2.4972406994817695

Epoch: 5| Step: 9
Training loss: 1.6163880957002965
Validation loss: 2.497854806506824

Epoch: 5| Step: 10
Training loss: 2.724555996060897
Validation loss: 2.500063386749321

Epoch: 5| Step: 11
Training loss: 0.3090641564960271
Validation loss: 2.483765033400612

Epoch: 348| Step: 0
Training loss: 2.0324052313262997
Validation loss: 2.4962727298952916

Epoch: 5| Step: 1
Training loss: 2.0406912075828156
Validation loss: 2.509913011470877

Epoch: 5| Step: 2
Training loss: 1.6521531303962342
Validation loss: 2.542492979734538

Epoch: 5| Step: 3
Training loss: 1.8415784817579393
Validation loss: 2.4949827154245034

Epoch: 5| Step: 4
Training loss: 1.8847383012915795
Validation loss: 2.5340431485299844

Epoch: 5| Step: 5
Training loss: 1.8680342665557854
Validation loss: 2.497010800325418

Epoch: 5| Step: 6
Training loss: 2.020011210268848
Validation loss: 2.520361979740471

Epoch: 5| Step: 7
Training loss: 1.5852757468569934
Validation loss: 2.482220549264363

Epoch: 5| Step: 8
Training loss: 1.3470165116389141
Validation loss: 2.517671210967948

Epoch: 5| Step: 9
Training loss: 2.032950173949062
Validation loss: 2.5102943724342572

Epoch: 5| Step: 10
Training loss: 2.4571783509970127
Validation loss: 2.532492999619163

Epoch: 5| Step: 11
Training loss: 2.112689769279499
Validation loss: 2.484852291139594

Epoch: 349| Step: 0
Training loss: 1.8794285926497407
Validation loss: 2.541632532192796

Epoch: 5| Step: 1
Training loss: 1.2773001660485377
Validation loss: 2.554578745760138

Epoch: 5| Step: 2
Training loss: 2.2723032425745027
Validation loss: 2.5679592889453455

Epoch: 5| Step: 3
Training loss: 1.9187575697361243
Validation loss: 2.5770297141781686

Epoch: 5| Step: 4
Training loss: 2.1375711752658417
Validation loss: 2.579617209105531

Epoch: 5| Step: 5
Training loss: 2.1435226542310346
Validation loss: 2.6130539472607066

Epoch: 5| Step: 6
Training loss: 2.2984983974249555
Validation loss: 2.614340297199021

Epoch: 5| Step: 7
Training loss: 1.5687309385562644
Validation loss: 2.557860073671734

Epoch: 5| Step: 8
Training loss: 1.5606921609368443
Validation loss: 2.542706967819287

Epoch: 5| Step: 9
Training loss: 1.9580995000742842
Validation loss: 2.504362309779691

Epoch: 5| Step: 10
Training loss: 1.9586531871637383
Validation loss: 2.5010608250271997

Epoch: 5| Step: 11
Training loss: 2.1562704555259917
Validation loss: 2.502966360715772

Epoch: 350| Step: 0
Training loss: 1.914289064038402
Validation loss: 2.4771137486465524

Epoch: 5| Step: 1
Training loss: 1.8176235918842747
Validation loss: 2.498642087746387

Epoch: 5| Step: 2
Training loss: 1.9583360049723264
Validation loss: 2.513244916712359

Epoch: 5| Step: 3
Training loss: 1.6999645481900938
Validation loss: 2.5327247161996413

Epoch: 5| Step: 4
Training loss: 2.3701123590031163
Validation loss: 2.5330361904649226

Epoch: 5| Step: 5
Training loss: 1.81128783634701
Validation loss: 2.5232129503931224

Epoch: 5| Step: 6
Training loss: 1.8073898493969824
Validation loss: 2.555104926378493

Epoch: 5| Step: 7
Training loss: 1.945317034735239
Validation loss: 2.5537437733471444

Epoch: 5| Step: 8
Training loss: 1.7766086944774437
Validation loss: 2.5720418892129318

Epoch: 5| Step: 9
Training loss: 2.090470435753931
Validation loss: 2.5317965769026243

Epoch: 5| Step: 10
Training loss: 1.633684354483331
Validation loss: 2.5436061249831146

Epoch: 5| Step: 11
Training loss: 1.3023548860308376
Validation loss: 2.5582302776873607

Epoch: 351| Step: 0
Training loss: 1.5684991491605464
Validation loss: 2.5148069105860054

Epoch: 5| Step: 1
Training loss: 2.2939347112223105
Validation loss: 2.5034957723851687

Epoch: 5| Step: 2
Training loss: 2.568751919413868
Validation loss: 2.5468936385114356

Epoch: 5| Step: 3
Training loss: 1.4235689741065223
Validation loss: 2.4841675061921147

Epoch: 5| Step: 4
Training loss: 2.199053634489077
Validation loss: 2.505284777457739

Epoch: 5| Step: 5
Training loss: 1.7609370288323598
Validation loss: 2.5632174735761715

Epoch: 5| Step: 6
Training loss: 1.9236282167312981
Validation loss: 2.5729031054078884

Epoch: 5| Step: 7
Training loss: 2.0649415794403154
Validation loss: 2.5574225523655323

Epoch: 5| Step: 8
Training loss: 1.3945356951303454
Validation loss: 2.6165429303703873

Epoch: 5| Step: 9
Training loss: 1.9784842937733946
Validation loss: 2.6161218229074614

Epoch: 5| Step: 10
Training loss: 1.679268363289994
Validation loss: 2.6077793100179

Epoch: 5| Step: 11
Training loss: 2.0639606274538496
Validation loss: 2.578818072013672

Epoch: 352| Step: 0
Training loss: 1.9448684124207685
Validation loss: 2.516571672385674

Epoch: 5| Step: 1
Training loss: 1.418701655030517
Validation loss: 2.5240688301886456

Epoch: 5| Step: 2
Training loss: 2.0314995245626664
Validation loss: 2.516104362260263

Epoch: 5| Step: 3
Training loss: 2.170575528447426
Validation loss: 2.509054939789808

Epoch: 5| Step: 4
Training loss: 2.440502957896179
Validation loss: 2.5165498348510926

Epoch: 5| Step: 5
Training loss: 1.5236064328160768
Validation loss: 2.505774702949373

Epoch: 5| Step: 6
Training loss: 2.0459902649439967
Validation loss: 2.5077039808044495

Epoch: 5| Step: 7
Training loss: 1.5242381803915537
Validation loss: 2.519379871956422

Epoch: 5| Step: 8
Training loss: 2.2123064850915823
Validation loss: 2.521873379107667

Epoch: 5| Step: 9
Training loss: 1.8591296891667772
Validation loss: 2.54474367780144

Epoch: 5| Step: 10
Training loss: 1.6941463837142008
Validation loss: 2.5362909811427494

Epoch: 5| Step: 11
Training loss: 3.186654072128796
Validation loss: 2.5182090897862714

Epoch: 353| Step: 0
Training loss: 1.779568263104483
Validation loss: 2.5328635147670955

Epoch: 5| Step: 1
Training loss: 2.4484667437279195
Validation loss: 2.561961024287918

Epoch: 5| Step: 2
Training loss: 1.5709143856329426
Validation loss: 2.5605031234529974

Epoch: 5| Step: 3
Training loss: 1.9378225611779396
Validation loss: 2.5192186107405563

Epoch: 5| Step: 4
Training loss: 1.8540868491948537
Validation loss: 2.506724956628175

Epoch: 5| Step: 5
Training loss: 2.0592353877671843
Validation loss: 2.477633492375957

Epoch: 5| Step: 6
Training loss: 2.062079762504334
Validation loss: 2.486785183409759

Epoch: 5| Step: 7
Training loss: 1.2912808836856138
Validation loss: 2.514980632481157

Epoch: 5| Step: 8
Training loss: 1.903662567134703
Validation loss: 2.5073065143320443

Epoch: 5| Step: 9
Training loss: 1.764528322169284
Validation loss: 2.4847252676819394

Epoch: 5| Step: 10
Training loss: 1.5226948028115008
Validation loss: 2.475959872985234

Epoch: 5| Step: 11
Training loss: 3.1742801661257127
Validation loss: 2.5194184704361957

Epoch: 354| Step: 0
Training loss: 2.0887214285210787
Validation loss: 2.595537779827828

Epoch: 5| Step: 1
Training loss: 2.0737843318992244
Validation loss: 2.668831004060649

Epoch: 5| Step: 2
Training loss: 1.95344077037244
Validation loss: 2.7474863962490974

Epoch: 5| Step: 3
Training loss: 1.9298415643758244
Validation loss: 2.7570234147801216

Epoch: 5| Step: 4
Training loss: 1.9388239244230407
Validation loss: 2.730262774046341

Epoch: 5| Step: 5
Training loss: 2.392783194336691
Validation loss: 2.671667083473276

Epoch: 5| Step: 6
Training loss: 2.3147006518151385
Validation loss: 2.5773517527961425

Epoch: 5| Step: 7
Training loss: 1.5655192387049643
Validation loss: 2.5105441022847423

Epoch: 5| Step: 8
Training loss: 1.930814344532
Validation loss: 2.479461677747184

Epoch: 5| Step: 9
Training loss: 1.463428352648315
Validation loss: 2.440788496062989

Epoch: 5| Step: 10
Training loss: 2.189334318287791
Validation loss: 2.457298369409967

Epoch: 5| Step: 11
Training loss: 2.432421749538298
Validation loss: 2.474982763641398

Epoch: 355| Step: 0
Training loss: 1.3814204046160425
Validation loss: 2.487155170437452

Epoch: 5| Step: 1
Training loss: 1.834115735631889
Validation loss: 2.4597483431147564

Epoch: 5| Step: 2
Training loss: 2.1121742042453766
Validation loss: 2.452314599333714

Epoch: 5| Step: 3
Training loss: 2.272210068373546
Validation loss: 2.452919285241862

Epoch: 5| Step: 4
Training loss: 1.9954883232109601
Validation loss: 2.4593934841665095

Epoch: 5| Step: 5
Training loss: 1.5183497839551885
Validation loss: 2.4621021562563574

Epoch: 5| Step: 6
Training loss: 2.3652739895590984
Validation loss: 2.4753650172950072

Epoch: 5| Step: 7
Training loss: 1.4744232666601538
Validation loss: 2.471543437810137

Epoch: 5| Step: 8
Training loss: 1.972184651722889
Validation loss: 2.5284482654164293

Epoch: 5| Step: 9
Training loss: 2.168505902803676
Validation loss: 2.573908554165967

Epoch: 5| Step: 10
Training loss: 2.046958513958559
Validation loss: 2.5822722091239245

Epoch: 5| Step: 11
Training loss: 1.3907153068108813
Validation loss: 2.6004481750052064

Epoch: 356| Step: 0
Training loss: 1.8862790687298032
Validation loss: 2.6648744183045596

Epoch: 5| Step: 1
Training loss: 2.106031466503488
Validation loss: 2.658500413716334

Epoch: 5| Step: 2
Training loss: 1.8992261465125537
Validation loss: 2.6620415436127582

Epoch: 5| Step: 3
Training loss: 2.0595824674027887
Validation loss: 2.6321138498267236

Epoch: 5| Step: 4
Training loss: 1.6352643308537906
Validation loss: 2.5860335801821566

Epoch: 5| Step: 5
Training loss: 1.640451767267914
Validation loss: 2.544748362327464

Epoch: 5| Step: 6
Training loss: 1.9015441091207652
Validation loss: 2.4528152448438174

Epoch: 5| Step: 7
Training loss: 2.345146271916131
Validation loss: 2.457123985622683

Epoch: 5| Step: 8
Training loss: 1.9443690451883662
Validation loss: 2.446538733497142

Epoch: 5| Step: 9
Training loss: 1.8151314148209954
Validation loss: 2.4647924596222954

Epoch: 5| Step: 10
Training loss: 1.7890477742084667
Validation loss: 2.4711563880709044

Epoch: 5| Step: 11
Training loss: 3.5172194192625095
Validation loss: 2.4561002834529324

Epoch: 357| Step: 0
Training loss: 2.161199224790116
Validation loss: 2.4393047311044613

Epoch: 5| Step: 1
Training loss: 2.1669166005082774
Validation loss: 2.4662374716426174

Epoch: 5| Step: 2
Training loss: 1.4774734674127212
Validation loss: 2.4378484656191857

Epoch: 5| Step: 3
Training loss: 1.565080343140252
Validation loss: 2.4578102061686775

Epoch: 5| Step: 4
Training loss: 1.7333365415885773
Validation loss: 2.5150599230041673

Epoch: 5| Step: 5
Training loss: 1.7352688522249091
Validation loss: 2.5629716648428724

Epoch: 5| Step: 6
Training loss: 2.273094964194756
Validation loss: 2.620144110621989

Epoch: 5| Step: 7
Training loss: 2.722665094391347
Validation loss: 2.6449770154957903

Epoch: 5| Step: 8
Training loss: 1.6649880857299126
Validation loss: 2.5451008872062806

Epoch: 5| Step: 9
Training loss: 1.8279279292901445
Validation loss: 2.5486873290635645

Epoch: 5| Step: 10
Training loss: 1.5936980145521686
Validation loss: 2.510466744621212

Epoch: 5| Step: 11
Training loss: 2.821453001251136
Validation loss: 2.4784605091761507

Epoch: 358| Step: 0
Training loss: 1.3760320085085018
Validation loss: 2.4791680557717246

Epoch: 5| Step: 1
Training loss: 1.608811659501979
Validation loss: 2.4550044884028845

Epoch: 5| Step: 2
Training loss: 2.470453278344316
Validation loss: 2.452427924993112

Epoch: 5| Step: 3
Training loss: 1.617422335615923
Validation loss: 2.454304482444538

Epoch: 5| Step: 4
Training loss: 2.680084910826883
Validation loss: 2.4531113286052495

Epoch: 5| Step: 5
Training loss: 1.9835874541619576
Validation loss: 2.454008826008827

Epoch: 5| Step: 6
Training loss: 1.676359205905865
Validation loss: 2.4662400858403175

Epoch: 5| Step: 7
Training loss: 1.4820714644474369
Validation loss: 2.449738613120495

Epoch: 5| Step: 8
Training loss: 2.3923537043982943
Validation loss: 2.4497460097401014

Epoch: 5| Step: 9
Training loss: 1.5870383064343745
Validation loss: 2.4680531157986785

Epoch: 5| Step: 10
Training loss: 2.1928205906877873
Validation loss: 2.4730354890072697

Epoch: 5| Step: 11
Training loss: 1.2673565828193114
Validation loss: 2.476244732579793

Epoch: 359| Step: 0
Training loss: 2.0222714868187572
Validation loss: 2.476061917806472

Epoch: 5| Step: 1
Training loss: 1.524276736988022
Validation loss: 2.4488221678420756

Epoch: 5| Step: 2
Training loss: 1.480023319601942
Validation loss: 2.4693026950091843

Epoch: 5| Step: 3
Training loss: 2.1549689869076287
Validation loss: 2.4738282012176462

Epoch: 5| Step: 4
Training loss: 2.0560847995800087
Validation loss: 2.4759290709442943

Epoch: 5| Step: 5
Training loss: 2.018376918839771
Validation loss: 2.4811446583099914

Epoch: 5| Step: 6
Training loss: 1.9035094525859293
Validation loss: 2.4960365507748796

Epoch: 5| Step: 7
Training loss: 2.176195197732789
Validation loss: 2.4943800781142236

Epoch: 5| Step: 8
Training loss: 1.4369981138393524
Validation loss: 2.513336404280806

Epoch: 5| Step: 9
Training loss: 1.5729680168746585
Validation loss: 2.486277078053074

Epoch: 5| Step: 10
Training loss: 1.9687968051735674
Validation loss: 2.490651329887335

Epoch: 5| Step: 11
Training loss: 2.133118659881013
Validation loss: 2.473972570813353

Epoch: 360| Step: 0
Training loss: 1.7011854694580957
Validation loss: 2.5047061255530547

Epoch: 5| Step: 1
Training loss: 1.9375716780662988
Validation loss: 2.5382065215361975

Epoch: 5| Step: 2
Training loss: 1.9718420784645925
Validation loss: 2.6038645200287887

Epoch: 5| Step: 3
Training loss: 2.1016877431314356
Validation loss: 2.6355481598709916

Epoch: 5| Step: 4
Training loss: 2.3041840601489354
Validation loss: 2.6181929142201867

Epoch: 5| Step: 5
Training loss: 1.8584392340667881
Validation loss: 2.569618842647278

Epoch: 5| Step: 6
Training loss: 2.0052077916792763
Validation loss: 2.528844196358431

Epoch: 5| Step: 7
Training loss: 1.2437869157536297
Validation loss: 2.4843564942508403

Epoch: 5| Step: 8
Training loss: 2.421171713820388
Validation loss: 2.469910067408851

Epoch: 5| Step: 9
Training loss: 1.3469709340069782
Validation loss: 2.4598389005052863

Epoch: 5| Step: 10
Training loss: 1.7617717997140203
Validation loss: 2.4839567316185525

Epoch: 5| Step: 11
Training loss: 1.989388448014798
Validation loss: 2.4910929916257216

Epoch: 361| Step: 0
Training loss: 1.6492285977082677
Validation loss: 2.473586640125966

Epoch: 5| Step: 1
Training loss: 1.8498321044617172
Validation loss: 2.4889287220999727

Epoch: 5| Step: 2
Training loss: 1.915999199566445
Validation loss: 2.502271506395804

Epoch: 5| Step: 3
Training loss: 1.6587126076112273
Validation loss: 2.484130911362356

Epoch: 5| Step: 4
Training loss: 1.8714678237109894
Validation loss: 2.5017930356062457

Epoch: 5| Step: 5
Training loss: 1.955874041911254
Validation loss: 2.5026149504737187

Epoch: 5| Step: 6
Training loss: 2.063274238224963
Validation loss: 2.567378335655994

Epoch: 5| Step: 7
Training loss: 1.8808773115180257
Validation loss: 2.5406897685580017

Epoch: 5| Step: 8
Training loss: 1.729318550823641
Validation loss: 2.5183874959525996

Epoch: 5| Step: 9
Training loss: 1.4057275861363985
Validation loss: 2.5253146170703378

Epoch: 5| Step: 10
Training loss: 1.952943045723735
Validation loss: 2.5058504393357057

Epoch: 5| Step: 11
Training loss: 1.797137697339367
Validation loss: 2.4977816375546436

Epoch: 362| Step: 0
Training loss: 1.8145713808678479
Validation loss: 2.506012422046029

Epoch: 5| Step: 1
Training loss: 1.5170403390498768
Validation loss: 2.491699003458434

Epoch: 5| Step: 2
Training loss: 2.0746060744330976
Validation loss: 2.471107041786218

Epoch: 5| Step: 3
Training loss: 1.5196898703661565
Validation loss: 2.5078769806270005

Epoch: 5| Step: 4
Training loss: 1.9948446467629073
Validation loss: 2.496625345183763

Epoch: 5| Step: 5
Training loss: 1.701801730906729
Validation loss: 2.4952996950531614

Epoch: 5| Step: 6
Training loss: 1.5715392525820047
Validation loss: 2.4903790081632518

Epoch: 5| Step: 7
Training loss: 1.727223955725256
Validation loss: 2.4701702603772433

Epoch: 5| Step: 8
Training loss: 2.048867457096844
Validation loss: 2.4737722942606393

Epoch: 5| Step: 9
Training loss: 1.9575048547443392
Validation loss: 2.5016743377840713

Epoch: 5| Step: 10
Training loss: 1.9495449366589348
Validation loss: 2.532920545171433

Epoch: 5| Step: 11
Training loss: 2.1087594723672454
Validation loss: 2.525708014616931

Epoch: 363| Step: 0
Training loss: 1.923880484396148
Validation loss: 2.5360182289597546

Epoch: 5| Step: 1
Training loss: 1.531005217001988
Validation loss: 2.5356020973769087

Epoch: 5| Step: 2
Training loss: 2.0171150791396797
Validation loss: 2.520808989562302

Epoch: 5| Step: 3
Training loss: 1.868054559731799
Validation loss: 2.5229476555628163

Epoch: 5| Step: 4
Training loss: 1.8938535756406294
Validation loss: 2.50839897776935

Epoch: 5| Step: 5
Training loss: 1.7314537121288784
Validation loss: 2.485995833573465

Epoch: 5| Step: 6
Training loss: 1.52978515625
Validation loss: 2.4938440268500424

Epoch: 5| Step: 7
Training loss: 1.5755654909304588
Validation loss: 2.464107655409997

Epoch: 5| Step: 8
Training loss: 2.186571632661675
Validation loss: 2.4979685556612856

Epoch: 5| Step: 9
Training loss: 1.463657071415664
Validation loss: 2.5046965392852525

Epoch: 5| Step: 10
Training loss: 2.179624276286812
Validation loss: 2.4877413528773076

Epoch: 5| Step: 11
Training loss: 1.5694940816105976
Validation loss: 2.4908100654516705

Epoch: 364| Step: 0
Training loss: 1.5698808674654448
Validation loss: 2.493870819402886

Epoch: 5| Step: 1
Training loss: 2.1943402835682373
Validation loss: 2.4851810938962333

Epoch: 5| Step: 2
Training loss: 1.389992559399347
Validation loss: 2.4699398786805764

Epoch: 5| Step: 3
Training loss: 1.4819336741917195
Validation loss: 2.515078736065616

Epoch: 5| Step: 4
Training loss: 2.0865547324232128
Validation loss: 2.4956756086350635

Epoch: 5| Step: 5
Training loss: 1.8610038995307354
Validation loss: 2.5255035528555623

Epoch: 5| Step: 6
Training loss: 1.7717217030892949
Validation loss: 2.542493780716773

Epoch: 5| Step: 7
Training loss: 1.555147265976802
Validation loss: 2.5554858057954815

Epoch: 5| Step: 8
Training loss: 2.0158498475984623
Validation loss: 2.5461209630004493

Epoch: 5| Step: 9
Training loss: 2.4345989080250043
Validation loss: 2.566609450549907

Epoch: 5| Step: 10
Training loss: 2.059976363185346
Validation loss: 2.5505180826783156

Epoch: 5| Step: 11
Training loss: 3.0900718325070877
Validation loss: 2.512893690671414

Epoch: 365| Step: 0
Training loss: 2.5863357652148893
Validation loss: 2.530469420840159

Epoch: 5| Step: 1
Training loss: 1.5926241170283273
Validation loss: 2.5077540152158257

Epoch: 5| Step: 2
Training loss: 1.4858452993964086
Validation loss: 2.4908082946441157

Epoch: 5| Step: 3
Training loss: 2.248425462596448
Validation loss: 2.464049612885235

Epoch: 5| Step: 4
Training loss: 1.8159406824171034
Validation loss: 2.466243259931797

Epoch: 5| Step: 5
Training loss: 1.66839136849043
Validation loss: 2.428606927636297

Epoch: 5| Step: 6
Training loss: 1.6770019353538086
Validation loss: 2.43941523632214

Epoch: 5| Step: 7
Training loss: 1.6805952591142448
Validation loss: 2.442464183218088

Epoch: 5| Step: 8
Training loss: 1.3850989969451646
Validation loss: 2.462749831117836

Epoch: 5| Step: 9
Training loss: 2.084516977396139
Validation loss: 2.4323208491979673

Epoch: 5| Step: 10
Training loss: 2.468093591655886
Validation loss: 2.4435156211426556

Epoch: 5| Step: 11
Training loss: 1.0182473001385772
Validation loss: 2.4417486454239423

Epoch: 366| Step: 0
Training loss: 1.7709337617408254
Validation loss: 2.4305947134103114

Epoch: 5| Step: 1
Training loss: 1.1223527703871359
Validation loss: 2.437488910454197

Epoch: 5| Step: 2
Training loss: 1.5233515006024767
Validation loss: 2.4430977254096375

Epoch: 5| Step: 3
Training loss: 2.4168133417101565
Validation loss: 2.474371658063422

Epoch: 5| Step: 4
Training loss: 2.237313106126402
Validation loss: 2.5188771386948248

Epoch: 5| Step: 5
Training loss: 2.474660919543833
Validation loss: 2.5226519161977485

Epoch: 5| Step: 6
Training loss: 1.7019189186327226
Validation loss: 2.542955774527093

Epoch: 5| Step: 7
Training loss: 2.017322151069047
Validation loss: 2.522094481370195

Epoch: 5| Step: 8
Training loss: 1.8699936469883023
Validation loss: 2.502977636430929

Epoch: 5| Step: 9
Training loss: 1.6127469191645223
Validation loss: 2.4852132162924003

Epoch: 5| Step: 10
Training loss: 1.848024424350229
Validation loss: 2.4453706175831442

Epoch: 5| Step: 11
Training loss: 1.7530254369740967
Validation loss: 2.4427220778631

Epoch: 367| Step: 0
Training loss: 1.5730674452439657
Validation loss: 2.4396418754748566

Epoch: 5| Step: 1
Training loss: 2.0004392379994895
Validation loss: 2.492855100193988

Epoch: 5| Step: 2
Training loss: 1.5966031584058447
Validation loss: 2.4973103200667133

Epoch: 5| Step: 3
Training loss: 2.3939210198168808
Validation loss: 2.5441472984369744

Epoch: 5| Step: 4
Training loss: 1.2158693357335517
Validation loss: 2.518333737957979

Epoch: 5| Step: 5
Training loss: 1.8388870246291276
Validation loss: 2.529847796715708

Epoch: 5| Step: 6
Training loss: 2.1139133939298773
Validation loss: 2.5200261972909943

Epoch: 5| Step: 7
Training loss: 1.7119107896476486
Validation loss: 2.543368287154605

Epoch: 5| Step: 8
Training loss: 1.9385201014474471
Validation loss: 2.532079495985814

Epoch: 5| Step: 9
Training loss: 1.9696588991616368
Validation loss: 2.5463173398118055

Epoch: 5| Step: 10
Training loss: 2.33653450676033
Validation loss: 2.579764675108129

Epoch: 5| Step: 11
Training loss: 1.1459908926170852
Validation loss: 2.6086274025951215

Epoch: 368| Step: 0
Training loss: 1.2580632025090246
Validation loss: 2.5959158705687417

Epoch: 5| Step: 1
Training loss: 1.8024483533383213
Validation loss: 2.587669322790083

Epoch: 5| Step: 2
Training loss: 1.7897223043013326
Validation loss: 2.590488531938065

Epoch: 5| Step: 3
Training loss: 1.7318335117862156
Validation loss: 2.5526258138597377

Epoch: 5| Step: 4
Training loss: 2.021157412416609
Validation loss: 2.5462873674165505

Epoch: 5| Step: 5
Training loss: 1.8400215338400574
Validation loss: 2.5054458074705797

Epoch: 5| Step: 6
Training loss: 2.187631875558917
Validation loss: 2.5029616694317784

Epoch: 5| Step: 7
Training loss: 2.04477414942924
Validation loss: 2.4751024444969243

Epoch: 5| Step: 8
Training loss: 2.2032865640906083
Validation loss: 2.4614542342926864

Epoch: 5| Step: 9
Training loss: 1.849681687678624
Validation loss: 2.4555739046585225

Epoch: 5| Step: 10
Training loss: 1.7582549491996
Validation loss: 2.456549188318772

Epoch: 5| Step: 11
Training loss: 1.9471580605752474
Validation loss: 2.469776306415633

Epoch: 369| Step: 0
Training loss: 1.4949543650624875
Validation loss: 2.451633751301612

Epoch: 5| Step: 1
Training loss: 2.034234773693035
Validation loss: 2.4298171022118438

Epoch: 5| Step: 2
Training loss: 1.7958055713864958
Validation loss: 2.449243621456527

Epoch: 5| Step: 3
Training loss: 1.6248193787182168
Validation loss: 2.46979075034543

Epoch: 5| Step: 4
Training loss: 2.1001264352429705
Validation loss: 2.4626031678109817

Epoch: 5| Step: 5
Training loss: 1.7932444507997498
Validation loss: 2.452441936405722

Epoch: 5| Step: 6
Training loss: 1.6972106994942564
Validation loss: 2.483379680459204

Epoch: 5| Step: 7
Training loss: 1.9370245811702704
Validation loss: 2.48494101820219

Epoch: 5| Step: 8
Training loss: 1.6434768594865723
Validation loss: 2.468448495762706

Epoch: 5| Step: 9
Training loss: 2.340003312263427
Validation loss: 2.5084695242559536

Epoch: 5| Step: 10
Training loss: 1.9095949935917775
Validation loss: 2.503189242138264

Epoch: 5| Step: 11
Training loss: 1.6105701490187498
Validation loss: 2.4931227903116424

Epoch: 370| Step: 0
Training loss: 2.1996196157887384
Validation loss: 2.508718774468474

Epoch: 5| Step: 1
Training loss: 1.466834015763343
Validation loss: 2.541489383241932

Epoch: 5| Step: 2
Training loss: 1.5530517253822058
Validation loss: 2.527140200877386

Epoch: 5| Step: 3
Training loss: 2.0471565111237533
Validation loss: 2.5666748363088248

Epoch: 5| Step: 4
Training loss: 1.7676482634565003
Validation loss: 2.5481292273085816

Epoch: 5| Step: 5
Training loss: 1.5514381228225453
Validation loss: 2.5495750531305634

Epoch: 5| Step: 6
Training loss: 2.3930331797804287
Validation loss: 2.5655576560025293

Epoch: 5| Step: 7
Training loss: 2.0119242442830414
Validation loss: 2.5754526757355807

Epoch: 5| Step: 8
Training loss: 1.5876487932535976
Validation loss: 2.577879283254374

Epoch: 5| Step: 9
Training loss: 1.876575062731159
Validation loss: 2.5471800638988173

Epoch: 5| Step: 10
Training loss: 1.8410158736473416
Validation loss: 2.5404177721569763

Epoch: 5| Step: 11
Training loss: 1.8026370335312107
Validation loss: 2.530742543377446

Epoch: 371| Step: 0
Training loss: 1.5734911578972133
Validation loss: 2.502523432185896

Epoch: 5| Step: 1
Training loss: 1.6821617178630435
Validation loss: 2.505736655493227

Epoch: 5| Step: 2
Training loss: 1.6126446148985156
Validation loss: 2.538824479121727

Epoch: 5| Step: 3
Training loss: 1.6251024800777965
Validation loss: 2.548893088028093

Epoch: 5| Step: 4
Training loss: 1.373724692808377
Validation loss: 2.5418834489604274

Epoch: 5| Step: 5
Training loss: 2.0666985981022847
Validation loss: 2.579025839430991

Epoch: 5| Step: 6
Training loss: 2.093910097292726
Validation loss: 2.549991152317929

Epoch: 5| Step: 7
Training loss: 1.8248107733671461
Validation loss: 2.5223196287667164

Epoch: 5| Step: 8
Training loss: 1.6387998328644824
Validation loss: 2.5191788182947175

Epoch: 5| Step: 9
Training loss: 2.032472917251985
Validation loss: 2.487306632540536

Epoch: 5| Step: 10
Training loss: 2.4134809169990863
Validation loss: 2.4760058767267474

Epoch: 5| Step: 11
Training loss: 2.9231292154291117
Validation loss: 2.4740710798304866

Epoch: 372| Step: 0
Training loss: 1.5051032516952283
Validation loss: 2.485528785967077

Epoch: 5| Step: 1
Training loss: 1.7902427012253874
Validation loss: 2.501378632935769

Epoch: 5| Step: 2
Training loss: 1.6222283127349602
Validation loss: 2.532160716801219

Epoch: 5| Step: 3
Training loss: 2.4244694748851052
Validation loss: 2.5126216406658917

Epoch: 5| Step: 4
Training loss: 1.588870413694289
Validation loss: 2.4847394288082505

Epoch: 5| Step: 5
Training loss: 1.9721526154545974
Validation loss: 2.5314159103462583

Epoch: 5| Step: 6
Training loss: 1.5778343764005132
Validation loss: 2.5413031448383827

Epoch: 5| Step: 7
Training loss: 1.7289732935990185
Validation loss: 2.5624199424426295

Epoch: 5| Step: 8
Training loss: 2.3709744921486258
Validation loss: 2.530404134005658

Epoch: 5| Step: 9
Training loss: 1.4938682158230483
Validation loss: 2.517591515370566

Epoch: 5| Step: 10
Training loss: 1.594614579800264
Validation loss: 2.5202109432866537

Epoch: 5| Step: 11
Training loss: 2.119008762458517
Validation loss: 2.482503562001429

Epoch: 373| Step: 0
Training loss: 1.8086227513536004
Validation loss: 2.4373953238451023

Epoch: 5| Step: 1
Training loss: 1.2481153108223582
Validation loss: 2.445991507153649

Epoch: 5| Step: 2
Training loss: 2.2307321155809756
Validation loss: 2.4475123795315428

Epoch: 5| Step: 3
Training loss: 2.2513157917853377
Validation loss: 2.470425214454025

Epoch: 5| Step: 4
Training loss: 2.4677374972649977
Validation loss: 2.425221254145955

Epoch: 5| Step: 5
Training loss: 1.587428327128933
Validation loss: 2.4264015227873665

Epoch: 5| Step: 6
Training loss: 1.7982988106870088
Validation loss: 2.4177320402485027

Epoch: 5| Step: 7
Training loss: 1.656606599817666
Validation loss: 2.413816923059578

Epoch: 5| Step: 8
Training loss: 1.6247797596676101
Validation loss: 2.440987586173091

Epoch: 5| Step: 9
Training loss: 1.6324871414402544
Validation loss: 2.473758481971575

Epoch: 5| Step: 10
Training loss: 1.9413194848058348
Validation loss: 2.500604004216008

Epoch: 5| Step: 11
Training loss: 1.974054728413137
Validation loss: 2.5245920105028623

Epoch: 374| Step: 0
Training loss: 1.8111194746270305
Validation loss: 2.4922479046204904

Epoch: 5| Step: 1
Training loss: 1.3841805452818088
Validation loss: 2.4846052347020047

Epoch: 5| Step: 2
Training loss: 2.036322612744014
Validation loss: 2.4729471301736177

Epoch: 5| Step: 3
Training loss: 1.5412592822164317
Validation loss: 2.496177825148574

Epoch: 5| Step: 4
Training loss: 1.9814223301787546
Validation loss: 2.4763110220674207

Epoch: 5| Step: 5
Training loss: 1.7171645047537258
Validation loss: 2.5146272706557573

Epoch: 5| Step: 6
Training loss: 1.2022774919145713
Validation loss: 2.5132935739993134

Epoch: 5| Step: 7
Training loss: 1.7378644464964355
Validation loss: 2.499306932384011

Epoch: 5| Step: 8
Training loss: 2.1047248729398063
Validation loss: 2.4860972346966976

Epoch: 5| Step: 9
Training loss: 1.5751530073412725
Validation loss: 2.490347084037913

Epoch: 5| Step: 10
Training loss: 2.312821855571222
Validation loss: 2.474688084371024

Epoch: 5| Step: 11
Training loss: 1.603716485735516
Validation loss: 2.470860790102275

Epoch: 375| Step: 0
Training loss: 1.6738590340002786
Validation loss: 2.4886352430984804

Epoch: 5| Step: 1
Training loss: 1.9182138694245068
Validation loss: 2.4838098726957885

Epoch: 5| Step: 2
Training loss: 1.5511895322118925
Validation loss: 2.4907447321888823

Epoch: 5| Step: 3
Training loss: 2.0681131448691263
Validation loss: 2.5235272874792263

Epoch: 5| Step: 4
Training loss: 1.9088480395487193
Validation loss: 2.5203110190550966

Epoch: 5| Step: 5
Training loss: 1.6204680556668327
Validation loss: 2.524428044273669

Epoch: 5| Step: 6
Training loss: 1.8756159724291894
Validation loss: 2.5308950905355956

Epoch: 5| Step: 7
Training loss: 1.8220571253517392
Validation loss: 2.5137033171565735

Epoch: 5| Step: 8
Training loss: 1.3200960602630945
Validation loss: 2.521699292956627

Epoch: 5| Step: 9
Training loss: 1.3919116293819767
Validation loss: 2.5106140820189315

Epoch: 5| Step: 10
Training loss: 2.155316358034349
Validation loss: 2.5012201788600597

Epoch: 5| Step: 11
Training loss: 1.1738648369200608
Validation loss: 2.5367096313651025

Epoch: 376| Step: 0
Training loss: 1.5991278029439409
Validation loss: 2.4928084370244963

Epoch: 5| Step: 1
Training loss: 2.2616367358160065
Validation loss: 2.4923392262606177

Epoch: 5| Step: 2
Training loss: 1.8241699342914777
Validation loss: 2.5204105173669626

Epoch: 5| Step: 3
Training loss: 1.8740229922200162
Validation loss: 2.513761924349897

Epoch: 5| Step: 4
Training loss: 1.4677232440581847
Validation loss: 2.5171348234758706

Epoch: 5| Step: 5
Training loss: 1.6567436058527758
Validation loss: 2.5432692690553416

Epoch: 5| Step: 6
Training loss: 2.312880407438692
Validation loss: 2.543768929232213

Epoch: 5| Step: 7
Training loss: 1.3046386618239245
Validation loss: 2.5327812751415735

Epoch: 5| Step: 8
Training loss: 1.9337151999816033
Validation loss: 2.5249435882750535

Epoch: 5| Step: 9
Training loss: 1.562356102993109
Validation loss: 2.5223252095878546

Epoch: 5| Step: 10
Training loss: 1.4317036571912396
Validation loss: 2.5621957326918765

Epoch: 5| Step: 11
Training loss: 1.8250170641584709
Validation loss: 2.5376812743282584

Epoch: 377| Step: 0
Training loss: 1.4486550111215433
Validation loss: 2.5328883492912255

Epoch: 5| Step: 1
Training loss: 1.4299467091534135
Validation loss: 2.5269679675037593

Epoch: 5| Step: 2
Training loss: 1.800003446469716
Validation loss: 2.5400926896451894

Epoch: 5| Step: 3
Training loss: 1.774729925751152
Validation loss: 2.521462765184185

Epoch: 5| Step: 4
Training loss: 1.4127788302251434
Validation loss: 2.5177441037443304

Epoch: 5| Step: 5
Training loss: 1.3420068834699626
Validation loss: 2.5259379978471257

Epoch: 5| Step: 6
Training loss: 1.3988157219058603
Validation loss: 2.508202654158227

Epoch: 5| Step: 7
Training loss: 1.9593736712437555
Validation loss: 2.5013991692344897

Epoch: 5| Step: 8
Training loss: 1.7865015882884838
Validation loss: 2.5080286291362803

Epoch: 5| Step: 9
Training loss: 2.214463297143796
Validation loss: 2.5223118601013486

Epoch: 5| Step: 10
Training loss: 2.360544281282188
Validation loss: 2.484745301933797

Epoch: 5| Step: 11
Training loss: 1.6145804948679268
Validation loss: 2.5104091744423234

Epoch: 378| Step: 0
Training loss: 1.1004323369828732
Validation loss: 2.548044603140036

Epoch: 5| Step: 1
Training loss: 1.2366243944543527
Validation loss: 2.5265916455030206

Epoch: 5| Step: 2
Training loss: 1.3940888459093994
Validation loss: 2.551808499439782

Epoch: 5| Step: 3
Training loss: 1.8247321833754515
Validation loss: 2.574403010456215

Epoch: 5| Step: 4
Training loss: 2.061290617589464
Validation loss: 2.5396514561638206

Epoch: 5| Step: 5
Training loss: 2.16008583216203
Validation loss: 2.5328942676534196

Epoch: 5| Step: 6
Training loss: 1.991948431293526
Validation loss: 2.5094125897674826

Epoch: 5| Step: 7
Training loss: 1.5706842086931767
Validation loss: 2.480972611322642

Epoch: 5| Step: 8
Training loss: 1.9165194565451935
Validation loss: 2.474074717678573

Epoch: 5| Step: 9
Training loss: 1.3927758973917985
Validation loss: 2.4689666998999384

Epoch: 5| Step: 10
Training loss: 2.1517047244999827
Validation loss: 2.442434207416692

Epoch: 5| Step: 11
Training loss: 1.7649794216955588
Validation loss: 2.4889975953405323

Epoch: 379| Step: 0
Training loss: 2.0095564693538046
Validation loss: 2.4679581985980668

Epoch: 5| Step: 1
Training loss: 1.4479005478801068
Validation loss: 2.4819444787092397

Epoch: 5| Step: 2
Training loss: 1.629880252605277
Validation loss: 2.4841075889253523

Epoch: 5| Step: 3
Training loss: 1.3193365699885142
Validation loss: 2.4900861469109623

Epoch: 5| Step: 4
Training loss: 1.507473368876042
Validation loss: 2.5214621032944695

Epoch: 5| Step: 5
Training loss: 1.4592735892436894
Validation loss: 2.5026727971971643

Epoch: 5| Step: 6
Training loss: 1.962146523101396
Validation loss: 2.5052845573857563

Epoch: 5| Step: 7
Training loss: 1.8628603541833813
Validation loss: 2.4562427972003653

Epoch: 5| Step: 8
Training loss: 2.3932825413930994
Validation loss: 2.501812337566642

Epoch: 5| Step: 9
Training loss: 1.9285948590464965
Validation loss: 2.459573381784986

Epoch: 5| Step: 10
Training loss: 1.6956783901854426
Validation loss: 2.458145430759878

Epoch: 5| Step: 11
Training loss: 1.6452067023276404
Validation loss: 2.4620316490086993

Epoch: 380| Step: 0
Training loss: 1.9013378452570286
Validation loss: 2.482581472881479

Epoch: 5| Step: 1
Training loss: 1.5791237569463001
Validation loss: 2.46205742597762

Epoch: 5| Step: 2
Training loss: 2.2238004987278175
Validation loss: 2.469679138524699

Epoch: 5| Step: 3
Training loss: 1.9340967622237857
Validation loss: 2.5067103926246994

Epoch: 5| Step: 4
Training loss: 2.0971726867125335
Validation loss: 2.5325325946335853

Epoch: 5| Step: 5
Training loss: 1.5239002796448446
Validation loss: 2.5289345892983

Epoch: 5| Step: 6
Training loss: 1.6114320663681896
Validation loss: 2.5307937925233275

Epoch: 5| Step: 7
Training loss: 1.5117946083296694
Validation loss: 2.524259935171141

Epoch: 5| Step: 8
Training loss: 1.2577288582044195
Validation loss: 2.521965656597004

Epoch: 5| Step: 9
Training loss: 1.7415530841544793
Validation loss: 2.5323431731341657

Epoch: 5| Step: 10
Training loss: 1.4438244556863173
Validation loss: 2.4615587429263166

Epoch: 5| Step: 11
Training loss: 1.5346058254300905
Validation loss: 2.4680551122367924

Epoch: 381| Step: 0
Training loss: 1.4714189993379005
Validation loss: 2.4707811707645573

Epoch: 5| Step: 1
Training loss: 1.9390874327748067
Validation loss: 2.4926649411595014

Epoch: 5| Step: 2
Training loss: 1.9957743947266702
Validation loss: 2.4948138167659595

Epoch: 5| Step: 3
Training loss: 1.8703684506058502
Validation loss: 2.499349473716535

Epoch: 5| Step: 4
Training loss: 2.270242760066912
Validation loss: 2.481259219555257

Epoch: 5| Step: 5
Training loss: 1.5050866980943383
Validation loss: 2.503459948172942

Epoch: 5| Step: 6
Training loss: 1.3272506977624832
Validation loss: 2.5178570865336716

Epoch: 5| Step: 7
Training loss: 1.4529011871910666
Validation loss: 2.5155118636443774

Epoch: 5| Step: 8
Training loss: 1.371011063128353
Validation loss: 2.5369256324787153

Epoch: 5| Step: 9
Training loss: 1.9086065266166317
Validation loss: 2.573237558706947

Epoch: 5| Step: 10
Training loss: 1.8792950075338881
Validation loss: 2.527012586638515

Epoch: 5| Step: 11
Training loss: 1.313174210815088
Validation loss: 2.56093965491126

Epoch: 382| Step: 0
Training loss: 1.6039697930875916
Validation loss: 2.5464984599851013

Epoch: 5| Step: 1
Training loss: 1.45084415395968
Validation loss: 2.4907492909356264

Epoch: 5| Step: 2
Training loss: 1.5543958687541366
Validation loss: 2.514886656900075

Epoch: 5| Step: 3
Training loss: 1.9074566883454571
Validation loss: 2.508353031488763

Epoch: 5| Step: 4
Training loss: 1.8571959477475923
Validation loss: 2.5002812743902103

Epoch: 5| Step: 5
Training loss: 1.7308506253657772
Validation loss: 2.506086906555207

Epoch: 5| Step: 6
Training loss: 1.2513598198195244
Validation loss: 2.5180645402012893

Epoch: 5| Step: 7
Training loss: 1.3200493273766167
Validation loss: 2.501565629749457

Epoch: 5| Step: 8
Training loss: 2.318988049567234
Validation loss: 2.483184917279785

Epoch: 5| Step: 9
Training loss: 1.8652863340480599
Validation loss: 2.466714166466342

Epoch: 5| Step: 10
Training loss: 1.993559660241514
Validation loss: 2.494886318208445

Epoch: 5| Step: 11
Training loss: 1.2474252887133686
Validation loss: 2.442782937044586

Epoch: 383| Step: 0
Training loss: 1.4859358762457446
Validation loss: 2.487672524723334

Epoch: 5| Step: 1
Training loss: 2.1075531049850276
Validation loss: 2.5419270402921152

Epoch: 5| Step: 2
Training loss: 1.6658554805156753
Validation loss: 2.6270462983919423

Epoch: 5| Step: 3
Training loss: 1.9768281539494506
Validation loss: 2.6228710086253226

Epoch: 5| Step: 4
Training loss: 2.010645904384913
Validation loss: 2.5752161705301697

Epoch: 5| Step: 5
Training loss: 1.5080895045909648
Validation loss: 2.5473845309579577

Epoch: 5| Step: 6
Training loss: 1.6590568223066786
Validation loss: 2.5080661506760933

Epoch: 5| Step: 7
Training loss: 1.4476932197704513
Validation loss: 2.541921604117891

Epoch: 5| Step: 8
Training loss: 1.6498589195278799
Validation loss: 2.565271038430263

Epoch: 5| Step: 9
Training loss: 1.3391607117218822
Validation loss: 2.5020712279398287

Epoch: 5| Step: 10
Training loss: 2.1326830478828893
Validation loss: 2.540417991140641

Epoch: 5| Step: 11
Training loss: 1.3315083660445926
Validation loss: 2.499315855670364

Epoch: 384| Step: 0
Training loss: 1.6351621231287112
Validation loss: 2.5281385206844127

Epoch: 5| Step: 1
Training loss: 2.0553257172194206
Validation loss: 2.505449481045873

Epoch: 5| Step: 2
Training loss: 2.4013405791022775
Validation loss: 2.4982481262249374

Epoch: 5| Step: 3
Training loss: 1.4882283038636164
Validation loss: 2.4766219299438057

Epoch: 5| Step: 4
Training loss: 1.8082524218527884
Validation loss: 2.5209663857795563

Epoch: 5| Step: 5
Training loss: 1.5057334204021773
Validation loss: 2.475152670361209

Epoch: 5| Step: 6
Training loss: 1.5517653410472658
Validation loss: 2.485430359356348

Epoch: 5| Step: 7
Training loss: 1.7926048956788327
Validation loss: 2.5264902535864624

Epoch: 5| Step: 8
Training loss: 1.3738525978492253
Validation loss: 2.5588440944898636

Epoch: 5| Step: 9
Training loss: 1.637872694278082
Validation loss: 2.5652815600921923

Epoch: 5| Step: 10
Training loss: 1.473175362076905
Validation loss: 2.5277764658930337

Epoch: 5| Step: 11
Training loss: 2.0407498565378432
Validation loss: 2.4964231652802185

Epoch: 385| Step: 0
Training loss: 1.4209761241112355
Validation loss: 2.48263859797004

Epoch: 5| Step: 1
Training loss: 1.1650551269651568
Validation loss: 2.497940928161322

Epoch: 5| Step: 2
Training loss: 1.8396076933766057
Validation loss: 2.528269716544599

Epoch: 5| Step: 3
Training loss: 2.2346670320043214
Validation loss: 2.512160840241603

Epoch: 5| Step: 4
Training loss: 1.8682573517530048
Validation loss: 2.5272730051444463

Epoch: 5| Step: 5
Training loss: 1.8773388580372827
Validation loss: 2.519845196782323

Epoch: 5| Step: 6
Training loss: 1.870230776372496
Validation loss: 2.4850611069187187

Epoch: 5| Step: 7
Training loss: 1.5333195150139716
Validation loss: 2.5103025700664685

Epoch: 5| Step: 8
Training loss: 1.758363289901803
Validation loss: 2.47508923966946

Epoch: 5| Step: 9
Training loss: 1.5621465664724299
Validation loss: 2.4441775002506625

Epoch: 5| Step: 10
Training loss: 1.6953747294031354
Validation loss: 2.477031827754238

Epoch: 5| Step: 11
Training loss: 2.16989539513968
Validation loss: 2.537490964820198

Epoch: 386| Step: 0
Training loss: 1.2592044497126538
Validation loss: 2.5324852366643187

Epoch: 5| Step: 1
Training loss: 1.7801298668452459
Validation loss: 2.553988509838632

Epoch: 5| Step: 2
Training loss: 2.281972274357754
Validation loss: 2.6098636999507576

Epoch: 5| Step: 3
Training loss: 1.700816628715027
Validation loss: 2.59983613372035

Epoch: 5| Step: 4
Training loss: 2.2533564434145523
Validation loss: 2.5657749996407686

Epoch: 5| Step: 5
Training loss: 1.7720662331699712
Validation loss: 2.5091527801652225

Epoch: 5| Step: 6
Training loss: 1.476137211017364
Validation loss: 2.4498282408842273

Epoch: 5| Step: 7
Training loss: 1.7960059676719022
Validation loss: 2.448361463244495

Epoch: 5| Step: 8
Training loss: 2.109039506016768
Validation loss: 2.439781722698176

Epoch: 5| Step: 9
Training loss: 1.6458722443950489
Validation loss: 2.4499919346267913

Epoch: 5| Step: 10
Training loss: 1.678842873351196
Validation loss: 2.474217597359703

Epoch: 5| Step: 11
Training loss: 1.6797170946929532
Validation loss: 2.4676311911337536

Epoch: 387| Step: 0
Training loss: 1.8661770820041985
Validation loss: 2.50272857060421

Epoch: 5| Step: 1
Training loss: 1.8927185195483593
Validation loss: 2.537816932535624

Epoch: 5| Step: 2
Training loss: 1.896572059937873
Validation loss: 2.5271290565583078

Epoch: 5| Step: 3
Training loss: 1.570241062949672
Validation loss: 2.54078276434905

Epoch: 5| Step: 4
Training loss: 2.236811876240365
Validation loss: 2.499446867309975

Epoch: 5| Step: 5
Training loss: 1.6343740634660244
Validation loss: 2.471351210843976

Epoch: 5| Step: 6
Training loss: 1.7722921832328926
Validation loss: 2.445934033852584

Epoch: 5| Step: 7
Training loss: 1.7037503555532576
Validation loss: 2.4368284555656876

Epoch: 5| Step: 8
Training loss: 2.029892922945811
Validation loss: 2.4424371440039927

Epoch: 5| Step: 9
Training loss: 1.7553583943168927
Validation loss: 2.4544814747147337

Epoch: 5| Step: 10
Training loss: 1.6718055496764435
Validation loss: 2.4747269222900794

Epoch: 5| Step: 11
Training loss: 2.6993636052393932
Validation loss: 2.524002065186555

Epoch: 388| Step: 0
Training loss: 1.7278433489171456
Validation loss: 2.565564180490393

Epoch: 5| Step: 1
Training loss: 2.174569194704126
Validation loss: 2.595704238696179

Epoch: 5| Step: 2
Training loss: 2.3676848943389017
Validation loss: 2.541947772683068

Epoch: 5| Step: 3
Training loss: 1.7034759159966468
Validation loss: 2.4915427965506036

Epoch: 5| Step: 4
Training loss: 1.4108344056241233
Validation loss: 2.476977039866015

Epoch: 5| Step: 5
Training loss: 1.7258161079336698
Validation loss: 2.4588283926667382

Epoch: 5| Step: 6
Training loss: 1.8679776614689343
Validation loss: 2.4826098155088103

Epoch: 5| Step: 7
Training loss: 1.7782783482401117
Validation loss: 2.5198864964848116

Epoch: 5| Step: 8
Training loss: 1.4162121866536606
Validation loss: 2.5111835457303813

Epoch: 5| Step: 9
Training loss: 1.9786840218432376
Validation loss: 2.5137837702959667

Epoch: 5| Step: 10
Training loss: 1.4731388667234482
Validation loss: 2.4819674312274462

Epoch: 5| Step: 11
Training loss: 1.449084910667199
Validation loss: 2.435336146942102

Epoch: 389| Step: 0
Training loss: 1.6083403289063
Validation loss: 2.4624547610508536

Epoch: 5| Step: 1
Training loss: 1.3590219411896287
Validation loss: 2.451610417543042

Epoch: 5| Step: 2
Training loss: 2.1554691172285274
Validation loss: 2.461053649744862

Epoch: 5| Step: 3
Training loss: 1.2557438490252
Validation loss: 2.5037609619583736

Epoch: 5| Step: 4
Training loss: 1.9601423011426389
Validation loss: 2.4851219825656594

Epoch: 5| Step: 5
Training loss: 1.6581094488456414
Validation loss: 2.5295968681752083

Epoch: 5| Step: 6
Training loss: 1.4719507768890747
Validation loss: 2.5252273026847973

Epoch: 5| Step: 7
Training loss: 2.0937469254656182
Validation loss: 2.493488840977863

Epoch: 5| Step: 8
Training loss: 1.8514670818224184
Validation loss: 2.4941958125338504

Epoch: 5| Step: 9
Training loss: 1.4303511449866
Validation loss: 2.507308804403664

Epoch: 5| Step: 10
Training loss: 1.9950203893092837
Validation loss: 2.4966092798626267

Epoch: 5| Step: 11
Training loss: 0.6968855048786297
Validation loss: 2.482878128090246

Epoch: 390| Step: 0
Training loss: 2.2407428194403605
Validation loss: 2.5138239879965143

Epoch: 5| Step: 1
Training loss: 1.4449789951210164
Validation loss: 2.5021943475604083

Epoch: 5| Step: 2
Training loss: 1.4859830478301967
Validation loss: 2.496700366378042

Epoch: 5| Step: 3
Training loss: 1.2579805250070437
Validation loss: 2.5136068731408727

Epoch: 5| Step: 4
Training loss: 1.539532971967243
Validation loss: 2.4962255993298226

Epoch: 5| Step: 5
Training loss: 1.6095630572914312
Validation loss: 2.4958959211537852

Epoch: 5| Step: 6
Training loss: 1.9060339883453765
Validation loss: 2.496327786724408

Epoch: 5| Step: 7
Training loss: 2.049860051658229
Validation loss: 2.483299782438874

Epoch: 5| Step: 8
Training loss: 1.4807828303311859
Validation loss: 2.4824489248879424

Epoch: 5| Step: 9
Training loss: 1.2148575858649917
Validation loss: 2.458771581029829

Epoch: 5| Step: 10
Training loss: 1.7225212338360987
Validation loss: 2.474618760683024

Epoch: 5| Step: 11
Training loss: 1.857152877246109
Validation loss: 2.461582228558239

Epoch: 391| Step: 0
Training loss: 1.7587839790537656
Validation loss: 2.47861058278971

Epoch: 5| Step: 1
Training loss: 1.8185200522919094
Validation loss: 2.479213274723331

Epoch: 5| Step: 2
Training loss: 1.7775916964114682
Validation loss: 2.464369138232916

Epoch: 5| Step: 3
Training loss: 1.6343427724195465
Validation loss: 2.4947434834159026

Epoch: 5| Step: 4
Training loss: 1.352953112743486
Validation loss: 2.457948934814555

Epoch: 5| Step: 5
Training loss: 1.5650018117973394
Validation loss: 2.446033018193444

Epoch: 5| Step: 6
Training loss: 1.2453218179734666
Validation loss: 2.425159282467376

Epoch: 5| Step: 7
Training loss: 1.6393028381265378
Validation loss: 2.4617303449090726

Epoch: 5| Step: 8
Training loss: 1.437426523735706
Validation loss: 2.430242693762118

Epoch: 5| Step: 9
Training loss: 2.2336986024789263
Validation loss: 2.4409784557654235

Epoch: 5| Step: 10
Training loss: 1.848775963900782
Validation loss: 2.4371994538333395

Epoch: 5| Step: 11
Training loss: 1.857910477065511
Validation loss: 2.436365297494782

Epoch: 392| Step: 0
Training loss: 1.8150363145037978
Validation loss: 2.4222337867199975

Epoch: 5| Step: 1
Training loss: 1.8691968759903699
Validation loss: 2.460492863930076

Epoch: 5| Step: 2
Training loss: 1.7047999134289251
Validation loss: 2.4462590442270016

Epoch: 5| Step: 3
Training loss: 1.5104288122631508
Validation loss: 2.4479250535753656

Epoch: 5| Step: 4
Training loss: 1.6614664809008284
Validation loss: 2.4387827660480736

Epoch: 5| Step: 5
Training loss: 2.0866128921079805
Validation loss: 2.4318216851373142

Epoch: 5| Step: 6
Training loss: 1.1081233956314065
Validation loss: 2.4707725344270397

Epoch: 5| Step: 7
Training loss: 1.6828467887140761
Validation loss: 2.476674154594606

Epoch: 5| Step: 8
Training loss: 1.6937342034198006
Validation loss: 2.4800204515222743

Epoch: 5| Step: 9
Training loss: 1.189214472639576
Validation loss: 2.5808491119216117

Epoch: 5| Step: 10
Training loss: 1.8574728973793673
Validation loss: 2.5746711483933993

Epoch: 5| Step: 11
Training loss: 1.9965674627663037
Validation loss: 2.5491819406529634

Epoch: 393| Step: 0
Training loss: 1.6927944063653093
Validation loss: 2.4863616070087406

Epoch: 5| Step: 1
Training loss: 1.7503554119508848
Validation loss: 2.5423286050260967

Epoch: 5| Step: 2
Training loss: 1.059888772526997
Validation loss: 2.5071569043341584

Epoch: 5| Step: 3
Training loss: 1.5817342597150519
Validation loss: 2.5301278220996903

Epoch: 5| Step: 4
Training loss: 1.6894423997130656
Validation loss: 2.5574335083532533

Epoch: 5| Step: 5
Training loss: 1.8689186657985193
Validation loss: 2.5742963587205576

Epoch: 5| Step: 6
Training loss: 1.9761338805817672
Validation loss: 2.5746827660052656

Epoch: 5| Step: 7
Training loss: 1.5959358932699164
Validation loss: 2.5156411946409225

Epoch: 5| Step: 8
Training loss: 1.8656618916555674
Validation loss: 2.489853957296626

Epoch: 5| Step: 9
Training loss: 2.0723122205897724
Validation loss: 2.4861208501432053

Epoch: 5| Step: 10
Training loss: 2.4020538403260137
Validation loss: 2.478605344414524

Epoch: 5| Step: 11
Training loss: 1.6382695319066347
Validation loss: 2.4896819216202584

Epoch: 394| Step: 0
Training loss: 1.7270118508387897
Validation loss: 2.5519544620803343

Epoch: 5| Step: 1
Training loss: 1.938380564275199
Validation loss: 2.5528307981407727

Epoch: 5| Step: 2
Training loss: 2.2887131356021087
Validation loss: 2.5539442686384524

Epoch: 5| Step: 3
Training loss: 1.543734435338927
Validation loss: 2.5434554142689594

Epoch: 5| Step: 4
Training loss: 2.0642437355008356
Validation loss: 2.516226066826748

Epoch: 5| Step: 5
Training loss: 1.4576611014003373
Validation loss: 2.4763230931102878

Epoch: 5| Step: 6
Training loss: 1.852053291526278
Validation loss: 2.4323216517449646

Epoch: 5| Step: 7
Training loss: 1.6338566995815318
Validation loss: 2.4221537193791027

Epoch: 5| Step: 8
Training loss: 1.4444504925201822
Validation loss: 2.386381128533976

Epoch: 5| Step: 9
Training loss: 1.4959374886523316
Validation loss: 2.428424400582575

Epoch: 5| Step: 10
Training loss: 1.5333027995566217
Validation loss: 2.4658822956415274

Epoch: 5| Step: 11
Training loss: 1.5353401986295918
Validation loss: 2.4860158815620843

Epoch: 395| Step: 0
Training loss: 1.9122508291850397
Validation loss: 2.5243222995315255

Epoch: 5| Step: 1
Training loss: 1.746715051087625
Validation loss: 2.5339778087176685

Epoch: 5| Step: 2
Training loss: 1.5948683610842689
Validation loss: 2.561070303104524

Epoch: 5| Step: 3
Training loss: 1.5580568846967455
Validation loss: 2.540937437652461

Epoch: 5| Step: 4
Training loss: 1.58662286991826
Validation loss: 2.5368014984058966

Epoch: 5| Step: 5
Training loss: 2.008490065899783
Validation loss: 2.4984406455924546

Epoch: 5| Step: 6
Training loss: 1.3303278437942214
Validation loss: 2.495299072006553

Epoch: 5| Step: 7
Training loss: 2.344799366320782
Validation loss: 2.4624045928797553

Epoch: 5| Step: 8
Training loss: 1.3080407639605485
Validation loss: 2.46183438785625

Epoch: 5| Step: 9
Training loss: 1.9128739384115594
Validation loss: 2.4752647577789837

Epoch: 5| Step: 10
Training loss: 1.6253782712379377
Validation loss: 2.4494569369575516

Epoch: 5| Step: 11
Training loss: 1.2500828715510182
Validation loss: 2.433127969465151

Epoch: 396| Step: 0
Training loss: 1.9687348017030242
Validation loss: 2.4695500111754747

Epoch: 5| Step: 1
Training loss: 2.0094991642631546
Validation loss: 2.4432769850946388

Epoch: 5| Step: 2
Training loss: 1.5827706575276295
Validation loss: 2.47246488299694

Epoch: 5| Step: 3
Training loss: 1.4963914858816743
Validation loss: 2.436899098885937

Epoch: 5| Step: 4
Training loss: 1.6730682535562438
Validation loss: 2.4211017892036675

Epoch: 5| Step: 5
Training loss: 1.5527401330229322
Validation loss: 2.452966620157619

Epoch: 5| Step: 6
Training loss: 1.57125977749085
Validation loss: 2.466724439993656

Epoch: 5| Step: 7
Training loss: 2.0998277275631723
Validation loss: 2.4386475808239454

Epoch: 5| Step: 8
Training loss: 1.6553346515690726
Validation loss: 2.4812791216476144

Epoch: 5| Step: 9
Training loss: 1.11094468512807
Validation loss: 2.4896155971101757

Epoch: 5| Step: 10
Training loss: 1.4021375924315491
Validation loss: 2.4879122629660664

Epoch: 5| Step: 11
Training loss: 0.3040135951570672
Validation loss: 2.4604300566160076

Epoch: 397| Step: 0
Training loss: 2.105603951552489
Validation loss: 2.495191296536305

Epoch: 5| Step: 1
Training loss: 1.4447116737067827
Validation loss: 2.518868793465957

Epoch: 5| Step: 2
Training loss: 1.7137349569493785
Validation loss: 2.4687384874743414

Epoch: 5| Step: 3
Training loss: 2.0021957027195234
Validation loss: 2.528559015723753

Epoch: 5| Step: 4
Training loss: 1.3445635262515858
Validation loss: 2.5363515260886778

Epoch: 5| Step: 5
Training loss: 1.5398950793702635
Validation loss: 2.513727222575282

Epoch: 5| Step: 6
Training loss: 1.5421567687709128
Validation loss: 2.498271101928742

Epoch: 5| Step: 7
Training loss: 1.3758682197493153
Validation loss: 2.4767544328060715

Epoch: 5| Step: 8
Training loss: 1.558853013122859
Validation loss: 2.4866482193260877

Epoch: 5| Step: 9
Training loss: 1.5128855379404695
Validation loss: 2.477004642509301

Epoch: 5| Step: 10
Training loss: 1.6672353807346938
Validation loss: 2.449156432345115

Epoch: 5| Step: 11
Training loss: 1.4035880006708294
Validation loss: 2.4826383358762847

Epoch: 398| Step: 0
Training loss: 1.7759942936848563
Validation loss: 2.468993305739403

Epoch: 5| Step: 1
Training loss: 1.5544574509837654
Validation loss: 2.4747257300653533

Epoch: 5| Step: 2
Training loss: 1.669412814175847
Validation loss: 2.468884729982414

Epoch: 5| Step: 3
Training loss: 1.1270685781381518
Validation loss: 2.46897994954324

Epoch: 5| Step: 4
Training loss: 1.7446573993396401
Validation loss: 2.4882304287705495

Epoch: 5| Step: 5
Training loss: 2.1375683868354804
Validation loss: 2.4831064532368496

Epoch: 5| Step: 6
Training loss: 1.6276604075569607
Validation loss: 2.4621396030170435

Epoch: 5| Step: 7
Training loss: 1.5753524143797755
Validation loss: 2.461443942804576

Epoch: 5| Step: 8
Training loss: 1.3239060654466173
Validation loss: 2.4427530891911142

Epoch: 5| Step: 9
Training loss: 1.3696607181438156
Validation loss: 2.4831092057012625

Epoch: 5| Step: 10
Training loss: 1.2784716558078162
Validation loss: 2.481351784348834

Epoch: 5| Step: 11
Training loss: 2.1443659261824495
Validation loss: 2.5064673455571245

Epoch: 399| Step: 0
Training loss: 1.2226378223139558
Validation loss: 2.485449884314736

Epoch: 5| Step: 1
Training loss: 1.4389467836922316
Validation loss: 2.4307499001022457

Epoch: 5| Step: 2
Training loss: 1.5716096445515382
Validation loss: 2.4641275750861804

Epoch: 5| Step: 3
Training loss: 1.7565307012753022
Validation loss: 2.4622916396495254

Epoch: 5| Step: 4
Training loss: 1.1098273523626578
Validation loss: 2.475627742818141

Epoch: 5| Step: 5
Training loss: 1.888727039371796
Validation loss: 2.437807866567117

Epoch: 5| Step: 6
Training loss: 1.8878373330927831
Validation loss: 2.4401275419230424

Epoch: 5| Step: 7
Training loss: 1.2885176460825254
Validation loss: 2.4073312320096143

Epoch: 5| Step: 8
Training loss: 1.7598710954667396
Validation loss: 2.418238910789886

Epoch: 5| Step: 9
Training loss: 1.4851506666051428
Validation loss: 2.4055566160254997

Epoch: 5| Step: 10
Training loss: 2.1546555304420476
Validation loss: 2.4008335070183517

Epoch: 5| Step: 11
Training loss: 1.113665116368889
Validation loss: 2.4228190725214347

Epoch: 400| Step: 0
Training loss: 1.9338883609010602
Validation loss: 2.4238804215479486

Epoch: 5| Step: 1
Training loss: 1.5821686861598683
Validation loss: 2.3995171621692823

Epoch: 5| Step: 2
Training loss: 1.3743347812959228
Validation loss: 2.413017697040296

Epoch: 5| Step: 3
Training loss: 1.2476242376626547
Validation loss: 2.4156042646708276

Epoch: 5| Step: 4
Training loss: 1.5797971421403894
Validation loss: 2.451315135239554

Epoch: 5| Step: 5
Training loss: 1.218763840425594
Validation loss: 2.4499503568563354

Epoch: 5| Step: 6
Training loss: 1.4942892561643668
Validation loss: 2.433703885920791

Epoch: 5| Step: 7
Training loss: 1.8815383715461302
Validation loss: 2.3987178659332558

Epoch: 5| Step: 8
Training loss: 1.138678051782936
Validation loss: 2.428010351484711

Epoch: 5| Step: 9
Training loss: 1.8032745510869665
Validation loss: 2.4218070728251333

Epoch: 5| Step: 10
Training loss: 2.0950759560738486
Validation loss: 2.40964603639546

Epoch: 5| Step: 11
Training loss: 2.8183251138932355
Validation loss: 2.4066930420804864

Epoch: 401| Step: 0
Training loss: 1.7032749914913958
Validation loss: 2.4290952584211265

Epoch: 5| Step: 1
Training loss: 1.6007760698970985
Validation loss: 2.4669109266770795

Epoch: 5| Step: 2
Training loss: 1.519676927188129
Validation loss: 2.4921810704131384

Epoch: 5| Step: 3
Training loss: 1.5061146560580947
Validation loss: 2.5200396042189235

Epoch: 5| Step: 4
Training loss: 1.3384643215686791
Validation loss: 2.533342556141913

Epoch: 5| Step: 5
Training loss: 2.154287025242385
Validation loss: 2.57470066111487

Epoch: 5| Step: 6
Training loss: 1.9393539172842063
Validation loss: 2.5956287550384283

Epoch: 5| Step: 7
Training loss: 1.6472492002808585
Validation loss: 2.5840856657697864

Epoch: 5| Step: 8
Training loss: 1.9558842813785162
Validation loss: 2.487426666955172

Epoch: 5| Step: 9
Training loss: 1.3931336652401534
Validation loss: 2.4660421461780735

Epoch: 5| Step: 10
Training loss: 1.4046331223262096
Validation loss: 2.493721038726673

Epoch: 5| Step: 11
Training loss: 0.7408147464204169
Validation loss: 2.5253556975122473

Epoch: 402| Step: 0
Training loss: 1.5011113341464888
Validation loss: 2.5612469804050018

Epoch: 5| Step: 1
Training loss: 1.4884727535041393
Validation loss: 2.5940084175464952

Epoch: 5| Step: 2
Training loss: 1.8752429169019003
Validation loss: 2.5651818484760764

Epoch: 5| Step: 3
Training loss: 1.7497781885446066
Validation loss: 2.557314728259322

Epoch: 5| Step: 4
Training loss: 1.2796090946235632
Validation loss: 2.5252945899650845

Epoch: 5| Step: 5
Training loss: 1.6224937184921953
Validation loss: 2.523210060570029

Epoch: 5| Step: 6
Training loss: 1.5775049332240814
Validation loss: 2.5711535379325547

Epoch: 5| Step: 7
Training loss: 2.0629564415997117
Validation loss: 2.553562114748132

Epoch: 5| Step: 8
Training loss: 1.910435630790187
Validation loss: 2.510153951919886

Epoch: 5| Step: 9
Training loss: 2.080272282238436
Validation loss: 2.523106646820262

Epoch: 5| Step: 10
Training loss: 1.5292710732028783
Validation loss: 2.508805766532015

Epoch: 5| Step: 11
Training loss: 1.5627782192486506
Validation loss: 2.5786108734364253

Epoch: 403| Step: 0
Training loss: 1.6670919432064573
Validation loss: 2.5365942671198343

Epoch: 5| Step: 1
Training loss: 1.4377597076666693
Validation loss: 2.512687929204122

Epoch: 5| Step: 2
Training loss: 1.8778533840696316
Validation loss: 2.4676415614869662

Epoch: 5| Step: 3
Training loss: 2.0420175237921847
Validation loss: 2.4525066090351197

Epoch: 5| Step: 4
Training loss: 1.6090545335232758
Validation loss: 2.421369532679093

Epoch: 5| Step: 5
Training loss: 1.3998385608780022
Validation loss: 2.41938345119689

Epoch: 5| Step: 6
Training loss: 1.4514210873347575
Validation loss: 2.4237395666657604

Epoch: 5| Step: 7
Training loss: 1.8827375341662984
Validation loss: 2.413062817637625

Epoch: 5| Step: 8
Training loss: 2.065333183324688
Validation loss: 2.4444331252553675

Epoch: 5| Step: 9
Training loss: 1.4795663141496256
Validation loss: 2.4746283269777205

Epoch: 5| Step: 10
Training loss: 1.2997556199944484
Validation loss: 2.506180129975908

Epoch: 5| Step: 11
Training loss: 1.2779912678117278
Validation loss: 2.4773476416056917

Epoch: 404| Step: 0
Training loss: 1.7189589633492806
Validation loss: 2.460373881552395

Epoch: 5| Step: 1
Training loss: 1.1988469146916643
Validation loss: 2.4766340997496306

Epoch: 5| Step: 2
Training loss: 1.5804316216037901
Validation loss: 2.4344191603109544

Epoch: 5| Step: 3
Training loss: 1.906377256554555
Validation loss: 2.4761478907345364

Epoch: 5| Step: 4
Training loss: 1.485992754722173
Validation loss: 2.4585961663373985

Epoch: 5| Step: 5
Training loss: 1.4899623717606747
Validation loss: 2.4670513602720505

Epoch: 5| Step: 6
Training loss: 2.039842244574679
Validation loss: 2.487513181597163

Epoch: 5| Step: 7
Training loss: 1.428167316636206
Validation loss: 2.4840635468332035

Epoch: 5| Step: 8
Training loss: 1.5026884622801226
Validation loss: 2.4800848355895697

Epoch: 5| Step: 9
Training loss: 1.5374063013570194
Validation loss: 2.44719979902202

Epoch: 5| Step: 10
Training loss: 1.6343887970380313
Validation loss: 2.443151329447094

Epoch: 5| Step: 11
Training loss: 1.3905393595524282
Validation loss: 2.4250703426200286

Epoch: 405| Step: 0
Training loss: 1.5857699451349911
Validation loss: 2.398140581372157

Epoch: 5| Step: 1
Training loss: 1.4300207364639574
Validation loss: 2.4058537569809864

Epoch: 5| Step: 2
Training loss: 1.570317282598244
Validation loss: 2.426143666262428

Epoch: 5| Step: 3
Training loss: 1.3918800262785225
Validation loss: 2.422823463860256

Epoch: 5| Step: 4
Training loss: 0.9878358100957464
Validation loss: 2.4501751031874597

Epoch: 5| Step: 5
Training loss: 1.80357551169574
Validation loss: 2.42934357640715

Epoch: 5| Step: 6
Training loss: 1.67219761382901
Validation loss: 2.4642945255559034

Epoch: 5| Step: 7
Training loss: 1.4937477143721072
Validation loss: 2.442238660176041

Epoch: 5| Step: 8
Training loss: 1.6434094732621756
Validation loss: 2.4373468734049832

Epoch: 5| Step: 9
Training loss: 1.8129526428122595
Validation loss: 2.4657939000493427

Epoch: 5| Step: 10
Training loss: 1.7811929124752395
Validation loss: 2.449131381531435

Epoch: 5| Step: 11
Training loss: 1.3328811305846961
Validation loss: 2.453471282848192

Epoch: 406| Step: 0
Training loss: 1.5733602374141866
Validation loss: 2.4260885808745543

Epoch: 5| Step: 1
Training loss: 1.4211563138522447
Validation loss: 2.478031180242566

Epoch: 5| Step: 2
Training loss: 1.3502615692908708
Validation loss: 2.4761998325191223

Epoch: 5| Step: 3
Training loss: 1.4461760544398392
Validation loss: 2.524379593732532

Epoch: 5| Step: 4
Training loss: 1.39441780889807
Validation loss: 2.4893979850842514

Epoch: 5| Step: 5
Training loss: 1.3315191095422674
Validation loss: 2.507186793765021

Epoch: 5| Step: 6
Training loss: 1.9358314589799117
Validation loss: 2.517472307592077

Epoch: 5| Step: 7
Training loss: 1.6244353266951672
Validation loss: 2.5308093444868858

Epoch: 5| Step: 8
Training loss: 1.5880799503234668
Validation loss: 2.486261459299884

Epoch: 5| Step: 9
Training loss: 1.5833607303189896
Validation loss: 2.5017899542673705

Epoch: 5| Step: 10
Training loss: 1.5603706346282855
Validation loss: 2.4958622585800625

Epoch: 5| Step: 11
Training loss: 1.8075651535384551
Validation loss: 2.4799395179359296

Epoch: 407| Step: 0
Training loss: 1.9458508952925493
Validation loss: 2.4915174382685503

Epoch: 5| Step: 1
Training loss: 1.7412387334345467
Validation loss: 2.5139398636986026

Epoch: 5| Step: 2
Training loss: 1.318359827112191
Validation loss: 2.512104785891073

Epoch: 5| Step: 3
Training loss: 1.526180048408815
Validation loss: 2.482573157702258

Epoch: 5| Step: 4
Training loss: 1.6006732984328937
Validation loss: 2.5112597420356164

Epoch: 5| Step: 5
Training loss: 1.6657196533333503
Validation loss: 2.4658984523767975

Epoch: 5| Step: 6
Training loss: 1.7962433077820925
Validation loss: 2.450013886950834

Epoch: 5| Step: 7
Training loss: 1.4140676424554715
Validation loss: 2.4743299198500526

Epoch: 5| Step: 8
Training loss: 1.654569384976323
Validation loss: 2.437210063726346

Epoch: 5| Step: 9
Training loss: 1.2809654012797604
Validation loss: 2.4224383693633045

Epoch: 5| Step: 10
Training loss: 1.1228932681975192
Validation loss: 2.422063196725141

Epoch: 5| Step: 11
Training loss: 1.2037746607550923
Validation loss: 2.4362707054128645

Epoch: 408| Step: 0
Training loss: 1.1217371460101848
Validation loss: 2.4503414170801237

Epoch: 5| Step: 1
Training loss: 1.431932697973574
Validation loss: 2.433885782353349

Epoch: 5| Step: 2
Training loss: 1.4058969690331582
Validation loss: 2.4530826593296546

Epoch: 5| Step: 3
Training loss: 1.6083212059762868
Validation loss: 2.4728503479992385

Epoch: 5| Step: 4
Training loss: 1.5636990333502911
Validation loss: 2.450431683601411

Epoch: 5| Step: 5
Training loss: 1.3859866936693084
Validation loss: 2.4259966039560443

Epoch: 5| Step: 6
Training loss: 1.8836365475375005
Validation loss: 2.4352328850872125

Epoch: 5| Step: 7
Training loss: 1.5910982997888798
Validation loss: 2.412059137848248

Epoch: 5| Step: 8
Training loss: 1.1137041861276733
Validation loss: 2.411749677312521

Epoch: 5| Step: 9
Training loss: 1.4074631438503096
Validation loss: 2.450247103043778

Epoch: 5| Step: 10
Training loss: 2.0205770769226796
Validation loss: 2.4425029010781505

Epoch: 5| Step: 11
Training loss: 0.8851963030784037
Validation loss: 2.4175454150697173

Epoch: 409| Step: 0
Training loss: 1.6297643948753282
Validation loss: 2.461785734413985

Epoch: 5| Step: 1
Training loss: 1.2934977667943715
Validation loss: 2.454408338291352

Epoch: 5| Step: 2
Training loss: 1.400598061067186
Validation loss: 2.4764504472511724

Epoch: 5| Step: 3
Training loss: 1.4213381581740467
Validation loss: 2.4594906221942416

Epoch: 5| Step: 4
Training loss: 1.470193032286937
Validation loss: 2.4604724101428195

Epoch: 5| Step: 5
Training loss: 2.0417894858443155
Validation loss: 2.454681708419899

Epoch: 5| Step: 6
Training loss: 1.5803019550161006
Validation loss: 2.4656710840776737

Epoch: 5| Step: 7
Training loss: 1.45150379271608
Validation loss: 2.4970562411953514

Epoch: 5| Step: 8
Training loss: 1.452871567150433
Validation loss: 2.469760708002815

Epoch: 5| Step: 9
Training loss: 1.3418137106470873
Validation loss: 2.429677388782457

Epoch: 5| Step: 10
Training loss: 1.1218143499870163
Validation loss: 2.4630810681374276

Epoch: 5| Step: 11
Training loss: 1.8679529001926833
Validation loss: 2.457921279841033

Epoch: 410| Step: 0
Training loss: 1.932698237033746
Validation loss: 2.4361973036509235

Epoch: 5| Step: 1
Training loss: 1.5524701739408562
Validation loss: 2.4428777059846425

Epoch: 5| Step: 2
Training loss: 1.3239075961872064
Validation loss: 2.4213078152579963

Epoch: 5| Step: 3
Training loss: 1.4704184288273052
Validation loss: 2.457036944748142

Epoch: 5| Step: 4
Training loss: 1.4355537673888537
Validation loss: 2.478197214101439

Epoch: 5| Step: 5
Training loss: 1.162791845132572
Validation loss: 2.4694087079257105

Epoch: 5| Step: 6
Training loss: 1.6188324012550748
Validation loss: 2.4669425037414436

Epoch: 5| Step: 7
Training loss: 1.4798834859245613
Validation loss: 2.4423910143649823

Epoch: 5| Step: 8
Training loss: 1.6697584641126848
Validation loss: 2.4634673219609957

Epoch: 5| Step: 9
Training loss: 1.5878343185069923
Validation loss: 2.4159639065674825

Epoch: 5| Step: 10
Training loss: 1.453107280007885
Validation loss: 2.389741921476758

Epoch: 5| Step: 11
Training loss: 1.1471779592060667
Validation loss: 2.441275114479454

Epoch: 411| Step: 0
Training loss: 1.136342094390597
Validation loss: 2.398926750259002

Epoch: 5| Step: 1
Training loss: 1.3623645400158424
Validation loss: 2.392040091502878

Epoch: 5| Step: 2
Training loss: 1.4966840650117863
Validation loss: 2.464272208634218

Epoch: 5| Step: 3
Training loss: 1.0943722725860927
Validation loss: 2.495650055502631

Epoch: 5| Step: 4
Training loss: 1.787548707418467
Validation loss: 2.478527813564078

Epoch: 5| Step: 5
Training loss: 1.3940599858035359
Validation loss: 2.481526727402942

Epoch: 5| Step: 6
Training loss: 1.52963358362272
Validation loss: 2.4912916006170858

Epoch: 5| Step: 7
Training loss: 1.5150755053296767
Validation loss: 2.5321058584628653

Epoch: 5| Step: 8
Training loss: 1.404411300645005
Validation loss: 2.5137882991170337

Epoch: 5| Step: 9
Training loss: 1.8215055689845685
Validation loss: 2.514152518447434

Epoch: 5| Step: 10
Training loss: 1.8760340700166944
Validation loss: 2.534410763828041

Epoch: 5| Step: 11
Training loss: 0.20653332807257627
Validation loss: 2.531863938747436

Epoch: 412| Step: 0
Training loss: 1.2837944352167974
Validation loss: 2.525107981321185

Epoch: 5| Step: 1
Training loss: 1.3052721369747
Validation loss: 2.541731787978186

Epoch: 5| Step: 2
Training loss: 1.314628827395503
Validation loss: 2.492746352274975

Epoch: 5| Step: 3
Training loss: 1.411655379426247
Validation loss: 2.4680216676602242

Epoch: 5| Step: 4
Training loss: 1.6153112759901926
Validation loss: 2.4980588807788586

Epoch: 5| Step: 5
Training loss: 2.090220080565435
Validation loss: 2.468401602615113

Epoch: 5| Step: 6
Training loss: 1.541994970607843
Validation loss: 2.4842276179584477

Epoch: 5| Step: 7
Training loss: 1.3706494777179294
Validation loss: 2.494295420631358

Epoch: 5| Step: 8
Training loss: 1.4895019331167532
Validation loss: 2.4889385307460654

Epoch: 5| Step: 9
Training loss: 1.7358280315614272
Validation loss: 2.5184711680591856

Epoch: 5| Step: 10
Training loss: 1.4451479431500922
Validation loss: 2.5158786547075436

Epoch: 5| Step: 11
Training loss: 1.2326741149358222
Validation loss: 2.5145541196251795

Epoch: 413| Step: 0
Training loss: 1.618613531185311
Validation loss: 2.4676182522856767

Epoch: 5| Step: 1
Training loss: 1.9790528783379104
Validation loss: 2.510950666170352

Epoch: 5| Step: 2
Training loss: 1.6422822121004412
Validation loss: 2.481685606275968

Epoch: 5| Step: 3
Training loss: 1.7124219751334073
Validation loss: 2.5051998778033298

Epoch: 5| Step: 4
Training loss: 1.4509108707860763
Validation loss: 2.444231342755591

Epoch: 5| Step: 5
Training loss: 1.3078619433756369
Validation loss: 2.483419490499459

Epoch: 5| Step: 6
Training loss: 1.3006988590941988
Validation loss: 2.4231810585958242

Epoch: 5| Step: 7
Training loss: 1.3447948651776835
Validation loss: 2.473534215745992

Epoch: 5| Step: 8
Training loss: 1.4909443894984495
Validation loss: 2.482509896603437

Epoch: 5| Step: 9
Training loss: 1.2400954761972318
Validation loss: 2.4940066101187504

Epoch: 5| Step: 10
Training loss: 1.1513147447337524
Validation loss: 2.4753386143842864

Epoch: 5| Step: 11
Training loss: 1.336448527077397
Validation loss: 2.4428146409663856

Epoch: 414| Step: 0
Training loss: 1.561096323847546
Validation loss: 2.4325756231264224

Epoch: 5| Step: 1
Training loss: 1.1494601620461513
Validation loss: 2.5060054491678487

Epoch: 5| Step: 2
Training loss: 1.765755842643965
Validation loss: 2.4537248384283923

Epoch: 5| Step: 3
Training loss: 1.8934787618948425
Validation loss: 2.451816963327682

Epoch: 5| Step: 4
Training loss: 1.4658917963030655
Validation loss: 2.5089068377092767

Epoch: 5| Step: 5
Training loss: 1.4590945119281238
Validation loss: 2.4597023705247953

Epoch: 5| Step: 6
Training loss: 1.2742783748258333
Validation loss: 2.498760329290849

Epoch: 5| Step: 7
Training loss: 1.1890673082131658
Validation loss: 2.4688567045949394

Epoch: 5| Step: 8
Training loss: 1.849256858545828
Validation loss: 2.4981956884992402

Epoch: 5| Step: 9
Training loss: 1.3302755111344367
Validation loss: 2.484244249210085

Epoch: 5| Step: 10
Training loss: 1.4977897413416172
Validation loss: 2.5043122770234185

Epoch: 5| Step: 11
Training loss: 1.3655020651925671
Validation loss: 2.5488755183971823

Epoch: 415| Step: 0
Training loss: 1.4163186636943348
Validation loss: 2.4703374981645836

Epoch: 5| Step: 1
Training loss: 1.2650591209226651
Validation loss: 2.5240987063008

Epoch: 5| Step: 2
Training loss: 1.946770546745565
Validation loss: 2.5184094871701492

Epoch: 5| Step: 3
Training loss: 1.3934683716205793
Validation loss: 2.5096634741353405

Epoch: 5| Step: 4
Training loss: 1.4251233398866816
Validation loss: 2.5228424787966937

Epoch: 5| Step: 5
Training loss: 1.5791642194878264
Validation loss: 2.4863546469433295

Epoch: 5| Step: 6
Training loss: 1.5505237125279872
Validation loss: 2.4994506669504633

Epoch: 5| Step: 7
Training loss: 1.2923532271288485
Validation loss: 2.502359171190719

Epoch: 5| Step: 8
Training loss: 1.1879965095532963
Validation loss: 2.463090776039392

Epoch: 5| Step: 9
Training loss: 1.838672305500733
Validation loss: 2.482118273362062

Epoch: 5| Step: 10
Training loss: 1.283601928239101
Validation loss: 2.4749499665928316

Epoch: 5| Step: 11
Training loss: 1.8763264732355158
Validation loss: 2.476940479175095

Epoch: 416| Step: 0
Training loss: 1.4124116481729585
Validation loss: 2.4651383285901045

Epoch: 5| Step: 1
Training loss: 1.1965799032615942
Validation loss: 2.4472847765523036

Epoch: 5| Step: 2
Training loss: 1.4286195695803738
Validation loss: 2.466853258178713

Epoch: 5| Step: 3
Training loss: 1.3149477069305742
Validation loss: 2.463909659345322

Epoch: 5| Step: 4
Training loss: 1.4030515112036408
Validation loss: 2.4299386110387546

Epoch: 5| Step: 5
Training loss: 1.4267255608414156
Validation loss: 2.4965049591990582

Epoch: 5| Step: 6
Training loss: 1.4470843202847712
Validation loss: 2.488090503833271

Epoch: 5| Step: 7
Training loss: 1.3004936839752939
Validation loss: 2.500978622028536

Epoch: 5| Step: 8
Training loss: 1.8336772234932421
Validation loss: 2.53685439122812

Epoch: 5| Step: 9
Training loss: 1.017406017077654
Validation loss: 2.4848584758312042

Epoch: 5| Step: 10
Training loss: 1.8707102977960082
Validation loss: 2.4765539600373487

Epoch: 5| Step: 11
Training loss: 1.4588229946777007
Validation loss: 2.4120210144909144

Epoch: 417| Step: 0
Training loss: 1.4752934568049185
Validation loss: 2.482766804515692

Epoch: 5| Step: 1
Training loss: 1.5679672720179414
Validation loss: 2.440635787445077

Epoch: 5| Step: 2
Training loss: 1.3227943253704866
Validation loss: 2.4694692151553572

Epoch: 5| Step: 3
Training loss: 1.7409540437245434
Validation loss: 2.486259968940461

Epoch: 5| Step: 4
Training loss: 1.527574604666183
Validation loss: 2.4936448303711014

Epoch: 5| Step: 5
Training loss: 1.1951240939585843
Validation loss: 2.499926554077847

Epoch: 5| Step: 6
Training loss: 1.1275102372138235
Validation loss: 2.465524151330682

Epoch: 5| Step: 7
Training loss: 1.1321917181228622
Validation loss: 2.462692857829276

Epoch: 5| Step: 8
Training loss: 2.0720421817123826
Validation loss: 2.488381547967499

Epoch: 5| Step: 9
Training loss: 1.480970071344667
Validation loss: 2.464156299290173

Epoch: 5| Step: 10
Training loss: 1.1025112746650485
Validation loss: 2.469946925221101

Epoch: 5| Step: 11
Training loss: 1.7278785350459558
Validation loss: 2.4555533694426077

Epoch: 418| Step: 0
Training loss: 1.6640437308672285
Validation loss: 2.4425198632079796

Epoch: 5| Step: 1
Training loss: 1.0993205312797374
Validation loss: 2.4497952834710706

Epoch: 5| Step: 2
Training loss: 1.167475210167606
Validation loss: 2.4477858177005785

Epoch: 5| Step: 3
Training loss: 1.055335855764948
Validation loss: 2.451111183580319

Epoch: 5| Step: 4
Training loss: 1.2671655297873623
Validation loss: 2.4668642076659415

Epoch: 5| Step: 5
Training loss: 1.2818530454573627
Validation loss: 2.4774791092285358

Epoch: 5| Step: 6
Training loss: 2.0360990891991473
Validation loss: 2.4814648247774476

Epoch: 5| Step: 7
Training loss: 1.5475956942993594
Validation loss: 2.4559899667310745

Epoch: 5| Step: 8
Training loss: 1.6556442880569
Validation loss: 2.426406738758089

Epoch: 5| Step: 9
Training loss: 1.2687620679159273
Validation loss: 2.4763083723673502

Epoch: 5| Step: 10
Training loss: 1.5295173807593831
Validation loss: 2.467151808606373

Epoch: 5| Step: 11
Training loss: 1.9500057489359304
Validation loss: 2.53544818390498

Epoch: 419| Step: 0
Training loss: 1.457697575363945
Validation loss: 2.5295109799369144

Epoch: 5| Step: 1
Training loss: 1.3273360657988746
Validation loss: 2.5335057964305068

Epoch: 5| Step: 2
Training loss: 1.2388722065561266
Validation loss: 2.451196001195022

Epoch: 5| Step: 3
Training loss: 1.3795183244368197
Validation loss: 2.489280164819557

Epoch: 5| Step: 4
Training loss: 1.8314023107520983
Validation loss: 2.475996424082843

Epoch: 5| Step: 5
Training loss: 1.6103458624207412
Validation loss: 2.523320611661726

Epoch: 5| Step: 6
Training loss: 1.293710086962406
Validation loss: 2.4890866176460906

Epoch: 5| Step: 7
Training loss: 1.373255707011369
Validation loss: 2.4799734867701417

Epoch: 5| Step: 8
Training loss: 1.931924982229613
Validation loss: 2.45104892214636

Epoch: 5| Step: 9
Training loss: 1.2308636712786512
Validation loss: 2.421158571822909

Epoch: 5| Step: 10
Training loss: 1.4345196220941336
Validation loss: 2.4061208170112725

Epoch: 5| Step: 11
Training loss: 1.3563293011945177
Validation loss: 2.40445394491002

Epoch: 420| Step: 0
Training loss: 1.7202467903248075
Validation loss: 2.477778865088617

Epoch: 5| Step: 1
Training loss: 1.2969036788527049
Validation loss: 2.452858954984533

Epoch: 5| Step: 2
Training loss: 1.93419340449102
Validation loss: 2.416008073717352

Epoch: 5| Step: 3
Training loss: 1.7440873807531176
Validation loss: 2.48299925677713

Epoch: 5| Step: 4
Training loss: 0.8621376022605837
Validation loss: 2.441448290653658

Epoch: 5| Step: 5
Training loss: 1.3934668317446546
Validation loss: 2.4657943109834752

Epoch: 5| Step: 6
Training loss: 1.4342132809629562
Validation loss: 2.4954546297728926

Epoch: 5| Step: 7
Training loss: 1.312755832261784
Validation loss: 2.456229490982382

Epoch: 5| Step: 8
Training loss: 1.342559375693065
Validation loss: 2.4971493084540652

Epoch: 5| Step: 9
Training loss: 1.0945045048606599
Validation loss: 2.4735829734475128

Epoch: 5| Step: 10
Training loss: 1.0988369493506485
Validation loss: 2.463443517577981

Epoch: 5| Step: 11
Training loss: 1.6657288853524996
Validation loss: 2.4874898269739227

Epoch: 421| Step: 0
Training loss: 1.6033407620094655
Validation loss: 2.4714558697358915

Epoch: 5| Step: 1
Training loss: 1.0655300467240714
Validation loss: 2.4731540911967667

Epoch: 5| Step: 2
Training loss: 1.5045079996663961
Validation loss: 2.513375718089702

Epoch: 5| Step: 3
Training loss: 1.4989598959710744
Validation loss: 2.498426029321336

Epoch: 5| Step: 4
Training loss: 1.56382344464512
Validation loss: 2.477630280752745

Epoch: 5| Step: 5
Training loss: 1.2022853249674725
Validation loss: 2.4622888356727315

Epoch: 5| Step: 6
Training loss: 1.6338763262148193
Validation loss: 2.413152595236431

Epoch: 5| Step: 7
Training loss: 1.3627673385544437
Validation loss: 2.402643915874785

Epoch: 5| Step: 8
Training loss: 1.4031267025943612
Validation loss: 2.3907185205854127

Epoch: 5| Step: 9
Training loss: 1.1594160910673752
Validation loss: 2.431567410307746

Epoch: 5| Step: 10
Training loss: 1.6944200830150147
Validation loss: 2.4425376813500983

Epoch: 5| Step: 11
Training loss: 0.7839818873648718
Validation loss: 2.451617836879781

Epoch: 422| Step: 0
Training loss: 1.5317106527184314
Validation loss: 2.4514240393551465

Epoch: 5| Step: 1
Training loss: 1.350740215677694
Validation loss: 2.431466092506492

Epoch: 5| Step: 2
Training loss: 1.3206146165445896
Validation loss: 2.5288608484491166

Epoch: 5| Step: 3
Training loss: 1.5269576655466994
Validation loss: 2.539025651713288

Epoch: 5| Step: 4
Training loss: 1.9579496075357543
Validation loss: 2.528235225687257

Epoch: 5| Step: 5
Training loss: 1.2692560455166269
Validation loss: 2.5720684195087715

Epoch: 5| Step: 6
Training loss: 0.9534878899815942
Validation loss: 2.5249425417276594

Epoch: 5| Step: 7
Training loss: 1.4458984836700486
Validation loss: 2.54748619094565

Epoch: 5| Step: 8
Training loss: 1.7026255864052113
Validation loss: 2.4981254543405513

Epoch: 5| Step: 9
Training loss: 1.379946740269872
Validation loss: 2.437879648964758

Epoch: 5| Step: 10
Training loss: 1.3525934862555615
Validation loss: 2.4722280749300523

Epoch: 5| Step: 11
Training loss: 1.4744476836021303
Validation loss: 2.4616795465609784

Epoch: 423| Step: 0
Training loss: 1.433515998748393
Validation loss: 2.464688593942915

Epoch: 5| Step: 1
Training loss: 1.8343868118763658
Validation loss: 2.474359005388707

Epoch: 5| Step: 2
Training loss: 1.255224135472192
Validation loss: 2.4354847336963297

Epoch: 5| Step: 3
Training loss: 0.9185731886359733
Validation loss: 2.4912812828540907

Epoch: 5| Step: 4
Training loss: 1.7081331585473953
Validation loss: 2.48456442008869

Epoch: 5| Step: 5
Training loss: 1.341615889557863
Validation loss: 2.5122834337663047

Epoch: 5| Step: 6
Training loss: 1.8089002180695
Validation loss: 2.49750196107438

Epoch: 5| Step: 7
Training loss: 1.3378327962810053
Validation loss: 2.5107013823216335

Epoch: 5| Step: 8
Training loss: 1.1442269190801784
Validation loss: 2.515759118969206

Epoch: 5| Step: 9
Training loss: 1.1591479097042168
Validation loss: 2.5396379943474914

Epoch: 5| Step: 10
Training loss: 1.3719905083414181
Validation loss: 2.6019460378200128

Epoch: 5| Step: 11
Training loss: 2.753843915517936
Validation loss: 2.587672658894022

Epoch: 424| Step: 0
Training loss: 1.3603334665292943
Validation loss: 2.5753335695037847

Epoch: 5| Step: 1
Training loss: 1.3811451401759
Validation loss: 2.6002213894292363

Epoch: 5| Step: 2
Training loss: 1.0070131665745086
Validation loss: 2.5155729837351184

Epoch: 5| Step: 3
Training loss: 1.6443581388066493
Validation loss: 2.4769931783758037

Epoch: 5| Step: 4
Training loss: 1.577283502706329
Validation loss: 2.5085981847549026

Epoch: 5| Step: 5
Training loss: 1.2590366827277033
Validation loss: 2.473418943263649

Epoch: 5| Step: 6
Training loss: 1.004854222253331
Validation loss: 2.466063639403349

Epoch: 5| Step: 7
Training loss: 1.7104904078371017
Validation loss: 2.5085598751962066

Epoch: 5| Step: 8
Training loss: 1.1412729487039015
Validation loss: 2.5065859511582733

Epoch: 5| Step: 9
Training loss: 1.925423486374604
Validation loss: 2.45802861415673

Epoch: 5| Step: 10
Training loss: 1.2316004801316547
Validation loss: 2.476932405751014

Epoch: 5| Step: 11
Training loss: 1.2581652981727978
Validation loss: 2.449427004147953

Epoch: 425| Step: 0
Training loss: 1.1219915855418585
Validation loss: 2.4539630090269697

Epoch: 5| Step: 1
Training loss: 1.1244312014059603
Validation loss: 2.452029957726497

Epoch: 5| Step: 2
Training loss: 1.1344741210507727
Validation loss: 2.480473343652191

Epoch: 5| Step: 3
Training loss: 1.9594262367375752
Validation loss: 2.4501468171679535

Epoch: 5| Step: 4
Training loss: 1.4774695138642264
Validation loss: 2.5641373814991315

Epoch: 5| Step: 5
Training loss: 1.6807131452558293
Validation loss: 2.5119568398975867

Epoch: 5| Step: 6
Training loss: 1.3028612432513929
Validation loss: 2.5066408032609493

Epoch: 5| Step: 7
Training loss: 1.5889309598929704
Validation loss: 2.4681334107829556

Epoch: 5| Step: 8
Training loss: 1.2356981356736458
Validation loss: 2.471226393783551

Epoch: 5| Step: 9
Training loss: 1.314822503573861
Validation loss: 2.4638522250113892

Epoch: 5| Step: 10
Training loss: 1.5290836658178397
Validation loss: 2.4322935461054747

Epoch: 5| Step: 11
Training loss: 1.6361059530220408
Validation loss: 2.4700340380266708

Epoch: 426| Step: 0
Training loss: 1.1999977389950114
Validation loss: 2.484027940272406

Epoch: 5| Step: 1
Training loss: 1.4393324574963613
Validation loss: 2.5126194859081674

Epoch: 5| Step: 2
Training loss: 1.0870854738701046
Validation loss: 2.5067328231363533

Epoch: 5| Step: 3
Training loss: 1.2275759646650946
Validation loss: 2.538769835208832

Epoch: 5| Step: 4
Training loss: 1.3201652760783495
Validation loss: 2.5718018836207475

Epoch: 5| Step: 5
Training loss: 1.797876957719712
Validation loss: 2.5528280780447834

Epoch: 5| Step: 6
Training loss: 1.4266196934076476
Validation loss: 2.536628988949455

Epoch: 5| Step: 7
Training loss: 1.5213279790647558
Validation loss: 2.521734164724043

Epoch: 5| Step: 8
Training loss: 1.4327125439571122
Validation loss: 2.4959011252297465

Epoch: 5| Step: 9
Training loss: 1.364826146816374
Validation loss: 2.5070590930540533

Epoch: 5| Step: 10
Training loss: 1.5329252926762724
Validation loss: 2.5411030732065343

Epoch: 5| Step: 11
Training loss: 0.7636615723210085
Validation loss: 2.529051630608057

Epoch: 427| Step: 0
Training loss: 1.4945434027425482
Validation loss: 2.5010921079693342

Epoch: 5| Step: 1
Training loss: 1.4778014137334614
Validation loss: 2.5459699017115844

Epoch: 5| Step: 2
Training loss: 2.09818879085925
Validation loss: 2.5467242311344993

Epoch: 5| Step: 3
Training loss: 1.0839172342488144
Validation loss: 2.5409680302683153

Epoch: 5| Step: 4
Training loss: 1.2808628893097564
Validation loss: 2.521051881448607

Epoch: 5| Step: 5
Training loss: 1.3845810437630752
Validation loss: 2.4808552638609314

Epoch: 5| Step: 6
Training loss: 1.2547761270615485
Validation loss: 2.493570874568166

Epoch: 5| Step: 7
Training loss: 1.544045837720083
Validation loss: 2.5298859449104265

Epoch: 5| Step: 8
Training loss: 1.4067101891204286
Validation loss: 2.51933966014179

Epoch: 5| Step: 9
Training loss: 1.3806114999465962
Validation loss: 2.528188596663504

Epoch: 5| Step: 10
Training loss: 1.507887843329912
Validation loss: 2.565058210448577

Epoch: 5| Step: 11
Training loss: 1.4323365730412945
Validation loss: 2.5419850358485045

Epoch: 428| Step: 0
Training loss: 1.761394665464343
Validation loss: 2.458546957874404

Epoch: 5| Step: 1
Training loss: 1.4647447069381394
Validation loss: 2.4682059765013626

Epoch: 5| Step: 2
Training loss: 1.2082755085931924
Validation loss: 2.5002055282350293

Epoch: 5| Step: 3
Training loss: 1.248617313503032
Validation loss: 2.4696987598524043

Epoch: 5| Step: 4
Training loss: 1.787443869716497
Validation loss: 2.4673131229887413

Epoch: 5| Step: 5
Training loss: 1.4452006528724612
Validation loss: 2.4374750943011896

Epoch: 5| Step: 6
Training loss: 1.1301204922669201
Validation loss: 2.4278922199750945

Epoch: 5| Step: 7
Training loss: 1.373965828127757
Validation loss: 2.450448075990327

Epoch: 5| Step: 8
Training loss: 1.5772037649931583
Validation loss: 2.4559367966213044

Epoch: 5| Step: 9
Training loss: 1.2719169853460148
Validation loss: 2.4805217006368228

Epoch: 5| Step: 10
Training loss: 1.8045967376476564
Validation loss: 2.5138479278334867

Epoch: 5| Step: 11
Training loss: 1.1634457381594896
Validation loss: 2.54937086307171

Epoch: 429| Step: 0
Training loss: 1.320606943739124
Validation loss: 2.526843698077959

Epoch: 5| Step: 1
Training loss: 1.2881298505977716
Validation loss: 2.525606449559076

Epoch: 5| Step: 2
Training loss: 1.20397532745758
Validation loss: 2.491404550910052

Epoch: 5| Step: 3
Training loss: 1.3806929211467998
Validation loss: 2.529476969430668

Epoch: 5| Step: 4
Training loss: 1.5234149637756185
Validation loss: 2.4956100962399472

Epoch: 5| Step: 5
Training loss: 1.9596917196066261
Validation loss: 2.443009889990449

Epoch: 5| Step: 6
Training loss: 1.2955775377456322
Validation loss: 2.5014956689151915

Epoch: 5| Step: 7
Training loss: 1.3569780021942235
Validation loss: 2.496964980673636

Epoch: 5| Step: 8
Training loss: 1.521088339272365
Validation loss: 2.465907834957918

Epoch: 5| Step: 9
Training loss: 1.1348520269017242
Validation loss: 2.4864101591159207

Epoch: 5| Step: 10
Training loss: 1.2060606180269169
Validation loss: 2.4704906588384667

Epoch: 5| Step: 11
Training loss: 1.6493764797376071
Validation loss: 2.4643931997247783

Epoch: 430| Step: 0
Training loss: 1.3829294791015523
Validation loss: 2.465490281583

Epoch: 5| Step: 1
Training loss: 1.1092225628207102
Validation loss: 2.4663774783712147

Epoch: 5| Step: 2
Training loss: 1.5276132331247003
Validation loss: 2.484035848664223

Epoch: 5| Step: 3
Training loss: 1.3698116731330934
Validation loss: 2.4537830361117887

Epoch: 5| Step: 4
Training loss: 1.7427246907757277
Validation loss: 2.4696964228389757

Epoch: 5| Step: 5
Training loss: 1.4176188055504702
Validation loss: 2.452426802942442

Epoch: 5| Step: 6
Training loss: 1.3153111461760227
Validation loss: 2.5082176570474326

Epoch: 5| Step: 7
Training loss: 1.287211852559891
Validation loss: 2.4837774081830526

Epoch: 5| Step: 8
Training loss: 1.2548042480574384
Validation loss: 2.5033934371080604

Epoch: 5| Step: 9
Training loss: 1.1466304549517157
Validation loss: 2.489489137923875

Epoch: 5| Step: 10
Training loss: 1.6526905895213364
Validation loss: 2.498246201632335

Epoch: 5| Step: 11
Training loss: 0.9572911746439259
Validation loss: 2.46887654974067

Epoch: 431| Step: 0
Training loss: 1.231265727296098
Validation loss: 2.505388778141356

Epoch: 5| Step: 1
Training loss: 1.6307351070731622
Validation loss: 2.4995191628261493

Epoch: 5| Step: 2
Training loss: 1.0553947055688913
Validation loss: 2.476517738074149

Epoch: 5| Step: 3
Training loss: 1.254180022682898
Validation loss: 2.4778722334299483

Epoch: 5| Step: 4
Training loss: 1.3497596579762754
Validation loss: 2.428539516001551

Epoch: 5| Step: 5
Training loss: 1.2330336707159304
Validation loss: 2.4919415993390115

Epoch: 5| Step: 6
Training loss: 1.2105419374250153
Validation loss: 2.447234910354625

Epoch: 5| Step: 7
Training loss: 0.9327818081150023
Validation loss: 2.469601520526926

Epoch: 5| Step: 8
Training loss: 1.6048744753894593
Validation loss: 2.4480325725521705

Epoch: 5| Step: 9
Training loss: 1.2818738767562252
Validation loss: 2.4504968369728237

Epoch: 5| Step: 10
Training loss: 1.2523248510427987
Validation loss: 2.5031369158603667

Epoch: 5| Step: 11
Training loss: 0.9140684991623378
Validation loss: 2.495992892301686

Epoch: 432| Step: 0
Training loss: 1.242452916993656
Validation loss: 2.516156837367197

Epoch: 5| Step: 1
Training loss: 1.6232097741375613
Validation loss: 2.493682598216565

Epoch: 5| Step: 2
Training loss: 1.1151628621650838
Validation loss: 2.4813878957127535

Epoch: 5| Step: 3
Training loss: 1.5117722139588998
Validation loss: 2.519498398046684

Epoch: 5| Step: 4
Training loss: 0.8478616562290602
Validation loss: 2.44369389078519

Epoch: 5| Step: 5
Training loss: 1.257157291331037
Validation loss: 2.4646862602400055

Epoch: 5| Step: 6
Training loss: 0.9528234348689325
Validation loss: 2.431238732070766

Epoch: 5| Step: 7
Training loss: 1.4570047411923317
Validation loss: 2.487009642782104

Epoch: 5| Step: 8
Training loss: 1.259515497970182
Validation loss: 2.4864015830576367

Epoch: 5| Step: 9
Training loss: 1.8616757943804174
Validation loss: 2.4659476249234618

Epoch: 5| Step: 10
Training loss: 0.9815760890696504
Validation loss: 2.508974091510108

Epoch: 5| Step: 11
Training loss: 1.1522324847799765
Validation loss: 2.4816533821763205

Epoch: 433| Step: 0
Training loss: 1.003311871862004
Validation loss: 2.4857266825621043

Epoch: 5| Step: 1
Training loss: 1.3113000470730085
Validation loss: 2.513655861322138

Epoch: 5| Step: 2
Training loss: 1.097898137601577
Validation loss: 2.502059699991646

Epoch: 5| Step: 3
Training loss: 1.426064826251554
Validation loss: 2.498350242823032

Epoch: 5| Step: 4
Training loss: 1.0123517033799887
Validation loss: 2.5283536863377463

Epoch: 5| Step: 5
Training loss: 1.4060742162404631
Validation loss: 2.5254631415603823

Epoch: 5| Step: 6
Training loss: 1.3254233313813346
Validation loss: 2.49667676744298

Epoch: 5| Step: 7
Training loss: 1.5676093677531893
Validation loss: 2.474098953801484

Epoch: 5| Step: 8
Training loss: 1.1402019604593636
Validation loss: 2.496986078426197

Epoch: 5| Step: 9
Training loss: 1.2623977959687365
Validation loss: 2.4947395810375648

Epoch: 5| Step: 10
Training loss: 1.3854672224338174
Validation loss: 2.467754928022299

Epoch: 5| Step: 11
Training loss: 1.5896294376725004
Validation loss: 2.464831526011097

Epoch: 434| Step: 0
Training loss: 1.244388286188185
Validation loss: 2.492553596353973

Epoch: 5| Step: 1
Training loss: 1.1469422032262584
Validation loss: 2.468587596396379

Epoch: 5| Step: 2
Training loss: 1.7049850665694206
Validation loss: 2.5343742398826503

Epoch: 5| Step: 3
Training loss: 1.0535496543222913
Validation loss: 2.5240884065402533

Epoch: 5| Step: 4
Training loss: 1.4795937078411774
Validation loss: 2.507301462696075

Epoch: 5| Step: 5
Training loss: 1.0562147033030604
Validation loss: 2.5405281258006998

Epoch: 5| Step: 6
Training loss: 1.1768360159439597
Validation loss: 2.543933382695806

Epoch: 5| Step: 7
Training loss: 1.482833704580751
Validation loss: 2.515752954960645

Epoch: 5| Step: 8
Training loss: 1.2075213082528373
Validation loss: 2.520190359247385

Epoch: 5| Step: 9
Training loss: 1.5387255304592689
Validation loss: 2.463761819165668

Epoch: 5| Step: 10
Training loss: 1.2070515455002606
Validation loss: 2.4952946011946975

Epoch: 5| Step: 11
Training loss: 0.8358307886195849
Validation loss: 2.4860049564872755

Epoch: 435| Step: 0
Training loss: 0.9166547420477471
Validation loss: 2.476226250317812

Epoch: 5| Step: 1
Training loss: 0.9225439780175769
Validation loss: 2.4541480326525296

Epoch: 5| Step: 2
Training loss: 1.0907593302811849
Validation loss: 2.410304728035135

Epoch: 5| Step: 3
Training loss: 1.2399813176101306
Validation loss: 2.4619671922918007

Epoch: 5| Step: 4
Training loss: 1.3662625044715522
Validation loss: 2.41434283310893

Epoch: 5| Step: 5
Training loss: 1.5669290711758683
Validation loss: 2.4643853915565685

Epoch: 5| Step: 6
Training loss: 1.175406107827493
Validation loss: 2.4455222099820175

Epoch: 5| Step: 7
Training loss: 1.334230190879838
Validation loss: 2.4574695917850202

Epoch: 5| Step: 8
Training loss: 1.2923538267019266
Validation loss: 2.4673985834482557

Epoch: 5| Step: 9
Training loss: 1.4763174509632664
Validation loss: 2.4876051303079

Epoch: 5| Step: 10
Training loss: 1.1281023165887083
Validation loss: 2.4811010080569256

Epoch: 5| Step: 11
Training loss: 1.1728312342118414
Validation loss: 2.4985286952860792

Epoch: 436| Step: 0
Training loss: 1.373447842607842
Validation loss: 2.4654657553403516

Epoch: 5| Step: 1
Training loss: 1.0773226751820861
Validation loss: 2.4728047595993066

Epoch: 5| Step: 2
Training loss: 1.840918678468512
Validation loss: 2.544973728591433

Epoch: 5| Step: 3
Training loss: 1.6540893280373201
Validation loss: 2.5176956153288517

Epoch: 5| Step: 4
Training loss: 0.8253072989956051
Validation loss: 2.523067474792994

Epoch: 5| Step: 5
Training loss: 1.2847639140102909
Validation loss: 2.528701914523231

Epoch: 5| Step: 6
Training loss: 1.1583740211220053
Validation loss: 2.573763659031698

Epoch: 5| Step: 7
Training loss: 1.1690945000285256
Validation loss: 2.497634062212571

Epoch: 5| Step: 8
Training loss: 1.0605349601511875
Validation loss: 2.4812141239701897

Epoch: 5| Step: 9
Training loss: 1.0894892946779116
Validation loss: 2.4307726433097634

Epoch: 5| Step: 10
Training loss: 1.2090666069696538
Validation loss: 2.4477563007392993

Epoch: 5| Step: 11
Training loss: 0.536521423358282
Validation loss: 2.4795861583850245

Epoch: 437| Step: 0
Training loss: 1.07592604472333
Validation loss: 2.456860856302017

Epoch: 5| Step: 1
Training loss: 1.6719295457159709
Validation loss: 2.4461604913869817

Epoch: 5| Step: 2
Training loss: 1.2357584287065424
Validation loss: 2.4714398719282227

Epoch: 5| Step: 3
Training loss: 1.1284156974264516
Validation loss: 2.449348470607952

Epoch: 5| Step: 4
Training loss: 1.3394049990984065
Validation loss: 2.4580276846129747

Epoch: 5| Step: 5
Training loss: 1.206315504281932
Validation loss: 2.406549360801376

Epoch: 5| Step: 6
Training loss: 1.1783602998139717
Validation loss: 2.4564730015602727

Epoch: 5| Step: 7
Training loss: 1.1495274153232327
Validation loss: 2.5221277347435236

Epoch: 5| Step: 8
Training loss: 1.8135271779167592
Validation loss: 2.477977889746671

Epoch: 5| Step: 9
Training loss: 1.0450755353942438
Validation loss: 2.4549490794334896

Epoch: 5| Step: 10
Training loss: 1.025976801853526
Validation loss: 2.5394818023328307

Epoch: 5| Step: 11
Training loss: 1.343815912803637
Validation loss: 2.4765612444789205

Epoch: 438| Step: 0
Training loss: 1.2100138925905546
Validation loss: 2.5105687183747336

Epoch: 5| Step: 1
Training loss: 0.8708337643879336
Validation loss: 2.460387242071537

Epoch: 5| Step: 2
Training loss: 1.3698708930752428
Validation loss: 2.456014524906281

Epoch: 5| Step: 3
Training loss: 1.442929091473954
Validation loss: 2.522987520470904

Epoch: 5| Step: 4
Training loss: 1.1800353693106391
Validation loss: 2.52131837061516

Epoch: 5| Step: 5
Training loss: 1.1968301351320618
Validation loss: 2.4983887765287336

Epoch: 5| Step: 6
Training loss: 0.9609900049271349
Validation loss: 2.4691486398946716

Epoch: 5| Step: 7
Training loss: 1.3083181062448042
Validation loss: 2.419087239099395

Epoch: 5| Step: 8
Training loss: 1.2137269900465641
Validation loss: 2.522114642203262

Epoch: 5| Step: 9
Training loss: 1.6125257445653345
Validation loss: 2.484634080009606

Epoch: 5| Step: 10
Training loss: 1.289388811829814
Validation loss: 2.517617871720698

Epoch: 5| Step: 11
Training loss: 0.6809972224101868
Validation loss: 2.486914033020206

Epoch: 439| Step: 0
Training loss: 1.264959466458205
Validation loss: 2.5670032938960974

Epoch: 5| Step: 1
Training loss: 0.9842490463814199
Validation loss: 2.521798242112251

Epoch: 5| Step: 2
Training loss: 1.5607031599523042
Validation loss: 2.5418574028415892

Epoch: 5| Step: 3
Training loss: 1.3433775718368315
Validation loss: 2.5424465750817364

Epoch: 5| Step: 4
Training loss: 1.1380487376035666
Validation loss: 2.5349990705874643

Epoch: 5| Step: 5
Training loss: 1.3079550479694821
Validation loss: 2.4715722285634016

Epoch: 5| Step: 6
Training loss: 0.9722550572042852
Validation loss: 2.4973557992430613

Epoch: 5| Step: 7
Training loss: 0.7795889170976971
Validation loss: 2.4748342322056485

Epoch: 5| Step: 8
Training loss: 1.2820142931981988
Validation loss: 2.486568168645501

Epoch: 5| Step: 9
Training loss: 1.1329624471408881
Validation loss: 2.4911509822787195

Epoch: 5| Step: 10
Training loss: 1.4351811987754304
Validation loss: 2.471069288700556

Epoch: 5| Step: 11
Training loss: 1.9578531637025585
Validation loss: 2.4964478768366845

Epoch: 440| Step: 0
Training loss: 1.1612852620498229
Validation loss: 2.526861291163028

Epoch: 5| Step: 1
Training loss: 1.594813646413812
Validation loss: 2.5064331293782263

Epoch: 5| Step: 2
Training loss: 1.361545715018443
Validation loss: 2.521965428133045

Epoch: 5| Step: 3
Training loss: 0.9929250844122921
Validation loss: 2.466509047403941

Epoch: 5| Step: 4
Training loss: 0.9489812043522446
Validation loss: 2.4306089426414146

Epoch: 5| Step: 5
Training loss: 1.3655681065769867
Validation loss: 2.498421353368888

Epoch: 5| Step: 6
Training loss: 0.9657469008946791
Validation loss: 2.4389046713451865

Epoch: 5| Step: 7
Training loss: 1.0939940044162073
Validation loss: 2.4878288428677777

Epoch: 5| Step: 8
Training loss: 1.6288038628689765
Validation loss: 2.50557647479836

Epoch: 5| Step: 9
Training loss: 1.862089979880179
Validation loss: 2.4882104645007304

Epoch: 5| Step: 10
Training loss: 1.1191311448046877
Validation loss: 2.4950575929058054

Epoch: 5| Step: 11
Training loss: 0.779860214032089
Validation loss: 2.5430741451863415

Epoch: 441| Step: 0
Training loss: 1.1646828246681695
Validation loss: 2.536851712740496

Epoch: 5| Step: 1
Training loss: 1.2585192288311564
Validation loss: 2.522975288789459

Epoch: 5| Step: 2
Training loss: 1.242271852328338
Validation loss: 2.5452510516432385

Epoch: 5| Step: 3
Training loss: 1.002053952860351
Validation loss: 2.535805535305657

Epoch: 5| Step: 4
Training loss: 1.370305717912548
Validation loss: 2.5548005579702693

Epoch: 5| Step: 5
Training loss: 1.227587714858498
Validation loss: 2.51745389716202

Epoch: 5| Step: 6
Training loss: 0.9634157184386858
Validation loss: 2.456280660882792

Epoch: 5| Step: 7
Training loss: 1.372778050897656
Validation loss: 2.4793537467338593

Epoch: 5| Step: 8
Training loss: 1.5483928131214626
Validation loss: 2.477867985754973

Epoch: 5| Step: 9
Training loss: 1.1588699454044156
Validation loss: 2.4889281792805864

Epoch: 5| Step: 10
Training loss: 1.062626662838744
Validation loss: 2.53736468159457

Epoch: 5| Step: 11
Training loss: 1.0695362478269026
Validation loss: 2.5231027253139184

Epoch: 442| Step: 0
Training loss: 0.9828698594862358
Validation loss: 2.5008309890581852

Epoch: 5| Step: 1
Training loss: 1.0579575319474297
Validation loss: 2.520399144246767

Epoch: 5| Step: 2
Training loss: 1.0115754604128033
Validation loss: 2.526439872632941

Epoch: 5| Step: 3
Training loss: 1.1289477489196076
Validation loss: 2.5382759832310144

Epoch: 5| Step: 4
Training loss: 0.9521758246762358
Validation loss: 2.4835203108119877

Epoch: 5| Step: 5
Training loss: 1.473711278405098
Validation loss: 2.5083804294583625

Epoch: 5| Step: 6
Training loss: 1.4018671612599065
Validation loss: 2.5072718737721313

Epoch: 5| Step: 7
Training loss: 1.3120048588075452
Validation loss: 2.511958670936244

Epoch: 5| Step: 8
Training loss: 0.8825392173503894
Validation loss: 2.513808228203889

Epoch: 5| Step: 9
Training loss: 1.0427272102611118
Validation loss: 2.5139263768208107

Epoch: 5| Step: 10
Training loss: 1.1946091920262392
Validation loss: 2.5109999534374494

Epoch: 5| Step: 11
Training loss: 1.6155208531943228
Validation loss: 2.5037988370886337

Epoch: 443| Step: 0
Training loss: 1.7728388780083568
Validation loss: 2.484176355893514

Epoch: 5| Step: 1
Training loss: 1.067781839709231
Validation loss: 2.5163809783623496

Epoch: 5| Step: 2
Training loss: 0.8318248367374989
Validation loss: 2.5374266925489124

Epoch: 5| Step: 3
Training loss: 0.9156230418734395
Validation loss: 2.521057532063829

Epoch: 5| Step: 4
Training loss: 1.1521902208371133
Validation loss: 2.5476196191285836

Epoch: 5| Step: 5
Training loss: 1.386768866694511
Validation loss: 2.50395838960427

Epoch: 5| Step: 6
Training loss: 1.0538729878034125
Validation loss: 2.509183045690342

Epoch: 5| Step: 7
Training loss: 1.2350567250989066
Validation loss: 2.4943936666938606

Epoch: 5| Step: 8
Training loss: 1.0190565385266852
Validation loss: 2.4981516363005776

Epoch: 5| Step: 9
Training loss: 1.1950702297051887
Validation loss: 2.4816995085440445

Epoch: 5| Step: 10
Training loss: 0.9612669961366787
Validation loss: 2.4735533546791277

Epoch: 5| Step: 11
Training loss: 1.0615517367720473
Validation loss: 2.4415375839512095

Epoch: 444| Step: 0
Training loss: 1.0237464729592998
Validation loss: 2.489693498900688

Epoch: 5| Step: 1
Training loss: 1.3624325709325322
Validation loss: 2.4937501191893685

Epoch: 5| Step: 2
Training loss: 1.1234015659320682
Validation loss: 2.4876792215355654

Epoch: 5| Step: 3
Training loss: 1.3648775914259568
Validation loss: 2.4848003183329763

Epoch: 5| Step: 4
Training loss: 1.1427693524871976
Validation loss: 2.5599291648259963

Epoch: 5| Step: 5
Training loss: 1.1027528540332834
Validation loss: 2.5164797102935546

Epoch: 5| Step: 6
Training loss: 1.494945912483124
Validation loss: 2.4717659213646286

Epoch: 5| Step: 7
Training loss: 1.3804724338657208
Validation loss: 2.489382589432237

Epoch: 5| Step: 8
Training loss: 1.0840913736957813
Validation loss: 2.484362172347567

Epoch: 5| Step: 9
Training loss: 1.0107881249939799
Validation loss: 2.4633956459971267

Epoch: 5| Step: 10
Training loss: 0.7984975116669467
Validation loss: 2.485190563570616

Epoch: 5| Step: 11
Training loss: 0.7702638266392475
Validation loss: 2.470815993232629

Epoch: 445| Step: 0
Training loss: 1.2967285625097071
Validation loss: 2.4832000253140056

Epoch: 5| Step: 1
Training loss: 0.7897306955628163
Validation loss: 2.486412680187759

Epoch: 5| Step: 2
Training loss: 1.6859157331049672
Validation loss: 2.4912947328222863

Epoch: 5| Step: 3
Training loss: 0.904905011740279
Validation loss: 2.4902518597157313

Epoch: 5| Step: 4
Training loss: 1.0961221311977352
Validation loss: 2.481869747969969

Epoch: 5| Step: 5
Training loss: 1.5381178692121888
Validation loss: 2.523807537870877

Epoch: 5| Step: 6
Training loss: 1.0642905574863941
Validation loss: 2.491606771239351

Epoch: 5| Step: 7
Training loss: 1.1198096813556693
Validation loss: 2.5343864812249874

Epoch: 5| Step: 8
Training loss: 1.2853553872775394
Validation loss: 2.5340823939468446

Epoch: 5| Step: 9
Training loss: 0.9933865128326782
Validation loss: 2.5150974660407477

Epoch: 5| Step: 10
Training loss: 1.312686997670949
Validation loss: 2.5330511913751637

Epoch: 5| Step: 11
Training loss: 1.188971962408104
Validation loss: 2.5407804927187883

Epoch: 446| Step: 0
Training loss: 0.9261583614449506
Validation loss: 2.470950823644589

Epoch: 5| Step: 1
Training loss: 1.270311415180339
Validation loss: 2.5020414441551644

Epoch: 5| Step: 2
Training loss: 1.0831065429594122
Validation loss: 2.5155389861887882

Epoch: 5| Step: 3
Training loss: 1.1256325321062
Validation loss: 2.48667377108061

Epoch: 5| Step: 4
Training loss: 1.1410512258479701
Validation loss: 2.540879906898638

Epoch: 5| Step: 5
Training loss: 1.48110489275359
Validation loss: 2.5369468795506367

Epoch: 5| Step: 6
Training loss: 1.3668232459800143
Validation loss: 2.5077776168663

Epoch: 5| Step: 7
Training loss: 1.4560299621161077
Validation loss: 2.522220105331595

Epoch: 5| Step: 8
Training loss: 1.4339063755686716
Validation loss: 2.5400011880376243

Epoch: 5| Step: 9
Training loss: 1.2107899237506796
Validation loss: 2.493820747449105

Epoch: 5| Step: 10
Training loss: 1.3592787522191452
Validation loss: 2.5324135449066683

Epoch: 5| Step: 11
Training loss: 1.0480448890237835
Validation loss: 2.562973316023209

Epoch: 447| Step: 0
Training loss: 1.494801254330324
Validation loss: 2.66043741735393

Epoch: 5| Step: 1
Training loss: 1.4750374482137099
Validation loss: 2.6310054225923745

Epoch: 5| Step: 2
Training loss: 1.3737517673248503
Validation loss: 2.619251693581825

Epoch: 5| Step: 3
Training loss: 1.5410943730374418
Validation loss: 2.552038189754721

Epoch: 5| Step: 4
Training loss: 1.2967824328374613
Validation loss: 2.515272159196839

Epoch: 5| Step: 5
Training loss: 0.9894896345785925
Validation loss: 2.477912486754743

Epoch: 5| Step: 6
Training loss: 1.6643033995001537
Validation loss: 2.517727103904499

Epoch: 5| Step: 7
Training loss: 1.0039612870028785
Validation loss: 2.521851737172335

Epoch: 5| Step: 8
Training loss: 0.9314088353129323
Validation loss: 2.4989513840498563

Epoch: 5| Step: 9
Training loss: 1.7108897023949226
Validation loss: 2.5157540290234417

Epoch: 5| Step: 10
Training loss: 1.4822730189437432
Validation loss: 2.5011213926747202

Epoch: 5| Step: 11
Training loss: 1.3676670650271168
Validation loss: 2.517654579566249

Epoch: 448| Step: 0
Training loss: 1.1623702069089459
Validation loss: 2.5894740125076776

Epoch: 5| Step: 1
Training loss: 1.5118644703265376
Validation loss: 2.756903194985831

Epoch: 5| Step: 2
Training loss: 1.7845003020590122
Validation loss: 2.7710724000885363

Epoch: 5| Step: 3
Training loss: 1.2985377854823161
Validation loss: 2.7678555152378483

Epoch: 5| Step: 4
Training loss: 1.3253967087142555
Validation loss: 2.717953941755899

Epoch: 5| Step: 5
Training loss: 1.221289800426822
Validation loss: 2.608558641296278

Epoch: 5| Step: 6
Training loss: 1.1712641840740514
Validation loss: 2.581024011936497

Epoch: 5| Step: 7
Training loss: 1.6280534373424385
Validation loss: 2.5523511019514142

Epoch: 5| Step: 8
Training loss: 1.581469777631636
Validation loss: 2.589033752938699

Epoch: 5| Step: 9
Training loss: 1.1289037156654078
Validation loss: 2.576077193187339

Epoch: 5| Step: 10
Training loss: 1.3222319515566647
Validation loss: 2.589263835745647

Epoch: 5| Step: 11
Training loss: 1.074629549026401
Validation loss: 2.6034034386226286

Epoch: 449| Step: 0
Training loss: 1.283496561857938
Validation loss: 2.5457861509388913

Epoch: 5| Step: 1
Training loss: 0.9107871427163777
Validation loss: 2.558051461949836

Epoch: 5| Step: 2
Training loss: 1.736270453028436
Validation loss: 2.556010480197102

Epoch: 5| Step: 3
Training loss: 0.733280990278652
Validation loss: 2.5511065027936835

Epoch: 5| Step: 4
Training loss: 1.618366272561974
Validation loss: 2.519197912122316

Epoch: 5| Step: 5
Training loss: 0.9498018585169223
Validation loss: 2.474509450194157

Epoch: 5| Step: 6
Training loss: 1.2664139725616155
Validation loss: 2.4926437510376296

Epoch: 5| Step: 7
Training loss: 1.149693120562664
Validation loss: 2.479432331538141

Epoch: 5| Step: 8
Training loss: 1.053443853630159
Validation loss: 2.4891730107393784

Epoch: 5| Step: 9
Training loss: 1.5453536904672494
Validation loss: 2.492152390187885

Epoch: 5| Step: 10
Training loss: 1.162216822681766
Validation loss: 2.5027079062870463

Epoch: 5| Step: 11
Training loss: 1.6249372030008695
Validation loss: 2.512651324736525

Epoch: 450| Step: 0
Training loss: 0.8154913781866295
Validation loss: 2.4921760080485127

Epoch: 5| Step: 1
Training loss: 1.3711468721624587
Validation loss: 2.5016641363067165

Epoch: 5| Step: 2
Training loss: 0.8804469189649471
Validation loss: 2.461140417381856

Epoch: 5| Step: 3
Training loss: 1.1557930739436022
Validation loss: 2.4786156648447277

Epoch: 5| Step: 4
Training loss: 1.0429345743244929
Validation loss: 2.4721508343232337

Epoch: 5| Step: 5
Training loss: 1.2294626149082002
Validation loss: 2.442302720339008

Epoch: 5| Step: 6
Training loss: 1.2702793206155183
Validation loss: 2.4804972689533535

Epoch: 5| Step: 7
Training loss: 1.424249448042594
Validation loss: 2.4844021345851965

Epoch: 5| Step: 8
Training loss: 1.0786631250154362
Validation loss: 2.437366286302643

Epoch: 5| Step: 9
Training loss: 1.5840132742431534
Validation loss: 2.470879081320784

Epoch: 5| Step: 10
Training loss: 1.2260601205444426
Validation loss: 2.4522069966828726

Epoch: 5| Step: 11
Training loss: 1.5402167779515636
Validation loss: 2.464080627929471

Epoch: 451| Step: 0
Training loss: 1.9669183960604122
Validation loss: 2.530624673469179

Epoch: 5| Step: 1
Training loss: 1.4973895882738884
Validation loss: 2.50377670960726

Epoch: 5| Step: 2
Training loss: 0.974976311909415
Validation loss: 2.4768206384625806

Epoch: 5| Step: 3
Training loss: 1.2631071028463117
Validation loss: 2.4634125892798813

Epoch: 5| Step: 4
Training loss: 1.241382265909557
Validation loss: 2.4855356604162093

Epoch: 5| Step: 5
Training loss: 1.1140215637475914
Validation loss: 2.4601220227975173

Epoch: 5| Step: 6
Training loss: 1.037161443233031
Validation loss: 2.425930282756974

Epoch: 5| Step: 7
Training loss: 0.8901626323667338
Validation loss: 2.5066311451294396

Epoch: 5| Step: 8
Training loss: 1.1014232682780203
Validation loss: 2.514538658733417

Epoch: 5| Step: 9
Training loss: 1.0161434904169588
Validation loss: 2.5193183868149394

Epoch: 5| Step: 10
Training loss: 0.9010098659364736
Validation loss: 2.50399765823791

Epoch: 5| Step: 11
Training loss: 0.9400070365682975
Validation loss: 2.5215107674846293

Epoch: 452| Step: 0
Training loss: 1.0755980912632461
Validation loss: 2.511909362932527

Epoch: 5| Step: 1
Training loss: 0.9098520056932881
Validation loss: 2.5336058881502015

Epoch: 5| Step: 2
Training loss: 1.1584247036215047
Validation loss: 2.5532814535127644

Epoch: 5| Step: 3
Training loss: 1.092094203473285
Validation loss: 2.4906600707970084

Epoch: 5| Step: 4
Training loss: 1.2682035575437798
Validation loss: 2.54770869084407

Epoch: 5| Step: 5
Training loss: 1.073055789161986
Validation loss: 2.5096727445562346

Epoch: 5| Step: 6
Training loss: 1.2943692646424503
Validation loss: 2.560092896449886

Epoch: 5| Step: 7
Training loss: 0.8805695795038199
Validation loss: 2.52534676002589

Epoch: 5| Step: 8
Training loss: 1.3853517913925733
Validation loss: 2.5360303017619032

Epoch: 5| Step: 9
Training loss: 1.0815522824267432
Validation loss: 2.48768003617339

Epoch: 5| Step: 10
Training loss: 1.0997750138900038
Validation loss: 2.4912311269514507

Epoch: 5| Step: 11
Training loss: 1.0792424588977148
Validation loss: 2.5122848118096632

Epoch: 453| Step: 0
Training loss: 1.2414990802720005
Validation loss: 2.4589026338799105

Epoch: 5| Step: 1
Training loss: 1.0678617165654816
Validation loss: 2.4999199258378346

Epoch: 5| Step: 2
Training loss: 1.0700268329393166
Validation loss: 2.49005261125608

Epoch: 5| Step: 3
Training loss: 1.0792079959354015
Validation loss: 2.4717668698561064

Epoch: 5| Step: 4
Training loss: 0.8379754154723366
Validation loss: 2.44479933890423

Epoch: 5| Step: 5
Training loss: 1.0913140554952812
Validation loss: 2.4878070644968884

Epoch: 5| Step: 6
Training loss: 1.1352801576265918
Validation loss: 2.4735239002193015

Epoch: 5| Step: 7
Training loss: 0.9167417726670284
Validation loss: 2.4635763360797176

Epoch: 5| Step: 8
Training loss: 0.6669967226737173
Validation loss: 2.4553408162288415

Epoch: 5| Step: 9
Training loss: 1.600774952851435
Validation loss: 2.431387659112975

Epoch: 5| Step: 10
Training loss: 1.0070266616989028
Validation loss: 2.5093718579796374

Epoch: 5| Step: 11
Training loss: 1.505967350315831
Validation loss: 2.5028801182702796

Epoch: 454| Step: 0
Training loss: 1.5308851469128342
Validation loss: 2.5097770957833077

Epoch: 5| Step: 1
Training loss: 1.4689411282463924
Validation loss: 2.462096459102025

Epoch: 5| Step: 2
Training loss: 1.1969821214671248
Validation loss: 2.5143387430339263

Epoch: 5| Step: 3
Training loss: 1.0501729345961495
Validation loss: 2.4755688026532456

Epoch: 5| Step: 4
Training loss: 0.8558431703051079
Validation loss: 2.5150936939882254

Epoch: 5| Step: 5
Training loss: 1.0695517404960568
Validation loss: 2.4782642771132846

Epoch: 5| Step: 6
Training loss: 0.9463271693380187
Validation loss: 2.495003547245478

Epoch: 5| Step: 7
Training loss: 0.9271687600428005
Validation loss: 2.540674638752011

Epoch: 5| Step: 8
Training loss: 0.8163480235969496
Validation loss: 2.5102656201604567

Epoch: 5| Step: 9
Training loss: 0.9113109941830486
Validation loss: 2.494077237089695

Epoch: 5| Step: 10
Training loss: 1.0794775950627657
Validation loss: 2.5034897091296395

Epoch: 5| Step: 11
Training loss: 0.8004224392035574
Validation loss: 2.5115761961165406

Epoch: 455| Step: 0
Training loss: 0.8406954682604747
Validation loss: 2.487188293825002

Epoch: 5| Step: 1
Training loss: 1.018592255906216
Validation loss: 2.4589998963350697

Epoch: 5| Step: 2
Training loss: 1.3143895036057713
Validation loss: 2.4728000512676096

Epoch: 5| Step: 3
Training loss: 0.7368851636552898
Validation loss: 2.46621719238313

Epoch: 5| Step: 4
Training loss: 1.3751211546493982
Validation loss: 2.501149620534246

Epoch: 5| Step: 5
Training loss: 0.9663654019628284
Validation loss: 2.48507269173498

Epoch: 5| Step: 6
Training loss: 1.490403791924248
Validation loss: 2.483509108757158

Epoch: 5| Step: 7
Training loss: 0.8203815249512407
Validation loss: 2.5142893868806313

Epoch: 5| Step: 8
Training loss: 1.2352636976997744
Validation loss: 2.517696345285882

Epoch: 5| Step: 9
Training loss: 1.4703488676821197
Validation loss: 2.596059188742823

Epoch: 5| Step: 10
Training loss: 1.081051489628005
Validation loss: 2.5452089769867854

Epoch: 5| Step: 11
Training loss: 1.1942809397151573
Validation loss: 2.5733450148206964

Epoch: 456| Step: 0
Training loss: 1.1664166296096588
Validation loss: 2.517746423778558

Epoch: 5| Step: 1
Training loss: 1.0608813353828372
Validation loss: 2.544261051238565

Epoch: 5| Step: 2
Training loss: 0.9885420624732514
Validation loss: 2.52953990814388

Epoch: 5| Step: 3
Training loss: 1.1412788502785012
Validation loss: 2.5556902069631975

Epoch: 5| Step: 4
Training loss: 0.7406535308106831
Validation loss: 2.5208110309171223

Epoch: 5| Step: 5
Training loss: 1.005315659612612
Validation loss: 2.48018149567404

Epoch: 5| Step: 6
Training loss: 1.0431158983531772
Validation loss: 2.5218555877486746

Epoch: 5| Step: 7
Training loss: 0.9594166824282062
Validation loss: 2.482709706384957

Epoch: 5| Step: 8
Training loss: 1.3667778491331064
Validation loss: 2.4908053712135736

Epoch: 5| Step: 9
Training loss: 1.2524668194607382
Validation loss: 2.4933415713424893

Epoch: 5| Step: 10
Training loss: 0.8987897762786659
Validation loss: 2.5253874623101087

Epoch: 5| Step: 11
Training loss: 1.1912087198572365
Validation loss: 2.527878446781012

Epoch: 457| Step: 0
Training loss: 0.7296230295849705
Validation loss: 2.5612873953215907

Epoch: 5| Step: 1
Training loss: 1.2853611374066425
Validation loss: 2.5708609423914357

Epoch: 5| Step: 2
Training loss: 1.512294452666597
Validation loss: 2.644344494159143

Epoch: 5| Step: 3
Training loss: 1.0374324316979613
Validation loss: 2.5798364449564484

Epoch: 5| Step: 4
Training loss: 1.4182191737963867
Validation loss: 2.594838787117066

Epoch: 5| Step: 5
Training loss: 0.6945768171880834
Validation loss: 2.582024324670412

Epoch: 5| Step: 6
Training loss: 0.850595222361153
Validation loss: 2.548129445629532

Epoch: 5| Step: 7
Training loss: 1.1310918433980501
Validation loss: 2.538402099800844

Epoch: 5| Step: 8
Training loss: 1.0721637837281128
Validation loss: 2.5481321726905386

Epoch: 5| Step: 9
Training loss: 1.258298933851598
Validation loss: 2.560025586668437

Epoch: 5| Step: 10
Training loss: 1.126330277929784
Validation loss: 2.540557229646304

Epoch: 5| Step: 11
Training loss: 0.7030109101028141
Validation loss: 2.5201375621129807

Epoch: 458| Step: 0
Training loss: 1.6578282448095552
Validation loss: 2.5167873216805225

Epoch: 5| Step: 1
Training loss: 0.7514197501470814
Validation loss: 2.5293975613656676

Epoch: 5| Step: 2
Training loss: 0.9565829725794596
Validation loss: 2.5223025002555017

Epoch: 5| Step: 3
Training loss: 0.9610395609922652
Validation loss: 2.500766696190426

Epoch: 5| Step: 4
Training loss: 1.0818339143793707
Validation loss: 2.504015213474547

Epoch: 5| Step: 5
Training loss: 1.3800911715700899
Validation loss: 2.4716826375709835

Epoch: 5| Step: 6
Training loss: 0.9512255769017992
Validation loss: 2.4928678263613455

Epoch: 5| Step: 7
Training loss: 0.8621544712511087
Validation loss: 2.4818753236840707

Epoch: 5| Step: 8
Training loss: 1.058662609380431
Validation loss: 2.51306902718986

Epoch: 5| Step: 9
Training loss: 0.8602141704686178
Validation loss: 2.4793970831748307

Epoch: 5| Step: 10
Training loss: 1.2044135290534477
Validation loss: 2.444683627837834

Epoch: 5| Step: 11
Training loss: 1.2030015361899749
Validation loss: 2.5122427465472246

Epoch: 459| Step: 0
Training loss: 1.1232183441619017
Validation loss: 2.5147671628905433

Epoch: 5| Step: 1
Training loss: 1.2596185642724216
Validation loss: 2.5323106992302633

Epoch: 5| Step: 2
Training loss: 0.9072488016250445
Validation loss: 2.4966250766002966

Epoch: 5| Step: 3
Training loss: 0.8148952537345036
Validation loss: 2.511355787662746

Epoch: 5| Step: 4
Training loss: 0.9741529722423231
Validation loss: 2.4776836629231824

Epoch: 5| Step: 5
Training loss: 1.0311439922062116
Validation loss: 2.5378778207683057

Epoch: 5| Step: 6
Training loss: 1.1948081554460166
Validation loss: 2.537484853602212

Epoch: 5| Step: 7
Training loss: 1.1315396227943109
Validation loss: 2.5766554295005717

Epoch: 5| Step: 8
Training loss: 1.203794317964655
Validation loss: 2.544632445101362

Epoch: 5| Step: 9
Training loss: 1.0883184444427478
Validation loss: 2.5380146935916637

Epoch: 5| Step: 10
Training loss: 0.9878432317175303
Validation loss: 2.502953652157899

Epoch: 5| Step: 11
Training loss: 1.3396873271595884
Validation loss: 2.510408189107634

Epoch: 460| Step: 0
Training loss: 1.0502323007197782
Validation loss: 2.5185328513820098

Epoch: 5| Step: 1
Training loss: 0.7563304763724294
Validation loss: 2.5432128046902487

Epoch: 5| Step: 2
Training loss: 1.0076842707001554
Validation loss: 2.5147269563236967

Epoch: 5| Step: 3
Training loss: 0.8793787724482475
Validation loss: 2.525572119000868

Epoch: 5| Step: 4
Training loss: 1.3467451913682977
Validation loss: 2.52543752596742

Epoch: 5| Step: 5
Training loss: 1.055407638531271
Validation loss: 2.492446212334861

Epoch: 5| Step: 6
Training loss: 1.1153389636165731
Validation loss: 2.4602378940693383

Epoch: 5| Step: 7
Training loss: 1.6120045484805243
Validation loss: 2.5106466525664097

Epoch: 5| Step: 8
Training loss: 0.6272690116856464
Validation loss: 2.5048398852620424

Epoch: 5| Step: 9
Training loss: 1.1366487461832755
Validation loss: 2.463456030735659

Epoch: 5| Step: 10
Training loss: 0.944133874997689
Validation loss: 2.4695632617118255

Epoch: 5| Step: 11
Training loss: 0.3302530694114302
Validation loss: 2.5011472930486636

Epoch: 461| Step: 0
Training loss: 0.9116930450503047
Validation loss: 2.5095336411030114

Epoch: 5| Step: 1
Training loss: 1.5100560865028012
Validation loss: 2.5034262067563646

Epoch: 5| Step: 2
Training loss: 0.8639993572100262
Validation loss: 2.5664443502399523

Epoch: 5| Step: 3
Training loss: 0.6987162014766205
Validation loss: 2.54887744763276

Epoch: 5| Step: 4
Training loss: 0.9682803092091403
Validation loss: 2.544310708385866

Epoch: 5| Step: 5
Training loss: 0.868408683581537
Validation loss: 2.592368964706702

Epoch: 5| Step: 6
Training loss: 0.7823925818427073
Validation loss: 2.5535258764020634

Epoch: 5| Step: 7
Training loss: 1.5568397231912008
Validation loss: 2.544312793355753

Epoch: 5| Step: 8
Training loss: 1.0748673024448134
Validation loss: 2.529189234422888

Epoch: 5| Step: 9
Training loss: 1.0904113494681211
Validation loss: 2.5016017193552287

Epoch: 5| Step: 10
Training loss: 1.3320960423437314
Validation loss: 2.530688839784961

Epoch: 5| Step: 11
Training loss: 0.9435530753922395
Validation loss: 2.5200117850595745

Epoch: 462| Step: 0
Training loss: 1.0315691714112967
Validation loss: 2.493997831147879

Epoch: 5| Step: 1
Training loss: 1.1067457069087945
Validation loss: 2.498490279043597

Epoch: 5| Step: 2
Training loss: 0.8670177809136034
Validation loss: 2.522295773275621

Epoch: 5| Step: 3
Training loss: 1.3745864332907463
Validation loss: 2.551573742703339

Epoch: 5| Step: 4
Training loss: 1.4111346287699167
Validation loss: 2.4964800572038404

Epoch: 5| Step: 5
Training loss: 0.8379018289310478
Validation loss: 2.4982110179095622

Epoch: 5| Step: 6
Training loss: 0.9045054646248378
Validation loss: 2.5166084823345494

Epoch: 5| Step: 7
Training loss: 0.7824958785317201
Validation loss: 2.5522979581204877

Epoch: 5| Step: 8
Training loss: 1.1747666857781163
Validation loss: 2.4813377840478608

Epoch: 5| Step: 9
Training loss: 0.8888952288964457
Validation loss: 2.4984747445911153

Epoch: 5| Step: 10
Training loss: 0.9582922277065913
Validation loss: 2.5680310018862635

Epoch: 5| Step: 11
Training loss: 0.7171667740097988
Validation loss: 2.5539698219730687

Epoch: 463| Step: 0
Training loss: 0.9685291223061687
Validation loss: 2.547144257367917

Epoch: 5| Step: 1
Training loss: 1.3223826865100752
Validation loss: 2.531657092007464

Epoch: 5| Step: 2
Training loss: 1.2335534560886774
Validation loss: 2.527248339495584

Epoch: 5| Step: 3
Training loss: 0.8868365104554816
Validation loss: 2.540644484441725

Epoch: 5| Step: 4
Training loss: 0.9077596914981685
Validation loss: 2.5437874909183624

Epoch: 5| Step: 5
Training loss: 0.9636944555166045
Validation loss: 2.4758584238103722

Epoch: 5| Step: 6
Training loss: 1.0996717093164097
Validation loss: 2.536535380692648

Epoch: 5| Step: 7
Training loss: 0.7132859897351593
Validation loss: 2.507828190517757

Epoch: 5| Step: 8
Training loss: 0.9922647821560822
Validation loss: 2.5169088531060217

Epoch: 5| Step: 9
Training loss: 1.4231023835741832
Validation loss: 2.4628342075727985

Epoch: 5| Step: 10
Training loss: 0.951471301188732
Validation loss: 2.5404985523859165

Epoch: 5| Step: 11
Training loss: 0.6754932561660583
Validation loss: 2.550992722286449

Epoch: 464| Step: 0
Training loss: 1.07113343102027
Validation loss: 2.5000882649734852

Epoch: 5| Step: 1
Training loss: 0.8379357599226271
Validation loss: 2.490213327755214

Epoch: 5| Step: 2
Training loss: 1.4979922845435494
Validation loss: 2.538486916274222

Epoch: 5| Step: 3
Training loss: 0.8717816634448785
Validation loss: 2.4982759054067425

Epoch: 5| Step: 4
Training loss: 0.8808590028343345
Validation loss: 2.5301275197725457

Epoch: 5| Step: 5
Training loss: 1.0043966676265563
Validation loss: 2.5779878252315083

Epoch: 5| Step: 6
Training loss: 0.6882037548902844
Validation loss: 2.5476411377022736

Epoch: 5| Step: 7
Training loss: 0.9800997035728732
Validation loss: 2.480693380442236

Epoch: 5| Step: 8
Training loss: 1.3361988369716682
Validation loss: 2.4713716067525167

Epoch: 5| Step: 9
Training loss: 0.9874477263992577
Validation loss: 2.4914984472980493

Epoch: 5| Step: 10
Training loss: 0.9277572468397758
Validation loss: 2.487996712409926

Epoch: 5| Step: 11
Training loss: 1.2219109259199576
Validation loss: 2.458426002329116

Epoch: 465| Step: 0
Training loss: 1.4276983045204155
Validation loss: 2.456109604370063

Epoch: 5| Step: 1
Training loss: 0.9956388743859275
Validation loss: 2.505473439444473

Epoch: 5| Step: 2
Training loss: 0.7957062846192676
Validation loss: 2.51791681813512

Epoch: 5| Step: 3
Training loss: 0.8434985457239916
Validation loss: 2.4674556373066086

Epoch: 5| Step: 4
Training loss: 0.9399590349402056
Validation loss: 2.4927811986717763

Epoch: 5| Step: 5
Training loss: 1.0142754024138776
Validation loss: 2.5374918300202736

Epoch: 5| Step: 6
Training loss: 1.4034185089817433
Validation loss: 2.473041144893477

Epoch: 5| Step: 7
Training loss: 0.9642822546871633
Validation loss: 2.503138662071583

Epoch: 5| Step: 8
Training loss: 1.06127690994419
Validation loss: 2.529446577553865

Epoch: 5| Step: 9
Training loss: 1.0095647910999022
Validation loss: 2.5309224368104535

Epoch: 5| Step: 10
Training loss: 0.7870676488678392
Validation loss: 2.4903327752911255

Epoch: 5| Step: 11
Training loss: 1.3764990957598724
Validation loss: 2.5194960362538907

Epoch: 466| Step: 0
Training loss: 0.7402781772990179
Validation loss: 2.4854232487960424

Epoch: 5| Step: 1
Training loss: 0.928475752292549
Validation loss: 2.5533950367146048

Epoch: 5| Step: 2
Training loss: 0.9757962692241026
Validation loss: 2.552869217727773

Epoch: 5| Step: 3
Training loss: 1.433826729035871
Validation loss: 2.506372896195319

Epoch: 5| Step: 4
Training loss: 0.8294016516283386
Validation loss: 2.5469599711591746

Epoch: 5| Step: 5
Training loss: 1.2592087572048951
Validation loss: 2.5049575566473385

Epoch: 5| Step: 6
Training loss: 0.9630684833418727
Validation loss: 2.551804238583335

Epoch: 5| Step: 7
Training loss: 0.6426907240703185
Validation loss: 2.5486214974203585

Epoch: 5| Step: 8
Training loss: 0.8501432999261012
Validation loss: 2.517559669965602

Epoch: 5| Step: 9
Training loss: 1.233325657090364
Validation loss: 2.495648729972773

Epoch: 5| Step: 10
Training loss: 1.0883808230096121
Validation loss: 2.4925385629495134

Epoch: 5| Step: 11
Training loss: 1.3100406675359908
Validation loss: 2.5189589764756666

Epoch: 467| Step: 0
Training loss: 1.1407248048359613
Validation loss: 2.492656759251153

Epoch: 5| Step: 1
Training loss: 1.5931444700719242
Validation loss: 2.493116275475315

Epoch: 5| Step: 2
Training loss: 0.8667671972130586
Validation loss: 2.503928689761887

Epoch: 5| Step: 3
Training loss: 0.9729482067041246
Validation loss: 2.5067510210294297

Epoch: 5| Step: 4
Training loss: 1.2772611538841843
Validation loss: 2.4900821574444

Epoch: 5| Step: 5
Training loss: 0.9292659605255043
Validation loss: 2.520818222935895

Epoch: 5| Step: 6
Training loss: 0.8792775704880043
Validation loss: 2.5036599627776535

Epoch: 5| Step: 7
Training loss: 0.8415872972350166
Validation loss: 2.4471469656553455

Epoch: 5| Step: 8
Training loss: 0.8667913339583025
Validation loss: 2.4831627941351884

Epoch: 5| Step: 9
Training loss: 0.7942260771268388
Validation loss: 2.48868146359723

Epoch: 5| Step: 10
Training loss: 0.9081704738859407
Validation loss: 2.531979914788949

Epoch: 5| Step: 11
Training loss: 0.9043150337653559
Validation loss: 2.507794872313091

Epoch: 468| Step: 0
Training loss: 0.9342370789460962
Validation loss: 2.5385430807287896

Epoch: 5| Step: 1
Training loss: 1.0551308724283235
Validation loss: 2.5294525452064796

Epoch: 5| Step: 2
Training loss: 0.7930128714778397
Validation loss: 2.507829386811726

Epoch: 5| Step: 3
Training loss: 0.839132886381579
Validation loss: 2.5468961679713993

Epoch: 5| Step: 4
Training loss: 0.7993149148581077
Validation loss: 2.530897861680103

Epoch: 5| Step: 5
Training loss: 0.9249485955260106
Validation loss: 2.509773446354139

Epoch: 5| Step: 6
Training loss: 0.8667367330679543
Validation loss: 2.519202050676563

Epoch: 5| Step: 7
Training loss: 1.0828724700042152
Validation loss: 2.4693020714376575

Epoch: 5| Step: 8
Training loss: 1.4491629782584605
Validation loss: 2.50802800331042

Epoch: 5| Step: 9
Training loss: 0.8433601043683883
Validation loss: 2.52345945114493

Epoch: 5| Step: 10
Training loss: 1.4943553097144444
Validation loss: 2.5398822419711196

Epoch: 5| Step: 11
Training loss: 0.44375271930667304
Validation loss: 2.565257569710607

Epoch: 469| Step: 0
Training loss: 1.0033990788596026
Validation loss: 2.5837348938653997

Epoch: 5| Step: 1
Training loss: 1.0542339904054432
Validation loss: 2.604692321495227

Epoch: 5| Step: 2
Training loss: 0.7900616202888573
Validation loss: 2.544793829108272

Epoch: 5| Step: 3
Training loss: 0.9768099356941112
Validation loss: 2.5756167376912664

Epoch: 5| Step: 4
Training loss: 0.7874551396989349
Validation loss: 2.5356546116880816

Epoch: 5| Step: 5
Training loss: 0.9643514512376758
Validation loss: 2.5059320444743074

Epoch: 5| Step: 6
Training loss: 0.9322922065491773
Validation loss: 2.5743394938174635

Epoch: 5| Step: 7
Training loss: 1.3477198046749728
Validation loss: 2.4696598126919205

Epoch: 5| Step: 8
Training loss: 0.8866557632459473
Validation loss: 2.5585249525143983

Epoch: 5| Step: 9
Training loss: 0.9299333071124146
Validation loss: 2.5226776585242

Epoch: 5| Step: 10
Training loss: 1.2425607084644459
Validation loss: 2.5445688841639442

Epoch: 5| Step: 11
Training loss: 1.7092695772066169
Validation loss: 2.540521638682862

Epoch: 470| Step: 0
Training loss: 1.3970088374050178
Validation loss: 2.5374291237828066

Epoch: 5| Step: 1
Training loss: 1.1444667758943894
Validation loss: 2.5826642774885302

Epoch: 5| Step: 2
Training loss: 1.2606865880216913
Validation loss: 2.541117012020503

Epoch: 5| Step: 3
Training loss: 1.0214566578943054
Validation loss: 2.550357945102776

Epoch: 5| Step: 4
Training loss: 0.9643308071411498
Validation loss: 2.575528627286766

Epoch: 5| Step: 5
Training loss: 1.1448330009479588
Validation loss: 2.5131704941427877

Epoch: 5| Step: 6
Training loss: 1.0850758049672518
Validation loss: 2.5357850386786183

Epoch: 5| Step: 7
Training loss: 0.9475709403463313
Validation loss: 2.448551381117651

Epoch: 5| Step: 8
Training loss: 0.9943874330061051
Validation loss: 2.5175242333159726

Epoch: 5| Step: 9
Training loss: 1.0388834519394186
Validation loss: 2.507180174813269

Epoch: 5| Step: 10
Training loss: 0.6693620483541668
Validation loss: 2.512662056857155

Epoch: 5| Step: 11
Training loss: 0.8580786203629945
Validation loss: 2.5714367781708716

Epoch: 471| Step: 0
Training loss: 1.0403863031684706
Validation loss: 2.5658999581858786

Epoch: 5| Step: 1
Training loss: 0.6595117707348084
Validation loss: 2.5950783120358047

Epoch: 5| Step: 2
Training loss: 1.0475873089550714
Validation loss: 2.655620421802707

Epoch: 5| Step: 3
Training loss: 1.0868808299122705
Validation loss: 2.649164364525666

Epoch: 5| Step: 4
Training loss: 1.5470823669156604
Validation loss: 2.6221761122136416

Epoch: 5| Step: 5
Training loss: 1.3431581923908598
Validation loss: 2.57266674423819

Epoch: 5| Step: 6
Training loss: 0.9591916359491426
Validation loss: 2.6091478595362445

Epoch: 5| Step: 7
Training loss: 1.122134054977973
Validation loss: 2.5214085093499907

Epoch: 5| Step: 8
Training loss: 0.9127260529075797
Validation loss: 2.5084750368851725

Epoch: 5| Step: 9
Training loss: 1.1244150336339063
Validation loss: 2.54260877375011

Epoch: 5| Step: 10
Training loss: 1.1010826093603527
Validation loss: 2.4877109243274402

Epoch: 5| Step: 11
Training loss: 1.0625178952673535
Validation loss: 2.5200873813415203

Epoch: 472| Step: 0
Training loss: 0.862976158396237
Validation loss: 2.5586723723234472

Epoch: 5| Step: 1
Training loss: 0.9903453636795461
Validation loss: 2.5046219182367464

Epoch: 5| Step: 2
Training loss: 1.3692754877687758
Validation loss: 2.5423078229893523

Epoch: 5| Step: 3
Training loss: 1.3219744363093533
Validation loss: 2.5663592500219923

Epoch: 5| Step: 4
Training loss: 0.8306278697151572
Validation loss: 2.600518037007715

Epoch: 5| Step: 5
Training loss: 0.7297597289840088
Validation loss: 2.5621115304765585

Epoch: 5| Step: 6
Training loss: 1.0317299621795466
Validation loss: 2.610826659575049

Epoch: 5| Step: 7
Training loss: 0.7551724567880319
Validation loss: 2.598485258897998

Epoch: 5| Step: 8
Training loss: 1.1162285590595595
Validation loss: 2.6137007189920625

Epoch: 5| Step: 9
Training loss: 0.8908186919421958
Validation loss: 2.574907263842015

Epoch: 5| Step: 10
Training loss: 0.9342546238752907
Validation loss: 2.5582815508825885

Epoch: 5| Step: 11
Training loss: 1.450658612467926
Validation loss: 2.580000516930856

Epoch: 473| Step: 0
Training loss: 0.8031035453810279
Validation loss: 2.573888534645182

Epoch: 5| Step: 1
Training loss: 0.6730294843608834
Validation loss: 2.536954178540545

Epoch: 5| Step: 2
Training loss: 0.6735358668662769
Validation loss: 2.510934192027817

Epoch: 5| Step: 3
Training loss: 1.3227005979850825
Validation loss: 2.5591316958312986

Epoch: 5| Step: 4
Training loss: 0.7441161945167418
Validation loss: 2.5421347239244056

Epoch: 5| Step: 5
Training loss: 0.9162526098633113
Validation loss: 2.5508925124979034

Epoch: 5| Step: 6
Training loss: 0.7430392146665734
Validation loss: 2.553471325342277

Epoch: 5| Step: 7
Training loss: 1.1632671327163444
Validation loss: 2.548032347490402

Epoch: 5| Step: 8
Training loss: 1.5146961315327
Validation loss: 2.5335220532227574

Epoch: 5| Step: 9
Training loss: 0.8761874044048078
Validation loss: 2.5537791372495775

Epoch: 5| Step: 10
Training loss: 0.9192888548095848
Validation loss: 2.5765237517303112

Epoch: 5| Step: 11
Training loss: 1.5373928870129736
Validation loss: 2.579549879257574

Epoch: 474| Step: 0
Training loss: 1.2862355995669625
Validation loss: 2.507220666833919

Epoch: 5| Step: 1
Training loss: 1.3058985953869908
Validation loss: 2.5822314301656903

Epoch: 5| Step: 2
Training loss: 1.2899635171536687
Validation loss: 2.5694081726320657

Epoch: 5| Step: 3
Training loss: 1.4850971272362758
Validation loss: 2.583942231334155

Epoch: 5| Step: 4
Training loss: 1.4002134245590887
Validation loss: 2.5680106657572717

Epoch: 5| Step: 5
Training loss: 1.1673527755051398
Validation loss: 2.5783682274959028

Epoch: 5| Step: 6
Training loss: 1.0974610721922746
Validation loss: 2.501262767084936

Epoch: 5| Step: 7
Training loss: 1.188275284912065
Validation loss: 2.493827877884183

Epoch: 5| Step: 8
Training loss: 0.8378911229556723
Validation loss: 2.4874402416022474

Epoch: 5| Step: 9
Training loss: 1.1063174167931322
Validation loss: 2.4580946593615067

Epoch: 5| Step: 10
Training loss: 0.9461982927594439
Validation loss: 2.4545383816012674

Epoch: 5| Step: 11
Training loss: 1.616156871617402
Validation loss: 2.4398943194383684

Epoch: 475| Step: 0
Training loss: 0.8848846557581823
Validation loss: 2.3855936298501503

Epoch: 5| Step: 1
Training loss: 1.545935605651176
Validation loss: 2.50381720707433

Epoch: 5| Step: 2
Training loss: 1.3976761007844996
Validation loss: 2.5411722094420606

Epoch: 5| Step: 3
Training loss: 1.5854529782254472
Validation loss: 2.557795202452705

Epoch: 5| Step: 4
Training loss: 1.0208463992366092
Validation loss: 2.5436496399273056

Epoch: 5| Step: 5
Training loss: 1.2964235002432778
Validation loss: 2.520858308705172

Epoch: 5| Step: 6
Training loss: 1.5845281794008297
Validation loss: 2.53566426896875

Epoch: 5| Step: 7
Training loss: 0.9322760312493708
Validation loss: 2.5163379551359153

Epoch: 5| Step: 8
Training loss: 1.1127292268314304
Validation loss: 2.5892417748955854

Epoch: 5| Step: 9
Training loss: 1.081106624027658
Validation loss: 2.5874950332102507

Epoch: 5| Step: 10
Training loss: 1.0517353136920113
Validation loss: 2.6404353116917054

Epoch: 5| Step: 11
Training loss: 2.215313035876381
Validation loss: 2.6008386492733426

Epoch: 476| Step: 0
Training loss: 1.228239771403794
Validation loss: 2.628064894319638

Epoch: 5| Step: 1
Training loss: 0.9358921887060071
Validation loss: 2.565439538606419

Epoch: 5| Step: 2
Training loss: 1.051329232313309
Validation loss: 2.5754107781872477

Epoch: 5| Step: 3
Training loss: 0.9271129574846714
Validation loss: 2.5299183694419995

Epoch: 5| Step: 4
Training loss: 1.1661854784781527
Validation loss: 2.56955970399682

Epoch: 5| Step: 5
Training loss: 0.8518811250999606
Validation loss: 2.5502597924268757

Epoch: 5| Step: 6
Training loss: 0.7964920544967378
Validation loss: 2.5288259649628424

Epoch: 5| Step: 7
Training loss: 0.9581272622397156
Validation loss: 2.5600903509259543

Epoch: 5| Step: 8
Training loss: 1.5786565508636503
Validation loss: 2.4949354131667856

Epoch: 5| Step: 9
Training loss: 1.2753598266434758
Validation loss: 2.515175623275943

Epoch: 5| Step: 10
Training loss: 1.3316339700207487
Validation loss: 2.541387184338138

Epoch: 5| Step: 11
Training loss: 0.7589719102810744
Validation loss: 2.5377133428527663

Epoch: 477| Step: 0
Training loss: 1.1398282861216231
Validation loss: 2.508395165941255

Epoch: 5| Step: 1
Training loss: 0.9140926910370261
Validation loss: 2.516971543668151

Epoch: 5| Step: 2
Training loss: 1.024251774096192
Validation loss: 2.506407271735892

Epoch: 5| Step: 3
Training loss: 1.0113997969236617
Validation loss: 2.5597397506696944

Epoch: 5| Step: 4
Training loss: 1.1269045708574696
Validation loss: 2.535766520272395

Epoch: 5| Step: 5
Training loss: 1.1835688220127865
Validation loss: 2.524878146753315

Epoch: 5| Step: 6
Training loss: 0.9116934700070408
Validation loss: 2.5406309242695597

Epoch: 5| Step: 7
Training loss: 0.7230903764907588
Validation loss: 2.50760107842649

Epoch: 5| Step: 8
Training loss: 0.9931238216923709
Validation loss: 2.5518331262331255

Epoch: 5| Step: 9
Training loss: 1.1388545993874009
Validation loss: 2.514803193401202

Epoch: 5| Step: 10
Training loss: 1.334370815440279
Validation loss: 2.5104947229704853

Epoch: 5| Step: 11
Training loss: 0.2771653286475708
Validation loss: 2.520381927795278

Epoch: 478| Step: 0
Training loss: 1.0997475356039474
Validation loss: 2.531906423500065

Epoch: 5| Step: 1
Training loss: 1.252341842411942
Validation loss: 2.479458027769997

Epoch: 5| Step: 2
Training loss: 1.0134901644620453
Validation loss: 2.512487460970232

Epoch: 5| Step: 3
Training loss: 0.8929288413006525
Validation loss: 2.523467454447078

Epoch: 5| Step: 4
Training loss: 0.7263709195136799
Validation loss: 2.526435893387372

Epoch: 5| Step: 5
Training loss: 0.7798619719180026
Validation loss: 2.5070889499705578

Epoch: 5| Step: 6
Training loss: 0.8551484296466564
Validation loss: 2.507835625752809

Epoch: 5| Step: 7
Training loss: 0.987571914082369
Validation loss: 2.5001056430271316

Epoch: 5| Step: 8
Training loss: 1.1961778487845574
Validation loss: 2.4751205779415435

Epoch: 5| Step: 9
Training loss: 0.808331580668119
Validation loss: 2.5000289955047137

Epoch: 5| Step: 10
Training loss: 1.088242588602493
Validation loss: 2.475879827807743

Epoch: 5| Step: 11
Training loss: 0.5706735278215495
Validation loss: 2.5149311309230473

Epoch: 479| Step: 0
Training loss: 0.9860016839707485
Validation loss: 2.527283280134155

Epoch: 5| Step: 1
Training loss: 1.7245287071707676
Validation loss: 2.526263228593683

Epoch: 5| Step: 2
Training loss: 0.9045786737796137
Validation loss: 2.538626182431782

Epoch: 5| Step: 3
Training loss: 0.8846813776524616
Validation loss: 2.519307775714882

Epoch: 5| Step: 4
Training loss: 1.1691445138690073
Validation loss: 2.5549579403333644

Epoch: 5| Step: 5
Training loss: 0.975149368190947
Validation loss: 2.5854449038278933

Epoch: 5| Step: 6
Training loss: 0.9394855136800042
Validation loss: 2.5510139183964213

Epoch: 5| Step: 7
Training loss: 0.7821354616528446
Validation loss: 2.6311298298370143

Epoch: 5| Step: 8
Training loss: 1.128498148824097
Validation loss: 2.5867577257506453

Epoch: 5| Step: 9
Training loss: 0.8234803204920944
Validation loss: 2.5592712514837825

Epoch: 5| Step: 10
Training loss: 0.7270699236561401
Validation loss: 2.540130498213964

Epoch: 5| Step: 11
Training loss: 0.5319422531193462
Validation loss: 2.548983444216971

Epoch: 480| Step: 0
Training loss: 1.1268887030370802
Validation loss: 2.5619623038759416

Epoch: 5| Step: 1
Training loss: 1.054054239683472
Validation loss: 2.523393006616521

Epoch: 5| Step: 2
Training loss: 0.8117821162936881
Validation loss: 2.5470861179713706

Epoch: 5| Step: 3
Training loss: 0.731876994585533
Validation loss: 2.522799829591161

Epoch: 5| Step: 4
Training loss: 1.546791382658526
Validation loss: 2.533259567380963

Epoch: 5| Step: 5
Training loss: 0.9728764970207435
Validation loss: 2.5618127525450016

Epoch: 5| Step: 6
Training loss: 0.77321274699653
Validation loss: 2.5359439811380846

Epoch: 5| Step: 7
Training loss: 0.7786171991873354
Validation loss: 2.5804070785934017

Epoch: 5| Step: 8
Training loss: 1.112245687070387
Validation loss: 2.594077407517738

Epoch: 5| Step: 9
Training loss: 0.794687484939221
Validation loss: 2.551941378531522

Epoch: 5| Step: 10
Training loss: 0.9864646288393268
Validation loss: 2.623983072666778

Epoch: 5| Step: 11
Training loss: 1.5654574062775202
Validation loss: 2.610501059720396

Epoch: 481| Step: 0
Training loss: 0.8101231582048549
Validation loss: 2.4971931794290185

Epoch: 5| Step: 1
Training loss: 1.379701941340071
Validation loss: 2.5850617999517542

Epoch: 5| Step: 2
Training loss: 0.9971955432764712
Validation loss: 2.5366761089939556

Epoch: 5| Step: 3
Training loss: 1.053703583841057
Validation loss: 2.557228768708851

Epoch: 5| Step: 4
Training loss: 0.9279982021043067
Validation loss: 2.5717915856332985

Epoch: 5| Step: 5
Training loss: 0.839311652956683
Validation loss: 2.5371178442598548

Epoch: 5| Step: 6
Training loss: 1.2387330587789547
Validation loss: 2.5105189319743366

Epoch: 5| Step: 7
Training loss: 0.8177474107739221
Validation loss: 2.5212056828142018

Epoch: 5| Step: 8
Training loss: 0.6858626287869597
Validation loss: 2.5154486252774104

Epoch: 5| Step: 9
Training loss: 0.6833268870848249
Validation loss: 2.5052777767800567

Epoch: 5| Step: 10
Training loss: 0.9953644719470679
Validation loss: 2.5261816058117206

Epoch: 5| Step: 11
Training loss: 0.5123774824005544
Validation loss: 2.544037160356345

Epoch: 482| Step: 0
Training loss: 0.7849066797902213
Validation loss: 2.5255613139039284

Epoch: 5| Step: 1
Training loss: 1.3184936455062484
Validation loss: 2.578701998944508

Epoch: 5| Step: 2
Training loss: 0.831055368855754
Validation loss: 2.568598019883162

Epoch: 5| Step: 3
Training loss: 0.8725539486446028
Validation loss: 2.588475248890592

Epoch: 5| Step: 4
Training loss: 0.8159251278392534
Validation loss: 2.6218971578868877

Epoch: 5| Step: 5
Training loss: 0.6498296569484762
Validation loss: 2.5544237978718334

Epoch: 5| Step: 6
Training loss: 0.8252143090222833
Validation loss: 2.605528888456349

Epoch: 5| Step: 7
Training loss: 0.8879724789577563
Validation loss: 2.5943294054174246

Epoch: 5| Step: 8
Training loss: 1.2513585337575857
Validation loss: 2.5742475269737097

Epoch: 5| Step: 9
Training loss: 0.8613017244682911
Validation loss: 2.511846636991453

Epoch: 5| Step: 10
Training loss: 1.1665672645910958
Validation loss: 2.5530131469218214

Epoch: 5| Step: 11
Training loss: 0.4501537874810533
Validation loss: 2.5119275668262

Epoch: 483| Step: 0
Training loss: 1.1103403968216075
Validation loss: 2.5483064236934343

Epoch: 5| Step: 1
Training loss: 1.3302339751008365
Validation loss: 2.545710078818167

Epoch: 5| Step: 2
Training loss: 0.6493214247175852
Validation loss: 2.5350294390028036

Epoch: 5| Step: 3
Training loss: 0.7379540419702996
Validation loss: 2.5456673854199825

Epoch: 5| Step: 4
Training loss: 1.2580978828005451
Validation loss: 2.6231482688108683

Epoch: 5| Step: 5
Training loss: 1.0475424731072063
Validation loss: 2.5965729177770007

Epoch: 5| Step: 6
Training loss: 0.8620768988178508
Validation loss: 2.565844559035276

Epoch: 5| Step: 7
Training loss: 0.694195997512256
Validation loss: 2.5846476569794716

Epoch: 5| Step: 8
Training loss: 0.9361493872248253
Validation loss: 2.5792213189698154

Epoch: 5| Step: 9
Training loss: 0.9885926491092287
Validation loss: 2.514443694733031

Epoch: 5| Step: 10
Training loss: 1.185397998191285
Validation loss: 2.5609947606268606

Epoch: 5| Step: 11
Training loss: 0.8540272172436711
Validation loss: 2.5673337950826998

Epoch: 484| Step: 0
Training loss: 0.7410287746294313
Validation loss: 2.5596023978665388

Epoch: 5| Step: 1
Training loss: 1.1369732444050924
Validation loss: 2.5465353678847458

Epoch: 5| Step: 2
Training loss: 1.2720511443364524
Validation loss: 2.518454912725596

Epoch: 5| Step: 3
Training loss: 0.9803194335069696
Validation loss: 2.560815559914761

Epoch: 5| Step: 4
Training loss: 0.8593500307096996
Validation loss: 2.5039228140233027

Epoch: 5| Step: 5
Training loss: 1.305837661055985
Validation loss: 2.571732917992448

Epoch: 5| Step: 6
Training loss: 0.7878184567763072
Validation loss: 2.5206511184684857

Epoch: 5| Step: 7
Training loss: 0.8449758172948202
Validation loss: 2.5669258207199572

Epoch: 5| Step: 8
Training loss: 1.114464649524595
Validation loss: 2.6108648687670692

Epoch: 5| Step: 9
Training loss: 0.9862737961715852
Validation loss: 2.5518923681525947

Epoch: 5| Step: 10
Training loss: 0.716539508236113
Validation loss: 2.489701808254541

Epoch: 5| Step: 11
Training loss: 0.3257894729930379
Validation loss: 2.5362599639295773

Epoch: 485| Step: 0
Training loss: 1.1620855248832804
Validation loss: 2.5401213643723333

Epoch: 5| Step: 1
Training loss: 1.2826910986007607
Validation loss: 2.5670700879140447

Epoch: 5| Step: 2
Training loss: 1.1821959648666223
Validation loss: 2.5668431417734263

Epoch: 5| Step: 3
Training loss: 1.2453652288169774
Validation loss: 2.54543558255967

Epoch: 5| Step: 4
Training loss: 0.7139522225265271
Validation loss: 2.5628284964860546

Epoch: 5| Step: 5
Training loss: 0.7638854681766869
Validation loss: 2.4847420355341683

Epoch: 5| Step: 6
Training loss: 0.7341099930523092
Validation loss: 2.541391620971091

Epoch: 5| Step: 7
Training loss: 0.9971598884778907
Validation loss: 2.5124830800525815

Epoch: 5| Step: 8
Training loss: 1.1860806867482898
Validation loss: 2.566770379697914

Epoch: 5| Step: 9
Training loss: 0.8557288066347045
Validation loss: 2.511449191281042

Epoch: 5| Step: 10
Training loss: 0.5484127223838067
Validation loss: 2.5044565533391623

Epoch: 5| Step: 11
Training loss: 0.3087782368701649
Validation loss: 2.5029437138777997

Epoch: 486| Step: 0
Training loss: 1.2747857848832458
Validation loss: 2.5019704682629764

Epoch: 5| Step: 1
Training loss: 1.1934842857505736
Validation loss: 2.4772940356510293

Epoch: 5| Step: 2
Training loss: 0.6110750350875979
Validation loss: 2.4947595468151076

Epoch: 5| Step: 3
Training loss: 0.7635775066323973
Validation loss: 2.5270907055735994

Epoch: 5| Step: 4
Training loss: 1.123581840145397
Validation loss: 2.5174343836559947

Epoch: 5| Step: 5
Training loss: 0.8216501138604763
Validation loss: 2.5094472403636585

Epoch: 5| Step: 6
Training loss: 0.9684010461702333
Validation loss: 2.5728054112667595

Epoch: 5| Step: 7
Training loss: 0.6409293591499847
Validation loss: 2.5044599407894355

Epoch: 5| Step: 8
Training loss: 0.9607772693560878
Validation loss: 2.557872280291469

Epoch: 5| Step: 9
Training loss: 1.0460747464243707
Validation loss: 2.60446250315989

Epoch: 5| Step: 10
Training loss: 0.6753600908462772
Validation loss: 2.5910819705524464

Epoch: 5| Step: 11
Training loss: 0.39370949779072784
Validation loss: 2.5964214975598385

Epoch: 487| Step: 0
Training loss: 0.9406983812673662
Validation loss: 2.632342088068241

Epoch: 5| Step: 1
Training loss: 0.6412659904092459
Validation loss: 2.630187558888393

Epoch: 5| Step: 2
Training loss: 0.9364098250258635
Validation loss: 2.6320435073520327

Epoch: 5| Step: 3
Training loss: 0.8748798969130117
Validation loss: 2.611234731247597

Epoch: 5| Step: 4
Training loss: 0.9216579893047462
Validation loss: 2.561523247468054

Epoch: 5| Step: 5
Training loss: 1.3059277150594704
Validation loss: 2.5788559426546573

Epoch: 5| Step: 6
Training loss: 1.3081098430427982
Validation loss: 2.6097208163205914

Epoch: 5| Step: 7
Training loss: 1.1369459836168452
Validation loss: 2.6004971985545464

Epoch: 5| Step: 8
Training loss: 0.8205454540994025
Validation loss: 2.586210783840415

Epoch: 5| Step: 9
Training loss: 0.6607485038777913
Validation loss: 2.532301837289258

Epoch: 5| Step: 10
Training loss: 0.49608274132235985
Validation loss: 2.5544226136766244

Epoch: 5| Step: 11
Training loss: 1.549504982442068
Validation loss: 2.58711008644699

Epoch: 488| Step: 0
Training loss: 1.0860924370101523
Validation loss: 2.574222775013796

Epoch: 5| Step: 1
Training loss: 0.8036933609626904
Validation loss: 2.576595307267176

Epoch: 5| Step: 2
Training loss: 0.7560223149962224
Validation loss: 2.6393075286060332

Epoch: 5| Step: 3
Training loss: 1.2506487593331297
Validation loss: 2.6112188156101688

Epoch: 5| Step: 4
Training loss: 1.1548710410055096
Validation loss: 2.676250767411501

Epoch: 5| Step: 5
Training loss: 0.9044611804238011
Validation loss: 2.680189865963933

Epoch: 5| Step: 6
Training loss: 1.079347773983325
Validation loss: 2.622512192908405

Epoch: 5| Step: 7
Training loss: 0.47585920124367054
Validation loss: 2.5592500034312526

Epoch: 5| Step: 8
Training loss: 0.9045170954580126
Validation loss: 2.5353859560780125

Epoch: 5| Step: 9
Training loss: 0.9897854782571575
Validation loss: 2.5917647397373536

Epoch: 5| Step: 10
Training loss: 0.7129848470214597
Validation loss: 2.585241921447196

Epoch: 5| Step: 11
Training loss: 0.9603442710241235
Validation loss: 2.5474550409689187

Epoch: 489| Step: 0
Training loss: 1.3270999318536554
Validation loss: 2.554714789910724

Epoch: 5| Step: 1
Training loss: 0.70044277186387
Validation loss: 2.543865871836505

Epoch: 5| Step: 2
Training loss: 0.7187228819665594
Validation loss: 2.564218851793443

Epoch: 5| Step: 3
Training loss: 0.8707202401410795
Validation loss: 2.5582963959971257

Epoch: 5| Step: 4
Training loss: 0.7644669084665944
Validation loss: 2.5813762740128863

Epoch: 5| Step: 5
Training loss: 1.479790041310075
Validation loss: 2.5551488520037084

Epoch: 5| Step: 6
Training loss: 0.826859821286949
Validation loss: 2.5275231975229167

Epoch: 5| Step: 7
Training loss: 1.0206696450443113
Validation loss: 2.567293036163154

Epoch: 5| Step: 8
Training loss: 0.7979999903772109
Validation loss: 2.54409381533078

Epoch: 5| Step: 9
Training loss: 0.8455626478982446
Validation loss: 2.5643114146203243

Epoch: 5| Step: 10
Training loss: 0.8225398025621685
Validation loss: 2.5472791620206907

Epoch: 5| Step: 11
Training loss: 0.6113303675016278
Validation loss: 2.5615815284415953

Epoch: 490| Step: 0
Training loss: 1.3738033115639718
Validation loss: 2.5268980612981364

Epoch: 5| Step: 1
Training loss: 0.9482144352694956
Validation loss: 2.5470246971150137

Epoch: 5| Step: 2
Training loss: 0.769262702673368
Validation loss: 2.4938167340807293

Epoch: 5| Step: 3
Training loss: 0.7221596325953538
Validation loss: 2.589586462835834

Epoch: 5| Step: 4
Training loss: 0.6964750964305669
Validation loss: 2.5683271824278093

Epoch: 5| Step: 5
Training loss: 0.6886306049273239
Validation loss: 2.5388129791506984

Epoch: 5| Step: 6
Training loss: 0.9693882900583818
Validation loss: 2.5783855075423268

Epoch: 5| Step: 7
Training loss: 0.8124123305926534
Validation loss: 2.5694346837267905

Epoch: 5| Step: 8
Training loss: 0.8199153483704886
Validation loss: 2.5459397867071605

Epoch: 5| Step: 9
Training loss: 0.9158485113754208
Validation loss: 2.528210247223046

Epoch: 5| Step: 10
Training loss: 1.3075693248510314
Validation loss: 2.5433711228265103

Epoch: 5| Step: 11
Training loss: 0.9472712251163394
Validation loss: 2.515220767570537

Epoch: 491| Step: 0
Training loss: 1.2702741122105428
Validation loss: 2.529424067653567

Epoch: 5| Step: 1
Training loss: 0.8294558357912356
Validation loss: 2.4996855816215984

Epoch: 5| Step: 2
Training loss: 0.6512806619026776
Validation loss: 2.5711567273961564

Epoch: 5| Step: 3
Training loss: 1.0433715728195279
Validation loss: 2.589590045821026

Epoch: 5| Step: 4
Training loss: 1.261832217378786
Validation loss: 2.5190015645132724

Epoch: 5| Step: 5
Training loss: 0.81746480842695
Validation loss: 2.5165667577726696

Epoch: 5| Step: 6
Training loss: 1.1673145822489195
Validation loss: 2.5520633359372114

Epoch: 5| Step: 7
Training loss: 0.7384082745464535
Validation loss: 2.5509249971397954

Epoch: 5| Step: 8
Training loss: 0.5784021177346754
Validation loss: 2.570072893378048

Epoch: 5| Step: 9
Training loss: 0.7936405662131194
Validation loss: 2.5339807646680454

Epoch: 5| Step: 10
Training loss: 0.6409052956691331
Validation loss: 2.5712614655598367

Epoch: 5| Step: 11
Training loss: 0.8057211006087948
Validation loss: 2.6283093323173135

Epoch: 492| Step: 0
Training loss: 0.648325761106869
Validation loss: 2.6310192268214703

Epoch: 5| Step: 1
Training loss: 0.9921513047712509
Validation loss: 2.638039389592412

Epoch: 5| Step: 2
Training loss: 0.5883317477373292
Validation loss: 2.622139507495976

Epoch: 5| Step: 3
Training loss: 1.5310365956353502
Validation loss: 2.6315379467706492

Epoch: 5| Step: 4
Training loss: 0.8947307580742502
Validation loss: 2.5566078846435234

Epoch: 5| Step: 5
Training loss: 0.7990068827918689
Validation loss: 2.5184604744992

Epoch: 5| Step: 6
Training loss: 0.9637410893999312
Validation loss: 2.552770943684978

Epoch: 5| Step: 7
Training loss: 0.8483176046560897
Validation loss: 2.5224532972636826

Epoch: 5| Step: 8
Training loss: 0.830633933289814
Validation loss: 2.5315224850147215

Epoch: 5| Step: 9
Training loss: 0.5740837405557675
Validation loss: 2.5577040311992554

Epoch: 5| Step: 10
Training loss: 1.17536133019404
Validation loss: 2.5470311871713434

Epoch: 5| Step: 11
Training loss: 0.8410120799640617
Validation loss: 2.5971319716430163

Epoch: 493| Step: 0
Training loss: 1.3942649864935828
Validation loss: 2.611443885324015

Epoch: 5| Step: 1
Training loss: 0.5052549956752836
Validation loss: 2.619574408247241

Epoch: 5| Step: 2
Training loss: 0.49804744346436614
Validation loss: 2.6184916041799697

Epoch: 5| Step: 3
Training loss: 0.8332511662664758
Validation loss: 2.675775447198743

Epoch: 5| Step: 4
Training loss: 1.0985142080076626
Validation loss: 2.683050349568671

Epoch: 5| Step: 5
Training loss: 1.2886931381483366
Validation loss: 2.695380632949149

Epoch: 5| Step: 6
Training loss: 0.7627090667773877
Validation loss: 2.6615074635927223

Epoch: 5| Step: 7
Training loss: 0.8357063401663117
Validation loss: 2.594688791410007

Epoch: 5| Step: 8
Training loss: 0.5643755585592722
Validation loss: 2.566046269067794

Epoch: 5| Step: 9
Training loss: 1.0411279556904807
Validation loss: 2.587643551338185

Epoch: 5| Step: 10
Training loss: 0.9375390680437957
Validation loss: 2.5231470505799196

Epoch: 5| Step: 11
Training loss: 0.2474726766738906
Validation loss: 2.5141875778641904

Epoch: 494| Step: 0
Training loss: 0.7573827724583677
Validation loss: 2.526484685897592

Epoch: 5| Step: 1
Training loss: 0.9389605589008609
Validation loss: 2.535752949685334

Epoch: 5| Step: 2
Training loss: 0.7680691611694672
Validation loss: 2.5122612090056693

Epoch: 5| Step: 3
Training loss: 0.9671555287341416
Validation loss: 2.512061618245602

Epoch: 5| Step: 4
Training loss: 1.1020896678278598
Validation loss: 2.555524049411513

Epoch: 5| Step: 5
Training loss: 1.1305040186591682
Validation loss: 2.5191930953019273

Epoch: 5| Step: 6
Training loss: 1.0916947810117559
Validation loss: 2.527975383759036

Epoch: 5| Step: 7
Training loss: 0.8567261534445237
Validation loss: 2.594513907025687

Epoch: 5| Step: 8
Training loss: 0.5726501683098277
Validation loss: 2.6014743633442867

Epoch: 5| Step: 9
Training loss: 0.6232030308113539
Validation loss: 2.6504789378465086

Epoch: 5| Step: 10
Training loss: 0.6733445574710937
Validation loss: 2.6371068146141843

Epoch: 5| Step: 11
Training loss: 0.5388901752962356
Validation loss: 2.5842539636328694

Epoch: 495| Step: 0
Training loss: 1.1523622672969303
Validation loss: 2.6205412220256825

Epoch: 5| Step: 1
Training loss: 0.47068341795635765
Validation loss: 2.5999278870082096

Epoch: 5| Step: 2
Training loss: 1.0162791566314302
Validation loss: 2.526291818456686

Epoch: 5| Step: 3
Training loss: 0.9959135603144608
Validation loss: 2.551999457920798

Epoch: 5| Step: 4
Training loss: 1.174194786451614
Validation loss: 2.564124805655055

Epoch: 5| Step: 5
Training loss: 0.751426492546486
Validation loss: 2.5715190950201823

Epoch: 5| Step: 6
Training loss: 0.9451176150865528
Validation loss: 2.5537885081542973

Epoch: 5| Step: 7
Training loss: 0.6649509097028183
Validation loss: 2.620547962167835

Epoch: 5| Step: 8
Training loss: 0.6778260094864703
Validation loss: 2.56683368887708

Epoch: 5| Step: 9
Training loss: 0.8310758092686222
Validation loss: 2.5744072049688733

Epoch: 5| Step: 10
Training loss: 0.9407648774632408
Validation loss: 2.59467138830677

Epoch: 5| Step: 11
Training loss: 0.8679595122717028
Validation loss: 2.583872219120798

Epoch: 496| Step: 0
Training loss: 0.923462035083952
Validation loss: 2.555346451603336

Epoch: 5| Step: 1
Training loss: 0.5879743902912625
Validation loss: 2.5636069767793788

Epoch: 5| Step: 2
Training loss: 0.6107537981228304
Validation loss: 2.5309026542613884

Epoch: 5| Step: 3
Training loss: 0.822965527946983
Validation loss: 2.56747512196786

Epoch: 5| Step: 4
Training loss: 0.7141199251619262
Validation loss: 2.5208702176655993

Epoch: 5| Step: 5
Training loss: 1.1353241535725833
Validation loss: 2.540584733901211

Epoch: 5| Step: 6
Training loss: 0.8909830076543219
Validation loss: 2.5317737249470227

Epoch: 5| Step: 7
Training loss: 0.8318843801472554
Validation loss: 2.568091632149366

Epoch: 5| Step: 8
Training loss: 0.9085260616945943
Validation loss: 2.590493498050315

Epoch: 5| Step: 9
Training loss: 0.8837637713275236
Validation loss: 2.6309875404198695

Epoch: 5| Step: 10
Training loss: 1.1124795804667906
Validation loss: 2.591805464522639

Epoch: 5| Step: 11
Training loss: 0.9248613382488684
Validation loss: 2.5616561655533765

Epoch: 497| Step: 0
Training loss: 0.9242668481147073
Validation loss: 2.6131248712437

Epoch: 5| Step: 1
Training loss: 1.123729571283018
Validation loss: 2.645402055919213

Epoch: 5| Step: 2
Training loss: 0.7765129672243195
Validation loss: 2.615497958532592

Epoch: 5| Step: 3
Training loss: 1.1056931338710903
Validation loss: 2.6180325334808847

Epoch: 5| Step: 4
Training loss: 0.7353045079955699
Validation loss: 2.5637832932811286

Epoch: 5| Step: 5
Training loss: 0.7951231755495242
Validation loss: 2.5320444606745145

Epoch: 5| Step: 6
Training loss: 1.109683678893566
Validation loss: 2.5535326028070466

Epoch: 5| Step: 7
Training loss: 0.9034313566671303
Validation loss: 2.554163444500416

Epoch: 5| Step: 8
Training loss: 0.7949321474353545
Validation loss: 2.578158337926616

Epoch: 5| Step: 9
Training loss: 0.9168900665522289
Validation loss: 2.580964426402951

Epoch: 5| Step: 10
Training loss: 0.7773967322308103
Validation loss: 2.534257373831826

Epoch: 5| Step: 11
Training loss: 0.866655822527117
Validation loss: 2.5968380052828786

Epoch: 498| Step: 0
Training loss: 0.943424893901817
Validation loss: 2.665992749759968

Epoch: 5| Step: 1
Training loss: 0.7424240137001374
Validation loss: 2.6433756457301985

Epoch: 5| Step: 2
Training loss: 0.9502473132811322
Validation loss: 2.702839852877306

Epoch: 5| Step: 3
Training loss: 0.6381884503927674
Validation loss: 2.6767362426497385

Epoch: 5| Step: 4
Training loss: 0.8434316599736632
Validation loss: 2.5786758489421446

Epoch: 5| Step: 5
Training loss: 0.7714807437859559
Validation loss: 2.6454602689379723

Epoch: 5| Step: 6
Training loss: 0.8365546470732353
Validation loss: 2.5850833776875763

Epoch: 5| Step: 7
Training loss: 1.0485254628878393
Validation loss: 2.5479613095664155

Epoch: 5| Step: 8
Training loss: 0.7645333350843309
Validation loss: 2.5677561855435407

Epoch: 5| Step: 9
Training loss: 1.2954541431468967
Validation loss: 2.561412793861664

Epoch: 5| Step: 10
Training loss: 1.152386266926187
Validation loss: 2.577550658398199

Epoch: 5| Step: 11
Training loss: 0.34938750872457597
Validation loss: 2.5169470572957704

Epoch: 499| Step: 0
Training loss: 1.0641924897727366
Validation loss: 2.5297628830125127

Epoch: 5| Step: 1
Training loss: 0.6042537681231671
Validation loss: 2.5747266797958757

Epoch: 5| Step: 2
Training loss: 0.7762186160170209
Validation loss: 2.572143771935686

Epoch: 5| Step: 3
Training loss: 0.9691152499350671
Validation loss: 2.5992314699070223

Epoch: 5| Step: 4
Training loss: 0.5145645217957724
Validation loss: 2.6424326982351607

Epoch: 5| Step: 5
Training loss: 1.0573898169650406
Validation loss: 2.6029862564194026

Epoch: 5| Step: 6
Training loss: 0.9192349081971439
Validation loss: 2.61137315534875

Epoch: 5| Step: 7
Training loss: 0.9436440048315157
Validation loss: 2.579976128201606

Epoch: 5| Step: 8
Training loss: 0.6761894536722218
Validation loss: 2.5522022310444252

Epoch: 5| Step: 9
Training loss: 1.2499050104288785
Validation loss: 2.543619278744263

Epoch: 5| Step: 10
Training loss: 0.8857050407384239
Validation loss: 2.5671180113576106

Epoch: 5| Step: 11
Training loss: 0.38090581366272797
Validation loss: 2.534776958037157

Epoch: 500| Step: 0
Training loss: 1.1167360474018246
Validation loss: 2.523202733633157

Epoch: 5| Step: 1
Training loss: 0.8289757083766585
Validation loss: 2.55281306882209

Epoch: 5| Step: 2
Training loss: 0.9322067875645909
Validation loss: 2.5707005224334045

Epoch: 5| Step: 3
Training loss: 0.7524391882267764
Validation loss: 2.650895754852593

Epoch: 5| Step: 4
Training loss: 1.1344120702650178
Validation loss: 2.6281786020734335

Epoch: 5| Step: 5
Training loss: 1.0259170198328136
Validation loss: 2.592725842668246

Epoch: 5| Step: 6
Training loss: 0.7633436819760442
Validation loss: 2.6082559458817394

Epoch: 5| Step: 7
Training loss: 0.866849747601444
Validation loss: 2.557933638742624

Epoch: 5| Step: 8
Training loss: 0.6857198295979393
Validation loss: 2.5549775891182747

Epoch: 5| Step: 9
Training loss: 1.0494376743087728
Validation loss: 2.616504002990178

Epoch: 5| Step: 10
Training loss: 1.06129252318255
Validation loss: 2.5824348338208845

Epoch: 5| Step: 11
Training loss: 0.880030883117103
Validation loss: 2.583645126282592

Epoch: 501| Step: 0
Training loss: 1.0308856898595746
Validation loss: 2.5988287781944353

Epoch: 5| Step: 1
Training loss: 0.8631939045488451
Validation loss: 2.5736789011880825

Epoch: 5| Step: 2
Training loss: 0.8475646571586279
Validation loss: 2.6210707953898096

Epoch: 5| Step: 3
Training loss: 0.7313585217147955
Validation loss: 2.619544782943954

Epoch: 5| Step: 4
Training loss: 0.8784341519080607
Validation loss: 2.6243460612689966

Epoch: 5| Step: 5
Training loss: 0.5184385237818767
Validation loss: 2.6222987600553718

Epoch: 5| Step: 6
Training loss: 0.75439453125
Validation loss: 2.6212339974871313

Epoch: 5| Step: 7
Training loss: 0.6696588873079866
Validation loss: 2.6406531699218583

Epoch: 5| Step: 8
Training loss: 1.0488741560909736
Validation loss: 2.6340323620929604

Epoch: 5| Step: 9
Training loss: 1.2936255408973458
Validation loss: 2.601205100558471

Epoch: 5| Step: 10
Training loss: 0.703772585728312
Validation loss: 2.6012685206803545

Epoch: 5| Step: 11
Training loss: 0.6467488142768717
Validation loss: 2.6040118145996956

Epoch: 502| Step: 0
Training loss: 0.739830974077813
Validation loss: 2.6053483049652484

Epoch: 5| Step: 1
Training loss: 0.8862108633011337
Validation loss: 2.540171638225186

Epoch: 5| Step: 2
Training loss: 0.5422452868357466
Validation loss: 2.5466740027687336

Epoch: 5| Step: 3
Training loss: 0.9064181928105957
Validation loss: 2.570725783618382

Epoch: 5| Step: 4
Training loss: 0.7990620464134197
Validation loss: 2.561839282135905

Epoch: 5| Step: 5
Training loss: 0.7668186925037475
Validation loss: 2.5377664515405765

Epoch: 5| Step: 6
Training loss: 1.1760701176344515
Validation loss: 2.566654535880053

Epoch: 5| Step: 7
Training loss: 0.5016264390447124
Validation loss: 2.553506045269786

Epoch: 5| Step: 8
Training loss: 0.6973603769243759
Validation loss: 2.5778092354729027

Epoch: 5| Step: 9
Training loss: 1.2476558639917512
Validation loss: 2.522412338901236

Epoch: 5| Step: 10
Training loss: 0.7067620412963257
Validation loss: 2.5682626993721946

Epoch: 5| Step: 11
Training loss: 0.4253147789742026
Validation loss: 2.5789182617807604

Epoch: 503| Step: 0
Training loss: 0.8786608883318482
Validation loss: 2.5828400238287528

Epoch: 5| Step: 1
Training loss: 0.9598529557027733
Validation loss: 2.5778180026290345

Epoch: 5| Step: 2
Training loss: 0.6833353262577614
Validation loss: 2.5976123318508986

Epoch: 5| Step: 3
Training loss: 0.7273851065345736
Validation loss: 2.564473927072844

Epoch: 5| Step: 4
Training loss: 0.8303991078614531
Validation loss: 2.6013693599394467

Epoch: 5| Step: 5
Training loss: 0.6325186765499209
Validation loss: 2.669040031069062

Epoch: 5| Step: 6
Training loss: 0.928327061913319
Validation loss: 2.551079589003205

Epoch: 5| Step: 7
Training loss: 1.0920666410841078
Validation loss: 2.591174217848206

Epoch: 5| Step: 8
Training loss: 0.7893693912575656
Validation loss: 2.5564106176478267

Epoch: 5| Step: 9
Training loss: 0.6376550495236423
Validation loss: 2.568639003679042

Epoch: 5| Step: 10
Training loss: 1.048958200241934
Validation loss: 2.5509046726247866

Epoch: 5| Step: 11
Training loss: 0.2589665506020254
Validation loss: 2.571445984283154

Epoch: 504| Step: 0
Training loss: 0.5045587322255561
Validation loss: 2.5984372334528896

Epoch: 5| Step: 1
Training loss: 0.6292832470773277
Validation loss: 2.4988963790619407

Epoch: 5| Step: 2
Training loss: 0.841345256553423
Validation loss: 2.5608592013852416

Epoch: 5| Step: 3
Training loss: 0.602099142120034
Validation loss: 2.558576192625729

Epoch: 5| Step: 4
Training loss: 0.84968720879783
Validation loss: 2.5025286006468153

Epoch: 5| Step: 5
Training loss: 0.8277231356986028
Validation loss: 2.534116483768724

Epoch: 5| Step: 6
Training loss: 0.6722873486960516
Validation loss: 2.5604492603417763

Epoch: 5| Step: 7
Training loss: 1.2506802615224604
Validation loss: 2.569535509993046

Epoch: 5| Step: 8
Training loss: 0.6775724014080952
Validation loss: 2.6286519434428124

Epoch: 5| Step: 9
Training loss: 0.789762092391489
Validation loss: 2.627294578247135

Epoch: 5| Step: 10
Training loss: 0.9153298615137185
Validation loss: 2.5891341574557325

Epoch: 5| Step: 11
Training loss: 0.8401742684019727
Validation loss: 2.5977770096093638

Epoch: 505| Step: 0
Training loss: 0.45572926839191574
Validation loss: 2.607503928275729

Epoch: 5| Step: 1
Training loss: 1.1245202525084628
Validation loss: 2.656110973085761

Epoch: 5| Step: 2
Training loss: 0.8628020531651593
Validation loss: 2.588628388812806

Epoch: 5| Step: 3
Training loss: 0.8296630539678151
Validation loss: 2.5475358320217545

Epoch: 5| Step: 4
Training loss: 0.6658732018651471
Validation loss: 2.560604561340932

Epoch: 5| Step: 5
Training loss: 1.1650034538512544
Validation loss: 2.545701169866904

Epoch: 5| Step: 6
Training loss: 0.5550771338758003
Validation loss: 2.5052818332498825

Epoch: 5| Step: 7
Training loss: 1.091424813791938
Validation loss: 2.5903664431142315

Epoch: 5| Step: 8
Training loss: 1.0235997428130483
Validation loss: 2.543720647906542

Epoch: 5| Step: 9
Training loss: 0.8142179154073522
Validation loss: 2.6059680748121132

Epoch: 5| Step: 10
Training loss: 0.7966950905356643
Validation loss: 2.562958455361885

Epoch: 5| Step: 11
Training loss: 0.777370586602944
Validation loss: 2.6107800292965897

Epoch: 506| Step: 0
Training loss: 0.6350851105925129
Validation loss: 2.5388232348265927

Epoch: 5| Step: 1
Training loss: 0.8634143226210529
Validation loss: 2.485310796117292

Epoch: 5| Step: 2
Training loss: 0.5964084639394481
Validation loss: 2.6081760530208036

Epoch: 5| Step: 3
Training loss: 0.5724174115941626
Validation loss: 2.6485705647006905

Epoch: 5| Step: 4
Training loss: 0.7894453498498979
Validation loss: 2.623026401101861

Epoch: 5| Step: 5
Training loss: 0.9726122804071567
Validation loss: 2.637885450157265

Epoch: 5| Step: 6
Training loss: 1.3261757402546304
Validation loss: 2.6365906672510206

Epoch: 5| Step: 7
Training loss: 0.8064239063041119
Validation loss: 2.6164919180336708

Epoch: 5| Step: 8
Training loss: 0.7125735060938725
Validation loss: 2.629640447415108

Epoch: 5| Step: 9
Training loss: 0.7220202147171539
Validation loss: 2.6685617885287116

Epoch: 5| Step: 10
Training loss: 0.7303062707050152
Validation loss: 2.6334169978621045

Epoch: 5| Step: 11
Training loss: 0.3517265572818947
Validation loss: 2.6074804368508944

Epoch: 507| Step: 0
Training loss: 0.7496807690565125
Validation loss: 2.641833781096874

Epoch: 5| Step: 1
Training loss: 0.9096838253029578
Validation loss: 2.608759436268138

Epoch: 5| Step: 2
Training loss: 0.8528763670750329
Validation loss: 2.5669921175314716

Epoch: 5| Step: 3
Training loss: 0.6747085127356659
Validation loss: 2.5948706124964764

Epoch: 5| Step: 4
Training loss: 0.4796230658083826
Validation loss: 2.5927981311414814

Epoch: 5| Step: 5
Training loss: 0.5536951671689123
Validation loss: 2.5728252770464826

Epoch: 5| Step: 6
Training loss: 0.9568737912559724
Validation loss: 2.604121373100577

Epoch: 5| Step: 7
Training loss: 0.9128480978883728
Validation loss: 2.572105311962034

Epoch: 5| Step: 8
Training loss: 0.9047425986264199
Validation loss: 2.631572178426202

Epoch: 5| Step: 9
Training loss: 1.0049930137657155
Validation loss: 2.5772468015212007

Epoch: 5| Step: 10
Training loss: 0.7192495103051432
Validation loss: 2.607010220953539

Epoch: 5| Step: 11
Training loss: 0.15268163014198727
Validation loss: 2.574474345182184

Epoch: 508| Step: 0
Training loss: 0.623354055800538
Validation loss: 2.552057874643408

Epoch: 5| Step: 1
Training loss: 0.6630084030372589
Validation loss: 2.5834475435626447

Epoch: 5| Step: 2
Training loss: 0.7779782643285149
Validation loss: 2.5629115704571714

Epoch: 5| Step: 3
Training loss: 1.0390051345478035
Validation loss: 2.5766358207231512

Epoch: 5| Step: 4
Training loss: 0.7669730871594188
Validation loss: 2.525176139233762

Epoch: 5| Step: 5
Training loss: 0.9855425435022823
Validation loss: 2.5455785720385133

Epoch: 5| Step: 6
Training loss: 0.6198897778302831
Validation loss: 2.6048643868683192

Epoch: 5| Step: 7
Training loss: 0.7404259104268853
Validation loss: 2.553141659947252

Epoch: 5| Step: 8
Training loss: 0.8762654622301359
Validation loss: 2.6257382293357927

Epoch: 5| Step: 9
Training loss: 0.6586476757557315
Validation loss: 2.626315665158715

Epoch: 5| Step: 10
Training loss: 0.8123593208594867
Validation loss: 2.600380118105624

Epoch: 5| Step: 11
Training loss: 0.5004528796073214
Validation loss: 2.593163374166897

Epoch: 509| Step: 0
Training loss: 0.7787486660182054
Validation loss: 2.606479084762752

Epoch: 5| Step: 1
Training loss: 0.6386877868723372
Validation loss: 2.622790451184382

Epoch: 5| Step: 2
Training loss: 0.5692108697421682
Validation loss: 2.607538772610498

Epoch: 5| Step: 3
Training loss: 0.9927366644281365
Validation loss: 2.6452420404990615

Epoch: 5| Step: 4
Training loss: 0.46028240980843527
Validation loss: 2.5828113118203766

Epoch: 5| Step: 5
Training loss: 0.9883437909628545
Validation loss: 2.5949397058777315

Epoch: 5| Step: 6
Training loss: 0.4654403832567721
Validation loss: 2.5632673874541907

Epoch: 5| Step: 7
Training loss: 0.9205581829325414
Validation loss: 2.6391308129132356

Epoch: 5| Step: 8
Training loss: 1.0364892402270784
Validation loss: 2.589006076551693

Epoch: 5| Step: 9
Training loss: 0.8932707455284173
Validation loss: 2.619957453498136

Epoch: 5| Step: 10
Training loss: 1.0801943393979203
Validation loss: 2.618588697826669

Epoch: 5| Step: 11
Training loss: 0.34980110153839433
Validation loss: 2.555006013198764

Epoch: 510| Step: 0
Training loss: 0.8297101091368343
Validation loss: 2.5392530985966637

Epoch: 5| Step: 1
Training loss: 0.9378759901755097
Validation loss: 2.5898261417271717

Epoch: 5| Step: 2
Training loss: 0.6566285222451236
Validation loss: 2.596503523519784

Epoch: 5| Step: 3
Training loss: 0.6772480959817982
Validation loss: 2.5636298859777993

Epoch: 5| Step: 4
Training loss: 0.514543091851737
Validation loss: 2.616586538371678

Epoch: 5| Step: 5
Training loss: 0.9046580044643965
Validation loss: 2.5779336029831468

Epoch: 5| Step: 6
Training loss: 0.7797137605758901
Validation loss: 2.5657133021397294

Epoch: 5| Step: 7
Training loss: 0.7544670588618928
Validation loss: 2.5451283150372745

Epoch: 5| Step: 8
Training loss: 0.8500264163680794
Validation loss: 2.6018439781189997

Epoch: 5| Step: 9
Training loss: 0.5561706700709157
Validation loss: 2.5911393221417125

Epoch: 5| Step: 10
Training loss: 1.033862417397939
Validation loss: 2.580722796640448

Epoch: 5| Step: 11
Training loss: 0.44391630709842256
Validation loss: 2.533026346682084

Epoch: 511| Step: 0
Training loss: 0.7535308140261553
Validation loss: 2.539464408169947

Epoch: 5| Step: 1
Training loss: 0.6333729416817736
Validation loss: 2.4548376547774753

Epoch: 5| Step: 2
Training loss: 0.7345184023832461
Validation loss: 2.507470851375701

Epoch: 5| Step: 3
Training loss: 0.8783776283013122
Validation loss: 2.513917268296633

Epoch: 5| Step: 4
Training loss: 1.0413292274695356
Validation loss: 2.5399589951276638

Epoch: 5| Step: 5
Training loss: 0.9869332147669143
Validation loss: 2.517128315535084

Epoch: 5| Step: 6
Training loss: 1.1148290749474856
Validation loss: 2.5074087116945636

Epoch: 5| Step: 7
Training loss: 0.7430700174946542
Validation loss: 2.4988781358943033

Epoch: 5| Step: 8
Training loss: 1.0235319021235303
Validation loss: 2.642032473915408

Epoch: 5| Step: 9
Training loss: 0.9255811257689077
Validation loss: 2.6691843617396906

Epoch: 5| Step: 10
Training loss: 0.7469834221068945
Validation loss: 2.631553382780732

Epoch: 5| Step: 11
Training loss: 0.4741050489639584
Validation loss: 2.6299429007322255

Epoch: 512| Step: 0
Training loss: 0.8729561368141315
Validation loss: 2.6496147570001662

Epoch: 5| Step: 1
Training loss: 0.9770787209820146
Validation loss: 2.66647798397194

Epoch: 5| Step: 2
Training loss: 0.7357379359281194
Validation loss: 2.658498620083666

Epoch: 5| Step: 3
Training loss: 1.0967448513274494
Validation loss: 2.628446158004553

Epoch: 5| Step: 4
Training loss: 1.1021317438311051
Validation loss: 2.567327959982057

Epoch: 5| Step: 5
Training loss: 0.528243533494314
Validation loss: 2.616002603162118

Epoch: 5| Step: 6
Training loss: 0.8010578701197703
Validation loss: 2.624436586709237

Epoch: 5| Step: 7
Training loss: 0.7312807679835561
Validation loss: 2.623612498872075

Epoch: 5| Step: 8
Training loss: 0.7778398857031439
Validation loss: 2.640866341932799

Epoch: 5| Step: 9
Training loss: 0.9585225844451227
Validation loss: 2.612984156197521

Epoch: 5| Step: 10
Training loss: 1.066331294852484
Validation loss: 2.614121405132962

Epoch: 5| Step: 11
Training loss: 0.4173929401573835
Validation loss: 2.578066083446814

Epoch: 513| Step: 0
Training loss: 0.5053043339812014
Validation loss: 2.5732587395171276

Epoch: 5| Step: 1
Training loss: 1.103482082160979
Validation loss: 2.5702103978123216

Epoch: 5| Step: 2
Training loss: 1.253525720771416
Validation loss: 2.606698992053948

Epoch: 5| Step: 3
Training loss: 0.7388025290311147
Validation loss: 2.66593826423908

Epoch: 5| Step: 4
Training loss: 0.7082791775215102
Validation loss: 2.679320344526907

Epoch: 5| Step: 5
Training loss: 0.7116995698959425
Validation loss: 2.6927489247512217

Epoch: 5| Step: 6
Training loss: 0.7278599383502256
Validation loss: 2.7491783373992487

Epoch: 5| Step: 7
Training loss: 1.1495044967609873
Validation loss: 2.718797104160718

Epoch: 5| Step: 8
Training loss: 0.8002583354836408
Validation loss: 2.7844544177818835

Epoch: 5| Step: 9
Training loss: 0.69822601086211
Validation loss: 2.719091620485691

Epoch: 5| Step: 10
Training loss: 0.7575074988016037
Validation loss: 2.7065709884728317

Epoch: 5| Step: 11
Training loss: 0.4308207220479727
Validation loss: 2.638849041175033

Epoch: 514| Step: 0
Training loss: 0.6584680403337668
Validation loss: 2.630617488851267

Epoch: 5| Step: 1
Training loss: 0.5662026927462208
Validation loss: 2.567559879543227

Epoch: 5| Step: 2
Training loss: 0.5965215095597277
Validation loss: 2.5292894596496835

Epoch: 5| Step: 3
Training loss: 1.1515711894024527
Validation loss: 2.5193407247892017

Epoch: 5| Step: 4
Training loss: 0.7622451528318134
Validation loss: 2.5383065120386656

Epoch: 5| Step: 5
Training loss: 0.846436884823719
Validation loss: 2.5574080692584995

Epoch: 5| Step: 6
Training loss: 1.0717633292079174
Validation loss: 2.54714288258366

Epoch: 5| Step: 7
Training loss: 1.3477569542452266
Validation loss: 2.5738457277789957

Epoch: 5| Step: 8
Training loss: 0.987368678765129
Validation loss: 2.5729816341048606

Epoch: 5| Step: 9
Training loss: 0.6430707162352008
Validation loss: 2.5536810810587878

Epoch: 5| Step: 10
Training loss: 0.8709624324059072
Validation loss: 2.6711907914281525

Epoch: 5| Step: 11
Training loss: 0.7518154265917373
Validation loss: 2.7293361357616823

Epoch: 515| Step: 0
Training loss: 1.0338427577442197
Validation loss: 2.7418674090172894

Epoch: 5| Step: 1
Training loss: 0.8069079235637641
Validation loss: 2.6417621519078143

Epoch: 5| Step: 2
Training loss: 0.9725523743831351
Validation loss: 2.6147368121346024

Epoch: 5| Step: 3
Training loss: 0.7745156528179149
Validation loss: 2.612739879449242

Epoch: 5| Step: 4
Training loss: 0.7608078033395057
Validation loss: 2.6111849981252004

Epoch: 5| Step: 5
Training loss: 0.5388808289834037
Validation loss: 2.608947182036259

Epoch: 5| Step: 6
Training loss: 0.8339705812264947
Validation loss: 2.601985866400001

Epoch: 5| Step: 7
Training loss: 0.7900175603291087
Validation loss: 2.6343317638452715

Epoch: 5| Step: 8
Training loss: 0.8457563705069098
Validation loss: 2.6027102339555004

Epoch: 5| Step: 9
Training loss: 0.8849210623650445
Validation loss: 2.631112395922253

Epoch: 5| Step: 10
Training loss: 0.6493989641542577
Validation loss: 2.636848171495786

Epoch: 5| Step: 11
Training loss: 1.2046255192230553
Validation loss: 2.6205743027652164

Epoch: 516| Step: 0
Training loss: 0.6782952442144753
Validation loss: 2.6667110258128273

Epoch: 5| Step: 1
Training loss: 0.9131574143773417
Validation loss: 2.6417604992073267

Epoch: 5| Step: 2
Training loss: 0.8621803271778885
Validation loss: 2.6406843114809293

Epoch: 5| Step: 3
Training loss: 0.9327682612422595
Validation loss: 2.6362097807014346

Epoch: 5| Step: 4
Training loss: 0.643649150763492
Validation loss: 2.7278288129526396

Epoch: 5| Step: 5
Training loss: 0.8152380803841508
Validation loss: 2.6828849556080625

Epoch: 5| Step: 6
Training loss: 0.8936514713423578
Validation loss: 2.696270202180213

Epoch: 5| Step: 7
Training loss: 1.1443673494959328
Validation loss: 2.719518688026411

Epoch: 5| Step: 8
Training loss: 0.7453279009813276
Validation loss: 2.6477003243759674

Epoch: 5| Step: 9
Training loss: 0.7262990740611937
Validation loss: 2.6792429711929313

Epoch: 5| Step: 10
Training loss: 0.9080949616370448
Validation loss: 2.636133493532329

Epoch: 5| Step: 11
Training loss: 1.0260157831996923
Validation loss: 2.5811151061321573

Epoch: 517| Step: 0
Training loss: 0.7150712615293993
Validation loss: 2.5190522638070436

Epoch: 5| Step: 1
Training loss: 0.8572268600967458
Validation loss: 2.560172175060166

Epoch: 5| Step: 2
Training loss: 0.8907815226828963
Validation loss: 2.5590751796825515

Epoch: 5| Step: 3
Training loss: 0.7153929804852417
Validation loss: 2.6002809653937113

Epoch: 5| Step: 4
Training loss: 0.7823144146642182
Validation loss: 2.6079979306641365

Epoch: 5| Step: 5
Training loss: 0.787623651575709
Validation loss: 2.626587325369697

Epoch: 5| Step: 6
Training loss: 1.153674685746739
Validation loss: 2.6206441646244847

Epoch: 5| Step: 7
Training loss: 0.6254447308401874
Validation loss: 2.6683913585495995

Epoch: 5| Step: 8
Training loss: 0.7869711629147922
Validation loss: 2.6598019954536323

Epoch: 5| Step: 9
Training loss: 1.0401606099199374
Validation loss: 2.7002504496035282

Epoch: 5| Step: 10
Training loss: 0.7806316980787733
Validation loss: 2.76306778019682

Epoch: 5| Step: 11
Training loss: 1.0214364093437878
Validation loss: 2.769472423766265

Epoch: 518| Step: 0
Training loss: 1.087947932981979
Validation loss: 2.7895171777023444

Epoch: 5| Step: 1
Training loss: 0.7295796904880536
Validation loss: 2.6012642453653094

Epoch: 5| Step: 2
Training loss: 1.1812133016385717
Validation loss: 2.66844167469349

Epoch: 5| Step: 3
Training loss: 0.8885966510165253
Validation loss: 2.5754219720198783

Epoch: 5| Step: 4
Training loss: 0.5681856289649094
Validation loss: 2.541439983676819

Epoch: 5| Step: 5
Training loss: 0.7749691064891382
Validation loss: 2.497269482378161

Epoch: 5| Step: 6
Training loss: 0.6861784978697021
Validation loss: 2.55170137829865

Epoch: 5| Step: 7
Training loss: 0.7672231304650713
Validation loss: 2.5352970235070016

Epoch: 5| Step: 8
Training loss: 0.6125898655341752
Validation loss: 2.5768199815905284

Epoch: 5| Step: 9
Training loss: 0.8451249963528763
Validation loss: 2.544678686920674

Epoch: 5| Step: 10
Training loss: 0.6408231010248447
Validation loss: 2.6035361092427673

Epoch: 5| Step: 11
Training loss: 0.8036916552023206
Validation loss: 2.576631275135864

Epoch: 519| Step: 0
Training loss: 0.8828906809529421
Validation loss: 2.6221685920354587

Epoch: 5| Step: 1
Training loss: 0.5781707230091435
Validation loss: 2.570299413274748

Epoch: 5| Step: 2
Training loss: 0.44332282297981684
Validation loss: 2.589052001618745

Epoch: 5| Step: 3
Training loss: 0.8006069458854822
Validation loss: 2.541513654657797

Epoch: 5| Step: 4
Training loss: 0.5549899606398121
Validation loss: 2.5636907578853583

Epoch: 5| Step: 5
Training loss: 0.7429717488032812
Validation loss: 2.578107186458197

Epoch: 5| Step: 6
Training loss: 0.7773143436869796
Validation loss: 2.6137788391042567

Epoch: 5| Step: 7
Training loss: 0.9169420710021934
Validation loss: 2.6014870755829347

Epoch: 5| Step: 8
Training loss: 1.1336796039903798
Validation loss: 2.6326069171455284

Epoch: 5| Step: 9
Training loss: 1.0509070565734089
Validation loss: 2.601099475212592

Epoch: 5| Step: 10
Training loss: 0.6348781779345465
Validation loss: 2.6656324062266883

Epoch: 5| Step: 11
Training loss: 0.8525563661058093
Validation loss: 2.6388018293966327

Epoch: 520| Step: 0
Training loss: 0.949746883703523
Validation loss: 2.6318715580857575

Epoch: 5| Step: 1
Training loss: 0.8468633010450334
Validation loss: 2.6519038454036803

Epoch: 5| Step: 2
Training loss: 0.8472032523159426
Validation loss: 2.6698728797359212

Epoch: 5| Step: 3
Training loss: 0.8075237473813627
Validation loss: 2.7121094837140167

Epoch: 5| Step: 4
Training loss: 0.8276358185259669
Validation loss: 2.678790176708589

Epoch: 5| Step: 5
Training loss: 0.6042258518650979
Validation loss: 2.5715911452114595

Epoch: 5| Step: 6
Training loss: 0.9809830065450147
Validation loss: 2.592120926737733

Epoch: 5| Step: 7
Training loss: 0.6669284237142249
Validation loss: 2.5696873276559025

Epoch: 5| Step: 8
Training loss: 0.567085043530638
Validation loss: 2.516501487249067

Epoch: 5| Step: 9
Training loss: 0.9736925602279508
Validation loss: 2.5293256289149944

Epoch: 5| Step: 10
Training loss: 0.6519141238679593
Validation loss: 2.5748932128046818

Epoch: 5| Step: 11
Training loss: 0.3863258099462498
Validation loss: 2.583583870911068

Epoch: 521| Step: 0
Training loss: 0.6808300281181401
Validation loss: 2.5629662422971484

Epoch: 5| Step: 1
Training loss: 0.79792040150883
Validation loss: 2.539652897589002

Epoch: 5| Step: 2
Training loss: 1.012272392404011
Validation loss: 2.6499208667923817

Epoch: 5| Step: 3
Training loss: 0.713952765181948
Validation loss: 2.650990681760665

Epoch: 5| Step: 4
Training loss: 0.8600175016307907
Validation loss: 2.5957341399204426

Epoch: 5| Step: 5
Training loss: 0.6014708907487214
Validation loss: 2.652695753722364

Epoch: 5| Step: 6
Training loss: 0.5779969099269091
Validation loss: 2.592448106986396

Epoch: 5| Step: 7
Training loss: 0.7761712360811411
Validation loss: 2.641956546644851

Epoch: 5| Step: 8
Training loss: 0.5504363853865186
Validation loss: 2.5559353245349175

Epoch: 5| Step: 9
Training loss: 0.9308942768246773
Validation loss: 2.5832825830048107

Epoch: 5| Step: 10
Training loss: 1.0914500441396935
Validation loss: 2.5322572054310255

Epoch: 5| Step: 11
Training loss: 0.48073500722338375
Validation loss: 2.5687435486519914

Epoch: 522| Step: 0
Training loss: 0.5916127588894523
Validation loss: 2.578641300329699

Epoch: 5| Step: 1
Training loss: 0.5501922000665621
Validation loss: 2.5259361376135954

Epoch: 5| Step: 2
Training loss: 0.7669552127016627
Validation loss: 2.592215865648543

Epoch: 5| Step: 3
Training loss: 0.8855598707890349
Validation loss: 2.536858992424674

Epoch: 5| Step: 4
Training loss: 0.6627109911362774
Validation loss: 2.5129936328792857

Epoch: 5| Step: 5
Training loss: 0.7428053442546557
Validation loss: 2.466515457318188

Epoch: 5| Step: 6
Training loss: 0.7253454536338108
Validation loss: 2.551141821480254

Epoch: 5| Step: 7
Training loss: 0.8383712990381793
Validation loss: 2.5469331559170403

Epoch: 5| Step: 8
Training loss: 1.0324493716298844
Validation loss: 2.5549556463128087

Epoch: 5| Step: 9
Training loss: 0.8387772641817574
Validation loss: 2.595026801190803

Epoch: 5| Step: 10
Training loss: 1.0302794542182134
Validation loss: 2.584867984227915

Epoch: 5| Step: 11
Training loss: 0.8120864402538019
Validation loss: 2.5935364294406535

Epoch: 523| Step: 0
Training loss: 0.6040915546642762
Validation loss: 2.5933359669757388

Epoch: 5| Step: 1
Training loss: 0.7983242395025083
Validation loss: 2.6501513630596456

Epoch: 5| Step: 2
Training loss: 0.7351585023300256
Validation loss: 2.675338340913418

Epoch: 5| Step: 3
Training loss: 0.670100374602939
Validation loss: 2.6891145883259115

Epoch: 5| Step: 4
Training loss: 0.7802438360335604
Validation loss: 2.679369389491269

Epoch: 5| Step: 5
Training loss: 0.6446092500595214
Validation loss: 2.7191606554936625

Epoch: 5| Step: 6
Training loss: 0.932878611408774
Validation loss: 2.6629420522407874

Epoch: 5| Step: 7
Training loss: 0.8750360685816426
Validation loss: 2.6430184579433966

Epoch: 5| Step: 8
Training loss: 0.8762808008807379
Validation loss: 2.6044443300358466

Epoch: 5| Step: 9
Training loss: 0.7784165690214097
Validation loss: 2.6206155066845516

Epoch: 5| Step: 10
Training loss: 0.6476562573625038
Validation loss: 2.6094019349739117

Epoch: 5| Step: 11
Training loss: 0.38918263216100224
Validation loss: 2.5745020157246845

Epoch: 524| Step: 0
Training loss: 0.5902667265836132
Validation loss: 2.5913388523817193

Epoch: 5| Step: 1
Training loss: 0.7849386872201259
Validation loss: 2.5797233250959075

Epoch: 5| Step: 2
Training loss: 1.2542409004640176
Validation loss: 2.569551335866443

Epoch: 5| Step: 3
Training loss: 0.7077138987866906
Validation loss: 2.608586685279251

Epoch: 5| Step: 4
Training loss: 0.6018842356954625
Validation loss: 2.595738487490732

Epoch: 5| Step: 5
Training loss: 0.7042814493209083
Validation loss: 2.616793808814507

Epoch: 5| Step: 6
Training loss: 0.5936393383701863
Validation loss: 2.6337758687346233

Epoch: 5| Step: 7
Training loss: 0.6755836065494218
Validation loss: 2.6675161235599707

Epoch: 5| Step: 8
Training loss: 0.8198983736563877
Validation loss: 2.643670336858542

Epoch: 5| Step: 9
Training loss: 0.6581411360803001
Validation loss: 2.652394364950386

Epoch: 5| Step: 10
Training loss: 0.6539049711408609
Validation loss: 2.645763596544339

Epoch: 5| Step: 11
Training loss: 0.98333582446758
Validation loss: 2.567702521007426

Epoch: 525| Step: 0
Training loss: 0.8254577941571846
Validation loss: 2.5593555277361957

Epoch: 5| Step: 1
Training loss: 0.7837028526349639
Validation loss: 2.5554944979300496

Epoch: 5| Step: 2
Training loss: 1.0357809233251343
Validation loss: 2.6010563198548153

Epoch: 5| Step: 3
Training loss: 0.7908237177388521
Validation loss: 2.5897583523072543

Epoch: 5| Step: 4
Training loss: 1.0602769596024628
Validation loss: 2.558229126319733

Epoch: 5| Step: 5
Training loss: 0.7753470766536494
Validation loss: 2.56138324050902

Epoch: 5| Step: 6
Training loss: 1.1464482940247207
Validation loss: 2.547464123168473

Epoch: 5| Step: 7
Training loss: 0.9511104618745689
Validation loss: 2.5529314980237694

Epoch: 5| Step: 8
Training loss: 0.8791134738348229
Validation loss: 2.6585691164100913

Epoch: 5| Step: 9
Training loss: 0.6620816025212181
Validation loss: 2.642423910493917

Epoch: 5| Step: 10
Training loss: 1.1121407539595591
Validation loss: 2.7108939072972777

Epoch: 5| Step: 11
Training loss: 0.2686253680070901
Validation loss: 2.6616671132553322

Epoch: 526| Step: 0
Training loss: 0.5928991143672799
Validation loss: 2.6425982312633227

Epoch: 5| Step: 1
Training loss: 1.0217575379035955
Validation loss: 2.6006702424233166

Epoch: 5| Step: 2
Training loss: 1.0349586154201162
Validation loss: 2.635444235123496

Epoch: 5| Step: 3
Training loss: 0.7475424078965011
Validation loss: 2.6505013323052933

Epoch: 5| Step: 4
Training loss: 0.7934420821909075
Validation loss: 2.655939132600758

Epoch: 5| Step: 5
Training loss: 0.8240694751523865
Validation loss: 2.6483377646062456

Epoch: 5| Step: 6
Training loss: 0.6639990832397153
Validation loss: 2.663149023573609

Epoch: 5| Step: 7
Training loss: 0.6225165379100722
Validation loss: 2.6574112616383183

Epoch: 5| Step: 8
Training loss: 1.133302043501559
Validation loss: 2.6347964251777336

Epoch: 5| Step: 9
Training loss: 0.6636845130008996
Validation loss: 2.648664650417325

Epoch: 5| Step: 10
Training loss: 0.6998640524458842
Validation loss: 2.6749105183023376

Epoch: 5| Step: 11
Training loss: 0.49086300185723186
Validation loss: 2.6038499747672392

Epoch: 527| Step: 0
Training loss: 0.7449248979464137
Validation loss: 2.562187195115766

Epoch: 5| Step: 1
Training loss: 0.6830629958609004
Validation loss: 2.5439792018202407

Epoch: 5| Step: 2
Training loss: 1.0199577637884887
Validation loss: 2.5341727372443525

Epoch: 5| Step: 3
Training loss: 0.7735792088013572
Validation loss: 2.5696724845598764

Epoch: 5| Step: 4
Training loss: 0.7715386866513531
Validation loss: 2.5374279531890003

Epoch: 5| Step: 5
Training loss: 0.6907815427850716
Validation loss: 2.565060412167682

Epoch: 5| Step: 6
Training loss: 0.7693463408325308
Validation loss: 2.59285787958546

Epoch: 5| Step: 7
Training loss: 0.723640884580906
Validation loss: 2.589983794893164

Epoch: 5| Step: 8
Training loss: 0.9174773828800719
Validation loss: 2.566467330879273

Epoch: 5| Step: 9
Training loss: 0.7373149542693717
Validation loss: 2.6393463981849785

Epoch: 5| Step: 10
Training loss: 0.9192990342840448
Validation loss: 2.6331501639517616

Epoch: 5| Step: 11
Training loss: 0.3942252001270621
Validation loss: 2.63140889833467

Epoch: 528| Step: 0
Training loss: 0.7060503609974527
Validation loss: 2.655687751354821

Epoch: 5| Step: 1
Training loss: 0.5879731991589665
Validation loss: 2.716747200294869

Epoch: 5| Step: 2
Training loss: 0.7975877304612249
Validation loss: 2.700368773330912

Epoch: 5| Step: 3
Training loss: 0.5972457672869735
Validation loss: 2.640710471912455

Epoch: 5| Step: 4
Training loss: 0.6720308300550045
Validation loss: 2.615891377638612

Epoch: 5| Step: 5
Training loss: 0.5554246168671757
Validation loss: 2.6261077163381494

Epoch: 5| Step: 6
Training loss: 0.8550299647027294
Validation loss: 2.590032529399589

Epoch: 5| Step: 7
Training loss: 1.0915948070044756
Validation loss: 2.5875720364222654

Epoch: 5| Step: 8
Training loss: 0.7997759579818906
Validation loss: 2.5937429182882803

Epoch: 5| Step: 9
Training loss: 0.7158712704619474
Validation loss: 2.58404164191943

Epoch: 5| Step: 10
Training loss: 0.7320129880795163
Validation loss: 2.5797930166968044

Epoch: 5| Step: 11
Training loss: 0.4585281214633644
Validation loss: 2.633589983507132

Epoch: 529| Step: 0
Training loss: 0.3844384288401415
Validation loss: 2.5909701813373647

Epoch: 5| Step: 1
Training loss: 0.8290047201475493
Validation loss: 2.65523317733721

Epoch: 5| Step: 2
Training loss: 0.6932162069880985
Validation loss: 2.603924497152633

Epoch: 5| Step: 3
Training loss: 0.7675772708179487
Validation loss: 2.660863154103136

Epoch: 5| Step: 4
Training loss: 0.785431391394999
Validation loss: 2.691230306793984

Epoch: 5| Step: 5
Training loss: 0.6244314468727267
Validation loss: 2.6438672628166406

Epoch: 5| Step: 6
Training loss: 0.6299821642212885
Validation loss: 2.663423758084954

Epoch: 5| Step: 7
Training loss: 0.9831442329189091
Validation loss: 2.6995064066423273

Epoch: 5| Step: 8
Training loss: 0.8294199050440988
Validation loss: 2.6615821501017805

Epoch: 5| Step: 9
Training loss: 0.9164791276576842
Validation loss: 2.6937822024315388

Epoch: 5| Step: 10
Training loss: 1.048346780186356
Validation loss: 2.6898451468384406

Epoch: 5| Step: 11
Training loss: 0.7185059008531886
Validation loss: 2.731059860402465

Epoch: 530| Step: 0
Training loss: 0.7087363237410411
Validation loss: 2.723779352749764

Epoch: 5| Step: 1
Training loss: 0.7591810159202987
Validation loss: 2.758533264724324

Epoch: 5| Step: 2
Training loss: 1.1143893967413636
Validation loss: 2.70611237402848

Epoch: 5| Step: 3
Training loss: 0.8298915518724496
Validation loss: 2.658289804944308

Epoch: 5| Step: 4
Training loss: 0.5409962895102188
Validation loss: 2.614875607409974

Epoch: 5| Step: 5
Training loss: 0.7532417650048
Validation loss: 2.6515647556982445

Epoch: 5| Step: 6
Training loss: 0.6592261177947837
Validation loss: 2.603902459411273

Epoch: 5| Step: 7
Training loss: 0.9935809585460577
Validation loss: 2.5765588685166843

Epoch: 5| Step: 8
Training loss: 0.6373050073593043
Validation loss: 2.6312739954841198

Epoch: 5| Step: 9
Training loss: 0.7496442745924631
Validation loss: 2.6045472566332184

Epoch: 5| Step: 10
Training loss: 0.7383720301769714
Validation loss: 2.581220186844919

Epoch: 5| Step: 11
Training loss: 0.3646698735479386
Validation loss: 2.6050476999851844

Epoch: 531| Step: 0
Training loss: 0.49367291476500447
Validation loss: 2.613173693090947

Epoch: 5| Step: 1
Training loss: 0.7778323760813148
Validation loss: 2.7227052258210036

Epoch: 5| Step: 2
Training loss: 0.8196218580517652
Validation loss: 2.6886454218683977

Epoch: 5| Step: 3
Training loss: 0.8427990393435341
Validation loss: 2.7247951758689477

Epoch: 5| Step: 4
Training loss: 0.7508913544927679
Validation loss: 2.693968892257593

Epoch: 5| Step: 5
Training loss: 0.701270540144003
Validation loss: 2.6258475017881646

Epoch: 5| Step: 6
Training loss: 0.7863372726401049
Validation loss: 2.6406394160552464

Epoch: 5| Step: 7
Training loss: 0.772419191720229
Validation loss: 2.6439009778896936

Epoch: 5| Step: 8
Training loss: 0.6499727298444707
Validation loss: 2.5771721360231354

Epoch: 5| Step: 9
Training loss: 0.6941122346566724
Validation loss: 2.6192130605764072

Epoch: 5| Step: 10
Training loss: 1.111178476887565
Validation loss: 2.6294755324009773

Epoch: 5| Step: 11
Training loss: 1.1051441700125628
Validation loss: 2.646902410281956

Epoch: 532| Step: 0
Training loss: 0.847012710635801
Validation loss: 2.639469175923654

Epoch: 5| Step: 1
Training loss: 0.538745123272484
Validation loss: 2.6401736120072403

Epoch: 5| Step: 2
Training loss: 1.0566639783044867
Validation loss: 2.6576386281409223

Epoch: 5| Step: 3
Training loss: 0.7643449163872095
Validation loss: 2.698024152335396

Epoch: 5| Step: 4
Training loss: 0.8299621501013713
Validation loss: 2.653075730038919

Epoch: 5| Step: 5
Training loss: 0.7800816382575924
Validation loss: 2.662903594230312

Epoch: 5| Step: 6
Training loss: 0.7392230611516992
Validation loss: 2.5961143181355615

Epoch: 5| Step: 7
Training loss: 0.6783183986681853
Validation loss: 2.6219919241536664

Epoch: 5| Step: 8
Training loss: 0.507208362086826
Validation loss: 2.5557012228522895

Epoch: 5| Step: 9
Training loss: 0.7725699983135242
Validation loss: 2.5859974549748856

Epoch: 5| Step: 10
Training loss: 0.9267452066285713
Validation loss: 2.5812323484209787

Epoch: 5| Step: 11
Training loss: 0.647501304139109
Validation loss: 2.5754795026146815

Epoch: 533| Step: 0
Training loss: 0.970464788455521
Validation loss: 2.5621879744324763

Epoch: 5| Step: 1
Training loss: 0.657673110147624
Validation loss: 2.5857365924893676

Epoch: 5| Step: 2
Training loss: 0.7233967878779233
Validation loss: 2.655191363887404

Epoch: 5| Step: 3
Training loss: 0.5039257962479801
Validation loss: 2.6393400485601397

Epoch: 5| Step: 4
Training loss: 0.6686190066879305
Validation loss: 2.6603128253642763

Epoch: 5| Step: 5
Training loss: 0.9244287324858053
Validation loss: 2.668070357897942

Epoch: 5| Step: 6
Training loss: 0.7442153532698325
Validation loss: 2.70598908107032

Epoch: 5| Step: 7
Training loss: 0.7096735019554743
Validation loss: 2.6729927290522495

Epoch: 5| Step: 8
Training loss: 0.5743477345616954
Validation loss: 2.6176967637797772

Epoch: 5| Step: 9
Training loss: 1.0520796004628852
Validation loss: 2.6647220999459664

Epoch: 5| Step: 10
Training loss: 0.9844759329260828
Validation loss: 2.6006052472740264

Epoch: 5| Step: 11
Training loss: 0.8885895743354953
Validation loss: 2.6172342229819385

Epoch: 534| Step: 0
Training loss: 1.0724522718288922
Validation loss: 2.5789617124747424

Epoch: 5| Step: 1
Training loss: 0.8375514484374091
Validation loss: 2.601287088335989

Epoch: 5| Step: 2
Training loss: 0.581004574962863
Validation loss: 2.6101965001312224

Epoch: 5| Step: 3
Training loss: 0.5303594473815803
Validation loss: 2.6107036687523126

Epoch: 5| Step: 4
Training loss: 0.8089404998183729
Validation loss: 2.6672700569353855

Epoch: 5| Step: 5
Training loss: 1.0250807520993577
Validation loss: 2.656207009509883

Epoch: 5| Step: 6
Training loss: 0.9277111813507007
Validation loss: 2.6116453295296393

Epoch: 5| Step: 7
Training loss: 0.6011738946297017
Validation loss: 2.564894470447694

Epoch: 5| Step: 8
Training loss: 0.5894076522568573
Validation loss: 2.5311601096938445

Epoch: 5| Step: 9
Training loss: 0.6815356854214824
Validation loss: 2.5804987874189904

Epoch: 5| Step: 10
Training loss: 0.7417365862717044
Validation loss: 2.5626699693646455

Epoch: 5| Step: 11
Training loss: 0.711490122884041
Validation loss: 2.5621917779598853

Epoch: 535| Step: 0
Training loss: 0.7063952583549683
Validation loss: 2.5695042252388007

Epoch: 5| Step: 1
Training loss: 0.5978020134986695
Validation loss: 2.5880305433535784

Epoch: 5| Step: 2
Training loss: 0.7685607754806724
Validation loss: 2.5813451481571263

Epoch: 5| Step: 3
Training loss: 0.8443788727982804
Validation loss: 2.6430526423899003

Epoch: 5| Step: 4
Training loss: 0.6222695311611107
Validation loss: 2.606421681946474

Epoch: 5| Step: 5
Training loss: 0.583678506724932
Validation loss: 2.649742352658386

Epoch: 5| Step: 6
Training loss: 0.9430269085917241
Validation loss: 2.617867551293576

Epoch: 5| Step: 7
Training loss: 0.8257859503288355
Validation loss: 2.6487974786816224

Epoch: 5| Step: 8
Training loss: 0.5498944170351235
Validation loss: 2.6188155125850203

Epoch: 5| Step: 9
Training loss: 0.7515359885760222
Validation loss: 2.6784877964617886

Epoch: 5| Step: 10
Training loss: 0.7462374164408534
Validation loss: 2.6544712431360677

Epoch: 5| Step: 11
Training loss: 0.41572302615987333
Validation loss: 2.62012255622237

Epoch: 536| Step: 0
Training loss: 0.8428917511145692
Validation loss: 2.6051425376941064

Epoch: 5| Step: 1
Training loss: 0.7442026988494415
Validation loss: 2.626110780425087

Epoch: 5| Step: 2
Training loss: 0.7899496548943871
Validation loss: 2.587417202237543

Epoch: 5| Step: 3
Training loss: 0.6460266798049016
Validation loss: 2.6332173927553257

Epoch: 5| Step: 4
Training loss: 1.0120674033316228
Validation loss: 2.6233894425535027

Epoch: 5| Step: 5
Training loss: 0.7543299773907598
Validation loss: 2.5981487868456443

Epoch: 5| Step: 6
Training loss: 0.48673017191458234
Validation loss: 2.5925014700436324

Epoch: 5| Step: 7
Training loss: 0.6046239558304152
Validation loss: 2.6529120958541608

Epoch: 5| Step: 8
Training loss: 0.43203905108894974
Validation loss: 2.6672696919394996

Epoch: 5| Step: 9
Training loss: 0.6487567529345258
Validation loss: 2.6683341967996093

Epoch: 5| Step: 10
Training loss: 0.677293221636086
Validation loss: 2.6824439786362606

Epoch: 5| Step: 11
Training loss: 0.5917593311449221
Validation loss: 2.6316909438695113

Epoch: 537| Step: 0
Training loss: 0.5648947707226064
Validation loss: 2.5842049856050187

Epoch: 5| Step: 1
Training loss: 0.5837803615050556
Validation loss: 2.5450375097142395

Epoch: 5| Step: 2
Training loss: 0.8075210163464016
Validation loss: 2.54369453077581

Epoch: 5| Step: 3
Training loss: 0.7572131195331318
Validation loss: 2.59087407717401

Epoch: 5| Step: 4
Training loss: 0.8458029884069097
Validation loss: 2.545357031419971

Epoch: 5| Step: 5
Training loss: 1.1422021491785124
Validation loss: 2.6052904063224434

Epoch: 5| Step: 6
Training loss: 0.8861499592175426
Validation loss: 2.5792493468504367

Epoch: 5| Step: 7
Training loss: 0.5462195964967956
Validation loss: 2.6064208243820355

Epoch: 5| Step: 8
Training loss: 0.5408713358364204
Validation loss: 2.5878751703916483

Epoch: 5| Step: 9
Training loss: 0.8296736865141953
Validation loss: 2.708917596347359

Epoch: 5| Step: 10
Training loss: 0.6741485055199157
Validation loss: 2.6943551358161972

Epoch: 5| Step: 11
Training loss: 1.128513571478856
Validation loss: 2.7137079694360984

Epoch: 538| Step: 0
Training loss: 0.5880879929480333
Validation loss: 2.698184225937365

Epoch: 5| Step: 1
Training loss: 0.6102559983780298
Validation loss: 2.6589929816574354

Epoch: 5| Step: 2
Training loss: 0.6330848861142364
Validation loss: 2.6941124792418525

Epoch: 5| Step: 3
Training loss: 0.5907789231612444
Validation loss: 2.642926975258005

Epoch: 5| Step: 4
Training loss: 0.8298121127068582
Validation loss: 2.6724883262336494

Epoch: 5| Step: 5
Training loss: 0.729724484472306
Validation loss: 2.6462946524657096

Epoch: 5| Step: 6
Training loss: 0.9676537925754304
Validation loss: 2.6858116065659665

Epoch: 5| Step: 7
Training loss: 0.9113331663382246
Validation loss: 2.5785408243397443

Epoch: 5| Step: 8
Training loss: 0.9231294405345485
Validation loss: 2.6060302144663336

Epoch: 5| Step: 9
Training loss: 0.5789761849810997
Validation loss: 2.5786781719421854

Epoch: 5| Step: 10
Training loss: 1.016566910826492
Validation loss: 2.6745010339176654

Epoch: 5| Step: 11
Training loss: 0.5863424554810641
Validation loss: 2.6669463604538075

Epoch: 539| Step: 0
Training loss: 0.8558652821018798
Validation loss: 2.705388238898409

Epoch: 5| Step: 1
Training loss: 0.8594112388599479
Validation loss: 2.686992390326441

Epoch: 5| Step: 2
Training loss: 0.8899439834796847
Validation loss: 2.6684580494331076

Epoch: 5| Step: 3
Training loss: 0.6074204030893039
Validation loss: 2.5340753610999407

Epoch: 5| Step: 4
Training loss: 0.8511946347306857
Validation loss: 2.645691181979898

Epoch: 5| Step: 5
Training loss: 0.8210652122293054
Validation loss: 2.6407936576538384

Epoch: 5| Step: 6
Training loss: 0.8296509125826763
Validation loss: 2.669653595563929

Epoch: 5| Step: 7
Training loss: 1.134271668490968
Validation loss: 2.6698795771974897

Epoch: 5| Step: 8
Training loss: 0.9385302287148171
Validation loss: 2.685212089247283

Epoch: 5| Step: 9
Training loss: 0.6924201298867837
Validation loss: 2.697422116044692

Epoch: 5| Step: 10
Training loss: 0.9745592245833288
Validation loss: 2.7356761089300825

Epoch: 5| Step: 11
Training loss: 0.3548027758707998
Validation loss: 2.6902899565645617

Epoch: 540| Step: 0
Training loss: 0.6084207252106179
Validation loss: 2.751611721357466

Epoch: 5| Step: 1
Training loss: 0.9259435776952961
Validation loss: 2.7011914991510424

Epoch: 5| Step: 2
Training loss: 0.4973377340314256
Validation loss: 2.7285602796209574

Epoch: 5| Step: 3
Training loss: 0.744121961785113
Validation loss: 2.703474176599246

Epoch: 5| Step: 4
Training loss: 0.6841242012787361
Validation loss: 2.662253670946071

Epoch: 5| Step: 5
Training loss: 0.8648595062447078
Validation loss: 2.6902266022453722

Epoch: 5| Step: 6
Training loss: 0.6283176107825812
Validation loss: 2.705014408247129

Epoch: 5| Step: 7
Training loss: 0.785109599231619
Validation loss: 2.658798330519657

Epoch: 5| Step: 8
Training loss: 0.8456461052470584
Validation loss: 2.6041614087369607

Epoch: 5| Step: 9
Training loss: 0.9868999372234318
Validation loss: 2.5982528307406954

Epoch: 5| Step: 10
Training loss: 0.5267717155231403
Validation loss: 2.6185454114934257

Epoch: 5| Step: 11
Training loss: 0.392638206629023
Validation loss: 2.64160899351042

Epoch: 541| Step: 0
Training loss: 0.9206643641408773
Validation loss: 2.6727741171233115

Epoch: 5| Step: 1
Training loss: 1.2319893297067765
Validation loss: 2.632509197117606

Epoch: 5| Step: 2
Training loss: 0.5957696095871894
Validation loss: 2.6249263692550344

Epoch: 5| Step: 3
Training loss: 0.6978760939993833
Validation loss: 2.6046000170952706

Epoch: 5| Step: 4
Training loss: 0.4552212273221365
Validation loss: 2.614371797786305

Epoch: 5| Step: 5
Training loss: 0.7446011297329579
Validation loss: 2.579508724137014

Epoch: 5| Step: 6
Training loss: 0.8904665755864356
Validation loss: 2.5915229018212216

Epoch: 5| Step: 7
Training loss: 0.7238889336197668
Validation loss: 2.5734677065736604

Epoch: 5| Step: 8
Training loss: 0.6737226763052221
Validation loss: 2.622764831664902

Epoch: 5| Step: 9
Training loss: 0.6030918349402623
Validation loss: 2.585849084331827

Epoch: 5| Step: 10
Training loss: 0.6528354322277834
Validation loss: 2.5996356354229446

Epoch: 5| Step: 11
Training loss: 0.6318814292225954
Validation loss: 2.5766942649262283

Epoch: 542| Step: 0
Training loss: 0.8024089367023707
Validation loss: 2.5450027562265767

Epoch: 5| Step: 1
Training loss: 0.4555083112073582
Validation loss: 2.593886800781582

Epoch: 5| Step: 2
Training loss: 0.7289091382066557
Validation loss: 2.617836217998595

Epoch: 5| Step: 3
Training loss: 0.7179260921984975
Validation loss: 2.605411122841496

Epoch: 5| Step: 4
Training loss: 0.542949127281788
Validation loss: 2.6315887278450365

Epoch: 5| Step: 5
Training loss: 0.7556851208341528
Validation loss: 2.6421982519651768

Epoch: 5| Step: 6
Training loss: 0.8483421960628792
Validation loss: 2.6661509124375615

Epoch: 5| Step: 7
Training loss: 0.5623665492382466
Validation loss: 2.616383245835352

Epoch: 5| Step: 8
Training loss: 0.5087797489888032
Validation loss: 2.590677954573916

Epoch: 5| Step: 9
Training loss: 0.49008054713522237
Validation loss: 2.583179835917282

Epoch: 5| Step: 10
Training loss: 1.11812344273245
Validation loss: 2.605560636639696

Epoch: 5| Step: 11
Training loss: 0.40028707514358747
Validation loss: 2.598065053948582

Epoch: 543| Step: 0
Training loss: 0.9354641107253335
Validation loss: 2.57714553684439

Epoch: 5| Step: 1
Training loss: 0.44366533586613927
Validation loss: 2.6020308045388587

Epoch: 5| Step: 2
Training loss: 0.5230378290466772
Validation loss: 2.6094649522090254

Epoch: 5| Step: 3
Training loss: 0.7194326724640328
Validation loss: 2.5495651485191306

Epoch: 5| Step: 4
Training loss: 0.8960536345837342
Validation loss: 2.607353626743899

Epoch: 5| Step: 5
Training loss: 0.6878111741964413
Validation loss: 2.625097810345922

Epoch: 5| Step: 6
Training loss: 0.6272561835223295
Validation loss: 2.604926468951788

Epoch: 5| Step: 7
Training loss: 0.5499026277352035
Validation loss: 2.670943899192001

Epoch: 5| Step: 8
Training loss: 0.5743591759694666
Validation loss: 2.6456655589298395

Epoch: 5| Step: 9
Training loss: 0.47360490539763445
Validation loss: 2.6291423784142696

Epoch: 5| Step: 10
Training loss: 0.7443716736790463
Validation loss: 2.5991991819549596

Epoch: 5| Step: 11
Training loss: 0.7137818083214187
Validation loss: 2.6396149955321833

Epoch: 544| Step: 0
Training loss: 0.5071232740125088
Validation loss: 2.6491652270030475

Epoch: 5| Step: 1
Training loss: 0.4795610024975579
Validation loss: 2.6519352406829455

Epoch: 5| Step: 2
Training loss: 0.7435525487814412
Validation loss: 2.6206856915461776

Epoch: 5| Step: 3
Training loss: 0.44703883455649707
Validation loss: 2.6423123891691027

Epoch: 5| Step: 4
Training loss: 0.9718731098217998
Validation loss: 2.673992886609184

Epoch: 5| Step: 5
Training loss: 0.811542533714099
Validation loss: 2.6369611878259054

Epoch: 5| Step: 6
Training loss: 0.7351086786589431
Validation loss: 2.637642848709917

Epoch: 5| Step: 7
Training loss: 0.7168581569991127
Validation loss: 2.5736523836338425

Epoch: 5| Step: 8
Training loss: 0.4759874783259393
Validation loss: 2.5968575801027924

Epoch: 5| Step: 9
Training loss: 0.5422502058194985
Validation loss: 2.6583602264642394

Epoch: 5| Step: 10
Training loss: 0.6367249283754115
Validation loss: 2.585119554096466

Epoch: 5| Step: 11
Training loss: 0.8602384217915141
Validation loss: 2.5995249133835236

Epoch: 545| Step: 0
Training loss: 0.3390843467881633
Validation loss: 2.6148616381754124

Epoch: 5| Step: 1
Training loss: 0.6535302980808492
Validation loss: 2.6297366610076107

Epoch: 5| Step: 2
Training loss: 0.6396063870884042
Validation loss: 2.557103137792788

Epoch: 5| Step: 3
Training loss: 0.6904981220435281
Validation loss: 2.5977370820818138

Epoch: 5| Step: 4
Training loss: 0.8650616544459342
Validation loss: 2.5735835583050215

Epoch: 5| Step: 5
Training loss: 0.549825989766189
Validation loss: 2.5551670977508523

Epoch: 5| Step: 6
Training loss: 0.7546264292014848
Validation loss: 2.603750492537866

Epoch: 5| Step: 7
Training loss: 0.6634779657501213
Validation loss: 2.6226369765225654

Epoch: 5| Step: 8
Training loss: 0.6433243520221775
Validation loss: 2.6186898583461087

Epoch: 5| Step: 9
Training loss: 0.7387871194927986
Validation loss: 2.6581712300902454

Epoch: 5| Step: 10
Training loss: 0.6101638871617359
Validation loss: 2.652527845358177

Epoch: 5| Step: 11
Training loss: 0.3675937839784666
Validation loss: 2.634480952330311

Epoch: 546| Step: 0
Training loss: 0.5736891971109624
Validation loss: 2.669144207191678

Epoch: 5| Step: 1
Training loss: 0.6892856686314667
Validation loss: 2.645631366941062

Epoch: 5| Step: 2
Training loss: 0.5498486191321782
Validation loss: 2.6716575422525812

Epoch: 5| Step: 3
Training loss: 0.7936330183437941
Validation loss: 2.609880942750889

Epoch: 5| Step: 4
Training loss: 0.6199008353977079
Validation loss: 2.6456121605071083

Epoch: 5| Step: 5
Training loss: 0.672498679673838
Validation loss: 2.674654524321662

Epoch: 5| Step: 6
Training loss: 0.7333474782822214
Validation loss: 2.62142127047354

Epoch: 5| Step: 7
Training loss: 0.374336410533308
Validation loss: 2.6304206926083484

Epoch: 5| Step: 8
Training loss: 0.5667232810050455
Validation loss: 2.7260883432740166

Epoch: 5| Step: 9
Training loss: 0.8778729616706668
Validation loss: 2.64736473765183

Epoch: 5| Step: 10
Training loss: 0.5404267394078849
Validation loss: 2.642671446692538

Epoch: 5| Step: 11
Training loss: 0.4016346469590828
Validation loss: 2.6459076951057545

Epoch: 547| Step: 0
Training loss: 0.5244877655122449
Validation loss: 2.62959991191348

Epoch: 5| Step: 1
Training loss: 0.698040059317353
Validation loss: 2.6656846452325524

Epoch: 5| Step: 2
Training loss: 0.6160683927994325
Validation loss: 2.5894848367235177

Epoch: 5| Step: 3
Training loss: 0.836842626240343
Validation loss: 2.6073987524028874

Epoch: 5| Step: 4
Training loss: 0.429569748436437
Validation loss: 2.5537972332953585

Epoch: 5| Step: 5
Training loss: 0.5902175729254807
Validation loss: 2.556323485184825

Epoch: 5| Step: 6
Training loss: 0.5956639511485536
Validation loss: 2.6054643462228233

Epoch: 5| Step: 7
Training loss: 0.5933381459178483
Validation loss: 2.621922122833453

Epoch: 5| Step: 8
Training loss: 0.7017594746995452
Validation loss: 2.671680261159313

Epoch: 5| Step: 9
Training loss: 0.7109967301396805
Validation loss: 2.627716384674136

Epoch: 5| Step: 10
Training loss: 0.9776421339208763
Validation loss: 2.622490300002098

Epoch: 5| Step: 11
Training loss: 0.7790935891776959
Validation loss: 2.6296255932851818

Epoch: 548| Step: 0
Training loss: 0.5147187042041763
Validation loss: 2.6854633813074402

Epoch: 5| Step: 1
Training loss: 0.5487368361821067
Validation loss: 2.6744521318286973

Epoch: 5| Step: 2
Training loss: 0.6935154269124588
Validation loss: 2.708481327317159

Epoch: 5| Step: 3
Training loss: 0.74583498476865
Validation loss: 2.7051808141504083

Epoch: 5| Step: 4
Training loss: 1.2555805567181142
Validation loss: 2.67589231757137

Epoch: 5| Step: 5
Training loss: 0.7292918551925569
Validation loss: 2.6741814390360727

Epoch: 5| Step: 6
Training loss: 0.5716742105746223
Validation loss: 2.6303014543623258

Epoch: 5| Step: 7
Training loss: 0.6386404467208129
Validation loss: 2.65891118351214

Epoch: 5| Step: 8
Training loss: 0.6115190494249553
Validation loss: 2.5772635822175687

Epoch: 5| Step: 9
Training loss: 0.8189419878021739
Validation loss: 2.62922729224804

Epoch: 5| Step: 10
Training loss: 0.5420449171105424
Validation loss: 2.592486349472703

Epoch: 5| Step: 11
Training loss: 0.5651176790886717
Validation loss: 2.6976168747013243

Epoch: 549| Step: 0
Training loss: 0.645898536241476
Validation loss: 2.609310459625585

Epoch: 5| Step: 1
Training loss: 0.6061737877832424
Validation loss: 2.5892494213993342

Epoch: 5| Step: 2
Training loss: 0.8376200846083944
Validation loss: 2.668883934203885

Epoch: 5| Step: 3
Training loss: 0.6243400427241729
Validation loss: 2.615984618434346

Epoch: 5| Step: 4
Training loss: 0.6549185916309128
Validation loss: 2.5547742449764126

Epoch: 5| Step: 5
Training loss: 0.5375509215785491
Validation loss: 2.5595787249051742

Epoch: 5| Step: 6
Training loss: 0.8616109716639518
Validation loss: 2.5521208364624592

Epoch: 5| Step: 7
Training loss: 0.5641378294290824
Validation loss: 2.641997866421054

Epoch: 5| Step: 8
Training loss: 0.8520737609387774
Validation loss: 2.605744903433569

Epoch: 5| Step: 9
Training loss: 0.8069400924204874
Validation loss: 2.644990735539567

Epoch: 5| Step: 10
Training loss: 0.8235843621581773
Validation loss: 2.633562005854238

Epoch: 5| Step: 11
Training loss: 0.16994342996093598
Validation loss: 2.637692623426584

Epoch: 550| Step: 0
Training loss: 0.8200972865125487
Validation loss: 2.639655140143684

Epoch: 5| Step: 1
Training loss: 0.729354334704376
Validation loss: 2.6494597841042147

Epoch: 5| Step: 2
Training loss: 0.7208466012281227
Validation loss: 2.6288352718662544

Epoch: 5| Step: 3
Training loss: 0.5203670003488235
Validation loss: 2.5906854779677464

Epoch: 5| Step: 4
Training loss: 0.7331892545726393
Validation loss: 2.630297333876549

Epoch: 5| Step: 5
Training loss: 0.7960141337735765
Validation loss: 2.6379373065846194

Epoch: 5| Step: 6
Training loss: 0.7448380373589063
Validation loss: 2.6209563718175253

Epoch: 5| Step: 7
Training loss: 0.6788072476560955
Validation loss: 2.571298273004614

Epoch: 5| Step: 8
Training loss: 0.6144309717102572
Validation loss: 2.651072643726087

Epoch: 5| Step: 9
Training loss: 0.4336734732803033
Validation loss: 2.63968296665871

Epoch: 5| Step: 10
Training loss: 0.5060816685128725
Validation loss: 2.639584010715493

Epoch: 5| Step: 11
Training loss: 0.8256823304548474
Validation loss: 2.6984067690184883

Testing loss: 2.300006727003558
