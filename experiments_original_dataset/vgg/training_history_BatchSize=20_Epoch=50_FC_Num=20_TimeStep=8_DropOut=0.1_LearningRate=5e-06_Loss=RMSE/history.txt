Epoch: 1| Step: 0
Training loss: 4.781139297699743
Validation loss: 4.684553915979466

Epoch: 5| Step: 1
Training loss: 4.841107441334567
Validation loss: 4.679073507865469

Epoch: 5| Step: 2
Training loss: 4.735818271526869
Validation loss: 4.673765287018056

Epoch: 5| Step: 3
Training loss: 4.970675113501623
Validation loss: 4.667632772147222

Epoch: 5| Step: 4
Training loss: 4.003737848973839
Validation loss: 4.662435758044146

Epoch: 5| Step: 5
Training loss: 4.832218545847145
Validation loss: 4.653833923068125

Epoch: 5| Step: 6
Training loss: 5.089482866259328
Validation loss: 4.6467688720460005

Epoch: 5| Step: 7
Training loss: 5.143712562990283
Validation loss: 4.638736524700253

Epoch: 5| Step: 8
Training loss: 5.198920306575777
Validation loss: 4.629305364944166

Epoch: 5| Step: 9
Training loss: 4.632909043642562
Validation loss: 4.621956708941113

Epoch: 5| Step: 10
Training loss: 3.9707398720170004
Validation loss: 4.612585150355712

Epoch: 5| Step: 11
Training loss: 5.568297033586485
Validation loss: 4.603957989942095

Epoch: 2| Step: 0
Training loss: 5.387553968402653
Validation loss: 4.596676921229073

Epoch: 5| Step: 1
Training loss: 4.747913303795305
Validation loss: 4.586392650297091

Epoch: 5| Step: 2
Training loss: 4.852842398605494
Validation loss: 4.578221299479021

Epoch: 5| Step: 3
Training loss: 4.592710416289656
Validation loss: 4.568118650768017

Epoch: 5| Step: 4
Training loss: 4.1580710186271785
Validation loss: 4.558103219569611

Epoch: 5| Step: 5
Training loss: 5.331980633058739
Validation loss: 4.54914258451715

Epoch: 5| Step: 6
Training loss: 5.200872260075708
Validation loss: 4.538805728375167

Epoch: 5| Step: 7
Training loss: 4.6384837544090844
Validation loss: 4.5295132432772025

Epoch: 5| Step: 8
Training loss: 3.8655222997075223
Validation loss: 4.518999231622491

Epoch: 5| Step: 9
Training loss: 4.480971902600431
Validation loss: 4.50487523547228

Epoch: 5| Step: 10
Training loss: 3.5703832840528404
Validation loss: 4.495332982194858

Epoch: 5| Step: 11
Training loss: 5.687474512734788
Validation loss: 4.4852791205952185

Epoch: 3| Step: 0
Training loss: 4.653606509266853
Validation loss: 4.472535888296177

Epoch: 5| Step: 1
Training loss: 5.187819505526751
Validation loss: 4.460287234895975

Epoch: 5| Step: 2
Training loss: 4.289783966031358
Validation loss: 4.4487788535805635

Epoch: 5| Step: 3
Training loss: 4.779522153520288
Validation loss: 4.437976918986101

Epoch: 5| Step: 4
Training loss: 4.687000095413822
Validation loss: 4.418414600742046

Epoch: 5| Step: 5
Training loss: 5.135901231582563
Validation loss: 4.402557015859427

Epoch: 5| Step: 6
Training loss: 4.552189922466983
Validation loss: 4.388737572638173

Epoch: 5| Step: 7
Training loss: 4.203781587162725
Validation loss: 4.3712424854362695

Epoch: 5| Step: 8
Training loss: 4.290459966298731
Validation loss: 4.353913339366899

Epoch: 5| Step: 9
Training loss: 3.782517654165959
Validation loss: 4.336471923335224

Epoch: 5| Step: 10
Training loss: 4.161997098585343
Validation loss: 4.31851714979103

Epoch: 5| Step: 11
Training loss: 3.5856482694581278
Validation loss: 4.2960319385566725

Epoch: 4| Step: 0
Training loss: 5.119186826145958
Validation loss: 4.274503431983004

Epoch: 5| Step: 1
Training loss: 3.9463993803792854
Validation loss: 4.252453170808567

Epoch: 5| Step: 2
Training loss: 4.420930687458303
Validation loss: 4.230865835596317

Epoch: 5| Step: 3
Training loss: 3.935621994475389
Validation loss: 4.20427095468483

Epoch: 5| Step: 4
Training loss: 4.235860753955953
Validation loss: 4.181945642366761

Epoch: 5| Step: 5
Training loss: 2.9114035576778394
Validation loss: 4.148920245438325

Epoch: 5| Step: 6
Training loss: 4.566653516615894
Validation loss: 4.117991099390135

Epoch: 5| Step: 7
Training loss: 4.061894298295728
Validation loss: 4.085294795743381

Epoch: 5| Step: 8
Training loss: 4.809652501677189
Validation loss: 4.054002590067581

Epoch: 5| Step: 9
Training loss: 4.3934330224944285
Validation loss: 4.010352422356538

Epoch: 5| Step: 10
Training loss: 4.077931834356026
Validation loss: 3.9728496633212904

Epoch: 5| Step: 11
Training loss: 3.344402071394665
Validation loss: 3.932328981470908

Epoch: 5| Step: 0
Training loss: 4.347511254812088
Validation loss: 3.8930007187109132

Epoch: 5| Step: 1
Training loss: 3.3516915392099005
Validation loss: 3.844816638814104

Epoch: 5| Step: 2
Training loss: 3.921385107561383
Validation loss: 3.789588005618081

Epoch: 5| Step: 3
Training loss: 3.0473122307477847
Validation loss: 3.728395375170549

Epoch: 5| Step: 4
Training loss: 3.90521836963394
Validation loss: 3.676876887216645

Epoch: 5| Step: 5
Training loss: 3.779132470786184
Validation loss: 3.6298792109259046

Epoch: 5| Step: 6
Training loss: 3.723290756605981
Validation loss: 3.5331269398874072

Epoch: 5| Step: 7
Training loss: 3.0116221688267197
Validation loss: 3.4707913620980557

Epoch: 5| Step: 8
Training loss: 4.021177735015814
Validation loss: 3.413463100537693

Epoch: 5| Step: 9
Training loss: 3.5062956727125028
Validation loss: 3.318633189663052

Epoch: 5| Step: 10
Training loss: 3.629920907958556
Validation loss: 3.251050455329421

Epoch: 5| Step: 11
Training loss: 2.9196579625716783
Validation loss: 3.174071286007696

Epoch: 6| Step: 0
Training loss: 3.0085850900006825
Validation loss: 3.098886156710881

Epoch: 5| Step: 1
Training loss: 3.116139783199319
Validation loss: 3.028204138121593

Epoch: 5| Step: 2
Training loss: 2.9434390800837145
Validation loss: 2.938816495878918

Epoch: 5| Step: 3
Training loss: 2.2376130656226767
Validation loss: 2.877587515436158

Epoch: 5| Step: 4
Training loss: 3.3090880473998174
Validation loss: 2.8334504774130282

Epoch: 5| Step: 5
Training loss: 2.2574059143399903
Validation loss: 2.766410942256797

Epoch: 5| Step: 6
Training loss: 2.92883841862638
Validation loss: 2.710554519116983

Epoch: 5| Step: 7
Training loss: 2.2670504591028964
Validation loss: 2.7160254964142068

Epoch: 5| Step: 8
Training loss: 2.9166619618695777
Validation loss: 2.705139802121728

Epoch: 5| Step: 9
Training loss: 3.124664593816837
Validation loss: 2.6848031159655568

Epoch: 5| Step: 10
Training loss: 2.2938305666544045
Validation loss: 2.743324605540471

Epoch: 5| Step: 11
Training loss: 2.297721758611947
Validation loss: 2.775983471048701

Epoch: 7| Step: 0
Training loss: 2.019982883267541
Validation loss: 2.7663946786915177

Epoch: 5| Step: 1
Training loss: 3.488069910223761
Validation loss: 2.815974766397849

Epoch: 5| Step: 2
Training loss: 2.2714677910105054
Validation loss: 2.8459116366901966

Epoch: 5| Step: 3
Training loss: 2.7797873433511726
Validation loss: 2.878627071707134

Epoch: 5| Step: 4
Training loss: 2.8374332235267903
Validation loss: 2.9160250718750906

Epoch: 5| Step: 5
Training loss: 3.064054911836043
Validation loss: 2.9161548858046045

Epoch: 5| Step: 6
Training loss: 2.9189448224217553
Validation loss: 2.841879197858567

Epoch: 5| Step: 7
Training loss: 2.90249522495452
Validation loss: 2.816355358692174

Epoch: 5| Step: 8
Training loss: 2.3945800378008
Validation loss: 2.786448385393205

Epoch: 5| Step: 9
Training loss: 2.7598467448434874
Validation loss: 2.786555726437851

Epoch: 5| Step: 10
Training loss: 2.9514883844895707
Validation loss: 2.7413081672945983

Epoch: 5| Step: 11
Training loss: 1.4093545341274496
Validation loss: 2.7311673450838874

Epoch: 8| Step: 0
Training loss: 1.9957436928365697
Validation loss: 2.6791338853822944

Epoch: 5| Step: 1
Training loss: 2.453184479399342
Validation loss: 2.70175509202998

Epoch: 5| Step: 2
Training loss: 2.929493645930199
Validation loss: 2.679302343598483

Epoch: 5| Step: 3
Training loss: 2.8829711208795836
Validation loss: 2.6307128170645533

Epoch: 5| Step: 4
Training loss: 3.1105088510073116
Validation loss: 2.6762611701295103

Epoch: 5| Step: 5
Training loss: 2.715298270180446
Validation loss: 2.639434888610273

Epoch: 5| Step: 6
Training loss: 2.19785625742356
Validation loss: 2.6573949403232846

Epoch: 5| Step: 7
Training loss: 3.233976035459262
Validation loss: 2.6796614754083166

Epoch: 5| Step: 8
Training loss: 2.1393548023140823
Validation loss: 2.669836616410585

Epoch: 5| Step: 9
Training loss: 2.291867669278195
Validation loss: 2.678478594790987

Epoch: 5| Step: 10
Training loss: 2.8590189394195122
Validation loss: 2.6646192459259295

Epoch: 5| Step: 11
Training loss: 1.6213352253321434
Validation loss: 2.6838543916644557

Epoch: 9| Step: 0
Training loss: 2.540493887395624
Validation loss: 2.661555780516721

Epoch: 5| Step: 1
Training loss: 2.4795297842942707
Validation loss: 2.6764833109391337

Epoch: 5| Step: 2
Training loss: 2.2577527312185244
Validation loss: 2.683036724178341

Epoch: 5| Step: 3
Training loss: 2.3242524986060813
Validation loss: 2.686976585133074

Epoch: 5| Step: 4
Training loss: 2.4043327719319625
Validation loss: 2.651357262243307

Epoch: 5| Step: 5
Training loss: 3.0512915268775336
Validation loss: 2.6380766096680035

Epoch: 5| Step: 6
Training loss: 3.1295336071769078
Validation loss: 2.6913295120350407

Epoch: 5| Step: 7
Training loss: 2.2522502878455453
Validation loss: 2.6687463173703136

Epoch: 5| Step: 8
Training loss: 3.124619422626519
Validation loss: 2.6737434665456843

Epoch: 5| Step: 9
Training loss: 2.7197086792500027
Validation loss: 2.643048568093151

Epoch: 5| Step: 10
Training loss: 2.6126240130472325
Validation loss: 2.637924299265725

Epoch: 5| Step: 11
Training loss: 2.788086878146733
Validation loss: 2.6790693254026796

Epoch: 10| Step: 0
Training loss: 3.251386786739976
Validation loss: 2.6311517376949696

Epoch: 5| Step: 1
Training loss: 2.870398280191491
Validation loss: 2.646900490567126

Epoch: 5| Step: 2
Training loss: 2.4863077958467805
Validation loss: 2.659133908870876

Epoch: 5| Step: 3
Training loss: 2.6372017425105505
Validation loss: 2.667305453850148

Epoch: 5| Step: 4
Training loss: 2.3590934534906087
Validation loss: 2.6716332725949283

Epoch: 5| Step: 5
Training loss: 2.68303904568316
Validation loss: 2.671954375011938

Epoch: 5| Step: 6
Training loss: 2.484647340062565
Validation loss: 2.6811814346824057

Epoch: 5| Step: 7
Training loss: 2.188805109067721
Validation loss: 2.65760286697892

Epoch: 5| Step: 8
Training loss: 2.000125285039233
Validation loss: 2.651023183931825

Epoch: 5| Step: 9
Training loss: 2.9153665278798693
Validation loss: 2.6760310146960733

Epoch: 5| Step: 10
Training loss: 3.0568566779174673
Validation loss: 2.6625383963823577

Epoch: 5| Step: 11
Training loss: 2.185289192179056
Validation loss: 2.677339780277856

Epoch: 11| Step: 0
Training loss: 2.3773148950185172
Validation loss: 2.6364974656674325

Epoch: 5| Step: 1
Training loss: 2.422515390699566
Validation loss: 2.66856416729763

Epoch: 5| Step: 2
Training loss: 2.096448383622958
Validation loss: 2.6664838219085163

Epoch: 5| Step: 3
Training loss: 2.3180420938838306
Validation loss: 2.6189314350711923

Epoch: 5| Step: 4
Training loss: 3.231955392605232
Validation loss: 2.626751935739888

Epoch: 5| Step: 5
Training loss: 2.303516568938462
Validation loss: 2.638416755140187

Epoch: 5| Step: 6
Training loss: 2.897282701956043
Validation loss: 2.6323650481715246

Epoch: 5| Step: 7
Training loss: 2.557106109744791
Validation loss: 2.630760162680446

Epoch: 5| Step: 8
Training loss: 2.8446995753204107
Validation loss: 2.649562844170562

Epoch: 5| Step: 9
Training loss: 2.257692644046503
Validation loss: 2.6296462953557525

Epoch: 5| Step: 10
Training loss: 3.1203007269471503
Validation loss: 2.649090066670132

Epoch: 5| Step: 11
Training loss: 2.367124852525495
Validation loss: 2.650808909952361

Epoch: 12| Step: 0
Training loss: 2.1639362394772514
Validation loss: 2.605942228915054

Epoch: 5| Step: 1
Training loss: 2.7417202195461274
Validation loss: 2.64151262943335

Epoch: 5| Step: 2
Training loss: 2.5751721667167073
Validation loss: 2.669220853508203

Epoch: 5| Step: 3
Training loss: 2.433072005134996
Validation loss: 2.6329101370828947

Epoch: 5| Step: 4
Training loss: 2.919414933000342
Validation loss: 2.658831434062406

Epoch: 5| Step: 5
Training loss: 2.898747265655294
Validation loss: 2.6556131833721017

Epoch: 5| Step: 6
Training loss: 1.9691376682857873
Validation loss: 2.6588821422115188

Epoch: 5| Step: 7
Training loss: 3.1004607504255235
Validation loss: 2.627968948394189

Epoch: 5| Step: 8
Training loss: 2.0839296886129626
Validation loss: 2.6517869704841255

Epoch: 5| Step: 9
Training loss: 2.2359757458116927
Validation loss: 2.6298557359897763

Epoch: 5| Step: 10
Training loss: 3.1624415637260292
Validation loss: 2.6451776710874872

Epoch: 5| Step: 11
Training loss: 3.0332424261982207
Validation loss: 2.632444459752521

Epoch: 13| Step: 0
Training loss: 2.709198847657492
Validation loss: 2.655001444118751

Epoch: 5| Step: 1
Training loss: 2.7208785570795855
Validation loss: 2.6211023647964584

Epoch: 5| Step: 2
Training loss: 2.461645212288741
Validation loss: 2.6088663583872855

Epoch: 5| Step: 3
Training loss: 2.7579803847956352
Validation loss: 2.6395141213628177

Epoch: 5| Step: 4
Training loss: 2.7333914595525437
Validation loss: 2.608719421692494

Epoch: 5| Step: 5
Training loss: 2.4323862671409087
Validation loss: 2.6312944391866875

Epoch: 5| Step: 6
Training loss: 2.0734691810056107
Validation loss: 2.62972600436113

Epoch: 5| Step: 7
Training loss: 2.238542205351322
Validation loss: 2.6132441633526615

Epoch: 5| Step: 8
Training loss: 2.022583888215612
Validation loss: 2.5851923280920834

Epoch: 5| Step: 9
Training loss: 2.4373684383002536
Validation loss: 2.601870511888269

Epoch: 5| Step: 10
Training loss: 3.476824461250609
Validation loss: 2.597676235494959

Epoch: 5| Step: 11
Training loss: 3.8442614455453654
Validation loss: 2.64423774807238

Epoch: 14| Step: 0
Training loss: 3.091696317655644
Validation loss: 2.6146918017214964

Epoch: 5| Step: 1
Training loss: 3.0485359555314364
Validation loss: 2.626154365728951

Epoch: 5| Step: 2
Training loss: 2.391300081166317
Validation loss: 2.617627235023634

Epoch: 5| Step: 3
Training loss: 2.322137801852999
Validation loss: 2.6098155032460197

Epoch: 5| Step: 4
Training loss: 2.8455970550646277
Validation loss: 2.6187297016046007

Epoch: 5| Step: 5
Training loss: 2.4371882508285663
Validation loss: 2.648249020241659

Epoch: 5| Step: 6
Training loss: 1.842186604403342
Validation loss: 2.640984031150867

Epoch: 5| Step: 7
Training loss: 2.6680321078506024
Validation loss: 2.60787024292159

Epoch: 5| Step: 8
Training loss: 2.5582697306460846
Validation loss: 2.608043346088207

Epoch: 5| Step: 9
Training loss: 2.524374584132796
Validation loss: 2.588702856273428

Epoch: 5| Step: 10
Training loss: 2.5851117339787346
Validation loss: 2.6468031650179737

Epoch: 5| Step: 11
Training loss: 1.324361742789509
Validation loss: 2.614001058558333

Epoch: 15| Step: 0
Training loss: 2.5044662634888124
Validation loss: 2.5851498083144078

Epoch: 5| Step: 1
Training loss: 2.9283279723145665
Validation loss: 2.613298078709935

Epoch: 5| Step: 2
Training loss: 2.3486969683285337
Validation loss: 2.5996549675409164

Epoch: 5| Step: 3
Training loss: 2.3599240504182917
Validation loss: 2.575951154892414

Epoch: 5| Step: 4
Training loss: 2.8516885807957397
Validation loss: 2.6013436287425775

Epoch: 5| Step: 5
Training loss: 2.434842348106307
Validation loss: 2.6509429386144134

Epoch: 5| Step: 6
Training loss: 2.067013281806754
Validation loss: 2.6190225174891

Epoch: 5| Step: 7
Training loss: 3.0833273363484666
Validation loss: 2.5906949377800528

Epoch: 5| Step: 8
Training loss: 2.7913366283977052
Validation loss: 2.6083833786141613

Epoch: 5| Step: 9
Training loss: 2.684834422541704
Validation loss: 2.6175806822482275

Epoch: 5| Step: 10
Training loss: 2.2868152823500196
Validation loss: 2.6032836001754407

Epoch: 5| Step: 11
Training loss: 2.178761275191686
Validation loss: 2.6044655984332548

Epoch: 16| Step: 0
Training loss: 2.70350388534151
Validation loss: 2.602108463739173

Epoch: 5| Step: 1
Training loss: 2.801287361927412
Validation loss: 2.619739131261699

Epoch: 5| Step: 2
Training loss: 2.5799103075154024
Validation loss: 2.6201710372587304

Epoch: 5| Step: 3
Training loss: 1.8775979164079468
Validation loss: 2.583043348792649

Epoch: 5| Step: 4
Training loss: 2.547655418978418
Validation loss: 2.6343825966516956

Epoch: 5| Step: 5
Training loss: 2.7122359890058596
Validation loss: 2.605833006202995

Epoch: 5| Step: 6
Training loss: 2.3423055648312214
Validation loss: 2.626604929257369

Epoch: 5| Step: 7
Training loss: 2.3069121405278943
Validation loss: 2.6253194917285207

Epoch: 5| Step: 8
Training loss: 2.5031593387072415
Validation loss: 2.5982356675319576

Epoch: 5| Step: 9
Training loss: 2.291266412171533
Validation loss: 2.6227934206689776

Epoch: 5| Step: 10
Training loss: 3.131021572773392
Validation loss: 2.61057083535195

Epoch: 5| Step: 11
Training loss: 4.056503330307868
Validation loss: 2.581262232556734

Epoch: 17| Step: 0
Training loss: 2.273383700333952
Validation loss: 2.613079867280011

Epoch: 5| Step: 1
Training loss: 1.94005029249383
Validation loss: 2.590535051957006

Epoch: 5| Step: 2
Training loss: 2.5241382676956903
Validation loss: 2.5929693403068073

Epoch: 5| Step: 3
Training loss: 2.459877294410912
Validation loss: 2.589691403119317

Epoch: 5| Step: 4
Training loss: 1.5209289242040434
Validation loss: 2.610318213298678

Epoch: 5| Step: 5
Training loss: 2.8606127785406397
Validation loss: 2.633944606655224

Epoch: 5| Step: 6
Training loss: 2.784767070186099
Validation loss: 2.6305372592731056

Epoch: 5| Step: 7
Training loss: 2.7948517540666575
Validation loss: 2.6258878682267444

Epoch: 5| Step: 8
Training loss: 2.7289487348908468
Validation loss: 2.6211876925799134

Epoch: 5| Step: 9
Training loss: 3.066192891661735
Validation loss: 2.600009286539904

Epoch: 5| Step: 10
Training loss: 2.682428765111018
Validation loss: 2.6123975961865997

Epoch: 5| Step: 11
Training loss: 2.8791248750942913
Validation loss: 2.605055021716577

Epoch: 18| Step: 0
Training loss: 1.912985487009962
Validation loss: 2.6103782856994875

Epoch: 5| Step: 1
Training loss: 2.432267465954339
Validation loss: 2.5867863670735476

Epoch: 5| Step: 2
Training loss: 2.6312510220849594
Validation loss: 2.5997414348791477

Epoch: 5| Step: 3
Training loss: 2.440133066457451
Validation loss: 2.582683586631215

Epoch: 5| Step: 4
Training loss: 2.8616850646606378
Validation loss: 2.590083817392405

Epoch: 5| Step: 5
Training loss: 2.423869241001491
Validation loss: 2.562315639593891

Epoch: 5| Step: 6
Training loss: 2.61001231925074
Validation loss: 2.5780123599328046

Epoch: 5| Step: 7
Training loss: 3.011081098647028
Validation loss: 2.5970879757763834

Epoch: 5| Step: 8
Training loss: 2.229456041989629
Validation loss: 2.569673105037414

Epoch: 5| Step: 9
Training loss: 2.777487449308618
Validation loss: 2.580722486767687

Epoch: 5| Step: 10
Training loss: 2.2957069385257376
Validation loss: 2.581082757053166

Epoch: 5| Step: 11
Training loss: 2.671497429833808
Validation loss: 2.5781365365434947

Epoch: 19| Step: 0
Training loss: 2.5755085933588595
Validation loss: 2.5879437096867255

Epoch: 5| Step: 1
Training loss: 2.3074728476269013
Validation loss: 2.6207706310997363

Epoch: 5| Step: 2
Training loss: 2.4703037828826075
Validation loss: 2.590750810170454

Epoch: 5| Step: 3
Training loss: 2.7685597683760697
Validation loss: 2.579908420738788

Epoch: 5| Step: 4
Training loss: 2.7726986182902484
Validation loss: 2.568728665296529

Epoch: 5| Step: 5
Training loss: 2.6816593844652923
Validation loss: 2.5788676723864077

Epoch: 5| Step: 6
Training loss: 2.2287118275401343
Validation loss: 2.549893067336854

Epoch: 5| Step: 7
Training loss: 3.0354308565044175
Validation loss: 2.56461883962447

Epoch: 5| Step: 8
Training loss: 2.1041716647954316
Validation loss: 2.5803067060118092

Epoch: 5| Step: 9
Training loss: 2.598909325351018
Validation loss: 2.566387159023956

Epoch: 5| Step: 10
Training loss: 2.347508176681692
Validation loss: 2.5859372963958074

Epoch: 5| Step: 11
Training loss: 1.7591364642932348
Validation loss: 2.5592298886526637

Epoch: 20| Step: 0
Training loss: 3.311993686200081
Validation loss: 2.562038620451979

Epoch: 5| Step: 1
Training loss: 2.466648414475554
Validation loss: 2.5914018565199997

Epoch: 5| Step: 2
Training loss: 2.7338596403290385
Validation loss: 2.597298221246852

Epoch: 5| Step: 3
Training loss: 2.2356149927373345
Validation loss: 2.581601969496441

Epoch: 5| Step: 4
Training loss: 2.4298169264098726
Validation loss: 2.5822655114165873

Epoch: 5| Step: 5
Training loss: 2.646794082143347
Validation loss: 2.5826186619504155

Epoch: 5| Step: 6
Training loss: 2.316552606240149
Validation loss: 2.589147924020402

Epoch: 5| Step: 7
Training loss: 1.9531528318329496
Validation loss: 2.5664403052855085

Epoch: 5| Step: 8
Training loss: 2.4259096071742197
Validation loss: 2.5734759172120967

Epoch: 5| Step: 9
Training loss: 2.3749310332875595
Validation loss: 2.5804977114318097

Epoch: 5| Step: 10
Training loss: 2.7927067560411776
Validation loss: 2.5719624106260586

Epoch: 5| Step: 11
Training loss: 2.1086218725691555
Validation loss: 2.604659607327352

Epoch: 21| Step: 0
Training loss: 2.687905391901469
Validation loss: 2.5887946146613077

Epoch: 5| Step: 1
Training loss: 2.224531994579909
Validation loss: 2.571537580021306

Epoch: 5| Step: 2
Training loss: 2.225831564337588
Validation loss: 2.586860211681791

Epoch: 5| Step: 3
Training loss: 2.5788508462718225
Validation loss: 2.5693957192437633

Epoch: 5| Step: 4
Training loss: 1.9380059350772203
Validation loss: 2.5665812285144938

Epoch: 5| Step: 5
Training loss: 2.28591170905916
Validation loss: 2.5951438934781055

Epoch: 5| Step: 6
Training loss: 2.2836909364475946
Validation loss: 2.5702195658014073

Epoch: 5| Step: 7
Training loss: 2.9820112683948703
Validation loss: 2.5657079938009493

Epoch: 5| Step: 8
Training loss: 3.3082005651114788
Validation loss: 2.5736318796258484

Epoch: 5| Step: 9
Training loss: 2.6960941673948353
Validation loss: 2.58211492190312

Epoch: 5| Step: 10
Training loss: 2.436314123179813
Validation loss: 2.560276602092161

Epoch: 5| Step: 11
Training loss: 1.495718009916508
Validation loss: 2.5689801567036894

Epoch: 22| Step: 0
Training loss: 1.9302719404922482
Validation loss: 2.571072246809719

Epoch: 5| Step: 1
Training loss: 2.7741363074842664
Validation loss: 2.5750239516196736

Epoch: 5| Step: 2
Training loss: 2.52228153549264
Validation loss: 2.5493323985564276

Epoch: 5| Step: 3
Training loss: 2.2410300852957517
Validation loss: 2.559273778414354

Epoch: 5| Step: 4
Training loss: 2.690231975068581
Validation loss: 2.5622278782330046

Epoch: 5| Step: 5
Training loss: 2.5917961390824127
Validation loss: 2.557183301588821

Epoch: 5| Step: 6
Training loss: 2.1462113377727454
Validation loss: 2.578667943792001

Epoch: 5| Step: 7
Training loss: 2.288395598977466
Validation loss: 2.567661313341524

Epoch: 5| Step: 8
Training loss: 3.1763907923264374
Validation loss: 2.566119932386314

Epoch: 5| Step: 9
Training loss: 2.507586792863345
Validation loss: 2.5478264449316685

Epoch: 5| Step: 10
Training loss: 2.621761867915014
Validation loss: 2.568488075503179

Epoch: 5| Step: 11
Training loss: 2.237465488444727
Validation loss: 2.562190316258379

Epoch: 23| Step: 0
Training loss: 2.563529389336638
Validation loss: 2.5778961735139956

Epoch: 5| Step: 1
Training loss: 2.607323393944282
Validation loss: 2.56826731392333

Epoch: 5| Step: 2
Training loss: 2.041901698175852
Validation loss: 2.5428142158834115

Epoch: 5| Step: 3
Training loss: 2.101841904455924
Validation loss: 2.553937632781297

Epoch: 5| Step: 4
Training loss: 2.855504485818622
Validation loss: 2.5451306296251133

Epoch: 5| Step: 5
Training loss: 2.847221686717244
Validation loss: 2.564252327899509

Epoch: 5| Step: 6
Training loss: 1.8078152853532994
Validation loss: 2.550465368055068

Epoch: 5| Step: 7
Training loss: 2.2199104390679616
Validation loss: 2.5483074645439876

Epoch: 5| Step: 8
Training loss: 2.8198474278671486
Validation loss: 2.5782860214349226

Epoch: 5| Step: 9
Training loss: 2.7280603355268562
Validation loss: 2.5303201105506585

Epoch: 5| Step: 10
Training loss: 2.4305581253280377
Validation loss: 2.556360142424944

Epoch: 5| Step: 11
Training loss: 4.116451074512187
Validation loss: 2.5176057264079135

Epoch: 24| Step: 0
Training loss: 1.8224107821464586
Validation loss: 2.5310421257846523

Epoch: 5| Step: 1
Training loss: 2.256677362011912
Validation loss: 2.560124552311962

Epoch: 5| Step: 2
Training loss: 2.6825873252114745
Validation loss: 2.548284249967167

Epoch: 5| Step: 3
Training loss: 2.8854268942604633
Validation loss: 2.5564541167054835

Epoch: 5| Step: 4
Training loss: 2.777466246831601
Validation loss: 2.553284620558234

Epoch: 5| Step: 5
Training loss: 2.32459016284622
Validation loss: 2.539931824368687

Epoch: 5| Step: 6
Training loss: 2.310681942936404
Validation loss: 2.5682767634770243

Epoch: 5| Step: 7
Training loss: 2.3421969545261354
Validation loss: 2.546888060819061

Epoch: 5| Step: 8
Training loss: 2.8629158484229618
Validation loss: 2.5388551989318113

Epoch: 5| Step: 9
Training loss: 2.0474095702084507
Validation loss: 2.5386682370553983

Epoch: 5| Step: 10
Training loss: 3.1635773463409644
Validation loss: 2.546469162666692

Epoch: 5| Step: 11
Training loss: 1.5733722086053012
Validation loss: 2.544037964757258

Epoch: 25| Step: 0
Training loss: 1.7411322027645293
Validation loss: 2.5254781992539095

Epoch: 5| Step: 1
Training loss: 2.5634319192541235
Validation loss: 2.5404587491465422

Epoch: 5| Step: 2
Training loss: 2.730900153269109
Validation loss: 2.5441201919320053

Epoch: 5| Step: 3
Training loss: 2.5686234603120557
Validation loss: 2.5291442393000363

Epoch: 5| Step: 4
Training loss: 2.8397984140337553
Validation loss: 2.5341461355821715

Epoch: 5| Step: 5
Training loss: 1.7614551017035271
Validation loss: 2.578629544527131

Epoch: 5| Step: 6
Training loss: 2.2769050502757446
Validation loss: 2.539479660586383

Epoch: 5| Step: 7
Training loss: 2.360632857960294
Validation loss: 2.575017254348772

Epoch: 5| Step: 8
Training loss: 2.3988922383894256
Validation loss: 2.583335373990473

Epoch: 5| Step: 9
Training loss: 3.1415027511562776
Validation loss: 2.5948213524781236

Epoch: 5| Step: 10
Training loss: 2.42614468172502
Validation loss: 2.5882023538420236

Epoch: 5| Step: 11
Training loss: 3.323097981416106
Validation loss: 2.5670287849584246

Epoch: 26| Step: 0
Training loss: 2.2575180759318805
Validation loss: 2.553880935563713

Epoch: 5| Step: 1
Training loss: 2.51145779453959
Validation loss: 2.5811670139141154

Epoch: 5| Step: 2
Training loss: 2.3083237749950762
Validation loss: 2.5851755085582564

Epoch: 5| Step: 3
Training loss: 2.5268418345797627
Validation loss: 2.545111094125407

Epoch: 5| Step: 4
Training loss: 2.5107589002992956
Validation loss: 2.544379230377996

Epoch: 5| Step: 5
Training loss: 3.1714026188617
Validation loss: 2.541826611838286

Epoch: 5| Step: 6
Training loss: 2.2114475052925293
Validation loss: 2.5242244450024676

Epoch: 5| Step: 7
Training loss: 2.7971561226668693
Validation loss: 2.5484037706180573

Epoch: 5| Step: 8
Training loss: 2.2943897945349994
Validation loss: 2.5283949767171108

Epoch: 5| Step: 9
Training loss: 2.3171370127162234
Validation loss: 2.530035626351587

Epoch: 5| Step: 10
Training loss: 2.073301065608848
Validation loss: 2.54866202289432

Epoch: 5| Step: 11
Training loss: 3.087793955535379
Validation loss: 2.535445680245925

Epoch: 27| Step: 0
Training loss: 2.8287430398798943
Validation loss: 2.5366988071338743

Epoch: 5| Step: 1
Training loss: 2.258421607831878
Validation loss: 2.5442598857403333

Epoch: 5| Step: 2
Training loss: 2.5598349319824907
Validation loss: 2.5115528239750877

Epoch: 5| Step: 3
Training loss: 2.171804193673536
Validation loss: 2.5489502235681636

Epoch: 5| Step: 4
Training loss: 2.1534438740059265
Validation loss: 2.5208675221943726

Epoch: 5| Step: 5
Training loss: 2.4161734132425403
Validation loss: 2.550114858602386

Epoch: 5| Step: 6
Training loss: 2.316750409193035
Validation loss: 2.5449037275548023

Epoch: 5| Step: 7
Training loss: 2.480770351066177
Validation loss: 2.5274130994980015

Epoch: 5| Step: 8
Training loss: 2.5581119462273643
Validation loss: 2.541735790177821

Epoch: 5| Step: 9
Training loss: 3.0771179100854034
Validation loss: 2.512752314372084

Epoch: 5| Step: 10
Training loss: 2.44766268663872
Validation loss: 2.5455862267708027

Epoch: 5| Step: 11
Training loss: 1.3225526934764413
Validation loss: 2.5435791806501418

Epoch: 28| Step: 0
Training loss: 2.0628103542909066
Validation loss: 2.5304638501290926

Epoch: 5| Step: 1
Training loss: 2.376797447654666
Validation loss: 2.5573878972632174

Epoch: 5| Step: 2
Training loss: 2.898484386465869
Validation loss: 2.5254627285346083

Epoch: 5| Step: 3
Training loss: 2.231160125204594
Validation loss: 2.5691208478133425

Epoch: 5| Step: 4
Training loss: 2.5707960050851884
Validation loss: 2.5298220291793223

Epoch: 5| Step: 5
Training loss: 2.4879878423583874
Validation loss: 2.5449493281810316

Epoch: 5| Step: 6
Training loss: 2.7186026697688317
Validation loss: 2.546267177546942

Epoch: 5| Step: 7
Training loss: 2.551787243748902
Validation loss: 2.519908476591722

Epoch: 5| Step: 8
Training loss: 2.433135796284626
Validation loss: 2.532714471129971

Epoch: 5| Step: 9
Training loss: 2.4947070357608934
Validation loss: 2.521258370898271

Epoch: 5| Step: 10
Training loss: 2.325523202744687
Validation loss: 2.5246284320058328

Epoch: 5| Step: 11
Training loss: 1.8992821341152775
Validation loss: 2.526103421403496

Epoch: 29| Step: 0
Training loss: 2.002867193190999
Validation loss: 2.5421054818260256

Epoch: 5| Step: 1
Training loss: 2.1495634700387085
Validation loss: 2.525994551438813

Epoch: 5| Step: 2
Training loss: 2.2350923680413652
Validation loss: 2.558163202377821

Epoch: 5| Step: 3
Training loss: 2.8116621676870492
Validation loss: 2.5663991663819075

Epoch: 5| Step: 4
Training loss: 2.4115253436429454
Validation loss: 2.538189926845034

Epoch: 5| Step: 5
Training loss: 2.186697458461346
Validation loss: 2.5662503904010063

Epoch: 5| Step: 6
Training loss: 2.8787820237996065
Validation loss: 2.5498408384766416

Epoch: 5| Step: 7
Training loss: 2.894188246693674
Validation loss: 2.544563998248887

Epoch: 5| Step: 8
Training loss: 1.8517769476082258
Validation loss: 2.5634314193383747

Epoch: 5| Step: 9
Training loss: 2.9056208760213194
Validation loss: 2.559329494464579

Epoch: 5| Step: 10
Training loss: 2.709190135311662
Validation loss: 2.54719468121169

Epoch: 5| Step: 11
Training loss: 2.4239739951259027
Validation loss: 2.5639659402360993

Epoch: 30| Step: 0
Training loss: 2.0775243134803034
Validation loss: 2.52479820452281

Epoch: 5| Step: 1
Training loss: 1.9789609567916846
Validation loss: 2.5472975557834867

Epoch: 5| Step: 2
Training loss: 1.928270197862098
Validation loss: 2.496264945832172

Epoch: 5| Step: 3
Training loss: 2.8649890589213873
Validation loss: 2.5172140816615585

Epoch: 5| Step: 4
Training loss: 1.9280854034067578
Validation loss: 2.5347341177209803

Epoch: 5| Step: 5
Training loss: 2.857218278161908
Validation loss: 2.538166345758819

Epoch: 5| Step: 6
Training loss: 3.124984435996398
Validation loss: 2.518830034721372

Epoch: 5| Step: 7
Training loss: 2.5263719061006378
Validation loss: 2.5171867285359655

Epoch: 5| Step: 8
Training loss: 2.33017164555878
Validation loss: 2.51548980365396

Epoch: 5| Step: 9
Training loss: 2.794838446245649
Validation loss: 2.5128024241882687

Epoch: 5| Step: 10
Training loss: 2.011983494791393
Validation loss: 2.5067696566922084

Epoch: 5| Step: 11
Training loss: 2.935309871971719
Validation loss: 2.5100117207756303

Epoch: 31| Step: 0
Training loss: 2.4161074967058953
Validation loss: 2.5104555203503187

Epoch: 5| Step: 1
Training loss: 1.943132151446061
Validation loss: 2.5362407008702976

Epoch: 5| Step: 2
Training loss: 2.1520756660120504
Validation loss: 2.5274602007287177

Epoch: 5| Step: 3
Training loss: 3.178944043872088
Validation loss: 2.4954850076894988

Epoch: 5| Step: 4
Training loss: 2.756585039808414
Validation loss: 2.5187860140817007

Epoch: 5| Step: 5
Training loss: 2.646551400212141
Validation loss: 2.5636895527836363

Epoch: 5| Step: 6
Training loss: 2.0941136741789594
Validation loss: 2.55242341299356

Epoch: 5| Step: 7
Training loss: 2.8000184194776403
Validation loss: 2.535965961132843

Epoch: 5| Step: 8
Training loss: 2.711028435580828
Validation loss: 2.5110271721910054

Epoch: 5| Step: 9
Training loss: 2.3809792392214932
Validation loss: 2.5343591723279064

Epoch: 5| Step: 10
Training loss: 1.7412183999989062
Validation loss: 2.5073260531717465

Epoch: 5| Step: 11
Training loss: 3.0830599345748477
Validation loss: 2.540241269094408

Epoch: 32| Step: 0
Training loss: 2.453844390157448
Validation loss: 2.542080530230628

Epoch: 5| Step: 1
Training loss: 2.6592017434473667
Validation loss: 2.5517237598099904

Epoch: 5| Step: 2
Training loss: 2.7223131354930907
Validation loss: 2.5381578173751045

Epoch: 5| Step: 3
Training loss: 2.3073258121165456
Validation loss: 2.517314501509938

Epoch: 5| Step: 4
Training loss: 2.2826836666487242
Validation loss: 2.520173606506114

Epoch: 5| Step: 5
Training loss: 2.138878659916098
Validation loss: 2.5139640395263934

Epoch: 5| Step: 6
Training loss: 2.6265431364254543
Validation loss: 2.5036214427475465

Epoch: 5| Step: 7
Training loss: 2.543541534654621
Validation loss: 2.525611385915128

Epoch: 5| Step: 8
Training loss: 2.5321037830579276
Validation loss: 2.5317003061505243

Epoch: 5| Step: 9
Training loss: 2.2654288371436673
Validation loss: 2.5149623953862634

Epoch: 5| Step: 10
Training loss: 2.5105192129208698
Validation loss: 2.5431052277287707

Epoch: 5| Step: 11
Training loss: 1.9097428137699834
Validation loss: 2.534322259576047

Epoch: 33| Step: 0
Training loss: 2.9859241239766137
Validation loss: 2.4977387095785986

Epoch: 5| Step: 1
Training loss: 1.904176866711343
Validation loss: 2.513259523879054

Epoch: 5| Step: 2
Training loss: 2.799399999637635
Validation loss: 2.5269122789664777

Epoch: 5| Step: 3
Training loss: 2.641711400933867
Validation loss: 2.545084040821163

Epoch: 5| Step: 4
Training loss: 2.251631145503004
Validation loss: 2.5349210758388043

Epoch: 5| Step: 5
Training loss: 2.265497559218817
Validation loss: 2.513574562273798

Epoch: 5| Step: 6
Training loss: 2.597653037621369
Validation loss: 2.508989372883926

Epoch: 5| Step: 7
Training loss: 2.123484688319438
Validation loss: 2.529251648094729

Epoch: 5| Step: 8
Training loss: 2.6543692718580583
Validation loss: 2.546761367852866

Epoch: 5| Step: 9
Training loss: 2.517440614577592
Validation loss: 2.5073220534966865

Epoch: 5| Step: 10
Training loss: 1.9131465043532712
Validation loss: 2.5159070230044605

Epoch: 5| Step: 11
Training loss: 2.2339009669115284
Validation loss: 2.52491142444924

Epoch: 34| Step: 0
Training loss: 2.802405148618664
Validation loss: 2.516593529467973

Epoch: 5| Step: 1
Training loss: 2.2117661719323314
Validation loss: 2.536995994612825

Epoch: 5| Step: 2
Training loss: 3.473433897743296
Validation loss: 2.512317765998701

Epoch: 5| Step: 3
Training loss: 2.0901218692712065
Validation loss: 2.5412594783041405

Epoch: 5| Step: 4
Training loss: 2.3874316859832483
Validation loss: 2.5330432732587105

Epoch: 5| Step: 5
Training loss: 2.877826130909596
Validation loss: 2.522495074108243

Epoch: 5| Step: 6
Training loss: 2.133638438619667
Validation loss: 2.5297100029223905

Epoch: 5| Step: 7
Training loss: 2.065355578236053
Validation loss: 2.5205701751068736

Epoch: 5| Step: 8
Training loss: 2.0667198246097747
Validation loss: 2.5561248165714257

Epoch: 5| Step: 9
Training loss: 2.125333871979368
Validation loss: 2.499102530719114

Epoch: 5| Step: 10
Training loss: 2.4451344580626584
Validation loss: 2.502442442358779

Epoch: 5| Step: 11
Training loss: 2.0707005550970896
Validation loss: 2.5119591375938306

Epoch: 35| Step: 0
Training loss: 2.2753425298363927
Validation loss: 2.521455870491125

Epoch: 5| Step: 1
Training loss: 2.687465933650369
Validation loss: 2.5315251220510415

Epoch: 5| Step: 2
Training loss: 2.766272000424845
Validation loss: 2.515043388881005

Epoch: 5| Step: 3
Training loss: 2.775687065641739
Validation loss: 2.5512053724675465

Epoch: 5| Step: 4
Training loss: 2.3686504816171046
Validation loss: 2.55497441056284

Epoch: 5| Step: 5
Training loss: 2.4525078647188003
Validation loss: 2.5347892131110576

Epoch: 5| Step: 6
Training loss: 2.2425322051696703
Validation loss: 2.557297484526585

Epoch: 5| Step: 7
Training loss: 2.8430424742798133
Validation loss: 2.5671554509254118

Epoch: 5| Step: 8
Training loss: 1.6912924924306831
Validation loss: 2.5533032803679987

Epoch: 5| Step: 9
Training loss: 1.5634573483165068
Validation loss: 2.5493887059519063

Epoch: 5| Step: 10
Training loss: 2.9536858888853086
Validation loss: 2.545905902023893

Epoch: 5| Step: 11
Training loss: 3.259527473138481
Validation loss: 2.550389978875466

Epoch: 36| Step: 0
Training loss: 2.2858880330363642
Validation loss: 2.5262234311072778

Epoch: 5| Step: 1
Training loss: 2.2443262194455538
Validation loss: 2.5144717927881484

Epoch: 5| Step: 2
Training loss: 2.6065568153311127
Validation loss: 2.5070072121011133

Epoch: 5| Step: 3
Training loss: 2.5169170213009124
Validation loss: 2.4877014203208883

Epoch: 5| Step: 4
Training loss: 2.7471213446201954
Validation loss: 2.5119070928744014

Epoch: 5| Step: 5
Training loss: 2.8277956101613673
Validation loss: 2.5015512263250304

Epoch: 5| Step: 6
Training loss: 2.4017988377808677
Validation loss: 2.5053963871493625

Epoch: 5| Step: 7
Training loss: 2.4535415198616586
Validation loss: 2.5006087714312777

Epoch: 5| Step: 8
Training loss: 2.492475821818754
Validation loss: 2.5101763991508794

Epoch: 5| Step: 9
Training loss: 2.3130430666438992
Validation loss: 2.5401992131380293

Epoch: 5| Step: 10
Training loss: 2.1290099512443708
Validation loss: 2.5025220626610523

Epoch: 5| Step: 11
Training loss: 2.7646532668405364
Validation loss: 2.493827579123346

Epoch: 37| Step: 0
Training loss: 2.391027678440763
Validation loss: 2.5238472455293373

Epoch: 5| Step: 1
Training loss: 2.309982063091707
Validation loss: 2.5107124452475023

Epoch: 5| Step: 2
Training loss: 2.6286598305467797
Validation loss: 2.499699367884963

Epoch: 5| Step: 3
Training loss: 2.478295619329609
Validation loss: 2.4986530927434756

Epoch: 5| Step: 4
Training loss: 2.653450242091579
Validation loss: 2.507354555871981

Epoch: 5| Step: 5
Training loss: 2.0654061390501566
Validation loss: 2.504296005154462

Epoch: 5| Step: 6
Training loss: 2.7934216538929437
Validation loss: 2.5272982208537607

Epoch: 5| Step: 7
Training loss: 2.6578753715672394
Validation loss: 2.5325563478147926

Epoch: 5| Step: 8
Training loss: 2.4674683153153074
Validation loss: 2.545695068602618

Epoch: 5| Step: 9
Training loss: 1.950994748924302
Validation loss: 2.5142103012259414

Epoch: 5| Step: 10
Training loss: 2.7588252728541756
Validation loss: 2.556754455286005

Epoch: 5| Step: 11
Training loss: 1.856429130567954
Validation loss: 2.529244692152436

Epoch: 38| Step: 0
Training loss: 2.558516965689441
Validation loss: 2.541163325629076

Epoch: 5| Step: 1
Training loss: 2.3051033291443197
Validation loss: 2.5416381077386596

Epoch: 5| Step: 2
Training loss: 2.483561256582522
Validation loss: 2.5241446316226286

Epoch: 5| Step: 3
Training loss: 2.7992083656571967
Validation loss: 2.5109982680805087

Epoch: 5| Step: 4
Training loss: 2.294875124191363
Validation loss: 2.5358037175686694

Epoch: 5| Step: 5
Training loss: 2.4607238676804863
Validation loss: 2.5081773019231792

Epoch: 5| Step: 6
Training loss: 2.3313180417519392
Validation loss: 2.519488584171966

Epoch: 5| Step: 7
Training loss: 2.1834753888147147
Validation loss: 2.502066673940125

Epoch: 5| Step: 8
Training loss: 2.5910696865119873
Validation loss: 2.528103389498308

Epoch: 5| Step: 9
Training loss: 2.3869419024796117
Validation loss: 2.504344516987833

Epoch: 5| Step: 10
Training loss: 2.5692575254984313
Validation loss: 2.5138925348317476

Epoch: 5| Step: 11
Training loss: 2.146422394820009
Validation loss: 2.495317202002089

Epoch: 39| Step: 0
Training loss: 2.208263492079616
Validation loss: 2.4964448485898565

Epoch: 5| Step: 1
Training loss: 2.152988233499581
Validation loss: 2.5336216228189765

Epoch: 5| Step: 2
Training loss: 2.3923104521824885
Validation loss: 2.5194894279537774

Epoch: 5| Step: 3
Training loss: 2.3163259662784217
Validation loss: 2.5052047314423

Epoch: 5| Step: 4
Training loss: 2.9882965685881877
Validation loss: 2.532696322507045

Epoch: 5| Step: 5
Training loss: 2.2350762607271077
Validation loss: 2.5361986843324313

Epoch: 5| Step: 6
Training loss: 2.837832487683058
Validation loss: 2.541258882162118

Epoch: 5| Step: 7
Training loss: 2.554603598613888
Validation loss: 2.5497105148965473

Epoch: 5| Step: 8
Training loss: 2.4249955285414537
Validation loss: 2.525900946299189

Epoch: 5| Step: 9
Training loss: 2.5264410797743797
Validation loss: 2.5420395871995902

Epoch: 5| Step: 10
Training loss: 2.3551528238005726
Validation loss: 2.53733605401728

Epoch: 5| Step: 11
Training loss: 2.9722523157927476
Validation loss: 2.533711331697704

Epoch: 40| Step: 0
Training loss: 2.794991908872081
Validation loss: 2.5110077828155393

Epoch: 5| Step: 1
Training loss: 1.8140452145090549
Validation loss: 2.4938265474023136

Epoch: 5| Step: 2
Training loss: 2.1265201740971764
Validation loss: 2.5049013411026873

Epoch: 5| Step: 3
Training loss: 3.2186803717628267
Validation loss: 2.503085779112182

Epoch: 5| Step: 4
Training loss: 2.7655110308769073
Validation loss: 2.501452973458186

Epoch: 5| Step: 5
Training loss: 1.8112390670288443
Validation loss: 2.51485472391639

Epoch: 5| Step: 6
Training loss: 2.9590257899845107
Validation loss: 2.5231562320885628

Epoch: 5| Step: 7
Training loss: 2.0643141888338965
Validation loss: 2.494748835239125

Epoch: 5| Step: 8
Training loss: 2.6881483316196126
Validation loss: 2.4909675107363745

Epoch: 5| Step: 9
Training loss: 1.9501068599471703
Validation loss: 2.4719771245540465

Epoch: 5| Step: 10
Training loss: 2.460476496068906
Validation loss: 2.5181272828650463

Epoch: 5| Step: 11
Training loss: 2.153440331122409
Validation loss: 2.4796770449351655

Epoch: 41| Step: 0
Training loss: 2.6623223402182346
Validation loss: 2.4973078895547483

Epoch: 5| Step: 1
Training loss: 2.2420554304935822
Validation loss: 2.5055992405716196

Epoch: 5| Step: 2
Training loss: 2.7428368128437515
Validation loss: 2.4777474201116987

Epoch: 5| Step: 3
Training loss: 2.3835998235004356
Validation loss: 2.4819189122879184

Epoch: 5| Step: 4
Training loss: 2.1859716253227783
Validation loss: 2.5035129819512707

Epoch: 5| Step: 5
Training loss: 2.4075494205397545
Validation loss: 2.502116880634004

Epoch: 5| Step: 6
Training loss: 2.151466703256113
Validation loss: 2.5291607872917137

Epoch: 5| Step: 7
Training loss: 2.52100474717973
Validation loss: 2.493315741286545

Epoch: 5| Step: 8
Training loss: 3.0081102100026955
Validation loss: 2.50403129277313

Epoch: 5| Step: 9
Training loss: 1.6409427880002367
Validation loss: 2.5176007940841734

Epoch: 5| Step: 10
Training loss: 2.6904938456506247
Validation loss: 2.4936117648608898

Epoch: 5| Step: 11
Training loss: 3.0961467052072993
Validation loss: 2.508345366102698

Epoch: 42| Step: 0
Training loss: 2.669920624828255
Validation loss: 2.514001511995169

Epoch: 5| Step: 1
Training loss: 1.9327254995071887
Validation loss: 2.5073184262474677

Epoch: 5| Step: 2
Training loss: 2.6690733202299683
Validation loss: 2.4755564149278744

Epoch: 5| Step: 3
Training loss: 3.1230377139875016
Validation loss: 2.491930219869081

Epoch: 5| Step: 4
Training loss: 2.269831678560995
Validation loss: 2.485847228861059

Epoch: 5| Step: 5
Training loss: 2.3978527238430845
Validation loss: 2.512971657517263

Epoch: 5| Step: 6
Training loss: 2.3137860201891836
Validation loss: 2.4928100270815396

Epoch: 5| Step: 7
Training loss: 2.0360311725231126
Validation loss: 2.492074822376921

Epoch: 5| Step: 8
Training loss: 2.1262658780518207
Validation loss: 2.505768090178843

Epoch: 5| Step: 9
Training loss: 2.384986461065159
Validation loss: 2.4918234867218376

Epoch: 5| Step: 10
Training loss: 2.8708896278948446
Validation loss: 2.488127783050552

Epoch: 5| Step: 11
Training loss: 1.4125740690137754
Validation loss: 2.49159645079444

Epoch: 43| Step: 0
Training loss: 2.511110223171711
Validation loss: 2.4945462463864785

Epoch: 5| Step: 1
Training loss: 2.727920674890693
Validation loss: 2.4983151082813446

Epoch: 5| Step: 2
Training loss: 3.239082338573246
Validation loss: 2.5219431921883255

Epoch: 5| Step: 3
Training loss: 2.1675904089915936
Validation loss: 2.5184656694213228

Epoch: 5| Step: 4
Training loss: 2.8996556439331815
Validation loss: 2.5062446942197933

Epoch: 5| Step: 5
Training loss: 1.9057086113252721
Validation loss: 2.4988284783429933

Epoch: 5| Step: 6
Training loss: 2.246166460270127
Validation loss: 2.5173348683418055

Epoch: 5| Step: 7
Training loss: 1.8547149733297839
Validation loss: 2.5224909330803067

Epoch: 5| Step: 8
Training loss: 2.651647282482997
Validation loss: 2.5289300601039866

Epoch: 5| Step: 9
Training loss: 2.097114933573432
Validation loss: 2.5000683536721837

Epoch: 5| Step: 10
Training loss: 1.9960907042119926
Validation loss: 2.512249310640948

Epoch: 5| Step: 11
Training loss: 3.1284929209673735
Validation loss: 2.4980580377118065

Epoch: 44| Step: 0
Training loss: 2.4460201519177325
Validation loss: 2.5210541984388075

Epoch: 5| Step: 1
Training loss: 2.806062239246903
Validation loss: 2.5234032855947413

Epoch: 5| Step: 2
Training loss: 2.322441075196529
Validation loss: 2.534250368910087

Epoch: 5| Step: 3
Training loss: 3.467940364892494
Validation loss: 2.5315280769411546

Epoch: 5| Step: 4
Training loss: 1.9367262618152716
Validation loss: 2.521827829984185

Epoch: 5| Step: 5
Training loss: 1.8940261010060326
Validation loss: 2.526319599919938

Epoch: 5| Step: 6
Training loss: 2.4026534710471283
Validation loss: 2.5180816186377957

Epoch: 5| Step: 7
Training loss: 2.4713190931773124
Validation loss: 2.5203342705622167

Epoch: 5| Step: 8
Training loss: 2.670646697459963
Validation loss: 2.537484270275703

Epoch: 5| Step: 9
Training loss: 1.8400616364936206
Validation loss: 2.5321927963930206

Epoch: 5| Step: 10
Training loss: 2.0596402311507953
Validation loss: 2.532936719436532

Epoch: 5| Step: 11
Training loss: 2.466992295740636
Validation loss: 2.5201015290301556

Epoch: 45| Step: 0
Training loss: 2.6807660748747666
Validation loss: 2.536323286582914

Epoch: 5| Step: 1
Training loss: 2.0126978001030844
Validation loss: 2.510455330409819

Epoch: 5| Step: 2
Training loss: 2.1758226702324257
Validation loss: 2.5253163479460694

Epoch: 5| Step: 3
Training loss: 2.996850744950807
Validation loss: 2.52910474049915

Epoch: 5| Step: 4
Training loss: 2.757803336066131
Validation loss: 2.5283619098917605

Epoch: 5| Step: 5
Training loss: 1.9648073469850935
Validation loss: 2.52852705504004

Epoch: 5| Step: 6
Training loss: 2.3617070275059
Validation loss: 2.4783569557699137

Epoch: 5| Step: 7
Training loss: 2.411838927146265
Validation loss: 2.5198649656103966

Epoch: 5| Step: 8
Training loss: 2.245936220698684
Validation loss: 2.514627041525076

Epoch: 5| Step: 9
Training loss: 2.413764317932808
Validation loss: 2.5071207282754004

Epoch: 5| Step: 10
Training loss: 2.5579035403129278
Validation loss: 2.511584980884497

Epoch: 5| Step: 11
Training loss: 2.407006677330654
Validation loss: 2.5167180445039263

Epoch: 46| Step: 0
Training loss: 2.5428805240731807
Validation loss: 2.4983477258447944

Epoch: 5| Step: 1
Training loss: 2.224705078638552
Validation loss: 2.508393700613589

Epoch: 5| Step: 2
Training loss: 1.5673975673468286
Validation loss: 2.5032648861040303

Epoch: 5| Step: 3
Training loss: 2.735370040771217
Validation loss: 2.4994906423159162

Epoch: 5| Step: 4
Training loss: 2.64228407527085
Validation loss: 2.5138751276059925

Epoch: 5| Step: 5
Training loss: 2.5774270702445103
Validation loss: 2.5212964087095138

Epoch: 5| Step: 6
Training loss: 2.6295289525035552
Validation loss: 2.524875191949702

Epoch: 5| Step: 7
Training loss: 2.9802732391027362
Validation loss: 2.5333124439628905

Epoch: 5| Step: 8
Training loss: 1.9482533237072077
Validation loss: 2.517711137720855

Epoch: 5| Step: 9
Training loss: 2.0012970533206413
Validation loss: 2.5332540812351416

Epoch: 5| Step: 10
Training loss: 2.592518433640515
Validation loss: 2.5296865627011407

Epoch: 5| Step: 11
Training loss: 2.046425806508257
Validation loss: 2.5246380724410376

Epoch: 47| Step: 0
Training loss: 2.900407065399533
Validation loss: 2.512492264946059

Epoch: 5| Step: 1
Training loss: 2.52544887443094
Validation loss: 2.5327620523030636

Epoch: 5| Step: 2
Training loss: 1.8053896640308036
Validation loss: 2.5068531201730626

Epoch: 5| Step: 3
Training loss: 2.0594977288730267
Validation loss: 2.5062532459786593

Epoch: 5| Step: 4
Training loss: 2.86400791746782
Validation loss: 2.5123168921290966

Epoch: 5| Step: 5
Training loss: 2.5541986120154365
Validation loss: 2.5069582465599956

Epoch: 5| Step: 6
Training loss: 2.6704760006424557
Validation loss: 2.497612138648393

Epoch: 5| Step: 7
Training loss: 2.2468123638139557
Validation loss: 2.5047319452312973

Epoch: 5| Step: 8
Training loss: 2.7116058141456687
Validation loss: 2.4929270289847185

Epoch: 5| Step: 9
Training loss: 2.6110033448167558
Validation loss: 2.5016827066177534

Epoch: 5| Step: 10
Training loss: 1.8468884411111333
Validation loss: 2.4906816866178114

Epoch: 5| Step: 11
Training loss: 0.9985749700765297
Validation loss: 2.497128506468334

Epoch: 48| Step: 0
Training loss: 2.2973974762498965
Validation loss: 2.489755470251739

Epoch: 5| Step: 1
Training loss: 2.3461330251743964
Validation loss: 2.4957873136919235

Epoch: 5| Step: 2
Training loss: 2.4423550890569703
Validation loss: 2.497900717214825

Epoch: 5| Step: 3
Training loss: 2.8083361851105137
Validation loss: 2.4948797681592074

Epoch: 5| Step: 4
Training loss: 1.9769467067105542
Validation loss: 2.472467936596229

Epoch: 5| Step: 5
Training loss: 2.5389651235834636
Validation loss: 2.4848215933328865

Epoch: 5| Step: 6
Training loss: 2.4183738751193165
Validation loss: 2.4958076213558797

Epoch: 5| Step: 7
Training loss: 2.8516563086560334
Validation loss: 2.512403735883547

Epoch: 5| Step: 8
Training loss: 2.2141774300498014
Validation loss: 2.5283509281210934

Epoch: 5| Step: 9
Training loss: 2.671110791232611
Validation loss: 2.5082009867249258

Epoch: 5| Step: 10
Training loss: 2.0405803307497297
Validation loss: 2.4940191850245537

Epoch: 5| Step: 11
Training loss: 2.7289348435890144
Validation loss: 2.521390905797484

Epoch: 49| Step: 0
Training loss: 2.3548203520074034
Validation loss: 2.502292406561991

Epoch: 5| Step: 1
Training loss: 1.8851853609900375
Validation loss: 2.50051013589605

Epoch: 5| Step: 2
Training loss: 2.486687597522479
Validation loss: 2.508693975891566

Epoch: 5| Step: 3
Training loss: 2.3499363951496175
Validation loss: 2.49901825781451

Epoch: 5| Step: 4
Training loss: 2.7886895109325116
Validation loss: 2.5498009278313414

Epoch: 5| Step: 5
Training loss: 2.51372868874582
Validation loss: 2.5042965010077105

Epoch: 5| Step: 6
Training loss: 2.178987123910886
Validation loss: 2.513716354707706

Epoch: 5| Step: 7
Training loss: 2.4344464273220763
Validation loss: 2.5130614453659432

Epoch: 5| Step: 8
Training loss: 2.6253141487696716
Validation loss: 2.5004904027600965

Epoch: 5| Step: 9
Training loss: 2.5715072313266747
Validation loss: 2.5160574610409894

Epoch: 5| Step: 10
Training loss: 2.293860500906633
Validation loss: 2.5025573723447554

Epoch: 5| Step: 11
Training loss: 2.3791435636967533
Validation loss: 2.4746438023782513

Epoch: 50| Step: 0
Training loss: 2.239061149815048
Validation loss: 2.5099673891418717

Epoch: 5| Step: 1
Training loss: 3.058048048581258
Validation loss: 2.5071745662235942

Epoch: 5| Step: 2
Training loss: 2.2063689461866476
Validation loss: 2.5111522104835835

Epoch: 5| Step: 3
Training loss: 2.8773947983376367
Validation loss: 2.506661179537381

Epoch: 5| Step: 4
Training loss: 2.216007418107104
Validation loss: 2.499941300656703

Epoch: 5| Step: 5
Training loss: 2.1815698077695966
Validation loss: 2.506545046612525

Epoch: 5| Step: 6
Training loss: 1.9876894566668126
Validation loss: 2.4959091074452506

Epoch: 5| Step: 7
Training loss: 1.990531322724369
Validation loss: 2.503460075153775

Epoch: 5| Step: 8
Training loss: 2.0750197536033816
Validation loss: 2.493641448148079

Epoch: 5| Step: 9
Training loss: 2.1836697423605913
Validation loss: 2.5031812930593422

Epoch: 5| Step: 10
Training loss: 3.313982074198705
Validation loss: 2.4968406105140013

Epoch: 5| Step: 11
Training loss: 2.182022757945624
Validation loss: 2.4841987859263384

Testing loss: 2.051248329242225
