Epoch: 1| Step: 0
Training loss: 4.945055239285005
Validation loss: 4.6739751630865065

Epoch: 5| Step: 1
Training loss: 4.920126952727646
Validation loss: 4.662356960976318

Epoch: 5| Step: 2
Training loss: 4.54662539921115
Validation loss: 4.652342596942749

Epoch: 5| Step: 3
Training loss: 3.5300727164583856
Validation loss: 4.645747396361402

Epoch: 5| Step: 4
Training loss: 4.932033554891153
Validation loss: 4.638105845399594

Epoch: 5| Step: 5
Training loss: 4.5483635107828295
Validation loss: 4.6297945997021195

Epoch: 5| Step: 6
Training loss: 4.660240562680298
Validation loss: 4.621455268982089

Epoch: 5| Step: 7
Training loss: 5.194078433672954
Validation loss: 4.614795028388862

Epoch: 5| Step: 8
Training loss: 5.093913257065516
Validation loss: 4.60608583327717

Epoch: 5| Step: 9
Training loss: 5.0471591928498505
Validation loss: 4.595117477884166

Epoch: 5| Step: 10
Training loss: 4.934867253552081
Validation loss: 4.583956167499715

Epoch: 5| Step: 11
Training loss: 3.153476818710196
Validation loss: 4.572668988494536

Epoch: 2| Step: 0
Training loss: 4.769842364187649
Validation loss: 4.5647054158257845

Epoch: 5| Step: 1
Training loss: 3.9229216983632567
Validation loss: 4.550626240765787

Epoch: 5| Step: 2
Training loss: 4.337271490316566
Validation loss: 4.534994717748749

Epoch: 5| Step: 3
Training loss: 3.6614108708842945
Validation loss: 4.525563040982964

Epoch: 5| Step: 4
Training loss: 5.545093002984094
Validation loss: 4.51134340780941

Epoch: 5| Step: 5
Training loss: 4.605461088243733
Validation loss: 4.498604195957745

Epoch: 5| Step: 6
Training loss: 4.8285113430073645
Validation loss: 4.481209447332292

Epoch: 5| Step: 7
Training loss: 4.145731760183307
Validation loss: 4.466067382598001

Epoch: 5| Step: 8
Training loss: 4.777986497287505
Validation loss: 4.44681809175151

Epoch: 5| Step: 9
Training loss: 5.355450586334078
Validation loss: 4.429502000013876

Epoch: 5| Step: 10
Training loss: 4.412219177473888
Validation loss: 4.410132859435222

Epoch: 5| Step: 11
Training loss: 4.692389214518266
Validation loss: 4.389121516550587

Epoch: 3| Step: 0
Training loss: 5.014164316790622
Validation loss: 4.370528133683937

Epoch: 5| Step: 1
Training loss: 4.817275811102617
Validation loss: 4.35205509541239

Epoch: 5| Step: 2
Training loss: 4.316876609341333
Validation loss: 4.327430467390397

Epoch: 5| Step: 3
Training loss: 4.365378999981166
Validation loss: 4.302397467880112

Epoch: 5| Step: 4
Training loss: 4.133111088428075
Validation loss: 4.276124192191509

Epoch: 5| Step: 5
Training loss: 3.237850367613018
Validation loss: 4.255789319845269

Epoch: 5| Step: 6
Training loss: 4.023397678807793
Validation loss: 4.231711292337039

Epoch: 5| Step: 7
Training loss: 5.112287805159565
Validation loss: 4.201920248046444

Epoch: 5| Step: 8
Training loss: 4.205728738349759
Validation loss: 4.1771971416745

Epoch: 5| Step: 9
Training loss: 4.039543905290367
Validation loss: 4.145394295619843

Epoch: 5| Step: 10
Training loss: 4.212618292440892
Validation loss: 4.113274009434968

Epoch: 5| Step: 11
Training loss: 5.434349989216544
Validation loss: 4.08711383290318

Epoch: 4| Step: 0
Training loss: 4.235620519583062
Validation loss: 4.040406087878761

Epoch: 5| Step: 1
Training loss: 4.153359232454901
Validation loss: 4.004060003538432

Epoch: 5| Step: 2
Training loss: 3.107072754242921
Validation loss: 3.9655317739957225

Epoch: 5| Step: 3
Training loss: 3.8489825601120713
Validation loss: 3.9245241293792135

Epoch: 5| Step: 4
Training loss: 4.371346392246427
Validation loss: 3.8740855645442993

Epoch: 5| Step: 5
Training loss: 4.365785322474479
Validation loss: 3.8368842982309843

Epoch: 5| Step: 6
Training loss: 4.182612057294601
Validation loss: 3.7822243404603513

Epoch: 5| Step: 7
Training loss: 3.069108023026696
Validation loss: 3.7364169859833956

Epoch: 5| Step: 8
Training loss: 3.8134426765059772
Validation loss: 3.6805360413679793

Epoch: 5| Step: 9
Training loss: 3.8968134308503863
Validation loss: 3.632031844290782

Epoch: 5| Step: 10
Training loss: 4.045788475492476
Validation loss: 3.562500909057858

Epoch: 5| Step: 11
Training loss: 2.5095530141584144
Validation loss: 3.498705471282893

Epoch: 5| Step: 0
Training loss: 3.370611940963745
Validation loss: 3.4382288189078425

Epoch: 5| Step: 1
Training loss: 3.2399148720283875
Validation loss: 3.375925655347154

Epoch: 5| Step: 2
Training loss: 2.7565698174281223
Validation loss: 3.3044842025474273

Epoch: 5| Step: 3
Training loss: 3.6285664344899122
Validation loss: 3.2410721173986916

Epoch: 5| Step: 4
Training loss: 3.4297438075976454
Validation loss: 3.1692850597922186

Epoch: 5| Step: 5
Training loss: 3.6444297195798727
Validation loss: 3.09761775964184

Epoch: 5| Step: 6
Training loss: 3.4368802985889126
Validation loss: 3.0436313219583013

Epoch: 5| Step: 7
Training loss: 2.879717398129688
Validation loss: 2.9541029580693587

Epoch: 5| Step: 8
Training loss: 2.5275331688580733
Validation loss: 2.8810741348822244

Epoch: 5| Step: 9
Training loss: 2.615151413277571
Validation loss: 2.8183194847394577

Epoch: 5| Step: 10
Training loss: 2.6414697864544023
Validation loss: 2.7682664078617476

Epoch: 5| Step: 11
Training loss: 3.0721523217942277
Validation loss: 2.72119086230364

Epoch: 6| Step: 0
Training loss: 2.8242955705211745
Validation loss: 2.6637349789710725

Epoch: 5| Step: 1
Training loss: 2.3015093080546634
Validation loss: 2.6406368578883472

Epoch: 5| Step: 2
Training loss: 2.724511104438598
Validation loss: 2.6431528252662697

Epoch: 5| Step: 3
Training loss: 2.337086066656293
Validation loss: 2.6277168307742507

Epoch: 5| Step: 4
Training loss: 2.606969032539722
Validation loss: 2.611908160861235

Epoch: 5| Step: 5
Training loss: 2.584267621652182
Validation loss: 2.629066530417506

Epoch: 5| Step: 6
Training loss: 2.2690574164491886
Validation loss: 2.6727625653529925

Epoch: 5| Step: 7
Training loss: 3.0546678313185516
Validation loss: 2.6988461352728477

Epoch: 5| Step: 8
Training loss: 2.822567954584238
Validation loss: 2.7155433357172027

Epoch: 5| Step: 9
Training loss: 2.626725674110033
Validation loss: 2.7490551690934786

Epoch: 5| Step: 10
Training loss: 3.2194697491983706
Validation loss: 2.745362435387727

Epoch: 5| Step: 11
Training loss: 2.059909233760208
Validation loss: 2.7740014698276325

Epoch: 7| Step: 0
Training loss: 2.271316955116966
Validation loss: 2.7415805083267175

Epoch: 5| Step: 1
Training loss: 2.973784344199435
Validation loss: 2.7519282097790727

Epoch: 5| Step: 2
Training loss: 2.6225170017851362
Validation loss: 2.7361720655776494

Epoch: 5| Step: 3
Training loss: 2.956059688063577
Validation loss: 2.696935870624443

Epoch: 5| Step: 4
Training loss: 2.6170383695559893
Validation loss: 2.6491925861398227

Epoch: 5| Step: 5
Training loss: 2.255745228443259
Validation loss: 2.670162745384215

Epoch: 5| Step: 6
Training loss: 2.2001172901445654
Validation loss: 2.6420848392610017

Epoch: 5| Step: 7
Training loss: 3.070839562446422
Validation loss: 2.634033606669426

Epoch: 5| Step: 8
Training loss: 2.630315394473038
Validation loss: 2.6293767212406536

Epoch: 5| Step: 9
Training loss: 2.5083906511451604
Validation loss: 2.6117198139614137

Epoch: 5| Step: 10
Training loss: 2.3415462051123974
Validation loss: 2.611593456954402

Epoch: 5| Step: 11
Training loss: 2.984689426335626
Validation loss: 2.6017989699353334

Epoch: 8| Step: 0
Training loss: 2.7812938901031297
Validation loss: 2.5751805648024595

Epoch: 5| Step: 1
Training loss: 2.748922830641268
Validation loss: 2.6023168148073377

Epoch: 5| Step: 2
Training loss: 2.685481266954278
Validation loss: 2.580548263096255

Epoch: 5| Step: 3
Training loss: 2.5500350725342553
Validation loss: 2.601988122774657

Epoch: 5| Step: 4
Training loss: 2.236207543999458
Validation loss: 2.573596113019092

Epoch: 5| Step: 5
Training loss: 2.1073493556147986
Validation loss: 2.5938310572203185

Epoch: 5| Step: 6
Training loss: 2.2119725908026435
Validation loss: 2.5789037318286234

Epoch: 5| Step: 7
Training loss: 2.856475694282871
Validation loss: 2.61946908369058

Epoch: 5| Step: 8
Training loss: 2.6688319495168598
Validation loss: 2.5995271031071723

Epoch: 5| Step: 9
Training loss: 2.4584993424910264
Validation loss: 2.6078871751153763

Epoch: 5| Step: 10
Training loss: 2.8831786876801053
Validation loss: 2.5970713365611173

Epoch: 5| Step: 11
Training loss: 2.618195752325933
Validation loss: 2.6005712955915947

Epoch: 9| Step: 0
Training loss: 2.103848033486295
Validation loss: 2.597599661839333

Epoch: 5| Step: 1
Training loss: 3.055644400104524
Validation loss: 2.5827913189969713

Epoch: 5| Step: 2
Training loss: 2.718711589673444
Validation loss: 2.5955809905799656

Epoch: 5| Step: 3
Training loss: 2.8840061600787315
Validation loss: 2.5940506887218717

Epoch: 5| Step: 4
Training loss: 2.2003550329703985
Validation loss: 2.5997776327654396

Epoch: 5| Step: 5
Training loss: 2.9588609323467323
Validation loss: 2.592125019763751

Epoch: 5| Step: 6
Training loss: 2.4731200929660044
Validation loss: 2.5941295997106937

Epoch: 5| Step: 7
Training loss: 1.8629109716474113
Validation loss: 2.586158416469954

Epoch: 5| Step: 8
Training loss: 2.531727686890201
Validation loss: 2.5940647470476534

Epoch: 5| Step: 9
Training loss: 2.7201207531042635
Validation loss: 2.5817009565018845

Epoch: 5| Step: 10
Training loss: 2.0792672596093906
Validation loss: 2.5947181740767467

Epoch: 5| Step: 11
Training loss: 3.277855561477531
Validation loss: 2.6051705345595453

Epoch: 10| Step: 0
Training loss: 2.7459617789234785
Validation loss: 2.608226146313596

Epoch: 5| Step: 1
Training loss: 2.4879764388155525
Validation loss: 2.5831022037405043

Epoch: 5| Step: 2
Training loss: 1.9683604990446284
Validation loss: 2.590556139274299

Epoch: 5| Step: 3
Training loss: 2.5314800016670747
Validation loss: 2.6081352296274076

Epoch: 5| Step: 4
Training loss: 2.3914934961803573
Validation loss: 2.607079804230965

Epoch: 5| Step: 5
Training loss: 3.2934396210274626
Validation loss: 2.587946711478264

Epoch: 5| Step: 6
Training loss: 1.834757129177657
Validation loss: 2.614669191741583

Epoch: 5| Step: 7
Training loss: 2.588102419841533
Validation loss: 2.59338104733904

Epoch: 5| Step: 8
Training loss: 2.5055294875231264
Validation loss: 2.584783563604009

Epoch: 5| Step: 9
Training loss: 2.1468217912546357
Validation loss: 2.5772937089499113

Epoch: 5| Step: 10
Training loss: 3.256913973718395
Validation loss: 2.5950068967374764

Epoch: 5| Step: 11
Training loss: 2.0975953276185724
Validation loss: 2.571961311755342

Epoch: 11| Step: 0
Training loss: 2.2404984016778817
Validation loss: 2.585642622070899

Epoch: 5| Step: 1
Training loss: 2.148741877409011
Validation loss: 2.570297689501482

Epoch: 5| Step: 2
Training loss: 2.1379362051628648
Validation loss: 2.5879211212856474

Epoch: 5| Step: 3
Training loss: 2.4746701685446317
Validation loss: 2.5646661542590827

Epoch: 5| Step: 4
Training loss: 2.2812424751053118
Validation loss: 2.565559262925413

Epoch: 5| Step: 5
Training loss: 2.5587902663379256
Validation loss: 2.582388979570969

Epoch: 5| Step: 6
Training loss: 2.596069218269683
Validation loss: 2.5803580775960855

Epoch: 5| Step: 7
Training loss: 2.8065789520559608
Validation loss: 2.5633619727302843

Epoch: 5| Step: 8
Training loss: 2.7839427299911987
Validation loss: 2.6006895171932123

Epoch: 5| Step: 9
Training loss: 3.2118710091368077
Validation loss: 2.5861230228560395

Epoch: 5| Step: 10
Training loss: 2.537512297201191
Validation loss: 2.5839405474186115

Epoch: 5| Step: 11
Training loss: 2.867513944663453
Validation loss: 2.5546315349394417

Epoch: 12| Step: 0
Training loss: 2.9117664772341096
Validation loss: 2.56985265836998

Epoch: 5| Step: 1
Training loss: 2.453736052976314
Validation loss: 2.5712521815163236

Epoch: 5| Step: 2
Training loss: 2.4269735505211423
Validation loss: 2.5661334817469217

Epoch: 5| Step: 3
Training loss: 2.4980333221998463
Validation loss: 2.591539452078981

Epoch: 5| Step: 4
Training loss: 1.6485645552570065
Validation loss: 2.5566609427720826

Epoch: 5| Step: 5
Training loss: 3.2063182265847217
Validation loss: 2.594064570888227

Epoch: 5| Step: 6
Training loss: 2.908764807348262
Validation loss: 2.5600669909692453

Epoch: 5| Step: 7
Training loss: 2.088044434779823
Validation loss: 2.5754201320996617

Epoch: 5| Step: 8
Training loss: 2.164753607281165
Validation loss: 2.5729840703518816

Epoch: 5| Step: 9
Training loss: 2.478853243295059
Validation loss: 2.5679761322661214

Epoch: 5| Step: 10
Training loss: 2.7362266156838526
Validation loss: 2.5665464822592994

Epoch: 5| Step: 11
Training loss: 2.7065646827758543
Validation loss: 2.576201833262054

Epoch: 13| Step: 0
Training loss: 2.033579620183276
Validation loss: 2.5815051990985944

Epoch: 5| Step: 1
Training loss: 2.6550644865663675
Validation loss: 2.5704346253853

Epoch: 5| Step: 2
Training loss: 2.3256172140268436
Validation loss: 2.5762988009358487

Epoch: 5| Step: 3
Training loss: 2.5734640818406
Validation loss: 2.580113274264827

Epoch: 5| Step: 4
Training loss: 2.0686067283782807
Validation loss: 2.5592925381757388

Epoch: 5| Step: 5
Training loss: 2.5354562355617047
Validation loss: 2.5499409298662217

Epoch: 5| Step: 6
Training loss: 2.247307756155998
Validation loss: 2.5542623689176587

Epoch: 5| Step: 7
Training loss: 2.847561137386227
Validation loss: 2.5530156061151477

Epoch: 5| Step: 8
Training loss: 2.275897710395525
Validation loss: 2.5994056566428148

Epoch: 5| Step: 9
Training loss: 3.48076658333914
Validation loss: 2.5730425550317317

Epoch: 5| Step: 10
Training loss: 2.6090089461267163
Validation loss: 2.537058202527493

Epoch: 5| Step: 11
Training loss: 1.9190502341902949
Validation loss: 2.5759683778803297

Epoch: 14| Step: 0
Training loss: 2.574796898248525
Validation loss: 2.5553779407873614

Epoch: 5| Step: 1
Training loss: 1.4216047596095602
Validation loss: 2.5865648359621756

Epoch: 5| Step: 2
Training loss: 2.4939725695266315
Validation loss: 2.57598838123743

Epoch: 5| Step: 3
Training loss: 2.2261508494192657
Validation loss: 2.570527343119294

Epoch: 5| Step: 4
Training loss: 2.8840840334454714
Validation loss: 2.5563549545616615

Epoch: 5| Step: 5
Training loss: 2.3674464320212167
Validation loss: 2.564194692628586

Epoch: 5| Step: 6
Training loss: 2.319579448565362
Validation loss: 2.5921549392810506

Epoch: 5| Step: 7
Training loss: 3.075426652043916
Validation loss: 2.5788739898552944

Epoch: 5| Step: 8
Training loss: 3.146350860130889
Validation loss: 2.555594669148682

Epoch: 5| Step: 9
Training loss: 2.8033967089510483
Validation loss: 2.581177932619922

Epoch: 5| Step: 10
Training loss: 2.068461962236964
Validation loss: 2.5536799607060554

Epoch: 5| Step: 11
Training loss: 2.4632603899420027
Validation loss: 2.5574939217903845

Epoch: 15| Step: 0
Training loss: 1.4293356707474352
Validation loss: 2.5493782239081333

Epoch: 5| Step: 1
Training loss: 1.964820452148157
Validation loss: 2.5458120378476625

Epoch: 5| Step: 2
Training loss: 2.7628093114790713
Validation loss: 2.575784159982565

Epoch: 5| Step: 3
Training loss: 3.3363019757529573
Validation loss: 2.5490679280975153

Epoch: 5| Step: 4
Training loss: 2.396310664738802
Validation loss: 2.5660315849298376

Epoch: 5| Step: 5
Training loss: 2.2917654074001885
Validation loss: 2.5706773439088493

Epoch: 5| Step: 6
Training loss: 2.9916333514583813
Validation loss: 2.553931697058588

Epoch: 5| Step: 7
Training loss: 2.0576856662415444
Validation loss: 2.5492502031130746

Epoch: 5| Step: 8
Training loss: 2.5547251100717285
Validation loss: 2.5528184234317552

Epoch: 5| Step: 9
Training loss: 2.7058573237527415
Validation loss: 2.565835901963015

Epoch: 5| Step: 10
Training loss: 2.567218622911712
Validation loss: 2.563373223053487

Epoch: 5| Step: 11
Training loss: 3.3103099276837775
Validation loss: 2.5617671515633083

Epoch: 16| Step: 0
Training loss: 1.8158998501297625
Validation loss: 2.5541680884136913

Epoch: 5| Step: 1
Training loss: 2.4346628550213785
Validation loss: 2.552684811668169

Epoch: 5| Step: 2
Training loss: 2.6363512475371382
Validation loss: 2.540057401139916

Epoch: 5| Step: 3
Training loss: 2.6739962896237137
Validation loss: 2.538477602371919

Epoch: 5| Step: 4
Training loss: 2.85819941467403
Validation loss: 2.548738390827665

Epoch: 5| Step: 5
Training loss: 2.482089352790672
Validation loss: 2.5608217124373227

Epoch: 5| Step: 6
Training loss: 2.5909033171423625
Validation loss: 2.5313729268118714

Epoch: 5| Step: 7
Training loss: 2.7440818047243574
Validation loss: 2.548693547891955

Epoch: 5| Step: 8
Training loss: 2.528468263613629
Validation loss: 2.5482359060529385

Epoch: 5| Step: 9
Training loss: 2.734483117282162
Validation loss: 2.5620442504639827

Epoch: 5| Step: 10
Training loss: 2.268166845949489
Validation loss: 2.5391692701534407

Epoch: 5| Step: 11
Training loss: 1.535716180388337
Validation loss: 2.556147831691487

Epoch: 17| Step: 0
Training loss: 2.7351252807154003
Validation loss: 2.5419687628353684

Epoch: 5| Step: 1
Training loss: 1.9756069361371662
Validation loss: 2.549104354525382

Epoch: 5| Step: 2
Training loss: 2.2121420231248385
Validation loss: 2.576501504682332

Epoch: 5| Step: 3
Training loss: 1.9833184981659493
Validation loss: 2.548828927888902

Epoch: 5| Step: 4
Training loss: 2.276071287845514
Validation loss: 2.537861047781523

Epoch: 5| Step: 5
Training loss: 2.853869030508993
Validation loss: 2.56821271625099

Epoch: 5| Step: 6
Training loss: 2.6216560135916143
Validation loss: 2.551776152568108

Epoch: 5| Step: 7
Training loss: 2.0965746145656055
Validation loss: 2.5742160525040103

Epoch: 5| Step: 8
Training loss: 2.9422513803930492
Validation loss: 2.54803535146533

Epoch: 5| Step: 9
Training loss: 2.9705471020418477
Validation loss: 2.5686521182009203

Epoch: 5| Step: 10
Training loss: 2.738656838598449
Validation loss: 2.571662308777211

Epoch: 5| Step: 11
Training loss: 2.7153934498566525
Validation loss: 2.57264977716998

Epoch: 18| Step: 0
Training loss: 2.959472777091752
Validation loss: 2.582978523535431

Epoch: 5| Step: 1
Training loss: 2.531923275169292
Validation loss: 2.58151172561071

Epoch: 5| Step: 2
Training loss: 2.796589501157111
Validation loss: 2.5705957420916845

Epoch: 5| Step: 3
Training loss: 1.926889406361334
Validation loss: 2.559265640602142

Epoch: 5| Step: 4
Training loss: 2.0770576432098733
Validation loss: 2.5642171161843135

Epoch: 5| Step: 5
Training loss: 2.632904322802989
Validation loss: 2.554179317003279

Epoch: 5| Step: 6
Training loss: 2.383558613015868
Validation loss: 2.5629465520417987

Epoch: 5| Step: 7
Training loss: 2.827012238326568
Validation loss: 2.5558865267783366

Epoch: 5| Step: 8
Training loss: 2.570575457169028
Validation loss: 2.5692829284651353

Epoch: 5| Step: 9
Training loss: 2.6929724223767844
Validation loss: 2.535961781383761

Epoch: 5| Step: 10
Training loss: 2.2450858599720056
Validation loss: 2.5628183097387427

Epoch: 5| Step: 11
Training loss: 0.7126798553337802
Validation loss: 2.5698785618467395

Epoch: 19| Step: 0
Training loss: 2.4301667062851706
Validation loss: 2.573156389402185

Epoch: 5| Step: 1
Training loss: 2.6393341882230077
Validation loss: 2.5490638204950513

Epoch: 5| Step: 2
Training loss: 2.47784679337632
Validation loss: 2.532941676804574

Epoch: 5| Step: 3
Training loss: 2.28350676645939
Validation loss: 2.5480330083262026

Epoch: 5| Step: 4
Training loss: 2.062480695229553
Validation loss: 2.535116923242215

Epoch: 5| Step: 5
Training loss: 2.5597221390610385
Validation loss: 2.5660207876021013

Epoch: 5| Step: 6
Training loss: 2.2891571754431927
Validation loss: 2.547786608007282

Epoch: 5| Step: 7
Training loss: 2.983978724508657
Validation loss: 2.5325578913421847

Epoch: 5| Step: 8
Training loss: 2.4025345889329643
Validation loss: 2.5206195619806495

Epoch: 5| Step: 9
Training loss: 3.034587320743029
Validation loss: 2.544016679286261

Epoch: 5| Step: 10
Training loss: 2.4154070717638176
Validation loss: 2.530214352925787

Epoch: 5| Step: 11
Training loss: 1.4184875379948805
Validation loss: 2.539764843171364

Epoch: 20| Step: 0
Training loss: 2.921997883706498
Validation loss: 2.5213407736106497

Epoch: 5| Step: 1
Training loss: 1.8131577843769562
Validation loss: 2.548722044002719

Epoch: 5| Step: 2
Training loss: 2.5604780640365488
Validation loss: 2.5415748569187038

Epoch: 5| Step: 3
Training loss: 1.9189285394066569
Validation loss: 2.5331806386764812

Epoch: 5| Step: 4
Training loss: 3.1511028357419404
Validation loss: 2.5716385440273517

Epoch: 5| Step: 5
Training loss: 2.6894725391626353
Validation loss: 2.533438921336259

Epoch: 5| Step: 6
Training loss: 2.475664138311216
Validation loss: 2.5508798733037836

Epoch: 5| Step: 7
Training loss: 2.7132847542909
Validation loss: 2.559765174353797

Epoch: 5| Step: 8
Training loss: 2.41918855382795
Validation loss: 2.551113011671075

Epoch: 5| Step: 9
Training loss: 2.039602858463251
Validation loss: 2.5517079732538583

Epoch: 5| Step: 10
Training loss: 2.228591797284954
Validation loss: 2.55318005929298

Epoch: 5| Step: 11
Training loss: 3.7210505445984663
Validation loss: 2.5485816534339696

Epoch: 21| Step: 0
Training loss: 2.289518447618377
Validation loss: 2.5522917928351316

Epoch: 5| Step: 1
Training loss: 2.666515842781949
Validation loss: 2.534793140052168

Epoch: 5| Step: 2
Training loss: 2.3495692933834493
Validation loss: 2.5361565495886893

Epoch: 5| Step: 3
Training loss: 2.5267019975283915
Validation loss: 2.5584482981564727

Epoch: 5| Step: 4
Training loss: 2.473148049957393
Validation loss: 2.536848844327733

Epoch: 5| Step: 5
Training loss: 2.1516739206268145
Validation loss: 2.542330050794637

Epoch: 5| Step: 6
Training loss: 2.0573818396270296
Validation loss: 2.56431399856793

Epoch: 5| Step: 7
Training loss: 3.063055805451407
Validation loss: 2.5411587048612656

Epoch: 5| Step: 8
Training loss: 2.332146365393197
Validation loss: 2.5362096987098535

Epoch: 5| Step: 9
Training loss: 2.5436997542234088
Validation loss: 2.549940086421342

Epoch: 5| Step: 10
Training loss: 2.851742924247144
Validation loss: 2.532304085141771

Epoch: 5| Step: 11
Training loss: 2.4551043452135044
Validation loss: 2.5495990897714855

Epoch: 22| Step: 0
Training loss: 2.6527929810448385
Validation loss: 2.53623611030266

Epoch: 5| Step: 1
Training loss: 2.4861074680843926
Validation loss: 2.5242684475425934

Epoch: 5| Step: 2
Training loss: 2.520487380656242
Validation loss: 2.535277337786081

Epoch: 5| Step: 3
Training loss: 2.123822839845077
Validation loss: 2.530045815519157

Epoch: 5| Step: 4
Training loss: 2.6766967989158608
Validation loss: 2.555681387221014

Epoch: 5| Step: 5
Training loss: 2.4335754295871905
Validation loss: 2.5373372246534838

Epoch: 5| Step: 6
Training loss: 2.4882411983506407
Validation loss: 2.5078195035050346

Epoch: 5| Step: 7
Training loss: 2.3449349014909187
Validation loss: 2.530052431584797

Epoch: 5| Step: 8
Training loss: 2.522252894265001
Validation loss: 2.5205547254990894

Epoch: 5| Step: 9
Training loss: 2.3212810511404665
Validation loss: 2.5491727749428255

Epoch: 5| Step: 10
Training loss: 2.6704190397576912
Validation loss: 2.5515736843034538

Epoch: 5| Step: 11
Training loss: 3.030722188714838
Validation loss: 2.515644661804825

Epoch: 23| Step: 0
Training loss: 2.0110893375957977
Validation loss: 2.534013060357465

Epoch: 5| Step: 1
Training loss: 2.8685402654302297
Validation loss: 2.5238668354078637

Epoch: 5| Step: 2
Training loss: 2.0759419612672927
Validation loss: 2.5204747683243336

Epoch: 5| Step: 3
Training loss: 2.921488527248353
Validation loss: 2.5148279811131293

Epoch: 5| Step: 4
Training loss: 2.1176595126515116
Validation loss: 2.5268155410241175

Epoch: 5| Step: 5
Training loss: 2.1944203583351864
Validation loss: 2.525896443128468

Epoch: 5| Step: 6
Training loss: 2.7157955559483824
Validation loss: 2.5326112375811953

Epoch: 5| Step: 7
Training loss: 2.5780238276195053
Validation loss: 2.5246673673335494

Epoch: 5| Step: 8
Training loss: 2.360112359233256
Validation loss: 2.5381880012276192

Epoch: 5| Step: 9
Training loss: 2.6711686299291966
Validation loss: 2.5274156641764196

Epoch: 5| Step: 10
Training loss: 2.749706426035755
Validation loss: 2.551062412159437

Epoch: 5| Step: 11
Training loss: 1.3077503731941649
Validation loss: 2.5590493687121874

Epoch: 24| Step: 0
Training loss: 2.465922511031889
Validation loss: 2.5504016564566343

Epoch: 5| Step: 1
Training loss: 2.6612152366822395
Validation loss: 2.5614452478592455

Epoch: 5| Step: 2
Training loss: 2.387569094951286
Validation loss: 2.545702319096052

Epoch: 5| Step: 3
Training loss: 3.0971274387546934
Validation loss: 2.533932073374952

Epoch: 5| Step: 4
Training loss: 2.3276725175720183
Validation loss: 2.5607918264010916

Epoch: 5| Step: 5
Training loss: 2.1239082673517236
Validation loss: 2.547275121731881

Epoch: 5| Step: 6
Training loss: 2.73728334797582
Validation loss: 2.5373427372073443

Epoch: 5| Step: 7
Training loss: 2.1875907879109344
Validation loss: 2.561185662544593

Epoch: 5| Step: 8
Training loss: 2.0442916059147307
Validation loss: 2.553901022455189

Epoch: 5| Step: 9
Training loss: 2.657618091790836
Validation loss: 2.545393862203517

Epoch: 5| Step: 10
Training loss: 2.561286452831278
Validation loss: 2.5540197318245137

Epoch: 5| Step: 11
Training loss: 2.1824548579875187
Validation loss: 2.537665388671274

Epoch: 25| Step: 0
Training loss: 1.9476936199032227
Validation loss: 2.5313716788539278

Epoch: 5| Step: 1
Training loss: 2.378994143010194
Validation loss: 2.5334897434319865

Epoch: 5| Step: 2
Training loss: 2.9335176785659542
Validation loss: 2.5236148712840736

Epoch: 5| Step: 3
Training loss: 2.7817354957227804
Validation loss: 2.5157804816238363

Epoch: 5| Step: 4
Training loss: 2.322117575376947
Validation loss: 2.5128234680364008

Epoch: 5| Step: 5
Training loss: 2.8711734682810333
Validation loss: 2.5409145076100685

Epoch: 5| Step: 6
Training loss: 2.7422811378076526
Validation loss: 2.5324132565821404

Epoch: 5| Step: 7
Training loss: 2.1910280387473704
Validation loss: 2.520212874756241

Epoch: 5| Step: 8
Training loss: 2.027228967728524
Validation loss: 2.5153393435150693

Epoch: 5| Step: 9
Training loss: 2.8720598528690022
Validation loss: 2.5188556090522836

Epoch: 5| Step: 10
Training loss: 2.337983935030916
Validation loss: 2.502719667424323

Epoch: 5| Step: 11
Training loss: 1.618223365337023
Validation loss: 2.5130126610394092

Epoch: 26| Step: 0
Training loss: 2.5581514631440867
Validation loss: 2.5294196846504655

Epoch: 5| Step: 1
Training loss: 2.4555564541860617
Validation loss: 2.521026660399674

Epoch: 5| Step: 2
Training loss: 3.0328879109695714
Validation loss: 2.5177434842790474

Epoch: 5| Step: 3
Training loss: 2.2156477180467657
Validation loss: 2.5165003069204075

Epoch: 5| Step: 4
Training loss: 3.181883257658686
Validation loss: 2.5164743415236392

Epoch: 5| Step: 5
Training loss: 2.2699033133463895
Validation loss: 2.536838496477262

Epoch: 5| Step: 6
Training loss: 2.0804805169397684
Validation loss: 2.5061816520916014

Epoch: 5| Step: 7
Training loss: 2.206938128912134
Validation loss: 2.5386355094850535

Epoch: 5| Step: 8
Training loss: 2.3295383131843943
Validation loss: 2.525534857544942

Epoch: 5| Step: 9
Training loss: 1.8182126486938652
Validation loss: 2.540226431876289

Epoch: 5| Step: 10
Training loss: 2.8836888581049944
Validation loss: 2.5387837027048947

Epoch: 5| Step: 11
Training loss: 2.276802116356333
Validation loss: 2.5303851443678154

Epoch: 27| Step: 0
Training loss: 2.404905562896176
Validation loss: 2.5215706016399975

Epoch: 5| Step: 1
Training loss: 2.709489683124212
Validation loss: 2.5411597447302197

Epoch: 5| Step: 2
Training loss: 1.8124196264928103
Validation loss: 2.5441029212438577

Epoch: 5| Step: 3
Training loss: 2.70007884652195
Validation loss: 2.534686687226201

Epoch: 5| Step: 4
Training loss: 3.1817865964634664
Validation loss: 2.530167825159171

Epoch: 5| Step: 5
Training loss: 3.0063752146317904
Validation loss: 2.534827255586947

Epoch: 5| Step: 6
Training loss: 2.210162239160982
Validation loss: 2.5083084170687098

Epoch: 5| Step: 7
Training loss: 2.1636090957010334
Validation loss: 2.524510902303424

Epoch: 5| Step: 8
Training loss: 2.915450105808365
Validation loss: 2.5295091537492937

Epoch: 5| Step: 9
Training loss: 1.962875442066591
Validation loss: 2.512758983878247

Epoch: 5| Step: 10
Training loss: 1.7742216418438839
Validation loss: 2.520119788063984

Epoch: 5| Step: 11
Training loss: 2.870958556021927
Validation loss: 2.5055438284295257

Epoch: 28| Step: 0
Training loss: 2.523961157540696
Validation loss: 2.5112554420486912

Epoch: 5| Step: 1
Training loss: 2.6682023355263196
Validation loss: 2.501164622040376

Epoch: 5| Step: 2
Training loss: 2.3659749466383024
Validation loss: 2.4929788622545948

Epoch: 5| Step: 3
Training loss: 2.5607755487611197
Validation loss: 2.510305007783459

Epoch: 5| Step: 4
Training loss: 2.1185273720235913
Validation loss: 2.5222166590225474

Epoch: 5| Step: 5
Training loss: 2.0794477340319366
Validation loss: 2.5087606711319865

Epoch: 5| Step: 6
Training loss: 3.110038341518923
Validation loss: 2.5147164206589654

Epoch: 5| Step: 7
Training loss: 2.1824346478827383
Validation loss: 2.495423532928644

Epoch: 5| Step: 8
Training loss: 2.683237910104219
Validation loss: 2.506900098490037

Epoch: 5| Step: 9
Training loss: 2.3635691569850614
Validation loss: 2.499924757937805

Epoch: 5| Step: 10
Training loss: 2.570372885136754
Validation loss: 2.492886288852199

Epoch: 5| Step: 11
Training loss: 2.190610254866622
Validation loss: 2.5194684476689195

Epoch: 29| Step: 0
Training loss: 2.973293321394448
Validation loss: 2.4920976078479495

Epoch: 5| Step: 1
Training loss: 2.8490372018631307
Validation loss: 2.517302883541726

Epoch: 5| Step: 2
Training loss: 2.2534936695877517
Validation loss: 2.547135142826952

Epoch: 5| Step: 3
Training loss: 2.6299537057029396
Validation loss: 2.552799752294994

Epoch: 5| Step: 4
Training loss: 2.455055012135138
Validation loss: 2.5707428348745234

Epoch: 5| Step: 5
Training loss: 2.8462014164587437
Validation loss: 2.5401283570144737

Epoch: 5| Step: 6
Training loss: 2.0124024645940968
Validation loss: 2.5683332937485255

Epoch: 5| Step: 7
Training loss: 2.4979369234011926
Validation loss: 2.5553096165406934

Epoch: 5| Step: 8
Training loss: 2.029975961063662
Validation loss: 2.543762161388272

Epoch: 5| Step: 9
Training loss: 1.8550120865872781
Validation loss: 2.5281126021248985

Epoch: 5| Step: 10
Training loss: 2.7924730834756555
Validation loss: 2.5277339706770348

Epoch: 5| Step: 11
Training loss: 1.7512850811403622
Validation loss: 2.5197577125834236

Epoch: 30| Step: 0
Training loss: 2.3194452071299665
Validation loss: 2.5390409693660945

Epoch: 5| Step: 1
Training loss: 2.4120648955286628
Validation loss: 2.5420041342303246

Epoch: 5| Step: 2
Training loss: 2.721924255135657
Validation loss: 2.5552305602890013

Epoch: 5| Step: 3
Training loss: 2.287965166500333
Validation loss: 2.5256063826920356

Epoch: 5| Step: 4
Training loss: 2.5277557744709225
Validation loss: 2.5248033706662785

Epoch: 5| Step: 5
Training loss: 2.3440040959267097
Validation loss: 2.506880015416796

Epoch: 5| Step: 6
Training loss: 2.8102284052867255
Validation loss: 2.5038110811156766

Epoch: 5| Step: 7
Training loss: 2.3485065259706763
Validation loss: 2.50701011663865

Epoch: 5| Step: 8
Training loss: 2.5355895719810535
Validation loss: 2.5142920419913457

Epoch: 5| Step: 9
Training loss: 2.468605230408429
Validation loss: 2.5123098339403844

Epoch: 5| Step: 10
Training loss: 2.415505579751483
Validation loss: 2.5111507012707532

Epoch: 5| Step: 11
Training loss: 2.3141986690950938
Validation loss: 2.524126740170605

Epoch: 31| Step: 0
Training loss: 2.6288058529596534
Validation loss: 2.5001645868483164

Epoch: 5| Step: 1
Training loss: 2.7911245379543437
Validation loss: 2.4845597180486316

Epoch: 5| Step: 2
Training loss: 2.5488234479722416
Validation loss: 2.5236586876331875

Epoch: 5| Step: 3
Training loss: 2.7680735982470734
Validation loss: 2.5232662973502817

Epoch: 5| Step: 4
Training loss: 2.451496920367988
Validation loss: 2.506790465856559

Epoch: 5| Step: 5
Training loss: 2.470342484641464
Validation loss: 2.5155703457725918

Epoch: 5| Step: 6
Training loss: 2.0492894732378075
Validation loss: 2.5366122233701076

Epoch: 5| Step: 7
Training loss: 2.5205120691132694
Validation loss: 2.5214474628799044

Epoch: 5| Step: 8
Training loss: 2.6618379942952077
Validation loss: 2.496890964067118

Epoch: 5| Step: 9
Training loss: 1.7658390151768513
Validation loss: 2.503815770808167

Epoch: 5| Step: 10
Training loss: 2.3584712236438983
Validation loss: 2.5092719120625766

Epoch: 5| Step: 11
Training loss: 2.250745226046431
Validation loss: 2.526813476999869

Epoch: 32| Step: 0
Training loss: 2.5726237471375284
Validation loss: 2.522880000523423

Epoch: 5| Step: 1
Training loss: 2.128426201969193
Validation loss: 2.4967192123409157

Epoch: 5| Step: 2
Training loss: 2.919032055053136
Validation loss: 2.5050767452922833

Epoch: 5| Step: 3
Training loss: 1.8830431405148202
Validation loss: 2.493397601284465

Epoch: 5| Step: 4
Training loss: 2.4988822345561177
Validation loss: 2.5231104147679053

Epoch: 5| Step: 5
Training loss: 2.35175269488844
Validation loss: 2.502646511697456

Epoch: 5| Step: 6
Training loss: 2.7989117755621327
Validation loss: 2.5094775478617555

Epoch: 5| Step: 7
Training loss: 1.876301250329628
Validation loss: 2.506832028187665

Epoch: 5| Step: 8
Training loss: 2.9748874867424577
Validation loss: 2.5163516975402613

Epoch: 5| Step: 9
Training loss: 2.5494753428746435
Validation loss: 2.4755861160709633

Epoch: 5| Step: 10
Training loss: 2.2626995272673303
Validation loss: 2.5076342130133993

Epoch: 5| Step: 11
Training loss: 2.7592312456748083
Validation loss: 2.500276395300809

Epoch: 33| Step: 0
Training loss: 2.6170300792208856
Validation loss: 2.5152197367256064

Epoch: 5| Step: 1
Training loss: 2.3023702060097198
Validation loss: 2.5344599789923756

Epoch: 5| Step: 2
Training loss: 2.050811127944556
Validation loss: 2.526937850125234

Epoch: 5| Step: 3
Training loss: 2.579335338970689
Validation loss: 2.511218700001842

Epoch: 5| Step: 4
Training loss: 2.7090573345719893
Validation loss: 2.50894656342153

Epoch: 5| Step: 5
Training loss: 2.281556618346818
Validation loss: 2.5230058117737966

Epoch: 5| Step: 6
Training loss: 1.978589191179974
Validation loss: 2.5136133526537856

Epoch: 5| Step: 7
Training loss: 2.574171143990284
Validation loss: 2.5226804701988312

Epoch: 5| Step: 8
Training loss: 2.786121431227849
Validation loss: 2.519907808380375

Epoch: 5| Step: 9
Training loss: 2.733333367448512
Validation loss: 2.5230740323799963

Epoch: 5| Step: 10
Training loss: 2.0184155449896486
Validation loss: 2.526868882688832

Epoch: 5| Step: 11
Training loss: 3.7558489644128987
Validation loss: 2.5071210531886563

Epoch: 34| Step: 0
Training loss: 2.026162216666541
Validation loss: 2.5094692070024296

Epoch: 5| Step: 1
Training loss: 2.7325496139280117
Validation loss: 2.5296417570700647

Epoch: 5| Step: 2
Training loss: 2.6117447012234747
Validation loss: 2.5044178472296186

Epoch: 5| Step: 3
Training loss: 2.1223871211397745
Validation loss: 2.519242294262388

Epoch: 5| Step: 4
Training loss: 2.6476869673085353
Validation loss: 2.519150800344776

Epoch: 5| Step: 5
Training loss: 2.409982733763579
Validation loss: 2.5214172716812535

Epoch: 5| Step: 6
Training loss: 2.2341060876749625
Validation loss: 2.5357541758989854

Epoch: 5| Step: 7
Training loss: 2.8304080073224496
Validation loss: 2.528635047918406

Epoch: 5| Step: 8
Training loss: 2.503591437344369
Validation loss: 2.530050641126011

Epoch: 5| Step: 9
Training loss: 2.2482481600400646
Validation loss: 2.523582418904183

Epoch: 5| Step: 10
Training loss: 2.6052605633010395
Validation loss: 2.5376277763003636

Epoch: 5| Step: 11
Training loss: 2.3453324125843653
Validation loss: 2.5080047644636334

Epoch: 35| Step: 0
Training loss: 2.079334566705274
Validation loss: 2.502991452188663

Epoch: 5| Step: 1
Training loss: 2.547790737164428
Validation loss: 2.5213637752831866

Epoch: 5| Step: 2
Training loss: 2.4897914357909166
Validation loss: 2.541872420086508

Epoch: 5| Step: 3
Training loss: 2.4272984967342883
Validation loss: 2.527783793327547

Epoch: 5| Step: 4
Training loss: 2.2335285637580933
Validation loss: 2.5204115047035156

Epoch: 5| Step: 5
Training loss: 2.6884052614954874
Validation loss: 2.498588133536014

Epoch: 5| Step: 6
Training loss: 2.802132295277658
Validation loss: 2.5058846495957563

Epoch: 5| Step: 7
Training loss: 2.689993211957457
Validation loss: 2.5066056719758483

Epoch: 5| Step: 8
Training loss: 2.174418873817153
Validation loss: 2.5012349098687046

Epoch: 5| Step: 9
Training loss: 2.5934531719921536
Validation loss: 2.508440024355359

Epoch: 5| Step: 10
Training loss: 2.0179607253851044
Validation loss: 2.493566671562624

Epoch: 5| Step: 11
Training loss: 3.0636868415339515
Validation loss: 2.5007695166103923

Epoch: 36| Step: 0
Training loss: 2.6090279536827783
Validation loss: 2.526471604139654

Epoch: 5| Step: 1
Training loss: 2.506101981569946
Validation loss: 2.5135490349920993

Epoch: 5| Step: 2
Training loss: 2.238758721944325
Validation loss: 2.5149145959531514

Epoch: 5| Step: 3
Training loss: 2.298569035088967
Validation loss: 2.5130992949628297

Epoch: 5| Step: 4
Training loss: 2.594754587523899
Validation loss: 2.5011087422642375

Epoch: 5| Step: 5
Training loss: 2.6093910810694596
Validation loss: 2.4942522374976908

Epoch: 5| Step: 6
Training loss: 2.0479015076840392
Validation loss: 2.5042518936565923

Epoch: 5| Step: 7
Training loss: 1.8583882382183665
Validation loss: 2.505127044331742

Epoch: 5| Step: 8
Training loss: 2.543516507316582
Validation loss: 2.511578494161013

Epoch: 5| Step: 9
Training loss: 2.967284473282894
Validation loss: 2.5014809791550388

Epoch: 5| Step: 10
Training loss: 2.3595132345162684
Validation loss: 2.5054197057006347

Epoch: 5| Step: 11
Training loss: 2.956627116435153
Validation loss: 2.508405233115215

Epoch: 37| Step: 0
Training loss: 2.188116368241597
Validation loss: 2.5167781919332297

Epoch: 5| Step: 1
Training loss: 2.6213018616151462
Validation loss: 2.5074883565445387

Epoch: 5| Step: 2
Training loss: 2.5309689212670947
Validation loss: 2.50336579408015

Epoch: 5| Step: 3
Training loss: 2.854146878436098
Validation loss: 2.5069625856184032

Epoch: 5| Step: 4
Training loss: 2.4242799692786723
Validation loss: 2.524559145705212

Epoch: 5| Step: 5
Training loss: 2.93543690407579
Validation loss: 2.506322953120836

Epoch: 5| Step: 6
Training loss: 2.2789518721195083
Validation loss: 2.4970849168151728

Epoch: 5| Step: 7
Training loss: 1.991559516812324
Validation loss: 2.510980496595278

Epoch: 5| Step: 8
Training loss: 1.8071937497865518
Validation loss: 2.5038294153034513

Epoch: 5| Step: 9
Training loss: 2.3716392832194093
Validation loss: 2.50438952530705

Epoch: 5| Step: 10
Training loss: 2.49384580346891
Validation loss: 2.537089871710174

Epoch: 5| Step: 11
Training loss: 2.7391161985731616
Validation loss: 2.5175881712372488

Epoch: 38| Step: 0
Training loss: 2.4592857994179926
Validation loss: 2.512266250668638

Epoch: 5| Step: 1
Training loss: 2.7170500428242357
Validation loss: 2.5273826041912604

Epoch: 5| Step: 2
Training loss: 2.345847043617887
Validation loss: 2.5478827934061727

Epoch: 5| Step: 3
Training loss: 2.488345925345459
Validation loss: 2.5159472028161174

Epoch: 5| Step: 4
Training loss: 3.1020630401364295
Validation loss: 2.5245500125838243

Epoch: 5| Step: 5
Training loss: 2.1760510152418435
Validation loss: 2.527240124110487

Epoch: 5| Step: 6
Training loss: 2.4386577302106107
Validation loss: 2.522395683623068

Epoch: 5| Step: 7
Training loss: 2.5885069836468335
Validation loss: 2.5391517310479985

Epoch: 5| Step: 8
Training loss: 1.6572582846523805
Validation loss: 2.5173868718784047

Epoch: 5| Step: 9
Training loss: 2.5535088949711486
Validation loss: 2.5338434543886317

Epoch: 5| Step: 10
Training loss: 2.444355055109018
Validation loss: 2.513321190839707

Epoch: 5| Step: 11
Training loss: 1.8893199861916956
Validation loss: 2.5177811530149894

Epoch: 39| Step: 0
Training loss: 2.398573682068781
Validation loss: 2.520008471732684

Epoch: 5| Step: 1
Training loss: 2.236960136027686
Validation loss: 2.5342713561778702

Epoch: 5| Step: 2
Training loss: 2.8460861503338353
Validation loss: 2.5033550002798135

Epoch: 5| Step: 3
Training loss: 2.819798726548732
Validation loss: 2.5086199291490425

Epoch: 5| Step: 4
Training loss: 2.2549247886481085
Validation loss: 2.4908998764477173

Epoch: 5| Step: 5
Training loss: 2.413908524525445
Validation loss: 2.512130533480339

Epoch: 5| Step: 6
Training loss: 3.0470379125617026
Validation loss: 2.506215289026951

Epoch: 5| Step: 7
Training loss: 2.200712357412008
Validation loss: 2.502157778165794

Epoch: 5| Step: 8
Training loss: 2.2884082054379147
Validation loss: 2.506512587244985

Epoch: 5| Step: 9
Training loss: 2.2764713978653615
Validation loss: 2.509626593987761

Epoch: 5| Step: 10
Training loss: 2.167695779197326
Validation loss: 2.485087302597736

Epoch: 5| Step: 11
Training loss: 2.1730436844487744
Validation loss: 2.5029441504644154

Epoch: 40| Step: 0
Training loss: 2.474284667861551
Validation loss: 2.4992126973555755

Epoch: 5| Step: 1
Training loss: 2.459243336586215
Validation loss: 2.4895429102490243

Epoch: 5| Step: 2
Training loss: 2.1502141091835556
Validation loss: 2.4929665451016145

Epoch: 5| Step: 3
Training loss: 2.646099487694916
Validation loss: 2.457983963327418

Epoch: 5| Step: 4
Training loss: 2.0087922670656866
Validation loss: 2.503936553152787

Epoch: 5| Step: 5
Training loss: 2.212823393727157
Validation loss: 2.509842816265415

Epoch: 5| Step: 6
Training loss: 2.0841745077130835
Validation loss: 2.5253187593686905

Epoch: 5| Step: 7
Training loss: 2.375017065689612
Validation loss: 2.5164124774668286

Epoch: 5| Step: 8
Training loss: 3.076774339565527
Validation loss: 2.4993792498336926

Epoch: 5| Step: 9
Training loss: 2.4354975373410936
Validation loss: 2.5121359866680373

Epoch: 5| Step: 10
Training loss: 2.767298994612967
Validation loss: 2.5250057862470445

Epoch: 5| Step: 11
Training loss: 2.189823224845558
Validation loss: 2.4816179431895713

Epoch: 41| Step: 0
Training loss: 1.850244688915294
Validation loss: 2.517471157314086

Epoch: 5| Step: 1
Training loss: 2.98161148023061
Validation loss: 2.5038533158045686

Epoch: 5| Step: 2
Training loss: 2.084306400662936
Validation loss: 2.5129346816295803

Epoch: 5| Step: 3
Training loss: 2.123639961791286
Validation loss: 2.5150712827448554

Epoch: 5| Step: 4
Training loss: 2.1135041688688885
Validation loss: 2.519126559933141

Epoch: 5| Step: 5
Training loss: 2.3748423875410385
Validation loss: 2.5342427916562102

Epoch: 5| Step: 6
Training loss: 2.3903654867696185
Validation loss: 2.503044069246261

Epoch: 5| Step: 7
Training loss: 2.995000647288461
Validation loss: 2.5085072966118407

Epoch: 5| Step: 8
Training loss: 2.907135531147449
Validation loss: 2.504753848121424

Epoch: 5| Step: 9
Training loss: 1.7994982602936989
Validation loss: 2.5067461069772463

Epoch: 5| Step: 10
Training loss: 2.6384194095890052
Validation loss: 2.503884793971709

Epoch: 5| Step: 11
Training loss: 3.2040180729083656
Validation loss: 2.513803659900495

Epoch: 42| Step: 0
Training loss: 2.3100205609616182
Validation loss: 2.513165074822432

Epoch: 5| Step: 1
Training loss: 2.518226747140179
Validation loss: 2.5046468384397618

Epoch: 5| Step: 2
Training loss: 2.2035114138839726
Validation loss: 2.488872128550356

Epoch: 5| Step: 3
Training loss: 2.643785560314645
Validation loss: 2.4916306255172898

Epoch: 5| Step: 4
Training loss: 2.311817687129366
Validation loss: 2.4883184085868066

Epoch: 5| Step: 5
Training loss: 2.5731419350134206
Validation loss: 2.4910347284425267

Epoch: 5| Step: 6
Training loss: 2.295815775043157
Validation loss: 2.4962158969210866

Epoch: 5| Step: 7
Training loss: 2.5474081593019453
Validation loss: 2.514483283585388

Epoch: 5| Step: 8
Training loss: 2.2947108654654524
Validation loss: 2.4898387639570627

Epoch: 5| Step: 9
Training loss: 2.7742541333205826
Validation loss: 2.489374029600079

Epoch: 5| Step: 10
Training loss: 2.3975278639143798
Validation loss: 2.5020834863764843

Epoch: 5| Step: 11
Training loss: 2.5344556125374553
Validation loss: 2.4867421834522485

Epoch: 43| Step: 0
Training loss: 2.349257140738699
Validation loss: 2.4967270208503036

Epoch: 5| Step: 1
Training loss: 2.6121202293228665
Validation loss: 2.485254913629266

Epoch: 5| Step: 2
Training loss: 2.245677823242511
Validation loss: 2.474417494611071

Epoch: 5| Step: 3
Training loss: 2.8064919620183373
Validation loss: 2.473578652141504

Epoch: 5| Step: 4
Training loss: 1.947570899289836
Validation loss: 2.4824140755175446

Epoch: 5| Step: 5
Training loss: 2.807470784226377
Validation loss: 2.487461184513502

Epoch: 5| Step: 6
Training loss: 2.450825871215515
Validation loss: 2.503692895584376

Epoch: 5| Step: 7
Training loss: 2.154862883735059
Validation loss: 2.5120107027231295

Epoch: 5| Step: 8
Training loss: 2.6789426074115386
Validation loss: 2.485514589370088

Epoch: 5| Step: 9
Training loss: 1.9297831893856052
Validation loss: 2.5146359894577115

Epoch: 5| Step: 10
Training loss: 2.674013408652949
Validation loss: 2.494261923648143

Epoch: 5| Step: 11
Training loss: 1.6417675581135922
Validation loss: 2.510868262725242

Epoch: 44| Step: 0
Training loss: 2.666398352793755
Validation loss: 2.50139242773943

Epoch: 5| Step: 1
Training loss: 2.174909817810083
Validation loss: 2.494943623437791

Epoch: 5| Step: 2
Training loss: 2.20563358848934
Validation loss: 2.493414641499957

Epoch: 5| Step: 3
Training loss: 2.9171571228374535
Validation loss: 2.5106630257197557

Epoch: 5| Step: 4
Training loss: 2.060577999801954
Validation loss: 2.4917124511718236

Epoch: 5| Step: 5
Training loss: 1.9943621565627294
Validation loss: 2.4886457454738915

Epoch: 5| Step: 6
Training loss: 2.9360049075051853
Validation loss: 2.4895815563328574

Epoch: 5| Step: 7
Training loss: 2.5458697810168003
Validation loss: 2.495918705572848

Epoch: 5| Step: 8
Training loss: 2.3258606825063084
Validation loss: 2.4953512560996303

Epoch: 5| Step: 9
Training loss: 2.1760529874072243
Validation loss: 2.514218717233731

Epoch: 5| Step: 10
Training loss: 2.5555832718530227
Validation loss: 2.5057084872377593

Epoch: 5| Step: 11
Training loss: 2.4031332067937323
Validation loss: 2.493493550084132

Epoch: 45| Step: 0
Training loss: 1.9567569989739266
Validation loss: 2.4949158230802673

Epoch: 5| Step: 1
Training loss: 2.0893825699523307
Validation loss: 2.51350572220203

Epoch: 5| Step: 2
Training loss: 2.0605089229324816
Validation loss: 2.510641239668643

Epoch: 5| Step: 3
Training loss: 2.4617113622362665
Validation loss: 2.511294671739376

Epoch: 5| Step: 4
Training loss: 2.5289610886542415
Validation loss: 2.5315789609420274

Epoch: 5| Step: 5
Training loss: 3.007662682703505
Validation loss: 2.528971757453804

Epoch: 5| Step: 6
Training loss: 2.7089254954566955
Validation loss: 2.5249453902240617

Epoch: 5| Step: 7
Training loss: 2.5186376125355565
Validation loss: 2.51989226798154

Epoch: 5| Step: 8
Training loss: 1.845525565512658
Validation loss: 2.545940013019743

Epoch: 5| Step: 9
Training loss: 2.3795221342663275
Validation loss: 2.5443752401450674

Epoch: 5| Step: 10
Training loss: 3.119176397434975
Validation loss: 2.545531193357948

Epoch: 5| Step: 11
Training loss: 1.7967912737372067
Validation loss: 2.5079056632383674

Epoch: 46| Step: 0
Training loss: 2.50004606204514
Validation loss: 2.499501095104798

Epoch: 5| Step: 1
Training loss: 2.2442223224426874
Validation loss: 2.5060076730384377

Epoch: 5| Step: 2
Training loss: 3.019896807139119
Validation loss: 2.4666574196599207

Epoch: 5| Step: 3
Training loss: 2.1976568662098095
Validation loss: 2.484402174571104

Epoch: 5| Step: 4
Training loss: 1.6425718110061835
Validation loss: 2.496929154268316

Epoch: 5| Step: 5
Training loss: 2.463265035849943
Validation loss: 2.5119460276464274

Epoch: 5| Step: 6
Training loss: 3.1399535415030986
Validation loss: 2.4949965157290217

Epoch: 5| Step: 7
Training loss: 2.4443882179536867
Validation loss: 2.492604710048013

Epoch: 5| Step: 8
Training loss: 2.028759177440444
Validation loss: 2.4861444573738174

Epoch: 5| Step: 9
Training loss: 2.75663814449969
Validation loss: 2.5022342195417577

Epoch: 5| Step: 10
Training loss: 2.417496790760518
Validation loss: 2.473774627423529

Epoch: 5| Step: 11
Training loss: 2.4234136800376254
Validation loss: 2.4882160599421743

Epoch: 47| Step: 0
Training loss: 1.810197617507191
Validation loss: 2.483713641797293

Epoch: 5| Step: 1
Training loss: 3.0422295001735282
Validation loss: 2.4998476756897374

Epoch: 5| Step: 2
Training loss: 2.6492031194821446
Validation loss: 2.5104775948998928

Epoch: 5| Step: 3
Training loss: 2.7489342791936084
Validation loss: 2.511447514136633

Epoch: 5| Step: 4
Training loss: 2.3763569418789054
Validation loss: 2.5238442521258264

Epoch: 5| Step: 5
Training loss: 1.8847774525009398
Validation loss: 2.5294403546066095

Epoch: 5| Step: 6
Training loss: 2.2200078488116657
Validation loss: 2.514375866188041

Epoch: 5| Step: 7
Training loss: 2.2617451035408727
Validation loss: 2.5199513166508605

Epoch: 5| Step: 8
Training loss: 2.6764493456258287
Validation loss: 2.542479402070456

Epoch: 5| Step: 9
Training loss: 2.1411126688104885
Validation loss: 2.5269979508629037

Epoch: 5| Step: 10
Training loss: 2.415540915305138
Validation loss: 2.537907790707783

Epoch: 5| Step: 11
Training loss: 3.1624676487892605
Validation loss: 2.555292736379952

Epoch: 48| Step: 0
Training loss: 2.8965768934355878
Validation loss: 2.5228465857775046

Epoch: 5| Step: 1
Training loss: 2.73225067453082
Validation loss: 2.5017464815716504

Epoch: 5| Step: 2
Training loss: 2.1952527672728803
Validation loss: 2.4950229136753257

Epoch: 5| Step: 3
Training loss: 2.594399795946742
Validation loss: 2.4847754629534378

Epoch: 5| Step: 4
Training loss: 2.2748936974139453
Validation loss: 2.490738227086123

Epoch: 5| Step: 5
Training loss: 2.338218366425462
Validation loss: 2.515245748645155

Epoch: 5| Step: 6
Training loss: 2.7450308553771587
Validation loss: 2.4881395172842944

Epoch: 5| Step: 7
Training loss: 2.6247670206494917
Validation loss: 2.4967787434019764

Epoch: 5| Step: 8
Training loss: 2.2569119990698376
Validation loss: 2.4812034620185446

Epoch: 5| Step: 9
Training loss: 2.242821048987632
Validation loss: 2.5011377189576307

Epoch: 5| Step: 10
Training loss: 2.187702496556591
Validation loss: 2.501681962060731

Epoch: 5| Step: 11
Training loss: 1.394996458616513
Validation loss: 2.4959413206294827

Epoch: 49| Step: 0
Training loss: 2.6150192160839434
Validation loss: 2.4889596825656652

Epoch: 5| Step: 1
Training loss: 2.4025959161671477
Validation loss: 2.497551533629083

Epoch: 5| Step: 2
Training loss: 2.0820948034610156
Validation loss: 2.4858030337593826

Epoch: 5| Step: 3
Training loss: 2.245425023582293
Validation loss: 2.4854101947296203

Epoch: 5| Step: 4
Training loss: 2.4487239940249643
Validation loss: 2.5018058334460367

Epoch: 5| Step: 5
Training loss: 2.695324353178194
Validation loss: 2.4944849734977423

Epoch: 5| Step: 6
Training loss: 2.436261278011862
Validation loss: 2.512829291335778

Epoch: 5| Step: 7
Training loss: 2.6063558506682276
Validation loss: 2.512007954244209

Epoch: 5| Step: 8
Training loss: 2.1670269544304306
Validation loss: 2.5399454078289323

Epoch: 5| Step: 9
Training loss: 2.588552668117629
Validation loss: 2.570621240039453

Epoch: 5| Step: 10
Training loss: 2.294992726632355
Validation loss: 2.551362945452658

Epoch: 5| Step: 11
Training loss: 3.628835556277914
Validation loss: 2.542680699626617

Epoch: 50| Step: 0
Training loss: 1.9760675828434415
Validation loss: 2.526529773601649

Epoch: 5| Step: 1
Training loss: 2.444079200834869
Validation loss: 2.5162241184787857

Epoch: 5| Step: 2
Training loss: 2.409216105445258
Validation loss: 2.513501402343638

Epoch: 5| Step: 3
Training loss: 2.906713633318247
Validation loss: 2.4947131123980726

Epoch: 5| Step: 4
Training loss: 2.1639789881928917
Validation loss: 2.507654535660344

Epoch: 5| Step: 5
Training loss: 1.939405242851309
Validation loss: 2.5007507309644823

Epoch: 5| Step: 6
Training loss: 2.2986482794587544
Validation loss: 2.4842979571154578

Epoch: 5| Step: 7
Training loss: 2.844568658722621
Validation loss: 2.4885281490716196

Epoch: 5| Step: 8
Training loss: 2.899476063194873
Validation loss: 2.4950085521123326

Epoch: 5| Step: 9
Training loss: 2.491874268557764
Validation loss: 2.4851787714420883

Epoch: 5| Step: 10
Training loss: 2.2755841479868617
Validation loss: 2.4880278741296253

Epoch: 5| Step: 11
Training loss: 1.3122789105896913
Validation loss: 2.4776600392293733

Epoch: 51| Step: 0
Training loss: 2.2706874718906653
Validation loss: 2.4952002305596275

Epoch: 5| Step: 1
Training loss: 2.3046074287600047
Validation loss: 2.493384210469931

Epoch: 5| Step: 2
Training loss: 2.040115376930968
Validation loss: 2.5030593987296887

Epoch: 5| Step: 3
Training loss: 2.887248278458221
Validation loss: 2.4961179713196846

Epoch: 5| Step: 4
Training loss: 2.376569931750995
Validation loss: 2.484829283311993

Epoch: 5| Step: 5
Training loss: 2.3645561877693684
Validation loss: 2.5036591374680173

Epoch: 5| Step: 6
Training loss: 2.3767664513990114
Validation loss: 2.497074553369594

Epoch: 5| Step: 7
Training loss: 2.4124646871087316
Validation loss: 2.5081267749188516

Epoch: 5| Step: 8
Training loss: 2.514123883395966
Validation loss: 2.499316125952037

Epoch: 5| Step: 9
Training loss: 2.630569090825722
Validation loss: 2.5130866534585197

Epoch: 5| Step: 10
Training loss: 2.243875114331687
Validation loss: 2.5171589271791235

Epoch: 5| Step: 11
Training loss: 2.8631620083032354
Validation loss: 2.4986944803224556

Epoch: 52| Step: 0
Training loss: 2.7377140257618264
Validation loss: 2.5176913026594847

Epoch: 5| Step: 1
Training loss: 2.6817617145935735
Validation loss: 2.5193723091244236

Epoch: 5| Step: 2
Training loss: 2.5822230280814535
Validation loss: 2.4919321054881145

Epoch: 5| Step: 3
Training loss: 2.2403142992976344
Validation loss: 2.5126076604067302

Epoch: 5| Step: 4
Training loss: 2.3890187969913357
Validation loss: 2.4816257291619275

Epoch: 5| Step: 5
Training loss: 2.1545419977202083
Validation loss: 2.4768074588388864

Epoch: 5| Step: 6
Training loss: 2.4506846152586785
Validation loss: 2.4885185124589677

Epoch: 5| Step: 7
Training loss: 2.3483392163165306
Validation loss: 2.4930429216263708

Epoch: 5| Step: 8
Training loss: 2.275126141415149
Validation loss: 2.497335619527066

Epoch: 5| Step: 9
Training loss: 2.3341470956940906
Validation loss: 2.4967428009277257

Epoch: 5| Step: 10
Training loss: 2.135590808249736
Validation loss: 2.4992565082616545

Epoch: 5| Step: 11
Training loss: 3.2278609722692253
Validation loss: 2.4900913292184828

Epoch: 53| Step: 0
Training loss: 2.3991227056519855
Validation loss: 2.4939278432424588

Epoch: 5| Step: 1
Training loss: 1.99808965284806
Validation loss: 2.4758735765516073

Epoch: 5| Step: 2
Training loss: 2.77948353422736
Validation loss: 2.4939623245956386

Epoch: 5| Step: 3
Training loss: 2.5060110306432346
Validation loss: 2.4893612716044693

Epoch: 5| Step: 4
Training loss: 2.1497460281826912
Validation loss: 2.4998479637963915

Epoch: 5| Step: 5
Training loss: 2.4204942274239523
Validation loss: 2.5008913159939214

Epoch: 5| Step: 6
Training loss: 2.615817312009451
Validation loss: 2.497347586957658

Epoch: 5| Step: 7
Training loss: 2.242329875399934
Validation loss: 2.4687708801481048

Epoch: 5| Step: 8
Training loss: 2.49350658175233
Validation loss: 2.4812289737544

Epoch: 5| Step: 9
Training loss: 2.166148368269573
Validation loss: 2.4970905679580664

Epoch: 5| Step: 10
Training loss: 2.858824796844881
Validation loss: 2.4630814109597106

Epoch: 5| Step: 11
Training loss: 1.2175882132843214
Validation loss: 2.4836315346149855

Epoch: 54| Step: 0
Training loss: 2.1800384785817255
Validation loss: 2.4960856828076654

Epoch: 5| Step: 1
Training loss: 2.704802857863849
Validation loss: 2.497439849805059

Epoch: 5| Step: 2
Training loss: 2.216904961055787
Validation loss: 2.4890903652536744

Epoch: 5| Step: 3
Training loss: 2.44432559832262
Validation loss: 2.4992972220633773

Epoch: 5| Step: 4
Training loss: 1.9945702160123102
Validation loss: 2.5030216731486883

Epoch: 5| Step: 5
Training loss: 1.9520904242333512
Validation loss: 2.496988895159609

Epoch: 5| Step: 6
Training loss: 2.1402602058936395
Validation loss: 2.4945954575495417

Epoch: 5| Step: 7
Training loss: 2.2677930258579337
Validation loss: 2.4945832658556046

Epoch: 5| Step: 8
Training loss: 3.05102006707708
Validation loss: 2.5207572260840734

Epoch: 5| Step: 9
Training loss: 3.316971837354035
Validation loss: 2.500505745912492

Epoch: 5| Step: 10
Training loss: 2.1596606274074013
Validation loss: 2.519731392414836

Epoch: 5| Step: 11
Training loss: 1.5777892709292558
Validation loss: 2.5031878451976155

Epoch: 55| Step: 0
Training loss: 2.3432036716769735
Validation loss: 2.5096970248216763

Epoch: 5| Step: 1
Training loss: 1.5785686511389496
Validation loss: 2.4988340798245865

Epoch: 5| Step: 2
Training loss: 2.308518358474451
Validation loss: 2.5369148835697186

Epoch: 5| Step: 3
Training loss: 2.5558999826924174
Validation loss: 2.5075060458124665

Epoch: 5| Step: 4
Training loss: 2.3258301350175095
Validation loss: 2.5459827740309504

Epoch: 5| Step: 5
Training loss: 2.2523596364445813
Validation loss: 2.51611147692395

Epoch: 5| Step: 6
Training loss: 2.2357338994574802
Validation loss: 2.5252025639451543

Epoch: 5| Step: 7
Training loss: 2.6842167338032787
Validation loss: 2.5321960408148594

Epoch: 5| Step: 8
Training loss: 2.118581277886681
Validation loss: 2.5273250793364848

Epoch: 5| Step: 9
Training loss: 3.231775981070051
Validation loss: 2.521029934953676

Epoch: 5| Step: 10
Training loss: 2.52533832209711
Validation loss: 2.502832846195065

Epoch: 5| Step: 11
Training loss: 2.7617974816394204
Validation loss: 2.494726667307359

Epoch: 56| Step: 0
Training loss: 2.549472069787242
Validation loss: 2.4990851794783895

Epoch: 5| Step: 1
Training loss: 2.013935771118744
Validation loss: 2.4972335330439184

Epoch: 5| Step: 2
Training loss: 2.103564815247156
Validation loss: 2.4911778416784816

Epoch: 5| Step: 3
Training loss: 2.4131361285755557
Validation loss: 2.4882286221913814

Epoch: 5| Step: 4
Training loss: 1.6635917749981672
Validation loss: 2.5008540125340075

Epoch: 5| Step: 5
Training loss: 2.2508243534154277
Validation loss: 2.496730685370366

Epoch: 5| Step: 6
Training loss: 2.539095552669481
Validation loss: 2.4884280566190786

Epoch: 5| Step: 7
Training loss: 2.9411979287430623
Validation loss: 2.498368155841357

Epoch: 5| Step: 8
Training loss: 2.803285040906266
Validation loss: 2.485869983497124

Epoch: 5| Step: 9
Training loss: 2.4891191206704444
Validation loss: 2.456089160593835

Epoch: 5| Step: 10
Training loss: 2.566662083246011
Validation loss: 2.4716823240758687

Epoch: 5| Step: 11
Training loss: 2.3675621416099655
Validation loss: 2.5069322318651106

Epoch: 57| Step: 0
Training loss: 2.154638047235198
Validation loss: 2.4708688552215756

Epoch: 5| Step: 1
Training loss: 2.5364918063629416
Validation loss: 2.5020701777810856

Epoch: 5| Step: 2
Training loss: 2.2303575798696564
Validation loss: 2.4785229397488697

Epoch: 5| Step: 3
Training loss: 1.8930228924220993
Validation loss: 2.481645272045087

Epoch: 5| Step: 4
Training loss: 2.352524874126994
Validation loss: 2.4723826734633123

Epoch: 5| Step: 5
Training loss: 1.9130731010687905
Validation loss: 2.47901971499031

Epoch: 5| Step: 6
Training loss: 2.9556868809211365
Validation loss: 2.464953025656583

Epoch: 5| Step: 7
Training loss: 2.4963758903166795
Validation loss: 2.4961442698508676

Epoch: 5| Step: 8
Training loss: 2.3485234796212437
Validation loss: 2.488472620273772

Epoch: 5| Step: 9
Training loss: 2.5706943587747983
Validation loss: 2.473646968856767

Epoch: 5| Step: 10
Training loss: 3.0505966540963567
Validation loss: 2.5104594497411843

Epoch: 5| Step: 11
Training loss: 1.6951689769271687
Validation loss: 2.4937938627370713

Epoch: 58| Step: 0
Training loss: 2.4698761894300048
Validation loss: 2.466673247118068

Epoch: 5| Step: 1
Training loss: 2.1503396231747014
Validation loss: 2.5098280506806305

Epoch: 5| Step: 2
Training loss: 2.091263960514111
Validation loss: 2.4942310250154347

Epoch: 5| Step: 3
Training loss: 2.635544895676271
Validation loss: 2.5055308197202675

Epoch: 5| Step: 4
Training loss: 2.408459924276953
Validation loss: 2.5044589332812848

Epoch: 5| Step: 5
Training loss: 2.5179889068601553
Validation loss: 2.4870659991113118

Epoch: 5| Step: 6
Training loss: 2.2411794489890364
Validation loss: 2.4800861293823577

Epoch: 5| Step: 7
Training loss: 2.0487542298176122
Validation loss: 2.494387864076735

Epoch: 5| Step: 8
Training loss: 2.444226593607814
Validation loss: 2.4986940072118338

Epoch: 5| Step: 9
Training loss: 2.6184514424059486
Validation loss: 2.481301659943885

Epoch: 5| Step: 10
Training loss: 2.678901312359887
Validation loss: 2.495063957348282

Epoch: 5| Step: 11
Training loss: 2.6841730328255116
Validation loss: 2.5056014806617815

Epoch: 59| Step: 0
Training loss: 2.17272295967739
Validation loss: 2.4885997638225352

Epoch: 5| Step: 1
Training loss: 2.8197152728548147
Validation loss: 2.5188236396190917

Epoch: 5| Step: 2
Training loss: 2.506560206063256
Validation loss: 2.515802258708894

Epoch: 5| Step: 3
Training loss: 2.134628919742258
Validation loss: 2.501151058331425

Epoch: 5| Step: 4
Training loss: 2.097927424060121
Validation loss: 2.5008765869336425

Epoch: 5| Step: 5
Training loss: 2.29155951740732
Validation loss: 2.5259054022672043

Epoch: 5| Step: 6
Training loss: 1.7819297564284324
Validation loss: 2.531142307078457

Epoch: 5| Step: 7
Training loss: 2.900155352673562
Validation loss: 2.4903008027036764

Epoch: 5| Step: 8
Training loss: 2.2180163822790187
Validation loss: 2.508604203983219

Epoch: 5| Step: 9
Training loss: 2.493811577440616
Validation loss: 2.497452232405533

Epoch: 5| Step: 10
Training loss: 2.2685946240565635
Validation loss: 2.4900430683129

Epoch: 5| Step: 11
Training loss: 4.507525615058682
Validation loss: 2.501750833640251

Epoch: 60| Step: 0
Training loss: 2.4657964301133055
Validation loss: 2.4858572274991877

Epoch: 5| Step: 1
Training loss: 2.648673258052715
Validation loss: 2.485066605515779

Epoch: 5| Step: 2
Training loss: 2.2862819409524695
Validation loss: 2.4636023892317924

Epoch: 5| Step: 3
Training loss: 2.2466823702224703
Validation loss: 2.4961923093246807

Epoch: 5| Step: 4
Training loss: 2.1904282725070665
Validation loss: 2.499929101256535

Epoch: 5| Step: 5
Training loss: 2.240668337095607
Validation loss: 2.4876025445526904

Epoch: 5| Step: 6
Training loss: 2.2890134422070867
Validation loss: 2.492876760741574

Epoch: 5| Step: 7
Training loss: 2.261016367688127
Validation loss: 2.4856460526722404

Epoch: 5| Step: 8
Training loss: 2.171599446112913
Validation loss: 2.4835072927435102

Epoch: 5| Step: 9
Training loss: 2.6882638067662348
Validation loss: 2.5003799110075384

Epoch: 5| Step: 10
Training loss: 2.5389630576981053
Validation loss: 2.4769927893523263

Epoch: 5| Step: 11
Training loss: 3.550145191930756
Validation loss: 2.505028424111255

Epoch: 61| Step: 0
Training loss: 2.5085721870667004
Validation loss: 2.488106037241071

Epoch: 5| Step: 1
Training loss: 2.2975774196992185
Validation loss: 2.4823437069907106

Epoch: 5| Step: 2
Training loss: 2.022514456755057
Validation loss: 2.4901854047759833

Epoch: 5| Step: 3
Training loss: 2.503207152276993
Validation loss: 2.4951793287169686

Epoch: 5| Step: 4
Training loss: 2.1953110881542948
Validation loss: 2.4959760706805976

Epoch: 5| Step: 5
Training loss: 2.6801676417342017
Validation loss: 2.481773754063449

Epoch: 5| Step: 6
Training loss: 1.7296608444682433
Validation loss: 2.5056737611510425

Epoch: 5| Step: 7
Training loss: 2.8537772996676933
Validation loss: 2.4786436420122913

Epoch: 5| Step: 8
Training loss: 2.9274512949995817
Validation loss: 2.48935873356564

Epoch: 5| Step: 9
Training loss: 2.3219480562076145
Validation loss: 2.4645425418005047

Epoch: 5| Step: 10
Training loss: 2.0953885399591967
Validation loss: 2.49201693693603

Epoch: 5| Step: 11
Training loss: 1.8582719367908598
Validation loss: 2.465658549929438

Epoch: 62| Step: 0
Training loss: 2.2430964631194277
Validation loss: 2.4689938267885196

Epoch: 5| Step: 1
Training loss: 1.8167299699982302
Validation loss: 2.490588130382874

Epoch: 5| Step: 2
Training loss: 2.164683669417164
Validation loss: 2.5011868441219827

Epoch: 5| Step: 3
Training loss: 2.183832854962927
Validation loss: 2.503479606316538

Epoch: 5| Step: 4
Training loss: 2.6899868304699575
Validation loss: 2.52210679216082

Epoch: 5| Step: 5
Training loss: 2.0072160718138328
Validation loss: 2.5131040878867847

Epoch: 5| Step: 6
Training loss: 2.5615101274732828
Validation loss: 2.54637268979337

Epoch: 5| Step: 7
Training loss: 2.1509990056743655
Validation loss: 2.526860827257553

Epoch: 5| Step: 8
Training loss: 2.7001066610673248
Validation loss: 2.5250579839129585

Epoch: 5| Step: 9
Training loss: 2.4038729135050896
Validation loss: 2.526905300859149

Epoch: 5| Step: 10
Training loss: 3.1651927295116824
Validation loss: 2.5273023520395164

Epoch: 5| Step: 11
Training loss: 2.8109424940895047
Validation loss: 2.5262518031752323

Epoch: 63| Step: 0
Training loss: 2.026523431476368
Validation loss: 2.498201500166131

Epoch: 5| Step: 1
Training loss: 2.617414322318913
Validation loss: 2.5045689396710893

Epoch: 5| Step: 2
Training loss: 2.7366140734892155
Validation loss: 2.4981919147856178

Epoch: 5| Step: 3
Training loss: 2.464983227345815
Validation loss: 2.4848116345047178

Epoch: 5| Step: 4
Training loss: 2.4007905730871184
Validation loss: 2.4937841588344263

Epoch: 5| Step: 5
Training loss: 2.3404591153980046
Validation loss: 2.485190935321555

Epoch: 5| Step: 6
Training loss: 1.5746363235094343
Validation loss: 2.4669680864444765

Epoch: 5| Step: 7
Training loss: 3.198432872416657
Validation loss: 2.495960333516609

Epoch: 5| Step: 8
Training loss: 2.00196324787837
Validation loss: 2.48734401137109

Epoch: 5| Step: 9
Training loss: 2.3893958029513698
Validation loss: 2.481340110097046

Epoch: 5| Step: 10
Training loss: 2.2234593232853817
Validation loss: 2.475385315921342

Epoch: 5| Step: 11
Training loss: 2.2492647029187975
Validation loss: 2.5003346676140388

Epoch: 64| Step: 0
Training loss: 2.196490748784768
Validation loss: 2.480085961149278

Epoch: 5| Step: 1
Training loss: 2.1098384771851117
Validation loss: 2.487661427223184

Epoch: 5| Step: 2
Training loss: 2.552884366708119
Validation loss: 2.4927075400525904

Epoch: 5| Step: 3
Training loss: 2.7741019299296052
Validation loss: 2.4894160223781383

Epoch: 5| Step: 4
Training loss: 2.23682296142417
Validation loss: 2.475777610967932

Epoch: 5| Step: 5
Training loss: 2.123700137032931
Validation loss: 2.4891884436057583

Epoch: 5| Step: 6
Training loss: 2.420319285177001
Validation loss: 2.4732140850442823

Epoch: 5| Step: 7
Training loss: 2.087057091787938
Validation loss: 2.4700939286862953

Epoch: 5| Step: 8
Training loss: 1.932060419796446
Validation loss: 2.508742384861804

Epoch: 5| Step: 9
Training loss: 3.032164131050124
Validation loss: 2.500552140299275

Epoch: 5| Step: 10
Training loss: 2.7840185209074777
Validation loss: 2.491205745558523

Epoch: 5| Step: 11
Training loss: 3.181769062257591
Validation loss: 2.4969342626955666

Epoch: 65| Step: 0
Training loss: 2.169856938335571
Validation loss: 2.4675404305674116

Epoch: 5| Step: 1
Training loss: 2.718600828090416
Validation loss: 2.5070230938969065

Epoch: 5| Step: 2
Training loss: 2.5783363024499915
Validation loss: 2.5049119815032794

Epoch: 5| Step: 3
Training loss: 2.149306353964492
Validation loss: 2.4972938593682463

Epoch: 5| Step: 4
Training loss: 2.1225113601290695
Validation loss: 2.488876616886113

Epoch: 5| Step: 5
Training loss: 2.441282125750931
Validation loss: 2.4907182011542344

Epoch: 5| Step: 6
Training loss: 2.612106355642836
Validation loss: 2.5008030833362094

Epoch: 5| Step: 7
Training loss: 1.772005149730493
Validation loss: 2.50204030067946

Epoch: 5| Step: 8
Training loss: 2.2951746245459024
Validation loss: 2.4751967626444142

Epoch: 5| Step: 9
Training loss: 3.0709274491510246
Validation loss: 2.498451659429052

Epoch: 5| Step: 10
Training loss: 2.173148570817455
Validation loss: 2.497705437751899

Epoch: 5| Step: 11
Training loss: 2.0673974585791437
Validation loss: 2.5008997887392934

Epoch: 66| Step: 0
Training loss: 2.7834148768131644
Validation loss: 2.5071959564574806

Epoch: 5| Step: 1
Training loss: 2.6859447503560703
Validation loss: 2.4873378088964606

Epoch: 5| Step: 2
Training loss: 2.3442711822864335
Validation loss: 2.4885981431324584

Epoch: 5| Step: 3
Training loss: 2.2903325330014535
Validation loss: 2.4712759346566684

Epoch: 5| Step: 4
Training loss: 2.9728330141063664
Validation loss: 2.486244288147556

Epoch: 5| Step: 5
Training loss: 1.7737602578767784
Validation loss: 2.4768421444417115

Epoch: 5| Step: 6
Training loss: 2.4931281057679366
Validation loss: 2.47197863156199

Epoch: 5| Step: 7
Training loss: 2.169834523198196
Validation loss: 2.460267194659218

Epoch: 5| Step: 8
Training loss: 2.736733514787864
Validation loss: 2.4780691038725204

Epoch: 5| Step: 9
Training loss: 1.9361087972674902
Validation loss: 2.479247832505658

Epoch: 5| Step: 10
Training loss: 2.038333572529082
Validation loss: 2.498162941700618

Epoch: 5| Step: 11
Training loss: 1.61853185236867
Validation loss: 2.4774400498058946

Epoch: 67| Step: 0
Training loss: 2.283169396170084
Validation loss: 2.4874262655853974

Epoch: 5| Step: 1
Training loss: 2.3775796432873832
Validation loss: 2.4932596656767254

Epoch: 5| Step: 2
Training loss: 2.6011040544239896
Validation loss: 2.4914871435548847

Epoch: 5| Step: 3
Training loss: 2.629504562243406
Validation loss: 2.480549640287737

Epoch: 5| Step: 4
Training loss: 2.366619986311054
Validation loss: 2.4997478258582753

Epoch: 5| Step: 5
Training loss: 2.16724005472478
Validation loss: 2.517717707286004

Epoch: 5| Step: 6
Training loss: 2.0878611634819193
Validation loss: 2.491544961561783

Epoch: 5| Step: 7
Training loss: 2.290495440265586
Validation loss: 2.5211712529284105

Epoch: 5| Step: 8
Training loss: 3.0326179485230416
Validation loss: 2.5003411775481283

Epoch: 5| Step: 9
Training loss: 1.8012998417583963
Validation loss: 2.5225842729170425

Epoch: 5| Step: 10
Training loss: 2.296816662936354
Validation loss: 2.507670864966098

Epoch: 5| Step: 11
Training loss: 2.7729355048827773
Validation loss: 2.5154632413679696

Epoch: 68| Step: 0
Training loss: 1.906747721747596
Validation loss: 2.491008088832919

Epoch: 5| Step: 1
Training loss: 1.9690196745719222
Validation loss: 2.5015297620109567

Epoch: 5| Step: 2
Training loss: 2.7863154199380884
Validation loss: 2.4944133544709315

Epoch: 5| Step: 3
Training loss: 2.1550822758734043
Validation loss: 2.490694653228305

Epoch: 5| Step: 4
Training loss: 2.2233022277387122
Validation loss: 2.491592822580742

Epoch: 5| Step: 5
Training loss: 2.9129634963163515
Validation loss: 2.503500319817179

Epoch: 5| Step: 6
Training loss: 2.872430897438454
Validation loss: 2.4958447872964693

Epoch: 5| Step: 7
Training loss: 2.2744784249829433
Validation loss: 2.493909171369824

Epoch: 5| Step: 8
Training loss: 2.669763812930555
Validation loss: 2.4621318280495794

Epoch: 5| Step: 9
Training loss: 2.476078696181985
Validation loss: 2.4823985925318444

Epoch: 5| Step: 10
Training loss: 1.8410571201503696
Validation loss: 2.4842354877254444

Epoch: 5| Step: 11
Training loss: 1.5552541955554946
Validation loss: 2.473306772195685

Epoch: 69| Step: 0
Training loss: 2.815402673544742
Validation loss: 2.487435860501829

Epoch: 5| Step: 1
Training loss: 2.5864977272977936
Validation loss: 2.495620507563378

Epoch: 5| Step: 2
Training loss: 1.8630875780710423
Validation loss: 2.475697367290277

Epoch: 5| Step: 3
Training loss: 2.6394349074288987
Validation loss: 2.4850918357453544

Epoch: 5| Step: 4
Training loss: 1.8406230466667135
Validation loss: 2.5135996822254687

Epoch: 5| Step: 5
Training loss: 2.2325481068723945
Validation loss: 2.496618244622996

Epoch: 5| Step: 6
Training loss: 2.550688340275289
Validation loss: 2.498861045475443

Epoch: 5| Step: 7
Training loss: 2.548707080758458
Validation loss: 2.4913932587029795

Epoch: 5| Step: 8
Training loss: 1.957677677319519
Validation loss: 2.4934848210992313

Epoch: 5| Step: 9
Training loss: 2.2560257226952007
Validation loss: 2.4862919215712744

Epoch: 5| Step: 10
Training loss: 2.5927129303791943
Validation loss: 2.4564973607938474

Epoch: 5| Step: 11
Training loss: 2.060546875
Validation loss: 2.493314968333038

Epoch: 70| Step: 0
Training loss: 1.914538141436056
Validation loss: 2.4931085851573136

Epoch: 5| Step: 1
Training loss: 2.983299021461415
Validation loss: 2.5018108922079687

Epoch: 5| Step: 2
Training loss: 1.7929109052913768
Validation loss: 2.5346902733506496

Epoch: 5| Step: 3
Training loss: 2.277056667756925
Validation loss: 2.522008016608604

Epoch: 5| Step: 4
Training loss: 2.2013172281062365
Validation loss: 2.5277547172977997

Epoch: 5| Step: 5
Training loss: 2.160503338871896
Validation loss: 2.5502211757650572

Epoch: 5| Step: 6
Training loss: 2.16008583216203
Validation loss: 2.5374835342662245

Epoch: 5| Step: 7
Training loss: 2.8177500573040564
Validation loss: 2.5322244793478403

Epoch: 5| Step: 8
Training loss: 2.1914428055106114
Validation loss: 2.5142047774646707

Epoch: 5| Step: 9
Training loss: 3.019841542160499
Validation loss: 2.4965235420218232

Epoch: 5| Step: 10
Training loss: 2.395665060574724
Validation loss: 2.5151043169426153

Epoch: 5| Step: 11
Training loss: 1.8953140371997257
Validation loss: 2.5035367723844453

Epoch: 71| Step: 0
Training loss: 2.058145260680718
Validation loss: 2.4916975681808538

Epoch: 5| Step: 1
Training loss: 2.6716588696964725
Validation loss: 2.476789963441882

Epoch: 5| Step: 2
Training loss: 2.3151366178271426
Validation loss: 2.483644622028929

Epoch: 5| Step: 3
Training loss: 2.5800586269430266
Validation loss: 2.501430551200919

Epoch: 5| Step: 4
Training loss: 2.012250574423468
Validation loss: 2.4819287926652907

Epoch: 5| Step: 5
Training loss: 2.0924503221163704
Validation loss: 2.484939207232719

Epoch: 5| Step: 6
Training loss: 2.427402513552104
Validation loss: 2.4759623324777795

Epoch: 5| Step: 7
Training loss: 3.003301393407521
Validation loss: 2.4839195257797044

Epoch: 5| Step: 8
Training loss: 2.3441281840066255
Validation loss: 2.4640940288235162

Epoch: 5| Step: 9
Training loss: 1.9363117265805334
Validation loss: 2.4624838617928804

Epoch: 5| Step: 10
Training loss: 2.4943064706937825
Validation loss: 2.4727660682561625

Epoch: 5| Step: 11
Training loss: 2.391376751154174
Validation loss: 2.453774287316895

Epoch: 72| Step: 0
Training loss: 2.617847234216144
Validation loss: 2.4866477039737407

Epoch: 5| Step: 1
Training loss: 2.473169354900715
Validation loss: 2.4780888271377575

Epoch: 5| Step: 2
Training loss: 2.01831065023682
Validation loss: 2.4724499745478354

Epoch: 5| Step: 3
Training loss: 2.334823802205942
Validation loss: 2.475304397334087

Epoch: 5| Step: 4
Training loss: 2.168298644663869
Validation loss: 2.492430576440444

Epoch: 5| Step: 5
Training loss: 2.496565748788704
Validation loss: 2.4769088510951005

Epoch: 5| Step: 6
Training loss: 2.1431715916207854
Validation loss: 2.4913577728483567

Epoch: 5| Step: 7
Training loss: 2.5274280846511727
Validation loss: 2.4753281438405654

Epoch: 5| Step: 8
Training loss: 2.0807619502063455
Validation loss: 2.5040251316329263

Epoch: 5| Step: 9
Training loss: 2.1841141791976484
Validation loss: 2.474834786144437

Epoch: 5| Step: 10
Training loss: 2.9015660431264547
Validation loss: 2.5015739929900995

Epoch: 5| Step: 11
Training loss: 1.8452674957136443
Validation loss: 2.509391200613867

Epoch: 73| Step: 0
Training loss: 2.1783703615193173
Validation loss: 2.532289279877513

Epoch: 5| Step: 1
Training loss: 3.17605781054791
Validation loss: 2.522858197904715

Epoch: 5| Step: 2
Training loss: 2.622042488504608
Validation loss: 2.5270488002856952

Epoch: 5| Step: 3
Training loss: 2.066562812513267
Validation loss: 2.5083815185590934

Epoch: 5| Step: 4
Training loss: 1.7178581004399258
Validation loss: 2.509014293261243

Epoch: 5| Step: 5
Training loss: 2.902509353451768
Validation loss: 2.5068501441234994

Epoch: 5| Step: 6
Training loss: 2.167818521329324
Validation loss: 2.5018010685117846

Epoch: 5| Step: 7
Training loss: 2.3962615141892933
Validation loss: 2.4761537701964444

Epoch: 5| Step: 8
Training loss: 2.6091593579027785
Validation loss: 2.4884842890089622

Epoch: 5| Step: 9
Training loss: 1.9317652215685002
Validation loss: 2.482542477731233

Epoch: 5| Step: 10
Training loss: 1.9665497489163015
Validation loss: 2.4956516158852247

Epoch: 5| Step: 11
Training loss: 2.372632000610513
Validation loss: 2.4837645654454445

Epoch: 74| Step: 0
Training loss: 2.050023809155159
Validation loss: 2.4844296687287115

Epoch: 5| Step: 1
Training loss: 2.3354795893808515
Validation loss: 2.504260989733189

Epoch: 5| Step: 2
Training loss: 2.1442550731490844
Validation loss: 2.5162452106964017

Epoch: 5| Step: 3
Training loss: 2.1907627296413112
Validation loss: 2.5016783603871002

Epoch: 5| Step: 4
Training loss: 2.4449511373743134
Validation loss: 2.4813329277625855

Epoch: 5| Step: 5
Training loss: 3.0754540953257705
Validation loss: 2.4988205074408674

Epoch: 5| Step: 6
Training loss: 2.019999407399912
Validation loss: 2.5090291546998684

Epoch: 5| Step: 7
Training loss: 2.0209043693510726
Validation loss: 2.529562297233621

Epoch: 5| Step: 8
Training loss: 2.4107430854974328
Validation loss: 2.5219160439808017

Epoch: 5| Step: 9
Training loss: 2.1295316285083974
Validation loss: 2.5244730526237724

Epoch: 5| Step: 10
Training loss: 3.0361533865196284
Validation loss: 2.5311721978181025

Epoch: 5| Step: 11
Training loss: 2.2959516057486797
Validation loss: 2.5184352294707155

Epoch: 75| Step: 0
Training loss: 2.126396617824141
Validation loss: 2.499558457483261

Epoch: 5| Step: 1
Training loss: 2.2838223729517733
Validation loss: 2.500624368107061

Epoch: 5| Step: 2
Training loss: 2.273808190186784
Validation loss: 2.4636516963159996

Epoch: 5| Step: 3
Training loss: 2.206020211418575
Validation loss: 2.466613734542976

Epoch: 5| Step: 4
Training loss: 2.422831389571148
Validation loss: 2.4633489591191524

Epoch: 5| Step: 5
Training loss: 2.195132645268223
Validation loss: 2.4863087068265437

Epoch: 5| Step: 6
Training loss: 2.28183247694037
Validation loss: 2.46998357937576

Epoch: 5| Step: 7
Training loss: 2.2289504781213143
Validation loss: 2.4785723989090083

Epoch: 5| Step: 8
Training loss: 2.1333143600971196
Validation loss: 2.473958058942813

Epoch: 5| Step: 9
Training loss: 3.076493193783943
Validation loss: 2.476166164963102

Epoch: 5| Step: 10
Training loss: 2.279580328280514
Validation loss: 2.451088321067219

Epoch: 5| Step: 11
Training loss: 3.434095048818726
Validation loss: 2.4471931091589845

Epoch: 76| Step: 0
Training loss: 2.339474249244564
Validation loss: 2.4932165263625667

Epoch: 5| Step: 1
Training loss: 2.8473836299973616
Validation loss: 2.497063052082708

Epoch: 5| Step: 2
Training loss: 2.2810532994580073
Validation loss: 2.4998918112551287

Epoch: 5| Step: 3
Training loss: 2.411935603874774
Validation loss: 2.5023206231966717

Epoch: 5| Step: 4
Training loss: 2.5988352000410986
Validation loss: 2.505285417847273

Epoch: 5| Step: 5
Training loss: 2.2723843471864287
Validation loss: 2.500261011008694

Epoch: 5| Step: 6
Training loss: 2.4488279770123778
Validation loss: 2.489666160631539

Epoch: 5| Step: 7
Training loss: 2.505470965306843
Validation loss: 2.5098002271827364

Epoch: 5| Step: 8
Training loss: 2.1278568586234874
Validation loss: 2.487737563305232

Epoch: 5| Step: 9
Training loss: 2.6428649250490355
Validation loss: 2.470393691959526

Epoch: 5| Step: 10
Training loss: 2.224601336992996
Validation loss: 2.478326291747908

Epoch: 5| Step: 11
Training loss: 1.6270506464385335
Validation loss: 2.4880908072756576

Epoch: 77| Step: 0
Training loss: 2.1824253620961716
Validation loss: 2.492218978029321

Epoch: 5| Step: 1
Training loss: 2.258479247593456
Validation loss: 2.4802112756097787

Epoch: 5| Step: 2
Training loss: 2.5723550675235924
Validation loss: 2.5043826113773147

Epoch: 5| Step: 3
Training loss: 3.2088925423370913
Validation loss: 2.5089835763069126

Epoch: 5| Step: 4
Training loss: 1.5634361514433177
Validation loss: 2.5256456923398245

Epoch: 5| Step: 5
Training loss: 1.672266976583853
Validation loss: 2.5208468962270354

Epoch: 5| Step: 6
Training loss: 2.14648026525852
Validation loss: 2.5518340332856297

Epoch: 5| Step: 7
Training loss: 2.73294631691449
Validation loss: 2.5257323177249447

Epoch: 5| Step: 8
Training loss: 2.2986072054929356
Validation loss: 2.5482745937324647

Epoch: 5| Step: 9
Training loss: 2.2704520532467822
Validation loss: 2.529948661412738

Epoch: 5| Step: 10
Training loss: 2.7540605217759797
Validation loss: 2.53805391673797

Epoch: 5| Step: 11
Training loss: 1.9012426679420922
Validation loss: 2.5222252334307407

Epoch: 78| Step: 0
Training loss: 2.77224009280241
Validation loss: 2.518898666181432

Epoch: 5| Step: 1
Training loss: 2.240268324550679
Validation loss: 2.4983887327904717

Epoch: 5| Step: 2
Training loss: 2.32707590109362
Validation loss: 2.503749062875543

Epoch: 5| Step: 3
Training loss: 1.6682273074721419
Validation loss: 2.487828778978446

Epoch: 5| Step: 4
Training loss: 2.647517491788058
Validation loss: 2.5107265943262846

Epoch: 5| Step: 5
Training loss: 2.065927374288002
Validation loss: 2.4795009036447446

Epoch: 5| Step: 6
Training loss: 2.5493846300396346
Validation loss: 2.4954408359827425

Epoch: 5| Step: 7
Training loss: 2.227436309143654
Validation loss: 2.4885913968988755

Epoch: 5| Step: 8
Training loss: 2.0089297025162676
Validation loss: 2.4736126842299817

Epoch: 5| Step: 9
Training loss: 2.939673897699691
Validation loss: 2.461411393167742

Epoch: 5| Step: 10
Training loss: 2.203679224739689
Validation loss: 2.465872407369204

Epoch: 5| Step: 11
Training loss: 1.4984614110795063
Validation loss: 2.479497548203084

Epoch: 79| Step: 0
Training loss: 2.402256612050253
Validation loss: 2.4716780396386535

Epoch: 5| Step: 1
Training loss: 2.7198767245630946
Validation loss: 2.465412640501956

Epoch: 5| Step: 2
Training loss: 1.7058068954190648
Validation loss: 2.4910926606340738

Epoch: 5| Step: 3
Training loss: 1.8228573017444873
Validation loss: 2.4811871126694904

Epoch: 5| Step: 4
Training loss: 2.1512282123603885
Validation loss: 2.480361245296224

Epoch: 5| Step: 5
Training loss: 2.97846439505123
Validation loss: 2.4952187235677648

Epoch: 5| Step: 6
Training loss: 2.561317543192931
Validation loss: 2.5212893736883406

Epoch: 5| Step: 7
Training loss: 2.0715343396661954
Validation loss: 2.5036884357935

Epoch: 5| Step: 8
Training loss: 2.201928862390167
Validation loss: 2.470321344323183

Epoch: 5| Step: 9
Training loss: 2.7489283814604786
Validation loss: 2.479179439725482

Epoch: 5| Step: 10
Training loss: 2.2893528672756673
Validation loss: 2.484200417484383

Epoch: 5| Step: 11
Training loss: 1.8512222685659
Validation loss: 2.496829820334789

Epoch: 80| Step: 0
Training loss: 2.4862742332017813
Validation loss: 2.461550606945894

Epoch: 5| Step: 1
Training loss: 2.037663824130089
Validation loss: 2.4818446370879435

Epoch: 5| Step: 2
Training loss: 2.694620060086207
Validation loss: 2.4940920162617184

Epoch: 5| Step: 3
Training loss: 1.8367255284984645
Validation loss: 2.4898574284510055

Epoch: 5| Step: 4
Training loss: 2.6651681524193114
Validation loss: 2.477321185640109

Epoch: 5| Step: 5
Training loss: 3.067987624679335
Validation loss: 2.4912614008528906

Epoch: 5| Step: 6
Training loss: 2.9431481136857176
Validation loss: 2.4694086777541937

Epoch: 5| Step: 7
Training loss: 1.714444820082343
Validation loss: 2.4793886351124317

Epoch: 5| Step: 8
Training loss: 1.8444043954014655
Validation loss: 2.482590348244164

Epoch: 5| Step: 9
Training loss: 1.79777331909792
Validation loss: 2.4808666160468613

Epoch: 5| Step: 10
Training loss: 2.4436841911957545
Validation loss: 2.481286434255207

Epoch: 5| Step: 11
Training loss: 1.5408942461257782
Validation loss: 2.485513837971366

Epoch: 81| Step: 0
Training loss: 2.3454600898308846
Validation loss: 2.4795080331919808

Epoch: 5| Step: 1
Training loss: 2.4465638880056377
Validation loss: 2.481432749938992

Epoch: 5| Step: 2
Training loss: 2.230121111125601
Validation loss: 2.5000124017089957

Epoch: 5| Step: 3
Training loss: 2.560265008352531
Validation loss: 2.4779485159426957

Epoch: 5| Step: 4
Training loss: 1.770334293133698
Validation loss: 2.4849913410378743

Epoch: 5| Step: 5
Training loss: 2.246232693562524
Validation loss: 2.4870735962734063

Epoch: 5| Step: 6
Training loss: 2.0548223298947486
Validation loss: 2.510461566782052

Epoch: 5| Step: 7
Training loss: 2.142705421526137
Validation loss: 2.4812780947179682

Epoch: 5| Step: 8
Training loss: 2.2396572603547766
Validation loss: 2.48203411220201

Epoch: 5| Step: 9
Training loss: 2.290767308247319
Validation loss: 2.501774892977768

Epoch: 5| Step: 10
Training loss: 3.152096271845519
Validation loss: 2.5055687592873466

Epoch: 5| Step: 11
Training loss: 2.117929026119661
Validation loss: 2.4859501066114014

Epoch: 82| Step: 0
Training loss: 2.4778472744765976
Validation loss: 2.492058071973012

Epoch: 5| Step: 1
Training loss: 1.9037247487908895
Validation loss: 2.48313693420963

Epoch: 5| Step: 2
Training loss: 2.1533756724743127
Validation loss: 2.4764082065336823

Epoch: 5| Step: 3
Training loss: 2.363519527308636
Validation loss: 2.4696825052949603

Epoch: 5| Step: 4
Training loss: 2.626792477371832
Validation loss: 2.464284588584485

Epoch: 5| Step: 5
Training loss: 2.938927486224713
Validation loss: 2.4702382068694195

Epoch: 5| Step: 6
Training loss: 2.4503101308290858
Validation loss: 2.473063089448827

Epoch: 5| Step: 7
Training loss: 1.7152946418142554
Validation loss: 2.4559358399937254

Epoch: 5| Step: 8
Training loss: 2.6609293392681215
Validation loss: 2.456260802946528

Epoch: 5| Step: 9
Training loss: 2.3370681118912944
Validation loss: 2.45770760967359

Epoch: 5| Step: 10
Training loss: 1.7909357516949675
Validation loss: 2.475702166415229

Epoch: 5| Step: 11
Training loss: 2.240095697981339
Validation loss: 2.4902395769451386

Epoch: 83| Step: 0
Training loss: 2.1802310607668445
Validation loss: 2.475597566656303

Epoch: 5| Step: 1
Training loss: 2.3127424783135915
Validation loss: 2.477922798043527

Epoch: 5| Step: 2
Training loss: 1.7270168207273828
Validation loss: 2.4709264963372264

Epoch: 5| Step: 3
Training loss: 2.589475763797129
Validation loss: 2.488452200853549

Epoch: 5| Step: 4
Training loss: 2.507871728120442
Validation loss: 2.4643366917312477

Epoch: 5| Step: 5
Training loss: 2.1625744492609247
Validation loss: 2.489447188279269

Epoch: 5| Step: 6
Training loss: 1.7772159069320461
Validation loss: 2.4841152711171435

Epoch: 5| Step: 7
Training loss: 3.007690110131691
Validation loss: 2.4979877161691646

Epoch: 5| Step: 8
Training loss: 2.3701159803767013
Validation loss: 2.4743420527507247

Epoch: 5| Step: 9
Training loss: 2.7140565018925247
Validation loss: 2.4921612035625604

Epoch: 5| Step: 10
Training loss: 2.0431890715328453
Validation loss: 2.479055038845488

Epoch: 5| Step: 11
Training loss: 1.6415473888202046
Validation loss: 2.5232696103362913

Epoch: 84| Step: 0
Training loss: 2.397911784556236
Validation loss: 2.546231697608515

Epoch: 5| Step: 1
Training loss: 2.4825315533771537
Validation loss: 2.5221083873796513

Epoch: 5| Step: 2
Training loss: 2.5909221814629495
Validation loss: 2.5395457976657303

Epoch: 5| Step: 3
Training loss: 2.715109042371778
Validation loss: 2.5115649095629484

Epoch: 5| Step: 4
Training loss: 2.2685452287388905
Validation loss: 2.547214894929574

Epoch: 5| Step: 5
Training loss: 2.811942490316553
Validation loss: 2.484072100969954

Epoch: 5| Step: 6
Training loss: 1.797909513468858
Validation loss: 2.5010184240207853

Epoch: 5| Step: 7
Training loss: 2.133759229089212
Validation loss: 2.493385190579593

Epoch: 5| Step: 8
Training loss: 2.1457633837313943
Validation loss: 2.453052608774422

Epoch: 5| Step: 9
Training loss: 2.084800152977845
Validation loss: 2.477811251834974

Epoch: 5| Step: 10
Training loss: 2.2327463042775677
Validation loss: 2.4635772736108636

Epoch: 5| Step: 11
Training loss: 2.786656985228055
Validation loss: 2.469272872021717

Epoch: 85| Step: 0
Training loss: 2.1985409710250194
Validation loss: 2.4732689763724833

Epoch: 5| Step: 1
Training loss: 1.8884730426701477
Validation loss: 2.478118195269856

Epoch: 5| Step: 2
Training loss: 2.7826824999628266
Validation loss: 2.4878355432523005

Epoch: 5| Step: 3
Training loss: 2.3127721677886166
Validation loss: 2.4816119846024525

Epoch: 5| Step: 4
Training loss: 2.2089448717870344
Validation loss: 2.4829619245655614

Epoch: 5| Step: 5
Training loss: 2.5454601266106196
Validation loss: 2.4845354200348595

Epoch: 5| Step: 6
Training loss: 1.7361807143775916
Validation loss: 2.4876041778717375

Epoch: 5| Step: 7
Training loss: 2.8916655446104427
Validation loss: 2.472977579700848

Epoch: 5| Step: 8
Training loss: 2.1873879540221863
Validation loss: 2.500716782175591

Epoch: 5| Step: 9
Training loss: 2.352097764039914
Validation loss: 2.50928928194004

Epoch: 5| Step: 10
Training loss: 2.3940045771670584
Validation loss: 2.4963485396701346

Epoch: 5| Step: 11
Training loss: 1.906685451112706
Validation loss: 2.478102220428175

Epoch: 86| Step: 0
Training loss: 1.7816911117737095
Validation loss: 2.495913216952877

Epoch: 5| Step: 1
Training loss: 2.475130551680814
Validation loss: 2.4854745850658726

Epoch: 5| Step: 2
Training loss: 2.632677567190963
Validation loss: 2.503267437822739

Epoch: 5| Step: 3
Training loss: 2.390996467801512
Validation loss: 2.5247964457495446

Epoch: 5| Step: 4
Training loss: 2.4764972281052504
Validation loss: 2.528051726258208

Epoch: 5| Step: 5
Training loss: 2.473508955983052
Validation loss: 2.5227481581539095

Epoch: 5| Step: 6
Training loss: 2.58172928837809
Validation loss: 2.5032659020296757

Epoch: 5| Step: 7
Training loss: 2.495530806745485
Validation loss: 2.5070333528177997

Epoch: 5| Step: 8
Training loss: 1.9818658659744663
Validation loss: 2.5145628189276215

Epoch: 5| Step: 9
Training loss: 2.244338436057264
Validation loss: 2.460286735594546

Epoch: 5| Step: 10
Training loss: 1.8601099693440113
Validation loss: 2.490294144854351

Epoch: 5| Step: 11
Training loss: 2.4259430221697222
Validation loss: 2.472713688750246

Epoch: 87| Step: 0
Training loss: 2.3216867198566415
Validation loss: 2.4730608982155964

Epoch: 5| Step: 1
Training loss: 1.8515117010560151
Validation loss: 2.485141236124873

Epoch: 5| Step: 2
Training loss: 2.607712541587827
Validation loss: 2.504665771361568

Epoch: 5| Step: 3
Training loss: 2.2144983954183726
Validation loss: 2.527915771936506

Epoch: 5| Step: 4
Training loss: 2.1048610284376603
Validation loss: 2.530231494622186

Epoch: 5| Step: 5
Training loss: 2.7498711642516835
Validation loss: 2.514123589022624

Epoch: 5| Step: 6
Training loss: 2.0261513909943933
Validation loss: 2.520145739552501

Epoch: 5| Step: 7
Training loss: 2.820979073918458
Validation loss: 2.5090342483896944

Epoch: 5| Step: 8
Training loss: 2.5237168668222387
Validation loss: 2.498231870528394

Epoch: 5| Step: 9
Training loss: 2.1126164150326554
Validation loss: 2.5069619476385974

Epoch: 5| Step: 10
Training loss: 2.294922082779246
Validation loss: 2.4777575476589875

Epoch: 5| Step: 11
Training loss: 1.158163086068838
Validation loss: 2.483522036815944

Epoch: 88| Step: 0
Training loss: 2.1573947687223014
Validation loss: 2.468425624799691

Epoch: 5| Step: 1
Training loss: 2.1875307353449034
Validation loss: 2.4798818900262924

Epoch: 5| Step: 2
Training loss: 2.137179532483161
Validation loss: 2.5035181523373446

Epoch: 5| Step: 3
Training loss: 2.3317293262401595
Validation loss: 2.469081285034506

Epoch: 5| Step: 4
Training loss: 2.1126198006693433
Validation loss: 2.4558284344369183

Epoch: 5| Step: 5
Training loss: 2.064868607301075
Validation loss: 2.4823760882061063

Epoch: 5| Step: 6
Training loss: 2.7161752193881403
Validation loss: 2.4833431280239506

Epoch: 5| Step: 7
Training loss: 2.6298014008123967
Validation loss: 2.486634236860211

Epoch: 5| Step: 8
Training loss: 2.8645183394023612
Validation loss: 2.4884477656455015

Epoch: 5| Step: 9
Training loss: 2.237975094613183
Validation loss: 2.4842835175567104

Epoch: 5| Step: 10
Training loss: 1.902239348192356
Validation loss: 2.4597756201286725

Epoch: 5| Step: 11
Training loss: 2.4806238801760943
Validation loss: 2.456325447826262

Epoch: 89| Step: 0
Training loss: 2.361944353266962
Validation loss: 2.4812685100207714

Epoch: 5| Step: 1
Training loss: 1.997903201548761
Validation loss: 2.4606411104496044

Epoch: 5| Step: 2
Training loss: 2.5573845954579637
Validation loss: 2.457849306743215

Epoch: 5| Step: 3
Training loss: 2.468493001574447
Validation loss: 2.462842004524485

Epoch: 5| Step: 4
Training loss: 2.2222787439257807
Validation loss: 2.4722825943674915

Epoch: 5| Step: 5
Training loss: 2.5682994995100064
Validation loss: 2.473000139425407

Epoch: 5| Step: 6
Training loss: 2.0099306326136483
Validation loss: 2.4801587609457587

Epoch: 5| Step: 7
Training loss: 1.8567978124455258
Validation loss: 2.465119311712474

Epoch: 5| Step: 8
Training loss: 2.4391690921890854
Validation loss: 2.4677631321097975

Epoch: 5| Step: 9
Training loss: 2.2969868950609063
Validation loss: 2.4448815799904597

Epoch: 5| Step: 10
Training loss: 1.9173619073631805
Validation loss: 2.462345802171847

Epoch: 5| Step: 11
Training loss: 4.408914396261789
Validation loss: 2.4556700590483143

Epoch: 90| Step: 0
Training loss: 2.486601881132701
Validation loss: 2.484002371299562

Epoch: 5| Step: 1
Training loss: 2.7601284428439365
Validation loss: 2.485315200949372

Epoch: 5| Step: 2
Training loss: 2.6011858143327697
Validation loss: 2.487375279116176

Epoch: 5| Step: 3
Training loss: 2.051934548291541
Validation loss: 2.494091639862925

Epoch: 5| Step: 4
Training loss: 2.0186737424070516
Validation loss: 2.4844443793375945

Epoch: 5| Step: 5
Training loss: 2.534721913330431
Validation loss: 2.5119050601028405

Epoch: 5| Step: 6
Training loss: 2.114374861439546
Validation loss: 2.5144929688426734

Epoch: 5| Step: 7
Training loss: 1.9276999303335778
Validation loss: 2.5292799626279607

Epoch: 5| Step: 8
Training loss: 2.512355694019114
Validation loss: 2.5085912685645355

Epoch: 5| Step: 9
Training loss: 2.019753656001795
Validation loss: 2.5052508088210086

Epoch: 5| Step: 10
Training loss: 2.3259687230901145
Validation loss: 2.4854485093789815

Epoch: 5| Step: 11
Training loss: 1.8627577072145893
Validation loss: 2.5114806019320395

Epoch: 91| Step: 0
Training loss: 2.1570532587981
Validation loss: 2.4554403013126214

Epoch: 5| Step: 1
Training loss: 2.3258731884094654
Validation loss: 2.4684599130548803

Epoch: 5| Step: 2
Training loss: 2.697818994902021
Validation loss: 2.4720276992386885

Epoch: 5| Step: 3
Training loss: 2.0341655054939496
Validation loss: 2.472964311305193

Epoch: 5| Step: 4
Training loss: 2.4468669399162826
Validation loss: 2.4775483448625035

Epoch: 5| Step: 5
Training loss: 2.1513113325420674
Validation loss: 2.494868025809046

Epoch: 5| Step: 6
Training loss: 2.0704200572738887
Validation loss: 2.4765519784729944

Epoch: 5| Step: 7
Training loss: 2.6436172776691818
Validation loss: 2.4569118290814864

Epoch: 5| Step: 8
Training loss: 2.4872435317741886
Validation loss: 2.4898449442421415

Epoch: 5| Step: 9
Training loss: 2.1410710225127056
Validation loss: 2.474283812678927

Epoch: 5| Step: 10
Training loss: 2.269932827900943
Validation loss: 2.459263327978394

Epoch: 5| Step: 11
Training loss: 1.800666987503251
Validation loss: 2.450377794902401

Epoch: 92| Step: 0
Training loss: 2.4793461219100137
Validation loss: 2.4786276084345844

Epoch: 5| Step: 1
Training loss: 1.658874447717058
Validation loss: 2.460597734359175

Epoch: 5| Step: 2
Training loss: 2.4790457901751544
Validation loss: 2.4669686340958514

Epoch: 5| Step: 3
Training loss: 2.3908425026477675
Validation loss: 2.484182678232053

Epoch: 5| Step: 4
Training loss: 2.2601089150844995
Validation loss: 2.4799805849158787

Epoch: 5| Step: 5
Training loss: 2.990970533413943
Validation loss: 2.4771908304958767

Epoch: 5| Step: 6
Training loss: 2.0900269615223
Validation loss: 2.4941425129309

Epoch: 5| Step: 7
Training loss: 2.306022231683819
Validation loss: 2.497447152881702

Epoch: 5| Step: 8
Training loss: 1.8930557640313774
Validation loss: 2.5285915299519206

Epoch: 5| Step: 9
Training loss: 1.7509227772083
Validation loss: 2.50004100765928

Epoch: 5| Step: 10
Training loss: 2.80688976650053
Validation loss: 2.524412374292986

Epoch: 5| Step: 11
Training loss: 1.3817220580283467
Validation loss: 2.505039706407221

Epoch: 93| Step: 0
Training loss: 2.2258822288650726
Validation loss: 2.4758066614431224

Epoch: 5| Step: 1
Training loss: 2.6262789743995762
Validation loss: 2.4723009413665245

Epoch: 5| Step: 2
Training loss: 2.6338060807755705
Validation loss: 2.504333455682311

Epoch: 5| Step: 3
Training loss: 2.4661340495025748
Validation loss: 2.4820352929114087

Epoch: 5| Step: 4
Training loss: 1.7943624427858276
Validation loss: 2.4973015765772675

Epoch: 5| Step: 5
Training loss: 2.185998237644054
Validation loss: 2.46198570896735

Epoch: 5| Step: 6
Training loss: 1.870514335991385
Validation loss: 2.4811466201910597

Epoch: 5| Step: 7
Training loss: 2.3361534605699616
Validation loss: 2.4608712364035332

Epoch: 5| Step: 8
Training loss: 2.014007155647181
Validation loss: 2.4728669633720464

Epoch: 5| Step: 9
Training loss: 2.41479935248889
Validation loss: 2.439284266625891

Epoch: 5| Step: 10
Training loss: 2.5248148557561936
Validation loss: 2.4664819616571547

Epoch: 5| Step: 11
Training loss: 2.482859407129467
Validation loss: 2.475719529057975

Epoch: 94| Step: 0
Training loss: 2.5567627856486093
Validation loss: 2.4546290725174584

Epoch: 5| Step: 1
Training loss: 2.219295595811733
Validation loss: 2.4664506888290587

Epoch: 5| Step: 2
Training loss: 2.0900553658557777
Validation loss: 2.470567971454436

Epoch: 5| Step: 3
Training loss: 2.085092208982254
Validation loss: 2.505768783965539

Epoch: 5| Step: 4
Training loss: 2.145507701375452
Validation loss: 2.501235283206702

Epoch: 5| Step: 5
Training loss: 2.067115935847897
Validation loss: 2.506838759017127

Epoch: 5| Step: 6
Training loss: 2.744698182069704
Validation loss: 2.5679092225472306

Epoch: 5| Step: 7
Training loss: 2.3935557831941088
Validation loss: 2.5281421475326002

Epoch: 5| Step: 8
Training loss: 2.374918384153523
Validation loss: 2.5301934733503457

Epoch: 5| Step: 9
Training loss: 2.41499098418707
Validation loss: 2.5176724025849198

Epoch: 5| Step: 10
Training loss: 2.255837074598919
Validation loss: 2.47287736800949

Epoch: 5| Step: 11
Training loss: 1.7800813823483472
Validation loss: 2.4926095563290467

Epoch: 95| Step: 0
Training loss: 1.9446762453906297
Validation loss: 2.47691236044421

Epoch: 5| Step: 1
Training loss: 2.417343329922177
Validation loss: 2.5064679043950435

Epoch: 5| Step: 2
Training loss: 2.2952788120028256
Validation loss: 2.48351302478207

Epoch: 5| Step: 3
Training loss: 2.4781486173372644
Validation loss: 2.476468685150226

Epoch: 5| Step: 4
Training loss: 2.689038656817277
Validation loss: 2.4679756801242663

Epoch: 5| Step: 5
Training loss: 1.9155851574685778
Validation loss: 2.4652999842603234

Epoch: 5| Step: 6
Training loss: 2.6197054920218035
Validation loss: 2.4566628524107115

Epoch: 5| Step: 7
Training loss: 2.7853728179409516
Validation loss: 2.469636576843236

Epoch: 5| Step: 8
Training loss: 1.8687574099390611
Validation loss: 2.4706225013897196

Epoch: 5| Step: 9
Training loss: 2.1883865739670267
Validation loss: 2.4566133039567415

Epoch: 5| Step: 10
Training loss: 1.6871430761314758
Validation loss: 2.4839169901793037

Epoch: 5| Step: 11
Training loss: 1.8976750981858133
Validation loss: 2.462170694571994

Epoch: 96| Step: 0
Training loss: 2.455292151445566
Validation loss: 2.4793373150690527

Epoch: 5| Step: 1
Training loss: 2.1525708198194966
Validation loss: 2.4639189265288715

Epoch: 5| Step: 2
Training loss: 1.9690291797147743
Validation loss: 2.4903002960854494

Epoch: 5| Step: 3
Training loss: 2.5904397638264873
Validation loss: 2.480215641434461

Epoch: 5| Step: 4
Training loss: 2.6026621834150903
Validation loss: 2.5028090550244997

Epoch: 5| Step: 5
Training loss: 1.8962918939155784
Validation loss: 2.476958410665201

Epoch: 5| Step: 6
Training loss: 1.88463798446519
Validation loss: 2.483178196345308

Epoch: 5| Step: 7
Training loss: 2.0900724767137286
Validation loss: 2.4850998786641645

Epoch: 5| Step: 8
Training loss: 2.814291828306554
Validation loss: 2.470202236139593

Epoch: 5| Step: 9
Training loss: 2.222548980001534
Validation loss: 2.4736008931322035

Epoch: 5| Step: 10
Training loss: 2.1251074819871016
Validation loss: 2.5024101084170853

Epoch: 5| Step: 11
Training loss: 1.9890613037489344
Validation loss: 2.4948850420451856

Epoch: 97| Step: 0
Training loss: 2.810415639987887
Validation loss: 2.4952324509047665

Epoch: 5| Step: 1
Training loss: 1.8856033598075652
Validation loss: 2.494230005409791

Epoch: 5| Step: 2
Training loss: 1.5235919580653465
Validation loss: 2.5098410549282733

Epoch: 5| Step: 3
Training loss: 2.4939966600850005
Validation loss: 2.505042161142566

Epoch: 5| Step: 4
Training loss: 2.681335209557351
Validation loss: 2.499926812372216

Epoch: 5| Step: 5
Training loss: 2.2282286717504647
Validation loss: 2.5130214131145436

Epoch: 5| Step: 6
Training loss: 2.3510556102424274
Validation loss: 2.5061731258534965

Epoch: 5| Step: 7
Training loss: 1.7585109425134593
Validation loss: 2.518889617047847

Epoch: 5| Step: 8
Training loss: 2.0887188031682236
Validation loss: 2.5190758857959783

Epoch: 5| Step: 9
Training loss: 3.0262157676805854
Validation loss: 2.5202498818218286

Epoch: 5| Step: 10
Training loss: 1.6182471595290167
Validation loss: 2.5180821827883766

Epoch: 5| Step: 11
Training loss: 2.5243041259910832
Validation loss: 2.4920571790401804

Epoch: 98| Step: 0
Training loss: 2.240938164228544
Validation loss: 2.488397682376301

Epoch: 5| Step: 1
Training loss: 2.409019263855968
Validation loss: 2.473048532071962

Epoch: 5| Step: 2
Training loss: 1.8095575322926325
Validation loss: 2.482482661301631

Epoch: 5| Step: 3
Training loss: 2.8856121414754052
Validation loss: 2.472347216104362

Epoch: 5| Step: 4
Training loss: 2.2339987271270267
Validation loss: 2.463525055606856

Epoch: 5| Step: 5
Training loss: 2.28530825899999
Validation loss: 2.4696817329896428

Epoch: 5| Step: 6
Training loss: 2.0722649346870905
Validation loss: 2.4491521044459708

Epoch: 5| Step: 7
Training loss: 2.183205012076479
Validation loss: 2.468261746923168

Epoch: 5| Step: 8
Training loss: 1.8229723313324953
Validation loss: 2.478784220445333

Epoch: 5| Step: 9
Training loss: 2.8061991153852945
Validation loss: 2.4617191788860575

Epoch: 5| Step: 10
Training loss: 2.2948876950579664
Validation loss: 2.4903438369528788

Epoch: 5| Step: 11
Training loss: 1.944331768343722
Validation loss: 2.451196479420576

Epoch: 99| Step: 0
Training loss: 2.39577831260418
Validation loss: 2.4837264208033574

Epoch: 5| Step: 1
Training loss: 2.4150780575539104
Validation loss: 2.4811822901214424

Epoch: 5| Step: 2
Training loss: 1.8709101258329037
Validation loss: 2.479855082537304

Epoch: 5| Step: 3
Training loss: 2.2338180381347845
Validation loss: 2.482998860692953

Epoch: 5| Step: 4
Training loss: 2.227051370056516
Validation loss: 2.4838215513375053

Epoch: 5| Step: 5
Training loss: 2.3934020822934987
Validation loss: 2.4772236259479095

Epoch: 5| Step: 6
Training loss: 1.6046191564044783
Validation loss: 2.4823249259723714

Epoch: 5| Step: 7
Training loss: 2.712025185088299
Validation loss: 2.515501552419803

Epoch: 5| Step: 8
Training loss: 2.5408334981989804
Validation loss: 2.492194176707796

Epoch: 5| Step: 9
Training loss: 2.135085128230549
Validation loss: 2.509393694638947

Epoch: 5| Step: 10
Training loss: 2.0073890090986595
Validation loss: 2.5019819787550683

Epoch: 5| Step: 11
Training loss: 2.3976627055180995
Validation loss: 2.487254671078932

Epoch: 100| Step: 0
Training loss: 1.6627868634308614
Validation loss: 2.4900452825023893

Epoch: 5| Step: 1
Training loss: 2.6425814632104285
Validation loss: 2.480330403792689

Epoch: 5| Step: 2
Training loss: 2.489036457430802
Validation loss: 2.4594490999839755

Epoch: 5| Step: 3
Training loss: 2.130323697598342
Validation loss: 2.461861177708939

Epoch: 5| Step: 4
Training loss: 2.2284168753112867
Validation loss: 2.46479482143745

Epoch: 5| Step: 5
Training loss: 2.25376830844139
Validation loss: 2.454138151746892

Epoch: 5| Step: 6
Training loss: 2.5604353239550375
Validation loss: 2.4742226723777483

Epoch: 5| Step: 7
Training loss: 2.7879430410239547
Validation loss: 2.470397270882702

Epoch: 5| Step: 8
Training loss: 1.7855459242880591
Validation loss: 2.480770875648366

Epoch: 5| Step: 9
Training loss: 2.619861022961441
Validation loss: 2.476206793044681

Epoch: 5| Step: 10
Training loss: 1.6830289030352832
Validation loss: 2.470253209096837

Epoch: 5| Step: 11
Training loss: 2.780822035191438
Validation loss: 2.464180350766089

Epoch: 101| Step: 0
Training loss: 2.2451678415950047
Validation loss: 2.488339889051008

Epoch: 5| Step: 1
Training loss: 2.539495624866686
Validation loss: 2.486186462745695

Epoch: 5| Step: 2
Training loss: 2.806786476969886
Validation loss: 2.517788140627825

Epoch: 5| Step: 3
Training loss: 2.1952901275689416
Validation loss: 2.5190071724038297

Epoch: 5| Step: 4
Training loss: 2.001502188161759
Validation loss: 2.538120983351994

Epoch: 5| Step: 5
Training loss: 2.3696103428369573
Validation loss: 2.5441321950497824

Epoch: 5| Step: 6
Training loss: 1.9863859185107235
Validation loss: 2.513618435077965

Epoch: 5| Step: 7
Training loss: 1.7725011563532707
Validation loss: 2.5211804830051485

Epoch: 5| Step: 8
Training loss: 1.7245216563328543
Validation loss: 2.5165131266811374

Epoch: 5| Step: 9
Training loss: 2.141823760132989
Validation loss: 2.4887079125611637

Epoch: 5| Step: 10
Training loss: 2.6308859276511294
Validation loss: 2.510438777831485

Epoch: 5| Step: 11
Training loss: 2.7132767580337314
Validation loss: 2.5069202428238375

Epoch: 102| Step: 0
Training loss: 1.9202421121136057
Validation loss: 2.497494705889554

Epoch: 5| Step: 1
Training loss: 2.106197195777841
Validation loss: 2.48543365682682

Epoch: 5| Step: 2
Training loss: 2.3897971920330545
Validation loss: 2.464273760666561

Epoch: 5| Step: 3
Training loss: 2.5422155902719727
Validation loss: 2.453674866265622

Epoch: 5| Step: 4
Training loss: 2.0325566710657172
Validation loss: 2.4816938723906175

Epoch: 5| Step: 5
Training loss: 2.238540075226708
Validation loss: 2.4425801194032

Epoch: 5| Step: 6
Training loss: 2.5554771019692124
Validation loss: 2.4572651038702293

Epoch: 5| Step: 7
Training loss: 2.6251220674743156
Validation loss: 2.4635598193434705

Epoch: 5| Step: 8
Training loss: 2.097201676369826
Validation loss: 2.468204496369984

Epoch: 5| Step: 9
Training loss: 1.8184338481661217
Validation loss: 2.4858628222431833

Epoch: 5| Step: 10
Training loss: 2.201921932641739
Validation loss: 2.466710012340738

Epoch: 5| Step: 11
Training loss: 2.09417583633077
Validation loss: 2.4698351193492005

Epoch: 103| Step: 0
Training loss: 2.8970657763165626
Validation loss: 2.4855384381678785

Epoch: 5| Step: 1
Training loss: 2.685911463178004
Validation loss: 2.455904076915054

Epoch: 5| Step: 2
Training loss: 2.3502683405156994
Validation loss: 2.476489712821825

Epoch: 5| Step: 3
Training loss: 2.507026620529527
Validation loss: 2.5099370895375657

Epoch: 5| Step: 4
Training loss: 1.7816904426941416
Validation loss: 2.519687314584479

Epoch: 5| Step: 5
Training loss: 1.7843518604708946
Validation loss: 2.5027311625627986

Epoch: 5| Step: 6
Training loss: 1.7913120569419108
Validation loss: 2.489897122951658

Epoch: 5| Step: 7
Training loss: 1.884828240337817
Validation loss: 2.488829719464793

Epoch: 5| Step: 8
Training loss: 2.511031417182225
Validation loss: 2.504698891236025

Epoch: 5| Step: 9
Training loss: 2.326732346974879
Validation loss: 2.4790184046118653

Epoch: 5| Step: 10
Training loss: 1.8589044825088654
Validation loss: 2.4654633861093123

Epoch: 5| Step: 11
Training loss: 1.6803892577029778
Validation loss: 2.4778536530556137

Epoch: 104| Step: 0
Training loss: 2.648194338458177
Validation loss: 2.4942789738898554

Epoch: 5| Step: 1
Training loss: 1.8626115343121565
Validation loss: 2.5074734087187283

Epoch: 5| Step: 2
Training loss: 1.8440763540285703
Validation loss: 2.51169748727392

Epoch: 5| Step: 3
Training loss: 2.618907397508754
Validation loss: 2.490016424078312

Epoch: 5| Step: 4
Training loss: 1.6929260896343348
Validation loss: 2.4880740380356348

Epoch: 5| Step: 5
Training loss: 1.7672049955788733
Validation loss: 2.497377188052418

Epoch: 5| Step: 6
Training loss: 2.5701835623173586
Validation loss: 2.4769467598236186

Epoch: 5| Step: 7
Training loss: 2.4638777349717262
Validation loss: 2.468973849807388

Epoch: 5| Step: 8
Training loss: 2.4212052926744776
Validation loss: 2.4801886893536795

Epoch: 5| Step: 9
Training loss: 2.0458401692179766
Validation loss: 2.4701849875374178

Epoch: 5| Step: 10
Training loss: 2.42443859641402
Validation loss: 2.455694294773266

Epoch: 5| Step: 11
Training loss: 1.8536124812104788
Validation loss: 2.4612705187041546

Epoch: 105| Step: 0
Training loss: 2.630562655815184
Validation loss: 2.5162086836405466

Epoch: 5| Step: 1
Training loss: 2.259422282756999
Validation loss: 2.4888531493265753

Epoch: 5| Step: 2
Training loss: 1.8191877172664388
Validation loss: 2.471570974526688

Epoch: 5| Step: 3
Training loss: 1.9324730293592844
Validation loss: 2.5183318642179224

Epoch: 5| Step: 4
Training loss: 2.266994719981678
Validation loss: 2.5086956865557606

Epoch: 5| Step: 5
Training loss: 2.8219630940522795
Validation loss: 2.546090326953611

Epoch: 5| Step: 6
Training loss: 2.1137480440587537
Validation loss: 2.534655842427187

Epoch: 5| Step: 7
Training loss: 1.745999054186413
Validation loss: 2.521444255845558

Epoch: 5| Step: 8
Training loss: 2.8843077216769357
Validation loss: 2.4824277215944317

Epoch: 5| Step: 9
Training loss: 1.6789307774899558
Validation loss: 2.495125277730687

Epoch: 5| Step: 10
Training loss: 2.1693449583971076
Validation loss: 2.4947057893714906

Epoch: 5| Step: 11
Training loss: 2.1065984466025487
Validation loss: 2.5035837633313527

Epoch: 106| Step: 0
Training loss: 1.9562450664811493
Validation loss: 2.462754732114439

Epoch: 5| Step: 1
Training loss: 2.3540685740151606
Validation loss: 2.4629752346009033

Epoch: 5| Step: 2
Training loss: 2.168960262077025
Validation loss: 2.4661339407408844

Epoch: 5| Step: 3
Training loss: 2.292938284208541
Validation loss: 2.4762224591704007

Epoch: 5| Step: 4
Training loss: 1.4660506096153751
Validation loss: 2.4583605802502366

Epoch: 5| Step: 5
Training loss: 2.4883315531917405
Validation loss: 2.4785169516766032

Epoch: 5| Step: 6
Training loss: 2.106187347476401
Validation loss: 2.470968533259098

Epoch: 5| Step: 7
Training loss: 2.7412213745570813
Validation loss: 2.4724371332405384

Epoch: 5| Step: 8
Training loss: 2.3651075636293206
Validation loss: 2.479470624375455

Epoch: 5| Step: 9
Training loss: 2.0783009848974436
Validation loss: 2.476423197457685

Epoch: 5| Step: 10
Training loss: 2.302969599415085
Validation loss: 2.475167843477033

Epoch: 5| Step: 11
Training loss: 1.8396071749647431
Validation loss: 2.4647962885023795

Epoch: 107| Step: 0
Training loss: 2.1237411136003455
Validation loss: 2.4594490151616224

Epoch: 5| Step: 1
Training loss: 2.1501642120105244
Validation loss: 2.485939241189305

Epoch: 5| Step: 2
Training loss: 2.943518621013534
Validation loss: 2.471355061720166

Epoch: 5| Step: 3
Training loss: 2.139725099180041
Validation loss: 2.468708297522132

Epoch: 5| Step: 4
Training loss: 1.8704326951134764
Validation loss: 2.475929343778956

Epoch: 5| Step: 5
Training loss: 1.8916791388930934
Validation loss: 2.465573141973313

Epoch: 5| Step: 6
Training loss: 2.5725826916689876
Validation loss: 2.510720275522152

Epoch: 5| Step: 7
Training loss: 2.4345359386675356
Validation loss: 2.546582846861997

Epoch: 5| Step: 8
Training loss: 2.091681754170548
Validation loss: 2.5016175322204766

Epoch: 5| Step: 9
Training loss: 1.9702956172452746
Validation loss: 2.486991308425637

Epoch: 5| Step: 10
Training loss: 2.1566694653280143
Validation loss: 2.4974301759800253

Epoch: 5| Step: 11
Training loss: 1.514431355585333
Validation loss: 2.4735677042636803

Epoch: 108| Step: 0
Training loss: 2.3702910068369842
Validation loss: 2.4805902085892404

Epoch: 5| Step: 1
Training loss: 1.9718865734310844
Validation loss: 2.4902868247897625

Epoch: 5| Step: 2
Training loss: 2.2278875323387597
Validation loss: 2.4945715021983084

Epoch: 5| Step: 3
Training loss: 2.628976806782088
Validation loss: 2.495021557950498

Epoch: 5| Step: 4
Training loss: 1.8977413078333172
Validation loss: 2.4928260949694914

Epoch: 5| Step: 5
Training loss: 2.30845071055783
Validation loss: 2.4673639261382547

Epoch: 5| Step: 6
Training loss: 1.9930842756032627
Validation loss: 2.4790739207724184

Epoch: 5| Step: 7
Training loss: 2.11456496758464
Validation loss: 2.490897922248509

Epoch: 5| Step: 8
Training loss: 2.1293480091047057
Validation loss: 2.4890404246265896

Epoch: 5| Step: 9
Training loss: 2.3969268514701962
Validation loss: 2.500169720451813

Epoch: 5| Step: 10
Training loss: 2.0754149699923765
Validation loss: 2.4949732311548107

Epoch: 5| Step: 11
Training loss: 2.2432450515282665
Validation loss: 2.4966790990961325

Epoch: 109| Step: 0
Training loss: 2.2724055409287858
Validation loss: 2.4747168525894407

Epoch: 5| Step: 1
Training loss: 2.315951992736445
Validation loss: 2.46396926545455

Epoch: 5| Step: 2
Training loss: 2.362088796362888
Validation loss: 2.4574982119036637

Epoch: 5| Step: 3
Training loss: 2.3499944281004734
Validation loss: 2.4671452010307386

Epoch: 5| Step: 4
Training loss: 1.8780150649509548
Validation loss: 2.4814467116723136

Epoch: 5| Step: 5
Training loss: 2.2098215474710803
Validation loss: 2.4780101736692197

Epoch: 5| Step: 6
Training loss: 2.624101303302503
Validation loss: 2.462329676590497

Epoch: 5| Step: 7
Training loss: 2.099492865590063
Validation loss: 2.45430510173129

Epoch: 5| Step: 8
Training loss: 2.30155468102271
Validation loss: 2.466705235993783

Epoch: 5| Step: 9
Training loss: 2.2147997224391096
Validation loss: 2.4468174285741595

Epoch: 5| Step: 10
Training loss: 1.5180818760017105
Validation loss: 2.461325272784134

Epoch: 5| Step: 11
Training loss: 2.381221652926029
Validation loss: 2.4920290275740973

Epoch: 110| Step: 0
Training loss: 1.9499727369505615
Validation loss: 2.4545145169308866

Epoch: 5| Step: 1
Training loss: 2.2789766663666184
Validation loss: 2.4925695503157916

Epoch: 5| Step: 2
Training loss: 1.8447111824812144
Validation loss: 2.4657720197222797

Epoch: 5| Step: 3
Training loss: 2.8999080577613556
Validation loss: 2.4942792168380308

Epoch: 5| Step: 4
Training loss: 2.27338317596447
Validation loss: 2.442919034078918

Epoch: 5| Step: 5
Training loss: 1.9539716792753252
Validation loss: 2.4710293319527654

Epoch: 5| Step: 6
Training loss: 2.1340139728792997
Validation loss: 2.4744249379012895

Epoch: 5| Step: 7
Training loss: 2.226701591564248
Validation loss: 2.472915326487417

Epoch: 5| Step: 8
Training loss: 1.844881518728439
Validation loss: 2.4755707488888823

Epoch: 5| Step: 9
Training loss: 2.5892281699715682
Validation loss: 2.466345199265979

Epoch: 5| Step: 10
Training loss: 2.179323665100727
Validation loss: 2.4611591098045356

Epoch: 5| Step: 11
Training loss: 1.0742935432058953
Validation loss: 2.489063984211337

Epoch: 111| Step: 0
Training loss: 1.8208459555437935
Validation loss: 2.4847994747653805

Epoch: 5| Step: 1
Training loss: 2.5948581396588164
Validation loss: 2.481868327021444

Epoch: 5| Step: 2
Training loss: 1.9741071445331744
Validation loss: 2.4668280447759803

Epoch: 5| Step: 3
Training loss: 2.239986708635679
Validation loss: 2.463815800184734

Epoch: 5| Step: 4
Training loss: 2.743735373768675
Validation loss: 2.4772399633588416

Epoch: 5| Step: 5
Training loss: 1.7282086978117368
Validation loss: 2.5100399713449137

Epoch: 5| Step: 6
Training loss: 1.7564818368391266
Validation loss: 2.472102371863484

Epoch: 5| Step: 7
Training loss: 2.297923880110688
Validation loss: 2.4754672792627725

Epoch: 5| Step: 8
Training loss: 2.2775420271076667
Validation loss: 2.4931171560749816

Epoch: 5| Step: 9
Training loss: 2.266476701274614
Validation loss: 2.4616609791561053

Epoch: 5| Step: 10
Training loss: 1.8682632220563642
Validation loss: 2.4747476476402572

Epoch: 5| Step: 11
Training loss: 2.9387960618407702
Validation loss: 2.473704055300357

Epoch: 112| Step: 0
Training loss: 2.6705334959773874
Validation loss: 2.4680699123939838

Epoch: 5| Step: 1
Training loss: 2.6836371050446193
Validation loss: 2.4555278640284146

Epoch: 5| Step: 2
Training loss: 2.096097398911868
Validation loss: 2.4890348290427733

Epoch: 5| Step: 3
Training loss: 2.202431427562555
Validation loss: 2.4725354704001687

Epoch: 5| Step: 4
Training loss: 2.1022165408112574
Validation loss: 2.487274904625698

Epoch: 5| Step: 5
Training loss: 1.9050304076003186
Validation loss: 2.506476437557157

Epoch: 5| Step: 6
Training loss: 2.3070786308179563
Validation loss: 2.4818533309615627

Epoch: 5| Step: 7
Training loss: 2.228137613611244
Validation loss: 2.475327393362944

Epoch: 5| Step: 8
Training loss: 2.001330767400945
Validation loss: 2.4849154926056216

Epoch: 5| Step: 9
Training loss: 1.1637384360422116
Validation loss: 2.510718198266224

Epoch: 5| Step: 10
Training loss: 1.934826760237869
Validation loss: 2.5049574575028677

Epoch: 5| Step: 11
Training loss: 2.8489098321016257
Validation loss: 2.4705096665384803

Epoch: 113| Step: 0
Training loss: 2.438420244268549
Validation loss: 2.509527641917502

Epoch: 5| Step: 1
Training loss: 1.9373357149430241
Validation loss: 2.48185567854238

Epoch: 5| Step: 2
Training loss: 2.5353482824635973
Validation loss: 2.4677417281598983

Epoch: 5| Step: 3
Training loss: 2.2606527553855167
Validation loss: 2.4765888337059976

Epoch: 5| Step: 4
Training loss: 1.4296340515485233
Validation loss: 2.4686178300783586

Epoch: 5| Step: 5
Training loss: 2.591918298540406
Validation loss: 2.4743374718048146

Epoch: 5| Step: 6
Training loss: 2.256366623165386
Validation loss: 2.4451339644316543

Epoch: 5| Step: 7
Training loss: 2.239902621434584
Validation loss: 2.46365169228373

Epoch: 5| Step: 8
Training loss: 1.6961014138166761
Validation loss: 2.474642072189119

Epoch: 5| Step: 9
Training loss: 2.60540624998243
Validation loss: 2.4873967058214395

Epoch: 5| Step: 10
Training loss: 1.7255320516310484
Validation loss: 2.4576601457755936

Epoch: 5| Step: 11
Training loss: 1.298315466185327
Validation loss: 2.4599134262159073

Epoch: 114| Step: 0
Training loss: 2.221794081876343
Validation loss: 2.4538873127867795

Epoch: 5| Step: 1
Training loss: 1.969682926570298
Validation loss: 2.4528236285031038

Epoch: 5| Step: 2
Training loss: 2.491951575517494
Validation loss: 2.469803963390186

Epoch: 5| Step: 3
Training loss: 1.716185303515386
Validation loss: 2.4834955206228324

Epoch: 5| Step: 4
Training loss: 1.980689403272898
Validation loss: 2.470568482119001

Epoch: 5| Step: 5
Training loss: 2.0185664988164356
Validation loss: 2.505312710581558

Epoch: 5| Step: 6
Training loss: 1.9058999537522343
Validation loss: 2.4922038907874335

Epoch: 5| Step: 7
Training loss: 2.4011916460595053
Validation loss: 2.499865546187215

Epoch: 5| Step: 8
Training loss: 2.132649174399792
Validation loss: 2.502605939712981

Epoch: 5| Step: 9
Training loss: 2.470243171428426
Validation loss: 2.4485790810612094

Epoch: 5| Step: 10
Training loss: 2.1454213558621658
Validation loss: 2.49488336372028

Epoch: 5| Step: 11
Training loss: 2.102589409522606
Validation loss: 2.4787668151464666

Epoch: 115| Step: 0
Training loss: 2.2107237587855004
Validation loss: 2.511196046489834

Epoch: 5| Step: 1
Training loss: 2.6565553377470246
Validation loss: 2.5014716585190455

Epoch: 5| Step: 2
Training loss: 1.775042710663483
Validation loss: 2.507921495772571

Epoch: 5| Step: 3
Training loss: 1.832610406815296
Validation loss: 2.5023434781397826

Epoch: 5| Step: 4
Training loss: 2.526291122441582
Validation loss: 2.492131901263349

Epoch: 5| Step: 5
Training loss: 2.298283255540747
Validation loss: 2.503745460207768

Epoch: 5| Step: 6
Training loss: 2.2542855457635307
Validation loss: 2.5152727575484315

Epoch: 5| Step: 7
Training loss: 2.0336578183188236
Validation loss: 2.497686571389194

Epoch: 5| Step: 8
Training loss: 1.8415131011505144
Validation loss: 2.471388002947169

Epoch: 5| Step: 9
Training loss: 2.1807245228197645
Validation loss: 2.490447262907963

Epoch: 5| Step: 10
Training loss: 1.8510372527468264
Validation loss: 2.483223352274359

Epoch: 5| Step: 11
Training loss: 2.4293500169117643
Validation loss: 2.4854392365365876

Epoch: 116| Step: 0
Training loss: 2.209107197417132
Validation loss: 2.465636217150618

Epoch: 5| Step: 1
Training loss: 2.4201748694930663
Validation loss: 2.4625005733340863

Epoch: 5| Step: 2
Training loss: 1.8521490656799262
Validation loss: 2.4404413376400718

Epoch: 5| Step: 3
Training loss: 2.9060094590266132
Validation loss: 2.468138832381317

Epoch: 5| Step: 4
Training loss: 1.9673139996566993
Validation loss: 2.474294887873278

Epoch: 5| Step: 5
Training loss: 2.1754934781502153
Validation loss: 2.500328785416112

Epoch: 5| Step: 6
Training loss: 1.9091919257120542
Validation loss: 2.5400990996402473

Epoch: 5| Step: 7
Training loss: 1.974997281422736
Validation loss: 2.5375751540606837

Epoch: 5| Step: 8
Training loss: 2.502733548114962
Validation loss: 2.545076991536096

Epoch: 5| Step: 9
Training loss: 1.9920417881952521
Validation loss: 2.5274598351949455

Epoch: 5| Step: 10
Training loss: 1.7511482558826397
Validation loss: 2.4776670277284465

Epoch: 5| Step: 11
Training loss: 1.8563441088932189
Validation loss: 2.483594147909252

Epoch: 117| Step: 0
Training loss: 2.402086693881867
Validation loss: 2.4624932311621777

Epoch: 5| Step: 1
Training loss: 2.048378079481482
Validation loss: 2.4666856351544078

Epoch: 5| Step: 2
Training loss: 2.123234520334158
Validation loss: 2.4659521408848537

Epoch: 5| Step: 3
Training loss: 2.8267803894714376
Validation loss: 2.460913154441261

Epoch: 5| Step: 4
Training loss: 1.9923492964322649
Validation loss: 2.4727297626834925

Epoch: 5| Step: 5
Training loss: 1.8517215193696461
Validation loss: 2.4918842589588497

Epoch: 5| Step: 6
Training loss: 1.934630021892945
Validation loss: 2.4542123365011803

Epoch: 5| Step: 7
Training loss: 1.866082602758842
Validation loss: 2.467515165809938

Epoch: 5| Step: 8
Training loss: 2.01197496282573
Validation loss: 2.4734414065874986

Epoch: 5| Step: 9
Training loss: 2.318486480956473
Validation loss: 2.448312282383033

Epoch: 5| Step: 10
Training loss: 2.315211690859484
Validation loss: 2.458856813143455

Epoch: 5| Step: 11
Training loss: 0.795225867928505
Validation loss: 2.498795757727113

Epoch: 118| Step: 0
Training loss: 1.5235880459469486
Validation loss: 2.4992024659555123

Epoch: 5| Step: 1
Training loss: 1.6254572591803573
Validation loss: 2.4926841862730176

Epoch: 5| Step: 2
Training loss: 2.2797071909691375
Validation loss: 2.457331345450594

Epoch: 5| Step: 3
Training loss: 2.308700326696024
Validation loss: 2.487066686132182

Epoch: 5| Step: 4
Training loss: 2.9522249979735062
Validation loss: 2.490123527902126

Epoch: 5| Step: 5
Training loss: 1.5927948426960672
Validation loss: 2.503331146609659

Epoch: 5| Step: 6
Training loss: 2.337064337292469
Validation loss: 2.5038555753105913

Epoch: 5| Step: 7
Training loss: 1.6482572050164228
Validation loss: 2.5050412153360986

Epoch: 5| Step: 8
Training loss: 2.1257823177224213
Validation loss: 2.539971628043144

Epoch: 5| Step: 9
Training loss: 2.1297122094672343
Validation loss: 2.5166117310580685

Epoch: 5| Step: 10
Training loss: 2.504498630382417
Validation loss: 2.5165785370378932

Epoch: 5| Step: 11
Training loss: 2.057604673372007
Validation loss: 2.467258819876375

Epoch: 119| Step: 0
Training loss: 2.220403243377631
Validation loss: 2.460374111697944

Epoch: 5| Step: 1
Training loss: 2.042321301303987
Validation loss: 2.4740136685791754

Epoch: 5| Step: 2
Training loss: 1.9406887394117118
Validation loss: 2.4703128049023073

Epoch: 5| Step: 3
Training loss: 2.134694592968517
Validation loss: 2.4695525333686557

Epoch: 5| Step: 4
Training loss: 1.8780567683617044
Validation loss: 2.472518694096278

Epoch: 5| Step: 5
Training loss: 2.3299033522310113
Validation loss: 2.478848458285785

Epoch: 5| Step: 6
Training loss: 2.1726303433736156
Validation loss: 2.4700728465675383

Epoch: 5| Step: 7
Training loss: 2.35750450109576
Validation loss: 2.469036612794013

Epoch: 5| Step: 8
Training loss: 1.8139442740463951
Validation loss: 2.4718781924960567

Epoch: 5| Step: 9
Training loss: 2.550716662209906
Validation loss: 2.467978775504788

Epoch: 5| Step: 10
Training loss: 1.6278951969623507
Validation loss: 2.4568273341432123

Epoch: 5| Step: 11
Training loss: 3.16248423455572
Validation loss: 2.4648632667441897

Epoch: 120| Step: 0
Training loss: 2.2947223982455407
Validation loss: 2.495577500615207

Epoch: 5| Step: 1
Training loss: 2.3063526409848163
Validation loss: 2.5218533246740855

Epoch: 5| Step: 2
Training loss: 2.250657197551936
Validation loss: 2.520052484815373

Epoch: 5| Step: 3
Training loss: 1.3826656802409034
Validation loss: 2.492250383913083

Epoch: 5| Step: 4
Training loss: 2.0221249362520854
Validation loss: 2.5219581054582862

Epoch: 5| Step: 5
Training loss: 2.2071356014462244
Validation loss: 2.5202621464390726

Epoch: 5| Step: 6
Training loss: 1.706218814215525
Validation loss: 2.518243493108751

Epoch: 5| Step: 7
Training loss: 2.569409243597443
Validation loss: 2.49580537645564

Epoch: 5| Step: 8
Training loss: 2.254196915156217
Validation loss: 2.4699501347688537

Epoch: 5| Step: 9
Training loss: 2.3087393622780654
Validation loss: 2.459954702327267

Epoch: 5| Step: 10
Training loss: 2.035032770141384
Validation loss: 2.468867836324977

Epoch: 5| Step: 11
Training loss: 1.5275028858063904
Validation loss: 2.4837563742159237

Epoch: 121| Step: 0
Training loss: 2.344282979763532
Validation loss: 2.4585652861570275

Epoch: 5| Step: 1
Training loss: 1.9928575772598973
Validation loss: 2.45336371068271

Epoch: 5| Step: 2
Training loss: 2.8059256113405704
Validation loss: 2.465661180856868

Epoch: 5| Step: 3
Training loss: 2.0552049572686992
Validation loss: 2.467126678786549

Epoch: 5| Step: 4
Training loss: 1.9387791625632804
Validation loss: 2.462603151675036

Epoch: 5| Step: 5
Training loss: 1.97401299983868
Validation loss: 2.4711053332414

Epoch: 5| Step: 6
Training loss: 2.0295123370487085
Validation loss: 2.4813503350791355

Epoch: 5| Step: 7
Training loss: 1.7278254796087564
Validation loss: 2.518046581877466

Epoch: 5| Step: 8
Training loss: 2.4735750778213497
Validation loss: 2.4813871610799327

Epoch: 5| Step: 9
Training loss: 2.101361233174248
Validation loss: 2.5112045655635096

Epoch: 5| Step: 10
Training loss: 1.6155787773087105
Validation loss: 2.508378977983381

Epoch: 5| Step: 11
Training loss: 1.36986519310399
Validation loss: 2.4783736765208904

Epoch: 122| Step: 0
Training loss: 1.8919484574190693
Validation loss: 2.4762875978984438

Epoch: 5| Step: 1
Training loss: 2.459283084921003
Validation loss: 2.5028872546487353

Epoch: 5| Step: 2
Training loss: 2.3245688294977436
Validation loss: 2.452906110842463

Epoch: 5| Step: 3
Training loss: 1.77494217147113
Validation loss: 2.457180667573215

Epoch: 5| Step: 4
Training loss: 1.7820276938490314
Validation loss: 2.453648885845007

Epoch: 5| Step: 5
Training loss: 2.026950099705357
Validation loss: 2.449841174342821

Epoch: 5| Step: 6
Training loss: 2.2662865034762536
Validation loss: 2.463527132331497

Epoch: 5| Step: 7
Training loss: 2.016992977109304
Validation loss: 2.466073226799807

Epoch: 5| Step: 8
Training loss: 2.2224896574691577
Validation loss: 2.468536669531602

Epoch: 5| Step: 9
Training loss: 2.0510131704799406
Validation loss: 2.4509151734669476

Epoch: 5| Step: 10
Training loss: 2.069152967960991
Validation loss: 2.4749645689794746

Epoch: 5| Step: 11
Training loss: 2.0263223592556505
Validation loss: 2.4925755325269625

Epoch: 123| Step: 0
Training loss: 2.324248292879469
Validation loss: 2.476831387464675

Epoch: 5| Step: 1
Training loss: 2.014417656361931
Validation loss: 2.5043377516873537

Epoch: 5| Step: 2
Training loss: 2.273136079607548
Validation loss: 2.4622533318054893

Epoch: 5| Step: 3
Training loss: 1.9132703114917702
Validation loss: 2.4578738907998074

Epoch: 5| Step: 4
Training loss: 2.052409370456583
Validation loss: 2.5097539166722886

Epoch: 5| Step: 5
Training loss: 2.730503240321105
Validation loss: 2.4514155212326876

Epoch: 5| Step: 6
Training loss: 1.9205924616104715
Validation loss: 2.4556561368491083

Epoch: 5| Step: 7
Training loss: 2.008055319742157
Validation loss: 2.4668345122538025

Epoch: 5| Step: 8
Training loss: 1.8833324933120519
Validation loss: 2.4660094336573932

Epoch: 5| Step: 9
Training loss: 1.4327937500370609
Validation loss: 2.428339953504068

Epoch: 5| Step: 10
Training loss: 1.9821232312383348
Validation loss: 2.493591674361457

Epoch: 5| Step: 11
Training loss: 2.3281757938041254
Validation loss: 2.462997466474142

Epoch: 124| Step: 0
Training loss: 2.270909322697959
Validation loss: 2.5159716041574245

Epoch: 5| Step: 1
Training loss: 1.6086200313635146
Validation loss: 2.4663948724206564

Epoch: 5| Step: 2
Training loss: 2.4875340560038675
Validation loss: 2.478208454197262

Epoch: 5| Step: 3
Training loss: 1.8574460065138523
Validation loss: 2.487063181125465

Epoch: 5| Step: 4
Training loss: 2.1079804508381295
Validation loss: 2.4902806495904777

Epoch: 5| Step: 5
Training loss: 2.288530828293729
Validation loss: 2.4891880405246103

Epoch: 5| Step: 6
Training loss: 2.1491996384342587
Validation loss: 2.4912543627618926

Epoch: 5| Step: 7
Training loss: 2.009546622011442
Validation loss: 2.474691588840831

Epoch: 5| Step: 8
Training loss: 2.0615266757435484
Validation loss: 2.450262939201

Epoch: 5| Step: 9
Training loss: 1.665481964897783
Validation loss: 2.4658795783345466

Epoch: 5| Step: 10
Training loss: 2.0218705992378085
Validation loss: 2.424776646317124

Epoch: 5| Step: 11
Training loss: 1.9871397207712755
Validation loss: 2.4631664193300793

Epoch: 125| Step: 0
Training loss: 2.076563886953426
Validation loss: 2.4754521681780344

Epoch: 5| Step: 1
Training loss: 1.7861672508127497
Validation loss: 2.4607511540659877

Epoch: 5| Step: 2
Training loss: 1.8126150292036223
Validation loss: 2.432139758826346

Epoch: 5| Step: 3
Training loss: 1.7704723962691222
Validation loss: 2.4640293902049573

Epoch: 5| Step: 4
Training loss: 1.6397707940638593
Validation loss: 2.4609626566897886

Epoch: 5| Step: 5
Training loss: 1.908986300847421
Validation loss: 2.4388809286401365

Epoch: 5| Step: 6
Training loss: 2.5608904365837355
Validation loss: 2.4966910159583575

Epoch: 5| Step: 7
Training loss: 2.358553711891557
Validation loss: 2.48195489132184

Epoch: 5| Step: 8
Training loss: 2.4554224614954765
Validation loss: 2.468792440154258

Epoch: 5| Step: 9
Training loss: 2.316112583322907
Validation loss: 2.477513095758229

Epoch: 5| Step: 10
Training loss: 1.5697346853112748
Validation loss: 2.4429834301764366

Epoch: 5| Step: 11
Training loss: 2.7944288585355435
Validation loss: 2.4329730855331384

Epoch: 126| Step: 0
Training loss: 2.0214400281971403
Validation loss: 2.473308659963421

Epoch: 5| Step: 1
Training loss: 2.445832900957614
Validation loss: 2.486270115753239

Epoch: 5| Step: 2
Training loss: 1.7419059765446085
Validation loss: 2.4449002748238047

Epoch: 5| Step: 3
Training loss: 1.5514862994548937
Validation loss: 2.4657061841884564

Epoch: 5| Step: 4
Training loss: 1.8460291337414125
Validation loss: 2.447866343258274

Epoch: 5| Step: 5
Training loss: 2.6825635062430218
Validation loss: 2.467996900912544

Epoch: 5| Step: 6
Training loss: 2.3042465564014605
Validation loss: 2.4831477998918503

Epoch: 5| Step: 7
Training loss: 1.8028440101159033
Validation loss: 2.451500693020874

Epoch: 5| Step: 8
Training loss: 2.1845609266533956
Validation loss: 2.4597155832393356

Epoch: 5| Step: 9
Training loss: 1.865205103459781
Validation loss: 2.5161901514446865

Epoch: 5| Step: 10
Training loss: 1.8609926896195108
Validation loss: 2.5075211241806272

Epoch: 5| Step: 11
Training loss: 1.857727089884497
Validation loss: 2.507190167620864

Epoch: 127| Step: 0
Training loss: 1.913196476794681
Validation loss: 2.4712682145623988

Epoch: 5| Step: 1
Training loss: 2.144209484982921
Validation loss: 2.471319935316705

Epoch: 5| Step: 2
Training loss: 2.5150943931020517
Validation loss: 2.473863781912432

Epoch: 5| Step: 3
Training loss: 1.842780229953201
Validation loss: 2.441271973032654

Epoch: 5| Step: 4
Training loss: 1.840266282467557
Validation loss: 2.4861385955451594

Epoch: 5| Step: 5
Training loss: 1.9053525844697694
Validation loss: 2.471704718780674

Epoch: 5| Step: 6
Training loss: 2.03811085443112
Validation loss: 2.4702391217645996

Epoch: 5| Step: 7
Training loss: 2.0758336564161657
Validation loss: 2.4689955287474157

Epoch: 5| Step: 8
Training loss: 2.1549003910843783
Validation loss: 2.462468989736938

Epoch: 5| Step: 9
Training loss: 1.788087870890032
Validation loss: 2.427247839306547

Epoch: 5| Step: 10
Training loss: 2.3287825711849917
Validation loss: 2.4723401020701954

Epoch: 5| Step: 11
Training loss: 1.7763976544854962
Validation loss: 2.468097846090391

Epoch: 128| Step: 0
Training loss: 1.9687646532270286
Validation loss: 2.485006591997927

Epoch: 5| Step: 1
Training loss: 2.4563979164993053
Validation loss: 2.6105626234170995

Epoch: 5| Step: 2
Training loss: 2.4213819432581714
Validation loss: 2.5640434331066824

Epoch: 5| Step: 3
Training loss: 2.0874509428735823
Validation loss: 2.583219419295593

Epoch: 5| Step: 4
Training loss: 2.0984512612693322
Validation loss: 2.561340620250785

Epoch: 5| Step: 5
Training loss: 2.1191939527420276
Validation loss: 2.547179018687533

Epoch: 5| Step: 6
Training loss: 2.0715316925313068
Validation loss: 2.527410334359044

Epoch: 5| Step: 7
Training loss: 1.5427012537609843
Validation loss: 2.515441425804665

Epoch: 5| Step: 8
Training loss: 1.6331780129495412
Validation loss: 2.4702944270515808

Epoch: 5| Step: 9
Training loss: 2.303339159673378
Validation loss: 2.491799634290181

Epoch: 5| Step: 10
Training loss: 1.4384144072302287
Validation loss: 2.4470141444749034

Epoch: 5| Step: 11
Training loss: 2.3867041654500176
Validation loss: 2.4586477900213652

Epoch: 129| Step: 0
Training loss: 1.8500604774281304
Validation loss: 2.437601107758215

Epoch: 5| Step: 1
Training loss: 2.1312195135268555
Validation loss: 2.436832532216685

Epoch: 5| Step: 2
Training loss: 1.9508410718466431
Validation loss: 2.423774823164461

Epoch: 5| Step: 3
Training loss: 1.7611070742529094
Validation loss: 2.4598420646833103

Epoch: 5| Step: 4
Training loss: 1.7247304733460462
Validation loss: 2.461667807263898

Epoch: 5| Step: 5
Training loss: 2.383337344541931
Validation loss: 2.4602523455442435

Epoch: 5| Step: 6
Training loss: 2.719082252983979
Validation loss: 2.468701125719469

Epoch: 5| Step: 7
Training loss: 2.224176138606031
Validation loss: 2.4766943462266067

Epoch: 5| Step: 8
Training loss: 1.566355716337301
Validation loss: 2.459116347662167

Epoch: 5| Step: 9
Training loss: 1.8722301369162373
Validation loss: 2.4840651184930764

Epoch: 5| Step: 10
Training loss: 1.5822963162877686
Validation loss: 2.4816643624351604

Epoch: 5| Step: 11
Training loss: 2.496602228994306
Validation loss: 2.4906520238963425

Epoch: 130| Step: 0
Training loss: 2.0848069002305176
Validation loss: 2.4450680668450273

Epoch: 5| Step: 1
Training loss: 1.6902518264225759
Validation loss: 2.4963150722266

Epoch: 5| Step: 2
Training loss: 1.529564533220289
Validation loss: 2.4474028974811195

Epoch: 5| Step: 3
Training loss: 2.4429826941609156
Validation loss: 2.4387384879229788

Epoch: 5| Step: 4
Training loss: 2.3854826428036384
Validation loss: 2.4409313177374696

Epoch: 5| Step: 5
Training loss: 2.05197567988181
Validation loss: 2.4190839004703415

Epoch: 5| Step: 6
Training loss: 1.9702443098207032
Validation loss: 2.462041524462275

Epoch: 5| Step: 7
Training loss: 1.817400063622953
Validation loss: 2.462457625352082

Epoch: 5| Step: 8
Training loss: 2.2593078940992872
Validation loss: 2.446901002488351

Epoch: 5| Step: 9
Training loss: 1.8723651174290468
Validation loss: 2.4563475336280476

Epoch: 5| Step: 10
Training loss: 1.971800363521618
Validation loss: 2.499201472227556

Epoch: 5| Step: 11
Training loss: 1.2458560920261113
Validation loss: 2.488362133841444

Epoch: 131| Step: 0
Training loss: 2.469711406234386
Validation loss: 2.4588346145349185

Epoch: 5| Step: 1
Training loss: 1.921718187835311
Validation loss: 2.4632947279148727

Epoch: 5| Step: 2
Training loss: 2.6279892930635746
Validation loss: 2.505029705021227

Epoch: 5| Step: 3
Training loss: 1.8365882531866429
Validation loss: 2.47552221292695

Epoch: 5| Step: 4
Training loss: 1.576737124069767
Validation loss: 2.4839679896444187

Epoch: 5| Step: 5
Training loss: 2.1041126307231166
Validation loss: 2.4352320896186215

Epoch: 5| Step: 6
Training loss: 2.0520364462309524
Validation loss: 2.4620604763453775

Epoch: 5| Step: 7
Training loss: 2.1460269235733413
Validation loss: 2.464813611087632

Epoch: 5| Step: 8
Training loss: 1.7357111415016002
Validation loss: 2.4432667064906806

Epoch: 5| Step: 9
Training loss: 1.840376661351081
Validation loss: 2.464981575007828

Epoch: 5| Step: 10
Training loss: 1.6952652463172522
Validation loss: 2.474984563833966

Epoch: 5| Step: 11
Training loss: 1.9744633923457844
Validation loss: 2.4766006426676817

Epoch: 132| Step: 0
Training loss: 1.9977237145493496
Validation loss: 2.5593956542433443

Epoch: 5| Step: 1
Training loss: 2.236933810240912
Validation loss: 2.5404275736127024

Epoch: 5| Step: 2
Training loss: 2.013532039844953
Validation loss: 2.5668294974691164

Epoch: 5| Step: 3
Training loss: 2.0461511860957597
Validation loss: 2.553529089828517

Epoch: 5| Step: 4
Training loss: 2.073656253730708
Validation loss: 2.55817397850427

Epoch: 5| Step: 5
Training loss: 2.0347539170899247
Validation loss: 2.5111987147609685

Epoch: 5| Step: 6
Training loss: 1.972888653350535
Validation loss: 2.509027078023513

Epoch: 5| Step: 7
Training loss: 1.6987788891669142
Validation loss: 2.4565265806365866

Epoch: 5| Step: 8
Training loss: 1.5029764843571298
Validation loss: 2.468660976720216

Epoch: 5| Step: 9
Training loss: 1.9719224225854297
Validation loss: 2.460172932046245

Epoch: 5| Step: 10
Training loss: 2.0906181255506953
Validation loss: 2.4852239729651693

Epoch: 5| Step: 11
Training loss: 2.4886479130053742
Validation loss: 2.4138424597148873

Epoch: 133| Step: 0
Training loss: 1.992420497059612
Validation loss: 2.4544539162596615

Epoch: 5| Step: 1
Training loss: 1.968342209014563
Validation loss: 2.4820972693603163

Epoch: 5| Step: 2
Training loss: 1.9673819254207894
Validation loss: 2.460028457270246

Epoch: 5| Step: 3
Training loss: 1.790704764674997
Validation loss: 2.4748317294444315

Epoch: 5| Step: 4
Training loss: 1.9122099338542777
Validation loss: 2.461178647694677

Epoch: 5| Step: 5
Training loss: 2.1363493828510145
Validation loss: 2.4645641871654793

Epoch: 5| Step: 6
Training loss: 2.263251593925162
Validation loss: 2.4794445336254682

Epoch: 5| Step: 7
Training loss: 1.8480369385375772
Validation loss: 2.4564128212676786

Epoch: 5| Step: 8
Training loss: 1.8879919080601253
Validation loss: 2.4275748951610874

Epoch: 5| Step: 9
Training loss: 1.9372794733369008
Validation loss: 2.484446330615948

Epoch: 5| Step: 10
Training loss: 1.7953494022517655
Validation loss: 2.4482296533901557

Epoch: 5| Step: 11
Training loss: 3.710007464666132
Validation loss: 2.4617252078183998

Epoch: 134| Step: 0
Training loss: 2.11426412744438
Validation loss: 2.4267914184453954

Epoch: 5| Step: 1
Training loss: 1.6669422716512479
Validation loss: 2.4518866156786605

Epoch: 5| Step: 2
Training loss: 2.4244125362518356
Validation loss: 2.46009380672802

Epoch: 5| Step: 3
Training loss: 1.7949937343222409
Validation loss: 2.5074341113193137

Epoch: 5| Step: 4
Training loss: 1.9677134615937495
Validation loss: 2.4982841365106516

Epoch: 5| Step: 5
Training loss: 2.2234942795560015
Validation loss: 2.500039084446882

Epoch: 5| Step: 6
Training loss: 2.095724285264212
Validation loss: 2.495248570874341

Epoch: 5| Step: 7
Training loss: 1.637157299493519
Validation loss: 2.489778368717568

Epoch: 5| Step: 8
Training loss: 2.0773398845130218
Validation loss: 2.4506901322089027

Epoch: 5| Step: 9
Training loss: 1.603204322919709
Validation loss: 2.464262174822318

Epoch: 5| Step: 10
Training loss: 1.7065021035209096
Validation loss: 2.4687141021500754

Epoch: 5| Step: 11
Training loss: 2.330094394163393
Validation loss: 2.4467992437140427

Epoch: 135| Step: 0
Training loss: 1.5192899929229526
Validation loss: 2.4558362900369133

Epoch: 5| Step: 1
Training loss: 2.4141840734393054
Validation loss: 2.455579849563385

Epoch: 5| Step: 2
Training loss: 1.4862066913579874
Validation loss: 2.4481996386228557

Epoch: 5| Step: 3
Training loss: 1.435547705410049
Validation loss: 2.454805092409982

Epoch: 5| Step: 4
Training loss: 2.543355745322629
Validation loss: 2.4725535885198098

Epoch: 5| Step: 5
Training loss: 1.5957259850049352
Validation loss: 2.4705910879674304

Epoch: 5| Step: 6
Training loss: 1.921884304117151
Validation loss: 2.452911638995924

Epoch: 5| Step: 7
Training loss: 1.8098611366367534
Validation loss: 2.478905611291597

Epoch: 5| Step: 8
Training loss: 2.4095436442883678
Validation loss: 2.477468655750766

Epoch: 5| Step: 9
Training loss: 2.546753488462056
Validation loss: 2.5066513946652185

Epoch: 5| Step: 10
Training loss: 1.811936915834238
Validation loss: 2.4986861829828406

Epoch: 5| Step: 11
Training loss: 1.529714554108109
Validation loss: 2.4699242973888897

Epoch: 136| Step: 0
Training loss: 1.9323911067193418
Validation loss: 2.523635435264155

Epoch: 5| Step: 1
Training loss: 1.7865779899658303
Validation loss: 2.4673796081481902

Epoch: 5| Step: 2
Training loss: 2.5192180113544977
Validation loss: 2.4843995594914015

Epoch: 5| Step: 3
Training loss: 2.139381883071316
Validation loss: 2.4771838266175332

Epoch: 5| Step: 4
Training loss: 2.035581460123456
Validation loss: 2.4552867217100665

Epoch: 5| Step: 5
Training loss: 1.5808883494669144
Validation loss: 2.451845665635565

Epoch: 5| Step: 6
Training loss: 1.855289169455256
Validation loss: 2.4390940711197686

Epoch: 5| Step: 7
Training loss: 1.7956444548772172
Validation loss: 2.4707342615791656

Epoch: 5| Step: 8
Training loss: 1.5295455165349279
Validation loss: 2.451003361921574

Epoch: 5| Step: 9
Training loss: 2.0966779818125922
Validation loss: 2.411487802994163

Epoch: 5| Step: 10
Training loss: 1.853379143050414
Validation loss: 2.409919422122976

Epoch: 5| Step: 11
Training loss: 2.4544995581385014
Validation loss: 2.4383355485532774

Epoch: 137| Step: 0
Training loss: 2.1354561654756505
Validation loss: 2.4352810859195997

Epoch: 5| Step: 1
Training loss: 1.2694304440897488
Validation loss: 2.485044181317124

Epoch: 5| Step: 2
Training loss: 2.038912245085099
Validation loss: 2.498422902080298

Epoch: 5| Step: 3
Training loss: 2.6195013493379515
Validation loss: 2.5257705064461096

Epoch: 5| Step: 4
Training loss: 1.8761586741789782
Validation loss: 2.550863894593455

Epoch: 5| Step: 5
Training loss: 2.0044870111316286
Validation loss: 2.4955220251750228

Epoch: 5| Step: 6
Training loss: 2.0744914936986314
Validation loss: 2.5181299023688215

Epoch: 5| Step: 7
Training loss: 1.727768420772967
Validation loss: 2.498479484060622

Epoch: 5| Step: 8
Training loss: 1.8072261377010672
Validation loss: 2.473806470258874

Epoch: 5| Step: 9
Training loss: 2.0878853722016477
Validation loss: 2.4815261109063624

Epoch: 5| Step: 10
Training loss: 1.5993649921350088
Validation loss: 2.455051710279538

Epoch: 5| Step: 11
Training loss: 0.8335673520199469
Validation loss: 2.4513376045686086

Epoch: 138| Step: 0
Training loss: 1.7163806189323598
Validation loss: 2.4190698765353664

Epoch: 5| Step: 1
Training loss: 1.968909484216416
Validation loss: 2.460470556938929

Epoch: 5| Step: 2
Training loss: 1.7820386646455992
Validation loss: 2.442249301056038

Epoch: 5| Step: 3
Training loss: 1.7908308460093474
Validation loss: 2.446633377260167

Epoch: 5| Step: 4
Training loss: 1.8107591358519468
Validation loss: 2.437991679559956

Epoch: 5| Step: 5
Training loss: 2.0934190630923046
Validation loss: 2.4485369254972196

Epoch: 5| Step: 6
Training loss: 1.7988525123889743
Validation loss: 2.444513169966772

Epoch: 5| Step: 7
Training loss: 2.0053737687733255
Validation loss: 2.4589145964603882

Epoch: 5| Step: 8
Training loss: 1.7171243782694914
Validation loss: 2.481904951209612

Epoch: 5| Step: 9
Training loss: 1.9891138638009849
Validation loss: 2.5035538090606138

Epoch: 5| Step: 10
Training loss: 1.8166349533649382
Validation loss: 2.4812270299551322

Epoch: 5| Step: 11
Training loss: 4.12320901541977
Validation loss: 2.490287662509416

Epoch: 139| Step: 0
Training loss: 1.3641119232487762
Validation loss: 2.48657983632996

Epoch: 5| Step: 1
Training loss: 1.675725051186522
Validation loss: 2.4527690754782028

Epoch: 5| Step: 2
Training loss: 1.862708045553562
Validation loss: 2.46325749431092

Epoch: 5| Step: 3
Training loss: 2.586878763709011
Validation loss: 2.4562318124979448

Epoch: 5| Step: 4
Training loss: 1.632985010114504
Validation loss: 2.441774113724504

Epoch: 5| Step: 5
Training loss: 1.612441983029425
Validation loss: 2.4413132387881538

Epoch: 5| Step: 6
Training loss: 1.8533364340987213
Validation loss: 2.4595153271728165

Epoch: 5| Step: 7
Training loss: 2.1085717826566794
Validation loss: 2.4526787289178276

Epoch: 5| Step: 8
Training loss: 1.6710568146192837
Validation loss: 2.475300652934294

Epoch: 5| Step: 9
Training loss: 1.9781089432533245
Validation loss: 2.458933839084257

Epoch: 5| Step: 10
Training loss: 2.2433140280668975
Validation loss: 2.460169588603814

Epoch: 5| Step: 11
Training loss: 1.4981675876489127
Validation loss: 2.4483092676342846

Epoch: 140| Step: 0
Training loss: 2.277002011237515
Validation loss: 2.415506587348336

Epoch: 5| Step: 1
Training loss: 1.8657795214279622
Validation loss: 2.429945070407258

Epoch: 5| Step: 2
Training loss: 2.2066594983855543
Validation loss: 2.4459044579903955

Epoch: 5| Step: 3
Training loss: 1.6994059843189868
Validation loss: 2.4508009712285905

Epoch: 5| Step: 4
Training loss: 1.499359788964582
Validation loss: 2.4809471850420985

Epoch: 5| Step: 5
Training loss: 1.9120775790975504
Validation loss: 2.437594411928891

Epoch: 5| Step: 6
Training loss: 1.8931915895142637
Validation loss: 2.464809274407169

Epoch: 5| Step: 7
Training loss: 2.1669693026337797
Validation loss: 2.450745990123774

Epoch: 5| Step: 8
Training loss: 2.0031206104153103
Validation loss: 2.4706549276644156

Epoch: 5| Step: 9
Training loss: 1.8779318457882164
Validation loss: 2.444743294326054

Epoch: 5| Step: 10
Training loss: 1.7457751638452688
Validation loss: 2.529881366372091

Epoch: 5| Step: 11
Training loss: 2.307929806836883
Validation loss: 2.617697966788233

Epoch: 141| Step: 0
Training loss: 1.6155801054806076
Validation loss: 2.611981937993951

Epoch: 5| Step: 1
Training loss: 2.1178555156138175
Validation loss: 2.5445630437082536

Epoch: 5| Step: 2
Training loss: 2.5191775051451217
Validation loss: 2.507042026704644

Epoch: 5| Step: 3
Training loss: 2.0133232754757158
Validation loss: 2.4800150238531864

Epoch: 5| Step: 4
Training loss: 1.5763287283032281
Validation loss: 2.4457401230796

Epoch: 5| Step: 5
Training loss: 1.988167570270571
Validation loss: 2.4633910084009067

Epoch: 5| Step: 6
Training loss: 1.8191995779506693
Validation loss: 2.444044399821211

Epoch: 5| Step: 7
Training loss: 1.9634248073082012
Validation loss: 2.460794309456733

Epoch: 5| Step: 8
Training loss: 1.7623642375413688
Validation loss: 2.4657376135124007

Epoch: 5| Step: 9
Training loss: 1.423002445805928
Validation loss: 2.4442069567897167

Epoch: 5| Step: 10
Training loss: 1.9163616462925528
Validation loss: 2.466783935802893

Epoch: 5| Step: 11
Training loss: 2.2086948842553693
Validation loss: 2.428133734511839

Epoch: 142| Step: 0
Training loss: 1.9167281292998155
Validation loss: 2.458523303843857

Epoch: 5| Step: 1
Training loss: 1.6737993520536023
Validation loss: 2.448554756652988

Epoch: 5| Step: 2
Training loss: 1.519791529313156
Validation loss: 2.4670522018548966

Epoch: 5| Step: 3
Training loss: 1.493249964316965
Validation loss: 2.460830661937152

Epoch: 5| Step: 4
Training loss: 2.2132013276195974
Validation loss: 2.4826311713026854

Epoch: 5| Step: 5
Training loss: 2.0560575493725333
Validation loss: 2.4939603369466874

Epoch: 5| Step: 6
Training loss: 2.328903989589225
Validation loss: 2.4906041886733727

Epoch: 5| Step: 7
Training loss: 2.064321580519632
Validation loss: 2.4888512533919585

Epoch: 5| Step: 8
Training loss: 1.8358606200658572
Validation loss: 2.4614609540058208

Epoch: 5| Step: 9
Training loss: 1.6203262902374684
Validation loss: 2.4728888130601145

Epoch: 5| Step: 10
Training loss: 1.908144025560947
Validation loss: 2.487479295756248

Epoch: 5| Step: 11
Training loss: 0.9158016841569699
Validation loss: 2.4498950079394746

Epoch: 143| Step: 0
Training loss: 1.364723906908204
Validation loss: 2.45316102878168

Epoch: 5| Step: 1
Training loss: 2.405458989112727
Validation loss: 2.4247736494208487

Epoch: 5| Step: 2
Training loss: 2.2697304196706964
Validation loss: 2.4289699406625562

Epoch: 5| Step: 3
Training loss: 1.7272672983932964
Validation loss: 2.4552309428228556

Epoch: 5| Step: 4
Training loss: 2.0444828644312185
Validation loss: 2.4226594290353174

Epoch: 5| Step: 5
Training loss: 1.3573370817856532
Validation loss: 2.455079403646536

Epoch: 5| Step: 6
Training loss: 1.5975543225145772
Validation loss: 2.485230852254709

Epoch: 5| Step: 7
Training loss: 2.299550476926971
Validation loss: 2.4702254928074803

Epoch: 5| Step: 8
Training loss: 1.3560222188344546
Validation loss: 2.4241345068746916

Epoch: 5| Step: 9
Training loss: 1.8798710176172186
Validation loss: 2.475632678511738

Epoch: 5| Step: 10
Training loss: 1.844851213467404
Validation loss: 2.4154511647845154

Epoch: 5| Step: 11
Training loss: 1.6042563508300245
Validation loss: 2.4537162068353013

Epoch: 144| Step: 0
Training loss: 1.6010095897961583
Validation loss: 2.437673142796444

Epoch: 5| Step: 1
Training loss: 2.007772126144414
Validation loss: 2.44917875517862

Epoch: 5| Step: 2
Training loss: 1.8193428174562951
Validation loss: 2.46742153841411

Epoch: 5| Step: 3
Training loss: 1.5169556272601694
Validation loss: 2.428941520172264

Epoch: 5| Step: 4
Training loss: 1.5591254606091056
Validation loss: 2.44362121610176

Epoch: 5| Step: 5
Training loss: 1.442995678578632
Validation loss: 2.4742195526882997

Epoch: 5| Step: 6
Training loss: 2.028365214130466
Validation loss: 2.41565343289834

Epoch: 5| Step: 7
Training loss: 1.6816896792533185
Validation loss: 2.441252444699508

Epoch: 5| Step: 8
Training loss: 1.9933183639287493
Validation loss: 2.4200460111169066

Epoch: 5| Step: 9
Training loss: 1.7326860882232147
Validation loss: 2.4285816280400585

Epoch: 5| Step: 10
Training loss: 2.4752041433895178
Validation loss: 2.42765343127828

Epoch: 5| Step: 11
Training loss: 2.800713999857283
Validation loss: 2.420448248027805

Epoch: 145| Step: 0
Training loss: 2.3254758368421755
Validation loss: 2.427105495586363

Epoch: 5| Step: 1
Training loss: 1.9718897170592216
Validation loss: 2.432547109996494

Epoch: 5| Step: 2
Training loss: 1.8753650309956196
Validation loss: 2.442383227373078

Epoch: 5| Step: 3
Training loss: 1.6811236961598517
Validation loss: 2.469479058854709

Epoch: 5| Step: 4
Training loss: 1.8100815785185855
Validation loss: 2.4528721620371265

Epoch: 5| Step: 5
Training loss: 1.5610636403358022
Validation loss: 2.4729947365186624

Epoch: 5| Step: 6
Training loss: 1.5468269880145677
Validation loss: 2.4299292306151234

Epoch: 5| Step: 7
Training loss: 1.8116221439584108
Validation loss: 2.4757435945949764

Epoch: 5| Step: 8
Training loss: 2.048208835854444
Validation loss: 2.444154906163848

Epoch: 5| Step: 9
Training loss: 1.6405213822840594
Validation loss: 2.4432997458683405

Epoch: 5| Step: 10
Training loss: 1.402696995355308
Validation loss: 2.4615275649447

Epoch: 5| Step: 11
Training loss: 3.054332195409024
Validation loss: 2.4631598434106805

Epoch: 146| Step: 0
Training loss: 1.8404770589288417
Validation loss: 2.4370223416893255

Epoch: 5| Step: 1
Training loss: 1.860998326611881
Validation loss: 2.462231036728998

Epoch: 5| Step: 2
Training loss: 1.7219416029107488
Validation loss: 2.502297204305583

Epoch: 5| Step: 3
Training loss: 2.0025231419820306
Validation loss: 2.5145791725075806

Epoch: 5| Step: 4
Training loss: 2.5041848442784658
Validation loss: 2.489412839922617

Epoch: 5| Step: 5
Training loss: 1.6427313951975162
Validation loss: 2.502294290327535

Epoch: 5| Step: 6
Training loss: 1.401943138939428
Validation loss: 2.4552176877667513

Epoch: 5| Step: 7
Training loss: 1.8783579956349177
Validation loss: 2.4785720021174042

Epoch: 5| Step: 8
Training loss: 1.7796523977406535
Validation loss: 2.4633739661679797

Epoch: 5| Step: 9
Training loss: 2.089655730443975
Validation loss: 2.5211181020018647

Epoch: 5| Step: 10
Training loss: 1.7870598791386922
Validation loss: 2.510631114194777

Epoch: 5| Step: 11
Training loss: 1.3793457022607547
Validation loss: 2.5354472239733963

Epoch: 147| Step: 0
Training loss: 1.653964282834491
Validation loss: 2.5442062195324056

Epoch: 5| Step: 1
Training loss: 1.9607855749359937
Validation loss: 2.5116952110915918

Epoch: 5| Step: 2
Training loss: 2.179569583013974
Validation loss: 2.5003016409097607

Epoch: 5| Step: 3
Training loss: 1.6097065852519947
Validation loss: 2.4494556148196285

Epoch: 5| Step: 4
Training loss: 1.2274779287090398
Validation loss: 2.497928416744421

Epoch: 5| Step: 5
Training loss: 1.417195931843801
Validation loss: 2.4217214228020123

Epoch: 5| Step: 6
Training loss: 2.360911898218547
Validation loss: 2.433297095834556

Epoch: 5| Step: 7
Training loss: 1.6851168157909195
Validation loss: 2.4550910206862966

Epoch: 5| Step: 8
Training loss: 2.0783771562684983
Validation loss: 2.4458037016100946

Epoch: 5| Step: 9
Training loss: 1.5390339185510375
Validation loss: 2.4147321313447763

Epoch: 5| Step: 10
Training loss: 1.9676165269713235
Validation loss: 2.4545571627495515

Epoch: 5| Step: 11
Training loss: 1.2406234010931132
Validation loss: 2.4553241591281725

Epoch: 148| Step: 0
Training loss: 2.0540769416862026
Validation loss: 2.4923892721771965

Epoch: 5| Step: 1
Training loss: 1.5573121731874089
Validation loss: 2.480835666702381

Epoch: 5| Step: 2
Training loss: 1.170968480755295
Validation loss: 2.53201144739474

Epoch: 5| Step: 3
Training loss: 2.1200386921932544
Validation loss: 2.507555139315071

Epoch: 5| Step: 4
Training loss: 1.0086861305863344
Validation loss: 2.5183419981764708

Epoch: 5| Step: 5
Training loss: 1.9620826690515007
Validation loss: 2.495971676702458

Epoch: 5| Step: 6
Training loss: 1.5324223759767295
Validation loss: 2.493913465414991

Epoch: 5| Step: 7
Training loss: 1.8473499520039691
Validation loss: 2.4735277597614806

Epoch: 5| Step: 8
Training loss: 2.474858609409063
Validation loss: 2.410023022498178

Epoch: 5| Step: 9
Training loss: 1.5063345192903657
Validation loss: 2.4201699110025627

Epoch: 5| Step: 10
Training loss: 1.9913875394879768
Validation loss: 2.457675972566207

Epoch: 5| Step: 11
Training loss: 2.432873761747737
Validation loss: 2.463600675482383

Epoch: 149| Step: 0
Training loss: 1.4141343240780362
Validation loss: 2.444925856567983

Epoch: 5| Step: 1
Training loss: 1.4659825488739302
Validation loss: 2.5052558090776555

Epoch: 5| Step: 2
Training loss: 1.8872472682280736
Validation loss: 2.460390044177862

Epoch: 5| Step: 3
Training loss: 2.3478950975629544
Validation loss: 2.4746535171068307

Epoch: 5| Step: 4
Training loss: 1.7775330830431444
Validation loss: 2.427838696391537

Epoch: 5| Step: 5
Training loss: 1.9351414507044749
Validation loss: 2.4682043534884577

Epoch: 5| Step: 6
Training loss: 1.437620240863246
Validation loss: 2.4412713260243266

Epoch: 5| Step: 7
Training loss: 1.3918670079892967
Validation loss: 2.4599395787370755

Epoch: 5| Step: 8
Training loss: 2.0292100493110254
Validation loss: 2.4772649224158094

Epoch: 5| Step: 9
Training loss: 1.8843503504417216
Validation loss: 2.523788167958676

Epoch: 5| Step: 10
Training loss: 2.0570957010026287
Validation loss: 2.5484243216798528

Epoch: 5| Step: 11
Training loss: 2.711328132034739
Validation loss: 2.5512534732100303

Epoch: 150| Step: 0
Training loss: 1.5564274085469492
Validation loss: 2.485877864049604

Epoch: 5| Step: 1
Training loss: 1.6596851353600648
Validation loss: 2.491845287796153

Epoch: 5| Step: 2
Training loss: 1.3862691230934023
Validation loss: 2.422560887990406

Epoch: 5| Step: 3
Training loss: 2.0639560068454363
Validation loss: 2.503126815592043

Epoch: 5| Step: 4
Training loss: 1.7214066520995845
Validation loss: 2.5203383973965496

Epoch: 5| Step: 5
Training loss: 1.863222581111695
Validation loss: 2.5232790453344096

Epoch: 5| Step: 6
Training loss: 1.7586130989328725
Validation loss: 2.5006394641346352

Epoch: 5| Step: 7
Training loss: 2.6944235399971226
Validation loss: 2.5017113192798583

Epoch: 5| Step: 8
Training loss: 1.890228860511627
Validation loss: 2.432608105308049

Epoch: 5| Step: 9
Training loss: 1.974281412088006
Validation loss: 2.4249745008760057

Epoch: 5| Step: 10
Training loss: 1.458328283392019
Validation loss: 2.49884553718076

Epoch: 5| Step: 11
Training loss: 1.741430417454062
Validation loss: 2.5253343529171315

Epoch: 151| Step: 0
Training loss: 1.8211679699607037
Validation loss: 2.5499099053255696

Epoch: 5| Step: 1
Training loss: 1.535090631922012
Validation loss: 2.554771348080818

Epoch: 5| Step: 2
Training loss: 1.9275641863831547
Validation loss: 2.607126595949696

Epoch: 5| Step: 3
Training loss: 1.747755996115418
Validation loss: 2.5902996898936785

Epoch: 5| Step: 4
Training loss: 1.9771918700814883
Validation loss: 2.532384600490797

Epoch: 5| Step: 5
Training loss: 1.7195891672560302
Validation loss: 2.5258459244752705

Epoch: 5| Step: 6
Training loss: 1.6022259338304758
Validation loss: 2.450769763806526

Epoch: 5| Step: 7
Training loss: 1.264418509654443
Validation loss: 2.4431899246016817

Epoch: 5| Step: 8
Training loss: 1.914313910963947
Validation loss: 2.459973621827876

Epoch: 5| Step: 9
Training loss: 1.847226373130832
Validation loss: 2.495132197405215

Epoch: 5| Step: 10
Training loss: 2.1666959858402266
Validation loss: 2.4631856630191074

Epoch: 5| Step: 11
Training loss: 2.396831160919066
Validation loss: 2.4706956101857367

Epoch: 152| Step: 0
Training loss: 1.8344038381048111
Validation loss: 2.4817560535056193

Epoch: 5| Step: 1
Training loss: 1.9314820134813835
Validation loss: 2.440351753878241

Epoch: 5| Step: 2
Training loss: 2.1654002327583197
Validation loss: 2.478773772471475

Epoch: 5| Step: 3
Training loss: 1.6336442207118147
Validation loss: 2.519436825109043

Epoch: 5| Step: 4
Training loss: 1.513787876729442
Validation loss: 2.451632746396555

Epoch: 5| Step: 5
Training loss: 1.5026012753393254
Validation loss: 2.4599351829845424

Epoch: 5| Step: 6
Training loss: 1.6513655271696634
Validation loss: 2.503375087822417

Epoch: 5| Step: 7
Training loss: 1.2458094448916586
Validation loss: 2.4479710769017315

Epoch: 5| Step: 8
Training loss: 1.313192139642635
Validation loss: 2.480911784018158

Epoch: 5| Step: 9
Training loss: 2.0721251415844737
Validation loss: 2.5051490885073204

Epoch: 5| Step: 10
Training loss: 2.1600170677005237
Validation loss: 2.492063820220455

Epoch: 5| Step: 11
Training loss: 2.4104831665502093
Validation loss: 2.4605929845016314

Epoch: 153| Step: 0
Training loss: 1.58762266330954
Validation loss: 2.4517383098269785

Epoch: 5| Step: 1
Training loss: 1.271606720694283
Validation loss: 2.451614935601676

Epoch: 5| Step: 2
Training loss: 1.59936432131638
Validation loss: 2.487484751068353

Epoch: 5| Step: 3
Training loss: 1.3535822071691626
Validation loss: 2.4806187742024917

Epoch: 5| Step: 4
Training loss: 1.8396073693692085
Validation loss: 2.445643819965156

Epoch: 5| Step: 5
Training loss: 2.2025247391903697
Validation loss: 2.4788245331008625

Epoch: 5| Step: 6
Training loss: 1.8024421364098184
Validation loss: 2.465938597004397

Epoch: 5| Step: 7
Training loss: 2.0178532075903868
Validation loss: 2.47160568940418

Epoch: 5| Step: 8
Training loss: 1.627551350054495
Validation loss: 2.463402969348682

Epoch: 5| Step: 9
Training loss: 1.946500606878751
Validation loss: 2.476478362634771

Epoch: 5| Step: 10
Training loss: 1.9720867883568836
Validation loss: 2.4966938250668447

Epoch: 5| Step: 11
Training loss: 1.0485002797371523
Validation loss: 2.4807792329084237

Epoch: 154| Step: 0
Training loss: 1.3037796973908642
Validation loss: 2.5483946722763915

Epoch: 5| Step: 1
Training loss: 2.0319083687404604
Validation loss: 2.6237605665629316

Epoch: 5| Step: 2
Training loss: 1.705264086812927
Validation loss: 2.620631677989183

Epoch: 5| Step: 3
Training loss: 1.4812380118226973
Validation loss: 2.585720199106129

Epoch: 5| Step: 4
Training loss: 1.230843962122215
Validation loss: 2.5132385765708305

Epoch: 5| Step: 5
Training loss: 2.0362442827700633
Validation loss: 2.543829710146553

Epoch: 5| Step: 6
Training loss: 1.847391057086711
Validation loss: 2.48460723383316

Epoch: 5| Step: 7
Training loss: 2.1076007303983446
Validation loss: 2.4515908905194284

Epoch: 5| Step: 8
Training loss: 1.5085256994812795
Validation loss: 2.4798530274981703

Epoch: 5| Step: 9
Training loss: 2.138950333256293
Validation loss: 2.4334696109923355

Epoch: 5| Step: 10
Training loss: 1.7436889200211967
Validation loss: 2.4500478490062485

Epoch: 5| Step: 11
Training loss: 1.6691298720363617
Validation loss: 2.49246064446134

Epoch: 155| Step: 0
Training loss: 2.2382570701478084
Validation loss: 2.4730253461391656

Epoch: 5| Step: 1
Training loss: 1.5446747052841427
Validation loss: 2.4672503121328457

Epoch: 5| Step: 2
Training loss: 1.7651552233642769
Validation loss: 2.460053146752216

Epoch: 5| Step: 3
Training loss: 1.752741029410911
Validation loss: 2.464299217888722

Epoch: 5| Step: 4
Training loss: 1.535613557293947
Validation loss: 2.4467490773219875

Epoch: 5| Step: 5
Training loss: 1.5211084804987416
Validation loss: 2.464254156612206

Epoch: 5| Step: 6
Training loss: 1.7990831159186054
Validation loss: 2.4349378911974227

Epoch: 5| Step: 7
Training loss: 2.1984408749335547
Validation loss: 2.438387727475117

Epoch: 5| Step: 8
Training loss: 1.4102055337594157
Validation loss: 2.5088598256954406

Epoch: 5| Step: 9
Training loss: 1.6070180874787585
Validation loss: 2.5551523996900825

Epoch: 5| Step: 10
Training loss: 1.6796237667323646
Validation loss: 2.5944010078433366

Epoch: 5| Step: 11
Training loss: 1.9963528638504227
Validation loss: 2.5315463006493664

Epoch: 156| Step: 0
Training loss: 1.276979446956696
Validation loss: 2.5251955850472063

Epoch: 5| Step: 1
Training loss: 1.9495050682516617
Validation loss: 2.4627533001370163

Epoch: 5| Step: 2
Training loss: 1.382975121542584
Validation loss: 2.516409362708931

Epoch: 5| Step: 3
Training loss: 1.4530608460405718
Validation loss: 2.4505583624781786

Epoch: 5| Step: 4
Training loss: 2.132775386724942
Validation loss: 2.4436006942693607

Epoch: 5| Step: 5
Training loss: 1.4620654805570938
Validation loss: 2.432324886435522

Epoch: 5| Step: 6
Training loss: 1.5299834638213088
Validation loss: 2.4545683856362848

Epoch: 5| Step: 7
Training loss: 1.7442717807236023
Validation loss: 2.4772104905753407

Epoch: 5| Step: 8
Training loss: 1.6533978934655176
Validation loss: 2.4589285385906723

Epoch: 5| Step: 9
Training loss: 1.4381602885506068
Validation loss: 2.465767801562885

Epoch: 5| Step: 10
Training loss: 2.2906648931633358
Validation loss: 2.4739403466357177

Epoch: 5| Step: 11
Training loss: 2.2343229274417333
Validation loss: 2.4619865200018185

Epoch: 157| Step: 0
Training loss: 1.6796041068733447
Validation loss: 2.4388457235140923

Epoch: 5| Step: 1
Training loss: 1.5175301287706562
Validation loss: 2.4878991321177297

Epoch: 5| Step: 2
Training loss: 2.1231129064880863
Validation loss: 2.4589339481644163

Epoch: 5| Step: 3
Training loss: 1.7395923256403725
Validation loss: 2.4340648246215633

Epoch: 5| Step: 4
Training loss: 1.8965750769818694
Validation loss: 2.4817228776288633

Epoch: 5| Step: 5
Training loss: 1.4968661313998761
Validation loss: 2.495097833746236

Epoch: 5| Step: 6
Training loss: 1.3743874312424522
Validation loss: 2.4420068800558785

Epoch: 5| Step: 7
Training loss: 1.4839986223589732
Validation loss: 2.457681378833862

Epoch: 5| Step: 8
Training loss: 1.5012654688512248
Validation loss: 2.4652464608694213

Epoch: 5| Step: 9
Training loss: 2.249235553155312
Validation loss: 2.417202398233299

Epoch: 5| Step: 10
Training loss: 1.562730848425397
Validation loss: 2.4624561770649755

Epoch: 5| Step: 11
Training loss: 1.1005710983291435
Validation loss: 2.4196591813242803

Epoch: 158| Step: 0
Training loss: 1.051039086229366
Validation loss: 2.4827370952457377

Epoch: 5| Step: 1
Training loss: 1.6668073912656005
Validation loss: 2.4976279568852036

Epoch: 5| Step: 2
Training loss: 1.4321413088397064
Validation loss: 2.472663240588583

Epoch: 5| Step: 3
Training loss: 1.8118946116748977
Validation loss: 2.437076120118621

Epoch: 5| Step: 4
Training loss: 1.663914633615254
Validation loss: 2.502159028783599

Epoch: 5| Step: 5
Training loss: 1.2466168875029162
Validation loss: 2.5179999417132533

Epoch: 5| Step: 6
Training loss: 1.7964119355986952
Validation loss: 2.4662179355628293

Epoch: 5| Step: 7
Training loss: 1.53740761952324
Validation loss: 2.436568697685477

Epoch: 5| Step: 8
Training loss: 2.328628997525728
Validation loss: 2.452221793238827

Epoch: 5| Step: 9
Training loss: 1.8800810315545395
Validation loss: 2.483321724348221

Epoch: 5| Step: 10
Training loss: 1.8909469204316371
Validation loss: 2.4497930369576193

Epoch: 5| Step: 11
Training loss: 1.799031166438587
Validation loss: 2.4757514572236854

Epoch: 159| Step: 0
Training loss: 1.3856170146128737
Validation loss: 2.5072888929929924

Epoch: 5| Step: 1
Training loss: 1.7257297630797943
Validation loss: 2.48516214644448

Epoch: 5| Step: 2
Training loss: 2.0600937186838713
Validation loss: 2.553555034403173

Epoch: 5| Step: 3
Training loss: 1.5716659255176035
Validation loss: 2.561599294024292

Epoch: 5| Step: 4
Training loss: 1.8758881690564035
Validation loss: 2.4882186929693098

Epoch: 5| Step: 5
Training loss: 1.2953508912069764
Validation loss: 2.411273167849718

Epoch: 5| Step: 6
Training loss: 1.991738601673023
Validation loss: 2.4637201753963

Epoch: 5| Step: 7
Training loss: 1.2152376670878644
Validation loss: 2.4875268476241845

Epoch: 5| Step: 8
Training loss: 1.5122484171312485
Validation loss: 2.479565797994954

Epoch: 5| Step: 9
Training loss: 1.7150450568772648
Validation loss: 2.4428619866484467

Epoch: 5| Step: 10
Training loss: 2.233006198134748
Validation loss: 2.494365111474547

Epoch: 5| Step: 11
Training loss: 2.0189831578391595
Validation loss: 2.4558145151581234

Epoch: 160| Step: 0
Training loss: 1.5250690819774253
Validation loss: 2.4026397315986885

Epoch: 5| Step: 1
Training loss: 1.837799102417829
Validation loss: 2.4673161104908976

Epoch: 5| Step: 2
Training loss: 1.7991415572906335
Validation loss: 2.480919664303367

Epoch: 5| Step: 3
Training loss: 1.561025457796546
Validation loss: 2.51050892471746

Epoch: 5| Step: 4
Training loss: 2.183996064549348
Validation loss: 2.4807607964429366

Epoch: 5| Step: 5
Training loss: 1.3197494299356798
Validation loss: 2.5261031756171435

Epoch: 5| Step: 6
Training loss: 1.8872669758227123
Validation loss: 2.459054406067476

Epoch: 5| Step: 7
Training loss: 1.0917037350910694
Validation loss: 2.4681235375669295

Epoch: 5| Step: 8
Training loss: 1.825325868855092
Validation loss: 2.455106522126048

Epoch: 5| Step: 9
Training loss: 0.9867892254498258
Validation loss: 2.4498964636522738

Epoch: 5| Step: 10
Training loss: 1.7678654726941379
Validation loss: 2.459029294493234

Epoch: 5| Step: 11
Training loss: 2.6992032040977794
Validation loss: 2.430294300449554

Epoch: 161| Step: 0
Training loss: 2.2089993774012546
Validation loss: 2.4574983655135707

Epoch: 5| Step: 1
Training loss: 1.8827863509392353
Validation loss: 2.468411422400503

Epoch: 5| Step: 2
Training loss: 1.682126992810051
Validation loss: 2.4367402494362067

Epoch: 5| Step: 3
Training loss: 1.6619686510914378
Validation loss: 2.464434699098839

Epoch: 5| Step: 4
Training loss: 1.5532202002593756
Validation loss: 2.4762544931803925

Epoch: 5| Step: 5
Training loss: 1.8204915363855756
Validation loss: 2.428475602071585

Epoch: 5| Step: 6
Training loss: 1.2043378587270503
Validation loss: 2.436933728815144

Epoch: 5| Step: 7
Training loss: 1.370779235066118
Validation loss: 2.431069623912956

Epoch: 5| Step: 8
Training loss: 1.1879232054046178
Validation loss: 2.491826203644036

Epoch: 5| Step: 9
Training loss: 1.5457821463089991
Validation loss: 2.457548338753255

Epoch: 5| Step: 10
Training loss: 1.8166342971554403
Validation loss: 2.515644495949713

Epoch: 5| Step: 11
Training loss: 1.5614895414355792
Validation loss: 2.4886594052816418

Epoch: 162| Step: 0
Training loss: 1.542137984666489
Validation loss: 2.5169952522804424

Epoch: 5| Step: 1
Training loss: 1.8120644802511219
Validation loss: 2.468738040814627

Epoch: 5| Step: 2
Training loss: 1.7702591432643169
Validation loss: 2.437339826358533

Epoch: 5| Step: 3
Training loss: 1.7287531975022188
Validation loss: 2.4406805623137036

Epoch: 5| Step: 4
Training loss: 1.2375017474383723
Validation loss: 2.448736190915989

Epoch: 5| Step: 5
Training loss: 1.1805224463862658
Validation loss: 2.4553347736429596

Epoch: 5| Step: 6
Training loss: 1.3219024294629387
Validation loss: 2.437988861896821

Epoch: 5| Step: 7
Training loss: 1.461331074784847
Validation loss: 2.430328178366635

Epoch: 5| Step: 8
Training loss: 1.5100370609712173
Validation loss: 2.41576167678577

Epoch: 5| Step: 9
Training loss: 1.5258260928360163
Validation loss: 2.461784116247812

Epoch: 5| Step: 10
Training loss: 2.540783952946519
Validation loss: 2.4470180742471626

Epoch: 5| Step: 11
Training loss: 1.7484314564727432
Validation loss: 2.423312947794434

Epoch: 163| Step: 0
Training loss: 1.4923370446170423
Validation loss: 2.435809207218854

Epoch: 5| Step: 1
Training loss: 1.3255909249810633
Validation loss: 2.4593064024332594

Epoch: 5| Step: 2
Training loss: 1.3614914302212997
Validation loss: 2.4287617055231623

Epoch: 5| Step: 3
Training loss: 1.7516480587455785
Validation loss: 2.4675866415973777

Epoch: 5| Step: 4
Training loss: 1.3139510988603145
Validation loss: 2.4163258959037894

Epoch: 5| Step: 5
Training loss: 1.8687799917002403
Validation loss: 2.477809559940655

Epoch: 5| Step: 6
Training loss: 1.7333639136086607
Validation loss: 2.4789146340644472

Epoch: 5| Step: 7
Training loss: 1.5620163741285347
Validation loss: 2.535876312426508

Epoch: 5| Step: 8
Training loss: 1.5344025215120252
Validation loss: 2.4596354112815284

Epoch: 5| Step: 9
Training loss: 1.9720633342778513
Validation loss: 2.4589131824468162

Epoch: 5| Step: 10
Training loss: 1.877460327846783
Validation loss: 2.47310077192952

Epoch: 5| Step: 11
Training loss: 0.5867360586160665
Validation loss: 2.40296267468447

Epoch: 164| Step: 0
Training loss: 1.6243301624951074
Validation loss: 2.3995247342984456

Epoch: 5| Step: 1
Training loss: 1.2209199514463103
Validation loss: 2.4169239833469254

Epoch: 5| Step: 2
Training loss: 1.7775280532018147
Validation loss: 2.4312314242002286

Epoch: 5| Step: 3
Training loss: 1.5008560757746958
Validation loss: 2.4375639340582715

Epoch: 5| Step: 4
Training loss: 2.226894313783104
Validation loss: 2.4427277022666813

Epoch: 5| Step: 5
Training loss: 1.8418964832348756
Validation loss: 2.4296028923848447

Epoch: 5| Step: 6
Training loss: 1.2755839973823957
Validation loss: 2.4283551838947086

Epoch: 5| Step: 7
Training loss: 1.3717161325563791
Validation loss: 2.4240864511807914

Epoch: 5| Step: 8
Training loss: 1.7267189472831108
Validation loss: 2.4821226758551407

Epoch: 5| Step: 9
Training loss: 1.8162109269981987
Validation loss: 2.4998966970558403

Epoch: 5| Step: 10
Training loss: 1.8550196696469883
Validation loss: 2.5341716082670165

Epoch: 5| Step: 11
Training loss: 1.30269269290338
Validation loss: 2.4962639111389278

Epoch: 165| Step: 0
Training loss: 1.662372285913681
Validation loss: 2.4051171687116146

Epoch: 5| Step: 1
Training loss: 1.3459896231133692
Validation loss: 2.397983661337713

Epoch: 5| Step: 2
Training loss: 1.3609486383448748
Validation loss: 2.4738795793279014

Epoch: 5| Step: 3
Training loss: 2.2200961260561316
Validation loss: 2.423620173580954

Epoch: 5| Step: 4
Training loss: 1.5056867884035343
Validation loss: 2.430617960779655

Epoch: 5| Step: 5
Training loss: 1.5441216519514875
Validation loss: 2.433340186986895

Epoch: 5| Step: 6
Training loss: 1.486965529005731
Validation loss: 2.4469592772123385

Epoch: 5| Step: 7
Training loss: 1.7298071567461009
Validation loss: 2.446854017126311

Epoch: 5| Step: 8
Training loss: 1.5604594830426626
Validation loss: 2.4459190124297807

Epoch: 5| Step: 9
Training loss: 1.5609096062566912
Validation loss: 2.4504739322423914

Epoch: 5| Step: 10
Training loss: 1.6043986445885094
Validation loss: 2.4249724730669513

Epoch: 5| Step: 11
Training loss: 2.373707771106436
Validation loss: 2.4919087882932893

Epoch: 166| Step: 0
Training loss: 1.3846511685911096
Validation loss: 2.4441880473378697

Epoch: 5| Step: 1
Training loss: 1.597397986245692
Validation loss: 2.496567161372031

Epoch: 5| Step: 2
Training loss: 1.2185962286556005
Validation loss: 2.4385301194263174

Epoch: 5| Step: 3
Training loss: 1.2143256257013542
Validation loss: 2.465404416504555

Epoch: 5| Step: 4
Training loss: 2.2695217953089424
Validation loss: 2.465112888093199

Epoch: 5| Step: 5
Training loss: 1.359995733142218
Validation loss: 2.4395789385548876

Epoch: 5| Step: 6
Training loss: 1.6907928270677401
Validation loss: 2.4662759069173474

Epoch: 5| Step: 7
Training loss: 1.8246994528792988
Validation loss: 2.42164342039686

Epoch: 5| Step: 8
Training loss: 2.079904697692458
Validation loss: 2.4555552101752336

Epoch: 5| Step: 9
Training loss: 1.6458229193378087
Validation loss: 2.4347436207948436

Epoch: 5| Step: 10
Training loss: 1.4158312447307795
Validation loss: 2.4608853491045926

Epoch: 5| Step: 11
Training loss: 0.7152301181935297
Validation loss: 2.4909898317622865

Epoch: 167| Step: 0
Training loss: 2.039761712051058
Validation loss: 2.4902651317417415

Epoch: 5| Step: 1
Training loss: 1.922656698897277
Validation loss: 2.500789942711886

Epoch: 5| Step: 2
Training loss: 1.7372658496308793
Validation loss: 2.4666163443144775

Epoch: 5| Step: 3
Training loss: 1.1533737493243432
Validation loss: 2.4947564926269403

Epoch: 5| Step: 4
Training loss: 1.9850821849423117
Validation loss: 2.4545959104290103

Epoch: 5| Step: 5
Training loss: 1.280135996269659
Validation loss: 2.46320265009279

Epoch: 5| Step: 6
Training loss: 1.4343771807751668
Validation loss: 2.408735267522841

Epoch: 5| Step: 7
Training loss: 1.266201217781172
Validation loss: 2.4556728139474764

Epoch: 5| Step: 8
Training loss: 1.2026767638861755
Validation loss: 2.4438254188646273

Epoch: 5| Step: 9
Training loss: 1.373196068766384
Validation loss: 2.4640139449001572

Epoch: 5| Step: 10
Training loss: 1.8415600330097395
Validation loss: 2.452281908266427

Epoch: 5| Step: 11
Training loss: 1.3000999705682943
Validation loss: 2.4243185575385406

Epoch: 168| Step: 0
Training loss: 1.128969289742102
Validation loss: 2.4615987948843356

Epoch: 5| Step: 1
Training loss: 2.042839790198132
Validation loss: 2.4197133004916163

Epoch: 5| Step: 2
Training loss: 1.3955395897143015
Validation loss: 2.4932297069027545

Epoch: 5| Step: 3
Training loss: 1.870347927589746
Validation loss: 2.464723256627539

Epoch: 5| Step: 4
Training loss: 1.6489961951948124
Validation loss: 2.4567903158970656

Epoch: 5| Step: 5
Training loss: 1.6347274866976362
Validation loss: 2.4715725943239897

Epoch: 5| Step: 6
Training loss: 1.4849265429120893
Validation loss: 2.5044665847798853

Epoch: 5| Step: 7
Training loss: 1.5047829190716058
Validation loss: 2.4549150475981483

Epoch: 5| Step: 8
Training loss: 1.541227647630115
Validation loss: 2.458732816328734

Epoch: 5| Step: 9
Training loss: 1.5868313530128724
Validation loss: 2.489563444422573

Epoch: 5| Step: 10
Training loss: 1.2054303364001158
Validation loss: 2.448455127716714

Epoch: 5| Step: 11
Training loss: 1.2384004264786452
Validation loss: 2.4464694689473663

Epoch: 169| Step: 0
Training loss: 1.612586807161811
Validation loss: 2.477845839193827

Epoch: 5| Step: 1
Training loss: 1.7184823954937176
Validation loss: 2.4715038926835233

Epoch: 5| Step: 2
Training loss: 1.29184787258536
Validation loss: 2.4897921140798744

Epoch: 5| Step: 3
Training loss: 1.3750718704860758
Validation loss: 2.462532386469994

Epoch: 5| Step: 4
Training loss: 1.305018217463878
Validation loss: 2.5004755759889457

Epoch: 5| Step: 5
Training loss: 1.5668889013220764
Validation loss: 2.4324431784012273

Epoch: 5| Step: 6
Training loss: 1.4574666127066311
Validation loss: 2.494696331923624

Epoch: 5| Step: 7
Training loss: 2.1495378485482197
Validation loss: 2.425482935845234

Epoch: 5| Step: 8
Training loss: 1.5270637587281106
Validation loss: 2.4439664229408513

Epoch: 5| Step: 9
Training loss: 1.3599006250482841
Validation loss: 2.4397330936643926

Epoch: 5| Step: 10
Training loss: 1.6483987378810538
Validation loss: 2.4758141808061667

Epoch: 5| Step: 11
Training loss: 2.5955807762502863
Validation loss: 2.4458259595947194

Epoch: 170| Step: 0
Training loss: 1.5039520653025424
Validation loss: 2.451159834103944

Epoch: 5| Step: 1
Training loss: 1.5746132330349194
Validation loss: 2.480012121747756

Epoch: 5| Step: 2
Training loss: 1.7587816067738278
Validation loss: 2.479011636315842

Epoch: 5| Step: 3
Training loss: 1.3719406772611664
Validation loss: 2.443190782535928

Epoch: 5| Step: 4
Training loss: 1.6784917789334035
Validation loss: 2.428133112641426

Epoch: 5| Step: 5
Training loss: 1.6376157501311213
Validation loss: 2.4602337915955

Epoch: 5| Step: 6
Training loss: 1.9544565773368598
Validation loss: 2.422798952625452

Epoch: 5| Step: 7
Training loss: 1.7127057696717194
Validation loss: 2.4587246750376

Epoch: 5| Step: 8
Training loss: 1.4053170818366987
Validation loss: 2.469460479694159

Epoch: 5| Step: 9
Training loss: 1.2517965757475225
Validation loss: 2.4079068247320086

Epoch: 5| Step: 10
Training loss: 1.1957104089185453
Validation loss: 2.507815752195664

Epoch: 5| Step: 11
Training loss: 1.047540254024288
Validation loss: 2.455847579889706

Epoch: 171| Step: 0
Training loss: 1.3131170184888303
Validation loss: 2.4564405902822113

Epoch: 5| Step: 1
Training loss: 1.9577558626475142
Validation loss: 2.474411476529956

Epoch: 5| Step: 2
Training loss: 1.153592225401469
Validation loss: 2.4752447110071967

Epoch: 5| Step: 3
Training loss: 1.5244625457736891
Validation loss: 2.415655197112729

Epoch: 5| Step: 4
Training loss: 0.94516317906412
Validation loss: 2.4914440413334464

Epoch: 5| Step: 5
Training loss: 1.6338483089414573
Validation loss: 2.5020387879555894

Epoch: 5| Step: 6
Training loss: 1.2282632104499822
Validation loss: 2.457444067855665

Epoch: 5| Step: 7
Training loss: 1.8314981233887635
Validation loss: 2.466342057528659

Epoch: 5| Step: 8
Training loss: 1.2164214949733614
Validation loss: 2.512675165045457

Epoch: 5| Step: 9
Training loss: 2.0369003349570987
Validation loss: 2.4314710933309196

Epoch: 5| Step: 10
Training loss: 1.6965355746145192
Validation loss: 2.4653007055538727

Epoch: 5| Step: 11
Training loss: 1.7314083398786217
Validation loss: 2.471712813299213

Epoch: 172| Step: 0
Training loss: 1.6910356287346953
Validation loss: 2.5090406387484694

Epoch: 5| Step: 1
Training loss: 1.2933080867551379
Validation loss: 2.499603243974949

Epoch: 5| Step: 2
Training loss: 1.6278001428238718
Validation loss: 2.487749119685071

Epoch: 5| Step: 3
Training loss: 1.8423808558540706
Validation loss: 2.489477675415786

Epoch: 5| Step: 4
Training loss: 1.547812900000185
Validation loss: 2.481028448121911

Epoch: 5| Step: 5
Training loss: 1.586637445843253
Validation loss: 2.466499522115745

Epoch: 5| Step: 6
Training loss: 1.3301412200526692
Validation loss: 2.4686153270509967

Epoch: 5| Step: 7
Training loss: 1.9269055533670247
Validation loss: 2.475013701885841

Epoch: 5| Step: 8
Training loss: 1.353579036663945
Validation loss: 2.5595562083178227

Epoch: 5| Step: 9
Training loss: 1.705835477898757
Validation loss: 2.5432240035263565

Epoch: 5| Step: 10
Training loss: 1.5093522980366854
Validation loss: 2.4997295173712324

Epoch: 5| Step: 11
Training loss: 1.3974200761900444
Validation loss: 2.444755962118149

Epoch: 173| Step: 0
Training loss: 2.122923565804374
Validation loss: 2.405339770706621

Epoch: 5| Step: 1
Training loss: 0.8598511503838006
Validation loss: 2.4886876786899337

Epoch: 5| Step: 2
Training loss: 1.6424342034572215
Validation loss: 2.45745837810528

Epoch: 5| Step: 3
Training loss: 1.5675809265613594
Validation loss: 2.479383584691924

Epoch: 5| Step: 4
Training loss: 1.6522706649164454
Validation loss: 2.4705115765489065

Epoch: 5| Step: 5
Training loss: 1.2926877917989479
Validation loss: 2.471805259341281

Epoch: 5| Step: 6
Training loss: 1.406210792842654
Validation loss: 2.468200751261335

Epoch: 5| Step: 7
Training loss: 1.6441879095273562
Validation loss: 2.4865570522336724

Epoch: 5| Step: 8
Training loss: 1.4511059095296928
Validation loss: 2.4717867679980707

Epoch: 5| Step: 9
Training loss: 1.42735893020116
Validation loss: 2.502947885261353

Epoch: 5| Step: 10
Training loss: 1.6527869529718773
Validation loss: 2.4896260115557944

Epoch: 5| Step: 11
Training loss: 1.7610203612632687
Validation loss: 2.5049158799316906

Epoch: 174| Step: 0
Training loss: 1.33398629631027
Validation loss: 2.5243237162593672

Epoch: 5| Step: 1
Training loss: 1.5046139327749293
Validation loss: 2.4894558276693464

Epoch: 5| Step: 2
Training loss: 0.9646006289442695
Validation loss: 2.4408253296494817

Epoch: 5| Step: 3
Training loss: 1.5496406107764953
Validation loss: 2.4200685634699792

Epoch: 5| Step: 4
Training loss: 1.4542783856401302
Validation loss: 2.4838941176669054

Epoch: 5| Step: 5
Training loss: 1.408801201784335
Validation loss: 2.4380954316761714

Epoch: 5| Step: 6
Training loss: 1.7171963692350145
Validation loss: 2.4976527798202666

Epoch: 5| Step: 7
Training loss: 1.5711250290680596
Validation loss: 2.4286441157236283

Epoch: 5| Step: 8
Training loss: 1.3836919714141516
Validation loss: 2.505432782392271

Epoch: 5| Step: 9
Training loss: 1.6338160592976483
Validation loss: 2.497592060440387

Epoch: 5| Step: 10
Training loss: 2.152116102305811
Validation loss: 2.5050058672982827

Epoch: 5| Step: 11
Training loss: 1.6875803186587708
Validation loss: 2.476193437644389

Epoch: 175| Step: 0
Training loss: 1.7111825288521825
Validation loss: 2.435186408888968

Epoch: 5| Step: 1
Training loss: 1.5652939040895193
Validation loss: 2.494697928741548

Epoch: 5| Step: 2
Training loss: 1.5771296166398294
Validation loss: 2.437651067111707

Epoch: 5| Step: 3
Training loss: 1.4967755788385888
Validation loss: 2.4521302233036866

Epoch: 5| Step: 4
Training loss: 1.458650808745619
Validation loss: 2.448583008321875

Epoch: 5| Step: 5
Training loss: 1.4821079811418203
Validation loss: 2.411931643714249

Epoch: 5| Step: 6
Training loss: 1.6395795124919081
Validation loss: 2.4771084549712543

Epoch: 5| Step: 7
Training loss: 1.1247912319178035
Validation loss: 2.50574063589394

Epoch: 5| Step: 8
Training loss: 1.3657809624553257
Validation loss: 2.4193959664024542

Epoch: 5| Step: 9
Training loss: 1.9009085691358518
Validation loss: 2.481855294283779

Epoch: 5| Step: 10
Training loss: 0.9693972056124869
Validation loss: 2.4439685223822565

Epoch: 5| Step: 11
Training loss: 1.7244268819782016
Validation loss: 2.4377493628896607

Epoch: 176| Step: 0
Training loss: 1.5695709451352444
Validation loss: 2.4784250285427616

Epoch: 5| Step: 1
Training loss: 1.1518165546229746
Validation loss: 2.4813367791619103

Epoch: 5| Step: 2
Training loss: 1.5424640844235078
Validation loss: 2.45442786313693

Epoch: 5| Step: 3
Training loss: 1.8789113256818137
Validation loss: 2.5069783290065373

Epoch: 5| Step: 4
Training loss: 1.1371120545890685
Validation loss: 2.4506431667968243

Epoch: 5| Step: 5
Training loss: 1.744605879120529
Validation loss: 2.4651037845789934

Epoch: 5| Step: 6
Training loss: 1.4164499603276866
Validation loss: 2.4489865312098185

Epoch: 5| Step: 7
Training loss: 1.0998861665779902
Validation loss: 2.491905559189441

Epoch: 5| Step: 8
Training loss: 1.6059849412765537
Validation loss: 2.5005318751399574

Epoch: 5| Step: 9
Training loss: 1.2781005857043233
Validation loss: 2.431856573236517

Epoch: 5| Step: 10
Training loss: 1.8224186316851458
Validation loss: 2.505447258662327

Epoch: 5| Step: 11
Training loss: 0.7343017054566437
Validation loss: 2.448842175345478

Epoch: 177| Step: 0
Training loss: 1.1957553716272111
Validation loss: 2.4553727342680296

Epoch: 5| Step: 1
Training loss: 1.2885715358831962
Validation loss: 2.502186820129096

Epoch: 5| Step: 2
Training loss: 1.6496866564451338
Validation loss: 2.464103200572708

Epoch: 5| Step: 3
Training loss: 1.1358004396806185
Validation loss: 2.4811718162114533

Epoch: 5| Step: 4
Training loss: 1.8014596583846538
Validation loss: 2.459428552693219

Epoch: 5| Step: 5
Training loss: 1.0282612463931748
Validation loss: 2.5057260423819336

Epoch: 5| Step: 6
Training loss: 1.1831139325300846
Validation loss: 2.5323899021863525

Epoch: 5| Step: 7
Training loss: 2.3510601736502856
Validation loss: 2.4980489190485717

Epoch: 5| Step: 8
Training loss: 1.2419327288698148
Validation loss: 2.4911506552825355

Epoch: 5| Step: 9
Training loss: 1.659047625013884
Validation loss: 2.5127085193534544

Epoch: 5| Step: 10
Training loss: 1.5251667087924403
Validation loss: 2.4911633283471475

Epoch: 5| Step: 11
Training loss: 1.3449805192352016
Validation loss: 2.529863546904731

Epoch: 178| Step: 0
Training loss: 1.4295118046767166
Validation loss: 2.501464309607935

Epoch: 5| Step: 1
Training loss: 1.1728028756612519
Validation loss: 2.510269229300231

Epoch: 5| Step: 2
Training loss: 1.2637687068199874
Validation loss: 2.503632358403399

Epoch: 5| Step: 3
Training loss: 1.7180838247550343
Validation loss: 2.446523076258438

Epoch: 5| Step: 4
Training loss: 1.514470319278884
Validation loss: 2.446528078789581

Epoch: 5| Step: 5
Training loss: 1.5095097767935628
Validation loss: 2.4520357268861845

Epoch: 5| Step: 6
Training loss: 1.4882910220008092
Validation loss: 2.488295211233819

Epoch: 5| Step: 7
Training loss: 1.3217730597830697
Validation loss: 2.421505836325662

Epoch: 5| Step: 8
Training loss: 1.4883349151147267
Validation loss: 2.4720261279629083

Epoch: 5| Step: 9
Training loss: 1.9227939672644871
Validation loss: 2.4787139292195874

Epoch: 5| Step: 10
Training loss: 1.574594154748057
Validation loss: 2.4921605857105344

Epoch: 5| Step: 11
Training loss: 0.5211923760413499
Validation loss: 2.4817402581929664

Epoch: 179| Step: 0
Training loss: 1.148583487230143
Validation loss: 2.481169353875278

Epoch: 5| Step: 1
Training loss: 1.4904013923855561
Validation loss: 2.5000317531794405

Epoch: 5| Step: 2
Training loss: 1.2071998256258525
Validation loss: 2.4478726092222365

Epoch: 5| Step: 3
Training loss: 1.496387422986317
Validation loss: 2.4116865376919465

Epoch: 5| Step: 4
Training loss: 1.451682574640844
Validation loss: 2.4446481100734725

Epoch: 5| Step: 5
Training loss: 1.4578955492770833
Validation loss: 2.43263885353636

Epoch: 5| Step: 6
Training loss: 1.0278493123176116
Validation loss: 2.4782963127902025

Epoch: 5| Step: 7
Training loss: 2.4806679953503488
Validation loss: 2.4516901063662986

Epoch: 5| Step: 8
Training loss: 1.5904362954432603
Validation loss: 2.451852958658568

Epoch: 5| Step: 9
Training loss: 1.05636384339197
Validation loss: 2.4778881395950534

Epoch: 5| Step: 10
Training loss: 1.183826385901576
Validation loss: 2.458064300288144

Epoch: 5| Step: 11
Training loss: 0.9112714230670894
Validation loss: 2.4672380275919648

Epoch: 180| Step: 0
Training loss: 2.0281985323937595
Validation loss: 2.4794940505259286

Epoch: 5| Step: 1
Training loss: 1.998140125951231
Validation loss: 2.5051003682009405

Epoch: 5| Step: 2
Training loss: 1.7142317598798624
Validation loss: 2.5090242668859566

Epoch: 5| Step: 3
Training loss: 1.4339844381799478
Validation loss: 2.430956281295287

Epoch: 5| Step: 4
Training loss: 0.8591482383485742
Validation loss: 2.4429048135196507

Epoch: 5| Step: 5
Training loss: 1.2943909075766589
Validation loss: 2.4341236637678407

Epoch: 5| Step: 6
Training loss: 1.1816294267612457
Validation loss: 2.464481071152076

Epoch: 5| Step: 7
Training loss: 1.2943243659120869
Validation loss: 2.476729508714462

Epoch: 5| Step: 8
Training loss: 1.3505260484592045
Validation loss: 2.512569000789639

Epoch: 5| Step: 9
Training loss: 1.1919531395617073
Validation loss: 2.476189177059961

Epoch: 5| Step: 10
Training loss: 1.6600977988331511
Validation loss: 2.4686834672420903

Epoch: 5| Step: 11
Training loss: 0.9720988074187149
Validation loss: 2.4997142191305906

Epoch: 181| Step: 0
Training loss: 2.036824953553559
Validation loss: 2.4422793279375896

Epoch: 5| Step: 1
Training loss: 1.506181694792993
Validation loss: 2.5087642111610964

Epoch: 5| Step: 2
Training loss: 1.3149447152442815
Validation loss: 2.5280963459127856

Epoch: 5| Step: 3
Training loss: 1.353480262899918
Validation loss: 2.5216713384667804

Epoch: 5| Step: 4
Training loss: 1.4561160897830396
Validation loss: 2.476406662106332

Epoch: 5| Step: 5
Training loss: 1.2047168060181765
Validation loss: 2.5098298337963385

Epoch: 5| Step: 6
Training loss: 1.657455437522912
Validation loss: 2.497341459051634

Epoch: 5| Step: 7
Training loss: 1.41919732792978
Validation loss: 2.466900619697248

Epoch: 5| Step: 8
Training loss: 1.2028265248425254
Validation loss: 2.4487433126714295

Epoch: 5| Step: 9
Training loss: 1.1742085936735898
Validation loss: 2.437975702572291

Epoch: 5| Step: 10
Training loss: 1.5286222214529657
Validation loss: 2.4744851679091178

Epoch: 5| Step: 11
Training loss: 1.1958327812875853
Validation loss: 2.4764199762419055

Epoch: 182| Step: 0
Training loss: 1.472391605629759
Validation loss: 2.500809719166359

Epoch: 5| Step: 1
Training loss: 1.2131334636064783
Validation loss: 2.488225452190731

Epoch: 5| Step: 2
Training loss: 1.3579655498466492
Validation loss: 2.5272413033540087

Epoch: 5| Step: 3
Training loss: 1.2463171588245723
Validation loss: 2.4929983938429783

Epoch: 5| Step: 4
Training loss: 1.613417649679891
Validation loss: 2.4835406287825017

Epoch: 5| Step: 5
Training loss: 2.1782633186107407
Validation loss: 2.479045040822971

Epoch: 5| Step: 6
Training loss: 0.9970039248432282
Validation loss: 2.474727518402227

Epoch: 5| Step: 7
Training loss: 1.6140444522819875
Validation loss: 2.469022908799612

Epoch: 5| Step: 8
Training loss: 1.4134116598158708
Validation loss: 2.5007244312203776

Epoch: 5| Step: 9
Training loss: 1.4524966286178569
Validation loss: 2.4350677361554802

Epoch: 5| Step: 10
Training loss: 1.3885728932232226
Validation loss: 2.5198294411380298

Epoch: 5| Step: 11
Training loss: 1.0486579629116926
Validation loss: 2.5075361153007054

Epoch: 183| Step: 0
Training loss: 2.1240968467917796
Validation loss: 2.459082591645795

Epoch: 5| Step: 1
Training loss: 1.214680357122753
Validation loss: 2.4545452194047854

Epoch: 5| Step: 2
Training loss: 1.4853183358894628
Validation loss: 2.4726264031784875

Epoch: 5| Step: 3
Training loss: 1.019514763358976
Validation loss: 2.5048170570631405

Epoch: 5| Step: 4
Training loss: 1.1949640900710985
Validation loss: 2.5120936796654734

Epoch: 5| Step: 5
Training loss: 1.470552839526384
Validation loss: 2.459274565743583

Epoch: 5| Step: 6
Training loss: 1.4646389016923127
Validation loss: 2.506624780333059

Epoch: 5| Step: 7
Training loss: 1.3966387896763914
Validation loss: 2.4538025052060655

Epoch: 5| Step: 8
Training loss: 1.3086710892782494
Validation loss: 2.4449740654012615

Epoch: 5| Step: 9
Training loss: 1.375
Validation loss: 2.485758618069476

Epoch: 5| Step: 10
Training loss: 1.4095387890158162
Validation loss: 2.4624180492893966

Epoch: 5| Step: 11
Training loss: 1.8271703591349302
Validation loss: 2.45984263209451

Epoch: 184| Step: 0
Training loss: 1.025234421231002
Validation loss: 2.4271746967512193

Epoch: 5| Step: 1
Training loss: 0.9516112391825956
Validation loss: 2.513510049957567

Epoch: 5| Step: 2
Training loss: 1.5583925810513939
Validation loss: 2.5221982497445166

Epoch: 5| Step: 3
Training loss: 1.5772132883822532
Validation loss: 2.4874147935711775

Epoch: 5| Step: 4
Training loss: 1.4071185926305223
Validation loss: 2.4608625935452184

Epoch: 5| Step: 5
Training loss: 1.2681368638222086
Validation loss: 2.4435812373966757

Epoch: 5| Step: 6
Training loss: 1.478013309831788
Validation loss: 2.410073532919057

Epoch: 5| Step: 7
Training loss: 2.194889557304013
Validation loss: 2.5018574926923383

Epoch: 5| Step: 8
Training loss: 1.4328317722035315
Validation loss: 2.504540710685203

Epoch: 5| Step: 9
Training loss: 1.1391224828345052
Validation loss: 2.4876070850971197

Epoch: 5| Step: 10
Training loss: 1.2990794462117723
Validation loss: 2.4666625303693404

Epoch: 5| Step: 11
Training loss: 1.5219055298047874
Validation loss: 2.4414575556132556

Epoch: 185| Step: 0
Training loss: 1.4496018553703005
Validation loss: 2.4573993053419567

Epoch: 5| Step: 1
Training loss: 1.2264604951271292
Validation loss: 2.463144828228085

Epoch: 5| Step: 2
Training loss: 1.3374438799911772
Validation loss: 2.410480974065463

Epoch: 5| Step: 3
Training loss: 1.6064697263769856
Validation loss: 2.4611860482784036

Epoch: 5| Step: 4
Training loss: 1.915722745856589
Validation loss: 2.5003845554860784

Epoch: 5| Step: 5
Training loss: 1.1927725040325323
Validation loss: 2.5157513636094095

Epoch: 5| Step: 6
Training loss: 1.3927650700693472
Validation loss: 2.4308742270388093

Epoch: 5| Step: 7
Training loss: 1.3498126482766757
Validation loss: 2.4190123631785774

Epoch: 5| Step: 8
Training loss: 1.1656062495382853
Validation loss: 2.4666305932959887

Epoch: 5| Step: 9
Training loss: 1.4773168503901026
Validation loss: 2.4545464254788363

Epoch: 5| Step: 10
Training loss: 1.0305235066590157
Validation loss: 2.476380559132644

Epoch: 5| Step: 11
Training loss: 1.4940501466171372
Validation loss: 2.4907147032802643

Epoch: 186| Step: 0
Training loss: 1.322516683750885
Validation loss: 2.449872945066611

Epoch: 5| Step: 1
Training loss: 1.1391925439265114
Validation loss: 2.49891764337493

Epoch: 5| Step: 2
Training loss: 0.9047920733216774
Validation loss: 2.465801637282957

Epoch: 5| Step: 3
Training loss: 1.3653305085352891
Validation loss: 2.496038676068728

Epoch: 5| Step: 4
Training loss: 1.4956136784840377
Validation loss: 2.465766443853885

Epoch: 5| Step: 5
Training loss: 2.135158045545005
Validation loss: 2.4793140176585413

Epoch: 5| Step: 6
Training loss: 1.329714418669968
Validation loss: 2.4567968704518486

Epoch: 5| Step: 7
Training loss: 1.37161588372417
Validation loss: 2.5103641691825995

Epoch: 5| Step: 8
Training loss: 1.3837695500647722
Validation loss: 2.523300486054368

Epoch: 5| Step: 9
Training loss: 1.506329612685694
Validation loss: 2.4928697590912723

Epoch: 5| Step: 10
Training loss: 1.4384381922973584
Validation loss: 2.4868720798838

Epoch: 5| Step: 11
Training loss: 0.9166516208858867
Validation loss: 2.563225759680509

Epoch: 187| Step: 0
Training loss: 1.3331732902239912
Validation loss: 2.4957041349283084

Epoch: 5| Step: 1
Training loss: 1.9871708555404834
Validation loss: 2.483611141390736

Epoch: 5| Step: 2
Training loss: 1.4779584633561689
Validation loss: 2.459057072339257

Epoch: 5| Step: 3
Training loss: 1.2844931332355278
Validation loss: 2.4868009047340616

Epoch: 5| Step: 4
Training loss: 1.4036284701017139
Validation loss: 2.497029723512733

Epoch: 5| Step: 5
Training loss: 1.5817798556046538
Validation loss: 2.5241973075558097

Epoch: 5| Step: 6
Training loss: 1.576895055110372
Validation loss: 2.478438019195106

Epoch: 5| Step: 7
Training loss: 1.206696102686037
Validation loss: 2.4582664283980162

Epoch: 5| Step: 8
Training loss: 1.4418641890379713
Validation loss: 2.533289413531541

Epoch: 5| Step: 9
Training loss: 1.2716941367482515
Validation loss: 2.5094372090395414

Epoch: 5| Step: 10
Training loss: 1.4914620918062806
Validation loss: 2.509849861601621

Epoch: 5| Step: 11
Training loss: 0.21414016477249384
Validation loss: 2.5768244150448774

Epoch: 188| Step: 0
Training loss: 1.451031643444239
Validation loss: 2.554880047462681

Epoch: 5| Step: 1
Training loss: 1.6968396599393145
Validation loss: 2.5229763715899836

Epoch: 5| Step: 2
Training loss: 0.8640257787920661
Validation loss: 2.500047617697222

Epoch: 5| Step: 3
Training loss: 1.4046198827574443
Validation loss: 2.5009524239841543

Epoch: 5| Step: 4
Training loss: 1.235116036018031
Validation loss: 2.517691791928842

Epoch: 5| Step: 5
Training loss: 1.45444354870753
Validation loss: 2.5158008490284054

Epoch: 5| Step: 6
Training loss: 1.1588729799722302
Validation loss: 2.5029574583817196

Epoch: 5| Step: 7
Training loss: 1.4994164762369444
Validation loss: 2.4929298004929974

Epoch: 5| Step: 8
Training loss: 1.3205722801564534
Validation loss: 2.5182708978729136

Epoch: 5| Step: 9
Training loss: 1.642264355458968
Validation loss: 2.451344121020499

Epoch: 5| Step: 10
Training loss: 1.1518625062708923
Validation loss: 2.4760679920569344

Epoch: 5| Step: 11
Training loss: 3.5650045057270954
Validation loss: 2.466931667355166

Epoch: 189| Step: 0
Training loss: 1.2225496775825122
Validation loss: 2.4974277953064004

Epoch: 5| Step: 1
Training loss: 1.251484847308917
Validation loss: 2.4566853840303393

Epoch: 5| Step: 2
Training loss: 1.5504545160662988
Validation loss: 2.5975677226572684

Epoch: 5| Step: 3
Training loss: 1.6558807249283414
Validation loss: 2.492377689482756

Epoch: 5| Step: 4
Training loss: 1.488428464001529
Validation loss: 2.4764936940997124

Epoch: 5| Step: 5
Training loss: 1.5645140827699657
Validation loss: 2.458386452284168

Epoch: 5| Step: 6
Training loss: 0.9388728897686563
Validation loss: 2.484323984897901

Epoch: 5| Step: 7
Training loss: 0.9950014595519436
Validation loss: 2.4596663204343137

Epoch: 5| Step: 8
Training loss: 1.9573676454077145
Validation loss: 2.404556747923688

Epoch: 5| Step: 9
Training loss: 0.9508783095006215
Validation loss: 2.4809152917091777

Epoch: 5| Step: 10
Training loss: 1.4731147517809577
Validation loss: 2.516997667728324

Epoch: 5| Step: 11
Training loss: 1.5163198235167743
Validation loss: 2.4985786212050187

Epoch: 190| Step: 0
Training loss: 1.3497834155515507
Validation loss: 2.4431317551438876

Epoch: 5| Step: 1
Training loss: 0.8020543097327033
Validation loss: 2.52312823665091

Epoch: 5| Step: 2
Training loss: 1.3831495747061584
Validation loss: 2.5133892217559968

Epoch: 5| Step: 3
Training loss: 0.9897692488985582
Validation loss: 2.4682766223109134

Epoch: 5| Step: 4
Training loss: 1.2800962324028753
Validation loss: 2.4638117077004464

Epoch: 5| Step: 5
Training loss: 1.7749383432129808
Validation loss: 2.4454152224803964

Epoch: 5| Step: 6
Training loss: 1.1348013946095699
Validation loss: 2.532307764868106

Epoch: 5| Step: 7
Training loss: 1.4980600050608177
Validation loss: 2.472873346762911

Epoch: 5| Step: 8
Training loss: 1.4368035661181606
Validation loss: 2.461849306115656

Epoch: 5| Step: 9
Training loss: 1.9088491012138267
Validation loss: 2.442548556819664

Epoch: 5| Step: 10
Training loss: 1.1299940102342505
Validation loss: 2.476843660521967

Epoch: 5| Step: 11
Training loss: 1.154902730041337
Validation loss: 2.4297325972351103

Epoch: 191| Step: 0
Training loss: 1.9053125421449901
Validation loss: 2.4933904257929695

Epoch: 5| Step: 1
Training loss: 1.4530431252660936
Validation loss: 2.4784526571457173

Epoch: 5| Step: 2
Training loss: 1.3001475580541746
Validation loss: 2.4903645041380416

Epoch: 5| Step: 3
Training loss: 1.5421338876915092
Validation loss: 2.4699762654805104

Epoch: 5| Step: 4
Training loss: 1.4081091141767648
Validation loss: 2.4682917270163154

Epoch: 5| Step: 5
Training loss: 1.2389240702284308
Validation loss: 2.4706631683616744

Epoch: 5| Step: 6
Training loss: 1.435792489351873
Validation loss: 2.5068410217764616

Epoch: 5| Step: 7
Training loss: 0.9841575382357355
Validation loss: 2.496102967342259

Epoch: 5| Step: 8
Training loss: 1.0866675907162284
Validation loss: 2.5539268854567267

Epoch: 5| Step: 9
Training loss: 1.099432326270343
Validation loss: 2.540060193576349

Epoch: 5| Step: 10
Training loss: 1.2628834076146271
Validation loss: 2.462330067930599

Epoch: 5| Step: 11
Training loss: 0.9288984524565623
Validation loss: 2.606562265340388

Epoch: 192| Step: 0
Training loss: 1.1205366923849562
Validation loss: 2.533536314100064

Epoch: 5| Step: 1
Training loss: 1.3693512279792344
Validation loss: 2.499064608263719

Epoch: 5| Step: 2
Training loss: 1.7564489204457066
Validation loss: 2.5177060438300125

Epoch: 5| Step: 3
Training loss: 1.3582114139596884
Validation loss: 2.534757189894137

Epoch: 5| Step: 4
Training loss: 1.526403503571694
Validation loss: 2.544319708103207

Epoch: 5| Step: 5
Training loss: 1.6423598063891414
Validation loss: 2.491153227385508

Epoch: 5| Step: 6
Training loss: 1.3831938309398994
Validation loss: 2.4930707867002737

Epoch: 5| Step: 7
Training loss: 1.3557822444851015
Validation loss: 2.5003258850364913

Epoch: 5| Step: 8
Training loss: 0.9253938403542704
Validation loss: 2.5042397985606977

Epoch: 5| Step: 9
Training loss: 1.257022680771415
Validation loss: 2.5473547719577265

Epoch: 5| Step: 10
Training loss: 1.4802222537362193
Validation loss: 2.507217649617491

Epoch: 5| Step: 11
Training loss: 1.3310289387440948
Validation loss: 2.4891225130294194

Epoch: 193| Step: 0
Training loss: 0.9179176478670001
Validation loss: 2.5583732102255

Epoch: 5| Step: 1
Training loss: 1.8521759690874644
Validation loss: 2.458533074190177

Epoch: 5| Step: 2
Training loss: 1.2415861677577873
Validation loss: 2.513146846293331

Epoch: 5| Step: 3
Training loss: 1.01558802610733
Validation loss: 2.5299695469351584

Epoch: 5| Step: 4
Training loss: 1.8396398346267755
Validation loss: 2.498016937847962

Epoch: 5| Step: 5
Training loss: 1.4657212540958298
Validation loss: 2.5288063545754835

Epoch: 5| Step: 6
Training loss: 1.3590139150629912
Validation loss: 2.4430550625376313

Epoch: 5| Step: 7
Training loss: 1.1714328694763154
Validation loss: 2.5601716085436386

Epoch: 5| Step: 8
Training loss: 1.0795992294862817
Validation loss: 2.494472858921546

Epoch: 5| Step: 9
Training loss: 1.331509440398261
Validation loss: 2.5220661708534173

Epoch: 5| Step: 10
Training loss: 1.1230989394351305
Validation loss: 2.4887915526656883

Epoch: 5| Step: 11
Training loss: 2.003019199761155
Validation loss: 2.4977492214030232

Epoch: 194| Step: 0
Training loss: 1.3625070729203332
Validation loss: 2.4742500006088664

Epoch: 5| Step: 1
Training loss: 1.1079843966146272
Validation loss: 2.514293748846753

Epoch: 5| Step: 2
Training loss: 1.5445673520119227
Validation loss: 2.5034906733787192

Epoch: 5| Step: 3
Training loss: 2.207574126056403
Validation loss: 2.506132174930503

Epoch: 5| Step: 4
Training loss: 1.3627706188964737
Validation loss: 2.464976609927016

Epoch: 5| Step: 5
Training loss: 1.2839976366621473
Validation loss: 2.47094375383454

Epoch: 5| Step: 6
Training loss: 1.3582669269188798
Validation loss: 2.4719052894430855

Epoch: 5| Step: 7
Training loss: 0.9964616582263238
Validation loss: 2.4767153699768105

Epoch: 5| Step: 8
Training loss: 0.8813184738611389
Validation loss: 2.4484288809275063

Epoch: 5| Step: 9
Training loss: 1.2883872373160208
Validation loss: 2.4619009079884995

Epoch: 5| Step: 10
Training loss: 1.255062295271881
Validation loss: 2.4917809883309316

Epoch: 5| Step: 11
Training loss: 0.5573490386617858
Validation loss: 2.474876355284107

Epoch: 195| Step: 0
Training loss: 1.8207791102851898
Validation loss: 2.4777887800164375

Epoch: 5| Step: 1
Training loss: 1.5876391072038067
Validation loss: 2.4985390407722656

Epoch: 5| Step: 2
Training loss: 0.8099867022564855
Validation loss: 2.4907900959340643

Epoch: 5| Step: 3
Training loss: 1.5141822791182546
Validation loss: 2.4605432790037645

Epoch: 5| Step: 4
Training loss: 1.0712824971668127
Validation loss: 2.5455484348430453

Epoch: 5| Step: 5
Training loss: 0.8436656132637098
Validation loss: 2.4884251184158264

Epoch: 5| Step: 6
Training loss: 1.0951684745534085
Validation loss: 2.487707633868777

Epoch: 5| Step: 7
Training loss: 1.2623242794159086
Validation loss: 2.4911258672517196

Epoch: 5| Step: 8
Training loss: 1.9659623892049494
Validation loss: 2.526862561005546

Epoch: 5| Step: 9
Training loss: 1.0099602812331676
Validation loss: 2.5495615248711876

Epoch: 5| Step: 10
Training loss: 1.4833174301037884
Validation loss: 2.487419012962193

Epoch: 5| Step: 11
Training loss: 0.9445149864393151
Validation loss: 2.5086155652373083

Epoch: 196| Step: 0
Training loss: 1.6518825311160734
Validation loss: 2.503858735441582

Epoch: 5| Step: 1
Training loss: 1.087950069645686
Validation loss: 2.5143027532800564

Epoch: 5| Step: 2
Training loss: 1.4715100591213977
Validation loss: 2.4497953807929065

Epoch: 5| Step: 3
Training loss: 1.2958598012561848
Validation loss: 2.4353427592392816

Epoch: 5| Step: 4
Training loss: 1.3245749205571828
Validation loss: 2.463036742830887

Epoch: 5| Step: 5
Training loss: 1.1730509135163738
Validation loss: 2.510502660763735

Epoch: 5| Step: 6
Training loss: 1.4318291304528892
Validation loss: 2.5014764240807734

Epoch: 5| Step: 7
Training loss: 1.3104174304145242
Validation loss: 2.4406614383089082

Epoch: 5| Step: 8
Training loss: 0.7274265688774543
Validation loss: 2.498998596378007

Epoch: 5| Step: 9
Training loss: 0.933297976323673
Validation loss: 2.5260270357527554

Epoch: 5| Step: 10
Training loss: 1.8793342721406059
Validation loss: 2.4638632704897323

Epoch: 5| Step: 11
Training loss: 0.8390338274782498
Validation loss: 2.4387922570226985

Epoch: 197| Step: 0
Training loss: 1.501112366528429
Validation loss: 2.454293893831199

Epoch: 5| Step: 1
Training loss: 1.2949804232380597
Validation loss: 2.5220780032110137

Epoch: 5| Step: 2
Training loss: 1.5726323239154647
Validation loss: 2.5113569031628664

Epoch: 5| Step: 3
Training loss: 1.9576547204425057
Validation loss: 2.4994715310867943

Epoch: 5| Step: 4
Training loss: 1.2570360049672875
Validation loss: 2.442234671867904

Epoch: 5| Step: 5
Training loss: 1.1760810140419604
Validation loss: 2.4818752616428124

Epoch: 5| Step: 6
Training loss: 1.3061689087004502
Validation loss: 2.4571078298144466

Epoch: 5| Step: 7
Training loss: 1.0429143998632868
Validation loss: 2.4763853890258836

Epoch: 5| Step: 8
Training loss: 1.0976674904027173
Validation loss: 2.4506337277997123

Epoch: 5| Step: 9
Training loss: 1.2450659647858384
Validation loss: 2.4873024309315586

Epoch: 5| Step: 10
Training loss: 0.8235046040881658
Validation loss: 2.44211062430134

Epoch: 5| Step: 11
Training loss: 1.594950653795663
Validation loss: 2.4631346365652944

Epoch: 198| Step: 0
Training loss: 1.3377133439940592
Validation loss: 2.4513273395007364

Epoch: 5| Step: 1
Training loss: 0.9013956546937708
Validation loss: 2.556757470383067

Epoch: 5| Step: 2
Training loss: 1.327007002658952
Validation loss: 2.4893682711509757

Epoch: 5| Step: 3
Training loss: 0.9066673172978796
Validation loss: 2.5442433363887296

Epoch: 5| Step: 4
Training loss: 1.1986800981493269
Validation loss: 2.4774894423697713

Epoch: 5| Step: 5
Training loss: 1.2651930648876555
Validation loss: 2.483171935458433

Epoch: 5| Step: 6
Training loss: 1.3162507551142164
Validation loss: 2.5391880806409195

Epoch: 5| Step: 7
Training loss: 1.2266543408652255
Validation loss: 2.4497067372463395

Epoch: 5| Step: 8
Training loss: 1.3748049597693162
Validation loss: 2.466150885351553

Epoch: 5| Step: 9
Training loss: 1.5102634571462872
Validation loss: 2.427586463766009

Epoch: 5| Step: 10
Training loss: 1.9738382858235282
Validation loss: 2.479182216584835

Epoch: 5| Step: 11
Training loss: 0.6036595046497787
Validation loss: 2.4839702012506084

Epoch: 199| Step: 0
Training loss: 1.3244602579538927
Validation loss: 2.4533644516822544

Epoch: 5| Step: 1
Training loss: 1.8096929715494932
Validation loss: 2.4813013556712424

Epoch: 5| Step: 2
Training loss: 1.342523281030518
Validation loss: 2.460989552911127

Epoch: 5| Step: 3
Training loss: 1.4758782794612577
Validation loss: 2.4888255024653962

Epoch: 5| Step: 4
Training loss: 1.579973856311299
Validation loss: 2.4605245536409046

Epoch: 5| Step: 5
Training loss: 1.150609978324475
Validation loss: 2.521808169116369

Epoch: 5| Step: 6
Training loss: 0.9011349197965629
Validation loss: 2.4903570067684595

Epoch: 5| Step: 7
Training loss: 1.1006662496865967
Validation loss: 2.4928325946239123

Epoch: 5| Step: 8
Training loss: 1.1130594132906624
Validation loss: 2.5570028624963035

Epoch: 5| Step: 9
Training loss: 1.3396573840725599
Validation loss: 2.521263827984346

Epoch: 5| Step: 10
Training loss: 1.2783986439904194
Validation loss: 2.483944675676016

Epoch: 5| Step: 11
Training loss: 0.6029024929269061
Validation loss: 2.5406265136789314

Epoch: 200| Step: 0
Training loss: 0.9682683362556739
Validation loss: 2.5405788803763096

Epoch: 5| Step: 1
Training loss: 1.0114062205809222
Validation loss: 2.5109059574541166

Epoch: 5| Step: 2
Training loss: 1.9635107778317018
Validation loss: 2.5488678326199405

Epoch: 5| Step: 3
Training loss: 1.5289755297262637
Validation loss: 2.5528801057016706

Epoch: 5| Step: 4
Training loss: 0.9626768544200446
Validation loss: 2.512598701297038

Epoch: 5| Step: 5
Training loss: 1.4032286930637987
Validation loss: 2.503544527885853

Epoch: 5| Step: 6
Training loss: 1.207324489293249
Validation loss: 2.509790921609453

Epoch: 5| Step: 7
Training loss: 1.2602804861772285
Validation loss: 2.5128792335793255

Epoch: 5| Step: 8
Training loss: 1.3825341068358246
Validation loss: 2.65778570099988

Epoch: 5| Step: 9
Training loss: 1.3758678298559581
Validation loss: 2.4768979059046257

Epoch: 5| Step: 10
Training loss: 1.4085909961370968
Validation loss: 2.6373251568512335

Epoch: 5| Step: 11
Training loss: 0.5318849639766138
Validation loss: 2.5103001996218657

Epoch: 201| Step: 0
Training loss: 1.026617511453956
Validation loss: 2.5180631120615957

Epoch: 5| Step: 1
Training loss: 0.9245207047421149
Validation loss: 2.530511826936351

Epoch: 5| Step: 2
Training loss: 1.1887894706711586
Validation loss: 2.475573581963178

Epoch: 5| Step: 3
Training loss: 2.1143916627304584
Validation loss: 2.5087488076423075

Epoch: 5| Step: 4
Training loss: 1.0568732888666397
Validation loss: 2.537803646924456

Epoch: 5| Step: 5
Training loss: 1.3734355175711392
Validation loss: 2.4734023195497112

Epoch: 5| Step: 6
Training loss: 1.546542661782052
Validation loss: 2.5171899212620947

Epoch: 5| Step: 7
Training loss: 0.8792206265551694
Validation loss: 2.4890698032307927

Epoch: 5| Step: 8
Training loss: 1.3793149347886633
Validation loss: 2.478868792507652

Epoch: 5| Step: 9
Training loss: 0.8671098966499847
Validation loss: 2.5065052570768813

Epoch: 5| Step: 10
Training loss: 1.3339733832647902
Validation loss: 2.475892871937722

Epoch: 5| Step: 11
Training loss: 0.6207574857766647
Validation loss: 2.5661111504268055

Epoch: 202| Step: 0
Training loss: 1.249445983183178
Validation loss: 2.539044545428055

Epoch: 5| Step: 1
Training loss: 1.802546697003756
Validation loss: 2.5863761510606915

Epoch: 5| Step: 2
Training loss: 1.1614479554857384
Validation loss: 2.5279580518928157

Epoch: 5| Step: 3
Training loss: 1.9233195760665747
Validation loss: 2.5076699260933206

Epoch: 5| Step: 4
Training loss: 1.1192193394752195
Validation loss: 2.42545260272731

Epoch: 5| Step: 5
Training loss: 1.1275934420010278
Validation loss: 2.4886356941706276

Epoch: 5| Step: 6
Training loss: 0.9604856467696181
Validation loss: 2.4760804534514658

Epoch: 5| Step: 7
Training loss: 0.9728597405148702
Validation loss: 2.5132602017633645

Epoch: 5| Step: 8
Training loss: 1.118401248213272
Validation loss: 2.4638513480640074

Epoch: 5| Step: 9
Training loss: 1.2669599109982368
Validation loss: 2.4452189548462493

Epoch: 5| Step: 10
Training loss: 1.1250158944596584
Validation loss: 2.4716896871813887

Epoch: 5| Step: 11
Training loss: 0.8898550017786725
Validation loss: 2.4644697059681833

Epoch: 203| Step: 0
Training loss: 1.1587862087711627
Validation loss: 2.522165131217444

Epoch: 5| Step: 1
Training loss: 1.574069108311086
Validation loss: 2.4904924525749226

Epoch: 5| Step: 2
Training loss: 1.164385859489479
Validation loss: 2.5420343740184066

Epoch: 5| Step: 3
Training loss: 1.4027878422056088
Validation loss: 2.484396804457973

Epoch: 5| Step: 4
Training loss: 1.301322572353563
Validation loss: 2.541014702357194

Epoch: 5| Step: 5
Training loss: 0.8150109592239176
Validation loss: 2.5372426636972216

Epoch: 5| Step: 6
Training loss: 1.7813912720456682
Validation loss: 2.473916032663737

Epoch: 5| Step: 7
Training loss: 1.263841290445158
Validation loss: 2.493892106649721

Epoch: 5| Step: 8
Training loss: 1.329976395849278
Validation loss: 2.561370852821203

Epoch: 5| Step: 9
Training loss: 0.9917509665574638
Validation loss: 2.4985256138974026

Epoch: 5| Step: 10
Training loss: 1.1432837760702403
Validation loss: 2.522420495182021

Epoch: 5| Step: 11
Training loss: 0.7010281556307351
Validation loss: 2.569031509232909

Epoch: 204| Step: 0
Training loss: 0.9047779756148886
Validation loss: 2.4757481769516665

Epoch: 5| Step: 1
Training loss: 0.9309839137333739
Validation loss: 2.5540526337135288

Epoch: 5| Step: 2
Training loss: 1.1757811486126928
Validation loss: 2.476166000475587

Epoch: 5| Step: 3
Training loss: 1.1723028800558668
Validation loss: 2.431540719754167

Epoch: 5| Step: 4
Training loss: 0.8487623530684173
Validation loss: 2.528677916920734

Epoch: 5| Step: 5
Training loss: 1.2950198221346574
Validation loss: 2.5258567047569116

Epoch: 5| Step: 6
Training loss: 1.4323513873972264
Validation loss: 2.511260426393482

Epoch: 5| Step: 7
Training loss: 1.9586412580013641
Validation loss: 2.5092292539045453

Epoch: 5| Step: 8
Training loss: 1.447978843982273
Validation loss: 2.527809799751886

Epoch: 5| Step: 9
Training loss: 0.9081523922112097
Validation loss: 2.5221763624584153

Epoch: 5| Step: 10
Training loss: 1.1460705193763627
Validation loss: 2.456996389848279

Epoch: 5| Step: 11
Training loss: 2.02597464194814
Validation loss: 2.524684200430296

Epoch: 205| Step: 0
Training loss: 0.7389919352162351
Validation loss: 2.559685401895463

Epoch: 5| Step: 1
Training loss: 1.8865047989052994
Validation loss: 2.5221812503859997

Epoch: 5| Step: 2
Training loss: 0.9579518775281611
Validation loss: 2.4858203298471806

Epoch: 5| Step: 3
Training loss: 1.2435925772256757
Validation loss: 2.5726004700956517

Epoch: 5| Step: 4
Training loss: 0.8822466969805205
Validation loss: 2.490726533014406

Epoch: 5| Step: 5
Training loss: 0.9673842062151624
Validation loss: 2.4252217129164397

Epoch: 5| Step: 6
Training loss: 1.7697932236791643
Validation loss: 2.4617884743986718

Epoch: 5| Step: 7
Training loss: 1.3868826755828731
Validation loss: 2.503364354578769

Epoch: 5| Step: 8
Training loss: 1.0640373327833195
Validation loss: 2.417518393010333

Epoch: 5| Step: 9
Training loss: 1.1584574788390012
Validation loss: 2.4398846780318686

Epoch: 5| Step: 10
Training loss: 1.3125399628867704
Validation loss: 2.480381118548094

Epoch: 5| Step: 11
Training loss: 1.2898403710656643
Validation loss: 2.4707560657965986

Epoch: 206| Step: 0
Training loss: 1.087481053505204
Validation loss: 2.4384164228599454

Epoch: 5| Step: 1
Training loss: 1.2862397238540544
Validation loss: 2.497779392439979

Epoch: 5| Step: 2
Training loss: 1.5509867111659923
Validation loss: 2.4480496607155353

Epoch: 5| Step: 3
Training loss: 1.2141007484881776
Validation loss: 2.466777440002348

Epoch: 5| Step: 4
Training loss: 0.8900686500625602
Validation loss: 2.4918680374932305

Epoch: 5| Step: 5
Training loss: 1.2895482390789264
Validation loss: 2.4504143019143014

Epoch: 5| Step: 6
Training loss: 1.2263171685630914
Validation loss: 2.4454520432506803

Epoch: 5| Step: 7
Training loss: 1.9364117673378063
Validation loss: 2.4597470467019162

Epoch: 5| Step: 8
Training loss: 0.8765285288165904
Validation loss: 2.4899978305942527

Epoch: 5| Step: 9
Training loss: 1.2792053189894101
Validation loss: 2.505025695731173

Epoch: 5| Step: 10
Training loss: 1.0158377791305613
Validation loss: 2.5131637703890917

Epoch: 5| Step: 11
Training loss: 0.5621436897921874
Validation loss: 2.5513615515265413

Epoch: 207| Step: 0
Training loss: 1.0025603181572564
Validation loss: 2.519193878060513

Epoch: 5| Step: 1
Training loss: 1.0764562989049524
Validation loss: 2.476675293737543

Epoch: 5| Step: 2
Training loss: 0.9649430814569635
Validation loss: 2.4764664487934955

Epoch: 5| Step: 3
Training loss: 0.9481758070869661
Validation loss: 2.4681919408758604

Epoch: 5| Step: 4
Training loss: 1.1549299798523789
Validation loss: 2.5012549191181415

Epoch: 5| Step: 5
Training loss: 1.333487288209553
Validation loss: 2.477485276238463

Epoch: 5| Step: 6
Training loss: 0.5181940983803187
Validation loss: 2.4266324231549015

Epoch: 5| Step: 7
Training loss: 2.184601743878712
Validation loss: 2.458856174802428

Epoch: 5| Step: 8
Training loss: 1.3075248338080543
Validation loss: 2.487398319306777

Epoch: 5| Step: 9
Training loss: 1.4460093699794054
Validation loss: 2.502220423423741

Epoch: 5| Step: 10
Training loss: 1.2468340835932774
Validation loss: 2.477039965021877

Epoch: 5| Step: 11
Training loss: 0.9389878863811656
Validation loss: 2.486877694315033

Epoch: 208| Step: 0
Training loss: 1.7220740339998917
Validation loss: 2.4662477552117252

Epoch: 5| Step: 1
Training loss: 1.0280502848739308
Validation loss: 2.4766620972960443

Epoch: 5| Step: 2
Training loss: 1.0772824519632644
Validation loss: 2.585301857970243

Epoch: 5| Step: 3
Training loss: 1.9789486078969165
Validation loss: 2.576140925347064

Epoch: 5| Step: 4
Training loss: 1.219843935912118
Validation loss: 2.5103450338872886

Epoch: 5| Step: 5
Training loss: 1.155068231771839
Validation loss: 2.500047035569545

Epoch: 5| Step: 6
Training loss: 1.0129614896806842
Validation loss: 2.5120545277030413

Epoch: 5| Step: 7
Training loss: 1.2996494994463441
Validation loss: 2.6062944010513234

Epoch: 5| Step: 8
Training loss: 1.2788712354001903
Validation loss: 2.5624662141200862

Epoch: 5| Step: 9
Training loss: 0.8323421345203291
Validation loss: 2.582040333695816

Epoch: 5| Step: 10
Training loss: 0.9922656531604607
Validation loss: 2.5286699929672674

Epoch: 5| Step: 11
Training loss: 0.7512548598197358
Validation loss: 2.511039673728936

Epoch: 209| Step: 0
Training loss: 1.1304282517946216
Validation loss: 2.5251526254535426

Epoch: 5| Step: 1
Training loss: 1.7186656584419824
Validation loss: 2.495714316982622

Epoch: 5| Step: 2
Training loss: 1.0140425458217388
Validation loss: 2.5185634005946707

Epoch: 5| Step: 3
Training loss: 1.4280479493839646
Validation loss: 2.488843509980844

Epoch: 5| Step: 4
Training loss: 1.1527850841510263
Validation loss: 2.467501952587001

Epoch: 5| Step: 5
Training loss: 1.1450864207041505
Validation loss: 2.479061897185112

Epoch: 5| Step: 6
Training loss: 1.4082014319294607
Validation loss: 2.535037217678963

Epoch: 5| Step: 7
Training loss: 0.8077534903070431
Validation loss: 2.4590860456395505

Epoch: 5| Step: 8
Training loss: 1.4405598623647247
Validation loss: 2.5011414048182146

Epoch: 5| Step: 9
Training loss: 1.1384734149286617
Validation loss: 2.4239149444384145

Epoch: 5| Step: 10
Training loss: 1.017122543768925
Validation loss: 2.4373898603546915

Epoch: 5| Step: 11
Training loss: 0.6678707876370684
Validation loss: 2.5372302090456227

Epoch: 210| Step: 0
Training loss: 0.922887827650129
Validation loss: 2.510555565554234

Epoch: 5| Step: 1
Training loss: 1.4587085059637837
Validation loss: 2.458439118862528

Epoch: 5| Step: 2
Training loss: 1.0603567834719618
Validation loss: 2.491034413394916

Epoch: 5| Step: 3
Training loss: 1.1249084435400316
Validation loss: 2.5288440274406954

Epoch: 5| Step: 4
Training loss: 1.3937597197463159
Validation loss: 2.5192011772233265

Epoch: 5| Step: 5
Training loss: 1.170951937486445
Validation loss: 2.463763202171881

Epoch: 5| Step: 6
Training loss: 0.6829211604692199
Validation loss: 2.4892593928527007

Epoch: 5| Step: 7
Training loss: 1.201002651792929
Validation loss: 2.458371335210021

Epoch: 5| Step: 8
Training loss: 1.1778935313823053
Validation loss: 2.500405683980159

Epoch: 5| Step: 9
Training loss: 1.291716738725026
Validation loss: 2.5092499595326125

Epoch: 5| Step: 10
Training loss: 1.7747487333588488
Validation loss: 2.487010467625247

Epoch: 5| Step: 11
Training loss: 1.2443378477810885
Validation loss: 2.51080104581337

Epoch: 211| Step: 0
Training loss: 0.8667241138590052
Validation loss: 2.483416608373178

Epoch: 5| Step: 1
Training loss: 1.2630306073102273
Validation loss: 2.514154644232372

Epoch: 5| Step: 2
Training loss: 0.7486150192586516
Validation loss: 2.595058853949586

Epoch: 5| Step: 3
Training loss: 1.6710735788862308
Validation loss: 2.596820660576138

Epoch: 5| Step: 4
Training loss: 1.3038080872189068
Validation loss: 2.5518136303657406

Epoch: 5| Step: 5
Training loss: 1.0184948794835946
Validation loss: 2.5941115207817305

Epoch: 5| Step: 6
Training loss: 1.212103989417368
Validation loss: 2.524461784379029

Epoch: 5| Step: 7
Training loss: 0.9693723648301098
Validation loss: 2.5651244470920935

Epoch: 5| Step: 8
Training loss: 1.6247206961411431
Validation loss: 2.5379398935553947

Epoch: 5| Step: 9
Training loss: 1.1388869957533405
Validation loss: 2.5502800636517633

Epoch: 5| Step: 10
Training loss: 1.6756112250302901
Validation loss: 2.5607187158655593

Epoch: 5| Step: 11
Training loss: 1.6252268852886853
Validation loss: 2.58596641931565

Epoch: 212| Step: 0
Training loss: 1.09355663225124
Validation loss: 2.5042837714320174

Epoch: 5| Step: 1
Training loss: 1.3426538920506677
Validation loss: 2.5509140463003246

Epoch: 5| Step: 2
Training loss: 1.2696573048145734
Validation loss: 2.5173548088141

Epoch: 5| Step: 3
Training loss: 0.9990674379266697
Validation loss: 2.59524623580325

Epoch: 5| Step: 4
Training loss: 1.8466515420415974
Validation loss: 2.5190926497809563

Epoch: 5| Step: 5
Training loss: 0.8680814654404126
Validation loss: 2.5631600669577272

Epoch: 5| Step: 6
Training loss: 1.3290394944407045
Validation loss: 2.5255287213293114

Epoch: 5| Step: 7
Training loss: 1.3162531551457308
Validation loss: 2.571814564844212

Epoch: 5| Step: 8
Training loss: 1.0829575082363045
Validation loss: 2.5381809210485877

Epoch: 5| Step: 9
Training loss: 1.3197979799203432
Validation loss: 2.470753444315024

Epoch: 5| Step: 10
Training loss: 0.725748446968459
Validation loss: 2.512682463376733

Epoch: 5| Step: 11
Training loss: 1.4827420538517473
Validation loss: 2.6090944143111536

Epoch: 213| Step: 0
Training loss: 1.7045700522295244
Validation loss: 2.601735274464945

Epoch: 5| Step: 1
Training loss: 1.8329350371183428
Validation loss: 2.5848921269586174

Epoch: 5| Step: 2
Training loss: 1.0990367096105822
Validation loss: 2.5626143569550366

Epoch: 5| Step: 3
Training loss: 1.416961732690901
Validation loss: 2.565227456526675

Epoch: 5| Step: 4
Training loss: 0.8774268690973702
Validation loss: 2.5615430029585906

Epoch: 5| Step: 5
Training loss: 0.8964859706889393
Validation loss: 2.5467380943244735

Epoch: 5| Step: 6
Training loss: 1.5616124493372383
Validation loss: 2.508807221719771

Epoch: 5| Step: 7
Training loss: 1.615393043852396
Validation loss: 2.5639155362614474

Epoch: 5| Step: 8
Training loss: 1.0320130039770854
Validation loss: 2.6273902501016178

Epoch: 5| Step: 9
Training loss: 1.190121868288487
Validation loss: 2.5681501760244436

Epoch: 5| Step: 10
Training loss: 1.1411722516487353
Validation loss: 2.6491737092656398

Epoch: 5| Step: 11
Training loss: 1.285023876665988
Validation loss: 2.604682901077467

Epoch: 214| Step: 0
Training loss: 1.2543232542273866
Validation loss: 2.501939005716365

Epoch: 5| Step: 1
Training loss: 1.01023048311038
Validation loss: 2.574383102827787

Epoch: 5| Step: 2
Training loss: 0.7346157734401686
Validation loss: 2.564704335545063

Epoch: 5| Step: 3
Training loss: 1.2617320718445797
Validation loss: 2.594160020737836

Epoch: 5| Step: 4
Training loss: 0.9266408478675744
Validation loss: 2.5531864870123298

Epoch: 5| Step: 5
Training loss: 1.3759358862339583
Validation loss: 2.604983813192216

Epoch: 5| Step: 6
Training loss: 2.05156258367348
Validation loss: 2.5566616810319407

Epoch: 5| Step: 7
Training loss: 1.127946756076887
Validation loss: 2.482447802400489

Epoch: 5| Step: 8
Training loss: 1.2842373795114785
Validation loss: 2.5796047202803

Epoch: 5| Step: 9
Training loss: 1.1606099689683285
Validation loss: 2.5570037288643555

Epoch: 5| Step: 10
Training loss: 1.344112524765984
Validation loss: 2.48002157911403

Epoch: 5| Step: 11
Training loss: 0.9725853461347505
Validation loss: 2.4890609190433555

Epoch: 215| Step: 0
Training loss: 0.7915487870912197
Validation loss: 2.494422225568813

Epoch: 5| Step: 1
Training loss: 1.4634448887151572
Validation loss: 2.486698088149125

Epoch: 5| Step: 2
Training loss: 0.9113802231516142
Validation loss: 2.495232128424688

Epoch: 5| Step: 3
Training loss: 1.1982683025023233
Validation loss: 2.4995316483958194

Epoch: 5| Step: 4
Training loss: 0.8484683738978265
Validation loss: 2.526687700043357

Epoch: 5| Step: 5
Training loss: 1.2266534662227506
Validation loss: 2.5844356443646292

Epoch: 5| Step: 6
Training loss: 1.0637476832076596
Validation loss: 2.5153664521222483

Epoch: 5| Step: 7
Training loss: 1.259446877068353
Validation loss: 2.5298412390164717

Epoch: 5| Step: 8
Training loss: 1.9979006955247969
Validation loss: 2.487294343213689

Epoch: 5| Step: 9
Training loss: 1.1278048095271802
Validation loss: 2.5026923821363103

Epoch: 5| Step: 10
Training loss: 1.1394836777392234
Validation loss: 2.524297935623592

Epoch: 5| Step: 11
Training loss: 1.5550538211352034
Validation loss: 2.532695467435802

Epoch: 216| Step: 0
Training loss: 1.3814669166880857
Validation loss: 2.5272770223795202

Epoch: 5| Step: 1
Training loss: 1.1158476577952317
Validation loss: 2.542228026361104

Epoch: 5| Step: 2
Training loss: 1.2331678547979568
Validation loss: 2.492630754712393

Epoch: 5| Step: 3
Training loss: 1.102028227487841
Validation loss: 2.5329093047023172

Epoch: 5| Step: 4
Training loss: 1.6437600110115402
Validation loss: 2.523048894542487

Epoch: 5| Step: 5
Training loss: 0.7382805637578449
Validation loss: 2.46921828210753

Epoch: 5| Step: 6
Training loss: 1.0022177541964008
Validation loss: 2.4742221785275573

Epoch: 5| Step: 7
Training loss: 1.797180879514702
Validation loss: 2.5291096386039267

Epoch: 5| Step: 8
Training loss: 0.9082914247965002
Validation loss: 2.5282761211518876

Epoch: 5| Step: 9
Training loss: 1.1307628636527745
Validation loss: 2.4482709885231912

Epoch: 5| Step: 10
Training loss: 1.0393864979799008
Validation loss: 2.5483064236934343

Epoch: 5| Step: 11
Training loss: 1.125011497014956
Validation loss: 2.5345434223034284

Epoch: 217| Step: 0
Training loss: 1.0740123203643586
Validation loss: 2.531904049740207

Epoch: 5| Step: 1
Training loss: 1.649387899205981
Validation loss: 2.5632846026528013

Epoch: 5| Step: 2
Training loss: 1.6343696871319224
Validation loss: 2.49494103533394

Epoch: 5| Step: 3
Training loss: 0.9413887117263818
Validation loss: 2.4836602252400883

Epoch: 5| Step: 4
Training loss: 1.3123104776060825
Validation loss: 2.501535377299809

Epoch: 5| Step: 5
Training loss: 1.1481643663363856
Validation loss: 2.4901263045253987

Epoch: 5| Step: 6
Training loss: 0.7643076793878298
Validation loss: 2.5088824349689602

Epoch: 5| Step: 7
Training loss: 1.1576232487787104
Validation loss: 2.529258348718961

Epoch: 5| Step: 8
Training loss: 0.8188155548409094
Validation loss: 2.4567717074975683

Epoch: 5| Step: 9
Training loss: 1.267373325631608
Validation loss: 2.499004547298182

Epoch: 5| Step: 10
Training loss: 1.1586979907234953
Validation loss: 2.5251171596338593

Epoch: 5| Step: 11
Training loss: 0.6829145272364764
Validation loss: 2.50736126746986

Epoch: 218| Step: 0
Training loss: 1.9965078144641841
Validation loss: 2.4736488483329353

Epoch: 5| Step: 1
Training loss: 0.7341578142135429
Validation loss: 2.480411418742848

Epoch: 5| Step: 2
Training loss: 1.2230603217644003
Validation loss: 2.5185375018283516

Epoch: 5| Step: 3
Training loss: 1.0523384213047158
Validation loss: 2.5050740090336414

Epoch: 5| Step: 4
Training loss: 1.1781111536806006
Validation loss: 2.511075267165523

Epoch: 5| Step: 5
Training loss: 0.6346069841951528
Validation loss: 2.545236060187244

Epoch: 5| Step: 6
Training loss: 0.9993270159206347
Validation loss: 2.5165893135961874

Epoch: 5| Step: 7
Training loss: 1.232793785117548
Validation loss: 2.4636832808801152

Epoch: 5| Step: 8
Training loss: 1.2457238009899974
Validation loss: 2.5102121552123684

Epoch: 5| Step: 9
Training loss: 1.069350931419566
Validation loss: 2.491950060655801

Epoch: 5| Step: 10
Training loss: 1.1110437763527172
Validation loss: 2.5320410963959876

Epoch: 5| Step: 11
Training loss: 1.2362888806036885
Validation loss: 2.5274740320161495

Epoch: 219| Step: 0
Training loss: 1.7256219986416623
Validation loss: 2.5840524562133504

Epoch: 5| Step: 1
Training loss: 1.1472887794721989
Validation loss: 2.6680702089647226

Epoch: 5| Step: 2
Training loss: 1.5463615104661088
Validation loss: 2.527028480295072

Epoch: 5| Step: 3
Training loss: 1.1415055938663845
Validation loss: 2.52530632065178

Epoch: 5| Step: 4
Training loss: 0.9540686391813474
Validation loss: 2.5479354561908027

Epoch: 5| Step: 5
Training loss: 1.0961364868272137
Validation loss: 2.4024859916114543

Epoch: 5| Step: 6
Training loss: 1.1728874410688837
Validation loss: 2.4805965440725792

Epoch: 5| Step: 7
Training loss: 0.795090678519714
Validation loss: 2.5001129681177052

Epoch: 5| Step: 8
Training loss: 1.3606604275452139
Validation loss: 2.524015519872791

Epoch: 5| Step: 9
Training loss: 1.0493644607496364
Validation loss: 2.5005584689068283

Epoch: 5| Step: 10
Training loss: 0.977704654353143
Validation loss: 2.5367809706657303

Epoch: 5| Step: 11
Training loss: 0.7390737569004094
Validation loss: 2.515057865131884

Epoch: 220| Step: 0
Training loss: 1.3009017109581307
Validation loss: 2.4739919673574176

Epoch: 5| Step: 1
Training loss: 0.8870754784743506
Validation loss: 2.511177016432389

Epoch: 5| Step: 2
Training loss: 0.8619598010020819
Validation loss: 2.5133770718192157

Epoch: 5| Step: 3
Training loss: 1.0071201163916037
Validation loss: 2.5306277707305287

Epoch: 5| Step: 4
Training loss: 1.1917466474693585
Validation loss: 2.5522888736607334

Epoch: 5| Step: 5
Training loss: 1.3137237656548233
Validation loss: 2.5335197946876713

Epoch: 5| Step: 6
Training loss: 1.1039194094122595
Validation loss: 2.4685176224934944

Epoch: 5| Step: 7
Training loss: 1.0000950648897502
Validation loss: 2.555265563441092

Epoch: 5| Step: 8
Training loss: 1.703059483939114
Validation loss: 2.507064172915513

Epoch: 5| Step: 9
Training loss: 1.3948081887567378
Validation loss: 2.502477237103745

Epoch: 5| Step: 10
Training loss: 0.9589884149967409
Validation loss: 2.539519213168713

Epoch: 5| Step: 11
Training loss: 0.8396034784164088
Validation loss: 2.48593147272306

Epoch: 221| Step: 0
Training loss: 0.9608757805581047
Validation loss: 2.4791721830119675

Epoch: 5| Step: 1
Training loss: 0.8557018850709891
Validation loss: 2.5134600886293823

Epoch: 5| Step: 2
Training loss: 1.0783336824439151
Validation loss: 2.5276708376507675

Epoch: 5| Step: 3
Training loss: 1.3179870079598432
Validation loss: 2.4953611728648384

Epoch: 5| Step: 4
Training loss: 1.5839047488367004
Validation loss: 2.5016770737901917

Epoch: 5| Step: 5
Training loss: 0.8640964163389039
Validation loss: 2.518439181912196

Epoch: 5| Step: 6
Training loss: 1.6116652257466442
Validation loss: 2.475846079664397

Epoch: 5| Step: 7
Training loss: 0.7489838869477832
Validation loss: 2.4731688969909675

Epoch: 5| Step: 8
Training loss: 1.0435864623092739
Validation loss: 2.457488142349079

Epoch: 5| Step: 9
Training loss: 1.2460184104410417
Validation loss: 2.4906770080918235

Epoch: 5| Step: 10
Training loss: 1.441947855933833
Validation loss: 2.5328779832994686

Epoch: 5| Step: 11
Training loss: 0.6342696144625645
Validation loss: 2.5337663787553306

Epoch: 222| Step: 0
Training loss: 1.2326011950441107
Validation loss: 2.4609318707921473

Epoch: 5| Step: 1
Training loss: 0.9288655341924669
Validation loss: 2.4811871507053245

Epoch: 5| Step: 2
Training loss: 1.0252598270372255
Validation loss: 2.478214655469391

Epoch: 5| Step: 3
Training loss: 1.2111208376994538
Validation loss: 2.465994999807011

Epoch: 5| Step: 4
Training loss: 1.5472702138014587
Validation loss: 2.4575476252900876

Epoch: 5| Step: 5
Training loss: 0.6561892572174685
Validation loss: 2.4635345480387922

Epoch: 5| Step: 6
Training loss: 0.8543260510925966
Validation loss: 2.5052833836681887

Epoch: 5| Step: 7
Training loss: 1.1294036086427253
Validation loss: 2.5046619895481523

Epoch: 5| Step: 8
Training loss: 0.9293381491399012
Validation loss: 2.5080601578825843

Epoch: 5| Step: 9
Training loss: 1.8728836195268168
Validation loss: 2.431240711750113

Epoch: 5| Step: 10
Training loss: 0.8595871056717237
Validation loss: 2.4236170850793712

Epoch: 5| Step: 11
Training loss: 1.0092433855446188
Validation loss: 2.4730292586801466

Epoch: 223| Step: 0
Training loss: 1.0250906369213448
Validation loss: 2.470208831516381

Epoch: 5| Step: 1
Training loss: 1.1951852369190796
Validation loss: 2.5267807079318865

Epoch: 5| Step: 2
Training loss: 1.0569242142690516
Validation loss: 2.5055467782767873

Epoch: 5| Step: 3
Training loss: 1.0349230233652076
Validation loss: 2.5001789903143967

Epoch: 5| Step: 4
Training loss: 1.7832943077214316
Validation loss: 2.4463092247290064

Epoch: 5| Step: 5
Training loss: 1.0022900704499524
Validation loss: 2.500213709279975

Epoch: 5| Step: 6
Training loss: 0.9176269869017049
Validation loss: 2.479920510407636

Epoch: 5| Step: 7
Training loss: 1.3838693491837846
Validation loss: 2.461670442456462

Epoch: 5| Step: 8
Training loss: 0.951100090184958
Validation loss: 2.457958056744885

Epoch: 5| Step: 9
Training loss: 0.965090762500075
Validation loss: 2.544215820925551

Epoch: 5| Step: 10
Training loss: 1.3004517925586407
Validation loss: 2.5508756128434014

Epoch: 5| Step: 11
Training loss: 1.5056844132206377
Validation loss: 2.501382016611364

Epoch: 224| Step: 0
Training loss: 1.2239467160370239
Validation loss: 2.570860069100846

Epoch: 5| Step: 1
Training loss: 1.1287597772421945
Validation loss: 2.467529631027411

Epoch: 5| Step: 2
Training loss: 0.9764387739005096
Validation loss: 2.467554970115764

Epoch: 5| Step: 3
Training loss: 0.9018325017907501
Validation loss: 2.5228163522569407

Epoch: 5| Step: 4
Training loss: 1.1938474565439505
Validation loss: 2.5645422589514277

Epoch: 5| Step: 5
Training loss: 1.5153997194847482
Validation loss: 2.5443541761405286

Epoch: 5| Step: 6
Training loss: 1.3628556426072296
Validation loss: 2.46907138342145

Epoch: 5| Step: 7
Training loss: 1.023323751636674
Validation loss: 2.4939937523414613

Epoch: 5| Step: 8
Training loss: 1.8700025080087743
Validation loss: 2.5265550753661876

Epoch: 5| Step: 9
Training loss: 1.3332039154345463
Validation loss: 2.5527324175468395

Epoch: 5| Step: 10
Training loss: 0.9883346241647183
Validation loss: 2.53692900006925

Epoch: 5| Step: 11
Training loss: 0.5966053618294692
Validation loss: 2.5375880924524434

Epoch: 225| Step: 0
Training loss: 0.809507471091352
Validation loss: 2.5007913687987

Epoch: 5| Step: 1
Training loss: 0.5999511341223182
Validation loss: 2.488478069416242

Epoch: 5| Step: 2
Training loss: 1.7617847235732822
Validation loss: 2.5476792865652564

Epoch: 5| Step: 3
Training loss: 1.0065933068389263
Validation loss: 2.498278716709533

Epoch: 5| Step: 4
Training loss: 1.0795945366283406
Validation loss: 2.493014898842341

Epoch: 5| Step: 5
Training loss: 1.4237914531992981
Validation loss: 2.49647314524454

Epoch: 5| Step: 6
Training loss: 1.3283520224025096
Validation loss: 2.556213354860022

Epoch: 5| Step: 7
Training loss: 0.8875841799290173
Validation loss: 2.5376624252688593

Epoch: 5| Step: 8
Training loss: 1.2302713871666415
Validation loss: 2.5208948117370453

Epoch: 5| Step: 9
Training loss: 1.1663835670222797
Validation loss: 2.485796044155563

Epoch: 5| Step: 10
Training loss: 0.8080311905298456
Validation loss: 2.5422008231919193

Epoch: 5| Step: 11
Training loss: 2.1725789857120765
Validation loss: 2.485086147323343

Epoch: 226| Step: 0
Training loss: 1.407383186683117
Validation loss: 2.4877424150745564

Epoch: 5| Step: 1
Training loss: 1.1915960942336576
Validation loss: 2.4760803651868186

Epoch: 5| Step: 2
Training loss: 0.8535093049747239
Validation loss: 2.5032161449994113

Epoch: 5| Step: 3
Training loss: 0.819296471028298
Validation loss: 2.4774861142769886

Epoch: 5| Step: 4
Training loss: 0.9887366772126639
Validation loss: 2.61165648977743

Epoch: 5| Step: 5
Training loss: 2.177583944145729
Validation loss: 2.5573213126231025

Epoch: 5| Step: 6
Training loss: 0.8219541199751271
Validation loss: 2.5537103578799036

Epoch: 5| Step: 7
Training loss: 0.8493464973051862
Validation loss: 2.4558857004566765

Epoch: 5| Step: 8
Training loss: 0.8649671843814438
Validation loss: 2.491012431746796

Epoch: 5| Step: 9
Training loss: 0.785523058484257
Validation loss: 2.4351290110081543

Epoch: 5| Step: 10
Training loss: 1.0361374721008858
Validation loss: 2.5315029524168686

Epoch: 5| Step: 11
Training loss: 1.4069675734036136
Validation loss: 2.5465206102505507

Epoch: 227| Step: 0
Training loss: 1.2344695429268153
Validation loss: 2.5616420418315418

Epoch: 5| Step: 1
Training loss: 0.8469980382750221
Validation loss: 2.507787876661875

Epoch: 5| Step: 2
Training loss: 1.0070746034415587
Validation loss: 2.492857212260078

Epoch: 5| Step: 3
Training loss: 1.3894817925242082
Validation loss: 2.5391137142396003

Epoch: 5| Step: 4
Training loss: 1.0961582374227394
Validation loss: 2.5300492374211423

Epoch: 5| Step: 5
Training loss: 0.903666529936049
Validation loss: 2.524736528688222

Epoch: 5| Step: 6
Training loss: 1.0141548667185722
Validation loss: 2.5664577933776753

Epoch: 5| Step: 7
Training loss: 1.8991731074069007
Validation loss: 2.5348152946269087

Epoch: 5| Step: 8
Training loss: 1.0568828763391955
Validation loss: 2.477280132720363

Epoch: 5| Step: 9
Training loss: 1.0904507604411375
Validation loss: 2.472270366977374

Epoch: 5| Step: 10
Training loss: 0.9860612262650628
Validation loss: 2.5030172141462774

Epoch: 5| Step: 11
Training loss: 0.7145208244305563
Validation loss: 2.5510873343161435

Epoch: 228| Step: 0
Training loss: 1.0126609391767687
Validation loss: 2.5501726562665343

Epoch: 5| Step: 1
Training loss: 1.3174523970746492
Validation loss: 2.486246643569187

Epoch: 5| Step: 2
Training loss: 0.8069920547878917
Validation loss: 2.5278131991362773

Epoch: 5| Step: 3
Training loss: 0.9059590826394764
Validation loss: 2.5392399300423185

Epoch: 5| Step: 4
Training loss: 0.9765878902949304
Validation loss: 2.5231674293892192

Epoch: 5| Step: 5
Training loss: 1.2665052767047678
Validation loss: 2.4594559180759434

Epoch: 5| Step: 6
Training loss: 0.8471483387720337
Validation loss: 2.513369368396863

Epoch: 5| Step: 7
Training loss: 0.7539080288722739
Validation loss: 2.528531533881765

Epoch: 5| Step: 8
Training loss: 1.3793325656712347
Validation loss: 2.4957284356576888

Epoch: 5| Step: 9
Training loss: 1.8913717765455413
Validation loss: 2.5490450789876693

Epoch: 5| Step: 10
Training loss: 1.142589445139569
Validation loss: 2.5484057742759108

Epoch: 5| Step: 11
Training loss: 0.6948398312217328
Validation loss: 2.48017655701664

Epoch: 229| Step: 0
Training loss: 0.6528825419364841
Validation loss: 2.490262171770924

Epoch: 5| Step: 1
Training loss: 1.9226491345921453
Validation loss: 2.5834546881033535

Epoch: 5| Step: 2
Training loss: 1.1414873704015274
Validation loss: 2.545703684902515

Epoch: 5| Step: 3
Training loss: 1.287814698137584
Validation loss: 2.531830936846682

Epoch: 5| Step: 4
Training loss: 0.858887308629079
Validation loss: 2.5644930613444905

Epoch: 5| Step: 5
Training loss: 0.8284621362177909
Validation loss: 2.519835196995983

Epoch: 5| Step: 6
Training loss: 1.0029203568630902
Validation loss: 2.5296783395263236

Epoch: 5| Step: 7
Training loss: 0.8265784956136096
Validation loss: 2.5013063395336714

Epoch: 5| Step: 8
Training loss: 1.008068791411163
Validation loss: 2.49354480585978

Epoch: 5| Step: 9
Training loss: 1.404984561794622
Validation loss: 2.4591303734819623

Epoch: 5| Step: 10
Training loss: 0.9312078722443252
Validation loss: 2.5152187256282517

Epoch: 5| Step: 11
Training loss: 1.030353387559931
Validation loss: 2.4545628288365373

Epoch: 230| Step: 0
Training loss: 0.650289945857476
Validation loss: 2.486513980412719

Epoch: 5| Step: 1
Training loss: 0.8839470990758956
Validation loss: 2.5503454434866373

Epoch: 5| Step: 2
Training loss: 0.9022361393955488
Validation loss: 2.5364687225525904

Epoch: 5| Step: 3
Training loss: 1.0758444951012998
Validation loss: 2.5366904304630267

Epoch: 5| Step: 4
Training loss: 1.4180581140863542
Validation loss: 2.582203805902678

Epoch: 5| Step: 5
Training loss: 2.132744756607874
Validation loss: 2.4818153010437745

Epoch: 5| Step: 6
Training loss: 0.7440648478375226
Validation loss: 2.519899712956259

Epoch: 5| Step: 7
Training loss: 1.0456489101487594
Validation loss: 2.529185230044553

Epoch: 5| Step: 8
Training loss: 0.9408549993930055
Validation loss: 2.516238755726725

Epoch: 5| Step: 9
Training loss: 1.1341652521259606
Validation loss: 2.6028537161623926

Epoch: 5| Step: 10
Training loss: 0.6178881615562978
Validation loss: 2.486111110297143

Epoch: 5| Step: 11
Training loss: 1.3234713535415188
Validation loss: 2.530845244742524

Epoch: 231| Step: 0
Training loss: 0.6843011084603209
Validation loss: 2.4739650378220044

Epoch: 5| Step: 1
Training loss: 1.1272855430375135
Validation loss: 2.465050815080432

Epoch: 5| Step: 2
Training loss: 1.8023009269928285
Validation loss: 2.4951752876738564

Epoch: 5| Step: 3
Training loss: 0.7581746130903034
Validation loss: 2.4754024319725585

Epoch: 5| Step: 4
Training loss: 1.1690313296431345
Validation loss: 2.498070584269918

Epoch: 5| Step: 5
Training loss: 0.5893152155241633
Validation loss: 2.521411921304543

Epoch: 5| Step: 6
Training loss: 1.1007813193089049
Validation loss: 2.5012813304468473

Epoch: 5| Step: 7
Training loss: 0.9018365664894448
Validation loss: 2.5504895676845267

Epoch: 5| Step: 8
Training loss: 1.135345573416059
Validation loss: 2.4435178815584053

Epoch: 5| Step: 9
Training loss: 1.1342089760087646
Validation loss: 2.519634404399505

Epoch: 5| Step: 10
Training loss: 1.0347533971597556
Validation loss: 2.4760501504083248

Epoch: 5| Step: 11
Training loss: 0.883491390110759
Validation loss: 2.4569016580616103

Epoch: 232| Step: 0
Training loss: 0.7922314753920136
Validation loss: 2.5148152850948655

Epoch: 5| Step: 1
Training loss: 1.7828625524049302
Validation loss: 2.535327625408998

Epoch: 5| Step: 2
Training loss: 0.8101309203084746
Validation loss: 2.459934413676562

Epoch: 5| Step: 3
Training loss: 1.0711924145064597
Validation loss: 2.52259964708621

Epoch: 5| Step: 4
Training loss: 1.0129550758861667
Validation loss: 2.470819985662971

Epoch: 5| Step: 5
Training loss: 1.0126120846721354
Validation loss: 2.4853876177477674

Epoch: 5| Step: 6
Training loss: 0.556280668891932
Validation loss: 2.566248896171678

Epoch: 5| Step: 7
Training loss: 1.1547583675704887
Validation loss: 2.5136957570057694

Epoch: 5| Step: 8
Training loss: 1.0559608966711134
Validation loss: 2.5532480747934407

Epoch: 5| Step: 9
Training loss: 1.1092840882781472
Validation loss: 2.5385631481060598

Epoch: 5| Step: 10
Training loss: 0.9604964135602947
Validation loss: 2.5291930384782395

Epoch: 5| Step: 11
Training loss: 1.3956092493284853
Validation loss: 2.5676447271757317

Epoch: 233| Step: 0
Training loss: 1.1682768450443886
Validation loss: 2.561846099166858

Epoch: 5| Step: 1
Training loss: 1.1363095730145405
Validation loss: 2.4717854216331863

Epoch: 5| Step: 2
Training loss: 0.8052761924413409
Validation loss: 2.5462123305190896

Epoch: 5| Step: 3
Training loss: 0.8396485212653882
Validation loss: 2.4634046711376114

Epoch: 5| Step: 4
Training loss: 1.154164986087021
Validation loss: 2.5249587041480592

Epoch: 5| Step: 5
Training loss: 0.7277861105301915
Validation loss: 2.5346162727427575

Epoch: 5| Step: 6
Training loss: 0.6441254002684421
Validation loss: 2.486423757291656

Epoch: 5| Step: 7
Training loss: 1.0821606940778281
Validation loss: 2.466722033712675

Epoch: 5| Step: 8
Training loss: 1.575698800452458
Validation loss: 2.503252274305247

Epoch: 5| Step: 9
Training loss: 1.3374627313145344
Validation loss: 2.554531438729004

Epoch: 5| Step: 10
Training loss: 1.0123818481643252
Validation loss: 2.499732841681046

Epoch: 5| Step: 11
Training loss: 0.8221527892049353
Validation loss: 2.587585028112849

Epoch: 234| Step: 0
Training loss: 0.92148471911506
Validation loss: 2.529728824842642

Epoch: 5| Step: 1
Training loss: 1.1409797639314423
Validation loss: 2.5084209516077705

Epoch: 5| Step: 2
Training loss: 0.7803849199120686
Validation loss: 2.588168508137401

Epoch: 5| Step: 3
Training loss: 0.9021399131515874
Validation loss: 2.4744096277435923

Epoch: 5| Step: 4
Training loss: 1.1276132114861095
Validation loss: 2.5673099438316638

Epoch: 5| Step: 5
Training loss: 1.2180456424736503
Validation loss: 2.572178801758717

Epoch: 5| Step: 6
Training loss: 1.4923389617584293
Validation loss: 2.486307200513334

Epoch: 5| Step: 7
Training loss: 0.7523137800638848
Validation loss: 2.441731895599681

Epoch: 5| Step: 8
Training loss: 1.4297623745015404
Validation loss: 2.5445394396979535

Epoch: 5| Step: 9
Training loss: 0.623395505365575
Validation loss: 2.5147438322571154

Epoch: 5| Step: 10
Training loss: 1.2012248702105097
Validation loss: 2.571066764072492

Epoch: 5| Step: 11
Training loss: 0.42145379550368395
Validation loss: 2.5339123123622396

Epoch: 235| Step: 0
Training loss: 1.0618797623660576
Validation loss: 2.5179113320954802

Epoch: 5| Step: 1
Training loss: 1.3017177475460755
Validation loss: 2.5039617142507824

Epoch: 5| Step: 2
Training loss: 1.6830888243257003
Validation loss: 2.552672903249393

Epoch: 5| Step: 3
Training loss: 1.0191753248490012
Validation loss: 2.5359457008415682

Epoch: 5| Step: 4
Training loss: 0.833526199592676
Validation loss: 2.4519093613555016

Epoch: 5| Step: 5
Training loss: 0.7191905040113002
Validation loss: 2.5476936865548363

Epoch: 5| Step: 6
Training loss: 0.8195968412583241
Validation loss: 2.445553147212344

Epoch: 5| Step: 7
Training loss: 0.9471892965180801
Validation loss: 2.5433653128204146

Epoch: 5| Step: 8
Training loss: 1.0145261248387578
Validation loss: 2.5282105222743336

Epoch: 5| Step: 9
Training loss: 0.7951636544210989
Validation loss: 2.4888632755886926

Epoch: 5| Step: 10
Training loss: 1.0397579189218191
Validation loss: 2.531588284528702

Epoch: 5| Step: 11
Training loss: 0.7319380726336863
Validation loss: 2.4826359090068393

Epoch: 236| Step: 0
Training loss: 1.2824534834964398
Validation loss: 2.5123547885298856

Epoch: 5| Step: 1
Training loss: 0.8246978885737857
Validation loss: 2.487865191638263

Epoch: 5| Step: 2
Training loss: 0.6711809654539378
Validation loss: 2.5648490288322137

Epoch: 5| Step: 3
Training loss: 1.5691972254638882
Validation loss: 2.506164373645857

Epoch: 5| Step: 4
Training loss: 0.9733193829486032
Validation loss: 2.4434364849458765

Epoch: 5| Step: 5
Training loss: 1.07570664445627
Validation loss: 2.476652526823662

Epoch: 5| Step: 6
Training loss: 0.8322854526814573
Validation loss: 2.510733918105041

Epoch: 5| Step: 7
Training loss: 0.8870537079008709
Validation loss: 2.494074773553919

Epoch: 5| Step: 8
Training loss: 1.1561642176793863
Validation loss: 2.517543241043631

Epoch: 5| Step: 9
Training loss: 0.9707348701305951
Validation loss: 2.487777079992247

Epoch: 5| Step: 10
Training loss: 0.758445278924722
Validation loss: 2.519183290096315

Epoch: 5| Step: 11
Training loss: 2.02409640744508
Validation loss: 2.428758506989056

Epoch: 237| Step: 0
Training loss: 0.90419134261626
Validation loss: 2.515833605139449

Epoch: 5| Step: 1
Training loss: 1.3457522888504285
Validation loss: 2.5356691171840215

Epoch: 5| Step: 2
Training loss: 1.7301015356619829
Validation loss: 2.652441716807715

Epoch: 5| Step: 3
Training loss: 0.9030236989266737
Validation loss: 2.524495246609858

Epoch: 5| Step: 4
Training loss: 0.894773925113909
Validation loss: 2.4883652038624122

Epoch: 5| Step: 5
Training loss: 1.0888683370404526
Validation loss: 2.581140088349855

Epoch: 5| Step: 6
Training loss: 0.6112503148489611
Validation loss: 2.5172516596593515

Epoch: 5| Step: 7
Training loss: 0.8588463284188989
Validation loss: 2.484951002496933

Epoch: 5| Step: 8
Training loss: 0.9743257159480082
Validation loss: 2.5006333760765855

Epoch: 5| Step: 9
Training loss: 1.2217263777704883
Validation loss: 2.558909571911164

Epoch: 5| Step: 10
Training loss: 1.1044117757463041
Validation loss: 2.528910038061077

Epoch: 5| Step: 11
Training loss: 1.2620681892931376
Validation loss: 2.4758844420110693

Epoch: 238| Step: 0
Training loss: 1.5207667488606882
Validation loss: 2.5184015309078713

Epoch: 5| Step: 1
Training loss: 0.7577425737662095
Validation loss: 2.4987436316547216

Epoch: 5| Step: 2
Training loss: 0.9596351854728652
Validation loss: 2.5220025296209903

Epoch: 5| Step: 3
Training loss: 0.8239413694105517
Validation loss: 2.5524182521570995

Epoch: 5| Step: 4
Training loss: 0.9456852895070371
Validation loss: 2.5085211888387158

Epoch: 5| Step: 5
Training loss: 0.9914748568653227
Validation loss: 2.5755873704626997

Epoch: 5| Step: 6
Training loss: 1.3544401724027113
Validation loss: 2.4591871263352485

Epoch: 5| Step: 7
Training loss: 0.9145887115482587
Validation loss: 2.4847519226767876

Epoch: 5| Step: 8
Training loss: 1.02067752868816
Validation loss: 2.5081455350247985

Epoch: 5| Step: 9
Training loss: 1.1162982949876499
Validation loss: 2.5420204890841305

Epoch: 5| Step: 10
Training loss: 1.160246155206203
Validation loss: 2.4665653626532356

Epoch: 5| Step: 11
Training loss: 0.44240861358517775
Validation loss: 2.543575400062833

Epoch: 239| Step: 0
Training loss: 0.8424512262687156
Validation loss: 2.5168752623839645

Epoch: 5| Step: 1
Training loss: 1.0152811495378073
Validation loss: 2.5142757319812397

Epoch: 5| Step: 2
Training loss: 1.0423109859302986
Validation loss: 2.5042524331544254

Epoch: 5| Step: 3
Training loss: 1.659498519754281
Validation loss: 2.4961624653431436

Epoch: 5| Step: 4
Training loss: 0.7089758838323741
Validation loss: 2.5588870979631704

Epoch: 5| Step: 5
Training loss: 0.8716402264141345
Validation loss: 2.5144653451182193

Epoch: 5| Step: 6
Training loss: 1.3315293605488165
Validation loss: 2.5159645680667855

Epoch: 5| Step: 7
Training loss: 1.0140399595321148
Validation loss: 2.5158596166349936

Epoch: 5| Step: 8
Training loss: 1.0611340212942337
Validation loss: 2.4718068950609173

Epoch: 5| Step: 9
Training loss: 1.0408217373016966
Validation loss: 2.5474810279062368

Epoch: 5| Step: 10
Training loss: 0.6811473996656366
Validation loss: 2.563018354851255

Epoch: 5| Step: 11
Training loss: 1.5096580003127613
Validation loss: 2.484072688840823

Epoch: 240| Step: 0
Training loss: 1.0795034359324673
Validation loss: 2.5070235812857553

Epoch: 5| Step: 1
Training loss: 0.9218684374042266
Validation loss: 2.459387033474286

Epoch: 5| Step: 2
Training loss: 1.7816367147846466
Validation loss: 2.539187247317365

Epoch: 5| Step: 3
Training loss: 1.0211155300254617
Validation loss: 2.523004587239094

Epoch: 5| Step: 4
Training loss: 0.9469505179225892
Validation loss: 2.474094131490448

Epoch: 5| Step: 5
Training loss: 1.1236667149861643
Validation loss: 2.5418152270649466

Epoch: 5| Step: 6
Training loss: 0.7085373995917069
Validation loss: 2.465817435989968

Epoch: 5| Step: 7
Training loss: 0.9454680385785507
Validation loss: 2.5630114130318464

Epoch: 5| Step: 8
Training loss: 0.957643803338072
Validation loss: 2.5154678066574228

Epoch: 5| Step: 9
Training loss: 0.8980940452555819
Validation loss: 2.4877422074270097

Epoch: 5| Step: 10
Training loss: 0.9879912904710708
Validation loss: 2.5806739421418534

Epoch: 5| Step: 11
Training loss: 0.5608856028402042
Validation loss: 2.562024909847581

Epoch: 241| Step: 0
Training loss: 1.7915281271785273
Validation loss: 2.4928944182026114

Epoch: 5| Step: 1
Training loss: 1.118625915295078
Validation loss: 2.5043285606869734

Epoch: 5| Step: 2
Training loss: 0.6805907419303671
Validation loss: 2.5452509033293444

Epoch: 5| Step: 3
Training loss: 0.7259706116710303
Validation loss: 2.466703246517702

Epoch: 5| Step: 4
Training loss: 1.13986734806391
Validation loss: 2.4763560685406265

Epoch: 5| Step: 5
Training loss: 1.1425540758520065
Validation loss: 2.481824281216377

Epoch: 5| Step: 6
Training loss: 0.7781909179342827
Validation loss: 2.4721415738876615

Epoch: 5| Step: 7
Training loss: 0.9142382852139145
Validation loss: 2.5232329979575736

Epoch: 5| Step: 8
Training loss: 0.8574516273845676
Validation loss: 2.500263565793097

Epoch: 5| Step: 9
Training loss: 0.933131083361961
Validation loss: 2.5518893687179816

Epoch: 5| Step: 10
Training loss: 0.9367880979293333
Validation loss: 2.517948286190551

Epoch: 5| Step: 11
Training loss: 0.36630801122258566
Validation loss: 2.5311247005768602

Epoch: 242| Step: 0
Training loss: 1.0091929481185882
Validation loss: 2.5064912625196087

Epoch: 5| Step: 1
Training loss: 0.9569497832832348
Validation loss: 2.53288784530812

Epoch: 5| Step: 2
Training loss: 0.6189570109548944
Validation loss: 2.5151335747640595

Epoch: 5| Step: 3
Training loss: 0.9690264953301773
Validation loss: 2.517161222100113

Epoch: 5| Step: 4
Training loss: 1.1111583077155558
Validation loss: 2.544955880129916

Epoch: 5| Step: 5
Training loss: 1.1527632644740629
Validation loss: 2.4813028530125716

Epoch: 5| Step: 6
Training loss: 0.9923990880077896
Validation loss: 2.551804376783907

Epoch: 5| Step: 7
Training loss: 0.9499897278682095
Validation loss: 2.5228959123391475

Epoch: 5| Step: 8
Training loss: 1.6211439010032422
Validation loss: 2.4937872938842784

Epoch: 5| Step: 9
Training loss: 0.6858164808706535
Validation loss: 2.5428621979797645

Epoch: 5| Step: 10
Training loss: 0.7106784725956089
Validation loss: 2.5652231695516066

Epoch: 5| Step: 11
Training loss: 0.654710507955925
Validation loss: 2.531797420506241

Epoch: 243| Step: 0
Training loss: 1.2172508801080826
Validation loss: 2.5449663550158355

Epoch: 5| Step: 1
Training loss: 0.7394531072665946
Validation loss: 2.5243971646380974

Epoch: 5| Step: 2
Training loss: 1.6016022467914717
Validation loss: 2.5371714705028094

Epoch: 5| Step: 3
Training loss: 0.8964102388199788
Validation loss: 2.4951290043241867

Epoch: 5| Step: 4
Training loss: 1.2278483751453626
Validation loss: 2.4978165350075288

Epoch: 5| Step: 5
Training loss: 0.7992138292864044
Validation loss: 2.499243633770044

Epoch: 5| Step: 6
Training loss: 0.9951435418799202
Validation loss: 2.51656735384271

Epoch: 5| Step: 7
Training loss: 0.8552467720106861
Validation loss: 2.481051050757213

Epoch: 5| Step: 8
Training loss: 0.8117300199840601
Validation loss: 2.5069619238629492

Epoch: 5| Step: 9
Training loss: 0.8893408971321392
Validation loss: 2.5935706685588866

Epoch: 5| Step: 10
Training loss: 1.2401210943436811
Validation loss: 2.4522838041171773

Epoch: 5| Step: 11
Training loss: 0.4751630152001512
Validation loss: 2.467600800433838

Epoch: 244| Step: 0
Training loss: 0.7641653822455087
Validation loss: 2.4915549114186213

Epoch: 5| Step: 1
Training loss: 0.8832894783709702
Validation loss: 2.5187472185666966

Epoch: 5| Step: 2
Training loss: 0.7825659540674608
Validation loss: 2.490393103234431

Epoch: 5| Step: 3
Training loss: 1.0399545841204225
Validation loss: 2.494264970476343

Epoch: 5| Step: 4
Training loss: 1.2118984224476805
Validation loss: 2.52776967095087

Epoch: 5| Step: 5
Training loss: 1.109079832111962
Validation loss: 2.5743374563197565

Epoch: 5| Step: 6
Training loss: 0.89255361711174
Validation loss: 2.5501983895762517

Epoch: 5| Step: 7
Training loss: 0.8146049303149587
Validation loss: 2.4884720094900263

Epoch: 5| Step: 8
Training loss: 1.0835029151430158
Validation loss: 2.477767689197422

Epoch: 5| Step: 9
Training loss: 1.6679110014520104
Validation loss: 2.4836331385468693

Epoch: 5| Step: 10
Training loss: 1.2032955098393885
Validation loss: 2.565925086604686

Epoch: 5| Step: 11
Training loss: 0.5821253041304895
Validation loss: 2.497842895196882

Epoch: 245| Step: 0
Training loss: 0.7856445691835953
Validation loss: 2.540491854035901

Epoch: 5| Step: 1
Training loss: 1.048483395886597
Validation loss: 2.4990443469424113

Epoch: 5| Step: 2
Training loss: 0.8058927084407734
Validation loss: 2.546261742835854

Epoch: 5| Step: 3
Training loss: 1.1163387142012606
Validation loss: 2.491457326945029

Epoch: 5| Step: 4
Training loss: 1.4896651914641466
Validation loss: 2.531836873375362

Epoch: 5| Step: 5
Training loss: 1.1829831905992652
Validation loss: 2.5331860347848756

Epoch: 5| Step: 6
Training loss: 0.9745346071235309
Validation loss: 2.5189239164247605

Epoch: 5| Step: 7
Training loss: 0.8900956036085295
Validation loss: 2.567147703785229

Epoch: 5| Step: 8
Training loss: 0.9095663033319852
Validation loss: 2.494697685834149

Epoch: 5| Step: 9
Training loss: 0.989473069054358
Validation loss: 2.4669895333479253

Epoch: 5| Step: 10
Training loss: 1.2661883666242062
Validation loss: 2.5328317927402937

Epoch: 5| Step: 11
Training loss: 0.7913508328977716
Validation loss: 2.447966811836618

Epoch: 246| Step: 0
Training loss: 0.9438391308663404
Validation loss: 2.5127184012210035

Epoch: 5| Step: 1
Training loss: 1.0490382603812762
Validation loss: 2.5539788440536597

Epoch: 5| Step: 2
Training loss: 0.6787039777000957
Validation loss: 2.529110078529473

Epoch: 5| Step: 3
Training loss: 1.7927999313097442
Validation loss: 2.4989707775264605

Epoch: 5| Step: 4
Training loss: 0.9717643969239496
Validation loss: 2.4730097380919567

Epoch: 5| Step: 5
Training loss: 1.0745493986863912
Validation loss: 2.445697514425456

Epoch: 5| Step: 6
Training loss: 0.7996354628548233
Validation loss: 2.468663298617538

Epoch: 5| Step: 7
Training loss: 1.1539826199331813
Validation loss: 2.4763719423229715

Epoch: 5| Step: 8
Training loss: 1.1169802066582672
Validation loss: 2.5173687508711957

Epoch: 5| Step: 9
Training loss: 0.8991999169307209
Validation loss: 2.535454207957128

Epoch: 5| Step: 10
Training loss: 0.7788580708348262
Validation loss: 2.5353780805169115

Epoch: 5| Step: 11
Training loss: 0.9586738036910912
Validation loss: 2.4730667448473276

Epoch: 247| Step: 0
Training loss: 1.006678986179261
Validation loss: 2.530128913618172

Epoch: 5| Step: 1
Training loss: 1.03233546149043
Validation loss: 2.479163539841761

Epoch: 5| Step: 2
Training loss: 0.8207921397011266
Validation loss: 2.5142853567965107

Epoch: 5| Step: 3
Training loss: 0.9357726396109439
Validation loss: 2.5019594500638176

Epoch: 5| Step: 4
Training loss: 0.9009919382532753
Validation loss: 2.5350174358904427

Epoch: 5| Step: 5
Training loss: 0.8683662307887329
Validation loss: 2.572520848508876

Epoch: 5| Step: 6
Training loss: 1.5387571390142862
Validation loss: 2.499357464792347

Epoch: 5| Step: 7
Training loss: 0.871395315478229
Validation loss: 2.4645015158552823

Epoch: 5| Step: 8
Training loss: 1.1872261635111907
Validation loss: 2.537833443548863

Epoch: 5| Step: 9
Training loss: 0.7126248216881401
Validation loss: 2.505970104820622

Epoch: 5| Step: 10
Training loss: 0.8173559040849744
Validation loss: 2.463408236018666

Epoch: 5| Step: 11
Training loss: 0.559391892034263
Validation loss: 2.4402150902765425

Epoch: 248| Step: 0
Training loss: 0.7317325043510703
Validation loss: 2.512018865094599

Epoch: 5| Step: 1
Training loss: 0.6569930365990327
Validation loss: 2.459476057187465

Epoch: 5| Step: 2
Training loss: 0.8832306673259354
Validation loss: 2.555512978336152

Epoch: 5| Step: 3
Training loss: 0.7803047565386118
Validation loss: 2.521307565019003

Epoch: 5| Step: 4
Training loss: 1.0754041754731103
Validation loss: 2.469855397057938

Epoch: 5| Step: 5
Training loss: 1.0746298818181186
Validation loss: 2.469520730214741

Epoch: 5| Step: 6
Training loss: 1.10642559576017
Validation loss: 2.4573450054952106

Epoch: 5| Step: 7
Training loss: 1.839308351015002
Validation loss: 2.53664035783685

Epoch: 5| Step: 8
Training loss: 0.6931872946811379
Validation loss: 2.525218252626157

Epoch: 5| Step: 9
Training loss: 0.691369459822132
Validation loss: 2.4731828752503238

Epoch: 5| Step: 10
Training loss: 0.8373157156130595
Validation loss: 2.562870318706334

Epoch: 5| Step: 11
Training loss: 0.6300240764861368
Validation loss: 2.4892688889155408

Epoch: 249| Step: 0
Training loss: 1.0423856097979551
Validation loss: 2.512418790789054

Epoch: 5| Step: 1
Training loss: 1.1988897213939345
Validation loss: 2.510573011624029

Epoch: 5| Step: 2
Training loss: 0.5899901303177022
Validation loss: 2.533559895149175

Epoch: 5| Step: 3
Training loss: 0.5927648653670629
Validation loss: 2.6056840455924752

Epoch: 5| Step: 4
Training loss: 1.1728898803651657
Validation loss: 2.453997983111548

Epoch: 5| Step: 5
Training loss: 0.7882412706563843
Validation loss: 2.55428144161814

Epoch: 5| Step: 6
Training loss: 1.7296915827895087
Validation loss: 2.543668800014014

Epoch: 5| Step: 7
Training loss: 0.6932830338694793
Validation loss: 2.4888150507422906

Epoch: 5| Step: 8
Training loss: 1.11477571532452
Validation loss: 2.5119499349320265

Epoch: 5| Step: 9
Training loss: 1.0102229899510597
Validation loss: 2.49126668239877

Epoch: 5| Step: 10
Training loss: 0.746619314057436
Validation loss: 2.47386315949059

Epoch: 5| Step: 11
Training loss: 0.2835855729786911
Validation loss: 2.478669506734001

Epoch: 250| Step: 0
Training loss: 0.9698483178418502
Validation loss: 2.537497913817001

Epoch: 5| Step: 1
Training loss: 0.49194896306710734
Validation loss: 2.5269157680129157

Epoch: 5| Step: 2
Training loss: 0.9469841293044355
Validation loss: 2.544580307369412

Epoch: 5| Step: 3
Training loss: 1.055192106121548
Validation loss: 2.5267505725950405

Epoch: 5| Step: 4
Training loss: 0.9176496559866161
Validation loss: 2.471956211207638

Epoch: 5| Step: 5
Training loss: 1.5497163820738826
Validation loss: 2.480709931270122

Epoch: 5| Step: 6
Training loss: 0.9175636533957683
Validation loss: 2.566450078968352

Epoch: 5| Step: 7
Training loss: 0.9689051288560724
Validation loss: 2.514450983980247

Epoch: 5| Step: 8
Training loss: 1.3083944140388204
Validation loss: 2.5263950644715827

Epoch: 5| Step: 9
Training loss: 0.7434617197101115
Validation loss: 2.5563813484352695

Epoch: 5| Step: 10
Training loss: 0.7721458207062595
Validation loss: 2.533278690368919

Epoch: 5| Step: 11
Training loss: 0.9741840542975665
Validation loss: 2.4763389911736744

Epoch: 251| Step: 0
Training loss: 0.8119961570216601
Validation loss: 2.506118907655129

Epoch: 5| Step: 1
Training loss: 0.5568919367414212
Validation loss: 2.5386472470055987

Epoch: 5| Step: 2
Training loss: 0.9722760541332791
Validation loss: 2.520818425888456

Epoch: 5| Step: 3
Training loss: 1.5148040278372894
Validation loss: 2.5435743221257523

Epoch: 5| Step: 4
Training loss: 0.8713342309021456
Validation loss: 2.546008861835976

Epoch: 5| Step: 5
Training loss: 0.9799369798560726
Validation loss: 2.5252302039681935

Epoch: 5| Step: 6
Training loss: 1.128950177562309
Validation loss: 2.5528247158620445

Epoch: 5| Step: 7
Training loss: 0.7562799195605416
Validation loss: 2.537083939641875

Epoch: 5| Step: 8
Training loss: 0.8059414842558138
Validation loss: 2.507595417296532

Epoch: 5| Step: 9
Training loss: 1.1808065197542383
Validation loss: 2.5918905992960677

Epoch: 5| Step: 10
Training loss: 0.6928610501895501
Validation loss: 2.521541077724583

Epoch: 5| Step: 11
Training loss: 0.9361829725548602
Validation loss: 2.52601056948263

Epoch: 252| Step: 0
Training loss: 0.8566408880105508
Validation loss: 2.5019107589688354

Epoch: 5| Step: 1
Training loss: 0.9453388872483386
Validation loss: 2.541078019897135

Epoch: 5| Step: 2
Training loss: 1.1655894767523147
Validation loss: 2.5866207169129374

Epoch: 5| Step: 3
Training loss: 1.612016010839117
Validation loss: 2.555318853541375

Epoch: 5| Step: 4
Training loss: 0.7523144138911122
Validation loss: 2.4960917839476355

Epoch: 5| Step: 5
Training loss: 0.8509109524309697
Validation loss: 2.6035780807371887

Epoch: 5| Step: 6
Training loss: 0.9540715754627411
Validation loss: 2.5597905046455147

Epoch: 5| Step: 7
Training loss: 0.9309222572720413
Validation loss: 2.5401181926474323

Epoch: 5| Step: 8
Training loss: 0.6680030590861054
Validation loss: 2.446830132317886

Epoch: 5| Step: 9
Training loss: 0.8576960027693401
Validation loss: 2.4812241292672965

Epoch: 5| Step: 10
Training loss: 1.0984319477836317
Validation loss: 2.5016177347452246

Epoch: 5| Step: 11
Training loss: 0.6945383283943116
Validation loss: 2.4841904361713354

Epoch: 253| Step: 0
Training loss: 0.754539500507583
Validation loss: 2.5134746925694262

Epoch: 5| Step: 1
Training loss: 1.0942869230912535
Validation loss: 2.5272638621766275

Epoch: 5| Step: 2
Training loss: 1.091334919110612
Validation loss: 2.5470716833452154

Epoch: 5| Step: 3
Training loss: 1.5689395957148353
Validation loss: 2.5968575686264903

Epoch: 5| Step: 4
Training loss: 0.7922595380724735
Validation loss: 2.541878817777172

Epoch: 5| Step: 5
Training loss: 1.1434557030608425
Validation loss: 2.5310811586936364

Epoch: 5| Step: 6
Training loss: 1.026374737015824
Validation loss: 2.5336425211938276

Epoch: 5| Step: 7
Training loss: 0.7117031292504449
Validation loss: 2.556468774252311

Epoch: 5| Step: 8
Training loss: 0.8738360156068362
Validation loss: 2.5019009952241342

Epoch: 5| Step: 9
Training loss: 0.9024010181832149
Validation loss: 2.5745978011211315

Epoch: 5| Step: 10
Training loss: 0.8620511089317154
Validation loss: 2.563109794415945

Epoch: 5| Step: 11
Training loss: 0.31775066479359015
Validation loss: 2.5517258542951797

Epoch: 254| Step: 0
Training loss: 1.4230179437402704
Validation loss: 2.520017335512944

Epoch: 5| Step: 1
Training loss: 1.0989406035862772
Validation loss: 2.5033793973769347

Epoch: 5| Step: 2
Training loss: 0.9152471250849952
Validation loss: 2.5391279945729592

Epoch: 5| Step: 3
Training loss: 0.5646872381432437
Validation loss: 2.5049729795134414

Epoch: 5| Step: 4
Training loss: 0.865502516140688
Validation loss: 2.513718777258257

Epoch: 5| Step: 5
Training loss: 0.8086169695630132
Validation loss: 2.5731072580477776

Epoch: 5| Step: 6
Training loss: 0.7881640616530037
Validation loss: 2.489114538982984

Epoch: 5| Step: 7
Training loss: 1.0952544628227405
Validation loss: 2.5404877306120044

Epoch: 5| Step: 8
Training loss: 1.2248633697764237
Validation loss: 2.453705433495696

Epoch: 5| Step: 9
Training loss: 0.6592489474609675
Validation loss: 2.4996169492202718

Epoch: 5| Step: 10
Training loss: 0.9145528342187816
Validation loss: 2.4745002889136485

Epoch: 5| Step: 11
Training loss: 1.252773403015355
Validation loss: 2.5232919192369585

Epoch: 255| Step: 0
Training loss: 0.7919895910556816
Validation loss: 2.5216947310697755

Epoch: 5| Step: 1
Training loss: 0.8580282582695838
Validation loss: 2.520242457590168

Epoch: 5| Step: 2
Training loss: 0.4534841462479662
Validation loss: 2.504762305818141

Epoch: 5| Step: 3
Training loss: 1.1605974379611623
Validation loss: 2.521497951464124

Epoch: 5| Step: 4
Training loss: 0.845541324070327
Validation loss: 2.5251937734417393

Epoch: 5| Step: 5
Training loss: 1.0872168380581462
Validation loss: 2.4189012236229064

Epoch: 5| Step: 6
Training loss: 1.5204676706727556
Validation loss: 2.468071393612336

Epoch: 5| Step: 7
Training loss: 0.7155584712525246
Validation loss: 2.5222568052768923

Epoch: 5| Step: 8
Training loss: 0.834519654496798
Validation loss: 2.495722263971521

Epoch: 5| Step: 9
Training loss: 0.9206646231044636
Validation loss: 2.5078005924120412

Epoch: 5| Step: 10
Training loss: 1.1211879571018173
Validation loss: 2.575563969779631

Epoch: 5| Step: 11
Training loss: 1.297481946360209
Validation loss: 2.5355376518511563

Epoch: 256| Step: 0
Training loss: 1.0788924208741584
Validation loss: 2.4821878598548435

Epoch: 5| Step: 1
Training loss: 1.1140520606280808
Validation loss: 2.5673148251529394

Epoch: 5| Step: 2
Training loss: 0.758603970648353
Validation loss: 2.4953096359099542

Epoch: 5| Step: 3
Training loss: 0.9840643861957885
Validation loss: 2.6104540278528274

Epoch: 5| Step: 4
Training loss: 0.9660942838477015
Validation loss: 2.5033240511802988

Epoch: 5| Step: 5
Training loss: 1.5012839703047582
Validation loss: 2.5052475493303348

Epoch: 5| Step: 6
Training loss: 0.5830785047142104
Validation loss: 2.5524838788491437

Epoch: 5| Step: 7
Training loss: 0.6615220337079372
Validation loss: 2.5128964460880603

Epoch: 5| Step: 8
Training loss: 0.8219771796699485
Validation loss: 2.5907628119748014

Epoch: 5| Step: 9
Training loss: 0.7185900136938006
Validation loss: 2.600056136729581

Epoch: 5| Step: 10
Training loss: 0.7989080337811885
Validation loss: 2.569554720622853

Epoch: 5| Step: 11
Training loss: 1.4765654064331515
Validation loss: 2.5074234816215295

Epoch: 257| Step: 0
Training loss: 0.7378033095114178
Validation loss: 2.573024511329375

Epoch: 5| Step: 1
Training loss: 0.8950293207959914
Validation loss: 2.4869084506274994

Epoch: 5| Step: 2
Training loss: 0.6102380509681538
Validation loss: 2.506930270350134

Epoch: 5| Step: 3
Training loss: 0.5211011357048542
Validation loss: 2.557143827983254

Epoch: 5| Step: 4
Training loss: 0.8073182665636733
Validation loss: 2.537395348606721

Epoch: 5| Step: 5
Training loss: 0.6608506111766191
Validation loss: 2.5104843040841254

Epoch: 5| Step: 6
Training loss: 1.2862827268687305
Validation loss: 2.505165037599217

Epoch: 5| Step: 7
Training loss: 1.0824631472827237
Validation loss: 2.570220072127002

Epoch: 5| Step: 8
Training loss: 1.0498384692057419
Validation loss: 2.532768871112813

Epoch: 5| Step: 9
Training loss: 1.5018678797228837
Validation loss: 2.532292547713555

Epoch: 5| Step: 10
Training loss: 0.8308289128195177
Validation loss: 2.5087325011921138

Epoch: 5| Step: 11
Training loss: 1.4777312320813953
Validation loss: 2.538392824722754

Epoch: 258| Step: 0
Training loss: 1.290083278732803
Validation loss: 2.5298167554801947

Epoch: 5| Step: 1
Training loss: 0.6354048107687934
Validation loss: 2.522360127839786

Epoch: 5| Step: 2
Training loss: 1.154210431110401
Validation loss: 2.611318766563611

Epoch: 5| Step: 3
Training loss: 0.8495008026554836
Validation loss: 2.5537169359767624

Epoch: 5| Step: 4
Training loss: 0.7807831704614399
Validation loss: 2.5427667837419463

Epoch: 5| Step: 5
Training loss: 1.522348180758749
Validation loss: 2.567474510632174

Epoch: 5| Step: 6
Training loss: 0.5357152706091773
Validation loss: 2.4697469114906028

Epoch: 5| Step: 7
Training loss: 0.6653667208543299
Validation loss: 2.499502160253454

Epoch: 5| Step: 8
Training loss: 1.1027184231530316
Validation loss: 2.5117972852611596

Epoch: 5| Step: 9
Training loss: 0.9803482224750694
Validation loss: 2.4670397230444103

Epoch: 5| Step: 10
Training loss: 0.5945726016848711
Validation loss: 2.5030994811644356

Epoch: 5| Step: 11
Training loss: 0.5759247071888834
Validation loss: 2.5201124560844304

Epoch: 259| Step: 0
Training loss: 0.5803889203017676
Validation loss: 2.489797632153178

Epoch: 5| Step: 1
Training loss: 1.1930389723379584
Validation loss: 2.5511835588148615

Epoch: 5| Step: 2
Training loss: 0.8260762765824721
Validation loss: 2.589147590216606

Epoch: 5| Step: 3
Training loss: 0.6256830774230399
Validation loss: 2.5343348931503398

Epoch: 5| Step: 4
Training loss: 0.7639244813044621
Validation loss: 2.428583231514611

Epoch: 5| Step: 5
Training loss: 1.7797975474320025
Validation loss: 2.481537295891915

Epoch: 5| Step: 6
Training loss: 0.9211513459217795
Validation loss: 2.5334156763869906

Epoch: 5| Step: 7
Training loss: 0.640523437264754
Validation loss: 2.5026162405579537

Epoch: 5| Step: 8
Training loss: 1.0614265180068057
Validation loss: 2.5103330136576973

Epoch: 5| Step: 9
Training loss: 0.83041676513804
Validation loss: 2.5246322822820226

Epoch: 5| Step: 10
Training loss: 0.6309963585435651
Validation loss: 2.511489707426984

Epoch: 5| Step: 11
Training loss: 0.9748750068555965
Validation loss: 2.504401877512662

Epoch: 260| Step: 0
Training loss: 1.0456620776528018
Validation loss: 2.458777405075893

Epoch: 5| Step: 1
Training loss: 0.9690252036231077
Validation loss: 2.562284130990307

Epoch: 5| Step: 2
Training loss: 0.8854020547596105
Validation loss: 2.4980561766005134

Epoch: 5| Step: 3
Training loss: 1.2809441829524746
Validation loss: 2.504193996136441

Epoch: 5| Step: 4
Training loss: 0.7643053788226064
Validation loss: 2.5022093110420056

Epoch: 5| Step: 5
Training loss: 0.7592921804468822
Validation loss: 2.4947146215999005

Epoch: 5| Step: 6
Training loss: 1.4221257418368787
Validation loss: 2.528382337037044

Epoch: 5| Step: 7
Training loss: 0.6276216834276401
Validation loss: 2.573732626382204

Epoch: 5| Step: 8
Training loss: 0.7718859436247788
Validation loss: 2.4396868172080213

Epoch: 5| Step: 9
Training loss: 0.4999348180722544
Validation loss: 2.4943483047630792

Epoch: 5| Step: 10
Training loss: 0.777268986005971
Validation loss: 2.5216111403201484

Epoch: 5| Step: 11
Training loss: 1.525429855799538
Validation loss: 2.504428176321673

Epoch: 261| Step: 0
Training loss: 1.3651802368781192
Validation loss: 2.488936537089491

Epoch: 5| Step: 1
Training loss: 1.040095396710084
Validation loss: 2.435675361953813

Epoch: 5| Step: 2
Training loss: 0.748179849702948
Validation loss: 2.573120002330948

Epoch: 5| Step: 3
Training loss: 0.7701299826410206
Validation loss: 2.428378522247809

Epoch: 5| Step: 4
Training loss: 1.0997346362900655
Validation loss: 2.5296562145765518

Epoch: 5| Step: 5
Training loss: 0.67940910162524
Validation loss: 2.4699933425978338

Epoch: 5| Step: 6
Training loss: 1.2023175985901724
Validation loss: 2.5231460505336503

Epoch: 5| Step: 7
Training loss: 0.7954609985213666
Validation loss: 2.452594586349141

Epoch: 5| Step: 8
Training loss: 0.9181568358882872
Validation loss: 2.4684696883399155

Epoch: 5| Step: 9
Training loss: 1.1284739580711642
Validation loss: 2.425008489980616

Epoch: 5| Step: 10
Training loss: 0.6606952340461218
Validation loss: 2.4990105777085128

Epoch: 5| Step: 11
Training loss: 0.5282900761044996
Validation loss: 2.5281529926814046

Epoch: 262| Step: 0
Training loss: 0.6000222887429237
Validation loss: 2.5224528305783944

Epoch: 5| Step: 1
Training loss: 1.000489353609418
Validation loss: 2.5221169976051097

Epoch: 5| Step: 2
Training loss: 0.733272983675943
Validation loss: 2.4861602446841036

Epoch: 5| Step: 3
Training loss: 0.78159523011883
Validation loss: 2.5620594925349454

Epoch: 5| Step: 4
Training loss: 0.7011242056026165
Validation loss: 2.476571328742078

Epoch: 5| Step: 5
Training loss: 1.0546969378013786
Validation loss: 2.5065344765569413

Epoch: 5| Step: 6
Training loss: 0.9934721912279916
Validation loss: 2.497496595262632

Epoch: 5| Step: 7
Training loss: 0.8865840658335494
Validation loss: 2.495940755454569

Epoch: 5| Step: 8
Training loss: 0.752563664667581
Validation loss: 2.5057991597410383

Epoch: 5| Step: 9
Training loss: 0.963336029103961
Validation loss: 2.487494539449759

Epoch: 5| Step: 10
Training loss: 1.6727792308911846
Validation loss: 2.578210255147635

Epoch: 5| Step: 11
Training loss: 0.4412887045389557
Validation loss: 2.5546382078806893

Epoch: 263| Step: 0
Training loss: 1.0743755434222397
Validation loss: 2.501068876172224

Epoch: 5| Step: 1
Training loss: 0.8402547850672617
Validation loss: 2.4709350517289446

Epoch: 5| Step: 2
Training loss: 1.599319450364806
Validation loss: 2.545687872721117

Epoch: 5| Step: 3
Training loss: 0.6596734352365334
Validation loss: 2.5719046835501587

Epoch: 5| Step: 4
Training loss: 0.6869131531328392
Validation loss: 2.575952948155595

Epoch: 5| Step: 5
Training loss: 1.0132858923318206
Validation loss: 2.5296019479392062

Epoch: 5| Step: 6
Training loss: 0.9513018948088107
Validation loss: 2.5431560871208294

Epoch: 5| Step: 7
Training loss: 0.6060492163413339
Validation loss: 2.5842431694027335

Epoch: 5| Step: 8
Training loss: 0.6763128273665867
Validation loss: 2.569963808380034

Epoch: 5| Step: 9
Training loss: 1.1175223428937608
Validation loss: 2.556169595207773

Epoch: 5| Step: 10
Training loss: 0.7025563377651056
Validation loss: 2.5893189525193443

Epoch: 5| Step: 11
Training loss: 0.7244499421869955
Validation loss: 2.6052399305593124

Epoch: 264| Step: 0
Training loss: 0.8621786679973135
Validation loss: 2.6021208216519756

Epoch: 5| Step: 1
Training loss: 0.8760396026756354
Validation loss: 2.5852190808011755

Epoch: 5| Step: 2
Training loss: 0.6705156369729206
Validation loss: 2.568331367523692

Epoch: 5| Step: 3
Training loss: 0.8872886540389451
Validation loss: 2.5608573471227802

Epoch: 5| Step: 4
Training loss: 1.0220529057270482
Validation loss: 2.5501159883124913

Epoch: 5| Step: 5
Training loss: 0.9782343172648564
Validation loss: 2.520615057256832

Epoch: 5| Step: 6
Training loss: 0.9291847215845577
Validation loss: 2.5683694759503872

Epoch: 5| Step: 7
Training loss: 1.417923603442578
Validation loss: 2.6032923826645082

Epoch: 5| Step: 8
Training loss: 0.7323125732244729
Validation loss: 2.535140569919554

Epoch: 5| Step: 9
Training loss: 0.7260810323265962
Validation loss: 2.493603845008539

Epoch: 5| Step: 10
Training loss: 0.7847343563915871
Validation loss: 2.4950013812538456

Epoch: 5| Step: 11
Training loss: 1.4543491252700735
Validation loss: 2.550842210431642

Epoch: 265| Step: 0
Training loss: 0.9690033673620618
Validation loss: 2.5490613263119575

Epoch: 5| Step: 1
Training loss: 0.7313643895854506
Validation loss: 2.5040759794303344

Epoch: 5| Step: 2
Training loss: 0.8679577267939976
Validation loss: 2.6016461012412546

Epoch: 5| Step: 3
Training loss: 0.5608655442439092
Validation loss: 2.5359508540690543

Epoch: 5| Step: 4
Training loss: 0.8765558307142397
Validation loss: 2.507063507224426

Epoch: 5| Step: 5
Training loss: 0.7816743079939182
Validation loss: 2.549714278594689

Epoch: 5| Step: 6
Training loss: 0.5581587051005281
Validation loss: 2.4717329831646686

Epoch: 5| Step: 7
Training loss: 0.9791712287363682
Validation loss: 2.535047300531984

Epoch: 5| Step: 8
Training loss: 1.6303948568901274
Validation loss: 2.5570052343238374

Epoch: 5| Step: 9
Training loss: 0.7070041040088291
Validation loss: 2.5742169478105748

Epoch: 5| Step: 10
Training loss: 1.161461811602164
Validation loss: 2.4743650777973865

Epoch: 5| Step: 11
Training loss: 0.812437898756819
Validation loss: 2.4904373006480185

Epoch: 266| Step: 0
Training loss: 0.9572550297901616
Validation loss: 2.5328414058741995

Epoch: 5| Step: 1
Training loss: 0.576048213813462
Validation loss: 2.614945984319594

Epoch: 5| Step: 2
Training loss: 0.7777208343354077
Validation loss: 2.5214635570877237

Epoch: 5| Step: 3
Training loss: 0.6952887327439745
Validation loss: 2.5013224322742182

Epoch: 5| Step: 4
Training loss: 0.8116370533574422
Validation loss: 2.5200264338148926

Epoch: 5| Step: 5
Training loss: 0.7928823790467717
Validation loss: 2.606932317182456

Epoch: 5| Step: 6
Training loss: 1.150783037959909
Validation loss: 2.5253984609011746

Epoch: 5| Step: 7
Training loss: 0.5898427900091784
Validation loss: 2.538825379083237

Epoch: 5| Step: 8
Training loss: 0.7261695209237243
Validation loss: 2.6380316886917003

Epoch: 5| Step: 9
Training loss: 1.1127202812448052
Validation loss: 2.537630320868433

Epoch: 5| Step: 10
Training loss: 1.4523075224414388
Validation loss: 2.5648535178373533

Epoch: 5| Step: 11
Training loss: 0.3881433238128415
Validation loss: 2.542790583918913

Epoch: 267| Step: 0
Training loss: 0.7061828243750061
Validation loss: 2.5110007901811437

Epoch: 5| Step: 1
Training loss: 0.9878826317514702
Validation loss: 2.5174653092374095

Epoch: 5| Step: 2
Training loss: 0.8762146148937796
Validation loss: 2.57605774004578

Epoch: 5| Step: 3
Training loss: 0.4739854581288263
Validation loss: 2.5330876481190066

Epoch: 5| Step: 4
Training loss: 1.0703391747039557
Validation loss: 2.5481100149917153

Epoch: 5| Step: 5
Training loss: 1.4728033260494389
Validation loss: 2.4979957255201417

Epoch: 5| Step: 6
Training loss: 0.7316706759691276
Validation loss: 2.5258630368235475

Epoch: 5| Step: 7
Training loss: 0.8127909652866768
Validation loss: 2.5275635149616265

Epoch: 5| Step: 8
Training loss: 0.7446158185965631
Validation loss: 2.519432456275301

Epoch: 5| Step: 9
Training loss: 0.6539133570568572
Validation loss: 2.568508330499161

Epoch: 5| Step: 10
Training loss: 1.0951959044561723
Validation loss: 2.5532552532586608

Epoch: 5| Step: 11
Training loss: 0.6500916352236032
Validation loss: 2.528250447616002

Epoch: 268| Step: 0
Training loss: 0.7321644241532543
Validation loss: 2.602422467089748

Epoch: 5| Step: 1
Training loss: 0.8764577371208231
Validation loss: 2.5580551085223924

Epoch: 5| Step: 2
Training loss: 0.8637758107062237
Validation loss: 2.6062638129181597

Epoch: 5| Step: 3
Training loss: 1.4144112172801775
Validation loss: 2.513531273637119

Epoch: 5| Step: 4
Training loss: 0.7447999451361696
Validation loss: 2.4628437288857903

Epoch: 5| Step: 5
Training loss: 0.6031778124678673
Validation loss: 2.5355600154059985

Epoch: 5| Step: 6
Training loss: 0.8378032647676436
Validation loss: 2.542557084865881

Epoch: 5| Step: 7
Training loss: 0.8974170030667689
Validation loss: 2.5161174623856986

Epoch: 5| Step: 8
Training loss: 0.7081044940050051
Validation loss: 2.497932202786917

Epoch: 5| Step: 9
Training loss: 1.16584820080526
Validation loss: 2.558796004437902

Epoch: 5| Step: 10
Training loss: 0.7570955483419202
Validation loss: 2.513577158856899

Epoch: 5| Step: 11
Training loss: 0.9992366499859635
Validation loss: 2.547091937040973

Epoch: 269| Step: 0
Training loss: 1.0098025759755713
Validation loss: 2.5394675611519766

Epoch: 5| Step: 1
Training loss: 0.7990414211102208
Validation loss: 2.516778274823432

Epoch: 5| Step: 2
Training loss: 0.9853295436247687
Validation loss: 2.5302153580307505

Epoch: 5| Step: 3
Training loss: 0.7540903607820658
Validation loss: 2.629618483521888

Epoch: 5| Step: 4
Training loss: 0.7154717110453654
Validation loss: 2.5451083931014606

Epoch: 5| Step: 5
Training loss: 0.7275145660987161
Validation loss: 2.51846806768092

Epoch: 5| Step: 6
Training loss: 0.7417226038065846
Validation loss: 2.574324961175443

Epoch: 5| Step: 7
Training loss: 0.8855727263902137
Validation loss: 2.522451465966488

Epoch: 5| Step: 8
Training loss: 1.481509846618868
Validation loss: 2.505602519428575

Epoch: 5| Step: 9
Training loss: 0.9236576818295116
Validation loss: 2.4776414171687318

Epoch: 5| Step: 10
Training loss: 0.662205511895009
Validation loss: 2.4750884570103016

Epoch: 5| Step: 11
Training loss: 1.1602164615714672
Validation loss: 2.4781217309674464

Epoch: 270| Step: 0
Training loss: 0.8716599544451489
Validation loss: 2.5049943350095267

Epoch: 5| Step: 1
Training loss: 1.447375006409772
Validation loss: 2.5270360713186193

Epoch: 5| Step: 2
Training loss: 0.725384403134287
Validation loss: 2.537473672501611

Epoch: 5| Step: 3
Training loss: 1.0489634279179785
Validation loss: 2.4485890391701277

Epoch: 5| Step: 4
Training loss: 0.6781777242740452
Validation loss: 2.5442679348906005

Epoch: 5| Step: 5
Training loss: 0.7324222819009286
Validation loss: 2.5244325461285864

Epoch: 5| Step: 6
Training loss: 0.5250339077035979
Validation loss: 2.555853182080533

Epoch: 5| Step: 7
Training loss: 0.8284558409074739
Validation loss: 2.525512487820298

Epoch: 5| Step: 8
Training loss: 0.9406683788245679
Validation loss: 2.504950953617007

Epoch: 5| Step: 9
Training loss: 0.7727554473610905
Validation loss: 2.5081673328519516

Epoch: 5| Step: 10
Training loss: 1.1871432722247355
Validation loss: 2.5119342622507586

Epoch: 5| Step: 11
Training loss: 0.7678599919934816
Validation loss: 2.5283814255003225

Epoch: 271| Step: 0
Training loss: 0.732759565706785
Validation loss: 2.408284151148164

Epoch: 5| Step: 1
Training loss: 0.7176347455823308
Validation loss: 2.5261184870781155

Epoch: 5| Step: 2
Training loss: 0.9950371018398162
Validation loss: 2.4534082795850587

Epoch: 5| Step: 3
Training loss: 0.6659235065552728
Validation loss: 2.542011559386074

Epoch: 5| Step: 4
Training loss: 0.5935132658985489
Validation loss: 2.5224838698847782

Epoch: 5| Step: 5
Training loss: 1.4723824567786528
Validation loss: 2.50899044588271

Epoch: 5| Step: 6
Training loss: 0.7709598351541794
Validation loss: 2.5336378043711894

Epoch: 5| Step: 7
Training loss: 0.6449123758486385
Validation loss: 2.526119358139562

Epoch: 5| Step: 8
Training loss: 0.9783810277411752
Validation loss: 2.509301287374819

Epoch: 5| Step: 9
Training loss: 1.0244216264094563
Validation loss: 2.4856715947459103

Epoch: 5| Step: 10
Training loss: 1.07912133660474
Validation loss: 2.5060292694544564

Epoch: 5| Step: 11
Training loss: 0.3490359222450495
Validation loss: 2.5231706086418635

Epoch: 272| Step: 0
Training loss: 1.021955567429838
Validation loss: 2.542750714980408

Epoch: 5| Step: 1
Training loss: 0.9045164035429425
Validation loss: 2.5531951791930254

Epoch: 5| Step: 2
Training loss: 0.7086443966027579
Validation loss: 2.489915312229472

Epoch: 5| Step: 3
Training loss: 0.9914835136974328
Validation loss: 2.490713979375289

Epoch: 5| Step: 4
Training loss: 1.510386981891644
Validation loss: 2.4835500107127886

Epoch: 5| Step: 5
Training loss: 0.6681204283426745
Validation loss: 2.533690920070254

Epoch: 5| Step: 6
Training loss: 0.5926622415285503
Validation loss: 2.5237616379047396

Epoch: 5| Step: 7
Training loss: 1.044132740406275
Validation loss: 2.5087566796837772

Epoch: 5| Step: 8
Training loss: 0.8133204059537568
Validation loss: 2.511939415303106

Epoch: 5| Step: 9
Training loss: 0.647184517198262
Validation loss: 2.515144219273451

Epoch: 5| Step: 10
Training loss: 0.64347595752064
Validation loss: 2.532719978056185

Epoch: 5| Step: 11
Training loss: 0.9002558013529934
Validation loss: 2.4770927182515208

Epoch: 273| Step: 0
Training loss: 0.9511569920810903
Validation loss: 2.5764935600877146

Epoch: 5| Step: 1
Training loss: 0.5889351016431681
Validation loss: 2.5904606640103167

Epoch: 5| Step: 2
Training loss: 0.7182651211095912
Validation loss: 2.6245549748131096

Epoch: 5| Step: 3
Training loss: 0.5883674335548362
Validation loss: 2.570932205381452

Epoch: 5| Step: 4
Training loss: 1.0427747110179348
Validation loss: 2.5171879045962466

Epoch: 5| Step: 5
Training loss: 0.6643343649465562
Validation loss: 2.487182066997319

Epoch: 5| Step: 6
Training loss: 0.6519926119777804
Validation loss: 2.5018528350653817

Epoch: 5| Step: 7
Training loss: 0.8075288403678335
Validation loss: 2.547965793234785

Epoch: 5| Step: 8
Training loss: 1.0034066229779788
Validation loss: 2.4705463465226916

Epoch: 5| Step: 9
Training loss: 1.348075602426241
Validation loss: 2.5562092101613105

Epoch: 5| Step: 10
Training loss: 0.8340525900751204
Validation loss: 2.5998941137075664

Epoch: 5| Step: 11
Training loss: 0.7016051927248224
Validation loss: 2.6187060529227555

Epoch: 274| Step: 0
Training loss: 1.1281735375442576
Validation loss: 2.521853151348881

Epoch: 5| Step: 1
Training loss: 0.878430725310375
Validation loss: 2.5345970599017953

Epoch: 5| Step: 2
Training loss: 0.572551720877408
Validation loss: 2.5835195340967894

Epoch: 5| Step: 3
Training loss: 0.5527135892268976
Validation loss: 2.6108961221158307

Epoch: 5| Step: 4
Training loss: 0.8792550984121738
Validation loss: 2.5205541343132367

Epoch: 5| Step: 5
Training loss: 0.747898893933244
Validation loss: 2.504785552934461

Epoch: 5| Step: 6
Training loss: 0.6116486705329321
Validation loss: 2.4801652577480824

Epoch: 5| Step: 7
Training loss: 1.0886233480127554
Validation loss: 2.56697370041726

Epoch: 5| Step: 8
Training loss: 0.6411175113953885
Validation loss: 2.484768818285167

Epoch: 5| Step: 9
Training loss: 1.2836841163703956
Validation loss: 2.552015709792038

Epoch: 5| Step: 10
Training loss: 1.061864326158464
Validation loss: 2.5271584444343933

Epoch: 5| Step: 11
Training loss: 0.9794839115116472
Validation loss: 2.498886861941202

Epoch: 275| Step: 0
Training loss: 1.0271841875329848
Validation loss: 2.5183316216177922

Epoch: 5| Step: 1
Training loss: 0.4491704997811517
Validation loss: 2.548360623374061

Epoch: 5| Step: 2
Training loss: 0.8300872443203116
Validation loss: 2.5556667679162697

Epoch: 5| Step: 3
Training loss: 0.9412178705818589
Validation loss: 2.552830953797108

Epoch: 5| Step: 4
Training loss: 1.5768758532339986
Validation loss: 2.519051912827575

Epoch: 5| Step: 5
Training loss: 1.0124739843723205
Validation loss: 2.5956048729190675

Epoch: 5| Step: 6
Training loss: 1.2194682230232574
Validation loss: 2.5830473062131674

Epoch: 5| Step: 7
Training loss: 0.6671651724802528
Validation loss: 2.552119318390506

Epoch: 5| Step: 8
Training loss: 0.7813779344712626
Validation loss: 2.5570167826254813

Epoch: 5| Step: 9
Training loss: 0.7381859369665936
Validation loss: 2.600867643532343

Epoch: 5| Step: 10
Training loss: 0.8246735678388913
Validation loss: 2.5737241888334523

Epoch: 5| Step: 11
Training loss: 0.5598671543553617
Validation loss: 2.5951397899015576

Epoch: 276| Step: 0
Training loss: 0.8742731345052593
Validation loss: 2.6391203842906874

Epoch: 5| Step: 1
Training loss: 0.9754743082602149
Validation loss: 2.509025430934848

Epoch: 5| Step: 2
Training loss: 0.9707844199327319
Validation loss: 2.592426579054053

Epoch: 5| Step: 3
Training loss: 1.115944978362583
Validation loss: 2.535011749773302

Epoch: 5| Step: 4
Training loss: 0.5477482227364509
Validation loss: 2.4957880659779925

Epoch: 5| Step: 5
Training loss: 0.8154622511157966
Validation loss: 2.4804271364100545

Epoch: 5| Step: 6
Training loss: 0.7443737956308764
Validation loss: 2.5870896622190283

Epoch: 5| Step: 7
Training loss: 0.8297076666441094
Validation loss: 2.5994506145466665

Epoch: 5| Step: 8
Training loss: 0.6268540776527469
Validation loss: 2.5842273085682503

Epoch: 5| Step: 9
Training loss: 0.537340731644202
Validation loss: 2.522345134239508

Epoch: 5| Step: 10
Training loss: 1.3041478028725755
Validation loss: 2.472347684211512

Epoch: 5| Step: 11
Training loss: 0.713915070520799
Validation loss: 2.604533987206905

Epoch: 277| Step: 0
Training loss: 0.5588775394051813
Validation loss: 2.6040531871230397

Epoch: 5| Step: 1
Training loss: 0.8927405478779084
Validation loss: 2.603845486226188

Epoch: 5| Step: 2
Training loss: 0.878951448761846
Validation loss: 2.5864867772783797

Epoch: 5| Step: 3
Training loss: 1.0205347961070743
Validation loss: 2.5704096241450154

Epoch: 5| Step: 4
Training loss: 1.379742506578836
Validation loss: 2.5400923141965333

Epoch: 5| Step: 5
Training loss: 1.3052817264917584
Validation loss: 2.611921396627674

Epoch: 5| Step: 6
Training loss: 0.5960572237795423
Validation loss: 2.573294763673383

Epoch: 5| Step: 7
Training loss: 1.1233165649347305
Validation loss: 2.5477669018148075

Epoch: 5| Step: 8
Training loss: 0.8755859728984838
Validation loss: 2.6129316923921704

Epoch: 5| Step: 9
Training loss: 0.6668352470240186
Validation loss: 2.5382819947014355

Epoch: 5| Step: 10
Training loss: 0.7891407540675013
Validation loss: 2.594451093330504

Epoch: 5| Step: 11
Training loss: 1.0584560177998996
Validation loss: 2.51489104548106

Epoch: 278| Step: 0
Training loss: 0.7245079031171638
Validation loss: 2.544564656081385

Epoch: 5| Step: 1
Training loss: 1.0981570693030067
Validation loss: 2.5295843955146506

Epoch: 5| Step: 2
Training loss: 0.8759216495512877
Validation loss: 2.4809363077198228

Epoch: 5| Step: 3
Training loss: 0.8181107901438525
Validation loss: 2.5360764262311406

Epoch: 5| Step: 4
Training loss: 0.67351250374649
Validation loss: 2.5465170641924764

Epoch: 5| Step: 5
Training loss: 1.4825256874213464
Validation loss: 2.5305136052916435

Epoch: 5| Step: 6
Training loss: 0.6889465675660518
Validation loss: 2.450008575268744

Epoch: 5| Step: 7
Training loss: 0.6976940644579137
Validation loss: 2.5227068462320714

Epoch: 5| Step: 8
Training loss: 0.6532302360990255
Validation loss: 2.5604684266294866

Epoch: 5| Step: 9
Training loss: 0.8271169465070569
Validation loss: 2.5329851278771303

Epoch: 5| Step: 10
Training loss: 0.9586396695232164
Validation loss: 2.6196219627570394

Epoch: 5| Step: 11
Training loss: 0.7678537820191196
Validation loss: 2.5007931841782316

Epoch: 279| Step: 0
Training loss: 0.2857792723990332
Validation loss: 2.5212662866243205

Epoch: 5| Step: 1
Training loss: 0.721137270125596
Validation loss: 2.5531790476649743

Epoch: 5| Step: 2
Training loss: 0.7535920748532837
Validation loss: 2.5052760003376346

Epoch: 5| Step: 3
Training loss: 0.901826355138413
Validation loss: 2.416358528689652

Epoch: 5| Step: 4
Training loss: 0.9092734971701005
Validation loss: 2.4918370852565155

Epoch: 5| Step: 5
Training loss: 0.6691276580213306
Validation loss: 2.5456035673958017

Epoch: 5| Step: 6
Training loss: 0.9425545175301747
Validation loss: 2.5485299979862974

Epoch: 5| Step: 7
Training loss: 0.6312494164643565
Validation loss: 2.5006812677374963

Epoch: 5| Step: 8
Training loss: 0.7770579977396773
Validation loss: 2.5214355211871013

Epoch: 5| Step: 9
Training loss: 0.9083164595573614
Validation loss: 2.504393285715209

Epoch: 5| Step: 10
Training loss: 1.5221044723806934
Validation loss: 2.4848129858053003

Epoch: 5| Step: 11
Training loss: 0.5320427533445161
Validation loss: 2.5292162868863017

Epoch: 280| Step: 0
Training loss: 0.6140189138382106
Validation loss: 2.5290264520213306

Epoch: 5| Step: 1
Training loss: 0.5728220659238692
Validation loss: 2.5282950480468314

Epoch: 5| Step: 2
Training loss: 0.8604924306386971
Validation loss: 2.5937140205676092

Epoch: 5| Step: 3
Training loss: 0.7995921913466035
Validation loss: 2.4970355020880763

Epoch: 5| Step: 4
Training loss: 1.6050578610219612
Validation loss: 2.591827127931215

Epoch: 5| Step: 5
Training loss: 0.6391044341788107
Validation loss: 2.470345822358268

Epoch: 5| Step: 6
Training loss: 0.7638826591545931
Validation loss: 2.534311562342742

Epoch: 5| Step: 7
Training loss: 0.709807913343936
Validation loss: 2.56956464290136

Epoch: 5| Step: 8
Training loss: 0.7339910355651965
Validation loss: 2.5772141302114484

Epoch: 5| Step: 9
Training loss: 0.964053336027293
Validation loss: 2.5143809016353873

Epoch: 5| Step: 10
Training loss: 0.8820078736038137
Validation loss: 2.5672330564766375

Epoch: 5| Step: 11
Training loss: 0.6642003084690304
Validation loss: 2.510727812979229

Epoch: 281| Step: 0
Training loss: 0.7202824551156303
Validation loss: 2.495502654656937

Epoch: 5| Step: 1
Training loss: 0.721143386471528
Validation loss: 2.4962132484514443

Epoch: 5| Step: 2
Training loss: 0.6058343091412032
Validation loss: 2.5391248020451296

Epoch: 5| Step: 3
Training loss: 1.5472164355218694
Validation loss: 2.6033321028805005

Epoch: 5| Step: 4
Training loss: 0.8534092607718496
Validation loss: 2.567822364199211

Epoch: 5| Step: 5
Training loss: 0.6259455680612873
Validation loss: 2.4548585460211196

Epoch: 5| Step: 6
Training loss: 0.8027037083320695
Validation loss: 2.5400701391618448

Epoch: 5| Step: 7
Training loss: 0.749709510178
Validation loss: 2.5942617968529715

Epoch: 5| Step: 8
Training loss: 0.4923061348974715
Validation loss: 2.5703369243817957

Epoch: 5| Step: 9
Training loss: 0.6210929582698742
Validation loss: 2.5928004070059893

Epoch: 5| Step: 10
Training loss: 1.1151916709513614
Validation loss: 2.4829188984054658

Epoch: 5| Step: 11
Training loss: 0.38033614775485314
Validation loss: 2.5405637909670262

Epoch: 282| Step: 0
Training loss: 0.5072246670458033
Validation loss: 2.5757768321826195

Epoch: 5| Step: 1
Training loss: 1.3754726811215994
Validation loss: 2.540985167836634

Epoch: 5| Step: 2
Training loss: 0.9416880205709601
Validation loss: 2.5211750671114963

Epoch: 5| Step: 3
Training loss: 0.7156895704165339
Validation loss: 2.5695655108331144

Epoch: 5| Step: 4
Training loss: 0.40689334912975955
Validation loss: 2.5923866419286203

Epoch: 5| Step: 5
Training loss: 0.6751339629365309
Validation loss: 2.50434188504813

Epoch: 5| Step: 6
Training loss: 0.817564840340981
Validation loss: 2.573460943489321

Epoch: 5| Step: 7
Training loss: 0.9020647550671125
Validation loss: 2.4917114464830266

Epoch: 5| Step: 8
Training loss: 0.6842857563932925
Validation loss: 2.5545524927020935

Epoch: 5| Step: 9
Training loss: 1.028059271476723
Validation loss: 2.5473964407002447

Epoch: 5| Step: 10
Training loss: 0.8531020360517905
Validation loss: 2.5612356586839824

Epoch: 5| Step: 11
Training loss: 1.200965181260488
Validation loss: 2.6061547790257524

Epoch: 283| Step: 0
Training loss: 0.733220633783958
Validation loss: 2.543340438032497

Epoch: 5| Step: 1
Training loss: 0.5819922568553348
Validation loss: 2.490853443861157

Epoch: 5| Step: 2
Training loss: 0.6544927047777537
Validation loss: 2.600961575683719

Epoch: 5| Step: 3
Training loss: 1.1047767657050116
Validation loss: 2.5155252472428082

Epoch: 5| Step: 4
Training loss: 0.8087340523446026
Validation loss: 2.5910573065633526

Epoch: 5| Step: 5
Training loss: 0.7090402376219893
Validation loss: 2.527881205513198

Epoch: 5| Step: 6
Training loss: 1.3031284359673958
Validation loss: 2.534613184274679

Epoch: 5| Step: 7
Training loss: 0.8748876635783195
Validation loss: 2.5354589625403756

Epoch: 5| Step: 8
Training loss: 0.8779937075821751
Validation loss: 2.5621359457980204

Epoch: 5| Step: 9
Training loss: 0.6883187620438732
Validation loss: 2.548110802512421

Epoch: 5| Step: 10
Training loss: 1.1017767515213193
Validation loss: 2.56821423641443

Epoch: 5| Step: 11
Training loss: 0.3760330355949047
Validation loss: 2.5432147108786003

Epoch: 284| Step: 0
Training loss: 0.7350637168903397
Validation loss: 2.4874471726710596

Epoch: 5| Step: 1
Training loss: 1.42784541959795
Validation loss: 2.5222045437318825

Epoch: 5| Step: 2
Training loss: 0.6993104672083202
Validation loss: 2.479903089048796

Epoch: 5| Step: 3
Training loss: 0.41820444609605995
Validation loss: 2.50633202780845

Epoch: 5| Step: 4
Training loss: 0.7051290773700886
Validation loss: 2.4565846492653773

Epoch: 5| Step: 5
Training loss: 0.7239904099271858
Validation loss: 2.563045399085641

Epoch: 5| Step: 6
Training loss: 0.8128251378867282
Validation loss: 2.4643139761040613

Epoch: 5| Step: 7
Training loss: 0.6886069749185849
Validation loss: 2.475753579868339

Epoch: 5| Step: 8
Training loss: 0.7430913541217702
Validation loss: 2.553771637389064

Epoch: 5| Step: 9
Training loss: 1.2212359188833757
Validation loss: 2.5262346659337624

Epoch: 5| Step: 10
Training loss: 0.6356183472006696
Validation loss: 2.524776158781879

Epoch: 5| Step: 11
Training loss: 0.24848254683097365
Validation loss: 2.4851169338032415

Epoch: 285| Step: 0
Training loss: 0.9523888856551722
Validation loss: 2.528397393061561

Epoch: 5| Step: 1
Training loss: 0.6205076175025391
Validation loss: 2.471138370258603

Epoch: 5| Step: 2
Training loss: 0.8105401463976178
Validation loss: 2.492428643369957

Epoch: 5| Step: 3
Training loss: 1.4626595858370934
Validation loss: 2.4983821163754643

Epoch: 5| Step: 4
Training loss: 0.8775890737682762
Validation loss: 2.5161159462806393

Epoch: 5| Step: 5
Training loss: 0.6002131351763041
Validation loss: 2.5668566292643398

Epoch: 5| Step: 6
Training loss: 0.5272877133584356
Validation loss: 2.5027720778413656

Epoch: 5| Step: 7
Training loss: 0.38993194132953324
Validation loss: 2.562621268837689

Epoch: 5| Step: 8
Training loss: 0.5034107463033675
Validation loss: 2.503043374704336

Epoch: 5| Step: 9
Training loss: 0.7782128617652486
Validation loss: 2.5669793853947493

Epoch: 5| Step: 10
Training loss: 0.8475878639586426
Validation loss: 2.5182450316020453

Epoch: 5| Step: 11
Training loss: 0.287962237163877
Validation loss: 2.526540358302273

Epoch: 286| Step: 0
Training loss: 0.3619484808377065
Validation loss: 2.5236804046091503

Epoch: 5| Step: 1
Training loss: 0.5625538005531288
Validation loss: 2.428833520094252

Epoch: 5| Step: 2
Training loss: 1.0244656123454294
Validation loss: 2.5714073825207913

Epoch: 5| Step: 3
Training loss: 0.5742596462504096
Validation loss: 2.5344750577065955

Epoch: 5| Step: 4
Training loss: 0.6383847865872135
Validation loss: 2.572787827317432

Epoch: 5| Step: 5
Training loss: 0.7378549303637023
Validation loss: 2.5334132589470775

Epoch: 5| Step: 6
Training loss: 0.6115001156214981
Validation loss: 2.543232511015211

Epoch: 5| Step: 7
Training loss: 0.9327483239773569
Validation loss: 2.4988020092842462

Epoch: 5| Step: 8
Training loss: 0.5955456885243817
Validation loss: 2.5283369641119733

Epoch: 5| Step: 9
Training loss: 0.5963484973443646
Validation loss: 2.500581526673563

Epoch: 5| Step: 10
Training loss: 1.4821899393452873
Validation loss: 2.4721859107464272

Epoch: 5| Step: 11
Training loss: 0.6377930266918085
Validation loss: 2.5509559022425905

Epoch: 287| Step: 0
Training loss: 0.8104126600805515
Validation loss: 2.5471711600889546

Epoch: 5| Step: 1
Training loss: 0.9269473301143336
Validation loss: 2.4854847051085556

Epoch: 5| Step: 2
Training loss: 1.0236045176964987
Validation loss: 2.492384668600683

Epoch: 5| Step: 3
Training loss: 0.5350324390060165
Validation loss: 2.5136503205342255

Epoch: 5| Step: 4
Training loss: 0.4555765132457531
Validation loss: 2.5601678097754665

Epoch: 5| Step: 5
Training loss: 0.6690788859641901
Validation loss: 2.527275473661471

Epoch: 5| Step: 6
Training loss: 1.537891387745477
Validation loss: 2.5905791169303423

Epoch: 5| Step: 7
Training loss: 0.8313501641867382
Validation loss: 2.549480665529231

Epoch: 5| Step: 8
Training loss: 0.6977520909963157
Validation loss: 2.5687067026664465

Epoch: 5| Step: 9
Training loss: 0.629305150304996
Validation loss: 2.5426256619309995

Epoch: 5| Step: 10
Training loss: 0.7332073424944049
Validation loss: 2.52232778928576

Epoch: 5| Step: 11
Training loss: 0.6830886718779039
Validation loss: 2.5418160614810645

Epoch: 288| Step: 0
Training loss: 0.7257642154727139
Validation loss: 2.5507560483379788

Epoch: 5| Step: 1
Training loss: 0.5213909851345511
Validation loss: 2.5769776112656246

Epoch: 5| Step: 2
Training loss: 0.8296019860288929
Validation loss: 2.499281790008735

Epoch: 5| Step: 3
Training loss: 1.3697548439481904
Validation loss: 2.5508636998729943

Epoch: 5| Step: 4
Training loss: 0.842505137147721
Validation loss: 2.5586191656582975

Epoch: 5| Step: 5
Training loss: 0.9964324674466676
Validation loss: 2.5531159952130187

Epoch: 5| Step: 6
Training loss: 0.7315630544263587
Validation loss: 2.598562593979586

Epoch: 5| Step: 7
Training loss: 0.8143256657164337
Validation loss: 2.501137681225194

Epoch: 5| Step: 8
Training loss: 0.5692796892022345
Validation loss: 2.5111063462280634

Epoch: 5| Step: 9
Training loss: 0.9421213370352314
Validation loss: 2.5239913517650905

Epoch: 5| Step: 10
Training loss: 0.5000856743367726
Validation loss: 2.525094644579358

Epoch: 5| Step: 11
Training loss: 0.5391737228867316
Validation loss: 2.517245345395216

Epoch: 289| Step: 0
Training loss: 0.6098434897052543
Validation loss: 2.5797929416074092

Epoch: 5| Step: 1
Training loss: 0.49719567956915534
Validation loss: 2.5310125357303486

Epoch: 5| Step: 2
Training loss: 0.7063253894166869
Validation loss: 2.5249283110006804

Epoch: 5| Step: 3
Training loss: 0.46614060496660537
Validation loss: 2.611589883235712

Epoch: 5| Step: 4
Training loss: 0.6987771712396047
Validation loss: 2.5313584025840083

Epoch: 5| Step: 5
Training loss: 1.0529350132030033
Validation loss: 2.4626376077282677

Epoch: 5| Step: 6
Training loss: 0.8296608987053176
Validation loss: 2.4994386161879354

Epoch: 5| Step: 7
Training loss: 0.5203259635306035
Validation loss: 2.460846704493426

Epoch: 5| Step: 8
Training loss: 0.7150565909284983
Validation loss: 2.5367439913357885

Epoch: 5| Step: 9
Training loss: 1.3845466042414052
Validation loss: 2.488939606401952

Epoch: 5| Step: 10
Training loss: 0.7781431218989999
Validation loss: 2.5698245859891813

Epoch: 5| Step: 11
Training loss: 0.829403376377722
Validation loss: 2.553827741880154

Epoch: 290| Step: 0
Training loss: 0.5497518619073873
Validation loss: 2.516110497770541

Epoch: 5| Step: 1
Training loss: 0.9830833619764914
Validation loss: 2.5665494200526733

Epoch: 5| Step: 2
Training loss: 0.6158958633106791
Validation loss: 2.545431082726279

Epoch: 5| Step: 3
Training loss: 1.4762414653896367
Validation loss: 2.5744530740463034

Epoch: 5| Step: 4
Training loss: 0.9259329241028986
Validation loss: 2.473455045938662

Epoch: 5| Step: 5
Training loss: 0.7772525753053422
Validation loss: 2.489267516089196

Epoch: 5| Step: 6
Training loss: 0.7868555005045821
Validation loss: 2.5206211029648147

Epoch: 5| Step: 7
Training loss: 0.700799380847198
Validation loss: 2.562160108866292

Epoch: 5| Step: 8
Training loss: 0.6146423640161707
Validation loss: 2.518850872427351

Epoch: 5| Step: 9
Training loss: 0.6883864107019194
Validation loss: 2.502201648670727

Epoch: 5| Step: 10
Training loss: 0.7544971581437757
Validation loss: 2.467079345767765

Epoch: 5| Step: 11
Training loss: 0.6384813216934366
Validation loss: 2.54235056108193

Epoch: 291| Step: 0
Training loss: 0.5304396282848687
Validation loss: 2.5534106669457306

Epoch: 5| Step: 1
Training loss: 0.6454570248198421
Validation loss: 2.414219374842278

Epoch: 5| Step: 2
Training loss: 0.8280263518111429
Validation loss: 2.5106295255323143

Epoch: 5| Step: 3
Training loss: 0.8460730609143086
Validation loss: 2.4743432050118583

Epoch: 5| Step: 4
Training loss: 1.466650740941599
Validation loss: 2.560896022570133

Epoch: 5| Step: 5
Training loss: 0.8784601054070054
Validation loss: 2.4922832661946623

Epoch: 5| Step: 6
Training loss: 0.49801680530205605
Validation loss: 2.5403918263695044

Epoch: 5| Step: 7
Training loss: 0.6390454427592587
Validation loss: 2.6069434823639774

Epoch: 5| Step: 8
Training loss: 0.6383165310058487
Validation loss: 2.5839562024084635

Epoch: 5| Step: 9
Training loss: 0.6037301728446344
Validation loss: 2.5263785199910314

Epoch: 5| Step: 10
Training loss: 0.7147779173841076
Validation loss: 2.5873509910849686

Epoch: 5| Step: 11
Training loss: 0.6663317782972445
Validation loss: 2.5304300801297326

Epoch: 292| Step: 0
Training loss: 0.6526946534558651
Validation loss: 2.6199053340897995

Epoch: 5| Step: 1
Training loss: 0.5429067782157551
Validation loss: 2.4610982327725877

Epoch: 5| Step: 2
Training loss: 0.9611938568803944
Validation loss: 2.6061546722957085

Epoch: 5| Step: 3
Training loss: 0.7056462754183644
Validation loss: 2.565153004654182

Epoch: 5| Step: 4
Training loss: 0.7156358509823573
Validation loss: 2.4942676508855257

Epoch: 5| Step: 5
Training loss: 0.7035419499429937
Validation loss: 2.5086889428889867

Epoch: 5| Step: 6
Training loss: 0.9418747238837168
Validation loss: 2.641413471250038

Epoch: 5| Step: 7
Training loss: 0.49668023592805755
Validation loss: 2.6170150130638987

Epoch: 5| Step: 8
Training loss: 0.8621840948885866
Validation loss: 2.6046973463397545

Epoch: 5| Step: 9
Training loss: 0.6533908549315967
Validation loss: 2.5255776847681117

Epoch: 5| Step: 10
Training loss: 1.3297550744571098
Validation loss: 2.5594676731085415

Epoch: 5| Step: 11
Training loss: 0.5080753233158656
Validation loss: 2.5474573592921486

Epoch: 293| Step: 0
Training loss: 0.5816261366556991
Validation loss: 2.5666455370685584

Epoch: 5| Step: 1
Training loss: 0.6002499516720258
Validation loss: 2.564047253253617

Epoch: 5| Step: 2
Training loss: 0.636350185698009
Validation loss: 2.5470185463672794

Epoch: 5| Step: 3
Training loss: 0.7323379265041132
Validation loss: 2.50889503430408

Epoch: 5| Step: 4
Training loss: 0.7267254062266558
Validation loss: 2.540781173035121

Epoch: 5| Step: 5
Training loss: 0.7677224681144812
Validation loss: 2.4859339543190826

Epoch: 5| Step: 6
Training loss: 0.8886026879510572
Validation loss: 2.499938507118532

Epoch: 5| Step: 7
Training loss: 0.7459112213709375
Validation loss: 2.5456047420349694

Epoch: 5| Step: 8
Training loss: 0.816866767625837
Validation loss: 2.560022975109487

Epoch: 5| Step: 9
Training loss: 0.5717511256565077
Validation loss: 2.5799763168743777

Epoch: 5| Step: 10
Training loss: 1.2666273033567632
Validation loss: 2.5419525913276617

Epoch: 5| Step: 11
Training loss: 0.5658541389127221
Validation loss: 2.5199935922591674

Epoch: 294| Step: 0
Training loss: 0.8512885326677395
Validation loss: 2.552823830564348

Epoch: 5| Step: 1
Training loss: 0.8602360659787
Validation loss: 2.5200468536277487

Epoch: 5| Step: 2
Training loss: 0.6604112437373557
Validation loss: 2.536439399465799

Epoch: 5| Step: 3
Training loss: 0.7940343077307712
Validation loss: 2.537185237103721

Epoch: 5| Step: 4
Training loss: 0.9837078982678408
Validation loss: 2.5112543739735202

Epoch: 5| Step: 5
Training loss: 0.4201223914880649
Validation loss: 2.512974648059477

Epoch: 5| Step: 6
Training loss: 0.6146067975839871
Validation loss: 2.5544406643298827

Epoch: 5| Step: 7
Training loss: 0.8568288016299299
Validation loss: 2.5058949785882154

Epoch: 5| Step: 8
Training loss: 1.2730357466635904
Validation loss: 2.47146607531839

Epoch: 5| Step: 9
Training loss: 0.5911821754700541
Validation loss: 2.55436184175265

Epoch: 5| Step: 10
Training loss: 0.5787599530610354
Validation loss: 2.550244160413406

Epoch: 5| Step: 11
Training loss: 0.39845384302467635
Validation loss: 2.513219137059634

Epoch: 295| Step: 0
Training loss: 0.6279546990760116
Validation loss: 2.4855140018402557

Epoch: 5| Step: 1
Training loss: 0.9876353750510745
Validation loss: 2.485992267116454

Epoch: 5| Step: 2
Training loss: 0.6444173770071716
Validation loss: 2.5684486363979393

Epoch: 5| Step: 3
Training loss: 0.5283421425531242
Validation loss: 2.591283011838809

Epoch: 5| Step: 4
Training loss: 0.7987014931290963
Validation loss: 2.6092866779844166

Epoch: 5| Step: 5
Training loss: 1.195069032694205
Validation loss: 2.5832877667828114

Epoch: 5| Step: 6
Training loss: 0.8561957070617053
Validation loss: 2.5092059489813114

Epoch: 5| Step: 7
Training loss: 0.5985860137320044
Validation loss: 2.5175932219619632

Epoch: 5| Step: 8
Training loss: 0.6128626810368893
Validation loss: 2.526121815986268

Epoch: 5| Step: 9
Training loss: 0.47170202230012304
Validation loss: 2.4574927425762443

Epoch: 5| Step: 10
Training loss: 0.8535957909827958
Validation loss: 2.6062234608086463

Epoch: 5| Step: 11
Training loss: 0.5784886479446745
Validation loss: 2.5478903183987427

Epoch: 296| Step: 0
Training loss: 0.6698829706311838
Validation loss: 2.5691405951490416

Epoch: 5| Step: 1
Training loss: 0.6809293429764521
Validation loss: 2.5462983693650667

Epoch: 5| Step: 2
Training loss: 0.9583559793754359
Validation loss: 2.5100377154271345

Epoch: 5| Step: 3
Training loss: 0.5223460703988532
Validation loss: 2.547028484283307

Epoch: 5| Step: 4
Training loss: 0.9285987441268667
Validation loss: 2.5124931960859898

Epoch: 5| Step: 5
Training loss: 0.3801395950714237
Validation loss: 2.5440868140641277

Epoch: 5| Step: 6
Training loss: 0.6192719714317633
Validation loss: 2.547065591214195

Epoch: 5| Step: 7
Training loss: 0.6847454287852377
Validation loss: 2.5560369903370774

Epoch: 5| Step: 8
Training loss: 1.356289222255614
Validation loss: 2.584000637150323

Epoch: 5| Step: 9
Training loss: 0.5458021539659587
Validation loss: 2.51740159115454

Epoch: 5| Step: 10
Training loss: 0.9895191205255771
Validation loss: 2.5456107186374908

Epoch: 5| Step: 11
Training loss: 0.6360273761645354
Validation loss: 2.503381546198998

Epoch: 297| Step: 0
Training loss: 0.5852990805029021
Validation loss: 2.5619798147799533

Epoch: 5| Step: 1
Training loss: 0.7106608596651585
Validation loss: 2.56942801441633

Epoch: 5| Step: 2
Training loss: 1.1287075514642768
Validation loss: 2.5562848804584406

Epoch: 5| Step: 3
Training loss: 1.2287146281276535
Validation loss: 2.5222756316138284

Epoch: 5| Step: 4
Training loss: 0.5938503531928127
Validation loss: 2.5681941841098355

Epoch: 5| Step: 5
Training loss: 0.46887014756606704
Validation loss: 2.5110289959951952

Epoch: 5| Step: 6
Training loss: 0.6644984665459017
Validation loss: 2.5549004647773432

Epoch: 5| Step: 7
Training loss: 0.7461577782444122
Validation loss: 2.508815253945027

Epoch: 5| Step: 8
Training loss: 0.7549468058989925
Validation loss: 2.5797745869980515

Epoch: 5| Step: 9
Training loss: 0.4705022802855056
Validation loss: 2.501393756182751

Epoch: 5| Step: 10
Training loss: 0.4322354287790834
Validation loss: 2.566067840235388

Epoch: 5| Step: 11
Training loss: 1.208097314255884
Validation loss: 2.5198489203275543

Epoch: 298| Step: 0
Training loss: 0.7435262551870007
Validation loss: 2.5580183279980524

Epoch: 5| Step: 1
Training loss: 0.7979450147754038
Validation loss: 2.5470615076841567

Epoch: 5| Step: 2
Training loss: 0.6810421215284184
Validation loss: 2.5550709688410786

Epoch: 5| Step: 3
Training loss: 0.7266122534339499
Validation loss: 2.6485240438269044

Epoch: 5| Step: 4
Training loss: 0.7224693675295758
Validation loss: 2.5041689405150622

Epoch: 5| Step: 5
Training loss: 0.5481058166522377
Validation loss: 2.603581047333124

Epoch: 5| Step: 6
Training loss: 1.543428531179651
Validation loss: 2.490294886832449

Epoch: 5| Step: 7
Training loss: 0.6286406578181717
Validation loss: 2.572224519401657

Epoch: 5| Step: 8
Training loss: 0.6272529051718364
Validation loss: 2.483663209078071

Epoch: 5| Step: 9
Training loss: 0.746661264969099
Validation loss: 2.5594226144934695

Epoch: 5| Step: 10
Training loss: 0.5927057368976416
Validation loss: 2.5503184009121163

Epoch: 5| Step: 11
Training loss: 0.246084621805107
Validation loss: 2.5852689618367406

Epoch: 299| Step: 0
Training loss: 0.45204670628779253
Validation loss: 2.5852907376560954

Epoch: 5| Step: 1
Training loss: 0.49743511550797687
Validation loss: 2.6013418682580958

Epoch: 5| Step: 2
Training loss: 0.6395866305942431
Validation loss: 2.5314562560454843

Epoch: 5| Step: 3
Training loss: 0.8363272213028966
Validation loss: 2.5784793379064705

Epoch: 5| Step: 4
Training loss: 1.2109591082213977
Validation loss: 2.514069398056945

Epoch: 5| Step: 5
Training loss: 0.7837852540673422
Validation loss: 2.537874460308305

Epoch: 5| Step: 6
Training loss: 0.8503157562115004
Validation loss: 2.4803917059359897

Epoch: 5| Step: 7
Training loss: 0.576195202371392
Validation loss: 2.585689225432305

Epoch: 5| Step: 8
Training loss: 0.8345254398122975
Validation loss: 2.496561690094134

Epoch: 5| Step: 9
Training loss: 0.6891523358870397
Validation loss: 2.4774966839634387

Epoch: 5| Step: 10
Training loss: 0.6629991432431814
Validation loss: 2.55881162691282

Epoch: 5| Step: 11
Training loss: 0.43377466980864027
Validation loss: 2.54660363497131

Epoch: 300| Step: 0
Training loss: 0.5423943479559261
Validation loss: 2.5108926263837694

Epoch: 5| Step: 1
Training loss: 0.4450323662613624
Validation loss: 2.609992295000486

Epoch: 5| Step: 2
Training loss: 0.8657685777046231
Validation loss: 2.5887059492842046

Epoch: 5| Step: 3
Training loss: 1.1162062917697777
Validation loss: 2.538033853162571

Epoch: 5| Step: 4
Training loss: 0.6165097777015894
Validation loss: 2.602605122007559

Epoch: 5| Step: 5
Training loss: 0.7912811963769941
Validation loss: 2.5415359890806415

Epoch: 5| Step: 6
Training loss: 0.7199329923867335
Validation loss: 2.472057352360834

Epoch: 5| Step: 7
Training loss: 0.6909251505879498
Validation loss: 2.5213209513432164

Epoch: 5| Step: 8
Training loss: 0.6381201271072832
Validation loss: 2.5484726581218187

Epoch: 5| Step: 9
Training loss: 0.6111714707775162
Validation loss: 2.52812484235099

Epoch: 5| Step: 10
Training loss: 1.2792134730983995
Validation loss: 2.5386651809086813

Epoch: 5| Step: 11
Training loss: 0.5832823038487657
Validation loss: 2.5404869074905485

Testing loss: 2.513337624966856
