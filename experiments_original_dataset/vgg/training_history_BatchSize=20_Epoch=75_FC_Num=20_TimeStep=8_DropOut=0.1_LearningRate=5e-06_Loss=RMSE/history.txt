Epoch: 1| Step: 0
Training loss: 7.9850209193233335
Validation loss: 8.56386696329471

Epoch: 5| Step: 1
Training loss: 8.255211773379278
Validation loss: 8.541541583998448

Epoch: 5| Step: 2
Training loss: 8.521994016604504
Validation loss: 8.518869977494733

Epoch: 5| Step: 3
Training loss: 8.549668547691812
Validation loss: 8.498493659489744

Epoch: 5| Step: 4
Training loss: 8.990818002251485
Validation loss: 8.476700095189411

Epoch: 5| Step: 5
Training loss: 9.481351115844914
Validation loss: 8.455385856524035

Epoch: 5| Step: 6
Training loss: 8.245109264420124
Validation loss: 8.434628881171841

Epoch: 5| Step: 7
Training loss: 8.345923665688304
Validation loss: 8.415007197890185

Epoch: 5| Step: 8
Training loss: 8.08926137525349
Validation loss: 8.392899189063963

Epoch: 5| Step: 9
Training loss: 8.89060354649213
Validation loss: 8.370132274775054

Epoch: 5| Step: 10
Training loss: 8.643435912587076
Validation loss: 8.347963543169968

Epoch: 5| Step: 11
Training loss: 8.666365789423716
Validation loss: 8.3240905875966

Epoch: 2| Step: 0
Training loss: 8.185262359720728
Validation loss: 8.298664424482025

Epoch: 5| Step: 1
Training loss: 8.611677412328211
Validation loss: 8.273690637372757

Epoch: 5| Step: 2
Training loss: 8.297249248562649
Validation loss: 8.246237359181086

Epoch: 5| Step: 3
Training loss: 8.669412129149189
Validation loss: 8.216110946814966

Epoch: 5| Step: 4
Training loss: 8.559406696329136
Validation loss: 8.190384102036461

Epoch: 5| Step: 5
Training loss: 8.490845631248481
Validation loss: 8.159248161523216

Epoch: 5| Step: 6
Training loss: 8.117686574828351
Validation loss: 8.127047549744852

Epoch: 5| Step: 7
Training loss: 7.596152094438716
Validation loss: 8.094476222936835

Epoch: 5| Step: 8
Training loss: 8.540860865351283
Validation loss: 8.057643087885847

Epoch: 5| Step: 9
Training loss: 7.307191666353643
Validation loss: 8.027868951971252

Epoch: 5| Step: 10
Training loss: 8.15112471045623
Validation loss: 7.989647604341053

Epoch: 5| Step: 11
Training loss: 8.981381124814806
Validation loss: 7.95377359699604

Epoch: 3| Step: 0
Training loss: 8.698664893824718
Validation loss: 7.9115814607911386

Epoch: 5| Step: 1
Training loss: 8.14688543239287
Validation loss: 7.873586325939992

Epoch: 5| Step: 2
Training loss: 8.358302537804944
Validation loss: 7.834741959500673

Epoch: 5| Step: 3
Training loss: 7.612866863562256
Validation loss: 7.787184855951063

Epoch: 5| Step: 4
Training loss: 7.460566039100471
Validation loss: 7.749591980724951

Epoch: 5| Step: 5
Training loss: 7.845025312238208
Validation loss: 7.703070495288837

Epoch: 5| Step: 6
Training loss: 8.28012503414379
Validation loss: 7.652805586401078

Epoch: 5| Step: 7
Training loss: 7.6818429865444315
Validation loss: 7.610408590044285

Epoch: 5| Step: 8
Training loss: 7.446049496658578
Validation loss: 7.560774130704191

Epoch: 5| Step: 9
Training loss: 7.302285649158371
Validation loss: 7.513327244020221

Epoch: 5| Step: 10
Training loss: 7.179207969483249
Validation loss: 7.4577027024059594

Epoch: 5| Step: 11
Training loss: 6.026696892946677
Validation loss: 7.397264537323375

Epoch: 4| Step: 0
Training loss: 7.279745969846616
Validation loss: 7.347840478031802

Epoch: 5| Step: 1
Training loss: 7.493235780255156
Validation loss: 7.2940281849525705

Epoch: 5| Step: 2
Training loss: 8.098805619708397
Validation loss: 7.231927533226916

Epoch: 5| Step: 3
Training loss: 7.437298170925511
Validation loss: 7.164647934350533

Epoch: 5| Step: 4
Training loss: 6.638256413522298
Validation loss: 7.103289112769108

Epoch: 5| Step: 5
Training loss: 6.8542767393168935
Validation loss: 7.042456674746098

Epoch: 5| Step: 6
Training loss: 7.805026943397326
Validation loss: 6.975004232170616

Epoch: 5| Step: 7
Training loss: 6.826286155606331
Validation loss: 6.906277157369069

Epoch: 5| Step: 8
Training loss: 6.518213722941236
Validation loss: 6.834988296729456

Epoch: 5| Step: 9
Training loss: 6.694548413043993
Validation loss: 6.768104468901114

Epoch: 5| Step: 10
Training loss: 6.734288615582122
Validation loss: 6.696586188020584

Epoch: 5| Step: 11
Training loss: 6.7043922489101195
Validation loss: 6.618790997842593

Epoch: 5| Step: 0
Training loss: 6.098436011261188
Validation loss: 6.534373630041304

Epoch: 5| Step: 1
Training loss: 6.7970226052578875
Validation loss: 6.4595916957768695

Epoch: 5| Step: 2
Training loss: 6.378527693719827
Validation loss: 6.379705562374454

Epoch: 5| Step: 3
Training loss: 6.805986562907866
Validation loss: 6.28745337962568

Epoch: 5| Step: 4
Training loss: 6.912455123010689
Validation loss: 6.217995915787122

Epoch: 5| Step: 5
Training loss: 6.2904462156932315
Validation loss: 6.111194271427331

Epoch: 5| Step: 6
Training loss: 6.464084287905933
Validation loss: 6.018737423765803

Epoch: 5| Step: 7
Training loss: 6.071219868639199
Validation loss: 5.907588181452992

Epoch: 5| Step: 8
Training loss: 5.5475934490156655
Validation loss: 5.821764443576876

Epoch: 5| Step: 9
Training loss: 4.920590187588218
Validation loss: 5.719312567217442

Epoch: 5| Step: 10
Training loss: 5.8648818523347686
Validation loss: 5.594351340138624

Epoch: 5| Step: 11
Training loss: 5.590560941718318
Validation loss: 5.514609037060048

Epoch: 6| Step: 0
Training loss: 5.072906535906797
Validation loss: 5.397969830613255

Epoch: 5| Step: 1
Training loss: 5.253693326017686
Validation loss: 5.296258288465456

Epoch: 5| Step: 2
Training loss: 5.303499383698524
Validation loss: 5.174243211925982

Epoch: 5| Step: 3
Training loss: 5.250667892842095
Validation loss: 5.048943968476274

Epoch: 5| Step: 4
Training loss: 4.974466741918683
Validation loss: 4.91662366762055

Epoch: 5| Step: 5
Training loss: 4.451523663561286
Validation loss: 4.7809968187371705

Epoch: 5| Step: 6
Training loss: 3.951657350728415
Validation loss: 4.666715317994783

Epoch: 5| Step: 7
Training loss: 5.054904278642213
Validation loss: 4.533493416194329

Epoch: 5| Step: 8
Training loss: 4.340271139860375
Validation loss: 4.399262752323058

Epoch: 5| Step: 9
Training loss: 4.7429992885922845
Validation loss: 4.244253485639454

Epoch: 5| Step: 10
Training loss: 4.34411312204674
Validation loss: 4.103715473230822

Epoch: 5| Step: 11
Training loss: 5.0773846365342905
Validation loss: 3.9697153113949826

Epoch: 7| Step: 0
Training loss: 3.9251812984119385
Validation loss: 3.817635220204425

Epoch: 5| Step: 1
Training loss: 3.887811340425072
Validation loss: 3.6654559903805124

Epoch: 5| Step: 2
Training loss: 3.8135808444448505
Validation loss: 3.522956792797284

Epoch: 5| Step: 3
Training loss: 3.533972981572562
Validation loss: 3.3884782631390644

Epoch: 5| Step: 4
Training loss: 4.213918674547852
Validation loss: 3.295385002929144

Epoch: 5| Step: 5
Training loss: 2.735867164008355
Validation loss: 3.1527949013900862

Epoch: 5| Step: 6
Training loss: 2.90268628241389
Validation loss: 2.9942774002145622

Epoch: 5| Step: 7
Training loss: 2.5185004439619565
Validation loss: 2.913569922657403

Epoch: 5| Step: 8
Training loss: 2.9362551709645595
Validation loss: 2.881223469803059

Epoch: 5| Step: 9
Training loss: 2.288154604276667
Validation loss: 2.814980885608479

Epoch: 5| Step: 10
Training loss: 3.0714916653663638
Validation loss: 2.808834325596662

Epoch: 5| Step: 11
Training loss: 2.67543675787673
Validation loss: 2.8358507134335333

Epoch: 8| Step: 0
Training loss: 3.4474260762942652
Validation loss: 2.7709886906506744

Epoch: 5| Step: 1
Training loss: 2.188025057312695
Validation loss: 2.823961294564993

Epoch: 5| Step: 2
Training loss: 2.7424679691527145
Validation loss: 2.801263623128593

Epoch: 5| Step: 3
Training loss: 2.6028094811432885
Validation loss: 2.847181366934905

Epoch: 5| Step: 4
Training loss: 2.5497657892714694
Validation loss: 2.8587660149672103

Epoch: 5| Step: 5
Training loss: 2.695732636809095
Validation loss: 2.9282864318826776

Epoch: 5| Step: 6
Training loss: 2.300391172233124
Validation loss: 2.911088081706378

Epoch: 5| Step: 7
Training loss: 2.9371529232083784
Validation loss: 2.944879454491768

Epoch: 5| Step: 8
Training loss: 3.6864770019840387
Validation loss: 2.9354499061458705

Epoch: 5| Step: 9
Training loss: 2.617336895223025
Validation loss: 2.8938956547408203

Epoch: 5| Step: 10
Training loss: 2.6769535810046308
Validation loss: 2.939922260686065

Epoch: 5| Step: 11
Training loss: 2.0998410119317663
Validation loss: 2.9113328095720905

Epoch: 9| Step: 0
Training loss: 2.4544417619477077
Validation loss: 2.87621970840876

Epoch: 5| Step: 1
Training loss: 3.5874039055584768
Validation loss: 2.90907330941165

Epoch: 5| Step: 2
Training loss: 2.6332379911361308
Validation loss: 2.877616224076685

Epoch: 5| Step: 3
Training loss: 3.2067384760450235
Validation loss: 2.839205842081419

Epoch: 5| Step: 4
Training loss: 3.0237019741096947
Validation loss: 2.827834168825131

Epoch: 5| Step: 5
Training loss: 2.770718039119287
Validation loss: 2.836575505534083

Epoch: 5| Step: 6
Training loss: 2.6864782653361057
Validation loss: 2.81396031438633

Epoch: 5| Step: 7
Training loss: 2.4113005112043733
Validation loss: 2.862257048723334

Epoch: 5| Step: 8
Training loss: 2.6965645798204223
Validation loss: 2.7929775068950535

Epoch: 5| Step: 9
Training loss: 2.0388488657618087
Validation loss: 2.7690987368067654

Epoch: 5| Step: 10
Training loss: 2.6870689046335023
Validation loss: 2.774385533806601

Epoch: 5| Step: 11
Training loss: 2.181905076435096
Validation loss: 2.7650596558066107

Epoch: 10| Step: 0
Training loss: 2.8376689910980724
Validation loss: 2.7249692617660077

Epoch: 5| Step: 1
Training loss: 2.837234242635424
Validation loss: 2.7350167638519474

Epoch: 5| Step: 2
Training loss: 3.1155340642485623
Validation loss: 2.8041875636289038

Epoch: 5| Step: 3
Training loss: 2.2937957468070405
Validation loss: 2.7486102465019475

Epoch: 5| Step: 4
Training loss: 3.426775067194376
Validation loss: 2.7299003755349696

Epoch: 5| Step: 5
Training loss: 2.7044251242520185
Validation loss: 2.7475960114699793

Epoch: 5| Step: 6
Training loss: 2.3188424639504146
Validation loss: 2.7094150192666695

Epoch: 5| Step: 7
Training loss: 2.4357461733063173
Validation loss: 2.767218401962676

Epoch: 5| Step: 8
Training loss: 2.5710108773510703
Validation loss: 2.7387142229086563

Epoch: 5| Step: 9
Training loss: 3.1346326758216985
Validation loss: 2.710446403940396

Epoch: 5| Step: 10
Training loss: 2.019737838124893
Validation loss: 2.7742238429903754

Epoch: 5| Step: 11
Training loss: 2.411132614735209
Validation loss: 2.7630110814494415

Epoch: 11| Step: 0
Training loss: 2.819017953253253
Validation loss: 2.778451669064988

Epoch: 5| Step: 1
Training loss: 2.5793810934517505
Validation loss: 2.7450120006245684

Epoch: 5| Step: 2
Training loss: 3.158295676645194
Validation loss: 2.705301309093648

Epoch: 5| Step: 3
Training loss: 2.7756487560565533
Validation loss: 2.714968053227014

Epoch: 5| Step: 4
Training loss: 2.7508021831934792
Validation loss: 2.735053728425544

Epoch: 5| Step: 5
Training loss: 3.1460001482323903
Validation loss: 2.748016704293389

Epoch: 5| Step: 6
Training loss: 2.0158395579088086
Validation loss: 2.737620848625715

Epoch: 5| Step: 7
Training loss: 2.297769074067914
Validation loss: 2.702817017314063

Epoch: 5| Step: 8
Training loss: 2.2449869895507084
Validation loss: 2.7052550770967785

Epoch: 5| Step: 9
Training loss: 2.229357440901795
Validation loss: 2.710395000164939

Epoch: 5| Step: 10
Training loss: 3.473909681781156
Validation loss: 2.7492051890556306

Epoch: 5| Step: 11
Training loss: 0.9859798911967063
Validation loss: 2.655686270040743

Epoch: 12| Step: 0
Training loss: 2.2068083794066014
Validation loss: 2.6615411828888536

Epoch: 5| Step: 1
Training loss: 2.5882861947088105
Validation loss: 2.6954916226487935

Epoch: 5| Step: 2
Training loss: 3.236236478881173
Validation loss: 2.7493049545193213

Epoch: 5| Step: 3
Training loss: 2.971808213567548
Validation loss: 2.712660418804727

Epoch: 5| Step: 4
Training loss: 2.01778774889659
Validation loss: 2.7239826899084467

Epoch: 5| Step: 5
Training loss: 1.9970236327444877
Validation loss: 2.6975711738758847

Epoch: 5| Step: 6
Training loss: 2.4061743984483526
Validation loss: 2.6918307644590076

Epoch: 5| Step: 7
Training loss: 2.8369486873962724
Validation loss: 2.6573496954391524

Epoch: 5| Step: 8
Training loss: 3.1810933972018476
Validation loss: 2.702520385554142

Epoch: 5| Step: 9
Training loss: 2.848168262975984
Validation loss: 2.736934285229931

Epoch: 5| Step: 10
Training loss: 2.872537968503317
Validation loss: 2.786850587324856

Epoch: 5| Step: 11
Training loss: 1.9381759448892064
Validation loss: 2.7000652813083748

Epoch: 13| Step: 0
Training loss: 3.3899512962060996
Validation loss: 2.7052934122545023

Epoch: 5| Step: 1
Training loss: 2.9253713323176256
Validation loss: 2.7536883455105476

Epoch: 5| Step: 2
Training loss: 2.1219952601200993
Validation loss: 2.735601124835426

Epoch: 5| Step: 3
Training loss: 2.3820898742568186
Validation loss: 2.738247880718742

Epoch: 5| Step: 4
Training loss: 3.0737347736889036
Validation loss: 2.7247066175091508

Epoch: 5| Step: 5
Training loss: 2.6435028285283253
Validation loss: 2.7743393054214813

Epoch: 5| Step: 6
Training loss: 2.794768152601291
Validation loss: 2.674982167864868

Epoch: 5| Step: 7
Training loss: 2.590410219499152
Validation loss: 2.761765248987665

Epoch: 5| Step: 8
Training loss: 2.7642755179430143
Validation loss: 2.685468978214489

Epoch: 5| Step: 9
Training loss: 2.1985185230022255
Validation loss: 2.6904048006968675

Epoch: 5| Step: 10
Training loss: 2.1481536122809204
Validation loss: 2.672751738310581

Epoch: 5| Step: 11
Training loss: 1.0376773292021466
Validation loss: 2.696191543018502

Epoch: 14| Step: 0
Training loss: 2.834354347565935
Validation loss: 2.738895530565818

Epoch: 5| Step: 1
Training loss: 3.1330131028939654
Validation loss: 2.7140824968168316

Epoch: 5| Step: 2
Training loss: 2.345124108908021
Validation loss: 2.7835385500801917

Epoch: 5| Step: 3
Training loss: 2.6295720202543587
Validation loss: 2.669270742773039

Epoch: 5| Step: 4
Training loss: 2.1339615741191063
Validation loss: 2.717073354723708

Epoch: 5| Step: 5
Training loss: 2.490334422775777
Validation loss: 2.7483566315656036

Epoch: 5| Step: 6
Training loss: 2.464555678181553
Validation loss: 2.765719970681707

Epoch: 5| Step: 7
Training loss: 2.5275000593145798
Validation loss: 2.708234184846702

Epoch: 5| Step: 8
Training loss: 2.729268914168622
Validation loss: 2.6973065431415946

Epoch: 5| Step: 9
Training loss: 2.9217240401657247
Validation loss: 2.7542952819626287

Epoch: 5| Step: 10
Training loss: 2.2783278470460497
Validation loss: 2.6643401678965617

Epoch: 5| Step: 11
Training loss: 4.054245059179074
Validation loss: 2.7208581767522864

Epoch: 15| Step: 0
Training loss: 3.0991926003178225
Validation loss: 2.704547215773342

Epoch: 5| Step: 1
Training loss: 2.3053286937441158
Validation loss: 2.718676138565148

Epoch: 5| Step: 2
Training loss: 2.5721776624279875
Validation loss: 2.7292941781946047

Epoch: 5| Step: 3
Training loss: 2.39481928276963
Validation loss: 2.704209115812478

Epoch: 5| Step: 4
Training loss: 3.164595344793559
Validation loss: 2.7409410061790442

Epoch: 5| Step: 5
Training loss: 2.29827796491284
Validation loss: 2.7555641540676046

Epoch: 5| Step: 6
Training loss: 2.625444192996829
Validation loss: 2.7151385542897404

Epoch: 5| Step: 7
Training loss: 2.8958113049737326
Validation loss: 2.729280430604226

Epoch: 5| Step: 8
Training loss: 2.475367597774138
Validation loss: 2.713203977829487

Epoch: 5| Step: 9
Training loss: 2.6321747230927097
Validation loss: 2.677172478751366

Epoch: 5| Step: 10
Training loss: 2.501428577429009
Validation loss: 2.6788026481316662

Epoch: 5| Step: 11
Training loss: 1.0259058066848818
Validation loss: 2.6793204001423585

Epoch: 16| Step: 0
Training loss: 2.339016419430135
Validation loss: 2.687826997986703

Epoch: 5| Step: 1
Training loss: 2.104002829741979
Validation loss: 2.659722190543745

Epoch: 5| Step: 2
Training loss: 2.8288214231771636
Validation loss: 2.7539313745818026

Epoch: 5| Step: 3
Training loss: 2.727023722378625
Validation loss: 2.7160556165001384

Epoch: 5| Step: 4
Training loss: 2.647743336676821
Validation loss: 2.632632267307827

Epoch: 5| Step: 5
Training loss: 2.3532519180904408
Validation loss: 2.7471922173761683

Epoch: 5| Step: 6
Training loss: 2.5085259014067534
Validation loss: 2.7074683654371827

Epoch: 5| Step: 7
Training loss: 3.133804734934712
Validation loss: 2.696493765302416

Epoch: 5| Step: 8
Training loss: 3.311634598454981
Validation loss: 2.69374501817188

Epoch: 5| Step: 9
Training loss: 2.4735120404229756
Validation loss: 2.652317532019797

Epoch: 5| Step: 10
Training loss: 2.0410963416679917
Validation loss: 2.6737041198494036

Epoch: 5| Step: 11
Training loss: 2.8868842587236854
Validation loss: 2.6502409789442205

Epoch: 17| Step: 0
Training loss: 2.164909885460433
Validation loss: 2.686753842175578

Epoch: 5| Step: 1
Training loss: 2.61502897155351
Validation loss: 2.740443414974497

Epoch: 5| Step: 2
Training loss: 2.1324380958221103
Validation loss: 2.6401925268918904

Epoch: 5| Step: 3
Training loss: 2.636013631846211
Validation loss: 2.6957992667021364

Epoch: 5| Step: 4
Training loss: 2.6904703625271478
Validation loss: 2.6716178264623647

Epoch: 5| Step: 5
Training loss: 2.398136679208574
Validation loss: 2.71763615062142

Epoch: 5| Step: 6
Training loss: 2.491144805233793
Validation loss: 2.714702999573836

Epoch: 5| Step: 7
Training loss: 3.240943614927097
Validation loss: 2.73382335366164

Epoch: 5| Step: 8
Training loss: 2.0963517151496407
Validation loss: 2.6707148422007236

Epoch: 5| Step: 9
Training loss: 3.460381663446081
Validation loss: 2.7032807292437586

Epoch: 5| Step: 10
Training loss: 2.5424858607496357
Validation loss: 2.6782244422371124

Epoch: 5| Step: 11
Training loss: 3.663598134886701
Validation loss: 2.7250584021559847

Epoch: 18| Step: 0
Training loss: 2.8363211716405266
Validation loss: 2.7368619308746207

Epoch: 5| Step: 1
Training loss: 2.971351206736493
Validation loss: 2.6424702887607627

Epoch: 5| Step: 2
Training loss: 2.6075113002572468
Validation loss: 2.6522696086276034

Epoch: 5| Step: 3
Training loss: 2.5775999517143617
Validation loss: 2.6977306741257867

Epoch: 5| Step: 4
Training loss: 2.336765512542478
Validation loss: 2.728474159080375

Epoch: 5| Step: 5
Training loss: 2.080881112430752
Validation loss: 2.685264322849109

Epoch: 5| Step: 6
Training loss: 2.8934106549538874
Validation loss: 2.65023033352666

Epoch: 5| Step: 7
Training loss: 2.285976269302614
Validation loss: 2.632033556405643

Epoch: 5| Step: 8
Training loss: 2.871802500742606
Validation loss: 2.639506266692538

Epoch: 5| Step: 9
Training loss: 2.310092291206215
Validation loss: 2.7193027862462076

Epoch: 5| Step: 10
Training loss: 2.4830535637205204
Validation loss: 2.7206286593376876

Epoch: 5| Step: 11
Training loss: 2.8806630626968737
Validation loss: 2.7146511787159002

Epoch: 19| Step: 0
Training loss: 2.7901594638715164
Validation loss: 2.678906081199548

Epoch: 5| Step: 1
Training loss: 2.817629734900959
Validation loss: 2.704906145084666

Epoch: 5| Step: 2
Training loss: 2.360325804866957
Validation loss: 2.67734034797505

Epoch: 5| Step: 3
Training loss: 2.605156600989647
Validation loss: 2.6765903706759504

Epoch: 5| Step: 4
Training loss: 2.747874045071594
Validation loss: 2.731155985735227

Epoch: 5| Step: 5
Training loss: 3.3725493682120997
Validation loss: 2.7321260413463575

Epoch: 5| Step: 6
Training loss: 2.6101707113276995
Validation loss: 2.7206005762641072

Epoch: 5| Step: 7
Training loss: 1.9062079753308252
Validation loss: 2.747823724676418

Epoch: 5| Step: 8
Training loss: 2.2594491906865684
Validation loss: 2.689977132648048

Epoch: 5| Step: 9
Training loss: 2.422235375941236
Validation loss: 2.683733248428114

Epoch: 5| Step: 10
Training loss: 2.5659255415117794
Validation loss: 2.6674770983887024

Epoch: 5| Step: 11
Training loss: 2.062944768864345
Validation loss: 2.688480542086792

Epoch: 20| Step: 0
Training loss: 2.4367198184574543
Validation loss: 2.705900281697237

Epoch: 5| Step: 1
Training loss: 2.837234914891658
Validation loss: 2.7335844986257447

Epoch: 5| Step: 2
Training loss: 2.763243776196196
Validation loss: 2.6580514633335994

Epoch: 5| Step: 3
Training loss: 2.393794134544895
Validation loss: 2.7333078863444165

Epoch: 5| Step: 4
Training loss: 2.4433659127298126
Validation loss: 2.653685798131942

Epoch: 5| Step: 5
Training loss: 2.9248178930732767
Validation loss: 2.7171032767306604

Epoch: 5| Step: 6
Training loss: 2.859677491577496
Validation loss: 2.6566058537591966

Epoch: 5| Step: 7
Training loss: 2.128846445905994
Validation loss: 2.721025953927754

Epoch: 5| Step: 8
Training loss: 3.1116637427859946
Validation loss: 2.6730339035484283

Epoch: 5| Step: 9
Training loss: 2.6870177967488726
Validation loss: 2.7441709758849435

Epoch: 5| Step: 10
Training loss: 1.9229709632732475
Validation loss: 2.695515091510799

Epoch: 5| Step: 11
Training loss: 2.2764568401210865
Validation loss: 2.6813250062139162

Epoch: 21| Step: 0
Training loss: 2.1047337085887667
Validation loss: 2.6806063805067866

Epoch: 5| Step: 1
Training loss: 3.0051552664811148
Validation loss: 2.717776416516953

Epoch: 5| Step: 2
Training loss: 3.2602366112339864
Validation loss: 2.735204607134661

Epoch: 5| Step: 3
Training loss: 2.767487152262762
Validation loss: 2.664987176147988

Epoch: 5| Step: 4
Training loss: 2.2866116575885003
Validation loss: 2.7356531915918074

Epoch: 5| Step: 5
Training loss: 2.1298172147882086
Validation loss: 2.687375065760632

Epoch: 5| Step: 6
Training loss: 2.1880217883543747
Validation loss: 2.736101393889477

Epoch: 5| Step: 7
Training loss: 3.366208246073409
Validation loss: 2.7193729483508213

Epoch: 5| Step: 8
Training loss: 2.1907002608884314
Validation loss: 2.611545330211944

Epoch: 5| Step: 9
Training loss: 2.400179152954645
Validation loss: 2.675730342334315

Epoch: 5| Step: 10
Training loss: 2.1108775121154673
Validation loss: 2.6527214717686927

Epoch: 5| Step: 11
Training loss: 2.268176096059205
Validation loss: 2.6588537394902816

Epoch: 22| Step: 0
Training loss: 2.6447629390406893
Validation loss: 2.655403929956732

Epoch: 5| Step: 1
Training loss: 2.8264434198924397
Validation loss: 2.6930355645473303

Epoch: 5| Step: 2
Training loss: 2.974060769440858
Validation loss: 2.688468344653108

Epoch: 5| Step: 3
Training loss: 2.9281698543080985
Validation loss: 2.695764114949527

Epoch: 5| Step: 4
Training loss: 2.272976228776815
Validation loss: 2.767446223606319

Epoch: 5| Step: 5
Training loss: 2.6002615577008847
Validation loss: 2.7228510023944272

Epoch: 5| Step: 6
Training loss: 2.069051106370726
Validation loss: 2.6884563799552144

Epoch: 5| Step: 7
Training loss: 2.3018415044977822
Validation loss: 2.6869714535087788

Epoch: 5| Step: 8
Training loss: 2.4699053414928795
Validation loss: 2.7643617988735225

Epoch: 5| Step: 9
Training loss: 2.5074532985426785
Validation loss: 2.7252332440276343

Epoch: 5| Step: 10
Training loss: 2.611053931735216
Validation loss: 2.7070720205314784

Epoch: 5| Step: 11
Training loss: 3.233621703066467
Validation loss: 2.6872206032589747

Epoch: 23| Step: 0
Training loss: 2.7458001925408153
Validation loss: 2.7336230306700693

Epoch: 5| Step: 1
Training loss: 2.41873329413113
Validation loss: 2.745887336190267

Epoch: 5| Step: 2
Training loss: 2.5097269611868644
Validation loss: 2.6782808903147424

Epoch: 5| Step: 3
Training loss: 2.7117122895150914
Validation loss: 2.6560032486840663

Epoch: 5| Step: 4
Training loss: 2.8664616385780315
Validation loss: 2.7189237349089943

Epoch: 5| Step: 5
Training loss: 2.284037519958489
Validation loss: 2.6965242398666955

Epoch: 5| Step: 6
Training loss: 2.6669979982372163
Validation loss: 2.7360964342768246

Epoch: 5| Step: 7
Training loss: 2.683799324879404
Validation loss: 2.61882462421755

Epoch: 5| Step: 8
Training loss: 2.6758881707652518
Validation loss: 2.644416152951247

Epoch: 5| Step: 9
Training loss: 2.2928323266486363
Validation loss: 2.7396247821955195

Epoch: 5| Step: 10
Training loss: 1.934957866949277
Validation loss: 2.6344075036146006

Epoch: 5| Step: 11
Training loss: 3.3029714326700104
Validation loss: 2.67595751847749

Epoch: 24| Step: 0
Training loss: 2.318878964027832
Validation loss: 2.6812565753799826

Epoch: 5| Step: 1
Training loss: 2.3546287848246803
Validation loss: 2.636670927391114

Epoch: 5| Step: 2
Training loss: 2.817668066013226
Validation loss: 2.725673973441278

Epoch: 5| Step: 3
Training loss: 2.0972470358530804
Validation loss: 2.7100105936352454

Epoch: 5| Step: 4
Training loss: 2.6232974571124092
Validation loss: 2.715431482745749

Epoch: 5| Step: 5
Training loss: 2.480566115983975
Validation loss: 2.6726293298398307

Epoch: 5| Step: 6
Training loss: 3.303275020660796
Validation loss: 2.6664119030035347

Epoch: 5| Step: 7
Training loss: 2.9782657105707058
Validation loss: 2.680858515604467

Epoch: 5| Step: 8
Training loss: 2.409179984387649
Validation loss: 2.6187484868666617

Epoch: 5| Step: 9
Training loss: 2.227439413220726
Validation loss: 2.6575053408877993

Epoch: 5| Step: 10
Training loss: 2.5247792553485793
Validation loss: 2.695009603388891

Epoch: 5| Step: 11
Training loss: 3.2174783805826266
Validation loss: 2.7568649739091993

Epoch: 25| Step: 0
Training loss: 2.4957065908850073
Validation loss: 2.7462337127223404

Epoch: 5| Step: 1
Training loss: 3.361048365936447
Validation loss: 2.7115367443301612

Epoch: 5| Step: 2
Training loss: 2.394326230804362
Validation loss: 2.7605245149285422

Epoch: 5| Step: 3
Training loss: 3.259232831215237
Validation loss: 2.79277832164569

Epoch: 5| Step: 4
Training loss: 2.263579504121353
Validation loss: 2.7704294072825575

Epoch: 5| Step: 5
Training loss: 1.7149369685876614
Validation loss: 2.739839452416195

Epoch: 5| Step: 6
Training loss: 2.673696867212912
Validation loss: 2.7567608370738745

Epoch: 5| Step: 7
Training loss: 2.814356720839814
Validation loss: 2.7306770096116706

Epoch: 5| Step: 8
Training loss: 1.6534473530359153
Validation loss: 2.664144274220065

Epoch: 5| Step: 9
Training loss: 2.438613734972141
Validation loss: 2.682372761707239

Epoch: 5| Step: 10
Training loss: 2.5144477127109397
Validation loss: 2.7025680445969016

Epoch: 5| Step: 11
Training loss: 2.9146099650157216
Validation loss: 2.730003655679232

Epoch: 26| Step: 0
Training loss: 3.1520236584312857
Validation loss: 2.6519142593425444

Epoch: 5| Step: 1
Training loss: 2.6076696613887362
Validation loss: 2.70457961059919

Epoch: 5| Step: 2
Training loss: 1.712218062310292
Validation loss: 2.620080971085425

Epoch: 5| Step: 3
Training loss: 2.3544400374318433
Validation loss: 2.6438396945164144

Epoch: 5| Step: 4
Training loss: 2.5305658993705595
Validation loss: 2.6514130515199925

Epoch: 5| Step: 5
Training loss: 2.388874884374609
Validation loss: 2.6726443129407373

Epoch: 5| Step: 6
Training loss: 3.1258363748927325
Validation loss: 2.70032560966543

Epoch: 5| Step: 7
Training loss: 2.391869613685255
Validation loss: 2.648933656742325

Epoch: 5| Step: 8
Training loss: 2.6360881588250065
Validation loss: 2.721646778978553

Epoch: 5| Step: 9
Training loss: 2.480125391466621
Validation loss: 2.7286875330901257

Epoch: 5| Step: 10
Training loss: 3.0825513587008277
Validation loss: 2.6600145516021447

Epoch: 5| Step: 11
Training loss: 0.9852342942231544
Validation loss: 2.6906975365319274

Epoch: 27| Step: 0
Training loss: 2.202109894341191
Validation loss: 2.7089802421789493

Epoch: 5| Step: 1
Training loss: 2.3155643676562474
Validation loss: 2.636658260452222

Epoch: 5| Step: 2
Training loss: 2.9924454938853127
Validation loss: 2.6889095047866705

Epoch: 5| Step: 3
Training loss: 2.5585958000349613
Validation loss: 2.651444969652115

Epoch: 5| Step: 4
Training loss: 2.6096354828525454
Validation loss: 2.7275517662909787

Epoch: 5| Step: 5
Training loss: 2.153394273106246
Validation loss: 2.6831215429591064

Epoch: 5| Step: 6
Training loss: 2.7647043193531036
Validation loss: 2.6845709674788614

Epoch: 5| Step: 7
Training loss: 2.663255228020104
Validation loss: 2.721310108077607

Epoch: 5| Step: 8
Training loss: 2.5408139804875844
Validation loss: 2.766365993680504

Epoch: 5| Step: 9
Training loss: 2.5041340026587005
Validation loss: 2.661323713168962

Epoch: 5| Step: 10
Training loss: 2.4697188395737295
Validation loss: 2.644719574015709

Epoch: 5| Step: 11
Training loss: 3.4178164028547595
Validation loss: 2.66929352293218

Epoch: 28| Step: 0
Training loss: 2.4919950117915457
Validation loss: 2.6336430976051894

Epoch: 5| Step: 1
Training loss: 2.934646519133223
Validation loss: 2.7097684518081624

Epoch: 5| Step: 2
Training loss: 2.7383423715427955
Validation loss: 2.6634593441180923

Epoch: 5| Step: 3
Training loss: 2.318585919026921
Validation loss: 2.707110331794439

Epoch: 5| Step: 4
Training loss: 2.839062862784615
Validation loss: 2.6794596872722893

Epoch: 5| Step: 5
Training loss: 2.699235267423006
Validation loss: 2.6457603768680444

Epoch: 5| Step: 6
Training loss: 2.290249253246967
Validation loss: 2.6453395154895025

Epoch: 5| Step: 7
Training loss: 2.495421795251909
Validation loss: 2.7652233715784176

Epoch: 5| Step: 8
Training loss: 2.366691915171447
Validation loss: 2.7434152135317826

Epoch: 5| Step: 9
Training loss: 2.904452188285785
Validation loss: 2.6671242780740316

Epoch: 5| Step: 10
Training loss: 2.1052809934111556
Validation loss: 2.6671697742995732

Epoch: 5| Step: 11
Training loss: 1.0480436947063771
Validation loss: 2.685765327585289

Epoch: 29| Step: 0
Training loss: 2.7315657653544685
Validation loss: 2.6226525861305245

Epoch: 5| Step: 1
Training loss: 2.4348383334029284
Validation loss: 2.6710097267076605

Epoch: 5| Step: 2
Training loss: 2.5118605601856006
Validation loss: 2.7431515903535666

Epoch: 5| Step: 3
Training loss: 2.180678057081158
Validation loss: 2.661704902400168

Epoch: 5| Step: 4
Training loss: 2.6266396261007774
Validation loss: 2.654683541303755

Epoch: 5| Step: 5
Training loss: 2.6163399761710338
Validation loss: 2.6367665189960596

Epoch: 5| Step: 6
Training loss: 3.223355452084582
Validation loss: 2.696264170829167

Epoch: 5| Step: 7
Training loss: 2.6001672067429125
Validation loss: 2.6899939210106893

Epoch: 5| Step: 8
Training loss: 2.6754849680572934
Validation loss: 2.6492140352654734

Epoch: 5| Step: 9
Training loss: 2.346593530591726
Validation loss: 2.630147802329934

Epoch: 5| Step: 10
Training loss: 2.532348206198935
Validation loss: 2.6852086338545496

Epoch: 5| Step: 11
Training loss: 0.9753976817824861
Validation loss: 2.6600385276674055

Epoch: 30| Step: 0
Training loss: 2.900400818058688
Validation loss: 2.6444554808753207

Epoch: 5| Step: 1
Training loss: 2.4662289845440797
Validation loss: 2.7478091587402225

Epoch: 5| Step: 2
Training loss: 2.8059570499431183
Validation loss: 2.665093551494329

Epoch: 5| Step: 3
Training loss: 2.1281748223879533
Validation loss: 2.692859639258418

Epoch: 5| Step: 4
Training loss: 2.232712026782082
Validation loss: 2.6446141314983307

Epoch: 5| Step: 5
Training loss: 2.4318728906705167
Validation loss: 2.6929532990484097

Epoch: 5| Step: 6
Training loss: 2.6212950400365402
Validation loss: 2.700690553212836

Epoch: 5| Step: 7
Training loss: 2.8688595752940484
Validation loss: 2.6844485354611645

Epoch: 5| Step: 8
Training loss: 2.317782991614146
Validation loss: 2.721919444874982

Epoch: 5| Step: 9
Training loss: 2.3779605683313116
Validation loss: 2.7419256427645293

Epoch: 5| Step: 10
Training loss: 3.1615654028034297
Validation loss: 2.723122927542566

Epoch: 5| Step: 11
Training loss: 2.080432041487548
Validation loss: 2.6309813292060897

Epoch: 31| Step: 0
Training loss: 2.0215199932701426
Validation loss: 2.704468104945663

Epoch: 5| Step: 1
Training loss: 1.914739372306603
Validation loss: 2.7230023018685636

Epoch: 5| Step: 2
Training loss: 2.634002507167309
Validation loss: 2.688469471652482

Epoch: 5| Step: 3
Training loss: 3.0961559457858385
Validation loss: 2.710044328935822

Epoch: 5| Step: 4
Training loss: 2.720224265782574
Validation loss: 2.7102187831889406

Epoch: 5| Step: 5
Training loss: 2.1686459695012315
Validation loss: 2.719921765721677

Epoch: 5| Step: 6
Training loss: 2.6546620727542742
Validation loss: 2.7191322942130385

Epoch: 5| Step: 7
Training loss: 2.726968642101721
Validation loss: 2.7322209984011

Epoch: 5| Step: 8
Training loss: 2.678724555225366
Validation loss: 2.6625420826733768

Epoch: 5| Step: 9
Training loss: 3.065706715092601
Validation loss: 2.737605502651772

Epoch: 5| Step: 10
Training loss: 2.370812790641438
Validation loss: 2.789398671752857

Epoch: 5| Step: 11
Training loss: 2.183038139286193
Validation loss: 2.662465307520113

Epoch: 32| Step: 0
Training loss: 3.1005920890687007
Validation loss: 2.657348514119787

Epoch: 5| Step: 1
Training loss: 3.112129256753676
Validation loss: 2.71061056696021

Epoch: 5| Step: 2
Training loss: 2.2909586997736566
Validation loss: 2.699912199753299

Epoch: 5| Step: 3
Training loss: 2.230869023471354
Validation loss: 2.6317203003268173

Epoch: 5| Step: 4
Training loss: 2.555870412236886
Validation loss: 2.679825544740484

Epoch: 5| Step: 5
Training loss: 2.5547362156694047
Validation loss: 2.6704745944910395

Epoch: 5| Step: 6
Training loss: 1.6732532845052677
Validation loss: 2.7289156373644556

Epoch: 5| Step: 7
Training loss: 2.4095291978943463
Validation loss: 2.7297261783252056

Epoch: 5| Step: 8
Training loss: 2.2190044418366144
Validation loss: 2.7256227456858886

Epoch: 5| Step: 9
Training loss: 2.7042572648948044
Validation loss: 2.693685694883599

Epoch: 5| Step: 10
Training loss: 2.645014708826022
Validation loss: 2.670740440665538

Epoch: 5| Step: 11
Training loss: 2.5178052091025402
Validation loss: 2.7499807169267076

Epoch: 33| Step: 0
Training loss: 2.512461029054156
Validation loss: 2.6544919797232844

Epoch: 5| Step: 1
Training loss: 3.22606280061974
Validation loss: 2.6578912414213383

Epoch: 5| Step: 2
Training loss: 2.356000495470186
Validation loss: 2.7163768839499056

Epoch: 5| Step: 3
Training loss: 2.7271167443202904
Validation loss: 2.686248391743979

Epoch: 5| Step: 4
Training loss: 2.618966298058727
Validation loss: 2.6420690737427086

Epoch: 5| Step: 5
Training loss: 2.6822526848685637
Validation loss: 2.6447553027912054

Epoch: 5| Step: 6
Training loss: 1.808726427389945
Validation loss: 2.651647653375678

Epoch: 5| Step: 7
Training loss: 2.1735488698523047
Validation loss: 2.6654725990093944

Epoch: 5| Step: 8
Training loss: 2.5299757587643605
Validation loss: 2.644033729863485

Epoch: 5| Step: 9
Training loss: 2.384397386118341
Validation loss: 2.6470549359012554

Epoch: 5| Step: 10
Training loss: 2.68172081857286
Validation loss: 2.6645111981416263

Epoch: 5| Step: 11
Training loss: 2.240642799721728
Validation loss: 2.595884153675847

Epoch: 34| Step: 0
Training loss: 2.873153425220867
Validation loss: 2.6607854755285993

Epoch: 5| Step: 1
Training loss: 2.620871066826024
Validation loss: 2.711841927085159

Epoch: 5| Step: 2
Training loss: 3.1556006037342694
Validation loss: 2.6779893734692384

Epoch: 5| Step: 3
Training loss: 2.8119816620338667
Validation loss: 2.664250677627888

Epoch: 5| Step: 4
Training loss: 2.4218433993339077
Validation loss: 2.6815445770007305

Epoch: 5| Step: 5
Training loss: 2.2466459706689865
Validation loss: 2.733111120317134

Epoch: 5| Step: 6
Training loss: 2.2594408545387266
Validation loss: 2.693659525249512

Epoch: 5| Step: 7
Training loss: 2.1551941207581824
Validation loss: 2.6557135171099366

Epoch: 5| Step: 8
Training loss: 2.331494344633681
Validation loss: 2.706368420706522

Epoch: 5| Step: 9
Training loss: 2.4407198253775895
Validation loss: 2.661134966461523

Epoch: 5| Step: 10
Training loss: 2.5983172730085524
Validation loss: 2.6888779981239788

Epoch: 5| Step: 11
Training loss: 3.1933808772211862
Validation loss: 2.699924010661524

Epoch: 35| Step: 0
Training loss: 2.3072381856559847
Validation loss: 2.750055121100583

Epoch: 5| Step: 1
Training loss: 2.417021286914475
Validation loss: 2.799496986273304

Epoch: 5| Step: 2
Training loss: 3.0437031203778004
Validation loss: 2.8382421294656814

Epoch: 5| Step: 3
Training loss: 2.004819189846873
Validation loss: 2.8424339008670167

Epoch: 5| Step: 4
Training loss: 2.571922748627658
Validation loss: 2.867001571655508

Epoch: 5| Step: 5
Training loss: 2.509595005752025
Validation loss: 2.9426322398292135

Epoch: 5| Step: 6
Training loss: 2.2965038804200666
Validation loss: 2.874985577367459

Epoch: 5| Step: 7
Training loss: 3.4245498862657775
Validation loss: 2.805163942494102

Epoch: 5| Step: 8
Training loss: 2.902413081166357
Validation loss: 2.73424128977512

Epoch: 5| Step: 9
Training loss: 2.638723738560902
Validation loss: 2.6853097799429353

Epoch: 5| Step: 10
Training loss: 2.637751533844095
Validation loss: 2.6564216146942297

Epoch: 5| Step: 11
Training loss: 0.8801043672877841
Validation loss: 2.6173752940352477

Epoch: 36| Step: 0
Training loss: 2.5102928943644853
Validation loss: 2.683289034450139

Epoch: 5| Step: 1
Training loss: 2.438163275830176
Validation loss: 2.650768611962903

Epoch: 5| Step: 2
Training loss: 2.6081615070463675
Validation loss: 2.6773297101259255

Epoch: 5| Step: 3
Training loss: 2.6265523044585732
Validation loss: 2.722774842359882

Epoch: 5| Step: 4
Training loss: 2.5602354883125957
Validation loss: 2.742305303870705

Epoch: 5| Step: 5
Training loss: 2.2520046840300556
Validation loss: 2.730269618088202

Epoch: 5| Step: 6
Training loss: 3.024916334019806
Validation loss: 2.7117324931328475

Epoch: 5| Step: 7
Training loss: 3.0355211821614874
Validation loss: 2.7015809921358365

Epoch: 5| Step: 8
Training loss: 2.321219835224036
Validation loss: 2.624939206342776

Epoch: 5| Step: 9
Training loss: 2.4063176727687168
Validation loss: 2.682316575659982

Epoch: 5| Step: 10
Training loss: 2.1844086738577673
Validation loss: 2.704495969852203

Epoch: 5| Step: 11
Training loss: 4.142094880244565
Validation loss: 2.694551749375886

Epoch: 37| Step: 0
Training loss: 2.576990421216672
Validation loss: 2.7391437509036787

Epoch: 5| Step: 1
Training loss: 2.609417669438505
Validation loss: 2.751866444183017

Epoch: 5| Step: 2
Training loss: 2.9975160806079786
Validation loss: 2.7165214898122874

Epoch: 5| Step: 3
Training loss: 2.5316041298384
Validation loss: 2.694071077475407

Epoch: 5| Step: 4
Training loss: 2.4524362168101277
Validation loss: 2.723030867269844

Epoch: 5| Step: 5
Training loss: 2.2678591531888377
Validation loss: 2.6452552747160407

Epoch: 5| Step: 6
Training loss: 2.337605164962013
Validation loss: 2.6788549807494713

Epoch: 5| Step: 7
Training loss: 2.4559351867362
Validation loss: 2.7282064340504237

Epoch: 5| Step: 8
Training loss: 2.5156729557371027
Validation loss: 2.6749578540963808

Epoch: 5| Step: 9
Training loss: 2.487826079652695
Validation loss: 2.6834248133776644

Epoch: 5| Step: 10
Training loss: 2.221945275162431
Validation loss: 2.7046444835654233

Epoch: 5| Step: 11
Training loss: 3.090605553854157
Validation loss: 2.654656392185204

Epoch: 38| Step: 0
Training loss: 2.2385925822076223
Validation loss: 2.67485003080696

Epoch: 5| Step: 1
Training loss: 2.2027676339842595
Validation loss: 2.6944647483180852

Epoch: 5| Step: 2
Training loss: 2.8194686176618857
Validation loss: 2.6244607363931456

Epoch: 5| Step: 3
Training loss: 1.5957189626853268
Validation loss: 2.684794994178625

Epoch: 5| Step: 4
Training loss: 2.9545852845181524
Validation loss: 2.622417996618162

Epoch: 5| Step: 5
Training loss: 2.479831980274193
Validation loss: 2.6845443907506534

Epoch: 5| Step: 6
Training loss: 2.737678232879278
Validation loss: 2.6519040626733257

Epoch: 5| Step: 7
Training loss: 2.460406339937568
Validation loss: 2.6819458574997785

Epoch: 5| Step: 8
Training loss: 2.077233029872741
Validation loss: 2.677831082739034

Epoch: 5| Step: 9
Training loss: 2.823990977534937
Validation loss: 2.710100248038049

Epoch: 5| Step: 10
Training loss: 3.105125859361908
Validation loss: 2.684830848260133

Epoch: 5| Step: 11
Training loss: 2.687492548022917
Validation loss: 2.6480890080401895

Epoch: 39| Step: 0
Training loss: 1.8882921186204586
Validation loss: 2.666617364477336

Epoch: 5| Step: 1
Training loss: 2.1516021170809094
Validation loss: 2.705917900094645

Epoch: 5| Step: 2
Training loss: 2.48017143810589
Validation loss: 2.7304504932380786

Epoch: 5| Step: 3
Training loss: 2.903413434272236
Validation loss: 2.7983688151529953

Epoch: 5| Step: 4
Training loss: 2.4546652653863
Validation loss: 2.729763265488829

Epoch: 5| Step: 5
Training loss: 2.7687136542214446
Validation loss: 2.730160791787784

Epoch: 5| Step: 6
Training loss: 3.1036880089986734
Validation loss: 2.752389862803257

Epoch: 5| Step: 7
Training loss: 2.546170189814115
Validation loss: 2.738305366108805

Epoch: 5| Step: 8
Training loss: 2.1226440159764874
Validation loss: 2.651429357203754

Epoch: 5| Step: 9
Training loss: 2.164020854673182
Validation loss: 2.6653140792695895

Epoch: 5| Step: 10
Training loss: 2.972452364733186
Validation loss: 2.726284344465717

Epoch: 5| Step: 11
Training loss: 1.9223819467240573
Validation loss: 2.7124137486751114

Epoch: 40| Step: 0
Training loss: 2.393127926306381
Validation loss: 2.665146932332737

Epoch: 5| Step: 1
Training loss: 2.2997029859081315
Validation loss: 2.615659630264013

Epoch: 5| Step: 2
Training loss: 1.9526717003266554
Validation loss: 2.683906211227497

Epoch: 5| Step: 3
Training loss: 2.253630570025794
Validation loss: 2.691306733837016

Epoch: 5| Step: 4
Training loss: 3.2017336917383528
Validation loss: 2.6127342560188866

Epoch: 5| Step: 5
Training loss: 2.0822825897410797
Validation loss: 2.719806823824595

Epoch: 5| Step: 6
Training loss: 3.031277685923823
Validation loss: 2.692571693116466

Epoch: 5| Step: 7
Training loss: 2.6199243611781386
Validation loss: 2.651473714001029

Epoch: 5| Step: 8
Training loss: 2.3942036490190373
Validation loss: 2.6918505821835863

Epoch: 5| Step: 9
Training loss: 2.7422687051166252
Validation loss: 2.660958578489559

Epoch: 5| Step: 10
Training loss: 2.7770273964684042
Validation loss: 2.620201584362765

Epoch: 5| Step: 11
Training loss: 2.940225838012384
Validation loss: 2.637005283186954

Epoch: 41| Step: 0
Training loss: 3.095325877792819
Validation loss: 2.675852011234559

Epoch: 5| Step: 1
Training loss: 2.9714245443788423
Validation loss: 2.6783359407421337

Epoch: 5| Step: 2
Training loss: 2.314384723409057
Validation loss: 2.6789877546046466

Epoch: 5| Step: 3
Training loss: 2.5899200658356647
Validation loss: 2.7743143441723226

Epoch: 5| Step: 4
Training loss: 1.8942290074832921
Validation loss: 2.7141517251149723

Epoch: 5| Step: 5
Training loss: 2.179378255147557
Validation loss: 2.7354760450923674

Epoch: 5| Step: 6
Training loss: 3.349517269369599
Validation loss: 2.761513223513843

Epoch: 5| Step: 7
Training loss: 2.333132076666559
Validation loss: 2.7057581665325614

Epoch: 5| Step: 8
Training loss: 2.737769064025856
Validation loss: 2.7267238529122526

Epoch: 5| Step: 9
Training loss: 1.9856430567759982
Validation loss: 2.763428536026375

Epoch: 5| Step: 10
Training loss: 2.5353876839963547
Validation loss: 2.696276119301971

Epoch: 5| Step: 11
Training loss: 3.1034102232927707
Validation loss: 2.5987276090801386

Epoch: 42| Step: 0
Training loss: 3.02856845817009
Validation loss: 2.65509676114598

Epoch: 5| Step: 1
Training loss: 2.06197940151608
Validation loss: 2.669999388225595

Epoch: 5| Step: 2
Training loss: 2.5249985156668653
Validation loss: 2.6748759202314853

Epoch: 5| Step: 3
Training loss: 2.7730054062062557
Validation loss: 2.5799997622467643

Epoch: 5| Step: 4
Training loss: 2.1759338873258396
Validation loss: 2.647075606741713

Epoch: 5| Step: 5
Training loss: 1.7504782023332572
Validation loss: 2.67979804608954

Epoch: 5| Step: 6
Training loss: 2.5458402813589265
Validation loss: 2.678132717369234

Epoch: 5| Step: 7
Training loss: 2.7260271218980434
Validation loss: 2.6348707151274517

Epoch: 5| Step: 8
Training loss: 2.4238735689610764
Validation loss: 2.586991478527354

Epoch: 5| Step: 9
Training loss: 2.6014879004061258
Validation loss: 2.6284909121006925

Epoch: 5| Step: 10
Training loss: 2.8755520829571695
Validation loss: 2.6730894522495565

Epoch: 5| Step: 11
Training loss: 1.6097584980448427
Validation loss: 2.646260825236983

Epoch: 43| Step: 0
Training loss: 2.065475860151754
Validation loss: 2.678438627795953

Epoch: 5| Step: 1
Training loss: 2.356602131968491
Validation loss: 2.7114627120492765

Epoch: 5| Step: 2
Training loss: 2.8038566017378868
Validation loss: 2.6665320449366137

Epoch: 5| Step: 3
Training loss: 2.7652144477558402
Validation loss: 2.7100695687363965

Epoch: 5| Step: 4
Training loss: 2.910476564534172
Validation loss: 2.744676100139592

Epoch: 5| Step: 5
Training loss: 2.4228104292281234
Validation loss: 2.679526907183827

Epoch: 5| Step: 6
Training loss: 2.451885128734476
Validation loss: 2.6636199359834025

Epoch: 5| Step: 7
Training loss: 2.9611687481845084
Validation loss: 2.628352733758973

Epoch: 5| Step: 8
Training loss: 2.006044076589355
Validation loss: 2.6427651973726807

Epoch: 5| Step: 9
Training loss: 2.4696083025450144
Validation loss: 2.61144100183965

Epoch: 5| Step: 10
Training loss: 2.176380670733889
Validation loss: 2.656080117122497

Epoch: 5| Step: 11
Training loss: 2.5994096159046047
Validation loss: 2.688583828224646

Epoch: 44| Step: 0
Training loss: 2.1883256716374975
Validation loss: 2.7158379140953564

Epoch: 5| Step: 1
Training loss: 2.6034634263686067
Validation loss: 2.7034603858995894

Epoch: 5| Step: 2
Training loss: 1.925846121974043
Validation loss: 2.6483776982250284

Epoch: 5| Step: 3
Training loss: 2.508639665656854
Validation loss: 2.654720030329522

Epoch: 5| Step: 4
Training loss: 2.6364888861031464
Validation loss: 2.717809053901101

Epoch: 5| Step: 5
Training loss: 3.3206923323643136
Validation loss: 2.588651579295749

Epoch: 5| Step: 6
Training loss: 2.5646909326023963
Validation loss: 2.7326748639724667

Epoch: 5| Step: 7
Training loss: 2.7077933335547697
Validation loss: 2.6440667364731794

Epoch: 5| Step: 8
Training loss: 1.8988931995911116
Validation loss: 2.6841894873930308

Epoch: 5| Step: 9
Training loss: 2.181724772115449
Validation loss: 2.6545558126656936

Epoch: 5| Step: 10
Training loss: 2.788417709572775
Validation loss: 2.6452118351411853

Epoch: 5| Step: 11
Training loss: 2.4442500039516473
Validation loss: 2.6116851813612123

Epoch: 45| Step: 0
Training loss: 2.4939184605194544
Validation loss: 2.6830643414396103

Epoch: 5| Step: 1
Training loss: 1.814034700139594
Validation loss: 2.5962485799233024

Epoch: 5| Step: 2
Training loss: 2.289240807368481
Validation loss: 2.697862526388436

Epoch: 5| Step: 3
Training loss: 2.6561448917910604
Validation loss: 2.7052132619803833

Epoch: 5| Step: 4
Training loss: 2.7530040805341613
Validation loss: 2.6082453614371044

Epoch: 5| Step: 5
Training loss: 2.7733210149668728
Validation loss: 2.7039003858747934

Epoch: 5| Step: 6
Training loss: 2.1703805515943544
Validation loss: 2.7265122016413588

Epoch: 5| Step: 7
Training loss: 2.49774573735261
Validation loss: 2.636303689571832

Epoch: 5| Step: 8
Training loss: 2.0484481473714395
Validation loss: 2.596920209354166

Epoch: 5| Step: 9
Training loss: 2.8819424936882885
Validation loss: 2.6802693987305877

Epoch: 5| Step: 10
Training loss: 2.046513765797194
Validation loss: 2.68924913115223

Epoch: 5| Step: 11
Training loss: 2.804768935697522
Validation loss: 2.6462591359289065

Epoch: 46| Step: 0
Training loss: 2.727488275882128
Validation loss: 2.6572199976423025

Epoch: 5| Step: 1
Training loss: 2.606732703865952
Validation loss: 2.638083553541424

Epoch: 5| Step: 2
Training loss: 1.7252356492669947
Validation loss: 2.6548531561992395

Epoch: 5| Step: 3
Training loss: 2.807508150056608
Validation loss: 2.6655574959230917

Epoch: 5| Step: 4
Training loss: 2.0954428135162257
Validation loss: 2.7150114670869017

Epoch: 5| Step: 5
Training loss: 2.2098807785189076
Validation loss: 2.6090066349020233

Epoch: 5| Step: 6
Training loss: 2.191104208518593
Validation loss: 2.6807887907026458

Epoch: 5| Step: 7
Training loss: 2.659488185172849
Validation loss: 2.6893091618041565

Epoch: 5| Step: 8
Training loss: 2.707593014599635
Validation loss: 2.6560703329022015

Epoch: 5| Step: 9
Training loss: 2.3714273585712005
Validation loss: 2.6948871590222807

Epoch: 5| Step: 10
Training loss: 3.1096326251627477
Validation loss: 2.6614938622857234

Epoch: 5| Step: 11
Training loss: 2.9296624347886095
Validation loss: 2.6434131927821767

Epoch: 47| Step: 0
Training loss: 2.2796118092930024
Validation loss: 2.5983165714356593

Epoch: 5| Step: 1
Training loss: 2.6342424533573343
Validation loss: 2.683620402774305

Epoch: 5| Step: 2
Training loss: 2.5914765471203673
Validation loss: 2.6415870463970763

Epoch: 5| Step: 3
Training loss: 2.4223894126696
Validation loss: 2.6725589107423517

Epoch: 5| Step: 4
Training loss: 2.9546989000928607
Validation loss: 2.5683584950570073

Epoch: 5| Step: 5
Training loss: 1.7790130489357552
Validation loss: 2.656541505413608

Epoch: 5| Step: 6
Training loss: 2.795726604291121
Validation loss: 2.689291652540689

Epoch: 5| Step: 7
Training loss: 2.8223329529436687
Validation loss: 2.6383925712941223

Epoch: 5| Step: 8
Training loss: 2.2135238347550743
Validation loss: 2.6423424133750957

Epoch: 5| Step: 9
Training loss: 1.991049407798112
Validation loss: 2.6592231118397884

Epoch: 5| Step: 10
Training loss: 2.4037967412711807
Validation loss: 2.678811624331105

Epoch: 5| Step: 11
Training loss: 3.645475504435928
Validation loss: 2.672404963561328

Epoch: 48| Step: 0
Training loss: 2.5337469712753524
Validation loss: 2.6802226126377313

Epoch: 5| Step: 1
Training loss: 3.173740683891623
Validation loss: 2.6656008368615987

Epoch: 5| Step: 2
Training loss: 2.8972879685374453
Validation loss: 2.684617744397749

Epoch: 5| Step: 3
Training loss: 2.7245417323312555
Validation loss: 2.6353317267157843

Epoch: 5| Step: 4
Training loss: 2.6001488679669094
Validation loss: 2.635044321638086

Epoch: 5| Step: 5
Training loss: 2.5342204243173283
Validation loss: 2.7350900568829815

Epoch: 5| Step: 6
Training loss: 2.7450908712552624
Validation loss: 2.6409468633356123

Epoch: 5| Step: 7
Training loss: 2.0611020754912848
Validation loss: 2.6446188607440697

Epoch: 5| Step: 8
Training loss: 2.1153169934595155
Validation loss: 2.6721353013694435

Epoch: 5| Step: 9
Training loss: 2.419048210114649
Validation loss: 2.607173847874655

Epoch: 5| Step: 10
Training loss: 2.1672836183384296
Validation loss: 2.655817686691572

Epoch: 5| Step: 11
Training loss: 1.2583490021258503
Validation loss: 2.6601721099813918

Epoch: 49| Step: 0
Training loss: 2.6430397504515595
Validation loss: 2.6854872078480514

Epoch: 5| Step: 1
Training loss: 2.4000836914093315
Validation loss: 2.7464804451699614

Epoch: 5| Step: 2
Training loss: 2.9197234529676064
Validation loss: 2.709677708576977

Epoch: 5| Step: 3
Training loss: 2.616557213342716
Validation loss: 2.689668748791041

Epoch: 5| Step: 4
Training loss: 2.70062316484837
Validation loss: 2.754517406708915

Epoch: 5| Step: 5
Training loss: 2.6532630731714715
Validation loss: 2.6983850482495524

Epoch: 5| Step: 6
Training loss: 1.6377023004099573
Validation loss: 2.7106490004584267

Epoch: 5| Step: 7
Training loss: 2.1507874000647065
Validation loss: 2.801480197637251

Epoch: 5| Step: 8
Training loss: 3.0232149579455645
Validation loss: 2.6518660477064504

Epoch: 5| Step: 9
Training loss: 2.131342007169633
Validation loss: 2.6430019086786856

Epoch: 5| Step: 10
Training loss: 2.5537298898376557
Validation loss: 2.6795660237915016

Epoch: 5| Step: 11
Training loss: 2.0881073485070543
Validation loss: 2.696022441447533

Epoch: 50| Step: 0
Training loss: 2.7267032794623907
Validation loss: 2.6179622964638116

Epoch: 5| Step: 1
Training loss: 2.4093942287682153
Validation loss: 2.6632155958151107

Epoch: 5| Step: 2
Training loss: 2.0697479053997707
Validation loss: 2.6845047397961275

Epoch: 5| Step: 3
Training loss: 2.6550784051672465
Validation loss: 2.677924184937521

Epoch: 5| Step: 4
Training loss: 2.6398258241359227
Validation loss: 2.698252013928725

Epoch: 5| Step: 5
Training loss: 2.2322562248868616
Validation loss: 2.6654638704567994

Epoch: 5| Step: 6
Training loss: 2.336430526298081
Validation loss: 2.684879174660261

Epoch: 5| Step: 7
Training loss: 2.8079289908383247
Validation loss: 2.676461805686461

Epoch: 5| Step: 8
Training loss: 2.90920820731237
Validation loss: 2.663560512378088

Epoch: 5| Step: 9
Training loss: 2.3300742367554523
Validation loss: 2.709759957590492

Epoch: 5| Step: 10
Training loss: 2.3516098473937235
Validation loss: 2.7150347708775717

Epoch: 5| Step: 11
Training loss: 2.957587206240846
Validation loss: 2.61173699125644

Epoch: 51| Step: 0
Training loss: 2.294550439522509
Validation loss: 2.728892310138129

Epoch: 5| Step: 1
Training loss: 2.935148231103466
Validation loss: 2.6337319965377874

Epoch: 5| Step: 2
Training loss: 2.98972946678222
Validation loss: 2.6189696322272145

Epoch: 5| Step: 3
Training loss: 2.2089627886323706
Validation loss: 2.6663746686351057

Epoch: 5| Step: 4
Training loss: 2.1050105401361945
Validation loss: 2.6274523481675116

Epoch: 5| Step: 5
Training loss: 2.063240380768913
Validation loss: 2.640059246875896

Epoch: 5| Step: 6
Training loss: 2.303703485972476
Validation loss: 2.657193547382193

Epoch: 5| Step: 7
Training loss: 2.199572465275645
Validation loss: 2.5875284462131445

Epoch: 5| Step: 8
Training loss: 2.790736361307527
Validation loss: 2.688227845112044

Epoch: 5| Step: 9
Training loss: 2.889525993308144
Validation loss: 2.643192989433776

Epoch: 5| Step: 10
Training loss: 2.6347183890664785
Validation loss: 2.624480010558216

Epoch: 5| Step: 11
Training loss: 1.9093392151821011
Validation loss: 2.6603355440653087

Epoch: 52| Step: 0
Training loss: 2.7237094062766842
Validation loss: 2.692994157291141

Epoch: 5| Step: 1
Training loss: 2.2818480452379815
Validation loss: 2.6845075151969806

Epoch: 5| Step: 2
Training loss: 2.123683970717609
Validation loss: 2.6578765115387215

Epoch: 5| Step: 3
Training loss: 2.570988250301996
Validation loss: 2.6570128336560477

Epoch: 5| Step: 4
Training loss: 2.201722909621452
Validation loss: 2.6782353269033305

Epoch: 5| Step: 5
Training loss: 2.454708487301373
Validation loss: 2.650448113766503

Epoch: 5| Step: 6
Training loss: 2.434878969729092
Validation loss: 2.6328918980852443

Epoch: 5| Step: 7
Training loss: 2.2982394778217112
Validation loss: 2.6643591088287817

Epoch: 5| Step: 8
Training loss: 2.3506134247133508
Validation loss: 2.7095967805898207

Epoch: 5| Step: 9
Training loss: 2.78510608601169
Validation loss: 2.602283167947458

Epoch: 5| Step: 10
Training loss: 2.980734956984445
Validation loss: 2.626171198949841

Epoch: 5| Step: 11
Training loss: 1.835232603418074
Validation loss: 2.679315639455539

Epoch: 53| Step: 0
Training loss: 2.473350102127002
Validation loss: 2.662167972732348

Epoch: 5| Step: 1
Training loss: 1.9007102642609663
Validation loss: 2.6173166309593148

Epoch: 5| Step: 2
Training loss: 2.2417737200203063
Validation loss: 2.64879189054744

Epoch: 5| Step: 3
Training loss: 2.486800443342273
Validation loss: 2.7339258024820965

Epoch: 5| Step: 4
Training loss: 2.49784586606982
Validation loss: 2.677356477203856

Epoch: 5| Step: 5
Training loss: 2.390731609685018
Validation loss: 2.6787916415382758

Epoch: 5| Step: 6
Training loss: 2.4371518595594233
Validation loss: 2.6680289466959044

Epoch: 5| Step: 7
Training loss: 2.3764662984604907
Validation loss: 2.6677337215297405

Epoch: 5| Step: 8
Training loss: 3.1170079076750494
Validation loss: 2.6971805585797592

Epoch: 5| Step: 9
Training loss: 2.238357729046265
Validation loss: 2.624741560460269

Epoch: 5| Step: 10
Training loss: 2.955433583989422
Validation loss: 2.6023796142439983

Epoch: 5| Step: 11
Training loss: 0.913937323712604
Validation loss: 2.6497113700445674

Epoch: 54| Step: 0
Training loss: 2.2723062853612377
Validation loss: 2.7322645126158864

Epoch: 5| Step: 1
Training loss: 2.173152081570687
Validation loss: 2.6699831159554317

Epoch: 5| Step: 2
Training loss: 2.742622623536285
Validation loss: 2.624610077190348

Epoch: 5| Step: 3
Training loss: 2.871505271847001
Validation loss: 2.675155655619255

Epoch: 5| Step: 4
Training loss: 2.414661123379278
Validation loss: 2.6433135835042862

Epoch: 5| Step: 5
Training loss: 1.7161498081776767
Validation loss: 2.693304126330524

Epoch: 5| Step: 6
Training loss: 2.0439906873920104
Validation loss: 2.616871202628745

Epoch: 5| Step: 7
Training loss: 3.226459640082614
Validation loss: 2.6597707583932113

Epoch: 5| Step: 8
Training loss: 2.7520483364639747
Validation loss: 2.694999112693485

Epoch: 5| Step: 9
Training loss: 2.2074412817398112
Validation loss: 2.6760856251108742

Epoch: 5| Step: 10
Training loss: 2.653231532605625
Validation loss: 2.7048625727040023

Epoch: 5| Step: 11
Training loss: 2.3946964275398295
Validation loss: 2.7148552324889255

Epoch: 55| Step: 0
Training loss: 2.348172605477188
Validation loss: 2.694669538093958

Epoch: 5| Step: 1
Training loss: 2.6769762030118422
Validation loss: 2.6281322305272172

Epoch: 5| Step: 2
Training loss: 2.369806332944543
Validation loss: 2.6462615272380225

Epoch: 5| Step: 3
Training loss: 2.444461954901815
Validation loss: 2.667572641825565

Epoch: 5| Step: 4
Training loss: 2.3284074240792405
Validation loss: 2.6810723239951004

Epoch: 5| Step: 5
Training loss: 2.657316823910299
Validation loss: 2.6295776265658217

Epoch: 5| Step: 6
Training loss: 2.713089849793135
Validation loss: 2.6075166720756133

Epoch: 5| Step: 7
Training loss: 2.4268734449626725
Validation loss: 2.623943172884026

Epoch: 5| Step: 8
Training loss: 3.213993446746963
Validation loss: 2.660316735055938

Epoch: 5| Step: 9
Training loss: 2.011675491608629
Validation loss: 2.5911108650391115

Epoch: 5| Step: 10
Training loss: 2.1534488561760115
Validation loss: 2.7013212481259297

Epoch: 5| Step: 11
Training loss: 1.7227382510643623
Validation loss: 2.646638917809537

Epoch: 56| Step: 0
Training loss: 2.269190436033378
Validation loss: 2.6692047197791626

Epoch: 5| Step: 1
Training loss: 2.1070845990752036
Validation loss: 2.6353696465852448

Epoch: 5| Step: 2
Training loss: 2.878931757116481
Validation loss: 2.681446847306935

Epoch: 5| Step: 3
Training loss: 2.6972534267804367
Validation loss: 2.740309888470377

Epoch: 5| Step: 4
Training loss: 3.0242371598247293
Validation loss: 2.6895235043664236

Epoch: 5| Step: 5
Training loss: 2.339753876808526
Validation loss: 2.7357822502701303

Epoch: 5| Step: 6
Training loss: 3.075347111657111
Validation loss: 2.686263239712378

Epoch: 5| Step: 7
Training loss: 1.9799910050004805
Validation loss: 2.655844530312003

Epoch: 5| Step: 8
Training loss: 2.147786544671837
Validation loss: 2.6483235855135203

Epoch: 5| Step: 9
Training loss: 1.8742548415543943
Validation loss: 2.6837424727998975

Epoch: 5| Step: 10
Training loss: 2.231333336222185
Validation loss: 2.6753738111681575

Epoch: 5| Step: 11
Training loss: 2.4748490721026806
Validation loss: 2.6870525342450233

Epoch: 57| Step: 0
Training loss: 2.708507405091195
Validation loss: 2.657857371165844

Epoch: 5| Step: 1
Training loss: 2.798149798677226
Validation loss: 2.69251738756068

Epoch: 5| Step: 2
Training loss: 3.038399199837112
Validation loss: 2.6478777925102364

Epoch: 5| Step: 3
Training loss: 2.833217020078294
Validation loss: 2.5733777468333097

Epoch: 5| Step: 4
Training loss: 1.7466300123799787
Validation loss: 2.6210413442907177

Epoch: 5| Step: 5
Training loss: 2.5429714689225578
Validation loss: 2.715353521335062

Epoch: 5| Step: 6
Training loss: 2.464864836540647
Validation loss: 2.6917505731486076

Epoch: 5| Step: 7
Training loss: 2.363611422087049
Validation loss: 2.67279807164879

Epoch: 5| Step: 8
Training loss: 2.3583020934966483
Validation loss: 2.6786361685755353

Epoch: 5| Step: 9
Training loss: 2.3831675780839903
Validation loss: 2.6543515246306586

Epoch: 5| Step: 10
Training loss: 2.229928453948468
Validation loss: 2.715016757932104

Epoch: 5| Step: 11
Training loss: 1.6816779120339893
Validation loss: 2.773662733504851

Epoch: 58| Step: 0
Training loss: 2.0506956827386955
Validation loss: 2.6935193809836195

Epoch: 5| Step: 1
Training loss: 2.4300343551090995
Validation loss: 2.8076061339229876

Epoch: 5| Step: 2
Training loss: 2.0040469947451873
Validation loss: 2.7791602198732366

Epoch: 5| Step: 3
Training loss: 2.5147432476058853
Validation loss: 2.7976445963117142

Epoch: 5| Step: 4
Training loss: 2.921805477845199
Validation loss: 2.852794795515377

Epoch: 5| Step: 5
Training loss: 2.806945741722247
Validation loss: 2.786829812549793

Epoch: 5| Step: 6
Training loss: 2.553422900671581
Validation loss: 2.7938278868682698

Epoch: 5| Step: 7
Training loss: 2.0244631726812727
Validation loss: 2.7435944363195466

Epoch: 5| Step: 8
Training loss: 2.699305222446962
Validation loss: 2.686534682351673

Epoch: 5| Step: 9
Training loss: 1.9664243252468698
Validation loss: 2.7108016589280726

Epoch: 5| Step: 10
Training loss: 2.30895445921583
Validation loss: 2.624341621032214

Epoch: 5| Step: 11
Training loss: 3.6060816945381458
Validation loss: 2.6035621068477237

Epoch: 59| Step: 0
Training loss: 2.214305132679679
Validation loss: 2.651492308491406

Epoch: 5| Step: 1
Training loss: 2.230044135781662
Validation loss: 2.7333200944797

Epoch: 5| Step: 2
Training loss: 3.3909620829436333
Validation loss: 2.634333792651146

Epoch: 5| Step: 3
Training loss: 2.2451912036855965
Validation loss: 2.7202246419328096

Epoch: 5| Step: 4
Training loss: 2.405451059849393
Validation loss: 2.6732043181139287

Epoch: 5| Step: 5
Training loss: 2.3952903353367963
Validation loss: 2.654866112382175

Epoch: 5| Step: 6
Training loss: 2.872512072611672
Validation loss: 2.6153285014597087

Epoch: 5| Step: 7
Training loss: 2.2012016612544887
Validation loss: 2.6150322043743763

Epoch: 5| Step: 8
Training loss: 2.46059441975492
Validation loss: 2.6613405926982217

Epoch: 5| Step: 9
Training loss: 2.0826870742429717
Validation loss: 2.6860519100763063

Epoch: 5| Step: 10
Training loss: 2.2412040228311088
Validation loss: 2.7814903298314526

Epoch: 5| Step: 11
Training loss: 3.263808187654909
Validation loss: 2.7012877293490405

Epoch: 60| Step: 0
Training loss: 2.211514562777499
Validation loss: 2.770623239760037

Epoch: 5| Step: 1
Training loss: 2.1638599948262534
Validation loss: 2.8200333739818535

Epoch: 5| Step: 2
Training loss: 2.457623772671828
Validation loss: 2.7773578462810806

Epoch: 5| Step: 3
Training loss: 2.2147676431272
Validation loss: 2.8509058609993394

Epoch: 5| Step: 4
Training loss: 2.543670698049806
Validation loss: 2.835271079207477

Epoch: 5| Step: 5
Training loss: 2.2657826335921962
Validation loss: 2.8444461005476347

Epoch: 5| Step: 6
Training loss: 2.226175696253739
Validation loss: 2.7101940890988216

Epoch: 5| Step: 7
Training loss: 2.712911541214815
Validation loss: 2.742750597284192

Epoch: 5| Step: 8
Training loss: 2.8749588673178494
Validation loss: 2.7361719276126073

Epoch: 5| Step: 9
Training loss: 2.6111939081181728
Validation loss: 2.6425127207877823

Epoch: 5| Step: 10
Training loss: 2.6259487798944035
Validation loss: 2.68878461756664

Epoch: 5| Step: 11
Training loss: 3.4233203082655583
Validation loss: 2.7127964780659766

Epoch: 61| Step: 0
Training loss: 2.795921887863366
Validation loss: 2.671685139563844

Epoch: 5| Step: 1
Training loss: 2.5693236886823194
Validation loss: 2.685699998593906

Epoch: 5| Step: 2
Training loss: 2.206106995008468
Validation loss: 2.6148847251730816

Epoch: 5| Step: 3
Training loss: 3.1221706552044406
Validation loss: 2.641722347673506

Epoch: 5| Step: 4
Training loss: 2.582802615461226
Validation loss: 2.6280415337636986

Epoch: 5| Step: 5
Training loss: 2.43796603320449
Validation loss: 2.7612917298824278

Epoch: 5| Step: 6
Training loss: 2.088853719203308
Validation loss: 2.615109570549631

Epoch: 5| Step: 7
Training loss: 2.0241888705852698
Validation loss: 2.6436528560024533

Epoch: 5| Step: 8
Training loss: 2.749113633622453
Validation loss: 2.7161052928811613

Epoch: 5| Step: 9
Training loss: 1.9348775281763309
Validation loss: 2.7173851394652497

Epoch: 5| Step: 10
Training loss: 2.6419951366059258
Validation loss: 2.6545910535404826

Epoch: 5| Step: 11
Training loss: 2.575372509724132
Validation loss: 2.6799437694142463

Epoch: 62| Step: 0
Training loss: 2.929610676076073
Validation loss: 2.684875052834477

Epoch: 5| Step: 1
Training loss: 2.8082835486401634
Validation loss: 2.6352606389193727

Epoch: 5| Step: 2
Training loss: 2.486860076023524
Validation loss: 2.6717973590002915

Epoch: 5| Step: 3
Training loss: 2.322851160149318
Validation loss: 2.732627695478893

Epoch: 5| Step: 4
Training loss: 2.043839861559537
Validation loss: 2.667057456995662

Epoch: 5| Step: 5
Training loss: 2.8980367131510745
Validation loss: 2.716557294500578

Epoch: 5| Step: 6
Training loss: 2.5519103841503
Validation loss: 2.6872601032382413

Epoch: 5| Step: 7
Training loss: 2.419992613662923
Validation loss: 2.730485387632282

Epoch: 5| Step: 8
Training loss: 2.3257095812799844
Validation loss: 2.683870829678483

Epoch: 5| Step: 9
Training loss: 2.0967595121186777
Validation loss: 2.6933807047625673

Epoch: 5| Step: 10
Training loss: 2.455938002011973
Validation loss: 2.596579513539976

Epoch: 5| Step: 11
Training loss: 1.6215444650637723
Validation loss: 2.6723667941426696

Epoch: 63| Step: 0
Training loss: 2.5121986322290355
Validation loss: 2.695686273872711

Epoch: 5| Step: 1
Training loss: 1.9283968049167513
Validation loss: 2.7141148492057607

Epoch: 5| Step: 2
Training loss: 2.527204412425199
Validation loss: 2.698118100446525

Epoch: 5| Step: 3
Training loss: 2.5537612589150536
Validation loss: 2.7318108952399665

Epoch: 5| Step: 4
Training loss: 2.496398429602881
Validation loss: 2.789975754986862

Epoch: 5| Step: 5
Training loss: 1.927125906259225
Validation loss: 2.7534701892663014

Epoch: 5| Step: 6
Training loss: 2.81975027804843
Validation loss: 2.6689911275561102

Epoch: 5| Step: 7
Training loss: 2.1534998950767803
Validation loss: 2.65440046582193

Epoch: 5| Step: 8
Training loss: 3.1063042434469366
Validation loss: 2.671563143311945

Epoch: 5| Step: 9
Training loss: 2.602885966414298
Validation loss: 2.60430466985616

Epoch: 5| Step: 10
Training loss: 1.9232199080203265
Validation loss: 2.6556105610727347

Epoch: 5| Step: 11
Training loss: 2.011994633692113
Validation loss: 2.651040159023933

Epoch: 64| Step: 0
Training loss: 2.524336616316855
Validation loss: 2.633674638898408

Epoch: 5| Step: 1
Training loss: 3.0411035896176974
Validation loss: 2.625494675725758

Epoch: 5| Step: 2
Training loss: 2.5112178890440555
Validation loss: 2.627570823455357

Epoch: 5| Step: 3
Training loss: 2.5718942894102157
Validation loss: 2.6282665235748146

Epoch: 5| Step: 4
Training loss: 2.2210695204350794
Validation loss: 2.734536073572652

Epoch: 5| Step: 5
Training loss: 1.8830225657176043
Validation loss: 2.629732792736816

Epoch: 5| Step: 6
Training loss: 2.6316449664016255
Validation loss: 2.660885397699084

Epoch: 5| Step: 7
Training loss: 2.5412765474523042
Validation loss: 2.6511758996421384

Epoch: 5| Step: 8
Training loss: 2.7807065454222513
Validation loss: 2.758038235107953

Epoch: 5| Step: 9
Training loss: 2.227076956225675
Validation loss: 2.7092975819521876

Epoch: 5| Step: 10
Training loss: 2.1524054489015727
Validation loss: 2.7024816085473113

Epoch: 5| Step: 11
Training loss: 2.281228992940253
Validation loss: 2.7328031145345064

Epoch: 65| Step: 0
Training loss: 2.7645684934408004
Validation loss: 2.7187791873929044

Epoch: 5| Step: 1
Training loss: 2.530874718997706
Validation loss: 2.69240930078626

Epoch: 5| Step: 2
Training loss: 2.6855727093927846
Validation loss: 2.7500091646504137

Epoch: 5| Step: 3
Training loss: 1.9861664382709512
Validation loss: 2.7147466134456764

Epoch: 5| Step: 4
Training loss: 3.0491319953369995
Validation loss: 2.7003210993849374

Epoch: 5| Step: 5
Training loss: 2.189388114243068
Validation loss: 2.6776583767676376

Epoch: 5| Step: 6
Training loss: 2.06250462387029
Validation loss: 2.646364967120441

Epoch: 5| Step: 7
Training loss: 2.7697075490431406
Validation loss: 2.59926962787873

Epoch: 5| Step: 8
Training loss: 1.687456836854848
Validation loss: 2.623791706059055

Epoch: 5| Step: 9
Training loss: 2.6129856370077857
Validation loss: 2.6315394416780067

Epoch: 5| Step: 10
Training loss: 2.0443558661073657
Validation loss: 2.637696385868875

Epoch: 5| Step: 11
Training loss: 2.8748397782503203
Validation loss: 2.6399509389730587

Epoch: 66| Step: 0
Training loss: 2.3748162851051213
Validation loss: 2.6245095120206323

Epoch: 5| Step: 1
Training loss: 2.2291022555828897
Validation loss: 2.6762073186909396

Epoch: 5| Step: 2
Training loss: 3.126693266841522
Validation loss: 2.738172092701789

Epoch: 5| Step: 3
Training loss: 2.2677057642667346
Validation loss: 2.662822404931147

Epoch: 5| Step: 4
Training loss: 2.310110146014417
Validation loss: 2.725667589842298

Epoch: 5| Step: 5
Training loss: 2.3264058569547132
Validation loss: 2.739039186943146

Epoch: 5| Step: 6
Training loss: 2.9653918095227105
Validation loss: 2.7603438073865387

Epoch: 5| Step: 7
Training loss: 2.334901203458795
Validation loss: 2.785629100350054

Epoch: 5| Step: 8
Training loss: 2.690522911270554
Validation loss: 2.7217856994356846

Epoch: 5| Step: 9
Training loss: 2.4625934176467714
Validation loss: 2.67023295609013

Epoch: 5| Step: 10
Training loss: 2.074353804564798
Validation loss: 2.637167282572448

Epoch: 5| Step: 11
Training loss: 1.6149976711433556
Validation loss: 2.6883547998159774

Epoch: 67| Step: 0
Training loss: 2.3617672949624398
Validation loss: 2.6718075503931873

Epoch: 5| Step: 1
Training loss: 2.5646321799994953
Validation loss: 2.689473525380627

Epoch: 5| Step: 2
Training loss: 2.105951200849076
Validation loss: 2.7097637372823504

Epoch: 5| Step: 3
Training loss: 2.316130906412863
Validation loss: 2.683264370193986

Epoch: 5| Step: 4
Training loss: 2.165180674848251
Validation loss: 2.6838592220302955

Epoch: 5| Step: 5
Training loss: 2.4621689394791018
Validation loss: 2.628614846904729

Epoch: 5| Step: 6
Training loss: 2.215835268618267
Validation loss: 2.744831256231083

Epoch: 5| Step: 7
Training loss: 3.306869327682334
Validation loss: 2.6633866050279877

Epoch: 5| Step: 8
Training loss: 2.4741144927414656
Validation loss: 2.7267421054799836

Epoch: 5| Step: 9
Training loss: 2.4629297336555918
Validation loss: 2.703440917853705

Epoch: 5| Step: 10
Training loss: 2.1947650702020263
Validation loss: 2.6974289108303786

Epoch: 5| Step: 11
Training loss: 0.6502341692272311
Validation loss: 2.6920708295796176

Epoch: 68| Step: 0
Training loss: 1.8323298294346626
Validation loss: 2.6546804952276455

Epoch: 5| Step: 1
Training loss: 2.887586161331178
Validation loss: 2.720456293122949

Epoch: 5| Step: 2
Training loss: 2.942961141253935
Validation loss: 2.6907152046326845

Epoch: 5| Step: 3
Training loss: 1.7425406743779532
Validation loss: 2.70211829474387

Epoch: 5| Step: 4
Training loss: 2.5256207826650443
Validation loss: 2.6715153903892697

Epoch: 5| Step: 5
Training loss: 1.785159856012154
Validation loss: 2.6618559491181224

Epoch: 5| Step: 6
Training loss: 2.8848386844379172
Validation loss: 2.6446732013869836

Epoch: 5| Step: 7
Training loss: 1.9323094890694532
Validation loss: 2.696403982699379

Epoch: 5| Step: 8
Training loss: 2.5933111348056057
Validation loss: 2.6684746883886596

Epoch: 5| Step: 9
Training loss: 3.1277328748474296
Validation loss: 2.6783985452263765

Epoch: 5| Step: 10
Training loss: 2.5999529100702037
Validation loss: 2.7053537900820874

Epoch: 5| Step: 11
Training loss: 2.6286332554091434
Validation loss: 2.6592562586584085

Epoch: 69| Step: 0
Training loss: 2.963739282402826
Validation loss: 2.671997632638564

Epoch: 5| Step: 1
Training loss: 1.869453364151485
Validation loss: 2.7192514695171783

Epoch: 5| Step: 2
Training loss: 2.3035547608610045
Validation loss: 2.677524622430861

Epoch: 5| Step: 3
Training loss: 2.184220498751055
Validation loss: 2.7024535335588977

Epoch: 5| Step: 4
Training loss: 2.5641632264859795
Validation loss: 2.7290632881114782

Epoch: 5| Step: 5
Training loss: 1.9747742415216523
Validation loss: 2.7082086693364786

Epoch: 5| Step: 6
Training loss: 1.8667631425222486
Validation loss: 2.72263086964815

Epoch: 5| Step: 7
Training loss: 2.591694764437772
Validation loss: 2.7498111587767267

Epoch: 5| Step: 8
Training loss: 2.8823900197496086
Validation loss: 2.692090793141315

Epoch: 5| Step: 9
Training loss: 2.2113166187487696
Validation loss: 2.7288738571706754

Epoch: 5| Step: 10
Training loss: 2.7380119332777277
Validation loss: 2.741532670508149

Epoch: 5| Step: 11
Training loss: 1.6742884248946859
Validation loss: 2.6134504673050856

Epoch: 70| Step: 0
Training loss: 2.3697408370271362
Validation loss: 2.7403363702579577

Epoch: 5| Step: 1
Training loss: 2.2497731200377267
Validation loss: 2.673896861115878

Epoch: 5| Step: 2
Training loss: 1.8904102928632078
Validation loss: 2.7221410511094413

Epoch: 5| Step: 3
Training loss: 2.2557993430865104
Validation loss: 2.7084959323686553

Epoch: 5| Step: 4
Training loss: 2.8839706120891804
Validation loss: 2.717395671688938

Epoch: 5| Step: 5
Training loss: 2.830087728859222
Validation loss: 2.7060546177497304

Epoch: 5| Step: 6
Training loss: 2.3913838297937295
Validation loss: 2.7715607288283395

Epoch: 5| Step: 7
Training loss: 1.9514810586372209
Validation loss: 2.6947805570814065

Epoch: 5| Step: 8
Training loss: 2.352930222513843
Validation loss: 2.7581052867877323

Epoch: 5| Step: 9
Training loss: 2.386718949787737
Validation loss: 2.625391889262603

Epoch: 5| Step: 10
Training loss: 2.8132027489817832
Validation loss: 2.706774396210768

Epoch: 5| Step: 11
Training loss: 2.6849809417900676
Validation loss: 2.709074492400666

Epoch: 71| Step: 0
Training loss: 1.8319290230215781
Validation loss: 2.6686929638594785

Epoch: 5| Step: 1
Training loss: 2.0908709417036815
Validation loss: 2.697035510582455

Epoch: 5| Step: 2
Training loss: 2.267228604765
Validation loss: 2.6851897770987327

Epoch: 5| Step: 3
Training loss: 2.411570525117092
Validation loss: 2.6734771200900997

Epoch: 5| Step: 4
Training loss: 2.7036088278955783
Validation loss: 2.742253584396037

Epoch: 5| Step: 5
Training loss: 1.9933006617357483
Validation loss: 2.7370825886203933

Epoch: 5| Step: 6
Training loss: 2.92345430663929
Validation loss: 2.7301695682044547

Epoch: 5| Step: 7
Training loss: 2.4791287865402807
Validation loss: 2.6986603037275563

Epoch: 5| Step: 8
Training loss: 2.0554937949081147
Validation loss: 2.6713570079663156

Epoch: 5| Step: 9
Training loss: 2.7704733899209812
Validation loss: 2.7291574926925883

Epoch: 5| Step: 10
Training loss: 2.991928527620954
Validation loss: 2.7370342547930884

Epoch: 5| Step: 11
Training loss: 1.9500391882846733
Validation loss: 2.6545581104283977

Epoch: 72| Step: 0
Training loss: 2.6389380489477356
Validation loss: 2.7736028380205067

Epoch: 5| Step: 1
Training loss: 2.077882221926508
Validation loss: 2.789357875851472

Epoch: 5| Step: 2
Training loss: 2.1827679268416813
Validation loss: 2.755437363093491

Epoch: 5| Step: 3
Training loss: 2.104301851166499
Validation loss: 2.9222213553434213

Epoch: 5| Step: 4
Training loss: 2.32175511170021
Validation loss: 2.834910922431118

Epoch: 5| Step: 5
Training loss: 2.2554724159118438
Validation loss: 2.906769859825527

Epoch: 5| Step: 6
Training loss: 2.5651519822571207
Validation loss: 2.8828225656831616

Epoch: 5| Step: 7
Training loss: 3.250995190178309
Validation loss: 2.844197168230443

Epoch: 5| Step: 8
Training loss: 2.7170474981003907
Validation loss: 2.8123740168011553

Epoch: 5| Step: 9
Training loss: 2.2835200263595046
Validation loss: 2.6750847422763036

Epoch: 5| Step: 10
Training loss: 2.208901913939429
Validation loss: 2.6988821413236233

Epoch: 5| Step: 11
Training loss: 2.9003071063311823
Validation loss: 2.7336310473602574

Epoch: 73| Step: 0
Training loss: 2.266877558191127
Validation loss: 2.696411133733549

Epoch: 5| Step: 1
Training loss: 2.6157348245149348
Validation loss: 2.6756546213300982

Epoch: 5| Step: 2
Training loss: 2.4917879651333887
Validation loss: 2.718150222508088

Epoch: 5| Step: 3
Training loss: 2.8318046110822475
Validation loss: 2.7284058512598794

Epoch: 5| Step: 4
Training loss: 2.6166816791986576
Validation loss: 2.6708076085018684

Epoch: 5| Step: 5
Training loss: 3.0144613125739204
Validation loss: 2.6642327986026477

Epoch: 5| Step: 6
Training loss: 2.6697118379344653
Validation loss: 2.678222289037549

Epoch: 5| Step: 7
Training loss: 2.3696291577857633
Validation loss: 2.638096285183771

Epoch: 5| Step: 8
Training loss: 1.929546026688689
Validation loss: 2.68641971714704

Epoch: 5| Step: 9
Training loss: 2.2759331183369746
Validation loss: 2.6535372027073865

Epoch: 5| Step: 10
Training loss: 2.5497097785201746
Validation loss: 2.6906189341371505

Epoch: 5| Step: 11
Training loss: 1.8655128790360482
Validation loss: 2.684377523442519

Epoch: 74| Step: 0
Training loss: 2.1226551357767596
Validation loss: 2.6606810169328416

Epoch: 5| Step: 1
Training loss: 1.8150388759726648
Validation loss: 2.699330814756878

Epoch: 5| Step: 2
Training loss: 2.780050469084462
Validation loss: 2.717033608107396

Epoch: 5| Step: 3
Training loss: 2.4410648198755363
Validation loss: 2.721385431186131

Epoch: 5| Step: 4
Training loss: 2.9739342647899103
Validation loss: 2.7013730783062497

Epoch: 5| Step: 5
Training loss: 1.979433951817424
Validation loss: 2.7332148243249055

Epoch: 5| Step: 6
Training loss: 2.389163798647719
Validation loss: 2.6609185126107486

Epoch: 5| Step: 7
Training loss: 2.5243722229668646
Validation loss: 2.704082778712965

Epoch: 5| Step: 8
Training loss: 2.2993486021019165
Validation loss: 2.650933120443916

Epoch: 5| Step: 9
Training loss: 2.240854751108149
Validation loss: 2.685145278033653

Epoch: 5| Step: 10
Training loss: 2.418484880767245
Validation loss: 2.672968285692262

Epoch: 5| Step: 11
Training loss: 1.8379024298488447
Validation loss: 2.660855179515903

Epoch: 75| Step: 0
Training loss: 2.496478652529723
Validation loss: 2.605404343540566

Epoch: 5| Step: 1
Training loss: 2.3576759131971303
Validation loss: 2.6883455062794788

Epoch: 5| Step: 2
Training loss: 2.1983328571372085
Validation loss: 2.647293804113101

Epoch: 5| Step: 3
Training loss: 2.224191145730641
Validation loss: 2.6777609302809453

Epoch: 5| Step: 4
Training loss: 2.388425725448436
Validation loss: 2.68615035241318

Epoch: 5| Step: 5
Training loss: 2.4385876307554617
Validation loss: 2.6868842975845726

Epoch: 5| Step: 6
Training loss: 1.99959524350502
Validation loss: 2.6003339270279033

Epoch: 5| Step: 7
Training loss: 2.9545003927569176
Validation loss: 2.6611760631161334

Epoch: 5| Step: 8
Training loss: 2.8129604386559297
Validation loss: 2.663986902292328

Epoch: 5| Step: 9
Training loss: 2.509165556303615
Validation loss: 2.63148084520388

Epoch: 5| Step: 10
Training loss: 2.253016780629929
Validation loss: 2.69836023665897

Epoch: 5| Step: 11
Training loss: 2.849708100478814
Validation loss: 2.735182524831557

Testing loss: 2.303829245884129
