Epoch: 1| Step: 0
Training loss: 4.330043792724609
Validation loss: 3.9854344526926675

Epoch: 6| Step: 1
Training loss: 3.667492389678955
Validation loss: 3.9602554639180503

Epoch: 6| Step: 2
Training loss: 4.183466911315918
Validation loss: 3.937608242034912

Epoch: 6| Step: 3
Training loss: 4.41145133972168
Validation loss: 3.9154529571533203

Epoch: 6| Step: 4
Training loss: 4.427026271820068
Validation loss: 3.893324613571167

Epoch: 6| Step: 5
Training loss: 3.594573974609375
Validation loss: 3.8793801069259644

Epoch: 6| Step: 6
Training loss: 3.9490928649902344
Validation loss: 3.864535649617513

Epoch: 6| Step: 7
Training loss: 3.690021276473999
Validation loss: 3.851961851119995

Epoch: 6| Step: 8
Training loss: 3.658151865005493
Validation loss: 3.8419382572174072

Epoch: 6| Step: 9
Training loss: 4.45820951461792
Validation loss: 3.8279343843460083

Epoch: 6| Step: 10
Training loss: 4.029400825500488
Validation loss: 3.8144580920537314

Epoch: 6| Step: 11
Training loss: 2.855548620223999
Validation loss: 3.798404335975647

Epoch: 6| Step: 12
Training loss: 4.937800407409668
Validation loss: 3.7824313243230185

Epoch: 6| Step: 13
Training loss: 3.905371904373169
Validation loss: 3.765562097231547

Epoch: 2| Step: 0
Training loss: 3.591749906539917
Validation loss: 3.7466601928075156

Epoch: 6| Step: 1
Training loss: 4.307784080505371
Validation loss: 3.7272212902704873

Epoch: 6| Step: 2
Training loss: 3.258833408355713
Validation loss: 3.705841382344564

Epoch: 6| Step: 3
Training loss: 4.522091865539551
Validation loss: 3.688810427983602

Epoch: 6| Step: 4
Training loss: 2.590817928314209
Validation loss: 3.66425621509552

Epoch: 6| Step: 5
Training loss: 3.6220703125
Validation loss: 3.646708051363627

Epoch: 6| Step: 6
Training loss: 4.795042991638184
Validation loss: 3.6210123697916665

Epoch: 6| Step: 7
Training loss: 4.0999274253845215
Validation loss: 3.598079204559326

Epoch: 6| Step: 8
Training loss: 3.732055187225342
Validation loss: 3.5742711623509726

Epoch: 6| Step: 9
Training loss: 3.995148181915283
Validation loss: 3.543700615564982

Epoch: 6| Step: 10
Training loss: 4.216341018676758
Validation loss: 3.522415359814962

Epoch: 6| Step: 11
Training loss: 2.892124891281128
Validation loss: 3.4899445374806723

Epoch: 6| Step: 12
Training loss: 3.165478467941284
Validation loss: 3.463541030883789

Epoch: 6| Step: 13
Training loss: 3.610172986984253
Validation loss: 3.4328471422195435

Epoch: 3| Step: 0
Training loss: 3.6693105697631836
Validation loss: 3.4024309317270913

Epoch: 6| Step: 1
Training loss: 3.463935375213623
Validation loss: 3.368442932764689

Epoch: 6| Step: 2
Training loss: 4.834018707275391
Validation loss: 3.341479937235514

Epoch: 6| Step: 3
Training loss: 3.4708919525146484
Validation loss: 3.304896831512451

Epoch: 6| Step: 4
Training loss: 2.812424659729004
Validation loss: 3.2664146423339844

Epoch: 6| Step: 5
Training loss: 3.329397678375244
Validation loss: 3.2203363180160522

Epoch: 6| Step: 6
Training loss: 3.580056667327881
Validation loss: 3.177819609642029

Epoch: 6| Step: 7
Training loss: 2.9753475189208984
Validation loss: 3.1362759272257485

Epoch: 6| Step: 8
Training loss: 3.2562050819396973
Validation loss: 3.090622862180074

Epoch: 6| Step: 9
Training loss: 2.901719093322754
Validation loss: 3.0433759689331055

Epoch: 6| Step: 10
Training loss: 3.306154727935791
Validation loss: 3.0051008065541587

Epoch: 6| Step: 11
Training loss: 2.1013410091400146
Validation loss: 2.9523364305496216

Epoch: 6| Step: 12
Training loss: 3.2731924057006836
Validation loss: 2.9062232971191406

Epoch: 6| Step: 13
Training loss: 2.9090723991394043
Validation loss: 2.8618587652842202

Epoch: 4| Step: 0
Training loss: 3.326622486114502
Validation loss: 2.8145128091176352

Epoch: 6| Step: 1
Training loss: 2.747999668121338
Validation loss: 2.758243978023529

Epoch: 6| Step: 2
Training loss: 2.8225936889648438
Validation loss: 2.7029829819997153

Epoch: 6| Step: 3
Training loss: 2.306715965270996
Validation loss: 2.6274898449579873

Epoch: 6| Step: 4
Training loss: 2.994976043701172
Validation loss: 2.575183351834615

Epoch: 6| Step: 5
Training loss: 2.6624860763549805
Validation loss: 2.5242548187573752

Epoch: 6| Step: 6
Training loss: 1.8778791427612305
Validation loss: 2.4845868349075317

Epoch: 6| Step: 7
Training loss: 2.0949056148529053
Validation loss: 2.419073164463043

Epoch: 6| Step: 8
Training loss: 2.3003063201904297
Validation loss: 2.3715368111928306

Epoch: 6| Step: 9
Training loss: 2.4246633052825928
Validation loss: 2.326484481493632

Epoch: 6| Step: 10
Training loss: 2.6337668895721436
Validation loss: 2.274959166844686

Epoch: 6| Step: 11
Training loss: 2.3907382488250732
Validation loss: 2.2184493144353232

Epoch: 6| Step: 12
Training loss: 1.690181016921997
Validation loss: 2.2017046411832175

Epoch: 6| Step: 13
Training loss: 1.8326005935668945
Validation loss: 2.1542811592419944

Epoch: 5| Step: 0
Training loss: 1.8722864389419556
Validation loss: 2.1362321972846985

Epoch: 6| Step: 1
Training loss: 1.9561715126037598
Validation loss: 2.140545070171356

Epoch: 6| Step: 2
Training loss: 1.8252545595169067
Validation loss: 2.140837530295054

Epoch: 6| Step: 3
Training loss: 2.141968011856079
Validation loss: 2.1396411061286926

Epoch: 6| Step: 4
Training loss: 1.935491919517517
Validation loss: 2.1398330529530845

Epoch: 6| Step: 5
Training loss: 2.258464813232422
Validation loss: 2.1808839639027915

Epoch: 6| Step: 6
Training loss: 2.1320977210998535
Validation loss: 2.210186799367269

Epoch: 6| Step: 7
Training loss: 1.6002833843231201
Validation loss: 2.204563240210215

Epoch: 6| Step: 8
Training loss: 2.808440923690796
Validation loss: 2.225774804751078

Epoch: 6| Step: 9
Training loss: 2.0903067588806152
Validation loss: 2.2255603472391763

Epoch: 6| Step: 10
Training loss: 3.0087766647338867
Validation loss: 2.2305103143056235

Epoch: 6| Step: 11
Training loss: 1.6712253093719482
Validation loss: 2.189696749051412

Epoch: 6| Step: 12
Training loss: 2.32950496673584
Validation loss: 2.1925589044888816

Epoch: 6| Step: 13
Training loss: 2.2378957271575928
Validation loss: 2.157501737276713

Epoch: 6| Step: 0
Training loss: 2.540739059448242
Validation loss: 2.155363082885742

Epoch: 6| Step: 1
Training loss: 1.8533629179000854
Validation loss: 2.1369728446006775

Epoch: 6| Step: 2
Training loss: 1.594289779663086
Validation loss: 2.1215714812278748

Epoch: 6| Step: 3
Training loss: 2.1959216594696045
Validation loss: 2.1186227599779763

Epoch: 6| Step: 4
Training loss: 1.963050365447998
Validation loss: 2.1018391648928323

Epoch: 6| Step: 5
Training loss: 2.273465633392334
Validation loss: 2.1114563743273416

Epoch: 6| Step: 6
Training loss: 2.7039506435394287
Validation loss: 2.099981407324473

Epoch: 6| Step: 7
Training loss: 1.8545341491699219
Validation loss: 2.0993096629778543

Epoch: 6| Step: 8
Training loss: 1.9438899755477905
Validation loss: 2.1067104736963906

Epoch: 6| Step: 9
Training loss: 2.5749688148498535
Validation loss: 2.128037134806315

Epoch: 6| Step: 10
Training loss: 2.1767148971557617
Validation loss: 2.1111811796824136

Epoch: 6| Step: 11
Training loss: 1.899236798286438
Validation loss: 2.118433137734731

Epoch: 6| Step: 12
Training loss: 1.8166084289550781
Validation loss: 2.1300929188728333

Epoch: 6| Step: 13
Training loss: 1.5215188264846802
Validation loss: 2.108323891957601

Epoch: 7| Step: 0
Training loss: 1.9673317670822144
Validation loss: 2.1003111600875854

Epoch: 6| Step: 1
Training loss: 2.0356805324554443
Validation loss: 2.0983956456184387

Epoch: 6| Step: 2
Training loss: 1.8351212739944458
Validation loss: 2.1089275081952414

Epoch: 6| Step: 3
Training loss: 2.9078621864318848
Validation loss: 2.1174110770225525

Epoch: 6| Step: 4
Training loss: 1.7142964601516724
Validation loss: 2.102217694123586

Epoch: 6| Step: 5
Training loss: 2.1624722480773926
Validation loss: 2.118104795614878

Epoch: 6| Step: 6
Training loss: 1.5703729391098022
Validation loss: 2.107995172341665

Epoch: 6| Step: 7
Training loss: 1.7897734642028809
Validation loss: 2.106746514638265

Epoch: 6| Step: 8
Training loss: 1.6386501789093018
Validation loss: 2.127362549304962

Epoch: 6| Step: 9
Training loss: 1.842973232269287
Validation loss: 2.0928202072779336

Epoch: 6| Step: 10
Training loss: 2.9901304244995117
Validation loss: 2.100571354230245

Epoch: 6| Step: 11
Training loss: 1.7215023040771484
Validation loss: 2.1076177954673767

Epoch: 6| Step: 12
Training loss: 2.17281436920166
Validation loss: 2.1082021991411843

Epoch: 6| Step: 13
Training loss: 2.204430103302002
Validation loss: 2.1078846057256064

Epoch: 8| Step: 0
Training loss: 1.6253869533538818
Validation loss: 2.0922268629074097

Epoch: 6| Step: 1
Training loss: 1.7001618146896362
Validation loss: 2.1039408842722573

Epoch: 6| Step: 2
Training loss: 1.9682506322860718
Validation loss: 2.100289801756541

Epoch: 6| Step: 3
Training loss: 2.686680316925049
Validation loss: 2.126532872517904

Epoch: 6| Step: 4
Training loss: 2.157078266143799
Validation loss: 2.113303025563558

Epoch: 6| Step: 5
Training loss: 1.9351285696029663
Validation loss: 2.097334543863932

Epoch: 6| Step: 6
Training loss: 2.4099154472351074
Validation loss: 2.1221149365107217

Epoch: 6| Step: 7
Training loss: 2.239898204803467
Validation loss: 2.1432213187217712

Epoch: 6| Step: 8
Training loss: 2.438352584838867
Validation loss: 2.1225874423980713

Epoch: 6| Step: 9
Training loss: 1.8684122562408447
Validation loss: 2.109366218249003

Epoch: 6| Step: 10
Training loss: 3.2426228523254395
Validation loss: 2.110072294871012

Epoch: 6| Step: 11
Training loss: 1.2812728881835938
Validation loss: 2.0958306988080344

Epoch: 6| Step: 12
Training loss: 1.43775475025177
Validation loss: 2.0886392990748086

Epoch: 6| Step: 13
Training loss: 1.768749713897705
Validation loss: 2.1085681716601052

Epoch: 9| Step: 0
Training loss: 2.3088321685791016
Validation loss: 2.088883380095164

Epoch: 6| Step: 1
Training loss: 2.1482419967651367
Validation loss: 2.0883191227912903

Epoch: 6| Step: 2
Training loss: 2.3499298095703125
Validation loss: 2.1046570539474487

Epoch: 6| Step: 3
Training loss: 1.7971335649490356
Validation loss: 2.110601822535197

Epoch: 6| Step: 4
Training loss: 2.0135464668273926
Validation loss: 2.0944610238075256

Epoch: 6| Step: 5
Training loss: 2.067626953125
Validation loss: 2.102837840716044

Epoch: 6| Step: 6
Training loss: 2.221601963043213
Validation loss: 2.1167572935422263

Epoch: 6| Step: 7
Training loss: 1.7364150285720825
Validation loss: 2.1010332306226096

Epoch: 6| Step: 8
Training loss: 1.7666901350021362
Validation loss: 2.1079742312431335

Epoch: 6| Step: 9
Training loss: 1.6712205410003662
Validation loss: 2.0912306110064187

Epoch: 6| Step: 10
Training loss: 2.047996997833252
Validation loss: 2.1040295163790383

Epoch: 6| Step: 11
Training loss: 2.5116868019104004
Validation loss: 2.089694400628408

Epoch: 6| Step: 12
Training loss: 1.8766908645629883
Validation loss: 2.1065568129221597

Epoch: 6| Step: 13
Training loss: 2.18386173248291
Validation loss: 2.0939998825391135

Epoch: 10| Step: 0
Training loss: 1.4470666646957397
Validation loss: 2.0928722421328225

Epoch: 6| Step: 1
Training loss: 2.473906993865967
Validation loss: 2.1020466486612954

Epoch: 6| Step: 2
Training loss: 1.5707857608795166
Validation loss: 2.0966498851776123

Epoch: 6| Step: 3
Training loss: 2.5949900150299072
Validation loss: 2.0964937607447305

Epoch: 6| Step: 4
Training loss: 1.9576001167297363
Validation loss: 2.0920514663060508

Epoch: 6| Step: 5
Training loss: 2.5623116493225098
Validation loss: 2.086452146371206

Epoch: 6| Step: 6
Training loss: 1.9336614608764648
Validation loss: 2.102697213490804

Epoch: 6| Step: 7
Training loss: 1.915170431137085
Validation loss: 2.0876852671305337

Epoch: 6| Step: 8
Training loss: 2.1595616340637207
Validation loss: 2.090701639652252

Epoch: 6| Step: 9
Training loss: 1.5917587280273438
Validation loss: 2.1068961222966514

Epoch: 6| Step: 10
Training loss: 1.9256075620651245
Validation loss: 2.080983519554138

Epoch: 6| Step: 11
Training loss: 2.254328727722168
Validation loss: 2.075041433175405

Epoch: 6| Step: 12
Training loss: 2.1894092559814453
Validation loss: 2.103711108366648

Epoch: 6| Step: 13
Training loss: 2.001154899597168
Validation loss: 2.1008682250976562

Epoch: 11| Step: 0
Training loss: 1.6330010890960693
Validation loss: 2.081839064757029

Epoch: 6| Step: 1
Training loss: 1.7979979515075684
Validation loss: 2.072214404741923

Epoch: 6| Step: 2
Training loss: 2.346118450164795
Validation loss: 2.08320023616155

Epoch: 6| Step: 3
Training loss: 1.8047791719436646
Validation loss: 2.1092154582341514

Epoch: 6| Step: 4
Training loss: 1.9671587944030762
Validation loss: 2.096876243750254

Epoch: 6| Step: 5
Training loss: 2.484445095062256
Validation loss: 2.068632165590922

Epoch: 6| Step: 6
Training loss: 1.4563921689987183
Validation loss: 2.080374598503113

Epoch: 6| Step: 7
Training loss: 2.8276729583740234
Validation loss: 2.082076847553253

Epoch: 6| Step: 8
Training loss: 2.3832671642303467
Validation loss: 2.1050145626068115

Epoch: 6| Step: 9
Training loss: 2.0303077697753906
Validation loss: 2.078070104122162

Epoch: 6| Step: 10
Training loss: 1.4658000469207764
Validation loss: 2.084372639656067

Epoch: 6| Step: 11
Training loss: 1.5198211669921875
Validation loss: 2.090398689111074

Epoch: 6| Step: 12
Training loss: 2.4554429054260254
Validation loss: 2.077656348546346

Epoch: 6| Step: 13
Training loss: 1.8932223320007324
Validation loss: 2.0619152188301086

Epoch: 12| Step: 0
Training loss: 1.7922968864440918
Validation loss: 2.0697787006696067

Epoch: 6| Step: 1
Training loss: 1.8474483489990234
Validation loss: 2.073932578166326

Epoch: 6| Step: 2
Training loss: 2.228015899658203
Validation loss: 2.081881046295166

Epoch: 6| Step: 3
Training loss: 1.4932396411895752
Validation loss: 2.0845089157422385

Epoch: 6| Step: 4
Training loss: 1.5920137166976929
Validation loss: 2.0773415168126426

Epoch: 6| Step: 5
Training loss: 2.118483066558838
Validation loss: 2.0813759167989097

Epoch: 6| Step: 6
Training loss: 2.1477725505828857
Validation loss: 2.066987156867981

Epoch: 6| Step: 7
Training loss: 1.9893275499343872
Validation loss: 2.0905319253603616

Epoch: 6| Step: 8
Training loss: 1.7735683917999268
Validation loss: 2.0788912773132324

Epoch: 6| Step: 9
Training loss: 2.5074143409729004
Validation loss: 2.0768474340438843

Epoch: 6| Step: 10
Training loss: 2.090524435043335
Validation loss: 2.063389301300049

Epoch: 6| Step: 11
Training loss: 2.3689818382263184
Validation loss: 2.088361899058024

Epoch: 6| Step: 12
Training loss: 2.1419320106506348
Validation loss: 2.0858762661616006

Epoch: 6| Step: 13
Training loss: 2.086726665496826
Validation loss: 2.095192551612854

Epoch: 13| Step: 0
Training loss: 2.6788744926452637
Validation loss: 2.0905823906262717

Epoch: 6| Step: 1
Training loss: 2.5271806716918945
Validation loss: 2.0883222222328186

Epoch: 6| Step: 2
Training loss: 2.3513901233673096
Validation loss: 2.085060199101766

Epoch: 6| Step: 3
Training loss: 1.7615996599197388
Validation loss: 2.087408423423767

Epoch: 6| Step: 4
Training loss: 2.1488940715789795
Validation loss: 2.0737905899683633

Epoch: 6| Step: 5
Training loss: 1.7068746089935303
Validation loss: 2.0849386056264243

Epoch: 6| Step: 6
Training loss: 1.5880602598190308
Validation loss: 2.085765461126963

Epoch: 6| Step: 7
Training loss: 1.7041075229644775
Validation loss: 2.088316559791565

Epoch: 6| Step: 8
Training loss: 1.350851058959961
Validation loss: 2.071263909339905

Epoch: 6| Step: 9
Training loss: 1.7083547115325928
Validation loss: 2.077381749947866

Epoch: 6| Step: 10
Training loss: 2.5078721046447754
Validation loss: 2.0639703075091043

Epoch: 6| Step: 11
Training loss: 2.1894471645355225
Validation loss: 2.0731555223464966

Epoch: 6| Step: 12
Training loss: 1.997915506362915
Validation loss: 2.068376362323761

Epoch: 6| Step: 13
Training loss: 2.0208024978637695
Validation loss: 2.081424037615458

Epoch: 14| Step: 0
Training loss: 1.4773211479187012
Validation loss: 2.058467229207357

Epoch: 6| Step: 1
Training loss: 1.941720962524414
Validation loss: 2.080601076285044

Epoch: 6| Step: 2
Training loss: 1.9326896667480469
Validation loss: 2.070283830165863

Epoch: 6| Step: 3
Training loss: 1.562903642654419
Validation loss: 2.0602408250172934

Epoch: 6| Step: 4
Training loss: 2.099687099456787
Validation loss: 2.0550498366355896

Epoch: 6| Step: 5
Training loss: 2.1164615154266357
Validation loss: 2.0726478497187295

Epoch: 6| Step: 6
Training loss: 2.3075597286224365
Validation loss: 2.0673420230547586

Epoch: 6| Step: 7
Training loss: 1.8137626647949219
Validation loss: 2.0766226649284363

Epoch: 6| Step: 8
Training loss: 2.550001621246338
Validation loss: 2.0662381251653037

Epoch: 6| Step: 9
Training loss: 2.4268534183502197
Validation loss: 2.070541739463806

Epoch: 6| Step: 10
Training loss: 2.820105791091919
Validation loss: 2.085169235865275

Epoch: 6| Step: 11
Training loss: 1.5270826816558838
Validation loss: 2.084364930788676

Epoch: 6| Step: 12
Training loss: 1.6305521726608276
Validation loss: 2.072857598463694

Epoch: 6| Step: 13
Training loss: 1.9859728813171387
Validation loss: 2.0627280473709106

Epoch: 15| Step: 0
Training loss: 2.61163330078125
Validation loss: 2.082558790842692

Epoch: 6| Step: 1
Training loss: 1.7001572847366333
Validation loss: 2.071768899758657

Epoch: 6| Step: 2
Training loss: 1.750972867012024
Validation loss: 2.0654044349988303

Epoch: 6| Step: 3
Training loss: 1.6502599716186523
Validation loss: 2.0783480405807495

Epoch: 6| Step: 4
Training loss: 2.1369788646698
Validation loss: 2.073967973391215

Epoch: 6| Step: 5
Training loss: 2.074681282043457
Validation loss: 2.044649839401245

Epoch: 6| Step: 6
Training loss: 2.0488088130950928
Validation loss: 2.070359249909719

Epoch: 6| Step: 7
Training loss: 2.38767409324646
Validation loss: 2.0764035979906716

Epoch: 6| Step: 8
Training loss: 2.9194765090942383
Validation loss: 2.0746676325798035

Epoch: 6| Step: 9
Training loss: 1.7081966400146484
Validation loss: 2.058801273504893

Epoch: 6| Step: 10
Training loss: 1.891810417175293
Validation loss: 2.058965583642324

Epoch: 6| Step: 11
Training loss: 1.5789611339569092
Validation loss: 2.0482267141342163

Epoch: 6| Step: 12
Training loss: 1.6934211254119873
Validation loss: 2.0523744026819863

Epoch: 6| Step: 13
Training loss: 1.6620606184005737
Validation loss: 2.0648892521858215

Epoch: 16| Step: 0
Training loss: 1.5247639417648315
Validation loss: 2.053988218307495

Epoch: 6| Step: 1
Training loss: 1.994074821472168
Validation loss: 2.0627513329188027

Epoch: 6| Step: 2
Training loss: 1.545630693435669
Validation loss: 2.0665160020192466

Epoch: 6| Step: 3
Training loss: 1.748215913772583
Validation loss: 2.0461663603782654

Epoch: 6| Step: 4
Training loss: 2.659587860107422
Validation loss: 2.0614780386288962

Epoch: 6| Step: 5
Training loss: 1.8228602409362793
Validation loss: 2.055770993232727

Epoch: 6| Step: 6
Training loss: 2.2959508895874023
Validation loss: 2.060379763444265

Epoch: 6| Step: 7
Training loss: 1.8521361351013184
Validation loss: 2.0711613297462463

Epoch: 6| Step: 8
Training loss: 1.7010698318481445
Validation loss: 2.0570425987243652

Epoch: 6| Step: 9
Training loss: 1.886254906654358
Validation loss: 2.03432567914327

Epoch: 6| Step: 10
Training loss: 2.4143054485321045
Validation loss: 2.0776229898134866

Epoch: 6| Step: 11
Training loss: 1.763271689414978
Validation loss: 2.061589479446411

Epoch: 6| Step: 12
Training loss: 2.976595640182495
Validation loss: 2.0581394831339517

Epoch: 6| Step: 13
Training loss: 1.979538917541504
Validation loss: 2.0514713724454245

Epoch: 17| Step: 0
Training loss: 1.9628117084503174
Validation loss: 2.067742943763733

Epoch: 6| Step: 1
Training loss: 2.020240068435669
Validation loss: 2.0552936792373657

Epoch: 6| Step: 2
Training loss: 1.8233146667480469
Validation loss: 2.0719809532165527

Epoch: 6| Step: 3
Training loss: 1.4637739658355713
Validation loss: 2.0433276096979776

Epoch: 6| Step: 4
Training loss: 1.7746025323867798
Validation loss: 2.068235198656718

Epoch: 6| Step: 5
Training loss: 2.3975601196289062
Validation loss: 2.044766823450724

Epoch: 6| Step: 6
Training loss: 3.1355490684509277
Validation loss: 2.03778874874115

Epoch: 6| Step: 7
Training loss: 2.673058032989502
Validation loss: 2.0546682278315225

Epoch: 6| Step: 8
Training loss: 1.6801538467407227
Validation loss: 2.0655590295791626

Epoch: 6| Step: 9
Training loss: 1.3933382034301758
Validation loss: 2.0525365074475608

Epoch: 6| Step: 10
Training loss: 2.5928146839141846
Validation loss: 2.0473506848017373

Epoch: 6| Step: 11
Training loss: 1.3520357608795166
Validation loss: 2.03871218363444

Epoch: 6| Step: 12
Training loss: 1.9749246835708618
Validation loss: 2.0580585996309915

Epoch: 6| Step: 13
Training loss: 1.7150883674621582
Validation loss: 2.0571268598238626

Epoch: 18| Step: 0
Training loss: 2.252969980239868
Validation loss: 2.0602497259775796

Epoch: 6| Step: 1
Training loss: 1.6697932481765747
Validation loss: 2.052405834197998

Epoch: 6| Step: 2
Training loss: 1.8316603899002075
Validation loss: 2.0390844345092773

Epoch: 6| Step: 3
Training loss: 2.022822856903076
Validation loss: 2.0461400548617044

Epoch: 6| Step: 4
Training loss: 2.072906017303467
Validation loss: 2.052022079626719

Epoch: 6| Step: 5
Training loss: 2.2317473888397217
Validation loss: 2.048777461051941

Epoch: 6| Step: 6
Training loss: 2.545226812362671
Validation loss: 2.0592912634213767

Epoch: 6| Step: 7
Training loss: 1.659060001373291
Validation loss: 2.0769421060880027

Epoch: 6| Step: 8
Training loss: 1.5402240753173828
Validation loss: 2.04237961769104

Epoch: 6| Step: 9
Training loss: 1.7447466850280762
Validation loss: 2.072858452796936

Epoch: 6| Step: 10
Training loss: 2.3106212615966797
Validation loss: 2.0482227206230164

Epoch: 6| Step: 11
Training loss: 1.8283491134643555
Validation loss: 2.0585699876149497

Epoch: 6| Step: 12
Training loss: 1.8173434734344482
Validation loss: 2.038319230079651

Epoch: 6| Step: 13
Training loss: 2.3454065322875977
Validation loss: 2.049546202023824

Epoch: 19| Step: 0
Training loss: 2.3638155460357666
Validation loss: 2.0516682863235474

Epoch: 6| Step: 1
Training loss: 2.487980604171753
Validation loss: 2.045488476753235

Epoch: 6| Step: 2
Training loss: 1.8647516965866089
Validation loss: 2.0674328605333963

Epoch: 6| Step: 3
Training loss: 2.157313823699951
Validation loss: 2.0284237464269004

Epoch: 6| Step: 4
Training loss: 2.6455841064453125
Validation loss: 2.0491495529810586

Epoch: 6| Step: 5
Training loss: 2.213672637939453
Validation loss: 2.05096968015035

Epoch: 6| Step: 6
Training loss: 1.701941967010498
Validation loss: 2.0432669520378113

Epoch: 6| Step: 7
Training loss: 1.867350459098816
Validation loss: 2.0519580046335855

Epoch: 6| Step: 8
Training loss: 1.3531570434570312
Validation loss: 2.0370641350746155

Epoch: 6| Step: 9
Training loss: 1.7905497550964355
Validation loss: 2.037649075190226

Epoch: 6| Step: 10
Training loss: 2.0287013053894043
Validation loss: 2.0462026596069336

Epoch: 6| Step: 11
Training loss: 1.678894281387329
Validation loss: 2.0644492904345193

Epoch: 6| Step: 12
Training loss: 2.021730422973633
Validation loss: 2.0383989413579306

Epoch: 6| Step: 13
Training loss: 1.8485755920410156
Validation loss: 2.0462640126546225

Epoch: 20| Step: 0
Training loss: 1.9012892246246338
Validation loss: 2.0299888253211975

Epoch: 6| Step: 1
Training loss: 1.8536250591278076
Validation loss: 2.036248524983724

Epoch: 6| Step: 2
Training loss: 2.1565372943878174
Validation loss: 2.0360904335975647

Epoch: 6| Step: 3
Training loss: 2.400972604751587
Validation loss: 2.038764178752899

Epoch: 6| Step: 4
Training loss: 1.966501235961914
Validation loss: 2.031150162220001

Epoch: 6| Step: 5
Training loss: 1.7881686687469482
Validation loss: 2.0521252751350403

Epoch: 6| Step: 6
Training loss: 1.6197831630706787
Validation loss: 2.057317634423574

Epoch: 6| Step: 7
Training loss: 1.9405407905578613
Validation loss: 2.0450017849604287

Epoch: 6| Step: 8
Training loss: 2.017895221710205
Validation loss: 2.0781052907307944

Epoch: 6| Step: 9
Training loss: 1.601618766784668
Validation loss: 2.06545090675354

Epoch: 6| Step: 10
Training loss: 1.8403112888336182
Validation loss: 2.0438414017359414

Epoch: 6| Step: 11
Training loss: 2.060298442840576
Validation loss: 2.0506675442059836

Epoch: 6| Step: 12
Training loss: 2.7285873889923096
Validation loss: 2.039530316988627

Epoch: 6| Step: 13
Training loss: 1.834028720855713
Validation loss: 2.06307582060496

Epoch: 21| Step: 0
Training loss: 2.007955551147461
Validation loss: 2.041314740975698

Epoch: 6| Step: 1
Training loss: 1.690672755241394
Validation loss: 2.0231958826382956

Epoch: 6| Step: 2
Training loss: 2.1645169258117676
Validation loss: 2.0436542431513467

Epoch: 6| Step: 3
Training loss: 1.5166184902191162
Validation loss: 2.0173179705937705

Epoch: 6| Step: 4
Training loss: 2.2924821376800537
Validation loss: 2.046863377094269

Epoch: 6| Step: 5
Training loss: 1.6210545301437378
Validation loss: 2.0405503312746682

Epoch: 6| Step: 6
Training loss: 2.2927584648132324
Validation loss: 2.0307359099388123

Epoch: 6| Step: 7
Training loss: 1.3077802658081055
Validation loss: 2.0367427269617715

Epoch: 6| Step: 8
Training loss: 2.002812147140503
Validation loss: 2.0073283116022744

Epoch: 6| Step: 9
Training loss: 1.9740713834762573
Validation loss: 2.0400177439053855

Epoch: 6| Step: 10
Training loss: 2.459200382232666
Validation loss: 2.038939972718557

Epoch: 6| Step: 11
Training loss: 2.2676265239715576
Validation loss: 2.039253214995066

Epoch: 6| Step: 12
Training loss: 2.248647928237915
Validation loss: 2.0256789922714233

Epoch: 6| Step: 13
Training loss: 2.0494956970214844
Validation loss: 2.042653481165568

Epoch: 22| Step: 0
Training loss: 2.1211514472961426
Validation loss: 2.057574212551117

Epoch: 6| Step: 1
Training loss: 1.5522927045822144
Validation loss: 2.064744790395101

Epoch: 6| Step: 2
Training loss: 1.2815457582473755
Validation loss: 2.079591532548269

Epoch: 6| Step: 3
Training loss: 2.0574493408203125
Validation loss: 2.050783634185791

Epoch: 6| Step: 4
Training loss: 1.698286533355713
Validation loss: 2.075144648551941

Epoch: 6| Step: 5
Training loss: 1.9275543689727783
Validation loss: 2.0890486240386963

Epoch: 6| Step: 6
Training loss: 2.3443284034729004
Validation loss: 2.0718653003374734

Epoch: 6| Step: 7
Training loss: 1.8234421014785767
Validation loss: 2.115861435731252

Epoch: 6| Step: 8
Training loss: 2.5300097465515137
Validation loss: 2.087902228037516

Epoch: 6| Step: 9
Training loss: 1.7732971906661987
Validation loss: 2.055038571357727

Epoch: 6| Step: 10
Training loss: 2.3942556381225586
Validation loss: 2.0503222544988

Epoch: 6| Step: 11
Training loss: 2.0568666458129883
Validation loss: 2.0419723987579346

Epoch: 6| Step: 12
Training loss: 2.123605966567993
Validation loss: 2.0341991583506265

Epoch: 6| Step: 13
Training loss: 2.103311538696289
Validation loss: 2.0281779964764914

Epoch: 23| Step: 0
Training loss: 2.341327428817749
Validation loss: 2.0135374466578164

Epoch: 6| Step: 1
Training loss: 1.5979353189468384
Validation loss: 2.045198122660319

Epoch: 6| Step: 2
Training loss: 1.8299484252929688
Validation loss: 2.030996024608612

Epoch: 6| Step: 3
Training loss: 2.213209867477417
Validation loss: 2.0275017619132996

Epoch: 6| Step: 4
Training loss: 1.5533816814422607
Validation loss: 2.0366017619768777

Epoch: 6| Step: 5
Training loss: 2.1201610565185547
Validation loss: 2.033410588900248

Epoch: 6| Step: 6
Training loss: 2.4088265895843506
Validation loss: 2.018912891546885

Epoch: 6| Step: 7
Training loss: 2.1256470680236816
Validation loss: 2.025826176007589

Epoch: 6| Step: 8
Training loss: 1.8150924444198608
Validation loss: 2.0179672042528787

Epoch: 6| Step: 9
Training loss: 2.252220392227173
Validation loss: 2.028113226095835

Epoch: 6| Step: 10
Training loss: 1.5680804252624512
Validation loss: 2.023240546385447

Epoch: 6| Step: 11
Training loss: 1.9851796627044678
Validation loss: 2.022641440232595

Epoch: 6| Step: 12
Training loss: 2.3696985244750977
Validation loss: 2.027424414952596

Epoch: 6| Step: 13
Training loss: 1.6450116634368896
Validation loss: 2.012288769086202

Epoch: 24| Step: 0
Training loss: 2.3209590911865234
Validation loss: 2.0296313961346946

Epoch: 6| Step: 1
Training loss: 1.9752302169799805
Validation loss: 2.0185226599375405

Epoch: 6| Step: 2
Training loss: 1.562636375427246
Validation loss: 2.0210546255111694

Epoch: 6| Step: 3
Training loss: 2.4521374702453613
Validation loss: 2.0449100732803345

Epoch: 6| Step: 4
Training loss: 1.935270071029663
Validation loss: 2.0337435801823935

Epoch: 6| Step: 5
Training loss: 1.5586761236190796
Validation loss: 2.0527066389719644

Epoch: 6| Step: 6
Training loss: 1.8850687742233276
Validation loss: 2.0526632269223533

Epoch: 6| Step: 7
Training loss: 2.412741184234619
Validation loss: 2.0411235888799033

Epoch: 6| Step: 8
Training loss: 1.8865854740142822
Validation loss: 2.057547310988108

Epoch: 6| Step: 9
Training loss: 1.3918488025665283
Validation loss: 2.0635138551394143

Epoch: 6| Step: 10
Training loss: 1.8448795080184937
Validation loss: 2.0592025319735208

Epoch: 6| Step: 11
Training loss: 2.557950019836426
Validation loss: 2.067557950814565

Epoch: 6| Step: 12
Training loss: 1.6900538206100464
Validation loss: 2.0634026328722634

Epoch: 6| Step: 13
Training loss: 1.9414266347885132
Validation loss: 2.0615190863609314

Epoch: 25| Step: 0
Training loss: 2.6128063201904297
Validation loss: 2.0546892285346985

Epoch: 6| Step: 1
Training loss: 1.9741277694702148
Validation loss: 2.0602774421374

Epoch: 6| Step: 2
Training loss: 1.365311622619629
Validation loss: 2.0267911553382874

Epoch: 6| Step: 3
Training loss: 2.342967987060547
Validation loss: 2.019807457923889

Epoch: 6| Step: 4
Training loss: 1.9539434909820557
Validation loss: 2.022393822669983

Epoch: 6| Step: 5
Training loss: 1.3057526350021362
Validation loss: 2.0001601576805115

Epoch: 6| Step: 6
Training loss: 1.5498697757720947
Validation loss: 2.0327481230099997

Epoch: 6| Step: 7
Training loss: 2.3722004890441895
Validation loss: 2.0144695043563843

Epoch: 6| Step: 8
Training loss: 2.0088987350463867
Validation loss: 2.021705408891042

Epoch: 6| Step: 9
Training loss: 1.8952505588531494
Validation loss: 2.046615501244863

Epoch: 6| Step: 10
Training loss: 1.8085148334503174
Validation loss: 2.025966783364614

Epoch: 6| Step: 11
Training loss: 2.160181999206543
Validation loss: 2.0477813680966697

Epoch: 6| Step: 12
Training loss: 2.359891653060913
Validation loss: 2.052774965763092

Epoch: 6| Step: 13
Training loss: 1.9470136165618896
Validation loss: 2.0438655018806458

Epoch: 26| Step: 0
Training loss: 2.1703810691833496
Validation loss: 2.038204034169515

Epoch: 6| Step: 1
Training loss: 2.532593250274658
Validation loss: 2.0570103923479715

Epoch: 6| Step: 2
Training loss: 2.3454697132110596
Validation loss: 2.0412133932113647

Epoch: 6| Step: 3
Training loss: 2.459113836288452
Validation loss: 2.0399871269861856

Epoch: 6| Step: 4
Training loss: 1.8298003673553467
Validation loss: 2.028161883354187

Epoch: 6| Step: 5
Training loss: 1.8935470581054688
Validation loss: 2.030842959880829

Epoch: 6| Step: 6
Training loss: 1.56613028049469
Validation loss: 2.0410168170928955

Epoch: 6| Step: 7
Training loss: 1.4467154741287231
Validation loss: 2.0213749607404075

Epoch: 6| Step: 8
Training loss: 1.6116231679916382
Validation loss: 2.0062286257743835

Epoch: 6| Step: 9
Training loss: 2.102400541305542
Validation loss: 2.0289806127548218

Epoch: 6| Step: 10
Training loss: 1.9621611833572388
Validation loss: 2.032377560933431

Epoch: 6| Step: 11
Training loss: 1.2477279901504517
Validation loss: 2.0412405729293823

Epoch: 6| Step: 12
Training loss: 1.746168613433838
Validation loss: 2.0296385089556375

Epoch: 6| Step: 13
Training loss: 2.5438220500946045
Validation loss: 2.004065990447998

Epoch: 27| Step: 0
Training loss: 2.554429054260254
Validation loss: 2.027879854043325

Epoch: 6| Step: 1
Training loss: 1.625932216644287
Validation loss: 2.0279117027918496

Epoch: 6| Step: 2
Training loss: 1.6767277717590332
Validation loss: 2.0266727805137634

Epoch: 6| Step: 3
Training loss: 2.275728225708008
Validation loss: 2.034139931201935

Epoch: 6| Step: 4
Training loss: 2.355717182159424
Validation loss: 2.0263880292574563

Epoch: 6| Step: 5
Training loss: 2.0578463077545166
Validation loss: 2.0122112234433494

Epoch: 6| Step: 6
Training loss: 1.3921294212341309
Validation loss: 2.0139233072598777

Epoch: 6| Step: 7
Training loss: 1.8100230693817139
Validation loss: 2.0389480193456015

Epoch: 6| Step: 8
Training loss: 1.9467356204986572
Validation loss: 2.0300135612487793

Epoch: 6| Step: 9
Training loss: 1.6157407760620117
Validation loss: 2.008708973725637

Epoch: 6| Step: 10
Training loss: 1.825402021408081
Validation loss: 2.0011474092801413

Epoch: 6| Step: 11
Training loss: 2.5940604209899902
Validation loss: 2.029353598753611

Epoch: 6| Step: 12
Training loss: 1.652176856994629
Validation loss: 2.0122156937917075

Epoch: 6| Step: 13
Training loss: 2.192600965499878
Validation loss: 2.0345240036646524

Epoch: 28| Step: 0
Training loss: 2.511599540710449
Validation loss: 2.0476427475611367

Epoch: 6| Step: 1
Training loss: 2.231032371520996
Validation loss: 2.0394760171572366

Epoch: 6| Step: 2
Training loss: 2.2472610473632812
Validation loss: 2.0198930899302163

Epoch: 6| Step: 3
Training loss: 1.4428322315216064
Validation loss: 2.0521062215169272

Epoch: 6| Step: 4
Training loss: 1.4912868738174438
Validation loss: 2.0504066348075867

Epoch: 6| Step: 5
Training loss: 1.6571948528289795
Validation loss: 2.0523174007733664

Epoch: 6| Step: 6
Training loss: 1.7122472524642944
Validation loss: 2.0476197600364685

Epoch: 6| Step: 7
Training loss: 2.5226526260375977
Validation loss: 2.052136699358622

Epoch: 6| Step: 8
Training loss: 2.1203982830047607
Validation loss: 2.0343522230784097

Epoch: 6| Step: 9
Training loss: 1.691706657409668
Validation loss: 2.0388461550076804

Epoch: 6| Step: 10
Training loss: 1.8892769813537598
Validation loss: 2.035908023516337

Epoch: 6| Step: 11
Training loss: 2.3375608921051025
Validation loss: 2.0236437916755676

Epoch: 6| Step: 12
Training loss: 1.9561492204666138
Validation loss: 2.020240843296051

Epoch: 6| Step: 13
Training loss: 1.5986030101776123
Validation loss: 2.023776193459829

Epoch: 29| Step: 0
Training loss: 2.4598538875579834
Validation loss: 2.0139950116475425

Epoch: 6| Step: 1
Training loss: 2.371412515640259
Validation loss: 2.000616669654846

Epoch: 6| Step: 2
Training loss: 1.4515831470489502
Validation loss: 2.0247087677319846

Epoch: 6| Step: 3
Training loss: 1.7144571542739868
Validation loss: 1.9990341862042744

Epoch: 6| Step: 4
Training loss: 1.457970142364502
Validation loss: 2.0103678703308105

Epoch: 6| Step: 5
Training loss: 1.6215623617172241
Validation loss: 2.0054001410802207

Epoch: 6| Step: 6
Training loss: 2.494865655899048
Validation loss: 2.0079066356023154

Epoch: 6| Step: 7
Training loss: 2.307145595550537
Validation loss: 2.0097439885139465

Epoch: 6| Step: 8
Training loss: 2.053954601287842
Validation loss: 2.0052688916524253

Epoch: 6| Step: 9
Training loss: 2.0651187896728516
Validation loss: 2.0169328451156616

Epoch: 6| Step: 10
Training loss: 1.3289432525634766
Validation loss: 2.030431648095449

Epoch: 6| Step: 11
Training loss: 2.2149689197540283
Validation loss: 2.021929065386454

Epoch: 6| Step: 12
Training loss: 1.5601046085357666
Validation loss: 2.02261753877004

Epoch: 6| Step: 13
Training loss: 2.2706260681152344
Validation loss: 2.010865787665049

Epoch: 30| Step: 0
Training loss: 2.2504425048828125
Validation loss: 2.017537315686544

Epoch: 6| Step: 1
Training loss: 2.4837865829467773
Validation loss: 2.034342964490255

Epoch: 6| Step: 2
Training loss: 2.711930274963379
Validation loss: 2.024472693602244

Epoch: 6| Step: 3
Training loss: 1.8194732666015625
Validation loss: 2.0323252081871033

Epoch: 6| Step: 4
Training loss: 1.5952391624450684
Validation loss: 2.0387575030326843

Epoch: 6| Step: 5
Training loss: 1.6698498725891113
Validation loss: 2.029281437397003

Epoch: 6| Step: 6
Training loss: 1.8705048561096191
Validation loss: 2.0250539978345237

Epoch: 6| Step: 7
Training loss: 2.1163854598999023
Validation loss: 2.0339809457461038

Epoch: 6| Step: 8
Training loss: 1.9598731994628906
Validation loss: 2.021432797114054

Epoch: 6| Step: 9
Training loss: 2.088078498840332
Validation loss: 2.0218878984451294

Epoch: 6| Step: 10
Training loss: 0.9477351903915405
Validation loss: 2.0083146691322327

Epoch: 6| Step: 11
Training loss: 2.2752137184143066
Validation loss: 1.998341977596283

Epoch: 6| Step: 12
Training loss: 1.5322761535644531
Validation loss: 2.001770536104838

Epoch: 6| Step: 13
Training loss: 2.0998470783233643
Validation loss: 2.004112402598063

Epoch: 31| Step: 0
Training loss: 2.6116302013397217
Validation loss: 1.997420032819112

Epoch: 6| Step: 1
Training loss: 1.9012216329574585
Validation loss: 1.9966432054837544

Epoch: 6| Step: 2
Training loss: 1.7645386457443237
Validation loss: 1.9934534430503845

Epoch: 6| Step: 3
Training loss: 1.6248834133148193
Validation loss: 1.9925305644671123

Epoch: 6| Step: 4
Training loss: 1.9750994443893433
Validation loss: 2.020282745361328

Epoch: 6| Step: 5
Training loss: 2.187854766845703
Validation loss: 1.9933592875798543

Epoch: 6| Step: 6
Training loss: 1.6205387115478516
Validation loss: 2.0039170583089194

Epoch: 6| Step: 7
Training loss: 1.9615771770477295
Validation loss: 2.008237282435099

Epoch: 6| Step: 8
Training loss: 1.5936479568481445
Validation loss: 2.022053043047587

Epoch: 6| Step: 9
Training loss: 2.042086601257324
Validation loss: 1.9936005473136902

Epoch: 6| Step: 10
Training loss: 1.6249725818634033
Validation loss: 2.020871162414551

Epoch: 6| Step: 11
Training loss: 1.8498289585113525
Validation loss: 2.0178473194440207

Epoch: 6| Step: 12
Training loss: 2.0634684562683105
Validation loss: 2.0650216341018677

Epoch: 6| Step: 13
Training loss: 2.6255125999450684
Validation loss: 2.056622485319773

Epoch: 32| Step: 0
Training loss: 1.845369815826416
Validation loss: 2.0559157729148865

Epoch: 6| Step: 1
Training loss: 1.3088202476501465
Validation loss: 2.0638206799825034

Epoch: 6| Step: 2
Training loss: 1.7988417148590088
Validation loss: 2.0568697253863015

Epoch: 6| Step: 3
Training loss: 1.4210468530654907
Validation loss: 2.0784125328063965

Epoch: 6| Step: 4
Training loss: 2.7065000534057617
Validation loss: 2.058473587036133

Epoch: 6| Step: 5
Training loss: 1.9164739847183228
Validation loss: 2.0531459053357444

Epoch: 6| Step: 6
Training loss: 1.631550908088684
Validation loss: 2.072706699371338

Epoch: 6| Step: 7
Training loss: 2.5811381340026855
Validation loss: 2.0632506807645163

Epoch: 6| Step: 8
Training loss: 1.7060993909835815
Validation loss: 2.009748876094818

Epoch: 6| Step: 9
Training loss: 1.5342824459075928
Validation loss: 2.009616712729136

Epoch: 6| Step: 10
Training loss: 1.8911395072937012
Validation loss: 1.995915671189626

Epoch: 6| Step: 11
Training loss: 2.698493003845215
Validation loss: 2.0222222208976746

Epoch: 6| Step: 12
Training loss: 2.14156174659729
Validation loss: 2.0132746497790017

Epoch: 6| Step: 13
Training loss: 1.9797905683517456
Validation loss: 1.9893850485483806

Epoch: 33| Step: 0
Training loss: 2.2378954887390137
Validation loss: 1.9920793374379475

Epoch: 6| Step: 1
Training loss: 1.8333890438079834
Validation loss: 2.0123291015625

Epoch: 6| Step: 2
Training loss: 1.6026679277420044
Validation loss: 2.003623684247335

Epoch: 6| Step: 3
Training loss: 1.8348535299301147
Validation loss: 2.0011806090672812

Epoch: 6| Step: 4
Training loss: 1.5973517894744873
Validation loss: 2.0035220781962075

Epoch: 6| Step: 5
Training loss: 2.5035998821258545
Validation loss: 2.0011304020881653

Epoch: 6| Step: 6
Training loss: 2.2212069034576416
Validation loss: 2.0149962107340493

Epoch: 6| Step: 7
Training loss: 2.6438968181610107
Validation loss: 2.006327271461487

Epoch: 6| Step: 8
Training loss: 2.143767833709717
Validation loss: 1.9864958723386128

Epoch: 6| Step: 9
Training loss: 1.640655517578125
Validation loss: 1.9989179571469624

Epoch: 6| Step: 10
Training loss: 1.6432745456695557
Validation loss: 2.0052911241849265

Epoch: 6| Step: 11
Training loss: 1.6346919536590576
Validation loss: 2.018728335698446

Epoch: 6| Step: 12
Training loss: 2.276413917541504
Validation loss: 2.029278834660848

Epoch: 6| Step: 13
Training loss: 1.604499340057373
Validation loss: 2.0154189268747964

Epoch: 34| Step: 0
Training loss: 2.421626091003418
Validation loss: 2.0423017342885337

Epoch: 6| Step: 1
Training loss: 1.4298648834228516
Validation loss: 2.01081520318985

Epoch: 6| Step: 2
Training loss: 1.8997946977615356
Validation loss: 2.0010377168655396

Epoch: 6| Step: 3
Training loss: 2.593888759613037
Validation loss: 2.020230293273926

Epoch: 6| Step: 4
Training loss: 2.0380194187164307
Validation loss: 2.0118082960446677

Epoch: 6| Step: 5
Training loss: 1.934103012084961
Validation loss: 1.9942840337753296

Epoch: 6| Step: 6
Training loss: 1.6229528188705444
Validation loss: 1.9957149624824524

Epoch: 6| Step: 7
Training loss: 1.303816318511963
Validation loss: 1.9980161984761555

Epoch: 6| Step: 8
Training loss: 1.6914180517196655
Validation loss: 2.0096528728803

Epoch: 6| Step: 9
Training loss: 2.3376054763793945
Validation loss: 2.0160075028737388

Epoch: 6| Step: 10
Training loss: 2.5030291080474854
Validation loss: 2.0094661513964334

Epoch: 6| Step: 11
Training loss: 1.6601412296295166
Validation loss: 2.0085599223772683

Epoch: 6| Step: 12
Training loss: 1.6863332986831665
Validation loss: 2.031773885091146

Epoch: 6| Step: 13
Training loss: 1.967689037322998
Validation loss: 2.0356759428977966

Epoch: 35| Step: 0
Training loss: 1.7254760265350342
Validation loss: 2.042182505130768

Epoch: 6| Step: 1
Training loss: 2.552730083465576
Validation loss: 2.04005366563797

Epoch: 6| Step: 2
Training loss: 2.0998616218566895
Validation loss: 2.018037438392639

Epoch: 6| Step: 3
Training loss: 1.5064449310302734
Validation loss: 2.029407024383545

Epoch: 6| Step: 4
Training loss: 1.5866948366165161
Validation loss: 2.0090885559717813

Epoch: 6| Step: 5
Training loss: 1.493025302886963
Validation loss: 2.0059540073076882

Epoch: 6| Step: 6
Training loss: 1.514317512512207
Validation loss: 2.0214050014813743

Epoch: 6| Step: 7
Training loss: 2.6165263652801514
Validation loss: 1.9949486255645752

Epoch: 6| Step: 8
Training loss: 1.8448517322540283
Validation loss: 2.00870672861735

Epoch: 6| Step: 9
Training loss: 2.1368768215179443
Validation loss: 1.9887197216351826

Epoch: 6| Step: 10
Training loss: 1.9178833961486816
Validation loss: 2.0043429732322693

Epoch: 6| Step: 11
Training loss: 3.286755084991455
Validation loss: 2.0051063100496926

Epoch: 6| Step: 12
Training loss: 1.1774373054504395
Validation loss: 2.013176381587982

Epoch: 6| Step: 13
Training loss: 2.1535186767578125
Validation loss: 1.9803995887438457

Epoch: 36| Step: 0
Training loss: 2.42513370513916
Validation loss: 2.0013186931610107

Epoch: 6| Step: 1
Training loss: 2.5344595909118652
Validation loss: 2.0011895895004272

Epoch: 6| Step: 2
Training loss: 1.7379710674285889
Validation loss: 2.021267751852671

Epoch: 6| Step: 3
Training loss: 2.1349997520446777
Validation loss: 2.030236760775248

Epoch: 6| Step: 4
Training loss: 1.1797903776168823
Validation loss: 2.0531997283299765

Epoch: 6| Step: 5
Training loss: 1.8040772676467896
Validation loss: 2.07605371872584

Epoch: 6| Step: 6
Training loss: 1.7099454402923584
Validation loss: 2.057233532269796

Epoch: 6| Step: 7
Training loss: 2.279662847518921
Validation loss: 2.0869709650675454

Epoch: 6| Step: 8
Training loss: 2.1256015300750732
Validation loss: 2.084407091140747

Epoch: 6| Step: 9
Training loss: 1.6195091009140015
Validation loss: 2.0844467878341675

Epoch: 6| Step: 10
Training loss: 1.8037176132202148
Validation loss: 2.118168373902639

Epoch: 6| Step: 11
Training loss: 2.1505935192108154
Validation loss: 2.1028608282407126

Epoch: 6| Step: 12
Training loss: 2.1744251251220703
Validation loss: 2.088881572087606

Epoch: 6| Step: 13
Training loss: 1.6920521259307861
Validation loss: 2.0899203618367515

Epoch: 37| Step: 0
Training loss: 2.430037498474121
Validation loss: 2.071747104326884

Epoch: 6| Step: 1
Training loss: 1.6968662738800049
Validation loss: 2.0223825176556907

Epoch: 6| Step: 2
Training loss: 1.5315073728561401
Validation loss: 2.0383002559343972

Epoch: 6| Step: 3
Training loss: 2.243619441986084
Validation loss: 2.013401448726654

Epoch: 6| Step: 4
Training loss: 1.8837546110153198
Validation loss: 2.0073596636454263

Epoch: 6| Step: 5
Training loss: 1.5699820518493652
Validation loss: 2.010987917582194

Epoch: 6| Step: 6
Training loss: 2.164076328277588
Validation loss: 2.0093975563844046

Epoch: 6| Step: 7
Training loss: 2.033007860183716
Validation loss: 2.0067805846532187

Epoch: 6| Step: 8
Training loss: 1.823715090751648
Validation loss: 2.0142816305160522

Epoch: 6| Step: 9
Training loss: 1.800117015838623
Validation loss: 1.9999315738677979

Epoch: 6| Step: 10
Training loss: 2.0151491165161133
Validation loss: 2.0014272729555764

Epoch: 6| Step: 11
Training loss: 1.5198415517807007
Validation loss: 2.0068666537602744

Epoch: 6| Step: 12
Training loss: 1.9559357166290283
Validation loss: 2.0063430666923523

Epoch: 6| Step: 13
Training loss: 2.2621636390686035
Validation loss: 2.0084593494733176

Epoch: 38| Step: 0
Training loss: 1.6757490634918213
Validation loss: 2.0014041662216187

Epoch: 6| Step: 1
Training loss: 1.408373475074768
Validation loss: 1.9985706011454265

Epoch: 6| Step: 2
Training loss: 2.319136142730713
Validation loss: 2.005034585793813

Epoch: 6| Step: 3
Training loss: 1.6066181659698486
Validation loss: 1.981941282749176

Epoch: 6| Step: 4
Training loss: 1.8178820610046387
Validation loss: 1.9935732285181682

Epoch: 6| Step: 5
Training loss: 1.814293622970581
Validation loss: 1.9959566990534465

Epoch: 6| Step: 6
Training loss: 2.1545820236206055
Validation loss: 2.0086824099222818

Epoch: 6| Step: 7
Training loss: 1.7151892185211182
Validation loss: 2.017892360687256

Epoch: 6| Step: 8
Training loss: 2.2881526947021484
Validation loss: 2.0121109088261924

Epoch: 6| Step: 9
Training loss: 1.478161096572876
Validation loss: 2.0045318802197776

Epoch: 6| Step: 10
Training loss: 2.167776584625244
Validation loss: 2.0051648020744324

Epoch: 6| Step: 11
Training loss: 1.6192634105682373
Validation loss: 2.0124030311902366

Epoch: 6| Step: 12
Training loss: 2.6646971702575684
Validation loss: 2.022591849168142

Epoch: 6| Step: 13
Training loss: 2.2587428092956543
Validation loss: 2.0295846263567605

Epoch: 39| Step: 0
Training loss: 2.1125400066375732
Validation loss: 2.0633318026860556

Epoch: 6| Step: 1
Training loss: 2.0284910202026367
Validation loss: 2.050233523050944

Epoch: 6| Step: 2
Training loss: 1.8403589725494385
Validation loss: 2.0786240100860596

Epoch: 6| Step: 3
Training loss: 1.962257742881775
Validation loss: 2.1055538654327393

Epoch: 6| Step: 4
Training loss: 1.9101470708847046
Validation loss: 2.126573065916697

Epoch: 6| Step: 5
Training loss: 1.6102646589279175
Validation loss: 2.0832412242889404

Epoch: 6| Step: 6
Training loss: 2.1992528438568115
Validation loss: 2.095072011152903

Epoch: 6| Step: 7
Training loss: 2.440925121307373
Validation loss: 2.081831395626068

Epoch: 6| Step: 8
Training loss: 1.6720855236053467
Validation loss: 2.059473236401876

Epoch: 6| Step: 9
Training loss: 2.2413222789764404
Validation loss: 2.0471853812535605

Epoch: 6| Step: 10
Training loss: 2.143812417984009
Validation loss: 2.017085313796997

Epoch: 6| Step: 11
Training loss: 1.817491054534912
Validation loss: 2.006627678871155

Epoch: 6| Step: 12
Training loss: 1.9134466648101807
Validation loss: 2.0102100372314453

Epoch: 6| Step: 13
Training loss: 1.3924517631530762
Validation loss: 1.995332956314087

Epoch: 40| Step: 0
Training loss: 1.9955137968063354
Validation loss: 2.009489973386129

Epoch: 6| Step: 1
Training loss: 1.7074904441833496
Validation loss: 2.005776822566986

Epoch: 6| Step: 2
Training loss: 2.3885698318481445
Validation loss: 1.9953277111053467

Epoch: 6| Step: 3
Training loss: 1.521794319152832
Validation loss: 1.9875810941060383

Epoch: 6| Step: 4
Training loss: 2.3311166763305664
Validation loss: 1.996685008207957

Epoch: 6| Step: 5
Training loss: 1.4858322143554688
Validation loss: 1.99998144308726

Epoch: 6| Step: 6
Training loss: 2.013221263885498
Validation loss: 1.9955521821975708

Epoch: 6| Step: 7
Training loss: 2.6072845458984375
Validation loss: 2.0172794461250305

Epoch: 6| Step: 8
Training loss: 2.091442823410034
Validation loss: 1.9986133376757305

Epoch: 6| Step: 9
Training loss: 1.8412730693817139
Validation loss: 1.981975257396698

Epoch: 6| Step: 10
Training loss: 1.9653282165527344
Validation loss: 1.9993811249732971

Epoch: 6| Step: 11
Training loss: 1.8960387706756592
Validation loss: 2.0051923990249634

Epoch: 6| Step: 12
Training loss: 1.485546588897705
Validation loss: 1.9917286237080891

Epoch: 6| Step: 13
Training loss: 1.8647685050964355
Validation loss: 2.0073646108309426

Epoch: 41| Step: 0
Training loss: 1.7926772832870483
Validation loss: 2.0071395436922708

Epoch: 6| Step: 1
Training loss: 1.4756686687469482
Validation loss: 2.0332605242729187

Epoch: 6| Step: 2
Training loss: 1.9287244081497192
Validation loss: 2.050881564617157

Epoch: 6| Step: 3
Training loss: 2.3214030265808105
Validation loss: 2.0237062176068625

Epoch: 6| Step: 4
Training loss: 1.890550971031189
Validation loss: 2.0639888644218445

Epoch: 6| Step: 5
Training loss: 2.6315717697143555
Validation loss: 2.0482287605603537

Epoch: 6| Step: 6
Training loss: 2.4700706005096436
Validation loss: 2.072926620642344

Epoch: 6| Step: 7
Training loss: 2.250053882598877
Validation loss: 2.0612197319666543

Epoch: 6| Step: 8
Training loss: 1.8180369138717651
Validation loss: 2.0640978813171387

Epoch: 6| Step: 9
Training loss: 1.6038620471954346
Validation loss: 2.0773205955823264

Epoch: 6| Step: 10
Training loss: 1.5667989253997803
Validation loss: 2.049727737903595

Epoch: 6| Step: 11
Training loss: 2.526728391647339
Validation loss: 2.058388829231262

Epoch: 6| Step: 12
Training loss: 1.9467837810516357
Validation loss: 2.032498757044474

Epoch: 6| Step: 13
Training loss: 0.961211085319519
Validation loss: 2.0245757500330606

Epoch: 42| Step: 0
Training loss: 1.9181523323059082
Validation loss: 2.027815898259481

Epoch: 6| Step: 1
Training loss: 2.096484661102295
Validation loss: 1.9860043327013652

Epoch: 6| Step: 2
Training loss: 1.4623215198516846
Validation loss: 2.0099812150001526

Epoch: 6| Step: 3
Training loss: 1.9189906120300293
Validation loss: 1.9911711812019348

Epoch: 6| Step: 4
Training loss: 1.424415111541748
Validation loss: 1.9912802179654439

Epoch: 6| Step: 5
Training loss: 2.0880911350250244
Validation loss: 1.9852185050646465

Epoch: 6| Step: 6
Training loss: 1.6348624229431152
Validation loss: 1.992207368214925

Epoch: 6| Step: 7
Training loss: 1.9758145809173584
Validation loss: 2.026285727818807

Epoch: 6| Step: 8
Training loss: 1.7095905542373657
Validation loss: 2.020500600337982

Epoch: 6| Step: 9
Training loss: 2.2690815925598145
Validation loss: 2.0231462319691977

Epoch: 6| Step: 10
Training loss: 2.2923433780670166
Validation loss: 2.0105963150660195

Epoch: 6| Step: 11
Training loss: 2.0775389671325684
Validation loss: 2.0192194183667502

Epoch: 6| Step: 12
Training loss: 2.075972080230713
Validation loss: 2.029634733994802

Epoch: 6| Step: 13
Training loss: 1.996209740638733
Validation loss: 2.018351137638092

Epoch: 43| Step: 0
Training loss: 1.705225944519043
Validation loss: 2.019878009955088

Epoch: 6| Step: 1
Training loss: 1.6375854015350342
Validation loss: 2.0316991408665976

Epoch: 6| Step: 2
Training loss: 1.8288781642913818
Validation loss: 2.0255282719930015

Epoch: 6| Step: 3
Training loss: 2.0381789207458496
Validation loss: 2.020822803179423

Epoch: 6| Step: 4
Training loss: 2.1087098121643066
Validation loss: 2.0325796206792197

Epoch: 6| Step: 5
Training loss: 2.5634093284606934
Validation loss: 2.0144872864087424

Epoch: 6| Step: 6
Training loss: 1.9272863864898682
Validation loss: 2.02219428618749

Epoch: 6| Step: 7
Training loss: 1.9803293943405151
Validation loss: 2.0155789852142334

Epoch: 6| Step: 8
Training loss: 1.5690569877624512
Validation loss: 2.028115729490916

Epoch: 6| Step: 9
Training loss: 2.6755895614624023
Validation loss: 2.0257615645726523

Epoch: 6| Step: 10
Training loss: 1.8342206478118896
Validation loss: 2.016450266043345

Epoch: 6| Step: 11
Training loss: 1.715397596359253
Validation loss: 2.0219789147377014

Epoch: 6| Step: 12
Training loss: 1.6058769226074219
Validation loss: 2.0338019132614136

Epoch: 6| Step: 13
Training loss: 1.3557493686676025
Validation loss: 2.0217838486035666

Epoch: 44| Step: 0
Training loss: 1.4164495468139648
Validation loss: 2.0305071473121643

Epoch: 6| Step: 1
Training loss: 2.146617889404297
Validation loss: 2.0258419116338096

Epoch: 6| Step: 2
Training loss: 2.329944372177124
Validation loss: 2.0390594402949014

Epoch: 6| Step: 3
Training loss: 1.963876724243164
Validation loss: 2.0013318061828613

Epoch: 6| Step: 4
Training loss: 1.418923258781433
Validation loss: 2.038709302743276

Epoch: 6| Step: 5
Training loss: 1.8331289291381836
Validation loss: 2.0279789765675864

Epoch: 6| Step: 6
Training loss: 2.0998430252075195
Validation loss: 2.0172300934791565

Epoch: 6| Step: 7
Training loss: 2.190290927886963
Validation loss: 2.0340649286905923

Epoch: 6| Step: 8
Training loss: 2.1175448894500732
Validation loss: 2.025283912817637

Epoch: 6| Step: 9
Training loss: 1.7274231910705566
Validation loss: 2.013247489929199

Epoch: 6| Step: 10
Training loss: 1.7889823913574219
Validation loss: 2.0266422033309937

Epoch: 6| Step: 11
Training loss: 1.7124073505401611
Validation loss: 2.0234495997428894

Epoch: 6| Step: 12
Training loss: 2.3386003971099854
Validation loss: 2.0239624977111816

Epoch: 6| Step: 13
Training loss: 1.5433650016784668
Validation loss: 2.023082693417867

Epoch: 45| Step: 0
Training loss: 1.9029784202575684
Validation loss: 2.030999481678009

Epoch: 6| Step: 1
Training loss: 1.4340333938598633
Validation loss: 2.0093297561009726

Epoch: 6| Step: 2
Training loss: 1.8479130268096924
Validation loss: 2.0162203510602317

Epoch: 6| Step: 3
Training loss: 2.20713210105896
Validation loss: 2.0166980226834617

Epoch: 6| Step: 4
Training loss: 1.7717219591140747
Validation loss: 1.981275200843811

Epoch: 6| Step: 5
Training loss: 2.368163585662842
Validation loss: 1.9821690519650776

Epoch: 6| Step: 6
Training loss: 2.227433681488037
Validation loss: 1.9809486865997314

Epoch: 6| Step: 7
Training loss: 1.8139164447784424
Validation loss: 1.9848504463831584

Epoch: 6| Step: 8
Training loss: 1.1548659801483154
Validation loss: 1.9755922555923462

Epoch: 6| Step: 9
Training loss: 1.6656668186187744
Validation loss: 1.967435399691264

Epoch: 6| Step: 10
Training loss: 1.8052774667739868
Validation loss: 1.991977592309316

Epoch: 6| Step: 11
Training loss: 2.701295852661133
Validation loss: 1.9951002597808838

Epoch: 6| Step: 12
Training loss: 1.8614940643310547
Validation loss: 1.987740417321523

Epoch: 6| Step: 13
Training loss: 2.006544351577759
Validation loss: 2.002737065156301

Epoch: 46| Step: 0
Training loss: 1.8470826148986816
Validation loss: 2.006787816683451

Epoch: 6| Step: 1
Training loss: 1.9484561681747437
Validation loss: 2.0238503019014993

Epoch: 6| Step: 2
Training loss: 1.5415202379226685
Validation loss: 2.0287668108940125

Epoch: 6| Step: 3
Training loss: 1.9389094114303589
Validation loss: 2.018332302570343

Epoch: 6| Step: 4
Training loss: 2.23397159576416
Validation loss: 2.054764191309611

Epoch: 6| Step: 5
Training loss: 2.2457022666931152
Validation loss: 2.064348896344503

Epoch: 6| Step: 6
Training loss: 1.7043914794921875
Validation loss: 2.073556343714396

Epoch: 6| Step: 7
Training loss: 2.3077354431152344
Validation loss: 2.0519441763559976

Epoch: 6| Step: 8
Training loss: 2.0896615982055664
Validation loss: 2.0552801291147866

Epoch: 6| Step: 9
Training loss: 2.316380262374878
Validation loss: 2.003617227077484

Epoch: 6| Step: 10
Training loss: 1.9023876190185547
Validation loss: 1.9930104811986287

Epoch: 6| Step: 11
Training loss: 1.7760525941848755
Validation loss: 1.9876416722933452

Epoch: 6| Step: 12
Training loss: 1.4945238828659058
Validation loss: 2.0031711657842

Epoch: 6| Step: 13
Training loss: 2.115957260131836
Validation loss: 1.9807244936625164

Epoch: 47| Step: 0
Training loss: 2.5736777782440186
Validation loss: 1.9830200672149658

Epoch: 6| Step: 1
Training loss: 1.779435634613037
Validation loss: 1.9817628463109334

Epoch: 6| Step: 2
Training loss: 2.421149253845215
Validation loss: 1.9782141049702961

Epoch: 6| Step: 3
Training loss: 1.910914421081543
Validation loss: 2.008192718029022

Epoch: 6| Step: 4
Training loss: 2.3574557304382324
Validation loss: 1.9796429077784221

Epoch: 6| Step: 5
Training loss: 1.3740620613098145
Validation loss: 1.9858476519584656

Epoch: 6| Step: 6
Training loss: 1.8425878286361694
Validation loss: 2.0057401061058044

Epoch: 6| Step: 7
Training loss: 1.926275372505188
Validation loss: 1.9975303610165913

Epoch: 6| Step: 8
Training loss: 1.48954439163208
Validation loss: 2.01669450600942

Epoch: 6| Step: 9
Training loss: 2.614989995956421
Validation loss: 2.0131587187449136

Epoch: 6| Step: 10
Training loss: 1.8065354824066162
Validation loss: 2.0153566201527915

Epoch: 6| Step: 11
Training loss: 1.3519316911697388
Validation loss: 2.0152058005332947

Epoch: 6| Step: 12
Training loss: 1.6176739931106567
Validation loss: 2.0135684609413147

Epoch: 6| Step: 13
Training loss: 1.5406734943389893
Validation loss: 2.014824867248535

Epoch: 48| Step: 0
Training loss: 1.1610922813415527
Validation loss: 2.0337676207224527

Epoch: 6| Step: 1
Training loss: 1.55967116355896
Validation loss: 2.0574124852816262

Epoch: 6| Step: 2
Training loss: 1.6458052396774292
Validation loss: 2.055640757083893

Epoch: 6| Step: 3
Training loss: 1.8453760147094727
Validation loss: 2.033230781555176

Epoch: 6| Step: 4
Training loss: 2.5975799560546875
Validation loss: 2.029550472895304

Epoch: 6| Step: 5
Training loss: 2.062479257583618
Validation loss: 2.029270827770233

Epoch: 6| Step: 6
Training loss: 2.1754705905914307
Validation loss: 2.02543572584788

Epoch: 6| Step: 7
Training loss: 1.7820637226104736
Validation loss: 2.0132896105448403

Epoch: 6| Step: 8
Training loss: 2.89599871635437
Validation loss: 2.00228883822759

Epoch: 6| Step: 9
Training loss: 2.059170722961426
Validation loss: 1.999708930651347

Epoch: 6| Step: 10
Training loss: 2.348087787628174
Validation loss: 2.0180710355440774

Epoch: 6| Step: 11
Training loss: 1.5156919956207275
Validation loss: 1.9821057120958965

Epoch: 6| Step: 12
Training loss: 1.0537080764770508
Validation loss: 1.9838887850443523

Epoch: 6| Step: 13
Training loss: 1.8733397722244263
Validation loss: 2.0214383204778037

Epoch: 49| Step: 0
Training loss: 1.750922679901123
Validation loss: 1.9986013571421306

Epoch: 6| Step: 1
Training loss: 2.096172332763672
Validation loss: 1.999645988146464

Epoch: 6| Step: 2
Training loss: 2.4249672889709473
Validation loss: 1.9944690664609273

Epoch: 6| Step: 3
Training loss: 2.3247323036193848
Validation loss: 2.0028876066207886

Epoch: 6| Step: 4
Training loss: 1.820823311805725
Validation loss: 1.984031577905019

Epoch: 6| Step: 5
Training loss: 1.827711582183838
Validation loss: 1.992150088151296

Epoch: 6| Step: 6
Training loss: 1.703011155128479
Validation loss: 1.9962818423906963

Epoch: 6| Step: 7
Training loss: 1.7851080894470215
Validation loss: 2.0222017765045166

Epoch: 6| Step: 8
Training loss: 1.5934430360794067
Validation loss: 2.0128621657689414

Epoch: 6| Step: 9
Training loss: 2.087301731109619
Validation loss: 2.01813797156016

Epoch: 6| Step: 10
Training loss: 1.9683092832565308
Validation loss: 2.009644786516825

Epoch: 6| Step: 11
Training loss: 1.7627729177474976
Validation loss: 2.0381849805514016

Epoch: 6| Step: 12
Training loss: 1.654942274093628
Validation loss: 2.0231454173723855

Epoch: 6| Step: 13
Training loss: 1.6832706928253174
Validation loss: 2.0393791794776917

Epoch: 50| Step: 0
Training loss: 1.6838016510009766
Validation loss: 2.0158819953600564

Epoch: 6| Step: 1
Training loss: 1.6909410953521729
Validation loss: 2.004948357741038

Epoch: 6| Step: 2
Training loss: 2.190767765045166
Validation loss: 2.0009573101997375

Epoch: 6| Step: 3
Training loss: 2.074794292449951
Validation loss: 1.9879802465438843

Epoch: 6| Step: 4
Training loss: 1.7899410724639893
Validation loss: 2.010651409626007

Epoch: 6| Step: 5
Training loss: 2.4562737941741943
Validation loss: 2.002462069193522

Epoch: 6| Step: 6
Training loss: 2.1516189575195312
Validation loss: 1.9882580041885376

Epoch: 6| Step: 7
Training loss: 1.9292373657226562
Validation loss: 1.9812599619229634

Epoch: 6| Step: 8
Training loss: 2.3791885375976562
Validation loss: 1.9956263105074565

Epoch: 6| Step: 9
Training loss: 2.0336380004882812
Validation loss: 2.0011202096939087

Epoch: 6| Step: 10
Training loss: 1.7827324867248535
Validation loss: 1.9898681441942851

Epoch: 6| Step: 11
Training loss: 1.7453280687332153
Validation loss: 2.0139075915018716

Epoch: 6| Step: 12
Training loss: 1.4560506343841553
Validation loss: 2.003656526406606

Epoch: 6| Step: 13
Training loss: 1.0680205821990967
Validation loss: 2.0228859384854636

Epoch: 51| Step: 0
Training loss: 1.3634800910949707
Validation loss: 1.9994573593139648

Epoch: 6| Step: 1
Training loss: 2.481006383895874
Validation loss: 2.0039794643719993

Epoch: 6| Step: 2
Training loss: 1.6262216567993164
Validation loss: 2.0209351976712546

Epoch: 6| Step: 3
Training loss: 1.405310034751892
Validation loss: 2.030846873919169

Epoch: 6| Step: 4
Training loss: 2.1205456256866455
Validation loss: 2.0420113801956177

Epoch: 6| Step: 5
Training loss: 1.8039354085922241
Validation loss: 2.0032414396603904

Epoch: 6| Step: 6
Training loss: 2.486440658569336
Validation loss: 2.0380067229270935

Epoch: 6| Step: 7
Training loss: 2.2490830421447754
Validation loss: 2.009178558985392

Epoch: 6| Step: 8
Training loss: 1.146806240081787
Validation loss: 2.011665463447571

Epoch: 6| Step: 9
Training loss: 1.8680521249771118
Validation loss: 2.0065643191337585

Epoch: 6| Step: 10
Training loss: 1.6536433696746826
Validation loss: 2.0048951705296836

Epoch: 6| Step: 11
Training loss: 1.9624876976013184
Validation loss: 2.001811663309733

Epoch: 6| Step: 12
Training loss: 2.5047428607940674
Validation loss: 2.0044968922932944

Epoch: 6| Step: 13
Training loss: 1.7649917602539062
Validation loss: 2.025997281074524

Epoch: 52| Step: 0
Training loss: 1.7591967582702637
Validation loss: 1.9958125154177349

Epoch: 6| Step: 1
Training loss: 2.0642786026000977
Validation loss: 1.979745904604594

Epoch: 6| Step: 2
Training loss: 1.8950395584106445
Validation loss: 1.9964349667231243

Epoch: 6| Step: 3
Training loss: 1.7233237028121948
Validation loss: 1.98127019405365

Epoch: 6| Step: 4
Training loss: 1.1566299200057983
Validation loss: 2.008839964866638

Epoch: 6| Step: 5
Training loss: 1.8988381624221802
Validation loss: 1.9866049488385518

Epoch: 6| Step: 6
Training loss: 1.5668442249298096
Validation loss: 1.9790976842244465

Epoch: 6| Step: 7
Training loss: 2.5318398475646973
Validation loss: 1.9741900364557903

Epoch: 6| Step: 8
Training loss: 1.6850367784500122
Validation loss: 1.9850300749142964

Epoch: 6| Step: 9
Training loss: 2.0118041038513184
Validation loss: 1.978460669517517

Epoch: 6| Step: 10
Training loss: 1.8348839282989502
Validation loss: 1.9666612148284912

Epoch: 6| Step: 11
Training loss: 2.0529026985168457
Validation loss: 1.9941342274347942

Epoch: 6| Step: 12
Training loss: 2.0953316688537598
Validation loss: 2.0140600204467773

Epoch: 6| Step: 13
Training loss: 2.1513242721557617
Validation loss: 1.9987844228744507

Epoch: 53| Step: 0
Training loss: 1.483426570892334
Validation loss: 2.012828767299652

Epoch: 6| Step: 1
Training loss: 1.7215865850448608
Validation loss: 2.025665521621704

Epoch: 6| Step: 2
Training loss: 2.1714043617248535
Validation loss: 2.0450997352600098

Epoch: 6| Step: 3
Training loss: 1.4444677829742432
Validation loss: 2.0524020195007324

Epoch: 6| Step: 4
Training loss: 2.218752384185791
Validation loss: 2.084299643834432

Epoch: 6| Step: 5
Training loss: 1.425106406211853
Validation loss: 2.088384985923767

Epoch: 6| Step: 6
Training loss: 1.8604955673217773
Validation loss: 2.097064812978109

Epoch: 6| Step: 7
Training loss: 2.4295289516448975
Validation loss: 2.0743667483329773

Epoch: 6| Step: 8
Training loss: 2.2651846408843994
Validation loss: 2.0287696917851767

Epoch: 6| Step: 9
Training loss: 2.157402992248535
Validation loss: 1.9880869785944622

Epoch: 6| Step: 10
Training loss: 2.2119829654693604
Validation loss: 2.00169571240743

Epoch: 6| Step: 11
Training loss: 1.4145243167877197
Validation loss: 1.99379297097524

Epoch: 6| Step: 12
Training loss: 2.4165406227111816
Validation loss: 1.9873532056808472

Epoch: 6| Step: 13
Training loss: 1.683197021484375
Validation loss: 1.9661260843276978

Epoch: 54| Step: 0
Training loss: 1.7503092288970947
Validation loss: 1.9869000514348347

Epoch: 6| Step: 1
Training loss: 1.6264671087265015
Validation loss: 1.9627535144488018

Epoch: 6| Step: 2
Training loss: 1.9038933515548706
Validation loss: 1.991079608599345

Epoch: 6| Step: 3
Training loss: 1.8844739198684692
Validation loss: 1.987968881924947

Epoch: 6| Step: 4
Training loss: 1.8888652324676514
Validation loss: 2.0218756000200906

Epoch: 6| Step: 5
Training loss: 1.8955345153808594
Validation loss: 2.0186562538146973

Epoch: 6| Step: 6
Training loss: 2.7024669647216797
Validation loss: 2.0225671927134194

Epoch: 6| Step: 7
Training loss: 1.4292445182800293
Validation loss: 2.0414448181788125

Epoch: 6| Step: 8
Training loss: 1.8530116081237793
Validation loss: 2.0230042934417725

Epoch: 6| Step: 9
Training loss: 1.8425469398498535
Validation loss: 2.050073742866516

Epoch: 6| Step: 10
Training loss: 1.9847745895385742
Validation loss: 2.023996373017629

Epoch: 6| Step: 11
Training loss: 2.7230165004730225
Validation loss: 2.0359833041826882

Epoch: 6| Step: 12
Training loss: 1.5865895748138428
Validation loss: 2.031309187412262

Epoch: 6| Step: 13
Training loss: 1.4589017629623413
Validation loss: 2.015968064467112

Epoch: 55| Step: 0
Training loss: 1.8220139741897583
Validation loss: 2.0074462493260703

Epoch: 6| Step: 1
Training loss: 1.947214961051941
Validation loss: 2.008303423722585

Epoch: 6| Step: 2
Training loss: 1.7870570421218872
Validation loss: 1.9924893975257874

Epoch: 6| Step: 3
Training loss: 1.2766163349151611
Validation loss: 1.9727117419242859

Epoch: 6| Step: 4
Training loss: 2.5089645385742188
Validation loss: 1.9891287088394165

Epoch: 6| Step: 5
Training loss: 1.7228333950042725
Validation loss: 1.9911874930063884

Epoch: 6| Step: 6
Training loss: 1.9949685335159302
Validation loss: 1.9797541499137878

Epoch: 6| Step: 7
Training loss: 1.8551082611083984
Validation loss: 1.996318519115448

Epoch: 6| Step: 8
Training loss: 1.7675135135650635
Validation loss: 1.9879650870958965

Epoch: 6| Step: 9
Training loss: 1.8700411319732666
Validation loss: 1.9945074915885925

Epoch: 6| Step: 10
Training loss: 1.6098508834838867
Validation loss: 2.005557417869568

Epoch: 6| Step: 11
Training loss: 2.363089084625244
Validation loss: 2.014267901579539

Epoch: 6| Step: 12
Training loss: 2.176726818084717
Validation loss: 2.011139432589213

Epoch: 6| Step: 13
Training loss: 1.4425227642059326
Validation loss: 1.991424838701884

Epoch: 56| Step: 0
Training loss: 1.8067915439605713
Validation loss: 2.0155590772628784

Epoch: 6| Step: 1
Training loss: 2.556915283203125
Validation loss: 2.034590244293213

Epoch: 6| Step: 2
Training loss: 2.2333984375
Validation loss: 2.0181620915730796

Epoch: 6| Step: 3
Training loss: 1.8086777925491333
Validation loss: 2.0236082871754966

Epoch: 6| Step: 4
Training loss: 1.8346608877182007
Validation loss: 1.9926666220029194

Epoch: 6| Step: 5
Training loss: 1.3779375553131104
Validation loss: 1.9993809461593628

Epoch: 6| Step: 6
Training loss: 1.7232489585876465
Validation loss: 2.0303292274475098

Epoch: 6| Step: 7
Training loss: 1.5793588161468506
Validation loss: 2.029190719127655

Epoch: 6| Step: 8
Training loss: 2.170621156692505
Validation loss: 2.048655947049459

Epoch: 6| Step: 9
Training loss: 1.8369101285934448
Validation loss: 2.0278654297192893

Epoch: 6| Step: 10
Training loss: 1.612685203552246
Validation loss: 2.0211898485819497

Epoch: 6| Step: 11
Training loss: 1.809006690979004
Validation loss: 2.032885750134786

Epoch: 6| Step: 12
Training loss: 2.5116052627563477
Validation loss: 2.0252994100252786

Epoch: 6| Step: 13
Training loss: 1.3573615550994873
Validation loss: 1.990859826405843

Epoch: 57| Step: 0
Training loss: 2.00870943069458
Validation loss: 2.005534907182058

Epoch: 6| Step: 1
Training loss: 2.0611777305603027
Validation loss: 1.9845231572786968

Epoch: 6| Step: 2
Training loss: 2.4245901107788086
Validation loss: 2.003577709197998

Epoch: 6| Step: 3
Training loss: 1.887795090675354
Validation loss: 1.982656717300415

Epoch: 6| Step: 4
Training loss: 1.3300386667251587
Validation loss: 1.9796748359998066

Epoch: 6| Step: 5
Training loss: 1.5986006259918213
Validation loss: 1.9887284636497498

Epoch: 6| Step: 6
Training loss: 2.08740234375
Validation loss: 1.975957949956258

Epoch: 6| Step: 7
Training loss: 1.8084540367126465
Validation loss: 1.9787328044573467

Epoch: 6| Step: 8
Training loss: 1.8237628936767578
Validation loss: 2.004922409852346

Epoch: 6| Step: 9
Training loss: 1.7928946018218994
Validation loss: 2.0064004262288413

Epoch: 6| Step: 10
Training loss: 1.898742914199829
Validation loss: 2.0094076792399087

Epoch: 6| Step: 11
Training loss: 2.1541857719421387
Validation loss: 2.0588881174723306

Epoch: 6| Step: 12
Training loss: 1.0941493511199951
Validation loss: 2.075246969858805

Epoch: 6| Step: 13
Training loss: 2.0677847862243652
Validation loss: 2.060811003049215

Epoch: 58| Step: 0
Training loss: 1.5591543912887573
Validation loss: 2.0924892822901406

Epoch: 6| Step: 1
Training loss: 2.524745464324951
Validation loss: 2.0836032827695212

Epoch: 6| Step: 2
Training loss: 2.119723081588745
Validation loss: 2.07487420241038

Epoch: 6| Step: 3
Training loss: 1.8801747560501099
Validation loss: 2.091789186000824

Epoch: 6| Step: 4
Training loss: 1.7591018676757812
Validation loss: 2.0691481232643127

Epoch: 6| Step: 5
Training loss: 1.748677372932434
Validation loss: 2.06522931655248

Epoch: 6| Step: 6
Training loss: 1.4743239879608154
Validation loss: 2.028189996878306

Epoch: 6| Step: 7
Training loss: 1.9184305667877197
Validation loss: 2.0068443218866983

Epoch: 6| Step: 8
Training loss: 2.2248497009277344
Validation loss: 2.038165509700775

Epoch: 6| Step: 9
Training loss: 1.8125630617141724
Validation loss: 2.012822469075521

Epoch: 6| Step: 10
Training loss: 2.3731846809387207
Validation loss: 2.0286494294802346

Epoch: 6| Step: 11
Training loss: 1.497197151184082
Validation loss: 2.0236900051434836

Epoch: 6| Step: 12
Training loss: 2.0372047424316406
Validation loss: 2.022665003935496

Epoch: 6| Step: 13
Training loss: 1.3788983821868896
Validation loss: 2.031085968017578

Epoch: 59| Step: 0
Training loss: 1.8025619983673096
Validation loss: 2.0029587944348655

Epoch: 6| Step: 1
Training loss: 1.5566338300704956
Validation loss: 2.0114305218060813

Epoch: 6| Step: 2
Training loss: 1.891857624053955
Validation loss: 1.979028860727946

Epoch: 6| Step: 3
Training loss: 1.6644864082336426
Validation loss: 2.004828770955404

Epoch: 6| Step: 4
Training loss: 2.0735440254211426
Validation loss: 1.9971273342768352

Epoch: 6| Step: 5
Training loss: 1.7942886352539062
Validation loss: 2.0133668382962546

Epoch: 6| Step: 6
Training loss: 1.7535526752471924
Validation loss: 2.0162543654441833

Epoch: 6| Step: 7
Training loss: 1.829952597618103
Validation loss: 2.0097498496373496

Epoch: 6| Step: 8
Training loss: 1.6577832698822021
Validation loss: 2.008037587006887

Epoch: 6| Step: 9
Training loss: 1.978738784790039
Validation loss: 2.0237895846366882

Epoch: 6| Step: 10
Training loss: 2.0619263648986816
Validation loss: 2.01765247186025

Epoch: 6| Step: 11
Training loss: 1.3008052110671997
Validation loss: 1.993315617243449

Epoch: 6| Step: 12
Training loss: 1.9077003002166748
Validation loss: 1.9867214163144429

Epoch: 6| Step: 13
Training loss: 2.597158908843994
Validation loss: 2.0031238198280334

Epoch: 60| Step: 0
Training loss: 2.3204445838928223
Validation loss: 1.9918354749679565

Epoch: 6| Step: 1
Training loss: 1.709399700164795
Validation loss: 1.9713130990664165

Epoch: 6| Step: 2
Training loss: 2.484281539916992
Validation loss: 1.9894874890645344

Epoch: 6| Step: 3
Training loss: 1.468526005744934
Validation loss: 2.000906825065613

Epoch: 6| Step: 4
Training loss: 1.7301807403564453
Validation loss: 1.9591188033421834

Epoch: 6| Step: 5
Training loss: 2.2903075218200684
Validation loss: 1.972135325272878

Epoch: 6| Step: 6
Training loss: 1.8221511840820312
Validation loss: 1.9933348894119263

Epoch: 6| Step: 7
Training loss: 1.872050166130066
Validation loss: 1.984038531780243

Epoch: 6| Step: 8
Training loss: 1.8624029159545898
Validation loss: 1.9860633810361226

Epoch: 6| Step: 9
Training loss: 1.0829871892929077
Validation loss: 1.9964498281478882

Epoch: 6| Step: 10
Training loss: 1.6598477363586426
Validation loss: 2.0054353872934976

Epoch: 6| Step: 11
Training loss: 1.2995260953903198
Validation loss: 2.026073237260183

Epoch: 6| Step: 12
Training loss: 2.3228065967559814
Validation loss: 2.0271735787391663

Epoch: 6| Step: 13
Training loss: 1.8816536664962769
Validation loss: 2.0846346815427146

Epoch: 61| Step: 0
Training loss: 1.915426254272461
Validation loss: 2.1207156976064048

Epoch: 6| Step: 1
Training loss: 2.528675079345703
Validation loss: 2.123583892981211

Epoch: 6| Step: 2
Training loss: 1.6284757852554321
Validation loss: 2.1483423511187234

Epoch: 6| Step: 3
Training loss: 1.7044121026992798
Validation loss: 2.148343582948049

Epoch: 6| Step: 4
Training loss: 1.6541187763214111
Validation loss: 2.1356890400250754

Epoch: 6| Step: 5
Training loss: 1.2745951414108276
Validation loss: 2.1212206880251565

Epoch: 6| Step: 6
Training loss: 1.926999807357788
Validation loss: 2.0954915086428323

Epoch: 6| Step: 7
Training loss: 1.3927878141403198
Validation loss: 2.0717201431592307

Epoch: 6| Step: 8
Training loss: 2.0373048782348633
Validation loss: 2.0434784293174744

Epoch: 6| Step: 9
Training loss: 2.0059092044830322
Validation loss: 2.013728698094686

Epoch: 6| Step: 10
Training loss: 2.2518277168273926
Validation loss: 1.9990385174751282

Epoch: 6| Step: 11
Training loss: 1.6533057689666748
Validation loss: 1.9973498185475667

Epoch: 6| Step: 12
Training loss: 2.048874616622925
Validation loss: 2.0003561973571777

Epoch: 6| Step: 13
Training loss: 1.950310468673706
Validation loss: 1.9618390202522278

Epoch: 62| Step: 0
Training loss: 1.9095627069473267
Validation loss: 1.9776206612586975

Epoch: 6| Step: 1
Training loss: 1.4002609252929688
Validation loss: 1.9850924213727315

Epoch: 6| Step: 2
Training loss: 1.4015355110168457
Validation loss: 1.9769699374834697

Epoch: 6| Step: 3
Training loss: 1.7627959251403809
Validation loss: 1.9699456095695496

Epoch: 6| Step: 4
Training loss: 1.523431658744812
Validation loss: 1.9784392913182576

Epoch: 6| Step: 5
Training loss: 2.0539464950561523
Validation loss: 1.965695897738139

Epoch: 6| Step: 6
Training loss: 1.8933801651000977
Validation loss: 1.9856863220532734

Epoch: 6| Step: 7
Training loss: 1.9106987714767456
Validation loss: 1.977982501188914

Epoch: 6| Step: 8
Training loss: 2.4260780811309814
Validation loss: 2.002244154612223

Epoch: 6| Step: 9
Training loss: 1.8667224645614624
Validation loss: 1.999997119108836

Epoch: 6| Step: 10
Training loss: 2.040280342102051
Validation loss: 1.9760958552360535

Epoch: 6| Step: 11
Training loss: 1.8308115005493164
Validation loss: 1.9916030367215474

Epoch: 6| Step: 12
Training loss: 2.2930290699005127
Validation loss: 2.037590821584066

Epoch: 6| Step: 13
Training loss: 1.6587674617767334
Validation loss: 2.0309381087621055

Epoch: 63| Step: 0
Training loss: 1.745138168334961
Validation loss: 2.0268483757972717

Epoch: 6| Step: 1
Training loss: 1.8886833190917969
Validation loss: 2.046624561150869

Epoch: 6| Step: 2
Training loss: 1.7576193809509277
Validation loss: 2.0267287691434226

Epoch: 6| Step: 3
Training loss: 1.20035719871521
Validation loss: 2.031633218129476

Epoch: 6| Step: 4
Training loss: 1.7298341989517212
Validation loss: 2.032509922981262

Epoch: 6| Step: 5
Training loss: 1.7969732284545898
Validation loss: 2.01181697845459

Epoch: 6| Step: 6
Training loss: 1.8925282955169678
Validation loss: 1.997858742872874

Epoch: 6| Step: 7
Training loss: 1.8509736061096191
Validation loss: 1.9907102584838867

Epoch: 6| Step: 8
Training loss: 1.7627787590026855
Validation loss: 1.977690319220225

Epoch: 6| Step: 9
Training loss: 1.8319345712661743
Validation loss: 2.00321235259374

Epoch: 6| Step: 10
Training loss: 2.6878795623779297
Validation loss: 1.9853765567143757

Epoch: 6| Step: 11
Training loss: 2.0604777336120605
Validation loss: 1.9954447944959004

Epoch: 6| Step: 12
Training loss: 1.6732419729232788
Validation loss: 1.9957062602043152

Epoch: 6| Step: 13
Training loss: 2.480391263961792
Validation loss: 1.9787619511286418

Epoch: 64| Step: 0
Training loss: 2.668437957763672
Validation loss: 1.9853068987528484

Epoch: 6| Step: 1
Training loss: 1.5064438581466675
Validation loss: 1.9863187074661255

Epoch: 6| Step: 2
Training loss: 1.9248106479644775
Validation loss: 1.988322337468465

Epoch: 6| Step: 3
Training loss: 1.4786572456359863
Validation loss: 2.0173205137252808

Epoch: 6| Step: 4
Training loss: 2.3189613819122314
Validation loss: 2.0396841565767923

Epoch: 6| Step: 5
Training loss: 1.9909594058990479
Validation loss: 2.04927792151769

Epoch: 6| Step: 6
Training loss: 1.9363023042678833
Validation loss: 2.061549663543701

Epoch: 6| Step: 7
Training loss: 2.3035049438476562
Validation loss: 2.09944482644399

Epoch: 6| Step: 8
Training loss: 1.4702595472335815
Validation loss: 2.087484876314799

Epoch: 6| Step: 9
Training loss: 1.698362112045288
Validation loss: 2.0799322923024497

Epoch: 6| Step: 10
Training loss: 1.8374416828155518
Validation loss: 2.079767187436422

Epoch: 6| Step: 11
Training loss: 1.8765366077423096
Validation loss: 2.036937117576599

Epoch: 6| Step: 12
Training loss: 1.636338233947754
Validation loss: 2.0577958822250366

Epoch: 6| Step: 13
Training loss: 1.6698774099349976
Validation loss: 2.0246275663375854

Epoch: 65| Step: 0
Training loss: 2.399017333984375
Validation loss: 2.029957195123037

Epoch: 6| Step: 1
Training loss: 2.548901081085205
Validation loss: 1.9989701509475708

Epoch: 6| Step: 2
Training loss: 2.3679728507995605
Validation loss: 2.0080934961636863

Epoch: 6| Step: 3
Training loss: 2.0179266929626465
Validation loss: 1.9863269329071045

Epoch: 6| Step: 4
Training loss: 1.2892073392868042
Validation loss: 1.979330042997996

Epoch: 6| Step: 5
Training loss: 1.3654435873031616
Validation loss: 1.9795595208803813

Epoch: 6| Step: 6
Training loss: 1.1618945598602295
Validation loss: 1.9746843775113423

Epoch: 6| Step: 7
Training loss: 2.330310821533203
Validation loss: 1.9890746275583904

Epoch: 6| Step: 8
Training loss: 1.9401088953018188
Validation loss: 1.9918585220972698

Epoch: 6| Step: 9
Training loss: 1.6307826042175293
Validation loss: 1.9846128622690837

Epoch: 6| Step: 10
Training loss: 1.4757696390151978
Validation loss: 1.9810324907302856

Epoch: 6| Step: 11
Training loss: 1.6375434398651123
Validation loss: 2.0064546267191568

Epoch: 6| Step: 12
Training loss: 2.062680959701538
Validation loss: 2.007294694582621

Epoch: 6| Step: 13
Training loss: 1.6029059886932373
Validation loss: 2.017470419406891

Epoch: 66| Step: 0
Training loss: 1.7479593753814697
Validation loss: 2.0659624338150024

Epoch: 6| Step: 1
Training loss: 1.7505528926849365
Validation loss: 2.0408562819163003

Epoch: 6| Step: 2
Training loss: 1.592830777168274
Validation loss: 2.0476310650507608

Epoch: 6| Step: 3
Training loss: 1.878605604171753
Validation loss: 2.1070726116498313

Epoch: 6| Step: 4
Training loss: 1.573854923248291
Validation loss: 2.0875823696454368

Epoch: 6| Step: 5
Training loss: 2.0018808841705322
Validation loss: 2.071022709210714

Epoch: 6| Step: 6
Training loss: 1.6770148277282715
Validation loss: 2.1285269459088645

Epoch: 6| Step: 7
Training loss: 2.5186076164245605
Validation loss: 2.122128943602244

Epoch: 6| Step: 8
Training loss: 1.9894349575042725
Validation loss: 2.098915616671244

Epoch: 6| Step: 9
Training loss: 1.5810962915420532
Validation loss: 2.0835637847582498

Epoch: 6| Step: 10
Training loss: 1.8058860301971436
Validation loss: 2.056358536084493

Epoch: 6| Step: 11
Training loss: 2.250088691711426
Validation loss: 2.0450706283251443

Epoch: 6| Step: 12
Training loss: 2.0656697750091553
Validation loss: 2.0171184142430625

Epoch: 6| Step: 13
Training loss: 1.4251437187194824
Validation loss: 1.98431263367335

Epoch: 67| Step: 0
Training loss: 1.7909138202667236
Validation loss: 1.9768670598665874

Epoch: 6| Step: 1
Training loss: 2.043470621109009
Validation loss: 1.9962904453277588

Epoch: 6| Step: 2
Training loss: 2.057732582092285
Validation loss: 1.9744974772135417

Epoch: 6| Step: 3
Training loss: 1.9684730768203735
Validation loss: 1.9721803466478984

Epoch: 6| Step: 4
Training loss: 2.016230583190918
Validation loss: 1.9924566547075908

Epoch: 6| Step: 5
Training loss: 1.7776825428009033
Validation loss: 1.9969404538472493

Epoch: 6| Step: 6
Training loss: 1.8072515726089478
Validation loss: 1.992483874162038

Epoch: 6| Step: 7
Training loss: 2.3441109657287598
Validation loss: 1.9796764453252156

Epoch: 6| Step: 8
Training loss: 1.7898492813110352
Validation loss: 1.9921159942944844

Epoch: 6| Step: 9
Training loss: 1.6045758724212646
Validation loss: 1.9893853068351746

Epoch: 6| Step: 10
Training loss: 1.265549898147583
Validation loss: 1.9986659685770671

Epoch: 6| Step: 11
Training loss: 1.5464353561401367
Validation loss: 1.9928452769915264

Epoch: 6| Step: 12
Training loss: 1.7272268533706665
Validation loss: 2.0290786822636924

Epoch: 6| Step: 13
Training loss: 2.0653862953186035
Validation loss: 2.0341575940450034

Epoch: 68| Step: 0
Training loss: 1.7065924406051636
Validation loss: 2.038850029309591

Epoch: 6| Step: 1
Training loss: 1.0352964401245117
Validation loss: 2.0470256209373474

Epoch: 6| Step: 2
Training loss: 1.4360826015472412
Validation loss: 2.090459187825521

Epoch: 6| Step: 3
Training loss: 2.047380208969116
Validation loss: 2.0761685371398926

Epoch: 6| Step: 4
Training loss: 1.963612675666809
Validation loss: 2.114001154899597

Epoch: 6| Step: 5
Training loss: 2.037586212158203
Validation loss: 2.0697273214658103

Epoch: 6| Step: 6
Training loss: 1.8216215372085571
Validation loss: 2.115529557069143

Epoch: 6| Step: 7
Training loss: 1.7440496683120728
Validation loss: 2.0503279765446982

Epoch: 6| Step: 8
Training loss: 2.0886290073394775
Validation loss: 2.0109402736028037

Epoch: 6| Step: 9
Training loss: 2.504398822784424
Validation loss: 2.0018069545427957

Epoch: 6| Step: 10
Training loss: 2.0998435020446777
Validation loss: 1.9755465984344482

Epoch: 6| Step: 11
Training loss: 1.4047191143035889
Validation loss: 1.9892958601315816

Epoch: 6| Step: 12
Training loss: 1.75984787940979
Validation loss: 2.0043227473894754

Epoch: 6| Step: 13
Training loss: 2.235887289047241
Validation loss: 1.9922591646512349

Epoch: 69| Step: 0
Training loss: 2.112382411956787
Validation loss: 1.971271316210429

Epoch: 6| Step: 1
Training loss: 1.6363525390625
Validation loss: 1.9946219126383464

Epoch: 6| Step: 2
Training loss: 1.9529001712799072
Validation loss: 2.002363443374634

Epoch: 6| Step: 3
Training loss: 1.2525895833969116
Validation loss: 1.9834051330884297

Epoch: 6| Step: 4
Training loss: 1.169447660446167
Validation loss: 1.9770333369572957

Epoch: 6| Step: 5
Training loss: 2.133819580078125
Validation loss: 1.9777806798617046

Epoch: 6| Step: 6
Training loss: 1.4022598266601562
Validation loss: 1.9833144545555115

Epoch: 6| Step: 7
Training loss: 2.1172471046447754
Validation loss: 2.014033794403076

Epoch: 6| Step: 8
Training loss: 2.2887542247772217
Validation loss: 2.0050288240114846

Epoch: 6| Step: 9
Training loss: 2.00205135345459
Validation loss: 2.01075545946757

Epoch: 6| Step: 10
Training loss: 1.4645640850067139
Validation loss: 1.990162988503774

Epoch: 6| Step: 11
Training loss: 2.220555543899536
Validation loss: 2.0141334732373557

Epoch: 6| Step: 12
Training loss: 2.2652199268341064
Validation loss: 2.0088508129119873

Epoch: 6| Step: 13
Training loss: 1.269845962524414
Validation loss: 1.9902787407239277

Epoch: 70| Step: 0
Training loss: 1.8530737161636353
Validation loss: 2.0356525977452598

Epoch: 6| Step: 1
Training loss: 2.8940296173095703
Validation loss: 2.0577503442764282

Epoch: 6| Step: 2
Training loss: 1.2437198162078857
Validation loss: 2.032293677330017

Epoch: 6| Step: 3
Training loss: 2.223950147628784
Validation loss: 2.0440049171447754

Epoch: 6| Step: 4
Training loss: 1.9044592380523682
Validation loss: 2.030404269695282

Epoch: 6| Step: 5
Training loss: 1.4569900035858154
Validation loss: 1.9933675130208333

Epoch: 6| Step: 6
Training loss: 1.3740932941436768
Validation loss: 1.9829613169034321

Epoch: 6| Step: 7
Training loss: 1.869786024093628
Validation loss: 1.9794140060742695

Epoch: 6| Step: 8
Training loss: 2.1589889526367188
Validation loss: 1.9722887078921

Epoch: 6| Step: 9
Training loss: 2.0729899406433105
Validation loss: 1.9781977534294128

Epoch: 6| Step: 10
Training loss: 1.4563188552856445
Validation loss: 1.9865312377611797

Epoch: 6| Step: 11
Training loss: 2.185236692428589
Validation loss: 1.9689819018046062

Epoch: 6| Step: 12
Training loss: 1.7084686756134033
Validation loss: 1.970955769220988

Epoch: 6| Step: 13
Training loss: 1.4665288925170898
Validation loss: 1.9714909394582112

Epoch: 71| Step: 0
Training loss: 1.6965388059616089
Validation loss: 1.9918180505434673

Epoch: 6| Step: 1
Training loss: 1.8755714893341064
Validation loss: 2.0024973352750144

Epoch: 6| Step: 2
Training loss: 1.8378348350524902
Validation loss: 2.008150637149811

Epoch: 6| Step: 3
Training loss: 1.3888649940490723
Validation loss: 2.0160080989201865

Epoch: 6| Step: 4
Training loss: 1.8773390054702759
Validation loss: 2.012993633747101

Epoch: 6| Step: 5
Training loss: 1.8292853832244873
Validation loss: 2.0703155994415283

Epoch: 6| Step: 6
Training loss: 1.8050849437713623
Validation loss: 2.0736714800198874

Epoch: 6| Step: 7
Training loss: 2.139758586883545
Validation loss: 2.0744425455729165

Epoch: 6| Step: 8
Training loss: 2.006971836090088
Validation loss: 2.0739309390385947

Epoch: 6| Step: 9
Training loss: 1.7764588594436646
Validation loss: 2.079473614692688

Epoch: 6| Step: 10
Training loss: 2.291414976119995
Validation loss: 2.046314318974813

Epoch: 6| Step: 11
Training loss: 1.985105037689209
Validation loss: 2.04955126841863

Epoch: 6| Step: 12
Training loss: 1.6986684799194336
Validation loss: 2.0389145414034524

Epoch: 6| Step: 13
Training loss: 1.3971019983291626
Validation loss: 2.015289584795634

Epoch: 72| Step: 0
Training loss: 1.5995709896087646
Validation loss: 1.986444314320882

Epoch: 6| Step: 1
Training loss: 1.6399242877960205
Validation loss: 2.0047037402788797

Epoch: 6| Step: 2
Training loss: 2.048868179321289
Validation loss: 1.9976402322451274

Epoch: 6| Step: 3
Training loss: 1.799058437347412
Validation loss: 1.9795995752016704

Epoch: 6| Step: 4
Training loss: 1.6294676065444946
Validation loss: 1.9877403378486633

Epoch: 6| Step: 5
Training loss: 1.6816813945770264
Validation loss: 1.9851499199867249

Epoch: 6| Step: 6
Training loss: 1.2538527250289917
Validation loss: 1.9991995294888814

Epoch: 6| Step: 7
Training loss: 2.2672529220581055
Validation loss: 2.0031021436055503

Epoch: 6| Step: 8
Training loss: 2.293161392211914
Validation loss: 2.006369332472483

Epoch: 6| Step: 9
Training loss: 1.605745553970337
Validation loss: 1.9933625062306721

Epoch: 6| Step: 10
Training loss: 1.674365758895874
Validation loss: 2.025289475917816

Epoch: 6| Step: 11
Training loss: 1.9394768476486206
Validation loss: 1.9775082270304363

Epoch: 6| Step: 12
Training loss: 1.871408224105835
Validation loss: 2.004672725995382

Epoch: 6| Step: 13
Training loss: 1.8285151720046997
Validation loss: 2.0065133770306907

Epoch: 73| Step: 0
Training loss: 1.4891986846923828
Validation loss: 1.9849461913108826

Epoch: 6| Step: 1
Training loss: 1.0834102630615234
Validation loss: 1.9521965980529785

Epoch: 6| Step: 2
Training loss: 1.9678270816802979
Validation loss: 1.9949949582417805

Epoch: 6| Step: 3
Training loss: 1.7500474452972412
Validation loss: 1.9980867306391399

Epoch: 6| Step: 4
Training loss: 1.6509298086166382
Validation loss: 1.9935345649719238

Epoch: 6| Step: 5
Training loss: 1.8629344701766968
Validation loss: 2.004574954509735

Epoch: 6| Step: 6
Training loss: 1.2225117683410645
Validation loss: 2.01775062084198

Epoch: 6| Step: 7
Training loss: 2.5173702239990234
Validation loss: 1.9967883626619976

Epoch: 6| Step: 8
Training loss: 1.3567535877227783
Validation loss: 2.051828900973002

Epoch: 6| Step: 9
Training loss: 2.273886203765869
Validation loss: 2.0267958442370095

Epoch: 6| Step: 10
Training loss: 2.3629047870635986
Validation loss: 2.0445027550061545

Epoch: 6| Step: 11
Training loss: 1.8941471576690674
Validation loss: 2.030313014984131

Epoch: 6| Step: 12
Training loss: 1.4881668090820312
Validation loss: 2.0313097635904946

Epoch: 6| Step: 13
Training loss: 1.9439747333526611
Validation loss: 2.0263559420903525

Epoch: 74| Step: 0
Training loss: 1.923079252243042
Validation loss: 1.9945231676101685

Epoch: 6| Step: 1
Training loss: 2.805746078491211
Validation loss: 2.047245979309082

Epoch: 6| Step: 2
Training loss: 1.8371447324752808
Validation loss: 1.989079773426056

Epoch: 6| Step: 3
Training loss: 1.7197928428649902
Validation loss: 1.9866555730501811

Epoch: 6| Step: 4
Training loss: 1.6854182481765747
Validation loss: 1.9779619773228962

Epoch: 6| Step: 5
Training loss: 1.4113450050354004
Validation loss: 1.983537216981252

Epoch: 6| Step: 6
Training loss: 1.8711236715316772
Validation loss: 1.9720638791720073

Epoch: 6| Step: 7
Training loss: 1.0300147533416748
Validation loss: 1.9712163209915161

Epoch: 6| Step: 8
Training loss: 1.6212530136108398
Validation loss: 1.9781358639399211

Epoch: 6| Step: 9
Training loss: 1.6759164333343506
Validation loss: 2.0029746294021606

Epoch: 6| Step: 10
Training loss: 1.7150764465332031
Validation loss: 2.002099017302195

Epoch: 6| Step: 11
Training loss: 2.128844738006592
Validation loss: 2.0109426975250244

Epoch: 6| Step: 12
Training loss: 1.744001865386963
Validation loss: 1.9992958903312683

Epoch: 6| Step: 13
Training loss: 1.6395502090454102
Validation loss: 1.9983821511268616

Epoch: 75| Step: 0
Training loss: 2.3143162727355957
Validation loss: 2.02778152624766

Epoch: 6| Step: 1
Training loss: 1.2373411655426025
Validation loss: 2.01847513516744

Epoch: 6| Step: 2
Training loss: 1.4095253944396973
Validation loss: 2.016168753306071

Epoch: 6| Step: 3
Training loss: 2.121112585067749
Validation loss: 2.0324888825416565

Epoch: 6| Step: 4
Training loss: 1.9239422082901
Validation loss: 2.0120307008425393

Epoch: 6| Step: 5
Training loss: 1.9110662937164307
Validation loss: 2.048280338446299

Epoch: 6| Step: 6
Training loss: 2.0119714736938477
Validation loss: 2.0179420709609985

Epoch: 6| Step: 7
Training loss: 1.7810027599334717
Validation loss: 2.013076384862264

Epoch: 6| Step: 8
Training loss: 1.6160714626312256
Validation loss: 2.011338452498118

Epoch: 6| Step: 9
Training loss: 1.196454644203186
Validation loss: 2.015302836894989

Epoch: 6| Step: 10
Training loss: 1.603668451309204
Validation loss: 1.9900009830792744

Epoch: 6| Step: 11
Training loss: 1.836172103881836
Validation loss: 2.0112029314041138

Epoch: 6| Step: 12
Training loss: 1.4236412048339844
Validation loss: 1.9722927808761597

Epoch: 6| Step: 13
Training loss: 2.3240909576416016
Validation loss: 1.9725379546483357

Epoch: 76| Step: 0
Training loss: 1.4473896026611328
Validation loss: 1.9743160605430603

Epoch: 6| Step: 1
Training loss: 1.4751918315887451
Validation loss: 1.9728488723436992

Epoch: 6| Step: 2
Training loss: 1.8588643074035645
Validation loss: 1.9855318268140156

Epoch: 6| Step: 3
Training loss: 2.261312484741211
Validation loss: 1.9878756403923035

Epoch: 6| Step: 4
Training loss: 1.3409490585327148
Validation loss: 2.0018810828526816

Epoch: 6| Step: 5
Training loss: 2.068819046020508
Validation loss: 1.9928021629651387

Epoch: 6| Step: 6
Training loss: 2.202272653579712
Validation loss: 2.017161945501963

Epoch: 6| Step: 7
Training loss: 1.9419115781784058
Validation loss: 2.009048422177633

Epoch: 6| Step: 8
Training loss: 1.4877653121948242
Validation loss: 1.997300148010254

Epoch: 6| Step: 9
Training loss: 1.7585505247116089
Validation loss: 1.9867631594340007

Epoch: 6| Step: 10
Training loss: 2.672410011291504
Validation loss: 1.9920860330263774

Epoch: 6| Step: 11
Training loss: 1.4063353538513184
Validation loss: 1.9835989077885945

Epoch: 6| Step: 12
Training loss: 1.322584867477417
Validation loss: 2.0135393142700195

Epoch: 6| Step: 13
Training loss: 1.2805196046829224
Validation loss: 1.9886551698048909

Epoch: 77| Step: 0
Training loss: 1.4713566303253174
Validation loss: 2.0166261196136475

Epoch: 6| Step: 1
Training loss: 1.9407612085342407
Validation loss: 2.015574097633362

Epoch: 6| Step: 2
Training loss: 1.8330233097076416
Validation loss: 2.030804673830668

Epoch: 6| Step: 3
Training loss: 1.603236436843872
Validation loss: 2.0085269014040628

Epoch: 6| Step: 4
Training loss: 2.117222785949707
Validation loss: 2.0312272111574807

Epoch: 6| Step: 5
Training loss: 1.9425841569900513
Validation loss: 2.0336481730143228

Epoch: 6| Step: 6
Training loss: 1.8311450481414795
Validation loss: 2.016996423403422

Epoch: 6| Step: 7
Training loss: 1.9027743339538574
Validation loss: 2.0016379356384277

Epoch: 6| Step: 8
Training loss: 1.68766188621521
Validation loss: 1.9823748270670574

Epoch: 6| Step: 9
Training loss: 2.048781394958496
Validation loss: 2.0110444029172263

Epoch: 6| Step: 10
Training loss: 1.2098355293273926
Validation loss: 2.0234453876813254

Epoch: 6| Step: 11
Training loss: 1.8310133218765259
Validation loss: 2.032231648763021

Epoch: 6| Step: 12
Training loss: 1.4810587167739868
Validation loss: 1.9976563652356465

Epoch: 6| Step: 13
Training loss: 1.5065813064575195
Validation loss: 1.999856690565745

Epoch: 78| Step: 0
Training loss: 2.0067925453186035
Validation loss: 1.9920868476231892

Epoch: 6| Step: 1
Training loss: 1.573957920074463
Validation loss: 1.9742636283238728

Epoch: 6| Step: 2
Training loss: 1.8213646411895752
Validation loss: 2.0045748154322305

Epoch: 6| Step: 3
Training loss: 1.0532582998275757
Validation loss: 1.9877432187398274

Epoch: 6| Step: 4
Training loss: 1.8131442070007324
Validation loss: 2.0032841563224792

Epoch: 6| Step: 5
Training loss: 2.0542755126953125
Validation loss: 1.964554786682129

Epoch: 6| Step: 6
Training loss: 2.3010964393615723
Validation loss: 1.9934087991714478

Epoch: 6| Step: 7
Training loss: 1.5869879722595215
Validation loss: 2.001502970854441

Epoch: 6| Step: 8
Training loss: 2.137268304824829
Validation loss: 1.9784043431282043

Epoch: 6| Step: 9
Training loss: 1.6016685962677002
Validation loss: 2.0036269625027976

Epoch: 6| Step: 10
Training loss: 0.8986376523971558
Validation loss: 1.9758017857869465

Epoch: 6| Step: 11
Training loss: 1.7762956619262695
Validation loss: 2.0332848032315574

Epoch: 6| Step: 12
Training loss: 1.900341510772705
Validation loss: 2.0267043908437095

Epoch: 6| Step: 13
Training loss: 1.6536834239959717
Validation loss: 2.055069903532664

Epoch: 79| Step: 0
Training loss: 2.0939576625823975
Validation loss: 2.040271580219269

Epoch: 6| Step: 1
Training loss: 2.381570339202881
Validation loss: 2.0798264543215432

Epoch: 6| Step: 2
Training loss: 1.393792748451233
Validation loss: 2.107416351636251

Epoch: 6| Step: 3
Training loss: 1.5006930828094482
Validation loss: 2.1312578916549683

Epoch: 6| Step: 4
Training loss: 2.2579712867736816
Validation loss: 2.1298717061678567

Epoch: 6| Step: 5
Training loss: 1.484218955039978
Validation loss: 2.12712154785792

Epoch: 6| Step: 6
Training loss: 2.107637882232666
Validation loss: 2.107648253440857

Epoch: 6| Step: 7
Training loss: 1.981642723083496
Validation loss: 2.076698621114095

Epoch: 6| Step: 8
Training loss: 1.604585886001587
Validation loss: 2.0629175504048667

Epoch: 6| Step: 9
Training loss: 1.440840244293213
Validation loss: 2.03425266345342

Epoch: 6| Step: 10
Training loss: 1.3811559677124023
Validation loss: 2.033169170220693

Epoch: 6| Step: 11
Training loss: 1.833593487739563
Validation loss: 1.9982171654701233

Epoch: 6| Step: 12
Training loss: 1.7150118350982666
Validation loss: 1.99169921875

Epoch: 6| Step: 13
Training loss: 1.2619554996490479
Validation loss: 1.9772908091545105

Epoch: 80| Step: 0
Training loss: 1.6508417129516602
Validation loss: 1.9943789839744568

Epoch: 6| Step: 1
Training loss: 1.6282377243041992
Validation loss: 1.9673096736272175

Epoch: 6| Step: 2
Training loss: 2.0158560276031494
Validation loss: 1.9730336864789326

Epoch: 6| Step: 3
Training loss: 1.6201754808425903
Validation loss: 1.9875276883443196

Epoch: 6| Step: 4
Training loss: 1.2994999885559082
Validation loss: 1.9644383390744526

Epoch: 6| Step: 5
Training loss: 2.1227595806121826
Validation loss: 1.993222971757253

Epoch: 6| Step: 6
Training loss: 1.9692494869232178
Validation loss: 2.0171719988187156

Epoch: 6| Step: 7
Training loss: 1.4074186086654663
Validation loss: 2.0352015296618142

Epoch: 6| Step: 8
Training loss: 1.671973705291748
Validation loss: 2.0195276935895285

Epoch: 6| Step: 9
Training loss: 2.0101044178009033
Validation loss: 2.0026744405428567

Epoch: 6| Step: 10
Training loss: 1.477735996246338
Validation loss: 1.9969066580136616

Epoch: 6| Step: 11
Training loss: 1.9136093854904175
Validation loss: 1.979841907819112

Epoch: 6| Step: 12
Training loss: 1.9076133966445923
Validation loss: 1.978873074054718

Epoch: 6| Step: 13
Training loss: 1.9652987718582153
Validation loss: 1.9645588994026184

Epoch: 81| Step: 0
Training loss: 2.2980270385742188
Validation loss: 1.9974453051884968

Epoch: 6| Step: 1
Training loss: 1.2913168668746948
Validation loss: 1.9666603803634644

Epoch: 6| Step: 2
Training loss: 1.855178713798523
Validation loss: 1.9832558830579121

Epoch: 6| Step: 3
Training loss: 2.1965935230255127
Validation loss: 1.9666296243667603

Epoch: 6| Step: 4
Training loss: 1.9724388122558594
Validation loss: 2.021311859289805

Epoch: 6| Step: 5
Training loss: 1.418572187423706
Validation loss: 2.040864408016205

Epoch: 6| Step: 6
Training loss: 1.5496991872787476
Validation loss: 2.036928176879883

Epoch: 6| Step: 7
Training loss: 1.787408709526062
Validation loss: 2.0402395725250244

Epoch: 6| Step: 8
Training loss: 1.3847137689590454
Validation loss: 2.034528454144796

Epoch: 6| Step: 9
Training loss: 1.9969490766525269
Validation loss: 2.0548502802848816

Epoch: 6| Step: 10
Training loss: 1.8401089906692505
Validation loss: 1.999712347984314

Epoch: 6| Step: 11
Training loss: 0.8773530721664429
Validation loss: 1.9862547516822815

Epoch: 6| Step: 12
Training loss: 2.484649896621704
Validation loss: 1.9840751886367798

Epoch: 6| Step: 13
Training loss: 1.228840947151184
Validation loss: 2.0035149653752646

Epoch: 82| Step: 0
Training loss: 1.3938437700271606
Validation loss: 1.968142032623291

Epoch: 6| Step: 1
Training loss: 1.489060640335083
Validation loss: 1.9826827843983967

Epoch: 6| Step: 2
Training loss: 2.191354274749756
Validation loss: 1.9899568756421406

Epoch: 6| Step: 3
Training loss: 1.9446169137954712
Validation loss: 1.9665549596150715

Epoch: 6| Step: 4
Training loss: 1.9029237031936646
Validation loss: 1.9667198061943054

Epoch: 6| Step: 5
Training loss: 0.9806539416313171
Validation loss: 2.0005981723467507

Epoch: 6| Step: 6
Training loss: 1.7366716861724854
Validation loss: 1.9889863928159077

Epoch: 6| Step: 7
Training loss: 2.2917675971984863
Validation loss: 1.9865039785703023

Epoch: 6| Step: 8
Training loss: 2.0018749237060547
Validation loss: 1.9964682857195537

Epoch: 6| Step: 9
Training loss: 1.483413577079773
Validation loss: 1.983434538046519

Epoch: 6| Step: 10
Training loss: 1.6606287956237793
Validation loss: 1.9907020330429077

Epoch: 6| Step: 11
Training loss: 1.1255483627319336
Validation loss: 2.0168317357699075

Epoch: 6| Step: 12
Training loss: 2.0448882579803467
Validation loss: 2.008024017016093

Epoch: 6| Step: 13
Training loss: 1.8069064617156982
Validation loss: 2.0288116137186685

Epoch: 83| Step: 0
Training loss: 2.288726329803467
Validation loss: 2.0361135403315225

Epoch: 6| Step: 1
Training loss: 1.3368663787841797
Validation loss: 2.0230788588523865

Epoch: 6| Step: 2
Training loss: 1.5840697288513184
Validation loss: 2.037894050280253

Epoch: 6| Step: 3
Training loss: 1.4585362672805786
Validation loss: 2.0272361437479653

Epoch: 6| Step: 4
Training loss: 1.8294867277145386
Validation loss: 2.0343600511550903

Epoch: 6| Step: 5
Training loss: 1.3260316848754883
Validation loss: 2.0388723611831665

Epoch: 6| Step: 6
Training loss: 2.5295002460479736
Validation loss: 2.0400283336639404

Epoch: 6| Step: 7
Training loss: 1.6748886108398438
Validation loss: 2.0374338626861572

Epoch: 6| Step: 8
Training loss: 1.9636454582214355
Validation loss: 2.029716730117798

Epoch: 6| Step: 9
Training loss: 1.7124652862548828
Validation loss: 2.0376110672950745

Epoch: 6| Step: 10
Training loss: 1.2887128591537476
Validation loss: 2.0170618295669556

Epoch: 6| Step: 11
Training loss: 2.0053911209106445
Validation loss: 1.9907584985097249

Epoch: 6| Step: 12
Training loss: 1.1762568950653076
Validation loss: 1.9714744091033936

Epoch: 6| Step: 13
Training loss: 1.6357150077819824
Validation loss: 1.9944806098937988

Epoch: 84| Step: 0
Training loss: 2.155369281768799
Validation loss: 1.98291810353597

Epoch: 6| Step: 1
Training loss: 1.262455701828003
Validation loss: 1.971383512020111

Epoch: 6| Step: 2
Training loss: 2.0923149585723877
Validation loss: 1.982758144537608

Epoch: 6| Step: 3
Training loss: 1.5970025062561035
Validation loss: 1.9676294525464375

Epoch: 6| Step: 4
Training loss: 1.7748948335647583
Validation loss: 1.984668493270874

Epoch: 6| Step: 5
Training loss: 1.2013942003250122
Validation loss: 2.0002463261286416

Epoch: 6| Step: 6
Training loss: 1.645381212234497
Validation loss: 2.002859115600586

Epoch: 6| Step: 7
Training loss: 1.9360333681106567
Validation loss: 2.018251617749532

Epoch: 6| Step: 8
Training loss: 1.209412932395935
Validation loss: 2.0461292068163552

Epoch: 6| Step: 9
Training loss: 2.578699827194214
Validation loss: 2.042388399442037

Epoch: 6| Step: 10
Training loss: 2.2936062812805176
Validation loss: 2.070785860220591

Epoch: 6| Step: 11
Training loss: 1.1173555850982666
Validation loss: 2.0588713685671487

Epoch: 6| Step: 12
Training loss: 1.9429068565368652
Validation loss: 2.0999234914779663

Epoch: 6| Step: 13
Training loss: 1.5372577905654907
Validation loss: 2.0564691027005515

Epoch: 85| Step: 0
Training loss: 1.5040831565856934
Validation loss: 2.00319904088974

Epoch: 6| Step: 1
Training loss: 2.184783935546875
Validation loss: 2.0181294480959573

Epoch: 6| Step: 2
Training loss: 1.511042833328247
Validation loss: 1.9809786279996235

Epoch: 6| Step: 3
Training loss: 1.280672311782837
Validation loss: 1.978500485420227

Epoch: 6| Step: 4
Training loss: 1.895461916923523
Validation loss: 1.983411471048991

Epoch: 6| Step: 5
Training loss: 1.7189702987670898
Validation loss: 1.9820962349573772

Epoch: 6| Step: 6
Training loss: 1.9563874006271362
Validation loss: 1.9773814678192139

Epoch: 6| Step: 7
Training loss: 1.631158709526062
Validation loss: 1.9947803020477295

Epoch: 6| Step: 8
Training loss: 1.9957139492034912
Validation loss: 1.9958389798800151

Epoch: 6| Step: 9
Training loss: 1.3236907720565796
Validation loss: 2.021292189757029

Epoch: 6| Step: 10
Training loss: 1.7627956867218018
Validation loss: 2.005216419696808

Epoch: 6| Step: 11
Training loss: 1.4867031574249268
Validation loss: 1.9704982837041218

Epoch: 6| Step: 12
Training loss: 1.128004789352417
Validation loss: 1.9970108071962993

Epoch: 6| Step: 13
Training loss: 1.967058777809143
Validation loss: 2.0031527280807495

Epoch: 86| Step: 0
Training loss: 2.330869436264038
Validation loss: 1.9767680366834004

Epoch: 6| Step: 1
Training loss: 1.085828185081482
Validation loss: 1.984763224919637

Epoch: 6| Step: 2
Training loss: 1.2563087940216064
Validation loss: 1.9723426500956218

Epoch: 6| Step: 3
Training loss: 1.6868494749069214
Validation loss: 1.986173113187154

Epoch: 6| Step: 4
Training loss: 1.7101978063583374
Validation loss: 1.9746764699618022

Epoch: 6| Step: 5
Training loss: 1.469094157218933
Validation loss: 1.9793049494425456

Epoch: 6| Step: 6
Training loss: 1.7740545272827148
Validation loss: 1.9866917332013447

Epoch: 6| Step: 7
Training loss: 1.616729497909546
Validation loss: 1.9873562852541606

Epoch: 6| Step: 8
Training loss: 2.048027992248535
Validation loss: 2.0304551124572754

Epoch: 6| Step: 9
Training loss: 1.3647520542144775
Validation loss: 2.0133361419041953

Epoch: 6| Step: 10
Training loss: 2.0865797996520996
Validation loss: 2.026888390382131

Epoch: 6| Step: 11
Training loss: 1.6114702224731445
Validation loss: 2.0487892031669617

Epoch: 6| Step: 12
Training loss: 1.502929925918579
Validation loss: 2.0431498487790427

Epoch: 6| Step: 13
Training loss: 1.7493641376495361
Validation loss: 2.0585646629333496

Epoch: 87| Step: 0
Training loss: 1.7652721405029297
Validation loss: 2.00449671347936

Epoch: 6| Step: 1
Training loss: 1.3131362199783325
Validation loss: 2.00579043229421

Epoch: 6| Step: 2
Training loss: 2.6357598304748535
Validation loss: 2.016679565111796

Epoch: 6| Step: 3
Training loss: 1.4017350673675537
Validation loss: 2.0240200956662497

Epoch: 6| Step: 4
Training loss: 1.9002189636230469
Validation loss: 1.995579202969869

Epoch: 6| Step: 5
Training loss: 1.2772996425628662
Validation loss: 2.0064929127693176

Epoch: 6| Step: 6
Training loss: 1.4404327869415283
Validation loss: 2.0035875837008157

Epoch: 6| Step: 7
Training loss: 1.8920845985412598
Validation loss: 1.998337725798289

Epoch: 6| Step: 8
Training loss: 1.3958425521850586
Validation loss: 2.00550377368927

Epoch: 6| Step: 9
Training loss: 1.8383784294128418
Validation loss: 2.015407621860504

Epoch: 6| Step: 10
Training loss: 1.306462287902832
Validation loss: 2.0011776288350425

Epoch: 6| Step: 11
Training loss: 1.9146676063537598
Validation loss: 2.0078506668408713

Epoch: 6| Step: 12
Training loss: 1.789214849472046
Validation loss: 2.0056567390759787

Epoch: 6| Step: 13
Training loss: 1.5464098453521729
Validation loss: 2.014400859673818

Epoch: 88| Step: 0
Training loss: 1.350476622581482
Validation loss: 2.0218406518300376

Epoch: 6| Step: 1
Training loss: 1.5588551759719849
Validation loss: 2.0009031097094216

Epoch: 6| Step: 2
Training loss: 2.1418564319610596
Validation loss: 1.9951882561047871

Epoch: 6| Step: 3
Training loss: 1.9869685173034668
Validation loss: 2.0305312077204385

Epoch: 6| Step: 4
Training loss: 1.4982671737670898
Validation loss: 1.9861558079719543

Epoch: 6| Step: 5
Training loss: 1.6171081066131592
Validation loss: 1.9928869207700093

Epoch: 6| Step: 6
Training loss: 1.8176450729370117
Validation loss: 1.9996431469917297

Epoch: 6| Step: 7
Training loss: 1.767002820968628
Validation loss: 2.014074901739756

Epoch: 6| Step: 8
Training loss: 1.479384422302246
Validation loss: 2.0339064995447793

Epoch: 6| Step: 9
Training loss: 1.4084876775741577
Validation loss: 1.985663652420044

Epoch: 6| Step: 10
Training loss: 1.6472856998443604
Validation loss: 1.9891393383344014

Epoch: 6| Step: 11
Training loss: 1.9138013124465942
Validation loss: 1.9911511341730754

Epoch: 6| Step: 12
Training loss: 1.4746544361114502
Validation loss: 1.972368597984314

Epoch: 6| Step: 13
Training loss: 1.5230228900909424
Validation loss: 1.9904732902844746

Epoch: 89| Step: 0
Training loss: 0.9630129933357239
Validation loss: 1.9834479689598083

Epoch: 6| Step: 1
Training loss: 2.172628879547119
Validation loss: 1.9836793740590413

Epoch: 6| Step: 2
Training loss: 1.8908357620239258
Validation loss: 1.9631980061531067

Epoch: 6| Step: 3
Training loss: 1.7266271114349365
Validation loss: 1.9800169467926025

Epoch: 6| Step: 4
Training loss: 0.9710912704467773
Validation loss: 1.9738701184590657

Epoch: 6| Step: 5
Training loss: 1.4298136234283447
Validation loss: 1.983790914217631

Epoch: 6| Step: 6
Training loss: 2.1682467460632324
Validation loss: 1.989142119884491

Epoch: 6| Step: 7
Training loss: 1.7895337343215942
Validation loss: 1.9856431285540264

Epoch: 6| Step: 8
Training loss: 1.5146279335021973
Validation loss: 1.962759514649709

Epoch: 6| Step: 9
Training loss: 1.651505708694458
Validation loss: 1.9521899422009785

Epoch: 6| Step: 10
Training loss: 1.8387694358825684
Validation loss: 1.9731863538424175

Epoch: 6| Step: 11
Training loss: 1.6835424900054932
Validation loss: 2.0049955447514853

Epoch: 6| Step: 12
Training loss: 1.908626675605774
Validation loss: 1.9805282950401306

Epoch: 6| Step: 13
Training loss: 1.0852264165878296
Validation loss: 2.0140602191289267

Epoch: 90| Step: 0
Training loss: 1.4521421194076538
Validation loss: 1.99772713581721

Epoch: 6| Step: 1
Training loss: 2.1009602546691895
Validation loss: 1.9931024114290874

Epoch: 6| Step: 2
Training loss: 2.1227781772613525
Validation loss: 1.9605608185132344

Epoch: 6| Step: 3
Training loss: 1.2587523460388184
Validation loss: 1.9815311034520466

Epoch: 6| Step: 4
Training loss: 2.1147477626800537
Validation loss: 1.996123731136322

Epoch: 6| Step: 5
Training loss: 1.5006992816925049
Validation loss: 2.004175921281179

Epoch: 6| Step: 6
Training loss: 1.7894301414489746
Validation loss: 2.017329454421997

Epoch: 6| Step: 7
Training loss: 1.7747015953063965
Validation loss: 1.9854096571604412

Epoch: 6| Step: 8
Training loss: 1.79170823097229
Validation loss: 1.9784126083056133

Epoch: 6| Step: 9
Training loss: 1.3572771549224854
Validation loss: 2.0136839548746743

Epoch: 6| Step: 10
Training loss: 1.2618480920791626
Validation loss: 2.0048281153043113

Epoch: 6| Step: 11
Training loss: 1.4268702268600464
Validation loss: 2.035063068072001

Epoch: 6| Step: 12
Training loss: 1.3772097826004028
Validation loss: 2.0296146074930825

Epoch: 6| Step: 13
Training loss: 1.9097905158996582
Validation loss: 2.0761720736821494

Epoch: 91| Step: 0
Training loss: 2.063392162322998
Validation loss: 2.0768498182296753

Epoch: 6| Step: 1
Training loss: 1.2025172710418701
Validation loss: 2.0416866143544516

Epoch: 6| Step: 2
Training loss: 1.4142487049102783
Validation loss: 2.0145374735196433

Epoch: 6| Step: 3
Training loss: 1.9266482591629028
Validation loss: 1.97744353612264

Epoch: 6| Step: 4
Training loss: 1.1849565505981445
Validation loss: 2.002243916193644

Epoch: 6| Step: 5
Training loss: 1.6138989925384521
Validation loss: 2.010860820611318

Epoch: 6| Step: 6
Training loss: 1.6981509923934937
Validation loss: 1.9770870804786682

Epoch: 6| Step: 7
Training loss: 1.8023747205734253
Validation loss: 1.977545956770579

Epoch: 6| Step: 8
Training loss: 1.4072768688201904
Validation loss: 1.9815205931663513

Epoch: 6| Step: 9
Training loss: 2.2112514972686768
Validation loss: 1.96931658188502

Epoch: 6| Step: 10
Training loss: 1.2427490949630737
Validation loss: 1.978001872698466

Epoch: 6| Step: 11
Training loss: 1.6401636600494385
Validation loss: 1.961383879184723

Epoch: 6| Step: 12
Training loss: 1.1672395467758179
Validation loss: 1.985106110572815

Epoch: 6| Step: 13
Training loss: 1.9612640142440796
Validation loss: 1.9919196168581645

Epoch: 92| Step: 0
Training loss: 1.1160390377044678
Validation loss: 2.0082135597864785

Epoch: 6| Step: 1
Training loss: 1.2088611125946045
Validation loss: 2.015805800755819

Epoch: 6| Step: 2
Training loss: 2.217474937438965
Validation loss: 2.004095276196798

Epoch: 6| Step: 3
Training loss: 1.566321849822998
Validation loss: 2.014862537384033

Epoch: 6| Step: 4
Training loss: 1.4437891244888306
Validation loss: 2.0717756748199463

Epoch: 6| Step: 5
Training loss: 1.5217851400375366
Validation loss: 2.058617035547892

Epoch: 6| Step: 6
Training loss: 1.777721643447876
Validation loss: 2.0693037708600364

Epoch: 6| Step: 7
Training loss: 2.1615822315216064
Validation loss: 2.0572595794995627

Epoch: 6| Step: 8
Training loss: 1.9208321571350098
Validation loss: 2.0724063515663147

Epoch: 6| Step: 9
Training loss: 1.1344189643859863
Validation loss: 2.025145093599955

Epoch: 6| Step: 10
Training loss: 1.5865858793258667
Validation loss: 1.9893788894017537

Epoch: 6| Step: 11
Training loss: 2.007026195526123
Validation loss: 1.9992330272992451

Epoch: 6| Step: 12
Training loss: 1.2685279846191406
Validation loss: 2.008691926797231

Epoch: 6| Step: 13
Training loss: 1.8267712593078613
Validation loss: 1.98184339205424

Epoch: 93| Step: 0
Training loss: 1.5010387897491455
Validation loss: 2.0101120471954346

Epoch: 6| Step: 1
Training loss: 1.6614317893981934
Validation loss: 2.0038333336512246

Epoch: 6| Step: 2
Training loss: 1.431880235671997
Validation loss: 1.9992818435033162

Epoch: 6| Step: 3
Training loss: 1.2805213928222656
Validation loss: 1.9910067319869995

Epoch: 6| Step: 4
Training loss: 1.9865527153015137
Validation loss: 2.0134064753850303

Epoch: 6| Step: 5
Training loss: 1.4882853031158447
Validation loss: 1.9918420910835266

Epoch: 6| Step: 6
Training loss: 0.9242264032363892
Validation loss: 2.0143486658732095

Epoch: 6| Step: 7
Training loss: 1.477817416191101
Validation loss: 2.026776651541392

Epoch: 6| Step: 8
Training loss: 1.581406593322754
Validation loss: 2.058130204677582

Epoch: 6| Step: 9
Training loss: 1.3554668426513672
Validation loss: 2.0661524534225464

Epoch: 6| Step: 10
Training loss: 1.8640365600585938
Validation loss: 2.1121674378712973

Epoch: 6| Step: 11
Training loss: 1.7756184339523315
Validation loss: 2.0612918734550476

Epoch: 6| Step: 12
Training loss: 1.6566663980484009
Validation loss: 2.09221084912618

Epoch: 6| Step: 13
Training loss: 2.086193799972534
Validation loss: 2.099381446838379

Epoch: 94| Step: 0
Training loss: 1.4834794998168945
Validation loss: 2.051201641559601

Epoch: 6| Step: 1
Training loss: 2.1278884410858154
Validation loss: 2.040184418360392

Epoch: 6| Step: 2
Training loss: 1.8405797481536865
Validation loss: 2.0000489950180054

Epoch: 6| Step: 3
Training loss: 1.7704626321792603
Validation loss: 2.010409891605377

Epoch: 6| Step: 4
Training loss: 1.7991435527801514
Validation loss: 2.024391492207845

Epoch: 6| Step: 5
Training loss: 1.008216142654419
Validation loss: 1.9937023123105366

Epoch: 6| Step: 6
Training loss: 1.0727758407592773
Validation loss: 2.002646525700887

Epoch: 6| Step: 7
Training loss: 1.766573190689087
Validation loss: 1.9933586517969768

Epoch: 6| Step: 8
Training loss: 1.5674446821212769
Validation loss: 2.003774265448252

Epoch: 6| Step: 9
Training loss: 1.357272744178772
Validation loss: 1.9997508525848389

Epoch: 6| Step: 10
Training loss: 1.6365761756896973
Validation loss: 1.9999631643295288

Epoch: 6| Step: 11
Training loss: 1.6520421504974365
Validation loss: 1.9987019300460815

Epoch: 6| Step: 12
Training loss: 1.378251552581787
Validation loss: 2.026869217554728

Epoch: 6| Step: 13
Training loss: 1.6117463111877441
Validation loss: 2.0010732611020408

Epoch: 95| Step: 0
Training loss: 1.2088162899017334
Validation loss: 2.0254679123560586

Epoch: 6| Step: 1
Training loss: 1.2410573959350586
Validation loss: 2.0249171058336892

Epoch: 6| Step: 2
Training loss: 1.7266595363616943
Validation loss: 2.022513747215271

Epoch: 6| Step: 3
Training loss: 2.037975549697876
Validation loss: 1.9903025428454082

Epoch: 6| Step: 4
Training loss: 2.037405490875244
Validation loss: 2.021132508913676

Epoch: 6| Step: 5
Training loss: 1.4911198616027832
Validation loss: 2.011228342851003

Epoch: 6| Step: 6
Training loss: 1.6767685413360596
Validation loss: 2.048092861970266

Epoch: 6| Step: 7
Training loss: 1.4843604564666748
Validation loss: 1.997841199239095

Epoch: 6| Step: 8
Training loss: 1.6112059354782104
Validation loss: 2.0376087427139282

Epoch: 6| Step: 9
Training loss: 1.3721938133239746
Validation loss: 2.0100693504015603

Epoch: 6| Step: 10
Training loss: 1.4233287572860718
Validation loss: 2.0319538513819375

Epoch: 6| Step: 11
Training loss: 0.9673397541046143
Validation loss: 2.024915397167206

Epoch: 6| Step: 12
Training loss: 1.9828684329986572
Validation loss: 2.0341924031575522

Epoch: 6| Step: 13
Training loss: 1.6228322982788086
Validation loss: 2.0341278513272605

Epoch: 96| Step: 0
Training loss: 1.1865262985229492
Validation loss: 2.0330926974614463

Epoch: 6| Step: 1
Training loss: 0.676844596862793
Validation loss: 2.0292139053344727

Epoch: 6| Step: 2
Training loss: 1.76617431640625
Validation loss: 2.037659525871277

Epoch: 6| Step: 3
Training loss: 1.7157952785491943
Validation loss: 2.0417849818865457

Epoch: 6| Step: 4
Training loss: 1.700066328048706
Validation loss: 2.0134676098823547

Epoch: 6| Step: 5
Training loss: 1.4026116132736206
Validation loss: 2.055207113424937

Epoch: 6| Step: 6
Training loss: 1.8893449306488037
Validation loss: 2.037892997264862

Epoch: 6| Step: 7
Training loss: 1.6746058464050293
Validation loss: 2.0331868330637612

Epoch: 6| Step: 8
Training loss: 1.6299878358840942
Validation loss: 2.0702503323554993

Epoch: 6| Step: 9
Training loss: 1.6262835264205933
Validation loss: 2.038369874159495

Epoch: 6| Step: 10
Training loss: 2.0372185707092285
Validation loss: 2.054971158504486

Epoch: 6| Step: 11
Training loss: 1.6180535554885864
Validation loss: 2.0306228001912436

Epoch: 6| Step: 12
Training loss: 1.4653329849243164
Validation loss: 2.031158149242401

Epoch: 6| Step: 13
Training loss: 1.6012814044952393
Validation loss: 1.9914240837097168

Epoch: 97| Step: 0
Training loss: 1.7549240589141846
Validation loss: 2.0248520970344543

Epoch: 6| Step: 1
Training loss: 1.7531940937042236
Validation loss: 2.0193459192911782

Epoch: 6| Step: 2
Training loss: 1.5756019353866577
Validation loss: 2.0258923768997192

Epoch: 6| Step: 3
Training loss: 1.899706482887268
Validation loss: 2.018152336279551

Epoch: 6| Step: 4
Training loss: 1.4508165121078491
Validation loss: 2.0079472859700522

Epoch: 6| Step: 5
Training loss: 1.3578908443450928
Validation loss: 2.0015552043914795

Epoch: 6| Step: 6
Training loss: 1.2585361003875732
Validation loss: 2.0372031331062317

Epoch: 6| Step: 7
Training loss: 1.8179411888122559
Validation loss: 1.9792379140853882

Epoch: 6| Step: 8
Training loss: 0.9685871601104736
Validation loss: 2.004721701145172

Epoch: 6| Step: 9
Training loss: 1.3495376110076904
Validation loss: 2.0524805585543313

Epoch: 6| Step: 10
Training loss: 2.0568161010742188
Validation loss: 2.026533782482147

Epoch: 6| Step: 11
Training loss: 1.4589486122131348
Validation loss: 2.019260585308075

Epoch: 6| Step: 12
Training loss: 1.0997322797775269
Validation loss: 2.016385078430176

Epoch: 6| Step: 13
Training loss: 1.9954173564910889
Validation loss: 2.0109349886576333

Epoch: 98| Step: 0
Training loss: 1.349273681640625
Validation loss: 2.002615968386332

Epoch: 6| Step: 1
Training loss: 1.4046947956085205
Validation loss: 2.0086349646250405

Epoch: 6| Step: 2
Training loss: 2.1890335083007812
Validation loss: 2.0095035632451377

Epoch: 6| Step: 3
Training loss: 1.3274157047271729
Validation loss: 2.0364567637443542

Epoch: 6| Step: 4
Training loss: 1.186448574066162
Validation loss: 2.0390628377596536

Epoch: 6| Step: 5
Training loss: 1.6963942050933838
Validation loss: 2.0429683526357016

Epoch: 6| Step: 6
Training loss: 1.9726401567459106
Validation loss: 1.9863317410151164

Epoch: 6| Step: 7
Training loss: 1.2296491861343384
Validation loss: 2.0455264250437417

Epoch: 6| Step: 8
Training loss: 1.6459786891937256
Validation loss: 2.0175843238830566

Epoch: 6| Step: 9
Training loss: 1.0798059701919556
Validation loss: 2.0193296472231546

Epoch: 6| Step: 10
Training loss: 0.9343979358673096
Validation loss: 2.052440822124481

Epoch: 6| Step: 11
Training loss: 1.7671723365783691
Validation loss: 2.0387231906255088

Epoch: 6| Step: 12
Training loss: 1.706800103187561
Validation loss: 2.060267527898153

Epoch: 6| Step: 13
Training loss: 1.8071272373199463
Validation loss: 2.0420450568199158

Epoch: 99| Step: 0
Training loss: 1.235807180404663
Validation loss: 2.0537644227345786

Epoch: 6| Step: 1
Training loss: 1.745880126953125
Validation loss: 2.051201065381368

Epoch: 6| Step: 2
Training loss: 1.1088327169418335
Validation loss: 2.027740995089213

Epoch: 6| Step: 3
Training loss: 1.5588765144348145
Validation loss: 2.026512066523234

Epoch: 6| Step: 4
Training loss: 2.394188404083252
Validation loss: 2.0193705757459006

Epoch: 6| Step: 5
Training loss: 1.4834702014923096
Validation loss: 2.033026099205017

Epoch: 6| Step: 6
Training loss: 1.6314233541488647
Validation loss: 2.0210589369138083

Epoch: 6| Step: 7
Training loss: 1.7260078191757202
Validation loss: 2.0636301835378013

Epoch: 6| Step: 8
Training loss: 1.499287724494934
Validation loss: 2.0095609227816262

Epoch: 6| Step: 9
Training loss: 1.7372480630874634
Validation loss: 2.045794049898783

Epoch: 6| Step: 10
Training loss: 1.3841021060943604
Validation loss: 1.9797534743944805

Epoch: 6| Step: 11
Training loss: 1.4275665283203125
Validation loss: 2.0085493524869285

Epoch: 6| Step: 12
Training loss: 0.9669883251190186
Validation loss: 1.991104781627655

Epoch: 6| Step: 13
Training loss: 1.3040146827697754
Validation loss: 2.0455322265625

Epoch: 100| Step: 0
Training loss: 1.6309318542480469
Validation loss: 2.0502424240112305

Epoch: 6| Step: 1
Training loss: 1.7902168035507202
Validation loss: 2.0310898224512735

Epoch: 6| Step: 2
Training loss: 1.6574795246124268
Validation loss: 2.057356576124827

Epoch: 6| Step: 3
Training loss: 0.942926287651062
Validation loss: 2.044758756955465

Epoch: 6| Step: 4
Training loss: 1.2829272747039795
Validation loss: 2.061942756175995

Epoch: 6| Step: 5
Training loss: 1.4999901056289673
Validation loss: 2.0356885194778442

Epoch: 6| Step: 6
Training loss: 1.794260859489441
Validation loss: 2.032319128513336

Epoch: 6| Step: 7
Training loss: 1.689354419708252
Validation loss: 2.029002050558726

Epoch: 6| Step: 8
Training loss: 1.555016040802002
Validation loss: 2.0124575098355613

Epoch: 6| Step: 9
Training loss: 2.3338937759399414
Validation loss: 2.010484059651693

Epoch: 6| Step: 10
Training loss: 0.7770215272903442
Validation loss: 1.9782585700352986

Epoch: 6| Step: 11
Training loss: 1.3996740579605103
Validation loss: 2.0107542872428894

Epoch: 6| Step: 12
Training loss: 1.33292555809021
Validation loss: 1.9937350153923035

Epoch: 6| Step: 13
Training loss: 1.7331366539001465
Validation loss: 2.0107669631640115

Testing loss: 1.8202334745324773
