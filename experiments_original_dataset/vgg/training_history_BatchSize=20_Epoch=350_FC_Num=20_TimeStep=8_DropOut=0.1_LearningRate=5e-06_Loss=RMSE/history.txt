Epoch: 1| Step: 0
Training loss: 7.1220756017094375
Validation loss: 6.734222445784688

Epoch: 5| Step: 1
Training loss: 6.305659449650822
Validation loss: 6.704243054694669

Epoch: 5| Step: 2
Training loss: 6.722852581023317
Validation loss: 6.676665207203582

Epoch: 5| Step: 3
Training loss: 7.274021997946619
Validation loss: 6.653056744341394

Epoch: 5| Step: 4
Training loss: 7.56314210293832
Validation loss: 6.629894607764953

Epoch: 5| Step: 5
Training loss: 5.998936240947158
Validation loss: 6.604500345972153

Epoch: 5| Step: 6
Training loss: 6.2848209080637725
Validation loss: 6.587227751904794

Epoch: 5| Step: 7
Training loss: 6.6364347993258495
Validation loss: 6.563846026238627

Epoch: 5| Step: 8
Training loss: 6.968525835888065
Validation loss: 6.541410036175921

Epoch: 5| Step: 9
Training loss: 6.740448587131403
Validation loss: 6.516411103443179

Epoch: 5| Step: 10
Training loss: 6.1006243151756285
Validation loss: 6.495511779591243

Epoch: 5| Step: 11
Training loss: 6.9307603145396435
Validation loss: 6.474288762182298

Epoch: 2| Step: 0
Training loss: 6.563222209609018
Validation loss: 6.444297670560129

Epoch: 5| Step: 1
Training loss: 5.9395073960649425
Validation loss: 6.417323074784921

Epoch: 5| Step: 2
Training loss: 5.381519710502903
Validation loss: 6.393307956642542

Epoch: 5| Step: 3
Training loss: 6.861468784140348
Validation loss: 6.362782245863388

Epoch: 5| Step: 4
Training loss: 6.5593146449961175
Validation loss: 6.33312864558412

Epoch: 5| Step: 5
Training loss: 7.330201202587154
Validation loss: 6.298189226419697

Epoch: 5| Step: 6
Training loss: 5.774336686786048
Validation loss: 6.2681980826971815

Epoch: 5| Step: 7
Training loss: 5.580318756843422
Validation loss: 6.23493487171378

Epoch: 5| Step: 8
Training loss: 6.119258135541802
Validation loss: 6.201703040735564

Epoch: 5| Step: 9
Training loss: 7.521116918851298
Validation loss: 6.159963426976811

Epoch: 5| Step: 10
Training loss: 6.230454361758465
Validation loss: 6.120756534781038

Epoch: 5| Step: 11
Training loss: 6.606362091239505
Validation loss: 6.078137408377069

Epoch: 3| Step: 0
Training loss: 5.9452185003040405
Validation loss: 6.029825744072189

Epoch: 5| Step: 1
Training loss: 5.7714956112411775
Validation loss: 5.997803961686601

Epoch: 5| Step: 2
Training loss: 5.8296825792327125
Validation loss: 5.951937506142975

Epoch: 5| Step: 3
Training loss: 5.695409954477425
Validation loss: 5.899682310678533

Epoch: 5| Step: 4
Training loss: 5.13933011242872
Validation loss: 5.8530313289144305

Epoch: 5| Step: 5
Training loss: 5.843652734609993
Validation loss: 5.799218087271471

Epoch: 5| Step: 6
Training loss: 6.636574476985413
Validation loss: 5.75417347805643

Epoch: 5| Step: 7
Training loss: 6.13331755484058
Validation loss: 5.699991516753905

Epoch: 5| Step: 8
Training loss: 5.661164735576071
Validation loss: 5.637571859359916

Epoch: 5| Step: 9
Training loss: 5.890286949434611
Validation loss: 5.57221084355648

Epoch: 5| Step: 10
Training loss: 5.652925979375274
Validation loss: 5.507268430563295

Epoch: 5| Step: 11
Training loss: 7.401248579110497
Validation loss: 5.43480507434127

Epoch: 4| Step: 0
Training loss: 4.8729787695641615
Validation loss: 5.377605243033116

Epoch: 5| Step: 1
Training loss: 5.437088874094729
Validation loss: 5.293694200338011

Epoch: 5| Step: 2
Training loss: 5.720866160936441
Validation loss: 5.2111071969329155

Epoch: 5| Step: 3
Training loss: 5.297515380318581
Validation loss: 5.137698499026842

Epoch: 5| Step: 4
Training loss: 5.363228616365915
Validation loss: 5.057284726086721

Epoch: 5| Step: 5
Training loss: 4.655818023101139
Validation loss: 4.96006474064291

Epoch: 5| Step: 6
Training loss: 5.714389159764872
Validation loss: 4.874766523524957

Epoch: 5| Step: 7
Training loss: 4.35928377445712
Validation loss: 4.78209759382064

Epoch: 5| Step: 8
Training loss: 4.662485338448798
Validation loss: 4.680938069604378

Epoch: 5| Step: 9
Training loss: 4.076438818298523
Validation loss: 4.567427843703961

Epoch: 5| Step: 10
Training loss: 4.945114445147893
Validation loss: 4.486754447400448

Epoch: 5| Step: 11
Training loss: 4.609876288617983
Validation loss: 4.366282278837664

Epoch: 5| Step: 0
Training loss: 4.295285350482017
Validation loss: 4.255550177798734

Epoch: 5| Step: 1
Training loss: 3.9660991316124896
Validation loss: 4.140392580047062

Epoch: 5| Step: 2
Training loss: 4.156749723981739
Validation loss: 4.016392704945111

Epoch: 5| Step: 3
Training loss: 2.763793770086791
Validation loss: 3.8945025994902767

Epoch: 5| Step: 4
Training loss: 4.090042881822449
Validation loss: 3.768991081788971

Epoch: 5| Step: 5
Training loss: 3.944903120197831
Validation loss: 3.657551460451657

Epoch: 5| Step: 6
Training loss: 3.566372824237528
Validation loss: 3.5547663529701325

Epoch: 5| Step: 7
Training loss: 2.573211797140277
Validation loss: 3.4127248126397993

Epoch: 5| Step: 8
Training loss: 3.6322404308477916
Validation loss: 3.3129354406653353

Epoch: 5| Step: 9
Training loss: 3.5993113070941747
Validation loss: 3.1924001732734695

Epoch: 5| Step: 10
Training loss: 3.840782446617628
Validation loss: 3.097454093311209

Epoch: 5| Step: 11
Training loss: 3.387376063708437
Validation loss: 2.9877393443106155

Epoch: 6| Step: 0
Training loss: 2.776022981982783
Validation loss: 2.9217553513724535

Epoch: 5| Step: 1
Training loss: 3.04655853975551
Validation loss: 2.824032300296768

Epoch: 5| Step: 2
Training loss: 3.712922346450171
Validation loss: 2.769238688337552

Epoch: 5| Step: 3
Training loss: 2.0580533963422925
Validation loss: 2.7356446579118

Epoch: 5| Step: 4
Training loss: 2.4403130364902887
Validation loss: 2.71519508192527

Epoch: 5| Step: 5
Training loss: 2.3583735683859595
Validation loss: 2.699474147816744

Epoch: 5| Step: 6
Training loss: 2.534220330237673
Validation loss: 2.6978905515744684

Epoch: 5| Step: 7
Training loss: 3.5723732107739896
Validation loss: 2.749620245230876

Epoch: 5| Step: 8
Training loss: 3.0063112946604233
Validation loss: 2.7632977056008827

Epoch: 5| Step: 9
Training loss: 2.172684552921548
Validation loss: 2.769458398546805

Epoch: 5| Step: 10
Training loss: 2.8811395851542954
Validation loss: 2.8488392825361255

Epoch: 5| Step: 11
Training loss: 2.98512953561841
Validation loss: 2.8587237834242605

Epoch: 7| Step: 0
Training loss: 2.4935597435598265
Validation loss: 2.8382809067157257

Epoch: 5| Step: 1
Training loss: 2.2323270362072916
Validation loss: 2.851777975223918

Epoch: 5| Step: 2
Training loss: 2.566010280585563
Validation loss: 2.863003691733633

Epoch: 5| Step: 3
Training loss: 3.0234160508767594
Validation loss: 2.8089490585289085

Epoch: 5| Step: 4
Training loss: 2.749120658388544
Validation loss: 2.8260404832619312

Epoch: 5| Step: 5
Training loss: 2.649391745091224
Validation loss: 2.8219947412150317

Epoch: 5| Step: 6
Training loss: 2.622805450077279
Validation loss: 2.816305023786866

Epoch: 5| Step: 7
Training loss: 2.529930712840508
Validation loss: 2.7865426606344785

Epoch: 5| Step: 8
Training loss: 3.698588235971939
Validation loss: 2.7917091570415176

Epoch: 5| Step: 9
Training loss: 2.716237013917892
Validation loss: 2.7304090021278977

Epoch: 5| Step: 10
Training loss: 2.781904850707276
Validation loss: 2.721489881328606

Epoch: 5| Step: 11
Training loss: 1.2709811338349566
Validation loss: 2.7276044310319003

Epoch: 8| Step: 0
Training loss: 2.38625170044716
Validation loss: 2.7373949322503717

Epoch: 5| Step: 1
Training loss: 2.6301582155394247
Validation loss: 2.6881622858690775

Epoch: 5| Step: 2
Training loss: 1.6859536326629085
Validation loss: 2.6960564991667497

Epoch: 5| Step: 3
Training loss: 2.606252846842064
Validation loss: 2.684413594037675

Epoch: 5| Step: 4
Training loss: 2.6271015111146596
Validation loss: 2.704903023351133

Epoch: 5| Step: 5
Training loss: 2.477369688362022
Validation loss: 2.672692473135518

Epoch: 5| Step: 6
Training loss: 3.0834137845927527
Validation loss: 2.7062561958659064

Epoch: 5| Step: 7
Training loss: 2.744160607967722
Validation loss: 2.704001584081261

Epoch: 5| Step: 8
Training loss: 3.4798207991050742
Validation loss: 2.708628870660528

Epoch: 5| Step: 9
Training loss: 2.484161655694394
Validation loss: 2.7087478112688834

Epoch: 5| Step: 10
Training loss: 2.7485384958870056
Validation loss: 2.709190696334775

Epoch: 5| Step: 11
Training loss: 2.582735782136998
Validation loss: 2.697673467527215

Epoch: 9| Step: 0
Training loss: 2.7637581424256754
Validation loss: 2.700744286136079

Epoch: 5| Step: 1
Training loss: 2.650662188297201
Validation loss: 2.7156357302964027

Epoch: 5| Step: 2
Training loss: 2.869997066802011
Validation loss: 2.6892118324960803

Epoch: 5| Step: 3
Training loss: 3.1357573939797905
Validation loss: 2.6975779719687196

Epoch: 5| Step: 4
Training loss: 2.873542250216923
Validation loss: 2.7102117895463564

Epoch: 5| Step: 5
Training loss: 3.189716540810135
Validation loss: 2.661011766019687

Epoch: 5| Step: 6
Training loss: 1.9015664269086276
Validation loss: 2.698412136598514

Epoch: 5| Step: 7
Training loss: 2.752072333738151
Validation loss: 2.7042693580521635

Epoch: 5| Step: 8
Training loss: 2.724878703926257
Validation loss: 2.6893040272429274

Epoch: 5| Step: 9
Training loss: 2.389655122174702
Validation loss: 2.7068788339662144

Epoch: 5| Step: 10
Training loss: 2.304332227317706
Validation loss: 2.6933819403566406

Epoch: 5| Step: 11
Training loss: 2.5800260066414618
Validation loss: 2.6902773205304835

Epoch: 10| Step: 0
Training loss: 2.5862189655460814
Validation loss: 2.7254011692249387

Epoch: 5| Step: 1
Training loss: 2.514593635628578
Validation loss: 2.713222530047025

Epoch: 5| Step: 2
Training loss: 2.9176775315899333
Validation loss: 2.70477699412335

Epoch: 5| Step: 3
Training loss: 2.5751588346511056
Validation loss: 2.660018499078218

Epoch: 5| Step: 4
Training loss: 2.659222364696097
Validation loss: 2.6807127938302657

Epoch: 5| Step: 5
Training loss: 2.636569458302468
Validation loss: 2.7203670274943437

Epoch: 5| Step: 6
Training loss: 2.7749189691483527
Validation loss: 2.7142451003628523

Epoch: 5| Step: 7
Training loss: 2.7078739852660365
Validation loss: 2.6771859744293853

Epoch: 5| Step: 8
Training loss: 2.2831431854969053
Validation loss: 2.690416062557662

Epoch: 5| Step: 9
Training loss: 2.9004465219782056
Validation loss: 2.715768297143805

Epoch: 5| Step: 10
Training loss: 2.7843069357211117
Validation loss: 2.706757788999531

Epoch: 5| Step: 11
Training loss: 1.2161594147778119
Validation loss: 2.6983014584728786

Epoch: 11| Step: 0
Training loss: 2.2111530535866346
Validation loss: 2.6943050473543937

Epoch: 5| Step: 1
Training loss: 2.955624930046405
Validation loss: 2.706742620379216

Epoch: 5| Step: 2
Training loss: 2.6049795077464255
Validation loss: 2.702422570781753

Epoch: 5| Step: 3
Training loss: 2.719374135604016
Validation loss: 2.6958432361493614

Epoch: 5| Step: 4
Training loss: 2.648030747768139
Validation loss: 2.7206602437769924

Epoch: 5| Step: 5
Training loss: 2.3809012330328865
Validation loss: 2.6752872651483735

Epoch: 5| Step: 6
Training loss: 3.299641248680698
Validation loss: 2.7139448511908317

Epoch: 5| Step: 7
Training loss: 2.8622402156569637
Validation loss: 2.713229314554344

Epoch: 5| Step: 8
Training loss: 2.3353193096611373
Validation loss: 2.691284527584454

Epoch: 5| Step: 9
Training loss: 2.413295586995087
Validation loss: 2.6884194102542054

Epoch: 5| Step: 10
Training loss: 2.832484810124312
Validation loss: 2.6943836694157763

Epoch: 5| Step: 11
Training loss: 1.0925017727416297
Validation loss: 2.7151003087436694

Epoch: 12| Step: 0
Training loss: 2.4860622986086804
Validation loss: 2.6535471460162494

Epoch: 5| Step: 1
Training loss: 2.4469917552077964
Validation loss: 2.6730050194028725

Epoch: 5| Step: 2
Training loss: 2.9257841835974947
Validation loss: 2.6888157780308535

Epoch: 5| Step: 3
Training loss: 2.6080723783302355
Validation loss: 2.680109348586909

Epoch: 5| Step: 4
Training loss: 3.049253660095525
Validation loss: 2.6832811302138087

Epoch: 5| Step: 5
Training loss: 2.5688504869988917
Validation loss: 2.7126287668548086

Epoch: 5| Step: 6
Training loss: 2.444746348011532
Validation loss: 2.6764409869229167

Epoch: 5| Step: 7
Training loss: 2.261884666774275
Validation loss: 2.693738549688303

Epoch: 5| Step: 8
Training loss: 2.2615562999936065
Validation loss: 2.6873813906082806

Epoch: 5| Step: 9
Training loss: 2.6789442983591387
Validation loss: 2.658596744959771

Epoch: 5| Step: 10
Training loss: 3.3788646188277096
Validation loss: 2.66205581010351

Epoch: 5| Step: 11
Training loss: 1.371929424831261
Validation loss: 2.6585263240999155

Epoch: 13| Step: 0
Training loss: 2.1467740364155086
Validation loss: 2.653311499041747

Epoch: 5| Step: 1
Training loss: 2.2073031367720564
Validation loss: 2.6650803039647437

Epoch: 5| Step: 2
Training loss: 3.142280559783617
Validation loss: 2.663615751423444

Epoch: 5| Step: 3
Training loss: 2.90546546109109
Validation loss: 2.682150680886025

Epoch: 5| Step: 4
Training loss: 2.856084879770575
Validation loss: 2.6805068673492567

Epoch: 5| Step: 5
Training loss: 3.0427723969364036
Validation loss: 2.6799505454987638

Epoch: 5| Step: 6
Training loss: 2.8166084798938615
Validation loss: 2.69150674057462

Epoch: 5| Step: 7
Training loss: 2.300941345137026
Validation loss: 2.680070643935099

Epoch: 5| Step: 8
Training loss: 2.405282160332336
Validation loss: 2.668053982640609

Epoch: 5| Step: 9
Training loss: 2.4236269613025208
Validation loss: 2.6656975375908893

Epoch: 5| Step: 10
Training loss: 2.6785244656033464
Validation loss: 2.676507228556031

Epoch: 5| Step: 11
Training loss: 3.300397536868428
Validation loss: 2.6955307950432075

Epoch: 14| Step: 0
Training loss: 2.0857700466421227
Validation loss: 2.689767782641871

Epoch: 5| Step: 1
Training loss: 3.087208778145067
Validation loss: 2.6781544169261093

Epoch: 5| Step: 2
Training loss: 2.039524186873986
Validation loss: 2.683270478894581

Epoch: 5| Step: 3
Training loss: 3.0188090063926927
Validation loss: 2.689204784222066

Epoch: 5| Step: 4
Training loss: 2.082472992317766
Validation loss: 2.7063343018813817

Epoch: 5| Step: 5
Training loss: 2.873949273539789
Validation loss: 2.6666427340526315

Epoch: 5| Step: 6
Training loss: 3.0856761966604997
Validation loss: 2.66905063496245

Epoch: 5| Step: 7
Training loss: 3.1058860642365094
Validation loss: 2.6704423830049295

Epoch: 5| Step: 8
Training loss: 2.303430971191494
Validation loss: 2.6692803892879478

Epoch: 5| Step: 9
Training loss: 2.1134116649049814
Validation loss: 2.6685442026970905

Epoch: 5| Step: 10
Training loss: 2.7817190396281375
Validation loss: 2.663651957719246

Epoch: 5| Step: 11
Training loss: 2.4031986855270917
Validation loss: 2.6873597285901707

Epoch: 15| Step: 0
Training loss: 2.405210790774705
Validation loss: 2.6896093411349167

Epoch: 5| Step: 1
Training loss: 2.9105512722147533
Validation loss: 2.649728361038825

Epoch: 5| Step: 2
Training loss: 2.915598610189219
Validation loss: 2.6684519012392554

Epoch: 5| Step: 3
Training loss: 2.6174007499700163
Validation loss: 2.6840113759550657

Epoch: 5| Step: 4
Training loss: 2.5927507245062125
Validation loss: 2.654784654826929

Epoch: 5| Step: 5
Training loss: 2.9272155912844697
Validation loss: 2.6679336523202144

Epoch: 5| Step: 6
Training loss: 2.571506396887038
Validation loss: 2.6629607606365937

Epoch: 5| Step: 7
Training loss: 2.9965380720892685
Validation loss: 2.66580219835124

Epoch: 5| Step: 8
Training loss: 2.2094631064192787
Validation loss: 2.6629072501713873

Epoch: 5| Step: 9
Training loss: 2.3096445341866128
Validation loss: 2.6896036955941462

Epoch: 5| Step: 10
Training loss: 2.282008005955633
Validation loss: 2.6984836075964433

Epoch: 5| Step: 11
Training loss: 3.4182017219709198
Validation loss: 2.6586187272753294

Epoch: 16| Step: 0
Training loss: 2.862138090618282
Validation loss: 2.692754635637188

Epoch: 5| Step: 1
Training loss: 2.9937153792320648
Validation loss: 2.6700128085416157

Epoch: 5| Step: 2
Training loss: 2.8475564486540885
Validation loss: 2.6678461890975464

Epoch: 5| Step: 3
Training loss: 2.54180112597736
Validation loss: 2.6687421929619717

Epoch: 5| Step: 4
Training loss: 2.5598720938796777
Validation loss: 2.6781401694249127

Epoch: 5| Step: 5
Training loss: 2.0545696036161725
Validation loss: 2.6895086448477543

Epoch: 5| Step: 6
Training loss: 2.433801437014625
Validation loss: 2.6648753204309723

Epoch: 5| Step: 7
Training loss: 2.8526540678845143
Validation loss: 2.6968296738252735

Epoch: 5| Step: 8
Training loss: 1.895220570170601
Validation loss: 2.634625351256186

Epoch: 5| Step: 9
Training loss: 2.8162130641419947
Validation loss: 2.6990668460630904

Epoch: 5| Step: 10
Training loss: 2.9910065633739413
Validation loss: 2.690559257622753

Epoch: 5| Step: 11
Training loss: 2.1684961175864035
Validation loss: 2.6587980689776107

Epoch: 17| Step: 0
Training loss: 2.288722719355971
Validation loss: 2.6698777577220927

Epoch: 5| Step: 1
Training loss: 2.02579775978949
Validation loss: 2.6520188160190923

Epoch: 5| Step: 2
Training loss: 3.5935504360351094
Validation loss: 2.6345293011168036

Epoch: 5| Step: 3
Training loss: 2.378457213367588
Validation loss: 2.6227571275794985

Epoch: 5| Step: 4
Training loss: 2.9163375850496362
Validation loss: 2.6562862692956015

Epoch: 5| Step: 5
Training loss: 2.2571118597554554
Validation loss: 2.6079213743832184

Epoch: 5| Step: 6
Training loss: 2.855855307656367
Validation loss: 2.646165572855679

Epoch: 5| Step: 7
Training loss: 2.963609762811715
Validation loss: 2.6547224177593223

Epoch: 5| Step: 8
Training loss: 2.250254298780404
Validation loss: 2.6621603155078457

Epoch: 5| Step: 9
Training loss: 2.728629042303202
Validation loss: 2.6457995027096373

Epoch: 5| Step: 10
Training loss: 2.2226468104478814
Validation loss: 2.6315074104595175

Epoch: 5| Step: 11
Training loss: 2.4475974233250617
Validation loss: 2.6635215262222327

Epoch: 18| Step: 0
Training loss: 3.005964390120557
Validation loss: 2.654047613952206

Epoch: 5| Step: 1
Training loss: 2.561719636024073
Validation loss: 2.6414974659865402

Epoch: 5| Step: 2
Training loss: 2.246824460794232
Validation loss: 2.6675646109533577

Epoch: 5| Step: 3
Training loss: 2.1704296544575525
Validation loss: 2.647781838546761

Epoch: 5| Step: 4
Training loss: 2.6021201879142852
Validation loss: 2.6381279577488552

Epoch: 5| Step: 5
Training loss: 2.6951360230099026
Validation loss: 2.6894484191868138

Epoch: 5| Step: 6
Training loss: 2.7024049185683827
Validation loss: 2.654092503404317

Epoch: 5| Step: 7
Training loss: 2.855633899176414
Validation loss: 2.6843087189277437

Epoch: 5| Step: 8
Training loss: 2.242345717958686
Validation loss: 2.6577331291904573

Epoch: 5| Step: 9
Training loss: 2.3951554597162366
Validation loss: 2.640082512382483

Epoch: 5| Step: 10
Training loss: 3.4806761674481588
Validation loss: 2.6751238829902415

Epoch: 5| Step: 11
Training loss: 2.1042891614654664
Validation loss: 2.6457435725347684

Epoch: 19| Step: 0
Training loss: 2.9870577432972385
Validation loss: 2.6784062079533055

Epoch: 5| Step: 1
Training loss: 2.309967510110502
Validation loss: 2.646791287839491

Epoch: 5| Step: 2
Training loss: 2.306000933340104
Validation loss: 2.6581977322850965

Epoch: 5| Step: 3
Training loss: 2.7493028624085865
Validation loss: 2.686067428538308

Epoch: 5| Step: 4
Training loss: 2.4385584953821366
Validation loss: 2.660887686262605

Epoch: 5| Step: 5
Training loss: 2.803981341453651
Validation loss: 2.642453179667951

Epoch: 5| Step: 6
Training loss: 2.712921735614003
Validation loss: 2.66316439572828

Epoch: 5| Step: 7
Training loss: 3.0952807406048293
Validation loss: 2.6525243436431527

Epoch: 5| Step: 8
Training loss: 2.2385087621609805
Validation loss: 2.647472288228628

Epoch: 5| Step: 9
Training loss: 2.145838604769358
Validation loss: 2.661577059093961

Epoch: 5| Step: 10
Training loss: 2.972525675207955
Validation loss: 2.6521827862399783

Epoch: 5| Step: 11
Training loss: 1.3753979713874291
Validation loss: 2.613334761652832

Epoch: 20| Step: 0
Training loss: 2.80541489713307
Validation loss: 2.6254351346080216

Epoch: 5| Step: 1
Training loss: 2.3295240870677865
Validation loss: 2.6454694239845895

Epoch: 5| Step: 2
Training loss: 2.172216704129329
Validation loss: 2.640692881176285

Epoch: 5| Step: 3
Training loss: 2.8197968664122546
Validation loss: 2.6347954335752215

Epoch: 5| Step: 4
Training loss: 2.0958580677956795
Validation loss: 2.6306386645956032

Epoch: 5| Step: 5
Training loss: 2.9450594441708144
Validation loss: 2.640627832806213

Epoch: 5| Step: 6
Training loss: 2.6501001411086436
Validation loss: 2.6750645218254476

Epoch: 5| Step: 7
Training loss: 2.8712646433515396
Validation loss: 2.649383960950797

Epoch: 5| Step: 8
Training loss: 2.033177327075767
Validation loss: 2.6634171301757177

Epoch: 5| Step: 9
Training loss: 2.5838584263699884
Validation loss: 2.6414370068941975

Epoch: 5| Step: 10
Training loss: 3.06697471840572
Validation loss: 2.6468898410974044

Epoch: 5| Step: 11
Training loss: 1.554185949347415
Validation loss: 2.6620473912785596

Epoch: 21| Step: 0
Training loss: 2.517181294183167
Validation loss: 2.654859897164114

Epoch: 5| Step: 1
Training loss: 2.867206292779437
Validation loss: 2.6533003380315754

Epoch: 5| Step: 2
Training loss: 2.8776443593712195
Validation loss: 2.6326389953614155

Epoch: 5| Step: 3
Training loss: 2.993766826032847
Validation loss: 2.5974123197289467

Epoch: 5| Step: 4
Training loss: 2.546583194047051
Validation loss: 2.640221111551942

Epoch: 5| Step: 5
Training loss: 2.0716402222880803
Validation loss: 2.6204072912756837

Epoch: 5| Step: 6
Training loss: 1.9695051652269697
Validation loss: 2.6422455910422027

Epoch: 5| Step: 7
Training loss: 2.260282333765523
Validation loss: 2.6786159934771967

Epoch: 5| Step: 8
Training loss: 2.778471855763791
Validation loss: 2.6251968998707067

Epoch: 5| Step: 9
Training loss: 2.2691538721854667
Validation loss: 2.65535343971401

Epoch: 5| Step: 10
Training loss: 2.965305297469748
Validation loss: 2.643438420523855

Epoch: 5| Step: 11
Training loss: 3.504177597579206
Validation loss: 2.6188352417709995

Epoch: 22| Step: 0
Training loss: 2.3204583016257243
Validation loss: 2.634360891012509

Epoch: 5| Step: 1
Training loss: 2.5029432137875824
Validation loss: 2.6372604303498766

Epoch: 5| Step: 2
Training loss: 2.0716765894182902
Validation loss: 2.6567597405005707

Epoch: 5| Step: 3
Training loss: 1.7716785732430214
Validation loss: 2.632841610016523

Epoch: 5| Step: 4
Training loss: 2.949646854276187
Validation loss: 2.6606212849942414

Epoch: 5| Step: 5
Training loss: 2.697186247191427
Validation loss: 2.6339490231604366

Epoch: 5| Step: 6
Training loss: 2.3845430687382185
Validation loss: 2.6567227186043874

Epoch: 5| Step: 7
Training loss: 2.772464635294954
Validation loss: 2.640437640553837

Epoch: 5| Step: 8
Training loss: 2.9032593793534383
Validation loss: 2.6157466737072883

Epoch: 5| Step: 9
Training loss: 2.7467787689955014
Validation loss: 2.6568185796126014

Epoch: 5| Step: 10
Training loss: 3.0394810876171645
Validation loss: 2.6244141893821404

Epoch: 5| Step: 11
Training loss: 3.4389201611843214
Validation loss: 2.6218773570180853

Epoch: 23| Step: 0
Training loss: 2.1692557149286222
Validation loss: 2.6211196397847267

Epoch: 5| Step: 1
Training loss: 2.5882183054631653
Validation loss: 2.6134306936674503

Epoch: 5| Step: 2
Training loss: 2.2636368018947595
Validation loss: 2.6222797445129924

Epoch: 5| Step: 3
Training loss: 2.4155453568884404
Validation loss: 2.641490339286902

Epoch: 5| Step: 4
Training loss: 3.002655125913694
Validation loss: 2.6373848193903537

Epoch: 5| Step: 5
Training loss: 2.7217582633806785
Validation loss: 2.670445902144502

Epoch: 5| Step: 6
Training loss: 2.7815814731534956
Validation loss: 2.6534036345509624

Epoch: 5| Step: 7
Training loss: 2.664746328165073
Validation loss: 2.6851602652886633

Epoch: 5| Step: 8
Training loss: 3.0908756968280344
Validation loss: 2.6621172786603715

Epoch: 5| Step: 9
Training loss: 2.2491594439919753
Validation loss: 2.6229967920630584

Epoch: 5| Step: 10
Training loss: 2.5419774621103937
Validation loss: 2.6628895038880116

Epoch: 5| Step: 11
Training loss: 1.943849434716437
Validation loss: 2.6207330704772698

Epoch: 24| Step: 0
Training loss: 2.04344787230997
Validation loss: 2.6276232331525886

Epoch: 5| Step: 1
Training loss: 2.242096796095187
Validation loss: 2.611901702695677

Epoch: 5| Step: 2
Training loss: 2.3784227302643006
Validation loss: 2.608435269325076

Epoch: 5| Step: 3
Training loss: 2.929367658322272
Validation loss: 2.608266754996775

Epoch: 5| Step: 4
Training loss: 1.8598743056824087
Validation loss: 2.6315983275172545

Epoch: 5| Step: 5
Training loss: 2.637736891101394
Validation loss: 2.6025884665356056

Epoch: 5| Step: 6
Training loss: 2.8680711262926573
Validation loss: 2.6250935341050403

Epoch: 5| Step: 7
Training loss: 2.5257008325887975
Validation loss: 2.6440840492802615

Epoch: 5| Step: 8
Training loss: 2.864807804444949
Validation loss: 2.6495046463022347

Epoch: 5| Step: 9
Training loss: 3.2101910319780025
Validation loss: 2.6402055155108113

Epoch: 5| Step: 10
Training loss: 2.395003553798006
Validation loss: 2.631165752587446

Epoch: 5| Step: 11
Training loss: 2.1764723606435963
Validation loss: 2.6242614380723284

Epoch: 25| Step: 0
Training loss: 2.572876830828672
Validation loss: 2.6523299631201476

Epoch: 5| Step: 1
Training loss: 2.8769418543991727
Validation loss: 2.632995191625485

Epoch: 5| Step: 2
Training loss: 2.7165415772110966
Validation loss: 2.6248655436155466

Epoch: 5| Step: 3
Training loss: 2.106479380990434
Validation loss: 2.631963968554046

Epoch: 5| Step: 4
Training loss: 2.654522322735647
Validation loss: 2.6070219154636627

Epoch: 5| Step: 5
Training loss: 2.283490374192977
Validation loss: 2.5967675010444213

Epoch: 5| Step: 6
Training loss: 2.286562338674325
Validation loss: 2.6125680342702844

Epoch: 5| Step: 7
Training loss: 2.439453418203295
Validation loss: 2.646701356220478

Epoch: 5| Step: 8
Training loss: 2.4561125428076402
Validation loss: 2.641183293780982

Epoch: 5| Step: 9
Training loss: 2.7994709434684215
Validation loss: 2.6381611286199753

Epoch: 5| Step: 10
Training loss: 2.931899555520637
Validation loss: 2.610605155480351

Epoch: 5| Step: 11
Training loss: 3.269012008873653
Validation loss: 2.6128551514013436

Epoch: 26| Step: 0
Training loss: 2.3319240015055396
Validation loss: 2.5974596068637994

Epoch: 5| Step: 1
Training loss: 2.4984519934218943
Validation loss: 2.597050952420844

Epoch: 5| Step: 2
Training loss: 2.1338024706386514
Validation loss: 2.6121969249518955

Epoch: 5| Step: 3
Training loss: 2.329258380464973
Validation loss: 2.634851701714611

Epoch: 5| Step: 4
Training loss: 3.440080263842646
Validation loss: 2.6055901998097837

Epoch: 5| Step: 5
Training loss: 2.7058382914875336
Validation loss: 2.617705427705301

Epoch: 5| Step: 6
Training loss: 2.066117553158396
Validation loss: 2.6205923033795187

Epoch: 5| Step: 7
Training loss: 2.5857371457210174
Validation loss: 2.6212071954667024

Epoch: 5| Step: 8
Training loss: 3.310101774558385
Validation loss: 2.6753425219906637

Epoch: 5| Step: 9
Training loss: 2.665111883223227
Validation loss: 2.6406433097309905

Epoch: 5| Step: 10
Training loss: 2.19337567996778
Validation loss: 2.6810520023430597

Epoch: 5| Step: 11
Training loss: 1.715072095262007
Validation loss: 2.62693119158091

Epoch: 27| Step: 0
Training loss: 2.85487787523304
Validation loss: 2.5991322351551687

Epoch: 5| Step: 1
Training loss: 2.6505811449923513
Validation loss: 2.6073854974883193

Epoch: 5| Step: 2
Training loss: 2.412156225822838
Validation loss: 2.637002487928374

Epoch: 5| Step: 3
Training loss: 2.764425933734349
Validation loss: 2.64340286749

Epoch: 5| Step: 4
Training loss: 2.8527226008653197
Validation loss: 2.604172162368062

Epoch: 5| Step: 5
Training loss: 1.8464950557986521
Validation loss: 2.6463391704068107

Epoch: 5| Step: 6
Training loss: 2.6164476857815524
Validation loss: 2.5976680860512675

Epoch: 5| Step: 7
Training loss: 2.7681323393678987
Validation loss: 2.6110265172930145

Epoch: 5| Step: 8
Training loss: 2.2363270588834796
Validation loss: 2.6213683256002747

Epoch: 5| Step: 9
Training loss: 2.47429044937013
Validation loss: 2.6317017171271893

Epoch: 5| Step: 10
Training loss: 2.7291356053416895
Validation loss: 2.6345546704885456

Epoch: 5| Step: 11
Training loss: 1.8507013692561272
Validation loss: 2.627556071047624

Epoch: 28| Step: 0
Training loss: 2.6897190602453027
Validation loss: 2.6030980600685685

Epoch: 5| Step: 1
Training loss: 2.466603758585411
Validation loss: 2.599798094875523

Epoch: 5| Step: 2
Training loss: 2.3346803273981935
Validation loss: 2.580087446590105

Epoch: 5| Step: 3
Training loss: 2.291388673971812
Validation loss: 2.6189416956330716

Epoch: 5| Step: 4
Training loss: 2.3501809963569205
Validation loss: 2.569324427170141

Epoch: 5| Step: 5
Training loss: 2.7257187201734348
Validation loss: 2.6037819171242838

Epoch: 5| Step: 6
Training loss: 2.6959559460388403
Validation loss: 2.6056603356973738

Epoch: 5| Step: 7
Training loss: 3.243782845920679
Validation loss: 2.6193501661029543

Epoch: 5| Step: 8
Training loss: 2.450507644688097
Validation loss: 2.624103586089447

Epoch: 5| Step: 9
Training loss: 2.296922125300469
Validation loss: 2.5765352761654263

Epoch: 5| Step: 10
Training loss: 2.450134592835719
Validation loss: 2.6027534897520437

Epoch: 5| Step: 11
Training loss: 3.570861507083549
Validation loss: 2.605510518789181

Epoch: 29| Step: 0
Training loss: 1.8804684051399247
Validation loss: 2.567869855792549

Epoch: 5| Step: 1
Training loss: 1.7221869350564634
Validation loss: 2.6030995636758543

Epoch: 5| Step: 2
Training loss: 2.539604809873385
Validation loss: 2.5825976059862783

Epoch: 5| Step: 3
Training loss: 2.5520167958415407
Validation loss: 2.5854039904775235

Epoch: 5| Step: 4
Training loss: 2.919083347930149
Validation loss: 2.5783790463211327

Epoch: 5| Step: 5
Training loss: 3.060671825085797
Validation loss: 2.5689342749800406

Epoch: 5| Step: 6
Training loss: 3.2905433927236047
Validation loss: 2.6127611449557566

Epoch: 5| Step: 7
Training loss: 2.1411124461051676
Validation loss: 2.5877887173147025

Epoch: 5| Step: 8
Training loss: 2.3390399654018985
Validation loss: 2.6015606938414084

Epoch: 5| Step: 9
Training loss: 2.7757628242961223
Validation loss: 2.593528155908768

Epoch: 5| Step: 10
Training loss: 2.2990506825280126
Validation loss: 2.6028247325773273

Epoch: 5| Step: 11
Training loss: 3.0446565817118887
Validation loss: 2.613924681896694

Epoch: 30| Step: 0
Training loss: 2.7238914719806937
Validation loss: 2.5939721659608437

Epoch: 5| Step: 1
Training loss: 2.3854229745129025
Validation loss: 2.585690278128377

Epoch: 5| Step: 2
Training loss: 2.5788970715978556
Validation loss: 2.5970241112099597

Epoch: 5| Step: 3
Training loss: 2.1682626885828293
Validation loss: 2.6403409101568283

Epoch: 5| Step: 4
Training loss: 2.4244129296148564
Validation loss: 2.568492244866181

Epoch: 5| Step: 5
Training loss: 2.3753314539862402
Validation loss: 2.595462850142529

Epoch: 5| Step: 6
Training loss: 2.7460238582133094
Validation loss: 2.611509257396894

Epoch: 5| Step: 7
Training loss: 2.1715080994189924
Validation loss: 2.5709922726454577

Epoch: 5| Step: 8
Training loss: 2.250633574397675
Validation loss: 2.621542288183569

Epoch: 5| Step: 9
Training loss: 3.1171027532927047
Validation loss: 2.6202934093079406

Epoch: 5| Step: 10
Training loss: 2.6326094642478894
Validation loss: 2.6143048557347055

Epoch: 5| Step: 11
Training loss: 3.3882806645578234
Validation loss: 2.6015648712972195

Epoch: 31| Step: 0
Training loss: 2.821861623603488
Validation loss: 2.599783184872108

Epoch: 5| Step: 1
Training loss: 2.770463321235772
Validation loss: 2.5872246515118023

Epoch: 5| Step: 2
Training loss: 1.8250492664114855
Validation loss: 2.5866172450319946

Epoch: 5| Step: 3
Training loss: 1.937704444681478
Validation loss: 2.5859311075890274

Epoch: 5| Step: 4
Training loss: 2.196141748165051
Validation loss: 2.596897249551107

Epoch: 5| Step: 5
Training loss: 2.1126632491919017
Validation loss: 2.579811596441611

Epoch: 5| Step: 6
Training loss: 2.826597528361848
Validation loss: 2.5791771350570087

Epoch: 5| Step: 7
Training loss: 2.7613816979613555
Validation loss: 2.588910547960824

Epoch: 5| Step: 8
Training loss: 3.5522083398444755
Validation loss: 2.580413423091953

Epoch: 5| Step: 9
Training loss: 2.0679169236546247
Validation loss: 2.585872835655018

Epoch: 5| Step: 10
Training loss: 2.8199369650755512
Validation loss: 2.554286808706383

Epoch: 5| Step: 11
Training loss: 1.535802108369958
Validation loss: 2.585414787545906

Epoch: 32| Step: 0
Training loss: 2.803180597917047
Validation loss: 2.5780028304621387

Epoch: 5| Step: 1
Training loss: 2.086436122776705
Validation loss: 2.594801191855862

Epoch: 5| Step: 2
Training loss: 2.194991227395291
Validation loss: 2.642732941349162

Epoch: 5| Step: 3
Training loss: 2.924683552113781
Validation loss: 2.6005122992871312

Epoch: 5| Step: 4
Training loss: 2.6643162044415365
Validation loss: 2.626314734657138

Epoch: 5| Step: 5
Training loss: 2.134590050962701
Validation loss: 2.644256667697229

Epoch: 5| Step: 6
Training loss: 3.2208320772300993
Validation loss: 2.6059523538279823

Epoch: 5| Step: 7
Training loss: 2.381577869180988
Validation loss: 2.6376730993155397

Epoch: 5| Step: 8
Training loss: 2.561500633565812
Validation loss: 2.5923354876344447

Epoch: 5| Step: 9
Training loss: 2.1362634484061402
Validation loss: 2.5790936798395085

Epoch: 5| Step: 10
Training loss: 2.613136549793878
Validation loss: 2.569745172194173

Epoch: 5| Step: 11
Training loss: 1.6450869239868555
Validation loss: 2.5585506328803262

Epoch: 33| Step: 0
Training loss: 2.34548113151252
Validation loss: 2.5624953711863325

Epoch: 5| Step: 1
Training loss: 2.6310957113594298
Validation loss: 2.5767177343787724

Epoch: 5| Step: 2
Training loss: 2.574684019978835
Validation loss: 2.557598225126485

Epoch: 5| Step: 3
Training loss: 3.1557908432360406
Validation loss: 2.5806310399579853

Epoch: 5| Step: 4
Training loss: 2.297650991133528
Validation loss: 2.5782981968511485

Epoch: 5| Step: 5
Training loss: 2.11329027551215
Validation loss: 2.592194075189966

Epoch: 5| Step: 6
Training loss: 2.3884572691438044
Validation loss: 2.581590750511647

Epoch: 5| Step: 7
Training loss: 2.6588799415905795
Validation loss: 2.5948019805196845

Epoch: 5| Step: 8
Training loss: 2.606798373193425
Validation loss: 2.579079121987107

Epoch: 5| Step: 9
Training loss: 2.642350214499754
Validation loss: 2.594211797700514

Epoch: 5| Step: 10
Training loss: 1.9960309819395157
Validation loss: 2.5847757001932883

Epoch: 5| Step: 11
Training loss: 2.8587272202118337
Validation loss: 2.59879525054562

Epoch: 34| Step: 0
Training loss: 2.1664093182635256
Validation loss: 2.5547783745051253

Epoch: 5| Step: 1
Training loss: 2.476310356132469
Validation loss: 2.5579334717458617

Epoch: 5| Step: 2
Training loss: 3.1736627060257447
Validation loss: 2.589966438805078

Epoch: 5| Step: 3
Training loss: 3.026023212492585
Validation loss: 2.5562440541795945

Epoch: 5| Step: 4
Training loss: 2.7423154795634153
Validation loss: 2.5650080641867006

Epoch: 5| Step: 5
Training loss: 2.29638272154726
Validation loss: 2.5862000592367913

Epoch: 5| Step: 6
Training loss: 2.4547826912413777
Validation loss: 2.6098454026649764

Epoch: 5| Step: 7
Training loss: 2.436450732413498
Validation loss: 2.574478726724943

Epoch: 5| Step: 8
Training loss: 2.686315053486719
Validation loss: 2.5905303351849653

Epoch: 5| Step: 9
Training loss: 2.1810125883037346
Validation loss: 2.558888561551558

Epoch: 5| Step: 10
Training loss: 1.8021050674215666
Validation loss: 2.565960737525889

Epoch: 5| Step: 11
Training loss: 2.5759555821291436
Validation loss: 2.5828983545697777

Epoch: 35| Step: 0
Training loss: 2.4609226771316983
Validation loss: 2.586097992740725

Epoch: 5| Step: 1
Training loss: 2.5294632433520348
Validation loss: 2.5591638895641013

Epoch: 5| Step: 2
Training loss: 2.7570375212730194
Validation loss: 2.578254734975101

Epoch: 5| Step: 3
Training loss: 3.270332703070061
Validation loss: 2.559982268593645

Epoch: 5| Step: 4
Training loss: 2.2560371361915763
Validation loss: 2.599847764974751

Epoch: 5| Step: 5
Training loss: 2.156544540854525
Validation loss: 2.583097882974933

Epoch: 5| Step: 6
Training loss: 2.1621291134699168
Validation loss: 2.528555990574933

Epoch: 5| Step: 7
Training loss: 2.583167306630643
Validation loss: 2.5596372966013643

Epoch: 5| Step: 8
Training loss: 2.294502849877176
Validation loss: 2.6060855484268544

Epoch: 5| Step: 9
Training loss: 2.78868036296903
Validation loss: 2.558204357228274

Epoch: 5| Step: 10
Training loss: 2.3098523215776283
Validation loss: 2.5745268016567695

Epoch: 5| Step: 11
Training loss: 3.624730724988315
Validation loss: 2.5608279658057627

Epoch: 36| Step: 0
Training loss: 2.270698811690865
Validation loss: 2.5727197356798612

Epoch: 5| Step: 1
Training loss: 2.6566896860073888
Validation loss: 2.580664314715195

Epoch: 5| Step: 2
Training loss: 2.2569934454921188
Validation loss: 2.5779232138840427

Epoch: 5| Step: 3
Training loss: 3.2561174186323347
Validation loss: 2.589376323974919

Epoch: 5| Step: 4
Training loss: 2.559193315217141
Validation loss: 2.5605783855828133

Epoch: 5| Step: 5
Training loss: 2.2986583403940304
Validation loss: 2.52280570664805

Epoch: 5| Step: 6
Training loss: 3.0358782171016454
Validation loss: 2.57253724104923

Epoch: 5| Step: 7
Training loss: 2.7186433617735934
Validation loss: 2.5731312177112105

Epoch: 5| Step: 8
Training loss: 2.2387207025925115
Validation loss: 2.57715230375084

Epoch: 5| Step: 9
Training loss: 2.0174029884507605
Validation loss: 2.5629899595515178

Epoch: 5| Step: 10
Training loss: 2.2790001003437763
Validation loss: 2.5383465075281437

Epoch: 5| Step: 11
Training loss: 1.5913123393826736
Validation loss: 2.5612743982332398

Epoch: 37| Step: 0
Training loss: 2.444515598109248
Validation loss: 2.570302254019648

Epoch: 5| Step: 1
Training loss: 2.571900036899702
Validation loss: 2.5661824446685295

Epoch: 5| Step: 2
Training loss: 2.0391781361263446
Validation loss: 2.6055559356301017

Epoch: 5| Step: 3
Training loss: 2.2606174245068824
Validation loss: 2.5681386835893107

Epoch: 5| Step: 4
Training loss: 1.8980384061804596
Validation loss: 2.535504960273109

Epoch: 5| Step: 5
Training loss: 2.437818653112127
Validation loss: 2.5867661438285774

Epoch: 5| Step: 6
Training loss: 2.114814695532838
Validation loss: 2.611788929445112

Epoch: 5| Step: 7
Training loss: 2.6437736564281256
Validation loss: 2.596152120143139

Epoch: 5| Step: 8
Training loss: 2.7025975942148888
Validation loss: 2.631846638447198

Epoch: 5| Step: 9
Training loss: 3.322604189603246
Validation loss: 2.5855315774366217

Epoch: 5| Step: 10
Training loss: 2.850982021664466
Validation loss: 2.5965972080069575

Epoch: 5| Step: 11
Training loss: 2.0181447920031053
Validation loss: 2.5954293593911175

Epoch: 38| Step: 0
Training loss: 2.3622457458283384
Validation loss: 2.553098380713833

Epoch: 5| Step: 1
Training loss: 2.3380650046573592
Validation loss: 2.608761195554961

Epoch: 5| Step: 2
Training loss: 2.5850476350213722
Validation loss: 2.5461922024793524

Epoch: 5| Step: 3
Training loss: 2.0362249632549605
Validation loss: 2.5545467878469528

Epoch: 5| Step: 4
Training loss: 2.6643570096730462
Validation loss: 2.5853736124339752

Epoch: 5| Step: 5
Training loss: 2.351812507798693
Validation loss: 2.5746356200142873

Epoch: 5| Step: 6
Training loss: 3.4545438449344807
Validation loss: 2.624737154955756

Epoch: 5| Step: 7
Training loss: 3.044899324403346
Validation loss: 2.6150463626391285

Epoch: 5| Step: 8
Training loss: 1.5560854660136962
Validation loss: 2.626468905949115

Epoch: 5| Step: 9
Training loss: 2.297364578489937
Validation loss: 2.578629045631489

Epoch: 5| Step: 10
Training loss: 2.1283904684468817
Validation loss: 2.545027446923585

Epoch: 5| Step: 11
Training loss: 2.4521079901333627
Validation loss: 2.552918952586817

Epoch: 39| Step: 0
Training loss: 2.4145067911026894
Validation loss: 2.606939637431439

Epoch: 5| Step: 1
Training loss: 2.659572005006989
Validation loss: 2.583952261758114

Epoch: 5| Step: 2
Training loss: 2.224140442681341
Validation loss: 2.5419439388644216

Epoch: 5| Step: 3
Training loss: 1.7682950920958025
Validation loss: 2.5673037720328566

Epoch: 5| Step: 4
Training loss: 2.294325055373976
Validation loss: 2.578102466215049

Epoch: 5| Step: 5
Training loss: 2.9234029273430893
Validation loss: 2.5511329295504783

Epoch: 5| Step: 6
Training loss: 2.5951649127222827
Validation loss: 2.5479006895956027

Epoch: 5| Step: 7
Training loss: 3.265057674208185
Validation loss: 2.573255404028831

Epoch: 5| Step: 8
Training loss: 2.395338809073553
Validation loss: 2.6614861098082363

Epoch: 5| Step: 9
Training loss: 2.3133895812584817
Validation loss: 2.5759061821431333

Epoch: 5| Step: 10
Training loss: 2.515417528778412
Validation loss: 2.6196166650605184

Epoch: 5| Step: 11
Training loss: 2.0787536129257727
Validation loss: 2.5647575776823333

Epoch: 40| Step: 0
Training loss: 2.3149267299583554
Validation loss: 2.6010564172459154

Epoch: 5| Step: 1
Training loss: 2.7548004213796142
Validation loss: 2.5518596038584374

Epoch: 5| Step: 2
Training loss: 2.1305413642597455
Validation loss: 2.5246581204935135

Epoch: 5| Step: 3
Training loss: 2.627369401700481
Validation loss: 2.6256336325400853

Epoch: 5| Step: 4
Training loss: 2.153256314596025
Validation loss: 2.5609148480303987

Epoch: 5| Step: 5
Training loss: 2.670972526680357
Validation loss: 2.5450606133875477

Epoch: 5| Step: 6
Training loss: 2.347983643716904
Validation loss: 2.635414712827257

Epoch: 5| Step: 7
Training loss: 3.186952880578077
Validation loss: 2.57893009138176

Epoch: 5| Step: 8
Training loss: 2.751235424316841
Validation loss: 2.5813981134564177

Epoch: 5| Step: 9
Training loss: 1.7682617214466436
Validation loss: 2.634896872955638

Epoch: 5| Step: 10
Training loss: 2.288382367328577
Validation loss: 2.5841002799922292

Epoch: 5| Step: 11
Training loss: 3.0268841006898146
Validation loss: 2.630682932018756

Epoch: 41| Step: 0
Training loss: 2.869875445703618
Validation loss: 2.5749168394912907

Epoch: 5| Step: 1
Training loss: 2.017868095011353
Validation loss: 2.5629348037091204

Epoch: 5| Step: 2
Training loss: 2.4266411920230393
Validation loss: 2.506978578649197

Epoch: 5| Step: 3
Training loss: 2.1888479167096397
Validation loss: 2.5680558173933274

Epoch: 5| Step: 4
Training loss: 2.587370783578633
Validation loss: 2.5658873290347746

Epoch: 5| Step: 5
Training loss: 2.0837460554116483
Validation loss: 2.5408830346659346

Epoch: 5| Step: 6
Training loss: 2.8467612619637053
Validation loss: 2.632354798419722

Epoch: 5| Step: 7
Training loss: 2.3790515673621826
Validation loss: 2.59335856950252

Epoch: 5| Step: 8
Training loss: 2.7402916247694766
Validation loss: 2.5416655358067066

Epoch: 5| Step: 9
Training loss: 2.4577774346063768
Validation loss: 2.5427033090027384

Epoch: 5| Step: 10
Training loss: 2.261765764502178
Validation loss: 2.5280568798587146

Epoch: 5| Step: 11
Training loss: 2.574600770241699
Validation loss: 2.551813042528768

Epoch: 42| Step: 0
Training loss: 2.632476332395982
Validation loss: 2.5567086183789827

Epoch: 5| Step: 1
Training loss: 1.9486938259012658
Validation loss: 2.5761238423367594

Epoch: 5| Step: 2
Training loss: 2.481497675835995
Validation loss: 2.5651801638632805

Epoch: 5| Step: 3
Training loss: 2.2056917429830207
Validation loss: 2.5512142349407747

Epoch: 5| Step: 4
Training loss: 2.382447161573925
Validation loss: 2.5681081399977668

Epoch: 5| Step: 5
Training loss: 2.1020705732771776
Validation loss: 2.5347989403133373

Epoch: 5| Step: 6
Training loss: 2.69027229859514
Validation loss: 2.514500542399475

Epoch: 5| Step: 7
Training loss: 2.1857595877133336
Validation loss: 2.602911174764916

Epoch: 5| Step: 8
Training loss: 2.6350330078547652
Validation loss: 2.5697638245862735

Epoch: 5| Step: 9
Training loss: 2.9853125891919574
Validation loss: 2.5597946571284407

Epoch: 5| Step: 10
Training loss: 2.969084389576483
Validation loss: 2.534864831132255

Epoch: 5| Step: 11
Training loss: 0.9828912360790789
Validation loss: 2.5909543041708343

Epoch: 43| Step: 0
Training loss: 2.4593470686958723
Validation loss: 2.572195447516233

Epoch: 5| Step: 1
Training loss: 2.2680279846550544
Validation loss: 2.6234738818264978

Epoch: 5| Step: 2
Training loss: 2.234655402668778
Validation loss: 2.594932527877714

Epoch: 5| Step: 3
Training loss: 2.45273329407774
Validation loss: 2.5757117025519936

Epoch: 5| Step: 4
Training loss: 2.0939235330663584
Validation loss: 2.6326065926256432

Epoch: 5| Step: 5
Training loss: 2.156149156948962
Validation loss: 2.6199448934430847

Epoch: 5| Step: 6
Training loss: 2.8219021784254057
Validation loss: 2.6270214728973613

Epoch: 5| Step: 7
Training loss: 2.5275326972151997
Validation loss: 2.7120130605809813

Epoch: 5| Step: 8
Training loss: 2.316267707374111
Validation loss: 2.680136832924135

Epoch: 5| Step: 9
Training loss: 2.7780945268811257
Validation loss: 2.575708034694712

Epoch: 5| Step: 10
Training loss: 3.228132184769352
Validation loss: 2.6582975125565103

Epoch: 5| Step: 11
Training loss: 2.0368642833295527
Validation loss: 2.5687985546352627

Epoch: 44| Step: 0
Training loss: 1.8941374379274976
Validation loss: 2.5713317264852367

Epoch: 5| Step: 1
Training loss: 2.38885652042116
Validation loss: 2.5975030304123425

Epoch: 5| Step: 2
Training loss: 2.632275082216802
Validation loss: 2.566835364664314

Epoch: 5| Step: 3
Training loss: 2.39829962020341
Validation loss: 2.6140149563853043

Epoch: 5| Step: 4
Training loss: 2.2743350220406113
Validation loss: 2.5553447605065482

Epoch: 5| Step: 5
Training loss: 3.5756538220053935
Validation loss: 2.5778916397830303

Epoch: 5| Step: 6
Training loss: 2.477008286075339
Validation loss: 2.530710417924105

Epoch: 5| Step: 7
Training loss: 1.920886087693047
Validation loss: 2.5548470823508747

Epoch: 5| Step: 8
Training loss: 2.778838151296303
Validation loss: 2.5207943020050423

Epoch: 5| Step: 9
Training loss: 2.210125561767769
Validation loss: 2.555110004029638

Epoch: 5| Step: 10
Training loss: 2.073286116247398
Validation loss: 2.5684804696857975

Epoch: 5| Step: 11
Training loss: 1.9871763145730665
Validation loss: 2.554587164881001

Epoch: 45| Step: 0
Training loss: 3.077189036942578
Validation loss: 2.5271807799350774

Epoch: 5| Step: 1
Training loss: 3.1405565244886615
Validation loss: 2.5252549050649837

Epoch: 5| Step: 2
Training loss: 2.4847693939972006
Validation loss: 2.5176100273863278

Epoch: 5| Step: 3
Training loss: 2.1889109829316338
Validation loss: 2.5449071938868775

Epoch: 5| Step: 4
Training loss: 2.005347018379496
Validation loss: 2.5765219723591044

Epoch: 5| Step: 5
Training loss: 2.583838403201691
Validation loss: 2.6089378074438248

Epoch: 5| Step: 6
Training loss: 2.735664891768532
Validation loss: 2.5538813206547135

Epoch: 5| Step: 7
Training loss: 2.5330304136201094
Validation loss: 2.6068759418120933

Epoch: 5| Step: 8
Training loss: 1.5258033575047294
Validation loss: 2.6295350764785086

Epoch: 5| Step: 9
Training loss: 2.925261304872135
Validation loss: 2.5566514036584245

Epoch: 5| Step: 10
Training loss: 1.650554147779156
Validation loss: 2.574438360684317

Epoch: 5| Step: 11
Training loss: 1.2152359504162231
Validation loss: 2.5588847997006705

Epoch: 46| Step: 0
Training loss: 2.431506785190912
Validation loss: 2.59847198145367

Epoch: 5| Step: 1
Training loss: 2.4561268122797055
Validation loss: 2.474047538086017

Epoch: 5| Step: 2
Training loss: 2.7805111364406736
Validation loss: 2.574589889237325

Epoch: 5| Step: 3
Training loss: 1.8909189295262692
Validation loss: 2.580435474722866

Epoch: 5| Step: 4
Training loss: 2.93501160107583
Validation loss: 2.5786851794536765

Epoch: 5| Step: 5
Training loss: 1.728294504968566
Validation loss: 2.603865202938744

Epoch: 5| Step: 6
Training loss: 2.199013844459047
Validation loss: 2.528483138398005

Epoch: 5| Step: 7
Training loss: 2.2556507360903852
Validation loss: 2.5758241385492533

Epoch: 5| Step: 8
Training loss: 3.020330996784816
Validation loss: 2.5776641433797525

Epoch: 5| Step: 9
Training loss: 2.200780391997636
Validation loss: 2.607866795521084

Epoch: 5| Step: 10
Training loss: 2.5463020288679026
Validation loss: 2.501793261941555

Epoch: 5| Step: 11
Training loss: 2.7028432710280668
Validation loss: 2.511740866841049

Epoch: 47| Step: 0
Training loss: 2.6754570757666847
Validation loss: 2.531502970075739

Epoch: 5| Step: 1
Training loss: 2.214929542023662
Validation loss: 2.529529583411807

Epoch: 5| Step: 2
Training loss: 2.1875634320462742
Validation loss: 2.5301062861081665

Epoch: 5| Step: 3
Training loss: 2.3764581721353086
Validation loss: 2.538320078757786

Epoch: 5| Step: 4
Training loss: 2.450150940585668
Validation loss: 2.5480177778693522

Epoch: 5| Step: 5
Training loss: 2.2598953935163086
Validation loss: 2.586836317734289

Epoch: 5| Step: 6
Training loss: 2.8517073085020943
Validation loss: 2.55243019290011

Epoch: 5| Step: 7
Training loss: 2.6403860853110848
Validation loss: 2.5706358361288255

Epoch: 5| Step: 8
Training loss: 2.7580460835812217
Validation loss: 2.5893020446932606

Epoch: 5| Step: 9
Training loss: 2.015396933257562
Validation loss: 2.5318388940676724

Epoch: 5| Step: 10
Training loss: 2.517169170443138
Validation loss: 2.59691297179737

Epoch: 5| Step: 11
Training loss: 1.5772084511124387
Validation loss: 2.5594545076446713

Epoch: 48| Step: 0
Training loss: 2.376493787305124
Validation loss: 2.5123977316892403

Epoch: 5| Step: 1
Training loss: 2.254443337695232
Validation loss: 2.5625605672951193

Epoch: 5| Step: 2
Training loss: 3.0739308553251994
Validation loss: 2.571076253566598

Epoch: 5| Step: 3
Training loss: 2.362816227331149
Validation loss: 2.5240002054941364

Epoch: 5| Step: 4
Training loss: 2.5643417438802376
Validation loss: 2.55590152961272

Epoch: 5| Step: 5
Training loss: 1.8551500548673197
Validation loss: 2.5872479985635737

Epoch: 5| Step: 6
Training loss: 2.849057788031162
Validation loss: 2.555684512421814

Epoch: 5| Step: 7
Training loss: 2.79096001368779
Validation loss: 2.585407097040787

Epoch: 5| Step: 8
Training loss: 2.035351178284797
Validation loss: 2.558576914802279

Epoch: 5| Step: 9
Training loss: 2.4318600475172185
Validation loss: 2.517782766756773

Epoch: 5| Step: 10
Training loss: 2.2442958369750468
Validation loss: 2.5682707448541318

Epoch: 5| Step: 11
Training loss: 2.795009310438996
Validation loss: 2.5602683374839423

Epoch: 49| Step: 0
Training loss: 2.6949574996909287
Validation loss: 2.556851748653953

Epoch: 5| Step: 1
Training loss: 2.4202342720761925
Validation loss: 2.553196984548241

Epoch: 5| Step: 2
Training loss: 2.3737921403998232
Validation loss: 2.605178222014486

Epoch: 5| Step: 3
Training loss: 2.571306679879354
Validation loss: 2.594693896885204

Epoch: 5| Step: 4
Training loss: 2.1186256169631044
Validation loss: 2.523890664241393

Epoch: 5| Step: 5
Training loss: 3.0745494233292363
Validation loss: 2.531056557630187

Epoch: 5| Step: 6
Training loss: 2.2154177505560346
Validation loss: 2.5580583861614468

Epoch: 5| Step: 7
Training loss: 2.541957671802742
Validation loss: 2.545549055347009

Epoch: 5| Step: 8
Training loss: 1.9078012626998087
Validation loss: 2.514001484334584

Epoch: 5| Step: 9
Training loss: 2.5517197849551185
Validation loss: 2.559227276281745

Epoch: 5| Step: 10
Training loss: 2.4192287631666245
Validation loss: 2.5608933575906425

Epoch: 5| Step: 11
Training loss: 2.246535388816376
Validation loss: 2.5489156968625246

Epoch: 50| Step: 0
Training loss: 2.240028325310499
Validation loss: 2.548971315846329

Epoch: 5| Step: 1
Training loss: 2.714491303982791
Validation loss: 2.5474578701418955

Epoch: 5| Step: 2
Training loss: 2.3129062811191634
Validation loss: 2.5748936950628623

Epoch: 5| Step: 3
Training loss: 2.3019749082230194
Validation loss: 2.5722303337393124

Epoch: 5| Step: 4
Training loss: 2.302544894200139
Validation loss: 2.5918770925971653

Epoch: 5| Step: 5
Training loss: 2.722101185069242
Validation loss: 2.563439231964051

Epoch: 5| Step: 6
Training loss: 2.1496030662869674
Validation loss: 2.56062056073881

Epoch: 5| Step: 7
Training loss: 1.8964644488968323
Validation loss: 2.5205860581508506

Epoch: 5| Step: 8
Training loss: 2.109613023679977
Validation loss: 2.5478172236573102

Epoch: 5| Step: 9
Training loss: 3.3533048924579205
Validation loss: 2.568637851175836

Epoch: 5| Step: 10
Training loss: 2.157605284313312
Validation loss: 2.547314508424668

Epoch: 5| Step: 11
Training loss: 2.9800537140376857
Validation loss: 2.5599924976703363

Epoch: 51| Step: 0
Training loss: 2.3394849498938926
Validation loss: 2.5160979148256835

Epoch: 5| Step: 1
Training loss: 2.133415164967494
Validation loss: 2.571678339815708

Epoch: 5| Step: 2
Training loss: 2.8909987749264054
Validation loss: 2.5387733099158605

Epoch: 5| Step: 3
Training loss: 2.7082430506599207
Validation loss: 2.5335466734772365

Epoch: 5| Step: 4
Training loss: 2.7512375907843407
Validation loss: 2.5581716135852726

Epoch: 5| Step: 5
Training loss: 1.6090248245448504
Validation loss: 2.534896960760184

Epoch: 5| Step: 6
Training loss: 2.130279825840506
Validation loss: 2.5654453392795324

Epoch: 5| Step: 7
Training loss: 2.4595724528250433
Validation loss: 2.5039764450001787

Epoch: 5| Step: 8
Training loss: 2.3017990374039496
Validation loss: 2.4815479363932966

Epoch: 5| Step: 9
Training loss: 2.3991117741129737
Validation loss: 2.562636263255989

Epoch: 5| Step: 10
Training loss: 2.6417186210489243
Validation loss: 2.5047790704155726

Epoch: 5| Step: 11
Training loss: 2.2633448208988827
Validation loss: 2.5411834114070775

Epoch: 52| Step: 0
Training loss: 1.5463627439085212
Validation loss: 2.483776000324681

Epoch: 5| Step: 1
Training loss: 3.2873468341610756
Validation loss: 2.529670532590635

Epoch: 5| Step: 2
Training loss: 3.12276531427
Validation loss: 2.491476282343828

Epoch: 5| Step: 3
Training loss: 2.2873333854656757
Validation loss: 2.5729046884378897

Epoch: 5| Step: 4
Training loss: 2.5516601730685973
Validation loss: 2.5255841866700717

Epoch: 5| Step: 5
Training loss: 2.243336665513321
Validation loss: 2.5952344997136536

Epoch: 5| Step: 6
Training loss: 2.638374950042954
Validation loss: 2.58508787382713

Epoch: 5| Step: 7
Training loss: 2.3126061904857362
Validation loss: 2.545146632620038

Epoch: 5| Step: 8
Training loss: 2.1837244421211737
Validation loss: 2.5419657966337086

Epoch: 5| Step: 9
Training loss: 2.041277854902244
Validation loss: 2.573025127137714

Epoch: 5| Step: 10
Training loss: 2.0772204043641795
Validation loss: 2.5854292578522524

Epoch: 5| Step: 11
Training loss: 1.6848286571603202
Validation loss: 2.525708423669397

Epoch: 53| Step: 0
Training loss: 1.6965925596324736
Validation loss: 2.586931788517113

Epoch: 5| Step: 1
Training loss: 2.775971794084063
Validation loss: 2.5991483948854106

Epoch: 5| Step: 2
Training loss: 1.9910582090497357
Validation loss: 2.5446839649541757

Epoch: 5| Step: 3
Training loss: 1.8261265713381203
Validation loss: 2.557334951330965

Epoch: 5| Step: 4
Training loss: 2.542657929863378
Validation loss: 2.595561735284057

Epoch: 5| Step: 5
Training loss: 2.894294512870777
Validation loss: 2.5585343875744706

Epoch: 5| Step: 6
Training loss: 2.2238574276857532
Validation loss: 2.565194709586956

Epoch: 5| Step: 7
Training loss: 2.223191986147235
Validation loss: 2.5101134062980326

Epoch: 5| Step: 8
Training loss: 2.4814390672577353
Validation loss: 2.556019473698657

Epoch: 5| Step: 9
Training loss: 2.4747086093338018
Validation loss: 2.5336382043016292

Epoch: 5| Step: 10
Training loss: 3.0858920709670365
Validation loss: 2.5694536554039713

Epoch: 5| Step: 11
Training loss: 2.150407810125189
Validation loss: 2.517978440077795

Epoch: 54| Step: 0
Training loss: 2.4544269969882833
Validation loss: 2.533849272505976

Epoch: 5| Step: 1
Training loss: 2.3466066372122
Validation loss: 2.5487467123112997

Epoch: 5| Step: 2
Training loss: 2.3182711371555857
Validation loss: 2.5445545172435224

Epoch: 5| Step: 3
Training loss: 2.671406933570815
Validation loss: 2.5759542400756077

Epoch: 5| Step: 4
Training loss: 2.4746134215263877
Validation loss: 2.5629709439046455

Epoch: 5| Step: 5
Training loss: 2.108921256536614
Validation loss: 2.566097273824276

Epoch: 5| Step: 6
Training loss: 2.1958652221371655
Validation loss: 2.5793214969248397

Epoch: 5| Step: 7
Training loss: 2.3885550918789624
Validation loss: 2.5672857634517183

Epoch: 5| Step: 8
Training loss: 2.1432110834730054
Validation loss: 2.527521531044462

Epoch: 5| Step: 9
Training loss: 2.5075054040091826
Validation loss: 2.5500949016065273

Epoch: 5| Step: 10
Training loss: 2.8919242619559817
Validation loss: 2.5890274103795377

Epoch: 5| Step: 11
Training loss: 1.9894577173119734
Validation loss: 2.557963598950368

Epoch: 55| Step: 0
Training loss: 2.562448826720836
Validation loss: 2.5404577559149892

Epoch: 5| Step: 1
Training loss: 2.518562639334093
Validation loss: 2.5548341885915193

Epoch: 5| Step: 2
Training loss: 1.91690189189723
Validation loss: 2.571063815985556

Epoch: 5| Step: 3
Training loss: 2.7278446363692446
Validation loss: 2.55078327515752

Epoch: 5| Step: 4
Training loss: 2.363758789239819
Validation loss: 2.5792250087920388

Epoch: 5| Step: 5
Training loss: 2.090917578781752
Validation loss: 2.58453071567942

Epoch: 5| Step: 6
Training loss: 2.68920152605142
Validation loss: 2.5745187602907715

Epoch: 5| Step: 7
Training loss: 2.7334357692163085
Validation loss: 2.528473551912024

Epoch: 5| Step: 8
Training loss: 2.6763779914536
Validation loss: 2.5816283880794058

Epoch: 5| Step: 9
Training loss: 1.795606082188568
Validation loss: 2.555162134904977

Epoch: 5| Step: 10
Training loss: 2.4817446813709876
Validation loss: 2.521885192674021

Epoch: 5| Step: 11
Training loss: 2.0525428399506707
Validation loss: 2.5315952026392154

Epoch: 56| Step: 0
Training loss: 2.3632322195972777
Validation loss: 2.5196995405429647

Epoch: 5| Step: 1
Training loss: 2.4564705164883347
Validation loss: 2.5274187810924347

Epoch: 5| Step: 2
Training loss: 2.9808920463458204
Validation loss: 2.553150776390963

Epoch: 5| Step: 3
Training loss: 2.0063178885789106
Validation loss: 2.511147176473951

Epoch: 5| Step: 4
Training loss: 1.5505539273476299
Validation loss: 2.5068689355782414

Epoch: 5| Step: 5
Training loss: 2.0465313572013257
Validation loss: 2.504874658602307

Epoch: 5| Step: 6
Training loss: 2.849177620007493
Validation loss: 2.606739996093503

Epoch: 5| Step: 7
Training loss: 2.381314166148169
Validation loss: 2.5993418337335727

Epoch: 5| Step: 8
Training loss: 2.4400345756082173
Validation loss: 2.549215438860887

Epoch: 5| Step: 9
Training loss: 2.9442536654135747
Validation loss: 2.547920289482812

Epoch: 5| Step: 10
Training loss: 2.214369842583585
Validation loss: 2.5493399543407715

Epoch: 5| Step: 11
Training loss: 2.268099045698272
Validation loss: 2.4957330768511636

Epoch: 57| Step: 0
Training loss: 2.304599980131131
Validation loss: 2.5154516859356653

Epoch: 5| Step: 1
Training loss: 2.8698551750194534
Validation loss: 2.6033766838940497

Epoch: 5| Step: 2
Training loss: 1.9445794497654745
Validation loss: 2.5439959949953215

Epoch: 5| Step: 3
Training loss: 1.9872359430293682
Validation loss: 2.5637638572889987

Epoch: 5| Step: 4
Training loss: 2.6302333616570377
Validation loss: 2.5595317722695183

Epoch: 5| Step: 5
Training loss: 2.3498571555369536
Validation loss: 2.6047998014732547

Epoch: 5| Step: 6
Training loss: 2.2466899047502507
Validation loss: 2.649892510477358

Epoch: 5| Step: 7
Training loss: 1.6511114769586221
Validation loss: 2.5823304411293058

Epoch: 5| Step: 8
Training loss: 3.102538601422298
Validation loss: 2.5832819177269104

Epoch: 5| Step: 9
Training loss: 2.091796191132591
Validation loss: 2.596661098375908

Epoch: 5| Step: 10
Training loss: 2.8243970379409635
Validation loss: 2.5979942771088975

Epoch: 5| Step: 11
Training loss: 1.9577446587111809
Validation loss: 2.5763894471981637

Epoch: 58| Step: 0
Training loss: 2.6107391629087737
Validation loss: 2.5514528832266175

Epoch: 5| Step: 1
Training loss: 2.7975132389795094
Validation loss: 2.590980276572802

Epoch: 5| Step: 2
Training loss: 2.2666184976545813
Validation loss: 2.567981992973097

Epoch: 5| Step: 3
Training loss: 3.024496361287432
Validation loss: 2.524016564836645

Epoch: 5| Step: 4
Training loss: 2.1703593502384533
Validation loss: 2.531039819900158

Epoch: 5| Step: 5
Training loss: 2.139332847703732
Validation loss: 2.5213758985537256

Epoch: 5| Step: 6
Training loss: 2.1034018256415736
Validation loss: 2.5548341302661632

Epoch: 5| Step: 7
Training loss: 2.156415628899723
Validation loss: 2.498341025819275

Epoch: 5| Step: 8
Training loss: 2.3291783350161475
Validation loss: 2.5568216957684653

Epoch: 5| Step: 9
Training loss: 2.7123848956600147
Validation loss: 2.5368310052728904

Epoch: 5| Step: 10
Training loss: 1.933418651320612
Validation loss: 2.514600699258639

Epoch: 5| Step: 11
Training loss: 1.7200295280538993
Validation loss: 2.529877368979359

Epoch: 59| Step: 0
Training loss: 2.527321581028399
Validation loss: 2.5522317389072433

Epoch: 5| Step: 1
Training loss: 2.0778374723992594
Validation loss: 2.5495809132759373

Epoch: 5| Step: 2
Training loss: 1.8246271954537798
Validation loss: 2.60050700468154

Epoch: 5| Step: 3
Training loss: 2.146797913967858
Validation loss: 2.5636640750181816

Epoch: 5| Step: 4
Training loss: 2.0021600979138063
Validation loss: 2.5362403483525995

Epoch: 5| Step: 5
Training loss: 2.450224114891493
Validation loss: 2.5229945980061568

Epoch: 5| Step: 6
Training loss: 2.5874675361697625
Validation loss: 2.5982884988062955

Epoch: 5| Step: 7
Training loss: 2.886804809113427
Validation loss: 2.6060561166697584

Epoch: 5| Step: 8
Training loss: 2.626325272757351
Validation loss: 2.5363736866346036

Epoch: 5| Step: 9
Training loss: 2.0606862965643025
Validation loss: 2.496310507725987

Epoch: 5| Step: 10
Training loss: 2.6363803674651285
Validation loss: 2.570031070471935

Epoch: 5| Step: 11
Training loss: 3.1155934476641733
Validation loss: 2.570838912966056

Epoch: 60| Step: 0
Training loss: 3.276130388005622
Validation loss: 2.5522066294152217

Epoch: 5| Step: 1
Training loss: 2.4720842082424297
Validation loss: 2.5067644038468972

Epoch: 5| Step: 2
Training loss: 2.428808807744829
Validation loss: 2.5225427062707717

Epoch: 5| Step: 3
Training loss: 2.4570539561376306
Validation loss: 2.517969736794801

Epoch: 5| Step: 4
Training loss: 1.9633004591002485
Validation loss: 2.5627642627076423

Epoch: 5| Step: 5
Training loss: 2.390045893719297
Validation loss: 2.520713895274902

Epoch: 5| Step: 6
Training loss: 2.3223416995332253
Validation loss: 2.4862347925193187

Epoch: 5| Step: 7
Training loss: 2.2477690975008824
Validation loss: 2.5293351021999104

Epoch: 5| Step: 8
Training loss: 1.8802530454213562
Validation loss: 2.503342631003599

Epoch: 5| Step: 9
Training loss: 2.089509684163929
Validation loss: 2.495669213908109

Epoch: 5| Step: 10
Training loss: 2.764753991163198
Validation loss: 2.5247219348046026

Epoch: 5| Step: 11
Training loss: 2.359554966006039
Validation loss: 2.5229724931932287

Epoch: 61| Step: 0
Training loss: 2.574116220009779
Validation loss: 2.4897141694892944

Epoch: 5| Step: 1
Training loss: 2.236787573914401
Validation loss: 2.5329140581796423

Epoch: 5| Step: 2
Training loss: 1.7794372972168935
Validation loss: 2.4917843850394825

Epoch: 5| Step: 3
Training loss: 3.023828919773665
Validation loss: 2.54513496605636

Epoch: 5| Step: 4
Training loss: 2.596058932359904
Validation loss: 2.5627124550988882

Epoch: 5| Step: 5
Training loss: 2.1621277902261724
Validation loss: 2.537158592633598

Epoch: 5| Step: 6
Training loss: 2.0773217506004165
Validation loss: 2.521766128774112

Epoch: 5| Step: 7
Training loss: 2.3500743732452247
Validation loss: 2.524055200644707

Epoch: 5| Step: 8
Training loss: 1.981184188760581
Validation loss: 2.569793146259535

Epoch: 5| Step: 9
Training loss: 2.820101236054816
Validation loss: 2.665610880514348

Epoch: 5| Step: 10
Training loss: 2.431216332366753
Validation loss: 2.616495566686491

Epoch: 5| Step: 11
Training loss: 3.405623912142536
Validation loss: 2.523936990880424

Epoch: 62| Step: 0
Training loss: 2.1425168107752026
Validation loss: 2.5584232923884263

Epoch: 5| Step: 1
Training loss: 2.3611528380453
Validation loss: 2.584246725199336

Epoch: 5| Step: 2
Training loss: 2.1306716178881073
Validation loss: 2.5124795808484293

Epoch: 5| Step: 3
Training loss: 2.586359087642455
Validation loss: 2.5268377498183603

Epoch: 5| Step: 4
Training loss: 1.9444100611538035
Validation loss: 2.4931039430626862

Epoch: 5| Step: 5
Training loss: 2.592920377486431
Validation loss: 2.4969331129024943

Epoch: 5| Step: 6
Training loss: 2.415194644073684
Validation loss: 2.5662904478100996

Epoch: 5| Step: 7
Training loss: 2.795433482776583
Validation loss: 2.554347895487862

Epoch: 5| Step: 8
Training loss: 2.444122122215505
Validation loss: 2.506047230649148

Epoch: 5| Step: 9
Training loss: 2.390452958442625
Validation loss: 2.5184880622925183

Epoch: 5| Step: 10
Training loss: 2.096857981037142
Validation loss: 2.5512631629487155

Epoch: 5| Step: 11
Training loss: 3.381433642013665
Validation loss: 2.475192568573361

Epoch: 63| Step: 0
Training loss: 2.2032875379842327
Validation loss: 2.5319613528586573

Epoch: 5| Step: 1
Training loss: 2.685163058510107
Validation loss: 2.5566726830213584

Epoch: 5| Step: 2
Training loss: 2.528878502138183
Validation loss: 2.5226871882770676

Epoch: 5| Step: 3
Training loss: 2.471867970530164
Validation loss: 2.5233813890767527

Epoch: 5| Step: 4
Training loss: 2.4012610500067546
Validation loss: 2.5346865108592938

Epoch: 5| Step: 5
Training loss: 2.233350932588079
Validation loss: 2.5291023130467556

Epoch: 5| Step: 6
Training loss: 2.115111963000501
Validation loss: 2.561295563556438

Epoch: 5| Step: 7
Training loss: 2.1975671451105394
Validation loss: 2.5280692009098322

Epoch: 5| Step: 8
Training loss: 2.221441007096577
Validation loss: 2.54769634584539

Epoch: 5| Step: 9
Training loss: 2.4447236250868647
Validation loss: 2.5079653565593754

Epoch: 5| Step: 10
Training loss: 2.4713462987572883
Validation loss: 2.518065696125918

Epoch: 5| Step: 11
Training loss: 2.1322753006146002
Validation loss: 2.5077118264150973

Epoch: 64| Step: 0
Training loss: 2.4852814370325436
Validation loss: 2.5117956676739106

Epoch: 5| Step: 1
Training loss: 2.1801956295464087
Validation loss: 2.5119603833318798

Epoch: 5| Step: 2
Training loss: 2.7359349623863873
Validation loss: 2.474872377425421

Epoch: 5| Step: 3
Training loss: 1.6601089291279758
Validation loss: 2.5085241965669853

Epoch: 5| Step: 4
Training loss: 1.9265019613810934
Validation loss: 2.5254677576105085

Epoch: 5| Step: 5
Training loss: 1.9796944633909388
Validation loss: 2.526566182898403

Epoch: 5| Step: 6
Training loss: 2.3353214536025857
Validation loss: 2.486430615282734

Epoch: 5| Step: 7
Training loss: 2.171873902245114
Validation loss: 2.5742425102252615

Epoch: 5| Step: 8
Training loss: 2.3280508554416204
Validation loss: 2.5283610612127942

Epoch: 5| Step: 9
Training loss: 2.92687381161933
Validation loss: 2.5523028545296866

Epoch: 5| Step: 10
Training loss: 1.921762354581167
Validation loss: 2.543151844970787

Epoch: 5| Step: 11
Training loss: 4.915938997031409
Validation loss: 2.5741315160238583

Epoch: 65| Step: 0
Training loss: 1.7995778197992855
Validation loss: 2.532462653744257

Epoch: 5| Step: 1
Training loss: 2.322392619825799
Validation loss: 2.5825723147538238

Epoch: 5| Step: 2
Training loss: 1.8911818007573002
Validation loss: 2.553587549363862

Epoch: 5| Step: 3
Training loss: 2.997444335827893
Validation loss: 2.4986162210414227

Epoch: 5| Step: 4
Training loss: 1.9845478853622187
Validation loss: 2.598010933355516

Epoch: 5| Step: 5
Training loss: 2.3477947682980833
Validation loss: 2.6071364914523385

Epoch: 5| Step: 6
Training loss: 2.197076380739353
Validation loss: 2.5897626255192985

Epoch: 5| Step: 7
Training loss: 2.7352484479683077
Validation loss: 2.564142429641004

Epoch: 5| Step: 8
Training loss: 2.2993667477135356
Validation loss: 2.563661761663289

Epoch: 5| Step: 9
Training loss: 2.698207814967232
Validation loss: 2.5182565387131075

Epoch: 5| Step: 10
Training loss: 2.4885445400097432
Validation loss: 2.540009260461101

Epoch: 5| Step: 11
Training loss: 2.441984892364933
Validation loss: 2.56975601959142

Epoch: 66| Step: 0
Training loss: 2.0449500897199915
Validation loss: 2.554824603773475

Epoch: 5| Step: 1
Training loss: 2.0455052109425593
Validation loss: 2.575118602718754

Epoch: 5| Step: 2
Training loss: 2.133136766537063
Validation loss: 2.4687919794207462

Epoch: 5| Step: 3
Training loss: 2.7442624319607614
Validation loss: 2.534011402067341

Epoch: 5| Step: 4
Training loss: 2.6925994044295516
Validation loss: 2.5129431335349133

Epoch: 5| Step: 5
Training loss: 2.273223552271865
Validation loss: 2.494631570339367

Epoch: 5| Step: 6
Training loss: 2.6460722767826126
Validation loss: 2.4761568092168296

Epoch: 5| Step: 7
Training loss: 2.102192497128393
Validation loss: 2.5274565335971904

Epoch: 5| Step: 8
Training loss: 2.819594865199152
Validation loss: 2.527559089429002

Epoch: 5| Step: 9
Training loss: 1.94374309182856
Validation loss: 2.560718812851097

Epoch: 5| Step: 10
Training loss: 2.169401777756656
Validation loss: 2.554329795564975

Epoch: 5| Step: 11
Training loss: 3.111061443961766
Validation loss: 2.490560716176757

Epoch: 67| Step: 0
Training loss: 2.518997017459232
Validation loss: 2.4954309673051367

Epoch: 5| Step: 1
Training loss: 2.738540093000813
Validation loss: 2.5047347453217266

Epoch: 5| Step: 2
Training loss: 1.902668449373397
Validation loss: 2.5453564616060573

Epoch: 5| Step: 3
Training loss: 2.2398038415510206
Validation loss: 2.4912318686504817

Epoch: 5| Step: 4
Training loss: 2.0628916050757473
Validation loss: 2.483931651832901

Epoch: 5| Step: 5
Training loss: 2.1331378842268447
Validation loss: 2.5282578306506553

Epoch: 5| Step: 6
Training loss: 2.44085403911143
Validation loss: 2.4989883044725936

Epoch: 5| Step: 7
Training loss: 2.7888274107088793
Validation loss: 2.5053645136178093

Epoch: 5| Step: 8
Training loss: 2.4593653910157145
Validation loss: 2.5135163103688294

Epoch: 5| Step: 9
Training loss: 1.6457635969364928
Validation loss: 2.559052043375892

Epoch: 5| Step: 10
Training loss: 1.8213606669486595
Validation loss: 2.586289703570794

Epoch: 5| Step: 11
Training loss: 3.3224352704151565
Validation loss: 2.5325400946299856

Epoch: 68| Step: 0
Training loss: 2.5791524053702126
Validation loss: 2.577938758981919

Epoch: 5| Step: 1
Training loss: 2.198956272323657
Validation loss: 2.572091067953596

Epoch: 5| Step: 2
Training loss: 1.7280302411497326
Validation loss: 2.627888796726947

Epoch: 5| Step: 3
Training loss: 2.084715638929332
Validation loss: 2.685208393382727

Epoch: 5| Step: 4
Training loss: 2.3434685093005307
Validation loss: 2.640605354612207

Epoch: 5| Step: 5
Training loss: 3.505725809172286
Validation loss: 2.7658416102868717

Epoch: 5| Step: 6
Training loss: 3.1193277378128563
Validation loss: 2.6463896899863157

Epoch: 5| Step: 7
Training loss: 2.128844430008387
Validation loss: 2.615727847898049

Epoch: 5| Step: 8
Training loss: 2.1907827540910025
Validation loss: 2.6298753823525844

Epoch: 5| Step: 9
Training loss: 2.2801508933881225
Validation loss: 2.5057642802953315

Epoch: 5| Step: 10
Training loss: 2.300690679920987
Validation loss: 2.526807780284195

Epoch: 5| Step: 11
Training loss: 1.4765763055065175
Validation loss: 2.5848275632885085

Epoch: 69| Step: 0
Training loss: 2.5300549170221966
Validation loss: 2.5145678994327474

Epoch: 5| Step: 1
Training loss: 2.2922537889627135
Validation loss: 2.6096636218500966

Epoch: 5| Step: 2
Training loss: 2.040181054140317
Validation loss: 2.579062285696557

Epoch: 5| Step: 3
Training loss: 2.093712308174319
Validation loss: 2.5610514865447933

Epoch: 5| Step: 4
Training loss: 2.880841664405306
Validation loss: 2.5219217812895813

Epoch: 5| Step: 5
Training loss: 2.165086194232135
Validation loss: 2.5653243046260985

Epoch: 5| Step: 6
Training loss: 2.3354673390898806
Validation loss: 2.5552275628290206

Epoch: 5| Step: 7
Training loss: 2.0478550552098254
Validation loss: 2.5257781818786986

Epoch: 5| Step: 8
Training loss: 2.1168452475399495
Validation loss: 2.5762187537998127

Epoch: 5| Step: 9
Training loss: 3.012525319353126
Validation loss: 2.4257896206148772

Epoch: 5| Step: 10
Training loss: 2.4829333459001885
Validation loss: 2.534068861383496

Epoch: 5| Step: 11
Training loss: 2.3257901561542194
Validation loss: 2.559844928803198

Epoch: 70| Step: 0
Training loss: 2.110206044699528
Validation loss: 2.55436037168148

Epoch: 5| Step: 1
Training loss: 1.9953932158081924
Validation loss: 2.5607217689685275

Epoch: 5| Step: 2
Training loss: 2.5978655049645596
Validation loss: 2.6163150187112296

Epoch: 5| Step: 3
Training loss: 2.7338338261900983
Validation loss: 2.621413183479563

Epoch: 5| Step: 4
Training loss: 2.3379224426093033
Validation loss: 2.603416131902289

Epoch: 5| Step: 5
Training loss: 2.451097756287265
Validation loss: 2.664280409864261

Epoch: 5| Step: 6
Training loss: 2.802098941877681
Validation loss: 2.643822470288698

Epoch: 5| Step: 7
Training loss: 1.9575199575369018
Validation loss: 2.5731897067678653

Epoch: 5| Step: 8
Training loss: 1.964617737043751
Validation loss: 2.5466544010913856

Epoch: 5| Step: 9
Training loss: 1.728078047543953
Validation loss: 2.5595166548706043

Epoch: 5| Step: 10
Training loss: 2.6551248299084245
Validation loss: 2.49758047602052

Epoch: 5| Step: 11
Training loss: 3.985776766860093
Validation loss: 2.5659275082581154

Epoch: 71| Step: 0
Training loss: 2.1225008012210695
Validation loss: 2.520751929479419

Epoch: 5| Step: 1
Training loss: 1.8432275064084898
Validation loss: 2.564114534949211

Epoch: 5| Step: 2
Training loss: 3.1381484558408
Validation loss: 2.555155980418404

Epoch: 5| Step: 3
Training loss: 2.8637127102339317
Validation loss: 2.5752406583440735

Epoch: 5| Step: 4
Training loss: 2.4938676008063383
Validation loss: 2.5640905181513167

Epoch: 5| Step: 5
Training loss: 2.5213928442430387
Validation loss: 2.592276409280754

Epoch: 5| Step: 6
Training loss: 2.1611558694898028
Validation loss: 2.560402539004486

Epoch: 5| Step: 7
Training loss: 2.1569355413915403
Validation loss: 2.583204982758246

Epoch: 5| Step: 8
Training loss: 2.4799429268576305
Validation loss: 2.6360813830469985

Epoch: 5| Step: 9
Training loss: 2.059094362717254
Validation loss: 2.580124020318679

Epoch: 5| Step: 10
Training loss: 2.477185962070658
Validation loss: 2.589956861263135

Epoch: 5| Step: 11
Training loss: 1.8717346368044279
Validation loss: 2.5317848370500977

Epoch: 72| Step: 0
Training loss: 1.9508432716834552
Validation loss: 2.5026665215691204

Epoch: 5| Step: 1
Training loss: 2.179617494395519
Validation loss: 2.53928876211037

Epoch: 5| Step: 2
Training loss: 2.6191739415176865
Validation loss: 2.5243256327760433

Epoch: 5| Step: 3
Training loss: 2.477164499179183
Validation loss: 2.4814932842439186

Epoch: 5| Step: 4
Training loss: 2.516143555831958
Validation loss: 2.5371708283728434

Epoch: 5| Step: 5
Training loss: 1.683370128393117
Validation loss: 2.5398932638419867

Epoch: 5| Step: 6
Training loss: 2.156710368229067
Validation loss: 2.5789806487360907

Epoch: 5| Step: 7
Training loss: 2.161686002085536
Validation loss: 2.6037355345838344

Epoch: 5| Step: 8
Training loss: 2.581238317578644
Validation loss: 2.6075370201184485

Epoch: 5| Step: 9
Training loss: 2.166931454055413
Validation loss: 2.630507513851501

Epoch: 5| Step: 10
Training loss: 2.2326319371245904
Validation loss: 2.6472757617819593

Epoch: 5| Step: 11
Training loss: 4.325006015310349
Validation loss: 2.576477314173342

Epoch: 73| Step: 0
Training loss: 2.0144300837120923
Validation loss: 2.5769349482339883

Epoch: 5| Step: 1
Training loss: 2.33679122378782
Validation loss: 2.6669593007236654

Epoch: 5| Step: 2
Training loss: 2.3081126478263907
Validation loss: 2.6281780124175644

Epoch: 5| Step: 3
Training loss: 2.4908845658540977
Validation loss: 2.6177851094286897

Epoch: 5| Step: 4
Training loss: 2.575097913639701
Validation loss: 2.5747356407176754

Epoch: 5| Step: 5
Training loss: 2.350406096250446
Validation loss: 2.5903527482211333

Epoch: 5| Step: 6
Training loss: 2.4031201108329654
Validation loss: 2.547086851206074

Epoch: 5| Step: 7
Training loss: 1.991038451083564
Validation loss: 2.498175718371476

Epoch: 5| Step: 8
Training loss: 1.74403891955704
Validation loss: 2.528716738826726

Epoch: 5| Step: 9
Training loss: 3.126690826756468
Validation loss: 2.583908560503993

Epoch: 5| Step: 10
Training loss: 2.078358801976554
Validation loss: 2.5609580145637385

Epoch: 5| Step: 11
Training loss: 1.4625144240491297
Validation loss: 2.492946688495546

Epoch: 74| Step: 0
Training loss: 2.135110811489101
Validation loss: 2.5062183807801115

Epoch: 5| Step: 1
Training loss: 2.2631623663210263
Validation loss: 2.5647998797154243

Epoch: 5| Step: 2
Training loss: 1.9771944626452995
Validation loss: 2.483308831249774

Epoch: 5| Step: 3
Training loss: 2.3035901576872364
Validation loss: 2.4990533745202237

Epoch: 5| Step: 4
Training loss: 2.3841384950386986
Validation loss: 2.465724837969619

Epoch: 5| Step: 5
Training loss: 1.6066203569858448
Validation loss: 2.5386047067955766

Epoch: 5| Step: 6
Training loss: 2.779285637302694
Validation loss: 2.5081506423913176

Epoch: 5| Step: 7
Training loss: 2.01309293459084
Validation loss: 2.52103568018977

Epoch: 5| Step: 8
Training loss: 2.851133382202655
Validation loss: 2.5489052362579723

Epoch: 5| Step: 9
Training loss: 2.3136299053496483
Validation loss: 2.524120592660456

Epoch: 5| Step: 10
Training loss: 2.2153997782958585
Validation loss: 2.492071406132812

Epoch: 5| Step: 11
Training loss: 2.9518775525426317
Validation loss: 2.5682691202876944

Epoch: 75| Step: 0
Training loss: 2.029123689900045
Validation loss: 2.5214855529955758

Epoch: 5| Step: 1
Training loss: 1.9690239730816979
Validation loss: 2.5220661747922937

Epoch: 5| Step: 2
Training loss: 1.6887153205162608
Validation loss: 2.523712674658936

Epoch: 5| Step: 3
Training loss: 2.5356572718514165
Validation loss: 2.5618800793526297

Epoch: 5| Step: 4
Training loss: 2.8818599295320344
Validation loss: 2.5955483433730846

Epoch: 5| Step: 5
Training loss: 2.4587893844266113
Validation loss: 2.5164703188863218

Epoch: 5| Step: 6
Training loss: 1.7882593342715976
Validation loss: 2.528978684685975

Epoch: 5| Step: 7
Training loss: 2.3268754921502004
Validation loss: 2.5323420178423612

Epoch: 5| Step: 8
Training loss: 2.3248966029976748
Validation loss: 2.6173309932107354

Epoch: 5| Step: 9
Training loss: 2.030281070549925
Validation loss: 2.4766961150923668

Epoch: 5| Step: 10
Training loss: 2.9943294975694723
Validation loss: 2.544717959599938

Epoch: 5| Step: 11
Training loss: 1.6790726356903303
Validation loss: 2.518084226353759

Epoch: 76| Step: 0
Training loss: 2.257952200715629
Validation loss: 2.5682346869735375

Epoch: 5| Step: 1
Training loss: 2.7800022712533576
Validation loss: 2.5480322597688225

Epoch: 5| Step: 2
Training loss: 2.229816401497488
Validation loss: 2.5005163930991112

Epoch: 5| Step: 3
Training loss: 2.9126583531107455
Validation loss: 2.5556219299365135

Epoch: 5| Step: 4
Training loss: 1.9156147170918763
Validation loss: 2.5621940267298053

Epoch: 5| Step: 5
Training loss: 1.9071066760595354
Validation loss: 2.545430907103826

Epoch: 5| Step: 6
Training loss: 2.535631414475389
Validation loss: 2.494281128560553

Epoch: 5| Step: 7
Training loss: 2.3543236829219736
Validation loss: 2.5273276047974584

Epoch: 5| Step: 8
Training loss: 2.022509387811439
Validation loss: 2.531713721886716

Epoch: 5| Step: 9
Training loss: 1.8098328138032715
Validation loss: 2.520365988283425

Epoch: 5| Step: 10
Training loss: 2.13217768461542
Validation loss: 2.485562250766321

Epoch: 5| Step: 11
Training loss: 0.9297236908351865
Validation loss: 2.537600149956332

Epoch: 77| Step: 0
Training loss: 2.0279367274283686
Validation loss: 2.524829004496748

Epoch: 5| Step: 1
Training loss: 2.8885853762826916
Validation loss: 2.5240999735974365

Epoch: 5| Step: 2
Training loss: 1.7877135542700826
Validation loss: 2.5201711132945106

Epoch: 5| Step: 3
Training loss: 1.491644555821277
Validation loss: 2.5436915099584154

Epoch: 5| Step: 4
Training loss: 2.351492947281731
Validation loss: 2.5422234290205523

Epoch: 5| Step: 5
Training loss: 2.377619653813596
Validation loss: 2.5839566176181017

Epoch: 5| Step: 6
Training loss: 2.1015808785354606
Validation loss: 2.5951993791676276

Epoch: 5| Step: 7
Training loss: 3.0231091224895428
Validation loss: 2.593698773012274

Epoch: 5| Step: 8
Training loss: 2.5070348942279335
Validation loss: 2.601498294683373

Epoch: 5| Step: 9
Training loss: 2.3934343573129624
Validation loss: 2.4712802419000326

Epoch: 5| Step: 10
Training loss: 2.2046697084613336
Validation loss: 2.539163358592512

Epoch: 5| Step: 11
Training loss: 1.028548430004037
Validation loss: 2.5099705118939624

Epoch: 78| Step: 0
Training loss: 2.725668511938878
Validation loss: 2.509425297284909

Epoch: 5| Step: 1
Training loss: 1.4819154942521156
Validation loss: 2.5248408278412104

Epoch: 5| Step: 2
Training loss: 1.884218253073851
Validation loss: 2.493881761803398

Epoch: 5| Step: 3
Training loss: 2.1297625858003517
Validation loss: 2.5114306160531115

Epoch: 5| Step: 4
Training loss: 2.385446362261999
Validation loss: 2.5216485838505402

Epoch: 5| Step: 5
Training loss: 2.2336895298044133
Validation loss: 2.524804338579264

Epoch: 5| Step: 6
Training loss: 1.9462754650569298
Validation loss: 2.5097263595339596

Epoch: 5| Step: 7
Training loss: 2.0912466313893057
Validation loss: 2.5060340580618745

Epoch: 5| Step: 8
Training loss: 2.8815584427246814
Validation loss: 2.5425465746576874

Epoch: 5| Step: 9
Training loss: 2.6405595398864428
Validation loss: 2.469793831384408

Epoch: 5| Step: 10
Training loss: 2.3392832598990543
Validation loss: 2.5302795543569725

Epoch: 5| Step: 11
Training loss: 3.310398514835694
Validation loss: 2.5208133796553724

Epoch: 79| Step: 0
Training loss: 2.4429584909192568
Validation loss: 2.5109439483414184

Epoch: 5| Step: 1
Training loss: 2.1915636737058275
Validation loss: 2.485809315993729

Epoch: 5| Step: 2
Training loss: 2.4299661654404874
Validation loss: 2.5503943492106362

Epoch: 5| Step: 3
Training loss: 2.181215905740102
Validation loss: 2.5025960437167813

Epoch: 5| Step: 4
Training loss: 2.073750531068335
Validation loss: 2.537088043146705

Epoch: 5| Step: 5
Training loss: 2.2677130186715626
Validation loss: 2.5063809758571494

Epoch: 5| Step: 6
Training loss: 2.0556148858429015
Validation loss: 2.538298224817721

Epoch: 5| Step: 7
Training loss: 2.4229646261973095
Validation loss: 2.53169937618899

Epoch: 5| Step: 8
Training loss: 1.9268027917606907
Validation loss: 2.5593040276368484

Epoch: 5| Step: 9
Training loss: 2.4237911396755147
Validation loss: 2.5170234915630165

Epoch: 5| Step: 10
Training loss: 2.222081329594678
Validation loss: 2.521223567413682

Epoch: 5| Step: 11
Training loss: 1.4776999316032018
Validation loss: 2.505608819421008

Epoch: 80| Step: 0
Training loss: 2.42535396627479
Validation loss: 2.481501967338701

Epoch: 5| Step: 1
Training loss: 1.9094724464835844
Validation loss: 2.5315330723849887

Epoch: 5| Step: 2
Training loss: 2.3185700832598415
Validation loss: 2.501735279725221

Epoch: 5| Step: 3
Training loss: 2.557972886562935
Validation loss: 2.5888450657107924

Epoch: 5| Step: 4
Training loss: 2.2267246120397934
Validation loss: 2.526755091935588

Epoch: 5| Step: 5
Training loss: 2.103225107063594
Validation loss: 2.5752691847334694

Epoch: 5| Step: 6
Training loss: 2.2802001418560094
Validation loss: 2.5118322055123454

Epoch: 5| Step: 7
Training loss: 2.542738943659338
Validation loss: 2.4998952426419865

Epoch: 5| Step: 8
Training loss: 2.0863907568036444
Validation loss: 2.531481602752037

Epoch: 5| Step: 9
Training loss: 2.6293174116040756
Validation loss: 2.5267350113762803

Epoch: 5| Step: 10
Training loss: 2.0023306141815764
Validation loss: 2.5504312825284012

Epoch: 5| Step: 11
Training loss: 1.8121232265988167
Validation loss: 2.4672897965924654

Epoch: 81| Step: 0
Training loss: 1.5757387457180458
Validation loss: 2.5007953570705985

Epoch: 5| Step: 1
Training loss: 1.8738140170083353
Validation loss: 2.4866234303577195

Epoch: 5| Step: 2
Training loss: 1.894550252602831
Validation loss: 2.5512081838529856

Epoch: 5| Step: 3
Training loss: 2.263382742636947
Validation loss: 2.513574204601182

Epoch: 5| Step: 4
Training loss: 3.0583570834562073
Validation loss: 2.5050942493456922

Epoch: 5| Step: 5
Training loss: 1.9264537573303129
Validation loss: 2.5259330778607487

Epoch: 5| Step: 6
Training loss: 2.053525414751013
Validation loss: 2.5965926055442297

Epoch: 5| Step: 7
Training loss: 2.802467168637792
Validation loss: 2.524553636717377

Epoch: 5| Step: 8
Training loss: 2.1052868822919333
Validation loss: 2.529860641118072

Epoch: 5| Step: 9
Training loss: 2.053672626916209
Validation loss: 2.513782952261972

Epoch: 5| Step: 10
Training loss: 2.5480352461995586
Validation loss: 2.5078282578588236

Epoch: 5| Step: 11
Training loss: 1.413921581011932
Validation loss: 2.5050176513548705

Epoch: 82| Step: 0
Training loss: 2.2484346878850663
Validation loss: 2.485062530039154

Epoch: 5| Step: 1
Training loss: 1.7438603738834926
Validation loss: 2.4809320993264974

Epoch: 5| Step: 2
Training loss: 2.283688222031803
Validation loss: 2.5481706455768607

Epoch: 5| Step: 3
Training loss: 2.356237282958989
Validation loss: 2.547258445722999

Epoch: 5| Step: 4
Training loss: 2.9557173718904717
Validation loss: 2.5171717593716934

Epoch: 5| Step: 5
Training loss: 1.8688938532037733
Validation loss: 2.5368377015413075

Epoch: 5| Step: 6
Training loss: 2.257748929617067
Validation loss: 2.430736724065804

Epoch: 5| Step: 7
Training loss: 2.268809428632054
Validation loss: 2.586245411868333

Epoch: 5| Step: 8
Training loss: 1.7965392089225793
Validation loss: 2.5337955249823643

Epoch: 5| Step: 9
Training loss: 2.3433989198314147
Validation loss: 2.5061603740987666

Epoch: 5| Step: 10
Training loss: 2.3399564432508217
Validation loss: 2.514015279025725

Epoch: 5| Step: 11
Training loss: 1.4007395970565717
Validation loss: 2.538487002368958

Epoch: 83| Step: 0
Training loss: 2.685034219534418
Validation loss: 2.578225565403547

Epoch: 5| Step: 1
Training loss: 1.7213866384178018
Validation loss: 2.4706393146944587

Epoch: 5| Step: 2
Training loss: 1.951698087161894
Validation loss: 2.5257208918714404

Epoch: 5| Step: 3
Training loss: 1.834950997740342
Validation loss: 2.5353535838391275

Epoch: 5| Step: 4
Training loss: 2.6984786303841903
Validation loss: 2.5168273690264193

Epoch: 5| Step: 5
Training loss: 2.7470779500204885
Validation loss: 2.517263116061904

Epoch: 5| Step: 6
Training loss: 2.66876378647685
Validation loss: 2.5059924507831646

Epoch: 5| Step: 7
Training loss: 2.1880622141290154
Validation loss: 2.536446508005346

Epoch: 5| Step: 8
Training loss: 2.0688879330108505
Validation loss: 2.5087047110820544

Epoch: 5| Step: 9
Training loss: 1.9710353726252023
Validation loss: 2.5342890662548054

Epoch: 5| Step: 10
Training loss: 2.03364023279329
Validation loss: 2.508529160597789

Epoch: 5| Step: 11
Training loss: 2.252835288713698
Validation loss: 2.5306407230517154

Epoch: 84| Step: 0
Training loss: 2.13478416441801
Validation loss: 2.5181400687002844

Epoch: 5| Step: 1
Training loss: 2.558627295820166
Validation loss: 2.5447520201555385

Epoch: 5| Step: 2
Training loss: 1.8306894818088462
Validation loss: 2.510979594566405

Epoch: 5| Step: 3
Training loss: 2.503262965368481
Validation loss: 2.4989063175369726

Epoch: 5| Step: 4
Training loss: 2.3227504676471025
Validation loss: 2.5752891086570995

Epoch: 5| Step: 5
Training loss: 2.0663404832841286
Validation loss: 2.5658059039750296

Epoch: 5| Step: 6
Training loss: 2.14078927627951
Validation loss: 2.497818666741086

Epoch: 5| Step: 7
Training loss: 1.7492743077384945
Validation loss: 2.551576316190286

Epoch: 5| Step: 8
Training loss: 3.028800682686045
Validation loss: 2.5532124584133196

Epoch: 5| Step: 9
Training loss: 2.1505478360590407
Validation loss: 2.5675798168609165

Epoch: 5| Step: 10
Training loss: 2.3079869332894023
Validation loss: 2.540336410598266

Epoch: 5| Step: 11
Training loss: 1.9681716553871973
Validation loss: 2.518565479268756

Epoch: 85| Step: 0
Training loss: 2.037877114623907
Validation loss: 2.4778796162285417

Epoch: 5| Step: 1
Training loss: 1.914572760629224
Validation loss: 2.547108321628673

Epoch: 5| Step: 2
Training loss: 2.290084870943758
Validation loss: 2.522089890656853

Epoch: 5| Step: 3
Training loss: 2.1279163543997734
Validation loss: 2.500064515235062

Epoch: 5| Step: 4
Training loss: 2.4770404342474364
Validation loss: 2.502717047668526

Epoch: 5| Step: 5
Training loss: 2.445924529975414
Validation loss: 2.479550882160354

Epoch: 5| Step: 6
Training loss: 2.4132696040926205
Validation loss: 2.4975313296403856

Epoch: 5| Step: 7
Training loss: 1.389602885568639
Validation loss: 2.519420025955547

Epoch: 5| Step: 8
Training loss: 2.0848090730699504
Validation loss: 2.4437156964274136

Epoch: 5| Step: 9
Training loss: 2.4288169552403467
Validation loss: 2.605081215804812

Epoch: 5| Step: 10
Training loss: 2.3838955778448256
Validation loss: 2.466874311434322

Epoch: 5| Step: 11
Training loss: 2.1401859028008205
Validation loss: 2.4521537891098117

Epoch: 86| Step: 0
Training loss: 2.146381962340179
Validation loss: 2.502149940946649

Epoch: 5| Step: 1
Training loss: 2.504781061377579
Validation loss: 2.511048044977137

Epoch: 5| Step: 2
Training loss: 2.494750041786971
Validation loss: 2.5006098519988083

Epoch: 5| Step: 3
Training loss: 2.2253258198694494
Validation loss: 2.5347709578498514

Epoch: 5| Step: 4
Training loss: 2.0168052588936356
Validation loss: 2.5698112474418946

Epoch: 5| Step: 5
Training loss: 1.9421924250349236
Validation loss: 2.6107547941874047

Epoch: 5| Step: 6
Training loss: 1.9666658299115658
Validation loss: 2.5283523700951323

Epoch: 5| Step: 7
Training loss: 2.3850070540605746
Validation loss: 2.525477636755478

Epoch: 5| Step: 8
Training loss: 2.2982201821641866
Validation loss: 2.5466909790646914

Epoch: 5| Step: 9
Training loss: 2.2801908359637544
Validation loss: 2.5215231146127732

Epoch: 5| Step: 10
Training loss: 1.8349589885317616
Validation loss: 2.542827229192476

Epoch: 5| Step: 11
Training loss: 1.5076311229660229
Validation loss: 2.543865176724632

Epoch: 87| Step: 0
Training loss: 2.4427811558217893
Validation loss: 2.5113571761043096

Epoch: 5| Step: 1
Training loss: 2.249712077898228
Validation loss: 2.4710145615818004

Epoch: 5| Step: 2
Training loss: 2.1837845993576384
Validation loss: 2.509852747017314

Epoch: 5| Step: 3
Training loss: 1.9049940505648246
Validation loss: 2.4656280180731716

Epoch: 5| Step: 4
Training loss: 1.796359709785236
Validation loss: 2.530855383548218

Epoch: 5| Step: 5
Training loss: 2.342607855659835
Validation loss: 2.493787273966566

Epoch: 5| Step: 6
Training loss: 2.3039084976821753
Validation loss: 2.554527141581663

Epoch: 5| Step: 7
Training loss: 1.8357654247402173
Validation loss: 2.5693590353325413

Epoch: 5| Step: 8
Training loss: 2.108624812346465
Validation loss: 2.570390949385482

Epoch: 5| Step: 9
Training loss: 2.2959565902088688
Validation loss: 2.5632304898791363

Epoch: 5| Step: 10
Training loss: 2.7181032661205884
Validation loss: 2.50251094566426

Epoch: 5| Step: 11
Training loss: 2.1835579365913724
Validation loss: 2.5761928099581066

Epoch: 88| Step: 0
Training loss: 2.1010853959694273
Validation loss: 2.505262328033269

Epoch: 5| Step: 1
Training loss: 1.8030369464391487
Validation loss: 2.4741790325035224

Epoch: 5| Step: 2
Training loss: 2.5541343906804785
Validation loss: 2.5125889553625305

Epoch: 5| Step: 3
Training loss: 2.249321517372113
Validation loss: 2.5260482919088307

Epoch: 5| Step: 4
Training loss: 1.7933882345188654
Validation loss: 2.5057552669838588

Epoch: 5| Step: 5
Training loss: 2.1988064259135944
Validation loss: 2.491451956089574

Epoch: 5| Step: 6
Training loss: 2.2544750639618703
Validation loss: 2.546891935951387

Epoch: 5| Step: 7
Training loss: 2.1598057936853414
Validation loss: 2.502686686086515

Epoch: 5| Step: 8
Training loss: 2.719453742487954
Validation loss: 2.548083691387295

Epoch: 5| Step: 9
Training loss: 1.6416944378796903
Validation loss: 2.538185445477046

Epoch: 5| Step: 10
Training loss: 2.0074328349315884
Validation loss: 2.5291112294057627

Epoch: 5| Step: 11
Training loss: 2.7370963369467014
Validation loss: 2.556612706742293

Epoch: 89| Step: 0
Training loss: 2.6121080898568696
Validation loss: 2.509389557722975

Epoch: 5| Step: 1
Training loss: 2.3772173118000746
Validation loss: 2.4580494479690995

Epoch: 5| Step: 2
Training loss: 2.0672332320341167
Validation loss: 2.51713962647535

Epoch: 5| Step: 3
Training loss: 2.232322977700588
Validation loss: 2.4892071688481225

Epoch: 5| Step: 4
Training loss: 1.8968027870975066
Validation loss: 2.4982819335995097

Epoch: 5| Step: 5
Training loss: 1.8820673944241586
Validation loss: 2.581803531579469

Epoch: 5| Step: 6
Training loss: 1.9256194319454172
Validation loss: 2.4929692069825995

Epoch: 5| Step: 7
Training loss: 2.0841632969994386
Validation loss: 2.5472799361486547

Epoch: 5| Step: 8
Training loss: 2.1090436887163593
Validation loss: 2.5296882041912894

Epoch: 5| Step: 9
Training loss: 2.137612443609909
Validation loss: 2.529531162167786

Epoch: 5| Step: 10
Training loss: 2.4662963649376346
Validation loss: 2.539221033869094

Epoch: 5| Step: 11
Training loss: 1.5749025587184775
Validation loss: 2.515162751276563

Epoch: 90| Step: 0
Training loss: 1.6076659229368329
Validation loss: 2.5355178132382745

Epoch: 5| Step: 1
Training loss: 1.8828400415962476
Validation loss: 2.506766599303764

Epoch: 5| Step: 2
Training loss: 2.043903902657745
Validation loss: 2.6157079547532787

Epoch: 5| Step: 3
Training loss: 2.1318721724474385
Validation loss: 2.5941376875110325

Epoch: 5| Step: 4
Training loss: 2.1500212779212013
Validation loss: 2.6130664929167056

Epoch: 5| Step: 5
Training loss: 1.9893651379943944
Validation loss: 2.5465039136963754

Epoch: 5| Step: 6
Training loss: 1.9505953466819284
Validation loss: 2.5857614877964363

Epoch: 5| Step: 7
Training loss: 2.2217395682177457
Validation loss: 2.6046237290143988

Epoch: 5| Step: 8
Training loss: 2.1747555737887185
Validation loss: 2.5534071713068265

Epoch: 5| Step: 9
Training loss: 3.2010909902933418
Validation loss: 2.5347423284130923

Epoch: 5| Step: 10
Training loss: 2.250100875288619
Validation loss: 2.590615918335682

Epoch: 5| Step: 11
Training loss: 1.9192055872709828
Validation loss: 2.582458764645923

Epoch: 91| Step: 0
Training loss: 2.8494430399320816
Validation loss: 2.520797301000746

Epoch: 5| Step: 1
Training loss: 1.4766065802882091
Validation loss: 2.493223331801328

Epoch: 5| Step: 2
Training loss: 2.2231667842375455
Validation loss: 2.5118216319986595

Epoch: 5| Step: 3
Training loss: 1.7108150072536157
Validation loss: 2.525649546965164

Epoch: 5| Step: 4
Training loss: 2.325450103014491
Validation loss: 2.629079385075452

Epoch: 5| Step: 5
Training loss: 2.532987304529181
Validation loss: 2.532919541139933

Epoch: 5| Step: 6
Training loss: 2.1520968259208106
Validation loss: 2.477710850741435

Epoch: 5| Step: 7
Training loss: 2.1204773514825934
Validation loss: 2.554233327890779

Epoch: 5| Step: 8
Training loss: 2.428751872675984
Validation loss: 2.550960641563071

Epoch: 5| Step: 9
Training loss: 1.8500502966152308
Validation loss: 2.5017582075202243

Epoch: 5| Step: 10
Training loss: 2.1808837014682454
Validation loss: 2.559372066702615

Epoch: 5| Step: 11
Training loss: 1.5748177044441796
Validation loss: 2.4755957809543476

Epoch: 92| Step: 0
Training loss: 2.183075380981855
Validation loss: 2.4864353497426714

Epoch: 5| Step: 1
Training loss: 1.3578317585974198
Validation loss: 2.5071228362484583

Epoch: 5| Step: 2
Training loss: 2.7538785459599406
Validation loss: 2.540411996456002

Epoch: 5| Step: 3
Training loss: 2.0848169638888447
Validation loss: 2.5171995941319896

Epoch: 5| Step: 4
Training loss: 2.098704383449782
Validation loss: 2.5372895296000464

Epoch: 5| Step: 5
Training loss: 2.0165461128499502
Validation loss: 2.5829104659372275

Epoch: 5| Step: 6
Training loss: 2.782926247192773
Validation loss: 2.5290991824938684

Epoch: 5| Step: 7
Training loss: 1.3585059358581548
Validation loss: 2.5631677525119065

Epoch: 5| Step: 8
Training loss: 2.6449890191295538
Validation loss: 2.542981016380466

Epoch: 5| Step: 9
Training loss: 2.2949729881276055
Validation loss: 2.5556290628623746

Epoch: 5| Step: 10
Training loss: 1.892956202863358
Validation loss: 2.5432876508056905

Epoch: 5| Step: 11
Training loss: 1.2214214195274722
Validation loss: 2.545579389611069

Epoch: 93| Step: 0
Training loss: 1.9047246364512498
Validation loss: 2.4550841500090255

Epoch: 5| Step: 1
Training loss: 1.82278346710392
Validation loss: 2.5001538666423206

Epoch: 5| Step: 2
Training loss: 2.294782866468163
Validation loss: 2.53528501382482

Epoch: 5| Step: 3
Training loss: 2.3221111069743294
Validation loss: 2.6128147813227143

Epoch: 5| Step: 4
Training loss: 2.2919355986037155
Validation loss: 2.508136720386773

Epoch: 5| Step: 5
Training loss: 2.317749971737253
Validation loss: 2.472360590272456

Epoch: 5| Step: 6
Training loss: 2.123958220083531
Validation loss: 2.5248776077281465

Epoch: 5| Step: 7
Training loss: 2.2779133053393066
Validation loss: 2.5918480667543586

Epoch: 5| Step: 8
Training loss: 2.168949379674541
Validation loss: 2.5270445428896986

Epoch: 5| Step: 9
Training loss: 2.116435124906845
Validation loss: 2.459400686140405

Epoch: 5| Step: 10
Training loss: 1.7683082379361996
Validation loss: 2.5154076199961004

Epoch: 5| Step: 11
Training loss: 2.0055478159554663
Validation loss: 2.470656170103576

Epoch: 94| Step: 0
Training loss: 1.8746848159366398
Validation loss: 2.555249077593519

Epoch: 5| Step: 1
Training loss: 2.095595955219359
Validation loss: 2.5519586195283943

Epoch: 5| Step: 2
Training loss: 2.447003836912102
Validation loss: 2.5019244972356094

Epoch: 5| Step: 3
Training loss: 1.7380508098659777
Validation loss: 2.5408181190212455

Epoch: 5| Step: 4
Training loss: 2.6266686721574644
Validation loss: 2.492629124687058

Epoch: 5| Step: 5
Training loss: 2.078183280873313
Validation loss: 2.492805085547556

Epoch: 5| Step: 6
Training loss: 1.9131615834568922
Validation loss: 2.5407801838394737

Epoch: 5| Step: 7
Training loss: 1.922788511436904
Validation loss: 2.5523527872474174

Epoch: 5| Step: 8
Training loss: 1.5539848234891231
Validation loss: 2.490296606146439

Epoch: 5| Step: 9
Training loss: 2.75948432196027
Validation loss: 2.5261716212767076

Epoch: 5| Step: 10
Training loss: 1.5098993752911611
Validation loss: 2.528005659715488

Epoch: 5| Step: 11
Training loss: 3.4888944183057418
Validation loss: 2.4789961681454327

Epoch: 95| Step: 0
Training loss: 2.103237123037114
Validation loss: 2.5347520949869278

Epoch: 5| Step: 1
Training loss: 2.225941139656293
Validation loss: 2.6176937315888185

Epoch: 5| Step: 2
Training loss: 1.8151609684627599
Validation loss: 2.5312518092333445

Epoch: 5| Step: 3
Training loss: 2.1978679729931425
Validation loss: 2.5740907528226624

Epoch: 5| Step: 4
Training loss: 2.302318946438119
Validation loss: 2.5181456390592953

Epoch: 5| Step: 5
Training loss: 1.8134559215219372
Validation loss: 2.501004919099654

Epoch: 5| Step: 6
Training loss: 1.7461037859532262
Validation loss: 2.5413775878941105

Epoch: 5| Step: 7
Training loss: 1.7984690354380426
Validation loss: 2.5170674917201112

Epoch: 5| Step: 8
Training loss: 2.9389758359390092
Validation loss: 2.5512631337452185

Epoch: 5| Step: 9
Training loss: 2.045779102277404
Validation loss: 2.4609012197413795

Epoch: 5| Step: 10
Training loss: 2.2068632618935764
Validation loss: 2.5610175613075286

Epoch: 5| Step: 11
Training loss: 2.100952173261513
Validation loss: 2.5708339707133177

Epoch: 96| Step: 0
Training loss: 2.1739212386349993
Validation loss: 2.486909493207697

Epoch: 5| Step: 1
Training loss: 2.919848386930584
Validation loss: 2.573207206898494

Epoch: 5| Step: 2
Training loss: 2.198843183684445
Validation loss: 2.538003553966682

Epoch: 5| Step: 3
Training loss: 1.8324653420286912
Validation loss: 2.5238374328205477

Epoch: 5| Step: 4
Training loss: 1.9540955840347702
Validation loss: 2.48469204349172

Epoch: 5| Step: 5
Training loss: 1.914954775482903
Validation loss: 2.491042851871588

Epoch: 5| Step: 6
Training loss: 2.2788646193328534
Validation loss: 2.5075676502396016

Epoch: 5| Step: 7
Training loss: 1.581744132655527
Validation loss: 2.574209766053889

Epoch: 5| Step: 8
Training loss: 2.2912742163111504
Validation loss: 2.578005346739053

Epoch: 5| Step: 9
Training loss: 1.9370326432179
Validation loss: 2.5421758334551185

Epoch: 5| Step: 10
Training loss: 1.819751112656555
Validation loss: 2.5362869938520873

Epoch: 5| Step: 11
Training loss: 1.9935530825384509
Validation loss: 2.514356309039151

Epoch: 97| Step: 0
Training loss: 2.440314892789547
Validation loss: 2.5656719657263696

Epoch: 5| Step: 1
Training loss: 1.6153097999979702
Validation loss: 2.5551516240593455

Epoch: 5| Step: 2
Training loss: 2.0615481868037118
Validation loss: 2.5136243553382744

Epoch: 5| Step: 3
Training loss: 2.1218578444673635
Validation loss: 2.5818626898967136

Epoch: 5| Step: 4
Training loss: 2.1191740393750997
Validation loss: 2.603633609892347

Epoch: 5| Step: 5
Training loss: 2.0156458180853214
Validation loss: 2.5221859334922616

Epoch: 5| Step: 6
Training loss: 2.2955993431562303
Validation loss: 2.578476610193395

Epoch: 5| Step: 7
Training loss: 1.9297329669491758
Validation loss: 2.555751042531213

Epoch: 5| Step: 8
Training loss: 1.9513894877163236
Validation loss: 2.5271240799258723

Epoch: 5| Step: 9
Training loss: 2.2129545143648355
Validation loss: 2.4964908528740057

Epoch: 5| Step: 10
Training loss: 2.3133991658447113
Validation loss: 2.5376909238963843

Epoch: 5| Step: 11
Training loss: 1.8433110635986154
Validation loss: 2.55347041109051

Epoch: 98| Step: 0
Training loss: 2.5602272934146515
Validation loss: 2.540079552820147

Epoch: 5| Step: 1
Training loss: 2.4080539233294496
Validation loss: 2.52840957297404

Epoch: 5| Step: 2
Training loss: 1.9332510596341117
Validation loss: 2.539420844980314

Epoch: 5| Step: 3
Training loss: 2.3983917728998065
Validation loss: 2.4987085264986866

Epoch: 5| Step: 4
Training loss: 1.9570661530266134
Validation loss: 2.5254895908035717

Epoch: 5| Step: 5
Training loss: 2.323198572224843
Validation loss: 2.5277621725203883

Epoch: 5| Step: 6
Training loss: 1.6490431843476336
Validation loss: 2.4916259846561055

Epoch: 5| Step: 7
Training loss: 2.0047518784494827
Validation loss: 2.516221696366297

Epoch: 5| Step: 8
Training loss: 2.377179200102898
Validation loss: 2.4903481770360996

Epoch: 5| Step: 9
Training loss: 2.1997095783316274
Validation loss: 2.5714661734849162

Epoch: 5| Step: 10
Training loss: 1.864886346273797
Validation loss: 2.5902893235463766

Epoch: 5| Step: 11
Training loss: 1.5489278715516521
Validation loss: 2.5514182619002916

Epoch: 99| Step: 0
Training loss: 1.5761583367845238
Validation loss: 2.5590563639805866

Epoch: 5| Step: 1
Training loss: 2.5101226908877035
Validation loss: 2.593422643080608

Epoch: 5| Step: 2
Training loss: 2.266292184393964
Validation loss: 2.5336920610241878

Epoch: 5| Step: 3
Training loss: 2.1204354123364912
Validation loss: 2.5995132462908224

Epoch: 5| Step: 4
Training loss: 2.2736224856280165
Validation loss: 2.5694155533916154

Epoch: 5| Step: 5
Training loss: 1.9518775313058954
Validation loss: 2.551751945674754

Epoch: 5| Step: 6
Training loss: 2.1096478321096397
Validation loss: 2.5612298678700216

Epoch: 5| Step: 7
Training loss: 2.3640645896362833
Validation loss: 2.4756124300670916

Epoch: 5| Step: 8
Training loss: 2.026515431324419
Validation loss: 2.5184805007269584

Epoch: 5| Step: 9
Training loss: 1.998094604757379
Validation loss: 2.550476379246016

Epoch: 5| Step: 10
Training loss: 1.748315613617148
Validation loss: 2.5047766788794363

Epoch: 5| Step: 11
Training loss: 1.7174171134571412
Validation loss: 2.5248639195979026

Epoch: 100| Step: 0
Training loss: 1.9019701079658058
Validation loss: 2.5074407474290745

Epoch: 5| Step: 1
Training loss: 2.0475690989775877
Validation loss: 2.554658518246698

Epoch: 5| Step: 2
Training loss: 1.3009972378688992
Validation loss: 2.556893961968298

Epoch: 5| Step: 3
Training loss: 2.8324332958154796
Validation loss: 2.5891417505616303

Epoch: 5| Step: 4
Training loss: 2.509655996815315
Validation loss: 2.587919775840633

Epoch: 5| Step: 5
Training loss: 1.9941757154226212
Validation loss: 2.6822832953066267

Epoch: 5| Step: 6
Training loss: 2.2360631794132924
Validation loss: 2.598377619038268

Epoch: 5| Step: 7
Training loss: 1.8798768516545106
Validation loss: 2.6182126936284607

Epoch: 5| Step: 8
Training loss: 2.045774440604001
Validation loss: 2.596873440304015

Epoch: 5| Step: 9
Training loss: 2.1471732564028163
Validation loss: 2.579074653890514

Epoch: 5| Step: 10
Training loss: 2.0044654824341017
Validation loss: 2.590196028388986

Epoch: 5| Step: 11
Training loss: 2.227942323619597
Validation loss: 2.4765701333940155

Epoch: 101| Step: 0
Training loss: 2.1078020801102832
Validation loss: 2.4910876439119067

Epoch: 5| Step: 1
Training loss: 2.274824944772215
Validation loss: 2.478678676651882

Epoch: 5| Step: 2
Training loss: 1.6766011115442592
Validation loss: 2.4917185012237733

Epoch: 5| Step: 3
Training loss: 2.118638895998316
Validation loss: 2.4626543545312782

Epoch: 5| Step: 4
Training loss: 2.2353333238730055
Validation loss: 2.5150877534877565

Epoch: 5| Step: 5
Training loss: 2.663859608550834
Validation loss: 2.4586688529326897

Epoch: 5| Step: 6
Training loss: 1.7685761221350855
Validation loss: 2.5023196068872497

Epoch: 5| Step: 7
Training loss: 2.2229979776981574
Validation loss: 2.493344069468831

Epoch: 5| Step: 8
Training loss: 1.6271566604847887
Validation loss: 2.5509205770875587

Epoch: 5| Step: 9
Training loss: 1.936154113424545
Validation loss: 2.5319076123409427

Epoch: 5| Step: 10
Training loss: 1.7240415785437802
Validation loss: 2.5240507768323552

Epoch: 5| Step: 11
Training loss: 1.5301121746654152
Validation loss: 2.515900480299457

Epoch: 102| Step: 0
Training loss: 1.5626898078072964
Validation loss: 2.570743010699918

Epoch: 5| Step: 1
Training loss: 2.110537964277645
Validation loss: 2.5293997018304006

Epoch: 5| Step: 2
Training loss: 2.0899679842235255
Validation loss: 2.5773170091302338

Epoch: 5| Step: 3
Training loss: 2.454651764452344
Validation loss: 2.579057187795551

Epoch: 5| Step: 4
Training loss: 2.39354353131325
Validation loss: 2.5577739149510594

Epoch: 5| Step: 5
Training loss: 2.165688244885594
Validation loss: 2.5770635192148443

Epoch: 5| Step: 6
Training loss: 1.8407661733583842
Validation loss: 2.529727866667736

Epoch: 5| Step: 7
Training loss: 1.8205636305570603
Validation loss: 2.500414897346178

Epoch: 5| Step: 8
Training loss: 2.3839288816661033
Validation loss: 2.4546107755504214

Epoch: 5| Step: 9
Training loss: 1.98639474042518
Validation loss: 2.494319665387923

Epoch: 5| Step: 10
Training loss: 1.430081172586636
Validation loss: 2.522081926310666

Epoch: 5| Step: 11
Training loss: 2.6241758960292243
Validation loss: 2.5981706650089973

Epoch: 103| Step: 0
Training loss: 2.009996465803237
Validation loss: 2.500093561646969

Epoch: 5| Step: 1
Training loss: 1.3972146425658847
Validation loss: 2.5436332955484855

Epoch: 5| Step: 2
Training loss: 1.689442823080946
Validation loss: 2.5156853315175622

Epoch: 5| Step: 3
Training loss: 2.217630130600836
Validation loss: 2.530189013155446

Epoch: 5| Step: 4
Training loss: 1.931859512192971
Validation loss: 2.536925988816995

Epoch: 5| Step: 5
Training loss: 1.8288697901908315
Validation loss: 2.530814698548137

Epoch: 5| Step: 6
Training loss: 1.9608833943839827
Validation loss: 2.463386064310452

Epoch: 5| Step: 7
Training loss: 1.7554258292926612
Validation loss: 2.516008572923158

Epoch: 5| Step: 8
Training loss: 2.231931724372303
Validation loss: 2.5371224567251294

Epoch: 5| Step: 9
Training loss: 2.924138299241474
Validation loss: 2.5474971721185495

Epoch: 5| Step: 10
Training loss: 2.033617019666737
Validation loss: 2.5317910993578856

Epoch: 5| Step: 11
Training loss: 2.338319514427037
Validation loss: 2.54451543139174

Epoch: 104| Step: 0
Training loss: 2.124180130714476
Validation loss: 2.49265022924804

Epoch: 5| Step: 1
Training loss: 2.309136289820993
Validation loss: 2.6006474952608

Epoch: 5| Step: 2
Training loss: 1.781481276104067
Validation loss: 2.5757543549904263

Epoch: 5| Step: 3
Training loss: 2.246589406927281
Validation loss: 2.5689142824345197

Epoch: 5| Step: 4
Training loss: 1.715022744675781
Validation loss: 2.6464065521546973

Epoch: 5| Step: 5
Training loss: 1.8615167928466423
Validation loss: 2.6641738808655235

Epoch: 5| Step: 6
Training loss: 2.5042031241591287
Validation loss: 2.6469372463901295

Epoch: 5| Step: 7
Training loss: 1.4773627640556133
Validation loss: 2.6117704630745378

Epoch: 5| Step: 8
Training loss: 2.6577326507504457
Validation loss: 2.6219676986875364

Epoch: 5| Step: 9
Training loss: 2.0889183205815
Validation loss: 2.4979783069385384

Epoch: 5| Step: 10
Training loss: 1.944069522709465
Validation loss: 2.495888941903712

Epoch: 5| Step: 11
Training loss: 1.3006440511295345
Validation loss: 2.4629328353777904

Epoch: 105| Step: 0
Training loss: 1.6976284258300693
Validation loss: 2.5446058766586748

Epoch: 5| Step: 1
Training loss: 1.5257387435625367
Validation loss: 2.5450449533433237

Epoch: 5| Step: 2
Training loss: 2.5612090045409035
Validation loss: 2.567918545756678

Epoch: 5| Step: 3
Training loss: 1.742335976059985
Validation loss: 2.5646341361171774

Epoch: 5| Step: 4
Training loss: 2.1923501876748497
Validation loss: 2.517238851552673

Epoch: 5| Step: 5
Training loss: 1.8377685506333548
Validation loss: 2.5324342178859087

Epoch: 5| Step: 6
Training loss: 1.8511146615454697
Validation loss: 2.5116756152715243

Epoch: 5| Step: 7
Training loss: 2.3759957284150435
Validation loss: 2.529034158816619

Epoch: 5| Step: 8
Training loss: 1.8544206409604038
Validation loss: 2.569738325862504

Epoch: 5| Step: 9
Training loss: 2.12638293873908
Validation loss: 2.5674179691902954

Epoch: 5| Step: 10
Training loss: 2.7132247378513226
Validation loss: 2.545283497051298

Epoch: 5| Step: 11
Training loss: 1.9378834621833017
Validation loss: 2.5525291728146944

Epoch: 106| Step: 0
Training loss: 1.6299455652333237
Validation loss: 2.6091534678518147

Epoch: 5| Step: 1
Training loss: 2.127180887713298
Validation loss: 2.53841720988713

Epoch: 5| Step: 2
Training loss: 2.111138404982069
Validation loss: 2.5387656796408034

Epoch: 5| Step: 3
Training loss: 1.9348812248188503
Validation loss: 2.5555501020126847

Epoch: 5| Step: 4
Training loss: 2.6444805822209494
Validation loss: 2.566522445641748

Epoch: 5| Step: 5
Training loss: 1.5813799235528339
Validation loss: 2.5691388435313125

Epoch: 5| Step: 6
Training loss: 1.781825056443196
Validation loss: 2.539843981862241

Epoch: 5| Step: 7
Training loss: 2.0312092703623876
Validation loss: 2.580185939202415

Epoch: 5| Step: 8
Training loss: 1.9538234224880244
Validation loss: 2.5120376811580214

Epoch: 5| Step: 9
Training loss: 1.8118305943269262
Validation loss: 2.549269231479

Epoch: 5| Step: 10
Training loss: 2.0263871892838137
Validation loss: 2.5902062647109227

Epoch: 5| Step: 11
Training loss: 2.1411711281559977
Validation loss: 2.5317169747702173

Epoch: 107| Step: 0
Training loss: 2.249567838067758
Validation loss: 2.529616280005368

Epoch: 5| Step: 1
Training loss: 2.6272495258551207
Validation loss: 2.524813191424715

Epoch: 5| Step: 2
Training loss: 2.0807723771734166
Validation loss: 2.5325191008602834

Epoch: 5| Step: 3
Training loss: 1.4579361056703284
Validation loss: 2.5654041999099695

Epoch: 5| Step: 4
Training loss: 1.4688918674212441
Validation loss: 2.4698210819208324

Epoch: 5| Step: 5
Training loss: 1.8484000065951913
Validation loss: 2.5991849946976706

Epoch: 5| Step: 6
Training loss: 1.934209367257989
Validation loss: 2.538231072869668

Epoch: 5| Step: 7
Training loss: 1.7314186675059589
Validation loss: 2.535016722677276

Epoch: 5| Step: 8
Training loss: 1.6507083383860877
Validation loss: 2.5214689822112484

Epoch: 5| Step: 9
Training loss: 2.466292401436031
Validation loss: 2.5382410256222045

Epoch: 5| Step: 10
Training loss: 1.9888698103976494
Validation loss: 2.5252691064143318

Epoch: 5| Step: 11
Training loss: 1.5752746221509668
Validation loss: 2.511093872714677

Epoch: 108| Step: 0
Training loss: 1.878971598355211
Validation loss: 2.5613288684304973

Epoch: 5| Step: 1
Training loss: 1.9807152829789956
Validation loss: 2.5564420820661655

Epoch: 5| Step: 2
Training loss: 1.5929747547225441
Validation loss: 2.595732371804386

Epoch: 5| Step: 3
Training loss: 2.0242001778896417
Validation loss: 2.6124789304050964

Epoch: 5| Step: 4
Training loss: 2.098353776092371
Validation loss: 2.5913534122815616

Epoch: 5| Step: 5
Training loss: 1.9611059473646344
Validation loss: 2.618971756382399

Epoch: 5| Step: 6
Training loss: 2.473188538832918
Validation loss: 2.56575819607554

Epoch: 5| Step: 7
Training loss: 1.8283760354901124
Validation loss: 2.5774348905524813

Epoch: 5| Step: 8
Training loss: 2.693849205084406
Validation loss: 2.5728560947644805

Epoch: 5| Step: 9
Training loss: 1.4556793404538382
Validation loss: 2.588742815692633

Epoch: 5| Step: 10
Training loss: 1.9089084910685372
Validation loss: 2.572168312172664

Epoch: 5| Step: 11
Training loss: 1.9103375370301323
Validation loss: 2.5806773527290074

Epoch: 109| Step: 0
Training loss: 2.0962061353903962
Validation loss: 2.5399735679527735

Epoch: 5| Step: 1
Training loss: 1.9928009285545254
Validation loss: 2.6585774229409442

Epoch: 5| Step: 2
Training loss: 2.252269553908487
Validation loss: 2.541073035398691

Epoch: 5| Step: 3
Training loss: 2.5632568730268024
Validation loss: 2.6052251965997524

Epoch: 5| Step: 4
Training loss: 2.2361301384452634
Validation loss: 2.4924990978386004

Epoch: 5| Step: 5
Training loss: 1.830765016149615
Validation loss: 2.542402029491126

Epoch: 5| Step: 6
Training loss: 2.1330372898009533
Validation loss: 2.4699582833011813

Epoch: 5| Step: 7
Training loss: 1.4729439128134476
Validation loss: 2.6010600398103105

Epoch: 5| Step: 8
Training loss: 2.3556131853195503
Validation loss: 2.5144885045027303

Epoch: 5| Step: 9
Training loss: 1.9009426840178907
Validation loss: 2.580197154670148

Epoch: 5| Step: 10
Training loss: 1.3833560629589745
Validation loss: 2.5522469500558556

Epoch: 5| Step: 11
Training loss: 1.2081662862781233
Validation loss: 2.4672586346631507

Epoch: 110| Step: 0
Training loss: 1.96123985603972
Validation loss: 2.6048539411902127

Epoch: 5| Step: 1
Training loss: 1.5633651626996008
Validation loss: 2.5458391380451992

Epoch: 5| Step: 2
Training loss: 2.2265535053272267
Validation loss: 2.4993784568949047

Epoch: 5| Step: 3
Training loss: 1.45185107102629
Validation loss: 2.5006679715423754

Epoch: 5| Step: 4
Training loss: 1.6026946741366115
Validation loss: 2.5847154209364747

Epoch: 5| Step: 5
Training loss: 2.28259216958139
Validation loss: 2.4850892133964178

Epoch: 5| Step: 6
Training loss: 2.0514342803283627
Validation loss: 2.5407689742318484

Epoch: 5| Step: 7
Training loss: 2.1468164605345676
Validation loss: 2.5249541068391532

Epoch: 5| Step: 8
Training loss: 2.350568085853484
Validation loss: 2.5242492071022475

Epoch: 5| Step: 9
Training loss: 1.7983206862652206
Validation loss: 2.560669625194257

Epoch: 5| Step: 10
Training loss: 2.122779808337421
Validation loss: 2.4744944235887307

Epoch: 5| Step: 11
Training loss: 1.5290701784603407
Validation loss: 2.53631075103996

Epoch: 111| Step: 0
Training loss: 2.142888563924849
Validation loss: 2.5498246448193114

Epoch: 5| Step: 1
Training loss: 1.6882705342148212
Validation loss: 2.52285989896464

Epoch: 5| Step: 2
Training loss: 2.0629297444542796
Validation loss: 2.495808365675195

Epoch: 5| Step: 3
Training loss: 1.5891591690652083
Validation loss: 2.551012843602506

Epoch: 5| Step: 4
Training loss: 1.8798423544753542
Validation loss: 2.4705125898591014

Epoch: 5| Step: 5
Training loss: 2.2893713003967537
Validation loss: 2.496935364745869

Epoch: 5| Step: 6
Training loss: 2.0698203599537925
Validation loss: 2.548657150672705

Epoch: 5| Step: 7
Training loss: 1.761048656837703
Validation loss: 2.488954629614064

Epoch: 5| Step: 8
Training loss: 2.207019799126821
Validation loss: 2.512588267412784

Epoch: 5| Step: 9
Training loss: 1.7549970671365691
Validation loss: 2.5900448873980007

Epoch: 5| Step: 10
Training loss: 1.840384304714123
Validation loss: 2.5080622848704195

Epoch: 5| Step: 11
Training loss: 2.59515545006413
Validation loss: 2.5620278605805717

Epoch: 112| Step: 0
Training loss: 2.4987095363254666
Validation loss: 2.5816173750783356

Epoch: 5| Step: 1
Training loss: 1.8029408775745184
Validation loss: 2.5027907411465633

Epoch: 5| Step: 2
Training loss: 2.1633437302295007
Validation loss: 2.5276364801084936

Epoch: 5| Step: 3
Training loss: 1.878369990411121
Validation loss: 2.548669958748946

Epoch: 5| Step: 4
Training loss: 1.9832493149835424
Validation loss: 2.490295616842942

Epoch: 5| Step: 5
Training loss: 2.172036034631121
Validation loss: 2.5523034480921667

Epoch: 5| Step: 6
Training loss: 1.7420386006998023
Validation loss: 2.5235441557367717

Epoch: 5| Step: 7
Training loss: 1.8274955644044915
Validation loss: 2.596346815297169

Epoch: 5| Step: 8
Training loss: 1.5668754350610654
Validation loss: 2.6055631110525312

Epoch: 5| Step: 9
Training loss: 1.0836259678985818
Validation loss: 2.552547768093867

Epoch: 5| Step: 10
Training loss: 2.316365285064102
Validation loss: 2.577307110915594

Epoch: 5| Step: 11
Training loss: 1.687290107954613
Validation loss: 2.5423228961860715

Epoch: 113| Step: 0
Training loss: 1.6041907354093279
Validation loss: 2.5591029390925666

Epoch: 5| Step: 1
Training loss: 2.055663946518702
Validation loss: 2.5761791708271486

Epoch: 5| Step: 2
Training loss: 1.6858296074341304
Validation loss: 2.6422260178597625

Epoch: 5| Step: 3
Training loss: 1.6859232989429926
Validation loss: 2.7439322866541147

Epoch: 5| Step: 4
Training loss: 2.8706436323395494
Validation loss: 2.7108988580505664

Epoch: 5| Step: 5
Training loss: 1.7668543898814455
Validation loss: 2.692198844733738

Epoch: 5| Step: 6
Training loss: 2.884874387019621
Validation loss: 2.7698334177999127

Epoch: 5| Step: 7
Training loss: 1.69634521250889
Validation loss: 2.670371061768851

Epoch: 5| Step: 8
Training loss: 1.803035690237885
Validation loss: 2.5637805189340104

Epoch: 5| Step: 9
Training loss: 1.9008558905418542
Validation loss: 2.6040139013623493

Epoch: 5| Step: 10
Training loss: 1.809810550427677
Validation loss: 2.5380572867455142

Epoch: 5| Step: 11
Training loss: 1.4951722815769657
Validation loss: 2.5652900370272955

Epoch: 114| Step: 0
Training loss: 2.021635925214387
Validation loss: 2.5916271638057315

Epoch: 5| Step: 1
Training loss: 1.797314266747975
Validation loss: 2.6645390782522473

Epoch: 5| Step: 2
Training loss: 2.1159004156119026
Validation loss: 2.6256135685172515

Epoch: 5| Step: 3
Training loss: 2.306480822086715
Validation loss: 2.558316180288692

Epoch: 5| Step: 4
Training loss: 1.8565790006851075
Validation loss: 2.587195379567203

Epoch: 5| Step: 5
Training loss: 2.6695576930780804
Validation loss: 2.6005113404524303

Epoch: 5| Step: 6
Training loss: 2.025855074595456
Validation loss: 2.5465235691962205

Epoch: 5| Step: 7
Training loss: 1.770600726240305
Validation loss: 2.6048333509923056

Epoch: 5| Step: 8
Training loss: 1.7492821447241111
Validation loss: 2.5464312394987454

Epoch: 5| Step: 9
Training loss: 1.8129841388107468
Validation loss: 2.549638649014743

Epoch: 5| Step: 10
Training loss: 1.5556314181191206
Validation loss: 2.57783263504255

Epoch: 5| Step: 11
Training loss: 2.431098552782228
Validation loss: 2.6114173594302224

Epoch: 115| Step: 0
Training loss: 2.1308466196771074
Validation loss: 2.589396350357313

Epoch: 5| Step: 1
Training loss: 1.5993090150793596
Validation loss: 2.5815229853445927

Epoch: 5| Step: 2
Training loss: 2.1126784841765303
Validation loss: 2.6206677143174

Epoch: 5| Step: 3
Training loss: 1.697926488118542
Validation loss: 2.586112470748258

Epoch: 5| Step: 4
Training loss: 1.988809631527805
Validation loss: 2.619832826648751

Epoch: 5| Step: 5
Training loss: 1.5240615740224353
Validation loss: 2.6034102956342373

Epoch: 5| Step: 6
Training loss: 1.9329257003705747
Validation loss: 2.6283762200540877

Epoch: 5| Step: 7
Training loss: 1.8954178141670615
Validation loss: 2.599165620863756

Epoch: 5| Step: 8
Training loss: 1.7005510390803724
Validation loss: 2.542510714594327

Epoch: 5| Step: 9
Training loss: 2.078648780840418
Validation loss: 2.570639352780807

Epoch: 5| Step: 10
Training loss: 2.1437504359653574
Validation loss: 2.599130805694535

Epoch: 5| Step: 11
Training loss: 4.086349203983249
Validation loss: 2.517590144177796

Epoch: 116| Step: 0
Training loss: 2.218694444417529
Validation loss: 2.548479620053169

Epoch: 5| Step: 1
Training loss: 2.564399015577761
Validation loss: 2.580191152302646

Epoch: 5| Step: 2
Training loss: 1.6176313445404054
Validation loss: 2.5928291118461018

Epoch: 5| Step: 3
Training loss: 2.1877706087850752
Validation loss: 2.478818185073336

Epoch: 5| Step: 4
Training loss: 2.316532742679562
Validation loss: 2.597421265492838

Epoch: 5| Step: 5
Training loss: 1.494641428274685
Validation loss: 2.5331588894195742

Epoch: 5| Step: 6
Training loss: 1.3504976697475832
Validation loss: 2.5588531207369742

Epoch: 5| Step: 7
Training loss: 1.7817433661118864
Validation loss: 2.535468205252301

Epoch: 5| Step: 8
Training loss: 1.5136243062081944
Validation loss: 2.569989347386331

Epoch: 5| Step: 9
Training loss: 2.08020328628725
Validation loss: 2.639635464957111

Epoch: 5| Step: 10
Training loss: 1.601058806321632
Validation loss: 2.6635267776194453

Epoch: 5| Step: 11
Training loss: 1.2032104065541427
Validation loss: 2.558403404085991

Epoch: 117| Step: 0
Training loss: 1.8057605806326182
Validation loss: 2.5662380223367105

Epoch: 5| Step: 1
Training loss: 1.7874800834346483
Validation loss: 2.583232032932933

Epoch: 5| Step: 2
Training loss: 1.8731401756366843
Validation loss: 2.5637047191993814

Epoch: 5| Step: 3
Training loss: 2.2338753521739507
Validation loss: 2.563023283105269

Epoch: 5| Step: 4
Training loss: 1.8089999243344554
Validation loss: 2.5902536181998457

Epoch: 5| Step: 5
Training loss: 1.7948043170408594
Validation loss: 2.5580283319180808

Epoch: 5| Step: 6
Training loss: 2.21272685294241
Validation loss: 2.5827675297201647

Epoch: 5| Step: 7
Training loss: 2.0829035379212626
Validation loss: 2.5865674514480386

Epoch: 5| Step: 8
Training loss: 1.8280320103136054
Validation loss: 2.575615769588596

Epoch: 5| Step: 9
Training loss: 1.4506346990613626
Validation loss: 2.5627756629544347

Epoch: 5| Step: 10
Training loss: 1.8724671740640442
Validation loss: 2.59318606439215

Epoch: 5| Step: 11
Training loss: 1.9648203308044554
Validation loss: 2.5726752508986843

Epoch: 118| Step: 0
Training loss: 1.9516482454250945
Validation loss: 2.5996619337936946

Epoch: 5| Step: 1
Training loss: 2.2324687589059264
Validation loss: 2.5305170206724745

Epoch: 5| Step: 2
Training loss: 1.8690702132113877
Validation loss: 2.5514658057537742

Epoch: 5| Step: 3
Training loss: 1.929666742993119
Validation loss: 2.510002708864207

Epoch: 5| Step: 4
Training loss: 1.6402075826878257
Validation loss: 2.4633146602140528

Epoch: 5| Step: 5
Training loss: 2.5052581803298963
Validation loss: 2.5273467137094814

Epoch: 5| Step: 6
Training loss: 1.7565068121652307
Validation loss: 2.5325774177650464

Epoch: 5| Step: 7
Training loss: 1.7483162272840451
Validation loss: 2.576437523106635

Epoch: 5| Step: 8
Training loss: 1.6721439323531246
Validation loss: 2.5518444040261086

Epoch: 5| Step: 9
Training loss: 1.4954065084054802
Validation loss: 2.5192080209086343

Epoch: 5| Step: 10
Training loss: 2.0684326850499652
Validation loss: 2.5859140777295466

Epoch: 5| Step: 11
Training loss: 1.7014182401793914
Validation loss: 2.518523637240741

Epoch: 119| Step: 0
Training loss: 1.409533249456444
Validation loss: 2.491672251343183

Epoch: 5| Step: 1
Training loss: 1.9954589909464313
Validation loss: 2.5325638222442763

Epoch: 5| Step: 2
Training loss: 2.0702308494733344
Validation loss: 2.6150978362318247

Epoch: 5| Step: 3
Training loss: 1.684287085565517
Validation loss: 2.5895880471757216

Epoch: 5| Step: 4
Training loss: 1.905722248001933
Validation loss: 2.519823539398791

Epoch: 5| Step: 5
Training loss: 1.8533613906538722
Validation loss: 2.4997286251916955

Epoch: 5| Step: 6
Training loss: 2.5847354180939046
Validation loss: 2.573055747490641

Epoch: 5| Step: 7
Training loss: 1.9688740040312382
Validation loss: 2.550859084993731

Epoch: 5| Step: 8
Training loss: 1.513591779004851
Validation loss: 2.576656096489393

Epoch: 5| Step: 9
Training loss: 1.6835609662964208
Validation loss: 2.5726042543669627

Epoch: 5| Step: 10
Training loss: 1.4570096502671763
Validation loss: 2.504000348065203

Epoch: 5| Step: 11
Training loss: 1.7433882197874915
Validation loss: 2.5748836389965817

Epoch: 120| Step: 0
Training loss: 1.6849081833950352
Validation loss: 2.5764683843711556

Epoch: 5| Step: 1
Training loss: 1.4737589221583969
Validation loss: 2.549428073629559

Epoch: 5| Step: 2
Training loss: 1.9849999712696602
Validation loss: 2.5703130720112792

Epoch: 5| Step: 3
Training loss: 1.8312066343204816
Validation loss: 2.570553773109174

Epoch: 5| Step: 4
Training loss: 2.087703343155688
Validation loss: 2.567243837097123

Epoch: 5| Step: 5
Training loss: 1.4011894724804055
Validation loss: 2.625610556819654

Epoch: 5| Step: 6
Training loss: 2.188429934521118
Validation loss: 2.5373838186679736

Epoch: 5| Step: 7
Training loss: 1.4913595409082878
Validation loss: 2.494138020130969

Epoch: 5| Step: 8
Training loss: 2.422891809451342
Validation loss: 2.6702597794258605

Epoch: 5| Step: 9
Training loss: 1.8923594188002117
Validation loss: 2.4902044396689287

Epoch: 5| Step: 10
Training loss: 1.7218981954185741
Validation loss: 2.592256686816606

Epoch: 5| Step: 11
Training loss: 2.03270493266035
Validation loss: 2.574119670159407

Epoch: 121| Step: 0
Training loss: 2.004573718296172
Validation loss: 2.6003217019754685

Epoch: 5| Step: 1
Training loss: 2.2916297447235787
Validation loss: 2.5619797488622487

Epoch: 5| Step: 2
Training loss: 1.4204356695134759
Validation loss: 2.623067920607014

Epoch: 5| Step: 3
Training loss: 2.0239628290298906
Validation loss: 2.4843934136434047

Epoch: 5| Step: 4
Training loss: 1.790097399571088
Validation loss: 2.5757797517348857

Epoch: 5| Step: 5
Training loss: 1.8512345679526638
Validation loss: 2.495527056867409

Epoch: 5| Step: 6
Training loss: 1.6296210973127725
Validation loss: 2.561872095232177

Epoch: 5| Step: 7
Training loss: 1.3406676047786754
Validation loss: 2.5820755986008628

Epoch: 5| Step: 8
Training loss: 2.069571999609137
Validation loss: 2.644395641642147

Epoch: 5| Step: 9
Training loss: 2.259652519857433
Validation loss: 2.5450576917739465

Epoch: 5| Step: 10
Training loss: 1.6524755547081722
Validation loss: 2.5528032156883276

Epoch: 5| Step: 11
Training loss: 1.4008681415557782
Validation loss: 2.498399432737036

Epoch: 122| Step: 0
Training loss: 1.6220955200808858
Validation loss: 2.560216553092023

Epoch: 5| Step: 1
Training loss: 1.609069573021429
Validation loss: 2.591135591777453

Epoch: 5| Step: 2
Training loss: 1.438174960028322
Validation loss: 2.517621241462465

Epoch: 5| Step: 3
Training loss: 1.7658151169767886
Validation loss: 2.6292766179783764

Epoch: 5| Step: 4
Training loss: 1.5960770615924997
Validation loss: 2.636110068813324

Epoch: 5| Step: 5
Training loss: 2.567170329857846
Validation loss: 2.56647453817231

Epoch: 5| Step: 6
Training loss: 1.6334484997195233
Validation loss: 2.629296589818635

Epoch: 5| Step: 7
Training loss: 1.7795634399793143
Validation loss: 2.472862138658514

Epoch: 5| Step: 8
Training loss: 1.8167289201178323
Validation loss: 2.615277245122453

Epoch: 5| Step: 9
Training loss: 1.9136318422963028
Validation loss: 2.6078000179027856

Epoch: 5| Step: 10
Training loss: 1.8426976190848185
Validation loss: 2.6521289684168097

Epoch: 5| Step: 11
Training loss: 3.058277566870834
Validation loss: 2.5980117669297904

Epoch: 123| Step: 0
Training loss: 1.052216071388701
Validation loss: 2.6073809978886064

Epoch: 5| Step: 1
Training loss: 1.6443774226137104
Validation loss: 2.543175618107085

Epoch: 5| Step: 2
Training loss: 1.474551653205954
Validation loss: 2.6473493957099095

Epoch: 5| Step: 3
Training loss: 2.2573246940399403
Validation loss: 2.5734052014094924

Epoch: 5| Step: 4
Training loss: 1.6764123968530267
Validation loss: 2.5097626128221933

Epoch: 5| Step: 5
Training loss: 1.929870473241028
Validation loss: 2.5495912152541678

Epoch: 5| Step: 6
Training loss: 2.1056012340188395
Validation loss: 2.647157699308542

Epoch: 5| Step: 7
Training loss: 1.8436008974983147
Validation loss: 2.584210471221052

Epoch: 5| Step: 8
Training loss: 1.736736991810546
Validation loss: 2.5636333696150393

Epoch: 5| Step: 9
Training loss: 2.274159320145209
Validation loss: 2.5188223637518465

Epoch: 5| Step: 10
Training loss: 1.5500211222040055
Validation loss: 2.6789928051098557

Epoch: 5| Step: 11
Training loss: 1.6461418764006917
Validation loss: 2.6162538333882357

Epoch: 124| Step: 0
Training loss: 1.8019050848093707
Validation loss: 2.5596154965911397

Epoch: 5| Step: 1
Training loss: 1.7058041000408177
Validation loss: 2.58858247925625

Epoch: 5| Step: 2
Training loss: 1.815915802402748
Validation loss: 2.558296077583331

Epoch: 5| Step: 3
Training loss: 1.8091734910669621
Validation loss: 2.6026210101635248

Epoch: 5| Step: 4
Training loss: 2.6088075306301457
Validation loss: 2.682167273788164

Epoch: 5| Step: 5
Training loss: 1.2385975526992172
Validation loss: 2.6035238725169587

Epoch: 5| Step: 6
Training loss: 1.8204518539067651
Validation loss: 2.706896893725348

Epoch: 5| Step: 7
Training loss: 1.552027050593686
Validation loss: 2.5011308734898616

Epoch: 5| Step: 8
Training loss: 1.6811038411079824
Validation loss: 2.549223041754884

Epoch: 5| Step: 9
Training loss: 1.945672978472257
Validation loss: 2.547730881277209

Epoch: 5| Step: 10
Training loss: 1.967908104010934
Validation loss: 2.5910923950716866

Epoch: 5| Step: 11
Training loss: 1.8210262487364195
Validation loss: 2.5511775582754064

Epoch: 125| Step: 0
Training loss: 1.6041390140016125
Validation loss: 2.593606558054409

Epoch: 5| Step: 1
Training loss: 2.6771599329418243
Validation loss: 2.4956274338259834

Epoch: 5| Step: 2
Training loss: 1.7672178122486641
Validation loss: 2.551957490633992

Epoch: 5| Step: 3
Training loss: 1.6862184815398544
Validation loss: 2.643206600349699

Epoch: 5| Step: 4
Training loss: 1.5940852841018613
Validation loss: 2.571995702903089

Epoch: 5| Step: 5
Training loss: 1.3687011622943683
Validation loss: 2.583228014265527

Epoch: 5| Step: 6
Training loss: 1.6236408124690138
Validation loss: 2.624070564985403

Epoch: 5| Step: 7
Training loss: 1.4496005395955647
Validation loss: 2.6028098971620692

Epoch: 5| Step: 8
Training loss: 1.7787366837346883
Validation loss: 2.5707462876193627

Epoch: 5| Step: 9
Training loss: 2.1531999550051384
Validation loss: 2.4983438728352816

Epoch: 5| Step: 10
Training loss: 1.9883290343172848
Validation loss: 2.552584421179669

Epoch: 5| Step: 11
Training loss: 2.2532950751124723
Validation loss: 2.624731598862201

Epoch: 126| Step: 0
Training loss: 1.9350361693991496
Validation loss: 2.542789075903805

Epoch: 5| Step: 1
Training loss: 1.6210121961554882
Validation loss: 2.6327883703256143

Epoch: 5| Step: 2
Training loss: 1.5710493038801068
Validation loss: 2.616571534203202

Epoch: 5| Step: 3
Training loss: 1.3432101562543168
Validation loss: 2.5897202076316987

Epoch: 5| Step: 4
Training loss: 1.797259414022053
Validation loss: 2.5806632811408656

Epoch: 5| Step: 5
Training loss: 1.7821868306786974
Validation loss: 2.591375968847421

Epoch: 5| Step: 6
Training loss: 1.7191885648742078
Validation loss: 2.5978145809250144

Epoch: 5| Step: 7
Training loss: 2.076447003025136
Validation loss: 2.5476551460264503

Epoch: 5| Step: 8
Training loss: 1.4870765596240665
Validation loss: 2.5989578045759765

Epoch: 5| Step: 9
Training loss: 1.9284699958285043
Validation loss: 2.7111701792188887

Epoch: 5| Step: 10
Training loss: 2.2767532132604527
Validation loss: 2.5636657567522536

Epoch: 5| Step: 11
Training loss: 1.485394017642974
Validation loss: 2.5214180793586367

Epoch: 127| Step: 0
Training loss: 1.3955283140114068
Validation loss: 2.56045365618522

Epoch: 5| Step: 1
Training loss: 1.4827600628632458
Validation loss: 2.5831774131317875

Epoch: 5| Step: 2
Training loss: 1.9760254141528468
Validation loss: 2.600971429711915

Epoch: 5| Step: 3
Training loss: 1.5184570281097256
Validation loss: 2.666584797188565

Epoch: 5| Step: 4
Training loss: 1.3686395835757965
Validation loss: 2.6131449893386676

Epoch: 5| Step: 5
Training loss: 2.0759676871458597
Validation loss: 2.5823319452880393

Epoch: 5| Step: 6
Training loss: 1.899042731617377
Validation loss: 2.6240583956242163

Epoch: 5| Step: 7
Training loss: 1.6572262747679478
Validation loss: 2.5547158923112225

Epoch: 5| Step: 8
Training loss: 2.331385230675324
Validation loss: 2.5845905034209067

Epoch: 5| Step: 9
Training loss: 1.4622641674861339
Validation loss: 2.6134450544672094

Epoch: 5| Step: 10
Training loss: 1.7657912184532882
Validation loss: 2.612252428714532

Epoch: 5| Step: 11
Training loss: 1.7427567035402203
Validation loss: 2.638776350270785

Epoch: 128| Step: 0
Training loss: 1.8778657629566318
Validation loss: 2.5787430764107055

Epoch: 5| Step: 1
Training loss: 1.9996480632123705
Validation loss: 2.5220932465459347

Epoch: 5| Step: 2
Training loss: 1.7019239617966693
Validation loss: 2.6109880650614143

Epoch: 5| Step: 3
Training loss: 1.7295553927124079
Validation loss: 2.571086100425225

Epoch: 5| Step: 4
Training loss: 1.8792093710547555
Validation loss: 2.5568665360203653

Epoch: 5| Step: 5
Training loss: 1.533066586774646
Validation loss: 2.512476516569604

Epoch: 5| Step: 6
Training loss: 2.275262159396568
Validation loss: 2.5913258335078435

Epoch: 5| Step: 7
Training loss: 1.8096269659405981
Validation loss: 2.5995077547521572

Epoch: 5| Step: 8
Training loss: 1.751848198545836
Validation loss: 2.61473779994624

Epoch: 5| Step: 9
Training loss: 1.4837424285618361
Validation loss: 2.5598729980836947

Epoch: 5| Step: 10
Training loss: 1.2436546442484613
Validation loss: 2.6295865875725295

Epoch: 5| Step: 11
Training loss: 1.0307782568027255
Validation loss: 2.592344416428822

Epoch: 129| Step: 0
Training loss: 1.9114591995223436
Validation loss: 2.6017653545607

Epoch: 5| Step: 1
Training loss: 1.5622816314693748
Validation loss: 2.5311325618988816

Epoch: 5| Step: 2
Training loss: 1.5259826527230718
Validation loss: 2.5612918323906655

Epoch: 5| Step: 3
Training loss: 1.6174241044930566
Validation loss: 2.596399267959795

Epoch: 5| Step: 4
Training loss: 2.1263562530575615
Validation loss: 2.6315938164684107

Epoch: 5| Step: 5
Training loss: 1.7148194191842407
Validation loss: 2.5608101444413083

Epoch: 5| Step: 6
Training loss: 2.0619663357285285
Validation loss: 2.5654625456716564

Epoch: 5| Step: 7
Training loss: 1.4832784517543707
Validation loss: 2.616512898667078

Epoch: 5| Step: 8
Training loss: 1.626382093291397
Validation loss: 2.493672294330234

Epoch: 5| Step: 9
Training loss: 1.7859676862486797
Validation loss: 2.5672005750369986

Epoch: 5| Step: 10
Training loss: 1.2977534616564161
Validation loss: 2.6208552419255184

Epoch: 5| Step: 11
Training loss: 2.4172230003427964
Validation loss: 2.663655519395634

Epoch: 130| Step: 0
Training loss: 1.7790851487983381
Validation loss: 2.6558750897781542

Epoch: 5| Step: 1
Training loss: 1.4778583632911046
Validation loss: 2.652585961917106

Epoch: 5| Step: 2
Training loss: 1.7809280639976792
Validation loss: 2.727822479918525

Epoch: 5| Step: 3
Training loss: 1.6652783890271365
Validation loss: 2.736215832820646

Epoch: 5| Step: 4
Training loss: 2.4075692263718915
Validation loss: 2.6770135459759055

Epoch: 5| Step: 5
Training loss: 1.6603430788716182
Validation loss: 2.578982451448596

Epoch: 5| Step: 6
Training loss: 1.3294471442800986
Validation loss: 2.5534824208312483

Epoch: 5| Step: 7
Training loss: 2.075738210235491
Validation loss: 2.5917367705423953

Epoch: 5| Step: 8
Training loss: 1.8356407412671347
Validation loss: 2.615595227873072

Epoch: 5| Step: 9
Training loss: 0.9722008922295792
Validation loss: 2.6234850485549956

Epoch: 5| Step: 10
Training loss: 1.994176492545946
Validation loss: 2.6129010070694894

Epoch: 5| Step: 11
Training loss: 1.3309234308133768
Validation loss: 2.576820590709056

Epoch: 131| Step: 0
Training loss: 2.636937472843688
Validation loss: 2.549351383444931

Epoch: 5| Step: 1
Training loss: 1.7379676107279247
Validation loss: 2.688492240633724

Epoch: 5| Step: 2
Training loss: 1.5757498666629193
Validation loss: 2.6709834836708404

Epoch: 5| Step: 3
Training loss: 1.4662472117886127
Validation loss: 2.672154817187623

Epoch: 5| Step: 4
Training loss: 2.2847061105125914
Validation loss: 2.687997561238664

Epoch: 5| Step: 5
Training loss: 1.3399522920912394
Validation loss: 2.6291331079480402

Epoch: 5| Step: 6
Training loss: 1.5891674205909598
Validation loss: 2.5774211192401904

Epoch: 5| Step: 7
Training loss: 1.5111908693317453
Validation loss: 2.6069727707323556

Epoch: 5| Step: 8
Training loss: 1.6486379492500831
Validation loss: 2.6055111212004114

Epoch: 5| Step: 9
Training loss: 1.5478135161432127
Validation loss: 2.570965557366466

Epoch: 5| Step: 10
Training loss: 1.7406531449787082
Validation loss: 2.601616283238839

Epoch: 5| Step: 11
Training loss: 1.355786508917295
Validation loss: 2.478817884503448

Epoch: 132| Step: 0
Training loss: 1.5223051900520952
Validation loss: 2.562311754833142

Epoch: 5| Step: 1
Training loss: 1.9298958607975611
Validation loss: 2.5975273884335004

Epoch: 5| Step: 2
Training loss: 2.006161972443944
Validation loss: 2.6609556459953163

Epoch: 5| Step: 3
Training loss: 1.3087144482874682
Validation loss: 2.652009121699826

Epoch: 5| Step: 4
Training loss: 2.1160833991909542
Validation loss: 2.6790482821692234

Epoch: 5| Step: 5
Training loss: 1.9624442584631732
Validation loss: 2.643823142877357

Epoch: 5| Step: 6
Training loss: 1.3756685365670795
Validation loss: 2.570262923917202

Epoch: 5| Step: 7
Training loss: 1.6250064556287034
Validation loss: 2.5464927292844894

Epoch: 5| Step: 8
Training loss: 1.4216951528977044
Validation loss: 2.6306963452124634

Epoch: 5| Step: 9
Training loss: 1.9881076099890782
Validation loss: 2.486738300476339

Epoch: 5| Step: 10
Training loss: 1.8420951011205327
Validation loss: 2.5151173255077452

Epoch: 5| Step: 11
Training loss: 1.4807682589928852
Validation loss: 2.58612574250407

Epoch: 133| Step: 0
Training loss: 1.5425261430055144
Validation loss: 2.637048477466472

Epoch: 5| Step: 1
Training loss: 1.082620178141447
Validation loss: 2.534675415396537

Epoch: 5| Step: 2
Training loss: 1.3295053377449624
Validation loss: 2.587537088297288

Epoch: 5| Step: 3
Training loss: 1.5884199585697465
Validation loss: 2.5759122157064014

Epoch: 5| Step: 4
Training loss: 1.7809569134434764
Validation loss: 2.7291226978011864

Epoch: 5| Step: 5
Training loss: 2.195798338213701
Validation loss: 2.5851832516288886

Epoch: 5| Step: 6
Training loss: 1.5060203852090726
Validation loss: 2.7170534796601284

Epoch: 5| Step: 7
Training loss: 1.9877017512577497
Validation loss: 2.662276264873201

Epoch: 5| Step: 8
Training loss: 1.451153638270757
Validation loss: 2.606837556018738

Epoch: 5| Step: 9
Training loss: 1.5796982128108328
Validation loss: 2.5992772869233365

Epoch: 5| Step: 10
Training loss: 1.941513457686599
Validation loss: 2.6155547443648546

Epoch: 5| Step: 11
Training loss: 3.120273525279249
Validation loss: 2.4897836913138907

Epoch: 134| Step: 0
Training loss: 1.4062663607175443
Validation loss: 2.617696338741957

Epoch: 5| Step: 1
Training loss: 1.618674806004589
Validation loss: 2.5972148281191623

Epoch: 5| Step: 2
Training loss: 2.2660700919883743
Validation loss: 2.7273261049374233

Epoch: 5| Step: 3
Training loss: 2.023062535011918
Validation loss: 2.746162710323294

Epoch: 5| Step: 4
Training loss: 1.9294460006516228
Validation loss: 2.850406440257781

Epoch: 5| Step: 5
Training loss: 1.494856120812278
Validation loss: 2.688672556616797

Epoch: 5| Step: 6
Training loss: 2.136784247417934
Validation loss: 2.6657465425175735

Epoch: 5| Step: 7
Training loss: 1.6218889974530328
Validation loss: 2.650464110549266

Epoch: 5| Step: 8
Training loss: 1.7435744713384833
Validation loss: 2.6526872078234556

Epoch: 5| Step: 9
Training loss: 1.239114715515021
Validation loss: 2.536226196684986

Epoch: 5| Step: 10
Training loss: 1.645792787591658
Validation loss: 2.5833956008502947

Epoch: 5| Step: 11
Training loss: 1.9114330057931344
Validation loss: 2.745036081124437

Epoch: 135| Step: 0
Training loss: 1.4577626701253152
Validation loss: 2.66384612740144

Epoch: 5| Step: 1
Training loss: 1.7866166900055047
Validation loss: 2.726741271183644

Epoch: 5| Step: 2
Training loss: 1.488886912702005
Validation loss: 2.732907938903778

Epoch: 5| Step: 3
Training loss: 1.7137867791857069
Validation loss: 2.8220139440757035

Epoch: 5| Step: 4
Training loss: 2.2411734916534107
Validation loss: 2.835536939007369

Epoch: 5| Step: 5
Training loss: 1.7629702704958186
Validation loss: 2.7240258288120556

Epoch: 5| Step: 6
Training loss: 2.472496762789467
Validation loss: 2.6897567396654183

Epoch: 5| Step: 7
Training loss: 1.3871043783928814
Validation loss: 2.542213433244195

Epoch: 5| Step: 8
Training loss: 1.8240705997665603
Validation loss: 2.6018112415006844

Epoch: 5| Step: 9
Training loss: 1.8607909637333448
Validation loss: 2.594873120073237

Epoch: 5| Step: 10
Training loss: 1.636353955095725
Validation loss: 2.6521533004409386

Epoch: 5| Step: 11
Training loss: 0.7208902586434491
Validation loss: 2.591354297833652

Epoch: 136| Step: 0
Training loss: 2.257059889229104
Validation loss: 2.659165865082014

Epoch: 5| Step: 1
Training loss: 1.829362368994592
Validation loss: 2.7097545941583694

Epoch: 5| Step: 2
Training loss: 1.753806266398659
Validation loss: 2.6748643961074596

Epoch: 5| Step: 3
Training loss: 1.7687768401680697
Validation loss: 2.572764567205099

Epoch: 5| Step: 4
Training loss: 2.0612920055655026
Validation loss: 2.6205414532681917

Epoch: 5| Step: 5
Training loss: 1.5096891909419867
Validation loss: 2.554067063891703

Epoch: 5| Step: 6
Training loss: 1.1562082437759489
Validation loss: 2.606293955096073

Epoch: 5| Step: 7
Training loss: 1.6636293232499246
Validation loss: 2.6103418238008977

Epoch: 5| Step: 8
Training loss: 1.207286326298108
Validation loss: 2.6321879513023942

Epoch: 5| Step: 9
Training loss: 1.6250213474925548
Validation loss: 2.649566874706174

Epoch: 5| Step: 10
Training loss: 1.8750417068929135
Validation loss: 2.6745469153767942

Epoch: 5| Step: 11
Training loss: 1.738879017434557
Validation loss: 2.7279959247200694

Epoch: 137| Step: 0
Training loss: 1.5702072791531745
Validation loss: 2.6898769468574066

Epoch: 5| Step: 1
Training loss: 1.625157862111317
Validation loss: 2.51750461183976

Epoch: 5| Step: 2
Training loss: 1.7978601823275844
Validation loss: 2.603864840500522

Epoch: 5| Step: 3
Training loss: 1.080619579718583
Validation loss: 2.704694127119332

Epoch: 5| Step: 4
Training loss: 1.0040359710123592
Validation loss: 2.6170313242912036

Epoch: 5| Step: 5
Training loss: 1.7042820351247687
Validation loss: 2.62825259905517

Epoch: 5| Step: 6
Training loss: 1.326530172181019
Validation loss: 2.5700304481481377

Epoch: 5| Step: 7
Training loss: 1.3619912938975454
Validation loss: 2.527154171499325

Epoch: 5| Step: 8
Training loss: 1.3053165678107488
Validation loss: 2.626323249112529

Epoch: 5| Step: 9
Training loss: 1.9231472611401879
Validation loss: 2.6084249369671135

Epoch: 5| Step: 10
Training loss: 2.5269748707447586
Validation loss: 2.589108132002634

Epoch: 5| Step: 11
Training loss: 1.996945074580143
Validation loss: 2.5878262839326234

Epoch: 138| Step: 0
Training loss: 1.8145957537582564
Validation loss: 2.568165114952779

Epoch: 5| Step: 1
Training loss: 1.4442734566174178
Validation loss: 2.6707130716497667

Epoch: 5| Step: 2
Training loss: 1.8452267955545385
Validation loss: 2.669027551248674

Epoch: 5| Step: 3
Training loss: 1.5734159254093194
Validation loss: 2.648395286681254

Epoch: 5| Step: 4
Training loss: 1.536587734484573
Validation loss: 2.695008250585417

Epoch: 5| Step: 5
Training loss: 1.1143591230441354
Validation loss: 2.604370694115325

Epoch: 5| Step: 6
Training loss: 1.3020483495463118
Validation loss: 2.5825809080307756

Epoch: 5| Step: 7
Training loss: 1.471930124987827
Validation loss: 2.6462298243850757

Epoch: 5| Step: 8
Training loss: 1.6416720001340614
Validation loss: 2.620789845221544

Epoch: 5| Step: 9
Training loss: 2.1918986102274642
Validation loss: 2.595303315466595

Epoch: 5| Step: 10
Training loss: 1.6442582363660723
Validation loss: 2.5727833444336548

Epoch: 5| Step: 11
Training loss: 1.489644385022595
Validation loss: 2.654663543413456

Epoch: 139| Step: 0
Training loss: 1.4396818437376169
Validation loss: 2.560604664150185

Epoch: 5| Step: 1
Training loss: 1.7571020428417754
Validation loss: 2.640739039680415

Epoch: 5| Step: 2
Training loss: 1.275220734057588
Validation loss: 2.6636330341357164

Epoch: 5| Step: 3
Training loss: 1.5930459206350818
Validation loss: 2.6353290955440043

Epoch: 5| Step: 4
Training loss: 1.5552789531122764
Validation loss: 2.620342895628747

Epoch: 5| Step: 5
Training loss: 1.7575446030666757
Validation loss: 2.567277850315846

Epoch: 5| Step: 6
Training loss: 1.8639604462204833
Validation loss: 2.667603139554749

Epoch: 5| Step: 7
Training loss: 1.6136483058902702
Validation loss: 2.6347001512751818

Epoch: 5| Step: 8
Training loss: 1.9339054357374872
Validation loss: 2.581350959268978

Epoch: 5| Step: 9
Training loss: 1.3747616474596787
Validation loss: 2.720753004972862

Epoch: 5| Step: 10
Training loss: 1.7292183175090312
Validation loss: 2.6843442797429544

Epoch: 5| Step: 11
Training loss: 1.2073416202842835
Validation loss: 2.599241972577704

Epoch: 140| Step: 0
Training loss: 1.4361717058028207
Validation loss: 2.6487724895041613

Epoch: 5| Step: 1
Training loss: 1.5507598798610223
Validation loss: 2.5906665103073077

Epoch: 5| Step: 2
Training loss: 1.6664305122279628
Validation loss: 2.6590435671747814

Epoch: 5| Step: 3
Training loss: 1.7385984667106107
Validation loss: 2.598163159466202

Epoch: 5| Step: 4
Training loss: 1.1574115589208676
Validation loss: 2.5960649018660775

Epoch: 5| Step: 5
Training loss: 1.4944548631720103
Validation loss: 2.615682603877037

Epoch: 5| Step: 6
Training loss: 1.2599301726050924
Validation loss: 2.6256724132169698

Epoch: 5| Step: 7
Training loss: 1.7967623467998448
Validation loss: 2.5889040746354883

Epoch: 5| Step: 8
Training loss: 2.03664796016279
Validation loss: 2.604791163269774

Epoch: 5| Step: 9
Training loss: 1.4698659026036909
Validation loss: 2.5760659636387606

Epoch: 5| Step: 10
Training loss: 1.3402159593696172
Validation loss: 2.556774818778388

Epoch: 5| Step: 11
Training loss: 1.5751604997509256
Validation loss: 2.5811659016429376

Epoch: 141| Step: 0
Training loss: 1.6512689363836235
Validation loss: 2.6603936655657887

Epoch: 5| Step: 1
Training loss: 1.8692841828483298
Validation loss: 2.6076532420781944

Epoch: 5| Step: 2
Training loss: 1.4740632719644835
Validation loss: 2.689975057176669

Epoch: 5| Step: 3
Training loss: 1.3420441911814918
Validation loss: 2.6528907852224477

Epoch: 5| Step: 4
Training loss: 1.3771574261114614
Validation loss: 2.628053595850145

Epoch: 5| Step: 5
Training loss: 1.732783850664349
Validation loss: 2.5654271395268524

Epoch: 5| Step: 6
Training loss: 1.0290173145501993
Validation loss: 2.7070853891688293

Epoch: 5| Step: 7
Training loss: 1.8329548083747367
Validation loss: 2.6475457309571175

Epoch: 5| Step: 8
Training loss: 1.5228703934944956
Validation loss: 2.627037421366561

Epoch: 5| Step: 9
Training loss: 1.4286621252288292
Validation loss: 2.588629551603842

Epoch: 5| Step: 10
Training loss: 2.222578372496054
Validation loss: 2.644358987611734

Epoch: 5| Step: 11
Training loss: 1.3368177135404566
Validation loss: 2.5657153658454224

Epoch: 142| Step: 0
Training loss: 1.1538357144274771
Validation loss: 2.585953315771013

Epoch: 5| Step: 1
Training loss: 2.073049326985607
Validation loss: 2.7191900795986537

Epoch: 5| Step: 2
Training loss: 1.2994075543911359
Validation loss: 2.733810617239692

Epoch: 5| Step: 3
Training loss: 1.6291159808119149
Validation loss: 2.705033666656227

Epoch: 5| Step: 4
Training loss: 1.8823052827152258
Validation loss: 2.742453950723121

Epoch: 5| Step: 5
Training loss: 1.4350509513555434
Validation loss: 2.637137805934449

Epoch: 5| Step: 6
Training loss: 1.7560992220302805
Validation loss: 2.5910746515103837

Epoch: 5| Step: 7
Training loss: 1.3095112331414003
Validation loss: 2.63252466894234

Epoch: 5| Step: 8
Training loss: 1.4654802490850478
Validation loss: 2.6762732988495856

Epoch: 5| Step: 9
Training loss: 1.35387456629023
Validation loss: 2.6010445736975893

Epoch: 5| Step: 10
Training loss: 1.6750862440993592
Validation loss: 2.665696087925727

Epoch: 5| Step: 11
Training loss: 0.33769523616192
Validation loss: 2.6392069099324345

Epoch: 143| Step: 0
Training loss: 1.3754291298267034
Validation loss: 2.70018538645092

Epoch: 5| Step: 1
Training loss: 1.5435157289238035
Validation loss: 2.630228859597866

Epoch: 5| Step: 2
Training loss: 1.0921784145430296
Validation loss: 2.6405033595191325

Epoch: 5| Step: 3
Training loss: 1.5043650534173816
Validation loss: 2.6632814427677203

Epoch: 5| Step: 4
Training loss: 1.5193879910678256
Validation loss: 2.538740585656541

Epoch: 5| Step: 5
Training loss: 1.629496808110096
Validation loss: 2.6147641173904175

Epoch: 5| Step: 6
Training loss: 1.0057962045925255
Validation loss: 2.674467851317085

Epoch: 5| Step: 7
Training loss: 1.5146548125319177
Validation loss: 2.625466884237102

Epoch: 5| Step: 8
Training loss: 1.919992781267901
Validation loss: 2.6612188165515103

Epoch: 5| Step: 9
Training loss: 2.1570319264489273
Validation loss: 2.7716339766325

Epoch: 5| Step: 10
Training loss: 1.4230206244469257
Validation loss: 2.7429949050883353

Epoch: 5| Step: 11
Training loss: 1.5417916358953456
Validation loss: 2.6336254143996802

Epoch: 144| Step: 0
Training loss: 1.3280633351091193
Validation loss: 2.621340170133896

Epoch: 5| Step: 1
Training loss: 1.2726392057529146
Validation loss: 2.616100907489016

Epoch: 5| Step: 2
Training loss: 1.4689817854425269
Validation loss: 2.6809248518883506

Epoch: 5| Step: 3
Training loss: 2.018595790582968
Validation loss: 2.6583368555980376

Epoch: 5| Step: 4
Training loss: 1.9352626803610644
Validation loss: 2.674161044586713

Epoch: 5| Step: 5
Training loss: 1.4389413987687532
Validation loss: 2.686770735719597

Epoch: 5| Step: 6
Training loss: 1.214277914567148
Validation loss: 2.701868283300723

Epoch: 5| Step: 7
Training loss: 1.4702058435200687
Validation loss: 2.6504374616846924

Epoch: 5| Step: 8
Training loss: 1.520731552410974
Validation loss: 2.59405627223385

Epoch: 5| Step: 9
Training loss: 1.3431356933224878
Validation loss: 2.6789766968573536

Epoch: 5| Step: 10
Training loss: 1.674124870569735
Validation loss: 2.7760494630476287

Epoch: 5| Step: 11
Training loss: 1.227028630607371
Validation loss: 2.6456626939690464

Epoch: 145| Step: 0
Training loss: 1.2131999384646426
Validation loss: 2.737378398307917

Epoch: 5| Step: 1
Training loss: 1.5055610569051445
Validation loss: 2.7656618751610655

Epoch: 5| Step: 2
Training loss: 1.315740762361037
Validation loss: 2.6444075915651992

Epoch: 5| Step: 3
Training loss: 1.1920947477524673
Validation loss: 2.7009916946509884

Epoch: 5| Step: 4
Training loss: 1.4498193529659966
Validation loss: 2.7522410992708792

Epoch: 5| Step: 5
Training loss: 1.9748978672902093
Validation loss: 2.6527625920380897

Epoch: 5| Step: 6
Training loss: 1.8108990274313694
Validation loss: 2.7758528172215637

Epoch: 5| Step: 7
Training loss: 2.0411081393506416
Validation loss: 2.6467520527994894

Epoch: 5| Step: 8
Training loss: 1.1037636807242968
Validation loss: 2.705611472680165

Epoch: 5| Step: 9
Training loss: 1.7824852658982995
Validation loss: 2.6363417782158893

Epoch: 5| Step: 10
Training loss: 1.6126594730740835
Validation loss: 2.636632187917696

Epoch: 5| Step: 11
Training loss: 2.0625120220411937
Validation loss: 2.5934996847985152

Epoch: 146| Step: 0
Training loss: 1.090879433582782
Validation loss: 2.7405496544160823

Epoch: 5| Step: 1
Training loss: 1.714529508330645
Validation loss: 2.7001360683828572

Epoch: 5| Step: 2
Training loss: 1.797763770517406
Validation loss: 2.8958745971776887

Epoch: 5| Step: 3
Training loss: 1.620278321129164
Validation loss: 2.8436118501076355

Epoch: 5| Step: 4
Training loss: 1.3970828181234642
Validation loss: 2.8814601776023

Epoch: 5| Step: 5
Training loss: 1.625434010574574
Validation loss: 2.772063166422048

Epoch: 5| Step: 6
Training loss: 1.4152565651400877
Validation loss: 2.761930559193269

Epoch: 5| Step: 7
Training loss: 1.6726886516285286
Validation loss: 2.6721727008310885

Epoch: 5| Step: 8
Training loss: 1.7946723374342826
Validation loss: 2.64729079081219

Epoch: 5| Step: 9
Training loss: 1.4827642434953474
Validation loss: 2.662811201710305

Epoch: 5| Step: 10
Training loss: 2.088239906435521
Validation loss: 2.6764105694866034

Epoch: 5| Step: 11
Training loss: 1.4004054368005912
Validation loss: 2.773664445501715

Epoch: 147| Step: 0
Training loss: 1.3605256746246526
Validation loss: 2.8353154925127333

Epoch: 5| Step: 1
Training loss: 1.7105240692479133
Validation loss: 2.838999640707182

Epoch: 5| Step: 2
Training loss: 1.6824580563989546
Validation loss: 2.817543717169002

Epoch: 5| Step: 3
Training loss: 2.111956450829755
Validation loss: 2.704886900458239

Epoch: 5| Step: 4
Training loss: 1.5372981303359554
Validation loss: 2.77298351386872

Epoch: 5| Step: 5
Training loss: 1.107874917234452
Validation loss: 2.7305149334597716

Epoch: 5| Step: 6
Training loss: 1.3242480069419664
Validation loss: 2.6325422463343484

Epoch: 5| Step: 7
Training loss: 1.4760936012724286
Validation loss: 2.636860920405166

Epoch: 5| Step: 8
Training loss: 1.7090735188803998
Validation loss: 2.6870941920294458

Epoch: 5| Step: 9
Training loss: 1.3420181203065098
Validation loss: 2.6009484903932263

Epoch: 5| Step: 10
Training loss: 2.420915672053165
Validation loss: 2.686414262741204

Epoch: 5| Step: 11
Training loss: 0.5085552945226065
Validation loss: 2.7277927410464624

Epoch: 148| Step: 0
Training loss: 1.9052974009216677
Validation loss: 2.6985606685434633

Epoch: 5| Step: 1
Training loss: 1.110357037935873
Validation loss: 2.6870495230143314

Epoch: 5| Step: 2
Training loss: 1.7354665534583509
Validation loss: 2.6158559154152705

Epoch: 5| Step: 3
Training loss: 1.0824592928027137
Validation loss: 2.679901066342991

Epoch: 5| Step: 4
Training loss: 1.572553108422286
Validation loss: 2.5905714609299033

Epoch: 5| Step: 5
Training loss: 1.2043226152082651
Validation loss: 2.573272268661146

Epoch: 5| Step: 6
Training loss: 1.6313223724095733
Validation loss: 2.693105820783547

Epoch: 5| Step: 7
Training loss: 2.0516174355536356
Validation loss: 2.6719738122169283

Epoch: 5| Step: 8
Training loss: 1.4524125844680775
Validation loss: 2.6593148968453506

Epoch: 5| Step: 9
Training loss: 1.521433602931749
Validation loss: 2.649271890791063

Epoch: 5| Step: 10
Training loss: 0.9826732033413369
Validation loss: 2.609058322839945

Epoch: 5| Step: 11
Training loss: 0.8116801233435946
Validation loss: 2.637041323674716

Epoch: 149| Step: 0
Training loss: 1.571419396931012
Validation loss: 2.6895085229572544

Epoch: 5| Step: 1
Training loss: 1.2518838039018156
Validation loss: 2.6559877116537107

Epoch: 5| Step: 2
Training loss: 1.1361965277651158
Validation loss: 2.6974281890002993

Epoch: 5| Step: 3
Training loss: 1.2062682175125363
Validation loss: 2.6712409711657514

Epoch: 5| Step: 4
Training loss: 1.3112962743341574
Validation loss: 2.6709012307588895

Epoch: 5| Step: 5
Training loss: 1.396545152742102
Validation loss: 2.6052527083123636

Epoch: 5| Step: 6
Training loss: 1.2457204995150346
Validation loss: 2.7018853801569374

Epoch: 5| Step: 7
Training loss: 2.2340331983225483
Validation loss: 2.701771097567204

Epoch: 5| Step: 8
Training loss: 1.4720135406928683
Validation loss: 2.665711676443189

Epoch: 5| Step: 9
Training loss: 1.819645771830214
Validation loss: 2.666006152982735

Epoch: 5| Step: 10
Training loss: 1.3411176758807157
Validation loss: 2.7090234476327755

Epoch: 5| Step: 11
Training loss: 0.8587995509881603
Validation loss: 2.72650265924028

Epoch: 150| Step: 0
Training loss: 2.0576174192423933
Validation loss: 2.6301487239214105

Epoch: 5| Step: 1
Training loss: 1.5267200806420345
Validation loss: 2.627841195240052

Epoch: 5| Step: 2
Training loss: 1.9787694498962973
Validation loss: 2.720160534956289

Epoch: 5| Step: 3
Training loss: 1.8269194189799518
Validation loss: 2.6400455388322284

Epoch: 5| Step: 4
Training loss: 1.2485868572321253
Validation loss: 2.618258637585624

Epoch: 5| Step: 5
Training loss: 1.4932198673096657
Validation loss: 2.610151000380601

Epoch: 5| Step: 6
Training loss: 1.2570054207489951
Validation loss: 2.7019141283686827

Epoch: 5| Step: 7
Training loss: 1.2913729682413804
Validation loss: 2.614919341990858

Epoch: 5| Step: 8
Training loss: 1.006300390652218
Validation loss: 2.6672520156503765

Epoch: 5| Step: 9
Training loss: 1.063704985440524
Validation loss: 2.654042901507586

Epoch: 5| Step: 10
Training loss: 1.2870585268017005
Validation loss: 2.661649500531342

Epoch: 5| Step: 11
Training loss: 2.1216134405938782
Validation loss: 2.635687807833535

Epoch: 151| Step: 0
Training loss: 1.7514728070586671
Validation loss: 2.669749111342923

Epoch: 5| Step: 1
Training loss: 1.1252942760022617
Validation loss: 2.6326316145008155

Epoch: 5| Step: 2
Training loss: 1.3335882578973026
Validation loss: 2.611842505904114

Epoch: 5| Step: 3
Training loss: 1.3081712182961676
Validation loss: 2.67211815171959

Epoch: 5| Step: 4
Training loss: 1.7529109178138562
Validation loss: 2.659395031493097

Epoch: 5| Step: 5
Training loss: 1.4655714338392198
Validation loss: 2.75600922643707

Epoch: 5| Step: 6
Training loss: 1.6495396694421243
Validation loss: 2.7028370227922225

Epoch: 5| Step: 7
Training loss: 1.3568878221015834
Validation loss: 2.697589189152702

Epoch: 5| Step: 8
Training loss: 1.0849596190079747
Validation loss: 2.6536045364495786

Epoch: 5| Step: 9
Training loss: 1.8836688235181724
Validation loss: 2.576025441220576

Epoch: 5| Step: 10
Training loss: 1.048347405600493
Validation loss: 2.625523443106608

Epoch: 5| Step: 11
Training loss: 1.679422330995014
Validation loss: 2.595314209149169

Epoch: 152| Step: 0
Training loss: 1.39883570622422
Validation loss: 2.6135812196643857

Epoch: 5| Step: 1
Training loss: 1.406511536755322
Validation loss: 2.720904523337788

Epoch: 5| Step: 2
Training loss: 1.1203910938397885
Validation loss: 2.720774236819117

Epoch: 5| Step: 3
Training loss: 1.4472638128889634
Validation loss: 2.6560749183249164

Epoch: 5| Step: 4
Training loss: 1.491834189244724
Validation loss: 2.716257129021418

Epoch: 5| Step: 5
Training loss: 1.5380566403459768
Validation loss: 2.68419238895273

Epoch: 5| Step: 6
Training loss: 1.4808287975361314
Validation loss: 2.7288510447037466

Epoch: 5| Step: 7
Training loss: 1.4371918057656947
Validation loss: 2.6910984285900854

Epoch: 5| Step: 8
Training loss: 1.7117802186251074
Validation loss: 2.630517885983955

Epoch: 5| Step: 9
Training loss: 1.976548990195925
Validation loss: 2.610238729888531

Epoch: 5| Step: 10
Training loss: 1.022601302895032
Validation loss: 2.6639347772940782

Epoch: 5| Step: 11
Training loss: 1.1465318920160006
Validation loss: 2.7561760640914246

Epoch: 153| Step: 0
Training loss: 1.3558539906721543
Validation loss: 2.7297737099234194

Epoch: 5| Step: 1
Training loss: 1.2823301739750863
Validation loss: 2.7032800530742502

Epoch: 5| Step: 2
Training loss: 1.7367116635375763
Validation loss: 2.663303446096737

Epoch: 5| Step: 3
Training loss: 1.3756662401935522
Validation loss: 2.7590622596165972

Epoch: 5| Step: 4
Training loss: 0.9469848531319336
Validation loss: 2.6960748598683684

Epoch: 5| Step: 5
Training loss: 1.5355885603124622
Validation loss: 2.651766111595944

Epoch: 5| Step: 6
Training loss: 2.0455383129499416
Validation loss: 2.8556097702919367

Epoch: 5| Step: 7
Training loss: 1.7944721243737443
Validation loss: 2.6726604519249486

Epoch: 5| Step: 8
Training loss: 1.3897834117157997
Validation loss: 2.7487614472367556

Epoch: 5| Step: 9
Training loss: 1.3655667534808689
Validation loss: 2.615973362726779

Epoch: 5| Step: 10
Training loss: 1.2981945356792048
Validation loss: 2.6169241056230135

Epoch: 5| Step: 11
Training loss: 1.0261547910548257
Validation loss: 2.564612835658363

Epoch: 154| Step: 0
Training loss: 1.3821902841828448
Validation loss: 2.648214520245337

Epoch: 5| Step: 1
Training loss: 1.6524057218865804
Validation loss: 2.720456822609655

Epoch: 5| Step: 2
Training loss: 1.5283448043664543
Validation loss: 2.688842142590258

Epoch: 5| Step: 3
Training loss: 2.084401683264832
Validation loss: 2.7215032995997004

Epoch: 5| Step: 4
Training loss: 0.8854830025151387
Validation loss: 2.6857675912496317

Epoch: 5| Step: 5
Training loss: 1.3528950026625755
Validation loss: 2.695867785322584

Epoch: 5| Step: 6
Training loss: 1.0905866927712662
Validation loss: 2.7073030174832513

Epoch: 5| Step: 7
Training loss: 1.495038728754568
Validation loss: 2.6565772846024265

Epoch: 5| Step: 8
Training loss: 1.297878612411514
Validation loss: 2.6933269097665473

Epoch: 5| Step: 9
Training loss: 1.4416382972410318
Validation loss: 2.6288509126897437

Epoch: 5| Step: 10
Training loss: 1.13568220037532
Validation loss: 2.6659508516782706

Epoch: 5| Step: 11
Training loss: 1.3649072432529348
Validation loss: 2.6443816217327405

Epoch: 155| Step: 0
Training loss: 1.422893536641734
Validation loss: 2.7070376647021837

Epoch: 5| Step: 1
Training loss: 1.057949250029855
Validation loss: 2.6928579238472716

Epoch: 5| Step: 2
Training loss: 2.1273876688581277
Validation loss: 2.5942248327259794

Epoch: 5| Step: 3
Training loss: 1.5488096527114077
Validation loss: 2.6653529646632195

Epoch: 5| Step: 4
Training loss: 1.038471139689563
Validation loss: 2.6666982482490416

Epoch: 5| Step: 5
Training loss: 1.0424892737845366
Validation loss: 2.6331588826661942

Epoch: 5| Step: 6
Training loss: 1.3525191873680726
Validation loss: 2.7155197948450067

Epoch: 5| Step: 7
Training loss: 1.2230803025489185
Validation loss: 2.788945150177272

Epoch: 5| Step: 8
Training loss: 1.4384522808276052
Validation loss: 2.685561675059834

Epoch: 5| Step: 9
Training loss: 1.2004983145476762
Validation loss: 2.6768826262247933

Epoch: 5| Step: 10
Training loss: 1.4426118930941474
Validation loss: 2.6610865373700174

Epoch: 5| Step: 11
Training loss: 1.0830897032835678
Validation loss: 2.6295717558054097

Epoch: 156| Step: 0
Training loss: 1.127544492533045
Validation loss: 2.727643703115638

Epoch: 5| Step: 1
Training loss: 1.451939088652476
Validation loss: 2.736631755515188

Epoch: 5| Step: 2
Training loss: 1.0177202766105504
Validation loss: 2.6536124729284465

Epoch: 5| Step: 3
Training loss: 1.239606082397635
Validation loss: 2.6727220371255904

Epoch: 5| Step: 4
Training loss: 1.3715493947617867
Validation loss: 2.677643926286086

Epoch: 5| Step: 5
Training loss: 0.986511032216815
Validation loss: 2.678744874137309

Epoch: 5| Step: 6
Training loss: 1.353432392682357
Validation loss: 2.666088746946326

Epoch: 5| Step: 7
Training loss: 1.0418832680889594
Validation loss: 2.7510471048317

Epoch: 5| Step: 8
Training loss: 1.5547177872511124
Validation loss: 2.7166993932469006

Epoch: 5| Step: 9
Training loss: 1.375019506836284
Validation loss: 2.721494958816009

Epoch: 5| Step: 10
Training loss: 1.9502197019592522
Validation loss: 2.673837472710293

Epoch: 5| Step: 11
Training loss: 2.3899786580302016
Validation loss: 2.752553819660889

Epoch: 157| Step: 0
Training loss: 1.1682210286174879
Validation loss: 2.7522347971444074

Epoch: 5| Step: 1
Training loss: 1.96004085634428
Validation loss: 2.736645654937644

Epoch: 5| Step: 2
Training loss: 1.212731441550039
Validation loss: 2.713533505203557

Epoch: 5| Step: 3
Training loss: 1.1866969354569534
Validation loss: 2.743960905694879

Epoch: 5| Step: 4
Training loss: 1.498267126491207
Validation loss: 2.6559154748637366

Epoch: 5| Step: 5
Training loss: 2.1362782918754135
Validation loss: 2.7493248168453888

Epoch: 5| Step: 6
Training loss: 1.3020418033334678
Validation loss: 2.7297320047297733

Epoch: 5| Step: 7
Training loss: 1.2558410548272516
Validation loss: 2.710002983614791

Epoch: 5| Step: 8
Training loss: 1.365053222163625
Validation loss: 2.695002209037909

Epoch: 5| Step: 9
Training loss: 1.0194198138258246
Validation loss: 2.7341236471271833

Epoch: 5| Step: 10
Training loss: 1.3585623581228075
Validation loss: 2.677975013803189

Epoch: 5| Step: 11
Training loss: 0.8458965688159413
Validation loss: 2.709624028155206

Epoch: 158| Step: 0
Training loss: 1.4996040139446534
Validation loss: 2.6655105578179406

Epoch: 5| Step: 1
Training loss: 1.9628606234103363
Validation loss: 2.6905304323916464

Epoch: 5| Step: 2
Training loss: 1.3594500641541458
Validation loss: 2.7101267134449

Epoch: 5| Step: 3
Training loss: 1.4101919661038114
Validation loss: 2.7079983076095457

Epoch: 5| Step: 4
Training loss: 1.4570395134494643
Validation loss: 2.6583519603610783

Epoch: 5| Step: 5
Training loss: 0.9834231664281547
Validation loss: 2.7734245622359985

Epoch: 5| Step: 6
Training loss: 0.9468307912848707
Validation loss: 2.5876176107094815

Epoch: 5| Step: 7
Training loss: 1.131127887268125
Validation loss: 2.63855448550426

Epoch: 5| Step: 8
Training loss: 1.180744985579085
Validation loss: 2.6972327869137227

Epoch: 5| Step: 9
Training loss: 1.4151382148286722
Validation loss: 2.647173547102668

Epoch: 5| Step: 10
Training loss: 1.303420862509197
Validation loss: 2.721193658697863

Epoch: 5| Step: 11
Training loss: 1.7158030127498323
Validation loss: 2.6601657503157266

Epoch: 159| Step: 0
Training loss: 1.4394354023353524
Validation loss: 2.6754952419414306

Epoch: 5| Step: 1
Training loss: 1.2874045142162922
Validation loss: 2.716804085709825

Epoch: 5| Step: 2
Training loss: 1.3735020888138738
Validation loss: 2.678150574077224

Epoch: 5| Step: 3
Training loss: 0.8431937185324949
Validation loss: 2.656284047824833

Epoch: 5| Step: 4
Training loss: 1.3231753849748646
Validation loss: 2.7188137967747243

Epoch: 5| Step: 5
Training loss: 2.0704407850142656
Validation loss: 2.755097465712273

Epoch: 5| Step: 6
Training loss: 1.095695835572065
Validation loss: 2.739286904682022

Epoch: 5| Step: 7
Training loss: 1.3014818200868818
Validation loss: 2.6303305222988116

Epoch: 5| Step: 8
Training loss: 1.141742002595741
Validation loss: 2.688112089405041

Epoch: 5| Step: 9
Training loss: 1.278628761607436
Validation loss: 2.643043572936629

Epoch: 5| Step: 10
Training loss: 1.3051196541868066
Validation loss: 2.6875690665722205

Epoch: 5| Step: 11
Training loss: 0.6989278347981394
Validation loss: 2.620439234508163

Epoch: 160| Step: 0
Training loss: 1.1836061886174731
Validation loss: 2.685814572950416

Epoch: 5| Step: 1
Training loss: 1.4530372182932416
Validation loss: 2.669894709677958

Epoch: 5| Step: 2
Training loss: 1.1666477860330786
Validation loss: 2.68092271382682

Epoch: 5| Step: 3
Training loss: 0.9891716184280576
Validation loss: 2.7133613802325702

Epoch: 5| Step: 4
Training loss: 1.0517737370580942
Validation loss: 2.6963396078012294

Epoch: 5| Step: 5
Training loss: 1.3687538983015173
Validation loss: 2.6916522618155345

Epoch: 5| Step: 6
Training loss: 1.143097431816104
Validation loss: 2.6538282611846924

Epoch: 5| Step: 7
Training loss: 1.8750033696462234
Validation loss: 2.6972098596817524

Epoch: 5| Step: 8
Training loss: 1.3130030803193962
Validation loss: 2.737027322410255

Epoch: 5| Step: 9
Training loss: 1.0301395564301208
Validation loss: 2.772128599536852

Epoch: 5| Step: 10
Training loss: 1.1155551108472967
Validation loss: 2.692627037980597

Epoch: 5| Step: 11
Training loss: 1.6926870100194393
Validation loss: 2.615474140096277

Epoch: 161| Step: 0
Training loss: 1.9469397299891138
Validation loss: 2.6543049067173867

Epoch: 5| Step: 1
Training loss: 1.0632525751982789
Validation loss: 2.657585008645588

Epoch: 5| Step: 2
Training loss: 1.5357553026671957
Validation loss: 2.656719179417211

Epoch: 5| Step: 3
Training loss: 1.3317015119504643
Validation loss: 2.6856313056389425

Epoch: 5| Step: 4
Training loss: 1.2008976817224053
Validation loss: 2.710522655659779

Epoch: 5| Step: 5
Training loss: 1.150415701989517
Validation loss: 2.6785338970612727

Epoch: 5| Step: 6
Training loss: 1.3735518632476857
Validation loss: 2.7065056992062133

Epoch: 5| Step: 7
Training loss: 1.0946706983892405
Validation loss: 2.65695501582871

Epoch: 5| Step: 8
Training loss: 1.1025692823270734
Validation loss: 2.680424854790458

Epoch: 5| Step: 9
Training loss: 1.167135904951446
Validation loss: 2.72099142744697

Epoch: 5| Step: 10
Training loss: 1.5068756513621862
Validation loss: 2.7639944330880284

Epoch: 5| Step: 11
Training loss: 0.7031879820696143
Validation loss: 2.7332604489165275

Epoch: 162| Step: 0
Training loss: 1.233782952205811
Validation loss: 2.665422847367535

Epoch: 5| Step: 1
Training loss: 1.2464480479370388
Validation loss: 2.763495828977161

Epoch: 5| Step: 2
Training loss: 0.9457492922670084
Validation loss: 2.696807181521178

Epoch: 5| Step: 3
Training loss: 1.0841796149307252
Validation loss: 2.7298628499090682

Epoch: 5| Step: 4
Training loss: 1.9175039066041146
Validation loss: 2.6352515426492262

Epoch: 5| Step: 5
Training loss: 1.1439677338684873
Validation loss: 2.779327017110658

Epoch: 5| Step: 6
Training loss: 1.1254551284772842
Validation loss: 2.7730161319914113

Epoch: 5| Step: 7
Training loss: 0.9269377812057252
Validation loss: 2.653396401304754

Epoch: 5| Step: 8
Training loss: 1.262894970891987
Validation loss: 2.6884644592729563

Epoch: 5| Step: 9
Training loss: 1.4947716670631215
Validation loss: 2.684838348325813

Epoch: 5| Step: 10
Training loss: 1.3094304840058704
Validation loss: 2.7328651110537905

Epoch: 5| Step: 11
Training loss: 1.576907679838694
Validation loss: 2.730376126051317

Epoch: 163| Step: 0
Training loss: 1.094882814416263
Validation loss: 2.7421610723165717

Epoch: 5| Step: 1
Training loss: 1.2287264644507045
Validation loss: 2.702699172008524

Epoch: 5| Step: 2
Training loss: 1.485408944871832
Validation loss: 2.7697426339111293

Epoch: 5| Step: 3
Training loss: 1.53917054702333
Validation loss: 2.737470110348313

Epoch: 5| Step: 4
Training loss: 0.9617970041995829
Validation loss: 2.722314624342659

Epoch: 5| Step: 5
Training loss: 1.2420589932361639
Validation loss: 2.742048348775232

Epoch: 5| Step: 6
Training loss: 1.3979774442935116
Validation loss: 2.709978786100428

Epoch: 5| Step: 7
Training loss: 1.1181447656290695
Validation loss: 2.78360323879792

Epoch: 5| Step: 8
Training loss: 2.122469348843414
Validation loss: 2.709232992742792

Epoch: 5| Step: 9
Training loss: 1.5486179897153682
Validation loss: 2.772949609243136

Epoch: 5| Step: 10
Training loss: 1.127599309451219
Validation loss: 2.787891231047023

Epoch: 5| Step: 11
Training loss: 1.136739514348043
Validation loss: 2.654892612022818

Epoch: 164| Step: 0
Training loss: 1.5213814187626327
Validation loss: 2.8381762149751055

Epoch: 5| Step: 1
Training loss: 1.1558351545771024
Validation loss: 2.7908490974180005

Epoch: 5| Step: 2
Training loss: 1.3098218933633627
Validation loss: 2.677823301508616

Epoch: 5| Step: 3
Training loss: 0.8413728854365762
Validation loss: 2.796651699877108

Epoch: 5| Step: 4
Training loss: 1.0319385541802266
Validation loss: 2.6504480350566957

Epoch: 5| Step: 5
Training loss: 1.4115911564378882
Validation loss: 2.714669457565171

Epoch: 5| Step: 6
Training loss: 1.4184744277386312
Validation loss: 2.7605037075691037

Epoch: 5| Step: 7
Training loss: 1.0701903670302144
Validation loss: 2.824974286122732

Epoch: 5| Step: 8
Training loss: 1.6769816760732288
Validation loss: 2.662168181701129

Epoch: 5| Step: 9
Training loss: 1.9152589133906324
Validation loss: 2.7201538298212258

Epoch: 5| Step: 10
Training loss: 0.918988639304721
Validation loss: 2.607317278760714

Epoch: 5| Step: 11
Training loss: 1.1483946292686504
Validation loss: 2.69746821345002

Epoch: 165| Step: 0
Training loss: 1.0888116796740177
Validation loss: 2.7596075647603397

Epoch: 5| Step: 1
Training loss: 1.4666214798699986
Validation loss: 2.8151244281294905

Epoch: 5| Step: 2
Training loss: 1.073099725655583
Validation loss: 2.747310117616834

Epoch: 5| Step: 3
Training loss: 1.5267503761402228
Validation loss: 2.810211571650949

Epoch: 5| Step: 4
Training loss: 1.2701532336778898
Validation loss: 2.7694954665813176

Epoch: 5| Step: 5
Training loss: 1.9381216959108631
Validation loss: 2.770435949502192

Epoch: 5| Step: 6
Training loss: 1.655844944780578
Validation loss: 2.6688427738499256

Epoch: 5| Step: 7
Training loss: 0.9170258244691791
Validation loss: 2.7326080026191164

Epoch: 5| Step: 8
Training loss: 1.1660134780327283
Validation loss: 2.8031742472949177

Epoch: 5| Step: 9
Training loss: 1.1136416203334079
Validation loss: 2.6897677715619843

Epoch: 5| Step: 10
Training loss: 1.06559185748426
Validation loss: 2.744796489926081

Epoch: 5| Step: 11
Training loss: 1.1516935421466414
Validation loss: 2.757947736527543

Epoch: 166| Step: 0
Training loss: 0.9346063461452334
Validation loss: 2.603957249168412

Epoch: 5| Step: 1
Training loss: 1.2184450795127946
Validation loss: 2.732807658449119

Epoch: 5| Step: 2
Training loss: 0.7969651264760013
Validation loss: 2.719624678268889

Epoch: 5| Step: 3
Training loss: 1.2385098219302255
Validation loss: 2.681851309520022

Epoch: 5| Step: 4
Training loss: 1.9559149994586733
Validation loss: 2.6439980364240108

Epoch: 5| Step: 5
Training loss: 1.4518832571950107
Validation loss: 2.7770986936239335

Epoch: 5| Step: 6
Training loss: 0.988868508742081
Validation loss: 2.6826290819598504

Epoch: 5| Step: 7
Training loss: 1.0358169462504108
Validation loss: 2.692564491301283

Epoch: 5| Step: 8
Training loss: 1.4643308835256954
Validation loss: 2.728870143991893

Epoch: 5| Step: 9
Training loss: 1.5009192987561937
Validation loss: 2.785387141076704

Epoch: 5| Step: 10
Training loss: 1.3056954698915115
Validation loss: 2.7699328276228

Epoch: 5| Step: 11
Training loss: 1.6525324720461598
Validation loss: 2.695586116005294

Epoch: 167| Step: 0
Training loss: 0.8930366390183274
Validation loss: 2.745632275748937

Epoch: 5| Step: 1
Training loss: 1.27458190981904
Validation loss: 2.7535768316397444

Epoch: 5| Step: 2
Training loss: 1.0090062959056831
Validation loss: 2.7929353654195572

Epoch: 5| Step: 3
Training loss: 1.4117315480718744
Validation loss: 2.6868145978003173

Epoch: 5| Step: 4
Training loss: 1.92278702348124
Validation loss: 2.5977964396878757

Epoch: 5| Step: 5
Training loss: 1.28465757579652
Validation loss: 2.759014336044666

Epoch: 5| Step: 6
Training loss: 1.6305301173989757
Validation loss: 2.7199172294986456

Epoch: 5| Step: 7
Training loss: 1.150202944719382
Validation loss: 2.6249810399778557

Epoch: 5| Step: 8
Training loss: 1.4025287134287796
Validation loss: 2.677162107404596

Epoch: 5| Step: 9
Training loss: 1.082403676634787
Validation loss: 2.7056042137825007

Epoch: 5| Step: 10
Training loss: 0.8973300244774352
Validation loss: 2.7247056112304757

Epoch: 5| Step: 11
Training loss: 0.8256181525178193
Validation loss: 2.7037490058329214

Epoch: 168| Step: 0
Training loss: 2.1113763427874646
Validation loss: 2.6759328683188417

Epoch: 5| Step: 1
Training loss: 1.0958433554496863
Validation loss: 2.7223285275309403

Epoch: 5| Step: 2
Training loss: 1.1584645277049632
Validation loss: 2.710634401510487

Epoch: 5| Step: 3
Training loss: 1.0088845989709787
Validation loss: 2.6678525974798886

Epoch: 5| Step: 4
Training loss: 0.926439365226815
Validation loss: 2.719952879917127

Epoch: 5| Step: 5
Training loss: 1.324231128015872
Validation loss: 2.661716498428197

Epoch: 5| Step: 6
Training loss: 0.9022910693094806
Validation loss: 2.700478476495966

Epoch: 5| Step: 7
Training loss: 1.2024608612035739
Validation loss: 2.687884798520842

Epoch: 5| Step: 8
Training loss: 1.6411089955267977
Validation loss: 2.6771505114863037

Epoch: 5| Step: 9
Training loss: 0.9347738684080732
Validation loss: 2.7349791231817306

Epoch: 5| Step: 10
Training loss: 1.0952236057837479
Validation loss: 2.7107952384742457

Epoch: 5| Step: 11
Training loss: 0.7551995287853323
Validation loss: 2.6920223702776123

Epoch: 169| Step: 0
Training loss: 2.1931779468805876
Validation loss: 2.6938868931138185

Epoch: 5| Step: 1
Training loss: 1.5532339384070364
Validation loss: 2.746834356175822

Epoch: 5| Step: 2
Training loss: 1.045470590996023
Validation loss: 2.737829126607186

Epoch: 5| Step: 3
Training loss: 1.2443586844079266
Validation loss: 2.6980189165355215

Epoch: 5| Step: 4
Training loss: 0.7802116360019375
Validation loss: 2.7267807232844414

Epoch: 5| Step: 5
Training loss: 1.199073857305096
Validation loss: 2.665872471730664

Epoch: 5| Step: 6
Training loss: 1.1282347163478104
Validation loss: 2.700480262478569

Epoch: 5| Step: 7
Training loss: 1.056769005385476
Validation loss: 2.718869349172982

Epoch: 5| Step: 8
Training loss: 1.1303179405024517
Validation loss: 2.7482581221219515

Epoch: 5| Step: 9
Training loss: 1.2230031066880025
Validation loss: 2.7057264338391733

Epoch: 5| Step: 10
Training loss: 1.2590025017238544
Validation loss: 2.7378502260292574

Epoch: 5| Step: 11
Training loss: 0.9323232137503421
Validation loss: 2.6604986133864563

Epoch: 170| Step: 0
Training loss: 1.2906849216839786
Validation loss: 2.68048146962997

Epoch: 5| Step: 1
Training loss: 1.9740091349188438
Validation loss: 2.7626167215167703

Epoch: 5| Step: 2
Training loss: 0.9374515838836729
Validation loss: 2.6921765978698144

Epoch: 5| Step: 3
Training loss: 1.1517029095663893
Validation loss: 2.6880884265636373

Epoch: 5| Step: 4
Training loss: 1.075237997456808
Validation loss: 2.699884648125423

Epoch: 5| Step: 5
Training loss: 1.1329183068683888
Validation loss: 2.7562789651641957

Epoch: 5| Step: 6
Training loss: 1.034912022984117
Validation loss: 2.6942301728617912

Epoch: 5| Step: 7
Training loss: 1.1037221529634995
Validation loss: 2.6755258999871168

Epoch: 5| Step: 8
Training loss: 1.0518893953858086
Validation loss: 2.708689414360331

Epoch: 5| Step: 9
Training loss: 1.478999956792556
Validation loss: 2.666667734583005

Epoch: 5| Step: 10
Training loss: 1.418535187713413
Validation loss: 2.7000398541676245

Epoch: 5| Step: 11
Training loss: 0.7045951097573159
Validation loss: 2.726856762328659

Epoch: 171| Step: 0
Training loss: 2.1663206142003824
Validation loss: 2.7975358999089126

Epoch: 5| Step: 1
Training loss: 1.330277527413741
Validation loss: 2.7542534683696

Epoch: 5| Step: 2
Training loss: 0.7211113990615926
Validation loss: 2.6274472288379003

Epoch: 5| Step: 3
Training loss: 1.2598843777301205
Validation loss: 2.775130830435757

Epoch: 5| Step: 4
Training loss: 0.9137577298694546
Validation loss: 2.7799524823880133

Epoch: 5| Step: 5
Training loss: 0.8819817541812924
Validation loss: 2.7541161279086013

Epoch: 5| Step: 6
Training loss: 1.0459559947470962
Validation loss: 2.7575897256497113

Epoch: 5| Step: 7
Training loss: 0.9738465039247622
Validation loss: 2.798594200366106

Epoch: 5| Step: 8
Training loss: 1.035446299097553
Validation loss: 2.7459290999082944

Epoch: 5| Step: 9
Training loss: 1.2672051349734534
Validation loss: 2.772972168189044

Epoch: 5| Step: 10
Training loss: 1.3617595935677589
Validation loss: 2.6355189101297585

Epoch: 5| Step: 11
Training loss: 0.4831210178443071
Validation loss: 2.8221509406383927

Epoch: 172| Step: 0
Training loss: 1.8332834742730997
Validation loss: 2.762218946224753

Epoch: 5| Step: 1
Training loss: 1.1218154126337287
Validation loss: 2.851652062111323

Epoch: 5| Step: 2
Training loss: 0.8997170003365392
Validation loss: 2.7972816157504323

Epoch: 5| Step: 3
Training loss: 1.2180037047513044
Validation loss: 2.75462064021793

Epoch: 5| Step: 4
Training loss: 1.6379691289151492
Validation loss: 2.7164374085582037

Epoch: 5| Step: 5
Training loss: 1.1803662198148268
Validation loss: 2.7179509446585293

Epoch: 5| Step: 6
Training loss: 1.152444608768112
Validation loss: 2.737907170072333

Epoch: 5| Step: 7
Training loss: 1.0462658376645797
Validation loss: 2.7183937884421536

Epoch: 5| Step: 8
Training loss: 1.1809570352877181
Validation loss: 2.7886040219011443

Epoch: 5| Step: 9
Training loss: 1.1465286688233478
Validation loss: 2.7370274784797997

Epoch: 5| Step: 10
Training loss: 0.9628822991744349
Validation loss: 2.8153590893547

Epoch: 5| Step: 11
Training loss: 0.6378035636025365
Validation loss: 2.7093436349698115

Epoch: 173| Step: 0
Training loss: 0.8213783242868516
Validation loss: 2.686340817625853

Epoch: 5| Step: 1
Training loss: 0.8319844693925998
Validation loss: 2.7832932164295396

Epoch: 5| Step: 2
Training loss: 1.134792675542876
Validation loss: 2.781320245977247

Epoch: 5| Step: 3
Training loss: 1.20127860734837
Validation loss: 2.7906509029415103

Epoch: 5| Step: 4
Training loss: 0.9307206127682341
Validation loss: 2.7368005004021323

Epoch: 5| Step: 5
Training loss: 1.3771485102124237
Validation loss: 2.804006031521692

Epoch: 5| Step: 6
Training loss: 0.8888502675514143
Validation loss: 2.8180097899353758

Epoch: 5| Step: 7
Training loss: 2.062394804150271
Validation loss: 2.7472167090770028

Epoch: 5| Step: 8
Training loss: 1.1426168321101182
Validation loss: 2.78369676640415

Epoch: 5| Step: 9
Training loss: 1.2781044564309942
Validation loss: 2.7785736379685844

Epoch: 5| Step: 10
Training loss: 1.3877196232641371
Validation loss: 2.8202700730617054

Epoch: 5| Step: 11
Training loss: 1.0150563922494213
Validation loss: 2.77870232984363

Epoch: 174| Step: 0
Training loss: 1.8729194542082968
Validation loss: 2.7900725458254727

Epoch: 5| Step: 1
Training loss: 0.8852098036320136
Validation loss: 2.8246218163756986

Epoch: 5| Step: 2
Training loss: 1.2399477169335649
Validation loss: 2.76720733061078

Epoch: 5| Step: 3
Training loss: 1.2161209898976755
Validation loss: 2.6926148593303676

Epoch: 5| Step: 4
Training loss: 1.0204091585650747
Validation loss: 2.7778688301952057

Epoch: 5| Step: 5
Training loss: 1.1172725405037904
Validation loss: 2.8066161704806505

Epoch: 5| Step: 6
Training loss: 1.213900233438081
Validation loss: 2.7614563741332856

Epoch: 5| Step: 7
Training loss: 1.047959861598237
Validation loss: 2.7631197356494823

Epoch: 5| Step: 8
Training loss: 1.0418634165284124
Validation loss: 2.784257587764476

Epoch: 5| Step: 9
Training loss: 0.9102703890634637
Validation loss: 2.6524207394736723

Epoch: 5| Step: 10
Training loss: 1.2937992805272565
Validation loss: 2.6491748529815506

Epoch: 5| Step: 11
Training loss: 1.1959813060766724
Validation loss: 2.75745300168761

Epoch: 175| Step: 0
Training loss: 1.8724653277987804
Validation loss: 2.704214321259292

Epoch: 5| Step: 1
Training loss: 0.9535263342218853
Validation loss: 2.870836927211452

Epoch: 5| Step: 2
Training loss: 1.0356757246083201
Validation loss: 2.7515806727158556

Epoch: 5| Step: 3
Training loss: 1.2466859755491193
Validation loss: 2.773878039263849

Epoch: 5| Step: 4
Training loss: 1.3829067219676128
Validation loss: 2.868372756211269

Epoch: 5| Step: 5
Training loss: 1.018036663984013
Validation loss: 2.708252807789453

Epoch: 5| Step: 6
Training loss: 1.022291225860565
Validation loss: 2.744495539944625

Epoch: 5| Step: 7
Training loss: 1.1409213060093333
Validation loss: 2.7094729385655394

Epoch: 5| Step: 8
Training loss: 1.3217124514368253
Validation loss: 2.7140861057798817

Epoch: 5| Step: 9
Training loss: 1.1429983556306746
Validation loss: 2.744669766165205

Epoch: 5| Step: 10
Training loss: 0.75894705405289
Validation loss: 2.7551949518139582

Epoch: 5| Step: 11
Training loss: 0.9866389021049292
Validation loss: 2.819305321095876

Epoch: 176| Step: 0
Training loss: 0.861094125115277
Validation loss: 2.732175341907815

Epoch: 5| Step: 1
Training loss: 1.1604323138968977
Validation loss: 2.7185134200133882

Epoch: 5| Step: 2
Training loss: 0.8022288937620004
Validation loss: 2.640428374003005

Epoch: 5| Step: 3
Training loss: 1.9239621498167816
Validation loss: 2.663172661815048

Epoch: 5| Step: 4
Training loss: 0.9816869333913665
Validation loss: 2.7154778268351683

Epoch: 5| Step: 5
Training loss: 1.2012346949083625
Validation loss: 2.7417571879480773

Epoch: 5| Step: 6
Training loss: 0.8489553455386019
Validation loss: 2.750196619663145

Epoch: 5| Step: 7
Training loss: 1.3615650206221424
Validation loss: 2.7396929625899844

Epoch: 5| Step: 8
Training loss: 1.1300649537348413
Validation loss: 2.8284072278514722

Epoch: 5| Step: 9
Training loss: 1.0562772848905175
Validation loss: 2.747944648972321

Epoch: 5| Step: 10
Training loss: 1.2088898604860874
Validation loss: 2.6838372206614074

Epoch: 5| Step: 11
Training loss: 1.2623817898391778
Validation loss: 2.857968246640387

Epoch: 177| Step: 0
Training loss: 0.8005413161176257
Validation loss: 2.8156261271913046

Epoch: 5| Step: 1
Training loss: 0.8992285521608515
Validation loss: 2.6513346464573337

Epoch: 5| Step: 2
Training loss: 1.0666024163883119
Validation loss: 2.802427427915877

Epoch: 5| Step: 3
Training loss: 1.9122813130928338
Validation loss: 2.8118220571844645

Epoch: 5| Step: 4
Training loss: 1.361063204893231
Validation loss: 2.6943175428259645

Epoch: 5| Step: 5
Training loss: 1.1544617407676623
Validation loss: 2.807382547939859

Epoch: 5| Step: 6
Training loss: 1.0815255536126114
Validation loss: 2.7821860934762443

Epoch: 5| Step: 7
Training loss: 0.9391046777986692
Validation loss: 2.7993640728142686

Epoch: 5| Step: 8
Training loss: 1.1645717658945287
Validation loss: 2.7198762935785714

Epoch: 5| Step: 9
Training loss: 1.06076446605333
Validation loss: 2.704963257481899

Epoch: 5| Step: 10
Training loss: 1.368963341656138
Validation loss: 2.7847796912749265

Epoch: 5| Step: 11
Training loss: 1.016141378737396
Validation loss: 2.7374820422682373

Epoch: 178| Step: 0
Training loss: 0.9406534247681804
Validation loss: 2.7962497850616104

Epoch: 5| Step: 1
Training loss: 0.8139146813380501
Validation loss: 2.758998475355368

Epoch: 5| Step: 2
Training loss: 0.8719267006041858
Validation loss: 2.662913662978354

Epoch: 5| Step: 3
Training loss: 0.8732435444424776
Validation loss: 2.7581417978597718

Epoch: 5| Step: 4
Training loss: 1.0738493128046518
Validation loss: 2.850587439506704

Epoch: 5| Step: 5
Training loss: 1.1633842591740782
Validation loss: 2.645544007519474

Epoch: 5| Step: 6
Training loss: 1.4625852543687827
Validation loss: 2.8093303657072344

Epoch: 5| Step: 7
Training loss: 1.9728111281829033
Validation loss: 2.791800667739853

Epoch: 5| Step: 8
Training loss: 1.01815316907718
Validation loss: 2.7336396018622997

Epoch: 5| Step: 9
Training loss: 1.3136370138986904
Validation loss: 2.7939733801397146

Epoch: 5| Step: 10
Training loss: 1.3789805967696174
Validation loss: 2.6952802057220464

Epoch: 5| Step: 11
Training loss: 1.0336037563955471
Validation loss: 2.8546613812099966

Epoch: 179| Step: 0
Training loss: 1.2486835223002408
Validation loss: 2.7129759110258815

Epoch: 5| Step: 1
Training loss: 0.7280819090179115
Validation loss: 2.70936909945915

Epoch: 5| Step: 2
Training loss: 0.9546223744656865
Validation loss: 2.6902183048127792

Epoch: 5| Step: 3
Training loss: 0.885915787580471
Validation loss: 2.737362172737449

Epoch: 5| Step: 4
Training loss: 1.0605165255930282
Validation loss: 2.849024433064245

Epoch: 5| Step: 5
Training loss: 1.1120851214611152
Validation loss: 2.7771424990964597

Epoch: 5| Step: 6
Training loss: 1.0303033471850727
Validation loss: 2.8462142747086947

Epoch: 5| Step: 7
Training loss: 1.3793613882218545
Validation loss: 2.723570179073777

Epoch: 5| Step: 8
Training loss: 1.8115410734485198
Validation loss: 2.673574669219411

Epoch: 5| Step: 9
Training loss: 1.479683056092563
Validation loss: 2.7784517763273247

Epoch: 5| Step: 10
Training loss: 0.9191635796906369
Validation loss: 2.7225539718674994

Epoch: 5| Step: 11
Training loss: 0.9148051187778203
Validation loss: 2.7631993117769875

Epoch: 180| Step: 0
Training loss: 0.9826929768719822
Validation loss: 2.7087230395882584

Epoch: 5| Step: 1
Training loss: 0.9772159983862235
Validation loss: 2.844450923627521

Epoch: 5| Step: 2
Training loss: 1.0968102286579018
Validation loss: 2.694830551918764

Epoch: 5| Step: 3
Training loss: 1.77896620926225
Validation loss: 2.734534453329539

Epoch: 5| Step: 4
Training loss: 1.1727429037080683
Validation loss: 2.718352984894923

Epoch: 5| Step: 5
Training loss: 1.2448263868440366
Validation loss: 2.7653416346554445

Epoch: 5| Step: 6
Training loss: 0.962850697523313
Validation loss: 2.740265802342325

Epoch: 5| Step: 7
Training loss: 1.441964472990433
Validation loss: 2.7848973093670417

Epoch: 5| Step: 8
Training loss: 1.017197726384336
Validation loss: 2.740461663163894

Epoch: 5| Step: 9
Training loss: 0.8212283153951615
Validation loss: 2.8105021197705726

Epoch: 5| Step: 10
Training loss: 0.9272141775028959
Validation loss: 2.809958793399094

Epoch: 5| Step: 11
Training loss: 1.2162967345931794
Validation loss: 2.792265227662089

Epoch: 181| Step: 0
Training loss: 0.8400169371418716
Validation loss: 2.762362594409311

Epoch: 5| Step: 1
Training loss: 0.803241207754989
Validation loss: 2.7850138737979586

Epoch: 5| Step: 2
Training loss: 0.9689210310055981
Validation loss: 2.770442581350066

Epoch: 5| Step: 3
Training loss: 1.2681157128608291
Validation loss: 2.841067460211969

Epoch: 5| Step: 4
Training loss: 1.205615154283504
Validation loss: 2.75208301837774

Epoch: 5| Step: 5
Training loss: 0.9014256418105838
Validation loss: 2.8036446930577505

Epoch: 5| Step: 6
Training loss: 0.7647668739469982
Validation loss: 2.7275987730809987

Epoch: 5| Step: 7
Training loss: 1.493450648746211
Validation loss: 2.7215984630292853

Epoch: 5| Step: 8
Training loss: 1.8839206204669507
Validation loss: 2.7338503325141064

Epoch: 5| Step: 9
Training loss: 1.3962515683622099
Validation loss: 2.8316076273167923

Epoch: 5| Step: 10
Training loss: 0.947272515026086
Validation loss: 2.696424743119707

Epoch: 5| Step: 11
Training loss: 1.6388850113271471
Validation loss: 2.7240805729169533

Epoch: 182| Step: 0
Training loss: 1.8215319433183639
Validation loss: 2.6375472813326124

Epoch: 5| Step: 1
Training loss: 0.8606087584891833
Validation loss: 2.7018721365371157

Epoch: 5| Step: 2
Training loss: 1.1559652029297947
Validation loss: 2.743724261969108

Epoch: 5| Step: 3
Training loss: 0.8490014367580051
Validation loss: 2.6946155070758353

Epoch: 5| Step: 4
Training loss: 1.1389441450924005
Validation loss: 2.7192156783840655

Epoch: 5| Step: 5
Training loss: 1.436827294883935
Validation loss: 2.710085178769172

Epoch: 5| Step: 6
Training loss: 0.6850451293405199
Validation loss: 2.8286768057053564

Epoch: 5| Step: 7
Training loss: 0.9785638062575047
Validation loss: 2.7010066344351404

Epoch: 5| Step: 8
Training loss: 0.8774272766843706
Validation loss: 2.7841480565089003

Epoch: 5| Step: 9
Training loss: 1.288323809196599
Validation loss: 2.7769569882390917

Epoch: 5| Step: 10
Training loss: 1.2491987044280972
Validation loss: 2.769968834918597

Epoch: 5| Step: 11
Training loss: 1.1576169671267136
Validation loss: 2.7387946242123005

Epoch: 183| Step: 0
Training loss: 0.9134987616966469
Validation loss: 2.741707211825596

Epoch: 5| Step: 1
Training loss: 1.1644369969471573
Validation loss: 2.6820768078917285

Epoch: 5| Step: 2
Training loss: 0.8821364320628026
Validation loss: 2.69537599645448

Epoch: 5| Step: 3
Training loss: 0.8852526269683599
Validation loss: 2.791180626467921

Epoch: 5| Step: 4
Training loss: 1.037526307289541
Validation loss: 2.659889398261665

Epoch: 5| Step: 5
Training loss: 1.0758422235899179
Validation loss: 2.7506749596392934

Epoch: 5| Step: 6
Training loss: 1.0922326598429197
Validation loss: 2.7260594272775935

Epoch: 5| Step: 7
Training loss: 1.2261870471687712
Validation loss: 2.7291168373354036

Epoch: 5| Step: 8
Training loss: 1.7604676940866049
Validation loss: 2.7006565943956784

Epoch: 5| Step: 9
Training loss: 0.6781830415629254
Validation loss: 2.8549820067200016

Epoch: 5| Step: 10
Training loss: 1.1030128076143502
Validation loss: 2.67186182885149

Epoch: 5| Step: 11
Training loss: 0.984148453574353
Validation loss: 2.688035057831954

Epoch: 184| Step: 0
Training loss: 1.588549787990468
Validation loss: 2.746217781836357

Epoch: 5| Step: 1
Training loss: 0.8330641232203627
Validation loss: 2.7499271910594625

Epoch: 5| Step: 2
Training loss: 0.8556023062349887
Validation loss: 2.8164141474527997

Epoch: 5| Step: 3
Training loss: 0.8602912180215445
Validation loss: 2.623894912985091

Epoch: 5| Step: 4
Training loss: 1.7597757862064434
Validation loss: 2.719624488325913

Epoch: 5| Step: 5
Training loss: 1.0612765168021299
Validation loss: 2.7973127644095244

Epoch: 5| Step: 6
Training loss: 0.8867342775304498
Validation loss: 2.7566005504048996

Epoch: 5| Step: 7
Training loss: 1.111660818707032
Validation loss: 2.710696445121934

Epoch: 5| Step: 8
Training loss: 1.0153511264976054
Validation loss: 2.764708595245703

Epoch: 5| Step: 9
Training loss: 0.8764926576584302
Validation loss: 2.8583274478870297

Epoch: 5| Step: 10
Training loss: 0.9141802915660693
Validation loss: 2.7415300905323865

Epoch: 5| Step: 11
Training loss: 0.48756276484681393
Validation loss: 2.7195775646988

Epoch: 185| Step: 0
Training loss: 0.9321337980019134
Validation loss: 2.8186288741336623

Epoch: 5| Step: 1
Training loss: 0.9935609517725813
Validation loss: 2.7496978564883308

Epoch: 5| Step: 2
Training loss: 1.1502316013648117
Validation loss: 2.7738263712737194

Epoch: 5| Step: 3
Training loss: 1.8777736493854673
Validation loss: 2.793944580049584

Epoch: 5| Step: 4
Training loss: 1.1786912159506424
Validation loss: 2.751942082480627

Epoch: 5| Step: 5
Training loss: 1.0980968202070194
Validation loss: 2.7235716818260016

Epoch: 5| Step: 6
Training loss: 0.9471613246481352
Validation loss: 2.755984859732245

Epoch: 5| Step: 7
Training loss: 1.2101509739346434
Validation loss: 2.7753375963535993

Epoch: 5| Step: 8
Training loss: 0.591629130444353
Validation loss: 2.633625137155645

Epoch: 5| Step: 9
Training loss: 0.831161689369603
Validation loss: 2.682586303133216

Epoch: 5| Step: 10
Training loss: 0.8028491232875834
Validation loss: 2.7870914251029744

Epoch: 5| Step: 11
Training loss: 1.325931667770876
Validation loss: 2.833238068316096

Epoch: 186| Step: 0
Training loss: 0.9235430674876105
Validation loss: 2.8895291871817252

Epoch: 5| Step: 1
Training loss: 0.8269721950229615
Validation loss: 2.7406386033999732

Epoch: 5| Step: 2
Training loss: 1.7812611763586803
Validation loss: 2.708975705969704

Epoch: 5| Step: 3
Training loss: 0.9416890332989366
Validation loss: 2.6736893841954195

Epoch: 5| Step: 4
Training loss: 1.118264219637546
Validation loss: 2.828040042675991

Epoch: 5| Step: 5
Training loss: 1.21088744029277
Validation loss: 2.763077365298115

Epoch: 5| Step: 6
Training loss: 1.1278098302795319
Validation loss: 2.8245534931504324

Epoch: 5| Step: 7
Training loss: 0.9348163659511313
Validation loss: 2.6962756808606425

Epoch: 5| Step: 8
Training loss: 1.0240907986327674
Validation loss: 2.7126467297387706

Epoch: 5| Step: 9
Training loss: 0.8881761111237344
Validation loss: 2.7137796196360013

Epoch: 5| Step: 10
Training loss: 1.164004023574482
Validation loss: 2.7422920670818534

Epoch: 5| Step: 11
Training loss: 1.5430874163228934
Validation loss: 2.809198960703589

Epoch: 187| Step: 0
Training loss: 1.0108822932786279
Validation loss: 2.729007837658199

Epoch: 5| Step: 1
Training loss: 1.0398249875961851
Validation loss: 2.785446315960423

Epoch: 5| Step: 2
Training loss: 1.0993811470454102
Validation loss: 2.8624006081973525

Epoch: 5| Step: 3
Training loss: 0.9962350483326395
Validation loss: 2.7807777803988145

Epoch: 5| Step: 4
Training loss: 1.1189030100436341
Validation loss: 2.8390212654194302

Epoch: 5| Step: 5
Training loss: 0.9645977865060447
Validation loss: 2.7233071700729985

Epoch: 5| Step: 6
Training loss: 0.6818066807340406
Validation loss: 2.845489493934328

Epoch: 5| Step: 7
Training loss: 1.786808576440051
Validation loss: 2.806995182741709

Epoch: 5| Step: 8
Training loss: 1.022979517376473
Validation loss: 2.767028991019324

Epoch: 5| Step: 9
Training loss: 0.9507886361279553
Validation loss: 2.8084596222536478

Epoch: 5| Step: 10
Training loss: 1.0421534291064243
Validation loss: 2.7541646921801934

Epoch: 5| Step: 11
Training loss: 1.268783114146787
Validation loss: 2.763175727512622

Epoch: 188| Step: 0
Training loss: 0.9813709135941022
Validation loss: 2.774729758068765

Epoch: 5| Step: 1
Training loss: 1.0179619531997408
Validation loss: 2.764896009385518

Epoch: 5| Step: 2
Training loss: 1.1126862123641883
Validation loss: 2.760586331509567

Epoch: 5| Step: 3
Training loss: 1.331206303985277
Validation loss: 2.7728268555547184

Epoch: 5| Step: 4
Training loss: 0.8450977017276718
Validation loss: 2.7661190812896588

Epoch: 5| Step: 5
Training loss: 0.7765990864599269
Validation loss: 2.7662934036170905

Epoch: 5| Step: 6
Training loss: 0.896902016156385
Validation loss: 2.826869682488623

Epoch: 5| Step: 7
Training loss: 0.981653903031934
Validation loss: 2.7627504967339935

Epoch: 5| Step: 8
Training loss: 0.8549664211371844
Validation loss: 2.750101658358182

Epoch: 5| Step: 9
Training loss: 1.7376231801669952
Validation loss: 2.721779936317635

Epoch: 5| Step: 10
Training loss: 1.0729527451952094
Validation loss: 2.8730841140875096

Epoch: 5| Step: 11
Training loss: 1.4424103338447942
Validation loss: 2.7803459341148353

Epoch: 189| Step: 0
Training loss: 1.0801441800163105
Validation loss: 2.8525119542086763

Epoch: 5| Step: 1
Training loss: 1.9868859452110843
Validation loss: 2.8188374255565343

Epoch: 5| Step: 2
Training loss: 1.0017736917487803
Validation loss: 2.810453889221851

Epoch: 5| Step: 3
Training loss: 1.064226206819305
Validation loss: 2.80252451182957

Epoch: 5| Step: 4
Training loss: 0.9923404966122947
Validation loss: 2.7851469905604835

Epoch: 5| Step: 5
Training loss: 0.7960856024537648
Validation loss: 2.756503261772508

Epoch: 5| Step: 6
Training loss: 0.8895185189380559
Validation loss: 2.8053420780868117

Epoch: 5| Step: 7
Training loss: 0.8399691820735707
Validation loss: 2.8275371664197713

Epoch: 5| Step: 8
Training loss: 0.8606851474463051
Validation loss: 2.7574752082644025

Epoch: 5| Step: 9
Training loss: 0.926873669150716
Validation loss: 2.81284727495691

Epoch: 5| Step: 10
Training loss: 1.1925230201562569
Validation loss: 2.74411479535057

Epoch: 5| Step: 11
Training loss: 0.30517971188874937
Validation loss: 2.7223994180906166

Epoch: 190| Step: 0
Training loss: 0.5155575159012084
Validation loss: 2.723448446094593

Epoch: 5| Step: 1
Training loss: 0.6067312061211049
Validation loss: 2.7809574994926525

Epoch: 5| Step: 2
Training loss: 1.1301961742866287
Validation loss: 2.779629235088534

Epoch: 5| Step: 3
Training loss: 2.153864549987957
Validation loss: 2.7532243285661555

Epoch: 5| Step: 4
Training loss: 0.8971013291983218
Validation loss: 2.8169171085600135

Epoch: 5| Step: 5
Training loss: 0.7584165937876843
Validation loss: 2.8044111882558496

Epoch: 5| Step: 6
Training loss: 0.8530615465090522
Validation loss: 2.7396303337233108

Epoch: 5| Step: 7
Training loss: 1.0535315501445428
Validation loss: 2.6518998558802953

Epoch: 5| Step: 8
Training loss: 0.9762951904661351
Validation loss: 2.7691525055493282

Epoch: 5| Step: 9
Training loss: 0.88486848953208
Validation loss: 2.775216136711686

Epoch: 5| Step: 10
Training loss: 0.9801756888185544
Validation loss: 2.8979268956683746

Epoch: 5| Step: 11
Training loss: 0.6121866456162632
Validation loss: 2.6165594685417464

Epoch: 191| Step: 0
Training loss: 0.801668485063115
Validation loss: 2.695457616760225

Epoch: 5| Step: 1
Training loss: 0.8504337214009388
Validation loss: 2.764322387196937

Epoch: 5| Step: 2
Training loss: 1.1365732316146897
Validation loss: 2.7798337938288626

Epoch: 5| Step: 3
Training loss: 0.8021516935933998
Validation loss: 2.788704978332096

Epoch: 5| Step: 4
Training loss: 0.8760726348689143
Validation loss: 2.791593758262053

Epoch: 5| Step: 5
Training loss: 0.7657560119641986
Validation loss: 2.7889852824772827

Epoch: 5| Step: 6
Training loss: 0.8191113351688893
Validation loss: 2.7097998823816245

Epoch: 5| Step: 7
Training loss: 0.9549973342518775
Validation loss: 2.801159860158473

Epoch: 5| Step: 8
Training loss: 0.9281815264407326
Validation loss: 2.775393832099953

Epoch: 5| Step: 9
Training loss: 1.917239297106489
Validation loss: 2.7285526594426135

Epoch: 5| Step: 10
Training loss: 0.9879625130618955
Validation loss: 2.76288804799722

Epoch: 5| Step: 11
Training loss: 0.3647181488730313
Validation loss: 2.748394076373173

Epoch: 192| Step: 0
Training loss: 1.1106265355809577
Validation loss: 2.7946051900905773

Epoch: 5| Step: 1
Training loss: 0.7797279026365309
Validation loss: 2.817580822488042

Epoch: 5| Step: 2
Training loss: 0.8844979999319077
Validation loss: 2.6910124159788396

Epoch: 5| Step: 3
Training loss: 0.8087143370416822
Validation loss: 2.7634950399269744

Epoch: 5| Step: 4
Training loss: 1.829423817985761
Validation loss: 2.7439011764588073

Epoch: 5| Step: 5
Training loss: 0.8072844884409738
Validation loss: 2.7628203213509126

Epoch: 5| Step: 6
Training loss: 0.6443521886685822
Validation loss: 2.744773277761592

Epoch: 5| Step: 7
Training loss: 1.0854875469433503
Validation loss: 2.7318149353385137

Epoch: 5| Step: 8
Training loss: 1.1229761250642394
Validation loss: 2.8098603930755846

Epoch: 5| Step: 9
Training loss: 0.9086380768161754
Validation loss: 2.779318488853053

Epoch: 5| Step: 10
Training loss: 0.9602067851835353
Validation loss: 2.8241318319548685

Epoch: 5| Step: 11
Training loss: 0.7680219381546841
Validation loss: 2.767104275882714

Epoch: 193| Step: 0
Training loss: 0.9764869050331096
Validation loss: 2.738631548494173

Epoch: 5| Step: 1
Training loss: 0.7612989785108749
Validation loss: 2.740164384516793

Epoch: 5| Step: 2
Training loss: 0.8471930860154435
Validation loss: 2.7502671494913393

Epoch: 5| Step: 3
Training loss: 0.8897335543569016
Validation loss: 2.776177581313197

Epoch: 5| Step: 4
Training loss: 1.2516403878844338
Validation loss: 2.8923428079352393

Epoch: 5| Step: 5
Training loss: 0.8353672399826866
Validation loss: 2.7726118515413964

Epoch: 5| Step: 6
Training loss: 0.7997337747700575
Validation loss: 2.791599797164411

Epoch: 5| Step: 7
Training loss: 1.0732689004616034
Validation loss: 2.743966258381766

Epoch: 5| Step: 8
Training loss: 1.6079040768181456
Validation loss: 2.759463603957776

Epoch: 5| Step: 9
Training loss: 1.1637371555852867
Validation loss: 2.7246721668368346

Epoch: 5| Step: 10
Training loss: 0.9980687626120186
Validation loss: 2.690946981797063

Epoch: 5| Step: 11
Training loss: 0.9926483405692941
Validation loss: 2.7590357955381704

Epoch: 194| Step: 0
Training loss: 0.5886988865882812
Validation loss: 2.7553101552646315

Epoch: 5| Step: 1
Training loss: 0.8393002903029113
Validation loss: 2.7961468272586423

Epoch: 5| Step: 2
Training loss: 1.2536731158611902
Validation loss: 2.7497296670052744

Epoch: 5| Step: 3
Training loss: 1.0608006519718383
Validation loss: 2.7283852650060183

Epoch: 5| Step: 4
Training loss: 1.3218316361910183
Validation loss: 2.714019137870463

Epoch: 5| Step: 5
Training loss: 0.8090844255042463
Validation loss: 2.792082639325144

Epoch: 5| Step: 6
Training loss: 0.8538678662327821
Validation loss: 2.79900023629316

Epoch: 5| Step: 7
Training loss: 0.9845619024225156
Validation loss: 2.7576503796064404

Epoch: 5| Step: 8
Training loss: 0.767819238120025
Validation loss: 2.7260019405639824

Epoch: 5| Step: 9
Training loss: 1.8507919317656214
Validation loss: 2.6809087626555606

Epoch: 5| Step: 10
Training loss: 0.9671926593796973
Validation loss: 2.7671308028079338

Epoch: 5| Step: 11
Training loss: 0.8902603540651308
Validation loss: 2.712744979665555

Epoch: 195| Step: 0
Training loss: 0.6568321869941871
Validation loss: 2.7439082978391944

Epoch: 5| Step: 1
Training loss: 0.8789434467497788
Validation loss: 2.782059148177045

Epoch: 5| Step: 2
Training loss: 0.9101720653027586
Validation loss: 2.744202238683114

Epoch: 5| Step: 3
Training loss: 0.8242000559634861
Validation loss: 2.788722447627266

Epoch: 5| Step: 4
Training loss: 0.8037622929014168
Validation loss: 2.825888935259433

Epoch: 5| Step: 5
Training loss: 1.9341839130536116
Validation loss: 2.7780840888942686

Epoch: 5| Step: 6
Training loss: 1.0207883020446735
Validation loss: 2.601156224019771

Epoch: 5| Step: 7
Training loss: 0.8404377101166878
Validation loss: 2.830718317979076

Epoch: 5| Step: 8
Training loss: 0.9014446188090115
Validation loss: 2.767173839860626

Epoch: 5| Step: 9
Training loss: 1.0905112679978084
Validation loss: 2.755917060765588

Epoch: 5| Step: 10
Training loss: 0.7321468396360962
Validation loss: 2.774919022847798

Epoch: 5| Step: 11
Training loss: 0.8568458099179087
Validation loss: 2.7557467575727843

Epoch: 196| Step: 0
Training loss: 0.7780166473936618
Validation loss: 2.816285453953618

Epoch: 5| Step: 1
Training loss: 1.184986616855811
Validation loss: 2.8005045812238225

Epoch: 5| Step: 2
Training loss: 0.8799993202900429
Validation loss: 2.7294053975491495

Epoch: 5| Step: 3
Training loss: 1.1065515398173809
Validation loss: 2.853302175000412

Epoch: 5| Step: 4
Training loss: 0.6991461178014687
Validation loss: 2.7137882147508057

Epoch: 5| Step: 5
Training loss: 1.0320186640212392
Validation loss: 2.763095402887322

Epoch: 5| Step: 6
Training loss: 1.6596685433674352
Validation loss: 2.7980392313225324

Epoch: 5| Step: 7
Training loss: 1.1955573136692128
Validation loss: 2.71542780606128

Epoch: 5| Step: 8
Training loss: 0.8837727750678918
Validation loss: 2.7437933271024133

Epoch: 5| Step: 9
Training loss: 0.9542040111002493
Validation loss: 2.7893736315806574

Epoch: 5| Step: 10
Training loss: 0.926663296445257
Validation loss: 2.708782713850524

Epoch: 5| Step: 11
Training loss: 0.6575670196549015
Validation loss: 2.7706039496294137

Epoch: 197| Step: 0
Training loss: 0.8438716023732293
Validation loss: 2.831107251496365

Epoch: 5| Step: 1
Training loss: 0.8486149021097996
Validation loss: 2.80021752253354

Epoch: 5| Step: 2
Training loss: 0.6685220757793199
Validation loss: 2.810820717512316

Epoch: 5| Step: 3
Training loss: 0.8526617532125741
Validation loss: 2.733477396095476

Epoch: 5| Step: 4
Training loss: 1.0586776981639798
Validation loss: 2.7644551168135165

Epoch: 5| Step: 5
Training loss: 1.2287675511299025
Validation loss: 2.702703196814423

Epoch: 5| Step: 6
Training loss: 1.8333288611733192
Validation loss: 2.7987677458279605

Epoch: 5| Step: 7
Training loss: 0.6445750366133991
Validation loss: 2.8281215541249565

Epoch: 5| Step: 8
Training loss: 0.7616014439170438
Validation loss: 2.78810650338573

Epoch: 5| Step: 9
Training loss: 0.9718284301394245
Validation loss: 2.751425139020264

Epoch: 5| Step: 10
Training loss: 0.7723435651534699
Validation loss: 2.7863344872068367

Epoch: 5| Step: 11
Training loss: 0.7407087753494002
Validation loss: 2.800118865033237

Epoch: 198| Step: 0
Training loss: 0.7452214519301223
Validation loss: 2.743940233400618

Epoch: 5| Step: 1
Training loss: 0.9328588362388205
Validation loss: 2.7748318171585136

Epoch: 5| Step: 2
Training loss: 0.9878188547993786
Validation loss: 2.794177411388016

Epoch: 5| Step: 3
Training loss: 0.7235767584749533
Validation loss: 2.7707013634156623

Epoch: 5| Step: 4
Training loss: 1.858425763601317
Validation loss: 2.8375804160118054

Epoch: 5| Step: 5
Training loss: 0.9674148280088778
Validation loss: 2.8030877469868

Epoch: 5| Step: 6
Training loss: 0.7663668716689006
Validation loss: 2.7682490535008597

Epoch: 5| Step: 7
Training loss: 1.0942856703050001
Validation loss: 2.8132093135581306

Epoch: 5| Step: 8
Training loss: 0.7321740303314735
Validation loss: 2.7857437976443005

Epoch: 5| Step: 9
Training loss: 0.6857479702567985
Validation loss: 2.789357943518673

Epoch: 5| Step: 10
Training loss: 0.9748450779710919
Validation loss: 2.7361165449784526

Epoch: 5| Step: 11
Training loss: 0.6517185253068842
Validation loss: 2.7843345617746538

Epoch: 199| Step: 0
Training loss: 0.5819442223123851
Validation loss: 2.796103689014939

Epoch: 5| Step: 1
Training loss: 0.927770417165841
Validation loss: 2.7298665217080704

Epoch: 5| Step: 2
Training loss: 1.0126159695744277
Validation loss: 2.8114104809716225

Epoch: 5| Step: 3
Training loss: 0.8260539085632366
Validation loss: 2.770628517631112

Epoch: 5| Step: 4
Training loss: 0.9356353654204461
Validation loss: 2.7071504222625413

Epoch: 5| Step: 5
Training loss: 0.9612208933199758
Validation loss: 2.8214943963920818

Epoch: 5| Step: 6
Training loss: 0.9231692135811244
Validation loss: 2.8612155028519393

Epoch: 5| Step: 7
Training loss: 0.9115044100786035
Validation loss: 2.7541089066774367

Epoch: 5| Step: 8
Training loss: 1.8859046459101734
Validation loss: 2.792991577624242

Epoch: 5| Step: 9
Training loss: 0.7627674415467194
Validation loss: 2.8186368006033278

Epoch: 5| Step: 10
Training loss: 0.9868709467973152
Validation loss: 2.760044455475458

Epoch: 5| Step: 11
Training loss: 0.7436677727003549
Validation loss: 2.75529673217609

Epoch: 200| Step: 0
Training loss: 1.7134671953554659
Validation loss: 2.730967576608862

Epoch: 5| Step: 1
Training loss: 1.0244919099129934
Validation loss: 2.780087731781495

Epoch: 5| Step: 2
Training loss: 1.2497610817509683
Validation loss: 2.8144230237626653

Epoch: 5| Step: 3
Training loss: 0.7241959124835613
Validation loss: 2.76604724972442

Epoch: 5| Step: 4
Training loss: 0.746970814580314
Validation loss: 2.7490673795703526

Epoch: 5| Step: 5
Training loss: 0.789991870126057
Validation loss: 2.853689395140148

Epoch: 5| Step: 6
Training loss: 0.6197238425535667
Validation loss: 2.840849714410054

Epoch: 5| Step: 7
Training loss: 1.1272473670114853
Validation loss: 2.7844725238177146

Epoch: 5| Step: 8
Training loss: 0.7720573518776425
Validation loss: 2.7747237289932873

Epoch: 5| Step: 9
Training loss: 1.057100206650694
Validation loss: 2.824678544516578

Epoch: 5| Step: 10
Training loss: 0.9829531194523197
Validation loss: 2.827629038842514

Epoch: 5| Step: 11
Training loss: 0.7352211318537466
Validation loss: 2.8439869939121727

Epoch: 201| Step: 0
Training loss: 0.9451995971345467
Validation loss: 2.758323676091448

Epoch: 5| Step: 1
Training loss: 0.8610872031211992
Validation loss: 2.7323708337466166

Epoch: 5| Step: 2
Training loss: 1.8092219866156938
Validation loss: 2.7348385917404103

Epoch: 5| Step: 3
Training loss: 0.6720755965167304
Validation loss: 2.783853241242605

Epoch: 5| Step: 4
Training loss: 0.7202730213525917
Validation loss: 2.7743275355992285

Epoch: 5| Step: 5
Training loss: 0.8637705663283439
Validation loss: 2.7701692801265954

Epoch: 5| Step: 6
Training loss: 0.8177837086012718
Validation loss: 2.808134792216565

Epoch: 5| Step: 7
Training loss: 1.0699744700122364
Validation loss: 2.8921419064173737

Epoch: 5| Step: 8
Training loss: 0.894301205835614
Validation loss: 2.819590313170291

Epoch: 5| Step: 9
Training loss: 0.7579608654020256
Validation loss: 2.767335772082572

Epoch: 5| Step: 10
Training loss: 0.7510867193062416
Validation loss: 2.7638481524248713

Epoch: 5| Step: 11
Training loss: 1.195393677990493
Validation loss: 2.7968452814324074

Epoch: 202| Step: 0
Training loss: 0.5876197063967952
Validation loss: 2.7403351667106715

Epoch: 5| Step: 1
Training loss: 0.6655371505003582
Validation loss: 2.707734237335274

Epoch: 5| Step: 2
Training loss: 0.7319891299707009
Validation loss: 2.7698386254453915

Epoch: 5| Step: 3
Training loss: 1.3062515477805572
Validation loss: 2.784248639317442

Epoch: 5| Step: 4
Training loss: 0.8565570754025917
Validation loss: 2.8146671705280157

Epoch: 5| Step: 5
Training loss: 0.9923957546075671
Validation loss: 2.706698093950242

Epoch: 5| Step: 6
Training loss: 0.7017500255056064
Validation loss: 2.828093597069158

Epoch: 5| Step: 7
Training loss: 0.9849017414229838
Validation loss: 2.729672579186836

Epoch: 5| Step: 8
Training loss: 1.7095389027795118
Validation loss: 2.81387576610304

Epoch: 5| Step: 9
Training loss: 0.8762496131428125
Validation loss: 2.7733786294626

Epoch: 5| Step: 10
Training loss: 0.8872371956080554
Validation loss: 2.833287629058068

Epoch: 5| Step: 11
Training loss: 0.3707482184909402
Validation loss: 2.7806180135933976

Epoch: 203| Step: 0
Training loss: 0.9219575618691764
Validation loss: 2.8945179371392515

Epoch: 5| Step: 1
Training loss: 0.5847304818417475
Validation loss: 2.8166078132955232

Epoch: 5| Step: 2
Training loss: 0.781438347047226
Validation loss: 2.725492411345659

Epoch: 5| Step: 3
Training loss: 0.5860077116543454
Validation loss: 2.828119102317323

Epoch: 5| Step: 4
Training loss: 1.1806429599993267
Validation loss: 2.7923377295668907

Epoch: 5| Step: 5
Training loss: 1.0874435081278686
Validation loss: 2.790783914567224

Epoch: 5| Step: 6
Training loss: 1.6581392848797485
Validation loss: 2.7428192649880447

Epoch: 5| Step: 7
Training loss: 0.9854671232815827
Validation loss: 2.785533895477025

Epoch: 5| Step: 8
Training loss: 0.9326152382076324
Validation loss: 2.8732572228289386

Epoch: 5| Step: 9
Training loss: 0.9457133365475283
Validation loss: 2.7351853868243174

Epoch: 5| Step: 10
Training loss: 0.7886629887269658
Validation loss: 2.767502849437254

Epoch: 5| Step: 11
Training loss: 0.7533585530535399
Validation loss: 2.826357593071516

Epoch: 204| Step: 0
Training loss: 0.7734050551265805
Validation loss: 2.8405348484742228

Epoch: 5| Step: 1
Training loss: 1.046214222541269
Validation loss: 2.7490705993112114

Epoch: 5| Step: 2
Training loss: 0.8328720644035057
Validation loss: 2.785217987132462

Epoch: 5| Step: 3
Training loss: 1.0727897433171116
Validation loss: 2.810557079318752

Epoch: 5| Step: 4
Training loss: 0.6215776681559606
Validation loss: 2.8216405825377233

Epoch: 5| Step: 5
Training loss: 0.6538399082744286
Validation loss: 2.7563944801067892

Epoch: 5| Step: 6
Training loss: 1.6024047125756093
Validation loss: 2.8050517604537837

Epoch: 5| Step: 7
Training loss: 0.9239588638929171
Validation loss: 2.7735782426395543

Epoch: 5| Step: 8
Training loss: 0.9567022575565504
Validation loss: 2.7369939632481604

Epoch: 5| Step: 9
Training loss: 0.9985220835979545
Validation loss: 2.8025689336526605

Epoch: 5| Step: 10
Training loss: 0.9112780946814493
Validation loss: 2.739528769081475

Epoch: 5| Step: 11
Training loss: 1.098406660751296
Validation loss: 2.6992058613345695

Epoch: 205| Step: 0
Training loss: 0.8152443315366821
Validation loss: 2.7976339258892122

Epoch: 5| Step: 1
Training loss: 0.9791134589869069
Validation loss: 2.6417644551576216

Epoch: 5| Step: 2
Training loss: 0.8569124485460966
Validation loss: 2.8766228546049266

Epoch: 5| Step: 3
Training loss: 0.5383234348016958
Validation loss: 2.732747372810344

Epoch: 5| Step: 4
Training loss: 1.7076569202752325
Validation loss: 2.8528848064384267

Epoch: 5| Step: 5
Training loss: 0.9130075349653493
Validation loss: 2.8089294303733596

Epoch: 5| Step: 6
Training loss: 0.8668862240483428
Validation loss: 2.786147687952279

Epoch: 5| Step: 7
Training loss: 0.664562979200139
Validation loss: 2.7744098087266096

Epoch: 5| Step: 8
Training loss: 0.7055099728729001
Validation loss: 2.7385880302508325

Epoch: 5| Step: 9
Training loss: 1.1149356796118917
Validation loss: 2.7538205649751304

Epoch: 5| Step: 10
Training loss: 1.094840732035146
Validation loss: 2.7310244713730643

Epoch: 5| Step: 11
Training loss: 0.8868284787752106
Validation loss: 2.756381040674478

Epoch: 206| Step: 0
Training loss: 1.0329412406059189
Validation loss: 2.8027374799226052

Epoch: 5| Step: 1
Training loss: 0.9478512241843198
Validation loss: 2.7575241132600126

Epoch: 5| Step: 2
Training loss: 0.7655046329470218
Validation loss: 2.7822929241406564

Epoch: 5| Step: 3
Training loss: 1.0203034848900039
Validation loss: 2.775046885440868

Epoch: 5| Step: 4
Training loss: 1.2595777741180272
Validation loss: 2.753013130539115

Epoch: 5| Step: 5
Training loss: 0.8063805925337652
Validation loss: 2.7099400901565334

Epoch: 5| Step: 6
Training loss: 0.6705218150596035
Validation loss: 2.7665505414073985

Epoch: 5| Step: 7
Training loss: 0.8848509757871669
Validation loss: 2.828788173753412

Epoch: 5| Step: 8
Training loss: 1.6172239879969952
Validation loss: 2.670443915654024

Epoch: 5| Step: 9
Training loss: 0.9036155424437085
Validation loss: 2.7509761508322486

Epoch: 5| Step: 10
Training loss: 0.9483815649591487
Validation loss: 2.6493286051538405

Epoch: 5| Step: 11
Training loss: 0.7806745317075402
Validation loss: 2.72432466429974

Epoch: 207| Step: 0
Training loss: 0.7041455809316053
Validation loss: 2.729138775797037

Epoch: 5| Step: 1
Training loss: 0.8106234227079107
Validation loss: 2.7309664525970416

Epoch: 5| Step: 2
Training loss: 0.8826323131219952
Validation loss: 2.753760667203911

Epoch: 5| Step: 3
Training loss: 0.883301793441066
Validation loss: 2.8044694675857396

Epoch: 5| Step: 4
Training loss: 0.6737973413484591
Validation loss: 2.7173008473032656

Epoch: 5| Step: 5
Training loss: 1.619671153729971
Validation loss: 2.7360308075161694

Epoch: 5| Step: 6
Training loss: 0.7600025895978075
Validation loss: 2.7708333715759124

Epoch: 5| Step: 7
Training loss: 1.0428794222521578
Validation loss: 2.703798842186629

Epoch: 5| Step: 8
Training loss: 0.7562564723470854
Validation loss: 2.7683194822481245

Epoch: 5| Step: 9
Training loss: 0.8205085883333261
Validation loss: 2.7332683649037257

Epoch: 5| Step: 10
Training loss: 1.0500096888322223
Validation loss: 2.782637896335434

Epoch: 5| Step: 11
Training loss: 1.0579406300059715
Validation loss: 2.772749845118678

Epoch: 208| Step: 0
Training loss: 0.5820122274068033
Validation loss: 2.7001765346506503

Epoch: 5| Step: 1
Training loss: 0.7595990152740323
Validation loss: 2.7752917578830236

Epoch: 5| Step: 2
Training loss: 1.0488502883700517
Validation loss: 2.807560560457022

Epoch: 5| Step: 3
Training loss: 0.9983811686449298
Validation loss: 2.684283827187043

Epoch: 5| Step: 4
Training loss: 0.9157580763939477
Validation loss: 2.789794480326622

Epoch: 5| Step: 5
Training loss: 0.7227087053386149
Validation loss: 2.7494471131470237

Epoch: 5| Step: 6
Training loss: 1.0674743892268672
Validation loss: 2.7687340123825095

Epoch: 5| Step: 7
Training loss: 1.551872196387018
Validation loss: 2.7530993386442764

Epoch: 5| Step: 8
Training loss: 0.7412566923511607
Validation loss: 2.749795772453954

Epoch: 5| Step: 9
Training loss: 0.5588159186033913
Validation loss: 2.7955956258978194

Epoch: 5| Step: 10
Training loss: 0.8525389576285911
Validation loss: 2.791717704382324

Epoch: 5| Step: 11
Training loss: 2.1831393784235993
Validation loss: 2.7296588589774813

Epoch: 209| Step: 0
Training loss: 1.0375219411713013
Validation loss: 2.8655326911593746

Epoch: 5| Step: 1
Training loss: 1.2178180750640206
Validation loss: 2.795942442300411

Epoch: 5| Step: 2
Training loss: 0.8310259983297167
Validation loss: 2.775165313373138

Epoch: 5| Step: 3
Training loss: 0.7902330836965784
Validation loss: 2.8133060465882247

Epoch: 5| Step: 4
Training loss: 0.7993163689652366
Validation loss: 2.8221619654079584

Epoch: 5| Step: 5
Training loss: 0.8836879946419082
Validation loss: 2.7113775029971583

Epoch: 5| Step: 6
Training loss: 0.9784188898510361
Validation loss: 2.6907237478958788

Epoch: 5| Step: 7
Training loss: 0.8103589678885915
Validation loss: 2.7024826506705635

Epoch: 5| Step: 8
Training loss: 0.7891345227297033
Validation loss: 2.812757116503646

Epoch: 5| Step: 9
Training loss: 1.7156862869850393
Validation loss: 2.7861592117379916

Epoch: 5| Step: 10
Training loss: 0.7172347142587492
Validation loss: 2.721622341880925

Epoch: 5| Step: 11
Training loss: 0.3192376385037874
Validation loss: 2.8059679613217052

Epoch: 210| Step: 0
Training loss: 0.8898075099729321
Validation loss: 2.809509096350526

Epoch: 5| Step: 1
Training loss: 1.0487426495663896
Validation loss: 2.770442269390019

Epoch: 5| Step: 2
Training loss: 0.8806559122587869
Validation loss: 2.7664709467676576

Epoch: 5| Step: 3
Training loss: 0.7636660212221696
Validation loss: 2.82813037077954

Epoch: 5| Step: 4
Training loss: 0.76467462838287
Validation loss: 2.7129022109624437

Epoch: 5| Step: 5
Training loss: 0.6374016826211836
Validation loss: 2.776677580684524

Epoch: 5| Step: 6
Training loss: 0.9146203189285356
Validation loss: 2.8338872295671753

Epoch: 5| Step: 7
Training loss: 1.2226975894069643
Validation loss: 2.7908347880759385

Epoch: 5| Step: 8
Training loss: 0.7424602208254724
Validation loss: 2.754282651027837

Epoch: 5| Step: 9
Training loss: 1.603105722649805
Validation loss: 2.8403078160929525

Epoch: 5| Step: 10
Training loss: 0.5863069768112182
Validation loss: 2.79814838213052

Epoch: 5| Step: 11
Training loss: 1.20744055070506
Validation loss: 2.772394516093139

Epoch: 211| Step: 0
Training loss: 0.5976457283240757
Validation loss: 2.759004247144569

Epoch: 5| Step: 1
Training loss: 0.7991609509581574
Validation loss: 2.7798859183599363

Epoch: 5| Step: 2
Training loss: 0.8859064692154152
Validation loss: 2.7820057502941284

Epoch: 5| Step: 3
Training loss: 0.8939186563949463
Validation loss: 2.712043496288294

Epoch: 5| Step: 4
Training loss: 0.9833898004116579
Validation loss: 2.7666556957517594

Epoch: 5| Step: 5
Training loss: 0.8570220640762982
Validation loss: 2.792141010542792

Epoch: 5| Step: 6
Training loss: 1.1432755909084074
Validation loss: 2.8259668387885672

Epoch: 5| Step: 7
Training loss: 1.8103548048868836
Validation loss: 2.8012884683618884

Epoch: 5| Step: 8
Training loss: 0.8422995568855005
Validation loss: 2.709099750404243

Epoch: 5| Step: 9
Training loss: 1.023799919429775
Validation loss: 2.831455191418072

Epoch: 5| Step: 10
Training loss: 0.7624450351102898
Validation loss: 2.7863118332233654

Epoch: 5| Step: 11
Training loss: 0.6074766766030855
Validation loss: 2.763505288574954

Epoch: 212| Step: 0
Training loss: 1.7066877704795747
Validation loss: 2.8168002702601473

Epoch: 5| Step: 1
Training loss: 0.9145834000977743
Validation loss: 2.734788456493532

Epoch: 5| Step: 2
Training loss: 0.5817693082492912
Validation loss: 2.789972813894247

Epoch: 5| Step: 3
Training loss: 0.7500275765753377
Validation loss: 2.7706862831294043

Epoch: 5| Step: 4
Training loss: 0.6169423690926832
Validation loss: 2.7590288788303887

Epoch: 5| Step: 5
Training loss: 0.9351781385213621
Validation loss: 2.730381674553717

Epoch: 5| Step: 6
Training loss: 1.0479661749083966
Validation loss: 2.8315931906568457

Epoch: 5| Step: 7
Training loss: 0.875232631549156
Validation loss: 2.8416595635553743

Epoch: 5| Step: 8
Training loss: 0.9338155826073216
Validation loss: 2.8342930217973885

Epoch: 5| Step: 9
Training loss: 0.872210347208824
Validation loss: 2.8458521482554078

Epoch: 5| Step: 10
Training loss: 0.6063420550271518
Validation loss: 2.8367278834064336

Epoch: 5| Step: 11
Training loss: 0.7060405893356044
Validation loss: 2.895175637312661

Epoch: 213| Step: 0
Training loss: 1.0931579077136566
Validation loss: 2.7541657309787873

Epoch: 5| Step: 1
Training loss: 0.7865812361391178
Validation loss: 2.8106194814387906

Epoch: 5| Step: 2
Training loss: 0.9160154297915903
Validation loss: 2.7519786789309832

Epoch: 5| Step: 3
Training loss: 0.9914890444117102
Validation loss: 2.7577059853996637

Epoch: 5| Step: 4
Training loss: 0.8182547053951514
Validation loss: 2.7810144503283287

Epoch: 5| Step: 5
Training loss: 0.8920377268232829
Validation loss: 2.8064506818668806

Epoch: 5| Step: 6
Training loss: 0.7655238259866435
Validation loss: 2.811241101275888

Epoch: 5| Step: 7
Training loss: 1.1362569073927684
Validation loss: 2.830597672951387

Epoch: 5| Step: 8
Training loss: 0.7219409598729223
Validation loss: 2.7692696215072274

Epoch: 5| Step: 9
Training loss: 1.0525170492934282
Validation loss: 2.8476635061135833

Epoch: 5| Step: 10
Training loss: 1.591202214101111
Validation loss: 2.812911346165692

Epoch: 5| Step: 11
Training loss: 0.309856006189465
Validation loss: 2.8385621073042273

Epoch: 214| Step: 0
Training loss: 0.9745804165071696
Validation loss: 2.7740380581667865

Epoch: 5| Step: 1
Training loss: 0.9111801740269566
Validation loss: 2.7865467960659105

Epoch: 5| Step: 2
Training loss: 0.8179825163140985
Validation loss: 2.8060189631340875

Epoch: 5| Step: 3
Training loss: 0.7948504141664479
Validation loss: 2.8869821740568984

Epoch: 5| Step: 4
Training loss: 1.5594276740403012
Validation loss: 2.7616385808420922

Epoch: 5| Step: 5
Training loss: 1.0212759239240223
Validation loss: 2.7815172159934294

Epoch: 5| Step: 6
Training loss: 0.7824151696362037
Validation loss: 2.8289651904795696

Epoch: 5| Step: 7
Training loss: 0.5947765210345037
Validation loss: 2.7458829911931706

Epoch: 5| Step: 8
Training loss: 0.6422246175095806
Validation loss: 2.835058340479284

Epoch: 5| Step: 9
Training loss: 0.629860124992637
Validation loss: 2.77322323468452

Epoch: 5| Step: 10
Training loss: 0.8342800643574685
Validation loss: 2.763913417006579

Epoch: 5| Step: 11
Training loss: 0.691668121401471
Validation loss: 2.770084912224311

Epoch: 215| Step: 0
Training loss: 0.5843413674779122
Validation loss: 2.792696297968355

Epoch: 5| Step: 1
Training loss: 0.8822805101454176
Validation loss: 2.789553156559638

Epoch: 5| Step: 2
Training loss: 1.7800276728418476
Validation loss: 2.7310678737041694

Epoch: 5| Step: 3
Training loss: 0.6054597669365744
Validation loss: 2.766791778248106

Epoch: 5| Step: 4
Training loss: 0.7706724119181244
Validation loss: 2.944488308887718

Epoch: 5| Step: 5
Training loss: 0.7584579707692852
Validation loss: 2.74665884585872

Epoch: 5| Step: 6
Training loss: 0.7285274883050917
Validation loss: 2.8106778988883696

Epoch: 5| Step: 7
Training loss: 0.8243930867302742
Validation loss: 2.7138051376762418

Epoch: 5| Step: 8
Training loss: 0.9732360949891145
Validation loss: 2.75195178935928

Epoch: 5| Step: 9
Training loss: 0.595505628522382
Validation loss: 2.718494388651475

Epoch: 5| Step: 10
Training loss: 1.2229909225526239
Validation loss: 2.8617379512380485

Epoch: 5| Step: 11
Training loss: 0.29186608388707375
Validation loss: 2.8177788855462835

Epoch: 216| Step: 0
Training loss: 0.9392480447935133
Validation loss: 2.7715206632238996

Epoch: 5| Step: 1
Training loss: 0.8406684906781178
Validation loss: 2.7322818410282017

Epoch: 5| Step: 2
Training loss: 0.9449725209635895
Validation loss: 2.7911775158076226

Epoch: 5| Step: 3
Training loss: 0.7275412745090115
Validation loss: 2.8086575008791788

Epoch: 5| Step: 4
Training loss: 0.7653664132782427
Validation loss: 2.7688452118002056

Epoch: 5| Step: 5
Training loss: 0.7428846598470038
Validation loss: 2.68220017039467

Epoch: 5| Step: 6
Training loss: 0.9112105259763775
Validation loss: 2.7983063315459016

Epoch: 5| Step: 7
Training loss: 0.9453479980865602
Validation loss: 2.722896968465788

Epoch: 5| Step: 8
Training loss: 0.4472356894524131
Validation loss: 2.7780766063461546

Epoch: 5| Step: 9
Training loss: 0.7362131691805394
Validation loss: 2.759646917779167

Epoch: 5| Step: 10
Training loss: 0.8856333673118247
Validation loss: 2.7821072853793747

Epoch: 5| Step: 11
Training loss: 3.257187598143452
Validation loss: 2.7617185773404294

Epoch: 217| Step: 0
Training loss: 0.6527157025774034
Validation loss: 2.806644376868614

Epoch: 5| Step: 1
Training loss: 0.9313695101250438
Validation loss: 2.8220473296364217

Epoch: 5| Step: 2
Training loss: 0.7576034100138568
Validation loss: 2.794548327818871

Epoch: 5| Step: 3
Training loss: 1.1934554190937325
Validation loss: 2.7973822234982793

Epoch: 5| Step: 4
Training loss: 0.4829796412266427
Validation loss: 2.731963440269268

Epoch: 5| Step: 5
Training loss: 0.7881909457636488
Validation loss: 2.7845458190587062

Epoch: 5| Step: 6
Training loss: 1.6735212118116898
Validation loss: 2.7893819688326307

Epoch: 5| Step: 7
Training loss: 0.6978085324985654
Validation loss: 2.6908970218665265

Epoch: 5| Step: 8
Training loss: 0.6879820434200892
Validation loss: 2.7798925008618154

Epoch: 5| Step: 9
Training loss: 0.5078350942426966
Validation loss: 2.843421141504761

Epoch: 5| Step: 10
Training loss: 0.7214767315206162
Validation loss: 2.7760957720972765

Epoch: 5| Step: 11
Training loss: 0.729062690587679
Validation loss: 2.7774873670456093

Epoch: 218| Step: 0
Training loss: 0.7217482765237958
Validation loss: 2.7847731096232486

Epoch: 5| Step: 1
Training loss: 0.6988761957820514
Validation loss: 2.7677933333991893

Epoch: 5| Step: 2
Training loss: 0.6183016896526627
Validation loss: 2.8481891763084004

Epoch: 5| Step: 3
Training loss: 0.8126076113523495
Validation loss: 2.747984557630242

Epoch: 5| Step: 4
Training loss: 0.7588401590667706
Validation loss: 2.7657506379004326

Epoch: 5| Step: 5
Training loss: 0.9219892398719391
Validation loss: 2.862418911825117

Epoch: 5| Step: 6
Training loss: 0.9180412750813499
Validation loss: 2.7500294698234344

Epoch: 5| Step: 7
Training loss: 1.0227417655842723
Validation loss: 2.7436766353232667

Epoch: 5| Step: 8
Training loss: 0.6844326648194767
Validation loss: 2.7813716318915493

Epoch: 5| Step: 9
Training loss: 0.7277094903808039
Validation loss: 2.820490383269302

Epoch: 5| Step: 10
Training loss: 1.5701141991357306
Validation loss: 2.709240359253835

Epoch: 5| Step: 11
Training loss: 0.3207834781991132
Validation loss: 2.758945880585162

Epoch: 219| Step: 0
Training loss: 0.8078145866440878
Validation loss: 2.7917811076112766

Epoch: 5| Step: 1
Training loss: 1.0095085244690343
Validation loss: 2.7982212605753016

Epoch: 5| Step: 2
Training loss: 0.8163244763173315
Validation loss: 2.7761321109736365

Epoch: 5| Step: 3
Training loss: 0.8162882961501979
Validation loss: 2.785830319422275

Epoch: 5| Step: 4
Training loss: 0.8482613930492211
Validation loss: 2.736288705270034

Epoch: 5| Step: 5
Training loss: 1.6288545815302902
Validation loss: 2.721022883545762

Epoch: 5| Step: 6
Training loss: 0.8334675958875802
Validation loss: 2.82079423081884

Epoch: 5| Step: 7
Training loss: 0.5941160980719856
Validation loss: 2.8093965008358093

Epoch: 5| Step: 8
Training loss: 1.0686004757157042
Validation loss: 2.7480214272997037

Epoch: 5| Step: 9
Training loss: 0.8810089390352078
Validation loss: 2.7467194735576377

Epoch: 5| Step: 10
Training loss: 0.7223930085632791
Validation loss: 2.817950382283851

Epoch: 5| Step: 11
Training loss: 0.6742811808407744
Validation loss: 2.790138528591014

Epoch: 220| Step: 0
Training loss: 0.5653382327842885
Validation loss: 2.737964620890602

Epoch: 5| Step: 1
Training loss: 0.8388672585537296
Validation loss: 2.8051578796718557

Epoch: 5| Step: 2
Training loss: 0.5458641519169605
Validation loss: 2.7999922679896545

Epoch: 5| Step: 3
Training loss: 0.7778385447045633
Validation loss: 2.8146948621231553

Epoch: 5| Step: 4
Training loss: 0.6787980936198982
Validation loss: 2.819991420175924

Epoch: 5| Step: 5
Training loss: 0.8115662931839083
Validation loss: 2.828616245381704

Epoch: 5| Step: 6
Training loss: 0.8474981274766968
Validation loss: 2.789404797319004

Epoch: 5| Step: 7
Training loss: 0.538818359375
Validation loss: 2.815462516022547

Epoch: 5| Step: 8
Training loss: 0.39747546495136543
Validation loss: 2.846658061639509

Epoch: 5| Step: 9
Training loss: 0.727178415094993
Validation loss: 2.8021498013995143

Epoch: 5| Step: 10
Training loss: 1.7348526992711326
Validation loss: 2.840659974417614

Epoch: 5| Step: 11
Training loss: 1.0204711323402036
Validation loss: 2.7534341646482443

Epoch: 221| Step: 0
Training loss: 0.8316413789802168
Validation loss: 2.7750116456849936

Epoch: 5| Step: 1
Training loss: 0.706071402324194
Validation loss: 2.7689749908309773

Epoch: 5| Step: 2
Training loss: 0.8751329252911002
Validation loss: 2.82987593443459

Epoch: 5| Step: 3
Training loss: 0.6391989023749437
Validation loss: 2.7531727600862337

Epoch: 5| Step: 4
Training loss: 0.6803358208755529
Validation loss: 2.8074628297695265

Epoch: 5| Step: 5
Training loss: 0.848669334477349
Validation loss: 2.736186334029924

Epoch: 5| Step: 6
Training loss: 0.6384205221494511
Validation loss: 2.840530616778565

Epoch: 5| Step: 7
Training loss: 0.9211084767491712
Validation loss: 2.734119654040738

Epoch: 5| Step: 8
Training loss: 0.8463928370322304
Validation loss: 2.8144743453317167

Epoch: 5| Step: 9
Training loss: 0.9731052082575093
Validation loss: 2.7372097071939274

Epoch: 5| Step: 10
Training loss: 0.7366558934052563
Validation loss: 2.7847207019978275

Epoch: 5| Step: 11
Training loss: 3.311964603557424
Validation loss: 2.8066940603388026

Epoch: 222| Step: 0
Training loss: 0.8581165462780419
Validation loss: 2.7411076556042957

Epoch: 5| Step: 1
Training loss: 0.9955688589567007
Validation loss: 2.80170898820439

Epoch: 5| Step: 2
Training loss: 1.0102845856113762
Validation loss: 2.9139913459933835

Epoch: 5| Step: 3
Training loss: 0.6821895891857441
Validation loss: 2.825086774168517

Epoch: 5| Step: 4
Training loss: 0.862913925250046
Validation loss: 2.904744886515784

Epoch: 5| Step: 5
Training loss: 0.7284029139650557
Validation loss: 2.8551903139696493

Epoch: 5| Step: 6
Training loss: 0.49459398905205465
Validation loss: 2.788643660382357

Epoch: 5| Step: 7
Training loss: 0.7163669221789052
Validation loss: 2.79117704956419

Epoch: 5| Step: 8
Training loss: 0.7123375824638069
Validation loss: 2.7928255164492004

Epoch: 5| Step: 9
Training loss: 0.7719223903671814
Validation loss: 2.826981856160727

Epoch: 5| Step: 10
Training loss: 1.7493715520227162
Validation loss: 2.901684730295716

Epoch: 5| Step: 11
Training loss: 0.5966363819346566
Validation loss: 2.819488426130622

Epoch: 223| Step: 0
Training loss: 0.6850361891744612
Validation loss: 2.8343743288879835

Epoch: 5| Step: 1
Training loss: 0.5722376845898203
Validation loss: 2.8050056815415685

Epoch: 5| Step: 2
Training loss: 0.6218086063463635
Validation loss: 2.8227910873708524

Epoch: 5| Step: 3
Training loss: 0.7501095850676023
Validation loss: 2.794970586828968

Epoch: 5| Step: 4
Training loss: 0.6883449563930132
Validation loss: 2.782336205102555

Epoch: 5| Step: 5
Training loss: 0.9473006723743631
Validation loss: 2.788652594726303

Epoch: 5| Step: 6
Training loss: 0.7658584394549445
Validation loss: 2.7736350781622403

Epoch: 5| Step: 7
Training loss: 1.4813635545172075
Validation loss: 2.8218460070253135

Epoch: 5| Step: 8
Training loss: 1.0657431528586006
Validation loss: 2.769131217729264

Epoch: 5| Step: 9
Training loss: 1.1737966929970385
Validation loss: 2.7724195806238843

Epoch: 5| Step: 10
Training loss: 0.7139559376207699
Validation loss: 2.8392463031140243

Epoch: 5| Step: 11
Training loss: 0.4578399187802172
Validation loss: 2.7482882214998767

Epoch: 224| Step: 0
Training loss: 1.59468701810566
Validation loss: 2.816777406345819

Epoch: 5| Step: 1
Training loss: 0.6041862687405856
Validation loss: 2.7558988644487474

Epoch: 5| Step: 2
Training loss: 0.8191320736301825
Validation loss: 2.7769887691078843

Epoch: 5| Step: 3
Training loss: 0.8707316377266013
Validation loss: 2.768297520556485

Epoch: 5| Step: 4
Training loss: 0.8896535293316141
Validation loss: 2.812606894263131

Epoch: 5| Step: 5
Training loss: 0.6324208307287066
Validation loss: 2.7973936086724063

Epoch: 5| Step: 6
Training loss: 0.9048467492653476
Validation loss: 2.841000828013198

Epoch: 5| Step: 7
Training loss: 0.9835626489692861
Validation loss: 2.8420970989752012

Epoch: 5| Step: 8
Training loss: 0.9005791390236236
Validation loss: 2.670080240236909

Epoch: 5| Step: 9
Training loss: 0.5525443623282881
Validation loss: 2.8113429373857604

Epoch: 5| Step: 10
Training loss: 0.6552652054339235
Validation loss: 2.692581772673812

Epoch: 5| Step: 11
Training loss: 0.44363586274254135
Validation loss: 2.8535376062053532

Epoch: 225| Step: 0
Training loss: 1.6088734558207125
Validation loss: 2.7580200599895717

Epoch: 5| Step: 1
Training loss: 0.8281497951610266
Validation loss: 2.814073860474537

Epoch: 5| Step: 2
Training loss: 0.5622562304092621
Validation loss: 2.7806658863660854

Epoch: 5| Step: 3
Training loss: 0.6776783285135171
Validation loss: 2.843299966352124

Epoch: 5| Step: 4
Training loss: 0.7571075542720528
Validation loss: 2.7561870391874614

Epoch: 5| Step: 5
Training loss: 0.7365687859857318
Validation loss: 2.8100266672149643

Epoch: 5| Step: 6
Training loss: 0.7129874385781214
Validation loss: 2.7450741737711404

Epoch: 5| Step: 7
Training loss: 0.7619038674797757
Validation loss: 2.8398678589243067

Epoch: 5| Step: 8
Training loss: 0.6766207557600078
Validation loss: 2.8604250614425566

Epoch: 5| Step: 9
Training loss: 0.7724984373305234
Validation loss: 2.805293433032631

Epoch: 5| Step: 10
Training loss: 0.5186085071400727
Validation loss: 2.7787240519980214

Epoch: 5| Step: 11
Training loss: 1.3221286719661538
Validation loss: 2.7702919328316615

Epoch: 226| Step: 0
Training loss: 0.6907095550973044
Validation loss: 2.8555092902204127

Epoch: 5| Step: 1
Training loss: 1.2041618536266685
Validation loss: 2.800197730292061

Epoch: 5| Step: 2
Training loss: 1.5735084313141598
Validation loss: 2.855602367386854

Epoch: 5| Step: 3
Training loss: 0.7964010512175009
Validation loss: 2.7301749934130877

Epoch: 5| Step: 4
Training loss: 0.922314232107202
Validation loss: 2.774596510297935

Epoch: 5| Step: 5
Training loss: 0.6846205710601609
Validation loss: 2.7536736680965292

Epoch: 5| Step: 6
Training loss: 0.6760094758898871
Validation loss: 2.737047850923302

Epoch: 5| Step: 7
Training loss: 0.5720067919848083
Validation loss: 2.8086399468949734

Epoch: 5| Step: 8
Training loss: 0.7154783756685781
Validation loss: 2.853773077165374

Epoch: 5| Step: 9
Training loss: 0.5291086685756776
Validation loss: 2.8081040943708193

Epoch: 5| Step: 10
Training loss: 0.4912966279961365
Validation loss: 2.7873586370777432

Epoch: 5| Step: 11
Training loss: 0.6305499897817173
Validation loss: 2.7594317184500228

Epoch: 227| Step: 0
Training loss: 1.682760080921953
Validation loss: 2.7509051047223307

Epoch: 5| Step: 1
Training loss: 0.5753453420105548
Validation loss: 2.8153056173501216

Epoch: 5| Step: 2
Training loss: 0.7695650199799927
Validation loss: 2.7958387945228904

Epoch: 5| Step: 3
Training loss: 0.7705221235254067
Validation loss: 2.8327829209677287

Epoch: 5| Step: 4
Training loss: 0.80120298863652
Validation loss: 2.8362341761522405

Epoch: 5| Step: 5
Training loss: 0.8538495770046748
Validation loss: 2.8810971747061025

Epoch: 5| Step: 6
Training loss: 0.7935759000503844
Validation loss: 2.8154386568097496

Epoch: 5| Step: 7
Training loss: 0.5867159948779561
Validation loss: 2.70809537991547

Epoch: 5| Step: 8
Training loss: 0.7152083670837175
Validation loss: 2.7265189658317466

Epoch: 5| Step: 9
Training loss: 0.639424082306821
Validation loss: 2.7662013292117695

Epoch: 5| Step: 10
Training loss: 0.7291307077169717
Validation loss: 2.7733107990104386

Epoch: 5| Step: 11
Training loss: 0.7707984289222587
Validation loss: 2.7532854214599096

Epoch: 228| Step: 0
Training loss: 0.8778810073883816
Validation loss: 2.818582210072005

Epoch: 5| Step: 1
Training loss: 0.7740869588918629
Validation loss: 2.8175724100174566

Epoch: 5| Step: 2
Training loss: 0.9574912075306353
Validation loss: 2.6940451586428154

Epoch: 5| Step: 3
Training loss: 0.5785675932153268
Validation loss: 2.7329868062584066

Epoch: 5| Step: 4
Training loss: 0.7109260977365166
Validation loss: 2.7685964071011067

Epoch: 5| Step: 5
Training loss: 0.9350038358028289
Validation loss: 2.7099609191711242

Epoch: 5| Step: 6
Training loss: 0.6817683889890662
Validation loss: 2.785867668841351

Epoch: 5| Step: 7
Training loss: 0.6996159837028318
Validation loss: 2.7584992689217347

Epoch: 5| Step: 8
Training loss: 0.7524072638110834
Validation loss: 2.709005292038403

Epoch: 5| Step: 9
Training loss: 1.5743127988829941
Validation loss: 2.7762080614465345

Epoch: 5| Step: 10
Training loss: 0.7518875687992236
Validation loss: 2.761075147627607

Epoch: 5| Step: 11
Training loss: 0.24494211244097305
Validation loss: 2.7308763591805874

Epoch: 229| Step: 0
Training loss: 0.5424273419396574
Validation loss: 2.794958054410341

Epoch: 5| Step: 1
Training loss: 0.9266281439186114
Validation loss: 2.8267120955767058

Epoch: 5| Step: 2
Training loss: 1.5365172121652362
Validation loss: 2.7736509500668065

Epoch: 5| Step: 3
Training loss: 0.8700627268178527
Validation loss: 2.7485891320937554

Epoch: 5| Step: 4
Training loss: 0.7377327794101487
Validation loss: 2.7494258064419723

Epoch: 5| Step: 5
Training loss: 0.8928060428437955
Validation loss: 2.8380521731373967

Epoch: 5| Step: 6
Training loss: 0.7842894746879839
Validation loss: 2.7997143609660653

Epoch: 5| Step: 7
Training loss: 0.6705258374523515
Validation loss: 2.7075529141742947

Epoch: 5| Step: 8
Training loss: 0.6275000637555945
Validation loss: 2.791780118392474

Epoch: 5| Step: 9
Training loss: 0.6339182200440582
Validation loss: 2.743340976904522

Epoch: 5| Step: 10
Training loss: 0.6367523090903294
Validation loss: 2.8047710678982685

Epoch: 5| Step: 11
Training loss: 0.5982326146878362
Validation loss: 2.7866624894027185

Epoch: 230| Step: 0
Training loss: 0.6115907342676681
Validation loss: 2.7316567379253374

Epoch: 5| Step: 1
Training loss: 0.45084813710949256
Validation loss: 2.848242236747777

Epoch: 5| Step: 2
Training loss: 0.8697689913841566
Validation loss: 2.7854574432089354

Epoch: 5| Step: 3
Training loss: 0.5903966724731652
Validation loss: 2.744730785256868

Epoch: 5| Step: 4
Training loss: 0.6202322545263386
Validation loss: 2.748653139839625

Epoch: 5| Step: 5
Training loss: 0.5914896554727568
Validation loss: 2.86110945941256

Epoch: 5| Step: 6
Training loss: 0.6579810880157817
Validation loss: 2.689093693890866

Epoch: 5| Step: 7
Training loss: 1.1000053817443978
Validation loss: 2.7784135263155476

Epoch: 5| Step: 8
Training loss: 0.697807721037501
Validation loss: 2.8079493370953768

Epoch: 5| Step: 9
Training loss: 0.7138936968054785
Validation loss: 2.7927022953577634

Epoch: 5| Step: 10
Training loss: 1.5140880381789452
Validation loss: 2.7676558500479254

Epoch: 5| Step: 11
Training loss: 0.5409515563266889
Validation loss: 2.7890147392963556

Epoch: 231| Step: 0
Training loss: 1.4894680787783219
Validation loss: 2.844725155177992

Epoch: 5| Step: 1
Training loss: 0.9948890132441967
Validation loss: 2.8124312569023138

Epoch: 5| Step: 2
Training loss: 1.0349762382175385
Validation loss: 2.792377158513655

Epoch: 5| Step: 3
Training loss: 0.5544853110590781
Validation loss: 2.823262300247056

Epoch: 5| Step: 4
Training loss: 0.6367689241638302
Validation loss: 2.6784752716485785

Epoch: 5| Step: 5
Training loss: 0.7787257805206905
Validation loss: 2.809134578495163

Epoch: 5| Step: 6
Training loss: 0.3682594681627791
Validation loss: 2.8244110119363977

Epoch: 5| Step: 7
Training loss: 1.067093177302151
Validation loss: 2.686196550796366

Epoch: 5| Step: 8
Training loss: 0.6010931834770291
Validation loss: 2.6979690139189203

Epoch: 5| Step: 9
Training loss: 0.6414197783257353
Validation loss: 2.7872634912806955

Epoch: 5| Step: 10
Training loss: 0.6505963111950526
Validation loss: 2.835648149734001

Epoch: 5| Step: 11
Training loss: 0.8051269960631887
Validation loss: 2.7852010629694908

Epoch: 232| Step: 0
Training loss: 0.8290987587601666
Validation loss: 2.810160416151134

Epoch: 5| Step: 1
Training loss: 0.8910750874734452
Validation loss: 2.8795968740894935

Epoch: 5| Step: 2
Training loss: 0.740078267971602
Validation loss: 2.8627891933054728

Epoch: 5| Step: 3
Training loss: 0.5814204243031934
Validation loss: 2.786069056096436

Epoch: 5| Step: 4
Training loss: 0.8351260730226633
Validation loss: 2.7546552212259807

Epoch: 5| Step: 5
Training loss: 1.5184867034118938
Validation loss: 2.805481368889611

Epoch: 5| Step: 6
Training loss: 0.666711125282189
Validation loss: 2.7120433094773158

Epoch: 5| Step: 7
Training loss: 0.8240755869839227
Validation loss: 2.676473716366392

Epoch: 5| Step: 8
Training loss: 0.6560316176587222
Validation loss: 2.7618754556918366

Epoch: 5| Step: 9
Training loss: 0.669986755076487
Validation loss: 2.752724331218133

Epoch: 5| Step: 10
Training loss: 1.1035084952065026
Validation loss: 2.8039921046353102

Epoch: 5| Step: 11
Training loss: 0.7373778856333847
Validation loss: 2.7798491782789623

Epoch: 233| Step: 0
Training loss: 0.6413500799565494
Validation loss: 2.7200019774593382

Epoch: 5| Step: 1
Training loss: 0.5823867787277197
Validation loss: 2.793325647701655

Epoch: 5| Step: 2
Training loss: 0.7264722132216066
Validation loss: 2.758002875279769

Epoch: 5| Step: 3
Training loss: 1.040901907888103
Validation loss: 2.8347986209668488

Epoch: 5| Step: 4
Training loss: 0.9174561063365038
Validation loss: 2.771368901161541

Epoch: 5| Step: 5
Training loss: 0.5951771149166428
Validation loss: 2.802217644565168

Epoch: 5| Step: 6
Training loss: 0.5609800412933668
Validation loss: 2.7735376581723568

Epoch: 5| Step: 7
Training loss: 0.7810082633818307
Validation loss: 2.785446644072233

Epoch: 5| Step: 8
Training loss: 0.6868199105772029
Validation loss: 2.721063966503222

Epoch: 5| Step: 9
Training loss: 1.4677915489515894
Validation loss: 2.762509568659578

Epoch: 5| Step: 10
Training loss: 0.8522729971914152
Validation loss: 2.8719360603812123

Epoch: 5| Step: 11
Training loss: 0.8996706916428834
Validation loss: 2.7982964908097405

Epoch: 234| Step: 0
Training loss: 1.0021137904391608
Validation loss: 2.8085631526718164

Epoch: 5| Step: 1
Training loss: 0.621345684849505
Validation loss: 2.801562928630387

Epoch: 5| Step: 2
Training loss: 0.7003984994440328
Validation loss: 2.8449762062179498

Epoch: 5| Step: 3
Training loss: 0.6796451643112893
Validation loss: 2.7563929664169633

Epoch: 5| Step: 4
Training loss: 0.5657179761311406
Validation loss: 2.9148071844335757

Epoch: 5| Step: 5
Training loss: 0.6560758177888333
Validation loss: 2.729995075228375

Epoch: 5| Step: 6
Training loss: 0.968907681829966
Validation loss: 2.813131883069392

Epoch: 5| Step: 7
Training loss: 0.8897918351111539
Validation loss: 2.837085123863184

Epoch: 5| Step: 8
Training loss: 0.5769914649203198
Validation loss: 2.8707647295110568

Epoch: 5| Step: 9
Training loss: 0.6709353951792933
Validation loss: 2.8425374782197372

Epoch: 5| Step: 10
Training loss: 1.6200572917367835
Validation loss: 2.9066416978930203

Epoch: 5| Step: 11
Training loss: 1.093314928989267
Validation loss: 2.834762038891438

Epoch: 235| Step: 0
Training loss: 0.8292645944501927
Validation loss: 2.805144302018896

Epoch: 5| Step: 1
Training loss: 0.6552599750619695
Validation loss: 2.8426277685065675

Epoch: 5| Step: 2
Training loss: 0.5621669366032737
Validation loss: 2.867854838445851

Epoch: 5| Step: 3
Training loss: 0.5118570213747016
Validation loss: 2.7313526671119264

Epoch: 5| Step: 4
Training loss: 0.583965084305916
Validation loss: 2.7461799293333318

Epoch: 5| Step: 5
Training loss: 0.6270073602813242
Validation loss: 2.7728045820420304

Epoch: 5| Step: 6
Training loss: 1.5462104834253858
Validation loss: 2.7240741600565155

Epoch: 5| Step: 7
Training loss: 0.847102041180218
Validation loss: 2.785126987783289

Epoch: 5| Step: 8
Training loss: 0.7971743227214654
Validation loss: 2.6862588093682556

Epoch: 5| Step: 9
Training loss: 0.9571133013993409
Validation loss: 2.7310584708942853

Epoch: 5| Step: 10
Training loss: 0.5321228486246784
Validation loss: 2.8872803385689156

Epoch: 5| Step: 11
Training loss: 0.885237309110393
Validation loss: 2.809004090901772

Epoch: 236| Step: 0
Training loss: 0.6336355625942108
Validation loss: 2.847842635555468

Epoch: 5| Step: 1
Training loss: 1.5157193813235752
Validation loss: 2.776607678785905

Epoch: 5| Step: 2
Training loss: 0.541426574853968
Validation loss: 2.8793026958705696

Epoch: 5| Step: 3
Training loss: 1.071063703898815
Validation loss: 2.7125990774808284

Epoch: 5| Step: 4
Training loss: 0.914250965740642
Validation loss: 2.8258589874759754

Epoch: 5| Step: 5
Training loss: 0.7276923306206603
Validation loss: 2.8134843763732627

Epoch: 5| Step: 6
Training loss: 0.799737128640402
Validation loss: 2.8785734152457416

Epoch: 5| Step: 7
Training loss: 0.7159022015079091
Validation loss: 2.785725792589165

Epoch: 5| Step: 8
Training loss: 0.5522733727150602
Validation loss: 2.726366216376666

Epoch: 5| Step: 9
Training loss: 0.581639919959487
Validation loss: 2.8094542435957583

Epoch: 5| Step: 10
Training loss: 0.7409723875535588
Validation loss: 2.7758981561454625

Epoch: 5| Step: 11
Training loss: 0.5939030700935675
Validation loss: 2.7877550346302367

Epoch: 237| Step: 0
Training loss: 0.6247021919266992
Validation loss: 2.8141353832848517

Epoch: 5| Step: 1
Training loss: 0.7424503061895454
Validation loss: 2.772903261981055

Epoch: 5| Step: 2
Training loss: 0.8938958189125145
Validation loss: 2.8191996216508706

Epoch: 5| Step: 3
Training loss: 0.8160447045637246
Validation loss: 2.8492547682408484

Epoch: 5| Step: 4
Training loss: 0.9105142045020695
Validation loss: 2.821743544850137

Epoch: 5| Step: 5
Training loss: 0.7185827972977544
Validation loss: 2.7876912476203444

Epoch: 5| Step: 6
Training loss: 1.4959958196316414
Validation loss: 2.7382259553776387

Epoch: 5| Step: 7
Training loss: 0.6579865232235421
Validation loss: 2.8370128165744286

Epoch: 5| Step: 8
Training loss: 0.7030141107220165
Validation loss: 2.7658921955009887

Epoch: 5| Step: 9
Training loss: 0.6513173600430897
Validation loss: 2.6876457160066276

Epoch: 5| Step: 10
Training loss: 0.6636849395920978
Validation loss: 2.7034576189321924

Epoch: 5| Step: 11
Training loss: 0.39151066512346555
Validation loss: 2.8643364551394295

Epoch: 238| Step: 0
Training loss: 0.8602175310498824
Validation loss: 2.787333575014756

Epoch: 5| Step: 1
Training loss: 0.6692189791489948
Validation loss: 2.746061662221494

Epoch: 5| Step: 2
Training loss: 0.6227509324898739
Validation loss: 2.8369542305620055

Epoch: 5| Step: 3
Training loss: 0.540415241364085
Validation loss: 2.7340088408403256

Epoch: 5| Step: 4
Training loss: 1.7462186149993475
Validation loss: 2.8595433559084698

Epoch: 5| Step: 5
Training loss: 0.6622299939680236
Validation loss: 2.800112209455868

Epoch: 5| Step: 6
Training loss: 0.5557190343284083
Validation loss: 2.810877137510552

Epoch: 5| Step: 7
Training loss: 0.773235487324746
Validation loss: 2.786335282267752

Epoch: 5| Step: 8
Training loss: 0.584033925687727
Validation loss: 2.939508306211357

Epoch: 5| Step: 9
Training loss: 0.6599699355632777
Validation loss: 2.7701023877727153

Epoch: 5| Step: 10
Training loss: 0.6681429541007002
Validation loss: 2.7439073963538325

Epoch: 5| Step: 11
Training loss: 0.733292370071159
Validation loss: 2.777709010518073

Epoch: 239| Step: 0
Training loss: 0.4891529998895531
Validation loss: 2.8462380923341937

Epoch: 5| Step: 1
Training loss: 0.6022378920022459
Validation loss: 2.8531199830907004

Epoch: 5| Step: 2
Training loss: 1.6754838728531283
Validation loss: 2.8513995955804496

Epoch: 5| Step: 3
Training loss: 0.7856838294727845
Validation loss: 2.868439556048638

Epoch: 5| Step: 4
Training loss: 0.8862075676599431
Validation loss: 2.7488160655357183

Epoch: 5| Step: 5
Training loss: 0.6402653871092641
Validation loss: 2.7900457065010476

Epoch: 5| Step: 6
Training loss: 0.48267340955922217
Validation loss: 2.7337163949443752

Epoch: 5| Step: 7
Training loss: 0.4612361457728944
Validation loss: 2.8076420826568373

Epoch: 5| Step: 8
Training loss: 0.6789193251989188
Validation loss: 2.8074222149806047

Epoch: 5| Step: 9
Training loss: 0.9731946933219089
Validation loss: 2.9133932011492223

Epoch: 5| Step: 10
Training loss: 0.6248819478124317
Validation loss: 2.836293463527358

Epoch: 5| Step: 11
Training loss: 0.4313396077423198
Validation loss: 2.8800814441417057

Epoch: 240| Step: 0
Training loss: 0.8149862031412418
Validation loss: 2.8994581648103273

Epoch: 5| Step: 1
Training loss: 0.7417563541347192
Validation loss: 2.7847219791132143

Epoch: 5| Step: 2
Training loss: 1.4103915792212747
Validation loss: 2.8396729142875228

Epoch: 5| Step: 3
Training loss: 0.9026502608856144
Validation loss: 2.7247502626661086

Epoch: 5| Step: 4
Training loss: 0.6730452924412007
Validation loss: 2.8376808272732528

Epoch: 5| Step: 5
Training loss: 0.670518192663164
Validation loss: 2.799961741645881

Epoch: 5| Step: 6
Training loss: 0.5896958930020199
Validation loss: 2.828039371746753

Epoch: 5| Step: 7
Training loss: 0.8117982327976055
Validation loss: 2.726581427682435

Epoch: 5| Step: 8
Training loss: 0.7742728144210077
Validation loss: 2.7540462593578865

Epoch: 5| Step: 9
Training loss: 0.713463874158965
Validation loss: 2.8125938399872332

Epoch: 5| Step: 10
Training loss: 0.5562158670561272
Validation loss: 2.8258341508588747

Epoch: 5| Step: 11
Training loss: 0.5802051905941272
Validation loss: 2.8907774086028684

Epoch: 241| Step: 0
Training loss: 0.5193065931989931
Validation loss: 2.8439912623811336

Epoch: 5| Step: 1
Training loss: 0.8057897111419988
Validation loss: 2.759352004868747

Epoch: 5| Step: 2
Training loss: 0.45508843930061305
Validation loss: 2.796895895512274

Epoch: 5| Step: 3
Training loss: 0.7729296317302691
Validation loss: 2.7451833859258903

Epoch: 5| Step: 4
Training loss: 0.7276215986504257
Validation loss: 2.8438392143088844

Epoch: 5| Step: 5
Training loss: 0.5160479689228518
Validation loss: 2.783981967391701

Epoch: 5| Step: 6
Training loss: 1.4539498889898521
Validation loss: 2.777337926902336

Epoch: 5| Step: 7
Training loss: 0.677165933607986
Validation loss: 2.842871554730223

Epoch: 5| Step: 8
Training loss: 1.0249496238238482
Validation loss: 2.755477691396496

Epoch: 5| Step: 9
Training loss: 0.5977985985471163
Validation loss: 2.8540285116483273

Epoch: 5| Step: 10
Training loss: 0.7935565968179983
Validation loss: 2.899147484836424

Epoch: 5| Step: 11
Training loss: 0.9512125746774897
Validation loss: 2.8254888799357745

Epoch: 242| Step: 0
Training loss: 0.579810109500248
Validation loss: 2.790872818016459

Epoch: 5| Step: 1
Training loss: 0.6237318046989128
Validation loss: 2.755686854805078

Epoch: 5| Step: 2
Training loss: 0.7420342538129807
Validation loss: 2.773335138858687

Epoch: 5| Step: 3
Training loss: 1.0035013651475047
Validation loss: 2.7477822934416656

Epoch: 5| Step: 4
Training loss: 0.749561579036791
Validation loss: 2.8589319153342343

Epoch: 5| Step: 5
Training loss: 0.5778288211446451
Validation loss: 2.807522165653122

Epoch: 5| Step: 6
Training loss: 0.582212535096688
Validation loss: 2.7295302932617913

Epoch: 5| Step: 7
Training loss: 0.6667986654694469
Validation loss: 2.7889151262657172

Epoch: 5| Step: 8
Training loss: 1.5957895580028045
Validation loss: 2.727716393037972

Epoch: 5| Step: 9
Training loss: 0.6692502851090164
Validation loss: 2.7596518134685675

Epoch: 5| Step: 10
Training loss: 0.6577232264017825
Validation loss: 2.7924022678062945

Epoch: 5| Step: 11
Training loss: 0.9231596255927214
Validation loss: 2.694767433375066

Epoch: 243| Step: 0
Training loss: 0.533389579394891
Validation loss: 2.7577593530823616

Epoch: 5| Step: 1
Training loss: 0.7382311930161451
Validation loss: 2.8204068760742578

Epoch: 5| Step: 2
Training loss: 1.405577562412845
Validation loss: 2.7419794914856874

Epoch: 5| Step: 3
Training loss: 0.6750133539574301
Validation loss: 2.8420501071799915

Epoch: 5| Step: 4
Training loss: 0.4855982654287209
Validation loss: 2.787384475857269

Epoch: 5| Step: 5
Training loss: 0.6542409844511625
Validation loss: 2.7901329743065553

Epoch: 5| Step: 6
Training loss: 0.8177733587825747
Validation loss: 2.845610383843344

Epoch: 5| Step: 7
Training loss: 0.7142252930562828
Validation loss: 2.7951898524111813

Epoch: 5| Step: 8
Training loss: 0.7084536076326986
Validation loss: 2.8398271688740704

Epoch: 5| Step: 9
Training loss: 0.8002493603819103
Validation loss: 2.8356655855716744

Epoch: 5| Step: 10
Training loss: 0.6199129504190565
Validation loss: 2.817344692596001

Epoch: 5| Step: 11
Training loss: 1.47679935553796
Validation loss: 2.7620543330437695

Epoch: 244| Step: 0
Training loss: 0.4934215817532296
Validation loss: 2.8135292218660553

Epoch: 5| Step: 1
Training loss: 0.6627968563911765
Validation loss: 2.837786958555222

Epoch: 5| Step: 2
Training loss: 0.7006220029550744
Validation loss: 2.941720561559535

Epoch: 5| Step: 3
Training loss: 0.7714472894567432
Validation loss: 2.856564855437919

Epoch: 5| Step: 4
Training loss: 0.7328681501718753
Validation loss: 2.6948106049672265

Epoch: 5| Step: 5
Training loss: 0.6237782457794471
Validation loss: 2.7673226550206445

Epoch: 5| Step: 6
Training loss: 0.6460467929220506
Validation loss: 2.7949076540425444

Epoch: 5| Step: 7
Training loss: 0.7046178229282654
Validation loss: 2.848669195525864

Epoch: 5| Step: 8
Training loss: 0.4252314386191074
Validation loss: 2.739120090080116

Epoch: 5| Step: 9
Training loss: 1.5023630919577677
Validation loss: 2.7829643280917695

Epoch: 5| Step: 10
Training loss: 0.7544149550355269
Validation loss: 2.7939325372572075

Epoch: 5| Step: 11
Training loss: 0.39457830771629804
Validation loss: 2.7724950021745163

Epoch: 245| Step: 0
Training loss: 0.6064220675867954
Validation loss: 2.7357143028568274

Epoch: 5| Step: 1
Training loss: 0.6931218989778432
Validation loss: 2.8686687755790468

Epoch: 5| Step: 2
Training loss: 0.6010851266399573
Validation loss: 2.8647610013946796

Epoch: 5| Step: 3
Training loss: 0.6579365176185108
Validation loss: 2.9520475988888197

Epoch: 5| Step: 4
Training loss: 0.6155056794227591
Validation loss: 2.877235990880584

Epoch: 5| Step: 5
Training loss: 0.7345575957857146
Validation loss: 2.860968751873813

Epoch: 5| Step: 6
Training loss: 1.5699523968374236
Validation loss: 2.830916691838473

Epoch: 5| Step: 7
Training loss: 0.6372135322794568
Validation loss: 2.8050717628079975

Epoch: 5| Step: 8
Training loss: 0.9584607405902963
Validation loss: 2.821934424725487

Epoch: 5| Step: 9
Training loss: 0.6342762630650195
Validation loss: 2.8012615449988925

Epoch: 5| Step: 10
Training loss: 0.7655891098641079
Validation loss: 2.7559528618845195

Epoch: 5| Step: 11
Training loss: 0.6581293398649722
Validation loss: 2.7612563253732914

Epoch: 246| Step: 0
Training loss: 0.7758573189403658
Validation loss: 2.825649562077265

Epoch: 5| Step: 1
Training loss: 1.484098067300223
Validation loss: 2.860070493152813

Epoch: 5| Step: 2
Training loss: 0.6106085640560664
Validation loss: 2.760317359193636

Epoch: 5| Step: 3
Training loss: 0.832798205855981
Validation loss: 2.7559358985850952

Epoch: 5| Step: 4
Training loss: 0.5233028295560385
Validation loss: 2.7771729757937105

Epoch: 5| Step: 5
Training loss: 0.6340159052860347
Validation loss: 2.799961454262402

Epoch: 5| Step: 6
Training loss: 0.46067427538556366
Validation loss: 2.837708525340596

Epoch: 5| Step: 7
Training loss: 0.5763724802227284
Validation loss: 2.802801076912758

Epoch: 5| Step: 8
Training loss: 0.6699272800594523
Validation loss: 2.8017597200695876

Epoch: 5| Step: 9
Training loss: 0.6584991106521174
Validation loss: 2.887083671468138

Epoch: 5| Step: 10
Training loss: 0.4959228701918488
Validation loss: 2.8010003515402424

Epoch: 5| Step: 11
Training loss: 0.6031697093619495
Validation loss: 2.7335325396497607

Epoch: 247| Step: 0
Training loss: 0.8405620253561091
Validation loss: 2.7763115439763526

Epoch: 5| Step: 1
Training loss: 0.8131259194558741
Validation loss: 2.814834173607786

Epoch: 5| Step: 2
Training loss: 0.6309361130659967
Validation loss: 2.8553864397187376

Epoch: 5| Step: 3
Training loss: 0.7651827566468296
Validation loss: 2.7985808925927174

Epoch: 5| Step: 4
Training loss: 0.7973681401269976
Validation loss: 2.8038453916143644

Epoch: 5| Step: 5
Training loss: 0.724972245901892
Validation loss: 2.855457377204565

Epoch: 5| Step: 6
Training loss: 0.7112715219415929
Validation loss: 2.750360244939324

Epoch: 5| Step: 7
Training loss: 0.49595219552490305
Validation loss: 2.844513553074358

Epoch: 5| Step: 8
Training loss: 0.7960309064654191
Validation loss: 2.769057645418577

Epoch: 5| Step: 9
Training loss: 0.7464125186943609
Validation loss: 2.740705540690422

Epoch: 5| Step: 10
Training loss: 1.5288478148164848
Validation loss: 2.8517328812373055

Epoch: 5| Step: 11
Training loss: 0.9633797105649519
Validation loss: 2.806884871800794

Epoch: 248| Step: 0
Training loss: 0.7704451889678096
Validation loss: 2.851905749838851

Epoch: 5| Step: 1
Training loss: 0.811999460243647
Validation loss: 2.892474873048166

Epoch: 5| Step: 2
Training loss: 0.7297928074522809
Validation loss: 2.810174418519611

Epoch: 5| Step: 3
Training loss: 0.5721452345517196
Validation loss: 2.81984122751454

Epoch: 5| Step: 4
Training loss: 0.970550340874889
Validation loss: 2.857595053009925

Epoch: 5| Step: 5
Training loss: 1.463801549823064
Validation loss: 2.781796033885927

Epoch: 5| Step: 6
Training loss: 0.7770976534862875
Validation loss: 2.8564064827477873

Epoch: 5| Step: 7
Training loss: 0.4813098987855306
Validation loss: 2.655923232380488

Epoch: 5| Step: 8
Training loss: 0.5733219591618596
Validation loss: 2.791743371156447

Epoch: 5| Step: 9
Training loss: 0.8368265647062364
Validation loss: 2.7498284127427817

Epoch: 5| Step: 10
Training loss: 0.6318881736989486
Validation loss: 2.805447527696194

Epoch: 5| Step: 11
Training loss: 0.2218735557159912
Validation loss: 2.825535544197473

Epoch: 249| Step: 0
Training loss: 0.49933014643188606
Validation loss: 2.7596171870788506

Epoch: 5| Step: 1
Training loss: 0.6881309128593007
Validation loss: 2.7316514174862174

Epoch: 5| Step: 2
Training loss: 0.406862842038301
Validation loss: 2.834002602761993

Epoch: 5| Step: 3
Training loss: 0.5122301589210037
Validation loss: 2.7766869828529255

Epoch: 5| Step: 4
Training loss: 0.6550114160372781
Validation loss: 2.7400204245764392

Epoch: 5| Step: 5
Training loss: 0.7619178707337617
Validation loss: 2.7825637743354266

Epoch: 5| Step: 6
Training loss: 0.6602188396691233
Validation loss: 2.802305954854744

Epoch: 5| Step: 7
Training loss: 0.7226487030460019
Validation loss: 2.858878431300034

Epoch: 5| Step: 8
Training loss: 0.8385403477123304
Validation loss: 2.7249905154445204

Epoch: 5| Step: 9
Training loss: 1.4440925191843608
Validation loss: 2.699642510648436

Epoch: 5| Step: 10
Training loss: 0.7766720730944018
Validation loss: 2.7087591545655605

Epoch: 5| Step: 11
Training loss: 0.3563093370244707
Validation loss: 2.84830284714125

Epoch: 250| Step: 0
Training loss: 0.53205238782033
Validation loss: 2.843486843578869

Epoch: 5| Step: 1
Training loss: 0.9386793665719924
Validation loss: 2.7515502772004705

Epoch: 5| Step: 2
Training loss: 0.3876522818642496
Validation loss: 2.83068332208021

Epoch: 5| Step: 3
Training loss: 0.7265144660412606
Validation loss: 2.804033520179392

Epoch: 5| Step: 4
Training loss: 0.9706519437686842
Validation loss: 2.7977354938782195

Epoch: 5| Step: 5
Training loss: 1.4478545232742812
Validation loss: 2.733136439694577

Epoch: 5| Step: 6
Training loss: 0.5965056969529671
Validation loss: 2.827204914659916

Epoch: 5| Step: 7
Training loss: 0.8019407484137276
Validation loss: 2.792888325420279

Epoch: 5| Step: 8
Training loss: 0.5461214868926291
Validation loss: 2.7730953739817084

Epoch: 5| Step: 9
Training loss: 0.5601150497543645
Validation loss: 2.79825864696368

Epoch: 5| Step: 10
Training loss: 0.5464479413815665
Validation loss: 2.867720312769476

Epoch: 5| Step: 11
Training loss: 0.5912755300159392
Validation loss: 2.7664905206685773

Epoch: 251| Step: 0
Training loss: 0.7904428551182489
Validation loss: 2.7202711198242415

Epoch: 5| Step: 1
Training loss: 0.7061204681777785
Validation loss: 2.8308341396676138

Epoch: 5| Step: 2
Training loss: 0.6677077380181177
Validation loss: 2.7589487863400577

Epoch: 5| Step: 3
Training loss: 0.6320592376585563
Validation loss: 2.8055836406777126

Epoch: 5| Step: 4
Training loss: 0.6693455744668213
Validation loss: 2.780178134983365

Epoch: 5| Step: 5
Training loss: 0.8609307165969047
Validation loss: 2.714921030824521

Epoch: 5| Step: 6
Training loss: 0.7078186203310948
Validation loss: 2.7326332612217357

Epoch: 5| Step: 7
Training loss: 1.4409672758740117
Validation loss: 2.8628214128167655

Epoch: 5| Step: 8
Training loss: 0.599902202662694
Validation loss: 2.834500606463678

Epoch: 5| Step: 9
Training loss: 0.4685465848157734
Validation loss: 2.7373274676213946

Epoch: 5| Step: 10
Training loss: 0.6684755332509524
Validation loss: 2.8190789805378342

Epoch: 5| Step: 11
Training loss: 0.8843944183482307
Validation loss: 2.8470239935981474

Epoch: 252| Step: 0
Training loss: 0.4551868227045273
Validation loss: 2.84427475890861

Epoch: 5| Step: 1
Training loss: 0.5477167735483919
Validation loss: 2.814166521899448

Epoch: 5| Step: 2
Training loss: 0.8526862193344532
Validation loss: 2.7447875974119498

Epoch: 5| Step: 3
Training loss: 0.5865301314107564
Validation loss: 2.888712743642432

Epoch: 5| Step: 4
Training loss: 0.6115314766992935
Validation loss: 2.7401121134456354

Epoch: 5| Step: 5
Training loss: 0.7083236936773464
Validation loss: 2.7320352880273346

Epoch: 5| Step: 6
Training loss: 0.6967187655017524
Validation loss: 2.838019059861422

Epoch: 5| Step: 7
Training loss: 0.6903854852363986
Validation loss: 2.9418582813778498

Epoch: 5| Step: 8
Training loss: 0.5990213250470298
Validation loss: 2.756017459162613

Epoch: 5| Step: 9
Training loss: 1.5581720302689546
Validation loss: 2.8846050330530586

Epoch: 5| Step: 10
Training loss: 0.7177349884738129
Validation loss: 2.7762580427018664

Epoch: 5| Step: 11
Training loss: 0.050797425499869236
Validation loss: 2.856538077475624

Epoch: 253| Step: 0
Training loss: 0.49445816813787336
Validation loss: 2.705175199270252

Epoch: 5| Step: 1
Training loss: 0.5895449152944207
Validation loss: 2.889232100574756

Epoch: 5| Step: 2
Training loss: 0.7951116311973865
Validation loss: 2.83822333741162

Epoch: 5| Step: 3
Training loss: 0.7938545053125359
Validation loss: 2.856603557843993

Epoch: 5| Step: 4
Training loss: 0.7376360218237624
Validation loss: 2.806874116172473

Epoch: 5| Step: 5
Training loss: 0.5602990110851237
Validation loss: 2.860705911904626

Epoch: 5| Step: 6
Training loss: 1.0742161421310674
Validation loss: 2.787208400322472

Epoch: 5| Step: 7
Training loss: 0.8578792386245568
Validation loss: 2.7552169927065555

Epoch: 5| Step: 8
Training loss: 0.6303575722613043
Validation loss: 2.8000508291024655

Epoch: 5| Step: 9
Training loss: 0.5186580116796894
Validation loss: 2.800107526417534

Epoch: 5| Step: 10
Training loss: 0.5682824203986806
Validation loss: 2.8434620456437574

Epoch: 5| Step: 11
Training loss: 3.031739657465161
Validation loss: 2.8123737342183155

Epoch: 254| Step: 0
Training loss: 0.7106512143039816
Validation loss: 2.7100978397465076

Epoch: 5| Step: 1
Training loss: 0.7260952749579029
Validation loss: 2.8175288558651195

Epoch: 5| Step: 2
Training loss: 0.617586441514867
Validation loss: 2.7660871001146794

Epoch: 5| Step: 3
Training loss: 0.5947462056741668
Validation loss: 2.8778791488975224

Epoch: 5| Step: 4
Training loss: 0.8296263778212973
Validation loss: 2.7313736965413815

Epoch: 5| Step: 5
Training loss: 0.9486344034088536
Validation loss: 2.7522911620424155

Epoch: 5| Step: 6
Training loss: 0.5990974651673365
Validation loss: 2.7393959957997662

Epoch: 5| Step: 7
Training loss: 0.5419037617900768
Validation loss: 2.7729637386091666

Epoch: 5| Step: 8
Training loss: 1.4523568532926163
Validation loss: 2.8608447503098127

Epoch: 5| Step: 9
Training loss: 0.8171642015684374
Validation loss: 2.769867116687835

Epoch: 5| Step: 10
Training loss: 0.6077993023770777
Validation loss: 2.9069871548680624

Epoch: 5| Step: 11
Training loss: 0.57143526733256
Validation loss: 2.8571043361752104

Epoch: 255| Step: 0
Training loss: 0.6110539659479889
Validation loss: 2.81019057011727

Epoch: 5| Step: 1
Training loss: 0.7076302620092885
Validation loss: 2.8522474746525743

Epoch: 5| Step: 2
Training loss: 1.3943688220575894
Validation loss: 2.7816658780634156

Epoch: 5| Step: 3
Training loss: 0.6968423108700558
Validation loss: 2.802337926811249

Epoch: 5| Step: 4
Training loss: 0.6933130598046204
Validation loss: 2.818831339280698

Epoch: 5| Step: 5
Training loss: 0.48684297448971936
Validation loss: 2.8795350904972294

Epoch: 5| Step: 6
Training loss: 0.403369558805372
Validation loss: 2.7274903410190703

Epoch: 5| Step: 7
Training loss: 0.565512432046056
Validation loss: 2.823079570184878

Epoch: 5| Step: 8
Training loss: 0.5808207321396375
Validation loss: 2.8016397214857416

Epoch: 5| Step: 9
Training loss: 0.8174869739882914
Validation loss: 2.7334743360653557

Epoch: 5| Step: 10
Training loss: 0.42862775338824616
Validation loss: 2.825931088010969

Epoch: 5| Step: 11
Training loss: 0.17406523531163387
Validation loss: 2.8125977605147696

Epoch: 256| Step: 0
Training loss: 0.6822072600553485
Validation loss: 2.7373853878664516

Epoch: 5| Step: 1
Training loss: 0.5589440321209493
Validation loss: 2.6948889984751556

Epoch: 5| Step: 2
Training loss: 0.6435822175639578
Validation loss: 2.8422957219566025

Epoch: 5| Step: 3
Training loss: 0.49739029932854767
Validation loss: 2.7934037552262776

Epoch: 5| Step: 4
Training loss: 0.5182579901521411
Validation loss: 2.8616607854542386

Epoch: 5| Step: 5
Training loss: 0.8247237624463839
Validation loss: 2.7533612336480076

Epoch: 5| Step: 6
Training loss: 1.3599549295165878
Validation loss: 2.741379273684933

Epoch: 5| Step: 7
Training loss: 0.6775398744835034
Validation loss: 2.8543318482560363

Epoch: 5| Step: 8
Training loss: 0.5244458861968775
Validation loss: 2.826498487713149

Epoch: 5| Step: 9
Training loss: 0.8091769119646008
Validation loss: 2.7495524591349545

Epoch: 5| Step: 10
Training loss: 0.5166041585067394
Validation loss: 2.8044061156563633

Epoch: 5| Step: 11
Training loss: 0.3836027668749733
Validation loss: 2.804965374710785

Epoch: 257| Step: 0
Training loss: 0.6219470562235687
Validation loss: 2.8224696278127577

Epoch: 5| Step: 1
Training loss: 0.5426389941572957
Validation loss: 2.819928468040477

Epoch: 5| Step: 2
Training loss: 1.3751580407610255
Validation loss: 2.817672614096245

Epoch: 5| Step: 3
Training loss: 0.48920493687269767
Validation loss: 2.858455906307537

Epoch: 5| Step: 4
Training loss: 0.5906105110369263
Validation loss: 2.769748820881725

Epoch: 5| Step: 5
Training loss: 0.7693368888978869
Validation loss: 2.8485786119844567

Epoch: 5| Step: 6
Training loss: 0.9049205236153968
Validation loss: 2.875742431160308

Epoch: 5| Step: 7
Training loss: 0.5300177700734456
Validation loss: 2.8610272558561336

Epoch: 5| Step: 8
Training loss: 0.6789324282393799
Validation loss: 2.76892925152943

Epoch: 5| Step: 9
Training loss: 0.49118205719337493
Validation loss: 2.73539145514459

Epoch: 5| Step: 10
Training loss: 0.8698188792709699
Validation loss: 2.7693245886425233

Epoch: 5| Step: 11
Training loss: 0.33089791020583387
Validation loss: 2.8045788410075034

Epoch: 258| Step: 0
Training loss: 0.782178898762906
Validation loss: 2.800363499740673

Epoch: 5| Step: 1
Training loss: 0.6182215996793087
Validation loss: 2.756856473458196

Epoch: 5| Step: 2
Training loss: 0.52887086510445
Validation loss: 2.82436147833042

Epoch: 5| Step: 3
Training loss: 0.693046843247407
Validation loss: 2.848528257100496

Epoch: 5| Step: 4
Training loss: 0.571954610109062
Validation loss: 2.891182771773308

Epoch: 5| Step: 5
Training loss: 0.690630741872264
Validation loss: 2.831474824811104

Epoch: 5| Step: 6
Training loss: 1.5199305933866745
Validation loss: 2.8104503863333434

Epoch: 5| Step: 7
Training loss: 0.8868246141332597
Validation loss: 2.7009437944682486

Epoch: 5| Step: 8
Training loss: 0.686456408423203
Validation loss: 2.8005756850733015

Epoch: 5| Step: 9
Training loss: 0.6493926998439472
Validation loss: 2.799236848974774

Epoch: 5| Step: 10
Training loss: 0.5601264094407563
Validation loss: 2.7152350054594607

Epoch: 5| Step: 11
Training loss: 0.45633582653514454
Validation loss: 2.8323082939652258

Epoch: 259| Step: 0
Training loss: 0.7401819940317299
Validation loss: 2.846752667023222

Epoch: 5| Step: 1
Training loss: 0.6821600566242105
Validation loss: 2.8388255452751148

Epoch: 5| Step: 2
Training loss: 0.615989802562541
Validation loss: 2.7678101450655364

Epoch: 5| Step: 3
Training loss: 0.6640463434385667
Validation loss: 2.7573654705835042

Epoch: 5| Step: 4
Training loss: 0.685812808892721
Validation loss: 2.7446556865926373

Epoch: 5| Step: 5
Training loss: 1.4201933589438904
Validation loss: 2.8833146420370954

Epoch: 5| Step: 6
Training loss: 0.7624955349150452
Validation loss: 2.8186315456630564

Epoch: 5| Step: 7
Training loss: 0.6515336631778882
Validation loss: 2.8349578433403733

Epoch: 5| Step: 8
Training loss: 0.5631971807082823
Validation loss: 2.79513565337084

Epoch: 5| Step: 9
Training loss: 0.6861850344023538
Validation loss: 2.733760583057917

Epoch: 5| Step: 10
Training loss: 0.8970246193525624
Validation loss: 2.9336608594591245

Epoch: 5| Step: 11
Training loss: 0.4005133464032444
Validation loss: 2.7478092635834246

Epoch: 260| Step: 0
Training loss: 0.5302651757708443
Validation loss: 2.765240216831676

Epoch: 5| Step: 1
Training loss: 0.8913780508838397
Validation loss: 2.8275022962770544

Epoch: 5| Step: 2
Training loss: 0.6204929925183227
Validation loss: 2.8058478842564663

Epoch: 5| Step: 3
Training loss: 0.5528025770401956
Validation loss: 2.735875853129567

Epoch: 5| Step: 4
Training loss: 0.7452338890988284
Validation loss: 2.7508368302602033

Epoch: 5| Step: 5
Training loss: 0.5215121201124467
Validation loss: 2.7927170717889274

Epoch: 5| Step: 6
Training loss: 0.4050025494224463
Validation loss: 2.777547210952512

Epoch: 5| Step: 7
Training loss: 1.421643248734493
Validation loss: 2.824883832484149

Epoch: 5| Step: 8
Training loss: 0.6950167980839829
Validation loss: 2.9033213697855618

Epoch: 5| Step: 9
Training loss: 0.7372333012057983
Validation loss: 2.7581387940076345

Epoch: 5| Step: 10
Training loss: 0.6793696219223508
Validation loss: 2.8511846352966868

Epoch: 5| Step: 11
Training loss: 0.9986893886846957
Validation loss: 2.7932452156155434

Epoch: 261| Step: 0
Training loss: 0.490186255779679
Validation loss: 2.8374057363405494

Epoch: 5| Step: 1
Training loss: 0.9381483379310052
Validation loss: 2.7232866218810554

Epoch: 5| Step: 2
Training loss: 0.45803205023362065
Validation loss: 2.82247247872846

Epoch: 5| Step: 3
Training loss: 0.6434406185213527
Validation loss: 2.860658166632125

Epoch: 5| Step: 4
Training loss: 0.8622759320658437
Validation loss: 2.7507998755403262

Epoch: 5| Step: 5
Training loss: 1.373869431140169
Validation loss: 2.776193419001142

Epoch: 5| Step: 6
Training loss: 0.3872312367439129
Validation loss: 2.7953049108246923

Epoch: 5| Step: 7
Training loss: 0.5529229479358448
Validation loss: 2.79093096537735

Epoch: 5| Step: 8
Training loss: 0.735459359058197
Validation loss: 2.9396366066344313

Epoch: 5| Step: 9
Training loss: 0.5582841668852166
Validation loss: 2.772526103247402

Epoch: 5| Step: 10
Training loss: 0.6354453335741889
Validation loss: 2.9334251331645587

Epoch: 5| Step: 11
Training loss: 0.7033689287709026
Validation loss: 2.8630562937215673

Epoch: 262| Step: 0
Training loss: 0.5901739699269035
Validation loss: 2.7769533965916935

Epoch: 5| Step: 1
Training loss: 0.7535526849898957
Validation loss: 2.8672621160321

Epoch: 5| Step: 2
Training loss: 0.43530353881967
Validation loss: 2.8420432422022874

Epoch: 5| Step: 3
Training loss: 0.633739522399667
Validation loss: 2.741810699397604

Epoch: 5| Step: 4
Training loss: 0.6402154404154369
Validation loss: 2.7936768494487083

Epoch: 5| Step: 5
Training loss: 0.5477301043070668
Validation loss: 2.873909093682261

Epoch: 5| Step: 6
Training loss: 0.40814584576587243
Validation loss: 2.891166983304701

Epoch: 5| Step: 7
Training loss: 0.5689463779427701
Validation loss: 2.8117054523373683

Epoch: 5| Step: 8
Training loss: 1.3761953446625363
Validation loss: 2.777868901718434

Epoch: 5| Step: 9
Training loss: 0.7367442849710681
Validation loss: 2.8219279015680945

Epoch: 5| Step: 10
Training loss: 0.6550745655161009
Validation loss: 2.8089298865969106

Epoch: 5| Step: 11
Training loss: 0.9411509630703453
Validation loss: 2.8177141388124087

Epoch: 263| Step: 0
Training loss: 0.694850703985897
Validation loss: 2.8330641903856684

Epoch: 5| Step: 1
Training loss: 0.7408637840898472
Validation loss: 2.807899944717724

Epoch: 5| Step: 2
Training loss: 0.6404705326588771
Validation loss: 2.852114967930531

Epoch: 5| Step: 3
Training loss: 1.3367800370239915
Validation loss: 2.8863465134102073

Epoch: 5| Step: 4
Training loss: 0.3895071055384855
Validation loss: 2.8438630343598734

Epoch: 5| Step: 5
Training loss: 0.6237085828619018
Validation loss: 2.85195762997226

Epoch: 5| Step: 6
Training loss: 0.5263070264983989
Validation loss: 2.858617508546164

Epoch: 5| Step: 7
Training loss: 0.5571071343008431
Validation loss: 2.907253796175786

Epoch: 5| Step: 8
Training loss: 0.799063202608148
Validation loss: 2.9096596108444737

Epoch: 5| Step: 9
Training loss: 0.4952351958061478
Validation loss: 2.7529186236378087

Epoch: 5| Step: 10
Training loss: 0.6994123350717049
Validation loss: 2.8192699368711116

Epoch: 5| Step: 11
Training loss: 1.3460083990330964
Validation loss: 2.839126881226523

Epoch: 264| Step: 0
Training loss: 0.37612076012962276
Validation loss: 2.8762667774516273

Epoch: 5| Step: 1
Training loss: 1.3359177794311552
Validation loss: 2.8473809400891983

Epoch: 5| Step: 2
Training loss: 0.5582029402714525
Validation loss: 2.750828672312852

Epoch: 5| Step: 3
Training loss: 0.5593344306086317
Validation loss: 2.8549592711243093

Epoch: 5| Step: 4
Training loss: 0.5858003074250565
Validation loss: 2.845440020035027

Epoch: 5| Step: 5
Training loss: 0.6382104215696328
Validation loss: 2.7822253449387016

Epoch: 5| Step: 6
Training loss: 0.7572632991999451
Validation loss: 2.7556256781606288

Epoch: 5| Step: 7
Training loss: 0.6093985479646792
Validation loss: 2.7899116697992943

Epoch: 5| Step: 8
Training loss: 0.5532606335741522
Validation loss: 2.77178850537161

Epoch: 5| Step: 9
Training loss: 0.6494090374056639
Validation loss: 2.785946830552744

Epoch: 5| Step: 10
Training loss: 0.766223751197262
Validation loss: 2.827716583633013

Epoch: 5| Step: 11
Training loss: 0.8495682980484022
Validation loss: 2.7832627567796253

Epoch: 265| Step: 0
Training loss: 0.7986534319366425
Validation loss: 2.81400823066003

Epoch: 5| Step: 1
Training loss: 0.6055063051451456
Validation loss: 2.8024148933959125

Epoch: 5| Step: 2
Training loss: 0.5650432630027447
Validation loss: 2.8234589391364824

Epoch: 5| Step: 3
Training loss: 1.3952655301619843
Validation loss: 2.7403485905831526

Epoch: 5| Step: 4
Training loss: 0.7117523302683922
Validation loss: 2.8731117232572396

Epoch: 5| Step: 5
Training loss: 0.6252547698512021
Validation loss: 2.7080725336439864

Epoch: 5| Step: 6
Training loss: 0.5520346158203341
Validation loss: 2.829529857685361

Epoch: 5| Step: 7
Training loss: 0.5210834919664752
Validation loss: 2.860061042074201

Epoch: 5| Step: 8
Training loss: 0.5730933234925994
Validation loss: 2.8038541818572407

Epoch: 5| Step: 9
Training loss: 0.576522384323129
Validation loss: 2.7741230184613035

Epoch: 5| Step: 10
Training loss: 0.6682631529809796
Validation loss: 2.8119591864092537

Epoch: 5| Step: 11
Training loss: 1.0027364007849862
Validation loss: 2.7726759818786535

Epoch: 266| Step: 0
Training loss: 0.8025186067723606
Validation loss: 2.707381460225468

Epoch: 5| Step: 1
Training loss: 0.7206449821196367
Validation loss: 2.733988336744734

Epoch: 5| Step: 2
Training loss: 0.4604159815453773
Validation loss: 2.7873920278635955

Epoch: 5| Step: 3
Training loss: 0.7630508512422836
Validation loss: 2.7848871109065296

Epoch: 5| Step: 4
Training loss: 0.7588088967027472
Validation loss: 2.803081194146566

Epoch: 5| Step: 5
Training loss: 0.40720773557325496
Validation loss: 2.860762046046532

Epoch: 5| Step: 6
Training loss: 0.873195490466263
Validation loss: 2.756559809676341

Epoch: 5| Step: 7
Training loss: 0.3311912457523721
Validation loss: 2.810377948730878

Epoch: 5| Step: 8
Training loss: 1.4574412569277087
Validation loss: 2.737720139969602

Epoch: 5| Step: 9
Training loss: 0.7377947460786832
Validation loss: 2.836801227507655

Epoch: 5| Step: 10
Training loss: 0.9192670690587306
Validation loss: 2.832356927495608

Epoch: 5| Step: 11
Training loss: 0.7934396782958218
Validation loss: 2.7945271161462704

Epoch: 267| Step: 0
Training loss: 0.6489827265270196
Validation loss: 2.7665575937138347

Epoch: 5| Step: 1
Training loss: 1.350499567564945
Validation loss: 2.7563914815585173

Epoch: 5| Step: 2
Training loss: 0.571779715307515
Validation loss: 2.743579384460039

Epoch: 5| Step: 3
Training loss: 0.5210833203874802
Validation loss: 2.7230689977829714

Epoch: 5| Step: 4
Training loss: 0.5654176173791317
Validation loss: 2.8317377047939356

Epoch: 5| Step: 5
Training loss: 0.7209932730489234
Validation loss: 2.8162195511520918

Epoch: 5| Step: 6
Training loss: 0.6942559905777621
Validation loss: 2.7953342370797456

Epoch: 5| Step: 7
Training loss: 0.7499672167288783
Validation loss: 2.814491128764197

Epoch: 5| Step: 8
Training loss: 0.5091378742428773
Validation loss: 2.749123321579638

Epoch: 5| Step: 9
Training loss: 0.5160277556524738
Validation loss: 2.7839676584364836

Epoch: 5| Step: 10
Training loss: 0.8457178198262332
Validation loss: 2.8095533759179334

Epoch: 5| Step: 11
Training loss: 0.7712629942208933
Validation loss: 2.7449573500619846

Epoch: 268| Step: 0
Training loss: 0.45903878396761033
Validation loss: 2.8346934046119756

Epoch: 5| Step: 1
Training loss: 0.5173791466911056
Validation loss: 2.76049078116098

Epoch: 5| Step: 2
Training loss: 1.3076068857825627
Validation loss: 2.7443819204654543

Epoch: 5| Step: 3
Training loss: 0.6744604267673813
Validation loss: 2.850944246479752

Epoch: 5| Step: 4
Training loss: 0.7872282179856364
Validation loss: 2.7888700808872002

Epoch: 5| Step: 5
Training loss: 0.5947093240779597
Validation loss: 2.809941438452735

Epoch: 5| Step: 6
Training loss: 0.8082611948117661
Validation loss: 2.7962734989252622

Epoch: 5| Step: 7
Training loss: 0.4042849515916629
Validation loss: 2.820907846947639

Epoch: 5| Step: 8
Training loss: 0.522202500927436
Validation loss: 2.812429805162218

Epoch: 5| Step: 9
Training loss: 0.5587091126725868
Validation loss: 2.7836036831127786

Epoch: 5| Step: 10
Training loss: 0.5857414935019802
Validation loss: 2.7885459970168207

Epoch: 5| Step: 11
Training loss: 0.754346017604735
Validation loss: 2.798660511109881

Epoch: 269| Step: 0
Training loss: 0.4924050259147333
Validation loss: 2.8583319138967327

Epoch: 5| Step: 1
Training loss: 0.515809950747951
Validation loss: 2.8130633390469275

Epoch: 5| Step: 2
Training loss: 0.6221862876493253
Validation loss: 2.799743942632514

Epoch: 5| Step: 3
Training loss: 0.6954007896346447
Validation loss: 2.843048155813853

Epoch: 5| Step: 4
Training loss: 1.3555400730683744
Validation loss: 2.8093807654627505

Epoch: 5| Step: 5
Training loss: 0.6106833570818266
Validation loss: 2.8610640854247547

Epoch: 5| Step: 6
Training loss: 0.35799772224420917
Validation loss: 2.7794315486902947

Epoch: 5| Step: 7
Training loss: 0.9462700714945651
Validation loss: 2.826787709714329

Epoch: 5| Step: 8
Training loss: 0.4056922495071329
Validation loss: 2.8159431150797616

Epoch: 5| Step: 9
Training loss: 0.5531875855119643
Validation loss: 2.8366222658298406

Epoch: 5| Step: 10
Training loss: 0.8273999260840361
Validation loss: 2.739132388366308

Epoch: 5| Step: 11
Training loss: 0.3887232837512278
Validation loss: 2.7542703626813183

Epoch: 270| Step: 0
Training loss: 0.6491798380036653
Validation loss: 2.8059560905044902

Epoch: 5| Step: 1
Training loss: 0.5705697511497819
Validation loss: 2.7265857159956943

Epoch: 5| Step: 2
Training loss: 0.5521573131105648
Validation loss: 2.7401365632925963

Epoch: 5| Step: 3
Training loss: 0.3888007099036223
Validation loss: 2.7889753661093057

Epoch: 5| Step: 4
Training loss: 0.8467252690454453
Validation loss: 2.76716521670766

Epoch: 5| Step: 5
Training loss: 0.38485929636621286
Validation loss: 2.762310739797522

Epoch: 5| Step: 6
Training loss: 0.6364159361291601
Validation loss: 2.745343000329042

Epoch: 5| Step: 7
Training loss: 0.6003355667392899
Validation loss: 2.8088447341935048

Epoch: 5| Step: 8
Training loss: 1.3860561883416904
Validation loss: 2.736549628053486

Epoch: 5| Step: 9
Training loss: 0.9746065311734405
Validation loss: 2.8275533663972054

Epoch: 5| Step: 10
Training loss: 0.5467839301438735
Validation loss: 2.803975290245819

Epoch: 5| Step: 11
Training loss: 0.6938084826863844
Validation loss: 2.79163464603754

Epoch: 271| Step: 0
Training loss: 0.6093542633440873
Validation loss: 2.7421713717168377

Epoch: 5| Step: 1
Training loss: 0.6438684697072748
Validation loss: 2.71728498442296

Epoch: 5| Step: 2
Training loss: 0.7492278415736914
Validation loss: 2.775275095343337

Epoch: 5| Step: 3
Training loss: 0.567918639353374
Validation loss: 2.812273429645499

Epoch: 5| Step: 4
Training loss: 0.48436314045323425
Validation loss: 2.9111800984941447

Epoch: 5| Step: 5
Training loss: 0.44239805418456646
Validation loss: 2.8485006398289605

Epoch: 5| Step: 6
Training loss: 0.6169637201932405
Validation loss: 2.781322603313895

Epoch: 5| Step: 7
Training loss: 1.4248978896114246
Validation loss: 2.7010148472354927

Epoch: 5| Step: 8
Training loss: 0.6493588531660203
Validation loss: 2.7744142343694946

Epoch: 5| Step: 9
Training loss: 0.5861304664755538
Validation loss: 2.866944967158619

Epoch: 5| Step: 10
Training loss: 0.5867887290132184
Validation loss: 2.9135949694699685

Epoch: 5| Step: 11
Training loss: 1.1944243179271754
Validation loss: 2.7738019820149185

Epoch: 272| Step: 0
Training loss: 0.6204138819484927
Validation loss: 2.7969382152836766

Epoch: 5| Step: 1
Training loss: 0.657488902364564
Validation loss: 2.851174342940994

Epoch: 5| Step: 2
Training loss: 0.5391071411666758
Validation loss: 2.7643279034998876

Epoch: 5| Step: 3
Training loss: 0.47719752105702934
Validation loss: 2.7780877005351314

Epoch: 5| Step: 4
Training loss: 0.803665475034628
Validation loss: 2.836238417760794

Epoch: 5| Step: 5
Training loss: 0.553778481106229
Validation loss: 2.800330079156209

Epoch: 5| Step: 6
Training loss: 0.71168265224999
Validation loss: 2.7471096570754567

Epoch: 5| Step: 7
Training loss: 0.7635005358710966
Validation loss: 2.8501299599803636

Epoch: 5| Step: 8
Training loss: 0.5077525763735072
Validation loss: 2.893925042622178

Epoch: 5| Step: 9
Training loss: 0.562331253807498
Validation loss: 2.8415311883605034

Epoch: 5| Step: 10
Training loss: 1.3947891723443373
Validation loss: 2.8257617771531334

Epoch: 5| Step: 11
Training loss: 0.25943575974691524
Validation loss: 2.8095874894136066

Epoch: 273| Step: 0
Training loss: 0.9194891492982313
Validation loss: 2.8722571613019845

Epoch: 5| Step: 1
Training loss: 0.5939645379620022
Validation loss: 2.759005348932027

Epoch: 5| Step: 2
Training loss: 0.5773185311514814
Validation loss: 2.7866214431130594

Epoch: 5| Step: 3
Training loss: 0.43349063781343583
Validation loss: 2.835692360952122

Epoch: 5| Step: 4
Training loss: 0.48787881670452665
Validation loss: 2.7831349147000664

Epoch: 5| Step: 5
Training loss: 0.6289164145459767
Validation loss: 2.804150564497978

Epoch: 5| Step: 6
Training loss: 0.7182754110746656
Validation loss: 2.838520572595641

Epoch: 5| Step: 7
Training loss: 0.7850661724288026
Validation loss: 2.8133745423251035

Epoch: 5| Step: 8
Training loss: 1.4213659192591028
Validation loss: 2.8367837776386775

Epoch: 5| Step: 9
Training loss: 0.5553479091365543
Validation loss: 2.8170279928996087

Epoch: 5| Step: 10
Training loss: 0.707793399308862
Validation loss: 2.7865863675563443

Epoch: 5| Step: 11
Training loss: 0.7999125164597393
Validation loss: 2.774443627477118

Epoch: 274| Step: 0
Training loss: 0.5495204156757193
Validation loss: 2.8962604301516177

Epoch: 5| Step: 1
Training loss: 0.4816098193289207
Validation loss: 2.8360467404570233

Epoch: 5| Step: 2
Training loss: 0.6933236126340553
Validation loss: 2.842140622667271

Epoch: 5| Step: 3
Training loss: 0.641848697996353
Validation loss: 2.8761570716776412

Epoch: 5| Step: 4
Training loss: 1.39532661729871
Validation loss: 2.8302312071971842

Epoch: 5| Step: 5
Training loss: 0.5107907915784926
Validation loss: 2.7772830110571047

Epoch: 5| Step: 6
Training loss: 0.535454854704218
Validation loss: 2.823559882490545

Epoch: 5| Step: 7
Training loss: 0.6686859073407804
Validation loss: 2.8531739371741707

Epoch: 5| Step: 8
Training loss: 0.4878342375228334
Validation loss: 2.8502837671421597

Epoch: 5| Step: 9
Training loss: 0.7928112606509532
Validation loss: 2.737092242943342

Epoch: 5| Step: 10
Training loss: 0.5305742847033922
Validation loss: 2.864773329011548

Epoch: 5| Step: 11
Training loss: 0.4857415488023781
Validation loss: 2.772042857796367

Epoch: 275| Step: 0
Training loss: 0.4323265873542736
Validation loss: 2.7980430053758027

Epoch: 5| Step: 1
Training loss: 0.5775093460565279
Validation loss: 2.8637263570936535

Epoch: 5| Step: 2
Training loss: 0.31291487096219617
Validation loss: 2.764675803651499

Epoch: 5| Step: 3
Training loss: 0.773365595393989
Validation loss: 2.821216639100505

Epoch: 5| Step: 4
Training loss: 0.6191598064929067
Validation loss: 2.7487066037781505

Epoch: 5| Step: 5
Training loss: 1.4002845968757993
Validation loss: 2.8132401057720533

Epoch: 5| Step: 6
Training loss: 0.8086555199364598
Validation loss: 2.736549613532854

Epoch: 5| Step: 7
Training loss: 0.631582194440739
Validation loss: 2.8214735140506275

Epoch: 5| Step: 8
Training loss: 0.4921782205100487
Validation loss: 2.8477084866282136

Epoch: 5| Step: 9
Training loss: 0.486113443444727
Validation loss: 2.888666843756403

Epoch: 5| Step: 10
Training loss: 0.47520182174319775
Validation loss: 2.8256775327672092

Epoch: 5| Step: 11
Training loss: 0.2007127448301241
Validation loss: 2.837364121683302

Epoch: 276| Step: 0
Training loss: 0.5388965351205709
Validation loss: 2.7808410686796488

Epoch: 5| Step: 1
Training loss: 0.43138239113757926
Validation loss: 2.8084582568908054

Epoch: 5| Step: 2
Training loss: 0.5610094189031662
Validation loss: 2.8175033887319825

Epoch: 5| Step: 3
Training loss: 0.7501671922613083
Validation loss: 2.744999312497431

Epoch: 5| Step: 4
Training loss: 0.7119195045713207
Validation loss: 2.8148422201679897

Epoch: 5| Step: 5
Training loss: 0.5799948378859373
Validation loss: 2.8692859174011414

Epoch: 5| Step: 6
Training loss: 1.3044214034405852
Validation loss: 2.818174085124025

Epoch: 5| Step: 7
Training loss: 0.4655356507053318
Validation loss: 2.803621934456646

Epoch: 5| Step: 8
Training loss: 0.5228438355790815
Validation loss: 2.675104327559019

Epoch: 5| Step: 9
Training loss: 0.457270421104495
Validation loss: 2.705635334746227

Epoch: 5| Step: 10
Training loss: 0.8411192678187338
Validation loss: 2.832094248805399

Epoch: 5| Step: 11
Training loss: 0.49430642343206566
Validation loss: 2.7335455481113526

Epoch: 277| Step: 0
Training loss: 0.542264330474535
Validation loss: 2.834911248322113

Epoch: 5| Step: 1
Training loss: 0.6482886177944377
Validation loss: 2.838614007337165

Epoch: 5| Step: 2
Training loss: 0.556454383077231
Validation loss: 2.7976446495749525

Epoch: 5| Step: 3
Training loss: 1.43789451824512
Validation loss: 2.7720431695762873

Epoch: 5| Step: 4
Training loss: 0.6612847969115446
Validation loss: 2.7797539684288943

Epoch: 5| Step: 5
Training loss: 0.41592081986592305
Validation loss: 2.870129478266461

Epoch: 5| Step: 6
Training loss: 0.6733969594342976
Validation loss: 2.7005738143113565

Epoch: 5| Step: 7
Training loss: 0.4939196850338127
Validation loss: 2.76722766036464

Epoch: 5| Step: 8
Training loss: 0.440771405942755
Validation loss: 2.7941866231259334

Epoch: 5| Step: 9
Training loss: 0.558648433542919
Validation loss: 2.8675113983559655

Epoch: 5| Step: 10
Training loss: 0.46744546561984346
Validation loss: 2.7990110523458367

Epoch: 5| Step: 11
Training loss: 0.303750234925607
Validation loss: 2.8063862861668136

Epoch: 278| Step: 0
Training loss: 0.4624831099905789
Validation loss: 2.803611800565788

Epoch: 5| Step: 1
Training loss: 0.6760502538934049
Validation loss: 2.8128186504555437

Epoch: 5| Step: 2
Training loss: 0.4379081014774932
Validation loss: 2.7687764432748008

Epoch: 5| Step: 3
Training loss: 0.753156615420717
Validation loss: 2.7479573958017323

Epoch: 5| Step: 4
Training loss: 0.36992022021526744
Validation loss: 2.8730454780926173

Epoch: 5| Step: 5
Training loss: 0.43304473898448753
Validation loss: 2.717154710808359

Epoch: 5| Step: 6
Training loss: 1.3303696457155556
Validation loss: 2.756334908576728

Epoch: 5| Step: 7
Training loss: 0.5572502679392058
Validation loss: 2.773010443103182

Epoch: 5| Step: 8
Training loss: 0.6726619636036014
Validation loss: 2.7819045007518874

Epoch: 5| Step: 9
Training loss: 0.6101265454357717
Validation loss: 2.9021665092008457

Epoch: 5| Step: 10
Training loss: 0.6620277421978557
Validation loss: 2.7460966223262635

Epoch: 5| Step: 11
Training loss: 0.4537439394249248
Validation loss: 2.829329130698204

Epoch: 279| Step: 0
Training loss: 0.6635545246269811
Validation loss: 2.8580329782161855

Epoch: 5| Step: 1
Training loss: 0.7602969079666854
Validation loss: 2.7517457355500765

Epoch: 5| Step: 2
Training loss: 0.5298651990764748
Validation loss: 2.8475857531032944

Epoch: 5| Step: 3
Training loss: 0.46733639873613947
Validation loss: 2.878564083585143

Epoch: 5| Step: 4
Training loss: 0.476624250319857
Validation loss: 2.850922429958829

Epoch: 5| Step: 5
Training loss: 1.4565865909439524
Validation loss: 2.7893284582707993

Epoch: 5| Step: 6
Training loss: 0.4812817711684585
Validation loss: 2.8347034379013913

Epoch: 5| Step: 7
Training loss: 0.49502953951771117
Validation loss: 2.779001169743703

Epoch: 5| Step: 8
Training loss: 0.43059331611264273
Validation loss: 2.872848956882589

Epoch: 5| Step: 9
Training loss: 0.5192749997669786
Validation loss: 2.8547800662590457

Epoch: 5| Step: 10
Training loss: 0.5122893551834702
Validation loss: 2.840630192851575

Epoch: 5| Step: 11
Training loss: 0.3254872292021772
Validation loss: 2.8263714167820044

Epoch: 280| Step: 0
Training loss: 0.6197243715398406
Validation loss: 2.8603017205084855

Epoch: 5| Step: 1
Training loss: 0.5128032752305146
Validation loss: 2.872648929479071

Epoch: 5| Step: 2
Training loss: 0.505326922416701
Validation loss: 2.7437074222027227

Epoch: 5| Step: 3
Training loss: 0.6351607046874338
Validation loss: 2.7711584371325007

Epoch: 5| Step: 4
Training loss: 0.5889536729251982
Validation loss: 2.823023510186067

Epoch: 5| Step: 5
Training loss: 1.442393473984167
Validation loss: 2.7627805317113405

Epoch: 5| Step: 6
Training loss: 0.687503771338089
Validation loss: 2.8868482712943044

Epoch: 5| Step: 7
Training loss: 0.5780455560484841
Validation loss: 2.7505620468760945

Epoch: 5| Step: 8
Training loss: 0.6172923228423122
Validation loss: 2.852814494461821

Epoch: 5| Step: 9
Training loss: 0.46052594319306983
Validation loss: 2.7766404403769895

Epoch: 5| Step: 10
Training loss: 0.4060654404369186
Validation loss: 2.755945746395094

Epoch: 5| Step: 11
Training loss: 0.33940794833999705
Validation loss: 2.8950549572969866

Epoch: 281| Step: 0
Training loss: 0.6855260079623335
Validation loss: 2.7516813195861043

Epoch: 5| Step: 1
Training loss: 0.5491522649729941
Validation loss: 2.769745962323695

Epoch: 5| Step: 2
Training loss: 0.41904691873438743
Validation loss: 2.822992423520229

Epoch: 5| Step: 3
Training loss: 0.4975682670394172
Validation loss: 2.8073646816650197

Epoch: 5| Step: 4
Training loss: 0.5761747198519546
Validation loss: 2.8146583328777246

Epoch: 5| Step: 5
Training loss: 0.7727522463511334
Validation loss: 2.8744055852211825

Epoch: 5| Step: 6
Training loss: 0.4279310566798862
Validation loss: 2.814143272990225

Epoch: 5| Step: 7
Training loss: 0.522267756889289
Validation loss: 2.806497997180825

Epoch: 5| Step: 8
Training loss: 0.6035629797075698
Validation loss: 2.6970924507842313

Epoch: 5| Step: 9
Training loss: 1.3754603308944677
Validation loss: 2.818931322405116

Epoch: 5| Step: 10
Training loss: 0.7337816154258452
Validation loss: 2.808599992868049

Epoch: 5| Step: 11
Training loss: 0.4505274740916726
Validation loss: 2.8059706838492033

Epoch: 282| Step: 0
Training loss: 0.6934972061920548
Validation loss: 2.8320572669927886

Epoch: 5| Step: 1
Training loss: 0.7517015705195254
Validation loss: 2.8015266962240366

Epoch: 5| Step: 2
Training loss: 0.5097418300877583
Validation loss: 2.854974396892015

Epoch: 5| Step: 3
Training loss: 0.4756906069146743
Validation loss: 2.900102084243038

Epoch: 5| Step: 4
Training loss: 1.3383588653700653
Validation loss: 2.8118509956641593

Epoch: 5| Step: 5
Training loss: 0.4822369116672639
Validation loss: 2.80633746097947

Epoch: 5| Step: 6
Training loss: 0.47359269748974786
Validation loss: 2.7941091099014206

Epoch: 5| Step: 7
Training loss: 0.4974914295809759
Validation loss: 2.8026504805322365

Epoch: 5| Step: 8
Training loss: 0.5091006447005137
Validation loss: 2.744185521311723

Epoch: 5| Step: 9
Training loss: 0.5649294839588462
Validation loss: 2.7396298913420183

Epoch: 5| Step: 10
Training loss: 0.4456092782477421
Validation loss: 2.828623999872702

Epoch: 5| Step: 11
Training loss: 0.7411860485697993
Validation loss: 2.866557745934269

Epoch: 283| Step: 0
Training loss: 0.5480630775715719
Validation loss: 2.7269929802898316

Epoch: 5| Step: 1
Training loss: 0.787894716190729
Validation loss: 2.90102898522464

Epoch: 5| Step: 2
Training loss: 1.288795767266529
Validation loss: 2.844360789005971

Epoch: 5| Step: 3
Training loss: 0.5136012619857198
Validation loss: 2.860120485053172

Epoch: 5| Step: 4
Training loss: 0.5179501905611618
Validation loss: 2.910163500475972

Epoch: 5| Step: 5
Training loss: 0.6246046484791633
Validation loss: 2.8610050995536938

Epoch: 5| Step: 6
Training loss: 0.5427352897358483
Validation loss: 2.931727107138676

Epoch: 5| Step: 7
Training loss: 0.5246812079610702
Validation loss: 2.724393036159769

Epoch: 5| Step: 8
Training loss: 0.8037440500587941
Validation loss: 2.8606885800704323

Epoch: 5| Step: 9
Training loss: 0.5274558054232147
Validation loss: 2.800654165026273

Epoch: 5| Step: 10
Training loss: 0.6102327032704885
Validation loss: 2.8179069397340255

Epoch: 5| Step: 11
Training loss: 0.4054965404769793
Validation loss: 2.884746023708549

Epoch: 284| Step: 0
Training loss: 0.4557600029095085
Validation loss: 2.7709898235233297

Epoch: 5| Step: 1
Training loss: 0.46176094920896366
Validation loss: 2.819451041140823

Epoch: 5| Step: 2
Training loss: 0.47455792874280206
Validation loss: 2.778015899518412

Epoch: 5| Step: 3
Training loss: 0.7782078832889301
Validation loss: 2.7314212212916846

Epoch: 5| Step: 4
Training loss: 0.8529580256788409
Validation loss: 2.8561356161963345

Epoch: 5| Step: 5
Training loss: 0.6246013084973845
Validation loss: 2.8538326337126154

Epoch: 5| Step: 6
Training loss: 0.603905610433341
Validation loss: 2.8184177624388167

Epoch: 5| Step: 7
Training loss: 1.3077047032420384
Validation loss: 2.825948478342465

Epoch: 5| Step: 8
Training loss: 0.4710286546209335
Validation loss: 2.8257667305590646

Epoch: 5| Step: 9
Training loss: 0.6218443359789385
Validation loss: 2.810666528646208

Epoch: 5| Step: 10
Training loss: 0.46715686595594674
Validation loss: 2.860667105257843

Epoch: 5| Step: 11
Training loss: 0.3186507851331344
Validation loss: 2.803022246247662

Epoch: 285| Step: 0
Training loss: 0.5423616541855563
Validation loss: 2.793629185413269

Epoch: 5| Step: 1
Training loss: 0.6583914105434445
Validation loss: 2.7162743693752356

Epoch: 5| Step: 2
Training loss: 0.6002447632398722
Validation loss: 2.81670101914158

Epoch: 5| Step: 3
Training loss: 0.44126557328080124
Validation loss: 2.8497398090382795

Epoch: 5| Step: 4
Training loss: 0.44259325289481183
Validation loss: 2.8318833130530865

Epoch: 5| Step: 5
Training loss: 0.5709727397831708
Validation loss: 2.8434480150453676

Epoch: 5| Step: 6
Training loss: 0.3947180504048611
Validation loss: 2.8009776743063

Epoch: 5| Step: 7
Training loss: 0.7398022117353772
Validation loss: 2.820386482318077

Epoch: 5| Step: 8
Training loss: 1.4784075799566048
Validation loss: 2.7561755450710224

Epoch: 5| Step: 9
Training loss: 0.5153754815453966
Validation loss: 2.8026969561587776

Epoch: 5| Step: 10
Training loss: 0.3543680146956876
Validation loss: 2.81136603277509

Epoch: 5| Step: 11
Training loss: 0.13042987969707942
Validation loss: 2.8216620515927198

Epoch: 286| Step: 0
Training loss: 0.5746519828885648
Validation loss: 2.7698034270229255

Epoch: 5| Step: 1
Training loss: 1.2591807345739063
Validation loss: 2.7941175183521554

Epoch: 5| Step: 2
Training loss: 0.5363463096564242
Validation loss: 2.7999049065541044

Epoch: 5| Step: 3
Training loss: 0.5817800658292286
Validation loss: 2.8130691376321972

Epoch: 5| Step: 4
Training loss: 0.7383489829988903
Validation loss: 2.784843177552068

Epoch: 5| Step: 5
Training loss: 0.5178828080399192
Validation loss: 2.821326463626828

Epoch: 5| Step: 6
Training loss: 0.8065600043180239
Validation loss: 2.7761901448367317

Epoch: 5| Step: 7
Training loss: 0.5136870175294506
Validation loss: 2.7890684446526155

Epoch: 5| Step: 8
Training loss: 0.6189085709033065
Validation loss: 2.8400818149105205

Epoch: 5| Step: 9
Training loss: 0.5353933212989457
Validation loss: 2.8944341151609847

Epoch: 5| Step: 10
Training loss: 0.6041175778495618
Validation loss: 2.844383853794356

Epoch: 5| Step: 11
Training loss: 0.285659659221467
Validation loss: 2.8492835357304402

Epoch: 287| Step: 0
Training loss: 0.553439765206111
Validation loss: 2.795395013804284

Epoch: 5| Step: 1
Training loss: 0.7071291608089542
Validation loss: 2.754906694934578

Epoch: 5| Step: 2
Training loss: 0.5984677807589579
Validation loss: 2.801851237563114

Epoch: 5| Step: 3
Training loss: 0.48917354688024534
Validation loss: 2.828565542146481

Epoch: 5| Step: 4
Training loss: 1.3274297352961615
Validation loss: 2.752104596891614

Epoch: 5| Step: 5
Training loss: 0.5091775300770756
Validation loss: 2.858361232990272

Epoch: 5| Step: 6
Training loss: 0.582986342451716
Validation loss: 2.72133204741668

Epoch: 5| Step: 7
Training loss: 0.4193879392421435
Validation loss: 2.8284179015958033

Epoch: 5| Step: 8
Training loss: 0.7570235874981066
Validation loss: 2.7851316746095196

Epoch: 5| Step: 9
Training loss: 0.43838022443879526
Validation loss: 2.758061423878207

Epoch: 5| Step: 10
Training loss: 0.48034601272090766
Validation loss: 2.806594264232239

Epoch: 5| Step: 11
Training loss: 0.5312777119308875
Validation loss: 2.76078252467151

Epoch: 288| Step: 0
Training loss: 0.5169834967770139
Validation loss: 2.761144791546274

Epoch: 5| Step: 1
Training loss: 0.9903513822328555
Validation loss: 2.8465393171386486

Epoch: 5| Step: 2
Training loss: 1.335092868717941
Validation loss: 2.797880641925943

Epoch: 5| Step: 3
Training loss: 0.6605392563897688
Validation loss: 2.8075132205897564

Epoch: 5| Step: 4
Training loss: 0.49981335792310455
Validation loss: 2.737350323764234

Epoch: 5| Step: 5
Training loss: 0.5763336213232321
Validation loss: 2.7780523777707185

Epoch: 5| Step: 6
Training loss: 0.42536198683391097
Validation loss: 2.799804300752384

Epoch: 5| Step: 7
Training loss: 0.6381321063939662
Validation loss: 2.819261994563258

Epoch: 5| Step: 8
Training loss: 0.6146665344386396
Validation loss: 2.804985182893573

Epoch: 5| Step: 9
Training loss: 0.5808335853295165
Validation loss: 2.8570399104032203

Epoch: 5| Step: 10
Training loss: 0.5173853677216359
Validation loss: 2.81632000442349

Epoch: 5| Step: 11
Training loss: 0.5006811449568767
Validation loss: 2.829419580909881

Epoch: 289| Step: 0
Training loss: 0.5149658208912243
Validation loss: 2.834454764463836

Epoch: 5| Step: 1
Training loss: 0.6703285339856433
Validation loss: 2.8087907986407554

Epoch: 5| Step: 2
Training loss: 0.6437770013794464
Validation loss: 2.80454203123032

Epoch: 5| Step: 3
Training loss: 0.48879567323145584
Validation loss: 2.7858489050464685

Epoch: 5| Step: 4
Training loss: 0.4174648527381378
Validation loss: 2.826549895796009

Epoch: 5| Step: 5
Training loss: 0.6246154078704559
Validation loss: 2.7569264185263043

Epoch: 5| Step: 6
Training loss: 0.7015516904750073
Validation loss: 2.857618953073416

Epoch: 5| Step: 7
Training loss: 0.5078842112452064
Validation loss: 2.7519171491102927

Epoch: 5| Step: 8
Training loss: 0.48242110279345773
Validation loss: 2.759206885821716

Epoch: 5| Step: 9
Training loss: 1.3611376504624615
Validation loss: 2.7491229060208178

Epoch: 5| Step: 10
Training loss: 0.5242750953376272
Validation loss: 2.7878918047391092

Epoch: 5| Step: 11
Training loss: 0.5132864314591438
Validation loss: 2.727529658451479

Epoch: 290| Step: 0
Training loss: 0.6856698472022342
Validation loss: 2.784946795805163

Epoch: 5| Step: 1
Training loss: 0.587716212967503
Validation loss: 2.7885455766454985

Epoch: 5| Step: 2
Training loss: 0.5586558487526834
Validation loss: 2.7992521019454415

Epoch: 5| Step: 3
Training loss: 0.4884131596724688
Validation loss: 2.7925735371855636

Epoch: 5| Step: 4
Training loss: 0.5350932620215111
Validation loss: 2.7710040023175506

Epoch: 5| Step: 5
Training loss: 1.3445097527566967
Validation loss: 2.874229362421887

Epoch: 5| Step: 6
Training loss: 0.6400693018465905
Validation loss: 2.773262831511261

Epoch: 5| Step: 7
Training loss: 0.41456878946503145
Validation loss: 2.929935729636864

Epoch: 5| Step: 8
Training loss: 0.722107343727597
Validation loss: 2.8405474910646062

Epoch: 5| Step: 9
Training loss: 0.3459053094871611
Validation loss: 2.868230991883624

Epoch: 5| Step: 10
Training loss: 0.5513174544690093
Validation loss: 2.80824712171486

Epoch: 5| Step: 11
Training loss: 0.413857823293403
Validation loss: 2.7696491928346685

Epoch: 291| Step: 0
Training loss: 0.6287785986962025
Validation loss: 2.889536386276722

Epoch: 5| Step: 1
Training loss: 0.7270564379449606
Validation loss: 2.8002211517463658

Epoch: 5| Step: 2
Training loss: 0.4606851759983805
Validation loss: 2.833174874044652

Epoch: 5| Step: 3
Training loss: 0.4892207757937736
Validation loss: 2.753425162929971

Epoch: 5| Step: 4
Training loss: 0.5477531195063797
Validation loss: 2.8093772506280525

Epoch: 5| Step: 5
Training loss: 0.49852400719620443
Validation loss: 2.7731291192051164

Epoch: 5| Step: 6
Training loss: 0.4674533393849936
Validation loss: 2.8833624807071585

Epoch: 5| Step: 7
Training loss: 0.7143437038451488
Validation loss: 2.806661242517937

Epoch: 5| Step: 8
Training loss: 0.5497857695284101
Validation loss: 2.7468201575014057

Epoch: 5| Step: 9
Training loss: 0.5644545505598078
Validation loss: 2.7832293307314337

Epoch: 5| Step: 10
Training loss: 0.5853535603440474
Validation loss: 2.896351076172582

Epoch: 5| Step: 11
Training loss: 2.7012093873084426
Validation loss: 2.765614992687561

Epoch: 292| Step: 0
Training loss: 0.38923452856056145
Validation loss: 2.744084049243489

Epoch: 5| Step: 1
Training loss: 0.353070532134252
Validation loss: 2.8579670474430907

Epoch: 5| Step: 2
Training loss: 0.5276547680382989
Validation loss: 2.9031007446108

Epoch: 5| Step: 3
Training loss: 0.448839375725912
Validation loss: 2.8221015081679774

Epoch: 5| Step: 4
Training loss: 0.6451506210750478
Validation loss: 2.808877636140462

Epoch: 5| Step: 5
Training loss: 0.36054499533711937
Validation loss: 2.843658721772397

Epoch: 5| Step: 6
Training loss: 0.7447627713304721
Validation loss: 2.8038668622920655

Epoch: 5| Step: 7
Training loss: 1.305909458287453
Validation loss: 2.8339133452004335

Epoch: 5| Step: 8
Training loss: 0.7445979277623697
Validation loss: 2.7641197785199796

Epoch: 5| Step: 9
Training loss: 0.6257601406999428
Validation loss: 2.793545710940784

Epoch: 5| Step: 10
Training loss: 0.6528008053372595
Validation loss: 2.8330257099177576

Epoch: 5| Step: 11
Training loss: 0.892241800663353
Validation loss: 2.8368473432511814

Epoch: 293| Step: 0
Training loss: 0.5900135680028681
Validation loss: 2.8571348882745693

Epoch: 5| Step: 1
Training loss: 0.5669641312383349
Validation loss: 2.7533735007961457

Epoch: 5| Step: 2
Training loss: 0.4737839290577622
Validation loss: 2.8741117121017217

Epoch: 5| Step: 3
Training loss: 0.6642660390046681
Validation loss: 2.8529419719460902

Epoch: 5| Step: 4
Training loss: 0.5820170663219075
Validation loss: 2.678784999734469

Epoch: 5| Step: 5
Training loss: 0.5497297706854642
Validation loss: 2.8402293073398845

Epoch: 5| Step: 6
Training loss: 0.7142695220746822
Validation loss: 2.827041081052113

Epoch: 5| Step: 7
Training loss: 0.3567300155939363
Validation loss: 2.9242715713767646

Epoch: 5| Step: 8
Training loss: 0.6527776816776105
Validation loss: 2.801480921025431

Epoch: 5| Step: 9
Training loss: 0.679073714309833
Validation loss: 2.8132993445237817

Epoch: 5| Step: 10
Training loss: 1.2271604113288332
Validation loss: 2.838073931079646

Epoch: 5| Step: 11
Training loss: 0.4581381606206174
Validation loss: 2.873759503115859

Epoch: 294| Step: 0
Training loss: 0.3013606621461644
Validation loss: 2.830634028085619

Epoch: 5| Step: 1
Training loss: 0.5537163735851155
Validation loss: 2.7781237451688536

Epoch: 5| Step: 2
Training loss: 0.509471296791572
Validation loss: 2.8948784678704267

Epoch: 5| Step: 3
Training loss: 0.5731727779029723
Validation loss: 2.8723197447358824

Epoch: 5| Step: 4
Training loss: 0.5543374582371535
Validation loss: 2.7478404379898373

Epoch: 5| Step: 5
Training loss: 0.551129008139495
Validation loss: 2.745669314493367

Epoch: 5| Step: 6
Training loss: 0.4127370384487073
Validation loss: 2.674560038016506

Epoch: 5| Step: 7
Training loss: 0.7034427136940176
Validation loss: 2.7403823149178512

Epoch: 5| Step: 8
Training loss: 1.234468963523371
Validation loss: 2.8313636606796706

Epoch: 5| Step: 9
Training loss: 0.41883793590790624
Validation loss: 2.752240160810807

Epoch: 5| Step: 10
Training loss: 0.45040175530873355
Validation loss: 2.75993149410336

Epoch: 5| Step: 11
Training loss: 0.8737588663156151
Validation loss: 2.7343608419869234

Epoch: 295| Step: 0
Training loss: 0.4480382085359438
Validation loss: 2.807768377241502

Epoch: 5| Step: 1
Training loss: 0.5436933882609666
Validation loss: 2.837165412557754

Epoch: 5| Step: 2
Training loss: 0.574183508381911
Validation loss: 2.8243675562065547

Epoch: 5| Step: 3
Training loss: 0.6968709646202222
Validation loss: 2.716360554874437

Epoch: 5| Step: 4
Training loss: 0.3778468787972629
Validation loss: 2.8591856520309755

Epoch: 5| Step: 5
Training loss: 1.31671614352754
Validation loss: 2.7558635997311773

Epoch: 5| Step: 6
Training loss: 0.4122855546596886
Validation loss: 2.7736932054584162

Epoch: 5| Step: 7
Training loss: 0.3282998504707177
Validation loss: 2.8289319743500605

Epoch: 5| Step: 8
Training loss: 0.4939053092013519
Validation loss: 2.7931215898002586

Epoch: 5| Step: 9
Training loss: 0.7840241198308455
Validation loss: 2.7744404156982

Epoch: 5| Step: 10
Training loss: 0.5801701071409884
Validation loss: 2.870536192994444

Epoch: 5| Step: 11
Training loss: 0.2879656524408814
Validation loss: 2.8830096755443746

Epoch: 296| Step: 0
Training loss: 0.5602075699583134
Validation loss: 2.8400564870511227

Epoch: 5| Step: 1
Training loss: 0.5134284309240995
Validation loss: 2.770813297734687

Epoch: 5| Step: 2
Training loss: 0.7028036442830974
Validation loss: 2.8728189626506437

Epoch: 5| Step: 3
Training loss: 1.2709499941367206
Validation loss: 2.853249661276833

Epoch: 5| Step: 4
Training loss: 0.6168190061284254
Validation loss: 2.834895020306735

Epoch: 5| Step: 5
Training loss: 0.6235824244423465
Validation loss: 2.8075800212666846

Epoch: 5| Step: 6
Training loss: 0.465198637825291
Validation loss: 2.7695225767960214

Epoch: 5| Step: 7
Training loss: 0.47928268299683235
Validation loss: 2.863184644067718

Epoch: 5| Step: 8
Training loss: 0.5410366949392317
Validation loss: 2.834390188370638

Epoch: 5| Step: 9
Training loss: 0.42213619058747115
Validation loss: 2.776907563328769

Epoch: 5| Step: 10
Training loss: 0.2800899263712775
Validation loss: 2.8337222012431114

Epoch: 5| Step: 11
Training loss: 0.14077753165835405
Validation loss: 2.8286109387408755

Epoch: 297| Step: 0
Training loss: 0.4567716138159573
Validation loss: 2.908963611471139

Epoch: 5| Step: 1
Training loss: 1.2341387558862729
Validation loss: 2.7425695734579394

Epoch: 5| Step: 2
Training loss: 0.43327909513777507
Validation loss: 2.811063904930281

Epoch: 5| Step: 3
Training loss: 0.4232479994603222
Validation loss: 2.7655102370134803

Epoch: 5| Step: 4
Training loss: 0.4616804923587855
Validation loss: 2.8413722189626633

Epoch: 5| Step: 5
Training loss: 0.5420664143640352
Validation loss: 2.7485097690931677

Epoch: 5| Step: 6
Training loss: 0.5363842317333014
Validation loss: 2.737823916131575

Epoch: 5| Step: 7
Training loss: 0.6853196074416846
Validation loss: 2.7693592156198794

Epoch: 5| Step: 8
Training loss: 0.36782898566962574
Validation loss: 2.7405964545775445

Epoch: 5| Step: 9
Training loss: 0.5412195420450203
Validation loss: 2.740569398954678

Epoch: 5| Step: 10
Training loss: 0.4420317210319331
Validation loss: 2.8180635913456262

Epoch: 5| Step: 11
Training loss: 0.5667833059778092
Validation loss: 2.9074777621268604

Epoch: 298| Step: 0
Training loss: 0.519093465277587
Validation loss: 2.8198516236662083

Epoch: 5| Step: 1
Training loss: 0.34999402160307014
Validation loss: 2.7605071011010716

Epoch: 5| Step: 2
Training loss: 0.5097805620248587
Validation loss: 2.892658776003111

Epoch: 5| Step: 3
Training loss: 0.7120470045840096
Validation loss: 2.8533867352790057

Epoch: 5| Step: 4
Training loss: 0.5125551449950719
Validation loss: 2.811855577886653

Epoch: 5| Step: 5
Training loss: 0.8211575469722378
Validation loss: 2.8365472920888344

Epoch: 5| Step: 6
Training loss: 1.2495019874327975
Validation loss: 2.752881916989842

Epoch: 5| Step: 7
Training loss: 0.38815399632891084
Validation loss: 2.73722722931406

Epoch: 5| Step: 8
Training loss: 0.5054670602101023
Validation loss: 2.805595700734239

Epoch: 5| Step: 9
Training loss: 0.5920994051426002
Validation loss: 2.8484850001529174

Epoch: 5| Step: 10
Training loss: 0.5367416510214702
Validation loss: 2.817508423647943

Epoch: 5| Step: 11
Training loss: 1.1023431271038282
Validation loss: 2.786356916394287

Epoch: 299| Step: 0
Training loss: 0.55398620006953
Validation loss: 2.748501943989719

Epoch: 5| Step: 1
Training loss: 0.5508611905137429
Validation loss: 2.7774470507246964

Epoch: 5| Step: 2
Training loss: 0.6397166907317546
Validation loss: 2.831608602621906

Epoch: 5| Step: 3
Training loss: 0.6448996444743166
Validation loss: 2.7347923468937196

Epoch: 5| Step: 4
Training loss: 0.6591377301461706
Validation loss: 2.758680360166013

Epoch: 5| Step: 5
Training loss: 0.47037846302275255
Validation loss: 2.832405875848279

Epoch: 5| Step: 6
Training loss: 0.5835730593689066
Validation loss: 2.899141759046326

Epoch: 5| Step: 7
Training loss: 1.2958345490886387
Validation loss: 2.705743807378865

Epoch: 5| Step: 8
Training loss: 0.5168395909239437
Validation loss: 2.788257468448062

Epoch: 5| Step: 9
Training loss: 0.7543705908670972
Validation loss: 2.7427464211718484

Epoch: 5| Step: 10
Training loss: 0.5360692999347233
Validation loss: 2.7282077503653976

Epoch: 5| Step: 11
Training loss: 0.4624606682832767
Validation loss: 2.7292124268769817

Epoch: 300| Step: 0
Training loss: 1.299846141220078
Validation loss: 2.822709647232378

Epoch: 5| Step: 1
Training loss: 0.7444386123393983
Validation loss: 2.7831357392301572

Epoch: 5| Step: 2
Training loss: 0.48920088568168246
Validation loss: 2.79627981548304

Epoch: 5| Step: 3
Training loss: 0.6047154324016569
Validation loss: 2.86881173025187

Epoch: 5| Step: 4
Training loss: 0.5094109832598063
Validation loss: 2.885165611022588

Epoch: 5| Step: 5
Training loss: 0.6448793107236414
Validation loss: 2.8562594117970175

Epoch: 5| Step: 6
Training loss: 0.3490804261750312
Validation loss: 2.7379831976308826

Epoch: 5| Step: 7
Training loss: 0.5632903057328097
Validation loss: 2.8198406479922498

Epoch: 5| Step: 8
Training loss: 0.3847087488883172
Validation loss: 2.760813502211601

Epoch: 5| Step: 9
Training loss: 0.7941124846824612
Validation loss: 2.796922956797866

Epoch: 5| Step: 10
Training loss: 0.5029341317878573
Validation loss: 2.786090826000529

Epoch: 5| Step: 11
Training loss: 0.30091350917318127
Validation loss: 2.780716048287896

Epoch: 301| Step: 0
Training loss: 0.5114592265362784
Validation loss: 2.8518052333134567

Epoch: 5| Step: 1
Training loss: 0.39051430087333816
Validation loss: 2.7888751461242225

Epoch: 5| Step: 2
Training loss: 0.5862182453234076
Validation loss: 2.7954970575898357

Epoch: 5| Step: 3
Training loss: 0.6355712942204665
Validation loss: 2.7992895561885502

Epoch: 5| Step: 4
Training loss: 0.6317505343940265
Validation loss: 2.810477504444066

Epoch: 5| Step: 5
Training loss: 0.5168590805203712
Validation loss: 2.8567273783732996

Epoch: 5| Step: 6
Training loss: 0.45149841711858874
Validation loss: 2.7270660518354157

Epoch: 5| Step: 7
Training loss: 0.4828602116043679
Validation loss: 2.829868422084692

Epoch: 5| Step: 8
Training loss: 0.6205033669268964
Validation loss: 2.707726723643557

Epoch: 5| Step: 9
Training loss: 0.657760924358405
Validation loss: 2.7270056538389764

Epoch: 5| Step: 10
Training loss: 1.2904022652685971
Validation loss: 2.7714730554429727

Epoch: 5| Step: 11
Training loss: 0.5957244368946434
Validation loss: 2.821734217120382

Epoch: 302| Step: 0
Training loss: 1.2803329349197077
Validation loss: 2.8198018831411584

Epoch: 5| Step: 1
Training loss: 0.4353812206326621
Validation loss: 2.86360721372036

Epoch: 5| Step: 2
Training loss: 0.5022290135846212
Validation loss: 2.8112192805392655

Epoch: 5| Step: 3
Training loss: 0.4299736457333612
Validation loss: 2.890783202507424

Epoch: 5| Step: 4
Training loss: 0.5914631522657423
Validation loss: 2.8569061655255603

Epoch: 5| Step: 5
Training loss: 0.6661963790873028
Validation loss: 2.8476078672969116

Epoch: 5| Step: 6
Training loss: 0.7206929524021661
Validation loss: 2.7972896879422184

Epoch: 5| Step: 7
Training loss: 0.5052669399390761
Validation loss: 2.875801292652887

Epoch: 5| Step: 8
Training loss: 0.4859381954764636
Validation loss: 2.844379208720276

Epoch: 5| Step: 9
Training loss: 0.42284488452457236
Validation loss: 2.791281799337991

Epoch: 5| Step: 10
Training loss: 0.43810601496682616
Validation loss: 2.785782221590465

Epoch: 5| Step: 11
Training loss: 0.377269177541558
Validation loss: 2.754953424287346

Epoch: 303| Step: 0
Training loss: 0.7481167115761798
Validation loss: 2.8674901617170185

Epoch: 5| Step: 1
Training loss: 0.5506697196856574
Validation loss: 2.8167300027200812

Epoch: 5| Step: 2
Training loss: 0.42790269370451406
Validation loss: 2.797056863508861

Epoch: 5| Step: 3
Training loss: 0.5266011979459994
Validation loss: 2.784358812392846

Epoch: 5| Step: 4
Training loss: 1.2067164532171448
Validation loss: 2.8418221209301535

Epoch: 5| Step: 5
Training loss: 0.4274447954517169
Validation loss: 2.7707969381098043

Epoch: 5| Step: 6
Training loss: 0.3306532369645274
Validation loss: 2.8068236572500975

Epoch: 5| Step: 7
Training loss: 0.560823618132554
Validation loss: 2.7666001064603263

Epoch: 5| Step: 8
Training loss: 0.42159397867366355
Validation loss: 2.7969227081719428

Epoch: 5| Step: 9
Training loss: 0.632752851335845
Validation loss: 2.7537435100257874

Epoch: 5| Step: 10
Training loss: 0.47726658885794165
Validation loss: 2.8230480231566077

Epoch: 5| Step: 11
Training loss: 0.7928249435440663
Validation loss: 2.856834645052699

Epoch: 304| Step: 0
Training loss: 0.38698177833069464
Validation loss: 2.770264442860386

Epoch: 5| Step: 1
Training loss: 0.43240721625178546
Validation loss: 2.769873859285408

Epoch: 5| Step: 2
Training loss: 0.6654856746444413
Validation loss: 2.8176451844609267

Epoch: 5| Step: 3
Training loss: 0.5485090366669291
Validation loss: 2.8369839491692104

Epoch: 5| Step: 4
Training loss: 0.4915058774887747
Validation loss: 2.852202499543582

Epoch: 5| Step: 5
Training loss: 0.44080434963815834
Validation loss: 2.7759110394365143

Epoch: 5| Step: 6
Training loss: 0.6583239617062948
Validation loss: 2.924271887309099

Epoch: 5| Step: 7
Training loss: 0.7850854186946231
Validation loss: 2.8270746110534675

Epoch: 5| Step: 8
Training loss: 1.283508821766952
Validation loss: 2.81882296930839

Epoch: 5| Step: 9
Training loss: 0.3661876213280574
Validation loss: 2.7704060782003928

Epoch: 5| Step: 10
Training loss: 0.6872663317571893
Validation loss: 2.7882976747761035

Epoch: 5| Step: 11
Training loss: 0.4776774012980371
Validation loss: 2.8194458529015223

Epoch: 305| Step: 0
Training loss: 0.456944465548635
Validation loss: 2.7309934251155092

Epoch: 5| Step: 1
Training loss: 0.48963213400066163
Validation loss: 2.8350172520168093

Epoch: 5| Step: 2
Training loss: 0.5914869346659
Validation loss: 2.8211833352621354

Epoch: 5| Step: 3
Training loss: 0.5775547823993524
Validation loss: 2.7952185792534507

Epoch: 5| Step: 4
Training loss: 0.5591456481187754
Validation loss: 2.8307394865679036

Epoch: 5| Step: 5
Training loss: 0.41662425977753886
Validation loss: 2.7857669590562715

Epoch: 5| Step: 6
Training loss: 1.2691548420352512
Validation loss: 2.825042745103656

Epoch: 5| Step: 7
Training loss: 0.5108284813534851
Validation loss: 2.8174928181998724

Epoch: 5| Step: 8
Training loss: 0.48231671998087305
Validation loss: 2.767079087813083

Epoch: 5| Step: 9
Training loss: 0.7629992164092834
Validation loss: 2.742870999148802

Epoch: 5| Step: 10
Training loss: 0.8176994485230678
Validation loss: 2.8966665487176004

Epoch: 5| Step: 11
Training loss: 0.4337886337972049
Validation loss: 2.7797950375022444

Epoch: 306| Step: 0
Training loss: 0.3830113186595518
Validation loss: 2.8660951208644323

Epoch: 5| Step: 1
Training loss: 0.4650574841910041
Validation loss: 2.811481697679874

Epoch: 5| Step: 2
Training loss: 0.5823638273052922
Validation loss: 2.7610052824740117

Epoch: 5| Step: 3
Training loss: 0.4833729592747074
Validation loss: 2.705053457429975

Epoch: 5| Step: 4
Training loss: 0.7389043368570685
Validation loss: 2.836276007031902

Epoch: 5| Step: 5
Training loss: 0.5491485474867455
Validation loss: 2.789869603080252

Epoch: 5| Step: 6
Training loss: 0.6059569820677609
Validation loss: 2.7499803412341657

Epoch: 5| Step: 7
Training loss: 0.6026544444992005
Validation loss: 2.8162450193126043

Epoch: 5| Step: 8
Training loss: 0.3677950357911113
Validation loss: 2.7852662017077576

Epoch: 5| Step: 9
Training loss: 1.3540141190901351
Validation loss: 2.818035118534873

Epoch: 5| Step: 10
Training loss: 0.543348220941073
Validation loss: 2.75536710261249

Epoch: 5| Step: 11
Training loss: 0.7924665166598575
Validation loss: 2.8830811117820305

Epoch: 307| Step: 0
Training loss: 0.5445952992144983
Validation loss: 2.85643416269414

Epoch: 5| Step: 1
Training loss: 0.6467949619626625
Validation loss: 2.8274535757312886

Epoch: 5| Step: 2
Training loss: 0.6686604805327726
Validation loss: 2.781262379879491

Epoch: 5| Step: 3
Training loss: 0.4570201970255506
Validation loss: 2.6784623387995365

Epoch: 5| Step: 4
Training loss: 0.5192067559848944
Validation loss: 2.712051921083732

Epoch: 5| Step: 5
Training loss: 0.40189794267273543
Validation loss: 2.796368164086202

Epoch: 5| Step: 6
Training loss: 0.5683822889395459
Validation loss: 2.7829179370060677

Epoch: 5| Step: 7
Training loss: 1.2354170830882991
Validation loss: 2.7689870417142344

Epoch: 5| Step: 8
Training loss: 0.441163832001946
Validation loss: 2.804591914879646

Epoch: 5| Step: 9
Training loss: 0.6857529680908921
Validation loss: 2.811988883023198

Epoch: 5| Step: 10
Training loss: 0.32330869007870794
Validation loss: 2.8201845937874155

Epoch: 5| Step: 11
Training loss: 0.21408347945884576
Validation loss: 2.79132735031174

Epoch: 308| Step: 0
Training loss: 0.31813728449322815
Validation loss: 2.791957930178701

Epoch: 5| Step: 1
Training loss: 0.5792419366386455
Validation loss: 2.810155960194701

Epoch: 5| Step: 2
Training loss: 0.507294552094428
Validation loss: 2.779862836597458

Epoch: 5| Step: 3
Training loss: 0.5000500951944052
Validation loss: 2.799486514532811

Epoch: 5| Step: 4
Training loss: 0.5650972433296029
Validation loss: 2.810347913424699

Epoch: 5| Step: 5
Training loss: 0.3440633234504457
Validation loss: 2.6786786396278197

Epoch: 5| Step: 6
Training loss: 0.5433466028814464
Validation loss: 2.7008013210225794

Epoch: 5| Step: 7
Training loss: 0.34845764503918863
Validation loss: 2.8607436276409635

Epoch: 5| Step: 8
Training loss: 0.7952484659673626
Validation loss: 2.785388585512352

Epoch: 5| Step: 9
Training loss: 1.269236275076317
Validation loss: 2.8562561459409115

Epoch: 5| Step: 10
Training loss: 0.4248198057093404
Validation loss: 2.749006221846072

Epoch: 5| Step: 11
Training loss: 0.3022544378999222
Validation loss: 2.7670965500339664

Epoch: 309| Step: 0
Training loss: 0.58768066509702
Validation loss: 2.827612400142487

Epoch: 5| Step: 1
Training loss: 0.7126295892085578
Validation loss: 2.8001543067806325

Epoch: 5| Step: 2
Training loss: 0.35251055150438887
Validation loss: 2.8644469292271655

Epoch: 5| Step: 3
Training loss: 0.5634191209415867
Validation loss: 2.8293257951344652

Epoch: 5| Step: 4
Training loss: 0.5507795726128325
Validation loss: 2.8307071405353383

Epoch: 5| Step: 5
Training loss: 0.4171955407900064
Validation loss: 2.81432674564541

Epoch: 5| Step: 6
Training loss: 1.2145609143098142
Validation loss: 2.8419408982388945

Epoch: 5| Step: 7
Training loss: 0.539152497228701
Validation loss: 2.7009104622661564

Epoch: 5| Step: 8
Training loss: 0.44203138392565394
Validation loss: 2.8295981678306794

Epoch: 5| Step: 9
Training loss: 0.5286903988950041
Validation loss: 2.8754184148912394

Epoch: 5| Step: 10
Training loss: 0.542158826350129
Validation loss: 2.7628385655684067

Epoch: 5| Step: 11
Training loss: 0.4189399416563693
Validation loss: 2.8346771963764423

Epoch: 310| Step: 0
Training loss: 0.587796377947545
Validation loss: 2.8239257153961113

Epoch: 5| Step: 1
Training loss: 0.45463866597535
Validation loss: 2.653590894635154

Epoch: 5| Step: 2
Training loss: 0.4651206818482444
Validation loss: 2.826664932360282

Epoch: 5| Step: 3
Training loss: 0.519551929263095
Validation loss: 2.7934568481054067

Epoch: 5| Step: 4
Training loss: 0.41771629766670587
Validation loss: 2.83879637435779

Epoch: 5| Step: 5
Training loss: 0.46422344781892527
Validation loss: 2.722067672181886

Epoch: 5| Step: 6
Training loss: 0.37498509854273493
Validation loss: 2.725142682201409

Epoch: 5| Step: 7
Training loss: 1.2723369874696042
Validation loss: 2.767134310273801

Epoch: 5| Step: 8
Training loss: 0.380180771582065
Validation loss: 2.856966254830477

Epoch: 5| Step: 9
Training loss: 0.5010429472189841
Validation loss: 2.7380465063601935

Epoch: 5| Step: 10
Training loss: 0.6126447886003196
Validation loss: 2.7612689963614514

Epoch: 5| Step: 11
Training loss: 0.7991054585127801
Validation loss: 2.7375867781972225

Epoch: 311| Step: 0
Training loss: 0.5055254861630772
Validation loss: 2.771468764895816

Epoch: 5| Step: 1
Training loss: 0.4819006169408414
Validation loss: 2.8295085922744847

Epoch: 5| Step: 2
Training loss: 0.598916439305111
Validation loss: 2.776655513369709

Epoch: 5| Step: 3
Training loss: 0.508815391283966
Validation loss: 2.822480982183376

Epoch: 5| Step: 4
Training loss: 0.7750639335348983
Validation loss: 2.8458013332144696

Epoch: 5| Step: 5
Training loss: 0.34439730386802925
Validation loss: 2.7567989731104445

Epoch: 5| Step: 6
Training loss: 1.1553095524125783
Validation loss: 2.8136752251668624

Epoch: 5| Step: 7
Training loss: 0.5265436672838706
Validation loss: 2.7412510728406336

Epoch: 5| Step: 8
Training loss: 0.4222063599954512
Validation loss: 2.7275211248503415

Epoch: 5| Step: 9
Training loss: 0.5979982781178107
Validation loss: 2.7821125539618476

Epoch: 5| Step: 10
Training loss: 0.6686102034721065
Validation loss: 2.7760097163057362

Epoch: 5| Step: 11
Training loss: 0.7844576408348188
Validation loss: 2.8452747505165514

Epoch: 312| Step: 0
Training loss: 0.5538331288872953
Validation loss: 2.7010999197856425

Epoch: 5| Step: 1
Training loss: 0.4837962969723015
Validation loss: 2.849952264017906

Epoch: 5| Step: 2
Training loss: 0.4422701593249828
Validation loss: 2.7559341611566928

Epoch: 5| Step: 3
Training loss: 1.2989152233777934
Validation loss: 2.7733927261965055

Epoch: 5| Step: 4
Training loss: 0.6096018344559939
Validation loss: 2.7241327814632186

Epoch: 5| Step: 5
Training loss: 0.4648038702775744
Validation loss: 2.8222568815419278

Epoch: 5| Step: 6
Training loss: 0.5971472074528813
Validation loss: 2.8067549697919416

Epoch: 5| Step: 7
Training loss: 0.33073999982898566
Validation loss: 2.8076537623580107

Epoch: 5| Step: 8
Training loss: 0.7003061800003
Validation loss: 2.7873496308702967

Epoch: 5| Step: 9
Training loss: 0.4997974521937618
Validation loss: 2.863169287573812

Epoch: 5| Step: 10
Training loss: 0.46048504233945375
Validation loss: 2.922542189855641

Epoch: 5| Step: 11
Training loss: 0.7058481887918987
Validation loss: 2.823062556298757

Epoch: 313| Step: 0
Training loss: 0.5834407764214095
Validation loss: 2.847297237669256

Epoch: 5| Step: 1
Training loss: 0.6031515510921145
Validation loss: 2.8673253385723134

Epoch: 5| Step: 2
Training loss: 0.5308615723059893
Validation loss: 2.853013227877129

Epoch: 5| Step: 3
Training loss: 0.5003964223533308
Validation loss: 2.8257475321077004

Epoch: 5| Step: 4
Training loss: 0.43329861193103786
Validation loss: 2.8197808297302167

Epoch: 5| Step: 5
Training loss: 0.49659634459805974
Validation loss: 2.759317651932513

Epoch: 5| Step: 6
Training loss: 0.3992480466958493
Validation loss: 2.7953861543160805

Epoch: 5| Step: 7
Training loss: 1.2911333039129638
Validation loss: 2.8751792471749775

Epoch: 5| Step: 8
Training loss: 0.6269667674449071
Validation loss: 2.833856388271821

Epoch: 5| Step: 9
Training loss: 0.5435831723852103
Validation loss: 2.836435451174781

Epoch: 5| Step: 10
Training loss: 0.7230449971195774
Validation loss: 2.766622859012439

Epoch: 5| Step: 11
Training loss: 0.5011440539944617
Validation loss: 2.7999269609348243

Epoch: 314| Step: 0
Training loss: 0.658565025562962
Validation loss: 2.8326775560958275

Epoch: 5| Step: 1
Training loss: 0.33808705788641036
Validation loss: 2.8040200539947464

Epoch: 5| Step: 2
Training loss: 0.4597114971906833
Validation loss: 2.763548119675605

Epoch: 5| Step: 3
Training loss: 0.4020141065955014
Validation loss: 2.770536856218381

Epoch: 5| Step: 4
Training loss: 0.6403058350245495
Validation loss: 2.7686797977729807

Epoch: 5| Step: 5
Training loss: 0.4847641888765492
Validation loss: 2.783593376417311

Epoch: 5| Step: 6
Training loss: 0.7090209447083318
Validation loss: 2.7928812826905727

Epoch: 5| Step: 7
Training loss: 0.49780571278592656
Validation loss: 2.800300372423508

Epoch: 5| Step: 8
Training loss: 1.197190349259816
Validation loss: 2.7517495478246183

Epoch: 5| Step: 9
Training loss: 0.45831852766167547
Validation loss: 2.7538592287202177

Epoch: 5| Step: 10
Training loss: 0.385761134973984
Validation loss: 2.7928739020330595

Epoch: 5| Step: 11
Training loss: 0.13183737153580238
Validation loss: 2.7839973824432094

Epoch: 315| Step: 0
Training loss: 0.5766467707386191
Validation loss: 2.8272433724547907

Epoch: 5| Step: 1
Training loss: 0.4443080683760984
Validation loss: 2.8004131492006534

Epoch: 5| Step: 2
Training loss: 0.4427920505429525
Validation loss: 2.7723762810119332

Epoch: 5| Step: 3
Training loss: 0.48139034057993113
Validation loss: 2.776781228172406

Epoch: 5| Step: 4
Training loss: 0.4202334290618093
Validation loss: 2.745623458304965

Epoch: 5| Step: 5
Training loss: 0.6120509058250454
Validation loss: 2.8320006480701156

Epoch: 5| Step: 6
Training loss: 0.4202992185458321
Validation loss: 2.780556899586049

Epoch: 5| Step: 7
Training loss: 1.1952900105274296
Validation loss: 2.803026013591696

Epoch: 5| Step: 8
Training loss: 0.5638605194701747
Validation loss: 2.7666278321248474

Epoch: 5| Step: 9
Training loss: 0.6143615829073785
Validation loss: 2.7618538132391777

Epoch: 5| Step: 10
Training loss: 0.44644506219651103
Validation loss: 2.8484697684313733

Epoch: 5| Step: 11
Training loss: 1.125640580801806
Validation loss: 2.791131029886428

Epoch: 316| Step: 0
Training loss: 0.5404045427247219
Validation loss: 2.8382698255554546

Epoch: 5| Step: 1
Training loss: 0.432584825945764
Validation loss: 2.7734032176589833

Epoch: 5| Step: 2
Training loss: 0.6721664506284615
Validation loss: 2.8429680821745653

Epoch: 5| Step: 3
Training loss: 0.36153710997378796
Validation loss: 2.823017242910939

Epoch: 5| Step: 4
Training loss: 1.324519390535964
Validation loss: 2.813904252757759

Epoch: 5| Step: 5
Training loss: 0.3937329439980179
Validation loss: 2.8471630351316546

Epoch: 5| Step: 6
Training loss: 0.361637457328763
Validation loss: 2.833537740673592

Epoch: 5| Step: 7
Training loss: 0.4656883388681194
Validation loss: 2.7850646886269868

Epoch: 5| Step: 8
Training loss: 0.557165574280496
Validation loss: 2.788625677612857

Epoch: 5| Step: 9
Training loss: 0.6071428105610741
Validation loss: 2.826800009647697

Epoch: 5| Step: 10
Training loss: 0.7986588426967235
Validation loss: 2.808200495622237

Epoch: 5| Step: 11
Training loss: 0.26038693576217065
Validation loss: 2.786010140473806

Epoch: 317| Step: 0
Training loss: 0.3504840628433079
Validation loss: 2.8222346743038225

Epoch: 5| Step: 1
Training loss: 0.5656843386131746
Validation loss: 2.8472942301837567

Epoch: 5| Step: 2
Training loss: 0.6207177805625813
Validation loss: 2.9163112537367772

Epoch: 5| Step: 3
Training loss: 0.5697457096830479
Validation loss: 2.8325288567808458

Epoch: 5| Step: 4
Training loss: 0.5943186446227365
Validation loss: 2.8001746137418566

Epoch: 5| Step: 5
Training loss: 1.1791014068032188
Validation loss: 2.7756144079716214

Epoch: 5| Step: 6
Training loss: 0.4784159342404657
Validation loss: 2.7603037193271254

Epoch: 5| Step: 7
Training loss: 0.5318823024728092
Validation loss: 2.916749089075523

Epoch: 5| Step: 8
Training loss: 0.5529817492662076
Validation loss: 2.778848161037527

Epoch: 5| Step: 9
Training loss: 0.6112704021270796
Validation loss: 2.801287425760182

Epoch: 5| Step: 10
Training loss: 0.49537814334100233
Validation loss: 2.825954925428264

Epoch: 5| Step: 11
Training loss: 0.5876414128818863
Validation loss: 2.7752980971387697

Epoch: 318| Step: 0
Training loss: 0.4043657548251437
Validation loss: 2.790465563882597

Epoch: 5| Step: 1
Training loss: 0.6328389903987713
Validation loss: 2.808516043700903

Epoch: 5| Step: 2
Training loss: 0.5286281908470725
Validation loss: 2.802387037918628

Epoch: 5| Step: 3
Training loss: 0.6249442314062393
Validation loss: 2.7752391246775807

Epoch: 5| Step: 4
Training loss: 0.30503561234107596
Validation loss: 2.7580353860237885

Epoch: 5| Step: 5
Training loss: 0.4661682716666369
Validation loss: 2.8027443773753538

Epoch: 5| Step: 6
Training loss: 0.500420750970025
Validation loss: 2.802097396153516

Epoch: 5| Step: 7
Training loss: 0.5593095474736437
Validation loss: 2.764267255905805

Epoch: 5| Step: 8
Training loss: 1.3052381621187277
Validation loss: 2.895505925521536

Epoch: 5| Step: 9
Training loss: 0.54618950524111
Validation loss: 2.8164259212828053

Epoch: 5| Step: 10
Training loss: 0.5520975063112196
Validation loss: 2.785748490564884

Epoch: 5| Step: 11
Training loss: 0.28701487432707007
Validation loss: 2.7479938392609435

Epoch: 319| Step: 0
Training loss: 0.34872976926350474
Validation loss: 2.8487841025756886

Epoch: 5| Step: 1
Training loss: 0.495229569120087
Validation loss: 2.86192946988185

Epoch: 5| Step: 2
Training loss: 0.47288491888934797
Validation loss: 2.8024443969292316

Epoch: 5| Step: 3
Training loss: 1.1883003649657036
Validation loss: 2.766752394004892

Epoch: 5| Step: 4
Training loss: 0.797956742225654
Validation loss: 2.7748444619564414

Epoch: 5| Step: 5
Training loss: 0.45560470698079497
Validation loss: 2.781740523954504

Epoch: 5| Step: 6
Training loss: 0.549315917968533
Validation loss: 2.878303968627303

Epoch: 5| Step: 7
Training loss: 0.4330269829511677
Validation loss: 2.8359759654789642

Epoch: 5| Step: 8
Training loss: 0.5963500465572796
Validation loss: 2.8400950226647335

Epoch: 5| Step: 9
Training loss: 0.4172557560664821
Validation loss: 2.8224066148012197

Epoch: 5| Step: 10
Training loss: 0.5039935664738919
Validation loss: 2.808749368359402

Epoch: 5| Step: 11
Training loss: 0.6166116949873495
Validation loss: 2.8140000546262653

Epoch: 320| Step: 0
Training loss: 0.8164411108431661
Validation loss: 2.832493188826836

Epoch: 5| Step: 1
Training loss: 0.48196023019075657
Validation loss: 2.7195915987689765

Epoch: 5| Step: 2
Training loss: 0.3531121116581763
Validation loss: 2.784835422436854

Epoch: 5| Step: 3
Training loss: 0.4950777899662887
Validation loss: 2.7958397041358127

Epoch: 5| Step: 4
Training loss: 0.5193259902121966
Validation loss: 2.8332031280855587

Epoch: 5| Step: 5
Training loss: 0.5010332815323846
Validation loss: 2.845830763950184

Epoch: 5| Step: 6
Training loss: 1.176840574274575
Validation loss: 2.754557784544864

Epoch: 5| Step: 7
Training loss: 0.3617859697603274
Validation loss: 2.7671582341598615

Epoch: 5| Step: 8
Training loss: 0.4245525795889327
Validation loss: 2.7685652224134514

Epoch: 5| Step: 9
Training loss: 0.4559379607963717
Validation loss: 2.750860274744484

Epoch: 5| Step: 10
Training loss: 0.3865606389351701
Validation loss: 2.7743944872109947

Epoch: 5| Step: 11
Training loss: 0.3767592371255648
Validation loss: 2.8106886611672213

Epoch: 321| Step: 0
Training loss: 0.44879895373599005
Validation loss: 2.7989158394790046

Epoch: 5| Step: 1
Training loss: 0.4104675564786696
Validation loss: 2.81125373425652

Epoch: 5| Step: 2
Training loss: 0.4032100499058683
Validation loss: 2.796761057573281

Epoch: 5| Step: 3
Training loss: 0.6225761620529733
Validation loss: 2.7957666783315607

Epoch: 5| Step: 4
Training loss: 0.39887477217129497
Validation loss: 2.786699011322548

Epoch: 5| Step: 5
Training loss: 0.3548490341310443
Validation loss: 2.844346528838061

Epoch: 5| Step: 6
Training loss: 1.2690736855711648
Validation loss: 2.756165575535161

Epoch: 5| Step: 7
Training loss: 0.6423121078518225
Validation loss: 2.7915986335112897

Epoch: 5| Step: 8
Training loss: 0.40110926450616624
Validation loss: 2.7798611534331052

Epoch: 5| Step: 9
Training loss: 0.6023465781139276
Validation loss: 2.7754961745835316

Epoch: 5| Step: 10
Training loss: 0.5543610055182809
Validation loss: 2.84417413685605

Epoch: 5| Step: 11
Training loss: 0.7465999942911364
Validation loss: 2.892619398648133

Epoch: 322| Step: 0
Training loss: 0.58281122979647
Validation loss: 2.8064325087797233

Epoch: 5| Step: 1
Training loss: 0.5235217297096608
Validation loss: 2.78988016432904

Epoch: 5| Step: 2
Training loss: 0.5698451648775134
Validation loss: 2.8207325961514758

Epoch: 5| Step: 3
Training loss: 0.6267981887417533
Validation loss: 2.7907430428047992

Epoch: 5| Step: 4
Training loss: 0.48616158265025394
Validation loss: 2.8077804102237653

Epoch: 5| Step: 5
Training loss: 0.4998704772319168
Validation loss: 2.930077583622481

Epoch: 5| Step: 6
Training loss: 0.6670532645414781
Validation loss: 2.783601138561663

Epoch: 5| Step: 7
Training loss: 0.759267452457678
Validation loss: 2.8838807687926984

Epoch: 5| Step: 8
Training loss: 0.49753975575193554
Validation loss: 2.911527289368418

Epoch: 5| Step: 9
Training loss: 0.6792898220509943
Validation loss: 2.8309362254469925

Epoch: 5| Step: 10
Training loss: 1.1760770102574454
Validation loss: 2.7547283451588456

Epoch: 5| Step: 11
Training loss: 0.43908282467101983
Validation loss: 2.7915264148971275

Epoch: 323| Step: 0
Training loss: 0.5396397582000594
Validation loss: 2.7494102011720307

Epoch: 5| Step: 1
Training loss: 0.5968157773820248
Validation loss: 2.77462945317082

Epoch: 5| Step: 2
Training loss: 0.5653502782426073
Validation loss: 2.8489589563307467

Epoch: 5| Step: 3
Training loss: 0.3786370609147032
Validation loss: 2.8424023170092947

Epoch: 5| Step: 4
Training loss: 0.5498449605552831
Validation loss: 2.7863720758700086

Epoch: 5| Step: 5
Training loss: 0.4302431848308748
Validation loss: 2.786821980975484

Epoch: 5| Step: 6
Training loss: 1.2545195888785494
Validation loss: 2.7890059984540896

Epoch: 5| Step: 7
Training loss: 0.46848577363898625
Validation loss: 2.820857586232838

Epoch: 5| Step: 8
Training loss: 0.3774722186659584
Validation loss: 2.785141686699713

Epoch: 5| Step: 9
Training loss: 0.5798232677874803
Validation loss: 2.8337236911543524

Epoch: 5| Step: 10
Training loss: 0.6409052956691331
Validation loss: 2.7734398891098406

Epoch: 5| Step: 11
Training loss: 0.3823813131484014
Validation loss: 2.766262620315918

Epoch: 324| Step: 0
Training loss: 0.5059004071064548
Validation loss: 2.7923890781628016

Epoch: 5| Step: 1
Training loss: 0.4524446509953225
Validation loss: 2.8435803177622145

Epoch: 5| Step: 2
Training loss: 0.5194645028511249
Validation loss: 2.7997060651277534

Epoch: 5| Step: 3
Training loss: 0.74015477540101
Validation loss: 2.801381198075223

Epoch: 5| Step: 4
Training loss: 0.46140598476672273
Validation loss: 2.821228815432162

Epoch: 5| Step: 5
Training loss: 0.6352178283345419
Validation loss: 2.742147045072562

Epoch: 5| Step: 6
Training loss: 0.5659709968111571
Validation loss: 2.857819497148733

Epoch: 5| Step: 7
Training loss: 0.45749624349792484
Validation loss: 2.7552986647010593

Epoch: 5| Step: 8
Training loss: 0.42009183416119134
Validation loss: 2.7744561093384807

Epoch: 5| Step: 9
Training loss: 0.4984158663703673
Validation loss: 2.820067084176226

Epoch: 5| Step: 10
Training loss: 1.2400018428973378
Validation loss: 2.7897271825515513

Epoch: 5| Step: 11
Training loss: 0.41607943121653385
Validation loss: 2.8857341906097336

Epoch: 325| Step: 0
Training loss: 0.6307612481582807
Validation loss: 2.7893323402695533

Epoch: 5| Step: 1
Training loss: 0.549175301972582
Validation loss: 2.847669699959373

Epoch: 5| Step: 2
Training loss: 0.6561659350366497
Validation loss: 2.878345840408889

Epoch: 5| Step: 3
Training loss: 0.4267988207076368
Validation loss: 2.7705790013393696

Epoch: 5| Step: 4
Training loss: 0.3886832997545523
Validation loss: 2.8319023857176067

Epoch: 5| Step: 5
Training loss: 0.46504844838699627
Validation loss: 2.8008209857046147

Epoch: 5| Step: 6
Training loss: 0.5120357958138151
Validation loss: 2.7983932068466593

Epoch: 5| Step: 7
Training loss: 1.2010805172797336
Validation loss: 2.8173550803297807

Epoch: 5| Step: 8
Training loss: 0.40959454175075555
Validation loss: 2.8457546260016087

Epoch: 5| Step: 9
Training loss: 0.4272074829093594
Validation loss: 2.8564864891975135

Epoch: 5| Step: 10
Training loss: 0.5593297684352804
Validation loss: 2.7898250182174658

Epoch: 5| Step: 11
Training loss: 0.4434408541519597
Validation loss: 2.866260309351933

Epoch: 326| Step: 0
Training loss: 0.40546831707940484
Validation loss: 2.7770391154984075

Epoch: 5| Step: 1
Training loss: 0.5133080299858154
Validation loss: 2.8370348346016163

Epoch: 5| Step: 2
Training loss: 0.6007895767964309
Validation loss: 2.8518346369234315

Epoch: 5| Step: 3
Training loss: 0.3539076259830496
Validation loss: 2.7837531330460434

Epoch: 5| Step: 4
Training loss: 1.2718462216732307
Validation loss: 2.862080702688604

Epoch: 5| Step: 5
Training loss: 0.43247887184927725
Validation loss: 2.855326407625075

Epoch: 5| Step: 6
Training loss: 0.5574255244797891
Validation loss: 2.8510955567586866

Epoch: 5| Step: 7
Training loss: 0.39875029459257816
Validation loss: 2.8893840772434074

Epoch: 5| Step: 8
Training loss: 0.45424418516956355
Validation loss: 2.840765788076427

Epoch: 5| Step: 9
Training loss: 0.4649083389160424
Validation loss: 2.880914299220426

Epoch: 5| Step: 10
Training loss: 0.6073217278745501
Validation loss: 2.7784153784034036

Epoch: 5| Step: 11
Training loss: 0.30639305568767594
Validation loss: 2.8062821285161625

Epoch: 327| Step: 0
Training loss: 0.5679286622562203
Validation loss: 2.838823340669713

Epoch: 5| Step: 1
Training loss: 0.47721377412201416
Validation loss: 2.839770134658645

Epoch: 5| Step: 2
Training loss: 0.6029769073274592
Validation loss: 2.814857067422864

Epoch: 5| Step: 3
Training loss: 0.6264125597001577
Validation loss: 2.7978767469336736

Epoch: 5| Step: 4
Training loss: 0.5427801779005559
Validation loss: 2.830355037237447

Epoch: 5| Step: 5
Training loss: 0.45209839051598677
Validation loss: 2.744477561094717

Epoch: 5| Step: 6
Training loss: 0.5384801400293744
Validation loss: 2.8050641309067434

Epoch: 5| Step: 7
Training loss: 0.45385596083743956
Validation loss: 2.8188802758087235

Epoch: 5| Step: 8
Training loss: 1.1604409944094713
Validation loss: 2.8689161073885057

Epoch: 5| Step: 9
Training loss: 0.41899435827740605
Validation loss: 2.766859662599624

Epoch: 5| Step: 10
Training loss: 0.6902404266765693
Validation loss: 2.809953402028783

Epoch: 5| Step: 11
Training loss: 0.5624277545310586
Validation loss: 2.817742625443273

Epoch: 328| Step: 0
Training loss: 0.43214859567387776
Validation loss: 2.789449314110733

Epoch: 5| Step: 1
Training loss: 1.214578286755363
Validation loss: 2.832730686151641

Epoch: 5| Step: 2
Training loss: 0.5275204115349024
Validation loss: 2.851539496760145

Epoch: 5| Step: 3
Training loss: 0.4290715571292882
Validation loss: 2.8922766769457824

Epoch: 5| Step: 4
Training loss: 0.48264462042987494
Validation loss: 2.900104745803815

Epoch: 5| Step: 5
Training loss: 0.5020224081828604
Validation loss: 2.8465358377167647

Epoch: 5| Step: 6
Training loss: 0.42850066917839014
Validation loss: 2.762713345392048

Epoch: 5| Step: 7
Training loss: 0.7387108335101067
Validation loss: 2.8223911948247173

Epoch: 5| Step: 8
Training loss: 0.6796697855427742
Validation loss: 2.8205940620297287

Epoch: 5| Step: 9
Training loss: 0.41000950322535185
Validation loss: 2.8185882827878044

Epoch: 5| Step: 10
Training loss: 0.6025349572040303
Validation loss: 2.8172161403391343

Epoch: 5| Step: 11
Training loss: 0.6523780356894049
Validation loss: 2.8067758554590774

Epoch: 329| Step: 0
Training loss: 0.5477723797100588
Validation loss: 2.761197711402871

Epoch: 5| Step: 1
Training loss: 0.4686427629512551
Validation loss: 2.826512163120653

Epoch: 5| Step: 2
Training loss: 0.5017757176478344
Validation loss: 2.827630307117787

Epoch: 5| Step: 3
Training loss: 0.5747239362358116
Validation loss: 2.8244323825543196

Epoch: 5| Step: 4
Training loss: 0.6779421177380885
Validation loss: 2.8733438199627095

Epoch: 5| Step: 5
Training loss: 0.48004441790899766
Validation loss: 2.78587338139691

Epoch: 5| Step: 6
Training loss: 0.3591270835569057
Validation loss: 2.741957137674114

Epoch: 5| Step: 7
Training loss: 1.1209977271663552
Validation loss: 2.8158332111234055

Epoch: 5| Step: 8
Training loss: 0.5137435805019446
Validation loss: 2.7843508418583958

Epoch: 5| Step: 9
Training loss: 0.537638150802658
Validation loss: 2.7577068319420097

Epoch: 5| Step: 10
Training loss: 0.36872248708598176
Validation loss: 2.8419473929378474

Epoch: 5| Step: 11
Training loss: 0.4270626349977213
Validation loss: 2.841019276505111

Epoch: 330| Step: 0
Training loss: 0.4284633538523524
Validation loss: 2.7954682803045654

Epoch: 5| Step: 1
Training loss: 0.5654813910845098
Validation loss: 2.8563098147171884

Epoch: 5| Step: 2
Training loss: 0.6613060007377142
Validation loss: 2.786958443988733

Epoch: 5| Step: 3
Training loss: 0.5794912124178159
Validation loss: 2.794768305446388

Epoch: 5| Step: 4
Training loss: 0.5798301552093957
Validation loss: 2.769838629031921

Epoch: 5| Step: 5
Training loss: 1.137503127209064
Validation loss: 2.780062521985015

Epoch: 5| Step: 6
Training loss: 0.5469040181771778
Validation loss: 2.7275173588394703

Epoch: 5| Step: 7
Training loss: 0.453239590855125
Validation loss: 2.779833297093747

Epoch: 5| Step: 8
Training loss: 0.5679343295784959
Validation loss: 2.7346988922115503

Epoch: 5| Step: 9
Training loss: 0.40218807653164984
Validation loss: 2.755681126536956

Epoch: 5| Step: 10
Training loss: 0.48267805579396705
Validation loss: 2.7742828155485317

Epoch: 5| Step: 11
Training loss: 0.2135272961332383
Validation loss: 2.8222059936559547

Epoch: 331| Step: 0
Training loss: 0.5993104866957535
Validation loss: 2.8311976536732

Epoch: 5| Step: 1
Training loss: 0.49132095227349004
Validation loss: 2.812344963604306

Epoch: 5| Step: 2
Training loss: 0.40649579022047044
Validation loss: 2.815218374715777

Epoch: 5| Step: 3
Training loss: 0.6287216721252614
Validation loss: 2.890471133011812

Epoch: 5| Step: 4
Training loss: 0.4100618889665579
Validation loss: 2.788418903054396

Epoch: 5| Step: 5
Training loss: 0.5763337764537881
Validation loss: 2.800174361856971

Epoch: 5| Step: 6
Training loss: 0.5600499465926692
Validation loss: 2.853052716629565

Epoch: 5| Step: 7
Training loss: 0.4560250184825331
Validation loss: 2.812600833356856

Epoch: 5| Step: 8
Training loss: 1.1119111849561505
Validation loss: 2.767014142031892

Epoch: 5| Step: 9
Training loss: 0.3395901972812237
Validation loss: 2.7361112985648552

Epoch: 5| Step: 10
Training loss: 0.582009743926815
Validation loss: 2.834418051777189

Epoch: 5| Step: 11
Training loss: 0.18218375599647252
Validation loss: 2.8002975627902504

Epoch: 332| Step: 0
Training loss: 0.6356932918654911
Validation loss: 2.7893352286155797

Epoch: 5| Step: 1
Training loss: 0.43941702800424554
Validation loss: 2.865000466695662

Epoch: 5| Step: 2
Training loss: 0.5647157896098426
Validation loss: 2.8174937102443076

Epoch: 5| Step: 3
Training loss: 0.4537841507904541
Validation loss: 2.7714922785898306

Epoch: 5| Step: 4
Training loss: 0.36981126124445485
Validation loss: 2.821824972385872

Epoch: 5| Step: 5
Training loss: 0.36257846081814116
Validation loss: 2.741856699061398

Epoch: 5| Step: 6
Training loss: 1.202156221812353
Validation loss: 2.789607289567282

Epoch: 5| Step: 7
Training loss: 0.44706280036637797
Validation loss: 2.758670954243782

Epoch: 5| Step: 8
Training loss: 0.580578187096291
Validation loss: 2.785193729728059

Epoch: 5| Step: 9
Training loss: 0.38583948381079375
Validation loss: 2.7961108266602626

Epoch: 5| Step: 10
Training loss: 0.44095875835473314
Validation loss: 2.788604253456773

Epoch: 5| Step: 11
Training loss: 0.5184430363171507
Validation loss: 2.872760965076001

Epoch: 333| Step: 0
Training loss: 0.5109060691941908
Validation loss: 2.8504393922052005

Epoch: 5| Step: 1
Training loss: 1.1940931695724706
Validation loss: 2.822152704182012

Epoch: 5| Step: 2
Training loss: 0.5346043379035003
Validation loss: 2.7576802792070407

Epoch: 5| Step: 3
Training loss: 0.5704788592447706
Validation loss: 2.811574999261485

Epoch: 5| Step: 4
Training loss: 0.37542366890651946
Validation loss: 2.7664945244855876

Epoch: 5| Step: 5
Training loss: 0.3744200752265031
Validation loss: 2.7918531879819515

Epoch: 5| Step: 6
Training loss: 0.433369140184879
Validation loss: 2.8649547763792524

Epoch: 5| Step: 7
Training loss: 0.5732933424523995
Validation loss: 2.807494651000129

Epoch: 5| Step: 8
Training loss: 0.3963691092877178
Validation loss: 2.8255769445704644

Epoch: 5| Step: 9
Training loss: 0.4345780275495816
Validation loss: 2.770161939367651

Epoch: 5| Step: 10
Training loss: 0.338031981783478
Validation loss: 2.7519558107188367

Epoch: 5| Step: 11
Training loss: 0.17604563222365047
Validation loss: 2.8193182703003523

Epoch: 334| Step: 0
Training loss: 0.5250765631115702
Validation loss: 2.8990097029467563

Epoch: 5| Step: 1
Training loss: 0.49567966751376846
Validation loss: 2.8101404464824538

Epoch: 5| Step: 2
Training loss: 0.6184342985373928
Validation loss: 2.7906838129274427

Epoch: 5| Step: 3
Training loss: 0.5175834799435544
Validation loss: 2.8037985948877244

Epoch: 5| Step: 4
Training loss: 0.3016734823270156
Validation loss: 2.663742329589264

Epoch: 5| Step: 5
Training loss: 0.39702041920462855
Validation loss: 2.7984600867789267

Epoch: 5| Step: 6
Training loss: 0.45371633617590074
Validation loss: 2.7637028884495507

Epoch: 5| Step: 7
Training loss: 1.1249445795607578
Validation loss: 2.8314738529683687

Epoch: 5| Step: 8
Training loss: 0.7113534318506137
Validation loss: 2.820439250419062

Epoch: 5| Step: 9
Training loss: 0.5411387004021162
Validation loss: 2.826102972344082

Epoch: 5| Step: 10
Training loss: 0.3745003789306476
Validation loss: 2.757418934923687

Epoch: 5| Step: 11
Training loss: 0.3825604134265751
Validation loss: 2.7394912375476923

Epoch: 335| Step: 0
Training loss: 1.137652298928698
Validation loss: 2.754305572056009

Epoch: 5| Step: 1
Training loss: 0.6775932274965815
Validation loss: 2.802471408182031

Epoch: 5| Step: 2
Training loss: 0.35927028789056725
Validation loss: 2.746364820693473

Epoch: 5| Step: 3
Training loss: 0.36730488463253197
Validation loss: 2.790897720156499

Epoch: 5| Step: 4
Training loss: 0.492587850113172
Validation loss: 2.835631792809916

Epoch: 5| Step: 5
Training loss: 0.4042277253949391
Validation loss: 2.8492834415941766

Epoch: 5| Step: 6
Training loss: 0.4797664254335138
Validation loss: 2.871973089038045

Epoch: 5| Step: 7
Training loss: 0.46296037880741453
Validation loss: 2.8976803293579274

Epoch: 5| Step: 8
Training loss: 0.5456385667824951
Validation loss: 2.8459663033779257

Epoch: 5| Step: 9
Training loss: 0.4789259260905532
Validation loss: 2.8222461844965987

Epoch: 5| Step: 10
Training loss: 0.42526819658453224
Validation loss: 2.8996840552894603

Epoch: 5| Step: 11
Training loss: 0.40805510981337545
Validation loss: 2.80603706101377

Epoch: 336| Step: 0
Training loss: 0.30639801632927527
Validation loss: 2.74470017996709

Epoch: 5| Step: 1
Training loss: 0.48827291863009425
Validation loss: 2.8489716731194448

Epoch: 5| Step: 2
Training loss: 0.3828393771020148
Validation loss: 2.7698148699665217

Epoch: 5| Step: 3
Training loss: 0.47970480002355004
Validation loss: 2.784087191262532

Epoch: 5| Step: 4
Training loss: 0.6592232244737107
Validation loss: 2.8645062915961295

Epoch: 5| Step: 5
Training loss: 0.6253471840728949
Validation loss: 2.870841688652411

Epoch: 5| Step: 6
Training loss: 0.5113837914877889
Validation loss: 2.847171559051045

Epoch: 5| Step: 7
Training loss: 0.5333529251443982
Validation loss: 2.8213800151773

Epoch: 5| Step: 8
Training loss: 0.5081706617983802
Validation loss: 2.7502708084973992

Epoch: 5| Step: 9
Training loss: 0.4945362603052774
Validation loss: 2.753565373528032

Epoch: 5| Step: 10
Training loss: 1.2088524865113164
Validation loss: 2.744016282057626

Epoch: 5| Step: 11
Training loss: 0.8216374913491665
Validation loss: 2.693600576258489

Epoch: 337| Step: 0
Training loss: 1.117632903830233
Validation loss: 2.772590547286394

Epoch: 5| Step: 1
Training loss: 0.5151565620252493
Validation loss: 2.7827873838570323

Epoch: 5| Step: 2
Training loss: 0.5754142564736434
Validation loss: 2.797243939295107

Epoch: 5| Step: 3
Training loss: 0.34995672350089047
Validation loss: 2.780378619501134

Epoch: 5| Step: 4
Training loss: 0.4936156065842351
Validation loss: 2.8986147494756063

Epoch: 5| Step: 5
Training loss: 0.5635049108716055
Validation loss: 2.7177797647087965

Epoch: 5| Step: 6
Training loss: 0.43838306271219907
Validation loss: 2.841221268465663

Epoch: 5| Step: 7
Training loss: 0.6361610919310708
Validation loss: 2.8879259585226165

Epoch: 5| Step: 8
Training loss: 0.555345547905061
Validation loss: 2.7361946409215596

Epoch: 5| Step: 9
Training loss: 0.37503649613486034
Validation loss: 2.8545374954252476

Epoch: 5| Step: 10
Training loss: 0.5063757598935285
Validation loss: 2.822251929015616

Epoch: 5| Step: 11
Training loss: 0.3155694775798741
Validation loss: 2.8742233277713245

Epoch: 338| Step: 0
Training loss: 0.4052313173765958
Validation loss: 2.788530546547842

Epoch: 5| Step: 1
Training loss: 0.30923732815486416
Validation loss: 2.8086399964127136

Epoch: 5| Step: 2
Training loss: 0.5970735389490024
Validation loss: 2.8227261986940086

Epoch: 5| Step: 3
Training loss: 1.082937804178858
Validation loss: 2.816578613311907

Epoch: 5| Step: 4
Training loss: 0.5208005100080012
Validation loss: 2.7971887004112292

Epoch: 5| Step: 5
Training loss: 0.5937985350196628
Validation loss: 2.7597098519245806

Epoch: 5| Step: 6
Training loss: 0.4563767074327336
Validation loss: 2.842674876559368

Epoch: 5| Step: 7
Training loss: 0.4544705440284118
Validation loss: 2.7613704413192077

Epoch: 5| Step: 8
Training loss: 0.2810389203492837
Validation loss: 2.8523543351470764

Epoch: 5| Step: 9
Training loss: 0.41709042894969445
Validation loss: 2.708041081188059

Epoch: 5| Step: 10
Training loss: 0.38922635500173
Validation loss: 2.8374561555698783

Epoch: 5| Step: 11
Training loss: 0.515948338709568
Validation loss: 2.8295268032280507

Epoch: 339| Step: 0
Training loss: 0.36962019835763243
Validation loss: 2.8027157808367127

Epoch: 5| Step: 1
Training loss: 0.46386127668931454
Validation loss: 2.8486551173412202

Epoch: 5| Step: 2
Training loss: 0.4090101305003128
Validation loss: 2.8327985999917797

Epoch: 5| Step: 3
Training loss: 0.38911535371317696
Validation loss: 2.8949114729523213

Epoch: 5| Step: 4
Training loss: 0.5022731903498503
Validation loss: 2.77174133048725

Epoch: 5| Step: 5
Training loss: 0.5416243671137979
Validation loss: 2.8032986381956375

Epoch: 5| Step: 6
Training loss: 0.5738723384684948
Validation loss: 2.8425781923788302

Epoch: 5| Step: 7
Training loss: 0.4510380269785472
Validation loss: 2.8606456025026015

Epoch: 5| Step: 8
Training loss: 1.1203733249470051
Validation loss: 2.8981697733463525

Epoch: 5| Step: 9
Training loss: 0.5199226109981702
Validation loss: 2.76331254220403

Epoch: 5| Step: 10
Training loss: 0.5843650572231835
Validation loss: 2.8429812345888434

Epoch: 5| Step: 11
Training loss: 0.40108050946804874
Validation loss: 2.7181095925616106

Epoch: 340| Step: 0
Training loss: 0.642111565400168
Validation loss: 2.7865964635439284

Epoch: 5| Step: 1
Training loss: 0.48975519112897387
Validation loss: 2.9121760209983676

Epoch: 5| Step: 2
Training loss: 0.570659584092073
Validation loss: 2.7759955630789155

Epoch: 5| Step: 3
Training loss: 0.45858698747318066
Validation loss: 2.7152475912026475

Epoch: 5| Step: 4
Training loss: 0.61610070646704
Validation loss: 2.727515417557174

Epoch: 5| Step: 5
Training loss: 0.3528844140405426
Validation loss: 2.7535705975093108

Epoch: 5| Step: 6
Training loss: 0.5121708103460855
Validation loss: 2.822757939360713

Epoch: 5| Step: 7
Training loss: 0.40022925870098497
Validation loss: 2.824746996597677

Epoch: 5| Step: 8
Training loss: 0.3903056746864193
Validation loss: 2.826624020619901

Epoch: 5| Step: 9
Training loss: 0.5568467946300338
Validation loss: 2.8761757782189425

Epoch: 5| Step: 10
Training loss: 1.0778760760882684
Validation loss: 2.809820230130983

Epoch: 5| Step: 11
Training loss: 0.5720294295706355
Validation loss: 2.7928111140797744

Epoch: 341| Step: 0
Training loss: 0.5241920953332909
Validation loss: 2.795889401951441

Epoch: 5| Step: 1
Training loss: 0.5063311464713668
Validation loss: 2.769688672181661

Epoch: 5| Step: 2
Training loss: 0.4908997628892321
Validation loss: 2.7085206125993917

Epoch: 5| Step: 3
Training loss: 0.28173132611818325
Validation loss: 2.796243198433683

Epoch: 5| Step: 4
Training loss: 0.494271995963795
Validation loss: 2.791447646293811

Epoch: 5| Step: 5
Training loss: 0.4492025621234114
Validation loss: 2.698768787998884

Epoch: 5| Step: 6
Training loss: 1.1445002633024073
Validation loss: 2.7522419438846706

Epoch: 5| Step: 7
Training loss: 0.5189656211660856
Validation loss: 2.839524252443209

Epoch: 5| Step: 8
Training loss: 0.6206944939773679
Validation loss: 2.7333010390068018

Epoch: 5| Step: 9
Training loss: 0.5419109661657548
Validation loss: 2.8208880061866823

Epoch: 5| Step: 10
Training loss: 0.42022736548673084
Validation loss: 2.829771019503308

Epoch: 5| Step: 11
Training loss: 0.49912895386025696
Validation loss: 2.813466838381592

Epoch: 342| Step: 0
Training loss: 0.3842771110873263
Validation loss: 2.7951097689599838

Epoch: 5| Step: 1
Training loss: 0.37728161902541146
Validation loss: 2.813225412419355

Epoch: 5| Step: 2
Training loss: 0.5930174022311518
Validation loss: 2.7543541943011225

Epoch: 5| Step: 3
Training loss: 0.2792961414034086
Validation loss: 2.773890989237938

Epoch: 5| Step: 4
Training loss: 0.39490819618691586
Validation loss: 2.7350626271625003

Epoch: 5| Step: 5
Training loss: 0.34225882784031
Validation loss: 2.746796240923368

Epoch: 5| Step: 6
Training loss: 0.459583783874337
Validation loss: 2.730120842725398

Epoch: 5| Step: 7
Training loss: 1.2048602780581381
Validation loss: 2.8166343854055027

Epoch: 5| Step: 8
Training loss: 0.4369809955047906
Validation loss: 2.813689866741729

Epoch: 5| Step: 9
Training loss: 0.4125601305628458
Validation loss: 2.72666004811613

Epoch: 5| Step: 10
Training loss: 0.5064913657037103
Validation loss: 2.779313409773538

Epoch: 5| Step: 11
Training loss: 0.7603321463935058
Validation loss: 2.781781933311244

Epoch: 343| Step: 0
Training loss: 0.45341461068659267
Validation loss: 2.8154772717965293

Epoch: 5| Step: 1
Training loss: 0.537172931031973
Validation loss: 2.770575211388329

Epoch: 5| Step: 2
Training loss: 0.4200808556815401
Validation loss: 2.7873134239832726

Epoch: 5| Step: 3
Training loss: 0.5159518333121533
Validation loss: 2.790585071125705

Epoch: 5| Step: 4
Training loss: 0.38354024028288364
Validation loss: 2.757925713856584

Epoch: 5| Step: 5
Training loss: 0.4580912564849493
Validation loss: 2.8092761495113847

Epoch: 5| Step: 6
Training loss: 1.115160403495794
Validation loss: 2.7191244211012298

Epoch: 5| Step: 7
Training loss: 0.5035732558883009
Validation loss: 2.7379951853666844

Epoch: 5| Step: 8
Training loss: 0.4104394207696422
Validation loss: 2.748114889821945

Epoch: 5| Step: 9
Training loss: 0.4398251971707357
Validation loss: 2.714572770387753

Epoch: 5| Step: 10
Training loss: 0.5147722591146919
Validation loss: 2.716623640353534

Epoch: 5| Step: 11
Training loss: 0.1385624010182923
Validation loss: 2.8630937043890126

Epoch: 344| Step: 0
Training loss: 0.5908272230516565
Validation loss: 2.787796969339674

Epoch: 5| Step: 1
Training loss: 0.3668874366770857
Validation loss: 2.7683175839323115

Epoch: 5| Step: 2
Training loss: 0.6147510870745132
Validation loss: 2.712671379529247

Epoch: 5| Step: 3
Training loss: 0.4126216542866113
Validation loss: 2.791136717432939

Epoch: 5| Step: 4
Training loss: 0.5126478772699015
Validation loss: 2.8413519686923627

Epoch: 5| Step: 5
Training loss: 0.5356177685849259
Validation loss: 2.8117099994658576

Epoch: 5| Step: 6
Training loss: 1.2306778503042757
Validation loss: 2.8008507862264227

Epoch: 5| Step: 7
Training loss: 0.534382114028424
Validation loss: 2.7516005872104636

Epoch: 5| Step: 8
Training loss: 0.3968768502740457
Validation loss: 2.7438612790087538

Epoch: 5| Step: 9
Training loss: 0.5264380695693643
Validation loss: 2.782427138631022

Epoch: 5| Step: 10
Training loss: 0.5101682162086328
Validation loss: 2.7237492196004776

Epoch: 5| Step: 11
Training loss: 0.41614627129918025
Validation loss: 2.7731354204173657

Epoch: 345| Step: 0
Training loss: 0.40618125627340984
Validation loss: 2.7713797587390174

Epoch: 5| Step: 1
Training loss: 0.4499216634064627
Validation loss: 2.790141636849222

Epoch: 5| Step: 2
Training loss: 0.4431862177886081
Validation loss: 2.7864562607992194

Epoch: 5| Step: 3
Training loss: 0.28115350339437706
Validation loss: 2.8394707579534697

Epoch: 5| Step: 4
Training loss: 0.3738597980024482
Validation loss: 2.7635229998457906

Epoch: 5| Step: 5
Training loss: 0.4330781156037084
Validation loss: 2.8126830571259074

Epoch: 5| Step: 6
Training loss: 0.43285103498980454
Validation loss: 2.801541826803421

Epoch: 5| Step: 7
Training loss: 0.35110358909873757
Validation loss: 2.795067066088613

Epoch: 5| Step: 8
Training loss: 0.42523408431758614
Validation loss: 2.783206112508676

Epoch: 5| Step: 9
Training loss: 0.4507995158813588
Validation loss: 2.8050648852440796

Epoch: 5| Step: 10
Training loss: 1.1705729562704938
Validation loss: 2.7788104348496927

Epoch: 5| Step: 11
Training loss: 0.3433890940679849
Validation loss: 2.8463579452968877

Epoch: 346| Step: 0
Training loss: 0.44872329589955434
Validation loss: 2.739095478834942

Epoch: 5| Step: 1
Training loss: 0.47342298126620236
Validation loss: 2.7388573519851507

Epoch: 5| Step: 2
Training loss: 0.45892736202587425
Validation loss: 2.7654729610972657

Epoch: 5| Step: 3
Training loss: 0.6488207638097319
Validation loss: 2.814942503788589

Epoch: 5| Step: 4
Training loss: 0.3175547324899059
Validation loss: 2.838005408398388

Epoch: 5| Step: 5
Training loss: 0.5939656919917552
Validation loss: 2.771753926663149

Epoch: 5| Step: 6
Training loss: 0.5918069215431654
Validation loss: 2.7743949168877435

Epoch: 5| Step: 7
Training loss: 0.4068082678254288
Validation loss: 2.7934364940873224

Epoch: 5| Step: 8
Training loss: 0.38125599481215744
Validation loss: 2.8326126448949887

Epoch: 5| Step: 9
Training loss: 1.035673710305439
Validation loss: 2.7540742647038123

Epoch: 5| Step: 10
Training loss: 0.5255111499369336
Validation loss: 2.8274814442532485

Epoch: 5| Step: 11
Training loss: 0.5422600986126013
Validation loss: 2.8280328380819784

Epoch: 347| Step: 0
Training loss: 0.5967839675907762
Validation loss: 2.7443278582537745

Epoch: 5| Step: 1
Training loss: 0.5546360797957521
Validation loss: 2.7872546558435336

Epoch: 5| Step: 2
Training loss: 0.5289735827276774
Validation loss: 2.815567971180183

Epoch: 5| Step: 3
Training loss: 0.42686080562734835
Validation loss: 2.7328521884124997

Epoch: 5| Step: 4
Training loss: 0.3948124931230374
Validation loss: 2.742786620969345

Epoch: 5| Step: 5
Training loss: 0.37825376824407403
Validation loss: 2.8331612202783325

Epoch: 5| Step: 6
Training loss: 0.488739973121485
Validation loss: 2.8620468712464544

Epoch: 5| Step: 7
Training loss: 0.3725551740056946
Validation loss: 2.86315572133015

Epoch: 5| Step: 8
Training loss: 0.47009085568393716
Validation loss: 2.79879647144095

Epoch: 5| Step: 9
Training loss: 0.39746669230875864
Validation loss: 2.799444985587643

Epoch: 5| Step: 10
Training loss: 1.0895709171402215
Validation loss: 2.7136762894363486

Epoch: 5| Step: 11
Training loss: 0.5098742665245577
Validation loss: 2.8008015843375498

Epoch: 348| Step: 0
Training loss: 0.4716867955779925
Validation loss: 2.8148311032037503

Epoch: 5| Step: 1
Training loss: 0.512490978394166
Validation loss: 2.84710272845806

Epoch: 5| Step: 2
Training loss: 0.4067953374257416
Validation loss: 2.84875870213861

Epoch: 5| Step: 3
Training loss: 0.2983848924854744
Validation loss: 2.8562834378100064

Epoch: 5| Step: 4
Training loss: 0.6032283556043491
Validation loss: 2.814219966128021

Epoch: 5| Step: 5
Training loss: 0.4490212711316814
Validation loss: 2.807572944624233

Epoch: 5| Step: 6
Training loss: 0.4472398708874634
Validation loss: 2.8004002296416783

Epoch: 5| Step: 7
Training loss: 0.4895623300659944
Validation loss: 2.796144706245416

Epoch: 5| Step: 8
Training loss: 0.54191707056179
Validation loss: 2.775478536138348

Epoch: 5| Step: 9
Training loss: 1.1348661552191257
Validation loss: 2.8452866493208533

Epoch: 5| Step: 10
Training loss: 0.4074903406858917
Validation loss: 2.780070272547774

Epoch: 5| Step: 11
Training loss: 0.2189432125348155
Validation loss: 2.7783677099885726

Epoch: 349| Step: 0
Training loss: 0.4177805753279138
Validation loss: 2.7998994035758495

Epoch: 5| Step: 1
Training loss: 0.6805224935021951
Validation loss: 2.8352661809477193

Epoch: 5| Step: 2
Training loss: 1.108547170465623
Validation loss: 2.8036355371987143

Epoch: 5| Step: 3
Training loss: 0.5539704375745679
Validation loss: 2.7960690699331305

Epoch: 5| Step: 4
Training loss: 0.5441217598585304
Validation loss: 2.831333163810514

Epoch: 5| Step: 5
Training loss: 0.4246080316067863
Validation loss: 2.799380549386808

Epoch: 5| Step: 6
Training loss: 0.3486431024138797
Validation loss: 2.7940417382762006

Epoch: 5| Step: 7
Training loss: 0.4547751240671242
Validation loss: 2.8405513520270507

Epoch: 5| Step: 8
Training loss: 0.3797276236287079
Validation loss: 2.749568302053528

Epoch: 5| Step: 9
Training loss: 0.5604248711601123
Validation loss: 2.7915972919289547

Epoch: 5| Step: 10
Training loss: 0.5738235722744881
Validation loss: 2.7675995324490734

Epoch: 5| Step: 11
Training loss: 0.4589022461479797
Validation loss: 2.7939989088602926

Epoch: 350| Step: 0
Training loss: 0.5699417267676216
Validation loss: 2.8098401313660433

Epoch: 5| Step: 1
Training loss: 1.1179787028234196
Validation loss: 2.806804548664982

Epoch: 5| Step: 2
Training loss: 0.44320464269955484
Validation loss: 2.7736128738188444

Epoch: 5| Step: 3
Training loss: 0.5300085484517063
Validation loss: 2.751105722020831

Epoch: 5| Step: 4
Training loss: 0.45108255930736146
Validation loss: 2.7802718546302003

Epoch: 5| Step: 5
Training loss: 0.2849714516470753
Validation loss: 2.8191786624075523

Epoch: 5| Step: 6
Training loss: 0.4677910691922282
Validation loss: 2.7374127652800477

Epoch: 5| Step: 7
Training loss: 0.4658419686007843
Validation loss: 2.753365487468214

Epoch: 5| Step: 8
Training loss: 0.46884144844660375
Validation loss: 2.903712200324375

Epoch: 5| Step: 9
Training loss: 0.5031746573258573
Validation loss: 2.7711713532131172

Epoch: 5| Step: 10
Training loss: 0.3922493919990257
Validation loss: 2.7325603494555795

Epoch: 5| Step: 11
Training loss: 0.4621957480550305
Validation loss: 2.8096409959932456

Testing loss: 2.562228956746184
