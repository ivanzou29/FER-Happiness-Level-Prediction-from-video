Epoch: 1| Step: 0
Training loss: 4.959451287589647
Validation loss: 5.670240224428615

Epoch: 5| Step: 1
Training loss: 6.135744285795639
Validation loss: 5.655151197231852

Epoch: 5| Step: 2
Training loss: 6.173561503160132
Validation loss: 5.640549621360156

Epoch: 5| Step: 3
Training loss: 6.0872592886267505
Validation loss: 5.6267772480680645

Epoch: 5| Step: 4
Training loss: 6.187016015438538
Validation loss: 5.614094370238274

Epoch: 5| Step: 5
Training loss: 6.743734489472576
Validation loss: 5.601548667050018

Epoch: 5| Step: 6
Training loss: 4.923806432171571
Validation loss: 5.590415543253325

Epoch: 5| Step: 7
Training loss: 5.456539451376104
Validation loss: 5.578824495397537

Epoch: 5| Step: 8
Training loss: 5.60148128945446
Validation loss: 5.567678177278771

Epoch: 5| Step: 9
Training loss: 5.174462906981982
Validation loss: 5.556635254475748

Epoch: 5| Step: 10
Training loss: 5.326759319971691
Validation loss: 5.544879629653432

Epoch: 5| Step: 11
Training loss: 5.0101628969553795
Validation loss: 5.532650111236667

Epoch: 2| Step: 0
Training loss: 6.0694713034230725
Validation loss: 5.518901496556046

Epoch: 5| Step: 1
Training loss: 5.391701941789954
Validation loss: 5.506033795514575

Epoch: 5| Step: 2
Training loss: 4.983765759200378
Validation loss: 5.491121017639749

Epoch: 5| Step: 3
Training loss: 5.571977235516163
Validation loss: 5.47502965875544

Epoch: 5| Step: 4
Training loss: 5.383433800262758
Validation loss: 5.460046494487434

Epoch: 5| Step: 5
Training loss: 5.80575629723306
Validation loss: 5.444422893200387

Epoch: 5| Step: 6
Training loss: 6.252432082950146
Validation loss: 5.428063875775496

Epoch: 5| Step: 7
Training loss: 5.757526281895616
Validation loss: 5.412282242773795

Epoch: 5| Step: 8
Training loss: 4.785419316748468
Validation loss: 5.393179342671239

Epoch: 5| Step: 9
Training loss: 5.829994045143293
Validation loss: 5.375720448966217

Epoch: 5| Step: 10
Training loss: 5.3453948406265805
Validation loss: 5.3570690625270085

Epoch: 5| Step: 11
Training loss: 4.256628813389825
Validation loss: 5.33704071778796

Epoch: 3| Step: 0
Training loss: 4.787210377032717
Validation loss: 5.31712944424293

Epoch: 5| Step: 1
Training loss: 5.327004770776995
Validation loss: 5.295737610478839

Epoch: 5| Step: 2
Training loss: 5.982526448849319
Validation loss: 5.275808363711644

Epoch: 5| Step: 3
Training loss: 6.3639181718726565
Validation loss: 5.250961775708947

Epoch: 5| Step: 4
Training loss: 5.516955163947398
Validation loss: 5.227406789482882

Epoch: 5| Step: 5
Training loss: 4.350787273504876
Validation loss: 5.202491355093245

Epoch: 5| Step: 6
Training loss: 5.345443011231915
Validation loss: 5.175268682854829

Epoch: 5| Step: 7
Training loss: 5.635061801683196
Validation loss: 5.150462499547867

Epoch: 5| Step: 8
Training loss: 5.4284640244206015
Validation loss: 5.119659548891964

Epoch: 5| Step: 9
Training loss: 4.846168357352305
Validation loss: 5.088753463205452

Epoch: 5| Step: 10
Training loss: 4.752928383276223
Validation loss: 5.053451206087331

Epoch: 5| Step: 11
Training loss: 4.087030151614382
Validation loss: 5.0211594608910355

Epoch: 4| Step: 0
Training loss: 5.067993574227201
Validation loss: 4.99046674910236

Epoch: 5| Step: 1
Training loss: 5.381512621985192
Validation loss: 4.952783205772607

Epoch: 5| Step: 2
Training loss: 4.837306110922339
Validation loss: 4.916207609998559

Epoch: 5| Step: 3
Training loss: 5.955776635300374
Validation loss: 4.8784608864190595

Epoch: 5| Step: 4
Training loss: 4.634163722175843
Validation loss: 4.830864319534426

Epoch: 5| Step: 5
Training loss: 4.769030945427725
Validation loss: 4.790903763230416

Epoch: 5| Step: 6
Training loss: 4.677743753252603
Validation loss: 4.740940497739417

Epoch: 5| Step: 7
Training loss: 5.374589771318453
Validation loss: 4.692104705815168

Epoch: 5| Step: 8
Training loss: 4.507904316249724
Validation loss: 4.639334331123328

Epoch: 5| Step: 9
Training loss: 4.370244738885774
Validation loss: 4.589835590328241

Epoch: 5| Step: 10
Training loss: 4.093283124319627
Validation loss: 4.5342137257880415

Epoch: 5| Step: 11
Training loss: 4.108277613098835
Validation loss: 4.471391621786225

Epoch: 5| Step: 0
Training loss: 5.5026469363638455
Validation loss: 4.409835718184515

Epoch: 5| Step: 1
Training loss: 3.9640087733012863
Validation loss: 4.340425495261891

Epoch: 5| Step: 2
Training loss: 4.284023528147538
Validation loss: 4.27726630804134

Epoch: 5| Step: 3
Training loss: 4.20822435496014
Validation loss: 4.205468608079747

Epoch: 5| Step: 4
Training loss: 3.8332173012020676
Validation loss: 4.12546227494688

Epoch: 5| Step: 5
Training loss: 4.524166700656282
Validation loss: 4.047260300448363

Epoch: 5| Step: 6
Training loss: 3.8890280759214346
Validation loss: 3.9697440296772593

Epoch: 5| Step: 7
Training loss: 4.026199607498236
Validation loss: 3.884200668617174

Epoch: 5| Step: 8
Training loss: 3.6268624092552706
Validation loss: 3.7876615680775636

Epoch: 5| Step: 9
Training loss: 3.6148463143462646
Validation loss: 3.6922480301234533

Epoch: 5| Step: 10
Training loss: 3.5873747959951046
Validation loss: 3.6069578909538658

Epoch: 5| Step: 11
Training loss: 3.8853526719510305
Validation loss: 3.512689820406306

Epoch: 6| Step: 0
Training loss: 3.239595484736346
Validation loss: 3.4117283352687444

Epoch: 5| Step: 1
Training loss: 3.0231162203633075
Validation loss: 3.2983815726787227

Epoch: 5| Step: 2
Training loss: 3.147377308945612
Validation loss: 3.212218308375117

Epoch: 5| Step: 3
Training loss: 2.7870462433174907
Validation loss: 3.1124201293257125

Epoch: 5| Step: 4
Training loss: 3.1324888904127928
Validation loss: 3.0280052561617743

Epoch: 5| Step: 5
Training loss: 2.9442917246369498
Validation loss: 2.9242437420204332

Epoch: 5| Step: 6
Training loss: 2.9437709993880943
Validation loss: 2.8552803572308565

Epoch: 5| Step: 7
Training loss: 2.366653533236459
Validation loss: 2.7855745940326453

Epoch: 5| Step: 8
Training loss: 3.6917774800933514
Validation loss: 2.712270183759932

Epoch: 5| Step: 9
Training loss: 2.5156570337755646
Validation loss: 2.6455921090665866

Epoch: 5| Step: 10
Training loss: 2.5078533799116483
Validation loss: 2.634739873075462

Epoch: 5| Step: 11
Training loss: 3.196273398076877
Validation loss: 2.605077059241206

Epoch: 7| Step: 0
Training loss: 2.4887290563617013
Validation loss: 2.6112095823274983

Epoch: 5| Step: 1
Training loss: 2.727171209642266
Validation loss: 2.5842032634190266

Epoch: 5| Step: 2
Training loss: 2.827150461463006
Validation loss: 2.6514685024249207

Epoch: 5| Step: 3
Training loss: 2.536571043253215
Validation loss: 2.6647194866105095

Epoch: 5| Step: 4
Training loss: 2.291347990131015
Validation loss: 2.6546341188484956

Epoch: 5| Step: 5
Training loss: 2.0930318027637256
Validation loss: 2.6770178357633228

Epoch: 5| Step: 6
Training loss: 2.6228781707661604
Validation loss: 2.693784675094693

Epoch: 5| Step: 7
Training loss: 2.7074297546967734
Validation loss: 2.6918685693179114

Epoch: 5| Step: 8
Training loss: 3.062212716466025
Validation loss: 2.7014906762457787

Epoch: 5| Step: 9
Training loss: 2.7574153106217905
Validation loss: 2.7184253696127594

Epoch: 5| Step: 10
Training loss: 2.4409040499109302
Validation loss: 2.7289995816944397

Epoch: 5| Step: 11
Training loss: 3.657458896158288
Validation loss: 2.723471506256273

Epoch: 8| Step: 0
Training loss: 2.6720620251612037
Validation loss: 2.7210382427227815

Epoch: 5| Step: 1
Training loss: 2.1474310719771244
Validation loss: 2.712283825280758

Epoch: 5| Step: 2
Training loss: 2.4165006010503514
Validation loss: 2.6438752097381832

Epoch: 5| Step: 3
Training loss: 2.705212266811664
Validation loss: 2.640218741110132

Epoch: 5| Step: 4
Training loss: 2.0973443451188345
Validation loss: 2.655384528588478

Epoch: 5| Step: 5
Training loss: 2.4404636852373778
Validation loss: 2.621395827053995

Epoch: 5| Step: 6
Training loss: 2.232092164690146
Validation loss: 2.5990048992340267

Epoch: 5| Step: 7
Training loss: 2.671686712401211
Validation loss: 2.6012067389263027

Epoch: 5| Step: 8
Training loss: 3.456476164828472
Validation loss: 2.612871826974144

Epoch: 5| Step: 9
Training loss: 2.8261268258870715
Validation loss: 2.587060859137336

Epoch: 5| Step: 10
Training loss: 2.70926273733751
Validation loss: 2.6083127027575244

Epoch: 5| Step: 11
Training loss: 0.827589761757889
Validation loss: 2.6036657016823015

Epoch: 9| Step: 0
Training loss: 3.2586686361008272
Validation loss: 2.613002494234164

Epoch: 5| Step: 1
Training loss: 2.5548399900136123
Validation loss: 2.6028289881542115

Epoch: 5| Step: 2
Training loss: 2.6106088428029293
Validation loss: 2.578425911961448

Epoch: 5| Step: 3
Training loss: 2.4345836310054874
Validation loss: 2.6020094379737193

Epoch: 5| Step: 4
Training loss: 2.3661130978598663
Validation loss: 2.565270655049054

Epoch: 5| Step: 5
Training loss: 3.1133391447918366
Validation loss: 2.5882454606074776

Epoch: 5| Step: 6
Training loss: 2.628371752609545
Validation loss: 2.589762119178563

Epoch: 5| Step: 7
Training loss: 1.8060380250300974
Validation loss: 2.624307344271216

Epoch: 5| Step: 8
Training loss: 2.308338648196642
Validation loss: 2.5897549038123215

Epoch: 5| Step: 9
Training loss: 2.410475451632641
Validation loss: 2.5821489239000646

Epoch: 5| Step: 10
Training loss: 2.7061465800833346
Validation loss: 2.6073632813536327

Epoch: 5| Step: 11
Training loss: 1.9038399642156068
Validation loss: 2.586156849235307

Epoch: 10| Step: 0
Training loss: 2.5329862691489793
Validation loss: 2.6078221617485977

Epoch: 5| Step: 1
Training loss: 2.156329056769424
Validation loss: 2.581535503371125

Epoch: 5| Step: 2
Training loss: 2.716451616103146
Validation loss: 2.5866767579570866

Epoch: 5| Step: 3
Training loss: 2.5428164856968425
Validation loss: 2.5845442569264616

Epoch: 5| Step: 4
Training loss: 2.8959117485425345
Validation loss: 2.612969000179771

Epoch: 5| Step: 5
Training loss: 2.236090688302846
Validation loss: 2.61870657642813

Epoch: 5| Step: 6
Training loss: 2.404978825085345
Validation loss: 2.6179363147407697

Epoch: 5| Step: 7
Training loss: 2.3799667625350325
Validation loss: 2.61630957952534

Epoch: 5| Step: 8
Training loss: 2.954477636185823
Validation loss: 2.605044614936993

Epoch: 5| Step: 9
Training loss: 2.7429985737951608
Validation loss: 2.629547428277257

Epoch: 5| Step: 10
Training loss: 2.88868227448052
Validation loss: 2.6183521241627306

Epoch: 5| Step: 11
Training loss: 1.2254749992587726
Validation loss: 2.627673687249912

Epoch: 11| Step: 0
Training loss: 2.612758886478209
Validation loss: 2.63732405508074

Epoch: 5| Step: 1
Training loss: 2.7687722095434006
Validation loss: 2.5953805080493106

Epoch: 5| Step: 2
Training loss: 2.8911008700887337
Validation loss: 2.6047392419146895

Epoch: 5| Step: 3
Training loss: 3.1804171388168383
Validation loss: 2.630246051983698

Epoch: 5| Step: 4
Training loss: 2.3273270026632353
Validation loss: 2.5834795054233197

Epoch: 5| Step: 5
Training loss: 1.84010983626479
Validation loss: 2.58519332335008

Epoch: 5| Step: 6
Training loss: 2.2381074048980256
Validation loss: 2.606102149148283

Epoch: 5| Step: 7
Training loss: 1.93300735367246
Validation loss: 2.6010748603809986

Epoch: 5| Step: 8
Training loss: 2.2834158244395666
Validation loss: 2.614635589857559

Epoch: 5| Step: 9
Training loss: 2.854347687338535
Validation loss: 2.6146265244177753

Epoch: 5| Step: 10
Training loss: 2.926061884175455
Validation loss: 2.6031884390621465

Epoch: 5| Step: 11
Training loss: 2.1357796957440254
Validation loss: 2.6314900300099637

Epoch: 12| Step: 0
Training loss: 1.9871970707578461
Validation loss: 2.599248355184352

Epoch: 5| Step: 1
Training loss: 2.9463037902039093
Validation loss: 2.5949480744436166

Epoch: 5| Step: 2
Training loss: 1.973511100840269
Validation loss: 2.604008621506255

Epoch: 5| Step: 3
Training loss: 2.685456408277382
Validation loss: 2.5945041509964994

Epoch: 5| Step: 4
Training loss: 2.6601897698305716
Validation loss: 2.5641159878052333

Epoch: 5| Step: 5
Training loss: 2.0269799760564338
Validation loss: 2.597018480525988

Epoch: 5| Step: 6
Training loss: 2.8298439155373414
Validation loss: 2.6062560867372664

Epoch: 5| Step: 7
Training loss: 2.1095167324345607
Validation loss: 2.5761761321870624

Epoch: 5| Step: 8
Training loss: 2.1190782950942957
Validation loss: 2.5601223094849

Epoch: 5| Step: 9
Training loss: 3.3143102629696686
Validation loss: 2.5702004992848613

Epoch: 5| Step: 10
Training loss: 2.931602726843231
Validation loss: 2.617309301777915

Epoch: 5| Step: 11
Training loss: 2.057595519470925
Validation loss: 2.6043879923547153

Epoch: 13| Step: 0
Training loss: 2.2134949682957066
Validation loss: 2.5818046301088664

Epoch: 5| Step: 1
Training loss: 2.3344102032112284
Validation loss: 2.5817240668401387

Epoch: 5| Step: 2
Training loss: 2.793544555210423
Validation loss: 2.596430002914127

Epoch: 5| Step: 3
Training loss: 1.9933186629509296
Validation loss: 2.5744683352600184

Epoch: 5| Step: 4
Training loss: 3.049481651159632
Validation loss: 2.5638820170116072

Epoch: 5| Step: 5
Training loss: 2.426319793530629
Validation loss: 2.5894498031594138

Epoch: 5| Step: 6
Training loss: 2.743749798403235
Validation loss: 2.5906750748185075

Epoch: 5| Step: 7
Training loss: 3.2892645911971448
Validation loss: 2.5838531668431113

Epoch: 5| Step: 8
Training loss: 2.167579299725702
Validation loss: 2.5930048396890073

Epoch: 5| Step: 9
Training loss: 1.9349740698405238
Validation loss: 2.5813817617917607

Epoch: 5| Step: 10
Training loss: 2.27112989209906
Validation loss: 2.618258273345679

Epoch: 5| Step: 11
Training loss: 3.9702881963557233
Validation loss: 2.581325390278977

Epoch: 14| Step: 0
Training loss: 2.4771639216997134
Validation loss: 2.587467129202155

Epoch: 5| Step: 1
Training loss: 2.6917129142575296
Validation loss: 2.603612090505972

Epoch: 5| Step: 2
Training loss: 2.6852887837629997
Validation loss: 2.59603014460633

Epoch: 5| Step: 3
Training loss: 2.406987064975014
Validation loss: 2.5680555369388194

Epoch: 5| Step: 4
Training loss: 2.5364149169548202
Validation loss: 2.583684014288424

Epoch: 5| Step: 5
Training loss: 2.2066671695689446
Validation loss: 2.5806040010146845

Epoch: 5| Step: 6
Training loss: 2.1840619999465662
Validation loss: 2.5784033538366016

Epoch: 5| Step: 7
Training loss: 2.5477265414660053
Validation loss: 2.5607937893316186

Epoch: 5| Step: 8
Training loss: 2.1503317510460764
Validation loss: 2.5659327193543073

Epoch: 5| Step: 9
Training loss: 2.6207435248856346
Validation loss: 2.558458875056859

Epoch: 5| Step: 10
Training loss: 3.2172781532710437
Validation loss: 2.5649269520432014

Epoch: 5| Step: 11
Training loss: 3.2982131628730462
Validation loss: 2.6008129663005044

Epoch: 15| Step: 0
Training loss: 2.4716877901388328
Validation loss: 2.583578318597961

Epoch: 5| Step: 1
Training loss: 2.674148128021671
Validation loss: 2.5720438010719056

Epoch: 5| Step: 2
Training loss: 2.878888030492721
Validation loss: 2.604415829500725

Epoch: 5| Step: 3
Training loss: 1.9327386988471154
Validation loss: 2.600419985950342

Epoch: 5| Step: 4
Training loss: 2.197797895600227
Validation loss: 2.590607739012565

Epoch: 5| Step: 5
Training loss: 1.9821763361063627
Validation loss: 2.5757516282483826

Epoch: 5| Step: 6
Training loss: 3.0513607554199154
Validation loss: 2.6210504349200896

Epoch: 5| Step: 7
Training loss: 2.4920527024122787
Validation loss: 2.6081371188375457

Epoch: 5| Step: 8
Training loss: 2.97411704544596
Validation loss: 2.600722932567564

Epoch: 5| Step: 9
Training loss: 2.759063869056444
Validation loss: 2.6105515916808275

Epoch: 5| Step: 10
Training loss: 2.1810996017415816
Validation loss: 2.5936534262300293

Epoch: 5| Step: 11
Training loss: 3.663603341099848
Validation loss: 2.5769706260954623

Epoch: 16| Step: 0
Training loss: 2.35958942171614
Validation loss: 2.6167719534832625

Epoch: 5| Step: 1
Training loss: 1.9612438676882897
Validation loss: 2.607087897581796

Epoch: 5| Step: 2
Training loss: 2.5693082847832525
Validation loss: 2.6046318681371314

Epoch: 5| Step: 3
Training loss: 2.8394236089872913
Validation loss: 2.6011811550647193

Epoch: 5| Step: 4
Training loss: 2.1258729375870837
Validation loss: 2.6114563093772283

Epoch: 5| Step: 5
Training loss: 2.8698365657407217
Validation loss: 2.6084669630922277

Epoch: 5| Step: 6
Training loss: 2.560049979198862
Validation loss: 2.5970081448229583

Epoch: 5| Step: 7
Training loss: 3.0942946445893256
Validation loss: 2.5880105582222828

Epoch: 5| Step: 8
Training loss: 2.5075976318338458
Validation loss: 2.602770844540431

Epoch: 5| Step: 9
Training loss: 2.141056100914781
Validation loss: 2.588727028476355

Epoch: 5| Step: 10
Training loss: 2.8847925679492477
Validation loss: 2.5782966209856424

Epoch: 5| Step: 11
Training loss: 1.2848886599712226
Validation loss: 2.6182137256594733

Epoch: 17| Step: 0
Training loss: 2.652559296918626
Validation loss: 2.5779861952281604

Epoch: 5| Step: 1
Training loss: 1.9842996658082686
Validation loss: 2.5789047680341777

Epoch: 5| Step: 2
Training loss: 2.515600263580585
Validation loss: 2.5856528226311237

Epoch: 5| Step: 3
Training loss: 2.5015069234608482
Validation loss: 2.602671290528217

Epoch: 5| Step: 4
Training loss: 2.6118337046217444
Validation loss: 2.586897019910614

Epoch: 5| Step: 5
Training loss: 3.1383171142169823
Validation loss: 2.575612506578509

Epoch: 5| Step: 6
Training loss: 2.3092029884296577
Validation loss: 2.5593262184533883

Epoch: 5| Step: 7
Training loss: 2.1223601605434483
Validation loss: 2.586417400473038

Epoch: 5| Step: 8
Training loss: 2.6321273500829028
Validation loss: 2.572815515998374

Epoch: 5| Step: 9
Training loss: 2.5482780476825484
Validation loss: 2.569903699682368

Epoch: 5| Step: 10
Training loss: 2.7807982002792415
Validation loss: 2.56244945863953

Epoch: 5| Step: 11
Training loss: 1.4619746479127216
Validation loss: 2.593728383292083

Epoch: 18| Step: 0
Training loss: 2.7207077694515722
Validation loss: 2.5611592095764366

Epoch: 5| Step: 1
Training loss: 2.4884296654435745
Validation loss: 2.561529828770302

Epoch: 5| Step: 2
Training loss: 2.8132774973777823
Validation loss: 2.5532916004946986

Epoch: 5| Step: 3
Training loss: 2.8229309776102935
Validation loss: 2.5748380765959094

Epoch: 5| Step: 4
Training loss: 2.4530976895312477
Validation loss: 2.5729601517888057

Epoch: 5| Step: 5
Training loss: 2.9722155771943757
Validation loss: 2.5797461681907428

Epoch: 5| Step: 6
Training loss: 2.433364587957593
Validation loss: 2.582185937784895

Epoch: 5| Step: 7
Training loss: 2.518071471795976
Validation loss: 2.5713812858249177

Epoch: 5| Step: 8
Training loss: 2.1874628336337634
Validation loss: 2.5614183903439818

Epoch: 5| Step: 9
Training loss: 2.112972102936545
Validation loss: 2.576539571308051

Epoch: 5| Step: 10
Training loss: 2.274340997343733
Validation loss: 2.560554355015851

Epoch: 5| Step: 11
Training loss: 1.7734631776001064
Validation loss: 2.561985743488934

Epoch: 19| Step: 0
Training loss: 2.069990140181938
Validation loss: 2.5608546627069635

Epoch: 5| Step: 1
Training loss: 2.2510636252821374
Validation loss: 2.5634523188337726

Epoch: 5| Step: 2
Training loss: 2.687224351807914
Validation loss: 2.5508999176229055

Epoch: 5| Step: 3
Training loss: 3.1086541495216045
Validation loss: 2.570006718558746

Epoch: 5| Step: 4
Training loss: 2.7114449941214445
Validation loss: 2.5651752513711443

Epoch: 5| Step: 5
Training loss: 2.3337362372999366
Validation loss: 2.558989314206168

Epoch: 5| Step: 6
Training loss: 2.8896241801005336
Validation loss: 2.5667025328788955

Epoch: 5| Step: 7
Training loss: 2.147119846291394
Validation loss: 2.5773748597341877

Epoch: 5| Step: 8
Training loss: 2.2977349364793738
Validation loss: 2.582093988792303

Epoch: 5| Step: 9
Training loss: 1.8854775462850695
Validation loss: 2.5560239859837557

Epoch: 5| Step: 10
Training loss: 2.8332585904603698
Validation loss: 2.5630461258167734

Epoch: 5| Step: 11
Training loss: 3.0704123599675825
Validation loss: 2.5859442381372473

Epoch: 20| Step: 0
Training loss: 1.7696763541240945
Validation loss: 2.587693067003542

Epoch: 5| Step: 1
Training loss: 2.5032848711906097
Validation loss: 2.555912715606539

Epoch: 5| Step: 2
Training loss: 2.351714373275215
Validation loss: 2.5851275394306037

Epoch: 5| Step: 3
Training loss: 3.1208366125791573
Validation loss: 2.579956544662921

Epoch: 5| Step: 4
Training loss: 2.320510804407422
Validation loss: 2.5762939154287463

Epoch: 5| Step: 5
Training loss: 2.0520010090950014
Validation loss: 2.5777017843266603

Epoch: 5| Step: 6
Training loss: 2.886886571153607
Validation loss: 2.5739359220308446

Epoch: 5| Step: 7
Training loss: 2.293111819429277
Validation loss: 2.5746605956516997

Epoch: 5| Step: 8
Training loss: 2.4298560767860393
Validation loss: 2.5507586031770573

Epoch: 5| Step: 9
Training loss: 3.224485305996358
Validation loss: 2.580153871089036

Epoch: 5| Step: 10
Training loss: 2.5627753877365613
Validation loss: 2.5701022926956294

Epoch: 5| Step: 11
Training loss: 2.318685352832914
Validation loss: 2.561348256965824

Epoch: 21| Step: 0
Training loss: 2.8070818953028884
Validation loss: 2.548469937272259

Epoch: 5| Step: 1
Training loss: 2.790398627622512
Validation loss: 2.551357996622131

Epoch: 5| Step: 2
Training loss: 2.667076576040399
Validation loss: 2.557271997462897

Epoch: 5| Step: 3
Training loss: 2.5791915999169257
Validation loss: 2.5840427318085504

Epoch: 5| Step: 4
Training loss: 2.313463577356446
Validation loss: 2.5569526165321608

Epoch: 5| Step: 5
Training loss: 2.221040537354732
Validation loss: 2.567753430964135

Epoch: 5| Step: 6
Training loss: 2.7591758578404795
Validation loss: 2.5745913786257466

Epoch: 5| Step: 7
Training loss: 2.6080700929384886
Validation loss: 2.54382088442928

Epoch: 5| Step: 8
Training loss: 2.096823415107497
Validation loss: 2.546963005651703

Epoch: 5| Step: 9
Training loss: 2.316885012575942
Validation loss: 2.571308035948946

Epoch: 5| Step: 10
Training loss: 2.5447983964312386
Validation loss: 2.5549803555275235

Epoch: 5| Step: 11
Training loss: 1.93701171875
Validation loss: 2.5758259511842057

Epoch: 22| Step: 0
Training loss: 2.3633280599702973
Validation loss: 2.5515226890135256

Epoch: 5| Step: 1
Training loss: 2.492425123982108
Validation loss: 2.565322198008752

Epoch: 5| Step: 2
Training loss: 2.355010891218979
Validation loss: 2.5506432706737323

Epoch: 5| Step: 3
Training loss: 2.8084193826806056
Validation loss: 2.5813520676120048

Epoch: 5| Step: 4
Training loss: 2.109234840540244
Validation loss: 2.602872512955424

Epoch: 5| Step: 5
Training loss: 2.373445504070194
Validation loss: 2.5723271576191555

Epoch: 5| Step: 6
Training loss: 3.2934769750716564
Validation loss: 2.602808210186418

Epoch: 5| Step: 7
Training loss: 2.3192359147840205
Validation loss: 2.574359436512914

Epoch: 5| Step: 8
Training loss: 2.597348853258114
Validation loss: 2.5959563312403913

Epoch: 5| Step: 9
Training loss: 2.2237881692888144
Validation loss: 2.5595085488806513

Epoch: 5| Step: 10
Training loss: 2.82825153552499
Validation loss: 2.560861874158687

Epoch: 5| Step: 11
Training loss: 1.8228600484138973
Validation loss: 2.549455166561848

Epoch: 23| Step: 0
Training loss: 2.2413479499241955
Validation loss: 2.5572891908673787

Epoch: 5| Step: 1
Training loss: 3.018739979097466
Validation loss: 2.5745762377561587

Epoch: 5| Step: 2
Training loss: 2.463884218257628
Validation loss: 2.562855668699975

Epoch: 5| Step: 3
Training loss: 3.2762156785479313
Validation loss: 2.5670431731523755

Epoch: 5| Step: 4
Training loss: 2.2322859167848823
Validation loss: 2.588509965596313

Epoch: 5| Step: 5
Training loss: 2.522461977200473
Validation loss: 2.5734381044375914

Epoch: 5| Step: 6
Training loss: 2.688843590860134
Validation loss: 2.59184488933812

Epoch: 5| Step: 7
Training loss: 2.0983851354545897
Validation loss: 2.5470400524679597

Epoch: 5| Step: 8
Training loss: 2.6259243563806915
Validation loss: 2.548994001932222

Epoch: 5| Step: 9
Training loss: 1.882810473935632
Validation loss: 2.540049982004675

Epoch: 5| Step: 10
Training loss: 2.438465709608658
Validation loss: 2.578352954689563

Epoch: 5| Step: 11
Training loss: 1.0037789468166114
Validation loss: 2.566100862507867

Epoch: 24| Step: 0
Training loss: 2.791145892937236
Validation loss: 2.572851594624579

Epoch: 5| Step: 1
Training loss: 2.9117031005897367
Validation loss: 2.5452992141717226

Epoch: 5| Step: 2
Training loss: 2.311197068478424
Validation loss: 2.5549719221497087

Epoch: 5| Step: 3
Training loss: 2.8699272848348016
Validation loss: 2.551310002980925

Epoch: 5| Step: 4
Training loss: 2.6308842058149837
Validation loss: 2.5610256295501235

Epoch: 5| Step: 5
Training loss: 2.2245782945452857
Validation loss: 2.570219391872745

Epoch: 5| Step: 6
Training loss: 2.556065925368816
Validation loss: 2.5653025568167114

Epoch: 5| Step: 7
Training loss: 2.8296686670023132
Validation loss: 2.585227427036409

Epoch: 5| Step: 8
Training loss: 2.1219646991090912
Validation loss: 2.5733407954143224

Epoch: 5| Step: 9
Training loss: 1.9332786842821843
Validation loss: 2.5712312140587543

Epoch: 5| Step: 10
Training loss: 2.2007358664158785
Validation loss: 2.561479047205693

Epoch: 5| Step: 11
Training loss: 2.256533567409252
Validation loss: 2.5322550477665433

Epoch: 25| Step: 0
Training loss: 2.4849984208529885
Validation loss: 2.5624579720811025

Epoch: 5| Step: 1
Training loss: 2.792873311579616
Validation loss: 2.5588995520254123

Epoch: 5| Step: 2
Training loss: 2.151343249838456
Validation loss: 2.5636787610918406

Epoch: 5| Step: 3
Training loss: 2.939783223522808
Validation loss: 2.529609847374126

Epoch: 5| Step: 4
Training loss: 2.820177238792471
Validation loss: 2.552723723790413

Epoch: 5| Step: 5
Training loss: 1.7777856298445442
Validation loss: 2.5316832018666555

Epoch: 5| Step: 6
Training loss: 2.084223696866318
Validation loss: 2.5656361849529814

Epoch: 5| Step: 7
Training loss: 2.0152782762969252
Validation loss: 2.5534833506403714

Epoch: 5| Step: 8
Training loss: 2.8772070333050417
Validation loss: 2.5732879152041215

Epoch: 5| Step: 9
Training loss: 2.5658772241204866
Validation loss: 2.5547128884145662

Epoch: 5| Step: 10
Training loss: 2.598488214104565
Validation loss: 2.542782680503368

Epoch: 5| Step: 11
Training loss: 3.4595189341139854
Validation loss: 2.577546600040176

Epoch: 26| Step: 0
Training loss: 2.1773332029592956
Validation loss: 2.551186471466174

Epoch: 5| Step: 1
Training loss: 2.4056671229277438
Validation loss: 2.5582747515350825

Epoch: 5| Step: 2
Training loss: 2.597099072352414
Validation loss: 2.554887411868081

Epoch: 5| Step: 3
Training loss: 2.8580624428848993
Validation loss: 2.5756106706513946

Epoch: 5| Step: 4
Training loss: 2.182143601619655
Validation loss: 2.589402404279205

Epoch: 5| Step: 5
Training loss: 2.881952586539128
Validation loss: 2.592306635538848

Epoch: 5| Step: 6
Training loss: 2.3533829141136158
Validation loss: 2.5868191325423786

Epoch: 5| Step: 7
Training loss: 2.341580416718893
Validation loss: 2.59748154819973

Epoch: 5| Step: 8
Training loss: 3.0324187237822575
Validation loss: 2.600320410700949

Epoch: 5| Step: 9
Training loss: 2.3199066937526833
Validation loss: 2.5903523762221865

Epoch: 5| Step: 10
Training loss: 2.5153868189299304
Validation loss: 2.5545811567814187

Epoch: 5| Step: 11
Training loss: 2.08092327589108
Validation loss: 2.57707672771038

Epoch: 27| Step: 0
Training loss: 2.0812427967393647
Validation loss: 2.5749803843260337

Epoch: 5| Step: 1
Training loss: 1.80892499687456
Validation loss: 2.5679321862087634

Epoch: 5| Step: 2
Training loss: 2.464613237196876
Validation loss: 2.565693028950152

Epoch: 5| Step: 3
Training loss: 2.2179627432209412
Validation loss: 2.5587316577814883

Epoch: 5| Step: 4
Training loss: 3.093365115490238
Validation loss: 2.5719174453798774

Epoch: 5| Step: 5
Training loss: 3.0202762133870085
Validation loss: 2.576606912347741

Epoch: 5| Step: 6
Training loss: 2.7458585418639996
Validation loss: 2.572195439792009

Epoch: 5| Step: 7
Training loss: 1.9203627304323827
Validation loss: 2.5611165157712987

Epoch: 5| Step: 8
Training loss: 2.806894268342644
Validation loss: 2.55354805129647

Epoch: 5| Step: 9
Training loss: 2.1832045752533653
Validation loss: 2.555060488724515

Epoch: 5| Step: 10
Training loss: 2.717438918816086
Validation loss: 2.5525453746111553

Epoch: 5| Step: 11
Training loss: 2.9124504314346646
Validation loss: 2.5517180914548345

Epoch: 28| Step: 0
Training loss: 2.5011642606072115
Validation loss: 2.544950140100546

Epoch: 5| Step: 1
Training loss: 2.7214725061023395
Validation loss: 2.5546068009629224

Epoch: 5| Step: 2
Training loss: 1.9915033100549848
Validation loss: 2.551772372445984

Epoch: 5| Step: 3
Training loss: 2.585854889163833
Validation loss: 2.5484611977902683

Epoch: 5| Step: 4
Training loss: 2.300210205092105
Validation loss: 2.541547722977737

Epoch: 5| Step: 5
Training loss: 2.497872114592858
Validation loss: 2.5491467779725707

Epoch: 5| Step: 6
Training loss: 2.7260879059833494
Validation loss: 2.548228768026119

Epoch: 5| Step: 7
Training loss: 2.969734430224287
Validation loss: 2.5470008116931617

Epoch: 5| Step: 8
Training loss: 2.596870291989095
Validation loss: 2.563647583115922

Epoch: 5| Step: 9
Training loss: 2.2478397383326274
Validation loss: 2.5338825519588424

Epoch: 5| Step: 10
Training loss: 2.3846321537242257
Validation loss: 2.5490977294515194

Epoch: 5| Step: 11
Training loss: 4.003799779453288
Validation loss: 2.551009003936487

Epoch: 29| Step: 0
Training loss: 2.8682136050794393
Validation loss: 2.553222049283371

Epoch: 5| Step: 1
Training loss: 2.593760019305997
Validation loss: 2.565377902740287

Epoch: 5| Step: 2
Training loss: 2.7255444743912665
Validation loss: 2.5323595001558794

Epoch: 5| Step: 3
Training loss: 2.0466273500143255
Validation loss: 2.556712084248259

Epoch: 5| Step: 4
Training loss: 2.2482502809666673
Validation loss: 2.548373462177255

Epoch: 5| Step: 5
Training loss: 2.352545447239935
Validation loss: 2.5567680737051903

Epoch: 5| Step: 6
Training loss: 1.803453163683114
Validation loss: 2.5556116328329495

Epoch: 5| Step: 7
Training loss: 2.7534684935762725
Validation loss: 2.5565714796413963

Epoch: 5| Step: 8
Training loss: 2.568907565368349
Validation loss: 2.5756968845307764

Epoch: 5| Step: 9
Training loss: 1.9764468193127618
Validation loss: 2.566452831075894

Epoch: 5| Step: 10
Training loss: 3.1289420631826053
Validation loss: 2.573548024561703

Epoch: 5| Step: 11
Training loss: 3.242820291927961
Validation loss: 2.5641154202229117

Epoch: 30| Step: 0
Training loss: 2.616420986604466
Validation loss: 2.5722649491487126

Epoch: 5| Step: 1
Training loss: 2.03414370486208
Validation loss: 2.5649316578027497

Epoch: 5| Step: 2
Training loss: 1.982790697487439
Validation loss: 2.583079971045916

Epoch: 5| Step: 3
Training loss: 2.2887298029743373
Validation loss: 2.5637925578738456

Epoch: 5| Step: 4
Training loss: 2.222202140664388
Validation loss: 2.553798022952218

Epoch: 5| Step: 5
Training loss: 2.649624358850038
Validation loss: 2.566740725478874

Epoch: 5| Step: 6
Training loss: 1.9311543808262013
Validation loss: 2.5391139372481635

Epoch: 5| Step: 7
Training loss: 2.796998261021226
Validation loss: 2.565276525809572

Epoch: 5| Step: 8
Training loss: 2.999429807517931
Validation loss: 2.559394501459258

Epoch: 5| Step: 9
Training loss: 2.4431106355390724
Validation loss: 2.551655333824165

Epoch: 5| Step: 10
Training loss: 3.238142390201702
Validation loss: 2.55146984330006

Epoch: 5| Step: 11
Training loss: 1.3254536409966031
Validation loss: 2.558072805393334

Epoch: 31| Step: 0
Training loss: 3.304250268892709
Validation loss: 2.537552728011165

Epoch: 5| Step: 1
Training loss: 2.689105153341222
Validation loss: 2.5558421979409855

Epoch: 5| Step: 2
Training loss: 2.0204689903456785
Validation loss: 2.563335220557793

Epoch: 5| Step: 3
Training loss: 2.5482051628851514
Validation loss: 2.5352883522478926

Epoch: 5| Step: 4
Training loss: 2.2642939373587345
Validation loss: 2.5695941582155806

Epoch: 5| Step: 5
Training loss: 2.613023320400207
Validation loss: 2.525578156776077

Epoch: 5| Step: 6
Training loss: 2.4615408021658993
Validation loss: 2.5415133458675863

Epoch: 5| Step: 7
Training loss: 2.1972799478699847
Validation loss: 2.534494690865501

Epoch: 5| Step: 8
Training loss: 2.6489739788961955
Validation loss: 2.5540957995400744

Epoch: 5| Step: 9
Training loss: 2.6720854023859424
Validation loss: 2.5443726632789896

Epoch: 5| Step: 10
Training loss: 1.6822483856334018
Validation loss: 2.545703864408453

Epoch: 5| Step: 11
Training loss: 2.8740138145438627
Validation loss: 2.5580439280135003

Epoch: 32| Step: 0
Training loss: 1.746247218682075
Validation loss: 2.553763915777297

Epoch: 5| Step: 1
Training loss: 2.9933839004708607
Validation loss: 2.5570986662611093

Epoch: 5| Step: 2
Training loss: 2.3305566365124943
Validation loss: 2.5543665358631293

Epoch: 5| Step: 3
Training loss: 2.464113734939656
Validation loss: 2.5517505792125244

Epoch: 5| Step: 4
Training loss: 2.1340691633591082
Validation loss: 2.5457497823920465

Epoch: 5| Step: 5
Training loss: 2.2942115755832195
Validation loss: 2.5547664564026795

Epoch: 5| Step: 6
Training loss: 3.331722267555842
Validation loss: 2.56816138603111

Epoch: 5| Step: 7
Training loss: 2.7424826612593836
Validation loss: 2.548169536446201

Epoch: 5| Step: 8
Training loss: 2.716671467018177
Validation loss: 2.53790749909315

Epoch: 5| Step: 9
Training loss: 2.720930080436561
Validation loss: 2.5565361349358704

Epoch: 5| Step: 10
Training loss: 1.676704205926359
Validation loss: 2.559730875023977

Epoch: 5| Step: 11
Training loss: 1.5320447299642417
Validation loss: 2.5455565013827774

Epoch: 33| Step: 0
Training loss: 2.336806732021248
Validation loss: 2.572985159133481

Epoch: 5| Step: 1
Training loss: 2.137542510028218
Validation loss: 2.5403441300082834

Epoch: 5| Step: 2
Training loss: 2.3467166689761854
Validation loss: 2.5482523222692235

Epoch: 5| Step: 3
Training loss: 3.010385339347344
Validation loss: 2.5377391359556842

Epoch: 5| Step: 4
Training loss: 2.245581420849303
Validation loss: 2.5442036463997413

Epoch: 5| Step: 5
Training loss: 1.9067568496014895
Validation loss: 2.5380217977190966

Epoch: 5| Step: 6
Training loss: 2.0634208704179966
Validation loss: 2.5531645093589947

Epoch: 5| Step: 7
Training loss: 2.6299287754466127
Validation loss: 2.524031314327382

Epoch: 5| Step: 8
Training loss: 3.140761491077514
Validation loss: 2.5400870657313837

Epoch: 5| Step: 9
Training loss: 2.8870504186156682
Validation loss: 2.524136681631006

Epoch: 5| Step: 10
Training loss: 2.5840503456419452
Validation loss: 2.514769768118007

Epoch: 5| Step: 11
Training loss: 2.2423174351914525
Validation loss: 2.527371763597875

Epoch: 34| Step: 0
Training loss: 2.2798710666139215
Validation loss: 2.5307755241432113

Epoch: 5| Step: 1
Training loss: 2.439208776668524
Validation loss: 2.5300018761587664

Epoch: 5| Step: 2
Training loss: 2.219513238003296
Validation loss: 2.517707255158978

Epoch: 5| Step: 3
Training loss: 2.2587016641651982
Validation loss: 2.542320309424769

Epoch: 5| Step: 4
Training loss: 3.126438267654597
Validation loss: 2.546423983278385

Epoch: 5| Step: 5
Training loss: 2.4771192628796252
Validation loss: 2.5380719409423134

Epoch: 5| Step: 6
Training loss: 2.870297774441677
Validation loss: 2.5760360230783688

Epoch: 5| Step: 7
Training loss: 2.5077380588214107
Validation loss: 2.5662170100394897

Epoch: 5| Step: 8
Training loss: 2.0890059743807665
Validation loss: 2.5728722631558556

Epoch: 5| Step: 9
Training loss: 2.5267348344543437
Validation loss: 2.5532023850428596

Epoch: 5| Step: 10
Training loss: 2.7789125371115975
Validation loss: 2.55794533625612

Epoch: 5| Step: 11
Training loss: 1.3039716481332855
Validation loss: 2.5556267772185444

Epoch: 35| Step: 0
Training loss: 2.794077833086869
Validation loss: 2.5744983712252503

Epoch: 5| Step: 1
Training loss: 2.4180621250839236
Validation loss: 2.5589814841127416

Epoch: 5| Step: 2
Training loss: 2.4719023074873387
Validation loss: 2.5722802194824816

Epoch: 5| Step: 3
Training loss: 2.669341285830277
Validation loss: 2.5683706189043627

Epoch: 5| Step: 4
Training loss: 2.290904062714226
Validation loss: 2.5715708295101836

Epoch: 5| Step: 5
Training loss: 1.8182307442671277
Validation loss: 2.540288380793718

Epoch: 5| Step: 6
Training loss: 2.5456407048532137
Validation loss: 2.554403724813802

Epoch: 5| Step: 7
Training loss: 2.1676258262710575
Validation loss: 2.5690131531417406

Epoch: 5| Step: 8
Training loss: 2.2716408673186046
Validation loss: 2.570291613771246

Epoch: 5| Step: 9
Training loss: 2.4668156252380227
Validation loss: 2.5521220236719473

Epoch: 5| Step: 10
Training loss: 3.2552045084612944
Validation loss: 2.5285435206375646

Epoch: 5| Step: 11
Training loss: 2.8759679408826626
Validation loss: 2.536921426900072

Epoch: 36| Step: 0
Training loss: 2.322367467804692
Validation loss: 2.5586872462305106

Epoch: 5| Step: 1
Training loss: 2.594686132424008
Validation loss: 2.549064884419285

Epoch: 5| Step: 2
Training loss: 2.265404841808642
Validation loss: 2.5389019489879896

Epoch: 5| Step: 3
Training loss: 2.469192658346692
Validation loss: 2.5442691765229615

Epoch: 5| Step: 4
Training loss: 2.1876640258328277
Validation loss: 2.526874752247525

Epoch: 5| Step: 5
Training loss: 2.0276153911675436
Validation loss: 2.553983900605693

Epoch: 5| Step: 6
Training loss: 2.8240023750370833
Validation loss: 2.5318766905258614

Epoch: 5| Step: 7
Training loss: 2.359009670242599
Validation loss: 2.5347437001251722

Epoch: 5| Step: 8
Training loss: 2.8958427557117297
Validation loss: 2.5283254793049736

Epoch: 5| Step: 9
Training loss: 2.5044709281551594
Validation loss: 2.5447946371737014

Epoch: 5| Step: 10
Training loss: 2.7766677312707713
Validation loss: 2.544073768149992

Epoch: 5| Step: 11
Training loss: 2.6837199041263062
Validation loss: 2.53298235117234

Epoch: 37| Step: 0
Training loss: 3.024173302039187
Validation loss: 2.5351082983904303

Epoch: 5| Step: 1
Training loss: 1.9241321613934597
Validation loss: 2.519073369808365

Epoch: 5| Step: 2
Training loss: 1.9382393564527116
Validation loss: 2.539381824856349

Epoch: 5| Step: 3
Training loss: 1.8611716557930036
Validation loss: 2.561252891417262

Epoch: 5| Step: 4
Training loss: 2.9145091842006674
Validation loss: 2.53647328136721

Epoch: 5| Step: 5
Training loss: 2.807527342312454
Validation loss: 2.560888776302096

Epoch: 5| Step: 6
Training loss: 2.5303842453303633
Validation loss: 2.5639704152893463

Epoch: 5| Step: 7
Training loss: 2.5629380944880387
Validation loss: 2.543500587801762

Epoch: 5| Step: 8
Training loss: 2.250655926357122
Validation loss: 2.5752791563582713

Epoch: 5| Step: 9
Training loss: 2.6536632733182177
Validation loss: 2.5362541748433656

Epoch: 5| Step: 10
Training loss: 2.4954882918740315
Validation loss: 2.575598632954006

Epoch: 5| Step: 11
Training loss: 2.8912088990083507
Validation loss: 2.593531302535232

Epoch: 38| Step: 0
Training loss: 2.492621404968243
Validation loss: 2.5494961463640746

Epoch: 5| Step: 1
Training loss: 2.3684757365779157
Validation loss: 2.5777702434256584

Epoch: 5| Step: 2
Training loss: 2.838348960751311
Validation loss: 2.552490779244821

Epoch: 5| Step: 3
Training loss: 3.5033890800747094
Validation loss: 2.5748851378602846

Epoch: 5| Step: 4
Training loss: 2.3367618394843355
Validation loss: 2.53186933766208

Epoch: 5| Step: 5
Training loss: 2.4082749008781086
Validation loss: 2.5386131358479185

Epoch: 5| Step: 6
Training loss: 2.0586092693170945
Validation loss: 2.5434422049795447

Epoch: 5| Step: 7
Training loss: 2.3511103705521403
Validation loss: 2.5353594670599704

Epoch: 5| Step: 8
Training loss: 2.076966615367252
Validation loss: 2.5386499744696804

Epoch: 5| Step: 9
Training loss: 2.7527751791289847
Validation loss: 2.53739874689446

Epoch: 5| Step: 10
Training loss: 1.9671000272590187
Validation loss: 2.5475742905172507

Epoch: 5| Step: 11
Training loss: 2.273276621576346
Validation loss: 2.5364721259983005

Epoch: 39| Step: 0
Training loss: 2.6235167536257844
Validation loss: 2.53518055265952

Epoch: 5| Step: 1
Training loss: 2.373989593000989
Validation loss: 2.5337005769940166

Epoch: 5| Step: 2
Training loss: 2.573023609816588
Validation loss: 2.5280914772806953

Epoch: 5| Step: 3
Training loss: 2.8295631756319874
Validation loss: 2.5364889590838136

Epoch: 5| Step: 4
Training loss: 2.706666247488406
Validation loss: 2.538372329419465

Epoch: 5| Step: 5
Training loss: 2.693543226621392
Validation loss: 2.541518309958834

Epoch: 5| Step: 6
Training loss: 1.84977397568971
Validation loss: 2.5355889098611275

Epoch: 5| Step: 7
Training loss: 2.5423528860135614
Validation loss: 2.549604918690956

Epoch: 5| Step: 8
Training loss: 2.592025551269713
Validation loss: 2.548901525928905

Epoch: 5| Step: 9
Training loss: 2.3721779570766364
Validation loss: 2.5256257897929353

Epoch: 5| Step: 10
Training loss: 1.9594354842248825
Validation loss: 2.5289564004175187

Epoch: 5| Step: 11
Training loss: 2.0692715313021557
Validation loss: 2.5351405209375186

Epoch: 40| Step: 0
Training loss: 2.390812286819713
Validation loss: 2.5499394007569385

Epoch: 5| Step: 1
Training loss: 2.2143203143743406
Validation loss: 2.5535448340035574

Epoch: 5| Step: 2
Training loss: 2.3281321685475835
Validation loss: 2.5651823015786395

Epoch: 5| Step: 3
Training loss: 2.9928008165596482
Validation loss: 2.571006149875289

Epoch: 5| Step: 4
Training loss: 2.3649885079747817
Validation loss: 2.571285469467023

Epoch: 5| Step: 5
Training loss: 2.5163843181783028
Validation loss: 2.5974810242411057

Epoch: 5| Step: 6
Training loss: 2.640565318499701
Validation loss: 2.5831430016410404

Epoch: 5| Step: 7
Training loss: 2.5168009787417556
Validation loss: 2.5665561897376445

Epoch: 5| Step: 8
Training loss: 2.065979075131061
Validation loss: 2.5588598486673346

Epoch: 5| Step: 9
Training loss: 2.137157443967949
Validation loss: 2.542964362996698

Epoch: 5| Step: 10
Training loss: 2.9141405519561294
Validation loss: 2.519461721007996

Epoch: 5| Step: 11
Training loss: 3.1885368306421253
Validation loss: 2.567832883144463

Epoch: 41| Step: 0
Training loss: 2.86553874411189
Validation loss: 2.5392086476055447

Epoch: 5| Step: 1
Training loss: 2.472556161888714
Validation loss: 2.5537149481562573

Epoch: 5| Step: 2
Training loss: 2.366033996944005
Validation loss: 2.541064430763074

Epoch: 5| Step: 3
Training loss: 2.5366066661494173
Validation loss: 2.549321148618388

Epoch: 5| Step: 4
Training loss: 2.943218589812764
Validation loss: 2.5372704153071193

Epoch: 5| Step: 5
Training loss: 2.6047273464621896
Validation loss: 2.5277675173158807

Epoch: 5| Step: 6
Training loss: 1.689291674005197
Validation loss: 2.5441680713049517

Epoch: 5| Step: 7
Training loss: 2.2145050704873888
Validation loss: 2.5384704995200944

Epoch: 5| Step: 8
Training loss: 2.773901672204793
Validation loss: 2.5481651330562722

Epoch: 5| Step: 9
Training loss: 2.1471473843110105
Validation loss: 2.5545949928885783

Epoch: 5| Step: 10
Training loss: 2.168497876729843
Validation loss: 2.542194629511481

Epoch: 5| Step: 11
Training loss: 3.245349050361024
Validation loss: 2.546943156572718

Epoch: 42| Step: 0
Training loss: 2.608524023851
Validation loss: 2.564005874482744

Epoch: 5| Step: 1
Training loss: 2.4469181919305125
Validation loss: 2.55259448531351

Epoch: 5| Step: 2
Training loss: 1.981873023815006
Validation loss: 2.5367851882252936

Epoch: 5| Step: 3
Training loss: 2.3674393825162485
Validation loss: 2.553457413118275

Epoch: 5| Step: 4
Training loss: 1.5910086897847098
Validation loss: 2.5349666992861897

Epoch: 5| Step: 5
Training loss: 2.1957299320937405
Validation loss: 2.545551697365338

Epoch: 5| Step: 6
Training loss: 2.756314743561804
Validation loss: 2.556812258273626

Epoch: 5| Step: 7
Training loss: 2.3623527279116847
Validation loss: 2.554192855808561

Epoch: 5| Step: 8
Training loss: 2.5016730432431227
Validation loss: 2.6077510135473

Epoch: 5| Step: 9
Training loss: 2.9054902426983023
Validation loss: 2.59194091534604

Epoch: 5| Step: 10
Training loss: 2.896682248909511
Validation loss: 2.58657183746979

Epoch: 5| Step: 11
Training loss: 3.442188048568315
Validation loss: 2.599869689977067

Epoch: 43| Step: 0
Training loss: 2.2200270725008555
Validation loss: 2.562619873282402

Epoch: 5| Step: 1
Training loss: 2.6709762757167828
Validation loss: 2.5448969002720765

Epoch: 5| Step: 2
Training loss: 2.2092033567754994
Validation loss: 2.554925538074139

Epoch: 5| Step: 3
Training loss: 2.2355409794419248
Validation loss: 2.5520116263974786

Epoch: 5| Step: 4
Training loss: 2.2611219181965785
Validation loss: 2.5744197305842134

Epoch: 5| Step: 5
Training loss: 2.1971950943541194
Validation loss: 2.5374767222534755

Epoch: 5| Step: 6
Training loss: 2.872891523672119
Validation loss: 2.5596057841358415

Epoch: 5| Step: 7
Training loss: 2.7728795309658714
Validation loss: 2.5358121951067636

Epoch: 5| Step: 8
Training loss: 2.181484889633653
Validation loss: 2.5492190201346414

Epoch: 5| Step: 9
Training loss: 2.4662285011773606
Validation loss: 2.5383511999465362

Epoch: 5| Step: 10
Training loss: 2.8243704474138753
Validation loss: 2.551238715610846

Epoch: 5| Step: 11
Training loss: 3.142197096860733
Validation loss: 2.566516895125122

Epoch: 44| Step: 0
Training loss: 2.2157157244488346
Validation loss: 2.5448253161443377

Epoch: 5| Step: 1
Training loss: 2.4283808785703798
Validation loss: 2.560318339896141

Epoch: 5| Step: 2
Training loss: 2.5106415285150905
Validation loss: 2.5221762127876386

Epoch: 5| Step: 3
Training loss: 2.3475178250904576
Validation loss: 2.5430048887748593

Epoch: 5| Step: 4
Training loss: 2.311578515463902
Validation loss: 2.5297503326322306

Epoch: 5| Step: 5
Training loss: 2.287426569025835
Validation loss: 2.5473468008075564

Epoch: 5| Step: 6
Training loss: 2.077501131647309
Validation loss: 2.5465200211917405

Epoch: 5| Step: 7
Training loss: 2.16744235409789
Validation loss: 2.540654259607448

Epoch: 5| Step: 8
Training loss: 2.510392712575086
Validation loss: 2.5286353307807743

Epoch: 5| Step: 9
Training loss: 2.689391424265006
Validation loss: 2.5612250156775795

Epoch: 5| Step: 10
Training loss: 3.1059652831230777
Validation loss: 2.5552656003742475

Epoch: 5| Step: 11
Training loss: 3.831891134113323
Validation loss: 2.5389202058485125

Epoch: 45| Step: 0
Training loss: 2.7961742865961927
Validation loss: 2.545629227869894

Epoch: 5| Step: 1
Training loss: 2.5298641791092247
Validation loss: 2.573216545657643

Epoch: 5| Step: 2
Training loss: 1.9276407483833393
Validation loss: 2.5450262368878938

Epoch: 5| Step: 3
Training loss: 2.223393912836451
Validation loss: 2.532721213582858

Epoch: 5| Step: 4
Training loss: 2.622785633339978
Validation loss: 2.5645158444802245

Epoch: 5| Step: 5
Training loss: 2.472185376305862
Validation loss: 2.5529662505856563

Epoch: 5| Step: 6
Training loss: 2.411100972159652
Validation loss: 2.5438071224975305

Epoch: 5| Step: 7
Training loss: 2.606831938909938
Validation loss: 2.5572422719459467

Epoch: 5| Step: 8
Training loss: 2.5950890267449744
Validation loss: 2.538130134177164

Epoch: 5| Step: 9
Training loss: 2.5763145794795643
Validation loss: 2.549703883605352

Epoch: 5| Step: 10
Training loss: 2.5358678821120284
Validation loss: 2.5350599892733165

Epoch: 5| Step: 11
Training loss: 2.07572706881885
Validation loss: 2.5265105975656246

Epoch: 46| Step: 0
Training loss: 2.0730647380857836
Validation loss: 2.5245795032784657

Epoch: 5| Step: 1
Training loss: 3.0253756518452106
Validation loss: 2.5574970680821614

Epoch: 5| Step: 2
Training loss: 2.2765984337981022
Validation loss: 2.5478919929989883

Epoch: 5| Step: 3
Training loss: 2.047341330019605
Validation loss: 2.554429981345289

Epoch: 5| Step: 4
Training loss: 2.426483298419704
Validation loss: 2.5343538453535857

Epoch: 5| Step: 5
Training loss: 1.7733254418281175
Validation loss: 2.550429023387008

Epoch: 5| Step: 6
Training loss: 2.64630563280156
Validation loss: 2.5518348624792675

Epoch: 5| Step: 7
Training loss: 2.5814013383665197
Validation loss: 2.560752633423863

Epoch: 5| Step: 8
Training loss: 3.1514879315263373
Validation loss: 2.5463702846544174

Epoch: 5| Step: 9
Training loss: 2.3678359349029905
Validation loss: 2.5166996305298417

Epoch: 5| Step: 10
Training loss: 2.4313759778488393
Validation loss: 2.5297136550063293

Epoch: 5| Step: 11
Training loss: 2.6525560611477634
Validation loss: 2.545534233456263

Epoch: 47| Step: 0
Training loss: 2.8779406228584237
Validation loss: 2.5359305721117034

Epoch: 5| Step: 1
Training loss: 2.3865815917716597
Validation loss: 2.5313024790154928

Epoch: 5| Step: 2
Training loss: 2.400835261434063
Validation loss: 2.543534906808329

Epoch: 5| Step: 3
Training loss: 2.71332438374511
Validation loss: 2.549260646714661

Epoch: 5| Step: 4
Training loss: 2.7300682811092916
Validation loss: 2.538679792465493

Epoch: 5| Step: 5
Training loss: 2.1912996262775257
Validation loss: 2.5246504436231407

Epoch: 5| Step: 6
Training loss: 2.3170455384963455
Validation loss: 2.536133333464892

Epoch: 5| Step: 7
Training loss: 2.3708902237094107
Validation loss: 2.5448121803280306

Epoch: 5| Step: 8
Training loss: 2.3912256022443508
Validation loss: 2.5450294278678696

Epoch: 5| Step: 9
Training loss: 2.10380780272652
Validation loss: 2.5387135035966972

Epoch: 5| Step: 10
Training loss: 2.600948501851478
Validation loss: 2.5353283346164317

Epoch: 5| Step: 11
Training loss: 2.4319069099930757
Validation loss: 2.539223074114859

Epoch: 48| Step: 0
Training loss: 2.435794135591899
Validation loss: 2.540651049447172

Epoch: 5| Step: 1
Training loss: 2.782953233710421
Validation loss: 2.545577820808129

Epoch: 5| Step: 2
Training loss: 2.167606797804647
Validation loss: 2.5445621223517203

Epoch: 5| Step: 3
Training loss: 2.073426176038807
Validation loss: 2.5536085333146583

Epoch: 5| Step: 4
Training loss: 2.435520737912331
Validation loss: 2.5619561075619295

Epoch: 5| Step: 5
Training loss: 2.56375556517415
Validation loss: 2.5410753145862515

Epoch: 5| Step: 6
Training loss: 2.0613948288578525
Validation loss: 2.5571634619146035

Epoch: 5| Step: 7
Training loss: 2.832046740259361
Validation loss: 2.5752180549582717

Epoch: 5| Step: 8
Training loss: 1.9966146308325414
Validation loss: 2.575094341352278

Epoch: 5| Step: 9
Training loss: 2.703039178974302
Validation loss: 2.5723672362552623

Epoch: 5| Step: 10
Training loss: 2.8318953698544767
Validation loss: 2.5535137812776187

Epoch: 5| Step: 11
Training loss: 2.334411122401346
Validation loss: 2.5787807478360585

Epoch: 49| Step: 0
Training loss: 2.5749052345096746
Validation loss: 2.5709851127924486

Epoch: 5| Step: 1
Training loss: 3.064473820088262
Validation loss: 2.5524769434072807

Epoch: 5| Step: 2
Training loss: 2.2486113395583462
Validation loss: 2.5430470506808405

Epoch: 5| Step: 3
Training loss: 2.2280837901880246
Validation loss: 2.5605380875053316

Epoch: 5| Step: 4
Training loss: 2.352827777303749
Validation loss: 2.550980932531198

Epoch: 5| Step: 5
Training loss: 2.2910699472060476
Validation loss: 2.549558337615299

Epoch: 5| Step: 6
Training loss: 2.8122884034986746
Validation loss: 2.534565179276837

Epoch: 5| Step: 7
Training loss: 2.209115075950713
Validation loss: 2.5140042741006283

Epoch: 5| Step: 8
Training loss: 1.9001228167341462
Validation loss: 2.5216930331633223

Epoch: 5| Step: 9
Training loss: 2.896812950218686
Validation loss: 2.5278655137100676

Epoch: 5| Step: 10
Training loss: 2.2184793011652117
Validation loss: 2.5177129566832517

Epoch: 5| Step: 11
Training loss: 2.6730776751442775
Validation loss: 2.5320872778393877

Epoch: 50| Step: 0
Training loss: 2.150539188640812
Validation loss: 2.5380414660673445

Epoch: 5| Step: 1
Training loss: 2.1012318858058587
Validation loss: 2.558054242510424

Epoch: 5| Step: 2
Training loss: 2.258019672115512
Validation loss: 2.5447300945791023

Epoch: 5| Step: 3
Training loss: 2.1355296283400205
Validation loss: 2.5403141516615473

Epoch: 5| Step: 4
Training loss: 2.7780569370715877
Validation loss: 2.5549719610311827

Epoch: 5| Step: 5
Training loss: 2.880684416032577
Validation loss: 2.6031162540400303

Epoch: 5| Step: 6
Training loss: 1.9358267172827488
Validation loss: 2.5576641752828824

Epoch: 5| Step: 7
Training loss: 2.5742485727715776
Validation loss: 2.557110662846259

Epoch: 5| Step: 8
Training loss: 2.7875266240648906
Validation loss: 2.5588076009511447

Epoch: 5| Step: 9
Training loss: 2.257881559483959
Validation loss: 2.5459464746256715

Epoch: 5| Step: 10
Training loss: 2.757395423711492
Validation loss: 2.5733738092857124

Epoch: 5| Step: 11
Training loss: 4.3498393675863145
Validation loss: 2.560089796032444

Epoch: 51| Step: 0
Training loss: 2.7312956991671666
Validation loss: 2.549976952299043

Epoch: 5| Step: 1
Training loss: 2.5089389255854986
Validation loss: 2.5312303259756077

Epoch: 5| Step: 2
Training loss: 2.0779301831703516
Validation loss: 2.549027260982631

Epoch: 5| Step: 3
Training loss: 2.104718755930336
Validation loss: 2.565478667725954

Epoch: 5| Step: 4
Training loss: 3.0995586081026887
Validation loss: 2.5574073389829945

Epoch: 5| Step: 5
Training loss: 2.12299061185654
Validation loss: 2.5463274579758353

Epoch: 5| Step: 6
Training loss: 2.3969310291411126
Validation loss: 2.5330325941550695

Epoch: 5| Step: 7
Training loss: 2.251579683808744
Validation loss: 2.530296065478265

Epoch: 5| Step: 8
Training loss: 2.562924047600141
Validation loss: 2.536691382091823

Epoch: 5| Step: 9
Training loss: 2.535185779934429
Validation loss: 2.53319649363375

Epoch: 5| Step: 10
Training loss: 2.4520469289025706
Validation loss: 2.532560017368209

Epoch: 5| Step: 11
Training loss: 2.503066185344797
Validation loss: 2.5639043096282044

Epoch: 52| Step: 0
Training loss: 2.3505482054512097
Validation loss: 2.54182588099443

Epoch: 5| Step: 1
Training loss: 2.3724912142013093
Validation loss: 2.532800831219737

Epoch: 5| Step: 2
Training loss: 2.0894204539912806
Validation loss: 2.5327451513028927

Epoch: 5| Step: 3
Training loss: 3.0049548557337027
Validation loss: 2.5603439595944293

Epoch: 5| Step: 4
Training loss: 2.1442455108335845
Validation loss: 2.5389562320478816

Epoch: 5| Step: 5
Training loss: 3.202300621574286
Validation loss: 2.5707415036247148

Epoch: 5| Step: 6
Training loss: 2.261414713345897
Validation loss: 2.5611110272364996

Epoch: 5| Step: 7
Training loss: 2.409126247127196
Validation loss: 2.5518005460948587

Epoch: 5| Step: 8
Training loss: 2.3234035055909854
Validation loss: 2.5445873736465066

Epoch: 5| Step: 9
Training loss: 2.3314446457507736
Validation loss: 2.557123051747692

Epoch: 5| Step: 10
Training loss: 2.462594773071165
Validation loss: 2.5435989973970696

Epoch: 5| Step: 11
Training loss: 1.6539127484871003
Validation loss: 2.5618697492377076

Epoch: 53| Step: 0
Training loss: 2.6362450746406134
Validation loss: 2.568399937143807

Epoch: 5| Step: 1
Training loss: 2.508619517310147
Validation loss: 2.5357564167735194

Epoch: 5| Step: 2
Training loss: 3.0651037863852957
Validation loss: 2.564470305122572

Epoch: 5| Step: 3
Training loss: 2.630766393297032
Validation loss: 2.5625294629395836

Epoch: 5| Step: 4
Training loss: 2.5274020487504223
Validation loss: 2.57046877802376

Epoch: 5| Step: 5
Training loss: 2.530215393366465
Validation loss: 2.578668305919291

Epoch: 5| Step: 6
Training loss: 2.1788378737954885
Validation loss: 2.579801896483762

Epoch: 5| Step: 7
Training loss: 1.9016235993724377
Validation loss: 2.5464020311352984

Epoch: 5| Step: 8
Training loss: 2.2997337767730337
Validation loss: 2.527910356718603

Epoch: 5| Step: 9
Training loss: 2.4578850116449202
Validation loss: 2.5339552626219675

Epoch: 5| Step: 10
Training loss: 2.2339142010775346
Validation loss: 2.5356729624487744

Epoch: 5| Step: 11
Training loss: 2.029171158657024
Validation loss: 2.532855141100544

Epoch: 54| Step: 0
Training loss: 2.308916976169615
Validation loss: 2.548341488817869

Epoch: 5| Step: 1
Training loss: 2.8181486414469528
Validation loss: 2.533066866741222

Epoch: 5| Step: 2
Training loss: 2.839398586637894
Validation loss: 2.5597462977484953

Epoch: 5| Step: 3
Training loss: 1.867938987785204
Validation loss: 2.5624366031340813

Epoch: 5| Step: 4
Training loss: 2.0659324521066704
Validation loss: 2.5539311641653764

Epoch: 5| Step: 5
Training loss: 2.5264991162523347
Validation loss: 2.5446873730276836

Epoch: 5| Step: 6
Training loss: 2.5442405134025874
Validation loss: 2.550001238373848

Epoch: 5| Step: 7
Training loss: 2.725725542823827
Validation loss: 2.576174539598885

Epoch: 5| Step: 8
Training loss: 2.3502034160151264
Validation loss: 2.5494837983309813

Epoch: 5| Step: 9
Training loss: 2.114320735567705
Validation loss: 2.5820535686719097

Epoch: 5| Step: 10
Training loss: 2.4707509876786924
Validation loss: 2.569445018224108

Epoch: 5| Step: 11
Training loss: 2.79362486488642
Validation loss: 2.5770054014156973

Epoch: 55| Step: 0
Training loss: 2.587187404455171
Validation loss: 2.5556102373370506

Epoch: 5| Step: 1
Training loss: 2.7653003221869423
Validation loss: 2.5320218561679524

Epoch: 5| Step: 2
Training loss: 2.3188724865912365
Validation loss: 2.524091047407587

Epoch: 5| Step: 3
Training loss: 2.9453307943003626
Validation loss: 2.5306504917156283

Epoch: 5| Step: 4
Training loss: 2.1180590422832646
Validation loss: 2.552665797088062

Epoch: 5| Step: 5
Training loss: 1.9755842479447792
Validation loss: 2.5442549797092586

Epoch: 5| Step: 6
Training loss: 1.3670104429854895
Validation loss: 2.5353941215593134

Epoch: 5| Step: 7
Training loss: 2.142854629242649
Validation loss: 2.5201718701273843

Epoch: 5| Step: 8
Training loss: 2.857313069314285
Validation loss: 2.5451873539335828

Epoch: 5| Step: 9
Training loss: 2.488512923685569
Validation loss: 2.5376920591372807

Epoch: 5| Step: 10
Training loss: 2.945142017560626
Validation loss: 2.522585013273648

Epoch: 5| Step: 11
Training loss: 1.047241602234034
Validation loss: 2.5451760739646874

Epoch: 56| Step: 0
Training loss: 2.8722743506981905
Validation loss: 2.509377871393356

Epoch: 5| Step: 1
Training loss: 2.2392788938851744
Validation loss: 2.5316573784561327

Epoch: 5| Step: 2
Training loss: 2.150202244849564
Validation loss: 2.527457716670215

Epoch: 5| Step: 3
Training loss: 1.6221445377828514
Validation loss: 2.5400305540926684

Epoch: 5| Step: 4
Training loss: 1.6502371993219274
Validation loss: 2.519897323943734

Epoch: 5| Step: 5
Training loss: 2.330179012445504
Validation loss: 2.542067559993695

Epoch: 5| Step: 6
Training loss: 2.424243580933497
Validation loss: 2.542038070923107

Epoch: 5| Step: 7
Training loss: 3.088452205466625
Validation loss: 2.527777658641263

Epoch: 5| Step: 8
Training loss: 2.701702383026112
Validation loss: 2.5148466932049036

Epoch: 5| Step: 9
Training loss: 2.685159950819842
Validation loss: 2.5317551732764283

Epoch: 5| Step: 10
Training loss: 2.757022387867859
Validation loss: 2.5410006750176724

Epoch: 5| Step: 11
Training loss: 2.799425464676903
Validation loss: 2.541300326404279

Epoch: 57| Step: 0
Training loss: 2.3791157046158364
Validation loss: 2.5308625587992486

Epoch: 5| Step: 1
Training loss: 2.2351259690186573
Validation loss: 2.52900931786937

Epoch: 5| Step: 2
Training loss: 2.245317885698351
Validation loss: 2.5493475412765254

Epoch: 5| Step: 3
Training loss: 2.242635861537132
Validation loss: 2.5288733482479264

Epoch: 5| Step: 4
Training loss: 2.0401974146820314
Validation loss: 2.541102574762044

Epoch: 5| Step: 5
Training loss: 2.2930245855704463
Validation loss: 2.5508564134226797

Epoch: 5| Step: 6
Training loss: 1.820900097749766
Validation loss: 2.567034868411216

Epoch: 5| Step: 7
Training loss: 3.0814906275883818
Validation loss: 2.5639382179789347

Epoch: 5| Step: 8
Training loss: 2.5206775984985685
Validation loss: 2.60159611799573

Epoch: 5| Step: 9
Training loss: 3.1418738468032217
Validation loss: 2.5799100764816054

Epoch: 5| Step: 10
Training loss: 2.6221867881776664
Validation loss: 2.566880364754155

Epoch: 5| Step: 11
Training loss: 2.373874498008204
Validation loss: 2.5526341674251767

Epoch: 58| Step: 0
Training loss: 1.8445595079492798
Validation loss: 2.568632088652047

Epoch: 5| Step: 1
Training loss: 1.9108617061078452
Validation loss: 2.5505329768742344

Epoch: 5| Step: 2
Training loss: 2.5594488447665937
Validation loss: 2.567907415929701

Epoch: 5| Step: 3
Training loss: 2.8684666246397854
Validation loss: 2.5603630180315045

Epoch: 5| Step: 4
Training loss: 2.446158460835098
Validation loss: 2.5323106090026006

Epoch: 5| Step: 5
Training loss: 2.397015078354359
Validation loss: 2.5688688655215306

Epoch: 5| Step: 6
Training loss: 3.4188246696170355
Validation loss: 2.534795377857205

Epoch: 5| Step: 7
Training loss: 1.8101550751321311
Validation loss: 2.5116537668098964

Epoch: 5| Step: 8
Training loss: 2.210707366073277
Validation loss: 2.5310203032021508

Epoch: 5| Step: 9
Training loss: 2.426050733257521
Validation loss: 2.5392102477295344

Epoch: 5| Step: 10
Training loss: 2.781627843672363
Validation loss: 2.5302431906420146

Epoch: 5| Step: 11
Training loss: 0.627738175917716
Validation loss: 2.5380569344801267

Epoch: 59| Step: 0
Training loss: 2.69922864280025
Validation loss: 2.5324827104626633

Epoch: 5| Step: 1
Training loss: 2.448919007182854
Validation loss: 2.503324261503718

Epoch: 5| Step: 2
Training loss: 2.8686562915531346
Validation loss: 2.5331906661739754

Epoch: 5| Step: 3
Training loss: 2.4087852894326547
Validation loss: 2.544583239291185

Epoch: 5| Step: 4
Training loss: 2.2902634110188735
Validation loss: 2.5225558517228692

Epoch: 5| Step: 5
Training loss: 2.3090912723336174
Validation loss: 2.531322101460935

Epoch: 5| Step: 6
Training loss: 2.5101064487697076
Validation loss: 2.529780789579967

Epoch: 5| Step: 7
Training loss: 2.752961558103031
Validation loss: 2.521970533115888

Epoch: 5| Step: 8
Training loss: 1.7304243852770975
Validation loss: 2.5360873588804407

Epoch: 5| Step: 9
Training loss: 2.493377210244599
Validation loss: 2.538356917719024

Epoch: 5| Step: 10
Training loss: 2.4658554104865975
Validation loss: 2.534335598715772

Epoch: 5| Step: 11
Training loss: 1.5163325594999786
Validation loss: 2.511829031683195

Epoch: 60| Step: 0
Training loss: 2.686927734482189
Validation loss: 2.547855531692581

Epoch: 5| Step: 1
Training loss: 2.0876099243460278
Validation loss: 2.5561641776640767

Epoch: 5| Step: 2
Training loss: 2.0575746623290123
Validation loss: 2.551997978703427

Epoch: 5| Step: 3
Training loss: 2.2123484069270853
Validation loss: 2.5873800289825706

Epoch: 5| Step: 4
Training loss: 2.120351081783857
Validation loss: 2.571281049643227

Epoch: 5| Step: 5
Training loss: 2.403441040528482
Validation loss: 2.5841702725720417

Epoch: 5| Step: 6
Training loss: 2.6559939092715643
Validation loss: 2.6111441685114833

Epoch: 5| Step: 7
Training loss: 2.6981173309365634
Validation loss: 2.6233357913984476

Epoch: 5| Step: 8
Training loss: 2.704119019953128
Validation loss: 2.6234074295316905

Epoch: 5| Step: 9
Training loss: 2.4310310794753325
Validation loss: 2.624692168427116

Epoch: 5| Step: 10
Training loss: 2.8214459875717828
Validation loss: 2.611873796999325

Epoch: 5| Step: 11
Training loss: 2.433462075089406
Validation loss: 2.594074006889375

Epoch: 61| Step: 0
Training loss: 1.9876013532023238
Validation loss: 2.5773615159363565

Epoch: 5| Step: 1
Training loss: 2.521609373414583
Validation loss: 2.5772930729618873

Epoch: 5| Step: 2
Training loss: 2.8352369383711307
Validation loss: 2.5556849633211165

Epoch: 5| Step: 3
Training loss: 2.5795703882151284
Validation loss: 2.5575373402750534

Epoch: 5| Step: 4
Training loss: 2.308445443232281
Validation loss: 2.5170064967231633

Epoch: 5| Step: 5
Training loss: 2.1519070440161734
Validation loss: 2.520507162183451

Epoch: 5| Step: 6
Training loss: 2.080294745542689
Validation loss: 2.53655533862931

Epoch: 5| Step: 7
Training loss: 2.301789093776092
Validation loss: 2.5357237123452316

Epoch: 5| Step: 8
Training loss: 2.918937634598049
Validation loss: 2.528750677059961

Epoch: 5| Step: 9
Training loss: 2.0164147537566475
Validation loss: 2.5166444943779736

Epoch: 5| Step: 10
Training loss: 3.049686484560957
Validation loss: 2.531547611307217

Epoch: 5| Step: 11
Training loss: 1.6166638987147175
Validation loss: 2.535618642401457

Epoch: 62| Step: 0
Training loss: 2.737196507461418
Validation loss: 2.553168211547539

Epoch: 5| Step: 1
Training loss: 2.4776466475581724
Validation loss: 2.5409462303793875

Epoch: 5| Step: 2
Training loss: 2.2600368643598228
Validation loss: 2.5361809327529286

Epoch: 5| Step: 3
Training loss: 2.049342989891166
Validation loss: 2.539744026465941

Epoch: 5| Step: 4
Training loss: 2.6881755600772945
Validation loss: 2.5627690770989067

Epoch: 5| Step: 5
Training loss: 3.2466620396523007
Validation loss: 2.575069362206168

Epoch: 5| Step: 6
Training loss: 2.1053247066334753
Validation loss: 2.5610102552591916

Epoch: 5| Step: 7
Training loss: 2.1204135991551114
Validation loss: 2.579282495001305

Epoch: 5| Step: 8
Training loss: 2.4089671065514318
Validation loss: 2.602210051141567

Epoch: 5| Step: 9
Training loss: 1.9145545794043874
Validation loss: 2.5678797400924327

Epoch: 5| Step: 10
Training loss: 2.129821468626001
Validation loss: 2.6023476325671977

Epoch: 5| Step: 11
Training loss: 4.188501722171753
Validation loss: 2.558416718626535

Epoch: 63| Step: 0
Training loss: 2.5285439803055345
Validation loss: 2.5691593485973496

Epoch: 5| Step: 1
Training loss: 2.2990637490757955
Validation loss: 2.541348407445558

Epoch: 5| Step: 2
Training loss: 1.849149395021241
Validation loss: 2.5406796318520994

Epoch: 5| Step: 3
Training loss: 2.1815777857515015
Validation loss: 2.528665482942009

Epoch: 5| Step: 4
Training loss: 2.840041036980952
Validation loss: 2.5322301266085248

Epoch: 5| Step: 5
Training loss: 2.2804177216129475
Validation loss: 2.532946893012054

Epoch: 5| Step: 6
Training loss: 2.652640010147909
Validation loss: 2.5431627198605815

Epoch: 5| Step: 7
Training loss: 2.825949575121458
Validation loss: 2.5382931565866196

Epoch: 5| Step: 8
Training loss: 2.417616021923595
Validation loss: 2.556747671304616

Epoch: 5| Step: 9
Training loss: 2.1586681572663737
Validation loss: 2.545609938148242

Epoch: 5| Step: 10
Training loss: 2.860606944364941
Validation loss: 2.551279378625583

Epoch: 5| Step: 11
Training loss: 2.1075535574880804
Validation loss: 2.5424577518955247

Epoch: 64| Step: 0
Training loss: 2.154237333081862
Validation loss: 2.525035604062242

Epoch: 5| Step: 1
Training loss: 1.8085569703418036
Validation loss: 2.516946611297417

Epoch: 5| Step: 2
Training loss: 2.8531997787854135
Validation loss: 2.510620476270175

Epoch: 5| Step: 3
Training loss: 1.9408672973928092
Validation loss: 2.538570849428694

Epoch: 5| Step: 4
Training loss: 2.6564699867257593
Validation loss: 2.5586690915883756

Epoch: 5| Step: 5
Training loss: 2.4289394588660347
Validation loss: 2.5332838686288346

Epoch: 5| Step: 6
Training loss: 2.45061310862288
Validation loss: 2.5444822773423965

Epoch: 5| Step: 7
Training loss: 2.932553936266361
Validation loss: 2.5396526159537527

Epoch: 5| Step: 8
Training loss: 2.5297311063970036
Validation loss: 2.560122224117741

Epoch: 5| Step: 9
Training loss: 2.5355765019368026
Validation loss: 2.539360066118893

Epoch: 5| Step: 10
Training loss: 2.444651163877848
Validation loss: 2.554757046311877

Epoch: 5| Step: 11
Training loss: 1.5933529228272463
Validation loss: 2.5511867128889945

Epoch: 65| Step: 0
Training loss: 2.438074679976313
Validation loss: 2.5413408435371654

Epoch: 5| Step: 1
Training loss: 2.7647865015696014
Validation loss: 2.568237471981283

Epoch: 5| Step: 2
Training loss: 1.5690984635295302
Validation loss: 2.5847614068649345

Epoch: 5| Step: 3
Training loss: 2.6409875744979083
Validation loss: 2.593923019092405

Epoch: 5| Step: 4
Training loss: 2.6630377714405666
Validation loss: 2.594842596382489

Epoch: 5| Step: 5
Training loss: 2.500355027739059
Validation loss: 2.61199315765579

Epoch: 5| Step: 6
Training loss: 2.7135090792426557
Validation loss: 2.5990290100232087

Epoch: 5| Step: 7
Training loss: 2.48240160990081
Validation loss: 2.583910878799696

Epoch: 5| Step: 8
Training loss: 2.2181087158155712
Validation loss: 2.563418200600527

Epoch: 5| Step: 9
Training loss: 2.6212135435378814
Validation loss: 2.568475961879511

Epoch: 5| Step: 10
Training loss: 2.0880767482376603
Validation loss: 2.57456356241842

Epoch: 5| Step: 11
Training loss: 1.936327117802687
Validation loss: 2.568440108003401

Epoch: 66| Step: 0
Training loss: 2.3419179240829235
Validation loss: 2.533206372049408

Epoch: 5| Step: 1
Training loss: 2.9836482416387464
Validation loss: 2.550688129962717

Epoch: 5| Step: 2
Training loss: 1.890814842592123
Validation loss: 2.5472156456771486

Epoch: 5| Step: 3
Training loss: 1.99300867247812
Validation loss: 2.5096051235309624

Epoch: 5| Step: 4
Training loss: 2.2948417746991927
Validation loss: 2.5231953633667557

Epoch: 5| Step: 5
Training loss: 2.201262857203543
Validation loss: 2.544214868206582

Epoch: 5| Step: 6
Training loss: 2.6994769225472166
Validation loss: 2.5306489882427856

Epoch: 5| Step: 7
Training loss: 2.5831514314987807
Validation loss: 2.514911943474737

Epoch: 5| Step: 8
Training loss: 2.564066152436365
Validation loss: 2.5227811449876842

Epoch: 5| Step: 9
Training loss: 2.894910450342623
Validation loss: 2.524003360082689

Epoch: 5| Step: 10
Training loss: 2.111946855165387
Validation loss: 2.5485388580691803

Epoch: 5| Step: 11
Training loss: 2.0115551928354445
Validation loss: 2.5318129270677643

Epoch: 67| Step: 0
Training loss: 2.5460058496172784
Validation loss: 2.5359287858031

Epoch: 5| Step: 1
Training loss: 3.0760137608174447
Validation loss: 2.5206314996568877

Epoch: 5| Step: 2
Training loss: 2.676427699055494
Validation loss: 2.5562474099218404

Epoch: 5| Step: 3
Training loss: 2.122145025181845
Validation loss: 2.547795131453681

Epoch: 5| Step: 4
Training loss: 2.4501038432009903
Validation loss: 2.5423858333875553

Epoch: 5| Step: 5
Training loss: 2.3901579157480652
Validation loss: 2.538780474527615

Epoch: 5| Step: 6
Training loss: 2.461788163678912
Validation loss: 2.5695098195622927

Epoch: 5| Step: 7
Training loss: 1.8743184440401768
Validation loss: 2.5756459387366504

Epoch: 5| Step: 8
Training loss: 2.216630810134493
Validation loss: 2.566407297057737

Epoch: 5| Step: 9
Training loss: 2.38169799755605
Validation loss: 2.582830539093439

Epoch: 5| Step: 10
Training loss: 2.4181831030669487
Validation loss: 2.591474929434627

Epoch: 5| Step: 11
Training loss: 1.7578188069548313
Validation loss: 2.5812071246326322

Epoch: 68| Step: 0
Training loss: 1.797536844186309
Validation loss: 2.5663305684644278

Epoch: 5| Step: 1
Training loss: 1.9951444933008133
Validation loss: 2.561270678672391

Epoch: 5| Step: 2
Training loss: 2.3430817732304865
Validation loss: 2.5555449319413643

Epoch: 5| Step: 3
Training loss: 2.4610936675399566
Validation loss: 2.5663151214383815

Epoch: 5| Step: 4
Training loss: 2.300014918735052
Validation loss: 2.518105585063345

Epoch: 5| Step: 5
Training loss: 3.0203625717788323
Validation loss: 2.52630188312824

Epoch: 5| Step: 6
Training loss: 2.1778633387402904
Validation loss: 2.5305528975955625

Epoch: 5| Step: 7
Training loss: 2.6525528253729544
Validation loss: 2.524056227881163

Epoch: 5| Step: 8
Training loss: 2.213061926222227
Validation loss: 2.53131437023559

Epoch: 5| Step: 9
Training loss: 2.3741215536915714
Validation loss: 2.535479332508099

Epoch: 5| Step: 10
Training loss: 2.7227760408995234
Validation loss: 2.5490235820089477

Epoch: 5| Step: 11
Training loss: 3.4192526885357686
Validation loss: 2.5472451586564846

Epoch: 69| Step: 0
Training loss: 2.124888024465316
Validation loss: 2.5276280891255327

Epoch: 5| Step: 1
Training loss: 1.9065823499780765
Validation loss: 2.505254028654347

Epoch: 5| Step: 2
Training loss: 3.003669719536024
Validation loss: 2.5100271442485647

Epoch: 5| Step: 3
Training loss: 2.3228123617204277
Validation loss: 2.55093511065782

Epoch: 5| Step: 4
Training loss: 2.153282666904489
Validation loss: 2.543920007971557

Epoch: 5| Step: 5
Training loss: 2.2572791713714375
Validation loss: 2.5255135911672615

Epoch: 5| Step: 6
Training loss: 2.5657244608437924
Validation loss: 2.5379390128510986

Epoch: 5| Step: 7
Training loss: 2.7031141512438097
Validation loss: 2.5446810448600705

Epoch: 5| Step: 8
Training loss: 2.627055952477509
Validation loss: 2.5377911323944593

Epoch: 5| Step: 9
Training loss: 2.6341337516616474
Validation loss: 2.5274815313014747

Epoch: 5| Step: 10
Training loss: 2.4261745557891525
Validation loss: 2.53266094859624

Epoch: 5| Step: 11
Training loss: 2.122673893287632
Validation loss: 2.512430089322702

Epoch: 70| Step: 0
Training loss: 2.3197620907836463
Validation loss: 2.523536794340694

Epoch: 5| Step: 1
Training loss: 2.496375508293126
Validation loss: 2.5114554489184577

Epoch: 5| Step: 2
Training loss: 2.8801215620346943
Validation loss: 2.5134097014205325

Epoch: 5| Step: 3
Training loss: 2.1693207794948504
Validation loss: 2.5206829228466785

Epoch: 5| Step: 4
Training loss: 2.655166943720006
Validation loss: 2.532039122945396

Epoch: 5| Step: 5
Training loss: 2.202342009230755
Validation loss: 2.527539960505694

Epoch: 5| Step: 6
Training loss: 2.658396672497761
Validation loss: 2.546017141517196

Epoch: 5| Step: 7
Training loss: 1.9487754302356735
Validation loss: 2.552335179157577

Epoch: 5| Step: 8
Training loss: 1.7877425609418378
Validation loss: 2.5413683549471604

Epoch: 5| Step: 9
Training loss: 2.6288473000796815
Validation loss: 2.5783378436150417

Epoch: 5| Step: 10
Training loss: 2.332110072965154
Validation loss: 2.5711639572831

Epoch: 5| Step: 11
Training loss: 3.4775460555690008
Validation loss: 2.5636186600311492

Epoch: 71| Step: 0
Training loss: 2.511590696306854
Validation loss: 2.543936994835551

Epoch: 5| Step: 1
Training loss: 2.266702014516581
Validation loss: 2.552256392755012

Epoch: 5| Step: 2
Training loss: 2.2324026512459705
Validation loss: 2.584323740631099

Epoch: 5| Step: 3
Training loss: 2.7043647348743804
Validation loss: 2.550599107767459

Epoch: 5| Step: 4
Training loss: 2.6017523802233846
Validation loss: 2.566043226171339

Epoch: 5| Step: 5
Training loss: 2.677214167820426
Validation loss: 2.550728194194677

Epoch: 5| Step: 6
Training loss: 2.052909749213425
Validation loss: 2.54177655441082

Epoch: 5| Step: 7
Training loss: 2.4267162542027583
Validation loss: 2.5548527982004594

Epoch: 5| Step: 8
Training loss: 2.9037430317894053
Validation loss: 2.5548567098561383

Epoch: 5| Step: 9
Training loss: 2.5129129706180415
Validation loss: 2.5225351115707757

Epoch: 5| Step: 10
Training loss: 1.407538480689998
Validation loss: 2.5245332258126685

Epoch: 5| Step: 11
Training loss: 1.5685626096623966
Validation loss: 2.5389402506815544

Epoch: 72| Step: 0
Training loss: 2.7845549074699254
Validation loss: 2.5235694953087164

Epoch: 5| Step: 1
Training loss: 2.5978953316023303
Validation loss: 2.5218467225510603

Epoch: 5| Step: 2
Training loss: 2.346051522966426
Validation loss: 2.5352128526572786

Epoch: 5| Step: 3
Training loss: 1.7050958831316811
Validation loss: 2.511602621523386

Epoch: 5| Step: 4
Training loss: 2.752397619105206
Validation loss: 2.52032315527281

Epoch: 5| Step: 5
Training loss: 1.9970903092481438
Validation loss: 2.515359690795357

Epoch: 5| Step: 6
Training loss: 1.9868992647343509
Validation loss: 2.5284161422444136

Epoch: 5| Step: 7
Training loss: 2.9165005954510965
Validation loss: 2.5349777111789087

Epoch: 5| Step: 8
Training loss: 2.7002886405944073
Validation loss: 2.5160679476593772

Epoch: 5| Step: 9
Training loss: 2.232935088031186
Validation loss: 2.526184279882929

Epoch: 5| Step: 10
Training loss: 2.1565166806045313
Validation loss: 2.5361814693757543

Epoch: 5| Step: 11
Training loss: 2.7051121458262286
Validation loss: 2.535335595165103

Epoch: 73| Step: 0
Training loss: 3.263854792712163
Validation loss: 2.5520887932751437

Epoch: 5| Step: 1
Training loss: 2.077865010683926
Validation loss: 2.5177837018585074

Epoch: 5| Step: 2
Training loss: 2.5500403083158596
Validation loss: 2.521580531510112

Epoch: 5| Step: 3
Training loss: 2.22361179722173
Validation loss: 2.5641280871582093

Epoch: 5| Step: 4
Training loss: 2.439143482650227
Validation loss: 2.508158328176082

Epoch: 5| Step: 5
Training loss: 2.607839075207939
Validation loss: 2.556038424465237

Epoch: 5| Step: 6
Training loss: 2.566447125578213
Validation loss: 2.5467288944641417

Epoch: 5| Step: 7
Training loss: 2.194018651265766
Validation loss: 2.5395616363545703

Epoch: 5| Step: 8
Training loss: 2.212166057320547
Validation loss: 2.5372337759137396

Epoch: 5| Step: 9
Training loss: 1.965681136501686
Validation loss: 2.537969132764514

Epoch: 5| Step: 10
Training loss: 1.9649508316256101
Validation loss: 2.5600444340512856

Epoch: 5| Step: 11
Training loss: 3.352656401556744
Validation loss: 2.5469218251735124

Epoch: 74| Step: 0
Training loss: 2.311930199608926
Validation loss: 2.527560535785099

Epoch: 5| Step: 1
Training loss: 2.641597501007737
Validation loss: 2.5375648346183315

Epoch: 5| Step: 2
Training loss: 2.1744364172717416
Validation loss: 2.5238576427080326

Epoch: 5| Step: 3
Training loss: 2.280994557750051
Validation loss: 2.5495716632796834

Epoch: 5| Step: 4
Training loss: 2.9071096153942957
Validation loss: 2.5147994643601295

Epoch: 5| Step: 5
Training loss: 2.5444169615862804
Validation loss: 2.5101302182663976

Epoch: 5| Step: 6
Training loss: 2.174844043445821
Validation loss: 2.5164634578865406

Epoch: 5| Step: 7
Training loss: 1.8294618723175933
Validation loss: 2.510163936846611

Epoch: 5| Step: 8
Training loss: 2.6518014794523705
Validation loss: 2.5250658739580647

Epoch: 5| Step: 9
Training loss: 2.313350211896344
Validation loss: 2.5294968966580464

Epoch: 5| Step: 10
Training loss: 2.5008547275453914
Validation loss: 2.531380391000311

Epoch: 5| Step: 11
Training loss: 2.4635889695339452
Validation loss: 2.556415782082441

Epoch: 75| Step: 0
Training loss: 1.925447260928564
Validation loss: 2.5233584884698215

Epoch: 5| Step: 1
Training loss: 2.5234768040669726
Validation loss: 2.5413961553192337

Epoch: 5| Step: 2
Training loss: 2.0426374060964476
Validation loss: 2.5656550491995618

Epoch: 5| Step: 3
Training loss: 2.4200237459010805
Validation loss: 2.5459439149576517

Epoch: 5| Step: 4
Training loss: 2.5722550585275568
Validation loss: 2.5528830417109853

Epoch: 5| Step: 5
Training loss: 2.8297918476347235
Validation loss: 2.5582566211477697

Epoch: 5| Step: 6
Training loss: 2.2923907667654024
Validation loss: 2.5681486519548864

Epoch: 5| Step: 7
Training loss: 2.2984746435964567
Validation loss: 2.575093623807986

Epoch: 5| Step: 8
Training loss: 2.9215864559231504
Validation loss: 2.5727410983726533

Epoch: 5| Step: 9
Training loss: 1.6222923903045015
Validation loss: 2.5882368707848613

Epoch: 5| Step: 10
Training loss: 2.7831503558594015
Validation loss: 2.5828768816564485

Epoch: 5| Step: 11
Training loss: 2.5324821769787618
Validation loss: 2.5842146344383425

Epoch: 76| Step: 0
Training loss: 2.343983142701031
Validation loss: 2.540848828411637

Epoch: 5| Step: 1
Training loss: 2.112586621195842
Validation loss: 2.582284261875736

Epoch: 5| Step: 2
Training loss: 2.558797720430118
Validation loss: 2.5239447604475798

Epoch: 5| Step: 3
Training loss: 2.046871971535808
Validation loss: 2.5528789149533915

Epoch: 5| Step: 4
Training loss: 1.9782238036153927
Validation loss: 2.547744376366161

Epoch: 5| Step: 5
Training loss: 2.0948465237357636
Validation loss: 2.5254630904238615

Epoch: 5| Step: 6
Training loss: 2.7110498058791315
Validation loss: 2.52953604766512

Epoch: 5| Step: 7
Training loss: 2.2081642685958105
Validation loss: 2.531392595803603

Epoch: 5| Step: 8
Training loss: 2.0490617791576433
Validation loss: 2.528740447317507

Epoch: 5| Step: 9
Training loss: 3.0691602257909487
Validation loss: 2.53573111279723

Epoch: 5| Step: 10
Training loss: 2.628668809798771
Validation loss: 2.5429552647261886

Epoch: 5| Step: 11
Training loss: 3.0792636991981084
Validation loss: 2.515300407950903

Epoch: 77| Step: 0
Training loss: 2.122496982028644
Validation loss: 2.533669524148247

Epoch: 5| Step: 1
Training loss: 2.289465129972471
Validation loss: 2.5354439602032954

Epoch: 5| Step: 2
Training loss: 1.866901583308299
Validation loss: 2.537424173224376

Epoch: 5| Step: 3
Training loss: 2.553632885996511
Validation loss: 2.5290025930168882

Epoch: 5| Step: 4
Training loss: 2.0419819127850065
Validation loss: 2.547020796832822

Epoch: 5| Step: 5
Training loss: 3.2927120013620343
Validation loss: 2.508162025503471

Epoch: 5| Step: 6
Training loss: 2.5231401486777116
Validation loss: 2.5409040629364865

Epoch: 5| Step: 7
Training loss: 2.37243302808484
Validation loss: 2.509357723035675

Epoch: 5| Step: 8
Training loss: 2.3586961388515797
Validation loss: 2.526965632348492

Epoch: 5| Step: 9
Training loss: 2.2734747290430595
Validation loss: 2.533521414088901

Epoch: 5| Step: 10
Training loss: 2.4579362279132226
Validation loss: 2.521615767361298

Epoch: 5| Step: 11
Training loss: 2.4500521712684518
Validation loss: 2.5494812539039824

Epoch: 78| Step: 0
Training loss: 2.4114526758203128
Validation loss: 2.5184996077377115

Epoch: 5| Step: 1
Training loss: 2.8023272175403573
Validation loss: 2.533906323849138

Epoch: 5| Step: 2
Training loss: 2.092110518619688
Validation loss: 2.5358182555105704

Epoch: 5| Step: 3
Training loss: 1.9917655946856758
Validation loss: 2.5308072680187332

Epoch: 5| Step: 4
Training loss: 2.3173809606108278
Validation loss: 2.543232835221065

Epoch: 5| Step: 5
Training loss: 2.465579254151486
Validation loss: 2.551216152673131

Epoch: 5| Step: 6
Training loss: 2.526746723580928
Validation loss: 2.5507867451833017

Epoch: 5| Step: 7
Training loss: 2.447719961068361
Validation loss: 2.580954619156618

Epoch: 5| Step: 8
Training loss: 2.287277306728407
Validation loss: 2.558278510399901

Epoch: 5| Step: 9
Training loss: 2.6007549876992413
Validation loss: 2.555811211996384

Epoch: 5| Step: 10
Training loss: 2.3612772365794497
Validation loss: 2.558553688570452

Epoch: 5| Step: 11
Training loss: 1.3840371436498522
Validation loss: 2.53746093710537

Epoch: 79| Step: 0
Training loss: 2.5074706988462516
Validation loss: 2.5755058779280673

Epoch: 5| Step: 1
Training loss: 2.30915786899344
Validation loss: 2.5762632872911166

Epoch: 5| Step: 2
Training loss: 2.542665712550757
Validation loss: 2.5875289856243944

Epoch: 5| Step: 3
Training loss: 2.3205355655810815
Validation loss: 2.5978061068721687

Epoch: 5| Step: 4
Training loss: 2.7814182702070456
Validation loss: 2.58424465322764

Epoch: 5| Step: 5
Training loss: 1.7999868895794995
Validation loss: 2.5467719308791312

Epoch: 5| Step: 6
Training loss: 2.110535027165177
Validation loss: 2.57411490401189

Epoch: 5| Step: 7
Training loss: 2.295692814324621
Validation loss: 2.5766745581316877

Epoch: 5| Step: 8
Training loss: 2.617921549782233
Validation loss: 2.5792490964996837

Epoch: 5| Step: 9
Training loss: 2.3912424524310776
Validation loss: 2.533514995293928

Epoch: 5| Step: 10
Training loss: 2.549290266562381
Validation loss: 2.533914807735207

Epoch: 5| Step: 11
Training loss: 2.4516760562152458
Validation loss: 2.5475460798783596

Epoch: 80| Step: 0
Training loss: 2.1259913656466716
Validation loss: 2.5204398594253368

Epoch: 5| Step: 1
Training loss: 2.773738533123531
Validation loss: 2.515029102141895

Epoch: 5| Step: 2
Training loss: 2.4129140152738513
Validation loss: 2.538280671866067

Epoch: 5| Step: 3
Training loss: 2.356730513816163
Validation loss: 2.540152737250438

Epoch: 5| Step: 4
Training loss: 2.1568861313264316
Validation loss: 2.550086841631658

Epoch: 5| Step: 5
Training loss: 2.5189273554074694
Validation loss: 2.5350532843904268

Epoch: 5| Step: 6
Training loss: 2.7933006249502856
Validation loss: 2.545142495270019

Epoch: 5| Step: 7
Training loss: 2.9664032344084457
Validation loss: 2.519380412157839

Epoch: 5| Step: 8
Training loss: 2.4154556353219356
Validation loss: 2.520365365521024

Epoch: 5| Step: 9
Training loss: 2.0842408556001466
Validation loss: 2.5340713585624135

Epoch: 5| Step: 10
Training loss: 1.872311890426635
Validation loss: 2.5447758095729074

Epoch: 5| Step: 11
Training loss: 2.2953145441990133
Validation loss: 2.5236165324693904

Epoch: 81| Step: 0
Training loss: 2.3043752685083203
Validation loss: 2.5279580852952344

Epoch: 5| Step: 1
Training loss: 2.101551382042501
Validation loss: 2.5572596384180644

Epoch: 5| Step: 2
Training loss: 2.9317040585867105
Validation loss: 2.5609071363193334

Epoch: 5| Step: 3
Training loss: 2.3414350139389972
Validation loss: 2.5585242303231817

Epoch: 5| Step: 4
Training loss: 2.184173124969183
Validation loss: 2.566759279724955

Epoch: 5| Step: 5
Training loss: 2.1999878969726563
Validation loss: 2.609541139624464

Epoch: 5| Step: 6
Training loss: 2.8624767718976027
Validation loss: 2.583040925879135

Epoch: 5| Step: 7
Training loss: 2.4138304960004193
Validation loss: 2.5970193335447926

Epoch: 5| Step: 8
Training loss: 2.1218975082799196
Validation loss: 2.6071398788529696

Epoch: 5| Step: 9
Training loss: 1.8496207183522282
Validation loss: 2.6071888718336047

Epoch: 5| Step: 10
Training loss: 2.738323216790125
Validation loss: 2.6053630706386377

Epoch: 5| Step: 11
Training loss: 2.2681565446465437
Validation loss: 2.600397653003387

Epoch: 82| Step: 0
Training loss: 2.3710006368789878
Validation loss: 2.572865297728781

Epoch: 5| Step: 1
Training loss: 2.2226167752426065
Validation loss: 2.5877440980899173

Epoch: 5| Step: 2
Training loss: 2.203330821710599
Validation loss: 2.5835614501053756

Epoch: 5| Step: 3
Training loss: 1.8635756541934614
Validation loss: 2.5803840527063926

Epoch: 5| Step: 4
Training loss: 2.600254222472175
Validation loss: 2.543575403968401

Epoch: 5| Step: 5
Training loss: 2.1626151302318144
Validation loss: 2.5579291414771825

Epoch: 5| Step: 6
Training loss: 2.8738968432767202
Validation loss: 2.5341058679901955

Epoch: 5| Step: 7
Training loss: 2.639810380050213
Validation loss: 2.5639480786903586

Epoch: 5| Step: 8
Training loss: 1.987910567768469
Validation loss: 2.530773426058024

Epoch: 5| Step: 9
Training loss: 2.248164275788448
Validation loss: 2.534963677865269

Epoch: 5| Step: 10
Training loss: 2.8638162776582186
Validation loss: 2.543276450296827

Epoch: 5| Step: 11
Training loss: 1.0655278091632427
Validation loss: 2.5488890035284286

Epoch: 83| Step: 0
Training loss: 2.5449842678100936
Validation loss: 2.509121609598618

Epoch: 5| Step: 1
Training loss: 2.2492749847452473
Validation loss: 2.512896667470041

Epoch: 5| Step: 2
Training loss: 1.9667684482918082
Validation loss: 2.5185927661444416

Epoch: 5| Step: 3
Training loss: 2.3612338190044317
Validation loss: 2.527132802784631

Epoch: 5| Step: 4
Training loss: 1.790984541395514
Validation loss: 2.5301720910416754

Epoch: 5| Step: 5
Training loss: 2.8195119128326493
Validation loss: 2.4881142760365655

Epoch: 5| Step: 6
Training loss: 2.645513400061006
Validation loss: 2.5444557619907417

Epoch: 5| Step: 7
Training loss: 2.345162131554833
Validation loss: 2.520723396983127

Epoch: 5| Step: 8
Training loss: 2.8514437716079204
Validation loss: 2.5291986237716513

Epoch: 5| Step: 9
Training loss: 2.364750277861903
Validation loss: 2.5274559243733234

Epoch: 5| Step: 10
Training loss: 1.9075229334421293
Validation loss: 2.5362478138836044

Epoch: 5| Step: 11
Training loss: 2.47150200152755
Validation loss: 2.5456568841508562

Epoch: 84| Step: 0
Training loss: 1.8156877306608141
Validation loss: 2.5565487791951487

Epoch: 5| Step: 1
Training loss: 2.3141706463297975
Validation loss: 2.5407408620230925

Epoch: 5| Step: 2
Training loss: 2.8721076680140385
Validation loss: 2.5266865500290145

Epoch: 5| Step: 3
Training loss: 2.7338180410728796
Validation loss: 2.553626385487065

Epoch: 5| Step: 4
Training loss: 2.0871718965447763
Validation loss: 2.5295634479041653

Epoch: 5| Step: 5
Training loss: 1.9320865189744942
Validation loss: 2.5052586442702895

Epoch: 5| Step: 6
Training loss: 2.9688136043762157
Validation loss: 2.5329256202308157

Epoch: 5| Step: 7
Training loss: 2.189804062635092
Validation loss: 2.54000987840719

Epoch: 5| Step: 8
Training loss: 2.1668215353954885
Validation loss: 2.527493916078786

Epoch: 5| Step: 9
Training loss: 2.431731906387848
Validation loss: 2.543543948326824

Epoch: 5| Step: 10
Training loss: 2.4196384069937733
Validation loss: 2.5331202650084763

Epoch: 5| Step: 11
Training loss: 1.8170079701006883
Validation loss: 2.5182370432612498

Epoch: 85| Step: 0
Training loss: 2.020128054950586
Validation loss: 2.551934200263213

Epoch: 5| Step: 1
Training loss: 2.294660889415277
Validation loss: 2.555116807910835

Epoch: 5| Step: 2
Training loss: 2.675237046193555
Validation loss: 2.5290634695635963

Epoch: 5| Step: 3
Training loss: 2.5448081400261704
Validation loss: 2.5282302924896016

Epoch: 5| Step: 4
Training loss: 1.8027026337942351
Validation loss: 2.54693841757736

Epoch: 5| Step: 5
Training loss: 2.5380836830261244
Validation loss: 2.5237220469881185

Epoch: 5| Step: 6
Training loss: 3.1948070172933107
Validation loss: 2.5553110510770805

Epoch: 5| Step: 7
Training loss: 2.4875933835697466
Validation loss: 2.5283960218354817

Epoch: 5| Step: 8
Training loss: 2.122750831044059
Validation loss: 2.5489474603576685

Epoch: 5| Step: 9
Training loss: 1.9403791262639234
Validation loss: 2.5481977713707864

Epoch: 5| Step: 10
Training loss: 1.94110491925898
Validation loss: 2.5217818073195333

Epoch: 5| Step: 11
Training loss: 2.476542957120497
Validation loss: 2.5283342923175334

Epoch: 86| Step: 0
Training loss: 2.332509974124104
Validation loss: 2.5092090429880822

Epoch: 5| Step: 1
Training loss: 2.211169550819363
Validation loss: 2.5167928950335368

Epoch: 5| Step: 2
Training loss: 2.4140925235794803
Validation loss: 2.526860901954203

Epoch: 5| Step: 3
Training loss: 2.2984868835911434
Validation loss: 2.4964446257489463

Epoch: 5| Step: 4
Training loss: 2.465066407026846
Validation loss: 2.5560365511594587

Epoch: 5| Step: 5
Training loss: 2.608749040458148
Validation loss: 2.5262701475235656

Epoch: 5| Step: 6
Training loss: 2.3749959845257997
Validation loss: 2.5309452768270617

Epoch: 5| Step: 7
Training loss: 2.213982200916286
Validation loss: 2.517230052971131

Epoch: 5| Step: 8
Training loss: 2.4409565015431016
Validation loss: 2.5373139410285996

Epoch: 5| Step: 9
Training loss: 2.4075516982187417
Validation loss: 2.552416051208964

Epoch: 5| Step: 10
Training loss: 2.2667185281916598
Validation loss: 2.5393293700209387

Epoch: 5| Step: 11
Training loss: 1.7410811259799621
Validation loss: 2.549778287885564

Epoch: 87| Step: 0
Training loss: 2.7341050368965716
Validation loss: 2.5437184609122374

Epoch: 5| Step: 1
Training loss: 2.6634588816257945
Validation loss: 2.5395972681536843

Epoch: 5| Step: 2
Training loss: 1.7274373457459415
Validation loss: 2.537872555980424

Epoch: 5| Step: 3
Training loss: 2.138916113158634
Validation loss: 2.5214328499593934

Epoch: 5| Step: 4
Training loss: 2.6080894729969897
Validation loss: 2.542446135510185

Epoch: 5| Step: 5
Training loss: 2.6011469511988277
Validation loss: 2.5602814250413437

Epoch: 5| Step: 6
Training loss: 2.4659578009318333
Validation loss: 2.5586706640122188

Epoch: 5| Step: 7
Training loss: 2.4139253151440925
Validation loss: 2.5388883012533956

Epoch: 5| Step: 8
Training loss: 1.9940315836984903
Validation loss: 2.5390694427395313

Epoch: 5| Step: 9
Training loss: 1.6528774689101533
Validation loss: 2.5269207765060857

Epoch: 5| Step: 10
Training loss: 2.4553816796600194
Validation loss: 2.5145118454066098

Epoch: 5| Step: 11
Training loss: 2.969259599817092
Validation loss: 2.5187970533306485

Epoch: 88| Step: 0
Training loss: 2.88366603879562
Validation loss: 2.5437698586865816

Epoch: 5| Step: 1
Training loss: 2.6035600388008855
Validation loss: 2.523765495407654

Epoch: 5| Step: 2
Training loss: 2.023237417336784
Validation loss: 2.5363784179526605

Epoch: 5| Step: 3
Training loss: 2.3749323383531102
Validation loss: 2.509658692453107

Epoch: 5| Step: 4
Training loss: 2.524365517243578
Validation loss: 2.534466426750922

Epoch: 5| Step: 5
Training loss: 2.2511676301772185
Validation loss: 2.516541438481774

Epoch: 5| Step: 6
Training loss: 2.3348625031531025
Validation loss: 2.5112883306299287

Epoch: 5| Step: 7
Training loss: 2.2723438477032527
Validation loss: 2.5144021199396565

Epoch: 5| Step: 8
Training loss: 1.6782576041513184
Validation loss: 2.5189167939295847

Epoch: 5| Step: 9
Training loss: 2.3958158298903474
Validation loss: 2.51742765550611

Epoch: 5| Step: 10
Training loss: 2.528133970416815
Validation loss: 2.5118166408576035

Epoch: 5| Step: 11
Training loss: 2.7227918024676363
Validation loss: 2.5594962433294794

Epoch: 89| Step: 0
Training loss: 2.6649880689171392
Validation loss: 2.509992711422636

Epoch: 5| Step: 1
Training loss: 2.2827492581797535
Validation loss: 2.5237956388345193

Epoch: 5| Step: 2
Training loss: 2.1973357193680805
Validation loss: 2.528508901898982

Epoch: 5| Step: 3
Training loss: 1.8343440506515916
Validation loss: 2.5328044964967664

Epoch: 5| Step: 4
Training loss: 2.2309061079251924
Validation loss: 2.5446977572785014

Epoch: 5| Step: 5
Training loss: 2.375512419182991
Validation loss: 2.5471058567319504

Epoch: 5| Step: 6
Training loss: 2.0408470558752936
Validation loss: 2.5651611257254534

Epoch: 5| Step: 7
Training loss: 2.5918682580128434
Validation loss: 2.571514862959957

Epoch: 5| Step: 8
Training loss: 2.7732025476789253
Validation loss: 2.5837537163251096

Epoch: 5| Step: 9
Training loss: 2.60350710845264
Validation loss: 2.6048418822720487

Epoch: 5| Step: 10
Training loss: 2.2589709204177932
Validation loss: 2.582915400466654

Epoch: 5| Step: 11
Training loss: 1.30924557066644
Validation loss: 2.55989780729935

Epoch: 90| Step: 0
Training loss: 2.646376716704386
Validation loss: 2.5796287582305264

Epoch: 5| Step: 1
Training loss: 2.5820051183258315
Validation loss: 2.602513083303828

Epoch: 5| Step: 2
Training loss: 2.4632862326937297
Validation loss: 2.5822730420082003

Epoch: 5| Step: 3
Training loss: 2.579412705164579
Validation loss: 2.565088610271136

Epoch: 5| Step: 4
Training loss: 1.837344016376732
Validation loss: 2.5570991324507024

Epoch: 5| Step: 5
Training loss: 2.536412097005568
Validation loss: 2.582247780297038

Epoch: 5| Step: 6
Training loss: 2.2012136839557583
Validation loss: 2.569904955987862

Epoch: 5| Step: 7
Training loss: 2.2788566680734985
Validation loss: 2.570921372606909

Epoch: 5| Step: 8
Training loss: 2.66993973453244
Validation loss: 2.5557077452935286

Epoch: 5| Step: 9
Training loss: 2.018427593362218
Validation loss: 2.5609650860786943

Epoch: 5| Step: 10
Training loss: 2.010658236469907
Validation loss: 2.553395499689845

Epoch: 5| Step: 11
Training loss: 1.5814360829503662
Validation loss: 2.5423768483152753

Epoch: 91| Step: 0
Training loss: 2.3528418625179826
Validation loss: 2.5436122605494065

Epoch: 5| Step: 1
Training loss: 2.2290357271996166
Validation loss: 2.5344279633744824

Epoch: 5| Step: 2
Training loss: 2.4049862602301393
Validation loss: 2.5144602426765292

Epoch: 5| Step: 3
Training loss: 2.6162999712185515
Validation loss: 2.5110394719641027

Epoch: 5| Step: 4
Training loss: 2.1268582914034084
Validation loss: 2.534603338777714

Epoch: 5| Step: 5
Training loss: 2.4954192156058648
Validation loss: 2.549741711344685

Epoch: 5| Step: 6
Training loss: 2.945981706032859
Validation loss: 2.5309187629201757

Epoch: 5| Step: 7
Training loss: 2.291788918673338
Validation loss: 2.529363592537004

Epoch: 5| Step: 8
Training loss: 2.392125874030167
Validation loss: 2.53011317293378

Epoch: 5| Step: 9
Training loss: 1.4105507253986755
Validation loss: 2.552763180131192

Epoch: 5| Step: 10
Training loss: 2.1486242594608083
Validation loss: 2.5249201864274697

Epoch: 5| Step: 11
Training loss: 3.349877705405724
Validation loss: 2.5289090226167725

Epoch: 92| Step: 0
Training loss: 2.963278295594444
Validation loss: 2.5370789277185746

Epoch: 5| Step: 1
Training loss: 2.5161979449326908
Validation loss: 2.5294466502104638

Epoch: 5| Step: 2
Training loss: 2.4157660439436275
Validation loss: 2.5458003704311625

Epoch: 5| Step: 3
Training loss: 2.3133765956266954
Validation loss: 2.5215171931992586

Epoch: 5| Step: 4
Training loss: 2.175043772114486
Validation loss: 2.5589737161084294

Epoch: 5| Step: 5
Training loss: 1.847372537327475
Validation loss: 2.545572177792545

Epoch: 5| Step: 6
Training loss: 2.2270185037091714
Validation loss: 2.549895104887445

Epoch: 5| Step: 7
Training loss: 1.950701132684763
Validation loss: 2.5587928403315905

Epoch: 5| Step: 8
Training loss: 2.6378952453383016
Validation loss: 2.5696510731606668

Epoch: 5| Step: 9
Training loss: 1.8740111604559748
Validation loss: 2.5763991118060043

Epoch: 5| Step: 10
Training loss: 2.6073679257644433
Validation loss: 2.572394398464048

Epoch: 5| Step: 11
Training loss: 2.3815653554601184
Validation loss: 2.5474647822018732

Epoch: 93| Step: 0
Training loss: 2.354187270442856
Validation loss: 2.54993308951911

Epoch: 5| Step: 1
Training loss: 1.9899607461862923
Validation loss: 2.5538543563647487

Epoch: 5| Step: 2
Training loss: 2.2615303659468853
Validation loss: 2.574454331990476

Epoch: 5| Step: 3
Training loss: 2.4563839397845255
Validation loss: 2.5658172365034506

Epoch: 5| Step: 4
Training loss: 2.7907146614596394
Validation loss: 2.5319744886458495

Epoch: 5| Step: 5
Training loss: 2.574062591586077
Validation loss: 2.5515725591320715

Epoch: 5| Step: 6
Training loss: 2.8373592795545672
Validation loss: 2.563546622151516

Epoch: 5| Step: 7
Training loss: 2.6294868814301084
Validation loss: 2.5581201323683405

Epoch: 5| Step: 8
Training loss: 2.125072029239378
Validation loss: 2.5512318507671474

Epoch: 5| Step: 9
Training loss: 2.042772097632281
Validation loss: 2.5408256786210695

Epoch: 5| Step: 10
Training loss: 1.8469746080314728
Validation loss: 2.5388617411742693

Epoch: 5| Step: 11
Training loss: 1.0364033222775375
Validation loss: 2.5410763779457866

Epoch: 94| Step: 0
Training loss: 2.1735772796153823
Validation loss: 2.5325446330584436

Epoch: 5| Step: 1
Training loss: 2.7032407173569584
Validation loss: 2.565493413111671

Epoch: 5| Step: 2
Training loss: 2.5337399139730494
Validation loss: 2.5282635398159434

Epoch: 5| Step: 3
Training loss: 1.92193194049129
Validation loss: 2.550387263966513

Epoch: 5| Step: 4
Training loss: 2.108498285145884
Validation loss: 2.570318274216123

Epoch: 5| Step: 5
Training loss: 1.9524287088935584
Validation loss: 2.5737211781734963

Epoch: 5| Step: 6
Training loss: 2.458547442751365
Validation loss: 2.5579587347367285

Epoch: 5| Step: 7
Training loss: 2.086717552604603
Validation loss: 2.561025389054798

Epoch: 5| Step: 8
Training loss: 3.0414779987784266
Validation loss: 2.535259948083005

Epoch: 5| Step: 9
Training loss: 2.071459182738572
Validation loss: 2.5478239163952763

Epoch: 5| Step: 10
Training loss: 2.4260990837600165
Validation loss: 2.542518126549085

Epoch: 5| Step: 11
Training loss: 2.678893925462409
Validation loss: 2.536856537148913

Epoch: 95| Step: 0
Training loss: 2.6087757267617895
Validation loss: 2.5291275969309894

Epoch: 5| Step: 1
Training loss: 2.41641910424993
Validation loss: 2.5304895483176866

Epoch: 5| Step: 2
Training loss: 1.8951060258901702
Validation loss: 2.543326745761133

Epoch: 5| Step: 3
Training loss: 1.9464819889563065
Validation loss: 2.5474645677235666

Epoch: 5| Step: 4
Training loss: 2.1619939178818823
Validation loss: 2.5334184134045783

Epoch: 5| Step: 5
Training loss: 2.521672626680776
Validation loss: 2.5205695602773526

Epoch: 5| Step: 6
Training loss: 2.6271240178788977
Validation loss: 2.5267458822226185

Epoch: 5| Step: 7
Training loss: 2.7443954403766964
Validation loss: 2.5159487387651307

Epoch: 5| Step: 8
Training loss: 2.031690344397388
Validation loss: 2.5274286034798026

Epoch: 5| Step: 9
Training loss: 2.536785900941259
Validation loss: 2.5248015056621633

Epoch: 5| Step: 10
Training loss: 2.2031954490273873
Validation loss: 2.5290604509101566

Epoch: 5| Step: 11
Training loss: 2.667449677268855
Validation loss: 2.5419066086582736

Epoch: 96| Step: 0
Training loss: 3.108685747747281
Validation loss: 2.5126429509225945

Epoch: 5| Step: 1
Training loss: 1.912722433780802
Validation loss: 2.518708765593207

Epoch: 5| Step: 2
Training loss: 2.5863632358782924
Validation loss: 2.5411416935611717

Epoch: 5| Step: 3
Training loss: 2.0201858846665464
Validation loss: 2.546642714128978

Epoch: 5| Step: 4
Training loss: 2.695503382903396
Validation loss: 2.5799904634425133

Epoch: 5| Step: 5
Training loss: 1.8439738250910314
Validation loss: 2.5604199092607525

Epoch: 5| Step: 6
Training loss: 2.233642564782524
Validation loss: 2.6222036089838205

Epoch: 5| Step: 7
Training loss: 2.5993845761474264
Validation loss: 2.5754434627306835

Epoch: 5| Step: 8
Training loss: 2.0799900949682466
Validation loss: 2.612838677230048

Epoch: 5| Step: 9
Training loss: 1.6356895688831588
Validation loss: 2.6041749966806065

Epoch: 5| Step: 10
Training loss: 2.4498501439877556
Validation loss: 2.5985043931319214

Epoch: 5| Step: 11
Training loss: 2.2716619630439783
Validation loss: 2.5937921566582163

Epoch: 97| Step: 0
Training loss: 2.2070729479606306
Validation loss: 2.6128186594323166

Epoch: 5| Step: 1
Training loss: 2.626929346140055
Validation loss: 2.5814355325562897

Epoch: 5| Step: 2
Training loss: 2.1618482368270593
Validation loss: 2.579846387375896

Epoch: 5| Step: 3
Training loss: 2.3640618666542754
Validation loss: 2.5539923878112942

Epoch: 5| Step: 4
Training loss: 2.2592830950563005
Validation loss: 2.5623498112774925

Epoch: 5| Step: 5
Training loss: 1.8983585042962092
Validation loss: 2.5808020246879444

Epoch: 5| Step: 6
Training loss: 2.248830385324609
Validation loss: 2.532647704580468

Epoch: 5| Step: 7
Training loss: 2.009924701589786
Validation loss: 2.5265695053189052

Epoch: 5| Step: 8
Training loss: 2.556830577627632
Validation loss: 2.545176483791422

Epoch: 5| Step: 9
Training loss: 2.8174494109058847
Validation loss: 2.536725305662935

Epoch: 5| Step: 10
Training loss: 2.2698536313967663
Validation loss: 2.54459103951402

Epoch: 5| Step: 11
Training loss: 2.4779688936302393
Validation loss: 2.546745497876727

Epoch: 98| Step: 0
Training loss: 2.313001629833368
Validation loss: 2.553570743405723

Epoch: 5| Step: 1
Training loss: 2.016575552193033
Validation loss: 2.5420853564392885

Epoch: 5| Step: 2
Training loss: 2.501553815532337
Validation loss: 2.5530140963575003

Epoch: 5| Step: 3
Training loss: 1.9495721469902545
Validation loss: 2.579650046378786

Epoch: 5| Step: 4
Training loss: 1.7089990233747214
Validation loss: 2.587941252974947

Epoch: 5| Step: 5
Training loss: 2.402921976112606
Validation loss: 2.5617010801775626

Epoch: 5| Step: 6
Training loss: 2.925472716907578
Validation loss: 2.595338805890415

Epoch: 5| Step: 7
Training loss: 2.6215574306357627
Validation loss: 2.5970160553499184

Epoch: 5| Step: 8
Training loss: 2.3026008081889833
Validation loss: 2.608960242439913

Epoch: 5| Step: 9
Training loss: 2.6853939054445406
Validation loss: 2.580907252865359

Epoch: 5| Step: 10
Training loss: 1.7780485327826179
Validation loss: 2.573021609885594

Epoch: 5| Step: 11
Training loss: 2.953830372366257
Validation loss: 2.5789953804811687

Epoch: 99| Step: 0
Training loss: 2.0990972985646836
Validation loss: 2.561055834807634

Epoch: 5| Step: 1
Training loss: 2.6316828355862225
Validation loss: 2.5511773908363997

Epoch: 5| Step: 2
Training loss: 2.4105198615252306
Validation loss: 2.529912999740535

Epoch: 5| Step: 3
Training loss: 2.224093061620135
Validation loss: 2.533260434026214

Epoch: 5| Step: 4
Training loss: 2.4913981272773476
Validation loss: 2.5313294009718224

Epoch: 5| Step: 5
Training loss: 2.6841848463713793
Validation loss: 2.522402213418913

Epoch: 5| Step: 6
Training loss: 2.683529515726198
Validation loss: 2.530581864924988

Epoch: 5| Step: 7
Training loss: 1.883366673379803
Validation loss: 2.5174421890765557

Epoch: 5| Step: 8
Training loss: 2.390598471500582
Validation loss: 2.529669169908747

Epoch: 5| Step: 9
Training loss: 2.140648723387305
Validation loss: 2.5282788283705813

Epoch: 5| Step: 10
Training loss: 1.8546513413308687
Validation loss: 2.4958031872779287

Epoch: 5| Step: 11
Training loss: 2.658464114839645
Validation loss: 2.539828618205098

Epoch: 100| Step: 0
Training loss: 2.2443398170613604
Validation loss: 2.560150942245443

Epoch: 5| Step: 1
Training loss: 2.0668056513085022
Validation loss: 2.524297160350815

Epoch: 5| Step: 2
Training loss: 3.004559548798358
Validation loss: 2.4990696308358142

Epoch: 5| Step: 3
Training loss: 1.979328617363144
Validation loss: 2.512451191644752

Epoch: 5| Step: 4
Training loss: 2.368092279034477
Validation loss: 2.4994639497487046

Epoch: 5| Step: 5
Training loss: 1.8792533950358867
Validation loss: 2.541689584712112

Epoch: 5| Step: 6
Training loss: 2.5549473061698724
Validation loss: 2.5347549363787496

Epoch: 5| Step: 7
Training loss: 2.2854244759448523
Validation loss: 2.51668424400187

Epoch: 5| Step: 8
Training loss: 2.188494537974203
Validation loss: 2.526929279914062

Epoch: 5| Step: 9
Training loss: 2.3051079835236234
Validation loss: 2.5696520241808303

Epoch: 5| Step: 10
Training loss: 2.4473620713113253
Validation loss: 2.5455950346601277

Epoch: 5| Step: 11
Training loss: 2.747920637342367
Validation loss: 2.567811516370891

Epoch: 101| Step: 0
Training loss: 2.414987232656277
Validation loss: 2.553979373047264

Epoch: 5| Step: 1
Training loss: 2.369161657631546
Validation loss: 2.568313940538378

Epoch: 5| Step: 2
Training loss: 1.6631490860047522
Validation loss: 2.581032356341688

Epoch: 5| Step: 3
Training loss: 2.4250278746585767
Validation loss: 2.55948905519904

Epoch: 5| Step: 4
Training loss: 2.270414879650529
Validation loss: 2.579480510365687

Epoch: 5| Step: 5
Training loss: 2.395117235280926
Validation loss: 2.54320199641903

Epoch: 5| Step: 6
Training loss: 2.4140088714272254
Validation loss: 2.5458062158525343

Epoch: 5| Step: 7
Training loss: 2.1409107769295175
Validation loss: 2.5639965486694196

Epoch: 5| Step: 8
Training loss: 2.359002494458169
Validation loss: 2.561578453094643

Epoch: 5| Step: 9
Training loss: 2.7006070973306784
Validation loss: 2.5231368591449446

Epoch: 5| Step: 10
Training loss: 2.1242671151528416
Validation loss: 2.535046967441872

Epoch: 5| Step: 11
Training loss: 2.663765183132083
Validation loss: 2.551827458120904

Epoch: 102| Step: 0
Training loss: 2.4691040171531804
Validation loss: 2.5505614446442637

Epoch: 5| Step: 1
Training loss: 2.456810387902268
Validation loss: 2.5381231203739985

Epoch: 5| Step: 2
Training loss: 2.492002091641107
Validation loss: 2.5400257728675832

Epoch: 5| Step: 3
Training loss: 1.8064974341481197
Validation loss: 2.533370348514588

Epoch: 5| Step: 4
Training loss: 2.0705843764953813
Validation loss: 2.5521834308430997

Epoch: 5| Step: 5
Training loss: 2.6014944989822415
Validation loss: 2.575521048046652

Epoch: 5| Step: 6
Training loss: 2.5144201200961303
Validation loss: 2.563762644472006

Epoch: 5| Step: 7
Training loss: 1.8801115298161781
Validation loss: 2.551797279882886

Epoch: 5| Step: 8
Training loss: 2.299267204310723
Validation loss: 2.5699021747199513

Epoch: 5| Step: 9
Training loss: 2.3097969960108533
Validation loss: 2.5371648279736907

Epoch: 5| Step: 10
Training loss: 2.289573117743332
Validation loss: 2.5674789679624475

Epoch: 5| Step: 11
Training loss: 2.330764400848087
Validation loss: 2.5490515677971493

Epoch: 103| Step: 0
Training loss: 1.4928358976060954
Validation loss: 2.5754008340732066

Epoch: 5| Step: 1
Training loss: 2.1326255856168785
Validation loss: 2.55167242881312

Epoch: 5| Step: 2
Training loss: 2.9151949484596074
Validation loss: 2.548357498937143

Epoch: 5| Step: 3
Training loss: 2.1196559578259673
Validation loss: 2.566568920103161

Epoch: 5| Step: 4
Training loss: 2.7130139228809442
Validation loss: 2.583908894984596

Epoch: 5| Step: 5
Training loss: 2.7200534370726994
Validation loss: 2.557525765191959

Epoch: 5| Step: 6
Training loss: 2.0540839059289753
Validation loss: 2.5429803874369195

Epoch: 5| Step: 7
Training loss: 2.224437998399129
Validation loss: 2.554785080114507

Epoch: 5| Step: 8
Training loss: 2.0245990733039694
Validation loss: 2.5373621210995787

Epoch: 5| Step: 9
Training loss: 2.5205878356267166
Validation loss: 2.540041064934172

Epoch: 5| Step: 10
Training loss: 2.2654947177654474
Validation loss: 2.5184729470276883

Epoch: 5| Step: 11
Training loss: 1.696605839466468
Validation loss: 2.520105021593059

Epoch: 104| Step: 0
Training loss: 1.9333031021692324
Validation loss: 2.544317876926857

Epoch: 5| Step: 1
Training loss: 2.447345899770811
Validation loss: 2.5430100140248793

Epoch: 5| Step: 2
Training loss: 2.5711053709487928
Validation loss: 2.5533381212449395

Epoch: 5| Step: 3
Training loss: 2.6638873537722363
Validation loss: 2.5422474062191105

Epoch: 5| Step: 4
Training loss: 1.802109301017991
Validation loss: 2.52277727416633

Epoch: 5| Step: 5
Training loss: 2.307191684413744
Validation loss: 2.5299699395923234

Epoch: 5| Step: 6
Training loss: 2.136336771908641
Validation loss: 2.528891724647004

Epoch: 5| Step: 7
Training loss: 2.3765974193969575
Validation loss: 2.539280433105103

Epoch: 5| Step: 8
Training loss: 2.8119979410286065
Validation loss: 2.529039826949236

Epoch: 5| Step: 9
Training loss: 2.0869418237434645
Validation loss: 2.5210590274651103

Epoch: 5| Step: 10
Training loss: 1.8252109222805943
Validation loss: 2.5363904537906827

Epoch: 5| Step: 11
Training loss: 2.228142321761375
Validation loss: 2.5549111069122805

Epoch: 105| Step: 0
Training loss: 2.5457194696697463
Validation loss: 2.5687455345108807

Epoch: 5| Step: 1
Training loss: 2.8815756524802185
Validation loss: 2.564797147137104

Epoch: 5| Step: 2
Training loss: 1.6592376680891536
Validation loss: 2.5802956661947127

Epoch: 5| Step: 3
Training loss: 2.440405849723514
Validation loss: 2.6360349752828167

Epoch: 5| Step: 4
Training loss: 1.9130541578285
Validation loss: 2.636500900122869

Epoch: 5| Step: 5
Training loss: 2.241567067293614
Validation loss: 2.65739558704702

Epoch: 5| Step: 6
Training loss: 1.9524912301817818
Validation loss: 2.6549044997310465

Epoch: 5| Step: 7
Training loss: 2.2565804786319874
Validation loss: 2.6146216858309095

Epoch: 5| Step: 8
Training loss: 2.052370570907493
Validation loss: 2.6221311309978454

Epoch: 5| Step: 9
Training loss: 2.611960860112479
Validation loss: 2.599171713183772

Epoch: 5| Step: 10
Training loss: 2.507375708834132
Validation loss: 2.5944965161505817

Epoch: 5| Step: 11
Training loss: 1.651511413303797
Validation loss: 2.5552511380873

Epoch: 106| Step: 0
Training loss: 2.4680773627522847
Validation loss: 2.56791757088325

Epoch: 5| Step: 1
Training loss: 2.4298284066607314
Validation loss: 2.559042109451178

Epoch: 5| Step: 2
Training loss: 2.2706441071323535
Validation loss: 2.5147827231097204

Epoch: 5| Step: 3
Training loss: 2.2404776510100013
Validation loss: 2.512042572995058

Epoch: 5| Step: 4
Training loss: 1.7987332231005637
Validation loss: 2.5103704849258532

Epoch: 5| Step: 5
Training loss: 2.3092832100555327
Validation loss: 2.5392054825651473

Epoch: 5| Step: 6
Training loss: 2.1942404304774676
Validation loss: 2.5135245310872096

Epoch: 5| Step: 7
Training loss: 2.24967519746965
Validation loss: 2.5368183919613934

Epoch: 5| Step: 8
Training loss: 2.5119997048347447
Validation loss: 2.5390467755735546

Epoch: 5| Step: 9
Training loss: 2.2657713744135926
Validation loss: 2.4989741207343377

Epoch: 5| Step: 10
Training loss: 2.53392988969359
Validation loss: 2.5463009793948124

Epoch: 5| Step: 11
Training loss: 1.0833863404339446
Validation loss: 2.548272819975241

Epoch: 107| Step: 0
Training loss: 1.9696446157268988
Validation loss: 2.5224340705459793

Epoch: 5| Step: 1
Training loss: 2.6708766566753583
Validation loss: 2.5580411202573248

Epoch: 5| Step: 2
Training loss: 2.496085535552309
Validation loss: 2.5980548906506145

Epoch: 5| Step: 3
Training loss: 2.37798944355103
Validation loss: 2.6040826338879244

Epoch: 5| Step: 4
Training loss: 2.1947957038087895
Validation loss: 2.5967971375410737

Epoch: 5| Step: 5
Training loss: 2.1235642912500357
Validation loss: 2.589127857347933

Epoch: 5| Step: 6
Training loss: 2.5907470600745004
Validation loss: 2.5691005087109073

Epoch: 5| Step: 7
Training loss: 2.348766400826582
Validation loss: 2.558009364825294

Epoch: 5| Step: 8
Training loss: 2.5214535499301918
Validation loss: 2.584460725173591

Epoch: 5| Step: 9
Training loss: 2.239705696016074
Validation loss: 2.560432611937777

Epoch: 5| Step: 10
Training loss: 1.571051124969543
Validation loss: 2.5233710903251385

Epoch: 5| Step: 11
Training loss: 1.8788079059583114
Validation loss: 2.5135195472799006

Epoch: 108| Step: 0
Training loss: 2.596748365488931
Validation loss: 2.538723207936862

Epoch: 5| Step: 1
Training loss: 1.9364817004532178
Validation loss: 2.538056085128936

Epoch: 5| Step: 2
Training loss: 2.454168207225305
Validation loss: 2.519509812690162

Epoch: 5| Step: 3
Training loss: 1.6702309484173214
Validation loss: 2.533401054075311

Epoch: 5| Step: 4
Training loss: 2.0637695566656706
Validation loss: 2.5369308228736576

Epoch: 5| Step: 5
Training loss: 2.78437886350216
Validation loss: 2.5253993145094222

Epoch: 5| Step: 6
Training loss: 2.2186766061598404
Validation loss: 2.558096929172942

Epoch: 5| Step: 7
Training loss: 2.31951099257137
Validation loss: 2.568961707438222

Epoch: 5| Step: 8
Training loss: 2.4345945991317697
Validation loss: 2.559937572171313

Epoch: 5| Step: 9
Training loss: 2.2022786780707406
Validation loss: 2.573569999917044

Epoch: 5| Step: 10
Training loss: 2.2855620716706584
Validation loss: 2.538389967835334

Epoch: 5| Step: 11
Training loss: 1.4556714787480476
Validation loss: 2.5358359665365477

Epoch: 109| Step: 0
Training loss: 2.263595408611963
Validation loss: 2.5459689262376246

Epoch: 5| Step: 1
Training loss: 2.5122457043457964
Validation loss: 2.52513119652588

Epoch: 5| Step: 2
Training loss: 1.971262766349832
Validation loss: 2.5459544813754844

Epoch: 5| Step: 3
Training loss: 2.325658118512715
Validation loss: 2.5470399744628445

Epoch: 5| Step: 4
Training loss: 2.9803813956522083
Validation loss: 2.5362079478500683

Epoch: 5| Step: 5
Training loss: 1.96067759702624
Validation loss: 2.5217097994470254

Epoch: 5| Step: 6
Training loss: 2.015095012687057
Validation loss: 2.54289166382006

Epoch: 5| Step: 7
Training loss: 2.1312266731663647
Validation loss: 2.5332005328476663

Epoch: 5| Step: 8
Training loss: 1.850427271500403
Validation loss: 2.5108542489646046

Epoch: 5| Step: 9
Training loss: 2.621155330201773
Validation loss: 2.524224193129893

Epoch: 5| Step: 10
Training loss: 1.9803547421958885
Validation loss: 2.5351757877578587

Epoch: 5| Step: 11
Training loss: 2.7094503495629563
Validation loss: 2.5160201652812417

Epoch: 110| Step: 0
Training loss: 2.346736378645751
Validation loss: 2.5263166310732643

Epoch: 5| Step: 1
Training loss: 2.7151144866971637
Validation loss: 2.5277656741487116

Epoch: 5| Step: 2
Training loss: 2.119853575706134
Validation loss: 2.516797923671487

Epoch: 5| Step: 3
Training loss: 2.0279226193308997
Validation loss: 2.53979909531588

Epoch: 5| Step: 4
Training loss: 2.0512399505610825
Validation loss: 2.5118323973261902

Epoch: 5| Step: 5
Training loss: 2.6899553659699715
Validation loss: 2.543889853079798

Epoch: 5| Step: 6
Training loss: 2.183914079184717
Validation loss: 2.5225806498922236

Epoch: 5| Step: 7
Training loss: 2.175653806614594
Validation loss: 2.505073309106132

Epoch: 5| Step: 8
Training loss: 2.360446206761219
Validation loss: 2.5419400659591838

Epoch: 5| Step: 9
Training loss: 2.523326954029373
Validation loss: 2.5435113948041606

Epoch: 5| Step: 10
Training loss: 1.3662868912193138
Validation loss: 2.5414046611091

Epoch: 5| Step: 11
Training loss: 1.0953076850905004
Validation loss: 2.5822855890983987

Epoch: 111| Step: 0
Training loss: 1.8476801864654253
Validation loss: 2.5620263638885725

Epoch: 5| Step: 1
Training loss: 2.113066092941929
Validation loss: 2.5860214296610025

Epoch: 5| Step: 2
Training loss: 1.9218640831117788
Validation loss: 2.5931332900622057

Epoch: 5| Step: 3
Training loss: 2.7219759338794933
Validation loss: 2.61185186246391

Epoch: 5| Step: 4
Training loss: 2.6510509098593826
Validation loss: 2.605714007667815

Epoch: 5| Step: 5
Training loss: 2.4380514059178386
Validation loss: 2.608376443271034

Epoch: 5| Step: 6
Training loss: 2.5307381194786482
Validation loss: 2.585376640264096

Epoch: 5| Step: 7
Training loss: 1.7716407580677784
Validation loss: 2.562731150924645

Epoch: 5| Step: 8
Training loss: 2.657155051034937
Validation loss: 2.5286754026298097

Epoch: 5| Step: 9
Training loss: 1.8728024638502363
Validation loss: 2.5736812364181243

Epoch: 5| Step: 10
Training loss: 1.7175029044980472
Validation loss: 2.527482832275857

Epoch: 5| Step: 11
Training loss: 3.1886539240486846
Validation loss: 2.5467545650535253

Epoch: 112| Step: 0
Training loss: 2.090694988544654
Validation loss: 2.5077251565682723

Epoch: 5| Step: 1
Training loss: 1.8969343851713765
Validation loss: 2.541506622830911

Epoch: 5| Step: 2
Training loss: 2.6981651358660077
Validation loss: 2.5175632528650524

Epoch: 5| Step: 3
Training loss: 3.0079776867180956
Validation loss: 2.510172053775216

Epoch: 5| Step: 4
Training loss: 1.8169274023455881
Validation loss: 2.523150786969759

Epoch: 5| Step: 5
Training loss: 2.3814592364641025
Validation loss: 2.5119186033134646

Epoch: 5| Step: 6
Training loss: 2.5239196883541517
Validation loss: 2.5459086451236197

Epoch: 5| Step: 7
Training loss: 1.682485405913906
Validation loss: 2.5332822569186284

Epoch: 5| Step: 8
Training loss: 2.2273863222033627
Validation loss: 2.513757059570142

Epoch: 5| Step: 9
Training loss: 2.6086826890816854
Validation loss: 2.5313936907010866

Epoch: 5| Step: 10
Training loss: 1.9241665460193587
Validation loss: 2.5340319718446733

Epoch: 5| Step: 11
Training loss: 2.207833527439896
Validation loss: 2.5667152044632067

Epoch: 113| Step: 0
Training loss: 2.2308397402105524
Validation loss: 2.534753288371881

Epoch: 5| Step: 1
Training loss: 2.2861890235974434
Validation loss: 2.524243900115141

Epoch: 5| Step: 2
Training loss: 2.4445524649402013
Validation loss: 2.552154479040687

Epoch: 5| Step: 3
Training loss: 2.223250753745961
Validation loss: 2.566939102665361

Epoch: 5| Step: 4
Training loss: 1.8994539781313635
Validation loss: 2.556973473797194

Epoch: 5| Step: 5
Training loss: 2.6610817440627383
Validation loss: 2.5580262853118483

Epoch: 5| Step: 6
Training loss: 1.6448880712350855
Validation loss: 2.5517612617353547

Epoch: 5| Step: 7
Training loss: 2.5075122499024096
Validation loss: 2.5731756116059006

Epoch: 5| Step: 8
Training loss: 1.7514475557586988
Validation loss: 2.587987661401805

Epoch: 5| Step: 9
Training loss: 2.132165160818986
Validation loss: 2.5764065226636603

Epoch: 5| Step: 10
Training loss: 2.208765263572159
Validation loss: 2.617066406181492

Epoch: 5| Step: 11
Training loss: 4.141989198914669
Validation loss: 2.5826199389964275

Epoch: 114| Step: 0
Training loss: 2.6471531096975935
Validation loss: 2.5619230667634216

Epoch: 5| Step: 1
Training loss: 2.2576216778750546
Validation loss: 2.517335677329012

Epoch: 5| Step: 2
Training loss: 2.1992328433301758
Validation loss: 2.5159171430390987

Epoch: 5| Step: 3
Training loss: 2.22891646314996
Validation loss: 2.553485163572668

Epoch: 5| Step: 4
Training loss: 1.9518592700452677
Validation loss: 2.555649594693696

Epoch: 5| Step: 5
Training loss: 2.241953767828971
Validation loss: 2.5899885011537997

Epoch: 5| Step: 6
Training loss: 2.5559166800540307
Validation loss: 2.5906199217080474

Epoch: 5| Step: 7
Training loss: 2.0236043382594002
Validation loss: 2.5348407919395655

Epoch: 5| Step: 8
Training loss: 2.514184764594197
Validation loss: 2.5423777138063333

Epoch: 5| Step: 9
Training loss: 2.836206176473048
Validation loss: 2.544380999040883

Epoch: 5| Step: 10
Training loss: 2.4460184948924564
Validation loss: 2.5569106955761325

Epoch: 5| Step: 11
Training loss: 2.446693298686894
Validation loss: 2.5229184942661496

Epoch: 115| Step: 0
Training loss: 2.284850427753066
Validation loss: 2.5068140389318527

Epoch: 5| Step: 1
Training loss: 2.6102189395321767
Validation loss: 2.5369376715943015

Epoch: 5| Step: 2
Training loss: 1.578313079806083
Validation loss: 2.537782876763628

Epoch: 5| Step: 3
Training loss: 2.558309711094585
Validation loss: 2.517667154731116

Epoch: 5| Step: 4
Training loss: 1.943291775088399
Validation loss: 2.5548340524990194

Epoch: 5| Step: 5
Training loss: 2.2492922623477636
Validation loss: 2.561688422570039

Epoch: 5| Step: 6
Training loss: 2.4065143390468475
Validation loss: 2.6231011190744513

Epoch: 5| Step: 7
Training loss: 1.9717627588601483
Validation loss: 2.6237033638846343

Epoch: 5| Step: 8
Training loss: 2.7138281809449394
Validation loss: 2.5726503254930053

Epoch: 5| Step: 9
Training loss: 2.018818063444801
Validation loss: 2.5519147129536144

Epoch: 5| Step: 10
Training loss: 1.91416034059167
Validation loss: 2.60781312214528

Epoch: 5| Step: 11
Training loss: 2.495856666349733
Validation loss: 2.5811024590568605

Epoch: 116| Step: 0
Training loss: 2.3068024839353143
Validation loss: 2.6133406764915836

Epoch: 5| Step: 1
Training loss: 2.6875342433433413
Validation loss: 2.5742589458285314

Epoch: 5| Step: 2
Training loss: 1.8755630919203123
Validation loss: 2.522085490969215

Epoch: 5| Step: 3
Training loss: 2.206870176125837
Validation loss: 2.5636163311351283

Epoch: 5| Step: 4
Training loss: 3.0147186656664458
Validation loss: 2.5526985841132857

Epoch: 5| Step: 5
Training loss: 2.214399451310029
Validation loss: 2.5667286229603135

Epoch: 5| Step: 6
Training loss: 1.852615829429633
Validation loss: 2.57170057837039

Epoch: 5| Step: 7
Training loss: 1.9947702458147019
Validation loss: 2.5553727042795833

Epoch: 5| Step: 8
Training loss: 2.092426166211693
Validation loss: 2.5382358829149925

Epoch: 5| Step: 9
Training loss: 1.9866640600191634
Validation loss: 2.5548880417687188

Epoch: 5| Step: 10
Training loss: 2.2417051215105523
Validation loss: 2.5578777214035444

Epoch: 5| Step: 11
Training loss: 2.089535813505974
Validation loss: 2.542979836622878

Epoch: 117| Step: 0
Training loss: 2.0468703408224647
Validation loss: 2.5607351684396527

Epoch: 5| Step: 1
Training loss: 2.1988868801760364
Validation loss: 2.5814929426028916

Epoch: 5| Step: 2
Training loss: 2.351205183998356
Validation loss: 2.5297986567523014

Epoch: 5| Step: 3
Training loss: 2.2274637105021498
Validation loss: 2.5321142071445606

Epoch: 5| Step: 4
Training loss: 1.8479220499550193
Validation loss: 2.5418195066201235

Epoch: 5| Step: 5
Training loss: 1.8160021260580985
Validation loss: 2.5384092341521973

Epoch: 5| Step: 6
Training loss: 1.6410197918318468
Validation loss: 2.5471457608545314

Epoch: 5| Step: 7
Training loss: 2.0509721358334763
Validation loss: 2.570830261119406

Epoch: 5| Step: 8
Training loss: 2.867312893737065
Validation loss: 2.5428787778064885

Epoch: 5| Step: 9
Training loss: 1.6883715039250435
Validation loss: 2.5786600386176226

Epoch: 5| Step: 10
Training loss: 3.1837773744015108
Validation loss: 2.533257120381007

Epoch: 5| Step: 11
Training loss: 2.395288643217383
Validation loss: 2.530474045423962

Epoch: 118| Step: 0
Training loss: 2.668750921959461
Validation loss: 2.5696228323405244

Epoch: 5| Step: 1
Training loss: 1.644417874376476
Validation loss: 2.57469423308852

Epoch: 5| Step: 2
Training loss: 2.224169492561353
Validation loss: 2.5277617873802765

Epoch: 5| Step: 3
Training loss: 2.149789280878234
Validation loss: 2.581594132951229

Epoch: 5| Step: 4
Training loss: 2.081453797955867
Validation loss: 2.559910528089711

Epoch: 5| Step: 5
Training loss: 2.0980311792127817
Validation loss: 2.5645473644007755

Epoch: 5| Step: 6
Training loss: 2.3078978856535763
Validation loss: 2.5584149984958566

Epoch: 5| Step: 7
Training loss: 2.3751737631425724
Validation loss: 2.533806857575355

Epoch: 5| Step: 8
Training loss: 2.4378211959098928
Validation loss: 2.524743965280215

Epoch: 5| Step: 9
Training loss: 2.1133754518846533
Validation loss: 2.5042424325911483

Epoch: 5| Step: 10
Training loss: 2.2798476415892055
Validation loss: 2.5388958216024617

Epoch: 5| Step: 11
Training loss: 2.0218650569995567
Validation loss: 2.518986976840751

Epoch: 119| Step: 0
Training loss: 1.9688117002476657
Validation loss: 2.5382162199870733

Epoch: 5| Step: 1
Training loss: 2.2320390775260894
Validation loss: 2.532993187363202

Epoch: 5| Step: 2
Training loss: 2.1310785532256453
Validation loss: 2.544306194849695

Epoch: 5| Step: 3
Training loss: 2.654511185528183
Validation loss: 2.5358968024397264

Epoch: 5| Step: 4
Training loss: 1.8611262433147
Validation loss: 2.5399705642211052

Epoch: 5| Step: 5
Training loss: 1.6090017830392502
Validation loss: 2.5277750157305077

Epoch: 5| Step: 6
Training loss: 3.113080447815757
Validation loss: 2.5826717242188266

Epoch: 5| Step: 7
Training loss: 2.0845144611240416
Validation loss: 2.587734400994101

Epoch: 5| Step: 8
Training loss: 2.0833668388215547
Validation loss: 2.5732568285608197

Epoch: 5| Step: 9
Training loss: 2.2141466338783204
Validation loss: 2.563512871379147

Epoch: 5| Step: 10
Training loss: 2.1593501706496943
Validation loss: 2.5855973433921955

Epoch: 5| Step: 11
Training loss: 1.7453794106248306
Validation loss: 2.5802867650070036

Epoch: 120| Step: 0
Training loss: 2.1205100701868105
Validation loss: 2.561492727766747

Epoch: 5| Step: 1
Training loss: 1.9383110071778664
Validation loss: 2.566875436165284

Epoch: 5| Step: 2
Training loss: 2.3780585220810146
Validation loss: 2.5751953163576133

Epoch: 5| Step: 3
Training loss: 2.056955920157431
Validation loss: 2.5380048025778184

Epoch: 5| Step: 4
Training loss: 2.6404836041216493
Validation loss: 2.552975706189084

Epoch: 5| Step: 5
Training loss: 1.8757571916733407
Validation loss: 2.5462561657100107

Epoch: 5| Step: 6
Training loss: 2.35033691507183
Validation loss: 2.560894447633535

Epoch: 5| Step: 7
Training loss: 2.012532308567936
Validation loss: 2.5227449606487027

Epoch: 5| Step: 8
Training loss: 2.4047376165193115
Validation loss: 2.5375350974776665

Epoch: 5| Step: 9
Training loss: 1.7762452472190975
Validation loss: 2.538778533706329

Epoch: 5| Step: 10
Training loss: 2.6166188091915004
Validation loss: 2.528479174154726

Epoch: 5| Step: 11
Training loss: 1.4624031589104574
Validation loss: 2.5493663390108265

Epoch: 121| Step: 0
Training loss: 2.239217778616185
Validation loss: 2.5518385938473047

Epoch: 5| Step: 1
Training loss: 2.2461963928652913
Validation loss: 2.5448042558651944

Epoch: 5| Step: 2
Training loss: 2.538461467324992
Validation loss: 2.5308240543897105

Epoch: 5| Step: 3
Training loss: 2.3651682484563037
Validation loss: 2.550379956679278

Epoch: 5| Step: 4
Training loss: 2.5131507220656
Validation loss: 2.527021376711731

Epoch: 5| Step: 5
Training loss: 2.1319848994566613
Validation loss: 2.538481210534765

Epoch: 5| Step: 6
Training loss: 1.5896371618166951
Validation loss: 2.5463011588586433

Epoch: 5| Step: 7
Training loss: 2.1282687011241253
Validation loss: 2.5664705397141723

Epoch: 5| Step: 8
Training loss: 2.4677972041420837
Validation loss: 2.557793800380415

Epoch: 5| Step: 9
Training loss: 2.272075861429977
Validation loss: 2.541756303306221

Epoch: 5| Step: 10
Training loss: 1.5307761257047314
Validation loss: 2.5824685584865783

Epoch: 5| Step: 11
Training loss: 1.842992400647877
Validation loss: 2.5364394190485804

Epoch: 122| Step: 0
Training loss: 2.3156434422632466
Validation loss: 2.5387819066649513

Epoch: 5| Step: 1
Training loss: 2.5998406654833444
Validation loss: 2.54941591230457

Epoch: 5| Step: 2
Training loss: 1.6548327013953839
Validation loss: 2.576312705493359

Epoch: 5| Step: 3
Training loss: 1.8654448225725204
Validation loss: 2.53940128902742

Epoch: 5| Step: 4
Training loss: 2.3106368523794947
Validation loss: 2.555506842187524

Epoch: 5| Step: 5
Training loss: 2.401335416244685
Validation loss: 2.547261483759878

Epoch: 5| Step: 6
Training loss: 2.1962500908405977
Validation loss: 2.5683167622056593

Epoch: 5| Step: 7
Training loss: 2.2544069576933077
Validation loss: 2.5673622816369366

Epoch: 5| Step: 8
Training loss: 2.2856549102019477
Validation loss: 2.579374211074515

Epoch: 5| Step: 9
Training loss: 2.3951455054949533
Validation loss: 2.5689026619376243

Epoch: 5| Step: 10
Training loss: 1.7266407254134752
Validation loss: 2.560695765104606

Epoch: 5| Step: 11
Training loss: 1.5371593966457777
Validation loss: 2.5713767502655624

Epoch: 123| Step: 0
Training loss: 2.5333988817000033
Validation loss: 2.5604402591207087

Epoch: 5| Step: 1
Training loss: 2.1420905672119535
Validation loss: 2.574120422708208

Epoch: 5| Step: 2
Training loss: 1.6852702491764933
Validation loss: 2.5701530778137

Epoch: 5| Step: 3
Training loss: 2.4676507361536495
Validation loss: 2.5774333353575916

Epoch: 5| Step: 4
Training loss: 2.657491506022877
Validation loss: 2.517145984417016

Epoch: 5| Step: 5
Training loss: 1.9934563279985777
Validation loss: 2.547993751653209

Epoch: 5| Step: 6
Training loss: 2.0795550481174176
Validation loss: 2.5420665908380515

Epoch: 5| Step: 7
Training loss: 2.4809076836972546
Validation loss: 2.535564182104693

Epoch: 5| Step: 8
Training loss: 2.371276245132819
Validation loss: 2.54691491359023

Epoch: 5| Step: 9
Training loss: 1.8968549497949292
Validation loss: 2.522309014538592

Epoch: 5| Step: 10
Training loss: 1.6423317160831017
Validation loss: 2.564274882668655

Epoch: 5| Step: 11
Training loss: 1.2119221283600445
Validation loss: 2.5752488401846283

Epoch: 124| Step: 0
Training loss: 2.103671125722886
Validation loss: 2.5884341761928353

Epoch: 5| Step: 1
Training loss: 1.9861162610939438
Validation loss: 2.642349522738305

Epoch: 5| Step: 2
Training loss: 2.141417530674467
Validation loss: 2.6561373929856904

Epoch: 5| Step: 3
Training loss: 2.5201201467785657
Validation loss: 2.651089704686618

Epoch: 5| Step: 4
Training loss: 1.9170146363664236
Validation loss: 2.6395077721414553

Epoch: 5| Step: 5
Training loss: 2.3193877461318833
Validation loss: 2.6185529496644384

Epoch: 5| Step: 6
Training loss: 1.857230993946167
Validation loss: 2.586283830575385

Epoch: 5| Step: 7
Training loss: 2.7399800427956063
Validation loss: 2.5666366117645736

Epoch: 5| Step: 8
Training loss: 1.3993394383234758
Validation loss: 2.6006466434320417

Epoch: 5| Step: 9
Training loss: 2.9642696905441666
Validation loss: 2.5681249088458467

Epoch: 5| Step: 10
Training loss: 1.492154745171833
Validation loss: 2.534911987888603

Epoch: 5| Step: 11
Training loss: 3.47064157408843
Validation loss: 2.557327224940028

Epoch: 125| Step: 0
Training loss: 2.492949079425784
Validation loss: 2.5505024600378268

Epoch: 5| Step: 1
Training loss: 1.724410429006748
Validation loss: 2.539906518966846

Epoch: 5| Step: 2
Training loss: 2.376865858671799
Validation loss: 2.543946277034916

Epoch: 5| Step: 3
Training loss: 2.4288719255801823
Validation loss: 2.5619947819325346

Epoch: 5| Step: 4
Training loss: 2.415303031911713
Validation loss: 2.5837627689739353

Epoch: 5| Step: 5
Training loss: 2.6617838939759895
Validation loss: 2.5456354951443148

Epoch: 5| Step: 6
Training loss: 2.3974790366552052
Validation loss: 2.546255919918244

Epoch: 5| Step: 7
Training loss: 2.1920168428887714
Validation loss: 2.5591856254907213

Epoch: 5| Step: 8
Training loss: 2.3190229023949454
Validation loss: 2.5422767756346225

Epoch: 5| Step: 9
Training loss: 1.9418117782766764
Validation loss: 2.5647876925098485

Epoch: 5| Step: 10
Training loss: 1.6666405993648337
Validation loss: 2.5416532005411927

Epoch: 5| Step: 11
Training loss: 2.202555156627652
Validation loss: 2.5331257455615916

Epoch: 126| Step: 0
Training loss: 2.215988912678604
Validation loss: 2.546489506978821

Epoch: 5| Step: 1
Training loss: 2.076037398080478
Validation loss: 2.5722037471819976

Epoch: 5| Step: 2
Training loss: 3.2269879446262553
Validation loss: 2.5302824949973273

Epoch: 5| Step: 3
Training loss: 1.8753364896837006
Validation loss: 2.565689838502368

Epoch: 5| Step: 4
Training loss: 2.23312791287659
Validation loss: 2.580816132087114

Epoch: 5| Step: 5
Training loss: 1.4811637273846354
Validation loss: 2.5566857326444046

Epoch: 5| Step: 6
Training loss: 1.6596064117050346
Validation loss: 2.573718422258603

Epoch: 5| Step: 7
Training loss: 2.125078760819245
Validation loss: 2.573847298650342

Epoch: 5| Step: 8
Training loss: 2.5257685143302777
Validation loss: 2.5876185628046393

Epoch: 5| Step: 9
Training loss: 1.8443762798556957
Validation loss: 2.5828686701333603

Epoch: 5| Step: 10
Training loss: 2.291610913609948
Validation loss: 2.5359363658539746

Epoch: 5| Step: 11
Training loss: 1.2542469358051318
Validation loss: 2.5481643299582184

Epoch: 127| Step: 0
Training loss: 2.4235279964075795
Validation loss: 2.5625578866018346

Epoch: 5| Step: 1
Training loss: 2.9493367758875113
Validation loss: 2.5415327174947446

Epoch: 5| Step: 2
Training loss: 2.07024109915202
Validation loss: 2.554816348747207

Epoch: 5| Step: 3
Training loss: 1.9253647297723533
Validation loss: 2.558448100130388

Epoch: 5| Step: 4
Training loss: 1.7136323512545255
Validation loss: 2.551220609204989

Epoch: 5| Step: 5
Training loss: 2.4124699249764783
Validation loss: 2.5305483987774258

Epoch: 5| Step: 6
Training loss: 2.1141626349824088
Validation loss: 2.5362782045566226

Epoch: 5| Step: 7
Training loss: 2.067197017402682
Validation loss: 2.536444784724861

Epoch: 5| Step: 8
Training loss: 1.7040362238996154
Validation loss: 2.5580420930694605

Epoch: 5| Step: 9
Training loss: 2.2619269346044346
Validation loss: 2.535262126700381

Epoch: 5| Step: 10
Training loss: 1.9145644794763084
Validation loss: 2.5370371639164535

Epoch: 5| Step: 11
Training loss: 1.1273654864271758
Validation loss: 2.534637566608701

Epoch: 128| Step: 0
Training loss: 1.5488868500206432
Validation loss: 2.5606644945557115

Epoch: 5| Step: 1
Training loss: 1.6340705369177926
Validation loss: 2.6118553312287816

Epoch: 5| Step: 2
Training loss: 1.7156773237855092
Validation loss: 2.597543615514105

Epoch: 5| Step: 3
Training loss: 2.1121988115658237
Validation loss: 2.600085380417764

Epoch: 5| Step: 4
Training loss: 2.4348488107856467
Validation loss: 2.5731400818807835

Epoch: 5| Step: 5
Training loss: 1.9436251511296199
Validation loss: 2.5974554534019703

Epoch: 5| Step: 6
Training loss: 2.6246362161605172
Validation loss: 2.6134297300694054

Epoch: 5| Step: 7
Training loss: 2.005679767891511
Validation loss: 2.652596762663248

Epoch: 5| Step: 8
Training loss: 2.4039965890615833
Validation loss: 2.581872424436276

Epoch: 5| Step: 9
Training loss: 2.1614694863150383
Validation loss: 2.5718708319493104

Epoch: 5| Step: 10
Training loss: 2.7338464716602378
Validation loss: 2.547873915445946

Epoch: 5| Step: 11
Training loss: 2.060436719508186
Validation loss: 2.572219798018501

Epoch: 129| Step: 0
Training loss: 2.1765184780031412
Validation loss: 2.5783612422402538

Epoch: 5| Step: 1
Training loss: 1.652898456360025
Validation loss: 2.5307059704165726

Epoch: 5| Step: 2
Training loss: 1.9908321781828404
Validation loss: 2.560336610883931

Epoch: 5| Step: 3
Training loss: 2.776846668168422
Validation loss: 2.519206686085849

Epoch: 5| Step: 4
Training loss: 2.144617742520947
Validation loss: 2.6001048467354604

Epoch: 5| Step: 5
Training loss: 2.2799612088835355
Validation loss: 2.5658249024833624

Epoch: 5| Step: 6
Training loss: 2.0032253484243414
Validation loss: 2.550542589504708

Epoch: 5| Step: 7
Training loss: 1.9671407510718668
Validation loss: 2.587353262142125

Epoch: 5| Step: 8
Training loss: 2.3477013404311684
Validation loss: 2.526680428405398

Epoch: 5| Step: 9
Training loss: 2.125819104469898
Validation loss: 2.552600357985806

Epoch: 5| Step: 10
Training loss: 2.1311064104053328
Validation loss: 2.5724845779526344

Epoch: 5| Step: 11
Training loss: 2.080976551867855
Validation loss: 2.561859093354797

Epoch: 130| Step: 0
Training loss: 2.0852342198681146
Validation loss: 2.577270158015957

Epoch: 5| Step: 1
Training loss: 2.9412178698599325
Validation loss: 2.5816915868669135

Epoch: 5| Step: 2
Training loss: 2.502030692286576
Validation loss: 2.5602947317554707

Epoch: 5| Step: 3
Training loss: 2.3907443746045645
Validation loss: 2.5810247162853943

Epoch: 5| Step: 4
Training loss: 1.9011913780589946
Validation loss: 2.576910183537065

Epoch: 5| Step: 5
Training loss: 1.7339470825172527
Validation loss: 2.5470529505808757

Epoch: 5| Step: 6
Training loss: 1.7356041341811064
Validation loss: 2.545960697124425

Epoch: 5| Step: 7
Training loss: 2.61753555944093
Validation loss: 2.520255465255335

Epoch: 5| Step: 8
Training loss: 2.133416282511424
Validation loss: 2.5216367928129864

Epoch: 5| Step: 9
Training loss: 1.6502613265271955
Validation loss: 2.5589193238893775

Epoch: 5| Step: 10
Training loss: 1.6501321624075647
Validation loss: 2.5344773859430108

Epoch: 5| Step: 11
Training loss: 2.106398792840805
Validation loss: 2.5610004006916385

Epoch: 131| Step: 0
Training loss: 2.254984949573441
Validation loss: 2.550336404657299

Epoch: 5| Step: 1
Training loss: 2.0580932472019984
Validation loss: 2.616329656045369

Epoch: 5| Step: 2
Training loss: 2.0711307851846534
Validation loss: 2.5804336884245824

Epoch: 5| Step: 3
Training loss: 1.9057754801498408
Validation loss: 2.6543668728829686

Epoch: 5| Step: 4
Training loss: 1.6204625383029416
Validation loss: 2.670623858167632

Epoch: 5| Step: 5
Training loss: 1.9365058317168047
Validation loss: 2.6449910360051003

Epoch: 5| Step: 6
Training loss: 2.8186699900299277
Validation loss: 2.6459795743721433

Epoch: 5| Step: 7
Training loss: 2.2340456846615258
Validation loss: 2.7053714157104483

Epoch: 5| Step: 8
Training loss: 2.4517735931951012
Validation loss: 2.690740180863897

Epoch: 5| Step: 9
Training loss: 2.1939644255001283
Validation loss: 2.69450552465307

Epoch: 5| Step: 10
Training loss: 1.9254419983572826
Validation loss: 2.6077390823101583

Epoch: 5| Step: 11
Training loss: 2.1596982722233857
Validation loss: 2.5850682214125307

Epoch: 132| Step: 0
Training loss: 2.98136422440295
Validation loss: 2.5388523425646854

Epoch: 5| Step: 1
Training loss: 2.007849192005748
Validation loss: 2.5466515183643197

Epoch: 5| Step: 2
Training loss: 1.9609874703776848
Validation loss: 2.528972908393041

Epoch: 5| Step: 3
Training loss: 2.2010728734252343
Validation loss: 2.573044585833147

Epoch: 5| Step: 4
Training loss: 2.0767451703258932
Validation loss: 2.538543839910926

Epoch: 5| Step: 5
Training loss: 2.3391566724555792
Validation loss: 2.5468725738825877

Epoch: 5| Step: 6
Training loss: 1.5680050574386546
Validation loss: 2.5304313992174494

Epoch: 5| Step: 7
Training loss: 1.9611921411055333
Validation loss: 2.535368257581293

Epoch: 5| Step: 8
Training loss: 2.403695670479468
Validation loss: 2.5476593982248548

Epoch: 5| Step: 9
Training loss: 2.202022844949656
Validation loss: 2.534643825787622

Epoch: 5| Step: 10
Training loss: 2.3365522615484693
Validation loss: 2.547984998841494

Epoch: 5| Step: 11
Training loss: 1.8876372761100788
Validation loss: 2.5483054140290085

Epoch: 133| Step: 0
Training loss: 1.7988737185454229
Validation loss: 2.5937106156327316

Epoch: 5| Step: 1
Training loss: 1.8610403472896853
Validation loss: 2.545042482544893

Epoch: 5| Step: 2
Training loss: 2.3467918493014572
Validation loss: 2.6278765826728963

Epoch: 5| Step: 3
Training loss: 2.0123306677051174
Validation loss: 2.6534975152062454

Epoch: 5| Step: 4
Training loss: 2.799868297885483
Validation loss: 2.626362204947083

Epoch: 5| Step: 5
Training loss: 2.2689127251563073
Validation loss: 2.62453730607682

Epoch: 5| Step: 6
Training loss: 2.0778642074891236
Validation loss: 2.6662839426132634

Epoch: 5| Step: 7
Training loss: 1.9856755357746703
Validation loss: 2.6109696843408283

Epoch: 5| Step: 8
Training loss: 2.2326477417111987
Validation loss: 2.6558937207807585

Epoch: 5| Step: 9
Training loss: 1.93880197402479
Validation loss: 2.5798123011215264

Epoch: 5| Step: 10
Training loss: 2.0635436914142944
Validation loss: 2.540196518623506

Epoch: 5| Step: 11
Training loss: 1.7009034673176067
Validation loss: 2.556561648764222

Epoch: 134| Step: 0
Training loss: 2.5968998546306072
Validation loss: 2.5744743934158527

Epoch: 5| Step: 1
Training loss: 2.641803546171157
Validation loss: 2.5570519380930112

Epoch: 5| Step: 2
Training loss: 2.0634911207632443
Validation loss: 2.5923083638378506

Epoch: 5| Step: 3
Training loss: 2.0381130770533704
Validation loss: 2.623214205065137

Epoch: 5| Step: 4
Training loss: 2.3471172304266097
Validation loss: 2.580842214213303

Epoch: 5| Step: 5
Training loss: 1.6604001572895826
Validation loss: 2.6367078314661088

Epoch: 5| Step: 6
Training loss: 2.2051743519332696
Validation loss: 2.5733044418342086

Epoch: 5| Step: 7
Training loss: 1.8810084393812372
Validation loss: 2.606055098883843

Epoch: 5| Step: 8
Training loss: 2.0879155185168243
Validation loss: 2.542423711399266

Epoch: 5| Step: 9
Training loss: 2.0493859185442456
Validation loss: 2.514335013304022

Epoch: 5| Step: 10
Training loss: 1.515131132537841
Validation loss: 2.523360732478654

Epoch: 5| Step: 11
Training loss: 2.6688094371457276
Validation loss: 2.5333864767739076

Epoch: 135| Step: 0
Training loss: 1.817387928819706
Validation loss: 2.55530618375794

Epoch: 5| Step: 1
Training loss: 2.4497877612924794
Validation loss: 2.5546099177565798

Epoch: 5| Step: 2
Training loss: 2.3579389231102676
Validation loss: 2.528255201994168

Epoch: 5| Step: 3
Training loss: 2.1143930158487496
Validation loss: 2.5342608900051653

Epoch: 5| Step: 4
Training loss: 2.5231982610809003
Validation loss: 2.5509877571608213

Epoch: 5| Step: 5
Training loss: 1.8227257183520622
Validation loss: 2.553680622025436

Epoch: 5| Step: 6
Training loss: 2.7514461702865676
Validation loss: 2.5824445777441003

Epoch: 5| Step: 7
Training loss: 1.9476813787927167
Validation loss: 2.6160181194474093

Epoch: 5| Step: 8
Training loss: 1.6846109313490614
Validation loss: 2.5897448920268213

Epoch: 5| Step: 9
Training loss: 1.6002119370999222
Validation loss: 2.6396203245979715

Epoch: 5| Step: 10
Training loss: 2.026308592902837
Validation loss: 2.625624669392883

Epoch: 5| Step: 11
Training loss: 2.0566366835046512
Validation loss: 2.5964726631776944

Epoch: 136| Step: 0
Training loss: 2.3358784033403044
Validation loss: 2.5663220775470714

Epoch: 5| Step: 1
Training loss: 1.8878750939956739
Validation loss: 2.5696459430580236

Epoch: 5| Step: 2
Training loss: 1.9018729565346502
Validation loss: 2.5155647065260562

Epoch: 5| Step: 3
Training loss: 1.962397301774905
Validation loss: 2.553523036445536

Epoch: 5| Step: 4
Training loss: 1.9253814467963808
Validation loss: 2.541035872233849

Epoch: 5| Step: 5
Training loss: 2.876238680489426
Validation loss: 2.5165438227850774

Epoch: 5| Step: 6
Training loss: 2.379563615045178
Validation loss: 2.5562172566612005

Epoch: 5| Step: 7
Training loss: 2.2712591162893845
Validation loss: 2.5628286127728903

Epoch: 5| Step: 8
Training loss: 1.684670796369033
Validation loss: 2.5218627669405236

Epoch: 5| Step: 9
Training loss: 1.69091662925427
Validation loss: 2.5446182425064547

Epoch: 5| Step: 10
Training loss: 2.3427024025938805
Validation loss: 2.5372651610047248

Epoch: 5| Step: 11
Training loss: 2.0422756558386412
Validation loss: 2.5522921781659025

Epoch: 137| Step: 0
Training loss: 2.4399608025763713
Validation loss: 2.5194126741959364

Epoch: 5| Step: 1
Training loss: 1.5585363085876944
Validation loss: 2.614950451907248

Epoch: 5| Step: 2
Training loss: 2.03098987967873
Validation loss: 2.5834059814010737

Epoch: 5| Step: 3
Training loss: 1.8306705326188608
Validation loss: 2.644117802916729

Epoch: 5| Step: 4
Training loss: 1.787229640228421
Validation loss: 2.6328617076256013

Epoch: 5| Step: 5
Training loss: 2.627311959983207
Validation loss: 2.689352598322332

Epoch: 5| Step: 6
Training loss: 2.447236787788998
Validation loss: 2.625152186114781

Epoch: 5| Step: 7
Training loss: 2.7943954131887354
Validation loss: 2.65912338124376

Epoch: 5| Step: 8
Training loss: 1.787492754728132
Validation loss: 2.6177910218016693

Epoch: 5| Step: 9
Training loss: 2.140645493458015
Validation loss: 2.5594662331392293

Epoch: 5| Step: 10
Training loss: 1.7522846023162586
Validation loss: 2.5734162746465916

Epoch: 5| Step: 11
Training loss: 1.9785905769212444
Validation loss: 2.53880485988153

Epoch: 138| Step: 0
Training loss: 2.2055862422487746
Validation loss: 2.5310311065814832

Epoch: 5| Step: 1
Training loss: 2.639047998238307
Validation loss: 2.551776970101508

Epoch: 5| Step: 2
Training loss: 2.0426983335238234
Validation loss: 2.563398227039708

Epoch: 5| Step: 3
Training loss: 1.7254230312269025
Validation loss: 2.5451336116542347

Epoch: 5| Step: 4
Training loss: 1.6893646393464237
Validation loss: 2.546814104534053

Epoch: 5| Step: 5
Training loss: 1.9409403251464015
Validation loss: 2.554453579520258

Epoch: 5| Step: 6
Training loss: 2.344408985319754
Validation loss: 2.5412693195137166

Epoch: 5| Step: 7
Training loss: 2.013435179658577
Validation loss: 2.5756425947689756

Epoch: 5| Step: 8
Training loss: 2.347223784717689
Validation loss: 2.532601698100958

Epoch: 5| Step: 9
Training loss: 2.1750322624532266
Validation loss: 2.538933972749206

Epoch: 5| Step: 10
Training loss: 2.4582580511775403
Validation loss: 2.5364557784509554

Epoch: 5| Step: 11
Training loss: 1.9018056370838468
Validation loss: 2.5569475386549794

Epoch: 139| Step: 0
Training loss: 2.059521344879297
Validation loss: 2.6247634818985603

Epoch: 5| Step: 1
Training loss: 2.463246645746374
Validation loss: 2.6726011995936747

Epoch: 5| Step: 2
Training loss: 2.819331540090093
Validation loss: 2.7154346435928947

Epoch: 5| Step: 3
Training loss: 1.4412976562614337
Validation loss: 2.6665052101808713

Epoch: 5| Step: 4
Training loss: 2.310826804583691
Validation loss: 2.6816534091601207

Epoch: 5| Step: 5
Training loss: 2.0259924116905728
Validation loss: 2.6733400035376187

Epoch: 5| Step: 6
Training loss: 1.6785587510323
Validation loss: 2.639786216497998

Epoch: 5| Step: 7
Training loss: 1.3985661282335256
Validation loss: 2.5856594424081862

Epoch: 5| Step: 8
Training loss: 2.3447623546049936
Validation loss: 2.5822754137072184

Epoch: 5| Step: 9
Training loss: 2.1947061916436925
Validation loss: 2.6097283343025364

Epoch: 5| Step: 10
Training loss: 2.1176074973319174
Validation loss: 2.5916861093861

Epoch: 5| Step: 11
Training loss: 1.4880175419460484
Validation loss: 2.5670344427247844

Epoch: 140| Step: 0
Training loss: 1.7239928304518737
Validation loss: 2.568871740718807

Epoch: 5| Step: 1
Training loss: 2.0487929814818377
Validation loss: 2.5525189916668247

Epoch: 5| Step: 2
Training loss: 2.383690744112607
Validation loss: 2.5550336379681746

Epoch: 5| Step: 3
Training loss: 2.2683443784012733
Validation loss: 2.534076980146136

Epoch: 5| Step: 4
Training loss: 2.234369344637456
Validation loss: 2.5619556306234963

Epoch: 5| Step: 5
Training loss: 1.5417839040082548
Validation loss: 2.5716414798665967

Epoch: 5| Step: 6
Training loss: 2.626198177271184
Validation loss: 2.520922585685952

Epoch: 5| Step: 7
Training loss: 1.7681767751341435
Validation loss: 2.547770239479023

Epoch: 5| Step: 8
Training loss: 1.9610223029899727
Validation loss: 2.5275515078368977

Epoch: 5| Step: 9
Training loss: 2.275457264984449
Validation loss: 2.553699566807909

Epoch: 5| Step: 10
Training loss: 2.1754250911229747
Validation loss: 2.5575634578204216

Epoch: 5| Step: 11
Training loss: 1.9127525362320292
Validation loss: 2.5755871120419442

Epoch: 141| Step: 0
Training loss: 2.1331097182657794
Validation loss: 2.6152698684422417

Epoch: 5| Step: 1
Training loss: 1.4272647194784063
Validation loss: 2.603628417021243

Epoch: 5| Step: 2
Training loss: 2.275858111512621
Validation loss: 2.5930378215739363

Epoch: 5| Step: 3
Training loss: 1.985385727482874
Validation loss: 2.6274488319377585

Epoch: 5| Step: 4
Training loss: 1.385664074062491
Validation loss: 2.6395448680133398

Epoch: 5| Step: 5
Training loss: 2.1754322148719516
Validation loss: 2.6376831325573216

Epoch: 5| Step: 6
Training loss: 2.4128590766236266
Validation loss: 2.607213314635327

Epoch: 5| Step: 7
Training loss: 2.7046534456239106
Validation loss: 2.585507125614262

Epoch: 5| Step: 8
Training loss: 1.9249489864178946
Validation loss: 2.5389319303147686

Epoch: 5| Step: 9
Training loss: 2.3145185372810744
Validation loss: 2.5656836550625393

Epoch: 5| Step: 10
Training loss: 1.8089771894173445
Validation loss: 2.5480879136306633

Epoch: 5| Step: 11
Training loss: 1.9180024992853932
Validation loss: 2.5606943374642688

Epoch: 142| Step: 0
Training loss: 2.118456133152641
Validation loss: 2.5170011724917165

Epoch: 5| Step: 1
Training loss: 2.058397316292156
Validation loss: 2.4969580382288057

Epoch: 5| Step: 2
Training loss: 1.8637308981701375
Validation loss: 2.548460133614009

Epoch: 5| Step: 3
Training loss: 2.472633687137875
Validation loss: 2.5605951533069016

Epoch: 5| Step: 4
Training loss: 2.0963517151496407
Validation loss: 2.537607110398404

Epoch: 5| Step: 5
Training loss: 2.3067362327044956
Validation loss: 2.551159829149383

Epoch: 5| Step: 6
Training loss: 2.2910279048450737
Validation loss: 2.5401147667107846

Epoch: 5| Step: 7
Training loss: 1.7865346849620665
Validation loss: 2.5711422269924897

Epoch: 5| Step: 8
Training loss: 1.8107112081570884
Validation loss: 2.580281964050886

Epoch: 5| Step: 9
Training loss: 1.961155852665051
Validation loss: 2.5453399096270446

Epoch: 5| Step: 10
Training loss: 2.0781688255335355
Validation loss: 2.603573488707104

Epoch: 5| Step: 11
Training loss: 1.1875981240137894
Validation loss: 2.5758938199468293

Epoch: 143| Step: 0
Training loss: 1.6890934379348541
Validation loss: 2.554975996924946

Epoch: 5| Step: 1
Training loss: 1.070236036256347
Validation loss: 2.5565125792989876

Epoch: 5| Step: 2
Training loss: 2.166212205419564
Validation loss: 2.5611486031006643

Epoch: 5| Step: 3
Training loss: 2.512244470612056
Validation loss: 2.570055831879131

Epoch: 5| Step: 4
Training loss: 2.130471422384703
Validation loss: 2.583914807979371

Epoch: 5| Step: 5
Training loss: 2.008762120208542
Validation loss: 2.590795438963173

Epoch: 5| Step: 6
Training loss: 1.726118764342982
Validation loss: 2.5728368180480707

Epoch: 5| Step: 7
Training loss: 2.716100168743404
Validation loss: 2.5768381664151927

Epoch: 5| Step: 8
Training loss: 2.411365273796796
Validation loss: 2.5356832660841135

Epoch: 5| Step: 9
Training loss: 1.7683814483673854
Validation loss: 2.5370441748483734

Epoch: 5| Step: 10
Training loss: 2.1308979761698987
Validation loss: 2.570643874183429

Epoch: 5| Step: 11
Training loss: 1.9821892061546424
Validation loss: 2.5558475500913116

Epoch: 144| Step: 0
Training loss: 1.9296571675129008
Validation loss: 2.5495647744653875

Epoch: 5| Step: 1
Training loss: 2.0168228729954443
Validation loss: 2.5448290636456226

Epoch: 5| Step: 2
Training loss: 2.576283114839123
Validation loss: 2.5744059199901006

Epoch: 5| Step: 3
Training loss: 1.7275213280560533
Validation loss: 2.588740812555794

Epoch: 5| Step: 4
Training loss: 2.0323305043847406
Validation loss: 2.601670042455692

Epoch: 5| Step: 5
Training loss: 2.448056664758479
Validation loss: 2.558105026044114

Epoch: 5| Step: 6
Training loss: 2.121979080816158
Validation loss: 2.5695240353523308

Epoch: 5| Step: 7
Training loss: 2.6078638509422363
Validation loss: 2.547807370698525

Epoch: 5| Step: 8
Training loss: 1.7254276602434053
Validation loss: 2.5368481492511146

Epoch: 5| Step: 9
Training loss: 1.7468941921210301
Validation loss: 2.5426431340963283

Epoch: 5| Step: 10
Training loss: 1.519695832035318
Validation loss: 2.5617189069776765

Epoch: 5| Step: 11
Training loss: 1.341321658364887
Validation loss: 2.58539528362726

Epoch: 145| Step: 0
Training loss: 2.060898592612747
Validation loss: 2.571382692078493

Epoch: 5| Step: 1
Training loss: 2.053099508141783
Validation loss: 2.5861103733820627

Epoch: 5| Step: 2
Training loss: 1.759131314084907
Validation loss: 2.595246143935827

Epoch: 5| Step: 3
Training loss: 2.480006954429474
Validation loss: 2.564332527759111

Epoch: 5| Step: 4
Training loss: 2.0939800079178337
Validation loss: 2.570339768950139

Epoch: 5| Step: 5
Training loss: 2.0548832441144045
Validation loss: 2.538953907918596

Epoch: 5| Step: 6
Training loss: 2.5041777988721683
Validation loss: 2.5443022864957285

Epoch: 5| Step: 7
Training loss: 2.094412855297412
Validation loss: 2.5458666593760544

Epoch: 5| Step: 8
Training loss: 1.8213064729814612
Validation loss: 2.564672934725264

Epoch: 5| Step: 9
Training loss: 1.7822992681017544
Validation loss: 2.5428459344867407

Epoch: 5| Step: 10
Training loss: 1.7313688189224272
Validation loss: 2.5472837170876477

Epoch: 5| Step: 11
Training loss: 1.138037162797455
Validation loss: 2.601959606789296

Epoch: 146| Step: 0
Training loss: 2.270262398531239
Validation loss: 2.6117297909558697

Epoch: 5| Step: 1
Training loss: 2.576172430285668
Validation loss: 2.636413315401603

Epoch: 5| Step: 2
Training loss: 1.5294074826051136
Validation loss: 2.625905875922334

Epoch: 5| Step: 3
Training loss: 1.9290795237205465
Validation loss: 2.6643230239996902

Epoch: 5| Step: 4
Training loss: 1.6956394425257606
Validation loss: 2.6426882799585854

Epoch: 5| Step: 5
Training loss: 1.8277954717486309
Validation loss: 2.665154506428347

Epoch: 5| Step: 6
Training loss: 1.7055941540426443
Validation loss: 2.645513140960656

Epoch: 5| Step: 7
Training loss: 1.9954530766494158
Validation loss: 2.6364406184688134

Epoch: 5| Step: 8
Training loss: 2.151180112014941
Validation loss: 2.64071534733955

Epoch: 5| Step: 9
Training loss: 1.9294459388674157
Validation loss: 2.668229019181913

Epoch: 5| Step: 10
Training loss: 2.2023790327576824
Validation loss: 2.6618932597559684

Epoch: 5| Step: 11
Training loss: 3.630728043617283
Validation loss: 2.6142142112533997

Epoch: 147| Step: 0
Training loss: 2.4906162582492937
Validation loss: 2.565135852340471

Epoch: 5| Step: 1
Training loss: 1.5736472178521024
Validation loss: 2.5759875713879326

Epoch: 5| Step: 2
Training loss: 2.403063261630495
Validation loss: 2.564498753757909

Epoch: 5| Step: 3
Training loss: 2.4734165173891864
Validation loss: 2.5789382884814627

Epoch: 5| Step: 4
Training loss: 1.6016417693082912
Validation loss: 2.5911332186035616

Epoch: 5| Step: 5
Training loss: 2.3772684607491548
Validation loss: 2.5889152062892546

Epoch: 5| Step: 6
Training loss: 2.001599506688229
Validation loss: 2.558174378482144

Epoch: 5| Step: 7
Training loss: 2.1576627443182574
Validation loss: 2.5591239826286887

Epoch: 5| Step: 8
Training loss: 2.0795217996873117
Validation loss: 2.5610792710802226

Epoch: 5| Step: 9
Training loss: 2.179760347194988
Validation loss: 2.549175004021623

Epoch: 5| Step: 10
Training loss: 1.7270558200511383
Validation loss: 2.541927818004084

Epoch: 5| Step: 11
Training loss: 2.8958435790248904
Validation loss: 2.552352242348139

Epoch: 148| Step: 0
Training loss: 1.8073546941872218
Validation loss: 2.532648622426531

Epoch: 5| Step: 1
Training loss: 2.2873972801950795
Validation loss: 2.5866458379834345

Epoch: 5| Step: 2
Training loss: 2.4559239256008363
Validation loss: 2.5246508174333613

Epoch: 5| Step: 3
Training loss: 1.5853809451249126
Validation loss: 2.60435358648222

Epoch: 5| Step: 4
Training loss: 2.493343838382289
Validation loss: 2.5854379223224653

Epoch: 5| Step: 5
Training loss: 1.8164207539953523
Validation loss: 2.5992972752418297

Epoch: 5| Step: 6
Training loss: 2.085236277925797
Validation loss: 2.565179617816137

Epoch: 5| Step: 7
Training loss: 1.200869737788504
Validation loss: 2.624837251568079

Epoch: 5| Step: 8
Training loss: 2.6454436448244167
Validation loss: 2.5844187007470416

Epoch: 5| Step: 9
Training loss: 1.8407748512705373
Validation loss: 2.5979375127666215

Epoch: 5| Step: 10
Training loss: 1.9737296932400696
Validation loss: 2.621998931462511

Epoch: 5| Step: 11
Training loss: 1.2865835687423923
Validation loss: 2.5709195487859104

Epoch: 149| Step: 0
Training loss: 1.9087481779378352
Validation loss: 2.585021426236889

Epoch: 5| Step: 1
Training loss: 1.8260322395018982
Validation loss: 2.62661053055557

Epoch: 5| Step: 2
Training loss: 2.0330770638528923
Validation loss: 2.594488999978918

Epoch: 5| Step: 3
Training loss: 1.6803688973768118
Validation loss: 2.586590468377715

Epoch: 5| Step: 4
Training loss: 1.2712767353828671
Validation loss: 2.60497572093127

Epoch: 5| Step: 5
Training loss: 2.891959052644143
Validation loss: 2.607432218952592

Epoch: 5| Step: 6
Training loss: 2.5347381858381053
Validation loss: 2.612731796001937

Epoch: 5| Step: 7
Training loss: 2.0385136943672473
Validation loss: 2.6334700135983353

Epoch: 5| Step: 8
Training loss: 1.9789649927552178
Validation loss: 2.641916152169425

Epoch: 5| Step: 9
Training loss: 1.8991011727145903
Validation loss: 2.6078326679148516

Epoch: 5| Step: 10
Training loss: 1.659186081989039
Validation loss: 2.607500598495332

Epoch: 5| Step: 11
Training loss: 2.7643596103489085
Validation loss: 2.556724016594109

Epoch: 150| Step: 0
Training loss: 1.5842591975099969
Validation loss: 2.6131653125630563

Epoch: 5| Step: 1
Training loss: 2.6935644701020145
Validation loss: 2.602122509073266

Epoch: 5| Step: 2
Training loss: 1.8185829164503682
Validation loss: 2.5884558870057868

Epoch: 5| Step: 3
Training loss: 1.8742309900657723
Validation loss: 2.568921246973356

Epoch: 5| Step: 4
Training loss: 2.1024088803752616
Validation loss: 2.565298219624697

Epoch: 5| Step: 5
Training loss: 2.096100242510852
Validation loss: 2.5591663214972002

Epoch: 5| Step: 6
Training loss: 2.106076296200468
Validation loss: 2.5516527098052455

Epoch: 5| Step: 7
Training loss: 1.620833998862214
Validation loss: 2.5686014387696847

Epoch: 5| Step: 8
Training loss: 2.337847894901121
Validation loss: 2.566970830833984

Epoch: 5| Step: 9
Training loss: 1.8694523438804316
Validation loss: 2.6103355444328553

Epoch: 5| Step: 10
Training loss: 2.0301131368219654
Validation loss: 2.645320881505262

Epoch: 5| Step: 11
Training loss: 1.5380417590381499
Validation loss: 2.62315557410384

Epoch: 151| Step: 0
Training loss: 1.8274834314057071
Validation loss: 2.6215229090518384

Epoch: 5| Step: 1
Training loss: 2.2806571294560416
Validation loss: 2.604265380260021

Epoch: 5| Step: 2
Training loss: 2.029194187653931
Validation loss: 2.6468442158445793

Epoch: 5| Step: 3
Training loss: 1.5787416518618125
Validation loss: 2.6141496820498995

Epoch: 5| Step: 4
Training loss: 1.7485690397224884
Validation loss: 2.645422908659233

Epoch: 5| Step: 5
Training loss: 2.1596628353326115
Validation loss: 2.6587777097184984

Epoch: 5| Step: 6
Training loss: 1.7729156667465218
Validation loss: 2.632578404524832

Epoch: 5| Step: 7
Training loss: 1.8989070107671864
Validation loss: 2.5812965748320473

Epoch: 5| Step: 8
Training loss: 2.2795917284315936
Validation loss: 2.5695269658752835

Epoch: 5| Step: 9
Training loss: 2.22496451874635
Validation loss: 2.563929035278399

Epoch: 5| Step: 10
Training loss: 2.138085299661056
Validation loss: 2.5454338458512815

Epoch: 5| Step: 11
Training loss: 1.5227010658679803
Validation loss: 2.5645328614892584

Epoch: 152| Step: 0
Training loss: 1.960695168161015
Validation loss: 2.563252718401512

Epoch: 5| Step: 1
Training loss: 1.6772560441389706
Validation loss: 2.582258559785832

Epoch: 5| Step: 2
Training loss: 2.1068373497897834
Validation loss: 2.5471291795516486

Epoch: 5| Step: 3
Training loss: 2.1016417988277247
Validation loss: 2.570590559770981

Epoch: 5| Step: 4
Training loss: 2.3109972427001773
Validation loss: 2.615507271630334

Epoch: 5| Step: 5
Training loss: 1.9038292569890443
Validation loss: 2.566654547491402

Epoch: 5| Step: 6
Training loss: 1.9396452563679105
Validation loss: 2.5751092457821834

Epoch: 5| Step: 7
Training loss: 1.5765426558879878
Validation loss: 2.583777890613889

Epoch: 5| Step: 8
Training loss: 1.8351472493060992
Validation loss: 2.596977542944371

Epoch: 5| Step: 9
Training loss: 1.8651916179449826
Validation loss: 2.600929767542607

Epoch: 5| Step: 10
Training loss: 2.590739605879922
Validation loss: 2.592347736936139

Epoch: 5| Step: 11
Training loss: 2.5129738811527584
Validation loss: 2.574668462946598

Epoch: 153| Step: 0
Training loss: 1.7014373677238994
Validation loss: 2.613355851260878

Epoch: 5| Step: 1
Training loss: 2.487491308609237
Validation loss: 2.65485622265749

Epoch: 5| Step: 2
Training loss: 2.352892325399077
Validation loss: 2.699776712798065

Epoch: 5| Step: 3
Training loss: 1.471762307422901
Validation loss: 2.7400934224346183

Epoch: 5| Step: 4
Training loss: 2.3126493869677343
Validation loss: 2.6892650633609914

Epoch: 5| Step: 5
Training loss: 1.8199029551822614
Validation loss: 2.670098891177068

Epoch: 5| Step: 6
Training loss: 1.7111277017298263
Validation loss: 2.6858285171326735

Epoch: 5| Step: 7
Training loss: 2.1490311236002695
Validation loss: 2.6259248027852418

Epoch: 5| Step: 8
Training loss: 1.9352200537255584
Validation loss: 2.630913072853195

Epoch: 5| Step: 9
Training loss: 2.365185788298963
Validation loss: 2.594335646943906

Epoch: 5| Step: 10
Training loss: 1.7323226470226183
Validation loss: 2.5719348537422215

Epoch: 5| Step: 11
Training loss: 2.1287980638365487
Validation loss: 2.5665959288604925

Epoch: 154| Step: 0
Training loss: 1.5516175290094352
Validation loss: 2.601715518701297

Epoch: 5| Step: 1
Training loss: 1.8834352215350736
Validation loss: 2.558107491992593

Epoch: 5| Step: 2
Training loss: 2.2092494383963723
Validation loss: 2.5987097723879313

Epoch: 5| Step: 3
Training loss: 1.5996836737027902
Validation loss: 2.6028025881985823

Epoch: 5| Step: 4
Training loss: 2.1339356535744445
Validation loss: 2.5531169757382295

Epoch: 5| Step: 5
Training loss: 2.1779242052213306
Validation loss: 2.5843283803195236

Epoch: 5| Step: 6
Training loss: 2.1533823155755902
Validation loss: 2.541798796632747

Epoch: 5| Step: 7
Training loss: 1.9256650568514215
Validation loss: 2.613814249694812

Epoch: 5| Step: 8
Training loss: 2.1187141798024105
Validation loss: 2.612131360920203

Epoch: 5| Step: 9
Training loss: 2.002378360897163
Validation loss: 2.6171562686404197

Epoch: 5| Step: 10
Training loss: 1.6505308193275054
Validation loss: 2.5993482772433123

Epoch: 5| Step: 11
Training loss: 2.524619377832961
Validation loss: 2.6018301985499432

Epoch: 155| Step: 0
Training loss: 2.056696848449503
Validation loss: 2.5982651496413

Epoch: 5| Step: 1
Training loss: 1.754279829650442
Validation loss: 2.6119860379302042

Epoch: 5| Step: 2
Training loss: 1.728336786188829
Validation loss: 2.619813431079977

Epoch: 5| Step: 3
Training loss: 2.2469294046704613
Validation loss: 2.6018937198852194

Epoch: 5| Step: 4
Training loss: 2.5299515396121017
Validation loss: 2.6300378964537927

Epoch: 5| Step: 5
Training loss: 2.0025354050305526
Validation loss: 2.612123904999047

Epoch: 5| Step: 6
Training loss: 1.750845772857753
Validation loss: 2.6301282448740215

Epoch: 5| Step: 7
Training loss: 1.9229987355990328
Validation loss: 2.601210512133141

Epoch: 5| Step: 8
Training loss: 1.5998534224842125
Validation loss: 2.6047324341679836

Epoch: 5| Step: 9
Training loss: 1.9108040614103516
Validation loss: 2.605342539752561

Epoch: 5| Step: 10
Training loss: 2.101155521735546
Validation loss: 2.6233466784910506

Epoch: 5| Step: 11
Training loss: 1.535351922763442
Validation loss: 2.5661522145879423

Epoch: 156| Step: 0
Training loss: 2.002018267804468
Validation loss: 2.5806474733686793

Epoch: 5| Step: 1
Training loss: 1.9166439787586127
Validation loss: 2.578898250332836

Epoch: 5| Step: 2
Training loss: 2.496463467673514
Validation loss: 2.5710007945060367

Epoch: 5| Step: 3
Training loss: 1.554617952104312
Validation loss: 2.531147801726195

Epoch: 5| Step: 4
Training loss: 1.6434545911475809
Validation loss: 2.5848210855027767

Epoch: 5| Step: 5
Training loss: 2.306467590818817
Validation loss: 2.542756567412487

Epoch: 5| Step: 6
Training loss: 2.1456030441214224
Validation loss: 2.547586747240818

Epoch: 5| Step: 7
Training loss: 1.5195474108937363
Validation loss: 2.5776352176323463

Epoch: 5| Step: 8
Training loss: 1.6511469264928609
Validation loss: 2.6435148989827155

Epoch: 5| Step: 9
Training loss: 2.4947811012336354
Validation loss: 2.642390870205068

Epoch: 5| Step: 10
Training loss: 1.9768986472670171
Validation loss: 2.6662103602793183

Epoch: 5| Step: 11
Training loss: 1.4276726705469587
Validation loss: 2.60426646550003

Epoch: 157| Step: 0
Training loss: 1.6436879222446796
Validation loss: 2.628642469060952

Epoch: 5| Step: 1
Training loss: 1.7350458445799608
Validation loss: 2.586888794267362

Epoch: 5| Step: 2
Training loss: 2.7787496064151926
Validation loss: 2.5752743576392017

Epoch: 5| Step: 3
Training loss: 1.8340392993181693
Validation loss: 2.573018779864755

Epoch: 5| Step: 4
Training loss: 2.1779974397936748
Validation loss: 2.572491708531439

Epoch: 5| Step: 5
Training loss: 2.065062231830263
Validation loss: 2.553270695644703

Epoch: 5| Step: 6
Training loss: 1.9589369702522388
Validation loss: 2.583833247441415

Epoch: 5| Step: 7
Training loss: 1.756697644510089
Validation loss: 2.5925906091132473

Epoch: 5| Step: 8
Training loss: 1.9407737515209997
Validation loss: 2.60496756381527

Epoch: 5| Step: 9
Training loss: 1.865356441318314
Validation loss: 2.580981427337833

Epoch: 5| Step: 10
Training loss: 1.6991008849208078
Validation loss: 2.623327354343957

Epoch: 5| Step: 11
Training loss: 1.498472469108752
Validation loss: 2.6239661194030974

Epoch: 158| Step: 0
Training loss: 2.3538625627648666
Validation loss: 2.624510284186866

Epoch: 5| Step: 1
Training loss: 2.236847583126293
Validation loss: 2.6785987295545697

Epoch: 5| Step: 2
Training loss: 2.2091182057713237
Validation loss: 2.689996642739329

Epoch: 5| Step: 3
Training loss: 2.1088790875751893
Validation loss: 2.677677076947709

Epoch: 5| Step: 4
Training loss: 1.731370333679534
Validation loss: 2.678228813542185

Epoch: 5| Step: 5
Training loss: 1.6318276095220616
Validation loss: 2.643139246020258

Epoch: 5| Step: 6
Training loss: 2.0263209473263326
Validation loss: 2.6472251765539445

Epoch: 5| Step: 7
Training loss: 1.5201240697217488
Validation loss: 2.6096784068836016

Epoch: 5| Step: 8
Training loss: 1.9930017938869
Validation loss: 2.6100197336271806

Epoch: 5| Step: 9
Training loss: 1.722940572859549
Validation loss: 2.610467980715924

Epoch: 5| Step: 10
Training loss: 2.0248931008839266
Validation loss: 2.6343399959605294

Epoch: 5| Step: 11
Training loss: 1.802799244351056
Validation loss: 2.5575869494001995

Epoch: 159| Step: 0
Training loss: 2.3452474261055145
Validation loss: 2.5895826439205694

Epoch: 5| Step: 1
Training loss: 2.1087931642936746
Validation loss: 2.5942751762590177

Epoch: 5| Step: 2
Training loss: 1.7289315795421984
Validation loss: 2.5676784797361885

Epoch: 5| Step: 3
Training loss: 1.7426562170553535
Validation loss: 2.5838586532060677

Epoch: 5| Step: 4
Training loss: 2.1052560787332872
Validation loss: 2.595015052624351

Epoch: 5| Step: 5
Training loss: 1.3078825427113763
Validation loss: 2.5927030028159024

Epoch: 5| Step: 6
Training loss: 1.9495132621319906
Validation loss: 2.5864274750700926

Epoch: 5| Step: 7
Training loss: 1.9496527974042008
Validation loss: 2.563895686688084

Epoch: 5| Step: 8
Training loss: 2.4171962705821715
Validation loss: 2.5994919870547437

Epoch: 5| Step: 9
Training loss: 1.703067043613229
Validation loss: 2.585222965723414

Epoch: 5| Step: 10
Training loss: 1.787618729176188
Validation loss: 2.6304052877177506

Epoch: 5| Step: 11
Training loss: 1.1543470136206528
Validation loss: 2.6333838351352528

Epoch: 160| Step: 0
Training loss: 2.363317265511984
Validation loss: 2.622054025041796

Epoch: 5| Step: 1
Training loss: 1.6715636631934312
Validation loss: 2.6050238393875236

Epoch: 5| Step: 2
Training loss: 2.4013446498090913
Validation loss: 2.601090733059356

Epoch: 5| Step: 3
Training loss: 1.9919880486669854
Validation loss: 2.669491115257576

Epoch: 5| Step: 4
Training loss: 2.0462969480615456
Validation loss: 2.667885432285164

Epoch: 5| Step: 5
Training loss: 1.770770449550311
Validation loss: 2.660265236450428

Epoch: 5| Step: 6
Training loss: 1.2032443891466178
Validation loss: 2.6310275183859675

Epoch: 5| Step: 7
Training loss: 2.2036838769540243
Validation loss: 2.6271442480887894

Epoch: 5| Step: 8
Training loss: 1.729152342342503
Validation loss: 2.6371045204810675

Epoch: 5| Step: 9
Training loss: 2.020751112481136
Validation loss: 2.561128801901086

Epoch: 5| Step: 10
Training loss: 1.5921717290125297
Validation loss: 2.605652378975753

Epoch: 5| Step: 11
Training loss: 1.2162276845611821
Validation loss: 2.5772401273721304

Epoch: 161| Step: 0
Training loss: 1.8838827802998461
Validation loss: 2.5699309478443446

Epoch: 5| Step: 1
Training loss: 1.6254459649465243
Validation loss: 2.5800450814051734

Epoch: 5| Step: 2
Training loss: 2.431255067952422
Validation loss: 2.612661618005025

Epoch: 5| Step: 3
Training loss: 2.0119173711111276
Validation loss: 2.599026311521775

Epoch: 5| Step: 4
Training loss: 1.8575490753550215
Validation loss: 2.6446397252939886

Epoch: 5| Step: 5
Training loss: 1.4093995322653128
Validation loss: 2.6539944253504584

Epoch: 5| Step: 6
Training loss: 2.16529056669543
Validation loss: 2.619685192990697

Epoch: 5| Step: 7
Training loss: 2.0133651958664305
Validation loss: 2.627968041158887

Epoch: 5| Step: 8
Training loss: 2.233584177344278
Validation loss: 2.636044999685321

Epoch: 5| Step: 9
Training loss: 1.777921008592049
Validation loss: 2.6180276992916873

Epoch: 5| Step: 10
Training loss: 1.6926757418111402
Validation loss: 2.5928447284942995

Epoch: 5| Step: 11
Training loss: 1.4626528211776957
Validation loss: 2.606387672630246

Epoch: 162| Step: 0
Training loss: 2.0298572166853
Validation loss: 2.6101917275471864

Epoch: 5| Step: 1
Training loss: 1.8678389813296437
Validation loss: 2.597942246681034

Epoch: 5| Step: 2
Training loss: 1.9906307346135632
Validation loss: 2.5641363315773553

Epoch: 5| Step: 3
Training loss: 2.0601847976830254
Validation loss: 2.5698034445239273

Epoch: 5| Step: 4
Training loss: 1.5455596417631214
Validation loss: 2.597920022445832

Epoch: 5| Step: 5
Training loss: 1.668206084114837
Validation loss: 2.5847683056444706

Epoch: 5| Step: 6
Training loss: 1.715654950323443
Validation loss: 2.594958843285808

Epoch: 5| Step: 7
Training loss: 2.584229149906187
Validation loss: 2.600778432920746

Epoch: 5| Step: 8
Training loss: 1.9292018140168572
Validation loss: 2.6275293202825587

Epoch: 5| Step: 9
Training loss: 1.8669910407359631
Validation loss: 2.6192021221666315

Epoch: 5| Step: 10
Training loss: 1.7143196573757167
Validation loss: 2.6193227834980197

Epoch: 5| Step: 11
Training loss: 1.3673090853442051
Validation loss: 2.624536250036758

Epoch: 163| Step: 0
Training loss: 1.6774882978778756
Validation loss: 2.6968219584630297

Epoch: 5| Step: 1
Training loss: 1.566662317973385
Validation loss: 2.6898157765897497

Epoch: 5| Step: 2
Training loss: 1.9007246266941475
Validation loss: 2.693148026762249

Epoch: 5| Step: 3
Training loss: 1.920965584307155
Validation loss: 2.636020746972381

Epoch: 5| Step: 4
Training loss: 1.4069244886495436
Validation loss: 2.6164473061023314

Epoch: 5| Step: 5
Training loss: 1.5708199056090242
Validation loss: 2.6337029887745573

Epoch: 5| Step: 6
Training loss: 2.0873482609039113
Validation loss: 2.608328725629968

Epoch: 5| Step: 7
Training loss: 2.44737570987689
Validation loss: 2.581539428469926

Epoch: 5| Step: 8
Training loss: 1.7963751719695493
Validation loss: 2.6496679022963643

Epoch: 5| Step: 9
Training loss: 2.151328621136391
Validation loss: 2.6651526017242424

Epoch: 5| Step: 10
Training loss: 2.4526400724612496
Validation loss: 2.581890789141611

Epoch: 5| Step: 11
Training loss: 1.97811725970497
Validation loss: 2.5898327489190605

Epoch: 164| Step: 0
Training loss: 1.7874349995779049
Validation loss: 2.5814014114849595

Epoch: 5| Step: 1
Training loss: 2.014736127401159
Validation loss: 2.54374033467599

Epoch: 5| Step: 2
Training loss: 1.4746481782974064
Validation loss: 2.570437545208217

Epoch: 5| Step: 3
Training loss: 1.908729816322559
Validation loss: 2.6457298789236225

Epoch: 5| Step: 4
Training loss: 1.760803526255826
Validation loss: 2.5892277517705717

Epoch: 5| Step: 5
Training loss: 1.9792374313820804
Validation loss: 2.5875807474655037

Epoch: 5| Step: 6
Training loss: 1.7382585502599663
Validation loss: 2.559937149185294

Epoch: 5| Step: 7
Training loss: 2.4811516730286267
Validation loss: 2.610678432905018

Epoch: 5| Step: 8
Training loss: 2.2295736731577374
Validation loss: 2.5858836134782814

Epoch: 5| Step: 9
Training loss: 1.6931480267023105
Validation loss: 2.5695385680844

Epoch: 5| Step: 10
Training loss: 1.839161805199906
Validation loss: 2.6127226935388643

Epoch: 5| Step: 11
Training loss: 2.3475985654830773
Validation loss: 2.6045294292825845

Epoch: 165| Step: 0
Training loss: 1.763511810981345
Validation loss: 2.6145948749201375

Epoch: 5| Step: 1
Training loss: 1.8036362529797254
Validation loss: 2.684974104403001

Epoch: 5| Step: 2
Training loss: 2.736227922694687
Validation loss: 2.6583781748809345

Epoch: 5| Step: 3
Training loss: 1.60077502732117
Validation loss: 2.6883370810973535

Epoch: 5| Step: 4
Training loss: 1.7766234562732333
Validation loss: 2.660947337555186

Epoch: 5| Step: 5
Training loss: 2.068538956955578
Validation loss: 2.6852733976817884

Epoch: 5| Step: 6
Training loss: 1.7520976437571274
Validation loss: 2.6591742164461207

Epoch: 5| Step: 7
Training loss: 1.7549785233403468
Validation loss: 2.647025544975721

Epoch: 5| Step: 8
Training loss: 2.1082957579791297
Validation loss: 2.687403773278044

Epoch: 5| Step: 9
Training loss: 1.685902864031455
Validation loss: 2.6146473300492947

Epoch: 5| Step: 10
Training loss: 1.5474052676291292
Validation loss: 2.630531794736012

Epoch: 5| Step: 11
Training loss: 0.9729778263764647
Validation loss: 2.576086278596725

Epoch: 166| Step: 0
Training loss: 1.7065011953935927
Validation loss: 2.580827160054864

Epoch: 5| Step: 1
Training loss: 1.6017807230330174
Validation loss: 2.603780970939397

Epoch: 5| Step: 2
Training loss: 2.083223899510257
Validation loss: 2.6025254469295285

Epoch: 5| Step: 3
Training loss: 2.5088810530770025
Validation loss: 2.625750230119614

Epoch: 5| Step: 4
Training loss: 1.774411845481382
Validation loss: 2.59550301168178

Epoch: 5| Step: 5
Training loss: 1.782767001214204
Validation loss: 2.59637589415269

Epoch: 5| Step: 6
Training loss: 1.5181365292937021
Validation loss: 2.5769782685336966

Epoch: 5| Step: 7
Training loss: 1.839091347571048
Validation loss: 2.616473583571148

Epoch: 5| Step: 8
Training loss: 1.8310318357949045
Validation loss: 2.6243495248755933

Epoch: 5| Step: 9
Training loss: 2.223444525680111
Validation loss: 2.6266255681478383

Epoch: 5| Step: 10
Training loss: 1.7388945794071664
Validation loss: 2.608231398588372

Epoch: 5| Step: 11
Training loss: 2.3319412801949673
Validation loss: 2.620496254446935

Epoch: 167| Step: 0
Training loss: 1.5414421158575196
Validation loss: 2.6579452938968684

Epoch: 5| Step: 1
Training loss: 1.4054837152385151
Validation loss: 2.6799873095361386

Epoch: 5| Step: 2
Training loss: 1.9571332162573856
Validation loss: 2.7656181680196226

Epoch: 5| Step: 3
Training loss: 2.607972641971064
Validation loss: 2.741897437249702

Epoch: 5| Step: 4
Training loss: 1.609737614640436
Validation loss: 2.6813457926138318

Epoch: 5| Step: 5
Training loss: 1.3261151533398607
Validation loss: 2.6731356422320096

Epoch: 5| Step: 6
Training loss: 2.7665015948890983
Validation loss: 2.6440713107773024

Epoch: 5| Step: 7
Training loss: 1.8770086972904467
Validation loss: 2.634551035534104

Epoch: 5| Step: 8
Training loss: 1.5295941488988047
Validation loss: 2.592477225740385

Epoch: 5| Step: 9
Training loss: 1.5590931180851886
Validation loss: 2.5964991236669985

Epoch: 5| Step: 10
Training loss: 2.243645277209356
Validation loss: 2.5839217820663505

Epoch: 5| Step: 11
Training loss: 1.5373439585579647
Validation loss: 2.614303385171446

Epoch: 168| Step: 0
Training loss: 1.787577450014691
Validation loss: 2.5771608071694687

Epoch: 5| Step: 1
Training loss: 1.1970559663141662
Validation loss: 2.5582421602369902

Epoch: 5| Step: 2
Training loss: 2.07355622308845
Validation loss: 2.598514030921465

Epoch: 5| Step: 3
Training loss: 2.4782933104651947
Validation loss: 2.6147131387371396

Epoch: 5| Step: 4
Training loss: 1.8410147081126378
Validation loss: 2.6021879626135083

Epoch: 5| Step: 5
Training loss: 1.974187819159718
Validation loss: 2.608343716276748

Epoch: 5| Step: 6
Training loss: 1.8400514003581756
Validation loss: 2.64345829664294

Epoch: 5| Step: 7
Training loss: 1.967610953085344
Validation loss: 2.6458539599017628

Epoch: 5| Step: 8
Training loss: 1.677031222021525
Validation loss: 2.620175871284888

Epoch: 5| Step: 9
Training loss: 1.7941772111700078
Validation loss: 2.628916173106601

Epoch: 5| Step: 10
Training loss: 1.907291190541276
Validation loss: 2.6271199869436974

Epoch: 5| Step: 11
Training loss: 1.9920119264314573
Validation loss: 2.6131136944573465

Epoch: 169| Step: 0
Training loss: 2.008975156213658
Validation loss: 2.60329959676165

Epoch: 5| Step: 1
Training loss: 2.105745711361067
Validation loss: 2.5813321308342623

Epoch: 5| Step: 2
Training loss: 1.8477090904632003
Validation loss: 2.632355949443177

Epoch: 5| Step: 3
Training loss: 1.973831280030689
Validation loss: 2.585940304358

Epoch: 5| Step: 4
Training loss: 2.5143041519473646
Validation loss: 2.635374677019504

Epoch: 5| Step: 5
Training loss: 1.5845385615627106
Validation loss: 2.6222517257436477

Epoch: 5| Step: 6
Training loss: 1.8503381729342152
Validation loss: 2.6390352373087063

Epoch: 5| Step: 7
Training loss: 2.000251039008648
Validation loss: 2.6384076471600384

Epoch: 5| Step: 8
Training loss: 1.457307681944807
Validation loss: 2.6086527135018702

Epoch: 5| Step: 9
Training loss: 1.7423354287060422
Validation loss: 2.6345818910097583

Epoch: 5| Step: 10
Training loss: 1.2632996661012224
Validation loss: 2.6250829570014305

Epoch: 5| Step: 11
Training loss: 1.1340405352040286
Validation loss: 2.6160878694433998

Epoch: 170| Step: 0
Training loss: 1.9337403521207717
Validation loss: 2.6175849233232675

Epoch: 5| Step: 1
Training loss: 2.577538255912676
Validation loss: 2.613237434783976

Epoch: 5| Step: 2
Training loss: 1.8341687712021082
Validation loss: 2.6279888394494746

Epoch: 5| Step: 3
Training loss: 1.5827502465314949
Validation loss: 2.594555915348472

Epoch: 5| Step: 4
Training loss: 1.803245133178016
Validation loss: 2.6322151359137806

Epoch: 5| Step: 5
Training loss: 1.7634549604244727
Validation loss: 2.5836347601501948

Epoch: 5| Step: 6
Training loss: 1.6940093767386275
Validation loss: 2.5956556719137285

Epoch: 5| Step: 7
Training loss: 1.489434863963261
Validation loss: 2.632332468465111

Epoch: 5| Step: 8
Training loss: 2.072029179378643
Validation loss: 2.5938792062466427

Epoch: 5| Step: 9
Training loss: 1.9002892524992248
Validation loss: 2.6529287405704394

Epoch: 5| Step: 10
Training loss: 1.5506514103342053
Validation loss: 2.6151767617057686

Epoch: 5| Step: 11
Training loss: 1.5639287900982086
Validation loss: 2.6558876501030384

Epoch: 171| Step: 0
Training loss: 2.2946577723698502
Validation loss: 2.642440859999889

Epoch: 5| Step: 1
Training loss: 1.7735618514102032
Validation loss: 2.6559520479530883

Epoch: 5| Step: 2
Training loss: 1.3152804215666587
Validation loss: 2.6473626475355867

Epoch: 5| Step: 3
Training loss: 1.6657013322756054
Validation loss: 2.61986947686669

Epoch: 5| Step: 4
Training loss: 1.989451126046696
Validation loss: 2.640220129512022

Epoch: 5| Step: 5
Training loss: 2.1052647989040807
Validation loss: 2.625502345292412

Epoch: 5| Step: 6
Training loss: 1.9646060868122448
Validation loss: 2.6368709981785043

Epoch: 5| Step: 7
Training loss: 1.2387015414647748
Validation loss: 2.62508120297673

Epoch: 5| Step: 8
Training loss: 1.6620117589165047
Validation loss: 2.578099083047704

Epoch: 5| Step: 9
Training loss: 1.8161099099873936
Validation loss: 2.5625573671323854

Epoch: 5| Step: 10
Training loss: 2.305197242357338
Validation loss: 2.6182444056309073

Epoch: 5| Step: 11
Training loss: 2.219733651481751
Validation loss: 2.610794747127631

Epoch: 172| Step: 0
Training loss: 1.7316086160122477
Validation loss: 2.6005027720453633

Epoch: 5| Step: 1
Training loss: 1.7522427628866102
Validation loss: 2.559952314548624

Epoch: 5| Step: 2
Training loss: 1.0922659478781553
Validation loss: 2.5950321605713222

Epoch: 5| Step: 3
Training loss: 1.7518391481746463
Validation loss: 2.578208216855795

Epoch: 5| Step: 4
Training loss: 2.0746079131896797
Validation loss: 2.5680056987193662

Epoch: 5| Step: 5
Training loss: 2.4701053423947035
Validation loss: 2.605090234381023

Epoch: 5| Step: 6
Training loss: 1.988955400314984
Validation loss: 2.6118057487528517

Epoch: 5| Step: 7
Training loss: 1.7997793857164148
Validation loss: 2.6383139675567864

Epoch: 5| Step: 8
Training loss: 1.6934655320134733
Validation loss: 2.645843281814815

Epoch: 5| Step: 9
Training loss: 1.8209327001395466
Validation loss: 2.6170984737001004

Epoch: 5| Step: 10
Training loss: 1.423650115597876
Validation loss: 2.679443904381351

Epoch: 5| Step: 11
Training loss: 2.9333856866961874
Validation loss: 2.626424232760401

Epoch: 173| Step: 0
Training loss: 1.755096779135578
Validation loss: 2.703639931409921

Epoch: 5| Step: 1
Training loss: 1.5747133145465728
Validation loss: 2.6750297363506084

Epoch: 5| Step: 2
Training loss: 1.8779940542059916
Validation loss: 2.6194741503488648

Epoch: 5| Step: 3
Training loss: 1.8021618893944955
Validation loss: 2.6186580796599497

Epoch: 5| Step: 4
Training loss: 2.116828015202762
Validation loss: 2.59525200813313

Epoch: 5| Step: 5
Training loss: 1.3513031639064905
Validation loss: 2.600103585918512

Epoch: 5| Step: 6
Training loss: 1.8079112930141796
Validation loss: 2.576420758236775

Epoch: 5| Step: 7
Training loss: 2.072466841410578
Validation loss: 2.629654001924337

Epoch: 5| Step: 8
Training loss: 2.3597461332751624
Validation loss: 2.625962262666183

Epoch: 5| Step: 9
Training loss: 2.0713995616741845
Validation loss: 2.6106261872287417

Epoch: 5| Step: 10
Training loss: 1.28367951954605
Validation loss: 2.601014401241132

Epoch: 5| Step: 11
Training loss: 2.39688547224122
Validation loss: 2.649362087618748

Epoch: 174| Step: 0
Training loss: 2.057238601450877
Validation loss: 2.6083679159347963

Epoch: 5| Step: 1
Training loss: 1.9710641006737564
Validation loss: 2.669553672257993

Epoch: 5| Step: 2
Training loss: 1.4299537119009555
Validation loss: 2.582427928807638

Epoch: 5| Step: 3
Training loss: 2.0007987811457397
Validation loss: 2.64206810742956

Epoch: 5| Step: 4
Training loss: 1.998048008594956
Validation loss: 2.688697688529193

Epoch: 5| Step: 5
Training loss: 1.5090952738419885
Validation loss: 2.636381712671421

Epoch: 5| Step: 6
Training loss: 2.2335645366197965
Validation loss: 2.6701018378127883

Epoch: 5| Step: 7
Training loss: 1.5724538749637618
Validation loss: 2.6464296192168097

Epoch: 5| Step: 8
Training loss: 1.886443945417157
Validation loss: 2.6079375101262063

Epoch: 5| Step: 9
Training loss: 1.1955918627632103
Validation loss: 2.616940660365859

Epoch: 5| Step: 10
Training loss: 1.913319657650144
Validation loss: 2.6540274690350643

Epoch: 5| Step: 11
Training loss: 1.1827875293429044
Validation loss: 2.6040950587282103

Epoch: 175| Step: 0
Training loss: 2.7177092215284477
Validation loss: 2.626758970060445

Epoch: 5| Step: 1
Training loss: 1.5643496437471534
Validation loss: 2.6157852743578247

Epoch: 5| Step: 2
Training loss: 1.5417046499298614
Validation loss: 2.609383322270384

Epoch: 5| Step: 3
Training loss: 2.270359223128507
Validation loss: 2.614869392116567

Epoch: 5| Step: 4
Training loss: 1.3031824533801053
Validation loss: 2.578929640694602

Epoch: 5| Step: 5
Training loss: 1.695334438762137
Validation loss: 2.5963955834138965

Epoch: 5| Step: 6
Training loss: 1.3957587217440721
Validation loss: 2.5884609107475915

Epoch: 5| Step: 7
Training loss: 1.6146185922361898
Validation loss: 2.579262091597438

Epoch: 5| Step: 8
Training loss: 1.7131038520005895
Validation loss: 2.6598678708902015

Epoch: 5| Step: 9
Training loss: 1.7999956978640537
Validation loss: 2.6186079014028656

Epoch: 5| Step: 10
Training loss: 1.627567537022716
Validation loss: 2.6796149678696826

Epoch: 5| Step: 11
Training loss: 2.343779296691897
Validation loss: 2.6338733116954223

Epoch: 176| Step: 0
Training loss: 1.9946088848253114
Validation loss: 2.6839251880414734

Epoch: 5| Step: 1
Training loss: 1.558175320017416
Validation loss: 2.691368802220264

Epoch: 5| Step: 2
Training loss: 1.4843659250082377
Validation loss: 2.712456408676316

Epoch: 5| Step: 3
Training loss: 1.625743549135266
Validation loss: 2.6800401713197877

Epoch: 5| Step: 4
Training loss: 1.7291160101153935
Validation loss: 2.660069289165475

Epoch: 5| Step: 5
Training loss: 1.9673027289640825
Validation loss: 2.702868561533949

Epoch: 5| Step: 6
Training loss: 2.125520305887419
Validation loss: 2.6486074154941446

Epoch: 5| Step: 7
Training loss: 2.3937192352150607
Validation loss: 2.5906705730373276

Epoch: 5| Step: 8
Training loss: 2.0252598395650683
Validation loss: 2.5982577361323846

Epoch: 5| Step: 9
Training loss: 1.2522542653802238
Validation loss: 2.6064339469927713

Epoch: 5| Step: 10
Training loss: 1.9019318120909665
Validation loss: 2.639772601117607

Epoch: 5| Step: 11
Training loss: 1.7733169044125592
Validation loss: 2.5767109701864093

Epoch: 177| Step: 0
Training loss: 1.8652908076991608
Validation loss: 2.5879689292337242

Epoch: 5| Step: 1
Training loss: 2.070226588356026
Validation loss: 2.6162496566043196

Epoch: 5| Step: 2
Training loss: 2.0673509828678696
Validation loss: 2.5744600158839352

Epoch: 5| Step: 3
Training loss: 2.1306352506230413
Validation loss: 2.604402406830716

Epoch: 5| Step: 4
Training loss: 1.6798710922330873
Validation loss: 2.590963019179142

Epoch: 5| Step: 5
Training loss: 1.846477624579434
Validation loss: 2.6311403882957656

Epoch: 5| Step: 6
Training loss: 1.3998506960274435
Validation loss: 2.647859756034226

Epoch: 5| Step: 7
Training loss: 1.4718525360401769
Validation loss: 2.632337848125882

Epoch: 5| Step: 8
Training loss: 1.4580393721990392
Validation loss: 2.6125944077926864

Epoch: 5| Step: 9
Training loss: 1.086111699684376
Validation loss: 2.658094599645873

Epoch: 5| Step: 10
Training loss: 2.5199205201345953
Validation loss: 2.668366584513072

Epoch: 5| Step: 11
Training loss: 1.7294874315072593
Validation loss: 2.6854500493020903

Epoch: 178| Step: 0
Training loss: 1.9989530684213115
Validation loss: 2.669057982107118

Epoch: 5| Step: 1
Training loss: 1.742844393614296
Validation loss: 2.685413903845842

Epoch: 5| Step: 2
Training loss: 1.8084024612410008
Validation loss: 2.711977789311761

Epoch: 5| Step: 3
Training loss: 2.092379448812404
Validation loss: 2.708358244903631

Epoch: 5| Step: 4
Training loss: 1.6703507079133884
Validation loss: 2.7440467646465185

Epoch: 5| Step: 5
Training loss: 1.9755044751571602
Validation loss: 2.6922649717041867

Epoch: 5| Step: 6
Training loss: 1.8549906867685473
Validation loss: 2.6486498242154872

Epoch: 5| Step: 7
Training loss: 2.011271780783984
Validation loss: 2.676539949766389

Epoch: 5| Step: 8
Training loss: 2.0953668073860285
Validation loss: 2.5838265384016403

Epoch: 5| Step: 9
Training loss: 1.479331190961811
Validation loss: 2.5849212578107243

Epoch: 5| Step: 10
Training loss: 1.2595688777139933
Validation loss: 2.614969591027153

Epoch: 5| Step: 11
Training loss: 0.8061383694986197
Validation loss: 2.588093342068887

Epoch: 179| Step: 0
Training loss: 1.9719975041998492
Validation loss: 2.6364969683021493

Epoch: 5| Step: 1
Training loss: 1.8449413523876579
Validation loss: 2.619111943022697

Epoch: 5| Step: 2
Training loss: 1.73662565447705
Validation loss: 2.60329533813809

Epoch: 5| Step: 3
Training loss: 1.3862752285752158
Validation loss: 2.5934623535781927

Epoch: 5| Step: 4
Training loss: 1.3826533080457801
Validation loss: 2.6188636422820704

Epoch: 5| Step: 5
Training loss: 2.1566675859868933
Validation loss: 2.637771038544091

Epoch: 5| Step: 6
Training loss: 1.9689189293456684
Validation loss: 2.651695104732628

Epoch: 5| Step: 7
Training loss: 1.0916521935316468
Validation loss: 2.699791280308464

Epoch: 5| Step: 8
Training loss: 1.983102826205797
Validation loss: 2.67877403757

Epoch: 5| Step: 9
Training loss: 1.5548854682668722
Validation loss: 2.6926365934416068

Epoch: 5| Step: 10
Training loss: 2.6140958374597356
Validation loss: 2.668452202785878

Epoch: 5| Step: 11
Training loss: 1.236395088298721
Validation loss: 2.667245319039957

Epoch: 180| Step: 0
Training loss: 1.5882218169178657
Validation loss: 2.6274780807766507

Epoch: 5| Step: 1
Training loss: 1.4708766556250126
Validation loss: 2.6128803947401678

Epoch: 5| Step: 2
Training loss: 2.3448315985753627
Validation loss: 2.6014099190905084

Epoch: 5| Step: 3
Training loss: 1.749932219691321
Validation loss: 2.610537930376749

Epoch: 5| Step: 4
Training loss: 1.8611282929849888
Validation loss: 2.6223656704079343

Epoch: 5| Step: 5
Training loss: 2.0558812839877985
Validation loss: 2.6527235220863727

Epoch: 5| Step: 6
Training loss: 0.9801369519783875
Validation loss: 2.6467803601876896

Epoch: 5| Step: 7
Training loss: 1.5773178907129144
Validation loss: 2.6074479043449523

Epoch: 5| Step: 8
Training loss: 2.125668813135576
Validation loss: 2.6334925904182724

Epoch: 5| Step: 9
Training loss: 1.838841904574265
Validation loss: 2.6302013560791133

Epoch: 5| Step: 10
Training loss: 1.7109280241960771
Validation loss: 2.6597102907531243

Epoch: 5| Step: 11
Training loss: 2.0996717150992303
Validation loss: 2.6216234069010835

Epoch: 181| Step: 0
Training loss: 1.4305034039485875
Validation loss: 2.620693598834324

Epoch: 5| Step: 1
Training loss: 1.7430829539516155
Validation loss: 2.5740281161321654

Epoch: 5| Step: 2
Training loss: 1.3617412536827642
Validation loss: 2.593180770151711

Epoch: 5| Step: 3
Training loss: 1.7018518851591566
Validation loss: 2.560025505178525

Epoch: 5| Step: 4
Training loss: 1.8785693209551872
Validation loss: 2.6128793358897533

Epoch: 5| Step: 5
Training loss: 1.7124480803478286
Validation loss: 2.6022505055693155

Epoch: 5| Step: 6
Training loss: 2.05401971793066
Validation loss: 2.6183594807772717

Epoch: 5| Step: 7
Training loss: 1.5467983958995344
Validation loss: 2.5881414558202547

Epoch: 5| Step: 8
Training loss: 2.6564074301348217
Validation loss: 2.6348221501573494

Epoch: 5| Step: 9
Training loss: 1.6906648557128794
Validation loss: 2.6359324321234556

Epoch: 5| Step: 10
Training loss: 1.575560497278577
Validation loss: 2.6628269003828025

Epoch: 5| Step: 11
Training loss: 0.2714225094788745
Validation loss: 2.6406256545929407

Epoch: 182| Step: 0
Training loss: 1.3385052904858805
Validation loss: 2.627662980650464

Epoch: 5| Step: 1
Training loss: 1.5811487821367227
Validation loss: 2.611626333415376

Epoch: 5| Step: 2
Training loss: 1.6823150664632118
Validation loss: 2.6687867086895056

Epoch: 5| Step: 3
Training loss: 1.6665310168694696
Validation loss: 2.6586716141210713

Epoch: 5| Step: 4
Training loss: 1.9560576737410118
Validation loss: 2.6123819804417834

Epoch: 5| Step: 5
Training loss: 2.21379750886295
Validation loss: 2.671930122922282

Epoch: 5| Step: 6
Training loss: 1.473771783281101
Validation loss: 2.611726987663908

Epoch: 5| Step: 7
Training loss: 1.8408523030625443
Validation loss: 2.6231896841372104

Epoch: 5| Step: 8
Training loss: 1.5133444548854997
Validation loss: 2.6030511348726946

Epoch: 5| Step: 9
Training loss: 1.835473769039723
Validation loss: 2.6197293667877926

Epoch: 5| Step: 10
Training loss: 2.2808831324894108
Validation loss: 2.6611872097603446

Epoch: 5| Step: 11
Training loss: 2.065204350148802
Validation loss: 2.5933345247435917

Epoch: 183| Step: 0
Training loss: 1.596206641627734
Validation loss: 2.626892546719865

Epoch: 5| Step: 1
Training loss: 1.647096929490034
Validation loss: 2.664995706833894

Epoch: 5| Step: 2
Training loss: 1.671601602892485
Validation loss: 2.7287888714358486

Epoch: 5| Step: 3
Training loss: 1.597885749580795
Validation loss: 2.6861953192935775

Epoch: 5| Step: 4
Training loss: 1.5181067686215117
Validation loss: 2.6586808357694194

Epoch: 5| Step: 5
Training loss: 1.9716618514895659
Validation loss: 2.6926912968808034

Epoch: 5| Step: 6
Training loss: 1.9890891122049092
Validation loss: 2.655510088771004

Epoch: 5| Step: 7
Training loss: 1.6383267244895805
Validation loss: 2.633244842136969

Epoch: 5| Step: 8
Training loss: 2.1320730191979576
Validation loss: 2.6440189190231935

Epoch: 5| Step: 9
Training loss: 1.922331778975753
Validation loss: 2.6709349058498755

Epoch: 5| Step: 10
Training loss: 1.7572877906103828
Validation loss: 2.629445550176264

Epoch: 5| Step: 11
Training loss: 2.334816347860119
Validation loss: 2.630451917542532

Epoch: 184| Step: 0
Training loss: 1.3261413121248131
Validation loss: 2.5820062821758984

Epoch: 5| Step: 1
Training loss: 2.587909050641952
Validation loss: 2.6394361306392793

Epoch: 5| Step: 2
Training loss: 1.4715811855306897
Validation loss: 2.6249472484132244

Epoch: 5| Step: 3
Training loss: 1.7550497766375008
Validation loss: 2.5916876847763106

Epoch: 5| Step: 4
Training loss: 1.9584568945139098
Validation loss: 2.586784262573086

Epoch: 5| Step: 5
Training loss: 1.2923517051344011
Validation loss: 2.6481892592258083

Epoch: 5| Step: 6
Training loss: 1.7110999043346755
Validation loss: 2.708386638312413

Epoch: 5| Step: 7
Training loss: 1.401687596074509
Validation loss: 2.6245067337343646

Epoch: 5| Step: 8
Training loss: 1.4981542993894363
Validation loss: 2.638134581412821

Epoch: 5| Step: 9
Training loss: 1.860438964072212
Validation loss: 2.6612229040918693

Epoch: 5| Step: 10
Training loss: 1.7596283074762697
Validation loss: 2.6248702062580023

Epoch: 5| Step: 11
Training loss: 1.5844608441634056
Validation loss: 2.6565754242311055

Epoch: 185| Step: 0
Training loss: 2.0632046738395986
Validation loss: 2.7107454244707605

Epoch: 5| Step: 1
Training loss: 1.429517975642467
Validation loss: 2.71212345020558

Epoch: 5| Step: 2
Training loss: 1.9352555349211935
Validation loss: 2.7411296285654876

Epoch: 5| Step: 3
Training loss: 1.8170505488475714
Validation loss: 2.8045796415226945

Epoch: 5| Step: 4
Training loss: 2.0585817050762425
Validation loss: 2.745779121647161

Epoch: 5| Step: 5
Training loss: 1.6624574039136373
Validation loss: 2.687494961785614

Epoch: 5| Step: 6
Training loss: 2.179969140455576
Validation loss: 2.6808634551240167

Epoch: 5| Step: 7
Training loss: 1.6424628000677286
Validation loss: 2.659273762088994

Epoch: 5| Step: 8
Training loss: 1.3112039070282984
Validation loss: 2.626413570238546

Epoch: 5| Step: 9
Training loss: 1.6311819888147199
Validation loss: 2.6282267341775376

Epoch: 5| Step: 10
Training loss: 1.9118508153397735
Validation loss: 2.6176802327937048

Epoch: 5| Step: 11
Training loss: 1.0711058300847953
Validation loss: 2.5780732120745538

Epoch: 186| Step: 0
Training loss: 1.6183723126924854
Validation loss: 2.6028341635369925

Epoch: 5| Step: 1
Training loss: 1.7027633703029206
Validation loss: 2.5824011510301057

Epoch: 5| Step: 2
Training loss: 1.7877281576877941
Validation loss: 2.6155561705465638

Epoch: 5| Step: 3
Training loss: 1.6835717998587232
Validation loss: 2.572528637392076

Epoch: 5| Step: 4
Training loss: 1.7408281163267878
Validation loss: 2.6398802991905064

Epoch: 5| Step: 5
Training loss: 1.5970393624420185
Validation loss: 2.6659406807488155

Epoch: 5| Step: 6
Training loss: 1.213067967815027
Validation loss: 2.628137666034454

Epoch: 5| Step: 7
Training loss: 1.0939355965230357
Validation loss: 2.631012018878278

Epoch: 5| Step: 8
Training loss: 0.8612176041399775
Validation loss: 2.6911715888273693

Epoch: 5| Step: 9
Training loss: 2.5824574452057925
Validation loss: 2.737057933647903

Epoch: 5| Step: 10
Training loss: 2.3351427850625406
Validation loss: 2.709823980679608

Epoch: 5| Step: 11
Training loss: 2.3984433649345536
Validation loss: 2.738083538875504

Epoch: 187| Step: 0
Training loss: 1.703230828313239
Validation loss: 2.6364880797658494

Epoch: 5| Step: 1
Training loss: 1.8048211911046346
Validation loss: 2.6095809017728193

Epoch: 5| Step: 2
Training loss: 1.6713957768205103
Validation loss: 2.5847821242864844

Epoch: 5| Step: 3
Training loss: 1.6442294534771487
Validation loss: 2.5863223601012306

Epoch: 5| Step: 4
Training loss: 1.2538548634299977
Validation loss: 2.6341433269738306

Epoch: 5| Step: 5
Training loss: 1.9104051798312573
Validation loss: 2.586315407851599

Epoch: 5| Step: 6
Training loss: 1.7196259087345744
Validation loss: 2.6624294694026758

Epoch: 5| Step: 7
Training loss: 2.2459139279240126
Validation loss: 2.646794671405167

Epoch: 5| Step: 8
Training loss: 1.6529348051272987
Validation loss: 2.591598708226689

Epoch: 5| Step: 9
Training loss: 1.499370363330867
Validation loss: 2.5585317046041385

Epoch: 5| Step: 10
Training loss: 2.0442998863796036
Validation loss: 2.6264248455042223

Epoch: 5| Step: 11
Training loss: 1.8875162086043502
Validation loss: 2.680265581152408

Epoch: 188| Step: 0
Training loss: 1.5991166954853637
Validation loss: 2.673636723818168

Epoch: 5| Step: 1
Training loss: 2.1501976986855458
Validation loss: 2.6420289282097005

Epoch: 5| Step: 2
Training loss: 1.7323813449802052
Validation loss: 2.6961364223920885

Epoch: 5| Step: 3
Training loss: 2.149050649366478
Validation loss: 2.702023743055948

Epoch: 5| Step: 4
Training loss: 1.500421941540122
Validation loss: 2.7313461022015306

Epoch: 5| Step: 5
Training loss: 1.1457214416433998
Validation loss: 2.673853719666361

Epoch: 5| Step: 6
Training loss: 2.1455760418856453
Validation loss: 2.6231971976011046

Epoch: 5| Step: 7
Training loss: 1.3996657193825637
Validation loss: 2.6437627670304473

Epoch: 5| Step: 8
Training loss: 1.8008668428216288
Validation loss: 2.6473513451189805

Epoch: 5| Step: 9
Training loss: 1.4967658622312785
Validation loss: 2.572718610103329

Epoch: 5| Step: 10
Training loss: 1.391411119781317
Validation loss: 2.5825713146391607

Epoch: 5| Step: 11
Training loss: 1.9942663976926003
Validation loss: 2.623100638104902

Epoch: 189| Step: 0
Training loss: 1.4765368262586938
Validation loss: 2.6553594704603527

Epoch: 5| Step: 1
Training loss: 1.9564249466251813
Validation loss: 2.6457179988043293

Epoch: 5| Step: 2
Training loss: 2.3666864752500167
Validation loss: 2.642298623261115

Epoch: 5| Step: 3
Training loss: 1.7176335263161049
Validation loss: 2.6716837414854075

Epoch: 5| Step: 4
Training loss: 1.6989623830042635
Validation loss: 2.6758981832306437

Epoch: 5| Step: 5
Training loss: 1.9946160567020321
Validation loss: 2.7009580743175166

Epoch: 5| Step: 6
Training loss: 1.764825825728962
Validation loss: 2.692747458291146

Epoch: 5| Step: 7
Training loss: 1.319121867897395
Validation loss: 2.6713619948047027

Epoch: 5| Step: 8
Training loss: 1.2143150233890885
Validation loss: 2.603995356965064

Epoch: 5| Step: 9
Training loss: 1.2593435600653768
Validation loss: 2.6484311984276987

Epoch: 5| Step: 10
Training loss: 1.8157521372418415
Validation loss: 2.6228324933189393

Epoch: 5| Step: 11
Training loss: 0.7918952101707959
Validation loss: 2.6693739534633676

Epoch: 190| Step: 0
Training loss: 1.3251703944495445
Validation loss: 2.6266290174023372

Epoch: 5| Step: 1
Training loss: 1.428487305207903
Validation loss: 2.6571205189967055

Epoch: 5| Step: 2
Training loss: 1.654041977738317
Validation loss: 2.6367723737373674

Epoch: 5| Step: 3
Training loss: 1.6282418265867504
Validation loss: 2.6346876633866176

Epoch: 5| Step: 4
Training loss: 1.4333146574592746
Validation loss: 2.648758811551977

Epoch: 5| Step: 5
Training loss: 1.6312351913072287
Validation loss: 2.6503782935009084

Epoch: 5| Step: 6
Training loss: 1.5148248821812826
Validation loss: 2.632124934610227

Epoch: 5| Step: 7
Training loss: 1.9720284548867277
Validation loss: 2.6617529694171678

Epoch: 5| Step: 8
Training loss: 1.6212700070078299
Validation loss: 2.5895672051645384

Epoch: 5| Step: 9
Training loss: 1.7473055668885136
Validation loss: 2.65324965799324

Epoch: 5| Step: 10
Training loss: 2.491099918513128
Validation loss: 2.703057981038813

Epoch: 5| Step: 11
Training loss: 0.6635252630660476
Validation loss: 2.674587148525094

Epoch: 191| Step: 0
Training loss: 1.5009300209826448
Validation loss: 2.600237018987417

Epoch: 5| Step: 1
Training loss: 1.7266697914998612
Validation loss: 2.6052140183344186

Epoch: 5| Step: 2
Training loss: 1.3251078723685425
Validation loss: 2.6457763175127638

Epoch: 5| Step: 3
Training loss: 1.5467725006977577
Validation loss: 2.59595144828728

Epoch: 5| Step: 4
Training loss: 1.8504343579700762
Validation loss: 2.6143564123237217

Epoch: 5| Step: 5
Training loss: 2.1419939550533535
Validation loss: 2.6001380938756906

Epoch: 5| Step: 6
Training loss: 1.5308960486066336
Validation loss: 2.6863146577961334

Epoch: 5| Step: 7
Training loss: 1.270311743629296
Validation loss: 2.6392466805878545

Epoch: 5| Step: 8
Training loss: 1.6963603916664987
Validation loss: 2.6742775063166535

Epoch: 5| Step: 9
Training loss: 1.373088201169509
Validation loss: 2.7216796254501454

Epoch: 5| Step: 10
Training loss: 2.123753462547816
Validation loss: 2.638089985269047

Epoch: 5| Step: 11
Training loss: 1.740259446499743
Validation loss: 2.6311896894887083

Epoch: 192| Step: 0
Training loss: 1.624855328502206
Validation loss: 2.6820319608618335

Epoch: 5| Step: 1
Training loss: 1.844178036934675
Validation loss: 2.6849241665301933

Epoch: 5| Step: 2
Training loss: 1.34520314621729
Validation loss: 2.703828598798828

Epoch: 5| Step: 3
Training loss: 1.1550099192436967
Validation loss: 2.668618167387496

Epoch: 5| Step: 4
Training loss: 1.513096775199787
Validation loss: 2.673174127700046

Epoch: 5| Step: 5
Training loss: 1.4382237809866574
Validation loss: 2.6479217642298107

Epoch: 5| Step: 6
Training loss: 2.132244551497923
Validation loss: 2.685101151902291

Epoch: 5| Step: 7
Training loss: 2.388855123158053
Validation loss: 2.6120910367022008

Epoch: 5| Step: 8
Training loss: 1.6573968911069186
Validation loss: 2.6389904079373756

Epoch: 5| Step: 9
Training loss: 1.5675691392851574
Validation loss: 2.621385322192128

Epoch: 5| Step: 10
Training loss: 1.4539386563222902
Validation loss: 2.632081885986349

Epoch: 5| Step: 11
Training loss: 1.8348414619208688
Validation loss: 2.661344101476799

Epoch: 193| Step: 0
Training loss: 0.9826806032981671
Validation loss: 2.696749214901923

Epoch: 5| Step: 1
Training loss: 1.3003794189777003
Validation loss: 2.7160272081657473

Epoch: 5| Step: 2
Training loss: 1.870472018291845
Validation loss: 2.644226759149494

Epoch: 5| Step: 3
Training loss: 1.947572001055428
Validation loss: 2.6813636927593967

Epoch: 5| Step: 4
Training loss: 1.8270425444703824
Validation loss: 2.6419995377734145

Epoch: 5| Step: 5
Training loss: 2.3695643612906117
Validation loss: 2.6349213565681846

Epoch: 5| Step: 6
Training loss: 1.5529546233583527
Validation loss: 2.640379501156657

Epoch: 5| Step: 7
Training loss: 1.5907877151212504
Validation loss: 2.6151381748654625

Epoch: 5| Step: 8
Training loss: 1.4001706428073302
Validation loss: 2.6504412247754865

Epoch: 5| Step: 9
Training loss: 1.3641719586303327
Validation loss: 2.6293650317035238

Epoch: 5| Step: 10
Training loss: 1.7841327830195455
Validation loss: 2.6870263480707233

Epoch: 5| Step: 11
Training loss: 2.507720850520596
Validation loss: 2.6372375279338174

Epoch: 194| Step: 0
Training loss: 1.5160444013640724
Validation loss: 2.6670295845872958

Epoch: 5| Step: 1
Training loss: 1.7677464526203845
Validation loss: 2.6527133023136518

Epoch: 5| Step: 2
Training loss: 1.469807183471932
Validation loss: 2.595764561278422

Epoch: 5| Step: 3
Training loss: 2.192046427248996
Validation loss: 2.666939376257891

Epoch: 5| Step: 4
Training loss: 1.4147969230262487
Validation loss: 2.6584473814660505

Epoch: 5| Step: 5
Training loss: 1.8054065675480158
Validation loss: 2.6232919282646834

Epoch: 5| Step: 6
Training loss: 1.561914944788617
Validation loss: 2.6220903543834644

Epoch: 5| Step: 7
Training loss: 2.005260582445464
Validation loss: 2.7105205446100467

Epoch: 5| Step: 8
Training loss: 1.7489325128602862
Validation loss: 2.703045978015853

Epoch: 5| Step: 9
Training loss: 1.440618284131199
Validation loss: 2.6837125749115085

Epoch: 5| Step: 10
Training loss: 1.1060673471299223
Validation loss: 2.634493079203364

Epoch: 5| Step: 11
Training loss: 1.7891557827414002
Validation loss: 2.648119326883949

Epoch: 195| Step: 0
Training loss: 1.3222051744715542
Validation loss: 2.6620546271407965

Epoch: 5| Step: 1
Training loss: 1.8116040481769784
Validation loss: 2.6452013816711104

Epoch: 5| Step: 2
Training loss: 1.6189125922006762
Validation loss: 2.7038884196574835

Epoch: 5| Step: 3
Training loss: 2.0064680890060793
Validation loss: 2.6631252545638113

Epoch: 5| Step: 4
Training loss: 2.11489575212548
Validation loss: 2.665243170575221

Epoch: 5| Step: 5
Training loss: 2.088657505948388
Validation loss: 2.6303876809389757

Epoch: 5| Step: 6
Training loss: 1.3523530357037636
Validation loss: 2.6962841991365503

Epoch: 5| Step: 7
Training loss: 1.221007628036653
Validation loss: 2.6128913729216015

Epoch: 5| Step: 8
Training loss: 1.7139506523479846
Validation loss: 2.715830795924439

Epoch: 5| Step: 9
Training loss: 0.8894268475966121
Validation loss: 2.6655108708780313

Epoch: 5| Step: 10
Training loss: 1.6041923702542225
Validation loss: 2.6332491617291063

Epoch: 5| Step: 11
Training loss: 1.3054207665729805
Validation loss: 2.646872606692983

Epoch: 196| Step: 0
Training loss: 1.8917981125904157
Validation loss: 2.581973696099458

Epoch: 5| Step: 1
Training loss: 1.659678958273965
Validation loss: 2.6565361616786003

Epoch: 5| Step: 2
Training loss: 1.7658341545521925
Validation loss: 2.5866586230974717

Epoch: 5| Step: 3
Training loss: 1.5697147882980407
Validation loss: 2.6294130249695398

Epoch: 5| Step: 4
Training loss: 1.4850017629799188
Validation loss: 2.6289368883211472

Epoch: 5| Step: 5
Training loss: 1.7540303549581182
Validation loss: 2.6742206821254504

Epoch: 5| Step: 6
Training loss: 1.2425301996778635
Validation loss: 2.6303221397832077

Epoch: 5| Step: 7
Training loss: 1.7868081094257626
Validation loss: 2.6388628194313206

Epoch: 5| Step: 8
Training loss: 1.5076030526435698
Validation loss: 2.643825021615721

Epoch: 5| Step: 9
Training loss: 1.1571686162806274
Validation loss: 2.658224942400191

Epoch: 5| Step: 10
Training loss: 2.05927486841937
Validation loss: 2.7088592581079816

Epoch: 5| Step: 11
Training loss: 0.9325720970877437
Validation loss: 2.6240736257724513

Epoch: 197| Step: 0
Training loss: 1.0788495490155292
Validation loss: 2.6427752451131292

Epoch: 5| Step: 1
Training loss: 1.1970209615365088
Validation loss: 2.6068087272417664

Epoch: 5| Step: 2
Training loss: 1.7473894129567416
Validation loss: 2.6608530589287582

Epoch: 5| Step: 3
Training loss: 1.9974481276555245
Validation loss: 2.6368679654320744

Epoch: 5| Step: 4
Training loss: 2.0372305054096436
Validation loss: 2.6360416324701603

Epoch: 5| Step: 5
Training loss: 1.7269032690086308
Validation loss: 2.6693226221534534

Epoch: 5| Step: 6
Training loss: 1.1925143732448291
Validation loss: 2.611970010870077

Epoch: 5| Step: 7
Training loss: 1.411280345134361
Validation loss: 2.6604277686472684

Epoch: 5| Step: 8
Training loss: 2.373125239832627
Validation loss: 2.615350794272325

Epoch: 5| Step: 9
Training loss: 1.420197471937866
Validation loss: 2.6372099317649953

Epoch: 5| Step: 10
Training loss: 1.5684621356823811
Validation loss: 2.619968292066299

Epoch: 5| Step: 11
Training loss: 1.5319592915646787
Validation loss: 2.6790920296610854

Epoch: 198| Step: 0
Training loss: 1.2634694616826134
Validation loss: 2.7490512338320507

Epoch: 5| Step: 1
Training loss: 2.1554675686740716
Validation loss: 2.617640794813032

Epoch: 5| Step: 2
Training loss: 1.1112103927814263
Validation loss: 2.6816708386398433

Epoch: 5| Step: 3
Training loss: 1.89787240114595
Validation loss: 2.6933964502458263

Epoch: 5| Step: 4
Training loss: 1.528478488719588
Validation loss: 2.732941642372204

Epoch: 5| Step: 5
Training loss: 1.6151983586900525
Validation loss: 2.705454463922858

Epoch: 5| Step: 6
Training loss: 1.2445920786865898
Validation loss: 2.6907491190863206

Epoch: 5| Step: 7
Training loss: 1.423958226919926
Validation loss: 2.6627310392940142

Epoch: 5| Step: 8
Training loss: 2.0727637408666864
Validation loss: 2.669769159957157

Epoch: 5| Step: 9
Training loss: 1.5783919306951442
Validation loss: 2.6184712615937875

Epoch: 5| Step: 10
Training loss: 2.143986200160125
Validation loss: 2.625302108152571

Epoch: 5| Step: 11
Training loss: 0.8597694878705887
Validation loss: 2.636573708395008

Epoch: 199| Step: 0
Training loss: 1.4643578295610762
Validation loss: 2.6550225769191775

Epoch: 5| Step: 1
Training loss: 1.98715645801998
Validation loss: 2.6341051669415254

Epoch: 5| Step: 2
Training loss: 1.4679140999423537
Validation loss: 2.6188310103074652

Epoch: 5| Step: 3
Training loss: 1.594649640649999
Validation loss: 2.6124409083325735

Epoch: 5| Step: 4
Training loss: 1.7285061076274
Validation loss: 2.640274099777401

Epoch: 5| Step: 5
Training loss: 1.74685679581494
Validation loss: 2.6765048234422095

Epoch: 5| Step: 6
Training loss: 1.5713254024649124
Validation loss: 2.660546885156097

Epoch: 5| Step: 7
Training loss: 1.334456576638855
Validation loss: 2.6952513885941483

Epoch: 5| Step: 8
Training loss: 2.28538389457729
Validation loss: 2.653061654900172

Epoch: 5| Step: 9
Training loss: 1.3561270486677477
Validation loss: 2.695263944179276

Epoch: 5| Step: 10
Training loss: 1.0843307903852957
Validation loss: 2.655884639071664

Epoch: 5| Step: 11
Training loss: 0.7985334155854591
Validation loss: 2.7078958426987345

Epoch: 200| Step: 0
Training loss: 1.1761322511442758
Validation loss: 2.700280352006985

Epoch: 5| Step: 1
Training loss: 1.566605324592634
Validation loss: 2.716587043006853

Epoch: 5| Step: 2
Training loss: 2.2082416827298825
Validation loss: 2.673138630115531

Epoch: 5| Step: 3
Training loss: 1.8464062194230237
Validation loss: 2.7163804094081865

Epoch: 5| Step: 4
Training loss: 1.4517502383072127
Validation loss: 2.6660261589466323

Epoch: 5| Step: 5
Training loss: 1.2878840753205365
Validation loss: 2.6251173674366806

Epoch: 5| Step: 6
Training loss: 1.4381136206516962
Validation loss: 2.630982865963691

Epoch: 5| Step: 7
Training loss: 2.240446577855651
Validation loss: 2.5719679629094063

Epoch: 5| Step: 8
Training loss: 1.7842666780158138
Validation loss: 2.5855265134232592

Epoch: 5| Step: 9
Training loss: 1.4882432827649748
Validation loss: 2.6087489147942575

Epoch: 5| Step: 10
Training loss: 1.5725186920268013
Validation loss: 2.6126354048590366

Epoch: 5| Step: 11
Training loss: 1.2511067735859553
Validation loss: 2.6550964767901633

Epoch: 201| Step: 0
Training loss: 1.6050452348983646
Validation loss: 2.6735559422029045

Epoch: 5| Step: 1
Training loss: 1.381712869616338
Validation loss: 2.7630581698949603

Epoch: 5| Step: 2
Training loss: 1.7556815561247785
Validation loss: 2.832772219834947

Epoch: 5| Step: 3
Training loss: 1.1825423906079295
Validation loss: 2.8417462636104722

Epoch: 5| Step: 4
Training loss: 1.24684383573283
Validation loss: 2.8653348486025267

Epoch: 5| Step: 5
Training loss: 1.7443452482238775
Validation loss: 2.8587191581758167

Epoch: 5| Step: 6
Training loss: 2.084956249079916
Validation loss: 2.809420865737889

Epoch: 5| Step: 7
Training loss: 1.1433122933419424
Validation loss: 2.6948312928764184

Epoch: 5| Step: 8
Training loss: 1.8005995917389594
Validation loss: 2.672212884221996

Epoch: 5| Step: 9
Training loss: 1.4053751025296128
Validation loss: 2.5925945711191387

Epoch: 5| Step: 10
Training loss: 2.218655221553467
Validation loss: 2.6593353005541664

Epoch: 5| Step: 11
Training loss: 1.0494301771115528
Validation loss: 2.6364852274398802

Epoch: 202| Step: 0
Training loss: 2.426967656294518
Validation loss: 2.5669749426768607

Epoch: 5| Step: 1
Training loss: 1.715371643703585
Validation loss: 2.589877312981188

Epoch: 5| Step: 2
Training loss: 1.5322464795152302
Validation loss: 2.6291877403160324

Epoch: 5| Step: 3
Training loss: 1.1674307920703424
Validation loss: 2.597870261953844

Epoch: 5| Step: 4
Training loss: 1.412564237366099
Validation loss: 2.5986603557776062

Epoch: 5| Step: 5
Training loss: 1.2182294271772458
Validation loss: 2.6339090593645165

Epoch: 5| Step: 6
Training loss: 1.8867145167080162
Validation loss: 2.6297133417459637

Epoch: 5| Step: 7
Training loss: 1.7729023533507426
Validation loss: 2.653462345916126

Epoch: 5| Step: 8
Training loss: 1.5145064483535526
Validation loss: 2.6357524504620167

Epoch: 5| Step: 9
Training loss: 1.4940163953410048
Validation loss: 2.6855617046524736

Epoch: 5| Step: 10
Training loss: 1.6173605711096029
Validation loss: 2.774887314934246

Epoch: 5| Step: 11
Training loss: 1.0707474541768571
Validation loss: 2.750049330529003

Epoch: 203| Step: 0
Training loss: 1.6687689476509087
Validation loss: 2.750190262281561

Epoch: 5| Step: 1
Training loss: 1.3272202046395292
Validation loss: 2.7382818522250845

Epoch: 5| Step: 2
Training loss: 1.3895557021444598
Validation loss: 2.7621039050499485

Epoch: 5| Step: 3
Training loss: 1.5656984780252474
Validation loss: 2.7085471631270566

Epoch: 5| Step: 4
Training loss: 1.554147597835989
Validation loss: 2.6948243809500845

Epoch: 5| Step: 5
Training loss: 1.7077871783195044
Validation loss: 2.6740300817687794

Epoch: 5| Step: 6
Training loss: 2.268732609958049
Validation loss: 2.6425924289012683

Epoch: 5| Step: 7
Training loss: 1.498780947279033
Validation loss: 2.669973726845774

Epoch: 5| Step: 8
Training loss: 0.9049782215048107
Validation loss: 2.7032256906972703

Epoch: 5| Step: 9
Training loss: 1.5925022551611918
Validation loss: 2.662511525106783

Epoch: 5| Step: 10
Training loss: 1.735480016656519
Validation loss: 2.614786076885594

Epoch: 5| Step: 11
Training loss: 1.3714272291880807
Validation loss: 2.654255013115889

Epoch: 204| Step: 0
Training loss: 1.7151641893893776
Validation loss: 2.6639652980250896

Epoch: 5| Step: 1
Training loss: 1.3516334118183997
Validation loss: 2.630090402408017

Epoch: 5| Step: 2
Training loss: 2.361903471541675
Validation loss: 2.6897177491013022

Epoch: 5| Step: 3
Training loss: 1.2704328885809446
Validation loss: 2.6576887834158893

Epoch: 5| Step: 4
Training loss: 1.7723225184845979
Validation loss: 2.695085466193924

Epoch: 5| Step: 5
Training loss: 1.4146246029990708
Validation loss: 2.715784640754058

Epoch: 5| Step: 6
Training loss: 1.4962401156628813
Validation loss: 2.7054907455380053

Epoch: 5| Step: 7
Training loss: 1.6457687397445788
Validation loss: 2.776485079671819

Epoch: 5| Step: 8
Training loss: 1.284673814749384
Validation loss: 2.7421764580050567

Epoch: 5| Step: 9
Training loss: 1.4179867409649818
Validation loss: 2.755834783475448

Epoch: 5| Step: 10
Training loss: 1.6178650841687974
Validation loss: 2.7403260277093633

Epoch: 5| Step: 11
Training loss: 0.6796892977285178
Validation loss: 2.7315870295323212

Epoch: 205| Step: 0
Training loss: 1.801032787306258
Validation loss: 2.713323007121889

Epoch: 5| Step: 1
Training loss: 1.6287979346106725
Validation loss: 2.646834904165478

Epoch: 5| Step: 2
Training loss: 1.6429461090806172
Validation loss: 2.6596848961380353

Epoch: 5| Step: 3
Training loss: 0.9962207787989461
Validation loss: 2.632510465055932

Epoch: 5| Step: 4
Training loss: 1.473015941132203
Validation loss: 2.6807144317805034

Epoch: 5| Step: 5
Training loss: 1.3156709966524667
Validation loss: 2.689201864059102

Epoch: 5| Step: 6
Training loss: 1.0466294641220726
Validation loss: 2.6330282724709564

Epoch: 5| Step: 7
Training loss: 2.340839969964656
Validation loss: 2.657311216307629

Epoch: 5| Step: 8
Training loss: 1.8052614298512675
Validation loss: 2.6388502232468363

Epoch: 5| Step: 9
Training loss: 1.6450417059391458
Validation loss: 2.6977431095419324

Epoch: 5| Step: 10
Training loss: 1.462475950907372
Validation loss: 2.69738780303622

Epoch: 5| Step: 11
Training loss: 2.163507052863879
Validation loss: 2.73970553387882

Epoch: 206| Step: 0
Training loss: 0.9436776708208117
Validation loss: 2.683353826097066

Epoch: 5| Step: 1
Training loss: 1.7621707040494008
Validation loss: 2.6753292806525595

Epoch: 5| Step: 2
Training loss: 1.6211155166083868
Validation loss: 2.6278454405474507

Epoch: 5| Step: 3
Training loss: 1.2980669817312873
Validation loss: 2.661470638378585

Epoch: 5| Step: 4
Training loss: 1.8859865019467963
Validation loss: 2.624400467754724

Epoch: 5| Step: 5
Training loss: 2.023223747834448
Validation loss: 2.6670632452422574

Epoch: 5| Step: 6
Training loss: 1.6887312741656721
Validation loss: 2.6557974149307744

Epoch: 5| Step: 7
Training loss: 1.661616932664493
Validation loss: 2.5943248601982005

Epoch: 5| Step: 8
Training loss: 1.671547117791865
Validation loss: 2.6402100720476738

Epoch: 5| Step: 9
Training loss: 0.9277269865042961
Validation loss: 2.6364107663221743

Epoch: 5| Step: 10
Training loss: 1.5083794195114062
Validation loss: 2.6982118869718055

Epoch: 5| Step: 11
Training loss: 1.6303253944300913
Validation loss: 2.6973415127445715

Epoch: 207| Step: 0
Training loss: 1.5684198769268882
Validation loss: 2.7691275854382633

Epoch: 5| Step: 1
Training loss: 1.8281526481950403
Validation loss: 2.74843373272182

Epoch: 5| Step: 2
Training loss: 1.5547261448950156
Validation loss: 2.7530093741411488

Epoch: 5| Step: 3
Training loss: 1.489009168536445
Validation loss: 2.744319565121262

Epoch: 5| Step: 4
Training loss: 1.073718977758686
Validation loss: 2.734046280493373

Epoch: 5| Step: 5
Training loss: 2.1949584240983944
Validation loss: 2.679455104793448

Epoch: 5| Step: 6
Training loss: 1.7391275810135356
Validation loss: 2.636081797583417

Epoch: 5| Step: 7
Training loss: 1.3327209834781084
Validation loss: 2.6575870869842193

Epoch: 5| Step: 8
Training loss: 1.849755608680204
Validation loss: 2.6404949152428654

Epoch: 5| Step: 9
Training loss: 1.0586345143932807
Validation loss: 2.6178847641442746

Epoch: 5| Step: 10
Training loss: 1.3185235719508541
Validation loss: 2.620120074706229

Epoch: 5| Step: 11
Training loss: 1.5195921270340753
Validation loss: 2.6286493282598475

Epoch: 208| Step: 0
Training loss: 1.4083060598648125
Validation loss: 2.6324095545009314

Epoch: 5| Step: 1
Training loss: 1.401418991992164
Validation loss: 2.6676333297102044

Epoch: 5| Step: 2
Training loss: 1.4752333375668252
Validation loss: 2.724197225264112

Epoch: 5| Step: 3
Training loss: 1.7239686979076378
Validation loss: 2.753900222230632

Epoch: 5| Step: 4
Training loss: 1.6202996572575956
Validation loss: 2.6893842287087733

Epoch: 5| Step: 5
Training loss: 1.6993551265316311
Validation loss: 2.722728669905983

Epoch: 5| Step: 6
Training loss: 1.4880571171555332
Validation loss: 2.7323348181678124

Epoch: 5| Step: 7
Training loss: 1.3477187874699557
Validation loss: 2.623963999290957

Epoch: 5| Step: 8
Training loss: 1.1250664373489667
Validation loss: 2.6220212793294198

Epoch: 5| Step: 9
Training loss: 1.5960855014193902
Validation loss: 2.6934043358620197

Epoch: 5| Step: 10
Training loss: 2.2623656933790817
Validation loss: 2.572919831422

Epoch: 5| Step: 11
Training loss: 0.7528061029361138
Validation loss: 2.598389879999582

Epoch: 209| Step: 0
Training loss: 2.03407513683553
Validation loss: 2.628303254622016

Epoch: 5| Step: 1
Training loss: 1.2621105991028185
Validation loss: 2.5929772957200012

Epoch: 5| Step: 2
Training loss: 2.1568876788624194
Validation loss: 2.6223489983829706

Epoch: 5| Step: 3
Training loss: 1.0872234716382778
Validation loss: 2.6560786509878063

Epoch: 5| Step: 4
Training loss: 1.6266035824148892
Validation loss: 2.6649026040189754

Epoch: 5| Step: 5
Training loss: 1.0811459331375803
Validation loss: 2.68118737584083

Epoch: 5| Step: 6
Training loss: 1.0790236224858032
Validation loss: 2.7320906661272994

Epoch: 5| Step: 7
Training loss: 1.731210312922075
Validation loss: 2.75778221819771

Epoch: 5| Step: 8
Training loss: 1.168271181890459
Validation loss: 2.7971656903987228

Epoch: 5| Step: 9
Training loss: 1.6095982368971495
Validation loss: 2.8402338437789165

Epoch: 5| Step: 10
Training loss: 1.8599526285476424
Validation loss: 2.758024337240356

Epoch: 5| Step: 11
Training loss: 2.0051467952120414
Validation loss: 2.7237145015100865

Epoch: 210| Step: 0
Training loss: 1.5382837949376247
Validation loss: 2.622264621385329

Epoch: 5| Step: 1
Training loss: 1.5287612620178266
Validation loss: 2.697297873408965

Epoch: 5| Step: 2
Training loss: 1.3328524209021966
Validation loss: 2.6579020131336066

Epoch: 5| Step: 3
Training loss: 1.753587723590523
Validation loss: 2.636032101739355

Epoch: 5| Step: 4
Training loss: 1.936771009570301
Validation loss: 2.7091688658496995

Epoch: 5| Step: 5
Training loss: 2.159798397616585
Validation loss: 2.6520583177561914

Epoch: 5| Step: 6
Training loss: 1.3201005754301824
Validation loss: 2.6329450885202346

Epoch: 5| Step: 7
Training loss: 1.922585456843775
Validation loss: 2.600023564818772

Epoch: 5| Step: 8
Training loss: 1.6616302050560143
Validation loss: 2.6616308277068534

Epoch: 5| Step: 9
Training loss: 1.3260947922789819
Validation loss: 2.6171542682720443

Epoch: 5| Step: 10
Training loss: 1.6860066623307228
Validation loss: 2.761265118081074

Epoch: 5| Step: 11
Training loss: 1.3470212020649717
Validation loss: 2.8345432024097215

Epoch: 211| Step: 0
Training loss: 1.7059755880167746
Validation loss: 2.7649646247195454

Epoch: 5| Step: 1
Training loss: 1.7277296445274235
Validation loss: 2.7482169360093134

Epoch: 5| Step: 2
Training loss: 1.4247798381518386
Validation loss: 2.7562298218211243

Epoch: 5| Step: 3
Training loss: 0.9557694193638065
Validation loss: 2.751225797958953

Epoch: 5| Step: 4
Training loss: 1.9146116753418554
Validation loss: 2.7203363964207847

Epoch: 5| Step: 5
Training loss: 0.8679608170415491
Validation loss: 2.659731950125128

Epoch: 5| Step: 6
Training loss: 1.634992540441639
Validation loss: 2.6766402339243767

Epoch: 5| Step: 7
Training loss: 1.7265214872020167
Validation loss: 2.6136794858354278

Epoch: 5| Step: 8
Training loss: 1.3969556320097105
Validation loss: 2.658872177755469

Epoch: 5| Step: 9
Training loss: 1.9680583283805593
Validation loss: 2.596673252671116

Epoch: 5| Step: 10
Training loss: 1.4548265892592402
Validation loss: 2.67176237854247

Epoch: 5| Step: 11
Training loss: 1.2963833164091416
Validation loss: 2.618261192955065

Epoch: 212| Step: 0
Training loss: 1.5296103593431603
Validation loss: 2.645293983669561

Epoch: 5| Step: 1
Training loss: 1.475600963947729
Validation loss: 2.6547972203108574

Epoch: 5| Step: 2
Training loss: 1.3248304906416202
Validation loss: 2.5715749204771963

Epoch: 5| Step: 3
Training loss: 1.4018002787866912
Validation loss: 2.667211589916743

Epoch: 5| Step: 4
Training loss: 1.6356983144769288
Validation loss: 2.667861284704587

Epoch: 5| Step: 5
Training loss: 1.4060511554430433
Validation loss: 2.7418640974860047

Epoch: 5| Step: 6
Training loss: 1.8286628909951084
Validation loss: 2.7951535622716404

Epoch: 5| Step: 7
Training loss: 2.178591873287423
Validation loss: 2.7802047193972292

Epoch: 5| Step: 8
Training loss: 1.2982028459947061
Validation loss: 2.7295144031873946

Epoch: 5| Step: 9
Training loss: 1.202498780803102
Validation loss: 2.767455879693663

Epoch: 5| Step: 10
Training loss: 1.4273945081650332
Validation loss: 2.693137089863073

Epoch: 5| Step: 11
Training loss: 1.7607914076202473
Validation loss: 2.6733878483519344

Epoch: 213| Step: 0
Training loss: 1.6868978768345453
Validation loss: 2.633614520761758

Epoch: 5| Step: 1
Training loss: 1.3578351825535921
Validation loss: 2.7003056996265813

Epoch: 5| Step: 2
Training loss: 1.1051284751600137
Validation loss: 2.6579202187978814

Epoch: 5| Step: 3
Training loss: 1.532192407328251
Validation loss: 2.630108532412761

Epoch: 5| Step: 4
Training loss: 1.7179598292404956
Validation loss: 2.6377712946388256

Epoch: 5| Step: 5
Training loss: 1.1110332077584655
Validation loss: 2.62175782115734

Epoch: 5| Step: 6
Training loss: 1.4785717408026555
Validation loss: 2.687339707702806

Epoch: 5| Step: 7
Training loss: 2.088950392255041
Validation loss: 2.5828666778254625

Epoch: 5| Step: 8
Training loss: 1.540631496578238
Validation loss: 2.6380008547378786

Epoch: 5| Step: 9
Training loss: 1.7107546634613298
Validation loss: 2.6412044581578953

Epoch: 5| Step: 10
Training loss: 1.6436206172020433
Validation loss: 2.677871711709351

Epoch: 5| Step: 11
Training loss: 0.7423276668501322
Validation loss: 2.6951045117316395

Epoch: 214| Step: 0
Training loss: 1.5777365329139272
Validation loss: 2.80210307207683

Epoch: 5| Step: 1
Training loss: 1.7203620979719438
Validation loss: 2.814614105385814

Epoch: 5| Step: 2
Training loss: 1.6430977488188163
Validation loss: 2.8146426728038483

Epoch: 5| Step: 3
Training loss: 1.2226735074223876
Validation loss: 2.8011582855446795

Epoch: 5| Step: 4
Training loss: 1.1934614122287084
Validation loss: 2.6325596009692807

Epoch: 5| Step: 5
Training loss: 1.657885769331413
Validation loss: 2.648771264979651

Epoch: 5| Step: 6
Training loss: 1.4282129740590617
Validation loss: 2.7018069083723875

Epoch: 5| Step: 7
Training loss: 1.616348048729969
Validation loss: 2.7031447312474657

Epoch: 5| Step: 8
Training loss: 2.0027182703205857
Validation loss: 2.603266920424213

Epoch: 5| Step: 9
Training loss: 1.2454988500527764
Validation loss: 2.611831260872351

Epoch: 5| Step: 10
Training loss: 1.4649290339756944
Validation loss: 2.6054297181674992

Epoch: 5| Step: 11
Training loss: 1.0949854276723872
Validation loss: 2.631334357748041

Epoch: 215| Step: 0
Training loss: 1.0033413377444664
Validation loss: 2.6292981275609235

Epoch: 5| Step: 1
Training loss: 1.9952402697747607
Validation loss: 2.654748009524779

Epoch: 5| Step: 2
Training loss: 1.2842602606614664
Validation loss: 2.6412706545100266

Epoch: 5| Step: 3
Training loss: 1.27819506539431
Validation loss: 2.612737172295639

Epoch: 5| Step: 4
Training loss: 1.4410302310078253
Validation loss: 2.6585131447367663

Epoch: 5| Step: 5
Training loss: 1.3267597137262341
Validation loss: 2.6031071618405073

Epoch: 5| Step: 6
Training loss: 1.699826888077834
Validation loss: 2.65762340718462

Epoch: 5| Step: 7
Training loss: 1.3271267898287367
Validation loss: 2.633919797148418

Epoch: 5| Step: 8
Training loss: 2.2936760040737703
Validation loss: 2.719589129479214

Epoch: 5| Step: 9
Training loss: 1.5041479932025712
Validation loss: 2.760301191085889

Epoch: 5| Step: 10
Training loss: 1.3869858175651368
Validation loss: 2.7308002901876804

Epoch: 5| Step: 11
Training loss: 0.37547962987331096
Validation loss: 2.7879882011496853

Epoch: 216| Step: 0
Training loss: 1.2997602058211
Validation loss: 2.7650582833841444

Epoch: 5| Step: 1
Training loss: 1.7720236498931496
Validation loss: 2.836177710666447

Epoch: 5| Step: 2
Training loss: 1.455081156273059
Validation loss: 2.7796159044222635

Epoch: 5| Step: 3
Training loss: 0.9912017972177094
Validation loss: 2.801334424015546

Epoch: 5| Step: 4
Training loss: 1.3063634741014347
Validation loss: 2.7554890838729387

Epoch: 5| Step: 5
Training loss: 1.4200820517675876
Validation loss: 2.617887875802736

Epoch: 5| Step: 6
Training loss: 1.8755816511148693
Validation loss: 2.685822800766448

Epoch: 5| Step: 7
Training loss: 2.02453877883292
Validation loss: 2.6824841970337903

Epoch: 5| Step: 8
Training loss: 1.4611910839620181
Validation loss: 2.6022613739867966

Epoch: 5| Step: 9
Training loss: 1.6447314505237751
Validation loss: 2.600003343283509

Epoch: 5| Step: 10
Training loss: 1.5976704268071347
Validation loss: 2.6159274166084336

Epoch: 5| Step: 11
Training loss: 0.5503175284888663
Validation loss: 2.5952604063142855

Epoch: 217| Step: 0
Training loss: 1.4386725411994876
Validation loss: 2.6316933031185696

Epoch: 5| Step: 1
Training loss: 1.3315728257304194
Validation loss: 2.6445021634777306

Epoch: 5| Step: 2
Training loss: 1.12943690938313
Validation loss: 2.6314629926880118

Epoch: 5| Step: 3
Training loss: 0.935134382637599
Validation loss: 2.7029657151584314

Epoch: 5| Step: 4
Training loss: 1.4549219649320537
Validation loss: 2.7022403121933634

Epoch: 5| Step: 5
Training loss: 1.2152350185077452
Validation loss: 2.654688997288836

Epoch: 5| Step: 6
Training loss: 1.8470678703176595
Validation loss: 2.6748179054374694

Epoch: 5| Step: 7
Training loss: 1.246025203146845
Validation loss: 2.7191865449964614

Epoch: 5| Step: 8
Training loss: 1.32732519863158
Validation loss: 2.7208325240487903

Epoch: 5| Step: 9
Training loss: 1.4644208373883003
Validation loss: 2.7318974196806356

Epoch: 5| Step: 10
Training loss: 2.2053012785667283
Validation loss: 2.721554157750789

Epoch: 5| Step: 11
Training loss: 2.164183905876437
Validation loss: 2.7261016587412525

Epoch: 218| Step: 0
Training loss: 1.3085533021967204
Validation loss: 2.617913911131832

Epoch: 5| Step: 1
Training loss: 2.031273122802585
Validation loss: 2.628708422445847

Epoch: 5| Step: 2
Training loss: 1.5671352297888765
Validation loss: 2.6371125028502496

Epoch: 5| Step: 3
Training loss: 1.4081138127505224
Validation loss: 2.693795091232456

Epoch: 5| Step: 4
Training loss: 1.4535801492592124
Validation loss: 2.640746522022083

Epoch: 5| Step: 5
Training loss: 1.8761306532604913
Validation loss: 2.6105653061882768

Epoch: 5| Step: 6
Training loss: 1.6183814465055613
Validation loss: 2.623777498437659

Epoch: 5| Step: 7
Training loss: 1.094300376835831
Validation loss: 2.6120060050602265

Epoch: 5| Step: 8
Training loss: 1.4802959411738623
Validation loss: 2.701443301576029

Epoch: 5| Step: 9
Training loss: 0.9912195064380996
Validation loss: 2.684323103924511

Epoch: 5| Step: 10
Training loss: 1.2942156815115422
Validation loss: 2.686264600617953

Epoch: 5| Step: 11
Training loss: 1.5079698233481538
Validation loss: 2.715464095267828

Epoch: 219| Step: 0
Training loss: 1.6694770800630097
Validation loss: 2.672682822209773

Epoch: 5| Step: 1
Training loss: 1.060431036761232
Validation loss: 2.6868637684749053

Epoch: 5| Step: 2
Training loss: 2.1182446532616996
Validation loss: 2.6667442397417815

Epoch: 5| Step: 3
Training loss: 1.316638914652785
Validation loss: 2.6296088690664567

Epoch: 5| Step: 4
Training loss: 1.6025792313864216
Validation loss: 2.6396872681887507

Epoch: 5| Step: 5
Training loss: 0.9497550422673179
Validation loss: 2.639316964703426

Epoch: 5| Step: 6
Training loss: 1.2916720708098213
Validation loss: 2.6834241285028337

Epoch: 5| Step: 7
Training loss: 1.151034215612446
Validation loss: 2.6828601358221107

Epoch: 5| Step: 8
Training loss: 2.1407036314396
Validation loss: 2.685876814486023

Epoch: 5| Step: 9
Training loss: 1.1359665731831217
Validation loss: 2.707497263508098

Epoch: 5| Step: 10
Training loss: 1.5133544589065169
Validation loss: 2.7322515580470164

Epoch: 5| Step: 11
Training loss: 1.0413751893730756
Validation loss: 2.747943976562775

Epoch: 220| Step: 0
Training loss: 1.4094447404138313
Validation loss: 2.726747446427794

Epoch: 5| Step: 1
Training loss: 1.3579340784845575
Validation loss: 2.666627884870891

Epoch: 5| Step: 2
Training loss: 1.1845791180339198
Validation loss: 2.615609447656333

Epoch: 5| Step: 3
Training loss: 1.0093202180434462
Validation loss: 2.697545719542962

Epoch: 5| Step: 4
Training loss: 1.2718883523076145
Validation loss: 2.652884511079227

Epoch: 5| Step: 5
Training loss: 1.1427501581559523
Validation loss: 2.6476915860099797

Epoch: 5| Step: 6
Training loss: 1.2724566748687476
Validation loss: 2.668171247074198

Epoch: 5| Step: 7
Training loss: 1.5243818437298327
Validation loss: 2.678257856482539

Epoch: 5| Step: 8
Training loss: 1.4866041611388296
Validation loss: 2.665601951168538

Epoch: 5| Step: 9
Training loss: 1.7660615769491306
Validation loss: 2.6859369390019956

Epoch: 5| Step: 10
Training loss: 2.4644094045173848
Validation loss: 2.6969057395954232

Epoch: 5| Step: 11
Training loss: 0.8546103085210179
Validation loss: 2.6459599574769843

Epoch: 221| Step: 0
Training loss: 1.4216638764640614
Validation loss: 2.673288339615166

Epoch: 5| Step: 1
Training loss: 0.9993614900115977
Validation loss: 2.684156918650607

Epoch: 5| Step: 2
Training loss: 0.9252378583212956
Validation loss: 2.6470511004443313

Epoch: 5| Step: 3
Training loss: 1.6092783334088832
Validation loss: 2.693734533615143

Epoch: 5| Step: 4
Training loss: 1.4261457421513573
Validation loss: 2.6369777222599957

Epoch: 5| Step: 5
Training loss: 1.6058931926635986
Validation loss: 2.66710839983899

Epoch: 5| Step: 6
Training loss: 1.2319471409159015
Validation loss: 2.6905563924669407

Epoch: 5| Step: 7
Training loss: 1.4048825715159063
Validation loss: 2.7159060515315034

Epoch: 5| Step: 8
Training loss: 1.9933789449064159
Validation loss: 2.706559533234771

Epoch: 5| Step: 9
Training loss: 1.553731653254025
Validation loss: 2.679217353853511

Epoch: 5| Step: 10
Training loss: 1.7888472648316713
Validation loss: 2.77740930014013

Epoch: 5| Step: 11
Training loss: 0.8045133383707918
Validation loss: 2.6631055699925614

Epoch: 222| Step: 0
Training loss: 1.5121536614986872
Validation loss: 2.706843686635775

Epoch: 5| Step: 1
Training loss: 0.7477000655167721
Validation loss: 2.7324593291261765

Epoch: 5| Step: 2
Training loss: 1.5618396126415974
Validation loss: 2.6774280650213944

Epoch: 5| Step: 3
Training loss: 1.3881096540115476
Validation loss: 2.690411506125235

Epoch: 5| Step: 4
Training loss: 1.2912680051717051
Validation loss: 2.6574785196507404

Epoch: 5| Step: 5
Training loss: 1.1819667397675055
Validation loss: 2.6931734120008888

Epoch: 5| Step: 6
Training loss: 1.2948012259824297
Validation loss: 2.7419601991064044

Epoch: 5| Step: 7
Training loss: 1.3483328627281799
Validation loss: 2.6755042830753566

Epoch: 5| Step: 8
Training loss: 1.4654955418394302
Validation loss: 2.6842962046210057

Epoch: 5| Step: 9
Training loss: 2.1606659934491965
Validation loss: 2.7823759507286274

Epoch: 5| Step: 10
Training loss: 1.6555239687572514
Validation loss: 2.726327397759175

Epoch: 5| Step: 11
Training loss: 1.3858199524515415
Validation loss: 2.643199831544549

Epoch: 223| Step: 0
Training loss: 1.4811674296225208
Validation loss: 2.668111239752483

Epoch: 5| Step: 1
Training loss: 1.0802337920604679
Validation loss: 2.693537336689199

Epoch: 5| Step: 2
Training loss: 0.8335854069614929
Validation loss: 2.6797574166684823

Epoch: 5| Step: 3
Training loss: 1.0144200145913023
Validation loss: 2.6486691623970113

Epoch: 5| Step: 4
Training loss: 0.9488632101432828
Validation loss: 2.701742222818026

Epoch: 5| Step: 5
Training loss: 1.6914947698040377
Validation loss: 2.7372026554888236

Epoch: 5| Step: 6
Training loss: 1.2956917201895288
Validation loss: 2.7169229499675516

Epoch: 5| Step: 7
Training loss: 1.2697563089272952
Validation loss: 2.765707743928128

Epoch: 5| Step: 8
Training loss: 1.561012170053825
Validation loss: 2.7581198109551233

Epoch: 5| Step: 9
Training loss: 2.368979804735908
Validation loss: 2.6915170400375255

Epoch: 5| Step: 10
Training loss: 1.953324696822272
Validation loss: 2.7156544268571725

Epoch: 5| Step: 11
Training loss: 1.3648544896297732
Validation loss: 2.720944815820407

Epoch: 224| Step: 0
Training loss: 1.3562590743785299
Validation loss: 2.665162499834153

Epoch: 5| Step: 1
Training loss: 1.4596027662134445
Validation loss: 2.6658936934948025

Epoch: 5| Step: 2
Training loss: 1.4452734039792456
Validation loss: 2.660563515712994

Epoch: 5| Step: 3
Training loss: 1.4074627203603305
Validation loss: 2.6540131799752227

Epoch: 5| Step: 4
Training loss: 1.245026517072428
Validation loss: 2.6032393152202116

Epoch: 5| Step: 5
Training loss: 1.1100446265073443
Validation loss: 2.657160711307819

Epoch: 5| Step: 6
Training loss: 2.06278585129243
Validation loss: 2.665839023353472

Epoch: 5| Step: 7
Training loss: 1.55851948114188
Validation loss: 2.682850749195452

Epoch: 5| Step: 8
Training loss: 1.703223409346882
Validation loss: 2.60679101825004

Epoch: 5| Step: 9
Training loss: 1.1750740636655577
Validation loss: 2.709149396656117

Epoch: 5| Step: 10
Training loss: 0.979328906368882
Validation loss: 2.766921506389907

Epoch: 5| Step: 11
Training loss: 0.7480479905242172
Validation loss: 2.788655562147605

Epoch: 225| Step: 0
Training loss: 1.6630735368876715
Validation loss: 2.821562742641043

Epoch: 5| Step: 1
Training loss: 1.3338678401239727
Validation loss: 2.868311872040897

Epoch: 5| Step: 2
Training loss: 1.4416480546459165
Validation loss: 2.809015025809481

Epoch: 5| Step: 3
Training loss: 1.4448682772515244
Validation loss: 2.7550321058703378

Epoch: 5| Step: 4
Training loss: 1.6433096582333524
Validation loss: 2.793593355064265

Epoch: 5| Step: 5
Training loss: 0.9225062778951927
Validation loss: 2.7133403906000133

Epoch: 5| Step: 6
Training loss: 1.3048141783473133
Validation loss: 2.7170018316021025

Epoch: 5| Step: 7
Training loss: 2.0813479563712365
Validation loss: 2.6802231556324023

Epoch: 5| Step: 8
Training loss: 1.2622024978762882
Validation loss: 2.658205217803946

Epoch: 5| Step: 9
Training loss: 1.5449013497668629
Validation loss: 2.664912952250363

Epoch: 5| Step: 10
Training loss: 1.480391930673124
Validation loss: 2.66304190841404

Epoch: 5| Step: 11
Training loss: 0.5770809179271548
Validation loss: 2.585430037847878

Epoch: 226| Step: 0
Training loss: 1.3396781618875313
Validation loss: 2.6249155681897696

Epoch: 5| Step: 1
Training loss: 1.4261271853982325
Validation loss: 2.704162762281032

Epoch: 5| Step: 2
Training loss: 2.0598499728634527
Validation loss: 2.6077017073183804

Epoch: 5| Step: 3
Training loss: 1.1808111132350785
Validation loss: 2.6691858560325117

Epoch: 5| Step: 4
Training loss: 1.5731326916960893
Validation loss: 2.7072290382220734

Epoch: 5| Step: 5
Training loss: 0.9244087765540722
Validation loss: 2.738641560095221

Epoch: 5| Step: 6
Training loss: 1.5547595750213619
Validation loss: 2.7039795923008416

Epoch: 5| Step: 7
Training loss: 1.4195144677521658
Validation loss: 2.6858613245120235

Epoch: 5| Step: 8
Training loss: 1.1499178940031365
Validation loss: 2.684630958424408

Epoch: 5| Step: 9
Training loss: 1.3860332675260594
Validation loss: 2.694930955353904

Epoch: 5| Step: 10
Training loss: 1.4421808905982165
Validation loss: 2.6493991617509507

Epoch: 5| Step: 11
Training loss: 1.4322045687000249
Validation loss: 2.650751815019362

Epoch: 227| Step: 0
Training loss: 1.7966876388392106
Validation loss: 2.6687670212083003

Epoch: 5| Step: 1
Training loss: 1.041772449208497
Validation loss: 2.678885885884174

Epoch: 5| Step: 2
Training loss: 1.3581679235663133
Validation loss: 2.6475035071717476

Epoch: 5| Step: 3
Training loss: 1.420877798658098
Validation loss: 2.6547377414151514

Epoch: 5| Step: 4
Training loss: 1.0225100792385717
Validation loss: 2.6639145020424926

Epoch: 5| Step: 5
Training loss: 1.6332085964035503
Validation loss: 2.6863618296201173

Epoch: 5| Step: 6
Training loss: 1.9374582839904888
Validation loss: 2.6917880765108397

Epoch: 5| Step: 7
Training loss: 1.3900325670475127
Validation loss: 2.649192559890786

Epoch: 5| Step: 8
Training loss: 1.0169962502507013
Validation loss: 2.707112177620334

Epoch: 5| Step: 9
Training loss: 1.633643126140598
Validation loss: 2.7443217913465494

Epoch: 5| Step: 10
Training loss: 1.086671814223737
Validation loss: 2.8108249267858048

Epoch: 5| Step: 11
Training loss: 1.5138405588972872
Validation loss: 2.720415920371009

Epoch: 228| Step: 0
Training loss: 1.2844471468002405
Validation loss: 2.6416750293041757

Epoch: 5| Step: 1
Training loss: 1.3459355523153136
Validation loss: 2.657574050615658

Epoch: 5| Step: 2
Training loss: 1.6185457726747823
Validation loss: 2.6346298118673213

Epoch: 5| Step: 3
Training loss: 1.5758209783324257
Validation loss: 2.633135959666723

Epoch: 5| Step: 4
Training loss: 2.3987454393750003
Validation loss: 2.6601310239577

Epoch: 5| Step: 5
Training loss: 1.2171530408964104
Validation loss: 2.665667657186631

Epoch: 5| Step: 6
Training loss: 1.2958998173445462
Validation loss: 2.6281656107144333

Epoch: 5| Step: 7
Training loss: 1.410669038057287
Validation loss: 2.735777438957402

Epoch: 5| Step: 8
Training loss: 1.4688036482732423
Validation loss: 2.720589165492826

Epoch: 5| Step: 9
Training loss: 1.2667105928551046
Validation loss: 2.7088796443629777

Epoch: 5| Step: 10
Training loss: 1.2027828671379768
Validation loss: 2.741888122301111

Epoch: 5| Step: 11
Training loss: 0.8436480919790094
Validation loss: 2.73971890825993

Epoch: 229| Step: 0
Training loss: 1.2822053650427967
Validation loss: 2.8395549639578883

Epoch: 5| Step: 1
Training loss: 1.1530485422481742
Validation loss: 2.757241111544585

Epoch: 5| Step: 2
Training loss: 2.057339541365099
Validation loss: 2.743785483117092

Epoch: 5| Step: 3
Training loss: 1.6048997302241303
Validation loss: 2.6721638343062573

Epoch: 5| Step: 4
Training loss: 1.3914887392586994
Validation loss: 2.7166469924795527

Epoch: 5| Step: 5
Training loss: 1.069577152445853
Validation loss: 2.6430168586492293

Epoch: 5| Step: 6
Training loss: 1.528145582064389
Validation loss: 2.609306147993769

Epoch: 5| Step: 7
Training loss: 1.764867569491206
Validation loss: 2.6683746706766605

Epoch: 5| Step: 8
Training loss: 1.4922220116264275
Validation loss: 2.6508821159620206

Epoch: 5| Step: 9
Training loss: 1.350132753767916
Validation loss: 2.618434688549761

Epoch: 5| Step: 10
Training loss: 1.374408508003333
Validation loss: 2.6769112013361727

Epoch: 5| Step: 11
Training loss: 1.3719682214298563
Validation loss: 2.6791124662955297

Epoch: 230| Step: 0
Training loss: 1.3993324101566023
Validation loss: 2.6642129059486725

Epoch: 5| Step: 1
Training loss: 1.5967673368048843
Validation loss: 2.7059659490188626

Epoch: 5| Step: 2
Training loss: 1.5817413441213322
Validation loss: 2.717159357669187

Epoch: 5| Step: 3
Training loss: 1.0644293826193902
Validation loss: 2.72751838593386

Epoch: 5| Step: 4
Training loss: 1.1901515169413905
Validation loss: 2.7455572017429914

Epoch: 5| Step: 5
Training loss: 1.602843502679735
Validation loss: 2.7055323323874796

Epoch: 5| Step: 6
Training loss: 1.8938869993302927
Validation loss: 2.7213448166876733

Epoch: 5| Step: 7
Training loss: 1.57000805385006
Validation loss: 2.7830812054973473

Epoch: 5| Step: 8
Training loss: 1.2804360479213583
Validation loss: 2.727278086296991

Epoch: 5| Step: 9
Training loss: 0.8053740748237768
Validation loss: 2.6270119623829817

Epoch: 5| Step: 10
Training loss: 1.3505161181847052
Validation loss: 2.6968146151268755

Epoch: 5| Step: 11
Training loss: 1.336188487964652
Validation loss: 2.6441903469801833

Epoch: 231| Step: 0
Training loss: 1.1438967667931552
Validation loss: 2.649750135745969

Epoch: 5| Step: 1
Training loss: 1.3944502948589288
Validation loss: 2.686226284205836

Epoch: 5| Step: 2
Training loss: 1.3754159991657464
Validation loss: 2.703324259137361

Epoch: 5| Step: 3
Training loss: 1.2906646020461612
Validation loss: 2.671541403232269

Epoch: 5| Step: 4
Training loss: 1.6179166615057405
Validation loss: 2.723711860889241

Epoch: 5| Step: 5
Training loss: 1.5587502307784606
Validation loss: 2.7072684279077177

Epoch: 5| Step: 6
Training loss: 2.293496898022806
Validation loss: 2.7044506019937335

Epoch: 5| Step: 7
Training loss: 0.805917263124532
Validation loss: 2.723975352324692

Epoch: 5| Step: 8
Training loss: 1.3197338935633753
Validation loss: 2.6887224525809206

Epoch: 5| Step: 9
Training loss: 1.1351185970270734
Validation loss: 2.6666831982120054

Epoch: 5| Step: 10
Training loss: 0.9304457065089425
Validation loss: 2.721324501910202

Epoch: 5| Step: 11
Training loss: 0.7546392642573905
Validation loss: 2.7067817510624823

Epoch: 232| Step: 0
Training loss: 1.611348173999323
Validation loss: 2.683903200168124

Epoch: 5| Step: 1
Training loss: 1.8527070061344924
Validation loss: 2.697046354323096

Epoch: 5| Step: 2
Training loss: 1.746995936047828
Validation loss: 2.7218374793542948

Epoch: 5| Step: 3
Training loss: 1.286244774929218
Validation loss: 2.691994213885909

Epoch: 5| Step: 4
Training loss: 1.0693819776404374
Validation loss: 2.70183342008579

Epoch: 5| Step: 5
Training loss: 1.1926084862551214
Validation loss: 2.678713570562319

Epoch: 5| Step: 6
Training loss: 1.0686555274121852
Validation loss: 2.72032983048769

Epoch: 5| Step: 7
Training loss: 1.3669447329106
Validation loss: 2.7240595254768416

Epoch: 5| Step: 8
Training loss: 1.303092392620978
Validation loss: 2.6634948364326156

Epoch: 5| Step: 9
Training loss: 1.4381472747417234
Validation loss: 2.7033280074049073

Epoch: 5| Step: 10
Training loss: 1.2233976608552097
Validation loss: 2.707004354324052

Epoch: 5| Step: 11
Training loss: 1.3493277536083348
Validation loss: 2.700108975254022

Epoch: 233| Step: 0
Training loss: 1.3408213793923287
Validation loss: 2.6350255168292156

Epoch: 5| Step: 1
Training loss: 1.70257440468849
Validation loss: 2.6681843154377227

Epoch: 5| Step: 2
Training loss: 1.2461097740171458
Validation loss: 2.644118261277928

Epoch: 5| Step: 3
Training loss: 1.4557597567142728
Validation loss: 2.6981281997841955

Epoch: 5| Step: 4
Training loss: 1.3728510797065323
Validation loss: 2.651587350789203

Epoch: 5| Step: 5
Training loss: 1.385521342211924
Validation loss: 2.668628512378573

Epoch: 5| Step: 6
Training loss: 1.0349940910723536
Validation loss: 2.6671954924529424

Epoch: 5| Step: 7
Training loss: 1.0043592803807382
Validation loss: 2.6579058478825375

Epoch: 5| Step: 8
Training loss: 1.3588429867845142
Validation loss: 2.6998434857344917

Epoch: 5| Step: 9
Training loss: 2.079558372931191
Validation loss: 2.6949000720286573

Epoch: 5| Step: 10
Training loss: 0.8391421559064748
Validation loss: 2.714498239024199

Epoch: 5| Step: 11
Training loss: 0.7189631353406031
Validation loss: 2.7241805820473375

Epoch: 234| Step: 0
Training loss: 1.8850243583542217
Validation loss: 2.6438452818454112

Epoch: 5| Step: 1
Training loss: 1.3415305860390208
Validation loss: 2.631174032363574

Epoch: 5| Step: 2
Training loss: 1.7189269928399715
Validation loss: 2.713753036106074

Epoch: 5| Step: 3
Training loss: 1.6185041587052582
Validation loss: 2.612890266551121

Epoch: 5| Step: 4
Training loss: 1.1320090766246298
Validation loss: 2.6462816787178625

Epoch: 5| Step: 5
Training loss: 1.1338011538101491
Validation loss: 2.662948423928535

Epoch: 5| Step: 6
Training loss: 1.16111535908613
Validation loss: 2.630496571424578

Epoch: 5| Step: 7
Training loss: 1.0262721749998658
Validation loss: 2.726804086790603

Epoch: 5| Step: 8
Training loss: 1.2861134405277506
Validation loss: 2.613142193267276

Epoch: 5| Step: 9
Training loss: 1.2145844210341192
Validation loss: 2.622284154146018

Epoch: 5| Step: 10
Training loss: 1.415290931205451
Validation loss: 2.6711868753384223

Epoch: 5| Step: 11
Training loss: 1.2848243168768394
Validation loss: 2.6791007879729363

Epoch: 235| Step: 0
Training loss: 1.4597546690095116
Validation loss: 2.7399679005905213

Epoch: 5| Step: 1
Training loss: 1.2922600131924562
Validation loss: 2.720050500723508

Epoch: 5| Step: 2
Training loss: 1.149835216077406
Validation loss: 2.7778466132032666

Epoch: 5| Step: 3
Training loss: 0.8324831241466599
Validation loss: 2.711792000429925

Epoch: 5| Step: 4
Training loss: 1.8460158956014854
Validation loss: 2.7619140030805345

Epoch: 5| Step: 5
Training loss: 1.4843887328466308
Validation loss: 2.8382280170612275

Epoch: 5| Step: 6
Training loss: 1.1875768435862593
Validation loss: 2.7037216696663635

Epoch: 5| Step: 7
Training loss: 1.079728026671483
Validation loss: 2.72625374343804

Epoch: 5| Step: 8
Training loss: 1.5428879342463024
Validation loss: 2.690913889399684

Epoch: 5| Step: 9
Training loss: 1.2722162112372117
Validation loss: 2.681827680338774

Epoch: 5| Step: 10
Training loss: 1.452709507761421
Validation loss: 2.693347188596056

Epoch: 5| Step: 11
Training loss: 0.5074714982903692
Validation loss: 2.662534711951771

Epoch: 236| Step: 0
Training loss: 1.3586398362014673
Validation loss: 2.6164826805787587

Epoch: 5| Step: 1
Training loss: 1.377856192463822
Validation loss: 2.6470480906200353

Epoch: 5| Step: 2
Training loss: 0.9650512966298491
Validation loss: 2.6573262203566452

Epoch: 5| Step: 3
Training loss: 1.485400036704917
Validation loss: 2.6296931048564147

Epoch: 5| Step: 4
Training loss: 0.7429936096974243
Validation loss: 2.7078314768600777

Epoch: 5| Step: 5
Training loss: 1.2182482640320393
Validation loss: 2.7568490612164935

Epoch: 5| Step: 6
Training loss: 1.7808344172163673
Validation loss: 2.7384241387003816

Epoch: 5| Step: 7
Training loss: 1.7586751219989891
Validation loss: 2.811292523336278

Epoch: 5| Step: 8
Training loss: 1.6206109120690446
Validation loss: 2.773121069824469

Epoch: 5| Step: 9
Training loss: 1.1806310455022084
Validation loss: 2.7232509275557564

Epoch: 5| Step: 10
Training loss: 1.2032973921490218
Validation loss: 2.7383225782960614

Epoch: 5| Step: 11
Training loss: 0.8645658644477894
Validation loss: 2.7329379092755386

Epoch: 237| Step: 0
Training loss: 1.4884931758868984
Validation loss: 2.7286469690289326

Epoch: 5| Step: 1
Training loss: 1.4489523753362052
Validation loss: 2.6564268763873584

Epoch: 5| Step: 2
Training loss: 1.1276929202254753
Validation loss: 2.6331818507380658

Epoch: 5| Step: 3
Training loss: 1.3892489708262858
Validation loss: 2.5980429091495214

Epoch: 5| Step: 4
Training loss: 1.245107421836703
Validation loss: 2.686229379567982

Epoch: 5| Step: 5
Training loss: 1.998377976712934
Validation loss: 2.697762011117397

Epoch: 5| Step: 6
Training loss: 1.251413785597639
Validation loss: 2.6503310790713455

Epoch: 5| Step: 7
Training loss: 0.7637245569814175
Validation loss: 2.7039978257258457

Epoch: 5| Step: 8
Training loss: 1.410321001483255
Validation loss: 2.7306956322911455

Epoch: 5| Step: 9
Training loss: 1.3053253807362042
Validation loss: 2.6872419577185536

Epoch: 5| Step: 10
Training loss: 1.1531891905743425
Validation loss: 2.7339745691556616

Epoch: 5| Step: 11
Training loss: 1.5411276347521252
Validation loss: 2.7215017884049013

Epoch: 238| Step: 0
Training loss: 1.2787550849104954
Validation loss: 2.7612903627824834

Epoch: 5| Step: 1
Training loss: 1.1971697372198171
Validation loss: 2.6510239783535705

Epoch: 5| Step: 2
Training loss: 2.0337309724730055
Validation loss: 2.7954846163720837

Epoch: 5| Step: 3
Training loss: 1.364385512866742
Validation loss: 2.6508536368928324

Epoch: 5| Step: 4
Training loss: 1.2476347957861351
Validation loss: 2.6961784851323913

Epoch: 5| Step: 5
Training loss: 1.2719894320210918
Validation loss: 2.724737341643288

Epoch: 5| Step: 6
Training loss: 1.3474293393379362
Validation loss: 2.673103905054137

Epoch: 5| Step: 7
Training loss: 0.9447940003444417
Validation loss: 2.7339062897552338

Epoch: 5| Step: 8
Training loss: 1.037066097757447
Validation loss: 2.672770236804487

Epoch: 5| Step: 9
Training loss: 1.0612696087107398
Validation loss: 2.674862587450551

Epoch: 5| Step: 10
Training loss: 1.2830686919747538
Validation loss: 2.699375804963713

Epoch: 5| Step: 11
Training loss: 2.4407405342372526
Validation loss: 2.720286461334676

Epoch: 239| Step: 0
Training loss: 1.2557926901855943
Validation loss: 2.646515053809391

Epoch: 5| Step: 1
Training loss: 0.790242361121712
Validation loss: 2.6956510506271925

Epoch: 5| Step: 2
Training loss: 0.977724558849187
Validation loss: 2.7646494220537403

Epoch: 5| Step: 3
Training loss: 1.1269381570069952
Validation loss: 2.720127768747155

Epoch: 5| Step: 4
Training loss: 1.4802561584664102
Validation loss: 2.736958197245073

Epoch: 5| Step: 5
Training loss: 1.266346196157409
Validation loss: 2.791496301311129

Epoch: 5| Step: 6
Training loss: 1.0827573687897853
Validation loss: 2.7712834800437975

Epoch: 5| Step: 7
Training loss: 2.060904492626544
Validation loss: 2.7354507401071184

Epoch: 5| Step: 8
Training loss: 1.0798866143576253
Validation loss: 2.7046588246812298

Epoch: 5| Step: 9
Training loss: 1.6240794435387609
Validation loss: 2.692392793142706

Epoch: 5| Step: 10
Training loss: 1.5139578075450892
Validation loss: 2.7294858292088753

Epoch: 5| Step: 11
Training loss: 1.2234993364825708
Validation loss: 2.7281793247391217

Epoch: 240| Step: 0
Training loss: 1.6842758319374846
Validation loss: 2.692749467064557

Epoch: 5| Step: 1
Training loss: 1.8703645627225733
Validation loss: 2.7136662406418113

Epoch: 5| Step: 2
Training loss: 2.102866523355981
Validation loss: 2.7209955164683044

Epoch: 5| Step: 3
Training loss: 1.129985043080686
Validation loss: 2.8020580738493757

Epoch: 5| Step: 4
Training loss: 0.8938932184030609
Validation loss: 2.7618075027844764

Epoch: 5| Step: 5
Training loss: 0.9900723236330616
Validation loss: 2.751495357548446

Epoch: 5| Step: 6
Training loss: 1.0454956760909992
Validation loss: 2.7307803949826677

Epoch: 5| Step: 7
Training loss: 1.0080206013004789
Validation loss: 2.7280485481133194

Epoch: 5| Step: 8
Training loss: 1.0065757792750716
Validation loss: 2.736646544294996

Epoch: 5| Step: 9
Training loss: 1.3125484548434585
Validation loss: 2.6906741973301664

Epoch: 5| Step: 10
Training loss: 0.7515398351221858
Validation loss: 2.6813153808020576

Epoch: 5| Step: 11
Training loss: 0.9620175068802849
Validation loss: 2.7116681524208968

Epoch: 241| Step: 0
Training loss: 1.3022975389397726
Validation loss: 2.755051735800691

Epoch: 5| Step: 1
Training loss: 1.0329249680034078
Validation loss: 2.7000897920948304

Epoch: 5| Step: 2
Training loss: 0.7413910055251398
Validation loss: 2.709815453642251

Epoch: 5| Step: 3
Training loss: 1.8739978655352085
Validation loss: 2.716320658854757

Epoch: 5| Step: 4
Training loss: 1.4455043356113604
Validation loss: 2.698629658183141

Epoch: 5| Step: 5
Training loss: 1.0483139169913462
Validation loss: 2.6864901722834107

Epoch: 5| Step: 6
Training loss: 1.6065922353975957
Validation loss: 2.6521599078055025

Epoch: 5| Step: 7
Training loss: 1.5379085184131371
Validation loss: 2.6910337274283713

Epoch: 5| Step: 8
Training loss: 1.5885882845015695
Validation loss: 2.644935926299489

Epoch: 5| Step: 9
Training loss: 1.0207216175738518
Validation loss: 2.7884281409411256

Epoch: 5| Step: 10
Training loss: 1.0814567721012736
Validation loss: 2.7344079497032374

Epoch: 5| Step: 11
Training loss: 0.5090464931006415
Validation loss: 2.7166452445509823

Epoch: 242| Step: 0
Training loss: 1.3776537255913779
Validation loss: 2.6849213175607884

Epoch: 5| Step: 1
Training loss: 2.089251339807796
Validation loss: 2.7190694621270675

Epoch: 5| Step: 2
Training loss: 1.113323117188353
Validation loss: 2.7504603170450435

Epoch: 5| Step: 3
Training loss: 1.5307413151550884
Validation loss: 2.8263234500094345

Epoch: 5| Step: 4
Training loss: 1.0361614025604635
Validation loss: 2.790103878220375

Epoch: 5| Step: 5
Training loss: 1.0153254727526648
Validation loss: 2.713425120647232

Epoch: 5| Step: 6
Training loss: 1.4283842389899668
Validation loss: 2.7192146371936987

Epoch: 5| Step: 7
Training loss: 1.125295494266779
Validation loss: 2.6262525605182128

Epoch: 5| Step: 8
Training loss: 1.669532775164181
Validation loss: 2.660036925535203

Epoch: 5| Step: 9
Training loss: 0.9964564841033495
Validation loss: 2.70772231557692

Epoch: 5| Step: 10
Training loss: 1.1750320633105036
Validation loss: 2.7218968095281575

Epoch: 5| Step: 11
Training loss: 0.792013222148131
Validation loss: 2.7058623020778025

Epoch: 243| Step: 0
Training loss: 1.3425961353113975
Validation loss: 2.7174364548816

Epoch: 5| Step: 1
Training loss: 0.9867782925168441
Validation loss: 2.6955098029267215

Epoch: 5| Step: 2
Training loss: 1.007839172956597
Validation loss: 2.6833713000634503

Epoch: 5| Step: 3
Training loss: 1.2157256430418317
Validation loss: 2.687804644713292

Epoch: 5| Step: 4
Training loss: 1.0138611956665315
Validation loss: 2.729179117790726

Epoch: 5| Step: 5
Training loss: 0.8195308776214597
Validation loss: 2.6663272959609063

Epoch: 5| Step: 6
Training loss: 1.4100092338367876
Validation loss: 2.711095627598723

Epoch: 5| Step: 7
Training loss: 1.4960521562735611
Validation loss: 2.737841398036333

Epoch: 5| Step: 8
Training loss: 1.279849054108765
Validation loss: 2.7335446432084987

Epoch: 5| Step: 9
Training loss: 1.1959057002927174
Validation loss: 2.7547825025713624

Epoch: 5| Step: 10
Training loss: 2.138243972960717
Validation loss: 2.6840087888034145

Epoch: 5| Step: 11
Training loss: 1.2693549400558928
Validation loss: 2.7064161679862284

Epoch: 244| Step: 0
Training loss: 1.2107525099689525
Validation loss: 2.7157530983759086

Epoch: 5| Step: 1
Training loss: 1.146299850977276
Validation loss: 2.677412225630318

Epoch: 5| Step: 2
Training loss: 1.0838550937299722
Validation loss: 2.658153749297466

Epoch: 5| Step: 3
Training loss: 1.4394165200039573
Validation loss: 2.6795244825359523

Epoch: 5| Step: 4
Training loss: 1.5258142955070841
Validation loss: 2.686262292995049

Epoch: 5| Step: 5
Training loss: 1.509633758036876
Validation loss: 2.724304065438691

Epoch: 5| Step: 6
Training loss: 1.0659709223526366
Validation loss: 2.747623892745354

Epoch: 5| Step: 7
Training loss: 0.9832536880652898
Validation loss: 2.7441319928197516

Epoch: 5| Step: 8
Training loss: 1.3164024918952524
Validation loss: 2.702090864874452

Epoch: 5| Step: 9
Training loss: 1.8769453765042325
Validation loss: 2.7684615866892166

Epoch: 5| Step: 10
Training loss: 0.757539050918018
Validation loss: 2.7572636080588326

Epoch: 5| Step: 11
Training loss: 1.3781252370129162
Validation loss: 2.749736242216715

Epoch: 245| Step: 0
Training loss: 0.9835495288170757
Validation loss: 2.8211316022619743

Epoch: 5| Step: 1
Training loss: 1.257343560227448
Validation loss: 2.726044821576421

Epoch: 5| Step: 2
Training loss: 1.3108499236288769
Validation loss: 2.7462736082617734

Epoch: 5| Step: 3
Training loss: 1.2497678064221278
Validation loss: 2.7599173268142763

Epoch: 5| Step: 4
Training loss: 1.5779663610511114
Validation loss: 2.745334442491

Epoch: 5| Step: 5
Training loss: 0.9621190815976874
Validation loss: 2.689691138280015

Epoch: 5| Step: 6
Training loss: 0.9609923308321523
Validation loss: 2.704197349335085

Epoch: 5| Step: 7
Training loss: 1.027735298298414
Validation loss: 2.6827410065403

Epoch: 5| Step: 8
Training loss: 1.255688882648614
Validation loss: 2.5958761402007062

Epoch: 5| Step: 9
Training loss: 0.9765606384259601
Validation loss: 2.694554053586414

Epoch: 5| Step: 10
Training loss: 2.057745568788012
Validation loss: 2.7424703779970967

Epoch: 5| Step: 11
Training loss: 1.4991430377776782
Validation loss: 2.6701522761222756

Epoch: 246| Step: 0
Training loss: 2.2703605883048037
Validation loss: 2.6642956188897573

Epoch: 5| Step: 1
Training loss: 1.3108629280495514
Validation loss: 2.671244745857761

Epoch: 5| Step: 2
Training loss: 0.9793039218936631
Validation loss: 2.6953832865832092

Epoch: 5| Step: 3
Training loss: 1.0090136799560752
Validation loss: 2.73324754631709

Epoch: 5| Step: 4
Training loss: 0.8016481498779235
Validation loss: 2.704661283727769

Epoch: 5| Step: 5
Training loss: 1.294814943987707
Validation loss: 2.7597303916948035

Epoch: 5| Step: 6
Training loss: 0.9282109050618926
Validation loss: 2.7629114261769834

Epoch: 5| Step: 7
Training loss: 1.4018670762238228
Validation loss: 2.728156195131211

Epoch: 5| Step: 8
Training loss: 1.3985044154348762
Validation loss: 2.7453944698248307

Epoch: 5| Step: 9
Training loss: 1.4383971690263566
Validation loss: 2.6978393209753126

Epoch: 5| Step: 10
Training loss: 0.9810758436148196
Validation loss: 2.624492783589034

Epoch: 5| Step: 11
Training loss: 1.0572183831034336
Validation loss: 2.690068270852164

Epoch: 247| Step: 0
Training loss: 1.4241229721399102
Validation loss: 2.6914087266915216

Epoch: 5| Step: 1
Training loss: 1.3355138899017653
Validation loss: 2.6789557122275234

Epoch: 5| Step: 2
Training loss: 1.0240539557874935
Validation loss: 2.7508702183667433

Epoch: 5| Step: 3
Training loss: 2.000922109701679
Validation loss: 2.724280877403626

Epoch: 5| Step: 4
Training loss: 1.0912233869840324
Validation loss: 2.755407381469443

Epoch: 5| Step: 5
Training loss: 0.8750544939783126
Validation loss: 2.6995843399602566

Epoch: 5| Step: 6
Training loss: 1.9169136454912699
Validation loss: 2.718495704187691

Epoch: 5| Step: 7
Training loss: 1.0025551457827087
Validation loss: 2.7770585755610866

Epoch: 5| Step: 8
Training loss: 1.140505588499406
Validation loss: 2.7356998322219015

Epoch: 5| Step: 9
Training loss: 0.9894505997364637
Validation loss: 2.740425869918186

Epoch: 5| Step: 10
Training loss: 1.1875195752588354
Validation loss: 2.7056185296171407

Epoch: 5| Step: 11
Training loss: 1.0089268991815765
Validation loss: 2.75370356758557

Epoch: 248| Step: 0
Training loss: 1.0381924421162825
Validation loss: 2.7444499790585866

Epoch: 5| Step: 1
Training loss: 1.1569957905447967
Validation loss: 2.718666316531285

Epoch: 5| Step: 2
Training loss: 1.6087931349632048
Validation loss: 2.7150341049532165

Epoch: 5| Step: 3
Training loss: 1.1105238647438647
Validation loss: 2.6931528921004246

Epoch: 5| Step: 4
Training loss: 1.1543779941720347
Validation loss: 2.6944541043395698

Epoch: 5| Step: 5
Training loss: 1.854150436273182
Validation loss: 2.60189796934879

Epoch: 5| Step: 6
Training loss: 1.7061089789273969
Validation loss: 2.7018555543452587

Epoch: 5| Step: 7
Training loss: 1.183781775719767
Validation loss: 2.672338081221066

Epoch: 5| Step: 8
Training loss: 1.0035925942939472
Validation loss: 2.71887635342991

Epoch: 5| Step: 9
Training loss: 1.2102155933150327
Validation loss: 2.7881515860414137

Epoch: 5| Step: 10
Training loss: 1.3161349144278767
Validation loss: 2.782151236942109

Epoch: 5| Step: 11
Training loss: 0.6123312133689375
Validation loss: 2.814939070008878

Epoch: 249| Step: 0
Training loss: 1.8456886573507048
Validation loss: 2.862170435467279

Epoch: 5| Step: 1
Training loss: 1.024643922224091
Validation loss: 2.8073293557170205

Epoch: 5| Step: 2
Training loss: 1.4225182388289528
Validation loss: 2.7711678526493384

Epoch: 5| Step: 3
Training loss: 1.0541120866861895
Validation loss: 2.732376645422578

Epoch: 5| Step: 4
Training loss: 0.8595293426631201
Validation loss: 2.7132839634533292

Epoch: 5| Step: 5
Training loss: 0.9587876065574
Validation loss: 2.699998109133965

Epoch: 5| Step: 6
Training loss: 1.3782496199196481
Validation loss: 2.713461753317704

Epoch: 5| Step: 7
Training loss: 1.9458418895634062
Validation loss: 2.7198245530250804

Epoch: 5| Step: 8
Training loss: 1.115894876957085
Validation loss: 2.729982521085014

Epoch: 5| Step: 9
Training loss: 1.268509861812667
Validation loss: 2.6746712602955127

Epoch: 5| Step: 10
Training loss: 0.8423186276184591
Validation loss: 2.6648458818755008

Epoch: 5| Step: 11
Training loss: 1.3833453342575945
Validation loss: 2.733257303232054

Epoch: 250| Step: 0
Training loss: 1.2003591377555305
Validation loss: 2.6750358341466964

Epoch: 5| Step: 1
Training loss: 0.8813318985563287
Validation loss: 2.7491460091891207

Epoch: 5| Step: 2
Training loss: 1.378764331635928
Validation loss: 2.8258527335203425

Epoch: 5| Step: 3
Training loss: 0.7970827991093629
Validation loss: 2.72528884965208

Epoch: 5| Step: 4
Training loss: 0.7968912309975763
Validation loss: 2.7602500877261735

Epoch: 5| Step: 5
Training loss: 0.8161372421451906
Validation loss: 2.734269930319493

Epoch: 5| Step: 6
Training loss: 1.3221032002027637
Validation loss: 2.736728679738065

Epoch: 5| Step: 7
Training loss: 1.1588711798058413
Validation loss: 2.78725259221783

Epoch: 5| Step: 8
Training loss: 1.1986374331418344
Validation loss: 2.7357205377341534

Epoch: 5| Step: 9
Training loss: 1.427601694603382
Validation loss: 2.721516507917555

Epoch: 5| Step: 10
Training loss: 2.0517241136124773
Validation loss: 2.6440823811240977

Epoch: 5| Step: 11
Training loss: 1.561496335975924
Validation loss: 2.6754401367762894

Testing loss: 2.3663517119368023
