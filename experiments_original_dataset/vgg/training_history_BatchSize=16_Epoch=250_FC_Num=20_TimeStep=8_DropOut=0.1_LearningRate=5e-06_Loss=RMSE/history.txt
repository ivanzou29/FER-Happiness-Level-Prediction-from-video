Epoch: 1| Step: 0
Training loss: 4.628082073252139
Validation loss: 4.032563145981287

Epoch: 6| Step: 1
Training loss: 4.217302992583056
Validation loss: 4.0127229804871245

Epoch: 6| Step: 2
Training loss: 4.736934159036917
Validation loss: 3.9915285406457754

Epoch: 6| Step: 3
Training loss: 3.9476127943723145
Validation loss: 3.965933654012196

Epoch: 6| Step: 4
Training loss: 4.563904010615827
Validation loss: 3.94246165193829

Epoch: 6| Step: 5
Training loss: 3.6160625908422372
Validation loss: 3.9230859515669754

Epoch: 6| Step: 6
Training loss: 3.158928669268177
Validation loss: 3.9017842515067893

Epoch: 6| Step: 7
Training loss: 3.2670144953410527
Validation loss: 3.877733619976537

Epoch: 6| Step: 8
Training loss: 4.534200615293346
Validation loss: 3.859779614694501

Epoch: 6| Step: 9
Training loss: 4.032742482774352
Validation loss: 3.8407580715515834

Epoch: 6| Step: 10
Training loss: 3.864496824764922
Validation loss: 3.8188025488102046

Epoch: 6| Step: 11
Training loss: 3.703117531555628
Validation loss: 3.798420072343213

Epoch: 6| Step: 12
Training loss: 4.415131404040134
Validation loss: 3.7798661781520186

Epoch: 6| Step: 13
Training loss: 3.18717087187115
Validation loss: 3.7612360363649615

Epoch: 2| Step: 0
Training loss: 3.634131669929526
Validation loss: 3.7404208011497406

Epoch: 6| Step: 1
Training loss: 3.2169025637711446
Validation loss: 3.7178450265973755

Epoch: 6| Step: 2
Training loss: 3.960799656863998
Validation loss: 3.6951558655869783

Epoch: 6| Step: 3
Training loss: 4.224668293408496
Validation loss: 3.6787286738923486

Epoch: 6| Step: 4
Training loss: 3.3378754822469565
Validation loss: 3.654564993594896

Epoch: 6| Step: 5
Training loss: 4.238981436978331
Validation loss: 3.6308827733761153

Epoch: 6| Step: 6
Training loss: 4.176086585904755
Validation loss: 3.611239635593061

Epoch: 6| Step: 7
Training loss: 3.288725412089098
Validation loss: 3.579857164033987

Epoch: 6| Step: 8
Training loss: 2.97421757001881
Validation loss: 3.5612218694445072

Epoch: 6| Step: 9
Training loss: 2.591382796348446
Validation loss: 3.538024008933075

Epoch: 6| Step: 10
Training loss: 4.464744640194827
Validation loss: 3.514472297734031

Epoch: 6| Step: 11
Training loss: 3.5016641747600312
Validation loss: 3.483585695923424

Epoch: 6| Step: 12
Training loss: 4.020808218184124
Validation loss: 3.459076575571304

Epoch: 6| Step: 13
Training loss: 3.718556631494384
Validation loss: 3.4285751543327554

Epoch: 3| Step: 0
Training loss: 2.8581378532569444
Validation loss: 3.3977679298228503

Epoch: 6| Step: 1
Training loss: 3.7615024904574734
Validation loss: 3.370430360589323

Epoch: 6| Step: 2
Training loss: 3.272568908385557
Validation loss: 3.3360355312168943

Epoch: 6| Step: 3
Training loss: 3.2602282744915936
Validation loss: 3.300454196113762

Epoch: 6| Step: 4
Training loss: 3.671377984356298
Validation loss: 3.262166578421444

Epoch: 6| Step: 5
Training loss: 2.9981483467152077
Validation loss: 3.22527001012064

Epoch: 6| Step: 6
Training loss: 3.4544697210233
Validation loss: 3.193626126688384

Epoch: 6| Step: 7
Training loss: 2.8564204392613632
Validation loss: 3.153564065660177

Epoch: 6| Step: 8
Training loss: 3.384103577104112
Validation loss: 3.115925838698717

Epoch: 6| Step: 9
Training loss: 3.094366917608281
Validation loss: 3.0728790065375784

Epoch: 6| Step: 10
Training loss: 3.0086316863357396
Validation loss: 3.0323240337175412

Epoch: 6| Step: 11
Training loss: 2.8399713584637665
Validation loss: 2.9831122478066288

Epoch: 6| Step: 12
Training loss: 3.296921860782193
Validation loss: 2.9431597383125503

Epoch: 6| Step: 13
Training loss: 3.390690394179647
Validation loss: 2.9037711260439405

Epoch: 4| Step: 0
Training loss: 2.748858908681056
Validation loss: 2.8575653575543827

Epoch: 6| Step: 1
Training loss: 2.904064874675785
Validation loss: 2.8197744319423363

Epoch: 6| Step: 2
Training loss: 2.5751243931621612
Validation loss: 2.769252503019752

Epoch: 6| Step: 3
Training loss: 3.0199181233605916
Validation loss: 2.73025290637046

Epoch: 6| Step: 4
Training loss: 3.25563734152189
Validation loss: 2.705329349020739

Epoch: 6| Step: 5
Training loss: 2.834923933512374
Validation loss: 2.6589310074829546

Epoch: 6| Step: 6
Training loss: 2.4064375568961847
Validation loss: 2.636231388215057

Epoch: 6| Step: 7
Training loss: 2.282079780895771
Validation loss: 2.608713123187012

Epoch: 6| Step: 8
Training loss: 2.5576655677160995
Validation loss: 2.606596863105514

Epoch: 6| Step: 9
Training loss: 2.891621186029749
Validation loss: 2.5832817677509436

Epoch: 6| Step: 10
Training loss: 2.4344211598477377
Validation loss: 2.5866705248335284

Epoch: 6| Step: 11
Training loss: 2.749029161572637
Validation loss: 2.592564078078314

Epoch: 6| Step: 12
Training loss: 2.105663283496285
Validation loss: 2.586864055737274

Epoch: 6| Step: 13
Training loss: 2.893295621523634
Validation loss: 2.6013515489985886

Epoch: 5| Step: 0
Training loss: 2.788045574904862
Validation loss: 2.591838484667012

Epoch: 6| Step: 1
Training loss: 2.193779678361335
Validation loss: 2.6035715618453708

Epoch: 6| Step: 2
Training loss: 2.8104321825538463
Validation loss: 2.5981816651973424

Epoch: 6| Step: 3
Training loss: 2.727013405840005
Validation loss: 2.6353283340869247

Epoch: 6| Step: 4
Training loss: 2.9059267582127184
Validation loss: 2.6386135799840256

Epoch: 6| Step: 5
Training loss: 1.8109657765930003
Validation loss: 2.650713307568377

Epoch: 6| Step: 6
Training loss: 2.4332702323709703
Validation loss: 2.6361042728967363

Epoch: 6| Step: 7
Training loss: 2.6238324429815965
Validation loss: 2.6137760228072215

Epoch: 6| Step: 8
Training loss: 2.6868772450535534
Validation loss: 2.639722048981697

Epoch: 6| Step: 9
Training loss: 2.198816943686596
Validation loss: 2.6287125794339232

Epoch: 6| Step: 10
Training loss: 2.6708662125284057
Validation loss: 2.6069900669483728

Epoch: 6| Step: 11
Training loss: 2.5293423092565033
Validation loss: 2.6127299139163083

Epoch: 6| Step: 12
Training loss: 2.982285971752134
Validation loss: 2.602863967587562

Epoch: 6| Step: 13
Training loss: 2.5941161850885326
Validation loss: 2.620966491793578

Epoch: 6| Step: 0
Training loss: 2.6289496000210204
Validation loss: 2.6059899978787304

Epoch: 6| Step: 1
Training loss: 2.662271115489669
Validation loss: 2.5777979633712054

Epoch: 6| Step: 2
Training loss: 2.2981785818352645
Validation loss: 2.5761957213267226

Epoch: 6| Step: 3
Training loss: 2.6159595854317597
Validation loss: 2.5832498342083956

Epoch: 6| Step: 4
Training loss: 1.750703465896935
Validation loss: 2.574249267397233

Epoch: 6| Step: 5
Training loss: 2.091944585120934
Validation loss: 2.5610711603388525

Epoch: 6| Step: 6
Training loss: 2.860996974491465
Validation loss: 2.590904337046134

Epoch: 6| Step: 7
Training loss: 2.8960335934413504
Validation loss: 2.5821987449810178

Epoch: 6| Step: 8
Training loss: 2.8314204958343714
Validation loss: 2.570810534491035

Epoch: 6| Step: 9
Training loss: 1.7812663295064275
Validation loss: 2.5667787046461323

Epoch: 6| Step: 10
Training loss: 2.4245962298383996
Validation loss: 2.5714234769609234

Epoch: 6| Step: 11
Training loss: 3.269965832266364
Validation loss: 2.5670219159024787

Epoch: 6| Step: 12
Training loss: 2.4338270048039043
Validation loss: 2.562311522212551

Epoch: 6| Step: 13
Training loss: 2.5521927998220235
Validation loss: 2.574418534363569

Epoch: 7| Step: 0
Training loss: 2.770649801117884
Validation loss: 2.565079700850302

Epoch: 6| Step: 1
Training loss: 2.3536511647304104
Validation loss: 2.568291871860268

Epoch: 6| Step: 2
Training loss: 2.6371247155646422
Validation loss: 2.556704690129088

Epoch: 6| Step: 3
Training loss: 2.7285289941568047
Validation loss: 2.56574491963247

Epoch: 6| Step: 4
Training loss: 2.1487744986051265
Validation loss: 2.5782798027033125

Epoch: 6| Step: 5
Training loss: 2.2857697535494372
Validation loss: 2.570172987285158

Epoch: 6| Step: 6
Training loss: 2.4899954886950946
Validation loss: 2.5557174861670324

Epoch: 6| Step: 7
Training loss: 2.7231886136633903
Validation loss: 2.577453618339931

Epoch: 6| Step: 8
Training loss: 2.8333116044351967
Validation loss: 2.5576627401242824

Epoch: 6| Step: 9
Training loss: 2.775226714349665
Validation loss: 2.5613134164500817

Epoch: 6| Step: 10
Training loss: 2.654174262913763
Validation loss: 2.556965114982619

Epoch: 6| Step: 11
Training loss: 2.2558215381702413
Validation loss: 2.5644146813956104

Epoch: 6| Step: 12
Training loss: 2.6290963318168195
Validation loss: 2.574488439021673

Epoch: 6| Step: 13
Training loss: 2.1861507069115977
Validation loss: 2.549196647807763

Epoch: 8| Step: 0
Training loss: 3.0090015785768425
Validation loss: 2.5479458311028025

Epoch: 6| Step: 1
Training loss: 2.3901130277649933
Validation loss: 2.5452757262712753

Epoch: 6| Step: 2
Training loss: 2.3732393665499445
Validation loss: 2.5650420721964897

Epoch: 6| Step: 3
Training loss: 2.145517813685725
Validation loss: 2.554826909576801

Epoch: 6| Step: 4
Training loss: 2.9832253363755097
Validation loss: 2.569072683320587

Epoch: 6| Step: 5
Training loss: 2.01200529853927
Validation loss: 2.56958586558508

Epoch: 6| Step: 6
Training loss: 2.5465118523753882
Validation loss: 2.556030433757166

Epoch: 6| Step: 7
Training loss: 2.4110103929913502
Validation loss: 2.559248373138605

Epoch: 6| Step: 8
Training loss: 2.335021997384925
Validation loss: 2.570506651868699

Epoch: 6| Step: 9
Training loss: 2.741174929348022
Validation loss: 2.5586906900071593

Epoch: 6| Step: 10
Training loss: 2.339892761022855
Validation loss: 2.571658785798249

Epoch: 6| Step: 11
Training loss: 2.65726523351937
Validation loss: 2.5622018314969917

Epoch: 6| Step: 12
Training loss: 2.6354796712428232
Validation loss: 2.55550081486976

Epoch: 6| Step: 13
Training loss: 2.8039503908761705
Validation loss: 2.5788996062626044

Epoch: 9| Step: 0
Training loss: 2.5009082098173625
Validation loss: 2.544450538143022

Epoch: 6| Step: 1
Training loss: 2.452496490631548
Validation loss: 2.5480982177464657

Epoch: 6| Step: 2
Training loss: 3.08498010390928
Validation loss: 2.5457917700671726

Epoch: 6| Step: 3
Training loss: 2.749446899972397
Validation loss: 2.568078891924806

Epoch: 6| Step: 4
Training loss: 2.8146457540017393
Validation loss: 2.552572450023708

Epoch: 6| Step: 5
Training loss: 2.446502785854753
Validation loss: 2.5376732414752037

Epoch: 6| Step: 6
Training loss: 2.015783141090707
Validation loss: 2.5557761638438614

Epoch: 6| Step: 7
Training loss: 1.6919270125624872
Validation loss: 2.549232795716386

Epoch: 6| Step: 8
Training loss: 2.6322154831262154
Validation loss: 2.5366767982434304

Epoch: 6| Step: 9
Training loss: 3.0877643055084483
Validation loss: 2.5507472115349095

Epoch: 6| Step: 10
Training loss: 2.3554373718499755
Validation loss: 2.539893365533972

Epoch: 6| Step: 11
Training loss: 2.7197967794178646
Validation loss: 2.548251086476048

Epoch: 6| Step: 12
Training loss: 2.2988457561584923
Validation loss: 2.5443979164540194

Epoch: 6| Step: 13
Training loss: 2.338389866807811
Validation loss: 2.550983695486161

Epoch: 10| Step: 0
Training loss: 2.379252391368662
Validation loss: 2.544849284442748

Epoch: 6| Step: 1
Training loss: 2.361963733985783
Validation loss: 2.545587990692594

Epoch: 6| Step: 2
Training loss: 2.7133736781120903
Validation loss: 2.5469862088690127

Epoch: 6| Step: 3
Training loss: 2.184010911103824
Validation loss: 2.5540307899248185

Epoch: 6| Step: 4
Training loss: 2.249652835765938
Validation loss: 2.537594649705983

Epoch: 6| Step: 5
Training loss: 2.8339672127538575
Validation loss: 2.5667716607586493

Epoch: 6| Step: 6
Training loss: 2.3420757162688153
Validation loss: 2.5574598134085127

Epoch: 6| Step: 7
Training loss: 2.4812094235885924
Validation loss: 2.5611165041348416

Epoch: 6| Step: 8
Training loss: 2.0936368086095416
Validation loss: 2.5553608667001817

Epoch: 6| Step: 9
Training loss: 2.70188063716896
Validation loss: 2.5619489340883166

Epoch: 6| Step: 10
Training loss: 2.765054762506639
Validation loss: 2.5646057548338197

Epoch: 6| Step: 11
Training loss: 2.7254368773061275
Validation loss: 2.574204494531394

Epoch: 6| Step: 12
Training loss: 2.890900469876713
Validation loss: 2.560387818619124

Epoch: 6| Step: 13
Training loss: 2.4875553335811795
Validation loss: 2.5556660138206433

Epoch: 11| Step: 0
Training loss: 2.4262458982830957
Validation loss: 2.5511798790567783

Epoch: 6| Step: 1
Training loss: 2.7259011764581484
Validation loss: 2.551395795943504

Epoch: 6| Step: 2
Training loss: 2.220099562568874
Validation loss: 2.5313371243023592

Epoch: 6| Step: 3
Training loss: 2.4191546513172213
Validation loss: 2.5400150175226366

Epoch: 6| Step: 4
Training loss: 2.6453319785431244
Validation loss: 2.5401788849303273

Epoch: 6| Step: 5
Training loss: 2.4824262929617453
Validation loss: 2.53925088819347

Epoch: 6| Step: 6
Training loss: 3.048283491052184
Validation loss: 2.5493909114619484

Epoch: 6| Step: 7
Training loss: 1.9879824070909984
Validation loss: 2.535995054659349

Epoch: 6| Step: 8
Training loss: 2.126436421218633
Validation loss: 2.5456341332036763

Epoch: 6| Step: 9
Training loss: 2.5122029978253577
Validation loss: 2.5357106469100743

Epoch: 6| Step: 10
Training loss: 2.599155263122545
Validation loss: 2.539333450336742

Epoch: 6| Step: 11
Training loss: 3.0547908365473586
Validation loss: 2.5342005107124574

Epoch: 6| Step: 12
Training loss: 2.6035166323317163
Validation loss: 2.547462099271934

Epoch: 6| Step: 13
Training loss: 2.309993209994026
Validation loss: 2.5356045930458255

Epoch: 12| Step: 0
Training loss: 2.499392149461699
Validation loss: 2.5349349369575447

Epoch: 6| Step: 1
Training loss: 2.3129676139863284
Validation loss: 2.5321189895771723

Epoch: 6| Step: 2
Training loss: 2.3218154920137555
Validation loss: 2.523430539841004

Epoch: 6| Step: 3
Training loss: 2.3733769944636105
Validation loss: 2.5326189491577877

Epoch: 6| Step: 4
Training loss: 2.370699753934104
Validation loss: 2.5390801844836868

Epoch: 6| Step: 5
Training loss: 2.7399774323529504
Validation loss: 2.5349119251859444

Epoch: 6| Step: 6
Training loss: 1.5914649289623657
Validation loss: 2.5350376722507355

Epoch: 6| Step: 7
Training loss: 2.750635767185154
Validation loss: 2.537620729790853

Epoch: 6| Step: 8
Training loss: 2.9925052484069536
Validation loss: 2.542892845571863

Epoch: 6| Step: 9
Training loss: 2.0648338522585448
Validation loss: 2.550078516729952

Epoch: 6| Step: 10
Training loss: 2.919937878823199
Validation loss: 2.5307861499660826

Epoch: 6| Step: 11
Training loss: 2.926929365749191
Validation loss: 2.5490896195582518

Epoch: 6| Step: 12
Training loss: 2.093977047580383
Validation loss: 2.553976716409158

Epoch: 6| Step: 13
Training loss: 2.8189267798769833
Validation loss: 2.54491565281031

Epoch: 13| Step: 0
Training loss: 2.774427210485609
Validation loss: 2.524283236883449

Epoch: 6| Step: 1
Training loss: 2.54872036410132
Validation loss: 2.5290045177720537

Epoch: 6| Step: 2
Training loss: 3.381827477519739
Validation loss: 2.5305363312274953

Epoch: 6| Step: 3
Training loss: 2.6702626142758352
Validation loss: 2.534446440605854

Epoch: 6| Step: 4
Training loss: 2.8429025917500583
Validation loss: 2.5404507641795258

Epoch: 6| Step: 5
Training loss: 1.5918022670537508
Validation loss: 2.5300204583548354

Epoch: 6| Step: 6
Training loss: 2.313566838150003
Validation loss: 2.5270021690255686

Epoch: 6| Step: 7
Training loss: 2.0651323108911974
Validation loss: 2.5224705704660035

Epoch: 6| Step: 8
Training loss: 2.1040285524671876
Validation loss: 2.531185274905702

Epoch: 6| Step: 9
Training loss: 2.1183227648447653
Validation loss: 2.5290490459846464

Epoch: 6| Step: 10
Training loss: 2.561989896291305
Validation loss: 2.533698824400355

Epoch: 6| Step: 11
Training loss: 2.217697538675388
Validation loss: 2.5187217338496786

Epoch: 6| Step: 12
Training loss: 2.814450075358341
Validation loss: 2.5223908985086254

Epoch: 6| Step: 13
Training loss: 2.634006399339507
Validation loss: 2.5405913616235463

Epoch: 14| Step: 0
Training loss: 2.2443541582075186
Validation loss: 2.5201768309247354

Epoch: 6| Step: 1
Training loss: 2.8655655350334057
Validation loss: 2.5308570556818406

Epoch: 6| Step: 2
Training loss: 2.705781986919139
Validation loss: 2.5296905171983273

Epoch: 6| Step: 3
Training loss: 2.573691793175427
Validation loss: 2.536076876699527

Epoch: 6| Step: 4
Training loss: 2.9701820533519006
Validation loss: 2.5283767656566023

Epoch: 6| Step: 5
Training loss: 2.5465935861710327
Validation loss: 2.526977779849782

Epoch: 6| Step: 6
Training loss: 2.193955188512669
Validation loss: 2.5310847774004097

Epoch: 6| Step: 7
Training loss: 2.526632170462668
Validation loss: 2.514632098197321

Epoch: 6| Step: 8
Training loss: 2.2729743407077048
Validation loss: 2.5235058880525583

Epoch: 6| Step: 9
Training loss: 2.281351270126172
Validation loss: 2.5273855560634204

Epoch: 6| Step: 10
Training loss: 2.9628928781097232
Validation loss: 2.5294572109231

Epoch: 6| Step: 11
Training loss: 2.2168624801002585
Validation loss: 2.5307470771787495

Epoch: 6| Step: 12
Training loss: 2.076154534742086
Validation loss: 2.5164255483543236

Epoch: 6| Step: 13
Training loss: 2.340493852228746
Validation loss: 2.5297527987318946

Epoch: 15| Step: 0
Training loss: 2.509685921794978
Validation loss: 2.5115030056621985

Epoch: 6| Step: 1
Training loss: 2.3245543678376728
Validation loss: 2.5355321510446522

Epoch: 6| Step: 2
Training loss: 2.7151448693448277
Validation loss: 2.5243754184108966

Epoch: 6| Step: 3
Training loss: 2.685363097405039
Validation loss: 2.519149538445257

Epoch: 6| Step: 4
Training loss: 2.7871536860856523
Validation loss: 2.526291515670478

Epoch: 6| Step: 5
Training loss: 2.249836809810073
Validation loss: 2.5228674434665943

Epoch: 6| Step: 6
Training loss: 2.1959147323007886
Validation loss: 2.5216310725837934

Epoch: 6| Step: 7
Training loss: 2.585429530658631
Validation loss: 2.518782283049145

Epoch: 6| Step: 8
Training loss: 2.2290596862030774
Validation loss: 2.5238664103126562

Epoch: 6| Step: 9
Training loss: 2.287365906334015
Validation loss: 2.52645704387075

Epoch: 6| Step: 10
Training loss: 2.5768953107264267
Validation loss: 2.517473919558805

Epoch: 6| Step: 11
Training loss: 2.2677275274115987
Validation loss: 2.5378422548588153

Epoch: 6| Step: 12
Training loss: 2.5425501887676365
Validation loss: 2.516828261065308

Epoch: 6| Step: 13
Training loss: 2.9565903449574322
Validation loss: 2.528946554502887

Epoch: 16| Step: 0
Training loss: 2.8709934346845785
Validation loss: 2.5276754280534446

Epoch: 6| Step: 1
Training loss: 2.521796953962424
Validation loss: 2.5178626239823885

Epoch: 6| Step: 2
Training loss: 2.3058854432646294
Validation loss: 2.5310520675570656

Epoch: 6| Step: 3
Training loss: 2.4925335013109593
Validation loss: 2.5234894486346486

Epoch: 6| Step: 4
Training loss: 2.5597738325527946
Validation loss: 2.5164314856966814

Epoch: 6| Step: 5
Training loss: 2.410048026401754
Validation loss: 2.512624439871332

Epoch: 6| Step: 6
Training loss: 2.3569305084821583
Validation loss: 2.5202450630702953

Epoch: 6| Step: 7
Training loss: 3.0598431954692344
Validation loss: 2.522741074020537

Epoch: 6| Step: 8
Training loss: 2.369925347774106
Validation loss: 2.5163860709877386

Epoch: 6| Step: 9
Training loss: 2.6077203129770052
Validation loss: 2.5119714683959447

Epoch: 6| Step: 10
Training loss: 1.967018577103968
Validation loss: 2.5066474117476285

Epoch: 6| Step: 11
Training loss: 2.189533922948821
Validation loss: 2.4959185662679215

Epoch: 6| Step: 12
Training loss: 2.5634452193024337
Validation loss: 2.5203788100599156

Epoch: 6| Step: 13
Training loss: 2.507480397323705
Validation loss: 2.5171229481485784

Epoch: 17| Step: 0
Training loss: 2.1867101060615375
Validation loss: 2.499775598309412

Epoch: 6| Step: 1
Training loss: 2.871459605463414
Validation loss: 2.4974806011771595

Epoch: 6| Step: 2
Training loss: 2.5623217264826215
Validation loss: 2.512636103193766

Epoch: 6| Step: 3
Training loss: 2.690739475699278
Validation loss: 2.512890326449863

Epoch: 6| Step: 4
Training loss: 2.6155193421456824
Validation loss: 2.4991743154770165

Epoch: 6| Step: 5
Training loss: 2.3259077330548448
Validation loss: 2.5198355399816244

Epoch: 6| Step: 6
Training loss: 1.9663238107998533
Validation loss: 2.5042912052899395

Epoch: 6| Step: 7
Training loss: 1.99842200015979
Validation loss: 2.519980819770441

Epoch: 6| Step: 8
Training loss: 2.552358703289243
Validation loss: 2.5015419178643556

Epoch: 6| Step: 9
Training loss: 2.805813449131664
Validation loss: 2.510043363133268

Epoch: 6| Step: 10
Training loss: 3.133937110625306
Validation loss: 2.5058050152221214

Epoch: 6| Step: 11
Training loss: 1.9554802083842961
Validation loss: 2.5149176256607393

Epoch: 6| Step: 12
Training loss: 2.3382378418344385
Validation loss: 2.51868033616473

Epoch: 6| Step: 13
Training loss: 2.707739799214737
Validation loss: 2.4960559489890652

Epoch: 18| Step: 0
Training loss: 2.662886463468125
Validation loss: 2.510501263935536

Epoch: 6| Step: 1
Training loss: 2.4013450469508504
Validation loss: 2.503845864776405

Epoch: 6| Step: 2
Training loss: 2.599668987917639
Validation loss: 2.507622669042741

Epoch: 6| Step: 3
Training loss: 2.410820323892728
Validation loss: 2.498226402896318

Epoch: 6| Step: 4
Training loss: 2.9001260861577713
Validation loss: 2.4909225330821196

Epoch: 6| Step: 5
Training loss: 2.3725213618869407
Validation loss: 2.5015443085218108

Epoch: 6| Step: 6
Training loss: 2.7083629508722105
Validation loss: 2.5068757396193795

Epoch: 6| Step: 7
Training loss: 2.3408480162367717
Validation loss: 2.5077235918139924

Epoch: 6| Step: 8
Training loss: 2.562257336547484
Validation loss: 2.5059979331841946

Epoch: 6| Step: 9
Training loss: 2.3611006331367124
Validation loss: 2.5059648879590948

Epoch: 6| Step: 10
Training loss: 2.4908049285109684
Validation loss: 2.497128633771126

Epoch: 6| Step: 11
Training loss: 2.127950863428653
Validation loss: 2.4939206274516126

Epoch: 6| Step: 12
Training loss: 2.573525041528405
Validation loss: 2.49892173402123

Epoch: 6| Step: 13
Training loss: 1.956172244443165
Validation loss: 2.4986188570243795

Epoch: 19| Step: 0
Training loss: 1.7930670152385477
Validation loss: 2.487058553710171

Epoch: 6| Step: 1
Training loss: 2.4833005105053383
Validation loss: 2.5025489369681404

Epoch: 6| Step: 2
Training loss: 2.90105342805534
Validation loss: 2.503005176586082

Epoch: 6| Step: 3
Training loss: 2.668013967463179
Validation loss: 2.515943155645204

Epoch: 6| Step: 4
Training loss: 2.633333420652879
Validation loss: 2.524903649987777

Epoch: 6| Step: 5
Training loss: 2.4182822866943487
Validation loss: 2.5192629018210106

Epoch: 6| Step: 6
Training loss: 1.8855976699300037
Validation loss: 2.500508034266874

Epoch: 6| Step: 7
Training loss: 2.1865918045293706
Validation loss: 2.4988542474396347

Epoch: 6| Step: 8
Training loss: 2.2010730900637383
Validation loss: 2.488811011340123

Epoch: 6| Step: 9
Training loss: 2.880716362975712
Validation loss: 2.4995049940236016

Epoch: 6| Step: 10
Training loss: 2.3796827430201652
Validation loss: 2.4981994820896976

Epoch: 6| Step: 11
Training loss: 2.3277085719092385
Validation loss: 2.501338973692565

Epoch: 6| Step: 12
Training loss: 2.3149754445893187
Validation loss: 2.485287113016067

Epoch: 6| Step: 13
Training loss: 3.1229528206600174
Validation loss: 2.4903900775976036

Epoch: 20| Step: 0
Training loss: 2.788443103901363
Validation loss: 2.497595966316793

Epoch: 6| Step: 1
Training loss: 2.2694144292761163
Validation loss: 2.490782386468913

Epoch: 6| Step: 2
Training loss: 2.5524605193339993
Validation loss: 2.511012340380629

Epoch: 6| Step: 3
Training loss: 1.8487359857963015
Validation loss: 2.499062823429574

Epoch: 6| Step: 4
Training loss: 2.0129585075517578
Validation loss: 2.5046387551669556

Epoch: 6| Step: 5
Training loss: 2.1702877254733606
Validation loss: 2.492249857761163

Epoch: 6| Step: 6
Training loss: 3.16865383506385
Validation loss: 2.5010997419646372

Epoch: 6| Step: 7
Training loss: 2.7537582033011785
Validation loss: 2.4980769867681576

Epoch: 6| Step: 8
Training loss: 2.562709055490787
Validation loss: 2.489624499269268

Epoch: 6| Step: 9
Training loss: 2.2972245761296017
Validation loss: 2.4953604085069787

Epoch: 6| Step: 10
Training loss: 2.8906032252135945
Validation loss: 2.4984599774279768

Epoch: 6| Step: 11
Training loss: 2.082770754831505
Validation loss: 2.4966396158770636

Epoch: 6| Step: 12
Training loss: 1.8302977602161474
Validation loss: 2.4833356334581755

Epoch: 6| Step: 13
Training loss: 2.806960690909743
Validation loss: 2.4883257963224383

Epoch: 21| Step: 0
Training loss: 2.079290307088537
Validation loss: 2.4855072991941776

Epoch: 6| Step: 1
Training loss: 2.768281339845733
Validation loss: 2.4866705631433526

Epoch: 6| Step: 2
Training loss: 2.348102546200733
Validation loss: 2.490186679358396

Epoch: 6| Step: 3
Training loss: 2.16546034854443
Validation loss: 2.4957388962427935

Epoch: 6| Step: 4
Training loss: 2.2654884034118674
Validation loss: 2.4800114728293075

Epoch: 6| Step: 5
Training loss: 1.9712450475152792
Validation loss: 2.4961733937181014

Epoch: 6| Step: 6
Training loss: 2.126284043063652
Validation loss: 2.486579556673722

Epoch: 6| Step: 7
Training loss: 2.6808236163240617
Validation loss: 2.4880875013487116

Epoch: 6| Step: 8
Training loss: 3.1644491830652215
Validation loss: 2.4842554699435517

Epoch: 6| Step: 9
Training loss: 2.316850539212883
Validation loss: 2.475470493692217

Epoch: 6| Step: 10
Training loss: 2.083610694224199
Validation loss: 2.4840431231627065

Epoch: 6| Step: 11
Training loss: 2.646137510421569
Validation loss: 2.4827728863695424

Epoch: 6| Step: 12
Training loss: 2.6505764676116663
Validation loss: 2.479127536325961

Epoch: 6| Step: 13
Training loss: 3.047662095350553
Validation loss: 2.494600998846885

Epoch: 22| Step: 0
Training loss: 2.39615435453674
Validation loss: 2.501746553047291

Epoch: 6| Step: 1
Training loss: 2.772469365025497
Validation loss: 2.5013919054961975

Epoch: 6| Step: 2
Training loss: 2.9975938684625274
Validation loss: 2.522646367603145

Epoch: 6| Step: 3
Training loss: 1.971797098836671
Validation loss: 2.490058842873986

Epoch: 6| Step: 4
Training loss: 2.211369233051707
Validation loss: 2.49082530072592

Epoch: 6| Step: 5
Training loss: 2.8708976003893603
Validation loss: 2.494043167588044

Epoch: 6| Step: 6
Training loss: 2.3515945381694188
Validation loss: 2.487880017695248

Epoch: 6| Step: 7
Training loss: 2.8182849305829905
Validation loss: 2.4824943862037148

Epoch: 6| Step: 8
Training loss: 2.0733992687342906
Validation loss: 2.4743396237664386

Epoch: 6| Step: 9
Training loss: 2.016150472588516
Validation loss: 2.489754025873772

Epoch: 6| Step: 10
Training loss: 2.5797796314961707
Validation loss: 2.4723102474138576

Epoch: 6| Step: 11
Training loss: 2.5545224944322857
Validation loss: 2.477849744123218

Epoch: 6| Step: 12
Training loss: 2.458060675118142
Validation loss: 2.485729863742294

Epoch: 6| Step: 13
Training loss: 2.335312979917759
Validation loss: 2.4710747118978427

Epoch: 23| Step: 0
Training loss: 2.403896518473102
Validation loss: 2.4827742627870304

Epoch: 6| Step: 1
Training loss: 2.7496412216577193
Validation loss: 2.4856431551430043

Epoch: 6| Step: 2
Training loss: 2.6659178775292807
Validation loss: 2.490541127578379

Epoch: 6| Step: 3
Training loss: 1.7457520835500207
Validation loss: 2.494218291863491

Epoch: 6| Step: 4
Training loss: 1.938219613598606
Validation loss: 2.482420978601005

Epoch: 6| Step: 5
Training loss: 2.485056657663337
Validation loss: 2.5096172996458974

Epoch: 6| Step: 6
Training loss: 2.567018758065522
Validation loss: 2.505337104475111

Epoch: 6| Step: 7
Training loss: 2.385791354896551
Validation loss: 2.5191504060012444

Epoch: 6| Step: 8
Training loss: 3.046962638963955
Validation loss: 2.5229284916754713

Epoch: 6| Step: 9
Training loss: 2.949717983408011
Validation loss: 2.4902008971912264

Epoch: 6| Step: 10
Training loss: 2.168789654899642
Validation loss: 2.4912765895038946

Epoch: 6| Step: 11
Training loss: 2.7176123683406552
Validation loss: 2.501891191734937

Epoch: 6| Step: 12
Training loss: 2.1567480645401553
Validation loss: 2.495283294742506

Epoch: 6| Step: 13
Training loss: 2.259783666434841
Validation loss: 2.4764625697627727

Epoch: 24| Step: 0
Training loss: 2.2739326488414924
Validation loss: 2.472362289913693

Epoch: 6| Step: 1
Training loss: 2.7490148513686963
Validation loss: 2.490173769942672

Epoch: 6| Step: 2
Training loss: 2.3812358705597045
Validation loss: 2.482701687733621

Epoch: 6| Step: 3
Training loss: 2.4365542606705173
Validation loss: 2.4860837646012763

Epoch: 6| Step: 4
Training loss: 2.1213311331254223
Validation loss: 2.47657971621846

Epoch: 6| Step: 5
Training loss: 2.7614097584227433
Validation loss: 2.4731906757273774

Epoch: 6| Step: 6
Training loss: 1.537047718173546
Validation loss: 2.4790629570904197

Epoch: 6| Step: 7
Training loss: 2.396276836533527
Validation loss: 2.4838861348345382

Epoch: 6| Step: 8
Training loss: 3.018618664145302
Validation loss: 2.4637578394903974

Epoch: 6| Step: 9
Training loss: 2.0027154131788376
Validation loss: 2.4683266932698467

Epoch: 6| Step: 10
Training loss: 2.737974228564202
Validation loss: 2.464537442818147

Epoch: 6| Step: 11
Training loss: 2.7399613345682816
Validation loss: 2.4880354044706303

Epoch: 6| Step: 12
Training loss: 2.2432975546641614
Validation loss: 2.486734033989644

Epoch: 6| Step: 13
Training loss: 2.370206211148709
Validation loss: 2.4718397740017446

Epoch: 25| Step: 0
Training loss: 2.570853967650796
Validation loss: 2.4737100309278857

Epoch: 6| Step: 1
Training loss: 2.6687026794669433
Validation loss: 2.4727094743975466

Epoch: 6| Step: 2
Training loss: 2.771502698390142
Validation loss: 2.4920418277208003

Epoch: 6| Step: 3
Training loss: 2.40263670088823
Validation loss: 2.4773364858241123

Epoch: 6| Step: 4
Training loss: 1.996836425217631
Validation loss: 2.476737384257157

Epoch: 6| Step: 5
Training loss: 2.7632627582012206
Validation loss: 2.4704807829797555

Epoch: 6| Step: 6
Training loss: 2.0359068088750596
Validation loss: 2.490124573125618

Epoch: 6| Step: 7
Training loss: 2.780728151890799
Validation loss: 2.4864260606039066

Epoch: 6| Step: 8
Training loss: 2.472727890543682
Validation loss: 2.504715128758334

Epoch: 6| Step: 9
Training loss: 2.3625204579915726
Validation loss: 2.486233094370324

Epoch: 6| Step: 10
Training loss: 2.32283145309182
Validation loss: 2.479355129056218

Epoch: 6| Step: 11
Training loss: 2.320088899158823
Validation loss: 2.4840531210642913

Epoch: 6| Step: 12
Training loss: 2.4585234897151587
Validation loss: 2.4785383748001677

Epoch: 6| Step: 13
Training loss: 2.144513017198221
Validation loss: 2.477783207134272

Epoch: 26| Step: 0
Training loss: 2.0761702673000597
Validation loss: 2.4752031159461674

Epoch: 6| Step: 1
Training loss: 2.540614384515223
Validation loss: 2.454922513600043

Epoch: 6| Step: 2
Training loss: 3.271359314307382
Validation loss: 2.484185873386269

Epoch: 6| Step: 3
Training loss: 2.1017193930675058
Validation loss: 2.467235511085547

Epoch: 6| Step: 4
Training loss: 3.174777201847725
Validation loss: 2.4735033814907252

Epoch: 6| Step: 5
Training loss: 2.638865590132094
Validation loss: 2.4557012001513634

Epoch: 6| Step: 6
Training loss: 2.41805177216365
Validation loss: 2.4617484396505396

Epoch: 6| Step: 7
Training loss: 2.252586150051385
Validation loss: 2.4674867705789585

Epoch: 6| Step: 8
Training loss: 2.1442419527518153
Validation loss: 2.4730322673958494

Epoch: 6| Step: 9
Training loss: 2.3192127845593378
Validation loss: 2.464648771559316

Epoch: 6| Step: 10
Training loss: 2.1736979347034926
Validation loss: 2.465351662998682

Epoch: 6| Step: 11
Training loss: 2.0964289365588473
Validation loss: 2.466400605965473

Epoch: 6| Step: 12
Training loss: 2.6487254658562374
Validation loss: 2.469894473862867

Epoch: 6| Step: 13
Training loss: 2.005675726249377
Validation loss: 2.4729838864821776

Epoch: 27| Step: 0
Training loss: 2.812391745285314
Validation loss: 2.477339774018009

Epoch: 6| Step: 1
Training loss: 2.155750825018483
Validation loss: 2.475383457829411

Epoch: 6| Step: 2
Training loss: 2.474869110037217
Validation loss: 2.4607563739303795

Epoch: 6| Step: 3
Training loss: 2.346917618569005
Validation loss: 2.473869921794333

Epoch: 6| Step: 4
Training loss: 2.0020374410598003
Validation loss: 2.454482251802828

Epoch: 6| Step: 5
Training loss: 2.269289197505259
Validation loss: 2.472173465886146

Epoch: 6| Step: 6
Training loss: 2.4298780556681194
Validation loss: 2.4667614360165486

Epoch: 6| Step: 7
Training loss: 2.9400711170340377
Validation loss: 2.487309336423929

Epoch: 6| Step: 8
Training loss: 1.718654144388475
Validation loss: 2.476214812669179

Epoch: 6| Step: 9
Training loss: 2.015754636395608
Validation loss: 2.481034438140621

Epoch: 6| Step: 10
Training loss: 3.1690995424236896
Validation loss: 2.4822986811321197

Epoch: 6| Step: 11
Training loss: 1.9324773474743726
Validation loss: 2.487912696201025

Epoch: 6| Step: 12
Training loss: 2.4704068575457527
Validation loss: 2.484137421770355

Epoch: 6| Step: 13
Training loss: 2.8546037733706395
Validation loss: 2.4809988021212166

Epoch: 28| Step: 0
Training loss: 2.8616054153182118
Validation loss: 2.466145570158147

Epoch: 6| Step: 1
Training loss: 2.7705840569897355
Validation loss: 2.4612396539148085

Epoch: 6| Step: 2
Training loss: 2.2662426336876758
Validation loss: 2.4636668092155323

Epoch: 6| Step: 3
Training loss: 2.955617992758234
Validation loss: 2.468512487454477

Epoch: 6| Step: 4
Training loss: 1.6989287030200992
Validation loss: 2.462648174584953

Epoch: 6| Step: 5
Training loss: 2.366882606737894
Validation loss: 2.470394094085984

Epoch: 6| Step: 6
Training loss: 1.9746800078937954
Validation loss: 2.461900456053113

Epoch: 6| Step: 7
Training loss: 2.0817503319148263
Validation loss: 2.4507024672701716

Epoch: 6| Step: 8
Training loss: 2.7399754310118967
Validation loss: 2.464991601861314

Epoch: 6| Step: 9
Training loss: 2.527088559222079
Validation loss: 2.454950556428741

Epoch: 6| Step: 10
Training loss: 2.531063967803372
Validation loss: 2.4556272181482055

Epoch: 6| Step: 11
Training loss: 2.508460985993107
Validation loss: 2.461196239937594

Epoch: 6| Step: 12
Training loss: 2.1083862247793586
Validation loss: 2.46106692988013

Epoch: 6| Step: 13
Training loss: 2.2491012473649197
Validation loss: 2.4716684016373613

Epoch: 29| Step: 0
Training loss: 2.1878969104896546
Validation loss: 2.471771676612406

Epoch: 6| Step: 1
Training loss: 2.6440322833492536
Validation loss: 2.458401151034169

Epoch: 6| Step: 2
Training loss: 2.8350401580496007
Validation loss: 2.4782584046626304

Epoch: 6| Step: 3
Training loss: 1.9848937910862385
Validation loss: 2.4871201134065384

Epoch: 6| Step: 4
Training loss: 2.7007578810435864
Validation loss: 2.4941813625672142

Epoch: 6| Step: 5
Training loss: 2.205231869847813
Validation loss: 2.4941666257454456

Epoch: 6| Step: 6
Training loss: 2.905046603539742
Validation loss: 2.493227144910828

Epoch: 6| Step: 7
Training loss: 2.379813286004832
Validation loss: 2.4803773878197832

Epoch: 6| Step: 8
Training loss: 2.2264785483076674
Validation loss: 2.487722480831027

Epoch: 6| Step: 9
Training loss: 2.7089130857035624
Validation loss: 2.4825844059962825

Epoch: 6| Step: 10
Training loss: 2.444672912218646
Validation loss: 2.469135157804346

Epoch: 6| Step: 11
Training loss: 1.9418921371111404
Validation loss: 2.4617672121989314

Epoch: 6| Step: 12
Training loss: 2.3998687151922895
Validation loss: 2.453919478458413

Epoch: 6| Step: 13
Training loss: 2.2760033040483623
Validation loss: 2.4631363909700856

Epoch: 30| Step: 0
Training loss: 2.669311900249386
Validation loss: 2.4719979533317678

Epoch: 6| Step: 1
Training loss: 2.9324851550989117
Validation loss: 2.461944922869519

Epoch: 6| Step: 2
Training loss: 2.288720427592394
Validation loss: 2.4493416446596

Epoch: 6| Step: 3
Training loss: 2.471592003673602
Validation loss: 2.4633168177724234

Epoch: 6| Step: 4
Training loss: 2.5339134238130323
Validation loss: 2.453551156189041

Epoch: 6| Step: 5
Training loss: 2.93803368448225
Validation loss: 2.449741727489367

Epoch: 6| Step: 6
Training loss: 2.4393315403297398
Validation loss: 2.452576108134593

Epoch: 6| Step: 7
Training loss: 2.5273816726410083
Validation loss: 2.4563138932450888

Epoch: 6| Step: 8
Training loss: 1.7113464424147369
Validation loss: 2.4511694595304747

Epoch: 6| Step: 9
Training loss: 1.810615875674121
Validation loss: 2.457879838225141

Epoch: 6| Step: 10
Training loss: 2.3681785598783054
Validation loss: 2.4535679184498584

Epoch: 6| Step: 11
Training loss: 2.8640861680904557
Validation loss: 2.459667221087195

Epoch: 6| Step: 12
Training loss: 1.6879156095372285
Validation loss: 2.4663042919217335

Epoch: 6| Step: 13
Training loss: 2.2721760714299535
Validation loss: 2.4562140128077306

Epoch: 31| Step: 0
Training loss: 2.117872289292355
Validation loss: 2.4578048304983584

Epoch: 6| Step: 1
Training loss: 2.603892889254652
Validation loss: 2.463076417849272

Epoch: 6| Step: 2
Training loss: 2.4195198667293574
Validation loss: 2.4654144738734334

Epoch: 6| Step: 3
Training loss: 2.1686059513679172
Validation loss: 2.4800135798108123

Epoch: 6| Step: 4
Training loss: 2.5906445400113136
Validation loss: 2.478383579048378

Epoch: 6| Step: 5
Training loss: 2.5473381510674606
Validation loss: 2.487432310087534

Epoch: 6| Step: 6
Training loss: 1.7180141607773405
Validation loss: 2.5084675758237633

Epoch: 6| Step: 7
Training loss: 2.9097787087318276
Validation loss: 2.512700373059744

Epoch: 6| Step: 8
Training loss: 2.708585482866133
Validation loss: 2.48797915394954

Epoch: 6| Step: 9
Training loss: 2.441224016636297
Validation loss: 2.4864256930329702

Epoch: 6| Step: 10
Training loss: 2.4108859894170203
Validation loss: 2.4868422119351643

Epoch: 6| Step: 11
Training loss: 2.6687684319817784
Validation loss: 2.4674739034419955

Epoch: 6| Step: 12
Training loss: 2.24107306561223
Validation loss: 2.4559197350214768

Epoch: 6| Step: 13
Training loss: 2.459255455049043
Validation loss: 2.453474032118271

Epoch: 32| Step: 0
Training loss: 2.7108077752024213
Validation loss: 2.4553582459814725

Epoch: 6| Step: 1
Training loss: 2.5907930731464774
Validation loss: 2.4562341380557595

Epoch: 6| Step: 2
Training loss: 2.5411625555016912
Validation loss: 2.4594765499594864

Epoch: 6| Step: 3
Training loss: 1.8844113980600605
Validation loss: 2.447941545941694

Epoch: 6| Step: 4
Training loss: 1.8387849194746189
Validation loss: 2.456176212810547

Epoch: 6| Step: 5
Training loss: 2.5388951642575424
Validation loss: 2.45088535777207

Epoch: 6| Step: 6
Training loss: 2.1912604570764906
Validation loss: 2.456539895355197

Epoch: 6| Step: 7
Training loss: 2.330259842034035
Validation loss: 2.4386542920927865

Epoch: 6| Step: 8
Training loss: 2.2707843833570465
Validation loss: 2.466591660115237

Epoch: 6| Step: 9
Training loss: 2.6220348504934385
Validation loss: 2.4574690339319383

Epoch: 6| Step: 10
Training loss: 2.746290305687881
Validation loss: 2.453154140550406

Epoch: 6| Step: 11
Training loss: 2.5279127185095502
Validation loss: 2.438613409078524

Epoch: 6| Step: 12
Training loss: 2.6406468497732303
Validation loss: 2.4610181684240597

Epoch: 6| Step: 13
Training loss: 2.161562691126417
Validation loss: 2.4473968982119185

Epoch: 33| Step: 0
Training loss: 2.4912629041706
Validation loss: 2.467781971618686

Epoch: 6| Step: 1
Training loss: 2.2388812953461557
Validation loss: 2.4668172360765657

Epoch: 6| Step: 2
Training loss: 2.1163860084914745
Validation loss: 2.450502439477839

Epoch: 6| Step: 3
Training loss: 2.4712727851183884
Validation loss: 2.449526031865583

Epoch: 6| Step: 4
Training loss: 2.248975520549036
Validation loss: 2.4612727184160947

Epoch: 6| Step: 5
Training loss: 2.176049481334201
Validation loss: 2.459267355321427

Epoch: 6| Step: 6
Training loss: 3.013367435408641
Validation loss: 2.4551593905655236

Epoch: 6| Step: 7
Training loss: 2.3755797632211344
Validation loss: 2.4623263844898555

Epoch: 6| Step: 8
Training loss: 2.262972206029325
Validation loss: 2.467894909043768

Epoch: 6| Step: 9
Training loss: 1.8071759394843714
Validation loss: 2.443047430147711

Epoch: 6| Step: 10
Training loss: 2.3073187855891346
Validation loss: 2.447683596506454

Epoch: 6| Step: 11
Training loss: 2.4101868168455214
Validation loss: 2.4600849915375647

Epoch: 6| Step: 12
Training loss: 2.321849788975574
Validation loss: 2.4748151132133556

Epoch: 6| Step: 13
Training loss: 3.070171013209851
Validation loss: 2.4659191189852216

Epoch: 34| Step: 0
Training loss: 1.970970234004075
Validation loss: 2.47492074550544

Epoch: 6| Step: 1
Training loss: 2.032969172756722
Validation loss: 2.4609073859092927

Epoch: 6| Step: 2
Training loss: 2.2209302908492026
Validation loss: 2.4589012643001142

Epoch: 6| Step: 3
Training loss: 3.270455324395921
Validation loss: 2.466136369750822

Epoch: 6| Step: 4
Training loss: 2.2902218743662552
Validation loss: 2.452464620222895

Epoch: 6| Step: 5
Training loss: 2.4835194008094192
Validation loss: 2.442913873696806

Epoch: 6| Step: 6
Training loss: 2.155820057339876
Validation loss: 2.462878943911468

Epoch: 6| Step: 7
Training loss: 1.629021436977601
Validation loss: 2.444937810334446

Epoch: 6| Step: 8
Training loss: 2.6660084706863714
Validation loss: 2.45794602484295

Epoch: 6| Step: 9
Training loss: 3.038590343051887
Validation loss: 2.450461283874716

Epoch: 6| Step: 10
Training loss: 2.4155537465235066
Validation loss: 2.449598308317824

Epoch: 6| Step: 11
Training loss: 3.019716481675011
Validation loss: 2.4496706475221073

Epoch: 6| Step: 12
Training loss: 2.1980358892952325
Validation loss: 2.451167416916804

Epoch: 6| Step: 13
Training loss: 1.5452378211572924
Validation loss: 2.437786884216475

Epoch: 35| Step: 0
Training loss: 2.624426824571746
Validation loss: 2.4662453222834624

Epoch: 6| Step: 1
Training loss: 2.247890012887704
Validation loss: 2.4332806348537575

Epoch: 6| Step: 2
Training loss: 2.2813145876585654
Validation loss: 2.449072598726175

Epoch: 6| Step: 3
Training loss: 2.3808778006362483
Validation loss: 2.4534825673877836

Epoch: 6| Step: 4
Training loss: 2.2862375162909028
Validation loss: 2.4465463793581566

Epoch: 6| Step: 5
Training loss: 2.111155344962555
Validation loss: 2.452717425267608

Epoch: 6| Step: 6
Training loss: 2.289302878403682
Validation loss: 2.4454361596898355

Epoch: 6| Step: 7
Training loss: 2.8353851032579076
Validation loss: 2.4614386477162813

Epoch: 6| Step: 8
Training loss: 1.8950936967136296
Validation loss: 2.4596699917034077

Epoch: 6| Step: 9
Training loss: 2.529109850710896
Validation loss: 2.46658861535108

Epoch: 6| Step: 10
Training loss: 1.8633695377569965
Validation loss: 2.4856483507102674

Epoch: 6| Step: 11
Training loss: 2.496809831325019
Validation loss: 2.4648623861262267

Epoch: 6| Step: 12
Training loss: 2.400322288490245
Validation loss: 2.463596195534177

Epoch: 6| Step: 13
Training loss: 3.1284982555763143
Validation loss: 2.466860180644292

Epoch: 36| Step: 0
Training loss: 2.686921079515125
Validation loss: 2.4541043151119495

Epoch: 6| Step: 1
Training loss: 2.194217938457845
Validation loss: 2.435139107748362

Epoch: 6| Step: 2
Training loss: 2.529320157801863
Validation loss: 2.450943513443195

Epoch: 6| Step: 3
Training loss: 2.214663974254303
Validation loss: 2.4515273283523737

Epoch: 6| Step: 4
Training loss: 2.1648840050755904
Validation loss: 2.4513918672807113

Epoch: 6| Step: 5
Training loss: 2.6733054631778965
Validation loss: 2.436292202360378

Epoch: 6| Step: 6
Training loss: 2.4347444266233844
Validation loss: 2.44731399476154

Epoch: 6| Step: 7
Training loss: 2.6089237759539454
Validation loss: 2.4375704078612883

Epoch: 6| Step: 8
Training loss: 2.4390410418058326
Validation loss: 2.435200307376335

Epoch: 6| Step: 9
Training loss: 2.2780103280467143
Validation loss: 2.436708892512056

Epoch: 6| Step: 10
Training loss: 2.9416691838614812
Validation loss: 2.4341973321122077

Epoch: 6| Step: 11
Training loss: 2.0733752358465716
Validation loss: 2.451103252043027

Epoch: 6| Step: 12
Training loss: 1.8553297131295523
Validation loss: 2.4539715547402756

Epoch: 6| Step: 13
Training loss: 2.30173305648678
Validation loss: 2.4383401400987585

Epoch: 37| Step: 0
Training loss: 1.7845088527734545
Validation loss: 2.4439515377885965

Epoch: 6| Step: 1
Training loss: 2.1744376233790446
Validation loss: 2.4545840158387646

Epoch: 6| Step: 2
Training loss: 2.3245001101691765
Validation loss: 2.4388783462149792

Epoch: 6| Step: 3
Training loss: 2.2290103774378958
Validation loss: 2.4504081762337884

Epoch: 6| Step: 4
Training loss: 2.747594648402255
Validation loss: 2.4586469859665034

Epoch: 6| Step: 5
Training loss: 2.5601782166019107
Validation loss: 2.4647745565061783

Epoch: 6| Step: 6
Training loss: 2.581386837784415
Validation loss: 2.4664155086890927

Epoch: 6| Step: 7
Training loss: 2.131543127580657
Validation loss: 2.4672525105398058

Epoch: 6| Step: 8
Training loss: 2.2002177434151196
Validation loss: 2.472082118613749

Epoch: 6| Step: 9
Training loss: 2.770426746644009
Validation loss: 2.4743985289742683

Epoch: 6| Step: 10
Training loss: 2.4302485269056033
Validation loss: 2.4941555133276636

Epoch: 6| Step: 11
Training loss: 2.5196375151706296
Validation loss: 2.4684313475908883

Epoch: 6| Step: 12
Training loss: 1.928255669665474
Validation loss: 2.4796727302430295

Epoch: 6| Step: 13
Training loss: 2.8292628575762877
Validation loss: 2.4515730206644926

Epoch: 38| Step: 0
Training loss: 2.1393287242238643
Validation loss: 2.461746228257512

Epoch: 6| Step: 1
Training loss: 2.8394274714779546
Validation loss: 2.456633826268783

Epoch: 6| Step: 2
Training loss: 2.2166958823704737
Validation loss: 2.455810146405705

Epoch: 6| Step: 3
Training loss: 1.651669051126606
Validation loss: 2.446042610997646

Epoch: 6| Step: 4
Training loss: 2.4502883352210234
Validation loss: 2.438144370436189

Epoch: 6| Step: 5
Training loss: 2.63721584579218
Validation loss: 2.4440822086076928

Epoch: 6| Step: 6
Training loss: 2.1821921120258505
Validation loss: 2.4506071901797126

Epoch: 6| Step: 7
Training loss: 1.6141133598593882
Validation loss: 2.4564842985968647

Epoch: 6| Step: 8
Training loss: 2.5031835313447273
Validation loss: 2.44205266507486

Epoch: 6| Step: 9
Training loss: 2.486251985713114
Validation loss: 2.4420085601432704

Epoch: 6| Step: 10
Training loss: 2.8724617741550422
Validation loss: 2.437855164825662

Epoch: 6| Step: 11
Training loss: 2.4944674308395545
Validation loss: 2.436219074450308

Epoch: 6| Step: 12
Training loss: 2.552374956765145
Validation loss: 2.463473463559332

Epoch: 6| Step: 13
Training loss: 2.442802725610482
Validation loss: 2.442067317726804

Epoch: 39| Step: 0
Training loss: 1.5515493033194605
Validation loss: 2.4458349967660613

Epoch: 6| Step: 1
Training loss: 2.4809945577971533
Validation loss: 2.4519818471057184

Epoch: 6| Step: 2
Training loss: 2.3329926877910743
Validation loss: 2.448309283864436

Epoch: 6| Step: 3
Training loss: 2.096079199787018
Validation loss: 2.456670025996168

Epoch: 6| Step: 4
Training loss: 2.361545297182188
Validation loss: 2.466242712119346

Epoch: 6| Step: 5
Training loss: 2.44777294846286
Validation loss: 2.466300562053324

Epoch: 6| Step: 6
Training loss: 2.165134756462368
Validation loss: 2.45509438318389

Epoch: 6| Step: 7
Training loss: 2.5984246286336066
Validation loss: 2.507173054616389

Epoch: 6| Step: 8
Training loss: 1.8459036581909891
Validation loss: 2.5066175139034854

Epoch: 6| Step: 9
Training loss: 2.094199972053581
Validation loss: 2.4741181546169884

Epoch: 6| Step: 10
Training loss: 2.668330110845421
Validation loss: 2.490810288796678

Epoch: 6| Step: 11
Training loss: 2.601221377257887
Validation loss: 2.4822913014716743

Epoch: 6| Step: 12
Training loss: 3.164526333189874
Validation loss: 2.45821437440112

Epoch: 6| Step: 13
Training loss: 2.8613321245705836
Validation loss: 2.435867610676733

Epoch: 40| Step: 0
Training loss: 1.98725135975363
Validation loss: 2.4347616774104064

Epoch: 6| Step: 1
Training loss: 2.2612574078811254
Validation loss: 2.4357138063866866

Epoch: 6| Step: 2
Training loss: 2.0389482605016456
Validation loss: 2.440258975225836

Epoch: 6| Step: 3
Training loss: 1.9034670542738408
Validation loss: 2.439736929297847

Epoch: 6| Step: 4
Training loss: 2.423085851385042
Validation loss: 2.4580000850862675

Epoch: 6| Step: 5
Training loss: 2.7741114697437306
Validation loss: 2.4389672875988757

Epoch: 6| Step: 6
Training loss: 1.9576041169326324
Validation loss: 2.4237149704252277

Epoch: 6| Step: 7
Training loss: 1.9361111985578598
Validation loss: 2.4385801188161143

Epoch: 6| Step: 8
Training loss: 2.713054171439322
Validation loss: 2.436399521157975

Epoch: 6| Step: 9
Training loss: 2.622233522475224
Validation loss: 2.4256233413744352

Epoch: 6| Step: 10
Training loss: 2.914718104189853
Validation loss: 2.4357768921170067

Epoch: 6| Step: 11
Training loss: 2.8482618485958247
Validation loss: 2.4228224921080934

Epoch: 6| Step: 12
Training loss: 2.2850248902215236
Validation loss: 2.4431596730783127

Epoch: 6| Step: 13
Training loss: 2.3639141149652896
Validation loss: 2.448066809628716

Epoch: 41| Step: 0
Training loss: 2.209904405761702
Validation loss: 2.4305319999885504

Epoch: 6| Step: 1
Training loss: 2.583084976399401
Validation loss: 2.438037837430389

Epoch: 6| Step: 2
Training loss: 1.8399627711842086
Validation loss: 2.446615276299352

Epoch: 6| Step: 3
Training loss: 2.9516171435684253
Validation loss: 2.4387216359543196

Epoch: 6| Step: 4
Training loss: 2.4817871434788903
Validation loss: 2.4435887868117634

Epoch: 6| Step: 5
Training loss: 1.9895115251880802
Validation loss: 2.4323960526235533

Epoch: 6| Step: 6
Training loss: 2.515671913230799
Validation loss: 2.439723020008112

Epoch: 6| Step: 7
Training loss: 2.5699894942725714
Validation loss: 2.431597744769175

Epoch: 6| Step: 8
Training loss: 2.274274429483616
Validation loss: 2.4376440902245946

Epoch: 6| Step: 9
Training loss: 2.0059560067172484
Validation loss: 2.431630681233329

Epoch: 6| Step: 10
Training loss: 2.090077609943798
Validation loss: 2.4381379001944046

Epoch: 6| Step: 11
Training loss: 2.3663963279881335
Validation loss: 2.453432019372174

Epoch: 6| Step: 12
Training loss: 2.6535636332580217
Validation loss: 2.446905265351351

Epoch: 6| Step: 13
Training loss: 2.425622808961142
Validation loss: 2.4443850073548172

Epoch: 42| Step: 0
Training loss: 2.396214949580844
Validation loss: 2.443085937486988

Epoch: 6| Step: 1
Training loss: 1.6333357415213965
Validation loss: 2.4322337784232912

Epoch: 6| Step: 2
Training loss: 1.6438838019504862
Validation loss: 2.449697428463921

Epoch: 6| Step: 3
Training loss: 2.0987707264043203
Validation loss: 2.458509622061215

Epoch: 6| Step: 4
Training loss: 2.3508640405307464
Validation loss: 2.4806145252235052

Epoch: 6| Step: 5
Training loss: 2.2269083390268327
Validation loss: 2.453179960181879

Epoch: 6| Step: 6
Training loss: 2.298283981704411
Validation loss: 2.44283903269799

Epoch: 6| Step: 7
Training loss: 1.9829961236289684
Validation loss: 2.464335103458178

Epoch: 6| Step: 8
Training loss: 2.993750101937629
Validation loss: 2.477310645280156

Epoch: 6| Step: 9
Training loss: 2.8412605539873548
Validation loss: 2.4618927731388522

Epoch: 6| Step: 10
Training loss: 2.579245029259429
Validation loss: 2.4760108758608443

Epoch: 6| Step: 11
Training loss: 2.724216446521377
Validation loss: 2.4749731184401873

Epoch: 6| Step: 12
Training loss: 2.5710711533542496
Validation loss: 2.4784009750138134

Epoch: 6| Step: 13
Training loss: 2.399735785881649
Validation loss: 2.457885585570506

Epoch: 43| Step: 0
Training loss: 2.578185757007811
Validation loss: 2.4576541129343115

Epoch: 6| Step: 1
Training loss: 1.7640439947355477
Validation loss: 2.451351780260836

Epoch: 6| Step: 2
Training loss: 2.008516062210049
Validation loss: 2.4234231574172953

Epoch: 6| Step: 3
Training loss: 2.312833504212265
Validation loss: 2.430721018169753

Epoch: 6| Step: 4
Training loss: 2.097447560760841
Validation loss: 2.4337221033201732

Epoch: 6| Step: 5
Training loss: 3.0766419841675883
Validation loss: 2.4291614482249964

Epoch: 6| Step: 6
Training loss: 2.3946615809058804
Validation loss: 2.424527002197997

Epoch: 6| Step: 7
Training loss: 2.1939158493776354
Validation loss: 2.4169667786569526

Epoch: 6| Step: 8
Training loss: 2.8181008413992075
Validation loss: 2.4474234280218186

Epoch: 6| Step: 9
Training loss: 2.3396992583073
Validation loss: 2.429877188945136

Epoch: 6| Step: 10
Training loss: 2.684141677823818
Validation loss: 2.4303009796033033

Epoch: 6| Step: 11
Training loss: 2.150362685019442
Validation loss: 2.4265159685987783

Epoch: 6| Step: 12
Training loss: 1.9344565576174944
Validation loss: 2.4213508941262862

Epoch: 6| Step: 13
Training loss: 2.583662340276301
Validation loss: 2.4165187055959736

Epoch: 44| Step: 0
Training loss: 2.1310645685604026
Validation loss: 2.437508020632337

Epoch: 6| Step: 1
Training loss: 1.97790734900088
Validation loss: 2.4534893696686

Epoch: 6| Step: 2
Training loss: 2.327867941778036
Validation loss: 2.43972709182245

Epoch: 6| Step: 3
Training loss: 2.900258769624899
Validation loss: 2.4380167388935963

Epoch: 6| Step: 4
Training loss: 2.3353450368286137
Validation loss: 2.4308996417191207

Epoch: 6| Step: 5
Training loss: 2.6886200456058846
Validation loss: 2.4332564494210405

Epoch: 6| Step: 6
Training loss: 2.3526579374347967
Validation loss: 2.442910653027268

Epoch: 6| Step: 7
Training loss: 2.544730377604305
Validation loss: 2.448758687965724

Epoch: 6| Step: 8
Training loss: 2.261199417181124
Validation loss: 2.4695750761100554

Epoch: 6| Step: 9
Training loss: 2.710482600409754
Validation loss: 2.471465568858811

Epoch: 6| Step: 10
Training loss: 1.821531157983916
Validation loss: 2.475244052812137

Epoch: 6| Step: 11
Training loss: 2.631179801385074
Validation loss: 2.469298217359825

Epoch: 6| Step: 12
Training loss: 2.137423383443901
Validation loss: 2.471494742369187

Epoch: 6| Step: 13
Training loss: 2.0254513649583203
Validation loss: 2.4626463431879584

Epoch: 45| Step: 0
Training loss: 2.3609111913178342
Validation loss: 2.4622557807818612

Epoch: 6| Step: 1
Training loss: 1.9527480104920012
Validation loss: 2.4461561703705508

Epoch: 6| Step: 2
Training loss: 2.371672759147677
Validation loss: 2.453982144744466

Epoch: 6| Step: 3
Training loss: 2.1112301051194526
Validation loss: 2.4334282244726837

Epoch: 6| Step: 4
Training loss: 2.539961341804022
Validation loss: 2.435815440984529

Epoch: 6| Step: 5
Training loss: 2.3992753444842263
Validation loss: 2.426022249905457

Epoch: 6| Step: 6
Training loss: 2.1261328874973575
Validation loss: 2.425930589879573

Epoch: 6| Step: 7
Training loss: 2.86395530520893
Validation loss: 2.4307383792480017

Epoch: 6| Step: 8
Training loss: 2.8720102106088183
Validation loss: 2.426511350585122

Epoch: 6| Step: 9
Training loss: 2.364475219764498
Validation loss: 2.4303439481143543

Epoch: 6| Step: 10
Training loss: 2.4272747264486254
Validation loss: 2.4334692435869916

Epoch: 6| Step: 11
Training loss: 2.494509963109927
Validation loss: 2.418764204366344

Epoch: 6| Step: 12
Training loss: 2.434512728711297
Validation loss: 2.432104398936705

Epoch: 6| Step: 13
Training loss: 1.6655677112797138
Validation loss: 2.4357474784150233

Epoch: 46| Step: 0
Training loss: 2.3291025861501944
Validation loss: 2.4235628542852075

Epoch: 6| Step: 1
Training loss: 2.57344675716734
Validation loss: 2.442266742887498

Epoch: 6| Step: 2
Training loss: 2.4459231653130957
Validation loss: 2.4336775780083864

Epoch: 6| Step: 3
Training loss: 2.3061003928518855
Validation loss: 2.4389893554433324

Epoch: 6| Step: 4
Training loss: 2.254525402055427
Validation loss: 2.417910228507909

Epoch: 6| Step: 5
Training loss: 2.0979625400148163
Validation loss: 2.4430744463424148

Epoch: 6| Step: 6
Training loss: 2.282969205831605
Validation loss: 2.442923063967849

Epoch: 6| Step: 7
Training loss: 2.4996047661213177
Validation loss: 2.4274073099393445

Epoch: 6| Step: 8
Training loss: 2.3550494629024854
Validation loss: 2.433053468478626

Epoch: 6| Step: 9
Training loss: 2.0130041071569895
Validation loss: 2.4345791099033374

Epoch: 6| Step: 10
Training loss: 2.609355629489292
Validation loss: 2.456072338690507

Epoch: 6| Step: 11
Training loss: 2.2225590636018495
Validation loss: 2.4558887018598896

Epoch: 6| Step: 12
Training loss: 2.531465497674809
Validation loss: 2.4605267863188622

Epoch: 6| Step: 13
Training loss: 2.266760179984202
Validation loss: 2.454601709982051

Epoch: 47| Step: 0
Training loss: 2.669971345612001
Validation loss: 2.450786715335121

Epoch: 6| Step: 1
Training loss: 2.449341303970057
Validation loss: 2.467952889309666

Epoch: 6| Step: 2
Training loss: 2.788751323020823
Validation loss: 2.456994910039664

Epoch: 6| Step: 3
Training loss: 2.2391210980943286
Validation loss: 2.445717441882704

Epoch: 6| Step: 4
Training loss: 2.7972526082275517
Validation loss: 2.448877516667422

Epoch: 6| Step: 5
Training loss: 2.140250402934657
Validation loss: 2.434328167407322

Epoch: 6| Step: 6
Training loss: 2.4745041629912716
Validation loss: 2.433639681052518

Epoch: 6| Step: 7
Training loss: 2.258585866718396
Validation loss: 2.4306739693512953

Epoch: 6| Step: 8
Training loss: 1.6031603773946614
Validation loss: 2.4359312633657235

Epoch: 6| Step: 9
Training loss: 2.0969496234742198
Validation loss: 2.4282757827241994

Epoch: 6| Step: 10
Training loss: 3.289064384695496
Validation loss: 2.421006537154315

Epoch: 6| Step: 11
Training loss: 2.1063789848881695
Validation loss: 2.435735911864752

Epoch: 6| Step: 12
Training loss: 1.9523816944967138
Validation loss: 2.4238106980313363

Epoch: 6| Step: 13
Training loss: 2.044398199758556
Validation loss: 2.4411889877286805

Epoch: 48| Step: 0
Training loss: 2.3776633738192756
Validation loss: 2.4481583874986828

Epoch: 6| Step: 1
Training loss: 2.6309518096929785
Validation loss: 2.430509879878946

Epoch: 6| Step: 2
Training loss: 2.1692055962970285
Validation loss: 2.4507304854238194

Epoch: 6| Step: 3
Training loss: 2.4966324059343075
Validation loss: 2.4815371477732517

Epoch: 6| Step: 4
Training loss: 2.978896299956337
Validation loss: 2.4956671042217966

Epoch: 6| Step: 5
Training loss: 2.3900946733246435
Validation loss: 2.4855606161054764

Epoch: 6| Step: 6
Training loss: 1.9094639559188455
Validation loss: 2.498387341118097

Epoch: 6| Step: 7
Training loss: 1.6444752880732187
Validation loss: 2.5191202937468202

Epoch: 6| Step: 8
Training loss: 2.7970667086063212
Validation loss: 2.5194811438967535

Epoch: 6| Step: 9
Training loss: 2.299250717018632
Validation loss: 2.4931510091186633

Epoch: 6| Step: 10
Training loss: 2.2286146912550038
Validation loss: 2.4759033641671175

Epoch: 6| Step: 11
Training loss: 2.614742947958542
Validation loss: 2.467219977137908

Epoch: 6| Step: 12
Training loss: 1.7022152491997462
Validation loss: 2.434434577105139

Epoch: 6| Step: 13
Training loss: 2.5249910562186897
Validation loss: 2.427861810573713

Epoch: 49| Step: 0
Training loss: 2.3316556030549034
Validation loss: 2.4231231754516838

Epoch: 6| Step: 1
Training loss: 1.782168502907036
Validation loss: 2.423910061222115

Epoch: 6| Step: 2
Training loss: 2.180870910756142
Validation loss: 2.4307296169867194

Epoch: 6| Step: 3
Training loss: 2.2965140545674716
Validation loss: 2.4328429899467228

Epoch: 6| Step: 4
Training loss: 2.4807009610795054
Validation loss: 2.4222102107567793

Epoch: 6| Step: 5
Training loss: 2.6264434660399516
Validation loss: 2.4373904635605004

Epoch: 6| Step: 6
Training loss: 1.9442552504761061
Validation loss: 2.4257467843851206

Epoch: 6| Step: 7
Training loss: 2.078035280972699
Validation loss: 2.445802389682417

Epoch: 6| Step: 8
Training loss: 2.470983340087947
Validation loss: 2.4181549378559204

Epoch: 6| Step: 9
Training loss: 2.4197644297172207
Validation loss: 2.4332384040901376

Epoch: 6| Step: 10
Training loss: 2.603918709712258
Validation loss: 2.4171534628959117

Epoch: 6| Step: 11
Training loss: 2.6934594017525417
Validation loss: 2.420481438812322

Epoch: 6| Step: 12
Training loss: 2.4016386160270216
Validation loss: 2.4234671414839855

Epoch: 6| Step: 13
Training loss: 2.337867781321145
Validation loss: 2.412584759898364

Epoch: 50| Step: 0
Training loss: 1.7222652207752842
Validation loss: 2.4300771157596244

Epoch: 6| Step: 1
Training loss: 2.249112271978189
Validation loss: 2.426849154743167

Epoch: 6| Step: 2
Training loss: 2.431309002550138
Validation loss: 2.436675087000557

Epoch: 6| Step: 3
Training loss: 2.2755226457139965
Validation loss: 2.4311019035153754

Epoch: 6| Step: 4
Training loss: 2.6099880206538386
Validation loss: 2.4223519624685164

Epoch: 6| Step: 5
Training loss: 1.858174168680079
Validation loss: 2.431935667550674

Epoch: 6| Step: 6
Training loss: 2.6543665772213023
Validation loss: 2.443213117182597

Epoch: 6| Step: 7
Training loss: 2.6888357879274993
Validation loss: 2.4306421724659235

Epoch: 6| Step: 8
Training loss: 2.230766423499367
Validation loss: 2.430067778794601

Epoch: 6| Step: 9
Training loss: 2.386403464112947
Validation loss: 2.4217975152859217

Epoch: 6| Step: 10
Training loss: 2.002235117334598
Validation loss: 2.433353091730174

Epoch: 6| Step: 11
Training loss: 2.2646886534942556
Validation loss: 2.4090392720352165

Epoch: 6| Step: 12
Training loss: 2.2841358482325766
Validation loss: 2.42611108934182

Epoch: 6| Step: 13
Training loss: 2.5358377019832243
Validation loss: 2.438807096270806

Epoch: 51| Step: 0
Training loss: 1.7834453773357988
Validation loss: 2.448841161181558

Epoch: 6| Step: 1
Training loss: 2.511096456038585
Validation loss: 2.4699857009442914

Epoch: 6| Step: 2
Training loss: 2.5046468463723035
Validation loss: 2.4387308583175598

Epoch: 6| Step: 3
Training loss: 2.4402051733085472
Validation loss: 2.4445052922025683

Epoch: 6| Step: 4
Training loss: 2.359393189214862
Validation loss: 2.490226931093347

Epoch: 6| Step: 5
Training loss: 1.7858024779748702
Validation loss: 2.474700323900903

Epoch: 6| Step: 6
Training loss: 2.4556380113745826
Validation loss: 2.468656626677934

Epoch: 6| Step: 7
Training loss: 2.270284977304353
Validation loss: 2.4640965445066922

Epoch: 6| Step: 8
Training loss: 2.2580665524644945
Validation loss: 2.4545101863374885

Epoch: 6| Step: 9
Training loss: 2.180728568025453
Validation loss: 2.4506568560142745

Epoch: 6| Step: 10
Training loss: 3.063734778775365
Validation loss: 2.416848263549497

Epoch: 6| Step: 11
Training loss: 2.158401632026129
Validation loss: 2.425806484613299

Epoch: 6| Step: 12
Training loss: 2.4343391856544945
Validation loss: 2.424306022670466

Epoch: 6| Step: 13
Training loss: 2.4245184469404317
Validation loss: 2.424947844268886

Epoch: 52| Step: 0
Training loss: 2.2995482996351124
Validation loss: 2.42713537419619

Epoch: 6| Step: 1
Training loss: 2.3386570846066985
Validation loss: 2.4242537598904823

Epoch: 6| Step: 2
Training loss: 2.581591408529251
Validation loss: 2.426423025288385

Epoch: 6| Step: 3
Training loss: 1.8850684994866787
Validation loss: 2.4094645838528246

Epoch: 6| Step: 4
Training loss: 1.9333400367204057
Validation loss: 2.4270202290158616

Epoch: 6| Step: 5
Training loss: 2.187457056986415
Validation loss: 2.410196461643505

Epoch: 6| Step: 6
Training loss: 2.2908496325003105
Validation loss: 2.4342272705905836

Epoch: 6| Step: 7
Training loss: 2.8973649911966413
Validation loss: 2.426990046093174

Epoch: 6| Step: 8
Training loss: 2.5934306488148864
Validation loss: 2.441324762637485

Epoch: 6| Step: 9
Training loss: 2.6624330252520223
Validation loss: 2.4336203731348083

Epoch: 6| Step: 10
Training loss: 2.0621506366189424
Validation loss: 2.4121973760410675

Epoch: 6| Step: 11
Training loss: 1.948978141658181
Validation loss: 2.422302257628098

Epoch: 6| Step: 12
Training loss: 2.673465099448648
Validation loss: 2.428830419816608

Epoch: 6| Step: 13
Training loss: 1.8450196630572453
Validation loss: 2.43571126138888

Epoch: 53| Step: 0
Training loss: 2.7464590684280696
Validation loss: 2.415741370631694

Epoch: 6| Step: 1
Training loss: 2.5658508350072347
Validation loss: 2.441505727140027

Epoch: 6| Step: 2
Training loss: 2.410324807973324
Validation loss: 2.4485546471104476

Epoch: 6| Step: 3
Training loss: 2.630773734077275
Validation loss: 2.4313999858705477

Epoch: 6| Step: 4
Training loss: 2.115106552361899
Validation loss: 2.424635595621656

Epoch: 6| Step: 5
Training loss: 2.062401971510366
Validation loss: 2.4305179726253248

Epoch: 6| Step: 6
Training loss: 1.9866300970377084
Validation loss: 2.430994914777263

Epoch: 6| Step: 7
Training loss: 2.052607074133101
Validation loss: 2.418662814360512

Epoch: 6| Step: 8
Training loss: 1.9999659058525858
Validation loss: 2.416929565029448

Epoch: 6| Step: 9
Training loss: 2.1311365047003115
Validation loss: 2.4256476602509083

Epoch: 6| Step: 10
Training loss: 2.755006827261162
Validation loss: 2.418391349481285

Epoch: 6| Step: 11
Training loss: 2.3408628864896652
Validation loss: 2.41818578153843

Epoch: 6| Step: 12
Training loss: 2.3280326261692084
Validation loss: 2.422232406659934

Epoch: 6| Step: 13
Training loss: 2.280471668979911
Validation loss: 2.4231923612057975

Epoch: 54| Step: 0
Training loss: 2.6815013918811688
Validation loss: 2.4309017994414397

Epoch: 6| Step: 1
Training loss: 2.1538523736801047
Validation loss: 2.4187179497592246

Epoch: 6| Step: 2
Training loss: 2.2578543160866023
Validation loss: 2.4373302971216164

Epoch: 6| Step: 3
Training loss: 2.1726243078139515
Validation loss: 2.4156218166420818

Epoch: 6| Step: 4
Training loss: 2.7163526993290286
Validation loss: 2.43257494521859

Epoch: 6| Step: 5
Training loss: 2.6934601098932998
Validation loss: 2.449295943167754

Epoch: 6| Step: 6
Training loss: 1.1169786591501865
Validation loss: 2.443781770725674

Epoch: 6| Step: 7
Training loss: 3.0397521660821583
Validation loss: 2.450022928948057

Epoch: 6| Step: 8
Training loss: 2.54378973252667
Validation loss: 2.434226650276883

Epoch: 6| Step: 9
Training loss: 1.9465753217499315
Validation loss: 2.440217939972535

Epoch: 6| Step: 10
Training loss: 2.2677317328261406
Validation loss: 2.4301999074106098

Epoch: 6| Step: 11
Training loss: 2.3989752250559255
Validation loss: 2.4363427879418658

Epoch: 6| Step: 12
Training loss: 1.820606257102864
Validation loss: 2.445817872821179

Epoch: 6| Step: 13
Training loss: 1.8064024732180846
Validation loss: 2.446390468909295

Epoch: 55| Step: 0
Training loss: 2.1426350978067905
Validation loss: 2.4409597736280575

Epoch: 6| Step: 1
Training loss: 2.079542322056965
Validation loss: 2.4348834739548177

Epoch: 6| Step: 2
Training loss: 1.9925233445660673
Validation loss: 2.45201547399682

Epoch: 6| Step: 3
Training loss: 1.7606840965094834
Validation loss: 2.447255728484184

Epoch: 6| Step: 4
Training loss: 1.9338420669940148
Validation loss: 2.4375710599273686

Epoch: 6| Step: 5
Training loss: 2.9963035062453347
Validation loss: 2.4433375173882452

Epoch: 6| Step: 6
Training loss: 2.3285032643497416
Validation loss: 2.4281156633836627

Epoch: 6| Step: 7
Training loss: 3.0271415003005386
Validation loss: 2.437258300861546

Epoch: 6| Step: 8
Training loss: 2.630413286640089
Validation loss: 2.4485494458627204

Epoch: 6| Step: 9
Training loss: 1.925537774903405
Validation loss: 2.431873282826802

Epoch: 6| Step: 10
Training loss: 2.117576985586705
Validation loss: 2.421513060729949

Epoch: 6| Step: 11
Training loss: 2.0505930205656195
Validation loss: 2.4321097415520527

Epoch: 6| Step: 12
Training loss: 1.9774985528258227
Validation loss: 2.4119125388859333

Epoch: 6| Step: 13
Training loss: 2.770637323621883
Validation loss: 2.419145469305468

Epoch: 56| Step: 0
Training loss: 2.7163046878482837
Validation loss: 2.4251644396659513

Epoch: 6| Step: 1
Training loss: 2.281503114636745
Validation loss: 2.427677512941544

Epoch: 6| Step: 2
Training loss: 2.403146104261098
Validation loss: 2.410491112230099

Epoch: 6| Step: 3
Training loss: 2.150122297490317
Validation loss: 2.4289482684839903

Epoch: 6| Step: 4
Training loss: 1.9974200178039179
Validation loss: 2.406869841498856

Epoch: 6| Step: 5
Training loss: 2.263670611113754
Validation loss: 2.4244553960556123

Epoch: 6| Step: 6
Training loss: 2.4028198762806006
Validation loss: 2.4137952835679193

Epoch: 6| Step: 7
Training loss: 2.872841065877979
Validation loss: 2.4154772846151675

Epoch: 6| Step: 8
Training loss: 2.6788449756270674
Validation loss: 2.416193312841575

Epoch: 6| Step: 9
Training loss: 2.129541816682411
Validation loss: 2.4303577312315148

Epoch: 6| Step: 10
Training loss: 2.043130725982101
Validation loss: 2.4138571807228373

Epoch: 6| Step: 11
Training loss: 1.884261970229945
Validation loss: 2.413385158354698

Epoch: 6| Step: 12
Training loss: 1.8153795191259359
Validation loss: 2.405976003264519

Epoch: 6| Step: 13
Training loss: 2.199849392330754
Validation loss: 2.4169558374002693

Epoch: 57| Step: 0
Training loss: 2.131584848181357
Validation loss: 2.4438978822001203

Epoch: 6| Step: 1
Training loss: 2.102616963801554
Validation loss: 2.4204234870039225

Epoch: 6| Step: 2
Training loss: 2.509866889068479
Validation loss: 2.4451608986625204

Epoch: 6| Step: 3
Training loss: 2.7895671484099966
Validation loss: 2.4632516143142076

Epoch: 6| Step: 4
Training loss: 1.8439465434172622
Validation loss: 2.45891393389413

Epoch: 6| Step: 5
Training loss: 2.257375285441322
Validation loss: 2.471668144409122

Epoch: 6| Step: 6
Training loss: 2.642957390905423
Validation loss: 2.4714657457177234

Epoch: 6| Step: 7
Training loss: 1.934328744856021
Validation loss: 2.4522459232829097

Epoch: 6| Step: 8
Training loss: 2.276979184946406
Validation loss: 2.467780989391434

Epoch: 6| Step: 9
Training loss: 2.3530649853838406
Validation loss: 2.4872400649599515

Epoch: 6| Step: 10
Training loss: 1.9678194177901855
Validation loss: 2.4745298562023157

Epoch: 6| Step: 11
Training loss: 2.5668041089237112
Validation loss: 2.432821683023117

Epoch: 6| Step: 12
Training loss: 2.6363728614275024
Validation loss: 2.4527807945884774

Epoch: 6| Step: 13
Training loss: 1.7583971873737294
Validation loss: 2.4438548430630256

Epoch: 58| Step: 0
Training loss: 1.2753740809070058
Validation loss: 2.4091276903627157

Epoch: 6| Step: 1
Training loss: 2.264702971058046
Validation loss: 2.431788502068848

Epoch: 6| Step: 2
Training loss: 1.9259894144395189
Validation loss: 2.4123642265576972

Epoch: 6| Step: 3
Training loss: 2.526594519662934
Validation loss: 2.4242189447302684

Epoch: 6| Step: 4
Training loss: 2.340905459705038
Validation loss: 2.415258792229557

Epoch: 6| Step: 5
Training loss: 2.3904563495262736
Validation loss: 2.408147006323311

Epoch: 6| Step: 6
Training loss: 3.0159831254421268
Validation loss: 2.401124921060053

Epoch: 6| Step: 7
Training loss: 2.4330971886304273
Validation loss: 2.4296579062733548

Epoch: 6| Step: 8
Training loss: 2.0685709988233065
Validation loss: 2.424074999060812

Epoch: 6| Step: 9
Training loss: 1.7183686266782514
Validation loss: 2.421884335735745

Epoch: 6| Step: 10
Training loss: 2.7063992465758733
Validation loss: 2.417901288284427

Epoch: 6| Step: 11
Training loss: 2.2505295448219957
Validation loss: 2.4198146464821786

Epoch: 6| Step: 12
Training loss: 2.1093675401343783
Validation loss: 2.4045418873490756

Epoch: 6| Step: 13
Training loss: 2.2708934694312757
Validation loss: 2.41628524357247

Epoch: 59| Step: 0
Training loss: 2.4211118418635205
Validation loss: 2.4160234702498684

Epoch: 6| Step: 1
Training loss: 2.1647486511289706
Validation loss: 2.427789238913122

Epoch: 6| Step: 2
Training loss: 2.291522790264854
Validation loss: 2.4314686337764

Epoch: 6| Step: 3
Training loss: 1.8797765290572004
Validation loss: 2.45335685136483

Epoch: 6| Step: 4
Training loss: 2.653750421611161
Validation loss: 2.4330000788527544

Epoch: 6| Step: 5
Training loss: 2.1623559275356667
Validation loss: 2.450089303484577

Epoch: 6| Step: 6
Training loss: 2.015700701097822
Validation loss: 2.459105505066925

Epoch: 6| Step: 7
Training loss: 2.1012793140987647
Validation loss: 2.455595566374219

Epoch: 6| Step: 8
Training loss: 2.189311340260285
Validation loss: 2.441453824406263

Epoch: 6| Step: 9
Training loss: 2.075717075950991
Validation loss: 2.462622825347806

Epoch: 6| Step: 10
Training loss: 2.362808356774003
Validation loss: 2.43713491917307

Epoch: 6| Step: 11
Training loss: 2.6425152395453178
Validation loss: 2.442738682626809

Epoch: 6| Step: 12
Training loss: 2.2157409035049302
Validation loss: 2.4480893229745777

Epoch: 6| Step: 13
Training loss: 2.3534077346574804
Validation loss: 2.434161712352391

Epoch: 60| Step: 0
Training loss: 2.487198862221679
Validation loss: 2.430466113185648

Epoch: 6| Step: 1
Training loss: 2.067348445702191
Validation loss: 2.404126646501028

Epoch: 6| Step: 2
Training loss: 2.173190041227814
Validation loss: 2.416321061074976

Epoch: 6| Step: 3
Training loss: 1.7721826760527921
Validation loss: 2.420682650509215

Epoch: 6| Step: 4
Training loss: 2.363059697130428
Validation loss: 2.3980107792454817

Epoch: 6| Step: 5
Training loss: 2.262884337095312
Validation loss: 2.4156585487052804

Epoch: 6| Step: 6
Training loss: 2.0570727525603396
Validation loss: 2.4164592363410833

Epoch: 6| Step: 7
Training loss: 2.2535053075063907
Validation loss: 2.405222933661444

Epoch: 6| Step: 8
Training loss: 1.8965053694689504
Validation loss: 2.430294096068795

Epoch: 6| Step: 9
Training loss: 2.7895352686833466
Validation loss: 2.406502863160689

Epoch: 6| Step: 10
Training loss: 2.6508668993068243
Validation loss: 2.4088040623308276

Epoch: 6| Step: 11
Training loss: 1.7837977342427176
Validation loss: 2.4225008576309266

Epoch: 6| Step: 12
Training loss: 2.6665560778892914
Validation loss: 2.4128190411058776

Epoch: 6| Step: 13
Training loss: 1.9962576184876835
Validation loss: 2.4029489638758337

Epoch: 61| Step: 0
Training loss: 2.115086487789584
Validation loss: 2.4210929100032703

Epoch: 6| Step: 1
Training loss: 1.5660804162308934
Validation loss: 2.413629832583021

Epoch: 6| Step: 2
Training loss: 2.995717488800484
Validation loss: 2.4236975262479934

Epoch: 6| Step: 3
Training loss: 2.39807454199023
Validation loss: 2.4397045583166483

Epoch: 6| Step: 4
Training loss: 2.0958043737919736
Validation loss: 2.4062513211069154

Epoch: 6| Step: 5
Training loss: 1.8281772312625657
Validation loss: 2.440156499789338

Epoch: 6| Step: 6
Training loss: 2.4196214589493446
Validation loss: 2.4398291129842664

Epoch: 6| Step: 7
Training loss: 1.5384380022412707
Validation loss: 2.418357969807495

Epoch: 6| Step: 8
Training loss: 2.986284533844295
Validation loss: 2.4474362382126267

Epoch: 6| Step: 9
Training loss: 2.418158257226898
Validation loss: 2.4277099624515275

Epoch: 6| Step: 10
Training loss: 1.764274553337559
Validation loss: 2.449496945486911

Epoch: 6| Step: 11
Training loss: 2.14366157282633
Validation loss: 2.4516026659127323

Epoch: 6| Step: 12
Training loss: 2.6881943626297584
Validation loss: 2.451095308321292

Epoch: 6| Step: 13
Training loss: 1.7231571913719184
Validation loss: 2.4435410425683677

Epoch: 62| Step: 0
Training loss: 2.0059864334530055
Validation loss: 2.4519057432916984

Epoch: 6| Step: 1
Training loss: 2.6561939906778798
Validation loss: 2.4075301674642557

Epoch: 6| Step: 2
Training loss: 2.3767502007733627
Validation loss: 2.4355338554370833

Epoch: 6| Step: 3
Training loss: 2.26355538385281
Validation loss: 2.4209338584771736

Epoch: 6| Step: 4
Training loss: 2.0061893061788965
Validation loss: 2.399157056860997

Epoch: 6| Step: 5
Training loss: 2.430564991766157
Validation loss: 2.429869175831214

Epoch: 6| Step: 6
Training loss: 2.188242541035156
Validation loss: 2.410083516165673

Epoch: 6| Step: 7
Training loss: 2.249940871415452
Validation loss: 2.437206136481668

Epoch: 6| Step: 8
Training loss: 2.079221622553637
Validation loss: 2.4334963906102467

Epoch: 6| Step: 9
Training loss: 2.496267679808027
Validation loss: 2.413202356802748

Epoch: 6| Step: 10
Training loss: 2.2462646419364236
Validation loss: 2.393933004184912

Epoch: 6| Step: 11
Training loss: 1.8721960082264342
Validation loss: 2.410748162275452

Epoch: 6| Step: 12
Training loss: 1.9277751883502514
Validation loss: 2.4318967303897745

Epoch: 6| Step: 13
Training loss: 2.396356929011094
Validation loss: 2.420580364104345

Epoch: 63| Step: 0
Training loss: 1.8158406351172298
Validation loss: 2.416471281593858

Epoch: 6| Step: 1
Training loss: 1.4043875334740217
Validation loss: 2.4372439535266004

Epoch: 6| Step: 2
Training loss: 2.561111073782427
Validation loss: 2.4842526387725323

Epoch: 6| Step: 3
Training loss: 2.2308247778121295
Validation loss: 2.5136287184584427

Epoch: 6| Step: 4
Training loss: 2.296934788762651
Validation loss: 2.540149037601844

Epoch: 6| Step: 5
Training loss: 2.84193379180479
Validation loss: 2.5375723902080836

Epoch: 6| Step: 6
Training loss: 2.6741936867754452
Validation loss: 2.492700992248752

Epoch: 6| Step: 7
Training loss: 2.6799693501556017
Validation loss: 2.4572278193293804

Epoch: 6| Step: 8
Training loss: 2.1808504673254743
Validation loss: 2.4395972464599347

Epoch: 6| Step: 9
Training loss: 1.4592438534739036
Validation loss: 2.412358461355696

Epoch: 6| Step: 10
Training loss: 2.320075334443931
Validation loss: 2.407336860693593

Epoch: 6| Step: 11
Training loss: 2.2364980574765077
Validation loss: 2.4008625291926906

Epoch: 6| Step: 12
Training loss: 2.6690437530441615
Validation loss: 2.4392808782618274

Epoch: 6| Step: 13
Training loss: 2.018782633703677
Validation loss: 2.4025436855741296

Epoch: 64| Step: 0
Training loss: 1.9950022241871608
Validation loss: 2.4232513618597906

Epoch: 6| Step: 1
Training loss: 2.864992387638331
Validation loss: 2.4246075299485783

Epoch: 6| Step: 2
Training loss: 2.2869477903130355
Validation loss: 2.431698195096405

Epoch: 6| Step: 3
Training loss: 2.306617471835535
Validation loss: 2.4228544162178376

Epoch: 6| Step: 4
Training loss: 2.4340650368482715
Validation loss: 2.3985299456048863

Epoch: 6| Step: 5
Training loss: 2.333300272389478
Validation loss: 2.4025501772469924

Epoch: 6| Step: 6
Training loss: 2.853006744440974
Validation loss: 2.4246282535090686

Epoch: 6| Step: 7
Training loss: 1.4261679765015363
Validation loss: 2.407678386592987

Epoch: 6| Step: 8
Training loss: 2.1895785674367834
Validation loss: 2.422202008228164

Epoch: 6| Step: 9
Training loss: 1.873056867173067
Validation loss: 2.417965430368868

Epoch: 6| Step: 10
Training loss: 2.428767971692859
Validation loss: 2.427871728859506

Epoch: 6| Step: 11
Training loss: 1.7335992401297418
Validation loss: 2.432881389304885

Epoch: 6| Step: 12
Training loss: 2.2999956379724686
Validation loss: 2.4411791316884615

Epoch: 6| Step: 13
Training loss: 1.5272833380495703
Validation loss: 2.4580187892656093

Epoch: 65| Step: 0
Training loss: 2.6226487301379757
Validation loss: 2.47025610457053

Epoch: 6| Step: 1
Training loss: 2.3449140582573156
Validation loss: 2.449296997702381

Epoch: 6| Step: 2
Training loss: 1.2534473090309894
Validation loss: 2.4545123152095902

Epoch: 6| Step: 3
Training loss: 2.541217065870762
Validation loss: 2.4611667263912493

Epoch: 6| Step: 4
Training loss: 2.051883887911652
Validation loss: 2.428259099516433

Epoch: 6| Step: 5
Training loss: 1.7690780766725718
Validation loss: 2.4171397277806297

Epoch: 6| Step: 6
Training loss: 1.888625798260013
Validation loss: 2.428805175719947

Epoch: 6| Step: 7
Training loss: 2.4075763564315755
Validation loss: 2.4219301525111914

Epoch: 6| Step: 8
Training loss: 2.6805250454902922
Validation loss: 2.421253058858793

Epoch: 6| Step: 9
Training loss: 2.523302954520715
Validation loss: 2.397081155212923

Epoch: 6| Step: 10
Training loss: 1.9932367890026743
Validation loss: 2.4023177313494055

Epoch: 6| Step: 11
Training loss: 1.9393320343539513
Validation loss: 2.434081019098753

Epoch: 6| Step: 12
Training loss: 2.553621122046287
Validation loss: 2.436616737551715

Epoch: 6| Step: 13
Training loss: 1.8751992437676868
Validation loss: 2.417327237009833

Epoch: 66| Step: 0
Training loss: 2.4612719111825836
Validation loss: 2.4190195457496224

Epoch: 6| Step: 1
Training loss: 2.1951098365501083
Validation loss: 2.398148891053916

Epoch: 6| Step: 2
Training loss: 2.4241576235923676
Validation loss: 2.4103945753909035

Epoch: 6| Step: 3
Training loss: 2.195457263666987
Validation loss: 2.400253676875846

Epoch: 6| Step: 4
Training loss: 1.7481426873401678
Validation loss: 2.3979524169519415

Epoch: 6| Step: 5
Training loss: 2.546518218904999
Validation loss: 2.4251697402223997

Epoch: 6| Step: 6
Training loss: 1.7865452944514413
Validation loss: 2.415298211487356

Epoch: 6| Step: 7
Training loss: 2.233013885577874
Validation loss: 2.4022764036254847

Epoch: 6| Step: 8
Training loss: 2.2253187487021258
Validation loss: 2.40604594632886

Epoch: 6| Step: 9
Training loss: 1.8283929872937894
Validation loss: 2.411251361333035

Epoch: 6| Step: 10
Training loss: 2.4932120677541496
Validation loss: 2.3896409712616213

Epoch: 6| Step: 11
Training loss: 2.693598282296449
Validation loss: 2.4124151574008796

Epoch: 6| Step: 12
Training loss: 1.7315724730122686
Validation loss: 2.41195727652579

Epoch: 6| Step: 13
Training loss: 1.9910631784467328
Validation loss: 2.4169041390870074

Epoch: 67| Step: 0
Training loss: 2.1056254652367583
Validation loss: 2.4403272762234702

Epoch: 6| Step: 1
Training loss: 1.9911741783711592
Validation loss: 2.4670492261133066

Epoch: 6| Step: 2
Training loss: 1.8849255113530639
Validation loss: 2.4787645548131714

Epoch: 6| Step: 3
Training loss: 2.2827611647205344
Validation loss: 2.472755080623882

Epoch: 6| Step: 4
Training loss: 2.224817924336226
Validation loss: 2.52926579950947

Epoch: 6| Step: 5
Training loss: 1.9847464026166126
Validation loss: 2.5409399202618568

Epoch: 6| Step: 6
Training loss: 2.852390618462943
Validation loss: 2.533157807049946

Epoch: 6| Step: 7
Training loss: 2.024596718084895
Validation loss: 2.4938429592847333

Epoch: 6| Step: 8
Training loss: 2.037321085183207
Validation loss: 2.466131423107827

Epoch: 6| Step: 9
Training loss: 2.273128108310121
Validation loss: 2.4654350236582463

Epoch: 6| Step: 10
Training loss: 2.2377400701015056
Validation loss: 2.403089652526987

Epoch: 6| Step: 11
Training loss: 2.17599710869597
Validation loss: 2.3987858091712675

Epoch: 6| Step: 12
Training loss: 2.269262826511586
Validation loss: 2.3907592170620364

Epoch: 6| Step: 13
Training loss: 2.20485127230741
Validation loss: 2.420708537427847

Epoch: 68| Step: 0
Training loss: 1.8511502736576633
Validation loss: 2.397548962418963

Epoch: 6| Step: 1
Training loss: 2.427349277928359
Validation loss: 2.4131023551025295

Epoch: 6| Step: 2
Training loss: 2.3818071089122523
Validation loss: 2.4295675201067137

Epoch: 6| Step: 3
Training loss: 2.312016204539603
Validation loss: 2.4509667785677847

Epoch: 6| Step: 4
Training loss: 2.4738682673606833
Validation loss: 2.4177040361932987

Epoch: 6| Step: 5
Training loss: 2.607478749087117
Validation loss: 2.400183209075654

Epoch: 6| Step: 6
Training loss: 2.381172791678623
Validation loss: 2.4017873807250685

Epoch: 6| Step: 7
Training loss: 1.9215018057376696
Validation loss: 2.392244011003639

Epoch: 6| Step: 8
Training loss: 1.5492641609681046
Validation loss: 2.41636050411533

Epoch: 6| Step: 9
Training loss: 1.5286366485718357
Validation loss: 2.4020888940284153

Epoch: 6| Step: 10
Training loss: 2.4850850560082853
Validation loss: 2.423125487688219

Epoch: 6| Step: 11
Training loss: 1.196885862375873
Validation loss: 2.420749435568665

Epoch: 6| Step: 12
Training loss: 2.4664328601792453
Validation loss: 2.4300946858355874

Epoch: 6| Step: 13
Training loss: 2.6234498669512893
Validation loss: 2.4674783320636666

Epoch: 69| Step: 0
Training loss: 1.9964312661842742
Validation loss: 2.427082386480537

Epoch: 6| Step: 1
Training loss: 1.8112630240509828
Validation loss: 2.455480768633712

Epoch: 6| Step: 2
Training loss: 2.5393836185159784
Validation loss: 2.4033366976100248

Epoch: 6| Step: 3
Training loss: 2.4554743117082256
Validation loss: 2.4160564134424094

Epoch: 6| Step: 4
Training loss: 1.675307698242046
Validation loss: 2.4161147495865247

Epoch: 6| Step: 5
Training loss: 1.832338612359691
Validation loss: 2.4162510700884567

Epoch: 6| Step: 6
Training loss: 1.9903044533862626
Validation loss: 2.405385881966263

Epoch: 6| Step: 7
Training loss: 2.3918900477422205
Validation loss: 2.3941916991997716

Epoch: 6| Step: 8
Training loss: 1.94865785528943
Validation loss: 2.4027906379527058

Epoch: 6| Step: 9
Training loss: 2.577336601161842
Validation loss: 2.4121219361836608

Epoch: 6| Step: 10
Training loss: 2.520703514686695
Validation loss: 2.40136060161807

Epoch: 6| Step: 11
Training loss: 2.3892930253295996
Validation loss: 2.4178953390732776

Epoch: 6| Step: 12
Training loss: 1.8479979120548227
Validation loss: 2.4049007051078477

Epoch: 6| Step: 13
Training loss: 2.247707682721517
Validation loss: 2.4127206210652568

Epoch: 70| Step: 0
Training loss: 2.4818390192763387
Validation loss: 2.3930483235359197

Epoch: 6| Step: 1
Training loss: 2.2220512867458653
Validation loss: 2.424472179191073

Epoch: 6| Step: 2
Training loss: 1.8054350918744433
Validation loss: 2.386743007438829

Epoch: 6| Step: 3
Training loss: 1.9940606978312199
Validation loss: 2.3979330536795844

Epoch: 6| Step: 4
Training loss: 2.0976610236939397
Validation loss: 2.404893021851172

Epoch: 6| Step: 5
Training loss: 2.184739687360002
Validation loss: 2.4368144318341747

Epoch: 6| Step: 6
Training loss: 2.170834957812892
Validation loss: 2.459523015494085

Epoch: 6| Step: 7
Training loss: 1.6107423769628237
Validation loss: 2.4524841362391188

Epoch: 6| Step: 8
Training loss: 1.621709720370688
Validation loss: 2.4867785041637616

Epoch: 6| Step: 9
Training loss: 1.7059472873991868
Validation loss: 2.499596912948909

Epoch: 6| Step: 10
Training loss: 2.096158023606622
Validation loss: 2.5195818834367403

Epoch: 6| Step: 11
Training loss: 2.5728550541922903
Validation loss: 2.5259913777068057

Epoch: 6| Step: 12
Training loss: 2.5167063408896984
Validation loss: 2.490017255904576

Epoch: 6| Step: 13
Training loss: 2.747600722544996
Validation loss: 2.434700099537248

Epoch: 71| Step: 0
Training loss: 2.1507309757762765
Validation loss: 2.4071471618391773

Epoch: 6| Step: 1
Training loss: 2.4502283962991616
Validation loss: 2.403682924744216

Epoch: 6| Step: 2
Training loss: 1.9603026072785985
Validation loss: 2.3944317463564917

Epoch: 6| Step: 3
Training loss: 2.0177237060255355
Validation loss: 2.4068932849998776

Epoch: 6| Step: 4
Training loss: 2.0545649618878414
Validation loss: 2.403444330621309

Epoch: 6| Step: 5
Training loss: 1.9390424925627254
Validation loss: 2.3869751970919992

Epoch: 6| Step: 6
Training loss: 2.0222837480098086
Validation loss: 2.390232826926897

Epoch: 6| Step: 7
Training loss: 2.16427853604232
Validation loss: 2.3729511592279384

Epoch: 6| Step: 8
Training loss: 1.9702910189928609
Validation loss: 2.434613825876767

Epoch: 6| Step: 9
Training loss: 2.5328414058741995
Validation loss: 2.4265631553516376

Epoch: 6| Step: 10
Training loss: 2.566398539306577
Validation loss: 2.4109562350435416

Epoch: 6| Step: 11
Training loss: 2.6007642466389487
Validation loss: 2.4255283651848654

Epoch: 6| Step: 12
Training loss: 1.793387303916972
Validation loss: 2.3879542838959735

Epoch: 6| Step: 13
Training loss: 1.760983738804115
Validation loss: 2.392496544102346

Epoch: 72| Step: 0
Training loss: 2.0349556792960426
Validation loss: 2.4086622226982746

Epoch: 6| Step: 1
Training loss: 2.344247790561451
Validation loss: 2.4228045740764257

Epoch: 6| Step: 2
Training loss: 2.1038823706811858
Validation loss: 2.413422533655939

Epoch: 6| Step: 3
Training loss: 2.033695216364228
Validation loss: 2.379008474173732

Epoch: 6| Step: 4
Training loss: 2.507874675229549
Validation loss: 2.4029614158482233

Epoch: 6| Step: 5
Training loss: 2.1251248715680404
Validation loss: 2.3774463619301445

Epoch: 6| Step: 6
Training loss: 2.1954557433179835
Validation loss: 2.399485273265803

Epoch: 6| Step: 7
Training loss: 2.0616869624420473
Validation loss: 2.388356730481171

Epoch: 6| Step: 8
Training loss: 2.0496354453491934
Validation loss: 2.3905016300057826

Epoch: 6| Step: 9
Training loss: 2.1998588213271213
Validation loss: 2.3859269930298628

Epoch: 6| Step: 10
Training loss: 1.7345150040488637
Validation loss: 2.413007182502517

Epoch: 6| Step: 11
Training loss: 2.587951244867837
Validation loss: 2.3862666624355717

Epoch: 6| Step: 12
Training loss: 1.5982567887313446
Validation loss: 2.4010872302141952

Epoch: 6| Step: 13
Training loss: 1.7766286899713792
Validation loss: 2.394535232714877

Epoch: 73| Step: 0
Training loss: 2.3534329601664985
Validation loss: 2.4216978274933383

Epoch: 6| Step: 1
Training loss: 2.3851406043170833
Validation loss: 2.3876348008053077

Epoch: 6| Step: 2
Training loss: 2.0735010317028784
Validation loss: 2.3979239395477627

Epoch: 6| Step: 3
Training loss: 1.9495204776100326
Validation loss: 2.4343040739997486

Epoch: 6| Step: 4
Training loss: 2.0576748905500586
Validation loss: 2.411249342582617

Epoch: 6| Step: 5
Training loss: 1.5869370491123644
Validation loss: 2.3990447842227627

Epoch: 6| Step: 6
Training loss: 1.7152357761253103
Validation loss: 2.3838147333000874

Epoch: 6| Step: 7
Training loss: 2.196933134565981
Validation loss: 2.4243331001990054

Epoch: 6| Step: 8
Training loss: 1.868728193583251
Validation loss: 2.4244923138833934

Epoch: 6| Step: 9
Training loss: 2.7881122754885572
Validation loss: 2.4497529521609933

Epoch: 6| Step: 10
Training loss: 1.6137758101948574
Validation loss: 2.392511525167876

Epoch: 6| Step: 11
Training loss: 2.2209225615802395
Validation loss: 2.4183747870425982

Epoch: 6| Step: 12
Training loss: 1.7602365691327213
Validation loss: 2.41808808935566

Epoch: 6| Step: 13
Training loss: 2.4038236200303507
Validation loss: 2.4081127668529243

Epoch: 74| Step: 0
Training loss: 2.003390061669663
Validation loss: 2.446869936142477

Epoch: 6| Step: 1
Training loss: 1.8175835188575133
Validation loss: 2.390617719651649

Epoch: 6| Step: 2
Training loss: 2.628640330045404
Validation loss: 2.4367612876819815

Epoch: 6| Step: 3
Training loss: 1.9943295201609366
Validation loss: 2.44594227863919

Epoch: 6| Step: 4
Training loss: 2.3227383555127696
Validation loss: 2.405639678376431

Epoch: 6| Step: 5
Training loss: 2.4637255179990225
Validation loss: 2.4284340097646666

Epoch: 6| Step: 6
Training loss: 2.2505761574464236
Validation loss: 2.446111457148998

Epoch: 6| Step: 7
Training loss: 2.075129249867585
Validation loss: 2.4290183843783586

Epoch: 6| Step: 8
Training loss: 2.2320149368688735
Validation loss: 2.4136601331863234

Epoch: 6| Step: 9
Training loss: 1.6849753249537884
Validation loss: 2.398998571785293

Epoch: 6| Step: 10
Training loss: 2.0676007631187927
Validation loss: 2.4122296796236635

Epoch: 6| Step: 11
Training loss: 1.97879396911467
Validation loss: 2.3812526078764753

Epoch: 6| Step: 12
Training loss: 1.9772549950293847
Validation loss: 2.4051168176271824

Epoch: 6| Step: 13
Training loss: 1.4955065498680513
Validation loss: 2.385696916623027

Epoch: 75| Step: 0
Training loss: 2.3754565151556672
Validation loss: 2.395369299579928

Epoch: 6| Step: 1
Training loss: 1.9998315501800292
Validation loss: 2.3904053913382697

Epoch: 6| Step: 2
Training loss: 2.0448203221038077
Validation loss: 2.3974134680042565

Epoch: 6| Step: 3
Training loss: 1.4659198521332666
Validation loss: 2.379563481452848

Epoch: 6| Step: 4
Training loss: 2.6065583702999557
Validation loss: 2.418523475231777

Epoch: 6| Step: 5
Training loss: 2.22349438678298
Validation loss: 2.394183384082009

Epoch: 6| Step: 6
Training loss: 2.4010529314440254
Validation loss: 2.416107340464463

Epoch: 6| Step: 7
Training loss: 1.6932282886563477
Validation loss: 2.4146919870053085

Epoch: 6| Step: 8
Training loss: 2.4473987978467884
Validation loss: 2.4136484196322674

Epoch: 6| Step: 9
Training loss: 1.2289756313946794
Validation loss: 2.4130549627621742

Epoch: 6| Step: 10
Training loss: 1.8669856133910434
Validation loss: 2.4493153708674407

Epoch: 6| Step: 11
Training loss: 1.998025157582975
Validation loss: 2.4662862144939663

Epoch: 6| Step: 12
Training loss: 2.289209875368597
Validation loss: 2.5221594377882677

Epoch: 6| Step: 13
Training loss: 1.8585549477579213
Validation loss: 2.519201212713532

Epoch: 76| Step: 0
Training loss: 2.737332472182168
Validation loss: 2.5168332343736695

Epoch: 6| Step: 1
Training loss: 2.402882089231037
Validation loss: 2.527722494920498

Epoch: 6| Step: 2
Training loss: 2.959429918240843
Validation loss: 2.4726331086002413

Epoch: 6| Step: 3
Training loss: 1.80051974634107
Validation loss: 2.4218569354952555

Epoch: 6| Step: 4
Training loss: 1.5816607759698977
Validation loss: 2.387124684178122

Epoch: 6| Step: 5
Training loss: 2.3814042729743163
Validation loss: 2.4244606080183195

Epoch: 6| Step: 6
Training loss: 1.3073618541989958
Validation loss: 2.4262934915351515

Epoch: 6| Step: 7
Training loss: 1.7659967081853616
Validation loss: 2.438709056985688

Epoch: 6| Step: 8
Training loss: 2.1545536168408055
Validation loss: 2.4888410272944483

Epoch: 6| Step: 9
Training loss: 2.205026333710039
Validation loss: 2.467345695424782

Epoch: 6| Step: 10
Training loss: 2.0148771806112644
Validation loss: 2.4466001067952226

Epoch: 6| Step: 11
Training loss: 2.281293999234558
Validation loss: 2.4287074853013344

Epoch: 6| Step: 12
Training loss: 2.3661733538531404
Validation loss: 2.403401740930784

Epoch: 6| Step: 13
Training loss: 2.2289081197758214
Validation loss: 2.423350526621019

Epoch: 77| Step: 0
Training loss: 1.857717721124007
Validation loss: 2.444615761456366

Epoch: 6| Step: 1
Training loss: 2.8662437112159465
Validation loss: 2.532687293253937

Epoch: 6| Step: 2
Training loss: 2.195156322639177
Validation loss: 2.5218703498781703

Epoch: 6| Step: 3
Training loss: 1.9467178232295042
Validation loss: 2.496147891448923

Epoch: 6| Step: 4
Training loss: 2.0068798942114197
Validation loss: 2.482713123506948

Epoch: 6| Step: 5
Training loss: 2.71924183222463
Validation loss: 2.470885065790507

Epoch: 6| Step: 6
Training loss: 2.2774066687344496
Validation loss: 2.4412334411497034

Epoch: 6| Step: 7
Training loss: 2.1277150032249925
Validation loss: 2.4436200493540237

Epoch: 6| Step: 8
Training loss: 1.0946527297944475
Validation loss: 2.4243504742408435

Epoch: 6| Step: 9
Training loss: 2.3291218306901134
Validation loss: 2.3698418804060806

Epoch: 6| Step: 10
Training loss: 1.9318551309897303
Validation loss: 2.388306484519609

Epoch: 6| Step: 11
Training loss: 2.013625224893074
Validation loss: 2.40902979579956

Epoch: 6| Step: 12
Training loss: 2.10179233357836
Validation loss: 2.414631625250167

Epoch: 6| Step: 13
Training loss: 1.859339737758136
Validation loss: 2.386460926637832

Epoch: 78| Step: 0
Training loss: 2.003598790070573
Validation loss: 2.371650215725419

Epoch: 6| Step: 1
Training loss: 1.9441965111595914
Validation loss: 2.4217300207572037

Epoch: 6| Step: 2
Training loss: 1.5821454795759082
Validation loss: 2.39802113583572

Epoch: 6| Step: 3
Training loss: 2.0378826133156682
Validation loss: 2.4155396568550507

Epoch: 6| Step: 4
Training loss: 1.7268656468837074
Validation loss: 2.403559497565306

Epoch: 6| Step: 5
Training loss: 2.133815431759262
Validation loss: 2.4032884843938676

Epoch: 6| Step: 6
Training loss: 1.6144224845586987
Validation loss: 2.4223927344400327

Epoch: 6| Step: 7
Training loss: 2.7553469954117418
Validation loss: 2.41787739274544

Epoch: 6| Step: 8
Training loss: 2.149829981979044
Validation loss: 2.4069093073458006

Epoch: 6| Step: 9
Training loss: 1.814846690089734
Validation loss: 2.4075680380265583

Epoch: 6| Step: 10
Training loss: 1.543040599840175
Validation loss: 2.390083052097961

Epoch: 6| Step: 11
Training loss: 2.434185611277194
Validation loss: 2.41808348811264

Epoch: 6| Step: 12
Training loss: 2.37868765592438
Validation loss: 2.411701039128858

Epoch: 6| Step: 13
Training loss: 2.048983819825987
Validation loss: 2.423003100107865

Epoch: 79| Step: 0
Training loss: 1.8985331946849917
Validation loss: 2.4665254316191048

Epoch: 6| Step: 1
Training loss: 1.998250016879546
Validation loss: 2.4262317478725657

Epoch: 6| Step: 2
Training loss: 2.4175562591476125
Validation loss: 2.422151020687315

Epoch: 6| Step: 3
Training loss: 2.36468222211065
Validation loss: 2.413807358576347

Epoch: 6| Step: 4
Training loss: 2.449763138668184
Validation loss: 2.4716724449402276

Epoch: 6| Step: 5
Training loss: 2.061345441932366
Validation loss: 2.3953291873968556

Epoch: 6| Step: 6
Training loss: 2.0390686970466776
Validation loss: 2.4001567199983382

Epoch: 6| Step: 7
Training loss: 1.3049669708807659
Validation loss: 2.3863185832214335

Epoch: 6| Step: 8
Training loss: 1.692500652386358
Validation loss: 2.4210692511245613

Epoch: 6| Step: 9
Training loss: 2.4250080147836908
Validation loss: 2.4396651017851627

Epoch: 6| Step: 10
Training loss: 1.746137921416788
Validation loss: 2.436897415275893

Epoch: 6| Step: 11
Training loss: 1.7124790580192983
Validation loss: 2.392621073434676

Epoch: 6| Step: 12
Training loss: 1.942785253016184
Validation loss: 2.3781946680839603

Epoch: 6| Step: 13
Training loss: 1.678840743145319
Validation loss: 2.355569359700923

Epoch: 80| Step: 0
Training loss: 1.932974051382763
Validation loss: 2.405200580789841

Epoch: 6| Step: 1
Training loss: 2.162414143351861
Validation loss: 2.382585133195354

Epoch: 6| Step: 2
Training loss: 2.216103062887499
Validation loss: 2.4190023962479206

Epoch: 6| Step: 3
Training loss: 1.4434363482731454
Validation loss: 2.387265406562163

Epoch: 6| Step: 4
Training loss: 2.21805432656077
Validation loss: 2.407830813117733

Epoch: 6| Step: 5
Training loss: 1.7647237587472124
Validation loss: 2.3860829740125293

Epoch: 6| Step: 6
Training loss: 2.419457194716499
Validation loss: 2.410428180738516

Epoch: 6| Step: 7
Training loss: 2.2973909382467816
Validation loss: 2.4048142629239995

Epoch: 6| Step: 8
Training loss: 1.7239776179991608
Validation loss: 2.4203036881728273

Epoch: 6| Step: 9
Training loss: 1.777057465353458
Validation loss: 2.3958785066630535

Epoch: 6| Step: 10
Training loss: 2.10195624197612
Validation loss: 2.395957633954243

Epoch: 6| Step: 11
Training loss: 1.522359613419911
Validation loss: 2.4174463285992767

Epoch: 6| Step: 12
Training loss: 2.2826497212468775
Validation loss: 2.373447596830079

Epoch: 6| Step: 13
Training loss: 1.7247283998157807
Validation loss: 2.4153273313105394

Epoch: 81| Step: 0
Training loss: 1.4610208905741533
Validation loss: 2.3894548315624484

Epoch: 6| Step: 1
Training loss: 1.7437356818373573
Validation loss: 2.4291111793091527

Epoch: 6| Step: 2
Training loss: 1.4943683126659728
Validation loss: 2.386933029387035

Epoch: 6| Step: 3
Training loss: 1.6546579302486188
Validation loss: 2.416475096596552

Epoch: 6| Step: 4
Training loss: 1.8608586779091474
Validation loss: 2.470483453004083

Epoch: 6| Step: 5
Training loss: 2.502088056226895
Validation loss: 2.467916412297685

Epoch: 6| Step: 6
Training loss: 1.8467004735493973
Validation loss: 2.4760646379812425

Epoch: 6| Step: 7
Training loss: 1.8277030523086109
Validation loss: 2.490731925376262

Epoch: 6| Step: 8
Training loss: 1.925314639746157
Validation loss: 2.4658928123366173

Epoch: 6| Step: 9
Training loss: 2.9684721164148766
Validation loss: 2.440568158557894

Epoch: 6| Step: 10
Training loss: 2.304419033125424
Validation loss: 2.3966076525645605

Epoch: 6| Step: 11
Training loss: 2.244083041920607
Validation loss: 2.407427289227227

Epoch: 6| Step: 12
Training loss: 1.5648435184137683
Validation loss: 2.389383429957194

Epoch: 6| Step: 13
Training loss: 1.8088967911867642
Validation loss: 2.4070838540303194

Epoch: 82| Step: 0
Training loss: 2.364872672462094
Validation loss: 2.4289833839416692

Epoch: 6| Step: 1
Training loss: 1.7772728539045297
Validation loss: 2.4051131250419306

Epoch: 6| Step: 2
Training loss: 1.9205372814600994
Validation loss: 2.435651175828413

Epoch: 6| Step: 3
Training loss: 2.315315285587167
Validation loss: 2.4208477015460117

Epoch: 6| Step: 4
Training loss: 1.8188095764679875
Validation loss: 2.4052691751954214

Epoch: 6| Step: 5
Training loss: 2.0765828311748664
Validation loss: 2.391246440623576

Epoch: 6| Step: 6
Training loss: 1.9206879213890082
Validation loss: 2.3802059237567437

Epoch: 6| Step: 7
Training loss: 1.6050228047162
Validation loss: 2.4035387659387397

Epoch: 6| Step: 8
Training loss: 2.2900638408174414
Validation loss: 2.420894038565823

Epoch: 6| Step: 9
Training loss: 1.4570445042229756
Validation loss: 2.4628347682442295

Epoch: 6| Step: 10
Training loss: 2.4805057552911403
Validation loss: 2.4655102585853945

Epoch: 6| Step: 11
Training loss: 1.7921448520418413
Validation loss: 2.469834270670267

Epoch: 6| Step: 12
Training loss: 1.7991312208596197
Validation loss: 2.4569430433975787

Epoch: 6| Step: 13
Training loss: 1.8369816185120358
Validation loss: 2.5137833988216256

Epoch: 83| Step: 0
Training loss: 1.7342567059839689
Validation loss: 2.4792271668133856

Epoch: 6| Step: 1
Training loss: 2.0181258899146863
Validation loss: 2.501296215987121

Epoch: 6| Step: 2
Training loss: 1.783271980418646
Validation loss: 2.4690274754650336

Epoch: 6| Step: 3
Training loss: 1.5528159066153484
Validation loss: 2.47534383960648

Epoch: 6| Step: 4
Training loss: 2.0209257229269686
Validation loss: 2.4564643533373163

Epoch: 6| Step: 5
Training loss: 1.8528647048603446
Validation loss: 2.4165092175812597

Epoch: 6| Step: 6
Training loss: 1.9390303197952334
Validation loss: 2.4176473491252315

Epoch: 6| Step: 7
Training loss: 2.279861550226659
Validation loss: 2.403860284421421

Epoch: 6| Step: 8
Training loss: 2.12151488449194
Validation loss: 2.3843396405439212

Epoch: 6| Step: 9
Training loss: 1.7321625077786096
Validation loss: 2.404151017541932

Epoch: 6| Step: 10
Training loss: 1.9770247932774243
Validation loss: 2.399006621757783

Epoch: 6| Step: 11
Training loss: 1.9704255739417937
Validation loss: 2.39023446443976

Epoch: 6| Step: 12
Training loss: 2.300920103381157
Validation loss: 2.4287957193413976

Epoch: 6| Step: 13
Training loss: 1.7339475637689123
Validation loss: 2.407091282672994

Epoch: 84| Step: 0
Training loss: 1.5552719781129345
Validation loss: 2.396743242272239

Epoch: 6| Step: 1
Training loss: 1.6040901892461021
Validation loss: 2.390161506750293

Epoch: 6| Step: 2
Training loss: 2.1630966289591873
Validation loss: 2.3549050014446355

Epoch: 6| Step: 3
Training loss: 1.49247866680803
Validation loss: 2.4072339576880997

Epoch: 6| Step: 4
Training loss: 1.6285271878196863
Validation loss: 2.4001561571022734

Epoch: 6| Step: 5
Training loss: 2.2218573933049983
Validation loss: 2.419856733831382

Epoch: 6| Step: 6
Training loss: 1.719460912545833
Validation loss: 2.404357198727484

Epoch: 6| Step: 7
Training loss: 1.8181124641455748
Validation loss: 2.4383434238429302

Epoch: 6| Step: 8
Training loss: 1.157244847149192
Validation loss: 2.407921808935579

Epoch: 6| Step: 9
Training loss: 2.0040192748796994
Validation loss: 2.4017686770674427

Epoch: 6| Step: 10
Training loss: 2.4726350370584935
Validation loss: 2.4082726403830783

Epoch: 6| Step: 11
Training loss: 2.3057523691925614
Validation loss: 2.3781574826856433

Epoch: 6| Step: 12
Training loss: 2.0188454620182594
Validation loss: 2.425600103473158

Epoch: 6| Step: 13
Training loss: 2.054049548768872
Validation loss: 2.418713629003104

Epoch: 85| Step: 0
Training loss: 1.5416221440390168
Validation loss: 2.392832565791428

Epoch: 6| Step: 1
Training loss: 1.7326931058376536
Validation loss: 2.3968805484632907

Epoch: 6| Step: 2
Training loss: 1.946109103062243
Validation loss: 2.411872141674016

Epoch: 6| Step: 3
Training loss: 1.5117009282601785
Validation loss: 2.3685075627434995

Epoch: 6| Step: 4
Training loss: 1.6951615226776824
Validation loss: 2.423593022504585

Epoch: 6| Step: 5
Training loss: 1.3181758046386736
Validation loss: 2.4514722662828814

Epoch: 6| Step: 6
Training loss: 2.090070423418171
Validation loss: 2.409550389207515

Epoch: 6| Step: 7
Training loss: 1.8401065322885244
Validation loss: 2.407682867436743

Epoch: 6| Step: 8
Training loss: 2.647675080962652
Validation loss: 2.4213998307908158

Epoch: 6| Step: 9
Training loss: 1.7505813722849934
Validation loss: 2.388718919350548

Epoch: 6| Step: 10
Training loss: 2.4403741959227254
Validation loss: 2.3965685725221175

Epoch: 6| Step: 11
Training loss: 2.0495328463965277
Validation loss: 2.4305217083587554

Epoch: 6| Step: 12
Training loss: 2.059258196330133
Validation loss: 2.4373460704747507

Epoch: 6| Step: 13
Training loss: 1.924989177623894
Validation loss: 2.3984709083972304

Epoch: 86| Step: 0
Training loss: 2.444772874077008
Validation loss: 2.3719806803403816

Epoch: 6| Step: 1
Training loss: 1.134131985110048
Validation loss: 2.3786454665922467

Epoch: 6| Step: 2
Training loss: 1.5418738234584666
Validation loss: 2.418279854805149

Epoch: 6| Step: 3
Training loss: 1.9444097546101855
Validation loss: 2.398223502918433

Epoch: 6| Step: 4
Training loss: 1.7509220282875122
Validation loss: 2.4335170384741893

Epoch: 6| Step: 5
Training loss: 1.9136940114846692
Validation loss: 2.46554300794789

Epoch: 6| Step: 6
Training loss: 1.9080528114175581
Validation loss: 2.459949097119637

Epoch: 6| Step: 7
Training loss: 1.6731334477732542
Validation loss: 2.4745835380941643

Epoch: 6| Step: 8
Training loss: 2.282924821141326
Validation loss: 2.5025698169543396

Epoch: 6| Step: 9
Training loss: 1.517306073914913
Validation loss: 2.4675902527726548

Epoch: 6| Step: 10
Training loss: 2.122035707840262
Validation loss: 2.4375323921072773

Epoch: 6| Step: 11
Training loss: 1.9314453520009602
Validation loss: 2.4505335976041533

Epoch: 6| Step: 12
Training loss: 2.0212730112930415
Validation loss: 2.4012692744235937

Epoch: 6| Step: 13
Training loss: 2.136442232807509
Validation loss: 2.3976035392289616

Epoch: 87| Step: 0
Training loss: 1.7050932264150842
Validation loss: 2.406480835910761

Epoch: 6| Step: 1
Training loss: 2.2321534750549636
Validation loss: 2.3951008934850617

Epoch: 6| Step: 2
Training loss: 1.4084709854495876
Validation loss: 2.4367774316249426

Epoch: 6| Step: 3
Training loss: 2.3437443033784935
Validation loss: 2.3984829031657195

Epoch: 6| Step: 4
Training loss: 1.8265008477084503
Validation loss: 2.366992157617837

Epoch: 6| Step: 5
Training loss: 1.9269508385001892
Validation loss: 2.4215177703243187

Epoch: 6| Step: 6
Training loss: 1.4508540959472978
Validation loss: 2.4582907516757193

Epoch: 6| Step: 7
Training loss: 2.254550147680952
Validation loss: 2.456553345472994

Epoch: 6| Step: 8
Training loss: 2.2791924800027044
Validation loss: 2.49913472460357

Epoch: 6| Step: 9
Training loss: 1.8847066761344902
Validation loss: 2.5204329106955212

Epoch: 6| Step: 10
Training loss: 1.4878627559168003
Validation loss: 2.4585722683239917

Epoch: 6| Step: 11
Training loss: 1.4390043596913435
Validation loss: 2.407350792042504

Epoch: 6| Step: 12
Training loss: 1.8931069594814847
Validation loss: 2.365254736764647

Epoch: 6| Step: 13
Training loss: 2.091012332086306
Validation loss: 2.4246355382614877

Epoch: 88| Step: 0
Training loss: 2.0937479503109135
Validation loss: 2.3677000743511023

Epoch: 6| Step: 1
Training loss: 2.05557127537029
Validation loss: 2.447759206590964

Epoch: 6| Step: 2
Training loss: 1.6820090640137944
Validation loss: 2.4027921263377205

Epoch: 6| Step: 3
Training loss: 1.81104878173376
Validation loss: 2.426472850419983

Epoch: 6| Step: 4
Training loss: 1.5916954710319628
Validation loss: 2.4332084207828784

Epoch: 6| Step: 5
Training loss: 1.7381698744165086
Validation loss: 2.4316071412259146

Epoch: 6| Step: 6
Training loss: 1.585468091226796
Validation loss: 2.4516366059590946

Epoch: 6| Step: 7
Training loss: 2.190429469808839
Validation loss: 2.388503153163699

Epoch: 6| Step: 8
Training loss: 1.6341506366374723
Validation loss: 2.4101419391753347

Epoch: 6| Step: 9
Training loss: 2.0154789125006043
Validation loss: 2.4058148209384056

Epoch: 6| Step: 10
Training loss: 1.1264394452191948
Validation loss: 2.5226958674091002

Epoch: 6| Step: 11
Training loss: 2.115423502264524
Validation loss: 2.600974206402265

Epoch: 6| Step: 12
Training loss: 2.3177069731861937
Validation loss: 2.652771710649069

Epoch: 6| Step: 13
Training loss: 2.3285646983458124
Validation loss: 2.6702677333673783

Epoch: 89| Step: 0
Training loss: 2.7458799884018177
Validation loss: 2.606095032388119

Epoch: 6| Step: 1
Training loss: 1.575043568689728
Validation loss: 2.5387831157638763

Epoch: 6| Step: 2
Training loss: 2.0944703414467227
Validation loss: 2.4937166726443643

Epoch: 6| Step: 3
Training loss: 2.169681566667912
Validation loss: 2.3920199743572375

Epoch: 6| Step: 4
Training loss: 1.723379662270374
Validation loss: 2.4008715080378438

Epoch: 6| Step: 5
Training loss: 1.7949036772659535
Validation loss: 2.3887531373785054

Epoch: 6| Step: 6
Training loss: 1.8020364023907458
Validation loss: 2.447047876167946

Epoch: 6| Step: 7
Training loss: 1.8685216247434198
Validation loss: 2.452690555792465

Epoch: 6| Step: 8
Training loss: 1.7661026165181182
Validation loss: 2.458867262924107

Epoch: 6| Step: 9
Training loss: 2.383807165443603
Validation loss: 2.4801810190319458

Epoch: 6| Step: 10
Training loss: 1.873225198636274
Validation loss: 2.4052272290896934

Epoch: 6| Step: 11
Training loss: 1.689429698627322
Validation loss: 2.4485925972216322

Epoch: 6| Step: 12
Training loss: 1.4966718786753503
Validation loss: 2.4090461998079324

Epoch: 6| Step: 13
Training loss: 1.7236539066742158
Validation loss: 2.4526074100347914

Epoch: 90| Step: 0
Training loss: 2.023951402600945
Validation loss: 2.503672413810208

Epoch: 6| Step: 1
Training loss: 2.1933420916018176
Validation loss: 2.51924957356852

Epoch: 6| Step: 2
Training loss: 1.850697246817383
Validation loss: 2.483325872687413

Epoch: 6| Step: 3
Training loss: 1.8434424062929695
Validation loss: 2.458004207454357

Epoch: 6| Step: 4
Training loss: 1.2272040274847407
Validation loss: 2.499352768721793

Epoch: 6| Step: 5
Training loss: 1.727545686992669
Validation loss: 2.4328009557562393

Epoch: 6| Step: 6
Training loss: 1.9763423510597877
Validation loss: 2.4128140180919204

Epoch: 6| Step: 7
Training loss: 2.0795498889131068
Validation loss: 2.4161413926346014

Epoch: 6| Step: 8
Training loss: 2.3495685830701545
Validation loss: 2.427610943030542

Epoch: 6| Step: 9
Training loss: 1.5666780687823563
Validation loss: 2.4283754132075854

Epoch: 6| Step: 10
Training loss: 1.3962120804380316
Validation loss: 2.4369147894233683

Epoch: 6| Step: 11
Training loss: 2.091794367485075
Validation loss: 2.4227903051600874

Epoch: 6| Step: 12
Training loss: 1.631953839574874
Validation loss: 2.3942792468406875

Epoch: 6| Step: 13
Training loss: 1.5535607016557957
Validation loss: 2.4381606844960486

Epoch: 91| Step: 0
Training loss: 1.4450058070399407
Validation loss: 2.3886309350145103

Epoch: 6| Step: 1
Training loss: 1.6744352328013274
Validation loss: 2.3909372861256553

Epoch: 6| Step: 2
Training loss: 1.6960148213566633
Validation loss: 2.413469309594108

Epoch: 6| Step: 3
Training loss: 2.1970733422811137
Validation loss: 2.3854516094819047

Epoch: 6| Step: 4
Training loss: 1.7648870225576985
Validation loss: 2.4296939763905847

Epoch: 6| Step: 5
Training loss: 2.1603406720481426
Validation loss: 2.4117512507875167

Epoch: 6| Step: 6
Training loss: 1.3607753249725012
Validation loss: 2.4419425599088247

Epoch: 6| Step: 7
Training loss: 2.3819674635041475
Validation loss: 2.4274997244853402

Epoch: 6| Step: 8
Training loss: 1.9592633642977457
Validation loss: 2.395278407528389

Epoch: 6| Step: 9
Training loss: 1.6725193814008552
Validation loss: 2.388346648098163

Epoch: 6| Step: 10
Training loss: 1.800865187933251
Validation loss: 2.4147926715972376

Epoch: 6| Step: 11
Training loss: 1.4719390336866474
Validation loss: 2.387095869522705

Epoch: 6| Step: 12
Training loss: 1.4877291078198325
Validation loss: 2.4450429700808303

Epoch: 6| Step: 13
Training loss: 1.9038487929360712
Validation loss: 2.4147052094511277

Epoch: 92| Step: 0
Training loss: 1.6523314130606597
Validation loss: 2.423750596160317

Epoch: 6| Step: 1
Training loss: 1.7690889930055356
Validation loss: 2.410908318419422

Epoch: 6| Step: 2
Training loss: 1.9154789257518312
Validation loss: 2.431935667550674

Epoch: 6| Step: 3
Training loss: 1.7484790459572603
Validation loss: 2.463454978229518

Epoch: 6| Step: 4
Training loss: 2.0089324321406976
Validation loss: 2.421617818323538

Epoch: 6| Step: 5
Training loss: 2.048590487216507
Validation loss: 2.428099003623598

Epoch: 6| Step: 6
Training loss: 1.5066778627896737
Validation loss: 2.5095372750467444

Epoch: 6| Step: 7
Training loss: 1.8378482047525466
Validation loss: 2.482033063571497

Epoch: 6| Step: 8
Training loss: 1.6628094464040848
Validation loss: 2.44231132312199

Epoch: 6| Step: 9
Training loss: 1.6912466066358856
Validation loss: 2.386928334791879

Epoch: 6| Step: 10
Training loss: 1.581654671012858
Validation loss: 2.378887274571967

Epoch: 6| Step: 11
Training loss: 2.0926860554333575
Validation loss: 2.429244774881666

Epoch: 6| Step: 12
Training loss: 1.952228920419157
Validation loss: 2.3946854923888186

Epoch: 6| Step: 13
Training loss: 1.5652793578882975
Validation loss: 2.3782134485359556

Epoch: 93| Step: 0
Training loss: 1.8367865364549902
Validation loss: 2.4624954378502117

Epoch: 6| Step: 1
Training loss: 1.0735401576454953
Validation loss: 2.4431511017452574

Epoch: 6| Step: 2
Training loss: 2.1796522787112877
Validation loss: 2.3992257246791597

Epoch: 6| Step: 3
Training loss: 2.42566242019109
Validation loss: 2.430344422267963

Epoch: 6| Step: 4
Training loss: 1.528646864449339
Validation loss: 2.419924904588184

Epoch: 6| Step: 5
Training loss: 1.7640932578825628
Validation loss: 2.43724065199723

Epoch: 6| Step: 6
Training loss: 1.8647570253877341
Validation loss: 2.388178410768523

Epoch: 6| Step: 7
Training loss: 1.683254694596847
Validation loss: 2.441411181635644

Epoch: 6| Step: 8
Training loss: 1.6504895062140446
Validation loss: 2.389973237860119

Epoch: 6| Step: 9
Training loss: 1.4675509651601226
Validation loss: 2.420349559496106

Epoch: 6| Step: 10
Training loss: 2.0529023164382183
Validation loss: 2.4353946494441634

Epoch: 6| Step: 11
Training loss: 1.8339393943332485
Validation loss: 2.4362941595844183

Epoch: 6| Step: 12
Training loss: 1.678925949272227
Validation loss: 2.431137510899155

Epoch: 6| Step: 13
Training loss: 1.7321797817828368
Validation loss: 2.4394632567823193

Epoch: 94| Step: 0
Training loss: 1.4757242396718893
Validation loss: 2.4341507586001048

Epoch: 6| Step: 1
Training loss: 1.4008376340480477
Validation loss: 2.418168642556172

Epoch: 6| Step: 2
Training loss: 2.260067035220997
Validation loss: 2.4073718787353857

Epoch: 6| Step: 3
Training loss: 1.6185430475449152
Validation loss: 2.4584486228504083

Epoch: 6| Step: 4
Training loss: 2.0202760485128817
Validation loss: 2.4511217818897824

Epoch: 6| Step: 5
Training loss: 1.742685221237391
Validation loss: 2.398660539658832

Epoch: 6| Step: 6
Training loss: 2.6102666188129255
Validation loss: 2.400608434642316

Epoch: 6| Step: 7
Training loss: 1.6302354544271627
Validation loss: 2.403902973432749

Epoch: 6| Step: 8
Training loss: 1.7061037385174596
Validation loss: 2.3969291060871507

Epoch: 6| Step: 9
Training loss: 1.7795996800860312
Validation loss: 2.4087028222181157

Epoch: 6| Step: 10
Training loss: 1.3102163247590453
Validation loss: 2.407153632843448

Epoch: 6| Step: 11
Training loss: 1.4028311389849886
Validation loss: 2.408909290129773

Epoch: 6| Step: 12
Training loss: 1.5226089963435985
Validation loss: 2.423136638868899

Epoch: 6| Step: 13
Training loss: 1.5290920076499277
Validation loss: 2.4387984689066933

Epoch: 95| Step: 0
Training loss: 1.413557478784192
Validation loss: 2.451314537486532

Epoch: 6| Step: 1
Training loss: 1.6254742737221253
Validation loss: 2.4800795843060315

Epoch: 6| Step: 2
Training loss: 2.5170018000332957
Validation loss: 2.4839666578806097

Epoch: 6| Step: 3
Training loss: 1.6523203746684338
Validation loss: 2.470988035800097

Epoch: 6| Step: 4
Training loss: 1.2805714554993683
Validation loss: 2.4905885053168184

Epoch: 6| Step: 5
Training loss: 2.34322992276628
Validation loss: 2.463185344409531

Epoch: 6| Step: 6
Training loss: 1.9630678315144154
Validation loss: 2.392338307097744

Epoch: 6| Step: 7
Training loss: 1.592818492857923
Validation loss: 2.419990561154246

Epoch: 6| Step: 8
Training loss: 1.7937785794310726
Validation loss: 2.412213321973743

Epoch: 6| Step: 9
Training loss: 1.485402123307364
Validation loss: 2.4366001359160245

Epoch: 6| Step: 10
Training loss: 1.760625597351428
Validation loss: 2.4143039784233706

Epoch: 6| Step: 11
Training loss: 1.7681285696576823
Validation loss: 2.47280242150397

Epoch: 6| Step: 12
Training loss: 1.8335297074773302
Validation loss: 2.405132513116444

Epoch: 6| Step: 13
Training loss: 1.5395472968413233
Validation loss: 2.4130883416894977

Epoch: 96| Step: 0
Training loss: 1.2917111091761546
Validation loss: 2.4670015573845876

Epoch: 6| Step: 1
Training loss: 1.9281524235832463
Validation loss: 2.40711406370091

Epoch: 6| Step: 2
Training loss: 1.7855894535573607
Validation loss: 2.4799505378292426

Epoch: 6| Step: 3
Training loss: 1.2484420126975455
Validation loss: 2.4698348739965534

Epoch: 6| Step: 4
Training loss: 1.301855794734741
Validation loss: 2.473127845439249

Epoch: 6| Step: 5
Training loss: 2.125015819715069
Validation loss: 2.5189030458005464

Epoch: 6| Step: 6
Training loss: 1.9958297047220372
Validation loss: 2.5275408094603633

Epoch: 6| Step: 7
Training loss: 1.9024338593183234
Validation loss: 2.4777065005501866

Epoch: 6| Step: 8
Training loss: 1.465298432038362
Validation loss: 2.451575662655786

Epoch: 6| Step: 9
Training loss: 2.662607282169584
Validation loss: 2.4417048401392742

Epoch: 6| Step: 10
Training loss: 1.732152391050728
Validation loss: 2.4298084879002944

Epoch: 6| Step: 11
Training loss: 1.7128211673934168
Validation loss: 2.436664927317168

Epoch: 6| Step: 12
Training loss: 1.3677533967651068
Validation loss: 2.4464505505892147

Epoch: 6| Step: 13
Training loss: 1.6801334232754623
Validation loss: 2.4084049500197473

Epoch: 97| Step: 0
Training loss: 1.8479564979271565
Validation loss: 2.4122567526907663

Epoch: 6| Step: 1
Training loss: 2.191304631180544
Validation loss: 2.4278866225788995

Epoch: 6| Step: 2
Training loss: 1.8206816859641404
Validation loss: 2.4238512815260225

Epoch: 6| Step: 3
Training loss: 1.5183062874611122
Validation loss: 2.427484910239068

Epoch: 6| Step: 4
Training loss: 1.5593012301133191
Validation loss: 2.4855994160292862

Epoch: 6| Step: 5
Training loss: 2.0116891210651837
Validation loss: 2.450271534307487

Epoch: 6| Step: 6
Training loss: 2.1149812020262297
Validation loss: 2.3933183876870845

Epoch: 6| Step: 7
Training loss: 1.6698951763673466
Validation loss: 2.435475103385876

Epoch: 6| Step: 8
Training loss: 1.438817291409539
Validation loss: 2.4310394810502123

Epoch: 6| Step: 9
Training loss: 1.1657305549506736
Validation loss: 2.444647799206945

Epoch: 6| Step: 10
Training loss: 1.4663161545290835
Validation loss: 2.4541589942989224

Epoch: 6| Step: 11
Training loss: 1.607075205393262
Validation loss: 2.441135320253539

Epoch: 6| Step: 12
Training loss: 1.3272632271342348
Validation loss: 2.4567503007897864

Epoch: 6| Step: 13
Training loss: 1.9710408763469287
Validation loss: 2.4167768080594363

Epoch: 98| Step: 0
Training loss: 1.7845950924544345
Validation loss: 2.409685118722743

Epoch: 6| Step: 1
Training loss: 1.307571376143349
Validation loss: 2.4533440073012613

Epoch: 6| Step: 2
Training loss: 1.482202968593101
Validation loss: 2.4723494642233

Epoch: 6| Step: 3
Training loss: 1.6535354537369729
Validation loss: 2.473404251424597

Epoch: 6| Step: 4
Training loss: 2.4229338269488396
Validation loss: 2.483247545113146

Epoch: 6| Step: 5
Training loss: 1.6479048749820926
Validation loss: 2.4981315942415905

Epoch: 6| Step: 6
Training loss: 1.872386955342757
Validation loss: 2.403915511377822

Epoch: 6| Step: 7
Training loss: 1.3376297522381038
Validation loss: 2.4022507316134876

Epoch: 6| Step: 8
Training loss: 1.3124325144538775
Validation loss: 2.4370674988555128

Epoch: 6| Step: 9
Training loss: 2.4404378938937654
Validation loss: 2.4422941256607857

Epoch: 6| Step: 10
Training loss: 1.266268625376606
Validation loss: 2.4393110312785242

Epoch: 6| Step: 11
Training loss: 1.9811313581593903
Validation loss: 2.4493735800379888

Epoch: 6| Step: 12
Training loss: 1.7138325483946113
Validation loss: 2.435656934839922

Epoch: 6| Step: 13
Training loss: 1.5361193094308776
Validation loss: 2.433990462508854

Epoch: 99| Step: 0
Training loss: 2.037957136674879
Validation loss: 2.416117052083759

Epoch: 6| Step: 1
Training loss: 1.3117752344762488
Validation loss: 2.4726499584533776

Epoch: 6| Step: 2
Training loss: 1.687356024357572
Validation loss: 2.518319450161744

Epoch: 6| Step: 3
Training loss: 2.2022415445949033
Validation loss: 2.5175934587144355

Epoch: 6| Step: 4
Training loss: 2.0447705348576815
Validation loss: 2.5054598633771437

Epoch: 6| Step: 5
Training loss: 2.222382808552074
Validation loss: 2.4848516474830213

Epoch: 6| Step: 6
Training loss: 1.365040821331385
Validation loss: 2.49816122780049

Epoch: 6| Step: 7
Training loss: 1.2325527405819354
Validation loss: 2.4682731972769285

Epoch: 6| Step: 8
Training loss: 1.2928889961654246
Validation loss: 2.486205508276899

Epoch: 6| Step: 9
Training loss: 1.5340387290531838
Validation loss: 2.4623975590473997

Epoch: 6| Step: 10
Training loss: 1.5451599786393069
Validation loss: 2.421195609670495

Epoch: 6| Step: 11
Training loss: 1.689978298521936
Validation loss: 2.473538804203745

Epoch: 6| Step: 12
Training loss: 1.2815875097335259
Validation loss: 2.4333479151441275

Epoch: 6| Step: 13
Training loss: 1.703256374506778
Validation loss: 2.4555502887408514

Epoch: 100| Step: 0
Training loss: 1.8293886952201992
Validation loss: 2.481133639716477

Epoch: 6| Step: 1
Training loss: 1.3585596818474852
Validation loss: 2.435032581970386

Epoch: 6| Step: 2
Training loss: 1.7647393630161543
Validation loss: 2.4136530540248216

Epoch: 6| Step: 3
Training loss: 2.38750638311841
Validation loss: 2.4547699436691106

Epoch: 6| Step: 4
Training loss: 1.7065587557388524
Validation loss: 2.4334080167527183

Epoch: 6| Step: 5
Training loss: 1.4239466739485098
Validation loss: 2.5174211522684864

Epoch: 6| Step: 6
Training loss: 1.417754270027523
Validation loss: 2.452606826773223

Epoch: 6| Step: 7
Training loss: 1.6634420035009427
Validation loss: 2.4482440215566608

Epoch: 6| Step: 8
Training loss: 1.8213019567447382
Validation loss: 2.4753281398273166

Epoch: 6| Step: 9
Training loss: 1.6635330145827252
Validation loss: 2.439663342717507

Epoch: 6| Step: 10
Training loss: 1.9698086874186302
Validation loss: 2.411106798050456

Epoch: 6| Step: 11
Training loss: 1.4448904710065626
Validation loss: 2.4431189223830567

Epoch: 6| Step: 12
Training loss: 1.4847390782432603
Validation loss: 2.4289442522183005

Epoch: 6| Step: 13
Training loss: 0.9444051439080562
Validation loss: 2.41919376071217

Epoch: 101| Step: 0
Training loss: 1.632129581131502
Validation loss: 2.4346482312520137

Epoch: 6| Step: 1
Training loss: 2.3751154419800176
Validation loss: 2.4150111897000697

Epoch: 6| Step: 2
Training loss: 1.0372408049040942
Validation loss: 2.4358970066152548

Epoch: 6| Step: 3
Training loss: 1.2564208583506742
Validation loss: 2.3871771605816576

Epoch: 6| Step: 4
Training loss: 1.623258831630542
Validation loss: 2.414566991408975

Epoch: 6| Step: 5
Training loss: 1.4249238244827733
Validation loss: 2.4358157998792866

Epoch: 6| Step: 6
Training loss: 1.3952563882205447
Validation loss: 2.4996282142119584

Epoch: 6| Step: 7
Training loss: 2.1152508313216045
Validation loss: 2.446138886228498

Epoch: 6| Step: 8
Training loss: 1.7875923879796378
Validation loss: 2.475390962425411

Epoch: 6| Step: 9
Training loss: 1.5338932500845779
Validation loss: 2.5004477179485667

Epoch: 6| Step: 10
Training loss: 1.6926569378215048
Validation loss: 2.4453278481161247

Epoch: 6| Step: 11
Training loss: 1.4617742906107885
Validation loss: 2.448183894620494

Epoch: 6| Step: 12
Training loss: 1.3655475481010824
Validation loss: 2.457429547313816

Epoch: 6| Step: 13
Training loss: 1.5886946140722662
Validation loss: 2.4837850194035567

Epoch: 102| Step: 0
Training loss: 1.5586545545147097
Validation loss: 2.436646654457368

Epoch: 6| Step: 1
Training loss: 1.2427097398356142
Validation loss: 2.4345852305269813

Epoch: 6| Step: 2
Training loss: 1.2811695166640038
Validation loss: 2.4554038670045113

Epoch: 6| Step: 3
Training loss: 1.589415096447721
Validation loss: 2.4698753447872925

Epoch: 6| Step: 4
Training loss: 1.823893679422984
Validation loss: 2.4375883233134052

Epoch: 6| Step: 5
Training loss: 1.6165717975401441
Validation loss: 2.404195329395007

Epoch: 6| Step: 6
Training loss: 1.126065914846941
Validation loss: 2.440376622077335

Epoch: 6| Step: 7
Training loss: 1.4613114964554448
Validation loss: 2.429596051849203

Epoch: 6| Step: 8
Training loss: 2.306121483506863
Validation loss: 2.4486481621989293

Epoch: 6| Step: 9
Training loss: 1.4657637898464821
Validation loss: 2.4314811521475965

Epoch: 6| Step: 10
Training loss: 1.4913266080250793
Validation loss: 2.4746743434295024

Epoch: 6| Step: 11
Training loss: 2.1636180214654477
Validation loss: 2.4972921011141955

Epoch: 6| Step: 12
Training loss: 1.6329610656610039
Validation loss: 2.4684695796811345

Epoch: 6| Step: 13
Training loss: 1.973661079940444
Validation loss: 2.457926487527711

Epoch: 103| Step: 0
Training loss: 2.1628422240314866
Validation loss: 2.455687850545259

Epoch: 6| Step: 1
Training loss: 1.991195611300753
Validation loss: 2.5500797165770774

Epoch: 6| Step: 2
Training loss: 2.055556661015577
Validation loss: 2.5364175802373468

Epoch: 6| Step: 3
Training loss: 1.5376369632410303
Validation loss: 2.5097664720506634

Epoch: 6| Step: 4
Training loss: 1.3597206903894299
Validation loss: 2.4419550815401174

Epoch: 6| Step: 5
Training loss: 1.3903333379513334
Validation loss: 2.4547082202019874

Epoch: 6| Step: 6
Training loss: 1.2084912602491724
Validation loss: 2.423784918019599

Epoch: 6| Step: 7
Training loss: 1.7057141563007445
Validation loss: 2.467472679530604

Epoch: 6| Step: 8
Training loss: 1.472484305383949
Validation loss: 2.432012151195261

Epoch: 6| Step: 9
Training loss: 1.1849029652586989
Validation loss: 2.4704751051473464

Epoch: 6| Step: 10
Training loss: 1.5883031780720056
Validation loss: 2.4444001499651855

Epoch: 6| Step: 11
Training loss: 1.314561451136843
Validation loss: 2.4702678151183997

Epoch: 6| Step: 12
Training loss: 2.0792741394806593
Validation loss: 2.4147107633504605

Epoch: 6| Step: 13
Training loss: 1.8149121774490984
Validation loss: 2.3902579547292344

Epoch: 104| Step: 0
Training loss: 1.9414542670039694
Validation loss: 2.4651021605310928

Epoch: 6| Step: 1
Training loss: 1.4274392716673083
Validation loss: 2.4649502126167833

Epoch: 6| Step: 2
Training loss: 1.1557902375712799
Validation loss: 2.5094708498411764

Epoch: 6| Step: 3
Training loss: 2.3189587481120824
Validation loss: 2.5295110309916033

Epoch: 6| Step: 4
Training loss: 1.9498368317244192
Validation loss: 2.515938685981567

Epoch: 6| Step: 5
Training loss: 1.0312575715682921
Validation loss: 2.523367850303993

Epoch: 6| Step: 6
Training loss: 1.5277132723898514
Validation loss: 2.4558434862622294

Epoch: 6| Step: 7
Training loss: 1.5409683587738943
Validation loss: 2.483514112787895

Epoch: 6| Step: 8
Training loss: 1.060718669992389
Validation loss: 2.4386116492522407

Epoch: 6| Step: 9
Training loss: 1.6184633538802766
Validation loss: 2.4229684801758142

Epoch: 6| Step: 10
Training loss: 1.988064377504147
Validation loss: 2.422448383669793

Epoch: 6| Step: 11
Training loss: 1.731311257170331
Validation loss: 2.4670685301159785

Epoch: 6| Step: 12
Training loss: 1.784434366658279
Validation loss: 2.4233958401635816

Epoch: 6| Step: 13
Training loss: 1.5062271243055931
Validation loss: 2.438110813000828

Epoch: 105| Step: 0
Training loss: 1.6295605998679423
Validation loss: 2.4793920708349027

Epoch: 6| Step: 1
Training loss: 1.635467706681605
Validation loss: 2.4497490511068154

Epoch: 6| Step: 2
Training loss: 1.3776411353224554
Validation loss: 2.487148088773302

Epoch: 6| Step: 3
Training loss: 1.306876578929792
Validation loss: 2.5100309753659715

Epoch: 6| Step: 4
Training loss: 1.5719318296196676
Validation loss: 2.496473511336128

Epoch: 6| Step: 5
Training loss: 1.5848260752803602
Validation loss: 2.514894462327739

Epoch: 6| Step: 6
Training loss: 1.9811045211185077
Validation loss: 2.4856870853202193

Epoch: 6| Step: 7
Training loss: 1.5276609125619243
Validation loss: 2.4691437918223236

Epoch: 6| Step: 8
Training loss: 1.603424850292042
Validation loss: 2.4448299073938546

Epoch: 6| Step: 9
Training loss: 1.6309688691256141
Validation loss: 2.4685235221411226

Epoch: 6| Step: 10
Training loss: 2.0071671335587813
Validation loss: 2.477705891121863

Epoch: 6| Step: 11
Training loss: 1.471109159432455
Validation loss: 2.470108784996894

Epoch: 6| Step: 12
Training loss: 1.3863697741183587
Validation loss: 2.4530274357599473

Epoch: 6| Step: 13
Training loss: 1.947504486157168
Validation loss: 2.4222709332121752

Epoch: 106| Step: 0
Training loss: 1.694163552785033
Validation loss: 2.4379186759744425

Epoch: 6| Step: 1
Training loss: 1.4381566413803764
Validation loss: 2.5293332601750667

Epoch: 6| Step: 2
Training loss: 2.6472365095302943
Validation loss: 2.486174549474987

Epoch: 6| Step: 3
Training loss: 1.6447730532223725
Validation loss: 2.54403445428733

Epoch: 6| Step: 4
Training loss: 1.364118958098997
Validation loss: 2.4999018808819415

Epoch: 6| Step: 5
Training loss: 1.38270482220572
Validation loss: 2.4594509903099455

Epoch: 6| Step: 6
Training loss: 1.1696086075655212
Validation loss: 2.4481707799515404

Epoch: 6| Step: 7
Training loss: 1.3294208263682132
Validation loss: 2.445516072047489

Epoch: 6| Step: 8
Training loss: 1.6397947844763756
Validation loss: 2.424354219477889

Epoch: 6| Step: 9
Training loss: 1.2371800095653482
Validation loss: 2.4275386912506502

Epoch: 6| Step: 10
Training loss: 1.1200188990258646
Validation loss: 2.51525267220975

Epoch: 6| Step: 11
Training loss: 1.7496101762650962
Validation loss: 2.4127502578436393

Epoch: 6| Step: 12
Training loss: 1.5351501930641485
Validation loss: 2.4592248113806217

Epoch: 6| Step: 13
Training loss: 1.6472363186012042
Validation loss: 2.445595843684577

Epoch: 107| Step: 0
Training loss: 2.069417508125659
Validation loss: 2.463041772321167

Epoch: 6| Step: 1
Training loss: 1.3800591250206842
Validation loss: 2.4510359808751434

Epoch: 6| Step: 2
Training loss: 1.3036648517135305
Validation loss: 2.509625010627014

Epoch: 6| Step: 3
Training loss: 1.7169456721238388
Validation loss: 2.449222522106034

Epoch: 6| Step: 4
Training loss: 1.3969257217517597
Validation loss: 2.4855145733828836

Epoch: 6| Step: 5
Training loss: 1.6038976253792334
Validation loss: 2.496270951024111

Epoch: 6| Step: 6
Training loss: 1.7083038544631293
Validation loss: 2.433488413907314

Epoch: 6| Step: 7
Training loss: 1.1877941469994104
Validation loss: 2.4977742221062393

Epoch: 6| Step: 8
Training loss: 1.33610359631701
Validation loss: 2.5042815103289127

Epoch: 6| Step: 9
Training loss: 1.8137787221557502
Validation loss: 2.518051288454069

Epoch: 6| Step: 10
Training loss: 1.0275058400900052
Validation loss: 2.4755172128060323

Epoch: 6| Step: 11
Training loss: 1.2741801898671945
Validation loss: 2.4249043131168126

Epoch: 6| Step: 12
Training loss: 1.8369467700437379
Validation loss: 2.410608035980581

Epoch: 6| Step: 13
Training loss: 1.6367971178471312
Validation loss: 2.454626826380873

Epoch: 108| Step: 0
Training loss: 1.473790872539325
Validation loss: 2.432818489826843

Epoch: 6| Step: 1
Training loss: 1.5437013070153052
Validation loss: 2.462181866616734

Epoch: 6| Step: 2
Training loss: 1.595174489417262
Validation loss: 2.4435325132277637

Epoch: 6| Step: 3
Training loss: 1.0820400637050787
Validation loss: 2.403120912797261

Epoch: 6| Step: 4
Training loss: 1.704132971706421
Validation loss: 2.429849519060245

Epoch: 6| Step: 5
Training loss: 1.1427607985315749
Validation loss: 2.4389915956157147

Epoch: 6| Step: 6
Training loss: 1.3262430657898514
Validation loss: 2.4865125341518186

Epoch: 6| Step: 7
Training loss: 2.315583415822791
Validation loss: 2.5361836393676285

Epoch: 6| Step: 8
Training loss: 2.1698154042215703
Validation loss: 2.4942020258344506

Epoch: 6| Step: 9
Training loss: 1.1736906101204492
Validation loss: 2.488619140168464

Epoch: 6| Step: 10
Training loss: 1.2715227206259403
Validation loss: 2.478046169366093

Epoch: 6| Step: 11
Training loss: 1.4629241980251337
Validation loss: 2.452272206186761

Epoch: 6| Step: 12
Training loss: 1.5823968912194382
Validation loss: 2.467262858326476

Epoch: 6| Step: 13
Training loss: 1.1183133088170085
Validation loss: 2.4408069739758584

Epoch: 109| Step: 0
Training loss: 1.9339477215065208
Validation loss: 2.4681127184409903

Epoch: 6| Step: 1
Training loss: 2.308611926218633
Validation loss: 2.4667338576917084

Epoch: 6| Step: 2
Training loss: 1.3303442421321474
Validation loss: 2.480183262052766

Epoch: 6| Step: 3
Training loss: 1.0738754001173096
Validation loss: 2.431896289218203

Epoch: 6| Step: 4
Training loss: 1.5333794559231475
Validation loss: 2.430977874275427

Epoch: 6| Step: 5
Training loss: 1.4446678579795256
Validation loss: 2.5132974950004323

Epoch: 6| Step: 6
Training loss: 1.5831679040250928
Validation loss: 2.459213945026318

Epoch: 6| Step: 7
Training loss: 0.8964388966712054
Validation loss: 2.428057811957953

Epoch: 6| Step: 8
Training loss: 1.9978413257043866
Validation loss: 2.4552370281482103

Epoch: 6| Step: 9
Training loss: 1.276856682450427
Validation loss: 2.479478260836028

Epoch: 6| Step: 10
Training loss: 1.3435407076348298
Validation loss: 2.4384920188241836

Epoch: 6| Step: 11
Training loss: 1.6603153646176234
Validation loss: 2.4293825013300303

Epoch: 6| Step: 12
Training loss: 1.4691302842027558
Validation loss: 2.4825066312641804

Epoch: 6| Step: 13
Training loss: 1.1526724653640543
Validation loss: 2.4680085175262656

Epoch: 110| Step: 0
Training loss: 2.0519674303916675
Validation loss: 2.5002684131218036

Epoch: 6| Step: 1
Training loss: 1.6160861333044068
Validation loss: 2.4983684938216

Epoch: 6| Step: 2
Training loss: 1.4005610363648033
Validation loss: 2.4993977934006355

Epoch: 6| Step: 3
Training loss: 1.6250750450998934
Validation loss: 2.5127907814049073

Epoch: 6| Step: 4
Training loss: 1.242402160138858
Validation loss: 2.5058805604050547

Epoch: 6| Step: 5
Training loss: 0.8481187745149036
Validation loss: 2.471920271505929

Epoch: 6| Step: 6
Training loss: 1.4160612533058072
Validation loss: 2.467055805759053

Epoch: 6| Step: 7
Training loss: 1.577377142134706
Validation loss: 2.470462985424596

Epoch: 6| Step: 8
Training loss: 1.4571978190018036
Validation loss: 2.462565905597537

Epoch: 6| Step: 9
Training loss: 1.9666895908161908
Validation loss: 2.485494413436211

Epoch: 6| Step: 10
Training loss: 1.6296477974053956
Validation loss: 2.466805702449401

Epoch: 6| Step: 11
Training loss: 1.4283883283985914
Validation loss: 2.4579111291650877

Epoch: 6| Step: 12
Training loss: 1.1549717822900925
Validation loss: 2.435749460547533

Epoch: 6| Step: 13
Training loss: 1.2287597413710136
Validation loss: 2.4925549115732735

Epoch: 111| Step: 0
Training loss: 0.9717065855357602
Validation loss: 2.4396602317706777

Epoch: 6| Step: 1
Training loss: 1.8335077318413926
Validation loss: 2.4417939145343794

Epoch: 6| Step: 2
Training loss: 1.4158499364270456
Validation loss: 2.4691198691616365

Epoch: 6| Step: 3
Training loss: 1.6331633414473312
Validation loss: 2.4972370933916888

Epoch: 6| Step: 4
Training loss: 1.347394613769986
Validation loss: 2.4551036330632567

Epoch: 6| Step: 5
Training loss: 1.2829138489250682
Validation loss: 2.4802731414321326

Epoch: 6| Step: 6
Training loss: 1.3043660207529828
Validation loss: 2.460962624396385

Epoch: 6| Step: 7
Training loss: 1.1238777072803032
Validation loss: 2.500557241325071

Epoch: 6| Step: 8
Training loss: 1.8273223027621583
Validation loss: 2.4846886170968925

Epoch: 6| Step: 9
Training loss: 1.3169936502429591
Validation loss: 2.4682845228118393

Epoch: 6| Step: 10
Training loss: 2.1629737291014894
Validation loss: 2.433329854161462

Epoch: 6| Step: 11
Training loss: 1.5330471469723583
Validation loss: 2.4729227301103602

Epoch: 6| Step: 12
Training loss: 1.567111876651329
Validation loss: 2.4712832849036515

Epoch: 6| Step: 13
Training loss: 0.949049883605683
Validation loss: 2.5587149477298494

Epoch: 112| Step: 0
Training loss: 1.8977450768139685
Validation loss: 2.568381259375336

Epoch: 6| Step: 1
Training loss: 2.2827174026556514
Validation loss: 2.5927591231262896

Epoch: 6| Step: 2
Training loss: 1.3957010699944858
Validation loss: 2.622329367610108

Epoch: 6| Step: 3
Training loss: 1.4526377855825914
Validation loss: 2.5229719301361486

Epoch: 6| Step: 4
Training loss: 1.944142491495142
Validation loss: 2.474898074841731

Epoch: 6| Step: 5
Training loss: 0.9496606496747723
Validation loss: 2.489909798406714

Epoch: 6| Step: 6
Training loss: 1.2462529287045578
Validation loss: 2.4534512442608447

Epoch: 6| Step: 7
Training loss: 1.6600751071622264
Validation loss: 2.4741541948921735

Epoch: 6| Step: 8
Training loss: 1.6371635615547748
Validation loss: 2.451540117098807

Epoch: 6| Step: 9
Training loss: 1.2329862484254042
Validation loss: 2.4788980151453543

Epoch: 6| Step: 10
Training loss: 1.3214390931023552
Validation loss: 2.506763686558226

Epoch: 6| Step: 11
Training loss: 1.2255528175772636
Validation loss: 2.4724148938349892

Epoch: 6| Step: 12
Training loss: 1.0646068217055922
Validation loss: 2.4972995319169935

Epoch: 6| Step: 13
Training loss: 1.4567721957310713
Validation loss: 2.4921110932726425

Epoch: 113| Step: 0
Training loss: 1.5024963904415194
Validation loss: 2.5407535027807597

Epoch: 6| Step: 1
Training loss: 2.5837155848897715
Validation loss: 2.5482715296148144

Epoch: 6| Step: 2
Training loss: 1.4433696989069635
Validation loss: 2.595615581627327

Epoch: 6| Step: 3
Training loss: 1.4836708406383794
Validation loss: 2.625955120286164

Epoch: 6| Step: 4
Training loss: 1.813232142462657
Validation loss: 2.5183000735399337

Epoch: 6| Step: 5
Training loss: 1.6061322773939175
Validation loss: 2.539245771004887

Epoch: 6| Step: 6
Training loss: 1.3323596538329525
Validation loss: 2.4161908624039308

Epoch: 6| Step: 7
Training loss: 1.0542002930134349
Validation loss: 2.4673512596718425

Epoch: 6| Step: 8
Training loss: 1.1719195548170729
Validation loss: 2.497250395919896

Epoch: 6| Step: 9
Training loss: 1.0907498219936032
Validation loss: 2.4749125250054873

Epoch: 6| Step: 10
Training loss: 0.982651549049181
Validation loss: 2.5047551470192593

Epoch: 6| Step: 11
Training loss: 1.8160007475376692
Validation loss: 2.5370404295526097

Epoch: 6| Step: 12
Training loss: 1.1030643046596302
Validation loss: 2.505035066593942

Epoch: 6| Step: 13
Training loss: 1.7351126262156806
Validation loss: 2.4620640028240275

Epoch: 114| Step: 0
Training loss: 1.2346698553687485
Validation loss: 2.5106368911407118

Epoch: 6| Step: 1
Training loss: 1.4667973626309943
Validation loss: 2.458248966730597

Epoch: 6| Step: 2
Training loss: 1.3197422037387543
Validation loss: 2.4823627920095324

Epoch: 6| Step: 3
Training loss: 0.9357311091267867
Validation loss: 2.508229491364518

Epoch: 6| Step: 4
Training loss: 1.219900957136469
Validation loss: 2.4659544975607974

Epoch: 6| Step: 5
Training loss: 1.5838597409736597
Validation loss: 2.501959589032398

Epoch: 6| Step: 6
Training loss: 1.6530892063585307
Validation loss: 2.43629800878711

Epoch: 6| Step: 7
Training loss: 1.4681028198281625
Validation loss: 2.4932905185743377

Epoch: 6| Step: 8
Training loss: 1.3035155646415881
Validation loss: 2.469293381650319

Epoch: 6| Step: 9
Training loss: 1.8774307389570164
Validation loss: 2.461177438816192

Epoch: 6| Step: 10
Training loss: 0.8509617357448597
Validation loss: 2.4591711739430173

Epoch: 6| Step: 11
Training loss: 1.3667699993813156
Validation loss: 2.441188841231264

Epoch: 6| Step: 12
Training loss: 1.5561692733968884
Validation loss: 2.4957874331024255

Epoch: 6| Step: 13
Training loss: 1.9290029570268636
Validation loss: 2.4739390295513672

Epoch: 115| Step: 0
Training loss: 1.394763702765608
Validation loss: 2.424942117177202

Epoch: 6| Step: 1
Training loss: 1.2589353679098625
Validation loss: 2.4980717295627337

Epoch: 6| Step: 2
Training loss: 1.2820596230370058
Validation loss: 2.4927869372814415

Epoch: 6| Step: 3
Training loss: 1.6794113996825033
Validation loss: 2.4982114752057014

Epoch: 6| Step: 4
Training loss: 2.030329686532915
Validation loss: 2.489726391011286

Epoch: 6| Step: 5
Training loss: 1.204110472708821
Validation loss: 2.5039773138458745

Epoch: 6| Step: 6
Training loss: 1.1245684325757586
Validation loss: 2.4745524499493343

Epoch: 6| Step: 7
Training loss: 1.241125168376861
Validation loss: 2.512344488072678

Epoch: 6| Step: 8
Training loss: 1.7275621791088673
Validation loss: 2.543715969298577

Epoch: 6| Step: 9
Training loss: 1.4383495971420275
Validation loss: 2.478975406182605

Epoch: 6| Step: 10
Training loss: 1.6589705956849905
Validation loss: 2.541902489483433

Epoch: 6| Step: 11
Training loss: 1.77408376337277
Validation loss: 2.4729592778927567

Epoch: 6| Step: 12
Training loss: 0.8889223186014867
Validation loss: 2.49460831023439

Epoch: 6| Step: 13
Training loss: 1.162872730510834
Validation loss: 2.524993849580029

Epoch: 116| Step: 0
Training loss: 1.2614444871557846
Validation loss: 2.49025546195882

Epoch: 6| Step: 1
Training loss: 1.5044516627164994
Validation loss: 2.5258379719724218

Epoch: 6| Step: 2
Training loss: 1.211166999972929
Validation loss: 2.4752544394308393

Epoch: 6| Step: 3
Training loss: 1.8502997748322796
Validation loss: 2.500338499676774

Epoch: 6| Step: 4
Training loss: 1.3959323885866568
Validation loss: 2.4804437350716384

Epoch: 6| Step: 5
Training loss: 1.2471818627612652
Validation loss: 2.454273432906501

Epoch: 6| Step: 6
Training loss: 1.0615761611324477
Validation loss: 2.4897670332252595

Epoch: 6| Step: 7
Training loss: 1.355309644700047
Validation loss: 2.5192850312963353

Epoch: 6| Step: 8
Training loss: 1.5241791313806041
Validation loss: 2.493521083436937

Epoch: 6| Step: 9
Training loss: 1.4532268037308096
Validation loss: 2.417052671144523

Epoch: 6| Step: 10
Training loss: 1.8209035675097678
Validation loss: 2.481307625281581

Epoch: 6| Step: 11
Training loss: 1.3511320101086475
Validation loss: 2.495763304104201

Epoch: 6| Step: 12
Training loss: 0.9183768481268043
Validation loss: 2.442619457675021

Epoch: 6| Step: 13
Training loss: 1.5576291266196038
Validation loss: 2.438244714028282

Epoch: 117| Step: 0
Training loss: 1.5136224160266456
Validation loss: 2.4969702163384593

Epoch: 6| Step: 1
Training loss: 1.222920642090314
Validation loss: 2.4485499651765625

Epoch: 6| Step: 2
Training loss: 1.293382791568141
Validation loss: 2.5468196901895825

Epoch: 6| Step: 3
Training loss: 1.3403277176473165
Validation loss: 2.560601818466127

Epoch: 6| Step: 4
Training loss: 1.3096098186271656
Validation loss: 2.5334733687981696

Epoch: 6| Step: 5
Training loss: 0.9059605958487496
Validation loss: 2.538177539463574

Epoch: 6| Step: 6
Training loss: 1.7392303961553353
Validation loss: 2.517101581100887

Epoch: 6| Step: 7
Training loss: 1.9703959895814513
Validation loss: 2.44600228197808

Epoch: 6| Step: 8
Training loss: 1.4140212753778032
Validation loss: 2.5121375526283796

Epoch: 6| Step: 9
Training loss: 0.8597239392793593
Validation loss: 2.4257496183158476

Epoch: 6| Step: 10
Training loss: 1.536773916475119
Validation loss: 2.447654163543562

Epoch: 6| Step: 11
Training loss: 1.7756791924193034
Validation loss: 2.4825044543689567

Epoch: 6| Step: 12
Training loss: 1.5368278274649871
Validation loss: 2.4901099958087602

Epoch: 6| Step: 13
Training loss: 0.9840668695570264
Validation loss: 2.505602519428575

Epoch: 118| Step: 0
Training loss: 1.850739372555783
Validation loss: 2.479369969941045

Epoch: 6| Step: 1
Training loss: 1.3406169206424716
Validation loss: 2.515875407011695

Epoch: 6| Step: 2
Training loss: 1.4336669237966928
Validation loss: 2.5104890287952615

Epoch: 6| Step: 3
Training loss: 1.8274845403390483
Validation loss: 2.5020080290385263

Epoch: 6| Step: 4
Training loss: 1.0749182071175452
Validation loss: 2.498722417544651

Epoch: 6| Step: 5
Training loss: 1.957873013011034
Validation loss: 2.498545525565171

Epoch: 6| Step: 6
Training loss: 1.2608851936013747
Validation loss: 2.476317384545338

Epoch: 6| Step: 7
Training loss: 1.1466935079135154
Validation loss: 2.487485206342761

Epoch: 6| Step: 8
Training loss: 1.1860757619001068
Validation loss: 2.527521134076555

Epoch: 6| Step: 9
Training loss: 0.9804909388246525
Validation loss: 2.4909805037752495

Epoch: 6| Step: 10
Training loss: 1.2350038785526052
Validation loss: 2.5237229444625853

Epoch: 6| Step: 11
Training loss: 1.4458864464289016
Validation loss: 2.450073012088001

Epoch: 6| Step: 12
Training loss: 1.2580807796614994
Validation loss: 2.5205958519878853

Epoch: 6| Step: 13
Training loss: 1.2219568756847867
Validation loss: 2.5090723567009965

Epoch: 119| Step: 0
Training loss: 1.7410493562857283
Validation loss: 2.4737710232682253

Epoch: 6| Step: 1
Training loss: 1.4541907555334699
Validation loss: 2.5850299652571462

Epoch: 6| Step: 2
Training loss: 1.5835505219456054
Validation loss: 2.691925899277415

Epoch: 6| Step: 3
Training loss: 1.4662379432956518
Validation loss: 2.6772731807696775

Epoch: 6| Step: 4
Training loss: 1.2822615189446764
Validation loss: 2.598528569732702

Epoch: 6| Step: 5
Training loss: 1.368529353363923
Validation loss: 2.53346834973213

Epoch: 6| Step: 6
Training loss: 1.7387218816966874
Validation loss: 2.603485939064589

Epoch: 6| Step: 7
Training loss: 1.4118951869836904
Validation loss: 2.514037600896396

Epoch: 6| Step: 8
Training loss: 1.2384264647237386
Validation loss: 2.466333888992898

Epoch: 6| Step: 9
Training loss: 1.6314992779967767
Validation loss: 2.5121162222664775

Epoch: 6| Step: 10
Training loss: 1.5942742476561245
Validation loss: 2.578208486573144

Epoch: 6| Step: 11
Training loss: 1.3443113529562762
Validation loss: 2.5715324498190593

Epoch: 6| Step: 12
Training loss: 1.313006530385218
Validation loss: 2.6019835107580436

Epoch: 6| Step: 13
Training loss: 1.2468782066361346
Validation loss: 2.5504049789874697

Epoch: 120| Step: 0
Training loss: 1.350819466151216
Validation loss: 2.4852119891253617

Epoch: 6| Step: 1
Training loss: 1.0374118055062784
Validation loss: 2.4949872305931255

Epoch: 6| Step: 2
Training loss: 1.2593989821959526
Validation loss: 2.5100626768465766

Epoch: 6| Step: 3
Training loss: 1.2619726911633973
Validation loss: 2.5768956191318737

Epoch: 6| Step: 4
Training loss: 1.4926755416615363
Validation loss: 2.5914670633274848

Epoch: 6| Step: 5
Training loss: 1.0915745490037383
Validation loss: 2.6439817337548805

Epoch: 6| Step: 6
Training loss: 1.979969029328853
Validation loss: 2.6242738809384782

Epoch: 6| Step: 7
Training loss: 1.2359675986076837
Validation loss: 2.547637638046282

Epoch: 6| Step: 8
Training loss: 1.459040261542582
Validation loss: 2.4979681818350543

Epoch: 6| Step: 9
Training loss: 1.3697523200859114
Validation loss: 2.5021261075503616

Epoch: 6| Step: 10
Training loss: 1.4349742759498998
Validation loss: 2.500032337297472

Epoch: 6| Step: 11
Training loss: 1.3260770828459985
Validation loss: 2.4524934931781193

Epoch: 6| Step: 12
Training loss: 1.3804191092528935
Validation loss: 2.5208677862245765

Epoch: 6| Step: 13
Training loss: 1.9746206039879164
Validation loss: 2.5189499610806125

Epoch: 121| Step: 0
Training loss: 1.2575707055116074
Validation loss: 2.5154520453159384

Epoch: 6| Step: 1
Training loss: 1.2274287378326774
Validation loss: 2.5135875214495025

Epoch: 6| Step: 2
Training loss: 1.643734990620711
Validation loss: 2.537573204487916

Epoch: 6| Step: 3
Training loss: 0.7378554150494263
Validation loss: 2.5065405007410644

Epoch: 6| Step: 4
Training loss: 1.527352257434147
Validation loss: 2.5077193055706855

Epoch: 6| Step: 5
Training loss: 1.3998617665983315
Validation loss: 2.538506549711796

Epoch: 6| Step: 6
Training loss: 0.8657478204072399
Validation loss: 2.447764230946458

Epoch: 6| Step: 7
Training loss: 0.9583656505995903
Validation loss: 2.5509325248410852

Epoch: 6| Step: 8
Training loss: 1.4269745314209272
Validation loss: 2.514485008089364

Epoch: 6| Step: 9
Training loss: 1.1718144210416361
Validation loss: 2.487780637900828

Epoch: 6| Step: 10
Training loss: 1.7397277985241726
Validation loss: 2.517625151777761

Epoch: 6| Step: 11
Training loss: 2.038249588205424
Validation loss: 2.5222585343124417

Epoch: 6| Step: 12
Training loss: 1.3087373113882428
Validation loss: 2.447903017587689

Epoch: 6| Step: 13
Training loss: 0.8584728707774287
Validation loss: 2.5331325280973127

Epoch: 122| Step: 0
Training loss: 1.2223092461199536
Validation loss: 2.417431723962908

Epoch: 6| Step: 1
Training loss: 1.4476714807111637
Validation loss: 2.5490344825119315

Epoch: 6| Step: 2
Training loss: 1.9346217649762698
Validation loss: 2.5583869287507826

Epoch: 6| Step: 3
Training loss: 1.2401258045644181
Validation loss: 2.4881725117844744

Epoch: 6| Step: 4
Training loss: 0.9429518172696194
Validation loss: 2.498949720381894

Epoch: 6| Step: 5
Training loss: 1.5294138740615626
Validation loss: 2.537765093205884

Epoch: 6| Step: 6
Training loss: 1.145682267143207
Validation loss: 2.487723982294035

Epoch: 6| Step: 7
Training loss: 1.1397688278246327
Validation loss: 2.5277207342518717

Epoch: 6| Step: 8
Training loss: 1.4806040196282912
Validation loss: 2.5431260677025094

Epoch: 6| Step: 9
Training loss: 0.9319935895756644
Validation loss: 2.572011724138804

Epoch: 6| Step: 10
Training loss: 1.349654775206441
Validation loss: 2.605183034288722

Epoch: 6| Step: 11
Training loss: 1.6519686225746884
Validation loss: 2.5461825812279546

Epoch: 6| Step: 12
Training loss: 1.232667055241008
Validation loss: 2.5266835658867923

Epoch: 6| Step: 13
Training loss: 1.316897292199669
Validation loss: 2.4773351705453313

Epoch: 123| Step: 0
Training loss: 1.7349389336472645
Validation loss: 2.5367594363316934

Epoch: 6| Step: 1
Training loss: 0.9413364432004812
Validation loss: 2.52107775635518

Epoch: 6| Step: 2
Training loss: 1.3382018235526705
Validation loss: 2.4767906332587604

Epoch: 6| Step: 3
Training loss: 1.303219866329793
Validation loss: 2.523677015403349

Epoch: 6| Step: 4
Training loss: 0.9327835973099015
Validation loss: 2.5021861690211042

Epoch: 6| Step: 5
Training loss: 1.166126239584175
Validation loss: 2.5419675513436726

Epoch: 6| Step: 6
Training loss: 0.9335380761054014
Validation loss: 2.555233895979632

Epoch: 6| Step: 7
Training loss: 1.7154074331162776
Validation loss: 2.629498883995172

Epoch: 6| Step: 8
Training loss: 1.2514451256432852
Validation loss: 2.5519943117977197

Epoch: 6| Step: 9
Training loss: 1.6572009541517305
Validation loss: 2.5479599215770428

Epoch: 6| Step: 10
Training loss: 1.4724642276790407
Validation loss: 2.5027650879968544

Epoch: 6| Step: 11
Training loss: 1.172444777255806
Validation loss: 2.4918678262028613

Epoch: 6| Step: 12
Training loss: 1.701260026822333
Validation loss: 2.524686805261327

Epoch: 6| Step: 13
Training loss: 1.4063715140506587
Validation loss: 2.491708548033314

Epoch: 124| Step: 0
Training loss: 1.7338629989269196
Validation loss: 2.57329484474309

Epoch: 6| Step: 1
Training loss: 1.037417148820919
Validation loss: 2.5262898798378686

Epoch: 6| Step: 2
Training loss: 1.377658095382903
Validation loss: 2.578014517834736

Epoch: 6| Step: 3
Training loss: 1.032350242228278
Validation loss: 2.4836978829324563

Epoch: 6| Step: 4
Training loss: 1.145078456639431
Validation loss: 2.5028819162585374

Epoch: 6| Step: 5
Training loss: 1.2987798466708698
Validation loss: 2.521600438408281

Epoch: 6| Step: 6
Training loss: 1.0668465959268572
Validation loss: 2.5450834904624005

Epoch: 6| Step: 7
Training loss: 1.8216402507843277
Validation loss: 2.5667953699425174

Epoch: 6| Step: 8
Training loss: 0.8661559215393225
Validation loss: 2.583908037637676

Epoch: 6| Step: 9
Training loss: 1.7687103186156201
Validation loss: 2.5879404814134226

Epoch: 6| Step: 10
Training loss: 1.227497497680351
Validation loss: 2.538295704401357

Epoch: 6| Step: 11
Training loss: 1.3229074202487237
Validation loss: 2.5307955863816476

Epoch: 6| Step: 12
Training loss: 1.559221643157914
Validation loss: 2.544057680309825

Epoch: 6| Step: 13
Training loss: 1.4987872307283596
Validation loss: 2.5440077136410624

Epoch: 125| Step: 0
Training loss: 1.368334566937416
Validation loss: 2.5020675692563277

Epoch: 6| Step: 1
Training loss: 1.31825769102941
Validation loss: 2.510118638283307

Epoch: 6| Step: 2
Training loss: 1.7439012523395288
Validation loss: 2.470334651042625

Epoch: 6| Step: 3
Training loss: 1.082535278591202
Validation loss: 2.5557789624275395

Epoch: 6| Step: 4
Training loss: 1.9462199718042927
Validation loss: 2.500211817986874

Epoch: 6| Step: 5
Training loss: 1.2176684446738693
Validation loss: 2.493802949156835

Epoch: 6| Step: 6
Training loss: 1.0661694050568304
Validation loss: 2.490641067306276

Epoch: 6| Step: 7
Training loss: 1.002846778481102
Validation loss: 2.484950304896862

Epoch: 6| Step: 8
Training loss: 1.4749515363845782
Validation loss: 2.5436976609402757

Epoch: 6| Step: 9
Training loss: 1.416105028158274
Validation loss: 2.5151769424645485

Epoch: 6| Step: 10
Training loss: 1.1670478584066917
Validation loss: 2.524376622604273

Epoch: 6| Step: 11
Training loss: 0.9920880125133827
Validation loss: 2.5629209312271595

Epoch: 6| Step: 12
Training loss: 1.034706334639975
Validation loss: 2.5322044048916488

Epoch: 6| Step: 13
Training loss: 1.0099984053797455
Validation loss: 2.4994017520994958

Epoch: 126| Step: 0
Training loss: 1.3076353292652547
Validation loss: 2.5201181127479555

Epoch: 6| Step: 1
Training loss: 1.4604210578246588
Validation loss: 2.548896798369443

Epoch: 6| Step: 2
Training loss: 0.6968042893736477
Validation loss: 2.5027945793717863

Epoch: 6| Step: 3
Training loss: 1.12692260700866
Validation loss: 2.514924151172378

Epoch: 6| Step: 4
Training loss: 1.190882383145689
Validation loss: 2.4711794427997806

Epoch: 6| Step: 5
Training loss: 1.8533992107721873
Validation loss: 2.544507648505746

Epoch: 6| Step: 6
Training loss: 1.0795902302231046
Validation loss: 2.5455960766193213

Epoch: 6| Step: 7
Training loss: 1.044833741080924
Validation loss: 2.488090663539795

Epoch: 6| Step: 8
Training loss: 1.0751724725804124
Validation loss: 2.557843761839507

Epoch: 6| Step: 9
Training loss: 0.909664037330474
Validation loss: 2.5322705319107293

Epoch: 6| Step: 10
Training loss: 1.002307018817135
Validation loss: 2.567417930497306

Epoch: 6| Step: 11
Training loss: 0.903445838248463
Validation loss: 2.5566205052341084

Epoch: 6| Step: 12
Training loss: 1.962744742518978
Validation loss: 2.681959725491213

Epoch: 6| Step: 13
Training loss: 1.8787042267300096
Validation loss: 2.6419017947838377

Epoch: 127| Step: 0
Training loss: 1.675559573861545
Validation loss: 2.634140932206226

Epoch: 6| Step: 1
Training loss: 1.4280890195224751
Validation loss: 2.5821443610873813

Epoch: 6| Step: 2
Training loss: 1.0280992754005036
Validation loss: 2.5214163103478358

Epoch: 6| Step: 3
Training loss: 1.8321102426250424
Validation loss: 2.5490924722483013

Epoch: 6| Step: 4
Training loss: 1.043704798285001
Validation loss: 2.4532457471801794

Epoch: 6| Step: 5
Training loss: 0.9441634201056837
Validation loss: 2.500346429981832

Epoch: 6| Step: 6
Training loss: 1.6033986057046559
Validation loss: 2.53764496187206

Epoch: 6| Step: 7
Training loss: 1.424568643032103
Validation loss: 2.514623817891213

Epoch: 6| Step: 8
Training loss: 1.2078831700109203
Validation loss: 2.541679903423257

Epoch: 6| Step: 9
Training loss: 0.9931172797813455
Validation loss: 2.549751724361272

Epoch: 6| Step: 10
Training loss: 1.261442833366057
Validation loss: 2.5683502932002376

Epoch: 6| Step: 11
Training loss: 1.059737147543746
Validation loss: 2.5210341276375487

Epoch: 6| Step: 12
Training loss: 1.4360277680923939
Validation loss: 2.546469814155333

Epoch: 6| Step: 13
Training loss: 1.2584956428655494
Validation loss: 2.508966356751544

Epoch: 128| Step: 0
Training loss: 1.4246706464857946
Validation loss: 2.5358259103244127

Epoch: 6| Step: 1
Training loss: 1.3256208710558957
Validation loss: 2.588872866610535

Epoch: 6| Step: 2
Training loss: 1.3402324146155238
Validation loss: 2.501085546368903

Epoch: 6| Step: 3
Training loss: 0.9948695719839621
Validation loss: 2.538557837780045

Epoch: 6| Step: 4
Training loss: 1.209874874376286
Validation loss: 2.5851855995231428

Epoch: 6| Step: 5
Training loss: 1.2528218842152805
Validation loss: 2.5593631276781816

Epoch: 6| Step: 6
Training loss: 1.1045636357167932
Validation loss: 2.566305018208541

Epoch: 6| Step: 7
Training loss: 1.1551735996887158
Validation loss: 2.496847501562757

Epoch: 6| Step: 8
Training loss: 1.093857514682915
Validation loss: 2.543730419061702

Epoch: 6| Step: 9
Training loss: 1.8282477182785897
Validation loss: 2.54315978630114

Epoch: 6| Step: 10
Training loss: 1.3365521271940612
Validation loss: 2.5469719647942806

Epoch: 6| Step: 11
Training loss: 1.25165938860779
Validation loss: 2.581240134108734

Epoch: 6| Step: 12
Training loss: 1.6969049243852627
Validation loss: 2.5867014944379876

Epoch: 6| Step: 13
Training loss: 0.6666204664990704
Validation loss: 2.4769089192767875

Epoch: 129| Step: 0
Training loss: 1.2387677028403437
Validation loss: 2.5397092259668708

Epoch: 6| Step: 1
Training loss: 0.9880226611152491
Validation loss: 2.5061702480929444

Epoch: 6| Step: 2
Training loss: 1.290255739899603
Validation loss: 2.564157717353081

Epoch: 6| Step: 3
Training loss: 1.3474668950276647
Validation loss: 2.537342322200155

Epoch: 6| Step: 4
Training loss: 1.8918109043380147
Validation loss: 2.5248476857490836

Epoch: 6| Step: 5
Training loss: 1.1829431338214127
Validation loss: 2.5023747450470832

Epoch: 6| Step: 6
Training loss: 1.3355017057212983
Validation loss: 2.5254090660780997

Epoch: 6| Step: 7
Training loss: 1.1986438976345255
Validation loss: 2.5004547500274046

Epoch: 6| Step: 8
Training loss: 1.0561467566058007
Validation loss: 2.5591981440895637

Epoch: 6| Step: 9
Training loss: 0.9827625146717736
Validation loss: 2.541901074736834

Epoch: 6| Step: 10
Training loss: 1.8807112495824632
Validation loss: 2.5528495780091087

Epoch: 6| Step: 11
Training loss: 0.6905663340235365
Validation loss: 2.5902795822869074

Epoch: 6| Step: 12
Training loss: 1.0923392871170208
Validation loss: 2.5494317792957157

Epoch: 6| Step: 13
Training loss: 1.4077172572088443
Validation loss: 2.5784751885451827

Epoch: 130| Step: 0
Training loss: 1.2983581151462087
Validation loss: 2.5639433943728434

Epoch: 6| Step: 1
Training loss: 1.1071077738973685
Validation loss: 2.5084449390494172

Epoch: 6| Step: 2
Training loss: 1.9323046770369008
Validation loss: 2.477667408627141

Epoch: 6| Step: 3
Training loss: 1.5269733574971849
Validation loss: 2.5289235825171033

Epoch: 6| Step: 4
Training loss: 0.807531202321671
Validation loss: 2.5873820178151465

Epoch: 6| Step: 5
Training loss: 0.9838591540997603
Validation loss: 2.5108571807036077

Epoch: 6| Step: 6
Training loss: 0.8517404772755476
Validation loss: 2.569876273414

Epoch: 6| Step: 7
Training loss: 1.3690520732720302
Validation loss: 2.5498130873200004

Epoch: 6| Step: 8
Training loss: 0.8597016147354757
Validation loss: 2.6146186025806624

Epoch: 6| Step: 9
Training loss: 1.3574213919878861
Validation loss: 2.526736045386462

Epoch: 6| Step: 10
Training loss: 1.2270789547352585
Validation loss: 2.544468442855985

Epoch: 6| Step: 11
Training loss: 1.2988775028795334
Validation loss: 2.533045661638197

Epoch: 6| Step: 12
Training loss: 1.3011942256587112
Validation loss: 2.4619996780908675

Epoch: 6| Step: 13
Training loss: 1.2750394609366
Validation loss: 2.5003009297133754

Epoch: 131| Step: 0
Training loss: 1.1300731290936925
Validation loss: 2.560431056115419

Epoch: 6| Step: 1
Training loss: 1.8683297083351889
Validation loss: 2.470805185896376

Epoch: 6| Step: 2
Training loss: 1.016186485604882
Validation loss: 2.5323478139105364

Epoch: 6| Step: 3
Training loss: 1.156706333323062
Validation loss: 2.5390411063051026

Epoch: 6| Step: 4
Training loss: 1.0369342433383273
Validation loss: 2.6022076346214473

Epoch: 6| Step: 5
Training loss: 1.1404171584470555
Validation loss: 2.5831088973554963

Epoch: 6| Step: 6
Training loss: 0.8690282170331507
Validation loss: 2.5756427799022474

Epoch: 6| Step: 7
Training loss: 1.1668242393531223
Validation loss: 2.538720914898541

Epoch: 6| Step: 8
Training loss: 1.0698853914433895
Validation loss: 2.5776871897092026

Epoch: 6| Step: 9
Training loss: 1.5480785889304467
Validation loss: 2.465078456563781

Epoch: 6| Step: 10
Training loss: 1.4652826490918864
Validation loss: 2.519365803020336

Epoch: 6| Step: 11
Training loss: 1.0327622855902503
Validation loss: 2.569051369393647

Epoch: 6| Step: 12
Training loss: 1.3016359196319072
Validation loss: 2.5245363659625952

Epoch: 6| Step: 13
Training loss: 1.6949603158812037
Validation loss: 2.560568151087355

Epoch: 132| Step: 0
Training loss: 1.0612278783894205
Validation loss: 2.5424163812235827

Epoch: 6| Step: 1
Training loss: 1.1722704919385443
Validation loss: 2.6152540362385626

Epoch: 6| Step: 2
Training loss: 0.9747684937508504
Validation loss: 2.5269251166679623

Epoch: 6| Step: 3
Training loss: 0.9632779284541401
Validation loss: 2.5119998867491473

Epoch: 6| Step: 4
Training loss: 1.6210329343119916
Validation loss: 2.44465881970598

Epoch: 6| Step: 5
Training loss: 1.2101649619589878
Validation loss: 2.542625439230443

Epoch: 6| Step: 6
Training loss: 1.5258989842429038
Validation loss: 2.542717350390703

Epoch: 6| Step: 7
Training loss: 0.8844208371849961
Validation loss: 2.5898964225894083

Epoch: 6| Step: 8
Training loss: 1.0542447891739795
Validation loss: 2.531121058378451

Epoch: 6| Step: 9
Training loss: 0.9709585609766987
Validation loss: 2.5477335132345806

Epoch: 6| Step: 10
Training loss: 1.8154942345597258
Validation loss: 2.56254807869072

Epoch: 6| Step: 11
Training loss: 1.072526632480691
Validation loss: 2.5702442983373546

Epoch: 6| Step: 12
Training loss: 1.4989052592361438
Validation loss: 2.5241561826796968

Epoch: 6| Step: 13
Training loss: 0.9758395150887667
Validation loss: 2.5745733052634785

Epoch: 133| Step: 0
Training loss: 0.7388816692920595
Validation loss: 2.5487041886599604

Epoch: 6| Step: 1
Training loss: 1.050944772922601
Validation loss: 2.528540365820096

Epoch: 6| Step: 2
Training loss: 1.028088317958781
Validation loss: 2.5978636847637833

Epoch: 6| Step: 3
Training loss: 1.346763204373538
Validation loss: 2.535197551059754

Epoch: 6| Step: 4
Training loss: 0.8351347803651694
Validation loss: 2.5393705679995415

Epoch: 6| Step: 5
Training loss: 0.9951405770470219
Validation loss: 2.525611515715595

Epoch: 6| Step: 6
Training loss: 0.9602669337814745
Validation loss: 2.539892919653698

Epoch: 6| Step: 7
Training loss: 1.9648198454295744
Validation loss: 2.5846050014035478

Epoch: 6| Step: 8
Training loss: 1.75449040461754
Validation loss: 2.592716348118934

Epoch: 6| Step: 9
Training loss: 1.1041035664120324
Validation loss: 2.5048760863295008

Epoch: 6| Step: 10
Training loss: 1.4636440399675126
Validation loss: 2.5130832618245926

Epoch: 6| Step: 11
Training loss: 1.0393956732973495
Validation loss: 2.528359713541443

Epoch: 6| Step: 12
Training loss: 1.25111758816723
Validation loss: 2.5536016709515037

Epoch: 6| Step: 13
Training loss: 1.0908235910173425
Validation loss: 2.551499698362059

Epoch: 134| Step: 0
Training loss: 1.1612899840732136
Validation loss: 2.5386532497705945

Epoch: 6| Step: 1
Training loss: 1.3270939583505255
Validation loss: 2.5258968246200983

Epoch: 6| Step: 2
Training loss: 0.9783195253423478
Validation loss: 2.5291382885953366

Epoch: 6| Step: 3
Training loss: 1.192342021722432
Validation loss: 2.593404088068443

Epoch: 6| Step: 4
Training loss: 0.940786323780772
Validation loss: 2.559137728183923

Epoch: 6| Step: 5
Training loss: 1.1943931285175033
Validation loss: 2.5492898924683054

Epoch: 6| Step: 6
Training loss: 1.6247207695133152
Validation loss: 2.528948094341257

Epoch: 6| Step: 7
Training loss: 1.0525483089061407
Validation loss: 2.554994383878564

Epoch: 6| Step: 8
Training loss: 1.4024039762947609
Validation loss: 2.5893609472911354

Epoch: 6| Step: 9
Training loss: 0.965585091763082
Validation loss: 2.533366319374695

Epoch: 6| Step: 10
Training loss: 0.9753376412810408
Validation loss: 2.507260143893834

Epoch: 6| Step: 11
Training loss: 1.7278138886072019
Validation loss: 2.5110403739714666

Epoch: 6| Step: 12
Training loss: 0.9674072804736775
Validation loss: 2.5988870864510543

Epoch: 6| Step: 13
Training loss: 1.374130667790762
Validation loss: 2.5727320976826826

Epoch: 135| Step: 0
Training loss: 1.1635231970559419
Validation loss: 2.5724024290927243

Epoch: 6| Step: 1
Training loss: 1.1065982938426875
Validation loss: 2.5713010237865066

Epoch: 6| Step: 2
Training loss: 0.7211992163935809
Validation loss: 2.5204704485861456

Epoch: 6| Step: 3
Training loss: 0.9376703743299114
Validation loss: 2.588406739022015

Epoch: 6| Step: 4
Training loss: 1.4552137887679968
Validation loss: 2.488892277103154

Epoch: 6| Step: 5
Training loss: 1.53170006813487
Validation loss: 2.5739139575187115

Epoch: 6| Step: 6
Training loss: 0.8659974257604913
Validation loss: 2.600240957881049

Epoch: 6| Step: 7
Training loss: 1.0476380030147425
Validation loss: 2.5354888023912054

Epoch: 6| Step: 8
Training loss: 1.103037016388394
Validation loss: 2.5215766588457202

Epoch: 6| Step: 9
Training loss: 1.0621964638161485
Validation loss: 2.5985453143053814

Epoch: 6| Step: 10
Training loss: 1.2191640199557345
Validation loss: 2.5158609236191727

Epoch: 6| Step: 11
Training loss: 0.6483570416642135
Validation loss: 2.589465390315068

Epoch: 6| Step: 12
Training loss: 1.1011786908239534
Validation loss: 2.6142539061254824

Epoch: 6| Step: 13
Training loss: 1.9473466770211645
Validation loss: 2.5654269304225608

Epoch: 136| Step: 0
Training loss: 1.3581457170362532
Validation loss: 2.565532432989529

Epoch: 6| Step: 1
Training loss: 0.7193491553097654
Validation loss: 2.602950908430979

Epoch: 6| Step: 2
Training loss: 0.8099501285976993
Validation loss: 2.5721274077854113

Epoch: 6| Step: 3
Training loss: 1.790252556272572
Validation loss: 2.5405393716631397

Epoch: 6| Step: 4
Training loss: 1.0054651765678353
Validation loss: 2.527271739438922

Epoch: 6| Step: 5
Training loss: 0.9877617416688075
Validation loss: 2.54825529674687

Epoch: 6| Step: 6
Training loss: 0.905916218292188
Validation loss: 2.5715659041163352

Epoch: 6| Step: 7
Training loss: 1.741608938449882
Validation loss: 2.562951474619818

Epoch: 6| Step: 8
Training loss: 0.9849948142733317
Validation loss: 2.551492090571655

Epoch: 6| Step: 9
Training loss: 1.033123857020988
Validation loss: 2.5745988255549306

Epoch: 6| Step: 10
Training loss: 0.8385619561878177
Validation loss: 2.5404368197548064

Epoch: 6| Step: 11
Training loss: 1.434837529358895
Validation loss: 2.5172055888458384

Epoch: 6| Step: 12
Training loss: 1.3724608819108428
Validation loss: 2.626458761786507

Epoch: 6| Step: 13
Training loss: 0.8582253829576942
Validation loss: 2.5213331457400576

Epoch: 137| Step: 0
Training loss: 1.1433819413116735
Validation loss: 2.5386167946896907

Epoch: 6| Step: 1
Training loss: 1.861988250781399
Validation loss: 2.5553340579760957

Epoch: 6| Step: 2
Training loss: 0.9649200718149159
Validation loss: 2.5493742492929052

Epoch: 6| Step: 3
Training loss: 1.2961319782673677
Validation loss: 2.5213850904518784

Epoch: 6| Step: 4
Training loss: 1.0013327062692046
Validation loss: 2.5963279138664324

Epoch: 6| Step: 5
Training loss: 0.9254451093177312
Validation loss: 2.5531627993079287

Epoch: 6| Step: 6
Training loss: 1.009514487817729
Validation loss: 2.464547390862478

Epoch: 6| Step: 7
Training loss: 0.7844638333417469
Validation loss: 2.6180207249904446

Epoch: 6| Step: 8
Training loss: 1.0878907893675538
Validation loss: 2.5294747740485604

Epoch: 6| Step: 9
Training loss: 1.2629500955914559
Validation loss: 2.544251844373661

Epoch: 6| Step: 10
Training loss: 1.127589847511956
Validation loss: 2.5976065494687406

Epoch: 6| Step: 11
Training loss: 1.312202374455089
Validation loss: 2.497236870621474

Epoch: 6| Step: 12
Training loss: 1.212176765537945
Validation loss: 2.5134285446197797

Epoch: 6| Step: 13
Training loss: 0.6815417417489783
Validation loss: 2.5850617615228564

Epoch: 138| Step: 0
Training loss: 1.1199458289669892
Validation loss: 2.5509022113964184

Epoch: 6| Step: 1
Training loss: 0.8538363484829468
Validation loss: 2.51069024416927

Epoch: 6| Step: 2
Training loss: 1.6914696097895685
Validation loss: 2.5695102139094463

Epoch: 6| Step: 3
Training loss: 0.6556127042317422
Validation loss: 2.588381293463084

Epoch: 6| Step: 4
Training loss: 0.8394890324442466
Validation loss: 2.5983446169990123

Epoch: 6| Step: 5
Training loss: 1.2226206618909605
Validation loss: 2.602173406071765

Epoch: 6| Step: 6
Training loss: 1.5326400986523452
Validation loss: 2.597262734648535

Epoch: 6| Step: 7
Training loss: 1.432995580460095
Validation loss: 2.589004372907501

Epoch: 6| Step: 8
Training loss: 1.4455167059076506
Validation loss: 2.6299756743511202

Epoch: 6| Step: 9
Training loss: 1.1877243432397486
Validation loss: 2.571062529335807

Epoch: 6| Step: 10
Training loss: 1.157051633337187
Validation loss: 2.5372161255448087

Epoch: 6| Step: 11
Training loss: 1.4181318373197958
Validation loss: 2.618286175496417

Epoch: 6| Step: 12
Training loss: 1.274006067204663
Validation loss: 2.5646812413045033

Epoch: 6| Step: 13
Training loss: 1.1495315634304593
Validation loss: 2.573682575797043

Epoch: 139| Step: 0
Training loss: 1.0754902475855708
Validation loss: 2.5226341677404407

Epoch: 6| Step: 1
Training loss: 1.5379414614684814
Validation loss: 2.576525475193775

Epoch: 6| Step: 2
Training loss: 1.300541944514489
Validation loss: 2.572836829631519

Epoch: 6| Step: 3
Training loss: 1.1574998235187437
Validation loss: 2.562829112806225

Epoch: 6| Step: 4
Training loss: 1.0570544773885187
Validation loss: 2.6159147441632093

Epoch: 6| Step: 5
Training loss: 0.9894423166822482
Validation loss: 2.6434059321987657

Epoch: 6| Step: 6
Training loss: 1.3458597786886666
Validation loss: 2.554047281691409

Epoch: 6| Step: 7
Training loss: 0.8506994861444733
Validation loss: 2.533307326543062

Epoch: 6| Step: 8
Training loss: 1.0811843587542072
Validation loss: 2.581862851498065

Epoch: 6| Step: 9
Training loss: 1.3074775148285445
Validation loss: 2.6102946292230906

Epoch: 6| Step: 10
Training loss: 0.8837746634812008
Validation loss: 2.5697009471213796

Epoch: 6| Step: 11
Training loss: 1.5741019004448247
Validation loss: 2.570431073670359

Epoch: 6| Step: 12
Training loss: 0.8880772875668067
Validation loss: 2.5584600360282104

Epoch: 6| Step: 13
Training loss: 0.9406774081714738
Validation loss: 2.550593947134546

Epoch: 140| Step: 0
Training loss: 1.1641399690592795
Validation loss: 2.52809583900964

Epoch: 6| Step: 1
Training loss: 1.1754123451201246
Validation loss: 2.517066889848459

Epoch: 6| Step: 2
Training loss: 0.769257705015139
Validation loss: 2.577118694542867

Epoch: 6| Step: 3
Training loss: 1.1555605714538317
Validation loss: 2.5406546506132948

Epoch: 6| Step: 4
Training loss: 1.005905002188748
Validation loss: 2.5556342249892174

Epoch: 6| Step: 5
Training loss: 0.8820893017677007
Validation loss: 2.4712896683653827

Epoch: 6| Step: 6
Training loss: 0.8755238872038353
Validation loss: 2.5436594191661124

Epoch: 6| Step: 7
Training loss: 0.8339992405730159
Validation loss: 2.5529559038584857

Epoch: 6| Step: 8
Training loss: 1.2632586173422886
Validation loss: 2.563014451775878

Epoch: 6| Step: 9
Training loss: 2.0326805359260987
Validation loss: 2.5600146437141693

Epoch: 6| Step: 10
Training loss: 1.2940321867947548
Validation loss: 2.5899146651910363

Epoch: 6| Step: 11
Training loss: 1.0215113328108079
Validation loss: 2.575379931250589

Epoch: 6| Step: 12
Training loss: 0.8459315531098509
Validation loss: 2.5249715970270548

Epoch: 6| Step: 13
Training loss: 0.9035297872618375
Validation loss: 2.553817398643294

Epoch: 141| Step: 0
Training loss: 1.150558381729261
Validation loss: 2.5713955839882057

Epoch: 6| Step: 1
Training loss: 0.8130353117848425
Validation loss: 2.6124367026367956

Epoch: 6| Step: 2
Training loss: 0.984001603530337
Validation loss: 2.5751781383487096

Epoch: 6| Step: 3
Training loss: 1.0708187047847295
Validation loss: 2.5702742058743016

Epoch: 6| Step: 4
Training loss: 1.5196461768928142
Validation loss: 2.537471198245801

Epoch: 6| Step: 5
Training loss: 1.0903590361705584
Validation loss: 2.530101570545723

Epoch: 6| Step: 6
Training loss: 0.9802683591283579
Validation loss: 2.5810661108789175

Epoch: 6| Step: 7
Training loss: 0.9461425730851977
Validation loss: 2.590302761822147

Epoch: 6| Step: 8
Training loss: 1.131997492716678
Validation loss: 2.5855896515090127

Epoch: 6| Step: 9
Training loss: 0.5022015383644803
Validation loss: 2.5561458768522938

Epoch: 6| Step: 10
Training loss: 1.8924249325254994
Validation loss: 2.523390888614274

Epoch: 6| Step: 11
Training loss: 1.07981276054664
Validation loss: 2.621144718256391

Epoch: 6| Step: 12
Training loss: 1.560597825919454
Validation loss: 2.5832117241774424

Epoch: 6| Step: 13
Training loss: 0.8179511825292739
Validation loss: 2.602808672005653

Epoch: 142| Step: 0
Training loss: 1.6270275671369656
Validation loss: 2.5837492197863283

Epoch: 6| Step: 1
Training loss: 0.7499818799690979
Validation loss: 2.50069705464283

Epoch: 6| Step: 2
Training loss: 1.1962383399642256
Validation loss: 2.526728999955094

Epoch: 6| Step: 3
Training loss: 0.9739715996857011
Validation loss: 2.5585403708599697

Epoch: 6| Step: 4
Training loss: 0.9286878324215789
Validation loss: 2.5902244399314593

Epoch: 6| Step: 5
Training loss: 1.5762482616345397
Validation loss: 2.5904761952303703

Epoch: 6| Step: 6
Training loss: 0.9300914495892321
Validation loss: 2.5789455148503806

Epoch: 6| Step: 7
Training loss: 0.8125167991662124
Validation loss: 2.6150932929207937

Epoch: 6| Step: 8
Training loss: 1.2308714192635588
Validation loss: 2.537245435739621

Epoch: 6| Step: 9
Training loss: 1.0174441551423414
Validation loss: 2.53128097264057

Epoch: 6| Step: 10
Training loss: 0.933454175914439
Validation loss: 2.5071364350094982

Epoch: 6| Step: 11
Training loss: 0.9398250993382712
Validation loss: 2.5263822712624298

Epoch: 6| Step: 12
Training loss: 0.8507210660302544
Validation loss: 2.5189203827862605

Epoch: 6| Step: 13
Training loss: 1.5413254111002785
Validation loss: 2.6121551033521357

Epoch: 143| Step: 0
Training loss: 0.8266263392697302
Validation loss: 2.5299920303862526

Epoch: 6| Step: 1
Training loss: 1.195663500343925
Validation loss: 2.514322611122106

Epoch: 6| Step: 2
Training loss: 1.3530322776547536
Validation loss: 2.528698376870186

Epoch: 6| Step: 3
Training loss: 1.113302986869756
Validation loss: 2.5856059342996085

Epoch: 6| Step: 4
Training loss: 0.802746180983553
Validation loss: 2.5926525904383775

Epoch: 6| Step: 5
Training loss: 0.7833951871543453
Validation loss: 2.5913730745335846

Epoch: 6| Step: 6
Training loss: 0.5907076137025571
Validation loss: 2.6700323491750195

Epoch: 6| Step: 7
Training loss: 1.0070706971627474
Validation loss: 2.5109700876371273

Epoch: 6| Step: 8
Training loss: 1.2317162865247895
Validation loss: 2.576873275061724

Epoch: 6| Step: 9
Training loss: 0.9845487955864125
Validation loss: 2.5283122184725033

Epoch: 6| Step: 10
Training loss: 1.0276406442954578
Validation loss: 2.5556554486842957

Epoch: 6| Step: 11
Training loss: 0.9933170287076372
Validation loss: 2.5381694299033777

Epoch: 6| Step: 12
Training loss: 1.567221945234819
Validation loss: 2.6110523490065307

Epoch: 6| Step: 13
Training loss: 1.3955325424106688
Validation loss: 2.5812267872010617

Epoch: 144| Step: 0
Training loss: 0.8134704076710437
Validation loss: 2.63254741235962

Epoch: 6| Step: 1
Training loss: 0.8470507449967856
Validation loss: 2.5786931500414547

Epoch: 6| Step: 2
Training loss: 0.8020795021130767
Validation loss: 2.5289884283450417

Epoch: 6| Step: 3
Training loss: 1.5899610171547531
Validation loss: 2.51946683894977

Epoch: 6| Step: 4
Training loss: 1.3327304649373937
Validation loss: 2.5737596873366164

Epoch: 6| Step: 5
Training loss: 1.3582270806926011
Validation loss: 2.5951458112854424

Epoch: 6| Step: 6
Training loss: 1.127287023522177
Validation loss: 2.586498572264043

Epoch: 6| Step: 7
Training loss: 1.1524795710807298
Validation loss: 2.5624950998150875

Epoch: 6| Step: 8
Training loss: 1.2212449969186279
Validation loss: 2.6632804580408296

Epoch: 6| Step: 9
Training loss: 0.9480440068211371
Validation loss: 2.5635735968738134

Epoch: 6| Step: 10
Training loss: 0.8521354217899241
Validation loss: 2.562607460559991

Epoch: 6| Step: 11
Training loss: 0.9915772010345802
Validation loss: 2.5738881139518277

Epoch: 6| Step: 12
Training loss: 0.6238777575637325
Validation loss: 2.5344805333703198

Epoch: 6| Step: 13
Training loss: 1.082834214382235
Validation loss: 2.564163536422781

Epoch: 145| Step: 0
Training loss: 0.5528487771197961
Validation loss: 2.5763997942844217

Epoch: 6| Step: 1
Training loss: 0.9406233258406737
Validation loss: 2.5656761241779997

Epoch: 6| Step: 2
Training loss: 0.9354068595581699
Validation loss: 2.523357441265017

Epoch: 6| Step: 3
Training loss: 1.7606494982839416
Validation loss: 2.5997583741617705

Epoch: 6| Step: 4
Training loss: 0.8264526899981854
Validation loss: 2.622610094143256

Epoch: 6| Step: 5
Training loss: 1.3897136745299725
Validation loss: 2.587159573924598

Epoch: 6| Step: 6
Training loss: 1.056910735912948
Validation loss: 2.5769248558006175

Epoch: 6| Step: 7
Training loss: 1.033336551466412
Validation loss: 2.581568289307252

Epoch: 6| Step: 8
Training loss: 0.7971952954026673
Validation loss: 2.4665304016372938

Epoch: 6| Step: 9
Training loss: 0.999255230843885
Validation loss: 2.591621582726693

Epoch: 6| Step: 10
Training loss: 1.0352643802236408
Validation loss: 2.4961634921189377

Epoch: 6| Step: 11
Training loss: 0.8623818247456351
Validation loss: 2.553683014444118

Epoch: 6| Step: 12
Training loss: 1.308957632913523
Validation loss: 2.573645242761043

Epoch: 6| Step: 13
Training loss: 0.9722941080644023
Validation loss: 2.526011127929661

Epoch: 146| Step: 0
Training loss: 0.7750782373376547
Validation loss: 2.582827569817967

Epoch: 6| Step: 1
Training loss: 1.1359739714884451
Validation loss: 2.56289938008641

Epoch: 6| Step: 2
Training loss: 1.2244290792566936
Validation loss: 2.54210167169222

Epoch: 6| Step: 3
Training loss: 0.9425066772649388
Validation loss: 2.496360163632045

Epoch: 6| Step: 4
Training loss: 1.0798302033073781
Validation loss: 2.6217432406528007

Epoch: 6| Step: 5
Training loss: 0.9689839296002369
Validation loss: 2.5505585351740674

Epoch: 6| Step: 6
Training loss: 1.3458173949692458
Validation loss: 2.5759777336244243

Epoch: 6| Step: 7
Training loss: 0.9260415141931901
Validation loss: 2.5706079036936513

Epoch: 6| Step: 8
Training loss: 0.9903583637088724
Validation loss: 2.5241854005179065

Epoch: 6| Step: 9
Training loss: 1.6246844498828947
Validation loss: 2.6111092809801475

Epoch: 6| Step: 10
Training loss: 0.8527686649964974
Validation loss: 2.6033858285740603

Epoch: 6| Step: 11
Training loss: 0.8065000323788092
Validation loss: 2.516438149399345

Epoch: 6| Step: 12
Training loss: 1.169687441867396
Validation loss: 2.525897217910378

Epoch: 6| Step: 13
Training loss: 0.743010295745244
Validation loss: 2.528963256985337

Epoch: 147| Step: 0
Training loss: 0.9307229822967684
Validation loss: 2.619018301500403

Epoch: 6| Step: 1
Training loss: 1.7979600367024573
Validation loss: 2.5445747675506083

Epoch: 6| Step: 2
Training loss: 0.6692692550066632
Validation loss: 2.6151782013888325

Epoch: 6| Step: 3
Training loss: 0.8174309391633728
Validation loss: 2.581981648840624

Epoch: 6| Step: 4
Training loss: 1.1162639081372574
Validation loss: 2.5876733537551755

Epoch: 6| Step: 5
Training loss: 0.8352128925866705
Validation loss: 2.6406713176931276

Epoch: 6| Step: 6
Training loss: 1.2104004191863702
Validation loss: 2.5678395101739073

Epoch: 6| Step: 7
Training loss: 0.8565193587930775
Validation loss: 2.5774516603886912

Epoch: 6| Step: 8
Training loss: 0.8285583226102281
Validation loss: 2.621889814987429

Epoch: 6| Step: 9
Training loss: 1.4129887503292902
Validation loss: 2.5670521009126497

Epoch: 6| Step: 10
Training loss: 0.9521601436580075
Validation loss: 2.5529985901609167

Epoch: 6| Step: 11
Training loss: 1.0120807721694656
Validation loss: 2.6007186391667307

Epoch: 6| Step: 12
Training loss: 0.6860676279223
Validation loss: 2.5102894752117995

Epoch: 6| Step: 13
Training loss: 1.1696012691313489
Validation loss: 2.5992778181636176

Epoch: 148| Step: 0
Training loss: 0.7530909661165159
Validation loss: 2.606672398820251

Epoch: 6| Step: 1
Training loss: 0.9111048785115367
Validation loss: 2.58040220856421

Epoch: 6| Step: 2
Training loss: 1.0579671095943959
Validation loss: 2.6166433954925155

Epoch: 6| Step: 3
Training loss: 0.8266500257219451
Validation loss: 2.6223154797534396

Epoch: 6| Step: 4
Training loss: 1.3459466234991326
Validation loss: 2.5686167231479047

Epoch: 6| Step: 5
Training loss: 1.058519874613213
Validation loss: 2.5645839157124493

Epoch: 6| Step: 6
Training loss: 1.0143429220019862
Validation loss: 2.541033514821408

Epoch: 6| Step: 7
Training loss: 1.2868601625762677
Validation loss: 2.609339799472235

Epoch: 6| Step: 8
Training loss: 0.8392813995505505
Validation loss: 2.5567148002120437

Epoch: 6| Step: 9
Training loss: 1.2358555184240303
Validation loss: 2.5721962160764495

Epoch: 6| Step: 10
Training loss: 0.789571956428421
Validation loss: 2.628900793409046

Epoch: 6| Step: 11
Training loss: 0.8798241463429832
Validation loss: 2.6081317368703836

Epoch: 6| Step: 12
Training loss: 1.4777357496214363
Validation loss: 2.5994619341547684

Epoch: 6| Step: 13
Training loss: 1.0983099569014354
Validation loss: 2.5786025404578505

Epoch: 149| Step: 0
Training loss: 0.8934556583081695
Validation loss: 2.541397007463068

Epoch: 6| Step: 1
Training loss: 1.1637576427270218
Validation loss: 2.5903102019334283

Epoch: 6| Step: 2
Training loss: 0.856501056592549
Validation loss: 2.5602439935956007

Epoch: 6| Step: 3
Training loss: 0.8735022669273094
Validation loss: 2.632040693613942

Epoch: 6| Step: 4
Training loss: 1.1540570469842866
Validation loss: 2.5660874291141815

Epoch: 6| Step: 5
Training loss: 1.111996468164475
Validation loss: 2.6087166875184633

Epoch: 6| Step: 6
Training loss: 1.1991727242351031
Validation loss: 2.5725539617189392

Epoch: 6| Step: 7
Training loss: 1.3650494233290982
Validation loss: 2.6452496452998275

Epoch: 6| Step: 8
Training loss: 1.5180468528864957
Validation loss: 2.5561343965140204

Epoch: 6| Step: 9
Training loss: 0.6729954979449799
Validation loss: 2.5974420138860435

Epoch: 6| Step: 10
Training loss: 0.6547454890241056
Validation loss: 2.5796522760787965

Epoch: 6| Step: 11
Training loss: 0.8007165650084572
Validation loss: 2.6096577748106435

Epoch: 6| Step: 12
Training loss: 0.8254622349363733
Validation loss: 2.6219560291619777

Epoch: 6| Step: 13
Training loss: 1.1885775646212458
Validation loss: 2.5959517391217353

Epoch: 150| Step: 0
Training loss: 0.697193302282574
Validation loss: 2.577553148137945

Epoch: 6| Step: 1
Training loss: 0.9997700784531425
Validation loss: 2.622266193558224

Epoch: 6| Step: 2
Training loss: 0.7324038083709254
Validation loss: 2.631691427043891

Epoch: 6| Step: 3
Training loss: 1.241700082794381
Validation loss: 2.6578769712647876

Epoch: 6| Step: 4
Training loss: 1.2310696058233341
Validation loss: 2.60136360882136

Epoch: 6| Step: 5
Training loss: 0.94327634836983
Validation loss: 2.5768335903435626

Epoch: 6| Step: 6
Training loss: 0.8786251720689341
Validation loss: 2.6218677482762343

Epoch: 6| Step: 7
Training loss: 0.9371585542050807
Validation loss: 2.61239052319552

Epoch: 6| Step: 8
Training loss: 0.6722242645183607
Validation loss: 2.5566669692976407

Epoch: 6| Step: 9
Training loss: 1.5654778142945176
Validation loss: 2.6006314097836363

Epoch: 6| Step: 10
Training loss: 1.4534043074405831
Validation loss: 2.603544211701687

Epoch: 6| Step: 11
Training loss: 1.187690568991951
Validation loss: 2.610391689058246

Epoch: 6| Step: 12
Training loss: 0.70457432043115
Validation loss: 2.604802432973258

Epoch: 6| Step: 13
Training loss: 1.0095753001545398
Validation loss: 2.629839281434155

Epoch: 151| Step: 0
Training loss: 0.8250653587807882
Validation loss: 2.5976028016215773

Epoch: 6| Step: 1
Training loss: 1.2802577014133514
Validation loss: 2.6112607891614044

Epoch: 6| Step: 2
Training loss: 1.293550205006955
Validation loss: 2.5766388279775083

Epoch: 6| Step: 3
Training loss: 0.6431592730851511
Validation loss: 2.621555626884785

Epoch: 6| Step: 4
Training loss: 0.9372999931610573
Validation loss: 2.6121887599617866

Epoch: 6| Step: 5
Training loss: 1.0926443233354575
Validation loss: 2.534659393321516

Epoch: 6| Step: 6
Training loss: 1.392627431630613
Validation loss: 2.6279065827982215

Epoch: 6| Step: 7
Training loss: 1.122177291564485
Validation loss: 2.5615299994107956

Epoch: 6| Step: 8
Training loss: 1.3363988425536681
Validation loss: 2.633516951287751

Epoch: 6| Step: 9
Training loss: 0.574587178271594
Validation loss: 2.5610388179688632

Epoch: 6| Step: 10
Training loss: 0.7612805793520923
Validation loss: 2.580982728287712

Epoch: 6| Step: 11
Training loss: 0.9687283728861888
Validation loss: 2.6202544959420715

Epoch: 6| Step: 12
Training loss: 0.8602750746363208
Validation loss: 2.5905139069460312

Epoch: 6| Step: 13
Training loss: 0.8843214591705703
Validation loss: 2.582357781289523

Epoch: 152| Step: 0
Training loss: 0.745151703961248
Validation loss: 2.666420587470762

Epoch: 6| Step: 1
Training loss: 1.1652756072731298
Validation loss: 2.5609563737212184

Epoch: 6| Step: 2
Training loss: 1.2259265198460174
Validation loss: 2.6303054011093776

Epoch: 6| Step: 3
Training loss: 1.0325483760630891
Validation loss: 2.653359377408124

Epoch: 6| Step: 4
Training loss: 0.8104838519126217
Validation loss: 2.6502555975817557

Epoch: 6| Step: 5
Training loss: 0.8341843948106398
Validation loss: 2.5437823125613064

Epoch: 6| Step: 6
Training loss: 1.4342889165706851
Validation loss: 2.648297999186116

Epoch: 6| Step: 7
Training loss: 0.8066229645132774
Validation loss: 2.671280778092618

Epoch: 6| Step: 8
Training loss: 0.6739805629627285
Validation loss: 2.5468214064499946

Epoch: 6| Step: 9
Training loss: 0.6635304282857093
Validation loss: 2.600149800191143

Epoch: 6| Step: 10
Training loss: 1.3309786040852707
Validation loss: 2.6380370058930294

Epoch: 6| Step: 11
Training loss: 1.2124220577239606
Validation loss: 2.587969347638139

Epoch: 6| Step: 12
Training loss: 0.792152021768575
Validation loss: 2.599690341237918

Epoch: 6| Step: 13
Training loss: 0.9591949293898184
Validation loss: 2.5744184880582424

Epoch: 153| Step: 0
Training loss: 1.1893743980674805
Validation loss: 2.594685397325886

Epoch: 6| Step: 1
Training loss: 0.9282279217614329
Validation loss: 2.5994720308061563

Epoch: 6| Step: 2
Training loss: 0.7754545017326983
Validation loss: 2.6364870925675143

Epoch: 6| Step: 3
Training loss: 0.9528325992514898
Validation loss: 2.647252510709656

Epoch: 6| Step: 4
Training loss: 1.0303218595145016
Validation loss: 2.6468532929174033

Epoch: 6| Step: 5
Training loss: 0.8403847304936515
Validation loss: 2.667828073511614

Epoch: 6| Step: 6
Training loss: 1.0419695350308342
Validation loss: 2.6509339785984367

Epoch: 6| Step: 7
Training loss: 0.8183219373055824
Validation loss: 2.6164914244590176

Epoch: 6| Step: 8
Training loss: 0.9976324426593004
Validation loss: 2.6098820237526654

Epoch: 6| Step: 9
Training loss: 0.6582858659033267
Validation loss: 2.605398288671954

Epoch: 6| Step: 10
Training loss: 1.1125328359151383
Validation loss: 2.640383888086518

Epoch: 6| Step: 11
Training loss: 0.5453540906375507
Validation loss: 2.5856736539326888

Epoch: 6| Step: 12
Training loss: 1.7399552760460197
Validation loss: 2.574014210811691

Epoch: 6| Step: 13
Training loss: 0.8333893200822827
Validation loss: 2.618699706360145

Epoch: 154| Step: 0
Training loss: 1.136150204815733
Validation loss: 2.6293354109242624

Epoch: 6| Step: 1
Training loss: 1.4973185732162966
Validation loss: 2.665539642434189

Epoch: 6| Step: 2
Training loss: 0.761100948881571
Validation loss: 2.5977387302851622

Epoch: 6| Step: 3
Training loss: 0.920286102434463
Validation loss: 2.558120217802311

Epoch: 6| Step: 4
Training loss: 0.5609623768000129
Validation loss: 2.641505032677724

Epoch: 6| Step: 5
Training loss: 0.7656905477063184
Validation loss: 2.5732978713436703

Epoch: 6| Step: 6
Training loss: 0.764026218169158
Validation loss: 2.5835086983461144

Epoch: 6| Step: 7
Training loss: 0.9662257810076693
Validation loss: 2.626204607845296

Epoch: 6| Step: 8
Training loss: 0.7619411828427148
Validation loss: 2.5986829062604078

Epoch: 6| Step: 9
Training loss: 1.4903126067379293
Validation loss: 2.5777267765018537

Epoch: 6| Step: 10
Training loss: 0.5520926480737063
Validation loss: 2.5936252916375637

Epoch: 6| Step: 11
Training loss: 1.1010414135564817
Validation loss: 2.568171853301648

Epoch: 6| Step: 12
Training loss: 1.008551275066606
Validation loss: 2.5957377679989686

Epoch: 6| Step: 13
Training loss: 0.8742105464874258
Validation loss: 2.5558330366816273

Epoch: 155| Step: 0
Training loss: 0.4391355935612535
Validation loss: 2.520702521553009

Epoch: 6| Step: 1
Training loss: 0.8467566291317574
Validation loss: 2.5604703044523878

Epoch: 6| Step: 2
Training loss: 1.1960549137082
Validation loss: 2.5664628872749837

Epoch: 6| Step: 3
Training loss: 0.7285571457226864
Validation loss: 2.587846825187031

Epoch: 6| Step: 4
Training loss: 1.6809699552076083
Validation loss: 2.584652445982877

Epoch: 6| Step: 5
Training loss: 0.5781727848409217
Validation loss: 2.5848797558549608

Epoch: 6| Step: 6
Training loss: 1.0557013830598105
Validation loss: 2.6485785462697335

Epoch: 6| Step: 7
Training loss: 1.1033531406925763
Validation loss: 2.5623929691447302

Epoch: 6| Step: 8
Training loss: 1.0478742015771418
Validation loss: 2.5480621473108203

Epoch: 6| Step: 9
Training loss: 1.147828388223584
Validation loss: 2.6275111705906746

Epoch: 6| Step: 10
Training loss: 0.8913458199374189
Validation loss: 2.6415481458564494

Epoch: 6| Step: 11
Training loss: 0.691856151692794
Validation loss: 2.6240655810245794

Epoch: 6| Step: 12
Training loss: 0.8401264513295797
Validation loss: 2.6087930605273857

Epoch: 6| Step: 13
Training loss: 1.1708356189818603
Validation loss: 2.5871150014467577

Epoch: 156| Step: 0
Training loss: 0.6408708612328093
Validation loss: 2.622667911561568

Epoch: 6| Step: 1
Training loss: 0.8123801950011851
Validation loss: 2.591110832450805

Epoch: 6| Step: 2
Training loss: 1.0787148451574613
Validation loss: 2.637843727023692

Epoch: 6| Step: 3
Training loss: 1.3210806784499174
Validation loss: 2.6169421332432035

Epoch: 6| Step: 4
Training loss: 1.382997920649159
Validation loss: 2.573453396761785

Epoch: 6| Step: 5
Training loss: 1.0070295619432552
Validation loss: 2.6617761087540113

Epoch: 6| Step: 6
Training loss: 1.0105859018287242
Validation loss: 2.5725086727805544

Epoch: 6| Step: 7
Training loss: 1.0403225937614622
Validation loss: 2.5967697734300885

Epoch: 6| Step: 8
Training loss: 0.9713945286660131
Validation loss: 2.6120405002947513

Epoch: 6| Step: 9
Training loss: 1.1239337106481844
Validation loss: 2.606976028785784

Epoch: 6| Step: 10
Training loss: 0.6178949864246005
Validation loss: 2.6163078386037677

Epoch: 6| Step: 11
Training loss: 0.9534216247257186
Validation loss: 2.6054508755750883

Epoch: 6| Step: 12
Training loss: 0.880330876655237
Validation loss: 2.620178904394786

Epoch: 6| Step: 13
Training loss: 0.7052674818566582
Validation loss: 2.6242694065102885

Epoch: 157| Step: 0
Training loss: 0.7413554295767663
Validation loss: 2.595329416592328

Epoch: 6| Step: 1
Training loss: 0.7485909736659847
Validation loss: 2.625577469537567

Epoch: 6| Step: 2
Training loss: 0.87349571620893
Validation loss: 2.6061291484424967

Epoch: 6| Step: 3
Training loss: 0.7489935161478004
Validation loss: 2.628775847981038

Epoch: 6| Step: 4
Training loss: 0.8561389684040259
Validation loss: 2.5820274333762137

Epoch: 6| Step: 5
Training loss: 1.0448361940996351
Validation loss: 2.637411957969256

Epoch: 6| Step: 6
Training loss: 1.2512316358135176
Validation loss: 2.5983640390098466

Epoch: 6| Step: 7
Training loss: 1.07663657233949
Validation loss: 2.6512598623679544

Epoch: 6| Step: 8
Training loss: 1.3567671040528262
Validation loss: 2.582524716559638

Epoch: 6| Step: 9
Training loss: 0.9965781735574987
Validation loss: 2.6410685059582746

Epoch: 6| Step: 10
Training loss: 1.0065857866039793
Validation loss: 2.6166151265415913

Epoch: 6| Step: 11
Training loss: 1.535571248499841
Validation loss: 2.5797254122515394

Epoch: 6| Step: 12
Training loss: 0.9261498984790852
Validation loss: 2.6243551309876216

Epoch: 6| Step: 13
Training loss: 0.9154733708049039
Validation loss: 2.5471064846568168

Epoch: 158| Step: 0
Training loss: 0.8714587896499211
Validation loss: 2.6159851045096953

Epoch: 6| Step: 1
Training loss: 0.7681753538433261
Validation loss: 2.6824435638577486

Epoch: 6| Step: 2
Training loss: 1.1549776138679364
Validation loss: 2.6751596141742264

Epoch: 6| Step: 3
Training loss: 1.1898467316217567
Validation loss: 2.5669088505352855

Epoch: 6| Step: 4
Training loss: 0.724734724775325
Validation loss: 2.669014021762201

Epoch: 6| Step: 5
Training loss: 0.6389174616224801
Validation loss: 2.5814902488597724

Epoch: 6| Step: 6
Training loss: 0.757710243483506
Validation loss: 2.6215188240308183

Epoch: 6| Step: 7
Training loss: 0.7492545714978731
Validation loss: 2.6183427073624337

Epoch: 6| Step: 8
Training loss: 1.0352706558057172
Validation loss: 2.631383430679953

Epoch: 6| Step: 9
Training loss: 0.7683471244296973
Validation loss: 2.597230299825455

Epoch: 6| Step: 10
Training loss: 1.4061654383348163
Validation loss: 2.5993409088631294

Epoch: 6| Step: 11
Training loss: 1.5050303035992987
Validation loss: 2.5804334766865575

Epoch: 6| Step: 12
Training loss: 0.9334438634603808
Validation loss: 2.5728605215353486

Epoch: 6| Step: 13
Training loss: 0.7829400664834302
Validation loss: 2.621483218142067

Epoch: 159| Step: 0
Training loss: 0.6927938814805955
Validation loss: 2.630071040935788

Epoch: 6| Step: 1
Training loss: 1.7114491155015892
Validation loss: 2.6237996702443542

Epoch: 6| Step: 2
Training loss: 0.855757782067396
Validation loss: 2.611852539481977

Epoch: 6| Step: 3
Training loss: 0.7148111054517853
Validation loss: 2.6581935728239237

Epoch: 6| Step: 4
Training loss: 1.091132000795268
Validation loss: 2.5892743635007114

Epoch: 6| Step: 5
Training loss: 0.5396667355870577
Validation loss: 2.603091152622921

Epoch: 6| Step: 6
Training loss: 0.701047625995793
Validation loss: 2.6098330356521315

Epoch: 6| Step: 7
Training loss: 1.1150406704314908
Validation loss: 2.6479880252550085

Epoch: 6| Step: 8
Training loss: 0.8514498714894276
Validation loss: 2.597320611442152

Epoch: 6| Step: 9
Training loss: 0.7928979024572842
Validation loss: 2.5933211711297623

Epoch: 6| Step: 10
Training loss: 0.8158960893072754
Validation loss: 2.630879787940771

Epoch: 6| Step: 11
Training loss: 1.0411336806813976
Validation loss: 2.6169835404969386

Epoch: 6| Step: 12
Training loss: 0.5824281504118348
Validation loss: 2.6518951620953324

Epoch: 6| Step: 13
Training loss: 0.9237900256311149
Validation loss: 2.598391091946779

Epoch: 160| Step: 0
Training loss: 0.5878420077780687
Validation loss: 2.638921184230635

Epoch: 6| Step: 1
Training loss: 1.458424901358178
Validation loss: 2.616354867759643

Epoch: 6| Step: 2
Training loss: 1.1597257386926472
Validation loss: 2.6537464835283937

Epoch: 6| Step: 3
Training loss: 1.0027195785613672
Validation loss: 2.6152606912456435

Epoch: 6| Step: 4
Training loss: 0.5188408760533897
Validation loss: 2.626958162097285

Epoch: 6| Step: 5
Training loss: 1.3061757992929004
Validation loss: 2.6663775336955284

Epoch: 6| Step: 6
Training loss: 0.8423749881330592
Validation loss: 2.6159427700461295

Epoch: 6| Step: 7
Training loss: 0.6254695082504323
Validation loss: 2.623380221812659

Epoch: 6| Step: 8
Training loss: 0.8551016938928951
Validation loss: 2.6375152213815967

Epoch: 6| Step: 9
Training loss: 0.5932659886838365
Validation loss: 2.6066200347381376

Epoch: 6| Step: 10
Training loss: 0.9071555053346241
Validation loss: 2.5602548890080965

Epoch: 6| Step: 11
Training loss: 1.0222022486258002
Validation loss: 2.6127253436744513

Epoch: 6| Step: 12
Training loss: 0.8230201720480625
Validation loss: 2.6399206392083374

Epoch: 6| Step: 13
Training loss: 0.7811379924590401
Validation loss: 2.615226960213225

Epoch: 161| Step: 0
Training loss: 1.4316168102661995
Validation loss: 2.5931784371581013

Epoch: 6| Step: 1
Training loss: 0.6820544759983959
Validation loss: 2.6061559378088077

Epoch: 6| Step: 2
Training loss: 0.8161134331623049
Validation loss: 2.593926128857176

Epoch: 6| Step: 3
Training loss: 0.8187351866102752
Validation loss: 2.6142766906945853

Epoch: 6| Step: 4
Training loss: 0.9143199069151872
Validation loss: 2.5607637710714943

Epoch: 6| Step: 5
Training loss: 0.7188723916046414
Validation loss: 2.5379251603108766

Epoch: 6| Step: 6
Training loss: 1.0930155876981682
Validation loss: 2.557572939153639

Epoch: 6| Step: 7
Training loss: 1.473653036071054
Validation loss: 2.6032265504810126

Epoch: 6| Step: 8
Training loss: 0.8305565027793606
Validation loss: 2.5908104965497554

Epoch: 6| Step: 9
Training loss: 0.7044342567139715
Validation loss: 2.5746678919029513

Epoch: 6| Step: 10
Training loss: 0.9479834285044196
Validation loss: 2.5987172954654967

Epoch: 6| Step: 11
Training loss: 0.5690815849811739
Validation loss: 2.5848610319097785

Epoch: 6| Step: 12
Training loss: 0.6573553993493136
Validation loss: 2.6018824108567125

Epoch: 6| Step: 13
Training loss: 0.712913575521516
Validation loss: 2.672047116868777

Epoch: 162| Step: 0
Training loss: 0.7753987347925828
Validation loss: 2.713024395179766

Epoch: 6| Step: 1
Training loss: 1.1207706637157095
Validation loss: 2.657472516142344

Epoch: 6| Step: 2
Training loss: 0.8119245839119741
Validation loss: 2.557571121350567

Epoch: 6| Step: 3
Training loss: 0.5649662787155877
Validation loss: 2.5837688437852635

Epoch: 6| Step: 4
Training loss: 0.8097750010409951
Validation loss: 2.5451325226675654

Epoch: 6| Step: 5
Training loss: 0.6876183321292684
Validation loss: 2.57325146822429

Epoch: 6| Step: 6
Training loss: 1.420532766789354
Validation loss: 2.651751280257216

Epoch: 6| Step: 7
Training loss: 0.9171591577261229
Validation loss: 2.630211304515004

Epoch: 6| Step: 8
Training loss: 0.8068616070215741
Validation loss: 2.6233670968747216

Epoch: 6| Step: 9
Training loss: 1.3217863174883548
Validation loss: 2.579410063167354

Epoch: 6| Step: 10
Training loss: 0.9195356266821819
Validation loss: 2.6434672481758392

Epoch: 6| Step: 11
Training loss: 0.9311319878067991
Validation loss: 2.6470816863699516

Epoch: 6| Step: 12
Training loss: 0.7697397327240119
Validation loss: 2.578271541861918

Epoch: 6| Step: 13
Training loss: 1.1343060349026846
Validation loss: 2.661621108679409

Epoch: 163| Step: 0
Training loss: 0.9142844427900328
Validation loss: 2.610422651238874

Epoch: 6| Step: 1
Training loss: 0.7929401486505072
Validation loss: 2.6199238454996068

Epoch: 6| Step: 2
Training loss: 0.7501970668018411
Validation loss: 2.5544883658193402

Epoch: 6| Step: 3
Training loss: 0.9872698225889197
Validation loss: 2.5560855714662587

Epoch: 6| Step: 4
Training loss: 0.6827629926877701
Validation loss: 2.6091502201321832

Epoch: 6| Step: 5
Training loss: 0.8109477694822189
Validation loss: 2.6279142188641496

Epoch: 6| Step: 6
Training loss: 0.6837030813797457
Validation loss: 2.586693183682715

Epoch: 6| Step: 7
Training loss: 1.4794858221036746
Validation loss: 2.6224099960374034

Epoch: 6| Step: 8
Training loss: 0.7320188507039622
Validation loss: 2.6151854643688783

Epoch: 6| Step: 9
Training loss: 0.9774463468593133
Validation loss: 2.6330276914469186

Epoch: 6| Step: 10
Training loss: 1.0228536556645687
Validation loss: 2.6547034903963964

Epoch: 6| Step: 11
Training loss: 0.8307334198239947
Validation loss: 2.690056508994005

Epoch: 6| Step: 12
Training loss: 1.001356218492591
Validation loss: 2.638395734070336

Epoch: 6| Step: 13
Training loss: 1.185993242524373
Validation loss: 2.6649309012667874

Epoch: 164| Step: 0
Training loss: 1.0243068235285322
Validation loss: 2.6022450236246253

Epoch: 6| Step: 1
Training loss: 0.7526673727102603
Validation loss: 2.56975095541665

Epoch: 6| Step: 2
Training loss: 0.7572360254876653
Validation loss: 2.610804503162253

Epoch: 6| Step: 3
Training loss: 0.9052495696080746
Validation loss: 2.6864711211423913

Epoch: 6| Step: 4
Training loss: 0.5814861843209624
Validation loss: 2.614934196081855

Epoch: 6| Step: 5
Training loss: 1.1727197272842291
Validation loss: 2.61712562905432

Epoch: 6| Step: 6
Training loss: 0.8056920272135341
Validation loss: 2.5838097215113427

Epoch: 6| Step: 7
Training loss: 0.8389440641159899
Validation loss: 2.6443058370502825

Epoch: 6| Step: 8
Training loss: 1.2590235690727851
Validation loss: 2.5941104715030185

Epoch: 6| Step: 9
Training loss: 0.5985431448412217
Validation loss: 2.612505977873222

Epoch: 6| Step: 10
Training loss: 0.9020139413504787
Validation loss: 2.619723345028071

Epoch: 6| Step: 11
Training loss: 0.6757396619050411
Validation loss: 2.572263802132121

Epoch: 6| Step: 12
Training loss: 0.6970893572949663
Validation loss: 2.643256086140375

Epoch: 6| Step: 13
Training loss: 1.1060778553964845
Validation loss: 2.6021460946798425

Epoch: 165| Step: 0
Training loss: 1.2380681380993217
Validation loss: 2.5709248888683183

Epoch: 6| Step: 1
Training loss: 1.0983217875713633
Validation loss: 2.676663292811046

Epoch: 6| Step: 2
Training loss: 0.8212751280773911
Validation loss: 2.5917811753794786

Epoch: 6| Step: 3
Training loss: 0.4891098468762277
Validation loss: 2.6339371841942567

Epoch: 6| Step: 4
Training loss: 0.7244376007230081
Validation loss: 2.6510991513078506

Epoch: 6| Step: 5
Training loss: 0.7496952788890344
Validation loss: 2.6422976551520914

Epoch: 6| Step: 6
Training loss: 0.7298251493938422
Validation loss: 2.5287920552388283

Epoch: 6| Step: 7
Training loss: 0.7315456184091732
Validation loss: 2.6704806282889773

Epoch: 6| Step: 8
Training loss: 0.9469910843196864
Validation loss: 2.6275416134564553

Epoch: 6| Step: 9
Training loss: 0.8270683745241384
Validation loss: 2.635017128514133

Epoch: 6| Step: 10
Training loss: 1.1185328246148638
Validation loss: 2.64375623637637

Epoch: 6| Step: 11
Training loss: 1.237439949813538
Validation loss: 2.607270372349257

Epoch: 6| Step: 12
Training loss: 0.8032442872633516
Validation loss: 2.643098443968993

Epoch: 6| Step: 13
Training loss: 0.7410333996271325
Validation loss: 2.605599967706368

Epoch: 166| Step: 0
Training loss: 1.0812265867664104
Validation loss: 2.6782427156172983

Epoch: 6| Step: 1
Training loss: 0.94810225517939
Validation loss: 2.6585941667058535

Epoch: 6| Step: 2
Training loss: 0.7237400485130384
Validation loss: 2.5964645979546894

Epoch: 6| Step: 3
Training loss: 0.530790298380297
Validation loss: 2.65441261022342

Epoch: 6| Step: 4
Training loss: 0.6093705495036049
Validation loss: 2.627283253778147

Epoch: 6| Step: 5
Training loss: 0.7999168755141945
Validation loss: 2.561055357701546

Epoch: 6| Step: 6
Training loss: 0.7708823643804739
Validation loss: 2.583512505091239

Epoch: 6| Step: 7
Training loss: 1.3243793401426496
Validation loss: 2.619175625538066

Epoch: 6| Step: 8
Training loss: 0.8607486150721018
Validation loss: 2.6023777475754057

Epoch: 6| Step: 9
Training loss: 1.0232796583688974
Validation loss: 2.6128073710757125

Epoch: 6| Step: 10
Training loss: 0.8445724434911949
Validation loss: 2.629561124935632

Epoch: 6| Step: 11
Training loss: 0.5482140088424587
Validation loss: 2.6122276109394393

Epoch: 6| Step: 12
Training loss: 0.8453810433117176
Validation loss: 2.6125585357825027

Epoch: 6| Step: 13
Training loss: 0.9757224780694047
Validation loss: 2.582468939314668

Epoch: 167| Step: 0
Training loss: 0.6321169480362953
Validation loss: 2.6740757316929797

Epoch: 6| Step: 1
Training loss: 0.5997038030669506
Validation loss: 2.689828809965718

Epoch: 6| Step: 2
Training loss: 1.198565127901625
Validation loss: 2.586240153354628

Epoch: 6| Step: 3
Training loss: 0.9863857743440175
Validation loss: 2.59696977383505

Epoch: 6| Step: 4
Training loss: 0.6038742974872803
Validation loss: 2.570870227847809

Epoch: 6| Step: 5
Training loss: 0.46854547171138167
Validation loss: 2.6158920346232213

Epoch: 6| Step: 6
Training loss: 1.319040261094476
Validation loss: 2.6447641710552645

Epoch: 6| Step: 7
Training loss: 1.0293785801114776
Validation loss: 2.5914852105386657

Epoch: 6| Step: 8
Training loss: 0.6796651376136741
Validation loss: 2.6381391603544246

Epoch: 6| Step: 9
Training loss: 0.9416865014769532
Validation loss: 2.516800031433542

Epoch: 6| Step: 10
Training loss: 0.7362438123277835
Validation loss: 2.610322509938849

Epoch: 6| Step: 11
Training loss: 0.6654534974133776
Validation loss: 2.6134498363147305

Epoch: 6| Step: 12
Training loss: 0.9878252507816593
Validation loss: 2.5809749071827017

Epoch: 6| Step: 13
Training loss: 1.0580562338928823
Validation loss: 2.6523017411798118

Epoch: 168| Step: 0
Training loss: 0.6998555357907946
Validation loss: 2.577550280697532

Epoch: 6| Step: 1
Training loss: 0.8281072218804042
Validation loss: 2.657380136661801

Epoch: 6| Step: 2
Training loss: 0.7432689617777917
Validation loss: 2.629145437075291

Epoch: 6| Step: 3
Training loss: 0.9441007619135695
Validation loss: 2.6346053180041755

Epoch: 6| Step: 4
Training loss: 1.2019027843229488
Validation loss: 2.619459306832746

Epoch: 6| Step: 5
Training loss: 0.6706893128543079
Validation loss: 2.588867248895856

Epoch: 6| Step: 6
Training loss: 0.6118764642341402
Validation loss: 2.587543000679407

Epoch: 6| Step: 7
Training loss: 0.638832935241899
Validation loss: 2.673570477946158

Epoch: 6| Step: 8
Training loss: 1.0518153324532207
Validation loss: 2.6295752011953484

Epoch: 6| Step: 9
Training loss: 0.5782282968976267
Validation loss: 2.6150766391111926

Epoch: 6| Step: 10
Training loss: 1.2036839462490063
Validation loss: 2.600666246882391

Epoch: 6| Step: 11
Training loss: 0.4248285396500526
Validation loss: 2.5986595109430355

Epoch: 6| Step: 12
Training loss: 1.1646489451879238
Validation loss: 2.6347529866052364

Epoch: 6| Step: 13
Training loss: 0.8304051372176231
Validation loss: 2.659038979399448

Epoch: 169| Step: 0
Training loss: 0.8696383304931335
Validation loss: 2.592786265196022

Epoch: 6| Step: 1
Training loss: 1.034361220899006
Validation loss: 2.6545926552172103

Epoch: 6| Step: 2
Training loss: 0.7419164062103062
Validation loss: 2.6694940365147577

Epoch: 6| Step: 3
Training loss: 0.6669583626208911
Validation loss: 2.6903437052035937

Epoch: 6| Step: 4
Training loss: 0.7868761043525685
Validation loss: 2.6296172935224345

Epoch: 6| Step: 5
Training loss: 0.7287826662283339
Validation loss: 2.6681251089096496

Epoch: 6| Step: 6
Training loss: 0.5705719449133515
Validation loss: 2.631278975229812

Epoch: 6| Step: 7
Training loss: 0.6477023634007141
Validation loss: 2.6124097495179472

Epoch: 6| Step: 8
Training loss: 0.7137713283151376
Validation loss: 2.6298004111039557

Epoch: 6| Step: 9
Training loss: 0.5625797056311795
Validation loss: 2.6203320491321604

Epoch: 6| Step: 10
Training loss: 0.8370422478772773
Validation loss: 2.609577666005508

Epoch: 6| Step: 11
Training loss: 1.1718806966007376
Validation loss: 2.6492835749865207

Epoch: 6| Step: 12
Training loss: 1.0168287333049015
Validation loss: 2.607649569624287

Epoch: 6| Step: 13
Training loss: 1.448381783772822
Validation loss: 2.6284496558925774

Epoch: 170| Step: 0
Training loss: 0.7019784267919962
Validation loss: 2.6686166374124

Epoch: 6| Step: 1
Training loss: 1.0129782006609733
Validation loss: 2.6494471933065267

Epoch: 6| Step: 2
Training loss: 0.9412876228523825
Validation loss: 2.637982688595393

Epoch: 6| Step: 3
Training loss: 0.5487990184953103
Validation loss: 2.727702998046816

Epoch: 6| Step: 4
Training loss: 0.8676150187445986
Validation loss: 2.6101972156374864

Epoch: 6| Step: 5
Training loss: 0.872946782529602
Validation loss: 2.6837083846645604

Epoch: 6| Step: 6
Training loss: 0.46066022065394
Validation loss: 2.574823118511028

Epoch: 6| Step: 7
Training loss: 1.3648928322834633
Validation loss: 2.65821110006907

Epoch: 6| Step: 8
Training loss: 0.6425423655661888
Validation loss: 2.6406301915947257

Epoch: 6| Step: 9
Training loss: 0.7164833984102135
Validation loss: 2.702815969806534

Epoch: 6| Step: 10
Training loss: 0.6812548488479381
Validation loss: 2.6287045904528332

Epoch: 6| Step: 11
Training loss: 0.9057929761073944
Validation loss: 2.6264776128016587

Epoch: 6| Step: 12
Training loss: 0.767423619063783
Validation loss: 2.6078515697651103

Epoch: 6| Step: 13
Training loss: 0.9286498682458967
Validation loss: 2.609823892627426

Epoch: 171| Step: 0
Training loss: 0.6383765234748823
Validation loss: 2.6775890026146683

Epoch: 6| Step: 1
Training loss: 0.7221939670301252
Validation loss: 2.644027241207745

Epoch: 6| Step: 2
Training loss: 0.6656490446950482
Validation loss: 2.692523327687732

Epoch: 6| Step: 3
Training loss: 0.7632753947881669
Validation loss: 2.630052261002517

Epoch: 6| Step: 4
Training loss: 0.41989611169605057
Validation loss: 2.643409975880186

Epoch: 6| Step: 5
Training loss: 0.9395571074170209
Validation loss: 2.6424544879479113

Epoch: 6| Step: 6
Training loss: 1.2637228152165056
Validation loss: 2.6721860172923546

Epoch: 6| Step: 7
Training loss: 0.7866455680501678
Validation loss: 2.648964948467156

Epoch: 6| Step: 8
Training loss: 1.0214833246812836
Validation loss: 2.6290584404903186

Epoch: 6| Step: 9
Training loss: 0.7333377655574488
Validation loss: 2.6200837919799147

Epoch: 6| Step: 10
Training loss: 0.8498411016042479
Validation loss: 2.645951190836625

Epoch: 6| Step: 11
Training loss: 0.8682962838272307
Validation loss: 2.669595195632173

Epoch: 6| Step: 12
Training loss: 0.5824488479437164
Validation loss: 2.6783719406320534

Epoch: 6| Step: 13
Training loss: 1.2129432064827725
Validation loss: 2.559408113593771

Epoch: 172| Step: 0
Training loss: 1.0922178708985084
Validation loss: 2.631649813325279

Epoch: 6| Step: 1
Training loss: 1.0226260164015908
Validation loss: 2.630626612474185

Epoch: 6| Step: 2
Training loss: 0.9407446344786746
Validation loss: 2.6070872650515153

Epoch: 6| Step: 3
Training loss: 0.7290380001080201
Validation loss: 2.7057400661294255

Epoch: 6| Step: 4
Training loss: 0.7187671659327081
Validation loss: 2.677431066666345

Epoch: 6| Step: 5
Training loss: 0.43802968385564345
Validation loss: 2.592999008720886

Epoch: 6| Step: 6
Training loss: 0.7371975650399409
Validation loss: 2.639909681234624

Epoch: 6| Step: 7
Training loss: 0.48804272738606097
Validation loss: 2.6073058370422824

Epoch: 6| Step: 8
Training loss: 0.8361767934394181
Validation loss: 2.651997906511918

Epoch: 6| Step: 9
Training loss: 0.6527079405074688
Validation loss: 2.580264450302837

Epoch: 6| Step: 10
Training loss: 1.4854213841146255
Validation loss: 2.662897550724874

Epoch: 6| Step: 11
Training loss: 0.8655352273930844
Validation loss: 2.603430900902681

Epoch: 6| Step: 12
Training loss: 0.7006708124038421
Validation loss: 2.6363837738125038

Epoch: 6| Step: 13
Training loss: 0.6930961646573679
Validation loss: 2.614444734058435

Epoch: 173| Step: 0
Training loss: 0.5897509015502119
Validation loss: 2.589892786327972

Epoch: 6| Step: 1
Training loss: 0.914749767450437
Validation loss: 2.6325609066188576

Epoch: 6| Step: 2
Training loss: 0.6006890433282408
Validation loss: 2.6660604880707113

Epoch: 6| Step: 3
Training loss: 0.940276992142645
Validation loss: 2.6333253928760936

Epoch: 6| Step: 4
Training loss: 1.1211650971893656
Validation loss: 2.608358904882823

Epoch: 6| Step: 5
Training loss: 0.7877982558733501
Validation loss: 2.6406329077728263

Epoch: 6| Step: 6
Training loss: 0.6521105777870604
Validation loss: 2.613530639852223

Epoch: 6| Step: 7
Training loss: 1.2312837354037054
Validation loss: 2.622733022812135

Epoch: 6| Step: 8
Training loss: 0.8466897543690389
Validation loss: 2.657126712103009

Epoch: 6| Step: 9
Training loss: 1.0781278195551616
Validation loss: 2.6641435955752164

Epoch: 6| Step: 10
Training loss: 1.1310886289035607
Validation loss: 2.657636916161485

Epoch: 6| Step: 11
Training loss: 0.5074819809669744
Validation loss: 2.5933678280351264

Epoch: 6| Step: 12
Training loss: 0.4362294617439092
Validation loss: 2.6343861752744786

Epoch: 6| Step: 13
Training loss: 0.8215311716403189
Validation loss: 2.6121079377328775

Epoch: 174| Step: 0
Training loss: 0.602701669078824
Validation loss: 2.637547462120705

Epoch: 6| Step: 1
Training loss: 1.213574203033214
Validation loss: 2.6615334193517755

Epoch: 6| Step: 2
Training loss: 0.5281681539747909
Validation loss: 2.6262860251172016

Epoch: 6| Step: 3
Training loss: 0.8915805041196408
Validation loss: 2.6643101641403497

Epoch: 6| Step: 4
Training loss: 0.7789460350902916
Validation loss: 2.6868016866055378

Epoch: 6| Step: 5
Training loss: 1.2290437712359026
Validation loss: 2.5744295472900522

Epoch: 6| Step: 6
Training loss: 0.49597232564123117
Validation loss: 2.6614789321211765

Epoch: 6| Step: 7
Training loss: 0.705815465983215
Validation loss: 2.673892562606186

Epoch: 6| Step: 8
Training loss: 0.5704725380622603
Validation loss: 2.60560485545352

Epoch: 6| Step: 9
Training loss: 0.9479174701282045
Validation loss: 2.6904480607547168

Epoch: 6| Step: 10
Training loss: 1.10341186035583
Validation loss: 2.5740585470252206

Epoch: 6| Step: 11
Training loss: 0.4456975510271255
Validation loss: 2.688876413175402

Epoch: 6| Step: 12
Training loss: 0.3639509734224974
Validation loss: 2.581911039030865

Epoch: 6| Step: 13
Training loss: 0.7424000084462864
Validation loss: 2.6481527589902574

Epoch: 175| Step: 0
Training loss: 1.045423611835405
Validation loss: 2.673096108205009

Epoch: 6| Step: 1
Training loss: 0.47937681593171777
Validation loss: 2.601121973996096

Epoch: 6| Step: 2
Training loss: 0.5933697888563576
Validation loss: 2.616378476942888

Epoch: 6| Step: 3
Training loss: 0.8835938970563987
Validation loss: 2.6856890646543556

Epoch: 6| Step: 4
Training loss: 0.6071399880990592
Validation loss: 2.6195245585141382

Epoch: 6| Step: 5
Training loss: 0.8354619893046092
Validation loss: 2.651267033998407

Epoch: 6| Step: 6
Training loss: 0.7661729136611932
Validation loss: 2.6401718774148546

Epoch: 6| Step: 7
Training loss: 0.9516962943890478
Validation loss: 2.588220892410746

Epoch: 6| Step: 8
Training loss: 0.5165944666816845
Validation loss: 2.5816601646724

Epoch: 6| Step: 9
Training loss: 0.5760370387695644
Validation loss: 2.600653901156919

Epoch: 6| Step: 10
Training loss: 1.078566861481322
Validation loss: 2.6237989887366933

Epoch: 6| Step: 11
Training loss: 1.1462625682145942
Validation loss: 2.6294055481576306

Epoch: 6| Step: 12
Training loss: 0.898792296304356
Validation loss: 2.6133441394790093

Epoch: 6| Step: 13
Training loss: 0.5074614264951506
Validation loss: 2.712687284036722

Epoch: 176| Step: 0
Training loss: 1.0471889537504073
Validation loss: 2.6446756147895654

Epoch: 6| Step: 1
Training loss: 0.6210312242044841
Validation loss: 2.6446334090379455

Epoch: 6| Step: 2
Training loss: 0.7204309378542115
Validation loss: 2.613855242830757

Epoch: 6| Step: 3
Training loss: 0.5424323416854829
Validation loss: 2.6432941197023787

Epoch: 6| Step: 4
Training loss: 0.6096116609003742
Validation loss: 2.614382137039879

Epoch: 6| Step: 5
Training loss: 1.1353802223072864
Validation loss: 2.577476866970106

Epoch: 6| Step: 6
Training loss: 0.9143545222254593
Validation loss: 2.6734574151277415

Epoch: 6| Step: 7
Training loss: 0.7157746803966482
Validation loss: 2.6646312952882445

Epoch: 6| Step: 8
Training loss: 0.4557702527372138
Validation loss: 2.636638679701482

Epoch: 6| Step: 9
Training loss: 0.7944986402333113
Validation loss: 2.6497983258958464

Epoch: 6| Step: 10
Training loss: 0.7408464865130119
Validation loss: 2.674467037858115

Epoch: 6| Step: 11
Training loss: 0.9312584370992558
Validation loss: 2.601126037581806

Epoch: 6| Step: 12
Training loss: 1.168997984092286
Validation loss: 2.6277447988319356

Epoch: 6| Step: 13
Training loss: 0.7669594482086607
Validation loss: 2.632114880181397

Epoch: 177| Step: 0
Training loss: 0.783024108671465
Validation loss: 2.6393705168341293

Epoch: 6| Step: 1
Training loss: 0.6107617274160514
Validation loss: 2.6186169568530917

Epoch: 6| Step: 2
Training loss: 0.6534911247444616
Validation loss: 2.6099917659410403

Epoch: 6| Step: 3
Training loss: 0.8646932248669457
Validation loss: 2.6903039957122497

Epoch: 6| Step: 4
Training loss: 1.1086496480192571
Validation loss: 2.639742069745362

Epoch: 6| Step: 5
Training loss: 0.658458988253662
Validation loss: 2.595841158451473

Epoch: 6| Step: 6
Training loss: 0.697019261024256
Validation loss: 2.6306470800892887

Epoch: 6| Step: 7
Training loss: 0.44257958353851057
Validation loss: 2.6212460226824046

Epoch: 6| Step: 8
Training loss: 0.6200855156927979
Validation loss: 2.636222796479891

Epoch: 6| Step: 9
Training loss: 0.8462310975413362
Validation loss: 2.637717050959223

Epoch: 6| Step: 10
Training loss: 0.9376196149176327
Validation loss: 2.6132840326177496

Epoch: 6| Step: 11
Training loss: 1.1921076476626273
Validation loss: 2.5842225379976824

Epoch: 6| Step: 12
Training loss: 0.8942758787024303
Validation loss: 2.569180905227066

Epoch: 6| Step: 13
Training loss: 0.5393802701354454
Validation loss: 2.594401848321053

Epoch: 178| Step: 0
Training loss: 0.6200706644704034
Validation loss: 2.6481794233434037

Epoch: 6| Step: 1
Training loss: 0.8272060117534461
Validation loss: 2.555548146716265

Epoch: 6| Step: 2
Training loss: 1.419628002709393
Validation loss: 2.646570258254375

Epoch: 6| Step: 3
Training loss: 0.8435344420695462
Validation loss: 2.6023787858861174

Epoch: 6| Step: 4
Training loss: 0.5990255290499585
Validation loss: 2.6379843756719383

Epoch: 6| Step: 5
Training loss: 0.7107269478359379
Validation loss: 2.6530239410983296

Epoch: 6| Step: 6
Training loss: 0.9585792633678151
Validation loss: 2.655637992216012

Epoch: 6| Step: 7
Training loss: 0.5661260503724223
Validation loss: 2.5901341647056304

Epoch: 6| Step: 8
Training loss: 0.6668545314218121
Validation loss: 2.6378045905086944

Epoch: 6| Step: 9
Training loss: 0.8432923594674769
Validation loss: 2.5336793223031804

Epoch: 6| Step: 10
Training loss: 0.6864528701132613
Validation loss: 2.5820524106142093

Epoch: 6| Step: 11
Training loss: 0.966618592749503
Validation loss: 2.6393852559001134

Epoch: 6| Step: 12
Training loss: 0.899217383203868
Validation loss: 2.6954180268347963

Epoch: 6| Step: 13
Training loss: 0.6202028230425107
Validation loss: 2.6646344865706224

Epoch: 179| Step: 0
Training loss: 0.8648969625283178
Validation loss: 2.694435161124511

Epoch: 6| Step: 1
Training loss: 0.6586365220920337
Validation loss: 2.661997094215586

Epoch: 6| Step: 2
Training loss: 0.6733870679908026
Validation loss: 2.64274248926336

Epoch: 6| Step: 3
Training loss: 1.0518560762114113
Validation loss: 2.578186358097387

Epoch: 6| Step: 4
Training loss: 0.8734939420475812
Validation loss: 2.6494950965106003

Epoch: 6| Step: 5
Training loss: 1.2337760920987935
Validation loss: 2.694544195238272

Epoch: 6| Step: 6
Training loss: 0.7859836602732997
Validation loss: 2.6262848449554848

Epoch: 6| Step: 7
Training loss: 0.6474474967378471
Validation loss: 2.6039343819337044

Epoch: 6| Step: 8
Training loss: 0.5368226551832374
Validation loss: 2.647316461924666

Epoch: 6| Step: 9
Training loss: 0.9115403746965879
Validation loss: 2.6161896734547074

Epoch: 6| Step: 10
Training loss: 0.731797259703179
Validation loss: 2.664221288101013

Epoch: 6| Step: 11
Training loss: 0.7750699319359347
Validation loss: 2.6768274791084985

Epoch: 6| Step: 12
Training loss: 0.9793930536004719
Validation loss: 2.6422761198041265

Epoch: 6| Step: 13
Training loss: 0.7239873637867038
Validation loss: 2.769245880877393

Epoch: 180| Step: 0
Training loss: 1.1468134705048099
Validation loss: 2.719914066556049

Epoch: 6| Step: 1
Training loss: 0.539634732580793
Validation loss: 2.6718308443283885

Epoch: 6| Step: 2
Training loss: 0.7211497507223579
Validation loss: 2.6264580507102537

Epoch: 6| Step: 3
Training loss: 1.1647532417037731
Validation loss: 2.6882731781875027

Epoch: 6| Step: 4
Training loss: 0.917196525256383
Validation loss: 2.7354677614397023

Epoch: 6| Step: 5
Training loss: 0.69034279110556
Validation loss: 2.6432595738257683

Epoch: 6| Step: 6
Training loss: 0.7103398923882852
Validation loss: 2.648870157106073

Epoch: 6| Step: 7
Training loss: 0.655554743730811
Validation loss: 2.579911585902039

Epoch: 6| Step: 8
Training loss: 0.6590705385617763
Validation loss: 2.669076550864359

Epoch: 6| Step: 9
Training loss: 0.7288259300471214
Validation loss: 2.6317979044339475

Epoch: 6| Step: 10
Training loss: 0.6468367523827734
Validation loss: 2.7130918416742653

Epoch: 6| Step: 11
Training loss: 0.7994430152763061
Validation loss: 2.6792197305774637

Epoch: 6| Step: 12
Training loss: 0.4749783467075542
Validation loss: 2.695873434327653

Epoch: 6| Step: 13
Training loss: 0.8977199508601064
Validation loss: 2.637421284084016

Epoch: 181| Step: 0
Training loss: 0.6386342635439526
Validation loss: 2.680777236411638

Epoch: 6| Step: 1
Training loss: 1.0622847843988368
Validation loss: 2.6333531580150584

Epoch: 6| Step: 2
Training loss: 0.864571069530848
Validation loss: 2.6366468330277133

Epoch: 6| Step: 3
Training loss: 0.8493113027776558
Validation loss: 2.6319461079919053

Epoch: 6| Step: 4
Training loss: 0.4730105372741129
Validation loss: 2.6494722998527407

Epoch: 6| Step: 5
Training loss: 0.6598520424475556
Validation loss: 2.628262324304265

Epoch: 6| Step: 6
Training loss: 0.9843369733943566
Validation loss: 2.6796537643696494

Epoch: 6| Step: 7
Training loss: 0.4455047660833856
Validation loss: 2.6093130504084283

Epoch: 6| Step: 8
Training loss: 0.7381730580653594
Validation loss: 2.6789600285705366

Epoch: 6| Step: 9
Training loss: 0.6289596061108214
Validation loss: 2.6610050798377447

Epoch: 6| Step: 10
Training loss: 0.7283342969292989
Validation loss: 2.677428128096786

Epoch: 6| Step: 11
Training loss: 0.5145778716205475
Validation loss: 2.720813494303776

Epoch: 6| Step: 12
Training loss: 0.9941608899042744
Validation loss: 2.683249487119774

Epoch: 6| Step: 13
Training loss: 0.6063905651302162
Validation loss: 2.6839016030283145

Epoch: 182| Step: 0
Training loss: 0.4051388804415713
Validation loss: 2.6461925162665585

Epoch: 6| Step: 1
Training loss: 0.8047584576477836
Validation loss: 2.68484670678577

Epoch: 6| Step: 2
Training loss: 0.7096895856335329
Validation loss: 2.6524451886697102

Epoch: 6| Step: 3
Training loss: 0.8102335128801662
Validation loss: 2.6566411048332683

Epoch: 6| Step: 4
Training loss: 1.1140722844147606
Validation loss: 2.6508195530464183

Epoch: 6| Step: 5
Training loss: 0.5066241518282244
Validation loss: 2.6832218717641303

Epoch: 6| Step: 6
Training loss: 0.9651506684833412
Validation loss: 2.6485429740915936

Epoch: 6| Step: 7
Training loss: 0.5891485601643749
Validation loss: 2.6713096957571882

Epoch: 6| Step: 8
Training loss: 0.8970992030718399
Validation loss: 2.6615639582885984

Epoch: 6| Step: 9
Training loss: 0.9209726734518544
Validation loss: 2.6903353084342223

Epoch: 6| Step: 10
Training loss: 0.6784748352826481
Validation loss: 2.681822998187536

Epoch: 6| Step: 11
Training loss: 0.5342917873889452
Validation loss: 2.6629442495048536

Epoch: 6| Step: 12
Training loss: 0.8901701987326873
Validation loss: 2.716936800306279

Epoch: 6| Step: 13
Training loss: 0.5976384976811002
Validation loss: 2.631261502661371

Epoch: 183| Step: 0
Training loss: 0.6378825264841209
Validation loss: 2.6758141582906423

Epoch: 6| Step: 1
Training loss: 0.8072339478234963
Validation loss: 2.712657503749922

Epoch: 6| Step: 2
Training loss: 0.45674256230391735
Validation loss: 2.706030326191205

Epoch: 6| Step: 3
Training loss: 0.6583563063230754
Validation loss: 2.6999861587358014

Epoch: 6| Step: 4
Training loss: 0.38545448100535656
Validation loss: 2.6889115995528674

Epoch: 6| Step: 5
Training loss: 0.7442570392530746
Validation loss: 2.6853202141564743

Epoch: 6| Step: 6
Training loss: 0.6565897833971368
Validation loss: 2.6919760578388847

Epoch: 6| Step: 7
Training loss: 0.8502533675286652
Validation loss: 2.6601135504418996

Epoch: 6| Step: 8
Training loss: 0.8883246110114568
Validation loss: 2.6971338872023387

Epoch: 6| Step: 9
Training loss: 0.8431293889547232
Validation loss: 2.712324859308991

Epoch: 6| Step: 10
Training loss: 0.7028772553447242
Validation loss: 2.7118150241722865

Epoch: 6| Step: 11
Training loss: 0.620167359252368
Validation loss: 2.6936116329805992

Epoch: 6| Step: 12
Training loss: 1.185677032615928
Validation loss: 2.6620631317727117

Epoch: 6| Step: 13
Training loss: 1.189461593723059
Validation loss: 2.7152782650486693

Epoch: 184| Step: 0
Training loss: 0.5680465886274405
Validation loss: 2.6197076155803263

Epoch: 6| Step: 1
Training loss: 0.6877510956076378
Validation loss: 2.691154464511948

Epoch: 6| Step: 2
Training loss: 0.569202361623579
Validation loss: 2.644264699856042

Epoch: 6| Step: 3
Training loss: 0.9159366923406418
Validation loss: 2.587917956321869

Epoch: 6| Step: 4
Training loss: 1.0198227038285932
Validation loss: 2.6427307009674474

Epoch: 6| Step: 5
Training loss: 0.6281892468442682
Validation loss: 2.6853203917282737

Epoch: 6| Step: 6
Training loss: 0.5553557977235175
Validation loss: 2.7293488730451156

Epoch: 6| Step: 7
Training loss: 0.912196022508778
Validation loss: 2.66870812168065

Epoch: 6| Step: 8
Training loss: 0.6213833835337842
Validation loss: 2.667345367926339

Epoch: 6| Step: 9
Training loss: 0.6437420724176949
Validation loss: 2.6232015413126013

Epoch: 6| Step: 10
Training loss: 0.2737410631419368
Validation loss: 2.6896555041128303

Epoch: 6| Step: 11
Training loss: 0.889502235902975
Validation loss: 2.6573257511893345

Epoch: 6| Step: 12
Training loss: 0.9351294747123031
Validation loss: 2.642836320118759

Epoch: 6| Step: 13
Training loss: 0.9256494162647149
Validation loss: 2.6487733071036725

Epoch: 185| Step: 0
Training loss: 0.5031573622821388
Validation loss: 2.6434811827435594

Epoch: 6| Step: 1
Training loss: 0.9632370888393967
Validation loss: 2.68483970625357

Epoch: 6| Step: 2
Training loss: 0.9223039566598741
Validation loss: 2.652647380275877

Epoch: 6| Step: 3
Training loss: 0.7038676472535408
Validation loss: 2.6733664203873024

Epoch: 6| Step: 4
Training loss: 0.680952189034528
Validation loss: 2.6397005377814384

Epoch: 6| Step: 5
Training loss: 1.064972301176683
Validation loss: 2.6845174992152567

Epoch: 6| Step: 6
Training loss: 0.6231048700492203
Validation loss: 2.6092759987329983

Epoch: 6| Step: 7
Training loss: 0.7324955203860014
Validation loss: 2.6640577269629775

Epoch: 6| Step: 8
Training loss: 0.5749133314246154
Validation loss: 2.600313408008734

Epoch: 6| Step: 9
Training loss: 0.5649448879335778
Validation loss: 2.663406067460985

Epoch: 6| Step: 10
Training loss: 0.579706863121059
Validation loss: 2.666467522596056

Epoch: 6| Step: 11
Training loss: 0.49217069687997966
Validation loss: 2.6001195715038863

Epoch: 6| Step: 12
Training loss: 1.047181668130134
Validation loss: 2.6465753631153084

Epoch: 6| Step: 13
Training loss: 0.5801660747194471
Validation loss: 2.5256322522379047

Epoch: 186| Step: 0
Training loss: 0.6893080647915864
Validation loss: 2.562859711559679

Epoch: 6| Step: 1
Training loss: 0.8599805259163092
Validation loss: 2.607528490037066

Epoch: 6| Step: 2
Training loss: 0.9583807014424108
Validation loss: 2.6766323471679905

Epoch: 6| Step: 3
Training loss: 0.9659196978001946
Validation loss: 2.603841247571309

Epoch: 6| Step: 4
Training loss: 0.7458772994425219
Validation loss: 2.577533230152639

Epoch: 6| Step: 5
Training loss: 0.39463553608340457
Validation loss: 2.581257745147736

Epoch: 6| Step: 6
Training loss: 1.099572840027769
Validation loss: 2.634075295869829

Epoch: 6| Step: 7
Training loss: 0.7351419218412273
Validation loss: 2.599994710158811

Epoch: 6| Step: 8
Training loss: 0.38672805543743416
Validation loss: 2.608707730984021

Epoch: 6| Step: 9
Training loss: 0.5200503631191491
Validation loss: 2.6095494499445167

Epoch: 6| Step: 10
Training loss: 0.4923250520836612
Validation loss: 2.5679249443215

Epoch: 6| Step: 11
Training loss: 0.5785335437541883
Validation loss: 2.5981909409543102

Epoch: 6| Step: 12
Training loss: 0.5308531793790005
Validation loss: 2.655508947783651

Epoch: 6| Step: 13
Training loss: 0.8063640351195277
Validation loss: 2.6969176005052127

Epoch: 187| Step: 0
Training loss: 0.6210043260988796
Validation loss: 2.631436057017737

Epoch: 6| Step: 1
Training loss: 0.8510692812961878
Validation loss: 2.677313595577767

Epoch: 6| Step: 2
Training loss: 0.40827528758317727
Validation loss: 2.62227661912427

Epoch: 6| Step: 3
Training loss: 0.6465919843010496
Validation loss: 2.678327758544298

Epoch: 6| Step: 4
Training loss: 0.6681431325195145
Validation loss: 2.645807226057232

Epoch: 6| Step: 5
Training loss: 0.5652509021254118
Validation loss: 2.713401942155042

Epoch: 6| Step: 6
Training loss: 0.5151684502686241
Validation loss: 2.6621922465854992

Epoch: 6| Step: 7
Training loss: 1.0094325329708742
Validation loss: 2.7055250916364093

Epoch: 6| Step: 8
Training loss: 0.7767957739969442
Validation loss: 2.6268141547862114

Epoch: 6| Step: 9
Training loss: 0.609261624475406
Validation loss: 2.674702358621302

Epoch: 6| Step: 10
Training loss: 0.8060455713664748
Validation loss: 2.7183496026917187

Epoch: 6| Step: 11
Training loss: 0.8612502705168057
Validation loss: 2.6497700357522738

Epoch: 6| Step: 12
Training loss: 0.9162166025234224
Validation loss: 2.6115501764005273

Epoch: 6| Step: 13
Training loss: 0.7275614280591202
Validation loss: 2.7237046502306055

Epoch: 188| Step: 0
Training loss: 0.40709587213864
Validation loss: 2.698681716750074

Epoch: 6| Step: 1
Training loss: 1.4175035118046069
Validation loss: 2.6959968398407694

Epoch: 6| Step: 2
Training loss: 0.693721644363335
Validation loss: 2.667527437363926

Epoch: 6| Step: 3
Training loss: 0.6971147518256272
Validation loss: 2.708479310038663

Epoch: 6| Step: 4
Training loss: 0.5262293024591391
Validation loss: 2.7361941290028304

Epoch: 6| Step: 5
Training loss: 0.7578843072907697
Validation loss: 2.690001883074776

Epoch: 6| Step: 6
Training loss: 0.6694559862883908
Validation loss: 2.6283088598601605

Epoch: 6| Step: 7
Training loss: 0.6701270142482093
Validation loss: 2.6391670370468043

Epoch: 6| Step: 8
Training loss: 0.5625344901637133
Validation loss: 2.727157134438569

Epoch: 6| Step: 9
Training loss: 0.6821936519972744
Validation loss: 2.664313534779244

Epoch: 6| Step: 10
Training loss: 0.4048881445762245
Validation loss: 2.658951854997304

Epoch: 6| Step: 11
Training loss: 0.6668539057490611
Validation loss: 2.6764350927596983

Epoch: 6| Step: 12
Training loss: 0.8990892782721609
Validation loss: 2.6720719738906236

Epoch: 6| Step: 13
Training loss: 0.6638279668990292
Validation loss: 2.638054554087654

Epoch: 189| Step: 0
Training loss: 0.5302991773002986
Validation loss: 2.633677460320725

Epoch: 6| Step: 1
Training loss: 0.9942690123749023
Validation loss: 2.7311476053209156

Epoch: 6| Step: 2
Training loss: 0.8401832781390992
Validation loss: 2.629880651828895

Epoch: 6| Step: 3
Training loss: 0.6244628743985918
Validation loss: 2.6633135655528517

Epoch: 6| Step: 4
Training loss: 0.5232938882617745
Validation loss: 2.591772459289336

Epoch: 6| Step: 5
Training loss: 1.300825650943714
Validation loss: 2.6098970511535184

Epoch: 6| Step: 6
Training loss: 0.5965756389595794
Validation loss: 2.7081050972258907

Epoch: 6| Step: 7
Training loss: 0.7788892172096069
Validation loss: 2.6479303705284534

Epoch: 6| Step: 8
Training loss: 0.6081680179917904
Validation loss: 2.75988578489804

Epoch: 6| Step: 9
Training loss: 0.6272239931796001
Validation loss: 2.62285453676343

Epoch: 6| Step: 10
Training loss: 0.4471732464804002
Validation loss: 2.6087805400158075

Epoch: 6| Step: 11
Training loss: 0.8110808670234815
Validation loss: 2.5762463284854555

Epoch: 6| Step: 12
Training loss: 0.6097858217891324
Validation loss: 2.7147721022704334

Epoch: 6| Step: 13
Training loss: 0.6065359001871745
Validation loss: 2.6397734102148664

Epoch: 190| Step: 0
Training loss: 0.8663010405218822
Validation loss: 2.681646722581511

Epoch: 6| Step: 1
Training loss: 0.8256020892052128
Validation loss: 2.628235866099689

Epoch: 6| Step: 2
Training loss: 0.4484232285518123
Validation loss: 2.6585884422258976

Epoch: 6| Step: 3
Training loss: 0.6672257423608002
Validation loss: 2.7429383600257844

Epoch: 6| Step: 4
Training loss: 0.9553571734154649
Validation loss: 2.627791025998908

Epoch: 6| Step: 5
Training loss: 0.763924403280195
Validation loss: 2.7318692160831484

Epoch: 6| Step: 6
Training loss: 0.7859463867534474
Validation loss: 2.6831281573672956

Epoch: 6| Step: 7
Training loss: 0.6420785649110388
Validation loss: 2.6277973619456674

Epoch: 6| Step: 8
Training loss: 0.9487426882676948
Validation loss: 2.6446909403140966

Epoch: 6| Step: 9
Training loss: 0.9477488435573662
Validation loss: 2.6764110854167154

Epoch: 6| Step: 10
Training loss: 0.6307924784335881
Validation loss: 2.676017761915644

Epoch: 6| Step: 11
Training loss: 0.5958048749231906
Validation loss: 2.6787660161742752

Epoch: 6| Step: 12
Training loss: 0.6125991818837611
Validation loss: 2.633617742084589

Epoch: 6| Step: 13
Training loss: 0.8459852774310714
Validation loss: 2.677051430201643

Epoch: 191| Step: 0
Training loss: 0.399900070761531
Validation loss: 2.635787550771519

Epoch: 6| Step: 1
Training loss: 0.39083219755098525
Validation loss: 2.6204465397713967

Epoch: 6| Step: 2
Training loss: 0.9420525955613918
Validation loss: 2.627832247183206

Epoch: 6| Step: 3
Training loss: 1.0081154419740919
Validation loss: 2.6586451857758266

Epoch: 6| Step: 4
Training loss: 0.9246460598306728
Validation loss: 2.7096582595373166

Epoch: 6| Step: 5
Training loss: 0.6222011362724511
Validation loss: 2.635840435912985

Epoch: 6| Step: 6
Training loss: 0.6185534849116033
Validation loss: 2.6618178560874144

Epoch: 6| Step: 7
Training loss: 0.8025115137670604
Validation loss: 2.649137751335583

Epoch: 6| Step: 8
Training loss: 0.7321990220860211
Validation loss: 2.63179570003931

Epoch: 6| Step: 9
Training loss: 0.744613737358304
Validation loss: 2.6481085378870284

Epoch: 6| Step: 10
Training loss: 0.7901727400619202
Validation loss: 2.6201774257541492

Epoch: 6| Step: 11
Training loss: 0.6127722504901508
Validation loss: 2.6721926346046505

Epoch: 6| Step: 12
Training loss: 0.4482876956086726
Validation loss: 2.613881724982107

Epoch: 6| Step: 13
Training loss: 0.6338946191380312
Validation loss: 2.6355716725075173

Epoch: 192| Step: 0
Training loss: 0.5287116499897074
Validation loss: 2.67904182269771

Epoch: 6| Step: 1
Training loss: 0.7197922737424493
Validation loss: 2.669652479227013

Epoch: 6| Step: 2
Training loss: 1.0046634416087565
Validation loss: 2.6722874388157356

Epoch: 6| Step: 3
Training loss: 0.32462981030055016
Validation loss: 2.6976810092196732

Epoch: 6| Step: 4
Training loss: 0.5673013126320449
Validation loss: 2.615750600639322

Epoch: 6| Step: 5
Training loss: 0.7457386390058509
Validation loss: 2.639417511434069

Epoch: 6| Step: 6
Training loss: 0.8124620722207913
Validation loss: 2.6890110824430353

Epoch: 6| Step: 7
Training loss: 0.42022644353198
Validation loss: 2.6090705145711524

Epoch: 6| Step: 8
Training loss: 0.4143963673348624
Validation loss: 2.707725329499246

Epoch: 6| Step: 9
Training loss: 0.7109001904433561
Validation loss: 2.646381146246455

Epoch: 6| Step: 10
Training loss: 0.5986470007654103
Validation loss: 2.6809834126195655

Epoch: 6| Step: 11
Training loss: 0.4894272440455785
Validation loss: 2.6503116724281144

Epoch: 6| Step: 12
Training loss: 0.5325399893310021
Validation loss: 2.7427622961600227

Epoch: 6| Step: 13
Training loss: 1.1114893898502562
Validation loss: 2.7217909515636713

Epoch: 193| Step: 0
Training loss: 0.40055274472475383
Validation loss: 2.6480789767105826

Epoch: 6| Step: 1
Training loss: 0.7282407513079309
Validation loss: 2.6761357798842926

Epoch: 6| Step: 2
Training loss: 0.7865718776430308
Validation loss: 2.6298807953700374

Epoch: 6| Step: 3
Training loss: 0.6294064398586721
Validation loss: 2.7006966445672806

Epoch: 6| Step: 4
Training loss: 0.6500973426849035
Validation loss: 2.6607114387099533

Epoch: 6| Step: 5
Training loss: 0.837246164599587
Validation loss: 2.6875415029943595

Epoch: 6| Step: 6
Training loss: 0.7560691838019092
Validation loss: 2.6580028808870915

Epoch: 6| Step: 7
Training loss: 0.4504362938416054
Validation loss: 2.712965918224588

Epoch: 6| Step: 8
Training loss: 0.8998197454505393
Validation loss: 2.6572438493825477

Epoch: 6| Step: 9
Training loss: 0.8849554805549483
Validation loss: 2.694484461872818

Epoch: 6| Step: 10
Training loss: 1.0525284319772765
Validation loss: 2.6932600674798834

Epoch: 6| Step: 11
Training loss: 0.5633930428685786
Validation loss: 2.6258759096867124

Epoch: 6| Step: 12
Training loss: 0.5031321886390195
Validation loss: 2.668763622692875

Epoch: 6| Step: 13
Training loss: 0.4893284211822782
Validation loss: 2.6464680688785016

Epoch: 194| Step: 0
Training loss: 0.49368918382352917
Validation loss: 2.6707046206004557

Epoch: 6| Step: 1
Training loss: 0.4527416087141262
Validation loss: 2.708174162857969

Epoch: 6| Step: 2
Training loss: 0.6379863548045355
Validation loss: 2.6182933691492924

Epoch: 6| Step: 3
Training loss: 0.7483710639790214
Validation loss: 2.6003852601597917

Epoch: 6| Step: 4
Training loss: 0.9116237090716368
Validation loss: 2.5574167121309532

Epoch: 6| Step: 5
Training loss: 0.6058567403690549
Validation loss: 2.6202381327446216

Epoch: 6| Step: 6
Training loss: 0.7985091563579441
Validation loss: 2.6744904980640754

Epoch: 6| Step: 7
Training loss: 0.6830417257021275
Validation loss: 2.6924777101274735

Epoch: 6| Step: 8
Training loss: 0.5127209175618801
Validation loss: 2.649467365550316

Epoch: 6| Step: 9
Training loss: 0.7592191324274262
Validation loss: 2.666533143952507

Epoch: 6| Step: 10
Training loss: 1.0091501274822112
Validation loss: 2.6445732169716356

Epoch: 6| Step: 11
Training loss: 0.9549452488368441
Validation loss: 2.728368858517028

Epoch: 6| Step: 12
Training loss: 0.5111881154760108
Validation loss: 2.6780184115873062

Epoch: 6| Step: 13
Training loss: 0.6630533966034987
Validation loss: 2.6894419108193715

Epoch: 195| Step: 0
Training loss: 0.49511693168197135
Validation loss: 2.6522290331864884

Epoch: 6| Step: 1
Training loss: 0.5495707690162289
Validation loss: 2.6283331705051807

Epoch: 6| Step: 2
Training loss: 0.5214655440570232
Validation loss: 2.585366561572172

Epoch: 6| Step: 3
Training loss: 0.6160034700983326
Validation loss: 2.622157404546597

Epoch: 6| Step: 4
Training loss: 0.731288674138815
Validation loss: 2.597849184295244

Epoch: 6| Step: 5
Training loss: 0.7240925305444202
Validation loss: 2.6671507415890403

Epoch: 6| Step: 6
Training loss: 0.9439282331099568
Validation loss: 2.704309075538451

Epoch: 6| Step: 7
Training loss: 0.9106848495598768
Validation loss: 2.6791380827838878

Epoch: 6| Step: 8
Training loss: 0.7188048963729189
Validation loss: 2.7151177649953557

Epoch: 6| Step: 9
Training loss: 0.6512206683445246
Validation loss: 2.6245180928943914

Epoch: 6| Step: 10
Training loss: 0.8301645032033381
Validation loss: 2.6401318874071524

Epoch: 6| Step: 11
Training loss: 0.6166667189683978
Validation loss: 2.6465869991585755

Epoch: 6| Step: 12
Training loss: 0.5169539808935257
Validation loss: 2.662756934626136

Epoch: 6| Step: 13
Training loss: 0.8308666119531585
Validation loss: 2.6001381702878423

Epoch: 196| Step: 0
Training loss: 0.5032002730363521
Validation loss: 2.5953953667933978

Epoch: 6| Step: 1
Training loss: 0.9230610927498997
Validation loss: 2.633599922914531

Epoch: 6| Step: 2
Training loss: 0.8445903337474261
Validation loss: 2.589569936540179

Epoch: 6| Step: 3
Training loss: 0.4571444053442743
Validation loss: 2.6361031725002104

Epoch: 6| Step: 4
Training loss: 0.4929998747707463
Validation loss: 2.6242061201682962

Epoch: 6| Step: 5
Training loss: 0.8126091516976975
Validation loss: 2.630443514642536

Epoch: 6| Step: 6
Training loss: 0.5592744854174111
Validation loss: 2.6551928941156344

Epoch: 6| Step: 7
Training loss: 0.5932249458124873
Validation loss: 2.615580202825779

Epoch: 6| Step: 8
Training loss: 0.6080030255446319
Validation loss: 2.604873368058611

Epoch: 6| Step: 9
Training loss: 0.6717487482727224
Validation loss: 2.663477560283111

Epoch: 6| Step: 10
Training loss: 0.7559596741835501
Validation loss: 2.6940830541116543

Epoch: 6| Step: 11
Training loss: 0.5296747751873668
Validation loss: 2.641267401148531

Epoch: 6| Step: 12
Training loss: 0.5816082793619171
Validation loss: 2.640366994980407

Epoch: 6| Step: 13
Training loss: 1.0182726461325953
Validation loss: 2.6080259083044104

Epoch: 197| Step: 0
Training loss: 1.2205194197707285
Validation loss: 2.5895281523157347

Epoch: 6| Step: 1
Training loss: 0.5349191850606019
Validation loss: 2.594771463649103

Epoch: 6| Step: 2
Training loss: 1.0693345997423138
Validation loss: 2.675557155460356

Epoch: 6| Step: 3
Training loss: 0.5663633659176506
Validation loss: 2.6493217170014627

Epoch: 6| Step: 4
Training loss: 0.8434108476360476
Validation loss: 2.5296507441784093

Epoch: 6| Step: 5
Training loss: 0.6172341920598273
Validation loss: 2.5716508127227766

Epoch: 6| Step: 6
Training loss: 0.5564815628599795
Validation loss: 2.625736541957629

Epoch: 6| Step: 7
Training loss: 0.5309245009961212
Validation loss: 2.7045866555363123

Epoch: 6| Step: 8
Training loss: 0.5372824650075506
Validation loss: 2.649562540474142

Epoch: 6| Step: 9
Training loss: 0.5845206869558246
Validation loss: 2.598033386235219

Epoch: 6| Step: 10
Training loss: 0.6598815346372779
Validation loss: 2.6776790673470443

Epoch: 6| Step: 11
Training loss: 0.5881076551549205
Validation loss: 2.6869608611841223

Epoch: 6| Step: 12
Training loss: 0.4846581738796785
Validation loss: 2.6091949339847917

Epoch: 6| Step: 13
Training loss: 0.5902329480843808
Validation loss: 2.663084564749524

Epoch: 198| Step: 0
Training loss: 0.5802817709679735
Validation loss: 2.6527932731371147

Epoch: 6| Step: 1
Training loss: 0.4782945394679232
Validation loss: 2.6130481382214055

Epoch: 6| Step: 2
Training loss: 0.8072895091038247
Validation loss: 2.6344127602546488

Epoch: 6| Step: 3
Training loss: 0.8464153717602984
Validation loss: 2.6510481369049517

Epoch: 6| Step: 4
Training loss: 0.389744777768025
Validation loss: 2.5732609033356377

Epoch: 6| Step: 5
Training loss: 0.8446687006013865
Validation loss: 2.651571559347286

Epoch: 6| Step: 6
Training loss: 0.5967996729507905
Validation loss: 2.576471465079293

Epoch: 6| Step: 7
Training loss: 0.7005566631546697
Validation loss: 2.6285381465647526

Epoch: 6| Step: 8
Training loss: 0.8880375872660162
Validation loss: 2.69632037940301

Epoch: 6| Step: 9
Training loss: 0.6639535253530441
Validation loss: 2.5722312220129218

Epoch: 6| Step: 10
Training loss: 0.5192232868410785
Validation loss: 2.68973002212281

Epoch: 6| Step: 11
Training loss: 0.6649501477822564
Validation loss: 2.6816901609657235

Epoch: 6| Step: 12
Training loss: 0.6530018302459538
Validation loss: 2.620680350512065

Epoch: 6| Step: 13
Training loss: 0.5900783198712498
Validation loss: 2.719605044669894

Epoch: 199| Step: 0
Training loss: 0.7068772754244689
Validation loss: 2.732596176655981

Epoch: 6| Step: 1
Training loss: 0.46812853942979465
Validation loss: 2.5991951650427185

Epoch: 6| Step: 2
Training loss: 0.4630901534372472
Validation loss: 2.71871420591915

Epoch: 6| Step: 3
Training loss: 0.62332166393937
Validation loss: 2.6647942694912072

Epoch: 6| Step: 4
Training loss: 0.5467838211343591
Validation loss: 2.677880407237962

Epoch: 6| Step: 5
Training loss: 0.5347621051012091
Validation loss: 2.720690520677948

Epoch: 6| Step: 6
Training loss: 0.6690186843173124
Validation loss: 2.70197683363197

Epoch: 6| Step: 7
Training loss: 0.9399365551315562
Validation loss: 2.645125321902911

Epoch: 6| Step: 8
Training loss: 0.4186221212161097
Validation loss: 2.649500195736172

Epoch: 6| Step: 9
Training loss: 0.9076860165751007
Validation loss: 2.6057463902639952

Epoch: 6| Step: 10
Training loss: 0.613062485473894
Validation loss: 2.62714036843818

Epoch: 6| Step: 11
Training loss: 0.5881458121497889
Validation loss: 2.6263142580586414

Epoch: 6| Step: 12
Training loss: 0.5578556118928965
Validation loss: 2.692063545241313

Epoch: 6| Step: 13
Training loss: 0.8305241003817107
Validation loss: 2.715192623272011

Epoch: 200| Step: 0
Training loss: 0.4950572321779714
Validation loss: 2.643405646585346

Epoch: 6| Step: 1
Training loss: 1.018398196084402
Validation loss: 2.6207547904305617

Epoch: 6| Step: 2
Training loss: 0.9294845616011176
Validation loss: 2.6681476047154336

Epoch: 6| Step: 3
Training loss: 0.6355070039496746
Validation loss: 2.6917584119185656

Epoch: 6| Step: 4
Training loss: 0.7145616985934817
Validation loss: 2.665580883607651

Epoch: 6| Step: 5
Training loss: 0.7239991366370728
Validation loss: 2.6323022546065893

Epoch: 6| Step: 6
Training loss: 0.6483398272018327
Validation loss: 2.666042200126057

Epoch: 6| Step: 7
Training loss: 0.6179057903022813
Validation loss: 2.594096792546088

Epoch: 6| Step: 8
Training loss: 0.38164255850389023
Validation loss: 2.661799643492531

Epoch: 6| Step: 9
Training loss: 0.551931384307047
Validation loss: 2.6154694645015044

Epoch: 6| Step: 10
Training loss: 0.6914419822295875
Validation loss: 2.666829586019347

Epoch: 6| Step: 11
Training loss: 0.5117710756528676
Validation loss: 2.6420658401642485

Epoch: 6| Step: 12
Training loss: 0.7899409022136867
Validation loss: 2.6980219541843655

Epoch: 6| Step: 13
Training loss: 0.6207759211916647
Validation loss: 2.6680915100540767

Epoch: 201| Step: 0
Training loss: 0.4996758840998843
Validation loss: 2.6413783366336117

Epoch: 6| Step: 1
Training loss: 0.5551320296119256
Validation loss: 2.5738889630576103

Epoch: 6| Step: 2
Training loss: 0.5988169600011398
Validation loss: 2.6396470977219053

Epoch: 6| Step: 3
Training loss: 0.6548508761179087
Validation loss: 2.7016996694130087

Epoch: 6| Step: 4
Training loss: 0.6914321549729753
Validation loss: 2.702047555922387

Epoch: 6| Step: 5
Training loss: 0.7481520456828763
Validation loss: 2.6814820163291393

Epoch: 6| Step: 6
Training loss: 0.8553343018389794
Validation loss: 2.648026471046027

Epoch: 6| Step: 7
Training loss: 0.7221356965669864
Validation loss: 2.612997224936926

Epoch: 6| Step: 8
Training loss: 0.7206956816498251
Validation loss: 2.664366248928717

Epoch: 6| Step: 9
Training loss: 0.4949263105065741
Validation loss: 2.621737610010062

Epoch: 6| Step: 10
Training loss: 0.4795343881593244
Validation loss: 2.690531787446574

Epoch: 6| Step: 11
Training loss: 0.7916436986770373
Validation loss: 2.7307280279566193

Epoch: 6| Step: 12
Training loss: 0.5285745174868183
Validation loss: 2.7183955096656027

Epoch: 6| Step: 13
Training loss: 0.8878803794662429
Validation loss: 2.645240819973446

Epoch: 202| Step: 0
Training loss: 0.46703219368036214
Validation loss: 2.6410920747674425

Epoch: 6| Step: 1
Training loss: 0.4780630657498412
Validation loss: 2.680550824514199

Epoch: 6| Step: 2
Training loss: 0.627990173938744
Validation loss: 2.6319619001773153

Epoch: 6| Step: 3
Training loss: 0.7138803796553798
Validation loss: 2.568974015986151

Epoch: 6| Step: 4
Training loss: 0.41166590834688055
Validation loss: 2.649909241639646

Epoch: 6| Step: 5
Training loss: 0.6134076322337564
Validation loss: 2.7080563599226206

Epoch: 6| Step: 6
Training loss: 0.8344475132439481
Validation loss: 2.6510050283322206

Epoch: 6| Step: 7
Training loss: 0.9359511933256398
Validation loss: 2.6508879451488694

Epoch: 6| Step: 8
Training loss: 0.7546331824427284
Validation loss: 2.6795790996072197

Epoch: 6| Step: 9
Training loss: 0.5587090860018896
Validation loss: 2.6502728699603373

Epoch: 6| Step: 10
Training loss: 0.3761681403017285
Validation loss: 2.6488146218035986

Epoch: 6| Step: 11
Training loss: 0.384236257215513
Validation loss: 2.6548512384917005

Epoch: 6| Step: 12
Training loss: 0.9280216454908321
Validation loss: 2.638958888770704

Epoch: 6| Step: 13
Training loss: 0.6163247270909917
Validation loss: 2.6778622000151726

Epoch: 203| Step: 0
Training loss: 0.6162072618377894
Validation loss: 2.664106217638109

Epoch: 6| Step: 1
Training loss: 0.6636482966536039
Validation loss: 2.6675729304374944

Epoch: 6| Step: 2
Training loss: 0.37983346339066343
Validation loss: 2.6800223197885344

Epoch: 6| Step: 3
Training loss: 0.4338284106659803
Validation loss: 2.662411697547193

Epoch: 6| Step: 4
Training loss: 0.6335005140084197
Validation loss: 2.6376284087442157

Epoch: 6| Step: 5
Training loss: 0.6121674160196752
Validation loss: 2.691472008893306

Epoch: 6| Step: 6
Training loss: 0.5946879256903949
Validation loss: 2.6466463196626537

Epoch: 6| Step: 7
Training loss: 0.8597319468549268
Validation loss: 2.718001529371305

Epoch: 6| Step: 8
Training loss: 1.009850031794671
Validation loss: 2.6551877309948466

Epoch: 6| Step: 9
Training loss: 0.5685697867387931
Validation loss: 2.634993090659728

Epoch: 6| Step: 10
Training loss: 0.7029908582098406
Validation loss: 2.6983171899684515

Epoch: 6| Step: 11
Training loss: 0.6332744748807037
Validation loss: 2.695372900539449

Epoch: 6| Step: 12
Training loss: 0.6492420169411507
Validation loss: 2.6947609231082605

Epoch: 6| Step: 13
Training loss: 0.8145331839679917
Validation loss: 2.7116048616221193

Epoch: 204| Step: 0
Training loss: 0.44925039428710617
Validation loss: 2.716172074032383

Epoch: 6| Step: 1
Training loss: 0.5495985603488573
Validation loss: 2.6703096902027825

Epoch: 6| Step: 2
Training loss: 0.7434285278548587
Validation loss: 2.6748167058352745

Epoch: 6| Step: 3
Training loss: 0.4546183608930976
Validation loss: 2.687520137977558

Epoch: 6| Step: 4
Training loss: 0.48396673224237846
Validation loss: 2.630165565571068

Epoch: 6| Step: 5
Training loss: 0.498073233112651
Validation loss: 2.716920097988298

Epoch: 6| Step: 6
Training loss: 0.751874448945691
Validation loss: 2.7102248751207614

Epoch: 6| Step: 7
Training loss: 0.9194030594579624
Validation loss: 2.687176818045652

Epoch: 6| Step: 8
Training loss: 0.7293518013031071
Validation loss: 2.6455968365641014

Epoch: 6| Step: 9
Training loss: 0.689856543589728
Validation loss: 2.6478232062348557

Epoch: 6| Step: 10
Training loss: 0.8179333654581786
Validation loss: 2.757594315180292

Epoch: 6| Step: 11
Training loss: 0.7935236225061295
Validation loss: 2.6736876676313535

Epoch: 6| Step: 12
Training loss: 0.7130454535421558
Validation loss: 2.7351890151585505

Epoch: 6| Step: 13
Training loss: 0.8377763007716216
Validation loss: 2.6962795568268922

Epoch: 205| Step: 0
Training loss: 0.43705870306525113
Validation loss: 2.655110110868987

Epoch: 6| Step: 1
Training loss: 0.649517538675225
Validation loss: 2.6717887849636086

Epoch: 6| Step: 2
Training loss: 0.9247023335485675
Validation loss: 2.6298349675735677

Epoch: 6| Step: 3
Training loss: 0.5591967602414243
Validation loss: 2.631420805303621

Epoch: 6| Step: 4
Training loss: 0.6707116412520236
Validation loss: 2.629858508625147

Epoch: 6| Step: 5
Training loss: 0.591520263687544
Validation loss: 2.6949186028035226

Epoch: 6| Step: 6
Training loss: 0.4671374877901921
Validation loss: 2.7016992502367576

Epoch: 6| Step: 7
Training loss: 0.46870862460318824
Validation loss: 2.5973427643118416

Epoch: 6| Step: 8
Training loss: 0.4608013145861815
Validation loss: 2.685248008050367

Epoch: 6| Step: 9
Training loss: 0.636553315745764
Validation loss: 2.6554523990880017

Epoch: 6| Step: 10
Training loss: 0.5713317855118862
Validation loss: 2.617945729208249

Epoch: 6| Step: 11
Training loss: 0.8254604658483399
Validation loss: 2.6806720374520867

Epoch: 6| Step: 12
Training loss: 0.8537900994017
Validation loss: 2.6765792213714854

Epoch: 6| Step: 13
Training loss: 0.47136568789513467
Validation loss: 2.692231426888012

Epoch: 206| Step: 0
Training loss: 0.9171669887868196
Validation loss: 2.684288131261597

Epoch: 6| Step: 1
Training loss: 0.7669222992951293
Validation loss: 2.6100033214884117

Epoch: 6| Step: 2
Training loss: 0.4272806905635245
Validation loss: 2.6826366659465677

Epoch: 6| Step: 3
Training loss: 0.573855642096515
Validation loss: 2.689378569767041

Epoch: 6| Step: 4
Training loss: 0.8640092222816514
Validation loss: 2.639067625105169

Epoch: 6| Step: 5
Training loss: 0.42128297096627026
Validation loss: 2.6221534190158375

Epoch: 6| Step: 6
Training loss: 0.6636384395374499
Validation loss: 2.6954669705415037

Epoch: 6| Step: 7
Training loss: 1.0323496648596775
Validation loss: 2.678735339584024

Epoch: 6| Step: 8
Training loss: 0.45498399211160406
Validation loss: 2.6594668039687472

Epoch: 6| Step: 9
Training loss: 0.48192447240172986
Validation loss: 2.6578317906514823

Epoch: 6| Step: 10
Training loss: 0.695762745670929
Validation loss: 2.7123719010817884

Epoch: 6| Step: 11
Training loss: 0.46437831625903064
Validation loss: 2.7317517440221053

Epoch: 6| Step: 12
Training loss: 0.5315544153817564
Validation loss: 2.6942529337182894

Epoch: 6| Step: 13
Training loss: 0.8604388501230203
Validation loss: 2.6842096798148787

Epoch: 207| Step: 0
Training loss: 0.7884257551808509
Validation loss: 2.6658441397601034

Epoch: 6| Step: 1
Training loss: 0.6744412714697462
Validation loss: 2.7330945023036692

Epoch: 6| Step: 2
Training loss: 0.5268383854172549
Validation loss: 2.6496074571714567

Epoch: 6| Step: 3
Training loss: 0.48253583913334996
Validation loss: 2.681692754058678

Epoch: 6| Step: 4
Training loss: 0.5619740146215783
Validation loss: 2.641833508474564

Epoch: 6| Step: 5
Training loss: 0.7991074724189097
Validation loss: 2.7314940325370216

Epoch: 6| Step: 6
Training loss: 0.9339566343520231
Validation loss: 2.6610103809995698

Epoch: 6| Step: 7
Training loss: 0.40489605717726007
Validation loss: 2.686518674786385

Epoch: 6| Step: 8
Training loss: 0.7697640855844061
Validation loss: 2.735777940060556

Epoch: 6| Step: 9
Training loss: 0.9081771026492899
Validation loss: 2.7009710061132948

Epoch: 6| Step: 10
Training loss: 0.6636666857340855
Validation loss: 2.696646665157868

Epoch: 6| Step: 11
Training loss: 0.4140304157134369
Validation loss: 2.63569594902496

Epoch: 6| Step: 12
Training loss: 0.6993013897868229
Validation loss: 2.6346281226426913

Epoch: 6| Step: 13
Training loss: 0.7722301114164951
Validation loss: 2.7089959483322312

Epoch: 208| Step: 0
Training loss: 0.46378317624307625
Validation loss: 2.6482368025603176

Epoch: 6| Step: 1
Training loss: 0.5700919103556684
Validation loss: 2.643519107845508

Epoch: 6| Step: 2
Training loss: 0.6875948840468589
Validation loss: 2.6254976799888725

Epoch: 6| Step: 3
Training loss: 0.7130569055060102
Validation loss: 2.691067109981578

Epoch: 6| Step: 4
Training loss: 0.7524157401527849
Validation loss: 2.6272340078401664

Epoch: 6| Step: 5
Training loss: 0.4400225193048034
Validation loss: 2.616901606037367

Epoch: 6| Step: 6
Training loss: 0.6021973121449422
Validation loss: 2.6215842139181174

Epoch: 6| Step: 7
Training loss: 0.7386519293712192
Validation loss: 2.70992765205722

Epoch: 6| Step: 8
Training loss: 0.5592141074547202
Validation loss: 2.6313334762126046

Epoch: 6| Step: 9
Training loss: 0.7912862055903428
Validation loss: 2.735153915635273

Epoch: 6| Step: 10
Training loss: 0.4797619218284264
Validation loss: 2.674092627316942

Epoch: 6| Step: 11
Training loss: 0.6924730250203681
Validation loss: 2.6459111755414395

Epoch: 6| Step: 12
Training loss: 0.8522898865908621
Validation loss: 2.6254337724415877

Epoch: 6| Step: 13
Training loss: 0.48432894457009856
Validation loss: 2.7202130323787572

Epoch: 209| Step: 0
Training loss: 0.889426177449681
Validation loss: 2.6552629768751976

Epoch: 6| Step: 1
Training loss: 0.5149889114723131
Validation loss: 2.6539490775761867

Epoch: 6| Step: 2
Training loss: 0.7564691651609836
Validation loss: 2.6448157048093943

Epoch: 6| Step: 3
Training loss: 0.5708551829627776
Validation loss: 2.6923521877461596

Epoch: 6| Step: 4
Training loss: 0.5804910185740925
Validation loss: 2.639415652140951

Epoch: 6| Step: 5
Training loss: 0.7880540578981294
Validation loss: 2.6712569178085706

Epoch: 6| Step: 6
Training loss: 0.32578069105946555
Validation loss: 2.669689779511722

Epoch: 6| Step: 7
Training loss: 0.7824968687732191
Validation loss: 2.667012078047967

Epoch: 6| Step: 8
Training loss: 0.48176755818121514
Validation loss: 2.68713772719921

Epoch: 6| Step: 9
Training loss: 0.43178229790327316
Validation loss: 2.6413382294953034

Epoch: 6| Step: 10
Training loss: 0.6860366766970474
Validation loss: 2.663454778868023

Epoch: 6| Step: 11
Training loss: 0.8496879102867962
Validation loss: 2.6666794766674715

Epoch: 6| Step: 12
Training loss: 0.4706573305765372
Validation loss: 2.692083088183474

Epoch: 6| Step: 13
Training loss: 0.8759137219329403
Validation loss: 2.6695623520864706

Epoch: 210| Step: 0
Training loss: 0.6775888512122074
Validation loss: 2.7365654446060854

Epoch: 6| Step: 1
Training loss: 0.5493041177010904
Validation loss: 2.669104882020561

Epoch: 6| Step: 2
Training loss: 0.40718160696734956
Validation loss: 2.7138207134098726

Epoch: 6| Step: 3
Training loss: 0.5658304905527397
Validation loss: 2.6736223779306085

Epoch: 6| Step: 4
Training loss: 0.42902836963243224
Validation loss: 2.633110550216697

Epoch: 6| Step: 5
Training loss: 0.8635733960208254
Validation loss: 2.598878149555218

Epoch: 6| Step: 6
Training loss: 0.6851343288416378
Validation loss: 2.698179921938856

Epoch: 6| Step: 7
Training loss: 0.5896245536503286
Validation loss: 2.6820169894614097

Epoch: 6| Step: 8
Training loss: 0.8164915925461494
Validation loss: 2.704010849525573

Epoch: 6| Step: 9
Training loss: 0.5259178097643534
Validation loss: 2.6684699120753086

Epoch: 6| Step: 10
Training loss: 0.6510263720941094
Validation loss: 2.6829876684975837

Epoch: 6| Step: 11
Training loss: 0.8938185005346672
Validation loss: 2.6535935376485855

Epoch: 6| Step: 12
Training loss: 0.5496852873843858
Validation loss: 2.637192551228724

Epoch: 6| Step: 13
Training loss: 0.7586838343646685
Validation loss: 2.7056174574926257

Epoch: 211| Step: 0
Training loss: 0.3486516503980048
Validation loss: 2.719660712403184

Epoch: 6| Step: 1
Training loss: 0.610309788609511
Validation loss: 2.6906619433836347

Epoch: 6| Step: 2
Training loss: 0.5383753889395552
Validation loss: 2.6268828315264154

Epoch: 6| Step: 3
Training loss: 0.6704875015129355
Validation loss: 2.643383218319398

Epoch: 6| Step: 4
Training loss: 0.47664782276230533
Validation loss: 2.67117527951389

Epoch: 6| Step: 5
Training loss: 0.9604117963643961
Validation loss: 2.6592821803556843

Epoch: 6| Step: 6
Training loss: 0.6115826208033632
Validation loss: 2.6397014259310345

Epoch: 6| Step: 7
Training loss: 0.8198212742255602
Validation loss: 2.6631942930280923

Epoch: 6| Step: 8
Training loss: 0.6097739209937112
Validation loss: 2.680289991320669

Epoch: 6| Step: 9
Training loss: 0.4500017722412815
Validation loss: 2.707776325363537

Epoch: 6| Step: 10
Training loss: 0.606485952099842
Validation loss: 2.6200341377266807

Epoch: 6| Step: 11
Training loss: 0.5666973023922072
Validation loss: 2.6923684816344586

Epoch: 6| Step: 12
Training loss: 0.3625847076232742
Validation loss: 2.6529560534061476

Epoch: 6| Step: 13
Training loss: 0.626821058392329
Validation loss: 2.7029855210733484

Epoch: 212| Step: 0
Training loss: 0.3671189710909781
Validation loss: 2.684985707231363

Epoch: 6| Step: 1
Training loss: 0.5065792072983842
Validation loss: 2.6761984989414156

Epoch: 6| Step: 2
Training loss: 0.4476095151888708
Validation loss: 2.6622598166624933

Epoch: 6| Step: 3
Training loss: 0.6591878254705993
Validation loss: 2.659636190388108

Epoch: 6| Step: 4
Training loss: 0.6531009277215086
Validation loss: 2.642875464816512

Epoch: 6| Step: 5
Training loss: 0.774184049719817
Validation loss: 2.6444427084739

Epoch: 6| Step: 6
Training loss: 0.4675494874424145
Validation loss: 2.696975828711917

Epoch: 6| Step: 7
Training loss: 0.4034678856526706
Validation loss: 2.730109282531529

Epoch: 6| Step: 8
Training loss: 0.5525277226600139
Validation loss: 2.670641675808205

Epoch: 6| Step: 9
Training loss: 0.5605975935583218
Validation loss: 2.7410153223031846

Epoch: 6| Step: 10
Training loss: 0.49634949407416273
Validation loss: 2.624419269205046

Epoch: 6| Step: 11
Training loss: 0.9687245273317519
Validation loss: 2.639349695316688

Epoch: 6| Step: 12
Training loss: 0.7688691054707238
Validation loss: 2.6767290204965457

Epoch: 6| Step: 13
Training loss: 0.3216420469514382
Validation loss: 2.6401259422846612

Epoch: 213| Step: 0
Training loss: 0.4871024589384098
Validation loss: 2.65486994777438

Epoch: 6| Step: 1
Training loss: 0.7824439652705487
Validation loss: 2.73870238341238

Epoch: 6| Step: 2
Training loss: 0.5023446541358322
Validation loss: 2.673993436441519

Epoch: 6| Step: 3
Training loss: 0.9187994262479287
Validation loss: 2.7658420053752018

Epoch: 6| Step: 4
Training loss: 0.6980184129783917
Validation loss: 2.627923291388886

Epoch: 6| Step: 5
Training loss: 0.49008425659644506
Validation loss: 2.7262244538735905

Epoch: 6| Step: 6
Training loss: 0.5090768772481225
Validation loss: 2.6583486606391213

Epoch: 6| Step: 7
Training loss: 0.5372145116382654
Validation loss: 2.7037910787395574

Epoch: 6| Step: 8
Training loss: 0.8340361174851935
Validation loss: 2.6775368233412418

Epoch: 6| Step: 9
Training loss: 0.6391548407139072
Validation loss: 2.638250837375741

Epoch: 6| Step: 10
Training loss: 0.6455102594418684
Validation loss: 2.6216851300193467

Epoch: 6| Step: 11
Training loss: 0.6765288038430259
Validation loss: 2.647604106961058

Epoch: 6| Step: 12
Training loss: 0.7064376995171099
Validation loss: 2.690151193262508

Epoch: 6| Step: 13
Training loss: 0.6718575674944827
Validation loss: 2.719817463550249

Epoch: 214| Step: 0
Training loss: 0.4487811071404811
Validation loss: 2.680728988000184

Epoch: 6| Step: 1
Training loss: 0.7500737471880369
Validation loss: 2.6024836531341604

Epoch: 6| Step: 2
Training loss: 0.5465476827646845
Validation loss: 2.603906837216859

Epoch: 6| Step: 3
Training loss: 0.7026764392560766
Validation loss: 2.704739612097149

Epoch: 6| Step: 4
Training loss: 0.7502718671149798
Validation loss: 2.630409993413441

Epoch: 6| Step: 5
Training loss: 0.6005274798468497
Validation loss: 2.65672446108678

Epoch: 6| Step: 6
Training loss: 0.8166673598643365
Validation loss: 2.6981502024392743

Epoch: 6| Step: 7
Training loss: 0.5667604062673531
Validation loss: 2.6847208424228213

Epoch: 6| Step: 8
Training loss: 0.4641964837803974
Validation loss: 2.643303755786732

Epoch: 6| Step: 9
Training loss: 0.7937038378170584
Validation loss: 2.670988653450472

Epoch: 6| Step: 10
Training loss: 0.5111543877508172
Validation loss: 2.683522156376282

Epoch: 6| Step: 11
Training loss: 0.48921937467912274
Validation loss: 2.6864809277636863

Epoch: 6| Step: 12
Training loss: 0.5468597954952509
Validation loss: 2.648273729270186

Epoch: 6| Step: 13
Training loss: 0.3234043002942043
Validation loss: 2.723263162536105

Epoch: 215| Step: 0
Training loss: 0.5135039138329067
Validation loss: 2.668893671449249

Epoch: 6| Step: 1
Training loss: 0.568975789451747
Validation loss: 2.7266714225516155

Epoch: 6| Step: 2
Training loss: 0.25113224885693064
Validation loss: 2.6989045022307208

Epoch: 6| Step: 3
Training loss: 0.6860885436438877
Validation loss: 2.6999587403194307

Epoch: 6| Step: 4
Training loss: 0.5662710620424061
Validation loss: 2.6552613830853975

Epoch: 6| Step: 5
Training loss: 0.44809080405756374
Validation loss: 2.663798806721796

Epoch: 6| Step: 6
Training loss: 0.5845169649721388
Validation loss: 2.7437026284081423

Epoch: 6| Step: 7
Training loss: 0.6523169780422889
Validation loss: 2.6705455037753962

Epoch: 6| Step: 8
Training loss: 0.6570393265852594
Validation loss: 2.7015915124297663

Epoch: 6| Step: 9
Training loss: 0.86016476494423
Validation loss: 2.693746699827552

Epoch: 6| Step: 10
Training loss: 0.4539998750759995
Validation loss: 2.638691090538071

Epoch: 6| Step: 11
Training loss: 0.6897668529952803
Validation loss: 2.6665244412244147

Epoch: 6| Step: 12
Training loss: 0.4644649147994891
Validation loss: 2.602656564928733

Epoch: 6| Step: 13
Training loss: 0.6124666477387035
Validation loss: 2.631101344629403

Epoch: 216| Step: 0
Training loss: 0.4976002953660723
Validation loss: 2.7378606904114573

Epoch: 6| Step: 1
Training loss: 0.5099617883915488
Validation loss: 2.6957064133433204

Epoch: 6| Step: 2
Training loss: 0.5924171998721002
Validation loss: 2.7193883972141895

Epoch: 6| Step: 3
Training loss: 0.5129887204519643
Validation loss: 2.70700283136538

Epoch: 6| Step: 4
Training loss: 0.5793586661989998
Validation loss: 2.6954366461869936

Epoch: 6| Step: 5
Training loss: 0.7552136168897994
Validation loss: 2.6777259015914514

Epoch: 6| Step: 6
Training loss: 0.6625861192906234
Validation loss: 2.633088222898456

Epoch: 6| Step: 7
Training loss: 1.0357972086046623
Validation loss: 2.6509177523109066

Epoch: 6| Step: 8
Training loss: 0.5251145044979154
Validation loss: 2.602275013843767

Epoch: 6| Step: 9
Training loss: 0.46004716911211935
Validation loss: 2.737036421612812

Epoch: 6| Step: 10
Training loss: 0.501353012734607
Validation loss: 2.61467261497577

Epoch: 6| Step: 11
Training loss: 0.4536124271512075
Validation loss: 2.6697692157715744

Epoch: 6| Step: 12
Training loss: 0.4790080436815611
Validation loss: 2.5959290003611573

Epoch: 6| Step: 13
Training loss: 0.5929290969315921
Validation loss: 2.6390646513468448

Epoch: 217| Step: 0
Training loss: 0.48739022400572646
Validation loss: 2.694522819384191

Epoch: 6| Step: 1
Training loss: 0.59599942202188
Validation loss: 2.6597261011036166

Epoch: 6| Step: 2
Training loss: 0.3051400735945737
Validation loss: 2.6139678965321376

Epoch: 6| Step: 3
Training loss: 0.506355955079805
Validation loss: 2.6751731757083883

Epoch: 6| Step: 4
Training loss: 0.6989251911096346
Validation loss: 2.6800821530859906

Epoch: 6| Step: 5
Training loss: 0.61035375976167
Validation loss: 2.6336228267875503

Epoch: 6| Step: 6
Training loss: 0.6141386416842021
Validation loss: 2.6729227878166473

Epoch: 6| Step: 7
Training loss: 0.42868629332596586
Validation loss: 2.6703301587087314

Epoch: 6| Step: 8
Training loss: 0.7252586725420614
Validation loss: 2.6879509983601197

Epoch: 6| Step: 9
Training loss: 0.556117270203518
Validation loss: 2.6438983289443176

Epoch: 6| Step: 10
Training loss: 0.7682160888248394
Validation loss: 2.70340697153725

Epoch: 6| Step: 11
Training loss: 0.554487783448781
Validation loss: 2.7102378360083685

Epoch: 6| Step: 12
Training loss: 0.646977400852296
Validation loss: 2.6407099301977772

Epoch: 6| Step: 13
Training loss: 0.5207763895059196
Validation loss: 2.658557151671813

Epoch: 218| Step: 0
Training loss: 0.5498811929435968
Validation loss: 2.604058825485193

Epoch: 6| Step: 1
Training loss: 0.7724798419630889
Validation loss: 2.6825219410440124

Epoch: 6| Step: 2
Training loss: 0.6152717215692287
Validation loss: 2.597979073793329

Epoch: 6| Step: 3
Training loss: 0.7518210555184485
Validation loss: 2.6719431431578307

Epoch: 6| Step: 4
Training loss: 0.6175092992970411
Validation loss: 2.6380436938024294

Epoch: 6| Step: 5
Training loss: 0.5711094239637158
Validation loss: 2.6540805409429633

Epoch: 6| Step: 6
Training loss: 0.512241009657063
Validation loss: 2.656604623496865

Epoch: 6| Step: 7
Training loss: 0.7288199190652445
Validation loss: 2.6931064220444862

Epoch: 6| Step: 8
Training loss: 0.3729412868122742
Validation loss: 2.702359026685289

Epoch: 6| Step: 9
Training loss: 0.4562910721202873
Validation loss: 2.6912072582899387

Epoch: 6| Step: 10
Training loss: 0.5514721696494372
Validation loss: 2.711892288737836

Epoch: 6| Step: 11
Training loss: 0.7927258500023977
Validation loss: 2.6991086018193644

Epoch: 6| Step: 12
Training loss: 0.759332528516071
Validation loss: 2.624828408703185

Epoch: 6| Step: 13
Training loss: 0.29328249344234436
Validation loss: 2.676382653436379

Epoch: 219| Step: 0
Training loss: 0.4480579305014852
Validation loss: 2.7155763072282153

Epoch: 6| Step: 1
Training loss: 0.8114669908707295
Validation loss: 2.6395258675702555

Epoch: 6| Step: 2
Training loss: 0.6048845487575228
Validation loss: 2.6786103599988857

Epoch: 6| Step: 3
Training loss: 0.4884144105536429
Validation loss: 2.6326011474778825

Epoch: 6| Step: 4
Training loss: 0.527938817855908
Validation loss: 2.645259124043112

Epoch: 6| Step: 5
Training loss: 0.4776256303391219
Validation loss: 2.6362807373936765

Epoch: 6| Step: 6
Training loss: 0.9228891516402227
Validation loss: 2.6265544527389335

Epoch: 6| Step: 7
Training loss: 0.6444685009553239
Validation loss: 2.639676196344824

Epoch: 6| Step: 8
Training loss: 0.30204215125290057
Validation loss: 2.667845157648166

Epoch: 6| Step: 9
Training loss: 0.5618712301838554
Validation loss: 2.6805191899557723

Epoch: 6| Step: 10
Training loss: 0.3817729263803406
Validation loss: 2.7138403888562963

Epoch: 6| Step: 11
Training loss: 0.517950334408576
Validation loss: 2.682409714752287

Epoch: 6| Step: 12
Training loss: 0.5721335144659574
Validation loss: 2.6682580927816604

Epoch: 6| Step: 13
Training loss: 0.7508023262042762
Validation loss: 2.613218222154075

Epoch: 220| Step: 0
Training loss: 0.702871404056214
Validation loss: 2.6189761071020157

Epoch: 6| Step: 1
Training loss: 0.6109485605706968
Validation loss: 2.6101959368601952

Epoch: 6| Step: 2
Training loss: 0.49166072933469884
Validation loss: 2.627701943087134

Epoch: 6| Step: 3
Training loss: 0.4716074159591172
Validation loss: 2.642932432960498

Epoch: 6| Step: 4
Training loss: 0.6413761944994809
Validation loss: 2.711152946713075

Epoch: 6| Step: 5
Training loss: 0.2788190689390532
Validation loss: 2.7051825364363618

Epoch: 6| Step: 6
Training loss: 0.3431329607778352
Validation loss: 2.6787987246274843

Epoch: 6| Step: 7
Training loss: 0.305575616977521
Validation loss: 2.707050978463464

Epoch: 6| Step: 8
Training loss: 1.0359572856043537
Validation loss: 2.6843974961095727

Epoch: 6| Step: 9
Training loss: 0.45354724809923863
Validation loss: 2.7043524217408774

Epoch: 6| Step: 10
Training loss: 0.41476420557666965
Validation loss: 2.66618313478544

Epoch: 6| Step: 11
Training loss: 0.6002879822553232
Validation loss: 2.6949073597585818

Epoch: 6| Step: 12
Training loss: 0.49110023054895446
Validation loss: 2.659185201503992

Epoch: 6| Step: 13
Training loss: 0.5213864695335317
Validation loss: 2.7895037732068895

Epoch: 221| Step: 0
Training loss: 0.33678479133365935
Validation loss: 2.7041444271056765

Epoch: 6| Step: 1
Training loss: 0.7757063830496755
Validation loss: 2.721683833887076

Epoch: 6| Step: 2
Training loss: 0.6215329326887079
Validation loss: 2.72058290689267

Epoch: 6| Step: 3
Training loss: 0.5196327741278594
Validation loss: 2.615593404818345

Epoch: 6| Step: 4
Training loss: 0.5779914701749773
Validation loss: 2.6491589684108043

Epoch: 6| Step: 5
Training loss: 0.5222386823279719
Validation loss: 2.663947706089216

Epoch: 6| Step: 6
Training loss: 0.4286153421723991
Validation loss: 2.7135727795789855

Epoch: 6| Step: 7
Training loss: 0.5486463741311655
Validation loss: 2.691331453580517

Epoch: 6| Step: 8
Training loss: 0.7156306037516849
Validation loss: 2.704439934871567

Epoch: 6| Step: 9
Training loss: 0.4135203140601207
Validation loss: 2.6995935911264453

Epoch: 6| Step: 10
Training loss: 0.9706548605880355
Validation loss: 2.660753045938145

Epoch: 6| Step: 11
Training loss: 0.5771000256057995
Validation loss: 2.6740015947512634

Epoch: 6| Step: 12
Training loss: 0.6542850550252898
Validation loss: 2.6782146591674514

Epoch: 6| Step: 13
Training loss: 0.4296543975563743
Validation loss: 2.666601662042185

Epoch: 222| Step: 0
Training loss: 0.4535397243093107
Validation loss: 2.642985145066201

Epoch: 6| Step: 1
Training loss: 0.4508479553267672
Validation loss: 2.689750128631064

Epoch: 6| Step: 2
Training loss: 0.5126836284940965
Validation loss: 2.7244370126838957

Epoch: 6| Step: 3
Training loss: 0.49315720355108056
Validation loss: 2.7465567273139944

Epoch: 6| Step: 4
Training loss: 0.32063203086357145
Validation loss: 2.700750038967846

Epoch: 6| Step: 5
Training loss: 0.5913757991636203
Validation loss: 2.7079212511004935

Epoch: 6| Step: 6
Training loss: 0.50639341583514
Validation loss: 2.6526085820146643

Epoch: 6| Step: 7
Training loss: 0.32194852544752267
Validation loss: 2.632206304625585

Epoch: 6| Step: 8
Training loss: 0.8329344669085591
Validation loss: 2.7194943633112585

Epoch: 6| Step: 9
Training loss: 0.5299572924285239
Validation loss: 2.6616364038148728

Epoch: 6| Step: 10
Training loss: 0.44693280626429416
Validation loss: 2.7134582789831176

Epoch: 6| Step: 11
Training loss: 1.1939755611123066
Validation loss: 2.708244884709508

Epoch: 6| Step: 12
Training loss: 0.398487779773358
Validation loss: 2.718953515982083

Epoch: 6| Step: 13
Training loss: 0.4449853364532295
Validation loss: 2.668498234781195

Epoch: 223| Step: 0
Training loss: 0.4174828601790973
Validation loss: 2.7296093491923723

Epoch: 6| Step: 1
Training loss: 0.4247045815564501
Validation loss: 2.7386129761518285

Epoch: 6| Step: 2
Training loss: 0.9055699394763516
Validation loss: 2.675857713632427

Epoch: 6| Step: 3
Training loss: 0.8359030600610318
Validation loss: 2.715991846378543

Epoch: 6| Step: 4
Training loss: 0.8663046527042303
Validation loss: 2.727847447792926

Epoch: 6| Step: 5
Training loss: 0.7569529978145414
Validation loss: 2.725090584138863

Epoch: 6| Step: 6
Training loss: 0.46480883940065326
Validation loss: 2.7467421755974533

Epoch: 6| Step: 7
Training loss: 0.4602280992977884
Validation loss: 2.65391757510867

Epoch: 6| Step: 8
Training loss: 0.4774487181782631
Validation loss: 2.672562494002251

Epoch: 6| Step: 9
Training loss: 0.4934143035828649
Validation loss: 2.6690391080184335

Epoch: 6| Step: 10
Training loss: 0.5458224385268656
Validation loss: 2.7534208262199216

Epoch: 6| Step: 11
Training loss: 0.5495942765082251
Validation loss: 2.655713524591246

Epoch: 6| Step: 12
Training loss: 0.43914309267668333
Validation loss: 2.7407114778661446

Epoch: 6| Step: 13
Training loss: 0.4409339031664857
Validation loss: 2.7470518840013907

Epoch: 224| Step: 0
Training loss: 0.7192699790542542
Validation loss: 2.720544770747192

Epoch: 6| Step: 1
Training loss: 0.6706433873353321
Validation loss: 2.720033291608299

Epoch: 6| Step: 2
Training loss: 0.47957120970651174
Validation loss: 2.6887581859388936

Epoch: 6| Step: 3
Training loss: 0.4569621563712065
Validation loss: 2.7564517978831673

Epoch: 6| Step: 4
Training loss: 0.4379374326790537
Validation loss: 2.6509992125183954

Epoch: 6| Step: 5
Training loss: 0.6439722353461943
Validation loss: 2.7317575624699373

Epoch: 6| Step: 6
Training loss: 0.5604258017758569
Validation loss: 2.6442637305884062

Epoch: 6| Step: 7
Training loss: 0.6979911086013479
Validation loss: 2.646782792311932

Epoch: 6| Step: 8
Training loss: 0.6936588553963903
Validation loss: 2.691075615212584

Epoch: 6| Step: 9
Training loss: 0.5204901486489653
Validation loss: 2.652271417709249

Epoch: 6| Step: 10
Training loss: 0.520413388388789
Validation loss: 2.6960551911047688

Epoch: 6| Step: 11
Training loss: 0.4985955750023446
Validation loss: 2.7416515786665023

Epoch: 6| Step: 12
Training loss: 0.48365370050665246
Validation loss: 2.7079773497768214

Epoch: 6| Step: 13
Training loss: 0.3934407412370484
Validation loss: 2.7099623671519315

Epoch: 225| Step: 0
Training loss: 0.7629220701144704
Validation loss: 2.683729424672409

Epoch: 6| Step: 1
Training loss: 0.6222240551451336
Validation loss: 2.6592785493160314

Epoch: 6| Step: 2
Training loss: 0.48894006153202735
Validation loss: 2.675175596873191

Epoch: 6| Step: 3
Training loss: 0.5730067066762131
Validation loss: 2.6605956489103586

Epoch: 6| Step: 4
Training loss: 0.8716041882687866
Validation loss: 2.73408893360378

Epoch: 6| Step: 5
Training loss: 0.5467495638178868
Validation loss: 2.6709453013770235

Epoch: 6| Step: 6
Training loss: 0.5250602732982265
Validation loss: 2.6933007292694

Epoch: 6| Step: 7
Training loss: 0.4326472218164959
Validation loss: 2.6612759034302833

Epoch: 6| Step: 8
Training loss: 0.4341180226495434
Validation loss: 2.7380013243442374

Epoch: 6| Step: 9
Training loss: 0.5932587548955028
Validation loss: 2.639798706609682

Epoch: 6| Step: 10
Training loss: 0.37271226985694134
Validation loss: 2.630469059375291

Epoch: 6| Step: 11
Training loss: 0.4614352109238198
Validation loss: 2.718211372776756

Epoch: 6| Step: 12
Training loss: 0.4689647182785196
Validation loss: 2.705698041886795

Epoch: 6| Step: 13
Training loss: 0.6175485593027058
Validation loss: 2.7350156632973888

Epoch: 226| Step: 0
Training loss: 0.33296215605774043
Validation loss: 2.749861236886017

Epoch: 6| Step: 1
Training loss: 0.47109332867503895
Validation loss: 2.7191176476494405

Epoch: 6| Step: 2
Training loss: 0.4420107188198101
Validation loss: 2.689876363340324

Epoch: 6| Step: 3
Training loss: 0.4375962083482274
Validation loss: 2.6709362559689254

Epoch: 6| Step: 4
Training loss: 0.7689627469319489
Validation loss: 2.6646807895601405

Epoch: 6| Step: 5
Training loss: 0.5217713555762211
Validation loss: 2.63894321374579

Epoch: 6| Step: 6
Training loss: 0.48217075004830856
Validation loss: 2.7117267892436825

Epoch: 6| Step: 7
Training loss: 0.7196705769227544
Validation loss: 2.696495953646967

Epoch: 6| Step: 8
Training loss: 0.48900769935194494
Validation loss: 2.7027421213402807

Epoch: 6| Step: 9
Training loss: 0.7871613970430791
Validation loss: 2.698360588245533

Epoch: 6| Step: 10
Training loss: 0.5013078631443557
Validation loss: 2.699616288364077

Epoch: 6| Step: 11
Training loss: 0.7957166592884691
Validation loss: 2.7005935752339276

Epoch: 6| Step: 12
Training loss: 0.3626781091836706
Validation loss: 2.7609178316070255

Epoch: 6| Step: 13
Training loss: 0.4313445650991338
Validation loss: 2.670387389336575

Epoch: 227| Step: 0
Training loss: 0.6556939085030066
Validation loss: 2.6927395984204505

Epoch: 6| Step: 1
Training loss: 0.4062610037853945
Validation loss: 2.750745657773907

Epoch: 6| Step: 2
Training loss: 0.572905043281787
Validation loss: 2.7212103019298794

Epoch: 6| Step: 3
Training loss: 0.3730349314110834
Validation loss: 2.7121005682710924

Epoch: 6| Step: 4
Training loss: 0.5375871787232566
Validation loss: 2.734257039750069

Epoch: 6| Step: 5
Training loss: 0.45808956498396186
Validation loss: 2.6587428643484032

Epoch: 6| Step: 6
Training loss: 0.4044661973591082
Validation loss: 2.7674363664653057

Epoch: 6| Step: 7
Training loss: 0.8031396515693539
Validation loss: 2.6516678126260937

Epoch: 6| Step: 8
Training loss: 0.29458900006917066
Validation loss: 2.656317317334029

Epoch: 6| Step: 9
Training loss: 0.5973506470286306
Validation loss: 2.7427985370047763

Epoch: 6| Step: 10
Training loss: 0.4704719703992316
Validation loss: 2.69389788965865

Epoch: 6| Step: 11
Training loss: 0.42994297409066345
Validation loss: 2.674061079816555

Epoch: 6| Step: 12
Training loss: 0.7590328497531543
Validation loss: 2.69563878245213

Epoch: 6| Step: 13
Training loss: 0.47207665965903606
Validation loss: 2.6907520209563613

Epoch: 228| Step: 0
Training loss: 0.6468450686767854
Validation loss: 2.65784796725318

Epoch: 6| Step: 1
Training loss: 0.5580297437075964
Validation loss: 2.685574410962051

Epoch: 6| Step: 2
Training loss: 0.3528395347103547
Validation loss: 2.726980976974691

Epoch: 6| Step: 3
Training loss: 0.9273130725134557
Validation loss: 2.661245697147014

Epoch: 6| Step: 4
Training loss: 0.35685497414809003
Validation loss: 2.6793873195247815

Epoch: 6| Step: 5
Training loss: 0.5526792411131051
Validation loss: 2.6853945195301114

Epoch: 6| Step: 6
Training loss: 0.49854767995678445
Validation loss: 2.6884593138607373

Epoch: 6| Step: 7
Training loss: 0.4563582592382808
Validation loss: 2.6966924847976808

Epoch: 6| Step: 8
Training loss: 0.7011784417740133
Validation loss: 2.6790264860255744

Epoch: 6| Step: 9
Training loss: 0.4565054158968505
Validation loss: 2.619927819255082

Epoch: 6| Step: 10
Training loss: 0.4995860233770025
Validation loss: 2.718727784047762

Epoch: 6| Step: 11
Training loss: 0.3949298544661497
Validation loss: 2.724722269469832

Epoch: 6| Step: 12
Training loss: 0.5207626549130373
Validation loss: 2.655826669506486

Epoch: 6| Step: 13
Training loss: 0.5763196335464713
Validation loss: 2.663816244876034

Epoch: 229| Step: 0
Training loss: 0.46513670016906816
Validation loss: 2.6680886728972992

Epoch: 6| Step: 1
Training loss: 0.5322709371284055
Validation loss: 2.5902384998478727

Epoch: 6| Step: 2
Training loss: 0.6066964285313288
Validation loss: 2.6851194543271713

Epoch: 6| Step: 3
Training loss: 0.6910674994854427
Validation loss: 2.6798605163297653

Epoch: 6| Step: 4
Training loss: 0.6568354311421303
Validation loss: 2.670004690132832

Epoch: 6| Step: 5
Training loss: 0.4172540775851799
Validation loss: 2.633903043621702

Epoch: 6| Step: 6
Training loss: 0.6582597883607216
Validation loss: 2.6551078210670074

Epoch: 6| Step: 7
Training loss: 0.7036208629530583
Validation loss: 2.711892171516571

Epoch: 6| Step: 8
Training loss: 0.7698455788226942
Validation loss: 2.7072130429362136

Epoch: 6| Step: 9
Training loss: 0.2917549419785371
Validation loss: 2.668919265048622

Epoch: 6| Step: 10
Training loss: 0.38785513170935754
Validation loss: 2.652810221923588

Epoch: 6| Step: 11
Training loss: 0.5515187783783762
Validation loss: 2.6571574736631156

Epoch: 6| Step: 12
Training loss: 0.5734224052417393
Validation loss: 2.6825315547199966

Epoch: 6| Step: 13
Training loss: 0.41013746672717927
Validation loss: 2.707683343406351

Epoch: 230| Step: 0
Training loss: 0.2920272448873829
Validation loss: 2.665460244111215

Epoch: 6| Step: 1
Training loss: 0.40974323731567835
Validation loss: 2.7115467130893065

Epoch: 6| Step: 2
Training loss: 0.4590317397332174
Validation loss: 2.6892961000521676

Epoch: 6| Step: 3
Training loss: 0.5926103949011375
Validation loss: 2.6848709347023973

Epoch: 6| Step: 4
Training loss: 0.8004602300520742
Validation loss: 2.647905744584611

Epoch: 6| Step: 5
Training loss: 0.5658982201883438
Validation loss: 2.661608284286274

Epoch: 6| Step: 6
Training loss: 0.5599973690022244
Validation loss: 2.5918606537304663

Epoch: 6| Step: 7
Training loss: 0.391351672420045
Validation loss: 2.64566062503737

Epoch: 6| Step: 8
Training loss: 0.44218105068828023
Validation loss: 2.68628151203108

Epoch: 6| Step: 9
Training loss: 0.6126624466092105
Validation loss: 2.714841656947072

Epoch: 6| Step: 10
Training loss: 0.5712165460452727
Validation loss: 2.682068903786783

Epoch: 6| Step: 11
Training loss: 0.36494032094302553
Validation loss: 2.654920731586633

Epoch: 6| Step: 12
Training loss: 0.4781794086988797
Validation loss: 2.7191257363326304

Epoch: 6| Step: 13
Training loss: 0.6133744478784894
Validation loss: 2.66025888447592

Epoch: 231| Step: 0
Training loss: 0.4094528160683613
Validation loss: 2.6239632723949713

Epoch: 6| Step: 1
Training loss: 0.5478781083419393
Validation loss: 2.672282145155019

Epoch: 6| Step: 2
Training loss: 0.48895228243891053
Validation loss: 2.7105430220742264

Epoch: 6| Step: 3
Training loss: 0.462465437035816
Validation loss: 2.632039093310856

Epoch: 6| Step: 4
Training loss: 0.5646391301425466
Validation loss: 2.614251398138766

Epoch: 6| Step: 5
Training loss: 0.6324360987835013
Validation loss: 2.6812742556739724

Epoch: 6| Step: 6
Training loss: 0.562785447067259
Validation loss: 2.6780822364719494

Epoch: 6| Step: 7
Training loss: 0.4954641206369275
Validation loss: 2.675112898396073

Epoch: 6| Step: 8
Training loss: 0.38421890221554356
Validation loss: 2.694339550790626

Epoch: 6| Step: 9
Training loss: 0.6200105830796748
Validation loss: 2.643517228889732

Epoch: 6| Step: 10
Training loss: 0.407673761730778
Validation loss: 2.6611748610974586

Epoch: 6| Step: 11
Training loss: 0.6279509972357332
Validation loss: 2.6099296178377553

Epoch: 6| Step: 12
Training loss: 0.7307160718691191
Validation loss: 2.6340603309785644

Epoch: 6| Step: 13
Training loss: 0.5174365731774839
Validation loss: 2.6690513309694235

Epoch: 232| Step: 0
Training loss: 0.6022534551366979
Validation loss: 2.6961425387738656

Epoch: 6| Step: 1
Training loss: 0.5785730017955186
Validation loss: 2.7048796322707673

Epoch: 6| Step: 2
Training loss: 0.8685193874081704
Validation loss: 2.751393109807844

Epoch: 6| Step: 3
Training loss: 0.6429231175560317
Validation loss: 2.709308746947534

Epoch: 6| Step: 4
Training loss: 0.4439224834756856
Validation loss: 2.686280631885811

Epoch: 6| Step: 5
Training loss: 0.5680678888452079
Validation loss: 2.7474455673754337

Epoch: 6| Step: 6
Training loss: 0.5357600237985155
Validation loss: 2.599577626742139

Epoch: 6| Step: 7
Training loss: 0.598388671875
Validation loss: 2.656954129707625

Epoch: 6| Step: 8
Training loss: 0.7359814624654645
Validation loss: 2.649177050414669

Epoch: 6| Step: 9
Training loss: 0.5125578196404567
Validation loss: 2.6960981173145107

Epoch: 6| Step: 10
Training loss: 0.4489183831492191
Validation loss: 2.644937834294583

Epoch: 6| Step: 11
Training loss: 0.390130282887261
Validation loss: 2.697412411808898

Epoch: 6| Step: 12
Training loss: 0.7128424641266184
Validation loss: 2.6742502255063583

Epoch: 6| Step: 13
Training loss: 0.5204605166935823
Validation loss: 2.690041087402846

Epoch: 233| Step: 0
Training loss: 0.3354764924490707
Validation loss: 2.7046017884987403

Epoch: 6| Step: 1
Training loss: 0.5529145934356632
Validation loss: 2.6449813271952887

Epoch: 6| Step: 2
Training loss: 0.4333931742516607
Validation loss: 2.636848186565455

Epoch: 6| Step: 3
Training loss: 0.6922023521879362
Validation loss: 2.6596161849152273

Epoch: 6| Step: 4
Training loss: 0.6463987403232392
Validation loss: 2.616577229115335

Epoch: 6| Step: 5
Training loss: 0.6653603157359483
Validation loss: 2.7099758938213405

Epoch: 6| Step: 6
Training loss: 0.5295989241007107
Validation loss: 2.645128086043881

Epoch: 6| Step: 7
Training loss: 0.4342073274738719
Validation loss: 2.6474876088208736

Epoch: 6| Step: 8
Training loss: 0.29173080840317733
Validation loss: 2.6656153563563145

Epoch: 6| Step: 9
Training loss: 0.5144801869150248
Validation loss: 2.66967641338821

Epoch: 6| Step: 10
Training loss: 0.5674469693231283
Validation loss: 2.712331466595715

Epoch: 6| Step: 11
Training loss: 0.382180412208043
Validation loss: 2.640474710194205

Epoch: 6| Step: 12
Training loss: 0.7538566770709895
Validation loss: 2.6992951091117896

Epoch: 6| Step: 13
Training loss: 0.5921861985728274
Validation loss: 2.7252602951601417

Epoch: 234| Step: 0
Training loss: 0.5343024689824559
Validation loss: 2.680930024730338

Epoch: 6| Step: 1
Training loss: 0.4678656023372473
Validation loss: 2.74569700729478

Epoch: 6| Step: 2
Training loss: 0.6264728834033273
Validation loss: 2.6799328008691328

Epoch: 6| Step: 3
Training loss: 0.367538730565644
Validation loss: 2.712518544287511

Epoch: 6| Step: 4
Training loss: 0.5648625614732408
Validation loss: 2.636875492664625

Epoch: 6| Step: 5
Training loss: 0.5508314610313341
Validation loss: 2.6723611251866037

Epoch: 6| Step: 6
Training loss: 0.49276170085366955
Validation loss: 2.683847414454006

Epoch: 6| Step: 7
Training loss: 0.6949497305233545
Validation loss: 2.6717918264073504

Epoch: 6| Step: 8
Training loss: 0.5588766595367454
Validation loss: 2.6464542476351545

Epoch: 6| Step: 9
Training loss: 0.5666342703824412
Validation loss: 2.712097733198055

Epoch: 6| Step: 10
Training loss: 0.7548839179224603
Validation loss: 2.7605041394079737

Epoch: 6| Step: 11
Training loss: 0.40306713295129976
Validation loss: 2.706895965234269

Epoch: 6| Step: 12
Training loss: 0.6067203260583519
Validation loss: 2.7393369866101778

Epoch: 6| Step: 13
Training loss: 0.8482849321129102
Validation loss: 2.6861887549673855

Epoch: 235| Step: 0
Training loss: 0.42209340552651126
Validation loss: 2.672349593935253

Epoch: 6| Step: 1
Training loss: 0.41921856556368314
Validation loss: 2.6174520406303725

Epoch: 6| Step: 2
Training loss: 0.9539084419643952
Validation loss: 2.7090009942309328

Epoch: 6| Step: 3
Training loss: 0.540861307438538
Validation loss: 2.679791862746587

Epoch: 6| Step: 4
Training loss: 0.34857801332608335
Validation loss: 2.6651191144927484

Epoch: 6| Step: 5
Training loss: 0.6398357088098385
Validation loss: 2.6399711988303753

Epoch: 6| Step: 6
Training loss: 0.5634377398413699
Validation loss: 2.7173130286456098

Epoch: 6| Step: 7
Training loss: 0.4151645425837629
Validation loss: 2.658043379401662

Epoch: 6| Step: 8
Training loss: 0.42193083923398506
Validation loss: 2.678214852047274

Epoch: 6| Step: 9
Training loss: 0.5969751004469022
Validation loss: 2.64627675723611

Epoch: 6| Step: 10
Training loss: 0.7254073281283216
Validation loss: 2.6628136490379624

Epoch: 6| Step: 11
Training loss: 0.3728818678292154
Validation loss: 2.6779838017350563

Epoch: 6| Step: 12
Training loss: 0.7481425649928067
Validation loss: 2.6280549755587925

Epoch: 6| Step: 13
Training loss: 0.6519702595995566
Validation loss: 2.6446371803874063

Epoch: 236| Step: 0
Training loss: 0.7023852589596826
Validation loss: 2.65498567298333

Epoch: 6| Step: 1
Training loss: 0.5568176523429038
Validation loss: 2.64278237962468

Epoch: 6| Step: 2
Training loss: 0.3981652732313504
Validation loss: 2.666567641644863

Epoch: 6| Step: 3
Training loss: 0.7784003356613345
Validation loss: 2.591933790364507

Epoch: 6| Step: 4
Training loss: 0.6856394213513343
Validation loss: 2.6773555533100053

Epoch: 6| Step: 5
Training loss: 0.4728660433165771
Validation loss: 2.6618024948168424

Epoch: 6| Step: 6
Training loss: 0.5284004080199776
Validation loss: 2.6289207152015437

Epoch: 6| Step: 7
Training loss: 0.5879095587738936
Validation loss: 2.6795124704866007

Epoch: 6| Step: 8
Training loss: 0.5216703047742317
Validation loss: 2.6455974223376293

Epoch: 6| Step: 9
Training loss: 0.3030043351993201
Validation loss: 2.6477402601048814

Epoch: 6| Step: 10
Training loss: 0.49600334545226277
Validation loss: 2.590983550902016

Epoch: 6| Step: 11
Training loss: 0.43040448105369
Validation loss: 2.699129065400591

Epoch: 6| Step: 12
Training loss: 0.33344194634502045
Validation loss: 2.5951039484062974

Epoch: 6| Step: 13
Training loss: 0.2751524145237028
Validation loss: 2.6505239664455154

Epoch: 237| Step: 0
Training loss: 0.5277593882045089
Validation loss: 2.6528715901544255

Epoch: 6| Step: 1
Training loss: 0.8734522482184746
Validation loss: 2.6448399914331526

Epoch: 6| Step: 2
Training loss: 0.39189011746926516
Validation loss: 2.6875090340159375

Epoch: 6| Step: 3
Training loss: 0.5074012558340004
Validation loss: 2.7006284912388145

Epoch: 6| Step: 4
Training loss: 0.4842819616732587
Validation loss: 2.647136222262556

Epoch: 6| Step: 5
Training loss: 0.3932188697965734
Validation loss: 2.693513942798788

Epoch: 6| Step: 6
Training loss: 0.4616265722909611
Validation loss: 2.654594923010176

Epoch: 6| Step: 7
Training loss: 0.384144625593467
Validation loss: 2.726581343883553

Epoch: 6| Step: 8
Training loss: 0.6245106211660849
Validation loss: 2.7118988677732334

Epoch: 6| Step: 9
Training loss: 0.7206484559369933
Validation loss: 2.7041932863434877

Epoch: 6| Step: 10
Training loss: 0.4961709540659954
Validation loss: 2.6182319644639596

Epoch: 6| Step: 11
Training loss: 0.6123530172594356
Validation loss: 2.6882792902877157

Epoch: 6| Step: 12
Training loss: 0.5816632586008624
Validation loss: 2.6636078447503184

Epoch: 6| Step: 13
Training loss: 0.43093311788918776
Validation loss: 2.5836302191866634

Epoch: 238| Step: 0
Training loss: 0.4203605312428923
Validation loss: 2.6520685231968204

Epoch: 6| Step: 1
Training loss: 0.5864275599571016
Validation loss: 2.664412668433007

Epoch: 6| Step: 2
Training loss: 0.6006137996506534
Validation loss: 2.7106081188081723

Epoch: 6| Step: 3
Training loss: 0.6455102132732398
Validation loss: 2.6988329613994213

Epoch: 6| Step: 4
Training loss: 0.44224264859137696
Validation loss: 2.624311106976739

Epoch: 6| Step: 5
Training loss: 0.46157679433002274
Validation loss: 2.715764434360315

Epoch: 6| Step: 6
Training loss: 0.32869736387862863
Validation loss: 2.7109832466655663

Epoch: 6| Step: 7
Training loss: 0.6525458291281532
Validation loss: 2.7125197528524216

Epoch: 6| Step: 8
Training loss: 0.4376045170326831
Validation loss: 2.6922668646067764

Epoch: 6| Step: 9
Training loss: 0.6507128355556837
Validation loss: 2.6872015942646326

Epoch: 6| Step: 10
Training loss: 0.678530025384269
Validation loss: 2.7118737237567863

Epoch: 6| Step: 11
Training loss: 0.5151274621502454
Validation loss: 2.661267414946858

Epoch: 6| Step: 12
Training loss: 0.6106880908182777
Validation loss: 2.7119672213948767

Epoch: 6| Step: 13
Training loss: 0.3842980501638158
Validation loss: 2.642417164120435

Epoch: 239| Step: 0
Training loss: 0.6411722683408583
Validation loss: 2.6628893658567545

Epoch: 6| Step: 1
Training loss: 0.5972552730843282
Validation loss: 2.6624117870970454

Epoch: 6| Step: 2
Training loss: 0.5592664922397851
Validation loss: 2.7074814018956284

Epoch: 6| Step: 3
Training loss: 0.34831300059360776
Validation loss: 2.670767876353098

Epoch: 6| Step: 4
Training loss: 0.6042163324221397
Validation loss: 2.6923950180277005

Epoch: 6| Step: 5
Training loss: 0.4972393595313169
Validation loss: 2.7562197083115536

Epoch: 6| Step: 6
Training loss: 0.5140329984414518
Validation loss: 2.708451852895041

Epoch: 6| Step: 7
Training loss: 0.6612464885942939
Validation loss: 2.7032684552709183

Epoch: 6| Step: 8
Training loss: 0.3541366854300638
Validation loss: 2.7196471389323165

Epoch: 6| Step: 9
Training loss: 0.4427295866707815
Validation loss: 2.6581520525986844

Epoch: 6| Step: 10
Training loss: 0.5086912328346676
Validation loss: 2.671455491652578

Epoch: 6| Step: 11
Training loss: 0.41251673158756064
Validation loss: 2.732928810966981

Epoch: 6| Step: 12
Training loss: 0.6849366866040005
Validation loss: 2.677894355637853

Epoch: 6| Step: 13
Training loss: 0.5841238308255465
Validation loss: 2.663789662460133

Epoch: 240| Step: 0
Training loss: 0.6154271383907657
Validation loss: 2.6802009557708204

Epoch: 6| Step: 1
Training loss: 0.3278374774606611
Validation loss: 2.7035750968045793

Epoch: 6| Step: 2
Training loss: 0.5021987492192171
Validation loss: 2.717287978598976

Epoch: 6| Step: 3
Training loss: 0.541585711396144
Validation loss: 2.6436280849955316

Epoch: 6| Step: 4
Training loss: 0.6829553947809859
Validation loss: 2.639258864606828

Epoch: 6| Step: 5
Training loss: 0.5218772408443014
Validation loss: 2.665265584479023

Epoch: 6| Step: 6
Training loss: 0.7091930492154096
Validation loss: 2.6641526416731174

Epoch: 6| Step: 7
Training loss: 0.5633173937583388
Validation loss: 2.640951027390726

Epoch: 6| Step: 8
Training loss: 0.5158821678412356
Validation loss: 2.6272795407028986

Epoch: 6| Step: 9
Training loss: 0.6841774328719006
Validation loss: 2.6780242206569325

Epoch: 6| Step: 10
Training loss: 0.4996453905284823
Validation loss: 2.6676649718439105

Epoch: 6| Step: 11
Training loss: 0.5609444195418879
Validation loss: 2.6792415622270895

Epoch: 6| Step: 12
Training loss: 0.7695524725916352
Validation loss: 2.6751645307953225

Epoch: 6| Step: 13
Training loss: 0.4198451837104194
Validation loss: 2.6430846802757295

Epoch: 241| Step: 0
Training loss: 0.5309908178544922
Validation loss: 2.692070157974783

Epoch: 6| Step: 1
Training loss: 0.6602605252046299
Validation loss: 2.6775227469324854

Epoch: 6| Step: 2
Training loss: 0.551049458016573
Validation loss: 2.707640549500858

Epoch: 6| Step: 3
Training loss: 0.608385701298773
Validation loss: 2.7467117156883667

Epoch: 6| Step: 4
Training loss: 0.6813826195657002
Validation loss: 2.7040978446944997

Epoch: 6| Step: 5
Training loss: 0.3944438799815251
Validation loss: 2.630300461065245

Epoch: 6| Step: 6
Training loss: 0.6201793489313613
Validation loss: 2.67065242585118

Epoch: 6| Step: 7
Training loss: 0.6257187048889122
Validation loss: 2.672597092285341

Epoch: 6| Step: 8
Training loss: 0.47885107621805595
Validation loss: 2.668328681225348

Epoch: 6| Step: 9
Training loss: 0.6014853589027207
Validation loss: 2.7331369412819417

Epoch: 6| Step: 10
Training loss: 0.6102586355039835
Validation loss: 2.7163498613796637

Epoch: 6| Step: 11
Training loss: 0.4669364018387123
Validation loss: 2.6915105569722084

Epoch: 6| Step: 12
Training loss: 0.7077225314260082
Validation loss: 2.7651985256305

Epoch: 6| Step: 13
Training loss: 0.5506112668319847
Validation loss: 2.7624105390099283

Epoch: 242| Step: 0
Training loss: 0.5780046698635697
Validation loss: 2.771166822016559

Epoch: 6| Step: 1
Training loss: 0.6604076787014093
Validation loss: 2.7866891830696723

Epoch: 6| Step: 2
Training loss: 0.5516934787749966
Validation loss: 2.722648573161777

Epoch: 6| Step: 3
Training loss: 0.4508190674678255
Validation loss: 2.5783329504128263

Epoch: 6| Step: 4
Training loss: 0.466583250955101
Validation loss: 2.704126808174481

Epoch: 6| Step: 5
Training loss: 0.6002992519523336
Validation loss: 2.6875371265064802

Epoch: 6| Step: 6
Training loss: 0.6950037410004191
Validation loss: 2.676385726777273

Epoch: 6| Step: 7
Training loss: 0.3419833628214711
Validation loss: 2.712053492488333

Epoch: 6| Step: 8
Training loss: 0.44635490082094703
Validation loss: 2.6862241096840593

Epoch: 6| Step: 9
Training loss: 0.4367349952583348
Validation loss: 2.6640806150892575

Epoch: 6| Step: 10
Training loss: 0.6095701052033751
Validation loss: 2.633180918890166

Epoch: 6| Step: 11
Training loss: 0.5065990622125854
Validation loss: 2.706996996407357

Epoch: 6| Step: 12
Training loss: 0.703697564863269
Validation loss: 2.6576089561665555

Epoch: 6| Step: 13
Training loss: 0.43522563771489237
Validation loss: 2.6458332607439488

Epoch: 243| Step: 0
Training loss: 0.6959924052539351
Validation loss: 2.696530406945274

Epoch: 6| Step: 1
Training loss: 0.595307140376277
Validation loss: 2.6630364732726335

Epoch: 6| Step: 2
Training loss: 0.5547872910259574
Validation loss: 2.7165989606022376

Epoch: 6| Step: 3
Training loss: 0.40386268779248835
Validation loss: 2.670903183434807

Epoch: 6| Step: 4
Training loss: 0.4463091956340679
Validation loss: 2.656789388307022

Epoch: 6| Step: 5
Training loss: 0.6804627130286616
Validation loss: 2.6079474101702793

Epoch: 6| Step: 6
Training loss: 0.6568700948835139
Validation loss: 2.6459404380526426

Epoch: 6| Step: 7
Training loss: 0.6144794494848985
Validation loss: 2.6374332015752366

Epoch: 6| Step: 8
Training loss: 0.3413052538270395
Validation loss: 2.697823023306251

Epoch: 6| Step: 9
Training loss: 0.6181378592531511
Validation loss: 2.675223559250667

Epoch: 6| Step: 10
Training loss: 0.3775065811164616
Validation loss: 2.687762166328749

Epoch: 6| Step: 11
Training loss: 0.36406823509839875
Validation loss: 2.7250922318694895

Epoch: 6| Step: 12
Training loss: 0.3279350957373398
Validation loss: 2.6589812355178015

Epoch: 6| Step: 13
Training loss: 0.45533871045726265
Validation loss: 2.6292497808152797

Epoch: 244| Step: 0
Training loss: 0.3741802952386445
Validation loss: 2.665856079246197

Epoch: 6| Step: 1
Training loss: 0.37217732890441996
Validation loss: 2.6285339515074746

Epoch: 6| Step: 2
Training loss: 0.30524549984875693
Validation loss: 2.695484940914374

Epoch: 6| Step: 3
Training loss: 0.510482605418291
Validation loss: 2.7135555000953224

Epoch: 6| Step: 4
Training loss: 0.25997489014748043
Validation loss: 2.7210828557664812

Epoch: 6| Step: 5
Training loss: 0.6612127529030798
Validation loss: 2.6599184173607227

Epoch: 6| Step: 6
Training loss: 0.5784588185096089
Validation loss: 2.6936268939854626

Epoch: 6| Step: 7
Training loss: 0.41009642755119335
Validation loss: 2.726777688527722

Epoch: 6| Step: 8
Training loss: 0.7276730407651771
Validation loss: 2.7441326679734317

Epoch: 6| Step: 9
Training loss: 0.6828278965381694
Validation loss: 2.716026125519599

Epoch: 6| Step: 10
Training loss: 0.674130512886275
Validation loss: 2.6925659191217055

Epoch: 6| Step: 11
Training loss: 0.5671036209001612
Validation loss: 2.687847070683425

Epoch: 6| Step: 12
Training loss: 0.5786844073010144
Validation loss: 2.744301281046556

Epoch: 6| Step: 13
Training loss: 0.6073598554049482
Validation loss: 2.6830473690204486

Epoch: 245| Step: 0
Training loss: 0.44272440338887276
Validation loss: 2.7271497471131507

Epoch: 6| Step: 1
Training loss: 0.3871007824049019
Validation loss: 2.7104276238077536

Epoch: 6| Step: 2
Training loss: 0.36287124631321976
Validation loss: 2.6660532444499347

Epoch: 6| Step: 3
Training loss: 0.5236154225416737
Validation loss: 2.6922090216256307

Epoch: 6| Step: 4
Training loss: 0.4472285759252706
Validation loss: 2.6519184998267975

Epoch: 6| Step: 5
Training loss: 0.45412003674408125
Validation loss: 2.5913096058270115

Epoch: 6| Step: 6
Training loss: 0.329956686941565
Validation loss: 2.6247311560395246

Epoch: 6| Step: 7
Training loss: 0.46408138750474026
Validation loss: 2.665025643230689

Epoch: 6| Step: 8
Training loss: 0.536453512472571
Validation loss: 2.6304427819839153

Epoch: 6| Step: 9
Training loss: 0.5185254909536047
Validation loss: 2.631410249857636

Epoch: 6| Step: 10
Training loss: 0.5885162066688838
Validation loss: 2.669274274622242

Epoch: 6| Step: 11
Training loss: 0.4574741434649312
Validation loss: 2.6619824504937775

Epoch: 6| Step: 12
Training loss: 0.7751943882835532
Validation loss: 2.71414108147966

Epoch: 6| Step: 13
Training loss: 0.45922705545147646
Validation loss: 2.5818470760803254

Epoch: 246| Step: 0
Training loss: 0.502895494798683
Validation loss: 2.6740547940478008

Epoch: 6| Step: 1
Training loss: 0.4533203788997235
Validation loss: 2.627527669972042

Epoch: 6| Step: 2
Training loss: 0.402199098824374
Validation loss: 2.6575636962357785

Epoch: 6| Step: 3
Training loss: 0.3335558277883046
Validation loss: 2.618629399984561

Epoch: 6| Step: 4
Training loss: 0.7261188752449137
Validation loss: 2.6838892330280095

Epoch: 6| Step: 5
Training loss: 0.3376077118055503
Validation loss: 2.64812325832948

Epoch: 6| Step: 6
Training loss: 0.3222838309954143
Validation loss: 2.6681129934136525

Epoch: 6| Step: 7
Training loss: 0.7371893179864204
Validation loss: 2.6902767887965964

Epoch: 6| Step: 8
Training loss: 0.49665905440447294
Validation loss: 2.677241025107386

Epoch: 6| Step: 9
Training loss: 0.4799395647596934
Validation loss: 2.6614007713428554

Epoch: 6| Step: 10
Training loss: 0.5646266736454847
Validation loss: 2.7125198773712

Epoch: 6| Step: 11
Training loss: 0.46982568658549095
Validation loss: 2.693221131323048

Epoch: 6| Step: 12
Training loss: 0.3603509215475859
Validation loss: 2.6844965541971666

Epoch: 6| Step: 13
Training loss: 0.43084885834268954
Validation loss: 2.6694969019486323

Epoch: 247| Step: 0
Training loss: 0.5735288614778195
Validation loss: 2.6316689744407324

Epoch: 6| Step: 1
Training loss: 0.4592673869820949
Validation loss: 2.7397941440558213

Epoch: 6| Step: 2
Training loss: 0.6657771021819616
Validation loss: 2.6670677558941835

Epoch: 6| Step: 3
Training loss: 0.6118319205762527
Validation loss: 2.6949277151648774

Epoch: 6| Step: 4
Training loss: 0.33248553893543803
Validation loss: 2.71136935822424

Epoch: 6| Step: 5
Training loss: 0.540009427076634
Validation loss: 2.7135850655178126

Epoch: 6| Step: 6
Training loss: 0.58844160956732
Validation loss: 2.673537675804081

Epoch: 6| Step: 7
Training loss: 0.775000063065557
Validation loss: 2.704327809999326

Epoch: 6| Step: 8
Training loss: 0.47188915711443596
Validation loss: 2.6695116384171187

Epoch: 6| Step: 9
Training loss: 0.6650523717951671
Validation loss: 2.7018513407610016

Epoch: 6| Step: 10
Training loss: 0.3530373050872445
Validation loss: 2.6889342909015146

Epoch: 6| Step: 11
Training loss: 0.5004473115853193
Validation loss: 2.7457307419161614

Epoch: 6| Step: 12
Training loss: 0.35855336179985864
Validation loss: 2.641136616459008

Epoch: 6| Step: 13
Training loss: 0.4036230101336979
Validation loss: 2.729540185386903

Epoch: 248| Step: 0
Training loss: 0.4300280521912341
Validation loss: 2.6762522484789066

Epoch: 6| Step: 1
Training loss: 0.3813802043393405
Validation loss: 2.6865853076366184

Epoch: 6| Step: 2
Training loss: 0.6559881414498816
Validation loss: 2.6904873471967155

Epoch: 6| Step: 3
Training loss: 0.3894712193302211
Validation loss: 2.667573779514989

Epoch: 6| Step: 4
Training loss: 0.6320884235489773
Validation loss: 2.6814264525452005

Epoch: 6| Step: 5
Training loss: 0.6319424806175412
Validation loss: 2.686989876290205

Epoch: 6| Step: 6
Training loss: 0.5228225739871457
Validation loss: 2.6333528260423

Epoch: 6| Step: 7
Training loss: 0.46997517373076586
Validation loss: 2.647409395199044

Epoch: 6| Step: 8
Training loss: 0.4702015337144638
Validation loss: 2.6280214087428573

Epoch: 6| Step: 9
Training loss: 0.4480965737247812
Validation loss: 2.675028941630728

Epoch: 6| Step: 10
Training loss: 0.3268179519499133
Validation loss: 2.630856882843219

Epoch: 6| Step: 11
Training loss: 0.611505695915363
Validation loss: 2.646989079358601

Epoch: 6| Step: 12
Training loss: 0.4617870390039261
Validation loss: 2.6667448394960056

Epoch: 6| Step: 13
Training loss: 0.3440015912518181
Validation loss: 2.7023704004751905

Epoch: 249| Step: 0
Training loss: 0.6345160360421629
Validation loss: 2.713982461478626

Epoch: 6| Step: 1
Training loss: 0.40156828582989057
Validation loss: 2.7062458258546

Epoch: 6| Step: 2
Training loss: 0.5315452204188253
Validation loss: 2.701942082117301

Epoch: 6| Step: 3
Training loss: 0.5745106688157051
Validation loss: 2.706555271917884

Epoch: 6| Step: 4
Training loss: 0.35730708212262224
Validation loss: 2.6841341128936818

Epoch: 6| Step: 5
Training loss: 0.39740094756122385
Validation loss: 2.734112085690738

Epoch: 6| Step: 6
Training loss: 0.4443324162270329
Validation loss: 2.6434135234915055

Epoch: 6| Step: 7
Training loss: 0.5650755146925666
Validation loss: 2.6396707168562803

Epoch: 6| Step: 8
Training loss: 0.5671116875458014
Validation loss: 2.710872594402676

Epoch: 6| Step: 9
Training loss: 0.3107023269915482
Validation loss: 2.686501724190546

Epoch: 6| Step: 10
Training loss: 0.5566531531279313
Validation loss: 2.6783825928866802

Epoch: 6| Step: 11
Training loss: 0.5738517990058845
Validation loss: 2.6818706120247917

Epoch: 6| Step: 12
Training loss: 0.5630011710075139
Validation loss: 2.6785846068042947

Epoch: 6| Step: 13
Training loss: 0.7089501995330407
Validation loss: 2.642103394550162

Epoch: 250| Step: 0
Training loss: 0.5643261565388434
Validation loss: 2.731893128796239

Epoch: 6| Step: 1
Training loss: 0.6271132980571842
Validation loss: 2.6575697817751225

Epoch: 6| Step: 2
Training loss: 0.3518877644027731
Validation loss: 2.6224413769633315

Epoch: 6| Step: 3
Training loss: 0.508663081352519
Validation loss: 2.6953150505016996

Epoch: 6| Step: 4
Training loss: 0.331128565104133
Validation loss: 2.692193819002812

Epoch: 6| Step: 5
Training loss: 0.5772465914480651
Validation loss: 2.70974294707885

Epoch: 6| Step: 6
Training loss: 0.62830067735229
Validation loss: 2.6805909527257157

Epoch: 6| Step: 7
Training loss: 0.7198184406326522
Validation loss: 2.570484932446279

Epoch: 6| Step: 8
Training loss: 0.3711739905089718
Validation loss: 2.7059228783082587

Epoch: 6| Step: 9
Training loss: 0.3436770578502189
Validation loss: 2.6311928269433786

Epoch: 6| Step: 10
Training loss: 0.3892292837205282
Validation loss: 2.626023683306079

Epoch: 6| Step: 11
Training loss: 0.5813239491500743
Validation loss: 2.6588154838854154

Epoch: 6| Step: 12
Training loss: 0.48992495251605855
Validation loss: 2.685694975497299

Epoch: 6| Step: 13
Training loss: 0.3506427601958812
Validation loss: 2.627307634410734

Testing loss: 2.490634999271018
