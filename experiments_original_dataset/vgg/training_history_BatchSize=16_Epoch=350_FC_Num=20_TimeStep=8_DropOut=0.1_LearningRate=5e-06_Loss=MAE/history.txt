Epoch: 1| Step: 0
Training loss: 4.384952068328857
Validation loss: 5.150270541508992

Epoch: 6| Step: 1
Training loss: 5.29193115234375
Validation loss: 5.137994607289632

Epoch: 6| Step: 2
Training loss: 5.547676086425781
Validation loss: 5.12653128306071

Epoch: 6| Step: 3
Training loss: 5.355737686157227
Validation loss: 5.113922119140625

Epoch: 6| Step: 4
Training loss: 5.692915439605713
Validation loss: 5.10209584236145

Epoch: 6| Step: 5
Training loss: 5.068366050720215
Validation loss: 5.086812416712443

Epoch: 6| Step: 6
Training loss: 5.042574405670166
Validation loss: 5.072616895039876

Epoch: 6| Step: 7
Training loss: 6.076204776763916
Validation loss: 5.057181517283122

Epoch: 6| Step: 8
Training loss: 4.627107620239258
Validation loss: 5.04254150390625

Epoch: 6| Step: 9
Training loss: 5.980791091918945
Validation loss: 5.028623183568318

Epoch: 6| Step: 10
Training loss: 4.541959762573242
Validation loss: 5.012114842732747

Epoch: 6| Step: 11
Training loss: 4.023862838745117
Validation loss: 4.998077233632405

Epoch: 6| Step: 12
Training loss: 5.2627410888671875
Validation loss: 4.98099160194397

Epoch: 6| Step: 13
Training loss: 5.051042556762695
Validation loss: 4.964753111203511

Epoch: 2| Step: 0
Training loss: 4.52916145324707
Validation loss: 4.947596629460652

Epoch: 6| Step: 1
Training loss: 5.297299385070801
Validation loss: 4.930222272872925

Epoch: 6| Step: 2
Training loss: 5.852300643920898
Validation loss: 4.911650975545247

Epoch: 6| Step: 3
Training loss: 4.792784214019775
Validation loss: 4.891769647598267

Epoch: 6| Step: 4
Training loss: 5.327037811279297
Validation loss: 4.870239655176799

Epoch: 6| Step: 5
Training loss: 5.129523277282715
Validation loss: 4.852241039276123

Epoch: 6| Step: 6
Training loss: 4.694645881652832
Validation loss: 4.833058675130208

Epoch: 6| Step: 7
Training loss: 5.052483081817627
Validation loss: 4.812635580698649

Epoch: 6| Step: 8
Training loss: 6.066956520080566
Validation loss: 4.787377993265788

Epoch: 6| Step: 9
Training loss: 4.658576011657715
Validation loss: 4.762712319691976

Epoch: 6| Step: 10
Training loss: 4.056412220001221
Validation loss: 4.7392518520355225

Epoch: 6| Step: 11
Training loss: 3.1335573196411133
Validation loss: 4.714989066123962

Epoch: 6| Step: 12
Training loss: 5.296149730682373
Validation loss: 4.6887216965357466

Epoch: 6| Step: 13
Training loss: 4.631538391113281
Validation loss: 4.660109202067058

Epoch: 3| Step: 0
Training loss: 4.460949897766113
Validation loss: 4.632227222124736

Epoch: 6| Step: 1
Training loss: 3.766936779022217
Validation loss: 4.60270078976949

Epoch: 6| Step: 2
Training loss: 4.235737323760986
Validation loss: 4.566326300303142

Epoch: 6| Step: 3
Training loss: 4.182182312011719
Validation loss: 4.539883653322856

Epoch: 6| Step: 4
Training loss: 4.520591735839844
Validation loss: 4.500038504600525

Epoch: 6| Step: 5
Training loss: 4.7649712562561035
Validation loss: 4.462226231892903

Epoch: 6| Step: 6
Training loss: 4.873666286468506
Validation loss: 4.425340453783671

Epoch: 6| Step: 7
Training loss: 5.01361083984375
Validation loss: 4.3818232615788775

Epoch: 6| Step: 8
Training loss: 4.556713104248047
Validation loss: 4.340694983800252

Epoch: 6| Step: 9
Training loss: 3.3656301498413086
Validation loss: 4.295563459396362

Epoch: 6| Step: 10
Training loss: 5.740346908569336
Validation loss: 4.247818946838379

Epoch: 6| Step: 11
Training loss: 4.20933723449707
Validation loss: 4.195482095082601

Epoch: 6| Step: 12
Training loss: 4.888805389404297
Validation loss: 4.149272004763286

Epoch: 6| Step: 13
Training loss: 4.011842727661133
Validation loss: 4.101190050443013

Epoch: 4| Step: 0
Training loss: 3.5359082221984863
Validation loss: 4.046222726504008

Epoch: 6| Step: 1
Training loss: 5.0430145263671875
Validation loss: 3.9934590657552085

Epoch: 6| Step: 2
Training loss: 4.261889934539795
Validation loss: 3.925697088241577

Epoch: 6| Step: 3
Training loss: 3.380730152130127
Validation loss: 3.866867701212565

Epoch: 6| Step: 4
Training loss: 2.8565425872802734
Validation loss: 3.8069242238998413

Epoch: 6| Step: 5
Training loss: 3.445455551147461
Validation loss: 3.745689074198405

Epoch: 6| Step: 6
Training loss: 3.7277207374572754
Validation loss: 3.676918546358744

Epoch: 6| Step: 7
Training loss: 3.406848669052124
Validation loss: 3.611238439877828

Epoch: 6| Step: 8
Training loss: 3.2681527137756348
Validation loss: 3.5451117753982544

Epoch: 6| Step: 9
Training loss: 4.926831245422363
Validation loss: 3.4673258463541665

Epoch: 6| Step: 10
Training loss: 3.8028688430786133
Validation loss: 3.4028803507486978

Epoch: 6| Step: 11
Training loss: 3.3457231521606445
Validation loss: 3.3157002528508506

Epoch: 6| Step: 12
Training loss: 3.14536452293396
Validation loss: 3.248349666595459

Epoch: 6| Step: 13
Training loss: 3.675844669342041
Validation loss: 3.1505789756774902

Epoch: 5| Step: 0
Training loss: 3.2515711784362793
Validation loss: 3.07713516553243

Epoch: 6| Step: 1
Training loss: 3.4196219444274902
Validation loss: 2.9952094554901123

Epoch: 6| Step: 2
Training loss: 2.8950109481811523
Validation loss: 2.906205137570699

Epoch: 6| Step: 3
Training loss: 1.933902382850647
Validation loss: 2.813818573951721

Epoch: 6| Step: 4
Training loss: 2.6254732608795166
Validation loss: 2.7249918381373086

Epoch: 6| Step: 5
Training loss: 3.244013786315918
Validation loss: 2.6336647669474282

Epoch: 6| Step: 6
Training loss: 2.667567014694214
Validation loss: 2.5470158656438193

Epoch: 6| Step: 7
Training loss: 2.606083393096924
Validation loss: 2.4714863697687783

Epoch: 6| Step: 8
Training loss: 2.483597755432129
Validation loss: 2.4231300354003906

Epoch: 6| Step: 9
Training loss: 2.618971824645996
Validation loss: 2.3352088133494058

Epoch: 6| Step: 10
Training loss: 2.487891674041748
Validation loss: 2.3079844315846763

Epoch: 6| Step: 11
Training loss: 1.9868245124816895
Validation loss: 2.250152826309204

Epoch: 6| Step: 12
Training loss: 1.963597059249878
Validation loss: 2.234077056248983

Epoch: 6| Step: 13
Training loss: 1.7505638599395752
Validation loss: 2.192492445309957

Epoch: 6| Step: 0
Training loss: 1.2953518629074097
Validation loss: 2.2424561182657876

Epoch: 6| Step: 1
Training loss: 2.0435476303100586
Validation loss: 2.2348699967066445

Epoch: 6| Step: 2
Training loss: 2.047706127166748
Validation loss: 2.2549545764923096

Epoch: 6| Step: 3
Training loss: 2.71632719039917
Validation loss: 2.2981903553009033

Epoch: 6| Step: 4
Training loss: 1.981349229812622
Validation loss: 2.2943191528320312

Epoch: 6| Step: 5
Training loss: 1.7471603155136108
Validation loss: 2.317864716053009

Epoch: 6| Step: 6
Training loss: 2.937190055847168
Validation loss: 2.3424359957377114

Epoch: 6| Step: 7
Training loss: 3.5697221755981445
Validation loss: 2.341008941332499

Epoch: 6| Step: 8
Training loss: 1.884372353553772
Validation loss: 2.350791891415914

Epoch: 6| Step: 9
Training loss: 2.050724983215332
Validation loss: 2.2712857921918235

Epoch: 6| Step: 10
Training loss: 2.430111885070801
Validation loss: 2.286038895448049

Epoch: 6| Step: 11
Training loss: 2.291266441345215
Validation loss: 2.2818740208943686

Epoch: 6| Step: 12
Training loss: 2.151371717453003
Validation loss: 2.2592833638191223

Epoch: 6| Step: 13
Training loss: 2.098013162612915
Validation loss: 2.2273945808410645

Epoch: 7| Step: 0
Training loss: 1.617781639099121
Validation loss: 2.2590991854667664

Epoch: 6| Step: 1
Training loss: 2.603504180908203
Validation loss: 2.2174896399180093

Epoch: 6| Step: 2
Training loss: 2.07209849357605
Validation loss: 2.2156895995140076

Epoch: 6| Step: 3
Training loss: 1.7300126552581787
Validation loss: 2.2157893975575766

Epoch: 6| Step: 4
Training loss: 2.1773266792297363
Validation loss: 2.220850686232249

Epoch: 6| Step: 5
Training loss: 3.209470748901367
Validation loss: 2.2190136512120566

Epoch: 6| Step: 6
Training loss: 2.26594614982605
Validation loss: 2.2143410642941794

Epoch: 6| Step: 7
Training loss: 2.215540885925293
Validation loss: 2.2017881075541177

Epoch: 6| Step: 8
Training loss: 2.3545098304748535
Validation loss: 2.2373916109402976

Epoch: 6| Step: 9
Training loss: 2.0251893997192383
Validation loss: 2.2345966696739197

Epoch: 6| Step: 10
Training loss: 1.873236060142517
Validation loss: 2.245505392551422

Epoch: 6| Step: 11
Training loss: 1.7513008117675781
Validation loss: 2.2174504597981772

Epoch: 6| Step: 12
Training loss: 1.6749995946884155
Validation loss: 2.2042346199353537

Epoch: 6| Step: 13
Training loss: 2.40842866897583
Validation loss: 2.210327128569285

Epoch: 8| Step: 0
Training loss: 1.619848370552063
Validation loss: 2.2118689815203347

Epoch: 6| Step: 1
Training loss: 2.492635726928711
Validation loss: 2.192076623439789

Epoch: 6| Step: 2
Training loss: 1.8327430486679077
Validation loss: 2.2128947178522744

Epoch: 6| Step: 3
Training loss: 1.5044198036193848
Validation loss: 2.2299553553263345

Epoch: 6| Step: 4
Training loss: 1.9334906339645386
Validation loss: 2.218675434589386

Epoch: 6| Step: 5
Training loss: 2.237419366836548
Validation loss: 2.2208310763041177

Epoch: 6| Step: 6
Training loss: 2.7530133724212646
Validation loss: 2.2137985626856485

Epoch: 6| Step: 7
Training loss: 1.7549748420715332
Validation loss: 2.1840001742045083

Epoch: 6| Step: 8
Training loss: 2.1855783462524414
Validation loss: 2.2062963445981345

Epoch: 6| Step: 9
Training loss: 2.5442519187927246
Validation loss: 2.2193758487701416

Epoch: 6| Step: 10
Training loss: 2.12808895111084
Validation loss: 2.2329364816347756

Epoch: 6| Step: 11
Training loss: 2.1615607738494873
Validation loss: 2.216292401154836

Epoch: 6| Step: 12
Training loss: 2.5750315189361572
Validation loss: 2.1941710909207663

Epoch: 6| Step: 13
Training loss: 2.3107588291168213
Validation loss: 2.20645934343338

Epoch: 9| Step: 0
Training loss: 2.028538465499878
Validation loss: 2.2311438719431558

Epoch: 6| Step: 1
Training loss: 2.7056102752685547
Validation loss: 2.209318161010742

Epoch: 6| Step: 2
Training loss: 2.4370598793029785
Validation loss: 2.1969931920369468

Epoch: 6| Step: 3
Training loss: 1.6783658266067505
Validation loss: 2.203851898511251

Epoch: 6| Step: 4
Training loss: 2.042130708694458
Validation loss: 2.211852252483368

Epoch: 6| Step: 5
Training loss: 2.0878548622131348
Validation loss: 2.2200737794240317

Epoch: 6| Step: 6
Training loss: 2.498950719833374
Validation loss: 2.2153991063435874

Epoch: 6| Step: 7
Training loss: 1.8423866033554077
Validation loss: 2.198138952255249

Epoch: 6| Step: 8
Training loss: 1.8057626485824585
Validation loss: 2.219568153222402

Epoch: 6| Step: 9
Training loss: 2.3955442905426025
Validation loss: 2.2031548221906028

Epoch: 6| Step: 10
Training loss: 2.3055806159973145
Validation loss: 2.212211827437083

Epoch: 6| Step: 11
Training loss: 2.16131854057312
Validation loss: 2.197020431359609

Epoch: 6| Step: 12
Training loss: 2.2703697681427
Validation loss: 2.188335657119751

Epoch: 6| Step: 13
Training loss: 1.5201303958892822
Validation loss: 2.213947872320811

Epoch: 10| Step: 0
Training loss: 1.9915475845336914
Validation loss: 2.2123307983080545

Epoch: 6| Step: 1
Training loss: 2.3104288578033447
Validation loss: 2.200068712234497

Epoch: 6| Step: 2
Training loss: 2.2722482681274414
Validation loss: 2.20233545700709

Epoch: 6| Step: 3
Training loss: 2.4406683444976807
Validation loss: 2.205676813920339

Epoch: 6| Step: 4
Training loss: 2.4516477584838867
Validation loss: 2.1985958019892373

Epoch: 6| Step: 5
Training loss: 2.272467613220215
Validation loss: 2.1962312857309976

Epoch: 6| Step: 6
Training loss: 1.8883384466171265
Validation loss: 2.1952046155929565

Epoch: 6| Step: 7
Training loss: 2.141662359237671
Validation loss: 2.20447705189387

Epoch: 6| Step: 8
Training loss: 1.5841509103775024
Validation loss: 2.187682549158732

Epoch: 6| Step: 9
Training loss: 1.498140811920166
Validation loss: 2.195732076962789

Epoch: 6| Step: 10
Training loss: 2.6281278133392334
Validation loss: 2.2033012310663858

Epoch: 6| Step: 11
Training loss: 2.1576108932495117
Validation loss: 2.228490471839905

Epoch: 6| Step: 12
Training loss: 2.2676713466644287
Validation loss: 2.195209344228109

Epoch: 6| Step: 13
Training loss: 1.8235288858413696
Validation loss: 2.179264505704244

Epoch: 11| Step: 0
Training loss: 1.445765495300293
Validation loss: 2.1773301561673484

Epoch: 6| Step: 1
Training loss: 2.2664408683776855
Validation loss: 2.193496743837992

Epoch: 6| Step: 2
Training loss: 1.6901130676269531
Validation loss: 2.208604653676351

Epoch: 6| Step: 3
Training loss: 2.4337079524993896
Validation loss: 2.191396713256836

Epoch: 6| Step: 4
Training loss: 2.7848148345947266
Validation loss: 2.195254604021708

Epoch: 6| Step: 5
Training loss: 1.8970983028411865
Validation loss: 2.179909070332845

Epoch: 6| Step: 6
Training loss: 1.8883123397827148
Validation loss: 2.191312313079834

Epoch: 6| Step: 7
Training loss: 2.1385722160339355
Validation loss: 2.180741469065348

Epoch: 6| Step: 8
Training loss: 2.1376781463623047
Validation loss: 2.188608765602112

Epoch: 6| Step: 9
Training loss: 2.6015968322753906
Validation loss: 2.208797494570414

Epoch: 6| Step: 10
Training loss: 1.9434325695037842
Validation loss: 2.174264152844747

Epoch: 6| Step: 11
Training loss: 2.1447830200195312
Validation loss: 2.195614278316498

Epoch: 6| Step: 12
Training loss: 2.5976507663726807
Validation loss: 2.171000599861145

Epoch: 6| Step: 13
Training loss: 1.7838037014007568
Validation loss: 2.206906239191691

Epoch: 12| Step: 0
Training loss: 1.5853049755096436
Validation loss: 2.1788019935290017

Epoch: 6| Step: 1
Training loss: 2.127467632293701
Validation loss: 2.1913567980130515

Epoch: 6| Step: 2
Training loss: 2.1487927436828613
Validation loss: 2.197298447291056

Epoch: 6| Step: 3
Training loss: 2.910202980041504
Validation loss: 2.1860156655311584

Epoch: 6| Step: 4
Training loss: 1.640944480895996
Validation loss: 2.1845313707987466

Epoch: 6| Step: 5
Training loss: 2.1218106746673584
Validation loss: 2.176959832509359

Epoch: 6| Step: 6
Training loss: 2.121408700942993
Validation loss: 2.19680392742157

Epoch: 6| Step: 7
Training loss: 2.1300864219665527
Validation loss: 2.19469161828359

Epoch: 6| Step: 8
Training loss: 2.0562734603881836
Validation loss: 2.1746309796969094

Epoch: 6| Step: 9
Training loss: 2.2144501209259033
Validation loss: 2.1861202716827393

Epoch: 6| Step: 10
Training loss: 1.6696217060089111
Validation loss: 2.180650254090627

Epoch: 6| Step: 11
Training loss: 1.8137286901474
Validation loss: 2.2048522432645163

Epoch: 6| Step: 12
Training loss: 2.5413007736206055
Validation loss: 2.195725599924723

Epoch: 6| Step: 13
Training loss: 2.316570520401001
Validation loss: 2.189072767893473

Epoch: 13| Step: 0
Training loss: 1.6808741092681885
Validation loss: 2.16265074412028

Epoch: 6| Step: 1
Training loss: 1.5917792320251465
Validation loss: 2.184953272342682

Epoch: 6| Step: 2
Training loss: 1.7505548000335693
Validation loss: 2.2092734376589456

Epoch: 6| Step: 3
Training loss: 1.9278900623321533
Validation loss: 2.1932186285654702

Epoch: 6| Step: 4
Training loss: 2.199414014816284
Validation loss: 2.17634109656016

Epoch: 6| Step: 5
Training loss: 1.9298040866851807
Validation loss: 2.1978675524393716

Epoch: 6| Step: 6
Training loss: 1.7810108661651611
Validation loss: 2.186626354853312

Epoch: 6| Step: 7
Training loss: 2.048051357269287
Validation loss: 2.190481503804525

Epoch: 6| Step: 8
Training loss: 3.323577880859375
Validation loss: 2.1814095179239907

Epoch: 6| Step: 9
Training loss: 2.811697006225586
Validation loss: 2.1993620793024697

Epoch: 6| Step: 10
Training loss: 2.038299560546875
Validation loss: 2.1868388652801514

Epoch: 6| Step: 11
Training loss: 1.6391551494598389
Validation loss: 2.1840039094289145

Epoch: 6| Step: 12
Training loss: 2.6433968544006348
Validation loss: 2.158129632472992

Epoch: 6| Step: 13
Training loss: 2.462144613265991
Validation loss: 2.185289482275645

Epoch: 14| Step: 0
Training loss: 2.1228909492492676
Validation loss: 2.1826257507006326

Epoch: 6| Step: 1
Training loss: 2.9447388648986816
Validation loss: 2.1921297709147134

Epoch: 6| Step: 2
Training loss: 1.9697097539901733
Validation loss: 2.159940262635549

Epoch: 6| Step: 3
Training loss: 2.5740389823913574
Validation loss: 2.183711210886637

Epoch: 6| Step: 4
Training loss: 1.620900273323059
Validation loss: 2.1772998174031577

Epoch: 6| Step: 5
Training loss: 2.3869595527648926
Validation loss: 2.1657849550247192

Epoch: 6| Step: 6
Training loss: 1.9913883209228516
Validation loss: 2.1658875147501626

Epoch: 6| Step: 7
Training loss: 2.3641672134399414
Validation loss: 2.1788644591967263

Epoch: 6| Step: 8
Training loss: 1.6972932815551758
Validation loss: 2.178223411242167

Epoch: 6| Step: 9
Training loss: 2.1147849559783936
Validation loss: 2.174428482850393

Epoch: 6| Step: 10
Training loss: 1.7776448726654053
Validation loss: 2.1846774419148765

Epoch: 6| Step: 11
Training loss: 1.711808204650879
Validation loss: 2.173092166582743

Epoch: 6| Step: 12
Training loss: 2.0345749855041504
Validation loss: 2.171314756075541

Epoch: 6| Step: 13
Training loss: 2.014730215072632
Validation loss: 2.1696109771728516

Epoch: 15| Step: 0
Training loss: 2.0379269123077393
Validation loss: 2.1787944436073303

Epoch: 6| Step: 1
Training loss: 2.7703909873962402
Validation loss: 2.1816197832425437

Epoch: 6| Step: 2
Training loss: 2.199191093444824
Validation loss: 2.1699388225873313

Epoch: 6| Step: 3
Training loss: 1.76279616355896
Validation loss: 2.1655855973561606

Epoch: 6| Step: 4
Training loss: 1.5840826034545898
Validation loss: 2.1797067523002625

Epoch: 6| Step: 5
Training loss: 2.221611976623535
Validation loss: 2.1880035599072776

Epoch: 6| Step: 6
Training loss: 1.7846137285232544
Validation loss: 2.169655740261078

Epoch: 6| Step: 7
Training loss: 1.7754764556884766
Validation loss: 2.186129013697306

Epoch: 6| Step: 8
Training loss: 1.3983969688415527
Validation loss: 2.191344658533732

Epoch: 6| Step: 9
Training loss: 2.9390175342559814
Validation loss: 2.194514354070028

Epoch: 6| Step: 10
Training loss: 2.8323142528533936
Validation loss: 2.2006579637527466

Epoch: 6| Step: 11
Training loss: 2.094888210296631
Validation loss: 2.1792655189832053

Epoch: 6| Step: 12
Training loss: 1.8804346323013306
Validation loss: 2.1986622412999473

Epoch: 6| Step: 13
Training loss: 2.0543558597564697
Validation loss: 2.195386449495951

Epoch: 16| Step: 0
Training loss: 1.866363763809204
Validation loss: 2.211525022983551

Epoch: 6| Step: 1
Training loss: 2.389796257019043
Validation loss: 2.147669712702433

Epoch: 6| Step: 2
Training loss: 1.5223948955535889
Validation loss: 2.1684446334838867

Epoch: 6| Step: 3
Training loss: 2.51035737991333
Validation loss: 2.178808073202769

Epoch: 6| Step: 4
Training loss: 1.5809170007705688
Validation loss: 2.1728145480155945

Epoch: 6| Step: 5
Training loss: 1.589191198348999
Validation loss: 2.1622716188430786

Epoch: 6| Step: 6
Training loss: 1.9340553283691406
Validation loss: 2.18533448378245

Epoch: 6| Step: 7
Training loss: 1.8506003618240356
Validation loss: 2.165545662244161

Epoch: 6| Step: 8
Training loss: 2.276500701904297
Validation loss: 2.1636101404825845

Epoch: 6| Step: 9
Training loss: 3.034811019897461
Validation loss: 2.176848848660787

Epoch: 6| Step: 10
Training loss: 2.5038816928863525
Validation loss: 2.178060531616211

Epoch: 6| Step: 11
Training loss: 2.626552104949951
Validation loss: 2.172439932823181

Epoch: 6| Step: 12
Training loss: 1.5310871601104736
Validation loss: 2.1417100628217063

Epoch: 6| Step: 13
Training loss: 1.9614537954330444
Validation loss: 2.1814347902933755

Epoch: 17| Step: 0
Training loss: 2.0552048683166504
Validation loss: 2.157802720864614

Epoch: 6| Step: 1
Training loss: 1.7866714000701904
Validation loss: 2.170164485772451

Epoch: 6| Step: 2
Training loss: 2.1646437644958496
Validation loss: 2.187817851702372

Epoch: 6| Step: 3
Training loss: 1.608955979347229
Validation loss: 2.1592884063720703

Epoch: 6| Step: 4
Training loss: 1.9042534828186035
Validation loss: 2.1820648511250815

Epoch: 6| Step: 5
Training loss: 2.0143113136291504
Validation loss: 2.189284086227417

Epoch: 6| Step: 6
Training loss: 2.505021095275879
Validation loss: 2.1628184715906777

Epoch: 6| Step: 7
Training loss: 1.951432704925537
Validation loss: 2.1636938651402793

Epoch: 6| Step: 8
Training loss: 1.4522762298583984
Validation loss: 2.1613940795262656

Epoch: 6| Step: 9
Training loss: 3.056954860687256
Validation loss: 2.178034484386444

Epoch: 6| Step: 10
Training loss: 2.3543336391448975
Validation loss: 2.138413449128469

Epoch: 6| Step: 11
Training loss: 1.8574721813201904
Validation loss: 2.1675060192743936

Epoch: 6| Step: 12
Training loss: 2.402716636657715
Validation loss: 2.1702335278193154

Epoch: 6| Step: 13
Training loss: 2.1538379192352295
Validation loss: 2.152374267578125

Epoch: 18| Step: 0
Training loss: 1.7787902355194092
Validation loss: 2.1752411127090454

Epoch: 6| Step: 1
Training loss: 1.4353809356689453
Validation loss: 2.1534913778305054

Epoch: 6| Step: 2
Training loss: 2.600928783416748
Validation loss: 2.1812129418055215

Epoch: 6| Step: 3
Training loss: 1.9227674007415771
Validation loss: 2.1680524945259094

Epoch: 6| Step: 4
Training loss: 2.2520391941070557
Validation loss: 2.1867677569389343

Epoch: 6| Step: 5
Training loss: 2.588160514831543
Validation loss: 2.1839331785837808

Epoch: 6| Step: 6
Training loss: 2.543689250946045
Validation loss: 2.1576118071873984

Epoch: 6| Step: 7
Training loss: 1.8820370435714722
Validation loss: 2.178637067476908

Epoch: 6| Step: 8
Training loss: 2.1928367614746094
Validation loss: 2.192797601222992

Epoch: 6| Step: 9
Training loss: 2.0963077545166016
Validation loss: 2.1781858801841736

Epoch: 6| Step: 10
Training loss: 1.5851564407348633
Validation loss: 2.154963731765747

Epoch: 6| Step: 11
Training loss: 1.9943809509277344
Validation loss: 2.1495364904403687

Epoch: 6| Step: 12
Training loss: 2.613025426864624
Validation loss: 2.1581945021947226

Epoch: 6| Step: 13
Training loss: 1.7880672216415405
Validation loss: 2.157434562842051

Epoch: 19| Step: 0
Training loss: 2.5744521617889404
Validation loss: 2.1837528546651206

Epoch: 6| Step: 1
Training loss: 1.7225127220153809
Validation loss: 2.13827516635259

Epoch: 6| Step: 2
Training loss: 2.084190607070923
Validation loss: 2.152227242787679

Epoch: 6| Step: 3
Training loss: 1.7836277484893799
Validation loss: 2.1746639013290405

Epoch: 6| Step: 4
Training loss: 2.583343982696533
Validation loss: 2.133672614892324

Epoch: 6| Step: 5
Training loss: 1.8714942932128906
Validation loss: 2.1234887639681497

Epoch: 6| Step: 6
Training loss: 1.888676643371582
Validation loss: 2.1264673471450806

Epoch: 6| Step: 7
Training loss: 1.822320818901062
Validation loss: 2.160867432753245

Epoch: 6| Step: 8
Training loss: 1.8084051609039307
Validation loss: 2.1406250993410745

Epoch: 6| Step: 9
Training loss: 2.588128089904785
Validation loss: 2.1359157959620156

Epoch: 6| Step: 10
Training loss: 2.2111029624938965
Validation loss: 2.130346715450287

Epoch: 6| Step: 11
Training loss: 2.334843873977661
Validation loss: 2.153656244277954

Epoch: 6| Step: 12
Training loss: 1.821690320968628
Validation loss: 2.130952556927999

Epoch: 6| Step: 13
Training loss: 1.9302043914794922
Validation loss: 2.1588435769081116

Epoch: 20| Step: 0
Training loss: 1.5305099487304688
Validation loss: 2.1602585911750793

Epoch: 6| Step: 1
Training loss: 2.107522964477539
Validation loss: 2.14132422208786

Epoch: 6| Step: 2
Training loss: 2.4160244464874268
Validation loss: 2.1415549317995706

Epoch: 6| Step: 3
Training loss: 1.7541377544403076
Validation loss: 2.1475658218065896

Epoch: 6| Step: 4
Training loss: 1.8925036191940308
Validation loss: 2.1525014837582908

Epoch: 6| Step: 5
Training loss: 2.6699252128601074
Validation loss: 2.1606649359067283

Epoch: 6| Step: 6
Training loss: 1.5747441053390503
Validation loss: 2.1459258993466697

Epoch: 6| Step: 7
Training loss: 2.049553871154785
Validation loss: 2.158440669377645

Epoch: 6| Step: 8
Training loss: 2.3673768043518066
Validation loss: 2.1248632868131003

Epoch: 6| Step: 9
Training loss: 2.504146099090576
Validation loss: 2.1430936058362327

Epoch: 6| Step: 10
Training loss: 1.9381062984466553
Validation loss: 2.159355044364929

Epoch: 6| Step: 11
Training loss: 1.215101718902588
Validation loss: 2.133518556753794

Epoch: 6| Step: 12
Training loss: 2.5425541400909424
Validation loss: 2.13263205687205

Epoch: 6| Step: 13
Training loss: 2.3132753372192383
Validation loss: 2.135424017906189

Epoch: 21| Step: 0
Training loss: 2.0242748260498047
Validation loss: 2.156169891357422

Epoch: 6| Step: 1
Training loss: 2.0434346199035645
Validation loss: 2.138950745264689

Epoch: 6| Step: 2
Training loss: 2.048121452331543
Validation loss: 2.1303603450457254

Epoch: 6| Step: 3
Training loss: 1.9957482814788818
Validation loss: 2.1400105953216553

Epoch: 6| Step: 4
Training loss: 1.6529886722564697
Validation loss: 2.147596776485443

Epoch: 6| Step: 5
Training loss: 1.5586645603179932
Validation loss: 2.135197858015696

Epoch: 6| Step: 6
Training loss: 2.4943575859069824
Validation loss: 2.1512547930081687

Epoch: 6| Step: 7
Training loss: 1.6757186651229858
Validation loss: 2.132600704828898

Epoch: 6| Step: 8
Training loss: 1.423596978187561
Validation loss: 2.1229599118232727

Epoch: 6| Step: 9
Training loss: 2.5953383445739746
Validation loss: 2.1316951314608255

Epoch: 6| Step: 10
Training loss: 2.1060009002685547
Validation loss: 2.1468718846639

Epoch: 6| Step: 11
Training loss: 2.662252426147461
Validation loss: 2.143555005391439

Epoch: 6| Step: 12
Training loss: 1.8884719610214233
Validation loss: 2.1377011140187583

Epoch: 6| Step: 13
Training loss: 2.634756088256836
Validation loss: 2.161433696746826

Epoch: 22| Step: 0
Training loss: 2.1276931762695312
Validation loss: 2.12326314051946

Epoch: 6| Step: 1
Training loss: 2.174144744873047
Validation loss: 2.143904527028402

Epoch: 6| Step: 2
Training loss: 1.487941026687622
Validation loss: 2.1373983224232993

Epoch: 6| Step: 3
Training loss: 2.257119655609131
Validation loss: 2.1568662524223328

Epoch: 6| Step: 4
Training loss: 2.1894309520721436
Validation loss: 2.1436747908592224

Epoch: 6| Step: 5
Training loss: 2.1616718769073486
Validation loss: 2.1207185983657837

Epoch: 6| Step: 6
Training loss: 2.3814172744750977
Validation loss: 2.1277223229408264

Epoch: 6| Step: 7
Training loss: 2.245999574661255
Validation loss: 2.1381521423657737

Epoch: 6| Step: 8
Training loss: 1.5453914403915405
Validation loss: 2.1456110080083213

Epoch: 6| Step: 9
Training loss: 1.784778356552124
Validation loss: 2.1338294545809426

Epoch: 6| Step: 10
Training loss: 2.5371804237365723
Validation loss: 2.123067259788513

Epoch: 6| Step: 11
Training loss: 1.773571491241455
Validation loss: 2.1305622855822244

Epoch: 6| Step: 12
Training loss: 2.4288134574890137
Validation loss: 2.1496317783991494

Epoch: 6| Step: 13
Training loss: 1.3363893032073975
Validation loss: 2.1343259612719216

Epoch: 23| Step: 0
Training loss: 2.1937670707702637
Validation loss: 2.1499006152153015

Epoch: 6| Step: 1
Training loss: 2.5040488243103027
Validation loss: 2.12821231285731

Epoch: 6| Step: 2
Training loss: 2.0113911628723145
Validation loss: 2.131532907485962

Epoch: 6| Step: 3
Training loss: 1.7976001501083374
Validation loss: 2.1410653988520303

Epoch: 6| Step: 4
Training loss: 2.4314498901367188
Validation loss: 2.151515026887258

Epoch: 6| Step: 5
Training loss: 2.4503226280212402
Validation loss: 2.1387922167778015

Epoch: 6| Step: 6
Training loss: 1.7636321783065796
Validation loss: 2.151177247365316

Epoch: 6| Step: 7
Training loss: 1.683795690536499
Validation loss: 2.125595490137736

Epoch: 6| Step: 8
Training loss: 1.9736278057098389
Validation loss: 2.1285385489463806

Epoch: 6| Step: 9
Training loss: 1.9778295755386353
Validation loss: 2.1279295285542807

Epoch: 6| Step: 10
Training loss: 1.9348057508468628
Validation loss: 2.1249663631121316

Epoch: 6| Step: 11
Training loss: 1.811553955078125
Validation loss: 2.1361564993858337

Epoch: 6| Step: 12
Training loss: 1.8313645124435425
Validation loss: 2.1329084436098733

Epoch: 6| Step: 13
Training loss: 2.458740234375
Validation loss: 2.1165533860524497

Epoch: 24| Step: 0
Training loss: 1.7317402362823486
Validation loss: 2.1216693123181662

Epoch: 6| Step: 1
Training loss: 2.055035352706909
Validation loss: 2.1364160577456155

Epoch: 6| Step: 2
Training loss: 2.6130943298339844
Validation loss: 2.1323754588762918

Epoch: 6| Step: 3
Training loss: 1.7769742012023926
Validation loss: 2.124915679295858

Epoch: 6| Step: 4
Training loss: 2.821788787841797
Validation loss: 2.0976760188738504

Epoch: 6| Step: 5
Training loss: 2.0212790966033936
Validation loss: 2.11985844373703

Epoch: 6| Step: 6
Training loss: 1.2021026611328125
Validation loss: 2.095623711744944

Epoch: 6| Step: 7
Training loss: 2.0984725952148438
Validation loss: 2.112612326939901

Epoch: 6| Step: 8
Training loss: 1.8031988143920898
Validation loss: 2.12559050321579

Epoch: 6| Step: 9
Training loss: 1.7398295402526855
Validation loss: 2.131875534852346

Epoch: 6| Step: 10
Training loss: 2.5928125381469727
Validation loss: 2.134378174940745

Epoch: 6| Step: 11
Training loss: 1.9998704195022583
Validation loss: 2.1311490535736084

Epoch: 6| Step: 12
Training loss: 1.836833119392395
Validation loss: 2.0963985522588096

Epoch: 6| Step: 13
Training loss: 2.377347946166992
Validation loss: 2.1259570717811584

Epoch: 25| Step: 0
Training loss: 2.185375213623047
Validation loss: 2.121114452679952

Epoch: 6| Step: 1
Training loss: 2.320140838623047
Validation loss: 2.107884148756663

Epoch: 6| Step: 2
Training loss: 2.245532989501953
Validation loss: 2.1277222633361816

Epoch: 6| Step: 3
Training loss: 2.4039056301116943
Validation loss: 2.1135069926579795

Epoch: 6| Step: 4
Training loss: 1.5389838218688965
Validation loss: 2.1142905354499817

Epoch: 6| Step: 5
Training loss: 2.0768423080444336
Validation loss: 2.1202696561813354

Epoch: 6| Step: 6
Training loss: 1.5876840353012085
Validation loss: 2.13539586464564

Epoch: 6| Step: 7
Training loss: 1.6673707962036133
Validation loss: 2.1179773608843484

Epoch: 6| Step: 8
Training loss: 1.681419849395752
Validation loss: 2.1124670108159385

Epoch: 6| Step: 9
Training loss: 1.72749662399292
Validation loss: 2.104095538457235

Epoch: 6| Step: 10
Training loss: 2.9542946815490723
Validation loss: 2.115221838156382

Epoch: 6| Step: 11
Training loss: 2.035336494445801
Validation loss: 2.1116188168525696

Epoch: 6| Step: 12
Training loss: 1.7886995077133179
Validation loss: 2.1295203963915506

Epoch: 6| Step: 13
Training loss: 2.3447718620300293
Validation loss: 2.124234596888224

Epoch: 26| Step: 0
Training loss: 2.1023621559143066
Validation loss: 2.105806549390157

Epoch: 6| Step: 1
Training loss: 2.3753485679626465
Validation loss: 2.120107372601827

Epoch: 6| Step: 2
Training loss: 2.1432085037231445
Validation loss: 2.1063849131266275

Epoch: 6| Step: 3
Training loss: 1.6664648056030273
Validation loss: 2.1358800331751504

Epoch: 6| Step: 4
Training loss: 2.681532382965088
Validation loss: 2.138213495413462

Epoch: 6| Step: 5
Training loss: 2.547088146209717
Validation loss: 2.1441803574562073

Epoch: 6| Step: 6
Training loss: 2.5125415325164795
Validation loss: 2.164297660191854

Epoch: 6| Step: 7
Training loss: 1.696058988571167
Validation loss: 2.1565584739049277

Epoch: 6| Step: 8
Training loss: 1.9829213619232178
Validation loss: 2.166891356309255

Epoch: 6| Step: 9
Training loss: 1.6620522737503052
Validation loss: 2.1417823433876038

Epoch: 6| Step: 10
Training loss: 1.6209344863891602
Validation loss: 2.1165624260902405

Epoch: 6| Step: 11
Training loss: 1.9734832048416138
Validation loss: 2.1156665484110513

Epoch: 6| Step: 12
Training loss: 1.9770606756210327
Validation loss: 2.1301404436429343

Epoch: 6| Step: 13
Training loss: 1.9958043098449707
Validation loss: 2.13368421792984

Epoch: 27| Step: 0
Training loss: 1.5734035968780518
Validation loss: 2.120846231778463

Epoch: 6| Step: 1
Training loss: 1.92875337600708
Validation loss: 2.114256123701731

Epoch: 6| Step: 2
Training loss: 2.059469699859619
Validation loss: 2.102240284283956

Epoch: 6| Step: 3
Training loss: 2.0426621437072754
Validation loss: 2.1091894706090293

Epoch: 6| Step: 4
Training loss: 2.22712779045105
Validation loss: 2.102536956469218

Epoch: 6| Step: 5
Training loss: 2.456480026245117
Validation loss: 2.105772376060486

Epoch: 6| Step: 6
Training loss: 1.8536834716796875
Validation loss: 2.11055721839269

Epoch: 6| Step: 7
Training loss: 2.6438608169555664
Validation loss: 2.1436819632848105

Epoch: 6| Step: 8
Training loss: 2.4275918006896973
Validation loss: 2.110548973083496

Epoch: 6| Step: 9
Training loss: 2.3100481033325195
Validation loss: 2.1366345485051474

Epoch: 6| Step: 10
Training loss: 1.747468113899231
Validation loss: 2.1280542413393655

Epoch: 6| Step: 11
Training loss: 2.098367929458618
Validation loss: 2.0892160336176553

Epoch: 6| Step: 12
Training loss: 1.4685767889022827
Validation loss: 2.0938252210617065

Epoch: 6| Step: 13
Training loss: 1.5793770551681519
Validation loss: 2.114844044049581

Epoch: 28| Step: 0
Training loss: 2.393817901611328
Validation loss: 2.0944900512695312

Epoch: 6| Step: 1
Training loss: 1.876768946647644
Validation loss: 2.12324450413386

Epoch: 6| Step: 2
Training loss: 1.3758416175842285
Validation loss: 2.1182335217793784

Epoch: 6| Step: 3
Training loss: 2.0069360733032227
Validation loss: 2.1111207405726113

Epoch: 6| Step: 4
Training loss: 2.061469554901123
Validation loss: 2.1269178986549377

Epoch: 6| Step: 5
Training loss: 2.262596368789673
Validation loss: 2.0902278224627175

Epoch: 6| Step: 6
Training loss: 1.5426907539367676
Validation loss: 2.113716165224711

Epoch: 6| Step: 7
Training loss: 1.9153103828430176
Validation loss: 2.0926953752835593

Epoch: 6| Step: 8
Training loss: 2.6847832202911377
Validation loss: 2.125644266605377

Epoch: 6| Step: 9
Training loss: 2.1234307289123535
Validation loss: 2.119873523712158

Epoch: 6| Step: 10
Training loss: 2.63323974609375
Validation loss: 2.1182210445404053

Epoch: 6| Step: 11
Training loss: 1.7715649604797363
Validation loss: 2.1237642566363015

Epoch: 6| Step: 12
Training loss: 2.1617696285247803
Validation loss: 2.10691370566686

Epoch: 6| Step: 13
Training loss: 1.4606602191925049
Validation loss: 2.1083601315816245

Epoch: 29| Step: 0
Training loss: 2.467846393585205
Validation loss: 2.1067914366722107

Epoch: 6| Step: 1
Training loss: 1.717911720275879
Validation loss: 2.095079759756724

Epoch: 6| Step: 2
Training loss: 2.3837366104125977
Validation loss: 2.087050278981527

Epoch: 6| Step: 3
Training loss: 2.0565738677978516
Validation loss: 2.078677773475647

Epoch: 6| Step: 4
Training loss: 2.1432173252105713
Validation loss: 2.095706065495809

Epoch: 6| Step: 5
Training loss: 1.9702060222625732
Validation loss: 2.0992164810498557

Epoch: 6| Step: 6
Training loss: 2.1059107780456543
Validation loss: 2.0848904053370156

Epoch: 6| Step: 7
Training loss: 1.6067955493927002
Validation loss: 2.0971054434776306

Epoch: 6| Step: 8
Training loss: 1.9834909439086914
Validation loss: 2.1100839972496033

Epoch: 6| Step: 9
Training loss: 1.9478600025177002
Validation loss: 2.106076101462046

Epoch: 6| Step: 10
Training loss: 1.9351708889007568
Validation loss: 2.0923343102137246

Epoch: 6| Step: 11
Training loss: 1.393027901649475
Validation loss: 2.086431622505188

Epoch: 6| Step: 12
Training loss: 1.9966983795166016
Validation loss: 2.094981928666433

Epoch: 6| Step: 13
Training loss: 2.467038154602051
Validation loss: 2.1050134102503457

Epoch: 30| Step: 0
Training loss: 1.5001074075698853
Validation loss: 2.108062982559204

Epoch: 6| Step: 1
Training loss: 2.516275405883789
Validation loss: 2.10307768980662

Epoch: 6| Step: 2
Training loss: 1.372171401977539
Validation loss: 2.094053268432617

Epoch: 6| Step: 3
Training loss: 2.3890573978424072
Validation loss: 2.0944848457972207

Epoch: 6| Step: 4
Training loss: 2.7759015560150146
Validation loss: 2.0992828607559204

Epoch: 6| Step: 5
Training loss: 2.207998514175415
Validation loss: 2.1022658745447793

Epoch: 6| Step: 6
Training loss: 1.5946533679962158
Validation loss: 2.082921048005422

Epoch: 6| Step: 7
Training loss: 2.5427722930908203
Validation loss: 2.071720023949941

Epoch: 6| Step: 8
Training loss: 1.9209351539611816
Validation loss: 2.1027076045672097

Epoch: 6| Step: 9
Training loss: 1.7780293226242065
Validation loss: 2.095183869202932

Epoch: 6| Step: 10
Training loss: 1.9830996990203857
Validation loss: 2.0865378777186074

Epoch: 6| Step: 11
Training loss: 1.5806964635849
Validation loss: 2.098876416683197

Epoch: 6| Step: 12
Training loss: 1.9431123733520508
Validation loss: 2.0579907496770224

Epoch: 6| Step: 13
Training loss: 2.041454315185547
Validation loss: 2.081384619077047

Epoch: 31| Step: 0
Training loss: 1.6601483821868896
Validation loss: 2.0963314970334372

Epoch: 6| Step: 1
Training loss: 1.3982270956039429
Validation loss: 2.11343381802241

Epoch: 6| Step: 2
Training loss: 2.0604653358459473
Validation loss: 2.107403119405111

Epoch: 6| Step: 3
Training loss: 2.3557374477386475
Validation loss: 2.0813919504483542

Epoch: 6| Step: 4
Training loss: 2.2325379848480225
Validation loss: 2.1070391138394675

Epoch: 6| Step: 5
Training loss: 1.7337270975112915
Validation loss: 2.090515971183777

Epoch: 6| Step: 6
Training loss: 2.1849639415740967
Validation loss: 2.0773020585378013

Epoch: 6| Step: 7
Training loss: 2.0721466541290283
Validation loss: 2.0931084156036377

Epoch: 6| Step: 8
Training loss: 1.7477080821990967
Validation loss: 2.0692289670308432

Epoch: 6| Step: 9
Training loss: 1.713768720626831
Validation loss: 2.1004347801208496

Epoch: 6| Step: 10
Training loss: 2.0562903881073
Validation loss: 2.103101968765259

Epoch: 6| Step: 11
Training loss: 2.204296112060547
Validation loss: 2.0837891697883606

Epoch: 6| Step: 12
Training loss: 2.594115734100342
Validation loss: 2.0950618584950766

Epoch: 6| Step: 13
Training loss: 1.8882808685302734
Validation loss: 2.096331159273783

Epoch: 32| Step: 0
Training loss: 1.9169942140579224
Validation loss: 2.104762017726898

Epoch: 6| Step: 1
Training loss: 2.0422768592834473
Validation loss: 2.072253942489624

Epoch: 6| Step: 2
Training loss: 1.7797317504882812
Validation loss: 2.072209139664968

Epoch: 6| Step: 3
Training loss: 3.001340389251709
Validation loss: 2.0899851520856223

Epoch: 6| Step: 4
Training loss: 1.8507065773010254
Validation loss: 2.095392386118571

Epoch: 6| Step: 5
Training loss: 2.2300291061401367
Validation loss: 2.0758743484814963

Epoch: 6| Step: 6
Training loss: 1.9853827953338623
Validation loss: 2.081280211607615

Epoch: 6| Step: 7
Training loss: 1.5877363681793213
Validation loss: 2.0957217812538147

Epoch: 6| Step: 8
Training loss: 2.1984570026397705
Validation loss: 2.1027468840281167

Epoch: 6| Step: 9
Training loss: 2.5198814868927
Validation loss: 2.0870757500330606

Epoch: 6| Step: 10
Training loss: 1.2853940725326538
Validation loss: 2.0856674909591675

Epoch: 6| Step: 11
Training loss: 2.034407138824463
Validation loss: 2.1053211092948914

Epoch: 6| Step: 12
Training loss: 1.8514000177383423
Validation loss: 2.080967962741852

Epoch: 6| Step: 13
Training loss: 1.9047596454620361
Validation loss: 2.0788373152414956

Epoch: 33| Step: 0
Training loss: 2.453702211380005
Validation loss: 2.078863481680552

Epoch: 6| Step: 1
Training loss: 2.268435478210449
Validation loss: 2.0624366402626038

Epoch: 6| Step: 2
Training loss: 1.8816413879394531
Validation loss: 2.076342761516571

Epoch: 6| Step: 3
Training loss: 2.2049875259399414
Validation loss: 2.0833370089530945

Epoch: 6| Step: 4
Training loss: 2.06976318359375
Validation loss: 2.0921385685602822

Epoch: 6| Step: 5
Training loss: 1.9544296264648438
Validation loss: 2.0880622069040933

Epoch: 6| Step: 6
Training loss: 1.8821234703063965
Validation loss: 2.0963516434033713

Epoch: 6| Step: 7
Training loss: 2.025984764099121
Validation loss: 2.108888586362203

Epoch: 6| Step: 8
Training loss: 1.3412046432495117
Validation loss: 2.095534086227417

Epoch: 6| Step: 9
Training loss: 1.2346111536026
Validation loss: 2.1082377433776855

Epoch: 6| Step: 10
Training loss: 2.5192573070526123
Validation loss: 2.083132346471151

Epoch: 6| Step: 11
Training loss: 1.6663117408752441
Validation loss: 2.0720461209615073

Epoch: 6| Step: 12
Training loss: 2.20096755027771
Validation loss: 2.077585975329081

Epoch: 6| Step: 13
Training loss: 2.7310757637023926
Validation loss: 2.114915986855825

Epoch: 34| Step: 0
Training loss: 1.90387761592865
Validation loss: 2.0991977055867515

Epoch: 6| Step: 1
Training loss: 1.9301356077194214
Validation loss: 2.096757173538208

Epoch: 6| Step: 2
Training loss: 1.539371132850647
Validation loss: 2.0876277089118958

Epoch: 6| Step: 3
Training loss: 2.1011440753936768
Validation loss: 2.0987940430641174

Epoch: 6| Step: 4
Training loss: 2.1074905395507812
Validation loss: 2.1201252738634744

Epoch: 6| Step: 5
Training loss: 1.6453005075454712
Validation loss: 2.0975646575291953

Epoch: 6| Step: 6
Training loss: 1.8387727737426758
Validation loss: 2.117555618286133

Epoch: 6| Step: 7
Training loss: 1.9365453720092773
Validation loss: 2.0952193339665732

Epoch: 6| Step: 8
Training loss: 3.04054594039917
Validation loss: 2.0846660137176514

Epoch: 6| Step: 9
Training loss: 2.03065824508667
Validation loss: 2.060694416364034

Epoch: 6| Step: 10
Training loss: 2.5061402320861816
Validation loss: 2.078192949295044

Epoch: 6| Step: 11
Training loss: 1.523007869720459
Validation loss: 2.0953577359517417

Epoch: 6| Step: 12
Training loss: 1.6249260902404785
Validation loss: 2.061130185921987

Epoch: 6| Step: 13
Training loss: 2.2456021308898926
Validation loss: 2.079433798789978

Epoch: 35| Step: 0
Training loss: 2.319150686264038
Validation loss: 2.0740625460942588

Epoch: 6| Step: 1
Training loss: 1.987666368484497
Validation loss: 2.0746513406435647

Epoch: 6| Step: 2
Training loss: 1.6560646295547485
Validation loss: 2.104905446370443

Epoch: 6| Step: 3
Training loss: 2.2219393253326416
Validation loss: 2.0943734844525657

Epoch: 6| Step: 4
Training loss: 2.0656838417053223
Validation loss: 2.0833354592323303

Epoch: 6| Step: 5
Training loss: 1.5790905952453613
Validation loss: 2.0799224177996316

Epoch: 6| Step: 6
Training loss: 2.6859095096588135
Validation loss: 2.1008932987848916

Epoch: 6| Step: 7
Training loss: 1.8820981979370117
Validation loss: 2.0579792261123657

Epoch: 6| Step: 8
Training loss: 1.7650878429412842
Validation loss: 2.0535643100738525

Epoch: 6| Step: 9
Training loss: 1.8567352294921875
Validation loss: 2.0813769896825156

Epoch: 6| Step: 10
Training loss: 1.7975878715515137
Validation loss: 2.0896973411242166

Epoch: 6| Step: 11
Training loss: 1.2526443004608154
Validation loss: 2.0772133270899453

Epoch: 6| Step: 12
Training loss: 2.343608856201172
Validation loss: 2.0767791668574014

Epoch: 6| Step: 13
Training loss: 2.7343711853027344
Validation loss: 2.071641484896342

Epoch: 36| Step: 0
Training loss: 2.7373414039611816
Validation loss: 2.07559871673584

Epoch: 6| Step: 1
Training loss: 1.5524554252624512
Validation loss: 2.0914884209632874

Epoch: 6| Step: 2
Training loss: 2.0461418628692627
Validation loss: 2.095132847627004

Epoch: 6| Step: 3
Training loss: 1.852668285369873
Validation loss: 2.049185832341512

Epoch: 6| Step: 4
Training loss: 1.64625084400177
Validation loss: 2.0711251298586526

Epoch: 6| Step: 5
Training loss: 2.474090576171875
Validation loss: 2.0755093097686768

Epoch: 6| Step: 6
Training loss: 1.892432689666748
Validation loss: 2.083858092625936

Epoch: 6| Step: 7
Training loss: 1.5410206317901611
Validation loss: 2.0622735222180686

Epoch: 6| Step: 8
Training loss: 2.0111141204833984
Validation loss: 2.0815701683362327

Epoch: 6| Step: 9
Training loss: 2.1256978511810303
Validation loss: 2.09102855126063

Epoch: 6| Step: 10
Training loss: 2.5705060958862305
Validation loss: 2.081843098004659

Epoch: 6| Step: 11
Training loss: 1.7945228815078735
Validation loss: 2.101885418097178

Epoch: 6| Step: 12
Training loss: 1.5903968811035156
Validation loss: 2.1073420643806458

Epoch: 6| Step: 13
Training loss: 2.0934736728668213
Validation loss: 2.0966415405273438

Epoch: 37| Step: 0
Training loss: 2.170274257659912
Validation loss: 2.084644893805186

Epoch: 6| Step: 1
Training loss: 2.2262232303619385
Validation loss: 2.074512302875519

Epoch: 6| Step: 2
Training loss: 1.7843201160430908
Validation loss: 2.0810381174087524

Epoch: 6| Step: 3
Training loss: 2.0239405632019043
Validation loss: 2.0841959516207376

Epoch: 6| Step: 4
Training loss: 2.4303526878356934
Validation loss: 2.0674092769622803

Epoch: 6| Step: 5
Training loss: 2.0595717430114746
Validation loss: 2.0987671613693237

Epoch: 6| Step: 6
Training loss: 2.34537410736084
Validation loss: 2.103033185005188

Epoch: 6| Step: 7
Training loss: 1.971584677696228
Validation loss: 2.069281498591105

Epoch: 6| Step: 8
Training loss: 1.499125361442566
Validation loss: 2.0974894563357034

Epoch: 6| Step: 9
Training loss: 1.862459659576416
Validation loss: 2.071256955464681

Epoch: 6| Step: 10
Training loss: 2.0407838821411133
Validation loss: 2.087283809979757

Epoch: 6| Step: 11
Training loss: 1.3627922534942627
Validation loss: 2.073830306529999

Epoch: 6| Step: 12
Training loss: 2.487950086593628
Validation loss: 2.072606364885966

Epoch: 6| Step: 13
Training loss: 2.106929302215576
Validation loss: 2.0719980597496033

Epoch: 38| Step: 0
Training loss: 2.294739007949829
Validation loss: 2.061472992102305

Epoch: 6| Step: 1
Training loss: 2.4011294841766357
Validation loss: 2.0631614128748574

Epoch: 6| Step: 2
Training loss: 2.548999786376953
Validation loss: 2.1007007360458374

Epoch: 6| Step: 3
Training loss: 2.22288179397583
Validation loss: 2.0853296915690103

Epoch: 6| Step: 4
Training loss: 1.7571877241134644
Validation loss: 2.0941589872042337

Epoch: 6| Step: 5
Training loss: 2.534478187561035
Validation loss: 2.074227432409922

Epoch: 6| Step: 6
Training loss: 1.7263400554656982
Validation loss: 2.0680517156918845

Epoch: 6| Step: 7
Training loss: 2.0670158863067627
Validation loss: 2.096143444379171

Epoch: 6| Step: 8
Training loss: 1.6594936847686768
Validation loss: 2.0820277333259583

Epoch: 6| Step: 9
Training loss: 1.9021856784820557
Validation loss: 2.0896199146906533

Epoch: 6| Step: 10
Training loss: 1.9382483959197998
Validation loss: 2.0609036882718406

Epoch: 6| Step: 11
Training loss: 1.4799116849899292
Validation loss: 2.070316712061564

Epoch: 6| Step: 12
Training loss: 2.355634927749634
Validation loss: 2.0727398792902627

Epoch: 6| Step: 13
Training loss: 1.0883879661560059
Validation loss: 2.063066820303599

Epoch: 39| Step: 0
Training loss: 1.6784554719924927
Validation loss: 2.066295782725016

Epoch: 6| Step: 1
Training loss: 2.081310272216797
Validation loss: 2.0612942775090537

Epoch: 6| Step: 2
Training loss: 1.2806928157806396
Validation loss: 2.0733991662661233

Epoch: 6| Step: 3
Training loss: 1.9645442962646484
Validation loss: 2.1006561120351157

Epoch: 6| Step: 4
Training loss: 2.1698055267333984
Validation loss: 2.035971522331238

Epoch: 6| Step: 5
Training loss: 2.525801181793213
Validation loss: 2.0703418056170144

Epoch: 6| Step: 6
Training loss: 2.137951612472534
Validation loss: 2.07058839003245

Epoch: 6| Step: 7
Training loss: 2.2942349910736084
Validation loss: 2.0588366985321045

Epoch: 6| Step: 8
Training loss: 1.4683115482330322
Validation loss: 2.0591389735539756

Epoch: 6| Step: 9
Training loss: 2.540499448776245
Validation loss: 2.070748448371887

Epoch: 6| Step: 10
Training loss: 2.0075230598449707
Validation loss: 2.0637118816375732

Epoch: 6| Step: 11
Training loss: 1.569586992263794
Validation loss: 2.060433030128479

Epoch: 6| Step: 12
Training loss: 1.62075674533844
Validation loss: 2.064110577106476

Epoch: 6| Step: 13
Training loss: 2.4777164459228516
Validation loss: 2.0907493432362876

Epoch: 40| Step: 0
Training loss: 1.438124656677246
Validation loss: 2.0617045164108276

Epoch: 6| Step: 1
Training loss: 1.4434102773666382
Validation loss: 2.067492365837097

Epoch: 6| Step: 2
Training loss: 1.4313831329345703
Validation loss: 2.0637646913528442

Epoch: 6| Step: 3
Training loss: 3.0948922634124756
Validation loss: 2.0650095542271933

Epoch: 6| Step: 4
Training loss: 1.8907850980758667
Validation loss: 2.0782851775487265

Epoch: 6| Step: 5
Training loss: 2.3545498847961426
Validation loss: 2.0422375996907554

Epoch: 6| Step: 6
Training loss: 1.84617280960083
Validation loss: 2.060079296429952

Epoch: 6| Step: 7
Training loss: 2.0761091709136963
Validation loss: 2.0794073144594827

Epoch: 6| Step: 8
Training loss: 1.633712649345398
Validation loss: 2.0796628991762796

Epoch: 6| Step: 9
Training loss: 2.177748680114746
Validation loss: 2.0917440255482993

Epoch: 6| Step: 10
Training loss: 2.1918396949768066
Validation loss: 2.075836181640625

Epoch: 6| Step: 11
Training loss: 1.76369309425354
Validation loss: 2.0482385555903115

Epoch: 6| Step: 12
Training loss: 1.7663187980651855
Validation loss: 2.0634503960609436

Epoch: 6| Step: 13
Training loss: 2.5903759002685547
Validation loss: 2.077689051628113

Epoch: 41| Step: 0
Training loss: 2.1171529293060303
Validation loss: 2.054474433263143

Epoch: 6| Step: 1
Training loss: 1.977604866027832
Validation loss: 2.060389777024587

Epoch: 6| Step: 2
Training loss: 1.7716262340545654
Validation loss: 2.0672295490900674

Epoch: 6| Step: 3
Training loss: 1.8453645706176758
Validation loss: 2.063181002934774

Epoch: 6| Step: 4
Training loss: 1.785978078842163
Validation loss: 2.093501329421997

Epoch: 6| Step: 5
Training loss: 2.538058042526245
Validation loss: 2.0574229955673218

Epoch: 6| Step: 6
Training loss: 2.117561101913452
Validation loss: 2.089662770430247

Epoch: 6| Step: 7
Training loss: 1.8943867683410645
Validation loss: 2.067253510157267

Epoch: 6| Step: 8
Training loss: 2.2071175575256348
Validation loss: 2.0775295893351235

Epoch: 6| Step: 9
Training loss: 1.8623920679092407
Validation loss: 2.062031169732412

Epoch: 6| Step: 10
Training loss: 2.149038314819336
Validation loss: 2.101871609687805

Epoch: 6| Step: 11
Training loss: 1.516937017440796
Validation loss: 2.0825270613034568

Epoch: 6| Step: 12
Training loss: 2.012845516204834
Validation loss: 2.0838341116905212

Epoch: 6| Step: 13
Training loss: 1.8824785947799683
Validation loss: 2.0774449706077576

Epoch: 42| Step: 0
Training loss: 1.529503583908081
Validation loss: 2.098978896935781

Epoch: 6| Step: 1
Training loss: 2.122213363647461
Validation loss: 2.0642672578493753

Epoch: 6| Step: 2
Training loss: 1.8632948398590088
Validation loss: 2.076131840546926

Epoch: 6| Step: 3
Training loss: 1.8189224004745483
Validation loss: 2.0558971166610718

Epoch: 6| Step: 4
Training loss: 1.9349143505096436
Validation loss: 2.0845288038253784

Epoch: 6| Step: 5
Training loss: 2.2161545753479004
Validation loss: 2.0566632548967996

Epoch: 6| Step: 6
Training loss: 1.8362728357315063
Validation loss: 2.0372966726620994

Epoch: 6| Step: 7
Training loss: 2.0167574882507324
Validation loss: 2.0830750664075217

Epoch: 6| Step: 8
Training loss: 2.080451726913452
Validation loss: 2.0624321897824607

Epoch: 6| Step: 9
Training loss: 2.5333900451660156
Validation loss: 2.064560612042745

Epoch: 6| Step: 10
Training loss: 1.7983949184417725
Validation loss: 2.0418894290924072

Epoch: 6| Step: 11
Training loss: 2.1653196811676025
Validation loss: 2.0694678823153176

Epoch: 6| Step: 12
Training loss: 2.26615047454834
Validation loss: 2.0481284856796265

Epoch: 6| Step: 13
Training loss: 1.4843512773513794
Validation loss: 2.081140081087748

Epoch: 43| Step: 0
Training loss: 2.100971221923828
Validation loss: 2.0434316794077554

Epoch: 6| Step: 1
Training loss: 1.5277729034423828
Validation loss: 2.0523220101992288

Epoch: 6| Step: 2
Training loss: 2.2842116355895996
Validation loss: 2.0393925309181213

Epoch: 6| Step: 3
Training loss: 1.9115500450134277
Validation loss: 2.0687161485354104

Epoch: 6| Step: 4
Training loss: 2.1871585845947266
Validation loss: 2.0653629104296365

Epoch: 6| Step: 5
Training loss: 1.8373826742172241
Validation loss: 2.093126058578491

Epoch: 6| Step: 6
Training loss: 1.841503620147705
Validation loss: 2.0756853421529136

Epoch: 6| Step: 7
Training loss: 2.4888572692871094
Validation loss: 2.0812126795450845

Epoch: 6| Step: 8
Training loss: 1.5833849906921387
Validation loss: 2.066490670045217

Epoch: 6| Step: 9
Training loss: 2.138561248779297
Validation loss: 2.05108634630839

Epoch: 6| Step: 10
Training loss: 2.0203328132629395
Validation loss: 2.0667247970898948

Epoch: 6| Step: 11
Training loss: 1.773808479309082
Validation loss: 2.0763232906659446

Epoch: 6| Step: 12
Training loss: 2.2786173820495605
Validation loss: 2.061182737350464

Epoch: 6| Step: 13
Training loss: 1.8602806329727173
Validation loss: 2.062693973382314

Epoch: 44| Step: 0
Training loss: 2.444540023803711
Validation loss: 2.045011520385742

Epoch: 6| Step: 1
Training loss: 2.2421703338623047
Validation loss: 2.041524052619934

Epoch: 6| Step: 2
Training loss: 2.1990222930908203
Validation loss: 2.0686164100964866

Epoch: 6| Step: 3
Training loss: 1.8292019367218018
Validation loss: 2.07031257947286

Epoch: 6| Step: 4
Training loss: 2.328078269958496
Validation loss: 2.0639161467552185

Epoch: 6| Step: 5
Training loss: 1.6771469116210938
Validation loss: 2.0740251541137695

Epoch: 6| Step: 6
Training loss: 1.9276609420776367
Validation loss: 2.1028817097345986

Epoch: 6| Step: 7
Training loss: 2.094071865081787
Validation loss: 2.0494341055552163

Epoch: 6| Step: 8
Training loss: 1.8061559200286865
Validation loss: 2.080569585164388

Epoch: 6| Step: 9
Training loss: 2.042147636413574
Validation loss: 2.0704378286997476

Epoch: 6| Step: 10
Training loss: 1.9704564809799194
Validation loss: 2.063782294591268

Epoch: 6| Step: 11
Training loss: 1.680037498474121
Validation loss: 2.0692339738210044

Epoch: 6| Step: 12
Training loss: 2.1313557624816895
Validation loss: 2.048239787419637

Epoch: 6| Step: 13
Training loss: 1.7028591632843018
Validation loss: 2.0404812494913735

Epoch: 45| Step: 0
Training loss: 1.977327585220337
Validation loss: 2.0682461659113565

Epoch: 6| Step: 1
Training loss: 2.0250730514526367
Validation loss: 2.067932883898417

Epoch: 6| Step: 2
Training loss: 1.8162661790847778
Validation loss: 2.0699622631073

Epoch: 6| Step: 3
Training loss: 1.6547036170959473
Validation loss: 2.0646890799204507

Epoch: 6| Step: 4
Training loss: 2.028113603591919
Validation loss: 2.0890074968338013

Epoch: 6| Step: 5
Training loss: 1.9239990711212158
Validation loss: 2.09125687678655

Epoch: 6| Step: 6
Training loss: 1.7880069017410278
Validation loss: 2.1098790963490806

Epoch: 6| Step: 7
Training loss: 2.535953998565674
Validation loss: 2.0933673977851868

Epoch: 6| Step: 8
Training loss: 1.6065176725387573
Validation loss: 2.11964750289917

Epoch: 6| Step: 9
Training loss: 2.1455163955688477
Validation loss: 2.13802699247996

Epoch: 6| Step: 10
Training loss: 2.4261960983276367
Validation loss: 2.120722532272339

Epoch: 6| Step: 11
Training loss: 2.7366983890533447
Validation loss: 2.1250126163164773

Epoch: 6| Step: 12
Training loss: 1.4070683717727661
Validation loss: 2.0785831411679587

Epoch: 6| Step: 13
Training loss: 1.984938383102417
Validation loss: 2.058859427769979

Epoch: 46| Step: 0
Training loss: 1.791143536567688
Validation loss: 2.038369297981262

Epoch: 6| Step: 1
Training loss: 2.0187203884124756
Validation loss: 2.0674626429875693

Epoch: 6| Step: 2
Training loss: 2.270031690597534
Validation loss: 2.0427501598993936

Epoch: 6| Step: 3
Training loss: 2.0268828868865967
Validation loss: 2.0597877502441406

Epoch: 6| Step: 4
Training loss: 1.9437546730041504
Validation loss: 2.047377904256185

Epoch: 6| Step: 5
Training loss: 2.296851634979248
Validation loss: 2.067678689956665

Epoch: 6| Step: 6
Training loss: 1.1244754791259766
Validation loss: 2.0915820201238

Epoch: 6| Step: 7
Training loss: 2.299614906311035
Validation loss: 2.07395209868749

Epoch: 6| Step: 8
Training loss: 2.2808971405029297
Validation loss: 2.0814605752627053

Epoch: 6| Step: 9
Training loss: 1.6627559661865234
Validation loss: 2.068145751953125

Epoch: 6| Step: 10
Training loss: 2.455069065093994
Validation loss: 2.0785455306371055

Epoch: 6| Step: 11
Training loss: 1.9671634435653687
Validation loss: 2.0747181375821433

Epoch: 6| Step: 12
Training loss: 2.0378901958465576
Validation loss: 2.076580504576365

Epoch: 6| Step: 13
Training loss: 2.257507801055908
Validation loss: 2.068024218082428

Epoch: 47| Step: 0
Training loss: 1.759613275527954
Validation loss: 2.0663188099861145

Epoch: 6| Step: 1
Training loss: 1.4311362504959106
Validation loss: 2.0560001929601035

Epoch: 6| Step: 2
Training loss: 2.048811912536621
Validation loss: 2.0379016995429993

Epoch: 6| Step: 3
Training loss: 2.873621940612793
Validation loss: 2.0595810810724893

Epoch: 6| Step: 4
Training loss: 2.529613733291626
Validation loss: 2.057112912336985

Epoch: 6| Step: 5
Training loss: 2.3971617221832275
Validation loss: 2.077898104985555

Epoch: 6| Step: 6
Training loss: 2.217639446258545
Validation loss: 2.073168933391571

Epoch: 6| Step: 7
Training loss: 1.308928370475769
Validation loss: 2.075019379456838

Epoch: 6| Step: 8
Training loss: 1.3703415393829346
Validation loss: 2.092127780119578

Epoch: 6| Step: 9
Training loss: 2.0026981830596924
Validation loss: 2.0792967875798545

Epoch: 6| Step: 10
Training loss: 2.2070155143737793
Validation loss: 2.0649413665135703

Epoch: 6| Step: 11
Training loss: 1.3518974781036377
Validation loss: 2.067242602507273

Epoch: 6| Step: 12
Training loss: 2.1028976440429688
Validation loss: 2.0605570872624717

Epoch: 6| Step: 13
Training loss: 2.1806888580322266
Validation loss: 2.064978380997976

Epoch: 48| Step: 0
Training loss: 2.5925087928771973
Validation loss: 2.0462671319643655

Epoch: 6| Step: 1
Training loss: 1.936293601989746
Validation loss: 2.055761476357778

Epoch: 6| Step: 2
Training loss: 2.445145606994629
Validation loss: 2.0539496342341104

Epoch: 6| Step: 3
Training loss: 2.2051198482513428
Validation loss: 2.065533459186554

Epoch: 6| Step: 4
Training loss: 1.3611383438110352
Validation loss: 2.044512669245402

Epoch: 6| Step: 5
Training loss: 1.6867326498031616
Validation loss: 2.062442441781362

Epoch: 6| Step: 6
Training loss: 1.9011976718902588
Validation loss: 2.05173659324646

Epoch: 6| Step: 7
Training loss: 1.8285578489303589
Validation loss: 2.0619723002115884

Epoch: 6| Step: 8
Training loss: 2.1429567337036133
Validation loss: 2.0461981892585754

Epoch: 6| Step: 9
Training loss: 2.056272506713867
Validation loss: 2.0606088042259216

Epoch: 6| Step: 10
Training loss: 1.8445221185684204
Validation loss: 2.0535029570261636

Epoch: 6| Step: 11
Training loss: 2.120330572128296
Validation loss: 2.054450273513794

Epoch: 6| Step: 12
Training loss: 1.6775171756744385
Validation loss: 2.037927210330963

Epoch: 6| Step: 13
Training loss: 1.9007878303527832
Validation loss: 2.0405299067497253

Epoch: 49| Step: 0
Training loss: 1.5362019538879395
Validation loss: 2.051270385583242

Epoch: 6| Step: 1
Training loss: 1.813981294631958
Validation loss: 2.060339609781901

Epoch: 6| Step: 2
Training loss: 2.505439519882202
Validation loss: 2.0619895855585733

Epoch: 6| Step: 3
Training loss: 2.5130960941314697
Validation loss: 2.0700369079907737

Epoch: 6| Step: 4
Training loss: 1.4613107442855835
Validation loss: 2.0573400457700095

Epoch: 6| Step: 5
Training loss: 2.0442662239074707
Validation loss: 2.063759704430898

Epoch: 6| Step: 6
Training loss: 1.6630581617355347
Validation loss: 2.043535590171814

Epoch: 6| Step: 7
Training loss: 1.559755802154541
Validation loss: 2.0784594416618347

Epoch: 6| Step: 8
Training loss: 1.8385885953903198
Validation loss: 2.0601598819096885

Epoch: 6| Step: 9
Training loss: 2.782339096069336
Validation loss: 2.0750712553660073

Epoch: 6| Step: 10
Training loss: 2.1183767318725586
Validation loss: 2.066228369871775

Epoch: 6| Step: 11
Training loss: 2.013805866241455
Validation loss: 2.0599482655525208

Epoch: 6| Step: 12
Training loss: 1.927440881729126
Validation loss: 2.0427268346150718

Epoch: 6| Step: 13
Training loss: 1.6673855781555176
Validation loss: 2.0544520020484924

Epoch: 50| Step: 0
Training loss: 1.7881863117218018
Validation loss: 2.054677446683248

Epoch: 6| Step: 1
Training loss: 1.995133876800537
Validation loss: 2.046690344810486

Epoch: 6| Step: 2
Training loss: 2.420602798461914
Validation loss: 2.05058091878891

Epoch: 6| Step: 3
Training loss: 2.8045740127563477
Validation loss: 2.0382713675498962

Epoch: 6| Step: 4
Training loss: 1.4242154359817505
Validation loss: 2.0129069487253823

Epoch: 6| Step: 5
Training loss: 1.584718108177185
Validation loss: 2.066435972849528

Epoch: 6| Step: 6
Training loss: 2.405532121658325
Validation loss: 2.057871659596761

Epoch: 6| Step: 7
Training loss: 2.9659667015075684
Validation loss: 2.0382713874181113

Epoch: 6| Step: 8
Training loss: 1.0397034883499146
Validation loss: 2.0339596470197043

Epoch: 6| Step: 9
Training loss: 1.4872941970825195
Validation loss: 2.0553459922472634

Epoch: 6| Step: 10
Training loss: 2.2790603637695312
Validation loss: 2.052226702372233

Epoch: 6| Step: 11
Training loss: 1.8864948749542236
Validation loss: 2.0267704129219055

Epoch: 6| Step: 12
Training loss: 1.7588376998901367
Validation loss: 2.0342217087745667

Epoch: 6| Step: 13
Training loss: 1.5602606534957886
Validation loss: 2.0466445088386536

Epoch: 51| Step: 0
Training loss: 2.379451274871826
Validation loss: 2.0263914267222085

Epoch: 6| Step: 1
Training loss: 1.6746923923492432
Validation loss: 2.044686953226725

Epoch: 6| Step: 2
Training loss: 2.155181407928467
Validation loss: 2.04451056321462

Epoch: 6| Step: 3
Training loss: 1.9602282047271729
Validation loss: 2.043372929096222

Epoch: 6| Step: 4
Training loss: 2.1479692459106445
Validation loss: 2.0603888432184854

Epoch: 6| Step: 5
Training loss: 1.7566195726394653
Validation loss: 2.037853956222534

Epoch: 6| Step: 6
Training loss: 1.6133850812911987
Validation loss: 2.0567956368128457

Epoch: 6| Step: 7
Training loss: 1.4764724969863892
Validation loss: 2.0179651180903115

Epoch: 6| Step: 8
Training loss: 2.179072141647339
Validation loss: 2.040642738342285

Epoch: 6| Step: 9
Training loss: 2.4107165336608887
Validation loss: 2.053648293018341

Epoch: 6| Step: 10
Training loss: 1.2976033687591553
Validation loss: 2.0602780183156333

Epoch: 6| Step: 11
Training loss: 1.7138423919677734
Validation loss: 2.0531678398450217

Epoch: 6| Step: 12
Training loss: 1.9673678874969482
Validation loss: 2.0441494584083557

Epoch: 6| Step: 13
Training loss: 2.406622886657715
Validation loss: 2.0294727087020874

Epoch: 52| Step: 0
Training loss: 2.4855949878692627
Validation loss: 2.0690322717030845

Epoch: 6| Step: 1
Training loss: 2.172534942626953
Validation loss: 2.0541557470957437

Epoch: 6| Step: 2
Training loss: 1.684004545211792
Validation loss: 2.037330389022827

Epoch: 6| Step: 3
Training loss: 2.3198702335357666
Validation loss: 2.039289712905884

Epoch: 6| Step: 4
Training loss: 1.5745631456375122
Validation loss: 2.060895562171936

Epoch: 6| Step: 5
Training loss: 2.395772695541382
Validation loss: 2.045881986618042

Epoch: 6| Step: 6
Training loss: 1.4482650756835938
Validation loss: 2.048043191432953

Epoch: 6| Step: 7
Training loss: 2.252415657043457
Validation loss: 2.0315149227778115

Epoch: 6| Step: 8
Training loss: 2.269897222518921
Validation loss: 2.059092899163564

Epoch: 6| Step: 9
Training loss: 2.0932023525238037
Validation loss: 2.0802007714907327

Epoch: 6| Step: 10
Training loss: 1.5733145475387573
Validation loss: 2.0768935879071555

Epoch: 6| Step: 11
Training loss: 1.686792016029358
Validation loss: 2.06789223353068

Epoch: 6| Step: 12
Training loss: 1.8167109489440918
Validation loss: 2.073150098323822

Epoch: 6| Step: 13
Training loss: 1.5844368934631348
Validation loss: 2.0691528916358948

Epoch: 53| Step: 0
Training loss: 1.2058165073394775
Validation loss: 2.052517553170522

Epoch: 6| Step: 1
Training loss: 2.1434435844421387
Validation loss: 2.0529174407323203

Epoch: 6| Step: 2
Training loss: 2.17146635055542
Validation loss: 2.0513824621836343

Epoch: 6| Step: 3
Training loss: 1.7592146396636963
Validation loss: 2.0406962831815085

Epoch: 6| Step: 4
Training loss: 2.0971131324768066
Validation loss: 2.057307779788971

Epoch: 6| Step: 5
Training loss: 1.8265933990478516
Validation loss: 2.0238797068595886

Epoch: 6| Step: 6
Training loss: 1.645820140838623
Validation loss: 2.050363302230835

Epoch: 6| Step: 7
Training loss: 1.320723295211792
Validation loss: 2.0504108468691506

Epoch: 6| Step: 8
Training loss: 2.0217251777648926
Validation loss: 2.0386765797932944

Epoch: 6| Step: 9
Training loss: 1.9640600681304932
Validation loss: 2.046480139096578

Epoch: 6| Step: 10
Training loss: 1.9366799592971802
Validation loss: 2.046469807624817

Epoch: 6| Step: 11
Training loss: 2.881143808364868
Validation loss: 2.0163573026657104

Epoch: 6| Step: 12
Training loss: 2.982109308242798
Validation loss: 2.038839817047119

Epoch: 6| Step: 13
Training loss: 1.419875144958496
Validation loss: 2.0270543893178306

Epoch: 54| Step: 0
Training loss: 1.3970799446105957
Validation loss: 2.0535256266593933

Epoch: 6| Step: 1
Training loss: 1.6530144214630127
Validation loss: 2.0387966434160867

Epoch: 6| Step: 2
Training loss: 2.3578953742980957
Validation loss: 2.067955732345581

Epoch: 6| Step: 3
Training loss: 1.4682778120040894
Validation loss: 2.0655789573987327

Epoch: 6| Step: 4
Training loss: 1.8300533294677734
Validation loss: 2.0371758341789246

Epoch: 6| Step: 5
Training loss: 1.8154674768447876
Validation loss: 2.059854487578074

Epoch: 6| Step: 6
Training loss: 1.9285576343536377
Validation loss: 2.052941461404165

Epoch: 6| Step: 7
Training loss: 1.9338983297348022
Validation loss: 2.065238813559214

Epoch: 6| Step: 8
Training loss: 2.022806406021118
Validation loss: 2.073246975739797

Epoch: 6| Step: 9
Training loss: 2.0631518363952637
Validation loss: 2.0568161010742188

Epoch: 6| Step: 10
Training loss: 1.8254427909851074
Validation loss: 2.078255275885264

Epoch: 6| Step: 11
Training loss: 2.265812635421753
Validation loss: 2.078739027182261

Epoch: 6| Step: 12
Training loss: 2.2929694652557373
Validation loss: 2.0915947357813516

Epoch: 6| Step: 13
Training loss: 2.501728057861328
Validation loss: 2.0619854728380838

Epoch: 55| Step: 0
Training loss: 2.08797287940979
Validation loss: 2.0691601037979126

Epoch: 6| Step: 1
Training loss: 1.9027814865112305
Validation loss: 2.0881811380386353

Epoch: 6| Step: 2
Training loss: 1.8399620056152344
Validation loss: 2.0533447861671448

Epoch: 6| Step: 3
Training loss: 1.5916528701782227
Validation loss: 2.0658538341522217

Epoch: 6| Step: 4
Training loss: 1.4988106489181519
Validation loss: 2.058616836865743

Epoch: 6| Step: 5
Training loss: 1.7110105752944946
Validation loss: 2.045694092909495

Epoch: 6| Step: 6
Training loss: 2.1223506927490234
Validation loss: 2.0653411149978638

Epoch: 6| Step: 7
Training loss: 2.6729607582092285
Validation loss: 2.042486011981964

Epoch: 6| Step: 8
Training loss: 2.1064276695251465
Validation loss: 2.030642032623291

Epoch: 6| Step: 9
Training loss: 2.0374348163604736
Validation loss: 2.028591593106588

Epoch: 6| Step: 10
Training loss: 1.9340996742248535
Validation loss: 2.0380712747573853

Epoch: 6| Step: 11
Training loss: 1.9363185167312622
Validation loss: 2.036817808945974

Epoch: 6| Step: 12
Training loss: 2.368091344833374
Validation loss: 2.0436699191729226

Epoch: 6| Step: 13
Training loss: 1.7602564096450806
Validation loss: 2.040442943572998

Epoch: 56| Step: 0
Training loss: 1.7561427354812622
Validation loss: 2.0433406035105386

Epoch: 6| Step: 1
Training loss: 1.6662746667861938
Validation loss: 2.0403338074684143

Epoch: 6| Step: 2
Training loss: 1.6637494564056396
Validation loss: 2.0515917340914407

Epoch: 6| Step: 3
Training loss: 2.014464855194092
Validation loss: 2.0789765119552612

Epoch: 6| Step: 4
Training loss: 2.3935513496398926
Validation loss: 2.079414506753286

Epoch: 6| Step: 5
Training loss: 1.4171044826507568
Validation loss: 2.09462571144104

Epoch: 6| Step: 6
Training loss: 1.5327856540679932
Validation loss: 2.0780790646870932

Epoch: 6| Step: 7
Training loss: 1.8541929721832275
Validation loss: 2.071180244286855

Epoch: 6| Step: 8
Training loss: 2.472475528717041
Validation loss: 2.0532826582590737

Epoch: 6| Step: 9
Training loss: 1.9408884048461914
Validation loss: 2.078477919101715

Epoch: 6| Step: 10
Training loss: 2.2979397773742676
Validation loss: 2.0361891984939575

Epoch: 6| Step: 11
Training loss: 2.758397102355957
Validation loss: 2.045244733492533

Epoch: 6| Step: 12
Training loss: 1.1706266403198242
Validation loss: 2.0212759574254355

Epoch: 6| Step: 13
Training loss: 2.446598768234253
Validation loss: 2.038088341554006

Epoch: 57| Step: 0
Training loss: 1.118733286857605
Validation loss: 2.029078483581543

Epoch: 6| Step: 1
Training loss: 2.1481409072875977
Validation loss: 2.054687261581421

Epoch: 6| Step: 2
Training loss: 1.668665885925293
Validation loss: 2.0323068102200827

Epoch: 6| Step: 3
Training loss: 1.4358775615692139
Validation loss: 2.037917375564575

Epoch: 6| Step: 4
Training loss: 2.371039390563965
Validation loss: 2.0337931712468467

Epoch: 6| Step: 5
Training loss: 1.1599318981170654
Validation loss: 2.0591424703598022

Epoch: 6| Step: 6
Training loss: 2.0755889415740967
Validation loss: 2.0462884505589805

Epoch: 6| Step: 7
Training loss: 1.7485966682434082
Validation loss: 2.0397708217302957

Epoch: 6| Step: 8
Training loss: 2.118311643600464
Validation loss: 2.0249236623446145

Epoch: 6| Step: 9
Training loss: 1.8987228870391846
Validation loss: 2.0447550415992737

Epoch: 6| Step: 10
Training loss: 2.120922565460205
Validation loss: 2.0550593535105386

Epoch: 6| Step: 11
Training loss: 2.09816837310791
Validation loss: 2.044196685155233

Epoch: 6| Step: 12
Training loss: 2.9778714179992676
Validation loss: 2.0402841369311013

Epoch: 6| Step: 13
Training loss: 2.364156484603882
Validation loss: 2.0381790002187095

Epoch: 58| Step: 0
Training loss: 1.9390140771865845
Validation loss: 2.0681756138801575

Epoch: 6| Step: 1
Training loss: 1.8959064483642578
Validation loss: 2.042742649714152

Epoch: 6| Step: 2
Training loss: 1.5868233442306519
Validation loss: 2.0434852639834085

Epoch: 6| Step: 3
Training loss: 2.162193775177002
Validation loss: 2.037715435028076

Epoch: 6| Step: 4
Training loss: 2.807663917541504
Validation loss: 2.0580353339513144

Epoch: 6| Step: 5
Training loss: 2.105370044708252
Validation loss: 2.035339633623759

Epoch: 6| Step: 6
Training loss: 2.4281861782073975
Validation loss: 2.0562413334846497

Epoch: 6| Step: 7
Training loss: 1.8817212581634521
Validation loss: 2.045301079750061

Epoch: 6| Step: 8
Training loss: 1.5242233276367188
Validation loss: 2.040891468524933

Epoch: 6| Step: 9
Training loss: 1.7410805225372314
Validation loss: 2.0435909827550254

Epoch: 6| Step: 10
Training loss: 1.3886651992797852
Validation loss: 2.0505212545394897

Epoch: 6| Step: 11
Training loss: 1.9068852663040161
Validation loss: 2.039139668146769

Epoch: 6| Step: 12
Training loss: 1.5390385389328003
Validation loss: 2.040554185708364

Epoch: 6| Step: 13
Training loss: 2.2085609436035156
Validation loss: 2.042189915974935

Epoch: 59| Step: 0
Training loss: 2.342944622039795
Validation loss: 2.028316934903463

Epoch: 6| Step: 1
Training loss: 1.7663501501083374
Validation loss: 2.0576760172843933

Epoch: 6| Step: 2
Training loss: 2.55440616607666
Validation loss: 2.074128568172455

Epoch: 6| Step: 3
Training loss: 1.5580840110778809
Validation loss: 2.063666065533956

Epoch: 6| Step: 4
Training loss: 1.9081335067749023
Validation loss: 2.0457078417142234

Epoch: 6| Step: 5
Training loss: 1.9963617324829102
Validation loss: 2.0558435320854187

Epoch: 6| Step: 6
Training loss: 1.1339057683944702
Validation loss: 2.0516231060028076

Epoch: 6| Step: 7
Training loss: 2.131678819656372
Validation loss: 2.0356049140294394

Epoch: 6| Step: 8
Training loss: 1.59978449344635
Validation loss: 2.063677728176117

Epoch: 6| Step: 9
Training loss: 2.552816390991211
Validation loss: 2.028465429941813

Epoch: 6| Step: 10
Training loss: 2.3061954975128174
Validation loss: 2.032488207022349

Epoch: 6| Step: 11
Training loss: 2.0876829624176025
Validation loss: 2.020744025707245

Epoch: 6| Step: 12
Training loss: 1.2721710205078125
Validation loss: 2.029914895693461

Epoch: 6| Step: 13
Training loss: 1.9828444719314575
Validation loss: 2.0486356218655906

Epoch: 60| Step: 0
Training loss: 1.6323363780975342
Validation loss: 2.0398831168810525

Epoch: 6| Step: 1
Training loss: 1.9589993953704834
Validation loss: 2.0435444116592407

Epoch: 6| Step: 2
Training loss: 1.841758370399475
Validation loss: 2.051852762699127

Epoch: 6| Step: 3
Training loss: 2.6397252082824707
Validation loss: 2.051964441935221

Epoch: 6| Step: 4
Training loss: 1.6323108673095703
Validation loss: 2.0393195350964866

Epoch: 6| Step: 5
Training loss: 1.7564682960510254
Validation loss: 2.0283974409103394

Epoch: 6| Step: 6
Training loss: 1.8058524131774902
Validation loss: 2.043265481789907

Epoch: 6| Step: 7
Training loss: 1.8004086017608643
Validation loss: 2.0535174210866294

Epoch: 6| Step: 8
Training loss: 2.0311596393585205
Validation loss: 2.048326770464579

Epoch: 6| Step: 9
Training loss: 1.4016528129577637
Validation loss: 2.0428535540898642

Epoch: 6| Step: 10
Training loss: 1.9919335842132568
Validation loss: 2.0595324635505676

Epoch: 6| Step: 11
Training loss: 2.622650146484375
Validation loss: 2.0606415470441184

Epoch: 6| Step: 12
Training loss: 1.65846586227417
Validation loss: 2.0556222399075827

Epoch: 6| Step: 13
Training loss: 2.116035223007202
Validation loss: 2.098213811715444

Epoch: 61| Step: 0
Training loss: 1.775033712387085
Validation loss: 2.0891149441401162

Epoch: 6| Step: 1
Training loss: 1.5159770250320435
Validation loss: 2.108084519704183

Epoch: 6| Step: 2
Training loss: 2.029503107070923
Validation loss: 2.094024181365967

Epoch: 6| Step: 3
Training loss: 2.371532917022705
Validation loss: 2.0726489623387656

Epoch: 6| Step: 4
Training loss: 2.0208029747009277
Validation loss: 2.0960324009259543

Epoch: 6| Step: 5
Training loss: 1.8570215702056885
Validation loss: 2.0683061480522156

Epoch: 6| Step: 6
Training loss: 2.0009567737579346
Validation loss: 2.062743345896403

Epoch: 6| Step: 7
Training loss: 1.8824069499969482
Validation loss: 2.040801525115967

Epoch: 6| Step: 8
Training loss: 1.4268033504486084
Validation loss: 2.0489478707313538

Epoch: 6| Step: 9
Training loss: 1.8892590999603271
Validation loss: 2.038703898588816

Epoch: 6| Step: 10
Training loss: 1.969052791595459
Validation loss: 2.032614588737488

Epoch: 6| Step: 11
Training loss: 1.9201266765594482
Validation loss: 2.0342543721199036

Epoch: 6| Step: 12
Training loss: 2.4134888648986816
Validation loss: 2.0314869483311973

Epoch: 6| Step: 13
Training loss: 1.9324450492858887
Validation loss: 2.0361921389897666

Epoch: 62| Step: 0
Training loss: 2.403428077697754
Validation loss: 2.047029713789622

Epoch: 6| Step: 1
Training loss: 1.092151165008545
Validation loss: 2.036906143029531

Epoch: 6| Step: 2
Training loss: 1.7504570484161377
Validation loss: 2.040774385134379

Epoch: 6| Step: 3
Training loss: 2.0404229164123535
Validation loss: 2.05133718252182

Epoch: 6| Step: 4
Training loss: 2.4319558143615723
Validation loss: 2.028005083401998

Epoch: 6| Step: 5
Training loss: 2.052417755126953
Validation loss: 2.0330230792363486

Epoch: 6| Step: 6
Training loss: 2.3880672454833984
Validation loss: 2.036782443523407

Epoch: 6| Step: 7
Training loss: 2.019627571105957
Validation loss: 2.0423845251401267

Epoch: 6| Step: 8
Training loss: 1.552863359451294
Validation loss: 2.042787273724874

Epoch: 6| Step: 9
Training loss: 1.9147255420684814
Validation loss: 2.0389849146207175

Epoch: 6| Step: 10
Training loss: 2.0984716415405273
Validation loss: 2.027086059252421

Epoch: 6| Step: 11
Training loss: 1.8147531747817993
Validation loss: 2.0287898778915405

Epoch: 6| Step: 12
Training loss: 1.7070341110229492
Validation loss: 2.049207011858622

Epoch: 6| Step: 13
Training loss: 1.8343737125396729
Validation loss: 2.0581732590993247

Epoch: 63| Step: 0
Training loss: 2.223573684692383
Validation loss: 2.05728147427241

Epoch: 6| Step: 1
Training loss: 1.2373191118240356
Validation loss: 2.0576433738072715

Epoch: 6| Step: 2
Training loss: 1.8398640155792236
Validation loss: 2.0718573331832886

Epoch: 6| Step: 3
Training loss: 1.6875665187835693
Validation loss: 2.04156086842219

Epoch: 6| Step: 4
Training loss: 1.779289960861206
Validation loss: 2.0749122301737466

Epoch: 6| Step: 5
Training loss: 1.9297062158584595
Validation loss: 2.043978989124298

Epoch: 6| Step: 6
Training loss: 1.7105402946472168
Validation loss: 2.0619412660598755

Epoch: 6| Step: 7
Training loss: 2.2194409370422363
Validation loss: 2.0392197966575623

Epoch: 6| Step: 8
Training loss: 2.256183624267578
Validation loss: 2.043625990549723

Epoch: 6| Step: 9
Training loss: 1.478421926498413
Validation loss: 2.063535292943319

Epoch: 6| Step: 10
Training loss: 2.016908884048462
Validation loss: 2.0514930287996926

Epoch: 6| Step: 11
Training loss: 1.8025223016738892
Validation loss: 2.0496114691098533

Epoch: 6| Step: 12
Training loss: 1.8556528091430664
Validation loss: 2.0595179200172424

Epoch: 6| Step: 13
Training loss: 2.921273708343506
Validation loss: 2.031467020511627

Epoch: 64| Step: 0
Training loss: 2.0147042274475098
Validation loss: 2.0553234815597534

Epoch: 6| Step: 1
Training loss: 1.2457022666931152
Validation loss: 2.0711944897969565

Epoch: 6| Step: 2
Training loss: 2.5414676666259766
Validation loss: 2.042928715546926

Epoch: 6| Step: 3
Training loss: 1.98638916015625
Validation loss: 2.0489275256792703

Epoch: 6| Step: 4
Training loss: 1.8800476789474487
Validation loss: 2.0271066228548684

Epoch: 6| Step: 5
Training loss: 2.5327353477478027
Validation loss: 2.0200214783350625

Epoch: 6| Step: 6
Training loss: 1.5037689208984375
Validation loss: 2.0509074926376343

Epoch: 6| Step: 7
Training loss: 1.730156421661377
Validation loss: 2.0263081192970276

Epoch: 6| Step: 8
Training loss: 1.8814034461975098
Validation loss: 2.04258793592453

Epoch: 6| Step: 9
Training loss: 1.8689815998077393
Validation loss: 2.063283125559489

Epoch: 6| Step: 10
Training loss: 1.41208016872406
Validation loss: 2.0328436891237893

Epoch: 6| Step: 11
Training loss: 2.1245031356811523
Validation loss: 2.0379080772399902

Epoch: 6| Step: 12
Training loss: 1.909138560295105
Validation loss: 2.0231724182764688

Epoch: 6| Step: 13
Training loss: 2.3079726696014404
Validation loss: 2.047272523244222

Epoch: 65| Step: 0
Training loss: 2.373627185821533
Validation loss: 2.0529497464497886

Epoch: 6| Step: 1
Training loss: 1.8959258794784546
Validation loss: 2.0456185936927795

Epoch: 6| Step: 2
Training loss: 2.2916834354400635
Validation loss: 2.0286529461542764

Epoch: 6| Step: 3
Training loss: 1.9656438827514648
Validation loss: 2.013192375500997

Epoch: 6| Step: 4
Training loss: 1.9789682626724243
Validation loss: 2.0516185959180198

Epoch: 6| Step: 5
Training loss: 2.062790632247925
Validation loss: 2.0301670034726462

Epoch: 6| Step: 6
Training loss: 1.5620900392532349
Validation loss: 2.0177016456921897

Epoch: 6| Step: 7
Training loss: 1.576059341430664
Validation loss: 2.025016486644745

Epoch: 6| Step: 8
Training loss: 2.1638941764831543
Validation loss: 2.0197542309761047

Epoch: 6| Step: 9
Training loss: 1.8554011583328247
Validation loss: 2.04296467701594

Epoch: 6| Step: 10
Training loss: 1.4122368097305298
Validation loss: 2.044491688410441

Epoch: 6| Step: 11
Training loss: 1.8664878606796265
Validation loss: 2.028502623240153

Epoch: 6| Step: 12
Training loss: 2.2294063568115234
Validation loss: 2.029579440752665

Epoch: 6| Step: 13
Training loss: 1.7485464811325073
Validation loss: 2.0298750003178916

Epoch: 66| Step: 0
Training loss: 1.8839091062545776
Validation loss: 2.052389939626058

Epoch: 6| Step: 1
Training loss: 1.7571263313293457
Validation loss: 2.0258107781410217

Epoch: 6| Step: 2
Training loss: 2.083535671234131
Validation loss: 2.055392583211263

Epoch: 6| Step: 3
Training loss: 2.158895254135132
Validation loss: 2.075987001260122

Epoch: 6| Step: 4
Training loss: 1.8359029293060303
Validation loss: 2.042154332002004

Epoch: 6| Step: 5
Training loss: 2.1670498847961426
Validation loss: 2.0224528114000955

Epoch: 6| Step: 6
Training loss: 1.9805680513381958
Validation loss: 2.051045536994934

Epoch: 6| Step: 7
Training loss: 2.3747122287750244
Validation loss: 2.049353818098704

Epoch: 6| Step: 8
Training loss: 1.3931810855865479
Validation loss: 2.074365238348643

Epoch: 6| Step: 9
Training loss: 1.6129202842712402
Validation loss: 2.0627400080362954

Epoch: 6| Step: 10
Training loss: 2.32491397857666
Validation loss: 2.0626740058263144

Epoch: 6| Step: 11
Training loss: 1.7744051218032837
Validation loss: 2.0597625573476157

Epoch: 6| Step: 12
Training loss: 1.3182393312454224
Validation loss: 2.0544894536336265

Epoch: 6| Step: 13
Training loss: 2.2158432006835938
Validation loss: 2.041267474492391

Epoch: 67| Step: 0
Training loss: 2.1610875129699707
Validation loss: 2.0445258816083274

Epoch: 6| Step: 1
Training loss: 2.598191261291504
Validation loss: 2.0516831080118814

Epoch: 6| Step: 2
Training loss: 1.441381812095642
Validation loss: 2.0465930104255676

Epoch: 6| Step: 3
Training loss: 1.6209666728973389
Validation loss: 2.03351761897405

Epoch: 6| Step: 4
Training loss: 2.1108181476593018
Validation loss: 2.0314766565958657

Epoch: 6| Step: 5
Training loss: 1.906616449356079
Validation loss: 2.0392961303393045

Epoch: 6| Step: 6
Training loss: 1.802220106124878
Validation loss: 2.068371136983236

Epoch: 6| Step: 7
Training loss: 2.158989906311035
Validation loss: 2.042430877685547

Epoch: 6| Step: 8
Training loss: 1.253176212310791
Validation loss: 2.053846756617228

Epoch: 6| Step: 9
Training loss: 1.8042693138122559
Validation loss: 2.0485681096712747

Epoch: 6| Step: 10
Training loss: 2.246466875076294
Validation loss: 2.0249715050061545

Epoch: 6| Step: 11
Training loss: 1.8329918384552002
Validation loss: 2.0429921746253967

Epoch: 6| Step: 12
Training loss: 2.09012508392334
Validation loss: 2.039146661758423

Epoch: 6| Step: 13
Training loss: 1.9367505311965942
Validation loss: 2.042461653550466

Epoch: 68| Step: 0
Training loss: 1.878688097000122
Validation loss: 2.0468358596165976

Epoch: 6| Step: 1
Training loss: 1.3899571895599365
Validation loss: 2.0331554412841797

Epoch: 6| Step: 2
Training loss: 1.8113987445831299
Validation loss: 2.0225877165794373

Epoch: 6| Step: 3
Training loss: 1.4577889442443848
Validation loss: 2.060530185699463

Epoch: 6| Step: 4
Training loss: 1.9628174304962158
Validation loss: 2.0563661456108093

Epoch: 6| Step: 5
Training loss: 1.8687515258789062
Validation loss: 2.0648518006006875

Epoch: 6| Step: 6
Training loss: 2.5401692390441895
Validation loss: 2.049310008684794

Epoch: 6| Step: 7
Training loss: 2.3925466537475586
Validation loss: 2.069412032763163

Epoch: 6| Step: 8
Training loss: 1.6622581481933594
Validation loss: 2.057998259862264

Epoch: 6| Step: 9
Training loss: 1.920591950416565
Validation loss: 2.0736538966496787

Epoch: 6| Step: 10
Training loss: 2.289271831512451
Validation loss: 2.0561474760373435

Epoch: 6| Step: 11
Training loss: 2.341817855834961
Validation loss: 2.084974984327952

Epoch: 6| Step: 12
Training loss: 1.9688913822174072
Validation loss: 2.082285245259603

Epoch: 6| Step: 13
Training loss: 1.2082469463348389
Validation loss: 2.0614362955093384

Epoch: 69| Step: 0
Training loss: 2.0924811363220215
Validation loss: 2.03964896996816

Epoch: 6| Step: 1
Training loss: 1.1339668035507202
Validation loss: 2.0268477400143943

Epoch: 6| Step: 2
Training loss: 2.5647850036621094
Validation loss: 2.021470586458842

Epoch: 6| Step: 3
Training loss: 2.07265305519104
Validation loss: 2.0434778134028115

Epoch: 6| Step: 4
Training loss: 1.5338056087493896
Validation loss: 2.028988858064016

Epoch: 6| Step: 5
Training loss: 1.2996058464050293
Validation loss: 2.0396002332369485

Epoch: 6| Step: 6
Training loss: 1.8760035037994385
Validation loss: 2.035684108734131

Epoch: 6| Step: 7
Training loss: 2.158170700073242
Validation loss: 2.03839377562205

Epoch: 6| Step: 8
Training loss: 1.91300630569458
Validation loss: 2.035194218158722

Epoch: 6| Step: 9
Training loss: 1.7620068788528442
Validation loss: 2.04484760761261

Epoch: 6| Step: 10
Training loss: 1.8893247842788696
Validation loss: 2.0372947454452515

Epoch: 6| Step: 11
Training loss: 2.412707567214966
Validation loss: 2.0343818267186484

Epoch: 6| Step: 12
Training loss: 1.7818903923034668
Validation loss: 2.0484760403633118

Epoch: 6| Step: 13
Training loss: 2.231337785720825
Validation loss: 2.0466180443763733

Epoch: 70| Step: 0
Training loss: 1.766155481338501
Validation loss: 2.0372575918833413

Epoch: 6| Step: 1
Training loss: 1.5293527841567993
Validation loss: 2.026105542977651

Epoch: 6| Step: 2
Training loss: 2.4393463134765625
Validation loss: 2.011709968249003

Epoch: 6| Step: 3
Training loss: 1.4637200832366943
Validation loss: 2.054745376110077

Epoch: 6| Step: 4
Training loss: 1.759809970855713
Validation loss: 2.068372686704

Epoch: 6| Step: 5
Training loss: 2.1444945335388184
Validation loss: 2.074121415615082

Epoch: 6| Step: 6
Training loss: 1.563169240951538
Validation loss: 2.0662314693133035

Epoch: 6| Step: 7
Training loss: 2.5368590354919434
Validation loss: 2.0801235238711038

Epoch: 6| Step: 8
Training loss: 2.034059524536133
Validation loss: 2.035476823647817

Epoch: 6| Step: 9
Training loss: 2.3931267261505127
Validation loss: 2.049213389555613

Epoch: 6| Step: 10
Training loss: 1.5940568447113037
Validation loss: 2.0273589491844177

Epoch: 6| Step: 11
Training loss: 1.7727179527282715
Validation loss: 2.060183306535085

Epoch: 6| Step: 12
Training loss: 1.8677830696105957
Validation loss: 2.0282296339670816

Epoch: 6| Step: 13
Training loss: 2.011941432952881
Validation loss: 2.0279398560523987

Epoch: 71| Step: 0
Training loss: 1.3960059881210327
Validation loss: 2.049893339474996

Epoch: 6| Step: 1
Training loss: 2.178722381591797
Validation loss: 2.0776573022206626

Epoch: 6| Step: 2
Training loss: 2.034867286682129
Validation loss: 2.041525661945343

Epoch: 6| Step: 3
Training loss: 1.4722293615341187
Validation loss: 2.0442136923472085

Epoch: 6| Step: 4
Training loss: 2.1996350288391113
Validation loss: 2.0281161268552146

Epoch: 6| Step: 5
Training loss: 2.068155288696289
Validation loss: 2.0453629891077676

Epoch: 6| Step: 6
Training loss: 2.259098529815674
Validation loss: 2.0340238213539124

Epoch: 6| Step: 7
Training loss: 1.1673212051391602
Validation loss: 2.0233498016993203

Epoch: 6| Step: 8
Training loss: 2.6120314598083496
Validation loss: 2.0403159062067666

Epoch: 6| Step: 9
Training loss: 1.8755261898040771
Validation loss: 2.054431358973185

Epoch: 6| Step: 10
Training loss: 1.4123589992523193
Validation loss: 2.0441137552261353

Epoch: 6| Step: 11
Training loss: 1.9002357721328735
Validation loss: 2.0490837693214417

Epoch: 6| Step: 12
Training loss: 1.8771851062774658
Validation loss: 2.0577563047409058

Epoch: 6| Step: 13
Training loss: 2.2538490295410156
Validation loss: 2.0497841238975525

Epoch: 72| Step: 0
Training loss: 2.1268796920776367
Validation loss: 2.0502474308013916

Epoch: 6| Step: 1
Training loss: 1.922126054763794
Validation loss: 2.036426603794098

Epoch: 6| Step: 2
Training loss: 1.7208001613616943
Validation loss: 2.051477233568827

Epoch: 6| Step: 3
Training loss: 2.3179383277893066
Validation loss: 2.050641040007273

Epoch: 6| Step: 4
Training loss: 1.4666341543197632
Validation loss: 2.049436390399933

Epoch: 6| Step: 5
Training loss: 2.066791534423828
Validation loss: 2.0549450715382895

Epoch: 6| Step: 6
Training loss: 1.940553903579712
Validation loss: 2.051473100980123

Epoch: 6| Step: 7
Training loss: 2.4141101837158203
Validation loss: 2.0544414122899375

Epoch: 6| Step: 8
Training loss: 2.499781608581543
Validation loss: 2.027390241622925

Epoch: 6| Step: 9
Training loss: 1.573102593421936
Validation loss: 2.0458835562070212

Epoch: 6| Step: 10
Training loss: 1.4028754234313965
Validation loss: 2.035936971505483

Epoch: 6| Step: 11
Training loss: 1.7142796516418457
Validation loss: 2.033622999986013

Epoch: 6| Step: 12
Training loss: 1.7935576438903809
Validation loss: 2.026936670144399

Epoch: 6| Step: 13
Training loss: 1.8563919067382812
Validation loss: 2.0335349440574646

Epoch: 73| Step: 0
Training loss: 2.1662979125976562
Validation loss: 2.043955445289612

Epoch: 6| Step: 1
Training loss: 1.9451812505722046
Validation loss: 2.0390493273735046

Epoch: 6| Step: 2
Training loss: 1.9940193891525269
Validation loss: 2.0472702980041504

Epoch: 6| Step: 3
Training loss: 2.0680952072143555
Validation loss: 2.0226447184880576

Epoch: 6| Step: 4
Training loss: 1.715990662574768
Validation loss: 2.0336257020632424

Epoch: 6| Step: 5
Training loss: 2.1676814556121826
Validation loss: 2.0571256081263223

Epoch: 6| Step: 6
Training loss: 1.7818005084991455
Validation loss: 2.0502330462137857

Epoch: 6| Step: 7
Training loss: 1.7295303344726562
Validation loss: 2.0137291749318442

Epoch: 6| Step: 8
Training loss: 1.910366415977478
Validation loss: 2.0456687013308206

Epoch: 6| Step: 9
Training loss: 1.4634642601013184
Validation loss: 2.040975570678711

Epoch: 6| Step: 10
Training loss: 1.9156675338745117
Validation loss: 2.007220129172007

Epoch: 6| Step: 11
Training loss: 2.6730589866638184
Validation loss: 2.014936923980713

Epoch: 6| Step: 12
Training loss: 1.4877617359161377
Validation loss: 2.048823873202006

Epoch: 6| Step: 13
Training loss: 1.5790960788726807
Validation loss: 2.0467123985290527

Epoch: 74| Step: 0
Training loss: 2.5147829055786133
Validation loss: 2.071844200293223

Epoch: 6| Step: 1
Training loss: 1.0473055839538574
Validation loss: 2.0677096446355185

Epoch: 6| Step: 2
Training loss: 2.6766817569732666
Validation loss: 2.0450520515441895

Epoch: 6| Step: 3
Training loss: 2.0537304878234863
Validation loss: 2.099542180697123

Epoch: 6| Step: 4
Training loss: 1.1711599826812744
Validation loss: 2.092907647291819

Epoch: 6| Step: 5
Training loss: 1.8109246492385864
Validation loss: 2.0682251850763955

Epoch: 6| Step: 6
Training loss: 1.8466225862503052
Validation loss: 2.069844126701355

Epoch: 6| Step: 7
Training loss: 2.2361745834350586
Validation loss: 2.0914300084114075

Epoch: 6| Step: 8
Training loss: 1.7956469058990479
Validation loss: 2.0574483474095664

Epoch: 6| Step: 9
Training loss: 1.5509133338928223
Validation loss: 2.0544158816337585

Epoch: 6| Step: 10
Training loss: 2.1434803009033203
Validation loss: 2.0757035613059998

Epoch: 6| Step: 11
Training loss: 2.3219757080078125
Validation loss: 2.0470966498057046

Epoch: 6| Step: 12
Training loss: 1.4997212886810303
Validation loss: 2.032496233781179

Epoch: 6| Step: 13
Training loss: 1.918315052986145
Validation loss: 2.0544589161872864

Epoch: 75| Step: 0
Training loss: 1.87416410446167
Validation loss: 2.0103087623914084

Epoch: 6| Step: 1
Training loss: 1.9575214385986328
Validation loss: 2.060637970765432

Epoch: 6| Step: 2
Training loss: 1.7628870010375977
Validation loss: 2.0226794679959617

Epoch: 6| Step: 3
Training loss: 1.9694015979766846
Validation loss: 2.038966417312622

Epoch: 6| Step: 4
Training loss: 1.5594041347503662
Validation loss: 2.045450210571289

Epoch: 6| Step: 5
Training loss: 2.2183046340942383
Validation loss: 2.0524799625078836

Epoch: 6| Step: 6
Training loss: 1.974902868270874
Validation loss: 2.0298677682876587

Epoch: 6| Step: 7
Training loss: 2.249555826187134
Validation loss: 2.0299920241038003

Epoch: 6| Step: 8
Training loss: 1.7842817306518555
Validation loss: 2.0519622762997947

Epoch: 6| Step: 9
Training loss: 2.118859052658081
Validation loss: 2.042044937610626

Epoch: 6| Step: 10
Training loss: 2.0440587997436523
Validation loss: 2.0157048106193542

Epoch: 6| Step: 11
Training loss: 1.7548476457595825
Validation loss: 2.0385077397028604

Epoch: 6| Step: 12
Training loss: 1.9058032035827637
Validation loss: 2.038942019144694

Epoch: 6| Step: 13
Training loss: 1.7945573329925537
Validation loss: 2.0362367630004883

Epoch: 76| Step: 0
Training loss: 1.7068697214126587
Validation loss: 2.017189343770345

Epoch: 6| Step: 1
Training loss: 2.0765647888183594
Validation loss: 2.0538528760274253

Epoch: 6| Step: 2
Training loss: 1.9710187911987305
Validation loss: 2.0228318174680076

Epoch: 6| Step: 3
Training loss: 1.9555163383483887
Validation loss: 2.044293840726217

Epoch: 6| Step: 4
Training loss: 1.9632445573806763
Validation loss: 2.0762258569399514

Epoch: 6| Step: 5
Training loss: 1.237267255783081
Validation loss: 2.037238677342733

Epoch: 6| Step: 6
Training loss: 2.295943021774292
Validation loss: 2.055994987487793

Epoch: 6| Step: 7
Training loss: 1.6050574779510498
Validation loss: 2.0688055952390036

Epoch: 6| Step: 8
Training loss: 1.6987494230270386
Validation loss: 2.060927708943685

Epoch: 6| Step: 9
Training loss: 1.7619218826293945
Validation loss: 2.0190823872884116

Epoch: 6| Step: 10
Training loss: 1.9225274324417114
Validation loss: 2.050609827041626

Epoch: 6| Step: 11
Training loss: 1.761411428451538
Validation loss: 2.0502926309903464

Epoch: 6| Step: 12
Training loss: 1.8195750713348389
Validation loss: 2.049442787965139

Epoch: 6| Step: 13
Training loss: 2.690465211868286
Validation loss: 2.046840270360311

Epoch: 77| Step: 0
Training loss: 2.3491339683532715
Validation loss: 2.0458529591560364

Epoch: 6| Step: 1
Training loss: 1.1119425296783447
Validation loss: 2.0411941607793174

Epoch: 6| Step: 2
Training loss: 1.1392700672149658
Validation loss: 2.0428946018218994

Epoch: 6| Step: 3
Training loss: 1.8893580436706543
Validation loss: 2.0525481502215066

Epoch: 6| Step: 4
Training loss: 2.0714330673217773
Validation loss: 2.040145993232727

Epoch: 6| Step: 5
Training loss: 1.49575674533844
Validation loss: 2.047880013783773

Epoch: 6| Step: 6
Training loss: 1.5736379623413086
Validation loss: 2.0361786683400473

Epoch: 6| Step: 7
Training loss: 1.9343913793563843
Validation loss: 2.0593172510464988

Epoch: 6| Step: 8
Training loss: 2.090240001678467
Validation loss: 2.0520148078600564

Epoch: 6| Step: 9
Training loss: 2.407180070877075
Validation loss: 2.047950526078542

Epoch: 6| Step: 10
Training loss: 2.3960623741149902
Validation loss: 2.0456458727518716

Epoch: 6| Step: 11
Training loss: 1.5570653676986694
Validation loss: 2.0620150764783225

Epoch: 6| Step: 12
Training loss: 2.1163549423217773
Validation loss: 2.034017185370127

Epoch: 6| Step: 13
Training loss: 2.327528476715088
Validation loss: 2.051152765750885

Epoch: 78| Step: 0
Training loss: 2.1027345657348633
Validation loss: 2.0370917320251465

Epoch: 6| Step: 1
Training loss: 1.895147442817688
Validation loss: 2.0354302128156028

Epoch: 6| Step: 2
Training loss: 1.8485866785049438
Validation loss: 2.0560175577799478

Epoch: 6| Step: 3
Training loss: 1.593419075012207
Validation loss: 2.0402535994847617

Epoch: 6| Step: 4
Training loss: 1.220382809638977
Validation loss: 2.029297391573588

Epoch: 6| Step: 5
Training loss: 2.0698318481445312
Validation loss: 2.0625995794932046

Epoch: 6| Step: 6
Training loss: 1.5411124229431152
Validation loss: 2.0405717492103577

Epoch: 6| Step: 7
Training loss: 1.9965457916259766
Validation loss: 2.053799251715342

Epoch: 6| Step: 8
Training loss: 2.6098666191101074
Validation loss: 2.0262356996536255

Epoch: 6| Step: 9
Training loss: 2.002469301223755
Validation loss: 2.022125760714213

Epoch: 6| Step: 10
Training loss: 2.0306806564331055
Validation loss: 2.012407422065735

Epoch: 6| Step: 11
Training loss: 1.386191725730896
Validation loss: 2.004324734210968

Epoch: 6| Step: 12
Training loss: 2.3994927406311035
Validation loss: 2.052468001842499

Epoch: 6| Step: 13
Training loss: 1.6504571437835693
Validation loss: 2.059969425201416

Epoch: 79| Step: 0
Training loss: 2.112473726272583
Validation loss: 2.017392853895823

Epoch: 6| Step: 1
Training loss: 1.6716963052749634
Validation loss: 2.046557903289795

Epoch: 6| Step: 2
Training loss: 1.573784351348877
Validation loss: 2.0157963037490845

Epoch: 6| Step: 3
Training loss: 2.292628526687622
Validation loss: 2.0477429231007895

Epoch: 6| Step: 4
Training loss: 1.857370376586914
Validation loss: 2.0416687528292337

Epoch: 6| Step: 5
Training loss: 1.8739148378372192
Validation loss: 2.0568288564682007

Epoch: 6| Step: 6
Training loss: 1.7420648336410522
Validation loss: 2.033950984477997

Epoch: 6| Step: 7
Training loss: 2.304067611694336
Validation loss: 2.0541606346766152

Epoch: 6| Step: 8
Training loss: 0.9484702348709106
Validation loss: 2.049030125141144

Epoch: 6| Step: 9
Training loss: 1.8388671875
Validation loss: 2.044746478398641

Epoch: 6| Step: 10
Training loss: 1.2361153364181519
Validation loss: 2.0288831988970437

Epoch: 6| Step: 11
Training loss: 3.044949531555176
Validation loss: 2.0605310996373496

Epoch: 6| Step: 12
Training loss: 1.8818267583847046
Validation loss: 2.038174788157145

Epoch: 6| Step: 13
Training loss: 1.8574590682983398
Validation loss: 2.0503875811894736

Epoch: 80| Step: 0
Training loss: 1.6199923753738403
Validation loss: 2.0432233015696206

Epoch: 6| Step: 1
Training loss: 1.8497077226638794
Validation loss: 2.0687071681022644

Epoch: 6| Step: 2
Training loss: 2.414651393890381
Validation loss: 2.0537100235621133

Epoch: 6| Step: 3
Training loss: 1.8019063472747803
Validation loss: 2.0364592472712197

Epoch: 6| Step: 4
Training loss: 1.9735158681869507
Validation loss: 2.034917195638021

Epoch: 6| Step: 5
Training loss: 1.7489458322525024
Validation loss: 2.0239654382069907

Epoch: 6| Step: 6
Training loss: 2.101409912109375
Validation loss: 2.043226977189382

Epoch: 6| Step: 7
Training loss: 1.5269685983657837
Validation loss: 2.0268050829569497

Epoch: 6| Step: 8
Training loss: 1.5761346817016602
Validation loss: 2.036352972189585

Epoch: 6| Step: 9
Training loss: 2.5866613388061523
Validation loss: 2.043296496073405

Epoch: 6| Step: 10
Training loss: 1.6568264961242676
Validation loss: 2.022052605946859

Epoch: 6| Step: 11
Training loss: 2.0894718170166016
Validation loss: 2.02421369155248

Epoch: 6| Step: 12
Training loss: 1.552126407623291
Validation loss: 2.0299533804257712

Epoch: 6| Step: 13
Training loss: 1.5419869422912598
Validation loss: 2.060233155886332

Epoch: 81| Step: 0
Training loss: 1.788686752319336
Validation loss: 2.0367625753084817

Epoch: 6| Step: 1
Training loss: 1.8271536827087402
Validation loss: 2.0639734268188477

Epoch: 6| Step: 2
Training loss: 2.352254867553711
Validation loss: 2.041733145713806

Epoch: 6| Step: 3
Training loss: 1.4112589359283447
Validation loss: 2.05265611410141

Epoch: 6| Step: 4
Training loss: 2.0882835388183594
Validation loss: 2.041674534479777

Epoch: 6| Step: 5
Training loss: 1.0075767040252686
Validation loss: 2.0469968914985657

Epoch: 6| Step: 6
Training loss: 1.20607590675354
Validation loss: 2.0671951373418174

Epoch: 6| Step: 7
Training loss: 1.5702170133590698
Validation loss: 2.0423223972320557

Epoch: 6| Step: 8
Training loss: 1.730940580368042
Validation loss: 2.0552427768707275

Epoch: 6| Step: 9
Training loss: 1.5894956588745117
Validation loss: 2.0808730522791543

Epoch: 6| Step: 10
Training loss: 2.798921823501587
Validation loss: 2.046648104985555

Epoch: 6| Step: 11
Training loss: 2.4412295818328857
Validation loss: 2.028874715169271

Epoch: 6| Step: 12
Training loss: 2.218705654144287
Validation loss: 2.0437636772791543

Epoch: 6| Step: 13
Training loss: 1.8220040798187256
Validation loss: 2.0353530248006186

Epoch: 82| Step: 0
Training loss: 2.0056674480438232
Validation loss: 2.0549479921658835

Epoch: 6| Step: 1
Training loss: 1.349484920501709
Validation loss: 2.0403025150299072

Epoch: 6| Step: 2
Training loss: 2.124202251434326
Validation loss: 2.0196064114570618

Epoch: 6| Step: 3
Training loss: 1.8200796842575073
Validation loss: 2.026784817377726

Epoch: 6| Step: 4
Training loss: 1.4957493543624878
Validation loss: 2.010191023349762

Epoch: 6| Step: 5
Training loss: 2.11862850189209
Validation loss: 2.0471397638320923

Epoch: 6| Step: 6
Training loss: 2.2068564891815186
Validation loss: 2.053338905175527

Epoch: 6| Step: 7
Training loss: 1.6270655393600464
Validation loss: 2.0690088073412576

Epoch: 6| Step: 8
Training loss: 2.170046806335449
Validation loss: 2.031577785809835

Epoch: 6| Step: 9
Training loss: 1.667571783065796
Validation loss: 2.024040937423706

Epoch: 6| Step: 10
Training loss: 1.710740566253662
Validation loss: 2.029061257839203

Epoch: 6| Step: 11
Training loss: 1.8692820072174072
Validation loss: 2.0354247291882834

Epoch: 6| Step: 12
Training loss: 2.5408995151519775
Validation loss: 2.0465265115102134

Epoch: 6| Step: 13
Training loss: 1.8803914785385132
Validation loss: 2.057978868484497

Epoch: 83| Step: 0
Training loss: 2.0015816688537598
Validation loss: 2.0296873251597085

Epoch: 6| Step: 1
Training loss: 1.5277893543243408
Validation loss: 2.063945750395457

Epoch: 6| Step: 2
Training loss: 1.8340814113616943
Validation loss: 2.0244074861208596

Epoch: 6| Step: 3
Training loss: 2.143965244293213
Validation loss: 2.0484216610590615

Epoch: 6| Step: 4
Training loss: 1.8682547807693481
Validation loss: 2.020985782146454

Epoch: 6| Step: 5
Training loss: 2.2667455673217773
Validation loss: 2.0481585264205933

Epoch: 6| Step: 6
Training loss: 1.6521830558776855
Validation loss: 2.057318091392517

Epoch: 6| Step: 7
Training loss: 1.8215622901916504
Validation loss: 2.012903849283854

Epoch: 6| Step: 8
Training loss: 1.869962215423584
Validation loss: 2.023112197717031

Epoch: 6| Step: 9
Training loss: 2.1834280490875244
Validation loss: 2.0325303872426352

Epoch: 6| Step: 10
Training loss: 1.5728428363800049
Validation loss: 2.018274962902069

Epoch: 6| Step: 11
Training loss: 1.72446870803833
Validation loss: 2.0350520809491477

Epoch: 6| Step: 12
Training loss: 1.81692373752594
Validation loss: 2.0226300954818726

Epoch: 6| Step: 13
Training loss: 1.59486722946167
Validation loss: 2.040505329767863

Epoch: 84| Step: 0
Training loss: 1.8393166065216064
Validation loss: 2.037219007809957

Epoch: 6| Step: 1
Training loss: 1.5309901237487793
Validation loss: 2.070306976636251

Epoch: 6| Step: 2
Training loss: 1.0437618494033813
Validation loss: 2.046819190184275

Epoch: 6| Step: 3
Training loss: 1.5456256866455078
Validation loss: 2.07428248723348

Epoch: 6| Step: 4
Training loss: 1.9927918910980225
Validation loss: 2.0274606943130493

Epoch: 6| Step: 5
Training loss: 1.7984901666641235
Validation loss: 2.0670827627182007

Epoch: 6| Step: 6
Training loss: 1.435566782951355
Validation loss: 2.0476771195729575

Epoch: 6| Step: 7
Training loss: 1.7781107425689697
Validation loss: 2.047682801882426

Epoch: 6| Step: 8
Training loss: 2.3620901107788086
Validation loss: 2.040289501349131

Epoch: 6| Step: 9
Training loss: 1.6752572059631348
Validation loss: 2.0448455810546875

Epoch: 6| Step: 10
Training loss: 1.8289027214050293
Validation loss: 2.0502459605534873

Epoch: 6| Step: 11
Training loss: 2.5561580657958984
Validation loss: 2.043903132279714

Epoch: 6| Step: 12
Training loss: 2.921757459640503
Validation loss: 2.0315231482187905

Epoch: 6| Step: 13
Training loss: 1.5110595226287842
Validation loss: 2.0445531606674194

Epoch: 85| Step: 0
Training loss: 2.477928400039673
Validation loss: 2.047290325164795

Epoch: 6| Step: 1
Training loss: 1.5577285289764404
Validation loss: 2.029753863811493

Epoch: 6| Step: 2
Training loss: 2.4918084144592285
Validation loss: 2.0426764686902366

Epoch: 6| Step: 3
Training loss: 1.4461058378219604
Validation loss: 2.062558968861898

Epoch: 6| Step: 4
Training loss: 1.470406413078308
Validation loss: 2.0194831093152366

Epoch: 6| Step: 5
Training loss: 1.502517819404602
Validation loss: 2.0266853173573813

Epoch: 6| Step: 6
Training loss: 1.8833987712860107
Validation loss: 2.040906389554342

Epoch: 6| Step: 7
Training loss: 1.8223395347595215
Validation loss: 2.0375160574913025

Epoch: 6| Step: 8
Training loss: 2.150693893432617
Validation loss: 2.0340664188067117

Epoch: 6| Step: 9
Training loss: 2.341818332672119
Validation loss: 2.058153748512268

Epoch: 6| Step: 10
Training loss: 1.6029151678085327
Validation loss: 2.0171396732330322

Epoch: 6| Step: 11
Training loss: 2.0860629081726074
Validation loss: 2.0196063915888467

Epoch: 6| Step: 12
Training loss: 1.3088610172271729
Validation loss: 2.0284804701805115

Epoch: 6| Step: 13
Training loss: 1.5653783082962036
Validation loss: 2.0407179594039917

Epoch: 86| Step: 0
Training loss: 2.6743993759155273
Validation loss: 2.0403623978296914

Epoch: 6| Step: 1
Training loss: 1.2783145904541016
Validation loss: 2.0468207597732544

Epoch: 6| Step: 2
Training loss: 1.6539134979248047
Validation loss: 2.0590760310490928

Epoch: 6| Step: 3
Training loss: 2.4614856243133545
Validation loss: 2.0223750670750937

Epoch: 6| Step: 4
Training loss: 2.3004510402679443
Validation loss: 2.055715183417002

Epoch: 6| Step: 5
Training loss: 1.724439263343811
Validation loss: 2.0389588475227356

Epoch: 6| Step: 6
Training loss: 1.7258840799331665
Validation loss: 2.024273951848348

Epoch: 6| Step: 7
Training loss: 1.9102413654327393
Validation loss: 2.0187673767407737

Epoch: 6| Step: 8
Training loss: 1.70635187625885
Validation loss: 2.045359253883362

Epoch: 6| Step: 9
Training loss: 1.7534170150756836
Validation loss: 2.0495261549949646

Epoch: 6| Step: 10
Training loss: 1.3377914428710938
Validation loss: 2.0527260502179465

Epoch: 6| Step: 11
Training loss: 1.1162973642349243
Validation loss: 2.00433212518692

Epoch: 6| Step: 12
Training loss: 1.3802051544189453
Validation loss: 2.0340611735979715

Epoch: 6| Step: 13
Training loss: 2.50339412689209
Validation loss: 2.024377465248108

Epoch: 87| Step: 0
Training loss: 1.928523302078247
Validation loss: 2.03604257106781

Epoch: 6| Step: 1
Training loss: 1.4609578847885132
Validation loss: 2.0068628191947937

Epoch: 6| Step: 2
Training loss: 1.6625216007232666
Validation loss: 2.029337008794149

Epoch: 6| Step: 3
Training loss: 2.2967023849487305
Validation loss: 2.0281749963760376

Epoch: 6| Step: 4
Training loss: 2.435032367706299
Validation loss: 2.0411527951558432

Epoch: 6| Step: 5
Training loss: 1.557175636291504
Validation loss: 2.0375293294588723

Epoch: 6| Step: 6
Training loss: 1.079452633857727
Validation loss: 2.036793271700541

Epoch: 6| Step: 7
Training loss: 1.529911756515503
Validation loss: 2.045109232266744

Epoch: 6| Step: 8
Training loss: 1.4301856756210327
Validation loss: 2.0412869254748025

Epoch: 6| Step: 9
Training loss: 2.487574815750122
Validation loss: 2.0536354978879294

Epoch: 6| Step: 10
Training loss: 2.2344789505004883
Validation loss: 2.057453453540802

Epoch: 6| Step: 11
Training loss: 1.6827658414840698
Validation loss: 2.050908704598745

Epoch: 6| Step: 12
Training loss: 2.2865982055664062
Validation loss: 2.075604955355326

Epoch: 6| Step: 13
Training loss: 1.5736855268478394
Validation loss: 2.0467927853266397

Epoch: 88| Step: 0
Training loss: 1.8718498945236206
Validation loss: 2.0498351057370505

Epoch: 6| Step: 1
Training loss: 2.4998459815979004
Validation loss: 2.0720903476079306

Epoch: 6| Step: 2
Training loss: 0.9845865964889526
Validation loss: 2.0478198329607644

Epoch: 6| Step: 3
Training loss: 1.622507929801941
Validation loss: 2.0323225458463035

Epoch: 6| Step: 4
Training loss: 2.5712971687316895
Validation loss: 2.0286702513694763

Epoch: 6| Step: 5
Training loss: 2.5168912410736084
Validation loss: 2.054071088631948

Epoch: 6| Step: 6
Training loss: 1.8824659585952759
Validation loss: 2.0194932421048484

Epoch: 6| Step: 7
Training loss: 1.7162983417510986
Validation loss: 2.0453930099805198

Epoch: 6| Step: 8
Training loss: 1.47947096824646
Validation loss: 2.0212931434313455

Epoch: 6| Step: 9
Training loss: 2.6903414726257324
Validation loss: 2.029209474722544

Epoch: 6| Step: 10
Training loss: 1.2257459163665771
Validation loss: 2.039992094039917

Epoch: 6| Step: 11
Training loss: 1.8969831466674805
Validation loss: 2.0313800573349

Epoch: 6| Step: 12
Training loss: 1.3813679218292236
Validation loss: 2.029775698979696

Epoch: 6| Step: 13
Training loss: 1.5448081493377686
Validation loss: 2.0292411843935647

Epoch: 89| Step: 0
Training loss: 1.7099699974060059
Validation loss: 2.0448367595672607

Epoch: 6| Step: 1
Training loss: 1.522388219833374
Validation loss: 2.041577716668447

Epoch: 6| Step: 2
Training loss: 2.020205497741699
Validation loss: 2.0308480858802795

Epoch: 6| Step: 3
Training loss: 1.7392516136169434
Validation loss: 2.05142476161321

Epoch: 6| Step: 4
Training loss: 1.8428387641906738
Validation loss: 2.0479543805122375

Epoch: 6| Step: 5
Training loss: 2.4886178970336914
Validation loss: 2.0672688285509744

Epoch: 6| Step: 6
Training loss: 1.6099634170532227
Validation loss: 2.042519291241964

Epoch: 6| Step: 7
Training loss: 1.5518667697906494
Validation loss: 2.0706565181414285

Epoch: 6| Step: 8
Training loss: 2.1281018257141113
Validation loss: 2.056252876917521

Epoch: 6| Step: 9
Training loss: 2.23506236076355
Validation loss: 2.02992316087087

Epoch: 6| Step: 10
Training loss: 1.4075579643249512
Validation loss: 2.0442022681236267

Epoch: 6| Step: 11
Training loss: 1.58516526222229
Validation loss: 2.0110696951548257

Epoch: 6| Step: 12
Training loss: 1.556190013885498
Validation loss: 2.0511464277903237

Epoch: 6| Step: 13
Training loss: 1.9269944429397583
Validation loss: 2.0537261168162027

Epoch: 90| Step: 0
Training loss: 1.6252232789993286
Validation loss: 2.0432278513908386

Epoch: 6| Step: 1
Training loss: 1.9032073020935059
Validation loss: 2.033096710840861

Epoch: 6| Step: 2
Training loss: 2.11411190032959
Validation loss: 2.0124189058939614

Epoch: 6| Step: 3
Training loss: 1.3366680145263672
Validation loss: 2.020827313264211

Epoch: 6| Step: 4
Training loss: 1.199155330657959
Validation loss: 2.023152470588684

Epoch: 6| Step: 5
Training loss: 2.3286070823669434
Validation loss: 2.0160149534543357

Epoch: 6| Step: 6
Training loss: 1.6018460988998413
Validation loss: 2.038684686024984

Epoch: 6| Step: 7
Training loss: 2.330503225326538
Validation loss: 2.012536883354187

Epoch: 6| Step: 8
Training loss: 1.441776990890503
Validation loss: 2.038593570391337

Epoch: 6| Step: 9
Training loss: 1.6615558862686157
Validation loss: 2.051674803098043

Epoch: 6| Step: 10
Training loss: 1.9627728462219238
Validation loss: 2.031709353129069

Epoch: 6| Step: 11
Training loss: 1.986582636833191
Validation loss: 2.0396923820177713

Epoch: 6| Step: 12
Training loss: 1.7663805484771729
Validation loss: 2.0146695176760354

Epoch: 6| Step: 13
Training loss: 2.28743839263916
Validation loss: 2.0511536796887717

Epoch: 91| Step: 0
Training loss: 1.4371178150177002
Validation loss: 2.045885980129242

Epoch: 6| Step: 1
Training loss: 2.2261619567871094
Validation loss: 2.046933968861898

Epoch: 6| Step: 2
Training loss: 1.7758915424346924
Validation loss: 2.0523786147435508

Epoch: 6| Step: 3
Training loss: 2.3246779441833496
Validation loss: 2.078462243080139

Epoch: 6| Step: 4
Training loss: 1.5502737760543823
Validation loss: 2.046463986237844

Epoch: 6| Step: 5
Training loss: 2.1102042198181152
Validation loss: 2.037126660346985

Epoch: 6| Step: 6
Training loss: 1.657529592514038
Validation loss: 2.044197599093119

Epoch: 6| Step: 7
Training loss: 1.6994287967681885
Validation loss: 2.044420818487803

Epoch: 6| Step: 8
Training loss: 1.8249937295913696
Validation loss: 2.035616099834442

Epoch: 6| Step: 9
Training loss: 2.1473889350891113
Validation loss: 2.0679962038993835

Epoch: 6| Step: 10
Training loss: 1.834228277206421
Validation loss: 2.0423831939697266

Epoch: 6| Step: 11
Training loss: 1.4844868183135986
Validation loss: 2.046727776527405

Epoch: 6| Step: 12
Training loss: 1.8169801235198975
Validation loss: 2.062311331431071

Epoch: 6| Step: 13
Training loss: 1.2457270622253418
Validation loss: 2.022352953751882

Epoch: 92| Step: 0
Training loss: 1.4133355617523193
Validation loss: 2.0335593620936074

Epoch: 6| Step: 1
Training loss: 1.7824335098266602
Validation loss: 2.023395578066508

Epoch: 6| Step: 2
Training loss: 2.3611953258514404
Validation loss: 2.0427396098772683

Epoch: 6| Step: 3
Training loss: 1.5341256856918335
Validation loss: 2.019815226395925

Epoch: 6| Step: 4
Training loss: 2.0386884212493896
Validation loss: 2.0348950823148093

Epoch: 6| Step: 5
Training loss: 2.2639055252075195
Validation loss: 2.032309889793396

Epoch: 6| Step: 6
Training loss: 1.7203662395477295
Validation loss: 2.0335189501444497

Epoch: 6| Step: 7
Training loss: 1.375096082687378
Validation loss: 2.024064322312673

Epoch: 6| Step: 8
Training loss: 1.2919301986694336
Validation loss: 2.007152875264486

Epoch: 6| Step: 9
Training loss: 1.8181971311569214
Validation loss: 2.0299250880877175

Epoch: 6| Step: 10
Training loss: 1.8512201309204102
Validation loss: 2.0105876326560974

Epoch: 6| Step: 11
Training loss: 1.7916581630706787
Validation loss: 2.028985341389974

Epoch: 6| Step: 12
Training loss: 2.0254156589508057
Validation loss: 2.031925896803538

Epoch: 6| Step: 13
Training loss: 1.9855842590332031
Validation loss: 2.072284460067749

Epoch: 93| Step: 0
Training loss: 1.8108513355255127
Validation loss: 2.0721948742866516

Epoch: 6| Step: 1
Training loss: 2.2585244178771973
Validation loss: 2.0660259326299033

Epoch: 6| Step: 2
Training loss: 1.3714981079101562
Validation loss: 2.024845242500305

Epoch: 6| Step: 3
Training loss: 1.3984858989715576
Validation loss: 2.0432000160217285

Epoch: 6| Step: 4
Training loss: 2.0044169425964355
Validation loss: 2.0138416091601052

Epoch: 6| Step: 5
Training loss: 1.810302972793579
Validation loss: 2.0157172282536826

Epoch: 6| Step: 6
Training loss: 1.9843358993530273
Validation loss: 2.080707589785258

Epoch: 6| Step: 7
Training loss: 1.5664622783660889
Validation loss: 2.0375825564066568

Epoch: 6| Step: 8
Training loss: 1.6844308376312256
Validation loss: 2.0187034606933594

Epoch: 6| Step: 9
Training loss: 2.1878867149353027
Validation loss: 2.0302524964014688

Epoch: 6| Step: 10
Training loss: 1.3600609302520752
Validation loss: 2.0226449966430664

Epoch: 6| Step: 11
Training loss: 1.725085735321045
Validation loss: 2.020322640736898

Epoch: 6| Step: 12
Training loss: 2.2306199073791504
Validation loss: 2.028877397378286

Epoch: 6| Step: 13
Training loss: 1.5693936347961426
Validation loss: 2.0255699356396994

Epoch: 94| Step: 0
Training loss: 2.546969413757324
Validation loss: 2.0186782479286194

Epoch: 6| Step: 1
Training loss: 1.9382208585739136
Validation loss: 2.027860482533773

Epoch: 6| Step: 2
Training loss: 1.5291498899459839
Validation loss: 2.016413470109304

Epoch: 6| Step: 3
Training loss: 1.9600696563720703
Validation loss: 1.9735441009203594

Epoch: 6| Step: 4
Training loss: 1.6363029479980469
Validation loss: 2.0295110940933228

Epoch: 6| Step: 5
Training loss: 1.720454216003418
Validation loss: 2.037530700365702

Epoch: 6| Step: 6
Training loss: 1.6947211027145386
Validation loss: 2.0474167664845786

Epoch: 6| Step: 7
Training loss: 2.0638747215270996
Validation loss: 2.0626630385716758

Epoch: 6| Step: 8
Training loss: 1.7146501541137695
Validation loss: 2.074479262034098

Epoch: 6| Step: 9
Training loss: 1.0984634160995483
Validation loss: 2.085924585660299

Epoch: 6| Step: 10
Training loss: 1.9520602226257324
Validation loss: 2.0624933441480002

Epoch: 6| Step: 11
Training loss: 1.0181429386138916
Validation loss: 2.046492874622345

Epoch: 6| Step: 12
Training loss: 1.4509835243225098
Validation loss: 2.0711610118548074

Epoch: 6| Step: 13
Training loss: 2.645310878753662
Validation loss: 2.0646511713663735

Epoch: 95| Step: 0
Training loss: 1.41465425491333
Validation loss: 2.0439417362213135

Epoch: 6| Step: 1
Training loss: 1.9065344333648682
Validation loss: 2.0839013854662576

Epoch: 6| Step: 2
Training loss: 1.0979440212249756
Validation loss: 2.0244573950767517

Epoch: 6| Step: 3
Training loss: 1.6792043447494507
Validation loss: 2.0230708718299866

Epoch: 6| Step: 4
Training loss: 1.65897798538208
Validation loss: 2.0399793783823648

Epoch: 6| Step: 5
Training loss: 1.7610764503479004
Validation loss: 2.048668920993805

Epoch: 6| Step: 6
Training loss: 2.2784264087677
Validation loss: 2.0156356493631997

Epoch: 6| Step: 7
Training loss: 1.5776585340499878
Validation loss: 1.9983282287915547

Epoch: 6| Step: 8
Training loss: 2.09183931350708
Validation loss: 2.029433329900106

Epoch: 6| Step: 9
Training loss: 1.1359758377075195
Validation loss: 2.0189186334609985

Epoch: 6| Step: 10
Training loss: 1.6625174283981323
Validation loss: 2.025642991065979

Epoch: 6| Step: 11
Training loss: 2.3222973346710205
Validation loss: 2.027477741241455

Epoch: 6| Step: 12
Training loss: 2.1067147254943848
Validation loss: 2.026077846686045

Epoch: 6| Step: 13
Training loss: 2.4575510025024414
Validation loss: 2.0569458405176797

Epoch: 96| Step: 0
Training loss: 1.4460997581481934
Validation loss: 2.036417285601298

Epoch: 6| Step: 1
Training loss: 2.0187606811523438
Validation loss: 2.0521614948908486

Epoch: 6| Step: 2
Training loss: 1.9126381874084473
Validation loss: 2.028072714805603

Epoch: 6| Step: 3
Training loss: 2.2950403690338135
Validation loss: 2.068849583466848

Epoch: 6| Step: 4
Training loss: 1.9614346027374268
Validation loss: 2.047815183798472

Epoch: 6| Step: 5
Training loss: 2.062087297439575
Validation loss: 2.051960905392965

Epoch: 6| Step: 6
Training loss: 1.6669788360595703
Validation loss: 2.0412426590919495

Epoch: 6| Step: 7
Training loss: 1.9216322898864746
Validation loss: 2.0646721522013345

Epoch: 6| Step: 8
Training loss: 1.4727318286895752
Validation loss: 2.0574461619059243

Epoch: 6| Step: 9
Training loss: 1.8468098640441895
Validation loss: 2.061911920706431

Epoch: 6| Step: 10
Training loss: 1.5338516235351562
Validation loss: 2.048928916454315

Epoch: 6| Step: 11
Training loss: 1.9379281997680664
Validation loss: 2.0447479089101157

Epoch: 6| Step: 12
Training loss: 1.6897417306900024
Validation loss: 2.028252383073171

Epoch: 6| Step: 13
Training loss: 1.268283486366272
Validation loss: 2.0457588831583657

Epoch: 97| Step: 0
Training loss: 1.6884095668792725
Validation loss: 2.0177972515424094

Epoch: 6| Step: 1
Training loss: 1.9473170042037964
Validation loss: 2.029521564642588

Epoch: 6| Step: 2
Training loss: 1.770632028579712
Validation loss: 2.0242175261179605

Epoch: 6| Step: 3
Training loss: 2.148132562637329
Validation loss: 2.026018798351288

Epoch: 6| Step: 4
Training loss: 1.3911200761795044
Validation loss: 2.051743964354197

Epoch: 6| Step: 5
Training loss: 1.3572354316711426
Validation loss: 2.0056928594907126

Epoch: 6| Step: 6
Training loss: 2.3935163021087646
Validation loss: 2.02238537867864

Epoch: 6| Step: 7
Training loss: 1.614184856414795
Validation loss: 2.0090096592903137

Epoch: 6| Step: 8
Training loss: 1.7527213096618652
Validation loss: 2.039175570011139

Epoch: 6| Step: 9
Training loss: 1.6933040618896484
Validation loss: 2.0120665431022644

Epoch: 6| Step: 10
Training loss: 1.759273886680603
Validation loss: 2.0416495402654014

Epoch: 6| Step: 11
Training loss: 1.7303502559661865
Validation loss: 2.0029390454292297

Epoch: 6| Step: 12
Training loss: 1.956301212310791
Validation loss: 2.0430359641710916

Epoch: 6| Step: 13
Training loss: 1.5821713209152222
Validation loss: 2.010658939679464

Epoch: 98| Step: 0
Training loss: 2.259591817855835
Validation loss: 2.0375667413075766

Epoch: 6| Step: 1
Training loss: 1.6938061714172363
Validation loss: 2.06441201766332

Epoch: 6| Step: 2
Training loss: 1.4474503993988037
Validation loss: 2.022036929925283

Epoch: 6| Step: 3
Training loss: 1.8005492687225342
Validation loss: 2.0770463148752847

Epoch: 6| Step: 4
Training loss: 1.1421104669570923
Validation loss: 2.083694040775299

Epoch: 6| Step: 5
Training loss: 1.9128870964050293
Validation loss: 2.0620278120040894

Epoch: 6| Step: 6
Training loss: 1.824519157409668
Validation loss: 2.067061960697174

Epoch: 6| Step: 7
Training loss: 1.597371220588684
Validation loss: 2.066823681195577

Epoch: 6| Step: 8
Training loss: 1.7007842063903809
Validation loss: 2.04833577076594

Epoch: 6| Step: 9
Training loss: 1.860490322113037
Validation loss: 2.038067658742269

Epoch: 6| Step: 10
Training loss: 2.150613784790039
Validation loss: 2.024943192799886

Epoch: 6| Step: 11
Training loss: 1.5257461071014404
Validation loss: 2.0548351208368936

Epoch: 6| Step: 12
Training loss: 1.8039554357528687
Validation loss: 2.002846121788025

Epoch: 6| Step: 13
Training loss: 1.8330639600753784
Validation loss: 2.040024161338806

Epoch: 99| Step: 0
Training loss: 1.8297488689422607
Validation loss: 2.0240941445032754

Epoch: 6| Step: 1
Training loss: 1.68526291847229
Validation loss: 2.042191127936045

Epoch: 6| Step: 2
Training loss: 1.3538451194763184
Validation loss: 1.990809937318166

Epoch: 6| Step: 3
Training loss: 2.1020145416259766
Validation loss: 2.000890552997589

Epoch: 6| Step: 4
Training loss: 1.9022040367126465
Validation loss: 2.017921586831411

Epoch: 6| Step: 5
Training loss: 1.8396052122116089
Validation loss: 1.9900456070899963

Epoch: 6| Step: 6
Training loss: 1.6185238361358643
Validation loss: 2.0497952103614807

Epoch: 6| Step: 7
Training loss: 1.821854591369629
Validation loss: 2.00448348124822

Epoch: 6| Step: 8
Training loss: 2.461199998855591
Validation loss: 2.017249663670858

Epoch: 6| Step: 9
Training loss: 1.121351718902588
Validation loss: 2.0410910646120706

Epoch: 6| Step: 10
Training loss: 1.6004939079284668
Validation loss: 2.049607833226522

Epoch: 6| Step: 11
Training loss: 2.0101914405822754
Validation loss: 2.058051029841105

Epoch: 6| Step: 12
Training loss: 1.4634989500045776
Validation loss: 2.0241161584854126

Epoch: 6| Step: 13
Training loss: 1.5644265413284302
Validation loss: 2.014513293902079

Epoch: 100| Step: 0
Training loss: 1.8034508228302002
Validation loss: 2.034743289152781

Epoch: 6| Step: 1
Training loss: 2.2011053562164307
Validation loss: 2.0454224944114685

Epoch: 6| Step: 2
Training loss: 1.725642442703247
Validation loss: 2.0407665371894836

Epoch: 6| Step: 3
Training loss: 1.7729427814483643
Validation loss: 2.0450089375178018

Epoch: 6| Step: 4
Training loss: 1.2900301218032837
Validation loss: 2.060166617234548

Epoch: 6| Step: 5
Training loss: 1.598152995109558
Validation loss: 2.0621439019838967

Epoch: 6| Step: 6
Training loss: 1.6337240934371948
Validation loss: 2.0626598795255027

Epoch: 6| Step: 7
Training loss: 1.6685469150543213
Validation loss: 2.0537437995274863

Epoch: 6| Step: 8
Training loss: 1.5408848524093628
Validation loss: 2.0655969381332397

Epoch: 6| Step: 9
Training loss: 1.8476369380950928
Validation loss: 2.0632326006889343

Epoch: 6| Step: 10
Training loss: 2.029648780822754
Validation loss: 2.060536285241445

Epoch: 6| Step: 11
Training loss: 1.7260103225708008
Validation loss: 2.0657421946525574

Epoch: 6| Step: 12
Training loss: 2.179119110107422
Validation loss: 2.0388167103131614

Epoch: 6| Step: 13
Training loss: 1.5080090761184692
Validation loss: 2.0433755914370217

Epoch: 101| Step: 0
Training loss: 1.5179352760314941
Validation loss: 2.0351772705713906

Epoch: 6| Step: 1
Training loss: 1.9523770809173584
Validation loss: 2.0315496722857156

Epoch: 6| Step: 2
Training loss: 1.6849210262298584
Validation loss: 2.044832706451416

Epoch: 6| Step: 3
Training loss: 1.5403132438659668
Validation loss: 2.029416839281718

Epoch: 6| Step: 4
Training loss: 1.832501769065857
Validation loss: 2.027757247289022

Epoch: 6| Step: 5
Training loss: 1.7263801097869873
Validation loss: 2.0298332373301187

Epoch: 6| Step: 6
Training loss: 1.7370308637619019
Validation loss: 2.0339661836624146

Epoch: 6| Step: 7
Training loss: 2.0300049781799316
Validation loss: 2.0322179198265076

Epoch: 6| Step: 8
Training loss: 1.63985013961792
Validation loss: 2.049065808455149

Epoch: 6| Step: 9
Training loss: 1.2054669857025146
Validation loss: 2.0491080284118652

Epoch: 6| Step: 10
Training loss: 2.4203310012817383
Validation loss: 2.046247124671936

Epoch: 6| Step: 11
Training loss: 1.4964478015899658
Validation loss: 2.0172210137049356

Epoch: 6| Step: 12
Training loss: 1.687300205230713
Validation loss: 2.0411974787712097

Epoch: 6| Step: 13
Training loss: 1.7013654708862305
Validation loss: 2.0432667334874473

Epoch: 102| Step: 0
Training loss: 1.22794771194458
Validation loss: 2.0503275791803994

Epoch: 6| Step: 1
Training loss: 1.6289117336273193
Validation loss: 2.093218763669332

Epoch: 6| Step: 2
Training loss: 1.9610682725906372
Validation loss: 2.0935166080792746

Epoch: 6| Step: 3
Training loss: 1.8211889266967773
Validation loss: 2.13704506556193

Epoch: 6| Step: 4
Training loss: 2.4118738174438477
Validation loss: 2.1108179092407227

Epoch: 6| Step: 5
Training loss: 1.8511130809783936
Validation loss: 2.0870853265126548

Epoch: 6| Step: 6
Training loss: 1.397159218788147
Validation loss: 2.0574891567230225

Epoch: 6| Step: 7
Training loss: 2.3375468254089355
Validation loss: 2.0194379885991416

Epoch: 6| Step: 8
Training loss: 1.7837661504745483
Validation loss: 2.0251025358835855

Epoch: 6| Step: 9
Training loss: 1.4982593059539795
Validation loss: 2.0468829870224

Epoch: 6| Step: 10
Training loss: 1.7941865921020508
Validation loss: 2.057519535223643

Epoch: 6| Step: 11
Training loss: 1.6976579427719116
Validation loss: 2.025754372278849

Epoch: 6| Step: 12
Training loss: 1.4830809831619263
Validation loss: 2.056345363457998

Epoch: 6| Step: 13
Training loss: 1.9714224338531494
Validation loss: 2.0392542680104575

Epoch: 103| Step: 0
Training loss: 1.7860366106033325
Validation loss: 2.063227951526642

Epoch: 6| Step: 1
Training loss: 2.172886371612549
Validation loss: 2.0700013637542725

Epoch: 6| Step: 2
Training loss: 2.0801186561584473
Validation loss: 2.056890924771627

Epoch: 6| Step: 3
Training loss: 1.7061033248901367
Validation loss: 2.035097897052765

Epoch: 6| Step: 4
Training loss: 1.1199321746826172
Validation loss: 2.0426964163780212

Epoch: 6| Step: 5
Training loss: 2.202955484390259
Validation loss: 2.022389014561971

Epoch: 6| Step: 6
Training loss: 1.106175422668457
Validation loss: 2.0246415734291077

Epoch: 6| Step: 7
Training loss: 1.6896162033081055
Validation loss: 2.036293109258016

Epoch: 6| Step: 8
Training loss: 1.6033382415771484
Validation loss: 2.027643918991089

Epoch: 6| Step: 9
Training loss: 1.1227868795394897
Validation loss: 2.050658424695333

Epoch: 6| Step: 10
Training loss: 1.9208954572677612
Validation loss: 2.040821293989817

Epoch: 6| Step: 11
Training loss: 1.824702501296997
Validation loss: 2.0640554229418435

Epoch: 6| Step: 12
Training loss: 2.0036401748657227
Validation loss: 2.0634986758232117

Epoch: 6| Step: 13
Training loss: 1.9038474559783936
Validation loss: 2.0732091069221497

Epoch: 104| Step: 0
Training loss: 1.9183766841888428
Validation loss: 2.052626132965088

Epoch: 6| Step: 1
Training loss: 1.530806303024292
Validation loss: 2.053391714890798

Epoch: 6| Step: 2
Training loss: 1.2511816024780273
Validation loss: 2.0195983250935874

Epoch: 6| Step: 3
Training loss: 1.7330665588378906
Validation loss: 2.0242108503977456

Epoch: 6| Step: 4
Training loss: 1.7215442657470703
Validation loss: 2.0104577938715615

Epoch: 6| Step: 5
Training loss: 1.9214023351669312
Validation loss: 2.0258945425351462

Epoch: 6| Step: 6
Training loss: 1.6506891250610352
Validation loss: 2.0133134921391806

Epoch: 6| Step: 7
Training loss: 1.147199034690857
Validation loss: 2.017137269179026

Epoch: 6| Step: 8
Training loss: 1.5632448196411133
Validation loss: 2.064486483732859

Epoch: 6| Step: 9
Training loss: 2.0827622413635254
Validation loss: 1.9948226014773052

Epoch: 6| Step: 10
Training loss: 1.7554830312728882
Validation loss: 2.0419729153315225

Epoch: 6| Step: 11
Training loss: 1.5421364307403564
Validation loss: 2.014238198598226

Epoch: 6| Step: 12
Training loss: 2.269261360168457
Validation loss: 2.02994312842687

Epoch: 6| Step: 13
Training loss: 1.8252489566802979
Validation loss: 2.0279924472173056

Epoch: 105| Step: 0
Training loss: 1.5117793083190918
Validation loss: 2.058686455090841

Epoch: 6| Step: 1
Training loss: 1.8922300338745117
Validation loss: 2.073785146077474

Epoch: 6| Step: 2
Training loss: 1.4096713066101074
Validation loss: 2.0674391984939575

Epoch: 6| Step: 3
Training loss: 1.8783327341079712
Validation loss: 2.0955342849095664

Epoch: 6| Step: 4
Training loss: 1.3911266326904297
Validation loss: 2.012579917907715

Epoch: 6| Step: 5
Training loss: 1.5363569259643555
Validation loss: 2.055743992328644

Epoch: 6| Step: 6
Training loss: 1.6624462604522705
Validation loss: 2.0470078587532043

Epoch: 6| Step: 7
Training loss: 1.932337760925293
Validation loss: 2.0313810110092163

Epoch: 6| Step: 8
Training loss: 1.817725658416748
Validation loss: 2.0358921686808267

Epoch: 6| Step: 9
Training loss: 1.229972243309021
Validation loss: 2.036713163057963

Epoch: 6| Step: 10
Training loss: 1.9202085733413696
Validation loss: 2.030341843763987

Epoch: 6| Step: 11
Training loss: 1.7442753314971924
Validation loss: 2.0303537448247275

Epoch: 6| Step: 12
Training loss: 2.0900816917419434
Validation loss: 2.0415963927904763

Epoch: 6| Step: 13
Training loss: 2.4517385959625244
Validation loss: 2.032471219698588

Epoch: 106| Step: 0
Training loss: 2.0344791412353516
Validation loss: 2.039330760637919

Epoch: 6| Step: 1
Training loss: 1.0656670331954956
Validation loss: 2.0103288094202676

Epoch: 6| Step: 2
Training loss: 1.564395785331726
Validation loss: 2.064898729324341

Epoch: 6| Step: 3
Training loss: 1.7352957725524902
Validation loss: 2.0377944707870483

Epoch: 6| Step: 4
Training loss: 1.9036728143692017
Validation loss: 2.055104394753774

Epoch: 6| Step: 5
Training loss: 1.3653275966644287
Validation loss: 2.043082336584727

Epoch: 6| Step: 6
Training loss: 1.9326837062835693
Validation loss: 2.1155771215756736

Epoch: 6| Step: 7
Training loss: 1.5291187763214111
Validation loss: 2.0518823067347207

Epoch: 6| Step: 8
Training loss: 1.7272217273712158
Validation loss: 2.0182252724965415

Epoch: 6| Step: 9
Training loss: 2.1553592681884766
Validation loss: 2.0560023188591003

Epoch: 6| Step: 10
Training loss: 1.5425264835357666
Validation loss: 2.040974497795105

Epoch: 6| Step: 11
Training loss: 1.961611270904541
Validation loss: 2.021660486857096

Epoch: 6| Step: 12
Training loss: 1.7183852195739746
Validation loss: 2.0410526593526206

Epoch: 6| Step: 13
Training loss: 1.6584452390670776
Validation loss: 2.0272584358851113

Epoch: 107| Step: 0
Training loss: 1.4896217584609985
Validation loss: 2.0494569738705954

Epoch: 6| Step: 1
Training loss: 1.8361016511917114
Validation loss: 2.039718985557556

Epoch: 6| Step: 2
Training loss: 1.3232457637786865
Validation loss: 2.069444020589193

Epoch: 6| Step: 3
Training loss: 1.6937298774719238
Validation loss: 2.052658200263977

Epoch: 6| Step: 4
Training loss: 1.2664930820465088
Validation loss: 2.0544522404670715

Epoch: 6| Step: 5
Training loss: 1.8405076265335083
Validation loss: 2.028754015763601

Epoch: 6| Step: 6
Training loss: 1.812741994857788
Validation loss: 2.052747964859009

Epoch: 6| Step: 7
Training loss: 1.3054754734039307
Validation loss: 2.061937948067983

Epoch: 6| Step: 8
Training loss: 1.0361405611038208
Validation loss: 2.0344976782798767

Epoch: 6| Step: 9
Training loss: 2.5520989894866943
Validation loss: 2.0318788488705954

Epoch: 6| Step: 10
Training loss: 1.299684762954712
Validation loss: 2.0538469155629477

Epoch: 6| Step: 11
Training loss: 1.3820185661315918
Validation loss: 2.0507533152898154

Epoch: 6| Step: 12
Training loss: 1.794084072113037
Validation loss: 2.032479206720988

Epoch: 6| Step: 13
Training loss: 2.576286792755127
Validation loss: 2.033004879951477

Epoch: 108| Step: 0
Training loss: 1.3962388038635254
Validation loss: 2.019506295522054

Epoch: 6| Step: 1
Training loss: 2.5074515342712402
Validation loss: 2.004379947980245

Epoch: 6| Step: 2
Training loss: 2.009284734725952
Validation loss: 2.047885219256083

Epoch: 6| Step: 3
Training loss: 2.0294737815856934
Validation loss: 2.0315291484196982

Epoch: 6| Step: 4
Training loss: 1.376014232635498
Validation loss: 2.028414487838745

Epoch: 6| Step: 5
Training loss: 0.7475281953811646
Validation loss: 2.041700998942057

Epoch: 6| Step: 6
Training loss: 1.6322472095489502
Validation loss: 2.0203473766644797

Epoch: 6| Step: 7
Training loss: 1.2111003398895264
Validation loss: 2.039713223775228

Epoch: 6| Step: 8
Training loss: 1.7392454147338867
Validation loss: 2.0351883371671042

Epoch: 6| Step: 9
Training loss: 2.18180251121521
Validation loss: 2.0291264255841575

Epoch: 6| Step: 10
Training loss: 1.2410261631011963
Validation loss: 2.078137973944346

Epoch: 6| Step: 11
Training loss: 2.0637459754943848
Validation loss: 2.0493996143341064

Epoch: 6| Step: 12
Training loss: 1.6366183757781982
Validation loss: 2.1080285708109536

Epoch: 6| Step: 13
Training loss: 1.5132710933685303
Validation loss: 2.086274743080139

Epoch: 109| Step: 0
Training loss: 1.7577810287475586
Validation loss: 2.0902649958928428

Epoch: 6| Step: 1
Training loss: 2.013620376586914
Validation loss: 2.038954198360443

Epoch: 6| Step: 2
Training loss: 0.9351149797439575
Validation loss: 2.054606556892395

Epoch: 6| Step: 3
Training loss: 1.7706784009933472
Validation loss: 2.0641932686169944

Epoch: 6| Step: 4
Training loss: 1.4984097480773926
Validation loss: 2.0644283294677734

Epoch: 6| Step: 5
Training loss: 1.9251335859298706
Validation loss: 2.0367834766705832

Epoch: 6| Step: 6
Training loss: 1.8249919414520264
Validation loss: 2.026283860206604

Epoch: 6| Step: 7
Training loss: 1.5401339530944824
Validation loss: 2.0350631276766458

Epoch: 6| Step: 8
Training loss: 2.144184112548828
Validation loss: 2.0166109204292297

Epoch: 6| Step: 9
Training loss: 1.9953389167785645
Validation loss: 2.051318645477295

Epoch: 6| Step: 10
Training loss: 1.2971198558807373
Validation loss: 2.0486615697542825

Epoch: 6| Step: 11
Training loss: 1.1654855012893677
Validation loss: 2.0207260251045227

Epoch: 6| Step: 12
Training loss: 1.5952584743499756
Validation loss: 2.0341291228930154

Epoch: 6| Step: 13
Training loss: 1.750779390335083
Validation loss: 2.00367138783137

Epoch: 110| Step: 0
Training loss: 1.4491209983825684
Validation loss: 2.074114461739858

Epoch: 6| Step: 1
Training loss: 1.2906265258789062
Validation loss: 2.0408039887746177

Epoch: 6| Step: 2
Training loss: 1.9521515369415283
Validation loss: 2.103978753089905

Epoch: 6| Step: 3
Training loss: 2.54801344871521
Validation loss: 2.113712728023529

Epoch: 6| Step: 4
Training loss: 1.5937962532043457
Validation loss: 2.0917684038480124

Epoch: 6| Step: 5
Training loss: 1.4802355766296387
Validation loss: 2.0655407309532166

Epoch: 6| Step: 6
Training loss: 1.7352004051208496
Validation loss: 2.0916941165924072

Epoch: 6| Step: 7
Training loss: 1.8792861700057983
Validation loss: 2.085436979929606

Epoch: 6| Step: 8
Training loss: 1.5197166204452515
Validation loss: 2.0853720903396606

Epoch: 6| Step: 9
Training loss: 1.7811919450759888
Validation loss: 2.0179956356684365

Epoch: 6| Step: 10
Training loss: 1.4788808822631836
Validation loss: 2.079781492551168

Epoch: 6| Step: 11
Training loss: 1.480068325996399
Validation loss: 2.0655861496925354

Epoch: 6| Step: 12
Training loss: 1.18101966381073
Validation loss: 2.041288594404856

Epoch: 6| Step: 13
Training loss: 1.8267481327056885
Validation loss: 2.037626326084137

Epoch: 111| Step: 0
Training loss: 1.6925679445266724
Validation loss: 2.039324919382731

Epoch: 6| Step: 1
Training loss: 1.8365005254745483
Validation loss: 2.061298112074534

Epoch: 6| Step: 2
Training loss: 1.4347639083862305
Validation loss: 2.0287304520606995

Epoch: 6| Step: 3
Training loss: 1.258709192276001
Validation loss: 2.024407227834066

Epoch: 6| Step: 4
Training loss: 1.611808180809021
Validation loss: 2.02878608306249

Epoch: 6| Step: 5
Training loss: 2.1800642013549805
Validation loss: 2.0359493692715964

Epoch: 6| Step: 6
Training loss: 1.617724895477295
Validation loss: 2.0358648101488748

Epoch: 6| Step: 7
Training loss: 1.9516632556915283
Validation loss: 2.0360554854075112

Epoch: 6| Step: 8
Training loss: 1.290234088897705
Validation loss: 2.0552735726038613

Epoch: 6| Step: 9
Training loss: 1.7196651697158813
Validation loss: 2.027434527873993

Epoch: 6| Step: 10
Training loss: 2.2648658752441406
Validation loss: 2.0070661703745523

Epoch: 6| Step: 11
Training loss: 1.3407888412475586
Validation loss: 2.076772133509318

Epoch: 6| Step: 12
Training loss: 1.4647462368011475
Validation loss: 2.0463664134343467

Epoch: 6| Step: 13
Training loss: 1.476001262664795
Validation loss: 2.0164854725201926

Epoch: 112| Step: 0
Training loss: 2.4951887130737305
Validation loss: 2.0345064798990884

Epoch: 6| Step: 1
Training loss: 2.0330076217651367
Validation loss: 2.0679145654042563

Epoch: 6| Step: 2
Training loss: 1.0581028461456299
Validation loss: 2.0474469860394797

Epoch: 6| Step: 3
Training loss: 1.4629902839660645
Validation loss: 2.0208670099576316

Epoch: 6| Step: 4
Training loss: 1.6906123161315918
Validation loss: 2.023101250330607

Epoch: 6| Step: 5
Training loss: 2.129258871078491
Validation loss: 2.0120696425437927

Epoch: 6| Step: 6
Training loss: 1.5555399656295776
Validation loss: 2.0407832860946655

Epoch: 6| Step: 7
Training loss: 1.6643750667572021
Validation loss: 2.0226263801256814

Epoch: 6| Step: 8
Training loss: 1.8720061779022217
Validation loss: 2.015809416770935

Epoch: 6| Step: 9
Training loss: 1.5696172714233398
Validation loss: 2.054286777973175

Epoch: 6| Step: 10
Training loss: 1.0879228115081787
Validation loss: 2.071964144706726

Epoch: 6| Step: 11
Training loss: 1.2364587783813477
Validation loss: 2.051404436429342

Epoch: 6| Step: 12
Training loss: 1.4867072105407715
Validation loss: 2.0299734075864158

Epoch: 6| Step: 13
Training loss: 1.5356981754302979
Validation loss: 2.0382071336110434

Epoch: 113| Step: 0
Training loss: 1.7988711595535278
Validation loss: 2.0602845748265586

Epoch: 6| Step: 1
Training loss: 1.0259883403778076
Validation loss: 2.0979764064153037

Epoch: 6| Step: 2
Training loss: 1.7825000286102295
Validation loss: 2.034425139427185

Epoch: 6| Step: 3
Training loss: 1.365807294845581
Validation loss: 2.003208577632904

Epoch: 6| Step: 4
Training loss: 1.9343867301940918
Validation loss: 2.0601822336514792

Epoch: 6| Step: 5
Training loss: 1.3700096607208252
Validation loss: 2.073017100493113

Epoch: 6| Step: 6
Training loss: 2.009951114654541
Validation loss: 2.0600780049959817

Epoch: 6| Step: 7
Training loss: 1.606197714805603
Validation loss: 2.037955641746521

Epoch: 6| Step: 8
Training loss: 1.260679006576538
Validation loss: 2.0218174854914346

Epoch: 6| Step: 9
Training loss: 1.3348934650421143
Validation loss: 2.031345029671987

Epoch: 6| Step: 10
Training loss: 1.7540788650512695
Validation loss: 2.067167421181997

Epoch: 6| Step: 11
Training loss: 1.6303073167800903
Validation loss: 2.0384960174560547

Epoch: 6| Step: 12
Training loss: 1.8937976360321045
Validation loss: 2.0550118684768677

Epoch: 6| Step: 13
Training loss: 1.9404836893081665
Validation loss: 2.057430903116862

Epoch: 114| Step: 0
Training loss: 1.5508556365966797
Validation loss: 2.0618903636932373

Epoch: 6| Step: 1
Training loss: 1.4722671508789062
Validation loss: 2.0879666407903037

Epoch: 6| Step: 2
Training loss: 0.9334197044372559
Validation loss: 2.020749568939209

Epoch: 6| Step: 3
Training loss: 1.260796070098877
Validation loss: 2.0528182983398438

Epoch: 6| Step: 4
Training loss: 2.1343252658843994
Validation loss: 2.071720997492472

Epoch: 6| Step: 5
Training loss: 1.8657268285751343
Validation loss: 2.0896008213361106

Epoch: 6| Step: 6
Training loss: 1.788131833076477
Validation loss: 2.050001859664917

Epoch: 6| Step: 7
Training loss: 1.394044041633606
Validation loss: 2.0661044120788574

Epoch: 6| Step: 8
Training loss: 1.6340126991271973
Validation loss: 2.058799763520559

Epoch: 6| Step: 9
Training loss: 1.4962377548217773
Validation loss: 2.059004008769989

Epoch: 6| Step: 10
Training loss: 1.9198254346847534
Validation loss: 2.007206360499064

Epoch: 6| Step: 11
Training loss: 1.2267450094223022
Validation loss: 2.016970972220103

Epoch: 6| Step: 12
Training loss: 1.7017512321472168
Validation loss: 2.0527674555778503

Epoch: 6| Step: 13
Training loss: 2.041503667831421
Validation loss: 2.0255384047826133

Epoch: 115| Step: 0
Training loss: 1.8606231212615967
Validation loss: 1.9954630136489868

Epoch: 6| Step: 1
Training loss: 1.9961881637573242
Validation loss: 1.9969297250111897

Epoch: 6| Step: 2
Training loss: 1.6318864822387695
Validation loss: 2.014166255791982

Epoch: 6| Step: 3
Training loss: 1.838577389717102
Validation loss: 2.0317229628562927

Epoch: 6| Step: 4
Training loss: 1.292956829071045
Validation loss: 2.0016911029815674

Epoch: 6| Step: 5
Training loss: 1.84165620803833
Validation loss: 2.043320377667745

Epoch: 6| Step: 6
Training loss: 1.440163493156433
Validation loss: 2.006138026714325

Epoch: 6| Step: 7
Training loss: 1.5163328647613525
Validation loss: 2.034124175707499

Epoch: 6| Step: 8
Training loss: 1.457116723060608
Validation loss: 2.0450517535209656

Epoch: 6| Step: 9
Training loss: 1.4574068784713745
Validation loss: 2.098439633846283

Epoch: 6| Step: 10
Training loss: 2.0113892555236816
Validation loss: 2.0939459005991616

Epoch: 6| Step: 11
Training loss: 1.6284000873565674
Validation loss: 2.0987480878829956

Epoch: 6| Step: 12
Training loss: 1.764167070388794
Validation loss: 2.1114971240361533

Epoch: 6| Step: 13
Training loss: 1.1007848978042603
Validation loss: 2.1187471548716226

Epoch: 116| Step: 0
Training loss: 1.2253236770629883
Validation loss: 2.0898481607437134

Epoch: 6| Step: 1
Training loss: 1.1677511930465698
Validation loss: 2.0424312154452005

Epoch: 6| Step: 2
Training loss: 1.233271837234497
Validation loss: 2.0343328714370728

Epoch: 6| Step: 3
Training loss: 1.3022825717926025
Validation loss: 2.0141236782073975

Epoch: 6| Step: 4
Training loss: 2.350403308868408
Validation loss: 2.054854929447174

Epoch: 6| Step: 5
Training loss: 2.0059380531311035
Validation loss: 2.005940000216166

Epoch: 6| Step: 6
Training loss: 1.1176941394805908
Validation loss: 2.025347113609314

Epoch: 6| Step: 7
Training loss: 2.336297035217285
Validation loss: 2.0328856706619263

Epoch: 6| Step: 8
Training loss: 0.9084551334381104
Validation loss: 1.9987183610598247

Epoch: 6| Step: 9
Training loss: 1.9478100538253784
Validation loss: 2.027709941069285

Epoch: 6| Step: 10
Training loss: 1.8708359003067017
Validation loss: 2.0300471981366477

Epoch: 6| Step: 11
Training loss: 2.015509605407715
Validation loss: 2.012696325778961

Epoch: 6| Step: 12
Training loss: 1.5455453395843506
Validation loss: 2.040008028348287

Epoch: 6| Step: 13
Training loss: 1.226001262664795
Validation loss: 2.054275631904602

Epoch: 117| Step: 0
Training loss: 1.6115233898162842
Validation loss: 2.0958721041679382

Epoch: 6| Step: 1
Training loss: 1.2788119316101074
Validation loss: 2.0718039870262146

Epoch: 6| Step: 2
Training loss: 2.0887482166290283
Validation loss: 2.047246774037679

Epoch: 6| Step: 3
Training loss: 1.9481201171875
Validation loss: 2.101506451765696

Epoch: 6| Step: 4
Training loss: 2.162184715270996
Validation loss: 2.0920196771621704

Epoch: 6| Step: 5
Training loss: 1.9600746631622314
Validation loss: 2.077724516391754

Epoch: 6| Step: 6
Training loss: 1.7035771608352661
Validation loss: 2.0806838274002075

Epoch: 6| Step: 7
Training loss: 1.4284446239471436
Validation loss: 2.0644718607266745

Epoch: 6| Step: 8
Training loss: 1.169774055480957
Validation loss: 2.074074467023214

Epoch: 6| Step: 9
Training loss: 1.6581772565841675
Validation loss: 2.0463322401046753

Epoch: 6| Step: 10
Training loss: 1.429979681968689
Validation loss: 2.0936700105667114

Epoch: 6| Step: 11
Training loss: 1.2949544191360474
Validation loss: 2.055746336778005

Epoch: 6| Step: 12
Training loss: 1.418699860572815
Validation loss: 2.0222889184951782

Epoch: 6| Step: 13
Training loss: 1.332433819770813
Validation loss: 2.0110045671463013

Epoch: 118| Step: 0
Training loss: 2.115159511566162
Validation loss: 2.030786414941152

Epoch: 6| Step: 1
Training loss: 1.2137868404388428
Validation loss: 2.0114460786183677

Epoch: 6| Step: 2
Training loss: 1.6310017108917236
Validation loss: 1.997993032137553

Epoch: 6| Step: 3
Training loss: 0.8442091941833496
Validation loss: 2.0572357177734375

Epoch: 6| Step: 4
Training loss: 1.4851347208023071
Validation loss: 2.042669177055359

Epoch: 6| Step: 5
Training loss: 1.323488473892212
Validation loss: 2.0192321141560874

Epoch: 6| Step: 6
Training loss: 1.820652961730957
Validation loss: 2.0551483432451882

Epoch: 6| Step: 7
Training loss: 2.084933042526245
Validation loss: 2.029223620891571

Epoch: 6| Step: 8
Training loss: 1.732198715209961
Validation loss: 2.065984785556793

Epoch: 6| Step: 9
Training loss: 2.04380464553833
Validation loss: 2.0478449861208596

Epoch: 6| Step: 10
Training loss: 1.105973243713379
Validation loss: 2.057136078675588

Epoch: 6| Step: 11
Training loss: 1.5333094596862793
Validation loss: 2.047063628832499

Epoch: 6| Step: 12
Training loss: 1.3338028192520142
Validation loss: 2.083368400732676

Epoch: 6| Step: 13
Training loss: 1.4252331256866455
Validation loss: 2.0680407285690308

Epoch: 119| Step: 0
Training loss: 1.1090034246444702
Validation loss: 2.0507830580075583

Epoch: 6| Step: 1
Training loss: 1.2163052558898926
Validation loss: 2.0309051275253296

Epoch: 6| Step: 2
Training loss: 1.9855546951293945
Validation loss: 2.044091820716858

Epoch: 6| Step: 3
Training loss: 2.2078213691711426
Validation loss: 2.038940727710724

Epoch: 6| Step: 4
Training loss: 1.9360496997833252
Validation loss: 2.0398254990577698

Epoch: 6| Step: 5
Training loss: 1.4624360799789429
Validation loss: 2.0548418760299683

Epoch: 6| Step: 6
Training loss: 2.011593818664551
Validation loss: 2.0534842014312744

Epoch: 6| Step: 7
Training loss: 1.3998712301254272
Validation loss: 2.0590531627337136

Epoch: 6| Step: 8
Training loss: 1.848160743713379
Validation loss: 2.0561288595199585

Epoch: 6| Step: 9
Training loss: 1.4086743593215942
Validation loss: 2.040014863014221

Epoch: 6| Step: 10
Training loss: 2.174323081970215
Validation loss: 2.0061248143514

Epoch: 6| Step: 11
Training loss: 1.320422649383545
Validation loss: 2.042427976926168

Epoch: 6| Step: 12
Training loss: 1.2104499340057373
Validation loss: 2.0303991635640464

Epoch: 6| Step: 13
Training loss: 0.8491941690444946
Validation loss: 2.0930056969324746

Epoch: 120| Step: 0
Training loss: 2.422898530960083
Validation loss: 2.1084457437197366

Epoch: 6| Step: 1
Training loss: 1.7018026113510132
Validation loss: 2.122750997543335

Epoch: 6| Step: 2
Training loss: 2.1019811630249023
Validation loss: 2.1153878966967263

Epoch: 6| Step: 3
Training loss: 1.149718999862671
Validation loss: 2.1025150219599404

Epoch: 6| Step: 4
Training loss: 1.5301551818847656
Validation loss: 2.1315120855967202

Epoch: 6| Step: 5
Training loss: 1.2552285194396973
Validation loss: 2.0937312245368958

Epoch: 6| Step: 6
Training loss: 1.5294740200042725
Validation loss: 2.07204137245814

Epoch: 6| Step: 7
Training loss: 1.4719847440719604
Validation loss: 2.027802368005117

Epoch: 6| Step: 8
Training loss: 1.9460599422454834
Validation loss: 1.9954785307248433

Epoch: 6| Step: 9
Training loss: 1.4458796977996826
Validation loss: 2.0872470339139304

Epoch: 6| Step: 10
Training loss: 1.8976706266403198
Validation loss: 1.993678609530131

Epoch: 6| Step: 11
Training loss: 1.1896955966949463
Validation loss: 1.9769992033640544

Epoch: 6| Step: 12
Training loss: 0.8943089246749878
Validation loss: 2.065091331799825

Epoch: 6| Step: 13
Training loss: 1.7128907442092896
Validation loss: 2.0025248328844705

Epoch: 121| Step: 0
Training loss: 1.348069190979004
Validation loss: 2.0288376212120056

Epoch: 6| Step: 1
Training loss: 2.326320171356201
Validation loss: 2.026599566141764

Epoch: 6| Step: 2
Training loss: 1.552992343902588
Validation loss: 2.0071217815081277

Epoch: 6| Step: 3
Training loss: 1.1618123054504395
Validation loss: 2.0369033018747964

Epoch: 6| Step: 4
Training loss: 2.117196798324585
Validation loss: 2.006605943044027

Epoch: 6| Step: 5
Training loss: 1.5785188674926758
Validation loss: 2.0242316325505576

Epoch: 6| Step: 6
Training loss: 1.2955913543701172
Validation loss: 2.056795060634613

Epoch: 6| Step: 7
Training loss: 1.6819225549697876
Validation loss: 2.0293437242507935

Epoch: 6| Step: 8
Training loss: 1.5293428897857666
Validation loss: 2.075888673464457

Epoch: 6| Step: 9
Training loss: 1.315335988998413
Validation loss: 2.0647212266921997

Epoch: 6| Step: 10
Training loss: 1.1891199350357056
Validation loss: 2.038386861483256

Epoch: 6| Step: 11
Training loss: 0.9631702899932861
Validation loss: 2.0305497646331787

Epoch: 6| Step: 12
Training loss: 1.7555880546569824
Validation loss: 2.060328423976898

Epoch: 6| Step: 13
Training loss: 1.6702756881713867
Validation loss: 2.067094306151072

Epoch: 122| Step: 0
Training loss: 1.6768267154693604
Validation loss: 2.09291273355484

Epoch: 6| Step: 1
Training loss: 1.8529800176620483
Validation loss: 2.065340201059977

Epoch: 6| Step: 2
Training loss: 1.3205524682998657
Validation loss: 2.064858098824819

Epoch: 6| Step: 3
Training loss: 2.290365695953369
Validation loss: 2.038562019666036

Epoch: 6| Step: 4
Training loss: 1.5972297191619873
Validation loss: 2.055716037750244

Epoch: 6| Step: 5
Training loss: 1.9965986013412476
Validation loss: 2.030333936214447

Epoch: 6| Step: 6
Training loss: 1.1448193788528442
Validation loss: 2.0484700202941895

Epoch: 6| Step: 7
Training loss: 1.5896766185760498
Validation loss: 2.0602755546569824

Epoch: 6| Step: 8
Training loss: 1.3373966217041016
Validation loss: 2.052076756954193

Epoch: 6| Step: 9
Training loss: 2.3010926246643066
Validation loss: 2.0646554827690125

Epoch: 6| Step: 10
Training loss: 0.7145864963531494
Validation loss: 2.004223128159841

Epoch: 6| Step: 11
Training loss: 0.9332969188690186
Validation loss: 2.037520468235016

Epoch: 6| Step: 12
Training loss: 1.4110779762268066
Validation loss: 2.0604194601376853

Epoch: 6| Step: 13
Training loss: 1.2647924423217773
Validation loss: 2.0656373302141824

Epoch: 123| Step: 0
Training loss: 1.7188482284545898
Validation loss: 2.0569263299306235

Epoch: 6| Step: 1
Training loss: 1.7964930534362793
Validation loss: 2.0738877852757773

Epoch: 6| Step: 2
Training loss: 1.192244052886963
Validation loss: 2.089942296346029

Epoch: 6| Step: 3
Training loss: 1.6072399616241455
Validation loss: 2.0482903520266214

Epoch: 6| Step: 4
Training loss: 1.6805963516235352
Validation loss: 2.036989390850067

Epoch: 6| Step: 5
Training loss: 1.439223289489746
Validation loss: 2.1035711566607156

Epoch: 6| Step: 6
Training loss: 1.8119347095489502
Validation loss: 2.0666757424672446

Epoch: 6| Step: 7
Training loss: 1.3722035884857178
Validation loss: 2.0780330300331116

Epoch: 6| Step: 8
Training loss: 1.2860732078552246
Validation loss: 2.0372780362764993

Epoch: 6| Step: 9
Training loss: 1.4534733295440674
Validation loss: 2.0449392596880593

Epoch: 6| Step: 10
Training loss: 1.615837812423706
Validation loss: 1.9955370426177979

Epoch: 6| Step: 11
Training loss: 1.5266647338867188
Validation loss: 2.030089100201925

Epoch: 6| Step: 12
Training loss: 1.2529072761535645
Validation loss: 2.046613077322642

Epoch: 6| Step: 13
Training loss: 1.57285737991333
Validation loss: 2.023101568222046

Epoch: 124| Step: 0
Training loss: 1.2971136569976807
Validation loss: 2.0434120893478394

Epoch: 6| Step: 1
Training loss: 1.8561410903930664
Validation loss: 2.0124618808428445

Epoch: 6| Step: 2
Training loss: 1.8340176343917847
Validation loss: 2.021040618419647

Epoch: 6| Step: 3
Training loss: 1.138793706893921
Validation loss: 2.033623913923899

Epoch: 6| Step: 4
Training loss: 1.4679826498031616
Validation loss: 2.043459892272949

Epoch: 6| Step: 5
Training loss: 1.7120190858840942
Validation loss: 2.037085473537445

Epoch: 6| Step: 6
Training loss: 1.906994104385376
Validation loss: 2.078418215115865

Epoch: 6| Step: 7
Training loss: 1.4528601169586182
Validation loss: 2.034465968608856

Epoch: 6| Step: 8
Training loss: 2.0357391834259033
Validation loss: 2.0491446256637573

Epoch: 6| Step: 9
Training loss: 1.406292200088501
Validation loss: 2.079552332560221

Epoch: 6| Step: 10
Training loss: 1.2950891256332397
Validation loss: 2.051974097887675

Epoch: 6| Step: 11
Training loss: 1.2506870031356812
Validation loss: 2.097555915514628

Epoch: 6| Step: 12
Training loss: 1.0175509452819824
Validation loss: 2.070028066635132

Epoch: 6| Step: 13
Training loss: 1.7339119911193848
Validation loss: 2.035233795642853

Epoch: 125| Step: 0
Training loss: 1.6895394325256348
Validation loss: 2.049373507499695

Epoch: 6| Step: 1
Training loss: 1.9129482507705688
Validation loss: 2.1022241711616516

Epoch: 6| Step: 2
Training loss: 2.0693655014038086
Validation loss: 2.027051031589508

Epoch: 6| Step: 3
Training loss: 1.2620166540145874
Validation loss: 2.0398295323053994

Epoch: 6| Step: 4
Training loss: 1.356900930404663
Validation loss: 2.0653560161590576

Epoch: 6| Step: 5
Training loss: 1.5963406562805176
Validation loss: 1.9900818864504497

Epoch: 6| Step: 6
Training loss: 1.3985755443572998
Validation loss: 2.0898980100949607

Epoch: 6| Step: 7
Training loss: 1.0784225463867188
Validation loss: 2.0446875294049582

Epoch: 6| Step: 8
Training loss: 1.1210286617279053
Validation loss: 2.034916619459788

Epoch: 6| Step: 9
Training loss: 1.604498267173767
Validation loss: 2.0607420007387796

Epoch: 6| Step: 10
Training loss: 1.9685243368148804
Validation loss: 2.0406207839647927

Epoch: 6| Step: 11
Training loss: 1.3048841953277588
Validation loss: 2.025124947230021

Epoch: 6| Step: 12
Training loss: 1.3494162559509277
Validation loss: 2.031192342440287

Epoch: 6| Step: 13
Training loss: 1.4341543912887573
Validation loss: 2.033997972806295

Epoch: 126| Step: 0
Training loss: 1.5915911197662354
Validation loss: 2.029949645201365

Epoch: 6| Step: 1
Training loss: 1.1160227060317993
Validation loss: 2.0934592684110007

Epoch: 6| Step: 2
Training loss: 1.5048805475234985
Validation loss: 2.0498450994491577

Epoch: 6| Step: 3
Training loss: 0.8382366895675659
Validation loss: 2.053901195526123

Epoch: 6| Step: 4
Training loss: 2.0317511558532715
Validation loss: 2.098974366982778

Epoch: 6| Step: 5
Training loss: 1.5190482139587402
Validation loss: 2.024750550587972

Epoch: 6| Step: 6
Training loss: 1.3821815252304077
Validation loss: 2.0733256538709006

Epoch: 6| Step: 7
Training loss: 1.5548934936523438
Validation loss: 2.020889699459076

Epoch: 6| Step: 8
Training loss: 1.324494481086731
Validation loss: 2.038309911886851

Epoch: 6| Step: 9
Training loss: 1.8322608470916748
Validation loss: 2.01217387119929

Epoch: 6| Step: 10
Training loss: 1.9856655597686768
Validation loss: 2.0034141540527344

Epoch: 6| Step: 11
Training loss: 1.4336256980895996
Validation loss: 2.0393659273783364

Epoch: 6| Step: 12
Training loss: 1.1962413787841797
Validation loss: 2.0532895723978677

Epoch: 6| Step: 13
Training loss: 1.919824481010437
Validation loss: 2.065533757209778

Epoch: 127| Step: 0
Training loss: 1.179242491722107
Validation loss: 2.0262889862060547

Epoch: 6| Step: 1
Training loss: 2.0465893745422363
Validation loss: 2.0603307485580444

Epoch: 6| Step: 2
Training loss: 1.70548415184021
Validation loss: 2.1061089634895325

Epoch: 6| Step: 3
Training loss: 1.4998879432678223
Validation loss: 2.042997578779856

Epoch: 6| Step: 4
Training loss: 1.3100833892822266
Validation loss: 2.0448652704556785

Epoch: 6| Step: 5
Training loss: 0.9943554401397705
Validation loss: 2.0543543100357056

Epoch: 6| Step: 6
Training loss: 1.9677488803863525
Validation loss: 2.063505311806997

Epoch: 6| Step: 7
Training loss: 1.0043246746063232
Validation loss: 2.0661120613416037

Epoch: 6| Step: 8
Training loss: 1.7016066312789917
Validation loss: 2.064092735449473

Epoch: 6| Step: 9
Training loss: 1.2645127773284912
Validation loss: 2.045334041118622

Epoch: 6| Step: 10
Training loss: 1.4457743167877197
Validation loss: 2.0694286823272705

Epoch: 6| Step: 11
Training loss: 1.6586554050445557
Validation loss: 2.0905327200889587

Epoch: 6| Step: 12
Training loss: 1.4589625597000122
Validation loss: 2.0379321575164795

Epoch: 6| Step: 13
Training loss: 1.771130084991455
Validation loss: 2.0605740944544473

Epoch: 128| Step: 0
Training loss: 1.993394136428833
Validation loss: 2.0898078282674155

Epoch: 6| Step: 1
Training loss: 2.2626190185546875
Validation loss: 2.0416100223859153

Epoch: 6| Step: 2
Training loss: 1.133054494857788
Validation loss: 2.017713745435079

Epoch: 6| Step: 3
Training loss: 1.0910793542861938
Validation loss: 2.0263507962226868

Epoch: 6| Step: 4
Training loss: 1.2233904600143433
Validation loss: 2.0495174328486123

Epoch: 6| Step: 5
Training loss: 1.3607510328292847
Validation loss: 2.044302821159363

Epoch: 6| Step: 6
Training loss: 1.4231643676757812
Validation loss: 2.014235774676005

Epoch: 6| Step: 7
Training loss: 2.0238418579101562
Validation loss: 2.0635580023129783

Epoch: 6| Step: 8
Training loss: 1.6516664028167725
Validation loss: 2.062528967857361

Epoch: 6| Step: 9
Training loss: 1.2647753953933716
Validation loss: 2.038494964440664

Epoch: 6| Step: 10
Training loss: 1.113587737083435
Validation loss: 2.05052520831426

Epoch: 6| Step: 11
Training loss: 1.5043561458587646
Validation loss: 2.0671674807866416

Epoch: 6| Step: 12
Training loss: 1.340331792831421
Validation loss: 2.0535308917363486

Epoch: 6| Step: 13
Training loss: 1.3068890571594238
Validation loss: 2.055179556210836

Epoch: 129| Step: 0
Training loss: 1.7029192447662354
Validation loss: 2.047373036543528

Epoch: 6| Step: 1
Training loss: 1.726922869682312
Validation loss: 2.0473510225613913

Epoch: 6| Step: 2
Training loss: 2.19880747795105
Validation loss: 2.0347956816355386

Epoch: 6| Step: 3
Training loss: 1.163776159286499
Validation loss: 2.0659504532814026

Epoch: 6| Step: 4
Training loss: 1.6591806411743164
Validation loss: 2.0686413049697876

Epoch: 6| Step: 5
Training loss: 1.0535985231399536
Validation loss: 2.0971969763437905

Epoch: 6| Step: 6
Training loss: 1.3606252670288086
Validation loss: 2.09146777788798

Epoch: 6| Step: 7
Training loss: 1.6606217622756958
Validation loss: 2.0807403326034546

Epoch: 6| Step: 8
Training loss: 1.3897303342819214
Validation loss: 2.1232879161834717

Epoch: 6| Step: 9
Training loss: 1.264824628829956
Validation loss: 2.1033456722895303

Epoch: 6| Step: 10
Training loss: 0.8718123435974121
Validation loss: 2.094028035799662

Epoch: 6| Step: 11
Training loss: 2.0737528800964355
Validation loss: 2.067194143931071

Epoch: 6| Step: 12
Training loss: 0.9994258880615234
Validation loss: 2.112010677655538

Epoch: 6| Step: 13
Training loss: 1.4680564403533936
Validation loss: 2.0204623142878213

Epoch: 130| Step: 0
Training loss: 1.7623546123504639
Validation loss: 2.0495585799217224

Epoch: 6| Step: 1
Training loss: 1.3146193027496338
Validation loss: 2.0696856578191123

Epoch: 6| Step: 2
Training loss: 1.949992299079895
Validation loss: 2.017480711142222

Epoch: 6| Step: 3
Training loss: 1.6565489768981934
Validation loss: 2.06325356165568

Epoch: 6| Step: 4
Training loss: 1.290339708328247
Validation loss: 2.0558998584747314

Epoch: 6| Step: 5
Training loss: 1.784692645072937
Validation loss: 2.0297506848971048

Epoch: 6| Step: 6
Training loss: 0.9703109264373779
Validation loss: 2.055424690246582

Epoch: 6| Step: 7
Training loss: 1.65480637550354
Validation loss: 2.0455531080563865

Epoch: 6| Step: 8
Training loss: 1.632251262664795
Validation loss: 2.0399184425671897

Epoch: 6| Step: 9
Training loss: 1.6466405391693115
Validation loss: 2.123247444629669

Epoch: 6| Step: 10
Training loss: 1.324790358543396
Validation loss: 2.0164321064949036

Epoch: 6| Step: 11
Training loss: 0.9353818893432617
Validation loss: 2.1066126624743142

Epoch: 6| Step: 12
Training loss: 1.184706211090088
Validation loss: 2.0932854413986206

Epoch: 6| Step: 13
Training loss: 0.9314963221549988
Validation loss: 2.051979641119639

Epoch: 131| Step: 0
Training loss: 2.2418174743652344
Validation loss: 2.0737746159235635

Epoch: 6| Step: 1
Training loss: 0.8593602180480957
Validation loss: 2.142814119656881

Epoch: 6| Step: 2
Training loss: 1.7051066160202026
Validation loss: 2.1416390538215637

Epoch: 6| Step: 3
Training loss: 1.533542275428772
Validation loss: 2.1144962509473166

Epoch: 6| Step: 4
Training loss: 1.095702886581421
Validation loss: 2.1211604277292886

Epoch: 6| Step: 5
Training loss: 1.5927050113677979
Validation loss: 2.1391971707344055

Epoch: 6| Step: 6
Training loss: 1.7812062501907349
Validation loss: 2.0444514552752175

Epoch: 6| Step: 7
Training loss: 0.8405715227127075
Validation loss: 2.0351730585098267

Epoch: 6| Step: 8
Training loss: 2.5872883796691895
Validation loss: 2.025647302468618

Epoch: 6| Step: 9
Training loss: 1.381750226020813
Validation loss: 2.0845913688341775

Epoch: 6| Step: 10
Training loss: 1.04282808303833
Validation loss: 2.0530721147855124

Epoch: 6| Step: 11
Training loss: 1.3928345441818237
Validation loss: 2.0612250169118247

Epoch: 6| Step: 12
Training loss: 1.8620021343231201
Validation loss: 2.0827784538269043

Epoch: 6| Step: 13
Training loss: 0.6325543522834778
Validation loss: 2.0465185244878135

Epoch: 132| Step: 0
Training loss: 1.476473093032837
Validation loss: 2.0946958462397256

Epoch: 6| Step: 1
Training loss: 1.383657693862915
Validation loss: 2.053056061267853

Epoch: 6| Step: 2
Training loss: 1.0010621547698975
Validation loss: 2.048434615135193

Epoch: 6| Step: 3
Training loss: 1.0455522537231445
Validation loss: 2.104101240634918

Epoch: 6| Step: 4
Training loss: 1.5110409259796143
Validation loss: 2.1122644344965615

Epoch: 6| Step: 5
Training loss: 1.698552131652832
Validation loss: 2.093128283818563

Epoch: 6| Step: 6
Training loss: 1.1092995405197144
Validation loss: 2.0786779125531516

Epoch: 6| Step: 7
Training loss: 1.9330451488494873
Validation loss: 2.029033144315084

Epoch: 6| Step: 8
Training loss: 1.277017593383789
Validation loss: 2.104142944018046

Epoch: 6| Step: 9
Training loss: 1.1347472667694092
Validation loss: 2.041801651318868

Epoch: 6| Step: 10
Training loss: 2.2068090438842773
Validation loss: 2.060268004735311

Epoch: 6| Step: 11
Training loss: 1.271040439605713
Validation loss: 2.021283805370331

Epoch: 6| Step: 12
Training loss: 1.4097998142242432
Validation loss: 2.0326915780703225

Epoch: 6| Step: 13
Training loss: 1.3744630813598633
Validation loss: 2.0635332067807517

Epoch: 133| Step: 0
Training loss: 1.3375787734985352
Validation loss: 2.0406062801678977

Epoch: 6| Step: 1
Training loss: 1.5072076320648193
Validation loss: 2.0389045675595603

Epoch: 6| Step: 2
Training loss: 1.6870896816253662
Validation loss: 2.057932436466217

Epoch: 6| Step: 3
Training loss: 1.0059924125671387
Validation loss: 2.10338165362676

Epoch: 6| Step: 4
Training loss: 1.2956666946411133
Validation loss: 2.129563013712565

Epoch: 6| Step: 5
Training loss: 1.8482463359832764
Validation loss: 2.0111289024353027

Epoch: 6| Step: 6
Training loss: 1.1470624208450317
Validation loss: 2.0102071364720664

Epoch: 6| Step: 7
Training loss: 1.3291261196136475
Validation loss: 2.0840027928352356

Epoch: 6| Step: 8
Training loss: 1.5211169719696045
Validation loss: 2.0850491523742676

Epoch: 6| Step: 9
Training loss: 1.0420818328857422
Validation loss: 2.0508217215538025

Epoch: 6| Step: 10
Training loss: 2.1349782943725586
Validation loss: 2.0385824044545493

Epoch: 6| Step: 11
Training loss: 1.2757116556167603
Validation loss: 2.055719792842865

Epoch: 6| Step: 12
Training loss: 1.0141210556030273
Validation loss: 2.0292227466901145

Epoch: 6| Step: 13
Training loss: 1.8009216785430908
Validation loss: 2.1046934922536216

Epoch: 134| Step: 0
Training loss: 1.403660774230957
Validation loss: 2.1024704774220786

Epoch: 6| Step: 1
Training loss: 2.2095649242401123
Validation loss: 2.0948643684387207

Epoch: 6| Step: 2
Training loss: 1.390961766242981
Validation loss: 2.0669530630111694

Epoch: 6| Step: 3
Training loss: 1.3242930173873901
Validation loss: 2.111494024594625

Epoch: 6| Step: 4
Training loss: 1.4183200597763062
Validation loss: 2.070621689160665

Epoch: 6| Step: 5
Training loss: 1.1922340393066406
Validation loss: 2.073685050010681

Epoch: 6| Step: 6
Training loss: 0.9924615621566772
Validation loss: 2.0991403063138327

Epoch: 6| Step: 7
Training loss: 1.207105040550232
Validation loss: 2.0394402742385864

Epoch: 6| Step: 8
Training loss: 1.2638728618621826
Validation loss: 2.0325421690940857

Epoch: 6| Step: 9
Training loss: 1.1071979999542236
Validation loss: 2.0721339782079062

Epoch: 6| Step: 10
Training loss: 1.1712291240692139
Validation loss: 2.0643619298934937

Epoch: 6| Step: 11
Training loss: 1.4810744524002075
Validation loss: 2.0723193486531577

Epoch: 6| Step: 12
Training loss: 1.3839478492736816
Validation loss: 2.086616317431132

Epoch: 6| Step: 13
Training loss: 1.8861602544784546
Validation loss: 2.0720768570899963

Epoch: 135| Step: 0
Training loss: 0.9662362337112427
Validation loss: 2.0910351276397705

Epoch: 6| Step: 1
Training loss: 1.1717017889022827
Validation loss: 2.116278608640035

Epoch: 6| Step: 2
Training loss: 0.8704262375831604
Validation loss: 2.044268568356832

Epoch: 6| Step: 3
Training loss: 0.8912742137908936
Validation loss: 2.0846705238024392

Epoch: 6| Step: 4
Training loss: 1.9875783920288086
Validation loss: 2.091755449771881

Epoch: 6| Step: 5
Training loss: 1.6200947761535645
Validation loss: 2.0784875750541687

Epoch: 6| Step: 6
Training loss: 2.286869764328003
Validation loss: 2.0565743843714395

Epoch: 6| Step: 7
Training loss: 1.2403661012649536
Validation loss: 2.0476094086964927

Epoch: 6| Step: 8
Training loss: 2.3114724159240723
Validation loss: 2.0699607729911804

Epoch: 6| Step: 9
Training loss: 1.5303447246551514
Validation loss: 2.051324804623922

Epoch: 6| Step: 10
Training loss: 1.569840669631958
Validation loss: 2.078983465830485

Epoch: 6| Step: 11
Training loss: 1.4265036582946777
Validation loss: 2.05038058757782

Epoch: 6| Step: 12
Training loss: 0.9620445966720581
Validation loss: 2.0915895899136863

Epoch: 6| Step: 13
Training loss: 0.6724521517753601
Validation loss: 2.044692873954773

Epoch: 136| Step: 0
Training loss: 1.4190542697906494
Validation loss: 2.0475491285324097

Epoch: 6| Step: 1
Training loss: 1.761584758758545
Validation loss: 2.0107235113779702

Epoch: 6| Step: 2
Training loss: 1.4192659854888916
Validation loss: 2.106874406337738

Epoch: 6| Step: 3
Training loss: 1.253631353378296
Validation loss: 2.0797260999679565

Epoch: 6| Step: 4
Training loss: 1.4480512142181396
Validation loss: 2.0261009335517883

Epoch: 6| Step: 5
Training loss: 0.6741392612457275
Validation loss: 2.0737754901250205

Epoch: 6| Step: 6
Training loss: 1.2577836513519287
Validation loss: 2.0691486597061157

Epoch: 6| Step: 7
Training loss: 1.6230266094207764
Validation loss: 2.0548205971717834

Epoch: 6| Step: 8
Training loss: 1.289311408996582
Validation loss: 2.0883299509684243

Epoch: 6| Step: 9
Training loss: 2.1395516395568848
Validation loss: 2.06853053967158

Epoch: 6| Step: 10
Training loss: 1.1934292316436768
Validation loss: 2.061018188794454

Epoch: 6| Step: 11
Training loss: 1.496882438659668
Validation loss: 2.071498533089956

Epoch: 6| Step: 12
Training loss: 0.9548267126083374
Validation loss: 2.05591481924057

Epoch: 6| Step: 13
Training loss: 1.2783820629119873
Validation loss: 2.059587061405182

Epoch: 137| Step: 0
Training loss: 1.2242118120193481
Validation loss: 2.0433425505956015

Epoch: 6| Step: 1
Training loss: 1.5822864770889282
Validation loss: 2.0871171951293945

Epoch: 6| Step: 2
Training loss: 1.0511360168457031
Validation loss: 2.0772059758504233

Epoch: 6| Step: 3
Training loss: 1.1679909229278564
Validation loss: 2.1061147451400757

Epoch: 6| Step: 4
Training loss: 1.755759596824646
Validation loss: 2.0526457031567893

Epoch: 6| Step: 5
Training loss: 1.0595608949661255
Validation loss: 2.0407824516296387

Epoch: 6| Step: 6
Training loss: 1.7408668994903564
Validation loss: 2.0901103814442954

Epoch: 6| Step: 7
Training loss: 1.3670860528945923
Validation loss: 2.060464878877004

Epoch: 6| Step: 8
Training loss: 1.8587934970855713
Validation loss: 2.0681326190630593

Epoch: 6| Step: 9
Training loss: 1.0913783311843872
Validation loss: 2.073146720727285

Epoch: 6| Step: 10
Training loss: 1.0635943412780762
Validation loss: 2.069206158320109

Epoch: 6| Step: 11
Training loss: 1.1591089963912964
Validation loss: 2.06666761636734

Epoch: 6| Step: 12
Training loss: 1.25771164894104
Validation loss: 2.060438652833303

Epoch: 6| Step: 13
Training loss: 1.8258450031280518
Validation loss: 2.020050843556722

Epoch: 138| Step: 0
Training loss: 1.8364474773406982
Validation loss: 2.0098790725072226

Epoch: 6| Step: 1
Training loss: 1.1023184061050415
Validation loss: 2.0521472295125327

Epoch: 6| Step: 2
Training loss: 1.2816470861434937
Validation loss: 2.053957462310791

Epoch: 6| Step: 3
Training loss: 1.825310468673706
Validation loss: 2.061385691165924

Epoch: 6| Step: 4
Training loss: 1.6769509315490723
Validation loss: 2.0320215225219727

Epoch: 6| Step: 5
Training loss: 1.5923051834106445
Validation loss: 2.066912531852722

Epoch: 6| Step: 6
Training loss: 1.4557523727416992
Validation loss: 2.0604006250699363

Epoch: 6| Step: 7
Training loss: 0.9709159731864929
Validation loss: 2.0695079962412515

Epoch: 6| Step: 8
Training loss: 1.1639028787612915
Validation loss: 2.0866915583610535

Epoch: 6| Step: 9
Training loss: 1.3149425983428955
Validation loss: 2.0621151328086853

Epoch: 6| Step: 10
Training loss: 2.078169822692871
Validation loss: 2.1032307147979736

Epoch: 6| Step: 11
Training loss: 1.1758756637573242
Validation loss: 2.100053628285726

Epoch: 6| Step: 12
Training loss: 1.268646478652954
Validation loss: 2.088348905245463

Epoch: 6| Step: 13
Training loss: 0.6874043941497803
Validation loss: 2.095162292321523

Epoch: 139| Step: 0
Training loss: 1.424691081047058
Validation loss: 2.1055578192075095

Epoch: 6| Step: 1
Training loss: 1.539482831954956
Validation loss: 2.064764698346456

Epoch: 6| Step: 2
Training loss: 0.9518027305603027
Validation loss: 2.1013678510983786

Epoch: 6| Step: 3
Training loss: 1.5603939294815063
Validation loss: 2.027722636858622

Epoch: 6| Step: 4
Training loss: 0.9464547038078308
Validation loss: 2.066179354985555

Epoch: 6| Step: 5
Training loss: 1.5536327362060547
Validation loss: 2.0453895131746926

Epoch: 6| Step: 6
Training loss: 1.6076667308807373
Validation loss: 2.084130346775055

Epoch: 6| Step: 7
Training loss: 1.7881157398223877
Validation loss: 2.016858617464701

Epoch: 6| Step: 8
Training loss: 1.422006368637085
Validation loss: 2.0854783058166504

Epoch: 6| Step: 9
Training loss: 1.1027814149856567
Validation loss: 2.077333370844523

Epoch: 6| Step: 10
Training loss: 1.3060123920440674
Validation loss: 2.0435272256533303

Epoch: 6| Step: 11
Training loss: 0.9823670983314514
Validation loss: 2.0812122027079263

Epoch: 6| Step: 12
Training loss: 2.01254940032959
Validation loss: 2.061845064163208

Epoch: 6| Step: 13
Training loss: 0.8616818189620972
Validation loss: 2.086223383744558

Epoch: 140| Step: 0
Training loss: 1.5258214473724365
Validation loss: 2.0670252044995627

Epoch: 6| Step: 1
Training loss: 1.3822112083435059
Validation loss: 2.0820208390553794

Epoch: 6| Step: 2
Training loss: 1.4269697666168213
Validation loss: 2.074014902114868

Epoch: 6| Step: 3
Training loss: 1.3721923828125
Validation loss: 2.0530033707618713

Epoch: 6| Step: 4
Training loss: 1.447660207748413
Validation loss: 2.0857447385787964

Epoch: 6| Step: 5
Training loss: 1.5129550695419312
Validation loss: 2.091456413269043

Epoch: 6| Step: 6
Training loss: 1.0766013860702515
Validation loss: 2.0621272921562195

Epoch: 6| Step: 7
Training loss: 1.1223723888397217
Validation loss: 2.0622893571853638

Epoch: 6| Step: 8
Training loss: 1.7320301532745361
Validation loss: 2.063367942969004

Epoch: 6| Step: 9
Training loss: 1.6117539405822754
Validation loss: 2.0596994161605835

Epoch: 6| Step: 10
Training loss: 1.342002034187317
Validation loss: 2.073018948237101

Epoch: 6| Step: 11
Training loss: 1.0221798419952393
Validation loss: 2.070611615975698

Epoch: 6| Step: 12
Training loss: 1.4474899768829346
Validation loss: 2.0950690110524497

Epoch: 6| Step: 13
Training loss: 0.8423004150390625
Validation loss: 2.08277161916097

Epoch: 141| Step: 0
Training loss: 1.1026275157928467
Validation loss: 2.06430983543396

Epoch: 6| Step: 1
Training loss: 1.28578782081604
Validation loss: 2.1329636176427207

Epoch: 6| Step: 2
Training loss: 1.1032311916351318
Validation loss: 2.045099357763926

Epoch: 6| Step: 3
Training loss: 1.657127857208252
Validation loss: 2.049272874991099

Epoch: 6| Step: 4
Training loss: 1.3688268661499023
Validation loss: 2.0881959597269693

Epoch: 6| Step: 5
Training loss: 1.37192964553833
Validation loss: 2.0713353554407754

Epoch: 6| Step: 6
Training loss: 1.652142882347107
Validation loss: 2.041151463985443

Epoch: 6| Step: 7
Training loss: 1.1537525653839111
Validation loss: 2.0472575426101685

Epoch: 6| Step: 8
Training loss: 1.1352252960205078
Validation loss: 2.029197653134664

Epoch: 6| Step: 9
Training loss: 1.1979928016662598
Validation loss: 2.0729943911234536

Epoch: 6| Step: 10
Training loss: 1.7820398807525635
Validation loss: 2.0502827167510986

Epoch: 6| Step: 11
Training loss: 1.0398790836334229
Validation loss: 2.0446372032165527

Epoch: 6| Step: 12
Training loss: 1.2093454599380493
Validation loss: 2.088597615559896

Epoch: 6| Step: 13
Training loss: 1.0763648748397827
Validation loss: 2.098862131436666

Epoch: 142| Step: 0
Training loss: 1.9145698547363281
Validation loss: 2.127279539903005

Epoch: 6| Step: 1
Training loss: 0.8942596912384033
Validation loss: 2.0673999786376953

Epoch: 6| Step: 2
Training loss: 1.6215729713439941
Validation loss: 2.1157619953155518

Epoch: 6| Step: 3
Training loss: 1.4039578437805176
Validation loss: 2.139884968598684

Epoch: 6| Step: 4
Training loss: 1.2482383251190186
Validation loss: 2.1185609102249146

Epoch: 6| Step: 5
Training loss: 1.612794280052185
Validation loss: 2.1065470973650613

Epoch: 6| Step: 6
Training loss: 1.8401895761489868
Validation loss: 2.0868287483851113

Epoch: 6| Step: 7
Training loss: 1.0477466583251953
Validation loss: 2.096691926320394

Epoch: 6| Step: 8
Training loss: 1.7704832553863525
Validation loss: 2.075671434402466

Epoch: 6| Step: 9
Training loss: 1.1987226009368896
Validation loss: 2.0338385303815207

Epoch: 6| Step: 10
Training loss: 0.7802426218986511
Validation loss: 2.1289657950401306

Epoch: 6| Step: 11
Training loss: 1.283837080001831
Validation loss: 2.0943036874135337

Epoch: 6| Step: 12
Training loss: 1.1796860694885254
Validation loss: 2.0416911443074546

Epoch: 6| Step: 13
Training loss: 0.8870379328727722
Validation loss: 2.072346806526184

Epoch: 143| Step: 0
Training loss: 1.628705620765686
Validation loss: 2.022667566935221

Epoch: 6| Step: 1
Training loss: 1.1075425148010254
Validation loss: 2.0842367013295493

Epoch: 6| Step: 2
Training loss: 1.1438860893249512
Validation loss: 2.0542980631192527

Epoch: 6| Step: 3
Training loss: 1.862492322921753
Validation loss: 2.0774115324020386

Epoch: 6| Step: 4
Training loss: 1.6249006986618042
Validation loss: 2.1064863204956055

Epoch: 6| Step: 5
Training loss: 1.2714605331420898
Validation loss: 2.03385200103124

Epoch: 6| Step: 6
Training loss: 1.0155659914016724
Validation loss: 2.078514873981476

Epoch: 6| Step: 7
Training loss: 0.6349003911018372
Validation loss: 2.052833875020345

Epoch: 6| Step: 8
Training loss: 1.222640037536621
Validation loss: 2.037353773911794

Epoch: 6| Step: 9
Training loss: 1.2192978858947754
Validation loss: 2.0574427048365274

Epoch: 6| Step: 10
Training loss: 0.9302372932434082
Validation loss: 2.0668490131696067

Epoch: 6| Step: 11
Training loss: 1.5233376026153564
Validation loss: 2.046437164147695

Epoch: 6| Step: 12
Training loss: 1.6979906558990479
Validation loss: 2.0855907797813416

Epoch: 6| Step: 13
Training loss: 1.476508617401123
Validation loss: 2.067759017149607

Epoch: 144| Step: 0
Training loss: 0.8929343223571777
Validation loss: 2.115090469519297

Epoch: 6| Step: 1
Training loss: 1.7387516498565674
Validation loss: 2.0919320980707803

Epoch: 6| Step: 2
Training loss: 1.0585894584655762
Validation loss: 2.0758373737335205

Epoch: 6| Step: 3
Training loss: 1.519113540649414
Validation loss: 2.160368104775747

Epoch: 6| Step: 4
Training loss: 1.1292387247085571
Validation loss: 2.0549492041269937

Epoch: 6| Step: 5
Training loss: 0.9854285717010498
Validation loss: 2.0765113631884256

Epoch: 6| Step: 6
Training loss: 1.6914772987365723
Validation loss: 2.036974012851715

Epoch: 6| Step: 7
Training loss: 1.087161660194397
Validation loss: 2.0453511476516724

Epoch: 6| Step: 8
Training loss: 1.807213544845581
Validation loss: 2.0616817077000937

Epoch: 6| Step: 9
Training loss: 0.9814887642860413
Validation loss: 2.099741578102112

Epoch: 6| Step: 10
Training loss: 1.9754353761672974
Validation loss: 2.050142824649811

Epoch: 6| Step: 11
Training loss: 1.2901004552841187
Validation loss: 2.0510245164235434

Epoch: 6| Step: 12
Training loss: 1.6512280702590942
Validation loss: 2.104008932908376

Epoch: 6| Step: 13
Training loss: 1.0796222686767578
Validation loss: 2.0475714802742004

Epoch: 145| Step: 0
Training loss: 1.265547513961792
Validation loss: 2.0039095083872476

Epoch: 6| Step: 1
Training loss: 1.6972428560256958
Validation loss: 1.9879802068074544

Epoch: 6| Step: 2
Training loss: 1.2261446714401245
Validation loss: 2.046016792456309

Epoch: 6| Step: 3
Training loss: 0.5907391309738159
Validation loss: 2.0727985898653665

Epoch: 6| Step: 4
Training loss: 1.6959716081619263
Validation loss: 2.1053085923194885

Epoch: 6| Step: 5
Training loss: 0.5301283001899719
Validation loss: 2.1054276823997498

Epoch: 6| Step: 6
Training loss: 1.603421688079834
Validation loss: 2.108193894227346

Epoch: 6| Step: 7
Training loss: 1.5372395515441895
Validation loss: 2.083241085211436

Epoch: 6| Step: 8
Training loss: 1.4064548015594482
Validation loss: 2.137750426928202

Epoch: 6| Step: 9
Training loss: 1.2683161497116089
Validation loss: 2.073188622792562

Epoch: 6| Step: 10
Training loss: 1.4591538906097412
Validation loss: 2.052106579144796

Epoch: 6| Step: 11
Training loss: 1.2629430294036865
Validation loss: 2.064315358797709

Epoch: 6| Step: 12
Training loss: 1.0643377304077148
Validation loss: 2.0619249741236367

Epoch: 6| Step: 13
Training loss: 1.7286304235458374
Validation loss: 2.0558194120724997

Epoch: 146| Step: 0
Training loss: 0.8926262259483337
Validation loss: 2.0342127680778503

Epoch: 6| Step: 1
Training loss: 1.4840351343154907
Validation loss: 2.056368072827657

Epoch: 6| Step: 2
Training loss: 1.134473204612732
Validation loss: 2.054002821445465

Epoch: 6| Step: 3
Training loss: 1.2610746622085571
Validation loss: 2.047027846177419

Epoch: 6| Step: 4
Training loss: 1.445146083831787
Validation loss: 2.0314377347628274

Epoch: 6| Step: 5
Training loss: 1.4548457860946655
Validation loss: 2.02977192401886

Epoch: 6| Step: 6
Training loss: 1.0184850692749023
Validation loss: 2.1105441649754844

Epoch: 6| Step: 7
Training loss: 1.4335558414459229
Validation loss: 2.049023747444153

Epoch: 6| Step: 8
Training loss: 1.4576828479766846
Validation loss: 2.0919295946756997

Epoch: 6| Step: 9
Training loss: 1.45656418800354
Validation loss: 2.104801038901011

Epoch: 6| Step: 10
Training loss: 1.4023895263671875
Validation loss: 2.188162088394165

Epoch: 6| Step: 11
Training loss: 1.5143831968307495
Validation loss: 2.181592265764872

Epoch: 6| Step: 12
Training loss: 1.6433773040771484
Validation loss: 2.155870536963145

Epoch: 6| Step: 13
Training loss: 1.3953838348388672
Validation loss: 2.096698224544525

Epoch: 147| Step: 0
Training loss: 1.2293705940246582
Validation loss: 2.130620280901591

Epoch: 6| Step: 1
Training loss: 1.4236574172973633
Validation loss: 2.1250891288121543

Epoch: 6| Step: 2
Training loss: 1.4358582496643066
Validation loss: 2.0203109979629517

Epoch: 6| Step: 3
Training loss: 1.3496639728546143
Validation loss: 2.0742934346199036

Epoch: 6| Step: 4
Training loss: 0.894114077091217
Validation loss: 2.0247879227002463

Epoch: 6| Step: 5
Training loss: 1.6432576179504395
Validation loss: 2.0090574820836387

Epoch: 6| Step: 6
Training loss: 1.3515784740447998
Validation loss: 2.0447040796279907

Epoch: 6| Step: 7
Training loss: 0.98213791847229
Validation loss: 2.064624845981598

Epoch: 6| Step: 8
Training loss: 1.7758071422576904
Validation loss: 2.0431362191836038

Epoch: 6| Step: 9
Training loss: 1.3105435371398926
Validation loss: 2.0839338302612305

Epoch: 6| Step: 10
Training loss: 1.1333014965057373
Validation loss: 2.013978282610575

Epoch: 6| Step: 11
Training loss: 1.346245288848877
Validation loss: 2.090892255306244

Epoch: 6| Step: 12
Training loss: 1.3795539140701294
Validation loss: 2.041843831539154

Epoch: 6| Step: 13
Training loss: 0.9249911308288574
Validation loss: 2.042479693889618

Epoch: 148| Step: 0
Training loss: 1.8682693243026733
Validation loss: 2.044286032517751

Epoch: 6| Step: 1
Training loss: 1.643236517906189
Validation loss: 2.107147216796875

Epoch: 6| Step: 2
Training loss: 1.206757664680481
Validation loss: 2.043022572994232

Epoch: 6| Step: 3
Training loss: 1.0478025674819946
Validation loss: 2.0644735296567283

Epoch: 6| Step: 4
Training loss: 1.3004080057144165
Validation loss: 2.0580438574155173

Epoch: 6| Step: 5
Training loss: 1.2295844554901123
Validation loss: 2.080759366353353

Epoch: 6| Step: 6
Training loss: 1.7668944597244263
Validation loss: 2.0165232022603354

Epoch: 6| Step: 7
Training loss: 0.9274430871009827
Validation loss: 2.0058202147483826

Epoch: 6| Step: 8
Training loss: 1.85921311378479
Validation loss: 2.0489355325698853

Epoch: 6| Step: 9
Training loss: 0.5799602270126343
Validation loss: 2.0529068311055503

Epoch: 6| Step: 10
Training loss: 1.1042461395263672
Validation loss: 2.0415340662002563

Epoch: 6| Step: 11
Training loss: 1.4927141666412354
Validation loss: 2.056883712609609

Epoch: 6| Step: 12
Training loss: 0.9228110313415527
Validation loss: 2.124802311261495

Epoch: 6| Step: 13
Training loss: 1.2818020582199097
Validation loss: 2.1138807932535806

Epoch: 149| Step: 0
Training loss: 1.2659882307052612
Validation loss: 2.1374038259188333

Epoch: 6| Step: 1
Training loss: 1.6874290704727173
Validation loss: 2.077499051888784

Epoch: 6| Step: 2
Training loss: 2.329089641571045
Validation loss: 2.134153366088867

Epoch: 6| Step: 3
Training loss: 1.3431181907653809
Validation loss: 2.0788251956303916

Epoch: 6| Step: 4
Training loss: 1.185903549194336
Validation loss: 2.05808162689209

Epoch: 6| Step: 5
Training loss: 1.547265648841858
Validation loss: 2.048187792301178

Epoch: 6| Step: 6
Training loss: 1.267209768295288
Validation loss: 2.060341715812683

Epoch: 6| Step: 7
Training loss: 0.941132664680481
Validation loss: 2.0161827007929483

Epoch: 6| Step: 8
Training loss: 0.9061456918716431
Validation loss: 2.0506160855293274

Epoch: 6| Step: 9
Training loss: 1.2809017896652222
Validation loss: 2.024685521920522

Epoch: 6| Step: 10
Training loss: 1.370943307876587
Validation loss: 2.094149728616079

Epoch: 6| Step: 11
Training loss: 0.9947957992553711
Validation loss: 2.075127283732096

Epoch: 6| Step: 12
Training loss: 1.2093154191970825
Validation loss: 2.0380565325419107

Epoch: 6| Step: 13
Training loss: 1.4172947406768799
Validation loss: 2.0772961378097534

Epoch: 150| Step: 0
Training loss: 1.4679644107818604
Validation loss: 2.0945557157198587

Epoch: 6| Step: 1
Training loss: 0.8507550954818726
Validation loss: 2.0946419835090637

Epoch: 6| Step: 2
Training loss: 1.599717617034912
Validation loss: 2.133885125319163

Epoch: 6| Step: 3
Training loss: 1.4237871170043945
Validation loss: 2.0854111512502036

Epoch: 6| Step: 4
Training loss: 0.995741605758667
Validation loss: 2.084045926729838

Epoch: 6| Step: 5
Training loss: 1.0737745761871338
Validation loss: 2.091216504573822

Epoch: 6| Step: 6
Training loss: 0.9202799797058105
Validation loss: 2.0490995248158774

Epoch: 6| Step: 7
Training loss: 1.4960285425186157
Validation loss: 2.0586363474527993

Epoch: 6| Step: 8
Training loss: 1.7939739227294922
Validation loss: 2.071296135584513

Epoch: 6| Step: 9
Training loss: 1.2856132984161377
Validation loss: 2.057403783003489

Epoch: 6| Step: 10
Training loss: 1.387190341949463
Validation loss: 1.9871194163958232

Epoch: 6| Step: 11
Training loss: 1.339221477508545
Validation loss: 2.0121999979019165

Epoch: 6| Step: 12
Training loss: 0.8342393636703491
Validation loss: 2.119396130243937

Epoch: 6| Step: 13
Training loss: 1.825977087020874
Validation loss: 2.0887183348337808

Epoch: 151| Step: 0
Training loss: 1.2324130535125732
Validation loss: 2.10617858171463

Epoch: 6| Step: 1
Training loss: 1.3538410663604736
Validation loss: 2.1035857597986856

Epoch: 6| Step: 2
Training loss: 1.2247717380523682
Validation loss: 2.124259610970815

Epoch: 6| Step: 3
Training loss: 1.0628252029418945
Validation loss: 2.0985684593518577

Epoch: 6| Step: 4
Training loss: 1.1524124145507812
Validation loss: 2.025788406531016

Epoch: 6| Step: 5
Training loss: 1.148559808731079
Validation loss: 2.0467158555984497

Epoch: 6| Step: 6
Training loss: 1.947261929512024
Validation loss: 2.0214051802953086

Epoch: 6| Step: 7
Training loss: 0.8273985385894775
Validation loss: 2.0877334475517273

Epoch: 6| Step: 8
Training loss: 1.2694250345230103
Validation loss: 2.02876353263855

Epoch: 6| Step: 9
Training loss: 1.21274995803833
Validation loss: 2.0032429099082947

Epoch: 6| Step: 10
Training loss: 1.4298205375671387
Validation loss: 2.0868680675824485

Epoch: 6| Step: 11
Training loss: 1.7187001705169678
Validation loss: 2.051816781361898

Epoch: 6| Step: 12
Training loss: 1.6729650497436523
Validation loss: 2.0889889200528464

Epoch: 6| Step: 13
Training loss: 1.0227015018463135
Validation loss: 2.0758245388666787

Epoch: 152| Step: 0
Training loss: 0.8635424375534058
Validation loss: 2.0483516852060952

Epoch: 6| Step: 1
Training loss: 1.2654083967208862
Validation loss: 2.0709391832351685

Epoch: 6| Step: 2
Training loss: 0.9761844277381897
Validation loss: 2.0776376326878867

Epoch: 6| Step: 3
Training loss: 0.9626147747039795
Validation loss: 2.067294438680013

Epoch: 6| Step: 4
Training loss: 1.115748643875122
Validation loss: 2.0594103833039603

Epoch: 6| Step: 5
Training loss: 1.5531795024871826
Validation loss: 1.9967707792917888

Epoch: 6| Step: 6
Training loss: 1.785489559173584
Validation loss: 2.0177961190541587

Epoch: 6| Step: 7
Training loss: 1.2642247676849365
Validation loss: 2.048413654168447

Epoch: 6| Step: 8
Training loss: 1.2035276889801025
Validation loss: 2.052233576774597

Epoch: 6| Step: 9
Training loss: 1.2544121742248535
Validation loss: 2.0597376426060996

Epoch: 6| Step: 10
Training loss: 1.3388752937316895
Validation loss: 2.038105090459188

Epoch: 6| Step: 11
Training loss: 1.3752691745758057
Validation loss: 2.0523330171902976

Epoch: 6| Step: 12
Training loss: 1.7723346948623657
Validation loss: 2.078189810117086

Epoch: 6| Step: 13
Training loss: 1.1862528324127197
Validation loss: 2.0414390563964844

Epoch: 153| Step: 0
Training loss: 1.1553714275360107
Validation loss: 2.110280613104502

Epoch: 6| Step: 1
Training loss: 0.8088905811309814
Validation loss: 2.107557197411855

Epoch: 6| Step: 2
Training loss: 0.6820797324180603
Validation loss: 2.082928737004598

Epoch: 6| Step: 3
Training loss: 1.6664091348648071
Validation loss: 2.069312810897827

Epoch: 6| Step: 4
Training loss: 1.3261327743530273
Validation loss: 2.084789276123047

Epoch: 6| Step: 5
Training loss: 1.401595115661621
Validation loss: 2.0711066921552024

Epoch: 6| Step: 6
Training loss: 0.9480171203613281
Validation loss: 2.092179516951243

Epoch: 6| Step: 7
Training loss: 0.9242333769798279
Validation loss: 2.0695391297340393

Epoch: 6| Step: 8
Training loss: 1.958432674407959
Validation loss: 2.0370825926462808

Epoch: 6| Step: 9
Training loss: 1.2999656200408936
Validation loss: 2.061958889166514

Epoch: 6| Step: 10
Training loss: 1.5396497249603271
Validation loss: 2.0245062907536826

Epoch: 6| Step: 11
Training loss: 1.2580599784851074
Validation loss: 2.04291037718455

Epoch: 6| Step: 12
Training loss: 1.2958259582519531
Validation loss: 2.015880525112152

Epoch: 6| Step: 13
Training loss: 1.4989020824432373
Validation loss: 2.059902528921763

Epoch: 154| Step: 0
Training loss: 1.3969553709030151
Validation loss: 2.0435190995534263

Epoch: 6| Step: 1
Training loss: 0.9956351518630981
Validation loss: 2.0405380527178445

Epoch: 6| Step: 2
Training loss: 1.2296360731124878
Validation loss: 2.1439990997314453

Epoch: 6| Step: 3
Training loss: 1.1012508869171143
Validation loss: 2.0897156993548074

Epoch: 6| Step: 4
Training loss: 1.4273645877838135
Validation loss: 2.0928730567296348

Epoch: 6| Step: 5
Training loss: 1.1132076978683472
Validation loss: 2.06402724981308

Epoch: 6| Step: 6
Training loss: 1.5702338218688965
Validation loss: 2.054517130057017

Epoch: 6| Step: 7
Training loss: 0.8960769176483154
Validation loss: 2.068290630976359

Epoch: 6| Step: 8
Training loss: 1.243757963180542
Validation loss: 2.0330622593561807

Epoch: 6| Step: 9
Training loss: 1.3144499063491821
Validation loss: 2.056457281112671

Epoch: 6| Step: 10
Training loss: 1.1961747407913208
Validation loss: 2.075068453947703

Epoch: 6| Step: 11
Training loss: 1.5450862646102905
Validation loss: 2.0555578470230103

Epoch: 6| Step: 12
Training loss: 0.9187431335449219
Validation loss: 2.0418754418691

Epoch: 6| Step: 13
Training loss: 1.38437819480896
Validation loss: 2.0637585719426474

Epoch: 155| Step: 0
Training loss: 1.5641746520996094
Validation loss: 2.042327662309011

Epoch: 6| Step: 1
Training loss: 0.9920908212661743
Validation loss: 2.0391839345296225

Epoch: 6| Step: 2
Training loss: 1.7789578437805176
Validation loss: 2.034632623195648

Epoch: 6| Step: 3
Training loss: 1.2576656341552734
Validation loss: 2.044858694076538

Epoch: 6| Step: 4
Training loss: 1.4700465202331543
Validation loss: 2.0276036262512207

Epoch: 6| Step: 5
Training loss: 1.555741310119629
Validation loss: 2.115602691968282

Epoch: 6| Step: 6
Training loss: 0.8521734476089478
Validation loss: 2.0640518267949424

Epoch: 6| Step: 7
Training loss: 0.9833252429962158
Validation loss: 2.04518852631251

Epoch: 6| Step: 8
Training loss: 1.3141127824783325
Validation loss: 2.086601674556732

Epoch: 6| Step: 9
Training loss: 1.2360475063323975
Validation loss: 2.107815742492676

Epoch: 6| Step: 10
Training loss: 0.9579430818557739
Validation loss: 2.0860320727030435

Epoch: 6| Step: 11
Training loss: 0.9210689663887024
Validation loss: 2.0732110142707825

Epoch: 6| Step: 12
Training loss: 0.9407947063446045
Validation loss: 2.0479546785354614

Epoch: 6| Step: 13
Training loss: 0.8954373598098755
Validation loss: 2.0427458683649697

Epoch: 156| Step: 0
Training loss: 1.2201409339904785
Validation loss: 2.057227591673533

Epoch: 6| Step: 1
Training loss: 1.380433201789856
Validation loss: 2.031815528869629

Epoch: 6| Step: 2
Training loss: 0.9446743726730347
Validation loss: 2.0181957681973777

Epoch: 6| Step: 3
Training loss: 1.4634733200073242
Validation loss: 2.0589756965637207

Epoch: 6| Step: 4
Training loss: 1.6395785808563232
Validation loss: 2.0667754411697388

Epoch: 6| Step: 5
Training loss: 0.8302503228187561
Validation loss: 2.01170806090037

Epoch: 6| Step: 6
Training loss: 1.097975730895996
Validation loss: 2.0739044547080994

Epoch: 6| Step: 7
Training loss: 1.946576714515686
Validation loss: 2.121332585811615

Epoch: 6| Step: 8
Training loss: 1.0053987503051758
Validation loss: 2.0691450436909995

Epoch: 6| Step: 9
Training loss: 0.6145336031913757
Validation loss: 2.096218744913737

Epoch: 6| Step: 10
Training loss: 0.8959835767745972
Validation loss: 2.063512663046519

Epoch: 6| Step: 11
Training loss: 1.0983595848083496
Validation loss: 2.0634587009747825

Epoch: 6| Step: 12
Training loss: 1.5402932167053223
Validation loss: 2.028547922770182

Epoch: 6| Step: 13
Training loss: 1.359458088874817
Validation loss: 2.055620789527893

Epoch: 157| Step: 0
Training loss: 1.029200553894043
Validation loss: 2.07299268245697

Epoch: 6| Step: 1
Training loss: 1.4997529983520508
Validation loss: 2.0639111200968423

Epoch: 6| Step: 2
Training loss: 0.6664464473724365
Validation loss: 2.044240951538086

Epoch: 6| Step: 3
Training loss: 0.8791528940200806
Validation loss: 2.072721799214681

Epoch: 6| Step: 4
Training loss: 0.8404560089111328
Validation loss: 2.04575252532959

Epoch: 6| Step: 5
Training loss: 1.9845205545425415
Validation loss: 2.1083438197771707

Epoch: 6| Step: 6
Training loss: 0.7429062128067017
Validation loss: 2.0753155946731567

Epoch: 6| Step: 7
Training loss: 1.7382797002792358
Validation loss: 2.083462715148926

Epoch: 6| Step: 8
Training loss: 0.8810423016548157
Validation loss: 2.0268382827440896

Epoch: 6| Step: 9
Training loss: 1.4923474788665771
Validation loss: 2.0269325176874795

Epoch: 6| Step: 10
Training loss: 1.14335036277771
Validation loss: 2.1008582711219788

Epoch: 6| Step: 11
Training loss: 1.4639198780059814
Validation loss: 2.0039567748705545

Epoch: 6| Step: 12
Training loss: 1.3062289953231812
Validation loss: 2.0447059075037637

Epoch: 6| Step: 13
Training loss: 1.6136283874511719
Validation loss: 2.07470566034317

Epoch: 158| Step: 0
Training loss: 0.9256998896598816
Validation loss: 2.055389682451884

Epoch: 6| Step: 1
Training loss: 1.1381492614746094
Validation loss: 2.1195916732152305

Epoch: 6| Step: 2
Training loss: 1.3251382112503052
Validation loss: 2.0363153417905173

Epoch: 6| Step: 3
Training loss: 1.5443274974822998
Validation loss: 2.0184630950291953

Epoch: 6| Step: 4
Training loss: 0.45945286750793457
Validation loss: 2.1213587125142417

Epoch: 6| Step: 5
Training loss: 0.5518031120300293
Validation loss: 2.065110226472219

Epoch: 6| Step: 6
Training loss: 1.452622413635254
Validation loss: 2.0968183676401773

Epoch: 6| Step: 7
Training loss: 1.189858317375183
Validation loss: 2.084860881169637

Epoch: 6| Step: 8
Training loss: 1.1281229257583618
Validation loss: 2.070087512334188

Epoch: 6| Step: 9
Training loss: 0.8811105489730835
Validation loss: 2.078692396481832

Epoch: 6| Step: 10
Training loss: 1.6554316282272339
Validation loss: 2.0757648746172586

Epoch: 6| Step: 11
Training loss: 1.113183856010437
Validation loss: 2.028507093588511

Epoch: 6| Step: 12
Training loss: 1.9018807411193848
Validation loss: 2.0430097182591758

Epoch: 6| Step: 13
Training loss: 1.1999462842941284
Validation loss: 2.043357769648234

Epoch: 159| Step: 0
Training loss: 1.1075674295425415
Validation loss: 2.0763641198476157

Epoch: 6| Step: 1
Training loss: 0.8932105302810669
Validation loss: 2.032392660776774

Epoch: 6| Step: 2
Training loss: 0.7825489044189453
Validation loss: 2.055428365866343

Epoch: 6| Step: 3
Training loss: 1.2011971473693848
Validation loss: 2.0416298111279807

Epoch: 6| Step: 4
Training loss: 1.280875563621521
Validation loss: 2.0802722374598184

Epoch: 6| Step: 5
Training loss: 0.6013433933258057
Validation loss: 2.0782508850097656

Epoch: 6| Step: 6
Training loss: 1.355797290802002
Validation loss: 2.0589312314987183

Epoch: 6| Step: 7
Training loss: 1.6012283563613892
Validation loss: 2.0312017599741616

Epoch: 6| Step: 8
Training loss: 1.1094706058502197
Validation loss: 2.0807376305262246

Epoch: 6| Step: 9
Training loss: 1.1509923934936523
Validation loss: 2.079210638999939

Epoch: 6| Step: 10
Training loss: 1.4314444065093994
Validation loss: 1.9859368403752644

Epoch: 6| Step: 11
Training loss: 1.9884177446365356
Validation loss: 2.043533126513163

Epoch: 6| Step: 12
Training loss: 0.5731674432754517
Validation loss: 2.033947785695394

Epoch: 6| Step: 13
Training loss: 1.2836060523986816
Validation loss: 2.0436290899912515

Epoch: 160| Step: 0
Training loss: 1.323838233947754
Validation loss: 2.058758536974589

Epoch: 6| Step: 1
Training loss: 1.528787612915039
Validation loss: 2.0139251748720803

Epoch: 6| Step: 2
Training loss: 1.0028207302093506
Validation loss: 2.035295387109121

Epoch: 6| Step: 3
Training loss: 1.0295546054840088
Validation loss: 2.0713712175687156

Epoch: 6| Step: 4
Training loss: 1.1874849796295166
Validation loss: 2.046002666155497

Epoch: 6| Step: 5
Training loss: 0.6104792356491089
Validation loss: 2.0560553471247354

Epoch: 6| Step: 6
Training loss: 1.6093370914459229
Validation loss: 2.0708327889442444

Epoch: 6| Step: 7
Training loss: 1.0471290349960327
Validation loss: 2.0524365305900574

Epoch: 6| Step: 8
Training loss: 0.9866764545440674
Validation loss: 2.0258557200431824

Epoch: 6| Step: 9
Training loss: 1.0367130041122437
Validation loss: 2.008905033270518

Epoch: 6| Step: 10
Training loss: 1.0777523517608643
Validation loss: 2.071825305620829

Epoch: 6| Step: 11
Training loss: 1.0716357231140137
Validation loss: 2.0768524209658303

Epoch: 6| Step: 12
Training loss: 1.8961384296417236
Validation loss: 2.059860050678253

Epoch: 6| Step: 13
Training loss: 0.9969911575317383
Validation loss: 2.0886154572168985

Epoch: 161| Step: 0
Training loss: 0.9398050308227539
Validation loss: 2.042023499806722

Epoch: 6| Step: 1
Training loss: 0.8388790488243103
Validation loss: 2.0287208557128906

Epoch: 6| Step: 2
Training loss: 1.4351420402526855
Validation loss: 2.039533774058024

Epoch: 6| Step: 3
Training loss: 1.0919857025146484
Validation loss: 2.0316539804140725

Epoch: 6| Step: 4
Training loss: 0.5496301651000977
Validation loss: 2.05330761273702

Epoch: 6| Step: 5
Training loss: 1.5115184783935547
Validation loss: 2.033096969127655

Epoch: 6| Step: 6
Training loss: 0.9998804330825806
Validation loss: 2.055847148100535

Epoch: 6| Step: 7
Training loss: 1.2992202043533325
Validation loss: 2.0418238639831543

Epoch: 6| Step: 8
Training loss: 1.412893295288086
Validation loss: 2.138345698515574

Epoch: 6| Step: 9
Training loss: 1.3653106689453125
Validation loss: 2.108726660410563

Epoch: 6| Step: 10
Training loss: 1.3973890542984009
Validation loss: 2.066671053568522

Epoch: 6| Step: 11
Training loss: 1.4091609716415405
Validation loss: 2.068318764368693

Epoch: 6| Step: 12
Training loss: 0.6681488752365112
Validation loss: 2.06472917397817

Epoch: 6| Step: 13
Training loss: 1.4626177549362183
Validation loss: 2.0499263207117715

Epoch: 162| Step: 0
Training loss: 1.1215660572052002
Validation loss: 2.05887899796168

Epoch: 6| Step: 1
Training loss: 1.6334571838378906
Validation loss: 2.059145132700602

Epoch: 6| Step: 2
Training loss: 1.1334419250488281
Validation loss: 2.1234673261642456

Epoch: 6| Step: 3
Training loss: 0.6653851270675659
Validation loss: 2.01610920826594

Epoch: 6| Step: 4
Training loss: 2.015500545501709
Validation loss: 2.0803387562433877

Epoch: 6| Step: 5
Training loss: 0.945159375667572
Validation loss: 2.0572352210680642

Epoch: 6| Step: 6
Training loss: 1.3615835905075073
Validation loss: 2.0417954126993814

Epoch: 6| Step: 7
Training loss: 1.0476869344711304
Validation loss: 2.0729833245277405

Epoch: 6| Step: 8
Training loss: 1.378255844116211
Validation loss: 2.1070743600527444

Epoch: 6| Step: 9
Training loss: 0.8724339604377747
Validation loss: 2.0825619101524353

Epoch: 6| Step: 10
Training loss: 0.6708858609199524
Validation loss: 2.079460918903351

Epoch: 6| Step: 11
Training loss: 1.1513698101043701
Validation loss: 2.106676936149597

Epoch: 6| Step: 12
Training loss: 1.0615092515945435
Validation loss: 2.0875951051712036

Epoch: 6| Step: 13
Training loss: 1.2140690088272095
Validation loss: 2.1547104914983115

Epoch: 163| Step: 0
Training loss: 0.5849807262420654
Validation loss: 2.050423721472422

Epoch: 6| Step: 1
Training loss: 0.7366700172424316
Validation loss: 2.007383664449056

Epoch: 6| Step: 2
Training loss: 0.8490269780158997
Validation loss: 2.0687461296717324

Epoch: 6| Step: 3
Training loss: 0.8767009973526001
Validation loss: 2.0982903639475503

Epoch: 6| Step: 4
Training loss: 1.321199655532837
Validation loss: 2.063956161340078

Epoch: 6| Step: 5
Training loss: 1.6860501766204834
Validation loss: 2.028867801030477

Epoch: 6| Step: 6
Training loss: 1.1189947128295898
Validation loss: 2.0787187218666077

Epoch: 6| Step: 7
Training loss: 1.2627214193344116
Validation loss: 2.056553224722544

Epoch: 6| Step: 8
Training loss: 1.030764102935791
Validation loss: 2.104797601699829

Epoch: 6| Step: 9
Training loss: 1.496145486831665
Validation loss: 2.124578615029653

Epoch: 6| Step: 10
Training loss: 1.0151784420013428
Validation loss: 2.1170151233673096

Epoch: 6| Step: 11
Training loss: 1.7543549537658691
Validation loss: 2.1105082432428994

Epoch: 6| Step: 12
Training loss: 0.7675596475601196
Validation loss: 2.051819622516632

Epoch: 6| Step: 13
Training loss: 1.3810992240905762
Validation loss: 2.0804356932640076

Epoch: 164| Step: 0
Training loss: 1.5613584518432617
Validation loss: 2.0522961417833963

Epoch: 6| Step: 1
Training loss: 0.8947381973266602
Validation loss: 2.046903371810913

Epoch: 6| Step: 2
Training loss: 1.1419622898101807
Validation loss: 2.0786449909210205

Epoch: 6| Step: 3
Training loss: 0.9774558544158936
Validation loss: 2.0217992663383484

Epoch: 6| Step: 4
Training loss: 1.1575345993041992
Validation loss: 2.0006087025006614

Epoch: 6| Step: 5
Training loss: 1.526615023612976
Validation loss: 2.024242401123047

Epoch: 6| Step: 6
Training loss: 1.1535736322402954
Validation loss: 2.069518486658732

Epoch: 6| Step: 7
Training loss: 0.7091540098190308
Validation loss: 2.089638074239095

Epoch: 6| Step: 8
Training loss: 1.5371484756469727
Validation loss: 2.093426287174225

Epoch: 6| Step: 9
Training loss: 0.8156338930130005
Validation loss: 2.051510751247406

Epoch: 6| Step: 10
Training loss: 1.1666312217712402
Validation loss: 2.0885689655939736

Epoch: 6| Step: 11
Training loss: 0.8515098690986633
Validation loss: 2.105762759844462

Epoch: 6| Step: 12
Training loss: 1.191730260848999
Validation loss: 2.096933682759603

Epoch: 6| Step: 13
Training loss: 1.353367805480957
Validation loss: 2.102232058842977

Epoch: 165| Step: 0
Training loss: 1.2075247764587402
Validation loss: 2.154638707637787

Epoch: 6| Step: 1
Training loss: 1.1909204721450806
Validation loss: 2.0307804942131042

Epoch: 6| Step: 2
Training loss: 1.122970461845398
Validation loss: 2.1166720191637673

Epoch: 6| Step: 3
Training loss: 1.258510708808899
Validation loss: 2.0472100575764975

Epoch: 6| Step: 4
Training loss: 1.20399010181427
Validation loss: 2.083275536696116

Epoch: 6| Step: 5
Training loss: 1.0730961561203003
Validation loss: 2.0672256549199424

Epoch: 6| Step: 6
Training loss: 0.9552721381187439
Validation loss: 2.0449360807736716

Epoch: 6| Step: 7
Training loss: 1.3039313554763794
Validation loss: 2.0458399653434753

Epoch: 6| Step: 8
Training loss: 0.9797194004058838
Validation loss: 2.0741576552391052

Epoch: 6| Step: 9
Training loss: 1.129271388053894
Validation loss: 2.0487988789876304

Epoch: 6| Step: 10
Training loss: 1.2340317964553833
Validation loss: 2.109887341658274

Epoch: 6| Step: 11
Training loss: 0.7830836772918701
Validation loss: 2.083828389644623

Epoch: 6| Step: 12
Training loss: 0.9681121706962585
Validation loss: 2.071084459622701

Epoch: 6| Step: 13
Training loss: 1.6022515296936035
Validation loss: 2.019343137741089

Epoch: 166| Step: 0
Training loss: 0.6508321166038513
Validation loss: 2.0223862330118814

Epoch: 6| Step: 1
Training loss: 0.7896741628646851
Validation loss: 2.0680813590685525

Epoch: 6| Step: 2
Training loss: 1.5132591724395752
Validation loss: 2.104085683822632

Epoch: 6| Step: 3
Training loss: 1.0527002811431885
Validation loss: 2.032715380191803

Epoch: 6| Step: 4
Training loss: 0.6887111663818359
Validation loss: 2.0376049280166626

Epoch: 6| Step: 5
Training loss: 1.4600830078125
Validation loss: 2.094788372516632

Epoch: 6| Step: 6
Training loss: 1.396986961364746
Validation loss: 2.0536632736523948

Epoch: 6| Step: 7
Training loss: 1.4629747867584229
Validation loss: 2.056628922621409

Epoch: 6| Step: 8
Training loss: 1.6634973287582397
Validation loss: 2.1516425410906472

Epoch: 6| Step: 9
Training loss: 0.7431085109710693
Validation loss: 2.0815351605415344

Epoch: 6| Step: 10
Training loss: 0.977918267250061
Validation loss: 2.081509749094645

Epoch: 6| Step: 11
Training loss: 0.7848676443099976
Validation loss: 2.10383411248525

Epoch: 6| Step: 12
Training loss: 0.9457408785820007
Validation loss: 2.0550381541252136

Epoch: 6| Step: 13
Training loss: 1.4160706996917725
Validation loss: 2.0908649563789368

Epoch: 167| Step: 0
Training loss: 1.7644765377044678
Validation loss: 2.0692601005236306

Epoch: 6| Step: 1
Training loss: 1.2813680171966553
Validation loss: 2.038468599319458

Epoch: 6| Step: 2
Training loss: 0.8187830448150635
Validation loss: 2.0625609159469604

Epoch: 6| Step: 3
Training loss: 1.3271243572235107
Validation loss: 2.0891364415486655

Epoch: 6| Step: 4
Training loss: 1.1661367416381836
Validation loss: 2.063217798868815

Epoch: 6| Step: 5
Training loss: 0.8736288547515869
Validation loss: 2.037240187327067

Epoch: 6| Step: 6
Training loss: 0.693304717540741
Validation loss: 2.12051389614741

Epoch: 6| Step: 7
Training loss: 1.727652668952942
Validation loss: 2.077108939488729

Epoch: 6| Step: 8
Training loss: 0.6787301301956177
Validation loss: 2.0632781783739724

Epoch: 6| Step: 9
Training loss: 0.43965834379196167
Validation loss: 2.049150546391805

Epoch: 6| Step: 10
Training loss: 1.1251509189605713
Validation loss: 2.044338603814443

Epoch: 6| Step: 11
Training loss: 1.3851596117019653
Validation loss: 2.0342899163564048

Epoch: 6| Step: 12
Training loss: 1.1693962812423706
Validation loss: 2.0929295420646667

Epoch: 6| Step: 13
Training loss: 0.9836409091949463
Validation loss: 2.035226821899414

Epoch: 168| Step: 0
Training loss: 1.1548819541931152
Validation loss: 2.0582298636436462

Epoch: 6| Step: 1
Training loss: 0.6998928189277649
Validation loss: 2.138599375883738

Epoch: 6| Step: 2
Training loss: 1.4806663990020752
Validation loss: 2.0614176193873086

Epoch: 6| Step: 3
Training loss: 0.8106018304824829
Validation loss: 2.0340075492858887

Epoch: 6| Step: 4
Training loss: 1.5590500831604004
Validation loss: 2.034599224726359

Epoch: 6| Step: 5
Training loss: 1.1164897680282593
Validation loss: 2.1068171660105386

Epoch: 6| Step: 6
Training loss: 0.9218575954437256
Validation loss: 2.094315846761068

Epoch: 6| Step: 7
Training loss: 0.724882960319519
Validation loss: 2.1306082208951316

Epoch: 6| Step: 8
Training loss: 1.032235860824585
Validation loss: 2.0871750116348267

Epoch: 6| Step: 9
Training loss: 1.1970746517181396
Validation loss: 2.0792265931765237

Epoch: 6| Step: 10
Training loss: 1.3299859762191772
Validation loss: 2.041657865047455

Epoch: 6| Step: 11
Training loss: 1.3000131845474243
Validation loss: 2.0546040137608848

Epoch: 6| Step: 12
Training loss: 0.9222509860992432
Validation loss: 2.066858649253845

Epoch: 6| Step: 13
Training loss: 0.9803842306137085
Validation loss: 2.0527217984199524

Epoch: 169| Step: 0
Training loss: 1.7700574398040771
Validation loss: 2.087201495965322

Epoch: 6| Step: 1
Training loss: 1.0506420135498047
Validation loss: 2.085624933242798

Epoch: 6| Step: 2
Training loss: 0.822441816329956
Validation loss: 2.124876340230306

Epoch: 6| Step: 3
Training loss: 1.242730736732483
Validation loss: 2.0507152676582336

Epoch: 6| Step: 4
Training loss: 1.5751750469207764
Validation loss: 2.004913548628489

Epoch: 6| Step: 5
Training loss: 0.7001112699508667
Validation loss: 2.00130824247996

Epoch: 6| Step: 6
Training loss: 0.7469884157180786
Validation loss: 2.0715086857477822

Epoch: 6| Step: 7
Training loss: 1.6597059965133667
Validation loss: 2.1011011401812234

Epoch: 6| Step: 8
Training loss: 1.2859243154525757
Validation loss: 2.115953246752421

Epoch: 6| Step: 9
Training loss: 0.7076833248138428
Validation loss: 2.106083114941915

Epoch: 6| Step: 10
Training loss: 1.0113433599472046
Validation loss: 2.0807557503382363

Epoch: 6| Step: 11
Training loss: 0.899478018283844
Validation loss: 2.0404357512791953

Epoch: 6| Step: 12
Training loss: 0.6928392648696899
Validation loss: 2.0889726877212524

Epoch: 6| Step: 13
Training loss: 0.9672725200653076
Validation loss: 2.077011207739512

Epoch: 170| Step: 0
Training loss: 1.1322648525238037
Validation loss: 2.045933802922567

Epoch: 6| Step: 1
Training loss: 0.8867314457893372
Validation loss: 2.057307004928589

Epoch: 6| Step: 2
Training loss: 0.9672349691390991
Validation loss: 2.104047179222107

Epoch: 6| Step: 3
Training loss: 1.51394522190094
Validation loss: 2.0795245369275412

Epoch: 6| Step: 4
Training loss: 1.4198601245880127
Validation loss: 2.0971337954203286

Epoch: 6| Step: 5
Training loss: 0.8632340431213379
Validation loss: 2.1005979975064597

Epoch: 6| Step: 6
Training loss: 0.6806043386459351
Validation loss: 2.0726597706476846

Epoch: 6| Step: 7
Training loss: 1.3993992805480957
Validation loss: 2.026097297668457

Epoch: 6| Step: 8
Training loss: 0.6526167988777161
Validation loss: 2.0277446111043296

Epoch: 6| Step: 9
Training loss: 1.1808242797851562
Validation loss: 2.080195943514506

Epoch: 6| Step: 10
Training loss: 0.588245153427124
Validation loss: 2.059788922468821

Epoch: 6| Step: 11
Training loss: 1.3412227630615234
Validation loss: 2.0985668698946633

Epoch: 6| Step: 12
Training loss: 1.1707098484039307
Validation loss: 2.0764954487482705

Epoch: 6| Step: 13
Training loss: 1.2809032201766968
Validation loss: 2.0491992036501565

Epoch: 171| Step: 0
Training loss: 1.145711898803711
Validation loss: 2.0470558404922485

Epoch: 6| Step: 1
Training loss: 1.2109959125518799
Validation loss: 2.101322650909424

Epoch: 6| Step: 2
Training loss: 0.8352397084236145
Validation loss: 2.0803461273511252

Epoch: 6| Step: 3
Training loss: 1.1768720149993896
Validation loss: 2.0507463812828064

Epoch: 6| Step: 4
Training loss: 1.4511096477508545
Validation loss: 2.0647022128105164

Epoch: 6| Step: 5
Training loss: 0.8213919997215271
Validation loss: 2.0892082850138345

Epoch: 6| Step: 6
Training loss: 0.8819838762283325
Validation loss: 2.1102002064387

Epoch: 6| Step: 7
Training loss: 1.211366057395935
Validation loss: 2.080749054749807

Epoch: 6| Step: 8
Training loss: 0.5827337503433228
Validation loss: 2.1056379874547324

Epoch: 6| Step: 9
Training loss: 1.2766201496124268
Validation loss: 2.060910403728485

Epoch: 6| Step: 10
Training loss: 1.2441984415054321
Validation loss: 2.121718188126882

Epoch: 6| Step: 11
Training loss: 0.6432076692581177
Validation loss: 2.0691993633906045

Epoch: 6| Step: 12
Training loss: 1.4716804027557373
Validation loss: 2.1121089855829873

Epoch: 6| Step: 13
Training loss: 1.1323169469833374
Validation loss: 2.0811341206232705

Epoch: 172| Step: 0
Training loss: 1.0546956062316895
Validation loss: 2.0883284409840903

Epoch: 6| Step: 1
Training loss: 1.3410921096801758
Validation loss: 2.11485763390859

Epoch: 6| Step: 2
Training loss: 1.359970211982727
Validation loss: 2.0541332562764487

Epoch: 6| Step: 3
Training loss: 1.7593671083450317
Validation loss: 2.062635898590088

Epoch: 6| Step: 4
Training loss: 1.429266095161438
Validation loss: 2.0421000321706138

Epoch: 6| Step: 5
Training loss: 1.147326946258545
Validation loss: 2.0715116461118064

Epoch: 6| Step: 6
Training loss: 0.8060407042503357
Validation loss: 2.0712156295776367

Epoch: 6| Step: 7
Training loss: 1.029099941253662
Validation loss: 2.070912798245748

Epoch: 6| Step: 8
Training loss: 1.1487069129943848
Validation loss: 2.11054797967275

Epoch: 6| Step: 9
Training loss: 0.6117190718650818
Validation loss: 2.07647971312205

Epoch: 6| Step: 10
Training loss: 0.9019891023635864
Validation loss: 2.1097973386446633

Epoch: 6| Step: 11
Training loss: 0.5349477529525757
Validation loss: 2.104626496632894

Epoch: 6| Step: 12
Training loss: 1.0300780534744263
Validation loss: 2.0160757501920066

Epoch: 6| Step: 13
Training loss: 0.744233250617981
Validation loss: 2.06860081354777

Epoch: 173| Step: 0
Training loss: 1.0857611894607544
Validation loss: 2.0812964042027793

Epoch: 6| Step: 1
Training loss: 0.8884193897247314
Validation loss: 2.0427273909250894

Epoch: 6| Step: 2
Training loss: 0.8416702747344971
Validation loss: 2.1434027949968972

Epoch: 6| Step: 3
Training loss: 1.2094813585281372
Validation loss: 2.079040825366974

Epoch: 6| Step: 4
Training loss: 1.1742557287216187
Validation loss: 2.107546587785085

Epoch: 6| Step: 5
Training loss: 0.9358199834823608
Validation loss: 2.1598317424456277

Epoch: 6| Step: 6
Training loss: 1.278045415878296
Validation loss: 2.1064111391703286

Epoch: 6| Step: 7
Training loss: 1.0843005180358887
Validation loss: 2.0782774686813354

Epoch: 6| Step: 8
Training loss: 0.6690859794616699
Validation loss: 2.0631167689959207

Epoch: 6| Step: 9
Training loss: 1.5116651058197021
Validation loss: 2.0703460772832236

Epoch: 6| Step: 10
Training loss: 1.1535837650299072
Validation loss: 2.03117827574412

Epoch: 6| Step: 11
Training loss: 1.3761379718780518
Validation loss: 2.0497838656107583

Epoch: 6| Step: 12
Training loss: 1.1215049028396606
Validation loss: 2.0606457789738974

Epoch: 6| Step: 13
Training loss: 1.1752476692199707
Validation loss: 2.0528813203175864

Epoch: 174| Step: 0
Training loss: 0.9380105137825012
Validation loss: 2.0256809194882712

Epoch: 6| Step: 1
Training loss: 1.3973827362060547
Validation loss: 2.0783751408259072

Epoch: 6| Step: 2
Training loss: 1.183962106704712
Validation loss: 2.0673613945643106

Epoch: 6| Step: 3
Training loss: 0.9181650876998901
Validation loss: 2.039122442404429

Epoch: 6| Step: 4
Training loss: 1.2823686599731445
Validation loss: 2.0979581077893577

Epoch: 6| Step: 5
Training loss: 0.6524643301963806
Validation loss: 2.0594239632288613

Epoch: 6| Step: 6
Training loss: 1.0871803760528564
Validation loss: 2.1246392329533896

Epoch: 6| Step: 7
Training loss: 1.268183708190918
Validation loss: 2.0530633330345154

Epoch: 6| Step: 8
Training loss: 1.1581001281738281
Validation loss: 2.141272246837616

Epoch: 6| Step: 9
Training loss: 0.33018165826797485
Validation loss: 2.1160853703816733

Epoch: 6| Step: 10
Training loss: 0.9224894046783447
Validation loss: 2.1387688517570496

Epoch: 6| Step: 11
Training loss: 1.0417516231536865
Validation loss: 2.051789323488871

Epoch: 6| Step: 12
Training loss: 0.6767394542694092
Validation loss: 2.081582248210907

Epoch: 6| Step: 13
Training loss: 1.7802194356918335
Validation loss: 2.1129066944122314

Epoch: 175| Step: 0
Training loss: 1.1794586181640625
Validation loss: 2.1509405771891275

Epoch: 6| Step: 1
Training loss: 1.2188923358917236
Validation loss: 2.1053726077079773

Epoch: 6| Step: 2
Training loss: 0.8387388586997986
Validation loss: 2.111581802368164

Epoch: 6| Step: 3
Training loss: 0.6417819857597351
Validation loss: 2.0504462321599326

Epoch: 6| Step: 4
Training loss: 0.8661271333694458
Validation loss: 2.0736753940582275

Epoch: 6| Step: 5
Training loss: 1.4724388122558594
Validation loss: 2.085532009601593

Epoch: 6| Step: 6
Training loss: 0.4454803466796875
Validation loss: 2.108074406782786

Epoch: 6| Step: 7
Training loss: 1.089275598526001
Validation loss: 2.0623661478360495

Epoch: 6| Step: 8
Training loss: 1.2167507410049438
Validation loss: 2.0476625561714172

Epoch: 6| Step: 9
Training loss: 1.1553955078125
Validation loss: 2.0904600818951926

Epoch: 6| Step: 10
Training loss: 1.5193917751312256
Validation loss: 2.0841768980026245

Epoch: 6| Step: 11
Training loss: 1.2946648597717285
Validation loss: 2.0752212007840476

Epoch: 6| Step: 12
Training loss: 1.0967516899108887
Validation loss: 2.113513966401418

Epoch: 6| Step: 13
Training loss: 0.8064548969268799
Validation loss: 2.0535678466161094

Epoch: 176| Step: 0
Training loss: 1.3283215761184692
Validation loss: 2.0876770416895547

Epoch: 6| Step: 1
Training loss: 0.8534397482872009
Validation loss: 2.071005622545878

Epoch: 6| Step: 2
Training loss: 0.9087705612182617
Validation loss: 2.0706844131151834

Epoch: 6| Step: 3
Training loss: 0.6062647700309753
Validation loss: 2.063345789909363

Epoch: 6| Step: 4
Training loss: 1.053194522857666
Validation loss: 2.063692291577657

Epoch: 6| Step: 5
Training loss: 0.8229823112487793
Validation loss: 2.0964462757110596

Epoch: 6| Step: 6
Training loss: 0.9663978815078735
Validation loss: 2.063037097454071

Epoch: 6| Step: 7
Training loss: 0.9021310806274414
Validation loss: 2.1141245365142822

Epoch: 6| Step: 8
Training loss: 1.2004027366638184
Validation loss: 2.083796739578247

Epoch: 6| Step: 9
Training loss: 1.5974633693695068
Validation loss: 2.0302029848098755

Epoch: 6| Step: 10
Training loss: 1.0550806522369385
Validation loss: 2.1293697158495584

Epoch: 6| Step: 11
Training loss: 0.9721484780311584
Validation loss: 2.061373313268026

Epoch: 6| Step: 12
Training loss: 0.9075917601585388
Validation loss: 2.0952592889467874

Epoch: 6| Step: 13
Training loss: 1.1041302680969238
Validation loss: 2.155558943748474

Epoch: 177| Step: 0
Training loss: 1.832990050315857
Validation loss: 2.0901529788970947

Epoch: 6| Step: 1
Training loss: 1.3882684707641602
Validation loss: 2.0992576281229653

Epoch: 6| Step: 2
Training loss: 0.5890998840332031
Validation loss: 2.074992537498474

Epoch: 6| Step: 3
Training loss: 1.0797035694122314
Validation loss: 2.079883416493734

Epoch: 6| Step: 4
Training loss: 1.847884178161621
Validation loss: 2.1012685100237527

Epoch: 6| Step: 5
Training loss: 0.9247757196426392
Validation loss: 2.0743083159128823

Epoch: 6| Step: 6
Training loss: 0.7415284514427185
Validation loss: 2.041381319363912

Epoch: 6| Step: 7
Training loss: 0.8884608149528503
Validation loss: 2.0778027176856995

Epoch: 6| Step: 8
Training loss: 0.7450569868087769
Validation loss: 2.1377191146214805

Epoch: 6| Step: 9
Training loss: 0.6782493591308594
Validation loss: 2.1089022159576416

Epoch: 6| Step: 10
Training loss: 1.0851606130599976
Validation loss: 2.031842370827993

Epoch: 6| Step: 11
Training loss: 0.7666411995887756
Validation loss: 2.1336745023727417

Epoch: 6| Step: 12
Training loss: 0.7703691720962524
Validation loss: 2.0818346738815308

Epoch: 6| Step: 13
Training loss: 0.8719301223754883
Validation loss: 2.0677843491236367

Epoch: 178| Step: 0
Training loss: 1.1029820442199707
Validation loss: 2.1128206849098206

Epoch: 6| Step: 1
Training loss: 1.1245763301849365
Validation loss: 2.0806487798690796

Epoch: 6| Step: 2
Training loss: 1.4036149978637695
Validation loss: 2.073950548966726

Epoch: 6| Step: 3
Training loss: 0.7379533052444458
Validation loss: 2.0501477320988974

Epoch: 6| Step: 4
Training loss: 1.1429810523986816
Validation loss: 2.0947782595952353

Epoch: 6| Step: 5
Training loss: 1.1282525062561035
Validation loss: 2.0558899442354837

Epoch: 6| Step: 6
Training loss: 0.8222623467445374
Validation loss: 2.076985160509745

Epoch: 6| Step: 7
Training loss: 0.7713923454284668
Validation loss: 2.0879217982292175

Epoch: 6| Step: 8
Training loss: 1.0635015964508057
Validation loss: 2.1013782620429993

Epoch: 6| Step: 9
Training loss: 0.9999020099639893
Validation loss: 2.1156079173088074

Epoch: 6| Step: 10
Training loss: 1.0034680366516113
Validation loss: 2.1495553453763327

Epoch: 6| Step: 11
Training loss: 0.8709405064582825
Validation loss: 2.0812614957491555

Epoch: 6| Step: 12
Training loss: 1.5675532817840576
Validation loss: 2.0489198764165244

Epoch: 6| Step: 13
Training loss: 0.5760003924369812
Validation loss: 2.076649089654287

Epoch: 179| Step: 0
Training loss: 0.955437421798706
Validation loss: 2.102160851160685

Epoch: 6| Step: 1
Training loss: 0.596811056137085
Validation loss: 2.106187184651693

Epoch: 6| Step: 2
Training loss: 0.9420326948165894
Validation loss: 2.124283770720164

Epoch: 6| Step: 3
Training loss: 0.9439641237258911
Validation loss: 2.104006369908651

Epoch: 6| Step: 4
Training loss: 1.0454219579696655
Validation loss: 2.1059818466504416

Epoch: 6| Step: 5
Training loss: 1.0502641201019287
Validation loss: 2.11991278330485

Epoch: 6| Step: 6
Training loss: 1.0826090574264526
Validation loss: 2.10365754365921

Epoch: 6| Step: 7
Training loss: 1.6301369667053223
Validation loss: 2.1067283948262534

Epoch: 6| Step: 8
Training loss: 0.9758219718933105
Validation loss: 2.0596744418144226

Epoch: 6| Step: 9
Training loss: 0.6973710060119629
Validation loss: 2.1064256032307944

Epoch: 6| Step: 10
Training loss: 1.1498429775238037
Validation loss: 2.1053920785586038

Epoch: 6| Step: 11
Training loss: 0.6914887428283691
Validation loss: 2.119525750478109

Epoch: 6| Step: 12
Training loss: 0.9165093898773193
Validation loss: 2.130762259165446

Epoch: 6| Step: 13
Training loss: 1.571821928024292
Validation loss: 2.053490857283274

Epoch: 180| Step: 0
Training loss: 1.5517382621765137
Validation loss: 2.1010183691978455

Epoch: 6| Step: 1
Training loss: 0.7704416513442993
Validation loss: 2.098884661992391

Epoch: 6| Step: 2
Training loss: 0.9135948419570923
Validation loss: 2.15376216173172

Epoch: 6| Step: 3
Training loss: 0.9442106485366821
Validation loss: 2.1272855401039124

Epoch: 6| Step: 4
Training loss: 0.8549111485481262
Validation loss: 2.107878347237905

Epoch: 6| Step: 5
Training loss: 1.282968521118164
Validation loss: 2.058534562587738

Epoch: 6| Step: 6
Training loss: 0.8053807616233826
Validation loss: 2.051225940386454

Epoch: 6| Step: 7
Training loss: 1.439906358718872
Validation loss: 2.0406756599744162

Epoch: 6| Step: 8
Training loss: 0.8191724419593811
Validation loss: 2.0719872315724692

Epoch: 6| Step: 9
Training loss: 1.5037007331848145
Validation loss: 2.094929317633311

Epoch: 6| Step: 10
Training loss: 0.7461738586425781
Validation loss: 2.082628687222799

Epoch: 6| Step: 11
Training loss: 0.8109402060508728
Validation loss: 2.0972224871317544

Epoch: 6| Step: 12
Training loss: 0.9738194346427917
Validation loss: 2.051122009754181

Epoch: 6| Step: 13
Training loss: 0.5585379004478455
Validation loss: 2.083686888217926

Epoch: 181| Step: 0
Training loss: 0.9376091957092285
Validation loss: 2.0926480690638223

Epoch: 6| Step: 1
Training loss: 1.6201651096343994
Validation loss: 2.0537502566973367

Epoch: 6| Step: 2
Training loss: 0.7787001729011536
Validation loss: 2.0862335364023843

Epoch: 6| Step: 3
Training loss: 1.3477481603622437
Validation loss: 2.087583323319753

Epoch: 6| Step: 4
Training loss: 1.2823036909103394
Validation loss: 2.0749994119008384

Epoch: 6| Step: 5
Training loss: 0.5388466715812683
Validation loss: 2.0694392323493958

Epoch: 6| Step: 6
Training loss: 0.6226428747177124
Validation loss: 2.085282544294993

Epoch: 6| Step: 7
Training loss: 0.870357871055603
Validation loss: 2.1016149123509726

Epoch: 6| Step: 8
Training loss: 0.7575231194496155
Validation loss: 2.1309128403663635

Epoch: 6| Step: 9
Training loss: 0.5411336421966553
Validation loss: 2.1243602633476257

Epoch: 6| Step: 10
Training loss: 1.6591017246246338
Validation loss: 2.0984331369400024

Epoch: 6| Step: 11
Training loss: 0.8868114948272705
Validation loss: 2.1329314907391868

Epoch: 6| Step: 12
Training loss: 1.322622537612915
Validation loss: 2.132188538710276

Epoch: 6| Step: 13
Training loss: 1.1441417932510376
Validation loss: 2.1469340125719705

Epoch: 182| Step: 0
Training loss: 1.0254932641983032
Validation loss: 2.1048675775527954

Epoch: 6| Step: 1
Training loss: 0.8647681474685669
Validation loss: 2.048814276854197

Epoch: 6| Step: 2
Training loss: 1.142338514328003
Validation loss: 2.0794347325960794

Epoch: 6| Step: 3
Training loss: 0.9610613584518433
Validation loss: 2.1253508726755777

Epoch: 6| Step: 4
Training loss: 1.0223195552825928
Validation loss: 2.1065369645754495

Epoch: 6| Step: 5
Training loss: 1.2984691858291626
Validation loss: 2.055142800013224

Epoch: 6| Step: 6
Training loss: 0.8858680725097656
Validation loss: 2.171177784601847

Epoch: 6| Step: 7
Training loss: 0.842903196811676
Validation loss: 2.072181463241577

Epoch: 6| Step: 8
Training loss: 1.2660770416259766
Validation loss: 2.0901313026746116

Epoch: 6| Step: 9
Training loss: 0.68677818775177
Validation loss: 2.1144303480784097

Epoch: 6| Step: 10
Training loss: 0.8661675453186035
Validation loss: 2.1069560448328652

Epoch: 6| Step: 11
Training loss: 0.7580394148826599
Validation loss: 2.0963472723960876

Epoch: 6| Step: 12
Training loss: 1.6203389167785645
Validation loss: 2.0687094728151956

Epoch: 6| Step: 13
Training loss: 0.998884379863739
Validation loss: 2.0997459093729653

Epoch: 183| Step: 0
Training loss: 1.0213083028793335
Validation loss: 2.078848958015442

Epoch: 6| Step: 1
Training loss: 0.3614303171634674
Validation loss: 2.1715653936068215

Epoch: 6| Step: 2
Training loss: 0.8401888608932495
Validation loss: 2.091981848080953

Epoch: 6| Step: 3
Training loss: 1.0589109659194946
Validation loss: 2.1232676108678183

Epoch: 6| Step: 4
Training loss: 0.7711524963378906
Validation loss: 2.1065560777982077

Epoch: 6| Step: 5
Training loss: 1.0522994995117188
Validation loss: 2.1128042737642923

Epoch: 6| Step: 6
Training loss: 0.9509966969490051
Validation loss: 2.091445247332255

Epoch: 6| Step: 7
Training loss: 1.3590147495269775
Validation loss: 2.103175620237986

Epoch: 6| Step: 8
Training loss: 0.878058910369873
Validation loss: 2.103824337323507

Epoch: 6| Step: 9
Training loss: 0.8983625173568726
Validation loss: 2.139737288157145

Epoch: 6| Step: 10
Training loss: 1.0538146495819092
Validation loss: 2.150718947251638

Epoch: 6| Step: 11
Training loss: 1.1333948373794556
Validation loss: 2.126023272673289

Epoch: 6| Step: 12
Training loss: 1.0691651105880737
Validation loss: 2.120674987634023

Epoch: 6| Step: 13
Training loss: 0.9776566624641418
Validation loss: 2.0891119043032327

Epoch: 184| Step: 0
Training loss: 0.5297226905822754
Validation loss: 2.0639312664667764

Epoch: 6| Step: 1
Training loss: 1.1268411874771118
Validation loss: 2.070735295613607

Epoch: 6| Step: 2
Training loss: 1.204890251159668
Validation loss: 2.1031925876935325

Epoch: 6| Step: 3
Training loss: 0.7673972845077515
Validation loss: 2.0831202069918313

Epoch: 6| Step: 4
Training loss: 0.9701566696166992
Validation loss: 2.0892282923062644

Epoch: 6| Step: 5
Training loss: 0.9312743544578552
Validation loss: 2.1328814029693604

Epoch: 6| Step: 6
Training loss: 1.0664221048355103
Validation loss: 2.1043046514193215

Epoch: 6| Step: 7
Training loss: 0.8094820380210876
Validation loss: 2.074833075205485

Epoch: 6| Step: 8
Training loss: 0.6739805340766907
Validation loss: 2.126349071661631

Epoch: 6| Step: 9
Training loss: 0.6185380816459656
Validation loss: 2.067573885122935

Epoch: 6| Step: 10
Training loss: 1.0646017789840698
Validation loss: 2.1231547792752585

Epoch: 6| Step: 11
Training loss: 1.7048754692077637
Validation loss: 2.1239266395568848

Epoch: 6| Step: 12
Training loss: 1.3814246654510498
Validation loss: 2.0942219694455466

Epoch: 6| Step: 13
Training loss: 1.1168978214263916
Validation loss: 2.0855420430501304

Epoch: 185| Step: 0
Training loss: 1.1744496822357178
Validation loss: 2.138885796070099

Epoch: 6| Step: 1
Training loss: 1.0281808376312256
Validation loss: 2.081705411275228

Epoch: 6| Step: 2
Training loss: 0.31843456625938416
Validation loss: 2.103624999523163

Epoch: 6| Step: 3
Training loss: 1.0359852313995361
Validation loss: 2.075933357079824

Epoch: 6| Step: 4
Training loss: 1.0391442775726318
Validation loss: 2.1244945526123047

Epoch: 6| Step: 5
Training loss: 0.3847726583480835
Validation loss: 2.0951935052871704

Epoch: 6| Step: 6
Training loss: 0.7341365218162537
Validation loss: 2.1313467621803284

Epoch: 6| Step: 7
Training loss: 0.7322593927383423
Validation loss: 2.053925116856893

Epoch: 6| Step: 8
Training loss: 0.8820270299911499
Validation loss: 2.0983542799949646

Epoch: 6| Step: 9
Training loss: 1.001271367073059
Validation loss: 2.087231934070587

Epoch: 6| Step: 10
Training loss: 0.7275050282478333
Validation loss: 2.1014593640963235

Epoch: 6| Step: 11
Training loss: 1.5392491817474365
Validation loss: 2.120154162247976

Epoch: 6| Step: 12
Training loss: 1.39383864402771
Validation loss: 2.1306189695994058

Epoch: 6| Step: 13
Training loss: 1.313549518585205
Validation loss: 2.0872026681900024

Epoch: 186| Step: 0
Training loss: 1.3613489866256714
Validation loss: 2.0831714868545532

Epoch: 6| Step: 1
Training loss: 0.6547209620475769
Validation loss: 2.086746652921041

Epoch: 6| Step: 2
Training loss: 1.0698012113571167
Validation loss: 2.148711303869883

Epoch: 6| Step: 3
Training loss: 0.6886109113693237
Validation loss: 2.1176527937253318

Epoch: 6| Step: 4
Training loss: 0.8513647317886353
Validation loss: 2.1118391354878745

Epoch: 6| Step: 5
Training loss: 0.5957664251327515
Validation loss: 2.1197200417518616

Epoch: 6| Step: 6
Training loss: 1.0526374578475952
Validation loss: 2.102514922618866

Epoch: 6| Step: 7
Training loss: 1.0044715404510498
Validation loss: 2.083060363928477

Epoch: 6| Step: 8
Training loss: 1.1438465118408203
Validation loss: 2.1009684205055237

Epoch: 6| Step: 9
Training loss: 0.8997476100921631
Validation loss: 2.1477606097857156

Epoch: 6| Step: 10
Training loss: 0.8572308421134949
Validation loss: 2.1449806491533914

Epoch: 6| Step: 11
Training loss: 0.9107058048248291
Validation loss: 2.0542332530021667

Epoch: 6| Step: 12
Training loss: 1.3866915702819824
Validation loss: 2.0958977739016214

Epoch: 6| Step: 13
Training loss: 0.654274046421051
Validation loss: 2.0643884738286338

Epoch: 187| Step: 0
Training loss: 0.4638006389141083
Validation loss: 2.093182682991028

Epoch: 6| Step: 1
Training loss: 1.101839303970337
Validation loss: 2.047091861565908

Epoch: 6| Step: 2
Training loss: 0.8399316072463989
Validation loss: 2.065048257509867

Epoch: 6| Step: 3
Training loss: 1.0420514345169067
Validation loss: 2.11514413356781

Epoch: 6| Step: 4
Training loss: 0.7741886377334595
Validation loss: 2.1567706863085427

Epoch: 6| Step: 5
Training loss: 1.120315670967102
Validation loss: 2.1166235407193503

Epoch: 6| Step: 6
Training loss: 1.2344088554382324
Validation loss: 2.1190916697184243

Epoch: 6| Step: 7
Training loss: 0.8011067509651184
Validation loss: 2.114597976207733

Epoch: 6| Step: 8
Training loss: 0.7237977385520935
Validation loss: 2.0987046559651694

Epoch: 6| Step: 9
Training loss: 1.8158349990844727
Validation loss: 2.08004363377889

Epoch: 6| Step: 10
Training loss: 0.6587147116661072
Validation loss: 2.087646226088206

Epoch: 6| Step: 11
Training loss: 0.6872972846031189
Validation loss: 2.13821941614151

Epoch: 6| Step: 12
Training loss: 0.5056621432304382
Validation loss: 2.108551879723867

Epoch: 6| Step: 13
Training loss: 1.2378754615783691
Validation loss: 2.0763313372929892

Epoch: 188| Step: 0
Training loss: 0.8813234567642212
Validation loss: 2.0698752403259277

Epoch: 6| Step: 1
Training loss: 1.7827157974243164
Validation loss: 2.102411429087321

Epoch: 6| Step: 2
Training loss: 0.998181164264679
Validation loss: 2.1140692234039307

Epoch: 6| Step: 3
Training loss: 0.7672428488731384
Validation loss: 2.123685876528422

Epoch: 6| Step: 4
Training loss: 0.9187779426574707
Validation loss: 2.0758146047592163

Epoch: 6| Step: 5
Training loss: 1.1961747407913208
Validation loss: 2.0745978554089866

Epoch: 6| Step: 6
Training loss: 0.6186979413032532
Validation loss: 2.1324154337247214

Epoch: 6| Step: 7
Training loss: 0.6815234422683716
Validation loss: 2.1062903006871543

Epoch: 6| Step: 8
Training loss: 0.9590834379196167
Validation loss: 2.134320696194967

Epoch: 6| Step: 9
Training loss: 0.7840933799743652
Validation loss: 2.1027137835820517

Epoch: 6| Step: 10
Training loss: 1.0775015354156494
Validation loss: 2.1220441460609436

Epoch: 6| Step: 11
Training loss: 0.5915699005126953
Validation loss: 2.1072535713513694

Epoch: 6| Step: 12
Training loss: 0.6263250112533569
Validation loss: 2.11883682012558

Epoch: 6| Step: 13
Training loss: 1.0902457237243652
Validation loss: 2.1382137735684714

Epoch: 189| Step: 0
Training loss: 1.3079091310501099
Validation loss: 2.0844237009684243

Epoch: 6| Step: 1
Training loss: 0.933395504951477
Validation loss: 2.1492932637532554

Epoch: 6| Step: 2
Training loss: 0.8439832329750061
Validation loss: 2.0968053936958313

Epoch: 6| Step: 3
Training loss: 0.6992201805114746
Validation loss: 2.1345944007237754

Epoch: 6| Step: 4
Training loss: 0.8780698776245117
Validation loss: 2.1732301115989685

Epoch: 6| Step: 5
Training loss: 0.6745545864105225
Validation loss: 2.098484377066294

Epoch: 6| Step: 6
Training loss: 1.0966711044311523
Validation loss: 2.0502214829126992

Epoch: 6| Step: 7
Training loss: 0.6432015895843506
Validation loss: 2.1521634260813394

Epoch: 6| Step: 8
Training loss: 0.8756323456764221
Validation loss: 2.146742860476176

Epoch: 6| Step: 9
Training loss: 1.0421788692474365
Validation loss: 2.047157069047292

Epoch: 6| Step: 10
Training loss: 0.8722357749938965
Validation loss: 2.1255250771840415

Epoch: 6| Step: 11
Training loss: 0.587699294090271
Validation loss: 2.1309340596199036

Epoch: 6| Step: 12
Training loss: 0.992367148399353
Validation loss: 2.1805860797564187

Epoch: 6| Step: 13
Training loss: 1.6605279445648193
Validation loss: 2.131089925765991

Epoch: 190| Step: 0
Training loss: 1.2116281986236572
Validation loss: 2.1365504066149392

Epoch: 6| Step: 1
Training loss: 1.3315982818603516
Validation loss: 2.132096250851949

Epoch: 6| Step: 2
Training loss: 0.40396395325660706
Validation loss: 2.1283232967058816

Epoch: 6| Step: 3
Training loss: 1.2905699014663696
Validation loss: 2.095747689406077

Epoch: 6| Step: 4
Training loss: 0.9259891510009766
Validation loss: 2.0344117283821106

Epoch: 6| Step: 5
Training loss: 1.0083532333374023
Validation loss: 2.0895460844039917

Epoch: 6| Step: 6
Training loss: 0.9291918277740479
Validation loss: 2.136497696240743

Epoch: 6| Step: 7
Training loss: 0.9598575830459595
Validation loss: 2.129875659942627

Epoch: 6| Step: 8
Training loss: 1.0960965156555176
Validation loss: 2.144265353679657

Epoch: 6| Step: 9
Training loss: 0.6758036017417908
Validation loss: 2.1413100759188333

Epoch: 6| Step: 10
Training loss: 0.9988988637924194
Validation loss: 2.1509549220403037

Epoch: 6| Step: 11
Training loss: 0.8952750563621521
Validation loss: 2.1395016511281333

Epoch: 6| Step: 12
Training loss: 0.9306746125221252
Validation loss: 2.123684366544088

Epoch: 6| Step: 13
Training loss: 0.5743473768234253
Validation loss: 2.0887840390205383

Epoch: 191| Step: 0
Training loss: 1.0186609029769897
Validation loss: 2.1134243408838906

Epoch: 6| Step: 1
Training loss: 0.7403700351715088
Validation loss: 2.057500123977661

Epoch: 6| Step: 2
Training loss: 0.912889838218689
Validation loss: 2.1045389572779336

Epoch: 6| Step: 3
Training loss: 0.9129859209060669
Validation loss: 2.1382489601771035

Epoch: 6| Step: 4
Training loss: 0.8924407958984375
Validation loss: 2.134645998477936

Epoch: 6| Step: 5
Training loss: 1.02737557888031
Validation loss: 2.1081598003705344

Epoch: 6| Step: 6
Training loss: 0.46921876072883606
Validation loss: 2.1014938950538635

Epoch: 6| Step: 7
Training loss: 0.8265262842178345
Validation loss: 2.1616766850153604

Epoch: 6| Step: 8
Training loss: 0.7659712433815002
Validation loss: 2.171168108781179

Epoch: 6| Step: 9
Training loss: 0.8220887184143066
Validation loss: 2.192534943421682

Epoch: 6| Step: 10
Training loss: 1.1772091388702393
Validation loss: 2.1534982124964395

Epoch: 6| Step: 11
Training loss: 0.8818178772926331
Validation loss: 2.0901034673055015

Epoch: 6| Step: 12
Training loss: 0.7961325645446777
Validation loss: 2.13291734457016

Epoch: 6| Step: 13
Training loss: 1.557309627532959
Validation loss: 2.098083217938741

Epoch: 192| Step: 0
Training loss: 1.2525184154510498
Validation loss: 2.1460995078086853

Epoch: 6| Step: 1
Training loss: 0.7329509258270264
Validation loss: 2.1170679926872253

Epoch: 6| Step: 2
Training loss: 1.0548551082611084
Validation loss: 2.1067205667495728

Epoch: 6| Step: 3
Training loss: 0.8505375385284424
Validation loss: 2.131493786970774

Epoch: 6| Step: 4
Training loss: 0.49884292483329773
Validation loss: 2.16255130370458

Epoch: 6| Step: 5
Training loss: 0.9909586310386658
Validation loss: 2.1580583651860556

Epoch: 6| Step: 6
Training loss: 0.8820593357086182
Validation loss: 2.137081503868103

Epoch: 6| Step: 7
Training loss: 0.7395231127738953
Validation loss: 2.160103738307953

Epoch: 6| Step: 8
Training loss: 1.4797859191894531
Validation loss: 2.105225404103597

Epoch: 6| Step: 9
Training loss: 1.2221733331680298
Validation loss: 2.117557247479757

Epoch: 6| Step: 10
Training loss: 0.8763902187347412
Validation loss: 2.118050277233124

Epoch: 6| Step: 11
Training loss: 0.9301813840866089
Validation loss: 2.12096639474233

Epoch: 6| Step: 12
Training loss: 0.8751364946365356
Validation loss: 2.0961925387382507

Epoch: 6| Step: 13
Training loss: 0.6311096549034119
Validation loss: 2.164870858192444

Epoch: 193| Step: 0
Training loss: 1.1578497886657715
Validation loss: 2.1032212177912393

Epoch: 6| Step: 1
Training loss: 0.8870354890823364
Validation loss: 2.069451173146566

Epoch: 6| Step: 2
Training loss: 0.8539620637893677
Validation loss: 2.098858376344045

Epoch: 6| Step: 3
Training loss: 1.231157660484314
Validation loss: 2.071557184060415

Epoch: 6| Step: 4
Training loss: 1.414232850074768
Validation loss: 2.0698383450508118

Epoch: 6| Step: 5
Training loss: 0.7823336720466614
Validation loss: 2.122258424758911

Epoch: 6| Step: 6
Training loss: 0.88420569896698
Validation loss: 2.129424730936686

Epoch: 6| Step: 7
Training loss: 1.064291000366211
Validation loss: 2.128631075223287

Epoch: 6| Step: 8
Training loss: 0.5724327564239502
Validation loss: 2.103996197382609

Epoch: 6| Step: 9
Training loss: 0.5235578417778015
Validation loss: 2.0992670257886252

Epoch: 6| Step: 10
Training loss: 0.6517050266265869
Validation loss: 2.1215781569480896

Epoch: 6| Step: 11
Training loss: 0.9296063780784607
Validation loss: 2.1877710819244385

Epoch: 6| Step: 12
Training loss: 1.3257577419281006
Validation loss: 2.0984681248664856

Epoch: 6| Step: 13
Training loss: 0.7601532340049744
Validation loss: 2.1127168933550515

Epoch: 194| Step: 0
Training loss: 0.6849873065948486
Validation loss: 2.0708810687065125

Epoch: 6| Step: 1
Training loss: 1.6426589488983154
Validation loss: 2.1202209194501243

Epoch: 6| Step: 2
Training loss: 0.6638383269309998
Validation loss: 2.145372986793518

Epoch: 6| Step: 3
Training loss: 0.9095385074615479
Validation loss: 2.1444302002588906

Epoch: 6| Step: 4
Training loss: 0.547110378742218
Validation loss: 2.1375732421875

Epoch: 6| Step: 5
Training loss: 0.8312301635742188
Validation loss: 2.1609310706456504

Epoch: 6| Step: 6
Training loss: 1.1361379623413086
Validation loss: 2.165103773276011

Epoch: 6| Step: 7
Training loss: 0.558139443397522
Validation loss: 2.115047335624695

Epoch: 6| Step: 8
Training loss: 0.5120806694030762
Validation loss: 2.1389508048693338

Epoch: 6| Step: 9
Training loss: 1.1530972719192505
Validation loss: 2.120370090007782

Epoch: 6| Step: 10
Training loss: 1.2684072256088257
Validation loss: 2.0725736816724143

Epoch: 6| Step: 11
Training loss: 1.0233062505722046
Validation loss: 2.0898794333140054

Epoch: 6| Step: 12
Training loss: 1.1965672969818115
Validation loss: 2.110333800315857

Epoch: 6| Step: 13
Training loss: 1.1183083057403564
Validation loss: 2.115391969680786

Epoch: 195| Step: 0
Training loss: 1.0494892597198486
Validation loss: 2.0764077504475913

Epoch: 6| Step: 1
Training loss: 1.1348881721496582
Validation loss: 2.0615657369295755

Epoch: 6| Step: 2
Training loss: 1.3397904634475708
Validation loss: 2.0777223110198975

Epoch: 6| Step: 3
Training loss: 0.9149773716926575
Validation loss: 2.125089724858602

Epoch: 6| Step: 4
Training loss: 0.8296971321105957
Validation loss: 2.156143069267273

Epoch: 6| Step: 5
Training loss: 0.5159574747085571
Validation loss: 2.148481806119283

Epoch: 6| Step: 6
Training loss: 0.8927170038223267
Validation loss: 2.2127484877904258

Epoch: 6| Step: 7
Training loss: 1.0196342468261719
Validation loss: 2.1387004057566323

Epoch: 6| Step: 8
Training loss: 1.3820593357086182
Validation loss: 2.1368064681688943

Epoch: 6| Step: 9
Training loss: 0.45044875144958496
Validation loss: 2.073087910811106

Epoch: 6| Step: 10
Training loss: 0.9736580848693848
Validation loss: 2.1141550143559775

Epoch: 6| Step: 11
Training loss: 0.7771152257919312
Validation loss: 2.105633795261383

Epoch: 6| Step: 12
Training loss: 1.3174840211868286
Validation loss: 2.0968837340672812

Epoch: 6| Step: 13
Training loss: 0.4971941113471985
Validation loss: 2.1220470666885376

Epoch: 196| Step: 0
Training loss: 0.9956565499305725
Validation loss: 2.107635815938314

Epoch: 6| Step: 1
Training loss: 1.7235422134399414
Validation loss: 2.0252737402915955

Epoch: 6| Step: 2
Training loss: 1.2784051895141602
Validation loss: 2.134605129559835

Epoch: 6| Step: 3
Training loss: 0.5889455676078796
Validation loss: 2.1548845171928406

Epoch: 6| Step: 4
Training loss: 1.1273998022079468
Validation loss: 2.143519699573517

Epoch: 6| Step: 5
Training loss: 0.7026416063308716
Validation loss: 2.125246246655782

Epoch: 6| Step: 6
Training loss: 0.6202104687690735
Validation loss: 2.150075137615204

Epoch: 6| Step: 7
Training loss: 0.8166041374206543
Validation loss: 2.11117156346639

Epoch: 6| Step: 8
Training loss: 0.9527559280395508
Validation loss: 2.1551615794499717

Epoch: 6| Step: 9
Training loss: 0.6997836828231812
Validation loss: 2.151605943838755

Epoch: 6| Step: 10
Training loss: 1.299391508102417
Validation loss: 2.1341145435969033

Epoch: 6| Step: 11
Training loss: 0.6698298454284668
Validation loss: 2.157034456729889

Epoch: 6| Step: 12
Training loss: 0.6197623014450073
Validation loss: 2.119080980618795

Epoch: 6| Step: 13
Training loss: 1.1812783479690552
Validation loss: 2.083868940671285

Epoch: 197| Step: 0
Training loss: 0.9250143766403198
Validation loss: 2.0813093980153403

Epoch: 6| Step: 1
Training loss: 1.150749921798706
Validation loss: 2.1218257943789163

Epoch: 6| Step: 2
Training loss: 1.2732594013214111
Validation loss: 2.0877596735954285

Epoch: 6| Step: 3
Training loss: 1.1646686792373657
Validation loss: 2.1702924370765686

Epoch: 6| Step: 4
Training loss: 0.7196533679962158
Validation loss: 2.0921876629193625

Epoch: 6| Step: 5
Training loss: 1.2539840936660767
Validation loss: 2.1476680040359497

Epoch: 6| Step: 6
Training loss: 0.8295608758926392
Validation loss: 2.193295478820801

Epoch: 6| Step: 7
Training loss: 1.0071500539779663
Validation loss: 2.15956974029541

Epoch: 6| Step: 8
Training loss: 0.6878940463066101
Validation loss: 2.096445878346761

Epoch: 6| Step: 9
Training loss: 0.827370822429657
Validation loss: 2.128938297430674

Epoch: 6| Step: 10
Training loss: 0.5622950792312622
Validation loss: 2.079162836074829

Epoch: 6| Step: 11
Training loss: 0.8044629096984863
Validation loss: 2.0988887747128806

Epoch: 6| Step: 12
Training loss: 0.6300035715103149
Validation loss: 2.1074432134628296

Epoch: 6| Step: 13
Training loss: 0.802117109298706
Validation loss: 2.10860284169515

Epoch: 198| Step: 0
Training loss: 0.9558355808258057
Validation loss: 2.108523726463318

Epoch: 6| Step: 1
Training loss: 0.9814699292182922
Validation loss: 2.1655705173810325

Epoch: 6| Step: 2
Training loss: 1.1412937641143799
Validation loss: 2.0928092002868652

Epoch: 6| Step: 3
Training loss: 0.47298240661621094
Validation loss: 2.089060882727305

Epoch: 6| Step: 4
Training loss: 0.6940374374389648
Validation loss: 2.174056649208069

Epoch: 6| Step: 5
Training loss: 0.5455713868141174
Validation loss: 2.157827099164327

Epoch: 6| Step: 6
Training loss: 0.8052697777748108
Validation loss: 2.069557507832845

Epoch: 6| Step: 7
Training loss: 1.651026725769043
Validation loss: 2.115452289581299

Epoch: 6| Step: 8
Training loss: 1.1474144458770752
Validation loss: 2.079327662785848

Epoch: 6| Step: 9
Training loss: 1.2001953125
Validation loss: 2.07708732287089

Epoch: 6| Step: 10
Training loss: 0.6349906325340271
Validation loss: 2.1203306913375854

Epoch: 6| Step: 11
Training loss: 0.5331261157989502
Validation loss: 2.158916195233663

Epoch: 6| Step: 12
Training loss: 1.1173642873764038
Validation loss: 2.1188412507375083

Epoch: 6| Step: 13
Training loss: 0.533889889717102
Validation loss: 2.139131188392639

Epoch: 199| Step: 0
Training loss: 0.6500352621078491
Validation loss: 2.187462011973063

Epoch: 6| Step: 1
Training loss: 0.9565720558166504
Validation loss: 2.1327461997667947

Epoch: 6| Step: 2
Training loss: 0.7772806286811829
Validation loss: 2.1182307998339334

Epoch: 6| Step: 3
Training loss: 0.6164218187332153
Validation loss: 2.102499783039093

Epoch: 6| Step: 4
Training loss: 0.7862040996551514
Validation loss: 2.0853246053059897

Epoch: 6| Step: 5
Training loss: 0.8792952299118042
Validation loss: 2.1005356907844543

Epoch: 6| Step: 6
Training loss: 1.7855536937713623
Validation loss: 2.1700663963953652

Epoch: 6| Step: 7
Training loss: 1.7554130554199219
Validation loss: 2.169032633304596

Epoch: 6| Step: 8
Training loss: 0.7402454018592834
Validation loss: 2.140633285045624

Epoch: 6| Step: 9
Training loss: 1.180970549583435
Validation loss: 2.166149457295736

Epoch: 6| Step: 10
Training loss: 0.47548067569732666
Validation loss: 2.116505980491638

Epoch: 6| Step: 11
Training loss: 0.7538758516311646
Validation loss: 2.126781980196635

Epoch: 6| Step: 12
Training loss: 0.7423912286758423
Validation loss: 2.1216452916463218

Epoch: 6| Step: 13
Training loss: 0.5025355219841003
Validation loss: 2.0914939443270364

Epoch: 200| Step: 0
Training loss: 0.8121250867843628
Validation loss: 2.1408507029215493

Epoch: 6| Step: 1
Training loss: 0.9868816137313843
Validation loss: 2.125945766766866

Epoch: 6| Step: 2
Training loss: 0.5349134802818298
Validation loss: 2.115430454413096

Epoch: 6| Step: 3
Training loss: 0.6785249710083008
Validation loss: 2.114153563976288

Epoch: 6| Step: 4
Training loss: 0.5540478229522705
Validation loss: 2.1766174038251243

Epoch: 6| Step: 5
Training loss: 1.291905164718628
Validation loss: 2.1324968934059143

Epoch: 6| Step: 6
Training loss: 0.5390021800994873
Validation loss: 2.157439708709717

Epoch: 6| Step: 7
Training loss: 0.7013126015663147
Validation loss: 2.0865993897120156

Epoch: 6| Step: 8
Training loss: 0.9368300437927246
Validation loss: 2.099006156126658

Epoch: 6| Step: 9
Training loss: 1.3271559476852417
Validation loss: 2.102931320667267

Epoch: 6| Step: 10
Training loss: 0.9300807118415833
Validation loss: 2.1500186125437417

Epoch: 6| Step: 11
Training loss: 1.503645420074463
Validation loss: 2.116900304953257

Epoch: 6| Step: 12
Training loss: 0.7776497602462769
Validation loss: 2.124215225378672

Epoch: 6| Step: 13
Training loss: 0.9652689695358276
Validation loss: 2.118848741054535

Epoch: 201| Step: 0
Training loss: 1.2583353519439697
Validation loss: 2.175026555856069

Epoch: 6| Step: 1
Training loss: 0.7727078199386597
Validation loss: 2.106469730536143

Epoch: 6| Step: 2
Training loss: 0.7852544188499451
Validation loss: 2.1438050667444863

Epoch: 6| Step: 3
Training loss: 0.5897023677825928
Validation loss: 2.1342585682868958

Epoch: 6| Step: 4
Training loss: 0.47307634353637695
Validation loss: 2.1558134953180947

Epoch: 6| Step: 5
Training loss: 0.7644699811935425
Validation loss: 2.2098968227704368

Epoch: 6| Step: 6
Training loss: 1.2945882081985474
Validation loss: 2.1111456155776978

Epoch: 6| Step: 7
Training loss: 0.6952763199806213
Validation loss: 2.169071694215139

Epoch: 6| Step: 8
Training loss: 0.7534998655319214
Validation loss: 2.1419139305750527

Epoch: 6| Step: 9
Training loss: 0.8526501059532166
Validation loss: 2.1572300791740417

Epoch: 6| Step: 10
Training loss: 1.5964021682739258
Validation loss: 2.0892402132352195

Epoch: 6| Step: 11
Training loss: 1.2723147869110107
Validation loss: 2.0619558691978455

Epoch: 6| Step: 12
Training loss: 0.8622320890426636
Validation loss: 2.1173024574915567

Epoch: 6| Step: 13
Training loss: 0.719693124294281
Validation loss: 2.115943749745687

Epoch: 202| Step: 0
Training loss: 0.5354165434837341
Validation loss: 2.1217294931411743

Epoch: 6| Step: 1
Training loss: 1.1055774688720703
Validation loss: 2.086067855358124

Epoch: 6| Step: 2
Training loss: 0.6816054582595825
Validation loss: 2.1539416511853537

Epoch: 6| Step: 3
Training loss: 1.0065642595291138
Validation loss: 2.128999968369802

Epoch: 6| Step: 4
Training loss: 0.7276411652565002
Validation loss: 2.0972820520401

Epoch: 6| Step: 5
Training loss: 0.7845050692558289
Validation loss: 2.1771169304847717

Epoch: 6| Step: 6
Training loss: 1.2033205032348633
Validation loss: 2.1504684686660767

Epoch: 6| Step: 7
Training loss: 0.8918172121047974
Validation loss: 2.209761063257853

Epoch: 6| Step: 8
Training loss: 0.6072351932525635
Validation loss: 2.2091514666875205

Epoch: 6| Step: 9
Training loss: 1.4436103105545044
Validation loss: 2.1449681321779885

Epoch: 6| Step: 10
Training loss: 0.6332927346229553
Validation loss: 2.100990653038025

Epoch: 6| Step: 11
Training loss: 1.1647863388061523
Validation loss: 2.1021728515625

Epoch: 6| Step: 12
Training loss: 1.0458078384399414
Validation loss: 2.101196070512136

Epoch: 6| Step: 13
Training loss: 0.8631696701049805
Validation loss: 2.04493514696757

Epoch: 203| Step: 0
Training loss: 0.8239086866378784
Validation loss: 2.1184622844060264

Epoch: 6| Step: 1
Training loss: 0.7939989566802979
Validation loss: 2.139777680238088

Epoch: 6| Step: 2
Training loss: 0.40882444381713867
Validation loss: 2.097874899705251

Epoch: 6| Step: 3
Training loss: 1.261576771736145
Validation loss: 2.169930716355642

Epoch: 6| Step: 4
Training loss: 0.8399385809898376
Validation loss: 2.1646283070246377

Epoch: 6| Step: 5
Training loss: 0.8679416179656982
Validation loss: 2.1190049052238464

Epoch: 6| Step: 6
Training loss: 1.1615428924560547
Validation loss: 2.107111910978953

Epoch: 6| Step: 7
Training loss: 1.0226129293441772
Validation loss: 2.1768027941385903

Epoch: 6| Step: 8
Training loss: 0.8218714594841003
Validation loss: 2.1550966103871665

Epoch: 6| Step: 9
Training loss: 0.9263022541999817
Validation loss: 2.1183934013048806

Epoch: 6| Step: 10
Training loss: 1.0688412189483643
Validation loss: 2.161033054192861

Epoch: 6| Step: 11
Training loss: 0.4566801190376282
Validation loss: 2.1747012933095298

Epoch: 6| Step: 12
Training loss: 1.0766987800598145
Validation loss: 2.111245115598043

Epoch: 6| Step: 13
Training loss: 0.9856925010681152
Validation loss: 2.1283415953318277

Epoch: 204| Step: 0
Training loss: 1.4770171642303467
Validation loss: 2.123912513256073

Epoch: 6| Step: 1
Training loss: 0.998744785785675
Validation loss: 2.128706137339274

Epoch: 6| Step: 2
Training loss: 0.9772133231163025
Validation loss: 2.178237954775492

Epoch: 6| Step: 3
Training loss: 0.9900667071342468
Validation loss: 2.0650415221850076

Epoch: 6| Step: 4
Training loss: 1.0733892917633057
Validation loss: 2.1318018635114035

Epoch: 6| Step: 5
Training loss: 0.9376792311668396
Validation loss: 2.1446823279062905

Epoch: 6| Step: 6
Training loss: 0.6881805658340454
Validation loss: 2.1612011790275574

Epoch: 6| Step: 7
Training loss: 0.9418780207633972
Validation loss: 2.1799001892407737

Epoch: 6| Step: 8
Training loss: 0.38341087102890015
Validation loss: 2.193491538365682

Epoch: 6| Step: 9
Training loss: 0.4000687301158905
Validation loss: 2.172831356525421

Epoch: 6| Step: 10
Training loss: 0.6332026124000549
Validation loss: 2.1455724636713662

Epoch: 6| Step: 11
Training loss: 0.8686081171035767
Validation loss: 2.1679232716560364

Epoch: 6| Step: 12
Training loss: 0.9131971001625061
Validation loss: 2.1343693335851035

Epoch: 6| Step: 13
Training loss: 0.3871753513813019
Validation loss: 2.115318695704142

Epoch: 205| Step: 0
Training loss: 0.8108505010604858
Validation loss: 2.083964467048645

Epoch: 6| Step: 1
Training loss: 1.4451826810836792
Validation loss: 2.0994234482447305

Epoch: 6| Step: 2
Training loss: 0.5781148076057434
Validation loss: 2.111560901006063

Epoch: 6| Step: 3
Training loss: 0.9922942519187927
Validation loss: 2.185510993003845

Epoch: 6| Step: 4
Training loss: 1.2545957565307617
Validation loss: 2.0904929439226785

Epoch: 6| Step: 5
Training loss: 0.8767876029014587
Validation loss: 2.1353312333424888

Epoch: 6| Step: 6
Training loss: 0.7116414904594421
Validation loss: 2.1162635882695517

Epoch: 6| Step: 7
Training loss: 0.3559343218803406
Validation loss: 2.113980293273926

Epoch: 6| Step: 8
Training loss: 1.3377487659454346
Validation loss: 2.163943966229757

Epoch: 6| Step: 9
Training loss: 0.5351044535636902
Validation loss: 2.1488540967305503

Epoch: 6| Step: 10
Training loss: 0.893029510974884
Validation loss: 2.158563713232676

Epoch: 6| Step: 11
Training loss: 0.9245800375938416
Validation loss: 2.156982898712158

Epoch: 6| Step: 12
Training loss: 0.5949339866638184
Validation loss: 2.1021414200464883

Epoch: 6| Step: 13
Training loss: 1.1720428466796875
Validation loss: 2.0919388135274253

Epoch: 206| Step: 0
Training loss: 1.0265886783599854
Validation loss: 2.120257019996643

Epoch: 6| Step: 1
Training loss: 0.9511551856994629
Validation loss: 2.104029059410095

Epoch: 6| Step: 2
Training loss: 1.1745902299880981
Validation loss: 2.09840194384257

Epoch: 6| Step: 3
Training loss: 0.6696749925613403
Validation loss: 2.097999413808187

Epoch: 6| Step: 4
Training loss: 0.9043155908584595
Validation loss: 2.175792396068573

Epoch: 6| Step: 5
Training loss: 0.4703814685344696
Validation loss: 2.1231934825579324

Epoch: 6| Step: 6
Training loss: 0.8575574159622192
Validation loss: 2.176613986492157

Epoch: 6| Step: 7
Training loss: 0.9771089553833008
Validation loss: 2.1371270418167114

Epoch: 6| Step: 8
Training loss: 0.7528735399246216
Validation loss: 2.1857686837514243

Epoch: 6| Step: 9
Training loss: 0.540589451789856
Validation loss: 2.1080012917518616

Epoch: 6| Step: 10
Training loss: 0.41280144453048706
Validation loss: 2.115982234477997

Epoch: 6| Step: 11
Training loss: 0.9250236749649048
Validation loss: 2.1264837781588235

Epoch: 6| Step: 12
Training loss: 0.7493962645530701
Validation loss: 2.1225659052530923

Epoch: 6| Step: 13
Training loss: 0.8704303503036499
Validation loss: 2.1614983876546225

Epoch: 207| Step: 0
Training loss: 0.6875280141830444
Validation loss: 2.1606165369351706

Epoch: 6| Step: 1
Training loss: 0.6310642957687378
Validation loss: 2.116704821586609

Epoch: 6| Step: 2
Training loss: 0.6037507057189941
Validation loss: 2.1154204607009888

Epoch: 6| Step: 3
Training loss: 1.3573766946792603
Validation loss: 2.1203784545262656

Epoch: 6| Step: 4
Training loss: 0.844941258430481
Validation loss: 2.120847543080648

Epoch: 6| Step: 5
Training loss: 0.8124607801437378
Validation loss: 2.1453391710917153

Epoch: 6| Step: 6
Training loss: 1.0757911205291748
Validation loss: 2.127333720525106

Epoch: 6| Step: 7
Training loss: 0.9611296653747559
Validation loss: 2.1603439251581826

Epoch: 6| Step: 8
Training loss: 0.5619369149208069
Validation loss: 2.1981096466382346

Epoch: 6| Step: 9
Training loss: 0.7285104393959045
Validation loss: 2.104767322540283

Epoch: 6| Step: 10
Training loss: 0.7827261686325073
Validation loss: 2.19203911225001

Epoch: 6| Step: 11
Training loss: 0.41166144609451294
Validation loss: 2.1202091375986734

Epoch: 6| Step: 12
Training loss: 0.8843166828155518
Validation loss: 2.108474830786387

Epoch: 6| Step: 13
Training loss: 1.0690652132034302
Validation loss: 2.169733226299286

Epoch: 208| Step: 0
Training loss: 1.0087010860443115
Validation loss: 2.1629480719566345

Epoch: 6| Step: 1
Training loss: 0.5495945811271667
Validation loss: 2.1259899735450745

Epoch: 6| Step: 2
Training loss: 1.1598365306854248
Validation loss: 2.09480752547582

Epoch: 6| Step: 3
Training loss: 0.8668733835220337
Validation loss: 2.1353790163993835

Epoch: 6| Step: 4
Training loss: 1.055273413658142
Validation loss: 2.0933839480082193

Epoch: 6| Step: 5
Training loss: 0.684463620185852
Validation loss: 2.2108415961265564

Epoch: 6| Step: 6
Training loss: 0.4607478976249695
Validation loss: 2.111106832822164

Epoch: 6| Step: 7
Training loss: 0.7921477556228638
Validation loss: 2.1085745096206665

Epoch: 6| Step: 8
Training loss: 0.7356475591659546
Validation loss: 2.161959250768026

Epoch: 6| Step: 9
Training loss: 0.7536295652389526
Validation loss: 2.1859703063964844

Epoch: 6| Step: 10
Training loss: 0.40503421425819397
Validation loss: 2.0779107411702475

Epoch: 6| Step: 11
Training loss: 0.6938292384147644
Validation loss: 2.147332747777303

Epoch: 6| Step: 12
Training loss: 1.028113842010498
Validation loss: 2.1206218600273132

Epoch: 6| Step: 13
Training loss: 0.7485208511352539
Validation loss: 2.132485806941986

Epoch: 209| Step: 0
Training loss: 0.8275404572486877
Validation loss: 2.20622456073761

Epoch: 6| Step: 1
Training loss: 0.8049046397209167
Validation loss: 2.1849883000055947

Epoch: 6| Step: 2
Training loss: 1.1195658445358276
Validation loss: 2.0920945405960083

Epoch: 6| Step: 3
Training loss: 1.0885393619537354
Validation loss: 2.1862938006718955

Epoch: 6| Step: 4
Training loss: 1.3664231300354004
Validation loss: 2.1420368949572244

Epoch: 6| Step: 5
Training loss: 0.5830245018005371
Validation loss: 2.129678964614868

Epoch: 6| Step: 6
Training loss: 0.5248457193374634
Validation loss: 2.195523182551066

Epoch: 6| Step: 7
Training loss: 0.5833284854888916
Validation loss: 2.129598697026571

Epoch: 6| Step: 8
Training loss: 0.5004088878631592
Validation loss: 2.1651318868001304

Epoch: 6| Step: 9
Training loss: 0.6239247918128967
Validation loss: 2.201113204161326

Epoch: 6| Step: 10
Training loss: 0.6355307102203369
Validation loss: 2.160266359647115

Epoch: 6| Step: 11
Training loss: 1.175196647644043
Validation loss: 2.188957850138346

Epoch: 6| Step: 12
Training loss: 0.8288452625274658
Validation loss: 2.165398597717285

Epoch: 6| Step: 13
Training loss: 0.6959409713745117
Validation loss: 2.1568033496538797

Epoch: 210| Step: 0
Training loss: 0.7907460927963257
Validation loss: 2.1161663929621377

Epoch: 6| Step: 1
Training loss: 0.9211161136627197
Validation loss: 2.0987277825673423

Epoch: 6| Step: 2
Training loss: 0.7015896439552307
Validation loss: 2.1737518111864724

Epoch: 6| Step: 3
Training loss: 0.624260425567627
Validation loss: 2.186540365219116

Epoch: 6| Step: 4
Training loss: 0.7675434947013855
Validation loss: 2.1833484768867493

Epoch: 6| Step: 5
Training loss: 1.3512358665466309
Validation loss: 2.1397263407707214

Epoch: 6| Step: 6
Training loss: 0.8570544719696045
Validation loss: 2.145610491434733

Epoch: 6| Step: 7
Training loss: 0.49996599555015564
Validation loss: 2.1508147915204368

Epoch: 6| Step: 8
Training loss: 0.7225523591041565
Validation loss: 2.1638731559117637

Epoch: 6| Step: 9
Training loss: 1.8966180086135864
Validation loss: 2.115790545940399

Epoch: 6| Step: 10
Training loss: 0.6532678604125977
Validation loss: 2.1705042918523154

Epoch: 6| Step: 11
Training loss: 0.6728049516677856
Validation loss: 2.202375829219818

Epoch: 6| Step: 12
Training loss: 0.5365170240402222
Validation loss: 2.1516515413920083

Epoch: 6| Step: 13
Training loss: 0.7439256906509399
Validation loss: 2.157953401406606

Epoch: 211| Step: 0
Training loss: 0.7477926015853882
Validation loss: 2.1331711212793985

Epoch: 6| Step: 1
Training loss: 0.508448600769043
Validation loss: 2.1558085282643638

Epoch: 6| Step: 2
Training loss: 0.6052300333976746
Validation loss: 2.151549299558004

Epoch: 6| Step: 3
Training loss: 0.7778866291046143
Validation loss: 2.1477222442626953

Epoch: 6| Step: 4
Training loss: 0.7815730571746826
Validation loss: 2.194842278957367

Epoch: 6| Step: 5
Training loss: 1.2189568281173706
Validation loss: 2.139879266421

Epoch: 6| Step: 6
Training loss: 0.5751928687095642
Validation loss: 2.108350316683451

Epoch: 6| Step: 7
Training loss: 0.8933473825454712
Validation loss: 2.140870749950409

Epoch: 6| Step: 8
Training loss: 0.8876151442527771
Validation loss: 2.1122238834698996

Epoch: 6| Step: 9
Training loss: 0.6770805716514587
Validation loss: 2.1967647473017373

Epoch: 6| Step: 10
Training loss: 0.8935974836349487
Validation loss: 2.1548377672831216

Epoch: 6| Step: 11
Training loss: 0.9009803533554077
Validation loss: 2.05997105439504

Epoch: 6| Step: 12
Training loss: 0.9738805294036865
Validation loss: 2.1377102533976235

Epoch: 6| Step: 13
Training loss: 0.8296165466308594
Validation loss: 2.1603253285090127

Epoch: 212| Step: 0
Training loss: 0.6405547857284546
Validation loss: 2.163778324921926

Epoch: 6| Step: 1
Training loss: 0.9700419306755066
Validation loss: 2.19472074508667

Epoch: 6| Step: 2
Training loss: 0.6147850751876831
Validation loss: 2.08511749903361

Epoch: 6| Step: 3
Training loss: 0.6681406497955322
Validation loss: 2.139539361000061

Epoch: 6| Step: 4
Training loss: 0.4004913866519928
Validation loss: 2.1290208299954734

Epoch: 6| Step: 5
Training loss: 0.4133574664592743
Validation loss: 2.141663829485575

Epoch: 6| Step: 6
Training loss: 1.1628048419952393
Validation loss: 2.1288752357165017

Epoch: 6| Step: 7
Training loss: 0.8184962868690491
Validation loss: 2.115390638510386

Epoch: 6| Step: 8
Training loss: 1.169850468635559
Validation loss: 2.0862009525299072

Epoch: 6| Step: 9
Training loss: 0.9465888738632202
Validation loss: 2.0691728989283242

Epoch: 6| Step: 10
Training loss: 1.01715886592865
Validation loss: 2.093062241872152

Epoch: 6| Step: 11
Training loss: 0.7797616720199585
Validation loss: 2.152113199234009

Epoch: 6| Step: 12
Training loss: 0.6529221534729004
Validation loss: 2.1217929124832153

Epoch: 6| Step: 13
Training loss: 0.6886690258979797
Validation loss: 2.2068987687428794

Epoch: 213| Step: 0
Training loss: 0.44905808568000793
Validation loss: 2.123149553934733

Epoch: 6| Step: 1
Training loss: 1.016743540763855
Validation loss: 2.186426897843679

Epoch: 6| Step: 2
Training loss: 0.5456637144088745
Validation loss: 2.1497605443000793

Epoch: 6| Step: 3
Training loss: 0.6909464001655579
Validation loss: 2.178847551345825

Epoch: 6| Step: 4
Training loss: 0.6217237710952759
Validation loss: 2.1483863989512124

Epoch: 6| Step: 5
Training loss: 0.9609228372573853
Validation loss: 2.1379669109980264

Epoch: 6| Step: 6
Training loss: 0.4989106059074402
Validation loss: 2.0485028823216758

Epoch: 6| Step: 7
Training loss: 0.78429114818573
Validation loss: 2.069129168987274

Epoch: 6| Step: 8
Training loss: 0.7547708749771118
Validation loss: 2.107435941696167

Epoch: 6| Step: 9
Training loss: 1.391554355621338
Validation loss: 2.098562995592753

Epoch: 6| Step: 10
Training loss: 0.3611091375350952
Validation loss: 2.1010692715644836

Epoch: 6| Step: 11
Training loss: 0.7720721960067749
Validation loss: 2.1147167881329856

Epoch: 6| Step: 12
Training loss: 1.1454706192016602
Validation loss: 2.1355033715566

Epoch: 6| Step: 13
Training loss: 0.9220612049102783
Validation loss: 2.1101486881573996

Epoch: 214| Step: 0
Training loss: 0.8388935327529907
Validation loss: 2.1629881660143533

Epoch: 6| Step: 1
Training loss: 0.8071708679199219
Validation loss: 2.1438560684521994

Epoch: 6| Step: 2
Training loss: 0.6692048907279968
Validation loss: 2.158343195915222

Epoch: 6| Step: 3
Training loss: 0.7733772993087769
Validation loss: 2.1685173511505127

Epoch: 6| Step: 4
Training loss: 0.7701425552368164
Validation loss: 2.138902485370636

Epoch: 6| Step: 5
Training loss: 0.43891382217407227
Validation loss: 2.137424727280935

Epoch: 6| Step: 6
Training loss: 0.6699435710906982
Validation loss: 2.171232839425405

Epoch: 6| Step: 7
Training loss: 1.2486917972564697
Validation loss: 2.1550620396931968

Epoch: 6| Step: 8
Training loss: 0.665340006351471
Validation loss: 2.101050615310669

Epoch: 6| Step: 9
Training loss: 1.4186301231384277
Validation loss: 2.1287178993225098

Epoch: 6| Step: 10
Training loss: 0.850706160068512
Validation loss: 2.1557284394900003

Epoch: 6| Step: 11
Training loss: 0.43213698267936707
Validation loss: 2.172185003757477

Epoch: 6| Step: 12
Training loss: 1.1435962915420532
Validation loss: 2.241618891557058

Epoch: 6| Step: 13
Training loss: 0.5243709087371826
Validation loss: 2.2141776084899902

Epoch: 215| Step: 0
Training loss: 0.7362679243087769
Validation loss: 2.198845148086548

Epoch: 6| Step: 1
Training loss: 0.9285602569580078
Validation loss: 2.1490529775619507

Epoch: 6| Step: 2
Training loss: 1.0588221549987793
Validation loss: 2.1765193541844687

Epoch: 6| Step: 3
Training loss: 0.8216663599014282
Validation loss: 2.1914286812146506

Epoch: 6| Step: 4
Training loss: 0.5456446409225464
Validation loss: 2.1514764030774436

Epoch: 6| Step: 5
Training loss: 0.8228926658630371
Validation loss: 2.208454688390096

Epoch: 6| Step: 6
Training loss: 0.5176986455917358
Validation loss: 2.1305786768595376

Epoch: 6| Step: 7
Training loss: 0.703665554523468
Validation loss: 2.1401615540186563

Epoch: 6| Step: 8
Training loss: 0.5853528380393982
Validation loss: 2.156170924504598

Epoch: 6| Step: 9
Training loss: 0.5595322847366333
Validation loss: 2.123261034488678

Epoch: 6| Step: 10
Training loss: 1.0704994201660156
Validation loss: 2.1554660399754844

Epoch: 6| Step: 11
Training loss: 1.005326509475708
Validation loss: 2.1523316701253257

Epoch: 6| Step: 12
Training loss: 0.635859489440918
Validation loss: 2.1231791178385415

Epoch: 6| Step: 13
Training loss: 0.6499040126800537
Validation loss: 2.1790870229403176

Epoch: 216| Step: 0
Training loss: 1.263230562210083
Validation loss: 2.133083721001943

Epoch: 6| Step: 1
Training loss: 0.7744641304016113
Validation loss: 2.179632306098938

Epoch: 6| Step: 2
Training loss: 0.8683080673217773
Validation loss: 2.1565855542818704

Epoch: 6| Step: 3
Training loss: 0.44781333208084106
Validation loss: 2.181922992070516

Epoch: 6| Step: 4
Training loss: 0.747626781463623
Validation loss: 2.1278963685035706

Epoch: 6| Step: 5
Training loss: 0.3899964988231659
Validation loss: 2.19438902537028

Epoch: 6| Step: 6
Training loss: 0.647996187210083
Validation loss: 2.1511470874150596

Epoch: 6| Step: 7
Training loss: 0.6336588859558105
Validation loss: 2.2077229420344033

Epoch: 6| Step: 8
Training loss: 1.0119669437408447
Validation loss: 2.1312438249588013

Epoch: 6| Step: 9
Training loss: 0.9786325693130493
Validation loss: 2.1352605621019998

Epoch: 6| Step: 10
Training loss: 0.7171708345413208
Validation loss: 2.099084953467051

Epoch: 6| Step: 11
Training loss: 0.8237542510032654
Validation loss: 2.179908831914266

Epoch: 6| Step: 12
Training loss: 0.841496467590332
Validation loss: 2.1073057452837625

Epoch: 6| Step: 13
Training loss: 0.4405486583709717
Validation loss: 2.144781311353048

Epoch: 217| Step: 0
Training loss: 0.5300086140632629
Validation loss: 2.1713387767473855

Epoch: 6| Step: 1
Training loss: 1.0474939346313477
Validation loss: 2.187415897846222

Epoch: 6| Step: 2
Training loss: 0.8652985692024231
Validation loss: 2.1787095864613852

Epoch: 6| Step: 3
Training loss: 0.6277029514312744
Validation loss: 2.1569412549336753

Epoch: 6| Step: 4
Training loss: 0.511796772480011
Validation loss: 2.1647019386291504

Epoch: 6| Step: 5
Training loss: 0.9163929224014282
Validation loss: 2.157948136329651

Epoch: 6| Step: 6
Training loss: 0.7759134769439697
Validation loss: 2.202609141667684

Epoch: 6| Step: 7
Training loss: 0.7500380277633667
Validation loss: 2.2238855361938477

Epoch: 6| Step: 8
Training loss: 0.8484747409820557
Validation loss: 2.209535241127014

Epoch: 6| Step: 9
Training loss: 0.5738964080810547
Validation loss: 2.1460115909576416

Epoch: 6| Step: 10
Training loss: 0.9507389068603516
Validation loss: 2.1772658824920654

Epoch: 6| Step: 11
Training loss: 0.73588627576828
Validation loss: 2.1771139105161033

Epoch: 6| Step: 12
Training loss: 0.3920303285121918
Validation loss: 2.146638572216034

Epoch: 6| Step: 13
Training loss: 0.8574787378311157
Validation loss: 2.186276296774546

Epoch: 218| Step: 0
Training loss: 0.612216055393219
Validation loss: 2.1364234685897827

Epoch: 6| Step: 1
Training loss: 0.9196463227272034
Validation loss: 2.1545300086339316

Epoch: 6| Step: 2
Training loss: 0.6896147131919861
Validation loss: 2.175231715043386

Epoch: 6| Step: 3
Training loss: 1.074568271636963
Validation loss: 2.1646246115366616

Epoch: 6| Step: 4
Training loss: 0.4935251474380493
Validation loss: 2.126872718334198

Epoch: 6| Step: 5
Training loss: 0.6982529163360596
Validation loss: 2.1622121731440225

Epoch: 6| Step: 6
Training loss: 0.6526985168457031
Validation loss: 2.1781357725461326

Epoch: 6| Step: 7
Training loss: 0.616187572479248
Validation loss: 2.1818210085233054

Epoch: 6| Step: 8
Training loss: 0.3951016068458557
Validation loss: 2.1749210953712463

Epoch: 6| Step: 9
Training loss: 0.8437678813934326
Validation loss: 2.2028450965881348

Epoch: 6| Step: 10
Training loss: 0.8809853792190552
Validation loss: 2.1759233474731445

Epoch: 6| Step: 11
Training loss: 1.0724661350250244
Validation loss: 2.155067503452301

Epoch: 6| Step: 12
Training loss: 0.5872842073440552
Validation loss: 2.1188718676567078

Epoch: 6| Step: 13
Training loss: 0.6225976347923279
Validation loss: 2.15886127948761

Epoch: 219| Step: 0
Training loss: 0.5409470200538635
Validation loss: 2.1815179189046225

Epoch: 6| Step: 1
Training loss: 0.5908476114273071
Validation loss: 2.217299739519755

Epoch: 6| Step: 2
Training loss: 0.4676123857498169
Validation loss: 2.145669380823771

Epoch: 6| Step: 3
Training loss: 0.47255125641822815
Validation loss: 2.1427879532178244

Epoch: 6| Step: 4
Training loss: 0.7494298815727234
Validation loss: 2.165716012318929

Epoch: 6| Step: 5
Training loss: 0.8094497323036194
Validation loss: 2.1651886701583862

Epoch: 6| Step: 6
Training loss: 0.9601186513900757
Validation loss: 2.141264001528422

Epoch: 6| Step: 7
Training loss: 1.1132299900054932
Validation loss: 2.1543203592300415

Epoch: 6| Step: 8
Training loss: 0.4141630232334137
Validation loss: 2.1403717597325644

Epoch: 6| Step: 9
Training loss: 0.8041462302207947
Validation loss: 2.1413347721099854

Epoch: 6| Step: 10
Training loss: 1.1511707305908203
Validation loss: 2.172057787577311

Epoch: 6| Step: 11
Training loss: 0.808194637298584
Validation loss: 2.1680407524108887

Epoch: 6| Step: 12
Training loss: 0.8606552481651306
Validation loss: 2.1026660998662314

Epoch: 6| Step: 13
Training loss: 0.8395171165466309
Validation loss: 2.124299089113871

Epoch: 220| Step: 0
Training loss: 0.5499597191810608
Validation loss: 2.1808828910191855

Epoch: 6| Step: 1
Training loss: 0.795754075050354
Validation loss: 2.1643855373064675

Epoch: 6| Step: 2
Training loss: 0.8742443323135376
Validation loss: 2.102822999159495

Epoch: 6| Step: 3
Training loss: 0.8749754428863525
Validation loss: 2.1452301144599915

Epoch: 6| Step: 4
Training loss: 0.324285089969635
Validation loss: 2.168402115503947

Epoch: 6| Step: 5
Training loss: 0.6370505094528198
Validation loss: 2.1595603624979653

Epoch: 6| Step: 6
Training loss: 1.139750599861145
Validation loss: 2.1413196325302124

Epoch: 6| Step: 7
Training loss: 0.5587615370750427
Validation loss: 2.189846694469452

Epoch: 6| Step: 8
Training loss: 1.1375571489334106
Validation loss: 2.203166961669922

Epoch: 6| Step: 9
Training loss: 0.3370346426963806
Validation loss: 2.144225557645162

Epoch: 6| Step: 10
Training loss: 0.6779892444610596
Validation loss: 2.1694264809290567

Epoch: 6| Step: 11
Training loss: 0.9014798402786255
Validation loss: 2.214241147041321

Epoch: 6| Step: 12
Training loss: 0.8910053372383118
Validation loss: 2.1643420457839966

Epoch: 6| Step: 13
Training loss: 0.9062523245811462
Validation loss: 2.158997734387716

Epoch: 221| Step: 0
Training loss: 0.5155205130577087
Validation loss: 2.214674969514211

Epoch: 6| Step: 1
Training loss: 0.8595945239067078
Validation loss: 2.1191612084706626

Epoch: 6| Step: 2
Training loss: 1.1172630786895752
Validation loss: 2.145535866419474

Epoch: 6| Step: 3
Training loss: 0.8956305980682373
Validation loss: 2.13138480981191

Epoch: 6| Step: 4
Training loss: 0.5333791971206665
Validation loss: 2.1364834308624268

Epoch: 6| Step: 5
Training loss: 0.4958643615245819
Validation loss: 2.1673328081766763

Epoch: 6| Step: 6
Training loss: 0.9687180519104004
Validation loss: 2.1314889987309775

Epoch: 6| Step: 7
Training loss: 0.4413589537143707
Validation loss: 2.0937641859054565

Epoch: 6| Step: 8
Training loss: 0.6872131824493408
Validation loss: 2.1669976313908896

Epoch: 6| Step: 9
Training loss: 1.2496260404586792
Validation loss: 2.1080086628595986

Epoch: 6| Step: 10
Training loss: 0.5066530108451843
Validation loss: 2.171897530555725

Epoch: 6| Step: 11
Training loss: 0.8527480959892273
Validation loss: 2.1839549938837686

Epoch: 6| Step: 12
Training loss: 0.9141519665718079
Validation loss: 2.2113001147905984

Epoch: 6| Step: 13
Training loss: 0.5265289545059204
Validation loss: 2.173945347468058

Epoch: 222| Step: 0
Training loss: 0.8087466955184937
Validation loss: 2.155434489250183

Epoch: 6| Step: 1
Training loss: 1.2161550521850586
Validation loss: 2.1830608248710632

Epoch: 6| Step: 2
Training loss: 0.5583789944648743
Validation loss: 2.1617710987726846

Epoch: 6| Step: 3
Training loss: 0.5559511184692383
Validation loss: 2.1302334467569985

Epoch: 6| Step: 4
Training loss: 0.46435976028442383
Validation loss: 2.160810927549998

Epoch: 6| Step: 5
Training loss: 0.7104363441467285
Validation loss: 2.2084105412165322

Epoch: 6| Step: 6
Training loss: 0.4621433913707733
Validation loss: 2.1747122605641684

Epoch: 6| Step: 7
Training loss: 0.7158137559890747
Validation loss: 2.1606075962384543

Epoch: 6| Step: 8
Training loss: 0.583266019821167
Validation loss: 2.1507089138031006

Epoch: 6| Step: 9
Training loss: 0.7876622676849365
Validation loss: 2.174576679865519

Epoch: 6| Step: 10
Training loss: 0.9908986687660217
Validation loss: 2.199971775213877

Epoch: 6| Step: 11
Training loss: 0.46846768260002136
Validation loss: 2.202371378739675

Epoch: 6| Step: 12
Training loss: 1.1366850137710571
Validation loss: 2.1664257248242698

Epoch: 6| Step: 13
Training loss: 0.5448994636535645
Validation loss: 2.1484224796295166

Epoch: 223| Step: 0
Training loss: 0.6108646988868713
Validation loss: 2.222310642401377

Epoch: 6| Step: 1
Training loss: 0.830092191696167
Validation loss: 2.1201034982999167

Epoch: 6| Step: 2
Training loss: 0.7227858304977417
Validation loss: 2.127412954966227

Epoch: 6| Step: 3
Training loss: 0.6784547567367554
Validation loss: 2.161197781562805

Epoch: 6| Step: 4
Training loss: 0.8062408566474915
Validation loss: 2.2069623271624246

Epoch: 6| Step: 5
Training loss: 0.6411467790603638
Validation loss: 2.1409859458605447

Epoch: 6| Step: 6
Training loss: 1.2502660751342773
Validation loss: 2.1674644947052

Epoch: 6| Step: 7
Training loss: 0.48307734727859497
Validation loss: 2.151238759358724

Epoch: 6| Step: 8
Training loss: 0.771977424621582
Validation loss: 2.1790525118509927

Epoch: 6| Step: 9
Training loss: 0.7144569158554077
Validation loss: 2.143262585004171

Epoch: 6| Step: 10
Training loss: 0.9412269592285156
Validation loss: 2.161074916521708

Epoch: 6| Step: 11
Training loss: 0.6345523595809937
Validation loss: 2.1535736521085105

Epoch: 6| Step: 12
Training loss: 0.45867621898651123
Validation loss: 2.160486022631327

Epoch: 6| Step: 13
Training loss: 0.5245032906532288
Validation loss: 2.187115569909414

Epoch: 224| Step: 0
Training loss: 0.5909818410873413
Validation loss: 2.165905316670736

Epoch: 6| Step: 1
Training loss: 0.38515377044677734
Validation loss: 2.170283635457357

Epoch: 6| Step: 2
Training loss: 0.6889066100120544
Validation loss: 2.197965979576111

Epoch: 6| Step: 3
Training loss: 1.0514006614685059
Validation loss: 2.1752456426620483

Epoch: 6| Step: 4
Training loss: 0.81873619556427
Validation loss: 2.1833824515342712

Epoch: 6| Step: 5
Training loss: 0.538613498210907
Validation loss: 2.153487583001455

Epoch: 6| Step: 6
Training loss: 0.6666390299797058
Validation loss: 2.170987367630005

Epoch: 6| Step: 7
Training loss: 0.7990266680717468
Validation loss: 2.1581680178642273

Epoch: 6| Step: 8
Training loss: 0.5333130359649658
Validation loss: 2.121654470761617

Epoch: 6| Step: 9
Training loss: 0.7775275707244873
Validation loss: 2.1684970458348594

Epoch: 6| Step: 10
Training loss: 0.2978633642196655
Validation loss: 2.1906996369361877

Epoch: 6| Step: 11
Training loss: 0.8220133781433105
Validation loss: 2.098863403002421

Epoch: 6| Step: 12
Training loss: 0.5229037404060364
Validation loss: 2.089961071809133

Epoch: 6| Step: 13
Training loss: 0.786506175994873
Validation loss: 2.2320714195569358

Epoch: 225| Step: 0
Training loss: 0.5104266405105591
Validation loss: 2.1627482771873474

Epoch: 6| Step: 1
Training loss: 0.6163447499275208
Validation loss: 2.19197146097819

Epoch: 6| Step: 2
Training loss: 0.6665071845054626
Validation loss: 2.236582259337107

Epoch: 6| Step: 3
Training loss: 0.5434986352920532
Validation loss: 2.2797754208246865

Epoch: 6| Step: 4
Training loss: 0.5834740400314331
Validation loss: 2.1565330823262534

Epoch: 6| Step: 5
Training loss: 0.6264923214912415
Validation loss: 2.211605191230774

Epoch: 6| Step: 6
Training loss: 1.2672502994537354
Validation loss: 2.119952936967214

Epoch: 6| Step: 7
Training loss: 1.0825586318969727
Validation loss: 2.089099566141764

Epoch: 6| Step: 8
Training loss: 0.8217854499816895
Validation loss: 2.1613361636797586

Epoch: 6| Step: 9
Training loss: 0.6104426980018616
Validation loss: 2.137744645277659

Epoch: 6| Step: 10
Training loss: 0.5438610315322876
Validation loss: 2.1681634187698364

Epoch: 6| Step: 11
Training loss: 0.5413605570793152
Validation loss: 2.2275326251983643

Epoch: 6| Step: 12
Training loss: 0.8464784622192383
Validation loss: 2.1500140031178794

Epoch: 6| Step: 13
Training loss: 0.9445061683654785
Validation loss: 2.1876919070879617

Epoch: 226| Step: 0
Training loss: 0.6105937957763672
Validation loss: 2.1610770225524902

Epoch: 6| Step: 1
Training loss: 0.8294898271560669
Validation loss: 2.166216194629669

Epoch: 6| Step: 2
Training loss: 0.6246721744537354
Validation loss: 2.215729216734568

Epoch: 6| Step: 3
Training loss: 0.38206157088279724
Validation loss: 2.178107957045237

Epoch: 6| Step: 4
Training loss: 0.8785123825073242
Validation loss: 2.1817709604899087

Epoch: 6| Step: 5
Training loss: 0.3427892029285431
Validation loss: 2.2651403148969016

Epoch: 6| Step: 6
Training loss: 1.095684289932251
Validation loss: 2.1556409796079

Epoch: 6| Step: 7
Training loss: 0.426921010017395
Validation loss: 2.205377459526062

Epoch: 6| Step: 8
Training loss: 1.1524958610534668
Validation loss: 2.1375373204549155

Epoch: 6| Step: 9
Training loss: 0.4815472960472107
Validation loss: 2.1355643471082053

Epoch: 6| Step: 10
Training loss: 0.8305235505104065
Validation loss: 2.157781501611074

Epoch: 6| Step: 11
Training loss: 0.5585172176361084
Validation loss: 2.154508193333944

Epoch: 6| Step: 12
Training loss: 0.40637850761413574
Validation loss: 2.120227058728536

Epoch: 6| Step: 13
Training loss: 0.6519691944122314
Validation loss: 2.1877677838007608

Epoch: 227| Step: 0
Training loss: 0.7564064264297485
Validation loss: 2.211272736390432

Epoch: 6| Step: 1
Training loss: 0.7523038983345032
Validation loss: 2.199705342451731

Epoch: 6| Step: 2
Training loss: 1.1979641914367676
Validation loss: 2.1216920415560403

Epoch: 6| Step: 3
Training loss: 0.3292921185493469
Validation loss: 2.226181228955587

Epoch: 6| Step: 4
Training loss: 0.5933688879013062
Validation loss: 2.2288413842519126

Epoch: 6| Step: 5
Training loss: 0.9032434225082397
Validation loss: 2.1903021335601807

Epoch: 6| Step: 6
Training loss: 0.9156804084777832
Validation loss: 2.179478327433268

Epoch: 6| Step: 7
Training loss: 0.754972517490387
Validation loss: 2.152176856994629

Epoch: 6| Step: 8
Training loss: 0.41453614830970764
Validation loss: 2.1703163981437683

Epoch: 6| Step: 9
Training loss: 0.40358608961105347
Validation loss: 2.1470555464426675

Epoch: 6| Step: 10
Training loss: 0.2990879416465759
Validation loss: 2.1350777546564736

Epoch: 6| Step: 11
Training loss: 0.6946576833724976
Validation loss: 2.160449981689453

Epoch: 6| Step: 12
Training loss: 0.8261408805847168
Validation loss: 2.1963142355283103

Epoch: 6| Step: 13
Training loss: 0.6268202662467957
Validation loss: 2.2065098683039346

Epoch: 228| Step: 0
Training loss: 0.7974979877471924
Validation loss: 2.1976171930631003

Epoch: 6| Step: 1
Training loss: 0.6494280695915222
Validation loss: 2.1770213842391968

Epoch: 6| Step: 2
Training loss: 0.4478873908519745
Validation loss: 2.1643548011779785

Epoch: 6| Step: 3
Training loss: 0.6967320442199707
Validation loss: 2.158114790916443

Epoch: 6| Step: 4
Training loss: 0.8616727590560913
Validation loss: 2.1692437529563904

Epoch: 6| Step: 5
Training loss: 0.7986366748809814
Validation loss: 2.202569286028544

Epoch: 6| Step: 6
Training loss: 0.5332595109939575
Validation loss: 2.167576769987742

Epoch: 6| Step: 7
Training loss: 0.35423362255096436
Validation loss: 2.199909965197245

Epoch: 6| Step: 8
Training loss: 0.5153980255126953
Validation loss: 2.1683162450790405

Epoch: 6| Step: 9
Training loss: 0.6100987792015076
Validation loss: 2.169228514035543

Epoch: 6| Step: 10
Training loss: 0.7340004444122314
Validation loss: 2.182584762573242

Epoch: 6| Step: 11
Training loss: 0.9975961446762085
Validation loss: 2.194293955961863

Epoch: 6| Step: 12
Training loss: 0.5116965174674988
Validation loss: 2.1894352237383523

Epoch: 6| Step: 13
Training loss: 0.9279704689979553
Validation loss: 2.181846022605896

Epoch: 229| Step: 0
Training loss: 0.869854211807251
Validation loss: 2.1992336312929788

Epoch: 6| Step: 1
Training loss: 0.6112549304962158
Validation loss: 2.21937495470047

Epoch: 6| Step: 2
Training loss: 0.8267939686775208
Validation loss: 2.210626244544983

Epoch: 6| Step: 3
Training loss: 0.8720121383666992
Validation loss: 2.1418232123057046

Epoch: 6| Step: 4
Training loss: 0.5184955596923828
Validation loss: 2.225914935270945

Epoch: 6| Step: 5
Training loss: 0.6944677233695984
Validation loss: 2.1916667222976685

Epoch: 6| Step: 6
Training loss: 0.8028321862220764
Validation loss: 2.2062678734461465

Epoch: 6| Step: 7
Training loss: 0.4739731252193451
Validation loss: 2.1383747259775796

Epoch: 6| Step: 8
Training loss: 1.2296183109283447
Validation loss: 2.1389518777529397

Epoch: 6| Step: 9
Training loss: 0.64689701795578
Validation loss: 2.128836135069529

Epoch: 6| Step: 10
Training loss: 0.6506857872009277
Validation loss: 2.188241481781006

Epoch: 6| Step: 11
Training loss: 0.2728899121284485
Validation loss: 2.2144795656204224

Epoch: 6| Step: 12
Training loss: 0.9275645017623901
Validation loss: 2.237867593765259

Epoch: 6| Step: 13
Training loss: 0.633691668510437
Validation loss: 2.2739879290262857

Epoch: 230| Step: 0
Training loss: 0.8545200824737549
Validation loss: 2.232086976369222

Epoch: 6| Step: 1
Training loss: 0.549299955368042
Validation loss: 2.1869866053263345

Epoch: 6| Step: 2
Training loss: 0.7093110680580139
Validation loss: 2.2505324880282083

Epoch: 6| Step: 3
Training loss: 0.5305132865905762
Validation loss: 2.1804943680763245

Epoch: 6| Step: 4
Training loss: 0.4406164288520813
Validation loss: 2.1823915441830954

Epoch: 6| Step: 5
Training loss: 0.6242766976356506
Validation loss: 2.1580493648846946

Epoch: 6| Step: 6
Training loss: 1.1969645023345947
Validation loss: 2.1932528217633567

Epoch: 6| Step: 7
Training loss: 0.7950761318206787
Validation loss: 2.1555911898612976

Epoch: 6| Step: 8
Training loss: 1.1207926273345947
Validation loss: 2.184857706228892

Epoch: 6| Step: 9
Training loss: 0.9722078442573547
Validation loss: 2.1806394855181375

Epoch: 6| Step: 10
Training loss: 0.6932835578918457
Validation loss: 2.179045538107554

Epoch: 6| Step: 11
Training loss: 0.7157463431358337
Validation loss: 2.1996187369028726

Epoch: 6| Step: 12
Training loss: 0.46825820207595825
Validation loss: 2.1991950273513794

Epoch: 6| Step: 13
Training loss: 0.9294723868370056
Validation loss: 2.1619489590326944

Epoch: 231| Step: 0
Training loss: 0.6376177072525024
Validation loss: 2.209527571996053

Epoch: 6| Step: 1
Training loss: 1.120497703552246
Validation loss: 2.210389812787374

Epoch: 6| Step: 2
Training loss: 0.6093254685401917
Validation loss: 2.21564519405365

Epoch: 6| Step: 3
Training loss: 0.6362566351890564
Validation loss: 2.165134847164154

Epoch: 6| Step: 4
Training loss: 0.5698593854904175
Validation loss: 2.179450035095215

Epoch: 6| Step: 5
Training loss: 0.5665267705917358
Validation loss: 2.197702487309774

Epoch: 6| Step: 6
Training loss: 0.734643816947937
Validation loss: 2.1708832581837973

Epoch: 6| Step: 7
Training loss: 0.47186022996902466
Validation loss: 2.214414656162262

Epoch: 6| Step: 8
Training loss: 0.6501280069351196
Validation loss: 2.163906753063202

Epoch: 6| Step: 9
Training loss: 0.5364304780960083
Validation loss: 2.1876965761184692

Epoch: 6| Step: 10
Training loss: 1.0945146083831787
Validation loss: 2.1695786317189536

Epoch: 6| Step: 11
Training loss: 0.49439555406570435
Validation loss: 2.1667439937591553

Epoch: 6| Step: 12
Training loss: 0.9729222059249878
Validation loss: 2.1461288928985596

Epoch: 6| Step: 13
Training loss: 0.5064480304718018
Validation loss: 2.163533627986908

Epoch: 232| Step: 0
Training loss: 0.5291023254394531
Validation loss: 2.225760340690613

Epoch: 6| Step: 1
Training loss: 0.7818145751953125
Validation loss: 2.1071667869885764

Epoch: 6| Step: 2
Training loss: 0.5076674222946167
Validation loss: 2.129677414894104

Epoch: 6| Step: 3
Training loss: 0.742510974407196
Validation loss: 2.177321513493856

Epoch: 6| Step: 4
Training loss: 0.532572865486145
Validation loss: 2.2702965339024863

Epoch: 6| Step: 5
Training loss: 0.47356218099594116
Validation loss: 2.1622856060663858

Epoch: 6| Step: 6
Training loss: 0.7203069925308228
Validation loss: 2.1091654896736145

Epoch: 6| Step: 7
Training loss: 0.9683517217636108
Validation loss: 2.221315840880076

Epoch: 6| Step: 8
Training loss: 0.607933759689331
Validation loss: 2.191788295904795

Epoch: 6| Step: 9
Training loss: 0.794304370880127
Validation loss: 2.2553583780924478

Epoch: 6| Step: 10
Training loss: 0.9447259306907654
Validation loss: 2.175024410088857

Epoch: 6| Step: 11
Training loss: 0.45320257544517517
Validation loss: 2.1630499164263406

Epoch: 6| Step: 12
Training loss: 0.5421971082687378
Validation loss: 2.1813830534617105

Epoch: 6| Step: 13
Training loss: 1.1198160648345947
Validation loss: 2.1524144411087036

Epoch: 233| Step: 0
Training loss: 0.3092444837093353
Validation loss: 2.169088284174601

Epoch: 6| Step: 1
Training loss: 0.7503836154937744
Validation loss: 2.2462854385375977

Epoch: 6| Step: 2
Training loss: 1.4845457077026367
Validation loss: 2.1807438135147095

Epoch: 6| Step: 3
Training loss: 0.4308611750602722
Validation loss: 2.1594451268514

Epoch: 6| Step: 4
Training loss: 0.5355359315872192
Validation loss: 2.1343870560328164

Epoch: 6| Step: 5
Training loss: 0.5002193450927734
Validation loss: 2.1850013534228006

Epoch: 6| Step: 6
Training loss: 1.0537259578704834
Validation loss: 2.200885315736135

Epoch: 6| Step: 7
Training loss: 0.7687033414840698
Validation loss: 2.1305724581082663

Epoch: 6| Step: 8
Training loss: 0.25857439637184143
Validation loss: 2.1711662809054055

Epoch: 6| Step: 9
Training loss: 0.6278259754180908
Validation loss: 2.2011753718058267

Epoch: 6| Step: 10
Training loss: 0.6211256980895996
Validation loss: 2.2122388084729514

Epoch: 6| Step: 11
Training loss: 0.7382559776306152
Validation loss: 2.1697614192962646

Epoch: 6| Step: 12
Training loss: 0.6454125046730042
Validation loss: 2.1928354104359946

Epoch: 6| Step: 13
Training loss: 0.5846251249313354
Validation loss: 2.220991929372152

Epoch: 234| Step: 0
Training loss: 0.7059306502342224
Validation loss: 2.2111801703770957

Epoch: 6| Step: 1
Training loss: 0.32840126752853394
Validation loss: 2.2526838382085166

Epoch: 6| Step: 2
Training loss: 0.7287724018096924
Validation loss: 2.17475833495458

Epoch: 6| Step: 3
Training loss: 0.5124384164810181
Validation loss: 2.198199152946472

Epoch: 6| Step: 4
Training loss: 0.6724982261657715
Validation loss: 2.2035268346468606

Epoch: 6| Step: 5
Training loss: 0.5050309300422668
Validation loss: 2.179280618826548

Epoch: 6| Step: 6
Training loss: 0.9357366561889648
Validation loss: 2.1970142126083374

Epoch: 6| Step: 7
Training loss: 0.6240329742431641
Validation loss: 2.197843869527181

Epoch: 6| Step: 8
Training loss: 0.911766529083252
Validation loss: 2.1793580849965415

Epoch: 6| Step: 9
Training loss: 0.7217867374420166
Validation loss: 2.137156844139099

Epoch: 6| Step: 10
Training loss: 0.8457584381103516
Validation loss: 2.210370739301046

Epoch: 6| Step: 11
Training loss: 1.1360177993774414
Validation loss: 2.1791019638379416

Epoch: 6| Step: 12
Training loss: 0.38974305987358093
Validation loss: 2.203706204891205

Epoch: 6| Step: 13
Training loss: 0.4223603308200836
Validation loss: 2.245419502258301

Epoch: 235| Step: 0
Training loss: 0.4707113206386566
Validation loss: 2.2105549573898315

Epoch: 6| Step: 1
Training loss: 0.9045131206512451
Validation loss: 2.208937664826711

Epoch: 6| Step: 2
Training loss: 0.9659085273742676
Validation loss: 2.2110157012939453

Epoch: 6| Step: 3
Training loss: 0.5683915615081787
Validation loss: 2.2308455109596252

Epoch: 6| Step: 4
Training loss: 1.027613639831543
Validation loss: 2.2087151606877646

Epoch: 6| Step: 5
Training loss: 0.4621964395046234
Validation loss: 2.2270865043004355

Epoch: 6| Step: 6
Training loss: 0.6277241706848145
Validation loss: 2.2176438768704734

Epoch: 6| Step: 7
Training loss: 0.6515645980834961
Validation loss: 2.1781543095906577

Epoch: 6| Step: 8
Training loss: 0.5582274198532104
Validation loss: 2.201091210047404

Epoch: 6| Step: 9
Training loss: 0.35425901412963867
Validation loss: 2.231085499127706

Epoch: 6| Step: 10
Training loss: 0.8993461728096008
Validation loss: 2.1245633363723755

Epoch: 6| Step: 11
Training loss: 0.5290964245796204
Validation loss: 2.202265818913778

Epoch: 6| Step: 12
Training loss: 0.680268406867981
Validation loss: 2.1939042607943215

Epoch: 6| Step: 13
Training loss: 0.6162285804748535
Validation loss: 2.135235051314036

Epoch: 236| Step: 0
Training loss: 0.5810718536376953
Validation loss: 2.15627654393514

Epoch: 6| Step: 1
Training loss: 0.9049251079559326
Validation loss: 2.198692957560221

Epoch: 6| Step: 2
Training loss: 0.345634788274765
Validation loss: 2.215443730354309

Epoch: 6| Step: 3
Training loss: 0.670127272605896
Validation loss: 2.2613313595453897

Epoch: 6| Step: 4
Training loss: 0.7672551870346069
Validation loss: 2.246371646722158

Epoch: 6| Step: 5
Training loss: 0.9687619805335999
Validation loss: 2.179506301879883

Epoch: 6| Step: 6
Training loss: 0.5635238885879517
Validation loss: 2.157935937245687

Epoch: 6| Step: 7
Training loss: 0.9862174987792969
Validation loss: 2.2148834069569907

Epoch: 6| Step: 8
Training loss: 0.6837177872657776
Validation loss: 2.1722478667894998

Epoch: 6| Step: 9
Training loss: 0.3414144515991211
Validation loss: 2.1531012058258057

Epoch: 6| Step: 10
Training loss: 0.7457665205001831
Validation loss: 2.161831498146057

Epoch: 6| Step: 11
Training loss: 0.6355397701263428
Validation loss: 2.1302507519721985

Epoch: 6| Step: 12
Training loss: 0.4007437825202942
Validation loss: 2.216918110847473

Epoch: 6| Step: 13
Training loss: 0.7105875015258789
Validation loss: 2.2098648150761924

Epoch: 237| Step: 0
Training loss: 0.6314342021942139
Validation loss: 2.158770183722178

Epoch: 6| Step: 1
Training loss: 0.6371086835861206
Validation loss: 2.188536763191223

Epoch: 6| Step: 2
Training loss: 0.5217862725257874
Validation loss: 2.1713832219441733

Epoch: 6| Step: 3
Training loss: 0.7194527983665466
Validation loss: 2.1523512601852417

Epoch: 6| Step: 4
Training loss: 0.7030375003814697
Validation loss: 2.2126827239990234

Epoch: 6| Step: 5
Training loss: 0.33815997838974
Validation loss: 2.2025895913441977

Epoch: 6| Step: 6
Training loss: 1.045426607131958
Validation loss: 2.1630324125289917

Epoch: 6| Step: 7
Training loss: 0.6772257089614868
Validation loss: 2.200843413670858

Epoch: 6| Step: 8
Training loss: 0.7148474454879761
Validation loss: 2.156150539716085

Epoch: 6| Step: 9
Training loss: 0.4624798893928528
Validation loss: 2.1778164903322854

Epoch: 6| Step: 10
Training loss: 0.8231735229492188
Validation loss: 2.2268227140108743

Epoch: 6| Step: 11
Training loss: 0.8294938206672668
Validation loss: 2.2115699648857117

Epoch: 6| Step: 12
Training loss: 0.4091416597366333
Validation loss: 2.1753867069880166

Epoch: 6| Step: 13
Training loss: 0.7902428507804871
Validation loss: 2.232891241709391

Epoch: 238| Step: 0
Training loss: 0.48644882440567017
Validation loss: 2.176867107550303

Epoch: 6| Step: 1
Training loss: 0.7231402397155762
Validation loss: 2.2204155127207437

Epoch: 6| Step: 2
Training loss: 1.0996990203857422
Validation loss: 2.2024106780687966

Epoch: 6| Step: 3
Training loss: 0.8272525668144226
Validation loss: 2.256066878636678

Epoch: 6| Step: 4
Training loss: 0.4793018102645874
Validation loss: 2.228925804297129

Epoch: 6| Step: 5
Training loss: 0.5877314209938049
Validation loss: 2.1871420542399087

Epoch: 6| Step: 6
Training loss: 0.6398378610610962
Validation loss: 2.1887477040290833

Epoch: 6| Step: 7
Training loss: 0.6813713312149048
Validation loss: 2.178264021873474

Epoch: 6| Step: 8
Training loss: 1.0131326913833618
Validation loss: 2.20363050699234

Epoch: 6| Step: 9
Training loss: 0.4878072738647461
Validation loss: 2.1605332692464194

Epoch: 6| Step: 10
Training loss: 0.7175949811935425
Validation loss: 2.138252854347229

Epoch: 6| Step: 11
Training loss: 0.507777214050293
Validation loss: 2.138663391272227

Epoch: 6| Step: 12
Training loss: 0.6494667530059814
Validation loss: 2.1724905172983804

Epoch: 6| Step: 13
Training loss: 0.4019814431667328
Validation loss: 2.1935657064119973

Epoch: 239| Step: 0
Training loss: 0.5696979761123657
Validation loss: 2.175183276335398

Epoch: 6| Step: 1
Training loss: 0.6392989754676819
Validation loss: 2.1757724285125732

Epoch: 6| Step: 2
Training loss: 0.4410769045352936
Validation loss: 2.1253914833068848

Epoch: 6| Step: 3
Training loss: 1.1003162860870361
Validation loss: 2.150576591491699

Epoch: 6| Step: 4
Training loss: 0.6070128083229065
Validation loss: 2.2137858867645264

Epoch: 6| Step: 5
Training loss: 0.6192439794540405
Validation loss: 2.2822628021240234

Epoch: 6| Step: 6
Training loss: 0.3377501964569092
Validation loss: 2.2150142987569175

Epoch: 6| Step: 7
Training loss: 0.7665289640426636
Validation loss: 2.1976181070009866

Epoch: 6| Step: 8
Training loss: 0.7876501083374023
Validation loss: 2.1707974870999656

Epoch: 6| Step: 9
Training loss: 0.5503369569778442
Validation loss: 2.1916711727778115

Epoch: 6| Step: 10
Training loss: 0.6227322220802307
Validation loss: 2.1611317793528237

Epoch: 6| Step: 11
Training loss: 1.1302664279937744
Validation loss: 2.143402616182963

Epoch: 6| Step: 12
Training loss: 0.8612334132194519
Validation loss: 2.1917934815088906

Epoch: 6| Step: 13
Training loss: 0.29722779989242554
Validation loss: 2.2127824624379477

Epoch: 240| Step: 0
Training loss: 0.9168921113014221
Validation loss: 2.1941803892453513

Epoch: 6| Step: 1
Training loss: 0.5628586411476135
Validation loss: 2.1923044125239053

Epoch: 6| Step: 2
Training loss: 0.7044418454170227
Validation loss: 2.2074931263923645

Epoch: 6| Step: 3
Training loss: 0.6527184247970581
Validation loss: 2.1874725619951882

Epoch: 6| Step: 4
Training loss: 1.09752357006073
Validation loss: 2.2764945824941

Epoch: 6| Step: 5
Training loss: 0.808815598487854
Validation loss: 2.2426969408988953

Epoch: 6| Step: 6
Training loss: 0.5008523464202881
Validation loss: 2.1803715030352273

Epoch: 6| Step: 7
Training loss: 0.6886779069900513
Validation loss: 2.176067133744558

Epoch: 6| Step: 8
Training loss: 0.5428338646888733
Validation loss: 2.2322938442230225

Epoch: 6| Step: 9
Training loss: 0.3485245704650879
Validation loss: 2.170093595981598

Epoch: 6| Step: 10
Training loss: 0.6753594875335693
Validation loss: 2.1822943091392517

Epoch: 6| Step: 11
Training loss: 0.3537355661392212
Validation loss: 2.1960995197296143

Epoch: 6| Step: 12
Training loss: 0.6138732433319092
Validation loss: 2.169195850690206

Epoch: 6| Step: 13
Training loss: 0.7802103757858276
Validation loss: 2.210348665714264

Epoch: 241| Step: 0
Training loss: 0.9505127668380737
Validation loss: 2.1502538124720254

Epoch: 6| Step: 1
Training loss: 0.5975180864334106
Validation loss: 2.2089125712712607

Epoch: 6| Step: 2
Training loss: 0.6580555438995361
Validation loss: 2.1400481462478638

Epoch: 6| Step: 3
Training loss: 0.6203914284706116
Validation loss: 2.2271332343419394

Epoch: 6| Step: 4
Training loss: 0.3141159415245056
Validation loss: 2.1710198124249778

Epoch: 6| Step: 5
Training loss: 0.747035026550293
Validation loss: 2.176967998345693

Epoch: 6| Step: 6
Training loss: 0.4568983316421509
Validation loss: 2.164169708887736

Epoch: 6| Step: 7
Training loss: 0.4671546518802643
Validation loss: 2.212611973285675

Epoch: 6| Step: 8
Training loss: 0.906074047088623
Validation loss: 2.2038907408714294

Epoch: 6| Step: 9
Training loss: 0.6333692669868469
Validation loss: 2.189619859059652

Epoch: 6| Step: 10
Training loss: 0.4912022650241852
Validation loss: 2.1546117862065635

Epoch: 6| Step: 11
Training loss: 0.519229531288147
Validation loss: 2.194154739379883

Epoch: 6| Step: 12
Training loss: 0.43905603885650635
Validation loss: 2.2063541412353516

Epoch: 6| Step: 13
Training loss: 0.8079416751861572
Validation loss: 2.1903578639030457

Epoch: 242| Step: 0
Training loss: 0.4410203993320465
Validation loss: 2.2281309564908347

Epoch: 6| Step: 1
Training loss: 0.8333942890167236
Validation loss: 2.1341808835665383

Epoch: 6| Step: 2
Training loss: 0.4684102535247803
Validation loss: 2.195987125237783

Epoch: 6| Step: 3
Training loss: 0.7435616254806519
Validation loss: 2.2276856899261475

Epoch: 6| Step: 4
Training loss: 0.7434169054031372
Validation loss: 2.2168975671132407

Epoch: 6| Step: 5
Training loss: 0.5218165516853333
Validation loss: 2.1783535877863565

Epoch: 6| Step: 6
Training loss: 0.7797966003417969
Validation loss: 2.1720808347066245

Epoch: 6| Step: 7
Training loss: 0.19026200473308563
Validation loss: 2.1325655380884805

Epoch: 6| Step: 8
Training loss: 0.3589455783367157
Validation loss: 2.146593471368154

Epoch: 6| Step: 9
Training loss: 0.5317631363868713
Validation loss: 2.211744765440623

Epoch: 6| Step: 10
Training loss: 0.7830396890640259
Validation loss: 2.1421483159065247

Epoch: 6| Step: 11
Training loss: 0.7440304756164551
Validation loss: 2.139690319697062

Epoch: 6| Step: 12
Training loss: 0.6563447713851929
Validation loss: 2.214719037214915

Epoch: 6| Step: 13
Training loss: 0.7028419971466064
Validation loss: 2.215948005517324

Epoch: 243| Step: 0
Training loss: 0.5132770538330078
Validation loss: 2.194943348566691

Epoch: 6| Step: 1
Training loss: 1.0150675773620605
Validation loss: 2.2313419580459595

Epoch: 6| Step: 2
Training loss: 0.4001658856868744
Validation loss: 2.2321890592575073

Epoch: 6| Step: 3
Training loss: 0.730108380317688
Validation loss: 2.2002817392349243

Epoch: 6| Step: 4
Training loss: 0.2539457678794861
Validation loss: 2.1927359898885093

Epoch: 6| Step: 5
Training loss: 0.9305530190467834
Validation loss: 2.195756514867147

Epoch: 6| Step: 6
Training loss: 0.6266696453094482
Validation loss: 2.148338476816813

Epoch: 6| Step: 7
Training loss: 0.49192720651626587
Validation loss: 2.1451964179674783

Epoch: 6| Step: 8
Training loss: 0.5063936710357666
Validation loss: 2.1752977768580117

Epoch: 6| Step: 9
Training loss: 0.23605754971504211
Validation loss: 2.1773127913475037

Epoch: 6| Step: 10
Training loss: 0.8040971755981445
Validation loss: 2.162687301635742

Epoch: 6| Step: 11
Training loss: 1.0377726554870605
Validation loss: 2.18174946308136

Epoch: 6| Step: 12
Training loss: 0.5648220181465149
Validation loss: 2.212794303894043

Epoch: 6| Step: 13
Training loss: 0.8231944441795349
Validation loss: 2.236963947614034

Epoch: 244| Step: 0
Training loss: 0.31756824254989624
Validation loss: 2.2474641601244607

Epoch: 6| Step: 1
Training loss: 0.44858747720718384
Validation loss: 2.2245556116104126

Epoch: 6| Step: 2
Training loss: 0.6673424243927002
Validation loss: 2.1519123315811157

Epoch: 6| Step: 3
Training loss: 0.6930110454559326
Validation loss: 2.1562737226486206

Epoch: 6| Step: 4
Training loss: 0.8128153085708618
Validation loss: 2.176297982533773

Epoch: 6| Step: 5
Training loss: 0.530424952507019
Validation loss: 2.171494642893473

Epoch: 6| Step: 6
Training loss: 0.6071434020996094
Validation loss: 2.1744030912717185

Epoch: 6| Step: 7
Training loss: 0.471031129360199
Validation loss: 2.241416891415914

Epoch: 6| Step: 8
Training loss: 0.7352612614631653
Validation loss: 2.221965511639913

Epoch: 6| Step: 9
Training loss: 0.7800592184066772
Validation loss: 2.2450100978215537

Epoch: 6| Step: 10
Training loss: 0.4713589549064636
Validation loss: 2.1992419163386026

Epoch: 6| Step: 11
Training loss: 0.8659306168556213
Validation loss: 2.2624136209487915

Epoch: 6| Step: 12
Training loss: 0.5905907154083252
Validation loss: 2.2354763547579446

Epoch: 6| Step: 13
Training loss: 1.2467331886291504
Validation loss: 2.225131094455719

Epoch: 245| Step: 0
Training loss: 0.5052220821380615
Validation loss: 2.2016032338142395

Epoch: 6| Step: 1
Training loss: 0.7820336222648621
Validation loss: 2.2079612612724304

Epoch: 6| Step: 2
Training loss: 0.6586399674415588
Validation loss: 2.210898756980896

Epoch: 6| Step: 3
Training loss: 1.0687159299850464
Validation loss: 2.1622143189112344

Epoch: 6| Step: 4
Training loss: 0.4854687452316284
Validation loss: 2.1594188809394836

Epoch: 6| Step: 5
Training loss: 0.5435718297958374
Validation loss: 2.1895798643430076

Epoch: 6| Step: 6
Training loss: 0.8662664890289307
Validation loss: 2.2206044793128967

Epoch: 6| Step: 7
Training loss: 0.42240411043167114
Validation loss: 2.196211795012156

Epoch: 6| Step: 8
Training loss: 0.5287203788757324
Validation loss: 2.18671445051829

Epoch: 6| Step: 9
Training loss: 0.4111284613609314
Validation loss: 2.2194491624832153

Epoch: 6| Step: 10
Training loss: 0.6419150233268738
Validation loss: 2.24250864982605

Epoch: 6| Step: 11
Training loss: 0.6221411228179932
Validation loss: 2.2068700989087424

Epoch: 6| Step: 12
Training loss: 0.7532964944839478
Validation loss: 2.2036772767702737

Epoch: 6| Step: 13
Training loss: 0.651192307472229
Validation loss: 2.211761792500814

Epoch: 246| Step: 0
Training loss: 0.5125753879547119
Validation loss: 2.2187108198801675

Epoch: 6| Step: 1
Training loss: 0.42358672618865967
Validation loss: 2.191519339879354

Epoch: 6| Step: 2
Training loss: 0.387761652469635
Validation loss: 2.1928247809410095

Epoch: 6| Step: 3
Training loss: 0.521689772605896
Validation loss: 2.1918554306030273

Epoch: 6| Step: 4
Training loss: 0.528454601764679
Validation loss: 2.173624118169149

Epoch: 6| Step: 5
Training loss: 0.6238246560096741
Validation loss: 2.1666003863016763

Epoch: 6| Step: 6
Training loss: 0.4872232675552368
Validation loss: 2.1957297325134277

Epoch: 6| Step: 7
Training loss: 0.6465003490447998
Validation loss: 2.1984951893488565

Epoch: 6| Step: 8
Training loss: 0.5376083254814148
Validation loss: 2.2222055991490683

Epoch: 6| Step: 9
Training loss: 2.018948554992676
Validation loss: 2.2037110726038613

Epoch: 6| Step: 10
Training loss: 0.48825544118881226
Validation loss: 2.2100968758265176

Epoch: 6| Step: 11
Training loss: 0.35659098625183105
Validation loss: 2.231054345766703

Epoch: 6| Step: 12
Training loss: 0.6114779710769653
Validation loss: 2.228434205055237

Epoch: 6| Step: 13
Training loss: 0.7123655676841736
Validation loss: 2.235189437866211

Epoch: 247| Step: 0
Training loss: 0.3689747452735901
Validation loss: 2.2231064240137735

Epoch: 6| Step: 1
Training loss: 0.5817741751670837
Validation loss: 2.1890246669451394

Epoch: 6| Step: 2
Training loss: 0.2014983892440796
Validation loss: 2.266891658306122

Epoch: 6| Step: 3
Training loss: 0.9946295619010925
Validation loss: 2.156433920065562

Epoch: 6| Step: 4
Training loss: 1.1639314889907837
Validation loss: 2.2283278902371726

Epoch: 6| Step: 5
Training loss: 0.5155397653579712
Validation loss: 2.1534366806348166

Epoch: 6| Step: 6
Training loss: 0.6169883608818054
Validation loss: 2.2165375351905823

Epoch: 6| Step: 7
Training loss: 0.5169405937194824
Validation loss: 2.2473713954289756

Epoch: 6| Step: 8
Training loss: 0.41933852434158325
Validation loss: 2.233751734097799

Epoch: 6| Step: 9
Training loss: 0.5997360944747925
Validation loss: 2.2267228960990906

Epoch: 6| Step: 10
Training loss: 0.9764430522918701
Validation loss: 2.216867983341217

Epoch: 6| Step: 11
Training loss: 0.9156808853149414
Validation loss: 2.2776307264963784

Epoch: 6| Step: 12
Training loss: 0.5444870591163635
Validation loss: 2.23356964190801

Epoch: 6| Step: 13
Training loss: 0.4103807210922241
Validation loss: 2.166262964407603

Epoch: 248| Step: 0
Training loss: 0.6369819641113281
Validation loss: 2.249518791834513

Epoch: 6| Step: 1
Training loss: 0.34859177470207214
Validation loss: 2.1799585421880088

Epoch: 6| Step: 2
Training loss: 0.7255458831787109
Validation loss: 2.2511051893234253

Epoch: 6| Step: 3
Training loss: 0.678386926651001
Validation loss: 2.1346086859703064

Epoch: 6| Step: 4
Training loss: 0.7518372535705566
Validation loss: 2.2222676873207092

Epoch: 6| Step: 5
Training loss: 0.30886998772621155
Validation loss: 2.160087525844574

Epoch: 6| Step: 6
Training loss: 0.9089508056640625
Validation loss: 2.2292049129803977

Epoch: 6| Step: 7
Training loss: 0.7771953344345093
Validation loss: 2.1829931934674582

Epoch: 6| Step: 8
Training loss: 0.9082144498825073
Validation loss: 2.22766641775767

Epoch: 6| Step: 9
Training loss: 0.6302974224090576
Validation loss: 2.2700500885645547

Epoch: 6| Step: 10
Training loss: 0.6909026503562927
Validation loss: 2.2764347195625305

Epoch: 6| Step: 11
Training loss: 0.5515596866607666
Validation loss: 2.2251981695493064

Epoch: 6| Step: 12
Training loss: 0.4279909133911133
Validation loss: 2.2153716683387756

Epoch: 6| Step: 13
Training loss: 0.579834520816803
Validation loss: 2.217251102129618

Epoch: 249| Step: 0
Training loss: 0.5358649492263794
Validation loss: 2.239337205886841

Epoch: 6| Step: 1
Training loss: 0.8894341588020325
Validation loss: 2.1808811028798423

Epoch: 6| Step: 2
Training loss: 0.9592739343643188
Validation loss: 2.2220231095949807

Epoch: 6| Step: 3
Training loss: 0.6678165793418884
Validation loss: 2.199427763621012

Epoch: 6| Step: 4
Training loss: 0.5424931049346924
Validation loss: 2.168950319290161

Epoch: 6| Step: 5
Training loss: 0.6551990509033203
Validation loss: 2.202380041281382

Epoch: 6| Step: 6
Training loss: 0.7416242957115173
Validation loss: 2.2241384387016296

Epoch: 6| Step: 7
Training loss: 0.5788593292236328
Validation loss: 2.2288265029589334

Epoch: 6| Step: 8
Training loss: 0.4117743968963623
Validation loss: 2.2348645528157554

Epoch: 6| Step: 9
Training loss: 0.4132278561592102
Validation loss: 2.288000504175822

Epoch: 6| Step: 10
Training loss: 0.5059608817100525
Validation loss: 2.245604713757833

Epoch: 6| Step: 11
Training loss: 0.6347374320030212
Validation loss: 2.2246310114860535

Epoch: 6| Step: 12
Training loss: 0.44095733761787415
Validation loss: 2.189000984032949

Epoch: 6| Step: 13
Training loss: 0.9466474652290344
Validation loss: 2.234351714452108

Epoch: 250| Step: 0
Training loss: 0.6699212193489075
Validation loss: 2.161064167817434

Epoch: 6| Step: 1
Training loss: 0.957578182220459
Validation loss: 2.1852760513623557

Epoch: 6| Step: 2
Training loss: 0.6434481739997864
Validation loss: 2.253774583339691

Epoch: 6| Step: 3
Training loss: 0.42239049077033997
Validation loss: 2.1724783976872764

Epoch: 6| Step: 4
Training loss: 0.7749321460723877
Validation loss: 2.1616992950439453

Epoch: 6| Step: 5
Training loss: 0.5021748542785645
Validation loss: 2.2399571339289346

Epoch: 6| Step: 6
Training loss: 0.6882629990577698
Validation loss: 2.208204368750254

Epoch: 6| Step: 7
Training loss: 0.47477948665618896
Validation loss: 2.1990816593170166

Epoch: 6| Step: 8
Training loss: 0.6390712261199951
Validation loss: 2.252462943394979

Epoch: 6| Step: 9
Training loss: 0.9236548542976379
Validation loss: 2.197026014328003

Epoch: 6| Step: 10
Training loss: 0.45021486282348633
Validation loss: 2.217422624429067

Epoch: 6| Step: 11
Training loss: 0.4526934325695038
Validation loss: 2.189357817173004

Epoch: 6| Step: 12
Training loss: 0.3511142432689667
Validation loss: 2.1782066226005554

Epoch: 6| Step: 13
Training loss: 0.2787272036075592
Validation loss: 2.1826624671618142

Epoch: 251| Step: 0
Training loss: 1.1052968502044678
Validation loss: 2.222730358441671

Epoch: 6| Step: 1
Training loss: 0.7218624353408813
Validation loss: 2.227716247240702

Epoch: 6| Step: 2
Training loss: 0.5326236486434937
Validation loss: 2.187179426352183

Epoch: 6| Step: 3
Training loss: 0.7651375532150269
Validation loss: 2.1772592067718506

Epoch: 6| Step: 4
Training loss: 1.1737847328186035
Validation loss: 2.1744794050852456

Epoch: 6| Step: 5
Training loss: 0.43063369393348694
Validation loss: 2.246062239011129

Epoch: 6| Step: 6
Training loss: 0.8492855429649353
Validation loss: 2.2049959301948547

Epoch: 6| Step: 7
Training loss: 0.30692094564437866
Validation loss: 2.287211080392202

Epoch: 6| Step: 8
Training loss: 0.3638959228992462
Validation loss: 2.2624242305755615

Epoch: 6| Step: 9
Training loss: 0.5786956548690796
Validation loss: 2.191082795461019

Epoch: 6| Step: 10
Training loss: 0.33056437969207764
Validation loss: 2.1993764837582908

Epoch: 6| Step: 11
Training loss: 0.31836047768592834
Validation loss: 2.2032589117685952

Epoch: 6| Step: 12
Training loss: 0.6576465368270874
Validation loss: 2.25334370136261

Epoch: 6| Step: 13
Training loss: 0.579584002494812
Validation loss: 2.175343950589498

Epoch: 252| Step: 0
Training loss: 0.5831444263458252
Validation loss: 2.248911996682485

Epoch: 6| Step: 1
Training loss: 0.62126225233078
Validation loss: 2.184264858563741

Epoch: 6| Step: 2
Training loss: 0.7441737055778503
Validation loss: 2.19098828236262

Epoch: 6| Step: 3
Training loss: 0.6623955965042114
Validation loss: 2.2216477195421853

Epoch: 6| Step: 4
Training loss: 0.3276101350784302
Validation loss: 2.189576049645742

Epoch: 6| Step: 5
Training loss: 0.7839065790176392
Validation loss: 2.187983512878418

Epoch: 6| Step: 6
Training loss: 0.9891140460968018
Validation loss: 2.1843735178311667

Epoch: 6| Step: 7
Training loss: 0.5556418895721436
Validation loss: 2.1745941241582236

Epoch: 6| Step: 8
Training loss: 0.4391441345214844
Validation loss: 2.2153552770614624

Epoch: 6| Step: 9
Training loss: 0.7119373679161072
Validation loss: 2.212870240211487

Epoch: 6| Step: 10
Training loss: 0.7311358451843262
Validation loss: 2.2204678654670715

Epoch: 6| Step: 11
Training loss: 0.5504674911499023
Validation loss: 2.167263408501943

Epoch: 6| Step: 12
Training loss: 0.5380994081497192
Validation loss: 2.222793161869049

Epoch: 6| Step: 13
Training loss: 0.5806298851966858
Validation loss: 2.2077414790789285

Epoch: 253| Step: 0
Training loss: 0.3982841670513153
Validation loss: 2.1710723638534546

Epoch: 6| Step: 1
Training loss: 0.363020658493042
Validation loss: 2.1993616819381714

Epoch: 6| Step: 2
Training loss: 0.5082470178604126
Validation loss: 2.1900017658869424

Epoch: 6| Step: 3
Training loss: 0.5065673589706421
Validation loss: 2.1788791020711265

Epoch: 6| Step: 4
Training loss: 0.5187002420425415
Validation loss: 2.1848254601160684

Epoch: 6| Step: 5
Training loss: 0.4573647081851959
Validation loss: 2.206447879473368

Epoch: 6| Step: 6
Training loss: 0.5603410005569458
Validation loss: 2.2170997063318887

Epoch: 6| Step: 7
Training loss: 1.1001163721084595
Validation loss: 2.175960878531138

Epoch: 6| Step: 8
Training loss: 0.29247111082077026
Validation loss: 2.1945523023605347

Epoch: 6| Step: 9
Training loss: 0.8068534135818481
Validation loss: 2.2175221045811973

Epoch: 6| Step: 10
Training loss: 0.38008418679237366
Validation loss: 2.211297074953715

Epoch: 6| Step: 11
Training loss: 0.7638510465621948
Validation loss: 2.189897278944651

Epoch: 6| Step: 12
Training loss: 0.7802237868309021
Validation loss: 2.2084955175717673

Epoch: 6| Step: 13
Training loss: 0.9394927024841309
Validation loss: 2.1512858470280967

Epoch: 254| Step: 0
Training loss: 0.4014087915420532
Validation loss: 2.1885521610577903

Epoch: 6| Step: 1
Training loss: 0.28527939319610596
Validation loss: 2.175465246041616

Epoch: 6| Step: 2
Training loss: 0.5502801537513733
Validation loss: 2.2409286896387735

Epoch: 6| Step: 3
Training loss: 0.42020806670188904
Validation loss: 2.1387241880098977

Epoch: 6| Step: 4
Training loss: 1.0599191188812256
Validation loss: 2.188003718852997

Epoch: 6| Step: 5
Training loss: 0.5201364159584045
Validation loss: 2.191956122716268

Epoch: 6| Step: 6
Training loss: 0.6983732581138611
Validation loss: 2.242755889892578

Epoch: 6| Step: 7
Training loss: 0.9895010590553284
Validation loss: 2.169113119443258

Epoch: 6| Step: 8
Training loss: 0.3611707389354706
Validation loss: 2.218836704889933

Epoch: 6| Step: 9
Training loss: 0.6432822942733765
Validation loss: 2.2100661396980286

Epoch: 6| Step: 10
Training loss: 0.45630717277526855
Validation loss: 2.158362885316213

Epoch: 6| Step: 11
Training loss: 0.6020839214324951
Validation loss: 2.1837485233942666

Epoch: 6| Step: 12
Training loss: 0.6271340847015381
Validation loss: 2.2053169409434

Epoch: 6| Step: 13
Training loss: 0.7904360294342041
Validation loss: 2.168780048688253

Epoch: 255| Step: 0
Training loss: 0.5307050943374634
Validation loss: 2.251561482747396

Epoch: 6| Step: 1
Training loss: 0.9181829690933228
Validation loss: 2.2590554555257163

Epoch: 6| Step: 2
Training loss: 0.544270932674408
Validation loss: 2.219074765841166

Epoch: 6| Step: 3
Training loss: 0.5076523423194885
Validation loss: 2.2506140867869058

Epoch: 6| Step: 4
Training loss: 0.8376150131225586
Validation loss: 2.2394770781199136

Epoch: 6| Step: 5
Training loss: 0.6056665182113647
Validation loss: 2.2314085960388184

Epoch: 6| Step: 6
Training loss: 0.3598594665527344
Validation loss: 2.215921918551127

Epoch: 6| Step: 7
Training loss: 0.504641056060791
Validation loss: 2.244294742743174

Epoch: 6| Step: 8
Training loss: 1.345120906829834
Validation loss: 2.2215783397356668

Epoch: 6| Step: 9
Training loss: 0.5839017629623413
Validation loss: 2.2491318186124167

Epoch: 6| Step: 10
Training loss: 0.2566630244255066
Validation loss: 2.203196346759796

Epoch: 6| Step: 11
Training loss: 0.527232825756073
Validation loss: 2.1356140772501626

Epoch: 6| Step: 12
Training loss: 0.5210543870925903
Validation loss: 2.211505134900411

Epoch: 6| Step: 13
Training loss: 0.7140659093856812
Validation loss: 2.2439518173535666

Epoch: 256| Step: 0
Training loss: 0.6228052377700806
Validation loss: 2.2021161317825317

Epoch: 6| Step: 1
Training loss: 0.7123528718948364
Validation loss: 2.220021108786265

Epoch: 6| Step: 2
Training loss: 0.7788058519363403
Validation loss: 2.2101444602012634

Epoch: 6| Step: 3
Training loss: 0.6422379016876221
Validation loss: 2.1981077988942466

Epoch: 6| Step: 4
Training loss: 0.46202605962753296
Validation loss: 2.2339208523432412

Epoch: 6| Step: 5
Training loss: 0.49048781394958496
Validation loss: 2.238873461882273

Epoch: 6| Step: 6
Training loss: 0.38295382261276245
Validation loss: 2.231310705343882

Epoch: 6| Step: 7
Training loss: 0.5399664044380188
Validation loss: 2.183907409509023

Epoch: 6| Step: 8
Training loss: 0.5419337153434753
Validation loss: 2.209797660509745

Epoch: 6| Step: 9
Training loss: 0.7141522765159607
Validation loss: 2.212544580300649

Epoch: 6| Step: 10
Training loss: 0.2988179326057434
Validation loss: 2.215868592262268

Epoch: 6| Step: 11
Training loss: 0.38708579540252686
Validation loss: 2.289490540822347

Epoch: 6| Step: 12
Training loss: 1.062535285949707
Validation loss: 2.239201029141744

Epoch: 6| Step: 13
Training loss: 1.1648656129837036
Validation loss: 2.231795529524485

Epoch: 257| Step: 0
Training loss: 0.3915279805660248
Validation loss: 2.2009558280309043

Epoch: 6| Step: 1
Training loss: 0.706444263458252
Validation loss: 2.2341312170028687

Epoch: 6| Step: 2
Training loss: 0.8775895833969116
Validation loss: 2.171181619167328

Epoch: 6| Step: 3
Training loss: 0.5981308221817017
Validation loss: 2.2325121561686196

Epoch: 6| Step: 4
Training loss: 0.3442079424858093
Validation loss: 2.1950804789861045

Epoch: 6| Step: 5
Training loss: 0.3681744933128357
Validation loss: 2.2448916832605996

Epoch: 6| Step: 6
Training loss: 0.5986944437026978
Validation loss: 2.1933539311091104

Epoch: 6| Step: 7
Training loss: 0.4601747393608093
Validation loss: 2.2724797328313193

Epoch: 6| Step: 8
Training loss: 0.6330706477165222
Validation loss: 2.2179996172587075

Epoch: 6| Step: 9
Training loss: 0.34734493494033813
Validation loss: 2.228928565979004

Epoch: 6| Step: 10
Training loss: 0.9189436435699463
Validation loss: 2.2223276098569236

Epoch: 6| Step: 11
Training loss: 0.4718596339225769
Validation loss: 2.2372172276178994

Epoch: 6| Step: 12
Training loss: 0.7616852521896362
Validation loss: 2.219058712323507

Epoch: 6| Step: 13
Training loss: 0.4824778437614441
Validation loss: 2.242500821749369

Epoch: 258| Step: 0
Training loss: 0.6480543613433838
Validation loss: 2.2378617922465005

Epoch: 6| Step: 1
Training loss: 0.6894558668136597
Validation loss: 2.2643954952557883

Epoch: 6| Step: 2
Training loss: 0.4429532587528229
Validation loss: 2.1587215065956116

Epoch: 6| Step: 3
Training loss: 0.8237695693969727
Validation loss: 2.196947375933329

Epoch: 6| Step: 4
Training loss: 0.7182378768920898
Validation loss: 2.1986639698346457

Epoch: 6| Step: 5
Training loss: 0.45069602131843567
Validation loss: 2.2295208970705667

Epoch: 6| Step: 6
Training loss: 0.6948697566986084
Validation loss: 2.215464433034261

Epoch: 6| Step: 7
Training loss: 0.3077565133571625
Validation loss: 2.269282877445221

Epoch: 6| Step: 8
Training loss: 0.6286659240722656
Validation loss: 2.2596449851989746

Epoch: 6| Step: 9
Training loss: 0.6036105751991272
Validation loss: 2.2426119248072305

Epoch: 6| Step: 10
Training loss: 0.4483529031276703
Validation loss: 2.2262697418530784

Epoch: 6| Step: 11
Training loss: 0.7278860807418823
Validation loss: 2.218368709087372

Epoch: 6| Step: 12
Training loss: 0.5722020864486694
Validation loss: 2.241719603538513

Epoch: 6| Step: 13
Training loss: 0.8162283897399902
Validation loss: 2.2062507271766663

Epoch: 259| Step: 0
Training loss: 0.5495894551277161
Validation loss: 2.1361357967058816

Epoch: 6| Step: 1
Training loss: 0.8373776078224182
Validation loss: 2.224574943383535

Epoch: 6| Step: 2
Training loss: 0.9670850038528442
Validation loss: 2.1863537232081094

Epoch: 6| Step: 3
Training loss: 0.43358850479125977
Validation loss: 2.2137821912765503

Epoch: 6| Step: 4
Training loss: 0.6704406142234802
Validation loss: 2.2355034550031028

Epoch: 6| Step: 5
Training loss: 0.45143043994903564
Validation loss: 2.196622451146444

Epoch: 6| Step: 6
Training loss: 0.5277547240257263
Validation loss: 2.2101619839668274

Epoch: 6| Step: 7
Training loss: 0.5663957595825195
Validation loss: 2.218188762664795

Epoch: 6| Step: 8
Training loss: 0.5441422462463379
Validation loss: 2.222570260365804

Epoch: 6| Step: 9
Training loss: 0.3231421113014221
Validation loss: 2.2531506220499673

Epoch: 6| Step: 10
Training loss: 0.8418781161308289
Validation loss: 2.237059235572815

Epoch: 6| Step: 11
Training loss: 0.8000715970993042
Validation loss: 2.211374282836914

Epoch: 6| Step: 12
Training loss: 0.515934944152832
Validation loss: 2.22650545835495

Epoch: 6| Step: 13
Training loss: 0.3954123258590698
Validation loss: 2.242560843626658

Epoch: 260| Step: 0
Training loss: 0.48259884119033813
Validation loss: 2.2161117990811667

Epoch: 6| Step: 1
Training loss: 0.43731969594955444
Validation loss: 2.2176389495531716

Epoch: 6| Step: 2
Training loss: 0.37867945432662964
Validation loss: 2.240320086479187

Epoch: 6| Step: 3
Training loss: 0.7458105087280273
Validation loss: 2.2421716849009194

Epoch: 6| Step: 4
Training loss: 1.1538727283477783
Validation loss: 2.2235383788744607

Epoch: 6| Step: 5
Training loss: 0.934599757194519
Validation loss: 2.2357439597447715

Epoch: 6| Step: 6
Training loss: 0.2801816463470459
Validation loss: 2.2190290888150535

Epoch: 6| Step: 7
Training loss: 0.864251971244812
Validation loss: 2.2005606094996133

Epoch: 6| Step: 8
Training loss: 0.7574695944786072
Validation loss: 2.2228812177975974

Epoch: 6| Step: 9
Training loss: 0.3532729744911194
Validation loss: 2.2520413200060525

Epoch: 6| Step: 10
Training loss: 0.2696698307991028
Validation loss: 2.2047993342081704

Epoch: 6| Step: 11
Training loss: 0.5568665266036987
Validation loss: 2.223085582256317

Epoch: 6| Step: 12
Training loss: 0.6965683698654175
Validation loss: 2.2918131748835244

Epoch: 6| Step: 13
Training loss: 0.3120535612106323
Validation loss: 2.198434889316559

Epoch: 261| Step: 0
Training loss: 0.2306455373764038
Validation loss: 2.2776621182759604

Epoch: 6| Step: 1
Training loss: 0.44384509325027466
Validation loss: 2.1960209210713706

Epoch: 6| Step: 2
Training loss: 0.3301154375076294
Validation loss: 2.241966803868612

Epoch: 6| Step: 3
Training loss: 0.3056776523590088
Validation loss: 2.2290533781051636

Epoch: 6| Step: 4
Training loss: 0.6053107380867004
Validation loss: 2.2719085613886514

Epoch: 6| Step: 5
Training loss: 0.6444380283355713
Validation loss: 2.2626133362452188

Epoch: 6| Step: 6
Training loss: 1.2360790967941284
Validation loss: 2.261979897816976

Epoch: 6| Step: 7
Training loss: 0.6066576242446899
Validation loss: 2.2301141222318015

Epoch: 6| Step: 8
Training loss: 0.6522090435028076
Validation loss: 2.2499385476112366

Epoch: 6| Step: 9
Training loss: 0.576604962348938
Validation loss: 2.1606641014417014

Epoch: 6| Step: 10
Training loss: 0.45669323205947876
Validation loss: 2.2279887398084006

Epoch: 6| Step: 11
Training loss: 0.7505943775177002
Validation loss: 2.2211477160453796

Epoch: 6| Step: 12
Training loss: 0.4631882905960083
Validation loss: 2.239617566267649

Epoch: 6| Step: 13
Training loss: 0.8762996196746826
Validation loss: 2.1506197253863015

Epoch: 262| Step: 0
Training loss: 0.519940197467804
Validation loss: 2.260554552078247

Epoch: 6| Step: 1
Training loss: 1.0019009113311768
Validation loss: 2.25929586092631

Epoch: 6| Step: 2
Training loss: 0.656404435634613
Validation loss: 2.25957198937734

Epoch: 6| Step: 3
Training loss: 0.43373528122901917
Validation loss: 2.225529114405314

Epoch: 6| Step: 4
Training loss: 0.5168964862823486
Validation loss: 2.272926608721415

Epoch: 6| Step: 5
Training loss: 0.31536492705345154
Validation loss: 2.20565527677536

Epoch: 6| Step: 6
Training loss: 0.31992584466934204
Validation loss: 2.2403726975123086

Epoch: 6| Step: 7
Training loss: 1.0637807846069336
Validation loss: 2.1825746297836304

Epoch: 6| Step: 8
Training loss: 0.4591166079044342
Validation loss: 2.2230875293413797

Epoch: 6| Step: 9
Training loss: 0.7576066255569458
Validation loss: 2.2277667919794717

Epoch: 6| Step: 10
Training loss: 0.49659714102745056
Validation loss: 2.2372394601504006

Epoch: 6| Step: 11
Training loss: 0.6315490007400513
Validation loss: 2.21360711256663

Epoch: 6| Step: 12
Training loss: 0.6502845883369446
Validation loss: 2.2716224789619446

Epoch: 6| Step: 13
Training loss: 0.42498934268951416
Validation loss: 2.2131532033284507

Epoch: 263| Step: 0
Training loss: 0.7442050576210022
Validation loss: 2.276716331640879

Epoch: 6| Step: 1
Training loss: 0.7568892240524292
Validation loss: 2.244011183579763

Epoch: 6| Step: 2
Training loss: 0.7577513456344604
Validation loss: 2.2614758213361106

Epoch: 6| Step: 3
Training loss: 0.9539618492126465
Validation loss: 2.264545480410258

Epoch: 6| Step: 4
Training loss: 0.40575459599494934
Validation loss: 2.2193357149759927

Epoch: 6| Step: 5
Training loss: 0.5496286153793335
Validation loss: 2.185708483060201

Epoch: 6| Step: 6
Training loss: 0.5524186491966248
Validation loss: 2.207307000954946

Epoch: 6| Step: 7
Training loss: 0.4099329113960266
Validation loss: 2.303936799367269

Epoch: 6| Step: 8
Training loss: 0.3320482671260834
Validation loss: 2.197289745012919

Epoch: 6| Step: 9
Training loss: 0.5766458511352539
Validation loss: 2.2440805037816367

Epoch: 6| Step: 10
Training loss: 0.6022287011146545
Validation loss: 2.3398055831591287

Epoch: 6| Step: 11
Training loss: 0.45030292868614197
Validation loss: 2.2264716227849326

Epoch: 6| Step: 12
Training loss: 0.5187584757804871
Validation loss: 2.2927476167678833

Epoch: 6| Step: 13
Training loss: 0.3947567939758301
Validation loss: 2.309647560119629

Epoch: 264| Step: 0
Training loss: 0.49920952320098877
Validation loss: 2.2505719860394797

Epoch: 6| Step: 1
Training loss: 0.6085525751113892
Validation loss: 2.2249160011609397

Epoch: 6| Step: 2
Training loss: 0.4086645841598511
Validation loss: 2.20180344581604

Epoch: 6| Step: 3
Training loss: 0.5067020058631897
Validation loss: 2.240408182144165

Epoch: 6| Step: 4
Training loss: 0.618524432182312
Validation loss: 2.204373081525167

Epoch: 6| Step: 5
Training loss: 0.44288742542266846
Validation loss: 2.2059481143951416

Epoch: 6| Step: 6
Training loss: 0.4638174772262573
Validation loss: 2.2099914948145547

Epoch: 6| Step: 7
Training loss: 0.5322824716567993
Validation loss: 2.199767450491587

Epoch: 6| Step: 8
Training loss: 0.3797169327735901
Validation loss: 2.246527453263601

Epoch: 6| Step: 9
Training loss: 0.4938434958457947
Validation loss: 2.2261876265207925

Epoch: 6| Step: 10
Training loss: 0.7903733253479004
Validation loss: 2.260244687398275

Epoch: 6| Step: 11
Training loss: 1.2181094884872437
Validation loss: 2.277719418207804

Epoch: 6| Step: 12
Training loss: 0.7323195934295654
Validation loss: 2.2447343269983926

Epoch: 6| Step: 13
Training loss: 0.36626824736595154
Validation loss: 2.216916640599569

Epoch: 265| Step: 0
Training loss: 0.5812903046607971
Validation loss: 2.2946613232294717

Epoch: 6| Step: 1
Training loss: 0.7071654796600342
Validation loss: 2.251101791858673

Epoch: 6| Step: 2
Training loss: 0.7448763847351074
Validation loss: 2.255538741747538

Epoch: 6| Step: 3
Training loss: 0.7350680828094482
Validation loss: 2.239557464917501

Epoch: 6| Step: 4
Training loss: 0.40601053833961487
Validation loss: 2.2717565496762595

Epoch: 6| Step: 5
Training loss: 0.7133752107620239
Validation loss: 2.2720198035240173

Epoch: 6| Step: 6
Training loss: 0.3075871467590332
Validation loss: 2.278856098651886

Epoch: 6| Step: 7
Training loss: 0.5685830116271973
Validation loss: 2.25808314482371

Epoch: 6| Step: 8
Training loss: 0.42056649923324585
Validation loss: 2.2839084466298423

Epoch: 6| Step: 9
Training loss: 0.613685131072998
Validation loss: 2.240015168984731

Epoch: 6| Step: 10
Training loss: 0.45465531945228577
Validation loss: 2.193036357561747

Epoch: 6| Step: 11
Training loss: 0.5591349005699158
Validation loss: 2.2675251762072244

Epoch: 6| Step: 12
Training loss: 0.631534218788147
Validation loss: 2.2524441878000894

Epoch: 6| Step: 13
Training loss: 0.2783512473106384
Validation loss: 2.2802164554595947

Epoch: 266| Step: 0
Training loss: 0.7747326493263245
Validation loss: 2.2448397676150003

Epoch: 6| Step: 1
Training loss: 0.4300310015678406
Validation loss: 2.246183613936106

Epoch: 6| Step: 2
Training loss: 0.466035395860672
Validation loss: 2.273747682571411

Epoch: 6| Step: 3
Training loss: 0.41509348154067993
Validation loss: 2.240323265393575

Epoch: 6| Step: 4
Training loss: 0.5949681401252747
Validation loss: 2.2253983418146768

Epoch: 6| Step: 5
Training loss: 0.4140852689743042
Validation loss: 2.2867217461268106

Epoch: 6| Step: 6
Training loss: 0.5071078538894653
Validation loss: 2.2770398457845054

Epoch: 6| Step: 7
Training loss: 0.40534132719039917
Validation loss: 2.189102907975515

Epoch: 6| Step: 8
Training loss: 0.6912329196929932
Validation loss: 2.2480241854985556

Epoch: 6| Step: 9
Training loss: 0.5800049304962158
Validation loss: 2.1888579527537027

Epoch: 6| Step: 10
Training loss: 0.3843895196914673
Validation loss: 2.2607444326082864

Epoch: 6| Step: 11
Training loss: 0.3246406018733978
Validation loss: 2.245659132798513

Epoch: 6| Step: 12
Training loss: 0.7140101194381714
Validation loss: 2.25216551621755

Epoch: 6| Step: 13
Training loss: 0.7932696342468262
Validation loss: 2.2561320066452026

Epoch: 267| Step: 0
Training loss: 0.4258055090904236
Validation loss: 2.238326589266459

Epoch: 6| Step: 1
Training loss: 0.6164852380752563
Validation loss: 2.2192567189534507

Epoch: 6| Step: 2
Training loss: 0.5887975692749023
Validation loss: 2.2698822220166526

Epoch: 6| Step: 3
Training loss: 0.5414665341377258
Validation loss: 2.2647278110186257

Epoch: 6| Step: 4
Training loss: 0.7998323440551758
Validation loss: 2.2209600607554116

Epoch: 6| Step: 5
Training loss: 0.3444156050682068
Validation loss: 2.314259668191274

Epoch: 6| Step: 6
Training loss: 0.6238055229187012
Validation loss: 2.242901384830475

Epoch: 6| Step: 7
Training loss: 0.6524866819381714
Validation loss: 2.2440643906593323

Epoch: 6| Step: 8
Training loss: 0.5023757219314575
Validation loss: 2.2351578076680503

Epoch: 6| Step: 9
Training loss: 0.7456666231155396
Validation loss: 2.195230265458425

Epoch: 6| Step: 10
Training loss: 0.36933839321136475
Validation loss: 2.2556690176328025

Epoch: 6| Step: 11
Training loss: 0.6163334846496582
Validation loss: 2.225282688935598

Epoch: 6| Step: 12
Training loss: 0.5381385087966919
Validation loss: 2.198557138442993

Epoch: 6| Step: 13
Training loss: 0.6348137855529785
Validation loss: 2.24029948314031

Epoch: 268| Step: 0
Training loss: 0.4096831679344177
Validation loss: 2.196774701277415

Epoch: 6| Step: 1
Training loss: 0.6741815805435181
Validation loss: 2.213576296965281

Epoch: 6| Step: 2
Training loss: 0.3772639334201813
Validation loss: 2.2092096408208213

Epoch: 6| Step: 3
Training loss: 0.6050840616226196
Validation loss: 2.21708349386851

Epoch: 6| Step: 4
Training loss: 0.4376652240753174
Validation loss: 2.2559101978937783

Epoch: 6| Step: 5
Training loss: 0.4314577877521515
Validation loss: 2.226232131322225

Epoch: 6| Step: 6
Training loss: 0.8958167433738708
Validation loss: 2.284789224465688

Epoch: 6| Step: 7
Training loss: 0.4410253167152405
Validation loss: 2.2507616877555847

Epoch: 6| Step: 8
Training loss: 0.3693327307701111
Validation loss: 2.3072038491566977

Epoch: 6| Step: 9
Training loss: 0.28073859214782715
Validation loss: 2.2085273265838623

Epoch: 6| Step: 10
Training loss: 0.5737242698669434
Validation loss: 2.263439178466797

Epoch: 6| Step: 11
Training loss: 0.4713020324707031
Validation loss: 2.1684652964274087

Epoch: 6| Step: 12
Training loss: 0.9868017435073853
Validation loss: 2.19948140780131

Epoch: 6| Step: 13
Training loss: 0.8415506482124329
Validation loss: 2.190184473991394

Epoch: 269| Step: 0
Training loss: 0.7404999732971191
Validation loss: 2.192405859629313

Epoch: 6| Step: 1
Training loss: 0.40583938360214233
Validation loss: 2.2283135652542114

Epoch: 6| Step: 2
Training loss: 0.8185737133026123
Validation loss: 2.269686500231425

Epoch: 6| Step: 3
Training loss: 0.8491003513336182
Validation loss: 2.2429461081822715

Epoch: 6| Step: 4
Training loss: 0.27275052666664124
Validation loss: 2.321128765741984

Epoch: 6| Step: 5
Training loss: 0.5168610215187073
Validation loss: 2.293193260828654

Epoch: 6| Step: 6
Training loss: 0.42406654357910156
Validation loss: 2.266638934612274

Epoch: 6| Step: 7
Training loss: 0.5935928225517273
Validation loss: 2.2415784200032554

Epoch: 6| Step: 8
Training loss: 0.6349597573280334
Validation loss: 2.277351677417755

Epoch: 6| Step: 9
Training loss: 0.4178650379180908
Validation loss: 2.23630424340566

Epoch: 6| Step: 10
Training loss: 0.30154943466186523
Validation loss: 2.1847018599510193

Epoch: 6| Step: 11
Training loss: 0.7378437519073486
Validation loss: 2.168639620145162

Epoch: 6| Step: 12
Training loss: 0.5314366817474365
Validation loss: 2.2338701287905374

Epoch: 6| Step: 13
Training loss: 0.6589906811714172
Validation loss: 2.2110204100608826

Epoch: 270| Step: 0
Training loss: 0.5816830396652222
Validation loss: 2.2206401030222573

Epoch: 6| Step: 1
Training loss: 0.5065635442733765
Validation loss: 2.213052988052368

Epoch: 6| Step: 2
Training loss: 0.43444645404815674
Validation loss: 2.238192598025004

Epoch: 6| Step: 3
Training loss: 0.34824299812316895
Validation loss: 2.2475170890490213

Epoch: 6| Step: 4
Training loss: 0.6634646654129028
Validation loss: 2.2567100127538047

Epoch: 6| Step: 5
Training loss: 0.44544321298599243
Validation loss: 2.2336538235346475

Epoch: 6| Step: 6
Training loss: 0.9046893119812012
Validation loss: 2.2666833798090615

Epoch: 6| Step: 7
Training loss: 0.7694694995880127
Validation loss: 2.190224270025889

Epoch: 6| Step: 8
Training loss: 0.41065216064453125
Validation loss: 2.2492496967315674

Epoch: 6| Step: 9
Training loss: 0.39180171489715576
Validation loss: 2.236418684323629

Epoch: 6| Step: 10
Training loss: 0.6980546712875366
Validation loss: 2.2190999190012612

Epoch: 6| Step: 11
Training loss: 0.369430273771286
Validation loss: 2.2600799798965454

Epoch: 6| Step: 12
Training loss: 0.8483065366744995
Validation loss: 2.2413336833318076

Epoch: 6| Step: 13
Training loss: 0.9843195676803589
Validation loss: 2.247167448202769

Epoch: 271| Step: 0
Training loss: 0.3653399348258972
Validation loss: 2.1707301338513694

Epoch: 6| Step: 1
Training loss: 0.9002061486244202
Validation loss: 2.2842043042182922

Epoch: 6| Step: 2
Training loss: 0.7135990262031555
Validation loss: 2.2410558462142944

Epoch: 6| Step: 3
Training loss: 0.43205904960632324
Validation loss: 2.238466739654541

Epoch: 6| Step: 4
Training loss: 0.3282996416091919
Validation loss: 2.2044845620791116

Epoch: 6| Step: 5
Training loss: 0.8577646017074585
Validation loss: 2.1731350421905518

Epoch: 6| Step: 6
Training loss: 0.5668107867240906
Validation loss: 2.232549528280894

Epoch: 6| Step: 7
Training loss: 0.5556795001029968
Validation loss: 2.2507861653963723

Epoch: 6| Step: 8
Training loss: 0.7628647685050964
Validation loss: 2.2022066712379456

Epoch: 6| Step: 9
Training loss: 0.8223758339881897
Validation loss: 2.259105662504832

Epoch: 6| Step: 10
Training loss: 0.48249053955078125
Validation loss: 2.200399180253347

Epoch: 6| Step: 11
Training loss: 0.4070720970630646
Validation loss: 2.2508710622787476

Epoch: 6| Step: 12
Training loss: 0.3663398325443268
Validation loss: 2.2280847430229187

Epoch: 6| Step: 13
Training loss: 0.47090038657188416
Validation loss: 2.2140090266863504

Epoch: 272| Step: 0
Training loss: 0.8911240696907043
Validation loss: 2.224958062171936

Epoch: 6| Step: 1
Training loss: 0.2793537378311157
Validation loss: 2.2103394865989685

Epoch: 6| Step: 2
Training loss: 0.5876645445823669
Validation loss: 2.231614073117574

Epoch: 6| Step: 3
Training loss: 0.7628644704818726
Validation loss: 2.253544549147288

Epoch: 6| Step: 4
Training loss: 0.40219610929489136
Validation loss: 2.2804155151049295

Epoch: 6| Step: 5
Training loss: 1.0376789569854736
Validation loss: 2.2560841838518777

Epoch: 6| Step: 6
Training loss: 0.29175204038619995
Validation loss: 2.1857518355051675

Epoch: 6| Step: 7
Training loss: 0.34445828199386597
Validation loss: 2.2418996890385947

Epoch: 6| Step: 8
Training loss: 0.3882638216018677
Validation loss: 2.2375354369481406

Epoch: 6| Step: 9
Training loss: 0.3537672758102417
Validation loss: 2.2251651088396707

Epoch: 6| Step: 10
Training loss: 0.5666143894195557
Validation loss: 2.2319175799687705

Epoch: 6| Step: 11
Training loss: 0.35501307249069214
Validation loss: 2.227888266245524

Epoch: 6| Step: 12
Training loss: 0.30732572078704834
Validation loss: 2.2685694297154746

Epoch: 6| Step: 13
Training loss: 0.6675150394439697
Validation loss: 2.2353474299112954

Epoch: 273| Step: 0
Training loss: 0.76362144947052
Validation loss: 2.2491323153177896

Epoch: 6| Step: 1
Training loss: 0.38945913314819336
Validation loss: 2.2395584980646768

Epoch: 6| Step: 2
Training loss: 0.2704172730445862
Validation loss: 2.2470924854278564

Epoch: 6| Step: 3
Training loss: 0.47854259610176086
Validation loss: 2.2733121713002524

Epoch: 6| Step: 4
Training loss: 0.6105668544769287
Validation loss: 2.246648907661438

Epoch: 6| Step: 5
Training loss: 0.7387363314628601
Validation loss: 2.280717412630717

Epoch: 6| Step: 6
Training loss: 0.6868187785148621
Validation loss: 2.235136012236277

Epoch: 6| Step: 7
Training loss: 0.5956383943557739
Validation loss: 2.2691862185796103

Epoch: 6| Step: 8
Training loss: 0.7810964584350586
Validation loss: 2.23559033870697

Epoch: 6| Step: 9
Training loss: 0.5779542922973633
Validation loss: 2.235660135746002

Epoch: 6| Step: 10
Training loss: 0.4974133372306824
Validation loss: 2.2155874967575073

Epoch: 6| Step: 11
Training loss: 0.4168325662612915
Validation loss: 2.221339523792267

Epoch: 6| Step: 12
Training loss: 0.23278945684432983
Validation loss: 2.258650779724121

Epoch: 6| Step: 13
Training loss: 0.42285171151161194
Validation loss: 2.209498167037964

Epoch: 274| Step: 0
Training loss: 0.23947352170944214
Validation loss: 2.222877621650696

Epoch: 6| Step: 1
Training loss: 0.7146521806716919
Validation loss: 2.2481419245402017

Epoch: 6| Step: 2
Training loss: 0.32697370648384094
Validation loss: 2.2367579142252603

Epoch: 6| Step: 3
Training loss: 0.34624794125556946
Validation loss: 2.2016056776046753

Epoch: 6| Step: 4
Training loss: 0.6375967860221863
Validation loss: 2.2307974894841514

Epoch: 6| Step: 5
Training loss: 0.6883782744407654
Validation loss: 2.249430457750956

Epoch: 6| Step: 6
Training loss: 0.3814776837825775
Validation loss: 2.2396169702212014

Epoch: 6| Step: 7
Training loss: 0.5360326170921326
Validation loss: 2.1930012702941895

Epoch: 6| Step: 8
Training loss: 0.3590773940086365
Validation loss: 2.252844055493673

Epoch: 6| Step: 9
Training loss: 0.837283194065094
Validation loss: 2.2029064496358237

Epoch: 6| Step: 10
Training loss: 0.389015793800354
Validation loss: 2.245434522628784

Epoch: 6| Step: 11
Training loss: 0.5424667000770569
Validation loss: 2.2737722992897034

Epoch: 6| Step: 12
Training loss: 1.164150357246399
Validation loss: 2.23431388537089

Epoch: 6| Step: 13
Training loss: 0.2748458981513977
Validation loss: 2.256399989128113

Epoch: 275| Step: 0
Training loss: 0.5853098034858704
Validation loss: 2.187494456768036

Epoch: 6| Step: 1
Training loss: 0.3980832099914551
Validation loss: 2.221842130025228

Epoch: 6| Step: 2
Training loss: 0.4105180501937866
Validation loss: 2.2743153969446817

Epoch: 6| Step: 3
Training loss: 0.32092756032943726
Validation loss: 2.229603926340739

Epoch: 6| Step: 4
Training loss: 1.2986807823181152
Validation loss: 2.2430601914723716

Epoch: 6| Step: 5
Training loss: 0.6516667604446411
Validation loss: 2.2153635223706565

Epoch: 6| Step: 6
Training loss: 0.5707297325134277
Validation loss: 2.2343531449635825

Epoch: 6| Step: 7
Training loss: 0.5228599905967712
Validation loss: 2.238804519176483

Epoch: 6| Step: 8
Training loss: 0.4036692976951599
Validation loss: 2.243887106577555

Epoch: 6| Step: 9
Training loss: 0.6258712410926819
Validation loss: 2.2430079579353333

Epoch: 6| Step: 10
Training loss: 0.41434842348098755
Validation loss: 2.265215039253235

Epoch: 6| Step: 11
Training loss: 0.4285264313220978
Validation loss: 2.2520041267077127

Epoch: 6| Step: 12
Training loss: 0.6144164204597473
Validation loss: 2.219649374485016

Epoch: 6| Step: 13
Training loss: 0.5244718790054321
Validation loss: 2.2707324028015137

Epoch: 276| Step: 0
Training loss: 0.45671069622039795
Validation loss: 2.260912994543711

Epoch: 6| Step: 1
Training loss: 0.46243947744369507
Validation loss: 2.296208083629608

Epoch: 6| Step: 2
Training loss: 0.4774060547351837
Validation loss: 2.2500463326772056

Epoch: 6| Step: 3
Training loss: 0.29440611600875854
Validation loss: 2.2214184204737344

Epoch: 6| Step: 4
Training loss: 0.5458493232727051
Validation loss: 2.240294019381205

Epoch: 6| Step: 5
Training loss: 0.5755079388618469
Validation loss: 2.2156869967778525

Epoch: 6| Step: 6
Training loss: 0.4004201889038086
Validation loss: 2.212353845437368

Epoch: 6| Step: 7
Training loss: 1.6409294605255127
Validation loss: 2.245377779006958

Epoch: 6| Step: 8
Training loss: 0.5529788732528687
Validation loss: 2.247671981652578

Epoch: 6| Step: 9
Training loss: 0.2588439881801605
Validation loss: 2.2338438828786216

Epoch: 6| Step: 10
Training loss: 0.38824212551116943
Validation loss: 2.252344290415446

Epoch: 6| Step: 11
Training loss: 0.36940181255340576
Validation loss: 2.232960522174835

Epoch: 6| Step: 12
Training loss: 0.35509350895881653
Validation loss: 2.26541397968928

Epoch: 6| Step: 13
Training loss: 0.7825545072555542
Validation loss: 2.2453633348147073

Epoch: 277| Step: 0
Training loss: 0.26347213983535767
Validation loss: 2.212457815806071

Epoch: 6| Step: 1
Training loss: 0.9284855127334595
Validation loss: 2.2547033429145813

Epoch: 6| Step: 2
Training loss: 0.2861268222332001
Validation loss: 2.2637588580449424

Epoch: 6| Step: 3
Training loss: 0.7518807649612427
Validation loss: 2.248519559701284

Epoch: 6| Step: 4
Training loss: 0.502082109451294
Validation loss: 2.250102619330088

Epoch: 6| Step: 5
Training loss: 0.3600100874900818
Validation loss: 2.2385364770889282

Epoch: 6| Step: 6
Training loss: 0.7946429252624512
Validation loss: 2.2451757987340293

Epoch: 6| Step: 7
Training loss: 0.566430926322937
Validation loss: 2.2639598846435547

Epoch: 6| Step: 8
Training loss: 0.6105753183364868
Validation loss: 2.276074012120565

Epoch: 6| Step: 9
Training loss: 0.41842544078826904
Validation loss: 2.2377771536509194

Epoch: 6| Step: 10
Training loss: 0.42197710275650024
Validation loss: 2.252616027990977

Epoch: 6| Step: 11
Training loss: 0.5746379494667053
Validation loss: 2.278882066408793

Epoch: 6| Step: 12
Training loss: 0.30658385157585144
Validation loss: 2.243053396542867

Epoch: 6| Step: 13
Training loss: 0.44893908500671387
Validation loss: 2.179966390132904

Epoch: 278| Step: 0
Training loss: 0.5791093707084656
Validation loss: 2.2579187750816345

Epoch: 6| Step: 1
Training loss: 0.7569112181663513
Validation loss: 2.164812525113424

Epoch: 6| Step: 2
Training loss: 0.45820456743240356
Validation loss: 2.2361889084180198

Epoch: 6| Step: 3
Training loss: 0.3791319727897644
Validation loss: 2.2967917919158936

Epoch: 6| Step: 4
Training loss: 1.39884352684021
Validation loss: 2.2740174531936646

Epoch: 6| Step: 5
Training loss: 0.19414982199668884
Validation loss: 2.213763336340586

Epoch: 6| Step: 6
Training loss: 0.32695111632347107
Validation loss: 2.2556273341178894

Epoch: 6| Step: 7
Training loss: 0.36899274587631226
Validation loss: 2.2020045121510825

Epoch: 6| Step: 8
Training loss: 0.6043763160705566
Validation loss: 2.306568702061971

Epoch: 6| Step: 9
Training loss: 0.823258638381958
Validation loss: 2.212209145228068

Epoch: 6| Step: 10
Training loss: 0.5446362495422363
Validation loss: 2.235329747200012

Epoch: 6| Step: 11
Training loss: 0.44091084599494934
Validation loss: 2.2468366225560508

Epoch: 6| Step: 12
Training loss: 0.3085566759109497
Validation loss: 2.2180492281913757

Epoch: 6| Step: 13
Training loss: 0.7670184969902039
Validation loss: 2.1910186608632407

Epoch: 279| Step: 0
Training loss: 0.3230079412460327
Validation loss: 2.207981844743093

Epoch: 6| Step: 1
Training loss: 0.7679167985916138
Validation loss: 2.2529136339823403

Epoch: 6| Step: 2
Training loss: 0.5114416480064392
Validation loss: 2.218905965487162

Epoch: 6| Step: 3
Training loss: 0.6488903164863586
Validation loss: 2.203692634900411

Epoch: 6| Step: 4
Training loss: 0.30481088161468506
Validation loss: 2.2255139350891113

Epoch: 6| Step: 5
Training loss: 1.0510973930358887
Validation loss: 2.219594120979309

Epoch: 6| Step: 6
Training loss: 0.6347829103469849
Validation loss: 2.2648551066716514

Epoch: 6| Step: 7
Training loss: 0.6757663488388062
Validation loss: 2.210035483042399

Epoch: 6| Step: 8
Training loss: 0.597381591796875
Validation loss: 2.245617091655731

Epoch: 6| Step: 9
Training loss: 0.49491870403289795
Validation loss: 2.2639966011047363

Epoch: 6| Step: 10
Training loss: 0.5238263010978699
Validation loss: 2.2229956785837808

Epoch: 6| Step: 11
Training loss: 0.8126621246337891
Validation loss: 2.217586080233256

Epoch: 6| Step: 12
Training loss: 0.2076444923877716
Validation loss: 2.2452858289082847

Epoch: 6| Step: 13
Training loss: 0.8266972303390503
Validation loss: 2.2242769400278726

Epoch: 280| Step: 0
Training loss: 0.9040946960449219
Validation loss: 2.192549447218577

Epoch: 6| Step: 1
Training loss: 0.5060248374938965
Validation loss: 2.2796008586883545

Epoch: 6| Step: 2
Training loss: 0.39548230171203613
Validation loss: 2.2382322947184243

Epoch: 6| Step: 3
Training loss: 0.2603107690811157
Validation loss: 2.1579501827557883

Epoch: 6| Step: 4
Training loss: 0.7896630167961121
Validation loss: 2.224846124649048

Epoch: 6| Step: 5
Training loss: 0.3815322518348694
Validation loss: 2.255576193332672

Epoch: 6| Step: 6
Training loss: 0.804107666015625
Validation loss: 2.224072496096293

Epoch: 6| Step: 7
Training loss: 0.8166463375091553
Validation loss: 2.2019833525021872

Epoch: 6| Step: 8
Training loss: 0.469225138425827
Validation loss: 2.221844514211019

Epoch: 6| Step: 9
Training loss: 0.5376827120780945
Validation loss: 2.2454957962036133

Epoch: 6| Step: 10
Training loss: 0.6722372174263
Validation loss: 2.266579786936442

Epoch: 6| Step: 11
Training loss: 0.2336340695619583
Validation loss: 2.2265979051589966

Epoch: 6| Step: 12
Training loss: 0.31661680340766907
Validation loss: 2.2128566900889077

Epoch: 6| Step: 13
Training loss: 0.3391563892364502
Validation loss: 2.2008774280548096

Epoch: 281| Step: 0
Training loss: 0.3154327869415283
Validation loss: 2.230408867200216

Epoch: 6| Step: 1
Training loss: 0.22993037104606628
Validation loss: 2.224196453889211

Epoch: 6| Step: 2
Training loss: 0.25618723034858704
Validation loss: 2.2428722977638245

Epoch: 6| Step: 3
Training loss: 0.2463982254266739
Validation loss: 2.245307286580404

Epoch: 6| Step: 4
Training loss: 0.364972323179245
Validation loss: 2.2623799244562783

Epoch: 6| Step: 5
Training loss: 0.5393873453140259
Validation loss: 2.1999060114224753

Epoch: 6| Step: 6
Training loss: 0.9625104665756226
Validation loss: 2.3024532993634543

Epoch: 6| Step: 7
Training loss: 0.31695300340652466
Validation loss: 2.2655857602755227

Epoch: 6| Step: 8
Training loss: 0.7381681203842163
Validation loss: 2.252569397290548

Epoch: 6| Step: 9
Training loss: 0.8591810464859009
Validation loss: 2.2764296332995095

Epoch: 6| Step: 10
Training loss: 0.40869763493537903
Validation loss: 2.2763471007347107

Epoch: 6| Step: 11
Training loss: 0.7319064140319824
Validation loss: 2.2458424965540567

Epoch: 6| Step: 12
Training loss: 0.7411674857139587
Validation loss: 2.286457816759745

Epoch: 6| Step: 13
Training loss: 0.3041500449180603
Validation loss: 2.2508070270220437

Epoch: 282| Step: 0
Training loss: 0.6651229858398438
Validation loss: 2.256812791029612

Epoch: 6| Step: 1
Training loss: 0.5630680918693542
Validation loss: 2.224646965662638

Epoch: 6| Step: 2
Training loss: 0.5033285617828369
Validation loss: 2.262360175450643

Epoch: 6| Step: 3
Training loss: 0.5119650959968567
Validation loss: 2.2653689781824746

Epoch: 6| Step: 4
Training loss: 0.5589818954467773
Validation loss: 2.2354439894358316

Epoch: 6| Step: 5
Training loss: 0.4431875944137573
Validation loss: 2.2540772755940757

Epoch: 6| Step: 6
Training loss: 0.600906491279602
Validation loss: 2.2203386227289834

Epoch: 6| Step: 7
Training loss: 0.3634391129016876
Validation loss: 2.203214168548584

Epoch: 6| Step: 8
Training loss: 0.4398241937160492
Validation loss: 2.2573535442352295

Epoch: 6| Step: 9
Training loss: 0.6640338897705078
Validation loss: 2.2362729708353677

Epoch: 6| Step: 10
Training loss: 0.367742657661438
Validation loss: 2.218786080678304

Epoch: 6| Step: 11
Training loss: 0.3625389337539673
Validation loss: 2.2733673652013144

Epoch: 6| Step: 12
Training loss: 0.3360603451728821
Validation loss: 2.2355169455210366

Epoch: 6| Step: 13
Training loss: 0.9742308855056763
Validation loss: 2.283877889315287

Epoch: 283| Step: 0
Training loss: 0.4789391756057739
Validation loss: 2.2482810020446777

Epoch: 6| Step: 1
Training loss: 0.45526695251464844
Validation loss: 2.2846169074376426

Epoch: 6| Step: 2
Training loss: 0.35069578886032104
Validation loss: 2.2683499455451965

Epoch: 6| Step: 3
Training loss: 0.5560178756713867
Validation loss: 2.2315471172332764

Epoch: 6| Step: 4
Training loss: 0.3327556848526001
Validation loss: 2.234557628631592

Epoch: 6| Step: 5
Training loss: 0.3717278242111206
Validation loss: 2.25920977195104

Epoch: 6| Step: 6
Training loss: 0.649009644985199
Validation loss: 2.245649735132853

Epoch: 6| Step: 7
Training loss: 0.8142009973526001
Validation loss: 2.286102016766866

Epoch: 6| Step: 8
Training loss: 0.4771224558353424
Validation loss: 2.2941604256629944

Epoch: 6| Step: 9
Training loss: 0.26679348945617676
Validation loss: 2.281262735525767

Epoch: 6| Step: 10
Training loss: 0.6813386678695679
Validation loss: 2.302930772304535

Epoch: 6| Step: 11
Training loss: 0.4010714888572693
Validation loss: 2.260615348815918

Epoch: 6| Step: 12
Training loss: 1.0157536268234253
Validation loss: 2.273220340410868

Epoch: 6| Step: 13
Training loss: 0.3811047673225403
Validation loss: 2.2268778681755066

Epoch: 284| Step: 0
Training loss: 0.5709018111228943
Validation loss: 2.2816425363222756

Epoch: 6| Step: 1
Training loss: 0.8854637742042542
Validation loss: 2.269720216592153

Epoch: 6| Step: 2
Training loss: 0.3832302391529083
Validation loss: 2.156572639942169

Epoch: 6| Step: 3
Training loss: 0.3111160695552826
Validation loss: 2.2860654989878335

Epoch: 6| Step: 4
Training loss: 0.5928896069526672
Validation loss: 2.220234433809916

Epoch: 6| Step: 5
Training loss: 0.2766713500022888
Validation loss: 2.2431411941846213

Epoch: 6| Step: 6
Training loss: 0.33197203278541565
Validation loss: 2.2104218006134033

Epoch: 6| Step: 7
Training loss: 0.354877233505249
Validation loss: 2.2428767879803977

Epoch: 6| Step: 8
Training loss: 0.39770928025245667
Validation loss: 2.239695727825165

Epoch: 6| Step: 9
Training loss: 0.7382054924964905
Validation loss: 2.2338896791140237

Epoch: 6| Step: 10
Training loss: 0.2331407070159912
Validation loss: 2.266864021619161

Epoch: 6| Step: 11
Training loss: 0.549647867679596
Validation loss: 2.2557830810546875

Epoch: 6| Step: 12
Training loss: 0.5030087828636169
Validation loss: 2.2274253368377686

Epoch: 6| Step: 13
Training loss: 0.8850317001342773
Validation loss: 2.2542323668797812

Epoch: 285| Step: 0
Training loss: 0.35362985730171204
Validation loss: 2.271557867527008

Epoch: 6| Step: 1
Training loss: 0.40870779752731323
Validation loss: 2.2261151870091758

Epoch: 6| Step: 2
Training loss: 0.25987371802330017
Validation loss: 2.2453359166781106

Epoch: 6| Step: 3
Training loss: 0.6249263882637024
Validation loss: 2.266913672288259

Epoch: 6| Step: 4
Training loss: 0.3044542372226715
Validation loss: 2.275792141755422

Epoch: 6| Step: 5
Training loss: 0.3538975119590759
Validation loss: 2.224131425221761

Epoch: 6| Step: 6
Training loss: 0.48719459772109985
Validation loss: 2.210689584414164

Epoch: 6| Step: 7
Training loss: 0.6732900142669678
Validation loss: 2.3036503195762634

Epoch: 6| Step: 8
Training loss: 0.7989205121994019
Validation loss: 2.1963045994440713

Epoch: 6| Step: 9
Training loss: 0.5492802858352661
Validation loss: 2.246275842189789

Epoch: 6| Step: 10
Training loss: 0.6121832132339478
Validation loss: 2.2190601229667664

Epoch: 6| Step: 11
Training loss: 0.7036559581756592
Validation loss: 2.250322381655375

Epoch: 6| Step: 12
Training loss: 0.40580326318740845
Validation loss: 2.254422684510549

Epoch: 6| Step: 13
Training loss: 0.3744364380836487
Validation loss: 2.292605996131897

Epoch: 286| Step: 0
Training loss: 0.2911342978477478
Validation loss: 2.275656759738922

Epoch: 6| Step: 1
Training loss: 0.4370662569999695
Validation loss: 2.247848868370056

Epoch: 6| Step: 2
Training loss: 1.083160638809204
Validation loss: 2.244801938533783

Epoch: 6| Step: 3
Training loss: 0.3907141089439392
Validation loss: 2.284516533215841

Epoch: 6| Step: 4
Training loss: 0.3169558644294739
Validation loss: 2.242326279481252

Epoch: 6| Step: 5
Training loss: 0.7595778107643127
Validation loss: 2.252195398012797

Epoch: 6| Step: 6
Training loss: 0.9691452980041504
Validation loss: 2.2628842194875083

Epoch: 6| Step: 7
Training loss: 0.2892090678215027
Validation loss: 2.2643909056981406

Epoch: 6| Step: 8
Training loss: 0.22457651793956757
Validation loss: 2.2639926870663962

Epoch: 6| Step: 9
Training loss: 0.5231346487998962
Validation loss: 2.2261851827303567

Epoch: 6| Step: 10
Training loss: 0.2455836534500122
Validation loss: 2.2363646825154624

Epoch: 6| Step: 11
Training loss: 0.3395105004310608
Validation loss: 2.2920747995376587

Epoch: 6| Step: 12
Training loss: 0.6921639442443848
Validation loss: 2.2608938415845237

Epoch: 6| Step: 13
Training loss: 0.32609182596206665
Validation loss: 2.233468691507975

Epoch: 287| Step: 0
Training loss: 0.25484588742256165
Validation loss: 2.21682737270991

Epoch: 6| Step: 1
Training loss: 0.4681638777256012
Validation loss: 2.2467507322629294

Epoch: 6| Step: 2
Training loss: 0.5914962291717529
Validation loss: 2.2502392133076987

Epoch: 6| Step: 3
Training loss: 0.50830078125
Validation loss: 2.2062352895736694

Epoch: 6| Step: 4
Training loss: 0.4975476861000061
Validation loss: 2.1950198213259378

Epoch: 6| Step: 5
Training loss: 0.354993999004364
Validation loss: 2.2561120986938477

Epoch: 6| Step: 6
Training loss: 0.6963258981704712
Validation loss: 2.245300849278768

Epoch: 6| Step: 7
Training loss: 0.6869979500770569
Validation loss: 2.2333643436431885

Epoch: 6| Step: 8
Training loss: 0.5044859647750854
Validation loss: 2.250939945379893

Epoch: 6| Step: 9
Training loss: 0.21700343489646912
Validation loss: 2.2312245766321817

Epoch: 6| Step: 10
Training loss: 0.654094398021698
Validation loss: 2.202147126197815

Epoch: 6| Step: 11
Training loss: 0.39631107449531555
Validation loss: 2.227754314740499

Epoch: 6| Step: 12
Training loss: 0.3845991790294647
Validation loss: 2.2427114049593606

Epoch: 6| Step: 13
Training loss: 0.8388553857803345
Validation loss: 2.2744097908337912

Epoch: 288| Step: 0
Training loss: 0.29336845874786377
Validation loss: 2.219307065010071

Epoch: 6| Step: 1
Training loss: 0.42915260791778564
Validation loss: 2.2451442877451577

Epoch: 6| Step: 2
Training loss: 0.6143041849136353
Validation loss: 2.234542270501455

Epoch: 6| Step: 3
Training loss: 0.39604461193084717
Validation loss: 2.243590076764425

Epoch: 6| Step: 4
Training loss: 0.40515172481536865
Validation loss: 2.255119959513346

Epoch: 6| Step: 5
Training loss: 0.6053034067153931
Validation loss: 2.2296657164891562

Epoch: 6| Step: 6
Training loss: 0.701472818851471
Validation loss: 2.252838611602783

Epoch: 6| Step: 7
Training loss: 0.5973904728889465
Validation loss: 2.197705566883087

Epoch: 6| Step: 8
Training loss: 0.8912419080734253
Validation loss: 2.276986539363861

Epoch: 6| Step: 9
Training loss: 0.3076028525829315
Validation loss: 2.2694589495658875

Epoch: 6| Step: 10
Training loss: 0.8281590938568115
Validation loss: 2.2657846808433533

Epoch: 6| Step: 11
Training loss: 0.5600253343582153
Validation loss: 2.2028763691584268

Epoch: 6| Step: 12
Training loss: 0.8398029804229736
Validation loss: 2.2293726205825806

Epoch: 6| Step: 13
Training loss: 0.4484117031097412
Validation loss: 2.244213024775187

Epoch: 289| Step: 0
Training loss: 0.4142036437988281
Validation loss: 2.2552815278371177

Epoch: 6| Step: 1
Training loss: 0.7475513219833374
Validation loss: 2.2348885536193848

Epoch: 6| Step: 2
Training loss: 0.44030630588531494
Validation loss: 2.2141961256663003

Epoch: 6| Step: 3
Training loss: 0.6496237516403198
Validation loss: 2.2876466313997903

Epoch: 6| Step: 4
Training loss: 0.7184332013130188
Validation loss: 2.2937582532564798

Epoch: 6| Step: 5
Training loss: 0.43888723850250244
Validation loss: 2.262196103731791

Epoch: 6| Step: 6
Training loss: 0.3743872046470642
Validation loss: 2.218228896458944

Epoch: 6| Step: 7
Training loss: 0.581999659538269
Validation loss: 2.21941069761912

Epoch: 6| Step: 8
Training loss: 0.3066791892051697
Validation loss: 2.222389300664266

Epoch: 6| Step: 9
Training loss: 0.43564146757125854
Validation loss: 2.2376354932785034

Epoch: 6| Step: 10
Training loss: 0.3227832317352295
Validation loss: 2.188220262527466

Epoch: 6| Step: 11
Training loss: 0.6280108094215393
Validation loss: 2.3355822364489236

Epoch: 6| Step: 12
Training loss: 0.7980818748474121
Validation loss: 2.281892498334249

Epoch: 6| Step: 13
Training loss: 0.5432899594306946
Validation loss: 2.2562785347302756

Epoch: 290| Step: 0
Training loss: 0.7276313304901123
Validation loss: 2.2347720861434937

Epoch: 6| Step: 1
Training loss: 0.6295417547225952
Validation loss: 2.279056111971537

Epoch: 6| Step: 2
Training loss: 0.4313960373401642
Validation loss: 2.269698659578959

Epoch: 6| Step: 3
Training loss: 0.5630328059196472
Validation loss: 2.2776456276575723

Epoch: 6| Step: 4
Training loss: 0.35422956943511963
Validation loss: 2.2433167695999146

Epoch: 6| Step: 5
Training loss: 0.6709882020950317
Validation loss: 2.2408005197842917

Epoch: 6| Step: 6
Training loss: 0.3188821077346802
Validation loss: 2.2669564286867776

Epoch: 6| Step: 7
Training loss: 0.44704195857048035
Validation loss: 2.25612872838974

Epoch: 6| Step: 8
Training loss: 0.7679380178451538
Validation loss: 2.235206206639608

Epoch: 6| Step: 9
Training loss: 0.6271483898162842
Validation loss: 2.2398074666659036

Epoch: 6| Step: 10
Training loss: 0.6222385764122009
Validation loss: 2.2253955403963723

Epoch: 6| Step: 11
Training loss: 0.3728914260864258
Validation loss: 2.230823596318563

Epoch: 6| Step: 12
Training loss: 0.5187959671020508
Validation loss: 2.188959777355194

Epoch: 6| Step: 13
Training loss: 0.2576832175254822
Validation loss: 2.318860431512197

Epoch: 291| Step: 0
Training loss: 0.27011722326278687
Validation loss: 2.256753126780192

Epoch: 6| Step: 1
Training loss: 0.2665037512779236
Validation loss: 2.223401447137197

Epoch: 6| Step: 2
Training loss: 0.3119282126426697
Validation loss: 2.2484187682469687

Epoch: 6| Step: 3
Training loss: 0.4153372347354889
Validation loss: 2.3737713098526

Epoch: 6| Step: 4
Training loss: 0.3278162479400635
Validation loss: 2.2640404303868613

Epoch: 6| Step: 5
Training loss: 0.7828120589256287
Validation loss: 2.2079116702079773

Epoch: 6| Step: 6
Training loss: 0.4437330961227417
Validation loss: 2.280331790447235

Epoch: 6| Step: 7
Training loss: 0.38582515716552734
Validation loss: 2.219176928202311

Epoch: 6| Step: 8
Training loss: 0.8246914148330688
Validation loss: 2.268905242284139

Epoch: 6| Step: 9
Training loss: 0.3074871897697449
Validation loss: 2.295488397280375

Epoch: 6| Step: 10
Training loss: 0.29615578055381775
Validation loss: 2.2803028424580893

Epoch: 6| Step: 11
Training loss: 0.6448301076889038
Validation loss: 2.248331864674886

Epoch: 6| Step: 12
Training loss: 0.5499677658081055
Validation loss: 2.238207777341207

Epoch: 6| Step: 13
Training loss: 0.8627798557281494
Validation loss: 2.218746781349182

Epoch: 292| Step: 0
Training loss: 0.49665936827659607
Validation loss: 2.258323629697164

Epoch: 6| Step: 1
Training loss: 0.5659722685813904
Validation loss: 2.240246295928955

Epoch: 6| Step: 2
Training loss: 0.4954083561897278
Validation loss: 2.236212690671285

Epoch: 6| Step: 3
Training loss: 0.5411739349365234
Validation loss: 2.231878320376078

Epoch: 6| Step: 4
Training loss: 0.3278195858001709
Validation loss: 2.2412564158439636

Epoch: 6| Step: 5
Training loss: 0.26934120059013367
Validation loss: 2.2330838243166604

Epoch: 6| Step: 6
Training loss: 0.3265644907951355
Validation loss: 2.2677798668543496

Epoch: 6| Step: 7
Training loss: 0.5871753692626953
Validation loss: 2.2829209566116333

Epoch: 6| Step: 8
Training loss: 0.4216284155845642
Validation loss: 2.3309377630551658

Epoch: 6| Step: 9
Training loss: 0.5529997944831848
Validation loss: 2.2766040166219077

Epoch: 6| Step: 10
Training loss: 0.498069167137146
Validation loss: 2.274745543797811

Epoch: 6| Step: 11
Training loss: 0.7833393812179565
Validation loss: 2.182469348112742

Epoch: 6| Step: 12
Training loss: 0.7889432907104492
Validation loss: 2.186702092488607

Epoch: 6| Step: 13
Training loss: 0.507896363735199
Validation loss: 2.2816349466641745

Epoch: 293| Step: 0
Training loss: 0.42408815026283264
Validation loss: 2.2349780400594077

Epoch: 6| Step: 1
Training loss: 0.48358404636383057
Validation loss: 2.2375530004501343

Epoch: 6| Step: 2
Training loss: 0.2823810279369354
Validation loss: 2.208583136399587

Epoch: 6| Step: 3
Training loss: 0.7234033346176147
Validation loss: 2.2784119645754495

Epoch: 6| Step: 4
Training loss: 0.2534482479095459
Validation loss: 2.2031091451644897

Epoch: 6| Step: 5
Training loss: 0.42491891980171204
Validation loss: 2.265377640724182

Epoch: 6| Step: 6
Training loss: 0.5997505187988281
Validation loss: 2.2815295457839966

Epoch: 6| Step: 7
Training loss: 0.2950190603733063
Validation loss: 2.2642560402552285

Epoch: 6| Step: 8
Training loss: 0.2215774953365326
Validation loss: 2.193647841612498

Epoch: 6| Step: 9
Training loss: 0.7502309083938599
Validation loss: 2.253215471903483

Epoch: 6| Step: 10
Training loss: 0.38091379404067993
Validation loss: 2.2581464846928916

Epoch: 6| Step: 11
Training loss: 0.7946059703826904
Validation loss: 2.2630701661109924

Epoch: 6| Step: 12
Training loss: 0.5844652652740479
Validation loss: 2.2688010931015015

Epoch: 6| Step: 13
Training loss: 0.5059691667556763
Validation loss: 2.2851526141166687

Epoch: 294| Step: 0
Training loss: 0.3334037661552429
Validation loss: 2.2322293718655906

Epoch: 6| Step: 1
Training loss: 0.6146841049194336
Validation loss: 2.2788117130597434

Epoch: 6| Step: 2
Training loss: 0.6536581516265869
Validation loss: 2.182591696580251

Epoch: 6| Step: 3
Training loss: 0.6999062895774841
Validation loss: 2.25675368309021

Epoch: 6| Step: 4
Training loss: 0.44053006172180176
Validation loss: 2.2840556502342224

Epoch: 6| Step: 5
Training loss: 0.28162482380867004
Validation loss: 2.264189124107361

Epoch: 6| Step: 6
Training loss: 0.4228200316429138
Validation loss: 2.2201577027638755

Epoch: 6| Step: 7
Training loss: 0.6684838533401489
Validation loss: 2.2594009240468345

Epoch: 6| Step: 8
Training loss: 0.3167690634727478
Validation loss: 2.2659830252329507

Epoch: 6| Step: 9
Training loss: 0.3789142370223999
Validation loss: 2.247095783551534

Epoch: 6| Step: 10
Training loss: 0.7592898607254028
Validation loss: 2.2261144717534385

Epoch: 6| Step: 11
Training loss: 0.2706371247768402
Validation loss: 2.2340861360232034

Epoch: 6| Step: 12
Training loss: 0.3721884489059448
Validation loss: 2.2968823313713074

Epoch: 6| Step: 13
Training loss: 0.7314486503601074
Validation loss: 2.2372039357821145

Epoch: 295| Step: 0
Training loss: 0.3559620678424835
Validation loss: 2.2489304741223655

Epoch: 6| Step: 1
Training loss: 0.6528087854385376
Validation loss: 2.259929895401001

Epoch: 6| Step: 2
Training loss: 0.5595192909240723
Validation loss: 2.274508019288381

Epoch: 6| Step: 3
Training loss: 0.47063612937927246
Validation loss: 2.2069522937138877

Epoch: 6| Step: 4
Training loss: 0.3355555534362793
Validation loss: 2.2681990265846252

Epoch: 6| Step: 5
Training loss: 0.24944497644901276
Validation loss: 2.223004400730133

Epoch: 6| Step: 6
Training loss: 0.44408997893333435
Validation loss: 2.2419946591059365

Epoch: 6| Step: 7
Training loss: 0.5561749935150146
Validation loss: 2.2766012946764627

Epoch: 6| Step: 8
Training loss: 0.619196891784668
Validation loss: 2.2462963263193765

Epoch: 6| Step: 9
Training loss: 0.3810005187988281
Validation loss: 2.243957241376241

Epoch: 6| Step: 10
Training loss: 0.2969219386577606
Validation loss: 2.2545685370763144

Epoch: 6| Step: 11
Training loss: 0.5748491287231445
Validation loss: 2.30585108200709

Epoch: 6| Step: 12
Training loss: 0.5916470289230347
Validation loss: 2.314235210418701

Epoch: 6| Step: 13
Training loss: 0.7216155529022217
Validation loss: 2.2830307483673096

Epoch: 296| Step: 0
Training loss: 0.6843599081039429
Validation loss: 2.2602630853652954

Epoch: 6| Step: 1
Training loss: 0.7207233905792236
Validation loss: 2.287837028503418

Epoch: 6| Step: 2
Training loss: 0.2846639156341553
Validation loss: 2.294307291507721

Epoch: 6| Step: 3
Training loss: 0.33052921295166016
Validation loss: 2.238437751928965

Epoch: 6| Step: 4
Training loss: 0.3714369535446167
Validation loss: 2.2988977432250977

Epoch: 6| Step: 5
Training loss: 0.5447877645492554
Validation loss: 2.2880773544311523

Epoch: 6| Step: 6
Training loss: 0.6472048163414001
Validation loss: 2.306816577911377

Epoch: 6| Step: 7
Training loss: 0.7218230366706848
Validation loss: 2.274582842985789

Epoch: 6| Step: 8
Training loss: 0.7510004043579102
Validation loss: 2.2741373578707376

Epoch: 6| Step: 9
Training loss: 0.5152280330657959
Validation loss: 2.2407801151275635

Epoch: 6| Step: 10
Training loss: 0.25396767258644104
Validation loss: 2.266266961892446

Epoch: 6| Step: 11
Training loss: 0.6651301383972168
Validation loss: 2.3227831919988

Epoch: 6| Step: 12
Training loss: 0.42135709524154663
Validation loss: 2.265607555707296

Epoch: 6| Step: 13
Training loss: 0.31860700249671936
Validation loss: 2.2807525197664895

Epoch: 297| Step: 0
Training loss: 0.38845664262771606
Validation loss: 2.2623956402142844

Epoch: 6| Step: 1
Training loss: 0.8737233281135559
Validation loss: 2.2831376791000366

Epoch: 6| Step: 2
Training loss: 0.2714216113090515
Validation loss: 2.2735681931177774

Epoch: 6| Step: 3
Training loss: 0.5623407363891602
Validation loss: 2.270887633164724

Epoch: 6| Step: 4
Training loss: 0.4010474383831024
Validation loss: 2.290820141633352

Epoch: 6| Step: 5
Training loss: 0.23552578687667847
Validation loss: 2.2699718872706094

Epoch: 6| Step: 6
Training loss: 0.7209305167198181
Validation loss: 2.23578147093455

Epoch: 6| Step: 7
Training loss: 0.48649197816848755
Validation loss: 2.242216110229492

Epoch: 6| Step: 8
Training loss: 0.3190407156944275
Validation loss: 2.2333547274271646

Epoch: 6| Step: 9
Training loss: 0.4439537525177002
Validation loss: 2.2784073750178018

Epoch: 6| Step: 10
Training loss: 0.4583969712257385
Validation loss: 2.2640611131985984

Epoch: 6| Step: 11
Training loss: 0.42580801248550415
Validation loss: 2.229986310005188

Epoch: 6| Step: 12
Training loss: 0.46367770433425903
Validation loss: 2.2559181451797485

Epoch: 6| Step: 13
Training loss: 0.8627215623855591
Validation loss: 2.245132088661194

Epoch: 298| Step: 0
Training loss: 0.5084900259971619
Validation loss: 2.241464376449585

Epoch: 6| Step: 1
Training loss: 0.5797548294067383
Validation loss: 2.2618802785873413

Epoch: 6| Step: 2
Training loss: 0.49142831563949585
Validation loss: 2.2582433025042215

Epoch: 6| Step: 3
Training loss: 0.29963207244873047
Validation loss: 2.2910277446111045

Epoch: 6| Step: 4
Training loss: 0.6367923021316528
Validation loss: 2.249829729398092

Epoch: 6| Step: 5
Training loss: 0.3105415105819702
Validation loss: 2.2458070119222007

Epoch: 6| Step: 6
Training loss: 0.35312604904174805
Validation loss: 2.230292717615763

Epoch: 6| Step: 7
Training loss: 0.4557706117630005
Validation loss: 2.2574731508890786

Epoch: 6| Step: 8
Training loss: 0.28803640604019165
Validation loss: 2.1934603254000344

Epoch: 6| Step: 9
Training loss: 0.7626342177391052
Validation loss: 2.182770828406016

Epoch: 6| Step: 10
Training loss: 0.5717244148254395
Validation loss: 2.206684629122416

Epoch: 6| Step: 11
Training loss: 0.17075422406196594
Validation loss: 2.2545589208602905

Epoch: 6| Step: 12
Training loss: 0.832061767578125
Validation loss: 2.199348529179891

Epoch: 6| Step: 13
Training loss: 0.5911683440208435
Validation loss: 2.239827255407969

Epoch: 299| Step: 0
Training loss: 0.20828792452812195
Validation loss: 2.2225751082102456

Epoch: 6| Step: 1
Training loss: 0.5138765573501587
Validation loss: 2.2713525692621865

Epoch: 6| Step: 2
Training loss: 0.5108461380004883
Validation loss: 2.26674222946167

Epoch: 6| Step: 3
Training loss: 0.4386262595653534
Validation loss: 2.2213224371274314

Epoch: 6| Step: 4
Training loss: 0.2987988293170929
Validation loss: 2.2342910369237265

Epoch: 6| Step: 5
Training loss: 0.2652868628501892
Validation loss: 2.2561007142066956

Epoch: 6| Step: 6
Training loss: 0.4512677788734436
Validation loss: 2.2570772568384805

Epoch: 6| Step: 7
Training loss: 0.7424371242523193
Validation loss: 2.2559560934702554

Epoch: 6| Step: 8
Training loss: 0.7498327493667603
Validation loss: 2.2010290225346885

Epoch: 6| Step: 9
Training loss: 0.7026171684265137
Validation loss: 2.2696842352549234

Epoch: 6| Step: 10
Training loss: 0.4287850260734558
Validation loss: 2.263885796070099

Epoch: 6| Step: 11
Training loss: 0.2663201689720154
Validation loss: 2.290202041467031

Epoch: 6| Step: 12
Training loss: 0.49122053384780884
Validation loss: 2.2588403622309365

Epoch: 6| Step: 13
Training loss: 0.6732608079910278
Validation loss: 2.2361096143722534

Epoch: 300| Step: 0
Training loss: 0.46891260147094727
Validation loss: 2.2832919359207153

Epoch: 6| Step: 1
Training loss: 0.3525211215019226
Validation loss: 2.240817348162333

Epoch: 6| Step: 2
Training loss: 0.34380415081977844
Validation loss: 2.2602652311325073

Epoch: 6| Step: 3
Training loss: 0.5546243190765381
Validation loss: 2.221386710802714

Epoch: 6| Step: 4
Training loss: 0.5414044260978699
Validation loss: 2.3080575267473855

Epoch: 6| Step: 5
Training loss: 0.5155432224273682
Validation loss: 2.1658631761868796

Epoch: 6| Step: 6
Training loss: 0.2727452516555786
Validation loss: 2.1990300019582114

Epoch: 6| Step: 7
Training loss: 0.5325045585632324
Validation loss: 2.2291519244511924

Epoch: 6| Step: 8
Training loss: 0.5218514204025269
Validation loss: 2.2945555647214255

Epoch: 6| Step: 9
Training loss: 0.8951845169067383
Validation loss: 2.283742904663086

Epoch: 6| Step: 10
Training loss: 0.3808196187019348
Validation loss: 2.270897110303243

Epoch: 6| Step: 11
Training loss: 0.6153292655944824
Validation loss: 2.2548591097195945

Epoch: 6| Step: 12
Training loss: 0.4335750341415405
Validation loss: 2.228341003259023

Epoch: 6| Step: 13
Training loss: 0.5582430362701416
Validation loss: 2.254303435484568

Epoch: 301| Step: 0
Training loss: 0.4586767554283142
Validation loss: 2.2611029744148254

Epoch: 6| Step: 1
Training loss: 0.37691226601600647
Validation loss: 2.2794655164082847

Epoch: 6| Step: 2
Training loss: 0.5822708606719971
Validation loss: 2.2589744130770364

Epoch: 6| Step: 3
Training loss: 0.4045311212539673
Validation loss: 2.2782238324483237

Epoch: 6| Step: 4
Training loss: 0.70932537317276
Validation loss: 2.2463218371073403

Epoch: 6| Step: 5
Training loss: 0.591279149055481
Validation loss: 2.2100700736045837

Epoch: 6| Step: 6
Training loss: 0.5118293762207031
Validation loss: 2.2721564372380576

Epoch: 6| Step: 7
Training loss: 0.33690690994262695
Validation loss: 2.214748978614807

Epoch: 6| Step: 8
Training loss: 0.24178531765937805
Validation loss: 2.279702623685201

Epoch: 6| Step: 9
Training loss: 0.5895551443099976
Validation loss: 2.2342137495676675

Epoch: 6| Step: 10
Training loss: 0.2677571177482605
Validation loss: 2.2664775252342224

Epoch: 6| Step: 11
Training loss: 0.7191744446754456
Validation loss: 2.287301520506541

Epoch: 6| Step: 12
Training loss: 0.6408851146697998
Validation loss: 2.2871890465418496

Epoch: 6| Step: 13
Training loss: 0.5753666162490845
Validation loss: 2.2978157997131348

Epoch: 302| Step: 0
Training loss: 0.6045640707015991
Validation loss: 2.266637643178304

Epoch: 6| Step: 1
Training loss: 0.2745339870452881
Validation loss: 2.265864451726278

Epoch: 6| Step: 2
Training loss: 1.0824121236801147
Validation loss: 2.25031848748525

Epoch: 6| Step: 3
Training loss: 0.6099246144294739
Validation loss: 2.2701715230941772

Epoch: 6| Step: 4
Training loss: 0.404291033744812
Validation loss: 2.1823115746180215

Epoch: 6| Step: 5
Training loss: 0.41922152042388916
Validation loss: 2.219327966372172

Epoch: 6| Step: 6
Training loss: 0.5226565599441528
Validation loss: 2.2347875833511353

Epoch: 6| Step: 7
Training loss: 0.6938515901565552
Validation loss: 2.2444721857706704

Epoch: 6| Step: 8
Training loss: 0.634208083152771
Validation loss: 2.213663717110952

Epoch: 6| Step: 9
Training loss: 0.7118308544158936
Validation loss: 2.323863406976064

Epoch: 6| Step: 10
Training loss: 0.40541282296180725
Validation loss: 2.240073343118032

Epoch: 6| Step: 11
Training loss: 0.3979014754295349
Validation loss: 2.2513767878214517

Epoch: 6| Step: 12
Training loss: 0.3965678811073303
Validation loss: 2.274336894353231

Epoch: 6| Step: 13
Training loss: 0.2689710259437561
Validation loss: 2.2397630413373313

Epoch: 303| Step: 0
Training loss: 0.9762661457061768
Validation loss: 2.2607158621152244

Epoch: 6| Step: 1
Training loss: 0.4724668860435486
Validation loss: 2.2398071686426797

Epoch: 6| Step: 2
Training loss: 0.28734737634658813
Validation loss: 2.209188461303711

Epoch: 6| Step: 3
Training loss: 0.2944532036781311
Validation loss: 2.258724093437195

Epoch: 6| Step: 4
Training loss: 0.41253143548965454
Validation loss: 2.21336821715037

Epoch: 6| Step: 5
Training loss: 0.3336859941482544
Validation loss: 2.19666588306427

Epoch: 6| Step: 6
Training loss: 0.3271908164024353
Validation loss: 2.2376733223597207

Epoch: 6| Step: 7
Training loss: 0.2967367470264435
Validation loss: 2.253979047139486

Epoch: 6| Step: 8
Training loss: 0.7209180593490601
Validation loss: 2.2608372966448465

Epoch: 6| Step: 9
Training loss: 0.670477032661438
Validation loss: 2.205245852470398

Epoch: 6| Step: 10
Training loss: 0.3804723918437958
Validation loss: 2.2898834149042764

Epoch: 6| Step: 11
Training loss: 0.3491327464580536
Validation loss: 2.310140331586202

Epoch: 6| Step: 12
Training loss: 0.7997379899024963
Validation loss: 2.2628581523895264

Epoch: 6| Step: 13
Training loss: 0.44477131962776184
Validation loss: 2.2299881974856057

Epoch: 304| Step: 0
Training loss: 0.3945004940032959
Validation loss: 2.21408748626709

Epoch: 6| Step: 1
Training loss: 0.2075340747833252
Validation loss: 2.257384955883026

Epoch: 6| Step: 2
Training loss: 0.7230631113052368
Validation loss: 2.25421279668808

Epoch: 6| Step: 3
Training loss: 0.3692963719367981
Validation loss: 2.2101228634516397

Epoch: 6| Step: 4
Training loss: 0.832621693611145
Validation loss: 2.2411015033721924

Epoch: 6| Step: 5
Training loss: 0.5149849057197571
Validation loss: 2.1930388609568277

Epoch: 6| Step: 6
Training loss: 0.2626897096633911
Validation loss: 2.2099371751149497

Epoch: 6| Step: 7
Training loss: 0.3830588459968567
Validation loss: 2.2215762933095298

Epoch: 6| Step: 8
Training loss: 0.5251703262329102
Validation loss: 2.230244517326355

Epoch: 6| Step: 9
Training loss: 0.2961031198501587
Validation loss: 2.2705527544021606

Epoch: 6| Step: 10
Training loss: 0.7552840709686279
Validation loss: 2.2644934256871543

Epoch: 6| Step: 11
Training loss: 0.3563340902328491
Validation loss: 2.254271467526754

Epoch: 6| Step: 12
Training loss: 0.5248419046401978
Validation loss: 2.244867980480194

Epoch: 6| Step: 13
Training loss: 0.5945780873298645
Validation loss: 2.2089338501294455

Epoch: 305| Step: 0
Training loss: 0.21665886044502258
Validation loss: 2.269347389539083

Epoch: 6| Step: 1
Training loss: 0.25404077768325806
Validation loss: 2.2308170994122825

Epoch: 6| Step: 2
Training loss: 0.7094361782073975
Validation loss: 2.241714040438334

Epoch: 6| Step: 3
Training loss: 0.6519022583961487
Validation loss: 2.219428817431132

Epoch: 6| Step: 4
Training loss: 0.6088375449180603
Validation loss: 2.2920360763867698

Epoch: 6| Step: 5
Training loss: 1.1575570106506348
Validation loss: 2.2813215851783752

Epoch: 6| Step: 6
Training loss: 0.4738130569458008
Validation loss: 2.2250028053919473

Epoch: 6| Step: 7
Training loss: 0.3268014192581177
Validation loss: 2.261363367239634

Epoch: 6| Step: 8
Training loss: 0.27936723828315735
Validation loss: 2.258168578147888

Epoch: 6| Step: 9
Training loss: 0.4972306787967682
Validation loss: 2.2975435853004456

Epoch: 6| Step: 10
Training loss: 0.5246647000312805
Validation loss: 2.18314266204834

Epoch: 6| Step: 11
Training loss: 0.18492771685123444
Validation loss: 2.224251170953115

Epoch: 6| Step: 12
Training loss: 0.4043238162994385
Validation loss: 2.2630358139673867

Epoch: 6| Step: 13
Training loss: 0.30988842248916626
Validation loss: 2.269554297129313

Epoch: 306| Step: 0
Training loss: 0.7477526068687439
Validation loss: 2.2283265590667725

Epoch: 6| Step: 1
Training loss: 0.4811896085739136
Validation loss: 2.21772430340449

Epoch: 6| Step: 2
Training loss: 0.1989295333623886
Validation loss: 2.264191667238871

Epoch: 6| Step: 3
Training loss: 0.5072734355926514
Validation loss: 2.2409775257110596

Epoch: 6| Step: 4
Training loss: 0.422460675239563
Validation loss: 2.237080911795298

Epoch: 6| Step: 5
Training loss: 0.5158854126930237
Validation loss: 2.2628950675328574

Epoch: 6| Step: 6
Training loss: 0.1775922328233719
Validation loss: 2.292605737845103

Epoch: 6| Step: 7
Training loss: 0.2733922004699707
Validation loss: 2.231590131918589

Epoch: 6| Step: 8
Training loss: 0.4706730842590332
Validation loss: 2.258041520913442

Epoch: 6| Step: 9
Training loss: 0.8883587121963501
Validation loss: 2.2461739579836526

Epoch: 6| Step: 10
Training loss: 0.7096573114395142
Validation loss: 2.2785361607869468

Epoch: 6| Step: 11
Training loss: 0.23001520335674286
Validation loss: 2.28067684173584

Epoch: 6| Step: 12
Training loss: 0.4396841526031494
Validation loss: 2.285704473654429

Epoch: 6| Step: 13
Training loss: 0.5563622117042542
Validation loss: 2.255284865697225

Epoch: 307| Step: 0
Training loss: 0.6613730192184448
Validation loss: 2.1785489916801453

Epoch: 6| Step: 1
Training loss: 0.3441159725189209
Validation loss: 2.2576078375180564

Epoch: 6| Step: 2
Training loss: 0.5972715616226196
Validation loss: 2.204591969648997

Epoch: 6| Step: 3
Training loss: 0.4387872815132141
Validation loss: 2.2252202232678733

Epoch: 6| Step: 4
Training loss: 0.33910828828811646
Validation loss: 2.287556529045105

Epoch: 6| Step: 5
Training loss: 0.39842095971107483
Validation loss: 2.296064098676046

Epoch: 6| Step: 6
Training loss: 0.39577537775039673
Validation loss: 2.269071380297343

Epoch: 6| Step: 7
Training loss: 0.40553486347198486
Validation loss: 2.2478661139806113

Epoch: 6| Step: 8
Training loss: 0.5416646003723145
Validation loss: 2.2043230533599854

Epoch: 6| Step: 9
Training loss: 0.546493411064148
Validation loss: 2.2702696323394775

Epoch: 6| Step: 10
Training loss: 0.3395640254020691
Validation loss: 2.3114840388298035

Epoch: 6| Step: 11
Training loss: 0.26984214782714844
Validation loss: 2.2362351020177207

Epoch: 6| Step: 12
Training loss: 0.7193616032600403
Validation loss: 2.2657704949378967

Epoch: 6| Step: 13
Training loss: 0.5473278760910034
Validation loss: 2.229208787282308

Epoch: 308| Step: 0
Training loss: 0.5671393871307373
Validation loss: 2.295720954736074

Epoch: 6| Step: 1
Training loss: 0.3655470311641693
Validation loss: 2.258509953816732

Epoch: 6| Step: 2
Training loss: 0.2182009518146515
Validation loss: 2.1963006258010864

Epoch: 6| Step: 3
Training loss: 0.30398595333099365
Validation loss: 2.2749054431915283

Epoch: 6| Step: 4
Training loss: 0.37743765115737915
Validation loss: 2.26140562693278

Epoch: 6| Step: 5
Training loss: 0.4872646629810333
Validation loss: 2.255544980367025

Epoch: 6| Step: 6
Training loss: 0.2898261547088623
Validation loss: 2.305878738562266

Epoch: 6| Step: 7
Training loss: 0.318372517824173
Validation loss: 2.245052615801493

Epoch: 6| Step: 8
Training loss: 0.31066790223121643
Validation loss: 2.2042807141939798

Epoch: 6| Step: 9
Training loss: 0.8259926438331604
Validation loss: 2.2772316535313926

Epoch: 6| Step: 10
Training loss: 0.40764039754867554
Validation loss: 2.2295408646265664

Epoch: 6| Step: 11
Training loss: 0.6328540444374084
Validation loss: 2.2910025914510093

Epoch: 6| Step: 12
Training loss: 1.0235614776611328
Validation loss: 2.2314082781473794

Epoch: 6| Step: 13
Training loss: 0.25081145763397217
Validation loss: 2.2283031344413757

Epoch: 309| Step: 0
Training loss: 0.9486839771270752
Validation loss: 2.2735290924708047

Epoch: 6| Step: 1
Training loss: 0.4758755564689636
Validation loss: 2.274040679136912

Epoch: 6| Step: 2
Training loss: 0.21171635389328003
Validation loss: 2.274457255999247

Epoch: 6| Step: 3
Training loss: 0.5772960782051086
Validation loss: 2.2473291556040444

Epoch: 6| Step: 4
Training loss: 0.4123515486717224
Validation loss: 2.224958121776581

Epoch: 6| Step: 5
Training loss: 0.37740784883499146
Validation loss: 2.2338465253512063

Epoch: 6| Step: 6
Training loss: 0.7320883274078369
Validation loss: 2.2229351003964744

Epoch: 6| Step: 7
Training loss: 0.31814348697662354
Validation loss: 2.2770503560702005

Epoch: 6| Step: 8
Training loss: 0.3849586844444275
Validation loss: 2.2393111189206443

Epoch: 6| Step: 9
Training loss: 0.25647538900375366
Validation loss: 2.2667799592018127

Epoch: 6| Step: 10
Training loss: 0.4948607385158539
Validation loss: 2.204523185888926

Epoch: 6| Step: 11
Training loss: 0.6979906558990479
Validation loss: 2.212435245513916

Epoch: 6| Step: 12
Training loss: 0.39858606457710266
Validation loss: 2.2440046668052673

Epoch: 6| Step: 13
Training loss: 0.4394136071205139
Validation loss: 2.1807556748390198

Epoch: 310| Step: 0
Training loss: 0.3542695641517639
Validation loss: 2.2418869733810425

Epoch: 6| Step: 1
Training loss: 0.5332498550415039
Validation loss: 2.227207620938619

Epoch: 6| Step: 2
Training loss: 0.18140336871147156
Validation loss: 2.235233187675476

Epoch: 6| Step: 3
Training loss: 0.6136767864227295
Validation loss: 2.2609893083572388

Epoch: 6| Step: 4
Training loss: 0.3630809783935547
Validation loss: 2.266066054503123

Epoch: 6| Step: 5
Training loss: 0.3402820825576782
Validation loss: 2.2013560930887857

Epoch: 6| Step: 6
Training loss: 0.3880946636199951
Validation loss: 2.2696017821629844

Epoch: 6| Step: 7
Training loss: 0.5572471022605896
Validation loss: 2.239841798941294

Epoch: 6| Step: 8
Training loss: 0.29973554611206055
Validation loss: 2.2380317648251853

Epoch: 6| Step: 9
Training loss: 0.6992002129554749
Validation loss: 2.235712548096975

Epoch: 6| Step: 10
Training loss: 0.7322924733161926
Validation loss: 2.253768265247345

Epoch: 6| Step: 11
Training loss: 0.6027465462684631
Validation loss: 2.2569830218950906

Epoch: 6| Step: 12
Training loss: 0.642719030380249
Validation loss: 2.223312020301819

Epoch: 6| Step: 13
Training loss: 0.26191946864128113
Validation loss: 2.22862317164739

Epoch: 311| Step: 0
Training loss: 0.5077368021011353
Validation loss: 2.2230992515881858

Epoch: 6| Step: 1
Training loss: 0.5671257376670837
Validation loss: 2.2411996920903525

Epoch: 6| Step: 2
Training loss: 0.5964481830596924
Validation loss: 2.2105332215627036

Epoch: 6| Step: 3
Training loss: 0.7440447807312012
Validation loss: 2.228166421254476

Epoch: 6| Step: 4
Training loss: 0.49048975110054016
Validation loss: 2.254770040512085

Epoch: 6| Step: 5
Training loss: 0.4558751881122589
Validation loss: 2.2545936504999795

Epoch: 6| Step: 6
Training loss: 0.3716173470020294
Validation loss: 2.2168357372283936

Epoch: 6| Step: 7
Training loss: 0.35014647245407104
Validation loss: 2.23571248849233

Epoch: 6| Step: 8
Training loss: 0.4240707755088806
Validation loss: 2.270043909549713

Epoch: 6| Step: 9
Training loss: 0.5062298774719238
Validation loss: 2.33022803068161

Epoch: 6| Step: 10
Training loss: 0.36612385511398315
Validation loss: 2.2837352752685547

Epoch: 6| Step: 11
Training loss: 0.9256067276000977
Validation loss: 2.2610886096954346

Epoch: 6| Step: 12
Training loss: 0.3391127288341522
Validation loss: 2.2506532669067383

Epoch: 6| Step: 13
Training loss: 0.3338126242160797
Validation loss: 2.2221361994743347

Epoch: 312| Step: 0
Training loss: 0.39773380756378174
Validation loss: 2.3236078023910522

Epoch: 6| Step: 1
Training loss: 0.39134830236434937
Validation loss: 2.2569395899772644

Epoch: 6| Step: 2
Training loss: 0.45128244161605835
Validation loss: 2.269551634788513

Epoch: 6| Step: 3
Training loss: 0.5579102039337158
Validation loss: 2.2672907511393228

Epoch: 6| Step: 4
Training loss: 0.2576684355735779
Validation loss: 2.2188339630762735

Epoch: 6| Step: 5
Training loss: 0.3052698075771332
Validation loss: 2.2689454356829324

Epoch: 6| Step: 6
Training loss: 0.18701934814453125
Validation loss: 2.2038970589637756

Epoch: 6| Step: 7
Training loss: 0.5117489695549011
Validation loss: 2.2704317371050515

Epoch: 6| Step: 8
Training loss: 1.1680363416671753
Validation loss: 2.242645561695099

Epoch: 6| Step: 9
Training loss: 0.23913130164146423
Validation loss: 2.306996981302897

Epoch: 6| Step: 10
Training loss: 0.6375914812088013
Validation loss: 2.214780350526174

Epoch: 6| Step: 11
Training loss: 0.32156920433044434
Validation loss: 2.2656414111455283

Epoch: 6| Step: 12
Training loss: 0.9236939549446106
Validation loss: 2.2829434672991433

Epoch: 6| Step: 13
Training loss: 0.2507723569869995
Validation loss: 2.206472337245941

Epoch: 313| Step: 0
Training loss: 0.8224772810935974
Validation loss: 2.2265308499336243

Epoch: 6| Step: 1
Training loss: 0.683628499507904
Validation loss: 2.2231602668762207

Epoch: 6| Step: 2
Training loss: 0.33723747730255127
Validation loss: 2.2278467814127603

Epoch: 6| Step: 3
Training loss: 0.3888401389122009
Validation loss: 2.2439759373664856

Epoch: 6| Step: 4
Training loss: 0.26157549023628235
Validation loss: 2.1537017822265625

Epoch: 6| Step: 5
Training loss: 0.36343786120414734
Validation loss: 2.259476602077484

Epoch: 6| Step: 6
Training loss: 0.4341646730899811
Validation loss: 2.2493945956230164

Epoch: 6| Step: 7
Training loss: 0.46770012378692627
Validation loss: 2.2055508693059287

Epoch: 6| Step: 8
Training loss: 0.3375079035758972
Validation loss: 2.2591851353645325

Epoch: 6| Step: 9
Training loss: 0.4689139127731323
Validation loss: 2.259582777818044

Epoch: 6| Step: 10
Training loss: 0.2784402370452881
Validation loss: 2.2332285245259604

Epoch: 6| Step: 11
Training loss: 0.30046695470809937
Validation loss: 2.17947781085968

Epoch: 6| Step: 12
Training loss: 0.657942533493042
Validation loss: 2.196844140688578

Epoch: 6| Step: 13
Training loss: 0.5375135540962219
Validation loss: 2.265795191129049

Epoch: 314| Step: 0
Training loss: 0.24914076924324036
Validation loss: 2.2836764256159463

Epoch: 6| Step: 1
Training loss: 0.25289005041122437
Validation loss: 2.2745131850242615

Epoch: 6| Step: 2
Training loss: 0.42328396439552307
Validation loss: 2.2309009631474814

Epoch: 6| Step: 3
Training loss: 0.8683025240898132
Validation loss: 2.2591597636540732

Epoch: 6| Step: 4
Training loss: 0.7149722576141357
Validation loss: 2.2153881986935935

Epoch: 6| Step: 5
Training loss: 0.34188583493232727
Validation loss: 2.2485916018486023

Epoch: 6| Step: 6
Training loss: 0.3795536458492279
Validation loss: 2.2382240096728006

Epoch: 6| Step: 7
Training loss: 0.40366795659065247
Validation loss: 2.248764713605245

Epoch: 6| Step: 8
Training loss: 0.4094787836074829
Validation loss: 2.264860192934672

Epoch: 6| Step: 9
Training loss: 0.5257775783538818
Validation loss: 2.1910900672276816

Epoch: 6| Step: 10
Training loss: 0.5129068493843079
Validation loss: 2.238265077273051

Epoch: 6| Step: 11
Training loss: 0.46939247846603394
Validation loss: 2.2415982683499656

Epoch: 6| Step: 12
Training loss: 0.46365875005722046
Validation loss: 2.2228453556696572

Epoch: 6| Step: 13
Training loss: 0.29803889989852905
Validation loss: 2.239145557085673

Epoch: 315| Step: 0
Training loss: 0.7841611504554749
Validation loss: 2.2459175189336142

Epoch: 6| Step: 1
Training loss: 0.3882637321949005
Validation loss: 2.2645171880722046

Epoch: 6| Step: 2
Training loss: 0.5687575340270996
Validation loss: 2.2373589277267456

Epoch: 6| Step: 3
Training loss: 0.350737988948822
Validation loss: 2.204387625058492

Epoch: 6| Step: 4
Training loss: 0.24945363402366638
Validation loss: 2.252698024113973

Epoch: 6| Step: 5
Training loss: 0.1966293454170227
Validation loss: 2.258987863858541

Epoch: 6| Step: 6
Training loss: 0.5314615964889526
Validation loss: 2.2592522303263345

Epoch: 6| Step: 7
Training loss: 1.046647071838379
Validation loss: 2.249792238076528

Epoch: 6| Step: 8
Training loss: 0.5008118152618408
Validation loss: 2.3131935596466064

Epoch: 6| Step: 9
Training loss: 0.6372178792953491
Validation loss: 2.305586516857147

Epoch: 6| Step: 10
Training loss: 0.315847784280777
Validation loss: 2.253972868124644

Epoch: 6| Step: 11
Training loss: 0.16920550167560577
Validation loss: 2.2171363830566406

Epoch: 6| Step: 12
Training loss: 0.29692697525024414
Validation loss: 2.263136863708496

Epoch: 6| Step: 13
Training loss: 0.3959781527519226
Validation loss: 2.215561270713806

Epoch: 316| Step: 0
Training loss: 0.49357980489730835
Validation loss: 2.247369905312856

Epoch: 6| Step: 1
Training loss: 0.2759985625743866
Validation loss: 2.1853971083958945

Epoch: 6| Step: 2
Training loss: 0.9067791700363159
Validation loss: 2.249636967976888

Epoch: 6| Step: 3
Training loss: 0.5184056162834167
Validation loss: 2.2667332887649536

Epoch: 6| Step: 4
Training loss: 0.5085712671279907
Validation loss: 2.314232031504313

Epoch: 6| Step: 5
Training loss: 0.3222230076789856
Validation loss: 2.2326166232426963

Epoch: 6| Step: 6
Training loss: 0.41688376665115356
Validation loss: 2.212963283061981

Epoch: 6| Step: 7
Training loss: 0.30502840876579285
Validation loss: 2.1754966974258423

Epoch: 6| Step: 8
Training loss: 0.4104829430580139
Validation loss: 2.2232456604639688

Epoch: 6| Step: 9
Training loss: 0.5261310338973999
Validation loss: 2.2127474546432495

Epoch: 6| Step: 10
Training loss: 0.27741315960884094
Validation loss: 2.247202237447103

Epoch: 6| Step: 11
Training loss: 0.46853122115135193
Validation loss: 2.2092254757881165

Epoch: 6| Step: 12
Training loss: 0.40783798694610596
Validation loss: 2.2113149563471475

Epoch: 6| Step: 13
Training loss: 0.6632037162780762
Validation loss: 2.2187256813049316

Epoch: 317| Step: 0
Training loss: 0.4980177879333496
Validation loss: 2.2200374007225037

Epoch: 6| Step: 1
Training loss: 0.18220458924770355
Validation loss: 2.202484369277954

Epoch: 6| Step: 2
Training loss: 0.2266879677772522
Validation loss: 2.244529406229655

Epoch: 6| Step: 3
Training loss: 0.42043542861938477
Validation loss: 2.227649529774984

Epoch: 6| Step: 4
Training loss: 0.29998281598091125
Validation loss: 2.1756765445073447

Epoch: 6| Step: 5
Training loss: 0.5055602192878723
Validation loss: 2.224717835585276

Epoch: 6| Step: 6
Training loss: 0.3278321921825409
Validation loss: 2.2105560302734375

Epoch: 6| Step: 7
Training loss: 0.2717110812664032
Validation loss: 2.2602909406026206

Epoch: 6| Step: 8
Training loss: 0.6369235515594482
Validation loss: 2.2268869280815125

Epoch: 6| Step: 9
Training loss: 0.4726216793060303
Validation loss: 2.2336910168329873

Epoch: 6| Step: 10
Training loss: 1.0873078107833862
Validation loss: 2.202928841114044

Epoch: 6| Step: 11
Training loss: 0.632885754108429
Validation loss: 2.227573871612549

Epoch: 6| Step: 12
Training loss: 0.5088849067687988
Validation loss: 2.2232491970062256

Epoch: 6| Step: 13
Training loss: 0.3513273000717163
Validation loss: 2.2580880324045816

Epoch: 318| Step: 0
Training loss: 0.4815485179424286
Validation loss: 2.218489090601603

Epoch: 6| Step: 1
Training loss: 0.3011474013328552
Validation loss: 2.220290203889211

Epoch: 6| Step: 2
Training loss: 0.5950886607170105
Validation loss: 2.245443264643351

Epoch: 6| Step: 3
Training loss: 0.27944350242614746
Validation loss: 2.2253113190333047

Epoch: 6| Step: 4
Training loss: 0.552307665348053
Validation loss: 2.2208401759465537

Epoch: 6| Step: 5
Training loss: 0.3750249445438385
Validation loss: 2.256367305914561

Epoch: 6| Step: 6
Training loss: 0.23063111305236816
Validation loss: 2.322383165359497

Epoch: 6| Step: 7
Training loss: 0.44528600573539734
Validation loss: 2.2070471048355103

Epoch: 6| Step: 8
Training loss: 0.4834819734096527
Validation loss: 2.2375298738479614

Epoch: 6| Step: 9
Training loss: 0.4618089199066162
Validation loss: 2.2636771400769553

Epoch: 6| Step: 10
Training loss: 0.48810306191444397
Validation loss: 2.195733149846395

Epoch: 6| Step: 11
Training loss: 0.7267353534698486
Validation loss: 2.23473326365153

Epoch: 6| Step: 12
Training loss: 0.49678248167037964
Validation loss: 2.2722965081532798

Epoch: 6| Step: 13
Training loss: 0.28920093178749084
Validation loss: 2.22283665339152

Epoch: 319| Step: 0
Training loss: 0.6026138067245483
Validation loss: 2.273600618044535

Epoch: 6| Step: 1
Training loss: 0.3804161250591278
Validation loss: 2.2724077304204306

Epoch: 6| Step: 2
Training loss: 0.6203831434249878
Validation loss: 2.1994442542394004

Epoch: 6| Step: 3
Training loss: 0.36408478021621704
Validation loss: 2.218231280644735

Epoch: 6| Step: 4
Training loss: 0.3577110171318054
Validation loss: 2.262885649998983

Epoch: 6| Step: 5
Training loss: 0.41434746980667114
Validation loss: 2.2278616031010947

Epoch: 6| Step: 6
Training loss: 0.2752279043197632
Validation loss: 2.2123285134633384

Epoch: 6| Step: 7
Training loss: 0.2610430121421814
Validation loss: 2.241866131623586

Epoch: 6| Step: 8
Training loss: 0.4982490837574005
Validation loss: 2.225327968597412

Epoch: 6| Step: 9
Training loss: 0.3385467529296875
Validation loss: 2.208210508028666

Epoch: 6| Step: 10
Training loss: 0.5168070197105408
Validation loss: 2.2580469449361167

Epoch: 6| Step: 11
Training loss: 0.9844642281532288
Validation loss: 2.2485684752464294

Epoch: 6| Step: 12
Training loss: 0.38986510038375854
Validation loss: 2.1756511529286704

Epoch: 6| Step: 13
Training loss: 0.506005048751831
Validation loss: 2.2310239473978677

Epoch: 320| Step: 0
Training loss: 0.5979031324386597
Validation loss: 2.2079950173695884

Epoch: 6| Step: 1
Training loss: 0.4256889820098877
Validation loss: 2.2297682563463845

Epoch: 6| Step: 2
Training loss: 0.471466600894928
Validation loss: 2.218703786532084

Epoch: 6| Step: 3
Training loss: 0.3412845730781555
Validation loss: 2.2219266096750894

Epoch: 6| Step: 4
Training loss: 0.4383660554885864
Validation loss: 2.2086375951766968

Epoch: 6| Step: 5
Training loss: 0.4917171597480774
Validation loss: 2.226183613141378

Epoch: 6| Step: 6
Training loss: 0.27157846093177795
Validation loss: 2.258062760035197

Epoch: 6| Step: 7
Training loss: 0.20187821984291077
Validation loss: 2.241134226322174

Epoch: 6| Step: 8
Training loss: 0.44940781593322754
Validation loss: 2.3061005671819053

Epoch: 6| Step: 9
Training loss: 0.4234806001186371
Validation loss: 2.246493935585022

Epoch: 6| Step: 10
Training loss: 0.33592239022254944
Validation loss: 2.3191171884536743

Epoch: 6| Step: 11
Training loss: 0.779085636138916
Validation loss: 2.273867209752401

Epoch: 6| Step: 12
Training loss: 0.7884563207626343
Validation loss: 2.246192435423533

Epoch: 6| Step: 13
Training loss: 0.4737285077571869
Validation loss: 2.2021291255950928

Epoch: 321| Step: 0
Training loss: 0.38582953810691833
Validation loss: 2.2549970149993896

Epoch: 6| Step: 1
Training loss: 0.4269331693649292
Validation loss: 2.264495770136515

Epoch: 6| Step: 2
Training loss: 0.5752047896385193
Validation loss: 2.223691403865814

Epoch: 6| Step: 3
Training loss: 0.4282242953777313
Validation loss: 2.2071566383043923

Epoch: 6| Step: 4
Training loss: 0.7155976295471191
Validation loss: 2.2407705783843994

Epoch: 6| Step: 5
Training loss: 0.4026307165622711
Validation loss: 2.2461649576822915

Epoch: 6| Step: 6
Training loss: 0.4557856321334839
Validation loss: 2.2074233492215476

Epoch: 6| Step: 7
Training loss: 0.5315467715263367
Validation loss: 2.2515523433685303

Epoch: 6| Step: 8
Training loss: 0.7784118056297302
Validation loss: 2.2702062527338662

Epoch: 6| Step: 9
Training loss: 0.2613401412963867
Validation loss: 2.24666299422582

Epoch: 6| Step: 10
Training loss: 0.26378247141838074
Validation loss: 2.233800212542216

Epoch: 6| Step: 11
Training loss: 0.3901253640651703
Validation loss: 2.300833066304525

Epoch: 6| Step: 12
Training loss: 0.552463173866272
Validation loss: 2.260423243045807

Epoch: 6| Step: 13
Training loss: 0.5096766948699951
Validation loss: 2.209458589553833

Epoch: 322| Step: 0
Training loss: 0.18507075309753418
Validation loss: 2.2608640591303506

Epoch: 6| Step: 1
Training loss: 0.3919154107570648
Validation loss: 2.2675861120224

Epoch: 6| Step: 2
Training loss: 0.3491767346858978
Validation loss: 2.2869014739990234

Epoch: 6| Step: 3
Training loss: 0.5054928064346313
Validation loss: 2.296678105990092

Epoch: 6| Step: 4
Training loss: 0.4155552089214325
Validation loss: 2.2119471430778503

Epoch: 6| Step: 5
Training loss: 0.6817446947097778
Validation loss: 2.2441091338793435

Epoch: 6| Step: 6
Training loss: 0.28918522596359253
Validation loss: 2.253828207651774

Epoch: 6| Step: 7
Training loss: 0.7450448274612427
Validation loss: 2.2369811733563743

Epoch: 6| Step: 8
Training loss: 0.6595245599746704
Validation loss: 2.302493631839752

Epoch: 6| Step: 9
Training loss: 0.3656238317489624
Validation loss: 2.2580166856447854

Epoch: 6| Step: 10
Training loss: 0.33607038855552673
Validation loss: 2.2182522416114807

Epoch: 6| Step: 11
Training loss: 0.6875789165496826
Validation loss: 2.2167060375213623

Epoch: 6| Step: 12
Training loss: 0.24456143379211426
Validation loss: 2.2508897185325623

Epoch: 6| Step: 13
Training loss: 0.25762027502059937
Validation loss: 2.2464018861452737

Epoch: 323| Step: 0
Training loss: 0.6812452077865601
Validation loss: 2.239277720451355

Epoch: 6| Step: 1
Training loss: 0.41840657591819763
Validation loss: 2.2178745667139688

Epoch: 6| Step: 2
Training loss: 0.7408895492553711
Validation loss: 2.256372888882955

Epoch: 6| Step: 3
Training loss: 0.3630187511444092
Validation loss: 2.2803043524424234

Epoch: 6| Step: 4
Training loss: 0.4883297085762024
Validation loss: 2.2258247534434

Epoch: 6| Step: 5
Training loss: 0.5541641116142273
Validation loss: 2.264748771985372

Epoch: 6| Step: 6
Training loss: 0.3812767267227173
Validation loss: 2.2294636368751526

Epoch: 6| Step: 7
Training loss: 0.9054710865020752
Validation loss: 2.223625202973684

Epoch: 6| Step: 8
Training loss: 0.23263926804065704
Validation loss: 2.2563027342160544

Epoch: 6| Step: 9
Training loss: 0.6570720076560974
Validation loss: 2.2944955031077066

Epoch: 6| Step: 10
Training loss: 0.3642383813858032
Validation loss: 2.2595712145169577

Epoch: 6| Step: 11
Training loss: 0.3057425320148468
Validation loss: 2.2474752267201743

Epoch: 6| Step: 12
Training loss: 0.45702627301216125
Validation loss: 2.2246785362561545

Epoch: 6| Step: 13
Training loss: 0.2634321451187134
Validation loss: 2.256265640258789

Epoch: 324| Step: 0
Training loss: 0.36955520510673523
Validation loss: 2.2390318512916565

Epoch: 6| Step: 1
Training loss: 0.40059006214141846
Validation loss: 2.2594425876935325

Epoch: 6| Step: 2
Training loss: 0.6342136859893799
Validation loss: 2.2091697255770364

Epoch: 6| Step: 3
Training loss: 0.7357233762741089
Validation loss: 2.1994526982307434

Epoch: 6| Step: 4
Training loss: 0.7129418849945068
Validation loss: 2.267176409562429

Epoch: 6| Step: 5
Training loss: 0.8573199510574341
Validation loss: 2.296438376108805

Epoch: 6| Step: 6
Training loss: 0.39300569891929626
Validation loss: 2.290678302447001

Epoch: 6| Step: 7
Training loss: 0.23415328562259674
Validation loss: 2.26714680592219

Epoch: 6| Step: 8
Training loss: 0.6021929979324341
Validation loss: 2.2548964420954385

Epoch: 6| Step: 9
Training loss: 0.17882856726646423
Validation loss: 2.2313976089159646

Epoch: 6| Step: 10
Training loss: 0.3532434403896332
Validation loss: 2.288263460000356

Epoch: 6| Step: 11
Training loss: 0.1771448254585266
Validation loss: 2.248885691165924

Epoch: 6| Step: 12
Training loss: 0.2418379932641983
Validation loss: 2.3227482438087463

Epoch: 6| Step: 13
Training loss: 0.40936970710754395
Validation loss: 2.224599083264669

Epoch: 325| Step: 0
Training loss: 0.48705729842185974
Validation loss: 2.2946295738220215

Epoch: 6| Step: 1
Training loss: 0.3836252689361572
Validation loss: 2.2889249126116433

Epoch: 6| Step: 2
Training loss: 0.364271879196167
Validation loss: 2.262467622756958

Epoch: 6| Step: 3
Training loss: 0.4661881923675537
Validation loss: 2.2276139656702676

Epoch: 6| Step: 4
Training loss: 0.3862776756286621
Validation loss: 2.233659029006958

Epoch: 6| Step: 5
Training loss: 0.2405051440000534
Validation loss: 2.2445876598358154

Epoch: 6| Step: 6
Training loss: 0.4301724135875702
Validation loss: 2.2483399311701455

Epoch: 6| Step: 7
Training loss: 0.47302424907684326
Validation loss: 2.2351460655530295

Epoch: 6| Step: 8
Training loss: 0.21187537908554077
Validation loss: 2.2397080858548484

Epoch: 6| Step: 9
Training loss: 0.47707971930503845
Validation loss: 2.196264326572418

Epoch: 6| Step: 10
Training loss: 0.5969835519790649
Validation loss: 2.2644190788269043

Epoch: 6| Step: 11
Training loss: 0.3800468146800995
Validation loss: 2.2069831093152366

Epoch: 6| Step: 12
Training loss: 1.0440783500671387
Validation loss: 2.250907758871714

Epoch: 6| Step: 13
Training loss: 0.2634522020816803
Validation loss: 2.2250671784083047

Epoch: 326| Step: 0
Training loss: 0.5066455602645874
Validation loss: 2.2888397773106894

Epoch: 6| Step: 1
Training loss: 0.5823224782943726
Validation loss: 2.1842499574025473

Epoch: 6| Step: 2
Training loss: 0.3959909677505493
Validation loss: 2.2507967750231423

Epoch: 6| Step: 3
Training loss: 0.536949872970581
Validation loss: 2.194898029168447

Epoch: 6| Step: 4
Training loss: 0.4368665814399719
Validation loss: 2.2252456744511924

Epoch: 6| Step: 5
Training loss: 0.2847321927547455
Validation loss: 2.272649109363556

Epoch: 6| Step: 6
Training loss: 0.3299930691719055
Validation loss: 2.2606303890546164

Epoch: 6| Step: 7
Training loss: 0.5058640241622925
Validation loss: 2.2683404088020325

Epoch: 6| Step: 8
Training loss: 0.20248016715049744
Validation loss: 2.2264452974001565

Epoch: 6| Step: 9
Training loss: 0.2376280426979065
Validation loss: 2.2628673712412515

Epoch: 6| Step: 10
Training loss: 0.3179748058319092
Validation loss: 2.193440020084381

Epoch: 6| Step: 11
Training loss: 0.35876184701919556
Validation loss: 2.1792508959770203

Epoch: 6| Step: 12
Training loss: 0.5400494933128357
Validation loss: 2.2412370642026267

Epoch: 6| Step: 13
Training loss: 1.005369782447815
Validation loss: 2.25876522064209

Epoch: 327| Step: 0
Training loss: 0.5126211643218994
Validation loss: 2.241185963153839

Epoch: 6| Step: 1
Training loss: 0.5647352337837219
Validation loss: 2.263782540957133

Epoch: 6| Step: 2
Training loss: 0.2923688292503357
Validation loss: 2.204005559285482

Epoch: 6| Step: 3
Training loss: 0.9495340585708618
Validation loss: 2.209272265434265

Epoch: 6| Step: 4
Training loss: 0.30763572454452515
Validation loss: 2.2494709889094033

Epoch: 6| Step: 5
Training loss: 0.5464967489242554
Validation loss: 2.237428287665049

Epoch: 6| Step: 6
Training loss: 0.5631580352783203
Validation loss: 2.2411524653434753

Epoch: 6| Step: 7
Training loss: 0.35716354846954346
Validation loss: 2.2344917456309

Epoch: 6| Step: 8
Training loss: 0.24863988161087036
Validation loss: 2.205181439717611

Epoch: 6| Step: 9
Training loss: 0.3827241063117981
Validation loss: 2.1868282556533813

Epoch: 6| Step: 10
Training loss: 0.366055428981781
Validation loss: 2.22222367922465

Epoch: 6| Step: 11
Training loss: 0.4272984266281128
Validation loss: 2.3036067287127175

Epoch: 6| Step: 12
Training loss: 0.45842045545578003
Validation loss: 2.222512443860372

Epoch: 6| Step: 13
Training loss: 0.20159567892551422
Validation loss: 2.24019988377889

Epoch: 328| Step: 0
Training loss: 0.36512327194213867
Validation loss: 2.2544131676355996

Epoch: 6| Step: 1
Training loss: 0.23561906814575195
Validation loss: 2.2140849828720093

Epoch: 6| Step: 2
Training loss: 0.3758366107940674
Validation loss: 2.257838408152262

Epoch: 6| Step: 3
Training loss: 0.8810015320777893
Validation loss: 2.2626123825709024

Epoch: 6| Step: 4
Training loss: 0.4956800639629364
Validation loss: 2.2161924044291177

Epoch: 6| Step: 5
Training loss: 0.3528313934803009
Validation loss: 2.2243609031041465

Epoch: 6| Step: 6
Training loss: 0.5775936245918274
Validation loss: 2.243097484111786

Epoch: 6| Step: 7
Training loss: 0.4005390703678131
Validation loss: 2.26583860317866

Epoch: 6| Step: 8
Training loss: 0.23011894524097443
Validation loss: 2.2923102180163064

Epoch: 6| Step: 9
Training loss: 0.8079066276550293
Validation loss: 2.309382418791453

Epoch: 6| Step: 10
Training loss: 0.5570885539054871
Validation loss: 2.2797042528788247

Epoch: 6| Step: 11
Training loss: 0.373562753200531
Validation loss: 2.2516543865203857

Epoch: 6| Step: 12
Training loss: 0.37037622928619385
Validation loss: 2.207432746887207

Epoch: 6| Step: 13
Training loss: 0.38597553968429565
Validation loss: 2.238077402114868

Epoch: 329| Step: 0
Training loss: 0.3355688154697418
Validation loss: 2.2186622619628906

Epoch: 6| Step: 1
Training loss: 0.30236250162124634
Validation loss: 2.246895213921865

Epoch: 6| Step: 2
Training loss: 0.5617712736129761
Validation loss: 2.221112052599589

Epoch: 6| Step: 3
Training loss: 0.5768436193466187
Validation loss: 2.28160697221756

Epoch: 6| Step: 4
Training loss: 0.30190709233283997
Validation loss: 2.2438841462135315

Epoch: 6| Step: 5
Training loss: 0.3720405697822571
Validation loss: 2.28825451930364

Epoch: 6| Step: 6
Training loss: 0.7383840084075928
Validation loss: 2.2057146430015564

Epoch: 6| Step: 7
Training loss: 0.5370336771011353
Validation loss: 2.260361631711324

Epoch: 6| Step: 8
Training loss: 0.41576021909713745
Validation loss: 2.2266536951065063

Epoch: 6| Step: 9
Training loss: 0.5617876052856445
Validation loss: 2.2316487630208335

Epoch: 6| Step: 10
Training loss: 0.5172518491744995
Validation loss: 2.1794659892717996

Epoch: 6| Step: 11
Training loss: 0.45640280842781067
Validation loss: 2.2600563367207847

Epoch: 6| Step: 12
Training loss: 0.39010846614837646
Validation loss: 2.303613603115082

Epoch: 6| Step: 13
Training loss: 0.3164438009262085
Validation loss: 2.2773417433102927

Epoch: 330| Step: 0
Training loss: 0.8675466775894165
Validation loss: 2.2710548639297485

Epoch: 6| Step: 1
Training loss: 0.2929879426956177
Validation loss: 2.2548577388127646

Epoch: 6| Step: 2
Training loss: 0.42443007230758667
Validation loss: 2.26132599512736

Epoch: 6| Step: 3
Training loss: 0.39204734563827515
Validation loss: 2.2586578925450644

Epoch: 6| Step: 4
Training loss: 0.27390992641448975
Validation loss: 2.2684832016626992

Epoch: 6| Step: 5
Training loss: 0.43269118666648865
Validation loss: 2.253401776154836

Epoch: 6| Step: 6
Training loss: 0.2920790910720825
Validation loss: 2.2741912603378296

Epoch: 6| Step: 7
Training loss: 0.33052825927734375
Validation loss: 2.2551006078720093

Epoch: 6| Step: 8
Training loss: 0.7930309772491455
Validation loss: 2.2482928037643433

Epoch: 6| Step: 9
Training loss: 0.5910066366195679
Validation loss: 2.2496846119562783

Epoch: 6| Step: 10
Training loss: 0.33649319410324097
Validation loss: 2.2374276717503867

Epoch: 6| Step: 11
Training loss: 0.25881657004356384
Validation loss: 2.2364527185757956

Epoch: 6| Step: 12
Training loss: 0.31749963760375977
Validation loss: 2.2226285537083945

Epoch: 6| Step: 13
Training loss: 0.5174871683120728
Validation loss: 2.2331295808156333

Epoch: 331| Step: 0
Training loss: 0.26005223393440247
Validation loss: 2.278762181599935

Epoch: 6| Step: 1
Training loss: 0.23685012757778168
Validation loss: 2.210584541161855

Epoch: 6| Step: 2
Training loss: 0.2522789239883423
Validation loss: 2.2288794120152793

Epoch: 6| Step: 3
Training loss: 0.4674621820449829
Validation loss: 2.312380572160085

Epoch: 6| Step: 4
Training loss: 0.47861969470977783
Validation loss: 2.2395498355229697

Epoch: 6| Step: 5
Training loss: 0.6140778064727783
Validation loss: 2.2706987261772156

Epoch: 6| Step: 6
Training loss: 0.3490183353424072
Validation loss: 2.2732678254445395

Epoch: 6| Step: 7
Training loss: 0.5794967412948608
Validation loss: 2.2342499494552612

Epoch: 6| Step: 8
Training loss: 0.24214762449264526
Validation loss: 2.2604682048161826

Epoch: 6| Step: 9
Training loss: 0.47299283742904663
Validation loss: 2.2502785523732505

Epoch: 6| Step: 10
Training loss: 0.2882908582687378
Validation loss: 2.2547448674837747

Epoch: 6| Step: 11
Training loss: 1.0162665843963623
Validation loss: 2.2618923584620156

Epoch: 6| Step: 12
Training loss: 0.3438347578048706
Validation loss: 2.300193806489309

Epoch: 6| Step: 13
Training loss: 0.32829079031944275
Validation loss: 2.2507373889287314

Epoch: 332| Step: 0
Training loss: 0.22353368997573853
Validation loss: 2.2410340507825217

Epoch: 6| Step: 1
Training loss: 0.2334771603345871
Validation loss: 2.291386087735494

Epoch: 6| Step: 2
Training loss: 0.6436706781387329
Validation loss: 2.240295966466268

Epoch: 6| Step: 3
Training loss: 0.4216528534889221
Validation loss: 2.262749175230662

Epoch: 6| Step: 4
Training loss: 0.5473679900169373
Validation loss: 2.2545204957326255

Epoch: 6| Step: 5
Training loss: 0.6961077451705933
Validation loss: 2.2724342346191406

Epoch: 6| Step: 6
Training loss: 0.779620885848999
Validation loss: 2.3118380109469094

Epoch: 6| Step: 7
Training loss: 0.2538250982761383
Validation loss: 2.27456796169281

Epoch: 6| Step: 8
Training loss: 0.3994187116622925
Validation loss: 2.3045066197713218

Epoch: 6| Step: 9
Training loss: 0.20892132818698883
Validation loss: 2.2854976256688437

Epoch: 6| Step: 10
Training loss: 0.4162539839744568
Validation loss: 2.250450531641642

Epoch: 6| Step: 11
Training loss: 0.35099536180496216
Validation loss: 2.3100847601890564

Epoch: 6| Step: 12
Training loss: 0.35543540120124817
Validation loss: 2.2597915132840476

Epoch: 6| Step: 13
Training loss: 0.18734949827194214
Validation loss: 2.2516896724700928

Epoch: 333| Step: 0
Training loss: 0.2803284525871277
Validation loss: 2.237998644510905

Epoch: 6| Step: 1
Training loss: 0.33506715297698975
Validation loss: 2.2933449149131775

Epoch: 6| Step: 2
Training loss: 0.4863016903400421
Validation loss: 2.229391117890676

Epoch: 6| Step: 3
Training loss: 0.30099356174468994
Validation loss: 2.2851831515630088

Epoch: 6| Step: 4
Training loss: 0.3283458948135376
Validation loss: 2.2747358481089273

Epoch: 6| Step: 5
Training loss: 0.49737656116485596
Validation loss: 2.231805423895518

Epoch: 6| Step: 6
Training loss: 0.5782500505447388
Validation loss: 2.291942914326986

Epoch: 6| Step: 7
Training loss: 0.29969531297683716
Validation loss: 2.208656132221222

Epoch: 6| Step: 8
Training loss: 0.33044499158859253
Validation loss: 2.227033813794454

Epoch: 6| Step: 9
Training loss: 0.6780363321304321
Validation loss: 2.2403948505719504

Epoch: 6| Step: 10
Training loss: 0.43743085861206055
Validation loss: 2.261567989985148

Epoch: 6| Step: 11
Training loss: 0.6073797941207886
Validation loss: 2.3003562688827515

Epoch: 6| Step: 12
Training loss: 0.4714623689651489
Validation loss: 2.182916045188904

Epoch: 6| Step: 13
Training loss: 0.24533602595329285
Validation loss: 2.234076658884684

Epoch: 334| Step: 0
Training loss: 0.641179084777832
Validation loss: 2.2565648754437766

Epoch: 6| Step: 1
Training loss: 0.5962786674499512
Validation loss: 2.269694209098816

Epoch: 6| Step: 2
Training loss: 0.53713458776474
Validation loss: 2.233993669350942

Epoch: 6| Step: 3
Training loss: 0.2462247908115387
Validation loss: 2.230842729409536

Epoch: 6| Step: 4
Training loss: 0.4293745756149292
Validation loss: 2.2827391823132834

Epoch: 6| Step: 5
Training loss: 0.37050938606262207
Validation loss: 2.2369616826375327

Epoch: 6| Step: 6
Training loss: 0.2648617625236511
Validation loss: 2.2465032736460366

Epoch: 6| Step: 7
Training loss: 0.4393638074398041
Validation loss: 2.282983660697937

Epoch: 6| Step: 8
Training loss: 0.6470452547073364
Validation loss: 2.2326162258783975

Epoch: 6| Step: 9
Training loss: 0.2911011278629303
Validation loss: 2.2634668548901877

Epoch: 6| Step: 10
Training loss: 0.14026355743408203
Validation loss: 2.2174419164657593

Epoch: 6| Step: 11
Training loss: 0.6011391282081604
Validation loss: 2.2123164931933084

Epoch: 6| Step: 12
Training loss: 0.2402004599571228
Validation loss: 2.2495578130086265

Epoch: 6| Step: 13
Training loss: 1.029807209968567
Validation loss: 2.31065305074056

Epoch: 335| Step: 0
Training loss: 0.3072887063026428
Validation loss: 2.239714523156484

Epoch: 6| Step: 1
Training loss: 0.23852132260799408
Validation loss: 2.292164941628774

Epoch: 6| Step: 2
Training loss: 0.568224310874939
Validation loss: 2.288604458173116

Epoch: 6| Step: 3
Training loss: 0.6279388666152954
Validation loss: 2.224320948123932

Epoch: 6| Step: 4
Training loss: 0.41155344247817993
Validation loss: 2.249394496281942

Epoch: 6| Step: 5
Training loss: 0.513245165348053
Validation loss: 2.295712391535441

Epoch: 6| Step: 6
Training loss: 0.38672688603401184
Validation loss: 2.2354139486948648

Epoch: 6| Step: 7
Training loss: 0.37486377358436584
Validation loss: 2.2489370703697205

Epoch: 6| Step: 8
Training loss: 0.3032892942428589
Validation loss: 2.252890487511953

Epoch: 6| Step: 9
Training loss: 0.25347447395324707
Validation loss: 2.250331699848175

Epoch: 6| Step: 10
Training loss: 0.5468431711196899
Validation loss: 2.2773675521214805

Epoch: 6| Step: 11
Training loss: 0.5896756649017334
Validation loss: 2.2571498354276023

Epoch: 6| Step: 12
Training loss: 0.626141369342804
Validation loss: 2.260609805583954

Epoch: 6| Step: 13
Training loss: 0.4043561816215515
Validation loss: 2.2635693351427713

Epoch: 336| Step: 0
Training loss: 0.3166022002696991
Validation loss: 2.279942274093628

Epoch: 6| Step: 1
Training loss: 0.3034268021583557
Validation loss: 2.1978086630503335

Epoch: 6| Step: 2
Training loss: 0.36035436391830444
Validation loss: 2.257895906766256

Epoch: 6| Step: 3
Training loss: 0.40285059809684753
Validation loss: 2.222076872984568

Epoch: 6| Step: 4
Training loss: 0.9534045457839966
Validation loss: 2.2930575609207153

Epoch: 6| Step: 5
Training loss: 0.3830258846282959
Validation loss: 2.2570060888926187

Epoch: 6| Step: 6
Training loss: 0.3369399309158325
Validation loss: 2.2766120433807373

Epoch: 6| Step: 7
Training loss: 0.43709316849708557
Validation loss: 2.2820211052894592

Epoch: 6| Step: 8
Training loss: 0.40367552638053894
Validation loss: 2.2580679853757224

Epoch: 6| Step: 9
Training loss: 0.5326796174049377
Validation loss: 2.2476828694343567

Epoch: 6| Step: 10
Training loss: 0.3094526529312134
Validation loss: 2.282587190469106

Epoch: 6| Step: 11
Training loss: 0.8569523096084595
Validation loss: 2.2826420267422995

Epoch: 6| Step: 12
Training loss: 0.37391942739486694
Validation loss: 2.24984476963679

Epoch: 6| Step: 13
Training loss: 0.359552264213562
Validation loss: 2.2447644074757895

Epoch: 337| Step: 0
Training loss: 0.5957883596420288
Validation loss: 2.2698703606923423

Epoch: 6| Step: 1
Training loss: 0.7949837446212769
Validation loss: 2.2499708930651345

Epoch: 6| Step: 2
Training loss: 0.2546599805355072
Validation loss: 2.291695694128672

Epoch: 6| Step: 3
Training loss: 0.22371333837509155
Validation loss: 2.2589380939801535

Epoch: 6| Step: 4
Training loss: 0.4855008125305176
Validation loss: 2.288291613260905

Epoch: 6| Step: 5
Training loss: 0.44844698905944824
Validation loss: 2.284315307935079

Epoch: 6| Step: 6
Training loss: 0.3337453305721283
Validation loss: 2.2728704810142517

Epoch: 6| Step: 7
Training loss: 0.598983645439148
Validation loss: 2.2554458578427634

Epoch: 6| Step: 8
Training loss: 0.42775923013687134
Validation loss: 2.2577479084332785

Epoch: 6| Step: 9
Training loss: 0.6305476427078247
Validation loss: 2.2845211823781333

Epoch: 6| Step: 10
Training loss: 0.31029564142227173
Validation loss: 2.2598045269648233

Epoch: 6| Step: 11
Training loss: 0.41404032707214355
Validation loss: 2.2614335417747498

Epoch: 6| Step: 12
Training loss: 0.37956464290618896
Validation loss: 2.26848441362381

Epoch: 6| Step: 13
Training loss: 0.4359346926212311
Validation loss: 2.2367888490358987

Epoch: 338| Step: 0
Training loss: 0.5889111161231995
Validation loss: 2.249187449614207

Epoch: 6| Step: 1
Training loss: 0.21287374198436737
Validation loss: 2.3199711243311563

Epoch: 6| Step: 2
Training loss: 0.4480040669441223
Validation loss: 2.2486703197161355

Epoch: 6| Step: 3
Training loss: 0.4598439335823059
Validation loss: 2.268849809964498

Epoch: 6| Step: 4
Training loss: 0.5729736089706421
Validation loss: 2.284501830736796

Epoch: 6| Step: 5
Training loss: 0.16890272498130798
Validation loss: 2.2255221605300903

Epoch: 6| Step: 6
Training loss: 0.5668207406997681
Validation loss: 2.2569010257720947

Epoch: 6| Step: 7
Training loss: 0.7860146760940552
Validation loss: 2.2245768706003823

Epoch: 6| Step: 8
Training loss: 0.27763062715530396
Validation loss: 2.271735111872355

Epoch: 6| Step: 9
Training loss: 0.45461684465408325
Validation loss: 2.2979111075401306

Epoch: 6| Step: 10
Training loss: 0.3762669861316681
Validation loss: 2.2560972770055137

Epoch: 6| Step: 11
Training loss: 0.47705549001693726
Validation loss: 2.247104903062185

Epoch: 6| Step: 12
Training loss: 0.35735785961151123
Validation loss: 2.251032988230387

Epoch: 6| Step: 13
Training loss: 0.4999394416809082
Validation loss: 2.2649525006612143

Epoch: 339| Step: 0
Training loss: 0.8145297765731812
Validation loss: 2.255380630493164

Epoch: 6| Step: 1
Training loss: 0.3004329800605774
Validation loss: 2.246068318684896

Epoch: 6| Step: 2
Training loss: 0.4431559145450592
Validation loss: 2.268424073855082

Epoch: 6| Step: 3
Training loss: 0.20932886004447937
Validation loss: 2.242292881011963

Epoch: 6| Step: 4
Training loss: 0.3291001617908478
Validation loss: 2.2216662565867105

Epoch: 6| Step: 5
Training loss: 0.5090845823287964
Validation loss: 2.2869818011919656

Epoch: 6| Step: 6
Training loss: 0.449602872133255
Validation loss: 2.308661242326101

Epoch: 6| Step: 7
Training loss: 0.37560856342315674
Validation loss: 2.3328757683436074

Epoch: 6| Step: 8
Training loss: 0.2753087282180786
Validation loss: 2.299016078313192

Epoch: 6| Step: 9
Training loss: 0.7799166440963745
Validation loss: 2.2501598993937173

Epoch: 6| Step: 10
Training loss: 0.4853435754776001
Validation loss: 2.27031809091568

Epoch: 6| Step: 11
Training loss: 0.5397545099258423
Validation loss: 2.272126038869222

Epoch: 6| Step: 12
Training loss: 0.31057047843933105
Validation loss: 2.2217180728912354

Epoch: 6| Step: 13
Training loss: 0.42321860790252686
Validation loss: 2.251524825890859

Epoch: 340| Step: 0
Training loss: 0.48050934076309204
Validation loss: 2.271384080251058

Epoch: 6| Step: 1
Training loss: 0.342252641916275
Validation loss: 2.2520691752433777

Epoch: 6| Step: 2
Training loss: 0.28896859288215637
Validation loss: 2.2581294973691306

Epoch: 6| Step: 3
Training loss: 0.3307151198387146
Validation loss: 2.2477102875709534

Epoch: 6| Step: 4
Training loss: 0.34366902709007263
Validation loss: 2.208597163359324

Epoch: 6| Step: 5
Training loss: 0.2922562062740326
Validation loss: 2.287129024664561

Epoch: 6| Step: 6
Training loss: 0.3120252788066864
Validation loss: 2.272886792818705

Epoch: 6| Step: 7
Training loss: 0.7656420469284058
Validation loss: 2.2977793216705322

Epoch: 6| Step: 8
Training loss: 0.43064790964126587
Validation loss: 2.2369954188664756

Epoch: 6| Step: 9
Training loss: 0.9039015173912048
Validation loss: 2.2513086199760437

Epoch: 6| Step: 10
Training loss: 0.5886275172233582
Validation loss: 2.25423671801885

Epoch: 6| Step: 11
Training loss: 0.21567022800445557
Validation loss: 2.2482457955678306

Epoch: 6| Step: 12
Training loss: 0.5318257808685303
Validation loss: 2.2535150051116943

Epoch: 6| Step: 13
Training loss: 0.28210410475730896
Validation loss: 2.2260262966156006

Epoch: 341| Step: 0
Training loss: 0.5474318861961365
Validation loss: 2.2602924903233848

Epoch: 6| Step: 1
Training loss: 0.17453792691230774
Validation loss: 2.2619087298711142

Epoch: 6| Step: 2
Training loss: 0.38959765434265137
Validation loss: 2.2491400639216104

Epoch: 6| Step: 3
Training loss: 0.18173913657665253
Validation loss: 2.238316019376119

Epoch: 6| Step: 4
Training loss: 0.37133610248565674
Validation loss: 2.2327627738316855

Epoch: 6| Step: 5
Training loss: 0.7882918119430542
Validation loss: 2.215456942717234

Epoch: 6| Step: 6
Training loss: 0.32067999243736267
Validation loss: 2.2399030923843384

Epoch: 6| Step: 7
Training loss: 0.2501511573791504
Validation loss: 2.202885627746582

Epoch: 6| Step: 8
Training loss: 0.5468631386756897
Validation loss: 2.23456080754598

Epoch: 6| Step: 9
Training loss: 0.36338862776756287
Validation loss: 2.2503397464752197

Epoch: 6| Step: 10
Training loss: 0.4283827245235443
Validation loss: 2.273794730504354

Epoch: 6| Step: 11
Training loss: 0.39970144629478455
Validation loss: 2.285426119963328

Epoch: 6| Step: 12
Training loss: 0.6962152719497681
Validation loss: 2.2746987342834473

Epoch: 6| Step: 13
Training loss: 0.34554052352905273
Validation loss: 2.2876100738843284

Epoch: 342| Step: 0
Training loss: 0.3589087128639221
Validation loss: 2.2155000368754068

Epoch: 6| Step: 1
Training loss: 0.3245672583580017
Validation loss: 2.2307947079340615

Epoch: 6| Step: 2
Training loss: 0.3036476969718933
Validation loss: 2.2465043862660727

Epoch: 6| Step: 3
Training loss: 0.47059062123298645
Validation loss: 2.2420881191889444

Epoch: 6| Step: 4
Training loss: 0.38316985964775085
Validation loss: 2.254337271054586

Epoch: 6| Step: 5
Training loss: 0.24025441706180573
Validation loss: 2.2599726915359497

Epoch: 6| Step: 6
Training loss: 0.6796746253967285
Validation loss: 2.2303556005160012

Epoch: 6| Step: 7
Training loss: 0.8010650873184204
Validation loss: 2.248474419116974

Epoch: 6| Step: 8
Training loss: 0.24975258111953735
Validation loss: 2.229068656762441

Epoch: 6| Step: 9
Training loss: 0.5870803594589233
Validation loss: 2.20149298508962

Epoch: 6| Step: 10
Training loss: 0.35913631319999695
Validation loss: 2.1651597221692405

Epoch: 6| Step: 11
Training loss: 0.2992170751094818
Validation loss: 2.192389706770579

Epoch: 6| Step: 12
Training loss: 0.531225323677063
Validation loss: 2.230609913667043

Epoch: 6| Step: 13
Training loss: 0.5417324304580688
Validation loss: 2.2053834199905396

Epoch: 343| Step: 0
Training loss: 0.850536048412323
Validation loss: 2.1948809822400412

Epoch: 6| Step: 1
Training loss: 0.3368196487426758
Validation loss: 2.2644535501797995

Epoch: 6| Step: 2
Training loss: 0.4293619990348816
Validation loss: 2.2658356030782065

Epoch: 6| Step: 3
Training loss: 0.26545220613479614
Validation loss: 2.2581812540690103

Epoch: 6| Step: 4
Training loss: 0.2831132709980011
Validation loss: 2.2101818919181824

Epoch: 6| Step: 5
Training loss: 0.643210232257843
Validation loss: 2.229841430981954

Epoch: 6| Step: 6
Training loss: 0.48642680048942566
Validation loss: 2.22896937529246

Epoch: 6| Step: 7
Training loss: 0.25367435812950134
Validation loss: 2.2334435979525247

Epoch: 6| Step: 8
Training loss: 0.521331787109375
Validation loss: 2.231962521870931

Epoch: 6| Step: 9
Training loss: 0.3262157440185547
Validation loss: 2.225495934486389

Epoch: 6| Step: 10
Training loss: 0.3492399752140045
Validation loss: 2.310959736506144

Epoch: 6| Step: 11
Training loss: 0.8224464654922485
Validation loss: 2.226072986920675

Epoch: 6| Step: 12
Training loss: 0.44870725274086
Validation loss: 2.241717219352722

Epoch: 6| Step: 13
Training loss: 0.3565464913845062
Validation loss: 2.2479096253712973

Epoch: 344| Step: 0
Training loss: 0.3211425542831421
Validation loss: 2.2396583557128906

Epoch: 6| Step: 1
Training loss: 0.5555801391601562
Validation loss: 2.229318896929423

Epoch: 6| Step: 2
Training loss: 0.44206109642982483
Validation loss: 2.1941193342208862

Epoch: 6| Step: 3
Training loss: 0.3027766942977905
Validation loss: 2.2563862403233848

Epoch: 6| Step: 4
Training loss: 0.3430519700050354
Validation loss: 2.2418669064839682

Epoch: 6| Step: 5
Training loss: 0.3650134205818176
Validation loss: 2.2201568285624185

Epoch: 6| Step: 6
Training loss: 0.5685622692108154
Validation loss: 2.212007224559784

Epoch: 6| Step: 7
Training loss: 0.329689085483551
Validation loss: 2.2368911504745483

Epoch: 6| Step: 8
Training loss: 0.31283584237098694
Validation loss: 2.25436270236969

Epoch: 6| Step: 9
Training loss: 0.40473678708076477
Validation loss: 2.229925553003947

Epoch: 6| Step: 10
Training loss: 0.4514352083206177
Validation loss: 2.2773107290267944

Epoch: 6| Step: 11
Training loss: 0.46938836574554443
Validation loss: 2.2942042350769043

Epoch: 6| Step: 12
Training loss: 0.7746394276618958
Validation loss: 2.2439571420351663

Epoch: 6| Step: 13
Training loss: 0.4342930316925049
Validation loss: 2.2382110357284546

Epoch: 345| Step: 0
Training loss: 0.7384732961654663
Validation loss: 2.26334019502004

Epoch: 6| Step: 1
Training loss: 0.2160363495349884
Validation loss: 2.2461134990056357

Epoch: 6| Step: 2
Training loss: 0.7476636171340942
Validation loss: 2.207658270994822

Epoch: 6| Step: 3
Training loss: 0.5241273045539856
Validation loss: 2.23705126841863

Epoch: 6| Step: 4
Training loss: 0.3184855580329895
Validation loss: 2.237226923306783

Epoch: 6| Step: 5
Training loss: 0.1325061023235321
Validation loss: 2.263341744740804

Epoch: 6| Step: 6
Training loss: 0.19096305966377258
Validation loss: 2.2569539149602256

Epoch: 6| Step: 7
Training loss: 0.4226270616054535
Validation loss: 2.2436497807502747

Epoch: 6| Step: 8
Training loss: 0.49385759234428406
Validation loss: 2.290417472521464

Epoch: 6| Step: 9
Training loss: 0.42270201444625854
Validation loss: 2.2556938330332437

Epoch: 6| Step: 10
Training loss: 0.3312946557998657
Validation loss: 2.1938263972600303

Epoch: 6| Step: 11
Training loss: 0.20477384328842163
Validation loss: 2.2596036394437156

Epoch: 6| Step: 12
Training loss: 0.32401683926582336
Validation loss: 2.2796446879704795

Epoch: 6| Step: 13
Training loss: 0.3990548253059387
Validation loss: 2.27670286099116

Epoch: 346| Step: 0
Training loss: 0.4116894602775574
Validation loss: 2.2647674282391868

Epoch: 6| Step: 1
Training loss: 0.4132113456726074
Validation loss: 2.2496068874994912

Epoch: 6| Step: 2
Training loss: 0.5011657476425171
Validation loss: 2.209108889102936

Epoch: 6| Step: 3
Training loss: 0.40809792280197144
Validation loss: 2.2347523967425027

Epoch: 6| Step: 4
Training loss: 0.4549819827079773
Validation loss: 2.230602244536082

Epoch: 6| Step: 5
Training loss: 0.8484876155853271
Validation loss: 2.3235520720481873

Epoch: 6| Step: 6
Training loss: 0.39266183972358704
Validation loss: 2.2297399838765464

Epoch: 6| Step: 7
Training loss: 0.3094025254249573
Validation loss: 2.2339341044425964

Epoch: 6| Step: 8
Training loss: 0.5154707431793213
Validation loss: 2.2203940947850547

Epoch: 6| Step: 9
Training loss: 0.24698591232299805
Validation loss: 2.292494257291158

Epoch: 6| Step: 10
Training loss: 0.49854546785354614
Validation loss: 2.274568498134613

Epoch: 6| Step: 11
Training loss: 0.38649922609329224
Validation loss: 2.263241986433665

Epoch: 6| Step: 12
Training loss: 0.6718910336494446
Validation loss: 2.257817029953003

Epoch: 6| Step: 13
Training loss: 0.3253399431705475
Validation loss: 2.2220118045806885

Epoch: 347| Step: 0
Training loss: 0.2592501640319824
Validation loss: 2.268023451169332

Epoch: 6| Step: 1
Training loss: 0.6263899803161621
Validation loss: 2.2032818595568338

Epoch: 6| Step: 2
Training loss: 0.3559337258338928
Validation loss: 2.248957872390747

Epoch: 6| Step: 3
Training loss: 0.2910950183868408
Validation loss: 2.220117708047231

Epoch: 6| Step: 4
Training loss: 0.42536866664886475
Validation loss: 2.2514630953470864

Epoch: 6| Step: 5
Training loss: 0.6242413520812988
Validation loss: 2.2394148310025535

Epoch: 6| Step: 6
Training loss: 0.33992040157318115
Validation loss: 2.289540727933248

Epoch: 6| Step: 7
Training loss: 0.4040822982788086
Validation loss: 2.259449541568756

Epoch: 6| Step: 8
Training loss: 0.2736116051673889
Validation loss: 2.300941308339437

Epoch: 6| Step: 9
Training loss: 0.3007254898548126
Validation loss: 2.2587340474128723

Epoch: 6| Step: 10
Training loss: 0.9093380570411682
Validation loss: 2.2558263738950095

Epoch: 6| Step: 11
Training loss: 0.39423197507858276
Validation loss: 2.316518863042196

Epoch: 6| Step: 12
Training loss: 0.4293251633644104
Validation loss: 2.2448474367459617

Epoch: 6| Step: 13
Training loss: 0.2621799409389496
Validation loss: 2.2355353633562722

Epoch: 348| Step: 0
Training loss: 0.2832796573638916
Validation loss: 2.2722174723943076

Epoch: 6| Step: 1
Training loss: 0.32000744342803955
Validation loss: 2.2327532370885215

Epoch: 6| Step: 2
Training loss: 0.3882717490196228
Validation loss: 2.292059063911438

Epoch: 6| Step: 3
Training loss: 0.2907457947731018
Validation loss: 2.276800791422526

Epoch: 6| Step: 4
Training loss: 0.5938044190406799
Validation loss: 2.270276049772898

Epoch: 6| Step: 5
Training loss: 0.3438776135444641
Validation loss: 2.2554022073745728

Epoch: 6| Step: 6
Training loss: 0.812247633934021
Validation loss: 2.257421592871348

Epoch: 6| Step: 7
Training loss: 0.2789069414138794
Validation loss: 2.2800638477007547

Epoch: 6| Step: 8
Training loss: 0.22587528824806213
Validation loss: 2.286754568417867

Epoch: 6| Step: 9
Training loss: 0.3212481141090393
Validation loss: 2.2881217002868652

Epoch: 6| Step: 10
Training loss: 0.2205357700586319
Validation loss: 2.293738305568695

Epoch: 6| Step: 11
Training loss: 0.6770391464233398
Validation loss: 2.2844516038894653

Epoch: 6| Step: 12
Training loss: 0.647220253944397
Validation loss: 2.280924220879873

Epoch: 6| Step: 13
Training loss: 0.44921547174453735
Validation loss: 2.3161503275235495

Epoch: 349| Step: 0
Training loss: 0.5166953802108765
Validation loss: 2.2740837732950845

Epoch: 6| Step: 1
Training loss: 0.6783784627914429
Validation loss: 2.2989322741826377

Epoch: 6| Step: 2
Training loss: 0.2601884603500366
Validation loss: 2.2517420848210654

Epoch: 6| Step: 3
Training loss: 0.2889159321784973
Validation loss: 2.2766189177831015

Epoch: 6| Step: 4
Training loss: 0.29022639989852905
Validation loss: 2.2247034112612405

Epoch: 6| Step: 5
Training loss: 0.26659777760505676
Validation loss: 2.23783145348231

Epoch: 6| Step: 6
Training loss: 0.3849714994430542
Validation loss: 2.2469410498936973

Epoch: 6| Step: 7
Training loss: 0.25363945960998535
Validation loss: 2.2297351360321045

Epoch: 6| Step: 8
Training loss: 0.3736293911933899
Validation loss: 2.2828151186307273

Epoch: 6| Step: 9
Training loss: 0.4606545865535736
Validation loss: 2.2758790055910745

Epoch: 6| Step: 10
Training loss: 0.24312400817871094
Validation loss: 2.2482338547706604

Epoch: 6| Step: 11
Training loss: 0.8359797596931458
Validation loss: 2.264590938886007

Epoch: 6| Step: 12
Training loss: 0.800499439239502
Validation loss: 2.271709938844045

Epoch: 6| Step: 13
Training loss: 0.21864856779575348
Validation loss: 2.310982624689738

Epoch: 350| Step: 0
Training loss: 0.3359021544456482
Validation loss: 2.308721582094828

Epoch: 6| Step: 1
Training loss: 0.3107231855392456
Validation loss: 2.305518865585327

Epoch: 6| Step: 2
Training loss: 0.49698156118392944
Validation loss: 2.257498621940613

Epoch: 6| Step: 3
Training loss: 0.5665656328201294
Validation loss: 2.264619986216227

Epoch: 6| Step: 4
Training loss: 0.8559664487838745
Validation loss: 2.301350394884745

Epoch: 6| Step: 5
Training loss: 0.38873380422592163
Validation loss: 2.246528665224711

Epoch: 6| Step: 6
Training loss: 0.2871263325214386
Validation loss: 2.2429840564727783

Epoch: 6| Step: 7
Training loss: 0.2467564344406128
Validation loss: 2.2537912329037986

Epoch: 6| Step: 8
Training loss: 0.2799533009529114
Validation loss: 2.2450136144955954

Epoch: 6| Step: 9
Training loss: 0.2513597905635834
Validation loss: 2.200467308362325

Epoch: 6| Step: 10
Training loss: 0.7563213109970093
Validation loss: 2.221562445163727

Epoch: 6| Step: 11
Training loss: 0.6886159181594849
Validation loss: 2.2213560740152993

Epoch: 6| Step: 12
Training loss: 0.465511679649353
Validation loss: 2.268295168876648

Epoch: 6| Step: 13
Training loss: 0.2136373519897461
Validation loss: 2.2481300830841064

Testing loss: 2.229226524023701
