Epoch: 1| Step: 0
Training loss: 6.670544624328613
Validation loss: 6.5847034851710005

Epoch: 5| Step: 1
Training loss: 5.936665058135986
Validation loss: 6.56175313393275

Epoch: 5| Step: 2
Training loss: 6.337693214416504
Validation loss: 6.538066486517589

Epoch: 5| Step: 3
Training loss: 6.658808708190918
Validation loss: 6.511635621388753

Epoch: 5| Step: 4
Training loss: 6.67517614364624
Validation loss: 6.491812368233998

Epoch: 5| Step: 5
Training loss: 6.622234344482422
Validation loss: 6.467786550521851

Epoch: 5| Step: 6
Training loss: 6.9159255027771
Validation loss: 6.4491516550381975

Epoch: 5| Step: 7
Training loss: 7.081032752990723
Validation loss: 6.426596204439799

Epoch: 5| Step: 8
Training loss: 6.018496513366699
Validation loss: 6.405899703502655

Epoch: 5| Step: 9
Training loss: 6.055850028991699
Validation loss: 6.381493449211121

Epoch: 5| Step: 10
Training loss: 6.508208274841309
Validation loss: 6.360057592391968

Epoch: 5| Step: 11
Training loss: 8.553790092468262
Validation loss: 6.334731260935466

Epoch: 2| Step: 0
Training loss: 7.342980861663818
Validation loss: 6.30908985932668

Epoch: 5| Step: 1
Training loss: 6.9392218589782715
Validation loss: 6.280136545499166

Epoch: 5| Step: 2
Training loss: 4.341348648071289
Validation loss: 6.248666763305664

Epoch: 5| Step: 3
Training loss: 7.376593589782715
Validation loss: 6.219908356666565

Epoch: 5| Step: 4
Training loss: 5.754413604736328
Validation loss: 6.181772033373515

Epoch: 5| Step: 5
Training loss: 6.6302947998046875
Validation loss: 6.14798100789388

Epoch: 5| Step: 6
Training loss: 5.898116111755371
Validation loss: 6.1146825949351

Epoch: 5| Step: 7
Training loss: 6.524081230163574
Validation loss: 6.075328131516774

Epoch: 5| Step: 8
Training loss: 5.866644859313965
Validation loss: 6.037255942821503

Epoch: 5| Step: 9
Training loss: 5.464829444885254
Validation loss: 5.997677048047383

Epoch: 5| Step: 10
Training loss: 6.322790622711182
Validation loss: 5.959059437115987

Epoch: 5| Step: 11
Training loss: 4.854327201843262
Validation loss: 5.9112041393915815

Epoch: 3| Step: 0
Training loss: 5.749224662780762
Validation loss: 5.863498051961263

Epoch: 5| Step: 1
Training loss: 6.961999416351318
Validation loss: 5.8243711193402605

Epoch: 5| Step: 2
Training loss: 5.731270790100098
Validation loss: 5.774091958999634

Epoch: 5| Step: 3
Training loss: 6.541583061218262
Validation loss: 5.723303596178691

Epoch: 5| Step: 4
Training loss: 5.60178804397583
Validation loss: 5.670510729153951

Epoch: 5| Step: 5
Training loss: 6.110958576202393
Validation loss: 5.616648356119792

Epoch: 5| Step: 6
Training loss: 4.467584133148193
Validation loss: 5.560096859931946

Epoch: 5| Step: 7
Training loss: 6.407207489013672
Validation loss: 5.505352258682251

Epoch: 5| Step: 8
Training loss: 5.022474765777588
Validation loss: 5.43474413951238

Epoch: 5| Step: 9
Training loss: 4.572058200836182
Validation loss: 5.36982677380244

Epoch: 5| Step: 10
Training loss: 4.921553611755371
Validation loss: 5.301519274711609

Epoch: 5| Step: 11
Training loss: 6.390758037567139
Validation loss: 5.239517986774445

Epoch: 4| Step: 0
Training loss: 4.460756778717041
Validation loss: 5.160981317361196

Epoch: 5| Step: 1
Training loss: 5.777113914489746
Validation loss: 5.082921544710795

Epoch: 5| Step: 2
Training loss: 4.703906059265137
Validation loss: 5.017988085746765

Epoch: 5| Step: 3
Training loss: 5.733937740325928
Validation loss: 4.928745627403259

Epoch: 5| Step: 4
Training loss: 5.169149398803711
Validation loss: 4.835795720418294

Epoch: 5| Step: 5
Training loss: 4.205347537994385
Validation loss: 4.752543479204178

Epoch: 5| Step: 6
Training loss: 4.476731777191162
Validation loss: 4.674127846956253

Epoch: 5| Step: 7
Training loss: 4.269780158996582
Validation loss: 4.584769864877065

Epoch: 5| Step: 8
Training loss: 3.7811837196350098
Validation loss: 4.483927736679713

Epoch: 5| Step: 9
Training loss: 4.978574752807617
Validation loss: 4.38386203845342

Epoch: 5| Step: 10
Training loss: 5.130037784576416
Validation loss: 4.279720425605774

Epoch: 5| Step: 11
Training loss: 5.106191635131836
Validation loss: 4.178376793861389

Epoch: 5| Step: 0
Training loss: 4.7974138259887695
Validation loss: 4.0808195769786835

Epoch: 5| Step: 1
Training loss: 4.201175689697266
Validation loss: 3.974674512942632

Epoch: 5| Step: 2
Training loss: 4.126333713531494
Validation loss: 3.8791200617949166

Epoch: 5| Step: 3
Training loss: 4.036437034606934
Validation loss: 3.7608664333820343

Epoch: 5| Step: 4
Training loss: 4.456280708312988
Validation loss: 3.6360837121804557

Epoch: 5| Step: 5
Training loss: 3.370877504348755
Validation loss: 3.554488887389501

Epoch: 5| Step: 6
Training loss: 2.729398012161255
Validation loss: 3.4517583549022675

Epoch: 5| Step: 7
Training loss: 3.2321133613586426
Validation loss: 3.3611097236474357

Epoch: 5| Step: 8
Training loss: 3.3796114921569824
Validation loss: 3.2253441313902536

Epoch: 5| Step: 9
Training loss: 3.14583683013916
Validation loss: 3.113170733054479

Epoch: 5| Step: 10
Training loss: 2.8609776496887207
Validation loss: 3.0341041684150696

Epoch: 5| Step: 11
Training loss: 3.4475855827331543
Validation loss: 2.9136562248071036

Epoch: 6| Step: 0
Training loss: 2.7256455421447754
Validation loss: 2.8172318637371063

Epoch: 5| Step: 1
Training loss: 2.7558364868164062
Validation loss: 2.7448489665985107

Epoch: 5| Step: 2
Training loss: 2.5484352111816406
Validation loss: 2.6688114205996194

Epoch: 5| Step: 3
Training loss: 2.190410852432251
Validation loss: 2.572102273503939

Epoch: 5| Step: 4
Training loss: 3.0579640865325928
Validation loss: 2.533875986933708

Epoch: 5| Step: 5
Training loss: 2.68723726272583
Validation loss: 2.457221488157908

Epoch: 5| Step: 6
Training loss: 2.003720283508301
Validation loss: 2.3790587037801743

Epoch: 5| Step: 7
Training loss: 1.913323998451233
Validation loss: 2.3140315214792886

Epoch: 5| Step: 8
Training loss: 2.8320541381835938
Validation loss: 2.307219942410787

Epoch: 5| Step: 9
Training loss: 1.4476487636566162
Validation loss: 2.2415687292814255

Epoch: 5| Step: 10
Training loss: 1.8211019039154053
Validation loss: 2.251343180735906

Epoch: 5| Step: 11
Training loss: 3.3515071868896484
Validation loss: 2.2547991474469504

Epoch: 7| Step: 0
Training loss: 2.630675792694092
Validation loss: 2.3046222925186157

Epoch: 5| Step: 1
Training loss: 1.8885021209716797
Validation loss: 2.318284824490547

Epoch: 5| Step: 2
Training loss: 1.9190788269042969
Validation loss: 2.3908128440380096

Epoch: 5| Step: 3
Training loss: 2.2690062522888184
Validation loss: 2.393262962500254

Epoch: 5| Step: 4
Training loss: 2.380125045776367
Validation loss: 2.466253767410914

Epoch: 5| Step: 5
Training loss: 2.6812233924865723
Validation loss: 2.4675874213377633

Epoch: 5| Step: 6
Training loss: 2.76951265335083
Validation loss: 2.404195378224055

Epoch: 5| Step: 7
Training loss: 2.3162901401519775
Validation loss: 2.3833252787590027

Epoch: 5| Step: 8
Training loss: 2.7203145027160645
Validation loss: 2.380860467751821

Epoch: 5| Step: 9
Training loss: 2.1245691776275635
Validation loss: 2.350460742910703

Epoch: 5| Step: 10
Training loss: 2.414280652999878
Validation loss: 2.3487446109453836

Epoch: 5| Step: 11
Training loss: 1.982618808746338
Validation loss: 2.2930103639761605

Epoch: 8| Step: 0
Training loss: 2.6052162647247314
Validation loss: 2.290077323714892

Epoch: 5| Step: 1
Training loss: 1.9983543157577515
Validation loss: 2.2431174914042153

Epoch: 5| Step: 2
Training loss: 2.507908344268799
Validation loss: 2.261602759361267

Epoch: 5| Step: 3
Training loss: 2.2655234336853027
Validation loss: 2.223336011171341

Epoch: 5| Step: 4
Training loss: 2.3843634128570557
Validation loss: 2.2221527695655823

Epoch: 5| Step: 5
Training loss: 2.1852245330810547
Validation loss: 2.279626796642939

Epoch: 5| Step: 6
Training loss: 2.0762553215026855
Validation loss: 2.2094448655843735

Epoch: 5| Step: 7
Training loss: 2.256063461303711
Validation loss: 2.225734750429789

Epoch: 5| Step: 8
Training loss: 2.22326922416687
Validation loss: 2.276936555902163

Epoch: 5| Step: 9
Training loss: 1.992957353591919
Validation loss: 2.266475980480512

Epoch: 5| Step: 10
Training loss: 1.550553560256958
Validation loss: 2.215791488687197

Epoch: 5| Step: 11
Training loss: 1.437748670578003
Validation loss: 2.26475261648496

Epoch: 9| Step: 0
Training loss: 1.9783493280410767
Validation loss: 2.265243276953697

Epoch: 5| Step: 1
Training loss: 2.416454315185547
Validation loss: 2.2392800649007163

Epoch: 5| Step: 2
Training loss: 2.491705894470215
Validation loss: 2.2372146546840668

Epoch: 5| Step: 3
Training loss: 2.8726468086242676
Validation loss: 2.207495480775833

Epoch: 5| Step: 4
Training loss: 1.8535406589508057
Validation loss: 2.2507072488466897

Epoch: 5| Step: 5
Training loss: 2.310014247894287
Validation loss: 2.2581643561522164

Epoch: 5| Step: 6
Training loss: 2.20298433303833
Validation loss: 2.249283423026403

Epoch: 5| Step: 7
Training loss: 1.9528858661651611
Validation loss: 2.2156917601823807

Epoch: 5| Step: 8
Training loss: 2.053551435470581
Validation loss: 2.2336575289567313

Epoch: 5| Step: 9
Training loss: 1.677952527999878
Validation loss: 2.253085821866989

Epoch: 5| Step: 10
Training loss: 1.8635578155517578
Validation loss: 2.1992332438627877

Epoch: 5| Step: 11
Training loss: 1.7934072017669678
Validation loss: 2.20607653260231

Epoch: 10| Step: 0
Training loss: 2.2183728218078613
Validation loss: 2.206598257025083

Epoch: 5| Step: 1
Training loss: 1.9085462093353271
Validation loss: 2.2356257140636444

Epoch: 5| Step: 2
Training loss: 2.2096107006073
Validation loss: 2.2282795011997223

Epoch: 5| Step: 3
Training loss: 1.9695857763290405
Validation loss: 2.197043612599373

Epoch: 5| Step: 4
Training loss: 2.187206983566284
Validation loss: 2.250046263138453

Epoch: 5| Step: 5
Training loss: 1.8781808614730835
Validation loss: 2.2250144332647324

Epoch: 5| Step: 6
Training loss: 2.102372646331787
Validation loss: 2.2308203081289926

Epoch: 5| Step: 7
Training loss: 1.9276320934295654
Validation loss: 2.227307826280594

Epoch: 5| Step: 8
Training loss: 2.4424712657928467
Validation loss: 2.2118184914191565

Epoch: 5| Step: 9
Training loss: 2.3810057640075684
Validation loss: 2.2905547519524894

Epoch: 5| Step: 10
Training loss: 2.3923392295837402
Validation loss: 2.285893812775612

Epoch: 5| Step: 11
Training loss: 1.1090325117111206
Validation loss: 2.207006335258484

Epoch: 11| Step: 0
Training loss: 1.7193139791488647
Validation loss: 2.22550002237161

Epoch: 5| Step: 1
Training loss: 1.805769681930542
Validation loss: 2.2233851899703345

Epoch: 5| Step: 2
Training loss: 2.016639471054077
Validation loss: 2.260870044430097

Epoch: 5| Step: 3
Training loss: 2.2713699340820312
Validation loss: 2.233190486828486

Epoch: 5| Step: 4
Training loss: 1.8569443225860596
Validation loss: 2.217713048060735

Epoch: 5| Step: 5
Training loss: 1.9404815435409546
Validation loss: 2.2230578660964966

Epoch: 5| Step: 6
Training loss: 1.9338325262069702
Validation loss: 2.2146106163660684

Epoch: 5| Step: 7
Training loss: 1.9228712320327759
Validation loss: 2.176375766595205

Epoch: 5| Step: 8
Training loss: 3.10459566116333
Validation loss: 2.1987845301628113

Epoch: 5| Step: 9
Training loss: 2.3300228118896484
Validation loss: 2.2156802068154016

Epoch: 5| Step: 10
Training loss: 2.759089231491089
Validation loss: 2.153035501639048

Epoch: 5| Step: 11
Training loss: 1.2523581981658936
Validation loss: 2.1442679862181344

Epoch: 12| Step: 0
Training loss: 2.592500925064087
Validation loss: 2.1807614217201867

Epoch: 5| Step: 1
Training loss: 2.477504253387451
Validation loss: 2.2243471145629883

Epoch: 5| Step: 2
Training loss: 1.7725508213043213
Validation loss: 2.2104077140490213

Epoch: 5| Step: 3
Training loss: 1.649714708328247
Validation loss: 2.1357658356428146

Epoch: 5| Step: 4
Training loss: 1.8863611221313477
Validation loss: 2.211270570755005

Epoch: 5| Step: 5
Training loss: 2.486646890640259
Validation loss: 2.1923874070247016

Epoch: 5| Step: 6
Training loss: 2.6924147605895996
Validation loss: 2.2213861445585885

Epoch: 5| Step: 7
Training loss: 2.410475492477417
Validation loss: 2.1817445953687034

Epoch: 5| Step: 8
Training loss: 2.2607333660125732
Validation loss: 2.22092172006766

Epoch: 5| Step: 9
Training loss: 1.4461971521377563
Validation loss: 2.1985664069652557

Epoch: 5| Step: 10
Training loss: 1.8622138500213623
Validation loss: 2.1626980702082315

Epoch: 5| Step: 11
Training loss: 1.258934497833252
Validation loss: 2.2197659562031427

Epoch: 13| Step: 0
Training loss: 1.3324609994888306
Validation loss: 2.1828245321909585

Epoch: 5| Step: 1
Training loss: 2.158679246902466
Validation loss: 2.193821504712105

Epoch: 5| Step: 2
Training loss: 2.445345878601074
Validation loss: 2.187023093303045

Epoch: 5| Step: 3
Training loss: 2.1972787380218506
Validation loss: 2.1902649253606796

Epoch: 5| Step: 4
Training loss: 2.165626049041748
Validation loss: 2.201661467552185

Epoch: 5| Step: 5
Training loss: 1.816410779953003
Validation loss: 2.191376894712448

Epoch: 5| Step: 6
Training loss: 2.4290103912353516
Validation loss: 2.232882837454478

Epoch: 5| Step: 7
Training loss: 2.407418966293335
Validation loss: 2.232218017180761

Epoch: 5| Step: 8
Training loss: 2.5636861324310303
Validation loss: 2.236235956350962

Epoch: 5| Step: 9
Training loss: 1.9550445079803467
Validation loss: 2.1889545917510986

Epoch: 5| Step: 10
Training loss: 2.3040013313293457
Validation loss: 2.1959037631750107

Epoch: 5| Step: 11
Training loss: 0.6831876039505005
Validation loss: 2.1747104624907174

Epoch: 14| Step: 0
Training loss: 2.1895408630371094
Validation loss: 2.2373377134402594

Epoch: 5| Step: 1
Training loss: 2.092747926712036
Validation loss: 2.1475790242354074

Epoch: 5| Step: 2
Training loss: 2.184349536895752
Validation loss: 2.1751105338335037

Epoch: 5| Step: 3
Training loss: 2.788360834121704
Validation loss: 2.152028739452362

Epoch: 5| Step: 4
Training loss: 2.0235304832458496
Validation loss: 2.1574247926473618

Epoch: 5| Step: 5
Training loss: 1.6238723993301392
Validation loss: 2.220226983229319

Epoch: 5| Step: 6
Training loss: 2.0145225524902344
Validation loss: 2.235627988974253

Epoch: 5| Step: 7
Training loss: 2.05873703956604
Validation loss: 2.2081311692794166

Epoch: 5| Step: 8
Training loss: 2.0829763412475586
Validation loss: 2.2146239479382834

Epoch: 5| Step: 9
Training loss: 2.01481032371521
Validation loss: 2.177427758773168

Epoch: 5| Step: 10
Training loss: 2.0724105834960938
Validation loss: 2.1752122243245444

Epoch: 5| Step: 11
Training loss: 1.7749933004379272
Validation loss: 2.1935807714859643

Epoch: 15| Step: 0
Training loss: 2.1484062671661377
Validation loss: 2.201144685347875

Epoch: 5| Step: 1
Training loss: 1.967384696006775
Validation loss: 2.1719806691010795

Epoch: 5| Step: 2
Training loss: 1.7562099695205688
Validation loss: 2.2111028283834457

Epoch: 5| Step: 3
Training loss: 2.4812769889831543
Validation loss: 2.171454578638077

Epoch: 5| Step: 4
Training loss: 2.500983715057373
Validation loss: 2.206724906961123

Epoch: 5| Step: 5
Training loss: 1.8684608936309814
Validation loss: 2.1726080725590386

Epoch: 5| Step: 6
Training loss: 2.3089404106140137
Validation loss: 2.1487626483043036

Epoch: 5| Step: 7
Training loss: 1.9831974506378174
Validation loss: 2.152295013268789

Epoch: 5| Step: 8
Training loss: 1.9907306432724
Validation loss: 2.2118931313355765

Epoch: 5| Step: 9
Training loss: 1.9007879495620728
Validation loss: 2.178219864765803

Epoch: 5| Step: 10
Training loss: 2.1242527961730957
Validation loss: 2.1530593931674957

Epoch: 5| Step: 11
Training loss: 1.914504885673523
Validation loss: 2.1611606081326804

Epoch: 16| Step: 0
Training loss: 2.1997735500335693
Validation loss: 2.1899797121683755

Epoch: 5| Step: 1
Training loss: 2.3893823623657227
Validation loss: 2.161232536037763

Epoch: 5| Step: 2
Training loss: 2.2107441425323486
Validation loss: 2.1800818790992103

Epoch: 5| Step: 3
Training loss: 2.2472076416015625
Validation loss: 2.1666123420000076

Epoch: 5| Step: 4
Training loss: 1.9689204692840576
Validation loss: 2.1184185842672982

Epoch: 5| Step: 5
Training loss: 1.8571374416351318
Validation loss: 2.10241029659907

Epoch: 5| Step: 6
Training loss: 1.7807576656341553
Validation loss: 2.189628059665362

Epoch: 5| Step: 7
Training loss: 2.0439491271972656
Validation loss: 2.1975063532590866

Epoch: 5| Step: 8
Training loss: 2.163638114929199
Validation loss: 2.161143740018209

Epoch: 5| Step: 9
Training loss: 2.1949679851531982
Validation loss: 2.1653154691060386

Epoch: 5| Step: 10
Training loss: 2.084218740463257
Validation loss: 2.150755604108175

Epoch: 5| Step: 11
Training loss: 1.9124984741210938
Validation loss: 2.160986547668775

Epoch: 17| Step: 0
Training loss: 2.413921594619751
Validation loss: 2.190097153186798

Epoch: 5| Step: 1
Training loss: 2.5058813095092773
Validation loss: 2.1610890328884125

Epoch: 5| Step: 2
Training loss: 1.7622528076171875
Validation loss: 2.1193436731894812

Epoch: 5| Step: 3
Training loss: 2.0838139057159424
Validation loss: 2.1334601591030755

Epoch: 5| Step: 4
Training loss: 1.8947274684906006
Validation loss: 2.111732299129168

Epoch: 5| Step: 5
Training loss: 2.8245112895965576
Validation loss: 2.0962820599476495

Epoch: 5| Step: 6
Training loss: 2.154512882232666
Validation loss: 2.207845062017441

Epoch: 5| Step: 7
Training loss: 2.222838878631592
Validation loss: 2.19000473121802

Epoch: 5| Step: 8
Training loss: 1.6260738372802734
Validation loss: 2.166602532068888

Epoch: 5| Step: 9
Training loss: 2.0418152809143066
Validation loss: 2.1585028866926828

Epoch: 5| Step: 10
Training loss: 1.4968076944351196
Validation loss: 2.1591594765583673

Epoch: 5| Step: 11
Training loss: 0.9054266214370728
Validation loss: 2.1440752297639847

Epoch: 18| Step: 0
Training loss: 2.631042957305908
Validation loss: 2.131206144889196

Epoch: 5| Step: 1
Training loss: 1.622839331626892
Validation loss: 2.1889838774998984

Epoch: 5| Step: 2
Training loss: 1.8212333917617798
Validation loss: 2.170163700977961

Epoch: 5| Step: 3
Training loss: 2.1111509799957275
Validation loss: 2.1667063931624093

Epoch: 5| Step: 4
Training loss: 1.590045690536499
Validation loss: 2.219778895378113

Epoch: 5| Step: 5
Training loss: 2.207003355026245
Validation loss: 2.174399361014366

Epoch: 5| Step: 6
Training loss: 2.0242648124694824
Validation loss: 2.1173324982325235

Epoch: 5| Step: 7
Training loss: 1.7591766119003296
Validation loss: 2.1606028974056244

Epoch: 5| Step: 8
Training loss: 2.405783176422119
Validation loss: 2.1186254024505615

Epoch: 5| Step: 9
Training loss: 2.4360287189483643
Validation loss: 2.162367045879364

Epoch: 5| Step: 10
Training loss: 1.8748047351837158
Validation loss: 2.172134429216385

Epoch: 5| Step: 11
Training loss: 3.000483274459839
Validation loss: 2.179374704758326

Epoch: 19| Step: 0
Training loss: 2.4697482585906982
Validation loss: 2.1442613850037255

Epoch: 5| Step: 1
Training loss: 2.181424617767334
Validation loss: 2.1110797127087912

Epoch: 5| Step: 2
Training loss: 1.5627456903457642
Validation loss: 2.1009371926387153

Epoch: 5| Step: 3
Training loss: 2.1638712882995605
Validation loss: 2.088303675254186

Epoch: 5| Step: 4
Training loss: 1.9820892810821533
Validation loss: 2.157103881239891

Epoch: 5| Step: 5
Training loss: 1.965181589126587
Validation loss: 2.13787180185318

Epoch: 5| Step: 6
Training loss: 2.2393016815185547
Validation loss: 2.1484924058119454

Epoch: 5| Step: 7
Training loss: 1.988109827041626
Validation loss: 2.11463355521361

Epoch: 5| Step: 8
Training loss: 2.084500789642334
Validation loss: 2.1559188216924667

Epoch: 5| Step: 9
Training loss: 2.1433210372924805
Validation loss: 2.182683994372686

Epoch: 5| Step: 10
Training loss: 1.9505226612091064
Validation loss: 2.1018167535463967

Epoch: 5| Step: 11
Training loss: 2.247465133666992
Validation loss: 2.139323348800341

Epoch: 20| Step: 0
Training loss: 2.470426082611084
Validation loss: 2.157892237106959

Epoch: 5| Step: 1
Training loss: 2.4713222980499268
Validation loss: 2.181618412335714

Epoch: 5| Step: 2
Training loss: 2.340027093887329
Validation loss: 2.163524051507314

Epoch: 5| Step: 3
Training loss: 2.5078675746917725
Validation loss: 2.167507827281952

Epoch: 5| Step: 4
Training loss: 1.9958651065826416
Validation loss: 2.12219608326753

Epoch: 5| Step: 5
Training loss: 2.2333827018737793
Validation loss: 2.134591892361641

Epoch: 5| Step: 6
Training loss: 1.7721173763275146
Validation loss: 2.104954093694687

Epoch: 5| Step: 7
Training loss: 1.8045555353164673
Validation loss: 2.1573343177636466

Epoch: 5| Step: 8
Training loss: 1.8336753845214844
Validation loss: 2.148933003346125

Epoch: 5| Step: 9
Training loss: 1.6781761646270752
Validation loss: 2.1260418693224588

Epoch: 5| Step: 10
Training loss: 1.7309706211090088
Validation loss: 2.1000012904405594

Epoch: 5| Step: 11
Training loss: 1.7093592882156372
Validation loss: 2.1363210578759513

Epoch: 21| Step: 0
Training loss: 1.5702855587005615
Validation loss: 2.09368696808815

Epoch: 5| Step: 1
Training loss: 2.73256254196167
Validation loss: 2.160950228571892

Epoch: 5| Step: 2
Training loss: 2.3260693550109863
Validation loss: 2.124385620156924

Epoch: 5| Step: 3
Training loss: 1.1316215991973877
Validation loss: 2.1288001984357834

Epoch: 5| Step: 4
Training loss: 2.097240447998047
Validation loss: 2.12540839612484

Epoch: 5| Step: 5
Training loss: 1.9482614994049072
Validation loss: 2.0953500171502433

Epoch: 5| Step: 6
Training loss: 1.8347152471542358
Validation loss: 2.1170414984226227

Epoch: 5| Step: 7
Training loss: 1.9440336227416992
Validation loss: 2.1496885418891907

Epoch: 5| Step: 8
Training loss: 2.080463171005249
Validation loss: 2.11429093281428

Epoch: 5| Step: 9
Training loss: 2.2532997131347656
Validation loss: 2.137851839264234

Epoch: 5| Step: 10
Training loss: 2.317476272583008
Validation loss: 2.1185551385084787

Epoch: 5| Step: 11
Training loss: 3.844395637512207
Validation loss: 2.0920291393995285

Epoch: 22| Step: 0
Training loss: 1.9140335321426392
Validation loss: 2.1474183201789856

Epoch: 5| Step: 1
Training loss: 1.8056738376617432
Validation loss: 2.135966256260872

Epoch: 5| Step: 2
Training loss: 1.8140068054199219
Validation loss: 2.14022987584273

Epoch: 5| Step: 3
Training loss: 2.5124354362487793
Validation loss: 2.13025730351607

Epoch: 5| Step: 4
Training loss: 1.7810218334197998
Validation loss: 2.1554525941610336

Epoch: 5| Step: 5
Training loss: 2.3895959854125977
Validation loss: 2.1457346181074777

Epoch: 5| Step: 6
Training loss: 1.7957346439361572
Validation loss: 2.140599638223648

Epoch: 5| Step: 7
Training loss: 2.3189127445220947
Validation loss: 2.164292926589648

Epoch: 5| Step: 8
Training loss: 2.0423617362976074
Validation loss: 2.170303533474604

Epoch: 5| Step: 9
Training loss: 2.5197672843933105
Validation loss: 2.1538303196430206

Epoch: 5| Step: 10
Training loss: 2.0282187461853027
Validation loss: 2.1567908823490143

Epoch: 5| Step: 11
Training loss: 2.5882339477539062
Validation loss: 2.1324790567159653

Epoch: 23| Step: 0
Training loss: 1.980076551437378
Validation loss: 2.144136110941569

Epoch: 5| Step: 1
Training loss: 1.4181064367294312
Validation loss: 2.140349527200063

Epoch: 5| Step: 2
Training loss: 2.0421528816223145
Validation loss: 2.120942324399948

Epoch: 5| Step: 3
Training loss: 2.046609401702881
Validation loss: 2.1059413254261017

Epoch: 5| Step: 4
Training loss: 1.9682226181030273
Validation loss: 2.102900246779124

Epoch: 5| Step: 5
Training loss: 2.5666823387145996
Validation loss: 2.1578884571790695

Epoch: 5| Step: 6
Training loss: 2.821608304977417
Validation loss: 2.1354490220546722

Epoch: 5| Step: 7
Training loss: 2.169602394104004
Validation loss: 2.080672671397527

Epoch: 5| Step: 8
Training loss: 2.193267345428467
Validation loss: 2.1304944852987924

Epoch: 5| Step: 9
Training loss: 1.8772863149642944
Validation loss: 2.12894207239151

Epoch: 5| Step: 10
Training loss: 1.6175979375839233
Validation loss: 2.112001955509186

Epoch: 5| Step: 11
Training loss: 0.8474410176277161
Validation loss: 2.122433289885521

Epoch: 24| Step: 0
Training loss: 2.048624038696289
Validation loss: 2.198429817954699

Epoch: 5| Step: 1
Training loss: 1.850520372390747
Validation loss: 2.1422989269097648

Epoch: 5| Step: 2
Training loss: 1.7968603372573853
Validation loss: 2.0956521232922873

Epoch: 5| Step: 3
Training loss: 2.2088828086853027
Validation loss: 2.139681155482928

Epoch: 5| Step: 4
Training loss: 1.7464587688446045
Validation loss: 2.1109679291645684

Epoch: 5| Step: 5
Training loss: 1.757441759109497
Validation loss: 2.077188566327095

Epoch: 5| Step: 6
Training loss: 2.039705514907837
Validation loss: 2.11032543083032

Epoch: 5| Step: 7
Training loss: 1.9730339050292969
Validation loss: 2.0992881854375205

Epoch: 5| Step: 8
Training loss: 2.006727457046509
Validation loss: 2.1116271068652472

Epoch: 5| Step: 9
Training loss: 2.8108320236206055
Validation loss: 2.1282480359077454

Epoch: 5| Step: 10
Training loss: 2.2089781761169434
Validation loss: 2.15466645359993

Epoch: 5| Step: 11
Training loss: 0.7584046721458435
Validation loss: 2.14287697772185

Epoch: 25| Step: 0
Training loss: 2.6308417320251465
Validation loss: 2.07405294974645

Epoch: 5| Step: 1
Training loss: 1.8866370916366577
Validation loss: 2.1198045710722604

Epoch: 5| Step: 2
Training loss: 1.742868185043335
Validation loss: 2.1259152591228485

Epoch: 5| Step: 3
Training loss: 2.1109626293182373
Validation loss: 2.0819983035326004

Epoch: 5| Step: 4
Training loss: 2.7770094871520996
Validation loss: 2.1053751607735953

Epoch: 5| Step: 5
Training loss: 2.229764223098755
Validation loss: 2.110162302851677

Epoch: 5| Step: 6
Training loss: 2.302351474761963
Validation loss: 2.1413927525281906

Epoch: 5| Step: 7
Training loss: 1.6341396570205688
Validation loss: 2.1219152957201004

Epoch: 5| Step: 8
Training loss: 2.039726972579956
Validation loss: 2.11048623919487

Epoch: 5| Step: 9
Training loss: 1.4577662944793701
Validation loss: 2.1924137274424234

Epoch: 5| Step: 10
Training loss: 1.8956184387207031
Validation loss: 2.1345086296399436

Epoch: 5| Step: 11
Training loss: 1.089033603668213
Validation loss: 2.1098719785610833

Epoch: 26| Step: 0
Training loss: 2.027601718902588
Validation loss: 2.1609545151392617

Epoch: 5| Step: 1
Training loss: 1.2692527770996094
Validation loss: 2.1233411033948264

Epoch: 5| Step: 2
Training loss: 1.9611587524414062
Validation loss: 2.11042590936025

Epoch: 5| Step: 3
Training loss: 1.9765465259552002
Validation loss: 2.118564928571383

Epoch: 5| Step: 4
Training loss: 2.849407434463501
Validation loss: 2.080267916123072

Epoch: 5| Step: 5
Training loss: 2.4386560916900635
Validation loss: 2.1508598178625107

Epoch: 5| Step: 6
Training loss: 1.7791284322738647
Validation loss: 2.127756436665853

Epoch: 5| Step: 7
Training loss: 2.0065693855285645
Validation loss: 2.1234415719906488

Epoch: 5| Step: 8
Training loss: 1.810323715209961
Validation loss: 2.1085098336140313

Epoch: 5| Step: 9
Training loss: 2.145956516265869
Validation loss: 2.1376173744599023

Epoch: 5| Step: 10
Training loss: 2.236717939376831
Validation loss: 2.110159625609716

Epoch: 5| Step: 11
Training loss: 2.5891032218933105
Validation loss: 2.0846234261989594

Epoch: 27| Step: 0
Training loss: 2.316758155822754
Validation loss: 2.0817731320858

Epoch: 5| Step: 1
Training loss: 2.1843504905700684
Validation loss: 2.100820943713188

Epoch: 5| Step: 2
Training loss: 1.1956946849822998
Validation loss: 2.1128071695566177

Epoch: 5| Step: 3
Training loss: 2.0899243354797363
Validation loss: 2.164686699708303

Epoch: 5| Step: 4
Training loss: 2.3547091484069824
Validation loss: 2.148212884863218

Epoch: 5| Step: 5
Training loss: 2.6544857025146484
Validation loss: 2.136214037736257

Epoch: 5| Step: 6
Training loss: 2.3282785415649414
Validation loss: 2.1389953941106796

Epoch: 5| Step: 7
Training loss: 1.3268249034881592
Validation loss: 2.123772452274958

Epoch: 5| Step: 8
Training loss: 1.9355566501617432
Validation loss: 2.133044163386027

Epoch: 5| Step: 9
Training loss: 2.141773223876953
Validation loss: 2.1437505781650543

Epoch: 5| Step: 10
Training loss: 1.8422876596450806
Validation loss: 2.081279401977857

Epoch: 5| Step: 11
Training loss: 1.8847852945327759
Validation loss: 2.1060325503349304

Epoch: 28| Step: 0
Training loss: 2.4205520153045654
Validation loss: 2.131047954161962

Epoch: 5| Step: 1
Training loss: 2.0099189281463623
Validation loss: 2.0783545672893524

Epoch: 5| Step: 2
Training loss: 2.1672544479370117
Validation loss: 2.1081561942895255

Epoch: 5| Step: 3
Training loss: 2.6948468685150146
Validation loss: 2.092539891600609

Epoch: 5| Step: 4
Training loss: 2.0725064277648926
Validation loss: 2.133937582373619

Epoch: 5| Step: 5
Training loss: 1.6690080165863037
Validation loss: 2.1649279594421387

Epoch: 5| Step: 6
Training loss: 1.1785056591033936
Validation loss: 2.0907234152158103

Epoch: 5| Step: 7
Training loss: 1.7380154132843018
Validation loss: 2.12936965127786

Epoch: 5| Step: 8
Training loss: 1.7814178466796875
Validation loss: 2.0802410592635474

Epoch: 5| Step: 9
Training loss: 2.0475282669067383
Validation loss: 2.073469430208206

Epoch: 5| Step: 10
Training loss: 2.2305774688720703
Validation loss: 2.0906732380390167

Epoch: 5| Step: 11
Training loss: 4.749884605407715
Validation loss: 2.1326957543691

Epoch: 29| Step: 0
Training loss: 1.621964693069458
Validation loss: 2.1472478012243905

Epoch: 5| Step: 1
Training loss: 2.4336493015289307
Validation loss: 2.095568522810936

Epoch: 5| Step: 2
Training loss: 2.4199161529541016
Validation loss: 2.0531781564156213

Epoch: 5| Step: 3
Training loss: 2.4497833251953125
Validation loss: 2.09113776187102

Epoch: 5| Step: 4
Training loss: 1.7686727046966553
Validation loss: 2.047344595193863

Epoch: 5| Step: 5
Training loss: 2.3010897636413574
Validation loss: 2.1204018592834473

Epoch: 5| Step: 6
Training loss: 2.087679386138916
Validation loss: 2.110613092780113

Epoch: 5| Step: 7
Training loss: 1.8429005146026611
Validation loss: 2.09638146062692

Epoch: 5| Step: 8
Training loss: 1.61136794090271
Validation loss: 2.0705153942108154

Epoch: 5| Step: 9
Training loss: 1.7703335285186768
Validation loss: 2.1182265281677246

Epoch: 5| Step: 10
Training loss: 1.7807865142822266
Validation loss: 2.1034004588921866

Epoch: 5| Step: 11
Training loss: 2.0940771102905273
Validation loss: 2.123478809992472

Epoch: 30| Step: 0
Training loss: 1.4822015762329102
Validation loss: 2.122528071204821

Epoch: 5| Step: 1
Training loss: 1.5236809253692627
Validation loss: 2.067256137728691

Epoch: 5| Step: 2
Training loss: 2.175426959991455
Validation loss: 2.1107383370399475

Epoch: 5| Step: 3
Training loss: 2.8027050495147705
Validation loss: 2.1065731942653656

Epoch: 5| Step: 4
Training loss: 2.2556915283203125
Validation loss: 2.1194391002257666

Epoch: 5| Step: 5
Training loss: 1.7347943782806396
Validation loss: 2.069065352280935

Epoch: 5| Step: 6
Training loss: 2.3335020542144775
Validation loss: 2.126315097014109

Epoch: 5| Step: 7
Training loss: 1.4523077011108398
Validation loss: 2.1365028073390326

Epoch: 5| Step: 8
Training loss: 1.5572618246078491
Validation loss: 2.146527980764707

Epoch: 5| Step: 9
Training loss: 2.6236369609832764
Validation loss: 2.1145265946785607

Epoch: 5| Step: 10
Training loss: 2.1018574237823486
Validation loss: 2.109641800324122

Epoch: 5| Step: 11
Training loss: 2.837376117706299
Validation loss: 2.098130231102308

Epoch: 31| Step: 0
Training loss: 2.1741065979003906
Validation loss: 2.1360476364692054

Epoch: 5| Step: 1
Training loss: 1.8395742177963257
Validation loss: 2.0780043552319207

Epoch: 5| Step: 2
Training loss: 1.7207826375961304
Validation loss: 2.0866091350714364

Epoch: 5| Step: 3
Training loss: 2.3541646003723145
Validation loss: 2.0878465274969735

Epoch: 5| Step: 4
Training loss: 1.5640052556991577
Validation loss: 2.053002044558525

Epoch: 5| Step: 5
Training loss: 2.1888983249664307
Validation loss: 2.0966336329778037

Epoch: 5| Step: 6
Training loss: 2.3764946460723877
Validation loss: 2.0990280359983444

Epoch: 5| Step: 7
Training loss: 1.805466651916504
Validation loss: 2.112791026631991

Epoch: 5| Step: 8
Training loss: 2.4161734580993652
Validation loss: 2.0828611751397452

Epoch: 5| Step: 9
Training loss: 1.7670376300811768
Validation loss: 2.1185879011948905

Epoch: 5| Step: 10
Training loss: 1.855590581893921
Validation loss: 2.133203754822413

Epoch: 5| Step: 11
Training loss: 2.4399209022521973
Validation loss: 2.089514975746473

Epoch: 32| Step: 0
Training loss: 1.7992109060287476
Validation loss: 2.09576981763045

Epoch: 5| Step: 1
Training loss: 1.727560043334961
Validation loss: 2.120747764905294

Epoch: 5| Step: 2
Training loss: 2.7507286071777344
Validation loss: 2.063025345404943

Epoch: 5| Step: 3
Training loss: 2.0151965618133545
Validation loss: 2.0884425242741904

Epoch: 5| Step: 4
Training loss: 1.5626035928726196
Validation loss: 2.131927877664566

Epoch: 5| Step: 5
Training loss: 2.1437904834747314
Validation loss: 2.0569196740786233

Epoch: 5| Step: 6
Training loss: 1.9213802814483643
Validation loss: 2.1255568265914917

Epoch: 5| Step: 7
Training loss: 2.1960768699645996
Validation loss: 2.1001953383286796

Epoch: 5| Step: 8
Training loss: 2.1705925464630127
Validation loss: 2.070107181866964

Epoch: 5| Step: 9
Training loss: 2.3156943321228027
Validation loss: 2.0418062259753547

Epoch: 5| Step: 10
Training loss: 1.8547054529190063
Validation loss: 2.1172086149454117

Epoch: 5| Step: 11
Training loss: 2.258054256439209
Validation loss: 2.121144264936447

Epoch: 33| Step: 0
Training loss: 1.7011268138885498
Validation loss: 2.109834219018618

Epoch: 5| Step: 1
Training loss: 1.8063020706176758
Validation loss: 2.076692913969358

Epoch: 5| Step: 2
Training loss: 2.469336748123169
Validation loss: 2.100761046012243

Epoch: 5| Step: 3
Training loss: 2.3202483654022217
Validation loss: 2.104028398791949

Epoch: 5| Step: 4
Training loss: 2.181844711303711
Validation loss: 2.1103854527076087

Epoch: 5| Step: 5
Training loss: 2.259897232055664
Validation loss: 2.106165091196696

Epoch: 5| Step: 6
Training loss: 1.5029627084732056
Validation loss: 2.0818995187679925

Epoch: 5| Step: 7
Training loss: 2.1147665977478027
Validation loss: 2.083154891928037

Epoch: 5| Step: 8
Training loss: 1.4222650527954102
Validation loss: 2.0368250807126365

Epoch: 5| Step: 9
Training loss: 2.0316030979156494
Validation loss: 2.089332729578018

Epoch: 5| Step: 10
Training loss: 2.3524627685546875
Validation loss: 2.0772541662057242

Epoch: 5| Step: 11
Training loss: 1.7967360019683838
Validation loss: 2.098339468240738

Epoch: 34| Step: 0
Training loss: 2.24481463432312
Validation loss: 2.0974529484907785

Epoch: 5| Step: 1
Training loss: 1.3947821855545044
Validation loss: 2.086976250012716

Epoch: 5| Step: 2
Training loss: 2.1114749908447266
Validation loss: 2.0594018946091333

Epoch: 5| Step: 3
Training loss: 1.6648101806640625
Validation loss: 2.077164222796758

Epoch: 5| Step: 4
Training loss: 1.304264783859253
Validation loss: 2.1394278903802237

Epoch: 5| Step: 5
Training loss: 1.7519276142120361
Validation loss: 2.0782903879880905

Epoch: 5| Step: 6
Training loss: 2.571056842803955
Validation loss: 2.122991611560186

Epoch: 5| Step: 7
Training loss: 2.2154922485351562
Validation loss: 2.075282653172811

Epoch: 5| Step: 8
Training loss: 2.1913483142852783
Validation loss: 2.0741241375605264

Epoch: 5| Step: 9
Training loss: 2.0674033164978027
Validation loss: 2.105983644723892

Epoch: 5| Step: 10
Training loss: 2.479743480682373
Validation loss: 2.078149060408274

Epoch: 5| Step: 11
Training loss: 2.1582562923431396
Validation loss: 2.0439622501532235

Epoch: 35| Step: 0
Training loss: 1.5629297494888306
Validation loss: 2.109619453549385

Epoch: 5| Step: 1
Training loss: 2.5040152072906494
Validation loss: 2.0840397079785666

Epoch: 5| Step: 2
Training loss: 2.041006088256836
Validation loss: 2.063830778002739

Epoch: 5| Step: 3
Training loss: 1.90253484249115
Validation loss: 2.076004763444265

Epoch: 5| Step: 4
Training loss: 2.3200554847717285
Validation loss: 2.106667309999466

Epoch: 5| Step: 5
Training loss: 1.7110878229141235
Validation loss: 2.011538098255793

Epoch: 5| Step: 6
Training loss: 1.5444889068603516
Validation loss: 2.085970809062322

Epoch: 5| Step: 7
Training loss: 1.9152805805206299
Validation loss: 2.1609813421964645

Epoch: 5| Step: 8
Training loss: 2.0774776935577393
Validation loss: 2.107610543568929

Epoch: 5| Step: 9
Training loss: 2.1273789405822754
Validation loss: 2.0878621488809586

Epoch: 5| Step: 10
Training loss: 2.542074680328369
Validation loss: 2.0671498080094657

Epoch: 5| Step: 11
Training loss: 1.8331242799758911
Validation loss: 2.0658359775940576

Epoch: 36| Step: 0
Training loss: 2.1286075115203857
Validation loss: 2.0310254196325936

Epoch: 5| Step: 1
Training loss: 1.9277286529541016
Validation loss: 2.0705970774094262

Epoch: 5| Step: 2
Training loss: 2.2752060890197754
Validation loss: 2.111178676287333

Epoch: 5| Step: 3
Training loss: 1.9151417016983032
Validation loss: 2.1022758980592093

Epoch: 5| Step: 4
Training loss: 2.1172573566436768
Validation loss: 2.0653200348218284

Epoch: 5| Step: 5
Training loss: 2.376333713531494
Validation loss: 2.1037511179844537

Epoch: 5| Step: 6
Training loss: 1.752350091934204
Validation loss: 2.0906810412804284

Epoch: 5| Step: 7
Training loss: 2.264481782913208
Validation loss: 2.0849263866742453

Epoch: 5| Step: 8
Training loss: 1.5980247259140015
Validation loss: 2.067277193069458

Epoch: 5| Step: 9
Training loss: 2.2659027576446533
Validation loss: 2.082582265138626

Epoch: 5| Step: 10
Training loss: 1.282053828239441
Validation loss: 2.086001177628835

Epoch: 5| Step: 11
Training loss: 1.445549726486206
Validation loss: 2.0760025829076767

Epoch: 37| Step: 0
Training loss: 1.9877662658691406
Validation loss: 2.06338739891847

Epoch: 5| Step: 1
Training loss: 2.104449510574341
Validation loss: 2.145780086517334

Epoch: 5| Step: 2
Training loss: 2.1853652000427246
Validation loss: 2.103273848692576

Epoch: 5| Step: 3
Training loss: 1.3903369903564453
Validation loss: 2.0344096273183823

Epoch: 5| Step: 4
Training loss: 1.5271387100219727
Validation loss: 2.1352124313513436

Epoch: 5| Step: 5
Training loss: 2.279379367828369
Validation loss: 2.111042246222496

Epoch: 5| Step: 6
Training loss: 2.0496103763580322
Validation loss: 2.0535463094711304

Epoch: 5| Step: 7
Training loss: 1.8283119201660156
Validation loss: 2.068841432531675

Epoch: 5| Step: 8
Training loss: 2.371309995651245
Validation loss: 2.108951449394226

Epoch: 5| Step: 9
Training loss: 1.5949934720993042
Validation loss: 2.091449057062467

Epoch: 5| Step: 10
Training loss: 2.399198293685913
Validation loss: 2.0835254192352295

Epoch: 5| Step: 11
Training loss: 3.2635607719421387
Validation loss: 2.0539922565221786

Epoch: 38| Step: 0
Training loss: 1.8677423000335693
Validation loss: 2.072775443394979

Epoch: 5| Step: 1
Training loss: 2.384553909301758
Validation loss: 2.1107731064160666

Epoch: 5| Step: 2
Training loss: 2.0413706302642822
Validation loss: 2.001292645931244

Epoch: 5| Step: 3
Training loss: 1.6708072423934937
Validation loss: 2.0714849829673767

Epoch: 5| Step: 4
Training loss: 2.2572226524353027
Validation loss: 2.0393505642811456

Epoch: 5| Step: 5
Training loss: 1.8171508312225342
Validation loss: 2.0780420253674188

Epoch: 5| Step: 6
Training loss: 2.0845208168029785
Validation loss: 2.075481101870537

Epoch: 5| Step: 7
Training loss: 1.9677097797393799
Validation loss: 2.067126472791036

Epoch: 5| Step: 8
Training loss: 1.811492919921875
Validation loss: 2.0986982733011246

Epoch: 5| Step: 9
Training loss: 1.944837212562561
Validation loss: 2.104131191968918

Epoch: 5| Step: 10
Training loss: 2.0644259452819824
Validation loss: 2.1125489473342896

Epoch: 5| Step: 11
Training loss: 2.87117862701416
Validation loss: 2.1060622533162436

Epoch: 39| Step: 0
Training loss: 2.228473424911499
Validation loss: 2.0413088897864022

Epoch: 5| Step: 1
Training loss: 1.777992606163025
Validation loss: 2.078773866097132

Epoch: 5| Step: 2
Training loss: 2.119825839996338
Validation loss: 2.068526635567347

Epoch: 5| Step: 3
Training loss: 2.148375988006592
Validation loss: 2.089340547720591

Epoch: 5| Step: 4
Training loss: 2.24798583984375
Validation loss: 2.059772625565529

Epoch: 5| Step: 5
Training loss: 2.193624258041382
Validation loss: 2.07094344496727

Epoch: 5| Step: 6
Training loss: 1.96881103515625
Validation loss: 2.070543736219406

Epoch: 5| Step: 7
Training loss: 1.8281402587890625
Validation loss: 2.099392205476761

Epoch: 5| Step: 8
Training loss: 1.9267370700836182
Validation loss: 2.0493475049734116

Epoch: 5| Step: 9
Training loss: 1.8878892660140991
Validation loss: 2.0681237876415253

Epoch: 5| Step: 10
Training loss: 1.7557296752929688
Validation loss: 2.038280814886093

Epoch: 5| Step: 11
Training loss: 1.8209948539733887
Validation loss: 2.0994463860988617

Epoch: 40| Step: 0
Training loss: 1.6914100646972656
Validation loss: 2.0520940323670707

Epoch: 5| Step: 1
Training loss: 1.9961621761322021
Validation loss: 2.0999032159646354

Epoch: 5| Step: 2
Training loss: 1.3551350831985474
Validation loss: 2.0658173163731894

Epoch: 5| Step: 3
Training loss: 2.421365261077881
Validation loss: 2.0691060622533164

Epoch: 5| Step: 4
Training loss: 2.2050411701202393
Validation loss: 2.0727320313453674

Epoch: 5| Step: 5
Training loss: 2.8814053535461426
Validation loss: 2.0510043452183404

Epoch: 5| Step: 6
Training loss: 1.265993595123291
Validation loss: 2.085958699385325

Epoch: 5| Step: 7
Training loss: 1.9317125082015991
Validation loss: 2.090122545758883

Epoch: 5| Step: 8
Training loss: 1.8267791271209717
Validation loss: 2.0629695802927017

Epoch: 5| Step: 9
Training loss: 1.540606141090393
Validation loss: 2.0887456287940345

Epoch: 5| Step: 10
Training loss: 2.657453775405884
Validation loss: 2.063513239224752

Epoch: 5| Step: 11
Training loss: 1.937779426574707
Validation loss: 2.0628356089194617

Epoch: 41| Step: 0
Training loss: 2.1620230674743652
Validation loss: 2.057435855269432

Epoch: 5| Step: 1
Training loss: 2.175096035003662
Validation loss: 2.0625158647696176

Epoch: 5| Step: 2
Training loss: 1.8318647146224976
Validation loss: 2.061309198538462

Epoch: 5| Step: 3
Training loss: 2.3616433143615723
Validation loss: 2.0967871248722076

Epoch: 5| Step: 4
Training loss: 1.599953532218933
Validation loss: 2.0781773726145425

Epoch: 5| Step: 5
Training loss: 2.5830719470977783
Validation loss: 2.0779997209707894

Epoch: 5| Step: 6
Training loss: 1.8648122549057007
Validation loss: 2.0748118112484613

Epoch: 5| Step: 7
Training loss: 1.930139183998108
Validation loss: 2.081441635886828

Epoch: 5| Step: 8
Training loss: 1.5390647649765015
Validation loss: 2.097911829749743

Epoch: 5| Step: 9
Training loss: 1.8601948022842407
Validation loss: 2.082576021552086

Epoch: 5| Step: 10
Training loss: 1.9047682285308838
Validation loss: 2.0776677479346595

Epoch: 5| Step: 11
Training loss: 1.7487674951553345
Validation loss: 2.0639901757240295

Epoch: 42| Step: 0
Training loss: 1.8978286981582642
Validation loss: 2.067416658004125

Epoch: 5| Step: 1
Training loss: 2.319336414337158
Validation loss: 2.0402559687693915

Epoch: 5| Step: 2
Training loss: 1.6049925088882446
Validation loss: 2.0835389296213784

Epoch: 5| Step: 3
Training loss: 2.1967363357543945
Validation loss: 2.0769988298416138

Epoch: 5| Step: 4
Training loss: 2.2300057411193848
Validation loss: 2.1032455066839852

Epoch: 5| Step: 5
Training loss: 1.6561568975448608
Validation loss: 2.0892143746217093

Epoch: 5| Step: 6
Training loss: 1.8158245086669922
Validation loss: 2.1010897060235343

Epoch: 5| Step: 7
Training loss: 1.7763149738311768
Validation loss: 2.009148751695951

Epoch: 5| Step: 8
Training loss: 2.120481491088867
Validation loss: 2.0760452349980674

Epoch: 5| Step: 9
Training loss: 2.0175812244415283
Validation loss: 2.060287540157636

Epoch: 5| Step: 10
Training loss: 2.050854206085205
Validation loss: 2.093136787414551

Epoch: 5| Step: 11
Training loss: 1.382637619972229
Validation loss: 2.11579958597819

Epoch: 43| Step: 0
Training loss: 1.7151119709014893
Validation loss: 2.0734342286984124

Epoch: 5| Step: 1
Training loss: 1.9364473819732666
Validation loss: 2.0760539968808494

Epoch: 5| Step: 2
Training loss: 2.4036011695861816
Validation loss: 2.1150363932053247

Epoch: 5| Step: 3
Training loss: 1.4422043561935425
Validation loss: 2.0680903792381287

Epoch: 5| Step: 4
Training loss: 2.1165578365325928
Validation loss: 2.1269283394018808

Epoch: 5| Step: 5
Training loss: 2.16953444480896
Validation loss: 2.123898684978485

Epoch: 5| Step: 6
Training loss: 2.26680850982666
Validation loss: 2.0451880196730294

Epoch: 5| Step: 7
Training loss: 2.008150577545166
Validation loss: 2.075883542497953

Epoch: 5| Step: 8
Training loss: 1.875658392906189
Validation loss: 2.127453774213791

Epoch: 5| Step: 9
Training loss: 2.0255658626556396
Validation loss: 2.0425355384747186

Epoch: 5| Step: 10
Training loss: 1.37388277053833
Validation loss: 2.0355259825785956

Epoch: 5| Step: 11
Training loss: 2.455076217651367
Validation loss: 2.0806012600660324

Epoch: 44| Step: 0
Training loss: 1.6892191171646118
Validation loss: 2.028756062189738

Epoch: 5| Step: 1
Training loss: 1.9369688034057617
Validation loss: 2.057947432001432

Epoch: 5| Step: 2
Training loss: 2.357144594192505
Validation loss: 2.0583673417568207

Epoch: 5| Step: 3
Training loss: 1.4280322790145874
Validation loss: 2.0946759581565857

Epoch: 5| Step: 4
Training loss: 2.326512336730957
Validation loss: 2.0974203745524087

Epoch: 5| Step: 5
Training loss: 2.1079983711242676
Validation loss: 2.0599111119906106

Epoch: 5| Step: 6
Training loss: 1.5452731847763062
Validation loss: 2.0609844078620276

Epoch: 5| Step: 7
Training loss: 1.9876333475112915
Validation loss: 2.081042860945066

Epoch: 5| Step: 8
Training loss: 1.7852153778076172
Validation loss: 2.113601510723432

Epoch: 5| Step: 9
Training loss: 2.5850841999053955
Validation loss: 2.0888208746910095

Epoch: 5| Step: 10
Training loss: 1.6309947967529297
Validation loss: 2.08378674586614

Epoch: 5| Step: 11
Training loss: 2.3107752799987793
Validation loss: 2.0788807521263757

Epoch: 45| Step: 0
Training loss: 2.2797982692718506
Validation loss: 2.1385166496038437

Epoch: 5| Step: 1
Training loss: 2.082108974456787
Validation loss: 2.089269498984019

Epoch: 5| Step: 2
Training loss: 2.0521068572998047
Validation loss: 2.0833157102266946

Epoch: 5| Step: 3
Training loss: 1.8653064966201782
Validation loss: 2.1015960524479547

Epoch: 5| Step: 4
Training loss: 1.7851022481918335
Validation loss: 2.0737797915935516

Epoch: 5| Step: 5
Training loss: 1.8564296960830688
Validation loss: 2.1020679473876953

Epoch: 5| Step: 6
Training loss: 1.8383986949920654
Validation loss: 2.0817923545837402

Epoch: 5| Step: 7
Training loss: 2.2408032417297363
Validation loss: 2.05666975180308

Epoch: 5| Step: 8
Training loss: 1.4628221988677979
Validation loss: 2.061313644051552

Epoch: 5| Step: 9
Training loss: 1.8088384866714478
Validation loss: 2.0549346059560776

Epoch: 5| Step: 10
Training loss: 2.158104658126831
Validation loss: 2.059263984362284

Epoch: 5| Step: 11
Training loss: 2.0734009742736816
Validation loss: 2.029748946428299

Epoch: 46| Step: 0
Training loss: 1.7135149240493774
Validation loss: 2.0901218553384147

Epoch: 5| Step: 1
Training loss: 1.706032156944275
Validation loss: 2.1167809069156647

Epoch: 5| Step: 2
Training loss: 1.5185571908950806
Validation loss: 2.0969867755969367

Epoch: 5| Step: 3
Training loss: 2.54156231880188
Validation loss: 2.105758195122083

Epoch: 5| Step: 4
Training loss: 2.1469173431396484
Validation loss: 2.101736292243004

Epoch: 5| Step: 5
Training loss: 2.218366861343384
Validation loss: 2.077940712372462

Epoch: 5| Step: 6
Training loss: 2.237619638442993
Validation loss: 2.1101937542359033

Epoch: 5| Step: 7
Training loss: 2.1985082626342773
Validation loss: 2.070003146926562

Epoch: 5| Step: 8
Training loss: 1.6519358158111572
Validation loss: 2.0742641339699426

Epoch: 5| Step: 9
Training loss: 2.1406662464141846
Validation loss: 2.0788209239641824

Epoch: 5| Step: 10
Training loss: 1.6837615966796875
Validation loss: 2.066259210308393

Epoch: 5| Step: 11
Training loss: 1.0858367681503296
Validation loss: 2.0513524065415063

Epoch: 47| Step: 0
Training loss: 2.1958842277526855
Validation loss: 2.054090296228727

Epoch: 5| Step: 1
Training loss: 2.604186534881592
Validation loss: 2.0778462340434394

Epoch: 5| Step: 2
Training loss: 1.2246206998825073
Validation loss: 2.093177149693171

Epoch: 5| Step: 3
Training loss: 1.8907585144042969
Validation loss: 2.059325118859609

Epoch: 5| Step: 4
Training loss: 1.983315110206604
Validation loss: 2.0517632315556207

Epoch: 5| Step: 5
Training loss: 1.9805492162704468
Validation loss: 2.0909719119469323

Epoch: 5| Step: 6
Training loss: 1.9759305715560913
Validation loss: 2.1011106818914413

Epoch: 5| Step: 7
Training loss: 1.671457290649414
Validation loss: 2.103052089611689

Epoch: 5| Step: 8
Training loss: 1.8619461059570312
Validation loss: 2.0744150330622992

Epoch: 5| Step: 9
Training loss: 1.9974193572998047
Validation loss: 2.062285835544268

Epoch: 5| Step: 10
Training loss: 2.20082426071167
Validation loss: 2.0615658362706504

Epoch: 5| Step: 11
Training loss: 1.4334886074066162
Validation loss: 2.0715828090906143

Epoch: 48| Step: 0
Training loss: 1.5632333755493164
Validation loss: 2.0834441035985947

Epoch: 5| Step: 1
Training loss: 2.280311346054077
Validation loss: 2.112240488330523

Epoch: 5| Step: 2
Training loss: 1.8165782690048218
Validation loss: 2.063585956891378

Epoch: 5| Step: 3
Training loss: 2.1726620197296143
Validation loss: 2.053161079684893

Epoch: 5| Step: 4
Training loss: 2.3209261894226074
Validation loss: 2.115490883588791

Epoch: 5| Step: 5
Training loss: 1.2726905345916748
Validation loss: 2.0926344146331153

Epoch: 5| Step: 6
Training loss: 2.25822114944458
Validation loss: 2.054304932554563

Epoch: 5| Step: 7
Training loss: 1.8170146942138672
Validation loss: 2.0677103896935782

Epoch: 5| Step: 8
Training loss: 1.998927354812622
Validation loss: 2.1080671648184457

Epoch: 5| Step: 9
Training loss: 2.29677677154541
Validation loss: 2.1153077284495034

Epoch: 5| Step: 10
Training loss: 1.6737754344940186
Validation loss: 2.0564777155717215

Epoch: 5| Step: 11
Training loss: 2.3752129077911377
Validation loss: 2.0499633252620697

Epoch: 49| Step: 0
Training loss: 2.4726574420928955
Validation loss: 2.0747712502876916

Epoch: 5| Step: 1
Training loss: 1.7930828332901
Validation loss: 2.044841984907786

Epoch: 5| Step: 2
Training loss: 2.1419143676757812
Validation loss: 2.041943217317263

Epoch: 5| Step: 3
Training loss: 1.6893527507781982
Validation loss: 2.0774943629900613

Epoch: 5| Step: 4
Training loss: 1.8524806499481201
Validation loss: 2.0751678943634033

Epoch: 5| Step: 5
Training loss: 2.005513906478882
Validation loss: 2.0808590004841485

Epoch: 5| Step: 6
Training loss: 1.57866370677948
Validation loss: 2.0705120166142783

Epoch: 5| Step: 7
Training loss: 1.5364781618118286
Validation loss: 2.1213708966970444

Epoch: 5| Step: 8
Training loss: 2.448270082473755
Validation loss: 2.1124856819709144

Epoch: 5| Step: 9
Training loss: 1.8721086978912354
Validation loss: 2.0856603235006332

Epoch: 5| Step: 10
Training loss: 1.9781310558319092
Validation loss: 2.090229739745458

Epoch: 5| Step: 11
Training loss: 2.450681686401367
Validation loss: 2.121160472432772

Epoch: 50| Step: 0
Training loss: 1.691401481628418
Validation loss: 2.1119460513194404

Epoch: 5| Step: 1
Training loss: 1.6468970775604248
Validation loss: 2.041651745637258

Epoch: 5| Step: 2
Training loss: 1.563780665397644
Validation loss: 2.0608604649702706

Epoch: 5| Step: 3
Training loss: 2.090195655822754
Validation loss: 2.0127007365226746

Epoch: 5| Step: 4
Training loss: 1.5406705141067505
Validation loss: 2.0578436156113944

Epoch: 5| Step: 5
Training loss: 1.9653418064117432
Validation loss: 2.0962138175964355

Epoch: 5| Step: 6
Training loss: 1.9689849615097046
Validation loss: 2.0923405388991037

Epoch: 5| Step: 7
Training loss: 1.7288408279418945
Validation loss: 2.0391108244657516

Epoch: 5| Step: 8
Training loss: 2.1102681159973145
Validation loss: 2.0736620078484216

Epoch: 5| Step: 9
Training loss: 2.8005130290985107
Validation loss: 2.0630585700273514

Epoch: 5| Step: 10
Training loss: 2.433396816253662
Validation loss: 2.1107565065224967

Epoch: 5| Step: 11
Training loss: 1.7154908180236816
Validation loss: 2.085314467549324

Epoch: 51| Step: 0
Training loss: 2.0573127269744873
Validation loss: 2.087499643365542

Epoch: 5| Step: 1
Training loss: 2.344308853149414
Validation loss: 2.04435400168101

Epoch: 5| Step: 2
Training loss: 1.420113205909729
Validation loss: 2.06330798069636

Epoch: 5| Step: 3
Training loss: 1.7975378036499023
Validation loss: 2.1107662419478097

Epoch: 5| Step: 4
Training loss: 1.7453407049179077
Validation loss: 2.057686910033226

Epoch: 5| Step: 5
Training loss: 2.0180552005767822
Validation loss: 2.0516184121370316

Epoch: 5| Step: 6
Training loss: 2.5534825325012207
Validation loss: 2.069578136006991

Epoch: 5| Step: 7
Training loss: 1.1404682397842407
Validation loss: 2.0686574081579843

Epoch: 5| Step: 8
Training loss: 1.6793121099472046
Validation loss: 2.0899982949097953

Epoch: 5| Step: 9
Training loss: 2.094942808151245
Validation loss: 2.061142380038897

Epoch: 5| Step: 10
Training loss: 2.214327573776245
Validation loss: 2.056307698289553

Epoch: 5| Step: 11
Training loss: 1.9057326316833496
Validation loss: 2.0369854917128882

Epoch: 52| Step: 0
Training loss: 1.704869031906128
Validation loss: 2.070654054482778

Epoch: 5| Step: 1
Training loss: 2.1580681800842285
Validation loss: 2.06048912803332

Epoch: 5| Step: 2
Training loss: 1.9300934076309204
Validation loss: 2.1090312947829566

Epoch: 5| Step: 3
Training loss: 1.8421955108642578
Validation loss: 2.1458298514286676

Epoch: 5| Step: 4
Training loss: 2.2002835273742676
Validation loss: 2.107878456513087

Epoch: 5| Step: 5
Training loss: 2.177493095397949
Validation loss: 2.1460151374340057

Epoch: 5| Step: 6
Training loss: 2.407395124435425
Validation loss: 2.086278279622396

Epoch: 5| Step: 7
Training loss: 1.8172111511230469
Validation loss: 2.0930992364883423

Epoch: 5| Step: 8
Training loss: 2.1220993995666504
Validation loss: 2.053635189930598

Epoch: 5| Step: 9
Training loss: 1.6605583429336548
Validation loss: 2.1244686196247735

Epoch: 5| Step: 10
Training loss: 1.1360011100769043
Validation loss: 2.0799128860235214

Epoch: 5| Step: 11
Training loss: 2.331660747528076
Validation loss: 2.066762293378512

Epoch: 53| Step: 0
Training loss: 1.9749435186386108
Validation loss: 2.0691473384698233

Epoch: 5| Step: 1
Training loss: 1.7474861145019531
Validation loss: 2.071510523557663

Epoch: 5| Step: 2
Training loss: 1.998931884765625
Validation loss: 2.02838763097922

Epoch: 5| Step: 3
Training loss: 2.07346773147583
Validation loss: 2.0783060987790427

Epoch: 5| Step: 4
Training loss: 1.8716309070587158
Validation loss: 2.077730049689611

Epoch: 5| Step: 5
Training loss: 2.0582540035247803
Validation loss: 2.064582178990046

Epoch: 5| Step: 6
Training loss: 2.4267234802246094
Validation loss: 2.1410033206144967

Epoch: 5| Step: 7
Training loss: 1.7104852199554443
Validation loss: 2.0585391024748483

Epoch: 5| Step: 8
Training loss: 2.2375435829162598
Validation loss: 2.080709551771482

Epoch: 5| Step: 9
Training loss: 1.6589629650115967
Validation loss: 2.0804033130407333

Epoch: 5| Step: 10
Training loss: 1.4551767110824585
Validation loss: 2.066620245575905

Epoch: 5| Step: 11
Training loss: 2.41847562789917
Validation loss: 2.1098042031129203

Epoch: 54| Step: 0
Training loss: 1.5452090501785278
Validation loss: 2.097514202197393

Epoch: 5| Step: 1
Training loss: 1.9228026866912842
Validation loss: 2.1013501236836114

Epoch: 5| Step: 2
Training loss: 1.3709304332733154
Validation loss: 1.9925848692655563

Epoch: 5| Step: 3
Training loss: 2.502915143966675
Validation loss: 2.1343284398317337

Epoch: 5| Step: 4
Training loss: 2.200052499771118
Validation loss: 2.062795196970304

Epoch: 5| Step: 5
Training loss: 2.362144947052002
Validation loss: 2.0783362835645676

Epoch: 5| Step: 6
Training loss: 1.5370217561721802
Validation loss: 2.0535167952378592

Epoch: 5| Step: 7
Training loss: 1.3397207260131836
Validation loss: 2.0116871098677316

Epoch: 5| Step: 8
Training loss: 2.034172773361206
Validation loss: 2.0752188165982566

Epoch: 5| Step: 9
Training loss: 2.1421689987182617
Validation loss: 2.0309016555547714

Epoch: 5| Step: 10
Training loss: 2.222442626953125
Validation loss: 2.1012276311715445

Epoch: 5| Step: 11
Training loss: 0.4724702835083008
Validation loss: 2.093818118174871

Epoch: 55| Step: 0
Training loss: 2.1138670444488525
Validation loss: 2.0486957480510077

Epoch: 5| Step: 1
Training loss: 1.9679046869277954
Validation loss: 2.0812666515509286

Epoch: 5| Step: 2
Training loss: 1.8314670324325562
Validation loss: 2.0603411147991815

Epoch: 5| Step: 3
Training loss: 1.9215198755264282
Validation loss: 2.1296635568141937

Epoch: 5| Step: 4
Training loss: 2.107543468475342
Validation loss: 2.0550569047530494

Epoch: 5| Step: 5
Training loss: 2.801995038986206
Validation loss: 2.076809530456861

Epoch: 5| Step: 6
Training loss: 2.0719165802001953
Validation loss: 2.09949384133021

Epoch: 5| Step: 7
Training loss: 1.8558509349822998
Validation loss: 2.0515421281258264

Epoch: 5| Step: 8
Training loss: 1.6326080560684204
Validation loss: 2.097118546565374

Epoch: 5| Step: 9
Training loss: 1.964377760887146
Validation loss: 2.0800181527932486

Epoch: 5| Step: 10
Training loss: 1.4781818389892578
Validation loss: 2.0473072677850723

Epoch: 5| Step: 11
Training loss: 1.236438274383545
Validation loss: 2.040141994754473

Epoch: 56| Step: 0
Training loss: 1.260718822479248
Validation loss: 2.0748707900444665

Epoch: 5| Step: 1
Training loss: 1.9710447788238525
Validation loss: 2.0518289109071097

Epoch: 5| Step: 2
Training loss: 1.6775190830230713
Validation loss: 2.1043511778116226

Epoch: 5| Step: 3
Training loss: 1.8273060321807861
Validation loss: 2.0965276012818017

Epoch: 5| Step: 4
Training loss: 1.677424669265747
Validation loss: 2.116454154253006

Epoch: 5| Step: 5
Training loss: 2.087094783782959
Validation loss: 2.1380559653043747

Epoch: 5| Step: 6
Training loss: 2.238647937774658
Validation loss: 2.0949676732222238

Epoch: 5| Step: 7
Training loss: 2.0279033184051514
Validation loss: 2.0783578852812448

Epoch: 5| Step: 8
Training loss: 2.1627869606018066
Validation loss: 2.0842594554026923

Epoch: 5| Step: 9
Training loss: 2.2237708568573
Validation loss: 2.1283192882935205

Epoch: 5| Step: 10
Training loss: 2.0209035873413086
Validation loss: 2.098629598816236

Epoch: 5| Step: 11
Training loss: 1.6604547500610352
Validation loss: 2.059342627724012

Epoch: 57| Step: 0
Training loss: 1.6345278024673462
Validation loss: 2.1133508334557214

Epoch: 5| Step: 1
Training loss: 2.0966525077819824
Validation loss: 2.091390843192736

Epoch: 5| Step: 2
Training loss: 1.8065860271453857
Validation loss: 2.1146700580914817

Epoch: 5| Step: 3
Training loss: 1.6304298639297485
Validation loss: 2.054658815264702

Epoch: 5| Step: 4
Training loss: 1.7063286304473877
Validation loss: 2.1595488488674164

Epoch: 5| Step: 5
Training loss: 1.9627975225448608
Validation loss: 2.0849462201197944

Epoch: 5| Step: 6
Training loss: 2.374669313430786
Validation loss: 2.0794278383255005

Epoch: 5| Step: 7
Training loss: 2.0753700733184814
Validation loss: 2.089269091685613

Epoch: 5| Step: 8
Training loss: 2.0812089443206787
Validation loss: 2.0588243206342063

Epoch: 5| Step: 9
Training loss: 1.7146692276000977
Validation loss: 2.1011857440074286

Epoch: 5| Step: 10
Training loss: 2.0050415992736816
Validation loss: 2.1049811989068985

Epoch: 5| Step: 11
Training loss: 1.2416871786117554
Validation loss: 2.0858825544516244

Epoch: 58| Step: 0
Training loss: 2.055209159851074
Validation loss: 2.0655483404795327

Epoch: 5| Step: 1
Training loss: 1.9515182971954346
Validation loss: 2.1048352072636285

Epoch: 5| Step: 2
Training loss: 1.5926611423492432
Validation loss: 2.1270127991835275

Epoch: 5| Step: 3
Training loss: 2.027923583984375
Validation loss: 2.067972550789515

Epoch: 5| Step: 4
Training loss: 2.510429859161377
Validation loss: 2.076042026281357

Epoch: 5| Step: 5
Training loss: 1.6061534881591797
Validation loss: 2.0520655314127603

Epoch: 5| Step: 6
Training loss: 1.59514582157135
Validation loss: 2.0223201662302017

Epoch: 5| Step: 7
Training loss: 1.936011552810669
Validation loss: 2.05192398528258

Epoch: 5| Step: 8
Training loss: 2.4156060218811035
Validation loss: 2.0293820202350616

Epoch: 5| Step: 9
Training loss: 1.716631293296814
Validation loss: 2.097596029440562

Epoch: 5| Step: 10
Training loss: 1.8038504123687744
Validation loss: 2.0720267544190087

Epoch: 5| Step: 11
Training loss: 1.2825645208358765
Validation loss: 2.0611052811145782

Epoch: 59| Step: 0
Training loss: 1.729824423789978
Validation loss: 2.1318125873804092

Epoch: 5| Step: 1
Training loss: 1.9814870357513428
Validation loss: 2.0820423612991967

Epoch: 5| Step: 2
Training loss: 1.6781284809112549
Validation loss: 2.1203408191601434

Epoch: 5| Step: 3
Training loss: 1.6258933544158936
Validation loss: 2.119199961423874

Epoch: 5| Step: 4
Training loss: 1.722611665725708
Validation loss: 2.0613664587338767

Epoch: 5| Step: 5
Training loss: 1.6953239440917969
Validation loss: 2.09870312611262

Epoch: 5| Step: 6
Training loss: 0.906600832939148
Validation loss: 2.110090414683024

Epoch: 5| Step: 7
Training loss: 1.9036321640014648
Validation loss: 2.0879696855942407

Epoch: 5| Step: 8
Training loss: 2.849942445755005
Validation loss: 2.116396506627401

Epoch: 5| Step: 9
Training loss: 2.360220193862915
Validation loss: 2.0703584800163903

Epoch: 5| Step: 10
Training loss: 2.1101739406585693
Validation loss: 2.049952124555906

Epoch: 5| Step: 11
Training loss: 3.181269645690918
Validation loss: 2.0809074888626733

Epoch: 60| Step: 0
Training loss: 1.8058379888534546
Validation loss: 2.1057329376538596

Epoch: 5| Step: 1
Training loss: 1.9660406112670898
Validation loss: 2.11654465397199

Epoch: 5| Step: 2
Training loss: 1.9303429126739502
Validation loss: 2.0823490917682648

Epoch: 5| Step: 3
Training loss: 1.7419334650039673
Validation loss: 2.0527150283257165

Epoch: 5| Step: 4
Training loss: 2.0840718746185303
Validation loss: 2.0603681405385337

Epoch: 5| Step: 5
Training loss: 2.1590518951416016
Validation loss: 2.0728861888249717

Epoch: 5| Step: 6
Training loss: 1.6200590133666992
Validation loss: 2.1039216419061026

Epoch: 5| Step: 7
Training loss: 2.114264965057373
Validation loss: 2.0720117390155792

Epoch: 5| Step: 8
Training loss: 1.4546144008636475
Validation loss: 2.0580755223830542

Epoch: 5| Step: 9
Training loss: 2.0774776935577393
Validation loss: 2.039877990881602

Epoch: 5| Step: 10
Training loss: 1.717733383178711
Validation loss: 2.025983730951945

Epoch: 5| Step: 11
Training loss: 0.45662081241607666
Validation loss: 2.02055857082208

Epoch: 61| Step: 0
Training loss: 1.9535554647445679
Validation loss: 2.035929580529531

Epoch: 5| Step: 1
Training loss: 2.402784824371338
Validation loss: 2.11689455807209

Epoch: 5| Step: 2
Training loss: 1.9913225173950195
Validation loss: 2.0753995378812156

Epoch: 5| Step: 3
Training loss: 2.4262166023254395
Validation loss: 2.100102181235949

Epoch: 5| Step: 4
Training loss: 2.2079989910125732
Validation loss: 2.2189712474743524

Epoch: 5| Step: 5
Training loss: 1.8008575439453125
Validation loss: 2.093933011094729

Epoch: 5| Step: 6
Training loss: 1.5122767686843872
Validation loss: 2.1339640468358994

Epoch: 5| Step: 7
Training loss: 1.9793497323989868
Validation loss: 2.111640746394793

Epoch: 5| Step: 8
Training loss: 1.2903121709823608
Validation loss: 2.1100049366553626

Epoch: 5| Step: 9
Training loss: 1.8923110961914062
Validation loss: 2.067582761247953

Epoch: 5| Step: 10
Training loss: 1.3571455478668213
Validation loss: 2.0779680808385215

Epoch: 5| Step: 11
Training loss: 3.0728607177734375
Validation loss: 2.03738796710968

Epoch: 62| Step: 0
Training loss: 1.504136323928833
Validation loss: 2.0899274547894797

Epoch: 5| Step: 1
Training loss: 2.185724973678589
Validation loss: 2.0730458746353784

Epoch: 5| Step: 2
Training loss: 1.9681529998779297
Validation loss: 2.103019038836161

Epoch: 5| Step: 3
Training loss: 2.751072406768799
Validation loss: 2.1050075193246207

Epoch: 5| Step: 4
Training loss: 1.6237766742706299
Validation loss: 2.132970154285431

Epoch: 5| Step: 5
Training loss: 2.0018832683563232
Validation loss: 2.09030781686306

Epoch: 5| Step: 6
Training loss: 1.4770116806030273
Validation loss: 2.1009850998719535

Epoch: 5| Step: 7
Training loss: 2.3656201362609863
Validation loss: 2.0754171510537467

Epoch: 5| Step: 8
Training loss: 2.1973624229431152
Validation loss: 2.0848989337682724

Epoch: 5| Step: 9
Training loss: 1.5812644958496094
Validation loss: 2.064894085129102

Epoch: 5| Step: 10
Training loss: 1.6864793300628662
Validation loss: 2.117524822552999

Epoch: 5| Step: 11
Training loss: 1.2540544271469116
Validation loss: 2.092316761612892

Epoch: 63| Step: 0
Training loss: 2.044370174407959
Validation loss: 2.079918091495832

Epoch: 5| Step: 1
Training loss: 1.6573848724365234
Validation loss: 2.0771311322848

Epoch: 5| Step: 2
Training loss: 1.5846283435821533
Validation loss: 2.0902310957511268

Epoch: 5| Step: 3
Training loss: 2.018569231033325
Validation loss: 2.0808861702680588

Epoch: 5| Step: 4
Training loss: 1.9294328689575195
Validation loss: 2.1159807642300925

Epoch: 5| Step: 5
Training loss: 1.9805781841278076
Validation loss: 2.0962062726418176

Epoch: 5| Step: 6
Training loss: 1.969580888748169
Validation loss: 2.1370841364065805

Epoch: 5| Step: 7
Training loss: 1.9189401865005493
Validation loss: 2.104990382989248

Epoch: 5| Step: 8
Training loss: 2.1587677001953125
Validation loss: 2.09061923623085

Epoch: 5| Step: 9
Training loss: 1.8980770111083984
Validation loss: 2.0990320493777594

Epoch: 5| Step: 10
Training loss: 1.5832557678222656
Validation loss: 2.133136366804441

Epoch: 5| Step: 11
Training loss: 1.2149946689605713
Validation loss: 2.092545504371325

Epoch: 64| Step: 0
Training loss: 1.5382124185562134
Validation loss: 2.037207509080569

Epoch: 5| Step: 1
Training loss: 1.7414190769195557
Validation loss: 2.094838877518972

Epoch: 5| Step: 2
Training loss: 2.136131525039673
Validation loss: 2.0901749233404794

Epoch: 5| Step: 3
Training loss: 1.9280065298080444
Validation loss: 2.091025705138842

Epoch: 5| Step: 4
Training loss: 1.7080663442611694
Validation loss: 2.0851313769817352

Epoch: 5| Step: 5
Training loss: 2.332831859588623
Validation loss: 2.1082835495471954

Epoch: 5| Step: 6
Training loss: 1.6760972738265991
Validation loss: 2.106125702460607

Epoch: 5| Step: 7
Training loss: 1.9843647480010986
Validation loss: 2.066273495554924

Epoch: 5| Step: 8
Training loss: 1.924159288406372
Validation loss: 2.056110163529714

Epoch: 5| Step: 9
Training loss: 1.724310278892517
Validation loss: 2.080186128616333

Epoch: 5| Step: 10
Training loss: 2.1095266342163086
Validation loss: 2.065921356280645

Epoch: 5| Step: 11
Training loss: 1.8401973247528076
Validation loss: 2.0763752162456512

Epoch: 65| Step: 0
Training loss: 2.332146167755127
Validation loss: 2.076888700326284

Epoch: 5| Step: 1
Training loss: 1.04213285446167
Validation loss: 2.0924361248811087

Epoch: 5| Step: 2
Training loss: 1.4987695217132568
Validation loss: 2.095684210459391

Epoch: 5| Step: 3
Training loss: 2.2676870822906494
Validation loss: 2.1030434469381967

Epoch: 5| Step: 4
Training loss: 1.503476619720459
Validation loss: 2.1029217342535653

Epoch: 5| Step: 5
Training loss: 1.9155651330947876
Validation loss: 2.066655784845352

Epoch: 5| Step: 6
Training loss: 1.90959894657135
Validation loss: 2.0765569458405175

Epoch: 5| Step: 7
Training loss: 1.6421964168548584
Validation loss: 2.0497602919737496

Epoch: 5| Step: 8
Training loss: 1.8278563022613525
Validation loss: 2.1398485749959946

Epoch: 5| Step: 9
Training loss: 2.3819408416748047
Validation loss: 2.128768195708593

Epoch: 5| Step: 10
Training loss: 2.037288188934326
Validation loss: 2.0754523475964866

Epoch: 5| Step: 11
Training loss: 2.384554386138916
Validation loss: 2.0816943595806756

Epoch: 66| Step: 0
Training loss: 1.7266868352890015
Validation loss: 2.097329795360565

Epoch: 5| Step: 1
Training loss: 2.266555070877075
Validation loss: 2.0848471174637475

Epoch: 5| Step: 2
Training loss: 1.6567022800445557
Validation loss: 2.0761524587869644

Epoch: 5| Step: 3
Training loss: 2.4337716102600098
Validation loss: 2.101527954141299

Epoch: 5| Step: 4
Training loss: 1.6680548191070557
Validation loss: 2.1206679145495095

Epoch: 5| Step: 5
Training loss: 2.026358127593994
Validation loss: 2.0828390767176947

Epoch: 5| Step: 6
Training loss: 1.3358814716339111
Validation loss: 2.101344113548597

Epoch: 5| Step: 7
Training loss: 1.8673204183578491
Validation loss: 2.124650696913401

Epoch: 5| Step: 8
Training loss: 1.8410613536834717
Validation loss: 2.07194813589255

Epoch: 5| Step: 9
Training loss: 1.8489348888397217
Validation loss: 2.1151078740755715

Epoch: 5| Step: 10
Training loss: 1.8682241439819336
Validation loss: 2.0422013203303018

Epoch: 5| Step: 11
Training loss: 1.481923222541809
Validation loss: 2.109522059559822

Epoch: 67| Step: 0
Training loss: 1.7257251739501953
Validation loss: 2.0756607005993524

Epoch: 5| Step: 1
Training loss: 1.6059436798095703
Validation loss: 2.135676622390747

Epoch: 5| Step: 2
Training loss: 1.83805251121521
Validation loss: 2.0911956230799356

Epoch: 5| Step: 3
Training loss: 2.2806649208068848
Validation loss: 2.0793616473674774

Epoch: 5| Step: 4
Training loss: 1.825927972793579
Validation loss: 2.0637611548105874

Epoch: 5| Step: 5
Training loss: 1.8592897653579712
Validation loss: 2.1495326856772103

Epoch: 5| Step: 6
Training loss: 2.131126880645752
Validation loss: 2.039262776573499

Epoch: 5| Step: 7
Training loss: 1.7349720001220703
Validation loss: 2.111593266328176

Epoch: 5| Step: 8
Training loss: 1.4100388288497925
Validation loss: 2.0629763007164

Epoch: 5| Step: 9
Training loss: 1.9708852767944336
Validation loss: 2.119205723206202

Epoch: 5| Step: 10
Training loss: 1.963067650794983
Validation loss: 2.057037884990374

Epoch: 5| Step: 11
Training loss: 3.028327465057373
Validation loss: 2.1147330850362778

Epoch: 68| Step: 0
Training loss: 2.6119022369384766
Validation loss: 2.047757312655449

Epoch: 5| Step: 1
Training loss: 1.946993112564087
Validation loss: 2.050826758146286

Epoch: 5| Step: 2
Training loss: 2.252392053604126
Validation loss: 2.1447869390249252

Epoch: 5| Step: 3
Training loss: 1.8921918869018555
Validation loss: 2.1419304559628167

Epoch: 5| Step: 4
Training loss: 1.5277535915374756
Validation loss: 2.2055783619483313

Epoch: 5| Step: 5
Training loss: 2.074347734451294
Validation loss: 2.1527890960375466

Epoch: 5| Step: 6
Training loss: 1.7730411291122437
Validation loss: 2.142199789484342

Epoch: 5| Step: 7
Training loss: 1.8545777797698975
Validation loss: 2.172527402639389

Epoch: 5| Step: 8
Training loss: 1.4766838550567627
Validation loss: 2.212749481201172

Epoch: 5| Step: 9
Training loss: 1.8853175640106201
Validation loss: 2.1227172364791236

Epoch: 5| Step: 10
Training loss: 1.9298808574676514
Validation loss: 2.066353961825371

Epoch: 5| Step: 11
Training loss: 2.201192617416382
Validation loss: 2.1522612273693085

Epoch: 69| Step: 0
Training loss: 1.7589843273162842
Validation loss: 2.1514927496512732

Epoch: 5| Step: 1
Training loss: 1.9272903203964233
Validation loss: 2.126519779364268

Epoch: 5| Step: 2
Training loss: 1.6825990676879883
Validation loss: 2.1397241204977036

Epoch: 5| Step: 3
Training loss: 1.997125267982483
Validation loss: 2.1572414388259253

Epoch: 5| Step: 4
Training loss: 1.589438557624817
Validation loss: 2.0939484437306723

Epoch: 5| Step: 5
Training loss: 2.2923569679260254
Validation loss: 2.12993685901165

Epoch: 5| Step: 6
Training loss: 2.1849822998046875
Validation loss: 2.1190952509641647

Epoch: 5| Step: 7
Training loss: 2.015610933303833
Validation loss: 2.1211169958114624

Epoch: 5| Step: 8
Training loss: 2.252793073654175
Validation loss: 2.1147592018047967

Epoch: 5| Step: 9
Training loss: 2.1436524391174316
Validation loss: 2.09640001753966

Epoch: 5| Step: 10
Training loss: 1.780194640159607
Validation loss: 2.114911119143168

Epoch: 5| Step: 11
Training loss: 1.3055230379104614
Validation loss: 2.081193039814631

Epoch: 70| Step: 0
Training loss: 1.995523452758789
Validation loss: 2.057431146502495

Epoch: 5| Step: 1
Training loss: 1.6508582830429077
Validation loss: 2.096960057814916

Epoch: 5| Step: 2
Training loss: 1.7781181335449219
Validation loss: 2.0819735626379647

Epoch: 5| Step: 3
Training loss: 2.21195387840271
Validation loss: 2.092147966225942

Epoch: 5| Step: 4
Training loss: 1.7206032276153564
Validation loss: 2.1720522145430246

Epoch: 5| Step: 5
Training loss: 1.5894007682800293
Validation loss: 2.1219262232383094

Epoch: 5| Step: 6
Training loss: 2.0211708545684814
Validation loss: 2.1391256054242453

Epoch: 5| Step: 7
Training loss: 1.865769624710083
Validation loss: 2.1140583554903665

Epoch: 5| Step: 8
Training loss: 2.4266490936279297
Validation loss: 2.0705052465200424

Epoch: 5| Step: 9
Training loss: 1.807090401649475
Validation loss: 2.150452251235644

Epoch: 5| Step: 10
Training loss: 1.700505256652832
Validation loss: 2.085303525129954

Epoch: 5| Step: 11
Training loss: 1.3718653917312622
Validation loss: 2.1000158488750458

Epoch: 71| Step: 0
Training loss: 1.8207868337631226
Validation loss: 2.0877215464909873

Epoch: 5| Step: 1
Training loss: 2.070178508758545
Validation loss: 2.0424523651599884

Epoch: 5| Step: 2
Training loss: 1.9858916997909546
Validation loss: 2.115306317806244

Epoch: 5| Step: 3
Training loss: 1.585273027420044
Validation loss: 2.134180709719658

Epoch: 5| Step: 4
Training loss: 1.6472835540771484
Validation loss: 2.0810294151306152

Epoch: 5| Step: 5
Training loss: 1.7426589727401733
Validation loss: 2.083964685599009

Epoch: 5| Step: 6
Training loss: 2.247326374053955
Validation loss: 2.11814812819163

Epoch: 5| Step: 7
Training loss: 1.7558174133300781
Validation loss: 2.1351522405942283

Epoch: 5| Step: 8
Training loss: 1.6961253881454468
Validation loss: 2.091996689637502

Epoch: 5| Step: 9
Training loss: 2.012753963470459
Validation loss: 2.0972362011671066

Epoch: 5| Step: 10
Training loss: 1.8706468343734741
Validation loss: 2.098647713661194

Epoch: 5| Step: 11
Training loss: 2.4715371131896973
Validation loss: 2.1417104502518973

Epoch: 72| Step: 0
Training loss: 1.7021448612213135
Validation loss: 2.0917204221089682

Epoch: 5| Step: 1
Training loss: 1.5055854320526123
Validation loss: 2.118847221136093

Epoch: 5| Step: 2
Training loss: 1.8377025127410889
Validation loss: 2.1077591677506766

Epoch: 5| Step: 3
Training loss: 2.0623862743377686
Validation loss: 2.1875062038501105

Epoch: 5| Step: 4
Training loss: 2.044297695159912
Validation loss: 2.134245311220487

Epoch: 5| Step: 5
Training loss: 2.003324508666992
Validation loss: 2.1478018214305243

Epoch: 5| Step: 6
Training loss: 1.9478235244750977
Validation loss: 2.1454760134220123

Epoch: 5| Step: 7
Training loss: 1.4833886623382568
Validation loss: 2.181103711326917

Epoch: 5| Step: 8
Training loss: 2.3699746131896973
Validation loss: 2.1068661461273828

Epoch: 5| Step: 9
Training loss: 1.6810786724090576
Validation loss: 2.162954419851303

Epoch: 5| Step: 10
Training loss: 1.7895982265472412
Validation loss: 2.1284529666105905

Epoch: 5| Step: 11
Training loss: 2.375856876373291
Validation loss: 2.090453421076139

Epoch: 73| Step: 0
Training loss: 1.4485394954681396
Validation loss: 2.0776278227567673

Epoch: 5| Step: 1
Training loss: 1.100571870803833
Validation loss: 2.060038963953654

Epoch: 5| Step: 2
Training loss: 2.6160013675689697
Validation loss: 2.0646759470303855

Epoch: 5| Step: 3
Training loss: 1.9063360691070557
Validation loss: 2.098248228430748

Epoch: 5| Step: 4
Training loss: 2.422703266143799
Validation loss: 2.0683682958285012

Epoch: 5| Step: 5
Training loss: 1.913923978805542
Validation loss: 2.1167229314645133

Epoch: 5| Step: 6
Training loss: 2.1458163261413574
Validation loss: 2.1671119779348373

Epoch: 5| Step: 7
Training loss: 1.5101646184921265
Validation loss: 2.113713597257932

Epoch: 5| Step: 8
Training loss: 1.6226695775985718
Validation loss: 2.0985628068447113

Epoch: 5| Step: 9
Training loss: 2.210221290588379
Validation loss: 2.1253401935100555

Epoch: 5| Step: 10
Training loss: 1.6344547271728516
Validation loss: 2.105916514992714

Epoch: 5| Step: 11
Training loss: 1.3746896982192993
Validation loss: 2.097185656428337

Epoch: 74| Step: 0
Training loss: 1.5404341220855713
Validation loss: 2.0927409877379737

Epoch: 5| Step: 1
Training loss: 1.8345272541046143
Validation loss: 2.061865026752154

Epoch: 5| Step: 2
Training loss: 1.8186219930648804
Validation loss: 2.1024076094230018

Epoch: 5| Step: 3
Training loss: 1.6659656763076782
Validation loss: 2.059271658460299

Epoch: 5| Step: 4
Training loss: 2.050464630126953
Validation loss: 2.1083707561095557

Epoch: 5| Step: 5
Training loss: 2.0144832134246826
Validation loss: 2.1240450143814087

Epoch: 5| Step: 6
Training loss: 1.4618264436721802
Validation loss: 2.0890544056892395

Epoch: 5| Step: 7
Training loss: 2.0484158992767334
Validation loss: 2.029698138435682

Epoch: 5| Step: 8
Training loss: 1.712604284286499
Validation loss: 2.1204622288544974

Epoch: 5| Step: 9
Training loss: 2.075451612472534
Validation loss: 2.074832042058309

Epoch: 5| Step: 10
Training loss: 2.373272180557251
Validation loss: 2.120930920044581

Epoch: 5| Step: 11
Training loss: 3.8907179832458496
Validation loss: 2.1373996237913766

Epoch: 75| Step: 0
Training loss: 1.4781408309936523
Validation loss: 2.068353225787481

Epoch: 5| Step: 1
Training loss: 2.2045624256134033
Validation loss: 2.0609056452910104

Epoch: 5| Step: 2
Training loss: 1.8327767848968506
Validation loss: 2.1161161561807

Epoch: 5| Step: 3
Training loss: 2.454833507537842
Validation loss: 2.087912698586782

Epoch: 5| Step: 4
Training loss: 1.6358118057250977
Validation loss: 2.1358582228422165

Epoch: 5| Step: 5
Training loss: 2.2933380603790283
Validation loss: 2.075964649518331

Epoch: 5| Step: 6
Training loss: 1.5250213146209717
Validation loss: 2.152802214026451

Epoch: 5| Step: 7
Training loss: 1.9414746761322021
Validation loss: 2.092939108610153

Epoch: 5| Step: 8
Training loss: 1.4587675333023071
Validation loss: 2.102819869915644

Epoch: 5| Step: 9
Training loss: 1.3787133693695068
Validation loss: 2.0296379824479422

Epoch: 5| Step: 10
Training loss: 1.8800504207611084
Validation loss: 2.0974103113015494

Epoch: 5| Step: 11
Training loss: 1.177210807800293
Validation loss: 2.1182162016630173

Epoch: 76| Step: 0
Training loss: 1.8517824411392212
Validation loss: 2.099284519751867

Epoch: 5| Step: 1
Training loss: 2.508950710296631
Validation loss: 2.114654392004013

Epoch: 5| Step: 2
Training loss: 1.5974658727645874
Validation loss: 2.061725323398908

Epoch: 5| Step: 3
Training loss: 1.678113579750061
Validation loss: 2.1070944716533027

Epoch: 5| Step: 4
Training loss: 1.691459059715271
Validation loss: 2.082532371083895

Epoch: 5| Step: 5
Training loss: 2.0462515354156494
Validation loss: 2.0932503839333854

Epoch: 5| Step: 6
Training loss: 1.647017240524292
Validation loss: 2.1257631878058114

Epoch: 5| Step: 7
Training loss: 1.5852738618850708
Validation loss: 2.031810616453489

Epoch: 5| Step: 8
Training loss: 2.0797111988067627
Validation loss: 2.156121407945951

Epoch: 5| Step: 9
Training loss: 1.9179036617279053
Validation loss: 2.0737095028162003

Epoch: 5| Step: 10
Training loss: 1.7244980335235596
Validation loss: 2.0926235566536584

Epoch: 5| Step: 11
Training loss: 1.0879590511322021
Validation loss: 2.0905223886171975

Epoch: 77| Step: 0
Training loss: 1.8107397556304932
Validation loss: 2.0901655157407126

Epoch: 5| Step: 1
Training loss: 1.8038685321807861
Validation loss: 2.1076855113108954

Epoch: 5| Step: 2
Training loss: 1.5711090564727783
Validation loss: 2.1049957275390625

Epoch: 5| Step: 3
Training loss: 1.407348871231079
Validation loss: 2.0561594863732657

Epoch: 5| Step: 4
Training loss: 1.6675268411636353
Validation loss: 2.1065916270017624

Epoch: 5| Step: 5
Training loss: 2.297621250152588
Validation loss: 2.1116839249928794

Epoch: 5| Step: 6
Training loss: 2.250335454940796
Validation loss: 2.1647239128748574

Epoch: 5| Step: 7
Training loss: 1.3623379468917847
Validation loss: 2.1318567295869193

Epoch: 5| Step: 8
Training loss: 2.0368716716766357
Validation loss: 2.1180275877316794

Epoch: 5| Step: 9
Training loss: 2.2989912033081055
Validation loss: 2.1315393845240274

Epoch: 5| Step: 10
Training loss: 1.3646981716156006
Validation loss: 2.1003361294666925

Epoch: 5| Step: 11
Training loss: 3.570185422897339
Validation loss: 2.150652860601743

Epoch: 78| Step: 0
Training loss: 1.974081039428711
Validation loss: 2.0976782391468682

Epoch: 5| Step: 1
Training loss: 2.1237173080444336
Validation loss: 2.0928445359071097

Epoch: 5| Step: 2
Training loss: 2.3964219093322754
Validation loss: 2.141748537619909

Epoch: 5| Step: 3
Training loss: 1.3638874292373657
Validation loss: 2.048208420475324

Epoch: 5| Step: 4
Training loss: 1.437906265258789
Validation loss: 2.104407176375389

Epoch: 5| Step: 5
Training loss: 1.8343546390533447
Validation loss: 2.098235785961151

Epoch: 5| Step: 6
Training loss: 1.6094748973846436
Validation loss: 2.096726248661677

Epoch: 5| Step: 7
Training loss: 2.2715163230895996
Validation loss: 2.1336356500784555

Epoch: 5| Step: 8
Training loss: 1.6207892894744873
Validation loss: 2.094016909599304

Epoch: 5| Step: 9
Training loss: 1.6056073904037476
Validation loss: 2.1035299648841224

Epoch: 5| Step: 10
Training loss: 1.9248321056365967
Validation loss: 2.1313286970059075

Epoch: 5| Step: 11
Training loss: 1.397429347038269
Validation loss: 2.091351995865504

Epoch: 79| Step: 0
Training loss: 1.6898037195205688
Validation loss: 2.048420866330465

Epoch: 5| Step: 1
Training loss: 2.331820487976074
Validation loss: 2.0088791151841483

Epoch: 5| Step: 2
Training loss: 1.6981780529022217
Validation loss: 2.042306676506996

Epoch: 5| Step: 3
Training loss: 1.8842999935150146
Validation loss: 2.047918607791265

Epoch: 5| Step: 4
Training loss: 1.6487877368927002
Validation loss: 2.0481114039818444

Epoch: 5| Step: 5
Training loss: 0.9075142741203308
Validation loss: 2.0483535329500833

Epoch: 5| Step: 6
Training loss: 1.4682705402374268
Validation loss: 2.09576652944088

Epoch: 5| Step: 7
Training loss: 2.1958870887756348
Validation loss: 2.0648177564144135

Epoch: 5| Step: 8
Training loss: 1.4515056610107422
Validation loss: 2.090582937002182

Epoch: 5| Step: 9
Training loss: 2.059041976928711
Validation loss: 2.1234422773122787

Epoch: 5| Step: 10
Training loss: 2.191664934158325
Validation loss: 2.082718019684156

Epoch: 5| Step: 11
Training loss: 2.615027666091919
Validation loss: 2.1232625395059586

Epoch: 80| Step: 0
Training loss: 1.7996944189071655
Validation loss: 2.1182291209697723

Epoch: 5| Step: 1
Training loss: 1.325195550918579
Validation loss: 2.0961522608995438

Epoch: 5| Step: 2
Training loss: 1.904456377029419
Validation loss: 2.1025620053211846

Epoch: 5| Step: 3
Training loss: 1.2510755062103271
Validation loss: 2.089859277009964

Epoch: 5| Step: 4
Training loss: 2.673426866531372
Validation loss: 2.129592979947726

Epoch: 5| Step: 5
Training loss: 2.027489423751831
Validation loss: 2.134849121173223

Epoch: 5| Step: 6
Training loss: 1.5136815309524536
Validation loss: 2.1177223374446235

Epoch: 5| Step: 7
Training loss: 1.663148283958435
Validation loss: 2.07042304178079

Epoch: 5| Step: 8
Training loss: 1.5229589939117432
Validation loss: 2.087945739428202

Epoch: 5| Step: 9
Training loss: 2.1063902378082275
Validation loss: 2.092396875222524

Epoch: 5| Step: 10
Training loss: 1.952325463294983
Validation loss: 2.0093575716018677

Epoch: 5| Step: 11
Training loss: 1.6935069561004639
Validation loss: 2.1095895171165466

Epoch: 81| Step: 0
Training loss: 1.4219133853912354
Validation loss: 2.1340245604515076

Epoch: 5| Step: 1
Training loss: 1.9351317882537842
Validation loss: 2.121528168519338

Epoch: 5| Step: 2
Training loss: 1.5600671768188477
Validation loss: 2.0742993901173272

Epoch: 5| Step: 3
Training loss: 2.0269129276275635
Validation loss: 2.1407904475927353

Epoch: 5| Step: 4
Training loss: 2.3210220336914062
Validation loss: 2.117735654115677

Epoch: 5| Step: 5
Training loss: 2.3874588012695312
Validation loss: 2.1591630975405374

Epoch: 5| Step: 6
Training loss: 1.4073359966278076
Validation loss: 2.125270744164785

Epoch: 5| Step: 7
Training loss: 1.8801281452178955
Validation loss: 2.102646455168724

Epoch: 5| Step: 8
Training loss: 1.7972099781036377
Validation loss: 2.0806169509887695

Epoch: 5| Step: 9
Training loss: 1.3964828252792358
Validation loss: 2.086369350552559

Epoch: 5| Step: 10
Training loss: 1.999352216720581
Validation loss: 2.1097924460967383

Epoch: 5| Step: 11
Training loss: 0.7574500441551208
Validation loss: 2.108952522277832

Epoch: 82| Step: 0
Training loss: 1.8984187841415405
Validation loss: 2.108905812104543

Epoch: 5| Step: 1
Training loss: 1.9405202865600586
Validation loss: 2.0540939370791116

Epoch: 5| Step: 2
Training loss: 1.5757774114608765
Validation loss: 2.1050900518894196

Epoch: 5| Step: 3
Training loss: 1.723201036453247
Validation loss: 2.062372306982676

Epoch: 5| Step: 4
Training loss: 0.896131694316864
Validation loss: 2.1472380956014

Epoch: 5| Step: 5
Training loss: 1.5935357809066772
Validation loss: 2.064121668537458

Epoch: 5| Step: 6
Training loss: 1.832411527633667
Validation loss: 2.1455867836872735

Epoch: 5| Step: 7
Training loss: 2.290226936340332
Validation loss: 2.1704234927892685

Epoch: 5| Step: 8
Training loss: 2.0709388256073
Validation loss: 2.1388960083325705

Epoch: 5| Step: 9
Training loss: 1.5884350538253784
Validation loss: 2.063776820898056

Epoch: 5| Step: 10
Training loss: 2.258866786956787
Validation loss: 2.1882489820321402

Epoch: 5| Step: 11
Training loss: 1.369266390800476
Validation loss: 2.145928089817365

Epoch: 83| Step: 0
Training loss: 2.0856871604919434
Validation loss: 2.07012044886748

Epoch: 5| Step: 1
Training loss: 2.188985824584961
Validation loss: 2.1020441353321075

Epoch: 5| Step: 2
Training loss: 1.6788095235824585
Validation loss: 2.0875384509563446

Epoch: 5| Step: 3
Training loss: 1.8875389099121094
Validation loss: 2.083544597029686

Epoch: 5| Step: 4
Training loss: 1.6741679906845093
Validation loss: 2.16359273592631

Epoch: 5| Step: 5
Training loss: 1.5637820959091187
Validation loss: 2.1339392314354577

Epoch: 5| Step: 6
Training loss: 2.0373542308807373
Validation loss: 2.136471559604009

Epoch: 5| Step: 7
Training loss: 1.6449000835418701
Validation loss: 2.1502988735834756

Epoch: 5| Step: 8
Training loss: 1.4393768310546875
Validation loss: 2.0961014231046042

Epoch: 5| Step: 9
Training loss: 2.1704065799713135
Validation loss: 2.1465581258138022

Epoch: 5| Step: 10
Training loss: 2.2215988636016846
Validation loss: 2.0491462697585425

Epoch: 5| Step: 11
Training loss: 1.2533776760101318
Validation loss: 2.0992693503697715

Epoch: 84| Step: 0
Training loss: 1.4123737812042236
Validation loss: 2.118668645620346

Epoch: 5| Step: 1
Training loss: 1.4329118728637695
Validation loss: 2.175719052553177

Epoch: 5| Step: 2
Training loss: 1.641615629196167
Validation loss: 2.0887228647867837

Epoch: 5| Step: 3
Training loss: 1.7806742191314697
Validation loss: 2.1662015120188394

Epoch: 5| Step: 4
Training loss: 1.8910449743270874
Validation loss: 2.101168473561605

Epoch: 5| Step: 5
Training loss: 2.0674827098846436
Validation loss: 2.13119837641716

Epoch: 5| Step: 6
Training loss: 1.6876366138458252
Validation loss: 2.0968076487382254

Epoch: 5| Step: 7
Training loss: 2.16184663772583
Validation loss: 2.0576906303564706

Epoch: 5| Step: 8
Training loss: 2.2498884201049805
Validation loss: 2.136114706595739

Epoch: 5| Step: 9
Training loss: 1.5168721675872803
Validation loss: 2.1235079964001975

Epoch: 5| Step: 10
Training loss: 1.7590538263320923
Validation loss: 2.049405793348948

Epoch: 5| Step: 11
Training loss: 2.7162868976593018
Validation loss: 2.113529622554779

Epoch: 85| Step: 0
Training loss: 1.849813461303711
Validation loss: 2.1082182178894677

Epoch: 5| Step: 1
Training loss: 1.4506809711456299
Validation loss: 2.1321797420581183

Epoch: 5| Step: 2
Training loss: 1.9756543636322021
Validation loss: 2.1207496523857117

Epoch: 5| Step: 3
Training loss: 1.437317132949829
Validation loss: 2.0720943957567215

Epoch: 5| Step: 4
Training loss: 2.010824680328369
Validation loss: 2.116203432281812

Epoch: 5| Step: 5
Training loss: 2.1023242473602295
Validation loss: 2.1253500133752823

Epoch: 5| Step: 6
Training loss: 1.3195321559906006
Validation loss: 2.097415496905645

Epoch: 5| Step: 7
Training loss: 2.371626615524292
Validation loss: 2.113427927096685

Epoch: 5| Step: 8
Training loss: 1.7216863632202148
Validation loss: 2.1204239229361215

Epoch: 5| Step: 9
Training loss: 1.971461534500122
Validation loss: 2.096739868323008

Epoch: 5| Step: 10
Training loss: 1.4997690916061401
Validation loss: 2.180674468477567

Epoch: 5| Step: 11
Training loss: 1.797189474105835
Validation loss: 2.145290652910868

Epoch: 86| Step: 0
Training loss: 1.7849889993667603
Validation loss: 2.1559693117936454

Epoch: 5| Step: 1
Training loss: 1.6998697519302368
Validation loss: 2.11540350317955

Epoch: 5| Step: 2
Training loss: 2.002652645111084
Validation loss: 2.119259705146154

Epoch: 5| Step: 3
Training loss: 1.7834608554840088
Validation loss: 2.0812537570794425

Epoch: 5| Step: 4
Training loss: 1.5740090608596802
Validation loss: 2.1293342113494873

Epoch: 5| Step: 5
Training loss: 1.0993616580963135
Validation loss: 2.124637926618258

Epoch: 5| Step: 6
Training loss: 1.7169036865234375
Validation loss: 2.0719545433918634

Epoch: 5| Step: 7
Training loss: 2.370575428009033
Validation loss: 2.098596250017484

Epoch: 5| Step: 8
Training loss: 1.6746307611465454
Validation loss: 2.1293150087197623

Epoch: 5| Step: 9
Training loss: 1.7359212636947632
Validation loss: 2.119942550857862

Epoch: 5| Step: 10
Training loss: 1.7731618881225586
Validation loss: 2.115639274319013

Epoch: 5| Step: 11
Training loss: 1.6270654201507568
Validation loss: 2.1403506249189377

Epoch: 87| Step: 0
Training loss: 1.8726485967636108
Validation loss: 2.116087739666303

Epoch: 5| Step: 1
Training loss: 1.8306796550750732
Validation loss: 2.108943447470665

Epoch: 5| Step: 2
Training loss: 1.9191904067993164
Validation loss: 2.094500114520391

Epoch: 5| Step: 3
Training loss: 1.6608558893203735
Validation loss: 2.0947037041187286

Epoch: 5| Step: 4
Training loss: 1.5948338508605957
Validation loss: 2.1396467834711075

Epoch: 5| Step: 5
Training loss: 1.3478022813796997
Validation loss: 2.116729731361071

Epoch: 5| Step: 6
Training loss: 1.7943956851959229
Validation loss: 2.139488473534584

Epoch: 5| Step: 7
Training loss: 1.8517307043075562
Validation loss: 2.09291240076224

Epoch: 5| Step: 8
Training loss: 2.0797653198242188
Validation loss: 2.132505923509598

Epoch: 5| Step: 9
Training loss: 1.5363988876342773
Validation loss: 2.1164443492889404

Epoch: 5| Step: 10
Training loss: 1.9984468221664429
Validation loss: 2.1008316973845163

Epoch: 5| Step: 11
Training loss: 2.5995850563049316
Validation loss: 2.1185905237992606

Epoch: 88| Step: 0
Training loss: 2.262760877609253
Validation loss: 2.1267681817213693

Epoch: 5| Step: 1
Training loss: 2.0418782234191895
Validation loss: 2.1342078745365143

Epoch: 5| Step: 2
Training loss: 1.5971684455871582
Validation loss: 2.0861743291219077

Epoch: 5| Step: 3
Training loss: 1.4989477396011353
Validation loss: 2.1031045764684677

Epoch: 5| Step: 4
Training loss: 1.634796142578125
Validation loss: 2.23492568731308

Epoch: 5| Step: 5
Training loss: 1.75314199924469
Validation loss: 2.1645532896121344

Epoch: 5| Step: 6
Training loss: 1.886905312538147
Validation loss: 2.1464759012063346

Epoch: 5| Step: 7
Training loss: 1.2994978427886963
Validation loss: 2.1452740679184594

Epoch: 5| Step: 8
Training loss: 2.1018645763397217
Validation loss: 2.08042519291242

Epoch: 5| Step: 9
Training loss: 1.8087981939315796
Validation loss: 2.0817350993553796

Epoch: 5| Step: 10
Training loss: 1.8708746433258057
Validation loss: 2.0604450901349387

Epoch: 5| Step: 11
Training loss: 2.1061015129089355
Validation loss: 2.1353290577729545

Epoch: 89| Step: 0
Training loss: 1.5727509260177612
Validation loss: 2.1121833821137748

Epoch: 5| Step: 1
Training loss: 1.7046654224395752
Validation loss: 2.118855357170105

Epoch: 5| Step: 2
Training loss: 1.4606306552886963
Validation loss: 2.146218185623487

Epoch: 5| Step: 3
Training loss: 1.7222859859466553
Validation loss: 2.0558511465787888

Epoch: 5| Step: 4
Training loss: 2.149226427078247
Validation loss: 2.096157838900884

Epoch: 5| Step: 5
Training loss: 2.4159228801727295
Validation loss: 2.1314678291479745

Epoch: 5| Step: 6
Training loss: 1.6463645696640015
Validation loss: 2.104405954480171

Epoch: 5| Step: 7
Training loss: 2.09865140914917
Validation loss: 2.1382733285427094

Epoch: 5| Step: 8
Training loss: 1.873557448387146
Validation loss: 2.156200831135114

Epoch: 5| Step: 9
Training loss: 1.3738791942596436
Validation loss: 2.1076314051946006

Epoch: 5| Step: 10
Training loss: 1.7237848043441772
Validation loss: 2.1411766012509665

Epoch: 5| Step: 11
Training loss: 1.47231924533844
Validation loss: 2.11974344154199

Epoch: 90| Step: 0
Training loss: 1.6845585107803345
Validation loss: 2.116672173142433

Epoch: 5| Step: 1
Training loss: 1.3428499698638916
Validation loss: 2.1330889215071998

Epoch: 5| Step: 2
Training loss: 1.746752142906189
Validation loss: 2.12765970826149

Epoch: 5| Step: 3
Training loss: 1.9631264209747314
Validation loss: 2.1397547821203866

Epoch: 5| Step: 4
Training loss: 1.7810838222503662
Validation loss: 2.1391404370466867

Epoch: 5| Step: 5
Training loss: 1.7893835306167603
Validation loss: 2.1429948955774307

Epoch: 5| Step: 6
Training loss: 1.4633175134658813
Validation loss: 2.1558497796456018

Epoch: 5| Step: 7
Training loss: 1.8644466400146484
Validation loss: 2.1166853457689285

Epoch: 5| Step: 8
Training loss: 1.8755531311035156
Validation loss: 2.1500840286413827

Epoch: 5| Step: 9
Training loss: 2.1013917922973633
Validation loss: 2.064567739764849

Epoch: 5| Step: 10
Training loss: 1.882885217666626
Validation loss: 2.0671335011720657

Epoch: 5| Step: 11
Training loss: 1.7736189365386963
Validation loss: 2.0615075131257377

Epoch: 91| Step: 0
Training loss: 1.8151416778564453
Validation loss: 2.0971246361732483

Epoch: 5| Step: 1
Training loss: 2.289731979370117
Validation loss: 2.1481440663337708

Epoch: 5| Step: 2
Training loss: 1.7725903987884521
Validation loss: 2.1489342699448266

Epoch: 5| Step: 3
Training loss: 1.418559193611145
Validation loss: 2.092761571208636

Epoch: 5| Step: 4
Training loss: 1.7723888158798218
Validation loss: 2.074244578679403

Epoch: 5| Step: 5
Training loss: 1.9519981145858765
Validation loss: 2.112139215071996

Epoch: 5| Step: 6
Training loss: 1.9040234088897705
Validation loss: 2.0833399494489035

Epoch: 5| Step: 7
Training loss: 2.0138323307037354
Validation loss: 2.0984559456507363

Epoch: 5| Step: 8
Training loss: 1.358551025390625
Validation loss: 2.0553345680236816

Epoch: 5| Step: 9
Training loss: 2.1024203300476074
Validation loss: 2.151707907517751

Epoch: 5| Step: 10
Training loss: 1.3487098217010498
Validation loss: 2.145590513944626

Epoch: 5| Step: 11
Training loss: 1.3348584175109863
Validation loss: 2.078351373473803

Epoch: 92| Step: 0
Training loss: 1.7163368463516235
Validation loss: 2.148129095633825

Epoch: 5| Step: 1
Training loss: 1.591876745223999
Validation loss: 2.118343934416771

Epoch: 5| Step: 2
Training loss: 1.9360164403915405
Validation loss: 2.1000299155712128

Epoch: 5| Step: 3
Training loss: 1.8734092712402344
Validation loss: 2.2051418920358024

Epoch: 5| Step: 4
Training loss: 1.9345169067382812
Validation loss: 2.1109987000624337

Epoch: 5| Step: 5
Training loss: 0.8396196365356445
Validation loss: 2.1868774642546973

Epoch: 5| Step: 6
Training loss: 1.9838100671768188
Validation loss: 2.190158178408941

Epoch: 5| Step: 7
Training loss: 1.7004451751708984
Validation loss: 2.170964946349462

Epoch: 5| Step: 8
Training loss: 1.5204229354858398
Validation loss: 2.1196115761995316

Epoch: 5| Step: 9
Training loss: 1.745995283126831
Validation loss: 2.195680851737658

Epoch: 5| Step: 10
Training loss: 2.407654047012329
Validation loss: 2.1536512076854706

Epoch: 5| Step: 11
Training loss: 2.427058458328247
Validation loss: 2.128392775853475

Epoch: 93| Step: 0
Training loss: 1.5041531324386597
Validation loss: 2.0892394483089447

Epoch: 5| Step: 1
Training loss: 2.063136577606201
Validation loss: 2.1416833450396857

Epoch: 5| Step: 2
Training loss: 2.5476391315460205
Validation loss: 2.1349833259979882

Epoch: 5| Step: 3
Training loss: 2.1959609985351562
Validation loss: 2.170070300499598

Epoch: 5| Step: 4
Training loss: 1.665584921836853
Validation loss: 2.1205341468254724

Epoch: 5| Step: 5
Training loss: 1.5749027729034424
Validation loss: 2.1585629483064017

Epoch: 5| Step: 6
Training loss: 1.5734002590179443
Validation loss: 2.1642953058083854

Epoch: 5| Step: 7
Training loss: 1.9748127460479736
Validation loss: 2.1438238670428595

Epoch: 5| Step: 8
Training loss: 1.1271679401397705
Validation loss: 2.142614354689916

Epoch: 5| Step: 9
Training loss: 1.2653565406799316
Validation loss: 2.0693522691726685

Epoch: 5| Step: 10
Training loss: 1.6626983880996704
Validation loss: 2.149220104018847

Epoch: 5| Step: 11
Training loss: 1.999640941619873
Validation loss: 2.0808973610401154

Epoch: 94| Step: 0
Training loss: 1.8785297870635986
Validation loss: 2.071679502725601

Epoch: 5| Step: 1
Training loss: 1.6275837421417236
Validation loss: 2.1301615238189697

Epoch: 5| Step: 2
Training loss: 1.9178558588027954
Validation loss: 2.1270773112773895

Epoch: 5| Step: 3
Training loss: 1.4006109237670898
Validation loss: 2.1355741371711097

Epoch: 5| Step: 4
Training loss: 1.8257595300674438
Validation loss: 2.104661891857783

Epoch: 5| Step: 5
Training loss: 1.9018722772598267
Validation loss: 2.1143158276875815

Epoch: 5| Step: 6
Training loss: 1.335064172744751
Validation loss: 2.126835639278094

Epoch: 5| Step: 7
Training loss: 1.423450231552124
Validation loss: 2.0821145127216973

Epoch: 5| Step: 8
Training loss: 2.018878698348999
Validation loss: 2.1015428602695465

Epoch: 5| Step: 9
Training loss: 1.7656673192977905
Validation loss: 2.1275152464707694

Epoch: 5| Step: 10
Training loss: 1.8054338693618774
Validation loss: 2.097053070863088

Epoch: 5| Step: 11
Training loss: 2.0506529808044434
Validation loss: 2.0893301765124

Epoch: 95| Step: 0
Training loss: 1.6098772287368774
Validation loss: 2.1429339994986853

Epoch: 5| Step: 1
Training loss: 2.239492177963257
Validation loss: 2.109406461318334

Epoch: 5| Step: 2
Training loss: 1.2886042594909668
Validation loss: 2.1078590154647827

Epoch: 5| Step: 3
Training loss: 1.993747353553772
Validation loss: 2.0890774925549827

Epoch: 5| Step: 4
Training loss: 1.704656958580017
Validation loss: 2.122101088364919

Epoch: 5| Step: 5
Training loss: 1.4847962856292725
Validation loss: 2.1158083279927573

Epoch: 5| Step: 6
Training loss: 1.6445649862289429
Validation loss: 2.121222957968712

Epoch: 5| Step: 7
Training loss: 1.9744046926498413
Validation loss: 2.125176712870598

Epoch: 5| Step: 8
Training loss: 1.8419902324676514
Validation loss: 2.1318465868631997

Epoch: 5| Step: 9
Training loss: 1.739837884902954
Validation loss: 2.1054569681485495

Epoch: 5| Step: 10
Training loss: 1.51031494140625
Validation loss: 2.1286838750044503

Epoch: 5| Step: 11
Training loss: 1.3708138465881348
Validation loss: 2.1460039615631104

Epoch: 96| Step: 0
Training loss: 2.076824903488159
Validation loss: 2.1439647177855172

Epoch: 5| Step: 1
Training loss: 2.3754546642303467
Validation loss: 2.1144250382979712

Epoch: 5| Step: 2
Training loss: 1.968443512916565
Validation loss: 2.1014901598294577

Epoch: 5| Step: 3
Training loss: 1.2764818668365479
Validation loss: 2.1173249085744223

Epoch: 5| Step: 4
Training loss: 1.488427758216858
Validation loss: 2.1075375427802405

Epoch: 5| Step: 5
Training loss: 1.6955152750015259
Validation loss: 2.1521584540605545

Epoch: 5| Step: 6
Training loss: 2.0031819343566895
Validation loss: 2.1104412178198495

Epoch: 5| Step: 7
Training loss: 1.7587382793426514
Validation loss: 2.1157725105683007

Epoch: 5| Step: 8
Training loss: 1.573561191558838
Validation loss: 2.0943636794885

Epoch: 5| Step: 9
Training loss: 1.5406091213226318
Validation loss: 2.150673637787501

Epoch: 5| Step: 10
Training loss: 1.0575162172317505
Validation loss: 2.1258839766184487

Epoch: 5| Step: 11
Training loss: 1.74977707862854
Validation loss: 2.1062215864658356

Epoch: 97| Step: 0
Training loss: 2.053377866744995
Validation loss: 2.1099549432595572

Epoch: 5| Step: 1
Training loss: 1.7554817199707031
Validation loss: 2.14175874988238

Epoch: 5| Step: 2
Training loss: 1.6313667297363281
Validation loss: 2.1639646838108697

Epoch: 5| Step: 3
Training loss: 1.7950836420059204
Validation loss: 2.1502869526545205

Epoch: 5| Step: 4
Training loss: 1.6489429473876953
Validation loss: 2.128967046737671

Epoch: 5| Step: 5
Training loss: 1.7871195077896118
Validation loss: 2.2000000327825546

Epoch: 5| Step: 6
Training loss: 1.8385614156723022
Validation loss: 2.1594765981038413

Epoch: 5| Step: 7
Training loss: 1.3351322412490845
Validation loss: 2.1010944743951163

Epoch: 5| Step: 8
Training loss: 2.316964626312256
Validation loss: 2.132862021525701

Epoch: 5| Step: 9
Training loss: 1.1848535537719727
Validation loss: 2.1063575595617294

Epoch: 5| Step: 10
Training loss: 1.6107299327850342
Validation loss: 2.1038718620936074

Epoch: 5| Step: 11
Training loss: 1.6846532821655273
Validation loss: 2.047891249259313

Epoch: 98| Step: 0
Training loss: 2.0945053100585938
Validation loss: 2.131368493040403

Epoch: 5| Step: 1
Training loss: 2.205212354660034
Validation loss: 2.0770862450202308

Epoch: 5| Step: 2
Training loss: 1.4230644702911377
Validation loss: 2.146628588438034

Epoch: 5| Step: 3
Training loss: 1.618101716041565
Validation loss: 2.1044840763012567

Epoch: 5| Step: 4
Training loss: 1.2749662399291992
Validation loss: 2.188909024000168

Epoch: 5| Step: 5
Training loss: 2.6419780254364014
Validation loss: 2.1330181459585824

Epoch: 5| Step: 6
Training loss: 1.5281143188476562
Validation loss: 2.122903441389402

Epoch: 5| Step: 7
Training loss: 1.2277889251708984
Validation loss: 2.1223356276750565

Epoch: 5| Step: 8
Training loss: 1.312808632850647
Validation loss: 2.1638447841008506

Epoch: 5| Step: 9
Training loss: 1.6363122463226318
Validation loss: 2.1442815562089286

Epoch: 5| Step: 10
Training loss: 1.5393526554107666
Validation loss: 2.137409215172132

Epoch: 5| Step: 11
Training loss: 1.1682668924331665
Validation loss: 2.166447957356771

Epoch: 99| Step: 0
Training loss: 1.7408668994903564
Validation loss: 2.1673699816068015

Epoch: 5| Step: 1
Training loss: 1.9507732391357422
Validation loss: 2.1959342857201896

Epoch: 5| Step: 2
Training loss: 1.656010389328003
Validation loss: 2.1093643804391227

Epoch: 5| Step: 3
Training loss: 1.9469006061553955
Validation loss: 2.096848741173744

Epoch: 5| Step: 4
Training loss: 1.7994441986083984
Validation loss: 2.1021831681331

Epoch: 5| Step: 5
Training loss: 1.5014755725860596
Validation loss: 2.186918000380198

Epoch: 5| Step: 6
Training loss: 1.4463428258895874
Validation loss: 2.1946399807929993

Epoch: 5| Step: 7
Training loss: 2.190103054046631
Validation loss: 2.1232557694117227

Epoch: 5| Step: 8
Training loss: 1.5011597871780396
Validation loss: 2.165170262257258

Epoch: 5| Step: 9
Training loss: 1.6785266399383545
Validation loss: 2.163483500480652

Epoch: 5| Step: 10
Training loss: 1.4280691146850586
Validation loss: 2.1381583362817764

Epoch: 5| Step: 11
Training loss: 1.2855172157287598
Validation loss: 2.14156104127566

Epoch: 100| Step: 0
Training loss: 1.2705655097961426
Validation loss: 2.0974956254164376

Epoch: 5| Step: 1
Training loss: 1.3206170797348022
Validation loss: 2.163665622472763

Epoch: 5| Step: 2
Training loss: 1.8249584436416626
Validation loss: 2.1118727922439575

Epoch: 5| Step: 3
Training loss: 1.7826706171035767
Validation loss: 2.1557271679242453

Epoch: 5| Step: 4
Training loss: 2.3590168952941895
Validation loss: 2.1715817153453827

Epoch: 5| Step: 5
Training loss: 2.0928261280059814
Validation loss: 2.1535584529240928

Epoch: 5| Step: 6
Training loss: 1.719082236289978
Validation loss: 2.19626052180926

Epoch: 5| Step: 7
Training loss: 2.0878403186798096
Validation loss: 2.1313110093275704

Epoch: 5| Step: 8
Training loss: 1.250174641609192
Validation loss: 2.1921289265155792

Epoch: 5| Step: 9
Training loss: 1.5500414371490479
Validation loss: 2.1996386647224426

Epoch: 5| Step: 10
Training loss: 1.6218559741973877
Validation loss: 2.120350807905197

Epoch: 5| Step: 11
Training loss: 0.9109043478965759
Validation loss: 2.1588709702094397

Epoch: 101| Step: 0
Training loss: 1.279987096786499
Validation loss: 2.1406288693348565

Epoch: 5| Step: 1
Training loss: 1.7538135051727295
Validation loss: 2.1372049301862717

Epoch: 5| Step: 2
Training loss: 0.975949764251709
Validation loss: 2.101953382293383

Epoch: 5| Step: 3
Training loss: 1.6588510274887085
Validation loss: 2.184761812289556

Epoch: 5| Step: 4
Training loss: 1.641821265220642
Validation loss: 2.0981180667877197

Epoch: 5| Step: 5
Training loss: 1.8382198810577393
Validation loss: 2.1511094669500985

Epoch: 5| Step: 6
Training loss: 1.6640350818634033
Validation loss: 2.1318472623825073

Epoch: 5| Step: 7
Training loss: 2.093780994415283
Validation loss: 2.11358251174291

Epoch: 5| Step: 8
Training loss: 2.463374376296997
Validation loss: 2.191357890764872

Epoch: 5| Step: 9
Training loss: 1.500045895576477
Validation loss: 2.1472274462381997

Epoch: 5| Step: 10
Training loss: 1.601569414138794
Validation loss: 2.2118454525868096

Epoch: 5| Step: 11
Training loss: 2.3180766105651855
Validation loss: 2.1773772686719894

Epoch: 102| Step: 0
Training loss: 1.1065375804901123
Validation loss: 2.1935407668352127

Epoch: 5| Step: 1
Training loss: 1.098645567893982
Validation loss: 2.141394058863322

Epoch: 5| Step: 2
Training loss: 1.5743263959884644
Validation loss: 2.1166549921035767

Epoch: 5| Step: 3
Training loss: 1.8615758419036865
Validation loss: 2.166379749774933

Epoch: 5| Step: 4
Training loss: 1.7206525802612305
Validation loss: 2.1526934603850045

Epoch: 5| Step: 5
Training loss: 1.9568889141082764
Validation loss: 2.1329273780186973

Epoch: 5| Step: 6
Training loss: 1.6145124435424805
Validation loss: 2.075834795832634

Epoch: 5| Step: 7
Training loss: 1.8754974603652954
Validation loss: 2.1507719854513803

Epoch: 5| Step: 8
Training loss: 1.795235276222229
Validation loss: 2.1435538480679193

Epoch: 5| Step: 9
Training loss: 1.8988564014434814
Validation loss: 2.13379896680514

Epoch: 5| Step: 10
Training loss: 1.7663806676864624
Validation loss: 2.1248685717582703

Epoch: 5| Step: 11
Training loss: 0.9502897262573242
Validation loss: 2.1653157522281012

Epoch: 103| Step: 0
Training loss: 1.5513700246810913
Validation loss: 2.124154885609945

Epoch: 5| Step: 1
Training loss: 1.1484099626541138
Validation loss: 2.0814449538787207

Epoch: 5| Step: 2
Training loss: 1.8332774639129639
Validation loss: 2.1582703590393066

Epoch: 5| Step: 3
Training loss: 1.2999862432479858
Validation loss: 2.1439648270606995

Epoch: 5| Step: 4
Training loss: 1.5974302291870117
Validation loss: 2.15007022023201

Epoch: 5| Step: 5
Training loss: 2.0230088233947754
Validation loss: 2.1520746648311615

Epoch: 5| Step: 6
Training loss: 2.535202980041504
Validation loss: 2.121255854765574

Epoch: 5| Step: 7
Training loss: 1.4694503545761108
Validation loss: 2.1667014360427856

Epoch: 5| Step: 8
Training loss: 1.7295070886611938
Validation loss: 2.163961465160052

Epoch: 5| Step: 9
Training loss: 1.59967839717865
Validation loss: 2.1354575703541436

Epoch: 5| Step: 10
Training loss: 1.6556050777435303
Validation loss: 2.0951215624809265

Epoch: 5| Step: 11
Training loss: 1.660663366317749
Validation loss: 2.200877452890078

Epoch: 104| Step: 0
Training loss: 1.4881558418273926
Validation loss: 2.1816903005043664

Epoch: 5| Step: 1
Training loss: 2.1228907108306885
Validation loss: 2.260075628757477

Epoch: 5| Step: 2
Training loss: 1.7637622356414795
Validation loss: 2.155131697654724

Epoch: 5| Step: 3
Training loss: 1.8142309188842773
Validation loss: 2.168660044670105

Epoch: 5| Step: 4
Training loss: 2.0412650108337402
Validation loss: 2.163058246175448

Epoch: 5| Step: 5
Training loss: 1.33970046043396
Validation loss: 2.2404584487279258

Epoch: 5| Step: 6
Training loss: 1.728955864906311
Validation loss: 2.145738194386164

Epoch: 5| Step: 7
Training loss: 1.3622074127197266
Validation loss: 2.1656034191449485

Epoch: 5| Step: 8
Training loss: 2.060473918914795
Validation loss: 2.094488710165024

Epoch: 5| Step: 9
Training loss: 1.4435983896255493
Validation loss: 2.1460706988970437

Epoch: 5| Step: 10
Training loss: 1.353489875793457
Validation loss: 2.0921963999668756

Epoch: 5| Step: 11
Training loss: 2.80452823638916
Validation loss: 2.174893170595169

Epoch: 105| Step: 0
Training loss: 1.2599191665649414
Validation loss: 2.147100488344828

Epoch: 5| Step: 1
Training loss: 1.2883694171905518
Validation loss: 2.2012643218040466

Epoch: 5| Step: 2
Training loss: 2.135030746459961
Validation loss: 2.129062910874685

Epoch: 5| Step: 3
Training loss: 1.2860561609268188
Validation loss: 2.221733570098877

Epoch: 5| Step: 4
Training loss: 1.8155057430267334
Validation loss: 2.1685511271158853

Epoch: 5| Step: 5
Training loss: 1.8296992778778076
Validation loss: 2.0913935552040734

Epoch: 5| Step: 6
Training loss: 1.6875921487808228
Validation loss: 2.162106215953827

Epoch: 5| Step: 7
Training loss: 1.5060398578643799
Validation loss: 2.196964060266813

Epoch: 5| Step: 8
Training loss: 1.61297607421875
Validation loss: 2.091596951087316

Epoch: 5| Step: 9
Training loss: 1.5172202587127686
Validation loss: 2.13790055612723

Epoch: 5| Step: 10
Training loss: 2.2398838996887207
Validation loss: 2.1605638017257056

Epoch: 5| Step: 11
Training loss: 1.0413419008255005
Validation loss: 2.13053135573864

Epoch: 106| Step: 0
Training loss: 1.1663278341293335
Validation loss: 2.1545629700024924

Epoch: 5| Step: 1
Training loss: 1.5318959951400757
Validation loss: 2.173583130041758

Epoch: 5| Step: 2
Training loss: 1.7393087148666382
Validation loss: 2.097422401110331

Epoch: 5| Step: 3
Training loss: 1.3225600719451904
Validation loss: 2.099221646785736

Epoch: 5| Step: 4
Training loss: 1.4011293649673462
Validation loss: 2.140872468551

Epoch: 5| Step: 5
Training loss: 1.7710613012313843
Validation loss: 2.200676550467809

Epoch: 5| Step: 6
Training loss: 1.8761018514633179
Validation loss: 2.1678317884604135

Epoch: 5| Step: 7
Training loss: 2.2970669269561768
Validation loss: 2.1457838962475457

Epoch: 5| Step: 8
Training loss: 1.0891151428222656
Validation loss: 2.163547898332278

Epoch: 5| Step: 9
Training loss: 1.8026670217514038
Validation loss: 2.2045207222302756

Epoch: 5| Step: 10
Training loss: 1.6902191638946533
Validation loss: 2.178355852762858

Epoch: 5| Step: 11
Training loss: 3.2553915977478027
Validation loss: 2.163853242993355

Epoch: 107| Step: 0
Training loss: 1.035751461982727
Validation loss: 2.1486487090587616

Epoch: 5| Step: 1
Training loss: 1.616599678993225
Validation loss: 2.115358759959539

Epoch: 5| Step: 2
Training loss: 2.052499532699585
Validation loss: 2.1597256511449814

Epoch: 5| Step: 3
Training loss: 1.6890392303466797
Validation loss: 2.2140149772167206

Epoch: 5| Step: 4
Training loss: 1.591604232788086
Validation loss: 2.197400391101837

Epoch: 5| Step: 5
Training loss: 1.928365707397461
Validation loss: 2.162009964386622

Epoch: 5| Step: 6
Training loss: 1.456446647644043
Validation loss: 2.2647513250509896

Epoch: 5| Step: 7
Training loss: 2.4018242359161377
Validation loss: 2.182918335000674

Epoch: 5| Step: 8
Training loss: 2.2794013023376465
Validation loss: 2.1806299835443497

Epoch: 5| Step: 9
Training loss: 1.7301075458526611
Validation loss: 2.1384181628624597

Epoch: 5| Step: 10
Training loss: 1.8954429626464844
Validation loss: 2.162063111861547

Epoch: 5| Step: 11
Training loss: 1.4572265148162842
Validation loss: 2.15813872218132

Epoch: 108| Step: 0
Training loss: 1.7145044803619385
Validation loss: 2.1541029512882233

Epoch: 5| Step: 1
Training loss: 1.4773776531219482
Validation loss: 2.2164868215719857

Epoch: 5| Step: 2
Training loss: 1.6196753978729248
Validation loss: 2.2063093880812326

Epoch: 5| Step: 3
Training loss: 1.3983523845672607
Validation loss: 2.245152418812116

Epoch: 5| Step: 4
Training loss: 1.797438621520996
Validation loss: 2.255086918671926

Epoch: 5| Step: 5
Training loss: 1.6151440143585205
Validation loss: 2.3042109409968057

Epoch: 5| Step: 6
Training loss: 1.8804004192352295
Validation loss: 2.2663421283165612

Epoch: 5| Step: 7
Training loss: 1.7448294162750244
Validation loss: 2.274079139033953

Epoch: 5| Step: 8
Training loss: 1.8413366079330444
Validation loss: 2.189639767011007

Epoch: 5| Step: 9
Training loss: 1.9502170085906982
Validation loss: 2.203379735350609

Epoch: 5| Step: 10
Training loss: 2.2933714389801025
Validation loss: 2.1515897860129676

Epoch: 5| Step: 11
Training loss: 0.8267298936843872
Validation loss: 2.0767551362514496

Epoch: 109| Step: 0
Training loss: 2.090928316116333
Validation loss: 2.1371156672636666

Epoch: 5| Step: 1
Training loss: 1.4369570016860962
Validation loss: 2.220123658577601

Epoch: 5| Step: 2
Training loss: 1.647138237953186
Validation loss: 2.1512929499149323

Epoch: 5| Step: 3
Training loss: 1.674483060836792
Validation loss: 2.165447860956192

Epoch: 5| Step: 4
Training loss: 2.2522051334381104
Validation loss: 2.1679691274960837

Epoch: 5| Step: 5
Training loss: 1.842058539390564
Validation loss: 2.129879136880239

Epoch: 5| Step: 6
Training loss: 2.0617480278015137
Validation loss: 2.1891313791275024

Epoch: 5| Step: 7
Training loss: 1.9853023290634155
Validation loss: 2.174015611410141

Epoch: 5| Step: 8
Training loss: 1.3527605533599854
Validation loss: 2.119020546476046

Epoch: 5| Step: 9
Training loss: 1.5496357679367065
Validation loss: 2.115522096554438

Epoch: 5| Step: 10
Training loss: 1.1732616424560547
Validation loss: 2.0754258135954538

Epoch: 5| Step: 11
Training loss: 2.732755184173584
Validation loss: 2.066582828760147

Epoch: 110| Step: 0
Training loss: 1.5340492725372314
Validation loss: 2.151769613226255

Epoch: 5| Step: 1
Training loss: 1.4071818590164185
Validation loss: 2.104415779312452

Epoch: 5| Step: 2
Training loss: 1.7592986822128296
Validation loss: 2.170025865236918

Epoch: 5| Step: 3
Training loss: 1.9487956762313843
Validation loss: 2.1635667035977044

Epoch: 5| Step: 4
Training loss: 1.2039148807525635
Validation loss: 2.1539030025402703

Epoch: 5| Step: 5
Training loss: 1.4191735982894897
Validation loss: 2.1186861048142114

Epoch: 5| Step: 6
Training loss: 1.8759644031524658
Validation loss: 2.167314519484838

Epoch: 5| Step: 7
Training loss: 1.785463571548462
Validation loss: 2.0940625419219336

Epoch: 5| Step: 8
Training loss: 1.592900276184082
Validation loss: 2.13009708126386

Epoch: 5| Step: 9
Training loss: 1.7905458211898804
Validation loss: 2.090025598804156

Epoch: 5| Step: 10
Training loss: 1.4652074575424194
Validation loss: 2.136828367908796

Epoch: 5| Step: 11
Training loss: 2.305798292160034
Validation loss: 2.1382309248050055

Epoch: 111| Step: 0
Training loss: 1.7338201999664307
Validation loss: 2.0813044607639313

Epoch: 5| Step: 1
Training loss: 1.3570966720581055
Validation loss: 2.1685727139314017

Epoch: 5| Step: 2
Training loss: 1.7388560771942139
Validation loss: 2.1610291401545205

Epoch: 5| Step: 3
Training loss: 1.616310477256775
Validation loss: 2.165880555907885

Epoch: 5| Step: 4
Training loss: 1.849914789199829
Validation loss: 2.216140349706014

Epoch: 5| Step: 5
Training loss: 1.1938377618789673
Validation loss: 2.1530891557534537

Epoch: 5| Step: 6
Training loss: 1.8055102825164795
Validation loss: 2.2383980502684913

Epoch: 5| Step: 7
Training loss: 1.4805032014846802
Validation loss: 2.228877067565918

Epoch: 5| Step: 8
Training loss: 2.0656933784484863
Validation loss: 2.109906390309334

Epoch: 5| Step: 9
Training loss: 1.2990778684616089
Validation loss: 2.1008306990067163

Epoch: 5| Step: 10
Training loss: 1.9177048206329346
Validation loss: 2.1500084002812705

Epoch: 5| Step: 11
Training loss: 1.1606948375701904
Validation loss: 2.1561393290758133

Epoch: 112| Step: 0
Training loss: 1.3120379447937012
Validation loss: 2.169099196791649

Epoch: 5| Step: 1
Training loss: 1.7367002964019775
Validation loss: 2.142337659994761

Epoch: 5| Step: 2
Training loss: 1.2659131288528442
Validation loss: 2.130912020802498

Epoch: 5| Step: 3
Training loss: 1.363685131072998
Validation loss: 2.1064532498518624

Epoch: 5| Step: 4
Training loss: 1.5597795248031616
Validation loss: 2.1382631113131843

Epoch: 5| Step: 5
Training loss: 1.907565712928772
Validation loss: 2.1487365067005157

Epoch: 5| Step: 6
Training loss: 1.345723032951355
Validation loss: 2.1693885227044425

Epoch: 5| Step: 7
Training loss: 2.019474506378174
Validation loss: 2.139654984076818

Epoch: 5| Step: 8
Training loss: 2.0079505443573
Validation loss: 2.0935489932696023

Epoch: 5| Step: 9
Training loss: 1.561931848526001
Validation loss: 2.1458519299825034

Epoch: 5| Step: 10
Training loss: 1.5582984685897827
Validation loss: 2.1747462451457977

Epoch: 5| Step: 11
Training loss: 1.01488196849823
Validation loss: 2.179453124602636

Epoch: 113| Step: 0
Training loss: 1.8608968257904053
Validation loss: 2.118707850575447

Epoch: 5| Step: 1
Training loss: 1.735882043838501
Validation loss: 2.140130415558815

Epoch: 5| Step: 2
Training loss: 1.829777479171753
Validation loss: 2.194747010866801

Epoch: 5| Step: 3
Training loss: 1.834275245666504
Validation loss: 2.1914835274219513

Epoch: 5| Step: 4
Training loss: 1.916054368019104
Validation loss: 2.206654886404673

Epoch: 5| Step: 5
Training loss: 1.7306740283966064
Validation loss: 2.1383992532889047

Epoch: 5| Step: 6
Training loss: 1.3909828662872314
Validation loss: 2.1961607287327447

Epoch: 5| Step: 7
Training loss: 1.6758811473846436
Validation loss: 2.159948488076528

Epoch: 5| Step: 8
Training loss: 1.4349496364593506
Validation loss: 2.1402085522810617

Epoch: 5| Step: 9
Training loss: 1.6237754821777344
Validation loss: 2.1638768712679544

Epoch: 5| Step: 10
Training loss: 1.2754464149475098
Validation loss: 2.1292509138584137

Epoch: 5| Step: 11
Training loss: 1.6256585121154785
Validation loss: 2.1397942254940667

Epoch: 114| Step: 0
Training loss: 1.6271419525146484
Validation loss: 2.1082281867663064

Epoch: 5| Step: 1
Training loss: 1.348605751991272
Validation loss: 2.1220073451598487

Epoch: 5| Step: 2
Training loss: 1.5434587001800537
Validation loss: 2.1764417638381324

Epoch: 5| Step: 3
Training loss: 1.3942829370498657
Validation loss: 2.1076678733030954

Epoch: 5| Step: 4
Training loss: 1.6356747150421143
Validation loss: 2.141610418756803

Epoch: 5| Step: 5
Training loss: 2.5461373329162598
Validation loss: 2.1819239308436713

Epoch: 5| Step: 6
Training loss: 1.7825212478637695
Validation loss: 2.184930811325709

Epoch: 5| Step: 7
Training loss: 1.298310399055481
Validation loss: 2.1924765209356942

Epoch: 5| Step: 8
Training loss: 1.6691615581512451
Validation loss: 2.1839389304320016

Epoch: 5| Step: 9
Training loss: 1.0798472166061401
Validation loss: 2.138495941956838

Epoch: 5| Step: 10
Training loss: 1.3910497426986694
Validation loss: 2.168232649564743

Epoch: 5| Step: 11
Training loss: 2.2712390422821045
Validation loss: 2.178729568918546

Epoch: 115| Step: 0
Training loss: 1.565943956375122
Validation loss: 2.0832804838816323

Epoch: 5| Step: 1
Training loss: 2.0264739990234375
Validation loss: 2.14368865887324

Epoch: 5| Step: 2
Training loss: 1.6210447549819946
Validation loss: 2.1297079622745514

Epoch: 5| Step: 3
Training loss: 1.7742016315460205
Validation loss: 2.1618408461411796

Epoch: 5| Step: 4
Training loss: 1.1021668910980225
Validation loss: 2.1387491077184677

Epoch: 5| Step: 5
Training loss: 1.905137300491333
Validation loss: 2.1312062541643777

Epoch: 5| Step: 6
Training loss: 1.4352346658706665
Validation loss: 2.0819546431303024

Epoch: 5| Step: 7
Training loss: 1.413558006286621
Validation loss: 2.199327270189921

Epoch: 5| Step: 8
Training loss: 1.5597261190414429
Validation loss: 2.1417661060889563

Epoch: 5| Step: 9
Training loss: 1.6111160516738892
Validation loss: 2.1501912822326026

Epoch: 5| Step: 10
Training loss: 1.4371278285980225
Validation loss: 2.149514451622963

Epoch: 5| Step: 11
Training loss: 1.1854196786880493
Validation loss: 2.185126135746638

Epoch: 116| Step: 0
Training loss: 1.961370825767517
Validation loss: 2.168926457564036

Epoch: 5| Step: 1
Training loss: 1.5027506351470947
Validation loss: 2.170180728038152

Epoch: 5| Step: 2
Training loss: 1.7303746938705444
Validation loss: 2.12889697154363

Epoch: 5| Step: 3
Training loss: 1.32369863986969
Validation loss: 2.1874206562836966

Epoch: 5| Step: 4
Training loss: 1.1303600072860718
Validation loss: 2.1398176699876785

Epoch: 5| Step: 5
Training loss: 1.4350900650024414
Validation loss: 2.1433949718872705

Epoch: 5| Step: 6
Training loss: 2.179593563079834
Validation loss: 2.1156399250030518

Epoch: 5| Step: 7
Training loss: 1.4858996868133545
Validation loss: 2.218296244740486

Epoch: 5| Step: 8
Training loss: 1.010292410850525
Validation loss: 2.211668332417806

Epoch: 5| Step: 9
Training loss: 1.9199063777923584
Validation loss: 2.192283257842064

Epoch: 5| Step: 10
Training loss: 1.1322587728500366
Validation loss: 2.1844551165898642

Epoch: 5| Step: 11
Training loss: 2.639587640762329
Validation loss: 2.1791319896777472

Epoch: 117| Step: 0
Training loss: 1.6091150045394897
Validation loss: 2.210526699821154

Epoch: 5| Step: 1
Training loss: 1.7273038625717163
Validation loss: 2.2127581437428794

Epoch: 5| Step: 2
Training loss: 1.9460456371307373
Validation loss: 2.1941129863262177

Epoch: 5| Step: 3
Training loss: 1.1927982568740845
Validation loss: 2.2311587631702423

Epoch: 5| Step: 4
Training loss: 1.282543420791626
Validation loss: 2.1428258568048477

Epoch: 5| Step: 5
Training loss: 1.678816556930542
Validation loss: 2.1723798712094626

Epoch: 5| Step: 6
Training loss: 1.3723398447036743
Validation loss: 2.177637681365013

Epoch: 5| Step: 7
Training loss: 1.539193868637085
Validation loss: 2.1185241440931954

Epoch: 5| Step: 8
Training loss: 1.7785015106201172
Validation loss: 2.2209053486585617

Epoch: 5| Step: 9
Training loss: 1.4967892169952393
Validation loss: 2.212522948781649

Epoch: 5| Step: 10
Training loss: 2.1054892539978027
Validation loss: 2.1742325723171234

Epoch: 5| Step: 11
Training loss: 0.8541770577430725
Validation loss: 2.179125338792801

Epoch: 118| Step: 0
Training loss: 2.3190057277679443
Validation loss: 2.137806713581085

Epoch: 5| Step: 1
Training loss: 1.5267305374145508
Validation loss: 2.1310092508792877

Epoch: 5| Step: 2
Training loss: 1.3293756246566772
Validation loss: 2.151148940126101

Epoch: 5| Step: 3
Training loss: 1.1995182037353516
Validation loss: 2.160540690024694

Epoch: 5| Step: 4
Training loss: 1.51593816280365
Validation loss: 2.1585839837789536

Epoch: 5| Step: 5
Training loss: 1.556024193763733
Validation loss: 2.146655003229777

Epoch: 5| Step: 6
Training loss: 1.422803521156311
Validation loss: 2.123915915687879

Epoch: 5| Step: 7
Training loss: 1.7746493816375732
Validation loss: 2.0799244741598764

Epoch: 5| Step: 8
Training loss: 1.517438292503357
Validation loss: 2.155483345190684

Epoch: 5| Step: 9
Training loss: 2.0348939895629883
Validation loss: 2.1948306957880654

Epoch: 5| Step: 10
Training loss: 1.4527562856674194
Validation loss: 2.2048558394114175

Epoch: 5| Step: 11
Training loss: 1.0304538011550903
Validation loss: 2.194585849841436

Epoch: 119| Step: 0
Training loss: 1.2628118991851807
Validation loss: 2.1724723676840463

Epoch: 5| Step: 1
Training loss: 1.0803035497665405
Validation loss: 2.186334212621053

Epoch: 5| Step: 2
Training loss: 1.573413610458374
Validation loss: 2.254575192928314

Epoch: 5| Step: 3
Training loss: 1.6120660305023193
Validation loss: 2.2660704106092453

Epoch: 5| Step: 4
Training loss: 1.9238669872283936
Validation loss: 2.2271257837613425

Epoch: 5| Step: 5
Training loss: 1.7369673252105713
Validation loss: 2.112739016612371

Epoch: 5| Step: 6
Training loss: 1.7132200002670288
Validation loss: 2.158896873394648

Epoch: 5| Step: 7
Training loss: 1.409973382949829
Validation loss: 2.1580237497886023

Epoch: 5| Step: 8
Training loss: 1.4780220985412598
Validation loss: 2.130148390928904

Epoch: 5| Step: 9
Training loss: 1.7161223888397217
Validation loss: 2.1452304323514304

Epoch: 5| Step: 10
Training loss: 1.9745317697525024
Validation loss: 2.2046988755464554

Epoch: 5| Step: 11
Training loss: 1.2619147300720215
Validation loss: 2.144459903240204

Epoch: 120| Step: 0
Training loss: 1.760352373123169
Validation loss: 2.187607616186142

Epoch: 5| Step: 1
Training loss: 1.7195355892181396
Validation loss: 2.119755590955416

Epoch: 5| Step: 2
Training loss: 1.7238715887069702
Validation loss: 2.201286961634954

Epoch: 5| Step: 3
Training loss: 1.5843729972839355
Validation loss: 2.1733374843994775

Epoch: 5| Step: 4
Training loss: 1.6005586385726929
Validation loss: 2.205062299966812

Epoch: 5| Step: 5
Training loss: 1.6938393115997314
Validation loss: 2.104541093111038

Epoch: 5| Step: 6
Training loss: 2.1688928604125977
Validation loss: 2.2103438079357147

Epoch: 5| Step: 7
Training loss: 1.1560709476470947
Validation loss: 2.19843357304732

Epoch: 5| Step: 8
Training loss: 1.6320064067840576
Validation loss: 2.163647696375847

Epoch: 5| Step: 9
Training loss: 1.543424129486084
Validation loss: 2.2277150650819144

Epoch: 5| Step: 10
Training loss: 1.1325764656066895
Validation loss: 2.156238024433454

Epoch: 5| Step: 11
Training loss: 2.4112472534179688
Validation loss: 2.2948973029851913

Epoch: 121| Step: 0
Training loss: 1.158850073814392
Validation loss: 2.2164233724276223

Epoch: 5| Step: 1
Training loss: 1.827718734741211
Validation loss: 2.145785947640737

Epoch: 5| Step: 2
Training loss: 1.4625332355499268
Validation loss: 2.216314524412155

Epoch: 5| Step: 3
Training loss: 1.446431279182434
Validation loss: 2.1937469194332757

Epoch: 5| Step: 4
Training loss: 1.2576080560684204
Validation loss: 2.1655339300632477

Epoch: 5| Step: 5
Training loss: 1.211047887802124
Validation loss: 2.145154520869255

Epoch: 5| Step: 6
Training loss: 1.8360271453857422
Validation loss: 2.1705280045668283

Epoch: 5| Step: 7
Training loss: 1.451014518737793
Validation loss: 2.172940214474996

Epoch: 5| Step: 8
Training loss: 1.463659644126892
Validation loss: 2.19123966495196

Epoch: 5| Step: 9
Training loss: 1.8065669536590576
Validation loss: 2.1485187311967215

Epoch: 5| Step: 10
Training loss: 2.0576305389404297
Validation loss: 2.143955558538437

Epoch: 5| Step: 11
Training loss: 1.6423814296722412
Validation loss: 2.1499069233735404

Epoch: 122| Step: 0
Training loss: 1.5121517181396484
Validation loss: 2.135235403974851

Epoch: 5| Step: 1
Training loss: 1.632318139076233
Validation loss: 2.142221356431643

Epoch: 5| Step: 2
Training loss: 1.0787508487701416
Validation loss: 2.2050758550564447

Epoch: 5| Step: 3
Training loss: 1.4664716720581055
Validation loss: 2.176899423201879

Epoch: 5| Step: 4
Training loss: 1.4795172214508057
Validation loss: 2.20277763903141

Epoch: 5| Step: 5
Training loss: 2.425839900970459
Validation loss: 2.256092051664988

Epoch: 5| Step: 6
Training loss: 1.3436161279678345
Validation loss: 2.187289203206698

Epoch: 5| Step: 7
Training loss: 1.4810583591461182
Validation loss: 2.2203159481287003

Epoch: 5| Step: 8
Training loss: 1.6836059093475342
Validation loss: 2.1961512168248496

Epoch: 5| Step: 9
Training loss: 1.043738842010498
Validation loss: 2.1625464459260306

Epoch: 5| Step: 10
Training loss: 1.7833245992660522
Validation loss: 2.179301679134369

Epoch: 5| Step: 11
Training loss: 1.434114694595337
Validation loss: 2.1156700551509857

Epoch: 123| Step: 0
Training loss: 1.5162233114242554
Validation loss: 2.1655263801415763

Epoch: 5| Step: 1
Training loss: 1.9604578018188477
Validation loss: 2.1797544906536737

Epoch: 5| Step: 2
Training loss: 1.8644202947616577
Validation loss: 2.2396539648373923

Epoch: 5| Step: 3
Training loss: 1.744359016418457
Validation loss: 2.208197002609571

Epoch: 5| Step: 4
Training loss: 1.5572401285171509
Validation loss: 2.1892265180746713

Epoch: 5| Step: 5
Training loss: 1.8795416355133057
Validation loss: 2.1852022806803384

Epoch: 5| Step: 6
Training loss: 1.6746902465820312
Validation loss: 2.2049983690182366

Epoch: 5| Step: 7
Training loss: 1.6536858081817627
Validation loss: 2.254905899365743

Epoch: 5| Step: 8
Training loss: 1.589718222618103
Validation loss: 2.146264354387919

Epoch: 5| Step: 9
Training loss: 1.3438212871551514
Validation loss: 2.160802731911341

Epoch: 5| Step: 10
Training loss: 1.4516810178756714
Validation loss: 2.157058427731196

Epoch: 5| Step: 11
Training loss: 0.9762505888938904
Validation loss: 2.2049899846315384

Epoch: 124| Step: 0
Training loss: 1.7043144702911377
Validation loss: 2.186375250418981

Epoch: 5| Step: 1
Training loss: 1.1833440065383911
Validation loss: 2.1938758293787637

Epoch: 5| Step: 2
Training loss: 1.599603295326233
Validation loss: 2.1812298049529395

Epoch: 5| Step: 3
Training loss: 1.5670961141586304
Validation loss: 2.179262970884641

Epoch: 5| Step: 4
Training loss: 1.2197749614715576
Validation loss: 2.2549693981806436

Epoch: 5| Step: 5
Training loss: 1.6056270599365234
Validation loss: 2.135239988565445

Epoch: 5| Step: 6
Training loss: 1.4785254001617432
Validation loss: 2.167669082681338

Epoch: 5| Step: 7
Training loss: 1.9823434352874756
Validation loss: 2.1701625933249793

Epoch: 5| Step: 8
Training loss: 1.2537708282470703
Validation loss: 2.102484772602717

Epoch: 5| Step: 9
Training loss: 1.5427560806274414
Validation loss: 2.2052767475446067

Epoch: 5| Step: 10
Training loss: 1.935198187828064
Validation loss: 2.1011203030745187

Epoch: 5| Step: 11
Training loss: 0.7045755386352539
Validation loss: 2.18160151441892

Epoch: 125| Step: 0
Training loss: 1.492017149925232
Validation loss: 2.1582834174235663

Epoch: 5| Step: 1
Training loss: 0.9591639637947083
Validation loss: 2.150355949997902

Epoch: 5| Step: 2
Training loss: 1.704874038696289
Validation loss: 2.2476145923137665

Epoch: 5| Step: 3
Training loss: 1.7111103534698486
Validation loss: 2.1408789108196893

Epoch: 5| Step: 4
Training loss: 1.4539682865142822
Validation loss: 2.160008137424787

Epoch: 5| Step: 5
Training loss: 1.5309333801269531
Validation loss: 2.204565773407618

Epoch: 5| Step: 6
Training loss: 1.433362364768982
Validation loss: 2.186169356107712

Epoch: 5| Step: 7
Training loss: 1.9367198944091797
Validation loss: 2.144019201397896

Epoch: 5| Step: 8
Training loss: 1.6539738178253174
Validation loss: 2.1189979563156762

Epoch: 5| Step: 9
Training loss: 1.2718391418457031
Validation loss: 2.101270536581675

Epoch: 5| Step: 10
Training loss: 1.513269066810608
Validation loss: 2.147495756546656

Epoch: 5| Step: 11
Training loss: 2.1238856315612793
Validation loss: 2.1110268384218216

Epoch: 126| Step: 0
Training loss: 1.6821568012237549
Validation loss: 2.1694569985071817

Epoch: 5| Step: 1
Training loss: 1.1338598728179932
Validation loss: 2.174495816230774

Epoch: 5| Step: 2
Training loss: 1.353895664215088
Validation loss: 2.1674088587363562

Epoch: 5| Step: 3
Training loss: 1.3214597702026367
Validation loss: 2.1748953809340796

Epoch: 5| Step: 4
Training loss: 2.1402714252471924
Validation loss: 2.0883855869372687

Epoch: 5| Step: 5
Training loss: 1.230381727218628
Validation loss: 2.1741370062033334

Epoch: 5| Step: 6
Training loss: 1.6217145919799805
Validation loss: 2.1518533726533255

Epoch: 5| Step: 7
Training loss: 1.7745857238769531
Validation loss: 2.1269900699456534

Epoch: 5| Step: 8
Training loss: 1.9863178730010986
Validation loss: 2.177558129032453

Epoch: 5| Step: 9
Training loss: 1.4422911405563354
Validation loss: 2.1418501436710358

Epoch: 5| Step: 10
Training loss: 1.8325084447860718
Validation loss: 2.153761704762777

Epoch: 5| Step: 11
Training loss: 1.287746787071228
Validation loss: 2.1773593574762344

Epoch: 127| Step: 0
Training loss: 1.0988212823867798
Validation loss: 2.2066896855831146

Epoch: 5| Step: 1
Training loss: 2.2587814331054688
Validation loss: 2.125485176841418

Epoch: 5| Step: 2
Training loss: 1.3595314025878906
Validation loss: 2.175353099902471

Epoch: 5| Step: 3
Training loss: 2.053438663482666
Validation loss: 2.1999671359856925

Epoch: 5| Step: 4
Training loss: 1.3862498998641968
Validation loss: 2.1356598486502967

Epoch: 5| Step: 5
Training loss: 1.408630609512329
Validation loss: 2.155488317211469

Epoch: 5| Step: 6
Training loss: 1.2715303897857666
Validation loss: 2.198463648557663

Epoch: 5| Step: 7
Training loss: 1.1875907182693481
Validation loss: 2.181363860766093

Epoch: 5| Step: 8
Training loss: 1.5587971210479736
Validation loss: 2.172485535343488

Epoch: 5| Step: 9
Training loss: 2.148751735687256
Validation loss: 2.1641420473655066

Epoch: 5| Step: 10
Training loss: 1.3411874771118164
Validation loss: 2.187501927216848

Epoch: 5| Step: 11
Training loss: 0.7350893020629883
Validation loss: 2.1438533812761307

Epoch: 128| Step: 0
Training loss: 1.1403172016143799
Validation loss: 2.1565343340237937

Epoch: 5| Step: 1
Training loss: 0.7824541330337524
Validation loss: 2.202902684609095

Epoch: 5| Step: 2
Training loss: 1.5333349704742432
Validation loss: 2.2055791517098746

Epoch: 5| Step: 3
Training loss: 1.6322777271270752
Validation loss: 2.1617633948723474

Epoch: 5| Step: 4
Training loss: 1.9371006488800049
Validation loss: 2.199762503306071

Epoch: 5| Step: 5
Training loss: 1.9430971145629883
Validation loss: 2.1940403878688812

Epoch: 5| Step: 6
Training loss: 1.2482357025146484
Validation loss: 2.213325619697571

Epoch: 5| Step: 7
Training loss: 1.5108985900878906
Validation loss: 2.167682647705078

Epoch: 5| Step: 8
Training loss: 1.5542694330215454
Validation loss: 2.168822338183721

Epoch: 5| Step: 9
Training loss: 1.8093726634979248
Validation loss: 2.1973437120517096

Epoch: 5| Step: 10
Training loss: 1.2202649116516113
Validation loss: 2.1912504186232886

Epoch: 5| Step: 11
Training loss: 1.775437831878662
Validation loss: 2.1442128966252008

Epoch: 129| Step: 0
Training loss: 1.931471824645996
Validation loss: 2.21419395506382

Epoch: 5| Step: 1
Training loss: 1.0744348764419556
Validation loss: 2.0810296684503555

Epoch: 5| Step: 2
Training loss: 1.6200469732284546
Validation loss: 2.2173703759908676

Epoch: 5| Step: 3
Training loss: 1.6766126155853271
Validation loss: 2.1997359842061996

Epoch: 5| Step: 4
Training loss: 2.0701277256011963
Validation loss: 2.1751869271198907

Epoch: 5| Step: 5
Training loss: 0.9099456071853638
Validation loss: 2.1983762880166373

Epoch: 5| Step: 6
Training loss: 1.2482450008392334
Validation loss: 2.1669027556975684

Epoch: 5| Step: 7
Training loss: 1.385128378868103
Validation loss: 2.1807444194952645

Epoch: 5| Step: 8
Training loss: 1.3437786102294922
Validation loss: 2.1717229783535004

Epoch: 5| Step: 9
Training loss: 1.7370086908340454
Validation loss: 2.1853631337483725

Epoch: 5| Step: 10
Training loss: 1.7037855386734009
Validation loss: 2.1916653364896774

Epoch: 5| Step: 11
Training loss: 0.6827844381332397
Validation loss: 2.2135732720295587

Epoch: 130| Step: 0
Training loss: 1.5164440870285034
Validation loss: 2.1739078362782798

Epoch: 5| Step: 1
Training loss: 1.1507580280303955
Validation loss: 2.195819998780886

Epoch: 5| Step: 2
Training loss: 1.3671659231185913
Validation loss: 2.171439006924629

Epoch: 5| Step: 3
Training loss: 1.2559001445770264
Validation loss: 2.201403041680654

Epoch: 5| Step: 4
Training loss: 1.339184045791626
Validation loss: 2.103286455074946

Epoch: 5| Step: 5
Training loss: 1.512344479560852
Validation loss: 2.152822415033976

Epoch: 5| Step: 6
Training loss: 1.746117353439331
Validation loss: 2.1693739543358483

Epoch: 5| Step: 7
Training loss: 1.5645684003829956
Validation loss: 2.259406919280688

Epoch: 5| Step: 8
Training loss: 1.2794331312179565
Validation loss: 2.1030221432447433

Epoch: 5| Step: 9
Training loss: 2.06756591796875
Validation loss: 2.199484666188558

Epoch: 5| Step: 10
Training loss: 2.0516724586486816
Validation loss: 2.220021292567253

Epoch: 5| Step: 11
Training loss: 0.5600482225418091
Validation loss: 2.0997303873300552

Epoch: 131| Step: 0
Training loss: 1.4350612163543701
Validation loss: 2.1758222530285516

Epoch: 5| Step: 1
Training loss: 1.7095749378204346
Validation loss: 2.176050533850988

Epoch: 5| Step: 2
Training loss: 1.1720794439315796
Validation loss: 2.140009199579557

Epoch: 5| Step: 3
Training loss: 1.1614830493927002
Validation loss: 2.139020790656408

Epoch: 5| Step: 4
Training loss: 1.1212425231933594
Validation loss: 2.1616228173176446

Epoch: 5| Step: 5
Training loss: 1.350388765335083
Validation loss: 2.1016017695267997

Epoch: 5| Step: 6
Training loss: 2.024573802947998
Validation loss: 2.196961065133413

Epoch: 5| Step: 7
Training loss: 1.3936316967010498
Validation loss: 2.1414324839909873

Epoch: 5| Step: 8
Training loss: 1.388169527053833
Validation loss: 2.158777376015981

Epoch: 5| Step: 9
Training loss: 1.9092013835906982
Validation loss: 2.213231086730957

Epoch: 5| Step: 10
Training loss: 1.5465468168258667
Validation loss: 2.1790751616160073

Epoch: 5| Step: 11
Training loss: 1.0881459712982178
Validation loss: 2.2067389488220215

Epoch: 132| Step: 0
Training loss: 1.8108789920806885
Validation loss: 2.158147012193998

Epoch: 5| Step: 1
Training loss: 1.5910325050354004
Validation loss: 2.1993943651517234

Epoch: 5| Step: 2
Training loss: 1.3291915655136108
Validation loss: 2.1539780100186667

Epoch: 5| Step: 3
Training loss: 1.2997123003005981
Validation loss: 2.17042467991511

Epoch: 5| Step: 4
Training loss: 1.5483930110931396
Validation loss: 2.181582366426786

Epoch: 5| Step: 5
Training loss: 1.3900947570800781
Validation loss: 2.134279583891233

Epoch: 5| Step: 6
Training loss: 1.4223735332489014
Validation loss: 2.202683061361313

Epoch: 5| Step: 7
Training loss: 1.3269844055175781
Validation loss: 2.1640878915786743

Epoch: 5| Step: 8
Training loss: 1.2643687725067139
Validation loss: 2.2156642079353333

Epoch: 5| Step: 9
Training loss: 1.7415679693222046
Validation loss: 2.1591688245534897

Epoch: 5| Step: 10
Training loss: 1.3314794301986694
Validation loss: 2.2105688055356345

Epoch: 5| Step: 11
Training loss: 1.7698405981063843
Validation loss: 2.1562105417251587

Epoch: 133| Step: 0
Training loss: 1.1159608364105225
Validation loss: 2.207314526041349

Epoch: 5| Step: 1
Training loss: 1.3696147203445435
Validation loss: 2.1770345071951547

Epoch: 5| Step: 2
Training loss: 1.6877498626708984
Validation loss: 2.126787319779396

Epoch: 5| Step: 3
Training loss: 1.5452393293380737
Validation loss: 2.216591715812683

Epoch: 5| Step: 4
Training loss: 1.390071988105774
Validation loss: 2.0767660439014435

Epoch: 5| Step: 5
Training loss: 1.8116710186004639
Validation loss: 2.1792364021142325

Epoch: 5| Step: 6
Training loss: 1.3812849521636963
Validation loss: 2.1935316920280457

Epoch: 5| Step: 7
Training loss: 1.2733591794967651
Validation loss: 2.202501118183136

Epoch: 5| Step: 8
Training loss: 1.2159252166748047
Validation loss: 2.258035654822985

Epoch: 5| Step: 9
Training loss: 1.662519097328186
Validation loss: 2.184180572628975

Epoch: 5| Step: 10
Training loss: 1.5658626556396484
Validation loss: 2.1999146888653436

Epoch: 5| Step: 11
Training loss: 1.3411439657211304
Validation loss: 2.2016045351823172

Epoch: 134| Step: 0
Training loss: 1.808971643447876
Validation loss: 2.194284200668335

Epoch: 5| Step: 1
Training loss: 1.462803602218628
Validation loss: 2.1611315459012985

Epoch: 5| Step: 2
Training loss: 0.9375252723693848
Validation loss: 2.2114098270734153

Epoch: 5| Step: 3
Training loss: 1.2896465063095093
Validation loss: 2.2283412168423333

Epoch: 5| Step: 4
Training loss: 1.778437852859497
Validation loss: 2.1612310111522675

Epoch: 5| Step: 5
Training loss: 1.294869065284729
Validation loss: 2.153505648175875

Epoch: 5| Step: 6
Training loss: 1.3855526447296143
Validation loss: 2.1974324186642966

Epoch: 5| Step: 7
Training loss: 1.3871382474899292
Validation loss: 2.2186357180277505

Epoch: 5| Step: 8
Training loss: 1.3837652206420898
Validation loss: 2.210110674301783

Epoch: 5| Step: 9
Training loss: 1.2803971767425537
Validation loss: 2.2136655996243157

Epoch: 5| Step: 10
Training loss: 1.5991487503051758
Validation loss: 2.204318255186081

Epoch: 5| Step: 11
Training loss: 2.59533953666687
Validation loss: 2.1341835955778756

Epoch: 135| Step: 0
Training loss: 1.1933573484420776
Validation loss: 2.1472193400065103

Epoch: 5| Step: 1
Training loss: 1.7300007343292236
Validation loss: 2.176521753271421

Epoch: 5| Step: 2
Training loss: 1.3923008441925049
Validation loss: 2.1967416306336722

Epoch: 5| Step: 3
Training loss: 1.3457869291305542
Validation loss: 2.201121067007383

Epoch: 5| Step: 4
Training loss: 1.5310357809066772
Validation loss: 2.1659593731164932

Epoch: 5| Step: 5
Training loss: 1.5496947765350342
Validation loss: 2.2362475295861564

Epoch: 5| Step: 6
Training loss: 1.1119228601455688
Validation loss: 2.215267171462377

Epoch: 5| Step: 7
Training loss: 1.9812147617340088
Validation loss: 2.208482727408409

Epoch: 5| Step: 8
Training loss: 1.4177443981170654
Validation loss: 2.165743976831436

Epoch: 5| Step: 9
Training loss: 1.5786257982254028
Validation loss: 2.2263930837313333

Epoch: 5| Step: 10
Training loss: 1.4772759675979614
Validation loss: 2.1783584356307983

Epoch: 5| Step: 11
Training loss: 1.8463687896728516
Validation loss: 2.21214497089386

Epoch: 136| Step: 0
Training loss: 1.6887524127960205
Validation loss: 2.1678862869739532

Epoch: 5| Step: 1
Training loss: 1.221286416053772
Validation loss: 2.187295973300934

Epoch: 5| Step: 2
Training loss: 1.8851003646850586
Validation loss: 2.1506188412507377

Epoch: 5| Step: 3
Training loss: 0.9056608080863953
Validation loss: 2.164062723517418

Epoch: 5| Step: 4
Training loss: 1.5022519826889038
Validation loss: 2.228707800308863

Epoch: 5| Step: 5
Training loss: 1.7892684936523438
Validation loss: 2.2213515589634576

Epoch: 5| Step: 6
Training loss: 1.522173285484314
Validation loss: 2.203162615497907

Epoch: 5| Step: 7
Training loss: 1.3728396892547607
Validation loss: 2.2228760570287704

Epoch: 5| Step: 8
Training loss: 1.1886333227157593
Validation loss: 2.196593383948008

Epoch: 5| Step: 9
Training loss: 1.147792935371399
Validation loss: 2.20808112124602

Epoch: 5| Step: 10
Training loss: 1.8393367528915405
Validation loss: 2.2048634439706802

Epoch: 5| Step: 11
Training loss: 2.451416015625
Validation loss: 2.213009705146154

Epoch: 137| Step: 0
Training loss: 1.2406686544418335
Validation loss: 2.1524716963370643

Epoch: 5| Step: 1
Training loss: 1.15892493724823
Validation loss: 2.201294591029485

Epoch: 5| Step: 2
Training loss: 1.5675933361053467
Validation loss: 2.2117286374171576

Epoch: 5| Step: 3
Training loss: 1.2761499881744385
Validation loss: 2.202026382088661

Epoch: 5| Step: 4
Training loss: 1.6678056716918945
Validation loss: 2.184261272350947

Epoch: 5| Step: 5
Training loss: 1.1549155712127686
Validation loss: 2.1850589315096536

Epoch: 5| Step: 6
Training loss: 1.327033281326294
Validation loss: 2.263366470734278

Epoch: 5| Step: 7
Training loss: 1.4628515243530273
Validation loss: 2.2640325129032135

Epoch: 5| Step: 8
Training loss: 1.8324863910675049
Validation loss: 2.2238741715749106

Epoch: 5| Step: 9
Training loss: 1.773857831954956
Validation loss: 2.205659970641136

Epoch: 5| Step: 10
Training loss: 1.4372206926345825
Validation loss: 2.2237428774436316

Epoch: 5| Step: 11
Training loss: 1.8607393503189087
Validation loss: 2.2092439283927283

Epoch: 138| Step: 0
Training loss: 2.1399831771850586
Validation loss: 2.1956978340943656

Epoch: 5| Step: 1
Training loss: 0.8635159730911255
Validation loss: 2.2781507869561515

Epoch: 5| Step: 2
Training loss: 1.217183232307434
Validation loss: 2.209610561529795

Epoch: 5| Step: 3
Training loss: 1.700679063796997
Validation loss: 2.1800549825032554

Epoch: 5| Step: 4
Training loss: 1.493204116821289
Validation loss: 2.2609868297974267

Epoch: 5| Step: 5
Training loss: 1.230312705039978
Validation loss: 2.2464501907428107

Epoch: 5| Step: 6
Training loss: 1.4703551530838013
Validation loss: 2.2183972845474877

Epoch: 5| Step: 7
Training loss: 1.7706091403961182
Validation loss: 2.2336173901955285

Epoch: 5| Step: 8
Training loss: 1.1519083976745605
Validation loss: 2.195298194885254

Epoch: 5| Step: 9
Training loss: 1.1523478031158447
Validation loss: 2.1782586574554443

Epoch: 5| Step: 10
Training loss: 1.3860018253326416
Validation loss: 2.256773849328359

Epoch: 5| Step: 11
Training loss: 1.7175748348236084
Validation loss: 2.237626443306605

Epoch: 139| Step: 0
Training loss: 1.6921688318252563
Validation loss: 2.213142062226931

Epoch: 5| Step: 1
Training loss: 1.6455001831054688
Validation loss: 2.1854638159275055

Epoch: 5| Step: 2
Training loss: 1.110059380531311
Validation loss: 2.1431534190972648

Epoch: 5| Step: 3
Training loss: 1.554146647453308
Validation loss: 2.191330914696058

Epoch: 5| Step: 4
Training loss: 1.439191460609436
Validation loss: 2.2269399166107178

Epoch: 5| Step: 5
Training loss: 1.4865094423294067
Validation loss: 2.205717941125234

Epoch: 5| Step: 6
Training loss: 1.7709592580795288
Validation loss: 2.210425540804863

Epoch: 5| Step: 7
Training loss: 1.446053147315979
Validation loss: 2.228229895234108

Epoch: 5| Step: 8
Training loss: 1.1132014989852905
Validation loss: 2.257093052069346

Epoch: 5| Step: 9
Training loss: 1.2508666515350342
Validation loss: 2.194261610507965

Epoch: 5| Step: 10
Training loss: 1.5000507831573486
Validation loss: 2.188358167807261

Epoch: 5| Step: 11
Training loss: 1.0708308219909668
Validation loss: 2.1676030655701957

Epoch: 140| Step: 0
Training loss: 1.4554929733276367
Validation loss: 2.2455456852912903

Epoch: 5| Step: 1
Training loss: 1.7213687896728516
Validation loss: 2.2640990565220513

Epoch: 5| Step: 2
Training loss: 0.9841654896736145
Validation loss: 2.283594787120819

Epoch: 5| Step: 3
Training loss: 1.458409070968628
Validation loss: 2.2525770912567773

Epoch: 5| Step: 4
Training loss: 1.396449327468872
Validation loss: 2.2144790639479957

Epoch: 5| Step: 5
Training loss: 1.187124252319336
Validation loss: 2.2399664918581643

Epoch: 5| Step: 6
Training loss: 1.6157588958740234
Validation loss: 2.1692067682743073

Epoch: 5| Step: 7
Training loss: 1.2746121883392334
Validation loss: 2.256017804145813

Epoch: 5| Step: 8
Training loss: 1.8207042217254639
Validation loss: 2.214942509929339

Epoch: 5| Step: 9
Training loss: 1.2943990230560303
Validation loss: 2.1930657078822455

Epoch: 5| Step: 10
Training loss: 1.7710691690444946
Validation loss: 2.2096070448557534

Epoch: 5| Step: 11
Training loss: 1.2085819244384766
Validation loss: 2.2529054135084152

Epoch: 141| Step: 0
Training loss: 1.4963055849075317
Validation loss: 2.181991924842199

Epoch: 5| Step: 1
Training loss: 1.7090799808502197
Validation loss: 2.184248000383377

Epoch: 5| Step: 2
Training loss: 1.5637528896331787
Validation loss: 2.229614794254303

Epoch: 5| Step: 3
Training loss: 1.3681561946868896
Validation loss: 2.1928666830062866

Epoch: 5| Step: 4
Training loss: 1.2514616250991821
Validation loss: 2.1909749607245126

Epoch: 5| Step: 5
Training loss: 1.281873345375061
Validation loss: 2.20174910624822

Epoch: 5| Step: 6
Training loss: 0.8629125356674194
Validation loss: 2.239398315548897

Epoch: 5| Step: 7
Training loss: 1.2669099569320679
Validation loss: 2.247096925973892

Epoch: 5| Step: 8
Training loss: 1.51032292842865
Validation loss: 2.215385322769483

Epoch: 5| Step: 9
Training loss: 1.6304271221160889
Validation loss: 2.220013921459516

Epoch: 5| Step: 10
Training loss: 1.6458861827850342
Validation loss: 2.2458055714766183

Epoch: 5| Step: 11
Training loss: 1.9445269107818604
Validation loss: 2.225254327058792

Epoch: 142| Step: 0
Training loss: 1.7164332866668701
Validation loss: 2.2821293572584787

Epoch: 5| Step: 1
Training loss: 1.2294461727142334
Validation loss: 2.2144265274206796

Epoch: 5| Step: 2
Training loss: 1.09612238407135
Validation loss: 2.2027094662189484

Epoch: 5| Step: 3
Training loss: 2.309074878692627
Validation loss: 2.1925395329793296

Epoch: 5| Step: 4
Training loss: 1.675054907798767
Validation loss: 2.233594089746475

Epoch: 5| Step: 5
Training loss: 1.3607864379882812
Validation loss: 2.2074118554592133

Epoch: 5| Step: 6
Training loss: 1.3772163391113281
Validation loss: 2.2040271560351052

Epoch: 5| Step: 7
Training loss: 1.1131778955459595
Validation loss: 2.231764167547226

Epoch: 5| Step: 8
Training loss: 1.0156415700912476
Validation loss: 2.165941963593165

Epoch: 5| Step: 9
Training loss: 1.2929918766021729
Validation loss: 2.204616591334343

Epoch: 5| Step: 10
Training loss: 1.0768964290618896
Validation loss: 2.2089129388332367

Epoch: 5| Step: 11
Training loss: 2.2542240619659424
Validation loss: 2.2766607950131097

Epoch: 143| Step: 0
Training loss: 2.135361433029175
Validation loss: 2.2571960985660553

Epoch: 5| Step: 1
Training loss: 1.014308214187622
Validation loss: 2.1782492150863013

Epoch: 5| Step: 2
Training loss: 1.0791614055633545
Validation loss: 2.241420567035675

Epoch: 5| Step: 3
Training loss: 1.543595552444458
Validation loss: 2.2802638113498688

Epoch: 5| Step: 4
Training loss: 1.4540350437164307
Validation loss: 2.2457785258690515

Epoch: 5| Step: 5
Training loss: 1.683905839920044
Validation loss: 2.271398574113846

Epoch: 5| Step: 6
Training loss: 1.3856364488601685
Validation loss: 2.1469035347302756

Epoch: 5| Step: 7
Training loss: 1.4516990184783936
Validation loss: 2.2318487763404846

Epoch: 5| Step: 8
Training loss: 1.3287469148635864
Validation loss: 2.220904861887296

Epoch: 5| Step: 9
Training loss: 1.3663733005523682
Validation loss: 2.1856912871201835

Epoch: 5| Step: 10
Training loss: 1.2224860191345215
Validation loss: 2.222480600078901

Epoch: 5| Step: 11
Training loss: 1.4076906442642212
Validation loss: 2.158415660262108

Epoch: 144| Step: 0
Training loss: 1.395298719406128
Validation loss: 2.218996375799179

Epoch: 5| Step: 1
Training loss: 1.736293077468872
Validation loss: 2.2522311011950173

Epoch: 5| Step: 2
Training loss: 1.238150715827942
Validation loss: 2.2588477532068887

Epoch: 5| Step: 3
Training loss: 1.4324369430541992
Validation loss: 2.246656904617945

Epoch: 5| Step: 4
Training loss: 0.841519832611084
Validation loss: 2.2504020084937415

Epoch: 5| Step: 5
Training loss: 0.9805936813354492
Validation loss: 2.1720236937204995

Epoch: 5| Step: 6
Training loss: 1.946170449256897
Validation loss: 2.287554919719696

Epoch: 5| Step: 7
Training loss: 1.3287465572357178
Validation loss: 2.2657574514547982

Epoch: 5| Step: 8
Training loss: 1.3606984615325928
Validation loss: 2.1637316246827445

Epoch: 5| Step: 9
Training loss: 1.143599033355713
Validation loss: 2.2006948391596475

Epoch: 5| Step: 10
Training loss: 1.6292858123779297
Validation loss: 2.201338137189547

Epoch: 5| Step: 11
Training loss: 1.0107651948928833
Validation loss: 2.2777761767307916

Epoch: 145| Step: 0
Training loss: 1.069724678993225
Validation loss: 2.2288509905338287

Epoch: 5| Step: 1
Training loss: 1.064474105834961
Validation loss: 2.1564364284276962

Epoch: 5| Step: 2
Training loss: 1.3811466693878174
Validation loss: 2.2124520341555276

Epoch: 5| Step: 3
Training loss: 1.3626877069473267
Validation loss: 2.2235986093680062

Epoch: 5| Step: 4
Training loss: 1.0811189413070679
Validation loss: 2.2007955610752106

Epoch: 5| Step: 5
Training loss: 1.3328943252563477
Validation loss: 2.2565469245115914

Epoch: 5| Step: 6
Training loss: 1.9088599681854248
Validation loss: 2.218679815530777

Epoch: 5| Step: 7
Training loss: 1.3928569555282593
Validation loss: 2.2790334771076837

Epoch: 5| Step: 8
Training loss: 1.4464590549468994
Validation loss: 2.2007941901683807

Epoch: 5| Step: 9
Training loss: 1.5549808740615845
Validation loss: 2.318372448285421

Epoch: 5| Step: 10
Training loss: 1.436989188194275
Validation loss: 2.226945454875628

Epoch: 5| Step: 11
Training loss: 3.098489284515381
Validation loss: 2.2273622949918113

Epoch: 146| Step: 0
Training loss: 1.399340033531189
Validation loss: 2.228768159945806

Epoch: 5| Step: 1
Training loss: 1.6664512157440186
Validation loss: 2.2330855329831443

Epoch: 5| Step: 2
Training loss: 1.331673264503479
Validation loss: 2.2763877511024475

Epoch: 5| Step: 3
Training loss: 1.823670744895935
Validation loss: 2.224928066134453

Epoch: 5| Step: 4
Training loss: 1.0562944412231445
Validation loss: 2.226404845714569

Epoch: 5| Step: 5
Training loss: 1.529081106185913
Validation loss: 2.204259147246679

Epoch: 5| Step: 6
Training loss: 1.3801820278167725
Validation loss: 2.246577183405558

Epoch: 5| Step: 7
Training loss: 1.0470099449157715
Validation loss: 2.254697879155477

Epoch: 5| Step: 8
Training loss: 1.0766115188598633
Validation loss: 2.234665801127752

Epoch: 5| Step: 9
Training loss: 1.525965929031372
Validation loss: 2.2495587915182114

Epoch: 5| Step: 10
Training loss: 0.990752100944519
Validation loss: 2.2708499282598495

Epoch: 5| Step: 11
Training loss: 1.1048610210418701
Validation loss: 2.2106060087680817

Epoch: 147| Step: 0
Training loss: 1.4550600051879883
Validation loss: 2.28372294207414

Epoch: 5| Step: 1
Training loss: 1.7107681035995483
Validation loss: 2.2935145248969397

Epoch: 5| Step: 2
Training loss: 1.3777072429656982
Validation loss: 2.21852138141791

Epoch: 5| Step: 3
Training loss: 1.0789715051651
Validation loss: 2.226033995548884

Epoch: 5| Step: 4
Training loss: 1.343247652053833
Validation loss: 2.2010428508122764

Epoch: 5| Step: 5
Training loss: 0.9018707275390625
Validation loss: 2.198239177465439

Epoch: 5| Step: 6
Training loss: 0.9909658432006836
Validation loss: 2.2261086205641427

Epoch: 5| Step: 7
Training loss: 1.3116990327835083
Validation loss: 2.231874247392019

Epoch: 5| Step: 8
Training loss: 1.7833969593048096
Validation loss: 2.1599162817001343

Epoch: 5| Step: 9
Training loss: 1.4473130702972412
Validation loss: 2.242731715242068

Epoch: 5| Step: 10
Training loss: 1.7926876544952393
Validation loss: 2.2094156990448632

Epoch: 5| Step: 11
Training loss: 1.8747283220291138
Validation loss: 2.2710059881210327

Epoch: 148| Step: 0
Training loss: 1.1954197883605957
Validation loss: 2.213805596033732

Epoch: 5| Step: 1
Training loss: 1.3078839778900146
Validation loss: 2.1690056224664054

Epoch: 5| Step: 2
Training loss: 1.3849356174468994
Validation loss: 2.1884418725967407

Epoch: 5| Step: 3
Training loss: 1.2613171339035034
Validation loss: 2.2009134143590927

Epoch: 5| Step: 4
Training loss: 1.6145257949829102
Validation loss: 2.257775068283081

Epoch: 5| Step: 5
Training loss: 1.3713157176971436
Validation loss: 2.2835434625546136

Epoch: 5| Step: 6
Training loss: 1.2690187692642212
Validation loss: 2.1917819380760193

Epoch: 5| Step: 7
Training loss: 1.3909465074539185
Validation loss: 2.172155116995176

Epoch: 5| Step: 8
Training loss: 0.980027973651886
Validation loss: 2.274194131294886

Epoch: 5| Step: 9
Training loss: 1.7023814916610718
Validation loss: 2.2205306589603424

Epoch: 5| Step: 10
Training loss: 1.6985902786254883
Validation loss: 2.2360308716694512

Epoch: 5| Step: 11
Training loss: 1.349050760269165
Validation loss: 2.2304039349158606

Epoch: 149| Step: 0
Training loss: 1.3784618377685547
Validation loss: 2.2668079237143197

Epoch: 5| Step: 1
Training loss: 1.3627994060516357
Validation loss: 2.1956321696440377

Epoch: 5| Step: 2
Training loss: 1.886234998703003
Validation loss: 2.2035739918549857

Epoch: 5| Step: 3
Training loss: 1.704491376876831
Validation loss: 2.2744581550359726

Epoch: 5| Step: 4
Training loss: 1.5813943147659302
Validation loss: 2.2468738506237664

Epoch: 5| Step: 5
Training loss: 1.2036552429199219
Validation loss: 2.2141663134098053

Epoch: 5| Step: 6
Training loss: 0.8807546496391296
Validation loss: 2.22729363044103

Epoch: 5| Step: 7
Training loss: 1.3380247354507446
Validation loss: 2.24686798453331

Epoch: 5| Step: 8
Training loss: 1.1523590087890625
Validation loss: 2.209995776414871

Epoch: 5| Step: 9
Training loss: 0.9556933641433716
Validation loss: 2.2008734047412872

Epoch: 5| Step: 10
Training loss: 1.746618628501892
Validation loss: 2.2714286198218665

Epoch: 5| Step: 11
Training loss: 2.129430055618286
Validation loss: 2.235292653242747

Epoch: 150| Step: 0
Training loss: 1.3886373043060303
Validation loss: 2.2640940994024277

Epoch: 5| Step: 1
Training loss: 1.2713029384613037
Validation loss: 2.24078461031119

Epoch: 5| Step: 2
Training loss: 0.8578154444694519
Validation loss: 2.212204545736313

Epoch: 5| Step: 3
Training loss: 1.3868238925933838
Validation loss: 2.245282679796219

Epoch: 5| Step: 4
Training loss: 1.2838255167007446
Validation loss: 2.27833383778731

Epoch: 5| Step: 5
Training loss: 1.3561923503875732
Validation loss: 2.272207647562027

Epoch: 5| Step: 6
Training loss: 1.7045986652374268
Validation loss: 2.247297783692678

Epoch: 5| Step: 7
Training loss: 1.1528658866882324
Validation loss: 2.3119372526804605

Epoch: 5| Step: 8
Training loss: 1.7653477191925049
Validation loss: 2.215654194355011

Epoch: 5| Step: 9
Training loss: 1.0290658473968506
Validation loss: 2.2384252150853476

Epoch: 5| Step: 10
Training loss: 1.3817194700241089
Validation loss: 2.2845082581043243

Epoch: 5| Step: 11
Training loss: 1.696480631828308
Validation loss: 2.321265975634257

Epoch: 151| Step: 0
Training loss: 1.2204535007476807
Validation loss: 2.268954654534658

Epoch: 5| Step: 1
Training loss: 1.5244178771972656
Validation loss: 2.2711972991625466

Epoch: 5| Step: 2
Training loss: 0.9677654504776001
Validation loss: 2.2239800294240317

Epoch: 5| Step: 3
Training loss: 1.2226083278656006
Validation loss: 2.2509190340836844

Epoch: 5| Step: 4
Training loss: 1.139939308166504
Validation loss: 2.3000594774881997

Epoch: 5| Step: 5
Training loss: 1.6587707996368408
Validation loss: 2.1663697014252343

Epoch: 5| Step: 6
Training loss: 1.7355893850326538
Validation loss: 2.2683572471141815

Epoch: 5| Step: 7
Training loss: 1.5576270818710327
Validation loss: 2.2289626051982245

Epoch: 5| Step: 8
Training loss: 1.6378352642059326
Validation loss: 2.1909924497207007

Epoch: 5| Step: 9
Training loss: 1.3385450839996338
Validation loss: 2.1906007577975593

Epoch: 5| Step: 10
Training loss: 0.621481716632843
Validation loss: 2.2448090662558875

Epoch: 5| Step: 11
Training loss: 1.0226258039474487
Validation loss: 2.232268437743187

Epoch: 152| Step: 0
Training loss: 1.3572638034820557
Validation loss: 2.2630128264427185

Epoch: 5| Step: 1
Training loss: 1.0807559490203857
Validation loss: 2.23240202665329

Epoch: 5| Step: 2
Training loss: 0.9077919721603394
Validation loss: 2.2515276670455933

Epoch: 5| Step: 3
Training loss: 1.4121730327606201
Validation loss: 2.2302358647187552

Epoch: 5| Step: 4
Training loss: 1.152320146560669
Validation loss: 2.200887680053711

Epoch: 5| Step: 5
Training loss: 1.1567370891571045
Validation loss: 2.2231025298436484

Epoch: 5| Step: 6
Training loss: 1.7161903381347656
Validation loss: 2.2095703333616257

Epoch: 5| Step: 7
Training loss: 1.5971218347549438
Validation loss: 2.2259120444456735

Epoch: 5| Step: 8
Training loss: 1.4446574449539185
Validation loss: 2.2700540026028952

Epoch: 5| Step: 9
Training loss: 1.408543348312378
Validation loss: 2.235008334120115

Epoch: 5| Step: 10
Training loss: 1.1497715711593628
Validation loss: 2.2020031412442527

Epoch: 5| Step: 11
Training loss: 1.6909350156784058
Validation loss: 2.2824596762657166

Epoch: 153| Step: 0
Training loss: 1.3585814237594604
Validation loss: 2.244368761777878

Epoch: 5| Step: 1
Training loss: 0.9765704870223999
Validation loss: 2.242775648832321

Epoch: 5| Step: 2
Training loss: 1.6640691757202148
Validation loss: 2.2055947879950204

Epoch: 5| Step: 3
Training loss: 1.0020253658294678
Validation loss: 2.2392103473345437

Epoch: 5| Step: 4
Training loss: 0.8716287612915039
Validation loss: 2.1916496654351554

Epoch: 5| Step: 5
Training loss: 1.3667067289352417
Validation loss: 2.2417396108309426

Epoch: 5| Step: 6
Training loss: 0.7091341018676758
Validation loss: 2.226039320230484

Epoch: 5| Step: 7
Training loss: 1.455237627029419
Validation loss: 2.1877156496047974

Epoch: 5| Step: 8
Training loss: 1.694109320640564
Validation loss: 2.2363237142562866

Epoch: 5| Step: 9
Training loss: 1.3985042572021484
Validation loss: 2.2810033162434897

Epoch: 5| Step: 10
Training loss: 1.4733335971832275
Validation loss: 2.248322998483976

Epoch: 5| Step: 11
Training loss: 1.3172273635864258
Validation loss: 2.2080046037832894

Epoch: 154| Step: 0
Training loss: 1.4724581241607666
Validation loss: 2.214161609609922

Epoch: 5| Step: 1
Training loss: 0.9314300417900085
Validation loss: 2.2344588339328766

Epoch: 5| Step: 2
Training loss: 1.4470274448394775
Validation loss: 2.2607738773028054

Epoch: 5| Step: 3
Training loss: 0.9766041040420532
Validation loss: 2.2953141778707504

Epoch: 5| Step: 4
Training loss: 2.059980869293213
Validation loss: 2.2797449827194214

Epoch: 5| Step: 5
Training loss: 1.5250707864761353
Validation loss: 2.2458869417508445

Epoch: 5| Step: 6
Training loss: 1.0444308519363403
Validation loss: 2.2511528531710305

Epoch: 5| Step: 7
Training loss: 1.1301836967468262
Validation loss: 2.317945197224617

Epoch: 5| Step: 8
Training loss: 1.2678196430206299
Validation loss: 2.2986848205327988

Epoch: 5| Step: 9
Training loss: 1.0545408725738525
Validation loss: 2.19474529226621

Epoch: 5| Step: 10
Training loss: 1.362428069114685
Validation loss: 2.2821125040451684

Epoch: 5| Step: 11
Training loss: 1.816711187362671
Validation loss: 2.2173081835110984

Epoch: 155| Step: 0
Training loss: 1.5788216590881348
Validation loss: 2.2587694178024926

Epoch: 5| Step: 1
Training loss: 1.7588574886322021
Validation loss: 2.2415663500626883

Epoch: 5| Step: 2
Training loss: 0.734772264957428
Validation loss: 2.2690923859675727

Epoch: 5| Step: 3
Training loss: 1.350206971168518
Validation loss: 2.217284858226776

Epoch: 5| Step: 4
Training loss: 1.5280530452728271
Validation loss: 2.2507466276486716

Epoch: 5| Step: 5
Training loss: 0.889661967754364
Validation loss: 2.2295306275288262

Epoch: 5| Step: 6
Training loss: 1.3478984832763672
Validation loss: 2.241110771894455

Epoch: 5| Step: 7
Training loss: 1.105534315109253
Validation loss: 2.2172052562236786

Epoch: 5| Step: 8
Training loss: 2.1888339519500732
Validation loss: 2.233536978562673

Epoch: 5| Step: 9
Training loss: 1.0846501588821411
Validation loss: 2.2146220256884894

Epoch: 5| Step: 10
Training loss: 0.9702337980270386
Validation loss: 2.231169064839681

Epoch: 5| Step: 11
Training loss: 1.1129392385482788
Validation loss: 2.3461361775795617

Epoch: 156| Step: 0
Training loss: 0.9611173868179321
Validation loss: 2.2465368062257767

Epoch: 5| Step: 1
Training loss: 0.8361854553222656
Validation loss: 2.252573917309443

Epoch: 5| Step: 2
Training loss: 1.4403376579284668
Validation loss: 2.2227925459543862

Epoch: 5| Step: 3
Training loss: 2.1560213565826416
Validation loss: 2.2469890415668488

Epoch: 5| Step: 4
Training loss: 1.414289951324463
Validation loss: 2.244146833817164

Epoch: 5| Step: 5
Training loss: 1.4806239604949951
Validation loss: 2.2102812081575394

Epoch: 5| Step: 6
Training loss: 0.8870317339897156
Validation loss: 2.2011391719182334

Epoch: 5| Step: 7
Training loss: 1.2880535125732422
Validation loss: 2.2508481244246163

Epoch: 5| Step: 8
Training loss: 1.0904215574264526
Validation loss: 2.277089069286982

Epoch: 5| Step: 9
Training loss: 1.4273900985717773
Validation loss: 2.2914578219254813

Epoch: 5| Step: 10
Training loss: 1.8544809818267822
Validation loss: 2.262603243192037

Epoch: 5| Step: 11
Training loss: 1.217947006225586
Validation loss: 2.305047939221064

Epoch: 157| Step: 0
Training loss: 1.2009735107421875
Validation loss: 2.331112280488014

Epoch: 5| Step: 1
Training loss: 1.5070548057556152
Validation loss: 2.3377412855625153

Epoch: 5| Step: 2
Training loss: 1.1372562646865845
Validation loss: 2.1657124360402427

Epoch: 5| Step: 3
Training loss: 1.4626538753509521
Validation loss: 2.2310326347748437

Epoch: 5| Step: 4
Training loss: 1.089821696281433
Validation loss: 2.2836535274982452

Epoch: 5| Step: 5
Training loss: 1.1740506887435913
Validation loss: 2.1797490268945694

Epoch: 5| Step: 6
Training loss: 1.4411901235580444
Validation loss: 2.2928540110588074

Epoch: 5| Step: 7
Training loss: 1.0233303308486938
Validation loss: 2.2057987501223884

Epoch: 5| Step: 8
Training loss: 1.23416006565094
Validation loss: 2.3129505664110184

Epoch: 5| Step: 9
Training loss: 1.336539387702942
Validation loss: 2.14312706887722

Epoch: 5| Step: 10
Training loss: 1.8853667974472046
Validation loss: 2.2188845773537955

Epoch: 5| Step: 11
Training loss: 1.8744090795516968
Validation loss: 2.2548448592424393

Epoch: 158| Step: 0
Training loss: 0.9471701383590698
Validation loss: 2.2606737365325293

Epoch: 5| Step: 1
Training loss: 1.4165159463882446
Validation loss: 2.207005739212036

Epoch: 5| Step: 2
Training loss: 1.2822805643081665
Validation loss: 2.2850407461325326

Epoch: 5| Step: 3
Training loss: 0.9270491600036621
Validation loss: 2.2819621860980988

Epoch: 5| Step: 4
Training loss: 1.5247132778167725
Validation loss: 2.2864004323879876

Epoch: 5| Step: 5
Training loss: 1.5688862800598145
Validation loss: 2.2539137403170266

Epoch: 5| Step: 6
Training loss: 1.631421446800232
Validation loss: 2.1770308117071786

Epoch: 5| Step: 7
Training loss: 1.6896644830703735
Validation loss: 2.2426624099413552

Epoch: 5| Step: 8
Training loss: 1.2339967489242554
Validation loss: 2.2476916511853537

Epoch: 5| Step: 9
Training loss: 1.1824922561645508
Validation loss: 2.2783846656481423

Epoch: 5| Step: 10
Training loss: 1.143161654472351
Validation loss: 2.2903926422198615

Epoch: 5| Step: 11
Training loss: 0.8727865219116211
Validation loss: 2.2507395297288895

Epoch: 159| Step: 0
Training loss: 1.4062421321868896
Validation loss: 2.1926731914281845

Epoch: 5| Step: 1
Training loss: 1.2713239192962646
Validation loss: 2.1732352574666343

Epoch: 5| Step: 2
Training loss: 1.3466875553131104
Validation loss: 2.1607800871133804

Epoch: 5| Step: 3
Training loss: 1.0993083715438843
Validation loss: 2.2339377949635186

Epoch: 5| Step: 4
Training loss: 1.5801557302474976
Validation loss: 2.24931401014328

Epoch: 5| Step: 5
Training loss: 1.5356253385543823
Validation loss: 2.211972251534462

Epoch: 5| Step: 6
Training loss: 1.7115700244903564
Validation loss: 2.292087346315384

Epoch: 5| Step: 7
Training loss: 1.1709048748016357
Validation loss: 2.2475085804859796

Epoch: 5| Step: 8
Training loss: 1.3956515789031982
Validation loss: 2.1381728996833167

Epoch: 5| Step: 9
Training loss: 0.9101408123970032
Validation loss: 2.281028543909391

Epoch: 5| Step: 10
Training loss: 1.1033390760421753
Validation loss: 2.2303458005189896

Epoch: 5| Step: 11
Training loss: 1.2120797634124756
Validation loss: 2.1875031193097434

Epoch: 160| Step: 0
Training loss: 0.9945327043533325
Validation loss: 2.2085709969202676

Epoch: 5| Step: 1
Training loss: 1.4470765590667725
Validation loss: 2.2625054717063904

Epoch: 5| Step: 2
Training loss: 1.707427978515625
Validation loss: 2.2513747910658517

Epoch: 5| Step: 3
Training loss: 1.5395119190216064
Validation loss: 2.2568809539079666

Epoch: 5| Step: 4
Training loss: 1.4253607988357544
Validation loss: 2.2618357837200165

Epoch: 5| Step: 5
Training loss: 1.1442091464996338
Validation loss: 2.2701290597518287

Epoch: 5| Step: 6
Training loss: 1.1174827814102173
Validation loss: 2.2060197045405707

Epoch: 5| Step: 7
Training loss: 1.7556159496307373
Validation loss: 2.267302672068278

Epoch: 5| Step: 8
Training loss: 1.2874171733856201
Validation loss: 2.294133255879084

Epoch: 5| Step: 9
Training loss: 1.5988644361495972
Validation loss: 2.2512243340412774

Epoch: 5| Step: 10
Training loss: 1.2591111660003662
Validation loss: 2.299387921889623

Epoch: 5| Step: 11
Training loss: 0.7669304609298706
Validation loss: 2.2677591343720755

Epoch: 161| Step: 0
Training loss: 1.1320819854736328
Validation loss: 2.249418472250303

Epoch: 5| Step: 1
Training loss: 0.896429717540741
Validation loss: 2.2299895683924356

Epoch: 5| Step: 2
Training loss: 1.139674186706543
Validation loss: 2.2664708495140076

Epoch: 5| Step: 3
Training loss: 1.025694489479065
Validation loss: 2.2452001174290976

Epoch: 5| Step: 4
Training loss: 1.4771093130111694
Validation loss: 2.2245897551377616

Epoch: 5| Step: 5
Training loss: 1.4145548343658447
Validation loss: 2.2460905462503433

Epoch: 5| Step: 6
Training loss: 0.9300872087478638
Validation loss: 2.2632480363051095

Epoch: 5| Step: 7
Training loss: 1.3378715515136719
Validation loss: 2.2585469583670297

Epoch: 5| Step: 8
Training loss: 1.2490464448928833
Validation loss: 2.231374283631643

Epoch: 5| Step: 9
Training loss: 1.6843334436416626
Validation loss: 2.2292011280854545

Epoch: 5| Step: 10
Training loss: 1.5632765293121338
Validation loss: 2.264266168077787

Epoch: 5| Step: 11
Training loss: 0.2449939250946045
Validation loss: 2.219344357649485

Epoch: 162| Step: 0
Training loss: 1.5624125003814697
Validation loss: 2.2299317369858422

Epoch: 5| Step: 1
Training loss: 1.2976713180541992
Validation loss: 2.255474661787351

Epoch: 5| Step: 2
Training loss: 1.003103256225586
Validation loss: 2.287675768136978

Epoch: 5| Step: 3
Training loss: 0.9754190444946289
Validation loss: 2.2300195743640265

Epoch: 5| Step: 4
Training loss: 1.0230056047439575
Validation loss: 2.1828758815924325

Epoch: 5| Step: 5
Training loss: 1.7043384313583374
Validation loss: 2.19054048260053

Epoch: 5| Step: 6
Training loss: 1.1879912614822388
Validation loss: 2.2194543381532035

Epoch: 5| Step: 7
Training loss: 1.414096474647522
Validation loss: 2.2502970894177756

Epoch: 5| Step: 8
Training loss: 0.7353513240814209
Validation loss: 2.236181060473124

Epoch: 5| Step: 9
Training loss: 1.4523755311965942
Validation loss: 2.2912256916364035

Epoch: 5| Step: 10
Training loss: 1.3984851837158203
Validation loss: 2.2247918943564096

Epoch: 5| Step: 11
Training loss: 1.8476510047912598
Validation loss: 2.238361358642578

Epoch: 163| Step: 0
Training loss: 1.0258022546768188
Validation loss: 2.190430631240209

Epoch: 5| Step: 1
Training loss: 1.366457223892212
Validation loss: 2.251034662127495

Epoch: 5| Step: 2
Training loss: 1.7324012517929077
Validation loss: 2.2262648244698844

Epoch: 5| Step: 3
Training loss: 0.9160642623901367
Validation loss: 2.183570077021917

Epoch: 5| Step: 4
Training loss: 1.5264780521392822
Validation loss: 2.234902799129486

Epoch: 5| Step: 5
Training loss: 1.0627259016036987
Validation loss: 2.21722212433815

Epoch: 5| Step: 6
Training loss: 1.1725744009017944
Validation loss: 2.135784318049749

Epoch: 5| Step: 7
Training loss: 0.9527525901794434
Validation loss: 2.238663002848625

Epoch: 5| Step: 8
Training loss: 1.3977839946746826
Validation loss: 2.279762953519821

Epoch: 5| Step: 9
Training loss: 1.2168400287628174
Validation loss: 2.3126304149627686

Epoch: 5| Step: 10
Training loss: 1.1796855926513672
Validation loss: 2.2069028665622077

Epoch: 5| Step: 11
Training loss: 2.6919193267822266
Validation loss: 2.2813733220100403

Epoch: 164| Step: 0
Training loss: 1.5235376358032227
Validation loss: 2.326025048891703

Epoch: 5| Step: 1
Training loss: 1.2403481006622314
Validation loss: 2.2516077856222787

Epoch: 5| Step: 2
Training loss: 1.3517247438430786
Validation loss: 2.2745163391033807

Epoch: 5| Step: 3
Training loss: 1.5074059963226318
Validation loss: 2.2528138359387717

Epoch: 5| Step: 4
Training loss: 1.341487169265747
Validation loss: 2.2413861056168876

Epoch: 5| Step: 5
Training loss: 1.0135798454284668
Validation loss: 2.2545788983503976

Epoch: 5| Step: 6
Training loss: 1.098971962928772
Validation loss: 2.264896869659424

Epoch: 5| Step: 7
Training loss: 1.0035320520401
Validation loss: 2.2079563538233438

Epoch: 5| Step: 8
Training loss: 1.3111979961395264
Validation loss: 2.2492198745409646

Epoch: 5| Step: 9
Training loss: 1.5874955654144287
Validation loss: 2.2802095909913382

Epoch: 5| Step: 10
Training loss: 1.0953423976898193
Validation loss: 2.2362153281768165

Epoch: 5| Step: 11
Training loss: 1.5869383811950684
Validation loss: 2.293254474798838

Epoch: 165| Step: 0
Training loss: 1.2769882678985596
Validation loss: 2.2250192165374756

Epoch: 5| Step: 1
Training loss: 1.1651427745819092
Validation loss: 2.283641427755356

Epoch: 5| Step: 2
Training loss: 1.3735954761505127
Validation loss: 2.2063862681388855

Epoch: 5| Step: 3
Training loss: 1.332025408744812
Validation loss: 2.243723134199778

Epoch: 5| Step: 4
Training loss: 1.3216031789779663
Validation loss: 2.252854491273562

Epoch: 5| Step: 5
Training loss: 1.08246910572052
Validation loss: 2.193878044684728

Epoch: 5| Step: 6
Training loss: 1.2771637439727783
Validation loss: 2.2517016232013702

Epoch: 5| Step: 7
Training loss: 1.2535426616668701
Validation loss: 2.307083566983541

Epoch: 5| Step: 8
Training loss: 1.3679075241088867
Validation loss: 2.367439632614454

Epoch: 5| Step: 9
Training loss: 1.2116472721099854
Validation loss: 2.3464061617851257

Epoch: 5| Step: 10
Training loss: 1.6349725723266602
Validation loss: 2.303127328554789

Epoch: 5| Step: 11
Training loss: 1.633490800857544
Validation loss: 2.2851030230522156

Epoch: 166| Step: 0
Training loss: 1.368650197982788
Validation loss: 2.314286728700002

Epoch: 5| Step: 1
Training loss: 0.8589151501655579
Validation loss: 2.199765125910441

Epoch: 5| Step: 2
Training loss: 0.7125562429428101
Validation loss: 2.2453793634970984

Epoch: 5| Step: 3
Training loss: 1.1010396480560303
Validation loss: 2.2728196531534195

Epoch: 5| Step: 4
Training loss: 1.3984218835830688
Validation loss: 2.2261915653944016

Epoch: 5| Step: 5
Training loss: 1.1329314708709717
Validation loss: 2.2386661171913147

Epoch: 5| Step: 6
Training loss: 1.2238852977752686
Validation loss: 2.290734201669693

Epoch: 5| Step: 7
Training loss: 1.3964762687683105
Validation loss: 2.24304469426473

Epoch: 5| Step: 8
Training loss: 1.3471978902816772
Validation loss: 2.225395530462265

Epoch: 5| Step: 9
Training loss: 1.3168672323226929
Validation loss: 2.2369552850723267

Epoch: 5| Step: 10
Training loss: 1.554126501083374
Validation loss: 2.2457086592912674

Epoch: 5| Step: 11
Training loss: 1.968625783920288
Validation loss: 2.299731428424517

Epoch: 167| Step: 0
Training loss: 1.2400847673416138
Validation loss: 2.30416110654672

Epoch: 5| Step: 1
Training loss: 1.2208024263381958
Validation loss: 2.3237723857164383

Epoch: 5| Step: 2
Training loss: 1.0836460590362549
Validation loss: 2.3112379213174186

Epoch: 5| Step: 3
Training loss: 0.8105568885803223
Validation loss: 2.2811310638984046

Epoch: 5| Step: 4
Training loss: 1.5611475706100464
Validation loss: 2.2771407663822174

Epoch: 5| Step: 5
Training loss: 1.262774109840393
Validation loss: 2.2211790680885315

Epoch: 5| Step: 6
Training loss: 1.1461365222930908
Validation loss: 2.2365316351254783

Epoch: 5| Step: 7
Training loss: 1.6699260473251343
Validation loss: 2.2498379151026406

Epoch: 5| Step: 8
Training loss: 1.3004268407821655
Validation loss: 2.225915715098381

Epoch: 5| Step: 9
Training loss: 1.7245508432388306
Validation loss: 2.228167394797007

Epoch: 5| Step: 10
Training loss: 1.5006496906280518
Validation loss: 2.2526007195313773

Epoch: 5| Step: 11
Training loss: 1.57210111618042
Validation loss: 2.2916806737581887

Epoch: 168| Step: 0
Training loss: 0.4700877070426941
Validation loss: 2.236069599787394

Epoch: 5| Step: 1
Training loss: 1.555455207824707
Validation loss: 2.2348120510578156

Epoch: 5| Step: 2
Training loss: 1.0752490758895874
Validation loss: 2.293478488922119

Epoch: 5| Step: 3
Training loss: 1.1962807178497314
Validation loss: 2.291235307852427

Epoch: 5| Step: 4
Training loss: 1.0324337482452393
Validation loss: 2.2646769831577935

Epoch: 5| Step: 5
Training loss: 1.7009378671646118
Validation loss: 2.3360161433617272

Epoch: 5| Step: 6
Training loss: 1.1677461862564087
Validation loss: 2.3327601651350656

Epoch: 5| Step: 7
Training loss: 1.5325506925582886
Validation loss: 2.288922722140948

Epoch: 5| Step: 8
Training loss: 1.310105323791504
Validation loss: 2.211194316546122

Epoch: 5| Step: 9
Training loss: 1.3334095478057861
Validation loss: 2.2384114464124045

Epoch: 5| Step: 10
Training loss: 1.132775068283081
Validation loss: 2.2368100831906

Epoch: 5| Step: 11
Training loss: 1.1568273305892944
Validation loss: 2.2530451118946075

Epoch: 169| Step: 0
Training loss: 1.2093522548675537
Validation loss: 2.3268691301345825

Epoch: 5| Step: 1
Training loss: 1.1422103643417358
Validation loss: 2.300000568230947

Epoch: 5| Step: 2
Training loss: 1.638837456703186
Validation loss: 2.348147834340731

Epoch: 5| Step: 3
Training loss: 1.2610719203948975
Validation loss: 2.354619195063909

Epoch: 5| Step: 4
Training loss: 1.757002592086792
Validation loss: 2.304491549730301

Epoch: 5| Step: 5
Training loss: 1.3604648113250732
Validation loss: 2.2462544987599053

Epoch: 5| Step: 6
Training loss: 1.3621437549591064
Validation loss: 2.2782949805259705

Epoch: 5| Step: 7
Training loss: 1.2457621097564697
Validation loss: 2.2909191151460013

Epoch: 5| Step: 8
Training loss: 0.9861442446708679
Validation loss: 2.2703219751516976

Epoch: 5| Step: 9
Training loss: 1.0618880987167358
Validation loss: 2.258193631966909

Epoch: 5| Step: 10
Training loss: 0.883729100227356
Validation loss: 2.2980360239744186

Epoch: 5| Step: 11
Training loss: 1.8477944135665894
Validation loss: 2.3297848055760064

Epoch: 170| Step: 0
Training loss: 1.6291682720184326
Validation loss: 2.2712909082571664

Epoch: 5| Step: 1
Training loss: 1.0704537630081177
Validation loss: 2.2781535983085632

Epoch: 5| Step: 2
Training loss: 0.9275960922241211
Validation loss: 2.2414652605851493

Epoch: 5| Step: 3
Training loss: 0.8677130937576294
Validation loss: 2.2657301972309747

Epoch: 5| Step: 4
Training loss: 1.1411378383636475
Validation loss: 2.250553846359253

Epoch: 5| Step: 5
Training loss: 1.0508854389190674
Validation loss: 2.2803062895933786

Epoch: 5| Step: 6
Training loss: 0.9099532961845398
Validation loss: 2.2367699493964515

Epoch: 5| Step: 7
Training loss: 1.3352406024932861
Validation loss: 2.2133122235536575

Epoch: 5| Step: 8
Training loss: 1.1559007167816162
Validation loss: 2.2527661522229514

Epoch: 5| Step: 9
Training loss: 1.674971342086792
Validation loss: 2.1707956939935684

Epoch: 5| Step: 10
Training loss: 1.5251652002334595
Validation loss: 2.2386318147182465

Epoch: 5| Step: 11
Training loss: 0.7069776058197021
Validation loss: 2.28325683871905

Epoch: 171| Step: 0
Training loss: 0.9132627248764038
Validation loss: 2.306427319844564

Epoch: 5| Step: 1
Training loss: 1.4384331703186035
Validation loss: 2.303091456492742

Epoch: 5| Step: 2
Training loss: 0.7938125729560852
Validation loss: 2.2732074658075967

Epoch: 5| Step: 3
Training loss: 1.3348747491836548
Validation loss: 2.2750116884708405

Epoch: 5| Step: 4
Training loss: 1.1800183057785034
Validation loss: 2.2514216204484305

Epoch: 5| Step: 5
Training loss: 1.8551661968231201
Validation loss: 2.305002599954605

Epoch: 5| Step: 6
Training loss: 0.935345470905304
Validation loss: 2.2480168690284095

Epoch: 5| Step: 7
Training loss: 0.9180895090103149
Validation loss: 2.2782354851563773

Epoch: 5| Step: 8
Training loss: 1.164851188659668
Validation loss: 2.266991227865219

Epoch: 5| Step: 9
Training loss: 1.0815513134002686
Validation loss: 2.20284196237723

Epoch: 5| Step: 10
Training loss: 1.3976314067840576
Validation loss: 2.199463834365209

Epoch: 5| Step: 11
Training loss: 0.6845887899398804
Validation loss: 2.303954948981603

Epoch: 172| Step: 0
Training loss: 1.373056411743164
Validation loss: 2.313857222596804

Epoch: 5| Step: 1
Training loss: 1.055596947669983
Validation loss: 2.2556045850118003

Epoch: 5| Step: 2
Training loss: 1.180276870727539
Validation loss: 2.263012225429217

Epoch: 5| Step: 3
Training loss: 1.337134599685669
Validation loss: 2.2731333573659263

Epoch: 5| Step: 4
Training loss: 1.4235981702804565
Validation loss: 2.248856176932653

Epoch: 5| Step: 5
Training loss: 0.8723534345626831
Validation loss: 2.257380316654841

Epoch: 5| Step: 6
Training loss: 1.1962658166885376
Validation loss: 2.2073180973529816

Epoch: 5| Step: 7
Training loss: 0.9670674204826355
Validation loss: 2.2141651759545007

Epoch: 5| Step: 8
Training loss: 1.4545115232467651
Validation loss: 2.306626151005427

Epoch: 5| Step: 9
Training loss: 0.9382730722427368
Validation loss: 2.2442646821339927

Epoch: 5| Step: 10
Training loss: 1.0015368461608887
Validation loss: 2.337829182545344

Epoch: 5| Step: 11
Training loss: 0.6280642747879028
Validation loss: 2.2905150006214776

Epoch: 173| Step: 0
Training loss: 1.0301716327667236
Validation loss: 2.2767139176527658

Epoch: 5| Step: 1
Training loss: 1.088254451751709
Validation loss: 2.2612157464027405

Epoch: 5| Step: 2
Training loss: 1.6683006286621094
Validation loss: 2.235706642270088

Epoch: 5| Step: 3
Training loss: 1.1882902383804321
Validation loss: 2.2452523012955985

Epoch: 5| Step: 4
Training loss: 0.7216771245002747
Validation loss: 2.3024747371673584

Epoch: 5| Step: 5
Training loss: 1.1419918537139893
Validation loss: 2.255556652943293

Epoch: 5| Step: 6
Training loss: 0.9477578997612
Validation loss: 2.283862516283989

Epoch: 5| Step: 7
Training loss: 1.8140347003936768
Validation loss: 2.166771426796913

Epoch: 5| Step: 8
Training loss: 1.153136968612671
Validation loss: 2.267715245485306

Epoch: 5| Step: 9
Training loss: 1.3085182905197144
Validation loss: 2.2711719423532486

Epoch: 5| Step: 10
Training loss: 0.882239818572998
Validation loss: 2.277665058771769

Epoch: 5| Step: 11
Training loss: 0.3269813060760498
Validation loss: 2.2582858502864838

Epoch: 174| Step: 0
Training loss: 1.5911061763763428
Validation loss: 2.2249492605527244

Epoch: 5| Step: 1
Training loss: 1.0041849613189697
Validation loss: 2.315449148416519

Epoch: 5| Step: 2
Training loss: 1.298417329788208
Validation loss: 2.237479120492935

Epoch: 5| Step: 3
Training loss: 1.3616316318511963
Validation loss: 2.2234541326761246

Epoch: 5| Step: 4
Training loss: 1.7986624240875244
Validation loss: 2.233580708503723

Epoch: 5| Step: 5
Training loss: 1.0418720245361328
Validation loss: 2.233540415763855

Epoch: 5| Step: 6
Training loss: 1.1340264081954956
Validation loss: 2.2464823772509894

Epoch: 5| Step: 7
Training loss: 1.1987535953521729
Validation loss: 2.2682248105605445

Epoch: 5| Step: 8
Training loss: 0.791122317314148
Validation loss: 2.2373065451780954

Epoch: 5| Step: 9
Training loss: 0.9913662672042847
Validation loss: 2.2523579597473145

Epoch: 5| Step: 10
Training loss: 0.8022306561470032
Validation loss: 2.304741377631823

Epoch: 5| Step: 11
Training loss: 0.22605609893798828
Validation loss: 2.2670140862464905

Epoch: 175| Step: 0
Training loss: 0.5401862859725952
Validation loss: 2.266872301697731

Epoch: 5| Step: 1
Training loss: 1.3358573913574219
Validation loss: 2.2794106702009835

Epoch: 5| Step: 2
Training loss: 1.4222915172576904
Validation loss: 2.2843059400717416

Epoch: 5| Step: 3
Training loss: 0.9474369287490845
Validation loss: 2.2762631326913834

Epoch: 5| Step: 4
Training loss: 1.175512671470642
Validation loss: 2.249328245719274

Epoch: 5| Step: 5
Training loss: 1.2039260864257812
Validation loss: 2.277410219113032

Epoch: 5| Step: 6
Training loss: 0.9277693033218384
Validation loss: 2.274531771739324

Epoch: 5| Step: 7
Training loss: 1.3118220567703247
Validation loss: 2.2483897904555

Epoch: 5| Step: 8
Training loss: 1.4981943368911743
Validation loss: 2.2945687820514045

Epoch: 5| Step: 9
Training loss: 1.281951665878296
Validation loss: 2.3810820976893106

Epoch: 5| Step: 10
Training loss: 0.9333418011665344
Validation loss: 2.270873044927915

Epoch: 5| Step: 11
Training loss: 2.496518850326538
Validation loss: 2.2624478191137314

Epoch: 176| Step: 0
Training loss: 1.15909743309021
Validation loss: 2.279086410999298

Epoch: 5| Step: 1
Training loss: 0.8603008389472961
Validation loss: 2.2622555096944175

Epoch: 5| Step: 2
Training loss: 0.7991013526916504
Validation loss: 2.2180023789405823

Epoch: 5| Step: 3
Training loss: 1.1338104009628296
Validation loss: 2.2238584806521735

Epoch: 5| Step: 4
Training loss: 1.3913135528564453
Validation loss: 2.287635584672292

Epoch: 5| Step: 5
Training loss: 1.3732500076293945
Validation loss: 2.2559082210063934

Epoch: 5| Step: 6
Training loss: 0.7841543555259705
Validation loss: 2.3132358491420746

Epoch: 5| Step: 7
Training loss: 1.3258488178253174
Validation loss: 2.3374800980091095

Epoch: 5| Step: 8
Training loss: 0.9313129186630249
Validation loss: 2.2550996392965317

Epoch: 5| Step: 9
Training loss: 0.9958686828613281
Validation loss: 2.3111595759789147

Epoch: 5| Step: 10
Training loss: 1.3124055862426758
Validation loss: 2.268889213601748

Epoch: 5| Step: 11
Training loss: 1.040649175643921
Validation loss: 2.256244813402494

Epoch: 177| Step: 0
Training loss: 1.0484182834625244
Validation loss: 2.2234756449858346

Epoch: 5| Step: 1
Training loss: 1.1467106342315674
Validation loss: 2.298965483903885

Epoch: 5| Step: 2
Training loss: 0.763841986656189
Validation loss: 2.2753445903460183

Epoch: 5| Step: 3
Training loss: 1.110843539237976
Validation loss: 2.2986329247554145

Epoch: 5| Step: 4
Training loss: 1.5378491878509521
Validation loss: 2.275003358721733

Epoch: 5| Step: 5
Training loss: 1.5379784107208252
Validation loss: 2.314082165559133

Epoch: 5| Step: 6
Training loss: 1.1810942888259888
Validation loss: 2.3053316871325173

Epoch: 5| Step: 7
Training loss: 1.0377362966537476
Validation loss: 2.228861684600512

Epoch: 5| Step: 8
Training loss: 0.8378422856330872
Validation loss: 2.302255521217982

Epoch: 5| Step: 9
Training loss: 1.4406230449676514
Validation loss: 2.2843095511198044

Epoch: 5| Step: 10
Training loss: 1.1892375946044922
Validation loss: 2.224810148278872

Epoch: 5| Step: 11
Training loss: 1.2718665599822998
Validation loss: 2.2996961077054343

Epoch: 178| Step: 0
Training loss: 0.9668301343917847
Validation loss: 2.198004573583603

Epoch: 5| Step: 1
Training loss: 1.3338230848312378
Validation loss: 2.2126988023519516

Epoch: 5| Step: 2
Training loss: 1.2875083684921265
Validation loss: 2.2455254147450128

Epoch: 5| Step: 3
Training loss: 0.9898920059204102
Validation loss: 2.347735861937205

Epoch: 5| Step: 4
Training loss: 1.0783997774124146
Validation loss: 2.3625272661447525

Epoch: 5| Step: 5
Training loss: 0.9189044833183289
Validation loss: 2.338626484076182

Epoch: 5| Step: 6
Training loss: 1.1184138059616089
Validation loss: 2.2945585002501807

Epoch: 5| Step: 7
Training loss: 1.2320549488067627
Validation loss: 2.2925021251042685

Epoch: 5| Step: 8
Training loss: 1.2742151021957397
Validation loss: 2.2172049482663474

Epoch: 5| Step: 9
Training loss: 1.3507144451141357
Validation loss: 2.2136115233103433

Epoch: 5| Step: 10
Training loss: 1.0768733024597168
Validation loss: 2.2491373121738434

Epoch: 5| Step: 11
Training loss: 1.5486348867416382
Validation loss: 2.243296047051748

Epoch: 179| Step: 0
Training loss: 1.5877234935760498
Validation loss: 2.1974870463212333

Epoch: 5| Step: 1
Training loss: 1.1449859142303467
Validation loss: 2.294947385787964

Epoch: 5| Step: 2
Training loss: 1.4210221767425537
Validation loss: 2.2195499738057456

Epoch: 5| Step: 3
Training loss: 0.7877131700515747
Validation loss: 2.236999293168386

Epoch: 5| Step: 4
Training loss: 1.2773598432540894
Validation loss: 2.256909966468811

Epoch: 5| Step: 5
Training loss: 1.3472708463668823
Validation loss: 2.2705949594577155

Epoch: 5| Step: 6
Training loss: 0.9984732866287231
Validation loss: 2.2691814800103507

Epoch: 5| Step: 7
Training loss: 1.1363624334335327
Validation loss: 2.2486265897750854

Epoch: 5| Step: 8
Training loss: 0.9142831563949585
Validation loss: 2.3106143871943154

Epoch: 5| Step: 9
Training loss: 1.2344447374343872
Validation loss: 2.1567844102780023

Epoch: 5| Step: 10
Training loss: 0.9985755681991577
Validation loss: 2.2643768191337585

Epoch: 5| Step: 11
Training loss: 0.46453040838241577
Validation loss: 2.2760426153739295

Epoch: 180| Step: 0
Training loss: 1.5199241638183594
Validation loss: 2.2421805461247764

Epoch: 5| Step: 1
Training loss: 1.0423468351364136
Validation loss: 2.310182665785154

Epoch: 5| Step: 2
Training loss: 0.8476970791816711
Validation loss: 2.237073560555776

Epoch: 5| Step: 3
Training loss: 0.7186452150344849
Validation loss: 2.2507170538107553

Epoch: 5| Step: 4
Training loss: 1.4185307025909424
Validation loss: 2.2477300663789115

Epoch: 5| Step: 5
Training loss: 1.1666868925094604
Validation loss: 2.305755843718847

Epoch: 5| Step: 6
Training loss: 0.9161384701728821
Validation loss: 2.293529212474823

Epoch: 5| Step: 7
Training loss: 1.1795361042022705
Validation loss: 2.31035382548968

Epoch: 5| Step: 8
Training loss: 1.071989893913269
Validation loss: 2.352314750353495

Epoch: 5| Step: 9
Training loss: 1.3202940225601196
Validation loss: 2.298591415087382

Epoch: 5| Step: 10
Training loss: 1.1043756008148193
Validation loss: 2.2810732622941337

Epoch: 5| Step: 11
Training loss: 0.9695029258728027
Validation loss: 2.2906899452209473

Epoch: 181| Step: 0
Training loss: 1.239786982536316
Validation loss: 2.2249808311462402

Epoch: 5| Step: 1
Training loss: 0.9533646702766418
Validation loss: 2.3206565380096436

Epoch: 5| Step: 2
Training loss: 0.7813056111335754
Validation loss: 2.2871910631656647

Epoch: 5| Step: 3
Training loss: 1.1797832250595093
Validation loss: 2.3121352791786194

Epoch: 5| Step: 4
Training loss: 1.5009998083114624
Validation loss: 2.2847864081462226

Epoch: 5| Step: 5
Training loss: 1.0959064960479736
Validation loss: 2.2208700478076935

Epoch: 5| Step: 6
Training loss: 0.8982784152030945
Validation loss: 2.244385908047358

Epoch: 5| Step: 7
Training loss: 0.8626288175582886
Validation loss: 2.1483532985051474

Epoch: 5| Step: 8
Training loss: 1.001433253288269
Validation loss: 2.277636547883352

Epoch: 5| Step: 9
Training loss: 1.2555301189422607
Validation loss: 2.3108367224534354

Epoch: 5| Step: 10
Training loss: 0.8162049055099487
Validation loss: 2.2880873680114746

Epoch: 5| Step: 11
Training loss: 2.106046199798584
Validation loss: 2.282814155022303

Epoch: 182| Step: 0
Training loss: 1.518902063369751
Validation loss: 2.2509800841410956

Epoch: 5| Step: 1
Training loss: 1.3501670360565186
Validation loss: 2.3127811700105667

Epoch: 5| Step: 2
Training loss: 1.3370625972747803
Validation loss: 2.3099888414144516

Epoch: 5| Step: 3
Training loss: 1.3139894008636475
Validation loss: 2.295369108517965

Epoch: 5| Step: 4
Training loss: 0.8213451504707336
Validation loss: 2.237237031261126

Epoch: 5| Step: 5
Training loss: 0.6859376430511475
Validation loss: 2.2979191641012826

Epoch: 5| Step: 6
Training loss: 1.162989854812622
Validation loss: 2.2542082965373993

Epoch: 5| Step: 7
Training loss: 0.9993500709533691
Validation loss: 2.302574783563614

Epoch: 5| Step: 8
Training loss: 0.7766279578208923
Validation loss: 2.2385588685671487

Epoch: 5| Step: 9
Training loss: 1.2023857831954956
Validation loss: 2.240725258986155

Epoch: 5| Step: 10
Training loss: 0.8080986142158508
Validation loss: 2.352430750926336

Epoch: 5| Step: 11
Training loss: 0.4974323511123657
Validation loss: 2.292300055424372

Epoch: 183| Step: 0
Training loss: 0.6904115676879883
Validation loss: 2.3073756645123162

Epoch: 5| Step: 1
Training loss: 0.6784070134162903
Validation loss: 2.2923667182525

Epoch: 5| Step: 2
Training loss: 1.1487278938293457
Validation loss: 2.229969928661982

Epoch: 5| Step: 3
Training loss: 0.8757686614990234
Validation loss: 2.292007843653361

Epoch: 5| Step: 4
Training loss: 1.7668492794036865
Validation loss: 2.3122512002786

Epoch: 5| Step: 5
Training loss: 1.1004678010940552
Validation loss: 2.2431976248820624

Epoch: 5| Step: 6
Training loss: 1.0096027851104736
Validation loss: 2.251529728372892

Epoch: 5| Step: 7
Training loss: 0.740826427936554
Validation loss: 2.2893610845009484

Epoch: 5| Step: 8
Training loss: 1.5862798690795898
Validation loss: 2.2605238258838654

Epoch: 5| Step: 9
Training loss: 1.5925571918487549
Validation loss: 2.353729099035263

Epoch: 5| Step: 10
Training loss: 1.333996057510376
Validation loss: 2.3410309155782065

Epoch: 5| Step: 11
Training loss: 0.7178255319595337
Validation loss: 2.323823243379593

Epoch: 184| Step: 0
Training loss: 1.1593903303146362
Validation loss: 2.3340983390808105

Epoch: 5| Step: 1
Training loss: 0.8526086807250977
Validation loss: 2.29747474193573

Epoch: 5| Step: 2
Training loss: 1.1166397333145142
Validation loss: 2.264204680919647

Epoch: 5| Step: 3
Training loss: 0.7580513954162598
Validation loss: 2.259620095292727

Epoch: 5| Step: 4
Training loss: 1.0300064086914062
Validation loss: 2.337195207675298

Epoch: 5| Step: 5
Training loss: 1.2316662073135376
Validation loss: 2.289983237783114

Epoch: 5| Step: 6
Training loss: 1.2481977939605713
Validation loss: 2.264329378803571

Epoch: 5| Step: 7
Training loss: 1.4985477924346924
Validation loss: 2.305303474267324

Epoch: 5| Step: 8
Training loss: 1.4088413715362549
Validation loss: 2.2731248140335083

Epoch: 5| Step: 9
Training loss: 1.3248708248138428
Validation loss: 2.290564308563868

Epoch: 5| Step: 10
Training loss: 0.7352678179740906
Validation loss: 2.2899077037970224

Epoch: 5| Step: 11
Training loss: 0.6747444868087769
Validation loss: 2.296195556720098

Epoch: 185| Step: 0
Training loss: 1.2283762693405151
Validation loss: 2.2620983322461448

Epoch: 5| Step: 1
Training loss: 1.2583212852478027
Validation loss: 2.344773809115092

Epoch: 5| Step: 2
Training loss: 1.1531965732574463
Validation loss: 2.2743201752503714

Epoch: 5| Step: 3
Training loss: 1.4361603260040283
Validation loss: 2.3979689379533133

Epoch: 5| Step: 4
Training loss: 0.7924116253852844
Validation loss: 2.262206902106603

Epoch: 5| Step: 5
Training loss: 0.9214269518852234
Validation loss: 2.2837849905093512

Epoch: 5| Step: 6
Training loss: 1.1092238426208496
Validation loss: 2.2761689176162085

Epoch: 5| Step: 7
Training loss: 1.0917730331420898
Validation loss: 2.252422725160917

Epoch: 5| Step: 8
Training loss: 1.0632518529891968
Validation loss: 2.3308412035306296

Epoch: 5| Step: 9
Training loss: 1.4547055959701538
Validation loss: 2.2752214471499124

Epoch: 5| Step: 10
Training loss: 0.9800812005996704
Validation loss: 2.342145929733912

Epoch: 5| Step: 11
Training loss: 1.143876075744629
Validation loss: 2.282084420323372

Epoch: 186| Step: 0
Training loss: 1.5441924333572388
Validation loss: 2.2608549992243447

Epoch: 5| Step: 1
Training loss: 1.007093906402588
Validation loss: 2.263982648650805

Epoch: 5| Step: 2
Training loss: 0.6286100149154663
Validation loss: 2.3134094129006066

Epoch: 5| Step: 3
Training loss: 0.8472222089767456
Validation loss: 2.2613059232632318

Epoch: 5| Step: 4
Training loss: 1.2334860563278198
Validation loss: 2.1795033713181815

Epoch: 5| Step: 5
Training loss: 1.1766798496246338
Validation loss: 2.3086299002170563

Epoch: 5| Step: 6
Training loss: 1.1351866722106934
Validation loss: 2.385259677966436

Epoch: 5| Step: 7
Training loss: 0.9537321329116821
Validation loss: 2.2799497842788696

Epoch: 5| Step: 8
Training loss: 1.243124008178711
Validation loss: 2.2385714650154114

Epoch: 5| Step: 9
Training loss: 1.0680805444717407
Validation loss: 2.282758896549543

Epoch: 5| Step: 10
Training loss: 1.2514278888702393
Validation loss: 2.302906890710195

Epoch: 5| Step: 11
Training loss: 1.0446407794952393
Validation loss: 2.2303761889537177

Epoch: 187| Step: 0
Training loss: 0.989151120185852
Validation loss: 2.289942592382431

Epoch: 5| Step: 1
Training loss: 0.9492796659469604
Validation loss: 2.267739027738571

Epoch: 5| Step: 2
Training loss: 1.5450512170791626
Validation loss: 2.302956610918045

Epoch: 5| Step: 3
Training loss: 1.1915372610092163
Validation loss: 2.229039947191874

Epoch: 5| Step: 4
Training loss: 1.1760365962982178
Validation loss: 2.348165770371755

Epoch: 5| Step: 5
Training loss: 0.9550715684890747
Validation loss: 2.2540521174669266

Epoch: 5| Step: 6
Training loss: 0.9069687128067017
Validation loss: 2.2582577069600425

Epoch: 5| Step: 7
Training loss: 0.7686764001846313
Validation loss: 2.3512357572714486

Epoch: 5| Step: 8
Training loss: 0.8969273567199707
Validation loss: 2.275141179561615

Epoch: 5| Step: 9
Training loss: 0.9500614404678345
Validation loss: 2.3119764824708304

Epoch: 5| Step: 10
Training loss: 1.3259750604629517
Validation loss: 2.303737928469976

Epoch: 5| Step: 11
Training loss: 0.5440841913223267
Validation loss: 2.343647470076879

Epoch: 188| Step: 0
Training loss: 1.5342774391174316
Validation loss: 2.272164190808932

Epoch: 5| Step: 1
Training loss: 1.3175461292266846
Validation loss: 2.3124832014242807

Epoch: 5| Step: 2
Training loss: 1.3536696434020996
Validation loss: 2.2233079075813293

Epoch: 5| Step: 3
Training loss: 1.3972727060317993
Validation loss: 2.300786962111791

Epoch: 5| Step: 4
Training loss: 0.916327178478241
Validation loss: 2.3037752558787665

Epoch: 5| Step: 5
Training loss: 1.3596402406692505
Validation loss: 2.2555909603834152

Epoch: 5| Step: 6
Training loss: 0.6901849508285522
Validation loss: 2.2935426433881125

Epoch: 5| Step: 7
Training loss: 0.8173822164535522
Validation loss: 2.271691143512726

Epoch: 5| Step: 8
Training loss: 1.0694172382354736
Validation loss: 2.2935214837392173

Epoch: 5| Step: 9
Training loss: 1.093374490737915
Validation loss: 2.2321038991212845

Epoch: 5| Step: 10
Training loss: 0.8871533274650574
Validation loss: 2.3088968048493066

Epoch: 5| Step: 11
Training loss: 0.5341691374778748
Validation loss: 2.290918067097664

Epoch: 189| Step: 0
Training loss: 0.7482331991195679
Validation loss: 2.253179222345352

Epoch: 5| Step: 1
Training loss: 0.9014908075332642
Validation loss: 2.27606338262558

Epoch: 5| Step: 2
Training loss: 1.083073616027832
Validation loss: 2.29299462834994

Epoch: 5| Step: 3
Training loss: 1.2216259241104126
Validation loss: 2.2381520370642343

Epoch: 5| Step: 4
Training loss: 1.4195083379745483
Validation loss: 2.252875337998072

Epoch: 5| Step: 5
Training loss: 0.9771445393562317
Validation loss: 2.243314892053604

Epoch: 5| Step: 6
Training loss: 1.177869200706482
Validation loss: 2.25184058646361

Epoch: 5| Step: 7
Training loss: 0.846588134765625
Validation loss: 2.2854006588459015

Epoch: 5| Step: 8
Training loss: 1.1524784564971924
Validation loss: 2.288413713375727

Epoch: 5| Step: 9
Training loss: 1.2238032817840576
Validation loss: 2.2841617663701377

Epoch: 5| Step: 10
Training loss: 1.0280427932739258
Validation loss: 2.260823592543602

Epoch: 5| Step: 11
Training loss: 0.5513352155685425
Validation loss: 2.2066000004609427

Epoch: 190| Step: 0
Training loss: 1.084815263748169
Validation loss: 2.32696096599102

Epoch: 5| Step: 1
Training loss: 0.779137909412384
Validation loss: 2.200666402777036

Epoch: 5| Step: 2
Training loss: 1.219040870666504
Validation loss: 2.26142618060112

Epoch: 5| Step: 3
Training loss: 0.9458605051040649
Validation loss: 2.299430380264918

Epoch: 5| Step: 4
Training loss: 1.195024013519287
Validation loss: 2.2521413465340934

Epoch: 5| Step: 5
Training loss: 0.6309477686882019
Validation loss: 2.284747620423635

Epoch: 5| Step: 6
Training loss: 1.052108883857727
Validation loss: 2.3094802796840668

Epoch: 5| Step: 7
Training loss: 1.8263728618621826
Validation loss: 2.2476893812417984

Epoch: 5| Step: 8
Training loss: 0.9143451452255249
Validation loss: 2.215441048145294

Epoch: 5| Step: 9
Training loss: 0.871976375579834
Validation loss: 2.2883455802996955

Epoch: 5| Step: 10
Training loss: 1.1212981939315796
Validation loss: 2.2916905085245767

Epoch: 5| Step: 11
Training loss: 0.8994344472885132
Validation loss: 2.248283416032791

Epoch: 191| Step: 0
Training loss: 1.0463478565216064
Validation loss: 2.2624027530352273

Epoch: 5| Step: 1
Training loss: 1.1834404468536377
Validation loss: 2.227156867583593

Epoch: 5| Step: 2
Training loss: 1.267957091331482
Validation loss: 2.265657916665077

Epoch: 5| Step: 3
Training loss: 1.623723030090332
Validation loss: 2.279568533102671

Epoch: 5| Step: 4
Training loss: 0.8384601473808289
Validation loss: 2.257859562834104

Epoch: 5| Step: 5
Training loss: 1.0245651006698608
Validation loss: 2.2366573015848794

Epoch: 5| Step: 6
Training loss: 0.622986912727356
Validation loss: 2.289890547593435

Epoch: 5| Step: 7
Training loss: 0.9554119110107422
Validation loss: 2.329794039328893

Epoch: 5| Step: 8
Training loss: 0.7705942988395691
Validation loss: 2.305683155854543

Epoch: 5| Step: 9
Training loss: 1.1479198932647705
Validation loss: 2.24754590789477

Epoch: 5| Step: 10
Training loss: 1.0067330598831177
Validation loss: 2.2945160965124765

Epoch: 5| Step: 11
Training loss: 0.5091635584831238
Validation loss: 2.2622945408026376

Epoch: 192| Step: 0
Training loss: 0.9496387243270874
Validation loss: 2.3131609161694846

Epoch: 5| Step: 1
Training loss: 1.56145179271698
Validation loss: 2.2707306494315467

Epoch: 5| Step: 2
Training loss: 0.8464491963386536
Validation loss: 2.2648799320062003

Epoch: 5| Step: 3
Training loss: 0.8025099039077759
Validation loss: 2.3176803439855576

Epoch: 5| Step: 4
Training loss: 0.9636308550834656
Validation loss: 2.270321786403656

Epoch: 5| Step: 5
Training loss: 0.9237529635429382
Validation loss: 2.3129188418388367

Epoch: 5| Step: 6
Training loss: 1.3184316158294678
Validation loss: 2.3268413643042245

Epoch: 5| Step: 7
Training loss: 1.1689947843551636
Validation loss: 2.2408719062805176

Epoch: 5| Step: 8
Training loss: 0.5529584884643555
Validation loss: 2.2195521543423333

Epoch: 5| Step: 9
Training loss: 1.130294919013977
Validation loss: 2.318072294195493

Epoch: 5| Step: 10
Training loss: 1.0780171155929565
Validation loss: 2.269584576288859

Epoch: 5| Step: 11
Training loss: 0.8799991011619568
Validation loss: 2.3041588068008423

Epoch: 193| Step: 0
Training loss: 1.2376257181167603
Validation loss: 2.233919749657313

Epoch: 5| Step: 1
Training loss: 0.6084362864494324
Validation loss: 2.2998646398385367

Epoch: 5| Step: 2
Training loss: 0.9742253422737122
Validation loss: 2.259519562125206

Epoch: 5| Step: 3
Training loss: 1.2259635925292969
Validation loss: 2.3019296328226724

Epoch: 5| Step: 4
Training loss: 1.1203144788742065
Validation loss: 2.283695941170057

Epoch: 5| Step: 5
Training loss: 0.5944510698318481
Validation loss: 2.3190229634443917

Epoch: 5| Step: 6
Training loss: 1.2277076244354248
Validation loss: 2.274819642305374

Epoch: 5| Step: 7
Training loss: 0.8877565264701843
Validation loss: 2.2714263101418815

Epoch: 5| Step: 8
Training loss: 1.400022268295288
Validation loss: 2.31014014283816

Epoch: 5| Step: 9
Training loss: 1.167415738105774
Validation loss: 2.2486701707045236

Epoch: 5| Step: 10
Training loss: 1.1424381732940674
Validation loss: 2.292269359032313

Epoch: 5| Step: 11
Training loss: 0.7010770440101624
Validation loss: 2.257525900999705

Epoch: 194| Step: 0
Training loss: 0.7919275164604187
Validation loss: 2.281914899746577

Epoch: 5| Step: 1
Training loss: 1.084202766418457
Validation loss: 2.2317895839611688

Epoch: 5| Step: 2
Training loss: 0.7020573019981384
Validation loss: 2.29390079776446

Epoch: 5| Step: 3
Training loss: 0.7545924186706543
Validation loss: 2.24890128771464

Epoch: 5| Step: 4
Training loss: 0.9148766398429871
Validation loss: 2.311034952600797

Epoch: 5| Step: 5
Training loss: 0.7823055982589722
Validation loss: 2.2542576690514884

Epoch: 5| Step: 6
Training loss: 1.2399752140045166
Validation loss: 2.2232862263917923

Epoch: 5| Step: 7
Training loss: 1.2148696184158325
Validation loss: 2.304421693086624

Epoch: 5| Step: 8
Training loss: 0.7628399729728699
Validation loss: 2.252132127682368

Epoch: 5| Step: 9
Training loss: 1.7110191583633423
Validation loss: 2.243245189388593

Epoch: 5| Step: 10
Training loss: 1.4625093936920166
Validation loss: 2.261159509420395

Epoch: 5| Step: 11
Training loss: 1.0341359376907349
Validation loss: 2.24696813027064

Epoch: 195| Step: 0
Training loss: 1.2325222492218018
Validation loss: 2.20915217200915

Epoch: 5| Step: 1
Training loss: 1.0685701370239258
Validation loss: 2.189747209350268

Epoch: 5| Step: 2
Training loss: 1.0020723342895508
Validation loss: 2.2880277136961618

Epoch: 5| Step: 3
Training loss: 0.9869953393936157
Validation loss: 2.2575495342413583

Epoch: 5| Step: 4
Training loss: 0.721473217010498
Validation loss: 2.2709019432465234

Epoch: 5| Step: 5
Training loss: 1.167101502418518
Validation loss: 2.2646298110485077

Epoch: 5| Step: 6
Training loss: 1.2189314365386963
Validation loss: 2.2857755223910012

Epoch: 5| Step: 7
Training loss: 1.2212769985198975
Validation loss: 2.2956053713957467

Epoch: 5| Step: 8
Training loss: 0.7668237090110779
Validation loss: 2.272801175713539

Epoch: 5| Step: 9
Training loss: 1.4080320596694946
Validation loss: 2.2456000645955405

Epoch: 5| Step: 10
Training loss: 0.9172951579093933
Validation loss: 2.2645256320635476

Epoch: 5| Step: 11
Training loss: 0.36370527744293213
Validation loss: 2.3110753248135247

Epoch: 196| Step: 0
Training loss: 0.9320969581604004
Validation loss: 2.30028789738814

Epoch: 5| Step: 1
Training loss: 0.9710761904716492
Validation loss: 2.2687276701132455

Epoch: 5| Step: 2
Training loss: 1.0540968179702759
Validation loss: 2.269168088833491

Epoch: 5| Step: 3
Training loss: 1.164299488067627
Validation loss: 2.286859114964803

Epoch: 5| Step: 4
Training loss: 1.1540729999542236
Validation loss: 2.2860532899697623

Epoch: 5| Step: 5
Training loss: 1.0711264610290527
Validation loss: 2.285815253853798

Epoch: 5| Step: 6
Training loss: 0.7634642720222473
Validation loss: 2.2707699139912925

Epoch: 5| Step: 7
Training loss: 1.3840641975402832
Validation loss: 2.2900911569595337

Epoch: 5| Step: 8
Training loss: 0.7537056803703308
Validation loss: 2.270055909951528

Epoch: 5| Step: 9
Training loss: 1.3782565593719482
Validation loss: 2.311109339197477

Epoch: 5| Step: 10
Training loss: 0.8904308080673218
Validation loss: 2.2801105976104736

Epoch: 5| Step: 11
Training loss: 0.3438413143157959
Validation loss: 2.261348600188891

Epoch: 197| Step: 0
Training loss: 1.2503639459609985
Validation loss: 2.2981593211491904

Epoch: 5| Step: 1
Training loss: 0.6336373090744019
Validation loss: 2.2653672099113464

Epoch: 5| Step: 2
Training loss: 0.6923638582229614
Validation loss: 2.2671454648176828

Epoch: 5| Step: 3
Training loss: 1.0461080074310303
Validation loss: 2.2264530708392463

Epoch: 5| Step: 4
Training loss: 0.7667770385742188
Validation loss: 2.2599116961161294

Epoch: 5| Step: 5
Training loss: 1.1372097730636597
Validation loss: 2.2596979836622872

Epoch: 5| Step: 6
Training loss: 0.9555295705795288
Validation loss: 2.287873223423958

Epoch: 5| Step: 7
Training loss: 1.1090152263641357
Validation loss: 2.241468836863836

Epoch: 5| Step: 8
Training loss: 1.0223811864852905
Validation loss: 2.207854708035787

Epoch: 5| Step: 9
Training loss: 0.9407553672790527
Validation loss: 2.3040869186321893

Epoch: 5| Step: 10
Training loss: 1.205324411392212
Validation loss: 2.1642514367898307

Epoch: 5| Step: 11
Training loss: 2.187835931777954
Validation loss: 2.2265731195608773

Epoch: 198| Step: 0
Training loss: 0.9794143438339233
Validation loss: 2.2504349648952484

Epoch: 5| Step: 1
Training loss: 0.8404447436332703
Validation loss: 2.2931866347789764

Epoch: 5| Step: 2
Training loss: 1.3092683553695679
Validation loss: 2.2899318734804788

Epoch: 5| Step: 3
Training loss: 1.1690189838409424
Validation loss: 2.3060865898927054

Epoch: 5| Step: 4
Training loss: 1.0573800802230835
Validation loss: 2.28992889324824

Epoch: 5| Step: 5
Training loss: 0.9825139045715332
Validation loss: 2.2306791692972183

Epoch: 5| Step: 6
Training loss: 0.9348291158676147
Validation loss: 2.305039331316948

Epoch: 5| Step: 7
Training loss: 0.8705005645751953
Validation loss: 2.2229912181695304

Epoch: 5| Step: 8
Training loss: 0.9265864491462708
Validation loss: 2.302220364411672

Epoch: 5| Step: 9
Training loss: 0.8131288290023804
Validation loss: 2.328370283047358

Epoch: 5| Step: 10
Training loss: 0.9124156832695007
Validation loss: 2.3437160650889077

Epoch: 5| Step: 11
Training loss: 0.4520872235298157
Validation loss: 2.2433545092741647

Epoch: 199| Step: 0
Training loss: 1.0842968225479126
Validation loss: 2.359279543161392

Epoch: 5| Step: 1
Training loss: 1.0676504373550415
Validation loss: 2.29665869474411

Epoch: 5| Step: 2
Training loss: 1.1137526035308838
Validation loss: 2.331983377536138

Epoch: 5| Step: 3
Training loss: 1.2278950214385986
Validation loss: 2.3141532788674035

Epoch: 5| Step: 4
Training loss: 0.9473447799682617
Validation loss: 2.2660911480585733

Epoch: 5| Step: 5
Training loss: 0.7088482975959778
Validation loss: 2.3320488085349402

Epoch: 5| Step: 6
Training loss: 1.0410354137420654
Validation loss: 2.2585059702396393

Epoch: 5| Step: 7
Training loss: 1.3786232471466064
Validation loss: 2.2944077452023826

Epoch: 5| Step: 8
Training loss: 1.0015761852264404
Validation loss: 2.3028609504302344

Epoch: 5| Step: 9
Training loss: 0.6616756319999695
Validation loss: 2.20257605612278

Epoch: 5| Step: 10
Training loss: 1.2287962436676025
Validation loss: 2.317817807197571

Epoch: 5| Step: 11
Training loss: 0.5885909795761108
Validation loss: 2.2509574641784034

Epoch: 200| Step: 0
Training loss: 0.868023693561554
Validation loss: 2.2931976517041526

Epoch: 5| Step: 1
Training loss: 0.6888002157211304
Validation loss: 2.270649035771688

Epoch: 5| Step: 2
Training loss: 1.0164239406585693
Validation loss: 2.2345963418483734

Epoch: 5| Step: 3
Training loss: 0.8467220067977905
Validation loss: 2.321563204129537

Epoch: 5| Step: 4
Training loss: 1.2874794006347656
Validation loss: 2.290716211001078

Epoch: 5| Step: 5
Training loss: 1.473547101020813
Validation loss: 2.3120221346616745

Epoch: 5| Step: 6
Training loss: 0.8360377550125122
Validation loss: 2.298196201523145

Epoch: 5| Step: 7
Training loss: 0.925800621509552
Validation loss: 2.3241203874349594

Epoch: 5| Step: 8
Training loss: 0.8417732119560242
Validation loss: 2.276072089870771

Epoch: 5| Step: 9
Training loss: 0.9905225038528442
Validation loss: 2.2623556355635324

Epoch: 5| Step: 10
Training loss: 0.9126966595649719
Validation loss: 2.2665597846110663

Epoch: 5| Step: 11
Training loss: 0.39728090167045593
Validation loss: 2.314741015434265

Epoch: 201| Step: 0
Training loss: 1.6360328197479248
Validation loss: 2.2923011978467307

Epoch: 5| Step: 1
Training loss: 1.0287065505981445
Validation loss: 2.265588194131851

Epoch: 5| Step: 2
Training loss: 0.5444973111152649
Validation loss: 2.280776838461558

Epoch: 5| Step: 3
Training loss: 0.8117803335189819
Validation loss: 2.216382493575414

Epoch: 5| Step: 4
Training loss: 0.7742680311203003
Validation loss: 2.30869988600413

Epoch: 5| Step: 5
Training loss: 1.2202138900756836
Validation loss: 2.326455016930898

Epoch: 5| Step: 6
Training loss: 0.6575169563293457
Validation loss: 2.3318962256113687

Epoch: 5| Step: 7
Training loss: 0.6109420657157898
Validation loss: 2.33518319328626

Epoch: 5| Step: 8
Training loss: 1.2173539400100708
Validation loss: 2.281296581029892

Epoch: 5| Step: 9
Training loss: 0.9832758903503418
Validation loss: 2.326898366212845

Epoch: 5| Step: 10
Training loss: 1.0745986700057983
Validation loss: 2.3347759594519935

Epoch: 5| Step: 11
Training loss: 0.33816802501678467
Validation loss: 2.297868937253952

Epoch: 202| Step: 0
Training loss: 1.1428018808364868
Validation loss: 2.364483912785848

Epoch: 5| Step: 1
Training loss: 0.5886138677597046
Validation loss: 2.3037353257338204

Epoch: 5| Step: 2
Training loss: 1.393738031387329
Validation loss: 2.272624890009562

Epoch: 5| Step: 3
Training loss: 0.7767655253410339
Validation loss: 2.346580093105634

Epoch: 5| Step: 4
Training loss: 1.0654510259628296
Validation loss: 2.27449432015419

Epoch: 5| Step: 5
Training loss: 1.1318868398666382
Validation loss: 2.321393166979154

Epoch: 5| Step: 6
Training loss: 0.7758718729019165
Validation loss: 2.2885664999485016

Epoch: 5| Step: 7
Training loss: 0.634782075881958
Validation loss: 2.293831000725428

Epoch: 5| Step: 8
Training loss: 1.2430908679962158
Validation loss: 2.3092510104179382

Epoch: 5| Step: 9
Training loss: 1.226477026939392
Validation loss: 2.2619388699531555

Epoch: 5| Step: 10
Training loss: 0.7895748019218445
Validation loss: 2.302714079618454

Epoch: 5| Step: 11
Training loss: 1.141571044921875
Validation loss: 2.3246860752503076

Epoch: 203| Step: 0
Training loss: 1.321057915687561
Validation loss: 2.3146025041739144

Epoch: 5| Step: 1
Training loss: 0.726340651512146
Validation loss: 2.318912923336029

Epoch: 5| Step: 2
Training loss: 0.9970498085021973
Validation loss: 2.2758864710728326

Epoch: 5| Step: 3
Training loss: 0.9252989888191223
Validation loss: 2.3283312221368155

Epoch: 5| Step: 4
Training loss: 0.8771525621414185
Validation loss: 2.267667278647423

Epoch: 5| Step: 5
Training loss: 0.7230691909790039
Validation loss: 2.32629286746184

Epoch: 5| Step: 6
Training loss: 1.1392967700958252
Validation loss: 2.363989770412445

Epoch: 5| Step: 7
Training loss: 0.7931004166603088
Validation loss: 2.3694015443325043

Epoch: 5| Step: 8
Training loss: 0.811109721660614
Validation loss: 2.2858207871516547

Epoch: 5| Step: 9
Training loss: 1.214061975479126
Validation loss: 2.2781180342038474

Epoch: 5| Step: 10
Training loss: 1.1965163946151733
Validation loss: 2.3576616793870926

Epoch: 5| Step: 11
Training loss: 0.41348111629486084
Validation loss: 2.3305002748966217

Epoch: 204| Step: 0
Training loss: 0.6501469016075134
Validation loss: 2.2647376507520676

Epoch: 5| Step: 1
Training loss: 0.970112144947052
Validation loss: 2.1795607258876166

Epoch: 5| Step: 2
Training loss: 0.7630324363708496
Validation loss: 2.241272985935211

Epoch: 5| Step: 3
Training loss: 1.035746455192566
Validation loss: 2.245300148924192

Epoch: 5| Step: 4
Training loss: 1.2751600742340088
Validation loss: 2.275138651331266

Epoch: 5| Step: 5
Training loss: 1.1741721630096436
Validation loss: 2.279980426033338

Epoch: 5| Step: 6
Training loss: 0.8819825053215027
Validation loss: 2.2865976691246033

Epoch: 5| Step: 7
Training loss: 0.872707724571228
Validation loss: 2.236097291111946

Epoch: 5| Step: 8
Training loss: 0.8548896908760071
Validation loss: 2.341105173031489

Epoch: 5| Step: 9
Training loss: 1.2593120336532593
Validation loss: 2.3149820069471994

Epoch: 5| Step: 10
Training loss: 1.0637006759643555
Validation loss: 2.253835156559944

Epoch: 5| Step: 11
Training loss: 1.3954353332519531
Validation loss: 2.3050186783075333

Epoch: 205| Step: 0
Training loss: 1.1155375242233276
Validation loss: 2.2953623632589975

Epoch: 5| Step: 1
Training loss: 0.6937047243118286
Validation loss: 2.309259762366613

Epoch: 5| Step: 2
Training loss: 0.8599634170532227
Validation loss: 2.30297381679217

Epoch: 5| Step: 3
Training loss: 1.3139687776565552
Validation loss: 2.2772462517023087

Epoch: 5| Step: 4
Training loss: 1.289810061454773
Validation loss: 2.327355235815048

Epoch: 5| Step: 5
Training loss: 1.2223076820373535
Validation loss: 2.270938351750374

Epoch: 5| Step: 6
Training loss: 0.952995777130127
Validation loss: 2.272224505742391

Epoch: 5| Step: 7
Training loss: 0.9694281816482544
Validation loss: 2.289312402407328

Epoch: 5| Step: 8
Training loss: 1.0137497186660767
Validation loss: 2.245953460534414

Epoch: 5| Step: 9
Training loss: 0.9676496386528015
Validation loss: 2.2448500593503318

Epoch: 5| Step: 10
Training loss: 0.9027593731880188
Validation loss: 2.3088517636060715

Epoch: 5| Step: 11
Training loss: 0.28749728202819824
Validation loss: 2.308507780234019

Epoch: 206| Step: 0
Training loss: 1.2026115655899048
Validation loss: 2.298191398382187

Epoch: 5| Step: 1
Training loss: 1.1204745769500732
Validation loss: 2.261406287550926

Epoch: 5| Step: 2
Training loss: 0.761541485786438
Validation loss: 2.299913947780927

Epoch: 5| Step: 3
Training loss: 0.7801297903060913
Validation loss: 2.2813006937503815

Epoch: 5| Step: 4
Training loss: 0.8423582315444946
Validation loss: 2.287890692551931

Epoch: 5| Step: 5
Training loss: 0.8937738537788391
Validation loss: 2.276579961180687

Epoch: 5| Step: 6
Training loss: 1.035174012184143
Validation loss: 2.3140595654646554

Epoch: 5| Step: 7
Training loss: 1.020830750465393
Validation loss: 2.230244795481364

Epoch: 5| Step: 8
Training loss: 0.9085190892219543
Validation loss: 2.2893753300110498

Epoch: 5| Step: 9
Training loss: 1.0240118503570557
Validation loss: 2.2966794967651367

Epoch: 5| Step: 10
Training loss: 0.9888759851455688
Validation loss: 2.34872530400753

Epoch: 5| Step: 11
Training loss: 0.48633694648742676
Validation loss: 2.2607428580522537

Epoch: 207| Step: 0
Training loss: 1.195345163345337
Validation loss: 2.2795437276363373

Epoch: 5| Step: 1
Training loss: 0.5738116502761841
Validation loss: 2.394130915403366

Epoch: 5| Step: 2
Training loss: 0.6718908548355103
Validation loss: 2.3001657028992972

Epoch: 5| Step: 3
Training loss: 0.8403177261352539
Validation loss: 2.266668160756429

Epoch: 5| Step: 4
Training loss: 1.0647728443145752
Validation loss: 2.2568516234556832

Epoch: 5| Step: 5
Training loss: 0.8942421078681946
Validation loss: 2.3643307387828827

Epoch: 5| Step: 6
Training loss: 1.354773759841919
Validation loss: 2.272585322459539

Epoch: 5| Step: 7
Training loss: 0.8603566884994507
Validation loss: 2.3057361990213394

Epoch: 5| Step: 8
Training loss: 1.1427931785583496
Validation loss: 2.2565824786822

Epoch: 5| Step: 9
Training loss: 0.5138648748397827
Validation loss: 2.275106350580851

Epoch: 5| Step: 10
Training loss: 1.103777527809143
Validation loss: 2.2055421819289527

Epoch: 5| Step: 11
Training loss: 1.3016432523727417
Validation loss: 2.2478082180023193

Epoch: 208| Step: 0
Training loss: 0.9763666391372681
Validation loss: 2.3061290035645166

Epoch: 5| Step: 1
Training loss: 1.1240323781967163
Validation loss: 2.3989840149879456

Epoch: 5| Step: 2
Training loss: 1.2368252277374268
Validation loss: 2.2983033806085587

Epoch: 5| Step: 3
Training loss: 0.8596305847167969
Validation loss: 2.301095431049665

Epoch: 5| Step: 4
Training loss: 1.1079432964324951
Validation loss: 2.3170604209105172

Epoch: 5| Step: 5
Training loss: 1.4359182119369507
Validation loss: 2.2260202964146933

Epoch: 5| Step: 6
Training loss: 0.8085911870002747
Validation loss: 2.2531180332104364

Epoch: 5| Step: 7
Training loss: 0.7633264660835266
Validation loss: 2.2616490026315055

Epoch: 5| Step: 8
Training loss: 0.90204918384552
Validation loss: 2.3718580653270087

Epoch: 5| Step: 9
Training loss: 1.1634845733642578
Validation loss: 2.3740647037823996

Epoch: 5| Step: 10
Training loss: 0.9091537594795227
Validation loss: 2.2737221966187158

Epoch: 5| Step: 11
Training loss: 1.6206915378570557
Validation loss: 2.2876359770695367

Epoch: 209| Step: 0
Training loss: 0.6605650186538696
Validation loss: 2.2918688555558524

Epoch: 5| Step: 1
Training loss: 1.245902419090271
Validation loss: 2.255835607647896

Epoch: 5| Step: 2
Training loss: 1.0124666690826416
Validation loss: 2.251839111248652

Epoch: 5| Step: 3
Training loss: 1.079784870147705
Validation loss: 2.29947899778684

Epoch: 5| Step: 4
Training loss: 1.0126876831054688
Validation loss: 2.2589681347211203

Epoch: 5| Step: 5
Training loss: 0.9495741724967957
Validation loss: 2.240233158071836

Epoch: 5| Step: 6
Training loss: 0.946022629737854
Validation loss: 2.3085774878660836

Epoch: 5| Step: 7
Training loss: 1.2103370428085327
Validation loss: 2.212140570084254

Epoch: 5| Step: 8
Training loss: 0.6824535131454468
Validation loss: 2.194237897793452

Epoch: 5| Step: 9
Training loss: 0.6787511706352234
Validation loss: 2.2359676559766135

Epoch: 5| Step: 10
Training loss: 0.9261072278022766
Validation loss: 2.3149051666259766

Epoch: 5| Step: 11
Training loss: 0.28680962324142456
Validation loss: 2.238437275091807

Epoch: 210| Step: 0
Training loss: 1.3179032802581787
Validation loss: 2.281779502828916

Epoch: 5| Step: 1
Training loss: 1.6923344135284424
Validation loss: 2.2983484466870627

Epoch: 5| Step: 2
Training loss: 1.2266108989715576
Validation loss: 2.297915826241175

Epoch: 5| Step: 3
Training loss: 1.089870810508728
Validation loss: 2.2679096907377243

Epoch: 5| Step: 4
Training loss: 0.7491493225097656
Validation loss: 2.2648112078507743

Epoch: 5| Step: 5
Training loss: 0.6043753623962402
Validation loss: 2.258159726858139

Epoch: 5| Step: 6
Training loss: 0.785208523273468
Validation loss: 2.2373419255018234

Epoch: 5| Step: 7
Training loss: 0.8125232458114624
Validation loss: 2.314235587914785

Epoch: 5| Step: 8
Training loss: 0.5486215353012085
Validation loss: 2.318147470553716

Epoch: 5| Step: 9
Training loss: 0.7525280714035034
Validation loss: 2.334844375650088

Epoch: 5| Step: 10
Training loss: 0.7313750386238098
Validation loss: 2.2811632653077445

Epoch: 5| Step: 11
Training loss: 1.8826637268066406
Validation loss: 2.3003970185915628

Epoch: 211| Step: 0
Training loss: 1.2604068517684937
Validation loss: 2.2226558278004327

Epoch: 5| Step: 1
Training loss: 0.6430634260177612
Validation loss: 2.255346402525902

Epoch: 5| Step: 2
Training loss: 1.0329372882843018
Validation loss: 2.1830841253201165

Epoch: 5| Step: 3
Training loss: 0.9254168272018433
Validation loss: 2.264564032355944

Epoch: 5| Step: 4
Training loss: 0.6829961538314819
Validation loss: 2.2478261490662894

Epoch: 5| Step: 5
Training loss: 1.1443583965301514
Validation loss: 2.314408411582311

Epoch: 5| Step: 6
Training loss: 0.7352021336555481
Validation loss: 2.3146974742412567

Epoch: 5| Step: 7
Training loss: 0.883923351764679
Validation loss: 2.2446423918008804

Epoch: 5| Step: 8
Training loss: 0.946190357208252
Validation loss: 2.240565930803617

Epoch: 5| Step: 9
Training loss: 1.0401567220687866
Validation loss: 2.2750824292500815

Epoch: 5| Step: 10
Training loss: 1.1742912530899048
Validation loss: 2.3006507555643716

Epoch: 5| Step: 11
Training loss: 1.3873041868209839
Validation loss: 2.2451618214448295

Epoch: 212| Step: 0
Training loss: 0.8586542010307312
Validation loss: 2.2757292886575065

Epoch: 5| Step: 1
Training loss: 0.6154696345329285
Validation loss: 2.325449367364248

Epoch: 5| Step: 2
Training loss: 1.2954013347625732
Validation loss: 2.33577894171079

Epoch: 5| Step: 3
Training loss: 0.7650293111801147
Validation loss: 2.324816475311915

Epoch: 5| Step: 4
Training loss: 0.8930118680000305
Validation loss: 2.2318991820017495

Epoch: 5| Step: 5
Training loss: 1.281929850578308
Validation loss: 2.309371918439865

Epoch: 5| Step: 6
Training loss: 0.7527053952217102
Validation loss: 2.2964903513590493

Epoch: 5| Step: 7
Training loss: 0.6947647929191589
Validation loss: 2.2085651954015098

Epoch: 5| Step: 8
Training loss: 1.0975544452667236
Validation loss: 2.3013703574736915

Epoch: 5| Step: 9
Training loss: 0.9163964986801147
Validation loss: 2.26867106060187

Epoch: 5| Step: 10
Training loss: 1.144301176071167
Validation loss: 2.229625314474106

Epoch: 5| Step: 11
Training loss: 1.2566425800323486
Validation loss: 2.230828270316124

Epoch: 213| Step: 0
Training loss: 0.4542689919471741
Validation loss: 2.291217709581057

Epoch: 5| Step: 1
Training loss: 0.6966747641563416
Validation loss: 2.2268498142560325

Epoch: 5| Step: 2
Training loss: 0.9143571853637695
Validation loss: 2.221784512201945

Epoch: 5| Step: 3
Training loss: 0.7518823742866516
Validation loss: 2.226614942153295

Epoch: 5| Step: 4
Training loss: 0.9665630459785461
Validation loss: 2.263065551718076

Epoch: 5| Step: 5
Training loss: 0.601739227771759
Validation loss: 2.2850674986839294

Epoch: 5| Step: 6
Training loss: 1.1920193433761597
Validation loss: 2.283620352546374

Epoch: 5| Step: 7
Training loss: 1.2201662063598633
Validation loss: 2.300336400667826

Epoch: 5| Step: 8
Training loss: 0.9911544919013977
Validation loss: 2.227305064598719

Epoch: 5| Step: 9
Training loss: 1.2080949544906616
Validation loss: 2.2321763187646866

Epoch: 5| Step: 10
Training loss: 0.9839178323745728
Validation loss: 2.286820034186045

Epoch: 5| Step: 11
Training loss: 0.7232231497764587
Validation loss: 2.254196897149086

Epoch: 214| Step: 0
Training loss: 0.7797259092330933
Validation loss: 2.232127398252487

Epoch: 5| Step: 1
Training loss: 0.7824245095252991
Validation loss: 2.2888734440008798

Epoch: 5| Step: 2
Training loss: 0.7690286636352539
Validation loss: 2.2037077049414315

Epoch: 5| Step: 3
Training loss: 0.8970695734024048
Validation loss: 2.283626745144526

Epoch: 5| Step: 4
Training loss: 0.792921781539917
Validation loss: 2.2794302602609

Epoch: 5| Step: 5
Training loss: 0.6460816264152527
Validation loss: 2.234346240758896

Epoch: 5| Step: 6
Training loss: 0.8477166295051575
Validation loss: 2.267953793207804

Epoch: 5| Step: 7
Training loss: 1.5902341604232788
Validation loss: 2.189752275745074

Epoch: 5| Step: 8
Training loss: 0.5811896920204163
Validation loss: 2.250192701816559

Epoch: 5| Step: 9
Training loss: 1.1003698110580444
Validation loss: 2.260049675901731

Epoch: 5| Step: 10
Training loss: 1.0368092060089111
Validation loss: 2.3228182593981423

Epoch: 5| Step: 11
Training loss: 1.6990747451782227
Validation loss: 2.2487686375776925

Epoch: 215| Step: 0
Training loss: 1.0594980716705322
Validation loss: 2.265871604283651

Epoch: 5| Step: 1
Training loss: 0.7198060750961304
Validation loss: 2.3126115798950195

Epoch: 5| Step: 2
Training loss: 0.8945169448852539
Validation loss: 2.3292527000109353

Epoch: 5| Step: 3
Training loss: 0.8143331408500671
Validation loss: 2.2731549640496573

Epoch: 5| Step: 4
Training loss: 0.8737975358963013
Validation loss: 2.275239576896032

Epoch: 5| Step: 5
Training loss: 0.7533710598945618
Validation loss: 2.2813808917999268

Epoch: 5| Step: 6
Training loss: 0.5938794016838074
Validation loss: 2.2987864514191947

Epoch: 5| Step: 7
Training loss: 1.2969028949737549
Validation loss: 2.216820319493612

Epoch: 5| Step: 8
Training loss: 0.9772392511367798
Validation loss: 2.335262934366862

Epoch: 5| Step: 9
Training loss: 1.3021408319473267
Validation loss: 2.2644712378581366

Epoch: 5| Step: 10
Training loss: 0.8957573771476746
Validation loss: 2.280082176129023

Epoch: 5| Step: 11
Training loss: 1.1779818534851074
Validation loss: 2.2754454612731934

Epoch: 216| Step: 0
Training loss: 1.0802757740020752
Validation loss: 2.2621881663799286

Epoch: 5| Step: 1
Training loss: 0.9198671579360962
Validation loss: 2.2325282444556556

Epoch: 5| Step: 2
Training loss: 0.8836848139762878
Validation loss: 2.2547281980514526

Epoch: 5| Step: 3
Training loss: 1.0463985204696655
Validation loss: 2.3003928562005362

Epoch: 5| Step: 4
Training loss: 1.1166913509368896
Validation loss: 2.3033450593551

Epoch: 5| Step: 5
Training loss: 0.9364778399467468
Validation loss: 2.2791940917571387

Epoch: 5| Step: 6
Training loss: 1.1334683895111084
Validation loss: 2.255596712231636

Epoch: 5| Step: 7
Training loss: 1.2661417722702026
Validation loss: 2.29472945133845

Epoch: 5| Step: 8
Training loss: 0.7131693959236145
Validation loss: 2.2434905966122947

Epoch: 5| Step: 9
Training loss: 0.6168425679206848
Validation loss: 2.2302613208691278

Epoch: 5| Step: 10
Training loss: 0.6690992116928101
Validation loss: 2.354224051038424

Epoch: 5| Step: 11
Training loss: 0.7498033046722412
Validation loss: 2.3174089094003043

Epoch: 217| Step: 0
Training loss: 1.2086236476898193
Validation loss: 2.272676890095075

Epoch: 5| Step: 1
Training loss: 0.6830728650093079
Validation loss: 2.2957880795001984

Epoch: 5| Step: 2
Training loss: 0.6024445295333862
Validation loss: 2.286002735296885

Epoch: 5| Step: 3
Training loss: 1.2996652126312256
Validation loss: 2.229961891969045

Epoch: 5| Step: 4
Training loss: 0.6826432943344116
Validation loss: 2.2091288616259894

Epoch: 5| Step: 5
Training loss: 0.757854163646698
Validation loss: 2.3267082422971725

Epoch: 5| Step: 6
Training loss: 1.322261095046997
Validation loss: 2.2828462322553

Epoch: 5| Step: 7
Training loss: 1.1895983219146729
Validation loss: 2.3442270904779434

Epoch: 5| Step: 8
Training loss: 1.1717839241027832
Validation loss: 2.3078962862491608

Epoch: 5| Step: 9
Training loss: 0.4237447679042816
Validation loss: 2.283605774243673

Epoch: 5| Step: 10
Training loss: 0.7751328349113464
Validation loss: 2.3096153934796653

Epoch: 5| Step: 11
Training loss: 0.4004666209220886
Validation loss: 2.3629737397034964

Epoch: 218| Step: 0
Training loss: 0.9061218500137329
Validation loss: 2.2782135556141534

Epoch: 5| Step: 1
Training loss: 1.0842045545578003
Validation loss: 2.2933731079101562

Epoch: 5| Step: 2
Training loss: 0.6986721754074097
Validation loss: 2.162655552228292

Epoch: 5| Step: 3
Training loss: 0.9436688423156738
Validation loss: 2.2981629172960916

Epoch: 5| Step: 4
Training loss: 0.610965371131897
Validation loss: 2.2942231396834054

Epoch: 5| Step: 5
Training loss: 0.788433849811554
Validation loss: 2.2562302450339

Epoch: 5| Step: 6
Training loss: 0.7979972958564758
Validation loss: 2.3012176950772605

Epoch: 5| Step: 7
Training loss: 1.0123153924942017
Validation loss: 2.288894305626551

Epoch: 5| Step: 8
Training loss: 0.75434410572052
Validation loss: 2.2810451040665307

Epoch: 5| Step: 9
Training loss: 0.9967878460884094
Validation loss: 2.277979771296183

Epoch: 5| Step: 10
Training loss: 0.6526082158088684
Validation loss: 2.2690695424874625

Epoch: 5| Step: 11
Training loss: 1.7770988941192627
Validation loss: 2.2874554793039956

Epoch: 219| Step: 0
Training loss: 0.3675130605697632
Validation loss: 2.3000442882378898

Epoch: 5| Step: 1
Training loss: 0.5374960899353027
Validation loss: 2.2313368866840997

Epoch: 5| Step: 2
Training loss: 1.4063756465911865
Validation loss: 2.2759626507759094

Epoch: 5| Step: 3
Training loss: 1.002812385559082
Validation loss: 2.2905063231786094

Epoch: 5| Step: 4
Training loss: 0.7501147389411926
Validation loss: 2.2321215768655143

Epoch: 5| Step: 5
Training loss: 0.5744563341140747
Validation loss: 2.2598931094010672

Epoch: 5| Step: 6
Training loss: 0.6156970858573914
Validation loss: 2.2837998270988464

Epoch: 5| Step: 7
Training loss: 1.2569315433502197
Validation loss: 2.2466373840967813

Epoch: 5| Step: 8
Training loss: 0.5895479321479797
Validation loss: 2.2541645417610803

Epoch: 5| Step: 9
Training loss: 0.8849455118179321
Validation loss: 2.2740634779135385

Epoch: 5| Step: 10
Training loss: 1.0228450298309326
Validation loss: 2.2826247016588845

Epoch: 5| Step: 11
Training loss: 1.3798881769180298
Validation loss: 2.301835914452871

Epoch: 220| Step: 0
Training loss: 0.7540271878242493
Validation loss: 2.2155616879463196

Epoch: 5| Step: 1
Training loss: 0.8684077262878418
Validation loss: 2.261254519224167

Epoch: 5| Step: 2
Training loss: 0.7546679377555847
Validation loss: 2.207162708044052

Epoch: 5| Step: 3
Training loss: 1.000470519065857
Validation loss: 2.285314748684565

Epoch: 5| Step: 4
Training loss: 0.792640745639801
Validation loss: 2.2495391964912415

Epoch: 5| Step: 5
Training loss: 0.8118621706962585
Validation loss: 2.25374698638916

Epoch: 5| Step: 6
Training loss: 0.7935460209846497
Validation loss: 2.2394285798072815

Epoch: 5| Step: 7
Training loss: 0.9462971687316895
Validation loss: 2.259254977107048

Epoch: 5| Step: 8
Training loss: 1.0809024572372437
Validation loss: 2.295928339163462

Epoch: 5| Step: 9
Training loss: 0.8878667950630188
Validation loss: 2.3126624723275504

Epoch: 5| Step: 10
Training loss: 0.6733912229537964
Validation loss: 2.240656147400538

Epoch: 5| Step: 11
Training loss: 1.4771897792816162
Validation loss: 2.228658437728882

Epoch: 221| Step: 0
Training loss: 0.7275066375732422
Validation loss: 2.3232864141464233

Epoch: 5| Step: 1
Training loss: 1.129871129989624
Validation loss: 2.215331385533015

Epoch: 5| Step: 2
Training loss: 0.8002211451530457
Validation loss: 2.2880509396394095

Epoch: 5| Step: 3
Training loss: 0.558658242225647
Validation loss: 2.2697264154752097

Epoch: 5| Step: 4
Training loss: 1.0939491987228394
Validation loss: 2.265844235817591

Epoch: 5| Step: 5
Training loss: 0.8998117446899414
Validation loss: 2.2622983505328498

Epoch: 5| Step: 6
Training loss: 0.7334955930709839
Validation loss: 2.1941822320222855

Epoch: 5| Step: 7
Training loss: 0.43335390090942383
Validation loss: 2.2763787557681403

Epoch: 5| Step: 8
Training loss: 1.0242644548416138
Validation loss: 2.304140200217565

Epoch: 5| Step: 9
Training loss: 1.1175848245620728
Validation loss: 2.2359032531579337

Epoch: 5| Step: 10
Training loss: 1.3416759967803955
Validation loss: 2.2179225782553353

Epoch: 5| Step: 11
Training loss: 0.9649484157562256
Validation loss: 2.218312775095304

Epoch: 222| Step: 0
Training loss: 0.6850215196609497
Validation loss: 2.2418187310298285

Epoch: 5| Step: 1
Training loss: 0.6657312512397766
Validation loss: 2.2131081173817315

Epoch: 5| Step: 2
Training loss: 1.1173925399780273
Validation loss: 2.181219533085823

Epoch: 5| Step: 3
Training loss: 1.0681625604629517
Validation loss: 2.239751696586609

Epoch: 5| Step: 4
Training loss: 0.9459295272827148
Validation loss: 2.2635055085023246

Epoch: 5| Step: 5
Training loss: 0.702608048915863
Validation loss: 2.270965894063314

Epoch: 5| Step: 6
Training loss: 0.8653801083564758
Validation loss: 2.2563315083583197

Epoch: 5| Step: 7
Training loss: 0.8886221647262573
Validation loss: 2.2349990804990134

Epoch: 5| Step: 8
Training loss: 0.9741100072860718
Validation loss: 2.2915572822093964

Epoch: 5| Step: 9
Training loss: 0.6407085061073303
Validation loss: 2.2817642440398536

Epoch: 5| Step: 10
Training loss: 0.7802639007568359
Validation loss: 2.2478609879811606

Epoch: 5| Step: 11
Training loss: 0.9563085436820984
Validation loss: 2.214431499441465

Epoch: 223| Step: 0
Training loss: 0.647978663444519
Validation loss: 2.241463969151179

Epoch: 5| Step: 1
Training loss: 1.4639503955841064
Validation loss: 2.233271211385727

Epoch: 5| Step: 2
Training loss: 0.7124323844909668
Validation loss: 2.2679591675599418

Epoch: 5| Step: 3
Training loss: 0.8405796885490417
Validation loss: 2.2438019017378488

Epoch: 5| Step: 4
Training loss: 0.93330317735672
Validation loss: 2.2954205373922982

Epoch: 5| Step: 5
Training loss: 0.9345380067825317
Validation loss: 2.2566438963015876

Epoch: 5| Step: 6
Training loss: 0.7138688564300537
Validation loss: 2.2604070951541266

Epoch: 5| Step: 7
Training loss: 0.5244865417480469
Validation loss: 2.189059133330981

Epoch: 5| Step: 8
Training loss: 1.0398643016815186
Validation loss: 2.2343611468871436

Epoch: 5| Step: 9
Training loss: 0.5961220860481262
Validation loss: 2.2164488484462104

Epoch: 5| Step: 10
Training loss: 1.0185585021972656
Validation loss: 2.1918315440416336

Epoch: 5| Step: 11
Training loss: 0.6245342493057251
Validation loss: 2.2514610588550568

Epoch: 224| Step: 0
Training loss: 0.6595095992088318
Validation loss: 2.2799573838710785

Epoch: 5| Step: 1
Training loss: 0.8227452039718628
Validation loss: 2.1959697703520455

Epoch: 5| Step: 2
Training loss: 0.9416793584823608
Validation loss: 2.2161319802204766

Epoch: 5| Step: 3
Training loss: 0.9418910145759583
Validation loss: 2.213279331723849

Epoch: 5| Step: 4
Training loss: 0.6139469146728516
Validation loss: 2.2112044592698417

Epoch: 5| Step: 5
Training loss: 0.9610254168510437
Validation loss: 2.245929032564163

Epoch: 5| Step: 6
Training loss: 0.5927830934524536
Validation loss: 2.2876099745432534

Epoch: 5| Step: 7
Training loss: 0.6382863521575928
Validation loss: 2.308283254504204

Epoch: 5| Step: 8
Training loss: 1.0410072803497314
Validation loss: 2.2961746007204056

Epoch: 5| Step: 9
Training loss: 1.0499334335327148
Validation loss: 2.267187014222145

Epoch: 5| Step: 10
Training loss: 0.8253974914550781
Validation loss: 2.2361197968324027

Epoch: 5| Step: 11
Training loss: 0.713499128818512
Validation loss: 2.2718588411808014

Epoch: 225| Step: 0
Training loss: 0.6586019396781921
Validation loss: 2.255434513092041

Epoch: 5| Step: 1
Training loss: 0.46625643968582153
Validation loss: 2.1963223814964294

Epoch: 5| Step: 2
Training loss: 0.8706876039505005
Validation loss: 2.297457685073217

Epoch: 5| Step: 3
Training loss: 1.0058327913284302
Validation loss: 2.2694451957941055

Epoch: 5| Step: 4
Training loss: 0.9832030534744263
Validation loss: 2.3783531288305917

Epoch: 5| Step: 5
Training loss: 0.8422502279281616
Validation loss: 2.3435795356829963

Epoch: 5| Step: 6
Training loss: 0.5487131476402283
Validation loss: 2.306697035829226

Epoch: 5| Step: 7
Training loss: 0.8327590823173523
Validation loss: 2.2626723448435464

Epoch: 5| Step: 8
Training loss: 0.8421322107315063
Validation loss: 2.3019637862841287

Epoch: 5| Step: 9
Training loss: 1.1224536895751953
Validation loss: 2.280193875233332

Epoch: 5| Step: 10
Training loss: 1.1951758861541748
Validation loss: 2.222809821367264

Epoch: 5| Step: 11
Training loss: 0.7705584764480591
Validation loss: 2.2551588118076324

Epoch: 226| Step: 0
Training loss: 0.9708274006843567
Validation loss: 2.2189543346563974

Epoch: 5| Step: 1
Training loss: 0.6593087315559387
Validation loss: 2.263360013564428

Epoch: 5| Step: 2
Training loss: 0.6514559984207153
Validation loss: 2.2697038650512695

Epoch: 5| Step: 3
Training loss: 0.6959212422370911
Validation loss: 2.2455710967381797

Epoch: 5| Step: 4
Training loss: 1.2198947668075562
Validation loss: 2.2054009089867272

Epoch: 5| Step: 5
Training loss: 0.7698774337768555
Validation loss: 2.286475638548533

Epoch: 5| Step: 6
Training loss: 0.8121652603149414
Validation loss: 2.241413543621699

Epoch: 5| Step: 7
Training loss: 0.7529160380363464
Validation loss: 2.2601306637128196

Epoch: 5| Step: 8
Training loss: 0.6560346484184265
Validation loss: 2.241620888312658

Epoch: 5| Step: 9
Training loss: 0.9002668261528015
Validation loss: 2.2424009293317795

Epoch: 5| Step: 10
Training loss: 0.9045243263244629
Validation loss: 2.2670794626077018

Epoch: 5| Step: 11
Training loss: 0.9988605976104736
Validation loss: 2.20800152917703

Epoch: 227| Step: 0
Training loss: 0.7951733469963074
Validation loss: 2.213273599743843

Epoch: 5| Step: 1
Training loss: 0.7331371307373047
Validation loss: 2.269917984803518

Epoch: 5| Step: 2
Training loss: 1.0517513751983643
Validation loss: 2.272151763240496

Epoch: 5| Step: 3
Training loss: 1.355513572692871
Validation loss: 2.309920663634936

Epoch: 5| Step: 4
Training loss: 0.8562778234481812
Validation loss: 2.2366077403227487

Epoch: 5| Step: 5
Training loss: 0.6656787395477295
Validation loss: 2.231285035610199

Epoch: 5| Step: 6
Training loss: 0.7181521058082581
Validation loss: 2.2736989110708237

Epoch: 5| Step: 7
Training loss: 0.7175822257995605
Validation loss: 2.2795806378126144

Epoch: 5| Step: 8
Training loss: 0.914443850517273
Validation loss: 2.2602245012919107

Epoch: 5| Step: 9
Training loss: 0.7786691188812256
Validation loss: 2.2662643492221832

Epoch: 5| Step: 10
Training loss: 0.4692807197570801
Validation loss: 2.3403123021125793

Epoch: 5| Step: 11
Training loss: 1.0284022092819214
Validation loss: 2.2491045892238617

Epoch: 228| Step: 0
Training loss: 0.8652532696723938
Validation loss: 2.2443638841311135

Epoch: 5| Step: 1
Training loss: 1.1169874668121338
Validation loss: 2.3017118076483407

Epoch: 5| Step: 2
Training loss: 0.5473264455795288
Validation loss: 2.2616969694693885

Epoch: 5| Step: 3
Training loss: 1.1272096633911133
Validation loss: 2.257985999186834

Epoch: 5| Step: 4
Training loss: 0.9193049669265747
Validation loss: 2.217248866955439

Epoch: 5| Step: 5
Training loss: 0.8518762588500977
Validation loss: 2.2994738618532815

Epoch: 5| Step: 6
Training loss: 0.6934171319007874
Validation loss: 2.243299643198649

Epoch: 5| Step: 7
Training loss: 0.8357810974121094
Validation loss: 2.3077783981959024

Epoch: 5| Step: 8
Training loss: 1.0774648189544678
Validation loss: 2.2604667047659555

Epoch: 5| Step: 9
Training loss: 0.9348276853561401
Validation loss: 2.243785227338473

Epoch: 5| Step: 10
Training loss: 0.5329192876815796
Validation loss: 2.2973063588142395

Epoch: 5| Step: 11
Training loss: 1.0783624649047852
Validation loss: 2.2480539778868356

Epoch: 229| Step: 0
Training loss: 0.7923154830932617
Validation loss: 2.283414055903753

Epoch: 5| Step: 1
Training loss: 1.0820038318634033
Validation loss: 2.3292942196130753

Epoch: 5| Step: 2
Training loss: 0.994592010974884
Validation loss: 2.2231295804182687

Epoch: 5| Step: 3
Training loss: 0.5230100154876709
Validation loss: 2.3162288119395575

Epoch: 5| Step: 4
Training loss: 1.2124122381210327
Validation loss: 2.2469565073649087

Epoch: 5| Step: 5
Training loss: 0.8854161500930786
Validation loss: 2.3372047742207847

Epoch: 5| Step: 6
Training loss: 0.7175084948539734
Validation loss: 2.3093269765377045

Epoch: 5| Step: 7
Training loss: 1.3663727045059204
Validation loss: 2.2648822367191315

Epoch: 5| Step: 8
Training loss: 0.6848767995834351
Validation loss: 2.2352508256832757

Epoch: 5| Step: 9
Training loss: 0.7235521078109741
Validation loss: 2.2304627945025763

Epoch: 5| Step: 10
Training loss: 0.6175710558891296
Validation loss: 2.238997370004654

Epoch: 5| Step: 11
Training loss: 0.45115435123443604
Validation loss: 2.2352214058240256

Epoch: 230| Step: 0
Training loss: 0.7128070592880249
Validation loss: 2.27745591600736

Epoch: 5| Step: 1
Training loss: 0.8370580673217773
Validation loss: 2.255621383587519

Epoch: 5| Step: 2
Training loss: 0.6385934948921204
Validation loss: 2.2503933707873025

Epoch: 5| Step: 3
Training loss: 0.8051841855049133
Validation loss: 2.242309848467509

Epoch: 5| Step: 4
Training loss: 0.6068695187568665
Validation loss: 2.307615280151367

Epoch: 5| Step: 5
Training loss: 1.092668056488037
Validation loss: 2.283330221970876

Epoch: 5| Step: 6
Training loss: 0.8528186678886414
Validation loss: 2.249936337272326

Epoch: 5| Step: 7
Training loss: 1.2713109254837036
Validation loss: 2.2610053022702536

Epoch: 5| Step: 8
Training loss: 0.5622135400772095
Validation loss: 2.2377571562925973

Epoch: 5| Step: 9
Training loss: 1.0519815683364868
Validation loss: 2.3103906015555062

Epoch: 5| Step: 10
Training loss: 0.7576683759689331
Validation loss: 2.2748047610123954

Epoch: 5| Step: 11
Training loss: 0.30431199073791504
Validation loss: 2.3049263954162598

Epoch: 231| Step: 0
Training loss: 0.8945401906967163
Validation loss: 2.274502068758011

Epoch: 5| Step: 1
Training loss: 0.9785623550415039
Validation loss: 2.348324626684189

Epoch: 5| Step: 2
Training loss: 0.5666859745979309
Validation loss: 2.256990318497022

Epoch: 5| Step: 3
Training loss: 0.6918274164199829
Validation loss: 2.2030571897824607

Epoch: 5| Step: 4
Training loss: 0.7542149424552917
Validation loss: 2.228010416030884

Epoch: 5| Step: 5
Training loss: 1.0859041213989258
Validation loss: 2.295385261376699

Epoch: 5| Step: 6
Training loss: 0.9860890507698059
Validation loss: 2.321101869146029

Epoch: 5| Step: 7
Training loss: 0.5483571290969849
Validation loss: 2.2710722784201303

Epoch: 5| Step: 8
Training loss: 0.8386524319648743
Validation loss: 2.273323655128479

Epoch: 5| Step: 9
Training loss: 0.6931148171424866
Validation loss: 2.2235536923011145

Epoch: 5| Step: 10
Training loss: 1.2669392824172974
Validation loss: 2.3462740580240884

Epoch: 5| Step: 11
Training loss: 0.8575975894927979
Validation loss: 2.260966549317042

Epoch: 232| Step: 0
Training loss: 1.0363788604736328
Validation loss: 2.244791408379873

Epoch: 5| Step: 1
Training loss: 1.215676188468933
Validation loss: 2.2864676068226495

Epoch: 5| Step: 2
Training loss: 1.2125532627105713
Validation loss: 2.274710367123286

Epoch: 5| Step: 3
Training loss: 0.9699957966804504
Validation loss: 2.3464324673016868

Epoch: 5| Step: 4
Training loss: 0.8222548365592957
Validation loss: 2.2520446479320526

Epoch: 5| Step: 5
Training loss: 1.1460037231445312
Validation loss: 2.3119324147701263

Epoch: 5| Step: 6
Training loss: 0.9896866083145142
Validation loss: 2.2900914400815964

Epoch: 5| Step: 7
Training loss: 0.7378194332122803
Validation loss: 2.2515306621789932

Epoch: 5| Step: 8
Training loss: 0.5565475225448608
Validation loss: 2.2079078356424966

Epoch: 5| Step: 9
Training loss: 0.5820857286453247
Validation loss: 2.259398192167282

Epoch: 5| Step: 10
Training loss: 0.6605689525604248
Validation loss: 2.2554567058881125

Epoch: 5| Step: 11
Training loss: 0.6525724530220032
Validation loss: 2.2613863895336785

Epoch: 233| Step: 0
Training loss: 0.8311823606491089
Validation loss: 2.2871833195288978

Epoch: 5| Step: 1
Training loss: 0.6034996509552002
Validation loss: 2.3218776186307273

Epoch: 5| Step: 2
Training loss: 0.5426928400993347
Validation loss: 2.354564597209295

Epoch: 5| Step: 3
Training loss: 0.8390549421310425
Validation loss: 2.3047330180803933

Epoch: 5| Step: 4
Training loss: 0.5913103222846985
Validation loss: 2.2667394975821176

Epoch: 5| Step: 5
Training loss: 1.0727818012237549
Validation loss: 2.256940613190333

Epoch: 5| Step: 6
Training loss: 0.7046786546707153
Validation loss: 2.291377454996109

Epoch: 5| Step: 7
Training loss: 1.3994848728179932
Validation loss: 2.2803474217653275

Epoch: 5| Step: 8
Training loss: 0.6301474571228027
Validation loss: 2.2663086454073587

Epoch: 5| Step: 9
Training loss: 0.9645444750785828
Validation loss: 2.2978418370087943

Epoch: 5| Step: 10
Training loss: 0.8212264180183411
Validation loss: 2.2931843350330987

Epoch: 5| Step: 11
Training loss: 0.8381367921829224
Validation loss: 2.2756375819444656

Epoch: 234| Step: 0
Training loss: 1.1823374032974243
Validation loss: 2.29037773112456

Epoch: 5| Step: 1
Training loss: 0.5807031393051147
Validation loss: 2.3473320056994758

Epoch: 5| Step: 2
Training loss: 0.703447699546814
Validation loss: 2.28625126183033

Epoch: 5| Step: 3
Training loss: 0.5264581441879272
Validation loss: 2.301682725548744

Epoch: 5| Step: 4
Training loss: 0.8327600359916687
Validation loss: 2.309596677621206

Epoch: 5| Step: 5
Training loss: 0.7661460638046265
Validation loss: 2.238600035508474

Epoch: 5| Step: 6
Training loss: 1.0969568490982056
Validation loss: 2.2585925310850143

Epoch: 5| Step: 7
Training loss: 0.9349132776260376
Validation loss: 2.305265709757805

Epoch: 5| Step: 8
Training loss: 1.0318526029586792
Validation loss: 2.2953441788752875

Epoch: 5| Step: 9
Training loss: 0.6826743483543396
Validation loss: 2.283545355002085

Epoch: 5| Step: 10
Training loss: 0.6381446123123169
Validation loss: 2.254065990447998

Epoch: 5| Step: 11
Training loss: 0.31713366508483887
Validation loss: 2.289886643489202

Epoch: 235| Step: 0
Training loss: 0.8919550180435181
Validation loss: 2.28517014781634

Epoch: 5| Step: 1
Training loss: 0.6233681440353394
Validation loss: 2.40317931274573

Epoch: 5| Step: 2
Training loss: 0.7264167070388794
Validation loss: 2.3024542977412543

Epoch: 5| Step: 3
Training loss: 0.665127158164978
Validation loss: 2.249122848113378

Epoch: 5| Step: 4
Training loss: 0.8917913436889648
Validation loss: 2.2473051349322

Epoch: 5| Step: 5
Training loss: 0.9121810793876648
Validation loss: 2.2494297524293265

Epoch: 5| Step: 6
Training loss: 1.0053564310073853
Validation loss: 2.2656602511803308

Epoch: 5| Step: 7
Training loss: 0.9223095774650574
Validation loss: 2.2982313384612403

Epoch: 5| Step: 8
Training loss: 0.7364537715911865
Validation loss: 2.274126480023066

Epoch: 5| Step: 9
Training loss: 0.8645561337471008
Validation loss: 2.305719976623853

Epoch: 5| Step: 10
Training loss: 1.1682379245758057
Validation loss: 2.2745900005102158

Epoch: 5| Step: 11
Training loss: 0.834854006767273
Validation loss: 2.318413649996122

Epoch: 236| Step: 0
Training loss: 0.573096752166748
Validation loss: 2.247929255167643

Epoch: 5| Step: 1
Training loss: 0.8406562805175781
Validation loss: 2.325875292221705

Epoch: 5| Step: 2
Training loss: 1.022173285484314
Validation loss: 2.3191063354412713

Epoch: 5| Step: 3
Training loss: 0.7416520118713379
Validation loss: 2.293981283903122

Epoch: 5| Step: 4
Training loss: 0.7239726781845093
Validation loss: 2.2807009518146515

Epoch: 5| Step: 5
Training loss: 0.7272283434867859
Validation loss: 2.2932447095712027

Epoch: 5| Step: 6
Training loss: 0.747796356678009
Validation loss: 2.2725676695505777

Epoch: 5| Step: 7
Training loss: 0.5663962960243225
Validation loss: 2.2229484419027963

Epoch: 5| Step: 8
Training loss: 1.1775285005569458
Validation loss: 2.3055778592824936

Epoch: 5| Step: 9
Training loss: 1.0872514247894287
Validation loss: 2.3347771714131036

Epoch: 5| Step: 10
Training loss: 0.7909516096115112
Validation loss: 2.2706044614315033

Epoch: 5| Step: 11
Training loss: 0.6202960014343262
Validation loss: 2.308257440725962

Epoch: 237| Step: 0
Training loss: 0.8593782186508179
Validation loss: 2.3100286523501077

Epoch: 5| Step: 1
Training loss: 0.803068995475769
Validation loss: 2.2783215989669166

Epoch: 5| Step: 2
Training loss: 1.28943932056427
Validation loss: 2.322503760457039

Epoch: 5| Step: 3
Training loss: 0.9071057438850403
Validation loss: 2.29548050959905

Epoch: 5| Step: 4
Training loss: 1.0310808420181274
Validation loss: 2.3724528551101685

Epoch: 5| Step: 5
Training loss: 0.9130045771598816
Validation loss: 2.2726563463608422

Epoch: 5| Step: 6
Training loss: 0.886452853679657
Validation loss: 2.3170916537443795

Epoch: 5| Step: 7
Training loss: 0.46600788831710815
Validation loss: 2.286296625932058

Epoch: 5| Step: 8
Training loss: 0.7657088041305542
Validation loss: 2.2569524943828583

Epoch: 5| Step: 9
Training loss: 0.6546412706375122
Validation loss: 2.319357454776764

Epoch: 5| Step: 10
Training loss: 0.6056686639785767
Validation loss: 2.356301963329315

Epoch: 5| Step: 11
Training loss: 0.3704080581665039
Validation loss: 2.3101760049661

Epoch: 238| Step: 0
Training loss: 0.8800126910209656
Validation loss: 2.301354040702184

Epoch: 5| Step: 1
Training loss: 0.7151437997817993
Validation loss: 2.3186208556095758

Epoch: 5| Step: 2
Training loss: 0.3938691020011902
Validation loss: 2.2783725460370383

Epoch: 5| Step: 3
Training loss: 0.7119181752204895
Validation loss: 2.314833109577497

Epoch: 5| Step: 4
Training loss: 0.8332127332687378
Validation loss: 2.2295015702644982

Epoch: 5| Step: 5
Training loss: 0.8198341131210327
Validation loss: 2.2824870447317758

Epoch: 5| Step: 6
Training loss: 1.267357587814331
Validation loss: 2.283034940560659

Epoch: 5| Step: 7
Training loss: 0.7098382711410522
Validation loss: 2.288360302646955

Epoch: 5| Step: 8
Training loss: 1.0584750175476074
Validation loss: 2.2775797297557197

Epoch: 5| Step: 9
Training loss: 0.8750439882278442
Validation loss: 2.2630621840556464

Epoch: 5| Step: 10
Training loss: 0.7220072150230408
Validation loss: 2.3005105704069138

Epoch: 5| Step: 11
Training loss: 0.5722852945327759
Validation loss: 2.261724536617597

Epoch: 239| Step: 0
Training loss: 0.7388066053390503
Validation loss: 2.2507981856664023

Epoch: 5| Step: 1
Training loss: 0.8791528940200806
Validation loss: 2.2969788908958435

Epoch: 5| Step: 2
Training loss: 0.6753535866737366
Validation loss: 2.309523900349935

Epoch: 5| Step: 3
Training loss: 0.6901131868362427
Validation loss: 2.3039419054985046

Epoch: 5| Step: 4
Training loss: 0.9804661870002747
Validation loss: 2.306547219554583

Epoch: 5| Step: 5
Training loss: 1.0238407850265503
Validation loss: 2.3488620022932687

Epoch: 5| Step: 6
Training loss: 0.5673803091049194
Validation loss: 2.2537316381931305

Epoch: 5| Step: 7
Training loss: 0.5600361824035645
Validation loss: 2.2346560756365457

Epoch: 5| Step: 8
Training loss: 0.6007788181304932
Validation loss: 2.2950079093376794

Epoch: 5| Step: 9
Training loss: 0.6297417879104614
Validation loss: 2.2938513259092965

Epoch: 5| Step: 10
Training loss: 1.3068257570266724
Validation loss: 2.3204775055249534

Epoch: 5| Step: 11
Training loss: 1.589697241783142
Validation loss: 2.299076726039251

Epoch: 240| Step: 0
Training loss: 0.6074215173721313
Validation loss: 2.2430590093135834

Epoch: 5| Step: 1
Training loss: 0.43985477089881897
Validation loss: 2.310387005408605

Epoch: 5| Step: 2
Training loss: 0.8102283477783203
Validation loss: 2.263102908929189

Epoch: 5| Step: 3
Training loss: 0.8563860058784485
Validation loss: 2.3426522413889566

Epoch: 5| Step: 4
Training loss: 0.7403286695480347
Validation loss: 2.26247002184391

Epoch: 5| Step: 5
Training loss: 0.8444822430610657
Validation loss: 2.297058199842771

Epoch: 5| Step: 6
Training loss: 0.7143747806549072
Validation loss: 2.321264217297236

Epoch: 5| Step: 7
Training loss: 1.074033498764038
Validation loss: 2.189412295818329

Epoch: 5| Step: 8
Training loss: 0.5945258736610413
Validation loss: 2.314788664380709

Epoch: 5| Step: 9
Training loss: 0.8451421856880188
Validation loss: 2.262411206960678

Epoch: 5| Step: 10
Training loss: 0.9227268099784851
Validation loss: 2.2730648070573807

Epoch: 5| Step: 11
Training loss: 0.3433345854282379
Validation loss: 2.3278531382481256

Epoch: 241| Step: 0
Training loss: 0.9291137456893921
Validation loss: 2.335464576880137

Epoch: 5| Step: 1
Training loss: 0.9214390516281128
Validation loss: 2.2945475578308105

Epoch: 5| Step: 2
Training loss: 1.1120285987854004
Validation loss: 2.252959653735161

Epoch: 5| Step: 3
Training loss: 1.3665027618408203
Validation loss: 2.3088871936003366

Epoch: 5| Step: 4
Training loss: 0.5536152720451355
Validation loss: 2.2268620679775872

Epoch: 5| Step: 5
Training loss: 0.6683823466300964
Validation loss: 2.307227303584417

Epoch: 5| Step: 6
Training loss: 0.38414984941482544
Validation loss: 2.25125186642011

Epoch: 5| Step: 7
Training loss: 0.3781735897064209
Validation loss: 2.3248863418896994

Epoch: 5| Step: 8
Training loss: 0.9100757837295532
Validation loss: 2.2932806511720023

Epoch: 5| Step: 9
Training loss: 0.6782796382904053
Validation loss: 2.2517922123273215

Epoch: 5| Step: 10
Training loss: 0.8189870119094849
Validation loss: 2.264566903313001

Epoch: 5| Step: 11
Training loss: 0.31903886795043945
Validation loss: 2.302918757001559

Epoch: 242| Step: 0
Training loss: 0.8824989199638367
Validation loss: 2.306189179420471

Epoch: 5| Step: 1
Training loss: 0.7432354688644409
Validation loss: 2.2780801306168237

Epoch: 5| Step: 2
Training loss: 0.8552668690681458
Validation loss: 2.2332036793231964

Epoch: 5| Step: 3
Training loss: 0.8393561244010925
Validation loss: 2.328653405110041

Epoch: 5| Step: 4
Training loss: 0.6525472402572632
Validation loss: 2.283470794558525

Epoch: 5| Step: 5
Training loss: 0.9863408207893372
Validation loss: 2.323211501042048

Epoch: 5| Step: 6
Training loss: 0.47964420914649963
Validation loss: 2.300708070397377

Epoch: 5| Step: 7
Training loss: 0.6533064246177673
Validation loss: 2.3211470743020377

Epoch: 5| Step: 8
Training loss: 1.0654147863388062
Validation loss: 2.2865550071001053

Epoch: 5| Step: 9
Training loss: 0.6789835691452026
Validation loss: 2.2934186259905496

Epoch: 5| Step: 10
Training loss: 0.8107095956802368
Validation loss: 2.304075613617897

Epoch: 5| Step: 11
Training loss: 0.5282508134841919
Validation loss: 2.3327744702498117

Epoch: 243| Step: 0
Training loss: 0.8852982521057129
Validation loss: 2.302163432041804

Epoch: 5| Step: 1
Training loss: 0.6560050249099731
Validation loss: 2.272256483634313

Epoch: 5| Step: 2
Training loss: 0.5698838233947754
Validation loss: 2.3039418160915375

Epoch: 5| Step: 3
Training loss: 0.908442497253418
Validation loss: 2.344187766313553

Epoch: 5| Step: 4
Training loss: 1.1486234664916992
Validation loss: 2.259335438410441

Epoch: 5| Step: 5
Training loss: 0.48248568177223206
Validation loss: 2.2806244591871896

Epoch: 5| Step: 6
Training loss: 1.3368152379989624
Validation loss: 2.2912283837795258

Epoch: 5| Step: 7
Training loss: 0.9165128469467163
Validation loss: 2.2930426597595215

Epoch: 5| Step: 8
Training loss: 0.6122628450393677
Validation loss: 2.362849533557892

Epoch: 5| Step: 9
Training loss: 0.9609988927841187
Validation loss: 2.2944580763578415

Epoch: 5| Step: 10
Training loss: 0.9309881925582886
Validation loss: 2.2968545059363046

Epoch: 5| Step: 11
Training loss: 1.6313574314117432
Validation loss: 2.2363424797852836

Epoch: 244| Step: 0
Training loss: 0.6282069087028503
Validation loss: 2.322051450610161

Epoch: 5| Step: 1
Training loss: 1.1191413402557373
Validation loss: 2.2200084577004113

Epoch: 5| Step: 2
Training loss: 0.7677487134933472
Validation loss: 2.2503754645586014

Epoch: 5| Step: 3
Training loss: 0.5638560056686401
Validation loss: 2.3634650111198425

Epoch: 5| Step: 4
Training loss: 0.8686358332633972
Validation loss: 2.2946348786354065

Epoch: 5| Step: 5
Training loss: 0.7969368696212769
Validation loss: 2.1954665978749595

Epoch: 5| Step: 6
Training loss: 0.7654169797897339
Validation loss: 2.255311071872711

Epoch: 5| Step: 7
Training loss: 0.6932380795478821
Validation loss: 2.281491289536158

Epoch: 5| Step: 8
Training loss: 1.112794041633606
Validation loss: 2.285240481297175

Epoch: 5| Step: 9
Training loss: 0.7097498178482056
Validation loss: 2.240486597021421

Epoch: 5| Step: 10
Training loss: 0.3210015296936035
Validation loss: 2.346880237261454

Epoch: 5| Step: 11
Training loss: 0.460014671087265
Validation loss: 2.25822185476621

Epoch: 245| Step: 0
Training loss: 0.695816159248352
Validation loss: 2.2086746593316398

Epoch: 5| Step: 1
Training loss: 0.4725114405155182
Validation loss: 2.2482320368289948

Epoch: 5| Step: 2
Training loss: 0.817622184753418
Validation loss: 2.2421856125195823

Epoch: 5| Step: 3
Training loss: 1.106943964958191
Validation loss: 2.235383858283361

Epoch: 5| Step: 4
Training loss: 0.5493899583816528
Validation loss: 2.284398208061854

Epoch: 5| Step: 5
Training loss: 0.6384619474411011
Validation loss: 2.2189983328183494

Epoch: 5| Step: 6
Training loss: 0.9770668148994446
Validation loss: 2.264265368382136

Epoch: 5| Step: 7
Training loss: 0.6222086548805237
Validation loss: 2.2392131884892783

Epoch: 5| Step: 8
Training loss: 0.5438582301139832
Validation loss: 2.300882190465927

Epoch: 5| Step: 9
Training loss: 1.2472858428955078
Validation loss: 2.2908417334159217

Epoch: 5| Step: 10
Training loss: 0.40615805983543396
Validation loss: 2.278931647539139

Epoch: 5| Step: 11
Training loss: 1.1477680206298828
Validation loss: 2.2809544503688812

Epoch: 246| Step: 0
Training loss: 0.4906388223171234
Validation loss: 2.2432462573051453

Epoch: 5| Step: 1
Training loss: 0.6095578670501709
Validation loss: 2.27703324953715

Epoch: 5| Step: 2
Training loss: 0.9842561483383179
Validation loss: 2.251529802878698

Epoch: 5| Step: 3
Training loss: 0.6385260820388794
Validation loss: 2.3091394205888114

Epoch: 5| Step: 4
Training loss: 0.7007914781570435
Validation loss: 2.364197313785553

Epoch: 5| Step: 5
Training loss: 0.7840654253959656
Validation loss: 2.25153848528862

Epoch: 5| Step: 6
Training loss: 0.7873731255531311
Validation loss: 2.3071809063355126

Epoch: 5| Step: 7
Training loss: 0.8196350336074829
Validation loss: 2.232477808992068

Epoch: 5| Step: 8
Training loss: 0.5075293779373169
Validation loss: 2.262876878182093

Epoch: 5| Step: 9
Training loss: 0.6336836814880371
Validation loss: 2.2422979523738227

Epoch: 5| Step: 10
Training loss: 0.9583080410957336
Validation loss: 2.3524270306030908

Epoch: 5| Step: 11
Training loss: 1.3875715732574463
Validation loss: 2.314779986937841

Epoch: 247| Step: 0
Training loss: 0.9029150009155273
Validation loss: 2.316078950961431

Epoch: 5| Step: 1
Training loss: 0.629230797290802
Validation loss: 2.292415753006935

Epoch: 5| Step: 2
Training loss: 0.701917827129364
Validation loss: 2.267230674624443

Epoch: 5| Step: 3
Training loss: 0.9596393704414368
Validation loss: 2.2998603830734887

Epoch: 5| Step: 4
Training loss: 0.9531828165054321
Validation loss: 2.3146202166875205

Epoch: 5| Step: 5
Training loss: 0.39964157342910767
Validation loss: 2.278243680795034

Epoch: 5| Step: 6
Training loss: 0.7933515906333923
Validation loss: 2.2479885717233024

Epoch: 5| Step: 7
Training loss: 0.4783685803413391
Validation loss: 2.2564885864655175

Epoch: 5| Step: 8
Training loss: 1.2213209867477417
Validation loss: 2.3095631102720895

Epoch: 5| Step: 9
Training loss: 0.45432060956954956
Validation loss: 2.2241508464018502

Epoch: 5| Step: 10
Training loss: 0.8779348134994507
Validation loss: 2.3087158302466073

Epoch: 5| Step: 11
Training loss: 0.2147943377494812
Validation loss: 2.2518659085035324

Epoch: 248| Step: 0
Training loss: 0.5808666348457336
Validation loss: 2.3179755210876465

Epoch: 5| Step: 1
Training loss: 0.7028472423553467
Validation loss: 2.300688162446022

Epoch: 5| Step: 2
Training loss: 0.6215585470199585
Validation loss: 2.2553663005431495

Epoch: 5| Step: 3
Training loss: 1.6688534021377563
Validation loss: 2.2735725392897925

Epoch: 5| Step: 4
Training loss: 0.5971664786338806
Validation loss: 2.2659790068864822

Epoch: 5| Step: 5
Training loss: 0.9534489512443542
Validation loss: 2.3170584738254547

Epoch: 5| Step: 6
Training loss: 0.7499666810035706
Validation loss: 2.263764222462972

Epoch: 5| Step: 7
Training loss: 0.8218768239021301
Validation loss: 2.3090362399816513

Epoch: 5| Step: 8
Training loss: 0.643075168132782
Validation loss: 2.279277885953585

Epoch: 5| Step: 9
Training loss: 0.7798964381217957
Validation loss: 2.320163995027542

Epoch: 5| Step: 10
Training loss: 0.633430004119873
Validation loss: 2.3084163069725037

Epoch: 5| Step: 11
Training loss: 0.5099974870681763
Validation loss: 2.200242896874746

Epoch: 249| Step: 0
Training loss: 0.4726044535636902
Validation loss: 2.248413031299909

Epoch: 5| Step: 1
Training loss: 0.8921917080879211
Validation loss: 2.308231314023336

Epoch: 5| Step: 2
Training loss: 0.595054030418396
Validation loss: 2.2947836915651956

Epoch: 5| Step: 3
Training loss: 0.8361614942550659
Validation loss: 2.3268368542194366

Epoch: 5| Step: 4
Training loss: 1.2251042127609253
Validation loss: 2.249626482526461

Epoch: 5| Step: 5
Training loss: 0.5866032838821411
Validation loss: 2.3062159717082977

Epoch: 5| Step: 6
Training loss: 1.0685997009277344
Validation loss: 2.262870043516159

Epoch: 5| Step: 7
Training loss: 0.47974079847335815
Validation loss: 2.367662658294042

Epoch: 5| Step: 8
Training loss: 0.7916509509086609
Validation loss: 2.3052111069361367

Epoch: 5| Step: 9
Training loss: 0.8537006378173828
Validation loss: 2.2642020136117935

Epoch: 5| Step: 10
Training loss: 0.5549919009208679
Validation loss: 2.2586395343144736

Epoch: 5| Step: 11
Training loss: 1.1240904331207275
Validation loss: 2.2475141435861588

Epoch: 250| Step: 0
Training loss: 0.6817097663879395
Validation loss: 2.2702121635278067

Epoch: 5| Step: 1
Training loss: 0.6920797228813171
Validation loss: 2.2182912627855935

Epoch: 5| Step: 2
Training loss: 0.6448618769645691
Validation loss: 2.2725173830986023

Epoch: 5| Step: 3
Training loss: 0.6091065406799316
Validation loss: 2.2888320038715997

Epoch: 5| Step: 4
Training loss: 0.5553017854690552
Validation loss: 2.2879596451918283

Epoch: 5| Step: 5
Training loss: 0.6949504613876343
Validation loss: 2.2592560599247613

Epoch: 5| Step: 6
Training loss: 0.8314299583435059
Validation loss: 2.2683883061011634

Epoch: 5| Step: 7
Training loss: 1.1325290203094482
Validation loss: 2.2446535229682922

Epoch: 5| Step: 8
Training loss: 1.0387582778930664
Validation loss: 2.3297360837459564

Epoch: 5| Step: 9
Training loss: 0.8453980684280396
Validation loss: 2.2409957895676293

Epoch: 5| Step: 10
Training loss: 0.5915188789367676
Validation loss: 2.2653931180636087

Epoch: 5| Step: 11
Training loss: 0.45972251892089844
Validation loss: 2.2781787117322287

Epoch: 251| Step: 0
Training loss: 0.5460972189903259
Validation loss: 2.271203691760699

Epoch: 5| Step: 1
Training loss: 0.8578680753707886
Validation loss: 2.2305714190006256

Epoch: 5| Step: 2
Training loss: 0.8285714983940125
Validation loss: 2.2290093898773193

Epoch: 5| Step: 3
Training loss: 0.8921198844909668
Validation loss: 2.2812935411930084

Epoch: 5| Step: 4
Training loss: 0.6284055113792419
Validation loss: 2.2931684851646423

Epoch: 5| Step: 5
Training loss: 1.0534770488739014
Validation loss: 2.27050211528937

Epoch: 5| Step: 6
Training loss: 1.1576435565948486
Validation loss: 2.2567521234353385

Epoch: 5| Step: 7
Training loss: 0.6563677787780762
Validation loss: 2.293700555960337

Epoch: 5| Step: 8
Training loss: 0.6493117809295654
Validation loss: 2.2512189050515494

Epoch: 5| Step: 9
Training loss: 0.6056214570999146
Validation loss: 2.26140196621418

Epoch: 5| Step: 10
Training loss: 0.6858401298522949
Validation loss: 2.274361083904902

Epoch: 5| Step: 11
Training loss: 0.7357620000839233
Validation loss: 2.223406990369161

Epoch: 252| Step: 0
Training loss: 0.8776149749755859
Validation loss: 2.246174246072769

Epoch: 5| Step: 1
Training loss: 0.7292559146881104
Validation loss: 2.2926135659217834

Epoch: 5| Step: 2
Training loss: 0.7625805139541626
Validation loss: 2.2422087589899697

Epoch: 5| Step: 3
Training loss: 0.7661250829696655
Validation loss: 2.3037030597527823

Epoch: 5| Step: 4
Training loss: 0.8982254266738892
Validation loss: 2.2108456591765084

Epoch: 5| Step: 5
Training loss: 0.7365300059318542
Validation loss: 2.2641058762868247

Epoch: 5| Step: 6
Training loss: 0.5076323747634888
Validation loss: 2.232269595066706

Epoch: 5| Step: 7
Training loss: 0.39568641781806946
Validation loss: 2.235691179831823

Epoch: 5| Step: 8
Training loss: 0.7777848839759827
Validation loss: 2.2950651049613953

Epoch: 5| Step: 9
Training loss: 1.0468193292617798
Validation loss: 2.308049892385801

Epoch: 5| Step: 10
Training loss: 1.0701408386230469
Validation loss: 2.294568051894506

Epoch: 5| Step: 11
Training loss: 0.6071621179580688
Validation loss: 2.2330648998419442

Epoch: 253| Step: 0
Training loss: 0.6424258947372437
Validation loss: 2.2991896867752075

Epoch: 5| Step: 1
Training loss: 0.705947756767273
Validation loss: 2.2759923189878464

Epoch: 5| Step: 2
Training loss: 0.6618682146072388
Validation loss: 2.1985192696253457

Epoch: 5| Step: 3
Training loss: 0.5915746688842773
Validation loss: 2.2744431495666504

Epoch: 5| Step: 4
Training loss: 1.0139387845993042
Validation loss: 2.2511321703592935

Epoch: 5| Step: 5
Training loss: 0.6686288714408875
Validation loss: 2.3134286602338157

Epoch: 5| Step: 6
Training loss: 1.1110436916351318
Validation loss: 2.287025307615598

Epoch: 5| Step: 7
Training loss: 0.5459415316581726
Validation loss: 2.2422271917263665

Epoch: 5| Step: 8
Training loss: 0.6500759720802307
Validation loss: 2.182533378402392

Epoch: 5| Step: 9
Training loss: 0.7241644859313965
Validation loss: 2.2855841318766275

Epoch: 5| Step: 10
Training loss: 0.8134430050849915
Validation loss: 2.2607781986395517

Epoch: 5| Step: 11
Training loss: 0.30505937337875366
Validation loss: 2.241729180018107

Epoch: 254| Step: 0
Training loss: 1.0790561437606812
Validation loss: 2.306108976403872

Epoch: 5| Step: 1
Training loss: 0.48085784912109375
Validation loss: 2.2811786433060965

Epoch: 5| Step: 2
Training loss: 0.44242167472839355
Validation loss: 2.2848165531953177

Epoch: 5| Step: 3
Training loss: 0.9398468136787415
Validation loss: 2.270358378688494

Epoch: 5| Step: 4
Training loss: 0.9303690195083618
Validation loss: 2.260545998811722

Epoch: 5| Step: 5
Training loss: 0.4258778989315033
Validation loss: 2.263243814309438

Epoch: 5| Step: 6
Training loss: 0.28846392035484314
Validation loss: 2.2719255636135736

Epoch: 5| Step: 7
Training loss: 1.1017290353775024
Validation loss: 2.316081235806147

Epoch: 5| Step: 8
Training loss: 0.5514460802078247
Validation loss: 2.2262136141459146

Epoch: 5| Step: 9
Training loss: 0.8546115756034851
Validation loss: 2.2309850553671517

Epoch: 5| Step: 10
Training loss: 0.442177951335907
Validation loss: 2.2699853678544364

Epoch: 5| Step: 11
Training loss: 1.0377477407455444
Validation loss: 2.3561813036600747

Epoch: 255| Step: 0
Training loss: 0.5202301740646362
Validation loss: 2.2625080198049545

Epoch: 5| Step: 1
Training loss: 0.595697283744812
Validation loss: 2.263535966475805

Epoch: 5| Step: 2
Training loss: 0.5981991291046143
Validation loss: 2.2031923085451126

Epoch: 5| Step: 3
Training loss: 0.5846741795539856
Validation loss: 2.2733515997727713

Epoch: 5| Step: 4
Training loss: 0.62200528383255
Validation loss: 2.291168654958407

Epoch: 5| Step: 5
Training loss: 0.5961738228797913
Validation loss: 2.27081727484862

Epoch: 5| Step: 6
Training loss: 0.5707052946090698
Validation loss: 2.2772662987311683

Epoch: 5| Step: 7
Training loss: 1.432457685470581
Validation loss: 2.253545751174291

Epoch: 5| Step: 8
Training loss: 0.9425410032272339
Validation loss: 2.3079971373081207

Epoch: 5| Step: 9
Training loss: 0.5749650001525879
Validation loss: 2.2967944343884787

Epoch: 5| Step: 10
Training loss: 0.6674879193305969
Validation loss: 2.3241761326789856

Epoch: 5| Step: 11
Training loss: 0.4196653366088867
Validation loss: 2.2852662156025567

Epoch: 256| Step: 0
Training loss: 0.4973616600036621
Validation loss: 2.2699265579382577

Epoch: 5| Step: 1
Training loss: 0.6254258155822754
Validation loss: 2.3042187690734863

Epoch: 5| Step: 2
Training loss: 0.8549118041992188
Validation loss: 2.2585401982069016

Epoch: 5| Step: 3
Training loss: 0.7243452072143555
Validation loss: 2.2801438669363656

Epoch: 5| Step: 4
Training loss: 0.8087292909622192
Validation loss: 2.352681666612625

Epoch: 5| Step: 5
Training loss: 0.8127244710922241
Validation loss: 2.352370763818423

Epoch: 5| Step: 6
Training loss: 0.7014719843864441
Validation loss: 2.255735824505488

Epoch: 5| Step: 7
Training loss: 0.7476335167884827
Validation loss: 2.2963915367921195

Epoch: 5| Step: 8
Training loss: 1.1859790086746216
Validation loss: 2.2829126169284186

Epoch: 5| Step: 9
Training loss: 0.5296813249588013
Validation loss: 2.2928003072738647

Epoch: 5| Step: 10
Training loss: 0.7082957625389099
Validation loss: 2.3217007219791412

Epoch: 5| Step: 11
Training loss: 0.46942421793937683
Validation loss: 2.3250149289766946

Epoch: 257| Step: 0
Training loss: 0.7892147898674011
Validation loss: 2.276246746381124

Epoch: 5| Step: 1
Training loss: 0.5516417026519775
Validation loss: 2.2028336028258004

Epoch: 5| Step: 2
Training loss: 0.9148858785629272
Validation loss: 2.308305248618126

Epoch: 5| Step: 3
Training loss: 1.1460193395614624
Validation loss: 2.2720364133516946

Epoch: 5| Step: 4
Training loss: 0.6131832003593445
Validation loss: 2.2433489809433618

Epoch: 5| Step: 5
Training loss: 0.7373726963996887
Validation loss: 2.227427124977112

Epoch: 5| Step: 6
Training loss: 0.7462586164474487
Validation loss: 2.288482944170634

Epoch: 5| Step: 7
Training loss: 0.5360614061355591
Validation loss: 2.2840282122294107

Epoch: 5| Step: 8
Training loss: 0.664975643157959
Validation loss: 2.2822629312674203

Epoch: 5| Step: 9
Training loss: 0.3245151937007904
Validation loss: 2.2804411550362906

Epoch: 5| Step: 10
Training loss: 0.48325425386428833
Validation loss: 2.279929752151171

Epoch: 5| Step: 11
Training loss: 1.1674909591674805
Validation loss: 2.3053022573391595

Epoch: 258| Step: 0
Training loss: 0.8731313943862915
Validation loss: 2.30604749917984

Epoch: 5| Step: 1
Training loss: 1.0187255144119263
Validation loss: 2.3566945691903434

Epoch: 5| Step: 2
Training loss: 0.9596153497695923
Validation loss: 2.3299140632152557

Epoch: 5| Step: 3
Training loss: 0.6697410345077515
Validation loss: 2.3623400827248893

Epoch: 5| Step: 4
Training loss: 0.8536473512649536
Validation loss: 2.2919287433226905

Epoch: 5| Step: 5
Training loss: 0.6463983654975891
Validation loss: 2.3528727491696677

Epoch: 5| Step: 6
Training loss: 0.55601567029953
Validation loss: 2.333274041612943

Epoch: 5| Step: 7
Training loss: 0.5511369109153748
Validation loss: 2.3089215954144797

Epoch: 5| Step: 8
Training loss: 0.5905054807662964
Validation loss: 2.288757016261419

Epoch: 5| Step: 9
Training loss: 0.7285858392715454
Validation loss: 2.3018360237280526

Epoch: 5| Step: 10
Training loss: 0.6083930730819702
Validation loss: 2.259347985188166

Epoch: 5| Step: 11
Training loss: 0.6873501539230347
Validation loss: 2.348185102144877

Epoch: 259| Step: 0
Training loss: 0.6353512406349182
Validation loss: 2.2750557412703833

Epoch: 5| Step: 1
Training loss: 0.6110407114028931
Validation loss: 2.265931432445844

Epoch: 5| Step: 2
Training loss: 0.5499438047409058
Validation loss: 2.363797202706337

Epoch: 5| Step: 3
Training loss: 0.6380402445793152
Validation loss: 2.2550928741693497

Epoch: 5| Step: 4
Training loss: 0.6366435885429382
Validation loss: 2.301026001572609

Epoch: 5| Step: 5
Training loss: 1.1393229961395264
Validation loss: 2.284259324272474

Epoch: 5| Step: 6
Training loss: 0.7437318563461304
Validation loss: 2.259008397658666

Epoch: 5| Step: 7
Training loss: 0.6027505993843079
Validation loss: 2.3033881187438965

Epoch: 5| Step: 8
Training loss: 0.6659672856330872
Validation loss: 2.259340633948644

Epoch: 5| Step: 9
Training loss: 1.308454155921936
Validation loss: 2.2695837169885635

Epoch: 5| Step: 10
Training loss: 0.41729432344436646
Validation loss: 2.381287237008413

Epoch: 5| Step: 11
Training loss: 0.29468733072280884
Validation loss: 2.2922915120919547

Epoch: 260| Step: 0
Training loss: 0.6365410089492798
Validation loss: 2.3302991688251495

Epoch: 5| Step: 1
Training loss: 1.1378824710845947
Validation loss: 2.270129164059957

Epoch: 5| Step: 2
Training loss: 0.4320463240146637
Validation loss: 2.306966001788775

Epoch: 5| Step: 3
Training loss: 0.9232389330863953
Validation loss: 2.2483590046564736

Epoch: 5| Step: 4
Training loss: 0.6305118799209595
Validation loss: 2.2487630546092987

Epoch: 5| Step: 5
Training loss: 0.7383657693862915
Validation loss: 2.3046151598294577

Epoch: 5| Step: 6
Training loss: 0.407965749502182
Validation loss: 2.321539302666982

Epoch: 5| Step: 7
Training loss: 0.5991015434265137
Validation loss: 2.3200067579746246

Epoch: 5| Step: 8
Training loss: 0.6003205180168152
Validation loss: 2.299242526292801

Epoch: 5| Step: 9
Training loss: 1.0024816989898682
Validation loss: 2.2776881953080497

Epoch: 5| Step: 10
Training loss: 0.5034229159355164
Validation loss: 2.2919990768035254

Epoch: 5| Step: 11
Training loss: 0.17408885061740875
Validation loss: 2.2999802033106485

Epoch: 261| Step: 0
Training loss: 0.629301130771637
Validation loss: 2.2513897866010666

Epoch: 5| Step: 1
Training loss: 0.8867942690849304
Validation loss: 2.2840474347273507

Epoch: 5| Step: 2
Training loss: 0.6105720400810242
Validation loss: 2.264678657054901

Epoch: 5| Step: 3
Training loss: 1.0728187561035156
Validation loss: 2.2713914761940637

Epoch: 5| Step: 4
Training loss: 0.4396505355834961
Validation loss: 2.3548321773608527

Epoch: 5| Step: 5
Training loss: 0.5624579191207886
Validation loss: 2.288638045390447

Epoch: 5| Step: 6
Training loss: 0.8425933718681335
Validation loss: 2.250186617175738

Epoch: 5| Step: 7
Training loss: 0.4590359628200531
Validation loss: 2.3140073915322623

Epoch: 5| Step: 8
Training loss: 0.867681622505188
Validation loss: 2.219517091910044

Epoch: 5| Step: 9
Training loss: 0.8992936015129089
Validation loss: 2.2402683595816293

Epoch: 5| Step: 10
Training loss: 0.7617083787918091
Validation loss: 2.279516244928042

Epoch: 5| Step: 11
Training loss: 0.8706142902374268
Validation loss: 2.333201438188553

Epoch: 262| Step: 0
Training loss: 0.44252508878707886
Validation loss: 2.257059241334597

Epoch: 5| Step: 1
Training loss: 0.729749321937561
Validation loss: 2.2639277627070746

Epoch: 5| Step: 2
Training loss: 0.8588927984237671
Validation loss: 2.334610859553019

Epoch: 5| Step: 3
Training loss: 0.5057259202003479
Validation loss: 2.2686008165280023

Epoch: 5| Step: 4
Training loss: 0.7703115940093994
Validation loss: 2.3273553351561227

Epoch: 5| Step: 5
Training loss: 0.5901473164558411
Validation loss: 2.3093139976263046

Epoch: 5| Step: 6
Training loss: 1.1617767810821533
Validation loss: 2.3069443504015603

Epoch: 5| Step: 7
Training loss: 0.5068522095680237
Validation loss: 2.2819564094146094

Epoch: 5| Step: 8
Training loss: 0.4947710931301117
Validation loss: 2.2883478701114655

Epoch: 5| Step: 9
Training loss: 0.686965823173523
Validation loss: 2.279303173224131

Epoch: 5| Step: 10
Training loss: 0.7119976878166199
Validation loss: 2.2863294829924903

Epoch: 5| Step: 11
Training loss: 0.9059315919876099
Validation loss: 2.309943010409673

Epoch: 263| Step: 0
Training loss: 0.9904645085334778
Validation loss: 2.3341689755519233

Epoch: 5| Step: 1
Training loss: 0.45327967405319214
Validation loss: 2.277224878470103

Epoch: 5| Step: 2
Training loss: 0.8902411460876465
Validation loss: 2.258524273832639

Epoch: 5| Step: 3
Training loss: 0.28081315755844116
Validation loss: 2.325169404347738

Epoch: 5| Step: 4
Training loss: 0.5492941737174988
Validation loss: 2.293619821468989

Epoch: 5| Step: 5
Training loss: 0.8613628149032593
Validation loss: 2.3320570091406503

Epoch: 5| Step: 6
Training loss: 0.7411671876907349
Validation loss: 2.3726539810498557

Epoch: 5| Step: 7
Training loss: 0.4987441599369049
Validation loss: 2.3196296244859695

Epoch: 5| Step: 8
Training loss: 0.9016386270523071
Validation loss: 2.2678594837586084

Epoch: 5| Step: 9
Training loss: 0.8179019093513489
Validation loss: 2.27118456363678

Epoch: 5| Step: 10
Training loss: 0.8973287343978882
Validation loss: 2.2986810008684793

Epoch: 5| Step: 11
Training loss: 0.31867802143096924
Validation loss: 2.3323726107676825

Epoch: 264| Step: 0
Training loss: 0.3399870991706848
Validation loss: 2.3048885613679886

Epoch: 5| Step: 1
Training loss: 0.6129778623580933
Validation loss: 2.3410317500432334

Epoch: 5| Step: 2
Training loss: 0.9609266519546509
Validation loss: 2.28465735912323

Epoch: 5| Step: 3
Training loss: 0.8733394742012024
Validation loss: 2.290135686596235

Epoch: 5| Step: 4
Training loss: 0.7922791242599487
Validation loss: 2.2663064698378244

Epoch: 5| Step: 5
Training loss: 0.8372446298599243
Validation loss: 2.296839083234469

Epoch: 5| Step: 6
Training loss: 0.8353182673454285
Validation loss: 2.3209612468878427

Epoch: 5| Step: 7
Training loss: 0.843856155872345
Validation loss: 2.336788773536682

Epoch: 5| Step: 8
Training loss: 0.48332199454307556
Validation loss: 2.2822508166233697

Epoch: 5| Step: 9
Training loss: 0.7201848030090332
Validation loss: 2.396166364351908

Epoch: 5| Step: 10
Training loss: 0.6961923837661743
Validation loss: 2.3086311519145966

Epoch: 5| Step: 11
Training loss: 0.42393484711647034
Validation loss: 2.299846569697062

Epoch: 265| Step: 0
Training loss: 0.7172120809555054
Validation loss: 2.2394952376683555

Epoch: 5| Step: 1
Training loss: 1.0932741165161133
Validation loss: 2.2989670733610788

Epoch: 5| Step: 2
Training loss: 0.5317910313606262
Validation loss: 2.242631827791532

Epoch: 5| Step: 3
Training loss: 0.5074238777160645
Validation loss: 2.2795419295628867

Epoch: 5| Step: 4
Training loss: 0.40324535965919495
Validation loss: 2.2929062445958457

Epoch: 5| Step: 5
Training loss: 0.5092675685882568
Validation loss: 2.306389590104421

Epoch: 5| Step: 6
Training loss: 0.6733516454696655
Validation loss: 2.3028543094793954

Epoch: 5| Step: 7
Training loss: 0.9736090898513794
Validation loss: 2.1909684240818024

Epoch: 5| Step: 8
Training loss: 0.9981666803359985
Validation loss: 2.2859808752934136

Epoch: 5| Step: 9
Training loss: 0.6310209035873413
Validation loss: 2.313203533490499

Epoch: 5| Step: 10
Training loss: 0.7711378931999207
Validation loss: 2.3223995914061866

Epoch: 5| Step: 11
Training loss: 1.1766977310180664
Validation loss: 2.2424083948135376

Epoch: 266| Step: 0
Training loss: 1.0301774740219116
Validation loss: 2.190934201081594

Epoch: 5| Step: 1
Training loss: 0.49962300062179565
Validation loss: 2.2469611167907715

Epoch: 5| Step: 2
Training loss: 0.5763468742370605
Validation loss: 2.2483822057644525

Epoch: 5| Step: 3
Training loss: 0.6080746650695801
Validation loss: 2.2768626312414804

Epoch: 5| Step: 4
Training loss: 0.49274206161499023
Validation loss: 2.2623047729333243

Epoch: 5| Step: 5
Training loss: 0.8215153813362122
Validation loss: 2.2703844706217446

Epoch: 5| Step: 6
Training loss: 0.6624759435653687
Validation loss: 2.2375767678022385

Epoch: 5| Step: 7
Training loss: 0.887359619140625
Validation loss: 2.187830001115799

Epoch: 5| Step: 8
Training loss: 0.7572681307792664
Validation loss: 2.243723581234614

Epoch: 5| Step: 9
Training loss: 0.7895048260688782
Validation loss: 2.330935994784037

Epoch: 5| Step: 10
Training loss: 0.5639963746070862
Validation loss: 2.2424009243647256

Epoch: 5| Step: 11
Training loss: 0.5973963141441345
Validation loss: 2.242693990468979

Epoch: 267| Step: 0
Training loss: 0.6930788159370422
Validation loss: 2.281336342295011

Epoch: 5| Step: 1
Training loss: 0.7553635835647583
Validation loss: 2.205511396129926

Epoch: 5| Step: 2
Training loss: 0.5156511068344116
Validation loss: 2.321034073829651

Epoch: 5| Step: 3
Training loss: 0.8080193400382996
Validation loss: 2.3052948315938315

Epoch: 5| Step: 4
Training loss: 1.0818521976470947
Validation loss: 2.228648453950882

Epoch: 5| Step: 5
Training loss: 0.5920432806015015
Validation loss: 2.1921367992957435

Epoch: 5| Step: 6
Training loss: 0.5941359400749207
Validation loss: 2.2522438963254294

Epoch: 5| Step: 7
Training loss: 0.8823917508125305
Validation loss: 2.232344314455986

Epoch: 5| Step: 8
Training loss: 0.4712351858615875
Validation loss: 2.194860408703486

Epoch: 5| Step: 9
Training loss: 0.656572699546814
Validation loss: 2.2803315967321396

Epoch: 5| Step: 10
Training loss: 0.42863717675209045
Validation loss: 2.287008891503016

Epoch: 5| Step: 11
Training loss: 1.4679896831512451
Validation loss: 2.211249738931656

Epoch: 268| Step: 0
Training loss: 0.5085741281509399
Validation loss: 2.2436417043209076

Epoch: 5| Step: 1
Training loss: 0.5853024125099182
Validation loss: 2.2244049459695816

Epoch: 5| Step: 2
Training loss: 0.7696657776832581
Validation loss: 2.27265465259552

Epoch: 5| Step: 3
Training loss: 0.5442148447036743
Validation loss: 2.2337264666954675

Epoch: 5| Step: 4
Training loss: 0.9484448432922363
Validation loss: 2.2603830893834433

Epoch: 5| Step: 5
Training loss: 0.5997186899185181
Validation loss: 2.2567614068587623

Epoch: 5| Step: 6
Training loss: 0.5522083044052124
Validation loss: 2.255037864049276

Epoch: 5| Step: 7
Training loss: 0.8655943870544434
Validation loss: 2.3046031445264816

Epoch: 5| Step: 8
Training loss: 0.4617213308811188
Validation loss: 2.2422938346862793

Epoch: 5| Step: 9
Training loss: 0.4963521957397461
Validation loss: 2.22882271806399

Epoch: 5| Step: 10
Training loss: 0.8443551063537598
Validation loss: 2.2410256961981454

Epoch: 5| Step: 11
Training loss: 2.5176453590393066
Validation loss: 2.2730222791433334

Epoch: 269| Step: 0
Training loss: 0.6298748850822449
Validation loss: 2.3273567308982215

Epoch: 5| Step: 1
Training loss: 0.5348219871520996
Validation loss: 2.2603944589694343

Epoch: 5| Step: 2
Training loss: 0.5980424880981445
Validation loss: 2.2794293463230133

Epoch: 5| Step: 3
Training loss: 0.7330289483070374
Validation loss: 2.2595230837663016

Epoch: 5| Step: 4
Training loss: 0.4415059983730316
Validation loss: 2.2545182704925537

Epoch: 5| Step: 5
Training loss: 0.5913473963737488
Validation loss: 2.2642044723033905

Epoch: 5| Step: 6
Training loss: 0.7974452376365662
Validation loss: 2.302694782614708

Epoch: 5| Step: 7
Training loss: 0.5994900465011597
Validation loss: 2.266613100965818

Epoch: 5| Step: 8
Training loss: 0.632786750793457
Validation loss: 2.2649590770403543

Epoch: 5| Step: 9
Training loss: 1.1778336763381958
Validation loss: 2.265094742178917

Epoch: 5| Step: 10
Training loss: 0.4275573790073395
Validation loss: 2.2389908929665885

Epoch: 5| Step: 11
Training loss: 0.342190146446228
Validation loss: 2.2424362699190774

Epoch: 270| Step: 0
Training loss: 0.4512022137641907
Validation loss: 2.278241753578186

Epoch: 5| Step: 1
Training loss: 0.7508405447006226
Validation loss: 2.298020432392756

Epoch: 5| Step: 2
Training loss: 0.4406202733516693
Validation loss: 2.2320303122202554

Epoch: 5| Step: 3
Training loss: 0.731927752494812
Validation loss: 2.178656294941902

Epoch: 5| Step: 4
Training loss: 0.6906801462173462
Validation loss: 2.2254625956217446

Epoch: 5| Step: 5
Training loss: 0.4187934994697571
Validation loss: 2.260412633419037

Epoch: 5| Step: 6
Training loss: 0.534952700138092
Validation loss: 2.1725486467281976

Epoch: 5| Step: 7
Training loss: 0.9330113530158997
Validation loss: 2.2480315665404

Epoch: 5| Step: 8
Training loss: 0.6341059803962708
Validation loss: 2.2919655442237854

Epoch: 5| Step: 9
Training loss: 1.1030696630477905
Validation loss: 2.2531822522481284

Epoch: 5| Step: 10
Training loss: 0.5980325937271118
Validation loss: 2.226643751064936

Epoch: 5| Step: 11
Training loss: 0.8319405913352966
Validation loss: 2.28918519616127

Epoch: 271| Step: 0
Training loss: 0.5506134033203125
Validation loss: 2.2683992236852646

Epoch: 5| Step: 1
Training loss: 0.43044596910476685
Validation loss: 2.2788827220598855

Epoch: 5| Step: 2
Training loss: 0.6988526582717896
Validation loss: 2.300259610017141

Epoch: 5| Step: 3
Training loss: 0.7173592448234558
Validation loss: 2.213709900776545

Epoch: 5| Step: 4
Training loss: 1.1585042476654053
Validation loss: 2.283508946498235

Epoch: 5| Step: 5
Training loss: 0.5376464128494263
Validation loss: 2.191247284412384

Epoch: 5| Step: 6
Training loss: 0.44499635696411133
Validation loss: 2.243137081464132

Epoch: 5| Step: 7
Training loss: 0.4617307186126709
Validation loss: 2.25268126030763

Epoch: 5| Step: 8
Training loss: 0.8693925142288208
Validation loss: 2.318334917227427

Epoch: 5| Step: 9
Training loss: 0.5719214677810669
Validation loss: 2.3739044616619744

Epoch: 5| Step: 10
Training loss: 0.8803942799568176
Validation loss: 2.219841882586479

Epoch: 5| Step: 11
Training loss: 0.4846205711364746
Validation loss: 2.266574516892433

Epoch: 272| Step: 0
Training loss: 0.8739182353019714
Validation loss: 2.270025998353958

Epoch: 5| Step: 1
Training loss: 0.4476257264614105
Validation loss: 2.301528573036194

Epoch: 5| Step: 2
Training loss: 0.6997319459915161
Validation loss: 2.2620166341463723

Epoch: 5| Step: 3
Training loss: 0.6089980602264404
Validation loss: 2.2534556289513907

Epoch: 5| Step: 4
Training loss: 0.5227203965187073
Validation loss: 2.24636842807134

Epoch: 5| Step: 5
Training loss: 0.7352935671806335
Validation loss: 2.2705202599366507

Epoch: 5| Step: 6
Training loss: 0.8293529748916626
Validation loss: 2.2542708665132523

Epoch: 5| Step: 7
Training loss: 0.6151914000511169
Validation loss: 2.312205279866854

Epoch: 5| Step: 8
Training loss: 0.9118539690971375
Validation loss: 2.245807612935702

Epoch: 5| Step: 9
Training loss: 0.7838338613510132
Validation loss: 2.2580147981643677

Epoch: 5| Step: 10
Training loss: 0.3547940254211426
Validation loss: 2.252090334892273

Epoch: 5| Step: 11
Training loss: 1.2040433883666992
Validation loss: 2.311243623495102

Epoch: 273| Step: 0
Training loss: 0.5389423966407776
Validation loss: 2.302105034391085

Epoch: 5| Step: 1
Training loss: 0.9058510065078735
Validation loss: 2.2596173932154975

Epoch: 5| Step: 2
Training loss: 0.9106349945068359
Validation loss: 2.3179732908805213

Epoch: 5| Step: 3
Training loss: 0.9588707089424133
Validation loss: 2.41920014222463

Epoch: 5| Step: 4
Training loss: 0.5030360221862793
Validation loss: 2.2415636678536734

Epoch: 5| Step: 5
Training loss: 0.4027997553348541
Validation loss: 2.3086079160372415

Epoch: 5| Step: 6
Training loss: 0.45142823457717896
Validation loss: 2.3301825324694314

Epoch: 5| Step: 7
Training loss: 0.5565429925918579
Validation loss: 2.3582133849461875

Epoch: 5| Step: 8
Training loss: 0.6877272725105286
Validation loss: 2.294434313972791

Epoch: 5| Step: 9
Training loss: 0.6813467144966125
Validation loss: 2.2977036237716675

Epoch: 5| Step: 10
Training loss: 0.4493047595024109
Validation loss: 2.2975040276845298

Epoch: 5| Step: 11
Training loss: 1.4769617319107056
Validation loss: 2.2306688080231347

Epoch: 274| Step: 0
Training loss: 0.8500048518180847
Validation loss: 2.309720908602079

Epoch: 5| Step: 1
Training loss: 0.7322627902030945
Validation loss: 2.3165315936009088

Epoch: 5| Step: 2
Training loss: 0.38510453701019287
Validation loss: 2.280983418226242

Epoch: 5| Step: 3
Training loss: 0.708062469959259
Validation loss: 2.282958542307218

Epoch: 5| Step: 4
Training loss: 0.6127783060073853
Validation loss: 2.338249201575915

Epoch: 5| Step: 5
Training loss: 0.5346417427062988
Validation loss: 2.330361619591713

Epoch: 5| Step: 6
Training loss: 0.6259160041809082
Validation loss: 2.3335909793774285

Epoch: 5| Step: 7
Training loss: 1.3018447160720825
Validation loss: 2.371913194656372

Epoch: 5| Step: 8
Training loss: 0.4778229296207428
Validation loss: 2.275441527366638

Epoch: 5| Step: 9
Training loss: 0.6729674339294434
Validation loss: 2.3625390231609344

Epoch: 5| Step: 10
Training loss: 0.46166133880615234
Validation loss: 2.3269782066345215

Epoch: 5| Step: 11
Training loss: 0.5190619230270386
Validation loss: 2.2643692940473557

Epoch: 275| Step: 0
Training loss: 0.30272799730300903
Validation loss: 2.331633781393369

Epoch: 5| Step: 1
Training loss: 0.5746801495552063
Validation loss: 2.281943202018738

Epoch: 5| Step: 2
Training loss: 0.4207130968570709
Validation loss: 2.2929550111293793

Epoch: 5| Step: 3
Training loss: 0.42872685194015503
Validation loss: 2.3089744498332343

Epoch: 5| Step: 4
Training loss: 1.2522847652435303
Validation loss: 2.292420064409574

Epoch: 5| Step: 5
Training loss: 0.645379364490509
Validation loss: 2.261740669608116

Epoch: 5| Step: 6
Training loss: 0.7266298532485962
Validation loss: 2.3220189760128656

Epoch: 5| Step: 7
Training loss: 0.42869558930397034
Validation loss: 2.279657488067945

Epoch: 5| Step: 8
Training loss: 1.150164008140564
Validation loss: 2.3276600738366446

Epoch: 5| Step: 9
Training loss: 0.7158395648002625
Validation loss: 2.294917364915212

Epoch: 5| Step: 10
Training loss: 0.5193244218826294
Validation loss: 2.332651729385058

Epoch: 5| Step: 11
Training loss: 0.26275062561035156
Validation loss: 2.3108801543712616

Epoch: 276| Step: 0
Training loss: 0.9027231335639954
Validation loss: 2.291562850276629

Epoch: 5| Step: 1
Training loss: 0.48422908782958984
Validation loss: 2.2761153976122537

Epoch: 5| Step: 2
Training loss: 0.6688106060028076
Validation loss: 2.2489676624536514

Epoch: 5| Step: 3
Training loss: 0.534264862537384
Validation loss: 2.307508255044619

Epoch: 5| Step: 4
Training loss: 0.931251049041748
Validation loss: 2.290143628915151

Epoch: 5| Step: 5
Training loss: 0.6335871815681458
Validation loss: 2.2478354970614114

Epoch: 5| Step: 6
Training loss: 0.3538437485694885
Validation loss: 2.288135359684626

Epoch: 5| Step: 7
Training loss: 0.6239957213401794
Validation loss: 2.3032180070877075

Epoch: 5| Step: 8
Training loss: 0.45002493262290955
Validation loss: 2.3174780209859214

Epoch: 5| Step: 9
Training loss: 0.7445207834243774
Validation loss: 2.2712622930606208

Epoch: 5| Step: 10
Training loss: 0.671331524848938
Validation loss: 2.343238045771917

Epoch: 5| Step: 11
Training loss: 0.28822362422943115
Validation loss: 2.2289830644925437

Epoch: 277| Step: 0
Training loss: 0.4285944104194641
Validation loss: 2.2546057403087616

Epoch: 5| Step: 1
Training loss: 0.632615327835083
Validation loss: 2.3154252668221793

Epoch: 5| Step: 2
Training loss: 0.5518550872802734
Validation loss: 2.222819541891416

Epoch: 5| Step: 3
Training loss: 1.0352771282196045
Validation loss: 2.2574198246002197

Epoch: 5| Step: 4
Training loss: 0.5711711645126343
Validation loss: 2.315978800257047

Epoch: 5| Step: 5
Training loss: 0.3201976716518402
Validation loss: 2.28186563650767

Epoch: 5| Step: 6
Training loss: 0.6447086334228516
Validation loss: 2.2810229311386743

Epoch: 5| Step: 7
Training loss: 0.699016273021698
Validation loss: 2.267656609416008

Epoch: 5| Step: 8
Training loss: 0.5547258853912354
Validation loss: 2.267893671989441

Epoch: 5| Step: 9
Training loss: 1.112638235092163
Validation loss: 2.3261272509892783

Epoch: 5| Step: 10
Training loss: 0.8337360620498657
Validation loss: 2.3716947734355927

Epoch: 5| Step: 11
Training loss: 0.3337963819503784
Validation loss: 2.3197386662165322

Epoch: 278| Step: 0
Training loss: 0.31800252199172974
Validation loss: 2.3215261101722717

Epoch: 5| Step: 1
Training loss: 0.38101571798324585
Validation loss: 2.272627746065458

Epoch: 5| Step: 2
Training loss: 0.41032862663269043
Validation loss: 2.252096394697825

Epoch: 5| Step: 3
Training loss: 0.9182745218276978
Validation loss: 2.294569253921509

Epoch: 5| Step: 4
Training loss: 0.3821282386779785
Validation loss: 2.317231039206187

Epoch: 5| Step: 5
Training loss: 0.29843905568122864
Validation loss: 2.3437086244424186

Epoch: 5| Step: 6
Training loss: 0.8381967544555664
Validation loss: 2.3053918927907944

Epoch: 5| Step: 7
Training loss: 1.0358704328536987
Validation loss: 2.2652664184570312

Epoch: 5| Step: 8
Training loss: 0.7007665038108826
Validation loss: 2.2358789344628653

Epoch: 5| Step: 9
Training loss: 0.5754233598709106
Validation loss: 2.3378373185793557

Epoch: 5| Step: 10
Training loss: 0.8350303769111633
Validation loss: 2.3333960523207984

Epoch: 5| Step: 11
Training loss: 0.8479297161102295
Validation loss: 2.261331116159757

Epoch: 279| Step: 0
Training loss: 0.7319310903549194
Validation loss: 2.328238328297933

Epoch: 5| Step: 1
Training loss: 0.7767630815505981
Validation loss: 2.286939283212026

Epoch: 5| Step: 2
Training loss: 1.0336592197418213
Validation loss: 2.300382832686106

Epoch: 5| Step: 3
Training loss: 0.6691824793815613
Validation loss: 2.2654824405908585

Epoch: 5| Step: 4
Training loss: 0.4310823082923889
Validation loss: 2.3113611936569214

Epoch: 5| Step: 5
Training loss: 0.4062032699584961
Validation loss: 2.275238881508509

Epoch: 5| Step: 6
Training loss: 0.46826010942459106
Validation loss: 2.3088306883970895

Epoch: 5| Step: 7
Training loss: 0.5605886578559875
Validation loss: 2.2809793800115585

Epoch: 5| Step: 8
Training loss: 0.45720916986465454
Validation loss: 2.265270233154297

Epoch: 5| Step: 9
Training loss: 0.6756845712661743
Validation loss: 2.29978679617246

Epoch: 5| Step: 10
Training loss: 0.5425534844398499
Validation loss: 2.3063482294480004

Epoch: 5| Step: 11
Training loss: 1.617645263671875
Validation loss: 2.348639557758967

Epoch: 280| Step: 0
Training loss: 0.6101914644241333
Validation loss: 2.3266400694847107

Epoch: 5| Step: 1
Training loss: 0.5162004232406616
Validation loss: 2.3369730512301126

Epoch: 5| Step: 2
Training loss: 0.6633598804473877
Validation loss: 2.3585427751143775

Epoch: 5| Step: 3
Training loss: 0.5069485306739807
Validation loss: 2.297513564427694

Epoch: 5| Step: 4
Training loss: 0.5071314573287964
Validation loss: 2.2692436824242272

Epoch: 5| Step: 5
Training loss: 0.7583263516426086
Validation loss: 2.288452406724294

Epoch: 5| Step: 6
Training loss: 0.6409584283828735
Validation loss: 2.2878164052963257

Epoch: 5| Step: 7
Training loss: 1.0604215860366821
Validation loss: 2.3763911773761115

Epoch: 5| Step: 8
Training loss: 0.4780775010585785
Validation loss: 2.259089489777883

Epoch: 5| Step: 9
Training loss: 0.6542187333106995
Validation loss: 2.3082465330759683

Epoch: 5| Step: 10
Training loss: 0.8789254426956177
Validation loss: 2.2449355820814767

Epoch: 5| Step: 11
Training loss: 0.4436148703098297
Validation loss: 2.2649028648932776

Epoch: 281| Step: 0
Training loss: 0.7916978001594543
Validation loss: 2.291350468993187

Epoch: 5| Step: 1
Training loss: 0.44921788573265076
Validation loss: 2.3058765282233558

Epoch: 5| Step: 2
Training loss: 0.36958765983581543
Validation loss: 2.304543450474739

Epoch: 5| Step: 3
Training loss: 0.9272562265396118
Validation loss: 2.308428327242533

Epoch: 5| Step: 4
Training loss: 0.7080482244491577
Validation loss: 2.240896612405777

Epoch: 5| Step: 5
Training loss: 0.4472026228904724
Validation loss: 2.2978049417336783

Epoch: 5| Step: 6
Training loss: 0.9326281547546387
Validation loss: 2.3137858708699546

Epoch: 5| Step: 7
Training loss: 0.5216744542121887
Validation loss: 2.2504325409730277

Epoch: 5| Step: 8
Training loss: 0.8836685419082642
Validation loss: 2.2194810708363852

Epoch: 5| Step: 9
Training loss: 0.505398154258728
Validation loss: 2.2181534618139267

Epoch: 5| Step: 10
Training loss: 0.7394798994064331
Validation loss: 2.197235365708669

Epoch: 5| Step: 11
Training loss: 0.11970949172973633
Validation loss: 2.313192675511042

Epoch: 282| Step: 0
Training loss: 0.6941319108009338
Validation loss: 2.23830538491408

Epoch: 5| Step: 1
Training loss: 0.4373153746128082
Validation loss: 2.251742015282313

Epoch: 5| Step: 2
Training loss: 0.36065220832824707
Validation loss: 2.2483894328276315

Epoch: 5| Step: 3
Training loss: 0.6893951296806335
Validation loss: 2.3364482621351876

Epoch: 5| Step: 4
Training loss: 0.46876955032348633
Validation loss: 2.2783557871977487

Epoch: 5| Step: 5
Training loss: 0.6728374361991882
Validation loss: 2.307179739077886

Epoch: 5| Step: 6
Training loss: 0.61421138048172
Validation loss: 2.2848328401645026

Epoch: 5| Step: 7
Training loss: 0.3896400034427643
Validation loss: 2.2546220322450004

Epoch: 5| Step: 8
Training loss: 0.8107597231864929
Validation loss: 2.252564460039139

Epoch: 5| Step: 9
Training loss: 0.7254839539527893
Validation loss: 2.2810607651869454

Epoch: 5| Step: 10
Training loss: 1.0046420097351074
Validation loss: 2.2534449299176535

Epoch: 5| Step: 11
Training loss: 0.5763249397277832
Validation loss: 2.3066026667753854

Epoch: 283| Step: 0
Training loss: 0.8113515973091125
Validation loss: 2.349551022052765

Epoch: 5| Step: 1
Training loss: 0.3481380343437195
Validation loss: 2.26022099951903

Epoch: 5| Step: 2
Training loss: 0.7812926769256592
Validation loss: 2.2795149038235345

Epoch: 5| Step: 3
Training loss: 0.7374005317687988
Validation loss: 2.265474940339724

Epoch: 5| Step: 4
Training loss: 0.67308109998703
Validation loss: 2.307018289963404

Epoch: 5| Step: 5
Training loss: 1.0712699890136719
Validation loss: 2.3242997427781424

Epoch: 5| Step: 6
Training loss: 0.3409687876701355
Validation loss: 2.319743365049362

Epoch: 5| Step: 7
Training loss: 0.452594518661499
Validation loss: 2.2970610757668815

Epoch: 5| Step: 8
Training loss: 0.33695611357688904
Validation loss: 2.2435858845710754

Epoch: 5| Step: 9
Training loss: 0.9101446270942688
Validation loss: 2.296446998914083

Epoch: 5| Step: 10
Training loss: 0.46156415343284607
Validation loss: 2.3031057814757028

Epoch: 5| Step: 11
Training loss: 0.5194903612136841
Validation loss: 2.3191122114658356

Epoch: 284| Step: 0
Training loss: 0.36349791288375854
Validation loss: 2.321072687705358

Epoch: 5| Step: 1
Training loss: 0.44629573822021484
Validation loss: 2.3059346973896027

Epoch: 5| Step: 2
Training loss: 0.698004424571991
Validation loss: 2.2965046813090644

Epoch: 5| Step: 3
Training loss: 1.094045639038086
Validation loss: 2.3397309879461923

Epoch: 5| Step: 4
Training loss: 0.7234174013137817
Validation loss: 2.3660603960355124

Epoch: 5| Step: 5
Training loss: 0.556443989276886
Validation loss: 2.3196676472822824

Epoch: 5| Step: 6
Training loss: 0.48461809754371643
Validation loss: 2.280295421679815

Epoch: 5| Step: 7
Training loss: 0.6595408320426941
Validation loss: 2.3300867875417075

Epoch: 5| Step: 8
Training loss: 0.4326368272304535
Validation loss: 2.2794543405373893

Epoch: 5| Step: 9
Training loss: 0.6755667924880981
Validation loss: 2.2293932139873505

Epoch: 5| Step: 10
Training loss: 0.7635669708251953
Validation loss: 2.362752308448156

Epoch: 5| Step: 11
Training loss: 0.2698274552822113
Validation loss: 2.2787091930707297

Epoch: 285| Step: 0
Training loss: 0.47660931944847107
Validation loss: 2.29441865781943

Epoch: 5| Step: 1
Training loss: 0.74183189868927
Validation loss: 2.3569588363170624

Epoch: 5| Step: 2
Training loss: 0.4792923033237457
Validation loss: 2.2736822913090386

Epoch: 5| Step: 3
Training loss: 0.2765319049358368
Validation loss: 2.2781891326109567

Epoch: 5| Step: 4
Training loss: 0.7928022146224976
Validation loss: 2.3088689843813577

Epoch: 5| Step: 5
Training loss: 0.838028609752655
Validation loss: 2.176913325985273

Epoch: 5| Step: 6
Training loss: 0.8189611434936523
Validation loss: 2.2185633927583694

Epoch: 5| Step: 7
Training loss: 0.9122446179389954
Validation loss: 2.297686646382014

Epoch: 5| Step: 8
Training loss: 0.39254456758499146
Validation loss: 2.310174991687139

Epoch: 5| Step: 9
Training loss: 0.9756515622138977
Validation loss: 2.3156135082244873

Epoch: 5| Step: 10
Training loss: 0.47729411721229553
Validation loss: 2.2668631821870804

Epoch: 5| Step: 11
Training loss: 0.43557101488113403
Validation loss: 2.2916360398133597

Epoch: 286| Step: 0
Training loss: 0.4263102412223816
Validation loss: 2.282857750852903

Epoch: 5| Step: 1
Training loss: 1.3553084135055542
Validation loss: 2.3102200478315353

Epoch: 5| Step: 2
Training loss: 0.6683304905891418
Validation loss: 2.250197490056356

Epoch: 5| Step: 3
Training loss: 0.5393384695053101
Validation loss: 2.2610234320163727

Epoch: 5| Step: 4
Training loss: 0.5494551658630371
Validation loss: 2.248042404651642

Epoch: 5| Step: 5
Training loss: 0.5123736262321472
Validation loss: 2.2625842789808908

Epoch: 5| Step: 6
Training loss: 0.5562682151794434
Validation loss: 2.2641737212737403

Epoch: 5| Step: 7
Training loss: 0.6003556251525879
Validation loss: 2.2420109113057456

Epoch: 5| Step: 8
Training loss: 0.49195989966392517
Validation loss: 2.2760135382413864

Epoch: 5| Step: 9
Training loss: 0.6700122952461243
Validation loss: 2.2861199428637824

Epoch: 5| Step: 10
Training loss: 0.5403720140457153
Validation loss: 2.378269592920939

Epoch: 5| Step: 11
Training loss: 1.2149155139923096
Validation loss: 2.239603733023008

Epoch: 287| Step: 0
Training loss: 0.5306625366210938
Validation loss: 2.274734223882357

Epoch: 5| Step: 1
Training loss: 0.47646206617355347
Validation loss: 2.201483661929766

Epoch: 5| Step: 2
Training loss: 0.5938857197761536
Validation loss: 2.2779345959424973

Epoch: 5| Step: 3
Training loss: 0.6728463768959045
Validation loss: 2.255449657638868

Epoch: 5| Step: 4
Training loss: 0.7836977243423462
Validation loss: 2.2521363298098245

Epoch: 5| Step: 5
Training loss: 0.646824061870575
Validation loss: 2.2325092256069183

Epoch: 5| Step: 6
Training loss: 0.5193902254104614
Validation loss: 2.2808920542399087

Epoch: 5| Step: 7
Training loss: 0.45591917634010315
Validation loss: 2.247652769088745

Epoch: 5| Step: 8
Training loss: 0.8909176588058472
Validation loss: 2.23800265789032

Epoch: 5| Step: 9
Training loss: 0.5500165224075317
Validation loss: 2.2791926811138787

Epoch: 5| Step: 10
Training loss: 0.5987947583198547
Validation loss: 2.292256623506546

Epoch: 5| Step: 11
Training loss: 0.8558579683303833
Validation loss: 2.2265011121829352

Epoch: 288| Step: 0
Training loss: 0.4223902225494385
Validation loss: 2.253031467398008

Epoch: 5| Step: 1
Training loss: 0.4266361594200134
Validation loss: 2.277576446533203

Epoch: 5| Step: 2
Training loss: 0.6679048538208008
Validation loss: 2.297717144091924

Epoch: 5| Step: 3
Training loss: 0.9928832054138184
Validation loss: 2.33715383708477

Epoch: 5| Step: 4
Training loss: 0.6113337874412537
Validation loss: 2.229058191180229

Epoch: 5| Step: 5
Training loss: 0.4070274233818054
Validation loss: 2.286730647087097

Epoch: 5| Step: 6
Training loss: 0.5434892773628235
Validation loss: 2.281089315811793

Epoch: 5| Step: 7
Training loss: 0.9790691137313843
Validation loss: 2.262637491027514

Epoch: 5| Step: 8
Training loss: 0.5579728484153748
Validation loss: 2.3087970664103827

Epoch: 5| Step: 9
Training loss: 0.6102045178413391
Validation loss: 2.32602488497893

Epoch: 5| Step: 10
Training loss: 0.42908579111099243
Validation loss: 2.2776276071866355

Epoch: 5| Step: 11
Training loss: 0.3330076336860657
Validation loss: 2.2266558905442557

Epoch: 289| Step: 0
Training loss: 0.46553468704223633
Validation loss: 2.2860367745161057

Epoch: 5| Step: 1
Training loss: 0.8344860076904297
Validation loss: 2.2511580983797708

Epoch: 5| Step: 2
Training loss: 0.5963643193244934
Validation loss: 2.2428002754847207

Epoch: 5| Step: 3
Training loss: 0.36580976843833923
Validation loss: 2.2924815515677133

Epoch: 5| Step: 4
Training loss: 0.4015219807624817
Validation loss: 2.279491196076075

Epoch: 5| Step: 5
Training loss: 0.4291895925998688
Validation loss: 2.2668447395165763

Epoch: 5| Step: 6
Training loss: 0.5515499114990234
Validation loss: 2.3014696339766183

Epoch: 5| Step: 7
Training loss: 1.1698925495147705
Validation loss: 2.2186252822478614

Epoch: 5| Step: 8
Training loss: 0.39175552129745483
Validation loss: 2.325378422935804

Epoch: 5| Step: 9
Training loss: 0.6094917058944702
Validation loss: 2.2383205691973367

Epoch: 5| Step: 10
Training loss: 0.6321094632148743
Validation loss: 2.2906724959611893

Epoch: 5| Step: 11
Training loss: 0.7729942798614502
Validation loss: 2.2670208513736725

Epoch: 290| Step: 0
Training loss: 0.866351306438446
Validation loss: 2.2769728899002075

Epoch: 5| Step: 1
Training loss: 0.48126134276390076
Validation loss: 2.299062192440033

Epoch: 5| Step: 2
Training loss: 0.8229125738143921
Validation loss: 2.2894353667894998

Epoch: 5| Step: 3
Training loss: 0.572799026966095
Validation loss: 2.248508801062902

Epoch: 5| Step: 4
Training loss: 0.48832646012306213
Validation loss: 2.288727656006813

Epoch: 5| Step: 5
Training loss: 0.6116093397140503
Validation loss: 2.3162512481212616

Epoch: 5| Step: 6
Training loss: 0.7053501009941101
Validation loss: 2.342432752251625

Epoch: 5| Step: 7
Training loss: 0.32732945680618286
Validation loss: 2.25190436343352

Epoch: 5| Step: 8
Training loss: 0.46237725019454956
Validation loss: 2.3173092901706696

Epoch: 5| Step: 9
Training loss: 0.47337213158607483
Validation loss: 2.3093678603569665

Epoch: 5| Step: 10
Training loss: 0.9040327072143555
Validation loss: 2.3401566594839096

Epoch: 5| Step: 11
Training loss: 0.3740376830101013
Validation loss: 2.3333865106105804

Epoch: 291| Step: 0
Training loss: 0.5455023050308228
Validation loss: 2.3905154863993325

Epoch: 5| Step: 1
Training loss: 0.7641396522521973
Validation loss: 2.3710762163003287

Epoch: 5| Step: 2
Training loss: 1.1747801303863525
Validation loss: 2.3256130615870156

Epoch: 5| Step: 3
Training loss: 0.5266932845115662
Validation loss: 2.36488730708758

Epoch: 5| Step: 4
Training loss: 0.9208003282546997
Validation loss: 2.3180418610572815

Epoch: 5| Step: 5
Training loss: 0.6979109644889832
Validation loss: 2.298961599667867

Epoch: 5| Step: 6
Training loss: 0.4146500527858734
Validation loss: 2.3232283194859824

Epoch: 5| Step: 7
Training loss: 0.4238186478614807
Validation loss: 2.285240183273951

Epoch: 5| Step: 8
Training loss: 0.48860111832618713
Validation loss: 2.358014702796936

Epoch: 5| Step: 9
Training loss: 0.5018438100814819
Validation loss: 2.3734102050463357

Epoch: 5| Step: 10
Training loss: 0.4449625015258789
Validation loss: 2.3385843137900033

Epoch: 5| Step: 11
Training loss: 0.31972599029541016
Validation loss: 2.304142485062281

Epoch: 292| Step: 0
Training loss: 0.31697335839271545
Validation loss: 2.286933739980062

Epoch: 5| Step: 1
Training loss: 0.7706432938575745
Validation loss: 2.316423535346985

Epoch: 5| Step: 2
Training loss: 0.5375046133995056
Validation loss: 2.284937411546707

Epoch: 5| Step: 3
Training loss: 0.3511626124382019
Validation loss: 2.349489072958628

Epoch: 5| Step: 4
Training loss: 0.43760451674461365
Validation loss: 2.3468424131472907

Epoch: 5| Step: 5
Training loss: 0.8568207025527954
Validation loss: 2.3026565313339233

Epoch: 5| Step: 6
Training loss: 0.702243447303772
Validation loss: 2.370040774345398

Epoch: 5| Step: 7
Training loss: 0.7231847643852234
Validation loss: 2.3009514113267264

Epoch: 5| Step: 8
Training loss: 0.5778205990791321
Validation loss: 2.3479359298944473

Epoch: 5| Step: 9
Training loss: 0.4714903235435486
Validation loss: 2.328120435277621

Epoch: 5| Step: 10
Training loss: 0.6164251565933228
Validation loss: 2.3053730676571527

Epoch: 5| Step: 11
Training loss: 0.3745279908180237
Validation loss: 2.3300801465908685

Epoch: 293| Step: 0
Training loss: 0.6042631268501282
Validation loss: 2.3214846750100455

Epoch: 5| Step: 1
Training loss: 0.7465659976005554
Validation loss: 2.305504490931829

Epoch: 5| Step: 2
Training loss: 0.6697965860366821
Validation loss: 2.2600997338692346

Epoch: 5| Step: 3
Training loss: 0.9326927065849304
Validation loss: 2.265643129746119

Epoch: 5| Step: 4
Training loss: 0.5778856873512268
Validation loss: 2.2976218909025192

Epoch: 5| Step: 5
Training loss: 0.5907515287399292
Validation loss: 2.307149921854337

Epoch: 5| Step: 6
Training loss: 0.45366907119750977
Validation loss: 2.3175538927316666

Epoch: 5| Step: 7
Training loss: 0.3584742844104767
Validation loss: 2.314019868771235

Epoch: 5| Step: 8
Training loss: 0.3765965402126312
Validation loss: 2.2812795639038086

Epoch: 5| Step: 9
Training loss: 0.42894354462623596
Validation loss: 2.2901527285575867

Epoch: 5| Step: 10
Training loss: 0.6365874409675598
Validation loss: 2.235803266366323

Epoch: 5| Step: 11
Training loss: 0.5234470367431641
Validation loss: 2.3088392366965613

Epoch: 294| Step: 0
Training loss: 0.48954659700393677
Validation loss: 2.297202850381533

Epoch: 5| Step: 1
Training loss: 0.7612668871879578
Validation loss: 2.3309969107309976

Epoch: 5| Step: 2
Training loss: 0.5700780749320984
Validation loss: 2.361320490638415

Epoch: 5| Step: 3
Training loss: 0.5359948873519897
Validation loss: 2.317591885725657

Epoch: 5| Step: 4
Training loss: 0.2373875379562378
Validation loss: 2.322285314400991

Epoch: 5| Step: 5
Training loss: 0.7404569387435913
Validation loss: 2.270662854115168

Epoch: 5| Step: 6
Training loss: 0.5788875222206116
Validation loss: 2.2627327938874564

Epoch: 5| Step: 7
Training loss: 0.7303348779678345
Validation loss: 2.304499755303065

Epoch: 5| Step: 8
Training loss: 0.9734376072883606
Validation loss: 2.2577074021101

Epoch: 5| Step: 9
Training loss: 0.6968023777008057
Validation loss: 2.319553852081299

Epoch: 5| Step: 10
Training loss: 0.3554140627384186
Validation loss: 2.309059197703997

Epoch: 5| Step: 11
Training loss: 0.060965120792388916
Validation loss: 2.264147957166036

Epoch: 295| Step: 0
Training loss: 1.1319466829299927
Validation loss: 2.313502868016561

Epoch: 5| Step: 1
Training loss: 0.5311063528060913
Validation loss: 2.2587428092956543

Epoch: 5| Step: 2
Training loss: 0.37482911348342896
Validation loss: 2.290147046248118

Epoch: 5| Step: 3
Training loss: 0.5548245906829834
Validation loss: 2.2621305882930756

Epoch: 5| Step: 4
Training loss: 0.2553871273994446
Validation loss: 2.2766167322794595

Epoch: 5| Step: 5
Training loss: 0.45825377106666565
Validation loss: 2.3045666416486106

Epoch: 5| Step: 6
Training loss: 0.6742674708366394
Validation loss: 2.306029886007309

Epoch: 5| Step: 7
Training loss: 0.4777095317840576
Validation loss: 2.3396201183398566

Epoch: 5| Step: 8
Training loss: 0.6555286049842834
Validation loss: 2.331361542145411

Epoch: 5| Step: 9
Training loss: 0.7763339877128601
Validation loss: 2.3070792158444724

Epoch: 5| Step: 10
Training loss: 0.6783744096755981
Validation loss: 2.325438608725866

Epoch: 5| Step: 11
Training loss: 0.5559678077697754
Validation loss: 2.2412289728720984

Epoch: 296| Step: 0
Training loss: 0.4793553352355957
Validation loss: 2.288141886393229

Epoch: 5| Step: 1
Training loss: 0.2633465826511383
Validation loss: 2.2736628452936807

Epoch: 5| Step: 2
Training loss: 0.6128203272819519
Validation loss: 2.3490082919597626

Epoch: 5| Step: 3
Training loss: 0.3355998396873474
Validation loss: 2.2341565787792206

Epoch: 5| Step: 4
Training loss: 0.7465814352035522
Validation loss: 2.2738578617572784

Epoch: 5| Step: 5
Training loss: 0.41307997703552246
Validation loss: 2.292859971523285

Epoch: 5| Step: 6
Training loss: 0.6659195423126221
Validation loss: 2.24832255144914

Epoch: 5| Step: 7
Training loss: 0.9626548886299133
Validation loss: 2.2928192069133124

Epoch: 5| Step: 8
Training loss: 0.6500316858291626
Validation loss: 2.284397413333257

Epoch: 5| Step: 9
Training loss: 0.4028424322605133
Validation loss: 2.3169332842032113

Epoch: 5| Step: 10
Training loss: 0.4691106379032135
Validation loss: 2.3220703502496085

Epoch: 5| Step: 11
Training loss: 1.488910436630249
Validation loss: 2.2764702836672464

Epoch: 297| Step: 0
Training loss: 0.334414541721344
Validation loss: 2.309532026449839

Epoch: 5| Step: 1
Training loss: 0.3927810788154602
Validation loss: 2.3144810497760773

Epoch: 5| Step: 2
Training loss: 0.4769801199436188
Validation loss: 2.275610605875651

Epoch: 5| Step: 3
Training loss: 0.6432338953018188
Validation loss: 2.2878042260805764

Epoch: 5| Step: 4
Training loss: 0.8222432136535645
Validation loss: 2.275912324587504

Epoch: 5| Step: 5
Training loss: 0.3045220971107483
Validation loss: 2.2841036170721054

Epoch: 5| Step: 6
Training loss: 0.6135085225105286
Validation loss: 2.29620523750782

Epoch: 5| Step: 7
Training loss: 0.8857194185256958
Validation loss: 2.2917875548203788

Epoch: 5| Step: 8
Training loss: 0.570573091506958
Validation loss: 2.34614160656929

Epoch: 5| Step: 9
Training loss: 0.49119657278060913
Validation loss: 2.2481190462907157

Epoch: 5| Step: 10
Training loss: 1.018019199371338
Validation loss: 2.283067435026169

Epoch: 5| Step: 11
Training loss: 0.22979624569416046
Validation loss: 2.285903215408325

Epoch: 298| Step: 0
Training loss: 0.7014438509941101
Validation loss: 2.269284357627233

Epoch: 5| Step: 1
Training loss: 0.8592826724052429
Validation loss: 2.3041420678297677

Epoch: 5| Step: 2
Training loss: 0.7176152467727661
Validation loss: 2.3086946656306586

Epoch: 5| Step: 3
Training loss: 0.7839527130126953
Validation loss: 2.2570578853289285

Epoch: 5| Step: 4
Training loss: 0.5956894755363464
Validation loss: 2.347544858853022

Epoch: 5| Step: 5
Training loss: 0.44502371549606323
Validation loss: 2.270060658454895

Epoch: 5| Step: 6
Training loss: 0.39531105756759644
Validation loss: 2.274391214052836

Epoch: 5| Step: 7
Training loss: 0.5025513768196106
Validation loss: 2.2872968862454095

Epoch: 5| Step: 8
Training loss: 0.8336579203605652
Validation loss: 2.3358332266410193

Epoch: 5| Step: 9
Training loss: 0.6117909550666809
Validation loss: 2.2481061468521752

Epoch: 5| Step: 10
Training loss: 0.33896979689598083
Validation loss: 2.2882922490437827

Epoch: 5| Step: 11
Training loss: 0.24725860357284546
Validation loss: 2.4286849896113076

Epoch: 299| Step: 0
Training loss: 0.46803539991378784
Validation loss: 2.294214184085528

Epoch: 5| Step: 1
Training loss: 0.8663192987442017
Validation loss: 2.3460106352965036

Epoch: 5| Step: 2
Training loss: 0.7991330027580261
Validation loss: 2.2989079107840857

Epoch: 5| Step: 3
Training loss: 0.5078301429748535
Validation loss: 2.240868697563807

Epoch: 5| Step: 4
Training loss: 0.29056835174560547
Validation loss: 2.288637638092041

Epoch: 5| Step: 5
Training loss: 0.7314306497573853
Validation loss: 2.2906129360198975

Epoch: 5| Step: 6
Training loss: 0.6935351490974426
Validation loss: 2.3515058358510337

Epoch: 5| Step: 7
Training loss: 0.7518346905708313
Validation loss: 2.2974309821923575

Epoch: 5| Step: 8
Training loss: 0.7775779962539673
Validation loss: 2.3490311900774636

Epoch: 5| Step: 9
Training loss: 0.3453889489173889
Validation loss: 2.2808789809544883

Epoch: 5| Step: 10
Training loss: 0.5236452221870422
Validation loss: 2.3669816305239997

Epoch: 5| Step: 11
Training loss: 0.9533283710479736
Validation loss: 2.261137823263804

Epoch: 300| Step: 0
Training loss: 0.6792541146278381
Validation loss: 2.2986074686050415

Epoch: 5| Step: 1
Training loss: 0.41712528467178345
Validation loss: 2.2192251880963645

Epoch: 5| Step: 2
Training loss: 0.7049817442893982
Validation loss: 2.3061059514681497

Epoch: 5| Step: 3
Training loss: 0.5645267367362976
Validation loss: 2.313493549823761

Epoch: 5| Step: 4
Training loss: 0.48146018385887146
Validation loss: 2.308202604452769

Epoch: 5| Step: 5
Training loss: 0.5712556838989258
Validation loss: 2.293759028116862

Epoch: 5| Step: 6
Training loss: 0.4858655035495758
Validation loss: 2.269688089688619

Epoch: 5| Step: 7
Training loss: 0.809370219707489
Validation loss: 2.264091963569323

Epoch: 5| Step: 8
Training loss: 0.3461110591888428
Validation loss: 2.3064183791478476

Epoch: 5| Step: 9
Training loss: 0.7058203220367432
Validation loss: 2.312951609492302

Epoch: 5| Step: 10
Training loss: 0.7510467767715454
Validation loss: 2.331717997789383

Epoch: 5| Step: 11
Training loss: 0.3301163911819458
Validation loss: 2.3024593790372214

Epoch: 301| Step: 0
Training loss: 0.28216853737831116
Validation loss: 2.27951588233312

Epoch: 5| Step: 1
Training loss: 0.6470533013343811
Validation loss: 2.267648776372274

Epoch: 5| Step: 2
Training loss: 0.6363412737846375
Validation loss: 2.289322634538015

Epoch: 5| Step: 3
Training loss: 0.5278877019882202
Validation loss: 2.242263893286387

Epoch: 5| Step: 4
Training loss: 0.9326418042182922
Validation loss: 2.226388399799665

Epoch: 5| Step: 5
Training loss: 0.4681968092918396
Validation loss: 2.2935931980609894

Epoch: 5| Step: 6
Training loss: 0.6833341717720032
Validation loss: 2.2512568881114325

Epoch: 5| Step: 7
Training loss: 0.47601932287216187
Validation loss: 2.3142189582188926

Epoch: 5| Step: 8
Training loss: 0.7780212163925171
Validation loss: 2.3069741874933243

Epoch: 5| Step: 9
Training loss: 0.5070996284484863
Validation loss: 2.3042535483837128

Epoch: 5| Step: 10
Training loss: 0.5514717102050781
Validation loss: 2.2876219948132834

Epoch: 5| Step: 11
Training loss: 0.37970179319381714
Validation loss: 2.2891588111718497

Epoch: 302| Step: 0
Training loss: 0.5918415188789368
Validation loss: 2.2623081455628076

Epoch: 5| Step: 1
Training loss: 0.48446136713027954
Validation loss: 2.288767491777738

Epoch: 5| Step: 2
Training loss: 0.7739656567573547
Validation loss: 2.2863659312327704

Epoch: 5| Step: 3
Training loss: 0.9233018159866333
Validation loss: 2.2772174378236136

Epoch: 5| Step: 4
Training loss: 0.5325848460197449
Validation loss: 2.365840196609497

Epoch: 5| Step: 5
Training loss: 0.8592208623886108
Validation loss: 2.2929576138655343

Epoch: 5| Step: 6
Training loss: 0.6285201907157898
Validation loss: 2.266320119301478

Epoch: 5| Step: 7
Training loss: 0.6534875631332397
Validation loss: 2.316801071166992

Epoch: 5| Step: 8
Training loss: 1.078332543373108
Validation loss: 2.3750945826371512

Epoch: 5| Step: 9
Training loss: 0.2799416482448578
Validation loss: 2.291934276620547

Epoch: 5| Step: 10
Training loss: 0.5148404240608215
Validation loss: 2.315382108092308

Epoch: 5| Step: 11
Training loss: 0.24920040369033813
Validation loss: 2.365341007709503

Epoch: 303| Step: 0
Training loss: 0.6568058729171753
Validation loss: 2.2900871286789575

Epoch: 5| Step: 1
Training loss: 0.8125377893447876
Validation loss: 2.323550055424372

Epoch: 5| Step: 2
Training loss: 0.5100703239440918
Validation loss: 2.3182297001282373

Epoch: 5| Step: 3
Training loss: 0.9564207792282104
Validation loss: 2.2653049329916635

Epoch: 5| Step: 4
Training loss: 0.5943011045455933
Validation loss: 2.224349250396093

Epoch: 5| Step: 5
Training loss: 0.42818355560302734
Validation loss: 2.312129408121109

Epoch: 5| Step: 6
Training loss: 0.4399212896823883
Validation loss: 2.2552034705877304

Epoch: 5| Step: 7
Training loss: 0.6714344620704651
Validation loss: 2.2424495816230774

Epoch: 5| Step: 8
Training loss: 0.5118122100830078
Validation loss: 2.2847215235233307

Epoch: 5| Step: 9
Training loss: 0.7107461094856262
Validation loss: 2.2889540990193686

Epoch: 5| Step: 10
Training loss: 0.32483649253845215
Validation loss: 2.3164255917072296

Epoch: 5| Step: 11
Training loss: 0.5880980491638184
Validation loss: 2.262154514590899

Epoch: 304| Step: 0
Training loss: 0.5913128852844238
Validation loss: 2.3037767161925635

Epoch: 5| Step: 1
Training loss: 0.3842465281486511
Validation loss: 2.266959011554718

Epoch: 5| Step: 2
Training loss: 0.6701374053955078
Validation loss: 2.239256888628006

Epoch: 5| Step: 3
Training loss: 0.5315718650817871
Validation loss: 2.2800441881020865

Epoch: 5| Step: 4
Training loss: 0.4322423040866852
Validation loss: 2.288083076477051

Epoch: 5| Step: 5
Training loss: 0.8203853368759155
Validation loss: 2.3169654111067453

Epoch: 5| Step: 6
Training loss: 0.3895261287689209
Validation loss: 2.254977434873581

Epoch: 5| Step: 7
Training loss: 0.6042969822883606
Validation loss: 2.267956336339315

Epoch: 5| Step: 8
Training loss: 0.5164312124252319
Validation loss: 2.2689125786225

Epoch: 5| Step: 9
Training loss: 0.9446552395820618
Validation loss: 2.2543065945307412

Epoch: 5| Step: 10
Training loss: 0.5917684435844421
Validation loss: 2.2761908968289695

Epoch: 5| Step: 11
Training loss: 0.5617842078208923
Validation loss: 2.320561488469442

Epoch: 305| Step: 0
Training loss: 0.5076781511306763
Validation loss: 2.2446811199188232

Epoch: 5| Step: 1
Training loss: 1.079146385192871
Validation loss: 2.247599979241689

Epoch: 5| Step: 2
Training loss: 0.6223332285881042
Validation loss: 2.2540620962778726

Epoch: 5| Step: 3
Training loss: 0.509351372718811
Validation loss: 2.2956389784812927

Epoch: 5| Step: 4
Training loss: 0.5136275291442871
Validation loss: 2.291795566678047

Epoch: 5| Step: 5
Training loss: 0.417367547750473
Validation loss: 2.2560163736343384

Epoch: 5| Step: 6
Training loss: 0.4170243740081787
Validation loss: 2.2457972317934036

Epoch: 5| Step: 7
Training loss: 0.7194382548332214
Validation loss: 2.3050481329361596

Epoch: 5| Step: 8
Training loss: 0.4792725145816803
Validation loss: 2.233628496527672

Epoch: 5| Step: 9
Training loss: 0.8443126678466797
Validation loss: 2.222927321990331

Epoch: 5| Step: 10
Training loss: 0.44647783041000366
Validation loss: 2.3744789212942123

Epoch: 5| Step: 11
Training loss: 0.2743295431137085
Validation loss: 2.3060064216454825

Epoch: 306| Step: 0
Training loss: 0.4862174093723297
Validation loss: 2.3205875356992087

Epoch: 5| Step: 1
Training loss: 0.2703549563884735
Validation loss: 2.2285432716210685

Epoch: 5| Step: 2
Training loss: 0.7275475263595581
Validation loss: 2.276071925957998

Epoch: 5| Step: 3
Training loss: 0.9791944622993469
Validation loss: 2.245882123708725

Epoch: 5| Step: 4
Training loss: 0.3348122835159302
Validation loss: 2.2831400086482367

Epoch: 5| Step: 5
Training loss: 0.6129657030105591
Validation loss: 2.2564704517523446

Epoch: 5| Step: 6
Training loss: 0.5015937089920044
Validation loss: 2.2867194215456643

Epoch: 5| Step: 7
Training loss: 0.5601769685745239
Validation loss: 2.235635628302892

Epoch: 5| Step: 8
Training loss: 0.7036916017532349
Validation loss: 2.2214151322841644

Epoch: 5| Step: 9
Training loss: 0.4059824049472809
Validation loss: 2.2724337677160897

Epoch: 5| Step: 10
Training loss: 0.5992921590805054
Validation loss: 2.3151304771502814

Epoch: 5| Step: 11
Training loss: 0.8648905754089355
Validation loss: 2.32280624906222

Epoch: 307| Step: 0
Training loss: 0.5510581135749817
Validation loss: 2.2705165346463523

Epoch: 5| Step: 1
Training loss: 0.5274657011032104
Validation loss: 2.296320845683416

Epoch: 5| Step: 2
Training loss: 0.5172792673110962
Validation loss: 2.3507846295833588

Epoch: 5| Step: 3
Training loss: 0.47767263650894165
Validation loss: 2.2923336923122406

Epoch: 5| Step: 4
Training loss: 0.6781474351882935
Validation loss: 2.29932177066803

Epoch: 5| Step: 5
Training loss: 0.4083564877510071
Validation loss: 2.2837840418020883

Epoch: 5| Step: 6
Training loss: 0.5263757705688477
Validation loss: 2.302354092399279

Epoch: 5| Step: 7
Training loss: 0.36861512064933777
Validation loss: 2.2821762561798096

Epoch: 5| Step: 8
Training loss: 0.4816834330558777
Validation loss: 2.3286011268695197

Epoch: 5| Step: 9
Training loss: 0.6777585744857788
Validation loss: 2.3135241816441217

Epoch: 5| Step: 10
Training loss: 0.794716477394104
Validation loss: 2.2712876747051873

Epoch: 5| Step: 11
Training loss: 0.471624493598938
Validation loss: 2.3216901222864785

Epoch: 308| Step: 0
Training loss: 0.5448629856109619
Validation loss: 2.260093614459038

Epoch: 5| Step: 1
Training loss: 0.5414737462997437
Validation loss: 2.357117384672165

Epoch: 5| Step: 2
Training loss: 0.4782811105251312
Validation loss: 2.2881161868572235

Epoch: 5| Step: 3
Training loss: 0.5660150647163391
Validation loss: 2.228527774413427

Epoch: 5| Step: 4
Training loss: 0.5918490886688232
Validation loss: 2.3251169323921204

Epoch: 5| Step: 5
Training loss: 0.4857618808746338
Validation loss: 2.2937334179878235

Epoch: 5| Step: 6
Training loss: 0.6330598592758179
Validation loss: 2.3366690576076508

Epoch: 5| Step: 7
Training loss: 0.37239858508110046
Validation loss: 2.2950436721245446

Epoch: 5| Step: 8
Training loss: 0.9797279238700867
Validation loss: 2.315233131249746

Epoch: 5| Step: 9
Training loss: 0.6370137929916382
Validation loss: 2.3113980988661447

Epoch: 5| Step: 10
Training loss: 0.5637105703353882
Validation loss: 2.274076819419861

Epoch: 5| Step: 11
Training loss: 0.3459851145744324
Validation loss: 2.3405928015708923

Epoch: 309| Step: 0
Training loss: 0.3766917586326599
Validation loss: 2.2444835851589837

Epoch: 5| Step: 1
Training loss: 0.5564115643501282
Validation loss: 2.3017952938874564

Epoch: 5| Step: 2
Training loss: 0.3612247705459595
Validation loss: 2.310261696577072

Epoch: 5| Step: 3
Training loss: 1.0327184200286865
Validation loss: 2.2824805974960327

Epoch: 5| Step: 4
Training loss: 0.5275602340698242
Validation loss: 2.2947326004505157

Epoch: 5| Step: 5
Training loss: 0.5489517450332642
Validation loss: 2.306886245807012

Epoch: 5| Step: 6
Training loss: 0.3456957936286926
Validation loss: 2.255241791407267

Epoch: 5| Step: 7
Training loss: 0.25654345750808716
Validation loss: 2.3114974995454154

Epoch: 5| Step: 8
Training loss: 0.6151583790779114
Validation loss: 2.2382264733314514

Epoch: 5| Step: 9
Training loss: 0.7533049583435059
Validation loss: 2.2757487148046494

Epoch: 5| Step: 10
Training loss: 0.7541905641555786
Validation loss: 2.316468815008799

Epoch: 5| Step: 11
Training loss: 0.2717154026031494
Validation loss: 2.3011166055997214

Epoch: 310| Step: 0
Training loss: 0.5169917345046997
Validation loss: 2.261930207411448

Epoch: 5| Step: 1
Training loss: 0.7228940725326538
Validation loss: 2.2836541483799615

Epoch: 5| Step: 2
Training loss: 0.3064229488372803
Validation loss: 2.314562574028969

Epoch: 5| Step: 3
Training loss: 0.3188970983028412
Validation loss: 2.2500113944212594

Epoch: 5| Step: 4
Training loss: 0.5179351568222046
Validation loss: 2.199444830417633

Epoch: 5| Step: 5
Training loss: 0.552392303943634
Validation loss: 2.213690996170044

Epoch: 5| Step: 6
Training loss: 0.2845286726951599
Validation loss: 2.264630933602651

Epoch: 5| Step: 7
Training loss: 0.4358062148094177
Validation loss: 2.2412073016166687

Epoch: 5| Step: 8
Training loss: 0.6160576343536377
Validation loss: 2.3015915850798288

Epoch: 5| Step: 9
Training loss: 0.6571400761604309
Validation loss: 2.295910487572352

Epoch: 5| Step: 10
Training loss: 0.9898754358291626
Validation loss: 2.2589958806832633

Epoch: 5| Step: 11
Training loss: 0.41442811489105225
Validation loss: 2.287954996029536

Epoch: 311| Step: 0
Training loss: 0.5611748695373535
Validation loss: 2.2993571708599725

Epoch: 5| Step: 1
Training loss: 0.4904695153236389
Validation loss: 2.2843884428342185

Epoch: 5| Step: 2
Training loss: 0.4577266573905945
Validation loss: 2.2820775657892227

Epoch: 5| Step: 3
Training loss: 0.44487467408180237
Validation loss: 2.255049223701159

Epoch: 5| Step: 4
Training loss: 0.5519258379936218
Validation loss: 2.294070820013682

Epoch: 5| Step: 5
Training loss: 0.5905502438545227
Validation loss: 2.2959629545609155

Epoch: 5| Step: 6
Training loss: 0.5787595510482788
Validation loss: 2.295355329910914

Epoch: 5| Step: 7
Training loss: 0.27077925205230713
Validation loss: 2.2960100372632346

Epoch: 5| Step: 8
Training loss: 0.6287326812744141
Validation loss: 2.3262797445058823

Epoch: 5| Step: 9
Training loss: 0.4359586238861084
Validation loss: 2.3424547811349234

Epoch: 5| Step: 10
Training loss: 0.9610328674316406
Validation loss: 2.285650839408239

Epoch: 5| Step: 11
Training loss: 0.790316104888916
Validation loss: 2.304274410009384

Epoch: 312| Step: 0
Training loss: 0.5280845761299133
Validation loss: 2.3055787881215415

Epoch: 5| Step: 1
Training loss: 0.5948292016983032
Validation loss: 2.3638561964035034

Epoch: 5| Step: 2
Training loss: 1.0350337028503418
Validation loss: 2.330408215522766

Epoch: 5| Step: 3
Training loss: 0.5777478218078613
Validation loss: 2.272123376528422

Epoch: 5| Step: 4
Training loss: 0.5150183439254761
Validation loss: 2.3169479767481485

Epoch: 5| Step: 5
Training loss: 0.47012925148010254
Validation loss: 2.24699596563975

Epoch: 5| Step: 6
Training loss: 0.5358473062515259
Validation loss: 2.2763373255729675

Epoch: 5| Step: 7
Training loss: 0.5028018355369568
Validation loss: 2.3093874156475067

Epoch: 5| Step: 8
Training loss: 0.39644354581832886
Validation loss: 2.279918819665909

Epoch: 5| Step: 9
Training loss: 0.8429883718490601
Validation loss: 2.2822566280762353

Epoch: 5| Step: 10
Training loss: 0.5997213125228882
Validation loss: 2.3117966800928116

Epoch: 5| Step: 11
Training loss: 0.9808387160301208
Validation loss: 2.223120699326197

Epoch: 313| Step: 0
Training loss: 0.41498756408691406
Validation loss: 2.2353796660900116

Epoch: 5| Step: 1
Training loss: 0.7758670449256897
Validation loss: 2.228537231683731

Epoch: 5| Step: 2
Training loss: 0.4868198335170746
Validation loss: 2.2751839558283486

Epoch: 5| Step: 3
Training loss: 0.36810511350631714
Validation loss: 2.325613925854365

Epoch: 5| Step: 4
Training loss: 0.5741470456123352
Validation loss: 2.2868844966093698

Epoch: 5| Step: 5
Training loss: 0.41072121262550354
Validation loss: 2.30251881480217

Epoch: 5| Step: 6
Training loss: 0.33430153131484985
Validation loss: 2.2567875385284424

Epoch: 5| Step: 7
Training loss: 0.38313931226730347
Validation loss: 2.2819023778041205

Epoch: 5| Step: 8
Training loss: 0.8102075457572937
Validation loss: 2.2471056381861367

Epoch: 5| Step: 9
Training loss: 0.8286789059638977
Validation loss: 2.2968954294919968

Epoch: 5| Step: 10
Training loss: 0.49767884612083435
Validation loss: 2.305526370803515

Epoch: 5| Step: 11
Training loss: 0.6447920799255371
Validation loss: 2.299810374776522

Epoch: 314| Step: 0
Training loss: 0.6165964007377625
Validation loss: 2.241696904102961

Epoch: 5| Step: 1
Training loss: 0.441672146320343
Validation loss: 2.247155010700226

Epoch: 5| Step: 2
Training loss: 0.5078858137130737
Validation loss: 2.2775560468435287

Epoch: 5| Step: 3
Training loss: 0.8925619125366211
Validation loss: 2.26108048359553

Epoch: 5| Step: 4
Training loss: 0.3737570345401764
Validation loss: 2.298240358630816

Epoch: 5| Step: 5
Training loss: 0.4310854971408844
Validation loss: 2.2342205146948495

Epoch: 5| Step: 6
Training loss: 0.39939337968826294
Validation loss: 2.191492552558581

Epoch: 5| Step: 7
Training loss: 0.4900645613670349
Validation loss: 2.292892018953959

Epoch: 5| Step: 8
Training loss: 0.7904015779495239
Validation loss: 2.234700933098793

Epoch: 5| Step: 9
Training loss: 0.6745584011077881
Validation loss: 2.256594732403755

Epoch: 5| Step: 10
Training loss: 0.49733105301856995
Validation loss: 2.272557487090429

Epoch: 5| Step: 11
Training loss: 0.22500914335250854
Validation loss: 2.2263116339842477

Epoch: 315| Step: 0
Training loss: 0.5666326880455017
Validation loss: 2.2522106617689133

Epoch: 5| Step: 1
Training loss: 0.7752903699874878
Validation loss: 2.3062167167663574

Epoch: 5| Step: 2
Training loss: 0.6872687339782715
Validation loss: 2.282658666372299

Epoch: 5| Step: 3
Training loss: 0.46639710664749146
Validation loss: 2.357957790295283

Epoch: 5| Step: 4
Training loss: 0.6484581828117371
Validation loss: 2.3064931333065033

Epoch: 5| Step: 5
Training loss: 0.557696521282196
Validation loss: 2.2871539493401847

Epoch: 5| Step: 6
Training loss: 0.4721156656742096
Validation loss: 2.259077087044716

Epoch: 5| Step: 7
Training loss: 0.3467082977294922
Validation loss: 2.3104603985945382

Epoch: 5| Step: 8
Training loss: 0.5588510036468506
Validation loss: 2.345755934715271

Epoch: 5| Step: 9
Training loss: 0.569523811340332
Validation loss: 2.214117685953776

Epoch: 5| Step: 10
Training loss: 0.7302943468093872
Validation loss: 2.2532750765482583

Epoch: 5| Step: 11
Training loss: 0.3289092779159546
Validation loss: 2.2585531026124954

Epoch: 316| Step: 0
Training loss: 0.6952967643737793
Validation loss: 2.3390680253505707

Epoch: 5| Step: 1
Training loss: 0.3928980529308319
Validation loss: 2.3201208213965097

Epoch: 5| Step: 2
Training loss: 0.8805097341537476
Validation loss: 2.3013790945212045

Epoch: 5| Step: 3
Training loss: 0.6190744042396545
Validation loss: 2.3667446821928024

Epoch: 5| Step: 4
Training loss: 0.5158067941665649
Validation loss: 2.3362968464692435

Epoch: 5| Step: 5
Training loss: 0.4980192184448242
Validation loss: 2.234131167332331

Epoch: 5| Step: 6
Training loss: 0.5478898286819458
Validation loss: 2.28792596856753

Epoch: 5| Step: 7
Training loss: 0.6425718665122986
Validation loss: 2.259924645225207

Epoch: 5| Step: 8
Training loss: 0.634790301322937
Validation loss: 2.3080392877260842

Epoch: 5| Step: 9
Training loss: 0.8527454137802124
Validation loss: 2.2881647050380707

Epoch: 5| Step: 10
Training loss: 0.793081521987915
Validation loss: 2.2793271442254386

Epoch: 5| Step: 11
Training loss: 0.23111103475093842
Validation loss: 2.3004817068576813

Epoch: 317| Step: 0
Training loss: 0.615982174873352
Validation loss: 2.3312853972117105

Epoch: 5| Step: 1
Training loss: 0.3911348283290863
Validation loss: 2.2570673724015555

Epoch: 5| Step: 2
Training loss: 0.28060001134872437
Validation loss: 2.3480735421180725

Epoch: 5| Step: 3
Training loss: 0.5010128617286682
Validation loss: 2.343122273683548

Epoch: 5| Step: 4
Training loss: 0.6996639966964722
Validation loss: 2.3394958774248757

Epoch: 5| Step: 5
Training loss: 0.375814288854599
Validation loss: 2.3093575487534204

Epoch: 5| Step: 6
Training loss: 0.3389037251472473
Validation loss: 2.2621895372867584

Epoch: 5| Step: 7
Training loss: 0.443838506937027
Validation loss: 2.301907698313395

Epoch: 5| Step: 8
Training loss: 0.4037521481513977
Validation loss: 2.2453533162673316

Epoch: 5| Step: 9
Training loss: 0.8660532832145691
Validation loss: 2.2488958487908044

Epoch: 5| Step: 10
Training loss: 0.6057072877883911
Validation loss: 2.3411961098512015

Epoch: 5| Step: 11
Training loss: 0.9818274974822998
Validation loss: 2.2746813545624414

Epoch: 318| Step: 0
Training loss: 0.49312925338745117
Validation loss: 2.3124434550603232

Epoch: 5| Step: 1
Training loss: 0.6317322850227356
Validation loss: 2.2059624393781028

Epoch: 5| Step: 2
Training loss: 0.7945840954780579
Validation loss: 2.2686984638373056

Epoch: 5| Step: 3
Training loss: 0.43650150299072266
Validation loss: 2.294146945079168

Epoch: 5| Step: 4
Training loss: 0.7172936201095581
Validation loss: 2.256430452068647

Epoch: 5| Step: 5
Training loss: 0.4249970018863678
Validation loss: 2.31081560254097

Epoch: 5| Step: 6
Training loss: 0.18622246384620667
Validation loss: 2.3088985284169516

Epoch: 5| Step: 7
Training loss: 0.47198373079299927
Validation loss: 2.3912041187286377

Epoch: 5| Step: 8
Training loss: 0.6046038269996643
Validation loss: 2.307824730873108

Epoch: 5| Step: 9
Training loss: 0.5519156455993652
Validation loss: 2.2744827965895333

Epoch: 5| Step: 10
Training loss: 0.43515920639038086
Validation loss: 2.3352860808372498

Epoch: 5| Step: 11
Training loss: 0.26216429471969604
Validation loss: 2.3156436483065286

Epoch: 319| Step: 0
Training loss: 0.23830148577690125
Validation loss: 2.2937388320763907

Epoch: 5| Step: 1
Training loss: 0.5253832936286926
Validation loss: 2.3522853453954062

Epoch: 5| Step: 2
Training loss: 0.6298390030860901
Validation loss: 2.3130233138799667

Epoch: 5| Step: 3
Training loss: 0.3244699537754059
Validation loss: 2.350187510251999

Epoch: 5| Step: 4
Training loss: 0.9101369976997375
Validation loss: 2.3285351345936456

Epoch: 5| Step: 5
Training loss: 0.3692760765552521
Validation loss: 2.23732420305411

Epoch: 5| Step: 6
Training loss: 1.0217292308807373
Validation loss: 2.3091557969649634

Epoch: 5| Step: 7
Training loss: 0.44900646805763245
Validation loss: 2.2621681292851767

Epoch: 5| Step: 8
Training loss: 0.307534396648407
Validation loss: 2.3371052940686545

Epoch: 5| Step: 9
Training loss: 0.6967922449111938
Validation loss: 2.294765149553617

Epoch: 5| Step: 10
Training loss: 0.5795871615409851
Validation loss: 2.342023844520251

Epoch: 5| Step: 11
Training loss: 1.2697759866714478
Validation loss: 2.2772162655989328

Epoch: 320| Step: 0
Training loss: 0.26994308829307556
Validation loss: 2.3136767695347467

Epoch: 5| Step: 1
Training loss: 0.5002054572105408
Validation loss: 2.281010796626409

Epoch: 5| Step: 2
Training loss: 0.6163327097892761
Validation loss: 2.2928845087687173

Epoch: 5| Step: 3
Training loss: 0.263627290725708
Validation loss: 2.2846619387467704

Epoch: 5| Step: 4
Training loss: 0.9030119180679321
Validation loss: 2.273546447356542

Epoch: 5| Step: 5
Training loss: 0.3191152811050415
Validation loss: 2.306544780731201

Epoch: 5| Step: 6
Training loss: 0.6092174649238586
Validation loss: 2.320269390940666

Epoch: 5| Step: 7
Training loss: 0.6980565786361694
Validation loss: 2.3594745099544525

Epoch: 5| Step: 8
Training loss: 0.7168668508529663
Validation loss: 2.389400134483973

Epoch: 5| Step: 9
Training loss: 0.5299466252326965
Validation loss: 2.296889901161194

Epoch: 5| Step: 10
Training loss: 0.48074445128440857
Validation loss: 2.300850421190262

Epoch: 5| Step: 11
Training loss: 0.3134360909461975
Validation loss: 2.2546387364466987

Epoch: 321| Step: 0
Training loss: 0.8520391583442688
Validation loss: 2.308662990729014

Epoch: 5| Step: 1
Training loss: 0.4811039865016937
Validation loss: 2.354888767004013

Epoch: 5| Step: 2
Training loss: 0.3937515318393707
Validation loss: 2.2940765569607415

Epoch: 5| Step: 3
Training loss: 0.3553869128227234
Validation loss: 2.3384358882904053

Epoch: 5| Step: 4
Training loss: 0.6216943860054016
Validation loss: 2.3448248505592346

Epoch: 5| Step: 5
Training loss: 0.729351282119751
Validation loss: 2.2752940356731415

Epoch: 5| Step: 6
Training loss: 0.31299102306365967
Validation loss: 2.302674795190493

Epoch: 5| Step: 7
Training loss: 0.5248667001724243
Validation loss: 2.383054941892624

Epoch: 5| Step: 8
Training loss: 0.45779117941856384
Validation loss: 2.324524611234665

Epoch: 5| Step: 9
Training loss: 0.5768068432807922
Validation loss: 2.345809275905291

Epoch: 5| Step: 10
Training loss: 0.6322654485702515
Validation loss: 2.3378972162803016

Epoch: 5| Step: 11
Training loss: 0.1318681240081787
Validation loss: 2.302504524588585

Epoch: 322| Step: 0
Training loss: 0.4949030876159668
Validation loss: 2.332031379143397

Epoch: 5| Step: 1
Training loss: 0.8129613995552063
Validation loss: 2.294724995891253

Epoch: 5| Step: 2
Training loss: 0.4334566593170166
Validation loss: 2.328906108935674

Epoch: 5| Step: 3
Training loss: 0.48721450567245483
Validation loss: 2.3189043203989663

Epoch: 5| Step: 4
Training loss: 0.4172697961330414
Validation loss: 2.250768095254898

Epoch: 5| Step: 5
Training loss: 0.5001307725906372
Validation loss: 2.2611202398935952

Epoch: 5| Step: 6
Training loss: 0.63624507188797
Validation loss: 2.2788289388020835

Epoch: 5| Step: 7
Training loss: 0.445168673992157
Validation loss: 2.3121422231197357

Epoch: 5| Step: 8
Training loss: 0.4936973452568054
Validation loss: 2.301899403333664

Epoch: 5| Step: 9
Training loss: 0.6915123462677002
Validation loss: 2.3443958262602487

Epoch: 5| Step: 10
Training loss: 0.5591999888420105
Validation loss: 2.251260921359062

Epoch: 5| Step: 11
Training loss: 0.40017127990722656
Validation loss: 2.256685107946396

Epoch: 323| Step: 0
Training loss: 0.3847469687461853
Validation loss: 2.2868686616420746

Epoch: 5| Step: 1
Training loss: 0.308592289686203
Validation loss: 2.282855381568273

Epoch: 5| Step: 2
Training loss: 0.4504241943359375
Validation loss: 2.3241349260012307

Epoch: 5| Step: 3
Training loss: 0.3850734233856201
Validation loss: 2.318756173054377

Epoch: 5| Step: 4
Training loss: 0.6328395009040833
Validation loss: 2.275570124387741

Epoch: 5| Step: 5
Training loss: 0.949628472328186
Validation loss: 2.2415781915187836

Epoch: 5| Step: 6
Training loss: 0.5378857254981995
Validation loss: 2.351795494556427

Epoch: 5| Step: 7
Training loss: 0.5193713903427124
Validation loss: 2.2934802224238715

Epoch: 5| Step: 8
Training loss: 0.4098110795021057
Validation loss: 2.2729229827721915

Epoch: 5| Step: 9
Training loss: 0.5873354077339172
Validation loss: 2.307262440522512

Epoch: 5| Step: 10
Training loss: 0.7196840047836304
Validation loss: 2.3324998219807944

Epoch: 5| Step: 11
Training loss: 0.5428204536437988
Validation loss: 2.330992743372917

Epoch: 324| Step: 0
Training loss: 0.5169603228569031
Validation loss: 2.3255516986052194

Epoch: 5| Step: 1
Training loss: 0.4190944731235504
Validation loss: 2.3103883961836496

Epoch: 5| Step: 2
Training loss: 0.42605552077293396
Validation loss: 2.2563214947779975

Epoch: 5| Step: 3
Training loss: 0.7323766946792603
Validation loss: 2.3010459740956626

Epoch: 5| Step: 4
Training loss: 0.6598265171051025
Validation loss: 2.3365340381860733

Epoch: 5| Step: 5
Training loss: 0.30439823865890503
Validation loss: 2.275971179207166

Epoch: 5| Step: 6
Training loss: 0.4756576418876648
Validation loss: 2.2678149243195853

Epoch: 5| Step: 7
Training loss: 0.2880886197090149
Validation loss: 2.2844487726688385

Epoch: 5| Step: 8
Training loss: 0.5869719386100769
Validation loss: 2.2849389910697937

Epoch: 5| Step: 9
Training loss: 0.8704262971878052
Validation loss: 2.308470552166303

Epoch: 5| Step: 10
Training loss: 0.4263944625854492
Validation loss: 2.2203441162904105

Epoch: 5| Step: 11
Training loss: 1.0762277841567993
Validation loss: 2.260248656074206

Epoch: 325| Step: 0
Training loss: 0.9621673822402954
Validation loss: 2.242498889565468

Epoch: 5| Step: 1
Training loss: 0.36841291189193726
Validation loss: 2.27665568391482

Epoch: 5| Step: 2
Training loss: 0.3830558657646179
Validation loss: 2.3298042317231498

Epoch: 5| Step: 3
Training loss: 0.4887087941169739
Validation loss: 2.284155329068502

Epoch: 5| Step: 4
Training loss: 0.5113745927810669
Validation loss: 2.2695402950048447

Epoch: 5| Step: 5
Training loss: 0.6260769367218018
Validation loss: 2.2108560105164847

Epoch: 5| Step: 6
Training loss: 0.3553250730037689
Validation loss: 2.2961038053035736

Epoch: 5| Step: 7
Training loss: 0.6051791906356812
Validation loss: 2.2503079622983932

Epoch: 5| Step: 8
Training loss: 0.3773368299007416
Validation loss: 2.209954390923182

Epoch: 5| Step: 9
Training loss: 0.29708346724510193
Validation loss: 2.264071842034658

Epoch: 5| Step: 10
Training loss: 0.5545116662979126
Validation loss: 2.3071087102095285

Epoch: 5| Step: 11
Training loss: 1.9903147220611572
Validation loss: 2.2034840981165567

Epoch: 326| Step: 0
Training loss: 0.4260084629058838
Validation loss: 2.324165771404902

Epoch: 5| Step: 1
Training loss: 0.4092825949192047
Validation loss: 2.263629595438639

Epoch: 5| Step: 2
Training loss: 0.6824634671211243
Validation loss: 2.213866318265597

Epoch: 5| Step: 3
Training loss: 0.6222420930862427
Validation loss: 2.3424019515514374

Epoch: 5| Step: 4
Training loss: 0.6994622945785522
Validation loss: 2.28254043062528

Epoch: 5| Step: 5
Training loss: 0.5798473358154297
Validation loss: 2.3094161649545035

Epoch: 5| Step: 6
Training loss: 0.5122920870780945
Validation loss: 2.288494418064753

Epoch: 5| Step: 7
Training loss: 0.5237951874732971
Validation loss: 2.298381050427755

Epoch: 5| Step: 8
Training loss: 0.4504288136959076
Validation loss: 2.2698467324177423

Epoch: 5| Step: 9
Training loss: 0.4234939217567444
Validation loss: 2.321984658638636

Epoch: 5| Step: 10
Training loss: 0.4657139778137207
Validation loss: 2.2868482619524

Epoch: 5| Step: 11
Training loss: 0.46539321541786194
Validation loss: 2.267359217007955

Epoch: 327| Step: 0
Training loss: 0.5489290356636047
Validation loss: 2.3114173412323

Epoch: 5| Step: 1
Training loss: 0.486070454120636
Validation loss: 2.257356425126394

Epoch: 5| Step: 2
Training loss: 0.5504462122917175
Validation loss: 2.2649053831895194

Epoch: 5| Step: 3
Training loss: 0.4736957550048828
Validation loss: 2.232991933822632

Epoch: 5| Step: 4
Training loss: 0.7243168950080872
Validation loss: 2.310380612810453

Epoch: 5| Step: 5
Training loss: 0.6000776290893555
Validation loss: 2.2246827830870948

Epoch: 5| Step: 6
Training loss: 0.3360327482223511
Validation loss: 2.305830438931783

Epoch: 5| Step: 7
Training loss: 0.48595303297042847
Validation loss: 2.242315669854482

Epoch: 5| Step: 8
Training loss: 0.766373336315155
Validation loss: 2.2463047554095588

Epoch: 5| Step: 9
Training loss: 0.35744160413742065
Validation loss: 2.2460026194651923

Epoch: 5| Step: 10
Training loss: 0.4814510941505432
Validation loss: 2.2282186100880303

Epoch: 5| Step: 11
Training loss: 1.0346037149429321
Validation loss: 2.291969766219457

Epoch: 328| Step: 0
Training loss: 0.6283808350563049
Validation loss: 2.281646877527237

Epoch: 5| Step: 1
Training loss: 0.6314052939414978
Validation loss: 2.3343301316102347

Epoch: 5| Step: 2
Training loss: 0.5659414529800415
Validation loss: 2.32539069155852

Epoch: 5| Step: 3
Training loss: 0.7105055451393127
Validation loss: 2.273191516598066

Epoch: 5| Step: 4
Training loss: 0.39599213004112244
Validation loss: 2.296857565641403

Epoch: 5| Step: 5
Training loss: 0.4786350727081299
Validation loss: 2.302566816409429

Epoch: 5| Step: 6
Training loss: 0.641455352306366
Validation loss: 2.279262954990069

Epoch: 5| Step: 7
Training loss: 0.48391038179397583
Validation loss: 2.256832018494606

Epoch: 5| Step: 8
Training loss: 0.6031341552734375
Validation loss: 2.208579649527868

Epoch: 5| Step: 9
Training loss: 0.4646427035331726
Validation loss: 2.3250001668930054

Epoch: 5| Step: 10
Training loss: 0.49901098012924194
Validation loss: 2.2690888990958533

Epoch: 5| Step: 11
Training loss: 0.32710444927215576
Validation loss: 2.2134786198536553

Epoch: 329| Step: 0
Training loss: 0.35080164670944214
Validation loss: 2.317965159813563

Epoch: 5| Step: 1
Training loss: 0.8644950985908508
Validation loss: 2.2204925318559012

Epoch: 5| Step: 2
Training loss: 0.4471149444580078
Validation loss: 2.2661716590325036

Epoch: 5| Step: 3
Training loss: 0.35485005378723145
Validation loss: 2.231479490796725

Epoch: 5| Step: 4
Training loss: 0.6604002118110657
Validation loss: 2.2934955755869546

Epoch: 5| Step: 5
Training loss: 0.6861543655395508
Validation loss: 2.2697234402100244

Epoch: 5| Step: 6
Training loss: 0.5312119722366333
Validation loss: 2.218117112914721

Epoch: 5| Step: 7
Training loss: 0.560921311378479
Validation loss: 2.2132621655861535

Epoch: 5| Step: 8
Training loss: 0.6012837290763855
Validation loss: 2.20739837984244

Epoch: 5| Step: 9
Training loss: 0.5009921193122864
Validation loss: 2.262452393770218

Epoch: 5| Step: 10
Training loss: 0.589123547077179
Validation loss: 2.2751212616761527

Epoch: 5| Step: 11
Training loss: 0.18601025640964508
Validation loss: 2.2996083398660025

Epoch: 330| Step: 0
Training loss: 0.5808875560760498
Validation loss: 2.2839468022187552

Epoch: 5| Step: 1
Training loss: 0.3768933415412903
Validation loss: 2.3029699275890985

Epoch: 5| Step: 2
Training loss: 0.3571670651435852
Validation loss: 2.235661576191584

Epoch: 5| Step: 3
Training loss: 0.514824390411377
Validation loss: 2.312011336286863

Epoch: 5| Step: 4
Training loss: 0.3307690918445587
Validation loss: 2.280412882566452

Epoch: 5| Step: 5
Training loss: 0.4906097948551178
Validation loss: 2.367453088363012

Epoch: 5| Step: 6
Training loss: 0.5142490863800049
Validation loss: 2.280721142888069

Epoch: 5| Step: 7
Training loss: 1.0845533609390259
Validation loss: 2.249116450548172

Epoch: 5| Step: 8
Training loss: 0.6277008056640625
Validation loss: 2.266422381003698

Epoch: 5| Step: 9
Training loss: 0.40734583139419556
Validation loss: 2.2834627081950507

Epoch: 5| Step: 10
Training loss: 0.2624112367630005
Validation loss: 2.2638910114765167

Epoch: 5| Step: 11
Training loss: 1.2766947746276855
Validation loss: 2.3076720237731934

Epoch: 331| Step: 0
Training loss: 0.20394006371498108
Validation loss: 2.2881204783916473

Epoch: 5| Step: 1
Training loss: 0.7252670526504517
Validation loss: 2.287779768308004

Epoch: 5| Step: 2
Training loss: 0.5198293328285217
Validation loss: 2.304686506589254

Epoch: 5| Step: 3
Training loss: 0.5115631222724915
Validation loss: 2.251536726951599

Epoch: 5| Step: 4
Training loss: 0.3196312189102173
Validation loss: 2.3169526805480323

Epoch: 5| Step: 5
Training loss: 0.42927852272987366
Validation loss: 2.305468534429868

Epoch: 5| Step: 6
Training loss: 0.8164658546447754
Validation loss: 2.3644029597441354

Epoch: 5| Step: 7
Training loss: 0.28203481435775757
Validation loss: 2.2908608118693032

Epoch: 5| Step: 8
Training loss: 0.4351213872432709
Validation loss: 2.256846542159716

Epoch: 5| Step: 9
Training loss: 0.5157859921455383
Validation loss: 2.303296133875847

Epoch: 5| Step: 10
Training loss: 0.4016987681388855
Validation loss: 2.3101271291573844

Epoch: 5| Step: 11
Training loss: 0.7458958625793457
Validation loss: 2.260657931367556

Epoch: 332| Step: 0
Training loss: 0.28547483682632446
Validation loss: 2.3188991099596024

Epoch: 5| Step: 1
Training loss: 0.5792903304100037
Validation loss: 2.3567554454008737

Epoch: 5| Step: 2
Training loss: 0.5770974159240723
Validation loss: 2.298750619093577

Epoch: 5| Step: 3
Training loss: 0.4492463171482086
Validation loss: 2.278463984529177

Epoch: 5| Step: 4
Training loss: 0.7041448354721069
Validation loss: 2.253145923217138

Epoch: 5| Step: 5
Training loss: 0.5594990849494934
Validation loss: 2.270030587911606

Epoch: 5| Step: 6
Training loss: 0.3092798888683319
Validation loss: 2.3117644637823105

Epoch: 5| Step: 7
Training loss: 0.7309204339981079
Validation loss: 2.345694899559021

Epoch: 5| Step: 8
Training loss: 0.36699381470680237
Validation loss: 2.3067855735619864

Epoch: 5| Step: 9
Training loss: 0.36647018790245056
Validation loss: 2.2674158215522766

Epoch: 5| Step: 10
Training loss: 0.3676568567752838
Validation loss: 2.2643148799737296

Epoch: 5| Step: 11
Training loss: 0.06114840507507324
Validation loss: 2.2663590957721076

Epoch: 333| Step: 0
Training loss: 0.5655316114425659
Validation loss: 2.2930695166190467

Epoch: 5| Step: 1
Training loss: 0.35967111587524414
Validation loss: 2.278524339199066

Epoch: 5| Step: 2
Training loss: 0.5157066583633423
Validation loss: 2.2085276742776236

Epoch: 5| Step: 3
Training loss: 0.6602315306663513
Validation loss: 2.2856212854385376

Epoch: 5| Step: 4
Training loss: 0.5192059278488159
Validation loss: 2.280008837580681

Epoch: 5| Step: 5
Training loss: 0.5625263452529907
Validation loss: 2.2577933967113495

Epoch: 5| Step: 6
Training loss: 0.566463053226471
Validation loss: 2.3386878271897635

Epoch: 5| Step: 7
Training loss: 0.4671032428741455
Validation loss: 2.2821093002955117

Epoch: 5| Step: 8
Training loss: 0.5256771445274353
Validation loss: 2.286892165740331

Epoch: 5| Step: 9
Training loss: 0.5875669717788696
Validation loss: 2.245302269856135

Epoch: 5| Step: 10
Training loss: 0.3059651851654053
Validation loss: 2.2414518843094506

Epoch: 5| Step: 11
Training loss: 0.16814854741096497
Validation loss: 2.2793660362561545

Epoch: 334| Step: 0
Training loss: 0.8057100176811218
Validation loss: 2.3349318703015647

Epoch: 5| Step: 1
Training loss: 0.27652987837791443
Validation loss: 2.2814879417419434

Epoch: 5| Step: 2
Training loss: 0.5560223460197449
Validation loss: 2.249025652805964

Epoch: 5| Step: 3
Training loss: 0.4623512327671051
Validation loss: 2.269035523136457

Epoch: 5| Step: 4
Training loss: 0.38539648056030273
Validation loss: 2.315697113672892

Epoch: 5| Step: 5
Training loss: 0.38449418544769287
Validation loss: 2.241387645403544

Epoch: 5| Step: 6
Training loss: 0.6004665493965149
Validation loss: 2.2417807579040527

Epoch: 5| Step: 7
Training loss: 0.253192663192749
Validation loss: 2.327926735083262

Epoch: 5| Step: 8
Training loss: 0.5374547243118286
Validation loss: 2.2900694708029428

Epoch: 5| Step: 9
Training loss: 0.5408852696418762
Validation loss: 2.3030159771442413

Epoch: 5| Step: 10
Training loss: 0.5902756452560425
Validation loss: 2.365868111451467

Epoch: 5| Step: 11
Training loss: 0.41077321767807007
Validation loss: 2.38007723291715

Epoch: 335| Step: 0
Training loss: 0.4839654862880707
Validation loss: 2.3371340483427048

Epoch: 5| Step: 1
Training loss: 0.6067323684692383
Validation loss: 2.2570735762516656

Epoch: 5| Step: 2
Training loss: 0.30897754430770874
Validation loss: 2.36618834733963

Epoch: 5| Step: 3
Training loss: 0.44545379281044006
Validation loss: 2.297475109497706

Epoch: 5| Step: 4
Training loss: 0.6595426797866821
Validation loss: 2.2791610111792884

Epoch: 5| Step: 5
Training loss: 0.6553277373313904
Validation loss: 2.2618862887223563

Epoch: 5| Step: 6
Training loss: 0.47179263830184937
Validation loss: 2.3453301936388016

Epoch: 5| Step: 7
Training loss: 0.8066915273666382
Validation loss: 2.2998627920945487

Epoch: 5| Step: 8
Training loss: 0.553471565246582
Validation loss: 2.268523414929708

Epoch: 5| Step: 9
Training loss: 0.5842254757881165
Validation loss: 2.3241351346174874

Epoch: 5| Step: 10
Training loss: 0.5011575222015381
Validation loss: 2.3174552818139396

Epoch: 5| Step: 11
Training loss: 0.7729591131210327
Validation loss: 2.301637997229894

Epoch: 336| Step: 0
Training loss: 0.5832878351211548
Validation loss: 2.339372386535009

Epoch: 5| Step: 1
Training loss: 0.3435618281364441
Validation loss: 2.3247500211000443

Epoch: 5| Step: 2
Training loss: 0.3390410542488098
Validation loss: 2.257669801513354

Epoch: 5| Step: 3
Training loss: 0.9340365529060364
Validation loss: 2.2875570158163705

Epoch: 5| Step: 4
Training loss: 0.36758536100387573
Validation loss: 2.242071439822515

Epoch: 5| Step: 5
Training loss: 0.6367834210395813
Validation loss: 2.2574749936660132

Epoch: 5| Step: 6
Training loss: 0.6303591728210449
Validation loss: 2.2561488151550293

Epoch: 5| Step: 7
Training loss: 0.2950119972229004
Validation loss: 2.3337791164716086

Epoch: 5| Step: 8
Training loss: 0.48189568519592285
Validation loss: 2.287602131565412

Epoch: 5| Step: 9
Training loss: 0.6907421350479126
Validation loss: 2.245073989033699

Epoch: 5| Step: 10
Training loss: 0.4322250485420227
Validation loss: 2.2455885310967765

Epoch: 5| Step: 11
Training loss: 0.32502812147140503
Validation loss: 2.2651398380597434

Epoch: 337| Step: 0
Training loss: 0.4135166108608246
Validation loss: 2.298660308122635

Epoch: 5| Step: 1
Training loss: 0.32857438921928406
Validation loss: 2.2559669564167657

Epoch: 5| Step: 2
Training loss: 0.639899730682373
Validation loss: 2.2175268779198327

Epoch: 5| Step: 3
Training loss: 0.25813207030296326
Validation loss: 2.2427719831466675

Epoch: 5| Step: 4
Training loss: 0.46741288900375366
Validation loss: 2.232549235224724

Epoch: 5| Step: 5
Training loss: 0.3494219481945038
Validation loss: 2.210519716143608

Epoch: 5| Step: 6
Training loss: 0.5550515055656433
Validation loss: 2.2202937056620917

Epoch: 5| Step: 7
Training loss: 0.6515678763389587
Validation loss: 2.212832440932592

Epoch: 5| Step: 8
Training loss: 0.8926938772201538
Validation loss: 2.206610679626465

Epoch: 5| Step: 9
Training loss: 0.5419991612434387
Validation loss: 2.15844689309597

Epoch: 5| Step: 10
Training loss: 0.47112974524497986
Validation loss: 2.1984339455763497

Epoch: 5| Step: 11
Training loss: 0.3229804039001465
Validation loss: 2.2382559974988303

Epoch: 338| Step: 0
Training loss: 0.441622257232666
Validation loss: 2.2484257221221924

Epoch: 5| Step: 1
Training loss: 0.5761606097221375
Validation loss: 2.2287456393241882

Epoch: 5| Step: 2
Training loss: 0.3701549470424652
Validation loss: 2.21757539610068

Epoch: 5| Step: 3
Training loss: 0.569419264793396
Validation loss: 2.234457477927208

Epoch: 5| Step: 4
Training loss: 0.5327094793319702
Validation loss: 2.2293630093336105

Epoch: 5| Step: 5
Training loss: 0.48643046617507935
Validation loss: 2.240837554136912

Epoch: 5| Step: 6
Training loss: 0.8570314645767212
Validation loss: 2.1897436579068503

Epoch: 5| Step: 7
Training loss: 0.33299943804740906
Validation loss: 2.2501437763373056

Epoch: 5| Step: 8
Training loss: 0.5429661870002747
Validation loss: 2.231809357802073

Epoch: 5| Step: 9
Training loss: 0.47159188985824585
Validation loss: 2.2685988744099936

Epoch: 5| Step: 10
Training loss: 0.3924082815647125
Validation loss: 2.2693206866582236

Epoch: 5| Step: 11
Training loss: 0.5350849032402039
Validation loss: 2.168814698855082

Epoch: 339| Step: 0
Training loss: 0.5260887145996094
Validation loss: 2.210045804580053

Epoch: 5| Step: 1
Training loss: 0.38306552171707153
Validation loss: 2.2187203417221704

Epoch: 5| Step: 2
Training loss: 0.21129164099693298
Validation loss: 2.216585179169973

Epoch: 5| Step: 3
Training loss: 0.8621472120285034
Validation loss: 2.234886109828949

Epoch: 5| Step: 4
Training loss: 0.33142098784446716
Validation loss: 2.223886469999949

Epoch: 5| Step: 5
Training loss: 0.6735004186630249
Validation loss: 2.2784494161605835

Epoch: 5| Step: 6
Training loss: 0.5880532264709473
Validation loss: 2.244740923245748

Epoch: 5| Step: 7
Training loss: 0.5682812929153442
Validation loss: 2.205404763420423

Epoch: 5| Step: 8
Training loss: 0.5510345697402954
Validation loss: 2.292332003513972

Epoch: 5| Step: 9
Training loss: 0.3834863603115082
Validation loss: 2.261369893948237

Epoch: 5| Step: 10
Training loss: 0.3527843952178955
Validation loss: 2.261460175116857

Epoch: 5| Step: 11
Training loss: 0.2746180295944214
Validation loss: 2.2769239644209542

Epoch: 340| Step: 0
Training loss: 0.4216339588165283
Validation loss: 2.2458210537830987

Epoch: 5| Step: 1
Training loss: 0.568541944026947
Validation loss: 2.2827678422133126

Epoch: 5| Step: 2
Training loss: 0.29478561878204346
Validation loss: 2.3288527627786

Epoch: 5| Step: 3
Training loss: 0.908438503742218
Validation loss: 2.3181705872217813

Epoch: 5| Step: 4
Training loss: 0.5188385844230652
Validation loss: 2.2642647127310433

Epoch: 5| Step: 5
Training loss: 0.46480607986450195
Validation loss: 2.3116826911767325

Epoch: 5| Step: 6
Training loss: 0.3992856442928314
Validation loss: 2.342098757624626

Epoch: 5| Step: 7
Training loss: 0.610828697681427
Validation loss: 2.26123716433843

Epoch: 5| Step: 8
Training loss: 0.6036474108695984
Validation loss: 2.3089020550251007

Epoch: 5| Step: 9
Training loss: 0.4906845986843109
Validation loss: 2.2730249911546707

Epoch: 5| Step: 10
Training loss: 0.3967457115650177
Validation loss: 2.27201110124588

Epoch: 5| Step: 11
Training loss: 0.15590804815292358
Validation loss: 2.2976113160451255

Epoch: 341| Step: 0
Training loss: 0.6724207997322083
Validation loss: 2.316994031270345

Epoch: 5| Step: 1
Training loss: 0.4822078347206116
Validation loss: 2.317149738470713

Epoch: 5| Step: 2
Training loss: 0.4871961176395416
Validation loss: 2.3108765880266824

Epoch: 5| Step: 3
Training loss: 0.3287273049354553
Validation loss: 2.2780025055011115

Epoch: 5| Step: 4
Training loss: 0.3569789230823517
Validation loss: 2.340111548701922

Epoch: 5| Step: 5
Training loss: 0.547993540763855
Validation loss: 2.2997714579105377

Epoch: 5| Step: 6
Training loss: 0.46512746810913086
Validation loss: 2.3165744791428247

Epoch: 5| Step: 7
Training loss: 0.6300539374351501
Validation loss: 2.2894928654034934

Epoch: 5| Step: 8
Training loss: 0.7112600207328796
Validation loss: 2.247760593891144

Epoch: 5| Step: 9
Training loss: 0.3684670329093933
Validation loss: 2.267500802874565

Epoch: 5| Step: 10
Training loss: 0.48060426115989685
Validation loss: 2.337666849295298

Epoch: 5| Step: 11
Training loss: 0.2546188235282898
Validation loss: 2.245010957121849

Epoch: 342| Step: 0
Training loss: 0.3539890646934509
Validation loss: 2.258372793594996

Epoch: 5| Step: 1
Training loss: 0.40337491035461426
Validation loss: 2.257464369138082

Epoch: 5| Step: 2
Training loss: 0.3079719543457031
Validation loss: 2.2771732111771903

Epoch: 5| Step: 3
Training loss: 0.45883113145828247
Validation loss: 2.2895284791787467

Epoch: 5| Step: 4
Training loss: 0.38245901465415955
Validation loss: 2.2697370847066245

Epoch: 5| Step: 5
Training loss: 0.24430184066295624
Validation loss: 2.3417293230692544

Epoch: 5| Step: 6
Training loss: 0.6230341196060181
Validation loss: 2.299765939513842

Epoch: 5| Step: 7
Training loss: 0.29541200399398804
Validation loss: 2.2556300361951194

Epoch: 5| Step: 8
Training loss: 1.0785869359970093
Validation loss: 2.2800083657105765

Epoch: 5| Step: 9
Training loss: 0.7057026028633118
Validation loss: 2.306107113758723

Epoch: 5| Step: 10
Training loss: 0.5126631855964661
Validation loss: 2.2596272031466165

Epoch: 5| Step: 11
Training loss: 0.951329231262207
Validation loss: 2.236472154657046

Epoch: 343| Step: 0
Training loss: 0.4407919943332672
Validation loss: 2.2648683289686837

Epoch: 5| Step: 1
Training loss: 0.4290575087070465
Validation loss: 2.2368593215942383

Epoch: 5| Step: 2
Training loss: 0.5790421366691589
Validation loss: 2.282063494126002

Epoch: 5| Step: 3
Training loss: 0.6321613192558289
Validation loss: 2.2476251224676767

Epoch: 5| Step: 4
Training loss: 0.769474983215332
Validation loss: 2.232602203885714

Epoch: 5| Step: 5
Training loss: 0.6712818145751953
Validation loss: 2.328475758433342

Epoch: 5| Step: 6
Training loss: 0.4850952625274658
Validation loss: 2.2477886974811554

Epoch: 5| Step: 7
Training loss: 0.2746090590953827
Validation loss: 2.178987607359886

Epoch: 5| Step: 8
Training loss: 0.38567668199539185
Validation loss: 2.290952851374944

Epoch: 5| Step: 9
Training loss: 0.6169980764389038
Validation loss: 2.222071796655655

Epoch: 5| Step: 10
Training loss: 0.4288383424282074
Validation loss: 2.259104703863462

Epoch: 5| Step: 11
Training loss: 0.3179863691329956
Validation loss: 2.3128711581230164

Epoch: 344| Step: 0
Training loss: 0.5521286725997925
Validation loss: 2.233380431930224

Epoch: 5| Step: 1
Training loss: 0.6177353262901306
Validation loss: 2.234412928422292

Epoch: 5| Step: 2
Training loss: 0.332734078168869
Validation loss: 2.2774040897687278

Epoch: 5| Step: 3
Training loss: 0.5642296671867371
Validation loss: 2.242912153402964

Epoch: 5| Step: 4
Training loss: 0.485403835773468
Validation loss: 2.2636893540620804

Epoch: 5| Step: 5
Training loss: 0.6056715250015259
Validation loss: 2.2689884354670844

Epoch: 5| Step: 6
Training loss: 0.46401339769363403
Validation loss: 2.2636545300483704

Epoch: 5| Step: 7
Training loss: 0.6115574240684509
Validation loss: 2.2226570149262748

Epoch: 5| Step: 8
Training loss: 0.8887607455253601
Validation loss: 2.25530743598938

Epoch: 5| Step: 9
Training loss: 0.2882564961910248
Validation loss: 2.229205086827278

Epoch: 5| Step: 10
Training loss: 0.27835923433303833
Validation loss: 2.232891966899236

Epoch: 5| Step: 11
Training loss: 0.44819700717926025
Validation loss: 2.255498915910721

Epoch: 345| Step: 0
Training loss: 0.29027852416038513
Validation loss: 2.2400769044955573

Epoch: 5| Step: 1
Training loss: 1.0462987422943115
Validation loss: 2.3300880740086236

Epoch: 5| Step: 2
Training loss: 0.6201061606407166
Validation loss: 2.2443512280782065

Epoch: 5| Step: 3
Training loss: 0.5538854002952576
Validation loss: 2.2313126921653748

Epoch: 5| Step: 4
Training loss: 0.4261009693145752
Validation loss: 2.2557680855194726

Epoch: 5| Step: 5
Training loss: 0.5667976140975952
Validation loss: 2.322977860768636

Epoch: 5| Step: 6
Training loss: 0.28360527753829956
Validation loss: 2.231946920355161

Epoch: 5| Step: 7
Training loss: 0.360869437456131
Validation loss: 2.3087278505166373

Epoch: 5| Step: 8
Training loss: 0.45673006772994995
Validation loss: 2.238485957185427

Epoch: 5| Step: 9
Training loss: 0.5781765580177307
Validation loss: 2.3011271407206855

Epoch: 5| Step: 10
Training loss: 0.7012251615524292
Validation loss: 2.2864833374818168

Epoch: 5| Step: 11
Training loss: 0.3249644637107849
Validation loss: 2.285112996896108

Epoch: 346| Step: 0
Training loss: 0.3376011252403259
Validation loss: 2.2642677277326584

Epoch: 5| Step: 1
Training loss: 0.47131258249282837
Validation loss: 2.2682839781045914

Epoch: 5| Step: 2
Training loss: 0.5810320377349854
Validation loss: 2.2126709520816803

Epoch: 5| Step: 3
Training loss: 0.9129946827888489
Validation loss: 2.289577196041743

Epoch: 5| Step: 4
Training loss: 0.6798785924911499
Validation loss: 2.272605687379837

Epoch: 5| Step: 5
Training loss: 0.44656476378440857
Validation loss: 2.289980267484983

Epoch: 5| Step: 6
Training loss: 0.2984033226966858
Validation loss: 2.2446982065836587

Epoch: 5| Step: 7
Training loss: 0.31747719645500183
Validation loss: 2.286175717910131

Epoch: 5| Step: 8
Training loss: 0.28788474202156067
Validation loss: 2.2839290698369346

Epoch: 5| Step: 9
Training loss: 0.6718462705612183
Validation loss: 2.275318215290705

Epoch: 5| Step: 10
Training loss: 0.46922197937965393
Validation loss: 2.2958428661028543

Epoch: 5| Step: 11
Training loss: 0.9260730147361755
Validation loss: 2.2814326832691827

Epoch: 347| Step: 0
Training loss: 0.3415226936340332
Validation loss: 2.3155237336953483

Epoch: 5| Step: 1
Training loss: 0.40429824590682983
Validation loss: 2.2816982765992484

Epoch: 5| Step: 2
Training loss: 0.36963480710983276
Validation loss: 2.280882716178894

Epoch: 5| Step: 3
Training loss: 0.33969318866729736
Validation loss: 2.2887261658906937

Epoch: 5| Step: 4
Training loss: 0.49371591210365295
Validation loss: 2.282457709312439

Epoch: 5| Step: 5
Training loss: 0.610578179359436
Validation loss: 2.303190290927887

Epoch: 5| Step: 6
Training loss: 0.4978249669075012
Validation loss: 2.2701859027147293

Epoch: 5| Step: 7
Training loss: 0.4623897969722748
Validation loss: 2.2732182492812476

Epoch: 5| Step: 8
Training loss: 0.7229479551315308
Validation loss: 2.314034362634023

Epoch: 5| Step: 9
Training loss: 0.454246461391449
Validation loss: 2.2557368675867715

Epoch: 5| Step: 10
Training loss: 0.48200201988220215
Validation loss: 2.3657564719518027

Epoch: 5| Step: 11
Training loss: 0.38724929094314575
Validation loss: 2.291924516359965

Epoch: 348| Step: 0
Training loss: 0.42300909757614136
Validation loss: 2.225459491213163

Epoch: 5| Step: 1
Training loss: 0.5565908551216125
Validation loss: 2.3209841748078666

Epoch: 5| Step: 2
Training loss: 0.4571322798728943
Validation loss: 2.2688086181879044

Epoch: 5| Step: 3
Training loss: 0.2971576750278473
Validation loss: 2.2980857839186988

Epoch: 5| Step: 4
Training loss: 0.573388934135437
Validation loss: 2.2573775351047516

Epoch: 5| Step: 5
Training loss: 0.5624679327011108
Validation loss: 2.299458553393682

Epoch: 5| Step: 6
Training loss: 0.436165988445282
Validation loss: 2.3018987079461417

Epoch: 5| Step: 7
Training loss: 0.7398472428321838
Validation loss: 2.2964064280192056

Epoch: 5| Step: 8
Training loss: 0.5299665927886963
Validation loss: 2.3066703379154205

Epoch: 5| Step: 9
Training loss: 0.42146992683410645
Validation loss: 2.29325299958388

Epoch: 5| Step: 10
Training loss: 0.545155942440033
Validation loss: 2.3224768936634064

Epoch: 5| Step: 11
Training loss: 0.15737897157669067
Validation loss: 2.3000524987777076

Epoch: 349| Step: 0
Training loss: 0.5570014119148254
Validation loss: 2.2968626767396927

Epoch: 5| Step: 1
Training loss: 0.31190961599349976
Validation loss: 2.286585042874018

Epoch: 5| Step: 2
Training loss: 0.41502779722213745
Validation loss: 2.239132503668467

Epoch: 5| Step: 3
Training loss: 0.546838104724884
Validation loss: 2.2748227417469025

Epoch: 5| Step: 4
Training loss: 0.5371350646018982
Validation loss: 2.249591420094172

Epoch: 5| Step: 5
Training loss: 0.6635386347770691
Validation loss: 2.3301549504200616

Epoch: 5| Step: 6
Training loss: 0.7770684957504272
Validation loss: 2.279911071062088

Epoch: 5| Step: 7
Training loss: 0.1965053230524063
Validation loss: 2.3112813929716745

Epoch: 5| Step: 8
Training loss: 0.5904420614242554
Validation loss: 2.2985658248265586

Epoch: 5| Step: 9
Training loss: 0.48641276359558105
Validation loss: 2.291253626346588

Epoch: 5| Step: 10
Training loss: 0.5988730192184448
Validation loss: 2.23383891582489

Epoch: 5| Step: 11
Training loss: 0.4697924554347992
Validation loss: 2.289648324251175

Epoch: 350| Step: 0
Training loss: 0.49024850130081177
Validation loss: 2.237783615787824

Epoch: 5| Step: 1
Training loss: 0.2833266854286194
Validation loss: 2.2751744190851846

Epoch: 5| Step: 2
Training loss: 0.5020859241485596
Validation loss: 2.3110389709472656

Epoch: 5| Step: 3
Training loss: 0.718082070350647
Validation loss: 2.3008733093738556

Epoch: 5| Step: 4
Training loss: 0.6806193590164185
Validation loss: 2.2800441881020865

Epoch: 5| Step: 5
Training loss: 0.535768985748291
Validation loss: 2.26774854461352

Epoch: 5| Step: 6
Training loss: 0.4830265939235687
Validation loss: 2.3062342504660287

Epoch: 5| Step: 7
Training loss: 0.47486692667007446
Validation loss: 2.2230692158142724

Epoch: 5| Step: 8
Training loss: 0.39363712072372437
Validation loss: 2.3107811510562897

Epoch: 5| Step: 9
Training loss: 0.646992564201355
Validation loss: 2.2827351043621698

Epoch: 5| Step: 10
Training loss: 0.5638316869735718
Validation loss: 2.285990903774897

Epoch: 5| Step: 11
Training loss: 0.44208061695098877
Validation loss: 2.3113661209742227

Epoch: 351| Step: 0
Training loss: 0.6436495780944824
Validation loss: 2.320961445569992

Epoch: 5| Step: 1
Training loss: 0.26521703600883484
Validation loss: 2.267205665508906

Epoch: 5| Step: 2
Training loss: 0.2962533235549927
Validation loss: 2.302210013071696

Epoch: 5| Step: 3
Training loss: 0.295715868473053
Validation loss: 2.2997869849205017

Epoch: 5| Step: 4
Training loss: 0.5403475761413574
Validation loss: 2.2792394955952964

Epoch: 5| Step: 5
Training loss: 0.35877537727355957
Validation loss: 2.285268763701121

Epoch: 5| Step: 6
Training loss: 0.49306946992874146
Validation loss: 2.3152256309986115

Epoch: 5| Step: 7
Training loss: 0.4108518660068512
Validation loss: 2.322429676850637

Epoch: 5| Step: 8
Training loss: 0.6097904443740845
Validation loss: 2.2643951376279197

Epoch: 5| Step: 9
Training loss: 0.7714203000068665
Validation loss: 2.282187173763911

Epoch: 5| Step: 10
Training loss: 0.6893131136894226
Validation loss: 2.32354229191939

Epoch: 5| Step: 11
Training loss: 0.34766048192977905
Validation loss: 2.287602295478185

Epoch: 352| Step: 0
Training loss: 0.3868826925754547
Validation loss: 2.293227960666021

Epoch: 5| Step: 1
Training loss: 0.8806136846542358
Validation loss: 2.2956822415192923

Epoch: 5| Step: 2
Training loss: 0.5846985578536987
Validation loss: 2.2569097727537155

Epoch: 5| Step: 3
Training loss: 0.44054585695266724
Validation loss: 2.265212525924047

Epoch: 5| Step: 4
Training loss: 0.27453145384788513
Validation loss: 2.256429841121038

Epoch: 5| Step: 5
Training loss: 0.28227001428604126
Validation loss: 2.2504563281933465

Epoch: 5| Step: 6
Training loss: 0.25558286905288696
Validation loss: 2.2661843250195184

Epoch: 5| Step: 7
Training loss: 0.4535096287727356
Validation loss: 2.2684185405572257

Epoch: 5| Step: 8
Training loss: 0.596707820892334
Validation loss: 2.276516775290171

Epoch: 5| Step: 9
Training loss: 0.9500908851623535
Validation loss: 2.3257549107074738

Epoch: 5| Step: 10
Training loss: 0.36811691522598267
Validation loss: 2.262217034896215

Epoch: 5| Step: 11
Training loss: 0.21562814712524414
Validation loss: 2.254003405570984

Epoch: 353| Step: 0
Training loss: 0.5280667543411255
Validation loss: 2.2683672308921814

Epoch: 5| Step: 1
Training loss: 0.4756365716457367
Validation loss: 2.2719837029774985

Epoch: 5| Step: 2
Training loss: 0.6289966702461243
Validation loss: 2.291689152518908

Epoch: 5| Step: 3
Training loss: 0.723789632320404
Validation loss: 2.279465605815252

Epoch: 5| Step: 4
Training loss: 0.5028876066207886
Validation loss: 2.2475298196077347

Epoch: 5| Step: 5
Training loss: 0.4136722683906555
Validation loss: 2.2357837011416755

Epoch: 5| Step: 6
Training loss: 0.6262542009353638
Validation loss: 2.337226609388987

Epoch: 5| Step: 7
Training loss: 0.41300565004348755
Validation loss: 2.294056991736094

Epoch: 5| Step: 8
Training loss: 0.42311280965805054
Validation loss: 2.271342953046163

Epoch: 5| Step: 9
Training loss: 0.45866304636001587
Validation loss: 2.2647436559200287

Epoch: 5| Step: 10
Training loss: 0.44206833839416504
Validation loss: 2.255068138241768

Epoch: 5| Step: 11
Training loss: 0.5921013355255127
Validation loss: 2.279710958401362

Epoch: 354| Step: 0
Training loss: 0.4788680076599121
Validation loss: 2.29612043996652

Epoch: 5| Step: 1
Training loss: 0.4496740400791168
Validation loss: 2.2628527681032815

Epoch: 5| Step: 2
Training loss: 0.36821889877319336
Validation loss: 2.2229465444882712

Epoch: 5| Step: 3
Training loss: 0.8274282217025757
Validation loss: 2.2589477052291236

Epoch: 5| Step: 4
Training loss: 0.30392488837242126
Validation loss: 2.242311308781306

Epoch: 5| Step: 5
Training loss: 0.4100796580314636
Validation loss: 2.2074451446533203

Epoch: 5| Step: 6
Training loss: 0.23265178501605988
Validation loss: 2.2373143980900445

Epoch: 5| Step: 7
Training loss: 0.48299115896224976
Validation loss: 2.2754298001527786

Epoch: 5| Step: 8
Training loss: 1.2032217979431152
Validation loss: 2.284040004014969

Epoch: 5| Step: 9
Training loss: 0.431356817483902
Validation loss: 2.2916911939779916

Epoch: 5| Step: 10
Training loss: 0.3773461580276489
Validation loss: 2.218848312894503

Epoch: 5| Step: 11
Training loss: 0.2941817045211792
Validation loss: 2.3006376922130585

Epoch: 355| Step: 0
Training loss: 0.48151159286499023
Validation loss: 2.301934232314428

Epoch: 5| Step: 1
Training loss: 0.7323150038719177
Validation loss: 2.317076633373896

Epoch: 5| Step: 2
Training loss: 0.46777087450027466
Validation loss: 2.298156718413035

Epoch: 5| Step: 3
Training loss: 0.43431586027145386
Validation loss: 2.280082583427429

Epoch: 5| Step: 4
Training loss: 0.6829356551170349
Validation loss: 2.292074700196584

Epoch: 5| Step: 5
Training loss: 0.6384145617485046
Validation loss: 2.2618451366821923

Epoch: 5| Step: 6
Training loss: 0.4065505862236023
Validation loss: 2.3323913663625717

Epoch: 5| Step: 7
Training loss: 0.42388805747032166
Validation loss: 2.210897594690323

Epoch: 5| Step: 8
Training loss: 0.44650062918663025
Validation loss: 2.238769978284836

Epoch: 5| Step: 9
Training loss: 0.9875212907791138
Validation loss: 2.2554954091707864

Epoch: 5| Step: 10
Training loss: 0.6117855310440063
Validation loss: 2.316211998462677

Epoch: 5| Step: 11
Training loss: 0.6721129417419434
Validation loss: 2.3297717620929084

Epoch: 356| Step: 0
Training loss: 0.7006786465644836
Validation loss: 2.292228957017263

Epoch: 5| Step: 1
Training loss: 0.5385136008262634
Validation loss: 2.31118934849898

Epoch: 5| Step: 2
Training loss: 0.3951874375343323
Validation loss: 2.206241379181544

Epoch: 5| Step: 3
Training loss: 0.5525887608528137
Validation loss: 2.214542826016744

Epoch: 5| Step: 4
Training loss: 0.4552551209926605
Validation loss: 2.230008323987325

Epoch: 5| Step: 5
Training loss: 0.9091320037841797
Validation loss: 2.2553986509641013

Epoch: 5| Step: 6
Training loss: 0.3892175555229187
Validation loss: 2.242623955011368

Epoch: 5| Step: 7
Training loss: 0.2820741534233093
Validation loss: 2.2014820178349814

Epoch: 5| Step: 8
Training loss: 0.3953455984592438
Validation loss: 2.2747869392236075

Epoch: 5| Step: 9
Training loss: 0.4257194399833679
Validation loss: 2.3101479212443032

Epoch: 5| Step: 10
Training loss: 0.7446978092193604
Validation loss: 2.269455070296923

Epoch: 5| Step: 11
Training loss: 0.3627674877643585
Validation loss: 2.299410402774811

Epoch: 357| Step: 0
Training loss: 0.2715371549129486
Validation loss: 2.2961776753266654

Epoch: 5| Step: 1
Training loss: 0.3006317913532257
Validation loss: 2.2378546396891275

Epoch: 5| Step: 2
Training loss: 0.8674443364143372
Validation loss: 2.2929934660593667

Epoch: 5| Step: 3
Training loss: 0.45231112837791443
Validation loss: 2.27450954914093

Epoch: 5| Step: 4
Training loss: 0.6032181978225708
Validation loss: 2.2159260710080466

Epoch: 5| Step: 5
Training loss: 0.42486459016799927
Validation loss: 2.2390031268199286

Epoch: 5| Step: 6
Training loss: 0.6825944781303406
Validation loss: 2.295512934525808

Epoch: 5| Step: 7
Training loss: 0.2818763554096222
Validation loss: 2.3132875015338263

Epoch: 5| Step: 8
Training loss: 0.7757295370101929
Validation loss: 2.317566732565562

Epoch: 5| Step: 9
Training loss: 0.6073765754699707
Validation loss: 2.28830024600029

Epoch: 5| Step: 10
Training loss: 0.3917151093482971
Validation loss: 2.270515968402227

Epoch: 5| Step: 11
Training loss: 1.2498362064361572
Validation loss: 2.2701175858577094

Epoch: 358| Step: 0
Training loss: 0.451241672039032
Validation loss: 2.2548947433630624

Epoch: 5| Step: 1
Training loss: 0.3121870160102844
Validation loss: 2.2574807504812875

Epoch: 5| Step: 2
Training loss: 0.7430181503295898
Validation loss: 2.22389617562294

Epoch: 5| Step: 3
Training loss: 0.4963107109069824
Validation loss: 2.2737358709176383

Epoch: 5| Step: 4
Training loss: 0.34564629197120667
Validation loss: 2.240487957994143

Epoch: 5| Step: 5
Training loss: 0.49167221784591675
Validation loss: 2.2403352359930673

Epoch: 5| Step: 6
Training loss: 0.3940233886241913
Validation loss: 2.2133220185836158

Epoch: 5| Step: 7
Training loss: 0.6178175210952759
Validation loss: 2.2350654304027557

Epoch: 5| Step: 8
Training loss: 0.5110467076301575
Validation loss: 2.260266602039337

Epoch: 5| Step: 9
Training loss: 0.5040820240974426
Validation loss: 2.2519049694140754

Epoch: 5| Step: 10
Training loss: 0.7905371785163879
Validation loss: 2.307088240981102

Epoch: 5| Step: 11
Training loss: 0.5878092646598816
Validation loss: 2.2987104455629983

Epoch: 359| Step: 0
Training loss: 0.29106250405311584
Validation loss: 2.243729372819265

Epoch: 5| Step: 1
Training loss: 1.0096641778945923
Validation loss: 2.2150954206784568

Epoch: 5| Step: 2
Training loss: 0.3911537528038025
Validation loss: 2.3114879578351974

Epoch: 5| Step: 3
Training loss: 0.3815111219882965
Validation loss: 2.276692201693853

Epoch: 5| Step: 4
Training loss: 0.383497416973114
Validation loss: 2.246533771355947

Epoch: 5| Step: 5
Training loss: 0.5091224908828735
Validation loss: 2.327607790629069

Epoch: 5| Step: 6
Training loss: 0.37929654121398926
Validation loss: 2.334891532858213

Epoch: 5| Step: 7
Training loss: 0.32109972834587097
Validation loss: 2.238876591126124

Epoch: 5| Step: 8
Training loss: 0.40899938344955444
Validation loss: 2.315745532512665

Epoch: 5| Step: 9
Training loss: 0.6085397005081177
Validation loss: 2.3008788426717124

Epoch: 5| Step: 10
Training loss: 0.4480280876159668
Validation loss: 2.3047953297694526

Epoch: 5| Step: 11
Training loss: 1.9177534580230713
Validation loss: 2.2842717518409095

Epoch: 360| Step: 0
Training loss: 0.5167680978775024
Validation loss: 2.3263788521289825

Epoch: 5| Step: 1
Training loss: 0.39071646332740784
Validation loss: 2.3330208162466683

Epoch: 5| Step: 2
Training loss: 0.23612479865550995
Validation loss: 2.286320428053538

Epoch: 5| Step: 3
Training loss: 0.5793952941894531
Validation loss: 2.236736630400022

Epoch: 5| Step: 4
Training loss: 0.29932183027267456
Validation loss: 2.3217003444830575

Epoch: 5| Step: 5
Training loss: 0.8667232394218445
Validation loss: 2.336906929810842

Epoch: 5| Step: 6
Training loss: 0.4826964735984802
Validation loss: 2.2730199793974557

Epoch: 5| Step: 7
Training loss: 0.3149468004703522
Validation loss: 2.256006250778834

Epoch: 5| Step: 8
Training loss: 0.34579816460609436
Validation loss: 2.2965138802925744

Epoch: 5| Step: 9
Training loss: 0.8517671823501587
Validation loss: 2.243432511885961

Epoch: 5| Step: 10
Training loss: 0.2875238358974457
Validation loss: 2.231650064388911

Epoch: 5| Step: 11
Training loss: 0.19143235683441162
Validation loss: 2.2567305068174996

Epoch: 361| Step: 0
Training loss: 0.3444633483886719
Validation loss: 2.292764196793238

Epoch: 5| Step: 1
Training loss: 0.5239700078964233
Validation loss: 2.2641575386126838

Epoch: 5| Step: 2
Training loss: 0.3965287506580353
Validation loss: 2.3163334280252457

Epoch: 5| Step: 3
Training loss: 0.6146777868270874
Validation loss: 2.277876526117325

Epoch: 5| Step: 4
Training loss: 0.6430081725120544
Validation loss: 2.2572490672270455

Epoch: 5| Step: 5
Training loss: 0.7388750910758972
Validation loss: 2.2955997635920844

Epoch: 5| Step: 6
Training loss: 0.3210287094116211
Validation loss: 2.284577429294586

Epoch: 5| Step: 7
Training loss: 0.3152100741863251
Validation loss: 2.2827962040901184

Epoch: 5| Step: 8
Training loss: 0.2648427188396454
Validation loss: 2.305372973283132

Epoch: 5| Step: 9
Training loss: 0.5391149520874023
Validation loss: 2.311498219768206

Epoch: 5| Step: 10
Training loss: 0.6938259601593018
Validation loss: 2.3320759485165277

Epoch: 5| Step: 11
Training loss: 0.4596891403198242
Validation loss: 2.2657364706198373

Epoch: 362| Step: 0
Training loss: 0.6673849821090698
Validation loss: 2.3307411074638367

Epoch: 5| Step: 1
Training loss: 0.36801379919052124
Validation loss: 2.29190094769001

Epoch: 5| Step: 2
Training loss: 0.6267381310462952
Validation loss: 2.3258797427018485

Epoch: 5| Step: 3
Training loss: 0.7053117156028748
Validation loss: 2.2894212106863656

Epoch: 5| Step: 4
Training loss: 0.3351079821586609
Validation loss: 2.248710572719574

Epoch: 5| Step: 5
Training loss: 0.5266858339309692
Validation loss: 2.257918193936348

Epoch: 5| Step: 6
Training loss: 0.34517431259155273
Validation loss: 2.382117837667465

Epoch: 5| Step: 7
Training loss: 0.43051204085350037
Validation loss: 2.2637015332778296

Epoch: 5| Step: 8
Training loss: 0.5263936519622803
Validation loss: 2.2238460779190063

Epoch: 5| Step: 9
Training loss: 0.4471725523471832
Validation loss: 2.29280016819636

Epoch: 5| Step: 10
Training loss: 0.4517356753349304
Validation loss: 2.2892758895953498

Epoch: 5| Step: 11
Training loss: 0.2684779167175293
Validation loss: 2.2816079209248223

Epoch: 363| Step: 0
Training loss: 0.43897008895874023
Validation loss: 2.2602405150731406

Epoch: 5| Step: 1
Training loss: 0.3073870539665222
Validation loss: 2.2479020754496255

Epoch: 5| Step: 2
Training loss: 0.45431631803512573
Validation loss: 2.253837063908577

Epoch: 5| Step: 3
Training loss: 0.3616844117641449
Validation loss: 2.302118167281151

Epoch: 5| Step: 4
Training loss: 0.33420291543006897
Validation loss: 2.281226168076197

Epoch: 5| Step: 5
Training loss: 0.5889745950698853
Validation loss: 2.2290387550989785

Epoch: 5| Step: 6
Training loss: 0.4611437916755676
Validation loss: 2.267793590823809

Epoch: 5| Step: 7
Training loss: 0.5168019533157349
Validation loss: 2.2961927553017936

Epoch: 5| Step: 8
Training loss: 0.3359810709953308
Validation loss: 2.230570286512375

Epoch: 5| Step: 9
Training loss: 0.870947539806366
Validation loss: 2.2737948497136435

Epoch: 5| Step: 10
Training loss: 0.6070687770843506
Validation loss: 2.252253090341886

Epoch: 5| Step: 11
Training loss: 0.24012289941310883
Validation loss: 2.269842172662417

Epoch: 364| Step: 0
Training loss: 0.33722832798957825
Validation loss: 2.2623548209667206

Epoch: 5| Step: 1
Training loss: 0.5444205403327942
Validation loss: 2.2665155827999115

Epoch: 5| Step: 2
Training loss: 0.353274405002594
Validation loss: 2.2664053787787757

Epoch: 5| Step: 3
Training loss: 0.2224380522966385
Validation loss: 2.211247811714808

Epoch: 5| Step: 4
Training loss: 0.5484605431556702
Validation loss: 2.250478297472

Epoch: 5| Step: 5
Training loss: 0.4521697461605072
Validation loss: 2.309765338897705

Epoch: 5| Step: 6
Training loss: 0.25151535868644714
Validation loss: 2.2720831433931985

Epoch: 5| Step: 7
Training loss: 0.8053256273269653
Validation loss: 2.2435682316621146

Epoch: 5| Step: 8
Training loss: 0.3498973250389099
Validation loss: 2.29226582745711

Epoch: 5| Step: 9
Training loss: 0.5945227146148682
Validation loss: 2.300009777148565

Epoch: 5| Step: 10
Training loss: 0.7375811338424683
Validation loss: 2.229226658741633

Epoch: 5| Step: 11
Training loss: 0.36858564615249634
Validation loss: 2.2545268634955087

Epoch: 365| Step: 0
Training loss: 0.3777838349342346
Validation loss: 2.3056495835383735

Epoch: 5| Step: 1
Training loss: 0.21898984909057617
Validation loss: 2.282974988222122

Epoch: 5| Step: 2
Training loss: 0.8334380984306335
Validation loss: 2.236163914203644

Epoch: 5| Step: 3
Training loss: 0.26047608256340027
Validation loss: 2.2416297445694604

Epoch: 5| Step: 4
Training loss: 0.33749356865882874
Validation loss: 2.24472306172053

Epoch: 5| Step: 5
Training loss: 0.5600178241729736
Validation loss: 2.329016382495562

Epoch: 5| Step: 6
Training loss: 0.30871227383613586
Validation loss: 2.2762490461270013

Epoch: 5| Step: 7
Training loss: 0.4024732708930969
Validation loss: 2.3195178558429084

Epoch: 5| Step: 8
Training loss: 0.6890131831169128
Validation loss: 2.2293005834023156

Epoch: 5| Step: 9
Training loss: 0.43051856756210327
Validation loss: 2.261284018556277

Epoch: 5| Step: 10
Training loss: 0.4554360806941986
Validation loss: 2.352890153725942

Epoch: 5| Step: 11
Training loss: 0.5702123045921326
Validation loss: 2.3583259185155234

Epoch: 366| Step: 0
Training loss: 0.44521012902259827
Validation loss: 2.3251490394274392

Epoch: 5| Step: 1
Training loss: 0.4793340563774109
Validation loss: 2.322666476170222

Epoch: 5| Step: 2
Training loss: 0.5020548105239868
Validation loss: 2.30553138256073

Epoch: 5| Step: 3
Training loss: 0.6310075521469116
Validation loss: 2.2770227740208306

Epoch: 5| Step: 4
Training loss: 0.5428439378738403
Validation loss: 2.324857711791992

Epoch: 5| Step: 5
Training loss: 0.45908480882644653
Validation loss: 2.244154612223307

Epoch: 5| Step: 6
Training loss: 0.35277339816093445
Validation loss: 2.285804659128189

Epoch: 5| Step: 7
Training loss: 0.5906041860580444
Validation loss: 2.337598611911138

Epoch: 5| Step: 8
Training loss: 0.2679126262664795
Validation loss: 2.281233713030815

Epoch: 5| Step: 9
Training loss: 0.4354114532470703
Validation loss: 2.2636557668447495

Epoch: 5| Step: 10
Training loss: 0.5306216478347778
Validation loss: 2.2964829802513123

Epoch: 5| Step: 11
Training loss: 0.4669109582901001
Validation loss: 2.2600349436203637

Epoch: 367| Step: 0
Training loss: 0.3579912483692169
Validation loss: 2.2906931936740875

Epoch: 5| Step: 1
Training loss: 0.23920539021492004
Validation loss: 2.270139296849569

Epoch: 5| Step: 2
Training loss: 0.6236962080001831
Validation loss: 2.2551754117012024

Epoch: 5| Step: 3
Training loss: 0.8529400825500488
Validation loss: 2.313809315363566

Epoch: 5| Step: 4
Training loss: 0.43267011642456055
Validation loss: 2.3317941576242447

Epoch: 5| Step: 5
Training loss: 0.4252989888191223
Validation loss: 2.2578011403481164

Epoch: 5| Step: 6
Training loss: 0.47713422775268555
Validation loss: 2.20563272635142

Epoch: 5| Step: 7
Training loss: 0.2455177754163742
Validation loss: 2.2699724634488425

Epoch: 5| Step: 8
Training loss: 0.5631903409957886
Validation loss: 2.3080496340990067

Epoch: 5| Step: 9
Training loss: 0.4145103394985199
Validation loss: 2.2823194017012916

Epoch: 5| Step: 10
Training loss: 0.51812744140625
Validation loss: 2.2721528112888336

Epoch: 5| Step: 11
Training loss: 0.21054720878601074
Validation loss: 2.288925757010778

Epoch: 368| Step: 0
Training loss: 0.24844050407409668
Validation loss: 2.344206074873606

Epoch: 5| Step: 1
Training loss: 0.3779546916484833
Validation loss: 2.3246704787015915

Epoch: 5| Step: 2
Training loss: 0.4802231192588806
Validation loss: 2.328111688296

Epoch: 5| Step: 3
Training loss: 0.49170589447021484
Validation loss: 2.302863578001658

Epoch: 5| Step: 4
Training loss: 0.7083748579025269
Validation loss: 2.262018178900083

Epoch: 5| Step: 5
Training loss: 0.4145681858062744
Validation loss: 2.263742675383886

Epoch: 5| Step: 6
Training loss: 0.434009313583374
Validation loss: 2.2572910288969674

Epoch: 5| Step: 7
Training loss: 0.2725573480129242
Validation loss: 2.2767594953378043

Epoch: 5| Step: 8
Training loss: 0.4541451334953308
Validation loss: 2.227262943983078

Epoch: 5| Step: 9
Training loss: 0.4315943717956543
Validation loss: 2.2887035409609475

Epoch: 5| Step: 10
Training loss: 0.9151014089584351
Validation loss: 2.250480145215988

Epoch: 5| Step: 11
Training loss: 0.217745840549469
Validation loss: 2.2556585669517517

Epoch: 369| Step: 0
Training loss: 0.9282663464546204
Validation loss: 2.2252173771460853

Epoch: 5| Step: 1
Training loss: 0.4210909903049469
Validation loss: 2.2553334335486093

Epoch: 5| Step: 2
Training loss: 0.5492299795150757
Validation loss: 2.2801710416873298

Epoch: 5| Step: 3
Training loss: 0.4493916928768158
Validation loss: 2.323437591393789

Epoch: 5| Step: 4
Training loss: 0.464280903339386
Validation loss: 2.2522555788358054

Epoch: 5| Step: 5
Training loss: 0.29830271005630493
Validation loss: 2.2609375466903052

Epoch: 5| Step: 6
Training loss: 0.5267418026924133
Validation loss: 2.289563794930776

Epoch: 5| Step: 7
Training loss: 0.3463916778564453
Validation loss: 2.1960494418938956

Epoch: 5| Step: 8
Training loss: 0.5772866010665894
Validation loss: 2.3006027787923813

Epoch: 5| Step: 9
Training loss: 0.3368604779243469
Validation loss: 2.302853132287661

Epoch: 5| Step: 10
Training loss: 0.5169326066970825
Validation loss: 2.286089619000753

Epoch: 5| Step: 11
Training loss: 0.34195131063461304
Validation loss: 2.2320005347331366

Epoch: 370| Step: 0
Training loss: 0.31283876299858093
Validation loss: 2.302423894405365

Epoch: 5| Step: 1
Training loss: 0.5546411275863647
Validation loss: 2.307066947221756

Epoch: 5| Step: 2
Training loss: 0.3236573338508606
Validation loss: 2.309997489054998

Epoch: 5| Step: 3
Training loss: 0.4876740872859955
Validation loss: 2.2819590667883554

Epoch: 5| Step: 4
Training loss: 0.2709777057170868
Validation loss: 2.3503678937753043

Epoch: 5| Step: 5
Training loss: 0.4824482798576355
Validation loss: 2.2341668059428534

Epoch: 5| Step: 6
Training loss: 0.4665777087211609
Validation loss: 2.263191729784012

Epoch: 5| Step: 7
Training loss: 0.3707696795463562
Validation loss: 2.342845469713211

Epoch: 5| Step: 8
Training loss: 0.5570336580276489
Validation loss: 2.2987003922462463

Epoch: 5| Step: 9
Training loss: 0.7820909023284912
Validation loss: 2.2564790646235147

Epoch: 5| Step: 10
Training loss: 0.3755072057247162
Validation loss: 2.261729563275973

Epoch: 5| Step: 11
Training loss: 1.3508645296096802
Validation loss: 2.323620244860649

Epoch: 371| Step: 0
Training loss: 0.37311044335365295
Validation loss: 2.289019286632538

Epoch: 5| Step: 1
Training loss: 0.21850690245628357
Validation loss: 2.2872395118077598

Epoch: 5| Step: 2
Training loss: 0.4549546241760254
Validation loss: 2.2558832466602325

Epoch: 5| Step: 3
Training loss: 0.24885967373847961
Validation loss: 2.2654186338186264

Epoch: 5| Step: 4
Training loss: 0.2832714915275574
Validation loss: 2.3019672433535256

Epoch: 5| Step: 5
Training loss: 0.262563019990921
Validation loss: 2.289566362897555

Epoch: 5| Step: 6
Training loss: 0.7549320459365845
Validation loss: 2.334196458260218

Epoch: 5| Step: 7
Training loss: 0.6205992698669434
Validation loss: 2.331614911556244

Epoch: 5| Step: 8
Training loss: 0.6393418908119202
Validation loss: 2.3195566733678183

Epoch: 5| Step: 9
Training loss: 0.3234703838825226
Validation loss: 2.341559112071991

Epoch: 5| Step: 10
Training loss: 0.32829704880714417
Validation loss: 2.325754165649414

Epoch: 5| Step: 11
Training loss: 1.2627291679382324
Validation loss: 2.3252079784870148

Epoch: 372| Step: 0
Training loss: 1.0231117010116577
Validation loss: 2.3020558754603067

Epoch: 5| Step: 1
Training loss: 0.4575827717781067
Validation loss: 2.3084340194861093

Epoch: 5| Step: 2
Training loss: 0.2737172245979309
Validation loss: 2.3408230344454446

Epoch: 5| Step: 3
Training loss: 0.6762794256210327
Validation loss: 2.2990537186463675

Epoch: 5| Step: 4
Training loss: 0.33816343545913696
Validation loss: 2.275096893310547

Epoch: 5| Step: 5
Training loss: 0.36137861013412476
Validation loss: 2.27282452583313

Epoch: 5| Step: 6
Training loss: 0.2315087616443634
Validation loss: 2.2785781174898148

Epoch: 5| Step: 7
Training loss: 0.40363675355911255
Validation loss: 2.2231730173031488

Epoch: 5| Step: 8
Training loss: 0.6033019423484802
Validation loss: 2.199826662739118

Epoch: 5| Step: 9
Training loss: 0.4232134222984314
Validation loss: 2.3055664002895355

Epoch: 5| Step: 10
Training loss: 0.2714776396751404
Validation loss: 2.306943009297053

Epoch: 5| Step: 11
Training loss: 0.257559597492218
Validation loss: 2.30073152979215

Epoch: 373| Step: 0
Training loss: 0.7249636054039001
Validation loss: 2.334373503923416

Epoch: 5| Step: 1
Training loss: 0.4742746353149414
Validation loss: 2.2993012567361197

Epoch: 5| Step: 2
Training loss: 0.8405681848526001
Validation loss: 2.2969053983688354

Epoch: 5| Step: 3
Training loss: 0.399655282497406
Validation loss: 2.2912846952676773

Epoch: 5| Step: 4
Training loss: 0.6278859376907349
Validation loss: 2.318935682376226

Epoch: 5| Step: 5
Training loss: 0.5193477869033813
Validation loss: 2.318977872530619

Epoch: 5| Step: 6
Training loss: 0.2618118226528168
Validation loss: 2.2490091075499854

Epoch: 5| Step: 7
Training loss: 0.4777146279811859
Validation loss: 2.2781794567902884

Epoch: 5| Step: 8
Training loss: 0.39251983165740967
Validation loss: 2.3037587801615396

Epoch: 5| Step: 9
Training loss: 0.4210117757320404
Validation loss: 2.3047619412342706

Epoch: 5| Step: 10
Training loss: 0.46004563570022583
Validation loss: 2.254125565290451

Epoch: 5| Step: 11
Training loss: 0.5498461723327637
Validation loss: 2.2566590209801993

Epoch: 374| Step: 0
Training loss: 0.5591952204704285
Validation loss: 2.228542317946752

Epoch: 5| Step: 1
Training loss: 0.40584611892700195
Validation loss: 2.260836740334829

Epoch: 5| Step: 2
Training loss: 0.2681058943271637
Validation loss: 2.2616365949312844

Epoch: 5| Step: 3
Training loss: 0.28919655084609985
Validation loss: 2.351621593038241

Epoch: 5| Step: 4
Training loss: 0.478959858417511
Validation loss: 2.303021882971128

Epoch: 5| Step: 5
Training loss: 0.2688932418823242
Validation loss: 2.252308890223503

Epoch: 5| Step: 6
Training loss: 0.5074673891067505
Validation loss: 2.227252801259359

Epoch: 5| Step: 7
Training loss: 0.5478278398513794
Validation loss: 2.30924062927564

Epoch: 5| Step: 8
Training loss: 0.6682356595993042
Validation loss: 2.27591664592425

Epoch: 5| Step: 9
Training loss: 0.6293845176696777
Validation loss: 2.224487215280533

Epoch: 5| Step: 10
Training loss: 0.5503221154212952
Validation loss: 2.271685262521108

Epoch: 5| Step: 11
Training loss: 0.3652338981628418
Validation loss: 2.2660546203454337

Epoch: 375| Step: 0
Training loss: 0.4616653323173523
Validation loss: 2.2682799249887466

Epoch: 5| Step: 1
Training loss: 0.2970995306968689
Validation loss: 2.3034879664580026

Epoch: 5| Step: 2
Training loss: 0.36265963315963745
Validation loss: 2.230992242693901

Epoch: 5| Step: 3
Training loss: 0.38375324010849
Validation loss: 2.2556082705656686

Epoch: 5| Step: 4
Training loss: 0.38538455963134766
Validation loss: 2.261164973179499

Epoch: 5| Step: 5
Training loss: 0.4928690791130066
Validation loss: 2.2860257724920907

Epoch: 5| Step: 6
Training loss: 0.43737712502479553
Validation loss: 2.2629029800494513

Epoch: 5| Step: 7
Training loss: 0.8854538798332214
Validation loss: 2.241328547398249

Epoch: 5| Step: 8
Training loss: 0.8764485120773315
Validation loss: 2.2512521793444953

Epoch: 5| Step: 9
Training loss: 0.38054075837135315
Validation loss: 2.2098290473222733

Epoch: 5| Step: 10
Training loss: 0.45450201630592346
Validation loss: 2.233528529604276

Epoch: 5| Step: 11
Training loss: 0.26443612575531006
Validation loss: 2.226702814300855

Epoch: 376| Step: 0
Training loss: 0.7571702003479004
Validation loss: 2.25223246216774

Epoch: 5| Step: 1
Training loss: 0.7287574410438538
Validation loss: 2.2700080573558807

Epoch: 5| Step: 2
Training loss: 0.2931736409664154
Validation loss: 2.2543754279613495

Epoch: 5| Step: 3
Training loss: 0.4153921604156494
Validation loss: 2.251687745253245

Epoch: 5| Step: 4
Training loss: 0.2777180075645447
Validation loss: 2.252995933095614

Epoch: 5| Step: 5
Training loss: 0.28461048007011414
Validation loss: 2.297180453936259

Epoch: 5| Step: 6
Training loss: 0.4323466420173645
Validation loss: 2.1957280387481055

Epoch: 5| Step: 7
Training loss: 0.2167007476091385
Validation loss: 2.2335980037848153

Epoch: 5| Step: 8
Training loss: 0.4354161322116852
Validation loss: 2.2112297415733337

Epoch: 5| Step: 9
Training loss: 0.6585592031478882
Validation loss: 2.231836214661598

Epoch: 5| Step: 10
Training loss: 0.3527027368545532
Validation loss: 2.269176716605822

Epoch: 5| Step: 11
Training loss: 0.4132865071296692
Validation loss: 2.1931211998065314

Epoch: 377| Step: 0
Training loss: 0.43306589126586914
Validation loss: 2.273181453347206

Epoch: 5| Step: 1
Training loss: 0.44681549072265625
Validation loss: 2.2247783144315085

Epoch: 5| Step: 2
Training loss: 0.48231473565101624
Validation loss: 2.2194723039865494

Epoch: 5| Step: 3
Training loss: 0.6277068853378296
Validation loss: 2.283072421948115

Epoch: 5| Step: 4
Training loss: 0.2975470721721649
Validation loss: 2.2668123096227646

Epoch: 5| Step: 5
Training loss: 0.414849191904068
Validation loss: 2.366244445244471

Epoch: 5| Step: 6
Training loss: 0.29515743255615234
Validation loss: 2.271788348754247

Epoch: 5| Step: 7
Training loss: 0.36032670736312866
Validation loss: 2.255221515893936

Epoch: 5| Step: 8
Training loss: 0.5301397442817688
Validation loss: 2.2983174373706183

Epoch: 5| Step: 9
Training loss: 0.2658945620059967
Validation loss: 2.313391918937365

Epoch: 5| Step: 10
Training loss: 0.8201721906661987
Validation loss: 2.2281790475050607

Epoch: 5| Step: 11
Training loss: 0.4677734375
Validation loss: 2.27218026916186

Epoch: 378| Step: 0
Training loss: 0.4276324212551117
Validation loss: 2.2303617695967355

Epoch: 5| Step: 1
Training loss: 0.24404935538768768
Validation loss: 2.274693250656128

Epoch: 5| Step: 2
Training loss: 0.4347262382507324
Validation loss: 2.2858355244000754

Epoch: 5| Step: 3
Training loss: 0.40704482793807983
Validation loss: 2.3273533483346305

Epoch: 5| Step: 4
Training loss: 0.7173582911491394
Validation loss: 2.2889668395121894

Epoch: 5| Step: 5
Training loss: 0.3590652346611023
Validation loss: 2.279169956843058

Epoch: 5| Step: 6
Training loss: 0.7425306439399719
Validation loss: 2.2307521601517997

Epoch: 5| Step: 7
Training loss: 0.2721720039844513
Validation loss: 2.2408376733462014

Epoch: 5| Step: 8
Training loss: 0.34072238206863403
Validation loss: 2.345336467027664

Epoch: 5| Step: 9
Training loss: 0.7502849698066711
Validation loss: 2.322580556074778

Epoch: 5| Step: 10
Training loss: 0.27539491653442383
Validation loss: 2.3230249285697937

Epoch: 5| Step: 11
Training loss: 0.6978278160095215
Validation loss: 2.3480363686879477

Epoch: 379| Step: 0
Training loss: 0.382563054561615
Validation loss: 2.3178411523501077

Epoch: 5| Step: 1
Training loss: 0.3499261736869812
Validation loss: 2.2346352289120355

Epoch: 5| Step: 2
Training loss: 0.264605849981308
Validation loss: 2.272503356138865

Epoch: 5| Step: 3
Training loss: 0.5167891383171082
Validation loss: 2.3152364691098533

Epoch: 5| Step: 4
Training loss: 0.7339925765991211
Validation loss: 2.2868001212676368

Epoch: 5| Step: 5
Training loss: 0.45444321632385254
Validation loss: 2.251651535431544

Epoch: 5| Step: 6
Training loss: 0.3923054337501526
Validation loss: 2.278555934627851

Epoch: 5| Step: 7
Training loss: 0.3162696957588196
Validation loss: 2.20759945611159

Epoch: 5| Step: 8
Training loss: 0.7449537515640259
Validation loss: 2.248482366402944

Epoch: 5| Step: 9
Training loss: 0.6204606294631958
Validation loss: 2.2626742670933404

Epoch: 5| Step: 10
Training loss: 0.3827601969242096
Validation loss: 2.270660157004992

Epoch: 5| Step: 11
Training loss: 0.23069129884243011
Validation loss: 2.257055878639221

Epoch: 380| Step: 0
Training loss: 0.2778163254261017
Validation loss: 2.256191069881121

Epoch: 5| Step: 1
Training loss: 0.4730096757411957
Validation loss: 2.2328521559635797

Epoch: 5| Step: 2
Training loss: 0.29259708523750305
Validation loss: 2.248942732810974

Epoch: 5| Step: 3
Training loss: 0.4481888711452484
Validation loss: 2.2563015669584274

Epoch: 5| Step: 4
Training loss: 0.4695657193660736
Validation loss: 2.2588918854792914

Epoch: 5| Step: 5
Training loss: 0.5457385778427124
Validation loss: 2.2628010710080466

Epoch: 5| Step: 6
Training loss: 0.6299494504928589
Validation loss: 2.272436867157618

Epoch: 5| Step: 7
Training loss: 0.3451178967952728
Validation loss: 2.2409817427396774

Epoch: 5| Step: 8
Training loss: 0.33767133951187134
Validation loss: 2.2710668593645096

Epoch: 5| Step: 9
Training loss: 0.4160791337490082
Validation loss: 2.2558658023675284

Epoch: 5| Step: 10
Training loss: 0.8483150601387024
Validation loss: 2.249182879924774

Epoch: 5| Step: 11
Training loss: 1.0308748483657837
Validation loss: 2.294809559981028

Epoch: 381| Step: 0
Training loss: 0.5878475904464722
Validation loss: 2.281340708335241

Epoch: 5| Step: 1
Training loss: 0.4025457501411438
Validation loss: 2.299340307712555

Epoch: 5| Step: 2
Training loss: 0.46188193559646606
Validation loss: 2.212570364276568

Epoch: 5| Step: 3
Training loss: 0.3659542202949524
Validation loss: 2.247456898291906

Epoch: 5| Step: 4
Training loss: 0.3162918984889984
Validation loss: 2.293818419178327

Epoch: 5| Step: 5
Training loss: 0.6817156076431274
Validation loss: 2.253288278977076

Epoch: 5| Step: 6
Training loss: 0.3655117452144623
Validation loss: 2.3248146871725717

Epoch: 5| Step: 7
Training loss: 0.33663153648376465
Validation loss: 2.305965304374695

Epoch: 5| Step: 8
Training loss: 0.7649813294410706
Validation loss: 2.2405933241049447

Epoch: 5| Step: 9
Training loss: 0.2544305920600891
Validation loss: 2.283895338575045

Epoch: 5| Step: 10
Training loss: 0.4169042706489563
Validation loss: 2.3166107734044394

Epoch: 5| Step: 11
Training loss: 0.24766767024993896
Validation loss: 2.271577298641205

Epoch: 382| Step: 0
Training loss: 0.6834202408790588
Validation loss: 2.292034755150477

Epoch: 5| Step: 1
Training loss: 0.3071182072162628
Validation loss: 2.360380565126737

Epoch: 5| Step: 2
Training loss: 0.44391947984695435
Validation loss: 2.309424042701721

Epoch: 5| Step: 3
Training loss: 0.5760634541511536
Validation loss: 2.294554059704145

Epoch: 5| Step: 4
Training loss: 0.26114457845687866
Validation loss: 2.300777872403463

Epoch: 5| Step: 5
Training loss: 0.49660491943359375
Validation loss: 2.3237603902816772

Epoch: 5| Step: 6
Training loss: 0.26699405908584595
Validation loss: 2.2997456391652427

Epoch: 5| Step: 7
Training loss: 0.7399030923843384
Validation loss: 2.3186387022336326

Epoch: 5| Step: 8
Training loss: 0.39938613772392273
Validation loss: 2.2808022846778235

Epoch: 5| Step: 9
Training loss: 0.4317105710506439
Validation loss: 2.333356430133184

Epoch: 5| Step: 10
Training loss: 0.2216358482837677
Validation loss: 2.3239973982175193

Epoch: 5| Step: 11
Training loss: 0.5564296245574951
Validation loss: 2.2899103462696075

Epoch: 383| Step: 0
Training loss: 0.3345264494419098
Validation loss: 2.3171300490697226

Epoch: 5| Step: 1
Training loss: 0.3323773741722107
Validation loss: 2.267381320397059

Epoch: 5| Step: 2
Training loss: 0.36940863728523254
Validation loss: 2.2823399702707925

Epoch: 5| Step: 3
Training loss: 0.378734827041626
Validation loss: 2.2527603755394616

Epoch: 5| Step: 4
Training loss: 0.2939259111881256
Validation loss: 2.255735139052073

Epoch: 5| Step: 5
Training loss: 0.27152806520462036
Validation loss: 2.240746483206749

Epoch: 5| Step: 6
Training loss: 0.6301482915878296
Validation loss: 2.275821437438329

Epoch: 5| Step: 7
Training loss: 0.3340233564376831
Validation loss: 2.2224721113840737

Epoch: 5| Step: 8
Training loss: 0.3050108850002289
Validation loss: 2.2427353858947754

Epoch: 5| Step: 9
Training loss: 0.5904695391654968
Validation loss: 2.281774570544561

Epoch: 5| Step: 10
Training loss: 1.067091464996338
Validation loss: 2.278974706927935

Epoch: 5| Step: 11
Training loss: 0.37370041012763977
Validation loss: 2.275274475415548

Epoch: 384| Step: 0
Training loss: 0.4541893005371094
Validation loss: 2.2654557824134827

Epoch: 5| Step: 1
Training loss: 0.38744837045669556
Validation loss: 2.2484157532453537

Epoch: 5| Step: 2
Training loss: 0.6886928081512451
Validation loss: 2.2831710974375405

Epoch: 5| Step: 3
Training loss: 0.3384610712528229
Validation loss: 2.280070642630259

Epoch: 5| Step: 4
Training loss: 0.2662610411643982
Validation loss: 2.262061362465223

Epoch: 5| Step: 5
Training loss: 0.31908491253852844
Validation loss: 2.2919427851835885

Epoch: 5| Step: 6
Training loss: 0.5759689807891846
Validation loss: 2.328721652428309

Epoch: 5| Step: 7
Training loss: 0.45522648096084595
Validation loss: 2.2837673127651215

Epoch: 5| Step: 8
Training loss: 0.5336203575134277
Validation loss: 2.310852696498235

Epoch: 5| Step: 9
Training loss: 0.3501347303390503
Validation loss: 2.293843890229861

Epoch: 5| Step: 10
Training loss: 0.8051015734672546
Validation loss: 2.259572962919871

Epoch: 5| Step: 11
Training loss: 0.2475198209285736
Validation loss: 2.3274719566106796

Epoch: 385| Step: 0
Training loss: 0.2597334086894989
Validation loss: 2.228402465581894

Epoch: 5| Step: 1
Training loss: 0.37645483016967773
Validation loss: 2.226517687241236

Epoch: 5| Step: 2
Training loss: 0.3312132954597473
Validation loss: 2.242161586880684

Epoch: 5| Step: 3
Training loss: 0.5817248821258545
Validation loss: 2.265321026245753

Epoch: 5| Step: 4
Training loss: 0.5459292531013489
Validation loss: 2.2738162130117416

Epoch: 5| Step: 5
Training loss: 0.8364168405532837
Validation loss: 2.2886260747909546

Epoch: 5| Step: 6
Training loss: 0.4175124764442444
Validation loss: 2.222684308886528

Epoch: 5| Step: 7
Training loss: 0.5740846991539001
Validation loss: 2.2849387576182685

Epoch: 5| Step: 8
Training loss: 0.4006834924221039
Validation loss: 2.244870771964391

Epoch: 5| Step: 9
Training loss: 0.36920422315597534
Validation loss: 2.2611531019210815

Epoch: 5| Step: 10
Training loss: 0.37140029668807983
Validation loss: 2.291450396180153

Epoch: 5| Step: 11
Training loss: 0.11477366089820862
Validation loss: 2.1989168524742126

Epoch: 386| Step: 0
Training loss: 0.9088243246078491
Validation loss: 2.205351322889328

Epoch: 5| Step: 1
Training loss: 0.32503587007522583
Validation loss: 2.2693609992663064

Epoch: 5| Step: 2
Training loss: 0.5571340322494507
Validation loss: 2.2259258131186166

Epoch: 5| Step: 3
Training loss: 0.31235092878341675
Validation loss: 2.300221766034762

Epoch: 5| Step: 4
Training loss: 0.4758230149745941
Validation loss: 2.257924328247706

Epoch: 5| Step: 5
Training loss: 0.33002081513404846
Validation loss: 2.2394800583521524

Epoch: 5| Step: 6
Training loss: 0.49419108033180237
Validation loss: 2.2314024219910302

Epoch: 5| Step: 7
Training loss: 0.28053098917007446
Validation loss: 2.2707428336143494

Epoch: 5| Step: 8
Training loss: 0.3174636960029602
Validation loss: 2.2261866132418313

Epoch: 5| Step: 9
Training loss: 0.22409352660179138
Validation loss: 2.2572904527187347

Epoch: 5| Step: 10
Training loss: 0.3505634665489197
Validation loss: 2.234598865111669

Epoch: 5| Step: 11
Training loss: 1.2851465940475464
Validation loss: 2.211853802204132

Epoch: 387| Step: 0
Training loss: 0.770388662815094
Validation loss: 2.2623056372006736

Epoch: 5| Step: 1
Training loss: 0.5179076194763184
Validation loss: 2.288160820802053

Epoch: 5| Step: 2
Training loss: 0.4607444703578949
Validation loss: 2.2797190248966217

Epoch: 5| Step: 3
Training loss: 0.4500252306461334
Validation loss: 2.246271843711535

Epoch: 5| Step: 4
Training loss: 0.2233227789402008
Validation loss: 2.266384576757749

Epoch: 5| Step: 5
Training loss: 0.5722447633743286
Validation loss: 2.3283523619174957

Epoch: 5| Step: 6
Training loss: 0.3338557183742523
Validation loss: 2.239673544963201

Epoch: 5| Step: 7
Training loss: 0.32438820600509644
Validation loss: 2.2512407153844833

Epoch: 5| Step: 8
Training loss: 0.4179094731807709
Validation loss: 2.244428873062134

Epoch: 5| Step: 9
Training loss: 0.33275485038757324
Validation loss: 2.2892265915870667

Epoch: 5| Step: 10
Training loss: 0.7608345150947571
Validation loss: 2.291495203971863

Epoch: 5| Step: 11
Training loss: 0.34168851375579834
Validation loss: 2.287987604737282

Epoch: 388| Step: 0
Training loss: 0.5424762964248657
Validation loss: 2.279896398385366

Epoch: 5| Step: 1
Training loss: 0.3885706961154938
Validation loss: 2.3068013787269592

Epoch: 5| Step: 2
Training loss: 0.37378793954849243
Validation loss: 2.3208199044068656

Epoch: 5| Step: 3
Training loss: 0.3787989616394043
Validation loss: 2.2774060368537903

Epoch: 5| Step: 4
Training loss: 0.5543860197067261
Validation loss: 2.2917173405488334

Epoch: 5| Step: 5
Training loss: 0.41961440443992615
Validation loss: 2.3122981737057366

Epoch: 5| Step: 6
Training loss: 0.807805061340332
Validation loss: 2.275884439547857

Epoch: 5| Step: 7
Training loss: 0.392250120639801
Validation loss: 2.2393016864856086

Epoch: 5| Step: 8
Training loss: 0.6200753450393677
Validation loss: 2.2748775631189346

Epoch: 5| Step: 9
Training loss: 0.35296326875686646
Validation loss: 2.2340408911307654

Epoch: 5| Step: 10
Training loss: 0.2576318383216858
Validation loss: 2.2593544274568558

Epoch: 5| Step: 11
Training loss: 0.2658866345882416
Validation loss: 2.25517729918162

Epoch: 389| Step: 0
Training loss: 0.3442850410938263
Validation loss: 2.270575692256292

Epoch: 5| Step: 1
Training loss: 0.30588260293006897
Validation loss: 2.269373049338659

Epoch: 5| Step: 2
Training loss: 0.8361466526985168
Validation loss: 2.3127670089403787

Epoch: 5| Step: 3
Training loss: 0.3398149311542511
Validation loss: 2.2990026275316873

Epoch: 5| Step: 4
Training loss: 0.8564184308052063
Validation loss: 2.2533689538637796

Epoch: 5| Step: 5
Training loss: 0.5836347341537476
Validation loss: 2.2394386678934097

Epoch: 5| Step: 6
Training loss: 0.32502737641334534
Validation loss: 2.308282732963562

Epoch: 5| Step: 7
Training loss: 0.4562436044216156
Validation loss: 2.2882381230592728

Epoch: 5| Step: 8
Training loss: 0.5430704355239868
Validation loss: 2.27264212568601

Epoch: 5| Step: 9
Training loss: 0.22256235778331757
Validation loss: 2.200221677621206

Epoch: 5| Step: 10
Training loss: 0.4721466898918152
Validation loss: 2.2843005607525506

Epoch: 5| Step: 11
Training loss: 0.28407588601112366
Validation loss: 2.2413329680760703

Epoch: 390| Step: 0
Training loss: 0.2574005126953125
Validation loss: 2.3285212020079293

Epoch: 5| Step: 1
Training loss: 0.5968114137649536
Validation loss: 2.3148646305004754

Epoch: 5| Step: 2
Training loss: 0.3730567693710327
Validation loss: 2.28782390554746

Epoch: 5| Step: 3
Training loss: 0.5455162525177002
Validation loss: 2.292919913927714

Epoch: 5| Step: 4
Training loss: 0.32946836948394775
Validation loss: 2.2697782715161643

Epoch: 5| Step: 5
Training loss: 0.5348854660987854
Validation loss: 2.293113738298416

Epoch: 5| Step: 6
Training loss: 0.5235394835472107
Validation loss: 2.2805570860703788

Epoch: 5| Step: 7
Training loss: 0.3578167259693146
Validation loss: 2.2637842992941537

Epoch: 5| Step: 8
Training loss: 0.723599374294281
Validation loss: 2.2823406606912613

Epoch: 5| Step: 9
Training loss: 0.3433486521244049
Validation loss: 2.282115792234739

Epoch: 5| Step: 10
Training loss: 0.529495358467102
Validation loss: 2.2236368656158447

Epoch: 5| Step: 11
Training loss: 0.32323575019836426
Validation loss: 2.303478702902794

Epoch: 391| Step: 0
Training loss: 0.45210686326026917
Validation loss: 2.2609336773554483

Epoch: 5| Step: 1
Training loss: 0.6135896444320679
Validation loss: 2.3142624696095786

Epoch: 5| Step: 2
Training loss: 0.5661231875419617
Validation loss: 2.330081512530645

Epoch: 5| Step: 3
Training loss: 0.751767098903656
Validation loss: 2.3470243314901986

Epoch: 5| Step: 4
Training loss: 0.45190659165382385
Validation loss: 2.278961425026258

Epoch: 5| Step: 5
Training loss: 0.4835609495639801
Validation loss: 2.2753504812717438

Epoch: 5| Step: 6
Training loss: 0.6037802696228027
Validation loss: 2.287238528331121

Epoch: 5| Step: 7
Training loss: 0.2636878490447998
Validation loss: 2.2792979776859283

Epoch: 5| Step: 8
Training loss: 0.45405760407447815
Validation loss: 2.250422179698944

Epoch: 5| Step: 9
Training loss: 0.3826771080493927
Validation loss: 2.3091315080722175

Epoch: 5| Step: 10
Training loss: 0.47960251569747925
Validation loss: 2.319776942332586

Epoch: 5| Step: 11
Training loss: 0.5346517562866211
Validation loss: 2.279870872696241

Epoch: 392| Step: 0
Training loss: 0.22039863467216492
Validation loss: 2.238740066687266

Epoch: 5| Step: 1
Training loss: 0.3861246705055237
Validation loss: 2.2736083418130875

Epoch: 5| Step: 2
Training loss: 0.6371713876724243
Validation loss: 2.3208935856819153

Epoch: 5| Step: 3
Training loss: 0.49363431334495544
Validation loss: 2.2721385608116784

Epoch: 5| Step: 4
Training loss: 0.4646035134792328
Validation loss: 2.2783495088418326

Epoch: 5| Step: 5
Training loss: 0.3411291837692261
Validation loss: 2.326931675275167

Epoch: 5| Step: 6
Training loss: 0.3104860484600067
Validation loss: 2.2686592837174735

Epoch: 5| Step: 7
Training loss: 0.4017605781555176
Validation loss: 2.2846209506193795

Epoch: 5| Step: 8
Training loss: 0.6063600778579712
Validation loss: 2.2481975754102073

Epoch: 5| Step: 9
Training loss: 0.4390128254890442
Validation loss: 2.28012245396773

Epoch: 5| Step: 10
Training loss: 0.6271164417266846
Validation loss: 2.266432603200277

Epoch: 5| Step: 11
Training loss: 0.2608811855316162
Validation loss: 2.241078798969587

Epoch: 393| Step: 0
Training loss: 0.6017596125602722
Validation loss: 2.335996389389038

Epoch: 5| Step: 1
Training loss: 0.2770002782344818
Validation loss: 2.248136599858602

Epoch: 5| Step: 2
Training loss: 0.5360136032104492
Validation loss: 2.2695257365703583

Epoch: 5| Step: 3
Training loss: 0.5389548540115356
Validation loss: 2.233545109629631

Epoch: 5| Step: 4
Training loss: 0.43816453218460083
Validation loss: 2.300546243786812

Epoch: 5| Step: 5
Training loss: 0.46238112449645996
Validation loss: 2.268247256676356

Epoch: 5| Step: 6
Training loss: 0.5720804929733276
Validation loss: 2.3021932194630303

Epoch: 5| Step: 7
Training loss: 0.550366997718811
Validation loss: 2.281994437177976

Epoch: 5| Step: 8
Training loss: 0.4798462986946106
Validation loss: 2.2596111992994943

Epoch: 5| Step: 9
Training loss: 0.33624425530433655
Validation loss: 2.289824883143107

Epoch: 5| Step: 10
Training loss: 0.30966734886169434
Validation loss: 2.3148585657278695

Epoch: 5| Step: 11
Training loss: 0.3068186640739441
Validation loss: 2.2572886049747467

Epoch: 394| Step: 0
Training loss: 0.33315831422805786
Validation loss: 2.2500270307064056

Epoch: 5| Step: 1
Training loss: 0.48406338691711426
Validation loss: 2.2645608385403952

Epoch: 5| Step: 2
Training loss: 0.6601549983024597
Validation loss: 2.289028455813726

Epoch: 5| Step: 3
Training loss: 0.23511943221092224
Validation loss: 2.196878766020139

Epoch: 5| Step: 4
Training loss: 0.5231279134750366
Validation loss: 2.3119855423768363

Epoch: 5| Step: 5
Training loss: 0.68199622631073
Validation loss: 2.2983131210009256

Epoch: 5| Step: 6
Training loss: 0.3009078800678253
Validation loss: 2.320784787336985

Epoch: 5| Step: 7
Training loss: 0.21001458168029785
Validation loss: 2.277959570288658

Epoch: 5| Step: 8
Training loss: 0.3239651322364807
Validation loss: 2.271305094162623

Epoch: 5| Step: 9
Training loss: 0.4398057460784912
Validation loss: 2.297573377688726

Epoch: 5| Step: 10
Training loss: 0.7050954103469849
Validation loss: 2.361629774173101

Epoch: 5| Step: 11
Training loss: 0.27119696140289307
Validation loss: 2.328699439764023

Epoch: 395| Step: 0
Training loss: 0.500991940498352
Validation loss: 2.289790858825048

Epoch: 5| Step: 1
Training loss: 0.7775748372077942
Validation loss: 2.3095565289258957

Epoch: 5| Step: 2
Training loss: 0.43730154633522034
Validation loss: 2.292525370915731

Epoch: 5| Step: 3
Training loss: 0.3711293637752533
Validation loss: 2.297248254219691

Epoch: 5| Step: 4
Training loss: 0.46078139543533325
Validation loss: 2.2838265746831894

Epoch: 5| Step: 5
Training loss: 0.34228459000587463
Validation loss: 2.2148351967334747

Epoch: 5| Step: 6
Training loss: 0.32829052209854126
Validation loss: 2.311639408270518

Epoch: 5| Step: 7
Training loss: 0.23430714011192322
Validation loss: 2.3176737229029336

Epoch: 5| Step: 8
Training loss: 0.37964197993278503
Validation loss: 2.2725147058566413

Epoch: 5| Step: 9
Training loss: 0.5934006571769714
Validation loss: 2.2913191815217337

Epoch: 5| Step: 10
Training loss: 0.5658750534057617
Validation loss: 2.3567935526371

Epoch: 5| Step: 11
Training loss: 0.18295353651046753
Validation loss: 2.305782357851664

Epoch: 396| Step: 0
Training loss: 0.42072272300720215
Validation loss: 2.2743337651093802

Epoch: 5| Step: 1
Training loss: 0.7283613085746765
Validation loss: 2.2618625164031982

Epoch: 5| Step: 2
Training loss: 0.2344246208667755
Validation loss: 2.3028473456700644

Epoch: 5| Step: 3
Training loss: 0.31048277020454407
Validation loss: 2.2138323734203973

Epoch: 5| Step: 4
Training loss: 0.23156511783599854
Validation loss: 2.2533559004465737

Epoch: 5| Step: 5
Training loss: 0.6679625511169434
Validation loss: 2.2580066273609796

Epoch: 5| Step: 6
Training loss: 0.37603747844696045
Validation loss: 2.2092204689979553

Epoch: 5| Step: 7
Training loss: 0.5082534551620483
Validation loss: 2.253304903705915

Epoch: 5| Step: 8
Training loss: 0.5368598699569702
Validation loss: 2.2967651238044104

Epoch: 5| Step: 9
Training loss: 0.3534671664237976
Validation loss: 2.224307671189308

Epoch: 5| Step: 10
Training loss: 0.44717201590538025
Validation loss: 2.286361580093702

Epoch: 5| Step: 11
Training loss: 0.34921789169311523
Validation loss: 2.275502393643061

Epoch: 397| Step: 0
Training loss: 0.4594959318637848
Validation loss: 2.2535909662644067

Epoch: 5| Step: 1
Training loss: 0.3002486824989319
Validation loss: 2.2613432854413986

Epoch: 5| Step: 2
Training loss: 0.45037204027175903
Validation loss: 2.2935251345237098

Epoch: 5| Step: 3
Training loss: 0.4809719920158386
Validation loss: 2.2514490286509194

Epoch: 5| Step: 4
Training loss: 0.2691843807697296
Validation loss: 2.231058860818545

Epoch: 5| Step: 5
Training loss: 0.7054640650749207
Validation loss: 2.312257637580236

Epoch: 5| Step: 6
Training loss: 0.66543048620224
Validation loss: 2.288579816619555

Epoch: 5| Step: 7
Training loss: 0.44427451491355896
Validation loss: 2.2699888249238334

Epoch: 5| Step: 8
Training loss: 0.5790001153945923
Validation loss: 2.2901111443837485

Epoch: 5| Step: 9
Training loss: 0.6168514490127563
Validation loss: 2.3389798402786255

Epoch: 5| Step: 10
Training loss: 0.3229004740715027
Validation loss: 2.3551823695500693

Epoch: 5| Step: 11
Training loss: 0.2121109962463379
Validation loss: 2.1985506117343903

Epoch: 398| Step: 0
Training loss: 0.3947595953941345
Validation loss: 2.287544071674347

Epoch: 5| Step: 1
Training loss: 0.2225114405155182
Validation loss: 2.360308234890302

Epoch: 5| Step: 2
Training loss: 0.2579135298728943
Validation loss: 2.3411755661169686

Epoch: 5| Step: 3
Training loss: 0.6788722276687622
Validation loss: 2.296830435593923

Epoch: 5| Step: 4
Training loss: 0.4755541682243347
Validation loss: 2.2873339305321374

Epoch: 5| Step: 5
Training loss: 0.43335890769958496
Validation loss: 2.3141921013593674

Epoch: 5| Step: 6
Training loss: 0.2802000641822815
Validation loss: 2.2963317930698395

Epoch: 5| Step: 7
Training loss: 0.4421255588531494
Validation loss: 2.2891708314418793

Epoch: 5| Step: 8
Training loss: 0.652710497379303
Validation loss: 2.3053757598002753

Epoch: 5| Step: 9
Training loss: 0.3951314091682434
Validation loss: 2.290675108631452

Epoch: 5| Step: 10
Training loss: 0.41686874628067017
Validation loss: 2.3509093622366586

Epoch: 5| Step: 11
Training loss: 0.2986275255680084
Validation loss: 2.327975337704023

Epoch: 399| Step: 0
Training loss: 0.8374229669570923
Validation loss: 2.283013269305229

Epoch: 5| Step: 1
Training loss: 0.3058261573314667
Validation loss: 2.302770887811979

Epoch: 5| Step: 2
Training loss: 0.3149360120296478
Validation loss: 2.2510197858015695

Epoch: 5| Step: 3
Training loss: 0.33310040831565857
Validation loss: 2.2752645760774612

Epoch: 5| Step: 4
Training loss: 0.5573689341545105
Validation loss: 2.273979405562083

Epoch: 5| Step: 5
Training loss: 0.5066834688186646
Validation loss: 2.336664001146952

Epoch: 5| Step: 6
Training loss: 0.5050240755081177
Validation loss: 2.301970899105072

Epoch: 5| Step: 7
Training loss: 0.307905375957489
Validation loss: 2.3170733551184335

Epoch: 5| Step: 8
Training loss: 0.467322438955307
Validation loss: 2.2998367051283517

Epoch: 5| Step: 9
Training loss: 0.31626349687576294
Validation loss: 2.2203196535507836

Epoch: 5| Step: 10
Training loss: 0.4636807441711426
Validation loss: 2.3288320998350778

Epoch: 5| Step: 11
Training loss: 1.0163830518722534
Validation loss: 2.2432079166173935

Epoch: 400| Step: 0
Training loss: 0.7042738199234009
Validation loss: 2.2744453698396683

Epoch: 5| Step: 1
Training loss: 0.4125862121582031
Validation loss: 2.2786512871583304

Epoch: 5| Step: 2
Training loss: 0.341290146112442
Validation loss: 2.320225238800049

Epoch: 5| Step: 3
Training loss: 0.2086435854434967
Validation loss: 2.2192829847335815

Epoch: 5| Step: 4
Training loss: 0.3054437041282654
Validation loss: 2.201064169406891

Epoch: 5| Step: 5
Training loss: 0.4200681746006012
Validation loss: 2.2159514079491296

Epoch: 5| Step: 6
Training loss: 0.2575874924659729
Validation loss: 2.193873718380928

Epoch: 5| Step: 7
Training loss: 0.3633856475353241
Validation loss: 2.3145282367865243

Epoch: 5| Step: 8
Training loss: 0.7025517225265503
Validation loss: 2.266976550221443

Epoch: 5| Step: 9
Training loss: 0.597769558429718
Validation loss: 2.31317829589049

Epoch: 5| Step: 10
Training loss: 0.4822373390197754
Validation loss: 2.245667556921641

Epoch: 5| Step: 11
Training loss: 0.2413087785243988
Validation loss: 2.283007711172104

Epoch: 401| Step: 0
Training loss: 0.2783840000629425
Validation loss: 2.246006111303965

Epoch: 5| Step: 1
Training loss: 0.3278137445449829
Validation loss: 2.2774031460285187

Epoch: 5| Step: 2
Training loss: 0.7288640141487122
Validation loss: 2.3098703970511756

Epoch: 5| Step: 3
Training loss: 0.3147773742675781
Validation loss: 2.2858676513036094

Epoch: 5| Step: 4
Training loss: 0.7531360387802124
Validation loss: 2.2511400282382965

Epoch: 5| Step: 5
Training loss: 0.38492876291275024
Validation loss: 2.2851855009794235

Epoch: 5| Step: 6
Training loss: 0.37624651193618774
Validation loss: 2.2443369030952454

Epoch: 5| Step: 7
Training loss: 0.2340106964111328
Validation loss: 2.2651021778583527

Epoch: 5| Step: 8
Training loss: 0.5703291893005371
Validation loss: 2.273381526271502

Epoch: 5| Step: 9
Training loss: 0.8417981863021851
Validation loss: 2.329484631617864

Epoch: 5| Step: 10
Training loss: 0.40945443511009216
Validation loss: 2.327499896287918

Epoch: 5| Step: 11
Training loss: 0.2509540319442749
Validation loss: 2.260354220867157

Epoch: 402| Step: 0
Training loss: 0.25527095794677734
Validation loss: 2.3280267914136252

Epoch: 5| Step: 1
Training loss: 0.2595977187156677
Validation loss: 2.270202467838923

Epoch: 5| Step: 2
Training loss: 0.7432960867881775
Validation loss: 2.247601012388865

Epoch: 5| Step: 3
Training loss: 0.40884894132614136
Validation loss: 2.2948965430259705

Epoch: 5| Step: 4
Training loss: 0.29962247610092163
Validation loss: 2.2840284506479898

Epoch: 5| Step: 5
Training loss: 0.4296448826789856
Validation loss: 2.3102962573369346

Epoch: 5| Step: 6
Training loss: 0.41110363602638245
Validation loss: 2.331062982479731

Epoch: 5| Step: 7
Training loss: 0.3799135684967041
Validation loss: 2.3194570442040763

Epoch: 5| Step: 8
Training loss: 0.5225998163223267
Validation loss: 2.2605259319146476

Epoch: 5| Step: 9
Training loss: 0.38107961416244507
Validation loss: 2.2787891179323196

Epoch: 5| Step: 10
Training loss: 0.40603989362716675
Validation loss: 2.278429319461187

Epoch: 5| Step: 11
Training loss: 2.0354647636413574
Validation loss: 2.3287860254446664

Epoch: 403| Step: 0
Training loss: 0.34057170152664185
Validation loss: 2.2780544261137643

Epoch: 5| Step: 1
Training loss: 0.6232446432113647
Validation loss: 2.2220587730407715

Epoch: 5| Step: 2
Training loss: 0.7754374146461487
Validation loss: 2.273736909031868

Epoch: 5| Step: 3
Training loss: 0.5145543813705444
Validation loss: 2.2972682267427444

Epoch: 5| Step: 4
Training loss: 0.6004443168640137
Validation loss: 2.2711989333232245

Epoch: 5| Step: 5
Training loss: 0.39414194226264954
Validation loss: 2.3199613193670907

Epoch: 5| Step: 6
Training loss: 0.3303850293159485
Validation loss: 2.249091108640035

Epoch: 5| Step: 7
Training loss: 0.3005172610282898
Validation loss: 2.2509938031435013

Epoch: 5| Step: 8
Training loss: 0.3262621760368347
Validation loss: 2.2912491460641227

Epoch: 5| Step: 9
Training loss: 0.3554947078227997
Validation loss: 2.286253333091736

Epoch: 5| Step: 10
Training loss: 0.3381050229072571
Validation loss: 2.2761818766593933

Epoch: 5| Step: 11
Training loss: 0.1287444829940796
Validation loss: 2.2638469487428665

Epoch: 404| Step: 0
Training loss: 0.39726582169532776
Validation loss: 2.2746378978093467

Epoch: 5| Step: 1
Training loss: 0.40472739934921265
Validation loss: 2.236014728744825

Epoch: 5| Step: 2
Training loss: 0.5134159922599792
Validation loss: 2.2630331764618554

Epoch: 5| Step: 3
Training loss: 0.3260496258735657
Validation loss: 2.2560542623202005

Epoch: 5| Step: 4
Training loss: 0.7553260922431946
Validation loss: 2.265596717596054

Epoch: 5| Step: 5
Training loss: 0.39472824335098267
Validation loss: 2.3059150775273642

Epoch: 5| Step: 6
Training loss: 0.25131723284721375
Validation loss: 2.2633822908004126

Epoch: 5| Step: 7
Training loss: 0.6023467779159546
Validation loss: 2.298011521498362

Epoch: 5| Step: 8
Training loss: 0.2039303332567215
Validation loss: 2.2508591512839

Epoch: 5| Step: 9
Training loss: 0.5664545893669128
Validation loss: 2.264338398973147

Epoch: 5| Step: 10
Training loss: 0.2536899447441101
Validation loss: 2.2981706708669662

Epoch: 5| Step: 11
Training loss: 0.6967771053314209
Validation loss: 2.3434486786524453

Epoch: 405| Step: 0
Training loss: 0.5104202628135681
Validation loss: 2.3053215642770133

Epoch: 5| Step: 1
Training loss: 0.32848963141441345
Validation loss: 2.2976230730613074

Epoch: 5| Step: 2
Training loss: 0.2568334639072418
Validation loss: 2.2678606510162354

Epoch: 5| Step: 3
Training loss: 0.3276973366737366
Validation loss: 2.2757585048675537

Epoch: 5| Step: 4
Training loss: 0.4434170126914978
Validation loss: 2.2809321582317352

Epoch: 5| Step: 5
Training loss: 0.28730711340904236
Validation loss: 2.3174836387236915

Epoch: 5| Step: 6
Training loss: 0.5910293459892273
Validation loss: 2.265694489081701

Epoch: 5| Step: 7
Training loss: 0.40069469809532166
Validation loss: 2.344675416747729

Epoch: 5| Step: 8
Training loss: 0.6971143484115601
Validation loss: 2.344289551178614

Epoch: 5| Step: 9
Training loss: 0.6321190595626831
Validation loss: 2.2945468674103418

Epoch: 5| Step: 10
Training loss: 0.2960595190525055
Validation loss: 2.3111657798290253

Epoch: 5| Step: 11
Training loss: 1.9857730865478516
Validation loss: 2.2533293267091117

Epoch: 406| Step: 0
Training loss: 0.4711056649684906
Validation loss: 2.32461579144001

Epoch: 5| Step: 1
Training loss: 0.5923367142677307
Validation loss: 2.2831534345944724

Epoch: 5| Step: 2
Training loss: 0.5261837840080261
Validation loss: 2.2393306444088616

Epoch: 5| Step: 3
Training loss: 0.2934594750404358
Validation loss: 2.3545259733994803

Epoch: 5| Step: 4
Training loss: 0.2580918073654175
Validation loss: 2.3114726543426514

Epoch: 5| Step: 5
Training loss: 0.45911961793899536
Validation loss: 2.267641027768453

Epoch: 5| Step: 6
Training loss: 0.3981113135814667
Validation loss: 2.273162310322126

Epoch: 5| Step: 7
Training loss: 0.22630318999290466
Validation loss: 2.199416756629944

Epoch: 5| Step: 8
Training loss: 0.5138148069381714
Validation loss: 2.2635265787442527

Epoch: 5| Step: 9
Training loss: 0.2662617266178131
Validation loss: 2.263599932193756

Epoch: 5| Step: 10
Training loss: 0.5590884685516357
Validation loss: 2.2398845305045447

Epoch: 5| Step: 11
Training loss: 0.9172074198722839
Validation loss: 2.270718897382418

Epoch: 407| Step: 0
Training loss: 0.5040596723556519
Validation loss: 2.2382923612991967

Epoch: 5| Step: 1
Training loss: 0.29702264070510864
Validation loss: 2.2167588075002036

Epoch: 5| Step: 2
Training loss: 0.6260944604873657
Validation loss: 2.2560784965753555

Epoch: 5| Step: 3
Training loss: 0.30755820870399475
Validation loss: 2.2381723523139954

Epoch: 5| Step: 4
Training loss: 0.3276539742946625
Validation loss: 2.2785836160182953

Epoch: 5| Step: 5
Training loss: 0.5204550623893738
Validation loss: 2.213615357875824

Epoch: 5| Step: 6
Training loss: 0.28878656029701233
Validation loss: 2.2694234400987625

Epoch: 5| Step: 7
Training loss: 0.4053025245666504
Validation loss: 2.2699554562568665

Epoch: 5| Step: 8
Training loss: 0.6381402015686035
Validation loss: 2.243455618619919

Epoch: 5| Step: 9
Training loss: 0.4646906852722168
Validation loss: 2.1825697322686515

Epoch: 5| Step: 10
Training loss: 0.36513227224349976
Validation loss: 2.2621996899445853

Epoch: 5| Step: 11
Training loss: 0.3041677176952362
Validation loss: 2.2900135964155197

Epoch: 408| Step: 0
Training loss: 0.6303117871284485
Validation loss: 2.3035618414481482

Epoch: 5| Step: 1
Training loss: 0.5720171928405762
Validation loss: 2.2796286841233573

Epoch: 5| Step: 2
Training loss: 0.3667348325252533
Validation loss: 2.296755095322927

Epoch: 5| Step: 3
Training loss: 0.44933000206947327
Validation loss: 2.264594703912735

Epoch: 5| Step: 4
Training loss: 0.33190909028053284
Validation loss: 2.28446501493454

Epoch: 5| Step: 5
Training loss: 0.3118121027946472
Validation loss: 2.301758756240209

Epoch: 5| Step: 6
Training loss: 0.2933278977870941
Validation loss: 2.280671755472819

Epoch: 5| Step: 7
Training loss: 0.2167137861251831
Validation loss: 2.2836802254120507

Epoch: 5| Step: 8
Training loss: 0.889325737953186
Validation loss: 2.272465298573176

Epoch: 5| Step: 9
Training loss: 0.3897436559200287
Validation loss: 2.3004787464936576

Epoch: 5| Step: 10
Training loss: 0.5322366952896118
Validation loss: 2.2339464078346887

Epoch: 5| Step: 11
Training loss: 0.30518972873687744
Validation loss: 2.2944704592227936

Epoch: 409| Step: 0
Training loss: 0.24947252869606018
Validation loss: 2.3389244129260383

Epoch: 5| Step: 1
Training loss: 0.4581660330295563
Validation loss: 2.323470652103424

Epoch: 5| Step: 2
Training loss: 0.42753639817237854
Validation loss: 2.265522991617521

Epoch: 5| Step: 3
Training loss: 0.9587362408638
Validation loss: 2.309251626332601

Epoch: 5| Step: 4
Training loss: 0.5193384289741516
Validation loss: 2.2662914097309113

Epoch: 5| Step: 5
Training loss: 0.3978373110294342
Validation loss: 2.336041803161303

Epoch: 5| Step: 6
Training loss: 0.323527991771698
Validation loss: 2.278938814997673

Epoch: 5| Step: 7
Training loss: 0.48508185148239136
Validation loss: 2.325654059648514

Epoch: 5| Step: 8
Training loss: 0.43746691942214966
Validation loss: 2.2913513481616974

Epoch: 5| Step: 9
Training loss: 0.4279588758945465
Validation loss: 2.2708937327067056

Epoch: 5| Step: 10
Training loss: 0.41464024782180786
Validation loss: 2.270463148752848

Epoch: 5| Step: 11
Training loss: 0.3620748519897461
Validation loss: 2.2509706368048987

Epoch: 410| Step: 0
Training loss: 0.5400114059448242
Validation loss: 2.2829559445381165

Epoch: 5| Step: 1
Training loss: 0.49877506494522095
Validation loss: 2.3048542390267053

Epoch: 5| Step: 2
Training loss: 0.5052269101142883
Validation loss: 2.290672461191813

Epoch: 5| Step: 3
Training loss: 0.28720736503601074
Validation loss: 2.2741095970074334

Epoch: 5| Step: 4
Training loss: 0.5684009194374084
Validation loss: 2.260262946287791

Epoch: 5| Step: 5
Training loss: 0.426642507314682
Validation loss: 2.354880670706431

Epoch: 5| Step: 6
Training loss: 0.3611660599708557
Validation loss: 2.2713448901971183

Epoch: 5| Step: 7
Training loss: 0.3218593895435333
Validation loss: 2.292069395383199

Epoch: 5| Step: 8
Training loss: 0.703690230846405
Validation loss: 2.273230488101641

Epoch: 5| Step: 9
Training loss: 0.2858697772026062
Validation loss: 2.264154930909475

Epoch: 5| Step: 10
Training loss: 0.3097805380821228
Validation loss: 2.270923286676407

Epoch: 5| Step: 11
Training loss: 0.2677726149559021
Validation loss: 2.25861985484759

Epoch: 411| Step: 0
Training loss: 0.7291756868362427
Validation loss: 2.1885652591784797

Epoch: 5| Step: 1
Training loss: 0.4757773280143738
Validation loss: 2.302638610204061

Epoch: 5| Step: 2
Training loss: 0.5566450953483582
Validation loss: 2.2954482485850654

Epoch: 5| Step: 3
Training loss: 0.558339536190033
Validation loss: 2.3013881345589957

Epoch: 5| Step: 4
Training loss: 0.17534862458705902
Validation loss: 2.279259612162908

Epoch: 5| Step: 5
Training loss: 0.330719530582428
Validation loss: 2.316059648990631

Epoch: 5| Step: 6
Training loss: 0.30596208572387695
Validation loss: 2.2980400721232095

Epoch: 5| Step: 7
Training loss: 0.26598218083381653
Validation loss: 2.242948388059934

Epoch: 5| Step: 8
Training loss: 0.4216422140598297
Validation loss: 2.342606713374456

Epoch: 5| Step: 9
Training loss: 0.42587417364120483
Validation loss: 2.2578631242116294

Epoch: 5| Step: 10
Training loss: 0.36485952138900757
Validation loss: 2.237048164010048

Epoch: 5| Step: 11
Training loss: 0.2255975604057312
Validation loss: 2.275215675433477

Epoch: 412| Step: 0
Training loss: 0.691184937953949
Validation loss: 2.288985848426819

Epoch: 5| Step: 1
Training loss: 0.24842700362205505
Validation loss: 2.3311023116111755

Epoch: 5| Step: 2
Training loss: 0.4059974253177643
Validation loss: 2.293411448597908

Epoch: 5| Step: 3
Training loss: 0.2603716254234314
Validation loss: 2.3164200137058892

Epoch: 5| Step: 4
Training loss: 0.3096075654029846
Validation loss: 2.2559767415126166

Epoch: 5| Step: 5
Training loss: 0.6814625263214111
Validation loss: 2.2938131590684256

Epoch: 5| Step: 6
Training loss: 0.3656667172908783
Validation loss: 2.292380914092064

Epoch: 5| Step: 7
Training loss: 0.5765223503112793
Validation loss: 2.2828320066134133

Epoch: 5| Step: 8
Training loss: 0.3267951011657715
Validation loss: 2.252750967939695

Epoch: 5| Step: 9
Training loss: 0.31691664457321167
Validation loss: 2.3207428455352783

Epoch: 5| Step: 10
Training loss: 0.3883303999900818
Validation loss: 2.2681931356589

Epoch: 5| Step: 11
Training loss: 0.20897400379180908
Validation loss: 2.2673619290192923

Epoch: 413| Step: 0
Training loss: 0.5913265943527222
Validation loss: 2.2953222592671714

Epoch: 5| Step: 1
Training loss: 0.4698358476161957
Validation loss: 2.2959422717491784

Epoch: 5| Step: 2
Training loss: 0.5158703923225403
Validation loss: 2.2713741262753806

Epoch: 5| Step: 3
Training loss: 0.38303905725479126
Validation loss: 2.2738019128640494

Epoch: 5| Step: 4
Training loss: 0.3072076439857483
Validation loss: 2.2539502531290054

Epoch: 5| Step: 5
Training loss: 0.5083365440368652
Validation loss: 2.2695195575555167

Epoch: 5| Step: 6
Training loss: 0.35960179567337036
Validation loss: 2.248760774731636

Epoch: 5| Step: 7
Training loss: 0.6752979159355164
Validation loss: 2.2646528482437134

Epoch: 5| Step: 8
Training loss: 0.20869818329811096
Validation loss: 2.2674899895985923

Epoch: 5| Step: 9
Training loss: 0.3572424054145813
Validation loss: 2.317520101865133

Epoch: 5| Step: 10
Training loss: 0.5444047451019287
Validation loss: 2.2954540650049844

Epoch: 5| Step: 11
Training loss: 0.10246026515960693
Validation loss: 2.2920867751042047

Epoch: 414| Step: 0
Training loss: 0.2738085687160492
Validation loss: 2.306481550137202

Epoch: 5| Step: 1
Training loss: 0.28714898228645325
Validation loss: 2.312303438782692

Epoch: 5| Step: 2
Training loss: 0.6463797092437744
Validation loss: 2.26904134452343

Epoch: 5| Step: 3
Training loss: 0.29076212644577026
Validation loss: 2.2766589472691217

Epoch: 5| Step: 4
Training loss: 0.5001909136772156
Validation loss: 2.3097870151201882

Epoch: 5| Step: 5
Training loss: 0.6540226936340332
Validation loss: 2.2989459534486136

Epoch: 5| Step: 6
Training loss: 0.7317395806312561
Validation loss: 2.3164029022057853

Epoch: 5| Step: 7
Training loss: 0.42999935150146484
Validation loss: 2.2894561886787415

Epoch: 5| Step: 8
Training loss: 0.2537863254547119
Validation loss: 2.2861891239881516

Epoch: 5| Step: 9
Training loss: 0.2848881781101227
Validation loss: 2.334937795996666

Epoch: 5| Step: 10
Training loss: 0.4827403426170349
Validation loss: 2.2634570052226386

Epoch: 5| Step: 11
Training loss: 0.5048056840896606
Validation loss: 2.3488839715719223

Epoch: 415| Step: 0
Training loss: 0.5374723672866821
Validation loss: 2.2842641919851303

Epoch: 5| Step: 1
Training loss: 0.4169062077999115
Validation loss: 2.2626352657874427

Epoch: 5| Step: 2
Training loss: 0.3492472171783447
Validation loss: 2.3069173296292624

Epoch: 5| Step: 3
Training loss: 0.593691349029541
Validation loss: 2.306260203321775

Epoch: 5| Step: 4
Training loss: 0.5365489721298218
Validation loss: 2.278008977572123

Epoch: 5| Step: 5
Training loss: 0.5277068018913269
Validation loss: 2.331720987955729

Epoch: 5| Step: 6
Training loss: 0.5386486053466797
Validation loss: 2.2890469829241433

Epoch: 5| Step: 7
Training loss: 0.40641897916793823
Validation loss: 2.318454975883166

Epoch: 5| Step: 8
Training loss: 0.32177072763442993
Validation loss: 2.3040802081425986

Epoch: 5| Step: 9
Training loss: 0.4022487699985504
Validation loss: 2.2353761394818625

Epoch: 5| Step: 10
Training loss: 0.5108221173286438
Validation loss: 2.331014414628347

Epoch: 5| Step: 11
Training loss: 0.28688353300094604
Validation loss: 2.291991020242373

Epoch: 416| Step: 0
Training loss: 0.4776601195335388
Validation loss: 2.311458965142568

Epoch: 5| Step: 1
Training loss: 0.5536518096923828
Validation loss: 2.287301073471705

Epoch: 5| Step: 2
Training loss: 0.3228791356086731
Validation loss: 2.2736167709032693

Epoch: 5| Step: 3
Training loss: 0.4793751835823059
Validation loss: 2.2650465965270996

Epoch: 5| Step: 4
Training loss: 0.3339061141014099
Validation loss: 2.282061686118444

Epoch: 5| Step: 5
Training loss: 0.7086456418037415
Validation loss: 2.3070975641409555

Epoch: 5| Step: 6
Training loss: 0.5649268627166748
Validation loss: 2.2787028302749

Epoch: 5| Step: 7
Training loss: 0.3936646580696106
Validation loss: 2.313411459326744

Epoch: 5| Step: 8
Training loss: 0.30131369829177856
Validation loss: 2.341753304004669

Epoch: 5| Step: 9
Training loss: 0.4414461553096771
Validation loss: 2.34187979499499

Epoch: 5| Step: 10
Training loss: 0.39033204317092896
Validation loss: 2.3003885547320047

Epoch: 5| Step: 11
Training loss: 0.15475177764892578
Validation loss: 2.3498056828975677

Epoch: 417| Step: 0
Training loss: 0.46143215894699097
Validation loss: 2.329110930363337

Epoch: 5| Step: 1
Training loss: 0.5776745080947876
Validation loss: 2.3320694665114083

Epoch: 5| Step: 2
Training loss: 0.3622330129146576
Validation loss: 2.382186154524485

Epoch: 5| Step: 3
Training loss: 0.5655940771102905
Validation loss: 2.3133641133705773

Epoch: 5| Step: 4
Training loss: 0.30555999279022217
Validation loss: 2.299179052313169

Epoch: 5| Step: 5
Training loss: 0.5339856147766113
Validation loss: 2.2739862203598022

Epoch: 5| Step: 6
Training loss: 0.5052131414413452
Validation loss: 2.262997438510259

Epoch: 5| Step: 7
Training loss: 0.8239885568618774
Validation loss: 2.2933146158854165

Epoch: 5| Step: 8
Training loss: 0.3510618209838867
Validation loss: 2.2523361245791116

Epoch: 5| Step: 9
Training loss: 0.5721489191055298
Validation loss: 2.3130158384641013

Epoch: 5| Step: 10
Training loss: 0.4436274468898773
Validation loss: 2.3461014727751413

Epoch: 5| Step: 11
Training loss: 0.54759281873703
Validation loss: 2.2949965645869574

Epoch: 418| Step: 0
Training loss: 0.33247438073158264
Validation loss: 2.3404308458169303

Epoch: 5| Step: 1
Training loss: 0.24783530831336975
Validation loss: 2.3197043041388192

Epoch: 5| Step: 2
Training loss: 0.41343823075294495
Validation loss: 2.2975118160247803

Epoch: 5| Step: 3
Training loss: 0.3996540606021881
Validation loss: 2.340749114751816

Epoch: 5| Step: 4
Training loss: 0.5493844747543335
Validation loss: 2.2782954623301825

Epoch: 5| Step: 5
Training loss: 0.2042173594236374
Validation loss: 2.261108785867691

Epoch: 5| Step: 6
Training loss: 0.5886461138725281
Validation loss: 2.30578450858593

Epoch: 5| Step: 7
Training loss: 0.3421516418457031
Validation loss: 2.3290564864873886

Epoch: 5| Step: 8
Training loss: 0.31400948762893677
Validation loss: 2.3348778833945594

Epoch: 5| Step: 9
Training loss: 0.6942983865737915
Validation loss: 2.3370125889778137

Epoch: 5| Step: 10
Training loss: 0.38400572538375854
Validation loss: 2.249403640627861

Epoch: 5| Step: 11
Training loss: 0.3460462689399719
Validation loss: 2.2819088896115622

Epoch: 419| Step: 0
Training loss: 0.4479028284549713
Validation loss: 2.2752272933721542

Epoch: 5| Step: 1
Training loss: 0.5300872921943665
Validation loss: 2.3182584842046103

Epoch: 5| Step: 2
Training loss: 0.342658668756485
Validation loss: 2.3340250750382743

Epoch: 5| Step: 3
Training loss: 0.4149523675441742
Validation loss: 2.301092435916265

Epoch: 5| Step: 4
Training loss: 0.29937607049942017
Validation loss: 2.2882131934165955

Epoch: 5| Step: 5
Training loss: 0.44884735345840454
Validation loss: 2.2751230597496033

Epoch: 5| Step: 6
Training loss: 0.5356009602546692
Validation loss: 2.318050801753998

Epoch: 5| Step: 7
Training loss: 0.57817143201828
Validation loss: 2.327266057332357

Epoch: 5| Step: 8
Training loss: 0.46932822465896606
Validation loss: 2.2643755028645196

Epoch: 5| Step: 9
Training loss: 0.2818593978881836
Validation loss: 2.280373310049375

Epoch: 5| Step: 10
Training loss: 0.5272356867790222
Validation loss: 2.319839561978976

Epoch: 5| Step: 11
Training loss: 0.1895757019519806
Validation loss: 2.2982097963492074

Epoch: 420| Step: 0
Training loss: 0.27977144718170166
Validation loss: 2.3520505130290985

Epoch: 5| Step: 1
Training loss: 0.351512610912323
Validation loss: 2.319677303234736

Epoch: 5| Step: 2
Training loss: 0.44751057028770447
Validation loss: 2.3427086671193442

Epoch: 5| Step: 3
Training loss: 0.5635671019554138
Validation loss: 2.3670815328756967

Epoch: 5| Step: 4
Training loss: 0.35131093859672546
Validation loss: 2.3064177532990775

Epoch: 5| Step: 5
Training loss: 0.23162980377674103
Validation loss: 2.3330008735259375

Epoch: 5| Step: 6
Training loss: 0.7314424514770508
Validation loss: 2.3124383240938187

Epoch: 5| Step: 7
Training loss: 0.43183380365371704
Validation loss: 2.2559781670570374

Epoch: 5| Step: 8
Training loss: 0.3646702170372009
Validation loss: 2.309671481450399

Epoch: 5| Step: 9
Training loss: 0.48025694489479065
Validation loss: 2.302023728688558

Epoch: 5| Step: 10
Training loss: 0.5810748338699341
Validation loss: 2.3395085831483207

Epoch: 5| Step: 11
Training loss: 0.17123235762119293
Validation loss: 2.305941825111707

Epoch: 421| Step: 0
Training loss: 0.27208539843559265
Validation loss: 2.3225074162085853

Epoch: 5| Step: 1
Training loss: 0.41138237714767456
Validation loss: 2.3503646651903787

Epoch: 5| Step: 2
Training loss: 0.3067673444747925
Validation loss: 2.2794404725233712

Epoch: 5| Step: 3
Training loss: 0.5290279388427734
Validation loss: 2.2997800459464393

Epoch: 5| Step: 4
Training loss: 0.24226610362529755
Validation loss: 2.3189140061537423

Epoch: 5| Step: 5
Training loss: 0.4624761939048767
Validation loss: 2.264704575141271

Epoch: 5| Step: 6
Training loss: 0.5837305784225464
Validation loss: 2.2864647756020227

Epoch: 5| Step: 7
Training loss: 0.32763463258743286
Validation loss: 2.302661587794622

Epoch: 5| Step: 8
Training loss: 0.7046987414360046
Validation loss: 2.2596357067426047

Epoch: 5| Step: 9
Training loss: 0.3714325428009033
Validation loss: 2.3435842096805573

Epoch: 5| Step: 10
Training loss: 0.24370327591896057
Validation loss: 2.3111863136291504

Epoch: 5| Step: 11
Training loss: 0.8473973274230957
Validation loss: 2.2599617540836334

Epoch: 422| Step: 0
Training loss: 0.46187645196914673
Validation loss: 2.262714217106501

Epoch: 5| Step: 1
Training loss: 0.6176342964172363
Validation loss: 2.2566547890504203

Epoch: 5| Step: 2
Training loss: 0.2501348853111267
Validation loss: 2.321225812037786

Epoch: 5| Step: 3
Training loss: 0.40775880217552185
Validation loss: 2.2421423296133676

Epoch: 5| Step: 4
Training loss: 0.2894603908061981
Validation loss: 2.2490749607483544

Epoch: 5| Step: 5
Training loss: 0.43873071670532227
Validation loss: 2.2555926541487374

Epoch: 5| Step: 6
Training loss: 0.4637095034122467
Validation loss: 2.2658540507157645

Epoch: 5| Step: 7
Training loss: 0.4109637141227722
Validation loss: 2.3109539498885474

Epoch: 5| Step: 8
Training loss: 0.5252358317375183
Validation loss: 2.3070205599069595

Epoch: 5| Step: 9
Training loss: 0.4195536971092224
Validation loss: 2.3054507076740265

Epoch: 5| Step: 10
Training loss: 0.4719325006008148
Validation loss: 2.3806541562080383

Epoch: 5| Step: 11
Training loss: 0.41237902641296387
Validation loss: 2.3074274013439813

Epoch: 423| Step: 0
Training loss: 0.38875994086265564
Validation loss: 2.278491457303365

Epoch: 5| Step: 1
Training loss: 0.593683123588562
Validation loss: 2.320099969704946

Epoch: 5| Step: 2
Training loss: 0.3799075484275818
Validation loss: 2.2162412106990814

Epoch: 5| Step: 3
Training loss: 0.6457695364952087
Validation loss: 2.2592110385497413

Epoch: 5| Step: 4
Training loss: 0.40023547410964966
Validation loss: 2.3653078178564706

Epoch: 5| Step: 5
Training loss: 0.4447822570800781
Validation loss: 2.314387251933416

Epoch: 5| Step: 6
Training loss: 0.7434402704238892
Validation loss: 2.317669928073883

Epoch: 5| Step: 7
Training loss: 0.4743921160697937
Validation loss: 2.258811970551809

Epoch: 5| Step: 8
Training loss: 0.22224390506744385
Validation loss: 2.27741447587808

Epoch: 5| Step: 9
Training loss: 0.38341864943504333
Validation loss: 2.2193735440572104

Epoch: 5| Step: 10
Training loss: 0.4992600083351135
Validation loss: 2.279232680797577

Epoch: 5| Step: 11
Training loss: 0.5832306146621704
Validation loss: 2.24829430381457

Epoch: 424| Step: 0
Training loss: 0.4473927915096283
Validation loss: 2.259296407302221

Epoch: 5| Step: 1
Training loss: 0.4042131304740906
Validation loss: 2.305276870727539

Epoch: 5| Step: 2
Training loss: 0.3743913769721985
Validation loss: 2.2949617157379785

Epoch: 5| Step: 3
Training loss: 0.34099632501602173
Validation loss: 2.2727170139551163

Epoch: 5| Step: 4
Training loss: 0.35987934470176697
Validation loss: 2.3106159369150796

Epoch: 5| Step: 5
Training loss: 0.470284640789032
Validation loss: 2.2777963429689407

Epoch: 5| Step: 6
Training loss: 0.3344004452228546
Validation loss: 2.259025981028875

Epoch: 5| Step: 7
Training loss: 0.28963106870651245
Validation loss: 2.2969033221403756

Epoch: 5| Step: 8
Training loss: 0.4452657699584961
Validation loss: 2.2765455543994904

Epoch: 5| Step: 9
Training loss: 0.4377191960811615
Validation loss: 2.2836091816425323

Epoch: 5| Step: 10
Training loss: 0.8120916485786438
Validation loss: 2.3699872295061746

Epoch: 5| Step: 11
Training loss: 0.38352105021476746
Validation loss: 2.3265959123770394

Epoch: 425| Step: 0
Training loss: 0.4158337712287903
Validation loss: 2.3387076208988824

Epoch: 5| Step: 1
Training loss: 0.34757786989212036
Validation loss: 2.3145084381103516

Epoch: 5| Step: 2
Training loss: 0.8516176342964172
Validation loss: 2.3094572126865387

Epoch: 5| Step: 3
Training loss: 0.2845351994037628
Validation loss: 2.336692382891973

Epoch: 5| Step: 4
Training loss: 0.3838256597518921
Validation loss: 2.3058712085088096

Epoch: 5| Step: 5
Training loss: 0.4982321858406067
Validation loss: 2.329434116681417

Epoch: 5| Step: 6
Training loss: 0.4471149444580078
Validation loss: 2.3146980702877045

Epoch: 5| Step: 7
Training loss: 0.22925090789794922
Validation loss: 2.2896107335885367

Epoch: 5| Step: 8
Training loss: 0.4632083475589752
Validation loss: 2.259647712111473

Epoch: 5| Step: 9
Training loss: 0.2651407718658447
Validation loss: 2.2658983866373696

Epoch: 5| Step: 10
Training loss: 0.4043818414211273
Validation loss: 2.2858533362547555

Epoch: 5| Step: 11
Training loss: 0.18095454573631287
Validation loss: 2.3053343345721564

Epoch: 426| Step: 0
Training loss: 0.2976733148097992
Validation loss: 2.287626733382543

Epoch: 5| Step: 1
Training loss: 0.26785266399383545
Validation loss: 2.305940717458725

Epoch: 5| Step: 2
Training loss: 0.6514784097671509
Validation loss: 2.303053855895996

Epoch: 5| Step: 3
Training loss: 0.3565005660057068
Validation loss: 2.3154172698656716

Epoch: 5| Step: 4
Training loss: 0.6769223213195801
Validation loss: 2.2651377419630685

Epoch: 5| Step: 5
Training loss: 0.3111880123615265
Validation loss: 2.2614418814579644

Epoch: 5| Step: 6
Training loss: 0.518140971660614
Validation loss: 2.341001878182093

Epoch: 5| Step: 7
Training loss: 0.3092116415500641
Validation loss: 2.2383373330036798

Epoch: 5| Step: 8
Training loss: 0.3867601156234741
Validation loss: 2.301429162422816

Epoch: 5| Step: 9
Training loss: 0.46289968490600586
Validation loss: 2.285942852497101

Epoch: 5| Step: 10
Training loss: 0.39376604557037354
Validation loss: 2.2843695978323617

Epoch: 5| Step: 11
Training loss: 0.6251639127731323
Validation loss: 2.284269462029139

Epoch: 427| Step: 0
Training loss: 0.8960798382759094
Validation loss: 2.3669901490211487

Epoch: 5| Step: 1
Training loss: 0.4147709012031555
Validation loss: 2.27700512111187

Epoch: 5| Step: 2
Training loss: 0.6583302617073059
Validation loss: 2.315262292822202

Epoch: 5| Step: 3
Training loss: 0.5239354968070984
Validation loss: 2.2755223413308463

Epoch: 5| Step: 4
Training loss: 0.6069250106811523
Validation loss: 2.301929146051407

Epoch: 5| Step: 5
Training loss: 0.3882684111595154
Validation loss: 2.229694445927938

Epoch: 5| Step: 6
Training loss: 0.364254891872406
Validation loss: 2.294301132361094

Epoch: 5| Step: 7
Training loss: 0.2572464048862457
Validation loss: 2.3015043387810388

Epoch: 5| Step: 8
Training loss: 0.2750214636325836
Validation loss: 2.307561993598938

Epoch: 5| Step: 9
Training loss: 0.23028972744941711
Validation loss: 2.318952133258184

Epoch: 5| Step: 10
Training loss: 0.3899368345737457
Validation loss: 2.3069495360056558

Epoch: 5| Step: 11
Training loss: 0.5611106157302856
Validation loss: 2.3164795537789664

Epoch: 428| Step: 0
Training loss: 0.32167765498161316
Validation loss: 2.288248578707377

Epoch: 5| Step: 1
Training loss: 0.7544841170310974
Validation loss: 2.2860317478577294

Epoch: 5| Step: 2
Training loss: 0.31281471252441406
Validation loss: 2.283401697874069

Epoch: 5| Step: 3
Training loss: 0.5173078775405884
Validation loss: 2.3717110554377236

Epoch: 5| Step: 4
Training loss: 0.2866172194480896
Validation loss: 2.2690180987119675

Epoch: 5| Step: 5
Training loss: 0.6867963671684265
Validation loss: 2.3164674838383994

Epoch: 5| Step: 6
Training loss: 0.5362739562988281
Validation loss: 2.2943190137545266

Epoch: 5| Step: 7
Training loss: 0.2557755410671234
Validation loss: 2.275264466802279

Epoch: 5| Step: 8
Training loss: 0.3729713261127472
Validation loss: 2.2752403020858765

Epoch: 5| Step: 9
Training loss: 0.38896438479423523
Validation loss: 2.30808487534523

Epoch: 5| Step: 10
Training loss: 0.4441312849521637
Validation loss: 2.316800226767858

Epoch: 5| Step: 11
Training loss: 0.28878796100616455
Validation loss: 2.251273746291796

Epoch: 429| Step: 0
Training loss: 0.7114275097846985
Validation loss: 2.269290571411451

Epoch: 5| Step: 1
Training loss: 0.45941391587257385
Validation loss: 2.3089352448781333

Epoch: 5| Step: 2
Training loss: 0.32870763540267944
Validation loss: 2.272307962179184

Epoch: 5| Step: 3
Training loss: 0.41784292459487915
Validation loss: 2.2411694079637527

Epoch: 5| Step: 4
Training loss: 0.3792461156845093
Validation loss: 2.2511194199323654

Epoch: 5| Step: 5
Training loss: 0.32210904359817505
Validation loss: 2.2465689380963645

Epoch: 5| Step: 6
Training loss: 0.42355290055274963
Validation loss: 2.3315582325061164

Epoch: 5| Step: 7
Training loss: 0.5822585821151733
Validation loss: 2.305844724178314

Epoch: 5| Step: 8
Training loss: 0.3227483630180359
Validation loss: 2.292707324028015

Epoch: 5| Step: 9
Training loss: 0.34090426564216614
Validation loss: 2.2766499718030295

Epoch: 5| Step: 10
Training loss: 0.7993868589401245
Validation loss: 2.2809955378373465

Epoch: 5| Step: 11
Training loss: 0.2816126346588135
Validation loss: 2.2700508336226144

Epoch: 430| Step: 0
Training loss: 0.16071300208568573
Validation loss: 2.2827154944340386

Epoch: 5| Step: 1
Training loss: 0.3025602698326111
Validation loss: 2.265483245253563

Epoch: 5| Step: 2
Training loss: 0.24813179671764374
Validation loss: 2.2730841090281806

Epoch: 5| Step: 3
Training loss: 0.4802742898464203
Validation loss: 2.230919679005941

Epoch: 5| Step: 4
Training loss: 0.34533795714378357
Validation loss: 2.28049665192763

Epoch: 5| Step: 5
Training loss: 0.48709607124328613
Validation loss: 2.245811233917872

Epoch: 5| Step: 6
Training loss: 0.5527647137641907
Validation loss: 2.2165614863236747

Epoch: 5| Step: 7
Training loss: 0.6096314787864685
Validation loss: 2.2731983910004296

Epoch: 5| Step: 8
Training loss: 0.34673604369163513
Validation loss: 2.2694410383701324

Epoch: 5| Step: 9
Training loss: 0.6306846737861633
Validation loss: 2.265478973587354

Epoch: 5| Step: 10
Training loss: 0.4426030218601227
Validation loss: 2.255290468533834

Epoch: 5| Step: 11
Training loss: 0.5506390333175659
Validation loss: 2.3420912822087607

Epoch: 431| Step: 0
Training loss: 0.32655608654022217
Validation loss: 2.267457276582718

Epoch: 5| Step: 1
Training loss: 0.3821943402290344
Validation loss: 2.267512912551562

Epoch: 5| Step: 2
Training loss: 0.3887181878089905
Validation loss: 2.27333011229833

Epoch: 5| Step: 3
Training loss: 0.3768751621246338
Validation loss: 2.2824762215216956

Epoch: 5| Step: 4
Training loss: 0.3615950345993042
Validation loss: 2.2994687855243683

Epoch: 5| Step: 5
Training loss: 0.22972825169563293
Validation loss: 2.267128492395083

Epoch: 5| Step: 6
Training loss: 0.7500152587890625
Validation loss: 2.253555119037628

Epoch: 5| Step: 7
Training loss: 0.34168606996536255
Validation loss: 2.3340156376361847

Epoch: 5| Step: 8
Training loss: 0.4430832862854004
Validation loss: 2.23627437154452

Epoch: 5| Step: 9
Training loss: 0.7044690251350403
Validation loss: 2.3357558151086173

Epoch: 5| Step: 10
Training loss: 0.2963349223136902
Validation loss: 2.2879152794679007

Epoch: 5| Step: 11
Training loss: 1.8902010917663574
Validation loss: 2.3309830178817115

Epoch: 432| Step: 0
Training loss: 0.4997437596321106
Validation loss: 2.325314333041509

Epoch: 5| Step: 1
Training loss: 0.42877063155174255
Validation loss: 2.329669197400411

Epoch: 5| Step: 2
Training loss: 0.40341082215309143
Validation loss: 2.36070782939593

Epoch: 5| Step: 3
Training loss: 0.4797617495059967
Validation loss: 2.34590574602286

Epoch: 5| Step: 4
Training loss: 0.5259579420089722
Validation loss: 2.268689289689064

Epoch: 5| Step: 5
Training loss: 0.3980904519557953
Validation loss: 2.2984238266944885

Epoch: 5| Step: 6
Training loss: 0.7377081513404846
Validation loss: 2.3206539849440255

Epoch: 5| Step: 7
Training loss: 0.2630358338356018
Validation loss: 2.3779250284036

Epoch: 5| Step: 8
Training loss: 0.3142833113670349
Validation loss: 2.4384818971157074

Epoch: 5| Step: 9
Training loss: 0.3139406740665436
Validation loss: 2.3698384712139764

Epoch: 5| Step: 10
Training loss: 0.2818721532821655
Validation loss: 2.342206339041392

Epoch: 5| Step: 11
Training loss: 0.09657754749059677
Validation loss: 2.306905214985212

Epoch: 433| Step: 0
Training loss: 0.3497239947319031
Validation loss: 2.3469575544198356

Epoch: 5| Step: 1
Training loss: 0.5370838642120361
Validation loss: 2.328996956348419

Epoch: 5| Step: 2
Training loss: 0.47168150544166565
Validation loss: 2.2975242088238397

Epoch: 5| Step: 3
Training loss: 0.43559855222702026
Validation loss: 2.3921318600575128

Epoch: 5| Step: 4
Training loss: 0.3696458339691162
Validation loss: 2.355038419365883

Epoch: 5| Step: 5
Training loss: 0.32672882080078125
Validation loss: 2.2858074804147086

Epoch: 5| Step: 6
Training loss: 0.31092941761016846
Validation loss: 2.286138966679573

Epoch: 5| Step: 7
Training loss: 0.7442833185195923
Validation loss: 2.3513108789920807

Epoch: 5| Step: 8
Training loss: 0.3305377662181854
Validation loss: 2.312063386042913

Epoch: 5| Step: 9
Training loss: 0.2592526078224182
Validation loss: 2.340690861145655

Epoch: 5| Step: 10
Training loss: 0.4609983563423157
Validation loss: 2.2614460488160453

Epoch: 5| Step: 11
Training loss: 1.197609782218933
Validation loss: 2.257998764514923

Epoch: 434| Step: 0
Training loss: 0.4462394118309021
Validation loss: 2.313601399461428

Epoch: 5| Step: 1
Training loss: 0.47772806882858276
Validation loss: 2.321965972582499

Epoch: 5| Step: 2
Training loss: 0.9185800552368164
Validation loss: 2.283469334244728

Epoch: 5| Step: 3
Training loss: 0.3444235622882843
Validation loss: 2.2432708789904914

Epoch: 5| Step: 4
Training loss: 0.2446834146976471
Validation loss: 2.2754362672567368

Epoch: 5| Step: 5
Training loss: 0.5073932409286499
Validation loss: 2.324732859929403

Epoch: 5| Step: 6
Training loss: 0.3055432438850403
Validation loss: 2.300257990757624

Epoch: 5| Step: 7
Training loss: 0.3395810127258301
Validation loss: 2.2778752595186234

Epoch: 5| Step: 8
Training loss: 0.24589447677135468
Validation loss: 2.256026272972425

Epoch: 5| Step: 9
Training loss: 0.20929989218711853
Validation loss: 2.252009058992068

Epoch: 5| Step: 10
Training loss: 0.34643325209617615
Validation loss: 2.331893960634867

Epoch: 5| Step: 11
Training loss: 0.14249303936958313
Validation loss: 2.2815834979216256

Epoch: 435| Step: 0
Training loss: 0.25930479168891907
Validation loss: 2.290857583284378

Epoch: 5| Step: 1
Training loss: 0.39559924602508545
Validation loss: 2.230617582798004

Epoch: 5| Step: 2
Training loss: 0.4202950894832611
Validation loss: 2.294363394379616

Epoch: 5| Step: 3
Training loss: 0.3388020098209381
Validation loss: 2.265820860862732

Epoch: 5| Step: 4
Training loss: 0.39105716347694397
Validation loss: 2.2918479442596436

Epoch: 5| Step: 5
Training loss: 0.48650622367858887
Validation loss: 2.318148131171862

Epoch: 5| Step: 6
Training loss: 0.3186248540878296
Validation loss: 2.2948115468025208

Epoch: 5| Step: 7
Training loss: 0.7569857835769653
Validation loss: 2.3551398615042367

Epoch: 5| Step: 8
Training loss: 0.2655969262123108
Validation loss: 2.334667225678762

Epoch: 5| Step: 9
Training loss: 0.7133172750473022
Validation loss: 2.260296811660131

Epoch: 5| Step: 10
Training loss: 0.296476811170578
Validation loss: 2.2841735084851584

Epoch: 5| Step: 11
Training loss: 0.4506215453147888
Validation loss: 2.2660030821959176

Epoch: 436| Step: 0
Training loss: 0.5232772827148438
Validation loss: 2.2667655994494758

Epoch: 5| Step: 1
Training loss: 0.8108378648757935
Validation loss: 2.252091189225515

Epoch: 5| Step: 2
Training loss: 0.3947519063949585
Validation loss: 2.208016579349836

Epoch: 5| Step: 3
Training loss: 0.3766563832759857
Validation loss: 2.264179080724716

Epoch: 5| Step: 4
Training loss: 0.4630780816078186
Validation loss: 2.251300791899363

Epoch: 5| Step: 5
Training loss: 0.32422393560409546
Validation loss: 2.2841316709915795

Epoch: 5| Step: 6
Training loss: 0.3953755795955658
Validation loss: 2.2760337193806968

Epoch: 5| Step: 7
Training loss: 0.39835429191589355
Validation loss: 2.292243540287018

Epoch: 5| Step: 8
Training loss: 0.35716181993484497
Validation loss: 2.272369851668676

Epoch: 5| Step: 9
Training loss: 0.2755078971385956
Validation loss: 2.2840259273846946

Epoch: 5| Step: 10
Training loss: 0.3250505328178406
Validation loss: 2.288244570295016

Epoch: 5| Step: 11
Training loss: 0.7448186874389648
Validation loss: 2.2687368988990784

Epoch: 437| Step: 0
Training loss: 0.3660549223423004
Validation loss: 2.3021508951981864

Epoch: 5| Step: 1
Training loss: 0.4252052903175354
Validation loss: 2.2552522470553718

Epoch: 5| Step: 2
Training loss: 0.3295426368713379
Validation loss: 2.2805450757344565

Epoch: 5| Step: 3
Training loss: 0.2734156847000122
Validation loss: 2.31626595556736

Epoch: 5| Step: 4
Training loss: 0.25170671939849854
Validation loss: 2.3155388633410134

Epoch: 5| Step: 5
Training loss: 0.4031263291835785
Validation loss: 2.32081530491511

Epoch: 5| Step: 6
Training loss: 0.6859055161476135
Validation loss: 2.273522565762202

Epoch: 5| Step: 7
Training loss: 0.314536988735199
Validation loss: 2.2941739608844123

Epoch: 5| Step: 8
Training loss: 0.5519499182701111
Validation loss: 2.255189895629883

Epoch: 5| Step: 9
Training loss: 0.41152262687683105
Validation loss: 2.340467323859533

Epoch: 5| Step: 10
Training loss: 0.38435253500938416
Validation loss: 2.2655925254027047

Epoch: 5| Step: 11
Training loss: 0.2725614309310913
Validation loss: 2.268726964791616

Epoch: 438| Step: 0
Training loss: 0.409951776266098
Validation loss: 2.3086445132891336

Epoch: 5| Step: 1
Training loss: 0.31089115142822266
Validation loss: 2.3150571336348853

Epoch: 5| Step: 2
Training loss: 0.30068379640579224
Validation loss: 2.274630054831505

Epoch: 5| Step: 3
Training loss: 0.37689632177352905
Validation loss: 2.282619516054789

Epoch: 5| Step: 4
Training loss: 0.3842267692089081
Validation loss: 2.3078587452570596

Epoch: 5| Step: 5
Training loss: 0.7061437368392944
Validation loss: 2.282057429353396

Epoch: 5| Step: 6
Training loss: 0.2783486247062683
Validation loss: 2.3294606109460196

Epoch: 5| Step: 7
Training loss: 0.2591380178928375
Validation loss: 2.282390226920446

Epoch: 5| Step: 8
Training loss: 0.25830861926078796
Validation loss: 2.259559710820516

Epoch: 5| Step: 9
Training loss: 0.9200469851493835
Validation loss: 2.2796106537183127

Epoch: 5| Step: 10
Training loss: 0.36171993613243103
Validation loss: 2.294559453924497

Epoch: 5| Step: 11
Training loss: 0.3585653305053711
Validation loss: 2.223120242357254

Epoch: 439| Step: 0
Training loss: 0.34953227639198303
Validation loss: 2.308481832345327

Epoch: 5| Step: 1
Training loss: 0.2473948895931244
Validation loss: 2.277442693710327

Epoch: 5| Step: 2
Training loss: 0.46539440751075745
Validation loss: 2.315775692462921

Epoch: 5| Step: 3
Training loss: 0.40418338775634766
Validation loss: 2.3225752462943396

Epoch: 5| Step: 4
Training loss: 0.27399200201034546
Validation loss: 2.2602358758449554

Epoch: 5| Step: 5
Training loss: 0.4982723295688629
Validation loss: 2.283202037215233

Epoch: 5| Step: 6
Training loss: 0.4380551874637604
Validation loss: 2.289172053337097

Epoch: 5| Step: 7
Training loss: 0.271251380443573
Validation loss: 2.318256492416064

Epoch: 5| Step: 8
Training loss: 0.38796910643577576
Validation loss: 2.299359525243441

Epoch: 5| Step: 9
Training loss: 0.49952393770217896
Validation loss: 2.211347818374634

Epoch: 5| Step: 10
Training loss: 0.5157055258750916
Validation loss: 2.3179916640122733

Epoch: 5| Step: 11
Training loss: 0.25932490825653076
Validation loss: 2.3057536582152047

Epoch: 440| Step: 0
Training loss: 0.5580055117607117
Validation loss: 2.2709137350320816

Epoch: 5| Step: 1
Training loss: 0.224771648645401
Validation loss: 2.3204476833343506

Epoch: 5| Step: 2
Training loss: 0.25207749009132385
Validation loss: 2.2802570462226868

Epoch: 5| Step: 3
Training loss: 0.3782013952732086
Validation loss: 2.231730967760086

Epoch: 5| Step: 4
Training loss: 0.659538745880127
Validation loss: 2.281792958577474

Epoch: 5| Step: 5
Training loss: 0.4515495300292969
Validation loss: 2.34123702843984

Epoch: 5| Step: 6
Training loss: 0.32123640179634094
Validation loss: 2.30084627866745

Epoch: 5| Step: 7
Training loss: 0.2914868891239166
Validation loss: 2.257399986187617

Epoch: 5| Step: 8
Training loss: 0.49011021852493286
Validation loss: 2.259956101576487

Epoch: 5| Step: 9
Training loss: 0.5147796869277954
Validation loss: 2.310593232512474

Epoch: 5| Step: 10
Training loss: 0.29142603278160095
Validation loss: 2.2535261313120523

Epoch: 5| Step: 11
Training loss: 0.3668712377548218
Validation loss: 2.271719440817833

Epoch: 441| Step: 0
Training loss: 0.3246118128299713
Validation loss: 2.254098196824392

Epoch: 5| Step: 1
Training loss: 0.2506565749645233
Validation loss: 2.2562084396680198

Epoch: 5| Step: 2
Training loss: 0.45584502816200256
Validation loss: 2.289942463239034

Epoch: 5| Step: 3
Training loss: 0.24328768253326416
Validation loss: 2.306202163298925

Epoch: 5| Step: 4
Training loss: 0.5145459175109863
Validation loss: 2.2426139612992606

Epoch: 5| Step: 5
Training loss: 0.3933332562446594
Validation loss: 2.2463439802328744

Epoch: 5| Step: 6
Training loss: 0.3066096901893616
Validation loss: 2.245367079973221

Epoch: 5| Step: 7
Training loss: 0.5210496783256531
Validation loss: 2.311854029695193

Epoch: 5| Step: 8
Training loss: 0.41505852341651917
Validation loss: 2.278275395433108

Epoch: 5| Step: 9
Training loss: 0.7799546122550964
Validation loss: 2.3150847107172012

Epoch: 5| Step: 10
Training loss: 0.3774872422218323
Validation loss: 2.260664920012156

Epoch: 5| Step: 11
Training loss: 0.15667665004730225
Validation loss: 2.271234711011251

Epoch: 442| Step: 0
Training loss: 0.3260231614112854
Validation loss: 2.2689573168754578

Epoch: 5| Step: 1
Training loss: 0.36305147409439087
Validation loss: 2.3021872490644455

Epoch: 5| Step: 2
Training loss: 1.0242559909820557
Validation loss: 2.3027698447306952

Epoch: 5| Step: 3
Training loss: 0.2554573118686676
Validation loss: 2.2537332822879157

Epoch: 5| Step: 4
Training loss: 0.22300127148628235
Validation loss: 2.291790862878164

Epoch: 5| Step: 5
Training loss: 0.36691176891326904
Validation loss: 2.26593325038751

Epoch: 5| Step: 6
Training loss: 0.2949835956096649
Validation loss: 2.310980240503947

Epoch: 5| Step: 7
Training loss: 0.34459662437438965
Validation loss: 2.3095667560895285

Epoch: 5| Step: 8
Training loss: 0.24828025698661804
Validation loss: 2.2852894167105355

Epoch: 5| Step: 9
Training loss: 0.3744276165962219
Validation loss: 2.237929751475652

Epoch: 5| Step: 10
Training loss: 0.374542772769928
Validation loss: 2.30490713318189

Epoch: 5| Step: 11
Training loss: 0.6690486073493958
Validation loss: 2.3150241672992706

Epoch: 443| Step: 0
Training loss: 0.32413047552108765
Validation loss: 2.319714695215225

Epoch: 5| Step: 1
Training loss: 0.3106669783592224
Validation loss: 2.280614892641703

Epoch: 5| Step: 2
Training loss: 0.2778165936470032
Validation loss: 2.305076852440834

Epoch: 5| Step: 3
Training loss: 0.3962661623954773
Validation loss: 2.2906860013802848

Epoch: 5| Step: 4
Training loss: 0.278594970703125
Validation loss: 2.296264419953028

Epoch: 5| Step: 5
Training loss: 0.4377889633178711
Validation loss: 2.309394250313441

Epoch: 5| Step: 6
Training loss: 0.6930190920829773
Validation loss: 2.287153258919716

Epoch: 5| Step: 7
Training loss: 0.2593260109424591
Validation loss: 2.32596784333388

Epoch: 5| Step: 8
Training loss: 0.36546653509140015
Validation loss: 2.2299641917149224

Epoch: 5| Step: 9
Training loss: 0.6242911219596863
Validation loss: 2.2758199274539948

Epoch: 5| Step: 10
Training loss: 0.5065174102783203
Validation loss: 2.246412287155787

Epoch: 5| Step: 11
Training loss: 0.833761990070343
Validation loss: 2.2641701797644296

Epoch: 444| Step: 0
Training loss: 0.4390573501586914
Validation loss: 2.2665300170580545

Epoch: 5| Step: 1
Training loss: 0.24932846426963806
Validation loss: 2.267951101064682

Epoch: 5| Step: 2
Training loss: 0.38690119981765747
Validation loss: 2.3079161594311395

Epoch: 5| Step: 3
Training loss: 0.8030188679695129
Validation loss: 2.2595487783352532

Epoch: 5| Step: 4
Training loss: 0.35397058725357056
Validation loss: 2.2890932857990265

Epoch: 5| Step: 5
Training loss: 0.506824791431427
Validation loss: 2.267897352576256

Epoch: 5| Step: 6
Training loss: 0.37845391035079956
Validation loss: 2.295169641574224

Epoch: 5| Step: 7
Training loss: 0.37372615933418274
Validation loss: 2.331039880712827

Epoch: 5| Step: 8
Training loss: 0.3193887174129486
Validation loss: 2.3058253079652786

Epoch: 5| Step: 9
Training loss: 0.4062070846557617
Validation loss: 2.348751207192739

Epoch: 5| Step: 10
Training loss: 0.4437771737575531
Validation loss: 2.2294054379065833

Epoch: 5| Step: 11
Training loss: 0.5227769613265991
Validation loss: 2.2829237331946692

Epoch: 445| Step: 0
Training loss: 0.3396773636341095
Validation loss: 2.2735586961110434

Epoch: 5| Step: 1
Training loss: 0.4388992190361023
Validation loss: 2.2654654880364737

Epoch: 5| Step: 2
Training loss: 0.48254650831222534
Validation loss: 2.2744726836681366

Epoch: 5| Step: 3
Training loss: 0.34695878624916077
Validation loss: 2.230293318629265

Epoch: 5| Step: 4
Training loss: 0.7103174924850464
Validation loss: 2.325648069381714

Epoch: 5| Step: 5
Training loss: 0.6390681266784668
Validation loss: 2.342953453461329

Epoch: 5| Step: 6
Training loss: 0.4276219308376312
Validation loss: 2.3309134344259896

Epoch: 5| Step: 7
Training loss: 0.350928395986557
Validation loss: 2.360606556137403

Epoch: 5| Step: 8
Training loss: 0.4267125129699707
Validation loss: 2.3126928359270096

Epoch: 5| Step: 9
Training loss: 0.4080832600593567
Validation loss: 2.2942006587982178

Epoch: 5| Step: 10
Training loss: 0.24011576175689697
Validation loss: 2.2741042524576187

Epoch: 5| Step: 11
Training loss: 0.48861533403396606
Validation loss: 2.333915571371714

Epoch: 446| Step: 0
Training loss: 0.4725739359855652
Validation loss: 2.3014619648456573

Epoch: 5| Step: 1
Training loss: 0.5115882158279419
Validation loss: 2.2997399965922036

Epoch: 5| Step: 2
Training loss: 0.26628923416137695
Validation loss: 2.282023956378301

Epoch: 5| Step: 3
Training loss: 0.37942808866500854
Validation loss: 2.298303206761678

Epoch: 5| Step: 4
Training loss: 0.27606436610221863
Validation loss: 2.348167965809504

Epoch: 5| Step: 5
Training loss: 0.31690898537635803
Validation loss: 2.306660463412603

Epoch: 5| Step: 6
Training loss: 0.6977960467338562
Validation loss: 2.2910172194242477

Epoch: 5| Step: 7
Training loss: 0.4488976001739502
Validation loss: 2.3003776421149573

Epoch: 5| Step: 8
Training loss: 0.4461369514465332
Validation loss: 2.26709753771623

Epoch: 5| Step: 9
Training loss: 0.3572586178779602
Validation loss: 2.3497167030970254

Epoch: 5| Step: 10
Training loss: 0.36801376938819885
Validation loss: 2.259730408589045

Epoch: 5| Step: 11
Training loss: 0.3938136100769043
Validation loss: 2.229303076863289

Epoch: 447| Step: 0
Training loss: 0.4463490843772888
Validation loss: 2.3203991999228797

Epoch: 5| Step: 1
Training loss: 0.35341018438339233
Validation loss: 2.2777453611294427

Epoch: 5| Step: 2
Training loss: 0.6785334348678589
Validation loss: 2.3117553889751434

Epoch: 5| Step: 3
Training loss: 0.18823479115962982
Validation loss: 2.3196329474449158

Epoch: 5| Step: 4
Training loss: 0.7078574895858765
Validation loss: 2.2534574468930564

Epoch: 5| Step: 5
Training loss: 0.39137667417526245
Validation loss: 2.2969126403331757

Epoch: 5| Step: 6
Training loss: 0.3911761939525604
Validation loss: 2.3091416458288827

Epoch: 5| Step: 7
Training loss: 0.3288585841655731
Validation loss: 2.3087191780408225

Epoch: 5| Step: 8
Training loss: 0.2897055149078369
Validation loss: 2.341809555888176

Epoch: 5| Step: 9
Training loss: 0.33025768399238586
Validation loss: 2.3078494518995285

Epoch: 5| Step: 10
Training loss: 0.2875427305698395
Validation loss: 2.341529364387194

Epoch: 5| Step: 11
Training loss: 0.2800874710083008
Validation loss: 2.3011212249596915

Epoch: 448| Step: 0
Training loss: 0.33270782232284546
Validation loss: 2.277970016002655

Epoch: 5| Step: 1
Training loss: 0.42263954877853394
Validation loss: 2.2791219701369605

Epoch: 5| Step: 2
Training loss: 0.38624128699302673
Validation loss: 2.323699871699015

Epoch: 5| Step: 3
Training loss: 0.20994910597801208
Validation loss: 2.2550059109926224

Epoch: 5| Step: 4
Training loss: 0.4810263514518738
Validation loss: 2.281435747941335

Epoch: 5| Step: 5
Training loss: 0.5103815197944641
Validation loss: 2.3114765683809915

Epoch: 5| Step: 6
Training loss: 0.5911139249801636
Validation loss: 2.2589255521694818

Epoch: 5| Step: 7
Training loss: 0.6133766174316406
Validation loss: 2.2950363755226135

Epoch: 5| Step: 8
Training loss: 0.20448803901672363
Validation loss: 2.314013803998629

Epoch: 5| Step: 9
Training loss: 0.3381667733192444
Validation loss: 2.248069077730179

Epoch: 5| Step: 10
Training loss: 0.34865278005599976
Validation loss: 2.2809719194968543

Epoch: 5| Step: 11
Training loss: 0.2537473440170288
Validation loss: 2.301627814769745

Epoch: 449| Step: 0
Training loss: 0.6932209730148315
Validation loss: 2.3113240003585815

Epoch: 5| Step: 1
Training loss: 0.4745737910270691
Validation loss: 2.3524782260258994

Epoch: 5| Step: 2
Training loss: 0.28818008303642273
Validation loss: 2.2760614156723022

Epoch: 5| Step: 3
Training loss: 0.7337465286254883
Validation loss: 2.325113147497177

Epoch: 5| Step: 4
Training loss: 0.6181265115737915
Validation loss: 2.3189214766025543

Epoch: 5| Step: 5
Training loss: 0.3567740321159363
Validation loss: 2.2942246198654175

Epoch: 5| Step: 6
Training loss: 0.46073538064956665
Validation loss: 2.2529210845629373

Epoch: 5| Step: 7
Training loss: 0.4000493884086609
Validation loss: 2.230600749452909

Epoch: 5| Step: 8
Training loss: 0.5151506662368774
Validation loss: 2.3144299586613974

Epoch: 5| Step: 9
Training loss: 0.34964507818222046
Validation loss: 2.2410048147042594

Epoch: 5| Step: 10
Training loss: 0.22730794548988342
Validation loss: 2.2962265660365424

Epoch: 5| Step: 11
Training loss: 0.2517242133617401
Validation loss: 2.260918532808622

Epoch: 450| Step: 0
Training loss: 0.27977854013442993
Validation loss: 2.2713511337836585

Epoch: 5| Step: 1
Training loss: 0.3033037781715393
Validation loss: 2.3286594301462173

Epoch: 5| Step: 2
Training loss: 0.27546754479408264
Validation loss: 2.2806179275115332

Epoch: 5| Step: 3
Training loss: 0.5563486218452454
Validation loss: 2.2585793932278952

Epoch: 5| Step: 4
Training loss: 0.5359429121017456
Validation loss: 2.334251085917155

Epoch: 5| Step: 5
Training loss: 0.4081362187862396
Validation loss: 2.3190950204928718

Epoch: 5| Step: 6
Training loss: 0.44786232709884644
Validation loss: 2.3492606778939567

Epoch: 5| Step: 7
Training loss: 0.7888916730880737
Validation loss: 2.251402040322622

Epoch: 5| Step: 8
Training loss: 0.3213565945625305
Validation loss: 2.2942835638920465

Epoch: 5| Step: 9
Training loss: 0.4092697203159332
Validation loss: 2.2913219928741455

Epoch: 5| Step: 10
Training loss: 0.4210822582244873
Validation loss: 2.3134062190850577

Epoch: 5| Step: 11
Training loss: 0.5153910517692566
Validation loss: 2.309981718659401

Epoch: 451| Step: 0
Training loss: 0.3156972825527191
Validation loss: 2.285644600788752

Epoch: 5| Step: 1
Training loss: 0.3152722418308258
Validation loss: 2.2891101439793906

Epoch: 5| Step: 2
Training loss: 0.4775090217590332
Validation loss: 2.302260806163152

Epoch: 5| Step: 3
Training loss: 0.46564096212387085
Validation loss: 2.3614999751249948

Epoch: 5| Step: 4
Training loss: 0.34884214401245117
Validation loss: 2.3418277502059937

Epoch: 5| Step: 5
Training loss: 0.30046647787094116
Validation loss: 2.393324782450994

Epoch: 5| Step: 6
Training loss: 0.40124887228012085
Validation loss: 2.3398762543996177

Epoch: 5| Step: 7
Training loss: 0.542313277721405
Validation loss: 2.260240763425827

Epoch: 5| Step: 8
Training loss: 0.7856353521347046
Validation loss: 2.3333897789319358

Epoch: 5| Step: 9
Training loss: 0.27979859709739685
Validation loss: 2.297986755768458

Epoch: 5| Step: 10
Training loss: 0.43242716789245605
Validation loss: 2.2800933122634888

Epoch: 5| Step: 11
Training loss: 0.24818944931030273
Validation loss: 2.2889705896377563

Epoch: 452| Step: 0
Training loss: 0.4281720221042633
Validation loss: 2.3258278568585715

Epoch: 5| Step: 1
Training loss: 0.33150529861450195
Validation loss: 2.270908539493879

Epoch: 5| Step: 2
Training loss: 0.6577614545822144
Validation loss: 2.2785308212041855

Epoch: 5| Step: 3
Training loss: 0.37382227182388306
Validation loss: 2.3028532365957894

Epoch: 5| Step: 4
Training loss: 0.35495156049728394
Validation loss: 2.2334073781967163

Epoch: 5| Step: 5
Training loss: 0.36309942603111267
Validation loss: 2.2706726690133414

Epoch: 5| Step: 6
Training loss: 0.47492432594299316
Validation loss: 2.324263016382853

Epoch: 5| Step: 7
Training loss: 0.5730492472648621
Validation loss: 2.2513971030712128

Epoch: 5| Step: 8
Training loss: 0.47359052300453186
Validation loss: 2.3171537021795907

Epoch: 5| Step: 9
Training loss: 0.3295712471008301
Validation loss: 2.2649071911970773

Epoch: 5| Step: 10
Training loss: 0.4144136309623718
Validation loss: 2.3738707900047302

Epoch: 5| Step: 11
Training loss: 0.27304384112358093
Validation loss: 2.354147712389628

Epoch: 453| Step: 0
Training loss: 0.3762017488479614
Validation loss: 2.3103630940119424

Epoch: 5| Step: 1
Training loss: 0.6074970960617065
Validation loss: 2.3445206185181937

Epoch: 5| Step: 2
Training loss: 0.3480014503002167
Validation loss: 2.2922096649805703

Epoch: 5| Step: 3
Training loss: 0.34331902861595154
Validation loss: 2.3577620486418405

Epoch: 5| Step: 4
Training loss: 0.3192371428012848
Validation loss: 2.3192765216032663

Epoch: 5| Step: 5
Training loss: 0.31585732102394104
Validation loss: 2.337233543395996

Epoch: 5| Step: 6
Training loss: 0.3082338273525238
Validation loss: 2.3396548330783844

Epoch: 5| Step: 7
Training loss: 0.8163865804672241
Validation loss: 2.377609754602114

Epoch: 5| Step: 8
Training loss: 0.4433775544166565
Validation loss: 2.3492001444101334

Epoch: 5| Step: 9
Training loss: 0.35200709104537964
Validation loss: 2.3156339724858603

Epoch: 5| Step: 10
Training loss: 0.3189367651939392
Validation loss: 2.317375972867012

Epoch: 5| Step: 11
Training loss: 0.30742979049682617
Validation loss: 2.315686658024788

Epoch: 454| Step: 0
Training loss: 0.36357879638671875
Validation loss: 2.255989576379458

Epoch: 5| Step: 1
Training loss: 0.5080140233039856
Validation loss: 2.3192840019861856

Epoch: 5| Step: 2
Training loss: 0.4638025164604187
Validation loss: 2.29212279121081

Epoch: 5| Step: 3
Training loss: 0.37380534410476685
Validation loss: 2.3047365844249725

Epoch: 5| Step: 4
Training loss: 0.2657865881919861
Validation loss: 2.307884782552719

Epoch: 5| Step: 5
Training loss: 0.20851731300354004
Validation loss: 2.315978452563286

Epoch: 5| Step: 6
Training loss: 0.3887271583080292
Validation loss: 2.2924149284760156

Epoch: 5| Step: 7
Training loss: 0.6904385685920715
Validation loss: 2.3224119345347085

Epoch: 5| Step: 8
Training loss: 0.27586129307746887
Validation loss: 2.2799852391084037

Epoch: 5| Step: 9
Training loss: 0.4022340774536133
Validation loss: 2.2861660520235696

Epoch: 5| Step: 10
Training loss: 0.30093446373939514
Validation loss: 2.289930209517479

Epoch: 5| Step: 11
Training loss: 0.35627102851867676
Validation loss: 2.2686488330364227

Epoch: 455| Step: 0
Training loss: 0.26773375272750854
Validation loss: 2.275996893644333

Epoch: 5| Step: 1
Training loss: 0.41952481865882874
Validation loss: 2.2973597000042596

Epoch: 5| Step: 2
Training loss: 0.2931918501853943
Validation loss: 2.327934871117274

Epoch: 5| Step: 3
Training loss: 0.3179747462272644
Validation loss: 2.295884440342585

Epoch: 5| Step: 4
Training loss: 0.642114520072937
Validation loss: 2.2898418257633844

Epoch: 5| Step: 5
Training loss: 0.473301500082016
Validation loss: 2.3144609232743583

Epoch: 5| Step: 6
Training loss: 0.38953009247779846
Validation loss: 2.3093420366446176

Epoch: 5| Step: 7
Training loss: 0.46952611207962036
Validation loss: 2.2894699970881143

Epoch: 5| Step: 8
Training loss: 0.6135196685791016
Validation loss: 2.2146708220243454

Epoch: 5| Step: 9
Training loss: 0.3891396224498749
Validation loss: 2.237685188651085

Epoch: 5| Step: 10
Training loss: 0.4117582440376282
Validation loss: 2.2958959390719733

Epoch: 5| Step: 11
Training loss: 0.40403056144714355
Validation loss: 2.2771453112363815

Epoch: 456| Step: 0
Training loss: 0.4711061418056488
Validation loss: 2.281712089975675

Epoch: 5| Step: 1
Training loss: 0.23022374510765076
Validation loss: 2.2770915776491165

Epoch: 5| Step: 2
Training loss: 0.24332885444164276
Validation loss: 2.2829815248648324

Epoch: 5| Step: 3
Training loss: 0.28900855779647827
Validation loss: 2.280529653032621

Epoch: 5| Step: 4
Training loss: 0.2962847948074341
Validation loss: 2.2341571052869162

Epoch: 5| Step: 5
Training loss: 0.9519511461257935
Validation loss: 2.251363863547643

Epoch: 5| Step: 6
Training loss: 0.3095068335533142
Validation loss: 2.2463679363330207

Epoch: 5| Step: 7
Training loss: 0.4939270615577698
Validation loss: 2.244921386241913

Epoch: 5| Step: 8
Training loss: 0.27573543787002563
Validation loss: 2.239888240893682

Epoch: 5| Step: 9
Training loss: 0.42172470688819885
Validation loss: 2.2578114668528237

Epoch: 5| Step: 10
Training loss: 0.4498106837272644
Validation loss: 2.2262374262015023

Epoch: 5| Step: 11
Training loss: 0.317499577999115
Validation loss: 2.260692204038302

Epoch: 457| Step: 0
Training loss: 0.26953721046447754
Validation loss: 2.207946628332138

Epoch: 5| Step: 1
Training loss: 0.44052624702453613
Validation loss: 2.290462856491407

Epoch: 5| Step: 2
Training loss: 0.33326002955436707
Validation loss: 2.2563497523466745

Epoch: 5| Step: 3
Training loss: 0.4196578860282898
Validation loss: 2.248786896467209

Epoch: 5| Step: 4
Training loss: 0.37543827295303345
Validation loss: 2.3217850079139075

Epoch: 5| Step: 5
Training loss: 0.4458227753639221
Validation loss: 2.24516295393308

Epoch: 5| Step: 6
Training loss: 0.3493499755859375
Validation loss: 2.2719126443068185

Epoch: 5| Step: 7
Training loss: 0.2901536822319031
Validation loss: 2.20551864306132

Epoch: 5| Step: 8
Training loss: 0.8586908578872681
Validation loss: 2.260050798455874

Epoch: 5| Step: 9
Training loss: 0.3540196716785431
Validation loss: 2.2382543881734214

Epoch: 5| Step: 10
Training loss: 0.6081153154373169
Validation loss: 2.317855551838875

Epoch: 5| Step: 11
Training loss: 0.29310429096221924
Validation loss: 2.2511906723181405

Epoch: 458| Step: 0
Training loss: 0.277473121881485
Validation loss: 2.2612985918919244

Epoch: 5| Step: 1
Training loss: 0.4836128354072571
Validation loss: 2.270683546861013

Epoch: 5| Step: 2
Training loss: 0.37129634618759155
Validation loss: 2.2680198500553765

Epoch: 5| Step: 3
Training loss: 0.27565521001815796
Validation loss: 2.273403912782669

Epoch: 5| Step: 4
Training loss: 0.49388012290000916
Validation loss: 2.2535147766272225

Epoch: 5| Step: 5
Training loss: 0.41829365491867065
Validation loss: 2.2808504005273185

Epoch: 5| Step: 6
Training loss: 0.5138357877731323
Validation loss: 2.3380384693543115

Epoch: 5| Step: 7
Training loss: 0.8917967677116394
Validation loss: 2.2903081625699997

Epoch: 5| Step: 8
Training loss: 0.3005112111568451
Validation loss: 2.25971611837546

Epoch: 5| Step: 9
Training loss: 0.4370079040527344
Validation loss: 2.2910364071528115

Epoch: 5| Step: 10
Training loss: 0.44810134172439575
Validation loss: 2.2580636789401374

Epoch: 5| Step: 11
Training loss: 0.607140064239502
Validation loss: 2.248319794734319

Epoch: 459| Step: 0
Training loss: 0.5793598890304565
Validation loss: 2.2715073376893997

Epoch: 5| Step: 1
Training loss: 0.2664047181606293
Validation loss: 2.2301560590664544

Epoch: 5| Step: 2
Training loss: 0.37720155715942383
Validation loss: 2.271874333421389

Epoch: 5| Step: 3
Training loss: 0.2761821746826172
Validation loss: 2.2266721775134406

Epoch: 5| Step: 4
Training loss: 0.5729846954345703
Validation loss: 2.259205957253774

Epoch: 5| Step: 5
Training loss: 0.2682360112667084
Validation loss: 2.333311766386032

Epoch: 5| Step: 6
Training loss: 0.38602763414382935
Validation loss: 2.317863017320633

Epoch: 5| Step: 7
Training loss: 0.2940681576728821
Validation loss: 2.2610480388005576

Epoch: 5| Step: 8
Training loss: 0.989249050617218
Validation loss: 2.254925698041916

Epoch: 5| Step: 9
Training loss: 0.30068451166152954
Validation loss: 2.323679198821386

Epoch: 5| Step: 10
Training loss: 0.27722230553627014
Validation loss: 2.313335051139196

Epoch: 5| Step: 11
Training loss: 0.11293967068195343
Validation loss: 2.2487230549256005

Epoch: 460| Step: 0
Training loss: 0.3129848539829254
Validation loss: 2.2363325158754983

Epoch: 5| Step: 1
Training loss: 0.5094747543334961
Validation loss: 2.2284147143363953

Epoch: 5| Step: 2
Training loss: 0.6339440941810608
Validation loss: 2.298368215560913

Epoch: 5| Step: 3
Training loss: 0.27627140283584595
Validation loss: 2.307001252969106

Epoch: 5| Step: 4
Training loss: 0.29104241728782654
Validation loss: 2.2463718255360923

Epoch: 5| Step: 5
Training loss: 0.6218923330307007
Validation loss: 2.2689746618270874

Epoch: 5| Step: 6
Training loss: 0.47734832763671875
Validation loss: 2.291600465774536

Epoch: 5| Step: 7
Training loss: 0.2348182499408722
Validation loss: 2.285432984431585

Epoch: 5| Step: 8
Training loss: 0.499644935131073
Validation loss: 2.251211166381836

Epoch: 5| Step: 9
Training loss: 0.46589237451553345
Validation loss: 2.345811272660891

Epoch: 5| Step: 10
Training loss: 0.35535264015197754
Validation loss: 2.3052890300750732

Epoch: 5| Step: 11
Training loss: 0.2877269685268402
Validation loss: 2.3657593031724296

Epoch: 461| Step: 0
Training loss: 0.6309455633163452
Validation loss: 2.296923359235128

Epoch: 5| Step: 1
Training loss: 0.6978440284729004
Validation loss: 2.3449700077374778

Epoch: 5| Step: 2
Training loss: 0.3128103017807007
Validation loss: 2.2931108474731445

Epoch: 5| Step: 3
Training loss: 0.4075152277946472
Validation loss: 2.3211368868748345

Epoch: 5| Step: 4
Training loss: 0.3108382821083069
Validation loss: 2.2896383702754974

Epoch: 5| Step: 5
Training loss: 0.3588222563266754
Validation loss: 2.267248645424843

Epoch: 5| Step: 6
Training loss: 0.24758866429328918
Validation loss: 2.2984180003404617

Epoch: 5| Step: 7
Training loss: 0.4072539210319519
Validation loss: 2.3489148070414863

Epoch: 5| Step: 8
Training loss: 0.3358399271965027
Validation loss: 2.3000443379084268

Epoch: 5| Step: 9
Training loss: 0.38243404030799866
Validation loss: 2.2971622745196023

Epoch: 5| Step: 10
Training loss: 0.4068071246147156
Validation loss: 2.334716886281967

Epoch: 5| Step: 11
Training loss: 0.16142049431800842
Validation loss: 2.312585229674975

Epoch: 462| Step: 0
Training loss: 0.3818071484565735
Validation loss: 2.318427895506223

Epoch: 5| Step: 1
Training loss: 0.2947880029678345
Validation loss: 2.3220790127913156

Epoch: 5| Step: 2
Training loss: 0.21017365157604218
Validation loss: 2.2932544400294623

Epoch: 5| Step: 3
Training loss: 0.3063117265701294
Validation loss: 2.2772675454616547

Epoch: 5| Step: 4
Training loss: 0.5304552912712097
Validation loss: 2.277739703655243

Epoch: 5| Step: 5
Training loss: 0.2969633936882019
Validation loss: 2.301859031120936

Epoch: 5| Step: 6
Training loss: 0.7802363038063049
Validation loss: 2.268990616003672

Epoch: 5| Step: 7
Training loss: 0.3417400121688843
Validation loss: 2.2887447426716485

Epoch: 5| Step: 8
Training loss: 0.5180860757827759
Validation loss: 2.3294731279214225

Epoch: 5| Step: 9
Training loss: 0.520553708076477
Validation loss: 2.3099414904912314

Epoch: 5| Step: 10
Training loss: 0.22620339691638947
Validation loss: 2.2658384442329407

Epoch: 5| Step: 11
Training loss: 0.22071081399917603
Validation loss: 2.2367688169082007

Epoch: 463| Step: 0
Training loss: 0.32833531498908997
Validation loss: 2.249517410993576

Epoch: 5| Step: 1
Training loss: 0.3746095299720764
Validation loss: 2.2789353827635446

Epoch: 5| Step: 2
Training loss: 0.3124822676181793
Validation loss: 2.2580605099598565

Epoch: 5| Step: 3
Training loss: 0.3005935549736023
Validation loss: 2.3107949743668237

Epoch: 5| Step: 4
Training loss: 0.4031568467617035
Validation loss: 2.2589613993962607

Epoch: 5| Step: 5
Training loss: 0.4074752926826477
Validation loss: 2.292916124065717

Epoch: 5| Step: 6
Training loss: 0.6847403645515442
Validation loss: 2.247090592980385

Epoch: 5| Step: 7
Training loss: 0.6614566445350647
Validation loss: 2.2665251890818277

Epoch: 5| Step: 8
Training loss: 0.29436808824539185
Validation loss: 2.283211941520373

Epoch: 5| Step: 9
Training loss: 0.49145135283470154
Validation loss: 2.2900118281443915

Epoch: 5| Step: 10
Training loss: 0.2272626906633377
Validation loss: 2.2775361637274423

Epoch: 5| Step: 11
Training loss: 0.3855280876159668
Validation loss: 2.313436190287272

Epoch: 464| Step: 0
Training loss: 0.3139757215976715
Validation loss: 2.248161017894745

Epoch: 5| Step: 1
Training loss: 0.43420296907424927
Validation loss: 2.2742003301779428

Epoch: 5| Step: 2
Training loss: 0.2953473627567291
Validation loss: 2.3192439476648965

Epoch: 5| Step: 3
Training loss: 0.3987484872341156
Validation loss: 2.26535926759243

Epoch: 5| Step: 4
Training loss: 0.5714594721794128
Validation loss: 2.263635903596878

Epoch: 5| Step: 5
Training loss: 0.4792630076408386
Validation loss: 2.3095455368359885

Epoch: 5| Step: 6
Training loss: 0.5505096316337585
Validation loss: 2.2929244339466095

Epoch: 5| Step: 7
Training loss: 0.47897157073020935
Validation loss: 2.2423807978630066

Epoch: 5| Step: 8
Training loss: 0.34389176964759827
Validation loss: 2.24838525056839

Epoch: 5| Step: 9
Training loss: 0.4815312325954437
Validation loss: 2.2684104839960733

Epoch: 5| Step: 10
Training loss: 0.2782297134399414
Validation loss: 2.2664368947347007

Epoch: 5| Step: 11
Training loss: 0.40512019395828247
Validation loss: 2.286761368314425

Epoch: 465| Step: 0
Training loss: 0.2150438278913498
Validation loss: 2.2354377806186676

Epoch: 5| Step: 1
Training loss: 0.48180627822875977
Validation loss: 2.3150055507818856

Epoch: 5| Step: 2
Training loss: 0.5758960843086243
Validation loss: 2.2826137642065683

Epoch: 5| Step: 3
Training loss: 0.5961224436759949
Validation loss: 2.288614014784495

Epoch: 5| Step: 4
Training loss: 0.3592105507850647
Validation loss: 2.2514976064364114

Epoch: 5| Step: 5
Training loss: 0.24759063124656677
Validation loss: 2.3019882837931314

Epoch: 5| Step: 6
Training loss: 0.41243743896484375
Validation loss: 2.283930922547976

Epoch: 5| Step: 7
Training loss: 0.38636916875839233
Validation loss: 2.271223877867063

Epoch: 5| Step: 8
Training loss: 0.32375746965408325
Validation loss: 2.2539016952117286

Epoch: 5| Step: 9
Training loss: 0.2843761444091797
Validation loss: 2.2884529531002045

Epoch: 5| Step: 10
Training loss: 0.30535581707954407
Validation loss: 2.319162825743357

Epoch: 5| Step: 11
Training loss: 0.1017693281173706
Validation loss: 2.2803465525309243

Epoch: 466| Step: 0
Training loss: 0.23395097255706787
Validation loss: 2.2605456014474234

Epoch: 5| Step: 1
Training loss: 0.20235994458198547
Validation loss: 2.260112851858139

Epoch: 5| Step: 2
Training loss: 0.4941030442714691
Validation loss: 2.2913947800795236

Epoch: 5| Step: 3
Training loss: 0.2766362428665161
Validation loss: 2.319704701503118

Epoch: 5| Step: 4
Training loss: 0.46785515546798706
Validation loss: 2.2967368264993033

Epoch: 5| Step: 5
Training loss: 0.28633683919906616
Validation loss: 2.3375050177176795

Epoch: 5| Step: 6
Training loss: 0.38493791222572327
Validation loss: 2.270373155673345

Epoch: 5| Step: 7
Training loss: 0.23859819769859314
Validation loss: 2.32317187388738

Epoch: 5| Step: 8
Training loss: 0.39809855818748474
Validation loss: 2.3159825007120767

Epoch: 5| Step: 9
Training loss: 0.5823520421981812
Validation loss: 2.246382017930349

Epoch: 5| Step: 10
Training loss: 0.47052621841430664
Validation loss: 2.2681478559970856

Epoch: 5| Step: 11
Training loss: 0.2636154890060425
Validation loss: 2.2781606018543243

Epoch: 467| Step: 0
Training loss: 0.21102090179920197
Validation loss: 2.2812289049228034

Epoch: 5| Step: 1
Training loss: 0.42612043023109436
Validation loss: 2.324776286880175

Epoch: 5| Step: 2
Training loss: 0.3295667767524719
Validation loss: 2.2595018992821374

Epoch: 5| Step: 3
Training loss: 0.3824651837348938
Validation loss: 2.2762303153673806

Epoch: 5| Step: 4
Training loss: 0.49564480781555176
Validation loss: 2.239951729774475

Epoch: 5| Step: 5
Training loss: 0.36971020698547363
Validation loss: 2.2638153582811356

Epoch: 5| Step: 6
Training loss: 0.40901613235473633
Validation loss: 2.2271170814832053

Epoch: 5| Step: 7
Training loss: 0.4218045771121979
Validation loss: 2.2749223907788596

Epoch: 5| Step: 8
Training loss: 0.7830056548118591
Validation loss: 2.2359452644983926

Epoch: 5| Step: 9
Training loss: 0.30824437737464905
Validation loss: 2.2854248384634652

Epoch: 5| Step: 10
Training loss: 0.2936059832572937
Validation loss: 2.275839408238729

Epoch: 5| Step: 11
Training loss: 0.27384382486343384
Validation loss: 2.278353586792946

Epoch: 468| Step: 0
Training loss: 0.34304898977279663
Validation loss: 2.2968214750289917

Epoch: 5| Step: 1
Training loss: 0.22917577624320984
Validation loss: 2.2592906951904297

Epoch: 5| Step: 2
Training loss: 0.41723281145095825
Validation loss: 2.2562286953131356

Epoch: 5| Step: 3
Training loss: 0.292182058095932
Validation loss: 2.2922292947769165

Epoch: 5| Step: 4
Training loss: 0.36531421542167664
Validation loss: 2.2265760600566864

Epoch: 5| Step: 5
Training loss: 0.42698270082473755
Validation loss: 2.277889763315519

Epoch: 5| Step: 6
Training loss: 0.594089686870575
Validation loss: 2.2815850426753364

Epoch: 5| Step: 7
Training loss: 0.22596219182014465
Validation loss: 2.2644041379292807

Epoch: 5| Step: 8
Training loss: 0.3140348494052887
Validation loss: 2.3038834234078727

Epoch: 5| Step: 9
Training loss: 0.5508187413215637
Validation loss: 2.2494691063960395

Epoch: 5| Step: 10
Training loss: 0.2579188644886017
Validation loss: 2.3136714696884155

Epoch: 5| Step: 11
Training loss: 0.1928764134645462
Validation loss: 2.278686265150706

Epoch: 469| Step: 0
Training loss: 0.30801793932914734
Validation loss: 2.2680712838967643

Epoch: 5| Step: 1
Training loss: 0.5264343619346619
Validation loss: 2.21373842159907

Epoch: 5| Step: 2
Training loss: 0.569476306438446
Validation loss: 2.2640840212504068

Epoch: 5| Step: 3
Training loss: 0.24166664481163025
Validation loss: 2.214716245730718

Epoch: 5| Step: 4
Training loss: 0.5508290529251099
Validation loss: 2.2955370793739953

Epoch: 5| Step: 5
Training loss: 0.5182872414588928
Validation loss: 2.279971251885096

Epoch: 5| Step: 6
Training loss: 0.26123809814453125
Validation loss: 2.2610327104727426

Epoch: 5| Step: 7
Training loss: 0.25031617283821106
Validation loss: 2.2454887330532074

Epoch: 5| Step: 8
Training loss: 0.25606971979141235
Validation loss: 2.3396034141381583

Epoch: 5| Step: 9
Training loss: 0.4984438419342041
Validation loss: 2.2859048744042716

Epoch: 5| Step: 10
Training loss: 0.31096357107162476
Validation loss: 2.2923163572947183

Epoch: 5| Step: 11
Training loss: 0.30511754751205444
Validation loss: 2.2754912674427032

Epoch: 470| Step: 0
Training loss: 0.5484382510185242
Validation loss: 2.197464490930239

Epoch: 5| Step: 1
Training loss: 0.2481851875782013
Validation loss: 2.2273399035135903

Epoch: 5| Step: 2
Training loss: 0.2275896817445755
Validation loss: 2.2575498720010123

Epoch: 5| Step: 3
Training loss: 0.37611040472984314
Validation loss: 2.2707199652989707

Epoch: 5| Step: 4
Training loss: 0.6753210425376892
Validation loss: 2.284283076723417

Epoch: 5| Step: 5
Training loss: 0.5002920031547546
Validation loss: 2.2233186662197113

Epoch: 5| Step: 6
Training loss: 0.34046515822410583
Validation loss: 2.233373761177063

Epoch: 5| Step: 7
Training loss: 0.3216979205608368
Validation loss: 2.27670689423879

Epoch: 5| Step: 8
Training loss: 0.45760077238082886
Validation loss: 2.2740855614344277

Epoch: 5| Step: 9
Training loss: 0.3419867157936096
Validation loss: 2.2607096284627914

Epoch: 5| Step: 10
Training loss: 0.26338809728622437
Validation loss: 2.2536474665006003

Epoch: 5| Step: 11
Training loss: 0.4365077316761017
Validation loss: 2.303805728753408

Epoch: 471| Step: 0
Training loss: 0.5341989994049072
Validation loss: 2.301280145843824

Epoch: 5| Step: 1
Training loss: 0.2359124720096588
Validation loss: 2.2773023744424186

Epoch: 5| Step: 2
Training loss: 0.3924883306026459
Validation loss: 2.281200885772705

Epoch: 5| Step: 3
Training loss: 0.6286951303482056
Validation loss: 2.254249095916748

Epoch: 5| Step: 4
Training loss: 0.40896064043045044
Validation loss: 2.283908943335215

Epoch: 5| Step: 5
Training loss: 0.416607141494751
Validation loss: 2.252194573481878

Epoch: 5| Step: 6
Training loss: 0.36196815967559814
Validation loss: 2.2380468944708505

Epoch: 5| Step: 7
Training loss: 0.4153826832771301
Validation loss: 2.282952770590782

Epoch: 5| Step: 8
Training loss: 0.38351958990097046
Validation loss: 2.254079749186834

Epoch: 5| Step: 9
Training loss: 0.5608347058296204
Validation loss: 2.351153016090393

Epoch: 5| Step: 10
Training loss: 0.3995203673839569
Validation loss: 2.2896586755911508

Epoch: 5| Step: 11
Training loss: 0.2733278274536133
Validation loss: 2.3121739476919174

Epoch: 472| Step: 0
Training loss: 0.5108623504638672
Validation loss: 2.3387388487656913

Epoch: 5| Step: 1
Training loss: 0.458442747592926
Validation loss: 2.341729313135147

Epoch: 5| Step: 2
Training loss: 0.286659836769104
Validation loss: 2.3456788063049316

Epoch: 5| Step: 3
Training loss: 0.3669249713420868
Validation loss: 2.299186294277509

Epoch: 5| Step: 4
Training loss: 0.3949926495552063
Validation loss: 2.295386552810669

Epoch: 5| Step: 5
Training loss: 0.32008880376815796
Validation loss: 2.3198598126570382

Epoch: 5| Step: 6
Training loss: 0.7418115735054016
Validation loss: 2.334692378838857

Epoch: 5| Step: 7
Training loss: 0.24287763237953186
Validation loss: 2.2147443244854608

Epoch: 5| Step: 8
Training loss: 0.3040481209754944
Validation loss: 2.3142312467098236

Epoch: 5| Step: 9
Training loss: 0.5340757966041565
Validation loss: 2.282339776555697

Epoch: 5| Step: 10
Training loss: 0.21176953613758087
Validation loss: 2.31857239206632

Epoch: 5| Step: 11
Training loss: 0.9742657542228699
Validation loss: 2.2928261955579123

Epoch: 473| Step: 0
Training loss: 0.41395267844200134
Validation loss: 2.2883667647838593

Epoch: 5| Step: 1
Training loss: 0.46441975235939026
Validation loss: 2.3240553736686707

Epoch: 5| Step: 2
Training loss: 0.29816171526908875
Validation loss: 2.2408554603656134

Epoch: 5| Step: 3
Training loss: 0.6090481281280518
Validation loss: 2.2854554851849875

Epoch: 5| Step: 4
Training loss: 0.5039526224136353
Validation loss: 2.289783408244451

Epoch: 5| Step: 5
Training loss: 0.35534346103668213
Validation loss: 2.3116150895754495

Epoch: 5| Step: 6
Training loss: 0.18949520587921143
Validation loss: 2.305879980325699

Epoch: 5| Step: 7
Training loss: 0.33030518889427185
Validation loss: 2.2669831961393356

Epoch: 5| Step: 8
Training loss: 0.26438453793525696
Validation loss: 2.253127564986547

Epoch: 5| Step: 9
Training loss: 0.3469291627407074
Validation loss: 2.247013201316198

Epoch: 5| Step: 10
Training loss: 0.45089927315711975
Validation loss: 2.2710363368193307

Epoch: 5| Step: 11
Training loss: 0.14164093136787415
Validation loss: 2.247569978237152

Epoch: 474| Step: 0
Training loss: 0.42748793959617615
Validation loss: 2.2820878426233926

Epoch: 5| Step: 1
Training loss: 0.8244296908378601
Validation loss: 2.2573514779408774

Epoch: 5| Step: 2
Training loss: 0.3390043377876282
Validation loss: 2.226365774869919

Epoch: 5| Step: 3
Training loss: 0.3876393735408783
Validation loss: 2.2126874725023904

Epoch: 5| Step: 4
Training loss: 0.35177090764045715
Validation loss: 2.274279753367106

Epoch: 5| Step: 5
Training loss: 0.3445433974266052
Validation loss: 2.2438027014335

Epoch: 5| Step: 6
Training loss: 0.2314867079257965
Validation loss: 2.2537300984064736

Epoch: 5| Step: 7
Training loss: 0.48813456296920776
Validation loss: 2.271102264523506

Epoch: 5| Step: 8
Training loss: 0.2516626715660095
Validation loss: 2.2755971600612006

Epoch: 5| Step: 9
Training loss: 0.3535073697566986
Validation loss: 2.2734931955734887

Epoch: 5| Step: 10
Training loss: 0.6377037167549133
Validation loss: 2.28799839814504

Epoch: 5| Step: 11
Training loss: 0.24561166763305664
Validation loss: 2.236470823486646

Epoch: 475| Step: 0
Training loss: 0.43141335248947144
Validation loss: 2.261821066339811

Epoch: 5| Step: 1
Training loss: 0.3118875026702881
Validation loss: 2.238416463136673

Epoch: 5| Step: 2
Training loss: 0.3011862337589264
Validation loss: 2.239076798160871

Epoch: 5| Step: 3
Training loss: 0.30790120363235474
Validation loss: 2.269494503736496

Epoch: 5| Step: 4
Training loss: 0.272602915763855
Validation loss: 2.2501688599586487

Epoch: 5| Step: 5
Training loss: 0.48278799653053284
Validation loss: 2.261998862028122

Epoch: 5| Step: 6
Training loss: 0.7297911643981934
Validation loss: 2.2563488831122718

Epoch: 5| Step: 7
Training loss: 0.3592235743999481
Validation loss: 2.260363608598709

Epoch: 5| Step: 8
Training loss: 0.2909148335456848
Validation loss: 2.227474441130956

Epoch: 5| Step: 9
Training loss: 0.6292484402656555
Validation loss: 2.29276309410731

Epoch: 5| Step: 10
Training loss: 0.24904179573059082
Validation loss: 2.2552508215109506

Epoch: 5| Step: 11
Training loss: 0.4849982261657715
Validation loss: 2.2763906518618264

Epoch: 476| Step: 0
Training loss: 0.47134527564048767
Validation loss: 2.259486109018326

Epoch: 5| Step: 1
Training loss: 0.23171460628509521
Validation loss: 2.316252668698629

Epoch: 5| Step: 2
Training loss: 0.45109549164772034
Validation loss: 2.294619858264923

Epoch: 5| Step: 3
Training loss: 0.3167186379432678
Validation loss: 2.2852944682041803

Epoch: 5| Step: 4
Training loss: 0.4019014239311218
Validation loss: 2.2503530979156494

Epoch: 5| Step: 5
Training loss: 0.3229932188987732
Validation loss: 2.241911455988884

Epoch: 5| Step: 6
Training loss: 0.6385976672172546
Validation loss: 2.3017210960388184

Epoch: 5| Step: 7
Training loss: 0.2730914056301117
Validation loss: 2.3018026451269784

Epoch: 5| Step: 8
Training loss: 0.5632866024971008
Validation loss: 2.2922346889972687

Epoch: 5| Step: 9
Training loss: 0.2548234164714813
Validation loss: 2.2733108401298523

Epoch: 5| Step: 10
Training loss: 0.20178282260894775
Validation loss: 2.317976395289103

Epoch: 5| Step: 11
Training loss: 0.45687663555145264
Validation loss: 2.280723825097084

Epoch: 477| Step: 0
Training loss: 0.2832435965538025
Validation loss: 2.3135897715886435

Epoch: 5| Step: 1
Training loss: 0.25749483704566956
Validation loss: 2.237812260786692

Epoch: 5| Step: 2
Training loss: 0.5800082087516785
Validation loss: 2.3462853928407035

Epoch: 5| Step: 3
Training loss: 0.36180973052978516
Validation loss: 2.264091968536377

Epoch: 5| Step: 4
Training loss: 0.23952265083789825
Validation loss: 2.2853745073080063

Epoch: 5| Step: 5
Training loss: 0.4840497374534607
Validation loss: 2.2396088242530823

Epoch: 5| Step: 6
Training loss: 0.5193086862564087
Validation loss: 2.284060309330622

Epoch: 5| Step: 7
Training loss: 0.42309635877609253
Validation loss: 2.247484634319941

Epoch: 5| Step: 8
Training loss: 0.34367257356643677
Validation loss: 2.28023661673069

Epoch: 5| Step: 9
Training loss: 0.3522724211215973
Validation loss: 2.307574267188708

Epoch: 5| Step: 10
Training loss: 0.1861758828163147
Validation loss: 2.2855321168899536

Epoch: 5| Step: 11
Training loss: 1.9293992519378662
Validation loss: 2.2428065836429596

Epoch: 478| Step: 0
Training loss: 0.5888239145278931
Validation loss: 2.1958355655272803

Epoch: 5| Step: 1
Training loss: 0.3672104775905609
Validation loss: 2.227435747782389

Epoch: 5| Step: 2
Training loss: 0.8027135729789734
Validation loss: 2.2534579237302146

Epoch: 5| Step: 3
Training loss: 0.36201509833335876
Validation loss: 2.2016475796699524

Epoch: 5| Step: 4
Training loss: 0.5365235209465027
Validation loss: 2.3001076380411782

Epoch: 5| Step: 5
Training loss: 0.38271647691726685
Validation loss: 2.252850373586019

Epoch: 5| Step: 6
Training loss: 0.188874751329422
Validation loss: 2.248553549249967

Epoch: 5| Step: 7
Training loss: 0.29688334465026855
Validation loss: 2.254044900337855

Epoch: 5| Step: 8
Training loss: 0.40024763345718384
Validation loss: 2.276805351177851

Epoch: 5| Step: 9
Training loss: 0.37764960527420044
Validation loss: 2.2678400675455728

Epoch: 5| Step: 10
Training loss: 0.20999491214752197
Validation loss: 2.2549562404553094

Epoch: 5| Step: 11
Training loss: 0.22764086723327637
Validation loss: 2.2556245227654776

Epoch: 479| Step: 0
Training loss: 0.21371254324913025
Validation loss: 2.2693689266840615

Epoch: 5| Step: 1
Training loss: 0.3009205460548401
Validation loss: 2.2953891456127167

Epoch: 5| Step: 2
Training loss: 0.4114268720149994
Validation loss: 2.246283228198687

Epoch: 5| Step: 3
Training loss: 0.7330350875854492
Validation loss: 2.2176939447720847

Epoch: 5| Step: 4
Training loss: 0.23630647361278534
Validation loss: 2.2051646014054618

Epoch: 5| Step: 5
Training loss: 0.34696343541145325
Validation loss: 2.285495618979136

Epoch: 5| Step: 6
Training loss: 0.3453589379787445
Validation loss: 2.294759606321653

Epoch: 5| Step: 7
Training loss: 0.45652371644973755
Validation loss: 2.2306950390338898

Epoch: 5| Step: 8
Training loss: 0.4208817481994629
Validation loss: 2.237758164604505

Epoch: 5| Step: 9
Training loss: 0.3005589246749878
Validation loss: 2.279016842444738

Epoch: 5| Step: 10
Training loss: 0.4856787621974945
Validation loss: 2.2311737338701882

Epoch: 5| Step: 11
Training loss: 0.2738170623779297
Validation loss: 2.3118692388137183

Epoch: 480| Step: 0
Training loss: 0.22562351822853088
Validation loss: 2.272112250328064

Epoch: 5| Step: 1
Training loss: 0.6250221729278564
Validation loss: 2.2886099318663278

Epoch: 5| Step: 2
Training loss: 0.4564712643623352
Validation loss: 2.3296168645222983

Epoch: 5| Step: 3
Training loss: 0.4223145842552185
Validation loss: 2.2649500966072083

Epoch: 5| Step: 4
Training loss: 0.6778649687767029
Validation loss: 2.2745025753974915

Epoch: 5| Step: 5
Training loss: 0.3059104084968567
Validation loss: 2.315691461165746

Epoch: 5| Step: 6
Training loss: 0.3307439684867859
Validation loss: 2.306306848923365

Epoch: 5| Step: 7
Training loss: 0.4130847454071045
Validation loss: 2.222100888689359

Epoch: 5| Step: 8
Training loss: 0.3717700242996216
Validation loss: 2.3116357624530792

Epoch: 5| Step: 9
Training loss: 0.27859362959861755
Validation loss: 2.292936459183693

Epoch: 5| Step: 10
Training loss: 0.553341269493103
Validation loss: 2.2549700240294137

Epoch: 5| Step: 11
Training loss: 0.5325497388839722
Validation loss: 2.242529888947805

Epoch: 481| Step: 0
Training loss: 0.36803916096687317
Validation loss: 2.301894168059031

Epoch: 5| Step: 1
Training loss: 0.3073265850543976
Validation loss: 2.246391440431277

Epoch: 5| Step: 2
Training loss: 0.33788004517555237
Validation loss: 2.225645979245504

Epoch: 5| Step: 3
Training loss: 0.3533143401145935
Validation loss: 2.256541281938553

Epoch: 5| Step: 4
Training loss: 0.3438794016838074
Validation loss: 2.2191130369901657

Epoch: 5| Step: 5
Training loss: 0.6575841903686523
Validation loss: 2.254856059948603

Epoch: 5| Step: 6
Training loss: 0.387155681848526
Validation loss: 2.2454274048407874

Epoch: 5| Step: 7
Training loss: 0.47219377756118774
Validation loss: 2.2487852772076926

Epoch: 5| Step: 8
Training loss: 0.30223548412323
Validation loss: 2.2994653383890786

Epoch: 5| Step: 9
Training loss: 0.8167098164558411
Validation loss: 2.2597373525301614

Epoch: 5| Step: 10
Training loss: 0.45205336809158325
Validation loss: 2.2932628144820533

Epoch: 5| Step: 11
Training loss: 0.1672123670578003
Validation loss: 2.231135442852974

Epoch: 482| Step: 0
Training loss: 0.5335735082626343
Validation loss: 2.2952249894539514

Epoch: 5| Step: 1
Training loss: 0.12882530689239502
Validation loss: 2.2602813144524894

Epoch: 5| Step: 2
Training loss: 0.46627968549728394
Validation loss: 2.2334007869164147

Epoch: 5| Step: 3
Training loss: 0.6423177719116211
Validation loss: 2.261393368244171

Epoch: 5| Step: 4
Training loss: 0.48943886160850525
Validation loss: 2.227651461958885

Epoch: 5| Step: 5
Training loss: 0.36760926246643066
Validation loss: 2.2594647059837976

Epoch: 5| Step: 6
Training loss: 0.30717572569847107
Validation loss: 2.2751998702685037

Epoch: 5| Step: 7
Training loss: 0.41991862654685974
Validation loss: 2.212474803129832

Epoch: 5| Step: 8
Training loss: 0.3850035071372986
Validation loss: 2.301984320084254

Epoch: 5| Step: 9
Training loss: 0.2978813350200653
Validation loss: 2.3093584974606833

Epoch: 5| Step: 10
Training loss: 0.48876214027404785
Validation loss: 2.289282808701197

Epoch: 5| Step: 11
Training loss: 0.34414517879486084
Validation loss: 2.3310303489367166

Epoch: 483| Step: 0
Training loss: 0.3250962495803833
Validation loss: 2.2757650514443717

Epoch: 5| Step: 1
Training loss: 0.2925184667110443
Validation loss: 2.2872642328341803

Epoch: 5| Step: 2
Training loss: 0.27656012773513794
Validation loss: 2.294455260038376

Epoch: 5| Step: 3
Training loss: 0.49695056676864624
Validation loss: 2.2628161211808524

Epoch: 5| Step: 4
Training loss: 0.3736414313316345
Validation loss: 2.289340744415919

Epoch: 5| Step: 5
Training loss: 0.6690741777420044
Validation loss: 2.321695407231649

Epoch: 5| Step: 6
Training loss: 0.6662629842758179
Validation loss: 2.3259804596503577

Epoch: 5| Step: 7
Training loss: 0.2508653402328491
Validation loss: 2.351373016834259

Epoch: 5| Step: 8
Training loss: 0.34242838621139526
Validation loss: 2.2885177731513977

Epoch: 5| Step: 9
Training loss: 0.35082799196243286
Validation loss: 2.2804185499747596

Epoch: 5| Step: 10
Training loss: 0.2610817849636078
Validation loss: 2.223499685525894

Epoch: 5| Step: 11
Training loss: 0.2452985942363739
Validation loss: 2.257080316543579

Epoch: 484| Step: 0
Training loss: 0.3247426450252533
Validation loss: 2.2887120991945267

Epoch: 5| Step: 1
Training loss: 0.5411645174026489
Validation loss: 2.315038407842318

Epoch: 5| Step: 2
Training loss: 0.315812885761261
Validation loss: 2.3231985618670783

Epoch: 5| Step: 3
Training loss: 0.4321942925453186
Validation loss: 2.2803364594777427

Epoch: 5| Step: 4
Training loss: 0.609347403049469
Validation loss: 2.3659654359022775

Epoch: 5| Step: 5
Training loss: 0.30235064029693604
Validation loss: 2.2059703916311264

Epoch: 5| Step: 6
Training loss: 0.39462000131607056
Validation loss: 2.263623595237732

Epoch: 5| Step: 7
Training loss: 0.5082801580429077
Validation loss: 2.2752345303694406

Epoch: 5| Step: 8
Training loss: 0.4201522767543793
Validation loss: 2.3025799840688705

Epoch: 5| Step: 9
Training loss: 0.5887623429298401
Validation loss: 2.2638621677954993

Epoch: 5| Step: 10
Training loss: 0.2512466013431549
Validation loss: 2.2581623246272406

Epoch: 5| Step: 11
Training loss: 0.3893048167228699
Validation loss: 2.2789794902006784

Epoch: 485| Step: 0
Training loss: 0.36875882744789124
Validation loss: 2.2636670668919883

Epoch: 5| Step: 1
Training loss: 0.3940585255622864
Validation loss: 2.231609250108401

Epoch: 5| Step: 2
Training loss: 0.26460424065589905
Validation loss: 2.222120280067126

Epoch: 5| Step: 3
Training loss: 0.3506149649620056
Validation loss: 2.2685135205586753

Epoch: 5| Step: 4
Training loss: 0.32457786798477173
Validation loss: 2.238751004139582

Epoch: 5| Step: 5
Training loss: 0.3482355773448944
Validation loss: 2.2720463822285333

Epoch: 5| Step: 6
Training loss: 0.8762471079826355
Validation loss: 2.2463758240143457

Epoch: 5| Step: 7
Training loss: 0.24880504608154297
Validation loss: 2.2578057001034417

Epoch: 5| Step: 8
Training loss: 0.2672363817691803
Validation loss: 2.24087256193161

Epoch: 5| Step: 9
Training loss: 0.24910321831703186
Validation loss: 2.306399534145991

Epoch: 5| Step: 10
Training loss: 0.22900524735450745
Validation loss: 2.2751093904177346

Epoch: 5| Step: 11
Training loss: 0.39446741342544556
Validation loss: 2.329916184147199

Epoch: 486| Step: 0
Training loss: 0.30779415369033813
Validation loss: 2.2974005242188773

Epoch: 5| Step: 1
Training loss: 0.25412487983703613
Validation loss: 2.2761453688144684

Epoch: 5| Step: 2
Training loss: 0.37206852436065674
Validation loss: 2.2515882352987924

Epoch: 5| Step: 3
Training loss: 0.6016423106193542
Validation loss: 2.2986217041810355

Epoch: 5| Step: 4
Training loss: 0.2709619104862213
Validation loss: 2.244157756368319

Epoch: 5| Step: 5
Training loss: 0.5370517373085022
Validation loss: 2.2715663065512977

Epoch: 5| Step: 6
Training loss: 0.6015096306800842
Validation loss: 2.2704023818174996

Epoch: 5| Step: 7
Training loss: 0.39423009753227234
Validation loss: 2.2738636235396066

Epoch: 5| Step: 8
Training loss: 0.30458250641822815
Validation loss: 2.254466265439987

Epoch: 5| Step: 9
Training loss: 0.5687922835350037
Validation loss: 2.2765835424264274

Epoch: 5| Step: 10
Training loss: 0.3173287510871887
Validation loss: 2.273438567916552

Epoch: 5| Step: 11
Training loss: 0.21988779306411743
Validation loss: 2.264173924922943

Epoch: 487| Step: 0
Training loss: 0.19574955105781555
Validation loss: 2.262950211763382

Epoch: 5| Step: 1
Training loss: 0.27075958251953125
Validation loss: 2.241213252147039

Epoch: 5| Step: 2
Training loss: 0.28572532534599304
Validation loss: 2.247169782718023

Epoch: 5| Step: 3
Training loss: 0.3558339476585388
Validation loss: 2.236103355884552

Epoch: 5| Step: 4
Training loss: 0.2827691435813904
Validation loss: 2.263717611630758

Epoch: 5| Step: 5
Training loss: 0.358859121799469
Validation loss: 2.3028033475081124

Epoch: 5| Step: 6
Training loss: 0.6619840860366821
Validation loss: 2.2288034856319427

Epoch: 5| Step: 7
Training loss: 0.5336723923683167
Validation loss: 2.256994058688482

Epoch: 5| Step: 8
Training loss: 0.6092596054077148
Validation loss: 2.249720349907875

Epoch: 5| Step: 9
Training loss: 0.3055136501789093
Validation loss: 2.262722502152125

Epoch: 5| Step: 10
Training loss: 0.21112418174743652
Validation loss: 2.225593169530233

Epoch: 5| Step: 11
Training loss: 1.0353809595108032
Validation loss: 2.243929237127304

Epoch: 488| Step: 0
Training loss: 0.43474501371383667
Validation loss: 2.2645049393177032

Epoch: 5| Step: 1
Training loss: 0.5266693234443665
Validation loss: 2.2590170949697495

Epoch: 5| Step: 2
Training loss: 0.3458639681339264
Validation loss: 2.2410541027784348

Epoch: 5| Step: 3
Training loss: 0.2698768079280853
Validation loss: 2.244615683952967

Epoch: 5| Step: 4
Training loss: 0.4308091700077057
Validation loss: 2.3456088403860726

Epoch: 5| Step: 5
Training loss: 0.32516351342201233
Validation loss: 2.290208781758944

Epoch: 5| Step: 6
Training loss: 0.3485238254070282
Validation loss: 2.282764653364817

Epoch: 5| Step: 7
Training loss: 0.5582850575447083
Validation loss: 2.3273757894833884

Epoch: 5| Step: 8
Training loss: 0.5464240908622742
Validation loss: 2.2692729234695435

Epoch: 5| Step: 9
Training loss: 0.20692133903503418
Validation loss: 2.2717167685429254

Epoch: 5| Step: 10
Training loss: 0.34324902296066284
Validation loss: 2.2744929989178977

Epoch: 5| Step: 11
Training loss: 0.18546104431152344
Validation loss: 2.274548262357712

Epoch: 489| Step: 0
Training loss: 0.272968053817749
Validation loss: 2.2248108983039856

Epoch: 5| Step: 1
Training loss: 0.24442808330059052
Validation loss: 2.3047099808851876

Epoch: 5| Step: 2
Training loss: 0.6066544651985168
Validation loss: 2.2725268999735513

Epoch: 5| Step: 3
Training loss: 0.27473604679107666
Validation loss: 2.259641150633494

Epoch: 5| Step: 4
Training loss: 0.38009577989578247
Validation loss: 2.3022430539131165

Epoch: 5| Step: 5
Training loss: 0.4118136763572693
Validation loss: 2.273346245288849

Epoch: 5| Step: 6
Training loss: 0.44406747817993164
Validation loss: 2.2774472335974374

Epoch: 5| Step: 7
Training loss: 0.42976894974708557
Validation loss: 2.286729246377945

Epoch: 5| Step: 8
Training loss: 0.3065020442008972
Validation loss: 2.312074532111486

Epoch: 5| Step: 9
Training loss: 0.2202218472957611
Validation loss: 2.295311485727628

Epoch: 5| Step: 10
Training loss: 0.3040606379508972
Validation loss: 2.2990450263023376

Epoch: 5| Step: 11
Training loss: 0.4222182035446167
Validation loss: 2.2974143425623574

Epoch: 490| Step: 0
Training loss: 0.3590872883796692
Validation loss: 2.3741057217121124

Epoch: 5| Step: 1
Training loss: 0.27383875846862793
Validation loss: 2.257565349340439

Epoch: 5| Step: 2
Training loss: 0.40146979689598083
Validation loss: 2.296508381764094

Epoch: 5| Step: 3
Training loss: 0.4226875901222229
Validation loss: 2.249619111418724

Epoch: 5| Step: 4
Training loss: 0.7006468772888184
Validation loss: 2.2945636014143624

Epoch: 5| Step: 5
Training loss: 0.32961133122444153
Validation loss: 2.2923304239908853

Epoch: 5| Step: 6
Training loss: 0.2998370826244354
Validation loss: 2.2527985026439032

Epoch: 5| Step: 7
Training loss: 0.33186012506484985
Validation loss: 2.222745805978775

Epoch: 5| Step: 8
Training loss: 0.3536176383495331
Validation loss: 2.202773163715998

Epoch: 5| Step: 9
Training loss: 0.22489699721336365
Validation loss: 2.276158402363459

Epoch: 5| Step: 10
Training loss: 0.3089977204799652
Validation loss: 2.277546316385269

Epoch: 5| Step: 11
Training loss: 0.24551469087600708
Validation loss: 2.3046454886595407

Epoch: 491| Step: 0
Training loss: 0.2349611222743988
Validation loss: 2.2037337174018226

Epoch: 5| Step: 1
Training loss: 0.2013634443283081
Validation loss: 2.243282159169515

Epoch: 5| Step: 2
Training loss: 0.7948907613754272
Validation loss: 2.261258751153946

Epoch: 5| Step: 3
Training loss: 0.48768091201782227
Validation loss: 2.2843689868847528

Epoch: 5| Step: 4
Training loss: 0.4562200605869293
Validation loss: 2.2326156347990036

Epoch: 5| Step: 5
Training loss: 0.309958279132843
Validation loss: 2.285180682937304

Epoch: 5| Step: 6
Training loss: 0.2133345603942871
Validation loss: 2.2800796131292977

Epoch: 5| Step: 7
Training loss: 0.2620695233345032
Validation loss: 2.296142796675364

Epoch: 5| Step: 8
Training loss: 0.5542292594909668
Validation loss: 2.2882452458143234

Epoch: 5| Step: 9
Training loss: 0.3481418490409851
Validation loss: 2.2855428755283356

Epoch: 5| Step: 10
Training loss: 0.1711404025554657
Validation loss: 2.267067606250445

Epoch: 5| Step: 11
Training loss: 0.3882550895214081
Validation loss: 2.3022501369317374

Epoch: 492| Step: 0
Training loss: 0.4025720953941345
Validation loss: 2.2700602263212204

Epoch: 5| Step: 1
Training loss: 0.36418676376342773
Validation loss: 2.2779372334480286

Epoch: 5| Step: 2
Training loss: 0.3081868886947632
Validation loss: 2.2240795294443765

Epoch: 5| Step: 3
Training loss: 0.2710367739200592
Validation loss: 2.3394120236237845

Epoch: 5| Step: 4
Training loss: 0.33390408754348755
Validation loss: 2.2902813057104745

Epoch: 5| Step: 5
Training loss: 0.43444451689720154
Validation loss: 2.2893219689528146

Epoch: 5| Step: 6
Training loss: 0.641076922416687
Validation loss: 2.243564839164416

Epoch: 5| Step: 7
Training loss: 0.3964293599128723
Validation loss: 2.248081927498182

Epoch: 5| Step: 8
Training loss: 0.3544355630874634
Validation loss: 2.2966729352871575

Epoch: 5| Step: 9
Training loss: 0.48521846532821655
Validation loss: 2.2721693168083825

Epoch: 5| Step: 10
Training loss: 0.28701329231262207
Validation loss: 2.3163563708464303

Epoch: 5| Step: 11
Training loss: 0.14858537912368774
Validation loss: 2.291720286011696

Epoch: 493| Step: 0
Training loss: 0.27272313833236694
Validation loss: 2.290129780769348

Epoch: 5| Step: 1
Training loss: 0.3675960600376129
Validation loss: 2.3308985829353333

Epoch: 5| Step: 2
Training loss: 0.758756697177887
Validation loss: 2.2864254961411157

Epoch: 5| Step: 3
Training loss: 0.30509501695632935
Validation loss: 2.2638108233610788

Epoch: 5| Step: 4
Training loss: 0.30732131004333496
Validation loss: 2.2994057138760886

Epoch: 5| Step: 5
Training loss: 0.23583635687828064
Validation loss: 2.274135092894236

Epoch: 5| Step: 6
Training loss: 0.24374821782112122
Validation loss: 2.266347885131836

Epoch: 5| Step: 7
Training loss: 0.36282461881637573
Validation loss: 2.3238353033860526

Epoch: 5| Step: 8
Training loss: 0.2897058427333832
Validation loss: 2.2863835295041404

Epoch: 5| Step: 9
Training loss: 0.5230181813240051
Validation loss: 2.28750541806221

Epoch: 5| Step: 10
Training loss: 0.49349576234817505
Validation loss: 2.236693079272906

Epoch: 5| Step: 11
Training loss: 0.4810029864311218
Validation loss: 2.2942434698343277

Epoch: 494| Step: 0
Training loss: 0.3508167266845703
Validation loss: 2.2799236128727594

Epoch: 5| Step: 1
Training loss: 0.5488448143005371
Validation loss: 2.3077379117409387

Epoch: 5| Step: 2
Training loss: 0.24895313382148743
Validation loss: 2.3384699622790017

Epoch: 5| Step: 3
Training loss: 0.1993374526500702
Validation loss: 2.296190400918325

Epoch: 5| Step: 4
Training loss: 0.3328803777694702
Validation loss: 2.31500510374705

Epoch: 5| Step: 5
Training loss: 0.19793418049812317
Validation loss: 2.2672983209292092

Epoch: 5| Step: 6
Training loss: 0.36555448174476624
Validation loss: 2.269222100575765

Epoch: 5| Step: 7
Training loss: 0.6633726358413696
Validation loss: 2.3037970463434854

Epoch: 5| Step: 8
Training loss: 0.27588343620300293
Validation loss: 2.2797046403090158

Epoch: 5| Step: 9
Training loss: 0.3807276487350464
Validation loss: 2.333437904715538

Epoch: 5| Step: 10
Training loss: 0.25325608253479004
Validation loss: 2.3017104466756186

Epoch: 5| Step: 11
Training loss: 0.7225348949432373
Validation loss: 2.3127698798974357

Epoch: 495| Step: 0
Training loss: 0.3749926686286926
Validation loss: 2.2255106369654336

Epoch: 5| Step: 1
Training loss: 0.2575117349624634
Validation loss: 2.2835076451301575

Epoch: 5| Step: 2
Training loss: 0.42316651344299316
Validation loss: 2.29568745692571

Epoch: 5| Step: 3
Training loss: 0.2691264748573303
Validation loss: 2.2720924268166223

Epoch: 5| Step: 4
Training loss: 0.45623183250427246
Validation loss: 2.3074646840492883

Epoch: 5| Step: 5
Training loss: 0.6843942403793335
Validation loss: 2.298270652691523

Epoch: 5| Step: 6
Training loss: 0.289494127035141
Validation loss: 2.3288120130697885

Epoch: 5| Step: 7
Training loss: 0.6200311779975891
Validation loss: 2.340101738770803

Epoch: 5| Step: 8
Training loss: 0.22285857796669006
Validation loss: 2.33019956946373

Epoch: 5| Step: 9
Training loss: 0.2529070973396301
Validation loss: 2.2663309623797736

Epoch: 5| Step: 10
Training loss: 0.22440023720264435
Validation loss: 2.2542936901251474

Epoch: 5| Step: 11
Training loss: 0.33833661675453186
Validation loss: 2.302318145831426

Epoch: 496| Step: 0
Training loss: 0.5284825563430786
Validation loss: 2.3224663535753884

Epoch: 5| Step: 1
Training loss: 0.586030900478363
Validation loss: 2.3273365249236426

Epoch: 5| Step: 2
Training loss: 0.26339417695999146
Validation loss: 2.3104843894640603

Epoch: 5| Step: 3
Training loss: 0.2263733446598053
Validation loss: 2.315863072872162

Epoch: 5| Step: 4
Training loss: 0.2766977548599243
Validation loss: 2.299474755922953

Epoch: 5| Step: 5
Training loss: 0.459058940410614
Validation loss: 2.3224861125151315

Epoch: 5| Step: 6
Training loss: 0.6314496994018555
Validation loss: 2.3455867966016135

Epoch: 5| Step: 7
Training loss: 0.435723215341568
Validation loss: 2.2956738471984863

Epoch: 5| Step: 8
Training loss: 0.474292129278183
Validation loss: 2.3360562175512314

Epoch: 5| Step: 9
Training loss: 0.29964548349380493
Validation loss: 2.3091761569182077

Epoch: 5| Step: 10
Training loss: 0.410928338766098
Validation loss: 2.31478721400102

Epoch: 5| Step: 11
Training loss: 0.29377472400665283
Validation loss: 2.3212640384833017

Epoch: 497| Step: 0
Training loss: 0.2475457638502121
Validation loss: 2.2749552031358085

Epoch: 5| Step: 1
Training loss: 0.374294638633728
Validation loss: 2.2518046150604882

Epoch: 5| Step: 2
Training loss: 0.8159703016281128
Validation loss: 2.2938647816578546

Epoch: 5| Step: 3
Training loss: 0.4496708810329437
Validation loss: 2.250330169995626

Epoch: 5| Step: 4
Training loss: 0.49040165543556213
Validation loss: 2.3296293119589486

Epoch: 5| Step: 5
Training loss: 0.3079150319099426
Validation loss: 2.29349347949028

Epoch: 5| Step: 6
Training loss: 0.2909570336341858
Validation loss: 2.294048915306727

Epoch: 5| Step: 7
Training loss: 0.3708175718784332
Validation loss: 2.3052509278059006

Epoch: 5| Step: 8
Training loss: 0.6152358651161194
Validation loss: 2.270924389362335

Epoch: 5| Step: 9
Training loss: 0.35175448656082153
Validation loss: 2.3074396898349128

Epoch: 5| Step: 10
Training loss: 0.3276992440223694
Validation loss: 2.3205235799153647

Epoch: 5| Step: 11
Training loss: 0.4044126570224762
Validation loss: 2.3071387807528176

Epoch: 498| Step: 0
Training loss: 0.36466747522354126
Validation loss: 2.283556282520294

Epoch: 5| Step: 1
Training loss: 0.2574829161167145
Validation loss: 2.258077879746755

Epoch: 5| Step: 2
Training loss: 0.2787570357322693
Validation loss: 2.2798668841520944

Epoch: 5| Step: 3
Training loss: 0.32879549264907837
Validation loss: 2.27145978808403

Epoch: 5| Step: 4
Training loss: 0.3341320753097534
Validation loss: 2.271191398302714

Epoch: 5| Step: 5
Training loss: 0.6159230470657349
Validation loss: 2.3165229956309

Epoch: 5| Step: 6
Training loss: 0.5133333206176758
Validation loss: 2.261832515398661

Epoch: 5| Step: 7
Training loss: 0.2932811379432678
Validation loss: 2.249028672774633

Epoch: 5| Step: 8
Training loss: 0.35680824518203735
Validation loss: 2.231843501329422

Epoch: 5| Step: 9
Training loss: 0.5010722279548645
Validation loss: 2.2614622910817466

Epoch: 5| Step: 10
Training loss: 0.45673054456710815
Validation loss: 2.2791625410318375

Epoch: 5| Step: 11
Training loss: 0.3049035668373108
Validation loss: 2.2731565982103348

Epoch: 499| Step: 0
Training loss: 0.5034345388412476
Validation loss: 2.3355340560277305

Epoch: 5| Step: 1
Training loss: 0.22920146584510803
Validation loss: 2.294898291428884

Epoch: 5| Step: 2
Training loss: 0.3098357617855072
Validation loss: 2.2806774576505027

Epoch: 5| Step: 3
Training loss: 0.3428466320037842
Validation loss: 2.2593903243541718

Epoch: 5| Step: 4
Training loss: 0.3281499743461609
Validation loss: 2.278056045373281

Epoch: 5| Step: 5
Training loss: 0.22574178874492645
Validation loss: 2.266240586837133

Epoch: 5| Step: 6
Training loss: 0.7353253364562988
Validation loss: 2.325448974967003

Epoch: 5| Step: 7
Training loss: 0.5626471042633057
Validation loss: 2.3083130717277527

Epoch: 5| Step: 8
Training loss: 0.24341920018196106
Validation loss: 2.306270698706309

Epoch: 5| Step: 9
Training loss: 0.3832052946090698
Validation loss: 2.312195916970571

Epoch: 5| Step: 10
Training loss: 0.37861162424087524
Validation loss: 2.298740570743879

Epoch: 5| Step: 11
Training loss: 0.4007952809333801
Validation loss: 2.30889522532622

Epoch: 500| Step: 0
Training loss: 0.27453768253326416
Validation loss: 2.3146772583325705

Epoch: 5| Step: 1
Training loss: 0.5748675465583801
Validation loss: 2.290840297937393

Epoch: 5| Step: 2
Training loss: 0.24575228989124298
Validation loss: 2.299667944510778

Epoch: 5| Step: 3
Training loss: 0.37530022859573364
Validation loss: 2.283083498477936

Epoch: 5| Step: 4
Training loss: 0.4621356427669525
Validation loss: 2.3106481035550437

Epoch: 5| Step: 5
Training loss: 0.35224947333335876
Validation loss: 2.2431949923435845

Epoch: 5| Step: 6
Training loss: 0.3762832283973694
Validation loss: 2.2850078095992408

Epoch: 5| Step: 7
Training loss: 0.28028982877731323
Validation loss: 2.2296420137087503

Epoch: 5| Step: 8
Training loss: 0.5884837508201599
Validation loss: 2.2580808848142624

Epoch: 5| Step: 9
Training loss: 0.28051191568374634
Validation loss: 2.2652858098347983

Epoch: 5| Step: 10
Training loss: 0.46183139085769653
Validation loss: 2.257035290201505

Epoch: 5| Step: 11
Training loss: 0.3072359263896942
Validation loss: 2.280196249485016

Testing loss: 2.0090545956179393
