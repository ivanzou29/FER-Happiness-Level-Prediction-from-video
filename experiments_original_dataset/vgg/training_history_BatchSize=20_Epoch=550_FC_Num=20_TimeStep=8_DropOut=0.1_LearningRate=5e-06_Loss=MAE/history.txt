Epoch: 1| Step: 0
Training loss: 2.7950470447540283
Validation loss: 2.795096526543299

Epoch: 5| Step: 1
Training loss: 3.0447049140930176
Validation loss: 2.7837308446566262

Epoch: 5| Step: 2
Training loss: 3.8183798789978027
Validation loss: 2.7748158673445382

Epoch: 5| Step: 3
Training loss: 2.5359230041503906
Validation loss: 2.765909214814504

Epoch: 5| Step: 4
Training loss: 2.8017024993896484
Validation loss: 2.7553985118865967

Epoch: 5| Step: 5
Training loss: 2.469956874847412
Validation loss: 2.7527458171049752

Epoch: 5| Step: 6
Training loss: 3.0539355278015137
Validation loss: 2.743030001719793

Epoch: 5| Step: 7
Training loss: 2.6391403675079346
Validation loss: 2.736715982357661

Epoch: 5| Step: 8
Training loss: 3.2881760597229004
Validation loss: 2.728731860717138

Epoch: 5| Step: 9
Training loss: 3.2752914428710938
Validation loss: 2.7203692694505057

Epoch: 5| Step: 10
Training loss: 2.9510154724121094
Validation loss: 2.7114535669485726

Epoch: 5| Step: 11
Training loss: 2.3717920780181885
Validation loss: 2.7060904006163278

Epoch: 2| Step: 0
Training loss: 2.792853593826294
Validation loss: 2.6974294185638428

Epoch: 5| Step: 1
Training loss: 3.1868953704833984
Validation loss: 2.6931430449088416

Epoch: 5| Step: 2
Training loss: 3.1157007217407227
Validation loss: 2.6807053883870444

Epoch: 5| Step: 3
Training loss: 2.7248427867889404
Validation loss: 2.6740402380625405

Epoch: 5| Step: 4
Training loss: 2.7235469818115234
Validation loss: 2.666318655014038

Epoch: 5| Step: 5
Training loss: 3.3852195739746094
Validation loss: 2.6554264624913535

Epoch: 5| Step: 6
Training loss: 2.9309563636779785
Validation loss: 2.648439715305964

Epoch: 5| Step: 7
Training loss: 2.5642991065979004
Validation loss: 2.635656495889028

Epoch: 5| Step: 8
Training loss: 2.457242727279663
Validation loss: 2.6292575895786285

Epoch: 5| Step: 9
Training loss: 2.8830463886260986
Validation loss: 2.6156809329986572

Epoch: 5| Step: 10
Training loss: 2.509939670562744
Validation loss: 2.6005525290966034

Epoch: 5| Step: 11
Training loss: 2.623866319656372
Validation loss: 2.593926618496577

Epoch: 3| Step: 0
Training loss: 2.88444447517395
Validation loss: 2.580837140480677

Epoch: 5| Step: 1
Training loss: 2.482236862182617
Validation loss: 2.568229009707769

Epoch: 5| Step: 2
Training loss: 2.4573864936828613
Validation loss: 2.5535704096158347

Epoch: 5| Step: 3
Training loss: 2.7134337425231934
Validation loss: 2.543155978123347

Epoch: 5| Step: 4
Training loss: 2.4781687259674072
Validation loss: 2.5325661351283393

Epoch: 5| Step: 5
Training loss: 2.743659019470215
Validation loss: 2.5180583000183105

Epoch: 5| Step: 6
Training loss: 2.7581236362457275
Validation loss: 2.50272266070048

Epoch: 5| Step: 7
Training loss: 3.106600284576416
Validation loss: 2.488372584184011

Epoch: 5| Step: 8
Training loss: 2.349480152130127
Validation loss: 2.4696335792541504

Epoch: 5| Step: 9
Training loss: 2.9953243732452393
Validation loss: 2.447510321935018

Epoch: 5| Step: 10
Training loss: 2.4896750450134277
Validation loss: 2.425861105322838

Epoch: 5| Step: 11
Training loss: 1.7014026641845703
Validation loss: 2.4116445183753967

Epoch: 4| Step: 0
Training loss: 2.779339551925659
Validation loss: 2.390153090159098

Epoch: 5| Step: 1
Training loss: 2.8219878673553467
Validation loss: 2.3614641626675925

Epoch: 5| Step: 2
Training loss: 2.393172025680542
Validation loss: 2.337837427854538

Epoch: 5| Step: 3
Training loss: 2.1266980171203613
Validation loss: 2.3107529481252036

Epoch: 5| Step: 4
Training loss: 2.2794277667999268
Validation loss: 2.2827141930659614

Epoch: 5| Step: 5
Training loss: 2.6823296546936035
Validation loss: 2.262317433953285

Epoch: 5| Step: 6
Training loss: 1.8043321371078491
Validation loss: 2.2353450854619346

Epoch: 5| Step: 7
Training loss: 2.4968533515930176
Validation loss: 2.207020123799642

Epoch: 5| Step: 8
Training loss: 2.210468292236328
Validation loss: 2.183582271138827

Epoch: 5| Step: 9
Training loss: 2.347999095916748
Validation loss: 2.1524617671966553

Epoch: 5| Step: 10
Training loss: 2.037417411804199
Validation loss: 2.129720384875933

Epoch: 5| Step: 11
Training loss: 1.4205845594406128
Validation loss: 2.1030218501885733

Epoch: 5| Step: 0
Training loss: 2.22585391998291
Validation loss: 2.090905417998632

Epoch: 5| Step: 1
Training loss: 2.4404444694519043
Validation loss: 2.068056672811508

Epoch: 5| Step: 2
Training loss: 1.9052181243896484
Validation loss: 2.056324670712153

Epoch: 5| Step: 3
Training loss: 2.398297071456909
Validation loss: 2.042263299226761

Epoch: 5| Step: 4
Training loss: 1.9637473821640015
Validation loss: 2.030904029806455

Epoch: 5| Step: 5
Training loss: 2.5217483043670654
Validation loss: 2.03630268573761

Epoch: 5| Step: 6
Training loss: 2.2300021648406982
Validation loss: 2.031913240750631

Epoch: 5| Step: 7
Training loss: 1.8420515060424805
Validation loss: 2.034309690197309

Epoch: 5| Step: 8
Training loss: 1.7066442966461182
Validation loss: 2.0402425030867257

Epoch: 5| Step: 9
Training loss: 1.7704048156738281
Validation loss: 2.0500496278206506

Epoch: 5| Step: 10
Training loss: 2.474752902984619
Validation loss: 2.060391828417778

Epoch: 5| Step: 11
Training loss: 0.5874601602554321
Validation loss: 2.064235652486483

Epoch: 6| Step: 0
Training loss: 1.9496066570281982
Validation loss: 2.0814205209414163

Epoch: 5| Step: 1
Training loss: 1.972621202468872
Validation loss: 2.0851226150989532

Epoch: 5| Step: 2
Training loss: 2.110663890838623
Validation loss: 2.114734614888827

Epoch: 5| Step: 3
Training loss: 2.1509041786193848
Validation loss: 2.1396682957808175

Epoch: 5| Step: 4
Training loss: 2.343195676803589
Validation loss: 2.134578416744868

Epoch: 5| Step: 5
Training loss: 1.743886947631836
Validation loss: 2.1448776721954346

Epoch: 5| Step: 6
Training loss: 2.5517096519470215
Validation loss: 2.123931184411049

Epoch: 5| Step: 7
Training loss: 2.0164313316345215
Validation loss: 2.1242296199003854

Epoch: 5| Step: 8
Training loss: 2.065007448196411
Validation loss: 2.1181484907865524

Epoch: 5| Step: 9
Training loss: 2.0640218257904053
Validation loss: 2.0784298280874887

Epoch: 5| Step: 10
Training loss: 2.0645010471343994
Validation loss: 2.0647120078404746

Epoch: 5| Step: 11
Training loss: 2.263998031616211
Validation loss: 2.055335611104965

Epoch: 7| Step: 0
Training loss: 1.5262800455093384
Validation loss: 2.050592770179113

Epoch: 5| Step: 1
Training loss: 1.8193928003311157
Validation loss: 2.040585642059644

Epoch: 5| Step: 2
Training loss: 2.45569109916687
Validation loss: 2.0366992354393005

Epoch: 5| Step: 3
Training loss: 1.986411690711975
Validation loss: 2.039540703097979

Epoch: 5| Step: 4
Training loss: 1.9631578922271729
Validation loss: 2.0289123008648553

Epoch: 5| Step: 5
Training loss: 2.547934055328369
Validation loss: 2.0384614864985147

Epoch: 5| Step: 6
Training loss: 2.3561851978302
Validation loss: 2.034303034345309

Epoch: 5| Step: 7
Training loss: 1.9345200061798096
Validation loss: 2.026257505019506

Epoch: 5| Step: 8
Training loss: 1.8720134496688843
Validation loss: 2.0296951482693353

Epoch: 5| Step: 9
Training loss: 2.158902406692505
Validation loss: 2.0312248269716897

Epoch: 5| Step: 10
Training loss: 2.2301197052001953
Validation loss: 2.0187427500883737

Epoch: 5| Step: 11
Training loss: 2.0582425594329834
Validation loss: 2.0239951511224112

Epoch: 8| Step: 0
Training loss: 2.3482747077941895
Validation loss: 2.0226638317108154

Epoch: 5| Step: 1
Training loss: 2.080805778503418
Validation loss: 2.034856071074804

Epoch: 5| Step: 2
Training loss: 2.1648600101470947
Validation loss: 2.020257199803988

Epoch: 5| Step: 3
Training loss: 2.2072644233703613
Validation loss: 2.0282660772403083

Epoch: 5| Step: 4
Training loss: 1.9874565601348877
Validation loss: 2.028209239244461

Epoch: 5| Step: 5
Training loss: 1.5256189107894897
Validation loss: 2.0265938192605972

Epoch: 5| Step: 6
Training loss: 2.093029260635376
Validation loss: 2.006351957718531

Epoch: 5| Step: 7
Training loss: 2.1103389263153076
Validation loss: 2.024594714244207

Epoch: 5| Step: 8
Training loss: 1.8505617380142212
Validation loss: 2.0248735000689826

Epoch: 5| Step: 9
Training loss: 2.8200201988220215
Validation loss: 2.016638368368149

Epoch: 5| Step: 10
Training loss: 1.612373948097229
Validation loss: 2.021228243907293

Epoch: 5| Step: 11
Training loss: 1.9212489128112793
Validation loss: 2.029926468928655

Epoch: 9| Step: 0
Training loss: 1.7894103527069092
Validation loss: 2.042237545053164

Epoch: 5| Step: 1
Training loss: 2.5906238555908203
Validation loss: 2.04712767402331

Epoch: 5| Step: 2
Training loss: 2.5161006450653076
Validation loss: 2.045657823483149

Epoch: 5| Step: 3
Training loss: 1.9010547399520874
Validation loss: 2.0590411027272544

Epoch: 5| Step: 4
Training loss: 1.1626627445220947
Validation loss: 2.050307979186376

Epoch: 5| Step: 5
Training loss: 1.7630336284637451
Validation loss: 2.0482606440782547

Epoch: 5| Step: 6
Training loss: 1.8167909383773804
Validation loss: 2.039887989560763

Epoch: 5| Step: 7
Training loss: 1.9660743474960327
Validation loss: 2.048600281278292

Epoch: 5| Step: 8
Training loss: 2.038754940032959
Validation loss: 2.0549449225266776

Epoch: 5| Step: 9
Training loss: 2.883457899093628
Validation loss: 2.068954144914945

Epoch: 5| Step: 10
Training loss: 1.9854309558868408
Validation loss: 2.0750289211670556

Epoch: 5| Step: 11
Training loss: 3.3200430870056152
Validation loss: 2.0721204727888107

Epoch: 10| Step: 0
Training loss: 1.7136188745498657
Validation loss: 2.0711697240670524

Epoch: 5| Step: 1
Training loss: 2.0706233978271484
Validation loss: 2.069441725810369

Epoch: 5| Step: 2
Training loss: 2.359734058380127
Validation loss: 2.082526216904322

Epoch: 5| Step: 3
Training loss: 2.1079444885253906
Validation loss: 2.0762785325447717

Epoch: 5| Step: 4
Training loss: 1.3860528469085693
Validation loss: 2.0624562799930573

Epoch: 5| Step: 5
Training loss: 2.08244252204895
Validation loss: 2.0786516815423965

Epoch: 5| Step: 6
Training loss: 1.6279780864715576
Validation loss: 2.073597108324369

Epoch: 5| Step: 7
Training loss: 2.1815528869628906
Validation loss: 2.06511959930261

Epoch: 5| Step: 8
Training loss: 2.110081195831299
Validation loss: 2.0621339877446494

Epoch: 5| Step: 9
Training loss: 2.5283782482147217
Validation loss: 2.04262275993824

Epoch: 5| Step: 10
Training loss: 2.174572706222534
Validation loss: 2.0562928915023804

Epoch: 5| Step: 11
Training loss: 3.1063425540924072
Validation loss: 2.03906387090683

Epoch: 11| Step: 0
Training loss: 1.8874889612197876
Validation loss: 2.034324124455452

Epoch: 5| Step: 1
Training loss: 1.7759950160980225
Validation loss: 2.0212983787059784

Epoch: 5| Step: 2
Training loss: 2.104210138320923
Validation loss: 2.0314937233924866

Epoch: 5| Step: 3
Training loss: 2.4797523021698
Validation loss: 2.00093183418115

Epoch: 5| Step: 4
Training loss: 1.647695779800415
Validation loss: 2.016194850206375

Epoch: 5| Step: 5
Training loss: 2.3033435344696045
Validation loss: 2.012049456437429

Epoch: 5| Step: 6
Training loss: 2.6095123291015625
Validation loss: 2.0072853664557138

Epoch: 5| Step: 7
Training loss: 2.1932060718536377
Validation loss: 2.0211148659388223

Epoch: 5| Step: 8
Training loss: 1.7626419067382812
Validation loss: 2.0274554044008255

Epoch: 5| Step: 9
Training loss: 1.8862844705581665
Validation loss: 2.037136216958364

Epoch: 5| Step: 10
Training loss: 2.0382814407348633
Validation loss: 2.0235472669204078

Epoch: 5| Step: 11
Training loss: 2.9528615474700928
Validation loss: 2.0238926162322364

Epoch: 12| Step: 0
Training loss: 2.0492007732391357
Validation loss: 2.0270266036192575

Epoch: 5| Step: 1
Training loss: 1.737409234046936
Validation loss: 2.0389966716368995

Epoch: 5| Step: 2
Training loss: 1.9383094310760498
Validation loss: 2.0196605722109475

Epoch: 5| Step: 3
Training loss: 2.1352972984313965
Validation loss: 2.026400407155355

Epoch: 5| Step: 4
Training loss: 2.186253786087036
Validation loss: 2.0360891819000244

Epoch: 5| Step: 5
Training loss: 2.2994027137756348
Validation loss: 2.023053154349327

Epoch: 5| Step: 6
Training loss: 2.5043022632598877
Validation loss: 2.0167216757933297

Epoch: 5| Step: 7
Training loss: 1.9388351440429688
Validation loss: 2.0183980216582618

Epoch: 5| Step: 8
Training loss: 1.782867431640625
Validation loss: 2.01487202445666

Epoch: 5| Step: 9
Training loss: 2.06071400642395
Validation loss: 2.012936736146609

Epoch: 5| Step: 10
Training loss: 2.3965063095092773
Validation loss: 2.007105832298597

Epoch: 5| Step: 11
Training loss: 1.6290785074234009
Validation loss: 2.0181420544783273

Epoch: 13| Step: 0
Training loss: 1.8399156332015991
Validation loss: 2.022419954339663

Epoch: 5| Step: 1
Training loss: 2.467367172241211
Validation loss: 2.020906448364258

Epoch: 5| Step: 2
Training loss: 2.2638814449310303
Validation loss: 2.0166761676470437

Epoch: 5| Step: 3
Training loss: 1.8259397745132446
Validation loss: 2.0055103302001953

Epoch: 5| Step: 4
Training loss: 2.014796018600464
Validation loss: 2.012242446343104

Epoch: 5| Step: 5
Training loss: 1.5484403371810913
Validation loss: 2.003427892923355

Epoch: 5| Step: 6
Training loss: 2.1459217071533203
Validation loss: 2.029709205031395

Epoch: 5| Step: 7
Training loss: 1.8721504211425781
Validation loss: 2.0100346356630325

Epoch: 5| Step: 8
Training loss: 1.9792976379394531
Validation loss: 2.0163720349470773

Epoch: 5| Step: 9
Training loss: 2.493931293487549
Validation loss: 2.004783953229586

Epoch: 5| Step: 10
Training loss: 1.8622146844863892
Validation loss: 2.018480122089386

Epoch: 5| Step: 11
Training loss: 2.9692306518554688
Validation loss: 2.007520084579786

Epoch: 14| Step: 0
Training loss: 2.241727590560913
Validation loss: 2.017724717656771

Epoch: 5| Step: 1
Training loss: 1.9787728786468506
Validation loss: 2.0124124536911645

Epoch: 5| Step: 2
Training loss: 2.0900893211364746
Validation loss: 2.0172533889611564

Epoch: 5| Step: 3
Training loss: 1.846339464187622
Validation loss: 2.014129360516866

Epoch: 5| Step: 4
Training loss: 2.0558199882507324
Validation loss: 2.021078333258629

Epoch: 5| Step: 5
Training loss: 1.9273898601531982
Validation loss: 2.0255254209041595

Epoch: 5| Step: 6
Training loss: 1.5742785930633545
Validation loss: 2.024659981330236

Epoch: 5| Step: 7
Training loss: 2.356184482574463
Validation loss: 2.0269366800785065

Epoch: 5| Step: 8
Training loss: 2.361468553543091
Validation loss: 2.025100529193878

Epoch: 5| Step: 9
Training loss: 2.0624756813049316
Validation loss: 2.031872863570849

Epoch: 5| Step: 10
Training loss: 1.9745107889175415
Validation loss: 2.0216503540674844

Epoch: 5| Step: 11
Training loss: 2.327254056930542
Validation loss: 2.0300728181997933

Epoch: 15| Step: 0
Training loss: 1.889603614807129
Validation loss: 2.0316393276055655

Epoch: 5| Step: 1
Training loss: 2.3467369079589844
Validation loss: 2.028684059778849

Epoch: 5| Step: 2
Training loss: 1.906502366065979
Validation loss: 2.006047308444977

Epoch: 5| Step: 3
Training loss: 1.834071397781372
Validation loss: 2.0129994501670203

Epoch: 5| Step: 4
Training loss: 1.5987663269042969
Validation loss: 2.0205831825733185

Epoch: 5| Step: 5
Training loss: 2.135507822036743
Validation loss: 2.013531302412351

Epoch: 5| Step: 6
Training loss: 2.693145513534546
Validation loss: 2.0171039750178656

Epoch: 5| Step: 7
Training loss: 2.712116241455078
Validation loss: 2.0043862064679465

Epoch: 5| Step: 8
Training loss: 2.2875447273254395
Validation loss: 2.0128208299477897

Epoch: 5| Step: 9
Training loss: 1.699777603149414
Validation loss: 2.006751522421837

Epoch: 5| Step: 10
Training loss: 1.3656575679779053
Validation loss: 2.009630858898163

Epoch: 5| Step: 11
Training loss: 1.839521884918213
Validation loss: 2.008171101411184

Epoch: 16| Step: 0
Training loss: 1.7801170349121094
Validation loss: 2.0090038577715554

Epoch: 5| Step: 1
Training loss: 2.34179949760437
Validation loss: 2.0124255319436393

Epoch: 5| Step: 2
Training loss: 1.8615955114364624
Validation loss: 2.012675310174624

Epoch: 5| Step: 3
Training loss: 1.6511294841766357
Validation loss: 2.014866049091021

Epoch: 5| Step: 4
Training loss: 1.775355339050293
Validation loss: 2.007585068543752

Epoch: 5| Step: 5
Training loss: 2.101242780685425
Validation loss: 2.033107504248619

Epoch: 5| Step: 6
Training loss: 1.6971909999847412
Validation loss: 2.0489057898521423

Epoch: 5| Step: 7
Training loss: 2.463932991027832
Validation loss: 2.061539833744367

Epoch: 5| Step: 8
Training loss: 2.6940150260925293
Validation loss: 2.065414398908615

Epoch: 5| Step: 9
Training loss: 1.3674598932266235
Validation loss: 2.0608984231948853

Epoch: 5| Step: 10
Training loss: 2.4657044410705566
Validation loss: 2.0683477222919464

Epoch: 5| Step: 11
Training loss: 3.1568970680236816
Validation loss: 2.0708052217960358

Epoch: 17| Step: 0
Training loss: 1.7582848072052002
Validation loss: 2.0598080654939017

Epoch: 5| Step: 1
Training loss: 1.9881172180175781
Validation loss: 2.0478918105363846

Epoch: 5| Step: 2
Training loss: 1.9845306873321533
Validation loss: 2.050795868039131

Epoch: 5| Step: 3
Training loss: 2.4339940547943115
Validation loss: 2.042651196320852

Epoch: 5| Step: 4
Training loss: 1.8259490728378296
Validation loss: 2.035254051287969

Epoch: 5| Step: 5
Training loss: 1.5890306234359741
Validation loss: 2.0206429809331894

Epoch: 5| Step: 6
Training loss: 2.3521275520324707
Validation loss: 2.0268903424342475

Epoch: 5| Step: 7
Training loss: 1.959359884262085
Validation loss: 2.042603721221288

Epoch: 5| Step: 8
Training loss: 2.0945394039154053
Validation loss: 2.0509585489829383

Epoch: 5| Step: 9
Training loss: 2.2858643531799316
Validation loss: 2.0309777359167733

Epoch: 5| Step: 10
Training loss: 1.960294485092163
Validation loss: 2.0232441425323486

Epoch: 5| Step: 11
Training loss: 1.9943472146987915
Validation loss: 2.0168547381957374

Epoch: 18| Step: 0
Training loss: 1.491666555404663
Validation loss: 2.0098345577716827

Epoch: 5| Step: 1
Training loss: 1.7979673147201538
Validation loss: 2.015630250175794

Epoch: 5| Step: 2
Training loss: 2.2417938709259033
Validation loss: 2.0168371250232062

Epoch: 5| Step: 3
Training loss: 2.1346395015716553
Validation loss: 2.0102108269929886

Epoch: 5| Step: 4
Training loss: 2.491176128387451
Validation loss: 2.0128163446982703

Epoch: 5| Step: 5
Training loss: 2.2865941524505615
Validation loss: 2.003864139318466

Epoch: 5| Step: 6
Training loss: 2.1245484352111816
Validation loss: 2.017674376567205

Epoch: 5| Step: 7
Training loss: 2.760153293609619
Validation loss: 2.0106270611286163

Epoch: 5| Step: 8
Training loss: 1.6670236587524414
Validation loss: 2.0130533625682197

Epoch: 5| Step: 9
Training loss: 1.5357019901275635
Validation loss: 2.007708956797918

Epoch: 5| Step: 10
Training loss: 1.9375375509262085
Validation loss: 2.011298105120659

Epoch: 5| Step: 11
Training loss: 0.9890289306640625
Validation loss: 2.0301349461078644

Epoch: 19| Step: 0
Training loss: 2.1078410148620605
Validation loss: 2.01505612830321

Epoch: 5| Step: 1
Training loss: 2.1183643341064453
Validation loss: 2.002379064758619

Epoch: 5| Step: 2
Training loss: 1.7988351583480835
Validation loss: 2.011615181962649

Epoch: 5| Step: 3
Training loss: 1.3373122215270996
Validation loss: 1.995094895362854

Epoch: 5| Step: 4
Training loss: 1.8962911367416382
Validation loss: 2.017476131518682

Epoch: 5| Step: 5
Training loss: 2.322758436203003
Validation loss: 2.0022723277409873

Epoch: 5| Step: 6
Training loss: 2.65861439704895
Validation loss: 2.0284395863612494

Epoch: 5| Step: 7
Training loss: 1.943092703819275
Validation loss: 2.013609195748965

Epoch: 5| Step: 8
Training loss: 2.0477614402770996
Validation loss: 2.015449305375417

Epoch: 5| Step: 9
Training loss: 2.427445650100708
Validation loss: 2.0170415540536246

Epoch: 5| Step: 10
Training loss: 1.6738370656967163
Validation loss: 2.0140192409356437

Epoch: 5| Step: 11
Training loss: 1.498358130455017
Validation loss: 2.0276983877023063

Epoch: 20| Step: 0
Training loss: 2.042560577392578
Validation loss: 2.040244276324908

Epoch: 5| Step: 1
Training loss: 1.8190343379974365
Validation loss: 2.015827084581057

Epoch: 5| Step: 2
Training loss: 1.6229076385498047
Validation loss: 2.021570617953936

Epoch: 5| Step: 3
Training loss: 2.4631423950195312
Validation loss: 2.006682629386584

Epoch: 5| Step: 4
Training loss: 1.8937934637069702
Validation loss: 2.0111554165681205

Epoch: 5| Step: 5
Training loss: 1.9923158884048462
Validation loss: 2.0090404649575553

Epoch: 5| Step: 6
Training loss: 2.3851282596588135
Validation loss: 2.016679957509041

Epoch: 5| Step: 7
Training loss: 1.7388875484466553
Validation loss: 2.0168024202187858

Epoch: 5| Step: 8
Training loss: 1.9646021127700806
Validation loss: 1.9897958437601726

Epoch: 5| Step: 9
Training loss: 2.154564619064331
Validation loss: 2.0026578654845557

Epoch: 5| Step: 10
Training loss: 2.2231264114379883
Validation loss: 2.0132580747207007

Epoch: 5| Step: 11
Training loss: 1.4372140169143677
Validation loss: 2.006052017211914

Epoch: 21| Step: 0
Training loss: 2.445493221282959
Validation loss: 2.0091084837913513

Epoch: 5| Step: 1
Training loss: 1.754591703414917
Validation loss: 2.0167744904756546

Epoch: 5| Step: 2
Training loss: 1.8915274143218994
Validation loss: 2.0533441404501596

Epoch: 5| Step: 3
Training loss: 2.178375720977783
Validation loss: 2.057496671875318

Epoch: 5| Step: 4
Training loss: 2.1341381072998047
Validation loss: 2.073072244723638

Epoch: 5| Step: 5
Training loss: 1.5217225551605225
Validation loss: 2.090873713294665

Epoch: 5| Step: 6
Training loss: 1.7299754619598389
Validation loss: 2.1015185912450156

Epoch: 5| Step: 7
Training loss: 2.074695110321045
Validation loss: 2.079183558622996

Epoch: 5| Step: 8
Training loss: 2.0758109092712402
Validation loss: 2.0798692852258682

Epoch: 5| Step: 9
Training loss: 2.6564056873321533
Validation loss: 2.084727550546328

Epoch: 5| Step: 10
Training loss: 1.9432357549667358
Validation loss: 2.077583094437917

Epoch: 5| Step: 11
Training loss: 1.0901386737823486
Validation loss: 2.0821422189474106

Epoch: 22| Step: 0
Training loss: 1.6444591283798218
Validation loss: 2.0445638547341027

Epoch: 5| Step: 1
Training loss: 1.9959640502929688
Validation loss: 2.0504871010780334

Epoch: 5| Step: 2
Training loss: 2.510080337524414
Validation loss: 2.0571786711613336

Epoch: 5| Step: 3
Training loss: 2.217029571533203
Validation loss: 2.0515225728352866

Epoch: 5| Step: 4
Training loss: 1.6099933385849
Validation loss: 2.0430019199848175

Epoch: 5| Step: 5
Training loss: 1.8286384344100952
Validation loss: 2.0449761946996055

Epoch: 5| Step: 6
Training loss: 2.200044631958008
Validation loss: 2.0481980592012405

Epoch: 5| Step: 7
Training loss: 1.6761481761932373
Validation loss: 2.020221173763275

Epoch: 5| Step: 8
Training loss: 2.326279401779175
Validation loss: 2.0332181801398597

Epoch: 5| Step: 9
Training loss: 2.1149113178253174
Validation loss: 2.0199211885531745

Epoch: 5| Step: 10
Training loss: 2.0332512855529785
Validation loss: 2.0152656634648642

Epoch: 5| Step: 11
Training loss: 1.1574369668960571
Validation loss: 2.0101410498221717

Epoch: 23| Step: 0
Training loss: 2.0665366649627686
Validation loss: 2.0162553638219833

Epoch: 5| Step: 1
Training loss: 2.243809938430786
Validation loss: 2.0085544834534326

Epoch: 5| Step: 2
Training loss: 1.5947482585906982
Validation loss: 2.0120768547058105

Epoch: 5| Step: 3
Training loss: 1.6599438190460205
Validation loss: 2.0218172619740167

Epoch: 5| Step: 4
Training loss: 2.5762321949005127
Validation loss: 2.0220979352792106

Epoch: 5| Step: 5
Training loss: 1.7376642227172852
Validation loss: 2.010513668258985

Epoch: 5| Step: 6
Training loss: 2.237090587615967
Validation loss: 2.0132658382256827

Epoch: 5| Step: 7
Training loss: 1.606895089149475
Validation loss: 2.029322107632955

Epoch: 5| Step: 8
Training loss: 1.6428909301757812
Validation loss: 2.0085254410902658

Epoch: 5| Step: 9
Training loss: 2.6487209796905518
Validation loss: 2.033467913667361

Epoch: 5| Step: 10
Training loss: 1.7054961919784546
Validation loss: 2.0215731660525003

Epoch: 5| Step: 11
Training loss: 3.2565152645111084
Validation loss: 2.0180858075618744

Epoch: 24| Step: 0
Training loss: 1.7928766012191772
Validation loss: 2.031963974237442

Epoch: 5| Step: 1
Training loss: 1.7266238927841187
Validation loss: 2.0423417339722314

Epoch: 5| Step: 2
Training loss: 2.1964571475982666
Validation loss: 2.055941566824913

Epoch: 5| Step: 3
Training loss: 1.5360291004180908
Validation loss: 2.0539422035217285

Epoch: 5| Step: 4
Training loss: 2.016261577606201
Validation loss: 2.056324909130732

Epoch: 5| Step: 5
Training loss: 2.1884078979492188
Validation loss: 2.089828828970591

Epoch: 5| Step: 6
Training loss: 1.877096176147461
Validation loss: 2.0768126845359802

Epoch: 5| Step: 7
Training loss: 2.1788289546966553
Validation loss: 2.0746761759122214

Epoch: 5| Step: 8
Training loss: 2.2184879779815674
Validation loss: 2.075969249010086

Epoch: 5| Step: 9
Training loss: 2.1182427406311035
Validation loss: 2.074997370441755

Epoch: 5| Step: 10
Training loss: 2.144453525543213
Validation loss: 2.061380371451378

Epoch: 5| Step: 11
Training loss: 2.1020727157592773
Validation loss: 2.0461945484081903

Epoch: 25| Step: 0
Training loss: 1.494868278503418
Validation loss: 2.0140767693519592

Epoch: 5| Step: 1
Training loss: 1.3768256902694702
Validation loss: 2.01758249104023

Epoch: 5| Step: 2
Training loss: 2.031006336212158
Validation loss: 2.000895862778028

Epoch: 5| Step: 3
Training loss: 2.0905020236968994
Validation loss: 1.9983969628810883

Epoch: 5| Step: 4
Training loss: 2.031374454498291
Validation loss: 1.9881512075662613

Epoch: 5| Step: 5
Training loss: 2.4290122985839844
Validation loss: 1.9957298586765926

Epoch: 5| Step: 6
Training loss: 1.6100318431854248
Validation loss: 1.993956744670868

Epoch: 5| Step: 7
Training loss: 2.0223023891448975
Validation loss: 1.994057799379031

Epoch: 5| Step: 8
Training loss: 2.299058675765991
Validation loss: 1.974885622660319

Epoch: 5| Step: 9
Training loss: 2.3037285804748535
Validation loss: 1.9898643493652344

Epoch: 5| Step: 10
Training loss: 2.375389575958252
Validation loss: 1.975574513276418

Epoch: 5| Step: 11
Training loss: 1.718670129776001
Validation loss: 1.9935702631870906

Epoch: 26| Step: 0
Training loss: 2.0485687255859375
Validation loss: 1.9953454385201137

Epoch: 5| Step: 1
Training loss: 2.342538833618164
Validation loss: 1.992006853222847

Epoch: 5| Step: 2
Training loss: 2.247286796569824
Validation loss: 1.990628033876419

Epoch: 5| Step: 3
Training loss: 2.47745943069458
Validation loss: 1.9836315264304478

Epoch: 5| Step: 4
Training loss: 1.81988525390625
Validation loss: 1.990490163366

Epoch: 5| Step: 5
Training loss: 2.3378286361694336
Validation loss: 1.9959155718485515

Epoch: 5| Step: 6
Training loss: 1.7148628234863281
Validation loss: 1.9893363515535991

Epoch: 5| Step: 7
Training loss: 1.7077856063842773
Validation loss: 1.982301150759061

Epoch: 5| Step: 8
Training loss: 1.8801467418670654
Validation loss: 1.9837156683206558

Epoch: 5| Step: 9
Training loss: 2.2278435230255127
Validation loss: 1.9926879107952118

Epoch: 5| Step: 10
Training loss: 1.3981964588165283
Validation loss: 1.9889754205942154

Epoch: 5| Step: 11
Training loss: 1.817434310913086
Validation loss: 1.9894429047902424

Epoch: 27| Step: 0
Training loss: 2.5415287017822266
Validation loss: 1.9968641499678295

Epoch: 5| Step: 1
Training loss: 1.5030620098114014
Validation loss: 1.9986637781063716

Epoch: 5| Step: 2
Training loss: 1.9770088195800781
Validation loss: 2.0143905580043793

Epoch: 5| Step: 3
Training loss: 1.8317196369171143
Validation loss: 2.0074085096518197

Epoch: 5| Step: 4
Training loss: 2.8490962982177734
Validation loss: 2.0255940556526184

Epoch: 5| Step: 5
Training loss: 1.70846688747406
Validation loss: 2.0187617391347885

Epoch: 5| Step: 6
Training loss: 2.201040029525757
Validation loss: 2.0134255439043045

Epoch: 5| Step: 7
Training loss: 2.030550718307495
Validation loss: 2.0298705101013184

Epoch: 5| Step: 8
Training loss: 1.554863452911377
Validation loss: 2.030143986145655

Epoch: 5| Step: 9
Training loss: 1.8760448694229126
Validation loss: 2.033678794900576

Epoch: 5| Step: 10
Training loss: 1.6312768459320068
Validation loss: 2.0499069740374884

Epoch: 5| Step: 11
Training loss: 2.053518772125244
Validation loss: 2.0459993282953897

Epoch: 28| Step: 0
Training loss: 2.004575252532959
Validation loss: 2.028930048147837

Epoch: 5| Step: 1
Training loss: 1.6783870458602905
Validation loss: 2.0292737782001495

Epoch: 5| Step: 2
Training loss: 3.0395729541778564
Validation loss: 2.027311990658442

Epoch: 5| Step: 3
Training loss: 1.5945861339569092
Validation loss: 2.0175744791825614

Epoch: 5| Step: 4
Training loss: 2.1131370067596436
Validation loss: 2.0320809880892434

Epoch: 5| Step: 5
Training loss: 1.94949471950531
Validation loss: 2.0114332983891168

Epoch: 5| Step: 6
Training loss: 2.0645229816436768
Validation loss: 2.0190390795469284

Epoch: 5| Step: 7
Training loss: 2.1485629081726074
Validation loss: 2.0005094607671103

Epoch: 5| Step: 8
Training loss: 1.6393754482269287
Validation loss: 1.9957828273375828

Epoch: 5| Step: 9
Training loss: 1.9084386825561523
Validation loss: 2.016561364134153

Epoch: 5| Step: 10
Training loss: 1.53878915309906
Validation loss: 2.0081831763188043

Epoch: 5| Step: 11
Training loss: 1.7835346460342407
Validation loss: 2.0009391059478125

Epoch: 29| Step: 0
Training loss: 2.103292942047119
Validation loss: 2.0127038111289344

Epoch: 5| Step: 1
Training loss: 2.326760768890381
Validation loss: 2.008072853088379

Epoch: 5| Step: 2
Training loss: 2.179469108581543
Validation loss: 2.0199585606654487

Epoch: 5| Step: 3
Training loss: 1.6497268676757812
Validation loss: 1.988899181286494

Epoch: 5| Step: 4
Training loss: 2.1707160472869873
Validation loss: 1.995683992902438

Epoch: 5| Step: 5
Training loss: 1.6062015295028687
Validation loss: 1.991103579600652

Epoch: 5| Step: 6
Training loss: 1.5500304698944092
Validation loss: 1.997265284260114

Epoch: 5| Step: 7
Training loss: 2.480198383331299
Validation loss: 2.008878375093142

Epoch: 5| Step: 8
Training loss: 1.9265201091766357
Validation loss: 2.0015074660380683

Epoch: 5| Step: 9
Training loss: 1.5933152437210083
Validation loss: 2.025118798017502

Epoch: 5| Step: 10
Training loss: 2.185324192047119
Validation loss: 2.0285426328579583

Epoch: 5| Step: 11
Training loss: 1.5805673599243164
Validation loss: 2.030353764692942

Epoch: 30| Step: 0
Training loss: 2.3437535762786865
Validation loss: 2.0427863796552024

Epoch: 5| Step: 1
Training loss: 2.0270402431488037
Validation loss: 2.0380780895551047

Epoch: 5| Step: 2
Training loss: 2.0065627098083496
Validation loss: 2.0531524618466697

Epoch: 5| Step: 3
Training loss: 1.3990004062652588
Validation loss: 2.0523282289505005

Epoch: 5| Step: 4
Training loss: 1.8597612380981445
Validation loss: 2.041001563270887

Epoch: 5| Step: 5
Training loss: 1.7866379022598267
Validation loss: 2.0645627826452255

Epoch: 5| Step: 6
Training loss: 2.3409764766693115
Validation loss: 2.047886868317922

Epoch: 5| Step: 7
Training loss: 1.6543601751327515
Validation loss: 2.0356736928224564

Epoch: 5| Step: 8
Training loss: 1.9965341091156006
Validation loss: 2.0240124811728797

Epoch: 5| Step: 9
Training loss: 2.4073240756988525
Validation loss: 2.0247236688931785

Epoch: 5| Step: 10
Training loss: 1.5715751647949219
Validation loss: 2.0063461561997733

Epoch: 5| Step: 11
Training loss: 2.789651393890381
Validation loss: 2.01253080368042

Epoch: 31| Step: 0
Training loss: 2.1282315254211426
Validation loss: 1.997197652856509

Epoch: 5| Step: 1
Training loss: 1.631951928138733
Validation loss: 1.998195841908455

Epoch: 5| Step: 2
Training loss: 1.953586220741272
Validation loss: 1.9921042621135712

Epoch: 5| Step: 3
Training loss: 2.1166176795959473
Validation loss: 1.9789742827415466

Epoch: 5| Step: 4
Training loss: 2.1787667274475098
Validation loss: 1.9754618853330612

Epoch: 5| Step: 5
Training loss: 2.0702602863311768
Validation loss: 1.9870434006055195

Epoch: 5| Step: 6
Training loss: 2.27034592628479
Validation loss: 1.9763550410668056

Epoch: 5| Step: 7
Training loss: 2.0756149291992188
Validation loss: 1.9716798464457195

Epoch: 5| Step: 8
Training loss: 1.8547286987304688
Validation loss: 1.9696793208519618

Epoch: 5| Step: 9
Training loss: 2.0244998931884766
Validation loss: 1.970330571134885

Epoch: 5| Step: 10
Training loss: 1.7025830745697021
Validation loss: 1.9701619495948155

Epoch: 5| Step: 11
Training loss: 1.0046963691711426
Validation loss: 1.9695145040750504

Epoch: 32| Step: 0
Training loss: 2.0542752742767334
Validation loss: 1.9823597818613052

Epoch: 5| Step: 1
Training loss: 1.786520004272461
Validation loss: 2.024316668510437

Epoch: 5| Step: 2
Training loss: 2.5915169715881348
Validation loss: 2.024529049793879

Epoch: 5| Step: 3
Training loss: 1.6837246417999268
Validation loss: 2.0470006863276162

Epoch: 5| Step: 4
Training loss: 1.823905348777771
Validation loss: 2.0684266686439514

Epoch: 5| Step: 5
Training loss: 2.3257946968078613
Validation loss: 2.0943961838881173

Epoch: 5| Step: 6
Training loss: 1.5939171314239502
Validation loss: 2.096586674451828

Epoch: 5| Step: 7
Training loss: 2.3524410724639893
Validation loss: 2.1229686588048935

Epoch: 5| Step: 8
Training loss: 1.943068265914917
Validation loss: 2.1210296054681144

Epoch: 5| Step: 9
Training loss: 1.828587293624878
Validation loss: 2.1174151450395584

Epoch: 5| Step: 10
Training loss: 1.969732642173767
Validation loss: 2.108885332942009

Epoch: 5| Step: 11
Training loss: 1.2302850484848022
Validation loss: 2.0942093332608542

Epoch: 33| Step: 0
Training loss: 1.57749342918396
Validation loss: 2.065458759665489

Epoch: 5| Step: 1
Training loss: 1.8739303350448608
Validation loss: 2.0375775347153344

Epoch: 5| Step: 2
Training loss: 2.117042064666748
Validation loss: 2.024793808658918

Epoch: 5| Step: 3
Training loss: 1.7900371551513672
Validation loss: 2.0025890519221625

Epoch: 5| Step: 4
Training loss: 1.9262077808380127
Validation loss: 1.9887216289838154

Epoch: 5| Step: 5
Training loss: 1.678800344467163
Validation loss: 1.9765401085217793

Epoch: 5| Step: 6
Training loss: 2.0595672130584717
Validation loss: 1.9739421059687932

Epoch: 5| Step: 7
Training loss: 2.0366177558898926
Validation loss: 1.974505936106046

Epoch: 5| Step: 8
Training loss: 1.5479190349578857
Validation loss: 1.9796043733755748

Epoch: 5| Step: 9
Training loss: 2.5951807498931885
Validation loss: 1.9725966453552246

Epoch: 5| Step: 10
Training loss: 2.1656875610351562
Validation loss: 1.9766685167948406

Epoch: 5| Step: 11
Training loss: 3.8765511512756348
Validation loss: 1.9744238009055455

Epoch: 34| Step: 0
Training loss: 2.037841558456421
Validation loss: 1.980036382873853

Epoch: 5| Step: 1
Training loss: 2.3181874752044678
Validation loss: 1.9713571816682816

Epoch: 5| Step: 2
Training loss: 2.4963467121124268
Validation loss: 1.9773057053486507

Epoch: 5| Step: 3
Training loss: 1.8235394954681396
Validation loss: 1.9809036900599797

Epoch: 5| Step: 4
Training loss: 1.9079879522323608
Validation loss: 1.9787233173847198

Epoch: 5| Step: 5
Training loss: 2.5853703022003174
Validation loss: 1.96840904156367

Epoch: 5| Step: 6
Training loss: 1.7846838235855103
Validation loss: 1.9812402973572414

Epoch: 5| Step: 7
Training loss: 2.0361642837524414
Validation loss: 1.9770183364550273

Epoch: 5| Step: 8
Training loss: 1.848732352256775
Validation loss: 1.9811360736687977

Epoch: 5| Step: 9
Training loss: 1.4375892877578735
Validation loss: 1.972631499171257

Epoch: 5| Step: 10
Training loss: 1.4564404487609863
Validation loss: 1.9696358144283295

Epoch: 5| Step: 11
Training loss: 2.469048023223877
Validation loss: 1.9814559916655223

Epoch: 35| Step: 0
Training loss: 2.123685359954834
Validation loss: 1.97672638297081

Epoch: 5| Step: 1
Training loss: 2.282259702682495
Validation loss: 1.9884633521238964

Epoch: 5| Step: 2
Training loss: 1.774634599685669
Validation loss: 1.9841806938250859

Epoch: 5| Step: 3
Training loss: 2.233513355255127
Validation loss: 1.9726184805234273

Epoch: 5| Step: 4
Training loss: 2.042677402496338
Validation loss: 1.9923349420229595

Epoch: 5| Step: 5
Training loss: 1.7792551517486572
Validation loss: 1.9846024910608928

Epoch: 5| Step: 6
Training loss: 1.9069068431854248
Validation loss: 2.004659056663513

Epoch: 5| Step: 7
Training loss: 1.564160943031311
Validation loss: 2.0101853956778846

Epoch: 5| Step: 8
Training loss: 2.285475015640259
Validation loss: 2.018820196390152

Epoch: 5| Step: 9
Training loss: 1.8511425256729126
Validation loss: 2.0334754486878714

Epoch: 5| Step: 10
Training loss: 1.642822265625
Validation loss: 2.0388073871533074

Epoch: 5| Step: 11
Training loss: 2.0890026092529297
Validation loss: 2.0402158349752426

Epoch: 36| Step: 0
Training loss: 1.9208866357803345
Validation loss: 2.0503960996866226

Epoch: 5| Step: 1
Training loss: 2.4715592861175537
Validation loss: 2.0557454029719033

Epoch: 5| Step: 2
Training loss: 1.3684619665145874
Validation loss: 2.0744599252939224

Epoch: 5| Step: 3
Training loss: 2.1414966583251953
Validation loss: 2.083190326889356

Epoch: 5| Step: 4
Training loss: 2.2518162727355957
Validation loss: 2.08816168208917

Epoch: 5| Step: 5
Training loss: 1.8106424808502197
Validation loss: 2.083289623260498

Epoch: 5| Step: 6
Training loss: 1.869462013244629
Validation loss: 2.0677167028188705

Epoch: 5| Step: 7
Training loss: 2.3022189140319824
Validation loss: 2.068721334139506

Epoch: 5| Step: 8
Training loss: 1.757480263710022
Validation loss: 2.0405391653378806

Epoch: 5| Step: 9
Training loss: 1.831801176071167
Validation loss: 2.014740745226542

Epoch: 5| Step: 10
Training loss: 1.9996376037597656
Validation loss: 2.018424461285273

Epoch: 5| Step: 11
Training loss: 1.16863214969635
Validation loss: 1.9883353759845097

Epoch: 37| Step: 0
Training loss: 2.2131686210632324
Validation loss: 1.9968525568644206

Epoch: 5| Step: 1
Training loss: 2.4250590801239014
Validation loss: 1.9798189103603363

Epoch: 5| Step: 2
Training loss: 2.102616548538208
Validation loss: 1.997166633605957

Epoch: 5| Step: 3
Training loss: 1.683614730834961
Validation loss: 1.97491288681825

Epoch: 5| Step: 4
Training loss: 2.075753688812256
Validation loss: 1.9562242676814396

Epoch: 5| Step: 5
Training loss: 1.3177680969238281
Validation loss: 1.9713647067546844

Epoch: 5| Step: 6
Training loss: 2.132667064666748
Validation loss: 1.9831309169530869

Epoch: 5| Step: 7
Training loss: 1.603283166885376
Validation loss: 1.9844151089588802

Epoch: 5| Step: 8
Training loss: 2.2557623386383057
Validation loss: 1.9991319676240284

Epoch: 5| Step: 9
Training loss: 1.9707143306732178
Validation loss: 1.9917562703291576

Epoch: 5| Step: 10
Training loss: 1.718613862991333
Validation loss: 1.9892175942659378

Epoch: 5| Step: 11
Training loss: 1.968311071395874
Validation loss: 1.9814682751893997

Epoch: 38| Step: 0
Training loss: 2.049943447113037
Validation loss: 1.9899295618136723

Epoch: 5| Step: 1
Training loss: 2.4540963172912598
Validation loss: 2.0056406557559967

Epoch: 5| Step: 2
Training loss: 2.0073115825653076
Validation loss: 1.989990120132764

Epoch: 5| Step: 3
Training loss: 1.9660460948944092
Validation loss: 1.9866861303647358

Epoch: 5| Step: 4
Training loss: 1.6384496688842773
Validation loss: 1.9922402600447338

Epoch: 5| Step: 5
Training loss: 2.1460602283477783
Validation loss: 2.0039249459902444

Epoch: 5| Step: 6
Training loss: 2.203613758087158
Validation loss: 2.007731467485428

Epoch: 5| Step: 7
Training loss: 2.0156161785125732
Validation loss: 2.0024704138437905

Epoch: 5| Step: 8
Training loss: 1.2299073934555054
Validation loss: 2.022988577683767

Epoch: 5| Step: 9
Training loss: 2.1100451946258545
Validation loss: 2.0271213551362357

Epoch: 5| Step: 10
Training loss: 1.4106184244155884
Validation loss: 2.0116816262404122

Epoch: 5| Step: 11
Training loss: 2.020974636077881
Validation loss: 1.99919988711675

Epoch: 39| Step: 0
Training loss: 1.3546208143234253
Validation loss: 2.020530720551809

Epoch: 5| Step: 1
Training loss: 1.9688438177108765
Validation loss: 2.0404871751864753

Epoch: 5| Step: 2
Training loss: 1.9930988550186157
Validation loss: 2.045748397707939

Epoch: 5| Step: 3
Training loss: 1.5871951580047607
Validation loss: 2.0826439609130225

Epoch: 5| Step: 4
Training loss: 2.0295116901397705
Validation loss: 2.0796876698732376

Epoch: 5| Step: 5
Training loss: 1.7354494333267212
Validation loss: 2.0856589674949646

Epoch: 5| Step: 6
Training loss: 1.8103344440460205
Validation loss: 2.0842879513899484

Epoch: 5| Step: 7
Training loss: 2.6964261531829834
Validation loss: 2.081351717313131

Epoch: 5| Step: 8
Training loss: 2.8319568634033203
Validation loss: 2.0901972403128943

Epoch: 5| Step: 9
Training loss: 1.731109380722046
Validation loss: 2.059010316928228

Epoch: 5| Step: 10
Training loss: 1.6837488412857056
Validation loss: 2.0561114301284156

Epoch: 5| Step: 11
Training loss: 2.1668267250061035
Validation loss: 2.027495870987574

Epoch: 40| Step: 0
Training loss: 1.7299350500106812
Validation loss: 2.0071133424838385

Epoch: 5| Step: 1
Training loss: 1.750215768814087
Validation loss: 1.9902490228414536

Epoch: 5| Step: 2
Training loss: 1.4033992290496826
Validation loss: 1.9879647890726726

Epoch: 5| Step: 3
Training loss: 2.132957935333252
Validation loss: 1.9773141294717789

Epoch: 5| Step: 4
Training loss: 1.864943504333496
Validation loss: 1.9629140347242355

Epoch: 5| Step: 5
Training loss: 2.213486433029175
Validation loss: 1.9644860376914342

Epoch: 5| Step: 6
Training loss: 2.320190191268921
Validation loss: 1.9764340966939926

Epoch: 5| Step: 7
Training loss: 2.1788296699523926
Validation loss: 1.980207199851672

Epoch: 5| Step: 8
Training loss: 1.9810909032821655
Validation loss: 1.9603228519360225

Epoch: 5| Step: 9
Training loss: 1.4619736671447754
Validation loss: 1.956928089261055

Epoch: 5| Step: 10
Training loss: 2.274423122406006
Validation loss: 1.9720935026804607

Epoch: 5| Step: 11
Training loss: 2.3143556118011475
Validation loss: 1.9636396219333012

Epoch: 41| Step: 0
Training loss: 1.5460054874420166
Validation loss: 1.9751431345939636

Epoch: 5| Step: 1
Training loss: 2.348477840423584
Validation loss: 1.9735010862350464

Epoch: 5| Step: 2
Training loss: 1.7944027185440063
Validation loss: 2.00577150285244

Epoch: 5| Step: 3
Training loss: 2.263676881790161
Validation loss: 2.0084974070390067

Epoch: 5| Step: 4
Training loss: 2.076160430908203
Validation loss: 2.0190776735544205

Epoch: 5| Step: 5
Training loss: 2.2117018699645996
Validation loss: 2.0424412190914154

Epoch: 5| Step: 6
Training loss: 1.8403728008270264
Validation loss: 2.052620232105255

Epoch: 5| Step: 7
Training loss: 1.0622209310531616
Validation loss: 2.0828561782836914

Epoch: 5| Step: 8
Training loss: 1.8002824783325195
Validation loss: 2.0800457199414573

Epoch: 5| Step: 9
Training loss: 1.940263032913208
Validation loss: 2.0990933726231256

Epoch: 5| Step: 10
Training loss: 2.693448305130005
Validation loss: 2.081366037329038

Epoch: 5| Step: 11
Training loss: 1.3534951210021973
Validation loss: 2.0895627637704215

Epoch: 42| Step: 0
Training loss: 1.9879649877548218
Validation loss: 2.0612101554870605

Epoch: 5| Step: 1
Training loss: 1.1775282621383667
Validation loss: 2.03451536099116

Epoch: 5| Step: 2
Training loss: 1.535945177078247
Validation loss: 2.0176684806744256

Epoch: 5| Step: 3
Training loss: 1.6394860744476318
Validation loss: 2.0084186842044196

Epoch: 5| Step: 4
Training loss: 1.9859485626220703
Validation loss: 1.9945067018270493

Epoch: 5| Step: 5
Training loss: 2.2064318656921387
Validation loss: 1.9969480335712433

Epoch: 5| Step: 6
Training loss: 1.784563660621643
Validation loss: 1.9779832462469737

Epoch: 5| Step: 7
Training loss: 2.5595898628234863
Validation loss: 1.9879633287588756

Epoch: 5| Step: 8
Training loss: 1.952389121055603
Validation loss: 1.992891366283099

Epoch: 5| Step: 9
Training loss: 2.116328001022339
Validation loss: 1.9770547449588776

Epoch: 5| Step: 10
Training loss: 1.8691800832748413
Validation loss: 1.9857679357131321

Epoch: 5| Step: 11
Training loss: 3.019804000854492
Validation loss: 1.9740971773862839

Epoch: 43| Step: 0
Training loss: 1.861421823501587
Validation loss: 1.9716696093479793

Epoch: 5| Step: 1
Training loss: 2.018766403198242
Validation loss: 1.978609785437584

Epoch: 5| Step: 2
Training loss: 2.182166576385498
Validation loss: 1.9717615395784378

Epoch: 5| Step: 3
Training loss: 2.0085597038269043
Validation loss: 1.980971485376358

Epoch: 5| Step: 4
Training loss: 1.66973876953125
Validation loss: 1.9844142943620682

Epoch: 5| Step: 5
Training loss: 2.314030408859253
Validation loss: 1.9699699034293492

Epoch: 5| Step: 6
Training loss: 1.1689808368682861
Validation loss: 1.9842232018709183

Epoch: 5| Step: 7
Training loss: 1.7057163715362549
Validation loss: 1.9732964138189952

Epoch: 5| Step: 8
Training loss: 2.4990551471710205
Validation loss: 1.9940729935963948

Epoch: 5| Step: 9
Training loss: 1.4481481313705444
Validation loss: 1.996594488620758

Epoch: 5| Step: 10
Training loss: 2.2823665142059326
Validation loss: 1.9942125876744587

Epoch: 5| Step: 11
Training loss: 1.545548439025879
Validation loss: 2.002095232407252

Epoch: 44| Step: 0
Training loss: 1.6006152629852295
Validation loss: 2.025883470972379

Epoch: 5| Step: 1
Training loss: 2.0356640815734863
Validation loss: 2.04197466870149

Epoch: 5| Step: 2
Training loss: 1.6701768636703491
Validation loss: 2.060284028450648

Epoch: 5| Step: 3
Training loss: 1.593360185623169
Validation loss: 2.058594877521197

Epoch: 5| Step: 4
Training loss: 1.897733449935913
Validation loss: 2.074075326323509

Epoch: 5| Step: 5
Training loss: 2.7530112266540527
Validation loss: 2.0568794111410775

Epoch: 5| Step: 6
Training loss: 2.0153582096099854
Validation loss: 2.069122905532519

Epoch: 5| Step: 7
Training loss: 1.4927669763565063
Validation loss: 2.073136736949285

Epoch: 5| Step: 8
Training loss: 1.7091219425201416
Validation loss: 2.0594109843174615

Epoch: 5| Step: 9
Training loss: 2.5935604572296143
Validation loss: 2.0398299346367517

Epoch: 5| Step: 10
Training loss: 1.844132423400879
Validation loss: 2.0391386250654855

Epoch: 5| Step: 11
Training loss: 1.9733203649520874
Validation loss: 2.015615756313006

Epoch: 45| Step: 0
Training loss: 1.6675262451171875
Validation loss: 2.022738665342331

Epoch: 5| Step: 1
Training loss: 2.5804319381713867
Validation loss: 1.9949129273494084

Epoch: 5| Step: 2
Training loss: 2.060102939605713
Validation loss: 1.9962608714898427

Epoch: 5| Step: 3
Training loss: 1.8493725061416626
Validation loss: 1.9686667571465175

Epoch: 5| Step: 4
Training loss: 2.441608190536499
Validation loss: 1.9652221103509266

Epoch: 5| Step: 5
Training loss: 1.662989616394043
Validation loss: 1.9754635592301686

Epoch: 5| Step: 6
Training loss: 1.9380470514297485
Validation loss: 1.9702996810277302

Epoch: 5| Step: 7
Training loss: 1.0763428211212158
Validation loss: 1.9615322599808376

Epoch: 5| Step: 8
Training loss: 2.2709879875183105
Validation loss: 1.9603020201126735

Epoch: 5| Step: 9
Training loss: 1.4825996160507202
Validation loss: 1.9714341660340626

Epoch: 5| Step: 10
Training loss: 1.8650691509246826
Validation loss: 1.9705108205477397

Epoch: 5| Step: 11
Training loss: 2.56154203414917
Validation loss: 1.965986390908559

Epoch: 46| Step: 0
Training loss: 2.0311203002929688
Validation loss: 1.9694525202115376

Epoch: 5| Step: 1
Training loss: 1.6370052099227905
Validation loss: 1.9720893055200577

Epoch: 5| Step: 2
Training loss: 2.024980306625366
Validation loss: 1.9703612824281056

Epoch: 5| Step: 3
Training loss: 2.0865046977996826
Validation loss: 1.983264371752739

Epoch: 5| Step: 4
Training loss: 1.953359603881836
Validation loss: 1.9856966882944107

Epoch: 5| Step: 5
Training loss: 1.5852246284484863
Validation loss: 1.9877620041370392

Epoch: 5| Step: 6
Training loss: 2.4346396923065186
Validation loss: 2.0254618922869363

Epoch: 5| Step: 7
Training loss: 1.9610376358032227
Validation loss: 2.0338338116804757

Epoch: 5| Step: 8
Training loss: 1.900888204574585
Validation loss: 2.0229679197072983

Epoch: 5| Step: 9
Training loss: 1.6705814599990845
Validation loss: 2.0139763752619424

Epoch: 5| Step: 10
Training loss: 1.661138892173767
Validation loss: 2.027151664098104

Epoch: 5| Step: 11
Training loss: 2.585057497024536
Validation loss: 2.0305124471584954

Epoch: 47| Step: 0
Training loss: 2.231067657470703
Validation loss: 2.0459383130073547

Epoch: 5| Step: 1
Training loss: 1.4524058103561401
Validation loss: 2.0512391179800034

Epoch: 5| Step: 2
Training loss: 2.404740810394287
Validation loss: 2.0616407146056495

Epoch: 5| Step: 3
Training loss: 2.311058759689331
Validation loss: 2.0621948490540185

Epoch: 5| Step: 4
Training loss: 1.4097926616668701
Validation loss: 2.052942474683126

Epoch: 5| Step: 5
Training loss: 2.26438570022583
Validation loss: 2.0675290872653327

Epoch: 5| Step: 6
Training loss: 2.07867169380188
Validation loss: 2.0433614999055862

Epoch: 5| Step: 7
Training loss: 1.3053919076919556
Validation loss: 2.0362859070301056

Epoch: 5| Step: 8
Training loss: 2.0491585731506348
Validation loss: 2.0246338794628778

Epoch: 5| Step: 9
Training loss: 1.6553863286972046
Validation loss: 2.01542521516482

Epoch: 5| Step: 10
Training loss: 1.6409215927124023
Validation loss: 1.9897426515817642

Epoch: 5| Step: 11
Training loss: 2.8959832191467285
Validation loss: 1.9874938676754634

Epoch: 48| Step: 0
Training loss: 1.51847243309021
Validation loss: 1.9707645724217098

Epoch: 5| Step: 1
Training loss: 1.8134186267852783
Validation loss: 1.965200240413348

Epoch: 5| Step: 2
Training loss: 1.8591045141220093
Validation loss: 1.9679053624471028

Epoch: 5| Step: 3
Training loss: 2.121399402618408
Validation loss: 1.964128812154134

Epoch: 5| Step: 4
Training loss: 1.8578065633773804
Validation loss: 1.9764894743760426

Epoch: 5| Step: 5
Training loss: 1.5668377876281738
Validation loss: 1.951934943596522

Epoch: 5| Step: 6
Training loss: 2.0846667289733887
Validation loss: 1.9597959915796916

Epoch: 5| Step: 7
Training loss: 2.533353805541992
Validation loss: 1.9641083578268688

Epoch: 5| Step: 8
Training loss: 2.1559338569641113
Validation loss: 1.9632495592037837

Epoch: 5| Step: 9
Training loss: 2.0592422485351562
Validation loss: 1.9753469129403431

Epoch: 5| Step: 10
Training loss: 1.660447120666504
Validation loss: 1.9702847997347515

Epoch: 5| Step: 11
Training loss: 1.3790901899337769
Validation loss: 1.9752937505642574

Epoch: 49| Step: 0
Training loss: 2.0721850395202637
Validation loss: 2.00182144343853

Epoch: 5| Step: 1
Training loss: 2.0011825561523438
Validation loss: 2.025675783554713

Epoch: 5| Step: 2
Training loss: 1.4239518642425537
Validation loss: 2.0171812921762466

Epoch: 5| Step: 3
Training loss: 1.857561707496643
Validation loss: 2.0552920202414193

Epoch: 5| Step: 4
Training loss: 1.147430419921875
Validation loss: 2.0751977811257043

Epoch: 5| Step: 5
Training loss: 2.5543551445007324
Validation loss: 2.1142558455467224

Epoch: 5| Step: 6
Training loss: 1.930612564086914
Validation loss: 2.1150763581196466

Epoch: 5| Step: 7
Training loss: 2.8439817428588867
Validation loss: 2.0985698898633323

Epoch: 5| Step: 8
Training loss: 1.613486886024475
Validation loss: 2.086403747399648

Epoch: 5| Step: 9
Training loss: 2.190258741378784
Validation loss: 2.0868677347898483

Epoch: 5| Step: 10
Training loss: 1.4428596496582031
Validation loss: 2.0673816402753196

Epoch: 5| Step: 11
Training loss: 1.9962306022644043
Validation loss: 2.037944103280703

Epoch: 50| Step: 0
Training loss: 1.8352434635162354
Validation loss: 2.0169563591480255

Epoch: 5| Step: 1
Training loss: 1.3690077066421509
Validation loss: 1.9821900576353073

Epoch: 5| Step: 2
Training loss: 1.8446924686431885
Validation loss: 1.9654606133699417

Epoch: 5| Step: 3
Training loss: 2.6051440238952637
Validation loss: 1.966767246524493

Epoch: 5| Step: 4
Training loss: 1.9927997589111328
Validation loss: 1.9719001551469166

Epoch: 5| Step: 5
Training loss: 1.939589500427246
Validation loss: 1.9507233798503876

Epoch: 5| Step: 6
Training loss: 2.0548384189605713
Validation loss: 1.963152105609576

Epoch: 5| Step: 7
Training loss: 1.8690402507781982
Validation loss: 1.9632176359494526

Epoch: 5| Step: 8
Training loss: 2.0509769916534424
Validation loss: 1.9561256915330887

Epoch: 5| Step: 9
Training loss: 1.6226171255111694
Validation loss: 1.9730481555064519

Epoch: 5| Step: 10
Training loss: 1.7502243518829346
Validation loss: 1.9718208461999893

Epoch: 5| Step: 11
Training loss: 3.2054104804992676
Validation loss: 1.9525728523731232

Epoch: 51| Step: 0
Training loss: 1.9750999212265015
Validation loss: 1.9623323877652485

Epoch: 5| Step: 1
Training loss: 1.7474521398544312
Validation loss: 1.971039667725563

Epoch: 5| Step: 2
Training loss: 2.2603542804718018
Validation loss: 1.9624394128719966

Epoch: 5| Step: 3
Training loss: 1.5866297483444214
Validation loss: 1.9806410570939381

Epoch: 5| Step: 4
Training loss: 1.9764025211334229
Validation loss: 1.9797934244076412

Epoch: 5| Step: 5
Training loss: 1.7605270147323608
Validation loss: 2.0076574434836707

Epoch: 5| Step: 6
Training loss: 1.8003432750701904
Validation loss: 2.006243204077085

Epoch: 5| Step: 7
Training loss: 2.0647709369659424
Validation loss: 2.007688785592715

Epoch: 5| Step: 8
Training loss: 1.7541297674179077
Validation loss: 2.027109523614248

Epoch: 5| Step: 9
Training loss: 1.8770116567611694
Validation loss: 2.035830174883207

Epoch: 5| Step: 10
Training loss: 2.005411386489868
Validation loss: 2.0540431340535483

Epoch: 5| Step: 11
Training loss: 2.1764321327209473
Validation loss: 2.070703705151876

Epoch: 52| Step: 0
Training loss: 1.7901670932769775
Validation loss: 2.055037493507067

Epoch: 5| Step: 1
Training loss: 1.954201102256775
Validation loss: 2.045102188984553

Epoch: 5| Step: 2
Training loss: 1.728093147277832
Validation loss: 2.042895327011744

Epoch: 5| Step: 3
Training loss: 2.698939561843872
Validation loss: 2.0321436474720636

Epoch: 5| Step: 4
Training loss: 1.6548011302947998
Validation loss: 2.0096657127141953

Epoch: 5| Step: 5
Training loss: 1.196349024772644
Validation loss: 1.9970630556344986

Epoch: 5| Step: 6
Training loss: 1.2890864610671997
Validation loss: 2.0082264145215354

Epoch: 5| Step: 7
Training loss: 2.5735695362091064
Validation loss: 1.9912479917208354

Epoch: 5| Step: 8
Training loss: 1.4663282632827759
Validation loss: 2.0060274799664817

Epoch: 5| Step: 9
Training loss: 1.9364665746688843
Validation loss: 2.0090399930874505

Epoch: 5| Step: 10
Training loss: 2.6519782543182373
Validation loss: 2.042252411444982

Epoch: 5| Step: 11
Training loss: 0.8006598949432373
Validation loss: 2.0349296679099402

Epoch: 53| Step: 0
Training loss: 2.7077651023864746
Validation loss: 2.0264270653327308

Epoch: 5| Step: 1
Training loss: 1.9767491817474365
Validation loss: 2.0189853558937707

Epoch: 5| Step: 2
Training loss: 1.1994088888168335
Validation loss: 2.045158331592878

Epoch: 5| Step: 3
Training loss: 1.3032137155532837
Validation loss: 2.050770436724027

Epoch: 5| Step: 4
Training loss: 1.419032335281372
Validation loss: 2.053568164507548

Epoch: 5| Step: 5
Training loss: 2.533021926879883
Validation loss: 2.0411856522162757

Epoch: 5| Step: 6
Training loss: 1.6256444454193115
Validation loss: 2.013464649518331

Epoch: 5| Step: 7
Training loss: 2.1751415729522705
Validation loss: 2.0336202681064606

Epoch: 5| Step: 8
Training loss: 2.032172679901123
Validation loss: 2.017546623945236

Epoch: 5| Step: 9
Training loss: 1.4045970439910889
Validation loss: 2.0310201942920685

Epoch: 5| Step: 10
Training loss: 2.162658214569092
Validation loss: 1.9939219603935878

Epoch: 5| Step: 11
Training loss: 2.5189199447631836
Validation loss: 1.9966524293025334

Epoch: 54| Step: 0
Training loss: 1.5847713947296143
Validation loss: 1.9964824865261714

Epoch: 5| Step: 1
Training loss: 1.4749466180801392
Validation loss: 2.008144343892733

Epoch: 5| Step: 2
Training loss: 1.7993618249893188
Validation loss: 2.016033172607422

Epoch: 5| Step: 3
Training loss: 2.520890712738037
Validation loss: 2.0032410820325217

Epoch: 5| Step: 4
Training loss: 2.148616313934326
Validation loss: 2.011288891235987

Epoch: 5| Step: 5
Training loss: 2.2639877796173096
Validation loss: 2.008123422662417

Epoch: 5| Step: 6
Training loss: 1.9232444763183594
Validation loss: 1.9986793100833893

Epoch: 5| Step: 7
Training loss: 2.103588819503784
Validation loss: 1.9964307447274525

Epoch: 5| Step: 8
Training loss: 1.4813064336776733
Validation loss: 1.9885037193695705

Epoch: 5| Step: 9
Training loss: 1.8111575841903687
Validation loss: 1.9950773268938065

Epoch: 5| Step: 10
Training loss: 1.6154266595840454
Validation loss: 2.005798747142156

Epoch: 5| Step: 11
Training loss: 1.0985187292099
Validation loss: 2.0075244506200156

Epoch: 55| Step: 0
Training loss: 1.9185152053833008
Validation loss: 2.010617181658745

Epoch: 5| Step: 1
Training loss: 1.5876737833023071
Validation loss: 2.0079659124215445

Epoch: 5| Step: 2
Training loss: 1.8898248672485352
Validation loss: 2.0144053349892297

Epoch: 5| Step: 3
Training loss: 1.3830976486206055
Validation loss: 2.0059255361557007

Epoch: 5| Step: 4
Training loss: 1.7210594415664673
Validation loss: 1.9986728429794312

Epoch: 5| Step: 5
Training loss: 2.1727235317230225
Validation loss: 2.00473224123319

Epoch: 5| Step: 6
Training loss: 2.033172130584717
Validation loss: 2.0049697756767273

Epoch: 5| Step: 7
Training loss: 1.568718671798706
Validation loss: 1.999607801437378

Epoch: 5| Step: 8
Training loss: 2.2551052570343018
Validation loss: 2.011404365301132

Epoch: 5| Step: 9
Training loss: 2.304654836654663
Validation loss: 2.017584095398585

Epoch: 5| Step: 10
Training loss: 1.6498897075653076
Validation loss: 1.9969332416852315

Epoch: 5| Step: 11
Training loss: 2.0234575271606445
Validation loss: 2.0024386992057166

Epoch: 56| Step: 0
Training loss: 2.033151626586914
Validation loss: 2.0138814200957618

Epoch: 5| Step: 1
Training loss: 1.9674774408340454
Validation loss: 2.008344675103823

Epoch: 5| Step: 2
Training loss: 1.9752161502838135
Validation loss: 2.023045818010966

Epoch: 5| Step: 3
Training loss: 1.6142752170562744
Validation loss: 2.0330304354429245

Epoch: 5| Step: 4
Training loss: 1.9033362865447998
Validation loss: 2.0292619367440543

Epoch: 5| Step: 5
Training loss: 1.4644219875335693
Validation loss: 2.0205786377191544

Epoch: 5| Step: 6
Training loss: 2.217075824737549
Validation loss: 2.0097191830476127

Epoch: 5| Step: 7
Training loss: 1.648415207862854
Validation loss: 2.0146032174428306

Epoch: 5| Step: 8
Training loss: 1.4698587656021118
Validation loss: 2.0128940294186273

Epoch: 5| Step: 9
Training loss: 1.5350885391235352
Validation loss: 1.9986080626646678

Epoch: 5| Step: 10
Training loss: 2.598815679550171
Validation loss: 1.9983002493778865

Epoch: 5| Step: 11
Training loss: 1.662555456161499
Validation loss: 1.9962785641352336

Epoch: 57| Step: 0
Training loss: 1.890271544456482
Validation loss: 1.984927197297414

Epoch: 5| Step: 1
Training loss: 1.6359367370605469
Validation loss: 2.0111959328254065

Epoch: 5| Step: 2
Training loss: 1.403308629989624
Validation loss: 1.998071312904358

Epoch: 5| Step: 3
Training loss: 2.1441333293914795
Validation loss: 2.0306129157543182

Epoch: 5| Step: 4
Training loss: 1.7937853336334229
Validation loss: 2.0069554895162582

Epoch: 5| Step: 5
Training loss: 2.566188335418701
Validation loss: 2.0140704661607742

Epoch: 5| Step: 6
Training loss: 1.686286211013794
Validation loss: 2.0370526909828186

Epoch: 5| Step: 7
Training loss: 1.4355862140655518
Validation loss: 2.014388476808866

Epoch: 5| Step: 8
Training loss: 2.3709089756011963
Validation loss: 1.9940966566403706

Epoch: 5| Step: 9
Training loss: 2.1030490398406982
Validation loss: 1.9822355806827545

Epoch: 5| Step: 10
Training loss: 1.6987556219100952
Validation loss: 1.9937654982010524

Epoch: 5| Step: 11
Training loss: 0.42139923572540283
Validation loss: 1.9620746970176697

Epoch: 58| Step: 0
Training loss: 1.9529539346694946
Validation loss: 1.9549663662910461

Epoch: 5| Step: 1
Training loss: 2.608614206314087
Validation loss: 1.9663515289624531

Epoch: 5| Step: 2
Training loss: 1.1050407886505127
Validation loss: 1.9669403086105983

Epoch: 5| Step: 3
Training loss: 2.232173442840576
Validation loss: 1.973480482896169

Epoch: 5| Step: 4
Training loss: 1.8134371042251587
Validation loss: 1.977617621421814

Epoch: 5| Step: 5
Training loss: 1.2460682392120361
Validation loss: 1.9869481126467388

Epoch: 5| Step: 6
Training loss: 1.4902002811431885
Validation loss: 2.008896768093109

Epoch: 5| Step: 7
Training loss: 1.6191399097442627
Validation loss: 1.9904612253109615

Epoch: 5| Step: 8
Training loss: 1.7472972869873047
Validation loss: 2.0143531610568366

Epoch: 5| Step: 9
Training loss: 2.094435453414917
Validation loss: 2.0208131670951843

Epoch: 5| Step: 10
Training loss: 2.473461866378784
Validation loss: 2.0322585503260293

Epoch: 5| Step: 11
Training loss: 2.096142292022705
Validation loss: 2.0287480652332306

Epoch: 59| Step: 0
Training loss: 1.6613165140151978
Validation loss: 2.037274186809858

Epoch: 5| Step: 1
Training loss: 2.3321163654327393
Validation loss: 2.0478777835766473

Epoch: 5| Step: 2
Training loss: 1.9269063472747803
Validation loss: 2.0410134295622506

Epoch: 5| Step: 3
Training loss: 1.4042350053787231
Validation loss: 2.0336021880308786

Epoch: 5| Step: 4
Training loss: 1.6801025867462158
Validation loss: 2.0569104750951133

Epoch: 5| Step: 5
Training loss: 1.8847181797027588
Validation loss: 2.0243581583102546

Epoch: 5| Step: 6
Training loss: 2.6329798698425293
Validation loss: 2.0507517705361047

Epoch: 5| Step: 7
Training loss: 1.4415010213851929
Validation loss: 2.025211989879608

Epoch: 5| Step: 8
Training loss: 1.5285637378692627
Validation loss: 1.9995511422554653

Epoch: 5| Step: 9
Training loss: 1.5700926780700684
Validation loss: 1.9999303271373112

Epoch: 5| Step: 10
Training loss: 2.170689821243286
Validation loss: 1.9796971728404362

Epoch: 5| Step: 11
Training loss: 1.6710011959075928
Validation loss: 1.9828320890665054

Epoch: 60| Step: 0
Training loss: 1.8355801105499268
Validation loss: 1.9702748854955037

Epoch: 5| Step: 1
Training loss: 1.7990270853042603
Validation loss: 1.9841709633668263

Epoch: 5| Step: 2
Training loss: 1.2588167190551758
Validation loss: 2.004241317510605

Epoch: 5| Step: 3
Training loss: 2.0023388862609863
Validation loss: 2.0022509644428887

Epoch: 5| Step: 4
Training loss: 2.5122745037078857
Validation loss: 2.0405337661504745

Epoch: 5| Step: 5
Training loss: 1.4529814720153809
Validation loss: 2.0377084811528525

Epoch: 5| Step: 6
Training loss: 2.340855121612549
Validation loss: 2.0423499594132104

Epoch: 5| Step: 7
Training loss: 2.1098532676696777
Validation loss: 2.02884833017985

Epoch: 5| Step: 8
Training loss: 2.232856273651123
Validation loss: 2.0282987157503762

Epoch: 5| Step: 9
Training loss: 1.6010525226593018
Validation loss: 2.041041577855746

Epoch: 5| Step: 10
Training loss: 1.6239769458770752
Validation loss: 2.024992217620214

Epoch: 5| Step: 11
Training loss: 0.5143191814422607
Validation loss: 2.001307720939318

Epoch: 61| Step: 0
Training loss: 1.5454975366592407
Validation loss: 1.984408050775528

Epoch: 5| Step: 1
Training loss: 2.3837602138519287
Validation loss: 1.99242302775383

Epoch: 5| Step: 2
Training loss: 1.9273121356964111
Validation loss: 1.9746056298414867

Epoch: 5| Step: 3
Training loss: 2.0253825187683105
Validation loss: 1.9895516733328502

Epoch: 5| Step: 4
Training loss: 1.8241932392120361
Validation loss: 1.9875883956750233

Epoch: 5| Step: 5
Training loss: 1.3869737386703491
Validation loss: 1.9687806417544682

Epoch: 5| Step: 6
Training loss: 2.138312578201294
Validation loss: 1.9744351108868916

Epoch: 5| Step: 7
Training loss: 1.5699961185455322
Validation loss: 1.98332546154658

Epoch: 5| Step: 8
Training loss: 1.4766958951950073
Validation loss: 1.993729904294014

Epoch: 5| Step: 9
Training loss: 2.218296527862549
Validation loss: 1.9893660644690196

Epoch: 5| Step: 10
Training loss: 1.423433542251587
Validation loss: 1.9996688216924667

Epoch: 5| Step: 11
Training loss: 2.556452751159668
Validation loss: 2.012153888742129

Epoch: 62| Step: 0
Training loss: 1.5183398723602295
Validation loss: 1.9978082577387493

Epoch: 5| Step: 1
Training loss: 1.5516822338104248
Validation loss: 2.0002550333738327

Epoch: 5| Step: 2
Training loss: 1.7949965000152588
Validation loss: 2.0255048672358194

Epoch: 5| Step: 3
Training loss: 1.7943756580352783
Validation loss: 2.038835813601812

Epoch: 5| Step: 4
Training loss: 2.0503616333007812
Validation loss: 2.024406537413597

Epoch: 5| Step: 5
Training loss: 2.2275004386901855
Validation loss: 2.0143876721461615

Epoch: 5| Step: 6
Training loss: 2.37607479095459
Validation loss: 2.0137003461519876

Epoch: 5| Step: 7
Training loss: 1.8050267696380615
Validation loss: 2.0186676681041718

Epoch: 5| Step: 8
Training loss: 1.5901238918304443
Validation loss: 1.9932811111211777

Epoch: 5| Step: 9
Training loss: 1.8415277004241943
Validation loss: 2.005327492952347

Epoch: 5| Step: 10
Training loss: 1.7282346487045288
Validation loss: 1.9877531627813976

Epoch: 5| Step: 11
Training loss: 1.381951093673706
Validation loss: 1.9861922065416973

Epoch: 63| Step: 0
Training loss: 1.9867807626724243
Validation loss: 2.0205428898334503

Epoch: 5| Step: 1
Training loss: 1.8252859115600586
Validation loss: 2.0320239812135696

Epoch: 5| Step: 2
Training loss: 2.48004412651062
Validation loss: 2.026153321067492

Epoch: 5| Step: 3
Training loss: 2.122682809829712
Validation loss: 2.0298305402199426

Epoch: 5| Step: 4
Training loss: 1.6193134784698486
Validation loss: 2.043073500196139

Epoch: 5| Step: 5
Training loss: 1.4490934610366821
Validation loss: 2.045940319697062

Epoch: 5| Step: 6
Training loss: 1.898643136024475
Validation loss: 2.017388274272283

Epoch: 5| Step: 7
Training loss: 1.7919960021972656
Validation loss: 2.0150717347860336

Epoch: 5| Step: 8
Training loss: 1.6388165950775146
Validation loss: 2.0087721943855286

Epoch: 5| Step: 9
Training loss: 1.7865650653839111
Validation loss: 1.999771426121394

Epoch: 5| Step: 10
Training loss: 1.5088856220245361
Validation loss: 1.9760093440612156

Epoch: 5| Step: 11
Training loss: 1.1692979335784912
Validation loss: 1.9859316448370616

Epoch: 64| Step: 0
Training loss: 2.0752182006835938
Validation loss: 1.9918990482886632

Epoch: 5| Step: 1
Training loss: 1.963280439376831
Validation loss: 1.9625798910856247

Epoch: 5| Step: 2
Training loss: 1.8641990423202515
Validation loss: 1.9629128575325012

Epoch: 5| Step: 3
Training loss: 1.5295153856277466
Validation loss: 1.970416098833084

Epoch: 5| Step: 4
Training loss: 1.8223559856414795
Validation loss: 1.9666850219170253

Epoch: 5| Step: 5
Training loss: 2.2248096466064453
Validation loss: 1.9764829178651173

Epoch: 5| Step: 6
Training loss: 1.7389419078826904
Validation loss: 1.97583702703317

Epoch: 5| Step: 7
Training loss: 1.779290795326233
Validation loss: 1.988517165184021

Epoch: 5| Step: 8
Training loss: 2.03928279876709
Validation loss: 1.9786930282910664

Epoch: 5| Step: 9
Training loss: 1.6736280918121338
Validation loss: 1.9856580942869186

Epoch: 5| Step: 10
Training loss: 1.4607938528060913
Validation loss: 1.9985728859901428

Epoch: 5| Step: 11
Training loss: 1.9089528322219849
Validation loss: 2.009405568242073

Epoch: 65| Step: 0
Training loss: 1.790117621421814
Validation loss: 2.0184086114168167

Epoch: 5| Step: 1
Training loss: 2.255042552947998
Validation loss: 2.0192945301532745

Epoch: 5| Step: 2
Training loss: 2.0273962020874023
Validation loss: 2.0003330409526825

Epoch: 5| Step: 3
Training loss: 1.2863283157348633
Validation loss: 2.0146832267443338

Epoch: 5| Step: 4
Training loss: 1.1754674911499023
Validation loss: 2.0035762836535773

Epoch: 5| Step: 5
Training loss: 1.8932619094848633
Validation loss: 1.9928254783153534

Epoch: 5| Step: 6
Training loss: 2.47070050239563
Validation loss: 2.001503532131513

Epoch: 5| Step: 7
Training loss: 1.8299421072006226
Validation loss: 2.0003424237171807

Epoch: 5| Step: 8
Training loss: 1.8074748516082764
Validation loss: 2.0094098647435508

Epoch: 5| Step: 9
Training loss: 1.3145158290863037
Validation loss: 2.003881588578224

Epoch: 5| Step: 10
Training loss: 2.073850631713867
Validation loss: 2.028592507044474

Epoch: 5| Step: 11
Training loss: 1.2050036191940308
Validation loss: 2.0227999488512673

Epoch: 66| Step: 0
Training loss: 1.255460500717163
Validation loss: 2.004756728808085

Epoch: 5| Step: 1
Training loss: 2.168752431869507
Validation loss: 1.997391362984975

Epoch: 5| Step: 2
Training loss: 1.6676563024520874
Validation loss: 1.9901173412799835

Epoch: 5| Step: 3
Training loss: 1.5265452861785889
Validation loss: 1.9731915642817814

Epoch: 5| Step: 4
Training loss: 1.8693625926971436
Validation loss: 1.9773330241441727

Epoch: 5| Step: 5
Training loss: 2.027308940887451
Validation loss: 1.989966630935669

Epoch: 5| Step: 6
Training loss: 1.9600296020507812
Validation loss: 1.9768701146046321

Epoch: 5| Step: 7
Training loss: 1.6232776641845703
Validation loss: 1.9585262934366863

Epoch: 5| Step: 8
Training loss: 2.39526104927063
Validation loss: 1.9859291116396587

Epoch: 5| Step: 9
Training loss: 1.9463586807250977
Validation loss: 1.9648752113183339

Epoch: 5| Step: 10
Training loss: 1.6038405895233154
Validation loss: 1.9794121732314427

Epoch: 5| Step: 11
Training loss: 1.4132096767425537
Validation loss: 1.9895681589841843

Epoch: 67| Step: 0
Training loss: 2.0494885444641113
Validation loss: 2.0072344491879144

Epoch: 5| Step: 1
Training loss: 2.239948272705078
Validation loss: 2.0206346909205117

Epoch: 5| Step: 2
Training loss: 1.413589358329773
Validation loss: 2.024230182170868

Epoch: 5| Step: 3
Training loss: 1.9052162170410156
Validation loss: 2.038348083694776

Epoch: 5| Step: 4
Training loss: 2.118704319000244
Validation loss: 2.0386013984680176

Epoch: 5| Step: 5
Training loss: 1.8906034231185913
Validation loss: 2.056997055808703

Epoch: 5| Step: 6
Training loss: 1.4178072214126587
Validation loss: 2.0360100269317627

Epoch: 5| Step: 7
Training loss: 2.0138163566589355
Validation loss: 2.0530092219511666

Epoch: 5| Step: 8
Training loss: 1.7674214839935303
Validation loss: 2.048118735353152

Epoch: 5| Step: 9
Training loss: 1.3682910203933716
Validation loss: 2.0125426799058914

Epoch: 5| Step: 10
Training loss: 1.8518364429473877
Validation loss: 1.9909784197807312

Epoch: 5| Step: 11
Training loss: 1.1143109798431396
Validation loss: 1.986103117465973

Epoch: 68| Step: 0
Training loss: 2.461812973022461
Validation loss: 1.9937146057685216

Epoch: 5| Step: 1
Training loss: 1.580604910850525
Validation loss: 1.9939852704604466

Epoch: 5| Step: 2
Training loss: 1.7221218347549438
Validation loss: 2.0122003257274628

Epoch: 5| Step: 3
Training loss: 1.1693109273910522
Validation loss: 1.991559813419978

Epoch: 5| Step: 4
Training loss: 1.7544348239898682
Validation loss: 2.0012125819921494

Epoch: 5| Step: 5
Training loss: 1.621530532836914
Validation loss: 2.0042470743258796

Epoch: 5| Step: 6
Training loss: 1.7877171039581299
Validation loss: 2.0122777273257575

Epoch: 5| Step: 7
Training loss: 2.0100436210632324
Validation loss: 2.021540731191635

Epoch: 5| Step: 8
Training loss: 1.97345769405365
Validation loss: 1.996506229043007

Epoch: 5| Step: 9
Training loss: 1.7230472564697266
Validation loss: 2.0405965546766915

Epoch: 5| Step: 10
Training loss: 2.101958990097046
Validation loss: 2.0190166433652244

Epoch: 5| Step: 11
Training loss: 0.7045798897743225
Validation loss: 2.0091232111056647

Epoch: 69| Step: 0
Training loss: 1.5018784999847412
Validation loss: 2.012790804107984

Epoch: 5| Step: 1
Training loss: 1.3120167255401611
Validation loss: 2.015645533800125

Epoch: 5| Step: 2
Training loss: 1.7461459636688232
Validation loss: 2.0106414755185447

Epoch: 5| Step: 3
Training loss: 1.8815536499023438
Validation loss: 2.0268179227908454

Epoch: 5| Step: 4
Training loss: 2.19502592086792
Validation loss: 2.0284591068824134

Epoch: 5| Step: 5
Training loss: 1.2791757583618164
Validation loss: 2.020886624852816

Epoch: 5| Step: 6
Training loss: 2.188044548034668
Validation loss: 2.0254891216754913

Epoch: 5| Step: 7
Training loss: 1.8166530132293701
Validation loss: 2.015472690264384

Epoch: 5| Step: 8
Training loss: 1.4129257202148438
Validation loss: 1.999463548262914

Epoch: 5| Step: 9
Training loss: 1.8049848079681396
Validation loss: 1.9970586001873016

Epoch: 5| Step: 10
Training loss: 2.166996717453003
Validation loss: 1.9960994670788448

Epoch: 5| Step: 11
Training loss: 3.63989520072937
Validation loss: 1.9620427936315536

Epoch: 70| Step: 0
Training loss: 2.5247631072998047
Validation loss: 1.9608325312534969

Epoch: 5| Step: 1
Training loss: 1.4688187837600708
Validation loss: 1.9674269805351894

Epoch: 5| Step: 2
Training loss: 1.7580311298370361
Validation loss: 1.943093091249466

Epoch: 5| Step: 3
Training loss: 2.0479538440704346
Validation loss: 1.975693255662918

Epoch: 5| Step: 4
Training loss: 1.5846846103668213
Validation loss: 1.957924907406171

Epoch: 5| Step: 5
Training loss: 1.88864004611969
Validation loss: 1.9562645504872005

Epoch: 5| Step: 6
Training loss: 2.0850813388824463
Validation loss: 1.9498449911673863

Epoch: 5| Step: 7
Training loss: 1.612103819847107
Validation loss: 1.9749536861975987

Epoch: 5| Step: 8
Training loss: 1.6989288330078125
Validation loss: 1.977165977160136

Epoch: 5| Step: 9
Training loss: 1.7448089122772217
Validation loss: 1.9982267320156097

Epoch: 5| Step: 10
Training loss: 1.3692119121551514
Validation loss: 1.980565105875333

Epoch: 5| Step: 11
Training loss: 1.8768649101257324
Validation loss: 1.9984166423479717

Epoch: 71| Step: 0
Training loss: 1.7738215923309326
Validation loss: 2.0498133152723312

Epoch: 5| Step: 1
Training loss: 1.914832353591919
Validation loss: 2.074042389790217

Epoch: 5| Step: 2
Training loss: 1.1001231670379639
Validation loss: 2.08082577586174

Epoch: 5| Step: 3
Training loss: 1.632197618484497
Validation loss: 2.086318085590998

Epoch: 5| Step: 4
Training loss: 1.431084394454956
Validation loss: 2.102996771534284

Epoch: 5| Step: 5
Training loss: 2.349163055419922
Validation loss: 2.1078132738669715

Epoch: 5| Step: 6
Training loss: 2.5865585803985596
Validation loss: 2.092110350728035

Epoch: 5| Step: 7
Training loss: 1.804071068763733
Validation loss: 2.055922915538152

Epoch: 5| Step: 8
Training loss: 1.895803451538086
Validation loss: 2.026207149028778

Epoch: 5| Step: 9
Training loss: 1.7970691919326782
Validation loss: 2.0080734491348267

Epoch: 5| Step: 10
Training loss: 1.2879441976547241
Validation loss: 1.9654427965482075

Epoch: 5| Step: 11
Training loss: 4.020042896270752
Validation loss: 1.9541432509819667

Epoch: 72| Step: 0
Training loss: 1.5348029136657715
Validation loss: 1.9457825968662898

Epoch: 5| Step: 1
Training loss: 2.0726418495178223
Validation loss: 1.9548007001479466

Epoch: 5| Step: 2
Training loss: 1.9143816232681274
Validation loss: 1.965789591272672

Epoch: 5| Step: 3
Training loss: 1.789000153541565
Validation loss: 1.964716245730718

Epoch: 5| Step: 4
Training loss: 1.6330028772354126
Validation loss: 1.965281253059705

Epoch: 5| Step: 5
Training loss: 2.021824598312378
Validation loss: 1.9600223104159038

Epoch: 5| Step: 6
Training loss: 2.3675427436828613
Validation loss: 1.9599196414152782

Epoch: 5| Step: 7
Training loss: 1.5997227430343628
Validation loss: 1.9578885684410732

Epoch: 5| Step: 8
Training loss: 1.6017427444458008
Validation loss: 1.9821933507919312

Epoch: 5| Step: 9
Training loss: 1.3883864879608154
Validation loss: 1.9696640123923619

Epoch: 5| Step: 10
Training loss: 1.9480844736099243
Validation loss: 1.9681707123915355

Epoch: 5| Step: 11
Training loss: 1.2169535160064697
Validation loss: 2.004900798201561

Epoch: 73| Step: 0
Training loss: 1.6929404735565186
Validation loss: 2.002241402864456

Epoch: 5| Step: 1
Training loss: 2.3720831871032715
Validation loss: 1.9963636447985966

Epoch: 5| Step: 2
Training loss: 1.848730444908142
Validation loss: 1.9899357954661052

Epoch: 5| Step: 3
Training loss: 1.8060848712921143
Validation loss: 2.0025182316700616

Epoch: 5| Step: 4
Training loss: 2.0315754413604736
Validation loss: 2.0180180370807648

Epoch: 5| Step: 5
Training loss: 1.2742981910705566
Validation loss: 2.003657708565394

Epoch: 5| Step: 6
Training loss: 1.7694298028945923
Validation loss: 2.005719189842542

Epoch: 5| Step: 7
Training loss: 2.2517035007476807
Validation loss: 2.0018993616104126

Epoch: 5| Step: 8
Training loss: 1.2334799766540527
Validation loss: 1.9916681796312332

Epoch: 5| Step: 9
Training loss: 1.870884656906128
Validation loss: 2.0026071270306907

Epoch: 5| Step: 10
Training loss: 1.3013765811920166
Validation loss: 1.9996665914853413

Epoch: 5| Step: 11
Training loss: 1.9703288078308105
Validation loss: 2.007670352856318

Epoch: 74| Step: 0
Training loss: 2.6831469535827637
Validation loss: 2.012476031978925

Epoch: 5| Step: 1
Training loss: 1.7876031398773193
Validation loss: 2.01563789943854

Epoch: 5| Step: 2
Training loss: 1.8839905261993408
Validation loss: 2.02163436015447

Epoch: 5| Step: 3
Training loss: 1.840174674987793
Validation loss: 2.0264135549465814

Epoch: 5| Step: 4
Training loss: 1.3236455917358398
Validation loss: 2.0339572678009668

Epoch: 5| Step: 5
Training loss: 1.5497647523880005
Validation loss: 2.025043393174807

Epoch: 5| Step: 6
Training loss: 1.8745228052139282
Validation loss: 2.040113151073456

Epoch: 5| Step: 7
Training loss: 1.4794163703918457
Validation loss: 2.0293967525164285

Epoch: 5| Step: 8
Training loss: 1.6147702932357788
Validation loss: 2.0346843699614205

Epoch: 5| Step: 9
Training loss: 1.519116997718811
Validation loss: 2.0183823108673096

Epoch: 5| Step: 10
Training loss: 1.8237979412078857
Validation loss: 2.0075080593427024

Epoch: 5| Step: 11
Training loss: 1.6418943405151367
Validation loss: 2.0060375283161798

Epoch: 75| Step: 0
Training loss: 1.5785431861877441
Validation loss: 1.9698144992192586

Epoch: 5| Step: 1
Training loss: 1.6074998378753662
Validation loss: 1.9769459168116252

Epoch: 5| Step: 2
Training loss: 2.3254504203796387
Validation loss: 1.9512742906808853

Epoch: 5| Step: 3
Training loss: 1.315058946609497
Validation loss: 1.957126076022784

Epoch: 5| Step: 4
Training loss: 1.659223198890686
Validation loss: 1.9541056205828984

Epoch: 5| Step: 5
Training loss: 1.606580138206482
Validation loss: 1.9569262911876042

Epoch: 5| Step: 6
Training loss: 1.8590854406356812
Validation loss: 1.9490014712015789

Epoch: 5| Step: 7
Training loss: 1.7657705545425415
Validation loss: 1.9607847531636555

Epoch: 5| Step: 8
Training loss: 1.9048948287963867
Validation loss: 1.9764794607957203

Epoch: 5| Step: 9
Training loss: 2.244993209838867
Validation loss: 1.9831727693478267

Epoch: 5| Step: 10
Training loss: 1.7915470600128174
Validation loss: 2.0073021153608956

Epoch: 5| Step: 11
Training loss: 1.4460411071777344
Validation loss: 2.016163264711698

Epoch: 76| Step: 0
Training loss: 1.457410216331482
Validation loss: 2.005778913696607

Epoch: 5| Step: 1
Training loss: 2.0216078758239746
Validation loss: 1.994866857926051

Epoch: 5| Step: 2
Training loss: 2.3116626739501953
Validation loss: 2.0017198671897254

Epoch: 5| Step: 3
Training loss: 1.7379544973373413
Validation loss: 1.996776853998502

Epoch: 5| Step: 4
Training loss: 1.6291406154632568
Validation loss: 1.9966920117537181

Epoch: 5| Step: 5
Training loss: 1.4527428150177002
Validation loss: 1.960530161857605

Epoch: 5| Step: 6
Training loss: 2.5243980884552
Validation loss: 1.984980637828509

Epoch: 5| Step: 7
Training loss: 1.6809831857681274
Validation loss: 1.9898535410563152

Epoch: 5| Step: 8
Training loss: 1.2355092763900757
Validation loss: 1.9835571398337681

Epoch: 5| Step: 9
Training loss: 1.4431084394454956
Validation loss: 1.9858622550964355

Epoch: 5| Step: 10
Training loss: 1.7121503353118896
Validation loss: 1.991877059141795

Epoch: 5| Step: 11
Training loss: 1.09079909324646
Validation loss: 1.9925841788450878

Epoch: 77| Step: 0
Training loss: 1.4485052824020386
Validation loss: 1.9940014829238255

Epoch: 5| Step: 1
Training loss: 2.2370729446411133
Validation loss: 2.026949882507324

Epoch: 5| Step: 2
Training loss: 1.7277923822402954
Validation loss: 2.0476240118344626

Epoch: 5| Step: 3
Training loss: 1.94796884059906
Validation loss: 2.039352094133695

Epoch: 5| Step: 4
Training loss: 1.701934814453125
Validation loss: 2.0290550192197165

Epoch: 5| Step: 5
Training loss: 1.7970666885375977
Validation loss: 2.022967572013537

Epoch: 5| Step: 6
Training loss: 1.2848223447799683
Validation loss: 1.9985562165578206

Epoch: 5| Step: 7
Training loss: 1.4006173610687256
Validation loss: 1.985634629925092

Epoch: 5| Step: 8
Training loss: 2.4325075149536133
Validation loss: 1.9859368751446407

Epoch: 5| Step: 9
Training loss: 1.363921880722046
Validation loss: 1.9836920499801636

Epoch: 5| Step: 10
Training loss: 1.9316648244857788
Validation loss: 1.9986060410737991

Epoch: 5| Step: 11
Training loss: 1.3975818157196045
Validation loss: 1.9764200647672017

Epoch: 78| Step: 0
Training loss: 1.8338998556137085
Validation loss: 2.013794889052709

Epoch: 5| Step: 1
Training loss: 1.7093257904052734
Validation loss: 2.018239746491114

Epoch: 5| Step: 2
Training loss: 2.051359176635742
Validation loss: 2.038371125857035

Epoch: 5| Step: 3
Training loss: 2.2013659477233887
Validation loss: 2.0205064912637076

Epoch: 5| Step: 4
Training loss: 2.084104061126709
Validation loss: 2.006073852380117

Epoch: 5| Step: 5
Training loss: 1.3435900211334229
Validation loss: 2.0066138158241906

Epoch: 5| Step: 6
Training loss: 1.2322020530700684
Validation loss: 2.010412027438482

Epoch: 5| Step: 7
Training loss: 1.8866775035858154
Validation loss: 1.99897567431132

Epoch: 5| Step: 8
Training loss: 2.0204756259918213
Validation loss: 1.9731668382883072

Epoch: 5| Step: 9
Training loss: 1.6151984930038452
Validation loss: 1.9713594218095143

Epoch: 5| Step: 10
Training loss: 1.3919503688812256
Validation loss: 1.991845225294431

Epoch: 5| Step: 11
Training loss: 1.0775127410888672
Validation loss: 1.962620844443639

Epoch: 79| Step: 0
Training loss: 1.7560291290283203
Validation loss: 2.0074579815069833

Epoch: 5| Step: 1
Training loss: 1.3701649904251099
Validation loss: 1.993438149491946

Epoch: 5| Step: 2
Training loss: 1.7439266443252563
Validation loss: 2.033281529943148

Epoch: 5| Step: 3
Training loss: 1.6638017892837524
Validation loss: 2.019157956043879

Epoch: 5| Step: 4
Training loss: 1.9236173629760742
Validation loss: 2.0292451828718185

Epoch: 5| Step: 5
Training loss: 1.998199462890625
Validation loss: 2.0878530393044152

Epoch: 5| Step: 6
Training loss: 2.109070301055908
Validation loss: 2.084628477692604

Epoch: 5| Step: 7
Training loss: 1.642428994178772
Validation loss: 2.075633858640989

Epoch: 5| Step: 8
Training loss: 2.008549928665161
Validation loss: 2.097587207953135

Epoch: 5| Step: 9
Training loss: 1.5529645681381226
Validation loss: 2.064145122965177

Epoch: 5| Step: 10
Training loss: 1.827486276626587
Validation loss: 2.050277590751648

Epoch: 5| Step: 11
Training loss: 0.7135535478591919
Validation loss: 2.005859633286794

Epoch: 80| Step: 0
Training loss: 2.0631539821624756
Validation loss: 1.997727672259013

Epoch: 5| Step: 1
Training loss: 1.477138638496399
Validation loss: 1.9966194480657578

Epoch: 5| Step: 2
Training loss: 1.3527641296386719
Validation loss: 1.987486109137535

Epoch: 5| Step: 3
Training loss: 1.6655876636505127
Validation loss: 1.9549337029457092

Epoch: 5| Step: 4
Training loss: 2.3505210876464844
Validation loss: 1.972690353790919

Epoch: 5| Step: 5
Training loss: 1.247556209564209
Validation loss: 1.9671794871489208

Epoch: 5| Step: 6
Training loss: 2.1380934715270996
Validation loss: 1.969994693994522

Epoch: 5| Step: 7
Training loss: 1.84320867061615
Validation loss: 1.9760169784228008

Epoch: 5| Step: 8
Training loss: 1.8907794952392578
Validation loss: 1.9630740582942963

Epoch: 5| Step: 9
Training loss: 1.4202392101287842
Validation loss: 1.9968231370051701

Epoch: 5| Step: 10
Training loss: 1.7312805652618408
Validation loss: 1.9833672245343525

Epoch: 5| Step: 11
Training loss: 1.0322015285491943
Validation loss: 1.9887323180834453

Epoch: 81| Step: 0
Training loss: 1.6728737354278564
Validation loss: 1.9885168274243672

Epoch: 5| Step: 1
Training loss: 1.7004823684692383
Validation loss: 2.000796357790629

Epoch: 5| Step: 2
Training loss: 1.9906295537948608
Validation loss: 2.0269917050997415

Epoch: 5| Step: 3
Training loss: 1.5595343112945557
Validation loss: 2.0254186491171517

Epoch: 5| Step: 4
Training loss: 1.4870938062667847
Validation loss: 2.0279959539572396

Epoch: 5| Step: 5
Training loss: 2.105940341949463
Validation loss: 1.9945717056592305

Epoch: 5| Step: 6
Training loss: 1.453149437904358
Validation loss: 2.0059595902760825

Epoch: 5| Step: 7
Training loss: 1.577103853225708
Validation loss: 1.9975225726763408

Epoch: 5| Step: 8
Training loss: 1.8142677545547485
Validation loss: 1.9997192273537319

Epoch: 5| Step: 9
Training loss: 2.0900135040283203
Validation loss: 1.9685166279474895

Epoch: 5| Step: 10
Training loss: 1.2972363233566284
Validation loss: 1.978913928071658

Epoch: 5| Step: 11
Training loss: 1.5452606678009033
Validation loss: 2.0139936804771423

Epoch: 82| Step: 0
Training loss: 1.1699167490005493
Validation loss: 2.013487954934438

Epoch: 5| Step: 1
Training loss: 1.6630840301513672
Validation loss: 2.0507374902566275

Epoch: 5| Step: 2
Training loss: 2.16760516166687
Validation loss: 2.042496527234713

Epoch: 5| Step: 3
Training loss: 1.441800832748413
Validation loss: 2.062060996890068

Epoch: 5| Step: 4
Training loss: 2.0279221534729004
Validation loss: 2.0545620073874793

Epoch: 5| Step: 5
Training loss: 1.7194631099700928
Validation loss: 2.0542265425125756

Epoch: 5| Step: 6
Training loss: 1.7437664270401
Validation loss: 2.027916972835859

Epoch: 5| Step: 7
Training loss: 1.4423359632492065
Validation loss: 2.0085066060225167

Epoch: 5| Step: 8
Training loss: 1.4879252910614014
Validation loss: 2.000834956765175

Epoch: 5| Step: 9
Training loss: 2.3213706016540527
Validation loss: 2.0013095090786615

Epoch: 5| Step: 10
Training loss: 1.6527830362319946
Validation loss: 1.97394464413325

Epoch: 5| Step: 11
Training loss: 2.7695131301879883
Validation loss: 1.9728649854660034

Epoch: 83| Step: 0
Training loss: 1.6324325799942017
Validation loss: 1.960753008723259

Epoch: 5| Step: 1
Training loss: 1.9938071966171265
Validation loss: 1.97043381134669

Epoch: 5| Step: 2
Training loss: 1.9675395488739014
Validation loss: 1.9684834033250809

Epoch: 5| Step: 3
Training loss: 2.0796425342559814
Validation loss: 1.9819754014412563

Epoch: 5| Step: 4
Training loss: 1.5908138751983643
Validation loss: 1.958591605226199

Epoch: 5| Step: 5
Training loss: 1.382147192955017
Validation loss: 1.9798965801795323

Epoch: 5| Step: 6
Training loss: 1.834665298461914
Validation loss: 1.9887143870194752

Epoch: 5| Step: 7
Training loss: 2.3360323905944824
Validation loss: 1.994756057858467

Epoch: 5| Step: 8
Training loss: 1.6830904483795166
Validation loss: 2.006973703702291

Epoch: 5| Step: 9
Training loss: 1.5664411783218384
Validation loss: 2.0029897540807724

Epoch: 5| Step: 10
Training loss: 1.2013404369354248
Validation loss: 2.023275072375933

Epoch: 5| Step: 11
Training loss: 0.8992369771003723
Validation loss: 2.047220607598623

Epoch: 84| Step: 0
Training loss: 1.6970001459121704
Validation loss: 2.0406237145264945

Epoch: 5| Step: 1
Training loss: 1.100631833076477
Validation loss: 2.0347116639216742

Epoch: 5| Step: 2
Training loss: 1.7711445093154907
Validation loss: 2.028622920314471

Epoch: 5| Step: 3
Training loss: 1.5757458209991455
Validation loss: 2.0181493759155273

Epoch: 5| Step: 4
Training loss: 1.9451935291290283
Validation loss: 1.9950257887442906

Epoch: 5| Step: 5
Training loss: 1.8429075479507446
Validation loss: 1.9966574360926945

Epoch: 5| Step: 6
Training loss: 1.6396558284759521
Validation loss: 2.012261008222898

Epoch: 5| Step: 7
Training loss: 2.137059211730957
Validation loss: 1.9885125209887822

Epoch: 5| Step: 8
Training loss: 1.3675172328948975
Validation loss: 1.972713013490041

Epoch: 5| Step: 9
Training loss: 1.7020199298858643
Validation loss: 1.9577694237232208

Epoch: 5| Step: 10
Training loss: 2.047621488571167
Validation loss: 1.9624618490537007

Epoch: 5| Step: 11
Training loss: 1.3545000553131104
Validation loss: 1.9681193828582764

Epoch: 85| Step: 0
Training loss: 2.719829797744751
Validation loss: 1.958007737994194

Epoch: 5| Step: 1
Training loss: 1.4413245916366577
Validation loss: 1.9338474770387013

Epoch: 5| Step: 2
Training loss: 1.8281805515289307
Validation loss: 1.96257750193278

Epoch: 5| Step: 3
Training loss: 1.3539831638336182
Validation loss: 1.9610863874355953

Epoch: 5| Step: 4
Training loss: 1.4688507318496704
Validation loss: 1.9660827815532684

Epoch: 5| Step: 5
Training loss: 1.4946634769439697
Validation loss: 1.9641410013039906

Epoch: 5| Step: 6
Training loss: 2.4074783325195312
Validation loss: 1.9616021911303203

Epoch: 5| Step: 7
Training loss: 1.7400233745574951
Validation loss: 1.980550264318784

Epoch: 5| Step: 8
Training loss: 1.686841607093811
Validation loss: 2.001905898253123

Epoch: 5| Step: 9
Training loss: 1.2269624471664429
Validation loss: 2.0049866288900375

Epoch: 5| Step: 10
Training loss: 1.6222591400146484
Validation loss: 2.027083143591881

Epoch: 5| Step: 11
Training loss: 0.7396560907363892
Validation loss: 2.0418430219093957

Epoch: 86| Step: 0
Training loss: 1.6213016510009766
Validation loss: 2.0217936982711158

Epoch: 5| Step: 1
Training loss: 1.1113308668136597
Validation loss: 2.008844176928202

Epoch: 5| Step: 2
Training loss: 1.3119381666183472
Validation loss: 2.0097541511058807

Epoch: 5| Step: 3
Training loss: 1.605046033859253
Validation loss: 1.9953895459572475

Epoch: 5| Step: 4
Training loss: 1.9946686029434204
Validation loss: 1.9729708830515544

Epoch: 5| Step: 5
Training loss: 1.9062923192977905
Validation loss: 1.9834770659605663

Epoch: 5| Step: 6
Training loss: 1.6337038278579712
Validation loss: 1.9634451866149902

Epoch: 5| Step: 7
Training loss: 1.881530523300171
Validation loss: 1.9749403794606526

Epoch: 5| Step: 8
Training loss: 1.7428066730499268
Validation loss: 1.9958337942759197

Epoch: 5| Step: 9
Training loss: 1.556719183921814
Validation loss: 1.9666990886131923

Epoch: 5| Step: 10
Training loss: 2.104966878890991
Validation loss: 1.9731937398513157

Epoch: 5| Step: 11
Training loss: 1.491684913635254
Validation loss: 1.981957068045934

Epoch: 87| Step: 0
Training loss: 1.3558237552642822
Validation loss: 1.9944327920675278

Epoch: 5| Step: 1
Training loss: 2.1281826496124268
Validation loss: 2.012701839208603

Epoch: 5| Step: 2
Training loss: 2.4049861431121826
Validation loss: 2.004873732725779

Epoch: 5| Step: 3
Training loss: 1.8022546768188477
Validation loss: 2.0263051986694336

Epoch: 5| Step: 4
Training loss: 1.5230134725570679
Validation loss: 2.0281339635451636

Epoch: 5| Step: 5
Training loss: 1.4205023050308228
Validation loss: 2.0143226186434426

Epoch: 5| Step: 6
Training loss: 1.0965516567230225
Validation loss: 2.0349098096291223

Epoch: 5| Step: 7
Training loss: 1.6170860528945923
Validation loss: 2.0264074901739755

Epoch: 5| Step: 8
Training loss: 1.4845683574676514
Validation loss: 1.9976489941279094

Epoch: 5| Step: 9
Training loss: 1.9623794555664062
Validation loss: 2.001952494184176

Epoch: 5| Step: 10
Training loss: 1.4176585674285889
Validation loss: 1.9845697432756424

Epoch: 5| Step: 11
Training loss: 1.7264748811721802
Validation loss: 1.9894100824991863

Epoch: 88| Step: 0
Training loss: 2.0370218753814697
Validation loss: 1.995823249220848

Epoch: 5| Step: 1
Training loss: 1.4716447591781616
Validation loss: 1.9788288921117783

Epoch: 5| Step: 2
Training loss: 1.6694751977920532
Validation loss: 2.004351948698362

Epoch: 5| Step: 3
Training loss: 1.5532785654067993
Validation loss: 1.973194142182668

Epoch: 5| Step: 4
Training loss: 1.9353469610214233
Validation loss: 1.996110623081525

Epoch: 5| Step: 5
Training loss: 1.2213366031646729
Validation loss: 1.97417247792085

Epoch: 5| Step: 6
Training loss: 1.1860789060592651
Validation loss: 2.0053469936052957

Epoch: 5| Step: 7
Training loss: 1.2354656457901
Validation loss: 2.00941609342893

Epoch: 5| Step: 8
Training loss: 2.274902820587158
Validation loss: 2.0241272697846093

Epoch: 5| Step: 9
Training loss: 1.5487253665924072
Validation loss: 2.0618102997541428

Epoch: 5| Step: 10
Training loss: 2.155327320098877
Validation loss: 2.0692000488440194

Epoch: 5| Step: 11
Training loss: 1.5274009704589844
Validation loss: 2.0693973104159036

Epoch: 89| Step: 0
Training loss: 2.2531797885894775
Validation loss: 2.062614550193151

Epoch: 5| Step: 1
Training loss: 1.9668880701065063
Validation loss: 2.05469773709774

Epoch: 5| Step: 2
Training loss: 1.5288211107254028
Validation loss: 2.061720366279284

Epoch: 5| Step: 3
Training loss: 1.2443548440933228
Validation loss: 2.032909741004308

Epoch: 5| Step: 4
Training loss: 1.6887333393096924
Validation loss: 2.034899984796842

Epoch: 5| Step: 5
Training loss: 1.5455738306045532
Validation loss: 1.982512354850769

Epoch: 5| Step: 6
Training loss: 1.476965308189392
Validation loss: 2.0040867179632187

Epoch: 5| Step: 7
Training loss: 1.7957912683486938
Validation loss: 1.9788800477981567

Epoch: 5| Step: 8
Training loss: 1.6947290897369385
Validation loss: 1.9834835976362228

Epoch: 5| Step: 9
Training loss: 1.0674121379852295
Validation loss: 1.9621829390525818

Epoch: 5| Step: 10
Training loss: 2.0160388946533203
Validation loss: 1.9708877801895142

Epoch: 5| Step: 11
Training loss: 2.089479923248291
Validation loss: 1.9781492948532104

Epoch: 90| Step: 0
Training loss: 1.2720454931259155
Validation loss: 1.9591168761253357

Epoch: 5| Step: 1
Training loss: 1.4787659645080566
Validation loss: 1.9821845640738804

Epoch: 5| Step: 2
Training loss: 1.912157416343689
Validation loss: 1.9854274690151215

Epoch: 5| Step: 3
Training loss: 1.2672646045684814
Validation loss: 1.9798778245846431

Epoch: 5| Step: 4
Training loss: 1.668343186378479
Validation loss: 1.97761865456899

Epoch: 5| Step: 5
Training loss: 1.5670868158340454
Validation loss: 2.00267585615317

Epoch: 5| Step: 6
Training loss: 1.755737543106079
Validation loss: 2.036494026581446

Epoch: 5| Step: 7
Training loss: 2.093209743499756
Validation loss: 2.0666281084219613

Epoch: 5| Step: 8
Training loss: 1.6137138605117798
Validation loss: 2.053125500679016

Epoch: 5| Step: 9
Training loss: 1.7808001041412354
Validation loss: 2.0684658537308374

Epoch: 5| Step: 10
Training loss: 2.1565864086151123
Validation loss: 2.0537151445945105

Epoch: 5| Step: 11
Training loss: 0.8381848335266113
Validation loss: 2.0378181835015616

Epoch: 91| Step: 0
Training loss: 1.2611585855484009
Validation loss: 2.0425896843274436

Epoch: 5| Step: 1
Training loss: 1.720205545425415
Validation loss: 2.017105460166931

Epoch: 5| Step: 2
Training loss: 1.4221078157424927
Validation loss: 2.028593664367994

Epoch: 5| Step: 3
Training loss: 1.4732211828231812
Validation loss: 2.0079808284838996

Epoch: 5| Step: 4
Training loss: 1.5320348739624023
Validation loss: 1.9977322568496068

Epoch: 5| Step: 5
Training loss: 1.446742057800293
Validation loss: 1.9944189290205638

Epoch: 5| Step: 6
Training loss: 1.470373511314392
Validation loss: 1.990675449371338

Epoch: 5| Step: 7
Training loss: 1.6191790103912354
Validation loss: 1.9843927671511967

Epoch: 5| Step: 8
Training loss: 1.7053180932998657
Validation loss: 1.9780579557021458

Epoch: 5| Step: 9
Training loss: 1.9073712825775146
Validation loss: 2.0095991790294647

Epoch: 5| Step: 10
Training loss: 2.436760902404785
Validation loss: 1.9937491814295452

Epoch: 5| Step: 11
Training loss: 2.0864338874816895
Validation loss: 1.9659964640935261

Epoch: 92| Step: 0
Training loss: 1.9162616729736328
Validation loss: 1.966611698269844

Epoch: 5| Step: 1
Training loss: 1.334896206855774
Validation loss: 1.9857522149880726

Epoch: 5| Step: 2
Training loss: 1.5524158477783203
Validation loss: 1.980037917693456

Epoch: 5| Step: 3
Training loss: 1.4667110443115234
Validation loss: 2.000375951329867

Epoch: 5| Step: 4
Training loss: 1.1601041555404663
Validation loss: 1.996309166153272

Epoch: 5| Step: 5
Training loss: 2.205456256866455
Validation loss: 2.008381242553393

Epoch: 5| Step: 6
Training loss: 1.5281730890274048
Validation loss: 2.0232974042495093

Epoch: 5| Step: 7
Training loss: 2.2306904792785645
Validation loss: 2.0558778047561646

Epoch: 5| Step: 8
Training loss: 1.000898003578186
Validation loss: 2.0450757443904877

Epoch: 5| Step: 9
Training loss: 2.1144423484802246
Validation loss: 2.045849228898684

Epoch: 5| Step: 10
Training loss: 1.7688868045806885
Validation loss: 2.0570515543222427

Epoch: 5| Step: 11
Training loss: 0.7721750140190125
Validation loss: 2.0090860525767007

Epoch: 93| Step: 0
Training loss: 1.162469506263733
Validation loss: 2.021738961338997

Epoch: 5| Step: 1
Training loss: 1.755215048789978
Validation loss: 1.9844518850247066

Epoch: 5| Step: 2
Training loss: 1.5035350322723389
Validation loss: 1.992121050755183

Epoch: 5| Step: 3
Training loss: 1.8401386737823486
Validation loss: 1.9891331146160762

Epoch: 5| Step: 4
Training loss: 1.5530450344085693
Validation loss: 1.97146575152874

Epoch: 5| Step: 5
Training loss: 1.6134393215179443
Validation loss: 1.9807131638129551

Epoch: 5| Step: 6
Training loss: 1.620910882949829
Validation loss: 1.9830252180496852

Epoch: 5| Step: 7
Training loss: 2.2938766479492188
Validation loss: 1.965444341301918

Epoch: 5| Step: 8
Training loss: 1.4040738344192505
Validation loss: 1.9785895695288975

Epoch: 5| Step: 9
Training loss: 1.729344367980957
Validation loss: 1.9846862157185872

Epoch: 5| Step: 10
Training loss: 1.519619345664978
Validation loss: 2.0001212308804193

Epoch: 5| Step: 11
Training loss: 1.7581110000610352
Validation loss: 2.0090056508779526

Epoch: 94| Step: 0
Training loss: 2.1073226928710938
Validation loss: 2.0247868994871774

Epoch: 5| Step: 1
Training loss: 1.6296026706695557
Validation loss: 2.0201180428266525

Epoch: 5| Step: 2
Training loss: 1.5998919010162354
Validation loss: 2.011668319503466

Epoch: 5| Step: 3
Training loss: 1.5575838088989258
Validation loss: 1.996057982246081

Epoch: 5| Step: 4
Training loss: 1.7788124084472656
Validation loss: 1.9994339893261592

Epoch: 5| Step: 5
Training loss: 1.410102367401123
Validation loss: 1.9873578349749248

Epoch: 5| Step: 6
Training loss: 1.5890086889266968
Validation loss: 2.0006555914878845

Epoch: 5| Step: 7
Training loss: 1.2615482807159424
Validation loss: 1.987455740571022

Epoch: 5| Step: 8
Training loss: 1.2972196340560913
Validation loss: 2.001286894083023

Epoch: 5| Step: 9
Training loss: 1.6773525476455688
Validation loss: 1.9781295855840046

Epoch: 5| Step: 10
Training loss: 1.774219274520874
Validation loss: 1.981823722521464

Epoch: 5| Step: 11
Training loss: 1.9069786071777344
Validation loss: 1.977331280708313

Epoch: 95| Step: 0
Training loss: 1.8911609649658203
Validation loss: 1.9598729113737743

Epoch: 5| Step: 1
Training loss: 1.5146631002426147
Validation loss: 1.97555107374986

Epoch: 5| Step: 2
Training loss: 1.730690360069275
Validation loss: 1.964090312520663

Epoch: 5| Step: 3
Training loss: 1.2966744899749756
Validation loss: 1.963892365495364

Epoch: 5| Step: 4
Training loss: 1.8502781391143799
Validation loss: 1.9920834104220073

Epoch: 5| Step: 5
Training loss: 2.139317035675049
Validation loss: 1.9818582634131114

Epoch: 5| Step: 6
Training loss: 0.8693771362304688
Validation loss: 2.0059869090716043

Epoch: 5| Step: 7
Training loss: 1.4193627834320068
Validation loss: 2.016591101884842

Epoch: 5| Step: 8
Training loss: 1.2965458631515503
Validation loss: 2.001311093568802

Epoch: 5| Step: 9
Training loss: 1.5150145292282104
Validation loss: 2.007317135731379

Epoch: 5| Step: 10
Training loss: 1.9052152633666992
Validation loss: 1.9775477747122447

Epoch: 5| Step: 11
Training loss: 2.8464908599853516
Validation loss: 1.984641616543134

Epoch: 96| Step: 0
Training loss: 1.1478573083877563
Validation loss: 1.946169341603915

Epoch: 5| Step: 1
Training loss: 1.171528935432434
Validation loss: 1.9610685060421627

Epoch: 5| Step: 2
Training loss: 1.637904405593872
Validation loss: 1.9540711293617885

Epoch: 5| Step: 3
Training loss: 1.4497756958007812
Validation loss: 1.963313768307368

Epoch: 5| Step: 4
Training loss: 1.5259685516357422
Validation loss: 1.9657137195269268

Epoch: 5| Step: 5
Training loss: 1.4011660814285278
Validation loss: 1.9553805241982143

Epoch: 5| Step: 6
Training loss: 1.8101364374160767
Validation loss: 1.9712235083182652

Epoch: 5| Step: 7
Training loss: 2.1508233547210693
Validation loss: 2.0074593077103295

Epoch: 5| Step: 8
Training loss: 1.3454983234405518
Validation loss: 2.006031349301338

Epoch: 5| Step: 9
Training loss: 2.3786463737487793
Validation loss: 2.0487618148326874

Epoch: 5| Step: 10
Training loss: 1.7148033380508423
Validation loss: 2.045411432782809

Epoch: 5| Step: 11
Training loss: 3.6046934127807617
Validation loss: 2.0587662806113562

Epoch: 97| Step: 0
Training loss: 1.9065074920654297
Validation loss: 2.024687593181928

Epoch: 5| Step: 1
Training loss: 1.614769697189331
Validation loss: 2.006040329734484

Epoch: 5| Step: 2
Training loss: 1.4606859683990479
Validation loss: 2.0318857381741204

Epoch: 5| Step: 3
Training loss: 1.4480555057525635
Validation loss: 1.9933062493801117

Epoch: 5| Step: 4
Training loss: 1.5143992900848389
Validation loss: 1.975624571243922

Epoch: 5| Step: 5
Training loss: 2.0683798789978027
Validation loss: 1.958984245856603

Epoch: 5| Step: 6
Training loss: 1.272125482559204
Validation loss: 1.9709337254365284

Epoch: 5| Step: 7
Training loss: 1.0287673473358154
Validation loss: 1.9645485132932663

Epoch: 5| Step: 8
Training loss: 1.6744304895401
Validation loss: 1.9800615360339482

Epoch: 5| Step: 9
Training loss: 1.5016385316848755
Validation loss: 1.980351189772288

Epoch: 5| Step: 10
Training loss: 1.9730794429779053
Validation loss: 1.9782173832257588

Epoch: 5| Step: 11
Training loss: 2.6920409202575684
Validation loss: 1.9728315373261769

Epoch: 98| Step: 0
Training loss: 1.1088972091674805
Validation loss: 1.9875646779934566

Epoch: 5| Step: 1
Training loss: 1.3050458431243896
Validation loss: 2.0009567389885583

Epoch: 5| Step: 2
Training loss: 1.462685465812683
Validation loss: 1.9790418495734532

Epoch: 5| Step: 3
Training loss: 1.6652228832244873
Validation loss: 2.0092528263727822

Epoch: 5| Step: 4
Training loss: 1.839807152748108
Validation loss: 1.9813312242428462

Epoch: 5| Step: 5
Training loss: 2.0484800338745117
Validation loss: 1.9796780447165172

Epoch: 5| Step: 6
Training loss: 1.3872506618499756
Validation loss: 1.9719758580128353

Epoch: 5| Step: 7
Training loss: 1.756890058517456
Validation loss: 1.9863673796256383

Epoch: 5| Step: 8
Training loss: 1.612510323524475
Validation loss: 1.9695302993059158

Epoch: 5| Step: 9
Training loss: 1.450993299484253
Validation loss: 2.0027604003747306

Epoch: 5| Step: 10
Training loss: 1.6212835311889648
Validation loss: 2.021629119912783

Epoch: 5| Step: 11
Training loss: 2.7535529136657715
Validation loss: 2.0101374089717865

Epoch: 99| Step: 0
Training loss: 1.3219784498214722
Validation loss: 2.0036486387252808

Epoch: 5| Step: 1
Training loss: 1.2850067615509033
Validation loss: 2.00954107940197

Epoch: 5| Step: 2
Training loss: 1.5136669874191284
Validation loss: 2.0234536627928414

Epoch: 5| Step: 3
Training loss: 1.3183609247207642
Validation loss: 1.9747598965962727

Epoch: 5| Step: 4
Training loss: 1.705060601234436
Validation loss: 2.0033369064331055

Epoch: 5| Step: 5
Training loss: 1.2788878679275513
Validation loss: 2.0121780236562095

Epoch: 5| Step: 6
Training loss: 2.0522613525390625
Validation loss: 2.0068920056025186

Epoch: 5| Step: 7
Training loss: 1.4699856042861938
Validation loss: 1.9939510971307755

Epoch: 5| Step: 8
Training loss: 1.9339275360107422
Validation loss: 1.9708753923575084

Epoch: 5| Step: 9
Training loss: 1.367760419845581
Validation loss: 1.9729597469170888

Epoch: 5| Step: 10
Training loss: 1.8559691905975342
Validation loss: 1.9623708824316661

Epoch: 5| Step: 11
Training loss: 2.9383273124694824
Validation loss: 1.9371182372172673

Epoch: 100| Step: 0
Training loss: 1.2512531280517578
Validation loss: 1.9787462055683136

Epoch: 5| Step: 1
Training loss: 1.5118777751922607
Validation loss: 1.9463441421588261

Epoch: 5| Step: 2
Training loss: 1.7276462316513062
Validation loss: 1.9733873804410298

Epoch: 5| Step: 3
Training loss: 2.114464521408081
Validation loss: 1.9754546384016674

Epoch: 5| Step: 4
Training loss: 1.9068450927734375
Validation loss: 1.9560204794009526

Epoch: 5| Step: 5
Training loss: 2.1367945671081543
Validation loss: 1.952588175733884

Epoch: 5| Step: 6
Training loss: 1.2038804292678833
Validation loss: 1.957365984718005

Epoch: 5| Step: 7
Training loss: 1.7455835342407227
Validation loss: 1.9512825806935628

Epoch: 5| Step: 8
Training loss: 1.8976995944976807
Validation loss: 1.9643455942471821

Epoch: 5| Step: 9
Training loss: 1.1335937976837158
Validation loss: 1.9928298592567444

Epoch: 5| Step: 10
Training loss: 1.5639235973358154
Validation loss: 1.999372770388921

Epoch: 5| Step: 11
Training loss: 1.2129589319229126
Validation loss: 1.9940285235643387

Epoch: 101| Step: 0
Training loss: 1.4045833349227905
Validation loss: 2.003982419768969

Epoch: 5| Step: 1
Training loss: 1.503058671951294
Validation loss: 2.0098401606082916

Epoch: 5| Step: 2
Training loss: 1.5239765644073486
Validation loss: 2.0131828586260476

Epoch: 5| Step: 3
Training loss: 1.272789716720581
Validation loss: 2.0013233919938407

Epoch: 5| Step: 4
Training loss: 1.4113351106643677
Validation loss: 2.0009497006734214

Epoch: 5| Step: 5
Training loss: 1.410220742225647
Validation loss: 2.0023490687211356

Epoch: 5| Step: 6
Training loss: 1.6689510345458984
Validation loss: 1.9684743136167526

Epoch: 5| Step: 7
Training loss: 2.1779212951660156
Validation loss: 1.9553853621085484

Epoch: 5| Step: 8
Training loss: 1.222203016281128
Validation loss: 1.967834323644638

Epoch: 5| Step: 9
Training loss: 1.917091727256775
Validation loss: 1.9485059926907222

Epoch: 5| Step: 10
Training loss: 1.6195749044418335
Validation loss: 1.9574607610702515

Epoch: 5| Step: 11
Training loss: 3.1558094024658203
Validation loss: 1.9848195314407349

Epoch: 102| Step: 0
Training loss: 1.469675064086914
Validation loss: 1.9677151242891948

Epoch: 5| Step: 1
Training loss: 1.5454407930374146
Validation loss: 1.9811222354571025

Epoch: 5| Step: 2
Training loss: 1.5480146408081055
Validation loss: 1.961521675189336

Epoch: 5| Step: 3
Training loss: 1.9292103052139282
Validation loss: 2.000279054045677

Epoch: 5| Step: 4
Training loss: 1.8041385412216187
Validation loss: 1.9988808035850525

Epoch: 5| Step: 5
Training loss: 1.5195749998092651
Validation loss: 2.011840278903643

Epoch: 5| Step: 6
Training loss: 1.7555290460586548
Validation loss: 2.0018018931150436

Epoch: 5| Step: 7
Training loss: 1.2522658109664917
Validation loss: 2.023232087492943

Epoch: 5| Step: 8
Training loss: 1.4777657985687256
Validation loss: 2.0112218856811523

Epoch: 5| Step: 9
Training loss: 1.8361402750015259
Validation loss: 1.983797326683998

Epoch: 5| Step: 10
Training loss: 1.269964575767517
Validation loss: 2.0017574777205787

Epoch: 5| Step: 11
Training loss: 0.43523940443992615
Validation loss: 1.9859177023172379

Epoch: 103| Step: 0
Training loss: 1.6110999584197998
Validation loss: 1.9801263461510341

Epoch: 5| Step: 1
Training loss: 1.3440687656402588
Validation loss: 1.9814844479163487

Epoch: 5| Step: 2
Training loss: 0.7314003705978394
Validation loss: 1.9758575906356175

Epoch: 5| Step: 3
Training loss: 1.9127947092056274
Validation loss: 1.9971156070629756

Epoch: 5| Step: 4
Training loss: 1.4672424793243408
Validation loss: 2.0005735705296197

Epoch: 5| Step: 5
Training loss: 1.7608344554901123
Validation loss: 1.986846352616946

Epoch: 5| Step: 6
Training loss: 1.8470417261123657
Validation loss: 1.959249456723531

Epoch: 5| Step: 7
Training loss: 1.3668791055679321
Validation loss: 1.978786622484525

Epoch: 5| Step: 8
Training loss: 2.1707048416137695
Validation loss: 1.9831849137941997

Epoch: 5| Step: 9
Training loss: 1.6911596059799194
Validation loss: 1.980947956442833

Epoch: 5| Step: 10
Training loss: 1.1373906135559082
Validation loss: 2.003429333368937

Epoch: 5| Step: 11
Training loss: 0.8922066688537598
Validation loss: 1.9928417851527531

Epoch: 104| Step: 0
Training loss: 0.820480465888977
Validation loss: 2.0426323066155114

Epoch: 5| Step: 1
Training loss: 1.7496201992034912
Validation loss: 2.0682777216037116

Epoch: 5| Step: 2
Training loss: 1.8995997905731201
Validation loss: 2.091482013463974

Epoch: 5| Step: 3
Training loss: 2.3733699321746826
Validation loss: 2.0906357914209366

Epoch: 5| Step: 4
Training loss: 1.6841180324554443
Validation loss: 2.0836085826158524

Epoch: 5| Step: 5
Training loss: 1.900686264038086
Validation loss: 2.0689556896686554

Epoch: 5| Step: 6
Training loss: 1.4864280223846436
Validation loss: 2.0304042051235833

Epoch: 5| Step: 7
Training loss: 1.4173957109451294
Validation loss: 2.003776808579763

Epoch: 5| Step: 8
Training loss: 1.5340335369110107
Validation loss: 1.9764772703250248

Epoch: 5| Step: 9
Training loss: 1.7057673931121826
Validation loss: 1.9770130266745884

Epoch: 5| Step: 10
Training loss: 1.2820703983306885
Validation loss: 1.9514551510413487

Epoch: 5| Step: 11
Training loss: 1.4007630348205566
Validation loss: 1.9456863701343536

Epoch: 105| Step: 0
Training loss: 1.089858055114746
Validation loss: 1.953622817993164

Epoch: 5| Step: 1
Training loss: 1.364859938621521
Validation loss: 1.9545009036858876

Epoch: 5| Step: 2
Training loss: 1.7797996997833252
Validation loss: 1.9616720328728359

Epoch: 5| Step: 3
Training loss: 1.5094987154006958
Validation loss: 1.9398162265618641

Epoch: 5| Step: 4
Training loss: 2.1656954288482666
Validation loss: 1.9398916413386662

Epoch: 5| Step: 5
Training loss: 1.9013121128082275
Validation loss: 1.9695296784241993

Epoch: 5| Step: 6
Training loss: 1.1508244276046753
Validation loss: 2.003313804666201

Epoch: 5| Step: 7
Training loss: 1.9740406274795532
Validation loss: 1.9837589810291927

Epoch: 5| Step: 8
Training loss: 1.4109792709350586
Validation loss: 2.0253778994083405

Epoch: 5| Step: 9
Training loss: 1.391052007675171
Validation loss: 2.006964107354482

Epoch: 5| Step: 10
Training loss: 1.4101958274841309
Validation loss: 2.0038029551506042

Epoch: 5| Step: 11
Training loss: 0.8811235427856445
Validation loss: 1.9811134835084279

Epoch: 106| Step: 0
Training loss: 1.8673617839813232
Validation loss: 2.031320412953695

Epoch: 5| Step: 1
Training loss: 1.5121837854385376
Validation loss: 2.0033879031737647

Epoch: 5| Step: 2
Training loss: 1.754866361618042
Validation loss: 1.9993339826663334

Epoch: 5| Step: 3
Training loss: 1.4353877305984497
Validation loss: 2.0151790926853814

Epoch: 5| Step: 4
Training loss: 1.6779201030731201
Validation loss: 2.001449758807818

Epoch: 5| Step: 5
Training loss: 1.9130876064300537
Validation loss: 2.005802442630132

Epoch: 5| Step: 6
Training loss: 1.409160852432251
Validation loss: 1.9882673819859822

Epoch: 5| Step: 7
Training loss: 1.3737146854400635
Validation loss: 1.984628364443779

Epoch: 5| Step: 8
Training loss: 1.573477029800415
Validation loss: 2.007581204175949

Epoch: 5| Step: 9
Training loss: 1.3720875978469849
Validation loss: 1.9894722004731495

Epoch: 5| Step: 10
Training loss: 1.1306421756744385
Validation loss: 1.9931987921396892

Epoch: 5| Step: 11
Training loss: 0.4940927028656006
Validation loss: 1.988739291826884

Epoch: 107| Step: 0
Training loss: 1.523571252822876
Validation loss: 1.9962535550196965

Epoch: 5| Step: 1
Training loss: 1.526031255722046
Validation loss: 2.0244916876157126

Epoch: 5| Step: 2
Training loss: 2.0049519538879395
Validation loss: 1.9755258460839589

Epoch: 5| Step: 3
Training loss: 1.401530385017395
Validation loss: 1.9837527771790822

Epoch: 5| Step: 4
Training loss: 2.038412094116211
Validation loss: 1.9801491002241771

Epoch: 5| Step: 5
Training loss: 2.0036263465881348
Validation loss: 1.9820684989293416

Epoch: 5| Step: 6
Training loss: 1.066637396812439
Validation loss: 1.9838186502456665

Epoch: 5| Step: 7
Training loss: 1.6929235458374023
Validation loss: 2.001825431982676

Epoch: 5| Step: 8
Training loss: 1.0884568691253662
Validation loss: 1.9988202154636383

Epoch: 5| Step: 9
Training loss: 1.0415785312652588
Validation loss: 2.013901794950167

Epoch: 5| Step: 10
Training loss: 1.544378399848938
Validation loss: 2.006305212775866

Epoch: 5| Step: 11
Training loss: 1.1919338703155518
Validation loss: 2.016734411319097

Epoch: 108| Step: 0
Training loss: 1.1842514276504517
Validation loss: 2.0031930208206177

Epoch: 5| Step: 1
Training loss: 1.2467461824417114
Validation loss: 2.026107286413511

Epoch: 5| Step: 2
Training loss: 1.4296451807022095
Validation loss: 2.01221331457297

Epoch: 5| Step: 3
Training loss: 1.8422276973724365
Validation loss: 2.019811992843946

Epoch: 5| Step: 4
Training loss: 1.9222214221954346
Validation loss: 1.9956756979227066

Epoch: 5| Step: 5
Training loss: 1.248922348022461
Validation loss: 1.9919198701779048

Epoch: 5| Step: 6
Training loss: 1.3508751392364502
Validation loss: 1.994177023569743

Epoch: 5| Step: 7
Training loss: 1.6240075826644897
Validation loss: 1.9944330304861069

Epoch: 5| Step: 8
Training loss: 1.5002620220184326
Validation loss: 1.979789137840271

Epoch: 5| Step: 9
Training loss: 1.806302785873413
Validation loss: 2.0024968485037484

Epoch: 5| Step: 10
Training loss: 1.579668641090393
Validation loss: 1.9975311905145645

Epoch: 5| Step: 11
Training loss: 0.8734086751937866
Validation loss: 2.000929926832517

Epoch: 109| Step: 0
Training loss: 1.5529913902282715
Validation loss: 1.9963482916355133

Epoch: 5| Step: 1
Training loss: 1.2910869121551514
Validation loss: 1.9749847253163655

Epoch: 5| Step: 2
Training loss: 1.7910503149032593
Validation loss: 1.95094529290994

Epoch: 5| Step: 3
Training loss: 1.8421077728271484
Validation loss: 1.962982142964999

Epoch: 5| Step: 4
Training loss: 1.3874926567077637
Validation loss: 1.9677978157997131

Epoch: 5| Step: 5
Training loss: 1.6040847301483154
Validation loss: 1.968582530816396

Epoch: 5| Step: 6
Training loss: 0.8332000970840454
Validation loss: 1.9652983844280243

Epoch: 5| Step: 7
Training loss: 1.6096073389053345
Validation loss: 1.9661956081787746

Epoch: 5| Step: 8
Training loss: 1.5531456470489502
Validation loss: 1.983096773425738

Epoch: 5| Step: 9
Training loss: 1.4856932163238525
Validation loss: 1.9606310079495113

Epoch: 5| Step: 10
Training loss: 1.5339956283569336
Validation loss: 1.97139177719752

Epoch: 5| Step: 11
Training loss: 1.5396785736083984
Validation loss: 1.971324861049652

Epoch: 110| Step: 0
Training loss: 1.2754991054534912
Validation loss: 1.9819009105364482

Epoch: 5| Step: 1
Training loss: 1.9266945123672485
Validation loss: 2.0016731272141137

Epoch: 5| Step: 2
Training loss: 1.6322561502456665
Validation loss: 1.983450785279274

Epoch: 5| Step: 3
Training loss: 1.3633514642715454
Validation loss: 1.995580365260442

Epoch: 5| Step: 4
Training loss: 1.1400058269500732
Validation loss: 1.973902851343155

Epoch: 5| Step: 5
Training loss: 1.6771472692489624
Validation loss: 1.9856279889742534

Epoch: 5| Step: 6
Training loss: 1.3305613994598389
Validation loss: 1.9739252080519993

Epoch: 5| Step: 7
Training loss: 1.4892183542251587
Validation loss: 1.9605828275283177

Epoch: 5| Step: 8
Training loss: 1.4461846351623535
Validation loss: 1.9626685629288356

Epoch: 5| Step: 9
Training loss: 1.6903095245361328
Validation loss: 1.9575712531805038

Epoch: 5| Step: 10
Training loss: 1.2367491722106934
Validation loss: 1.9624282071987789

Epoch: 5| Step: 11
Training loss: 2.4944863319396973
Validation loss: 1.966609964768092

Epoch: 111| Step: 0
Training loss: 0.9480029940605164
Validation loss: 1.9804905205965042

Epoch: 5| Step: 1
Training loss: 1.4713997840881348
Validation loss: 1.9735238254070282

Epoch: 5| Step: 2
Training loss: 1.3378973007202148
Validation loss: 1.9803534547487895

Epoch: 5| Step: 3
Training loss: 1.6974893808364868
Validation loss: 1.986758679151535

Epoch: 5| Step: 4
Training loss: 1.218375563621521
Validation loss: 1.993123968442281

Epoch: 5| Step: 5
Training loss: 1.421594500541687
Validation loss: 2.0029927641153336

Epoch: 5| Step: 6
Training loss: 1.730133295059204
Validation loss: 2.0050823986530304

Epoch: 5| Step: 7
Training loss: 1.614466667175293
Validation loss: 1.9933124631643295

Epoch: 5| Step: 8
Training loss: 2.2220263481140137
Validation loss: 1.9938246111075084

Epoch: 5| Step: 9
Training loss: 1.5380290746688843
Validation loss: 1.9879071414470673

Epoch: 5| Step: 10
Training loss: 1.076535940170288
Validation loss: 1.9947934051354725

Epoch: 5| Step: 11
Training loss: 0.996283769607544
Validation loss: 1.9825762460629146

Epoch: 112| Step: 0
Training loss: 0.9827266931533813
Validation loss: 1.9828089078267415

Epoch: 5| Step: 1
Training loss: 1.7073663473129272
Validation loss: 1.9808946053187053

Epoch: 5| Step: 2
Training loss: 1.5138492584228516
Validation loss: 1.9620886147022247

Epoch: 5| Step: 3
Training loss: 1.0852607488632202
Validation loss: 1.9739208022753398

Epoch: 5| Step: 4
Training loss: 1.2360320091247559
Validation loss: 1.9684663514296215

Epoch: 5| Step: 5
Training loss: 1.8792235851287842
Validation loss: 1.9859366317590077

Epoch: 5| Step: 6
Training loss: 2.2404568195343018
Validation loss: 1.9706560571988423

Epoch: 5| Step: 7
Training loss: 1.1427468061447144
Validation loss: 1.9768059353033702

Epoch: 5| Step: 8
Training loss: 1.6686795949935913
Validation loss: 1.9701615124940872

Epoch: 5| Step: 9
Training loss: 1.1299216747283936
Validation loss: 1.995886579155922

Epoch: 5| Step: 10
Training loss: 1.3434655666351318
Validation loss: 1.976641207933426

Epoch: 5| Step: 11
Training loss: 1.9422810077667236
Validation loss: 1.9643295804659526

Epoch: 113| Step: 0
Training loss: 1.5941506624221802
Validation loss: 1.961684172352155

Epoch: 5| Step: 1
Training loss: 1.261959433555603
Validation loss: 1.9704012821118038

Epoch: 5| Step: 2
Training loss: 1.5706173181533813
Validation loss: 1.9504931916793187

Epoch: 5| Step: 3
Training loss: 1.7223052978515625
Validation loss: 1.9762061287959416

Epoch: 5| Step: 4
Training loss: 1.045701503753662
Validation loss: 1.960457131266594

Epoch: 5| Step: 5
Training loss: 1.6093374490737915
Validation loss: 1.9454141358534496

Epoch: 5| Step: 6
Training loss: 1.1859228610992432
Validation loss: 1.9300162394841511

Epoch: 5| Step: 7
Training loss: 1.3377195596694946
Validation loss: 1.9697878807783127

Epoch: 5| Step: 8
Training loss: 1.8056652545928955
Validation loss: 1.9616515686114628

Epoch: 5| Step: 9
Training loss: 1.208355188369751
Validation loss: 1.9661934673786163

Epoch: 5| Step: 10
Training loss: 1.4976156949996948
Validation loss: 1.9758431613445282

Epoch: 5| Step: 11
Training loss: 2.3608145713806152
Validation loss: 1.9709910502036412

Epoch: 114| Step: 0
Training loss: 1.556674599647522
Validation loss: 2.006350780526797

Epoch: 5| Step: 1
Training loss: 1.6296653747558594
Validation loss: 2.0183803786834082

Epoch: 5| Step: 2
Training loss: 1.262434959411621
Validation loss: 2.0101046015818915

Epoch: 5| Step: 3
Training loss: 1.0413377285003662
Validation loss: 1.9993726710478466

Epoch: 5| Step: 4
Training loss: 1.3276941776275635
Validation loss: 1.9885807434717815

Epoch: 5| Step: 5
Training loss: 1.5200618505477905
Validation loss: 1.9710637430349986

Epoch: 5| Step: 6
Training loss: 1.831372857093811
Validation loss: 1.9892781327168148

Epoch: 5| Step: 7
Training loss: 1.3812603950500488
Validation loss: 1.965917557477951

Epoch: 5| Step: 8
Training loss: 1.588371753692627
Validation loss: 1.990741178393364

Epoch: 5| Step: 9
Training loss: 1.578721284866333
Validation loss: 1.9956291615962982

Epoch: 5| Step: 10
Training loss: 1.5514568090438843
Validation loss: 1.9812744458516438

Epoch: 5| Step: 11
Training loss: 1.316772222518921
Validation loss: 1.9991306165854137

Epoch: 115| Step: 0
Training loss: 1.9302661418914795
Validation loss: 1.9789763689041138

Epoch: 5| Step: 1
Training loss: 1.4264055490493774
Validation loss: 1.9655604759852092

Epoch: 5| Step: 2
Training loss: 1.2306671142578125
Validation loss: 1.9855733513832092

Epoch: 5| Step: 3
Training loss: 1.3781336545944214
Validation loss: 1.9982458005348842

Epoch: 5| Step: 4
Training loss: 1.5329205989837646
Validation loss: 1.9991766810417175

Epoch: 5| Step: 5
Training loss: 1.4726910591125488
Validation loss: 1.9915734827518463

Epoch: 5| Step: 6
Training loss: 1.3854377269744873
Validation loss: 1.982588027914365

Epoch: 5| Step: 7
Training loss: 1.3047291040420532
Validation loss: 1.9749131947755814

Epoch: 5| Step: 8
Training loss: 1.62095046043396
Validation loss: 1.9764317373434703

Epoch: 5| Step: 9
Training loss: 1.4280660152435303
Validation loss: 1.9892371247212093

Epoch: 5| Step: 10
Training loss: 1.3124765157699585
Validation loss: 1.9865667670965195

Epoch: 5| Step: 11
Training loss: 0.353995144367218
Validation loss: 1.9903871218363445

Epoch: 116| Step: 0
Training loss: 1.3533782958984375
Validation loss: 1.9884993185599644

Epoch: 5| Step: 1
Training loss: 0.6120584607124329
Validation loss: 1.9385496079921722

Epoch: 5| Step: 2
Training loss: 1.448779582977295
Validation loss: 1.9697106033563614

Epoch: 5| Step: 3
Training loss: 1.7389640808105469
Validation loss: 1.9817366103331249

Epoch: 5| Step: 4
Training loss: 1.2593544721603394
Validation loss: 1.9644310226043065

Epoch: 5| Step: 5
Training loss: 1.6853660345077515
Validation loss: 1.9617117196321487

Epoch: 5| Step: 6
Training loss: 1.064319133758545
Validation loss: 1.9678975492715836

Epoch: 5| Step: 7
Training loss: 1.668117880821228
Validation loss: 1.9820129772027333

Epoch: 5| Step: 8
Training loss: 1.557042121887207
Validation loss: 1.9756272236506145

Epoch: 5| Step: 9
Training loss: 1.5542526245117188
Validation loss: 1.970550964275996

Epoch: 5| Step: 10
Training loss: 1.5917028188705444
Validation loss: 1.974982072909673

Epoch: 5| Step: 11
Training loss: 2.570387840270996
Validation loss: 1.958569238583247

Epoch: 117| Step: 0
Training loss: 1.4945344924926758
Validation loss: 1.9590555131435394

Epoch: 5| Step: 1
Training loss: 1.582581877708435
Validation loss: 1.9881399422883987

Epoch: 5| Step: 2
Training loss: 1.321488857269287
Validation loss: 1.9699999193350475

Epoch: 5| Step: 3
Training loss: 1.348987340927124
Validation loss: 1.9610563963651657

Epoch: 5| Step: 4
Training loss: 1.5033843517303467
Validation loss: 1.9596375326315563

Epoch: 5| Step: 5
Training loss: 1.5275394916534424
Validation loss: 1.9999211877584457

Epoch: 5| Step: 6
Training loss: 1.432631254196167
Validation loss: 1.9685459931691487

Epoch: 5| Step: 7
Training loss: 1.2278358936309814
Validation loss: 2.000327909986178

Epoch: 5| Step: 8
Training loss: 1.1486587524414062
Validation loss: 1.9724833120902379

Epoch: 5| Step: 9
Training loss: 1.1581450700759888
Validation loss: 2.02124086022377

Epoch: 5| Step: 10
Training loss: 2.091028928756714
Validation loss: 1.9905610581239064

Epoch: 5| Step: 11
Training loss: 1.2202956676483154
Validation loss: 1.9815309047698975

Epoch: 118| Step: 0
Training loss: 1.2943649291992188
Validation loss: 1.9809468239545822

Epoch: 5| Step: 1
Training loss: 1.3674370050430298
Validation loss: 1.9619941463073094

Epoch: 5| Step: 2
Training loss: 1.6524652242660522
Validation loss: 1.98222483197848

Epoch: 5| Step: 3
Training loss: 1.534013032913208
Validation loss: 1.9625821361939113

Epoch: 5| Step: 4
Training loss: 2.3476481437683105
Validation loss: 1.9752374440431595

Epoch: 5| Step: 5
Training loss: 1.2796962261199951
Validation loss: 1.9500259806712468

Epoch: 5| Step: 6
Training loss: 1.4108954668045044
Validation loss: 1.9687589854002

Epoch: 5| Step: 7
Training loss: 1.088674545288086
Validation loss: 1.9751176983118057

Epoch: 5| Step: 8
Training loss: 1.431387186050415
Validation loss: 1.9446894228458405

Epoch: 5| Step: 9
Training loss: 0.9261773824691772
Validation loss: 1.9887221455574036

Epoch: 5| Step: 10
Training loss: 1.1242201328277588
Validation loss: 1.978191723426183

Epoch: 5| Step: 11
Training loss: 1.9512672424316406
Validation loss: 1.9919101148843765

Epoch: 119| Step: 0
Training loss: 1.2783151865005493
Validation loss: 1.970745434363683

Epoch: 5| Step: 1
Training loss: 1.243424892425537
Validation loss: 1.949294537305832

Epoch: 5| Step: 2
Training loss: 0.9617454409599304
Validation loss: 1.9902402758598328

Epoch: 5| Step: 3
Training loss: 1.8114149570465088
Validation loss: 1.9751404176155727

Epoch: 5| Step: 4
Training loss: 1.6454299688339233
Validation loss: 1.940032571554184

Epoch: 5| Step: 5
Training loss: 1.0005786418914795
Validation loss: 1.9640129556258519

Epoch: 5| Step: 6
Training loss: 2.000331401824951
Validation loss: 1.9858902146418889

Epoch: 5| Step: 7
Training loss: 1.2993032932281494
Validation loss: 1.997389445702235

Epoch: 5| Step: 8
Training loss: 2.0477871894836426
Validation loss: 2.000880166888237

Epoch: 5| Step: 9
Training loss: 1.330333948135376
Validation loss: 2.004378323753675

Epoch: 5| Step: 10
Training loss: 1.4798080921173096
Validation loss: 1.9658784220616023

Epoch: 5| Step: 11
Training loss: 0.19447797536849976
Validation loss: 1.9956297477086384

Epoch: 120| Step: 0
Training loss: 1.8320319652557373
Validation loss: 1.9482262283563614

Epoch: 5| Step: 1
Training loss: 1.0730406045913696
Validation loss: 1.9895861943562825

Epoch: 5| Step: 2
Training loss: 1.1275193691253662
Validation loss: 1.9528373181819916

Epoch: 5| Step: 3
Training loss: 1.6984984874725342
Validation loss: 1.9602016657590866

Epoch: 5| Step: 4
Training loss: 1.6396604776382446
Validation loss: 1.9777046193679173

Epoch: 5| Step: 5
Training loss: 1.365807294845581
Validation loss: 1.9686727027098339

Epoch: 5| Step: 6
Training loss: 1.4531338214874268
Validation loss: 1.9965821256240208

Epoch: 5| Step: 7
Training loss: 0.8591820597648621
Validation loss: 1.9966194132963817

Epoch: 5| Step: 8
Training loss: 1.571608304977417
Validation loss: 1.9541023870309193

Epoch: 5| Step: 9
Training loss: 1.1677576303482056
Validation loss: 1.983152871330579

Epoch: 5| Step: 10
Training loss: 1.7816206216812134
Validation loss: 1.9810091157754262

Epoch: 5| Step: 11
Training loss: 1.2050384283065796
Validation loss: 1.9550709823767345

Epoch: 121| Step: 0
Training loss: 1.1044106483459473
Validation loss: 1.9609913577636082

Epoch: 5| Step: 1
Training loss: 1.810621976852417
Validation loss: 1.9611243108908336

Epoch: 5| Step: 2
Training loss: 1.6331278085708618
Validation loss: 1.953908622264862

Epoch: 5| Step: 3
Training loss: 1.4963401556015015
Validation loss: 1.958880086739858

Epoch: 5| Step: 4
Training loss: 1.5005557537078857
Validation loss: 1.9320216625928879

Epoch: 5| Step: 5
Training loss: 1.6243183612823486
Validation loss: 1.9433086564143498

Epoch: 5| Step: 6
Training loss: 0.9709307551383972
Validation loss: 1.9674522032340367

Epoch: 5| Step: 7
Training loss: 1.2779481410980225
Validation loss: 1.9838220824797947

Epoch: 5| Step: 8
Training loss: 1.4961836338043213
Validation loss: 1.9972275296847026

Epoch: 5| Step: 9
Training loss: 1.150221586227417
Validation loss: 2.00393479069074

Epoch: 5| Step: 10
Training loss: 1.615081787109375
Validation loss: 2.0271865129470825

Epoch: 5| Step: 11
Training loss: 1.2123961448669434
Validation loss: 2.006995419661204

Epoch: 122| Step: 0
Training loss: 1.4817806482315063
Validation loss: 2.002604295810064

Epoch: 5| Step: 1
Training loss: 1.2133729457855225
Validation loss: 2.0091733833154044

Epoch: 5| Step: 2
Training loss: 1.6304261684417725
Validation loss: 1.9703192015488942

Epoch: 5| Step: 3
Training loss: 1.8523409366607666
Validation loss: 1.9628751029570897

Epoch: 5| Step: 4
Training loss: 1.1627967357635498
Validation loss: 1.9919148286183674

Epoch: 5| Step: 5
Training loss: 1.1763370037078857
Validation loss: 1.9584288100401561

Epoch: 5| Step: 6
Training loss: 1.160106897354126
Validation loss: 1.9459338337182999

Epoch: 5| Step: 7
Training loss: 0.995481014251709
Validation loss: 1.9807082414627075

Epoch: 5| Step: 8
Training loss: 1.155813455581665
Validation loss: 1.9381415496269863

Epoch: 5| Step: 9
Training loss: 1.7068555355072021
Validation loss: 1.9614514013131459

Epoch: 5| Step: 10
Training loss: 2.1438021659851074
Validation loss: 1.9675220449765523

Epoch: 5| Step: 11
Training loss: 0.7840139865875244
Validation loss: 2.00733291109403

Epoch: 123| Step: 0
Training loss: 1.3701279163360596
Validation loss: 2.015409300724665

Epoch: 5| Step: 1
Training loss: 1.087463140487671
Validation loss: 2.0193771620591483

Epoch: 5| Step: 2
Training loss: 1.6586811542510986
Validation loss: 2.009402349591255

Epoch: 5| Step: 3
Training loss: 1.7230218648910522
Validation loss: 2.0099087953567505

Epoch: 5| Step: 4
Training loss: 1.2714029550552368
Validation loss: 1.9864744891722996

Epoch: 5| Step: 5
Training loss: 1.6940158605575562
Validation loss: 1.9837906112273533

Epoch: 5| Step: 6
Training loss: 1.6512314081192017
Validation loss: 1.9733455975850422

Epoch: 5| Step: 7
Training loss: 1.205913782119751
Validation loss: 1.961014265815417

Epoch: 5| Step: 8
Training loss: 1.1956514120101929
Validation loss: 1.9590310355027516

Epoch: 5| Step: 9
Training loss: 1.465397596359253
Validation loss: 1.9509684592485428

Epoch: 5| Step: 10
Training loss: 1.0766031742095947
Validation loss: 1.957583283384641

Epoch: 5| Step: 11
Training loss: 1.2347667217254639
Validation loss: 1.984755073984464

Epoch: 124| Step: 0
Training loss: 1.3266724348068237
Validation loss: 1.9868597437938054

Epoch: 5| Step: 1
Training loss: 1.0750681161880493
Validation loss: 1.9684052218993504

Epoch: 5| Step: 2
Training loss: 1.622854471206665
Validation loss: 1.9781232128540676

Epoch: 5| Step: 3
Training loss: 1.2655366659164429
Validation loss: 1.9565128087997437

Epoch: 5| Step: 4
Training loss: 1.6538677215576172
Validation loss: 1.9526331027348836

Epoch: 5| Step: 5
Training loss: 1.718907356262207
Validation loss: 1.9622098058462143

Epoch: 5| Step: 6
Training loss: 1.5748746395111084
Validation loss: 1.9806467195351918

Epoch: 5| Step: 7
Training loss: 1.6869500875473022
Validation loss: 1.9480693886677425

Epoch: 5| Step: 8
Training loss: 1.1854058504104614
Validation loss: 1.9462341119845707

Epoch: 5| Step: 9
Training loss: 0.5391522645950317
Validation loss: 1.981288492679596

Epoch: 5| Step: 10
Training loss: 1.6097227334976196
Validation loss: 1.9932883580525715

Epoch: 5| Step: 11
Training loss: 1.33492910861969
Validation loss: 1.9787005484104156

Epoch: 125| Step: 0
Training loss: 1.587677001953125
Validation loss: 1.9921675771474838

Epoch: 5| Step: 1
Training loss: 1.0971484184265137
Validation loss: 1.9593788534402847

Epoch: 5| Step: 2
Training loss: 1.7286125421524048
Validation loss: 1.9909109969933827

Epoch: 5| Step: 3
Training loss: 1.1531505584716797
Validation loss: 1.9688126842180889

Epoch: 5| Step: 4
Training loss: 1.4015003442764282
Validation loss: 1.983065461119016

Epoch: 5| Step: 5
Training loss: 1.8511323928833008
Validation loss: 1.9702648321787517

Epoch: 5| Step: 6
Training loss: 1.1368920803070068
Validation loss: 1.9360611885786057

Epoch: 5| Step: 7
Training loss: 1.8373829126358032
Validation loss: 1.9710659235715866

Epoch: 5| Step: 8
Training loss: 1.2146894931793213
Validation loss: 1.9448791841665904

Epoch: 5| Step: 9
Training loss: 1.316534399986267
Validation loss: 1.951796978712082

Epoch: 5| Step: 10
Training loss: 0.6210306286811829
Validation loss: 1.95175701379776

Epoch: 5| Step: 11
Training loss: 1.109123706817627
Validation loss: 1.9942167351643245

Epoch: 126| Step: 0
Training loss: 1.0743929147720337
Validation loss: 1.9742141216993332

Epoch: 5| Step: 1
Training loss: 1.3369523286819458
Validation loss: 1.9581593821446102

Epoch: 5| Step: 2
Training loss: 1.438490629196167
Validation loss: 1.9737307280302048

Epoch: 5| Step: 3
Training loss: 1.7022838592529297
Validation loss: 1.967998743057251

Epoch: 5| Step: 4
Training loss: 0.8605840802192688
Validation loss: 1.9652278920014699

Epoch: 5| Step: 5
Training loss: 1.422731637954712
Validation loss: 1.9796119978030522

Epoch: 5| Step: 6
Training loss: 1.4823262691497803
Validation loss: 1.9617336591084797

Epoch: 5| Step: 7
Training loss: 1.045540452003479
Validation loss: 1.9839495768149693

Epoch: 5| Step: 8
Training loss: 1.8925094604492188
Validation loss: 1.9995286365350087

Epoch: 5| Step: 9
Training loss: 1.006592035293579
Validation loss: 1.9735884964466095

Epoch: 5| Step: 10
Training loss: 1.588006615638733
Validation loss: 1.984870860973994

Epoch: 5| Step: 11
Training loss: 2.005556106567383
Validation loss: 2.0105888346831002

Epoch: 127| Step: 0
Training loss: 1.5195986032485962
Validation loss: 1.9746246685584385

Epoch: 5| Step: 1
Training loss: 0.7735965847969055
Validation loss: 1.9900580793619156

Epoch: 5| Step: 2
Training loss: 1.181771993637085
Validation loss: 1.968647172053655

Epoch: 5| Step: 3
Training loss: 2.1919565200805664
Validation loss: 1.9540339012940724

Epoch: 5| Step: 4
Training loss: 1.0948210954666138
Validation loss: 1.9518348276615143

Epoch: 5| Step: 5
Training loss: 1.5073189735412598
Validation loss: 1.9582626024882

Epoch: 5| Step: 6
Training loss: 1.4879138469696045
Validation loss: 1.952873686949412

Epoch: 5| Step: 7
Training loss: 1.0053170919418335
Validation loss: 1.9603716085354488

Epoch: 5| Step: 8
Training loss: 1.1788504123687744
Validation loss: 1.9892942160367966

Epoch: 5| Step: 9
Training loss: 1.9281107187271118
Validation loss: 1.9560415248076122

Epoch: 5| Step: 10
Training loss: 0.9658190011978149
Validation loss: 1.9388369868199031

Epoch: 5| Step: 11
Training loss: 0.31690216064453125
Validation loss: 1.9376919716596603

Epoch: 128| Step: 0
Training loss: 1.718693494796753
Validation loss: 1.9528245677550633

Epoch: 5| Step: 1
Training loss: 1.4430906772613525
Validation loss: 1.9654041479031246

Epoch: 5| Step: 2
Training loss: 1.28122079372406
Validation loss: 1.9699664413928986

Epoch: 5| Step: 3
Training loss: 1.0915733575820923
Validation loss: 1.9621233989795048

Epoch: 5| Step: 4
Training loss: 1.2293285131454468
Validation loss: 1.937379742662112

Epoch: 5| Step: 5
Training loss: 1.429328203201294
Validation loss: 1.9430902649958928

Epoch: 5| Step: 6
Training loss: 1.1401655673980713
Validation loss: 1.9900734424591064

Epoch: 5| Step: 7
Training loss: 1.308743953704834
Validation loss: 2.020611842473348

Epoch: 5| Step: 8
Training loss: 1.3361073732376099
Validation loss: 2.0540738652149835

Epoch: 5| Step: 9
Training loss: 1.3104641437530518
Validation loss: 2.0345699042081833

Epoch: 5| Step: 10
Training loss: 1.6001564264297485
Validation loss: 2.0206743578116098

Epoch: 5| Step: 11
Training loss: 2.1226110458374023
Validation loss: 1.9692050864299138

Epoch: 129| Step: 0
Training loss: 0.9738378524780273
Validation loss: 1.9601026326417923

Epoch: 5| Step: 1
Training loss: 1.4285038709640503
Validation loss: 1.9411713033914566

Epoch: 5| Step: 2
Training loss: 2.065443515777588
Validation loss: 1.971585750579834

Epoch: 5| Step: 3
Training loss: 1.639501929283142
Validation loss: 1.933513621489207

Epoch: 5| Step: 4
Training loss: 1.502608299255371
Validation loss: 2.0006274580955505

Epoch: 5| Step: 5
Training loss: 1.0717097520828247
Validation loss: 1.9677271395921707

Epoch: 5| Step: 6
Training loss: 1.1560999155044556
Validation loss: 1.9553323487440746

Epoch: 5| Step: 7
Training loss: 1.1507391929626465
Validation loss: 1.924340878923734

Epoch: 5| Step: 8
Training loss: 1.0691450834274292
Validation loss: 1.9594225784142811

Epoch: 5| Step: 9
Training loss: 2.041097640991211
Validation loss: 1.9849853714307149

Epoch: 5| Step: 10
Training loss: 1.2794545888900757
Validation loss: 2.0153015653292337

Epoch: 5| Step: 11
Training loss: 0.8707383871078491
Validation loss: 1.994603266318639

Epoch: 130| Step: 0
Training loss: 1.789219856262207
Validation loss: 1.974946916103363

Epoch: 5| Step: 1
Training loss: 0.8764222860336304
Validation loss: 1.904527594645818

Epoch: 5| Step: 2
Training loss: 0.7859134078025818
Validation loss: 1.9348292797803879

Epoch: 5| Step: 3
Training loss: 1.2806633710861206
Validation loss: 1.9411955525477727

Epoch: 5| Step: 4
Training loss: 1.4345289468765259
Validation loss: 1.909065509835879

Epoch: 5| Step: 5
Training loss: 1.6950485706329346
Validation loss: 1.918618897596995

Epoch: 5| Step: 6
Training loss: 1.6314849853515625
Validation loss: 1.9407182385524113

Epoch: 5| Step: 7
Training loss: 1.3489644527435303
Validation loss: 1.9329961190621059

Epoch: 5| Step: 8
Training loss: 1.0079799890518188
Validation loss: 1.9819764991601307

Epoch: 5| Step: 9
Training loss: 1.0347156524658203
Validation loss: 1.960043137272199

Epoch: 5| Step: 10
Training loss: 1.6091182231903076
Validation loss: 1.9646293073892593

Epoch: 5| Step: 11
Training loss: 2.1167120933532715
Validation loss: 1.9778296053409576

Epoch: 131| Step: 0
Training loss: 1.0809290409088135
Validation loss: 1.9580497244993846

Epoch: 5| Step: 1
Training loss: 1.1326830387115479
Validation loss: 1.9751614928245544

Epoch: 5| Step: 2
Training loss: 2.0053811073303223
Validation loss: 1.9440927157799404

Epoch: 5| Step: 3
Training loss: 0.9806609153747559
Validation loss: 1.9503206262985866

Epoch: 5| Step: 4
Training loss: 1.253713846206665
Validation loss: 1.9539741973082225

Epoch: 5| Step: 5
Training loss: 1.2972055673599243
Validation loss: 1.964594582716624

Epoch: 5| Step: 6
Training loss: 1.2677186727523804
Validation loss: 1.962579756975174

Epoch: 5| Step: 7
Training loss: 1.3505709171295166
Validation loss: 1.9437020222345989

Epoch: 5| Step: 8
Training loss: 1.1400306224822998
Validation loss: 1.962351679801941

Epoch: 5| Step: 9
Training loss: 0.9852725267410278
Validation loss: 1.9853721410036087

Epoch: 5| Step: 10
Training loss: 1.740352988243103
Validation loss: 1.9588545610507329

Epoch: 5| Step: 11
Training loss: 1.7384986877441406
Validation loss: 1.9938700099786122

Epoch: 132| Step: 0
Training loss: 1.248504877090454
Validation loss: 1.9584725697835286

Epoch: 5| Step: 1
Training loss: 1.2816507816314697
Validation loss: 1.975334922472636

Epoch: 5| Step: 2
Training loss: 0.9570499658584595
Validation loss: 1.9747601946194966

Epoch: 5| Step: 3
Training loss: 0.8936861753463745
Validation loss: 1.932421753803889

Epoch: 5| Step: 4
Training loss: 0.9379221200942993
Validation loss: 1.9818227291107178

Epoch: 5| Step: 5
Training loss: 1.0084511041641235
Validation loss: 1.9486586600542068

Epoch: 5| Step: 6
Training loss: 1.9170385599136353
Validation loss: 1.9827834218740463

Epoch: 5| Step: 7
Training loss: 0.796998143196106
Validation loss: 1.9426028728485107

Epoch: 5| Step: 8
Training loss: 1.779566764831543
Validation loss: 1.9841599663098652

Epoch: 5| Step: 9
Training loss: 1.832759141921997
Validation loss: 1.9389942834774654

Epoch: 5| Step: 10
Training loss: 1.4396811723709106
Validation loss: 1.9788358608881633

Epoch: 5| Step: 11
Training loss: 1.0218240022659302
Validation loss: 1.9880186865727107

Epoch: 133| Step: 0
Training loss: 1.4849956035614014
Validation loss: 1.9484815696875255

Epoch: 5| Step: 1
Training loss: 0.8859632611274719
Validation loss: 1.9909949799378712

Epoch: 5| Step: 2
Training loss: 1.074966549873352
Validation loss: 1.9398840417464573

Epoch: 5| Step: 3
Training loss: 1.7020034790039062
Validation loss: 1.9547404795885086

Epoch: 5| Step: 4
Training loss: 1.41573965549469
Validation loss: 1.9538257817427318

Epoch: 5| Step: 5
Training loss: 1.4783703088760376
Validation loss: 1.9331391255060832

Epoch: 5| Step: 6
Training loss: 1.1665558815002441
Validation loss: 1.9467232376337051

Epoch: 5| Step: 7
Training loss: 1.6842429637908936
Validation loss: 1.9318237503369649

Epoch: 5| Step: 8
Training loss: 0.9643135070800781
Validation loss: 1.9749598503112793

Epoch: 5| Step: 9
Training loss: 0.9715287089347839
Validation loss: 1.973718563715617

Epoch: 5| Step: 10
Training loss: 1.4013361930847168
Validation loss: 1.9722190151611965

Epoch: 5| Step: 11
Training loss: 1.1905152797698975
Validation loss: 1.977659170826276

Epoch: 134| Step: 0
Training loss: 1.0228259563446045
Validation loss: 1.9725333501895268

Epoch: 5| Step: 1
Training loss: 0.8433341979980469
Validation loss: 1.9336820890506108

Epoch: 5| Step: 2
Training loss: 1.3882938623428345
Validation loss: 1.9646550466616948

Epoch: 5| Step: 3
Training loss: 1.090969443321228
Validation loss: 1.9460121740897496

Epoch: 5| Step: 4
Training loss: 1.6805477142333984
Validation loss: 1.9466611196597416

Epoch: 5| Step: 5
Training loss: 1.0999042987823486
Validation loss: 1.9574118554592133

Epoch: 5| Step: 6
Training loss: 1.383157730102539
Validation loss: 1.951731299360593

Epoch: 5| Step: 7
Training loss: 1.0628423690795898
Validation loss: 1.95568252603213

Epoch: 5| Step: 8
Training loss: 1.2542293071746826
Validation loss: 1.9466048528750737

Epoch: 5| Step: 9
Training loss: 1.2576711177825928
Validation loss: 1.9752756903568904

Epoch: 5| Step: 10
Training loss: 1.8425174951553345
Validation loss: 1.966929852962494

Epoch: 5| Step: 11
Training loss: 1.1397571563720703
Validation loss: 1.986423412958781

Epoch: 135| Step: 0
Training loss: 0.9239928126335144
Validation loss: 1.9906455775101979

Epoch: 5| Step: 1
Training loss: 1.755462646484375
Validation loss: 1.9610334932804108

Epoch: 5| Step: 2
Training loss: 1.0935859680175781
Validation loss: 1.9576560258865356

Epoch: 5| Step: 3
Training loss: 1.5819475650787354
Validation loss: 1.9500469714403152

Epoch: 5| Step: 4
Training loss: 1.999789834022522
Validation loss: 1.9666941463947296

Epoch: 5| Step: 5
Training loss: 1.181330680847168
Validation loss: 1.9695490101973216

Epoch: 5| Step: 6
Training loss: 1.2809622287750244
Validation loss: 1.9737583349148433

Epoch: 5| Step: 7
Training loss: 1.2433078289031982
Validation loss: 1.963381787141164

Epoch: 5| Step: 8
Training loss: 1.0727429389953613
Validation loss: 1.9708301027615864

Epoch: 5| Step: 9
Training loss: 0.9384795427322388
Validation loss: 1.9369554768006008

Epoch: 5| Step: 10
Training loss: 1.0277444124221802
Validation loss: 1.9363829443852107

Epoch: 5| Step: 11
Training loss: 0.27921223640441895
Validation loss: 1.9123351524273555

Epoch: 136| Step: 0
Training loss: 1.491721510887146
Validation loss: 1.9426217824220657

Epoch: 5| Step: 1
Training loss: 0.7750200033187866
Validation loss: 2.012291267514229

Epoch: 5| Step: 2
Training loss: 0.9931719899177551
Validation loss: 1.980504314104716

Epoch: 5| Step: 3
Training loss: 1.5783367156982422
Validation loss: 1.9882616599400837

Epoch: 5| Step: 4
Training loss: 1.3698102235794067
Validation loss: 1.9601729263861973

Epoch: 5| Step: 5
Training loss: 1.1468288898468018
Validation loss: 1.95888618628184

Epoch: 5| Step: 6
Training loss: 1.6221287250518799
Validation loss: 1.9749362816413243

Epoch: 5| Step: 7
Training loss: 1.2445363998413086
Validation loss: 1.9427869766950607

Epoch: 5| Step: 8
Training loss: 1.5076014995574951
Validation loss: 1.9926470915476482

Epoch: 5| Step: 9
Training loss: 1.2800750732421875
Validation loss: 1.9673268844683964

Epoch: 5| Step: 10
Training loss: 0.9569829702377319
Validation loss: 1.9684515645106633

Epoch: 5| Step: 11
Training loss: 1.1817799806594849
Validation loss: 1.9914001127084096

Epoch: 137| Step: 0
Training loss: 0.8189682960510254
Validation loss: 1.996833657224973

Epoch: 5| Step: 1
Training loss: 0.9701215624809265
Validation loss: 1.9786613037188847

Epoch: 5| Step: 2
Training loss: 1.2739337682724
Validation loss: 1.917837416132291

Epoch: 5| Step: 3
Training loss: 1.247352957725525
Validation loss: 1.9708885153134663

Epoch: 5| Step: 4
Training loss: 1.8484045267105103
Validation loss: 1.9480176270008087

Epoch: 5| Step: 5
Training loss: 1.0086549520492554
Validation loss: 1.9207667410373688

Epoch: 5| Step: 6
Training loss: 1.6658108234405518
Validation loss: 1.94159430762132

Epoch: 5| Step: 7
Training loss: 1.202719807624817
Validation loss: 1.9693187077840169

Epoch: 5| Step: 8
Training loss: 1.1951696872711182
Validation loss: 1.9478728423515956

Epoch: 5| Step: 9
Training loss: 1.3217432498931885
Validation loss: 1.9595464169979095

Epoch: 5| Step: 10
Training loss: 1.1871552467346191
Validation loss: 1.9541139751672745

Epoch: 5| Step: 11
Training loss: 2.106832981109619
Validation loss: 2.0020976016918817

Epoch: 138| Step: 0
Training loss: 1.0363962650299072
Validation loss: 1.9744852433602016

Epoch: 5| Step: 1
Training loss: 1.8352644443511963
Validation loss: 1.9825567702452342

Epoch: 5| Step: 2
Training loss: 1.3934274911880493
Validation loss: 1.9888175527254741

Epoch: 5| Step: 3
Training loss: 0.7988227009773254
Validation loss: 1.9621502260367076

Epoch: 5| Step: 4
Training loss: 1.0941734313964844
Validation loss: 1.9323178629080455

Epoch: 5| Step: 5
Training loss: 1.2607301473617554
Validation loss: 1.9548249592383702

Epoch: 5| Step: 6
Training loss: 1.4983155727386475
Validation loss: 1.9639752904574077

Epoch: 5| Step: 7
Training loss: 1.0124396085739136
Validation loss: 1.9743615438540776

Epoch: 5| Step: 8
Training loss: 1.2717536687850952
Validation loss: 1.9398565938075383

Epoch: 5| Step: 9
Training loss: 1.180219292640686
Validation loss: 1.935535192489624

Epoch: 5| Step: 10
Training loss: 1.4740605354309082
Validation loss: 1.9380290806293488

Epoch: 5| Step: 11
Training loss: 1.9385179281234741
Validation loss: 1.9520190507173538

Epoch: 139| Step: 0
Training loss: 1.391601800918579
Validation loss: 1.9868524968624115

Epoch: 5| Step: 1
Training loss: 1.0248496532440186
Validation loss: 1.9813822110493977

Epoch: 5| Step: 2
Training loss: 1.1337693929672241
Validation loss: 1.9784091611703236

Epoch: 5| Step: 3
Training loss: 1.1581552028656006
Validation loss: 1.9950258086125057

Epoch: 5| Step: 4
Training loss: 1.6429555416107178
Validation loss: 1.9707067012786865

Epoch: 5| Step: 5
Training loss: 1.5380020141601562
Validation loss: 1.9608331869045894

Epoch: 5| Step: 6
Training loss: 1.1509406566619873
Validation loss: 1.9267203758160274

Epoch: 5| Step: 7
Training loss: 1.2204560041427612
Validation loss: 1.9678062746922176

Epoch: 5| Step: 8
Training loss: 1.3188483715057373
Validation loss: 1.9631530245145161

Epoch: 5| Step: 9
Training loss: 1.2983198165893555
Validation loss: 1.9503744890292485

Epoch: 5| Step: 10
Training loss: 0.9743559956550598
Validation loss: 1.9431538383165996

Epoch: 5| Step: 11
Training loss: 1.3227429389953613
Validation loss: 1.9765080561240513

Epoch: 140| Step: 0
Training loss: 1.0966672897338867
Validation loss: 1.9955577900012333

Epoch: 5| Step: 1
Training loss: 1.1914173364639282
Validation loss: 1.966152881582578

Epoch: 5| Step: 2
Training loss: 0.9585210680961609
Validation loss: 1.9826981127262115

Epoch: 5| Step: 3
Training loss: 1.578244924545288
Validation loss: 1.9814778168996174

Epoch: 5| Step: 4
Training loss: 1.7069114446640015
Validation loss: 1.9802356660366058

Epoch: 5| Step: 5
Training loss: 1.5971362590789795
Validation loss: 1.974742626150449

Epoch: 5| Step: 6
Training loss: 1.81259286403656
Validation loss: 1.9474118053913116

Epoch: 5| Step: 7
Training loss: 0.9300500750541687
Validation loss: 1.9767897973457973

Epoch: 5| Step: 8
Training loss: 0.6438518762588501
Validation loss: 1.9396500488122304

Epoch: 5| Step: 9
Training loss: 1.154265284538269
Validation loss: 1.9836959342161815

Epoch: 5| Step: 10
Training loss: 1.1762241125106812
Validation loss: 1.9536538422107697

Epoch: 5| Step: 11
Training loss: 0.7584584355354309
Validation loss: 1.9630086024602253

Epoch: 141| Step: 0
Training loss: 0.8662933111190796
Validation loss: 1.9667497326930363

Epoch: 5| Step: 1
Training loss: 1.5963107347488403
Validation loss: 1.984095533688863

Epoch: 5| Step: 2
Training loss: 1.7156072854995728
Validation loss: 1.957325870792071

Epoch: 5| Step: 3
Training loss: 1.349501132965088
Validation loss: 1.9276680847009022

Epoch: 5| Step: 4
Training loss: 1.328044056892395
Validation loss: 1.942758580048879

Epoch: 5| Step: 5
Training loss: 1.2296849489212036
Validation loss: 1.9498425374428432

Epoch: 5| Step: 6
Training loss: 1.1444361209869385
Validation loss: 1.9324562946955364

Epoch: 5| Step: 7
Training loss: 1.0742316246032715
Validation loss: 1.9537073224782944

Epoch: 5| Step: 8
Training loss: 0.7407959699630737
Validation loss: 1.9451766808827717

Epoch: 5| Step: 9
Training loss: 1.0440224409103394
Validation loss: 1.9521057655413945

Epoch: 5| Step: 10
Training loss: 1.1327705383300781
Validation loss: 1.9414928754170735

Epoch: 5| Step: 11
Training loss: 1.8100626468658447
Validation loss: 1.9857635200023651

Epoch: 142| Step: 0
Training loss: 1.123716115951538
Validation loss: 1.9649321188529332

Epoch: 5| Step: 1
Training loss: 1.3801485300064087
Validation loss: 1.9646612753470738

Epoch: 5| Step: 2
Training loss: 1.5541770458221436
Validation loss: 1.9468107620875041

Epoch: 5| Step: 3
Training loss: 0.9350997805595398
Validation loss: 1.9332759082317352

Epoch: 5| Step: 4
Training loss: 1.2506062984466553
Validation loss: 1.966151754061381

Epoch: 5| Step: 5
Training loss: 1.2572964429855347
Validation loss: 1.943771670262019

Epoch: 5| Step: 6
Training loss: 1.0219814777374268
Validation loss: 1.9565592408180237

Epoch: 5| Step: 7
Training loss: 1.295638084411621
Validation loss: 1.947349637746811

Epoch: 5| Step: 8
Training loss: 1.4154949188232422
Validation loss: 1.953447123368581

Epoch: 5| Step: 9
Training loss: 0.7361751794815063
Validation loss: 1.9149911055962245

Epoch: 5| Step: 10
Training loss: 1.1982487440109253
Validation loss: 1.972341924905777

Epoch: 5| Step: 11
Training loss: 2.8365097045898438
Validation loss: 1.9830036063989003

Epoch: 143| Step: 0
Training loss: 1.3094924688339233
Validation loss: 1.9601719081401825

Epoch: 5| Step: 1
Training loss: 1.7008787393569946
Validation loss: 1.9395023783047993

Epoch: 5| Step: 2
Training loss: 1.1492981910705566
Validation loss: 1.9889330963293712

Epoch: 5| Step: 3
Training loss: 1.0438110828399658
Validation loss: 1.9090267270803452

Epoch: 5| Step: 4
Training loss: 1.2284590005874634
Validation loss: 1.9719190845886867

Epoch: 5| Step: 5
Training loss: 1.453338861465454
Validation loss: 1.9489246755838394

Epoch: 5| Step: 6
Training loss: 1.4068844318389893
Validation loss: 1.933504934112231

Epoch: 5| Step: 7
Training loss: 1.320749044418335
Validation loss: 1.9720451732476552

Epoch: 5| Step: 8
Training loss: 1.0692352056503296
Validation loss: 1.9284268021583557

Epoch: 5| Step: 9
Training loss: 0.9303202629089355
Validation loss: 1.947206199169159

Epoch: 5| Step: 10
Training loss: 1.0755329132080078
Validation loss: 1.9879333823919296

Epoch: 5| Step: 11
Training loss: 0.5182756185531616
Validation loss: 1.9353160659472148

Epoch: 144| Step: 0
Training loss: 1.2840007543563843
Validation loss: 1.9260854075352352

Epoch: 5| Step: 1
Training loss: 1.587564468383789
Validation loss: 1.9604458510875702

Epoch: 5| Step: 2
Training loss: 1.296871304512024
Validation loss: 1.9594830125570297

Epoch: 5| Step: 3
Training loss: 1.1880958080291748
Validation loss: 1.9422708650430043

Epoch: 5| Step: 4
Training loss: 1.0225636959075928
Validation loss: 1.947051227092743

Epoch: 5| Step: 5
Training loss: 1.4108023643493652
Validation loss: 1.9557172457377117

Epoch: 5| Step: 6
Training loss: 1.4212502241134644
Validation loss: 1.92740402619044

Epoch: 5| Step: 7
Training loss: 0.8465266227722168
Validation loss: 1.9386895050605137

Epoch: 5| Step: 8
Training loss: 1.440344214439392
Validation loss: 1.9611455301443736

Epoch: 5| Step: 9
Training loss: 1.092883825302124
Validation loss: 1.989347790678342

Epoch: 5| Step: 10
Training loss: 0.8663715124130249
Validation loss: 1.9923424224058788

Epoch: 5| Step: 11
Training loss: 2.841282367706299
Validation loss: 1.9772483458121617

Epoch: 145| Step: 0
Training loss: 1.976422905921936
Validation loss: 1.9720318913459778

Epoch: 5| Step: 1
Training loss: 1.0107465982437134
Validation loss: 1.9485111435254414

Epoch: 5| Step: 2
Training loss: 1.4742650985717773
Validation loss: 1.923355718453725

Epoch: 5| Step: 3
Training loss: 1.566210389137268
Validation loss: 1.9287345657745998

Epoch: 5| Step: 4
Training loss: 1.328023910522461
Validation loss: 1.9444241722424824

Epoch: 5| Step: 5
Training loss: 0.8547737002372742
Validation loss: 1.9533843646446865

Epoch: 5| Step: 6
Training loss: 0.8262554407119751
Validation loss: 1.9245684891939163

Epoch: 5| Step: 7
Training loss: 1.093518614768982
Validation loss: 1.9408656905094783

Epoch: 5| Step: 8
Training loss: 1.4884512424468994
Validation loss: 1.9886051466067631

Epoch: 5| Step: 9
Training loss: 1.103705644607544
Validation loss: 1.9618585954109828

Epoch: 5| Step: 10
Training loss: 0.7026119828224182
Validation loss: 1.9894999315341313

Epoch: 5| Step: 11
Training loss: 1.1423108577728271
Validation loss: 1.986890623966853

Epoch: 146| Step: 0
Training loss: 1.175447940826416
Validation loss: 1.9802695562442143

Epoch: 5| Step: 1
Training loss: 1.3346989154815674
Validation loss: 1.9530381113290787

Epoch: 5| Step: 2
Training loss: 1.282102108001709
Validation loss: 1.9526922504107158

Epoch: 5| Step: 3
Training loss: 1.1651246547698975
Validation loss: 1.9479835977156956

Epoch: 5| Step: 4
Training loss: 1.0215331315994263
Validation loss: 1.9588945756355922

Epoch: 5| Step: 5
Training loss: 1.1919851303100586
Validation loss: 1.9580790499846141

Epoch: 5| Step: 6
Training loss: 0.7256730198860168
Validation loss: 1.928550238410632

Epoch: 5| Step: 7
Training loss: 1.2891802787780762
Validation loss: 1.9832482139269512

Epoch: 5| Step: 8
Training loss: 1.1173381805419922
Validation loss: 1.9388021926085155

Epoch: 5| Step: 9
Training loss: 1.4263520240783691
Validation loss: 1.9520730276902516

Epoch: 5| Step: 10
Training loss: 1.192947506904602
Validation loss: 1.946928362051646

Epoch: 5| Step: 11
Training loss: 2.3635635375976562
Validation loss: 1.9220743079980214

Epoch: 147| Step: 0
Training loss: 1.2754970788955688
Validation loss: 1.9605028728644054

Epoch: 5| Step: 1
Training loss: 1.7847992181777954
Validation loss: 1.9643858671188354

Epoch: 5| Step: 2
Training loss: 1.092357873916626
Validation loss: 1.9528078536192577

Epoch: 5| Step: 3
Training loss: 1.3193702697753906
Validation loss: 1.928573747475942

Epoch: 5| Step: 4
Training loss: 1.3440053462982178
Validation loss: 1.9489582379659016

Epoch: 5| Step: 5
Training loss: 1.076040506362915
Validation loss: 1.92204183836778

Epoch: 5| Step: 6
Training loss: 1.0103868246078491
Validation loss: 1.9591854910055797

Epoch: 5| Step: 7
Training loss: 1.2773017883300781
Validation loss: 1.9718222518761952

Epoch: 5| Step: 8
Training loss: 1.031937599182129
Validation loss: 1.987745891014735

Epoch: 5| Step: 9
Training loss: 0.9392404556274414
Validation loss: 1.980494702855746

Epoch: 5| Step: 10
Training loss: 1.1892235279083252
Validation loss: 1.952779750029246

Epoch: 5| Step: 11
Training loss: 0.4330892562866211
Validation loss: 1.9468724479277928

Epoch: 148| Step: 0
Training loss: 0.7976921796798706
Validation loss: 1.9800074646870296

Epoch: 5| Step: 1
Training loss: 1.0677868127822876
Validation loss: 1.9731363107760747

Epoch: 5| Step: 2
Training loss: 1.4059417247772217
Validation loss: 1.9636584768692653

Epoch: 5| Step: 3
Training loss: 0.36608225107192993
Validation loss: 1.959450677037239

Epoch: 5| Step: 4
Training loss: 1.5169601440429688
Validation loss: 1.9680283615986507

Epoch: 5| Step: 5
Training loss: 1.2751648426055908
Validation loss: 1.9303325861692429

Epoch: 5| Step: 6
Training loss: 0.7731124758720398
Validation loss: 1.9421810805797577

Epoch: 5| Step: 7
Training loss: 1.3141604661941528
Validation loss: 1.9329524636268616

Epoch: 5| Step: 8
Training loss: 0.7085459232330322
Validation loss: 1.983604942758878

Epoch: 5| Step: 9
Training loss: 1.6294233798980713
Validation loss: 1.9633204142252605

Epoch: 5| Step: 10
Training loss: 1.4966284036636353
Validation loss: 1.982375979423523

Epoch: 5| Step: 11
Training loss: 1.8997693061828613
Validation loss: 1.9596597254276276

Epoch: 149| Step: 0
Training loss: 0.9525438547134399
Validation loss: 1.9691308190425236

Epoch: 5| Step: 1
Training loss: 0.6622840762138367
Validation loss: 1.9449611455202103

Epoch: 5| Step: 2
Training loss: 0.8590987920761108
Validation loss: 1.9581912159919739

Epoch: 5| Step: 3
Training loss: 1.413941740989685
Validation loss: 1.9531140675147374

Epoch: 5| Step: 4
Training loss: 0.8202667236328125
Validation loss: 1.9424393673737843

Epoch: 5| Step: 5
Training loss: 1.659706473350525
Validation loss: 2.002578670779864

Epoch: 5| Step: 6
Training loss: 1.135083794593811
Validation loss: 1.9464640965064366

Epoch: 5| Step: 7
Training loss: 1.2266433238983154
Validation loss: 1.993233437339465

Epoch: 5| Step: 8
Training loss: 1.0210397243499756
Validation loss: 1.994567945599556

Epoch: 5| Step: 9
Training loss: 1.2620443105697632
Validation loss: 1.9781794995069504

Epoch: 5| Step: 10
Training loss: 1.4705760478973389
Validation loss: 1.9718777537345886

Epoch: 5| Step: 11
Training loss: 1.386723279953003
Validation loss: 2.011523683865865

Epoch: 150| Step: 0
Training loss: 0.9024661779403687
Validation loss: 1.9705172975858052

Epoch: 5| Step: 1
Training loss: 1.084591031074524
Validation loss: 1.9825826187928517

Epoch: 5| Step: 2
Training loss: 1.050180196762085
Validation loss: 1.9517642855644226

Epoch: 5| Step: 3
Training loss: 1.4896496534347534
Validation loss: 1.996069113413493

Epoch: 5| Step: 4
Training loss: 1.385413408279419
Validation loss: 1.999854937195778

Epoch: 5| Step: 5
Training loss: 1.6957868337631226
Validation loss: 1.9703776786724727

Epoch: 5| Step: 6
Training loss: 0.9836803674697876
Validation loss: 1.935769036412239

Epoch: 5| Step: 7
Training loss: 1.080127477645874
Validation loss: 1.9489022940397263

Epoch: 5| Step: 8
Training loss: 0.65704345703125
Validation loss: 1.962547351916631

Epoch: 5| Step: 9
Training loss: 1.1963818073272705
Validation loss: 1.9729639043410618

Epoch: 5| Step: 10
Training loss: 1.098520278930664
Validation loss: 1.9583404660224915

Epoch: 5| Step: 11
Training loss: 0.680268406867981
Validation loss: 2.008782376845678

Epoch: 151| Step: 0
Training loss: 1.148447036743164
Validation loss: 1.9507117122411728

Epoch: 5| Step: 1
Training loss: 1.3383855819702148
Validation loss: 1.950053185224533

Epoch: 5| Step: 2
Training loss: 1.0847853422164917
Validation loss: 1.9678284724553425

Epoch: 5| Step: 3
Training loss: 0.7792209386825562
Validation loss: 1.9986251890659332

Epoch: 5| Step: 4
Training loss: 1.1360523700714111
Validation loss: 1.9608993728955586

Epoch: 5| Step: 5
Training loss: 0.9629116058349609
Validation loss: 1.9607993066310883

Epoch: 5| Step: 6
Training loss: 1.1956987380981445
Validation loss: 1.9377489735682805

Epoch: 5| Step: 7
Training loss: 2.0215003490448
Validation loss: 1.9556719362735748

Epoch: 5| Step: 8
Training loss: 1.4743036031723022
Validation loss: 1.9660085688034694

Epoch: 5| Step: 9
Training loss: 0.8714375495910645
Validation loss: 1.9513938675324123

Epoch: 5| Step: 10
Training loss: 0.9165078401565552
Validation loss: 1.9794016530116398

Epoch: 5| Step: 11
Training loss: 0.9005204439163208
Validation loss: 1.9241512815157573

Epoch: 152| Step: 0
Training loss: 1.1966559886932373
Validation loss: 1.9927489558855693

Epoch: 5| Step: 1
Training loss: 1.3680939674377441
Validation loss: 2.0513824969530106

Epoch: 5| Step: 2
Training loss: 1.1628661155700684
Validation loss: 2.0107296307881675

Epoch: 5| Step: 3
Training loss: 0.9476356506347656
Validation loss: 2.0158301293849945

Epoch: 5| Step: 4
Training loss: 1.1449754238128662
Validation loss: 1.993975932399432

Epoch: 5| Step: 5
Training loss: 0.8070691823959351
Validation loss: 1.974686250090599

Epoch: 5| Step: 6
Training loss: 1.4933171272277832
Validation loss: 1.9138314922650654

Epoch: 5| Step: 7
Training loss: 1.0704195499420166
Validation loss: 1.9515228271484375

Epoch: 5| Step: 8
Training loss: 1.1350969076156616
Validation loss: 1.9717469960451126

Epoch: 5| Step: 9
Training loss: 1.3537839651107788
Validation loss: 1.9700107276439667

Epoch: 5| Step: 10
Training loss: 1.8643213510513306
Validation loss: 1.9252791007359822

Epoch: 5| Step: 11
Training loss: 1.1128814220428467
Validation loss: 1.9294732461373012

Epoch: 153| Step: 0
Training loss: 0.8944498896598816
Validation loss: 1.954980154832204

Epoch: 5| Step: 1
Training loss: 1.064927101135254
Validation loss: 1.9507405559221904

Epoch: 5| Step: 2
Training loss: 1.024095892906189
Validation loss: 1.9573238343000412

Epoch: 5| Step: 3
Training loss: 1.2440235614776611
Validation loss: 1.961706668138504

Epoch: 5| Step: 4
Training loss: 0.6121547818183899
Validation loss: 1.9348824322223663

Epoch: 5| Step: 5
Training loss: 1.5868228673934937
Validation loss: 1.9419639557600021

Epoch: 5| Step: 6
Training loss: 0.8211193084716797
Validation loss: 1.9738709578911464

Epoch: 5| Step: 7
Training loss: 1.238266110420227
Validation loss: 1.9427290707826614

Epoch: 5| Step: 8
Training loss: 1.5236080884933472
Validation loss: 1.9230553259452183

Epoch: 5| Step: 9
Training loss: 1.1038130521774292
Validation loss: 1.9466103861729305

Epoch: 5| Step: 10
Training loss: 1.0206578969955444
Validation loss: 1.9511325508356094

Epoch: 5| Step: 11
Training loss: 2.545341968536377
Validation loss: 1.9334317247072856

Epoch: 154| Step: 0
Training loss: 1.1084619760513306
Validation loss: 1.9273517280817032

Epoch: 5| Step: 1
Training loss: 0.8896695971488953
Validation loss: 1.970749869942665

Epoch: 5| Step: 2
Training loss: 0.5677579641342163
Validation loss: 1.9688256432612736

Epoch: 5| Step: 3
Training loss: 0.8773223757743835
Validation loss: 1.9695395578940709

Epoch: 5| Step: 4
Training loss: 1.7522342205047607
Validation loss: 1.9646886438131332

Epoch: 5| Step: 5
Training loss: 1.6057484149932861
Validation loss: 1.9717115312814713

Epoch: 5| Step: 6
Training loss: 1.3905317783355713
Validation loss: 1.9510753105084102

Epoch: 5| Step: 7
Training loss: 0.8236051797866821
Validation loss: 1.9714890867471695

Epoch: 5| Step: 8
Training loss: 1.3922617435455322
Validation loss: 1.9532518833875656

Epoch: 5| Step: 9
Training loss: 1.1662594079971313
Validation loss: 2.0086155186096826

Epoch: 5| Step: 10
Training loss: 0.9350698590278625
Validation loss: 1.962244600057602

Epoch: 5| Step: 11
Training loss: 0.9700863361358643
Validation loss: 2.0030125180880227

Epoch: 155| Step: 0
Training loss: 1.2006723880767822
Validation loss: 1.982236663500468

Epoch: 5| Step: 1
Training loss: 0.9607508778572083
Validation loss: 1.9694083233674367

Epoch: 5| Step: 2
Training loss: 1.1884931325912476
Validation loss: 1.9801816493272781

Epoch: 5| Step: 3
Training loss: 1.2371103763580322
Validation loss: 1.9516998877127965

Epoch: 5| Step: 4
Training loss: 1.1686546802520752
Validation loss: 1.978371039032936

Epoch: 5| Step: 5
Training loss: 0.99864661693573
Validation loss: 1.9584499150514603

Epoch: 5| Step: 6
Training loss: 0.7528630495071411
Validation loss: 1.9940517445405324

Epoch: 5| Step: 7
Training loss: 1.6534888744354248
Validation loss: 1.9565915912389755

Epoch: 5| Step: 8
Training loss: 1.1144620180130005
Validation loss: 1.9475950648387272

Epoch: 5| Step: 9
Training loss: 0.776645839214325
Validation loss: 1.9717041651407878

Epoch: 5| Step: 10
Training loss: 1.0983073711395264
Validation loss: 1.975259706377983

Epoch: 5| Step: 11
Training loss: 1.8031508922576904
Validation loss: 1.9391334454218547

Epoch: 156| Step: 0
Training loss: 1.0879080295562744
Validation loss: 1.956767499446869

Epoch: 5| Step: 1
Training loss: 1.1009197235107422
Validation loss: 1.986190398534139

Epoch: 5| Step: 2
Training loss: 0.9920543432235718
Validation loss: 1.91649995247523

Epoch: 5| Step: 3
Training loss: 1.103272557258606
Validation loss: 1.9596276034911473

Epoch: 5| Step: 4
Training loss: 0.7515375018119812
Validation loss: 1.943971872329712

Epoch: 5| Step: 5
Training loss: 1.7587320804595947
Validation loss: 1.9370613545179367

Epoch: 5| Step: 6
Training loss: 0.8780094385147095
Validation loss: 1.9659291009108226

Epoch: 5| Step: 7
Training loss: 1.1818313598632812
Validation loss: 1.9436382055282593

Epoch: 5| Step: 8
Training loss: 0.8781211972236633
Validation loss: 1.941281537214915

Epoch: 5| Step: 9
Training loss: 0.9152238965034485
Validation loss: 1.970461755990982

Epoch: 5| Step: 10
Training loss: 1.3732645511627197
Validation loss: 1.9879182279109955

Epoch: 5| Step: 11
Training loss: 1.890044927597046
Validation loss: 1.9794395168622334

Epoch: 157| Step: 0
Training loss: 1.3440929651260376
Validation loss: 2.0056275775035224

Epoch: 5| Step: 1
Training loss: 1.3928381204605103
Validation loss: 1.9871175736188889

Epoch: 5| Step: 2
Training loss: 1.1251322031021118
Validation loss: 1.9963089376688004

Epoch: 5| Step: 3
Training loss: 1.1763770580291748
Validation loss: 1.9605569690465927

Epoch: 5| Step: 4
Training loss: 0.7354971170425415
Validation loss: 1.9616850465536118

Epoch: 5| Step: 5
Training loss: 0.7676953673362732
Validation loss: 2.01523723701636

Epoch: 5| Step: 6
Training loss: 0.9920751452445984
Validation loss: 1.9714024464289348

Epoch: 5| Step: 7
Training loss: 0.9487469792366028
Validation loss: 1.9795624762773514

Epoch: 5| Step: 8
Training loss: 1.2386926412582397
Validation loss: 2.0271892150243125

Epoch: 5| Step: 9
Training loss: 0.8575625419616699
Validation loss: 2.0188174545764923

Epoch: 5| Step: 10
Training loss: 1.307881236076355
Validation loss: 1.9708753277858098

Epoch: 5| Step: 11
Training loss: 1.0797677040100098
Validation loss: 1.9661006728808086

Epoch: 158| Step: 0
Training loss: 1.5899016857147217
Validation loss: 1.975830947359403

Epoch: 5| Step: 1
Training loss: 1.0706027746200562
Validation loss: 1.9723212073246639

Epoch: 5| Step: 2
Training loss: 0.7883130311965942
Validation loss: 1.9874085436264675

Epoch: 5| Step: 3
Training loss: 1.3392670154571533
Validation loss: 2.006369099020958

Epoch: 5| Step: 4
Training loss: 0.9619641304016113
Validation loss: 1.982893670598666

Epoch: 5| Step: 5
Training loss: 0.871782124042511
Validation loss: 1.9496713827053707

Epoch: 5| Step: 6
Training loss: 1.1710164546966553
Validation loss: 2.002448618412018

Epoch: 5| Step: 7
Training loss: 1.1119332313537598
Validation loss: 1.9861725022395451

Epoch: 5| Step: 8
Training loss: 0.46018362045288086
Validation loss: 1.9665820548931758

Epoch: 5| Step: 9
Training loss: 1.0222200155258179
Validation loss: 2.0006870726744332

Epoch: 5| Step: 10
Training loss: 1.6336416006088257
Validation loss: 1.9435151020685832

Epoch: 5| Step: 11
Training loss: 1.1283644437789917
Validation loss: 2.01407157878081

Epoch: 159| Step: 0
Training loss: 0.8361721038818359
Validation loss: 2.0076517860094705

Epoch: 5| Step: 1
Training loss: 1.2492144107818604
Validation loss: 1.9653263986110687

Epoch: 5| Step: 2
Training loss: 0.7381277680397034
Validation loss: 1.9655582904815674

Epoch: 5| Step: 3
Training loss: 1.0723901987075806
Validation loss: 1.9327524999777477

Epoch: 5| Step: 4
Training loss: 1.4911115169525146
Validation loss: 1.98233100771904

Epoch: 5| Step: 5
Training loss: 1.2922189235687256
Validation loss: 1.9658509095509846

Epoch: 5| Step: 6
Training loss: 1.0151960849761963
Validation loss: 1.9938929130633671

Epoch: 5| Step: 7
Training loss: 0.6530247926712036
Validation loss: 1.9562408576409023

Epoch: 5| Step: 8
Training loss: 1.436536431312561
Validation loss: 1.9508945097525914

Epoch: 5| Step: 9
Training loss: 1.116822600364685
Validation loss: 1.9453636407852173

Epoch: 5| Step: 10
Training loss: 1.2659540176391602
Validation loss: 1.9753984262545903

Epoch: 5| Step: 11
Training loss: 0.13748878240585327
Validation loss: 1.9878914405902226

Epoch: 160| Step: 0
Training loss: 1.0245214700698853
Validation loss: 1.9749445865551631

Epoch: 5| Step: 1
Training loss: 1.5956811904907227
Validation loss: 1.941925639907519

Epoch: 5| Step: 2
Training loss: 1.144787311553955
Validation loss: 1.9594422777493794

Epoch: 5| Step: 3
Training loss: 1.0067218542099
Validation loss: 1.9622741788625717

Epoch: 5| Step: 4
Training loss: 1.094082236289978
Validation loss: 1.9823153913021088

Epoch: 5| Step: 5
Training loss: 0.6116243600845337
Validation loss: 1.9788767049709957

Epoch: 5| Step: 6
Training loss: 1.471090316772461
Validation loss: 1.9819502731164296

Epoch: 5| Step: 7
Training loss: 1.12168288230896
Validation loss: 1.9766732603311539

Epoch: 5| Step: 8
Training loss: 0.8644460439682007
Validation loss: 2.0140191117922464

Epoch: 5| Step: 9
Training loss: 0.9599115252494812
Validation loss: 2.0288534512122474

Epoch: 5| Step: 10
Training loss: 1.0156893730163574
Validation loss: 2.020172486702601

Epoch: 5| Step: 11
Training loss: 1.3632075786590576
Validation loss: 1.9849204868078232

Epoch: 161| Step: 0
Training loss: 1.3646153211593628
Validation loss: 1.9990214407444

Epoch: 5| Step: 1
Training loss: 0.8515630960464478
Validation loss: 2.0011454423268638

Epoch: 5| Step: 2
Training loss: 1.199359655380249
Validation loss: 1.963907261689504

Epoch: 5| Step: 3
Training loss: 0.9800575375556946
Validation loss: 1.9680002083381016

Epoch: 5| Step: 4
Training loss: 1.4375418424606323
Validation loss: 1.9770538359880447

Epoch: 5| Step: 5
Training loss: 1.0665881633758545
Validation loss: 2.001053363084793

Epoch: 5| Step: 6
Training loss: 0.5170531868934631
Validation loss: 1.9811342259248097

Epoch: 5| Step: 7
Training loss: 1.1861006021499634
Validation loss: 1.98892180621624

Epoch: 5| Step: 8
Training loss: 1.2658336162567139
Validation loss: 1.9988114088773727

Epoch: 5| Step: 9
Training loss: 0.9990261197090149
Validation loss: 1.993189995487531

Epoch: 5| Step: 10
Training loss: 1.2566494941711426
Validation loss: 1.957363948225975

Epoch: 5| Step: 11
Training loss: 0.32436603307724
Validation loss: 1.9724428951740265

Epoch: 162| Step: 0
Training loss: 1.121163010597229
Validation loss: 1.9778764843940735

Epoch: 5| Step: 1
Training loss: 1.0011801719665527
Validation loss: 1.9513392200072606

Epoch: 5| Step: 2
Training loss: 0.8251171112060547
Validation loss: 2.0009506990512214

Epoch: 5| Step: 3
Training loss: 1.6314204931259155
Validation loss: 1.9829382201035817

Epoch: 5| Step: 4
Training loss: 1.574150562286377
Validation loss: 1.9588958323001862

Epoch: 5| Step: 5
Training loss: 0.7751756906509399
Validation loss: 1.9888306707143784

Epoch: 5| Step: 6
Training loss: 1.375377893447876
Validation loss: 1.971162959933281

Epoch: 5| Step: 7
Training loss: 0.3980361819267273
Validation loss: 1.9606961955626805

Epoch: 5| Step: 8
Training loss: 0.847942054271698
Validation loss: 1.9616923133532207

Epoch: 5| Step: 9
Training loss: 1.589424967765808
Validation loss: 1.9914570301771164

Epoch: 5| Step: 10
Training loss: 0.5582975149154663
Validation loss: 1.968732511003812

Epoch: 5| Step: 11
Training loss: 1.3148986101150513
Validation loss: 1.9973115473985672

Epoch: 163| Step: 0
Training loss: 1.4500178098678589
Validation loss: 1.9836845993995667

Epoch: 5| Step: 1
Training loss: 1.1743980646133423
Validation loss: 1.9786439438660939

Epoch: 5| Step: 2
Training loss: 1.1423513889312744
Validation loss: 2.0001263419787088

Epoch: 5| Step: 3
Training loss: 1.2013981342315674
Validation loss: 1.9811206062634785

Epoch: 5| Step: 4
Training loss: 0.9793710708618164
Validation loss: 1.975276341040929

Epoch: 5| Step: 5
Training loss: 1.1986359357833862
Validation loss: 1.9905805836121242

Epoch: 5| Step: 6
Training loss: 1.0765535831451416
Validation loss: 1.9992973357439041

Epoch: 5| Step: 7
Training loss: 1.0821168422698975
Validation loss: 1.9738958080609639

Epoch: 5| Step: 8
Training loss: 0.8557069897651672
Validation loss: 2.01068085928758

Epoch: 5| Step: 9
Training loss: 0.5409058332443237
Validation loss: 1.9999954501787822

Epoch: 5| Step: 10
Training loss: 1.1631534099578857
Validation loss: 2.0035772224267325

Epoch: 5| Step: 11
Training loss: 1.5120179653167725
Validation loss: 2.002554173270861

Epoch: 164| Step: 0
Training loss: 1.0005416870117188
Validation loss: 2.0026003072659173

Epoch: 5| Step: 1
Training loss: 0.6550219655036926
Validation loss: 2.008452912171682

Epoch: 5| Step: 2
Training loss: 1.0606657266616821
Validation loss: 1.987527812520663

Epoch: 5| Step: 3
Training loss: 0.8059982061386108
Validation loss: 1.977364222208659

Epoch: 5| Step: 4
Training loss: 1.0956156253814697
Validation loss: 2.003739674886068

Epoch: 5| Step: 5
Training loss: 1.227357268333435
Validation loss: 1.9696333408355713

Epoch: 5| Step: 6
Training loss: 1.330849289894104
Validation loss: 2.0101535568634668

Epoch: 5| Step: 7
Training loss: 0.9296627044677734
Validation loss: 1.9762321064869564

Epoch: 5| Step: 8
Training loss: 1.1950466632843018
Validation loss: 2.0023384938637414

Epoch: 5| Step: 9
Training loss: 1.4654563665390015
Validation loss: 1.982353483637174

Epoch: 5| Step: 10
Training loss: 1.1012349128723145
Validation loss: 2.0098042686780295

Epoch: 5| Step: 11
Training loss: 1.5516579151153564
Validation loss: 2.0192912270625434

Epoch: 165| Step: 0
Training loss: 1.0601637363433838
Validation loss: 1.9889181902011235

Epoch: 5| Step: 1
Training loss: 1.1555383205413818
Validation loss: 1.9965149561564128

Epoch: 5| Step: 2
Training loss: 0.7553870677947998
Validation loss: 1.973559319972992

Epoch: 5| Step: 3
Training loss: 0.8052917718887329
Validation loss: 1.9969320247570674

Epoch: 5| Step: 4
Training loss: 0.9678235054016113
Validation loss: 2.00804736216863

Epoch: 5| Step: 5
Training loss: 1.2085247039794922
Validation loss: 1.9939422309398651

Epoch: 5| Step: 6
Training loss: 0.7999353408813477
Validation loss: 2.0070928086837134

Epoch: 5| Step: 7
Training loss: 0.8123536109924316
Validation loss: 1.995327889919281

Epoch: 5| Step: 8
Training loss: 1.5944271087646484
Validation loss: 1.992716019352277

Epoch: 5| Step: 9
Training loss: 1.0213090181350708
Validation loss: 2.007637103398641

Epoch: 5| Step: 10
Training loss: 1.0580581426620483
Validation loss: 2.0299664239088693

Epoch: 5| Step: 11
Training loss: 2.0578784942626953
Validation loss: 1.990615079800288

Epoch: 166| Step: 0
Training loss: 1.3291041851043701
Validation loss: 1.9957744081815083

Epoch: 5| Step: 1
Training loss: 0.9305191040039062
Validation loss: 2.000676820675532

Epoch: 5| Step: 2
Training loss: 1.1155798435211182
Validation loss: 2.006161113580068

Epoch: 5| Step: 3
Training loss: 1.142993450164795
Validation loss: 1.9914956589539845

Epoch: 5| Step: 4
Training loss: 0.7475355267524719
Validation loss: 2.0091544538736343

Epoch: 5| Step: 5
Training loss: 1.27357816696167
Validation loss: 2.00409143169721

Epoch: 5| Step: 6
Training loss: 0.9427703022956848
Validation loss: 1.9805307785669963

Epoch: 5| Step: 7
Training loss: 0.6225234270095825
Validation loss: 1.9933767467737198

Epoch: 5| Step: 8
Training loss: 1.3360297679901123
Validation loss: 1.982419028878212

Epoch: 5| Step: 9
Training loss: 1.3430862426757812
Validation loss: 1.9681161940097809

Epoch: 5| Step: 10
Training loss: 0.8233757019042969
Validation loss: 1.9749927719434102

Epoch: 5| Step: 11
Training loss: 1.3646329641342163
Validation loss: 1.9918906688690186

Epoch: 167| Step: 0
Training loss: 1.1473089456558228
Validation loss: 1.980480785171191

Epoch: 5| Step: 1
Training loss: 0.9999074935913086
Validation loss: 2.0025057395299277

Epoch: 5| Step: 2
Training loss: 1.0986084938049316
Validation loss: 2.0126327524582543

Epoch: 5| Step: 3
Training loss: 0.8871399164199829
Validation loss: 2.0202888945738473

Epoch: 5| Step: 4
Training loss: 1.0204709768295288
Validation loss: 1.9870830823977788

Epoch: 5| Step: 5
Training loss: 0.7932394742965698
Validation loss: 1.9870960116386414

Epoch: 5| Step: 6
Training loss: 0.7442218065261841
Validation loss: 1.9999808371067047

Epoch: 5| Step: 7
Training loss: 1.0111784934997559
Validation loss: 2.015261724591255

Epoch: 5| Step: 8
Training loss: 1.291993260383606
Validation loss: 1.9910793403784435

Epoch: 5| Step: 9
Training loss: 1.2827703952789307
Validation loss: 1.9941166539986928

Epoch: 5| Step: 10
Training loss: 1.2511706352233887
Validation loss: 1.9982603092988331

Epoch: 5| Step: 11
Training loss: 0.7436368465423584
Validation loss: 2.013279542326927

Epoch: 168| Step: 0
Training loss: 0.6050068140029907
Validation loss: 1.977893387277921

Epoch: 5| Step: 1
Training loss: 1.324096918106079
Validation loss: 1.9925406227509181

Epoch: 5| Step: 2
Training loss: 0.9197462797164917
Validation loss: 1.9999859581391017

Epoch: 5| Step: 3
Training loss: 1.3130533695220947
Validation loss: 2.004063164194425

Epoch: 5| Step: 4
Training loss: 0.7412958145141602
Validation loss: 2.01454521715641

Epoch: 5| Step: 5
Training loss: 1.2791593074798584
Validation loss: 2.017238905032476

Epoch: 5| Step: 6
Training loss: 1.1812118291854858
Validation loss: 2.037586842974027

Epoch: 5| Step: 7
Training loss: 0.9470949172973633
Validation loss: 1.9862663944562275

Epoch: 5| Step: 8
Training loss: 1.2096437215805054
Validation loss: 1.9702677925427754

Epoch: 5| Step: 9
Training loss: 0.6719624400138855
Validation loss: 1.9873152027527492

Epoch: 5| Step: 10
Training loss: 1.4100992679595947
Validation loss: 1.9852814227342606

Epoch: 5| Step: 11
Training loss: 0.4963826537132263
Validation loss: 1.9849283546209335

Epoch: 169| Step: 0
Training loss: 0.771986722946167
Validation loss: 1.99659064412117

Epoch: 5| Step: 1
Training loss: 1.1224799156188965
Validation loss: 1.9743298689524333

Epoch: 5| Step: 2
Training loss: 1.2916977405548096
Validation loss: 2.0171476701895394

Epoch: 5| Step: 3
Training loss: 1.2752889394760132
Validation loss: 2.0038587898015976

Epoch: 5| Step: 4
Training loss: 0.9574036598205566
Validation loss: 2.031399647394816

Epoch: 5| Step: 5
Training loss: 1.209007978439331
Validation loss: 2.002517431974411

Epoch: 5| Step: 6
Training loss: 0.9624488949775696
Validation loss: 2.006776695450147

Epoch: 5| Step: 7
Training loss: 1.3017337322235107
Validation loss: 1.9777401586373646

Epoch: 5| Step: 8
Training loss: 0.9030202031135559
Validation loss: 1.9755472143491108

Epoch: 5| Step: 9
Training loss: 1.022758960723877
Validation loss: 2.0378278543551764

Epoch: 5| Step: 10
Training loss: 0.8103723526000977
Validation loss: 2.0043184558550515

Epoch: 5| Step: 11
Training loss: 1.1116740703582764
Validation loss: 2.0001321186621985

Epoch: 170| Step: 0
Training loss: 0.8682290315628052
Validation loss: 2.0069471995035806

Epoch: 5| Step: 1
Training loss: 1.016493558883667
Validation loss: 2.000514268875122

Epoch: 5| Step: 2
Training loss: 2.0339314937591553
Validation loss: 1.9936329821745555

Epoch: 5| Step: 3
Training loss: 0.4682249128818512
Validation loss: 1.9726169258356094

Epoch: 5| Step: 4
Training loss: 0.9651119112968445
Validation loss: 2.0280239234368005

Epoch: 5| Step: 5
Training loss: 1.2075426578521729
Validation loss: 1.9947466154893239

Epoch: 5| Step: 6
Training loss: 0.9927467107772827
Validation loss: 1.9794196585814159

Epoch: 5| Step: 7
Training loss: 1.1180254220962524
Validation loss: 1.993666206796964

Epoch: 5| Step: 8
Training loss: 0.8867502212524414
Validation loss: 1.9989837010701497

Epoch: 5| Step: 9
Training loss: 1.206544280052185
Validation loss: 2.0057381888230643

Epoch: 5| Step: 10
Training loss: 0.6445765495300293
Validation loss: 1.9731336782375972

Epoch: 5| Step: 11
Training loss: 0.9822409152984619
Validation loss: 2.003844459851583

Epoch: 171| Step: 0
Training loss: 1.489259123802185
Validation loss: 2.0085118114948273

Epoch: 5| Step: 1
Training loss: 0.9286998510360718
Validation loss: 1.99493012825648

Epoch: 5| Step: 2
Training loss: 0.7971800565719604
Validation loss: 1.9944598178068798

Epoch: 5| Step: 3
Training loss: 0.6272369027137756
Validation loss: 1.9927548070748646

Epoch: 5| Step: 4
Training loss: 1.0760166645050049
Validation loss: 1.9980208774407704

Epoch: 5| Step: 5
Training loss: 0.8569124937057495
Validation loss: 1.9824402779340744

Epoch: 5| Step: 6
Training loss: 1.4081928730010986
Validation loss: 2.024307534098625

Epoch: 5| Step: 7
Training loss: 0.8634217977523804
Validation loss: 2.026517997185389

Epoch: 5| Step: 8
Training loss: 1.2754584550857544
Validation loss: 2.0044368157784143

Epoch: 5| Step: 9
Training loss: 0.9000580906867981
Validation loss: 2.0038175334533057

Epoch: 5| Step: 10
Training loss: 1.2957179546356201
Validation loss: 1.9616486231486003

Epoch: 5| Step: 11
Training loss: 0.06506887078285217
Validation loss: 1.99536628027757

Epoch: 172| Step: 0
Training loss: 0.9420914649963379
Validation loss: 2.0012921690940857

Epoch: 5| Step: 1
Training loss: 1.065456748008728
Validation loss: 2.0716707656780877

Epoch: 5| Step: 2
Training loss: 1.2880349159240723
Validation loss: 2.0063799619674683

Epoch: 5| Step: 3
Training loss: 1.1054617166519165
Validation loss: 1.9977738757928212

Epoch: 5| Step: 4
Training loss: 1.0572926998138428
Validation loss: 1.9740506956974666

Epoch: 5| Step: 5
Training loss: 0.5316518545150757
Validation loss: 1.9784690588712692

Epoch: 5| Step: 6
Training loss: 1.3008413314819336
Validation loss: 1.947980026404063

Epoch: 5| Step: 7
Training loss: 1.4856375455856323
Validation loss: 2.020755668481191

Epoch: 5| Step: 8
Training loss: 1.4047119617462158
Validation loss: 2.015899429718653

Epoch: 5| Step: 9
Training loss: 0.9594987630844116
Validation loss: 2.026440287629763

Epoch: 5| Step: 10
Training loss: 1.113364577293396
Validation loss: 2.008773515621821

Epoch: 5| Step: 11
Training loss: 0.3749202489852905
Validation loss: 1.9915645519892375

Epoch: 173| Step: 0
Training loss: 1.2158738374710083
Validation loss: 2.014173130194346

Epoch: 5| Step: 1
Training loss: 0.9828314781188965
Validation loss: 2.009316176176071

Epoch: 5| Step: 2
Training loss: 0.9876688122749329
Validation loss: 2.0406620601812997

Epoch: 5| Step: 3
Training loss: 1.0472296476364136
Validation loss: 2.1256971657276154

Epoch: 5| Step: 4
Training loss: 1.6981321573257446
Validation loss: 2.0721270938714347

Epoch: 5| Step: 5
Training loss: 0.922114372253418
Validation loss: 2.0415917287270227

Epoch: 5| Step: 6
Training loss: 0.9094419479370117
Validation loss: 2.036944235364596

Epoch: 5| Step: 7
Training loss: 0.7617124319076538
Validation loss: 2.033087372779846

Epoch: 5| Step: 8
Training loss: 1.2318600416183472
Validation loss: 2.0558677365382514

Epoch: 5| Step: 9
Training loss: 1.510711669921875
Validation loss: 2.0896056493123374

Epoch: 5| Step: 10
Training loss: 1.6376975774765015
Validation loss: 2.098097046216329

Epoch: 5| Step: 11
Training loss: 1.8619474172592163
Validation loss: 2.1396981875101724

Epoch: 174| Step: 0
Training loss: 1.283447265625
Validation loss: 2.074258337418238

Epoch: 5| Step: 1
Training loss: 1.036272644996643
Validation loss: 2.0369254797697067

Epoch: 5| Step: 2
Training loss: 0.6976189017295837
Validation loss: 1.9840477655331294

Epoch: 5| Step: 3
Training loss: 0.9065749049186707
Validation loss: 2.008321558435758

Epoch: 5| Step: 4
Training loss: 1.554165244102478
Validation loss: 2.015862132112185

Epoch: 5| Step: 5
Training loss: 1.4224611520767212
Validation loss: 2.0205857704083123

Epoch: 5| Step: 6
Training loss: 1.2933177947998047
Validation loss: 2.071605404218038

Epoch: 5| Step: 7
Training loss: 1.0541077852249146
Validation loss: 2.0406326403220496

Epoch: 5| Step: 8
Training loss: 1.1818162202835083
Validation loss: 1.9832214017709096

Epoch: 5| Step: 9
Training loss: 0.7328601479530334
Validation loss: 1.9773211826880772

Epoch: 5| Step: 10
Training loss: 1.3342355489730835
Validation loss: 1.9558287660280864

Epoch: 5| Step: 11
Training loss: 0.7349482774734497
Validation loss: 1.9961702277263005

Epoch: 175| Step: 0
Training loss: 0.8756505250930786
Validation loss: 1.9647417763868968

Epoch: 5| Step: 1
Training loss: 0.865667998790741
Validation loss: 1.9394382337729137

Epoch: 5| Step: 2
Training loss: 1.2619240283966064
Validation loss: 1.965006336569786

Epoch: 5| Step: 3
Training loss: 1.3356646299362183
Validation loss: 1.957268863916397

Epoch: 5| Step: 4
Training loss: 1.3531196117401123
Validation loss: 1.9669294555981953

Epoch: 5| Step: 5
Training loss: 0.3893459737300873
Validation loss: 1.9703033020099003

Epoch: 5| Step: 6
Training loss: 1.1058037281036377
Validation loss: 1.978887269894282

Epoch: 5| Step: 7
Training loss: 1.2386882305145264
Validation loss: 1.9801611453294754

Epoch: 5| Step: 8
Training loss: 0.6236749291419983
Validation loss: 1.9380306899547577

Epoch: 5| Step: 9
Training loss: 1.0346392393112183
Validation loss: 1.9985104004542034

Epoch: 5| Step: 10
Training loss: 1.5528048276901245
Validation loss: 2.010242447257042

Epoch: 5| Step: 11
Training loss: 0.6130269765853882
Validation loss: 1.9923429439465206

Epoch: 176| Step: 0
Training loss: 1.3041483163833618
Validation loss: 2.002743045488993

Epoch: 5| Step: 1
Training loss: 0.7487625479698181
Validation loss: 2.017404849330584

Epoch: 5| Step: 2
Training loss: 0.9751374125480652
Validation loss: 1.9813450525204341

Epoch: 5| Step: 3
Training loss: 0.7484431266784668
Validation loss: 1.9898833135763805

Epoch: 5| Step: 4
Training loss: 1.4889397621154785
Validation loss: 2.0072123308976493

Epoch: 5| Step: 5
Training loss: 0.7186519503593445
Validation loss: 2.01337664326032

Epoch: 5| Step: 6
Training loss: 1.031500220298767
Validation loss: 2.0156716058651605

Epoch: 5| Step: 7
Training loss: 0.7932901978492737
Validation loss: 1.9983522991339366

Epoch: 5| Step: 8
Training loss: 0.7192454934120178
Validation loss: 2.011464794476827

Epoch: 5| Step: 9
Training loss: 0.7103893160820007
Validation loss: 2.0082556704680123

Epoch: 5| Step: 10
Training loss: 1.3284451961517334
Validation loss: 2.008983795841535

Epoch: 5| Step: 11
Training loss: 2.235999345779419
Validation loss: 2.0104409903287888

Epoch: 177| Step: 0
Training loss: 1.1407147645950317
Validation loss: 2.001904174685478

Epoch: 5| Step: 1
Training loss: 1.5855209827423096
Validation loss: 2.0069265564282737

Epoch: 5| Step: 2
Training loss: 0.9242947697639465
Validation loss: 1.999137704571088

Epoch: 5| Step: 3
Training loss: 0.7850697636604309
Validation loss: 1.9811573574940364

Epoch: 5| Step: 4
Training loss: 1.0663032531738281
Validation loss: 1.9547320405642192

Epoch: 5| Step: 5
Training loss: 0.992087721824646
Validation loss: 1.9599159111579258

Epoch: 5| Step: 6
Training loss: 0.529352068901062
Validation loss: 1.9781098465124767

Epoch: 5| Step: 7
Training loss: 1.3395072221755981
Validation loss: 1.9777229279279709

Epoch: 5| Step: 8
Training loss: 0.6166307926177979
Validation loss: 1.9823816816012065

Epoch: 5| Step: 9
Training loss: 1.1675446033477783
Validation loss: 1.9858088145653408

Epoch: 5| Step: 10
Training loss: 1.358807921409607
Validation loss: 2.0049476325511932

Epoch: 5| Step: 11
Training loss: 1.1586190462112427
Validation loss: 1.9856456965208054

Epoch: 178| Step: 0
Training loss: 0.7380589842796326
Validation loss: 2.0089169293642044

Epoch: 5| Step: 1
Training loss: 0.9148787260055542
Validation loss: 1.9797027856111526

Epoch: 5| Step: 2
Training loss: 0.9796732664108276
Validation loss: 1.9681562980016072

Epoch: 5| Step: 3
Training loss: 0.9636044502258301
Validation loss: 1.9762303878863652

Epoch: 5| Step: 4
Training loss: 0.9851668477058411
Validation loss: 1.9639948258797328

Epoch: 5| Step: 5
Training loss: 1.1520271301269531
Validation loss: 1.9903916319211323

Epoch: 5| Step: 6
Training loss: 0.5464105010032654
Validation loss: 2.0066784421602883

Epoch: 5| Step: 7
Training loss: 0.9977084398269653
Validation loss: 2.0083571821451187

Epoch: 5| Step: 8
Training loss: 1.250628113746643
Validation loss: 2.019978885849317

Epoch: 5| Step: 9
Training loss: 1.2229416370391846
Validation loss: 2.0133224030335746

Epoch: 5| Step: 10
Training loss: 1.1276781558990479
Validation loss: 1.9824031790097554

Epoch: 5| Step: 11
Training loss: 1.33303701877594
Validation loss: 1.9835131218036015

Epoch: 179| Step: 0
Training loss: 0.720486044883728
Validation loss: 1.9787458678086598

Epoch: 5| Step: 1
Training loss: 0.828155517578125
Validation loss: 2.0125203927357993

Epoch: 5| Step: 2
Training loss: 1.4548622369766235
Validation loss: 2.0046489338080087

Epoch: 5| Step: 3
Training loss: 1.3094011545181274
Validation loss: 2.0056114296118417

Epoch: 5| Step: 4
Training loss: 0.9587041139602661
Validation loss: 1.9766022215286891

Epoch: 5| Step: 5
Training loss: 1.0164313316345215
Validation loss: 1.975142444173495

Epoch: 5| Step: 6
Training loss: 0.8323675394058228
Validation loss: 1.9795106301705043

Epoch: 5| Step: 7
Training loss: 0.768912136554718
Validation loss: 1.9647729247808456

Epoch: 5| Step: 8
Training loss: 0.9036283493041992
Validation loss: 1.9829991906881332

Epoch: 5| Step: 9
Training loss: 0.9871529340744019
Validation loss: 1.9790328095356624

Epoch: 5| Step: 10
Training loss: 1.1257671117782593
Validation loss: 1.9971094975868862

Epoch: 5| Step: 11
Training loss: 0.5490756630897522
Validation loss: 1.9776594241460164

Epoch: 180| Step: 0
Training loss: 1.0640735626220703
Validation loss: 1.947210431098938

Epoch: 5| Step: 1
Training loss: 0.7925756573677063
Validation loss: 1.9981844623883565

Epoch: 5| Step: 2
Training loss: 0.7841919660568237
Validation loss: 1.9911722391843796

Epoch: 5| Step: 3
Training loss: 0.6256505250930786
Validation loss: 1.9846587777137756

Epoch: 5| Step: 4
Training loss: 1.123624324798584
Validation loss: 2.0295654982328415

Epoch: 5| Step: 5
Training loss: 0.9861932992935181
Validation loss: 1.9939232965310414

Epoch: 5| Step: 6
Training loss: 0.7773518562316895
Validation loss: 2.0001179029544196

Epoch: 5| Step: 7
Training loss: 0.8777152895927429
Validation loss: 1.982258215546608

Epoch: 5| Step: 8
Training loss: 1.2768828868865967
Validation loss: 2.002267320950826

Epoch: 5| Step: 9
Training loss: 0.8218270540237427
Validation loss: 2.0160575956106186

Epoch: 5| Step: 10
Training loss: 1.4472190141677856
Validation loss: 1.991757293542226

Epoch: 5| Step: 11
Training loss: 0.25059759616851807
Validation loss: 2.0092420478661857

Epoch: 181| Step: 0
Training loss: 0.6304882764816284
Validation loss: 2.0054457436005273

Epoch: 5| Step: 1
Training loss: 0.8768855929374695
Validation loss: 1.9938451945781708

Epoch: 5| Step: 2
Training loss: 0.9342182874679565
Validation loss: 2.057203024625778

Epoch: 5| Step: 3
Training loss: 1.5627237558364868
Validation loss: 2.0250476946433387

Epoch: 5| Step: 4
Training loss: 0.9144078493118286
Validation loss: 1.993984078367551

Epoch: 5| Step: 5
Training loss: 1.2344863414764404
Validation loss: 2.0345731327931085

Epoch: 5| Step: 6
Training loss: 0.8492876887321472
Validation loss: 1.9732911189397175

Epoch: 5| Step: 7
Training loss: 1.1169193983078003
Validation loss: 2.005331406990687

Epoch: 5| Step: 8
Training loss: 0.7153733968734741
Validation loss: 2.013264457384745

Epoch: 5| Step: 9
Training loss: 1.0453382730484009
Validation loss: 2.0324380695819855

Epoch: 5| Step: 10
Training loss: 1.0084284543991089
Validation loss: 2.034285604953766

Epoch: 5| Step: 11
Training loss: 0.9497121572494507
Validation loss: 2.007363498210907

Epoch: 182| Step: 0
Training loss: 0.7551884055137634
Validation loss: 2.0108800729115806

Epoch: 5| Step: 1
Training loss: 1.215282917022705
Validation loss: 1.9798613339662552

Epoch: 5| Step: 2
Training loss: 0.7435445785522461
Validation loss: 1.964929684996605

Epoch: 5| Step: 3
Training loss: 1.416643500328064
Validation loss: 1.9877651383479435

Epoch: 5| Step: 4
Training loss: 0.6425909399986267
Validation loss: 1.9991318235794704

Epoch: 5| Step: 5
Training loss: 0.8457223773002625
Validation loss: 2.023484006524086

Epoch: 5| Step: 6
Training loss: 1.0454612970352173
Validation loss: 1.9851393351952236

Epoch: 5| Step: 7
Training loss: 0.7521612048149109
Validation loss: 1.9829863806565602

Epoch: 5| Step: 8
Training loss: 1.3839337825775146
Validation loss: 1.998544414838155

Epoch: 5| Step: 9
Training loss: 0.769504725933075
Validation loss: 1.9856993407011032

Epoch: 5| Step: 10
Training loss: 0.7973166704177856
Validation loss: 2.0117478917042413

Epoch: 5| Step: 11
Training loss: 0.33673524856567383
Validation loss: 1.9794163753588994

Epoch: 183| Step: 0
Training loss: 1.2475217580795288
Validation loss: 1.9747087111075718

Epoch: 5| Step: 1
Training loss: 1.6333423852920532
Validation loss: 1.9946546306212742

Epoch: 5| Step: 2
Training loss: 1.0790174007415771
Validation loss: 1.9730127503474553

Epoch: 5| Step: 3
Training loss: 0.6117806434631348
Validation loss: 1.9790044377247493

Epoch: 5| Step: 4
Training loss: 0.7123742699623108
Validation loss: 1.9884621451298397

Epoch: 5| Step: 5
Training loss: 0.658079206943512
Validation loss: 2.0121242105960846

Epoch: 5| Step: 6
Training loss: 0.9345940351486206
Validation loss: 1.993834023674329

Epoch: 5| Step: 7
Training loss: 0.7382017374038696
Validation loss: 1.9965053796768188

Epoch: 5| Step: 8
Training loss: 1.0961947441101074
Validation loss: 2.0072262982527413

Epoch: 5| Step: 9
Training loss: 1.1382005214691162
Validation loss: 2.032050068179766

Epoch: 5| Step: 10
Training loss: 1.071428894996643
Validation loss: 2.000845432281494

Epoch: 5| Step: 11
Training loss: 0.29908981919288635
Validation loss: 1.9911867429812748

Epoch: 184| Step: 0
Training loss: 1.331634283065796
Validation loss: 1.9690099408229191

Epoch: 5| Step: 1
Training loss: 0.5688886046409607
Validation loss: 1.9927828361590703

Epoch: 5| Step: 2
Training loss: 1.3541322946548462
Validation loss: 1.9782862216234207

Epoch: 5| Step: 3
Training loss: 0.6340974569320679
Validation loss: 1.9819617172082264

Epoch: 5| Step: 4
Training loss: 1.2769801616668701
Validation loss: 2.0103116234143577

Epoch: 5| Step: 5
Training loss: 1.1067770719528198
Validation loss: 2.0018075108528137

Epoch: 5| Step: 6
Training loss: 0.6586029529571533
Validation loss: 2.0273876637220383

Epoch: 5| Step: 7
Training loss: 0.902623176574707
Validation loss: 1.9647900958855946

Epoch: 5| Step: 8
Training loss: 0.7092469334602356
Validation loss: 1.9772307326396306

Epoch: 5| Step: 9
Training loss: 1.2324942350387573
Validation loss: 1.98992753525575

Epoch: 5| Step: 10
Training loss: 0.6761431694030762
Validation loss: 2.0153777400652566

Epoch: 5| Step: 11
Training loss: 0.2295244336128235
Validation loss: 1.977297604084015

Epoch: 185| Step: 0
Training loss: 1.5143829584121704
Validation loss: 1.9812628328800201

Epoch: 5| Step: 1
Training loss: 0.694194495677948
Validation loss: 1.9993217140436172

Epoch: 5| Step: 2
Training loss: 0.8487809300422668
Validation loss: 1.998742217818896

Epoch: 5| Step: 3
Training loss: 1.0939689874649048
Validation loss: 2.0435356497764587

Epoch: 5| Step: 4
Training loss: 0.6681671142578125
Validation loss: 2.012272616227468

Epoch: 5| Step: 5
Training loss: 1.0582749843597412
Validation loss: 2.0099864999453225

Epoch: 5| Step: 6
Training loss: 0.6336342692375183
Validation loss: 1.9997740934292476

Epoch: 5| Step: 7
Training loss: 0.8674919009208679
Validation loss: 2.0035281827052436

Epoch: 5| Step: 8
Training loss: 1.3330577611923218
Validation loss: 1.9890940139691036

Epoch: 5| Step: 9
Training loss: 0.6326403617858887
Validation loss: 2.028312474489212

Epoch: 5| Step: 10
Training loss: 1.2354007959365845
Validation loss: 2.0164405753215155

Epoch: 5| Step: 11
Training loss: 0.3041912317276001
Validation loss: 1.9813726196686428

Epoch: 186| Step: 0
Training loss: 0.9806855320930481
Validation loss: 2.0144741783539453

Epoch: 5| Step: 1
Training loss: 0.7036094665527344
Validation loss: 2.0069600393374762

Epoch: 5| Step: 2
Training loss: 0.8981130719184875
Validation loss: 2.072994271914164

Epoch: 5| Step: 3
Training loss: 0.8211883306503296
Validation loss: 2.046171933412552

Epoch: 5| Step: 4
Training loss: 1.3478105068206787
Validation loss: 2.0509540736675262

Epoch: 5| Step: 5
Training loss: 1.2418462038040161
Validation loss: 1.9901493787765503

Epoch: 5| Step: 6
Training loss: 0.662964403629303
Validation loss: 2.0192189514636993

Epoch: 5| Step: 7
Training loss: 1.3286632299423218
Validation loss: 2.012699474891027

Epoch: 5| Step: 8
Training loss: 1.1457037925720215
Validation loss: 2.0648067643245063

Epoch: 5| Step: 9
Training loss: 1.390537977218628
Validation loss: 2.050345708926519

Epoch: 5| Step: 10
Training loss: 0.7404455542564392
Validation loss: 2.0601845433314643

Epoch: 5| Step: 11
Training loss: 1.1022320985794067
Validation loss: 2.0421131253242493

Epoch: 187| Step: 0
Training loss: 0.5761517286300659
Validation loss: 2.0071804523468018

Epoch: 5| Step: 1
Training loss: 0.8565295338630676
Validation loss: 2.037176181872686

Epoch: 5| Step: 2
Training loss: 0.70121830701828
Validation loss: 2.0107489923636117

Epoch: 5| Step: 3
Training loss: 1.007272720336914
Validation loss: 1.9945323566595714

Epoch: 5| Step: 4
Training loss: 1.2720474004745483
Validation loss: 1.99379995961984

Epoch: 5| Step: 5
Training loss: 1.364985466003418
Validation loss: 1.9869557668765385

Epoch: 5| Step: 6
Training loss: 1.111092209815979
Validation loss: 2.0255577762921653

Epoch: 5| Step: 7
Training loss: 0.8643806576728821
Validation loss: 2.0345010658105216

Epoch: 5| Step: 8
Training loss: 0.9633728265762329
Validation loss: 2.022687410314878

Epoch: 5| Step: 9
Training loss: 0.623934268951416
Validation loss: 1.9688284794489543

Epoch: 5| Step: 10
Training loss: 1.091071367263794
Validation loss: 1.9909270753463109

Epoch: 5| Step: 11
Training loss: 0.9828367829322815
Validation loss: 1.9953870673974354

Epoch: 188| Step: 0
Training loss: 0.9372474551200867
Validation loss: 1.9930260727802913

Epoch: 5| Step: 1
Training loss: 0.37036916613578796
Validation loss: 2.0081567813952765

Epoch: 5| Step: 2
Training loss: 1.3144782781600952
Validation loss: 2.0424553652604422

Epoch: 5| Step: 3
Training loss: 1.0288398265838623
Validation loss: 2.007711097598076

Epoch: 5| Step: 4
Training loss: 1.0840554237365723
Validation loss: 1.9884879738092422

Epoch: 5| Step: 5
Training loss: 0.7322885394096375
Validation loss: 1.984863246480624

Epoch: 5| Step: 6
Training loss: 0.5366420149803162
Validation loss: 2.0086338967084885

Epoch: 5| Step: 7
Training loss: 0.8566447496414185
Validation loss: 1.981639231244723

Epoch: 5| Step: 8
Training loss: 0.5147297382354736
Validation loss: 1.980138639609019

Epoch: 5| Step: 9
Training loss: 1.0622879266738892
Validation loss: 1.974814881881078

Epoch: 5| Step: 10
Training loss: 1.1960837841033936
Validation loss: 2.0018887519836426

Epoch: 5| Step: 11
Training loss: 2.407090425491333
Validation loss: 2.0012341886758804

Epoch: 189| Step: 0
Training loss: 0.9313100576400757
Validation loss: 2.0184873044490814

Epoch: 5| Step: 1
Training loss: 0.9271475076675415
Validation loss: 2.0230649511019387

Epoch: 5| Step: 2
Training loss: 0.771670937538147
Validation loss: 1.9816113660732906

Epoch: 5| Step: 3
Training loss: 1.167680025100708
Validation loss: 1.9894295086463292

Epoch: 5| Step: 4
Training loss: 1.37479567527771
Validation loss: 1.9997043410936992

Epoch: 5| Step: 5
Training loss: 0.690677285194397
Validation loss: 2.015241871277491

Epoch: 5| Step: 6
Training loss: 0.7828071713447571
Validation loss: 2.044248183568319

Epoch: 5| Step: 7
Training loss: 0.9608132243156433
Validation loss: 2.0307011355956397

Epoch: 5| Step: 8
Training loss: 0.4368206858634949
Validation loss: 1.997429996728897

Epoch: 5| Step: 9
Training loss: 0.8582993745803833
Validation loss: 1.967025597890218

Epoch: 5| Step: 10
Training loss: 1.1050870418548584
Validation loss: 2.0329317996899285

Epoch: 5| Step: 11
Training loss: 0.9593623876571655
Validation loss: 2.001176511247953

Epoch: 190| Step: 0
Training loss: 0.8369881510734558
Validation loss: 2.022582362095515

Epoch: 5| Step: 1
Training loss: 0.9407054781913757
Validation loss: 1.9679747720559437

Epoch: 5| Step: 2
Training loss: 1.1810681819915771
Validation loss: 1.968912015358607

Epoch: 5| Step: 3
Training loss: 0.5337321758270264
Validation loss: 1.959636355439822

Epoch: 5| Step: 4
Training loss: 0.9618020057678223
Validation loss: 2.0008738189935684

Epoch: 5| Step: 5
Training loss: 0.5794197916984558
Validation loss: 1.9943442891041439

Epoch: 5| Step: 6
Training loss: 0.5444661974906921
Validation loss: 1.9955093363920848

Epoch: 5| Step: 7
Training loss: 0.7075822949409485
Validation loss: 1.985224425792694

Epoch: 5| Step: 8
Training loss: 1.3659082651138306
Validation loss: 2.0221888720989227

Epoch: 5| Step: 9
Training loss: 0.962903618812561
Validation loss: 2.010581155618032

Epoch: 5| Step: 10
Training loss: 1.1642276048660278
Validation loss: 2.005019098520279

Epoch: 5| Step: 11
Training loss: 0.2542448043823242
Validation loss: 2.014489491780599

Epoch: 191| Step: 0
Training loss: 1.2136164903640747
Validation loss: 2.0065332849820456

Epoch: 5| Step: 1
Training loss: 1.0064525604248047
Validation loss: 2.0122670580943427

Epoch: 5| Step: 2
Training loss: 0.6988779902458191
Validation loss: 1.984166532754898

Epoch: 5| Step: 3
Training loss: 0.8986676931381226
Validation loss: 2.0214770336945853

Epoch: 5| Step: 4
Training loss: 0.6534726023674011
Validation loss: 1.9875386854012806

Epoch: 5| Step: 5
Training loss: 0.7113288640975952
Validation loss: 2.0070709784825644

Epoch: 5| Step: 6
Training loss: 0.637271523475647
Validation loss: 2.0093286534150443

Epoch: 5| Step: 7
Training loss: 1.0163743495941162
Validation loss: 1.9904309113820393

Epoch: 5| Step: 8
Training loss: 1.0283360481262207
Validation loss: 2.013120616475741

Epoch: 5| Step: 9
Training loss: 1.197060227394104
Validation loss: 2.014031713207563

Epoch: 5| Step: 10
Training loss: 0.8631561398506165
Validation loss: 2.021402026216189

Epoch: 5| Step: 11
Training loss: 0.3231660723686218
Validation loss: 2.003896286090215

Epoch: 192| Step: 0
Training loss: 1.0842607021331787
Validation loss: 2.0244711339473724

Epoch: 5| Step: 1
Training loss: 0.8602851033210754
Validation loss: 1.9962818175554276

Epoch: 5| Step: 2
Training loss: 0.8819218873977661
Validation loss: 1.9911393970251083

Epoch: 5| Step: 3
Training loss: 0.8115034103393555
Validation loss: 2.024317746361097

Epoch: 5| Step: 4
Training loss: 0.702797532081604
Validation loss: 2.012031232317289

Epoch: 5| Step: 5
Training loss: 1.2712903022766113
Validation loss: 1.9702742397785187

Epoch: 5| Step: 6
Training loss: 0.4741005003452301
Validation loss: 1.9852188626925151

Epoch: 5| Step: 7
Training loss: 0.6003581285476685
Validation loss: 2.0017918994029364

Epoch: 5| Step: 8
Training loss: 0.9766719937324524
Validation loss: 1.9999691943327587

Epoch: 5| Step: 9
Training loss: 0.9121416211128235
Validation loss: 2.0148725509643555

Epoch: 5| Step: 10
Training loss: 1.3486473560333252
Validation loss: 2.007475475470225

Epoch: 5| Step: 11
Training loss: 0.9991719722747803
Validation loss: 2.0137141942977905

Epoch: 193| Step: 0
Training loss: 0.7992511987686157
Validation loss: 2.010614568988482

Epoch: 5| Step: 1
Training loss: 0.8984456062316895
Validation loss: 1.996537297964096

Epoch: 5| Step: 2
Training loss: 0.9424546957015991
Validation loss: 2.0136901885271072

Epoch: 5| Step: 3
Training loss: 1.0326741933822632
Validation loss: 1.9828346570332844

Epoch: 5| Step: 4
Training loss: 0.8511641621589661
Validation loss: 2.01437039176623

Epoch: 5| Step: 5
Training loss: 0.8477495312690735
Validation loss: 2.0150445799032846

Epoch: 5| Step: 6
Training loss: 0.9454498291015625
Validation loss: 2.0266344199577966

Epoch: 5| Step: 7
Training loss: 0.9347151517868042
Validation loss: 2.0593757778406143

Epoch: 5| Step: 8
Training loss: 0.6062361001968384
Validation loss: 2.0337466994921365

Epoch: 5| Step: 9
Training loss: 1.0696834325790405
Validation loss: 2.0537947763999305

Epoch: 5| Step: 10
Training loss: 0.9573497772216797
Validation loss: 2.041303073366483

Epoch: 5| Step: 11
Training loss: 1.118255853652954
Validation loss: 2.035828858613968

Epoch: 194| Step: 0
Training loss: 0.9764047861099243
Validation loss: 1.9842161933581035

Epoch: 5| Step: 1
Training loss: 0.6467229127883911
Validation loss: 2.0068704336881638

Epoch: 5| Step: 2
Training loss: 0.7028148770332336
Validation loss: 2.0080762853225074

Epoch: 5| Step: 3
Training loss: 1.1650506258010864
Validation loss: 2.029174988468488

Epoch: 5| Step: 4
Training loss: 0.813022792339325
Validation loss: 2.0242110192775726

Epoch: 5| Step: 5
Training loss: 1.168916940689087
Validation loss: 2.025901272892952

Epoch: 5| Step: 6
Training loss: 1.269289255142212
Validation loss: 1.9656465301911037

Epoch: 5| Step: 7
Training loss: 0.1993890255689621
Validation loss: 2.0268702656030655

Epoch: 5| Step: 8
Training loss: 0.9858379364013672
Validation loss: 1.9735165139039357

Epoch: 5| Step: 9
Training loss: 0.9914266467094421
Validation loss: 1.9958886504173279

Epoch: 5| Step: 10
Training loss: 1.069366216659546
Validation loss: 1.9893660346666973

Epoch: 5| Step: 11
Training loss: 0.3971625566482544
Validation loss: 2.0095800012350082

Epoch: 195| Step: 0
Training loss: 1.371288537979126
Validation loss: 2.0425503154595694

Epoch: 5| Step: 1
Training loss: 0.4523138999938965
Validation loss: 1.9552322328090668

Epoch: 5| Step: 2
Training loss: 0.7290316820144653
Validation loss: 1.9792014509439468

Epoch: 5| Step: 3
Training loss: 0.7067617177963257
Validation loss: 1.9937125245730083

Epoch: 5| Step: 4
Training loss: 0.8863240480422974
Validation loss: 2.0164139370123544

Epoch: 5| Step: 5
Training loss: 0.8079715967178345
Validation loss: 2.0051744282245636

Epoch: 5| Step: 6
Training loss: 0.9914901852607727
Validation loss: 1.9744099825620651

Epoch: 5| Step: 7
Training loss: 0.7742381691932678
Validation loss: 1.9910367329915364

Epoch: 5| Step: 8
Training loss: 0.9238029718399048
Validation loss: 2.0043181777000427

Epoch: 5| Step: 9
Training loss: 1.114579677581787
Validation loss: 1.963964452346166

Epoch: 5| Step: 10
Training loss: 0.9468587040901184
Validation loss: 1.9819525082906086

Epoch: 5| Step: 11
Training loss: 1.2509713172912598
Validation loss: 2.002999330560366

Epoch: 196| Step: 0
Training loss: 0.7834064364433289
Validation loss: 1.974980557958285

Epoch: 5| Step: 1
Training loss: 0.6862841844558716
Validation loss: 2.0235942900180817

Epoch: 5| Step: 2
Training loss: 0.914847195148468
Validation loss: 2.0180673797925315

Epoch: 5| Step: 3
Training loss: 1.2607030868530273
Validation loss: 2.0552918960650763

Epoch: 5| Step: 4
Training loss: 1.1131856441497803
Validation loss: 1.9998766481876373

Epoch: 5| Step: 5
Training loss: 0.7906047701835632
Validation loss: 2.0456718653440475

Epoch: 5| Step: 6
Training loss: 0.735758900642395
Validation loss: 2.0306750535964966

Epoch: 5| Step: 7
Training loss: 1.3823246955871582
Validation loss: 2.008807589610418

Epoch: 5| Step: 8
Training loss: 0.7517815828323364
Validation loss: 2.0252309888601303

Epoch: 5| Step: 9
Training loss: 0.6579127311706543
Validation loss: 2.049741417169571

Epoch: 5| Step: 10
Training loss: 0.6029751896858215
Validation loss: 2.020464152097702

Epoch: 5| Step: 11
Training loss: 1.0100728273391724
Validation loss: 1.992878754933675

Epoch: 197| Step: 0
Training loss: 1.1923673152923584
Validation loss: 2.011103759209315

Epoch: 5| Step: 1
Training loss: 0.7963663339614868
Validation loss: 2.0421767632166543

Epoch: 5| Step: 2
Training loss: 0.9932928085327148
Validation loss: 1.9885307848453522

Epoch: 5| Step: 3
Training loss: 0.9835432171821594
Validation loss: 2.0402104407548904

Epoch: 5| Step: 4
Training loss: 0.7749298810958862
Validation loss: 2.008377641439438

Epoch: 5| Step: 5
Training loss: 0.8190218806266785
Validation loss: 2.046005959312121

Epoch: 5| Step: 6
Training loss: 0.842843234539032
Validation loss: 2.0270967185497284

Epoch: 5| Step: 7
Training loss: 0.9581485986709595
Validation loss: 1.9980834523836772

Epoch: 5| Step: 8
Training loss: 0.7461811304092407
Validation loss: 1.9938208162784576

Epoch: 5| Step: 9
Training loss: 0.5003344416618347
Validation loss: 2.000494966904322

Epoch: 5| Step: 10
Training loss: 0.892656147480011
Validation loss: 2.0157846212387085

Epoch: 5| Step: 11
Training loss: 1.4576386213302612
Validation loss: 2.019116073846817

Epoch: 198| Step: 0
Training loss: 0.590326189994812
Validation loss: 2.026150733232498

Epoch: 5| Step: 1
Training loss: 0.8722073435783386
Validation loss: 2.028717706600825

Epoch: 5| Step: 2
Training loss: 0.5818902254104614
Validation loss: 2.039661477009455

Epoch: 5| Step: 3
Training loss: 1.0254614353179932
Validation loss: 2.009401813149452

Epoch: 5| Step: 4
Training loss: 0.9948514103889465
Validation loss: 2.001396040121714

Epoch: 5| Step: 5
Training loss: 0.8188691139221191
Validation loss: 2.0411917765935264

Epoch: 5| Step: 6
Training loss: 0.5423782467842102
Validation loss: 2.063774893681208

Epoch: 5| Step: 7
Training loss: 1.0235000848770142
Validation loss: 2.051002159714699

Epoch: 5| Step: 8
Training loss: 1.1468188762664795
Validation loss: 2.0458901127179465

Epoch: 5| Step: 9
Training loss: 0.585175096988678
Validation loss: 2.01181631286939

Epoch: 5| Step: 10
Training loss: 1.2756439447402954
Validation loss: 2.0259960691134133

Epoch: 5| Step: 11
Training loss: 1.6186299324035645
Validation loss: 2.0207630892594657

Epoch: 199| Step: 0
Training loss: 0.7390239834785461
Validation loss: 2.022407606244087

Epoch: 5| Step: 1
Training loss: 1.4234803915023804
Validation loss: 2.010492538412412

Epoch: 5| Step: 2
Training loss: 0.6613789200782776
Validation loss: 2.0310915261507034

Epoch: 5| Step: 3
Training loss: 0.9751908183097839
Validation loss: 2.034528930981954

Epoch: 5| Step: 4
Training loss: 0.7716535329818726
Validation loss: 1.9940445572137833

Epoch: 5| Step: 5
Training loss: 0.9098176956176758
Validation loss: 2.027931183576584

Epoch: 5| Step: 6
Training loss: 0.7158553004264832
Validation loss: 1.99140760799249

Epoch: 5| Step: 7
Training loss: 0.9280573129653931
Validation loss: 2.026600028077761

Epoch: 5| Step: 8
Training loss: 0.8266369104385376
Validation loss: 2.0365582207838693

Epoch: 5| Step: 9
Training loss: 0.6497042775154114
Validation loss: 2.0171338816483817

Epoch: 5| Step: 10
Training loss: 0.8985552787780762
Validation loss: 1.9960469007492065

Epoch: 5| Step: 11
Training loss: 0.9168494939804077
Validation loss: 2.061208263039589

Epoch: 200| Step: 0
Training loss: 1.2479006052017212
Validation loss: 2.032448331514994

Epoch: 5| Step: 1
Training loss: 0.7676461935043335
Validation loss: 2.010102624694506

Epoch: 5| Step: 2
Training loss: 0.8995984196662903
Validation loss: 2.0129650284846625

Epoch: 5| Step: 3
Training loss: 0.6758699417114258
Validation loss: 1.9998334248860676

Epoch: 5| Step: 4
Training loss: 0.7318078875541687
Validation loss: 2.021605834364891

Epoch: 5| Step: 5
Training loss: 0.6523195505142212
Validation loss: 2.0556630144516626

Epoch: 5| Step: 6
Training loss: 1.17183518409729
Validation loss: 2.0161201109488807

Epoch: 5| Step: 7
Training loss: 1.3303413391113281
Validation loss: 2.0139260441064835

Epoch: 5| Step: 8
Training loss: 0.6395143866539001
Validation loss: 2.0310366302728653

Epoch: 5| Step: 9
Training loss: 1.0162564516067505
Validation loss: 2.0399208615223565

Epoch: 5| Step: 10
Training loss: 0.8933874368667603
Validation loss: 2.022930617133776

Epoch: 5| Step: 11
Training loss: 1.3230764865875244
Validation loss: 2.0225453873475394

Epoch: 201| Step: 0
Training loss: 0.8238310813903809
Validation loss: 1.9964585502942402

Epoch: 5| Step: 1
Training loss: 0.5646864175796509
Validation loss: 2.0384234189987183

Epoch: 5| Step: 2
Training loss: 0.9125798344612122
Validation loss: 2.0125433752934136

Epoch: 5| Step: 3
Training loss: 0.9138346910476685
Validation loss: 1.9942630281051

Epoch: 5| Step: 4
Training loss: 0.8396302461624146
Validation loss: 1.9677796065807343

Epoch: 5| Step: 5
Training loss: 0.5754400491714478
Validation loss: 2.015349492430687

Epoch: 5| Step: 6
Training loss: 0.8489516973495483
Validation loss: 1.9903631607691448

Epoch: 5| Step: 7
Training loss: 0.5388146638870239
Validation loss: 1.9942911565303802

Epoch: 5| Step: 8
Training loss: 1.1771024465560913
Validation loss: 1.9882408529520035

Epoch: 5| Step: 9
Training loss: 1.3413665294647217
Validation loss: 2.0512181719144187

Epoch: 5| Step: 10
Training loss: 0.886858344078064
Validation loss: 2.0554710576931634

Epoch: 5| Step: 11
Training loss: 1.1070072650909424
Validation loss: 2.0133393108844757

Epoch: 202| Step: 0
Training loss: 0.7839374542236328
Validation loss: 2.0114046881596246

Epoch: 5| Step: 1
Training loss: 1.3985822200775146
Validation loss: 2.0017396261294684

Epoch: 5| Step: 2
Training loss: 0.7897224426269531
Validation loss: 2.0493356386820474

Epoch: 5| Step: 3
Training loss: 1.1045783758163452
Validation loss: 2.102924639979998

Epoch: 5| Step: 4
Training loss: 1.1140042543411255
Validation loss: 2.097524955868721

Epoch: 5| Step: 5
Training loss: 1.0706876516342163
Validation loss: 2.085808356602987

Epoch: 5| Step: 6
Training loss: 0.9547444581985474
Validation loss: 2.020587742328644

Epoch: 5| Step: 7
Training loss: 0.7418557405471802
Validation loss: 2.004448319474856

Epoch: 5| Step: 8
Training loss: 0.9826852083206177
Validation loss: 2.015744681159655

Epoch: 5| Step: 9
Training loss: 0.6426097750663757
Validation loss: 2.0362616082032523

Epoch: 5| Step: 10
Training loss: 0.7888585329055786
Validation loss: 2.040727749466896

Epoch: 5| Step: 11
Training loss: 1.2845789194107056
Validation loss: 2.045835261543592

Epoch: 203| Step: 0
Training loss: 0.8743717074394226
Validation loss: 2.04550264775753

Epoch: 5| Step: 1
Training loss: 1.1533994674682617
Validation loss: 2.0292111933231354

Epoch: 5| Step: 2
Training loss: 0.5373193025588989
Validation loss: 2.0017612179120383

Epoch: 5| Step: 3
Training loss: 0.5543875694274902
Validation loss: 2.039690524339676

Epoch: 5| Step: 4
Training loss: 0.8799009323120117
Validation loss: 2.054156854748726

Epoch: 5| Step: 5
Training loss: 1.3719704151153564
Validation loss: 2.011813059449196

Epoch: 5| Step: 6
Training loss: 0.7400901317596436
Validation loss: 2.0587264746427536

Epoch: 5| Step: 7
Training loss: 1.5097167491912842
Validation loss: 2.0076719373464584

Epoch: 5| Step: 8
Training loss: 0.8283044695854187
Validation loss: 2.033754383524259

Epoch: 5| Step: 9
Training loss: 0.6923305988311768
Validation loss: 2.0048367927471795

Epoch: 5| Step: 10
Training loss: 0.5952628254890442
Validation loss: 1.9907655715942383

Epoch: 5| Step: 11
Training loss: 0.8692637085914612
Validation loss: 2.0148744533459344

Epoch: 204| Step: 0
Training loss: 0.826056957244873
Validation loss: 2.002786507209142

Epoch: 5| Step: 1
Training loss: 0.8263354301452637
Validation loss: 2.0245670626560845

Epoch: 5| Step: 2
Training loss: 0.6375963091850281
Validation loss: 2.0418347318967185

Epoch: 5| Step: 3
Training loss: 0.7827240228652954
Validation loss: 2.0309148132801056

Epoch: 5| Step: 4
Training loss: 0.7331425547599792
Validation loss: 1.9894791146119435

Epoch: 5| Step: 5
Training loss: 0.9498111605644226
Validation loss: 1.9897444595893223

Epoch: 5| Step: 6
Training loss: 1.0906178951263428
Validation loss: 2.044104019800822

Epoch: 5| Step: 7
Training loss: 0.9286434054374695
Validation loss: 2.05042564868927

Epoch: 5| Step: 8
Training loss: 0.9032170176506042
Validation loss: 2.05128380159537

Epoch: 5| Step: 9
Training loss: 1.1704399585723877
Validation loss: 2.016855761408806

Epoch: 5| Step: 10
Training loss: 0.6796892881393433
Validation loss: 2.0465369522571564

Epoch: 5| Step: 11
Training loss: 0.8900831937789917
Validation loss: 1.9997895509004593

Epoch: 205| Step: 0
Training loss: 0.6779546141624451
Validation loss: 1.9963606993357341

Epoch: 5| Step: 1
Training loss: 0.7885823249816895
Validation loss: 1.9884911179542542

Epoch: 5| Step: 2
Training loss: 0.9984157681465149
Validation loss: 1.9991021653016408

Epoch: 5| Step: 3
Training loss: 0.6971544027328491
Validation loss: 2.0181526243686676

Epoch: 5| Step: 4
Training loss: 1.0044246912002563
Validation loss: 2.037793517112732

Epoch: 5| Step: 5
Training loss: 0.8766926527023315
Validation loss: 2.021344934900602

Epoch: 5| Step: 6
Training loss: 0.7932860255241394
Validation loss: 2.0030125230550766

Epoch: 5| Step: 7
Training loss: 0.6196646690368652
Validation loss: 2.0231219083070755

Epoch: 5| Step: 8
Training loss: 0.9307245016098022
Validation loss: 2.01194129884243

Epoch: 5| Step: 9
Training loss: 0.9587032198905945
Validation loss: 2.0479288548231125

Epoch: 5| Step: 10
Training loss: 0.9971657991409302
Validation loss: 2.03883159160614

Epoch: 5| Step: 11
Training loss: 1.8116610050201416
Validation loss: 1.980633224050204

Epoch: 206| Step: 0
Training loss: 0.9423534274101257
Validation loss: 2.003826563556989

Epoch: 5| Step: 1
Training loss: 0.8566159009933472
Validation loss: 1.9712624549865723

Epoch: 5| Step: 2
Training loss: 0.9313632845878601
Validation loss: 2.009875074028969

Epoch: 5| Step: 3
Training loss: 0.8839116096496582
Validation loss: 1.9905991305907567

Epoch: 5| Step: 4
Training loss: 0.3828522562980652
Validation loss: 1.9739979356527328

Epoch: 5| Step: 5
Training loss: 1.2404844760894775
Validation loss: 2.0167492032051086

Epoch: 5| Step: 6
Training loss: 0.41706228256225586
Validation loss: 1.9578727980454762

Epoch: 5| Step: 7
Training loss: 1.1990476846694946
Validation loss: 2.010282372434934

Epoch: 5| Step: 8
Training loss: 0.6576309204101562
Validation loss: 2.0109133819739022

Epoch: 5| Step: 9
Training loss: 0.5143946409225464
Validation loss: 2.0106811126073203

Epoch: 5| Step: 10
Training loss: 1.0166434049606323
Validation loss: 1.969032461444537

Epoch: 5| Step: 11
Training loss: 0.47976136207580566
Validation loss: 2.0035363783439

Epoch: 207| Step: 0
Training loss: 1.2936627864837646
Validation loss: 2.0150234450896582

Epoch: 5| Step: 1
Training loss: 0.947331428527832
Validation loss: 2.0060985585053763

Epoch: 5| Step: 2
Training loss: 0.952563464641571
Validation loss: 2.018893947203954

Epoch: 5| Step: 3
Training loss: 0.8751217126846313
Validation loss: 2.048357605934143

Epoch: 5| Step: 4
Training loss: 0.9583092927932739
Validation loss: 1.98524276415507

Epoch: 5| Step: 5
Training loss: 0.7579503655433655
Validation loss: 1.9970695674419403

Epoch: 5| Step: 6
Training loss: 1.246246337890625
Validation loss: 1.9842710345983505

Epoch: 5| Step: 7
Training loss: 0.9620529413223267
Validation loss: 1.974242851138115

Epoch: 5| Step: 8
Training loss: 0.7394781112670898
Validation loss: 2.0389002561569214

Epoch: 5| Step: 9
Training loss: 0.6342978477478027
Validation loss: 2.0200644731521606

Epoch: 5| Step: 10
Training loss: 0.8972430229187012
Validation loss: 1.9933112214008968

Epoch: 5| Step: 11
Training loss: 0.47810161113739014
Validation loss: 1.9861546903848648

Epoch: 208| Step: 0
Training loss: 0.8298853039741516
Validation loss: 1.983668585618337

Epoch: 5| Step: 1
Training loss: 0.6609594225883484
Validation loss: 1.9755575408538182

Epoch: 5| Step: 2
Training loss: 0.6239579319953918
Validation loss: 1.968007688721021

Epoch: 5| Step: 3
Training loss: 1.021202802658081
Validation loss: 2.0098150918881097

Epoch: 5| Step: 4
Training loss: 1.2033182382583618
Validation loss: 1.9860244989395142

Epoch: 5| Step: 5
Training loss: 0.9228722453117371
Validation loss: 2.036352808276812

Epoch: 5| Step: 6
Training loss: 0.7573224306106567
Validation loss: 2.010509724418322

Epoch: 5| Step: 7
Training loss: 1.0066242218017578
Validation loss: 2.0188651432593665

Epoch: 5| Step: 8
Training loss: 0.6948448419570923
Validation loss: 2.030823061863581

Epoch: 5| Step: 9
Training loss: 0.4450598359107971
Validation loss: 1.9906027068694432

Epoch: 5| Step: 10
Training loss: 0.865388035774231
Validation loss: 1.9859326084454854

Epoch: 5| Step: 11
Training loss: 1.1061429977416992
Validation loss: 2.0448553562164307

Epoch: 209| Step: 0
Training loss: 0.45774561166763306
Validation loss: 2.0074148873488107

Epoch: 5| Step: 1
Training loss: 0.7163437604904175
Validation loss: 2.011399984359741

Epoch: 5| Step: 2
Training loss: 1.0066038370132446
Validation loss: 2.0369980881611505

Epoch: 5| Step: 3
Training loss: 0.5433414578437805
Validation loss: 2.0213422576586404

Epoch: 5| Step: 4
Training loss: 0.4581436216831207
Validation loss: 2.0323092341423035

Epoch: 5| Step: 5
Training loss: 0.6180854439735413
Validation loss: 2.0177170683940253

Epoch: 5| Step: 6
Training loss: 0.901909351348877
Validation loss: 2.006010135014852

Epoch: 5| Step: 7
Training loss: 1.3626396656036377
Validation loss: 2.0183341999848685

Epoch: 5| Step: 8
Training loss: 0.8193413019180298
Validation loss: 2.025747691591581

Epoch: 5| Step: 9
Training loss: 0.765461266040802
Validation loss: 2.032316784063975

Epoch: 5| Step: 10
Training loss: 1.245274305343628
Validation loss: 2.0066378712654114

Epoch: 5| Step: 11
Training loss: 1.2104427814483643
Validation loss: 2.0020812352498374

Epoch: 210| Step: 0
Training loss: 0.573579728603363
Validation loss: 2.0245036482810974

Epoch: 5| Step: 1
Training loss: 0.661522626876831
Validation loss: 2.0388793845971427

Epoch: 5| Step: 2
Training loss: 0.6138353943824768
Validation loss: 2.0159109036127725

Epoch: 5| Step: 3
Training loss: 1.019775152206421
Validation loss: 1.998951032757759

Epoch: 5| Step: 4
Training loss: 0.7442890405654907
Validation loss: 2.031910315155983

Epoch: 5| Step: 5
Training loss: 0.6911361217498779
Validation loss: 1.996391882499059

Epoch: 5| Step: 6
Training loss: 0.44737520813941956
Validation loss: 2.0229362746079764

Epoch: 5| Step: 7
Training loss: 0.785699725151062
Validation loss: 2.0257524847984314

Epoch: 5| Step: 8
Training loss: 0.9824950098991394
Validation loss: 2.031361331542333

Epoch: 5| Step: 9
Training loss: 1.618546724319458
Validation loss: 1.9935890684525173

Epoch: 5| Step: 10
Training loss: 0.6668583154678345
Validation loss: 2.000989173849424

Epoch: 5| Step: 11
Training loss: 0.6038985252380371
Validation loss: 2.000807742277781

Epoch: 211| Step: 0
Training loss: 0.7930761575698853
Validation loss: 1.9836319933334987

Epoch: 5| Step: 1
Training loss: 0.5545797348022461
Validation loss: 2.020265976587931

Epoch: 5| Step: 2
Training loss: 0.6418209075927734
Validation loss: 1.9914033462603886

Epoch: 5| Step: 3
Training loss: 0.9724113345146179
Validation loss: 2.0011009871959686

Epoch: 5| Step: 4
Training loss: 0.9286203384399414
Validation loss: 1.9845639020204544

Epoch: 5| Step: 5
Training loss: 1.0475637912750244
Validation loss: 1.9978231489658356

Epoch: 5| Step: 6
Training loss: 0.9158436059951782
Validation loss: 2.013812616467476

Epoch: 5| Step: 7
Training loss: 1.2539691925048828
Validation loss: 2.020650267601013

Epoch: 5| Step: 8
Training loss: 0.6057883501052856
Validation loss: 2.024553194642067

Epoch: 5| Step: 9
Training loss: 0.7042057514190674
Validation loss: 2.035303125778834

Epoch: 5| Step: 10
Training loss: 0.6945446729660034
Validation loss: 2.0330110490322113

Epoch: 5| Step: 11
Training loss: 0.9072896242141724
Validation loss: 2.003064920504888

Epoch: 212| Step: 0
Training loss: 0.8269364237785339
Validation loss: 2.0114664832750955

Epoch: 5| Step: 1
Training loss: 0.9946797490119934
Validation loss: 2.04329381386439

Epoch: 5| Step: 2
Training loss: 1.1393457651138306
Validation loss: 2.090150753657023

Epoch: 5| Step: 3
Training loss: 1.3568811416625977
Validation loss: 2.0689330995082855

Epoch: 5| Step: 4
Training loss: 0.9434887766838074
Validation loss: 2.0645712117354074

Epoch: 5| Step: 5
Training loss: 0.5165015459060669
Validation loss: 1.9934210081895192

Epoch: 5| Step: 6
Training loss: 0.9689094424247742
Validation loss: 2.029715766509374

Epoch: 5| Step: 7
Training loss: 0.8271800875663757
Validation loss: 2.0096771170695624

Epoch: 5| Step: 8
Training loss: 0.4682203233242035
Validation loss: 2.0311751862366996

Epoch: 5| Step: 9
Training loss: 0.7076676487922668
Validation loss: 2.0528553426265717

Epoch: 5| Step: 10
Training loss: 1.166011929512024
Validation loss: 2.080944836139679

Epoch: 5| Step: 11
Training loss: 0.2878861427307129
Validation loss: 2.050303449233373

Epoch: 213| Step: 0
Training loss: 0.9933384656906128
Validation loss: 2.0018172363440194

Epoch: 5| Step: 1
Training loss: 1.1411514282226562
Validation loss: 2.0197763890028

Epoch: 5| Step: 2
Training loss: 0.6997113823890686
Validation loss: 1.9765719920396805

Epoch: 5| Step: 3
Training loss: 0.581147313117981
Validation loss: 2.014075035850207

Epoch: 5| Step: 4
Training loss: 0.8763093948364258
Validation loss: 2.041298598051071

Epoch: 5| Step: 5
Training loss: 0.9048444628715515
Validation loss: 2.036522939801216

Epoch: 5| Step: 6
Training loss: 0.8287056684494019
Validation loss: 2.046662757794062

Epoch: 5| Step: 7
Training loss: 0.6464072465896606
Validation loss: 2.0155527591705322

Epoch: 5| Step: 8
Training loss: 1.1089622974395752
Validation loss: 2.0237915962934494

Epoch: 5| Step: 9
Training loss: 0.823361873626709
Validation loss: 2.0022527476151786

Epoch: 5| Step: 10
Training loss: 0.5315908193588257
Validation loss: 2.0350223233302436

Epoch: 5| Step: 11
Training loss: 0.05989652872085571
Validation loss: 1.9980136901140213

Epoch: 214| Step: 0
Training loss: 0.4760317802429199
Validation loss: 2.025355418523153

Epoch: 5| Step: 1
Training loss: 0.7693101167678833
Validation loss: 2.0317329367001853

Epoch: 5| Step: 2
Training loss: 0.68639075756073
Validation loss: 2.007083843151728

Epoch: 5| Step: 3
Training loss: 1.0296717882156372
Validation loss: 2.040579378604889

Epoch: 5| Step: 4
Training loss: 0.35047346353530884
Validation loss: 2.0233087490002313

Epoch: 5| Step: 5
Training loss: 1.1663649082183838
Validation loss: 2.0170565843582153

Epoch: 5| Step: 6
Training loss: 0.71782386302948
Validation loss: 2.019808903336525

Epoch: 5| Step: 7
Training loss: 0.7019420862197876
Validation loss: 2.0086980561415353

Epoch: 5| Step: 8
Training loss: 1.1344226598739624
Validation loss: 2.032863919933637

Epoch: 5| Step: 9
Training loss: 1.0222796201705933
Validation loss: 2.0209954281648

Epoch: 5| Step: 10
Training loss: 0.9750115275382996
Validation loss: 2.025036816795667

Epoch: 5| Step: 11
Training loss: 0.10511216521263123
Validation loss: 2.004928549130758

Epoch: 215| Step: 0
Training loss: 1.0898799896240234
Validation loss: 2.022735113898913

Epoch: 5| Step: 1
Training loss: 1.418933391571045
Validation loss: 2.0414320528507233

Epoch: 5| Step: 2
Training loss: 0.9125978350639343
Validation loss: 2.004653126001358

Epoch: 5| Step: 3
Training loss: 0.8177057504653931
Validation loss: 2.0253435919682183

Epoch: 5| Step: 4
Training loss: 0.7884753346443176
Validation loss: 2.0679797927538552

Epoch: 5| Step: 5
Training loss: 0.7542134523391724
Validation loss: 2.0159457325935364

Epoch: 5| Step: 6
Training loss: 0.5861219167709351
Validation loss: 2.0185500532388687

Epoch: 5| Step: 7
Training loss: 0.6486166715621948
Validation loss: 2.0231542189915976

Epoch: 5| Step: 8
Training loss: 0.6005544662475586
Validation loss: 2.011921872695287

Epoch: 5| Step: 9
Training loss: 0.7324262857437134
Validation loss: 2.0313452978928885

Epoch: 5| Step: 10
Training loss: 0.8679336309432983
Validation loss: 2.0123916963736215

Epoch: 5| Step: 11
Training loss: 1.1695046424865723
Validation loss: 2.0440654903650284

Epoch: 216| Step: 0
Training loss: 0.9661453366279602
Validation loss: 2.0211446235577264

Epoch: 5| Step: 1
Training loss: 1.0732574462890625
Validation loss: 2.0041897296905518

Epoch: 5| Step: 2
Training loss: 0.5524591207504272
Validation loss: 2.0063135574261346

Epoch: 5| Step: 3
Training loss: 1.0017036199569702
Validation loss: 1.9952056060234706

Epoch: 5| Step: 4
Training loss: 0.8314508199691772
Validation loss: 1.9870777974526088

Epoch: 5| Step: 5
Training loss: 0.5636237859725952
Validation loss: 2.0205107827981315

Epoch: 5| Step: 6
Training loss: 0.8841608166694641
Validation loss: 1.9994969268639882

Epoch: 5| Step: 7
Training loss: 1.0769304037094116
Validation loss: 1.9892519911130269

Epoch: 5| Step: 8
Training loss: 0.5583774447441101
Validation loss: 2.036887288093567

Epoch: 5| Step: 9
Training loss: 0.8150073289871216
Validation loss: 1.9927161534627278

Epoch: 5| Step: 10
Training loss: 0.4690015912055969
Validation loss: 2.0325749963521957

Epoch: 5| Step: 11
Training loss: 1.1077561378479004
Validation loss: 2.0302767753601074

Epoch: 217| Step: 0
Training loss: 0.5407378077507019
Validation loss: 2.021126056710879

Epoch: 5| Step: 1
Training loss: 0.80775386095047
Validation loss: 2.0326548169056573

Epoch: 5| Step: 2
Training loss: 0.961469292640686
Validation loss: 1.9984818696975708

Epoch: 5| Step: 3
Training loss: 0.8105441927909851
Validation loss: 2.0066430419683456

Epoch: 5| Step: 4
Training loss: 0.8250023126602173
Validation loss: 1.9829316784938176

Epoch: 5| Step: 5
Training loss: 0.8292175531387329
Validation loss: 2.0386342306931815

Epoch: 5| Step: 6
Training loss: 0.7863849401473999
Validation loss: 1.9902553011973698

Epoch: 5| Step: 7
Training loss: 0.8528143763542175
Validation loss: 2.0307716031869254

Epoch: 5| Step: 8
Training loss: 0.873977541923523
Validation loss: 2.0375896046559014

Epoch: 5| Step: 9
Training loss: 0.9312760233879089
Validation loss: 2.0405526409546533

Epoch: 5| Step: 10
Training loss: 0.3446079194545746
Validation loss: 2.0233018646637597

Epoch: 5| Step: 11
Training loss: 1.9074956178665161
Validation loss: 2.0200037956237793

Epoch: 218| Step: 0
Training loss: 0.5362100601196289
Validation loss: 2.0387022346258163

Epoch: 5| Step: 1
Training loss: 0.683140754699707
Validation loss: 2.0379996498425803

Epoch: 5| Step: 2
Training loss: 1.0985933542251587
Validation loss: 2.0161409129699073

Epoch: 5| Step: 3
Training loss: 0.7627846002578735
Validation loss: 1.9943002263704936

Epoch: 5| Step: 4
Training loss: 0.8664665222167969
Validation loss: 2.0097016046444574

Epoch: 5| Step: 5
Training loss: 0.3656948208808899
Validation loss: 2.0107109944025674

Epoch: 5| Step: 6
Training loss: 0.8285033106803894
Validation loss: 2.0302970707416534

Epoch: 5| Step: 7
Training loss: 0.8794828653335571
Validation loss: 2.0119157135486603

Epoch: 5| Step: 8
Training loss: 0.5350078344345093
Validation loss: 1.9931738475958507

Epoch: 5| Step: 9
Training loss: 1.1923933029174805
Validation loss: 1.9826896985371907

Epoch: 5| Step: 10
Training loss: 0.8450322151184082
Validation loss: 2.030681620041529

Epoch: 5| Step: 11
Training loss: 0.15817022323608398
Validation loss: 2.0104622840881348

Epoch: 219| Step: 0
Training loss: 0.47102922201156616
Validation loss: 1.9876709977785747

Epoch: 5| Step: 1
Training loss: 0.9936712980270386
Validation loss: 2.045891617735227

Epoch: 5| Step: 2
Training loss: 0.9619284868240356
Validation loss: 2.015589868028959

Epoch: 5| Step: 3
Training loss: 0.7977913022041321
Validation loss: 2.029185190796852

Epoch: 5| Step: 4
Training loss: 0.814433217048645
Validation loss: 2.04309518635273

Epoch: 5| Step: 5
Training loss: 0.8075008392333984
Validation loss: 2.0675042817989984

Epoch: 5| Step: 6
Training loss: 1.093595266342163
Validation loss: 1.9996295968691509

Epoch: 5| Step: 7
Training loss: 0.6806820034980774
Validation loss: 1.9919262329737346

Epoch: 5| Step: 8
Training loss: 0.3650504946708679
Validation loss: 1.9804866562287013

Epoch: 5| Step: 9
Training loss: 0.8633554577827454
Validation loss: 2.0175991555054984

Epoch: 5| Step: 10
Training loss: 0.3798971474170685
Validation loss: 2.031348461906115

Epoch: 5| Step: 11
Training loss: 0.947466254234314
Validation loss: 1.9955762475728989

Epoch: 220| Step: 0
Training loss: 0.7329007387161255
Validation loss: 1.9924979954957962

Epoch: 5| Step: 1
Training loss: 0.6525422930717468
Validation loss: 2.005345250169436

Epoch: 5| Step: 2
Training loss: 0.9218557476997375
Validation loss: 2.027041474978129

Epoch: 5| Step: 3
Training loss: 0.8337001800537109
Validation loss: 2.039871876438459

Epoch: 5| Step: 4
Training loss: 0.8187613487243652
Validation loss: 2.0087745785713196

Epoch: 5| Step: 5
Training loss: 0.8371552228927612
Validation loss: 2.037323455015818

Epoch: 5| Step: 6
Training loss: 0.822501540184021
Validation loss: 1.9822663515806198

Epoch: 5| Step: 7
Training loss: 0.6452590227127075
Validation loss: 2.0184724728266397

Epoch: 5| Step: 8
Training loss: 0.8102361559867859
Validation loss: 2.0003343572219214

Epoch: 5| Step: 9
Training loss: 1.0115219354629517
Validation loss: 2.0069788644711175

Epoch: 5| Step: 10
Training loss: 0.5659575462341309
Validation loss: 2.0181670089562735

Epoch: 5| Step: 11
Training loss: 0.7456842660903931
Validation loss: 2.019713838895162

Epoch: 221| Step: 0
Training loss: 0.6529136896133423
Validation loss: 2.0550474375486374

Epoch: 5| Step: 1
Training loss: 0.6590404510498047
Validation loss: 2.0442889034748077

Epoch: 5| Step: 2
Training loss: 0.864540696144104
Validation loss: 2.0208534002304077

Epoch: 5| Step: 3
Training loss: 0.5608621835708618
Validation loss: 2.0461489061514535

Epoch: 5| Step: 4
Training loss: 0.8743240237236023
Validation loss: 2.0292663474877677

Epoch: 5| Step: 5
Training loss: 0.4189167022705078
Validation loss: 2.055409943064054

Epoch: 5| Step: 6
Training loss: 0.48163071274757385
Validation loss: 2.0480312953392663

Epoch: 5| Step: 7
Training loss: 0.8669593930244446
Validation loss: 2.0310583412647247

Epoch: 5| Step: 8
Training loss: 0.7215173244476318
Validation loss: 2.005871663490931

Epoch: 5| Step: 9
Training loss: 1.2058687210083008
Validation loss: 2.044601336121559

Epoch: 5| Step: 10
Training loss: 1.2327191829681396
Validation loss: 2.011800949772199

Epoch: 5| Step: 11
Training loss: 0.5278453826904297
Validation loss: 2.048303544521332

Epoch: 222| Step: 0
Training loss: 0.6759656667709351
Validation loss: 2.0547081927458444

Epoch: 5| Step: 1
Training loss: 0.5206230878829956
Validation loss: 2.021566023429235

Epoch: 5| Step: 2
Training loss: 0.708724856376648
Validation loss: 2.033598189552625

Epoch: 5| Step: 3
Training loss: 1.2301981449127197
Validation loss: 2.041048084696134

Epoch: 5| Step: 4
Training loss: 0.7648671865463257
Validation loss: 2.060961753129959

Epoch: 5| Step: 5
Training loss: 0.8904140591621399
Validation loss: 2.072815885146459

Epoch: 5| Step: 6
Training loss: 1.130219578742981
Validation loss: 2.033785030245781

Epoch: 5| Step: 7
Training loss: 0.7803192138671875
Validation loss: 2.0236823012431464

Epoch: 5| Step: 8
Training loss: 0.4935963749885559
Validation loss: 2.0661774625380835

Epoch: 5| Step: 9
Training loss: 0.6096888780593872
Validation loss: 2.051725218693415

Epoch: 5| Step: 10
Training loss: 0.8584243655204773
Validation loss: 2.0195618073145547

Epoch: 5| Step: 11
Training loss: 0.6845748424530029
Validation loss: 2.067243129014969

Epoch: 223| Step: 0
Training loss: 0.6736925840377808
Validation loss: 2.0346104502677917

Epoch: 5| Step: 1
Training loss: 0.29116639494895935
Validation loss: 2.057939504583677

Epoch: 5| Step: 2
Training loss: 1.3136398792266846
Validation loss: 2.0368831108013787

Epoch: 5| Step: 3
Training loss: 0.8434485197067261
Validation loss: 2.0370167891184487

Epoch: 5| Step: 4
Training loss: 0.5909318923950195
Validation loss: 2.0089602967103324

Epoch: 5| Step: 5
Training loss: 0.40681329369544983
Validation loss: 2.000729943315188

Epoch: 5| Step: 6
Training loss: 0.7608383893966675
Validation loss: 2.03543950120608

Epoch: 5| Step: 7
Training loss: 0.8691893815994263
Validation loss: 2.027866785724958

Epoch: 5| Step: 8
Training loss: 0.9344288110733032
Validation loss: 2.0321310261885324

Epoch: 5| Step: 9
Training loss: 1.0095726251602173
Validation loss: 2.0290017972389855

Epoch: 5| Step: 10
Training loss: 0.7398327589035034
Validation loss: 2.0266454219818115

Epoch: 5| Step: 11
Training loss: 1.4696611166000366
Validation loss: 2.004363397757212

Epoch: 224| Step: 0
Training loss: 0.7799086570739746
Validation loss: 2.005828320980072

Epoch: 5| Step: 1
Training loss: 0.3645133972167969
Validation loss: 2.0314298619826636

Epoch: 5| Step: 2
Training loss: 0.8367698788642883
Validation loss: 2.035472651322683

Epoch: 5| Step: 3
Training loss: 0.5713224411010742
Validation loss: 2.0491221050421395

Epoch: 5| Step: 4
Training loss: 1.0734037160873413
Validation loss: 2.0703436036904654

Epoch: 5| Step: 5
Training loss: 0.87786865234375
Validation loss: 2.0723632474740348

Epoch: 5| Step: 6
Training loss: 1.197831153869629
Validation loss: 2.075377648075422

Epoch: 5| Step: 7
Training loss: 0.5786535739898682
Validation loss: 2.051783243815104

Epoch: 5| Step: 8
Training loss: 0.9025564193725586
Validation loss: 2.0301440407832465

Epoch: 5| Step: 9
Training loss: 0.6030657887458801
Validation loss: 2.04328516125679

Epoch: 5| Step: 10
Training loss: 0.7603351473808289
Validation loss: 2.050495227177938

Epoch: 5| Step: 11
Training loss: 1.195190668106079
Validation loss: 2.018593579530716

Epoch: 225| Step: 0
Training loss: 0.4953555166721344
Validation loss: 2.034235139687856

Epoch: 5| Step: 1
Training loss: 0.6638156175613403
Validation loss: 2.017759104569753

Epoch: 5| Step: 2
Training loss: 0.8802775144577026
Validation loss: 2.098964477578799

Epoch: 5| Step: 3
Training loss: 0.7892786860466003
Validation loss: 2.054840346177419

Epoch: 5| Step: 4
Training loss: 1.1125010251998901
Validation loss: 2.0446769247452417

Epoch: 5| Step: 5
Training loss: 0.5710258483886719
Validation loss: 2.0280046860376992

Epoch: 5| Step: 6
Training loss: 0.6983288526535034
Validation loss: 2.0137960563103356

Epoch: 5| Step: 7
Training loss: 0.6492577195167542
Validation loss: 2.0112729569276175

Epoch: 5| Step: 8
Training loss: 0.7610689997673035
Validation loss: 2.0172095646460853

Epoch: 5| Step: 9
Training loss: 0.7758884429931641
Validation loss: 2.0213279724121094

Epoch: 5| Step: 10
Training loss: 1.1431138515472412
Validation loss: 2.0265674690405526

Epoch: 5| Step: 11
Training loss: 0.42818331718444824
Validation loss: 1.9887300878763199

Epoch: 226| Step: 0
Training loss: 1.1517343521118164
Validation loss: 2.0145230293273926

Epoch: 5| Step: 1
Training loss: 1.1127233505249023
Validation loss: 2.048303117354711

Epoch: 5| Step: 2
Training loss: 1.1086162328720093
Validation loss: 2.011799077192942

Epoch: 5| Step: 3
Training loss: 0.9074671864509583
Validation loss: 2.024726693828901

Epoch: 5| Step: 4
Training loss: 0.4575102925300598
Validation loss: 2.050305277109146

Epoch: 5| Step: 5
Training loss: 1.0396119356155396
Validation loss: 2.030982658267021

Epoch: 5| Step: 6
Training loss: 0.3213261067867279
Validation loss: 2.006657123565674

Epoch: 5| Step: 7
Training loss: 0.8070642352104187
Validation loss: 2.0184217592080436

Epoch: 5| Step: 8
Training loss: 0.5175662636756897
Validation loss: 2.0286779205004373

Epoch: 5| Step: 9
Training loss: 0.7154257893562317
Validation loss: 2.0140707343816757

Epoch: 5| Step: 10
Training loss: 0.6676527261734009
Validation loss: 2.0290274620056152

Epoch: 5| Step: 11
Training loss: 0.18256545066833496
Validation loss: 1.9849139402310054

Epoch: 227| Step: 0
Training loss: 0.7544211745262146
Validation loss: 2.02286688486735

Epoch: 5| Step: 1
Training loss: 0.4263245463371277
Validation loss: 1.9822561393181484

Epoch: 5| Step: 2
Training loss: 0.987979531288147
Validation loss: 1.9990449647108715

Epoch: 5| Step: 3
Training loss: 0.9722518920898438
Validation loss: 2.033253644903501

Epoch: 5| Step: 4
Training loss: 0.872011661529541
Validation loss: 2.0475684255361557

Epoch: 5| Step: 5
Training loss: 0.6531741619110107
Validation loss: 2.033167084058126

Epoch: 5| Step: 6
Training loss: 0.4213288426399231
Validation loss: 2.0315414319435754

Epoch: 5| Step: 7
Training loss: 0.46536073088645935
Validation loss: 2.0379994064569473

Epoch: 5| Step: 8
Training loss: 0.4958565831184387
Validation loss: 2.0258907973766327

Epoch: 5| Step: 9
Training loss: 1.2098848819732666
Validation loss: 2.026308720310529

Epoch: 5| Step: 10
Training loss: 1.0156495571136475
Validation loss: 2.048071642716726

Epoch: 5| Step: 11
Training loss: 0.5050008296966553
Validation loss: 2.018323168158531

Epoch: 228| Step: 0
Training loss: 0.6344335079193115
Validation loss: 2.0184365759293237

Epoch: 5| Step: 1
Training loss: 0.33667460083961487
Validation loss: 2.0097995648781457

Epoch: 5| Step: 2
Training loss: 0.9962136149406433
Validation loss: 2.0354863107204437

Epoch: 5| Step: 3
Training loss: 0.8369737863540649
Validation loss: 2.04532682398955

Epoch: 5| Step: 4
Training loss: 0.6772419214248657
Validation loss: 2.0036424100399017

Epoch: 5| Step: 5
Training loss: 1.0183168649673462
Validation loss: 2.070189451177915

Epoch: 5| Step: 6
Training loss: 0.9183588027954102
Validation loss: 1.9866650501887004

Epoch: 5| Step: 7
Training loss: 0.8709880709648132
Validation loss: 1.9967029988765717

Epoch: 5| Step: 8
Training loss: 0.5767045617103577
Validation loss: 2.022182822227478

Epoch: 5| Step: 9
Training loss: 1.042769432067871
Validation loss: 2.020776708920797

Epoch: 5| Step: 10
Training loss: 0.6720434427261353
Validation loss: 2.0086640069882074

Epoch: 5| Step: 11
Training loss: 1.1815818548202515
Validation loss: 2.057969177762667

Epoch: 229| Step: 0
Training loss: 0.9348995089530945
Validation loss: 2.0333097825447717

Epoch: 5| Step: 1
Training loss: 0.8937959671020508
Validation loss: 2.0147612392902374

Epoch: 5| Step: 2
Training loss: 0.7262903451919556
Validation loss: 1.9938641587893169

Epoch: 5| Step: 3
Training loss: 0.8959323763847351
Validation loss: 2.007653762896856

Epoch: 5| Step: 4
Training loss: 0.847547709941864
Validation loss: 2.007553363839785

Epoch: 5| Step: 5
Training loss: 0.5671537518501282
Validation loss: 2.013266166051229

Epoch: 5| Step: 6
Training loss: 0.6742836833000183
Validation loss: 2.0083070347706475

Epoch: 5| Step: 7
Training loss: 0.8490419387817383
Validation loss: 2.0099268158276877

Epoch: 5| Step: 8
Training loss: 0.5643023252487183
Validation loss: 2.0079625298579535

Epoch: 5| Step: 9
Training loss: 0.6735116243362427
Validation loss: 2.040122469266256

Epoch: 5| Step: 10
Training loss: 0.8171161413192749
Validation loss: 2.0269945561885834

Epoch: 5| Step: 11
Training loss: 0.9251188039779663
Validation loss: 2.064469650387764

Epoch: 230| Step: 0
Training loss: 0.6996220946311951
Validation loss: 1.997035230199496

Epoch: 5| Step: 1
Training loss: 1.0611332654953003
Validation loss: 2.001562148332596

Epoch: 5| Step: 2
Training loss: 0.32919296622276306
Validation loss: 2.0086059967676797

Epoch: 5| Step: 3
Training loss: 1.036210298538208
Validation loss: 2.0283307234446206

Epoch: 5| Step: 4
Training loss: 0.8203562498092651
Validation loss: 2.035771628220876

Epoch: 5| Step: 5
Training loss: 1.149401307106018
Validation loss: 2.0184797048568726

Epoch: 5| Step: 6
Training loss: 0.9553951025009155
Validation loss: 2.0487153430779776

Epoch: 5| Step: 7
Training loss: 0.7533572316169739
Validation loss: 2.0491486489772797

Epoch: 5| Step: 8
Training loss: 0.6514171361923218
Validation loss: 2.0628567934036255

Epoch: 5| Step: 9
Training loss: 0.43235865235328674
Validation loss: 1.9985104997952778

Epoch: 5| Step: 10
Training loss: 0.4871393144130707
Validation loss: 1.9945072333017986

Epoch: 5| Step: 11
Training loss: 0.5553510785102844
Validation loss: 2.024719630678495

Epoch: 231| Step: 0
Training loss: 0.6832493543624878
Validation loss: 2.03314579029878

Epoch: 5| Step: 1
Training loss: 0.8752225637435913
Validation loss: 2.051852891842524

Epoch: 5| Step: 2
Training loss: 1.1357858180999756
Validation loss: 2.0070443650086722

Epoch: 5| Step: 3
Training loss: 0.7003127932548523
Validation loss: 2.021888335545858

Epoch: 5| Step: 4
Training loss: 0.6923073530197144
Validation loss: 2.015465001265208

Epoch: 5| Step: 5
Training loss: 0.8094102740287781
Validation loss: 2.0307695865631104

Epoch: 5| Step: 6
Training loss: 0.44392576813697815
Validation loss: 2.0265311201413474

Epoch: 5| Step: 7
Training loss: 0.4014131426811218
Validation loss: 2.0530881136655807

Epoch: 5| Step: 8
Training loss: 0.44228118658065796
Validation loss: 2.011702467997869

Epoch: 5| Step: 9
Training loss: 0.6571957468986511
Validation loss: 2.011295328537623

Epoch: 5| Step: 10
Training loss: 1.3755635023117065
Validation loss: 2.001027926802635

Epoch: 5| Step: 11
Training loss: 0.17133110761642456
Validation loss: 2.0048221548398337

Epoch: 232| Step: 0
Training loss: 0.7818695306777954
Validation loss: 2.062805657585462

Epoch: 5| Step: 1
Training loss: 0.6777269244194031
Validation loss: 2.0466337154308953

Epoch: 5| Step: 2
Training loss: 1.1829923391342163
Validation loss: 1.9939280847708385

Epoch: 5| Step: 3
Training loss: 0.25290945172309875
Validation loss: 1.9991636822621028

Epoch: 5| Step: 4
Training loss: 0.6132692098617554
Validation loss: 2.020348916451136

Epoch: 5| Step: 5
Training loss: 0.689287006855011
Validation loss: 2.0110920568307242

Epoch: 5| Step: 6
Training loss: 0.719294548034668
Validation loss: 2.0438819577296576

Epoch: 5| Step: 7
Training loss: 0.37571272253990173
Validation loss: 2.0135782063007355

Epoch: 5| Step: 8
Training loss: 1.3735851049423218
Validation loss: 2.0415127128362656

Epoch: 5| Step: 9
Training loss: 0.924116313457489
Validation loss: 2.0068890353043876

Epoch: 5| Step: 10
Training loss: 0.5831429362297058
Validation loss: 2.0515103737513223

Epoch: 5| Step: 11
Training loss: 1.194676160812378
Validation loss: 2.0495646248261132

Epoch: 233| Step: 0
Training loss: 1.0823733806610107
Validation loss: 2.0195139398177466

Epoch: 5| Step: 1
Training loss: 0.712871253490448
Validation loss: 2.034225508570671

Epoch: 5| Step: 2
Training loss: 0.8874908685684204
Validation loss: 2.0827269355456033

Epoch: 5| Step: 3
Training loss: 0.619604766368866
Validation loss: 2.029301345348358

Epoch: 5| Step: 4
Training loss: 0.658819854259491
Validation loss: 2.082499543825785

Epoch: 5| Step: 5
Training loss: 0.3111373782157898
Validation loss: 2.0286498914162316

Epoch: 5| Step: 6
Training loss: 1.0378036499023438
Validation loss: 2.0214565644661584

Epoch: 5| Step: 7
Training loss: 0.646314799785614
Validation loss: 2.0330242266257605

Epoch: 5| Step: 8
Training loss: 0.6481791734695435
Validation loss: 1.996656984090805

Epoch: 5| Step: 9
Training loss: 0.872376561164856
Validation loss: 2.019176627198855

Epoch: 5| Step: 10
Training loss: 0.5686753988265991
Validation loss: 2.070512374242147

Epoch: 5| Step: 11
Training loss: 0.15498533844947815
Validation loss: 2.060758958260218

Epoch: 234| Step: 0
Training loss: 0.6180367469787598
Validation loss: 2.06008180975914

Epoch: 5| Step: 1
Training loss: 0.4643773138523102
Validation loss: 2.076845129330953

Epoch: 5| Step: 2
Training loss: 1.0739915370941162
Validation loss: 2.078668306271235

Epoch: 5| Step: 3
Training loss: 0.8787223696708679
Validation loss: 2.042999083797137

Epoch: 5| Step: 4
Training loss: 0.4923035502433777
Validation loss: 2.040773242712021

Epoch: 5| Step: 5
Training loss: 0.762292742729187
Validation loss: 2.0450524985790253

Epoch: 5| Step: 6
Training loss: 0.6005096435546875
Validation loss: 2.0825975835323334

Epoch: 5| Step: 7
Training loss: 0.7080749869346619
Validation loss: 2.0390085726976395

Epoch: 5| Step: 8
Training loss: 0.6262506246566772
Validation loss: 2.0323021511236825

Epoch: 5| Step: 9
Training loss: 0.8295713663101196
Validation loss: 2.052758182088534

Epoch: 5| Step: 10
Training loss: 0.9605234265327454
Validation loss: 2.025919089714686

Epoch: 5| Step: 11
Training loss: 0.8627514243125916
Validation loss: 2.033596009016037

Epoch: 235| Step: 0
Training loss: 0.8094087839126587
Validation loss: 2.0628024140993753

Epoch: 5| Step: 1
Training loss: 0.6425365805625916
Validation loss: 2.042110428214073

Epoch: 5| Step: 2
Training loss: 0.7456915974617004
Validation loss: 2.0746738463640213

Epoch: 5| Step: 3
Training loss: 1.0124585628509521
Validation loss: 2.0689247896273932

Epoch: 5| Step: 4
Training loss: 0.6813521385192871
Validation loss: 2.009147420525551

Epoch: 5| Step: 5
Training loss: 0.5308178663253784
Validation loss: 2.0319007635116577

Epoch: 5| Step: 6
Training loss: 0.5526245832443237
Validation loss: 2.0340524365504584

Epoch: 5| Step: 7
Training loss: 0.8152639269828796
Validation loss: 2.0510602047046027

Epoch: 5| Step: 8
Training loss: 1.278900384902954
Validation loss: 2.0764922201633453

Epoch: 5| Step: 9
Training loss: 0.5060588121414185
Validation loss: 2.0215286165475845

Epoch: 5| Step: 10
Training loss: 0.47279787063598633
Validation loss: 1.9799349705378215

Epoch: 5| Step: 11
Training loss: 0.3480086922645569
Validation loss: 2.0617981453736625

Epoch: 236| Step: 0
Training loss: 0.7004944682121277
Validation loss: 2.03103935221831

Epoch: 5| Step: 1
Training loss: 0.8521021008491516
Validation loss: 2.0746369063854218

Epoch: 5| Step: 2
Training loss: 0.8444496393203735
Validation loss: 2.0634196748336158

Epoch: 5| Step: 3
Training loss: 0.6441962122917175
Validation loss: 2.019853577017784

Epoch: 5| Step: 4
Training loss: 0.5686362385749817
Validation loss: 2.0116844524939856

Epoch: 5| Step: 5
Training loss: 0.8654600381851196
Validation loss: 2.0377602924903235

Epoch: 5| Step: 6
Training loss: 0.48679178953170776
Validation loss: 2.0071275482575097

Epoch: 5| Step: 7
Training loss: 0.9209701418876648
Validation loss: 2.022365987300873

Epoch: 5| Step: 8
Training loss: 0.4870133399963379
Validation loss: 2.043061892191569

Epoch: 5| Step: 9
Training loss: 0.9480450749397278
Validation loss: 2.0334588338931403

Epoch: 5| Step: 10
Training loss: 0.7270672917366028
Validation loss: 2.0025904327630997

Epoch: 5| Step: 11
Training loss: 0.3445360064506531
Validation loss: 2.021068568030993

Epoch: 237| Step: 0
Training loss: 0.9829667806625366
Validation loss: 2.091847057143847

Epoch: 5| Step: 1
Training loss: 0.800135612487793
Validation loss: 2.0870814422766366

Epoch: 5| Step: 2
Training loss: 0.7288833856582642
Validation loss: 2.092447573939959

Epoch: 5| Step: 3
Training loss: 0.8859626650810242
Validation loss: 2.0317357579867044

Epoch: 5| Step: 4
Training loss: 0.7717318534851074
Validation loss: 2.06109955906868

Epoch: 5| Step: 5
Training loss: 0.4391571879386902
Validation loss: 2.0278854171435037

Epoch: 5| Step: 6
Training loss: 0.3648453652858734
Validation loss: 2.0330892155567803

Epoch: 5| Step: 7
Training loss: 0.6429201364517212
Validation loss: 2.0418315728505454

Epoch: 5| Step: 8
Training loss: 0.6787621378898621
Validation loss: 2.075422858198484

Epoch: 5| Step: 9
Training loss: 1.1185544729232788
Validation loss: 2.054952561855316

Epoch: 5| Step: 10
Training loss: 0.6867340207099915
Validation loss: 2.0807229479153952

Epoch: 5| Step: 11
Training loss: 0.3980027437210083
Validation loss: 2.0090119590361915

Epoch: 238| Step: 0
Training loss: 0.45176181197166443
Validation loss: 2.055850028991699

Epoch: 5| Step: 1
Training loss: 0.7121320962905884
Validation loss: 2.04824664692084

Epoch: 5| Step: 2
Training loss: 0.7541230916976929
Validation loss: 2.0202291111151376

Epoch: 5| Step: 3
Training loss: 0.9421084523200989
Validation loss: 2.0382521748542786

Epoch: 5| Step: 4
Training loss: 0.6337632536888123
Validation loss: 2.0151741057634354

Epoch: 5| Step: 5
Training loss: 0.8099236488342285
Validation loss: 2.049174815416336

Epoch: 5| Step: 6
Training loss: 0.842745304107666
Validation loss: 2.075288623571396

Epoch: 5| Step: 7
Training loss: 0.5142549872398376
Validation loss: 2.087321932117144

Epoch: 5| Step: 8
Training loss: 0.8194265365600586
Validation loss: 2.0244948863983154

Epoch: 5| Step: 9
Training loss: 0.677208423614502
Validation loss: 2.064552595218023

Epoch: 5| Step: 10
Training loss: 0.46479368209838867
Validation loss: 2.0754680236180625

Epoch: 5| Step: 11
Training loss: 0.7707193493843079
Validation loss: 2.0598144829273224

Epoch: 239| Step: 0
Training loss: 0.9296923875808716
Validation loss: 2.045460045337677

Epoch: 5| Step: 1
Training loss: 0.6786297559738159
Validation loss: 2.0854803174734116

Epoch: 5| Step: 2
Training loss: 0.6066931486129761
Validation loss: 2.080627292394638

Epoch: 5| Step: 3
Training loss: 0.723073422908783
Validation loss: 2.0908248921235404

Epoch: 5| Step: 4
Training loss: 0.5645650029182434
Validation loss: 2.0713670949141183

Epoch: 5| Step: 5
Training loss: 0.8222658038139343
Validation loss: 2.0484926253557205

Epoch: 5| Step: 6
Training loss: 0.6931658983230591
Validation loss: 2.0461056480805078

Epoch: 5| Step: 7
Training loss: 0.5862991809844971
Validation loss: 2.075984090566635

Epoch: 5| Step: 8
Training loss: 0.7980660796165466
Validation loss: 2.0606716523567834

Epoch: 5| Step: 9
Training loss: 0.6960189342498779
Validation loss: 2.074210132161776

Epoch: 5| Step: 10
Training loss: 0.6915638446807861
Validation loss: 2.0433050245046616

Epoch: 5| Step: 11
Training loss: 1.2930982112884521
Validation loss: 2.038563152154287

Epoch: 240| Step: 0
Training loss: 0.9858587980270386
Validation loss: 2.0554116467634835

Epoch: 5| Step: 1
Training loss: 0.4717927873134613
Validation loss: 2.0741615692774453

Epoch: 5| Step: 2
Training loss: 0.8912870287895203
Validation loss: 2.0741273313760757

Epoch: 5| Step: 3
Training loss: 0.43396544456481934
Validation loss: 2.0510625342528024

Epoch: 5| Step: 4
Training loss: 1.0526583194732666
Validation loss: 2.0693108985821405

Epoch: 5| Step: 5
Training loss: 0.6935656070709229
Validation loss: 2.0004395792881646

Epoch: 5| Step: 6
Training loss: 0.5815774202346802
Validation loss: 2.019141584634781

Epoch: 5| Step: 7
Training loss: 0.9571506381034851
Validation loss: 2.0336809754371643

Epoch: 5| Step: 8
Training loss: 0.5896302461624146
Validation loss: 2.0359940777222314

Epoch: 5| Step: 9
Training loss: 0.5646151304244995
Validation loss: 2.0408711036046348

Epoch: 5| Step: 10
Training loss: 0.482368141412735
Validation loss: 2.0834348996480307

Epoch: 5| Step: 11
Training loss: 0.7965973615646362
Validation loss: 2.0540530482927957

Epoch: 241| Step: 0
Training loss: 0.9489227533340454
Validation loss: 2.056836078564326

Epoch: 5| Step: 1
Training loss: 1.0322065353393555
Validation loss: 2.0397536009550095

Epoch: 5| Step: 2
Training loss: 0.417315810918808
Validation loss: 2.013302912314733

Epoch: 5| Step: 3
Training loss: 0.4779682755470276
Validation loss: 2.0877094815174737

Epoch: 5| Step: 4
Training loss: 0.5940496325492859
Validation loss: 2.0248523702224097

Epoch: 5| Step: 5
Training loss: 0.6916574239730835
Validation loss: 1.9887089282274246

Epoch: 5| Step: 6
Training loss: 0.7380133271217346
Validation loss: 2.0280732164780297

Epoch: 5| Step: 7
Training loss: 0.4922827184200287
Validation loss: 2.003907322883606

Epoch: 5| Step: 8
Training loss: 0.7421110272407532
Validation loss: 2.0281981378793716

Epoch: 5| Step: 9
Training loss: 0.6035404205322266
Validation loss: 2.009424904982249

Epoch: 5| Step: 10
Training loss: 1.0589768886566162
Validation loss: 2.022679169972738

Epoch: 5| Step: 11
Training loss: 0.8626700639724731
Validation loss: 2.036922718087832

Epoch: 242| Step: 0
Training loss: 0.7169541120529175
Validation loss: 2.0326828906933465

Epoch: 5| Step: 1
Training loss: 0.6063831448554993
Validation loss: 2.0066247085730233

Epoch: 5| Step: 2
Training loss: 0.6575112342834473
Validation loss: 2.0063365201155343

Epoch: 5| Step: 3
Training loss: 0.6977879405021667
Validation loss: 2.0119895190000534

Epoch: 5| Step: 4
Training loss: 0.4411233067512512
Validation loss: 2.032839074730873

Epoch: 5| Step: 5
Training loss: 0.6603003144264221
Validation loss: 2.035204380750656

Epoch: 5| Step: 6
Training loss: 0.6917542219161987
Validation loss: 2.0526420225699744

Epoch: 5| Step: 7
Training loss: 0.6930993795394897
Validation loss: 2.051472947001457

Epoch: 5| Step: 8
Training loss: 0.6147486567497253
Validation loss: 2.010292187333107

Epoch: 5| Step: 9
Training loss: 1.059975266456604
Validation loss: 2.045824949940046

Epoch: 5| Step: 10
Training loss: 0.9205068349838257
Validation loss: 2.04960668583711

Epoch: 5| Step: 11
Training loss: 0.961523175239563
Validation loss: 2.041658937931061

Epoch: 243| Step: 0
Training loss: 0.778811514377594
Validation loss: 2.0411807894706726

Epoch: 5| Step: 1
Training loss: 0.7178718447685242
Validation loss: 2.0771813144286475

Epoch: 5| Step: 2
Training loss: 0.3056715428829193
Validation loss: 1.9730475346247356

Epoch: 5| Step: 3
Training loss: 1.410207986831665
Validation loss: 2.0058885465065637

Epoch: 5| Step: 4
Training loss: 0.878031849861145
Validation loss: 2.0407447765270867

Epoch: 5| Step: 5
Training loss: 0.5293472409248352
Validation loss: 2.0215090115865073

Epoch: 5| Step: 6
Training loss: 0.5245891809463501
Validation loss: 2.048919821778933

Epoch: 5| Step: 7
Training loss: 0.431989848613739
Validation loss: 2.003917013605436

Epoch: 5| Step: 8
Training loss: 0.9285880923271179
Validation loss: 2.027304768562317

Epoch: 5| Step: 9
Training loss: 0.9025813937187195
Validation loss: 2.0334241837263107

Epoch: 5| Step: 10
Training loss: 0.4334076941013336
Validation loss: 2.0338970025380454

Epoch: 5| Step: 11
Training loss: 0.16230082511901855
Validation loss: 2.0571102102597556

Epoch: 244| Step: 0
Training loss: 0.6212132573127747
Validation loss: 2.0374277532100677

Epoch: 5| Step: 1
Training loss: 0.6744787096977234
Validation loss: 2.0679416159788766

Epoch: 5| Step: 2
Training loss: 0.47695571184158325
Validation loss: 2.0570006519556046

Epoch: 5| Step: 3
Training loss: 0.6736461520195007
Validation loss: 2.0302731643120446

Epoch: 5| Step: 4
Training loss: 0.8258228302001953
Validation loss: 2.0399850805600486

Epoch: 5| Step: 5
Training loss: 0.9580265879631042
Validation loss: 2.036492943763733

Epoch: 5| Step: 6
Training loss: 0.8156927824020386
Validation loss: 2.023244614402453

Epoch: 5| Step: 7
Training loss: 0.7044332027435303
Validation loss: 2.06479974091053

Epoch: 5| Step: 8
Training loss: 0.9469741582870483
Validation loss: 2.05290520687898

Epoch: 5| Step: 9
Training loss: 0.6040921211242676
Validation loss: 2.087819238503774

Epoch: 5| Step: 10
Training loss: 0.8942924737930298
Validation loss: 2.055412217974663

Epoch: 5| Step: 11
Training loss: 0.48970019817352295
Validation loss: 2.052780340115229

Epoch: 245| Step: 0
Training loss: 0.382350355386734
Validation loss: 2.061035697658857

Epoch: 5| Step: 1
Training loss: 1.122795820236206
Validation loss: 2.0600211123625436

Epoch: 5| Step: 2
Training loss: 0.553153932094574
Validation loss: 2.0714024752378464

Epoch: 5| Step: 3
Training loss: 0.990857720375061
Validation loss: 2.0256229241689048

Epoch: 5| Step: 4
Training loss: 0.613641083240509
Validation loss: 2.0193311274051666

Epoch: 5| Step: 5
Training loss: 0.4479929804801941
Validation loss: 2.038779079914093

Epoch: 5| Step: 6
Training loss: 0.6097908616065979
Validation loss: 2.011600891749064

Epoch: 5| Step: 7
Training loss: 0.46220022439956665
Validation loss: 2.0250247915585837

Epoch: 5| Step: 8
Training loss: 1.0466413497924805
Validation loss: 2.0572168131669364

Epoch: 5| Step: 9
Training loss: 0.9190223813056946
Validation loss: 2.064068228006363

Epoch: 5| Step: 10
Training loss: 0.46207576990127563
Validation loss: 2.0561034083366394

Epoch: 5| Step: 11
Training loss: 0.8998430371284485
Validation loss: 1.9826850791772206

Epoch: 246| Step: 0
Training loss: 0.6907858848571777
Validation loss: 2.042873134215673

Epoch: 5| Step: 1
Training loss: 0.917212963104248
Validation loss: 2.0592467188835144

Epoch: 5| Step: 2
Training loss: 0.7105490565299988
Validation loss: 2.0214400639136634

Epoch: 5| Step: 3
Training loss: 0.5788329243659973
Validation loss: 2.0320791403452554

Epoch: 5| Step: 4
Training loss: 0.6384078860282898
Validation loss: 1.9827158202727635

Epoch: 5| Step: 5
Training loss: 0.39734983444213867
Validation loss: 2.0500786751508713

Epoch: 5| Step: 6
Training loss: 0.8772827982902527
Validation loss: 2.024026026328405

Epoch: 5| Step: 7
Training loss: 0.7141997218132019
Validation loss: 2.031970962882042

Epoch: 5| Step: 8
Training loss: 0.4714116156101227
Validation loss: 2.0199037144581475

Epoch: 5| Step: 9
Training loss: 0.8660111427307129
Validation loss: 2.0164237717787423

Epoch: 5| Step: 10
Training loss: 0.7604606747627258
Validation loss: 2.0227640767892203

Epoch: 5| Step: 11
Training loss: 0.28552019596099854
Validation loss: 2.0331204384565353

Epoch: 247| Step: 0
Training loss: 0.6484674215316772
Validation loss: 2.016422833005587

Epoch: 5| Step: 1
Training loss: 0.46563777327537537
Validation loss: 1.996321568886439

Epoch: 5| Step: 2
Training loss: 0.8257463574409485
Validation loss: 1.9966970433791478

Epoch: 5| Step: 3
Training loss: 0.7821955680847168
Validation loss: 1.9631424496571224

Epoch: 5| Step: 4
Training loss: 0.7113038301467896
Validation loss: 2.0253791511058807

Epoch: 5| Step: 5
Training loss: 0.48053330183029175
Validation loss: 2.017224967479706

Epoch: 5| Step: 6
Training loss: 0.698261022567749
Validation loss: 1.9857189158598583

Epoch: 5| Step: 7
Training loss: 0.989592432975769
Validation loss: 2.044629027446111

Epoch: 5| Step: 8
Training loss: 0.5352808237075806
Validation loss: 2.000886157155037

Epoch: 5| Step: 9
Training loss: 1.0832383632659912
Validation loss: 2.005478948354721

Epoch: 5| Step: 10
Training loss: 0.6243215799331665
Validation loss: 2.034042368332545

Epoch: 5| Step: 11
Training loss: 0.11564719676971436
Validation loss: 1.9879875034093857

Epoch: 248| Step: 0
Training loss: 0.6369318962097168
Validation loss: 2.010134314497312

Epoch: 5| Step: 1
Training loss: 0.9609052538871765
Validation loss: 2.0071627646684647

Epoch: 5| Step: 2
Training loss: 0.4492703080177307
Validation loss: 2.0082742472489676

Epoch: 5| Step: 3
Training loss: 1.2002875804901123
Validation loss: 2.0207215398550034

Epoch: 5| Step: 4
Training loss: 1.0410668849945068
Validation loss: 2.0094191133975983

Epoch: 5| Step: 5
Training loss: 0.4977097511291504
Validation loss: 2.006683940688769

Epoch: 5| Step: 6
Training loss: 0.7254015207290649
Validation loss: 2.0035276661316552

Epoch: 5| Step: 7
Training loss: 0.5162134170532227
Validation loss: 2.000325640042623

Epoch: 5| Step: 8
Training loss: 0.5772806406021118
Validation loss: 2.029288495580355

Epoch: 5| Step: 9
Training loss: 0.36624568700790405
Validation loss: 2.0297965904076896

Epoch: 5| Step: 10
Training loss: 0.5177441835403442
Validation loss: 2.016677568356196

Epoch: 5| Step: 11
Training loss: 0.8804141283035278
Validation loss: 2.0400278568267822

Epoch: 249| Step: 0
Training loss: 0.9325189590454102
Validation loss: 2.0155085374911628

Epoch: 5| Step: 1
Training loss: 0.6107013821601868
Validation loss: 2.021934762597084

Epoch: 5| Step: 2
Training loss: 0.5176341533660889
Validation loss: 2.0241625905036926

Epoch: 5| Step: 3
Training loss: 0.6845489740371704
Validation loss: 2.048942635456721

Epoch: 5| Step: 4
Training loss: 0.7502409815788269
Validation loss: 2.057979315519333

Epoch: 5| Step: 5
Training loss: 0.5777798891067505
Validation loss: 2.013849859436353

Epoch: 5| Step: 6
Training loss: 0.9571703672409058
Validation loss: 2.048682078719139

Epoch: 5| Step: 7
Training loss: 0.4582274556159973
Validation loss: 2.032432481646538

Epoch: 5| Step: 8
Training loss: 0.5796970725059509
Validation loss: 2.0316338340441384

Epoch: 5| Step: 9
Training loss: 0.9328234791755676
Validation loss: 2.049020747343699

Epoch: 5| Step: 10
Training loss: 0.7244119644165039
Validation loss: 2.0676680405934653

Epoch: 5| Step: 11
Training loss: 0.20244181156158447
Validation loss: 2.018434057633082

Epoch: 250| Step: 0
Training loss: 0.7994518280029297
Validation loss: 2.042889883120855

Epoch: 5| Step: 1
Training loss: 0.6811665296554565
Validation loss: 2.0126785337924957

Epoch: 5| Step: 2
Training loss: 0.7335289716720581
Validation loss: 2.039036030570666

Epoch: 5| Step: 3
Training loss: 0.4087510108947754
Validation loss: 2.057247186700503

Epoch: 5| Step: 4
Training loss: 1.1328704357147217
Validation loss: 2.0533987979094186

Epoch: 5| Step: 5
Training loss: 0.9058080911636353
Validation loss: 2.0539008329312005

Epoch: 5| Step: 6
Training loss: 0.44157838821411133
Validation loss: 2.064192866285642

Epoch: 5| Step: 7
Training loss: 0.9138345718383789
Validation loss: 2.036306490500768

Epoch: 5| Step: 8
Training loss: 0.5064295530319214
Validation loss: 2.032521535952886

Epoch: 5| Step: 9
Training loss: 0.5603070259094238
Validation loss: 1.998128538330396

Epoch: 5| Step: 10
Training loss: 0.5305755734443665
Validation loss: 2.0727793872356415

Epoch: 5| Step: 11
Training loss: 0.09755226969718933
Validation loss: 2.00739586353302

Epoch: 251| Step: 0
Training loss: 0.8940401077270508
Validation loss: 2.0262649605671563

Epoch: 5| Step: 1
Training loss: 0.5076016187667847
Validation loss: 2.0433466831843057

Epoch: 5| Step: 2
Training loss: 0.4220483899116516
Validation loss: 2.046320468187332

Epoch: 5| Step: 3
Training loss: 0.5056741833686829
Validation loss: 2.055928702155749

Epoch: 5| Step: 4
Training loss: 0.5771315097808838
Validation loss: 2.0283289750417075

Epoch: 5| Step: 5
Training loss: 0.539626955986023
Validation loss: 2.053196499745051

Epoch: 5| Step: 6
Training loss: 0.7561498880386353
Validation loss: 2.036497707168261

Epoch: 5| Step: 7
Training loss: 1.1453088521957397
Validation loss: 2.0545103450616202

Epoch: 5| Step: 8
Training loss: 0.6809096336364746
Validation loss: 2.0361547668774924

Epoch: 5| Step: 9
Training loss: 0.8960559964179993
Validation loss: 2.0456132739782333

Epoch: 5| Step: 10
Training loss: 0.6469249725341797
Validation loss: 2.0580810656150184

Epoch: 5| Step: 11
Training loss: 0.33397841453552246
Validation loss: 2.0268024504184723

Epoch: 252| Step: 0
Training loss: 1.1248779296875
Validation loss: 2.0617447247107825

Epoch: 5| Step: 1
Training loss: 0.6125440001487732
Validation loss: 2.065251797437668

Epoch: 5| Step: 2
Training loss: 0.41838401556015015
Validation loss: 2.0523128360509872

Epoch: 5| Step: 3
Training loss: 0.5741069912910461
Validation loss: 2.082451264063517

Epoch: 5| Step: 4
Training loss: 0.7961977124214172
Validation loss: 2.01152773698171

Epoch: 5| Step: 5
Training loss: 0.29193374514579773
Validation loss: 2.055777986844381

Epoch: 5| Step: 6
Training loss: 0.6692080497741699
Validation loss: 2.0146906723578772

Epoch: 5| Step: 7
Training loss: 0.7855362892150879
Validation loss: 2.033450464407603

Epoch: 5| Step: 8
Training loss: 0.6765963435173035
Validation loss: 2.002229318022728

Epoch: 5| Step: 9
Training loss: 0.5661843419075012
Validation loss: 1.999942849079768

Epoch: 5| Step: 10
Training loss: 0.8299866914749146
Validation loss: 2.0450912242134414

Epoch: 5| Step: 11
Training loss: 0.9884388446807861
Validation loss: 2.0358799199263253

Epoch: 253| Step: 0
Training loss: 0.8984552621841431
Validation loss: 2.041980355978012

Epoch: 5| Step: 1
Training loss: 0.761325478553772
Validation loss: 2.0287398199240365

Epoch: 5| Step: 2
Training loss: 0.6110697984695435
Validation loss: 2.031544476747513

Epoch: 5| Step: 3
Training loss: 0.7078779339790344
Validation loss: 2.044157693783442

Epoch: 5| Step: 4
Training loss: 0.40714970231056213
Validation loss: 2.000157763560613

Epoch: 5| Step: 5
Training loss: 0.563642144203186
Validation loss: 2.074978401263555

Epoch: 5| Step: 6
Training loss: 0.6637600660324097
Validation loss: 2.036155621210734

Epoch: 5| Step: 7
Training loss: 0.5455485582351685
Validation loss: 2.035522093375524

Epoch: 5| Step: 8
Training loss: 0.5171514749526978
Validation loss: 2.0192805230617523

Epoch: 5| Step: 9
Training loss: 0.6714451909065247
Validation loss: 2.0424805829922357

Epoch: 5| Step: 10
Training loss: 1.104038953781128
Validation loss: 2.000141148765882

Epoch: 5| Step: 11
Training loss: 0.46883028745651245
Validation loss: 1.998361811041832

Epoch: 254| Step: 0
Training loss: 0.8241448402404785
Validation loss: 2.0125753780206046

Epoch: 5| Step: 1
Training loss: 0.8930395245552063
Validation loss: 2.035036494334539

Epoch: 5| Step: 2
Training loss: 0.8888246417045593
Validation loss: 2.0515320946772895

Epoch: 5| Step: 3
Training loss: 0.5520097017288208
Validation loss: 2.043132265408834

Epoch: 5| Step: 4
Training loss: 0.35010048747062683
Validation loss: 2.050268217921257

Epoch: 5| Step: 5
Training loss: 0.8843099474906921
Validation loss: 2.0306998093922934

Epoch: 5| Step: 6
Training loss: 0.8812801241874695
Validation loss: 2.000387112299601

Epoch: 5| Step: 7
Training loss: 0.44482332468032837
Validation loss: 2.0069840202728906

Epoch: 5| Step: 8
Training loss: 0.5262306928634644
Validation loss: 1.9928711553414662

Epoch: 5| Step: 9
Training loss: 0.41791385412216187
Validation loss: 2.0285848329464593

Epoch: 5| Step: 10
Training loss: 0.8044731020927429
Validation loss: 2.017272333304087

Epoch: 5| Step: 11
Training loss: 0.4675166606903076
Validation loss: 2.0187621215979257

Epoch: 255| Step: 0
Training loss: 0.7307397723197937
Validation loss: 2.0133390923341117

Epoch: 5| Step: 1
Training loss: 0.8664191961288452
Validation loss: 2.04377489288648

Epoch: 5| Step: 2
Training loss: 0.23931321501731873
Validation loss: 2.009903813401858

Epoch: 5| Step: 3
Training loss: 0.7479287385940552
Validation loss: 2.023787245154381

Epoch: 5| Step: 4
Training loss: 0.5120949745178223
Validation loss: 2.0431838234265647

Epoch: 5| Step: 5
Training loss: 0.7780343294143677
Validation loss: 2.0487790008385978

Epoch: 5| Step: 6
Training loss: 0.8456090092658997
Validation loss: 2.0124275286992392

Epoch: 5| Step: 7
Training loss: 0.48471030592918396
Validation loss: 2.010581468542417

Epoch: 5| Step: 8
Training loss: 0.9266061782836914
Validation loss: 2.0411921540896096

Epoch: 5| Step: 9
Training loss: 0.3662058711051941
Validation loss: 2.0128525296847024

Epoch: 5| Step: 10
Training loss: 0.9514380693435669
Validation loss: 2.0220611741145453

Epoch: 5| Step: 11
Training loss: 1.4019635915756226
Validation loss: 2.0219053675731025

Epoch: 256| Step: 0
Training loss: 1.170534372329712
Validation loss: 2.04611965517203

Epoch: 5| Step: 1
Training loss: 0.6154962182044983
Validation loss: 2.03050963083903

Epoch: 5| Step: 2
Training loss: 0.4975484013557434
Validation loss: 2.056572139263153

Epoch: 5| Step: 3
Training loss: 0.6149057149887085
Validation loss: 2.040614222486814

Epoch: 5| Step: 4
Training loss: 0.562613308429718
Validation loss: 2.0261213978131614

Epoch: 5| Step: 5
Training loss: 0.8062537908554077
Validation loss: 2.02766985197862

Epoch: 5| Step: 6
Training loss: 0.5675160884857178
Validation loss: 2.011270115772883

Epoch: 5| Step: 7
Training loss: 0.8147271871566772
Validation loss: 2.0301542580127716

Epoch: 5| Step: 8
Training loss: 0.5532830953598022
Validation loss: 2.024695669611295

Epoch: 5| Step: 9
Training loss: 0.6331782937049866
Validation loss: 2.021508276462555

Epoch: 5| Step: 10
Training loss: 0.5419418811798096
Validation loss: 2.047736023863157

Epoch: 5| Step: 11
Training loss: 0.7011767029762268
Validation loss: 2.079566796620687

Epoch: 257| Step: 0
Training loss: 0.21726766228675842
Validation loss: 2.041759505867958

Epoch: 5| Step: 1
Training loss: 0.631938636302948
Validation loss: 2.0173948208491006

Epoch: 5| Step: 2
Training loss: 0.7531110644340515
Validation loss: 2.053938095768293

Epoch: 5| Step: 3
Training loss: 0.29159122705459595
Validation loss: 2.030037894845009

Epoch: 5| Step: 4
Training loss: 0.7079769372940063
Validation loss: 2.0145599295695624

Epoch: 5| Step: 5
Training loss: 0.9989748001098633
Validation loss: 2.0100208868583045

Epoch: 5| Step: 6
Training loss: 0.6299369931221008
Validation loss: 2.02042455971241

Epoch: 5| Step: 7
Training loss: 0.9004356265068054
Validation loss: 2.0353277722994485

Epoch: 5| Step: 8
Training loss: 0.5240971446037292
Validation loss: 2.0191006114085517

Epoch: 5| Step: 9
Training loss: 0.7784209847450256
Validation loss: 2.0273802330096564

Epoch: 5| Step: 10
Training loss: 0.7760149240493774
Validation loss: 2.0742665032545724

Epoch: 5| Step: 11
Training loss: 0.8722732067108154
Validation loss: 2.063858280579249

Epoch: 258| Step: 0
Training loss: 0.8362149000167847
Validation loss: 2.0557765563329062

Epoch: 5| Step: 1
Training loss: 0.4009726643562317
Validation loss: 2.097184548775355

Epoch: 5| Step: 2
Training loss: 0.6034019589424133
Validation loss: 2.0430848797162375

Epoch: 5| Step: 3
Training loss: 0.57658851146698
Validation loss: 2.0566807836294174

Epoch: 5| Step: 4
Training loss: 0.4853023588657379
Validation loss: 2.026411364475886

Epoch: 5| Step: 5
Training loss: 1.0875022411346436
Validation loss: 2.024088501930237

Epoch: 5| Step: 6
Training loss: 1.1636911630630493
Validation loss: 2.075901155670484

Epoch: 5| Step: 7
Training loss: 0.7990695238113403
Validation loss: 2.0569084535042443

Epoch: 5| Step: 8
Training loss: 0.6971348524093628
Validation loss: 2.037464290857315

Epoch: 5| Step: 9
Training loss: 0.6636461019515991
Validation loss: 2.0614122301340103

Epoch: 5| Step: 10
Training loss: 0.5473328232765198
Validation loss: 2.026111289858818

Epoch: 5| Step: 11
Training loss: 0.7013435363769531
Validation loss: 2.04615618288517

Epoch: 259| Step: 0
Training loss: 0.7512037754058838
Validation loss: 1.983249728878339

Epoch: 5| Step: 1
Training loss: 0.7329948544502258
Validation loss: 2.0639823426802955

Epoch: 5| Step: 2
Training loss: 0.8755252957344055
Validation loss: 2.012868285179138

Epoch: 5| Step: 3
Training loss: 0.7100353240966797
Validation loss: 2.0563132017850876

Epoch: 5| Step: 4
Training loss: 0.701539158821106
Validation loss: 2.0334536681572595

Epoch: 5| Step: 5
Training loss: 0.4524076581001282
Validation loss: 2.02699122329553

Epoch: 5| Step: 6
Training loss: 0.5051348209381104
Validation loss: 2.023323819041252

Epoch: 5| Step: 7
Training loss: 0.4538792669773102
Validation loss: 2.0010494689146676

Epoch: 5| Step: 8
Training loss: 0.6184765100479126
Validation loss: 2.025778571764628

Epoch: 5| Step: 9
Training loss: 0.4796055853366852
Validation loss: 2.0156562129656472

Epoch: 5| Step: 10
Training loss: 0.7362231016159058
Validation loss: 2.0163979778687158

Epoch: 5| Step: 11
Training loss: 1.1659330129623413
Validation loss: 2.0089745024840036

Epoch: 260| Step: 0
Training loss: 0.6561743021011353
Validation loss: 2.0399977465470633

Epoch: 5| Step: 1
Training loss: 0.6853405833244324
Validation loss: 2.055611158410708

Epoch: 5| Step: 2
Training loss: 0.5489896535873413
Validation loss: 2.014854038755099

Epoch: 5| Step: 3
Training loss: 0.9040741920471191
Validation loss: 2.032930552959442

Epoch: 5| Step: 4
Training loss: 0.7511770129203796
Validation loss: 2.0180496722459793

Epoch: 5| Step: 5
Training loss: 0.9040796160697937
Validation loss: 2.039411390821139

Epoch: 5| Step: 6
Training loss: 0.323307603597641
Validation loss: 2.028421719868978

Epoch: 5| Step: 7
Training loss: 0.7325547933578491
Validation loss: 2.000584860642751

Epoch: 5| Step: 8
Training loss: 0.4980386793613434
Validation loss: 2.0564901729424796

Epoch: 5| Step: 9
Training loss: 0.644221842288971
Validation loss: 2.056960314512253

Epoch: 5| Step: 10
Training loss: 0.5654379725456238
Validation loss: 2.024203767379125

Epoch: 5| Step: 11
Training loss: 0.7870990633964539
Validation loss: 2.0398517896731696

Epoch: 261| Step: 0
Training loss: 0.7063249945640564
Validation loss: 2.0365414917469025

Epoch: 5| Step: 1
Training loss: 0.6967240571975708
Validation loss: 2.0704401234785714

Epoch: 5| Step: 2
Training loss: 0.3633522391319275
Validation loss: 2.054458270470301

Epoch: 5| Step: 3
Training loss: 0.4905720353126526
Validation loss: 2.057888388633728

Epoch: 5| Step: 4
Training loss: 0.7849028706550598
Validation loss: 2.0486069520314536

Epoch: 5| Step: 5
Training loss: 0.8319002389907837
Validation loss: 2.0525160183509192

Epoch: 5| Step: 6
Training loss: 0.38294702768325806
Validation loss: 2.066849191983541

Epoch: 5| Step: 7
Training loss: 0.47348999977111816
Validation loss: 2.0005054771900177

Epoch: 5| Step: 8
Training loss: 0.5929077863693237
Validation loss: 2.021326800187429

Epoch: 5| Step: 9
Training loss: 1.0099201202392578
Validation loss: 2.029432083169619

Epoch: 5| Step: 10
Training loss: 0.6868557333946228
Validation loss: 2.0428923765818277

Epoch: 5| Step: 11
Training loss: 1.28511643409729
Validation loss: 2.069162209828695

Epoch: 262| Step: 0
Training loss: 0.7949522733688354
Validation loss: 2.0490916619698205

Epoch: 5| Step: 1
Training loss: 0.6838452816009521
Validation loss: 2.0443425128857293

Epoch: 5| Step: 2
Training loss: 0.28667041659355164
Validation loss: 2.072902391354243

Epoch: 5| Step: 3
Training loss: 0.38409703969955444
Validation loss: 2.0664062052965164

Epoch: 5| Step: 4
Training loss: 0.8112580180168152
Validation loss: 2.013408809900284

Epoch: 5| Step: 5
Training loss: 0.733711838722229
Validation loss: 2.0556277881066003

Epoch: 5| Step: 6
Training loss: 1.127378225326538
Validation loss: 1.9882005055745442

Epoch: 5| Step: 7
Training loss: 0.37902897596359253
Validation loss: 2.0739094763994217

Epoch: 5| Step: 8
Training loss: 0.7120341062545776
Validation loss: 2.029669667283694

Epoch: 5| Step: 9
Training loss: 1.1247198581695557
Validation loss: 2.049385537703832

Epoch: 5| Step: 10
Training loss: 0.6199683547019958
Validation loss: 2.0257004847129187

Epoch: 5| Step: 11
Training loss: 0.4819759130477905
Validation loss: 2.0271024256944656

Epoch: 263| Step: 0
Training loss: 0.4703350067138672
Validation loss: 2.0335411429405212

Epoch: 5| Step: 1
Training loss: 0.7175464630126953
Validation loss: 2.0563079019387565

Epoch: 5| Step: 2
Training loss: 1.006424069404602
Validation loss: 2.0767211814721427

Epoch: 5| Step: 3
Training loss: 0.4865545332431793
Validation loss: 2.069711526234945

Epoch: 5| Step: 4
Training loss: 0.8611519932746887
Validation loss: 2.0904002090295157

Epoch: 5| Step: 5
Training loss: 0.6238120794296265
Validation loss: 2.0584921340147653

Epoch: 5| Step: 6
Training loss: 0.37886109948158264
Validation loss: 2.0128199805816016

Epoch: 5| Step: 7
Training loss: 0.5293338298797607
Validation loss: 2.0572830736637115

Epoch: 5| Step: 8
Training loss: 0.779626727104187
Validation loss: 2.0468901793162027

Epoch: 5| Step: 9
Training loss: 0.5183907151222229
Validation loss: 2.0334156403938928

Epoch: 5| Step: 10
Training loss: 1.2628567218780518
Validation loss: 2.0478416085243225

Epoch: 5| Step: 11
Training loss: 0.30700021982192993
Validation loss: 2.0265202124913535

Epoch: 264| Step: 0
Training loss: 0.9484384655952454
Validation loss: 2.015608017643293

Epoch: 5| Step: 1
Training loss: 1.1367501020431519
Validation loss: 2.0315964271624884

Epoch: 5| Step: 2
Training loss: 0.7744161486625671
Validation loss: 2.044953698913256

Epoch: 5| Step: 3
Training loss: 0.6208531260490417
Validation loss: 2.0641532291968665

Epoch: 5| Step: 4
Training loss: 0.7738733291625977
Validation loss: 2.0376026878754296

Epoch: 5| Step: 5
Training loss: 0.4941716194152832
Validation loss: 2.0577917397022247

Epoch: 5| Step: 6
Training loss: 0.5181302428245544
Validation loss: 2.0357214162747064

Epoch: 5| Step: 7
Training loss: 0.3939732313156128
Validation loss: 2.0343761841456094

Epoch: 5| Step: 8
Training loss: 0.5450761914253235
Validation loss: 2.016882136464119

Epoch: 5| Step: 9
Training loss: 0.5410913228988647
Validation loss: 2.052350560824076

Epoch: 5| Step: 10
Training loss: 0.7348628044128418
Validation loss: 2.038632114728292

Epoch: 5| Step: 11
Training loss: 0.8497966527938843
Validation loss: 2.056921382745107

Epoch: 265| Step: 0
Training loss: 0.5958672761917114
Validation loss: 2.0469729006290436

Epoch: 5| Step: 1
Training loss: 0.7306342124938965
Validation loss: 2.005252202351888

Epoch: 5| Step: 2
Training loss: 0.7771967053413391
Validation loss: 2.0642765114704766

Epoch: 5| Step: 3
Training loss: 0.4549551010131836
Validation loss: 2.0401464998722076

Epoch: 5| Step: 4
Training loss: 0.7808004021644592
Validation loss: 2.074172481894493

Epoch: 5| Step: 5
Training loss: 0.4785051941871643
Validation loss: 2.054766540726026

Epoch: 5| Step: 6
Training loss: 0.6938501596450806
Validation loss: 2.02104743818442

Epoch: 5| Step: 7
Training loss: 1.013778567314148
Validation loss: 2.0111103604237237

Epoch: 5| Step: 8
Training loss: 0.6413289308547974
Validation loss: 2.0547969291607537

Epoch: 5| Step: 9
Training loss: 0.7454164624214172
Validation loss: 1.9935441265503566

Epoch: 5| Step: 10
Training loss: 0.5601585507392883
Validation loss: 2.06336077551047

Epoch: 5| Step: 11
Training loss: 0.4070226848125458
Validation loss: 2.052543501059214

Epoch: 266| Step: 0
Training loss: 0.737978458404541
Validation loss: 2.014840140938759

Epoch: 5| Step: 1
Training loss: 0.7133119106292725
Validation loss: 2.0389781296253204

Epoch: 5| Step: 2
Training loss: 0.964756965637207
Validation loss: 2.086643308401108

Epoch: 5| Step: 3
Training loss: 0.5838958621025085
Validation loss: 2.093448450167974

Epoch: 5| Step: 4
Training loss: 0.9894396662712097
Validation loss: 2.0776410500208535

Epoch: 5| Step: 5
Training loss: 0.5941461324691772
Validation loss: 2.0973924746116004

Epoch: 5| Step: 6
Training loss: 1.2663705348968506
Validation loss: 2.0533333718776703

Epoch: 5| Step: 7
Training loss: 0.7010138630867004
Validation loss: 2.0818558583656945

Epoch: 5| Step: 8
Training loss: 0.48214203119277954
Validation loss: 2.07158770163854

Epoch: 5| Step: 9
Training loss: 0.4184209704399109
Validation loss: 2.069777394334475

Epoch: 5| Step: 10
Training loss: 0.5126004219055176
Validation loss: 2.0536896089712777

Epoch: 5| Step: 11
Training loss: 0.12080937623977661
Validation loss: 2.0510660161574683

Epoch: 267| Step: 0
Training loss: 0.5816208124160767
Validation loss: 2.0711558063824973

Epoch: 5| Step: 1
Training loss: 0.6364817023277283
Validation loss: 2.065312917033831

Epoch: 5| Step: 2
Training loss: 0.6288572549819946
Validation loss: 2.0555920004844666

Epoch: 5| Step: 3
Training loss: 1.1683976650238037
Validation loss: 2.0499699115753174

Epoch: 5| Step: 4
Training loss: 0.5022082924842834
Validation loss: 2.050756057103475

Epoch: 5| Step: 5
Training loss: 0.6805922389030457
Validation loss: 2.0385263164838157

Epoch: 5| Step: 6
Training loss: 0.5423908233642578
Validation loss: 2.025049110253652

Epoch: 5| Step: 7
Training loss: 0.4088815152645111
Validation loss: 1.9973307251930237

Epoch: 5| Step: 8
Training loss: 0.6705203056335449
Validation loss: 2.007010559240977

Epoch: 5| Step: 9
Training loss: 0.6604759693145752
Validation loss: 2.0409771353006363

Epoch: 5| Step: 10
Training loss: 0.5488615036010742
Validation loss: 2.0337657829125724

Epoch: 5| Step: 11
Training loss: 1.6097685098648071
Validation loss: 2.0412140786647797

Epoch: 268| Step: 0
Training loss: 0.7890051603317261
Validation loss: 2.0426130245129266

Epoch: 5| Step: 1
Training loss: 0.905899167060852
Validation loss: 2.0493969718615213

Epoch: 5| Step: 2
Training loss: 0.8147674798965454
Validation loss: 2.0479472825924554

Epoch: 5| Step: 3
Training loss: 0.6439879536628723
Validation loss: 2.031814823547999

Epoch: 5| Step: 4
Training loss: 0.47828078269958496
Validation loss: 2.0292925586303077

Epoch: 5| Step: 5
Training loss: 0.848924994468689
Validation loss: 2.082998255888621

Epoch: 5| Step: 6
Training loss: 0.4766920208930969
Validation loss: 2.0245446463425956

Epoch: 5| Step: 7
Training loss: 0.5661630630493164
Validation loss: 2.05238875746727

Epoch: 5| Step: 8
Training loss: 0.457815945148468
Validation loss: 2.02888323366642

Epoch: 5| Step: 9
Training loss: 0.5615993738174438
Validation loss: 2.035360887646675

Epoch: 5| Step: 10
Training loss: 0.6985431909561157
Validation loss: 2.0496370842059455

Epoch: 5| Step: 11
Training loss: 0.5194382667541504
Validation loss: 2.0450991789499917

Epoch: 269| Step: 0
Training loss: 0.6086719632148743
Validation loss: 2.055755620201429

Epoch: 5| Step: 1
Training loss: 0.8818627595901489
Validation loss: 2.032141000032425

Epoch: 5| Step: 2
Training loss: 0.46190038323402405
Validation loss: 2.0388176838556924

Epoch: 5| Step: 3
Training loss: 0.6050252914428711
Validation loss: 2.0275616149107614

Epoch: 5| Step: 4
Training loss: 0.8093085289001465
Validation loss: 2.0326458464066186

Epoch: 5| Step: 5
Training loss: 0.7317039370536804
Validation loss: 2.016865521669388

Epoch: 5| Step: 6
Training loss: 0.3896854519844055
Validation loss: 2.0479414959748587

Epoch: 5| Step: 7
Training loss: 0.5781673192977905
Validation loss: 2.0293680081764855

Epoch: 5| Step: 8
Training loss: 0.5362576842308044
Validation loss: 2.0292264173428216

Epoch: 5| Step: 9
Training loss: 0.8044141530990601
Validation loss: 2.0452570964892707

Epoch: 5| Step: 10
Training loss: 0.522591233253479
Validation loss: 2.0738254288832345

Epoch: 5| Step: 11
Training loss: 0.8517085313796997
Validation loss: 2.0400493194659552

Epoch: 270| Step: 0
Training loss: 0.6110824346542358
Validation loss: 1.9904657850662868

Epoch: 5| Step: 1
Training loss: 0.8139489889144897
Validation loss: 2.008334810535113

Epoch: 5| Step: 2
Training loss: 0.40424293279647827
Validation loss: 2.0055185705423355

Epoch: 5| Step: 3
Training loss: 0.8571885824203491
Validation loss: 2.009803225596746

Epoch: 5| Step: 4
Training loss: 0.6505354642868042
Validation loss: 2.019533544778824

Epoch: 5| Step: 5
Training loss: 0.4673941135406494
Validation loss: 2.0446861485640206

Epoch: 5| Step: 6
Training loss: 0.2706741988658905
Validation loss: 2.05211940407753

Epoch: 5| Step: 7
Training loss: 0.7797315120697021
Validation loss: 2.0444307575623193

Epoch: 5| Step: 8
Training loss: 0.7826470136642456
Validation loss: 2.0351221362749734

Epoch: 5| Step: 9
Training loss: 0.30770397186279297
Validation loss: 2.0354813933372498

Epoch: 5| Step: 10
Training loss: 0.5885078310966492
Validation loss: 2.0367570718129477

Epoch: 5| Step: 11
Training loss: 1.0763798952102661
Validation loss: 2.060466726620992

Epoch: 271| Step: 0
Training loss: 0.6881746053695679
Validation loss: 2.090850760539373

Epoch: 5| Step: 1
Training loss: 0.6275567412376404
Validation loss: 2.022934685150782

Epoch: 5| Step: 2
Training loss: 1.1711015701293945
Validation loss: 2.0624958276748657

Epoch: 5| Step: 3
Training loss: 0.602899432182312
Validation loss: 2.0288134465614953

Epoch: 5| Step: 4
Training loss: 0.4061085283756256
Validation loss: 2.0708214243253074

Epoch: 5| Step: 5
Training loss: 0.4943583607673645
Validation loss: 2.0519095957279205

Epoch: 5| Step: 6
Training loss: 0.6264696717262268
Validation loss: 2.035522316892942

Epoch: 5| Step: 7
Training loss: 0.7037172317504883
Validation loss: 2.041937286655108

Epoch: 5| Step: 8
Training loss: 0.46234798431396484
Validation loss: 2.088059996565183

Epoch: 5| Step: 9
Training loss: 0.34001272916793823
Validation loss: 2.0522255152463913

Epoch: 5| Step: 10
Training loss: 0.6819429397583008
Validation loss: 2.071004639069239

Epoch: 5| Step: 11
Training loss: 1.1921117305755615
Validation loss: 1.9851558357477188

Epoch: 272| Step: 0
Training loss: 0.5485278964042664
Validation loss: 2.0458090802033744

Epoch: 5| Step: 1
Training loss: 0.8114345669746399
Validation loss: 2.0780863563219705

Epoch: 5| Step: 2
Training loss: 0.8791561126708984
Validation loss: 2.073211203018824

Epoch: 5| Step: 3
Training loss: 0.6444845795631409
Validation loss: 2.0408831387758255

Epoch: 5| Step: 4
Training loss: 0.5679576992988586
Validation loss: 2.0430348217487335

Epoch: 5| Step: 5
Training loss: 0.4856356680393219
Validation loss: 2.062088946501414

Epoch: 5| Step: 6
Training loss: 0.7166293263435364
Validation loss: 2.0220092087984085

Epoch: 5| Step: 7
Training loss: 0.3541489541530609
Validation loss: 2.0417370150486627

Epoch: 5| Step: 8
Training loss: 0.5734226107597351
Validation loss: 2.045251707235972

Epoch: 5| Step: 9
Training loss: 0.4915889799594879
Validation loss: 2.051324581106504

Epoch: 5| Step: 10
Training loss: 0.7083960771560669
Validation loss: 2.0401439567406974

Epoch: 5| Step: 11
Training loss: 0.7670432925224304
Validation loss: 2.006126508116722

Epoch: 273| Step: 0
Training loss: 0.844561755657196
Validation loss: 2.040122831861178

Epoch: 5| Step: 1
Training loss: 0.8833516240119934
Validation loss: 2.0347997645537057

Epoch: 5| Step: 2
Training loss: 0.7450688481330872
Validation loss: 2.0581484884023666

Epoch: 5| Step: 3
Training loss: 0.7442577481269836
Validation loss: 2.015276854236921

Epoch: 5| Step: 4
Training loss: 0.7335899472236633
Validation loss: 2.0199153323968253

Epoch: 5| Step: 5
Training loss: 0.5019462704658508
Validation loss: 1.994007522861163

Epoch: 5| Step: 6
Training loss: 0.5994199514389038
Validation loss: 1.9971657345692317

Epoch: 5| Step: 7
Training loss: 0.5318382978439331
Validation loss: 1.9970109562079112

Epoch: 5| Step: 8
Training loss: 0.844172477722168
Validation loss: 2.057480365037918

Epoch: 5| Step: 9
Training loss: 0.7343282699584961
Validation loss: 2.047193850080172

Epoch: 5| Step: 10
Training loss: 0.7004926800727844
Validation loss: 2.0514698177576065

Epoch: 5| Step: 11
Training loss: 0.22639858722686768
Validation loss: 2.0104448795318604

Epoch: 274| Step: 0
Training loss: 0.47711578011512756
Validation loss: 2.050709679722786

Epoch: 5| Step: 1
Training loss: 0.3989660143852234
Validation loss: 2.036156346400579

Epoch: 5| Step: 2
Training loss: 0.6604453325271606
Validation loss: 1.9949429978926976

Epoch: 5| Step: 3
Training loss: 1.1117875576019287
Validation loss: 2.008987973133723

Epoch: 5| Step: 4
Training loss: 0.8776983022689819
Validation loss: 2.0290424823760986

Epoch: 5| Step: 5
Training loss: 0.6967058181762695
Validation loss: 2.0415240426858268

Epoch: 5| Step: 6
Training loss: 1.0135762691497803
Validation loss: 2.0329487025737762

Epoch: 5| Step: 7
Training loss: 0.4555934965610504
Validation loss: 2.0259943356116614

Epoch: 5| Step: 8
Training loss: 0.6047021150588989
Validation loss: 1.9905322790145874

Epoch: 5| Step: 9
Training loss: 0.6212843656539917
Validation loss: 2.04437085489432

Epoch: 5| Step: 10
Training loss: 0.5028595328330994
Validation loss: 2.041758269071579

Epoch: 5| Step: 11
Training loss: 0.17150190472602844
Validation loss: 2.0720971475044885

Epoch: 275| Step: 0
Training loss: 0.7082679867744446
Validation loss: 2.037051737308502

Epoch: 5| Step: 1
Training loss: 0.6462715864181519
Validation loss: 2.0287415037552514

Epoch: 5| Step: 2
Training loss: 0.5330548286437988
Validation loss: 2.043224349617958

Epoch: 5| Step: 3
Training loss: 0.40549930930137634
Validation loss: 2.0358484387397766

Epoch: 5| Step: 4
Training loss: 0.7265084981918335
Validation loss: 2.0280549426873526

Epoch: 5| Step: 5
Training loss: 0.3983149826526642
Validation loss: 2.0347911765178046

Epoch: 5| Step: 6
Training loss: 0.6813289523124695
Validation loss: 2.0365921209255853

Epoch: 5| Step: 7
Training loss: 0.48120251297950745
Validation loss: 2.061470260222753

Epoch: 5| Step: 8
Training loss: 0.7414936423301697
Validation loss: 2.031306857864062

Epoch: 5| Step: 9
Training loss: 0.7788015604019165
Validation loss: 2.0407342364390693

Epoch: 5| Step: 10
Training loss: 0.6331079602241516
Validation loss: 2.06509467959404

Epoch: 5| Step: 11
Training loss: 1.4296470880508423
Validation loss: 2.051334505279859

Epoch: 276| Step: 0
Training loss: 0.5090216398239136
Validation loss: 2.0485264311234155

Epoch: 5| Step: 1
Training loss: 0.7061020731925964
Validation loss: 2.03684368232886

Epoch: 5| Step: 2
Training loss: 0.4233335554599762
Validation loss: 2.0296932011842728

Epoch: 5| Step: 3
Training loss: 0.9701555371284485
Validation loss: 1.9882264733314514

Epoch: 5| Step: 4
Training loss: 0.6594300270080566
Validation loss: 2.0492221117019653

Epoch: 5| Step: 5
Training loss: 0.4068523347377777
Validation loss: 2.037920897205671

Epoch: 5| Step: 6
Training loss: 0.535703182220459
Validation loss: 2.059176658590635

Epoch: 5| Step: 7
Training loss: 1.0520966053009033
Validation loss: 2.0099963496128717

Epoch: 5| Step: 8
Training loss: 0.37284716963768005
Validation loss: 2.0175132155418396

Epoch: 5| Step: 9
Training loss: 0.9454606771469116
Validation loss: 2.019848272204399

Epoch: 5| Step: 10
Training loss: 0.5023000836372375
Validation loss: 2.018602137764295

Epoch: 5| Step: 11
Training loss: 0.0994635820388794
Validation loss: 2.05350269873937

Epoch: 277| Step: 0
Training loss: 0.48437491059303284
Validation loss: 2.0182463775078454

Epoch: 5| Step: 1
Training loss: 0.47909727692604065
Validation loss: 2.087652320663134

Epoch: 5| Step: 2
Training loss: 0.6662657856941223
Validation loss: 2.0307751148939133

Epoch: 5| Step: 3
Training loss: 0.8752323985099792
Validation loss: 2.0435230284929276

Epoch: 5| Step: 4
Training loss: 0.9490877985954285
Validation loss: 2.0493546773989997

Epoch: 5| Step: 5
Training loss: 0.587313175201416
Validation loss: 2.0937771002451577

Epoch: 5| Step: 6
Training loss: 0.7846593260765076
Validation loss: 2.0662741164366403

Epoch: 5| Step: 7
Training loss: 0.42269667983055115
Validation loss: 2.0797694325447083

Epoch: 5| Step: 8
Training loss: 0.43627816438674927
Validation loss: 2.0467602660258613

Epoch: 5| Step: 9
Training loss: 0.544653058052063
Validation loss: 2.066279316941897

Epoch: 5| Step: 10
Training loss: 0.4465141296386719
Validation loss: 2.0726274450620017

Epoch: 5| Step: 11
Training loss: 0.13591289520263672
Validation loss: 2.0376580705245337

Epoch: 278| Step: 0
Training loss: 0.8639518022537231
Validation loss: 2.0846828321615853

Epoch: 5| Step: 1
Training loss: 0.4366251826286316
Validation loss: 2.0165332903464637

Epoch: 5| Step: 2
Training loss: 0.3597225844860077
Validation loss: 2.1041286389033

Epoch: 5| Step: 3
Training loss: 0.6708061099052429
Validation loss: 2.0894542882839837

Epoch: 5| Step: 4
Training loss: 0.7490068674087524
Validation loss: 2.0797534634669623

Epoch: 5| Step: 5
Training loss: 0.8666927218437195
Validation loss: 2.0609360337257385

Epoch: 5| Step: 6
Training loss: 0.5967645049095154
Validation loss: 1.9870714843273163

Epoch: 5| Step: 7
Training loss: 0.8664658665657043
Validation loss: 2.0718562652667365

Epoch: 5| Step: 8
Training loss: 0.4047777056694031
Validation loss: 2.036572515964508

Epoch: 5| Step: 9
Training loss: 0.770197868347168
Validation loss: 2.052657092610995

Epoch: 5| Step: 10
Training loss: 0.33324307203292847
Validation loss: 2.0143110007047653

Epoch: 5| Step: 11
Training loss: 0.5398820638656616
Validation loss: 2.0683602144320807

Epoch: 279| Step: 0
Training loss: 0.5825686454772949
Validation loss: 2.0708126227060952

Epoch: 5| Step: 1
Training loss: 0.7800458073616028
Validation loss: 2.052136927843094

Epoch: 5| Step: 2
Training loss: 0.5006696581840515
Validation loss: 2.0800982465346656

Epoch: 5| Step: 3
Training loss: 0.605414628982544
Validation loss: 2.0474541733662286

Epoch: 5| Step: 4
Training loss: 0.5514437556266785
Validation loss: 2.052698324124018

Epoch: 5| Step: 5
Training loss: 0.7031356692314148
Validation loss: 2.0504528184731803

Epoch: 5| Step: 6
Training loss: 0.7584676742553711
Validation loss: 2.0527875423431396

Epoch: 5| Step: 7
Training loss: 0.7783567905426025
Validation loss: 2.0272951324780784

Epoch: 5| Step: 8
Training loss: 1.1266396045684814
Validation loss: 2.0669725288947425

Epoch: 5| Step: 9
Training loss: 0.26015180349349976
Validation loss: 2.061079432566961

Epoch: 5| Step: 10
Training loss: 0.35262811183929443
Validation loss: 2.0296697368224463

Epoch: 5| Step: 11
Training loss: 0.1931425929069519
Validation loss: 2.0291402290264764

Epoch: 280| Step: 0
Training loss: 0.27132999897003174
Validation loss: 2.0143809715906777

Epoch: 5| Step: 1
Training loss: 0.6282954216003418
Validation loss: 2.063232516249021

Epoch: 5| Step: 2
Training loss: 0.5440347194671631
Validation loss: 2.0490785390138626

Epoch: 5| Step: 3
Training loss: 0.5046316981315613
Validation loss: 2.0743482261896133

Epoch: 5| Step: 4
Training loss: 0.7830008268356323
Validation loss: 2.0318236450354257

Epoch: 5| Step: 5
Training loss: 0.9218977093696594
Validation loss: 2.0306049287319183

Epoch: 5| Step: 6
Training loss: 0.6808599233627319
Validation loss: 2.049578179915746

Epoch: 5| Step: 7
Training loss: 0.507872462272644
Validation loss: 1.9776579439640045

Epoch: 5| Step: 8
Training loss: 0.5291699171066284
Validation loss: 2.048900917172432

Epoch: 5| Step: 9
Training loss: 0.4868944585323334
Validation loss: 2.0420792003472648

Epoch: 5| Step: 10
Training loss: 0.604759156703949
Validation loss: 2.017901678880056

Epoch: 5| Step: 11
Training loss: 0.763216495513916
Validation loss: 2.038752312461535

Epoch: 281| Step: 0
Training loss: 0.3712300658226013
Validation loss: 2.0356255869070687

Epoch: 5| Step: 1
Training loss: 0.45806533098220825
Validation loss: 1.9984894096851349

Epoch: 5| Step: 2
Training loss: 0.9080198407173157
Validation loss: 2.0155953665574393

Epoch: 5| Step: 3
Training loss: 0.426428884267807
Validation loss: 2.0146116664012275

Epoch: 5| Step: 4
Training loss: 0.750827431678772
Validation loss: 2.0193252116441727

Epoch: 5| Step: 5
Training loss: 0.31599801778793335
Validation loss: 1.9813470244407654

Epoch: 5| Step: 6
Training loss: 0.981411337852478
Validation loss: 2.0151036928097406

Epoch: 5| Step: 7
Training loss: 0.7478467226028442
Validation loss: 2.0044121791919074

Epoch: 5| Step: 8
Training loss: 0.5671544075012207
Validation loss: 1.982481097181638

Epoch: 5| Step: 9
Training loss: 0.7917554974555969
Validation loss: 2.044173628091812

Epoch: 5| Step: 10
Training loss: 0.463026225566864
Validation loss: 2.0101351141929626

Epoch: 5| Step: 11
Training loss: 0.6115504503250122
Validation loss: 2.051237245400747

Epoch: 282| Step: 0
Training loss: 0.3894849419593811
Validation loss: 2.020582064986229

Epoch: 5| Step: 1
Training loss: 0.8021696209907532
Validation loss: 2.006160631775856

Epoch: 5| Step: 2
Training loss: 0.3244204819202423
Validation loss: 2.070252761244774

Epoch: 5| Step: 3
Training loss: 0.9127094149589539
Validation loss: 2.00963594019413

Epoch: 5| Step: 4
Training loss: 0.23886604607105255
Validation loss: 2.0862701684236526

Epoch: 5| Step: 5
Training loss: 0.5912231206893921
Validation loss: 2.034306844075521

Epoch: 5| Step: 6
Training loss: 0.4526662826538086
Validation loss: 2.0175689458847046

Epoch: 5| Step: 7
Training loss: 0.5911425948143005
Validation loss: 2.058153743545214

Epoch: 5| Step: 8
Training loss: 1.3987560272216797
Validation loss: 2.0834049681822457

Epoch: 5| Step: 9
Training loss: 0.5583456158638
Validation loss: 2.047849794228872

Epoch: 5| Step: 10
Training loss: 0.44013676047325134
Validation loss: 2.048233608404795

Epoch: 5| Step: 11
Training loss: 1.1951658725738525
Validation loss: 2.044478024045626

Epoch: 283| Step: 0
Training loss: 0.9390920400619507
Validation loss: 2.0176099638144174

Epoch: 5| Step: 1
Training loss: 0.443589985370636
Validation loss: 2.0473180760939917

Epoch: 5| Step: 2
Training loss: 0.633457362651825
Validation loss: 2.026333451271057

Epoch: 5| Step: 3
Training loss: 0.8776470422744751
Validation loss: 2.0699735432863235

Epoch: 5| Step: 4
Training loss: 0.5168346166610718
Validation loss: 2.054088438550631

Epoch: 5| Step: 5
Training loss: 0.4604717195034027
Validation loss: 2.071252624193827

Epoch: 5| Step: 6
Training loss: 0.9366434812545776
Validation loss: 2.0756342162688575

Epoch: 5| Step: 7
Training loss: 0.5064622759819031
Validation loss: 2.06754998366038

Epoch: 5| Step: 8
Training loss: 0.4480171799659729
Validation loss: 2.05708717306455

Epoch: 5| Step: 9
Training loss: 0.41371387243270874
Validation loss: 2.0586400975783667

Epoch: 5| Step: 10
Training loss: 0.6844907999038696
Validation loss: 2.027043124039968

Epoch: 5| Step: 11
Training loss: 0.15631616115570068
Validation loss: 2.031365752220154

Epoch: 284| Step: 0
Training loss: 0.5579360723495483
Validation loss: 2.0358262608448663

Epoch: 5| Step: 1
Training loss: 0.5148276090621948
Validation loss: 2.0389570941527686

Epoch: 5| Step: 2
Training loss: 0.7660272717475891
Validation loss: 2.0337327867746353

Epoch: 5| Step: 3
Training loss: 1.0527592897415161
Validation loss: 2.049863134821256

Epoch: 5| Step: 4
Training loss: 0.8547248840332031
Validation loss: 2.0247587809960046

Epoch: 5| Step: 5
Training loss: 0.8658803701400757
Validation loss: 1.9751085738341014

Epoch: 5| Step: 6
Training loss: 0.5004721879959106
Validation loss: 2.0035019665956497

Epoch: 5| Step: 7
Training loss: 0.7919002175331116
Validation loss: 2.001928354303042

Epoch: 5| Step: 8
Training loss: 0.7169575691223145
Validation loss: 2.018880178531011

Epoch: 5| Step: 9
Training loss: 0.9114068746566772
Validation loss: 2.0488057186206183

Epoch: 5| Step: 10
Training loss: 0.4489579200744629
Validation loss: 2.012367690602938

Epoch: 5| Step: 11
Training loss: 0.8689203858375549
Validation loss: 1.9774923125902812

Epoch: 285| Step: 0
Training loss: 0.6582995653152466
Validation loss: 1.9759580890337627

Epoch: 5| Step: 1
Training loss: 0.6705423593521118
Validation loss: 1.996201977133751

Epoch: 5| Step: 2
Training loss: 0.8280029296875
Validation loss: 2.0227716316779456

Epoch: 5| Step: 3
Training loss: 0.476975679397583
Validation loss: 2.0359598050514855

Epoch: 5| Step: 4
Training loss: 0.5077425241470337
Validation loss: 2.0134671479463577

Epoch: 5| Step: 5
Training loss: 0.3760914206504822
Validation loss: 2.012812445561091

Epoch: 5| Step: 6
Training loss: 0.9148243069648743
Validation loss: 2.0021132081747055

Epoch: 5| Step: 7
Training loss: 0.5804252028465271
Validation loss: 2.037311057249705

Epoch: 5| Step: 8
Training loss: 0.7410371899604797
Validation loss: 2.032411495844523

Epoch: 5| Step: 9
Training loss: 0.5312718152999878
Validation loss: 2.029038593173027

Epoch: 5| Step: 10
Training loss: 0.4842774271965027
Validation loss: 2.0316272576649985

Epoch: 5| Step: 11
Training loss: 0.42513227462768555
Validation loss: 2.019148493806521

Epoch: 286| Step: 0
Training loss: 0.5447620153427124
Validation loss: 2.0348804742097855

Epoch: 5| Step: 1
Training loss: 0.8443967700004578
Validation loss: 2.0144994209210076

Epoch: 5| Step: 2
Training loss: 0.6398394703865051
Validation loss: 2.079507455229759

Epoch: 5| Step: 3
Training loss: 0.983860969543457
Validation loss: 2.062086910009384

Epoch: 5| Step: 4
Training loss: 0.6558977365493774
Validation loss: 2.0609294970830283

Epoch: 5| Step: 5
Training loss: 0.4085511565208435
Validation loss: 2.010676925381025

Epoch: 5| Step: 6
Training loss: 0.4115460515022278
Validation loss: 2.032876213391622

Epoch: 5| Step: 7
Training loss: 0.5466293692588806
Validation loss: 2.033317486445109

Epoch: 5| Step: 8
Training loss: 0.8988780975341797
Validation loss: 2.054964746038119

Epoch: 5| Step: 9
Training loss: 0.49741992354393005
Validation loss: 2.072808086872101

Epoch: 5| Step: 10
Training loss: 0.9110078811645508
Validation loss: 2.074137975772222

Epoch: 5| Step: 11
Training loss: 0.37929296493530273
Validation loss: 2.0474769671758017

Epoch: 287| Step: 0
Training loss: 0.4021943211555481
Validation loss: 2.03414686024189

Epoch: 5| Step: 1
Training loss: 0.3950934112071991
Validation loss: 2.066128874818484

Epoch: 5| Step: 2
Training loss: 0.7480608820915222
Validation loss: 2.0346538722515106

Epoch: 5| Step: 3
Training loss: 0.8816580772399902
Validation loss: 2.0593284567197165

Epoch: 5| Step: 4
Training loss: 0.5261748433113098
Validation loss: 2.0672902166843414

Epoch: 5| Step: 5
Training loss: 0.370062917470932
Validation loss: 2.054866840442022

Epoch: 5| Step: 6
Training loss: 0.7756855487823486
Validation loss: 2.0633728156487146

Epoch: 5| Step: 7
Training loss: 0.4778442978858948
Validation loss: 2.035535082221031

Epoch: 5| Step: 8
Training loss: 0.9289854168891907
Validation loss: 2.036401549975077

Epoch: 5| Step: 9
Training loss: 0.49734383821487427
Validation loss: 2.014927953481674

Epoch: 5| Step: 10
Training loss: 0.7865296602249146
Validation loss: 2.029170607527097

Epoch: 5| Step: 11
Training loss: 0.979308009147644
Validation loss: 2.043987974524498

Epoch: 288| Step: 0
Training loss: 0.5128945112228394
Validation loss: 2.046730329593023

Epoch: 5| Step: 1
Training loss: 0.7402974367141724
Validation loss: 2.00628270705541

Epoch: 5| Step: 2
Training loss: 0.9786229133605957
Validation loss: 2.0341989248991013

Epoch: 5| Step: 3
Training loss: 0.9016455411911011
Validation loss: 2.0520499596993127

Epoch: 5| Step: 4
Training loss: 0.32818853855133057
Validation loss: 1.9986923187971115

Epoch: 5| Step: 5
Training loss: 0.5492594242095947
Validation loss: 2.0069644898176193

Epoch: 5| Step: 6
Training loss: 0.5320851802825928
Validation loss: 2.0523655861616135

Epoch: 5| Step: 7
Training loss: 0.4346606731414795
Validation loss: 2.004738728205363

Epoch: 5| Step: 8
Training loss: 0.45931750535964966
Validation loss: 2.0365101993083954

Epoch: 5| Step: 9
Training loss: 0.6262475848197937
Validation loss: 1.9966295957565308

Epoch: 5| Step: 10
Training loss: 0.46622270345687866
Validation loss: 2.0447502036889396

Epoch: 5| Step: 11
Training loss: 1.1072874069213867
Validation loss: 1.997954621911049

Epoch: 289| Step: 0
Training loss: 0.4429987072944641
Validation loss: 2.0182975629965463

Epoch: 5| Step: 1
Training loss: 0.6913975477218628
Validation loss: 2.0219580779472985

Epoch: 5| Step: 2
Training loss: 0.37074655294418335
Validation loss: 2.03824974099795

Epoch: 5| Step: 3
Training loss: 0.8455306887626648
Validation loss: 2.0533564339081445

Epoch: 5| Step: 4
Training loss: 0.5149465799331665
Validation loss: 2.046892171104749

Epoch: 5| Step: 5
Training loss: 0.4169921875
Validation loss: 2.004650726914406

Epoch: 5| Step: 6
Training loss: 0.8263037800788879
Validation loss: 2.05983600517114

Epoch: 5| Step: 7
Training loss: 0.8429397344589233
Validation loss: 2.018715649843216

Epoch: 5| Step: 8
Training loss: 0.8356429934501648
Validation loss: 2.0187686582406363

Epoch: 5| Step: 9
Training loss: 0.5316988229751587
Validation loss: 2.036622315645218

Epoch: 5| Step: 10
Training loss: 0.25583377480506897
Validation loss: 2.0583115766445794

Epoch: 5| Step: 11
Training loss: 0.5573787689208984
Validation loss: 2.052735522389412

Epoch: 290| Step: 0
Training loss: 0.7045769691467285
Validation loss: 2.012983982761701

Epoch: 5| Step: 1
Training loss: 0.44003695249557495
Validation loss: 2.049422333637873

Epoch: 5| Step: 2
Training loss: 0.7414592504501343
Validation loss: 2.0346145729223886

Epoch: 5| Step: 3
Training loss: 0.36237597465515137
Validation loss: 2.0812625040610633

Epoch: 5| Step: 4
Training loss: 0.48877763748168945
Validation loss: 2.0348478108644485

Epoch: 5| Step: 5
Training loss: 0.6240031123161316
Validation loss: 2.025902360677719

Epoch: 5| Step: 6
Training loss: 0.2689502239227295
Validation loss: 2.0500688751538596

Epoch: 5| Step: 7
Training loss: 0.7549988627433777
Validation loss: 2.041208749016126

Epoch: 5| Step: 8
Training loss: 0.8584005236625671
Validation loss: 2.0316559274991355

Epoch: 5| Step: 9
Training loss: 0.44219905138015747
Validation loss: 2.0383416016896567

Epoch: 5| Step: 10
Training loss: 0.8406310081481934
Validation loss: 2.0588403195142746

Epoch: 5| Step: 11
Training loss: 0.7465157508850098
Validation loss: 2.0659369925657907

Epoch: 291| Step: 0
Training loss: 0.321492463350296
Validation loss: 2.023451328277588

Epoch: 5| Step: 1
Training loss: 0.4433794915676117
Validation loss: 2.068643649419149

Epoch: 5| Step: 2
Training loss: 0.6592482328414917
Validation loss: 2.0705772986014686

Epoch: 5| Step: 3
Training loss: 0.3716059923171997
Validation loss: 2.0636507471402488

Epoch: 5| Step: 4
Training loss: 0.3825133740901947
Validation loss: 2.036234696706136

Epoch: 5| Step: 5
Training loss: 0.5502803921699524
Validation loss: 2.048722212513288

Epoch: 5| Step: 6
Training loss: 0.5070018768310547
Validation loss: 2.067722643415133

Epoch: 5| Step: 7
Training loss: 0.9017623066902161
Validation loss: 2.0232099841038385

Epoch: 5| Step: 8
Training loss: 0.8001416325569153
Validation loss: 2.0646489957968392

Epoch: 5| Step: 9
Training loss: 0.7130913138389587
Validation loss: 2.023197958866755

Epoch: 5| Step: 10
Training loss: 0.9722627401351929
Validation loss: 2.0275464355945587

Epoch: 5| Step: 11
Training loss: 0.3841063380241394
Validation loss: 2.056238447626432

Epoch: 292| Step: 0
Training loss: 0.5782787203788757
Validation loss: 2.062883491317431

Epoch: 5| Step: 1
Training loss: 0.4796629846096039
Validation loss: 2.087728629509608

Epoch: 5| Step: 2
Training loss: 0.5498116612434387
Validation loss: 2.0647586534420648

Epoch: 5| Step: 3
Training loss: 0.5156151056289673
Validation loss: 2.0876705050468445

Epoch: 5| Step: 4
Training loss: 0.5186853408813477
Validation loss: 2.0585378805796304

Epoch: 5| Step: 5
Training loss: 0.7272791862487793
Validation loss: 2.067791427175204

Epoch: 5| Step: 6
Training loss: 0.6282126903533936
Validation loss: 2.039546156922976

Epoch: 5| Step: 7
Training loss: 0.5583304166793823
Validation loss: 2.0453722874323526

Epoch: 5| Step: 8
Training loss: 0.4790855348110199
Validation loss: 2.066760857899984

Epoch: 5| Step: 9
Training loss: 0.9823697805404663
Validation loss: 2.0536943624416986

Epoch: 5| Step: 10
Training loss: 0.42200642824172974
Validation loss: 2.047935505708059

Epoch: 5| Step: 11
Training loss: 0.27098262310028076
Validation loss: 2.026376262307167

Epoch: 293| Step: 0
Training loss: 0.3892666697502136
Validation loss: 2.0015438199043274

Epoch: 5| Step: 1
Training loss: 0.6368072032928467
Validation loss: 2.01901180545489

Epoch: 5| Step: 2
Training loss: 0.4767903685569763
Validation loss: 2.0225240339835486

Epoch: 5| Step: 3
Training loss: 0.6920272707939148
Validation loss: 2.0071118026971817

Epoch: 5| Step: 4
Training loss: 0.6368452906608582
Validation loss: 2.0265782525142035

Epoch: 5| Step: 5
Training loss: 0.4692784249782562
Validation loss: 2.001388688882192

Epoch: 5| Step: 6
Training loss: 0.707222580909729
Validation loss: 2.066701129078865

Epoch: 5| Step: 7
Training loss: 0.5816431045532227
Validation loss: 2.075319310029348

Epoch: 5| Step: 8
Training loss: 0.7596880197525024
Validation loss: 2.075595607360204

Epoch: 5| Step: 9
Training loss: 0.4645621180534363
Validation loss: 2.070134694377581

Epoch: 5| Step: 10
Training loss: 0.5584958791732788
Validation loss: 2.0296717484792075

Epoch: 5| Step: 11
Training loss: 0.22768551111221313
Validation loss: 2.027191529671351

Epoch: 294| Step: 0
Training loss: 0.3274294435977936
Validation loss: 2.0405599574247995

Epoch: 5| Step: 1
Training loss: 0.8594285845756531
Validation loss: 2.0279542058706284

Epoch: 5| Step: 2
Training loss: 0.7723060846328735
Validation loss: 2.0697241028149924

Epoch: 5| Step: 3
Training loss: 0.25030165910720825
Validation loss: 2.0508576035499573

Epoch: 5| Step: 4
Training loss: 0.29622024297714233
Validation loss: 2.026922732591629

Epoch: 5| Step: 5
Training loss: 0.7074264287948608
Validation loss: 2.0523729423681893

Epoch: 5| Step: 6
Training loss: 0.7516986131668091
Validation loss: 2.0575114687283835

Epoch: 5| Step: 7
Training loss: 0.8631860613822937
Validation loss: 2.022250513235728

Epoch: 5| Step: 8
Training loss: 0.42560261487960815
Validation loss: 2.0170351515213647

Epoch: 5| Step: 9
Training loss: 0.3023863434791565
Validation loss: 2.0578414102395377

Epoch: 5| Step: 10
Training loss: 0.6542661786079407
Validation loss: 2.0349609504143396

Epoch: 5| Step: 11
Training loss: 0.45878350734710693
Validation loss: 2.034491086999575

Epoch: 295| Step: 0
Training loss: 0.638114869594574
Validation loss: 2.0283218175172806

Epoch: 5| Step: 1
Training loss: 0.5335962772369385
Validation loss: 2.02527262767156

Epoch: 5| Step: 2
Training loss: 0.745675265789032
Validation loss: 2.0264568279186883

Epoch: 5| Step: 3
Training loss: 0.898716151714325
Validation loss: 2.0943134228388467

Epoch: 5| Step: 4
Training loss: 0.4709346294403076
Validation loss: 2.0755086541175842

Epoch: 5| Step: 5
Training loss: 1.3550161123275757
Validation loss: 2.0181307643651962

Epoch: 5| Step: 6
Training loss: 0.4686752259731293
Validation loss: 2.041124333937963

Epoch: 5| Step: 7
Training loss: 0.37690025568008423
Validation loss: 2.0467771838108697

Epoch: 5| Step: 8
Training loss: 0.29246586561203003
Validation loss: 2.0412632524967194

Epoch: 5| Step: 9
Training loss: 0.3177018463611603
Validation loss: 2.024483323097229

Epoch: 5| Step: 10
Training loss: 0.7507895231246948
Validation loss: 2.0846045712629953

Epoch: 5| Step: 11
Training loss: 1.0401113033294678
Validation loss: 2.0351080944140754

Epoch: 296| Step: 0
Training loss: 0.6018193960189819
Validation loss: 2.0459965566794076

Epoch: 5| Step: 1
Training loss: 0.9044774770736694
Validation loss: 2.037817766269048

Epoch: 5| Step: 2
Training loss: 0.624561607837677
Validation loss: 1.993139535188675

Epoch: 5| Step: 3
Training loss: 0.8445340394973755
Validation loss: 2.003594463070234

Epoch: 5| Step: 4
Training loss: 0.6400510668754578
Validation loss: 2.026983544230461

Epoch: 5| Step: 5
Training loss: 0.6437129974365234
Validation loss: 1.9832083384195964

Epoch: 5| Step: 6
Training loss: 0.8797826766967773
Validation loss: 2.038281872868538

Epoch: 5| Step: 7
Training loss: 0.4145292639732361
Validation loss: 2.0054214894771576

Epoch: 5| Step: 8
Training loss: 0.4724701941013336
Validation loss: 2.0643783112366996

Epoch: 5| Step: 9
Training loss: 0.46289220452308655
Validation loss: 2.034169703722

Epoch: 5| Step: 10
Training loss: 0.4094448983669281
Validation loss: 2.0641188621520996

Epoch: 5| Step: 11
Training loss: 0.2385898232460022
Validation loss: 2.0220142056544623

Epoch: 297| Step: 0
Training loss: 1.0526872873306274
Validation loss: 2.0262586772441864

Epoch: 5| Step: 1
Training loss: 0.45198631286621094
Validation loss: 2.030012294650078

Epoch: 5| Step: 2
Training loss: 0.4894433915615082
Validation loss: 2.0150752663612366

Epoch: 5| Step: 3
Training loss: 0.8288692235946655
Validation loss: 2.028675009806951

Epoch: 5| Step: 4
Training loss: 0.3997786045074463
Validation loss: 2.072311739126841

Epoch: 5| Step: 5
Training loss: 0.856881320476532
Validation loss: 2.0261706560850143

Epoch: 5| Step: 6
Training loss: 0.6206434965133667
Validation loss: 2.0289657612641654

Epoch: 5| Step: 7
Training loss: 0.4638708233833313
Validation loss: 2.039215460419655

Epoch: 5| Step: 8
Training loss: 0.6936112642288208
Validation loss: 2.0703854262828827

Epoch: 5| Step: 9
Training loss: 0.43473339080810547
Validation loss: 2.0384255001942315

Epoch: 5| Step: 10
Training loss: 0.5276039838790894
Validation loss: 2.057818651199341

Epoch: 5| Step: 11
Training loss: 0.562495231628418
Validation loss: 2.0202200015385947

Epoch: 298| Step: 0
Training loss: 0.4314325451850891
Validation loss: 2.0460260808467865

Epoch: 5| Step: 1
Training loss: 0.8867559432983398
Validation loss: 2.0339229752620063

Epoch: 5| Step: 2
Training loss: 0.5106647610664368
Validation loss: 2.0591264019409814

Epoch: 5| Step: 3
Training loss: 0.30263400077819824
Validation loss: 1.9818925509850185

Epoch: 5| Step: 4
Training loss: 0.525765061378479
Validation loss: 2.0435862690210342

Epoch: 5| Step: 5
Training loss: 0.8800069689750671
Validation loss: 1.9988397061824799

Epoch: 5| Step: 6
Training loss: 0.4794723391532898
Validation loss: 2.02667802075545

Epoch: 5| Step: 7
Training loss: 0.5329846143722534
Validation loss: 2.0514998932679496

Epoch: 5| Step: 8
Training loss: 0.6729259490966797
Validation loss: 2.0077223430077233

Epoch: 5| Step: 9
Training loss: 0.6377608180046082
Validation loss: 2.009452760219574

Epoch: 5| Step: 10
Training loss: 0.7062909603118896
Validation loss: 2.019802580277125

Epoch: 5| Step: 11
Training loss: 0.3348360061645508
Validation loss: 2.007356916864713

Epoch: 299| Step: 0
Training loss: 0.46230602264404297
Validation loss: 2.016296918193499

Epoch: 5| Step: 1
Training loss: 0.3616701662540436
Validation loss: 2.0452019770940146

Epoch: 5| Step: 2
Training loss: 0.7275072932243347
Validation loss: 1.9996562898159027

Epoch: 5| Step: 3
Training loss: 0.9283855557441711
Validation loss: 2.067602495352427

Epoch: 5| Step: 4
Training loss: 0.5044103860855103
Validation loss: 2.028329625725746

Epoch: 5| Step: 5
Training loss: 0.6225191354751587
Validation loss: 2.009512181083361

Epoch: 5| Step: 6
Training loss: 0.48984259366989136
Validation loss: 2.044177586833636

Epoch: 5| Step: 7
Training loss: 0.44918376207351685
Validation loss: 2.0638973116874695

Epoch: 5| Step: 8
Training loss: 0.7895824313163757
Validation loss: 2.048745726545652

Epoch: 5| Step: 9
Training loss: 0.5452950596809387
Validation loss: 2.02710497379303

Epoch: 5| Step: 10
Training loss: 0.6446205973625183
Validation loss: 2.0487209061781564

Epoch: 5| Step: 11
Training loss: 0.34256887435913086
Validation loss: 2.061958904067675

Epoch: 300| Step: 0
Training loss: 0.8566239476203918
Validation loss: 2.043933644890785

Epoch: 5| Step: 1
Training loss: 0.3964309096336365
Validation loss: 2.041551431020101

Epoch: 5| Step: 2
Training loss: 0.7247942090034485
Validation loss: 2.0657930225133896

Epoch: 5| Step: 3
Training loss: 0.6918788552284241
Validation loss: 2.04291370511055

Epoch: 5| Step: 4
Training loss: 0.5106498003005981
Validation loss: 2.072178383668264

Epoch: 5| Step: 5
Training loss: 0.6520563364028931
Validation loss: 2.028584470351537

Epoch: 5| Step: 6
Training loss: 0.889478325843811
Validation loss: 2.0768392831087112

Epoch: 5| Step: 7
Training loss: 0.42415183782577515
Validation loss: 2.0825022558371225

Epoch: 5| Step: 8
Training loss: 0.3523826003074646
Validation loss: 2.080190743009249

Epoch: 5| Step: 9
Training loss: 0.5478474497795105
Validation loss: 2.070563773314158

Epoch: 5| Step: 10
Training loss: 0.35557010769844055
Validation loss: 2.0918189883232117

Epoch: 5| Step: 11
Training loss: 1.3224568367004395
Validation loss: 2.053994119167328

Epoch: 301| Step: 0
Training loss: 0.5982373952865601
Validation loss: 2.0338889360427856

Epoch: 5| Step: 1
Training loss: 0.6776971817016602
Validation loss: 2.0808745672305426

Epoch: 5| Step: 2
Training loss: 0.6046136021614075
Validation loss: 2.059350540240606

Epoch: 5| Step: 3
Training loss: 0.3911002278327942
Validation loss: 2.0339195330937705

Epoch: 5| Step: 4
Training loss: 0.362043559551239
Validation loss: 2.055171271165212

Epoch: 5| Step: 5
Training loss: 0.5596635937690735
Validation loss: 2.045024409890175

Epoch: 5| Step: 6
Training loss: 0.43556079268455505
Validation loss: 2.0842415541410446

Epoch: 5| Step: 7
Training loss: 0.6412184834480286
Validation loss: 2.0418711155653

Epoch: 5| Step: 8
Training loss: 0.45186394453048706
Validation loss: 2.0558151602745056

Epoch: 5| Step: 9
Training loss: 0.7628929615020752
Validation loss: 2.041327794392904

Epoch: 5| Step: 10
Training loss: 0.6605589985847473
Validation loss: 2.065831412871679

Epoch: 5| Step: 11
Training loss: 0.5271616578102112
Validation loss: 2.082426498333613

Epoch: 302| Step: 0
Training loss: 0.5182504653930664
Validation loss: 2.0480329593022666

Epoch: 5| Step: 1
Training loss: 0.7258742451667786
Validation loss: 2.0881665448347726

Epoch: 5| Step: 2
Training loss: 0.483454167842865
Validation loss: 2.030404433608055

Epoch: 5| Step: 3
Training loss: 0.9515599012374878
Validation loss: 2.0353327244520187

Epoch: 5| Step: 4
Training loss: 0.4964113235473633
Validation loss: 2.037126729885737

Epoch: 5| Step: 5
Training loss: 0.4149031639099121
Validation loss: 2.0615613162517548

Epoch: 5| Step: 6
Training loss: 0.4508237838745117
Validation loss: 2.0580728401740394

Epoch: 5| Step: 7
Training loss: 0.445080041885376
Validation loss: 2.041097750266393

Epoch: 5| Step: 8
Training loss: 0.46519285440444946
Validation loss: 2.040583461523056

Epoch: 5| Step: 9
Training loss: 0.29163843393325806
Validation loss: 2.035129656394323

Epoch: 5| Step: 10
Training loss: 0.6281867027282715
Validation loss: 2.0622963259617486

Epoch: 5| Step: 11
Training loss: 0.43879902362823486
Validation loss: 2.1017344097296395

Epoch: 303| Step: 0
Training loss: 0.5608059763908386
Validation loss: 2.0290521482626596

Epoch: 5| Step: 1
Training loss: 0.7460068464279175
Validation loss: 2.011619950334231

Epoch: 5| Step: 2
Training loss: 0.6104106903076172
Validation loss: 2.037908916672071

Epoch: 5| Step: 3
Training loss: 0.555790901184082
Validation loss: 2.0328094561894736

Epoch: 5| Step: 4
Training loss: 1.1335945129394531
Validation loss: 2.0422901610533395

Epoch: 5| Step: 5
Training loss: 0.3054433763027191
Validation loss: 2.0410107374191284

Epoch: 5| Step: 6
Training loss: 0.3344515264034271
Validation loss: 2.022110273440679

Epoch: 5| Step: 7
Training loss: 0.553846001625061
Validation loss: 2.0470729172229767

Epoch: 5| Step: 8
Training loss: 0.6767556071281433
Validation loss: 2.0510560224453607

Epoch: 5| Step: 9
Training loss: 0.5840855836868286
Validation loss: 2.084669351577759

Epoch: 5| Step: 10
Training loss: 0.5059536099433899
Validation loss: 2.0518334060907364

Epoch: 5| Step: 11
Training loss: 0.3506641387939453
Validation loss: 2.049786855777105

Epoch: 304| Step: 0
Training loss: 0.5105863809585571
Validation loss: 2.0584411174058914

Epoch: 5| Step: 1
Training loss: 0.627996563911438
Validation loss: 2.0304638743400574

Epoch: 5| Step: 2
Training loss: 0.6110230684280396
Validation loss: 2.0156430850426355

Epoch: 5| Step: 3
Training loss: 0.5383362770080566
Validation loss: 2.005589117606481

Epoch: 5| Step: 4
Training loss: 0.5132165551185608
Validation loss: 2.055703620115916

Epoch: 5| Step: 5
Training loss: 0.7110498547554016
Validation loss: 2.037486563126246

Epoch: 5| Step: 6
Training loss: 0.3378313183784485
Validation loss: 2.0382942855358124

Epoch: 5| Step: 7
Training loss: 0.8720465898513794
Validation loss: 2.000890240073204

Epoch: 5| Step: 8
Training loss: 0.6540037393569946
Validation loss: 2.006317382057508

Epoch: 5| Step: 9
Training loss: 0.4872627258300781
Validation loss: 1.991235728065173

Epoch: 5| Step: 10
Training loss: 0.5361846089363098
Validation loss: 2.015195126334826

Epoch: 5| Step: 11
Training loss: 0.16413187980651855
Validation loss: 2.0399970759948096

Epoch: 305| Step: 0
Training loss: 0.6052110195159912
Validation loss: 1.994145875175794

Epoch: 5| Step: 1
Training loss: 0.1405109465122223
Validation loss: 1.9709060887495677

Epoch: 5| Step: 2
Training loss: 0.5901901721954346
Validation loss: 2.0019957224527993

Epoch: 5| Step: 3
Training loss: 0.9826778173446655
Validation loss: 2.016582707564036

Epoch: 5| Step: 4
Training loss: 0.3293916583061218
Validation loss: 2.0137784431378045

Epoch: 5| Step: 5
Training loss: 0.7860445380210876
Validation loss: 2.0444813470045724

Epoch: 5| Step: 6
Training loss: 0.31046780943870544
Validation loss: 2.008149261275927

Epoch: 5| Step: 7
Training loss: 0.5506682991981506
Validation loss: 1.9809150199095409

Epoch: 5| Step: 8
Training loss: 0.5042423605918884
Validation loss: 2.0304219474395118

Epoch: 5| Step: 9
Training loss: 1.0397236347198486
Validation loss: 2.046075468262037

Epoch: 5| Step: 10
Training loss: 0.30642884969711304
Validation loss: 2.017301162083944

Epoch: 5| Step: 11
Training loss: 0.6536548733711243
Validation loss: 2.0348359992106757

Epoch: 306| Step: 0
Training loss: 0.6116963028907776
Validation loss: 2.0645837485790253

Epoch: 5| Step: 1
Training loss: 0.8043063879013062
Validation loss: 1.999563177426656

Epoch: 5| Step: 2
Training loss: 0.40110841393470764
Validation loss: 2.0549204299847283

Epoch: 5| Step: 3
Training loss: 0.4317159056663513
Validation loss: 2.0645939707756042

Epoch: 5| Step: 4
Training loss: 0.6082301139831543
Validation loss: 2.0617162734270096

Epoch: 5| Step: 5
Training loss: 0.368427574634552
Validation loss: 2.0572878619035087

Epoch: 5| Step: 6
Training loss: 0.3186159133911133
Validation loss: 2.0730476478735604

Epoch: 5| Step: 7
Training loss: 0.7324605584144592
Validation loss: 2.0663131028413773

Epoch: 5| Step: 8
Training loss: 0.5286294221878052
Validation loss: 2.0235317796468735

Epoch: 5| Step: 9
Training loss: 0.5195297002792358
Validation loss: 2.0072883615891137

Epoch: 5| Step: 10
Training loss: 0.7657696604728699
Validation loss: 1.987021451195081

Epoch: 5| Step: 11
Training loss: 0.04232454299926758
Validation loss: 2.043161153793335

Epoch: 307| Step: 0
Training loss: 0.7341574430465698
Validation loss: 2.040125146508217

Epoch: 5| Step: 1
Training loss: 0.8106015920639038
Validation loss: 2.0698351015647254

Epoch: 5| Step: 2
Training loss: 0.4696676731109619
Validation loss: 2.0390078673760095

Epoch: 5| Step: 3
Training loss: 0.6607591509819031
Validation loss: 2.0097958743572235

Epoch: 5| Step: 4
Training loss: 0.27009207010269165
Validation loss: 2.0303758333126702

Epoch: 5| Step: 5
Training loss: 0.5053588151931763
Validation loss: 2.032418524225553

Epoch: 5| Step: 6
Training loss: 0.9239538311958313
Validation loss: 2.0426324208577475

Epoch: 5| Step: 7
Training loss: 0.32454073429107666
Validation loss: 2.035321205854416

Epoch: 5| Step: 8
Training loss: 0.47808513045310974
Validation loss: 1.9731571276982625

Epoch: 5| Step: 9
Training loss: 0.7470303773880005
Validation loss: 2.059553454319636

Epoch: 5| Step: 10
Training loss: 0.26434606313705444
Validation loss: 2.0614831844965615

Epoch: 5| Step: 11
Training loss: 0.190413236618042
Validation loss: 2.001124064127604

Epoch: 308| Step: 0
Training loss: 0.38784700632095337
Validation loss: 2.045831640561422

Epoch: 5| Step: 1
Training loss: 0.5709554553031921
Validation loss: 2.0470337023337684

Epoch: 5| Step: 2
Training loss: 0.8202616572380066
Validation loss: 2.041989396015803

Epoch: 5| Step: 3
Training loss: 0.8491096496582031
Validation loss: 2.055180162191391

Epoch: 5| Step: 4
Training loss: 0.4582342505455017
Validation loss: 2.027491291364034

Epoch: 5| Step: 5
Training loss: 0.35721129179000854
Validation loss: 2.026465559999148

Epoch: 5| Step: 6
Training loss: 0.7191100716590881
Validation loss: 1.9956049770116806

Epoch: 5| Step: 7
Training loss: 0.798425555229187
Validation loss: 2.0063546945651374

Epoch: 5| Step: 8
Training loss: 0.5706031918525696
Validation loss: 2.02161413927873

Epoch: 5| Step: 9
Training loss: 0.253172904253006
Validation loss: 2.027273505926132

Epoch: 5| Step: 10
Training loss: 0.17485812306404114
Validation loss: 2.0613508224487305

Epoch: 5| Step: 11
Training loss: 0.05404120683670044
Validation loss: 2.0174071143070855

Epoch: 309| Step: 0
Training loss: 0.361045777797699
Validation loss: 2.0533372312784195

Epoch: 5| Step: 1
Training loss: 0.44856590032577515
Validation loss: 2.031689112385114

Epoch: 5| Step: 2
Training loss: 0.4890890121459961
Validation loss: 2.0522913336753845

Epoch: 5| Step: 3
Training loss: 0.6115608215332031
Validation loss: 2.061459635694822

Epoch: 5| Step: 4
Training loss: 0.7165654301643372
Validation loss: 2.084068720539411

Epoch: 5| Step: 5
Training loss: 0.6706596612930298
Validation loss: 2.0334006349245706

Epoch: 5| Step: 6
Training loss: 0.45033544301986694
Validation loss: 2.0243272483348846

Epoch: 5| Step: 7
Training loss: 0.5591695308685303
Validation loss: 2.0203626851240792

Epoch: 5| Step: 8
Training loss: 0.5351495742797852
Validation loss: 2.004442344109217

Epoch: 5| Step: 9
Training loss: 0.5175318121910095
Validation loss: 2.0409065385659537

Epoch: 5| Step: 10
Training loss: 0.5974702835083008
Validation loss: 2.034277155995369

Epoch: 5| Step: 11
Training loss: 0.4810408353805542
Validation loss: 2.05186760922273

Epoch: 310| Step: 0
Training loss: 0.5975589156150818
Validation loss: 2.020206853747368

Epoch: 5| Step: 1
Training loss: 0.9125099182128906
Validation loss: 2.06817859907945

Epoch: 5| Step: 2
Training loss: 0.5318962335586548
Validation loss: 2.0110936611890793

Epoch: 5| Step: 3
Training loss: 0.6991246938705444
Validation loss: 2.0451892018318176

Epoch: 5| Step: 4
Training loss: 0.48420628905296326
Validation loss: 2.0388969033956528

Epoch: 5| Step: 5
Training loss: 0.26817575097084045
Validation loss: 2.059243236978849

Epoch: 5| Step: 6
Training loss: 0.7169328927993774
Validation loss: 2.0424410551786423

Epoch: 5| Step: 7
Training loss: 0.23405209183692932
Validation loss: 2.0771940549214682

Epoch: 5| Step: 8
Training loss: 0.5554790496826172
Validation loss: 2.0813765029112496

Epoch: 5| Step: 9
Training loss: 0.2603350877761841
Validation loss: 2.0882540494203568

Epoch: 5| Step: 10
Training loss: 0.5355740785598755
Validation loss: 2.052577073375384

Epoch: 5| Step: 11
Training loss: 0.10164928436279297
Validation loss: 2.0762032022078833

Epoch: 311| Step: 0
Training loss: 0.724529504776001
Validation loss: 2.0527533441781998

Epoch: 5| Step: 1
Training loss: 0.49466967582702637
Validation loss: 2.0487209806839624

Epoch: 5| Step: 2
Training loss: 0.9832507967948914
Validation loss: 2.054235056042671

Epoch: 5| Step: 3
Training loss: 0.400749146938324
Validation loss: 2.07522218922774

Epoch: 5| Step: 4
Training loss: 0.5367198586463928
Validation loss: 2.083747868736585

Epoch: 5| Step: 5
Training loss: 0.5685031414031982
Validation loss: 2.0378604233264923

Epoch: 5| Step: 6
Training loss: 0.393704891204834
Validation loss: 2.024519845843315

Epoch: 5| Step: 7
Training loss: 0.5732384920120239
Validation loss: 2.0600192795197168

Epoch: 5| Step: 8
Training loss: 0.40177232027053833
Validation loss: 2.0328626135985055

Epoch: 5| Step: 9
Training loss: 0.4091629087924957
Validation loss: 2.029468754927317

Epoch: 5| Step: 10
Training loss: 0.3358997404575348
Validation loss: 2.047331670920054

Epoch: 5| Step: 11
Training loss: 0.691187858581543
Validation loss: 2.05915305018425

Epoch: 312| Step: 0
Training loss: 0.6207941174507141
Validation loss: 2.062089204788208

Epoch: 5| Step: 1
Training loss: 0.4822661876678467
Validation loss: 2.0641774783531823

Epoch: 5| Step: 2
Training loss: 0.5219405889511108
Validation loss: 2.005020226041476

Epoch: 5| Step: 3
Training loss: 0.3684088885784149
Validation loss: 2.0738429029782615

Epoch: 5| Step: 4
Training loss: 0.9694393277168274
Validation loss: 2.00156506896019

Epoch: 5| Step: 5
Training loss: 0.5083344578742981
Validation loss: 2.039461210370064

Epoch: 5| Step: 6
Training loss: 0.4720054268836975
Validation loss: 2.06315083305041

Epoch: 5| Step: 7
Training loss: 0.5061457753181458
Validation loss: 2.058849056561788

Epoch: 5| Step: 8
Training loss: 0.560484766960144
Validation loss: 2.0504289070765176

Epoch: 5| Step: 9
Training loss: 0.7227810621261597
Validation loss: 2.0479221691687903

Epoch: 5| Step: 10
Training loss: 0.560249924659729
Validation loss: 2.0319600900014243

Epoch: 5| Step: 11
Training loss: 0.9048542380332947
Validation loss: 2.0247242798407874

Epoch: 313| Step: 0
Training loss: 0.6670044660568237
Validation loss: 2.037605052193006

Epoch: 5| Step: 1
Training loss: 0.44724544882774353
Validation loss: 2.026100625594457

Epoch: 5| Step: 2
Training loss: 0.5261865854263306
Validation loss: 2.0589540799458823

Epoch: 5| Step: 3
Training loss: 0.44099292159080505
Validation loss: 2.0417746901512146

Epoch: 5| Step: 4
Training loss: 0.5645641088485718
Validation loss: 2.0953821490208306

Epoch: 5| Step: 5
Training loss: 0.3200366497039795
Validation loss: 2.0641906410455704

Epoch: 5| Step: 6
Training loss: 0.6996364593505859
Validation loss: 2.0875941117604575

Epoch: 5| Step: 7
Training loss: 0.5371701717376709
Validation loss: 2.0113983750343323

Epoch: 5| Step: 8
Training loss: 0.4508357048034668
Validation loss: 2.036745071411133

Epoch: 5| Step: 9
Training loss: 0.6762523651123047
Validation loss: 2.036173770825068

Epoch: 5| Step: 10
Training loss: 0.8514184951782227
Validation loss: 2.0362256864706674

Epoch: 5| Step: 11
Training loss: 0.5362093448638916
Validation loss: 2.0155717879533768

Epoch: 314| Step: 0
Training loss: 0.4538368582725525
Validation loss: 2.0512430469195047

Epoch: 5| Step: 1
Training loss: 0.6645205616950989
Validation loss: 2.0442371368408203

Epoch: 5| Step: 2
Training loss: 0.8664175868034363
Validation loss: 2.0030389527479806

Epoch: 5| Step: 3
Training loss: 0.6745263338088989
Validation loss: 2.038736273845037

Epoch: 5| Step: 4
Training loss: 0.4983927309513092
Validation loss: 2.06045571466287

Epoch: 5| Step: 5
Training loss: 0.33722782135009766
Validation loss: 2.0265573312838874

Epoch: 5| Step: 6
Training loss: 0.6686699986457825
Validation loss: 2.0406687557697296

Epoch: 5| Step: 7
Training loss: 0.5497924089431763
Validation loss: 2.0369166334470115

Epoch: 5| Step: 8
Training loss: 0.35829681158065796
Validation loss: 2.0733009229103723

Epoch: 5| Step: 9
Training loss: 0.6126161813735962
Validation loss: 2.0061991959810257

Epoch: 5| Step: 10
Training loss: 0.8446365594863892
Validation loss: 2.058980107307434

Epoch: 5| Step: 11
Training loss: 0.2643861770629883
Validation loss: 2.0090124209721885

Epoch: 315| Step: 0
Training loss: 0.5314684510231018
Validation loss: 2.0326664398113885

Epoch: 5| Step: 1
Training loss: 0.3198622167110443
Validation loss: 2.0734557012716928

Epoch: 5| Step: 2
Training loss: 0.8147815465927124
Validation loss: 2.0458830197652182

Epoch: 5| Step: 3
Training loss: 0.9495058059692383
Validation loss: 2.0434901217619577

Epoch: 5| Step: 4
Training loss: 0.40536409616470337
Validation loss: 2.0246763477722802

Epoch: 5| Step: 5
Training loss: 0.3382568955421448
Validation loss: 2.0899177292982736

Epoch: 5| Step: 6
Training loss: 0.4077381193637848
Validation loss: 2.067010516921679

Epoch: 5| Step: 7
Training loss: 0.5415137410163879
Validation loss: 2.043553759654363

Epoch: 5| Step: 8
Training loss: 0.40139904618263245
Validation loss: 2.0615495642026267

Epoch: 5| Step: 9
Training loss: 0.8451906442642212
Validation loss: 2.0715661396582923

Epoch: 5| Step: 10
Training loss: 0.6506935954093933
Validation loss: 2.0582774778207145

Epoch: 5| Step: 11
Training loss: 0.23600202798843384
Validation loss: 2.0818442702293396

Epoch: 316| Step: 0
Training loss: 0.6336594820022583
Validation loss: 2.0894712756077447

Epoch: 5| Step: 1
Training loss: 0.3912835419178009
Validation loss: 2.0341016401847205

Epoch: 5| Step: 2
Training loss: 0.695159912109375
Validation loss: 2.0548371771971383

Epoch: 5| Step: 3
Training loss: 0.6056380271911621
Validation loss: 2.033042083183924

Epoch: 5| Step: 4
Training loss: 0.35283201932907104
Validation loss: 2.054785947004954

Epoch: 5| Step: 5
Training loss: 0.5157071352005005
Validation loss: 1.9839386145273845

Epoch: 5| Step: 6
Training loss: 0.4652572572231293
Validation loss: 2.0695347090562186

Epoch: 5| Step: 7
Training loss: 0.8052303194999695
Validation loss: 1.996797929207484

Epoch: 5| Step: 8
Training loss: 0.35159245133399963
Validation loss: 2.0583347926537194

Epoch: 5| Step: 9
Training loss: 0.6963886618614197
Validation loss: 2.0746933917204538

Epoch: 5| Step: 10
Training loss: 0.23125657439231873
Validation loss: 2.031839703520139

Epoch: 5| Step: 11
Training loss: 0.8247705698013306
Validation loss: 2.049672305583954

Epoch: 317| Step: 0
Training loss: 0.4052768647670746
Validation loss: 2.0835501700639725

Epoch: 5| Step: 1
Training loss: 0.5481719374656677
Validation loss: 2.068184718489647

Epoch: 5| Step: 2
Training loss: 0.34751802682876587
Validation loss: 2.03917067249616

Epoch: 5| Step: 3
Training loss: 0.6240100860595703
Validation loss: 2.0227440744638443

Epoch: 5| Step: 4
Training loss: 0.5375984907150269
Validation loss: 2.0245229303836823

Epoch: 5| Step: 5
Training loss: 0.5771650075912476
Validation loss: 2.0716247161229453

Epoch: 5| Step: 6
Training loss: 0.7204569578170776
Validation loss: 2.0160763363043466

Epoch: 5| Step: 7
Training loss: 0.8369614481925964
Validation loss: 2.043417582909266

Epoch: 5| Step: 8
Training loss: 0.6938319206237793
Validation loss: 2.0545441607634225

Epoch: 5| Step: 9
Training loss: 0.4912504255771637
Validation loss: 2.0315047999223075

Epoch: 5| Step: 10
Training loss: 0.42783457040786743
Validation loss: 2.054989149173101

Epoch: 5| Step: 11
Training loss: 0.3513794541358948
Validation loss: 2.0861263473828635

Epoch: 318| Step: 0
Training loss: 0.4389254152774811
Validation loss: 2.1329344113667807

Epoch: 5| Step: 1
Training loss: 0.40936994552612305
Validation loss: 2.0404853026072183

Epoch: 5| Step: 2
Training loss: 0.5349278450012207
Validation loss: 2.0641308973232904

Epoch: 5| Step: 3
Training loss: 0.5252323150634766
Validation loss: 2.055797263979912

Epoch: 5| Step: 4
Training loss: 0.9064429402351379
Validation loss: 2.0744610875844955

Epoch: 5| Step: 5
Training loss: 0.43104925751686096
Validation loss: 2.072187786300977

Epoch: 5| Step: 6
Training loss: 0.9997434616088867
Validation loss: 2.0558921545743942

Epoch: 5| Step: 7
Training loss: 0.7654649019241333
Validation loss: 2.03591750562191

Epoch: 5| Step: 8
Training loss: 0.46331095695495605
Validation loss: 2.04302745560805

Epoch: 5| Step: 9
Training loss: 0.7131656408309937
Validation loss: 2.0559631288051605

Epoch: 5| Step: 10
Training loss: 0.696127712726593
Validation loss: 2.0581320921579995

Epoch: 5| Step: 11
Training loss: 0.18681657314300537
Validation loss: 2.0712720453739166

Epoch: 319| Step: 0
Training loss: 0.8729439973831177
Validation loss: 2.077677751580874

Epoch: 5| Step: 1
Training loss: 0.38230571150779724
Validation loss: 2.1017578889926276

Epoch: 5| Step: 2
Training loss: 0.7021572589874268
Validation loss: 2.084145983060201

Epoch: 5| Step: 3
Training loss: 0.4427967667579651
Validation loss: 2.1033791353305182

Epoch: 5| Step: 4
Training loss: 0.4383903443813324
Validation loss: 2.0349605083465576

Epoch: 5| Step: 5
Training loss: 0.4835706353187561
Validation loss: 2.0696678956349692

Epoch: 5| Step: 6
Training loss: 0.4153648316860199
Validation loss: 2.017089659969012

Epoch: 5| Step: 7
Training loss: 0.8516448736190796
Validation loss: 2.03584032257398

Epoch: 5| Step: 8
Training loss: 0.445796400308609
Validation loss: 2.027598058183988

Epoch: 5| Step: 9
Training loss: 0.7708632946014404
Validation loss: 2.022487332423528

Epoch: 5| Step: 10
Training loss: 0.5595875978469849
Validation loss: 2.0092104425032935

Epoch: 5| Step: 11
Training loss: 0.6898624897003174
Validation loss: 2.033691848317782

Epoch: 320| Step: 0
Training loss: 0.41483038663864136
Validation loss: 2.073795194427172

Epoch: 5| Step: 1
Training loss: 0.9340730905532837
Validation loss: 2.032555545369784

Epoch: 5| Step: 2
Training loss: 0.4643331468105316
Validation loss: 2.025969331463178

Epoch: 5| Step: 3
Training loss: 0.4733222424983978
Validation loss: 2.0104286670684814

Epoch: 5| Step: 4
Training loss: 0.6708847880363464
Validation loss: 2.0708430310090384

Epoch: 5| Step: 5
Training loss: 0.7179059386253357
Validation loss: 2.0309967001279197

Epoch: 5| Step: 6
Training loss: 0.5015484690666199
Validation loss: 2.06313756108284

Epoch: 5| Step: 7
Training loss: 0.8531292080879211
Validation loss: 2.036685809493065

Epoch: 5| Step: 8
Training loss: 0.51099693775177
Validation loss: 2.0342643409967422

Epoch: 5| Step: 9
Training loss: 0.2434094399213791
Validation loss: 2.0653353383143744

Epoch: 5| Step: 10
Training loss: 0.5784689784049988
Validation loss: 2.087398022413254

Epoch: 5| Step: 11
Training loss: 0.2594364881515503
Validation loss: 2.0617329627275467

Epoch: 321| Step: 0
Training loss: 0.7644447684288025
Validation loss: 2.0931384215752282

Epoch: 5| Step: 1
Training loss: 0.46791204810142517
Validation loss: 2.068265199661255

Epoch: 5| Step: 2
Training loss: 0.3452731668949127
Validation loss: 2.118370453516642

Epoch: 5| Step: 3
Training loss: 0.5745778679847717
Validation loss: 2.0601208806037903

Epoch: 5| Step: 4
Training loss: 0.7120173573493958
Validation loss: 2.0850173284610114

Epoch: 5| Step: 5
Training loss: 0.4090935289859772
Validation loss: 2.0404448360204697

Epoch: 5| Step: 6
Training loss: 0.3872778117656708
Validation loss: 2.056249658266703

Epoch: 5| Step: 7
Training loss: 0.7191214561462402
Validation loss: 2.063011641303698

Epoch: 5| Step: 8
Training loss: 0.6607047319412231
Validation loss: 2.055727223555247

Epoch: 5| Step: 9
Training loss: 0.6970175504684448
Validation loss: 2.0598715941111245

Epoch: 5| Step: 10
Training loss: 0.5418900847434998
Validation loss: 2.05979851881663

Epoch: 5| Step: 11
Training loss: 0.5287548303604126
Validation loss: 2.04819825788339

Epoch: 322| Step: 0
Training loss: 0.652937114238739
Validation loss: 2.047782431046168

Epoch: 5| Step: 1
Training loss: 0.479847252368927
Validation loss: 2.060795779029528

Epoch: 5| Step: 2
Training loss: 0.5126367807388306
Validation loss: 2.0443005363146463

Epoch: 5| Step: 3
Training loss: 0.6472523808479309
Validation loss: 2.0543365279833474

Epoch: 5| Step: 4
Training loss: 0.4663984179496765
Validation loss: 2.03588297466437

Epoch: 5| Step: 5
Training loss: 0.9006948471069336
Validation loss: 2.0830214470624924

Epoch: 5| Step: 6
Training loss: 0.24169091880321503
Validation loss: 2.03570094704628

Epoch: 5| Step: 7
Training loss: 0.5723283886909485
Validation loss: 2.059464251001676

Epoch: 5| Step: 8
Training loss: 0.5205495953559875
Validation loss: 2.0414220889409385

Epoch: 5| Step: 9
Training loss: 0.8812493085861206
Validation loss: 2.0318125188350677

Epoch: 5| Step: 10
Training loss: 0.39297449588775635
Validation loss: 2.028280188639959

Epoch: 5| Step: 11
Training loss: 0.15409541130065918
Validation loss: 2.068432872494062

Epoch: 323| Step: 0
Training loss: 0.9095543026924133
Validation loss: 2.1033144990603128

Epoch: 5| Step: 1
Training loss: 0.4362357258796692
Validation loss: 2.084558685620626

Epoch: 5| Step: 2
Training loss: 0.589781641960144
Validation loss: 2.1106308549642563

Epoch: 5| Step: 3
Training loss: 1.1657068729400635
Validation loss: 2.0894246796766915

Epoch: 5| Step: 4
Training loss: 0.325905978679657
Validation loss: 2.08861280977726

Epoch: 5| Step: 5
Training loss: 0.5504031777381897
Validation loss: 2.0733598669370017

Epoch: 5| Step: 6
Training loss: 0.584795355796814
Validation loss: 2.0099484771490097

Epoch: 5| Step: 7
Training loss: 0.3580956757068634
Validation loss: 2.052665134270986

Epoch: 5| Step: 8
Training loss: 0.4571347236633301
Validation loss: 2.057335456212362

Epoch: 5| Step: 9
Training loss: 0.5553084015846252
Validation loss: 2.054522827267647

Epoch: 5| Step: 10
Training loss: 0.6848214864730835
Validation loss: 2.02713776131471

Epoch: 5| Step: 11
Training loss: 0.818647563457489
Validation loss: 2.016202613711357

Epoch: 324| Step: 0
Training loss: 0.5479900240898132
Validation loss: 2.0091733833154044

Epoch: 5| Step: 1
Training loss: 0.4974757730960846
Validation loss: 2.043792655070623

Epoch: 5| Step: 2
Training loss: 0.6257551908493042
Validation loss: 2.0374201933542886

Epoch: 5| Step: 3
Training loss: 0.2677873969078064
Validation loss: 2.0591507454713187

Epoch: 5| Step: 4
Training loss: 0.6116797924041748
Validation loss: 2.057970091700554

Epoch: 5| Step: 5
Training loss: 0.7478985786437988
Validation loss: 2.039688150087992

Epoch: 5| Step: 6
Training loss: 0.24921484291553497
Validation loss: 2.0340654104948044

Epoch: 5| Step: 7
Training loss: 0.47090715169906616
Validation loss: 2.0093242476383844

Epoch: 5| Step: 8
Training loss: 0.4091520309448242
Validation loss: 2.0733609994252524

Epoch: 5| Step: 9
Training loss: 0.594652533531189
Validation loss: 2.0564524779717126

Epoch: 5| Step: 10
Training loss: 0.7049261331558228
Validation loss: 2.0573809146881104

Epoch: 5| Step: 11
Training loss: 0.8360471725463867
Validation loss: 2.0435315718253455

Epoch: 325| Step: 0
Training loss: 0.43554434180259705
Validation loss: 2.035372957587242

Epoch: 5| Step: 1
Training loss: 0.8063632249832153
Validation loss: 2.0397415459156036

Epoch: 5| Step: 2
Training loss: 0.6323041319847107
Validation loss: 2.022390216588974

Epoch: 5| Step: 3
Training loss: 0.37604230642318726
Validation loss: 2.0447200735410056

Epoch: 5| Step: 4
Training loss: 0.4741365313529968
Validation loss: 2.0279309252897897

Epoch: 5| Step: 5
Training loss: 0.3290632665157318
Validation loss: 2.0433268745740256

Epoch: 5| Step: 6
Training loss: 0.5628217458724976
Validation loss: 2.054340382417043

Epoch: 5| Step: 7
Training loss: 0.5212754607200623
Validation loss: 2.0085275073846183

Epoch: 5| Step: 8
Training loss: 0.31188637018203735
Validation loss: 2.0300147285064063

Epoch: 5| Step: 9
Training loss: 0.7959104180335999
Validation loss: 2.008170341451963

Epoch: 5| Step: 10
Training loss: 0.5853387117385864
Validation loss: 2.0483516454696655

Epoch: 5| Step: 11
Training loss: 0.272102415561676
Validation loss: 2.0458474109570184

Epoch: 326| Step: 0
Training loss: 0.2653321623802185
Validation loss: 2.048379232486089

Epoch: 5| Step: 1
Training loss: 0.35014379024505615
Validation loss: 2.0320724745591483

Epoch: 5| Step: 2
Training loss: 0.4398248791694641
Validation loss: 2.046331822872162

Epoch: 5| Step: 3
Training loss: 0.8552452921867371
Validation loss: 2.0122488041718802

Epoch: 5| Step: 4
Training loss: 0.7188948392868042
Validation loss: 2.0166332870721817

Epoch: 5| Step: 5
Training loss: 0.2889927625656128
Validation loss: 2.0144215325514474

Epoch: 5| Step: 6
Training loss: 0.5033535361289978
Validation loss: 2.0398316929737725

Epoch: 5| Step: 7
Training loss: 0.3305699825286865
Validation loss: 2.0659755766391754

Epoch: 5| Step: 8
Training loss: 0.3600778877735138
Validation loss: 2.0471731076637902

Epoch: 5| Step: 9
Training loss: 0.43822699785232544
Validation loss: 2.039370914300283

Epoch: 5| Step: 10
Training loss: 0.8325834274291992
Validation loss: 2.0049803107976913

Epoch: 5| Step: 11
Training loss: 1.081936001777649
Validation loss: 2.043858826160431

Epoch: 327| Step: 0
Training loss: 0.43920379877090454
Validation loss: 2.038016065955162

Epoch: 5| Step: 1
Training loss: 0.47168102860450745
Validation loss: 2.019397040208181

Epoch: 5| Step: 2
Training loss: 0.647748589515686
Validation loss: 2.0260947197675705

Epoch: 5| Step: 3
Training loss: 0.5858810544013977
Validation loss: 2.060691863298416

Epoch: 5| Step: 4
Training loss: 0.6175611615180969
Validation loss: 2.058464546998342

Epoch: 5| Step: 5
Training loss: 0.45030611753463745
Validation loss: 2.041266535719236

Epoch: 5| Step: 6
Training loss: 0.4392774999141693
Validation loss: 2.042075976729393

Epoch: 5| Step: 7
Training loss: 0.6075872182846069
Validation loss: 2.0594337731599808

Epoch: 5| Step: 8
Training loss: 0.3562011122703552
Validation loss: 2.03155916929245

Epoch: 5| Step: 9
Training loss: 0.5988798141479492
Validation loss: 2.0517735928297043

Epoch: 5| Step: 10
Training loss: 0.3804762065410614
Validation loss: 2.050129493077596

Epoch: 5| Step: 11
Training loss: 1.0976688861846924
Validation loss: 2.070573995510737

Epoch: 328| Step: 0
Training loss: 0.4756799638271332
Validation loss: 2.042229210337003

Epoch: 5| Step: 1
Training loss: 0.49335533380508423
Validation loss: 2.0233503381411233

Epoch: 5| Step: 2
Training loss: 0.36143001914024353
Validation loss: 2.043697029352188

Epoch: 5| Step: 3
Training loss: 0.21818582713603973
Validation loss: 2.0457600305477777

Epoch: 5| Step: 4
Training loss: 0.7948980331420898
Validation loss: 2.0764504124720893

Epoch: 5| Step: 5
Training loss: 0.2701647877693176
Validation loss: 2.0465759684642157

Epoch: 5| Step: 6
Training loss: 0.7201967239379883
Validation loss: 2.053656359513601

Epoch: 5| Step: 7
Training loss: 0.3785524368286133
Validation loss: 2.0909528583288193

Epoch: 5| Step: 8
Training loss: 0.6761170625686646
Validation loss: 2.0499193569024405

Epoch: 5| Step: 9
Training loss: 0.4367319941520691
Validation loss: 2.0575095415115356

Epoch: 5| Step: 10
Training loss: 0.7341244220733643
Validation loss: 2.0876189321279526

Epoch: 5| Step: 11
Training loss: 0.15105798840522766
Validation loss: 2.0679843922456107

Epoch: 329| Step: 0
Training loss: 0.7747712135314941
Validation loss: 2.0471559514602027

Epoch: 5| Step: 1
Training loss: 0.3390425145626068
Validation loss: 2.0563460886478424

Epoch: 5| Step: 2
Training loss: 0.3156769871711731
Validation loss: 2.055017943183581

Epoch: 5| Step: 3
Training loss: 1.0496522188186646
Validation loss: 2.059682180484136

Epoch: 5| Step: 4
Training loss: 0.26739442348480225
Validation loss: 2.0565331826607385

Epoch: 5| Step: 5
Training loss: 0.4507543444633484
Validation loss: 2.0637617905934653

Epoch: 5| Step: 6
Training loss: 0.5402727127075195
Validation loss: 2.0473861346642175

Epoch: 5| Step: 7
Training loss: 0.6107740998268127
Validation loss: 2.036617025732994

Epoch: 5| Step: 8
Training loss: 0.308805376291275
Validation loss: 2.0359938889741898

Epoch: 5| Step: 9
Training loss: 0.8121225237846375
Validation loss: 2.010842243830363

Epoch: 5| Step: 10
Training loss: 0.3929958641529083
Validation loss: 2.0384897738695145

Epoch: 5| Step: 11
Training loss: 0.6281887888908386
Validation loss: 1.9823041905959446

Epoch: 330| Step: 0
Training loss: 0.3879256844520569
Validation loss: 2.022756357987722

Epoch: 5| Step: 1
Training loss: 0.382699191570282
Validation loss: 2.017232974370321

Epoch: 5| Step: 2
Training loss: 0.39391443133354187
Validation loss: 2.080316190918287

Epoch: 5| Step: 3
Training loss: 0.8028131723403931
Validation loss: 2.048071657617887

Epoch: 5| Step: 4
Training loss: 0.4341823160648346
Validation loss: 2.043638457854589

Epoch: 5| Step: 5
Training loss: 0.36156657338142395
Validation loss: 2.0445454816023507

Epoch: 5| Step: 6
Training loss: 0.7028883099555969
Validation loss: 2.041838213801384

Epoch: 5| Step: 7
Training loss: 0.7381986379623413
Validation loss: 2.0468854208787284

Epoch: 5| Step: 8
Training loss: 0.6649235486984253
Validation loss: 2.04359133541584

Epoch: 5| Step: 9
Training loss: 0.4519619941711426
Validation loss: 2.048548916975657

Epoch: 5| Step: 10
Training loss: 0.4268600344657898
Validation loss: 2.051315059264501

Epoch: 5| Step: 11
Training loss: 0.36248478293418884
Validation loss: 2.0189593036969504

Epoch: 331| Step: 0
Training loss: 0.26927876472473145
Validation loss: 2.0267013063033423

Epoch: 5| Step: 1
Training loss: 0.7643828988075256
Validation loss: 2.018004690607389

Epoch: 5| Step: 2
Training loss: 0.6978307962417603
Validation loss: 2.055344134569168

Epoch: 5| Step: 3
Training loss: 0.5617668032646179
Validation loss: 2.0485262920459113

Epoch: 5| Step: 4
Training loss: 0.2592499256134033
Validation loss: 2.032198448975881

Epoch: 5| Step: 5
Training loss: 0.4679289758205414
Validation loss: 2.049911007285118

Epoch: 5| Step: 6
Training loss: 0.7545310854911804
Validation loss: 2.049981693426768

Epoch: 5| Step: 7
Training loss: 0.36545127630233765
Validation loss: 2.048320949077606

Epoch: 5| Step: 8
Training loss: 0.8156588673591614
Validation loss: 2.052029028534889

Epoch: 5| Step: 9
Training loss: 0.3421640992164612
Validation loss: 2.0746271113554635

Epoch: 5| Step: 10
Training loss: 0.2912522256374359
Validation loss: 2.0847067634264627

Epoch: 5| Step: 11
Training loss: 0.4217524528503418
Validation loss: 2.069052199522654

Epoch: 332| Step: 0
Training loss: 0.5672143697738647
Validation loss: 2.036152998606364

Epoch: 5| Step: 1
Training loss: 0.33849474787712097
Validation loss: 2.0797279477119446

Epoch: 5| Step: 2
Training loss: 0.4840005040168762
Validation loss: 2.0693091998497644

Epoch: 5| Step: 3
Training loss: 0.6540281176567078
Validation loss: 2.060336803396543

Epoch: 5| Step: 4
Training loss: 0.6785507798194885
Validation loss: 2.013655627767245

Epoch: 5| Step: 5
Training loss: 0.39976176619529724
Validation loss: 2.046728958686193

Epoch: 5| Step: 6
Training loss: 0.6707007884979248
Validation loss: 1.9809532314538956

Epoch: 5| Step: 7
Training loss: 0.40906721353530884
Validation loss: 2.0693123936653137

Epoch: 5| Step: 8
Training loss: 0.5495315194129944
Validation loss: 2.022767206033071

Epoch: 5| Step: 9
Training loss: 0.752022385597229
Validation loss: 2.0019490122795105

Epoch: 5| Step: 10
Training loss: 0.23223397135734558
Validation loss: 2.038991222778956

Epoch: 5| Step: 11
Training loss: 0.1933409571647644
Validation loss: 1.9725709507862728

Epoch: 333| Step: 0
Training loss: 0.44438084959983826
Validation loss: 2.0509770711263022

Epoch: 5| Step: 1
Training loss: 0.4111405313014984
Validation loss: 2.019243896007538

Epoch: 5| Step: 2
Training loss: 0.4594441056251526
Validation loss: 2.0345979233582816

Epoch: 5| Step: 3
Training loss: 0.5403162837028503
Validation loss: 2.1083967636028924

Epoch: 5| Step: 4
Training loss: 0.6462377309799194
Validation loss: 2.056106840570768

Epoch: 5| Step: 5
Training loss: 0.422595739364624
Validation loss: 2.0407736798127494

Epoch: 5| Step: 6
Training loss: 0.16600412130355835
Validation loss: 2.0248687118291855

Epoch: 5| Step: 7
Training loss: 0.43236979842185974
Validation loss: 2.034884035587311

Epoch: 5| Step: 8
Training loss: 0.5573357343673706
Validation loss: 2.050238221883774

Epoch: 5| Step: 9
Training loss: 0.8025161623954773
Validation loss: 2.0158168425162635

Epoch: 5| Step: 10
Training loss: 0.46933072805404663
Validation loss: 2.0085425873597464

Epoch: 5| Step: 11
Training loss: 0.8816770911216736
Validation loss: 2.026100014646848

Epoch: 334| Step: 0
Training loss: 0.2559807598590851
Validation loss: 2.0487248053153357

Epoch: 5| Step: 1
Training loss: 0.5856836438179016
Validation loss: 2.0207334707180657

Epoch: 5| Step: 2
Training loss: 0.3045370280742645
Validation loss: 1.9894242137670517

Epoch: 5| Step: 3
Training loss: 0.38748717308044434
Validation loss: 2.042025238275528

Epoch: 5| Step: 4
Training loss: 0.46299514174461365
Validation loss: 2.0684688736995063

Epoch: 5| Step: 5
Training loss: 0.8003400564193726
Validation loss: 2.0215766429901123

Epoch: 5| Step: 6
Training loss: 0.7832634449005127
Validation loss: 2.02242940167586

Epoch: 5| Step: 7
Training loss: 0.6012382507324219
Validation loss: 2.054154093066851

Epoch: 5| Step: 8
Training loss: 0.7659847736358643
Validation loss: 2.065989171465238

Epoch: 5| Step: 9
Training loss: 0.2587643563747406
Validation loss: 2.0909588436285653

Epoch: 5| Step: 10
Training loss: 0.20933666825294495
Validation loss: 2.0659853319327035

Epoch: 5| Step: 11
Training loss: 0.6083903908729553
Validation loss: 2.051345000664393

Epoch: 335| Step: 0
Training loss: 0.35704097151756287
Validation loss: 2.0488194028536477

Epoch: 5| Step: 1
Training loss: 0.42248088121414185
Validation loss: 2.011950065692266

Epoch: 5| Step: 2
Training loss: 0.4611131548881531
Validation loss: 2.05388580262661

Epoch: 5| Step: 3
Training loss: 0.45220404863357544
Validation loss: 2.067739248275757

Epoch: 5| Step: 4
Training loss: 0.7432047724723816
Validation loss: 2.0563177267710366

Epoch: 5| Step: 5
Training loss: 0.4232848286628723
Validation loss: 2.033305952946345

Epoch: 5| Step: 6
Training loss: 0.41583919525146484
Validation loss: 2.0205021500587463

Epoch: 5| Step: 7
Training loss: 0.22265370190143585
Validation loss: 1.9971099942922592

Epoch: 5| Step: 8
Training loss: 0.8085037469863892
Validation loss: 2.0136667092641196

Epoch: 5| Step: 9
Training loss: 0.6035716533660889
Validation loss: 2.061249146858851

Epoch: 5| Step: 10
Training loss: 0.7544957399368286
Validation loss: 2.0219436585903168

Epoch: 5| Step: 11
Training loss: 1.040112018585205
Validation loss: 2.0563896894454956

Epoch: 336| Step: 0
Training loss: 0.6885017156600952
Validation loss: 2.045115292072296

Epoch: 5| Step: 1
Training loss: 0.5939368009567261
Validation loss: 2.0385348796844482

Epoch: 5| Step: 2
Training loss: 0.54330974817276
Validation loss: 2.0071342835823693

Epoch: 5| Step: 3
Training loss: 0.5211248397827148
Validation loss: 2.018809904654821

Epoch: 5| Step: 4
Training loss: 0.6094670295715332
Validation loss: 2.041755810379982

Epoch: 5| Step: 5
Training loss: 0.4262823164463043
Validation loss: 1.9894325534502666

Epoch: 5| Step: 6
Training loss: 0.4105050563812256
Validation loss: 2.042133758465449

Epoch: 5| Step: 7
Training loss: 0.37847745418548584
Validation loss: 2.0296525259812674

Epoch: 5| Step: 8
Training loss: 0.39255934953689575
Validation loss: 2.069157227873802

Epoch: 5| Step: 9
Training loss: 0.5713378190994263
Validation loss: 2.041252742211024

Epoch: 5| Step: 10
Training loss: 0.5988506078720093
Validation loss: 1.991898164153099

Epoch: 5| Step: 11
Training loss: 0.5398961305618286
Validation loss: 2.0365090370178223

Epoch: 337| Step: 0
Training loss: 0.6267123222351074
Validation loss: 2.079001565774282

Epoch: 5| Step: 1
Training loss: 0.337539404630661
Validation loss: 2.0388100296258926

Epoch: 5| Step: 2
Training loss: 0.5337744951248169
Validation loss: 2.065057635307312

Epoch: 5| Step: 3
Training loss: 0.5180248022079468
Validation loss: 2.041105886300405

Epoch: 5| Step: 4
Training loss: 0.3501841723918915
Validation loss: 2.060041452447573

Epoch: 5| Step: 5
Training loss: 0.5841759443283081
Validation loss: 2.008437136809031

Epoch: 5| Step: 6
Training loss: 0.40169715881347656
Validation loss: 2.069716289639473

Epoch: 5| Step: 7
Training loss: 0.26977092027664185
Validation loss: 2.055786947409312

Epoch: 5| Step: 8
Training loss: 0.7475118041038513
Validation loss: 2.051132410764694

Epoch: 5| Step: 9
Training loss: 0.47997626662254333
Validation loss: 2.0605729470650354

Epoch: 5| Step: 10
Training loss: 0.5295367240905762
Validation loss: 2.0797108759482703

Epoch: 5| Step: 11
Training loss: 0.5492309331893921
Validation loss: 2.0418047110239663

Epoch: 338| Step: 0
Training loss: 0.5605788230895996
Validation loss: 2.0404675950606666

Epoch: 5| Step: 1
Training loss: 0.567245364189148
Validation loss: 2.0624253352483115

Epoch: 5| Step: 2
Training loss: 0.3589037358760834
Validation loss: 2.0126258383194604

Epoch: 5| Step: 3
Training loss: 0.4444817900657654
Validation loss: 2.026341994603475

Epoch: 5| Step: 4
Training loss: 0.4146556258201599
Validation loss: 2.028601328531901

Epoch: 5| Step: 5
Training loss: 0.2265336513519287
Validation loss: 2.0312679409980774

Epoch: 5| Step: 6
Training loss: 0.6006649732589722
Validation loss: 2.047281881173452

Epoch: 5| Step: 7
Training loss: 0.46907562017440796
Validation loss: 1.9630022943019867

Epoch: 5| Step: 8
Training loss: 0.7989298105239868
Validation loss: 2.030324508746465

Epoch: 5| Step: 9
Training loss: 0.5538275241851807
Validation loss: 2.0359215438365936

Epoch: 5| Step: 10
Training loss: 0.36721307039260864
Validation loss: 2.027752553423246

Epoch: 5| Step: 11
Training loss: 0.40468305349349976
Validation loss: 2.0251642912626266

Epoch: 339| Step: 0
Training loss: 0.5995572805404663
Validation loss: 2.0243080258369446

Epoch: 5| Step: 1
Training loss: 0.22724811732769012
Validation loss: 2.055961017807325

Epoch: 5| Step: 2
Training loss: 0.4953588843345642
Validation loss: 2.0541661977767944

Epoch: 5| Step: 3
Training loss: 0.6495134234428406
Validation loss: 2.032250558336576

Epoch: 5| Step: 4
Training loss: 0.5796445608139038
Validation loss: 2.0393744707107544

Epoch: 5| Step: 5
Training loss: 0.4441760182380676
Validation loss: 2.052109196782112

Epoch: 5| Step: 6
Training loss: 0.3508550524711609
Validation loss: 2.0087488492329917

Epoch: 5| Step: 7
Training loss: 0.5165719389915466
Validation loss: 2.0419504741827645

Epoch: 5| Step: 8
Training loss: 0.34620195627212524
Validation loss: 2.0701046933730445

Epoch: 5| Step: 9
Training loss: 0.39126208424568176
Validation loss: 2.0361712276935577

Epoch: 5| Step: 10
Training loss: 0.8883693814277649
Validation loss: 2.016415521502495

Epoch: 5| Step: 11
Training loss: 0.28377604484558105
Validation loss: 2.006011351943016

Epoch: 340| Step: 0
Training loss: 0.7597001791000366
Validation loss: 2.036047418912252

Epoch: 5| Step: 1
Training loss: 0.4610691964626312
Validation loss: 2.034757157166799

Epoch: 5| Step: 2
Training loss: 0.49155837297439575
Validation loss: 2.0391985277334848

Epoch: 5| Step: 3
Training loss: 0.5255783200263977
Validation loss: 2.096172640721003

Epoch: 5| Step: 4
Training loss: 0.18147000670433044
Validation loss: 2.0246968368689218

Epoch: 5| Step: 5
Training loss: 0.27597951889038086
Validation loss: 2.081067552169164

Epoch: 5| Step: 6
Training loss: 0.5159803628921509
Validation loss: 2.039326637983322

Epoch: 5| Step: 7
Training loss: 0.9087273478507996
Validation loss: 2.062461242079735

Epoch: 5| Step: 8
Training loss: 0.6972616314888
Validation loss: 2.0547140737374625

Epoch: 5| Step: 9
Training loss: 0.5113435983657837
Validation loss: 2.065928176045418

Epoch: 5| Step: 10
Training loss: 0.5792660713195801
Validation loss: 2.0598327020804086

Epoch: 5| Step: 11
Training loss: 0.7135365009307861
Validation loss: 2.0624467631181083

Epoch: 341| Step: 0
Training loss: 0.45069122314453125
Validation loss: 2.04675163825353

Epoch: 5| Step: 1
Training loss: 0.4351533353328705
Validation loss: 2.043374478816986

Epoch: 5| Step: 2
Training loss: 0.4833020567893982
Validation loss: 2.078394671281179

Epoch: 5| Step: 3
Training loss: 0.5747421979904175
Validation loss: 2.0853052039941153

Epoch: 5| Step: 4
Training loss: 0.30228644609451294
Validation loss: 2.0527479549249015

Epoch: 5| Step: 5
Training loss: 0.49861717224121094
Validation loss: 2.057383125027021

Epoch: 5| Step: 6
Training loss: 1.2483127117156982
Validation loss: 2.0872652580340705

Epoch: 5| Step: 7
Training loss: 0.48936280608177185
Validation loss: 2.0740802536408105

Epoch: 5| Step: 8
Training loss: 0.42454394698143005
Validation loss: 2.0609185993671417

Epoch: 5| Step: 9
Training loss: 0.31921952962875366
Validation loss: 2.0468368430932364

Epoch: 5| Step: 10
Training loss: 0.43016546964645386
Validation loss: 2.058407634496689

Epoch: 5| Step: 11
Training loss: 0.14911043643951416
Validation loss: 2.0747208644946418

Epoch: 342| Step: 0
Training loss: 0.6395490765571594
Validation loss: 2.0789763977130256

Epoch: 5| Step: 1
Training loss: 0.6934700012207031
Validation loss: 2.1059245516856513

Epoch: 5| Step: 2
Training loss: 0.37999629974365234
Validation loss: 2.033708040912946

Epoch: 5| Step: 3
Training loss: 0.6002780795097351
Validation loss: 2.0638406773408255

Epoch: 5| Step: 4
Training loss: 0.3697969317436218
Validation loss: 2.0398584653933844

Epoch: 5| Step: 5
Training loss: 0.47996068000793457
Validation loss: 2.0536862164735794

Epoch: 5| Step: 6
Training loss: 0.5403703451156616
Validation loss: 2.0737798611323037

Epoch: 5| Step: 7
Training loss: 0.30903759598731995
Validation loss: 2.036957159638405

Epoch: 5| Step: 8
Training loss: 0.5115513801574707
Validation loss: 2.1163509835799537

Epoch: 5| Step: 9
Training loss: 0.5747722387313843
Validation loss: 2.027146796385447

Epoch: 5| Step: 10
Training loss: 0.44395798444747925
Validation loss: 2.058341925342878

Epoch: 5| Step: 11
Training loss: 0.773474931716919
Validation loss: 2.0243354539076486

Epoch: 343| Step: 0
Training loss: 0.49957847595214844
Validation loss: 2.0734523087739944

Epoch: 5| Step: 1
Training loss: 0.6509689092636108
Validation loss: 2.1154581209023795

Epoch: 5| Step: 2
Training loss: 0.3856712877750397
Validation loss: 2.0822803477446237

Epoch: 5| Step: 3
Training loss: 0.5647099614143372
Validation loss: 2.0508927454551062

Epoch: 5| Step: 4
Training loss: 0.589413046836853
Validation loss: 2.066348761320114

Epoch: 5| Step: 5
Training loss: 0.5420204401016235
Validation loss: 2.0693877190351486

Epoch: 5| Step: 6
Training loss: 0.6766764521598816
Validation loss: 2.07142540315787

Epoch: 5| Step: 7
Training loss: 0.3233051896095276
Validation loss: 2.065630932648977

Epoch: 5| Step: 8
Training loss: 0.3862532675266266
Validation loss: 2.051373983422915

Epoch: 5| Step: 9
Training loss: 0.3685002326965332
Validation loss: 2.052567626039187

Epoch: 5| Step: 10
Training loss: 0.3239855170249939
Validation loss: 2.064643914500872

Epoch: 5| Step: 11
Training loss: 0.2413397878408432
Validation loss: 2.0576379895210266

Epoch: 344| Step: 0
Training loss: 0.49778634309768677
Validation loss: 2.044190362095833

Epoch: 5| Step: 1
Training loss: 0.7245612740516663
Validation loss: 2.0734002888202667

Epoch: 5| Step: 2
Training loss: 0.4438420236110687
Validation loss: 2.093879888455073

Epoch: 5| Step: 3
Training loss: 0.4652389585971832
Validation loss: 2.063992351293564

Epoch: 5| Step: 4
Training loss: 0.8568002581596375
Validation loss: 2.1086130986611047

Epoch: 5| Step: 5
Training loss: 0.4050918519496918
Validation loss: 2.074028357863426

Epoch: 5| Step: 6
Training loss: 0.41072192788124084
Validation loss: 2.058616856733958

Epoch: 5| Step: 7
Training loss: 0.19499139487743378
Validation loss: 2.0449528843164444

Epoch: 5| Step: 8
Training loss: 0.6423147916793823
Validation loss: 2.074612776438395

Epoch: 5| Step: 9
Training loss: 0.3774915039539337
Validation loss: 2.093795577685038

Epoch: 5| Step: 10
Training loss: 0.3573755621910095
Validation loss: 2.05780262251695

Epoch: 5| Step: 11
Training loss: 0.3957238793373108
Validation loss: 2.0817824651797614

Epoch: 345| Step: 0
Training loss: 0.3786703944206238
Validation loss: 2.034216195344925

Epoch: 5| Step: 1
Training loss: 0.276885449886322
Validation loss: 2.0623957365751266

Epoch: 5| Step: 2
Training loss: 0.6377027630805969
Validation loss: 2.044255703687668

Epoch: 5| Step: 3
Training loss: 0.4008804261684418
Validation loss: 2.0177203764518103

Epoch: 5| Step: 4
Training loss: 0.3839595317840576
Validation loss: 2.0856584956248603

Epoch: 5| Step: 5
Training loss: 0.9467355012893677
Validation loss: 2.0822217961152396

Epoch: 5| Step: 6
Training loss: 0.4177338480949402
Validation loss: 2.025197073817253

Epoch: 5| Step: 7
Training loss: 0.42019882798194885
Validation loss: 2.0325902700424194

Epoch: 5| Step: 8
Training loss: 0.40395116806030273
Validation loss: 2.0528002778689065

Epoch: 5| Step: 9
Training loss: 0.4065771996974945
Validation loss: 2.0415649861097336

Epoch: 5| Step: 10
Training loss: 0.46924275159835815
Validation loss: 2.0365053464969

Epoch: 5| Step: 11
Training loss: 0.27890557050704956
Validation loss: 2.0497283985217414

Epoch: 346| Step: 0
Training loss: 0.2510266900062561
Validation loss: 2.0618889331817627

Epoch: 5| Step: 1
Training loss: 0.45661622285842896
Validation loss: 2.0406033943096795

Epoch: 5| Step: 2
Training loss: 0.6335168480873108
Validation loss: 2.0540460546811423

Epoch: 5| Step: 3
Training loss: 0.31773483753204346
Validation loss: 2.066291183233261

Epoch: 5| Step: 4
Training loss: 0.5154411792755127
Validation loss: 2.0399582584698996

Epoch: 5| Step: 5
Training loss: 0.24761855602264404
Validation loss: 2.0945581942796707

Epoch: 5| Step: 6
Training loss: 0.39060407876968384
Validation loss: 2.077937642733256

Epoch: 5| Step: 7
Training loss: 0.4156075417995453
Validation loss: 2.062186280886332

Epoch: 5| Step: 8
Training loss: 0.5752756595611572
Validation loss: 2.044620598355929

Epoch: 5| Step: 9
Training loss: 0.8795669674873352
Validation loss: 2.0289226522048316

Epoch: 5| Step: 10
Training loss: 0.653751015663147
Validation loss: 2.0173180600007377

Epoch: 5| Step: 11
Training loss: 0.14470785856246948
Validation loss: 2.0413537373145423

Epoch: 347| Step: 0
Training loss: 0.3547661304473877
Validation loss: 2.04531958202521

Epoch: 5| Step: 1
Training loss: 0.46312230825424194
Validation loss: 2.0939085632562637

Epoch: 5| Step: 2
Training loss: 0.5070706605911255
Validation loss: 2.051842615008354

Epoch: 5| Step: 3
Training loss: 0.7205232381820679
Validation loss: 2.0774184117714563

Epoch: 5| Step: 4
Training loss: 0.5838868021965027
Validation loss: 2.0626597801844277

Epoch: 5| Step: 5
Training loss: 0.34216076135635376
Validation loss: 2.0206063787142434

Epoch: 5| Step: 6
Training loss: 0.48956093192100525
Validation loss: 2.054592271645864

Epoch: 5| Step: 7
Training loss: 0.44024139642715454
Validation loss: 2.063143069545428

Epoch: 5| Step: 8
Training loss: 0.6729723811149597
Validation loss: 2.037092993656794

Epoch: 5| Step: 9
Training loss: 0.4482704997062683
Validation loss: 2.0226730008920035

Epoch: 5| Step: 10
Training loss: 0.41015610098838806
Validation loss: 2.0269449402888617

Epoch: 5| Step: 11
Training loss: 0.28471362590789795
Validation loss: 2.0341759771108627

Epoch: 348| Step: 0
Training loss: 0.341416597366333
Validation loss: 2.02172859509786

Epoch: 5| Step: 1
Training loss: 0.6387202739715576
Validation loss: 2.103059634566307

Epoch: 5| Step: 2
Training loss: 0.9915717840194702
Validation loss: 2.059700762232145

Epoch: 5| Step: 3
Training loss: 0.2743890881538391
Validation loss: 2.053699776530266

Epoch: 5| Step: 4
Training loss: 0.3941114842891693
Validation loss: 2.0076686491568885

Epoch: 5| Step: 5
Training loss: 0.26078206300735474
Validation loss: 2.0287141501903534

Epoch: 5| Step: 6
Training loss: 0.7057603597640991
Validation loss: 2.042920579512914

Epoch: 5| Step: 7
Training loss: 0.35703977942466736
Validation loss: 2.076890299717585

Epoch: 5| Step: 8
Training loss: 0.44520148634910583
Validation loss: 2.042356957991918

Epoch: 5| Step: 9
Training loss: 0.6997841596603394
Validation loss: 2.0687110970417657

Epoch: 5| Step: 10
Training loss: 0.21928159892559052
Validation loss: 2.0661834677060447

Epoch: 5| Step: 11
Training loss: 0.6734904646873474
Validation loss: 2.0533543030420938

Epoch: 349| Step: 0
Training loss: 0.4868134558200836
Validation loss: 2.0186321387688317

Epoch: 5| Step: 1
Training loss: 0.7180014848709106
Validation loss: 2.0573852012554803

Epoch: 5| Step: 2
Training loss: 0.48300185799598694
Validation loss: 2.064383109410604

Epoch: 5| Step: 3
Training loss: 0.7359095215797424
Validation loss: 2.0361237674951553

Epoch: 5| Step: 4
Training loss: 0.27380555868148804
Validation loss: 2.0314617305994034

Epoch: 5| Step: 5
Training loss: 0.31123149394989014
Validation loss: 2.0435921400785446

Epoch: 5| Step: 6
Training loss: 0.7464856505393982
Validation loss: 2.094462037086487

Epoch: 5| Step: 7
Training loss: 0.445756733417511
Validation loss: 2.0677324632803598

Epoch: 5| Step: 8
Training loss: 0.6302632093429565
Validation loss: 2.0801179707050323

Epoch: 5| Step: 9
Training loss: 0.3444003164768219
Validation loss: 2.058633948365847

Epoch: 5| Step: 10
Training loss: 0.33879584074020386
Validation loss: 2.0604172746340432

Epoch: 5| Step: 11
Training loss: 0.24277502298355103
Validation loss: 2.04587559401989

Epoch: 350| Step: 0
Training loss: 0.38694271445274353
Validation loss: 2.0646798610687256

Epoch: 5| Step: 1
Training loss: 0.5143779516220093
Validation loss: 2.061571399370829

Epoch: 5| Step: 2
Training loss: 0.7724863886833191
Validation loss: 2.0747138063112893

Epoch: 5| Step: 3
Training loss: 0.4754067063331604
Validation loss: 2.0250957707564035

Epoch: 5| Step: 4
Training loss: 0.4412175714969635
Validation loss: 2.0507369488477707

Epoch: 5| Step: 5
Training loss: 0.5383070707321167
Validation loss: 2.0419924358526864

Epoch: 5| Step: 6
Training loss: 0.6943696737289429
Validation loss: 2.1041140208641687

Epoch: 5| Step: 7
Training loss: 0.21893008053302765
Validation loss: 2.0827887803316116

Epoch: 5| Step: 8
Training loss: 0.5134594440460205
Validation loss: 2.053769106666247

Epoch: 5| Step: 9
Training loss: 0.3076273500919342
Validation loss: 2.0778045058250427

Epoch: 5| Step: 10
Training loss: 0.44623929262161255
Validation loss: 2.067149763305982

Epoch: 5| Step: 11
Training loss: 0.09787338972091675
Validation loss: 2.03566346069177

Epoch: 351| Step: 0
Training loss: 0.3765662908554077
Validation loss: 2.058911472558975

Epoch: 5| Step: 1
Training loss: 0.29422807693481445
Validation loss: 2.0880469977855682

Epoch: 5| Step: 2
Training loss: 0.6621612310409546
Validation loss: 2.0395211031039557

Epoch: 5| Step: 3
Training loss: 0.677198052406311
Validation loss: 2.058609997232755

Epoch: 5| Step: 4
Training loss: 0.32038742303848267
Validation loss: 2.077935049931208

Epoch: 5| Step: 5
Training loss: 0.3742246627807617
Validation loss: 2.0875360866387687

Epoch: 5| Step: 6
Training loss: 0.2260906994342804
Validation loss: 2.0434302190939584

Epoch: 5| Step: 7
Training loss: 1.0530411005020142
Validation loss: 2.0691029528776803

Epoch: 5| Step: 8
Training loss: 0.3148905336856842
Validation loss: 2.044944316148758

Epoch: 5| Step: 9
Training loss: 0.6115536093711853
Validation loss: 2.075253054499626

Epoch: 5| Step: 10
Training loss: 0.22487418353557587
Validation loss: 2.0597661485274634

Epoch: 5| Step: 11
Training loss: 0.12684381008148193
Validation loss: 2.056577538450559

Epoch: 352| Step: 0
Training loss: 0.37942925095558167
Validation loss: 2.06160976489385

Epoch: 5| Step: 1
Training loss: 0.7708582282066345
Validation loss: 2.0883990426858268

Epoch: 5| Step: 2
Training loss: 0.5674833655357361
Validation loss: 2.074924493829409

Epoch: 5| Step: 3
Training loss: 0.39667245745658875
Validation loss: 2.085230678319931

Epoch: 5| Step: 4
Training loss: 0.4363325238227844
Validation loss: 2.08062573770682

Epoch: 5| Step: 5
Training loss: 0.5940855741500854
Validation loss: 2.104588508605957

Epoch: 5| Step: 6
Training loss: 0.46247178316116333
Validation loss: 2.1069549322128296

Epoch: 5| Step: 7
Training loss: 0.3243297338485718
Validation loss: 2.1016215036312738

Epoch: 5| Step: 8
Training loss: 0.44778984785079956
Validation loss: 2.0795831233263016

Epoch: 5| Step: 9
Training loss: 0.41206836700439453
Validation loss: 2.1070356170336404

Epoch: 5| Step: 10
Training loss: 0.6142191290855408
Validation loss: 2.1040814767281213

Epoch: 5| Step: 11
Training loss: 0.26681655645370483
Validation loss: 2.084688047568003

Epoch: 353| Step: 0
Training loss: 0.5237158536911011
Validation loss: 2.094345142443975

Epoch: 5| Step: 1
Training loss: 0.5848686695098877
Validation loss: 2.0824082096417746

Epoch: 5| Step: 2
Training loss: 0.736129641532898
Validation loss: 2.095379243294398

Epoch: 5| Step: 3
Training loss: 0.3586166501045227
Validation loss: 2.0554198771715164

Epoch: 5| Step: 4
Training loss: 0.35566574335098267
Validation loss: 2.0707941253980002

Epoch: 5| Step: 5
Training loss: 0.5161957740783691
Validation loss: 2.031191274523735

Epoch: 5| Step: 6
Training loss: 0.649117112159729
Validation loss: 2.073508381843567

Epoch: 5| Step: 7
Training loss: 0.6144523620605469
Validation loss: 2.0323466360569

Epoch: 5| Step: 8
Training loss: 0.30911925435066223
Validation loss: 2.0630034506320953

Epoch: 5| Step: 9
Training loss: 0.27317216992378235
Validation loss: 2.0553804337978363

Epoch: 5| Step: 10
Training loss: 0.44997620582580566
Validation loss: 2.0495040118694305

Epoch: 5| Step: 11
Training loss: 0.2824435234069824
Validation loss: 2.086855247616768

Epoch: 354| Step: 0
Training loss: 0.41453027725219727
Validation loss: 2.0194407552480698

Epoch: 5| Step: 1
Training loss: 0.5118840932846069
Validation loss: 2.0768456558386483

Epoch: 5| Step: 2
Training loss: 0.3887883126735687
Validation loss: 2.0451692740122476

Epoch: 5| Step: 3
Training loss: 0.3959764838218689
Validation loss: 1.9899320205052693

Epoch: 5| Step: 4
Training loss: 0.26163753867149353
Validation loss: 2.0534529834985733

Epoch: 5| Step: 5
Training loss: 0.5253068804740906
Validation loss: 2.0650151123603186

Epoch: 5| Step: 6
Training loss: 0.4911796450614929
Validation loss: 1.996873398621877

Epoch: 5| Step: 7
Training loss: 0.3255683481693268
Validation loss: 2.08444906771183

Epoch: 5| Step: 8
Training loss: 0.5826632380485535
Validation loss: 2.0805173814296722

Epoch: 5| Step: 9
Training loss: 0.6870599985122681
Validation loss: 2.0302501171827316

Epoch: 5| Step: 10
Training loss: 0.7576445937156677
Validation loss: 2.046616772810618

Epoch: 5| Step: 11
Training loss: 0.5365177392959595
Validation loss: 2.0362735937039056

Epoch: 355| Step: 0
Training loss: 0.30688396096229553
Validation loss: 2.0615456899007163

Epoch: 5| Step: 1
Training loss: 0.42113789916038513
Validation loss: 2.0393621623516083

Epoch: 5| Step: 2
Training loss: 0.342507541179657
Validation loss: 2.0571500758330026

Epoch: 5| Step: 3
Training loss: 0.32064706087112427
Validation loss: 2.074978689352671

Epoch: 5| Step: 4
Training loss: 0.3564091622829437
Validation loss: 2.072989761829376

Epoch: 5| Step: 5
Training loss: 0.9060455560684204
Validation loss: 2.027836501598358

Epoch: 5| Step: 6
Training loss: 0.3979545533657074
Validation loss: 2.015938629706701

Epoch: 5| Step: 7
Training loss: 0.6791738867759705
Validation loss: 2.081581771373749

Epoch: 5| Step: 8
Training loss: 0.3948735296726227
Validation loss: 2.020974343021711

Epoch: 5| Step: 9
Training loss: 0.44839030504226685
Validation loss: 2.0312875360250473

Epoch: 5| Step: 10
Training loss: 0.5794440507888794
Validation loss: 2.0790683229764304

Epoch: 5| Step: 11
Training loss: 0.09420430660247803
Validation loss: 2.0621714840332666

Epoch: 356| Step: 0
Training loss: 0.33150702714920044
Validation loss: 2.0216947545607886

Epoch: 5| Step: 1
Training loss: 0.6273720264434814
Validation loss: 2.0083271662394204

Epoch: 5| Step: 2
Training loss: 0.5188923478126526
Validation loss: 2.0624048113822937

Epoch: 5| Step: 3
Training loss: 0.46926364302635193
Validation loss: 2.064872379104296

Epoch: 5| Step: 4
Training loss: 0.298012912273407
Validation loss: 2.0426852057377496

Epoch: 5| Step: 5
Training loss: 0.2315462827682495
Validation loss: 2.104421059290568

Epoch: 5| Step: 6
Training loss: 0.5640016794204712
Validation loss: 2.0674344450235367

Epoch: 5| Step: 7
Training loss: 0.4021073281764984
Validation loss: 2.08587953945001

Epoch: 5| Step: 8
Training loss: 0.5765848755836487
Validation loss: 2.065255989631017

Epoch: 5| Step: 9
Training loss: 0.6600981950759888
Validation loss: 2.0977025628089905

Epoch: 5| Step: 10
Training loss: 0.2346072942018509
Validation loss: 2.0719575186570487

Epoch: 5| Step: 11
Training loss: 0.8729521632194519
Validation loss: 2.0884136160214744

Epoch: 357| Step: 0
Training loss: 0.2144535779953003
Validation loss: 2.105804597338041

Epoch: 5| Step: 1
Training loss: 0.2231365144252777
Validation loss: 2.1048954725265503

Epoch: 5| Step: 2
Training loss: 0.8964940309524536
Validation loss: 2.135578547914823

Epoch: 5| Step: 3
Training loss: 0.5114690065383911
Validation loss: 2.071360722184181

Epoch: 5| Step: 4
Training loss: 0.6536267995834351
Validation loss: 2.071257477005323

Epoch: 5| Step: 5
Training loss: 0.4413956105709076
Validation loss: 2.0736034065485

Epoch: 5| Step: 6
Training loss: 0.44082289934158325
Validation loss: 2.102094625433286

Epoch: 5| Step: 7
Training loss: 0.6959550976753235
Validation loss: 2.106387048959732

Epoch: 5| Step: 8
Training loss: 0.4598458707332611
Validation loss: 2.059236019849777

Epoch: 5| Step: 9
Training loss: 0.4432738721370697
Validation loss: 2.1080463329950967

Epoch: 5| Step: 10
Training loss: 0.28850454092025757
Validation loss: 2.104736497004827

Epoch: 5| Step: 11
Training loss: 0.6981563568115234
Validation loss: 2.1215167244275412

Epoch: 358| Step: 0
Training loss: 0.352092444896698
Validation loss: 2.1427001555760703

Epoch: 5| Step: 1
Training loss: 0.7864953279495239
Validation loss: 2.065661519765854

Epoch: 5| Step: 2
Training loss: 0.5903916358947754
Validation loss: 2.046277016401291

Epoch: 5| Step: 3
Training loss: 0.4554674029350281
Validation loss: 2.0972872426112494

Epoch: 5| Step: 4
Training loss: 0.19685009121894836
Validation loss: 2.034895102183024

Epoch: 5| Step: 5
Training loss: 0.3671516478061676
Validation loss: 2.1171538879474006

Epoch: 5| Step: 6
Training loss: 0.7877359390258789
Validation loss: 2.080683539311091

Epoch: 5| Step: 7
Training loss: 0.46408146619796753
Validation loss: 2.0458639661471048

Epoch: 5| Step: 8
Training loss: 0.37336185574531555
Validation loss: 2.081535870830218

Epoch: 5| Step: 9
Training loss: 0.3445318341255188
Validation loss: 2.0629319548606873

Epoch: 5| Step: 10
Training loss: 0.3487766981124878
Validation loss: 2.055963228146235

Epoch: 5| Step: 11
Training loss: 0.4155818223953247
Validation loss: 2.0454894254604974

Epoch: 359| Step: 0
Training loss: 0.5523548722267151
Validation loss: 2.103478545943896

Epoch: 5| Step: 1
Training loss: 0.2677253782749176
Validation loss: 2.002129649122556

Epoch: 5| Step: 2
Training loss: 0.6727348566055298
Validation loss: 2.0964723030726113

Epoch: 5| Step: 3
Training loss: 0.6475115418434143
Validation loss: 2.054813399910927

Epoch: 5| Step: 4
Training loss: 0.4817434251308441
Validation loss: 2.0343026916186013

Epoch: 5| Step: 5
Training loss: 0.515937089920044
Validation loss: 2.0797652204831443

Epoch: 5| Step: 6
Training loss: 0.5366854071617126
Validation loss: 2.039082561930021

Epoch: 5| Step: 7
Training loss: 0.3062354028224945
Validation loss: 2.0916453152894974

Epoch: 5| Step: 8
Training loss: 0.4645768105983734
Validation loss: 2.0584305624167123

Epoch: 5| Step: 9
Training loss: 0.4978838860988617
Validation loss: 2.0578707406918206

Epoch: 5| Step: 10
Training loss: 0.5410174131393433
Validation loss: 2.045404667655627

Epoch: 5| Step: 11
Training loss: 0.13679206371307373
Validation loss: 2.06741955379645

Epoch: 360| Step: 0
Training loss: 0.570184588432312
Validation loss: 2.025181849797567

Epoch: 5| Step: 1
Training loss: 0.5999582409858704
Validation loss: 2.0581447780132294

Epoch: 5| Step: 2
Training loss: 0.6904075741767883
Validation loss: 2.0568016866842904

Epoch: 5| Step: 3
Training loss: 0.27202311158180237
Validation loss: 2.075454736749331

Epoch: 5| Step: 4
Training loss: 0.6147178411483765
Validation loss: 2.107767512400945

Epoch: 5| Step: 5
Training loss: 0.2880208194255829
Validation loss: 2.046053489049276

Epoch: 5| Step: 6
Training loss: 0.5097383260726929
Validation loss: 2.0967010160287223

Epoch: 5| Step: 7
Training loss: 0.17866191267967224
Validation loss: 2.0570648511250815

Epoch: 5| Step: 8
Training loss: 0.21934056282043457
Validation loss: 2.0316848953564963

Epoch: 5| Step: 9
Training loss: 0.29750490188598633
Validation loss: 2.0613792538642883

Epoch: 5| Step: 10
Training loss: 0.8473259806632996
Validation loss: 2.030244901776314

Epoch: 5| Step: 11
Training loss: 0.8391135931015015
Validation loss: 2.05229414999485

Epoch: 361| Step: 0
Training loss: 0.368779718875885
Validation loss: 2.0461271603902182

Epoch: 5| Step: 1
Training loss: 0.6520458459854126
Validation loss: 2.0962115426858268

Epoch: 5| Step: 2
Training loss: 0.3540993630886078
Validation loss: 2.038591211040815

Epoch: 5| Step: 3
Training loss: 0.8285404443740845
Validation loss: 2.0331259071826935

Epoch: 5| Step: 4
Training loss: 0.3192934989929199
Validation loss: 2.059172362089157

Epoch: 5| Step: 5
Training loss: 0.14500540494918823
Validation loss: 2.0648712565501532

Epoch: 5| Step: 6
Training loss: 0.632541298866272
Validation loss: 2.0558254023392997

Epoch: 5| Step: 7
Training loss: 0.6143824458122253
Validation loss: 2.0472709635893502

Epoch: 5| Step: 8
Training loss: 0.5069836378097534
Validation loss: 2.0457757810751596

Epoch: 5| Step: 9
Training loss: 0.2794159948825836
Validation loss: 2.0598576168219247

Epoch: 5| Step: 10
Training loss: 0.270244300365448
Validation loss: 2.050710697968801

Epoch: 5| Step: 11
Training loss: 1.0735656023025513
Validation loss: 2.0636122624079385

Epoch: 362| Step: 0
Training loss: 0.6022772789001465
Validation loss: 2.042430579662323

Epoch: 5| Step: 1
Training loss: 0.5780467391014099
Validation loss: 2.065427919228872

Epoch: 5| Step: 2
Training loss: 0.2806186079978943
Validation loss: 2.053618997335434

Epoch: 5| Step: 3
Training loss: 0.5421726703643799
Validation loss: 2.0787310898303986

Epoch: 5| Step: 4
Training loss: 0.7167950868606567
Validation loss: 2.075636367003123

Epoch: 5| Step: 5
Training loss: 0.303688108921051
Validation loss: 2.0638272811969123

Epoch: 5| Step: 6
Training loss: 0.5825656652450562
Validation loss: 2.0705297191937766

Epoch: 5| Step: 7
Training loss: 0.3472641110420227
Validation loss: 2.1180330713589988

Epoch: 5| Step: 8
Training loss: 0.48024410009384155
Validation loss: 2.053318460782369

Epoch: 5| Step: 9
Training loss: 0.39823222160339355
Validation loss: 2.085635393857956

Epoch: 5| Step: 10
Training loss: 0.45180973410606384
Validation loss: 2.077494819959005

Epoch: 5| Step: 11
Training loss: 0.20972394943237305
Validation loss: 2.1019272208213806

Epoch: 363| Step: 0
Training loss: 0.22808003425598145
Validation loss: 2.09422438343366

Epoch: 5| Step: 1
Training loss: 0.38581377267837524
Validation loss: 2.068186417222023

Epoch: 5| Step: 2
Training loss: 0.4262353479862213
Validation loss: 2.1382175187269845

Epoch: 5| Step: 3
Training loss: 0.5904898643493652
Validation loss: 2.109890639781952

Epoch: 5| Step: 4
Training loss: 0.4758242964744568
Validation loss: 2.057250216603279

Epoch: 5| Step: 5
Training loss: 1.125343680381775
Validation loss: 2.115022659301758

Epoch: 5| Step: 6
Training loss: 0.467501163482666
Validation loss: 2.0953954805930457

Epoch: 5| Step: 7
Training loss: 0.48510241508483887
Validation loss: 2.0786637663841248

Epoch: 5| Step: 8
Training loss: 0.5664902329444885
Validation loss: 2.08690253396829

Epoch: 5| Step: 9
Training loss: 0.6818742752075195
Validation loss: 2.114182343085607

Epoch: 5| Step: 10
Training loss: 0.32834261655807495
Validation loss: 2.0858801205952964

Epoch: 5| Step: 11
Training loss: 0.19993984699249268
Validation loss: 2.052779575188955

Epoch: 364| Step: 0
Training loss: 0.7029937505722046
Validation loss: 2.05339706937472

Epoch: 5| Step: 1
Training loss: 0.5655087232589722
Validation loss: 2.0874318033456802

Epoch: 5| Step: 2
Training loss: 0.5162270069122314
Validation loss: 2.0411714911460876

Epoch: 5| Step: 3
Training loss: 0.221154123544693
Validation loss: 2.056327313184738

Epoch: 5| Step: 4
Training loss: 0.3937860131263733
Validation loss: 2.0828961034615836

Epoch: 5| Step: 5
Training loss: 0.48640090227127075
Validation loss: 2.061091959476471

Epoch: 5| Step: 6
Training loss: 0.5439054369926453
Validation loss: 2.0383368780215583

Epoch: 5| Step: 7
Training loss: 0.352897971868515
Validation loss: 2.019122928380966

Epoch: 5| Step: 8
Training loss: 0.5646536946296692
Validation loss: 2.048128833373388

Epoch: 5| Step: 9
Training loss: 0.4597952365875244
Validation loss: 2.032443180680275

Epoch: 5| Step: 10
Training loss: 0.46945929527282715
Validation loss: 2.0293620079755783

Epoch: 5| Step: 11
Training loss: 0.16986502707004547
Validation loss: 2.0425916264454522

Epoch: 365| Step: 0
Training loss: 0.4150472581386566
Validation loss: 2.026397551099459

Epoch: 5| Step: 1
Training loss: 0.23106244206428528
Validation loss: 2.030034547050794

Epoch: 5| Step: 2
Training loss: 0.4382961392402649
Validation loss: 2.039232447743416

Epoch: 5| Step: 3
Training loss: 0.4113757610321045
Validation loss: 2.047535960872968

Epoch: 5| Step: 4
Training loss: 0.6117514371871948
Validation loss: 2.0832631339629493

Epoch: 5| Step: 5
Training loss: 0.6868285536766052
Validation loss: 2.0330732266108194

Epoch: 5| Step: 6
Training loss: 0.3872792422771454
Validation loss: 2.0592979987462363

Epoch: 5| Step: 7
Training loss: 0.5935026407241821
Validation loss: 2.0554994692405066

Epoch: 5| Step: 8
Training loss: 0.3966887593269348
Validation loss: 2.058565855026245

Epoch: 5| Step: 9
Training loss: 0.3926827013492584
Validation loss: 2.0399306267499924

Epoch: 5| Step: 10
Training loss: 0.7044758796691895
Validation loss: 2.0770263423522315

Epoch: 5| Step: 11
Training loss: 1.1054432392120361
Validation loss: 2.0826971580584845

Epoch: 366| Step: 0
Training loss: 0.6034645438194275
Validation loss: 2.0777231554190316

Epoch: 5| Step: 1
Training loss: 0.4956435263156891
Validation loss: 2.040273442864418

Epoch: 5| Step: 2
Training loss: 0.3018922209739685
Validation loss: 2.0367221434911094

Epoch: 5| Step: 3
Training loss: 0.32803815603256226
Validation loss: 2.0377035985390344

Epoch: 5| Step: 4
Training loss: 0.2150118052959442
Validation loss: 2.0345406184593835

Epoch: 5| Step: 5
Training loss: 0.3361721634864807
Validation loss: 2.0909838577111564

Epoch: 5| Step: 6
Training loss: 0.3819940686225891
Validation loss: 2.0490213483572006

Epoch: 5| Step: 7
Training loss: 0.9462846517562866
Validation loss: 2.0244821459054947

Epoch: 5| Step: 8
Training loss: 0.4252592921257019
Validation loss: 2.032919153571129

Epoch: 5| Step: 9
Training loss: 0.447415828704834
Validation loss: 2.034233644604683

Epoch: 5| Step: 10
Training loss: 0.4862891137599945
Validation loss: 2.057942514618238

Epoch: 5| Step: 11
Training loss: 0.601661205291748
Validation loss: 2.062742590904236

Epoch: 367| Step: 0
Training loss: 0.3467404246330261
Validation loss: 2.020026375850042

Epoch: 5| Step: 1
Training loss: 0.8552660942077637
Validation loss: 2.0690740644931793

Epoch: 5| Step: 2
Training loss: 0.3742876648902893
Validation loss: 2.0543790459632874

Epoch: 5| Step: 3
Training loss: 0.662848949432373
Validation loss: 2.0583882679541907

Epoch: 5| Step: 4
Training loss: 0.4820035994052887
Validation loss: 2.033510759472847

Epoch: 5| Step: 5
Training loss: 0.32008838653564453
Validation loss: 2.0635291387637458

Epoch: 5| Step: 6
Training loss: 0.7004052400588989
Validation loss: 2.071709558367729

Epoch: 5| Step: 7
Training loss: 0.25749433040618896
Validation loss: 2.065130283435186

Epoch: 5| Step: 8
Training loss: 0.4458073079586029
Validation loss: 2.0377159863710403

Epoch: 5| Step: 9
Training loss: 0.21736149489879608
Validation loss: 2.094300086299578

Epoch: 5| Step: 10
Training loss: 0.30141815543174744
Validation loss: 2.0865543286005654

Epoch: 5| Step: 11
Training loss: 0.2994176149368286
Validation loss: 2.0494198948144913

Epoch: 368| Step: 0
Training loss: 0.4036080241203308
Validation loss: 2.0747536371151605

Epoch: 5| Step: 1
Training loss: 0.4887605607509613
Validation loss: 2.100034678975741

Epoch: 5| Step: 2
Training loss: 0.5724617838859558
Validation loss: 2.060034230351448

Epoch: 5| Step: 3
Training loss: 0.8872522115707397
Validation loss: 2.0956283460060754

Epoch: 5| Step: 4
Training loss: 0.521750807762146
Validation loss: 2.1000101566314697

Epoch: 5| Step: 5
Training loss: 0.30880463123321533
Validation loss: 2.1132584512233734

Epoch: 5| Step: 6
Training loss: 0.4709433913230896
Validation loss: 2.0648193806409836

Epoch: 5| Step: 7
Training loss: 0.4446219801902771
Validation loss: 2.07595727344354

Epoch: 5| Step: 8
Training loss: 0.22782909870147705
Validation loss: 2.094694788257281

Epoch: 5| Step: 9
Training loss: 0.30351439118385315
Validation loss: 2.060366148749987

Epoch: 5| Step: 10
Training loss: 0.31690746545791626
Validation loss: 2.094570532441139

Epoch: 5| Step: 11
Training loss: 0.5884436368942261
Validation loss: 2.0691336592038474

Epoch: 369| Step: 0
Training loss: 0.688158392906189
Validation loss: 2.0781826923290887

Epoch: 5| Step: 1
Training loss: 0.28119856119155884
Validation loss: 2.089698572953542

Epoch: 5| Step: 2
Training loss: 0.4318315088748932
Validation loss: 2.066976765791575

Epoch: 5| Step: 3
Training loss: 0.3794053792953491
Validation loss: 2.0647228558858237

Epoch: 5| Step: 4
Training loss: 0.3640257716178894
Validation loss: 2.0805734445651374

Epoch: 5| Step: 5
Training loss: 0.5150854587554932
Validation loss: 2.058773179848989

Epoch: 5| Step: 6
Training loss: 0.4613296091556549
Validation loss: 2.0755784064531326

Epoch: 5| Step: 7
Training loss: 0.307583212852478
Validation loss: 2.007876063386599

Epoch: 5| Step: 8
Training loss: 0.37445706129074097
Validation loss: 2.0893515745798745

Epoch: 5| Step: 9
Training loss: 0.8746196031570435
Validation loss: 2.043539131681124

Epoch: 5| Step: 10
Training loss: 0.5507295727729797
Validation loss: 2.066362574696541

Epoch: 5| Step: 11
Training loss: 0.14192986488342285
Validation loss: 2.046791677673658

Epoch: 370| Step: 0
Training loss: 0.20550790429115295
Validation loss: 2.0535787642002106

Epoch: 5| Step: 1
Training loss: 0.636621356010437
Validation loss: 2.023401364684105

Epoch: 5| Step: 2
Training loss: 0.4957706034183502
Validation loss: 2.0371589163939157

Epoch: 5| Step: 3
Training loss: 0.28909915685653687
Validation loss: 2.1136312087376914

Epoch: 5| Step: 4
Training loss: 0.5424616932868958
Validation loss: 2.060907766222954

Epoch: 5| Step: 5
Training loss: 0.33732447028160095
Validation loss: 2.0740584631760917

Epoch: 5| Step: 6
Training loss: 0.26890498399734497
Validation loss: 2.055004487435023

Epoch: 5| Step: 7
Training loss: 0.7630961537361145
Validation loss: 2.0776531596978507

Epoch: 5| Step: 8
Training loss: 0.19611462950706482
Validation loss: 2.0273819118738174

Epoch: 5| Step: 9
Training loss: 0.7548576593399048
Validation loss: 2.035613829890887

Epoch: 5| Step: 10
Training loss: 0.5322785973548889
Validation loss: 2.0729911079009375

Epoch: 5| Step: 11
Training loss: 0.698387622833252
Validation loss: 2.077498823404312

Epoch: 371| Step: 0
Training loss: 0.5429096221923828
Validation loss: 2.0862821688254676

Epoch: 5| Step: 1
Training loss: 0.18955230712890625
Validation loss: 2.068455229202906

Epoch: 5| Step: 2
Training loss: 0.268135130405426
Validation loss: 2.0346073508262634

Epoch: 5| Step: 3
Training loss: 0.3584490418434143
Validation loss: 2.027202695608139

Epoch: 5| Step: 4
Training loss: 0.38488006591796875
Validation loss: 2.0391428222258887

Epoch: 5| Step: 5
Training loss: 0.265086829662323
Validation loss: 2.0407164096832275

Epoch: 5| Step: 6
Training loss: 0.4569331109523773
Validation loss: 2.046777601043383

Epoch: 5| Step: 7
Training loss: 0.8845918774604797
Validation loss: 2.0358586609363556

Epoch: 5| Step: 8
Training loss: 0.43384474515914917
Validation loss: 2.0701648592948914

Epoch: 5| Step: 9
Training loss: 0.5408922433853149
Validation loss: 2.0688336541255317

Epoch: 5| Step: 10
Training loss: 0.4297204911708832
Validation loss: 2.000277509291967

Epoch: 5| Step: 11
Training loss: 0.2126917839050293
Validation loss: 2.0556380301713943

Epoch: 372| Step: 0
Training loss: 0.5842491984367371
Validation loss: 2.0176579455534616

Epoch: 5| Step: 1
Training loss: 0.25600379705429077
Validation loss: 2.060618758201599

Epoch: 5| Step: 2
Training loss: 0.3895249664783478
Validation loss: 2.035115440686544

Epoch: 5| Step: 3
Training loss: 0.34099650382995605
Validation loss: 2.0345623840888343

Epoch: 5| Step: 4
Training loss: 0.2204752266407013
Validation loss: 2.043679560224215

Epoch: 5| Step: 5
Training loss: 0.46881455183029175
Validation loss: 2.0341701358556747

Epoch: 5| Step: 6
Training loss: 0.6913248300552368
Validation loss: 2.0751874446868896

Epoch: 5| Step: 7
Training loss: 0.472583532333374
Validation loss: 2.0722397565841675

Epoch: 5| Step: 8
Training loss: 0.3777264654636383
Validation loss: 2.0604105244080224

Epoch: 5| Step: 9
Training loss: 0.6827062368392944
Validation loss: 2.0705831249554953

Epoch: 5| Step: 10
Training loss: 0.34393763542175293
Validation loss: 2.096830358107885

Epoch: 5| Step: 11
Training loss: 1.126617431640625
Validation loss: 2.107793008287748

Epoch: 373| Step: 0
Training loss: 0.5814274549484253
Validation loss: 2.059094473719597

Epoch: 5| Step: 1
Training loss: 0.6496241688728333
Validation loss: 2.084141423304876

Epoch: 5| Step: 2
Training loss: 0.3191499412059784
Validation loss: 2.068906605243683

Epoch: 5| Step: 3
Training loss: 0.3895460367202759
Validation loss: 2.065823867917061

Epoch: 5| Step: 4
Training loss: 0.6133230328559875
Validation loss: 2.0746275236209235

Epoch: 5| Step: 5
Training loss: 0.32746315002441406
Validation loss: 2.0517854392528534

Epoch: 5| Step: 6
Training loss: 0.3573872447013855
Validation loss: 2.063868761062622

Epoch: 5| Step: 7
Training loss: 0.4206278920173645
Validation loss: 2.060923228661219

Epoch: 5| Step: 8
Training loss: 0.36145681142807007
Validation loss: 2.069228162368139

Epoch: 5| Step: 9
Training loss: 0.6784495711326599
Validation loss: 2.083252936601639

Epoch: 5| Step: 10
Training loss: 0.4669279456138611
Validation loss: 2.030351127187411

Epoch: 5| Step: 11
Training loss: 0.19627171754837036
Validation loss: 2.059974655508995

Epoch: 374| Step: 0
Training loss: 0.4978918135166168
Validation loss: 2.0708708465099335

Epoch: 5| Step: 1
Training loss: 0.9117652773857117
Validation loss: 2.064736838142077

Epoch: 5| Step: 2
Training loss: 0.4374309480190277
Validation loss: 2.1032760043938956

Epoch: 5| Step: 3
Training loss: 0.5218633413314819
Validation loss: 2.0707120448350906

Epoch: 5| Step: 4
Training loss: 0.2648509442806244
Validation loss: 2.1037292381127677

Epoch: 5| Step: 5
Training loss: 0.30217182636260986
Validation loss: 2.049507647752762

Epoch: 5| Step: 6
Training loss: 0.17102624475955963
Validation loss: 2.044614553451538

Epoch: 5| Step: 7
Training loss: 0.452291876077652
Validation loss: 2.0687276224295297

Epoch: 5| Step: 8
Training loss: 0.4765142798423767
Validation loss: 2.037795623143514

Epoch: 5| Step: 9
Training loss: 0.5443875193595886
Validation loss: 2.110353708267212

Epoch: 5| Step: 10
Training loss: 0.40491485595703125
Validation loss: 2.030829648176829

Epoch: 5| Step: 11
Training loss: 0.48151180148124695
Validation loss: 2.069081127643585

Epoch: 375| Step: 0
Training loss: 0.21998831629753113
Validation loss: 2.0427663326263428

Epoch: 5| Step: 1
Training loss: 0.3436756730079651
Validation loss: 2.015533591310183

Epoch: 5| Step: 2
Training loss: 0.5185956954956055
Validation loss: 2.09415365755558

Epoch: 5| Step: 3
Training loss: 0.27287358045578003
Validation loss: 2.0244452009598413

Epoch: 5| Step: 4
Training loss: 0.5683383941650391
Validation loss: 2.0356853753328323

Epoch: 5| Step: 5
Training loss: 0.37982505559921265
Validation loss: 2.040969933072726

Epoch: 5| Step: 6
Training loss: 0.5461139678955078
Validation loss: 2.0579885641733804

Epoch: 5| Step: 7
Training loss: 0.5578898191452026
Validation loss: 2.055496871471405

Epoch: 5| Step: 8
Training loss: 0.8097766637802124
Validation loss: 2.061728318532308

Epoch: 5| Step: 9
Training loss: 0.3717416524887085
Validation loss: 2.0524135877688727

Epoch: 5| Step: 10
Training loss: 0.5627202987670898
Validation loss: 2.043783982594808

Epoch: 5| Step: 11
Training loss: 0.31824201345443726
Validation loss: 2.076934665441513

Epoch: 376| Step: 0
Training loss: 0.43253523111343384
Validation loss: 2.070133700966835

Epoch: 5| Step: 1
Training loss: 0.27214449644088745
Validation loss: 2.0446469634771347

Epoch: 5| Step: 2
Training loss: 0.515419602394104
Validation loss: 2.058637872338295

Epoch: 5| Step: 3
Training loss: 0.4607720971107483
Validation loss: 2.0302786181370416

Epoch: 5| Step: 4
Training loss: 0.21404913067817688
Validation loss: 2.0630721747875214

Epoch: 5| Step: 5
Training loss: 0.3451974093914032
Validation loss: 2.0690223773320517

Epoch: 5| Step: 6
Training loss: 0.28089308738708496
Validation loss: 2.0429915140072503

Epoch: 5| Step: 7
Training loss: 0.44343701004981995
Validation loss: 2.032650873064995

Epoch: 5| Step: 8
Training loss: 0.36734020709991455
Validation loss: 2.044276108344396

Epoch: 5| Step: 9
Training loss: 0.5088257193565369
Validation loss: 2.070053905248642

Epoch: 5| Step: 10
Training loss: 0.6143093705177307
Validation loss: 2.0621811052163443

Epoch: 5| Step: 11
Training loss: 2.3295750617980957
Validation loss: 2.0786558190981546

Epoch: 377| Step: 0
Training loss: 0.2602703869342804
Validation loss: 2.0798771729071936

Epoch: 5| Step: 1
Training loss: 0.4031953811645508
Validation loss: 2.051551267504692

Epoch: 5| Step: 2
Training loss: 0.16838207840919495
Validation loss: 2.0671589424212775

Epoch: 5| Step: 3
Training loss: 0.4525832235813141
Validation loss: 2.049534499645233

Epoch: 5| Step: 4
Training loss: 0.5353556871414185
Validation loss: 2.034380868077278

Epoch: 5| Step: 5
Training loss: 0.4891747832298279
Validation loss: 2.064457560578982

Epoch: 5| Step: 6
Training loss: 0.3357661962509155
Validation loss: 2.1103977262973785

Epoch: 5| Step: 7
Training loss: 0.9722388386726379
Validation loss: 2.0933096607526145

Epoch: 5| Step: 8
Training loss: 0.45739442110061646
Validation loss: 2.1280711591243744

Epoch: 5| Step: 9
Training loss: 0.4166494905948639
Validation loss: 2.081613997618357

Epoch: 5| Step: 10
Training loss: 0.29441434144973755
Validation loss: 2.048635890086492

Epoch: 5| Step: 11
Training loss: 0.20633184909820557
Validation loss: 2.0976751943429313

Epoch: 378| Step: 0
Training loss: 0.18827317655086517
Validation loss: 2.072707697749138

Epoch: 5| Step: 1
Training loss: 0.23608358204364777
Validation loss: 2.0417158553997674

Epoch: 5| Step: 2
Training loss: 1.0228780508041382
Validation loss: 2.044975688060125

Epoch: 5| Step: 3
Training loss: 0.3751181662082672
Validation loss: 2.0564474165439606

Epoch: 5| Step: 4
Training loss: 0.5216590166091919
Validation loss: 2.032715827226639

Epoch: 5| Step: 5
Training loss: 0.6060721278190613
Validation loss: 2.072400947411855

Epoch: 5| Step: 6
Training loss: 0.3934749960899353
Validation loss: 2.0671117901802063

Epoch: 5| Step: 7
Training loss: 0.37489429116249084
Validation loss: 2.090226555864016

Epoch: 5| Step: 8
Training loss: 0.4204789996147156
Validation loss: 2.0930031339327493

Epoch: 5| Step: 9
Training loss: 0.4419448971748352
Validation loss: 2.0291461696227393

Epoch: 5| Step: 10
Training loss: 0.34234148263931274
Validation loss: 2.067669466137886

Epoch: 5| Step: 11
Training loss: 0.6864089965820312
Validation loss: 2.0611560146013894

Epoch: 379| Step: 0
Training loss: 0.4335328936576843
Validation loss: 2.0286408414443335

Epoch: 5| Step: 1
Training loss: 0.6751939058303833
Validation loss: 2.039981946349144

Epoch: 5| Step: 2
Training loss: 0.3661375939846039
Validation loss: 2.04018305738767

Epoch: 5| Step: 3
Training loss: 0.4068738520145416
Validation loss: 2.040925621986389

Epoch: 5| Step: 4
Training loss: 0.35277533531188965
Validation loss: 2.1061319361130395

Epoch: 5| Step: 5
Training loss: 0.6089705228805542
Validation loss: 2.0763289680083594

Epoch: 5| Step: 6
Training loss: 0.32563382387161255
Validation loss: 2.087664544582367

Epoch: 5| Step: 7
Training loss: 0.4264693260192871
Validation loss: 2.0716006755828857

Epoch: 5| Step: 8
Training loss: 0.6083781123161316
Validation loss: 2.0559353629748025

Epoch: 5| Step: 9
Training loss: 0.7152851819992065
Validation loss: 2.0912037938833237

Epoch: 5| Step: 10
Training loss: 0.26518869400024414
Validation loss: 2.0642762581507363

Epoch: 5| Step: 11
Training loss: 0.35635554790496826
Validation loss: 2.058477928241094

Epoch: 380| Step: 0
Training loss: 0.4269378185272217
Validation loss: 2.0395047813653946

Epoch: 5| Step: 1
Training loss: 0.43733254075050354
Validation loss: 2.072105144460996

Epoch: 5| Step: 2
Training loss: 0.5125287771224976
Validation loss: 2.0612266262372336

Epoch: 5| Step: 3
Training loss: 0.26152607798576355
Validation loss: 2.0387426614761353

Epoch: 5| Step: 4
Training loss: 0.4939652383327484
Validation loss: 2.089051196972529

Epoch: 5| Step: 5
Training loss: 1.0662784576416016
Validation loss: 2.083027179042498

Epoch: 5| Step: 6
Training loss: 0.648974597454071
Validation loss: 2.0456984490156174

Epoch: 5| Step: 7
Training loss: 0.37053123116493225
Validation loss: 2.038094997406006

Epoch: 5| Step: 8
Training loss: 0.22185663878917694
Validation loss: 2.0716751168171563

Epoch: 5| Step: 9
Training loss: 0.16725416481494904
Validation loss: 2.0693818728129068

Epoch: 5| Step: 10
Training loss: 0.4049677848815918
Validation loss: 2.0749059170484543

Epoch: 5| Step: 11
Training loss: 0.17461228370666504
Validation loss: 2.0665792922178903

Epoch: 381| Step: 0
Training loss: 0.3859606385231018
Validation loss: 2.0827104250590005

Epoch: 5| Step: 1
Training loss: 0.4492911398410797
Validation loss: 2.0315061261256537

Epoch: 5| Step: 2
Training loss: 0.5256596803665161
Validation loss: 2.0433955242236457

Epoch: 5| Step: 3
Training loss: 0.4040473997592926
Validation loss: 2.0611533373594284

Epoch: 5| Step: 4
Training loss: 0.39952021837234497
Validation loss: 2.0920454065004983

Epoch: 5| Step: 5
Training loss: 0.42380958795547485
Validation loss: 2.049497971932093

Epoch: 5| Step: 6
Training loss: 0.4906795620918274
Validation loss: 2.0412467370430627

Epoch: 5| Step: 7
Training loss: 0.7326494455337524
Validation loss: 2.048015092809995

Epoch: 5| Step: 8
Training loss: 0.425275981426239
Validation loss: 2.0932776679595313

Epoch: 5| Step: 9
Training loss: 0.6081291437149048
Validation loss: 2.030419478813807

Epoch: 5| Step: 10
Training loss: 0.3116772770881653
Validation loss: 2.0759633630514145

Epoch: 5| Step: 11
Training loss: 0.4318361282348633
Validation loss: 2.0715648581584296

Epoch: 382| Step: 0
Training loss: 0.3535754084587097
Validation loss: 2.069728503624598

Epoch: 5| Step: 1
Training loss: 0.6915179491043091
Validation loss: 2.086316635211309

Epoch: 5| Step: 2
Training loss: 0.477499783039093
Validation loss: 2.1055970738331475

Epoch: 5| Step: 3
Training loss: 0.24557633697986603
Validation loss: 2.0479831248521805

Epoch: 5| Step: 4
Training loss: 0.5670493841171265
Validation loss: 2.0535073975721994

Epoch: 5| Step: 5
Training loss: 0.46572622656822205
Validation loss: 2.092359592517217

Epoch: 5| Step: 6
Training loss: 0.2667533755302429
Validation loss: 2.056515837709109

Epoch: 5| Step: 7
Training loss: 0.31258565187454224
Validation loss: 2.068553720911344

Epoch: 5| Step: 8
Training loss: 0.6284416913986206
Validation loss: 2.070550113916397

Epoch: 5| Step: 9
Training loss: 0.6519639492034912
Validation loss: 2.0167116075754166

Epoch: 5| Step: 10
Training loss: 0.6197274327278137
Validation loss: 2.084648827711741

Epoch: 5| Step: 11
Training loss: 0.41447150707244873
Validation loss: 2.0466628968715668

Epoch: 383| Step: 0
Training loss: 0.45757466554641724
Validation loss: 2.04508276283741

Epoch: 5| Step: 1
Training loss: 0.5444735288619995
Validation loss: 2.040703942378362

Epoch: 5| Step: 2
Training loss: 0.8948413729667664
Validation loss: 2.0599606235822043

Epoch: 5| Step: 3
Training loss: 0.3174249529838562
Validation loss: 2.039088969429334

Epoch: 5| Step: 4
Training loss: 0.40120354294776917
Validation loss: 2.0654542495807013

Epoch: 5| Step: 5
Training loss: 0.48683857917785645
Validation loss: 2.043960710366567

Epoch: 5| Step: 6
Training loss: 0.5593899488449097
Validation loss: 2.0562207202116647

Epoch: 5| Step: 7
Training loss: 0.4131194055080414
Validation loss: 2.089628388484319

Epoch: 5| Step: 8
Training loss: 0.48844918608665466
Validation loss: 2.0132404069105783

Epoch: 5| Step: 9
Training loss: 0.764768660068512
Validation loss: 2.0548226833343506

Epoch: 5| Step: 10
Training loss: 0.36045387387275696
Validation loss: 2.034228727221489

Epoch: 5| Step: 11
Training loss: 0.2617993652820587
Validation loss: 2.0545445730288825

Epoch: 384| Step: 0
Training loss: 0.32193052768707275
Validation loss: 2.02754507958889

Epoch: 5| Step: 1
Training loss: 0.4628313183784485
Validation loss: 2.061572233835856

Epoch: 5| Step: 2
Training loss: 0.3118796944618225
Validation loss: 2.0111167182525

Epoch: 5| Step: 3
Training loss: 0.38491684198379517
Validation loss: 2.0640030205249786

Epoch: 5| Step: 4
Training loss: 0.505699872970581
Validation loss: 1.9742073714733124

Epoch: 5| Step: 5
Training loss: 0.4678459167480469
Validation loss: 2.0495047171910605

Epoch: 5| Step: 6
Training loss: 0.6251694560050964
Validation loss: 2.075174003839493

Epoch: 5| Step: 7
Training loss: 0.33581143617630005
Validation loss: 2.03767229616642

Epoch: 5| Step: 8
Training loss: 0.5107714533805847
Validation loss: 2.011557305852572

Epoch: 5| Step: 9
Training loss: 0.8521953821182251
Validation loss: 2.0238693157831826

Epoch: 5| Step: 10
Training loss: 0.37601447105407715
Validation loss: 2.024969587723414

Epoch: 5| Step: 11
Training loss: 0.33079802989959717
Validation loss: 2.0609636853138604

Epoch: 385| Step: 0
Training loss: 0.487993061542511
Validation loss: 2.009781946738561

Epoch: 5| Step: 1
Training loss: 0.4351300597190857
Validation loss: 2.006996621688207

Epoch: 5| Step: 2
Training loss: 0.3210015296936035
Validation loss: 2.041286384065946

Epoch: 5| Step: 3
Training loss: 0.3858115077018738
Validation loss: 2.0600212117036185

Epoch: 5| Step: 4
Training loss: 0.32897743582725525
Validation loss: 2.0168517231941223

Epoch: 5| Step: 5
Training loss: 0.8426612615585327
Validation loss: 2.0508854935566583

Epoch: 5| Step: 6
Training loss: 0.4938262104988098
Validation loss: 2.027336910367012

Epoch: 5| Step: 7
Training loss: 0.3846527636051178
Validation loss: 2.0578248848517737

Epoch: 5| Step: 8
Training loss: 0.4706236720085144
Validation loss: 2.0466847270727158

Epoch: 5| Step: 9
Training loss: 0.6192067861557007
Validation loss: 2.037310148278872

Epoch: 5| Step: 10
Training loss: 0.3614741265773773
Validation loss: 2.0600219070911407

Epoch: 5| Step: 11
Training loss: 0.242915540933609
Validation loss: 2.026660387714704

Epoch: 386| Step: 0
Training loss: 0.5970278978347778
Validation loss: 2.05437862376372

Epoch: 5| Step: 1
Training loss: 0.41361236572265625
Validation loss: 2.094470043977102

Epoch: 5| Step: 2
Training loss: 0.2693728506565094
Validation loss: 2.049406667550405

Epoch: 5| Step: 3
Training loss: 0.3097178339958191
Validation loss: 2.088845511277517

Epoch: 5| Step: 4
Training loss: 0.417059987783432
Validation loss: 2.0747197419404984

Epoch: 5| Step: 5
Training loss: 0.7686145901679993
Validation loss: 2.0784443616867065

Epoch: 5| Step: 6
Training loss: 0.41370731592178345
Validation loss: 2.074027190605799

Epoch: 5| Step: 7
Training loss: 0.6915571689605713
Validation loss: 2.0487868785858154

Epoch: 5| Step: 8
Training loss: 0.3776330351829529
Validation loss: 2.060141940911611

Epoch: 5| Step: 9
Training loss: 0.5001040697097778
Validation loss: 2.065027048190435

Epoch: 5| Step: 10
Training loss: 0.46235451102256775
Validation loss: 2.0638580272595086

Epoch: 5| Step: 11
Training loss: 0.3844909071922302
Validation loss: 2.0523642748594284

Epoch: 387| Step: 0
Training loss: 0.38709867000579834
Validation loss: 2.075051779548327

Epoch: 5| Step: 1
Training loss: 0.29669418931007385
Validation loss: 2.066649744908015

Epoch: 5| Step: 2
Training loss: 0.7119452953338623
Validation loss: 2.073287546634674

Epoch: 5| Step: 3
Training loss: 0.3991149365901947
Validation loss: 2.0896276285250983

Epoch: 5| Step: 4
Training loss: 0.2791009545326233
Validation loss: 2.0768587986628213

Epoch: 5| Step: 5
Training loss: 0.5605770349502563
Validation loss: 2.0720312893390656

Epoch: 5| Step: 6
Training loss: 0.42336177825927734
Validation loss: 2.060235247015953

Epoch: 5| Step: 7
Training loss: 0.5857549905776978
Validation loss: 2.0876555740833282

Epoch: 5| Step: 8
Training loss: 0.6048294305801392
Validation loss: 2.050682877500852

Epoch: 5| Step: 9
Training loss: 0.36375290155410767
Validation loss: 2.103041857481003

Epoch: 5| Step: 10
Training loss: 0.4126620292663574
Validation loss: 2.07239763935407

Epoch: 5| Step: 11
Training loss: 1.0792524814605713
Validation loss: 2.090578079223633

Epoch: 388| Step: 0
Training loss: 0.695728063583374
Validation loss: 2.1269593785206475

Epoch: 5| Step: 1
Training loss: 0.484959214925766
Validation loss: 2.1212254216273627

Epoch: 5| Step: 2
Training loss: 0.7217797040939331
Validation loss: 2.0802409698565802

Epoch: 5| Step: 3
Training loss: 0.23260846734046936
Validation loss: 2.0813560287157693

Epoch: 5| Step: 4
Training loss: 0.4910306930541992
Validation loss: 2.0865300397078195

Epoch: 5| Step: 5
Training loss: 0.5559931397438049
Validation loss: 2.089120810230573

Epoch: 5| Step: 6
Training loss: 0.4668068289756775
Validation loss: 2.0574599703152976

Epoch: 5| Step: 7
Training loss: 0.23022107779979706
Validation loss: 2.0765946159760156

Epoch: 5| Step: 8
Training loss: 0.275080144405365
Validation loss: 2.064710130294164

Epoch: 5| Step: 9
Training loss: 0.27180880308151245
Validation loss: 2.047335142890612

Epoch: 5| Step: 10
Training loss: 0.27651649713516235
Validation loss: 2.1031564523776374

Epoch: 5| Step: 11
Training loss: 0.13901859521865845
Validation loss: 2.048933744430542

Epoch: 389| Step: 0
Training loss: 0.26926180720329285
Validation loss: 2.0533856401840844

Epoch: 5| Step: 1
Training loss: 0.39183372259140015
Validation loss: 2.0462872932354608

Epoch: 5| Step: 2
Training loss: 0.3583891987800598
Validation loss: 2.1137876957654953

Epoch: 5| Step: 3
Training loss: 0.43452826142311096
Validation loss: 2.0906321307023368

Epoch: 5| Step: 4
Training loss: 0.5227028727531433
Validation loss: 2.0581947416067123

Epoch: 5| Step: 5
Training loss: 0.3755614757537842
Validation loss: 2.044615536928177

Epoch: 5| Step: 6
Training loss: 0.36126235127449036
Validation loss: 2.0699109782775245

Epoch: 5| Step: 7
Training loss: 0.5490272045135498
Validation loss: 2.0669894764820733

Epoch: 5| Step: 8
Training loss: 0.48448729515075684
Validation loss: 2.090293437242508

Epoch: 5| Step: 9
Training loss: 0.5998770594596863
Validation loss: 2.0430444528659186

Epoch: 5| Step: 10
Training loss: 0.43079155683517456
Validation loss: 2.03127051393191

Epoch: 5| Step: 11
Training loss: 0.12191939353942871
Validation loss: 2.0933791349331536

Epoch: 390| Step: 0
Training loss: 0.5384382009506226
Validation loss: 2.0876237948735556

Epoch: 5| Step: 1
Training loss: 0.27372604608535767
Validation loss: 2.110814948876699

Epoch: 5| Step: 2
Training loss: 0.40603265166282654
Validation loss: 2.0855614691972733

Epoch: 5| Step: 3
Training loss: 0.6670189499855042
Validation loss: 2.0878439793984094

Epoch: 5| Step: 4
Training loss: 0.5327266454696655
Validation loss: 2.0548716485500336

Epoch: 5| Step: 5
Training loss: 0.43759211897850037
Validation loss: 2.1045189698537192

Epoch: 5| Step: 6
Training loss: 0.4260798394680023
Validation loss: 2.142484337091446

Epoch: 5| Step: 7
Training loss: 0.40751200914382935
Validation loss: 2.062917093435923

Epoch: 5| Step: 8
Training loss: 0.3153919577598572
Validation loss: 2.1163147687911987

Epoch: 5| Step: 9
Training loss: 0.6353110074996948
Validation loss: 2.062335034211477

Epoch: 5| Step: 10
Training loss: 0.2400318831205368
Validation loss: 2.100833088159561

Epoch: 5| Step: 11
Training loss: 0.13724464178085327
Validation loss: 2.085667128364245

Epoch: 391| Step: 0
Training loss: 0.4434683918952942
Validation loss: 2.0739295879999795

Epoch: 5| Step: 1
Training loss: 0.4048148989677429
Validation loss: 2.0844632188479104

Epoch: 5| Step: 2
Training loss: 0.42583316564559937
Validation loss: 2.094363510608673

Epoch: 5| Step: 3
Training loss: 0.30592840909957886
Validation loss: 2.0853345096111298

Epoch: 5| Step: 4
Training loss: 0.4180598258972168
Validation loss: 2.0870484560728073

Epoch: 5| Step: 5
Training loss: 0.30304330587387085
Validation loss: 2.048411245147387

Epoch: 5| Step: 6
Training loss: 0.4341806471347809
Validation loss: 2.0595541646083197

Epoch: 5| Step: 7
Training loss: 0.6371558904647827
Validation loss: 2.0811306486527124

Epoch: 5| Step: 8
Training loss: 0.5273343920707703
Validation loss: 2.0795019219319024

Epoch: 5| Step: 9
Training loss: 0.24636244773864746
Validation loss: 2.0947346836328506

Epoch: 5| Step: 10
Training loss: 0.5218626856803894
Validation loss: 2.0608771443367004

Epoch: 5| Step: 11
Training loss: 0.4602172374725342
Validation loss: 2.052921935915947

Epoch: 392| Step: 0
Training loss: 0.45346933603286743
Validation loss: 2.0717633863290152

Epoch: 5| Step: 1
Training loss: 0.6868993639945984
Validation loss: 2.0506744335095086

Epoch: 5| Step: 2
Training loss: 0.34938621520996094
Validation loss: 2.1027112156152725

Epoch: 5| Step: 3
Training loss: 0.3061692714691162
Validation loss: 2.0870379408200583

Epoch: 5| Step: 4
Training loss: 0.2660209536552429
Validation loss: 2.1168291121721268

Epoch: 5| Step: 5
Training loss: 0.4534694254398346
Validation loss: 2.0813190390666327

Epoch: 5| Step: 6
Training loss: 0.48189765214920044
Validation loss: 2.0624545514583588

Epoch: 5| Step: 7
Training loss: 0.5695621371269226
Validation loss: 2.077839454015096

Epoch: 5| Step: 8
Training loss: 0.3247634470462799
Validation loss: 2.086872642238935

Epoch: 5| Step: 9
Training loss: 0.6051169633865356
Validation loss: 2.0178240140279136

Epoch: 5| Step: 10
Training loss: 0.28524357080459595
Validation loss: 2.062305028239886

Epoch: 5| Step: 11
Training loss: 0.1263902187347412
Validation loss: 2.084369267026583

Epoch: 393| Step: 0
Training loss: 0.39456161856651306
Validation loss: 2.0683278143405914

Epoch: 5| Step: 1
Training loss: 0.650018036365509
Validation loss: 2.073020502924919

Epoch: 5| Step: 2
Training loss: 0.20076695084571838
Validation loss: 2.0649189750353494

Epoch: 5| Step: 3
Training loss: 0.41270899772644043
Validation loss: 2.057562400897344

Epoch: 5| Step: 4
Training loss: 0.4961473345756531
Validation loss: 2.066276972492536

Epoch: 5| Step: 5
Training loss: 0.5630698204040527
Validation loss: 2.063822011152903

Epoch: 5| Step: 6
Training loss: 0.1483422964811325
Validation loss: 2.056020677089691

Epoch: 5| Step: 7
Training loss: 0.27627333998680115
Validation loss: 2.0835809310277305

Epoch: 5| Step: 8
Training loss: 0.29820042848587036
Validation loss: 2.0683254251877465

Epoch: 5| Step: 9
Training loss: 0.7180474400520325
Validation loss: 2.0815807580947876

Epoch: 5| Step: 10
Training loss: 0.5310665369033813
Validation loss: 2.0836258083581924

Epoch: 5| Step: 11
Training loss: 0.589297890663147
Validation loss: 2.093578432997068

Epoch: 394| Step: 0
Training loss: 0.3135336935520172
Validation loss: 2.0902048299709954

Epoch: 5| Step: 1
Training loss: 0.31616073846817017
Validation loss: 2.047648474574089

Epoch: 5| Step: 2
Training loss: 0.386104017496109
Validation loss: 2.120864366491636

Epoch: 5| Step: 3
Training loss: 0.5918151140213013
Validation loss: 2.0648098091284433

Epoch: 5| Step: 4
Training loss: 0.32982152700424194
Validation loss: 2.066368450721105

Epoch: 5| Step: 5
Training loss: 0.26820695400238037
Validation loss: 2.0465793857971826

Epoch: 5| Step: 6
Training loss: 0.5054789781570435
Validation loss: 2.093820795416832

Epoch: 5| Step: 7
Training loss: 0.8145944476127625
Validation loss: 2.094649165868759

Epoch: 5| Step: 8
Training loss: 0.23260045051574707
Validation loss: 2.055635323127111

Epoch: 5| Step: 9
Training loss: 0.4771943986415863
Validation loss: 2.0233821819225946

Epoch: 5| Step: 10
Training loss: 0.3504734933376312
Validation loss: 2.0327931692202887

Epoch: 5| Step: 11
Training loss: 0.6653562784194946
Validation loss: 2.111536994576454

Epoch: 395| Step: 0
Training loss: 0.2673413157463074
Validation loss: 2.074927488962809

Epoch: 5| Step: 1
Training loss: 0.33403223752975464
Validation loss: 2.0333945949872336

Epoch: 5| Step: 2
Training loss: 0.3359908163547516
Validation loss: 2.0183726797501245

Epoch: 5| Step: 3
Training loss: 0.43250322341918945
Validation loss: 2.084177096684774

Epoch: 5| Step: 4
Training loss: 0.3388743996620178
Validation loss: 2.0436261892318726

Epoch: 5| Step: 5
Training loss: 0.18850329518318176
Validation loss: 2.0367997884750366

Epoch: 5| Step: 6
Training loss: 0.6521903276443481
Validation loss: 2.0962990323702493

Epoch: 5| Step: 7
Training loss: 0.6993306279182434
Validation loss: 2.0937432944774628

Epoch: 5| Step: 8
Training loss: 0.3961469531059265
Validation loss: 2.0711610664923987

Epoch: 5| Step: 9
Training loss: 0.4198246896266937
Validation loss: 2.0558479328950248

Epoch: 5| Step: 10
Training loss: 0.3834037184715271
Validation loss: 2.091732452313105

Epoch: 5| Step: 11
Training loss: 0.15349042415618896
Validation loss: 2.067538703481356

Epoch: 396| Step: 0
Training loss: 0.2867012917995453
Validation loss: 2.1105247835318246

Epoch: 5| Step: 1
Training loss: 0.3363620340824127
Validation loss: 2.0436992148558297

Epoch: 5| Step: 2
Training loss: 0.40583571791648865
Validation loss: 2.119256764650345

Epoch: 5| Step: 3
Training loss: 0.44223514199256897
Validation loss: 2.083852802713712

Epoch: 5| Step: 4
Training loss: 0.46005988121032715
Validation loss: 2.068066264192263

Epoch: 5| Step: 5
Training loss: 0.33376407623291016
Validation loss: 2.031120171149572

Epoch: 5| Step: 6
Training loss: 0.6330046057701111
Validation loss: 2.066894625624021

Epoch: 5| Step: 7
Training loss: 0.5508648753166199
Validation loss: 2.0739045987526574

Epoch: 5| Step: 8
Training loss: 0.17029257118701935
Validation loss: 2.0138629525899887

Epoch: 5| Step: 9
Training loss: 0.5193020105361938
Validation loss: 2.076536695162455

Epoch: 5| Step: 10
Training loss: 0.47774019837379456
Validation loss: 2.0408085187276206

Epoch: 5| Step: 11
Training loss: 0.12062084674835205
Validation loss: 2.051588475704193

Epoch: 397| Step: 0
Training loss: 0.36403998732566833
Validation loss: 2.0521182169516883

Epoch: 5| Step: 1
Training loss: 0.6998313665390015
Validation loss: 2.0701242635647454

Epoch: 5| Step: 2
Training loss: 0.4163844585418701
Validation loss: 2.0903461078802743

Epoch: 5| Step: 3
Training loss: 0.4035329818725586
Validation loss: 2.0837514152129493

Epoch: 5| Step: 4
Training loss: 0.2261168509721756
Validation loss: 2.1014278531074524

Epoch: 5| Step: 5
Training loss: 0.39713627099990845
Validation loss: 2.058516954382261

Epoch: 5| Step: 6
Training loss: 0.8403397798538208
Validation loss: 2.080805480480194

Epoch: 5| Step: 7
Training loss: 0.33104902505874634
Validation loss: 2.101578801870346

Epoch: 5| Step: 8
Training loss: 0.4587160050868988
Validation loss: 2.077583829561869

Epoch: 5| Step: 9
Training loss: 0.3478584885597229
Validation loss: 2.0952102094888687

Epoch: 5| Step: 10
Training loss: 0.29009178280830383
Validation loss: 2.088756928841273

Epoch: 5| Step: 11
Training loss: 0.2034914493560791
Validation loss: 2.065755625565847

Epoch: 398| Step: 0
Training loss: 0.7664243578910828
Validation loss: 2.093288630247116

Epoch: 5| Step: 1
Training loss: 0.39877384901046753
Validation loss: 2.0853860676288605

Epoch: 5| Step: 2
Training loss: 0.2791499197483063
Validation loss: 2.087488760550817

Epoch: 5| Step: 3
Training loss: 0.3671603500843048
Validation loss: 2.0350648214419684

Epoch: 5| Step: 4
Training loss: 0.5057944059371948
Validation loss: 2.0460878014564514

Epoch: 5| Step: 5
Training loss: 0.4506298899650574
Validation loss: 2.0373946925004325

Epoch: 5| Step: 6
Training loss: 0.32863014936447144
Validation loss: 2.0319438874721527

Epoch: 5| Step: 7
Training loss: 0.549153208732605
Validation loss: 2.036211311817169

Epoch: 5| Step: 8
Training loss: 0.5276628136634827
Validation loss: 2.0174082070589066

Epoch: 5| Step: 9
Training loss: 0.45796269178390503
Validation loss: 2.0656797885894775

Epoch: 5| Step: 10
Training loss: 0.2785842716693878
Validation loss: 2.064487636089325

Epoch: 5| Step: 11
Training loss: 0.816284716129303
Validation loss: 2.0538238932689032

Epoch: 399| Step: 0
Training loss: 0.20167331397533417
Validation loss: 2.0390806247790656

Epoch: 5| Step: 1
Training loss: 0.3270140290260315
Validation loss: 2.040746256709099

Epoch: 5| Step: 2
Training loss: 0.5683363676071167
Validation loss: 2.055835952361425

Epoch: 5| Step: 3
Training loss: 0.4075905382633209
Validation loss: 2.045542905728022

Epoch: 5| Step: 4
Training loss: 0.2806721031665802
Validation loss: 2.048444539308548

Epoch: 5| Step: 5
Training loss: 0.3440316915512085
Validation loss: 2.095398336648941

Epoch: 5| Step: 6
Training loss: 0.6258813142776489
Validation loss: 2.0577012995878854

Epoch: 5| Step: 7
Training loss: 0.31460893154144287
Validation loss: 2.0918164600928626

Epoch: 5| Step: 8
Training loss: 0.677463173866272
Validation loss: 2.0623655964930854

Epoch: 5| Step: 9
Training loss: 0.46013230085372925
Validation loss: 2.0609910736481347

Epoch: 5| Step: 10
Training loss: 0.42376819252967834
Validation loss: 2.0586425016323724

Epoch: 5| Step: 11
Training loss: 0.6452268958091736
Validation loss: 2.0451268454392753

Epoch: 400| Step: 0
Training loss: 0.22007575631141663
Validation loss: 2.0575705418984094

Epoch: 5| Step: 1
Training loss: 0.3951006531715393
Validation loss: 2.0398364861806235

Epoch: 5| Step: 2
Training loss: 0.32720619440078735
Validation loss: 2.0808913856744766

Epoch: 5| Step: 3
Training loss: 0.46218347549438477
Validation loss: 2.0811710755030313

Epoch: 5| Step: 4
Training loss: 0.3808908760547638
Validation loss: 2.082724779844284

Epoch: 5| Step: 5
Training loss: 0.30211055278778076
Validation loss: 2.0600768675406775

Epoch: 5| Step: 6
Training loss: 0.6424323320388794
Validation loss: 2.098667025566101

Epoch: 5| Step: 7
Training loss: 0.6703075170516968
Validation loss: 2.0713964949051538

Epoch: 5| Step: 8
Training loss: 0.3256368637084961
Validation loss: 2.097447862227758

Epoch: 5| Step: 9
Training loss: 0.5463022589683533
Validation loss: 2.057520161072413

Epoch: 5| Step: 10
Training loss: 0.5825142860412598
Validation loss: 2.0632357050975165

Epoch: 5| Step: 11
Training loss: 0.4529595971107483
Validation loss: 2.054829756418864

Epoch: 401| Step: 0
Training loss: 0.5139281749725342
Validation loss: 2.042865976691246

Epoch: 5| Step: 1
Training loss: 0.47533464431762695
Validation loss: 2.057064731915792

Epoch: 5| Step: 2
Training loss: 0.5374614000320435
Validation loss: 2.0270388225714364

Epoch: 5| Step: 3
Training loss: 0.41660624742507935
Validation loss: 2.063758671283722

Epoch: 5| Step: 4
Training loss: 0.5540637373924255
Validation loss: 2.0691815416018167

Epoch: 5| Step: 5
Training loss: 0.4641229212284088
Validation loss: 2.041842425862948

Epoch: 5| Step: 6
Training loss: 0.3957732915878296
Validation loss: 2.08382015923659

Epoch: 5| Step: 7
Training loss: 0.511320948600769
Validation loss: 2.0778124382098517

Epoch: 5| Step: 8
Training loss: 0.3585253357887268
Validation loss: 2.06037109096845

Epoch: 5| Step: 9
Training loss: 0.2896677851676941
Validation loss: 2.051571329434713

Epoch: 5| Step: 10
Training loss: 0.3170291483402252
Validation loss: 2.0277095983425775

Epoch: 5| Step: 11
Training loss: 0.19076693058013916
Validation loss: 2.0348871499300003

Epoch: 402| Step: 0
Training loss: 0.4357072710990906
Validation loss: 2.0518552511930466

Epoch: 5| Step: 1
Training loss: 0.4101800322532654
Validation loss: 2.0730722149213157

Epoch: 5| Step: 2
Training loss: 0.6476877331733704
Validation loss: 2.0476935108502707

Epoch: 5| Step: 3
Training loss: 0.5956438779830933
Validation loss: 2.051671266555786

Epoch: 5| Step: 4
Training loss: 0.5728335380554199
Validation loss: 2.09038183093071

Epoch: 5| Step: 5
Training loss: 0.48631030321121216
Validation loss: 2.0530331383148828

Epoch: 5| Step: 6
Training loss: 0.2653924226760864
Validation loss: 2.047136758764585

Epoch: 5| Step: 7
Training loss: 0.4776003956794739
Validation loss: 2.076981137196223

Epoch: 5| Step: 8
Training loss: 0.4411472678184509
Validation loss: 2.0551683604717255

Epoch: 5| Step: 9
Training loss: 0.32170745730400085
Validation loss: 2.08860016365846

Epoch: 5| Step: 10
Training loss: 0.18890301883220673
Validation loss: 2.019945686062177

Epoch: 5| Step: 11
Training loss: 0.12047600746154785
Validation loss: 2.083195815483729

Epoch: 403| Step: 0
Training loss: 0.44313740730285645
Validation loss: 2.064131036400795

Epoch: 5| Step: 1
Training loss: 0.3247504234313965
Validation loss: 2.049541711807251

Epoch: 5| Step: 2
Training loss: 0.4290323257446289
Validation loss: 2.0947549690802894

Epoch: 5| Step: 3
Training loss: 0.6721585392951965
Validation loss: 2.071103389064471

Epoch: 5| Step: 4
Training loss: 0.2811136245727539
Validation loss: 2.077016517519951

Epoch: 5| Step: 5
Training loss: 0.2877601981163025
Validation loss: 2.124263053139051

Epoch: 5| Step: 6
Training loss: 0.3069078326225281
Validation loss: 2.0769362847010293

Epoch: 5| Step: 7
Training loss: 0.2812337279319763
Validation loss: 2.093170791864395

Epoch: 5| Step: 8
Training loss: 0.5940309762954712
Validation loss: 2.0912677297989526

Epoch: 5| Step: 9
Training loss: 0.2979481816291809
Validation loss: 2.0535704096158347

Epoch: 5| Step: 10
Training loss: 0.5093017220497131
Validation loss: 2.0809427946805954

Epoch: 5| Step: 11
Training loss: 1.1831165552139282
Validation loss: 2.0948809534311295

Epoch: 404| Step: 0
Training loss: 0.558838963508606
Validation loss: 2.078347861766815

Epoch: 5| Step: 1
Training loss: 0.26701459288597107
Validation loss: 2.067950283487638

Epoch: 5| Step: 2
Training loss: 0.23260636627674103
Validation loss: 2.084044019381205

Epoch: 5| Step: 3
Training loss: 0.5115283727645874
Validation loss: 2.101570427417755

Epoch: 5| Step: 4
Training loss: 0.45836004614830017
Validation loss: 2.0327623039484024

Epoch: 5| Step: 5
Training loss: 0.2239067554473877
Validation loss: 2.0689945816993713

Epoch: 5| Step: 6
Training loss: 0.5290830731391907
Validation loss: 2.0604879558086395

Epoch: 5| Step: 7
Training loss: 0.5506870150566101
Validation loss: 2.0372231851021447

Epoch: 5| Step: 8
Training loss: 0.5523859262466431
Validation loss: 1.9972478101650875

Epoch: 5| Step: 9
Training loss: 0.5653091669082642
Validation loss: 2.049887960155805

Epoch: 5| Step: 10
Training loss: 0.3626836836338043
Validation loss: 2.0694297750790915

Epoch: 5| Step: 11
Training loss: 0.26881253719329834
Validation loss: 2.0835989316304526

Epoch: 405| Step: 0
Training loss: 0.24898883700370789
Validation loss: 2.016008049249649

Epoch: 5| Step: 1
Training loss: 0.32961955666542053
Validation loss: 2.0529418140649796

Epoch: 5| Step: 2
Training loss: 0.7955554723739624
Validation loss: 2.0190753688414893

Epoch: 5| Step: 3
Training loss: 0.5059090852737427
Validation loss: 2.0713037153085074

Epoch: 5| Step: 4
Training loss: 0.3055628836154938
Validation loss: 2.0779580622911453

Epoch: 5| Step: 5
Training loss: 0.44164276123046875
Validation loss: 2.0372464259465537

Epoch: 5| Step: 6
Training loss: 0.3117603659629822
Validation loss: 2.038500795761744

Epoch: 5| Step: 7
Training loss: 0.4854596257209778
Validation loss: 2.063237115740776

Epoch: 5| Step: 8
Training loss: 0.4723474085330963
Validation loss: 2.063590129216512

Epoch: 5| Step: 9
Training loss: 0.2814282774925232
Validation loss: 2.054366648197174

Epoch: 5| Step: 10
Training loss: 0.5235016942024231
Validation loss: 2.078079422314962

Epoch: 5| Step: 11
Training loss: 0.0495719313621521
Validation loss: 2.067415783802668

Epoch: 406| Step: 0
Training loss: 0.5316709280014038
Validation loss: 2.061884035666784

Epoch: 5| Step: 1
Training loss: 0.25699687004089355
Validation loss: 2.02778268357118

Epoch: 5| Step: 2
Training loss: 0.4024891257286072
Validation loss: 2.0634493877490363

Epoch: 5| Step: 3
Training loss: 0.42035382986068726
Validation loss: 2.0542030880848565

Epoch: 5| Step: 4
Training loss: 0.4215005934238434
Validation loss: 2.06976784269015

Epoch: 5| Step: 5
Training loss: 0.4619410037994385
Validation loss: 2.090569237867991

Epoch: 5| Step: 6
Training loss: 0.3312581181526184
Validation loss: 2.0975781132777533

Epoch: 5| Step: 7
Training loss: 0.4831627309322357
Validation loss: 2.103451758623123

Epoch: 5| Step: 8
Training loss: 0.30494076013565063
Validation loss: 2.0827577213446298

Epoch: 5| Step: 9
Training loss: 0.5805914998054504
Validation loss: 2.033333510160446

Epoch: 5| Step: 10
Training loss: 0.50678551197052
Validation loss: 2.0566494514544806

Epoch: 5| Step: 11
Training loss: 0.2361883968114853
Validation loss: 2.0736446479956308

Epoch: 407| Step: 0
Training loss: 0.18983744084835052
Validation loss: 2.0870861311753592

Epoch: 5| Step: 1
Training loss: 0.22773492336273193
Validation loss: 2.0382747600475946

Epoch: 5| Step: 2
Training loss: 0.16649021208286285
Validation loss: 2.104646881421407

Epoch: 5| Step: 3
Training loss: 0.5987241268157959
Validation loss: 2.1023009518782296

Epoch: 5| Step: 4
Training loss: 0.23483113944530487
Validation loss: 2.023833359281222

Epoch: 5| Step: 5
Training loss: 0.9288180470466614
Validation loss: 2.063244551420212

Epoch: 5| Step: 6
Training loss: 0.49952277541160583
Validation loss: 2.094226360321045

Epoch: 5| Step: 7
Training loss: 0.31716975569725037
Validation loss: 2.077901601791382

Epoch: 5| Step: 8
Training loss: 0.33722591400146484
Validation loss: 2.073067625363668

Epoch: 5| Step: 9
Training loss: 0.5089232325553894
Validation loss: 2.037376975019773

Epoch: 5| Step: 10
Training loss: 0.4574551582336426
Validation loss: 2.0630428393681846

Epoch: 5| Step: 11
Training loss: 0.6512548327445984
Validation loss: 2.069004793961843

Epoch: 408| Step: 0
Training loss: 0.42684322595596313
Validation loss: 2.0111466894547143

Epoch: 5| Step: 1
Training loss: 0.42064204812049866
Validation loss: 2.044643759727478

Epoch: 5| Step: 2
Training loss: 0.5314767956733704
Validation loss: 2.078196426232656

Epoch: 5| Step: 3
Training loss: 0.36243683099746704
Validation loss: 2.089359243710836

Epoch: 5| Step: 4
Training loss: 0.24801325798034668
Validation loss: 2.0481697022914886

Epoch: 5| Step: 5
Training loss: 0.4001452326774597
Validation loss: 2.0482424596945443

Epoch: 5| Step: 6
Training loss: 0.3388547897338867
Validation loss: 2.090313578645388

Epoch: 5| Step: 7
Training loss: 0.7650412917137146
Validation loss: 2.068682461977005

Epoch: 5| Step: 8
Training loss: 0.3979772925376892
Validation loss: 2.0744048406680426

Epoch: 5| Step: 9
Training loss: 0.20652687549591064
Validation loss: 2.066632558902105

Epoch: 5| Step: 10
Training loss: 0.4816410541534424
Validation loss: 2.057555675506592

Epoch: 5| Step: 11
Training loss: 0.4005068838596344
Validation loss: 2.07185431321462

Epoch: 409| Step: 0
Training loss: 0.2777867317199707
Validation loss: 2.095751737554868

Epoch: 5| Step: 1
Training loss: 0.5668894052505493
Validation loss: 2.12701087196668

Epoch: 5| Step: 2
Training loss: 0.331471711397171
Validation loss: 2.0861254384120307

Epoch: 5| Step: 3
Training loss: 0.2713983952999115
Validation loss: 2.102522522211075

Epoch: 5| Step: 4
Training loss: 0.5325441360473633
Validation loss: 2.0897066593170166

Epoch: 5| Step: 5
Training loss: 0.49729928374290466
Validation loss: 2.141654615600904

Epoch: 5| Step: 6
Training loss: 0.41420578956604004
Validation loss: 2.117983435591062

Epoch: 5| Step: 7
Training loss: 0.4620540738105774
Validation loss: 2.1184545209010444

Epoch: 5| Step: 8
Training loss: 0.550936758518219
Validation loss: 2.073692868153254

Epoch: 5| Step: 9
Training loss: 0.33615535497665405
Validation loss: 2.0619225054979324

Epoch: 5| Step: 10
Training loss: 0.2789280116558075
Validation loss: 2.073886667688688

Epoch: 5| Step: 11
Training loss: 0.19069510698318481
Validation loss: 2.0542869021495185

Epoch: 410| Step: 0
Training loss: 0.3149968683719635
Validation loss: 2.054651618003845

Epoch: 5| Step: 1
Training loss: 0.6276066899299622
Validation loss: 2.097696835796038

Epoch: 5| Step: 2
Training loss: 0.22180528938770294
Validation loss: 2.0879443486531577

Epoch: 5| Step: 3
Training loss: 0.4272022843360901
Validation loss: 2.0655329873164496

Epoch: 5| Step: 4
Training loss: 0.42782992124557495
Validation loss: 2.1013974199692407

Epoch: 5| Step: 5
Training loss: 0.4647463858127594
Validation loss: 2.083426594734192

Epoch: 5| Step: 6
Training loss: 0.3274666965007782
Validation loss: 2.0786538372437158

Epoch: 5| Step: 7
Training loss: 0.40883246064186096
Validation loss: 2.039268066485723

Epoch: 5| Step: 8
Training loss: 0.7991725206375122
Validation loss: 2.047516177097956

Epoch: 5| Step: 9
Training loss: 0.22538384795188904
Validation loss: 2.0486987779537835

Epoch: 5| Step: 10
Training loss: 0.30134233832359314
Validation loss: 2.0807800044616065

Epoch: 5| Step: 11
Training loss: 0.2095249891281128
Validation loss: 2.063128431638082

Epoch: 411| Step: 0
Training loss: 0.7133553624153137
Validation loss: 2.0398465593655906

Epoch: 5| Step: 1
Training loss: 0.38717859983444214
Validation loss: 2.0675436158974967

Epoch: 5| Step: 2
Training loss: 0.450714111328125
Validation loss: 2.0814239035050073

Epoch: 5| Step: 3
Training loss: 0.29802075028419495
Validation loss: 2.05893537402153

Epoch: 5| Step: 4
Training loss: 0.43702030181884766
Validation loss: 2.1369764606157937

Epoch: 5| Step: 5
Training loss: 0.4149400293827057
Validation loss: 2.0475741823514304

Epoch: 5| Step: 6
Training loss: 0.42669373750686646
Validation loss: 2.096693088610967

Epoch: 5| Step: 7
Training loss: 0.2786615490913391
Validation loss: 2.082024027903875

Epoch: 5| Step: 8
Training loss: 0.5705953240394592
Validation loss: 2.06875941157341

Epoch: 5| Step: 9
Training loss: 0.3835177719593048
Validation loss: 2.0824343959490457

Epoch: 5| Step: 10
Training loss: 0.32133227586746216
Validation loss: 2.0524303565422692

Epoch: 5| Step: 11
Training loss: 0.28830528259277344
Validation loss: 2.060751289129257

Epoch: 412| Step: 0
Training loss: 0.6800910830497742
Validation loss: 2.071274851759275

Epoch: 5| Step: 1
Training loss: 0.6331096887588501
Validation loss: 2.0262376964092255

Epoch: 5| Step: 2
Training loss: 0.3136194050312042
Validation loss: 2.0815488348404565

Epoch: 5| Step: 3
Training loss: 0.37985748052597046
Validation loss: 2.066365415851275

Epoch: 5| Step: 4
Training loss: 0.22396457195281982
Validation loss: 2.0680512686570487

Epoch: 5| Step: 5
Training loss: 0.39484483003616333
Validation loss: 2.069824834664663

Epoch: 5| Step: 6
Training loss: 0.187341570854187
Validation loss: 2.028315708041191

Epoch: 5| Step: 7
Training loss: 0.2874244451522827
Validation loss: 2.034900411963463

Epoch: 5| Step: 8
Training loss: 0.6175698637962341
Validation loss: 2.034420073032379

Epoch: 5| Step: 9
Training loss: 0.40234827995300293
Validation loss: 2.054590250054995

Epoch: 5| Step: 10
Training loss: 0.3943083882331848
Validation loss: 2.067576994498571

Epoch: 5| Step: 11
Training loss: 0.3217126131057739
Validation loss: 2.06942056119442

Epoch: 413| Step: 0
Training loss: 0.5261017084121704
Validation loss: 2.0521041601896286

Epoch: 5| Step: 1
Training loss: 0.24694538116455078
Validation loss: 2.0553805232048035

Epoch: 5| Step: 2
Training loss: 0.35905981063842773
Validation loss: 2.0675283074378967

Epoch: 5| Step: 3
Training loss: 0.7759135365486145
Validation loss: 2.0777085423469543

Epoch: 5| Step: 4
Training loss: 0.5089121460914612
Validation loss: 2.096674154202143

Epoch: 5| Step: 5
Training loss: 0.5507968664169312
Validation loss: 2.0765657673279443

Epoch: 5| Step: 6
Training loss: 0.18608564138412476
Validation loss: 2.070947676897049

Epoch: 5| Step: 7
Training loss: 0.26679497957229614
Validation loss: 2.0500305692354837

Epoch: 5| Step: 8
Training loss: 0.449209600687027
Validation loss: 2.091725781559944

Epoch: 5| Step: 9
Training loss: 0.5682021379470825
Validation loss: 2.0696714520454407

Epoch: 5| Step: 10
Training loss: 0.2772842049598694
Validation loss: 2.0562811692555747

Epoch: 5| Step: 11
Training loss: 0.42704373598098755
Validation loss: 2.057892551024755

Epoch: 414| Step: 0
Training loss: 0.2778990864753723
Validation loss: 2.076136514544487

Epoch: 5| Step: 1
Training loss: 0.6284196972846985
Validation loss: 2.072982206940651

Epoch: 5| Step: 2
Training loss: 0.2350171059370041
Validation loss: 2.0943912218014398

Epoch: 5| Step: 3
Training loss: 0.26775798201560974
Validation loss: 2.065312604109446

Epoch: 5| Step: 4
Training loss: 0.4269948899745941
Validation loss: 2.0593704680601754

Epoch: 5| Step: 5
Training loss: 0.23510321974754333
Validation loss: 2.0859253803888955

Epoch: 5| Step: 6
Training loss: 0.37968146800994873
Validation loss: 2.0679707576831183

Epoch: 5| Step: 7
Training loss: 0.679155707359314
Validation loss: 2.0408568183581033

Epoch: 5| Step: 8
Training loss: 0.5195616483688354
Validation loss: 2.08503029247125

Epoch: 5| Step: 9
Training loss: 0.4940546154975891
Validation loss: 2.0791970690091452

Epoch: 5| Step: 10
Training loss: 0.22025370597839355
Validation loss: 2.104937662680944

Epoch: 5| Step: 11
Training loss: 1.2335020303726196
Validation loss: 2.0728710939486823

Epoch: 415| Step: 0
Training loss: 0.322630375623703
Validation loss: 2.102549374103546

Epoch: 5| Step: 1
Training loss: 0.36873626708984375
Validation loss: 2.1673814753691354

Epoch: 5| Step: 2
Training loss: 0.6174834370613098
Validation loss: 2.1029643217722573

Epoch: 5| Step: 3
Training loss: 0.5304652452468872
Validation loss: 2.1391570369402566

Epoch: 5| Step: 4
Training loss: 0.5239824056625366
Validation loss: 2.070056915283203

Epoch: 5| Step: 5
Training loss: 0.37791067361831665
Validation loss: 2.1530468861262

Epoch: 5| Step: 6
Training loss: 0.3542477488517761
Validation loss: 2.0823529412349067

Epoch: 5| Step: 7
Training loss: 0.2210104912519455
Validation loss: 2.0912601302067437

Epoch: 5| Step: 8
Training loss: 0.44323500990867615
Validation loss: 2.1180066665013633

Epoch: 5| Step: 9
Training loss: 0.40887945890426636
Validation loss: 2.097505102554957

Epoch: 5| Step: 10
Training loss: 0.3174055218696594
Validation loss: 2.1144581188758216

Epoch: 5| Step: 11
Training loss: 0.2325582504272461
Validation loss: 2.0734540025393167

Epoch: 416| Step: 0
Training loss: 0.2916213870048523
Validation loss: 2.133080020546913

Epoch: 5| Step: 1
Training loss: 0.44664913415908813
Validation loss: 2.1490820993979773

Epoch: 5| Step: 2
Training loss: 0.5465055108070374
Validation loss: 2.120999659101168

Epoch: 5| Step: 3
Training loss: 0.3411523699760437
Validation loss: 2.0967542082071304

Epoch: 5| Step: 4
Training loss: 0.6651736497879028
Validation loss: 2.1076586743195853

Epoch: 5| Step: 5
Training loss: 0.5257095098495483
Validation loss: 2.1072037667036057

Epoch: 5| Step: 6
Training loss: 0.5456421971321106
Validation loss: 2.1155730734268823

Epoch: 5| Step: 7
Training loss: 0.2356947660446167
Validation loss: 2.09297151863575

Epoch: 5| Step: 8
Training loss: 0.5482324361801147
Validation loss: 2.0967169205347695

Epoch: 5| Step: 9
Training loss: 0.3853916525840759
Validation loss: 2.1599208215872445

Epoch: 5| Step: 10
Training loss: 0.18041270971298218
Validation loss: 2.119514827926954

Epoch: 5| Step: 11
Training loss: 0.29754340648651123
Validation loss: 2.081776554385821

Epoch: 417| Step: 0
Training loss: 0.6371089816093445
Validation loss: 2.1112649589776993

Epoch: 5| Step: 1
Training loss: 0.21340355277061462
Validation loss: 2.1147332390149436

Epoch: 5| Step: 2
Training loss: 0.3205508589744568
Validation loss: 2.0981010794639587

Epoch: 5| Step: 3
Training loss: 0.489382803440094
Validation loss: 2.0911781042814255

Epoch: 5| Step: 4
Training loss: 0.44245797395706177
Validation loss: 2.064170906941096

Epoch: 5| Step: 5
Training loss: 0.46804118156433105
Validation loss: 2.070585603515307

Epoch: 5| Step: 6
Training loss: 0.31923338770866394
Validation loss: 2.097454180320104

Epoch: 5| Step: 7
Training loss: 0.36622354388237
Validation loss: 2.07420485218366

Epoch: 5| Step: 8
Training loss: 0.30763334035873413
Validation loss: 2.055484568079313

Epoch: 5| Step: 9
Training loss: 0.43080559372901917
Validation loss: 2.0586104840040207

Epoch: 5| Step: 10
Training loss: 0.3925033509731293
Validation loss: 2.032772108912468

Epoch: 5| Step: 11
Training loss: 0.8002557754516602
Validation loss: 2.030686845382055

Epoch: 418| Step: 0
Training loss: 0.6568809747695923
Validation loss: 2.0241394639015198

Epoch: 5| Step: 1
Training loss: 0.6360820531845093
Validation loss: 2.0670839647452035

Epoch: 5| Step: 2
Training loss: 0.4500909447669983
Validation loss: 2.0290523072083793

Epoch: 5| Step: 3
Training loss: 0.5114133954048157
Validation loss: 2.0934703250726066

Epoch: 5| Step: 4
Training loss: 0.36661046743392944
Validation loss: 2.0664892892042794

Epoch: 5| Step: 5
Training loss: 0.35334357619285583
Validation loss: 2.0892969419558844

Epoch: 5| Step: 6
Training loss: 0.4232974648475647
Validation loss: 2.046218747893969

Epoch: 5| Step: 7
Training loss: 0.3101070523262024
Validation loss: 2.0730492373307547

Epoch: 5| Step: 8
Training loss: 0.16400310397148132
Validation loss: 2.0642820050319037

Epoch: 5| Step: 9
Training loss: 0.19716553390026093
Validation loss: 2.0404609739780426

Epoch: 5| Step: 10
Training loss: 0.2672739028930664
Validation loss: 2.0934543311595917

Epoch: 5| Step: 11
Training loss: 0.3085658550262451
Validation loss: 2.0904420713583627

Epoch: 419| Step: 0
Training loss: 0.487708181142807
Validation loss: 2.082034081220627

Epoch: 5| Step: 1
Training loss: 0.1941748410463333
Validation loss: 2.082471470038096

Epoch: 5| Step: 2
Training loss: 0.31770241260528564
Validation loss: 2.1292874018351235

Epoch: 5| Step: 3
Training loss: 0.27013126015663147
Validation loss: 2.07766259709994

Epoch: 5| Step: 4
Training loss: 0.33677995204925537
Validation loss: 2.0814527372519174

Epoch: 5| Step: 5
Training loss: 0.4407663345336914
Validation loss: 2.078605348865191

Epoch: 5| Step: 6
Training loss: 0.7086539268493652
Validation loss: 2.0732203871011734

Epoch: 5| Step: 7
Training loss: 0.3748630881309509
Validation loss: 2.0842221875985465

Epoch: 5| Step: 8
Training loss: 0.2675364315509796
Validation loss: 2.0410749167203903

Epoch: 5| Step: 9
Training loss: 0.5381419062614441
Validation loss: 2.066504329442978

Epoch: 5| Step: 10
Training loss: 0.670333743095398
Validation loss: 2.0858722080787024

Epoch: 5| Step: 11
Training loss: 0.12992796301841736
Validation loss: 2.062570189436277

Epoch: 420| Step: 0
Training loss: 0.37936562299728394
Validation loss: 2.118513524532318

Epoch: 5| Step: 1
Training loss: 0.45389240980148315
Validation loss: 2.0490598479906716

Epoch: 5| Step: 2
Training loss: 0.27819696068763733
Validation loss: 2.0711324910322824

Epoch: 5| Step: 3
Training loss: 0.5736037492752075
Validation loss: 2.060463160276413

Epoch: 5| Step: 4
Training loss: 0.28461959958076477
Validation loss: 2.0345653295516968

Epoch: 5| Step: 5
Training loss: 0.27812162041664124
Validation loss: 2.0777503003676734

Epoch: 5| Step: 6
Training loss: 0.3366393446922302
Validation loss: 2.0322945415973663

Epoch: 5| Step: 7
Training loss: 0.18836864829063416
Validation loss: 2.0251673758029938

Epoch: 5| Step: 8
Training loss: 0.4285338819026947
Validation loss: 2.0746244192123413

Epoch: 5| Step: 9
Training loss: 0.30754002928733826
Validation loss: 2.063778435190519

Epoch: 5| Step: 10
Training loss: 0.7428420782089233
Validation loss: 2.067120482524236

Epoch: 5| Step: 11
Training loss: 0.4138641655445099
Validation loss: 2.085121512413025

Epoch: 421| Step: 0
Training loss: 0.4095255434513092
Validation loss: 2.1223958482344947

Epoch: 5| Step: 1
Training loss: 0.5979576706886292
Validation loss: 2.062128628293673

Epoch: 5| Step: 2
Training loss: 0.619825541973114
Validation loss: 2.0723430663347244

Epoch: 5| Step: 3
Training loss: 0.17581132054328918
Validation loss: 2.0595283955335617

Epoch: 5| Step: 4
Training loss: 0.34944337606430054
Validation loss: 2.097770939270655

Epoch: 5| Step: 5
Training loss: 0.3538098633289337
Validation loss: 2.0667517483234406

Epoch: 5| Step: 6
Training loss: 0.21841582655906677
Validation loss: 2.0741879592339196

Epoch: 5| Step: 7
Training loss: 0.31148475408554077
Validation loss: 2.0706500013669333

Epoch: 5| Step: 8
Training loss: 0.25142160058021545
Validation loss: 2.068095808227857

Epoch: 5| Step: 9
Training loss: 0.5976983308792114
Validation loss: 2.0641356656948724

Epoch: 5| Step: 10
Training loss: 0.37459322810173035
Validation loss: 2.1068147818247476

Epoch: 5| Step: 11
Training loss: 0.3144962787628174
Validation loss: 2.1031859318415322

Epoch: 422| Step: 0
Training loss: 0.39249199628829956
Validation loss: 2.065645625193914

Epoch: 5| Step: 1
Training loss: 0.47262874245643616
Validation loss: 2.048405716816584

Epoch: 5| Step: 2
Training loss: 0.20480990409851074
Validation loss: 2.0267929385105767

Epoch: 5| Step: 3
Training loss: 0.553400993347168
Validation loss: 2.0818220476309457

Epoch: 5| Step: 4
Training loss: 0.33165356516838074
Validation loss: 2.0483205070098243

Epoch: 5| Step: 5
Training loss: 0.37547773122787476
Validation loss: 2.070479397972425

Epoch: 5| Step: 6
Training loss: 0.5060838460922241
Validation loss: 2.039696221550306

Epoch: 5| Step: 7
Training loss: 0.37964385747909546
Validation loss: 2.06756828725338

Epoch: 5| Step: 8
Training loss: 0.47165989875793457
Validation loss: 2.10422890384992

Epoch: 5| Step: 9
Training loss: 0.5239599943161011
Validation loss: 2.0832462112108865

Epoch: 5| Step: 10
Training loss: 0.4015352129936218
Validation loss: 2.079821452498436

Epoch: 5| Step: 11
Training loss: 0.6661417484283447
Validation loss: 2.1305479307969413

Epoch: 423| Step: 0
Training loss: 0.35890311002731323
Validation loss: 2.096791153152784

Epoch: 5| Step: 1
Training loss: 0.17899847030639648
Validation loss: 2.0971560180187225

Epoch: 5| Step: 2
Training loss: 0.33545541763305664
Validation loss: 2.0837864379088082

Epoch: 5| Step: 3
Training loss: 0.3595616817474365
Validation loss: 2.0926209489504495

Epoch: 5| Step: 4
Training loss: 0.24914872646331787
Validation loss: 2.1116433988014855

Epoch: 5| Step: 5
Training loss: 0.4106535017490387
Validation loss: 2.096128652493159

Epoch: 5| Step: 6
Training loss: 0.6765388250350952
Validation loss: 2.1203280091285706

Epoch: 5| Step: 7
Training loss: 0.24678440392017365
Validation loss: 2.1004555424054465

Epoch: 5| Step: 8
Training loss: 0.461824506521225
Validation loss: 2.110358143846194

Epoch: 5| Step: 9
Training loss: 0.4643966257572174
Validation loss: 2.0886816481749215

Epoch: 5| Step: 10
Training loss: 0.4006858766078949
Validation loss: 2.1166614989439645

Epoch: 5| Step: 11
Training loss: 1.7410907745361328
Validation loss: 2.1040120323499045

Epoch: 424| Step: 0
Training loss: 0.4563075006008148
Validation loss: 2.1001800894737244

Epoch: 5| Step: 1
Training loss: 0.38174816966056824
Validation loss: 2.09603721400102

Epoch: 5| Step: 2
Training loss: 0.4470970034599304
Validation loss: 2.1132402469714484

Epoch: 5| Step: 3
Training loss: 0.30498871207237244
Validation loss: 2.120312422513962

Epoch: 5| Step: 4
Training loss: 0.35042962431907654
Validation loss: 2.083840196331342

Epoch: 5| Step: 5
Training loss: 0.7226971983909607
Validation loss: 2.0815480649471283

Epoch: 5| Step: 6
Training loss: 0.4734307825565338
Validation loss: 2.070673406124115

Epoch: 5| Step: 7
Training loss: 0.22216090559959412
Validation loss: 2.05083821217219

Epoch: 5| Step: 8
Training loss: 0.22418323159217834
Validation loss: 2.085448975364367

Epoch: 5| Step: 9
Training loss: 0.4117014408111572
Validation loss: 2.1137676586707435

Epoch: 5| Step: 10
Training loss: 0.2395544946193695
Validation loss: 2.0518883913755417

Epoch: 5| Step: 11
Training loss: 1.6249418258666992
Validation loss: 2.089981993039449

Epoch: 425| Step: 0
Training loss: 0.27149122953414917
Validation loss: 2.070309887329737

Epoch: 5| Step: 1
Training loss: 0.46362385153770447
Validation loss: 2.0841735949118934

Epoch: 5| Step: 2
Training loss: 0.9499900937080383
Validation loss: 2.085637092590332

Epoch: 5| Step: 3
Training loss: 0.19485893845558167
Validation loss: 2.1198999881744385

Epoch: 5| Step: 4
Training loss: 0.2966260313987732
Validation loss: 2.051011552413305

Epoch: 5| Step: 5
Training loss: 0.32648223638534546
Validation loss: 2.0496425131956735

Epoch: 5| Step: 6
Training loss: 0.4214911460876465
Validation loss: 2.0849373241265616

Epoch: 5| Step: 7
Training loss: 0.23140576481819153
Validation loss: 2.083026255170504

Epoch: 5| Step: 8
Training loss: 0.3137475848197937
Validation loss: 2.0345783481995263

Epoch: 5| Step: 9
Training loss: 0.5240241289138794
Validation loss: 2.1126836985349655

Epoch: 5| Step: 10
Training loss: 0.32194775342941284
Validation loss: 2.0423721025387445

Epoch: 5| Step: 11
Training loss: 0.19061875343322754
Validation loss: 2.1177536696195602

Epoch: 426| Step: 0
Training loss: 0.33962541818618774
Validation loss: 2.083419625957807

Epoch: 5| Step: 1
Training loss: 0.19596567749977112
Validation loss: 2.0407483180363974

Epoch: 5| Step: 2
Training loss: 0.3331725001335144
Validation loss: 2.078355794151624

Epoch: 5| Step: 3
Training loss: 0.4903951585292816
Validation loss: 2.061835457881292

Epoch: 5| Step: 4
Training loss: 0.49840623140335083
Validation loss: 2.093668982386589

Epoch: 5| Step: 5
Training loss: 0.6952295303344727
Validation loss: 2.069188808401426

Epoch: 5| Step: 6
Training loss: 0.36762383580207825
Validation loss: 2.0626345028479895

Epoch: 5| Step: 7
Training loss: 0.2720498740673065
Validation loss: 2.049086774388949

Epoch: 5| Step: 8
Training loss: 0.5346935987472534
Validation loss: 2.075317377845446

Epoch: 5| Step: 9
Training loss: 0.4048713147640228
Validation loss: 2.0664921204249063

Epoch: 5| Step: 10
Training loss: 0.2699640095233917
Validation loss: 2.0233879884084067

Epoch: 5| Step: 11
Training loss: 0.965006947517395
Validation loss: 2.052657117446264

Epoch: 427| Step: 0
Training loss: 0.30955639481544495
Validation loss: 2.0755085150400796

Epoch: 5| Step: 1
Training loss: 0.6032745838165283
Validation loss: 2.058052490154902

Epoch: 5| Step: 2
Training loss: 0.43595632910728455
Validation loss: 2.0715607603391013

Epoch: 5| Step: 3
Training loss: 0.48617133498191833
Validation loss: 2.0392754723628364

Epoch: 5| Step: 4
Training loss: 0.8336634635925293
Validation loss: 2.07305775086085

Epoch: 5| Step: 5
Training loss: 0.26972001791000366
Validation loss: 2.120609531799952

Epoch: 5| Step: 6
Training loss: 0.46382784843444824
Validation loss: 2.028898134827614

Epoch: 5| Step: 7
Training loss: 0.25774261355400085
Validation loss: 2.031844640771548

Epoch: 5| Step: 8
Training loss: 0.18288013339042664
Validation loss: 2.0685870001713433

Epoch: 5| Step: 9
Training loss: 0.2816813588142395
Validation loss: 2.0923311163981757

Epoch: 5| Step: 10
Training loss: 0.3690969944000244
Validation loss: 2.074200908342997

Epoch: 5| Step: 11
Training loss: 0.21900510787963867
Validation loss: 2.0224453608194985

Epoch: 428| Step: 0
Training loss: 0.2990022301673889
Validation loss: 2.0866268227497735

Epoch: 5| Step: 1
Training loss: 0.679435670375824
Validation loss: 2.0709202041228614

Epoch: 5| Step: 2
Training loss: 0.43033942580223083
Validation loss: 2.090227166811625

Epoch: 5| Step: 3
Training loss: 0.2318251132965088
Validation loss: 2.06694067021211

Epoch: 5| Step: 4
Training loss: 0.37373408675193787
Validation loss: 2.0834045807520547

Epoch: 5| Step: 5
Training loss: 0.42561739683151245
Validation loss: 2.13489938278993

Epoch: 5| Step: 6
Training loss: 0.6394599676132202
Validation loss: 2.1179391145706177

Epoch: 5| Step: 7
Training loss: 0.2034425288438797
Validation loss: 2.084428310394287

Epoch: 5| Step: 8
Training loss: 0.47731536626815796
Validation loss: 2.112917428215345

Epoch: 5| Step: 9
Training loss: 0.256631076335907
Validation loss: 2.1032795955737433

Epoch: 5| Step: 10
Training loss: 0.4152325987815857
Validation loss: 2.096166580915451

Epoch: 5| Step: 11
Training loss: 0.48908084630966187
Validation loss: 2.0745592564344406

Epoch: 429| Step: 0
Training loss: 0.49600300192832947
Validation loss: 2.097025399406751

Epoch: 5| Step: 1
Training loss: 0.21603670716285706
Validation loss: 2.100949694712957

Epoch: 5| Step: 2
Training loss: 0.4294279217720032
Validation loss: 2.0639616499344506

Epoch: 5| Step: 3
Training loss: 0.699001133441925
Validation loss: 2.0809651960929236

Epoch: 5| Step: 4
Training loss: 0.38851624727249146
Validation loss: 2.0617196957270303

Epoch: 5| Step: 5
Training loss: 0.3020959198474884
Validation loss: 2.105314791202545

Epoch: 5| Step: 6
Training loss: 0.31199198961257935
Validation loss: 2.1121549556652703

Epoch: 5| Step: 7
Training loss: 0.3698906898498535
Validation loss: 2.085929016272227

Epoch: 5| Step: 8
Training loss: 0.7231347560882568
Validation loss: 2.143976613879204

Epoch: 5| Step: 9
Training loss: 0.26858898997306824
Validation loss: 2.1187011500199637

Epoch: 5| Step: 10
Training loss: 0.24040111899375916
Validation loss: 2.1045252978801727

Epoch: 5| Step: 11
Training loss: 0.05704629421234131
Validation loss: 2.0959203441937766

Epoch: 430| Step: 0
Training loss: 0.8537898063659668
Validation loss: 2.129669497410456

Epoch: 5| Step: 1
Training loss: 0.32238566875457764
Validation loss: 2.127003490924835

Epoch: 5| Step: 2
Training loss: 0.3413752615451813
Validation loss: 2.0805510779221854

Epoch: 5| Step: 3
Training loss: 0.5146228671073914
Validation loss: 2.0913648307323456

Epoch: 5| Step: 4
Training loss: 0.27247557044029236
Validation loss: 2.119459996620814

Epoch: 5| Step: 5
Training loss: 0.3409877419471741
Validation loss: 2.1032298107941947

Epoch: 5| Step: 6
Training loss: 0.3216319978237152
Validation loss: 2.0785838464895883

Epoch: 5| Step: 7
Training loss: 0.26190754771232605
Validation loss: 2.1438324401775994

Epoch: 5| Step: 8
Training loss: 0.26960521936416626
Validation loss: 2.0915471961100898

Epoch: 5| Step: 9
Training loss: 0.7252187132835388
Validation loss: 2.054935097694397

Epoch: 5| Step: 10
Training loss: 0.28395020961761475
Validation loss: 2.112290491660436

Epoch: 5| Step: 11
Training loss: 0.14006656408309937
Validation loss: 2.073075304428736

Epoch: 431| Step: 0
Training loss: 0.19305172562599182
Validation loss: 2.0970390886068344

Epoch: 5| Step: 1
Training loss: 0.35893407464027405
Validation loss: 2.0988224148750305

Epoch: 5| Step: 2
Training loss: 0.43094682693481445
Validation loss: 2.1023105134566626

Epoch: 5| Step: 3
Training loss: 0.42052268981933594
Validation loss: 2.064728875954946

Epoch: 5| Step: 4
Training loss: 0.36794087290763855
Validation loss: 2.082589308420817

Epoch: 5| Step: 5
Training loss: 0.40317973494529724
Validation loss: 2.1049192398786545

Epoch: 5| Step: 6
Training loss: 0.7005992531776428
Validation loss: 2.109404439727465

Epoch: 5| Step: 7
Training loss: 0.41433924436569214
Validation loss: 2.0743899047374725

Epoch: 5| Step: 8
Training loss: 0.39189377427101135
Validation loss: 2.083922505378723

Epoch: 5| Step: 9
Training loss: 0.5602343678474426
Validation loss: 2.080349495013555

Epoch: 5| Step: 10
Training loss: 0.39879244565963745
Validation loss: 2.0899812380472818

Epoch: 5| Step: 11
Training loss: 0.28569769859313965
Validation loss: 2.0911395947138467

Epoch: 432| Step: 0
Training loss: 0.24921107292175293
Validation loss: 2.044904733697573

Epoch: 5| Step: 1
Training loss: 0.348087877035141
Validation loss: 2.0507740328709283

Epoch: 5| Step: 2
Training loss: 0.42874106764793396
Validation loss: 2.061923344930013

Epoch: 5| Step: 3
Training loss: 0.44712528586387634
Validation loss: 2.0632857282956443

Epoch: 5| Step: 4
Training loss: 0.2907602787017822
Validation loss: 2.0624715934197106

Epoch: 5| Step: 5
Training loss: 0.5127639770507812
Validation loss: 2.141959701975187

Epoch: 5| Step: 6
Training loss: 0.38005656003952026
Validation loss: 2.074525440732638

Epoch: 5| Step: 7
Training loss: 0.26746851205825806
Validation loss: 2.0931549817323685

Epoch: 5| Step: 8
Training loss: 0.5227698087692261
Validation loss: 2.096078266700109

Epoch: 5| Step: 9
Training loss: 0.34353119134902954
Validation loss: 2.120888868967692

Epoch: 5| Step: 10
Training loss: 0.5048568844795227
Validation loss: 2.0709925293922424

Epoch: 5| Step: 11
Training loss: 0.3746081590652466
Validation loss: 2.084852486848831

Epoch: 433| Step: 0
Training loss: 0.19240252673625946
Validation loss: 2.107964833577474

Epoch: 5| Step: 1
Training loss: 0.2833382487297058
Validation loss: 2.067885602513949

Epoch: 5| Step: 2
Training loss: 0.541854977607727
Validation loss: 2.067204420765241

Epoch: 5| Step: 3
Training loss: 0.5369666814804077
Validation loss: 2.0965008238951364

Epoch: 5| Step: 4
Training loss: 0.3106449246406555
Validation loss: 2.0642166833082833

Epoch: 5| Step: 5
Training loss: 0.4461182653903961
Validation loss: 2.059690331419309

Epoch: 5| Step: 6
Training loss: 0.4409162402153015
Validation loss: 2.0920859575271606

Epoch: 5| Step: 7
Training loss: 0.40027865767478943
Validation loss: 2.147616778810819

Epoch: 5| Step: 8
Training loss: 0.36180999875068665
Validation loss: 2.109330783287684

Epoch: 5| Step: 9
Training loss: 0.647209107875824
Validation loss: 2.0960715860128403

Epoch: 5| Step: 10
Training loss: 0.3820672929286957
Validation loss: 2.115662266810735

Epoch: 5| Step: 11
Training loss: 0.08962869644165039
Validation loss: 2.0966781079769135

Epoch: 434| Step: 0
Training loss: 0.31012052297592163
Validation loss: 2.1061695963144302

Epoch: 5| Step: 1
Training loss: 0.39120179414749146
Validation loss: 2.079281667868296

Epoch: 5| Step: 2
Training loss: 0.6145763397216797
Validation loss: 2.0726934671401978

Epoch: 5| Step: 3
Training loss: 0.44290581345558167
Validation loss: 2.0920717070500054

Epoch: 5| Step: 4
Training loss: 0.34927186369895935
Validation loss: 2.1194504847129187

Epoch: 5| Step: 5
Training loss: 0.5589975714683533
Validation loss: 2.102339153488477

Epoch: 5| Step: 6
Training loss: 0.23069651424884796
Validation loss: 2.08233713110288

Epoch: 5| Step: 7
Training loss: 0.5512919425964355
Validation loss: 2.120795726776123

Epoch: 5| Step: 8
Training loss: 0.5072098970413208
Validation loss: 2.0867747366428375

Epoch: 5| Step: 9
Training loss: 0.22653928399085999
Validation loss: 2.102403481801351

Epoch: 5| Step: 10
Training loss: 0.26168492436408997
Validation loss: 2.0894690603017807

Epoch: 5| Step: 11
Training loss: 0.11084109544754028
Validation loss: 2.0878397474686303

Epoch: 435| Step: 0
Training loss: 0.35994821786880493
Validation loss: 2.085080941518148

Epoch: 5| Step: 1
Training loss: 0.20135395228862762
Validation loss: 2.0758428275585175

Epoch: 5| Step: 2
Training loss: 0.5279129147529602
Validation loss: 2.087608555952708

Epoch: 5| Step: 3
Training loss: 0.5254901051521301
Validation loss: 2.070856422185898

Epoch: 5| Step: 4
Training loss: 0.21327777206897736
Validation loss: 2.0759788503249488

Epoch: 5| Step: 5
Training loss: 0.24067659676074982
Validation loss: 2.099110335111618

Epoch: 5| Step: 6
Training loss: 0.571405827999115
Validation loss: 2.078009992837906

Epoch: 5| Step: 7
Training loss: 0.24230749905109406
Validation loss: 2.1069504419962564

Epoch: 5| Step: 8
Training loss: 0.6605484485626221
Validation loss: 2.06584769487381

Epoch: 5| Step: 9
Training loss: 0.25155729055404663
Validation loss: 2.083627372980118

Epoch: 5| Step: 10
Training loss: 0.3761635720729828
Validation loss: 2.068710833787918

Epoch: 5| Step: 11
Training loss: 0.48610639572143555
Validation loss: 2.0791062961022058

Epoch: 436| Step: 0
Training loss: 0.3948555886745453
Validation loss: 2.106659988562266

Epoch: 5| Step: 1
Training loss: 0.40391650795936584
Validation loss: 2.115102529525757

Epoch: 5| Step: 2
Training loss: 0.2771924138069153
Validation loss: 2.120129411419233

Epoch: 5| Step: 3
Training loss: 0.3490779995918274
Validation loss: 2.113972693681717

Epoch: 5| Step: 4
Training loss: 0.3239261209964752
Validation loss: 2.084537779291471

Epoch: 5| Step: 5
Training loss: 0.7796548008918762
Validation loss: 2.096719205379486

Epoch: 5| Step: 6
Training loss: 0.22046196460723877
Validation loss: 2.0890611509482064

Epoch: 5| Step: 7
Training loss: 0.21503642201423645
Validation loss: 2.101347183187803

Epoch: 5| Step: 8
Training loss: 0.6028602719306946
Validation loss: 2.0432166953881583

Epoch: 5| Step: 9
Training loss: 0.3797453045845032
Validation loss: 2.0575342228015265

Epoch: 5| Step: 10
Training loss: 0.25459209084510803
Validation loss: 2.0839492082595825

Epoch: 5| Step: 11
Training loss: 0.6828340291976929
Validation loss: 2.0934328784545264

Epoch: 437| Step: 0
Training loss: 0.2604750096797943
Validation loss: 2.121373623609543

Epoch: 5| Step: 1
Training loss: 0.7719511985778809
Validation loss: 2.0940053115288415

Epoch: 5| Step: 2
Training loss: 0.4529491066932678
Validation loss: 2.0909721354643502

Epoch: 5| Step: 3
Training loss: 0.5786442756652832
Validation loss: 2.108629440267881

Epoch: 5| Step: 4
Training loss: 0.3127520978450775
Validation loss: 2.0808496375878653

Epoch: 5| Step: 5
Training loss: 0.44543200731277466
Validation loss: 2.083247661590576

Epoch: 5| Step: 6
Training loss: 0.25283974409103394
Validation loss: 2.0689141104618707

Epoch: 5| Step: 7
Training loss: 0.48312243819236755
Validation loss: 2.0440820306539536

Epoch: 5| Step: 8
Training loss: 0.45066195726394653
Validation loss: 2.0816144744555154

Epoch: 5| Step: 9
Training loss: 0.3583804965019226
Validation loss: 2.0748306463162103

Epoch: 5| Step: 10
Training loss: 0.41990646719932556
Validation loss: 2.052375316619873

Epoch: 5| Step: 11
Training loss: 0.20659220218658447
Validation loss: 2.035906732082367

Epoch: 438| Step: 0
Training loss: 0.46916502714157104
Validation loss: 2.036045844356219

Epoch: 5| Step: 1
Training loss: 0.19213494658470154
Validation loss: 2.0748018324375153

Epoch: 5| Step: 2
Training loss: 0.5346832871437073
Validation loss: 2.0510228325923285

Epoch: 5| Step: 3
Training loss: 0.5848882794380188
Validation loss: 2.054081122080485

Epoch: 5| Step: 4
Training loss: 0.4049850404262543
Validation loss: 2.0837037712335587

Epoch: 5| Step: 5
Training loss: 0.39104729890823364
Validation loss: 2.0463175574938455

Epoch: 5| Step: 6
Training loss: 0.2660883963108063
Validation loss: 2.0406722128391266

Epoch: 5| Step: 7
Training loss: 0.3375803828239441
Validation loss: 2.0437518705924353

Epoch: 5| Step: 8
Training loss: 0.4236651062965393
Validation loss: 2.044487237930298

Epoch: 5| Step: 9
Training loss: 0.5154620409011841
Validation loss: 2.036244968573252

Epoch: 5| Step: 10
Training loss: 0.1816246062517166
Validation loss: 2.054408848285675

Epoch: 5| Step: 11
Training loss: 1.3940470218658447
Validation loss: 2.025913620988528

Epoch: 439| Step: 0
Training loss: 0.3434154987335205
Validation loss: 2.035551130771637

Epoch: 5| Step: 1
Training loss: 0.3228246569633484
Validation loss: 2.0675346553325653

Epoch: 5| Step: 2
Training loss: 0.26852211356163025
Validation loss: 2.0515488932530084

Epoch: 5| Step: 3
Training loss: 0.36099475622177124
Validation loss: 2.073277855912844

Epoch: 5| Step: 4
Training loss: 0.6001173257827759
Validation loss: 2.078891416390737

Epoch: 5| Step: 5
Training loss: 0.5752485394477844
Validation loss: 2.065670629342397

Epoch: 5| Step: 6
Training loss: 0.38100486993789673
Validation loss: 2.076727623740832

Epoch: 5| Step: 7
Training loss: 0.2645281255245209
Validation loss: 2.0457851688067117

Epoch: 5| Step: 8
Training loss: 0.5109063982963562
Validation loss: 2.060850446422895

Epoch: 5| Step: 9
Training loss: 0.19476532936096191
Validation loss: 2.027689998348554

Epoch: 5| Step: 10
Training loss: 0.4649471342563629
Validation loss: 2.0389992594718933

Epoch: 5| Step: 11
Training loss: 1.9910664558410645
Validation loss: 2.058583229780197

Epoch: 440| Step: 0
Training loss: 0.6113772392272949
Validation loss: 2.0938730289538703

Epoch: 5| Step: 1
Training loss: 0.43701180815696716
Validation loss: 2.069305956363678

Epoch: 5| Step: 2
Training loss: 0.37091004848480225
Validation loss: 2.084431747595469

Epoch: 5| Step: 3
Training loss: 0.4239291548728943
Validation loss: 2.064678132534027

Epoch: 5| Step: 4
Training loss: 0.5128428339958191
Validation loss: 2.1028360525767007

Epoch: 5| Step: 5
Training loss: 0.2527356445789337
Validation loss: 2.0581772277752557

Epoch: 5| Step: 6
Training loss: 0.5085551738739014
Validation loss: 2.0476134568452835

Epoch: 5| Step: 7
Training loss: 0.2894434928894043
Validation loss: 2.1274549464384713

Epoch: 5| Step: 8
Training loss: 0.3799683451652527
Validation loss: 2.0809137920538583

Epoch: 5| Step: 9
Training loss: 0.28161129355430603
Validation loss: 2.0995610604683557

Epoch: 5| Step: 10
Training loss: 0.2567767798900604
Validation loss: 2.1182973633209863

Epoch: 5| Step: 11
Training loss: 0.2818552255630493
Validation loss: 2.0702342639366784

Epoch: 441| Step: 0
Training loss: 0.3956073820590973
Validation loss: 2.095947722593943

Epoch: 5| Step: 1
Training loss: 0.29395633935928345
Validation loss: 2.122139180699984

Epoch: 5| Step: 2
Training loss: 0.23484988510608673
Validation loss: 2.101010416944822

Epoch: 5| Step: 3
Training loss: 0.39950981736183167
Validation loss: 2.0986245622237525

Epoch: 5| Step: 4
Training loss: 0.4278632700443268
Validation loss: 2.1002716223398843

Epoch: 5| Step: 5
Training loss: 0.2705383896827698
Validation loss: 2.099323878685633

Epoch: 5| Step: 6
Training loss: 0.7641280889511108
Validation loss: 2.120448336005211

Epoch: 5| Step: 7
Training loss: 0.4233720898628235
Validation loss: 2.09600460032622

Epoch: 5| Step: 8
Training loss: 0.3003581166267395
Validation loss: 2.0837455640236535

Epoch: 5| Step: 9
Training loss: 0.3557173013687134
Validation loss: 2.081633855899175

Epoch: 5| Step: 10
Training loss: 0.36667177081108093
Validation loss: 2.0797327210505805

Epoch: 5| Step: 11
Training loss: 0.5649698972702026
Validation loss: 2.0928733746210733

Epoch: 442| Step: 0
Training loss: 0.18142524361610413
Validation loss: 2.099241187175115

Epoch: 5| Step: 1
Training loss: 0.3321894705295563
Validation loss: 2.0673734496037164

Epoch: 5| Step: 2
Training loss: 0.48862481117248535
Validation loss: 2.0723217129707336

Epoch: 5| Step: 3
Training loss: 0.28237900137901306
Validation loss: 2.0661954979101815

Epoch: 5| Step: 4
Training loss: 0.5140607953071594
Validation loss: 2.098716080188751

Epoch: 5| Step: 5
Training loss: 0.495461642742157
Validation loss: 2.0674694577852883

Epoch: 5| Step: 6
Training loss: 0.21127235889434814
Validation loss: 2.107208490371704

Epoch: 5| Step: 7
Training loss: 0.242269366979599
Validation loss: 2.083635484178861

Epoch: 5| Step: 8
Training loss: 0.5017408132553101
Validation loss: 2.0803962498903275

Epoch: 5| Step: 9
Training loss: 0.5023881793022156
Validation loss: 2.042515734831492

Epoch: 5| Step: 10
Training loss: 0.3752833902835846
Validation loss: 2.0565260499715805

Epoch: 5| Step: 11
Training loss: 0.11871349811553955
Validation loss: 2.05827001730601

Epoch: 443| Step: 0
Training loss: 0.2579564154148102
Validation loss: 2.0465125838915506

Epoch: 5| Step: 1
Training loss: 0.7482465505599976
Validation loss: 2.066379338502884

Epoch: 5| Step: 2
Training loss: 0.5163794755935669
Validation loss: 2.0671648383140564

Epoch: 5| Step: 3
Training loss: 0.3991261422634125
Validation loss: 2.052700027823448

Epoch: 5| Step: 4
Training loss: 0.5486375689506531
Validation loss: 2.0563916067282357

Epoch: 5| Step: 5
Training loss: 0.34820836782455444
Validation loss: 2.081420843799909

Epoch: 5| Step: 6
Training loss: 0.5267326235771179
Validation loss: 2.1212218105793

Epoch: 5| Step: 7
Training loss: 0.4973629117012024
Validation loss: 2.1169291734695435

Epoch: 5| Step: 8
Training loss: 0.47076621651649475
Validation loss: 2.0962025225162506

Epoch: 5| Step: 9
Training loss: 0.21683891117572784
Validation loss: 2.1219304402669272

Epoch: 5| Step: 10
Training loss: 0.4938168525695801
Validation loss: 2.08475253979365

Epoch: 5| Step: 11
Training loss: 0.42104244232177734
Validation loss: 2.0598550140857697

Epoch: 444| Step: 0
Training loss: 0.21133379638195038
Validation loss: 2.0723831405242286

Epoch: 5| Step: 1
Training loss: 0.4012852609157562
Validation loss: 2.0501809418201447

Epoch: 5| Step: 2
Training loss: 0.30248942971229553
Validation loss: 2.0765611827373505

Epoch: 5| Step: 3
Training loss: 0.6474525332450867
Validation loss: 2.031834363937378

Epoch: 5| Step: 4
Training loss: 0.590657114982605
Validation loss: 2.076184252897898

Epoch: 5| Step: 5
Training loss: 0.4051504135131836
Validation loss: 2.074196606874466

Epoch: 5| Step: 6
Training loss: 0.5872780680656433
Validation loss: 2.100721557935079

Epoch: 5| Step: 7
Training loss: 0.3946734070777893
Validation loss: 2.0740254620711007

Epoch: 5| Step: 8
Training loss: 0.4766225814819336
Validation loss: 2.0835908750693

Epoch: 5| Step: 9
Training loss: 0.3980257213115692
Validation loss: 2.0593821853399277

Epoch: 5| Step: 10
Training loss: 0.30848705768585205
Validation loss: 2.052976364890734

Epoch: 5| Step: 11
Training loss: 0.19695135951042175
Validation loss: 2.1045150806506476

Epoch: 445| Step: 0
Training loss: 0.30916324257850647
Validation loss: 2.0618183563152948

Epoch: 5| Step: 1
Training loss: 0.4795278012752533
Validation loss: 2.060392906268438

Epoch: 5| Step: 2
Training loss: 0.3905979096889496
Validation loss: 2.083805873990059

Epoch: 5| Step: 3
Training loss: 0.6077266931533813
Validation loss: 2.0800800224145255

Epoch: 5| Step: 4
Training loss: 0.21341712772846222
Validation loss: 2.0517766724030175

Epoch: 5| Step: 5
Training loss: 0.48536473512649536
Validation loss: 2.0810380429029465

Epoch: 5| Step: 6
Training loss: 0.681773841381073
Validation loss: 2.1117327362298965

Epoch: 5| Step: 7
Training loss: 0.3303932547569275
Validation loss: 2.0699660778045654

Epoch: 5| Step: 8
Training loss: 0.38841482996940613
Validation loss: 2.090140933791796

Epoch: 5| Step: 9
Training loss: 0.5454460382461548
Validation loss: 2.0777456363042197

Epoch: 5| Step: 10
Training loss: 0.20922470092773438
Validation loss: 2.0950818608204522

Epoch: 5| Step: 11
Training loss: 0.4775490164756775
Validation loss: 2.0698331197102866

Epoch: 446| Step: 0
Training loss: 0.5852862596511841
Validation loss: 2.0388640761375427

Epoch: 5| Step: 1
Training loss: 0.28199416399002075
Validation loss: 2.0409102191527686

Epoch: 5| Step: 2
Training loss: 0.5495821237564087
Validation loss: 2.0544505367676416

Epoch: 5| Step: 3
Training loss: 0.31090807914733887
Validation loss: 2.1021638065576553

Epoch: 5| Step: 4
Training loss: 0.6678741574287415
Validation loss: 2.0686102708180747

Epoch: 5| Step: 5
Training loss: 0.4441479742527008
Validation loss: 2.0579072535037994

Epoch: 5| Step: 6
Training loss: 0.21826517581939697
Validation loss: 2.08445676167806

Epoch: 5| Step: 7
Training loss: 0.301801860332489
Validation loss: 2.0836007545391717

Epoch: 5| Step: 8
Training loss: 0.36887326836586
Validation loss: 2.1198839445908866

Epoch: 5| Step: 9
Training loss: 0.27862516045570374
Validation loss: 2.0885317077239356

Epoch: 5| Step: 10
Training loss: 0.5779594779014587
Validation loss: 2.126586596171061

Epoch: 5| Step: 11
Training loss: 0.31435203552246094
Validation loss: 2.122697134812673

Epoch: 447| Step: 0
Training loss: 0.21902170777320862
Validation loss: 2.1187296907107034

Epoch: 5| Step: 1
Training loss: 0.27574390172958374
Validation loss: 2.128933861851692

Epoch: 5| Step: 2
Training loss: 0.5456503629684448
Validation loss: 2.075533797343572

Epoch: 5| Step: 3
Training loss: 0.3033229410648346
Validation loss: 2.107890233397484

Epoch: 5| Step: 4
Training loss: 0.2556169033050537
Validation loss: 2.0842647552490234

Epoch: 5| Step: 5
Training loss: 0.3458835184574127
Validation loss: 2.0749797970056534

Epoch: 5| Step: 6
Training loss: 0.5083070397377014
Validation loss: 2.0951780329147973

Epoch: 5| Step: 7
Training loss: 0.5403041243553162
Validation loss: 2.104947800437609

Epoch: 5| Step: 8
Training loss: 0.3300088047981262
Validation loss: 2.0329575538635254

Epoch: 5| Step: 9
Training loss: 0.6852677464485168
Validation loss: 2.0877733379602432

Epoch: 5| Step: 10
Training loss: 0.2829877734184265
Validation loss: 2.1211192905902863

Epoch: 5| Step: 11
Training loss: 0.14137864112854004
Validation loss: 2.0574122965335846

Epoch: 448| Step: 0
Training loss: 0.14040443301200867
Validation loss: 2.0774909953276315

Epoch: 5| Step: 1
Training loss: 0.46753424406051636
Validation loss: 2.0905509144067764

Epoch: 5| Step: 2
Training loss: 0.9642707705497742
Validation loss: 2.0689053535461426

Epoch: 5| Step: 3
Training loss: 0.2576872706413269
Validation loss: 2.0465512573719025

Epoch: 5| Step: 4
Training loss: 0.260587602853775
Validation loss: 2.0607816725969315

Epoch: 5| Step: 5
Training loss: 0.20567551255226135
Validation loss: 2.0742070426543555

Epoch: 5| Step: 6
Training loss: 0.3090320825576782
Validation loss: 2.084633246064186

Epoch: 5| Step: 7
Training loss: 0.22434651851654053
Validation loss: 2.0584744811058044

Epoch: 5| Step: 8
Training loss: 0.3632572293281555
Validation loss: 2.058681145310402

Epoch: 5| Step: 9
Training loss: 0.3530189096927643
Validation loss: 2.0809288819630942

Epoch: 5| Step: 10
Training loss: 0.395890474319458
Validation loss: 2.0574539502461753

Epoch: 5| Step: 11
Training loss: 0.8509327173233032
Validation loss: 2.0460358361403146

Epoch: 449| Step: 0
Training loss: 0.4585951864719391
Validation loss: 2.0720664213101068

Epoch: 5| Step: 1
Training loss: 0.27885714173316956
Validation loss: 2.0882203529278436

Epoch: 5| Step: 2
Training loss: 0.44462624192237854
Validation loss: 2.0877006401618323

Epoch: 5| Step: 3
Training loss: 0.4934961199760437
Validation loss: 2.100207805633545

Epoch: 5| Step: 4
Training loss: 0.6316121816635132
Validation loss: 2.10910173257192

Epoch: 5| Step: 5
Training loss: 0.3750898838043213
Validation loss: 2.067531476418177

Epoch: 5| Step: 6
Training loss: 0.5197187662124634
Validation loss: 2.076195811231931

Epoch: 5| Step: 7
Training loss: 0.25714200735092163
Validation loss: 2.089425345261892

Epoch: 5| Step: 8
Training loss: 0.2198292762041092
Validation loss: 2.092630053559939

Epoch: 5| Step: 9
Training loss: 0.4895362854003906
Validation loss: 2.045244331161181

Epoch: 5| Step: 10
Training loss: 0.2720182538032532
Validation loss: 2.1000726222991943

Epoch: 5| Step: 11
Training loss: 0.16189095377922058
Validation loss: 2.0884149769941964

Epoch: 450| Step: 0
Training loss: 0.2663406431674957
Validation loss: 2.0574653247992196

Epoch: 5| Step: 1
Training loss: 0.3745298683643341
Validation loss: 2.0983676463365555

Epoch: 5| Step: 2
Training loss: 0.1871843785047531
Validation loss: 2.0652586023012796

Epoch: 5| Step: 3
Training loss: 0.2979219853878021
Validation loss: 2.0846268385648727

Epoch: 5| Step: 4
Training loss: 0.28476351499557495
Validation loss: 2.05967415869236

Epoch: 5| Step: 5
Training loss: 0.6202061176300049
Validation loss: 2.022065967321396

Epoch: 5| Step: 6
Training loss: 0.36013808846473694
Validation loss: 2.04114276667436

Epoch: 5| Step: 7
Training loss: 0.41967830061912537
Validation loss: 2.0457175771395364

Epoch: 5| Step: 8
Training loss: 0.3175455331802368
Validation loss: 2.0635360131661096

Epoch: 5| Step: 9
Training loss: 0.5559108853340149
Validation loss: 2.0825246075789132

Epoch: 5| Step: 10
Training loss: 0.3515264391899109
Validation loss: 2.0474971334139505

Epoch: 5| Step: 11
Training loss: 0.9006475806236267
Validation loss: 2.075026348233223

Epoch: 451| Step: 0
Training loss: 0.19247718155384064
Validation loss: 2.089761475721995

Epoch: 5| Step: 1
Training loss: 0.5049737691879272
Validation loss: 2.1076573034127555

Epoch: 5| Step: 2
Training loss: 0.31252992153167725
Validation loss: 2.08353428542614

Epoch: 5| Step: 3
Training loss: 0.4890820384025574
Validation loss: 2.0608278711636863

Epoch: 5| Step: 4
Training loss: 0.46766385436058044
Validation loss: 2.0777502357959747

Epoch: 5| Step: 5
Training loss: 0.4244472086429596
Validation loss: 2.0760615170001984

Epoch: 5| Step: 6
Training loss: 0.3488079905509949
Validation loss: 2.0774073203404746

Epoch: 5| Step: 7
Training loss: 0.35785847902297974
Validation loss: 2.1114308834075928

Epoch: 5| Step: 8
Training loss: 0.23313847184181213
Validation loss: 2.0728846341371536

Epoch: 5| Step: 9
Training loss: 0.5329564213752747
Validation loss: 2.0456596414248147

Epoch: 5| Step: 10
Training loss: 0.19374015927314758
Validation loss: 2.060535748799642

Epoch: 5| Step: 11
Training loss: 0.6058502197265625
Validation loss: 2.109911262989044

Epoch: 452| Step: 0
Training loss: 0.335874080657959
Validation loss: 2.1058109949032464

Epoch: 5| Step: 1
Training loss: 0.3207767903804779
Validation loss: 2.118180066347122

Epoch: 5| Step: 2
Training loss: 0.4596725404262543
Validation loss: 2.082597553730011

Epoch: 5| Step: 3
Training loss: 0.19096431136131287
Validation loss: 2.088991085688273

Epoch: 5| Step: 4
Training loss: 0.8047651052474976
Validation loss: 2.0731135507424674

Epoch: 5| Step: 5
Training loss: 0.3064095377922058
Validation loss: 2.1079463561375937

Epoch: 5| Step: 6
Training loss: 0.3750368356704712
Validation loss: 2.1124668767054877

Epoch: 5| Step: 7
Training loss: 0.33852654695510864
Validation loss: 2.071812649567922

Epoch: 5| Step: 8
Training loss: 0.32492202520370483
Validation loss: 2.0438255071640015

Epoch: 5| Step: 9
Training loss: 0.23416773974895477
Validation loss: 2.087343692779541

Epoch: 5| Step: 10
Training loss: 0.4087793231010437
Validation loss: 2.110325256983439

Epoch: 5| Step: 11
Training loss: 0.23384559154510498
Validation loss: 2.086492126186689

Epoch: 453| Step: 0
Training loss: 0.19536656141281128
Validation loss: 2.0867733359336853

Epoch: 5| Step: 1
Training loss: 0.3935851752758026
Validation loss: 2.110561420520147

Epoch: 5| Step: 2
Training loss: 0.2958442270755768
Validation loss: 2.111182451248169

Epoch: 5| Step: 3
Training loss: 0.19787366688251495
Validation loss: 2.0985566526651382

Epoch: 5| Step: 4
Training loss: 0.32024723291397095
Validation loss: 2.0685359239578247

Epoch: 5| Step: 5
Training loss: 0.33049044013023376
Validation loss: 2.09759513537089

Epoch: 5| Step: 6
Training loss: 0.30254966020584106
Validation loss: 2.049403672417005

Epoch: 5| Step: 7
Training loss: 0.5072068572044373
Validation loss: 2.116173048814138

Epoch: 5| Step: 8
Training loss: 0.3753342926502228
Validation loss: 2.091247464219729

Epoch: 5| Step: 9
Training loss: 0.3713347911834717
Validation loss: 2.076267013947169

Epoch: 5| Step: 10
Training loss: 0.7699958086013794
Validation loss: 2.0723584095637

Epoch: 5| Step: 11
Training loss: 0.07593387365341187
Validation loss: 2.0549330512682595

Epoch: 454| Step: 0
Training loss: 0.537360668182373
Validation loss: 2.071946144104004

Epoch: 5| Step: 1
Training loss: 0.7779232263565063
Validation loss: 2.0931716561317444

Epoch: 5| Step: 2
Training loss: 0.20663242042064667
Validation loss: 2.1142484843730927

Epoch: 5| Step: 3
Training loss: 0.347878634929657
Validation loss: 2.0639163901408515

Epoch: 5| Step: 4
Training loss: 0.38594764471054077
Validation loss: 2.0609307239452996

Epoch: 5| Step: 5
Training loss: 0.29883599281311035
Validation loss: 2.092566639184952

Epoch: 5| Step: 6
Training loss: 0.42815476655960083
Validation loss: 2.083784674604734

Epoch: 5| Step: 7
Training loss: 0.20758672058582306
Validation loss: 2.115086793899536

Epoch: 5| Step: 8
Training loss: 0.44026169180870056
Validation loss: 2.0548151483138404

Epoch: 5| Step: 9
Training loss: 0.34986528754234314
Validation loss: 2.1079234381516776

Epoch: 5| Step: 10
Training loss: 0.5233507752418518
Validation loss: 2.092081223924955

Epoch: 5| Step: 11
Training loss: 0.2149541676044464
Validation loss: 2.0755940030018487

Epoch: 455| Step: 0
Training loss: 0.3689238429069519
Validation loss: 2.0887221296628318

Epoch: 5| Step: 1
Training loss: 0.3267894387245178
Validation loss: 2.0943935910860696

Epoch: 5| Step: 2
Training loss: 0.2089812010526657
Validation loss: 2.0613210598627725

Epoch: 5| Step: 3
Training loss: 0.3958960175514221
Validation loss: 2.083661069472631

Epoch: 5| Step: 4
Training loss: 0.7335672974586487
Validation loss: 2.0684679547945657

Epoch: 5| Step: 5
Training loss: 0.38229280710220337
Validation loss: 2.057601441939672

Epoch: 5| Step: 6
Training loss: 0.28265509009361267
Validation loss: 2.087306241194407

Epoch: 5| Step: 7
Training loss: 0.4113397002220154
Validation loss: 2.126798093318939

Epoch: 5| Step: 8
Training loss: 0.34448039531707764
Validation loss: 2.0938724229733148

Epoch: 5| Step: 9
Training loss: 0.3858439028263092
Validation loss: 2.0903157542149224

Epoch: 5| Step: 10
Training loss: 0.46589499711990356
Validation loss: 2.09534128010273

Epoch: 5| Step: 11
Training loss: 0.23569631576538086
Validation loss: 2.06584270298481

Epoch: 456| Step: 0
Training loss: 0.32813745737075806
Validation loss: 2.114889547228813

Epoch: 5| Step: 1
Training loss: 0.430561363697052
Validation loss: 2.1009298463662467

Epoch: 5| Step: 2
Training loss: 0.7356155514717102
Validation loss: 2.0899932185808816

Epoch: 5| Step: 3
Training loss: 0.5371342897415161
Validation loss: 2.0847980280717215

Epoch: 5| Step: 4
Training loss: 0.5620765089988708
Validation loss: 2.0581715206305184

Epoch: 5| Step: 5
Training loss: 0.3533341884613037
Validation loss: 2.089099705219269

Epoch: 5| Step: 6
Training loss: 0.26210540533065796
Validation loss: 2.0796587516864142

Epoch: 5| Step: 7
Training loss: 0.435192346572876
Validation loss: 2.098007301489512

Epoch: 5| Step: 8
Training loss: 0.47872868180274963
Validation loss: 2.075773666302363

Epoch: 5| Step: 9
Training loss: 0.39884036779403687
Validation loss: 2.1218033730983734

Epoch: 5| Step: 10
Training loss: 0.2589125633239746
Validation loss: 2.1199716528256736

Epoch: 5| Step: 11
Training loss: 0.2357136607170105
Validation loss: 2.0962798992792764

Epoch: 457| Step: 0
Training loss: 0.5287554264068604
Validation loss: 2.1049246986707053

Epoch: 5| Step: 1
Training loss: 0.3396018445491791
Validation loss: 2.083389461040497

Epoch: 5| Step: 2
Training loss: 0.5679423809051514
Validation loss: 2.1033950050671897

Epoch: 5| Step: 3
Training loss: 0.3093736171722412
Validation loss: 2.0568342556556067

Epoch: 5| Step: 4
Training loss: 0.2834929823875427
Validation loss: 2.097865551710129

Epoch: 5| Step: 5
Training loss: 0.4053167700767517
Validation loss: 2.083020160595576

Epoch: 5| Step: 6
Training loss: 0.28044313192367554
Validation loss: 2.1017928421497345

Epoch: 5| Step: 7
Training loss: 0.34591418504714966
Validation loss: 2.096774806578954

Epoch: 5| Step: 8
Training loss: 0.4980739653110504
Validation loss: 2.0746637980143228

Epoch: 5| Step: 9
Training loss: 0.24326515197753906
Validation loss: 2.1301236897706985

Epoch: 5| Step: 10
Training loss: 0.226288840174675
Validation loss: 2.1140863994757333

Epoch: 5| Step: 11
Training loss: 0.2529239058494568
Validation loss: 2.0687355051438012

Epoch: 458| Step: 0
Training loss: 0.22410981357097626
Validation loss: 2.08310600121816

Epoch: 5| Step: 1
Training loss: 0.1671130657196045
Validation loss: 2.0921602497498193

Epoch: 5| Step: 2
Training loss: 0.32108792662620544
Validation loss: 2.1004176984230676

Epoch: 5| Step: 3
Training loss: 0.9602770805358887
Validation loss: 2.0963114549716315

Epoch: 5| Step: 4
Training loss: 0.2155396044254303
Validation loss: 2.0802236199378967

Epoch: 5| Step: 5
Training loss: 0.21915841102600098
Validation loss: 2.1182738542556763

Epoch: 5| Step: 6
Training loss: 0.4821246564388275
Validation loss: 2.0989112059275308

Epoch: 5| Step: 7
Training loss: 0.28129497170448303
Validation loss: 2.086245611310005

Epoch: 5| Step: 8
Training loss: 0.3750223219394684
Validation loss: 2.073322003086408

Epoch: 5| Step: 9
Training loss: 0.1663382351398468
Validation loss: 2.0913529843091965

Epoch: 5| Step: 10
Training loss: 0.4330076277256012
Validation loss: 2.1005822519461312

Epoch: 5| Step: 11
Training loss: 0.37351980805397034
Validation loss: 2.0723864088455834

Epoch: 459| Step: 0
Training loss: 0.40935689210891724
Validation loss: 2.0856302430232367

Epoch: 5| Step: 1
Training loss: 0.3479633331298828
Validation loss: 2.1170008728901544

Epoch: 5| Step: 2
Training loss: 0.3957178294658661
Validation loss: 2.095449924468994

Epoch: 5| Step: 3
Training loss: 0.26193568110466003
Validation loss: 2.1049513121445975

Epoch: 5| Step: 4
Training loss: 0.3249714970588684
Validation loss: 2.0838523705800376

Epoch: 5| Step: 5
Training loss: 0.13221454620361328
Validation loss: 2.101429561773936

Epoch: 5| Step: 6
Training loss: 0.39362531900405884
Validation loss: 2.0715903590122857

Epoch: 5| Step: 7
Training loss: 0.5571688413619995
Validation loss: 2.116967116792997

Epoch: 5| Step: 8
Training loss: 0.5755850076675415
Validation loss: 2.1180025339126587

Epoch: 5| Step: 9
Training loss: 0.4041154384613037
Validation loss: 2.0966841876506805

Epoch: 5| Step: 10
Training loss: 0.4391325116157532
Validation loss: 2.0894828935464225

Epoch: 5| Step: 11
Training loss: 0.10363973677158356
Validation loss: 2.1299078315496445

Epoch: 460| Step: 0
Training loss: 0.41101446747779846
Validation loss: 2.1253911703824997

Epoch: 5| Step: 1
Training loss: 0.5042846202850342
Validation loss: 2.142717863122622

Epoch: 5| Step: 2
Training loss: 0.5072288513183594
Validation loss: 2.084651157259941

Epoch: 5| Step: 3
Training loss: 0.5820749402046204
Validation loss: 2.0968085527420044

Epoch: 5| Step: 4
Training loss: 0.3802783191204071
Validation loss: 2.078307161728541

Epoch: 5| Step: 5
Training loss: 0.4570065438747406
Validation loss: 2.035218119621277

Epoch: 5| Step: 6
Training loss: 0.26873302459716797
Validation loss: 2.100169206658999

Epoch: 5| Step: 7
Training loss: 0.4247511923313141
Validation loss: 2.098596359292666

Epoch: 5| Step: 8
Training loss: 0.2922828793525696
Validation loss: 2.087433541814486

Epoch: 5| Step: 9
Training loss: 0.3349155783653259
Validation loss: 2.093194837371508

Epoch: 5| Step: 10
Training loss: 0.697080135345459
Validation loss: 2.0931898256142936

Epoch: 5| Step: 11
Training loss: 0.9480767250061035
Validation loss: 2.1116800953944526

Epoch: 461| Step: 0
Training loss: 0.20571760833263397
Validation loss: 2.0635507504145303

Epoch: 5| Step: 1
Training loss: 0.3853728175163269
Validation loss: 2.069236929217974

Epoch: 5| Step: 2
Training loss: 0.23234467208385468
Validation loss: 2.1013000508149466

Epoch: 5| Step: 3
Training loss: 0.3572489321231842
Validation loss: 2.0864956279595694

Epoch: 5| Step: 4
Training loss: 0.6197625398635864
Validation loss: 2.0797726263602576

Epoch: 5| Step: 5
Training loss: 0.3554457426071167
Validation loss: 2.095468670129776

Epoch: 5| Step: 6
Training loss: 0.6074118614196777
Validation loss: 2.0880102763573327

Epoch: 5| Step: 7
Training loss: 0.3378888964653015
Validation loss: 2.0697716971238456

Epoch: 5| Step: 8
Training loss: 0.285405695438385
Validation loss: 2.0896017054716745

Epoch: 5| Step: 9
Training loss: 0.12998536229133606
Validation loss: 2.0801208913326263

Epoch: 5| Step: 10
Training loss: 0.3208768963813782
Validation loss: 2.0778906693061194

Epoch: 5| Step: 11
Training loss: 0.8006901741027832
Validation loss: 2.1010279059410095

Epoch: 462| Step: 0
Training loss: 0.524087131023407
Validation loss: 2.110799729824066

Epoch: 5| Step: 1
Training loss: 0.3387402594089508
Validation loss: 2.1360698342323303

Epoch: 5| Step: 2
Training loss: 0.2523750066757202
Validation loss: 2.0984065234661102

Epoch: 5| Step: 3
Training loss: 0.45300596952438354
Validation loss: 2.144641011953354

Epoch: 5| Step: 4
Training loss: 0.21018052101135254
Validation loss: 2.111170142889023

Epoch: 5| Step: 5
Training loss: 0.41904574632644653
Validation loss: 2.1048398266235986

Epoch: 5| Step: 6
Training loss: 0.48488450050354004
Validation loss: 2.083726167678833

Epoch: 5| Step: 7
Training loss: 0.2763838469982147
Validation loss: 2.115827336907387

Epoch: 5| Step: 8
Training loss: 0.375997930765152
Validation loss: 2.084799215197563

Epoch: 5| Step: 9
Training loss: 0.4512821137905121
Validation loss: 2.0898797114690146

Epoch: 5| Step: 10
Training loss: 0.41928690671920776
Validation loss: 2.055301641424497

Epoch: 5| Step: 11
Training loss: 0.22617435455322266
Validation loss: 2.0900516510009766

Epoch: 463| Step: 0
Training loss: 0.2542174160480499
Validation loss: 2.0867095788319907

Epoch: 5| Step: 1
Training loss: 0.4299198091030121
Validation loss: 2.078617831071218

Epoch: 5| Step: 2
Training loss: 0.2322080135345459
Validation loss: 2.1214099327723184

Epoch: 5| Step: 3
Training loss: 0.5859217643737793
Validation loss: 2.1153151392936707

Epoch: 5| Step: 4
Training loss: 0.27518516778945923
Validation loss: 2.0684141516685486

Epoch: 5| Step: 5
Training loss: 0.7155245542526245
Validation loss: 2.067788670460383

Epoch: 5| Step: 6
Training loss: 0.2699378728866577
Validation loss: 2.1081151266892753

Epoch: 5| Step: 7
Training loss: 0.21856994926929474
Validation loss: 2.0998536199331284

Epoch: 5| Step: 8
Training loss: 0.3788840174674988
Validation loss: 2.1221521298090615

Epoch: 5| Step: 9
Training loss: 0.31136608123779297
Validation loss: 2.103515019019445

Epoch: 5| Step: 10
Training loss: 0.32756727933883667
Validation loss: 2.0871328910191855

Epoch: 5| Step: 11
Training loss: 0.3453517258167267
Validation loss: 2.09914268553257

Epoch: 464| Step: 0
Training loss: 0.5292208790779114
Validation loss: 2.1155051986376443

Epoch: 5| Step: 1
Training loss: 0.27926555275917053
Validation loss: 2.1123263835906982

Epoch: 5| Step: 2
Training loss: 0.3493078649044037
Validation loss: 2.0967904229958854

Epoch: 5| Step: 3
Training loss: 0.2759566009044647
Validation loss: 2.1043691585461297

Epoch: 5| Step: 4
Training loss: 0.2366972416639328
Validation loss: 2.1242712338765464

Epoch: 5| Step: 5
Training loss: 0.6985885500907898
Validation loss: 2.122661123673121

Epoch: 5| Step: 6
Training loss: 0.3253896236419678
Validation loss: 2.053831239541372

Epoch: 5| Step: 7
Training loss: 0.5001537203788757
Validation loss: 2.0795071125030518

Epoch: 5| Step: 8
Training loss: 0.25513699650764465
Validation loss: 2.074593330423037

Epoch: 5| Step: 9
Training loss: 0.36797744035720825
Validation loss: 2.098700056473414

Epoch: 5| Step: 10
Training loss: 0.29228663444519043
Validation loss: 2.091798891623815

Epoch: 5| Step: 11
Training loss: 0.7248499393463135
Validation loss: 2.0734417885541916

Epoch: 465| Step: 0
Training loss: 0.31937292218208313
Validation loss: 2.1337729692459106

Epoch: 5| Step: 1
Training loss: 0.3168650269508362
Validation loss: 2.1031334598859153

Epoch: 5| Step: 2
Training loss: 0.3175376057624817
Validation loss: 2.1337695171435676

Epoch: 5| Step: 3
Training loss: 0.5502141118049622
Validation loss: 2.084554781516393

Epoch: 5| Step: 4
Training loss: 0.2279570996761322
Validation loss: 2.0808298488458

Epoch: 5| Step: 5
Training loss: 0.32655176520347595
Validation loss: 2.109789644678434

Epoch: 5| Step: 6
Training loss: 0.30394357442855835
Validation loss: 2.1227990488211312

Epoch: 5| Step: 7
Training loss: 0.37413424253463745
Validation loss: 2.0947882185379663

Epoch: 5| Step: 8
Training loss: 0.40078186988830566
Validation loss: 2.121247172355652

Epoch: 5| Step: 9
Training loss: 0.3554210066795349
Validation loss: 2.1067109803358712

Epoch: 5| Step: 10
Training loss: 0.4816170632839203
Validation loss: 2.144372060894966

Epoch: 5| Step: 11
Training loss: 0.17592716217041016
Validation loss: 2.125954126318296

Epoch: 466| Step: 0
Training loss: 0.5278934240341187
Validation loss: 2.147671033938726

Epoch: 5| Step: 1
Training loss: 0.2526317238807678
Validation loss: 2.0811392267545066

Epoch: 5| Step: 2
Training loss: 0.2549918293952942
Validation loss: 2.0724290708700814

Epoch: 5| Step: 3
Training loss: 0.2523910701274872
Validation loss: 2.078544487555822

Epoch: 5| Step: 4
Training loss: 0.3356444239616394
Validation loss: 2.096753880381584

Epoch: 5| Step: 5
Training loss: 0.4124426245689392
Validation loss: 2.1016610860824585

Epoch: 5| Step: 6
Training loss: 0.3825691342353821
Validation loss: 2.1089804420868554

Epoch: 5| Step: 7
Training loss: 0.5231152176856995
Validation loss: 2.0849845856428146

Epoch: 5| Step: 8
Training loss: 0.48925718665122986
Validation loss: 2.045567288994789

Epoch: 5| Step: 9
Training loss: 0.5076605081558228
Validation loss: 2.1082744846741357

Epoch: 5| Step: 10
Training loss: 0.25437918305397034
Validation loss: 2.0785635014375052

Epoch: 5| Step: 11
Training loss: 0.22685599327087402
Validation loss: 2.1150314062833786

Epoch: 467| Step: 0
Training loss: 0.6034517288208008
Validation loss: 2.106647198398908

Epoch: 5| Step: 1
Training loss: 0.3020178973674774
Validation loss: 2.0925721675157547

Epoch: 5| Step: 2
Training loss: 0.210214763879776
Validation loss: 2.10005055864652

Epoch: 5| Step: 3
Training loss: 0.2746606767177582
Validation loss: 2.080913762251536

Epoch: 5| Step: 4
Training loss: 0.38322585821151733
Validation loss: 2.108208566904068

Epoch: 5| Step: 5
Training loss: 0.6596838235855103
Validation loss: 2.1191525806983313

Epoch: 5| Step: 6
Training loss: 0.4053787291049957
Validation loss: 2.0699620445569358

Epoch: 5| Step: 7
Training loss: 0.31054338812828064
Validation loss: 2.0618130216995874

Epoch: 5| Step: 8
Training loss: 0.29430127143859863
Validation loss: 2.090702563524246

Epoch: 5| Step: 9
Training loss: 0.4522581994533539
Validation loss: 2.117009753982226

Epoch: 5| Step: 10
Training loss: 0.30908146500587463
Validation loss: 2.082071304321289

Epoch: 5| Step: 11
Training loss: 0.11349081993103027
Validation loss: 2.1512902677059174

Epoch: 468| Step: 0
Training loss: 0.1446448266506195
Validation loss: 2.09241392215093

Epoch: 5| Step: 1
Training loss: 0.4586765170097351
Validation loss: 2.1346344649791718

Epoch: 5| Step: 2
Training loss: 0.33031323552131653
Validation loss: 2.1026146511236825

Epoch: 5| Step: 3
Training loss: 0.22583384811878204
Validation loss: 2.1172501146793365

Epoch: 5| Step: 4
Training loss: 0.5586710572242737
Validation loss: 2.0919132878383

Epoch: 5| Step: 5
Training loss: 0.35196056962013245
Validation loss: 2.0920501997073493

Epoch: 5| Step: 6
Training loss: 0.23025529086589813
Validation loss: 2.130948488910993

Epoch: 5| Step: 7
Training loss: 0.3197620213031769
Validation loss: 2.1133457024892173

Epoch: 5| Step: 8
Training loss: 0.4041828215122223
Validation loss: 2.0751966734727225

Epoch: 5| Step: 9
Training loss: 0.5262197256088257
Validation loss: 2.075552557905515

Epoch: 5| Step: 10
Training loss: 0.3124252259731293
Validation loss: 2.1164801319440207

Epoch: 5| Step: 11
Training loss: 0.152459979057312
Validation loss: 2.10234072804451

Epoch: 469| Step: 0
Training loss: 0.27930504083633423
Validation loss: 2.1051591336727142

Epoch: 5| Step: 1
Training loss: 0.2787702977657318
Validation loss: 2.127469847599665

Epoch: 5| Step: 2
Training loss: 0.7346640229225159
Validation loss: 2.092840999364853

Epoch: 5| Step: 3
Training loss: 0.42611703276634216
Validation loss: 2.119192043940226

Epoch: 5| Step: 4
Training loss: 0.3869563639163971
Validation loss: 2.12528558075428

Epoch: 5| Step: 5
Training loss: 0.38352474570274353
Validation loss: 2.0823443283637366

Epoch: 5| Step: 6
Training loss: 0.3848486840724945
Validation loss: 2.111100892225901

Epoch: 5| Step: 7
Training loss: 0.30690109729766846
Validation loss: 2.1165470629930496

Epoch: 5| Step: 8
Training loss: 0.19450753927230835
Validation loss: 2.0518164932727814

Epoch: 5| Step: 9
Training loss: 0.501413881778717
Validation loss: 2.080110639333725

Epoch: 5| Step: 10
Training loss: 0.20888395607471466
Validation loss: 2.088819364706675

Epoch: 5| Step: 11
Training loss: 0.3476923108100891
Validation loss: 2.064982051650683

Epoch: 470| Step: 0
Training loss: 0.3425508439540863
Validation loss: 2.128926530480385

Epoch: 5| Step: 1
Training loss: 0.41221141815185547
Validation loss: 2.1113610764344535

Epoch: 5| Step: 2
Training loss: 0.18769723176956177
Validation loss: 2.0877580444018045

Epoch: 5| Step: 3
Training loss: 0.42962759733200073
Validation loss: 2.0790879478057227

Epoch: 5| Step: 4
Training loss: 0.37111201882362366
Validation loss: 2.058875078956286

Epoch: 5| Step: 5
Training loss: 0.491137832403183
Validation loss: 2.0796792656183243

Epoch: 5| Step: 6
Training loss: 0.24026374518871307
Validation loss: 2.1064415921767554

Epoch: 5| Step: 7
Training loss: 0.2972499132156372
Validation loss: 2.1121827562650046

Epoch: 5| Step: 8
Training loss: 0.498147577047348
Validation loss: 2.14877679447333

Epoch: 5| Step: 9
Training loss: 0.22098448872566223
Validation loss: 2.1363323032855988

Epoch: 5| Step: 10
Training loss: 0.3936830759048462
Validation loss: 2.0733144829670587

Epoch: 5| Step: 11
Training loss: 0.1340962052345276
Validation loss: 2.1380625218153

Epoch: 471| Step: 0
Training loss: 0.14528706669807434
Validation loss: 2.1000955005486808

Epoch: 5| Step: 1
Training loss: 0.27328863739967346
Validation loss: 2.0819886128107705

Epoch: 5| Step: 2
Training loss: 0.5213668942451477
Validation loss: 2.0822112411260605

Epoch: 5| Step: 3
Training loss: 0.2738511860370636
Validation loss: 2.138766974210739

Epoch: 5| Step: 4
Training loss: 0.4208844304084778
Validation loss: 2.093161399165789

Epoch: 5| Step: 5
Training loss: 0.3650750517845154
Validation loss: 2.0741997063159943

Epoch: 5| Step: 6
Training loss: 0.4125944972038269
Validation loss: 2.122073923548063

Epoch: 5| Step: 7
Training loss: 0.34084591269493103
Validation loss: 2.114252045750618

Epoch: 5| Step: 8
Training loss: 0.36055657267570496
Validation loss: 2.10737415154775

Epoch: 5| Step: 9
Training loss: 0.3724677562713623
Validation loss: 2.0555760860443115

Epoch: 5| Step: 10
Training loss: 0.6440423130989075
Validation loss: 2.0679569641749063

Epoch: 5| Step: 11
Training loss: 0.10726672410964966
Validation loss: 2.1037199894587197

Epoch: 472| Step: 0
Training loss: 0.317805677652359
Validation loss: 2.1238117863734565

Epoch: 5| Step: 1
Training loss: 0.5333441495895386
Validation loss: 2.1006893863280616

Epoch: 5| Step: 2
Training loss: 0.17112024128437042
Validation loss: 2.095058023929596

Epoch: 5| Step: 3
Training loss: 0.4196290373802185
Validation loss: 2.0962531169255576

Epoch: 5| Step: 4
Training loss: 0.22026364505290985
Validation loss: 2.0887368420759835

Epoch: 5| Step: 5
Training loss: 0.37328967452049255
Validation loss: 2.0562637796004615

Epoch: 5| Step: 6
Training loss: 0.28967878222465515
Validation loss: 2.072900096575419

Epoch: 5| Step: 7
Training loss: 0.49643200635910034
Validation loss: 2.094184239705404

Epoch: 5| Step: 8
Training loss: 0.2638298571109772
Validation loss: 2.113333190480868

Epoch: 5| Step: 9
Training loss: 0.3319414556026459
Validation loss: 2.100175494949023

Epoch: 5| Step: 10
Training loss: 0.3739292323589325
Validation loss: 2.098604033390681

Epoch: 5| Step: 11
Training loss: 0.23883557319641113
Validation loss: 2.079486226042112

Epoch: 473| Step: 0
Training loss: 0.3389904499053955
Validation loss: 2.0809027353922525

Epoch: 5| Step: 1
Training loss: 0.35054537653923035
Validation loss: 2.079265038172404

Epoch: 5| Step: 2
Training loss: 0.31750333309173584
Validation loss: 2.0921435058116913

Epoch: 5| Step: 3
Training loss: 0.7510644197463989
Validation loss: 2.096850315729777

Epoch: 5| Step: 4
Training loss: 0.2220989465713501
Validation loss: 2.091644510626793

Epoch: 5| Step: 5
Training loss: 0.25977519154548645
Validation loss: 2.0684954226017

Epoch: 5| Step: 6
Training loss: 0.33102717995643616
Validation loss: 2.0697067926327386

Epoch: 5| Step: 7
Training loss: 0.43167248368263245
Validation loss: 2.142625937859217

Epoch: 5| Step: 8
Training loss: 0.4492063522338867
Validation loss: 2.0949116200208664

Epoch: 5| Step: 9
Training loss: 0.4544658660888672
Validation loss: 2.078731124599775

Epoch: 5| Step: 10
Training loss: 0.4105253219604492
Validation loss: 2.139285539587339

Epoch: 5| Step: 11
Training loss: 0.192541241645813
Validation loss: 2.06784417728583

Epoch: 474| Step: 0
Training loss: 0.25066614151000977
Validation loss: 2.0775914589564004

Epoch: 5| Step: 1
Training loss: 0.34061309695243835
Validation loss: 2.0907234946886697

Epoch: 5| Step: 2
Training loss: 0.3203345835208893
Validation loss: 2.100665807723999

Epoch: 5| Step: 3
Training loss: 0.8622602224349976
Validation loss: 2.0670864433050156

Epoch: 5| Step: 4
Training loss: 0.39335423707962036
Validation loss: 2.0937934269507728

Epoch: 5| Step: 5
Training loss: 0.36354148387908936
Validation loss: 2.1053995887438455

Epoch: 5| Step: 6
Training loss: 0.452134907245636
Validation loss: 2.1472909996906915

Epoch: 5| Step: 7
Training loss: 0.4760673940181732
Validation loss: 2.1427198896805444

Epoch: 5| Step: 8
Training loss: 0.515544056892395
Validation loss: 2.113614112138748

Epoch: 5| Step: 9
Training loss: 0.3639658987522125
Validation loss: 2.1330555429061255

Epoch: 5| Step: 10
Training loss: 0.4740358889102936
Validation loss: 2.1004052509864173

Epoch: 5| Step: 11
Training loss: 0.209161177277565
Validation loss: 2.138158400853475

Epoch: 475| Step: 0
Training loss: 0.24004749953746796
Validation loss: 2.131483182311058

Epoch: 5| Step: 1
Training loss: 0.32179731130599976
Validation loss: 2.108757028977076

Epoch: 5| Step: 2
Training loss: 0.5493686199188232
Validation loss: 2.0883948107560477

Epoch: 5| Step: 3
Training loss: 0.5829031467437744
Validation loss: 2.1136291722456613

Epoch: 5| Step: 4
Training loss: 0.25156548619270325
Validation loss: 2.110321124394735

Epoch: 5| Step: 5
Training loss: 0.23722946643829346
Validation loss: 2.0691640426715217

Epoch: 5| Step: 6
Training loss: 0.30700454115867615
Validation loss: 2.101432571808497

Epoch: 5| Step: 7
Training loss: 0.4511086046695709
Validation loss: 2.118426779905955

Epoch: 5| Step: 8
Training loss: 0.3345906734466553
Validation loss: 2.123742257555326

Epoch: 5| Step: 9
Training loss: 0.46604546904563904
Validation loss: 2.110001891851425

Epoch: 5| Step: 10
Training loss: 0.4819258749485016
Validation loss: 2.097432553768158

Epoch: 5| Step: 11
Training loss: 0.47292640805244446
Validation loss: 2.094015419483185

Epoch: 476| Step: 0
Training loss: 0.27628910541534424
Validation loss: 2.0499092787504196

Epoch: 5| Step: 1
Training loss: 0.30928507447242737
Validation loss: 2.0981130500634513

Epoch: 5| Step: 2
Training loss: 0.42617034912109375
Validation loss: 2.044854129354159

Epoch: 5| Step: 3
Training loss: 0.2166747748851776
Validation loss: 2.062634845574697

Epoch: 5| Step: 4
Training loss: 0.569309413433075
Validation loss: 2.0327606797218323

Epoch: 5| Step: 5
Training loss: 0.4040946364402771
Validation loss: 2.078216334184011

Epoch: 5| Step: 6
Training loss: 0.34748420119285583
Validation loss: 2.0881567895412445

Epoch: 5| Step: 7
Training loss: 0.45095768570899963
Validation loss: 2.0941653350989022

Epoch: 5| Step: 8
Training loss: 0.28467410802841187
Validation loss: 2.0541564424832663

Epoch: 5| Step: 9
Training loss: 0.2513771653175354
Validation loss: 2.085031325618426

Epoch: 5| Step: 10
Training loss: 0.3246731162071228
Validation loss: 2.0780828843514123

Epoch: 5| Step: 11
Training loss: 0.07862651348114014
Validation loss: 2.122767979900042

Epoch: 477| Step: 0
Training loss: 0.34404364228248596
Validation loss: 2.1028672258059182

Epoch: 5| Step: 1
Training loss: 0.34513935446739197
Validation loss: 2.0565989514191947

Epoch: 5| Step: 2
Training loss: 0.3576028048992157
Validation loss: 2.1198520958423615

Epoch: 5| Step: 3
Training loss: 0.44366854429244995
Validation loss: 2.0923109352588654

Epoch: 5| Step: 4
Training loss: 0.24535346031188965
Validation loss: 2.1058735052744546

Epoch: 5| Step: 5
Training loss: 0.5764892101287842
Validation loss: 2.0761145502328873

Epoch: 5| Step: 6
Training loss: 0.5128308534622192
Validation loss: 2.140072991450628

Epoch: 5| Step: 7
Training loss: 0.13375510275363922
Validation loss: 2.1051332503557205

Epoch: 5| Step: 8
Training loss: 0.4598225951194763
Validation loss: 2.0996219416459403

Epoch: 5| Step: 9
Training loss: 0.2970487177371979
Validation loss: 2.1424540827671685

Epoch: 5| Step: 10
Training loss: 0.29823821783065796
Validation loss: 2.1091131468613944

Epoch: 5| Step: 11
Training loss: 0.1931360960006714
Validation loss: 2.089519202709198

Epoch: 478| Step: 0
Training loss: 0.4917968809604645
Validation loss: 2.1149275998274484

Epoch: 5| Step: 1
Training loss: 0.28285425901412964
Validation loss: 2.1267214516798654

Epoch: 5| Step: 2
Training loss: 0.24050438404083252
Validation loss: 2.10071237385273

Epoch: 5| Step: 3
Training loss: 0.3543696105480194
Validation loss: 2.116180251042048

Epoch: 5| Step: 4
Training loss: 0.3026618957519531
Validation loss: 2.0912645707527795

Epoch: 5| Step: 5
Training loss: 0.48259297013282776
Validation loss: 2.093130206068357

Epoch: 5| Step: 6
Training loss: 0.6421771049499512
Validation loss: 2.1067062069972358

Epoch: 5| Step: 7
Training loss: 0.36161547899246216
Validation loss: 2.0882506916920343

Epoch: 5| Step: 8
Training loss: 0.2518802285194397
Validation loss: 2.037846803665161

Epoch: 5| Step: 9
Training loss: 0.2976232171058655
Validation loss: 2.094205394387245

Epoch: 5| Step: 10
Training loss: 0.3177822232246399
Validation loss: 2.0654194156328836

Epoch: 5| Step: 11
Training loss: 0.2343723475933075
Validation loss: 2.110944464802742

Epoch: 479| Step: 0
Training loss: 0.6477649211883545
Validation loss: 2.0968751907348633

Epoch: 5| Step: 1
Training loss: 0.31700050830841064
Validation loss: 2.109536717335383

Epoch: 5| Step: 2
Training loss: 0.5612569451332092
Validation loss: 2.06179050107797

Epoch: 5| Step: 3
Training loss: 0.21600377559661865
Validation loss: 2.086509734392166

Epoch: 5| Step: 4
Training loss: 0.21334123611450195
Validation loss: 2.0882442047198615

Epoch: 5| Step: 5
Training loss: 0.41851216554641724
Validation loss: 2.059612641731898

Epoch: 5| Step: 6
Training loss: 0.4660889506340027
Validation loss: 2.091267759601275

Epoch: 5| Step: 7
Training loss: 0.45765572786331177
Validation loss: 2.095299099882444

Epoch: 5| Step: 8
Training loss: 0.426105260848999
Validation loss: 2.1015335420767465

Epoch: 5| Step: 9
Training loss: 0.22253921627998352
Validation loss: 2.0945405115683875

Epoch: 5| Step: 10
Training loss: 0.19408626854419708
Validation loss: 2.095069189866384

Epoch: 5| Step: 11
Training loss: 0.4719791114330292
Validation loss: 2.0662871400515237

Epoch: 480| Step: 0
Training loss: 0.47658610343933105
Validation loss: 2.118728682398796

Epoch: 5| Step: 1
Training loss: 0.2290940284729004
Validation loss: 2.104830577969551

Epoch: 5| Step: 2
Training loss: 0.32003912329673767
Validation loss: 2.112592021624247

Epoch: 5| Step: 3
Training loss: 0.1721498966217041
Validation loss: 2.1281303465366364

Epoch: 5| Step: 4
Training loss: 0.246566504240036
Validation loss: 2.0695982625087104

Epoch: 5| Step: 5
Training loss: 0.7971234917640686
Validation loss: 2.0899998595317206

Epoch: 5| Step: 6
Training loss: 0.3232724964618683
Validation loss: 2.046039715409279

Epoch: 5| Step: 7
Training loss: 0.40919598937034607
Validation loss: 2.111421446005503

Epoch: 5| Step: 8
Training loss: 0.3361908495426178
Validation loss: 2.0937093595663705

Epoch: 5| Step: 9
Training loss: 0.43210935592651367
Validation loss: 2.1234130412340164

Epoch: 5| Step: 10
Training loss: 0.26109418272972107
Validation loss: 2.0696520706017814

Epoch: 5| Step: 11
Training loss: 0.2619146406650543
Validation loss: 2.0576592683792114

Epoch: 481| Step: 0
Training loss: 0.30856427550315857
Validation loss: 2.1096082826455436

Epoch: 5| Step: 1
Training loss: 0.3616441488265991
Validation loss: 2.07748773197333

Epoch: 5| Step: 2
Training loss: 0.8052369356155396
Validation loss: 2.087861826022466

Epoch: 5| Step: 3
Training loss: 0.21267354488372803
Validation loss: 2.0899675687154136

Epoch: 5| Step: 4
Training loss: 0.4818659722805023
Validation loss: 2.085627476374308

Epoch: 5| Step: 5
Training loss: 0.24612243473529816
Validation loss: 2.116930678486824

Epoch: 5| Step: 6
Training loss: 0.4298240542411804
Validation loss: 2.0521178444226584

Epoch: 5| Step: 7
Training loss: 0.4948543906211853
Validation loss: 2.122427066167196

Epoch: 5| Step: 8
Training loss: 0.2730296850204468
Validation loss: 2.080177982648214

Epoch: 5| Step: 9
Training loss: 0.21954354643821716
Validation loss: 2.120102142294248

Epoch: 5| Step: 10
Training loss: 0.2480335235595703
Validation loss: 2.137437090277672

Epoch: 5| Step: 11
Training loss: 0.22808274626731873
Validation loss: 2.1001083751519523

Epoch: 482| Step: 0
Training loss: 0.29964256286621094
Validation loss: 2.137835741043091

Epoch: 5| Step: 1
Training loss: 0.6746565103530884
Validation loss: 2.092608446876208

Epoch: 5| Step: 2
Training loss: 0.1487450748682022
Validation loss: 2.101659486691157

Epoch: 5| Step: 3
Training loss: 0.4197999835014343
Validation loss: 2.1126592606306076

Epoch: 5| Step: 4
Training loss: 0.2850255072116852
Validation loss: 2.115661030014356

Epoch: 5| Step: 5
Training loss: 0.33145928382873535
Validation loss: 2.133691444993019

Epoch: 5| Step: 6
Training loss: 0.2784927487373352
Validation loss: 2.115644117196401

Epoch: 5| Step: 7
Training loss: 0.29554495215415955
Validation loss: 2.128660241762797

Epoch: 5| Step: 8
Training loss: 0.7059685587882996
Validation loss: 2.083025569717089

Epoch: 5| Step: 9
Training loss: 0.3408563435077667
Validation loss: 2.101083959142367

Epoch: 5| Step: 10
Training loss: 0.24863660335540771
Validation loss: 2.0903848161300025

Epoch: 5| Step: 11
Training loss: 0.1528780460357666
Validation loss: 2.110371564825376

Epoch: 483| Step: 0
Training loss: 0.19457045197486877
Validation loss: 2.0868906378746033

Epoch: 5| Step: 1
Training loss: 0.6445773243904114
Validation loss: 2.1443867882092795

Epoch: 5| Step: 2
Training loss: 0.5096283555030823
Validation loss: 2.165843258301417

Epoch: 5| Step: 3
Training loss: 0.4612666070461273
Validation loss: 2.145402972896894

Epoch: 5| Step: 4
Training loss: 0.44479283690452576
Validation loss: 2.1084298292795816

Epoch: 5| Step: 5
Training loss: 0.2774955928325653
Validation loss: 2.0952485650777817

Epoch: 5| Step: 6
Training loss: 0.5459364652633667
Validation loss: 2.130614841977755

Epoch: 5| Step: 7
Training loss: 0.1895817518234253
Validation loss: 2.0664935608704886

Epoch: 5| Step: 8
Training loss: 0.2591968774795532
Validation loss: 2.0694622298081717

Epoch: 5| Step: 9
Training loss: 0.3952810764312744
Validation loss: 2.1004636883735657

Epoch: 5| Step: 10
Training loss: 0.23361268639564514
Validation loss: 2.0626573115587234

Epoch: 5| Step: 11
Training loss: 0.7534589767456055
Validation loss: 2.1441290825605392

Epoch: 484| Step: 0
Training loss: 0.24688616394996643
Validation loss: 2.1126107523838678

Epoch: 5| Step: 1
Training loss: 0.261258065700531
Validation loss: 2.1230065574248633

Epoch: 5| Step: 2
Training loss: 0.35360997915267944
Validation loss: 2.12857656677564

Epoch: 5| Step: 3
Training loss: 0.34896695613861084
Validation loss: 2.1375022381544113

Epoch: 5| Step: 4
Training loss: 0.45292574167251587
Validation loss: 2.1715940634409585

Epoch: 5| Step: 5
Training loss: 0.3062160313129425
Validation loss: 2.1513110051552453

Epoch: 5| Step: 6
Training loss: 0.7489949464797974
Validation loss: 2.15514874458313

Epoch: 5| Step: 7
Training loss: 0.27691370248794556
Validation loss: 2.1042887419462204

Epoch: 5| Step: 8
Training loss: 0.3012337386608124
Validation loss: 2.119111875693003

Epoch: 5| Step: 9
Training loss: 0.4122452735900879
Validation loss: 2.116305708885193

Epoch: 5| Step: 10
Training loss: 0.29670336842536926
Validation loss: 2.1099566221237183

Epoch: 5| Step: 11
Training loss: 0.15428423881530762
Validation loss: 2.089864412943522

Epoch: 485| Step: 0
Training loss: 0.18637636303901672
Validation loss: 2.0847763071457543

Epoch: 5| Step: 1
Training loss: 0.3320877254009247
Validation loss: 2.0870197812716165

Epoch: 5| Step: 2
Training loss: 0.6916467547416687
Validation loss: 2.124845877289772

Epoch: 5| Step: 3
Training loss: 0.3107602596282959
Validation loss: 2.1030833373467126

Epoch: 5| Step: 4
Training loss: 0.2158258706331253
Validation loss: 2.13176121811072

Epoch: 5| Step: 5
Training loss: 0.30156585574150085
Validation loss: 2.0920476466417313

Epoch: 5| Step: 6
Training loss: 0.25277775526046753
Validation loss: 2.1243520180384317

Epoch: 5| Step: 7
Training loss: 0.4589267671108246
Validation loss: 2.119357923666636

Epoch: 5| Step: 8
Training loss: 0.3074430823326111
Validation loss: 2.129268988966942

Epoch: 5| Step: 9
Training loss: 0.20905819535255432
Validation loss: 2.09089328845342

Epoch: 5| Step: 10
Training loss: 0.28806576132774353
Validation loss: 2.0933066606521606

Epoch: 5| Step: 11
Training loss: 1.224143385887146
Validation loss: 2.082191358009974

Epoch: 486| Step: 0
Training loss: 0.46576938033103943
Validation loss: 2.0688602725664773

Epoch: 5| Step: 1
Training loss: 0.33063560724258423
Validation loss: 2.06499807536602

Epoch: 5| Step: 2
Training loss: 0.27180418372154236
Validation loss: 2.0633942981561026

Epoch: 5| Step: 3
Training loss: 0.29972702264785767
Validation loss: 2.10578661163648

Epoch: 5| Step: 4
Training loss: 0.5095478296279907
Validation loss: 2.1139983236789703

Epoch: 5| Step: 5
Training loss: 0.22357988357543945
Validation loss: 2.0728853940963745

Epoch: 5| Step: 6
Training loss: 0.23924624919891357
Validation loss: 2.0915901362895966

Epoch: 5| Step: 7
Training loss: 0.39007800817489624
Validation loss: 2.0695555359125137

Epoch: 5| Step: 8
Training loss: 0.6460027694702148
Validation loss: 2.0870528320471444

Epoch: 5| Step: 9
Training loss: 0.3780497908592224
Validation loss: 2.0973525991042457

Epoch: 5| Step: 10
Training loss: 0.3257434666156769
Validation loss: 2.0904113252957663

Epoch: 5| Step: 11
Training loss: 0.33333829045295715
Validation loss: 2.0881415406862893

Epoch: 487| Step: 0
Training loss: 0.2456492930650711
Validation loss: 2.0958831359942756

Epoch: 5| Step: 1
Training loss: 0.25542595982551575
Validation loss: 2.0917652944723764

Epoch: 5| Step: 2
Training loss: 0.2505418062210083
Validation loss: 2.1209096709887185

Epoch: 5| Step: 3
Training loss: 0.3843012750148773
Validation loss: 2.099246790011724

Epoch: 5| Step: 4
Training loss: 0.28069615364074707
Validation loss: 2.148606831828753

Epoch: 5| Step: 5
Training loss: 1.024745225906372
Validation loss: 2.1104646573464074

Epoch: 5| Step: 6
Training loss: 0.3418821692466736
Validation loss: 2.1585808098316193

Epoch: 5| Step: 7
Training loss: 0.3641126751899719
Validation loss: 2.1363836924235025

Epoch: 5| Step: 8
Training loss: 0.1833895444869995
Validation loss: 2.105382204055786

Epoch: 5| Step: 9
Training loss: 0.24219369888305664
Validation loss: 2.144781003395716

Epoch: 5| Step: 10
Training loss: 0.40475255250930786
Validation loss: 2.1107539733250937

Epoch: 5| Step: 11
Training loss: 0.2749793529510498
Validation loss: 2.1289171079794564

Epoch: 488| Step: 0
Training loss: 0.31376343965530396
Validation loss: 2.1485102077325187

Epoch: 5| Step: 1
Training loss: 0.39742738008499146
Validation loss: 2.1084772845109305

Epoch: 5| Step: 2
Training loss: 0.23601360619068146
Validation loss: 2.1151184489329657

Epoch: 5| Step: 3
Training loss: 0.30600693821907043
Validation loss: 2.1040123055378595

Epoch: 5| Step: 4
Training loss: 0.248386949300766
Validation loss: 2.1331078112125397

Epoch: 5| Step: 5
Training loss: 0.18316783010959625
Validation loss: 2.1247930179039636

Epoch: 5| Step: 6
Training loss: 0.49824124574661255
Validation loss: 2.0981157273054123

Epoch: 5| Step: 7
Training loss: 0.24656352400779724
Validation loss: 2.0950180987517038

Epoch: 5| Step: 8
Training loss: 0.35256463289260864
Validation loss: 2.115338762601217

Epoch: 5| Step: 9
Training loss: 0.40770477056503296
Validation loss: 2.109682554999987

Epoch: 5| Step: 10
Training loss: 0.7008380889892578
Validation loss: 2.1245224674542746

Epoch: 5| Step: 11
Training loss: 0.10486900806427002
Validation loss: 2.0946568151315055

Epoch: 489| Step: 0
Training loss: 0.3265018165111542
Validation loss: 2.0857124477624893

Epoch: 5| Step: 1
Training loss: 0.30881839990615845
Validation loss: 2.093716343243917

Epoch: 5| Step: 2
Training loss: 0.6007488369941711
Validation loss: 2.088804359237353

Epoch: 5| Step: 3
Training loss: 0.27537795901298523
Validation loss: 2.0805373142162957

Epoch: 5| Step: 4
Training loss: 0.410683810710907
Validation loss: 2.1146934082110724

Epoch: 5| Step: 5
Training loss: 0.30463096499443054
Validation loss: 2.1047474145889282

Epoch: 5| Step: 6
Training loss: 0.5964557528495789
Validation loss: 2.1163118183612823

Epoch: 5| Step: 7
Training loss: 0.2631012797355652
Validation loss: 2.1192775666713715

Epoch: 5| Step: 8
Training loss: 0.48537564277648926
Validation loss: 2.1381429036458335

Epoch: 5| Step: 9
Training loss: 0.22286491096019745
Validation loss: 2.0712446918090186

Epoch: 5| Step: 10
Training loss: 0.2918390929698944
Validation loss: 2.1013203859329224

Epoch: 5| Step: 11
Training loss: 0.23309838771820068
Validation loss: 2.0926584055026374

Epoch: 490| Step: 0
Training loss: 0.32261958718299866
Validation loss: 2.0678234001000724

Epoch: 5| Step: 1
Training loss: 0.389375239610672
Validation loss: 2.0504904935757318

Epoch: 5| Step: 2
Training loss: 0.450678288936615
Validation loss: 2.075888822476069

Epoch: 5| Step: 3
Training loss: 0.4175131916999817
Validation loss: 2.0268271615107856

Epoch: 5| Step: 4
Training loss: 0.29435646533966064
Validation loss: 2.103791505098343

Epoch: 5| Step: 5
Training loss: 0.28621989488601685
Validation loss: 2.102477505803108

Epoch: 5| Step: 6
Training loss: 0.4872092306613922
Validation loss: 2.129935716589292

Epoch: 5| Step: 7
Training loss: 0.35161781311035156
Validation loss: 2.0976731528838477

Epoch: 5| Step: 8
Training loss: 0.2492564618587494
Validation loss: 2.0876670628786087

Epoch: 5| Step: 9
Training loss: 0.5619064569473267
Validation loss: 2.094844033320745

Epoch: 5| Step: 10
Training loss: 0.39924153685569763
Validation loss: 2.1126666218042374

Epoch: 5| Step: 11
Training loss: 0.18584807217121124
Validation loss: 2.102688064177831

Epoch: 491| Step: 0
Training loss: 0.30027633905410767
Validation loss: 2.092660203576088

Epoch: 5| Step: 1
Training loss: 0.25380516052246094
Validation loss: 2.093142847220103

Epoch: 5| Step: 2
Training loss: 0.3345084488391876
Validation loss: 2.0899341305096946

Epoch: 5| Step: 3
Training loss: 0.34420162439346313
Validation loss: 2.0869545539220176

Epoch: 5| Step: 4
Training loss: 0.21215371787548065
Validation loss: 2.141697625319163

Epoch: 5| Step: 5
Training loss: 0.4778878092765808
Validation loss: 2.1021118064721427

Epoch: 5| Step: 6
Training loss: 0.5075443387031555
Validation loss: 2.1019892742236457

Epoch: 5| Step: 7
Training loss: 0.5976015329360962
Validation loss: 2.081620300809542

Epoch: 5| Step: 8
Training loss: 0.386948823928833
Validation loss: 2.0731278459231057

Epoch: 5| Step: 9
Training loss: 0.3250581622123718
Validation loss: 2.0976195434729257

Epoch: 5| Step: 10
Training loss: 0.2180682122707367
Validation loss: 2.0710265785455704

Epoch: 5| Step: 11
Training loss: 0.34247368574142456
Validation loss: 2.072523057460785

Epoch: 492| Step: 0
Training loss: 0.5099517107009888
Validation loss: 2.09838575621446

Epoch: 5| Step: 1
Training loss: 0.5420597791671753
Validation loss: 2.071677645047506

Epoch: 5| Step: 2
Training loss: 0.27402156591415405
Validation loss: 2.068839912613233

Epoch: 5| Step: 3
Training loss: 0.3654172420501709
Validation loss: 2.0646883149941764

Epoch: 5| Step: 4
Training loss: 0.263272225856781
Validation loss: 2.086114759246508

Epoch: 5| Step: 5
Training loss: 0.4173815846443176
Validation loss: 2.07591704527537

Epoch: 5| Step: 6
Training loss: 0.22612187266349792
Validation loss: 2.0839780072371163

Epoch: 5| Step: 7
Training loss: 0.4202360212802887
Validation loss: 2.1107459912697473

Epoch: 5| Step: 8
Training loss: 0.5239163637161255
Validation loss: 2.1033193270365396

Epoch: 5| Step: 9
Training loss: 0.18374404311180115
Validation loss: 2.0990147391955056

Epoch: 5| Step: 10
Training loss: 0.22826163470745087
Validation loss: 2.098748043179512

Epoch: 5| Step: 11
Training loss: 0.27111494541168213
Validation loss: 2.1009903152783713

Epoch: 493| Step: 0
Training loss: 0.4815266728401184
Validation loss: 2.072134405374527

Epoch: 5| Step: 1
Training loss: 0.35342463850975037
Validation loss: 2.081397215525309

Epoch: 5| Step: 2
Training loss: 0.17660436034202576
Validation loss: 2.1043730974197388

Epoch: 5| Step: 3
Training loss: 0.1752987653017044
Validation loss: 2.0897294928630195

Epoch: 5| Step: 4
Training loss: 0.4786451458930969
Validation loss: 2.088983878493309

Epoch: 5| Step: 5
Training loss: 0.33236613869667053
Validation loss: 2.106562246878942

Epoch: 5| Step: 6
Training loss: 0.43498700857162476
Validation loss: 2.145499661564827

Epoch: 5| Step: 7
Training loss: 0.3968799412250519
Validation loss: 2.142228126525879

Epoch: 5| Step: 8
Training loss: 0.26197078824043274
Validation loss: 2.087075650691986

Epoch: 5| Step: 9
Training loss: 0.23753957450389862
Validation loss: 2.066860834757487

Epoch: 5| Step: 10
Training loss: 0.47470393776893616
Validation loss: 2.071366791923841

Epoch: 5| Step: 11
Training loss: 0.17256689071655273
Validation loss: 2.103928123911222

Epoch: 494| Step: 0
Training loss: 0.3464887738227844
Validation loss: 2.1080094625552497

Epoch: 5| Step: 1
Training loss: 0.598848819732666
Validation loss: 2.128127341469129

Epoch: 5| Step: 2
Training loss: 0.30461305379867554
Validation loss: 2.1428273618221283

Epoch: 5| Step: 3
Training loss: 0.2930727005004883
Validation loss: 2.104621037840843

Epoch: 5| Step: 4
Training loss: 0.4267004132270813
Validation loss: 2.179738074541092

Epoch: 5| Step: 5
Training loss: 0.3322654962539673
Validation loss: 2.1955077201128006

Epoch: 5| Step: 6
Training loss: 0.39544573426246643
Validation loss: 2.131447503964106

Epoch: 5| Step: 7
Training loss: 0.35629409551620483
Validation loss: 2.154429644346237

Epoch: 5| Step: 8
Training loss: 0.3309140205383301
Validation loss: 2.146913548310598

Epoch: 5| Step: 9
Training loss: 0.26195189356803894
Validation loss: 2.102731784184774

Epoch: 5| Step: 10
Training loss: 0.2106807678937912
Validation loss: 2.1596754292647042

Epoch: 5| Step: 11
Training loss: 0.1386999487876892
Validation loss: 2.141360471645991

Epoch: 495| Step: 0
Training loss: 0.5361697673797607
Validation loss: 2.1515539437532425

Epoch: 5| Step: 1
Training loss: 0.20737819373607635
Validation loss: 2.169897456963857

Epoch: 5| Step: 2
Training loss: 0.3109864592552185
Validation loss: 2.1289796580870948

Epoch: 5| Step: 3
Training loss: 0.36919546127319336
Validation loss: 2.159189427892367

Epoch: 5| Step: 4
Training loss: 0.47792357206344604
Validation loss: 2.09514527519544

Epoch: 5| Step: 5
Training loss: 0.34346485137939453
Validation loss: 2.1375695566336312

Epoch: 5| Step: 6
Training loss: 0.15839943289756775
Validation loss: 2.110477785269419

Epoch: 5| Step: 7
Training loss: 0.3612191081047058
Validation loss: 2.102685958147049

Epoch: 5| Step: 8
Training loss: 0.8049233555793762
Validation loss: 2.105120042959849

Epoch: 5| Step: 9
Training loss: 0.24756309390068054
Validation loss: 2.1088556349277496

Epoch: 5| Step: 10
Training loss: 0.21079358458518982
Validation loss: 2.1021243383487067

Epoch: 5| Step: 11
Training loss: 0.08271855115890503
Validation loss: 2.1102891663710275

Epoch: 496| Step: 0
Training loss: 0.3820013999938965
Validation loss: 2.0995869586865106

Epoch: 5| Step: 1
Training loss: 0.3953554630279541
Validation loss: 2.1137620707352958

Epoch: 5| Step: 2
Training loss: 0.46097880601882935
Validation loss: 2.0727388858795166

Epoch: 5| Step: 3
Training loss: 0.21324864029884338
Validation loss: 2.0694178392489753

Epoch: 5| Step: 4
Training loss: 0.34109073877334595
Validation loss: 2.115089396635691

Epoch: 5| Step: 5
Training loss: 0.40697699785232544
Validation loss: 2.1259915928045907

Epoch: 5| Step: 6
Training loss: 0.22430630028247833
Validation loss: 2.098701616128286

Epoch: 5| Step: 7
Training loss: 0.5074044466018677
Validation loss: 2.121726835767428

Epoch: 5| Step: 8
Training loss: 0.27413585782051086
Validation loss: 2.128936896721522

Epoch: 5| Step: 9
Training loss: 0.26483869552612305
Validation loss: 2.1195121705532074

Epoch: 5| Step: 10
Training loss: 0.4494979977607727
Validation loss: 2.080543885628382

Epoch: 5| Step: 11
Training loss: 0.23272907733917236
Validation loss: 2.07707246641318

Epoch: 497| Step: 0
Training loss: 0.23583979904651642
Validation loss: 2.04533389210701

Epoch: 5| Step: 1
Training loss: 0.2740819454193115
Validation loss: 2.125436618924141

Epoch: 5| Step: 2
Training loss: 0.2584071457386017
Validation loss: 2.1213799019654593

Epoch: 5| Step: 3
Training loss: 0.32402175664901733
Validation loss: 2.1378365407387414

Epoch: 5| Step: 4
Training loss: 0.2319166213274002
Validation loss: 2.120166132847468

Epoch: 5| Step: 5
Training loss: 0.3134087026119232
Validation loss: 2.0835390935341516

Epoch: 5| Step: 6
Training loss: 0.21586838364601135
Validation loss: 2.077454447746277

Epoch: 5| Step: 7
Training loss: 0.4793083071708679
Validation loss: 2.1003686090310416

Epoch: 5| Step: 8
Training loss: 0.4762576222419739
Validation loss: 2.09622456630071

Epoch: 5| Step: 9
Training loss: 0.485606849193573
Validation loss: 2.0913075854380927

Epoch: 5| Step: 10
Training loss: 0.5652951598167419
Validation loss: 2.0754293700059256

Epoch: 5| Step: 11
Training loss: 0.7212347984313965
Validation loss: 2.0889444003502526

Epoch: 498| Step: 0
Training loss: 0.2798713147640228
Validation loss: 2.0920951763788858

Epoch: 5| Step: 1
Training loss: 0.7264229655265808
Validation loss: 2.089268227418264

Epoch: 5| Step: 2
Training loss: 0.2948610186576843
Validation loss: 2.0955668836832047

Epoch: 5| Step: 3
Training loss: 0.544987142086029
Validation loss: 2.107513298590978

Epoch: 5| Step: 4
Training loss: 0.24559859931468964
Validation loss: 2.1133838494618735

Epoch: 5| Step: 5
Training loss: 0.33109837770462036
Validation loss: 2.15576234459877

Epoch: 5| Step: 6
Training loss: 0.40366679430007935
Validation loss: 2.160554106036822

Epoch: 5| Step: 7
Training loss: 0.2704654335975647
Validation loss: 2.099087874094645

Epoch: 5| Step: 8
Training loss: 0.2849275469779968
Validation loss: 2.0991420845190683

Epoch: 5| Step: 9
Training loss: 0.20803622901439667
Validation loss: 2.130937620997429

Epoch: 5| Step: 10
Training loss: 0.4140893518924713
Validation loss: 2.1099820782740912

Epoch: 5| Step: 11
Training loss: 0.31365394592285156
Validation loss: 2.0557649781306586

Epoch: 499| Step: 0
Training loss: 0.2154553383588791
Validation loss: 2.101382151246071

Epoch: 5| Step: 1
Training loss: 0.4819812774658203
Validation loss: 2.1285315404335656

Epoch: 5| Step: 2
Training loss: 0.5362310409545898
Validation loss: 2.0765914817651114

Epoch: 5| Step: 3
Training loss: 0.32478564977645874
Validation loss: 2.0918564945459366

Epoch: 5| Step: 4
Training loss: 0.3589893877506256
Validation loss: 2.051547904809316

Epoch: 5| Step: 5
Training loss: 0.3261403441429138
Validation loss: 2.06182328859965

Epoch: 5| Step: 6
Training loss: 0.4387578070163727
Validation loss: 2.0904251585404077

Epoch: 5| Step: 7
Training loss: 0.17586156725883484
Validation loss: 2.067868481079737

Epoch: 5| Step: 8
Training loss: 0.3745178282260895
Validation loss: 2.1236371199289956

Epoch: 5| Step: 9
Training loss: 0.22033372521400452
Validation loss: 2.07318647702535

Epoch: 5| Step: 10
Training loss: 0.3511684536933899
Validation loss: 2.0290986696879068

Epoch: 5| Step: 11
Training loss: 0.3098286986351013
Validation loss: 2.113259350260099

Epoch: 500| Step: 0
Training loss: 0.307508647441864
Validation loss: 2.070632115006447

Epoch: 5| Step: 1
Training loss: 0.24303758144378662
Validation loss: 2.0491118679443994

Epoch: 5| Step: 2
Training loss: 0.3551831841468811
Validation loss: 2.0754800339539847

Epoch: 5| Step: 3
Training loss: 0.29242128133773804
Validation loss: 2.085091918706894

Epoch: 5| Step: 4
Training loss: 0.6689393520355225
Validation loss: 2.0623424698909125

Epoch: 5| Step: 5
Training loss: 0.18399105966091156
Validation loss: 2.0632133036851883

Epoch: 5| Step: 6
Training loss: 0.374088317155838
Validation loss: 2.04338209827741

Epoch: 5| Step: 7
Training loss: 0.35523226857185364
Validation loss: 2.036536360780398

Epoch: 5| Step: 8
Training loss: 0.36288732290267944
Validation loss: 2.0677285492420197

Epoch: 5| Step: 9
Training loss: 0.17846760153770447
Validation loss: 2.114853317538897

Epoch: 5| Step: 10
Training loss: 0.4900851845741272
Validation loss: 2.085966174801191

Epoch: 5| Step: 11
Training loss: 0.2756706774234772
Validation loss: 2.0747363020976386

Epoch: 501| Step: 0
Training loss: 0.2609812021255493
Validation loss: 2.0366948395967484

Epoch: 5| Step: 1
Training loss: 0.3932553231716156
Validation loss: 2.086681937177976

Epoch: 5| Step: 2
Training loss: 0.2602030634880066
Validation loss: 2.1020232985417047

Epoch: 5| Step: 3
Training loss: 0.39581507444381714
Validation loss: 2.032206729054451

Epoch: 5| Step: 4
Training loss: 0.6242298483848572
Validation loss: 2.104654868443807

Epoch: 5| Step: 5
Training loss: 0.2668699622154236
Validation loss: 2.118917773167292

Epoch: 5| Step: 6
Training loss: 0.3122345507144928
Validation loss: 2.1395957867304483

Epoch: 5| Step: 7
Training loss: 0.3762226700782776
Validation loss: 2.1102273712555566

Epoch: 5| Step: 8
Training loss: 0.4608999192714691
Validation loss: 2.140400836865107

Epoch: 5| Step: 9
Training loss: 0.2891080975532532
Validation loss: 2.1032184660434723

Epoch: 5| Step: 10
Training loss: 0.2902895510196686
Validation loss: 2.12253308792909

Epoch: 5| Step: 11
Training loss: 0.9467813968658447
Validation loss: 2.0707988192637763

Epoch: 502| Step: 0
Training loss: 0.35278621315956116
Validation loss: 2.124807760119438

Epoch: 5| Step: 1
Training loss: 0.22994676232337952
Validation loss: 2.096747249364853

Epoch: 5| Step: 2
Training loss: 0.22417065501213074
Validation loss: 2.1059934397538504

Epoch: 5| Step: 3
Training loss: 0.4482170045375824
Validation loss: 2.0647999147574105

Epoch: 5| Step: 4
Training loss: 0.26440173387527466
Validation loss: 2.0827169915040336

Epoch: 5| Step: 5
Training loss: 0.4650798439979553
Validation loss: 2.1312297681967416

Epoch: 5| Step: 6
Training loss: 0.5155600905418396
Validation loss: 2.0940489868323007

Epoch: 5| Step: 7
Training loss: 0.656586229801178
Validation loss: 2.097197781006495

Epoch: 5| Step: 8
Training loss: 0.3202647566795349
Validation loss: 2.0970466285943985

Epoch: 5| Step: 9
Training loss: 0.25646549463272095
Validation loss: 2.080062518517176

Epoch: 5| Step: 10
Training loss: 0.3050568997859955
Validation loss: 2.100759377082189

Epoch: 5| Step: 11
Training loss: 0.17541281878948212
Validation loss: 2.117092102766037

Epoch: 503| Step: 0
Training loss: 0.3012351393699646
Validation loss: 2.133342057466507

Epoch: 5| Step: 1
Training loss: 0.5543456077575684
Validation loss: 2.118945375084877

Epoch: 5| Step: 2
Training loss: 0.36978453397750854
Validation loss: 2.096644381682078

Epoch: 5| Step: 3
Training loss: 0.23674312233924866
Validation loss: 2.0888412098089852

Epoch: 5| Step: 4
Training loss: 0.19792962074279785
Validation loss: 2.1098232517639794

Epoch: 5| Step: 5
Training loss: 0.26886528730392456
Validation loss: 2.121693084637324

Epoch: 5| Step: 6
Training loss: 0.42797988653182983
Validation loss: 2.130383183558782

Epoch: 5| Step: 7
Training loss: 0.4543348252773285
Validation loss: 2.0693702747424445

Epoch: 5| Step: 8
Training loss: 0.2490357905626297
Validation loss: 2.119131843249003

Epoch: 5| Step: 9
Training loss: 0.24375614523887634
Validation loss: 2.1090828677018485

Epoch: 5| Step: 10
Training loss: 0.18688514828681946
Validation loss: 2.106440007686615

Epoch: 5| Step: 11
Training loss: 0.5691733360290527
Validation loss: 2.0964815417925515

Epoch: 504| Step: 0
Training loss: 0.1613396257162094
Validation loss: 2.151353324453036

Epoch: 5| Step: 1
Training loss: 0.19144150614738464
Validation loss: 2.1160396883885064

Epoch: 5| Step: 2
Training loss: 0.45652875304222107
Validation loss: 2.1235395719607673

Epoch: 5| Step: 3
Training loss: 0.22846975922584534
Validation loss: 2.0953785330057144

Epoch: 5| Step: 4
Training loss: 0.515819251537323
Validation loss: 2.0756336053212485

Epoch: 5| Step: 5
Training loss: 0.35422131419181824
Validation loss: 2.0806458989779153

Epoch: 5| Step: 6
Training loss: 0.3993072509765625
Validation loss: 2.1182052195072174

Epoch: 5| Step: 7
Training loss: 0.3206689953804016
Validation loss: 2.0626533726851144

Epoch: 5| Step: 8
Training loss: 0.4331067204475403
Validation loss: 2.1114713748296103

Epoch: 5| Step: 9
Training loss: 0.2758377194404602
Validation loss: 2.103604863087336

Epoch: 5| Step: 10
Training loss: 0.25012487173080444
Validation loss: 2.1326686292886734

Epoch: 5| Step: 11
Training loss: 0.7662405371665955
Validation loss: 2.0455089708169303

Epoch: 505| Step: 0
Training loss: 0.3932775557041168
Validation loss: 2.118794242540995

Epoch: 5| Step: 1
Training loss: 0.19407919049263
Validation loss: 2.0568545957406363

Epoch: 5| Step: 2
Training loss: 0.35090088844299316
Validation loss: 2.090953052043915

Epoch: 5| Step: 3
Training loss: 0.5740336775779724
Validation loss: 2.116020758946737

Epoch: 5| Step: 4
Training loss: 0.2794362008571625
Validation loss: 2.0897329250971475

Epoch: 5| Step: 5
Training loss: 0.24935448169708252
Validation loss: 2.0952695657809577

Epoch: 5| Step: 6
Training loss: 0.2599864602088928
Validation loss: 2.1539751390616098

Epoch: 5| Step: 7
Training loss: 0.39063164591789246
Validation loss: 2.1037555038928986

Epoch: 5| Step: 8
Training loss: 0.45528897643089294
Validation loss: 2.1206674178441367

Epoch: 5| Step: 9
Training loss: 0.30271729826927185
Validation loss: 2.1158026506503425

Epoch: 5| Step: 10
Training loss: 0.17294345796108246
Validation loss: 2.066846410433451

Epoch: 5| Step: 11
Training loss: 0.2984561026096344
Validation loss: 2.1008188972870507

Epoch: 506| Step: 0
Training loss: 0.5937434434890747
Validation loss: 2.081610321998596

Epoch: 5| Step: 1
Training loss: 0.20103642344474792
Validation loss: 2.092717632651329

Epoch: 5| Step: 2
Training loss: 0.21181228756904602
Validation loss: 2.1094598372777305

Epoch: 5| Step: 3
Training loss: 0.26923075318336487
Validation loss: 2.1023736049731574

Epoch: 5| Step: 4
Training loss: 0.30157676339149475
Validation loss: 2.0712524553140006

Epoch: 5| Step: 5
Training loss: 0.2541791498661041
Validation loss: 2.1062359511852264

Epoch: 5| Step: 6
Training loss: 0.30258992314338684
Validation loss: 2.0671196033557258

Epoch: 5| Step: 7
Training loss: 0.6226187944412231
Validation loss: 2.0980532517035804

Epoch: 5| Step: 8
Training loss: 0.26742023229599
Validation loss: 2.0952342549959817

Epoch: 5| Step: 9
Training loss: 0.164155051112175
Validation loss: 2.057379111647606

Epoch: 5| Step: 10
Training loss: 0.48780256509780884
Validation loss: 2.1277286807696023

Epoch: 5| Step: 11
Training loss: 0.7370521426200867
Validation loss: 2.100751424829165

Epoch: 507| Step: 0
Training loss: 0.3046714663505554
Validation loss: 2.0864537159601846

Epoch: 5| Step: 1
Training loss: 0.3177645206451416
Validation loss: 2.0660847326119742

Epoch: 5| Step: 2
Training loss: 0.2918691039085388
Validation loss: 2.1301985681056976

Epoch: 5| Step: 3
Training loss: 0.3183479905128479
Validation loss: 2.085367903113365

Epoch: 5| Step: 4
Training loss: 0.5931534171104431
Validation loss: 2.068769723176956

Epoch: 5| Step: 5
Training loss: 0.2501913905143738
Validation loss: 2.0698962112267814

Epoch: 5| Step: 6
Training loss: 0.18697489798069
Validation loss: 2.0940473129351935

Epoch: 5| Step: 7
Training loss: 0.2075667828321457
Validation loss: 2.1516147206226983

Epoch: 5| Step: 8
Training loss: 0.21036824584007263
Validation loss: 2.098062535127004

Epoch: 5| Step: 9
Training loss: 0.5792714357376099
Validation loss: 2.089265525341034

Epoch: 5| Step: 10
Training loss: 0.41757965087890625
Validation loss: 2.1289647817611694

Epoch: 5| Step: 11
Training loss: 0.21228086948394775
Validation loss: 2.121756503979365

Epoch: 508| Step: 0
Training loss: 0.33662310242652893
Validation loss: 2.1383912165959678

Epoch: 5| Step: 1
Training loss: 0.2412528246641159
Validation loss: 2.1353350579738617

Epoch: 5| Step: 2
Training loss: 0.3907493054866791
Validation loss: 2.0871301343043647

Epoch: 5| Step: 3
Training loss: 0.2766083776950836
Validation loss: 2.115444074074427

Epoch: 5| Step: 4
Training loss: 0.6751052141189575
Validation loss: 2.129403457045555

Epoch: 5| Step: 5
Training loss: 0.4447666108608246
Validation loss: 2.1389648069938025

Epoch: 5| Step: 6
Training loss: 0.41812586784362793
Validation loss: 2.117212474346161

Epoch: 5| Step: 7
Training loss: 0.4586471617221832
Validation loss: 2.117779632409414

Epoch: 5| Step: 8
Training loss: 0.2522205412387848
Validation loss: 2.1252365758021674

Epoch: 5| Step: 9
Training loss: 0.29837578535079956
Validation loss: 2.0701845486958823

Epoch: 5| Step: 10
Training loss: 0.22682614624500275
Validation loss: 2.089418888092041

Epoch: 5| Step: 11
Training loss: 0.16320013999938965
Validation loss: 2.101418678959211

Epoch: 509| Step: 0
Training loss: 0.3927329480648041
Validation loss: 2.061318506797155

Epoch: 5| Step: 1
Training loss: 0.43079710006713867
Validation loss: 2.046507408221563

Epoch: 5| Step: 2
Training loss: 0.23638615012168884
Validation loss: 2.0571837723255157

Epoch: 5| Step: 3
Training loss: 0.3619462847709656
Validation loss: 2.0662519484758377

Epoch: 5| Step: 4
Training loss: 0.45547041296958923
Validation loss: 2.0802490413188934

Epoch: 5| Step: 5
Training loss: 0.24756960570812225
Validation loss: 2.0409373193979263

Epoch: 5| Step: 6
Training loss: 0.574066162109375
Validation loss: 2.1110912760098777

Epoch: 5| Step: 7
Training loss: 0.22260145843029022
Validation loss: 2.053724596897761

Epoch: 5| Step: 8
Training loss: 0.31603941321372986
Validation loss: 2.099667956431707

Epoch: 5| Step: 9
Training loss: 0.26681801676750183
Validation loss: 2.068401242295901

Epoch: 5| Step: 10
Training loss: 0.2298113852739334
Validation loss: 2.0875402788321176

Epoch: 5| Step: 11
Training loss: 0.8069047927856445
Validation loss: 2.1117338140805564

Epoch: 510| Step: 0
Training loss: 0.304537296295166
Validation loss: 2.0646636188030243

Epoch: 5| Step: 1
Training loss: 0.47326335310935974
Validation loss: 2.0839576721191406

Epoch: 5| Step: 2
Training loss: 0.29574427008628845
Validation loss: 2.0845631857713065

Epoch: 5| Step: 3
Training loss: 0.24778859317302704
Validation loss: 2.0622842411200204

Epoch: 5| Step: 4
Training loss: 0.37552982568740845
Validation loss: 2.1184538155794144

Epoch: 5| Step: 5
Training loss: 0.316284716129303
Validation loss: 2.0929226726293564

Epoch: 5| Step: 6
Training loss: 0.18892544507980347
Validation loss: 2.057445764541626

Epoch: 5| Step: 7
Training loss: 0.28402960300445557
Validation loss: 2.1063185383876166

Epoch: 5| Step: 8
Training loss: 0.5377888679504395
Validation loss: 2.132170870900154

Epoch: 5| Step: 9
Training loss: 0.34356996417045593
Validation loss: 2.1226903796195984

Epoch: 5| Step: 10
Training loss: 0.24639733135700226
Validation loss: 2.141325588027636

Epoch: 5| Step: 11
Training loss: 0.47669434547424316
Validation loss: 2.137357364098231

Epoch: 511| Step: 0
Training loss: 0.17773425579071045
Validation loss: 2.1243844429651895

Epoch: 5| Step: 1
Training loss: 0.31889456510543823
Validation loss: 2.091441030303637

Epoch: 5| Step: 2
Training loss: 0.19649136066436768
Validation loss: 2.1204088032245636

Epoch: 5| Step: 3
Training loss: 0.37824946641921997
Validation loss: 2.0890901933113732

Epoch: 5| Step: 4
Training loss: 0.29215943813323975
Validation loss: 2.1072528958320618

Epoch: 5| Step: 5
Training loss: 0.3771522045135498
Validation loss: 2.1055880586306253

Epoch: 5| Step: 6
Training loss: 0.2887212038040161
Validation loss: 2.107402116060257

Epoch: 5| Step: 7
Training loss: 0.17388157546520233
Validation loss: 2.107229004303614

Epoch: 5| Step: 8
Training loss: 0.684237539768219
Validation loss: 2.13281586766243

Epoch: 5| Step: 9
Training loss: 0.3874647319316864
Validation loss: 2.1173441112041473

Epoch: 5| Step: 10
Training loss: 0.343478262424469
Validation loss: 2.121696655948957

Epoch: 5| Step: 11
Training loss: 0.023187369108200073
Validation loss: 2.089737464984258

Epoch: 512| Step: 0
Training loss: 0.3469904661178589
Validation loss: 2.1087091118097305

Epoch: 5| Step: 1
Training loss: 0.5495794415473938
Validation loss: 2.0779896477858224

Epoch: 5| Step: 2
Training loss: 0.14607906341552734
Validation loss: 2.0665197173754373

Epoch: 5| Step: 3
Training loss: 0.37690725922584534
Validation loss: 2.0929463555415473

Epoch: 5| Step: 4
Training loss: 0.19942381978034973
Validation loss: 2.115994080901146

Epoch: 5| Step: 5
Training loss: 0.28740498423576355
Validation loss: 2.1144308298826218

Epoch: 5| Step: 6
Training loss: 0.1857808381319046
Validation loss: 2.0666474103927612

Epoch: 5| Step: 7
Training loss: 0.3145950436592102
Validation loss: 2.097117558121681

Epoch: 5| Step: 8
Training loss: 0.49899688363075256
Validation loss: 2.082263926664988

Epoch: 5| Step: 9
Training loss: 0.2388163059949875
Validation loss: 2.0925415058930716

Epoch: 5| Step: 10
Training loss: 0.3865000009536743
Validation loss: 2.1332577764987946

Epoch: 5| Step: 11
Training loss: 0.23102247714996338
Validation loss: 2.095002810160319

Epoch: 513| Step: 0
Training loss: 0.37669965624809265
Validation loss: 2.0899822314580283

Epoch: 5| Step: 1
Training loss: 0.4598625600337982
Validation loss: 2.1106905738512673

Epoch: 5| Step: 2
Training loss: 0.24498334527015686
Validation loss: 2.1349812050660453

Epoch: 5| Step: 3
Training loss: 0.19705308973789215
Validation loss: 2.0761613845825195

Epoch: 5| Step: 4
Training loss: 0.33214670419692993
Validation loss: 2.1185396860043206

Epoch: 5| Step: 5
Training loss: 0.3523526191711426
Validation loss: 2.109103019038836

Epoch: 5| Step: 6
Training loss: 0.6371225118637085
Validation loss: 2.0914772152900696

Epoch: 5| Step: 7
Training loss: 0.47962793707847595
Validation loss: 2.110746016105016

Epoch: 5| Step: 8
Training loss: 0.2073727548122406
Validation loss: 2.033024544517199

Epoch: 5| Step: 9
Training loss: 0.3537013530731201
Validation loss: 2.1415642152229943

Epoch: 5| Step: 10
Training loss: 0.24580097198486328
Validation loss: 2.1363252798716226

Epoch: 5| Step: 11
Training loss: 0.356815367937088
Validation loss: 2.121675839026769

Epoch: 514| Step: 0
Training loss: 0.4254337251186371
Validation loss: 2.1424934218327203

Epoch: 5| Step: 1
Training loss: 0.22181276977062225
Validation loss: 2.096327612797419

Epoch: 5| Step: 2
Training loss: 0.2785743772983551
Validation loss: 2.1235092928012214

Epoch: 5| Step: 3
Training loss: 0.19749680161476135
Validation loss: 2.1009018818537393

Epoch: 5| Step: 4
Training loss: 0.3772808015346527
Validation loss: 2.1285962810118995

Epoch: 5| Step: 5
Training loss: 0.3700295388698578
Validation loss: 2.0997464706500373

Epoch: 5| Step: 6
Training loss: 0.7347890734672546
Validation loss: 2.0889270653327308

Epoch: 5| Step: 7
Training loss: 0.40907877683639526
Validation loss: 2.077748636404673

Epoch: 5| Step: 8
Training loss: 0.2298048436641693
Validation loss: 2.106199954946836

Epoch: 5| Step: 9
Training loss: 0.27583444118499756
Validation loss: 2.0840124090512595

Epoch: 5| Step: 10
Training loss: 0.2111935168504715
Validation loss: 2.094753220677376

Epoch: 5| Step: 11
Training loss: 0.6127942800521851
Validation loss: 2.0993144810199738

Epoch: 515| Step: 0
Training loss: 0.38313427567481995
Validation loss: 2.136555314064026

Epoch: 5| Step: 1
Training loss: 0.42182308435440063
Validation loss: 2.1416246791680655

Epoch: 5| Step: 2
Training loss: 0.2336229830980301
Validation loss: 2.1410116255283356

Epoch: 5| Step: 3
Training loss: 0.25239333510398865
Validation loss: 2.13828906416893

Epoch: 5| Step: 4
Training loss: 0.4534282088279724
Validation loss: 2.1015524019797645

Epoch: 5| Step: 5
Training loss: 0.17853377759456635
Validation loss: 2.1182130624850593

Epoch: 5| Step: 6
Training loss: 0.30186423659324646
Validation loss: 2.1198772539695105

Epoch: 5| Step: 7
Training loss: 0.5440349578857422
Validation loss: 2.0969918916622796

Epoch: 5| Step: 8
Training loss: 0.44595640897750854
Validation loss: 2.120583767692248

Epoch: 5| Step: 9
Training loss: 0.36772626638412476
Validation loss: 2.0956530769666037

Epoch: 5| Step: 10
Training loss: 0.25474146008491516
Validation loss: 2.132677594820658

Epoch: 5| Step: 11
Training loss: 0.12346373498439789
Validation loss: 2.1331225832303367

Epoch: 516| Step: 0
Training loss: 0.20077912509441376
Validation loss: 2.1500591983397803

Epoch: 5| Step: 1
Training loss: 0.38287872076034546
Validation loss: 2.147903248667717

Epoch: 5| Step: 2
Training loss: 0.35309624671936035
Validation loss: 2.180361951390902

Epoch: 5| Step: 3
Training loss: 0.27171579003334045
Validation loss: 2.0900547007719674

Epoch: 5| Step: 4
Training loss: 0.3959107995033264
Validation loss: 2.1061830470959344

Epoch: 5| Step: 5
Training loss: 0.2852434515953064
Validation loss: 2.098692829410235

Epoch: 5| Step: 6
Training loss: 0.4199151396751404
Validation loss: 2.0971801032622657

Epoch: 5| Step: 7
Training loss: 0.3710485100746155
Validation loss: 2.1157287458578744

Epoch: 5| Step: 8
Training loss: 0.33032235503196716
Validation loss: 2.098190108935038

Epoch: 5| Step: 9
Training loss: 0.23465943336486816
Validation loss: 2.091470276316007

Epoch: 5| Step: 10
Training loss: 0.2999975085258484
Validation loss: 2.0421213606993356

Epoch: 5| Step: 11
Training loss: 0.31715208292007446
Validation loss: 2.0875196357568107

Epoch: 517| Step: 0
Training loss: 0.6671251058578491
Validation loss: 2.115233287215233

Epoch: 5| Step: 1
Training loss: 0.24914467334747314
Validation loss: 2.1587062825759253

Epoch: 5| Step: 2
Training loss: 0.3305419087409973
Validation loss: 2.0891291201114655

Epoch: 5| Step: 3
Training loss: 0.22296445071697235
Validation loss: 2.1476273288329444

Epoch: 5| Step: 4
Training loss: 0.37740424275398254
Validation loss: 2.1614198833703995

Epoch: 5| Step: 5
Training loss: 0.311998188495636
Validation loss: 2.153047129511833

Epoch: 5| Step: 6
Training loss: 0.3078143000602722
Validation loss: 2.116340617338816

Epoch: 5| Step: 7
Training loss: 0.2898978888988495
Validation loss: 2.1232614318529763

Epoch: 5| Step: 8
Training loss: 0.3394925892353058
Validation loss: 2.1078429917494454

Epoch: 5| Step: 9
Training loss: 0.35377034544944763
Validation loss: 2.091362083951632

Epoch: 5| Step: 10
Training loss: 0.39650875329971313
Validation loss: 2.0775764832894006

Epoch: 5| Step: 11
Training loss: 0.08022171258926392
Validation loss: 2.1181988020737967

Epoch: 518| Step: 0
Training loss: 0.4248369336128235
Validation loss: 2.138079504172007

Epoch: 5| Step: 1
Training loss: 0.463432252407074
Validation loss: 2.128293658296267

Epoch: 5| Step: 2
Training loss: 0.38855230808258057
Validation loss: 2.1131134182214737

Epoch: 5| Step: 3
Training loss: 0.3426043391227722
Validation loss: 2.1241192519664764

Epoch: 5| Step: 4
Training loss: 0.2670195698738098
Validation loss: 2.1186927358309426

Epoch: 5| Step: 5
Training loss: 0.34646835923194885
Validation loss: 2.049289877216021

Epoch: 5| Step: 6
Training loss: 0.29060396552085876
Validation loss: 2.0797331730524697

Epoch: 5| Step: 7
Training loss: 0.5555402040481567
Validation loss: 2.106076324979464

Epoch: 5| Step: 8
Training loss: 0.44353026151657104
Validation loss: 2.08387357989947

Epoch: 5| Step: 9
Training loss: 0.2944319546222687
Validation loss: 2.118534798423449

Epoch: 5| Step: 10
Training loss: 0.4298937916755676
Validation loss: 2.0326751470565796

Epoch: 5| Step: 11
Training loss: 0.20978033542633057
Validation loss: 2.0789756129185357

Epoch: 519| Step: 0
Training loss: 0.4089500308036804
Validation loss: 2.082919716835022

Epoch: 5| Step: 1
Training loss: 0.22803768515586853
Validation loss: 2.060707226395607

Epoch: 5| Step: 2
Training loss: 0.2983327805995941
Validation loss: 2.087889149785042

Epoch: 5| Step: 3
Training loss: 0.24520769715309143
Validation loss: 2.04207851489385

Epoch: 5| Step: 4
Training loss: 0.36279767751693726
Validation loss: 2.0318631380796432

Epoch: 5| Step: 5
Training loss: 0.3716273605823517
Validation loss: 2.074932724237442

Epoch: 5| Step: 6
Training loss: 0.1955549418926239
Validation loss: 2.094627613822619

Epoch: 5| Step: 7
Training loss: 0.5717320442199707
Validation loss: 2.1215039740006127

Epoch: 5| Step: 8
Training loss: 0.317631334066391
Validation loss: 2.0766153633594513

Epoch: 5| Step: 9
Training loss: 0.43689361214637756
Validation loss: 2.0542198369900384

Epoch: 5| Step: 10
Training loss: 0.29505428671836853
Validation loss: 2.0783648639917374

Epoch: 5| Step: 11
Training loss: 0.3713277578353882
Validation loss: 2.0966734935839972

Epoch: 520| Step: 0
Training loss: 0.21662378311157227
Validation loss: 2.06832192838192

Epoch: 5| Step: 1
Training loss: 0.32297247648239136
Validation loss: 2.0591305991013846

Epoch: 5| Step: 2
Training loss: 0.38627421855926514
Validation loss: 2.0709130416313806

Epoch: 5| Step: 3
Training loss: 0.44831520318984985
Validation loss: 2.0842493226130805

Epoch: 5| Step: 4
Training loss: 0.31769129633903503
Validation loss: 2.0749627202749252

Epoch: 5| Step: 5
Training loss: 0.22079792618751526
Validation loss: 2.1002157827218375

Epoch: 5| Step: 6
Training loss: 0.24521079659461975
Validation loss: 2.119110196828842

Epoch: 5| Step: 7
Training loss: 0.4856376647949219
Validation loss: 2.0866400649150214

Epoch: 5| Step: 8
Training loss: 0.3605102598667145
Validation loss: 2.1154004335403442

Epoch: 5| Step: 9
Training loss: 0.6067122220993042
Validation loss: 2.110848128795624

Epoch: 5| Step: 10
Training loss: 0.31524989008903503
Validation loss: 2.103443960348765

Epoch: 5| Step: 11
Training loss: 0.8290125727653503
Validation loss: 2.072887644171715

Epoch: 521| Step: 0
Training loss: 0.36056122183799744
Validation loss: 2.103591168920199

Epoch: 5| Step: 1
Training loss: 0.4108845293521881
Validation loss: 2.0954111168781915

Epoch: 5| Step: 2
Training loss: 0.1852962225675583
Validation loss: 2.0708524833122888

Epoch: 5| Step: 3
Training loss: 0.1940137892961502
Validation loss: 2.0736341973145804

Epoch: 5| Step: 4
Training loss: 0.5451240539550781
Validation loss: 2.0802065481742225

Epoch: 5| Step: 5
Training loss: 0.3690893054008484
Validation loss: 2.0977478275696435

Epoch: 5| Step: 6
Training loss: 0.25979477167129517
Validation loss: 2.124666308363279

Epoch: 5| Step: 7
Training loss: 0.3510747253894806
Validation loss: 2.1142036418120065

Epoch: 5| Step: 8
Training loss: 0.4403238296508789
Validation loss: 2.094619005918503

Epoch: 5| Step: 9
Training loss: 0.16917923092842102
Validation loss: 2.1095365285873413

Epoch: 5| Step: 10
Training loss: 0.1974906027317047
Validation loss: 2.0855572621027627

Epoch: 5| Step: 11
Training loss: 0.4615687429904938
Validation loss: 2.085412542025248

Epoch: 522| Step: 0
Training loss: 0.6388594508171082
Validation loss: 2.101326361298561

Epoch: 5| Step: 1
Training loss: 0.3830011487007141
Validation loss: 2.1086665391921997

Epoch: 5| Step: 2
Training loss: 0.323270708322525
Validation loss: 2.0520818531513214

Epoch: 5| Step: 3
Training loss: 0.4645121991634369
Validation loss: 2.086775297919909

Epoch: 5| Step: 4
Training loss: 0.23372285068035126
Validation loss: 2.1090579678614936

Epoch: 5| Step: 5
Training loss: 0.13340458273887634
Validation loss: 2.0824736058712006

Epoch: 5| Step: 6
Training loss: 0.29615718126296997
Validation loss: 2.0980985363324485

Epoch: 5| Step: 7
Training loss: 0.3558269143104553
Validation loss: 2.092228760321935

Epoch: 5| Step: 8
Training loss: 0.18304747343063354
Validation loss: 2.1024055778980255

Epoch: 5| Step: 9
Training loss: 0.31790339946746826
Validation loss: 2.132552986343702

Epoch: 5| Step: 10
Training loss: 0.25357115268707275
Validation loss: 2.0821520388126373

Epoch: 5| Step: 11
Training loss: 0.16072434186935425
Validation loss: 2.0763790557781854

Epoch: 523| Step: 0
Training loss: 0.40777015686035156
Validation loss: 2.0775861789782843

Epoch: 5| Step: 1
Training loss: 0.28497859835624695
Validation loss: 2.1041975617408752

Epoch: 5| Step: 2
Training loss: 0.2873691916465759
Validation loss: 2.115380123257637

Epoch: 5| Step: 3
Training loss: 0.3485201895236969
Validation loss: 2.0937635749578476

Epoch: 5| Step: 4
Training loss: 0.4379241466522217
Validation loss: 2.0849712193012238

Epoch: 5| Step: 5
Training loss: 0.4008913040161133
Validation loss: 2.0835143278042474

Epoch: 5| Step: 6
Training loss: 0.2129192352294922
Validation loss: 2.128016874194145

Epoch: 5| Step: 7
Training loss: 0.36780714988708496
Validation loss: 2.1152906268835068

Epoch: 5| Step: 8
Training loss: 0.671448826789856
Validation loss: 2.074321443835894

Epoch: 5| Step: 9
Training loss: 0.48859095573425293
Validation loss: 2.111129437883695

Epoch: 5| Step: 10
Training loss: 0.21138668060302734
Validation loss: 2.0937568694353104

Epoch: 5| Step: 11
Training loss: 0.22305786609649658
Validation loss: 2.072339102625847

Epoch: 524| Step: 0
Training loss: 0.2920904755592346
Validation loss: 2.1074822743733725

Epoch: 5| Step: 1
Training loss: 0.33629173040390015
Validation loss: 2.1138822535673776

Epoch: 5| Step: 2
Training loss: 0.24801044166088104
Validation loss: 2.0933284064133963

Epoch: 5| Step: 3
Training loss: 0.38522034883499146
Validation loss: 2.0963381081819534

Epoch: 5| Step: 4
Training loss: 0.3815564215183258
Validation loss: 2.086412658294042

Epoch: 5| Step: 5
Training loss: 0.18492022156715393
Validation loss: 2.083225737015406

Epoch: 5| Step: 6
Training loss: 0.30299025774002075
Validation loss: 2.1208492517471313

Epoch: 5| Step: 7
Training loss: 0.20942945778369904
Validation loss: 2.0907703240712485

Epoch: 5| Step: 8
Training loss: 0.41941386461257935
Validation loss: 2.0756374448537827

Epoch: 5| Step: 9
Training loss: 0.28250494599342346
Validation loss: 2.0772418876489005

Epoch: 5| Step: 10
Training loss: 0.46680253744125366
Validation loss: 2.141934687892596

Epoch: 5| Step: 11
Training loss: 0.22783219814300537
Validation loss: 2.11110512415568

Epoch: 525| Step: 0
Training loss: 0.21057507395744324
Validation loss: 2.0925284922122955

Epoch: 5| Step: 1
Training loss: 0.4438978135585785
Validation loss: 2.0902036378781

Epoch: 5| Step: 2
Training loss: 0.5385100245475769
Validation loss: 2.0957681934038797

Epoch: 5| Step: 3
Training loss: 0.18981121480464935
Validation loss: 2.0697617679834366

Epoch: 5| Step: 4
Training loss: 0.21440379321575165
Validation loss: 2.110224033395449

Epoch: 5| Step: 5
Training loss: 0.3291529715061188
Validation loss: 2.0546833078066506

Epoch: 5| Step: 6
Training loss: 0.23100054264068604
Validation loss: 2.047247514128685

Epoch: 5| Step: 7
Training loss: 0.3294093608856201
Validation loss: 2.0775864173968634

Epoch: 5| Step: 8
Training loss: 0.46938785910606384
Validation loss: 2.1015803068876266

Epoch: 5| Step: 9
Training loss: 0.40780895948410034
Validation loss: 2.135726903875669

Epoch: 5| Step: 10
Training loss: 0.30095118284225464
Validation loss: 2.111099655429522

Epoch: 5| Step: 11
Training loss: 0.3589094877243042
Validation loss: 2.0966205398241677

Epoch: 526| Step: 0
Training loss: 0.45981207489967346
Validation loss: 2.064981530110041

Epoch: 5| Step: 1
Training loss: 0.2896069586277008
Validation loss: 2.076252947251002

Epoch: 5| Step: 2
Training loss: 0.4594655930995941
Validation loss: 2.0709513376156488

Epoch: 5| Step: 3
Training loss: 0.30010706186294556
Validation loss: 2.105420549710592

Epoch: 5| Step: 4
Training loss: 0.27095848321914673
Validation loss: 2.0761420925458274

Epoch: 5| Step: 5
Training loss: 0.4095519483089447
Validation loss: 2.1003102312485376

Epoch: 5| Step: 6
Training loss: 0.45293134450912476
Validation loss: 2.0210705449183783

Epoch: 5| Step: 7
Training loss: 0.1862780749797821
Validation loss: 2.0667869299650192

Epoch: 5| Step: 8
Training loss: 0.3431752920150757
Validation loss: 2.095182811220487

Epoch: 5| Step: 9
Training loss: 0.19936449825763702
Validation loss: 2.0753528475761414

Epoch: 5| Step: 10
Training loss: 0.25184911489486694
Validation loss: 2.067759176095327

Epoch: 5| Step: 11
Training loss: 0.11748203635215759
Validation loss: 2.0892277459303537

Epoch: 527| Step: 0
Training loss: 0.49042564630508423
Validation loss: 2.033635770281156

Epoch: 5| Step: 1
Training loss: 0.20953261852264404
Validation loss: 2.0799222389856973

Epoch: 5| Step: 2
Training loss: 0.2445162832736969
Validation loss: 2.0530172983805337

Epoch: 5| Step: 3
Training loss: 0.3191928267478943
Validation loss: 2.0825919210910797

Epoch: 5| Step: 4
Training loss: 0.305808961391449
Validation loss: 2.1006049811840057

Epoch: 5| Step: 5
Training loss: 0.31938260793685913
Validation loss: 2.0519083787997565

Epoch: 5| Step: 6
Training loss: 0.5543522238731384
Validation loss: 2.102852910757065

Epoch: 5| Step: 7
Training loss: 0.3290289640426636
Validation loss: 2.058194691936175

Epoch: 5| Step: 8
Training loss: 0.2414398491382599
Validation loss: 2.0977092186609902

Epoch: 5| Step: 9
Training loss: 0.39370593428611755
Validation loss: 2.0891102651755014

Epoch: 5| Step: 10
Training loss: 0.3128184974193573
Validation loss: 2.111656586329142

Epoch: 5| Step: 11
Training loss: 0.13634592294692993
Validation loss: 2.0862898379564285

Epoch: 528| Step: 0
Training loss: 0.3427058458328247
Validation loss: 2.0781992971897125

Epoch: 5| Step: 1
Training loss: 0.427659273147583
Validation loss: 2.115689386924108

Epoch: 5| Step: 2
Training loss: 0.19069847464561462
Validation loss: 2.1172342548767724

Epoch: 5| Step: 3
Training loss: 0.33180707693099976
Validation loss: 2.1437742511431375

Epoch: 5| Step: 4
Training loss: 0.40128979086875916
Validation loss: 2.0995151102542877

Epoch: 5| Step: 5
Training loss: 0.22618183493614197
Validation loss: 2.141538773973783

Epoch: 5| Step: 6
Training loss: 0.22264596819877625
Validation loss: 2.1034496277570724

Epoch: 5| Step: 7
Training loss: 0.48068031668663025
Validation loss: 2.110656941930453

Epoch: 5| Step: 8
Training loss: 0.3499082922935486
Validation loss: 2.1034064342578254

Epoch: 5| Step: 9
Training loss: 0.2507682740688324
Validation loss: 2.12699722747008

Epoch: 5| Step: 10
Training loss: 0.33229702711105347
Validation loss: 2.117947369813919

Epoch: 5| Step: 11
Training loss: 0.2326090931892395
Validation loss: 2.110002115368843

Epoch: 529| Step: 0
Training loss: 0.4929320216178894
Validation loss: 2.082481801509857

Epoch: 5| Step: 1
Training loss: 0.590691864490509
Validation loss: 2.0678484390179315

Epoch: 5| Step: 2
Training loss: 0.22428174316883087
Validation loss: 2.0854919453461966

Epoch: 5| Step: 3
Training loss: 0.48939695954322815
Validation loss: 2.0749636689821878

Epoch: 5| Step: 4
Training loss: 0.19384589791297913
Validation loss: 2.074089671174685

Epoch: 5| Step: 5
Training loss: 0.20611944794654846
Validation loss: 2.0474720299243927

Epoch: 5| Step: 6
Training loss: 0.33765560388565063
Validation loss: 2.0918784538904824

Epoch: 5| Step: 7
Training loss: 0.2999219000339508
Validation loss: 2.108682855963707

Epoch: 5| Step: 8
Training loss: 0.2976679801940918
Validation loss: 2.086034173766772

Epoch: 5| Step: 9
Training loss: 0.3339167535305023
Validation loss: 2.0893912514050803

Epoch: 5| Step: 10
Training loss: 0.20225217938423157
Validation loss: 2.100093891223272

Epoch: 5| Step: 11
Training loss: 0.1988428831100464
Validation loss: 2.077039216955503

Epoch: 530| Step: 0
Training loss: 0.37972116470336914
Validation loss: 2.1229160775740943

Epoch: 5| Step: 1
Training loss: 0.16966772079467773
Validation loss: 2.098359336455663

Epoch: 5| Step: 2
Training loss: 0.18995872139930725
Validation loss: 2.1112807343403497

Epoch: 5| Step: 3
Training loss: 0.1434096246957779
Validation loss: 2.0973617136478424

Epoch: 5| Step: 4
Training loss: 0.2494935542345047
Validation loss: 2.0914955536524453

Epoch: 5| Step: 5
Training loss: 0.26892155408859253
Validation loss: 2.0955246488253274

Epoch: 5| Step: 6
Training loss: 0.23387646675109863
Validation loss: 2.088577186067899

Epoch: 5| Step: 7
Training loss: 0.38018521666526794
Validation loss: 2.1011882225672402

Epoch: 5| Step: 8
Training loss: 0.4035619795322418
Validation loss: 2.0804562916358313

Epoch: 5| Step: 9
Training loss: 0.509889543056488
Validation loss: 2.1246595730384192

Epoch: 5| Step: 10
Training loss: 0.2343885898590088
Validation loss: 2.0882020195325217

Epoch: 5| Step: 11
Training loss: 0.17056164145469666
Validation loss: 2.108707090218862

Epoch: 531| Step: 0
Training loss: 0.3200318217277527
Validation loss: 2.094266469279925

Epoch: 5| Step: 1
Training loss: 0.3422631621360779
Validation loss: 2.080772484342257

Epoch: 5| Step: 2
Training loss: 0.5742096900939941
Validation loss: 2.09442072113355

Epoch: 5| Step: 3
Training loss: 0.19203701615333557
Validation loss: 2.1082131266593933

Epoch: 5| Step: 4
Training loss: 0.3503427803516388
Validation loss: 2.0674812396367392

Epoch: 5| Step: 5
Training loss: 0.34160733222961426
Validation loss: 2.114781975746155

Epoch: 5| Step: 6
Training loss: 0.2924545407295227
Validation loss: 2.0888508955637612

Epoch: 5| Step: 7
Training loss: 0.2298288643360138
Validation loss: 2.077681536475817

Epoch: 5| Step: 8
Training loss: 0.5849810838699341
Validation loss: 2.0712122172117233

Epoch: 5| Step: 9
Training loss: 0.25818824768066406
Validation loss: 2.0921433717012405

Epoch: 5| Step: 10
Training loss: 0.2520068287849426
Validation loss: 2.0748517960309982

Epoch: 5| Step: 11
Training loss: 0.19138234853744507
Validation loss: 2.086059590180715

Epoch: 532| Step: 0
Training loss: 0.37337595224380493
Validation loss: 2.07277804116408

Epoch: 5| Step: 1
Training loss: 0.4796658456325531
Validation loss: 2.0632146100203195

Epoch: 5| Step: 2
Training loss: 0.386182963848114
Validation loss: 2.0738788892825446

Epoch: 5| Step: 3
Training loss: 0.3323373794555664
Validation loss: 2.0418354670206704

Epoch: 5| Step: 4
Training loss: 0.39268454909324646
Validation loss: 2.091085895895958

Epoch: 5| Step: 5
Training loss: 0.16840529441833496
Validation loss: 2.1202754179636636

Epoch: 5| Step: 6
Training loss: 0.23238129913806915
Validation loss: 2.145361994703611

Epoch: 5| Step: 7
Training loss: 0.3028126060962677
Validation loss: 2.123668298125267

Epoch: 5| Step: 8
Training loss: 0.22111335396766663
Validation loss: 2.106733039021492

Epoch: 5| Step: 9
Training loss: 0.4725831151008606
Validation loss: 2.100606600443522

Epoch: 5| Step: 10
Training loss: 0.19619598984718323
Validation loss: 2.0487496008475623

Epoch: 5| Step: 11
Training loss: 0.0993291437625885
Validation loss: 2.0827421049276986

Epoch: 533| Step: 0
Training loss: 0.2448311299085617
Validation loss: 2.0477880040804544

Epoch: 5| Step: 1
Training loss: 0.3313043713569641
Validation loss: 2.094557046890259

Epoch: 5| Step: 2
Training loss: 0.22016319632530212
Validation loss: 2.0653861115376153

Epoch: 5| Step: 3
Training loss: 0.4245120882987976
Validation loss: 2.1200673977533975

Epoch: 5| Step: 4
Training loss: 0.12339866161346436
Validation loss: 2.1042853196461997

Epoch: 5| Step: 5
Training loss: 0.41467970609664917
Validation loss: 2.095949371655782

Epoch: 5| Step: 6
Training loss: 0.2719060778617859
Validation loss: 2.068944126367569

Epoch: 5| Step: 7
Training loss: 0.5765385627746582
Validation loss: 2.105364282925924

Epoch: 5| Step: 8
Training loss: 0.6854320168495178
Validation loss: 2.0949854105710983

Epoch: 5| Step: 9
Training loss: 0.3560029864311218
Validation loss: 2.0911916345357895

Epoch: 5| Step: 10
Training loss: 0.23425468802452087
Validation loss: 2.098906214038531

Epoch: 5| Step: 11
Training loss: 0.2394399642944336
Validation loss: 2.1186093787352243

Epoch: 534| Step: 0
Training loss: 0.24488547444343567
Validation loss: 2.1031200339396796

Epoch: 5| Step: 1
Training loss: 0.2992340922355652
Validation loss: 2.0577211678028107

Epoch: 5| Step: 2
Training loss: 0.44348740577697754
Validation loss: 2.091932401061058

Epoch: 5| Step: 3
Training loss: 0.1922605335712433
Validation loss: 2.0749450425306954

Epoch: 5| Step: 4
Training loss: 0.21563637256622314
Validation loss: 2.0870954990386963

Epoch: 5| Step: 5
Training loss: 0.45152217149734497
Validation loss: 2.091880371173223

Epoch: 5| Step: 6
Training loss: 0.5456757545471191
Validation loss: 2.106994221607844

Epoch: 5| Step: 7
Training loss: 0.2678479254245758
Validation loss: 2.101948161919912

Epoch: 5| Step: 8
Training loss: 0.27956148982048035
Validation loss: 2.073093980550766

Epoch: 5| Step: 9
Training loss: 0.31736499071121216
Validation loss: 2.140429198741913

Epoch: 5| Step: 10
Training loss: 0.5882678031921387
Validation loss: 2.100763350725174

Epoch: 5| Step: 11
Training loss: 0.24857422709465027
Validation loss: 2.0588994125525155

Epoch: 535| Step: 0
Training loss: 0.24034127593040466
Validation loss: 2.03674279153347

Epoch: 5| Step: 1
Training loss: 0.3066283166408539
Validation loss: 2.0792423685391745

Epoch: 5| Step: 2
Training loss: 0.2856604754924774
Validation loss: 2.110054607192675

Epoch: 5| Step: 3
Training loss: 0.4579387605190277
Validation loss: 2.0943895876407623

Epoch: 5| Step: 4
Training loss: 0.1951402872800827
Validation loss: 2.0890592485666275

Epoch: 5| Step: 5
Training loss: 0.36405596137046814
Validation loss: 2.0590181847413382

Epoch: 5| Step: 6
Training loss: 0.26655495166778564
Validation loss: 2.11215673883756

Epoch: 5| Step: 7
Training loss: 0.3350779116153717
Validation loss: 2.096806218226751

Epoch: 5| Step: 8
Training loss: 0.2717720568180084
Validation loss: 2.1013622333606086

Epoch: 5| Step: 9
Training loss: 0.5427056550979614
Validation loss: 2.0974262207746506

Epoch: 5| Step: 10
Training loss: 0.3148409426212311
Validation loss: 2.1453401893377304

Epoch: 5| Step: 11
Training loss: 0.35049009323120117
Validation loss: 2.1014537463585534

Epoch: 536| Step: 0
Training loss: 0.382059246301651
Validation loss: 2.124033287167549

Epoch: 5| Step: 1
Training loss: 0.2405991554260254
Validation loss: 2.1462799410025277

Epoch: 5| Step: 2
Training loss: 0.49429672956466675
Validation loss: 2.078849842151006

Epoch: 5| Step: 3
Training loss: 0.49021443724632263
Validation loss: 2.1220883578062057

Epoch: 5| Step: 4
Training loss: 0.2351139783859253
Validation loss: 2.1163201481103897

Epoch: 5| Step: 5
Training loss: 0.34648552536964417
Validation loss: 2.1048101087411246

Epoch: 5| Step: 6
Training loss: 0.22320064902305603
Validation loss: 2.1310423562924066

Epoch: 5| Step: 7
Training loss: 0.36876440048217773
Validation loss: 2.10288734237353

Epoch: 5| Step: 8
Training loss: 0.22658085823059082
Validation loss: 2.1350246568520865

Epoch: 5| Step: 9
Training loss: 0.253897488117218
Validation loss: 2.089133227864901

Epoch: 5| Step: 10
Training loss: 0.21383941173553467
Validation loss: 2.069020147124926

Epoch: 5| Step: 11
Training loss: 0.1321842074394226
Validation loss: 2.114504555861155

Epoch: 537| Step: 0
Training loss: 0.2899355888366699
Validation loss: 2.1558173298835754

Epoch: 5| Step: 1
Training loss: 0.2282092571258545
Validation loss: 2.0969919115304947

Epoch: 5| Step: 2
Training loss: 0.2419145405292511
Validation loss: 2.085998718937238

Epoch: 5| Step: 3
Training loss: 0.22446712851524353
Validation loss: 2.078881651163101

Epoch: 5| Step: 4
Training loss: 0.5291463732719421
Validation loss: 2.1159713665644326

Epoch: 5| Step: 5
Training loss: 0.32173818349838257
Validation loss: 2.086231971780459

Epoch: 5| Step: 6
Training loss: 0.5960140228271484
Validation loss: 2.0956404358148575

Epoch: 5| Step: 7
Training loss: 0.3195599913597107
Validation loss: 2.124765321612358

Epoch: 5| Step: 8
Training loss: 0.19941170513629913
Validation loss: 2.101999908685684

Epoch: 5| Step: 9
Training loss: 0.2258192002773285
Validation loss: 2.0851588249206543

Epoch: 5| Step: 10
Training loss: 0.3406468331813812
Validation loss: 2.0982777774333954

Epoch: 5| Step: 11
Training loss: 0.4443321228027344
Validation loss: 2.083193009098371

Epoch: 538| Step: 0
Training loss: 0.2985249161720276
Validation loss: 2.0880880057811737

Epoch: 5| Step: 1
Training loss: 0.5218216180801392
Validation loss: 2.0503702014684677

Epoch: 5| Step: 2
Training loss: 0.25470471382141113
Validation loss: 2.065514196952184

Epoch: 5| Step: 3
Training loss: 0.4370175898075104
Validation loss: 2.044297600785891

Epoch: 5| Step: 4
Training loss: 0.40550750494003296
Validation loss: 2.0941960910956063

Epoch: 5| Step: 5
Training loss: 0.254595547914505
Validation loss: 2.096240282058716

Epoch: 5| Step: 6
Training loss: 0.44541463255882263
Validation loss: 2.078779156009356

Epoch: 5| Step: 7
Training loss: 0.2688472867012024
Validation loss: 2.074983095129331

Epoch: 5| Step: 8
Training loss: 0.37225764989852905
Validation loss: 2.082905570665995

Epoch: 5| Step: 9
Training loss: 0.355823814868927
Validation loss: 2.0656446317831674

Epoch: 5| Step: 10
Training loss: 0.2676495611667633
Validation loss: 2.1071106841166816

Epoch: 5| Step: 11
Training loss: 0.2041243016719818
Validation loss: 2.084456145763397

Epoch: 539| Step: 0
Training loss: 0.41018620133399963
Validation loss: 2.0781960437695184

Epoch: 5| Step: 1
Training loss: 0.2064450979232788
Validation loss: 2.0795517563819885

Epoch: 5| Step: 2
Training loss: 0.29446354508399963
Validation loss: 2.098235845565796

Epoch: 5| Step: 3
Training loss: 0.18469367921352386
Validation loss: 2.075794448455175

Epoch: 5| Step: 4
Training loss: 0.20078611373901367
Validation loss: 2.0437403470277786

Epoch: 5| Step: 5
Training loss: 0.27346181869506836
Validation loss: 2.122188702225685

Epoch: 5| Step: 6
Training loss: 0.2632659077644348
Validation loss: 2.0856990267833075

Epoch: 5| Step: 7
Training loss: 0.27615994215011597
Validation loss: 2.050736422340075

Epoch: 5| Step: 8
Training loss: 0.3021678030490875
Validation loss: 2.096986338496208

Epoch: 5| Step: 9
Training loss: 0.33188533782958984
Validation loss: 2.060047924518585

Epoch: 5| Step: 10
Training loss: 0.509196400642395
Validation loss: 2.0495283057292304

Epoch: 5| Step: 11
Training loss: 1.2761518955230713
Validation loss: 2.0405850211779275

Epoch: 540| Step: 0
Training loss: 0.6639518141746521
Validation loss: 2.1099316527446113

Epoch: 5| Step: 1
Training loss: 0.26990336179733276
Validation loss: 2.077990169326464

Epoch: 5| Step: 2
Training loss: 0.19558189809322357
Validation loss: 2.0928056140740714

Epoch: 5| Step: 3
Training loss: 0.36688849329948425
Validation loss: 2.1260612110296884

Epoch: 5| Step: 4
Training loss: 0.2929973602294922
Validation loss: 2.117564926544825

Epoch: 5| Step: 5
Training loss: 0.188680499792099
Validation loss: 2.0949587573607764

Epoch: 5| Step: 6
Training loss: 0.23100130259990692
Validation loss: 2.1079364319642386

Epoch: 5| Step: 7
Training loss: 0.27299100160598755
Validation loss: 2.0979565580685935

Epoch: 5| Step: 8
Training loss: 0.49977216124534607
Validation loss: 2.104041854540507

Epoch: 5| Step: 9
Training loss: 0.3213244676589966
Validation loss: 2.1156506339708963

Epoch: 5| Step: 10
Training loss: 0.19463443756103516
Validation loss: 2.1021810273329415

Epoch: 5| Step: 11
Training loss: 0.25105512142181396
Validation loss: 2.1114034404357276

Epoch: 541| Step: 0
Training loss: 0.19922681152820587
Validation loss: 2.1335713813702264

Epoch: 5| Step: 1
Training loss: 0.4582260251045227
Validation loss: 2.157553215821584

Epoch: 5| Step: 2
Training loss: 0.3461633324623108
Validation loss: 2.1246092319488525

Epoch: 5| Step: 3
Training loss: 0.2411692589521408
Validation loss: 2.1085968613624573

Epoch: 5| Step: 4
Training loss: 0.3144579231739044
Validation loss: 2.0960415303707123

Epoch: 5| Step: 5
Training loss: 0.29684895277023315
Validation loss: 2.095159555474917

Epoch: 5| Step: 6
Training loss: 0.3590632677078247
Validation loss: 2.0657355884710946

Epoch: 5| Step: 7
Training loss: 0.2703428268432617
Validation loss: 2.0820879687865577

Epoch: 5| Step: 8
Training loss: 0.219818115234375
Validation loss: 2.12169615427653

Epoch: 5| Step: 9
Training loss: 0.25131505727767944
Validation loss: 2.1029938459396362

Epoch: 5| Step: 10
Training loss: 0.5087939500808716
Validation loss: 2.1106608708699546

Epoch: 5| Step: 11
Training loss: 0.3479432463645935
Validation loss: 2.0826249917348227

Epoch: 542| Step: 0
Training loss: 0.5583306550979614
Validation loss: 2.1055568009614944

Epoch: 5| Step: 1
Training loss: 0.5690688490867615
Validation loss: 2.1075109243392944

Epoch: 5| Step: 2
Training loss: 0.26342111825942993
Validation loss: 2.1661629676818848

Epoch: 5| Step: 3
Training loss: 0.24370984733104706
Validation loss: 2.10243089000384

Epoch: 5| Step: 4
Training loss: 0.2026841640472412
Validation loss: 2.1012725879748664

Epoch: 5| Step: 5
Training loss: 0.1734394133090973
Validation loss: 2.0796640863021216

Epoch: 5| Step: 6
Training loss: 0.404930979013443
Validation loss: 2.093655988574028

Epoch: 5| Step: 7
Training loss: 0.14033696055412292
Validation loss: 2.081274166703224

Epoch: 5| Step: 8
Training loss: 0.3625521957874298
Validation loss: 2.059892545143763

Epoch: 5| Step: 9
Training loss: 0.28817206621170044
Validation loss: 2.1035644809405007

Epoch: 5| Step: 10
Training loss: 0.2474605143070221
Validation loss: 2.083606332540512

Epoch: 5| Step: 11
Training loss: 0.5966779589653015
Validation loss: 2.071199655532837

Epoch: 543| Step: 0
Training loss: 0.2681044042110443
Validation loss: 2.1106858948866525

Epoch: 5| Step: 1
Training loss: 0.19575409591197968
Validation loss: 2.0889200816551843

Epoch: 5| Step: 2
Training loss: 0.45253926515579224
Validation loss: 2.0984599689642587

Epoch: 5| Step: 3
Training loss: 0.1758938729763031
Validation loss: 2.0919922639926276

Epoch: 5| Step: 4
Training loss: 0.18755874037742615
Validation loss: 2.0783910701672235

Epoch: 5| Step: 5
Training loss: 0.3793852627277374
Validation loss: 2.092626998821894

Epoch: 5| Step: 6
Training loss: 0.42497968673706055
Validation loss: 2.0859889537096024

Epoch: 5| Step: 7
Training loss: 0.23464560508728027
Validation loss: 2.102812518676122

Epoch: 5| Step: 8
Training loss: 0.6053527593612671
Validation loss: 2.0768777479728064

Epoch: 5| Step: 9
Training loss: 0.23127131164073944
Validation loss: 2.1037524193525314

Epoch: 5| Step: 10
Training loss: 0.24558012187480927
Validation loss: 2.1274189750353494

Epoch: 5| Step: 11
Training loss: 0.21854281425476074
Validation loss: 2.1086868941783905

Epoch: 544| Step: 0
Training loss: 0.3763551712036133
Validation loss: 2.113604207833608

Epoch: 5| Step: 1
Training loss: 0.17870283126831055
Validation loss: 2.101560413837433

Epoch: 5| Step: 2
Training loss: 0.19075936079025269
Validation loss: 2.0833828449249268

Epoch: 5| Step: 3
Training loss: 0.32589954137802124
Validation loss: 2.1053169270356498

Epoch: 5| Step: 4
Training loss: 0.3008600175380707
Validation loss: 2.0904876440763474

Epoch: 5| Step: 5
Training loss: 0.3429490029811859
Validation loss: 2.089097246527672

Epoch: 5| Step: 6
Training loss: 0.22647421061992645
Validation loss: 2.095717743039131

Epoch: 5| Step: 7
Training loss: 0.28510287404060364
Validation loss: 2.079695403575897

Epoch: 5| Step: 8
Training loss: 0.3963942229747772
Validation loss: 2.0707764675219855

Epoch: 5| Step: 9
Training loss: 0.5681449174880981
Validation loss: 2.074638530611992

Epoch: 5| Step: 10
Training loss: 0.18764615058898926
Validation loss: 2.085425545771917

Epoch: 5| Step: 11
Training loss: 0.10062985122203827
Validation loss: 2.081366648276647

Epoch: 545| Step: 0
Training loss: 0.16255611181259155
Validation loss: 2.086488867799441

Epoch: 5| Step: 1
Training loss: 0.20391133427619934
Validation loss: 2.092677583297094

Epoch: 5| Step: 2
Training loss: 0.23723630607128143
Validation loss: 2.0860710591077805

Epoch: 5| Step: 3
Training loss: 0.6717855930328369
Validation loss: 2.0795020759105682

Epoch: 5| Step: 4
Training loss: 0.27015963196754456
Validation loss: 2.0899542768796286

Epoch: 5| Step: 5
Training loss: 0.3087688982486725
Validation loss: 2.1116903871297836

Epoch: 5| Step: 6
Training loss: 0.160146564245224
Validation loss: 2.0619706163803735

Epoch: 5| Step: 7
Training loss: 0.5107403993606567
Validation loss: 2.093678295612335

Epoch: 5| Step: 8
Training loss: 0.2299424111843109
Validation loss: 2.0740824788808823

Epoch: 5| Step: 9
Training loss: 0.21524012088775635
Validation loss: 2.0589399933815002

Epoch: 5| Step: 10
Training loss: 0.27291563153266907
Validation loss: 2.07061834136645

Epoch: 5| Step: 11
Training loss: 0.1592634916305542
Validation loss: 2.1126532008250556

Epoch: 546| Step: 0
Training loss: 0.36236006021499634
Validation loss: 2.1124011327823005

Epoch: 5| Step: 1
Training loss: 0.2059541940689087
Validation loss: 2.1124949554602304

Epoch: 5| Step: 2
Training loss: 0.5973730087280273
Validation loss: 2.1377463738123574

Epoch: 5| Step: 3
Training loss: 0.43090328574180603
Validation loss: 2.142427002390226

Epoch: 5| Step: 4
Training loss: 0.38652604818344116
Validation loss: 2.0969987908999124

Epoch: 5| Step: 5
Training loss: 0.20235320925712585
Validation loss: 2.1267716189225516

Epoch: 5| Step: 6
Training loss: 0.2787629961967468
Validation loss: 2.138405720392863

Epoch: 5| Step: 7
Training loss: 0.41611042618751526
Validation loss: 2.111119344830513

Epoch: 5| Step: 8
Training loss: 0.2665415406227112
Validation loss: 2.126317764321963

Epoch: 5| Step: 9
Training loss: 0.2876876890659332
Validation loss: 2.1199965327978134

Epoch: 5| Step: 10
Training loss: 0.2252921611070633
Validation loss: 2.113165428241094

Epoch: 5| Step: 11
Training loss: 0.4405064880847931
Validation loss: 2.084875851869583

Epoch: 547| Step: 0
Training loss: 0.23691003024578094
Validation loss: 2.090405762195587

Epoch: 5| Step: 1
Training loss: 0.2536483705043793
Validation loss: 2.1047158588965735

Epoch: 5| Step: 2
Training loss: 0.3468833565711975
Validation loss: 2.129589413603147

Epoch: 5| Step: 3
Training loss: 0.5386258363723755
Validation loss: 2.1186930338541665

Epoch: 5| Step: 4
Training loss: 0.5142439603805542
Validation loss: 2.1717063983281455

Epoch: 5| Step: 5
Training loss: 0.44492393732070923
Validation loss: 2.111788501342138

Epoch: 5| Step: 6
Training loss: 0.3362390697002411
Validation loss: 2.136236757040024

Epoch: 5| Step: 7
Training loss: 0.2693897783756256
Validation loss: 2.1518404334783554

Epoch: 5| Step: 8
Training loss: 0.5791689157485962
Validation loss: 2.101902852455775

Epoch: 5| Step: 9
Training loss: 0.35696977376937866
Validation loss: 2.1085686733325324

Epoch: 5| Step: 10
Training loss: 0.3074107766151428
Validation loss: 2.0960155725479126

Epoch: 5| Step: 11
Training loss: 0.732178807258606
Validation loss: 2.0668026258548102

Epoch: 548| Step: 0
Training loss: 0.5630263090133667
Validation loss: 2.0756371269623437

Epoch: 5| Step: 1
Training loss: 0.2019086331129074
Validation loss: 2.1061196426550546

Epoch: 5| Step: 2
Training loss: 0.642882764339447
Validation loss: 2.101262698570887

Epoch: 5| Step: 3
Training loss: 0.21392150223255157
Validation loss: 2.1081830312808356

Epoch: 5| Step: 4
Training loss: 0.2298874855041504
Validation loss: 2.103888620932897

Epoch: 5| Step: 5
Training loss: 0.17254988849163055
Validation loss: 2.11624867717425

Epoch: 5| Step: 6
Training loss: 0.2890540361404419
Validation loss: 2.0936490495999656

Epoch: 5| Step: 7
Training loss: 0.3015678822994232
Validation loss: 2.071192502975464

Epoch: 5| Step: 8
Training loss: 0.4028233587741852
Validation loss: 2.0940828919410706

Epoch: 5| Step: 9
Training loss: 0.2645931839942932
Validation loss: 2.075591484705607

Epoch: 5| Step: 10
Training loss: 0.3572499752044678
Validation loss: 2.0558609316746392

Epoch: 5| Step: 11
Training loss: 0.29414069652557373
Validation loss: 2.1501343051592507

Epoch: 549| Step: 0
Training loss: 0.24383410811424255
Validation loss: 2.0944641530513763

Epoch: 5| Step: 1
Training loss: 0.2146071493625641
Validation loss: 2.1203153828779855

Epoch: 5| Step: 2
Training loss: 0.3701651692390442
Validation loss: 2.0837396879990897

Epoch: 5| Step: 3
Training loss: 0.24268925189971924
Validation loss: 2.0902850727240243

Epoch: 5| Step: 4
Training loss: 0.6442800760269165
Validation loss: 2.104770382245382

Epoch: 5| Step: 5
Training loss: 0.19152002036571503
Validation loss: 2.085528070727984

Epoch: 5| Step: 6
Training loss: 0.19413697719573975
Validation loss: 2.1293511986732483

Epoch: 5| Step: 7
Training loss: 0.40014249086380005
Validation loss: 2.084937041004499

Epoch: 5| Step: 8
Training loss: 0.2767372131347656
Validation loss: 2.1088541398445764

Epoch: 5| Step: 9
Training loss: 0.2545228600502014
Validation loss: 2.1162170668443046

Epoch: 5| Step: 10
Training loss: 0.40996474027633667
Validation loss: 2.137088115016619

Epoch: 5| Step: 11
Training loss: 0.2838782072067261
Validation loss: 2.1052603274583817

Epoch: 550| Step: 0
Training loss: 0.15984567999839783
Validation loss: 2.081749518712362

Epoch: 5| Step: 1
Training loss: 0.2859465479850769
Validation loss: 2.1523504654566445

Epoch: 5| Step: 2
Training loss: 0.25268545746803284
Validation loss: 2.09276574353377

Epoch: 5| Step: 3
Training loss: 0.19482269883155823
Validation loss: 2.113910992940267

Epoch: 5| Step: 4
Training loss: 0.5896495580673218
Validation loss: 2.0777363081773124

Epoch: 5| Step: 5
Training loss: 0.41394442319869995
Validation loss: 2.110586568713188

Epoch: 5| Step: 6
Training loss: 0.21221253275871277
Validation loss: 2.1055527279774346

Epoch: 5| Step: 7
Training loss: 0.33733704686164856
Validation loss: 2.05840203166008

Epoch: 5| Step: 8
Training loss: 0.35947665572166443
Validation loss: 2.060505375266075

Epoch: 5| Step: 9
Training loss: 0.5049992799758911
Validation loss: 2.0492460330327353

Epoch: 5| Step: 10
Training loss: 0.17562401294708252
Validation loss: 2.064641465743383

Epoch: 5| Step: 11
Training loss: 0.15510880947113037
Validation loss: 2.0901008546352386

Testing loss: 1.7623597134789117
