Epoch: 1| Step: 0
Training loss: 4.546278032788582
Validation loss: 4.335302692487387

Epoch: 5| Step: 1
Training loss: 4.2085257508254985
Validation loss: 4.304151064292692

Epoch: 5| Step: 2
Training loss: 4.390100631081865
Validation loss: 4.27555908875001

Epoch: 5| Step: 3
Training loss: 4.8102939057522045
Validation loss: 4.256508681828972

Epoch: 5| Step: 4
Training loss: 4.0655463900872135
Validation loss: 4.230462015275182

Epoch: 5| Step: 5
Training loss: 4.556037401804404
Validation loss: 4.206620465799244

Epoch: 5| Step: 6
Training loss: 4.052641424009368
Validation loss: 4.181797006252514

Epoch: 5| Step: 7
Training loss: 3.8014640547630805
Validation loss: 4.153833169409663

Epoch: 5| Step: 8
Training loss: 4.480834839555571
Validation loss: 4.125352444667868

Epoch: 5| Step: 9
Training loss: 4.097813111422064
Validation loss: 4.09966838879612

Epoch: 5| Step: 10
Training loss: 4.219031656541165
Validation loss: 4.068602092142559

Epoch: 5| Step: 11
Training loss: 5.327801020552439
Validation loss: 4.0431272171587604

Epoch: 2| Step: 0
Training loss: 3.4888208875353195
Validation loss: 4.013832315547116

Epoch: 5| Step: 1
Training loss: 4.695025900219865
Validation loss: 3.9883164700987064

Epoch: 5| Step: 2
Training loss: 4.418163453794275
Validation loss: 3.9536116530424583

Epoch: 5| Step: 3
Training loss: 4.257481217401707
Validation loss: 3.9181448686746756

Epoch: 5| Step: 4
Training loss: 4.007555025690296
Validation loss: 3.8879647716135004

Epoch: 5| Step: 5
Training loss: 4.078751205364661
Validation loss: 3.8490500622023647

Epoch: 5| Step: 6
Training loss: 3.3219509973741452
Validation loss: 3.8151574123516356

Epoch: 5| Step: 7
Training loss: 3.9192985187283513
Validation loss: 3.7698702539518467

Epoch: 5| Step: 8
Training loss: 3.10252184888599
Validation loss: 3.731473484513666

Epoch: 5| Step: 9
Training loss: 3.8790781034910085
Validation loss: 3.696201666433285

Epoch: 5| Step: 10
Training loss: 3.8090845036385548
Validation loss: 3.6509978781054615

Epoch: 5| Step: 11
Training loss: 5.007366475969
Validation loss: 3.6018815247525535

Epoch: 3| Step: 0
Training loss: 3.449933955348225
Validation loss: 3.56062023026594

Epoch: 5| Step: 1
Training loss: 3.8992206039225583
Validation loss: 3.518426050549879

Epoch: 5| Step: 2
Training loss: 3.5394524028976475
Validation loss: 3.4652855672772116

Epoch: 5| Step: 3
Training loss: 3.1430058351244696
Validation loss: 3.4165915077750766

Epoch: 5| Step: 4
Training loss: 3.3798735011429093
Validation loss: 3.3703944607010747

Epoch: 5| Step: 5
Training loss: 3.3590475233281607
Validation loss: 3.322284887558138

Epoch: 5| Step: 6
Training loss: 3.3666901187898226
Validation loss: 3.2630109104371963

Epoch: 5| Step: 7
Training loss: 3.2635143705448777
Validation loss: 3.218319095545178

Epoch: 5| Step: 8
Training loss: 3.7913347175809817
Validation loss: 3.160004871893801

Epoch: 5| Step: 9
Training loss: 3.019053669379488
Validation loss: 3.099044411796765

Epoch: 5| Step: 10
Training loss: 3.2237066233313705
Validation loss: 3.0440405058822515

Epoch: 5| Step: 11
Training loss: 1.8150772318946402
Validation loss: 2.9881973786728375

Epoch: 4| Step: 0
Training loss: 2.855825754123497
Validation loss: 2.9252673836569096

Epoch: 5| Step: 1
Training loss: 2.3509643402250937
Validation loss: 2.8741340231394275

Epoch: 5| Step: 2
Training loss: 2.8132453778455297
Validation loss: 2.8283598962116043

Epoch: 5| Step: 3
Training loss: 2.9426278342430283
Validation loss: 2.7876229226303746

Epoch: 5| Step: 4
Training loss: 2.9738848800183995
Validation loss: 2.7340248210655114

Epoch: 5| Step: 5
Training loss: 3.0682693944178356
Validation loss: 2.6997083669801643

Epoch: 5| Step: 6
Training loss: 3.0686972060003344
Validation loss: 2.681022337530786

Epoch: 5| Step: 7
Training loss: 2.843573260841104
Validation loss: 2.647683507967164

Epoch: 5| Step: 8
Training loss: 2.2894883524591565
Validation loss: 2.627717891206847

Epoch: 5| Step: 9
Training loss: 1.5998996196491488
Validation loss: 2.604404165246383

Epoch: 5| Step: 10
Training loss: 2.5288476729186216
Validation loss: 2.598885530714767

Epoch: 5| Step: 11
Training loss: 1.9559746057855105
Validation loss: 2.5985893619559866

Epoch: 5| Step: 0
Training loss: 2.326805918751888
Validation loss: 2.624623222407277

Epoch: 5| Step: 1
Training loss: 2.1044137891429666
Validation loss: 2.6211856952881356

Epoch: 5| Step: 2
Training loss: 2.8707712005254966
Validation loss: 2.6516922350473386

Epoch: 5| Step: 3
Training loss: 3.4451984550994346
Validation loss: 2.674775023967318

Epoch: 5| Step: 4
Training loss: 2.5334864026388533
Validation loss: 2.6946919376443366

Epoch: 5| Step: 5
Training loss: 2.5630343740646007
Validation loss: 2.7254255414580233

Epoch: 5| Step: 6
Training loss: 2.0824462019072403
Validation loss: 2.7367157934900495

Epoch: 5| Step: 7
Training loss: 2.694817627520137
Validation loss: 2.7153457031198487

Epoch: 5| Step: 8
Training loss: 3.0784179238299214
Validation loss: 2.7513260082836064

Epoch: 5| Step: 9
Training loss: 2.9822719014150483
Validation loss: 2.7430880952399286

Epoch: 5| Step: 10
Training loss: 2.363149894657887
Validation loss: 2.7288715346143424

Epoch: 5| Step: 11
Training loss: 1.018062307957878
Validation loss: 2.7006818520423037

Epoch: 6| Step: 0
Training loss: 2.9570605983310774
Validation loss: 2.670856787468997

Epoch: 5| Step: 1
Training loss: 2.9726264140051657
Validation loss: 2.657714458752661

Epoch: 5| Step: 2
Training loss: 2.6842049203977516
Validation loss: 2.63379609311299

Epoch: 5| Step: 3
Training loss: 2.324783897611402
Validation loss: 2.630179272229887

Epoch: 5| Step: 4
Training loss: 2.4214995062365
Validation loss: 2.591799929822335

Epoch: 5| Step: 5
Training loss: 2.623810271451839
Validation loss: 2.5997598223831577

Epoch: 5| Step: 6
Training loss: 3.076449330245402
Validation loss: 2.6134634025737875

Epoch: 5| Step: 7
Training loss: 2.5849619520622773
Validation loss: 2.573270944510656

Epoch: 5| Step: 8
Training loss: 2.0434497391036257
Validation loss: 2.569273931126506

Epoch: 5| Step: 9
Training loss: 2.1240968467917796
Validation loss: 2.5868222431665835

Epoch: 5| Step: 10
Training loss: 2.7355547294629226
Validation loss: 2.5901985673381023

Epoch: 5| Step: 11
Training loss: 1.6574292573173295
Validation loss: 2.5863107870919206

Epoch: 7| Step: 0
Training loss: 2.66153012730662
Validation loss: 2.578572868209143

Epoch: 5| Step: 1
Training loss: 2.5391637224414643
Validation loss: 2.576759971144128

Epoch: 5| Step: 2
Training loss: 1.9214468998675505
Validation loss: 2.586120376190168

Epoch: 5| Step: 3
Training loss: 2.398502808716135
Validation loss: 2.5916940284911902

Epoch: 5| Step: 4
Training loss: 2.8814962219817195
Validation loss: 2.5673432325947267

Epoch: 5| Step: 5
Training loss: 2.645394436535602
Validation loss: 2.585888807408794

Epoch: 5| Step: 6
Training loss: 2.6363684301422445
Validation loss: 2.5916197006430712

Epoch: 5| Step: 7
Training loss: 2.691262206720078
Validation loss: 2.578888843550438

Epoch: 5| Step: 8
Training loss: 2.430651899577845
Validation loss: 2.600377482130377

Epoch: 5| Step: 9
Training loss: 2.0633768471898892
Validation loss: 2.5867457130445515

Epoch: 5| Step: 10
Training loss: 2.8270839229199876
Validation loss: 2.587042078019067

Epoch: 5| Step: 11
Training loss: 3.162103644702189
Validation loss: 2.5706077027397805

Epoch: 8| Step: 0
Training loss: 2.4113792148296382
Validation loss: 2.5864771830107096

Epoch: 5| Step: 1
Training loss: 3.195494257227453
Validation loss: 2.5756738126789007

Epoch: 5| Step: 2
Training loss: 2.065770763615566
Validation loss: 2.585076744906744

Epoch: 5| Step: 3
Training loss: 2.436938881478267
Validation loss: 2.5893414155484136

Epoch: 5| Step: 4
Training loss: 2.5544293474427238
Validation loss: 2.575533834385369

Epoch: 5| Step: 5
Training loss: 2.5558961581417217
Validation loss: 2.585343483794112

Epoch: 5| Step: 6
Training loss: 3.0202015358581136
Validation loss: 2.5756757179850958

Epoch: 5| Step: 7
Training loss: 2.247849814546631
Validation loss: 2.5803616425963214

Epoch: 5| Step: 8
Training loss: 2.6738614734384023
Validation loss: 2.5957440405826864

Epoch: 5| Step: 9
Training loss: 2.420362627902959
Validation loss: 2.5962142383718665

Epoch: 5| Step: 10
Training loss: 2.4307392947063136
Validation loss: 2.566657098116523

Epoch: 5| Step: 11
Training loss: 1.621268315855167
Validation loss: 2.591140771346523

Epoch: 9| Step: 0
Training loss: 2.3385720594395125
Validation loss: 2.5909847701476685

Epoch: 5| Step: 1
Training loss: 1.9300899317646047
Validation loss: 2.5823909222381745

Epoch: 5| Step: 2
Training loss: 2.438110079588875
Validation loss: 2.5960648329872384

Epoch: 5| Step: 3
Training loss: 2.669190960441156
Validation loss: 2.624231657477409

Epoch: 5| Step: 4
Training loss: 2.644813691556215
Validation loss: 2.6313692470600785

Epoch: 5| Step: 5
Training loss: 2.953907212098577
Validation loss: 2.6311551885671243

Epoch: 5| Step: 6
Training loss: 2.1830212110326834
Validation loss: 2.6364241371866055

Epoch: 5| Step: 7
Training loss: 2.178593186531139
Validation loss: 2.6384742676000186

Epoch: 5| Step: 8
Training loss: 2.761290003019228
Validation loss: 2.622087050703578

Epoch: 5| Step: 9
Training loss: 2.4418049479137367
Validation loss: 2.6100965861283885

Epoch: 5| Step: 10
Training loss: 3.523734137319076
Validation loss: 2.6270560243252508

Epoch: 5| Step: 11
Training loss: 1.8247625614543457
Validation loss: 2.589048586715735

Epoch: 10| Step: 0
Training loss: 1.946438934328583
Validation loss: 2.5893552845971555

Epoch: 5| Step: 1
Training loss: 2.6104692003748977
Validation loss: 2.5867802820670747

Epoch: 5| Step: 2
Training loss: 2.7076319348708875
Validation loss: 2.5757959808369595

Epoch: 5| Step: 3
Training loss: 2.756353754352754
Validation loss: 2.580016985160896

Epoch: 5| Step: 4
Training loss: 2.6530764302367422
Validation loss: 2.5806780802690246

Epoch: 5| Step: 5
Training loss: 2.970599431642773
Validation loss: 2.558010291047158

Epoch: 5| Step: 6
Training loss: 2.1906678286731416
Validation loss: 2.578934615583102

Epoch: 5| Step: 7
Training loss: 2.0134168254306526
Validation loss: 2.5647538050732304

Epoch: 5| Step: 8
Training loss: 2.511217414336937
Validation loss: 2.566147000066266

Epoch: 5| Step: 9
Training loss: 3.2799921440402597
Validation loss: 2.554686446194524

Epoch: 5| Step: 10
Training loss: 1.971365024498115
Validation loss: 2.560840115606991

Epoch: 5| Step: 11
Training loss: 1.6230075799291408
Validation loss: 2.556496643566065

Epoch: 11| Step: 0
Training loss: 2.8268536824163313
Validation loss: 2.568754773471973

Epoch: 5| Step: 1
Training loss: 2.6422609757776447
Validation loss: 2.551398330674006

Epoch: 5| Step: 2
Training loss: 2.7392592051021416
Validation loss: 2.5728711472987955

Epoch: 5| Step: 3
Training loss: 2.877267358093643
Validation loss: 2.553014730611466

Epoch: 5| Step: 4
Training loss: 2.2575930584455435
Validation loss: 2.5570036977838924

Epoch: 5| Step: 5
Training loss: 2.338136792269176
Validation loss: 2.542484801886842

Epoch: 5| Step: 6
Training loss: 2.1765022658361044
Validation loss: 2.557625173250626

Epoch: 5| Step: 7
Training loss: 2.8917611853316525
Validation loss: 2.5667963800742823

Epoch: 5| Step: 8
Training loss: 2.0872084499677896
Validation loss: 2.551579757884355

Epoch: 5| Step: 9
Training loss: 2.0438076652767605
Validation loss: 2.5585905662303268

Epoch: 5| Step: 10
Training loss: 2.401840132361715
Validation loss: 2.5476101631426413

Epoch: 5| Step: 11
Training loss: 3.2781268560733396
Validation loss: 2.559887321719316

Epoch: 12| Step: 0
Training loss: 2.106524427517233
Validation loss: 2.562760855415606

Epoch: 5| Step: 1
Training loss: 2.588942150755968
Validation loss: 2.5595243164338704

Epoch: 5| Step: 2
Training loss: 2.235701160749303
Validation loss: 2.566624578423991

Epoch: 5| Step: 3
Training loss: 3.055442619163224
Validation loss: 2.5769093643396457

Epoch: 5| Step: 4
Training loss: 2.2220852995121736
Validation loss: 2.567446806912863

Epoch: 5| Step: 5
Training loss: 2.4363386860065512
Validation loss: 2.5654788032537823

Epoch: 5| Step: 6
Training loss: 2.9468137117810684
Validation loss: 2.575098534738845

Epoch: 5| Step: 7
Training loss: 2.7443820616375625
Validation loss: 2.5749956308408044

Epoch: 5| Step: 8
Training loss: 2.316625060478584
Validation loss: 2.561544773344051

Epoch: 5| Step: 9
Training loss: 2.8124511714511375
Validation loss: 2.5689317188818315

Epoch: 5| Step: 10
Training loss: 2.310989917833825
Validation loss: 2.5552625135381515

Epoch: 5| Step: 11
Training loss: 0.3842391270170733
Validation loss: 2.545193915027443

Epoch: 13| Step: 0
Training loss: 2.6652687899109058
Validation loss: 2.558722464160633

Epoch: 5| Step: 1
Training loss: 2.2008376997538823
Validation loss: 2.543242600438245

Epoch: 5| Step: 2
Training loss: 2.597660471977302
Validation loss: 2.5761112093199343

Epoch: 5| Step: 3
Training loss: 3.4663968739308624
Validation loss: 2.549301197099425

Epoch: 5| Step: 4
Training loss: 2.3370850465028874
Validation loss: 2.5631297237151482

Epoch: 5| Step: 5
Training loss: 2.449264988318273
Validation loss: 2.5542978423154143

Epoch: 5| Step: 6
Training loss: 2.4196096346619984
Validation loss: 2.5395954726891063

Epoch: 5| Step: 7
Training loss: 2.575480451482643
Validation loss: 2.5531347768745007

Epoch: 5| Step: 8
Training loss: 2.4191304067885278
Validation loss: 2.5460023555171616

Epoch: 5| Step: 9
Training loss: 1.9848340322068478
Validation loss: 2.5439796626041082

Epoch: 5| Step: 10
Training loss: 2.459171787964588
Validation loss: 2.559524987886903

Epoch: 5| Step: 11
Training loss: 0.9030848510688132
Validation loss: 2.53637313830247

Epoch: 14| Step: 0
Training loss: 2.187948344469962
Validation loss: 2.5405819772328475

Epoch: 5| Step: 1
Training loss: 2.542283395038259
Validation loss: 2.5361877913324653

Epoch: 5| Step: 2
Training loss: 2.2745855519827285
Validation loss: 2.551216501174592

Epoch: 5| Step: 3
Training loss: 2.2965668971182733
Validation loss: 2.532829788528669

Epoch: 5| Step: 4
Training loss: 2.8967303160715274
Validation loss: 2.5508155995695185

Epoch: 5| Step: 5
Training loss: 1.7912648068206714
Validation loss: 2.5386833690362174

Epoch: 5| Step: 6
Training loss: 2.688732662951954
Validation loss: 2.5324855073286323

Epoch: 5| Step: 7
Training loss: 2.717598331360393
Validation loss: 2.5533369851791754

Epoch: 5| Step: 8
Training loss: 2.345005055403801
Validation loss: 2.5634654172624782

Epoch: 5| Step: 9
Training loss: 2.5789613234247906
Validation loss: 2.535186853601254

Epoch: 5| Step: 10
Training loss: 2.8329709513178463
Validation loss: 2.540293578004953

Epoch: 5| Step: 11
Training loss: 2.8432841495793246
Validation loss: 2.5442318570064666

Epoch: 15| Step: 0
Training loss: 2.196088986169404
Validation loss: 2.550481072717626

Epoch: 5| Step: 1
Training loss: 2.7182838654202675
Validation loss: 2.5344154164971755

Epoch: 5| Step: 2
Training loss: 2.6093888882021874
Validation loss: 2.549852284815478

Epoch: 5| Step: 3
Training loss: 2.9613339604092683
Validation loss: 2.527765057139359

Epoch: 5| Step: 4
Training loss: 2.216275621880346
Validation loss: 2.5218543252329884

Epoch: 5| Step: 5
Training loss: 2.308498012668282
Validation loss: 2.535786558694109

Epoch: 5| Step: 6
Training loss: 2.5644404809760646
Validation loss: 2.5539490140825847

Epoch: 5| Step: 7
Training loss: 2.313944803422003
Validation loss: 2.537056060692879

Epoch: 5| Step: 8
Training loss: 2.3524924432387886
Validation loss: 2.526742096106761

Epoch: 5| Step: 9
Training loss: 2.2878903457201147
Validation loss: 2.543181774242863

Epoch: 5| Step: 10
Training loss: 2.9761773608690745
Validation loss: 2.5492314824604594

Epoch: 5| Step: 11
Training loss: 1.5016792752113766
Validation loss: 2.51898537175781

Epoch: 16| Step: 0
Training loss: 2.211601669786126
Validation loss: 2.5374276164963674

Epoch: 5| Step: 1
Training loss: 2.6935515470045956
Validation loss: 2.538846422440123

Epoch: 5| Step: 2
Training loss: 2.150475994913616
Validation loss: 2.5241357646254112

Epoch: 5| Step: 3
Training loss: 1.8828567562995975
Validation loss: 2.5264477721245964

Epoch: 5| Step: 4
Training loss: 2.0811266338454932
Validation loss: 2.5268552820079693

Epoch: 5| Step: 5
Training loss: 2.581496098126971
Validation loss: 2.5224079437143683

Epoch: 5| Step: 6
Training loss: 2.2773299306774106
Validation loss: 2.532430891391344

Epoch: 5| Step: 7
Training loss: 3.2514398759764642
Validation loss: 2.5327065951064287

Epoch: 5| Step: 8
Training loss: 2.701613428045083
Validation loss: 2.518340862102182

Epoch: 5| Step: 9
Training loss: 1.9523571488682752
Validation loss: 2.5277754716082477

Epoch: 5| Step: 10
Training loss: 3.20231580980317
Validation loss: 2.5201836463387837

Epoch: 5| Step: 11
Training loss: 2.454817849916676
Validation loss: 2.515469398188044

Epoch: 17| Step: 0
Training loss: 2.289657150989988
Validation loss: 2.5323160305025416

Epoch: 5| Step: 1
Training loss: 2.5675240554351264
Validation loss: 2.524655039517588

Epoch: 5| Step: 2
Training loss: 2.502113212091541
Validation loss: 2.5155201568238232

Epoch: 5| Step: 3
Training loss: 2.7731786472787685
Validation loss: 2.53459152961805

Epoch: 5| Step: 4
Training loss: 2.7060827049366085
Validation loss: 2.54172184889461

Epoch: 5| Step: 5
Training loss: 2.598150908905558
Validation loss: 2.5399767907025925

Epoch: 5| Step: 6
Training loss: 2.994297966552427
Validation loss: 2.5367165355087247

Epoch: 5| Step: 7
Training loss: 1.605872852859968
Validation loss: 2.5341356571319458

Epoch: 5| Step: 8
Training loss: 2.285251504591891
Validation loss: 2.5273026763235547

Epoch: 5| Step: 9
Training loss: 2.3433328893162764
Validation loss: 2.5366091451648023

Epoch: 5| Step: 10
Training loss: 2.3808978283400024
Validation loss: 2.5212686073576096

Epoch: 5| Step: 11
Training loss: 2.8694962605067986
Validation loss: 2.5229786986251748

Epoch: 18| Step: 0
Training loss: 2.625839280880708
Validation loss: 2.5350327581687995

Epoch: 5| Step: 1
Training loss: 2.6004549252051423
Validation loss: 2.525991609739392

Epoch: 5| Step: 2
Training loss: 2.9186285414328097
Validation loss: 2.5279402306571717

Epoch: 5| Step: 3
Training loss: 2.497330384628312
Validation loss: 2.5079610430020525

Epoch: 5| Step: 4
Training loss: 2.4288178387020736
Validation loss: 2.5063375411754456

Epoch: 5| Step: 5
Training loss: 2.4770831694949145
Validation loss: 2.4952399794093214

Epoch: 5| Step: 6
Training loss: 2.5177874067518378
Validation loss: 2.5212331657055698

Epoch: 5| Step: 7
Training loss: 2.673313757364163
Validation loss: 2.5206559305321403

Epoch: 5| Step: 8
Training loss: 2.212653905828094
Validation loss: 2.5196997179588876

Epoch: 5| Step: 9
Training loss: 1.952259207517327
Validation loss: 2.5287968596678283

Epoch: 5| Step: 10
Training loss: 2.2881920106521445
Validation loss: 2.5081565597149384

Epoch: 5| Step: 11
Training loss: 2.5748894010328423
Validation loss: 2.5126621418599537

Epoch: 19| Step: 0
Training loss: 1.640311510925518
Validation loss: 2.528492610910542

Epoch: 5| Step: 1
Training loss: 1.7940853855392358
Validation loss: 2.516569848650884

Epoch: 5| Step: 2
Training loss: 2.679176571018388
Validation loss: 2.5252805107088014

Epoch: 5| Step: 3
Training loss: 2.390342745605175
Validation loss: 2.518279028119126

Epoch: 5| Step: 4
Training loss: 2.44232931768685
Validation loss: 2.518813941434235

Epoch: 5| Step: 5
Training loss: 2.3658155236061496
Validation loss: 2.501199617261302

Epoch: 5| Step: 6
Training loss: 3.236769669684929
Validation loss: 2.5080364559072703

Epoch: 5| Step: 7
Training loss: 2.217845356227391
Validation loss: 2.522026005808748

Epoch: 5| Step: 8
Training loss: 3.0159126105055734
Validation loss: 2.518274108948547

Epoch: 5| Step: 9
Training loss: 2.222215659078867
Validation loss: 2.5312869575534003

Epoch: 5| Step: 10
Training loss: 2.5734404572572376
Validation loss: 2.5274953192376053

Epoch: 5| Step: 11
Training loss: 3.365673317735081
Validation loss: 2.5153743034533327

Epoch: 20| Step: 0
Training loss: 2.4370544221958577
Validation loss: 2.51044322563041

Epoch: 5| Step: 1
Training loss: 2.7077552080559553
Validation loss: 2.52854939416645

Epoch: 5| Step: 2
Training loss: 2.734051058517795
Validation loss: 2.5165416753331966

Epoch: 5| Step: 3
Training loss: 2.1446448679914925
Validation loss: 2.50028018573428

Epoch: 5| Step: 4
Training loss: 2.1330805459854583
Validation loss: 2.5130527922553263

Epoch: 5| Step: 5
Training loss: 2.1847777730684856
Validation loss: 2.5265473963958986

Epoch: 5| Step: 6
Training loss: 2.22303036724015
Validation loss: 2.5226879246655636

Epoch: 5| Step: 7
Training loss: 3.2573544845810405
Validation loss: 2.526182726562498

Epoch: 5| Step: 8
Training loss: 2.4514935164656655
Validation loss: 2.5467457202170047

Epoch: 5| Step: 9
Training loss: 2.3890579173690925
Validation loss: 2.5355087901148416

Epoch: 5| Step: 10
Training loss: 2.2731667059113305
Validation loss: 2.5529243731259177

Epoch: 5| Step: 11
Training loss: 3.124152564539862
Validation loss: 2.5286234976780233

Epoch: 21| Step: 0
Training loss: 2.6129036988455807
Validation loss: 2.523453073679892

Epoch: 5| Step: 1
Training loss: 2.0044471650176794
Validation loss: 2.510885580017059

Epoch: 5| Step: 2
Training loss: 2.004346654136637
Validation loss: 2.4987812886418843

Epoch: 5| Step: 3
Training loss: 2.927419369415443
Validation loss: 2.4908252329251677

Epoch: 5| Step: 4
Training loss: 2.3972814302388072
Validation loss: 2.4881550563749455

Epoch: 5| Step: 5
Training loss: 1.7942313608405565
Validation loss: 2.4857598769379097

Epoch: 5| Step: 6
Training loss: 2.393193479541004
Validation loss: 2.4939519919904165

Epoch: 5| Step: 7
Training loss: 2.6734828461324476
Validation loss: 2.5065362877769792

Epoch: 5| Step: 8
Training loss: 3.0806171378594325
Validation loss: 2.4981874213151753

Epoch: 5| Step: 9
Training loss: 2.4067204003222202
Validation loss: 2.506841620159061

Epoch: 5| Step: 10
Training loss: 2.4067749837908234
Validation loss: 2.4953464430107015

Epoch: 5| Step: 11
Training loss: 2.5365392735992143
Validation loss: 2.512276144161386

Epoch: 22| Step: 0
Training loss: 2.0482394497335568
Validation loss: 2.5057052422185304

Epoch: 5| Step: 1
Training loss: 2.482792764324783
Validation loss: 2.493447590101663

Epoch: 5| Step: 2
Training loss: 3.0282058374344487
Validation loss: 2.4893612955482194

Epoch: 5| Step: 3
Training loss: 2.516978213834688
Validation loss: 2.4973367373117763

Epoch: 5| Step: 4
Training loss: 2.663257913663482
Validation loss: 2.5006065189231954

Epoch: 5| Step: 5
Training loss: 2.326139384186138
Validation loss: 2.5010888231993573

Epoch: 5| Step: 6
Training loss: 1.8013355122055854
Validation loss: 2.50362083565951

Epoch: 5| Step: 7
Training loss: 2.077287548233136
Validation loss: 2.5062886814610956

Epoch: 5| Step: 8
Training loss: 2.633047936663436
Validation loss: 2.5051133156969603

Epoch: 5| Step: 9
Training loss: 2.266225485314042
Validation loss: 2.500060458246977

Epoch: 5| Step: 10
Training loss: 2.80296455528013
Validation loss: 2.505997994628245

Epoch: 5| Step: 11
Training loss: 3.1483042194184176
Validation loss: 2.5017185225270335

Epoch: 23| Step: 0
Training loss: 2.259752542232008
Validation loss: 2.502326959241418

Epoch: 5| Step: 1
Training loss: 2.351277381619911
Validation loss: 2.4988007331329953

Epoch: 5| Step: 2
Training loss: 2.1149398302758535
Validation loss: 2.5063910273402445

Epoch: 5| Step: 3
Training loss: 2.041844133202736
Validation loss: 2.531649938628143

Epoch: 5| Step: 4
Training loss: 2.4252485836077216
Validation loss: 2.545962285200973

Epoch: 5| Step: 5
Training loss: 2.6669080644859444
Validation loss: 2.574791874854042

Epoch: 5| Step: 6
Training loss: 2.5575441027406307
Validation loss: 2.583280006494071

Epoch: 5| Step: 7
Training loss: 2.0352572308050974
Validation loss: 2.5851189699902104

Epoch: 5| Step: 8
Training loss: 3.3659769169995695
Validation loss: 2.5535059616266267

Epoch: 5| Step: 9
Training loss: 2.5907590235518305
Validation loss: 2.557711601092627

Epoch: 5| Step: 10
Training loss: 2.7162507946085217
Validation loss: 2.532127373524605

Epoch: 5| Step: 11
Training loss: 2.4271749279982924
Validation loss: 2.544988709882514

Epoch: 24| Step: 0
Training loss: 1.86001293875183
Validation loss: 2.5404926673799855

Epoch: 5| Step: 1
Training loss: 2.42705803286309
Validation loss: 2.509213663206062

Epoch: 5| Step: 2
Training loss: 2.6043641180841455
Validation loss: 2.4873926621190585

Epoch: 5| Step: 3
Training loss: 2.6494320602733703
Validation loss: 2.494856645750627

Epoch: 5| Step: 4
Training loss: 2.1995671540050847
Validation loss: 2.489916640811567

Epoch: 5| Step: 5
Training loss: 2.4795908418119814
Validation loss: 2.4943280369928678

Epoch: 5| Step: 6
Training loss: 2.751248596412893
Validation loss: 2.4935321349388535

Epoch: 5| Step: 7
Training loss: 2.722583129426347
Validation loss: 2.4960270307098154

Epoch: 5| Step: 8
Training loss: 2.9542710436920254
Validation loss: 2.497835915421257

Epoch: 5| Step: 9
Training loss: 2.169869903848543
Validation loss: 2.4885013788367756

Epoch: 5| Step: 10
Training loss: 2.065187264141952
Validation loss: 2.498925470854563

Epoch: 5| Step: 11
Training loss: 1.983636553476428
Validation loss: 2.4745896581252183

Epoch: 25| Step: 0
Training loss: 2.11822259240826
Validation loss: 2.480283595105724

Epoch: 5| Step: 1
Training loss: 2.5162684405542266
Validation loss: 2.5150568263204764

Epoch: 5| Step: 2
Training loss: 2.298458254348959
Validation loss: 2.49437621897597

Epoch: 5| Step: 3
Training loss: 2.548058451348885
Validation loss: 2.482330768793218

Epoch: 5| Step: 4
Training loss: 2.0728671452982423
Validation loss: 2.4890245957171495

Epoch: 5| Step: 5
Training loss: 2.2668182387816938
Validation loss: 2.4746528467114968

Epoch: 5| Step: 6
Training loss: 2.4951397381564115
Validation loss: 2.4917780421210565

Epoch: 5| Step: 7
Training loss: 2.6755894947258088
Validation loss: 2.4762910158591542

Epoch: 5| Step: 8
Training loss: 2.780537374688752
Validation loss: 2.5056202180454736

Epoch: 5| Step: 9
Training loss: 2.8391911781386803
Validation loss: 2.501433632982517

Epoch: 5| Step: 10
Training loss: 2.4062660513998924
Validation loss: 2.4929439429078273

Epoch: 5| Step: 11
Training loss: 1.67767845478056
Validation loss: 2.5127404420538233

Epoch: 26| Step: 0
Training loss: 2.6857022327222206
Validation loss: 2.5013464897750812

Epoch: 5| Step: 1
Training loss: 3.0253274220217903
Validation loss: 2.507160795309606

Epoch: 5| Step: 2
Training loss: 2.179562254011137
Validation loss: 2.501564426488887

Epoch: 5| Step: 3
Training loss: 2.324837328234534
Validation loss: 2.515866487178671

Epoch: 5| Step: 4
Training loss: 2.359824232571225
Validation loss: 2.5087875974024

Epoch: 5| Step: 5
Training loss: 1.9756120650807194
Validation loss: 2.51156959268789

Epoch: 5| Step: 6
Training loss: 2.5619359209681596
Validation loss: 2.5018010367455257

Epoch: 5| Step: 7
Training loss: 2.503979376857278
Validation loss: 2.5052913934866092

Epoch: 5| Step: 8
Training loss: 2.4925664057633234
Validation loss: 2.4919550876011933

Epoch: 5| Step: 9
Training loss: 1.7968968929118063
Validation loss: 2.488701663589688

Epoch: 5| Step: 10
Training loss: 2.546613059586467
Validation loss: 2.4843957368317153

Epoch: 5| Step: 11
Training loss: 3.4255610431114794
Validation loss: 2.4937339815662636

Epoch: 27| Step: 0
Training loss: 2.3190809892771447
Validation loss: 2.5006477867740236

Epoch: 5| Step: 1
Training loss: 1.8439208775879092
Validation loss: 2.4882310495946904

Epoch: 5| Step: 2
Training loss: 2.6429397098796246
Validation loss: 2.4892136260708186

Epoch: 5| Step: 3
Training loss: 1.8950575893780448
Validation loss: 2.477414057967115

Epoch: 5| Step: 4
Training loss: 2.6470985291189617
Validation loss: 2.475694293598339

Epoch: 5| Step: 5
Training loss: 1.9462962899310738
Validation loss: 2.4776699706705227

Epoch: 5| Step: 6
Training loss: 2.0799488296083304
Validation loss: 2.485403907489455

Epoch: 5| Step: 7
Training loss: 3.1455328252556423
Validation loss: 2.4806636503448676

Epoch: 5| Step: 8
Training loss: 2.730252717166887
Validation loss: 2.48122145078235

Epoch: 5| Step: 9
Training loss: 2.0231284122715203
Validation loss: 2.48517584138927

Epoch: 5| Step: 10
Training loss: 2.644063663137505
Validation loss: 2.4907092510541435

Epoch: 5| Step: 11
Training loss: 4.5486476104022575
Validation loss: 2.485019180465606

Epoch: 28| Step: 0
Training loss: 2.0619191594524717
Validation loss: 2.4920627479062305

Epoch: 5| Step: 1
Training loss: 2.6206876664751264
Validation loss: 2.479360822613519

Epoch: 5| Step: 2
Training loss: 2.6839446569953647
Validation loss: 2.4892845626277698

Epoch: 5| Step: 3
Training loss: 2.356184969138706
Validation loss: 2.4808474954921227

Epoch: 5| Step: 4
Training loss: 2.112622057757454
Validation loss: 2.5002688342827066

Epoch: 5| Step: 5
Training loss: 2.200733808033866
Validation loss: 2.490018193454229

Epoch: 5| Step: 6
Training loss: 2.5177465934408407
Validation loss: 2.5101070899079367

Epoch: 5| Step: 7
Training loss: 2.406177172859206
Validation loss: 2.5015123402389436

Epoch: 5| Step: 8
Training loss: 2.8421686827218617
Validation loss: 2.5075561752917177

Epoch: 5| Step: 9
Training loss: 2.6695116086465576
Validation loss: 2.520985655215321

Epoch: 5| Step: 10
Training loss: 2.370053611503108
Validation loss: 2.525756010965218

Epoch: 5| Step: 11
Training loss: 1.8216833102113652
Validation loss: 2.5084037202694653

Epoch: 29| Step: 0
Training loss: 2.003341863024807
Validation loss: 2.5138696268185567

Epoch: 5| Step: 1
Training loss: 2.514578275720229
Validation loss: 2.5128190600309535

Epoch: 5| Step: 2
Training loss: 2.2374187092425837
Validation loss: 2.523884496476032

Epoch: 5| Step: 3
Training loss: 2.35660041206963
Validation loss: 2.5203714670093036

Epoch: 5| Step: 4
Training loss: 2.348459623617099
Validation loss: 2.513664488644481

Epoch: 5| Step: 5
Training loss: 2.468041620147792
Validation loss: 2.4866220720509413

Epoch: 5| Step: 6
Training loss: 2.7015027597241352
Validation loss: 2.4960881722178496

Epoch: 5| Step: 7
Training loss: 2.80226817224542
Validation loss: 2.510031418635377

Epoch: 5| Step: 8
Training loss: 2.5330793575501596
Validation loss: 2.4822721758829775

Epoch: 5| Step: 9
Training loss: 2.759013403489067
Validation loss: 2.481975352188475

Epoch: 5| Step: 10
Training loss: 1.821882103305795
Validation loss: 2.4867608791773095

Epoch: 5| Step: 11
Training loss: 3.0371247613155274
Validation loss: 2.500023492066952

Epoch: 30| Step: 0
Training loss: 2.513753822964911
Validation loss: 2.4820235418260648

Epoch: 5| Step: 1
Training loss: 2.1665289419368485
Validation loss: 2.4995131177451806

Epoch: 5| Step: 2
Training loss: 2.118679407794845
Validation loss: 2.4797097754564614

Epoch: 5| Step: 3
Training loss: 2.8044724235845138
Validation loss: 2.489864869472536

Epoch: 5| Step: 4
Training loss: 2.924722355112052
Validation loss: 2.478849115523787

Epoch: 5| Step: 5
Training loss: 2.4513416976156623
Validation loss: 2.4861629977633815

Epoch: 5| Step: 6
Training loss: 2.7840630524609398
Validation loss: 2.487604617150516

Epoch: 5| Step: 7
Training loss: 2.0487773878071867
Validation loss: 2.49862373139881

Epoch: 5| Step: 8
Training loss: 2.601603373071846
Validation loss: 2.47485480412456

Epoch: 5| Step: 9
Training loss: 2.6176689046816737
Validation loss: 2.4858916589525264

Epoch: 5| Step: 10
Training loss: 1.5851277506274775
Validation loss: 2.4868610986508166

Epoch: 5| Step: 11
Training loss: 1.4735850028744222
Validation loss: 2.4836525256416033

Epoch: 31| Step: 0
Training loss: 2.710925539193715
Validation loss: 2.4826764592230433

Epoch: 5| Step: 1
Training loss: 2.5587601702198692
Validation loss: 2.479090109746362

Epoch: 5| Step: 2
Training loss: 2.187334980871124
Validation loss: 2.4854614753126665

Epoch: 5| Step: 3
Training loss: 1.9700216394775378
Validation loss: 2.4909205071144003

Epoch: 5| Step: 4
Training loss: 1.7470973328856558
Validation loss: 2.4625056402267695

Epoch: 5| Step: 5
Training loss: 2.603029312994589
Validation loss: 2.486226873141628

Epoch: 5| Step: 6
Training loss: 2.6733995516305997
Validation loss: 2.4998083041129395

Epoch: 5| Step: 7
Training loss: 2.7746829393041956
Validation loss: 2.473736499410924

Epoch: 5| Step: 8
Training loss: 2.3783198794345504
Validation loss: 2.484434550949145

Epoch: 5| Step: 9
Training loss: 2.5452201475246174
Validation loss: 2.4762851226821674

Epoch: 5| Step: 10
Training loss: 2.517240396579628
Validation loss: 2.486649445784344

Epoch: 5| Step: 11
Training loss: 2.2817722924552966
Validation loss: 2.4796749617049882

Epoch: 32| Step: 0
Training loss: 2.205451656630702
Validation loss: 2.4936706490508023

Epoch: 5| Step: 1
Training loss: 2.3562623769905575
Validation loss: 2.5105516560985146

Epoch: 5| Step: 2
Training loss: 2.8905006175730925
Validation loss: 2.504960017411848

Epoch: 5| Step: 3
Training loss: 2.21632091101102
Validation loss: 2.515370069740621

Epoch: 5| Step: 4
Training loss: 2.153039726262897
Validation loss: 2.512192178724924

Epoch: 5| Step: 5
Training loss: 1.8888800899761933
Validation loss: 2.534726044174402

Epoch: 5| Step: 6
Training loss: 2.4760161076886087
Validation loss: 2.51305973372057

Epoch: 5| Step: 7
Training loss: 2.5051727186646824
Validation loss: 2.5073316990617887

Epoch: 5| Step: 8
Training loss: 3.0842176835929718
Validation loss: 2.4984146217315004

Epoch: 5| Step: 9
Training loss: 2.459538622288251
Validation loss: 2.509208647082118

Epoch: 5| Step: 10
Training loss: 2.5030742816334874
Validation loss: 2.494853826609868

Epoch: 5| Step: 11
Training loss: 1.417899642395237
Validation loss: 2.48886322769161

Epoch: 33| Step: 0
Training loss: 2.4500046827310458
Validation loss: 2.492111097258864

Epoch: 5| Step: 1
Training loss: 2.444284436258283
Validation loss: 2.4951558228927393

Epoch: 5| Step: 2
Training loss: 2.7936231580097743
Validation loss: 2.5058338523748342

Epoch: 5| Step: 3
Training loss: 2.7095232085947925
Validation loss: 2.499862635335483

Epoch: 5| Step: 4
Training loss: 1.6960993755709404
Validation loss: 2.489064227668528

Epoch: 5| Step: 5
Training loss: 2.2452389890228543
Validation loss: 2.4882600225464393

Epoch: 5| Step: 6
Training loss: 2.399701409839207
Validation loss: 2.4793860207548257

Epoch: 5| Step: 7
Training loss: 2.4073396667774647
Validation loss: 2.487610315787274

Epoch: 5| Step: 8
Training loss: 2.918750581598326
Validation loss: 2.4800178698759865

Epoch: 5| Step: 9
Training loss: 2.324746977461485
Validation loss: 2.4812337781950786

Epoch: 5| Step: 10
Training loss: 2.1637387911518915
Validation loss: 2.4841667343910854

Epoch: 5| Step: 11
Training loss: 1.9273603979040386
Validation loss: 2.478988562258368

Epoch: 34| Step: 0
Training loss: 2.987149531664581
Validation loss: 2.499429407172261

Epoch: 5| Step: 1
Training loss: 2.523204969906312
Validation loss: 2.48133614260048

Epoch: 5| Step: 2
Training loss: 2.4450322682254266
Validation loss: 2.478119003028877

Epoch: 5| Step: 3
Training loss: 2.5198201331782704
Validation loss: 2.4853057997012185

Epoch: 5| Step: 4
Training loss: 2.824929555504135
Validation loss: 2.4818815077887924

Epoch: 5| Step: 5
Training loss: 2.373224900086716
Validation loss: 2.5114782167773866

Epoch: 5| Step: 6
Training loss: 2.1110686108287586
Validation loss: 2.499099275134675

Epoch: 5| Step: 7
Training loss: 2.0250620561675006
Validation loss: 2.4931278109078394

Epoch: 5| Step: 8
Training loss: 1.7085278408069622
Validation loss: 2.4928447689769984

Epoch: 5| Step: 9
Training loss: 2.619975048849091
Validation loss: 2.5015955899567976

Epoch: 5| Step: 10
Training loss: 2.3616926923065766
Validation loss: 2.496101646032764

Epoch: 5| Step: 11
Training loss: 2.4479936519989285
Validation loss: 2.490783287835445

Epoch: 35| Step: 0
Training loss: 2.261119387572708
Validation loss: 2.504131547033112

Epoch: 5| Step: 1
Training loss: 2.445882420044575
Validation loss: 2.5060455538535904

Epoch: 5| Step: 2
Training loss: 2.5861486250791033
Validation loss: 2.502467090505896

Epoch: 5| Step: 3
Training loss: 1.9673519923222524
Validation loss: 2.497529509901123

Epoch: 5| Step: 4
Training loss: 2.4603619583684275
Validation loss: 2.5054822575048723

Epoch: 5| Step: 5
Training loss: 2.81790794093317
Validation loss: 2.544784190858803

Epoch: 5| Step: 6
Training loss: 2.383051225554273
Validation loss: 2.528107607781274

Epoch: 5| Step: 7
Training loss: 2.3690708838856542
Validation loss: 2.515647043009156

Epoch: 5| Step: 8
Training loss: 2.67284522928666
Validation loss: 2.4895807981810703

Epoch: 5| Step: 9
Training loss: 2.4696025100752097
Validation loss: 2.5144561832352688

Epoch: 5| Step: 10
Training loss: 2.472515276947499
Validation loss: 2.50848222467016

Epoch: 5| Step: 11
Training loss: 0.8431157447979973
Validation loss: 2.471499364759315

Epoch: 36| Step: 0
Training loss: 2.5605781605640203
Validation loss: 2.4689484166434448

Epoch: 5| Step: 1
Training loss: 2.435341686424858
Validation loss: 2.4724259332035787

Epoch: 5| Step: 2
Training loss: 2.5185993689086192
Validation loss: 2.4767921573922997

Epoch: 5| Step: 3
Training loss: 2.7359130893143324
Validation loss: 2.4845988574628697

Epoch: 5| Step: 4
Training loss: 2.5513258348302776
Validation loss: 2.461422851173308

Epoch: 5| Step: 5
Training loss: 2.647787368783012
Validation loss: 2.4815663990361134

Epoch: 5| Step: 6
Training loss: 1.9309147318460638
Validation loss: 2.485260068037459

Epoch: 5| Step: 7
Training loss: 2.263872192050805
Validation loss: 2.4739381340942286

Epoch: 5| Step: 8
Training loss: 2.3571684163016564
Validation loss: 2.4722194717751487

Epoch: 5| Step: 9
Training loss: 2.228917211912779
Validation loss: 2.479393941949394

Epoch: 5| Step: 10
Training loss: 2.4840169204713045
Validation loss: 2.473785251117607

Epoch: 5| Step: 11
Training loss: 2.219282811623505
Validation loss: 2.502442791698041

Epoch: 37| Step: 0
Training loss: 2.8029033118184494
Validation loss: 2.488108897964769

Epoch: 5| Step: 1
Training loss: 2.259135139364482
Validation loss: 2.4978342609530637

Epoch: 5| Step: 2
Training loss: 2.071882350902837
Validation loss: 2.4989978013308183

Epoch: 5| Step: 3
Training loss: 2.5030668520989727
Validation loss: 2.4920062614079574

Epoch: 5| Step: 4
Training loss: 2.504486350051442
Validation loss: 2.4942077970209504

Epoch: 5| Step: 5
Training loss: 2.334497626784853
Validation loss: 2.490692367823235

Epoch: 5| Step: 6
Training loss: 2.14491732653662
Validation loss: 2.501645222363783

Epoch: 5| Step: 7
Training loss: 2.1697303556978613
Validation loss: 2.5119648047082843

Epoch: 5| Step: 8
Training loss: 2.9578093660220124
Validation loss: 2.5080766786289583

Epoch: 5| Step: 9
Training loss: 2.242962108616844
Validation loss: 2.5068967420760107

Epoch: 5| Step: 10
Training loss: 2.553998755141801
Validation loss: 2.506674860064156

Epoch: 5| Step: 11
Training loss: 2.5259775894270318
Validation loss: 2.490297196537048

Epoch: 38| Step: 0
Training loss: 2.730677344304433
Validation loss: 2.486661450661395

Epoch: 5| Step: 1
Training loss: 1.9296535844177636
Validation loss: 2.480247003050103

Epoch: 5| Step: 2
Training loss: 2.5018530653659803
Validation loss: 2.4757856721077185

Epoch: 5| Step: 3
Training loss: 2.6434790181553343
Validation loss: 2.4801847720852828

Epoch: 5| Step: 4
Training loss: 2.3772533167632277
Validation loss: 2.4712604160568494

Epoch: 5| Step: 5
Training loss: 2.978539638735164
Validation loss: 2.475183120850427

Epoch: 5| Step: 6
Training loss: 1.8703456968135568
Validation loss: 2.485916263402498

Epoch: 5| Step: 7
Training loss: 2.007897282454261
Validation loss: 2.480249642534528

Epoch: 5| Step: 8
Training loss: 2.264317839172415
Validation loss: 2.472582779325644

Epoch: 5| Step: 9
Training loss: 2.5167855375734085
Validation loss: 2.46664723848304

Epoch: 5| Step: 10
Training loss: 2.630736123690522
Validation loss: 2.4752024617534993

Epoch: 5| Step: 11
Training loss: 3.033157849388429
Validation loss: 2.487373565770544

Epoch: 39| Step: 0
Training loss: 2.36939360800208
Validation loss: 2.474285334341701

Epoch: 5| Step: 1
Training loss: 2.637888737817239
Validation loss: 2.472262844872304

Epoch: 5| Step: 2
Training loss: 2.387632803693532
Validation loss: 2.4698949022141043

Epoch: 5| Step: 3
Training loss: 2.531406256479876
Validation loss: 2.464710834544747

Epoch: 5| Step: 4
Training loss: 2.219788536619727
Validation loss: 2.4872072398209246

Epoch: 5| Step: 5
Training loss: 1.9682946056891881
Validation loss: 2.4874825625551242

Epoch: 5| Step: 6
Training loss: 2.2557433259517103
Validation loss: 2.485225629832404

Epoch: 5| Step: 7
Training loss: 2.372387302242368
Validation loss: 2.4866933561868727

Epoch: 5| Step: 8
Training loss: 2.402727992645157
Validation loss: 2.491326744491273

Epoch: 5| Step: 9
Training loss: 2.747101556767751
Validation loss: 2.4759835048761865

Epoch: 5| Step: 10
Training loss: 2.4623691814548865
Validation loss: 2.51513547853491

Epoch: 5| Step: 11
Training loss: 3.4634855719973894
Validation loss: 2.5053342396323988

Epoch: 40| Step: 0
Training loss: 2.9487812046083324
Validation loss: 2.4996830997681863

Epoch: 5| Step: 1
Training loss: 2.1773822585287728
Validation loss: 2.4860723123654465

Epoch: 5| Step: 2
Training loss: 1.8726429429136477
Validation loss: 2.4959858974026288

Epoch: 5| Step: 3
Training loss: 2.277506330127482
Validation loss: 2.481754740569118

Epoch: 5| Step: 4
Training loss: 2.058034397404985
Validation loss: 2.4708330484639904

Epoch: 5| Step: 5
Training loss: 2.9939880531291827
Validation loss: 2.4850952895665612

Epoch: 5| Step: 6
Training loss: 2.188585066754634
Validation loss: 2.486273717771915

Epoch: 5| Step: 7
Training loss: 2.4752307283379262
Validation loss: 2.471125469874537

Epoch: 5| Step: 8
Training loss: 2.1168087553657777
Validation loss: 2.487554650688789

Epoch: 5| Step: 9
Training loss: 2.668709111849666
Validation loss: 2.492108530130734

Epoch: 5| Step: 10
Training loss: 2.6247229656989477
Validation loss: 2.490231319251087

Epoch: 5| Step: 11
Training loss: 2.539209919097795
Validation loss: 2.48164408714709

Epoch: 41| Step: 0
Training loss: 2.1719776376307194
Validation loss: 2.4775031476493212

Epoch: 5| Step: 1
Training loss: 2.861281629581705
Validation loss: 2.476121066891541

Epoch: 5| Step: 2
Training loss: 2.076946411925511
Validation loss: 2.47863622141048

Epoch: 5| Step: 3
Training loss: 2.1050431594592154
Validation loss: 2.4965234226465296

Epoch: 5| Step: 4
Training loss: 2.3506818877773346
Validation loss: 2.5038759504479606

Epoch: 5| Step: 5
Training loss: 1.9530999143896837
Validation loss: 2.5042779123939747

Epoch: 5| Step: 6
Training loss: 2.6256162737451882
Validation loss: 2.5081212654849603

Epoch: 5| Step: 7
Training loss: 2.755089644896517
Validation loss: 2.51208559465035

Epoch: 5| Step: 8
Training loss: 2.70811610206535
Validation loss: 2.5182248891000536

Epoch: 5| Step: 9
Training loss: 2.6971957938665967
Validation loss: 2.534437970258343

Epoch: 5| Step: 10
Training loss: 2.2635786614962172
Validation loss: 2.516381278393278

Epoch: 5| Step: 11
Training loss: 1.5176047540044248
Validation loss: 2.5149647614365795

Epoch: 42| Step: 0
Training loss: 2.1656411262561335
Validation loss: 2.5106441953971594

Epoch: 5| Step: 1
Training loss: 3.0413384630638567
Validation loss: 2.49657738765566

Epoch: 5| Step: 2
Training loss: 2.1718384444638876
Validation loss: 2.4881485165536565

Epoch: 5| Step: 3
Training loss: 2.035560026036665
Validation loss: 2.5010711719552523

Epoch: 5| Step: 4
Training loss: 2.4378591419614306
Validation loss: 2.493994433470731

Epoch: 5| Step: 5
Training loss: 2.9070551587551487
Validation loss: 2.4760022818375624

Epoch: 5| Step: 6
Training loss: 2.807733693234895
Validation loss: 2.459096718651585

Epoch: 5| Step: 7
Training loss: 1.5238190784396055
Validation loss: 2.4652477805830384

Epoch: 5| Step: 8
Training loss: 2.802664024187845
Validation loss: 2.472196531221818

Epoch: 5| Step: 9
Training loss: 2.0685763006672317
Validation loss: 2.4723816569015433

Epoch: 5| Step: 10
Training loss: 2.278856040341315
Validation loss: 2.479839892032367

Epoch: 5| Step: 11
Training loss: 1.8870817668445319
Validation loss: 2.482913072972568

Epoch: 43| Step: 0
Training loss: 1.9225965556488565
Validation loss: 2.4672474614483764

Epoch: 5| Step: 1
Training loss: 2.495135151598737
Validation loss: 2.4755161493761237

Epoch: 5| Step: 2
Training loss: 2.372551710170221
Validation loss: 2.481847128774449

Epoch: 5| Step: 3
Training loss: 2.3968831844264704
Validation loss: 2.504504516669585

Epoch: 5| Step: 4
Training loss: 2.669418454934094
Validation loss: 2.5006816530758287

Epoch: 5| Step: 5
Training loss: 1.8134966773672405
Validation loss: 2.5147048183404355

Epoch: 5| Step: 6
Training loss: 2.560364088900388
Validation loss: 2.53355251580223

Epoch: 5| Step: 7
Training loss: 2.4973117680301637
Validation loss: 2.518555780089803

Epoch: 5| Step: 8
Training loss: 2.847076147617417
Validation loss: 2.5653128769807263

Epoch: 5| Step: 9
Training loss: 2.5209216162825596
Validation loss: 2.561847495143655

Epoch: 5| Step: 10
Training loss: 2.5488328955594723
Validation loss: 2.5446092438449632

Epoch: 5| Step: 11
Training loss: 2.141585976630472
Validation loss: 2.524666249844893

Epoch: 44| Step: 0
Training loss: 2.516805999469336
Validation loss: 2.5198272018691914

Epoch: 5| Step: 1
Training loss: 2.554745921362296
Validation loss: 2.502383554177571

Epoch: 5| Step: 2
Training loss: 2.195863050613207
Validation loss: 2.487640198473957

Epoch: 5| Step: 3
Training loss: 2.435004889074035
Validation loss: 2.4797535142963074

Epoch: 5| Step: 4
Training loss: 2.606069515574618
Validation loss: 2.4647588619520793

Epoch: 5| Step: 5
Training loss: 1.9338304779330613
Validation loss: 2.4854643410786483

Epoch: 5| Step: 6
Training loss: 2.6100526946145264
Validation loss: 2.485438648988943

Epoch: 5| Step: 7
Training loss: 2.0873725897915976
Validation loss: 2.4750419906945917

Epoch: 5| Step: 8
Training loss: 2.322115008552668
Validation loss: 2.46680018932435

Epoch: 5| Step: 9
Training loss: 3.132049391502009
Validation loss: 2.4562246861661987

Epoch: 5| Step: 10
Training loss: 2.247021505065333
Validation loss: 2.477853797385307

Epoch: 5| Step: 11
Training loss: 1.3749770249267943
Validation loss: 2.4822396112176532

Epoch: 45| Step: 0
Training loss: 2.5953851164890858
Validation loss: 2.4861247500667663

Epoch: 5| Step: 1
Training loss: 2.0817828575959645
Validation loss: 2.4734532586899207

Epoch: 5| Step: 2
Training loss: 2.928531021743239
Validation loss: 2.4653138902792193

Epoch: 5| Step: 3
Training loss: 1.8677810300205793
Validation loss: 2.456870744452927

Epoch: 5| Step: 4
Training loss: 2.569361270096752
Validation loss: 2.483290249548931

Epoch: 5| Step: 5
Training loss: 2.1965264598729783
Validation loss: 2.479008434492635

Epoch: 5| Step: 6
Training loss: 2.30736869413623
Validation loss: 2.4835956638677197

Epoch: 5| Step: 7
Training loss: 2.601267296707449
Validation loss: 2.4841797709980504

Epoch: 5| Step: 8
Training loss: 2.199674786025453
Validation loss: 2.479463494720652

Epoch: 5| Step: 9
Training loss: 2.3078556333112656
Validation loss: 2.4755893925448955

Epoch: 5| Step: 10
Training loss: 2.5087459169971367
Validation loss: 2.486165914665532

Epoch: 5| Step: 11
Training loss: 2.3388906330374977
Validation loss: 2.4786193240782053

Epoch: 46| Step: 0
Training loss: 2.1247051258817637
Validation loss: 2.4859678132714373

Epoch: 5| Step: 1
Training loss: 2.7190829544516837
Validation loss: 2.4932940028738373

Epoch: 5| Step: 2
Training loss: 2.17239110289627
Validation loss: 2.4999832053415116

Epoch: 5| Step: 3
Training loss: 2.7069320770637053
Validation loss: 2.5220129678858165

Epoch: 5| Step: 4
Training loss: 2.6970939609226465
Validation loss: 2.548346260288335

Epoch: 5| Step: 5
Training loss: 2.122982301405572
Validation loss: 2.542275458785445

Epoch: 5| Step: 6
Training loss: 2.473154412538873
Validation loss: 2.5402312968039564

Epoch: 5| Step: 7
Training loss: 2.3595889165040838
Validation loss: 2.547629059482013

Epoch: 5| Step: 8
Training loss: 2.1780115609751043
Validation loss: 2.537208494502121

Epoch: 5| Step: 9
Training loss: 2.8262192854631656
Validation loss: 2.5374938070600637

Epoch: 5| Step: 10
Training loss: 2.070799572347708
Validation loss: 2.522601769690832

Epoch: 5| Step: 11
Training loss: 2.0815305411934024
Validation loss: 2.5110951821793486

Epoch: 47| Step: 0
Training loss: 2.844550554544749
Validation loss: 2.4930306565916536

Epoch: 5| Step: 1
Training loss: 2.2258378840773303
Validation loss: 2.4739225779844065

Epoch: 5| Step: 2
Training loss: 2.515438475713063
Validation loss: 2.4729924186881362

Epoch: 5| Step: 3
Training loss: 1.622792431732801
Validation loss: 2.461368478648954

Epoch: 5| Step: 4
Training loss: 1.7503227208797192
Validation loss: 2.4712489011566237

Epoch: 5| Step: 5
Training loss: 2.546125992239853
Validation loss: 2.478331839358562

Epoch: 5| Step: 6
Training loss: 2.633440525754388
Validation loss: 2.4643184950591794

Epoch: 5| Step: 7
Training loss: 2.888485338276529
Validation loss: 2.4738810209273914

Epoch: 5| Step: 8
Training loss: 1.5581555814224615
Validation loss: 2.455452420338872

Epoch: 5| Step: 9
Training loss: 2.5095120669278312
Validation loss: 2.4833059389941723

Epoch: 5| Step: 10
Training loss: 2.636795246286181
Validation loss: 2.48740680606267

Epoch: 5| Step: 11
Training loss: 3.255005283380724
Validation loss: 2.4723065908968467

Epoch: 48| Step: 0
Training loss: 2.6739707891998634
Validation loss: 2.4700652172253563

Epoch: 5| Step: 1
Training loss: 2.193508071818477
Validation loss: 2.46504995467938

Epoch: 5| Step: 2
Training loss: 2.0326302167369112
Validation loss: 2.4832940539084745

Epoch: 5| Step: 3
Training loss: 2.510663180033646
Validation loss: 2.4693187589620376

Epoch: 5| Step: 4
Training loss: 2.3484034816894814
Validation loss: 2.4833071671031175

Epoch: 5| Step: 5
Training loss: 2.6642749511489656
Validation loss: 2.4675508757811726

Epoch: 5| Step: 6
Training loss: 2.47156740534179
Validation loss: 2.4726569651300845

Epoch: 5| Step: 7
Training loss: 2.145662825640186
Validation loss: 2.4706023103955737

Epoch: 5| Step: 8
Training loss: 2.4189947906349736
Validation loss: 2.4640752901282736

Epoch: 5| Step: 9
Training loss: 2.224629201959769
Validation loss: 2.4633643803642378

Epoch: 5| Step: 10
Training loss: 2.6764037361870363
Validation loss: 2.464965365916455

Epoch: 5| Step: 11
Training loss: 2.6124406725704215
Validation loss: 2.4753324661056446

Epoch: 49| Step: 0
Training loss: 2.313935942347602
Validation loss: 2.464876018540661

Epoch: 5| Step: 1
Training loss: 2.5127143844313604
Validation loss: 2.467363575858589

Epoch: 5| Step: 2
Training loss: 2.6792249808681445
Validation loss: 2.470788291297599

Epoch: 5| Step: 3
Training loss: 2.3481187920162125
Validation loss: 2.484319798238133

Epoch: 5| Step: 4
Training loss: 2.220710425587164
Validation loss: 2.472217016595606

Epoch: 5| Step: 5
Training loss: 2.8377333490486265
Validation loss: 2.4708326343473206

Epoch: 5| Step: 6
Training loss: 2.19461091801062
Validation loss: 2.4854880864406472

Epoch: 5| Step: 7
Training loss: 2.5041228630648247
Validation loss: 2.471635645013429

Epoch: 5| Step: 8
Training loss: 2.3057809078689098
Validation loss: 2.481921894216771

Epoch: 5| Step: 9
Training loss: 2.5597279138812836
Validation loss: 2.481768302209023

Epoch: 5| Step: 10
Training loss: 1.5867303078708024
Validation loss: 2.474822392737911

Epoch: 5| Step: 11
Training loss: 2.5822199811650304
Validation loss: 2.472470295097309

Epoch: 50| Step: 0
Training loss: 2.24072068780217
Validation loss: 2.478757336962023

Epoch: 5| Step: 1
Training loss: 2.0627327989918185
Validation loss: 2.4626884004327128

Epoch: 5| Step: 2
Training loss: 1.6779627261562973
Validation loss: 2.487364166311448

Epoch: 5| Step: 3
Training loss: 2.814792461706196
Validation loss: 2.484294330238891

Epoch: 5| Step: 4
Training loss: 2.6056249477343463
Validation loss: 2.4972476630199147

Epoch: 5| Step: 5
Training loss: 2.346343982828263
Validation loss: 2.4890135840689864

Epoch: 5| Step: 6
Training loss: 2.4432181752828526
Validation loss: 2.475976936918261

Epoch: 5| Step: 7
Training loss: 2.1310659110922483
Validation loss: 2.4736817309028787

Epoch: 5| Step: 8
Training loss: 2.0588818806305214
Validation loss: 2.4702356692902456

Epoch: 5| Step: 9
Training loss: 2.7504193246365594
Validation loss: 2.4663378685393407

Epoch: 5| Step: 10
Training loss: 2.801771257646809
Validation loss: 2.475702633888024

Epoch: 5| Step: 11
Training loss: 2.3351836247911897
Validation loss: 2.4676873096833485

Epoch: 51| Step: 0
Training loss: 2.734165902998505
Validation loss: 2.454087621282651

Epoch: 5| Step: 1
Training loss: 2.2408630500015625
Validation loss: 2.4845600938922967

Epoch: 5| Step: 2
Training loss: 2.2844273635561305
Validation loss: 2.46456064411037

Epoch: 5| Step: 3
Training loss: 2.2688711128800536
Validation loss: 2.491691472228807

Epoch: 5| Step: 4
Training loss: 2.1774631759035032
Validation loss: 2.481788022094209

Epoch: 5| Step: 5
Training loss: 2.366291644600967
Validation loss: 2.478244573282743

Epoch: 5| Step: 6
Training loss: 2.482965609401037
Validation loss: 2.4766173291479774

Epoch: 5| Step: 7
Training loss: 2.9705393969920735
Validation loss: 2.48115222956082

Epoch: 5| Step: 8
Training loss: 2.07394585547405
Validation loss: 2.4817538919634488

Epoch: 5| Step: 9
Training loss: 1.8980196897291364
Validation loss: 2.464280783096787

Epoch: 5| Step: 10
Training loss: 2.598577121050409
Validation loss: 2.4665410545193662

Epoch: 5| Step: 11
Training loss: 1.572846678467248
Validation loss: 2.4725780926686656

Epoch: 52| Step: 0
Training loss: 2.472121821256651
Validation loss: 2.45788835819504

Epoch: 5| Step: 1
Training loss: 1.9909311559166196
Validation loss: 2.480872714571857

Epoch: 5| Step: 2
Training loss: 2.2698880832659962
Validation loss: 2.472892904582559

Epoch: 5| Step: 3
Training loss: 2.43309513084486
Validation loss: 2.4730967148943677

Epoch: 5| Step: 4
Training loss: 2.4414484371355063
Validation loss: 2.490011139880518

Epoch: 5| Step: 5
Training loss: 2.5862209014951847
Validation loss: 2.4828422904703067

Epoch: 5| Step: 6
Training loss: 2.376699843190722
Validation loss: 2.483372456020543

Epoch: 5| Step: 7
Training loss: 1.8463237707938742
Validation loss: 2.481870606542698

Epoch: 5| Step: 8
Training loss: 2.5706859189825537
Validation loss: 2.486159609357683

Epoch: 5| Step: 9
Training loss: 2.6726835042617068
Validation loss: 2.4877092431591765

Epoch: 5| Step: 10
Training loss: 2.381806308113167
Validation loss: 2.4875432172052996

Epoch: 5| Step: 11
Training loss: 2.3697014983632885
Validation loss: 2.4714480396660816

Epoch: 53| Step: 0
Training loss: 2.712414429892627
Validation loss: 2.485551251756251

Epoch: 5| Step: 1
Training loss: 2.2739637886525967
Validation loss: 2.4706369061950735

Epoch: 5| Step: 2
Training loss: 2.1352253773927385
Validation loss: 2.4649619403116465

Epoch: 5| Step: 3
Training loss: 2.7700045118054164
Validation loss: 2.4765600531372436

Epoch: 5| Step: 4
Training loss: 1.8386538924275324
Validation loss: 2.4741243500804484

Epoch: 5| Step: 5
Training loss: 2.3665007045026676
Validation loss: 2.454873589629802

Epoch: 5| Step: 6
Training loss: 2.6008228247113547
Validation loss: 2.4702932105697664

Epoch: 5| Step: 7
Training loss: 1.8850693848283318
Validation loss: 2.4586369817242275

Epoch: 5| Step: 8
Training loss: 2.0959819455352
Validation loss: 2.471732137146918

Epoch: 5| Step: 9
Training loss: 2.695602445625252
Validation loss: 2.4673450874635976

Epoch: 5| Step: 10
Training loss: 2.6600775574011295
Validation loss: 2.448948802196583

Epoch: 5| Step: 11
Training loss: 1.3718696854820804
Validation loss: 2.4604583112232357

Epoch: 54| Step: 0
Training loss: 2.507103650458402
Validation loss: 2.468851835830438

Epoch: 5| Step: 1
Training loss: 1.9394088693968872
Validation loss: 2.4901506876128883

Epoch: 5| Step: 2
Training loss: 2.4893403726133267
Validation loss: 2.4690848175792484

Epoch: 5| Step: 3
Training loss: 2.566904423175609
Validation loss: 2.474882023019243

Epoch: 5| Step: 4
Training loss: 2.068562008709072
Validation loss: 2.4812608390334345

Epoch: 5| Step: 5
Training loss: 1.7027740116848697
Validation loss: 2.477633608651875

Epoch: 5| Step: 6
Training loss: 1.4522621300115717
Validation loss: 2.472892882487954

Epoch: 5| Step: 7
Training loss: 2.7032844628723467
Validation loss: 2.4520439025400784

Epoch: 5| Step: 8
Training loss: 2.0349531017401206
Validation loss: 2.4730298612269754

Epoch: 5| Step: 9
Training loss: 3.471776380949506
Validation loss: 2.47436017570863

Epoch: 5| Step: 10
Training loss: 2.3101220147412005
Validation loss: 2.4479516912890102

Epoch: 5| Step: 11
Training loss: 3.1263827507206963
Validation loss: 2.4545605097896592

Epoch: 55| Step: 0
Training loss: 2.37095669345571
Validation loss: 2.451655026422698

Epoch: 5| Step: 1
Training loss: 2.2139552788357246
Validation loss: 2.4586163266331984

Epoch: 5| Step: 2
Training loss: 1.738943252519411
Validation loss: 2.4698294520990416

Epoch: 5| Step: 3
Training loss: 2.537747556139382
Validation loss: 2.4739472332086336

Epoch: 5| Step: 4
Training loss: 2.0657473344689863
Validation loss: 2.463673738618324

Epoch: 5| Step: 5
Training loss: 2.3408370162628884
Validation loss: 2.4653765651150747

Epoch: 5| Step: 6
Training loss: 2.426777068585574
Validation loss: 2.4751808411905545

Epoch: 5| Step: 7
Training loss: 2.3385037516102396
Validation loss: 2.4630682243670354

Epoch: 5| Step: 8
Training loss: 2.488273872113032
Validation loss: 2.465825380628558

Epoch: 5| Step: 9
Training loss: 2.895386768918097
Validation loss: 2.47038143511368

Epoch: 5| Step: 10
Training loss: 2.648955798001013
Validation loss: 2.501151437639659

Epoch: 5| Step: 11
Training loss: 1.3839303794532603
Validation loss: 2.4601950115737226

Epoch: 56| Step: 0
Training loss: 2.360914422862222
Validation loss: 2.4913046537721555

Epoch: 5| Step: 1
Training loss: 2.221033881927331
Validation loss: 2.4486178685698077

Epoch: 5| Step: 2
Training loss: 2.3475468716395587
Validation loss: 2.4619578532009294

Epoch: 5| Step: 3
Training loss: 2.617784301125056
Validation loss: 2.4754580854096964

Epoch: 5| Step: 4
Training loss: 2.155692097456607
Validation loss: 2.454804993263358

Epoch: 5| Step: 5
Training loss: 2.2940049697569385
Validation loss: 2.477344858679979

Epoch: 5| Step: 6
Training loss: 2.5005871083373714
Validation loss: 2.4706859080402057

Epoch: 5| Step: 7
Training loss: 2.3144516828186434
Validation loss: 2.469101019744201

Epoch: 5| Step: 8
Training loss: 2.52384553332658
Validation loss: 2.4897412299251886

Epoch: 5| Step: 9
Training loss: 2.323610575629603
Validation loss: 2.481397267766874

Epoch: 5| Step: 10
Training loss: 2.264719394034462
Validation loss: 2.4640132474199996

Epoch: 5| Step: 11
Training loss: 1.1410952604582347
Validation loss: 2.4689248019113053

Epoch: 57| Step: 0
Training loss: 2.496712525850155
Validation loss: 2.5021039176325006

Epoch: 5| Step: 1
Training loss: 1.9435896387216973
Validation loss: 2.4759316067005788

Epoch: 5| Step: 2
Training loss: 2.469397158242124
Validation loss: 2.468923659192349

Epoch: 5| Step: 3
Training loss: 2.1128599413242783
Validation loss: 2.4844109354679094

Epoch: 5| Step: 4
Training loss: 2.4778958651234713
Validation loss: 2.4747585662131937

Epoch: 5| Step: 5
Training loss: 2.333990299744049
Validation loss: 2.4737677022201945

Epoch: 5| Step: 6
Training loss: 2.3773521019534734
Validation loss: 2.464522309057006

Epoch: 5| Step: 7
Training loss: 2.066833221225547
Validation loss: 2.4684107825058414

Epoch: 5| Step: 8
Training loss: 2.6701343063978786
Validation loss: 2.4723596219184154

Epoch: 5| Step: 9
Training loss: 2.365342532267239
Validation loss: 2.4784268903667543

Epoch: 5| Step: 10
Training loss: 2.575166056195208
Validation loss: 2.492807149834718

Epoch: 5| Step: 11
Training loss: 1.7235347384899133
Validation loss: 2.4712774762607324

Epoch: 58| Step: 0
Training loss: 2.047927469384802
Validation loss: 2.4822274608902086

Epoch: 5| Step: 1
Training loss: 2.4730326530253675
Validation loss: 2.4764357854313483

Epoch: 5| Step: 2
Training loss: 2.1151673085296374
Validation loss: 2.477624687466426

Epoch: 5| Step: 3
Training loss: 2.4134331040105876
Validation loss: 2.475534022963786

Epoch: 5| Step: 4
Training loss: 2.37456167091261
Validation loss: 2.4619951952294206

Epoch: 5| Step: 5
Training loss: 2.5428452703495763
Validation loss: 2.4746862980127977

Epoch: 5| Step: 6
Training loss: 1.8317190851909066
Validation loss: 2.464787943551352

Epoch: 5| Step: 7
Training loss: 2.434498626351336
Validation loss: 2.459549471052143

Epoch: 5| Step: 8
Training loss: 2.6668655996825223
Validation loss: 2.4577569016337812

Epoch: 5| Step: 9
Training loss: 2.983149411660851
Validation loss: 2.4466093847284855

Epoch: 5| Step: 10
Training loss: 1.6997845288772915
Validation loss: 2.473450142046329

Epoch: 5| Step: 11
Training loss: 2.2785576387322095
Validation loss: 2.449862377849265

Epoch: 59| Step: 0
Training loss: 1.7896677517621498
Validation loss: 2.4659837000131035

Epoch: 5| Step: 1
Training loss: 2.791116081335957
Validation loss: 2.4646943415334057

Epoch: 5| Step: 2
Training loss: 2.1605020146324123
Validation loss: 2.4733438123453597

Epoch: 5| Step: 3
Training loss: 2.542606919852744
Validation loss: 2.4811452909167095

Epoch: 5| Step: 4
Training loss: 2.375404323493843
Validation loss: 2.47341134030808

Epoch: 5| Step: 5
Training loss: 2.139803540846778
Validation loss: 2.4772985630090725

Epoch: 5| Step: 6
Training loss: 2.009463451568527
Validation loss: 2.4920832892207803

Epoch: 5| Step: 7
Training loss: 2.517591099080466
Validation loss: 2.503525112302964

Epoch: 5| Step: 8
Training loss: 1.9726247048452403
Validation loss: 2.490242122064645

Epoch: 5| Step: 9
Training loss: 2.5507302154997076
Validation loss: 2.4816320119634563

Epoch: 5| Step: 10
Training loss: 2.792413232150309
Validation loss: 2.5153865562990796

Epoch: 5| Step: 11
Training loss: 2.504720332358257
Validation loss: 2.5070140038793918

Epoch: 60| Step: 0
Training loss: 2.3230797292728353
Validation loss: 2.46990251800515

Epoch: 5| Step: 1
Training loss: 2.8573215803378442
Validation loss: 2.473576166182303

Epoch: 5| Step: 2
Training loss: 2.085622813744066
Validation loss: 2.461242156370628

Epoch: 5| Step: 3
Training loss: 2.0169614161374065
Validation loss: 2.47683392831339

Epoch: 5| Step: 4
Training loss: 2.342206421229183
Validation loss: 2.461665870213966

Epoch: 5| Step: 5
Training loss: 2.1908494646598924
Validation loss: 2.461289573391331

Epoch: 5| Step: 6
Training loss: 1.9608227213669538
Validation loss: 2.442446360472508

Epoch: 5| Step: 7
Training loss: 2.1537121197894527
Validation loss: 2.4638355004622494

Epoch: 5| Step: 8
Training loss: 3.0240356484486717
Validation loss: 2.4667523305318837

Epoch: 5| Step: 9
Training loss: 2.3470857406252623
Validation loss: 2.4689309057919826

Epoch: 5| Step: 10
Training loss: 2.5355589183896887
Validation loss: 2.4722895860126144

Epoch: 5| Step: 11
Training loss: 1.9677893701859632
Validation loss: 2.45568844925642

Epoch: 61| Step: 0
Training loss: 3.057703426951735
Validation loss: 2.4662757780220175

Epoch: 5| Step: 1
Training loss: 2.3892748641639954
Validation loss: 2.447814798602801

Epoch: 5| Step: 2
Training loss: 1.6794350367818298
Validation loss: 2.4679173059144404

Epoch: 5| Step: 3
Training loss: 2.431214469120493
Validation loss: 2.4643199745012043

Epoch: 5| Step: 4
Training loss: 2.1895313095847375
Validation loss: 2.4799483626960552

Epoch: 5| Step: 5
Training loss: 2.1136875854878387
Validation loss: 2.4761995436669184

Epoch: 5| Step: 6
Training loss: 2.7192639270736905
Validation loss: 2.4740475059634086

Epoch: 5| Step: 7
Training loss: 2.361590627210259
Validation loss: 2.4841728408102886

Epoch: 5| Step: 8
Training loss: 1.9729799514927437
Validation loss: 2.4992302027308053

Epoch: 5| Step: 9
Training loss: 2.421341966606635
Validation loss: 2.4617567121798336

Epoch: 5| Step: 10
Training loss: 2.1832257610737185
Validation loss: 2.4807784840798495

Epoch: 5| Step: 11
Training loss: 1.8319751592642781
Validation loss: 2.4841490188922144

Epoch: 62| Step: 0
Training loss: 2.2550649854342324
Validation loss: 2.4640317164666987

Epoch: 5| Step: 1
Training loss: 2.4340330067311013
Validation loss: 2.478301896543862

Epoch: 5| Step: 2
Training loss: 2.254473583412692
Validation loss: 2.489158084628118

Epoch: 5| Step: 3
Training loss: 2.6138752944958528
Validation loss: 2.46060219958026

Epoch: 5| Step: 4
Training loss: 2.5670527510474255
Validation loss: 2.4562221341093364

Epoch: 5| Step: 5
Training loss: 2.4581467078109034
Validation loss: 2.4523029124284825

Epoch: 5| Step: 6
Training loss: 2.0420737995931044
Validation loss: 2.45358653495217

Epoch: 5| Step: 7
Training loss: 2.011681417470651
Validation loss: 2.458697267172762

Epoch: 5| Step: 8
Training loss: 2.53176940486836
Validation loss: 2.4592926785539397

Epoch: 5| Step: 9
Training loss: 2.4093516782826776
Validation loss: 2.4623518820171113

Epoch: 5| Step: 10
Training loss: 2.2535047785113926
Validation loss: 2.435824857876058

Epoch: 5| Step: 11
Training loss: 1.7472898751513433
Validation loss: 2.461376736311287

Epoch: 63| Step: 0
Training loss: 2.759678714406894
Validation loss: 2.4733006951804013

Epoch: 5| Step: 1
Training loss: 2.0908853092273554
Validation loss: 2.4625293649255484

Epoch: 5| Step: 2
Training loss: 1.905746268332675
Validation loss: 2.470278391561381

Epoch: 5| Step: 3
Training loss: 2.419268676187452
Validation loss: 2.4405971926034273

Epoch: 5| Step: 4
Training loss: 2.5389442768450183
Validation loss: 2.468037079833952

Epoch: 5| Step: 5
Training loss: 2.895071208387756
Validation loss: 2.467939541571316

Epoch: 5| Step: 6
Training loss: 2.070427196852336
Validation loss: 2.45820899355285

Epoch: 5| Step: 7
Training loss: 2.4651498740481834
Validation loss: 2.46672351976765

Epoch: 5| Step: 8
Training loss: 1.967609559611382
Validation loss: 2.48054892342827

Epoch: 5| Step: 9
Training loss: 1.6450022840628957
Validation loss: 2.4750460023971805

Epoch: 5| Step: 10
Training loss: 2.230739276467327
Validation loss: 2.4789555937942134

Epoch: 5| Step: 11
Training loss: 3.391443672316425
Validation loss: 2.491643210420804

Epoch: 64| Step: 0
Training loss: 1.9121536390034282
Validation loss: 2.4806867408581805

Epoch: 5| Step: 1
Training loss: 2.7286312267196244
Validation loss: 2.4701834351975305

Epoch: 5| Step: 2
Training loss: 2.758940123076644
Validation loss: 2.469564452406207

Epoch: 5| Step: 3
Training loss: 2.361711570332599
Validation loss: 2.4812235867642265

Epoch: 5| Step: 4
Training loss: 2.260446351965365
Validation loss: 2.468390120660767

Epoch: 5| Step: 5
Training loss: 1.6958239087242033
Validation loss: 2.464620407795167

Epoch: 5| Step: 6
Training loss: 1.7574541192828554
Validation loss: 2.4595309966206584

Epoch: 5| Step: 7
Training loss: 2.3325680317826287
Validation loss: 2.4620729602184834

Epoch: 5| Step: 8
Training loss: 2.4357907097456772
Validation loss: 2.4341855949528717

Epoch: 5| Step: 9
Training loss: 2.3534655807049716
Validation loss: 2.468714162510086

Epoch: 5| Step: 10
Training loss: 2.5525971706325383
Validation loss: 2.466123535850346

Epoch: 5| Step: 11
Training loss: 2.7350991298417386
Validation loss: 2.4754970998580754

Epoch: 65| Step: 0
Training loss: 2.30378690030811
Validation loss: 2.467813036366569

Epoch: 5| Step: 1
Training loss: 2.193935301690027
Validation loss: 2.4398812497860853

Epoch: 5| Step: 2
Training loss: 2.8116654747412264
Validation loss: 2.4419645296745744

Epoch: 5| Step: 3
Training loss: 2.181513742498478
Validation loss: 2.460817441080537

Epoch: 5| Step: 4
Training loss: 2.4309337890847753
Validation loss: 2.4480946063577607

Epoch: 5| Step: 5
Training loss: 2.660798878847392
Validation loss: 2.462183559162969

Epoch: 5| Step: 6
Training loss: 2.1474627138748907
Validation loss: 2.4608655686941736

Epoch: 5| Step: 7
Training loss: 1.9671931090210568
Validation loss: 2.453497018163017

Epoch: 5| Step: 8
Training loss: 2.185367743929725
Validation loss: 2.4678467615241892

Epoch: 5| Step: 9
Training loss: 2.471138776283933
Validation loss: 2.4626750201268797

Epoch: 5| Step: 10
Training loss: 1.9546260711263
Validation loss: 2.4862472469083805

Epoch: 5| Step: 11
Training loss: 3.380544840672847
Validation loss: 2.4568512471080357

Epoch: 66| Step: 0
Training loss: 2.0612825210439443
Validation loss: 2.4566885785540844

Epoch: 5| Step: 1
Training loss: 1.8998853397907483
Validation loss: 2.45691801132662

Epoch: 5| Step: 2
Training loss: 2.105948144127579
Validation loss: 2.476443058186204

Epoch: 5| Step: 3
Training loss: 2.4869103120922205
Validation loss: 2.4716457574113853

Epoch: 5| Step: 4
Training loss: 1.6543110708372983
Validation loss: 2.463769367225119

Epoch: 5| Step: 5
Training loss: 2.1989199501445147
Validation loss: 2.4584029815527577

Epoch: 5| Step: 6
Training loss: 2.5201096454866123
Validation loss: 2.4687358477544956

Epoch: 5| Step: 7
Training loss: 2.5689008830882027
Validation loss: 2.470076582805061

Epoch: 5| Step: 8
Training loss: 2.6382690393257366
Validation loss: 2.46872856839048

Epoch: 5| Step: 9
Training loss: 2.660226694930417
Validation loss: 2.4552370200560323

Epoch: 5| Step: 10
Training loss: 2.115184554396546
Validation loss: 2.461495722678962

Epoch: 5| Step: 11
Training loss: 3.160914835751978
Validation loss: 2.4652228449281495

Epoch: 67| Step: 0
Training loss: 3.0094043829286607
Validation loss: 2.4513571640035443

Epoch: 5| Step: 1
Training loss: 1.6341854328334002
Validation loss: 2.4459771582466687

Epoch: 5| Step: 2
Training loss: 2.398677652370253
Validation loss: 2.452377509170043

Epoch: 5| Step: 3
Training loss: 2.2950995193877852
Validation loss: 2.460257372650986

Epoch: 5| Step: 4
Training loss: 2.354058344776695
Validation loss: 2.4479575918036707

Epoch: 5| Step: 5
Training loss: 2.069021030892541
Validation loss: 2.4471764250155474

Epoch: 5| Step: 6
Training loss: 1.5845634634273587
Validation loss: 2.438723786755932

Epoch: 5| Step: 7
Training loss: 2.199449869211129
Validation loss: 2.458458490472417

Epoch: 5| Step: 8
Training loss: 2.5566324185792664
Validation loss: 2.4623225558035484

Epoch: 5| Step: 9
Training loss: 2.6957227311791536
Validation loss: 2.458713576171969

Epoch: 5| Step: 10
Training loss: 2.3706067259104544
Validation loss: 2.460969621963367

Epoch: 5| Step: 11
Training loss: 2.1017592100520397
Validation loss: 2.4554735632539852

Epoch: 68| Step: 0
Training loss: 2.1247726767627357
Validation loss: 2.4616276071121055

Epoch: 5| Step: 1
Training loss: 2.1383755413279286
Validation loss: 2.4633749743487883

Epoch: 5| Step: 2
Training loss: 2.6854336801428476
Validation loss: 2.468243897144489

Epoch: 5| Step: 3
Training loss: 2.618099953173509
Validation loss: 2.478782280740435

Epoch: 5| Step: 4
Training loss: 1.5610983856349214
Validation loss: 2.4533698492295577

Epoch: 5| Step: 5
Training loss: 2.0397336593368003
Validation loss: 2.4749481643681666

Epoch: 5| Step: 6
Training loss: 2.9528542046292072
Validation loss: 2.4726268250300025

Epoch: 5| Step: 7
Training loss: 2.1601451025014695
Validation loss: 2.4795955132110667

Epoch: 5| Step: 8
Training loss: 2.4871098082949303
Validation loss: 2.4605604942612236

Epoch: 5| Step: 9
Training loss: 2.1327805289642447
Validation loss: 2.4602595127013416

Epoch: 5| Step: 10
Training loss: 2.416349346330779
Validation loss: 2.4721370230208444

Epoch: 5| Step: 11
Training loss: 1.5552324269756286
Validation loss: 2.4645425579237523

Epoch: 69| Step: 0
Training loss: 2.642952248986649
Validation loss: 2.461693420570396

Epoch: 5| Step: 1
Training loss: 2.2795157960753167
Validation loss: 2.4564471579024567

Epoch: 5| Step: 2
Training loss: 2.3940419230730177
Validation loss: 2.4703433653165767

Epoch: 5| Step: 3
Training loss: 2.2993103403143866
Validation loss: 2.4645248343801134

Epoch: 5| Step: 4
Training loss: 1.8930900204267764
Validation loss: 2.4772618065575567

Epoch: 5| Step: 5
Training loss: 2.1675672004604523
Validation loss: 2.4571128916556817

Epoch: 5| Step: 6
Training loss: 2.1609263918378065
Validation loss: 2.465176506977181

Epoch: 5| Step: 7
Training loss: 2.710958167445309
Validation loss: 2.477980976641842

Epoch: 5| Step: 8
Training loss: 2.018835659985128
Validation loss: 2.47197631277872

Epoch: 5| Step: 9
Training loss: 2.188500747649161
Validation loss: 2.4755078465812446

Epoch: 5| Step: 10
Training loss: 2.425849065892337
Validation loss: 2.4716170077073714

Epoch: 5| Step: 11
Training loss: 2.405357690807656
Validation loss: 2.460827912812206

Epoch: 70| Step: 0
Training loss: 2.331804376298001
Validation loss: 2.446525597827768

Epoch: 5| Step: 1
Training loss: 2.49165352867856
Validation loss: 2.4405576365312682

Epoch: 5| Step: 2
Training loss: 1.9551520852838957
Validation loss: 2.4569447334878323

Epoch: 5| Step: 3
Training loss: 1.570538708539835
Validation loss: 2.441311631467275

Epoch: 5| Step: 4
Training loss: 2.811432190686731
Validation loss: 2.477141576349067

Epoch: 5| Step: 5
Training loss: 2.2521544843709473
Validation loss: 2.46449289378997

Epoch: 5| Step: 6
Training loss: 2.4053442104767506
Validation loss: 2.430079065725462

Epoch: 5| Step: 7
Training loss: 2.1451213976601564
Validation loss: 2.445887281731595

Epoch: 5| Step: 8
Training loss: 2.676254787449695
Validation loss: 2.445370861327963

Epoch: 5| Step: 9
Training loss: 2.820100390629085
Validation loss: 2.4571373193403585

Epoch: 5| Step: 10
Training loss: 2.107795293354586
Validation loss: 2.441915026739352

Epoch: 5| Step: 11
Training loss: 1.2062711328424283
Validation loss: 2.452623692697591

Epoch: 71| Step: 0
Training loss: 2.167168986950318
Validation loss: 2.44667935585955

Epoch: 5| Step: 1
Training loss: 2.0838135610862465
Validation loss: 2.4701562268642436

Epoch: 5| Step: 2
Training loss: 1.9169438065007263
Validation loss: 2.477068250742286

Epoch: 5| Step: 3
Training loss: 2.9330210526728857
Validation loss: 2.4990765853026327

Epoch: 5| Step: 4
Training loss: 1.8786139944953355
Validation loss: 2.524402906146014

Epoch: 5| Step: 5
Training loss: 2.489907875348437
Validation loss: 2.501296112725941

Epoch: 5| Step: 6
Training loss: 2.0887038500086055
Validation loss: 2.4993960207282298

Epoch: 5| Step: 7
Training loss: 2.01285723720157
Validation loss: 2.491668192651424

Epoch: 5| Step: 8
Training loss: 2.8432994108274663
Validation loss: 2.484996090232849

Epoch: 5| Step: 9
Training loss: 2.296604062663412
Validation loss: 2.480250127174003

Epoch: 5| Step: 10
Training loss: 2.4191960438534514
Validation loss: 2.481470345354977

Epoch: 5| Step: 11
Training loss: 2.741269732402956
Validation loss: 2.4563908149145814

Epoch: 72| Step: 0
Training loss: 2.4100282409406217
Validation loss: 2.4470730985153235

Epoch: 5| Step: 1
Training loss: 2.3219532929026343
Validation loss: 2.448340802615176

Epoch: 5| Step: 2
Training loss: 2.2737812424705326
Validation loss: 2.432345879145951

Epoch: 5| Step: 3
Training loss: 2.153647247892113
Validation loss: 2.459486585119057

Epoch: 5| Step: 4
Training loss: 1.6689213839758072
Validation loss: 2.441343427739906

Epoch: 5| Step: 5
Training loss: 2.4989240238261483
Validation loss: 2.4479033381863533

Epoch: 5| Step: 6
Training loss: 2.2569671421050845
Validation loss: 2.4607335566225434

Epoch: 5| Step: 7
Training loss: 2.3899350635533403
Validation loss: 2.4594745102058044

Epoch: 5| Step: 8
Training loss: 2.4133672114184486
Validation loss: 2.467914709594593

Epoch: 5| Step: 9
Training loss: 2.322753444348414
Validation loss: 2.4607058138500153

Epoch: 5| Step: 10
Training loss: 2.2541209735105645
Validation loss: 2.4991544982562615

Epoch: 5| Step: 11
Training loss: 3.03007720597108
Validation loss: 2.4917916727976026

Epoch: 73| Step: 0
Training loss: 2.5666556737920336
Validation loss: 2.4639569685871368

Epoch: 5| Step: 1
Training loss: 1.8838263983064625
Validation loss: 2.4777143709827714

Epoch: 5| Step: 2
Training loss: 2.7577635676984182
Validation loss: 2.469809053510789

Epoch: 5| Step: 3
Training loss: 2.639814173342793
Validation loss: 2.454493649066607

Epoch: 5| Step: 4
Training loss: 1.9850781614159534
Validation loss: 2.420686011556299

Epoch: 5| Step: 5
Training loss: 2.460811454330345
Validation loss: 2.459847195610433

Epoch: 5| Step: 6
Training loss: 2.5154903209957284
Validation loss: 2.4531375779398426

Epoch: 5| Step: 7
Training loss: 1.6647840198272326
Validation loss: 2.4413462232203953

Epoch: 5| Step: 8
Training loss: 2.3132773458904596
Validation loss: 2.4711989115166584

Epoch: 5| Step: 9
Training loss: 1.8297134410605682
Validation loss: 2.457515375730186

Epoch: 5| Step: 10
Training loss: 2.4236285352642266
Validation loss: 2.451052898138609

Epoch: 5| Step: 11
Training loss: 1.3149770341615532
Validation loss: 2.444220342682939

Epoch: 74| Step: 0
Training loss: 2.4724448838373085
Validation loss: 2.433654433341377

Epoch: 5| Step: 1
Training loss: 2.269363265788577
Validation loss: 2.465782264944706

Epoch: 5| Step: 2
Training loss: 2.403325570297225
Validation loss: 2.450965882824044

Epoch: 5| Step: 3
Training loss: 2.1647332319162444
Validation loss: 2.4466355941923266

Epoch: 5| Step: 4
Training loss: 1.9276176193112826
Validation loss: 2.4487107483718535

Epoch: 5| Step: 5
Training loss: 2.57045330369225
Validation loss: 2.4536750606015323

Epoch: 5| Step: 6
Training loss: 2.741573080148765
Validation loss: 2.45183658579161

Epoch: 5| Step: 7
Training loss: 2.0484035695726295
Validation loss: 2.4408098514708474

Epoch: 5| Step: 8
Training loss: 2.390947507160002
Validation loss: 2.4583940188681686

Epoch: 5| Step: 9
Training loss: 2.162493085023265
Validation loss: 2.469705139364895

Epoch: 5| Step: 10
Training loss: 1.9610188379934264
Validation loss: 2.458508543193249

Epoch: 5| Step: 11
Training loss: 1.2846583181531284
Validation loss: 2.4712057454300504

Epoch: 75| Step: 0
Training loss: 2.4676800111235218
Validation loss: 2.4671676489989918

Epoch: 5| Step: 1
Training loss: 2.235480188591253
Validation loss: 2.484511157769196

Epoch: 5| Step: 2
Training loss: 2.4092461894196098
Validation loss: 2.4924757142065137

Epoch: 5| Step: 3
Training loss: 2.7446650862535966
Validation loss: 2.4990996010908173

Epoch: 5| Step: 4
Training loss: 2.435878312013952
Validation loss: 2.487020954892788

Epoch: 5| Step: 5
Training loss: 2.2102394754456722
Validation loss: 2.4963293586218294

Epoch: 5| Step: 6
Training loss: 1.6942997029852087
Validation loss: 2.482061332413872

Epoch: 5| Step: 7
Training loss: 2.5822720552422735
Validation loss: 2.4894910672912394

Epoch: 5| Step: 8
Training loss: 2.116497194709604
Validation loss: 2.4579877219820774

Epoch: 5| Step: 9
Training loss: 1.769828720857438
Validation loss: 2.4624316609447976

Epoch: 5| Step: 10
Training loss: 1.757721351803504
Validation loss: 2.4498969178020507

Epoch: 5| Step: 11
Training loss: 3.6209359901078075
Validation loss: 2.4463116815451507

Epoch: 76| Step: 0
Training loss: 2.2490508938768574
Validation loss: 2.4540435342927376

Epoch: 5| Step: 1
Training loss: 2.038189112670556
Validation loss: 2.4399622682874633

Epoch: 5| Step: 2
Training loss: 1.9163561721522808
Validation loss: 2.4380036714000455

Epoch: 5| Step: 3
Training loss: 2.2854233284096543
Validation loss: 2.4461123607621573

Epoch: 5| Step: 4
Training loss: 2.4668582476715653
Validation loss: 2.4693161802078016

Epoch: 5| Step: 5
Training loss: 2.5755873704626997
Validation loss: 2.462909838576046

Epoch: 5| Step: 6
Training loss: 2.400367780162345
Validation loss: 2.4841815385327464

Epoch: 5| Step: 7
Training loss: 2.582107150394926
Validation loss: 2.478452208228473

Epoch: 5| Step: 8
Training loss: 2.401395384137021
Validation loss: 2.4583541733187095

Epoch: 5| Step: 9
Training loss: 1.9351911015735306
Validation loss: 2.464726041712785

Epoch: 5| Step: 10
Training loss: 2.4041795616751696
Validation loss: 2.4409004765821316

Epoch: 5| Step: 11
Training loss: 2.625534548146945
Validation loss: 2.459407088326077

Epoch: 77| Step: 0
Training loss: 2.2498089391332234
Validation loss: 2.453187953845817

Epoch: 5| Step: 1
Training loss: 2.480805237542325
Validation loss: 2.4930792541463735

Epoch: 5| Step: 2
Training loss: 2.355340198153049
Validation loss: 2.493996405159675

Epoch: 5| Step: 3
Training loss: 2.4049504721889057
Validation loss: 2.5161990227535997

Epoch: 5| Step: 4
Training loss: 2.3961991293476785
Validation loss: 2.562107308079597

Epoch: 5| Step: 5
Training loss: 2.455223497989408
Validation loss: 2.5531316923258434

Epoch: 5| Step: 6
Training loss: 2.6011812314462297
Validation loss: 2.56160105079755

Epoch: 5| Step: 7
Training loss: 2.214347662696412
Validation loss: 2.535786076833627

Epoch: 5| Step: 8
Training loss: 1.9612084919589463
Validation loss: 2.5277001642065664

Epoch: 5| Step: 9
Training loss: 2.0577346775456324
Validation loss: 2.4918392161254235

Epoch: 5| Step: 10
Training loss: 2.132061948516795
Validation loss: 2.4905299910065954

Epoch: 5| Step: 11
Training loss: 1.9228673094438375
Validation loss: 2.481360906321136

Epoch: 78| Step: 0
Training loss: 2.024941610742518
Validation loss: 2.455663812980618

Epoch: 5| Step: 1
Training loss: 2.237333779580879
Validation loss: 2.445959633214957

Epoch: 5| Step: 2
Training loss: 2.322033176707531
Validation loss: 2.4529635503815745

Epoch: 5| Step: 3
Training loss: 2.061436234314448
Validation loss: 2.443953842513624

Epoch: 5| Step: 4
Training loss: 2.330920902371591
Validation loss: 2.4373303338039514

Epoch: 5| Step: 5
Training loss: 2.542395086083726
Validation loss: 2.4480631473354095

Epoch: 5| Step: 6
Training loss: 2.4022975017779
Validation loss: 2.444232405571737

Epoch: 5| Step: 7
Training loss: 2.1387822370925558
Validation loss: 2.4690650143417625

Epoch: 5| Step: 8
Training loss: 2.2215222514615993
Validation loss: 2.440509743437686

Epoch: 5| Step: 9
Training loss: 2.3160765543524975
Validation loss: 2.464083794723735

Epoch: 5| Step: 10
Training loss: 2.611903170807742
Validation loss: 2.434454792626435

Epoch: 5| Step: 11
Training loss: 1.417835828367658
Validation loss: 2.4499526437736923

Epoch: 79| Step: 0
Training loss: 1.8109460944036786
Validation loss: 2.443713554084532

Epoch: 5| Step: 1
Training loss: 2.207096605261599
Validation loss: 2.4442164043481993

Epoch: 5| Step: 2
Training loss: 2.965770953398536
Validation loss: 2.446942071819576

Epoch: 5| Step: 3
Training loss: 2.253323114285443
Validation loss: 2.4292387880204833

Epoch: 5| Step: 4
Training loss: 1.847241215938861
Validation loss: 2.443959390916813

Epoch: 5| Step: 5
Training loss: 1.6536310470600828
Validation loss: 2.457544492517355

Epoch: 5| Step: 6
Training loss: 1.9261197610898106
Validation loss: 2.457218961514688

Epoch: 5| Step: 7
Training loss: 2.073123046211654
Validation loss: 2.4946441321394595

Epoch: 5| Step: 8
Training loss: 2.311979802363521
Validation loss: 2.467141601283733

Epoch: 5| Step: 9
Training loss: 2.686913980865422
Validation loss: 2.4816644304861937

Epoch: 5| Step: 10
Training loss: 2.6270932525358766
Validation loss: 2.4838799277247077

Epoch: 5| Step: 11
Training loss: 2.3704218658785416
Validation loss: 2.471952104069245

Epoch: 80| Step: 0
Training loss: 2.087801097238638
Validation loss: 2.4774444205141113

Epoch: 5| Step: 1
Training loss: 2.5765000279650696
Validation loss: 2.4494610919538324

Epoch: 5| Step: 2
Training loss: 2.0824673823885353
Validation loss: 2.4338287027829533

Epoch: 5| Step: 3
Training loss: 2.5697026326363566
Validation loss: 2.443454231354213

Epoch: 5| Step: 4
Training loss: 2.313109137236681
Validation loss: 2.4261961155777123

Epoch: 5| Step: 5
Training loss: 2.0332902492065195
Validation loss: 2.442049557171808

Epoch: 5| Step: 6
Training loss: 2.1423731438951306
Validation loss: 2.4072900893963993

Epoch: 5| Step: 7
Training loss: 2.092409074601244
Validation loss: 2.4400599437330985

Epoch: 5| Step: 8
Training loss: 2.240123157351247
Validation loss: 2.4347542760706804

Epoch: 5| Step: 9
Training loss: 2.1131506013941275
Validation loss: 2.4377669999208584

Epoch: 5| Step: 10
Training loss: 2.2969864798759505
Validation loss: 2.4372443692744263

Epoch: 5| Step: 11
Training loss: 2.8167400188788916
Validation loss: 2.4230238681397727

Epoch: 81| Step: 0
Training loss: 2.151443209973758
Validation loss: 2.4412719323403116

Epoch: 5| Step: 1
Training loss: 2.6436735534437177
Validation loss: 2.4498510259470008

Epoch: 5| Step: 2
Training loss: 1.855682553471313
Validation loss: 2.430497922592489

Epoch: 5| Step: 3
Training loss: 2.3526072668415887
Validation loss: 2.444221163676585

Epoch: 5| Step: 4
Training loss: 2.3246070857959027
Validation loss: 2.451625288610465

Epoch: 5| Step: 5
Training loss: 2.3993755084407633
Validation loss: 2.445724903467292

Epoch: 5| Step: 6
Training loss: 2.3406250529677584
Validation loss: 2.466985123982889

Epoch: 5| Step: 7
Training loss: 2.1832708621612333
Validation loss: 2.4605377074359174

Epoch: 5| Step: 8
Training loss: 1.8000890762752921
Validation loss: 2.443266763413448

Epoch: 5| Step: 9
Training loss: 2.80637574455758
Validation loss: 2.4616390903424574

Epoch: 5| Step: 10
Training loss: 1.7378147142104976
Validation loss: 2.467848033555013

Epoch: 5| Step: 11
Training loss: 1.583654856243883
Validation loss: 2.4654632652301163

Epoch: 82| Step: 0
Training loss: 2.60629090201577
Validation loss: 2.4535893731668423

Epoch: 5| Step: 1
Training loss: 2.689736079205774
Validation loss: 2.4699907001971515

Epoch: 5| Step: 2
Training loss: 1.896780664652881
Validation loss: 2.4461613117294645

Epoch: 5| Step: 3
Training loss: 2.178447849422567
Validation loss: 2.4520486264188524

Epoch: 5| Step: 4
Training loss: 2.4253059941359254
Validation loss: 2.461316780855664

Epoch: 5| Step: 5
Training loss: 1.551454181866218
Validation loss: 2.4414487260302367

Epoch: 5| Step: 6
Training loss: 1.9144535832928955
Validation loss: 2.4451760933462285

Epoch: 5| Step: 7
Training loss: 1.8811969077897417
Validation loss: 2.453452094557834

Epoch: 5| Step: 8
Training loss: 2.557997120024228
Validation loss: 2.448315248437735

Epoch: 5| Step: 9
Training loss: 2.2154928665683364
Validation loss: 2.459939207208456

Epoch: 5| Step: 10
Training loss: 2.4122529886713293
Validation loss: 2.44004509174784

Epoch: 5| Step: 11
Training loss: 1.5744112337250515
Validation loss: 2.425012803617413

Epoch: 83| Step: 0
Training loss: 2.117785830251714
Validation loss: 2.4516038004968492

Epoch: 5| Step: 1
Training loss: 2.148407648052551
Validation loss: 2.4578430015448136

Epoch: 5| Step: 2
Training loss: 2.275496032630917
Validation loss: 2.478059715222416

Epoch: 5| Step: 3
Training loss: 2.228486417801318
Validation loss: 2.527999961756704

Epoch: 5| Step: 4
Training loss: 2.45366813332655
Validation loss: 2.5272165391245047

Epoch: 5| Step: 5
Training loss: 2.2586701028243
Validation loss: 2.502396869046002

Epoch: 5| Step: 6
Training loss: 2.4597763955442495
Validation loss: 2.5071949718411077

Epoch: 5| Step: 7
Training loss: 1.776293098200669
Validation loss: 2.507241779322918

Epoch: 5| Step: 8
Training loss: 1.8533200963780303
Validation loss: 2.4649931272452172

Epoch: 5| Step: 9
Training loss: 2.3785674757497075
Validation loss: 2.4650026684295883

Epoch: 5| Step: 10
Training loss: 2.523554182159882
Validation loss: 2.4377160954664934

Epoch: 5| Step: 11
Training loss: 2.6859303703457584
Validation loss: 2.4489100483253345

Epoch: 84| Step: 0
Training loss: 3.002514103610974
Validation loss: 2.4360194967488766

Epoch: 5| Step: 1
Training loss: 1.5461108699735495
Validation loss: 2.446024209188118

Epoch: 5| Step: 2
Training loss: 2.1612346364893336
Validation loss: 2.4458564462062484

Epoch: 5| Step: 3
Training loss: 2.5901745891272743
Validation loss: 2.412872831989097

Epoch: 5| Step: 4
Training loss: 2.225345104757038
Validation loss: 2.4433036734830806

Epoch: 5| Step: 5
Training loss: 2.259677103826099
Validation loss: 2.4495939528115094

Epoch: 5| Step: 6
Training loss: 2.391095084054327
Validation loss: 2.441962672595274

Epoch: 5| Step: 7
Training loss: 2.064791360248934
Validation loss: 2.4369014755053997

Epoch: 5| Step: 8
Training loss: 2.459510219787719
Validation loss: 2.4424231931492106

Epoch: 5| Step: 9
Training loss: 1.7096221605664874
Validation loss: 2.425550723217645

Epoch: 5| Step: 10
Training loss: 1.9067882340807818
Validation loss: 2.430282789698425

Epoch: 5| Step: 11
Training loss: 1.8092635626069107
Validation loss: 2.424752320753359

Epoch: 85| Step: 0
Training loss: 2.4370733034350684
Validation loss: 2.464835119055999

Epoch: 5| Step: 1
Training loss: 1.724572808816591
Validation loss: 2.463339853118954

Epoch: 5| Step: 2
Training loss: 2.1825069664213634
Validation loss: 2.470490879999346

Epoch: 5| Step: 3
Training loss: 2.646781741394324
Validation loss: 2.522383427410559

Epoch: 5| Step: 4
Training loss: 2.6035166323317163
Validation loss: 2.5182487792099817

Epoch: 5| Step: 5
Training loss: 2.603616997246959
Validation loss: 2.506200815211272

Epoch: 5| Step: 6
Training loss: 2.3005971009112907
Validation loss: 2.5260241845433766

Epoch: 5| Step: 7
Training loss: 1.8108453103430269
Validation loss: 2.4918650575000463

Epoch: 5| Step: 8
Training loss: 2.04494869065214
Validation loss: 2.482385862716029

Epoch: 5| Step: 9
Training loss: 1.9271767533486546
Validation loss: 2.459440431932182

Epoch: 5| Step: 10
Training loss: 2.138087195335681
Validation loss: 2.4462560838010647

Epoch: 5| Step: 11
Training loss: 2.2007053154956107
Validation loss: 2.4522157794269233

Epoch: 86| Step: 0
Training loss: 2.0677408620996567
Validation loss: 2.4413611079810957

Epoch: 5| Step: 1
Training loss: 2.4018280220053305
Validation loss: 2.4246164290555656

Epoch: 5| Step: 2
Training loss: 2.7058573237527415
Validation loss: 2.428487352510678

Epoch: 5| Step: 3
Training loss: 2.093999136151242
Validation loss: 2.439116593974167

Epoch: 5| Step: 4
Training loss: 2.1179647110042525
Validation loss: 2.442084886962296

Epoch: 5| Step: 5
Training loss: 2.249047183575248
Validation loss: 2.437429952837636

Epoch: 5| Step: 6
Training loss: 2.287688275703128
Validation loss: 2.437766358094904

Epoch: 5| Step: 7
Training loss: 2.007648743360025
Validation loss: 2.4273049999623146

Epoch: 5| Step: 8
Training loss: 2.2111708447147636
Validation loss: 2.4228657408523286

Epoch: 5| Step: 9
Training loss: 2.3359804691713184
Validation loss: 2.4414372393866555

Epoch: 5| Step: 10
Training loss: 2.1014946568539368
Validation loss: 2.4238029148738582

Epoch: 5| Step: 11
Training loss: 1.8684360687000274
Validation loss: 2.4171467802912234

Epoch: 87| Step: 0
Training loss: 2.10013188447534
Validation loss: 2.429093921110857

Epoch: 5| Step: 1
Training loss: 2.3608278765370163
Validation loss: 2.440337392164114

Epoch: 5| Step: 2
Training loss: 2.025668177628541
Validation loss: 2.4419062516967878

Epoch: 5| Step: 3
Training loss: 2.598849695008092
Validation loss: 2.4549765655625344

Epoch: 5| Step: 4
Training loss: 2.1134186592486244
Validation loss: 2.4770318678591217

Epoch: 5| Step: 5
Training loss: 2.117945461503972
Validation loss: 2.4695406826586956

Epoch: 5| Step: 6
Training loss: 2.6008573842385503
Validation loss: 2.4673502611682285

Epoch: 5| Step: 7
Training loss: 1.8343694605573102
Validation loss: 2.476059727221077

Epoch: 5| Step: 8
Training loss: 2.230835251501563
Validation loss: 2.4690911785610807

Epoch: 5| Step: 9
Training loss: 1.868712883520081
Validation loss: 2.437079458556995

Epoch: 5| Step: 10
Training loss: 2.1132840704766878
Validation loss: 2.4419702615927976

Epoch: 5| Step: 11
Training loss: 1.977317635655015
Validation loss: 2.431036485744989

Epoch: 88| Step: 0
Training loss: 1.5356201558081328
Validation loss: 2.45412813317229

Epoch: 5| Step: 1
Training loss: 2.2003386713656776
Validation loss: 2.5030207166566285

Epoch: 5| Step: 2
Training loss: 2.324991152346604
Validation loss: 2.4730767750723843

Epoch: 5| Step: 3
Training loss: 2.450272377599329
Validation loss: 2.454732902490623

Epoch: 5| Step: 4
Training loss: 1.9264103788414684
Validation loss: 2.4754048518877183

Epoch: 5| Step: 5
Training loss: 1.9453685706457087
Validation loss: 2.4655096501716165

Epoch: 5| Step: 6
Training loss: 2.4205567740889977
Validation loss: 2.4720573563793926

Epoch: 5| Step: 7
Training loss: 2.449113907463713
Validation loss: 2.4713753349970657

Epoch: 5| Step: 8
Training loss: 1.8095083869429818
Validation loss: 2.445882554076176

Epoch: 5| Step: 9
Training loss: 1.9262062207395327
Validation loss: 2.455652342262456

Epoch: 5| Step: 10
Training loss: 3.018440315994859
Validation loss: 2.4389788347516936

Epoch: 5| Step: 11
Training loss: 0.7962510901522997
Validation loss: 2.424848363828404

Epoch: 89| Step: 0
Training loss: 2.5943623015392334
Validation loss: 2.4346213663753735

Epoch: 5| Step: 1
Training loss: 2.169103486993273
Validation loss: 2.420338301072694

Epoch: 5| Step: 2
Training loss: 1.7719024871362639
Validation loss: 2.4237776880910813

Epoch: 5| Step: 3
Training loss: 2.041340458040036
Validation loss: 2.41975121438979

Epoch: 5| Step: 4
Training loss: 1.979506700986662
Validation loss: 2.4135896596196638

Epoch: 5| Step: 5
Training loss: 2.0881545040143696
Validation loss: 2.4143470711655826

Epoch: 5| Step: 6
Training loss: 2.5634557290820097
Validation loss: 2.406915023690183

Epoch: 5| Step: 7
Training loss: 2.5437276853290283
Validation loss: 2.4304799487449533

Epoch: 5| Step: 8
Training loss: 1.9997796890986868
Validation loss: 2.419955126369993

Epoch: 5| Step: 9
Training loss: 2.2291268556076194
Validation loss: 2.4158198843475605

Epoch: 5| Step: 10
Training loss: 2.2373473131306088
Validation loss: 2.4257076045439945

Epoch: 5| Step: 11
Training loss: 1.134298100242581
Validation loss: 2.43518966833002

Epoch: 90| Step: 0
Training loss: 2.361302579957721
Validation loss: 2.4392754943371324

Epoch: 5| Step: 1
Training loss: 2.200581482422046
Validation loss: 2.4403801432538117

Epoch: 5| Step: 2
Training loss: 2.389369959285846
Validation loss: 2.455695399149626

Epoch: 5| Step: 3
Training loss: 2.6819028899770196
Validation loss: 2.4399912321865997

Epoch: 5| Step: 4
Training loss: 2.1914438934628926
Validation loss: 2.40940875018635

Epoch: 5| Step: 5
Training loss: 2.3625436687974886
Validation loss: 2.4214116340284093

Epoch: 5| Step: 6
Training loss: 2.1545111237524504
Validation loss: 2.4281386481007488

Epoch: 5| Step: 7
Training loss: 2.065282043518755
Validation loss: 2.437901639045016

Epoch: 5| Step: 8
Training loss: 1.7513888842167336
Validation loss: 2.4277648310082114

Epoch: 5| Step: 9
Training loss: 1.7011896739076766
Validation loss: 2.431342198291616

Epoch: 5| Step: 10
Training loss: 2.1428957958368358
Validation loss: 2.416436970964916

Epoch: 5| Step: 11
Training loss: 0.8918721685651974
Validation loss: 2.426460936697693

Epoch: 91| Step: 0
Training loss: 2.1547950590534115
Validation loss: 2.445781477947627

Epoch: 5| Step: 1
Training loss: 2.393526298886882
Validation loss: 2.478141650239763

Epoch: 5| Step: 2
Training loss: 1.917785262830814
Validation loss: 2.4656036906254255

Epoch: 5| Step: 3
Training loss: 1.8276571995746644
Validation loss: 2.4510016596282815

Epoch: 5| Step: 4
Training loss: 2.090720874999971
Validation loss: 2.463987642101369

Epoch: 5| Step: 5
Training loss: 1.937492924338926
Validation loss: 2.44288328123131

Epoch: 5| Step: 6
Training loss: 2.7617010523378758
Validation loss: 2.446683269928597

Epoch: 5| Step: 7
Training loss: 1.4845521520008982
Validation loss: 2.4400475711562706

Epoch: 5| Step: 8
Training loss: 2.418697610923523
Validation loss: 2.454492240600796

Epoch: 5| Step: 9
Training loss: 2.4114556418967554
Validation loss: 2.4305801509944853

Epoch: 5| Step: 10
Training loss: 2.2867547077027486
Validation loss: 2.4116543730659927

Epoch: 5| Step: 11
Training loss: 1.9605217603134002
Validation loss: 2.4259014744843483

Epoch: 92| Step: 0
Training loss: 2.02011235802774
Validation loss: 2.4372044490076985

Epoch: 5| Step: 1
Training loss: 2.2131526350845396
Validation loss: 2.4449663841501903

Epoch: 5| Step: 2
Training loss: 1.7875355696973836
Validation loss: 2.440573720763699

Epoch: 5| Step: 3
Training loss: 1.755523887213173
Validation loss: 2.448303489693603

Epoch: 5| Step: 4
Training loss: 1.9972552300161601
Validation loss: 2.4567489279883157

Epoch: 5| Step: 5
Training loss: 1.7536077096630387
Validation loss: 2.4781820455032872

Epoch: 5| Step: 6
Training loss: 2.525615496260017
Validation loss: 2.4981740641283245

Epoch: 5| Step: 7
Training loss: 2.237551052427461
Validation loss: 2.506687012763804

Epoch: 5| Step: 8
Training loss: 2.9445777199130605
Validation loss: 2.5065659349246223

Epoch: 5| Step: 9
Training loss: 1.9288205813375838
Validation loss: 2.5003637883623857

Epoch: 5| Step: 10
Training loss: 2.085926527358781
Validation loss: 2.4618962998577243

Epoch: 5| Step: 11
Training loss: 3.303878504793794
Validation loss: 2.4490469832271753

Epoch: 93| Step: 0
Training loss: 1.8978687580425329
Validation loss: 2.432680910945825

Epoch: 5| Step: 1
Training loss: 1.5921010481524331
Validation loss: 2.4077219919451758

Epoch: 5| Step: 2
Training loss: 2.5700510002152246
Validation loss: 2.4304053604555786

Epoch: 5| Step: 3
Training loss: 2.6832447519154194
Validation loss: 2.4513465565804715

Epoch: 5| Step: 4
Training loss: 2.191262415553171
Validation loss: 2.4178716201460153

Epoch: 5| Step: 5
Training loss: 1.483718405614564
Validation loss: 2.449966401726143

Epoch: 5| Step: 6
Training loss: 2.093426465900712
Validation loss: 2.4348476235144028

Epoch: 5| Step: 7
Training loss: 1.7083393732599932
Validation loss: 2.417591971528635

Epoch: 5| Step: 8
Training loss: 2.3046454991538328
Validation loss: 2.4259725752203134

Epoch: 5| Step: 9
Training loss: 2.4069481369472543
Validation loss: 2.4320805980145686

Epoch: 5| Step: 10
Training loss: 2.470972244020356
Validation loss: 2.4189344335811143

Epoch: 5| Step: 11
Training loss: 2.9844761376944002
Validation loss: 2.425607995538264

Epoch: 94| Step: 0
Training loss: 2.4349419302155293
Validation loss: 2.432600031766322

Epoch: 5| Step: 1
Training loss: 1.918525444086722
Validation loss: 2.4226868735055764

Epoch: 5| Step: 2
Training loss: 2.2902393635749654
Validation loss: 2.432102397495212

Epoch: 5| Step: 3
Training loss: 2.0922904549779755
Validation loss: 2.437117436538279

Epoch: 5| Step: 4
Training loss: 1.691716753714576
Validation loss: 2.453912066080625

Epoch: 5| Step: 5
Training loss: 2.6430881907384394
Validation loss: 2.444675220327165

Epoch: 5| Step: 6
Training loss: 2.0660607782897875
Validation loss: 2.4306668784366745

Epoch: 5| Step: 7
Training loss: 1.9862282576910415
Validation loss: 2.451809893043572

Epoch: 5| Step: 8
Training loss: 1.8551657981501541
Validation loss: 2.45113921327348

Epoch: 5| Step: 9
Training loss: 2.212030470860678
Validation loss: 2.4243873772760445

Epoch: 5| Step: 10
Training loss: 2.0681355096775356
Validation loss: 2.4279353456797206

Epoch: 5| Step: 11
Training loss: 2.405337965886095
Validation loss: 2.438694245655768

Epoch: 95| Step: 0
Training loss: 2.015039876538558
Validation loss: 2.436069366200595

Epoch: 5| Step: 1
Training loss: 2.298547356506661
Validation loss: 2.415836217577413

Epoch: 5| Step: 2
Training loss: 1.8437024126538917
Validation loss: 2.42010769503932

Epoch: 5| Step: 3
Training loss: 2.2401163457559954
Validation loss: 2.4208788987028194

Epoch: 5| Step: 4
Training loss: 2.203831552607428
Validation loss: 2.419577224322578

Epoch: 5| Step: 5
Training loss: 1.93726310512291
Validation loss: 2.4363499520409557

Epoch: 5| Step: 6
Training loss: 2.439796051037955
Validation loss: 2.4591726605212925

Epoch: 5| Step: 7
Training loss: 1.7338225025949918
Validation loss: 2.417353772175964

Epoch: 5| Step: 8
Training loss: 2.4246673237811334
Validation loss: 2.4186778243415876

Epoch: 5| Step: 9
Training loss: 2.5825093298537642
Validation loss: 2.428352921637514

Epoch: 5| Step: 10
Training loss: 1.793477835925307
Validation loss: 2.412646251653056

Epoch: 5| Step: 11
Training loss: 2.104585536647749
Validation loss: 2.4343545703087823

Epoch: 96| Step: 0
Training loss: 2.741506725697509
Validation loss: 2.4385230330241843

Epoch: 5| Step: 1
Training loss: 2.039281256038325
Validation loss: 2.4841575727346434

Epoch: 5| Step: 2
Training loss: 2.3778458660791264
Validation loss: 2.4911792952002068

Epoch: 5| Step: 3
Training loss: 1.867779498243526
Validation loss: 2.4906014684237965

Epoch: 5| Step: 4
Training loss: 2.4877565031214854
Validation loss: 2.5116319161805913

Epoch: 5| Step: 5
Training loss: 1.6168654853767936
Validation loss: 2.4702231200984968

Epoch: 5| Step: 6
Training loss: 1.9684974871777576
Validation loss: 2.443258192456083

Epoch: 5| Step: 7
Training loss: 2.23032893128427
Validation loss: 2.4647134100563495

Epoch: 5| Step: 8
Training loss: 2.207665492385459
Validation loss: 2.448191275648641

Epoch: 5| Step: 9
Training loss: 2.1085758532131735
Validation loss: 2.450013132773773

Epoch: 5| Step: 10
Training loss: 1.8157521372418415
Validation loss: 2.4209685198144664

Epoch: 5| Step: 11
Training loss: 0.7675653898235832
Validation loss: 2.445286097602375

Epoch: 97| Step: 0
Training loss: 1.515521331073154
Validation loss: 2.4218322586061736

Epoch: 5| Step: 1
Training loss: 2.0960319950704784
Validation loss: 2.4052218308916076

Epoch: 5| Step: 2
Training loss: 2.0298000148865283
Validation loss: 2.4197403349887177

Epoch: 5| Step: 3
Training loss: 2.010128718757309
Validation loss: 2.4136739580703424

Epoch: 5| Step: 4
Training loss: 1.6235623235508945
Validation loss: 2.4243852178534153

Epoch: 5| Step: 5
Training loss: 2.562054572120524
Validation loss: 2.4176621784525487

Epoch: 5| Step: 6
Training loss: 2.1429991538811106
Validation loss: 2.422882104486652

Epoch: 5| Step: 7
Training loss: 1.8567955011884434
Validation loss: 2.4327614321746

Epoch: 5| Step: 8
Training loss: 2.473347692250868
Validation loss: 2.43721441486965

Epoch: 5| Step: 9
Training loss: 2.0596104812865086
Validation loss: 2.4351844630128183

Epoch: 5| Step: 10
Training loss: 2.554526787698619
Validation loss: 2.416439118990668

Epoch: 5| Step: 11
Training loss: 1.511635869240647
Validation loss: 2.4266418060882486

Epoch: 98| Step: 0
Training loss: 2.0678132716790416
Validation loss: 2.4474059255234537

Epoch: 5| Step: 1
Training loss: 1.7989146722274856
Validation loss: 2.4262339752574738

Epoch: 5| Step: 2
Training loss: 1.8652795596416816
Validation loss: 2.4323101219985537

Epoch: 5| Step: 3
Training loss: 2.286678491882503
Validation loss: 2.4450053630502206

Epoch: 5| Step: 4
Training loss: 2.650631246417744
Validation loss: 2.4173232137650067

Epoch: 5| Step: 5
Training loss: 2.2636899906253123
Validation loss: 2.434334125428652

Epoch: 5| Step: 6
Training loss: 1.7798311706371701
Validation loss: 2.4165424994655536

Epoch: 5| Step: 7
Training loss: 2.0827979989487817
Validation loss: 2.401001759581561

Epoch: 5| Step: 8
Training loss: 2.2236080444725674
Validation loss: 2.4266994865873963

Epoch: 5| Step: 9
Training loss: 2.042658065600169
Validation loss: 2.429485602949661

Epoch: 5| Step: 10
Training loss: 2.0049950688555955
Validation loss: 2.374248950561568

Epoch: 5| Step: 11
Training loss: 2.0311410728005055
Validation loss: 2.4004009009674925

Epoch: 99| Step: 0
Training loss: 2.1279035814354903
Validation loss: 2.410578348138437

Epoch: 5| Step: 1
Training loss: 2.040417801764044
Validation loss: 2.437946926616544

Epoch: 5| Step: 2
Training loss: 2.3525380490476233
Validation loss: 2.4299172336771284

Epoch: 5| Step: 3
Training loss: 2.2642860402282783
Validation loss: 2.407239126465401

Epoch: 5| Step: 4
Training loss: 2.2094093676191258
Validation loss: 2.4116570175964718

Epoch: 5| Step: 5
Training loss: 2.234657109730996
Validation loss: 2.437236309052711

Epoch: 5| Step: 6
Training loss: 2.109091958730311
Validation loss: 2.4294271217161088

Epoch: 5| Step: 7
Training loss: 2.192173570193069
Validation loss: 2.435826436190825

Epoch: 5| Step: 8
Training loss: 1.2381728452770615
Validation loss: 2.4211824965237088

Epoch: 5| Step: 9
Training loss: 2.462665447738062
Validation loss: 2.414139780332229

Epoch: 5| Step: 10
Training loss: 1.6820022601771278
Validation loss: 2.4422428132161436

Epoch: 5| Step: 11
Training loss: 0.9579487042561109
Validation loss: 2.411605522876312

Epoch: 100| Step: 0
Training loss: 2.264421024723422
Validation loss: 2.432839633444885

Epoch: 5| Step: 1
Training loss: 2.15922142619936
Validation loss: 2.4244805830074863

Epoch: 5| Step: 2
Training loss: 1.6395627170350728
Validation loss: 2.4326552637306365

Epoch: 5| Step: 3
Training loss: 1.6121068194188612
Validation loss: 2.4033412816180335

Epoch: 5| Step: 4
Training loss: 1.5071794831507435
Validation loss: 2.408204684291808

Epoch: 5| Step: 5
Training loss: 2.053059560351236
Validation loss: 2.4206958997379666

Epoch: 5| Step: 6
Training loss: 2.782182001551714
Validation loss: 2.4181442710593006

Epoch: 5| Step: 7
Training loss: 2.4484949822120283
Validation loss: 2.396224656834157

Epoch: 5| Step: 8
Training loss: 1.891388920070791
Validation loss: 2.4015896117467634

Epoch: 5| Step: 9
Training loss: 1.754503110333325
Validation loss: 2.436729382696311

Epoch: 5| Step: 10
Training loss: 2.468125662746809
Validation loss: 2.4440904555766223

Epoch: 5| Step: 11
Training loss: 1.9323980159917526
Validation loss: 2.4565122386729215

Epoch: 101| Step: 0
Training loss: 2.1237561568540855
Validation loss: 2.4109427077277736

Epoch: 5| Step: 1
Training loss: 1.8233314986745657
Validation loss: 2.420039081993524

Epoch: 5| Step: 2
Training loss: 2.1024734054498238
Validation loss: 2.4136700522090813

Epoch: 5| Step: 3
Training loss: 1.6949126303781792
Validation loss: 2.4167244934420236

Epoch: 5| Step: 4
Training loss: 2.49312150726877
Validation loss: 2.402835289102098

Epoch: 5| Step: 5
Training loss: 2.235884789912532
Validation loss: 2.427915257952742

Epoch: 5| Step: 6
Training loss: 1.8953909584907713
Validation loss: 2.404383641528155

Epoch: 5| Step: 7
Training loss: 1.6125417127315103
Validation loss: 2.4198243555386347

Epoch: 5| Step: 8
Training loss: 2.5724840817269454
Validation loss: 2.4245021373727296

Epoch: 5| Step: 9
Training loss: 2.0295825863594503
Validation loss: 2.42734192356106

Epoch: 5| Step: 10
Training loss: 2.2166722199602287
Validation loss: 2.444131755035435

Epoch: 5| Step: 11
Training loss: 1.6310956772340566
Validation loss: 2.4460090278956383

Epoch: 102| Step: 0
Training loss: 2.1307808278516895
Validation loss: 2.4645035192013425

Epoch: 5| Step: 1
Training loss: 2.2915502576450266
Validation loss: 2.464848945076169

Epoch: 5| Step: 2
Training loss: 2.029804830705858
Validation loss: 2.4768199084913443

Epoch: 5| Step: 3
Training loss: 1.4883855347629367
Validation loss: 2.4783112642344145

Epoch: 5| Step: 4
Training loss: 2.196180287504787
Validation loss: 2.4730851502992257

Epoch: 5| Step: 5
Training loss: 2.190356324353807
Validation loss: 2.431430461334732

Epoch: 5| Step: 6
Training loss: 2.253206088105585
Validation loss: 2.459948087534773

Epoch: 5| Step: 7
Training loss: 2.096995670581545
Validation loss: 2.4334461193912644

Epoch: 5| Step: 8
Training loss: 1.6310393274127815
Validation loss: 2.4243579770020207

Epoch: 5| Step: 9
Training loss: 1.9095585361807021
Validation loss: 2.422869685191232

Epoch: 5| Step: 10
Training loss: 2.179801473064714
Validation loss: 2.4082388482044337

Epoch: 5| Step: 11
Training loss: 2.6660926220852406
Validation loss: 2.4139503897402377

Epoch: 103| Step: 0
Training loss: 1.8473194936447055
Validation loss: 2.4193605968191476

Epoch: 5| Step: 1
Training loss: 1.6727851458101153
Validation loss: 2.4237969903946857

Epoch: 5| Step: 2
Training loss: 1.7555852045836393
Validation loss: 2.4169078054372743

Epoch: 5| Step: 3
Training loss: 2.2193467318282334
Validation loss: 2.4286807674082738

Epoch: 5| Step: 4
Training loss: 1.8816022346734707
Validation loss: 2.3993418849201054

Epoch: 5| Step: 5
Training loss: 2.542714658544649
Validation loss: 2.412788264688081

Epoch: 5| Step: 6
Training loss: 1.90221102210389
Validation loss: 2.393365668609232

Epoch: 5| Step: 7
Training loss: 2.0678678077932866
Validation loss: 2.389623843722416

Epoch: 5| Step: 8
Training loss: 2.338478874830509
Validation loss: 2.4316395342108184

Epoch: 5| Step: 9
Training loss: 1.6661779720366374
Validation loss: 2.4235062796635507

Epoch: 5| Step: 10
Training loss: 2.082962715243771
Validation loss: 2.3988177218675175

Epoch: 5| Step: 11
Training loss: 2.8436591165293543
Validation loss: 2.411876907163355

Epoch: 104| Step: 0
Training loss: 1.9672791572530461
Validation loss: 2.425316840378752

Epoch: 5| Step: 1
Training loss: 2.3046778791841036
Validation loss: 2.401270399693727

Epoch: 5| Step: 2
Training loss: 1.9761741769373453
Validation loss: 2.412928163502919

Epoch: 5| Step: 3
Training loss: 2.1129763906868666
Validation loss: 2.413891132942896

Epoch: 5| Step: 4
Training loss: 2.216869900882816
Validation loss: 2.4701511575673427

Epoch: 5| Step: 5
Training loss: 2.0710305174416925
Validation loss: 2.4500247089606195

Epoch: 5| Step: 6
Training loss: 2.1684220123727473
Validation loss: 2.422470860347013

Epoch: 5| Step: 7
Training loss: 1.9487374424361565
Validation loss: 2.4348631110347023

Epoch: 5| Step: 8
Training loss: 2.3718126894439564
Validation loss: 2.4012562138048272

Epoch: 5| Step: 9
Training loss: 1.838040904145136
Validation loss: 2.3938007536936627

Epoch: 5| Step: 10
Training loss: 1.5629797389742357
Validation loss: 2.3814586712343053

Epoch: 5| Step: 11
Training loss: 2.569085845896872
Validation loss: 2.413373204722094

Epoch: 105| Step: 0
Training loss: 2.310776351664546
Validation loss: 2.480782868928448

Epoch: 5| Step: 1
Training loss: 1.9884132686171514
Validation loss: 2.5378575287674274

Epoch: 5| Step: 2
Training loss: 1.484279749976461
Validation loss: 2.534196500532548

Epoch: 5| Step: 3
Training loss: 2.259355380868744
Validation loss: 2.562217037736162

Epoch: 5| Step: 4
Training loss: 2.901815661600704
Validation loss: 2.555599399866639

Epoch: 5| Step: 5
Training loss: 2.1173953696818866
Validation loss: 2.5208505118917053

Epoch: 5| Step: 6
Training loss: 2.211508848955294
Validation loss: 2.469260525127062

Epoch: 5| Step: 7
Training loss: 2.129101553541533
Validation loss: 2.4405229440501643

Epoch: 5| Step: 8
Training loss: 1.7812613771309496
Validation loss: 2.3939321721696096

Epoch: 5| Step: 9
Training loss: 1.7073785703495912
Validation loss: 2.4220693243678033

Epoch: 5| Step: 10
Training loss: 1.4765847017748432
Validation loss: 2.383995062878956

Epoch: 5| Step: 11
Training loss: 2.442882268660104
Validation loss: 2.422496149947785

Epoch: 106| Step: 0
Training loss: 1.9160887911297755
Validation loss: 2.4131898424087908

Epoch: 5| Step: 1
Training loss: 2.071424538274888
Validation loss: 2.3978275389116646

Epoch: 5| Step: 2
Training loss: 2.5261053857271683
Validation loss: 2.3980702876031224

Epoch: 5| Step: 3
Training loss: 2.325247400718543
Validation loss: 2.4136931971229525

Epoch: 5| Step: 4
Training loss: 1.711027656862275
Validation loss: 2.4055029630112172

Epoch: 5| Step: 5
Training loss: 1.9729728822309127
Validation loss: 2.387534281599371

Epoch: 5| Step: 6
Training loss: 2.6098965791696003
Validation loss: 2.401935048473971

Epoch: 5| Step: 7
Training loss: 1.5194977509010292
Validation loss: 2.4119581002639103

Epoch: 5| Step: 8
Training loss: 1.8712967222976906
Validation loss: 2.391519325205915

Epoch: 5| Step: 9
Training loss: 1.2900007128159083
Validation loss: 2.437010683357428

Epoch: 5| Step: 10
Training loss: 1.8755962059711555
Validation loss: 2.438563304453692

Epoch: 5| Step: 11
Training loss: 2.149969380182861
Validation loss: 2.439340011055143

Epoch: 107| Step: 0
Training loss: 1.5487062807970715
Validation loss: 2.4519549574153094

Epoch: 5| Step: 1
Training loss: 1.896059281295618
Validation loss: 2.4622396989913473

Epoch: 5| Step: 2
Training loss: 2.1318965524049824
Validation loss: 2.4596278283221085

Epoch: 5| Step: 3
Training loss: 1.5351967842632923
Validation loss: 2.4203525475049004

Epoch: 5| Step: 4
Training loss: 2.1962716936007296
Validation loss: 2.4011279991886205

Epoch: 5| Step: 5
Training loss: 1.7573367683066419
Validation loss: 2.403043662564464

Epoch: 5| Step: 6
Training loss: 2.1865818821744623
Validation loss: 2.4091215875323315

Epoch: 5| Step: 7
Training loss: 1.1173797655389106
Validation loss: 2.3990469209053296

Epoch: 5| Step: 8
Training loss: 2.6582529033902262
Validation loss: 2.3940371428295673

Epoch: 5| Step: 9
Training loss: 2.3515068377120225
Validation loss: 2.4002386903284796

Epoch: 5| Step: 10
Training loss: 2.046705399104291
Validation loss: 2.4091002439985454

Epoch: 5| Step: 11
Training loss: 2.2391328107145756
Validation loss: 2.3896981148284286

Epoch: 108| Step: 0
Training loss: 2.09131697306356
Validation loss: 2.4161206415081065

Epoch: 5| Step: 1
Training loss: 1.5631455423072211
Validation loss: 2.420517848829807

Epoch: 5| Step: 2
Training loss: 2.344972622188992
Validation loss: 2.443023691107518

Epoch: 5| Step: 3
Training loss: 1.85546528062998
Validation loss: 2.4721813258051912

Epoch: 5| Step: 4
Training loss: 1.9390549726440003
Validation loss: 2.497893701807827

Epoch: 5| Step: 5
Training loss: 2.2582491020269266
Validation loss: 2.52446805304732

Epoch: 5| Step: 6
Training loss: 1.9948580326630632
Validation loss: 2.4921656281758153

Epoch: 5| Step: 7
Training loss: 1.6268355932749894
Validation loss: 2.451259770533574

Epoch: 5| Step: 8
Training loss: 1.585589140417748
Validation loss: 2.4636429462757614

Epoch: 5| Step: 9
Training loss: 2.681962807257349
Validation loss: 2.440542128161738

Epoch: 5| Step: 10
Training loss: 1.7413718191502117
Validation loss: 2.396979357798835

Epoch: 5| Step: 11
Training loss: 2.0412603350235794
Validation loss: 2.3857679205625852

Epoch: 109| Step: 0
Training loss: 1.690158445390882
Validation loss: 2.370790389889425

Epoch: 5| Step: 1
Training loss: 2.582374538391122
Validation loss: 2.404761060151856

Epoch: 5| Step: 2
Training loss: 2.1255889525212925
Validation loss: 2.383130926732936

Epoch: 5| Step: 3
Training loss: 2.1225161902503253
Validation loss: 2.388238746465344

Epoch: 5| Step: 4
Training loss: 1.8517135365365838
Validation loss: 2.3888099882091476

Epoch: 5| Step: 5
Training loss: 2.001053294343806
Validation loss: 2.392192056868731

Epoch: 5| Step: 6
Training loss: 2.1429817980884662
Validation loss: 2.3881184437700127

Epoch: 5| Step: 7
Training loss: 1.900571275457909
Validation loss: 2.395399735785109

Epoch: 5| Step: 8
Training loss: 1.9831250677099737
Validation loss: 2.396901416425764

Epoch: 5| Step: 9
Training loss: 1.3284943011085908
Validation loss: 2.406615204778234

Epoch: 5| Step: 10
Training loss: 1.9534500461945001
Validation loss: 2.4096000911759434

Epoch: 5| Step: 11
Training loss: 1.4868770192386342
Validation loss: 2.419086097477679

Epoch: 110| Step: 0
Training loss: 2.743475109050693
Validation loss: 2.4072879146368966

Epoch: 5| Step: 1
Training loss: 1.243384402421986
Validation loss: 2.4350062312973995

Epoch: 5| Step: 2
Training loss: 2.2410002964739624
Validation loss: 2.4330929260726784

Epoch: 5| Step: 3
Training loss: 1.8952993821761754
Validation loss: 2.430808423073444

Epoch: 5| Step: 4
Training loss: 1.806866342001947
Validation loss: 2.4185530409023954

Epoch: 5| Step: 5
Training loss: 1.560907391476389
Validation loss: 2.4391610240729826

Epoch: 5| Step: 6
Training loss: 2.130713467449599
Validation loss: 2.3959144405789266

Epoch: 5| Step: 7
Training loss: 1.5451875981381489
Validation loss: 2.4042827730774983

Epoch: 5| Step: 8
Training loss: 1.9549222077992652
Validation loss: 2.4041489928293953

Epoch: 5| Step: 9
Training loss: 2.0653294892953586
Validation loss: 2.404327483283201

Epoch: 5| Step: 10
Training loss: 1.8101939296628637
Validation loss: 2.4048210913334014

Epoch: 5| Step: 11
Training loss: 2.4779168405934215
Validation loss: 2.3739180651992364

Epoch: 111| Step: 0
Training loss: 2.4026555549048507
Validation loss: 2.39013002710961

Epoch: 5| Step: 1
Training loss: 2.5670106777003268
Validation loss: 2.4139412620083243

Epoch: 5| Step: 2
Training loss: 1.3637742514687379
Validation loss: 2.383774316250621

Epoch: 5| Step: 3
Training loss: 2.1316641486269603
Validation loss: 2.393523626023508

Epoch: 5| Step: 4
Training loss: 1.9134836372570996
Validation loss: 2.4354438137915957

Epoch: 5| Step: 5
Training loss: 1.94916407445393
Validation loss: 2.4133962434025467

Epoch: 5| Step: 6
Training loss: 2.015768001717774
Validation loss: 2.406337121319364

Epoch: 5| Step: 7
Training loss: 1.8763006149875703
Validation loss: 2.4039279604098702

Epoch: 5| Step: 8
Training loss: 1.5044633898503965
Validation loss: 2.3997630040389715

Epoch: 5| Step: 9
Training loss: 1.4599470565289112
Validation loss: 2.4053581781466353

Epoch: 5| Step: 10
Training loss: 1.8059792127542982
Validation loss: 2.397395739215918

Epoch: 5| Step: 11
Training loss: 1.9224995784486227
Validation loss: 2.3951435187933368

Epoch: 112| Step: 0
Training loss: 1.9225503618764883
Validation loss: 2.3715762716287143

Epoch: 5| Step: 1
Training loss: 1.5652868975592085
Validation loss: 2.3887683664890385

Epoch: 5| Step: 2
Training loss: 1.2948954537804638
Validation loss: 2.3937001572574967

Epoch: 5| Step: 3
Training loss: 2.080579756304711
Validation loss: 2.401871849376959

Epoch: 5| Step: 4
Training loss: 2.1777569277840056
Validation loss: 2.4099511626546426

Epoch: 5| Step: 5
Training loss: 2.0020009998086574
Validation loss: 2.394340374771829

Epoch: 5| Step: 6
Training loss: 1.8350637101591372
Validation loss: 2.395422630075926

Epoch: 5| Step: 7
Training loss: 2.692525733250984
Validation loss: 2.4361101695735172

Epoch: 5| Step: 8
Training loss: 2.239731776322916
Validation loss: 2.4189537498913216

Epoch: 5| Step: 9
Training loss: 1.4990315489906758
Validation loss: 2.4302156534641997

Epoch: 5| Step: 10
Training loss: 1.80384456880965
Validation loss: 2.411348650740053

Epoch: 5| Step: 11
Training loss: 1.7086668929433406
Validation loss: 2.412755680371223

Epoch: 113| Step: 0
Training loss: 1.7213686328305084
Validation loss: 2.4242109948707395

Epoch: 5| Step: 1
Training loss: 2.244923055982702
Validation loss: 2.3831328379944594

Epoch: 5| Step: 2
Training loss: 2.1408937382989714
Validation loss: 2.3772406841647418

Epoch: 5| Step: 3
Training loss: 1.7885486914426951
Validation loss: 2.4106001978323506

Epoch: 5| Step: 4
Training loss: 1.7902026811857732
Validation loss: 2.4010154339287535

Epoch: 5| Step: 5
Training loss: 1.6732815681419457
Validation loss: 2.382718523183891

Epoch: 5| Step: 6
Training loss: 2.0961303844229198
Validation loss: 2.3807087851412536

Epoch: 5| Step: 7
Training loss: 1.713613498963864
Validation loss: 2.363811979784072

Epoch: 5| Step: 8
Training loss: 1.4359689935296018
Validation loss: 2.3854643193667266

Epoch: 5| Step: 9
Training loss: 2.0530991597632484
Validation loss: 2.4212817726847105

Epoch: 5| Step: 10
Training loss: 2.364879628801839
Validation loss: 2.411352898178834

Epoch: 5| Step: 11
Training loss: 1.3275647945359978
Validation loss: 2.423355732761355

Epoch: 114| Step: 0
Training loss: 1.9389152895172357
Validation loss: 2.4201512365301365

Epoch: 5| Step: 1
Training loss: 1.8003295861605262
Validation loss: 2.4176270053918913

Epoch: 5| Step: 2
Training loss: 1.684854906893022
Validation loss: 2.408269967386217

Epoch: 5| Step: 3
Training loss: 1.726740072793731
Validation loss: 2.3987510260850953

Epoch: 5| Step: 4
Training loss: 1.7306793980230581
Validation loss: 2.3932845877511033

Epoch: 5| Step: 5
Training loss: 2.1644131483108326
Validation loss: 2.373641135659105

Epoch: 5| Step: 6
Training loss: 1.7168870019093976
Validation loss: 2.386141953434291

Epoch: 5| Step: 7
Training loss: 1.9014182845559333
Validation loss: 2.418199116338494

Epoch: 5| Step: 8
Training loss: 2.0678690760579
Validation loss: 2.432947853796811

Epoch: 5| Step: 9
Training loss: 2.1479292944738284
Validation loss: 2.420792434093017

Epoch: 5| Step: 10
Training loss: 2.138963820505936
Validation loss: 2.3845418126761126

Epoch: 5| Step: 11
Training loss: 0.8603389189155913
Validation loss: 2.3808247055437697

Epoch: 115| Step: 0
Training loss: 2.0423258541205365
Validation loss: 2.406441094708256

Epoch: 5| Step: 1
Training loss: 1.7741573402060502
Validation loss: 2.356794702117492

Epoch: 5| Step: 2
Training loss: 1.9532286959777376
Validation loss: 2.366233457173972

Epoch: 5| Step: 3
Training loss: 2.061708587471105
Validation loss: 2.415072529179509

Epoch: 5| Step: 4
Training loss: 1.7305422524025422
Validation loss: 2.3983925723031576

Epoch: 5| Step: 5
Training loss: 1.8569807778361438
Validation loss: 2.4079659771385016

Epoch: 5| Step: 6
Training loss: 2.038043823684442
Validation loss: 2.353862009899865

Epoch: 5| Step: 7
Training loss: 1.8904758741347176
Validation loss: 2.4160093216439917

Epoch: 5| Step: 8
Training loss: 1.8088501322143213
Validation loss: 2.3843056924928705

Epoch: 5| Step: 9
Training loss: 1.9092198984735989
Validation loss: 2.39817785872735

Epoch: 5| Step: 10
Training loss: 1.8854999910211474
Validation loss: 2.3926716335993437

Epoch: 5| Step: 11
Training loss: 0.8287966182019305
Validation loss: 2.366261430139437

Epoch: 116| Step: 0
Training loss: 2.393494523162664
Validation loss: 2.403098476298263

Epoch: 5| Step: 1
Training loss: 1.6638510126392754
Validation loss: 2.3966068836538765

Epoch: 5| Step: 2
Training loss: 2.112297463724356
Validation loss: 2.4343144924689737

Epoch: 5| Step: 3
Training loss: 2.110462049904455
Validation loss: 2.4501233131490205

Epoch: 5| Step: 4
Training loss: 2.128438299702881
Validation loss: 2.4208824851703192

Epoch: 5| Step: 5
Training loss: 1.967503046811373
Validation loss: 2.4217842987468092

Epoch: 5| Step: 6
Training loss: 2.05522572245317
Validation loss: 2.3956764722695696

Epoch: 5| Step: 7
Training loss: 1.2429933153526667
Validation loss: 2.419123234812865

Epoch: 5| Step: 8
Training loss: 1.7628252229872157
Validation loss: 2.4039496949222454

Epoch: 5| Step: 9
Training loss: 1.4034666278460632
Validation loss: 2.391784357759512

Epoch: 5| Step: 10
Training loss: 1.623385874833337
Validation loss: 2.3880048284684166

Epoch: 5| Step: 11
Training loss: 1.8399115223966078
Validation loss: 2.366272089418972

Epoch: 117| Step: 0
Training loss: 1.2112169497048493
Validation loss: 2.3736455489237827

Epoch: 5| Step: 1
Training loss: 2.041269562178419
Validation loss: 2.3986373097446148

Epoch: 5| Step: 2
Training loss: 1.8068934578152382
Validation loss: 2.430959587273076

Epoch: 5| Step: 3
Training loss: 1.823367261146697
Validation loss: 2.3965412932136756

Epoch: 5| Step: 4
Training loss: 1.7468138709658176
Validation loss: 2.3954725795538825

Epoch: 5| Step: 5
Training loss: 2.1764128776655873
Validation loss: 2.3901696197354623

Epoch: 5| Step: 6
Training loss: 2.077071073209596
Validation loss: 2.413025836100924

Epoch: 5| Step: 7
Training loss: 1.252028773933875
Validation loss: 2.4250982841421553

Epoch: 5| Step: 8
Training loss: 1.6410761621573877
Validation loss: 2.392748218121468

Epoch: 5| Step: 9
Training loss: 1.9039124086051078
Validation loss: 2.4263312821396825

Epoch: 5| Step: 10
Training loss: 2.437567587673482
Validation loss: 2.426758512500685

Epoch: 5| Step: 11
Training loss: 1.7910842466364318
Validation loss: 2.441778470974235

Epoch: 118| Step: 0
Training loss: 1.558306368766225
Validation loss: 2.4487469881463397

Epoch: 5| Step: 1
Training loss: 2.11481187709751
Validation loss: 2.486647887742807

Epoch: 5| Step: 2
Training loss: 1.8882529140203963
Validation loss: 2.553605934644159

Epoch: 5| Step: 3
Training loss: 1.9590395066784148
Validation loss: 2.4727158220375776

Epoch: 5| Step: 4
Training loss: 1.6505752369934774
Validation loss: 2.434966372251852

Epoch: 5| Step: 5
Training loss: 2.0362797599477105
Validation loss: 2.4605658719858154

Epoch: 5| Step: 6
Training loss: 1.5142384902191697
Validation loss: 2.43183650360252

Epoch: 5| Step: 7
Training loss: 1.7837960635187464
Validation loss: 2.3955704807440927

Epoch: 5| Step: 8
Training loss: 2.0149911283009034
Validation loss: 2.3854346809095692

Epoch: 5| Step: 9
Training loss: 1.7197214329051123
Validation loss: 2.4081184432132448

Epoch: 5| Step: 10
Training loss: 2.364674660239606
Validation loss: 2.422188203309791

Epoch: 5| Step: 11
Training loss: 1.339357159843309
Validation loss: 2.3772151429600195

Epoch: 119| Step: 0
Training loss: 1.7694570092128241
Validation loss: 2.4059361876592207

Epoch: 5| Step: 1
Training loss: 2.4164131842784133
Validation loss: 2.397995820107581

Epoch: 5| Step: 2
Training loss: 2.4986662167752627
Validation loss: 2.4154346726659828

Epoch: 5| Step: 3
Training loss: 2.136160992173779
Validation loss: 2.4070042877024367

Epoch: 5| Step: 4
Training loss: 1.398989222288029
Validation loss: 2.3949519664736605

Epoch: 5| Step: 5
Training loss: 1.4987589152296057
Validation loss: 2.368575319846356

Epoch: 5| Step: 6
Training loss: 1.5701825292139855
Validation loss: 2.3769298501130294

Epoch: 5| Step: 7
Training loss: 1.5561868922908306
Validation loss: 2.448158752699566

Epoch: 5| Step: 8
Training loss: 2.164973428752554
Validation loss: 2.4534347869070263

Epoch: 5| Step: 9
Training loss: 1.8543205483120586
Validation loss: 2.522851933111628

Epoch: 5| Step: 10
Training loss: 1.861626103857747
Validation loss: 2.460598442900675

Epoch: 5| Step: 11
Training loss: 2.1086293350727843
Validation loss: 2.4186325230355354

Epoch: 120| Step: 0
Training loss: 1.8953807695866154
Validation loss: 2.3618593798919436

Epoch: 5| Step: 1
Training loss: 2.0594823320172266
Validation loss: 2.3729807359141506

Epoch: 5| Step: 2
Training loss: 1.5968909634204695
Validation loss: 2.4111768580230315

Epoch: 5| Step: 3
Training loss: 1.5827018917559064
Validation loss: 2.4170415946457458

Epoch: 5| Step: 4
Training loss: 1.732391597995012
Validation loss: 2.3958156474469643

Epoch: 5| Step: 5
Training loss: 1.7999378140621878
Validation loss: 2.403700346791781

Epoch: 5| Step: 6
Training loss: 2.159969052693522
Validation loss: 2.4259634927220928

Epoch: 5| Step: 7
Training loss: 1.8801978860355273
Validation loss: 2.4021851650091213

Epoch: 5| Step: 8
Training loss: 1.4861300884156183
Validation loss: 2.4194288965225175

Epoch: 5| Step: 9
Training loss: 1.6581077952666037
Validation loss: 2.394503578246024

Epoch: 5| Step: 10
Training loss: 2.088505339524574
Validation loss: 2.391904469845025

Epoch: 5| Step: 11
Training loss: 2.550640201612104
Validation loss: 2.408438096413267

Epoch: 121| Step: 0
Training loss: 1.7404845943015694
Validation loss: 2.446469785673302

Epoch: 5| Step: 1
Training loss: 2.2376179669359533
Validation loss: 2.482053187594245

Epoch: 5| Step: 2
Training loss: 2.1058870087658943
Validation loss: 2.4727362930656644

Epoch: 5| Step: 3
Training loss: 1.4227583101251426
Validation loss: 2.4336077024856895

Epoch: 5| Step: 4
Training loss: 1.3199818665530483
Validation loss: 2.4225791153719225

Epoch: 5| Step: 5
Training loss: 2.4409207525082897
Validation loss: 2.4336739573316155

Epoch: 5| Step: 6
Training loss: 1.5180519572024653
Validation loss: 2.399071434646684

Epoch: 5| Step: 7
Training loss: 1.81237443949436
Validation loss: 2.4057465517900125

Epoch: 5| Step: 8
Training loss: 2.12068096380482
Validation loss: 2.4112217720505975

Epoch: 5| Step: 9
Training loss: 1.6641902247738352
Validation loss: 2.412142400476882

Epoch: 5| Step: 10
Training loss: 1.692793279619344
Validation loss: 2.3993412390259197

Epoch: 5| Step: 11
Training loss: 1.9841040478849017
Validation loss: 2.4100884129701186

Epoch: 122| Step: 0
Training loss: 1.6906831882920046
Validation loss: 2.400316043250706

Epoch: 5| Step: 1
Training loss: 1.4322080645582005
Validation loss: 2.4417911765235956

Epoch: 5| Step: 2
Training loss: 1.5498983719025963
Validation loss: 2.430584941111145

Epoch: 5| Step: 3
Training loss: 1.5987653170546088
Validation loss: 2.408609537985835

Epoch: 5| Step: 4
Training loss: 1.545435148642698
Validation loss: 2.420891297434887

Epoch: 5| Step: 5
Training loss: 2.107777308346304
Validation loss: 2.4366725654297996

Epoch: 5| Step: 6
Training loss: 1.926261238496091
Validation loss: 2.4017718267537322

Epoch: 5| Step: 7
Training loss: 1.938970991829525
Validation loss: 2.41992930938917

Epoch: 5| Step: 8
Training loss: 2.0247844204532743
Validation loss: 2.4262488585581936

Epoch: 5| Step: 9
Training loss: 1.833554413499082
Validation loss: 2.4115041944016604

Epoch: 5| Step: 10
Training loss: 1.8812787785657619
Validation loss: 2.373187352170857

Epoch: 5| Step: 11
Training loss: 2.1632285594206104
Validation loss: 2.399629770803196

Epoch: 123| Step: 0
Training loss: 1.7679553561982297
Validation loss: 2.4117505093596363

Epoch: 5| Step: 1
Training loss: 2.0350639336967764
Validation loss: 2.4097432916754116

Epoch: 5| Step: 2
Training loss: 1.7238601318541382
Validation loss: 2.429608694354254

Epoch: 5| Step: 3
Training loss: 1.7794983265100657
Validation loss: 2.3987166773443063

Epoch: 5| Step: 4
Training loss: 1.6651901221340413
Validation loss: 2.3897542406528665

Epoch: 5| Step: 5
Training loss: 1.7019088322599965
Validation loss: 2.39909828767216

Epoch: 5| Step: 6
Training loss: 1.6564274099088934
Validation loss: 2.3916084867859793

Epoch: 5| Step: 7
Training loss: 1.9498806061017577
Validation loss: 2.414305865007054

Epoch: 5| Step: 8
Training loss: 1.373486379332994
Validation loss: 2.42765267424676

Epoch: 5| Step: 9
Training loss: 2.3705095705854173
Validation loss: 2.4289260848724115

Epoch: 5| Step: 10
Training loss: 2.217959948364724
Validation loss: 2.4462971436550447

Epoch: 5| Step: 11
Training loss: 1.8500375383022478
Validation loss: 2.4187901857440157

Epoch: 124| Step: 0
Training loss: 1.6477378336648705
Validation loss: 2.393816102163499

Epoch: 5| Step: 1
Training loss: 1.6120621552517818
Validation loss: 2.37905160703094

Epoch: 5| Step: 2
Training loss: 2.296099577302862
Validation loss: 2.3586212579471497

Epoch: 5| Step: 3
Training loss: 1.303554248323344
Validation loss: 2.3630285248782923

Epoch: 5| Step: 4
Training loss: 1.5962840858829037
Validation loss: 2.399840190156345

Epoch: 5| Step: 5
Training loss: 1.652635553083779
Validation loss: 2.405611232094776

Epoch: 5| Step: 6
Training loss: 1.6929657334466737
Validation loss: 2.4318229923522114

Epoch: 5| Step: 7
Training loss: 2.220951331500655
Validation loss: 2.4015932725214273

Epoch: 5| Step: 8
Training loss: 1.6384019595287198
Validation loss: 2.401377351730821

Epoch: 5| Step: 9
Training loss: 2.3480723896077778
Validation loss: 2.4042034673325925

Epoch: 5| Step: 10
Training loss: 1.5430120148206428
Validation loss: 2.395115874851413

Epoch: 5| Step: 11
Training loss: 0.6902825442886635
Validation loss: 2.3839295775743228

Epoch: 125| Step: 0
Training loss: 2.105902405987153
Validation loss: 2.3996485201108917

Epoch: 5| Step: 1
Training loss: 1.931606558565881
Validation loss: 2.411867792178552

Epoch: 5| Step: 2
Training loss: 1.54517085676901
Validation loss: 2.393517313239623

Epoch: 5| Step: 3
Training loss: 1.8815570618722406
Validation loss: 2.44771399504447

Epoch: 5| Step: 4
Training loss: 2.1240849488219653
Validation loss: 2.470219579127716

Epoch: 5| Step: 5
Training loss: 1.8262242926760213
Validation loss: 2.4390660496290217

Epoch: 5| Step: 6
Training loss: 1.7864674900661792
Validation loss: 2.4210323672675016

Epoch: 5| Step: 7
Training loss: 1.870299168589412
Validation loss: 2.4064016748490578

Epoch: 5| Step: 8
Training loss: 1.5179018831471196
Validation loss: 2.3781967148930914

Epoch: 5| Step: 9
Training loss: 1.3318274557434038
Validation loss: 2.40151828550607

Epoch: 5| Step: 10
Training loss: 1.6245552334634505
Validation loss: 2.41486201785914

Epoch: 5| Step: 11
Training loss: 1.5517374545106923
Validation loss: 2.396286437822677

Epoch: 126| Step: 0
Training loss: 1.7030599739190087
Validation loss: 2.416756321351156

Epoch: 5| Step: 1
Training loss: 2.1128101775753696
Validation loss: 2.381316035065114

Epoch: 5| Step: 2
Training loss: 1.840202539533387
Validation loss: 2.4116053416274545

Epoch: 5| Step: 3
Training loss: 1.686561323401914
Validation loss: 2.407145936143169

Epoch: 5| Step: 4
Training loss: 1.3263413063999108
Validation loss: 2.4206738805756185

Epoch: 5| Step: 5
Training loss: 2.162140802087824
Validation loss: 2.3655236023001103

Epoch: 5| Step: 6
Training loss: 1.621854672460749
Validation loss: 2.4006570120387534

Epoch: 5| Step: 7
Training loss: 1.4937280820890513
Validation loss: 2.388326435370865

Epoch: 5| Step: 8
Training loss: 1.4598934910737635
Validation loss: 2.3843633076492345

Epoch: 5| Step: 9
Training loss: 2.0625745586443758
Validation loss: 2.4178756712385843

Epoch: 5| Step: 10
Training loss: 1.5737587230583028
Validation loss: 2.477112116431208

Epoch: 5| Step: 11
Training loss: 2.129608654373491
Validation loss: 2.4579356944159283

Epoch: 127| Step: 0
Training loss: 1.7112885554827808
Validation loss: 2.4156312587931668

Epoch: 5| Step: 1
Training loss: 1.6075447563953194
Validation loss: 2.409189958966701

Epoch: 5| Step: 2
Training loss: 1.8441802993640561
Validation loss: 2.4266138188850532

Epoch: 5| Step: 3
Training loss: 1.6358332093378538
Validation loss: 2.385179428036282

Epoch: 5| Step: 4
Training loss: 1.745625751084092
Validation loss: 2.408249453686555

Epoch: 5| Step: 5
Training loss: 1.9342142978157508
Validation loss: 2.405663356856781

Epoch: 5| Step: 6
Training loss: 1.7607247197812828
Validation loss: 2.4021667994224334

Epoch: 5| Step: 7
Training loss: 1.5083091589885493
Validation loss: 2.442275813566844

Epoch: 5| Step: 8
Training loss: 1.7516185904649455
Validation loss: 2.4461258012070246

Epoch: 5| Step: 9
Training loss: 1.9418160142340948
Validation loss: 2.4281788565130076

Epoch: 5| Step: 10
Training loss: 1.90929831992355
Validation loss: 2.38582998273745

Epoch: 5| Step: 11
Training loss: 2.1708530793661747
Validation loss: 2.3890239823078256

Epoch: 128| Step: 0
Training loss: 1.7694292523290676
Validation loss: 2.4181543277977635

Epoch: 5| Step: 1
Training loss: 1.6506363364151397
Validation loss: 2.473877382794473

Epoch: 5| Step: 2
Training loss: 2.043397934946699
Validation loss: 2.5587133268024447

Epoch: 5| Step: 3
Training loss: 2.2358527998539497
Validation loss: 2.5947259422706375

Epoch: 5| Step: 4
Training loss: 1.9928998683269594
Validation loss: 2.6302953283948853

Epoch: 5| Step: 5
Training loss: 1.9764359625920833
Validation loss: 2.6114562142760045

Epoch: 5| Step: 6
Training loss: 1.4927764848625347
Validation loss: 2.468413422573312

Epoch: 5| Step: 7
Training loss: 1.4442064331678466
Validation loss: 2.409065877872721

Epoch: 5| Step: 8
Training loss: 1.9820772820503907
Validation loss: 2.3755468107137294

Epoch: 5| Step: 9
Training loss: 1.6197257646931067
Validation loss: 2.371468214351638

Epoch: 5| Step: 10
Training loss: 1.7838542706194844
Validation loss: 2.389991946539352

Epoch: 5| Step: 11
Training loss: 1.466959572212243
Validation loss: 2.432328692909304

Epoch: 129| Step: 0
Training loss: 1.9545304391578568
Validation loss: 2.436992661749324

Epoch: 5| Step: 1
Training loss: 2.746747434255711
Validation loss: 2.4562599576662487

Epoch: 5| Step: 2
Training loss: 1.6270937269255763
Validation loss: 2.431474077886676

Epoch: 5| Step: 3
Training loss: 1.7160581142793103
Validation loss: 2.424559563527202

Epoch: 5| Step: 4
Training loss: 1.6395345060970017
Validation loss: 2.4208727988234098

Epoch: 5| Step: 5
Training loss: 1.5652140125523832
Validation loss: 2.407914688150025

Epoch: 5| Step: 6
Training loss: 1.8882829015090912
Validation loss: 2.407478415292415

Epoch: 5| Step: 7
Training loss: 1.6309841450915201
Validation loss: 2.396459567421683

Epoch: 5| Step: 8
Training loss: 1.7232175850995468
Validation loss: 2.448120820210141

Epoch: 5| Step: 9
Training loss: 1.4077886852489843
Validation loss: 2.4827312813901057

Epoch: 5| Step: 10
Training loss: 1.6373567999039338
Validation loss: 2.473487886906437

Epoch: 5| Step: 11
Training loss: 1.5905037524584695
Validation loss: 2.467942608820353

Epoch: 130| Step: 0
Training loss: 2.136583955128947
Validation loss: 2.4407661758601087

Epoch: 5| Step: 1
Training loss: 1.8163347127629978
Validation loss: 2.424743053417545

Epoch: 5| Step: 2
Training loss: 1.709685193915983
Validation loss: 2.4037361141841247

Epoch: 5| Step: 3
Training loss: 1.8099654662278444
Validation loss: 2.375508979584344

Epoch: 5| Step: 4
Training loss: 1.6563822135696247
Validation loss: 2.389456369829056

Epoch: 5| Step: 5
Training loss: 1.629404042244492
Validation loss: 2.3940849033401777

Epoch: 5| Step: 6
Training loss: 1.2249330521798703
Validation loss: 2.41021407360451

Epoch: 5| Step: 7
Training loss: 1.5655259396095396
Validation loss: 2.4509660408964926

Epoch: 5| Step: 8
Training loss: 1.9505912520188315
Validation loss: 2.4413010719531663

Epoch: 5| Step: 9
Training loss: 1.5934917016245684
Validation loss: 2.4327452860820418

Epoch: 5| Step: 10
Training loss: 2.0332752401881207
Validation loss: 2.3886918747845214

Epoch: 5| Step: 11
Training loss: 2.111349467435203
Validation loss: 2.406558504185919

Epoch: 131| Step: 0
Training loss: 1.5881580911106519
Validation loss: 2.4327047366213987

Epoch: 5| Step: 1
Training loss: 1.8770738576747954
Validation loss: 2.4709405757302276

Epoch: 5| Step: 2
Training loss: 1.7633469325564592
Validation loss: 2.52270081339839

Epoch: 5| Step: 3
Training loss: 1.7865409572464175
Validation loss: 2.4827545127234814

Epoch: 5| Step: 4
Training loss: 2.072570950866221
Validation loss: 2.476061873673818

Epoch: 5| Step: 5
Training loss: 1.80975936997253
Validation loss: 2.4527628564494734

Epoch: 5| Step: 6
Training loss: 1.546166074505906
Validation loss: 2.4203364992275564

Epoch: 5| Step: 7
Training loss: 1.3509415539679146
Validation loss: 2.3739332723082858

Epoch: 5| Step: 8
Training loss: 1.9530377788141897
Validation loss: 2.3692938159412984

Epoch: 5| Step: 9
Training loss: 1.5513793406946383
Validation loss: 2.403117597458595

Epoch: 5| Step: 10
Training loss: 1.7304324454122375
Validation loss: 2.3326182263018085

Epoch: 5| Step: 11
Training loss: 1.5007673526023155
Validation loss: 2.3683017043132075

Epoch: 132| Step: 0
Training loss: 1.3334481766038417
Validation loss: 2.4230842955198253

Epoch: 5| Step: 1
Training loss: 1.4068572534622206
Validation loss: 2.369365915193669

Epoch: 5| Step: 2
Training loss: 1.611427479773058
Validation loss: 2.384601098919331

Epoch: 5| Step: 3
Training loss: 1.5822173586037234
Validation loss: 2.3875732016201376

Epoch: 5| Step: 4
Training loss: 1.5626885109672242
Validation loss: 2.4281703427604824

Epoch: 5| Step: 5
Training loss: 2.270387261584666
Validation loss: 2.4602591210318874

Epoch: 5| Step: 6
Training loss: 1.478714923200777
Validation loss: 2.389091804130071

Epoch: 5| Step: 7
Training loss: 2.2513876980148178
Validation loss: 2.4400317419832853

Epoch: 5| Step: 8
Training loss: 1.434595158454642
Validation loss: 2.394251854316307

Epoch: 5| Step: 9
Training loss: 1.8806120491025617
Validation loss: 2.4174837602821397

Epoch: 5| Step: 10
Training loss: 1.5473906303052076
Validation loss: 2.4011933174704585

Epoch: 5| Step: 11
Training loss: 1.874317426417394
Validation loss: 2.3778104591636606

Epoch: 133| Step: 0
Training loss: 1.3127984661250245
Validation loss: 2.3700004373890704

Epoch: 5| Step: 1
Training loss: 1.7095495717174098
Validation loss: 2.3881484066587264

Epoch: 5| Step: 2
Training loss: 1.9489522075166024
Validation loss: 2.3649854920219844

Epoch: 5| Step: 3
Training loss: 1.8455426181656436
Validation loss: 2.3327721505615693

Epoch: 5| Step: 4
Training loss: 1.594808264541548
Validation loss: 2.383003856708908

Epoch: 5| Step: 5
Training loss: 2.016439702001491
Validation loss: 2.3909355493764517

Epoch: 5| Step: 6
Training loss: 1.489253169818583
Validation loss: 2.3877323992864685

Epoch: 5| Step: 7
Training loss: 1.395296287656023
Validation loss: 2.380362980755405

Epoch: 5| Step: 8
Training loss: 1.757755329473948
Validation loss: 2.3784093019341532

Epoch: 5| Step: 9
Training loss: 1.9043841376240334
Validation loss: 2.396949057696971

Epoch: 5| Step: 10
Training loss: 1.7000153877459456
Validation loss: 2.385993106329798

Epoch: 5| Step: 11
Training loss: 0.7027585664224992
Validation loss: 2.402521063817811

Epoch: 134| Step: 0
Training loss: 1.845214908354557
Validation loss: 2.351062860986325

Epoch: 5| Step: 1
Training loss: 1.1433210517030883
Validation loss: 2.3708983984490306

Epoch: 5| Step: 2
Training loss: 1.3918953996935435
Validation loss: 2.3958298365249546

Epoch: 5| Step: 3
Training loss: 1.2740251554284274
Validation loss: 2.39236581288543

Epoch: 5| Step: 4
Training loss: 2.1034938630489908
Validation loss: 2.396822676736159

Epoch: 5| Step: 5
Training loss: 1.6416995934348733
Validation loss: 2.3720916039328093

Epoch: 5| Step: 6
Training loss: 2.3188817400665482
Validation loss: 2.374092522634223

Epoch: 5| Step: 7
Training loss: 1.5508224520266531
Validation loss: 2.3768407899071633

Epoch: 5| Step: 8
Training loss: 1.825953440938553
Validation loss: 2.4067032704999614

Epoch: 5| Step: 9
Training loss: 1.8212918115344534
Validation loss: 2.3605162489833504

Epoch: 5| Step: 10
Training loss: 1.3693921433615774
Validation loss: 2.4046629795594905

Epoch: 5| Step: 11
Training loss: 0.5964811403677721
Validation loss: 2.4298064191526785

Epoch: 135| Step: 0
Training loss: 1.3740464718968088
Validation loss: 2.4865804515735714

Epoch: 5| Step: 1
Training loss: 1.7084729284922098
Validation loss: 2.502088485022161

Epoch: 5| Step: 2
Training loss: 1.5727080486804528
Validation loss: 2.4844969553574052

Epoch: 5| Step: 3
Training loss: 1.7367932069015668
Validation loss: 2.497567877281439

Epoch: 5| Step: 4
Training loss: 1.091024599950078
Validation loss: 2.4076241743243707

Epoch: 5| Step: 5
Training loss: 1.8880395787503328
Validation loss: 2.4395205771184396

Epoch: 5| Step: 6
Training loss: 2.0329542786447656
Validation loss: 2.367144383876089

Epoch: 5| Step: 7
Training loss: 1.9317064110148086
Validation loss: 2.3874991265473424

Epoch: 5| Step: 8
Training loss: 1.2380366038579254
Validation loss: 2.4030560148314124

Epoch: 5| Step: 9
Training loss: 1.5823360196649219
Validation loss: 2.3848282131237233

Epoch: 5| Step: 10
Training loss: 2.126919832836038
Validation loss: 2.422479459743074

Epoch: 5| Step: 11
Training loss: 1.8600242186579563
Validation loss: 2.4081907867585834

Epoch: 136| Step: 0
Training loss: 1.2105507509921007
Validation loss: 2.4022259070793783

Epoch: 5| Step: 1
Training loss: 1.3282841306609618
Validation loss: 2.3621071770638196

Epoch: 5| Step: 2
Training loss: 1.9357433354113864
Validation loss: 2.399918872236922

Epoch: 5| Step: 3
Training loss: 1.8245909349983422
Validation loss: 2.4017453572655336

Epoch: 5| Step: 4
Training loss: 1.7385763882170997
Validation loss: 2.4412835255612815

Epoch: 5| Step: 5
Training loss: 1.565674494343623
Validation loss: 2.4739754498876767

Epoch: 5| Step: 6
Training loss: 1.4859509584798147
Validation loss: 2.44213050373886

Epoch: 5| Step: 7
Training loss: 1.6868609878619534
Validation loss: 2.4503386440243764

Epoch: 5| Step: 8
Training loss: 1.882348347668793
Validation loss: 2.458795909410966

Epoch: 5| Step: 9
Training loss: 1.6490620519230104
Validation loss: 2.4078728768322617

Epoch: 5| Step: 10
Training loss: 1.8735891756407992
Validation loss: 2.3573503249002474

Epoch: 5| Step: 11
Training loss: 1.4933121522326593
Validation loss: 2.3504223979949277

Epoch: 137| Step: 0
Training loss: 1.6044545926723852
Validation loss: 2.340480881155782

Epoch: 5| Step: 1
Training loss: 1.8241873826264652
Validation loss: 2.3500437051009615

Epoch: 5| Step: 2
Training loss: 2.0224335879065785
Validation loss: 2.4066383700697416

Epoch: 5| Step: 3
Training loss: 1.2996465642691484
Validation loss: 2.4067478387412886

Epoch: 5| Step: 4
Training loss: 1.7438258520330028
Validation loss: 2.4008936943305796

Epoch: 5| Step: 5
Training loss: 1.2211560683111793
Validation loss: 2.3559333212389078

Epoch: 5| Step: 6
Training loss: 1.3620015343700846
Validation loss: 2.3824566872513437

Epoch: 5| Step: 7
Training loss: 1.5440162676166715
Validation loss: 2.363052993974839

Epoch: 5| Step: 8
Training loss: 1.543086334770014
Validation loss: 2.3424009785270723

Epoch: 5| Step: 9
Training loss: 2.0067717827336704
Validation loss: 2.3853153487653733

Epoch: 5| Step: 10
Training loss: 1.592416542058142
Validation loss: 2.3846215931779624

Epoch: 5| Step: 11
Training loss: 1.5539434751690249
Validation loss: 2.4351564658846865

Epoch: 138| Step: 0
Training loss: 1.6680995344931664
Validation loss: 2.4377469646836736

Epoch: 5| Step: 1
Training loss: 1.4353949018728296
Validation loss: 2.419650703284064

Epoch: 5| Step: 2
Training loss: 1.4616579125699336
Validation loss: 2.4040604740360565

Epoch: 5| Step: 3
Training loss: 1.612768133181847
Validation loss: 2.3722508732000835

Epoch: 5| Step: 4
Training loss: 1.6058712939592796
Validation loss: 2.446665055649493

Epoch: 5| Step: 5
Training loss: 1.429562422487244
Validation loss: 2.3920352574230432

Epoch: 5| Step: 6
Training loss: 1.6087511205187661
Validation loss: 2.392771440857577

Epoch: 5| Step: 7
Training loss: 1.1620537239662063
Validation loss: 2.4162503670437094

Epoch: 5| Step: 8
Training loss: 1.5854478653366566
Validation loss: 2.386737321863585

Epoch: 5| Step: 9
Training loss: 2.0882402489515686
Validation loss: 2.381626857680028

Epoch: 5| Step: 10
Training loss: 1.4146942919144034
Validation loss: 2.3655037048029692

Epoch: 5| Step: 11
Training loss: 3.24934747454238
Validation loss: 2.39218867862738

Epoch: 139| Step: 0
Training loss: 1.389037737287737
Validation loss: 2.3812764120431034

Epoch: 5| Step: 1
Training loss: 1.6701561479035807
Validation loss: 2.394538165814202

Epoch: 5| Step: 2
Training loss: 1.4447965783675392
Validation loss: 2.3779272352306506

Epoch: 5| Step: 3
Training loss: 1.2259960445881648
Validation loss: 2.4074399408630978

Epoch: 5| Step: 4
Training loss: 1.6050476858595375
Validation loss: 2.3700391088282244

Epoch: 5| Step: 5
Training loss: 1.6143980432653524
Validation loss: 2.4048165968955164

Epoch: 5| Step: 6
Training loss: 1.5975437264584582
Validation loss: 2.432957861593433

Epoch: 5| Step: 7
Training loss: 1.6793920212718203
Validation loss: 2.4667853896034

Epoch: 5| Step: 8
Training loss: 1.8563919501182904
Validation loss: 2.4384505708852484

Epoch: 5| Step: 9
Training loss: 2.075096964581306
Validation loss: 2.4247657423493294

Epoch: 5| Step: 10
Training loss: 1.7314904083902787
Validation loss: 2.4044560313388756

Epoch: 5| Step: 11
Training loss: 1.700024153032946
Validation loss: 2.388400308014232

Epoch: 140| Step: 0
Training loss: 1.9336619971975784
Validation loss: 2.3679296297529286

Epoch: 5| Step: 1
Training loss: 1.7352541508165382
Validation loss: 2.3808866295364175

Epoch: 5| Step: 2
Training loss: 1.5803453292589862
Validation loss: 2.4292458094948426

Epoch: 5| Step: 3
Training loss: 1.6741045764721771
Validation loss: 2.4118389312651582

Epoch: 5| Step: 4
Training loss: 1.5146985712860757
Validation loss: 2.3954756110341933

Epoch: 5| Step: 5
Training loss: 1.7304462233340845
Validation loss: 2.3732714930011554

Epoch: 5| Step: 6
Training loss: 1.966305259320956
Validation loss: 2.37276566125151

Epoch: 5| Step: 7
Training loss: 0.9394940785703072
Validation loss: 2.382224013403892

Epoch: 5| Step: 8
Training loss: 1.6505154353693812
Validation loss: 2.3636283136263505

Epoch: 5| Step: 9
Training loss: 1.3147581746931118
Validation loss: 2.422565240840999

Epoch: 5| Step: 10
Training loss: 1.6120687366389064
Validation loss: 2.408995107015811

Epoch: 5| Step: 11
Training loss: 1.3059327356270305
Validation loss: 2.4247734732532145

Epoch: 141| Step: 0
Training loss: 1.4883406819969869
Validation loss: 2.3783101387826546

Epoch: 5| Step: 1
Training loss: 2.0375082004124665
Validation loss: 2.3932638065514107

Epoch: 5| Step: 2
Training loss: 1.40644224760116
Validation loss: 2.394158193746096

Epoch: 5| Step: 3
Training loss: 1.4600342594986981
Validation loss: 2.360472872121854

Epoch: 5| Step: 4
Training loss: 1.4175716295931806
Validation loss: 2.3311978293403053

Epoch: 5| Step: 5
Training loss: 1.8935439850699998
Validation loss: 2.3635202040075396

Epoch: 5| Step: 6
Training loss: 0.9442392356931648
Validation loss: 2.3420144712577633

Epoch: 5| Step: 7
Training loss: 1.3935457909666966
Validation loss: 2.3696041885387467

Epoch: 5| Step: 8
Training loss: 1.2611411458461317
Validation loss: 2.399539735654904

Epoch: 5| Step: 9
Training loss: 1.5974647015416361
Validation loss: 2.404275980325863

Epoch: 5| Step: 10
Training loss: 1.968697562351947
Validation loss: 2.373854344093298

Epoch: 5| Step: 11
Training loss: 1.646854164527385
Validation loss: 2.3648284933461117

Epoch: 142| Step: 0
Training loss: 1.479505562800514
Validation loss: 2.3702941501538324

Epoch: 5| Step: 1
Training loss: 1.2030546489806013
Validation loss: 2.413672542247813

Epoch: 5| Step: 2
Training loss: 1.8294992742628235
Validation loss: 2.41844569213271

Epoch: 5| Step: 3
Training loss: 1.6005739464115736
Validation loss: 2.395293636625151

Epoch: 5| Step: 4
Training loss: 1.5466260613394893
Validation loss: 2.4152233270981354

Epoch: 5| Step: 5
Training loss: 1.4126989629596267
Validation loss: 2.394820141439798

Epoch: 5| Step: 6
Training loss: 1.3629633579324605
Validation loss: 2.401704979307918

Epoch: 5| Step: 7
Training loss: 1.602165071595694
Validation loss: 2.4361950812976567

Epoch: 5| Step: 8
Training loss: 1.2373838331626144
Validation loss: 2.4185711013321995

Epoch: 5| Step: 9
Training loss: 1.8189664783964627
Validation loss: 2.407814287370253

Epoch: 5| Step: 10
Training loss: 1.998861644554023
Validation loss: 2.392420943929501

Epoch: 5| Step: 11
Training loss: 1.4604561568656242
Validation loss: 2.372939075172145

Epoch: 143| Step: 0
Training loss: 1.824824165339093
Validation loss: 2.4660547005324864

Epoch: 5| Step: 1
Training loss: 1.5672208803373897
Validation loss: 2.4384966426659647

Epoch: 5| Step: 2
Training loss: 1.5392847820427094
Validation loss: 2.4277301930488457

Epoch: 5| Step: 3
Training loss: 1.5796189743256703
Validation loss: 2.45790581838263

Epoch: 5| Step: 4
Training loss: 1.991892474899506
Validation loss: 2.4709691443490924

Epoch: 5| Step: 5
Training loss: 0.9571217396832441
Validation loss: 2.4313796959208123

Epoch: 5| Step: 6
Training loss: 1.40903574207692
Validation loss: 2.4064049051634115

Epoch: 5| Step: 7
Training loss: 1.545295139751371
Validation loss: 2.406485533643271

Epoch: 5| Step: 8
Training loss: 1.5564058861542012
Validation loss: 2.4292852226125485

Epoch: 5| Step: 9
Training loss: 1.9502550325146593
Validation loss: 2.416910707275583

Epoch: 5| Step: 10
Training loss: 1.4919196882135115
Validation loss: 2.427409151553088

Epoch: 5| Step: 11
Training loss: 1.8179010618794607
Validation loss: 2.399405100972228

Epoch: 144| Step: 0
Training loss: 1.187811559663203
Validation loss: 2.404210671419371

Epoch: 5| Step: 1
Training loss: 1.7768987412934656
Validation loss: 2.4153672347692585

Epoch: 5| Step: 2
Training loss: 1.3529239038184355
Validation loss: 2.4115321612883225

Epoch: 5| Step: 3
Training loss: 2.024248939916223
Validation loss: 2.4038162081516035

Epoch: 5| Step: 4
Training loss: 1.4280256608265574
Validation loss: 2.3850040592569584

Epoch: 5| Step: 5
Training loss: 1.5858701494319687
Validation loss: 2.403119437017397

Epoch: 5| Step: 6
Training loss: 1.5328528131594739
Validation loss: 2.4110388682776667

Epoch: 5| Step: 7
Training loss: 1.5500503470334837
Validation loss: 2.4127629042130705

Epoch: 5| Step: 8
Training loss: 1.312385054505021
Validation loss: 2.463607224014878

Epoch: 5| Step: 9
Training loss: 1.493739414576608
Validation loss: 2.4358288322093493

Epoch: 5| Step: 10
Training loss: 1.66372490982179
Validation loss: 2.481858624523009

Epoch: 5| Step: 11
Training loss: 1.20937882060549
Validation loss: 2.3889765988248755

Epoch: 145| Step: 0
Training loss: 1.724368881098588
Validation loss: 2.365702752028625

Epoch: 5| Step: 1
Training loss: 1.767888062001683
Validation loss: 2.4051170819731125

Epoch: 5| Step: 2
Training loss: 1.3655625195908072
Validation loss: 2.3828736511054824

Epoch: 5| Step: 3
Training loss: 1.691098579456941
Validation loss: 2.42497654506968

Epoch: 5| Step: 4
Training loss: 1.2830040717799926
Validation loss: 2.3766278838728003

Epoch: 5| Step: 5
Training loss: 1.954267244116265
Validation loss: 2.4365904203188973

Epoch: 5| Step: 6
Training loss: 1.5722346142855996
Validation loss: 2.4045166402740588

Epoch: 5| Step: 7
Training loss: 1.4655395482901643
Validation loss: 2.427336316710698

Epoch: 5| Step: 8
Training loss: 1.4326703582445113
Validation loss: 2.4067766348141424

Epoch: 5| Step: 9
Training loss: 1.5079716415622615
Validation loss: 2.4446797512028677

Epoch: 5| Step: 10
Training loss: 1.3927964391161094
Validation loss: 2.4178107646054836

Epoch: 5| Step: 11
Training loss: 1.4358666303909935
Validation loss: 2.404966621071463

Epoch: 146| Step: 0
Training loss: 1.3461311003052356
Validation loss: 2.392345187726769

Epoch: 5| Step: 1
Training loss: 2.0396365238328684
Validation loss: 2.421379629356682

Epoch: 5| Step: 2
Training loss: 1.7374868570832378
Validation loss: 2.355442559395554

Epoch: 5| Step: 3
Training loss: 1.3170443383518151
Validation loss: 2.433884135433947

Epoch: 5| Step: 4
Training loss: 1.189229258249158
Validation loss: 2.422889058280255

Epoch: 5| Step: 5
Training loss: 1.5659227647699006
Validation loss: 2.4078725137725954

Epoch: 5| Step: 6
Training loss: 1.3901742783387496
Validation loss: 2.446202178244637

Epoch: 5| Step: 7
Training loss: 0.9758291313695526
Validation loss: 2.4507710791553006

Epoch: 5| Step: 8
Training loss: 1.3187270718429938
Validation loss: 2.4107037565886102

Epoch: 5| Step: 9
Training loss: 1.5870905851340504
Validation loss: 2.398259084818937

Epoch: 5| Step: 10
Training loss: 1.8574481886033718
Validation loss: 2.416375320784228

Epoch: 5| Step: 11
Training loss: 1.8805356643366058
Validation loss: 2.4555102857911426

Epoch: 147| Step: 0
Training loss: 1.5702710502050468
Validation loss: 2.40036803675412

Epoch: 5| Step: 1
Training loss: 1.1663060425666019
Validation loss: 2.4421232671053827

Epoch: 5| Step: 2
Training loss: 1.2726973740669976
Validation loss: 2.424662202399193

Epoch: 5| Step: 3
Training loss: 1.3946774617115298
Validation loss: 2.399150651242525

Epoch: 5| Step: 4
Training loss: 1.2905815652923156
Validation loss: 2.4210090463187774

Epoch: 5| Step: 5
Training loss: 1.8511355909891654
Validation loss: 2.3855968862583823

Epoch: 5| Step: 6
Training loss: 1.5358215133010684
Validation loss: 2.4432399282473916

Epoch: 5| Step: 7
Training loss: 2.028936388969205
Validation loss: 2.3947559021055578

Epoch: 5| Step: 8
Training loss: 1.227779586401327
Validation loss: 2.42658472601608

Epoch: 5| Step: 9
Training loss: 1.5567912527842271
Validation loss: 2.4376849894955424

Epoch: 5| Step: 10
Training loss: 1.7379797513284878
Validation loss: 2.400159503434661

Epoch: 5| Step: 11
Training loss: 0.5468373421918625
Validation loss: 2.4197496132734564

Epoch: 148| Step: 0
Training loss: 1.3716870189993893
Validation loss: 2.4306070727989106

Epoch: 5| Step: 1
Training loss: 1.4111093697366124
Validation loss: 2.4648463294030347

Epoch: 5| Step: 2
Training loss: 1.6158341351737122
Validation loss: 2.448855282362189

Epoch: 5| Step: 3
Training loss: 1.2159665429600963
Validation loss: 2.475982080549588

Epoch: 5| Step: 4
Training loss: 1.3088583607523592
Validation loss: 2.40540230462999

Epoch: 5| Step: 5
Training loss: 1.2668094508522885
Validation loss: 2.4091139012428786

Epoch: 5| Step: 6
Training loss: 1.5452898168490112
Validation loss: 2.416369480873275

Epoch: 5| Step: 7
Training loss: 2.1679073840554826
Validation loss: 2.3950112895195117

Epoch: 5| Step: 8
Training loss: 1.3313610818572543
Validation loss: 2.371624308536475

Epoch: 5| Step: 9
Training loss: 1.4705427875227919
Validation loss: 2.4216932125981945

Epoch: 5| Step: 10
Training loss: 1.6788664474491
Validation loss: 2.3849288547148944

Epoch: 5| Step: 11
Training loss: 1.2880207823267318
Validation loss: 2.4284436802696865

Epoch: 149| Step: 0
Training loss: 1.2116153419587472
Validation loss: 2.431612799509522

Epoch: 5| Step: 1
Training loss: 1.5960797503917514
Validation loss: 2.416342410718027

Epoch: 5| Step: 2
Training loss: 1.2757529522478352
Validation loss: 2.4168634615440943

Epoch: 5| Step: 3
Training loss: 1.4982170794107121
Validation loss: 2.423861712136715

Epoch: 5| Step: 4
Training loss: 1.292855756265127
Validation loss: 2.4319477729918613

Epoch: 5| Step: 5
Training loss: 2.034637677979019
Validation loss: 2.4450141411907387

Epoch: 5| Step: 6
Training loss: 1.3220069440639102
Validation loss: 2.4151217370254154

Epoch: 5| Step: 7
Training loss: 1.5548294232635833
Validation loss: 2.4195041906666463

Epoch: 5| Step: 8
Training loss: 1.2473112753265572
Validation loss: 2.396781405545063

Epoch: 5| Step: 9
Training loss: 1.5185139445147249
Validation loss: 2.4289211728764473

Epoch: 5| Step: 10
Training loss: 1.7062448047377194
Validation loss: 2.4017835589368985

Epoch: 5| Step: 11
Training loss: 1.8026596500205623
Validation loss: 2.436719639076657

Epoch: 150| Step: 0
Training loss: 1.5257505414756478
Validation loss: 2.4041568561422104

Epoch: 5| Step: 1
Training loss: 1.4660006824507432
Validation loss: 2.4544972228426105

Epoch: 5| Step: 2
Training loss: 1.893563375310459
Validation loss: 2.4211652023244654

Epoch: 5| Step: 3
Training loss: 1.3219191126756407
Validation loss: 2.434325763790479

Epoch: 5| Step: 4
Training loss: 1.704042520019433
Validation loss: 2.428147061729278

Epoch: 5| Step: 5
Training loss: 0.8605980233235567
Validation loss: 2.425137951047003

Epoch: 5| Step: 6
Training loss: 1.7736189157063151
Validation loss: 2.4002786459693928

Epoch: 5| Step: 7
Training loss: 1.2654342036601625
Validation loss: 2.402651180455404

Epoch: 5| Step: 8
Training loss: 1.319115090115976
Validation loss: 2.452204327014125

Epoch: 5| Step: 9
Training loss: 1.976657367585788
Validation loss: 2.431026216682831

Epoch: 5| Step: 10
Training loss: 1.3688631524820454
Validation loss: 2.4400301134617206

Epoch: 5| Step: 11
Training loss: 0.48638606205117635
Validation loss: 2.433366665927563

Epoch: 151| Step: 0
Training loss: 1.4402038190231894
Validation loss: 2.4586403434127644

Epoch: 5| Step: 1
Training loss: 1.4563058474068578
Validation loss: 2.426171681409173

Epoch: 5| Step: 2
Training loss: 1.1847259846893785
Validation loss: 2.377027240351012

Epoch: 5| Step: 3
Training loss: 1.826426572938718
Validation loss: 2.4300978396875665

Epoch: 5| Step: 4
Training loss: 1.6245190568946828
Validation loss: 2.45124210495158

Epoch: 5| Step: 5
Training loss: 1.2090479721572924
Validation loss: 2.411345799884609

Epoch: 5| Step: 6
Training loss: 1.4920233990774996
Validation loss: 2.413537024843518

Epoch: 5| Step: 7
Training loss: 1.8194568898921528
Validation loss: 2.4094013121966262

Epoch: 5| Step: 8
Training loss: 1.439941820187928
Validation loss: 2.3990458111557067

Epoch: 5| Step: 9
Training loss: 1.2234176848501104
Validation loss: 2.404765158116668

Epoch: 5| Step: 10
Training loss: 1.5929252135878773
Validation loss: 2.3753417965404253

Epoch: 5| Step: 11
Training loss: 1.1279643528222836
Validation loss: 2.4195025709105322

Epoch: 152| Step: 0
Training loss: 1.8674566481944748
Validation loss: 2.3897680749682864

Epoch: 5| Step: 1
Training loss: 1.4231512190087663
Validation loss: 2.4242577429489724

Epoch: 5| Step: 2
Training loss: 1.3337190288748182
Validation loss: 2.4325079212536744

Epoch: 5| Step: 3
Training loss: 1.451298786430874
Validation loss: 2.4010319754404255

Epoch: 5| Step: 4
Training loss: 0.9993905952386691
Validation loss: 2.423404766265873

Epoch: 5| Step: 5
Training loss: 1.339124748002777
Validation loss: 2.42781118535876

Epoch: 5| Step: 6
Training loss: 1.5418861937377502
Validation loss: 2.4117285423957373

Epoch: 5| Step: 7
Training loss: 1.5628757787875063
Validation loss: 2.4422605560953987

Epoch: 5| Step: 8
Training loss: 2.0371433156478633
Validation loss: 2.4282166177753943

Epoch: 5| Step: 9
Training loss: 0.940375083851332
Validation loss: 2.4111740255045997

Epoch: 5| Step: 10
Training loss: 1.4060411934007029
Validation loss: 2.3673889275893507

Epoch: 5| Step: 11
Training loss: 0.8393460950610967
Validation loss: 2.435322926373057

Epoch: 153| Step: 0
Training loss: 0.9424908986145449
Validation loss: 2.4142338014006364

Epoch: 5| Step: 1
Training loss: 1.7214056133328988
Validation loss: 2.4468850877341968

Epoch: 5| Step: 2
Training loss: 1.565324519212744
Validation loss: 2.427599566873447

Epoch: 5| Step: 3
Training loss: 1.600743005015508
Validation loss: 2.4333731202787665

Epoch: 5| Step: 4
Training loss: 1.1012278379879743
Validation loss: 2.3987662600538844

Epoch: 5| Step: 5
Training loss: 1.3551678062358796
Validation loss: 2.3831868987569758

Epoch: 5| Step: 6
Training loss: 1.769128210386793
Validation loss: 2.4308718608731903

Epoch: 5| Step: 7
Training loss: 1.219796978129684
Validation loss: 2.4013755108375054

Epoch: 5| Step: 8
Training loss: 1.3495454234802995
Validation loss: 2.4721989100734643

Epoch: 5| Step: 9
Training loss: 1.6659905095236516
Validation loss: 2.450479498314275

Epoch: 5| Step: 10
Training loss: 1.374708188042842
Validation loss: 2.43595734303312

Epoch: 5| Step: 11
Training loss: 1.3743726859912413
Validation loss: 2.3791888569722848

Epoch: 154| Step: 0
Training loss: 1.7565765783142442
Validation loss: 2.403176698265018

Epoch: 5| Step: 1
Training loss: 1.4507315007288673
Validation loss: 2.463732604490041

Epoch: 5| Step: 2
Training loss: 1.18873747545257
Validation loss: 2.470510000287777

Epoch: 5| Step: 3
Training loss: 1.569913823016215
Validation loss: 2.4241963900093135

Epoch: 5| Step: 4
Training loss: 0.9849632261644136
Validation loss: 2.402307165844247

Epoch: 5| Step: 5
Training loss: 1.6530987973651476
Validation loss: 2.4105545819413345

Epoch: 5| Step: 6
Training loss: 0.8836416553628036
Validation loss: 2.4531521927284134

Epoch: 5| Step: 7
Training loss: 1.3620065232903524
Validation loss: 2.390128347962125

Epoch: 5| Step: 8
Training loss: 1.4649545856506265
Validation loss: 2.428855622750535

Epoch: 5| Step: 9
Training loss: 1.6025873394284056
Validation loss: 2.4552726253809305

Epoch: 5| Step: 10
Training loss: 2.0496846491472067
Validation loss: 2.444056439190804

Epoch: 5| Step: 11
Training loss: 1.5697055231905481
Validation loss: 2.4060780083921927

Epoch: 155| Step: 0
Training loss: 1.4153738106359848
Validation loss: 2.4287242595050063

Epoch: 5| Step: 1
Training loss: 1.4512834262201975
Validation loss: 2.398658042319246

Epoch: 5| Step: 2
Training loss: 1.7282314605755915
Validation loss: 2.467015224286108

Epoch: 5| Step: 3
Training loss: 1.5504526707850461
Validation loss: 2.490986412036165

Epoch: 5| Step: 4
Training loss: 1.8912683448481686
Validation loss: 2.44110040401973

Epoch: 5| Step: 5
Training loss: 1.488569657222969
Validation loss: 2.3828046809000436

Epoch: 5| Step: 6
Training loss: 1.4297270222188374
Validation loss: 2.3928957275514238

Epoch: 5| Step: 7
Training loss: 0.9643520384135983
Validation loss: 2.431317186612196

Epoch: 5| Step: 8
Training loss: 1.5671018354558868
Validation loss: 2.4228840561430034

Epoch: 5| Step: 9
Training loss: 1.2133818536181507
Validation loss: 2.4265686411717464

Epoch: 5| Step: 10
Training loss: 1.2007465881229291
Validation loss: 2.4224493186643548

Epoch: 5| Step: 11
Training loss: 1.7350609599900495
Validation loss: 2.423692402816823

Epoch: 156| Step: 0
Training loss: 1.5011809786288006
Validation loss: 2.3944075792579382

Epoch: 5| Step: 1
Training loss: 1.4073833137373037
Validation loss: 2.394340347803358

Epoch: 5| Step: 2
Training loss: 2.0861544264105953
Validation loss: 2.410311454338481

Epoch: 5| Step: 3
Training loss: 1.6256713947391384
Validation loss: 2.4952156958198413

Epoch: 5| Step: 4
Training loss: 1.1830863242621512
Validation loss: 2.480478786338066

Epoch: 5| Step: 5
Training loss: 1.5149102639542258
Validation loss: 2.488305830821617

Epoch: 5| Step: 6
Training loss: 1.1532245437951623
Validation loss: 2.3978181758001247

Epoch: 5| Step: 7
Training loss: 1.3799278214140847
Validation loss: 2.4290220160844376

Epoch: 5| Step: 8
Training loss: 1.425877732448279
Validation loss: 2.3905916440211605

Epoch: 5| Step: 9
Training loss: 1.295548001406024
Validation loss: 2.402701490277757

Epoch: 5| Step: 10
Training loss: 1.0787204259219951
Validation loss: 2.425446696612968

Epoch: 5| Step: 11
Training loss: 1.1824236332628568
Validation loss: 2.4846682225533723

Epoch: 157| Step: 0
Training loss: 1.4121311128032727
Validation loss: 2.513545410800574

Epoch: 5| Step: 1
Training loss: 1.4346724357636707
Validation loss: 2.5137114700799197

Epoch: 5| Step: 2
Training loss: 1.3051576509654288
Validation loss: 2.5167464053129995

Epoch: 5| Step: 3
Training loss: 1.9264874198496889
Validation loss: 2.491144546028861

Epoch: 5| Step: 4
Training loss: 1.5615197730960757
Validation loss: 2.4605856467308795

Epoch: 5| Step: 5
Training loss: 1.3469433211768607
Validation loss: 2.4539337242488704

Epoch: 5| Step: 6
Training loss: 1.1158465360487633
Validation loss: 2.484716459916424

Epoch: 5| Step: 7
Training loss: 1.2276388900090676
Validation loss: 2.4306462799275965

Epoch: 5| Step: 8
Training loss: 1.3225114106549558
Validation loss: 2.4598274795455164

Epoch: 5| Step: 9
Training loss: 1.5674251752696107
Validation loss: 2.4862205679883767

Epoch: 5| Step: 10
Training loss: 1.9171612004821172
Validation loss: 2.4406650323389094

Epoch: 5| Step: 11
Training loss: 1.7901948901588833
Validation loss: 2.442908733636332

Epoch: 158| Step: 0
Training loss: 1.220015187012622
Validation loss: 2.441804756701466

Epoch: 5| Step: 1
Training loss: 1.766308677438386
Validation loss: 2.433225821271162

Epoch: 5| Step: 2
Training loss: 1.7461149824588194
Validation loss: 2.4402060892863444

Epoch: 5| Step: 3
Training loss: 1.4348396064094466
Validation loss: 2.4571713203972254

Epoch: 5| Step: 4
Training loss: 1.0284402311851566
Validation loss: 2.450830488001177

Epoch: 5| Step: 5
Training loss: 1.41951228429861
Validation loss: 2.44796350042033

Epoch: 5| Step: 6
Training loss: 1.1480153144685543
Validation loss: 2.42875839655366

Epoch: 5| Step: 7
Training loss: 1.3244434267363028
Validation loss: 2.406591444849888

Epoch: 5| Step: 8
Training loss: 1.4613713726872823
Validation loss: 2.4232387353815064

Epoch: 5| Step: 9
Training loss: 1.4489694056943734
Validation loss: 2.3948370161127976

Epoch: 5| Step: 10
Training loss: 1.6512434522223185
Validation loss: 2.4941639133641673

Epoch: 5| Step: 11
Training loss: 1.214483176933482
Validation loss: 2.4879823801637193

Epoch: 159| Step: 0
Training loss: 1.4204374319259392
Validation loss: 2.498621960165156

Epoch: 5| Step: 1
Training loss: 1.1157283724381744
Validation loss: 2.4914561467134937

Epoch: 5| Step: 2
Training loss: 1.3645072605195694
Validation loss: 2.4366122813772098

Epoch: 5| Step: 3
Training loss: 1.1643463403161103
Validation loss: 2.4295416560256746

Epoch: 5| Step: 4
Training loss: 1.6269927643964983
Validation loss: 2.440389754207908

Epoch: 5| Step: 5
Training loss: 1.4546112335568548
Validation loss: 2.475736819352403

Epoch: 5| Step: 6
Training loss: 1.541493156910375
Validation loss: 2.52091623726916

Epoch: 5| Step: 7
Training loss: 1.3720790007509618
Validation loss: 2.4712022842562766

Epoch: 5| Step: 8
Training loss: 1.1796822453059708
Validation loss: 2.492530005984478

Epoch: 5| Step: 9
Training loss: 1.8810344864088613
Validation loss: 2.4660067346183907

Epoch: 5| Step: 10
Training loss: 1.4116962086957863
Validation loss: 2.423204957178919

Epoch: 5| Step: 11
Training loss: 1.0721601145934656
Validation loss: 2.422863541122074

Epoch: 160| Step: 0
Training loss: 1.4848938687607118
Validation loss: 2.4856995824185586

Epoch: 5| Step: 1
Training loss: 1.5246738210081294
Validation loss: 2.4669690005389833

Epoch: 5| Step: 2
Training loss: 1.6587450200159193
Validation loss: 2.4999917964005975

Epoch: 5| Step: 3
Training loss: 2.2929600158213126
Validation loss: 2.568769472981174

Epoch: 5| Step: 4
Training loss: 1.3185380376624314
Validation loss: 2.469293606941488

Epoch: 5| Step: 5
Training loss: 1.2366507592853282
Validation loss: 2.4406567778657493

Epoch: 5| Step: 6
Training loss: 1.3983044267984968
Validation loss: 2.4508123876385026

Epoch: 5| Step: 7
Training loss: 1.3139354939267842
Validation loss: 2.459040937310989

Epoch: 5| Step: 8
Training loss: 1.4930177146591432
Validation loss: 2.492471166588701

Epoch: 5| Step: 9
Training loss: 0.9964787356322872
Validation loss: 2.5056456219236947

Epoch: 5| Step: 10
Training loss: 1.5432351956704085
Validation loss: 2.44139839069373

Epoch: 5| Step: 11
Training loss: 1.065913718927625
Validation loss: 2.4762721046887406

Epoch: 161| Step: 0
Training loss: 1.9652036788444784
Validation loss: 2.410735902992086

Epoch: 5| Step: 1
Training loss: 0.9554584268681331
Validation loss: 2.4539091715632853

Epoch: 5| Step: 2
Training loss: 1.290555424696854
Validation loss: 2.373162545942034

Epoch: 5| Step: 3
Training loss: 1.194731078514306
Validation loss: 2.420629111149497

Epoch: 5| Step: 4
Training loss: 1.3235100394121473
Validation loss: 2.4414615879145107

Epoch: 5| Step: 5
Training loss: 1.3369839679952298
Validation loss: 2.4591788492016264

Epoch: 5| Step: 6
Training loss: 1.6148772761717676
Validation loss: 2.4667104311767925

Epoch: 5| Step: 7
Training loss: 1.2999917690309966
Validation loss: 2.440168432137851

Epoch: 5| Step: 8
Training loss: 1.630392517150164
Validation loss: 2.472174486551892

Epoch: 5| Step: 9
Training loss: 1.4432050031357464
Validation loss: 2.4566159890532275

Epoch: 5| Step: 10
Training loss: 1.3127015277004237
Validation loss: 2.4155245389524307

Epoch: 5| Step: 11
Training loss: 0.8879480117666472
Validation loss: 2.457584781691273

Epoch: 162| Step: 0
Training loss: 1.306083343679804
Validation loss: 2.5089761959463077

Epoch: 5| Step: 1
Training loss: 1.368508229611077
Validation loss: 2.4809599903101307

Epoch: 5| Step: 2
Training loss: 1.334613925171538
Validation loss: 2.520688491527377

Epoch: 5| Step: 3
Training loss: 1.4324873726972296
Validation loss: 2.479636461693771

Epoch: 5| Step: 4
Training loss: 1.6474707783493876
Validation loss: 2.3990307549496475

Epoch: 5| Step: 5
Training loss: 1.2891421669126124
Validation loss: 2.4620240290453315

Epoch: 5| Step: 6
Training loss: 1.4788886422360012
Validation loss: 2.5081759513282456

Epoch: 5| Step: 7
Training loss: 1.5680857190426885
Validation loss: 2.426258279824611

Epoch: 5| Step: 8
Training loss: 0.9775224773817843
Validation loss: 2.435842782088268

Epoch: 5| Step: 9
Training loss: 1.7236025194310356
Validation loss: 2.543410528964635

Epoch: 5| Step: 10
Training loss: 1.2305282336192578
Validation loss: 2.5143083479446204

Epoch: 5| Step: 11
Training loss: 1.2632579567766422
Validation loss: 2.494302284858631

Epoch: 163| Step: 0
Training loss: 1.3768352918054898
Validation loss: 2.485365823980857

Epoch: 5| Step: 1
Training loss: 1.935403119858662
Validation loss: 2.4630717514194616

Epoch: 5| Step: 2
Training loss: 1.3515853438899954
Validation loss: 2.457463099660881

Epoch: 5| Step: 3
Training loss: 1.5708587607324995
Validation loss: 2.4328455951116243

Epoch: 5| Step: 4
Training loss: 1.1826565497326555
Validation loss: 2.482428593980374

Epoch: 5| Step: 5
Training loss: 1.2023624629398084
Validation loss: 2.477297977540739

Epoch: 5| Step: 6
Training loss: 1.4525946192691501
Validation loss: 2.474970224471112

Epoch: 5| Step: 7
Training loss: 1.302411361065198
Validation loss: 2.4748827455341207

Epoch: 5| Step: 8
Training loss: 1.0976668387883115
Validation loss: 2.4891959844039113

Epoch: 5| Step: 9
Training loss: 1.4122533447825671
Validation loss: 2.419848381693741

Epoch: 5| Step: 10
Training loss: 1.2434355026654742
Validation loss: 2.4956662961716614

Epoch: 5| Step: 11
Training loss: 1.0368131800106688
Validation loss: 2.4799737871999725

Epoch: 164| Step: 0
Training loss: 1.630887443620732
Validation loss: 2.483402241693809

Epoch: 5| Step: 1
Training loss: 1.495097493466186
Validation loss: 2.442729385925105

Epoch: 5| Step: 2
Training loss: 1.2641073947473835
Validation loss: 2.5058444729582656

Epoch: 5| Step: 3
Training loss: 1.1220474705641206
Validation loss: 2.5019523269211317

Epoch: 5| Step: 4
Training loss: 1.5844081777375554
Validation loss: 2.496092177954205

Epoch: 5| Step: 5
Training loss: 1.394746224211775
Validation loss: 2.44571787040655

Epoch: 5| Step: 6
Training loss: 1.2050191657730474
Validation loss: 2.417351972215719

Epoch: 5| Step: 7
Training loss: 1.586722494446822
Validation loss: 2.4799225153181785

Epoch: 5| Step: 8
Training loss: 1.2623707884584072
Validation loss: 2.437535672864141

Epoch: 5| Step: 9
Training loss: 1.1472139652766848
Validation loss: 2.481973707160245

Epoch: 5| Step: 10
Training loss: 1.2148959525811849
Validation loss: 2.4532598187115244

Epoch: 5| Step: 11
Training loss: 1.6776920264409365
Validation loss: 2.466931264664309

Epoch: 165| Step: 0
Training loss: 1.155287470857286
Validation loss: 2.454980225635558

Epoch: 5| Step: 1
Training loss: 1.2696046309170939
Validation loss: 2.46287736679893

Epoch: 5| Step: 2
Training loss: 1.2372503471936709
Validation loss: 2.4477033495112948

Epoch: 5| Step: 3
Training loss: 1.4708658764114428
Validation loss: 2.4581263597828804

Epoch: 5| Step: 4
Training loss: 1.4171532001150884
Validation loss: 2.455758897932434

Epoch: 5| Step: 5
Training loss: 1.785422407546842
Validation loss: 2.433508175998097

Epoch: 5| Step: 6
Training loss: 0.9287036530442663
Validation loss: 2.4925269211654726

Epoch: 5| Step: 7
Training loss: 1.4527145954702645
Validation loss: 2.434634305131064

Epoch: 5| Step: 8
Training loss: 1.3505929986709846
Validation loss: 2.4427328894762925

Epoch: 5| Step: 9
Training loss: 1.099638591263038
Validation loss: 2.457993503428374

Epoch: 5| Step: 10
Training loss: 1.6535159883559576
Validation loss: 2.417181841155885

Epoch: 5| Step: 11
Training loss: 0.9795064877562474
Validation loss: 2.4349091690976645

Epoch: 166| Step: 0
Training loss: 0.7494733073677314
Validation loss: 2.467025114017953

Epoch: 5| Step: 1
Training loss: 1.1170926353885915
Validation loss: 2.4930908096734705

Epoch: 5| Step: 2
Training loss: 1.3070195080673772
Validation loss: 2.4856008987914504

Epoch: 5| Step: 3
Training loss: 1.597941328883764
Validation loss: 2.43632844948676

Epoch: 5| Step: 4
Training loss: 1.1960876544420833
Validation loss: 2.4775032559119063

Epoch: 5| Step: 5
Training loss: 2.0380844167384717
Validation loss: 2.4944629187125185

Epoch: 5| Step: 6
Training loss: 0.9388400355413083
Validation loss: 2.4387110020862766

Epoch: 5| Step: 7
Training loss: 1.2828665049402765
Validation loss: 2.4652673042027122

Epoch: 5| Step: 8
Training loss: 1.2752842997560045
Validation loss: 2.447390131765477

Epoch: 5| Step: 9
Training loss: 1.4148718272413803
Validation loss: 2.4573624089046184

Epoch: 5| Step: 10
Training loss: 1.305268940453358
Validation loss: 2.4774915394669033

Epoch: 5| Step: 11
Training loss: 1.1135090912686303
Validation loss: 2.483022479602091

Epoch: 167| Step: 0
Training loss: 1.1015735923262722
Validation loss: 2.42247869699387

Epoch: 5| Step: 1
Training loss: 1.145292165869756
Validation loss: 2.4322595750759635

Epoch: 5| Step: 2
Training loss: 1.7613372051235925
Validation loss: 2.434941240727054

Epoch: 5| Step: 3
Training loss: 1.0193479526657327
Validation loss: 2.412889613346437

Epoch: 5| Step: 4
Training loss: 1.3947672924659338
Validation loss: 2.3978845971716876

Epoch: 5| Step: 5
Training loss: 1.0777858255900823
Validation loss: 2.4373918003944643

Epoch: 5| Step: 6
Training loss: 1.6705033567064318
Validation loss: 2.4947225379259326

Epoch: 5| Step: 7
Training loss: 1.1554925860666863
Validation loss: 2.4530436447648585

Epoch: 5| Step: 8
Training loss: 1.7217530804514174
Validation loss: 2.4502532493985703

Epoch: 5| Step: 9
Training loss: 1.149461562115925
Validation loss: 2.4605284941344494

Epoch: 5| Step: 10
Training loss: 1.3255254549296913
Validation loss: 2.434720582146052

Epoch: 5| Step: 11
Training loss: 0.7105756404647139
Validation loss: 2.4504739930516934

Epoch: 168| Step: 0
Training loss: 1.00613796487105
Validation loss: 2.4911588421374993

Epoch: 5| Step: 1
Training loss: 1.3748457562024106
Validation loss: 2.471878612465837

Epoch: 5| Step: 2
Training loss: 1.2971200826315867
Validation loss: 2.4244024255710377

Epoch: 5| Step: 3
Training loss: 1.81240778721349
Validation loss: 2.4732555930583606

Epoch: 5| Step: 4
Training loss: 1.7566270688182593
Validation loss: 2.4776456572131464

Epoch: 5| Step: 5
Training loss: 1.3896698403871608
Validation loss: 2.4239970355078695

Epoch: 5| Step: 6
Training loss: 0.6715859079519488
Validation loss: 2.4376730898183006

Epoch: 5| Step: 7
Training loss: 1.2263756384925164
Validation loss: 2.4228691931742556

Epoch: 5| Step: 8
Training loss: 1.1231624643300306
Validation loss: 2.4647853096766155

Epoch: 5| Step: 9
Training loss: 1.2677373330595476
Validation loss: 2.4581123848132376

Epoch: 5| Step: 10
Training loss: 1.2078675764586662
Validation loss: 2.4440605749159983

Epoch: 5| Step: 11
Training loss: 0.8704235081444124
Validation loss: 2.4467837870856903

Epoch: 169| Step: 0
Training loss: 1.018794528011459
Validation loss: 2.4425339355245748

Epoch: 5| Step: 1
Training loss: 1.2736809620664404
Validation loss: 2.4728820761939767

Epoch: 5| Step: 2
Training loss: 1.446593917667023
Validation loss: 2.486151334116336

Epoch: 5| Step: 3
Training loss: 1.575984598636408
Validation loss: 2.415079614463614

Epoch: 5| Step: 4
Training loss: 1.211600534365043
Validation loss: 2.497750764565352

Epoch: 5| Step: 5
Training loss: 1.1921105976224715
Validation loss: 2.477292912832874

Epoch: 5| Step: 6
Training loss: 1.6622671552241277
Validation loss: 2.4836098834331044

Epoch: 5| Step: 7
Training loss: 0.8601648688858996
Validation loss: 2.450973547299495

Epoch: 5| Step: 8
Training loss: 0.8346112863243276
Validation loss: 2.4857795671558063

Epoch: 5| Step: 9
Training loss: 1.4326812584194428
Validation loss: 2.444207946458235

Epoch: 5| Step: 10
Training loss: 1.3913490039459007
Validation loss: 2.4900632014066915

Epoch: 5| Step: 11
Training loss: 2.4466440883533638
Validation loss: 2.4802258269937254

Epoch: 170| Step: 0
Training loss: 1.1515132691666095
Validation loss: 2.481272161338355

Epoch: 5| Step: 1
Training loss: 1.3207785331276631
Validation loss: 2.4795342514799095

Epoch: 5| Step: 2
Training loss: 0.9628657711140926
Validation loss: 2.4819321888483077

Epoch: 5| Step: 3
Training loss: 1.2885673265464361
Validation loss: 2.5325466296505823

Epoch: 5| Step: 4
Training loss: 1.4749771568986425
Validation loss: 2.4493611652800875

Epoch: 5| Step: 5
Training loss: 1.166137791149128
Validation loss: 2.475378519632306

Epoch: 5| Step: 6
Training loss: 1.2619682986423468
Validation loss: 2.4492470568775877

Epoch: 5| Step: 7
Training loss: 1.0692348205973086
Validation loss: 2.51001874584883

Epoch: 5| Step: 8
Training loss: 1.792200925555574
Validation loss: 2.4883753680400433

Epoch: 5| Step: 9
Training loss: 1.5101075568639903
Validation loss: 2.4753931094580484

Epoch: 5| Step: 10
Training loss: 1.3465325134720443
Validation loss: 2.520654669386125

Epoch: 5| Step: 11
Training loss: 1.3696340849807396
Validation loss: 2.482861199610557

Epoch: 171| Step: 0
Training loss: 1.448330177520252
Validation loss: 2.458292267073826

Epoch: 5| Step: 1
Training loss: 0.846090391087227
Validation loss: 2.444915448779805

Epoch: 5| Step: 2
Training loss: 1.1711556833697778
Validation loss: 2.4304591422410695

Epoch: 5| Step: 3
Training loss: 0.9219358391810503
Validation loss: 2.4821856626692482

Epoch: 5| Step: 4
Training loss: 1.4917235926558199
Validation loss: 2.4752144499070305

Epoch: 5| Step: 5
Training loss: 1.1528820267742041
Validation loss: 2.485443269427897

Epoch: 5| Step: 6
Training loss: 1.1843894575137446
Validation loss: 2.4158779753707154

Epoch: 5| Step: 7
Training loss: 1.9305237104989688
Validation loss: 2.505446318956291

Epoch: 5| Step: 8
Training loss: 1.1182074525901704
Validation loss: 2.4842549261030418

Epoch: 5| Step: 9
Training loss: 1.2152552260471108
Validation loss: 2.5038367850457117

Epoch: 5| Step: 10
Training loss: 1.0393014504014313
Validation loss: 2.4733074791046232

Epoch: 5| Step: 11
Training loss: 1.517277239768842
Validation loss: 2.4734129990637186

Epoch: 172| Step: 0
Training loss: 1.3315325835564025
Validation loss: 2.4143810885012997

Epoch: 5| Step: 1
Training loss: 1.7695462055711129
Validation loss: 2.475378947034558

Epoch: 5| Step: 2
Training loss: 0.9741897444089485
Validation loss: 2.4400300768199727

Epoch: 5| Step: 3
Training loss: 1.2355630203624954
Validation loss: 2.4387372088557164

Epoch: 5| Step: 4
Training loss: 0.6335298216679519
Validation loss: 2.496079123966068

Epoch: 5| Step: 5
Training loss: 1.0672228135707402
Validation loss: 2.448845676236102

Epoch: 5| Step: 6
Training loss: 1.3485109576641818
Validation loss: 2.488070001423123

Epoch: 5| Step: 7
Training loss: 0.9929800697719899
Validation loss: 2.4550701860467927

Epoch: 5| Step: 8
Training loss: 1.5710474069096994
Validation loss: 2.412354604839667

Epoch: 5| Step: 9
Training loss: 1.3763917901557825
Validation loss: 2.4555732674868516

Epoch: 5| Step: 10
Training loss: 1.4132682297814851
Validation loss: 2.49766508181795

Epoch: 5| Step: 11
Training loss: 1.5757986617178377
Validation loss: 2.49360573334584

Epoch: 173| Step: 0
Training loss: 0.9186913426157511
Validation loss: 2.4931694256826575

Epoch: 5| Step: 1
Training loss: 1.357697251743767
Validation loss: 2.4796764239725073

Epoch: 5| Step: 2
Training loss: 1.124524439856943
Validation loss: 2.455988176884938

Epoch: 5| Step: 3
Training loss: 1.4750612084571502
Validation loss: 2.5240973091252

Epoch: 5| Step: 4
Training loss: 1.276615880366059
Validation loss: 2.4478114910392317

Epoch: 5| Step: 5
Training loss: 1.2798731314102185
Validation loss: 2.4800024240043546

Epoch: 5| Step: 6
Training loss: 1.3158687320479137
Validation loss: 2.5178185726195284

Epoch: 5| Step: 7
Training loss: 1.1961367887780485
Validation loss: 2.443872033606409

Epoch: 5| Step: 8
Training loss: 0.9078374311007881
Validation loss: 2.505861832896747

Epoch: 5| Step: 9
Training loss: 1.9457510947820276
Validation loss: 2.4535051970454362

Epoch: 5| Step: 10
Training loss: 0.9993939351285439
Validation loss: 2.5063279988018223

Epoch: 5| Step: 11
Training loss: 0.8806002758120993
Validation loss: 2.500562258912723

Epoch: 174| Step: 0
Training loss: 0.8513812300908202
Validation loss: 2.461546278641779

Epoch: 5| Step: 1
Training loss: 1.563175131852995
Validation loss: 2.5150978412707943

Epoch: 5| Step: 2
Training loss: 0.9440267662298718
Validation loss: 2.5268824656053304

Epoch: 5| Step: 3
Training loss: 1.214926075982374
Validation loss: 2.4877968021621593

Epoch: 5| Step: 4
Training loss: 1.3763532914734606
Validation loss: 2.482412204678576

Epoch: 5| Step: 5
Training loss: 0.7605429940695313
Validation loss: 2.516072855350183

Epoch: 5| Step: 6
Training loss: 1.2192680040555075
Validation loss: 2.490271295012006

Epoch: 5| Step: 7
Training loss: 1.6962895544355576
Validation loss: 2.4856151868181895

Epoch: 5| Step: 8
Training loss: 1.6465925405139907
Validation loss: 2.573781815274023

Epoch: 5| Step: 9
Training loss: 1.1563083015383406
Validation loss: 2.535615731456586

Epoch: 5| Step: 10
Training loss: 1.3471256261892952
Validation loss: 2.511797712398939

Epoch: 5| Step: 11
Training loss: 1.3408663214606007
Validation loss: 2.507802355182287

Epoch: 175| Step: 0
Training loss: 1.2750179569999405
Validation loss: 2.4567259804569246

Epoch: 5| Step: 1
Training loss: 1.7446828172427167
Validation loss: 2.466755516045821

Epoch: 5| Step: 2
Training loss: 1.0937356130471196
Validation loss: 2.521335123630206

Epoch: 5| Step: 3
Training loss: 0.9904112347550312
Validation loss: 2.5404917406369454

Epoch: 5| Step: 4
Training loss: 1.1479721683624202
Validation loss: 2.5136862939412645

Epoch: 5| Step: 5
Training loss: 1.6483670621891853
Validation loss: 2.5307700640151776

Epoch: 5| Step: 6
Training loss: 1.3910879157590033
Validation loss: 2.533274935584662

Epoch: 5| Step: 7
Training loss: 1.1919561899154152
Validation loss: 2.4677793228246294

Epoch: 5| Step: 8
Training loss: 0.7436736235952193
Validation loss: 2.479434765549848

Epoch: 5| Step: 9
Training loss: 1.2006194542394837
Validation loss: 2.4807266942268935

Epoch: 5| Step: 10
Training loss: 0.8965216070019111
Validation loss: 2.504338072994914

Epoch: 5| Step: 11
Training loss: 1.2015328709951247
Validation loss: 2.482412270708211

Epoch: 176| Step: 0
Training loss: 0.9043353671950817
Validation loss: 2.4890906605920518

Epoch: 5| Step: 1
Training loss: 1.250612776285244
Validation loss: 2.5003185585831242

Epoch: 5| Step: 2
Training loss: 1.0574508634834745
Validation loss: 2.530349932483187

Epoch: 5| Step: 3
Training loss: 1.9993760804688854
Validation loss: 2.4791341460256135

Epoch: 5| Step: 4
Training loss: 1.052016769166743
Validation loss: 2.5087710852973153

Epoch: 5| Step: 5
Training loss: 1.6933855628922245
Validation loss: 2.4960710089676894

Epoch: 5| Step: 6
Training loss: 1.6476329991747198
Validation loss: 2.4955107117916424

Epoch: 5| Step: 7
Training loss: 0.8578969208635965
Validation loss: 2.480192398336255

Epoch: 5| Step: 8
Training loss: 0.9952829688944681
Validation loss: 2.4806855394840164

Epoch: 5| Step: 9
Training loss: 0.7774243336990297
Validation loss: 2.55530044559663

Epoch: 5| Step: 10
Training loss: 1.2188159729145347
Validation loss: 2.516967229758131

Epoch: 5| Step: 11
Training loss: 0.6662325687525764
Validation loss: 2.542982024252409

Epoch: 177| Step: 0
Training loss: 1.6193751773812046
Validation loss: 2.5328878158927606

Epoch: 5| Step: 1
Training loss: 1.5088216932403902
Validation loss: 2.5290494977047335

Epoch: 5| Step: 2
Training loss: 1.2246729881398273
Validation loss: 2.479175056047964

Epoch: 5| Step: 3
Training loss: 1.0875310389156065
Validation loss: 2.4653568570045605

Epoch: 5| Step: 4
Training loss: 0.8895613358671651
Validation loss: 2.4728485482616334

Epoch: 5| Step: 5
Training loss: 1.4456028002375645
Validation loss: 2.4969020205465213

Epoch: 5| Step: 6
Training loss: 0.9970835536335374
Validation loss: 2.5252311520478754

Epoch: 5| Step: 7
Training loss: 1.0372957396224587
Validation loss: 2.5028381370602824

Epoch: 5| Step: 8
Training loss: 1.0859746583577703
Validation loss: 2.4779238123320577

Epoch: 5| Step: 9
Training loss: 1.667452515665226
Validation loss: 2.5068831004060472

Epoch: 5| Step: 10
Training loss: 1.147489610678986
Validation loss: 2.5076368791322188

Epoch: 5| Step: 11
Training loss: 0.9576397576688152
Validation loss: 2.5098733445934736

Epoch: 178| Step: 0
Training loss: 1.119701730827758
Validation loss: 2.549229623637116

Epoch: 5| Step: 1
Training loss: 1.3529604258899641
Validation loss: 2.550964613706568

Epoch: 5| Step: 2
Training loss: 1.243935464804157
Validation loss: 2.5644833015086164

Epoch: 5| Step: 3
Training loss: 1.1821719653777523
Validation loss: 2.4779101815424007

Epoch: 5| Step: 4
Training loss: 0.8509359241909492
Validation loss: 2.5097111914999286

Epoch: 5| Step: 5
Training loss: 1.8387530226069955
Validation loss: 2.498749253204677

Epoch: 5| Step: 6
Training loss: 1.0314811100785672
Validation loss: 2.5319865689586836

Epoch: 5| Step: 7
Training loss: 1.1865880375611322
Validation loss: 2.525136897023932

Epoch: 5| Step: 8
Training loss: 1.1358993041111523
Validation loss: 2.5304890418939427

Epoch: 5| Step: 9
Training loss: 0.9815617582408843
Validation loss: 2.533887928930209

Epoch: 5| Step: 10
Training loss: 1.3586199187028334
Validation loss: 2.52539822684725

Epoch: 5| Step: 11
Training loss: 1.2066655762458498
Validation loss: 2.552029203632356

Epoch: 179| Step: 0
Training loss: 1.1538829803703259
Validation loss: 2.526738608786304

Epoch: 5| Step: 1
Training loss: 0.9943132831403274
Validation loss: 2.490587799324132

Epoch: 5| Step: 2
Training loss: 1.2290948857614516
Validation loss: 2.5063958687637946

Epoch: 5| Step: 3
Training loss: 1.0624492857554406
Validation loss: 2.506991865150462

Epoch: 5| Step: 4
Training loss: 0.7336312443878085
Validation loss: 2.5054783540102914

Epoch: 5| Step: 5
Training loss: 1.6103049248950825
Validation loss: 2.4268198395547285

Epoch: 5| Step: 6
Training loss: 1.7713948724547375
Validation loss: 2.5211803234245997

Epoch: 5| Step: 7
Training loss: 1.411393571144437
Validation loss: 2.506667338161514

Epoch: 5| Step: 8
Training loss: 1.3033758640098032
Validation loss: 2.465693128472141

Epoch: 5| Step: 9
Training loss: 1.2621086156022843
Validation loss: 2.5132697039825054

Epoch: 5| Step: 10
Training loss: 0.9822405122535154
Validation loss: 2.5511456005896984

Epoch: 5| Step: 11
Training loss: 0.44673571783546234
Validation loss: 2.481401383292483

Epoch: 180| Step: 0
Training loss: 1.224998594789283
Validation loss: 2.538596974269835

Epoch: 5| Step: 1
Training loss: 1.0987383846845098
Validation loss: 2.544394238595327

Epoch: 5| Step: 2
Training loss: 1.5598452331114059
Validation loss: 2.5540443081248543

Epoch: 5| Step: 3
Training loss: 1.6591754484431207
Validation loss: 2.5244924979503587

Epoch: 5| Step: 4
Training loss: 0.7874215314008809
Validation loss: 2.5402700633745345

Epoch: 5| Step: 5
Training loss: 1.071327007112022
Validation loss: 2.5124682845143056

Epoch: 5| Step: 6
Training loss: 1.2302121818325087
Validation loss: 2.5693545619319065

Epoch: 5| Step: 7
Training loss: 1.0360701647199573
Validation loss: 2.4803691313356206

Epoch: 5| Step: 8
Training loss: 1.0688621551380708
Validation loss: 2.5091895801769533

Epoch: 5| Step: 9
Training loss: 1.0255768525086804
Validation loss: 2.523548592246925

Epoch: 5| Step: 10
Training loss: 1.11903410133306
Validation loss: 2.536477638474041

Epoch: 5| Step: 11
Training loss: 1.1973932145355424
Validation loss: 2.518319895916965

Epoch: 181| Step: 0
Training loss: 1.0068004168988873
Validation loss: 2.510535495895097

Epoch: 5| Step: 1
Training loss: 1.0455929891608104
Validation loss: 2.5037960478543977

Epoch: 5| Step: 2
Training loss: 1.3532919870991633
Validation loss: 2.5406202848796564

Epoch: 5| Step: 3
Training loss: 1.542015534526784
Validation loss: 2.514602559976679

Epoch: 5| Step: 4
Training loss: 1.2171458911761994
Validation loss: 2.502159016872956

Epoch: 5| Step: 5
Training loss: 1.5422259510507006
Validation loss: 2.565737137258576

Epoch: 5| Step: 6
Training loss: 1.5971231107322192
Validation loss: 2.555179012040673

Epoch: 5| Step: 7
Training loss: 1.109430016241448
Validation loss: 2.55412205340289

Epoch: 5| Step: 8
Training loss: 0.9495225271151043
Validation loss: 2.563457445830258

Epoch: 5| Step: 9
Training loss: 1.0171376041767324
Validation loss: 2.524230891357616

Epoch: 5| Step: 10
Training loss: 1.1389234209382106
Validation loss: 2.5276805529452147

Epoch: 5| Step: 11
Training loss: 0.8819866875338012
Validation loss: 2.6068157258234708

Epoch: 182| Step: 0
Training loss: 1.2497620356072356
Validation loss: 2.5065928867528817

Epoch: 5| Step: 1
Training loss: 1.0696904957646047
Validation loss: 2.542397578991885

Epoch: 5| Step: 2
Training loss: 1.2678210197690898
Validation loss: 2.5220476029207024

Epoch: 5| Step: 3
Training loss: 1.2817004737727529
Validation loss: 2.5316756777501497

Epoch: 5| Step: 4
Training loss: 0.860371272265101
Validation loss: 2.4751119065754046

Epoch: 5| Step: 5
Training loss: 1.0099305363175457
Validation loss: 2.481181052953185

Epoch: 5| Step: 6
Training loss: 1.7652593588533003
Validation loss: 2.5166190771841226

Epoch: 5| Step: 7
Training loss: 1.342468715423972
Validation loss: 2.545728710249495

Epoch: 5| Step: 8
Training loss: 1.1294387036899174
Validation loss: 2.52996476829258

Epoch: 5| Step: 9
Training loss: 0.9311214255854416
Validation loss: 2.5222887430110816

Epoch: 5| Step: 10
Training loss: 0.6953358164103212
Validation loss: 2.572446171345983

Epoch: 5| Step: 11
Training loss: 0.6739156914909097
Validation loss: 2.543762266830872

Epoch: 183| Step: 0
Training loss: 1.4047414105246596
Validation loss: 2.527461051675412

Epoch: 5| Step: 1
Training loss: 1.0464468123019286
Validation loss: 2.5342660486185373

Epoch: 5| Step: 2
Training loss: 1.3672062027878118
Validation loss: 2.5532505804497183

Epoch: 5| Step: 3
Training loss: 0.9449243300281059
Validation loss: 2.5315144404673093

Epoch: 5| Step: 4
Training loss: 1.8399980808330976
Validation loss: 2.578096212361225

Epoch: 5| Step: 5
Training loss: 0.8245272669172777
Validation loss: 2.5675824246026453

Epoch: 5| Step: 6
Training loss: 0.9025159068832397
Validation loss: 2.5738963618447794

Epoch: 5| Step: 7
Training loss: 1.5468680641712405
Validation loss: 2.537956990900902

Epoch: 5| Step: 8
Training loss: 1.180399294715394
Validation loss: 2.5432682808274305

Epoch: 5| Step: 9
Training loss: 0.8555628755250813
Validation loss: 2.5132374144733296

Epoch: 5| Step: 10
Training loss: 0.5774977864392286
Validation loss: 2.545874966834029

Epoch: 5| Step: 11
Training loss: 0.9172782411155259
Validation loss: 2.5152370339316517

Epoch: 184| Step: 0
Training loss: 0.9024782947455731
Validation loss: 2.5368541915164213

Epoch: 5| Step: 1
Training loss: 1.7214824111265956
Validation loss: 2.495849545690986

Epoch: 5| Step: 2
Training loss: 0.9525520916709223
Validation loss: 2.5318277311938804

Epoch: 5| Step: 3
Training loss: 1.258875522056231
Validation loss: 2.5491188010237953

Epoch: 5| Step: 4
Training loss: 1.5320347701775834
Validation loss: 2.5189335865797755

Epoch: 5| Step: 5
Training loss: 0.8178588137487619
Validation loss: 2.5793022588996903

Epoch: 5| Step: 6
Training loss: 1.1688714764953643
Validation loss: 2.579508743392827

Epoch: 5| Step: 7
Training loss: 0.9019937868728986
Validation loss: 2.5277312510846484

Epoch: 5| Step: 8
Training loss: 1.339902959911073
Validation loss: 2.523472757162066

Epoch: 5| Step: 9
Training loss: 1.1801673974089364
Validation loss: 2.518787587739652

Epoch: 5| Step: 10
Training loss: 0.6380558601158713
Validation loss: 2.487842974348953

Epoch: 5| Step: 11
Training loss: 0.6039723763527992
Validation loss: 2.545951636875145

Epoch: 185| Step: 0
Training loss: 0.8735361797567718
Validation loss: 2.522993621524031

Epoch: 5| Step: 1
Training loss: 1.0003715063470469
Validation loss: 2.5605359711306965

Epoch: 5| Step: 2
Training loss: 1.068070395264192
Validation loss: 2.539871986660097

Epoch: 5| Step: 3
Training loss: 1.2920924325864729
Validation loss: 2.526426444620065

Epoch: 5| Step: 4
Training loss: 1.0239565748715105
Validation loss: 2.4924033817873084

Epoch: 5| Step: 5
Training loss: 1.296200036582246
Validation loss: 2.488026596444903

Epoch: 5| Step: 6
Training loss: 0.9361402823685189
Validation loss: 2.4863338065850367

Epoch: 5| Step: 7
Training loss: 1.8695821051370038
Validation loss: 2.560164038163493

Epoch: 5| Step: 8
Training loss: 0.6210056458368595
Validation loss: 2.555269093470798

Epoch: 5| Step: 9
Training loss: 1.503872957728092
Validation loss: 2.5533421986274933

Epoch: 5| Step: 10
Training loss: 1.2751347283630856
Validation loss: 2.5360748672181925

Epoch: 5| Step: 11
Training loss: 0.8133135903677348
Validation loss: 2.4779123103559613

Epoch: 186| Step: 0
Training loss: 1.2114668642740287
Validation loss: 2.514346143212581

Epoch: 5| Step: 1
Training loss: 1.2433979207019499
Validation loss: 2.563407586032577

Epoch: 5| Step: 2
Training loss: 1.5958830079530397
Validation loss: 2.5442816084311795

Epoch: 5| Step: 3
Training loss: 0.8736962755683385
Validation loss: 2.5507253394393716

Epoch: 5| Step: 4
Training loss: 0.9206319283757548
Validation loss: 2.5195268931585293

Epoch: 5| Step: 5
Training loss: 0.8095063298138737
Validation loss: 2.5285944077317

Epoch: 5| Step: 6
Training loss: 1.351269023101462
Validation loss: 2.5265453164250187

Epoch: 5| Step: 7
Training loss: 1.1334861593894858
Validation loss: 2.484098043139099

Epoch: 5| Step: 8
Training loss: 0.9663204059389678
Validation loss: 2.4704443231871345

Epoch: 5| Step: 9
Training loss: 1.3823664748707405
Validation loss: 2.5270895655702716

Epoch: 5| Step: 10
Training loss: 0.8296906408333103
Validation loss: 2.5559278465480784

Epoch: 5| Step: 11
Training loss: 0.4552034524733042
Validation loss: 2.491622155141721

Epoch: 187| Step: 0
Training loss: 0.9194662338516455
Validation loss: 2.5027132490177495

Epoch: 5| Step: 1
Training loss: 1.3237966579323028
Validation loss: 2.4985065787831013

Epoch: 5| Step: 2
Training loss: 0.7820428258627908
Validation loss: 2.5059831925147176

Epoch: 5| Step: 3
Training loss: 1.0042829586030781
Validation loss: 2.566434646209358

Epoch: 5| Step: 4
Training loss: 0.7776998346496069
Validation loss: 2.5026634115350967

Epoch: 5| Step: 5
Training loss: 1.0880530628174385
Validation loss: 2.5766741089777123

Epoch: 5| Step: 6
Training loss: 0.997952182405892
Validation loss: 2.4875284450508466

Epoch: 5| Step: 7
Training loss: 1.1943569976871213
Validation loss: 2.5683836381005496

Epoch: 5| Step: 8
Training loss: 1.855629811574596
Validation loss: 2.5216958183596185

Epoch: 5| Step: 9
Training loss: 1.2463123285285713
Validation loss: 2.5327573103072036

Epoch: 5| Step: 10
Training loss: 1.0414166849905628
Validation loss: 2.53461982761189

Epoch: 5| Step: 11
Training loss: 0.9489490141482533
Validation loss: 2.598731301787661

Epoch: 188| Step: 0
Training loss: 1.0943007581136317
Validation loss: 2.522569178258665

Epoch: 5| Step: 1
Training loss: 1.192827521397722
Validation loss: 2.51767076904363

Epoch: 5| Step: 2
Training loss: 0.7350524861545865
Validation loss: 2.520115897387168

Epoch: 5| Step: 3
Training loss: 1.527611126143059
Validation loss: 2.516679088822922

Epoch: 5| Step: 4
Training loss: 1.0031855627298736
Validation loss: 2.5566455713762886

Epoch: 5| Step: 5
Training loss: 0.8455956370915124
Validation loss: 2.560739872203784

Epoch: 5| Step: 6
Training loss: 1.1021018905856033
Validation loss: 2.5554901926837297

Epoch: 5| Step: 7
Training loss: 1.5719134013223228
Validation loss: 2.531951936481817

Epoch: 5| Step: 8
Training loss: 0.9366038807995665
Validation loss: 2.4850647786477307

Epoch: 5| Step: 9
Training loss: 1.4133584393139773
Validation loss: 2.5212067151518807

Epoch: 5| Step: 10
Training loss: 0.7868836034133255
Validation loss: 2.5825811580585487

Epoch: 5| Step: 11
Training loss: 1.1788487768604776
Validation loss: 2.559262001576861

Epoch: 189| Step: 0
Training loss: 1.1312077171896067
Validation loss: 2.5798931050673475

Epoch: 5| Step: 1
Training loss: 1.184429113113093
Validation loss: 2.5632188261740785

Epoch: 5| Step: 2
Training loss: 1.3295538901274102
Validation loss: 2.5973403547374527

Epoch: 5| Step: 3
Training loss: 0.942192382546801
Validation loss: 2.5570412504779747

Epoch: 5| Step: 4
Training loss: 1.2796172461595718
Validation loss: 2.5397430838038786

Epoch: 5| Step: 5
Training loss: 1.1031766927997069
Validation loss: 2.5282319702886893

Epoch: 5| Step: 6
Training loss: 1.2690134723871043
Validation loss: 2.528607747622356

Epoch: 5| Step: 7
Training loss: 1.0379082715218064
Validation loss: 2.5832421584088303

Epoch: 5| Step: 8
Training loss: 0.8560839666067602
Validation loss: 2.5700392457053427

Epoch: 5| Step: 9
Training loss: 1.3574010614130476
Validation loss: 2.56504922927402

Epoch: 5| Step: 10
Training loss: 1.0571890093696503
Validation loss: 2.5165856029915807

Epoch: 5| Step: 11
Training loss: 0.6444499802648532
Validation loss: 2.594513451387778

Epoch: 190| Step: 0
Training loss: 0.9056949889081587
Validation loss: 2.5259210315227114

Epoch: 5| Step: 1
Training loss: 1.033270965252715
Validation loss: 2.5304847667313215

Epoch: 5| Step: 2
Training loss: 0.8343034263515792
Validation loss: 2.5472998177021062

Epoch: 5| Step: 3
Training loss: 0.9968875190642353
Validation loss: 2.5344052096195835

Epoch: 5| Step: 4
Training loss: 1.1006447506399175
Validation loss: 2.576434854923975

Epoch: 5| Step: 5
Training loss: 0.8553564964744794
Validation loss: 2.6025093310711354

Epoch: 5| Step: 6
Training loss: 1.334053853181869
Validation loss: 2.5724863987332336

Epoch: 5| Step: 7
Training loss: 1.1751016065616255
Validation loss: 2.5708203823674296

Epoch: 5| Step: 8
Training loss: 1.440901422357132
Validation loss: 2.5629453078296374

Epoch: 5| Step: 9
Training loss: 1.3797234985217317
Validation loss: 2.5317278693489946

Epoch: 5| Step: 10
Training loss: 0.9885966585471336
Validation loss: 2.549769950288202

Epoch: 5| Step: 11
Training loss: 1.568871287486395
Validation loss: 2.5363114325552143

Epoch: 191| Step: 0
Training loss: 1.4976554667630484
Validation loss: 2.5310862609901945

Epoch: 5| Step: 1
Training loss: 1.0028076097577792
Validation loss: 2.498582815779681

Epoch: 5| Step: 2
Training loss: 1.0041875185456919
Validation loss: 2.6123252758510143

Epoch: 5| Step: 3
Training loss: 0.9895379742048008
Validation loss: 2.541544498311215

Epoch: 5| Step: 4
Training loss: 0.6874392005739144
Validation loss: 2.5939856866436997

Epoch: 5| Step: 5
Training loss: 1.2180515146182422
Validation loss: 2.494117133284594

Epoch: 5| Step: 6
Training loss: 1.205290888423688
Validation loss: 2.5409769519049363

Epoch: 5| Step: 7
Training loss: 1.0682189960761235
Validation loss: 2.59672244695372

Epoch: 5| Step: 8
Training loss: 1.0048535104525793
Validation loss: 2.5336821845021524

Epoch: 5| Step: 9
Training loss: 1.2241109658162
Validation loss: 2.500851494103395

Epoch: 5| Step: 10
Training loss: 0.9224749084099608
Validation loss: 2.5005931309585097

Epoch: 5| Step: 11
Training loss: 0.7877811187461966
Validation loss: 2.582794742173175

Epoch: 192| Step: 0
Training loss: 0.9755102668566052
Validation loss: 2.5385932880068642

Epoch: 5| Step: 1
Training loss: 1.0290502726931559
Validation loss: 2.5520867068729034

Epoch: 5| Step: 2
Training loss: 1.3322061999925936
Validation loss: 2.607417832655994

Epoch: 5| Step: 3
Training loss: 1.060824868876891
Validation loss: 2.595025993454636

Epoch: 5| Step: 4
Training loss: 1.5745146593978385
Validation loss: 2.5639308369500853

Epoch: 5| Step: 5
Training loss: 1.3695303760793436
Validation loss: 2.5514024461988116

Epoch: 5| Step: 6
Training loss: 1.0090894667258175
Validation loss: 2.5571324298225657

Epoch: 5| Step: 7
Training loss: 1.0055093396937214
Validation loss: 2.6292679015033777

Epoch: 5| Step: 8
Training loss: 1.3650767572361497
Validation loss: 2.632701486573238

Epoch: 5| Step: 9
Training loss: 1.1556040016028448
Validation loss: 2.668028004678527

Epoch: 5| Step: 10
Training loss: 0.8863944918590475
Validation loss: 2.6479093349444325

Epoch: 5| Step: 11
Training loss: 1.9162939027060704
Validation loss: 2.5883222918101962

Epoch: 193| Step: 0
Training loss: 0.9836580602393684
Validation loss: 2.5296279278173825

Epoch: 5| Step: 1
Training loss: 1.1945481692725761
Validation loss: 2.576845976944965

Epoch: 5| Step: 2
Training loss: 1.239735420364403
Validation loss: 2.5740577944583296

Epoch: 5| Step: 3
Training loss: 1.4273444816199121
Validation loss: 2.600367220902738

Epoch: 5| Step: 4
Training loss: 0.6286925195542316
Validation loss: 2.579732174316121

Epoch: 5| Step: 5
Training loss: 1.1085052304348813
Validation loss: 2.6012648220272396

Epoch: 5| Step: 6
Training loss: 1.2945076350358609
Validation loss: 2.5757573941280856

Epoch: 5| Step: 7
Training loss: 0.8255013344243873
Validation loss: 2.534903668016018

Epoch: 5| Step: 8
Training loss: 0.7972942820010133
Validation loss: 2.6080373849541756

Epoch: 5| Step: 9
Training loss: 1.6868715882240328
Validation loss: 2.562122053481496

Epoch: 5| Step: 10
Training loss: 0.7734309109493837
Validation loss: 2.5908527968951542

Epoch: 5| Step: 11
Training loss: 0.9922237239442772
Validation loss: 2.552025106635158

Epoch: 194| Step: 0
Training loss: 0.8654499000800941
Validation loss: 2.590097502201194

Epoch: 5| Step: 1
Training loss: 0.857394728524118
Validation loss: 2.6119537364955314

Epoch: 5| Step: 2
Training loss: 1.1112070134948797
Validation loss: 2.5845530127674214

Epoch: 5| Step: 3
Training loss: 0.9487833036827255
Validation loss: 2.5211450223828566

Epoch: 5| Step: 4
Training loss: 1.0626778173312341
Validation loss: 2.498902238791602

Epoch: 5| Step: 5
Training loss: 1.4106948965026693
Validation loss: 2.5326278335238883

Epoch: 5| Step: 6
Training loss: 0.6750647213601485
Validation loss: 2.513677079818542

Epoch: 5| Step: 7
Training loss: 1.4271859552096497
Validation loss: 2.5685848509394975

Epoch: 5| Step: 8
Training loss: 1.2041803660597967
Validation loss: 2.592152179970227

Epoch: 5| Step: 9
Training loss: 0.8208269595045556
Validation loss: 2.614533881116184

Epoch: 5| Step: 10
Training loss: 1.2356370678911963
Validation loss: 2.5543194076913993

Epoch: 5| Step: 11
Training loss: 1.0227547617791883
Validation loss: 2.519438343158705

Epoch: 195| Step: 0
Training loss: 1.1289321738041802
Validation loss: 2.5497562672188656

Epoch: 5| Step: 1
Training loss: 0.7118984895737576
Validation loss: 2.5692520814205264

Epoch: 5| Step: 2
Training loss: 1.1321377026912052
Validation loss: 2.571147798433575

Epoch: 5| Step: 3
Training loss: 0.869072523556502
Validation loss: 2.5252718404599555

Epoch: 5| Step: 4
Training loss: 0.757280536624042
Validation loss: 2.578160102682331

Epoch: 5| Step: 5
Training loss: 1.1730518789372022
Validation loss: 2.561714618009039

Epoch: 5| Step: 6
Training loss: 1.1786789277414962
Validation loss: 2.5756263454155732

Epoch: 5| Step: 7
Training loss: 0.6068925176148866
Validation loss: 2.590540999679263

Epoch: 5| Step: 8
Training loss: 1.5685623816651892
Validation loss: 2.5590745566354234

Epoch: 5| Step: 9
Training loss: 1.1212548329601086
Validation loss: 2.5992107931278436

Epoch: 5| Step: 10
Training loss: 1.3812566938281223
Validation loss: 2.582944172854626

Epoch: 5| Step: 11
Training loss: 1.1246354254103375
Validation loss: 2.555188688836912

Epoch: 196| Step: 0
Training loss: 0.664095462654156
Validation loss: 2.6055780184822908

Epoch: 5| Step: 1
Training loss: 1.4563188626621175
Validation loss: 2.5716018766580193

Epoch: 5| Step: 2
Training loss: 1.1325459133718976
Validation loss: 2.6249004943092555

Epoch: 5| Step: 3
Training loss: 1.2478584541325142
Validation loss: 2.56546307036122

Epoch: 5| Step: 4
Training loss: 0.8783735229036792
Validation loss: 2.6066869550097933

Epoch: 5| Step: 5
Training loss: 1.0793322010313162
Validation loss: 2.6030864357047543

Epoch: 5| Step: 6
Training loss: 1.3399612775588166
Validation loss: 2.5831833278009495

Epoch: 5| Step: 7
Training loss: 1.1613662010338288
Validation loss: 2.5331376458702675

Epoch: 5| Step: 8
Training loss: 0.8470500061401741
Validation loss: 2.5889824076918377

Epoch: 5| Step: 9
Training loss: 0.855710592008325
Validation loss: 2.587533183814157

Epoch: 5| Step: 10
Training loss: 1.2500283714889366
Validation loss: 2.6310489872243514

Epoch: 5| Step: 11
Training loss: 0.9068428599619007
Validation loss: 2.566144421835598

Epoch: 197| Step: 0
Training loss: 1.065696564002528
Validation loss: 2.626507439793613

Epoch: 5| Step: 1
Training loss: 1.2334473419763272
Validation loss: 2.576748613491335

Epoch: 5| Step: 2
Training loss: 0.6591036830459456
Validation loss: 2.5647511131157037

Epoch: 5| Step: 3
Training loss: 0.789557349013152
Validation loss: 2.5569894492942793

Epoch: 5| Step: 4
Training loss: 1.2718121037408316
Validation loss: 2.5358003093083057

Epoch: 5| Step: 5
Training loss: 1.0718859502383162
Validation loss: 2.5745396353779206

Epoch: 5| Step: 6
Training loss: 1.5180997013576971
Validation loss: 2.5649116263121363

Epoch: 5| Step: 7
Training loss: 0.7387813912578665
Validation loss: 2.5326340976696846

Epoch: 5| Step: 8
Training loss: 1.4052522722655818
Validation loss: 2.6487106624980825

Epoch: 5| Step: 9
Training loss: 0.9707561762414584
Validation loss: 2.5812724542757235

Epoch: 5| Step: 10
Training loss: 0.9940646579099016
Validation loss: 2.6130974196023438

Epoch: 5| Step: 11
Training loss: 1.1845616578543072
Validation loss: 2.51444509332194

Epoch: 198| Step: 0
Training loss: 0.8965388927629254
Validation loss: 2.5990845045043685

Epoch: 5| Step: 1
Training loss: 1.4544305986335184
Validation loss: 2.5796944051088295

Epoch: 5| Step: 2
Training loss: 0.7448192715808768
Validation loss: 2.5966786469104406

Epoch: 5| Step: 3
Training loss: 1.2245868881570299
Validation loss: 2.614465326455233

Epoch: 5| Step: 4
Training loss: 0.840181114392148
Validation loss: 2.5429846181535565

Epoch: 5| Step: 5
Training loss: 1.5627256611948823
Validation loss: 2.553149593550766

Epoch: 5| Step: 6
Training loss: 1.1051030716788903
Validation loss: 2.5702798603617483

Epoch: 5| Step: 7
Training loss: 0.7963366840673152
Validation loss: 2.5409499288672612

Epoch: 5| Step: 8
Training loss: 0.7843022802922628
Validation loss: 2.562251893104511

Epoch: 5| Step: 9
Training loss: 0.9635423539992621
Validation loss: 2.6288843593281164

Epoch: 5| Step: 10
Training loss: 0.8178683972670101
Validation loss: 2.5412567868683906

Epoch: 5| Step: 11
Training loss: 0.3718518594546322
Validation loss: 2.595252188039757

Epoch: 199| Step: 0
Training loss: 1.242388343169039
Validation loss: 2.5943230221965896

Epoch: 5| Step: 1
Training loss: 1.1137659991792417
Validation loss: 2.609686187645143

Epoch: 5| Step: 2
Training loss: 0.9567708809564808
Validation loss: 2.6184831515169495

Epoch: 5| Step: 3
Training loss: 0.8302817420301868
Validation loss: 2.5385998622300794

Epoch: 5| Step: 4
Training loss: 1.1377835873914537
Validation loss: 2.592160074657263

Epoch: 5| Step: 5
Training loss: 0.804887839257424
Validation loss: 2.5792499630983405

Epoch: 5| Step: 6
Training loss: 1.1781640225937202
Validation loss: 2.5670165270668495

Epoch: 5| Step: 7
Training loss: 0.8267565883354354
Validation loss: 2.595048556378857

Epoch: 5| Step: 8
Training loss: 0.9500552914239757
Validation loss: 2.6317531933631484

Epoch: 5| Step: 9
Training loss: 0.9872073041542122
Validation loss: 2.589777282506324

Epoch: 5| Step: 10
Training loss: 1.400491878408344
Validation loss: 2.5772618900838506

Epoch: 5| Step: 11
Training loss: 1.2196123544628377
Validation loss: 2.5885022132880775

Epoch: 200| Step: 0
Training loss: 0.9133508634509196
Validation loss: 2.550799523093885

Epoch: 5| Step: 1
Training loss: 1.0363937753990287
Validation loss: 2.6092254325503497

Epoch: 5| Step: 2
Training loss: 1.3220346719607137
Validation loss: 2.5532822316569783

Epoch: 5| Step: 3
Training loss: 1.2806109718906047
Validation loss: 2.5570498596253928

Epoch: 5| Step: 4
Training loss: 1.075151794273569
Validation loss: 2.582756285027774

Epoch: 5| Step: 5
Training loss: 1.080327534635809
Validation loss: 2.5734128370649256

Epoch: 5| Step: 6
Training loss: 0.8859767413993773
Validation loss: 2.5647867493691674

Epoch: 5| Step: 7
Training loss: 1.1869481962994626
Validation loss: 2.598469240320089

Epoch: 5| Step: 8
Training loss: 1.028345931876078
Validation loss: 2.5815195104558826

Epoch: 5| Step: 9
Training loss: 0.696726465004987
Validation loss: 2.6142764208984812

Epoch: 5| Step: 10
Training loss: 1.124371512016921
Validation loss: 2.588724376797867

Epoch: 5| Step: 11
Training loss: 0.5561168682784015
Validation loss: 2.6120291553301875

Epoch: 201| Step: 0
Training loss: 1.4842311588663772
Validation loss: 2.6048841034959747

Epoch: 5| Step: 1
Training loss: 0.9143388444553863
Validation loss: 2.573359730573599

Epoch: 5| Step: 2
Training loss: 0.9005982000425727
Validation loss: 2.6000962578854807

Epoch: 5| Step: 3
Training loss: 0.6631559129964606
Validation loss: 2.605605804788682

Epoch: 5| Step: 4
Training loss: 1.1410010776029909
Validation loss: 2.6122563342791802

Epoch: 5| Step: 5
Training loss: 0.7478862221417982
Validation loss: 2.5718343301232673

Epoch: 5| Step: 6
Training loss: 0.6879790544398804
Validation loss: 2.6391209903225787

Epoch: 5| Step: 7
Training loss: 1.0093523430422031
Validation loss: 2.610935315736762

Epoch: 5| Step: 8
Training loss: 1.3085300714741983
Validation loss: 2.575582838453158

Epoch: 5| Step: 9
Training loss: 0.9295755206716932
Validation loss: 2.5893714861608492

Epoch: 5| Step: 10
Training loss: 1.103377720140713
Validation loss: 2.5839620691606804

Epoch: 5| Step: 11
Training loss: 0.6857250884033956
Validation loss: 2.565286842205797

Epoch: 202| Step: 0
Training loss: 1.0580785982938798
Validation loss: 2.578628101774606

Epoch: 5| Step: 1
Training loss: 0.5452899031889561
Validation loss: 2.584936720471998

Epoch: 5| Step: 2
Training loss: 0.8821563645482069
Validation loss: 2.5828882931301966

Epoch: 5| Step: 3
Training loss: 1.0572201872217084
Validation loss: 2.5712795815182568

Epoch: 5| Step: 4
Training loss: 1.0642749322251817
Validation loss: 2.6351557377546055

Epoch: 5| Step: 5
Training loss: 0.7434761104042219
Validation loss: 2.638240425984624

Epoch: 5| Step: 6
Training loss: 1.1446675815041703
Validation loss: 2.6036249601887405

Epoch: 5| Step: 7
Training loss: 1.4969607398338822
Validation loss: 2.6135003378681603

Epoch: 5| Step: 8
Training loss: 0.7278959282328427
Validation loss: 2.5789772821285926

Epoch: 5| Step: 9
Training loss: 1.3301203380725641
Validation loss: 2.614525582839659

Epoch: 5| Step: 10
Training loss: 0.8316497644555634
Validation loss: 2.575864185914464

Epoch: 5| Step: 11
Training loss: 0.570299357432646
Validation loss: 2.6200932328547037

Epoch: 203| Step: 0
Training loss: 0.8662759956433626
Validation loss: 2.61058061124998

Epoch: 5| Step: 1
Training loss: 1.0587097892646629
Validation loss: 2.5595113317395644

Epoch: 5| Step: 2
Training loss: 0.681059450220948
Validation loss: 2.5901588566616955

Epoch: 5| Step: 3
Training loss: 0.6810789007155211
Validation loss: 2.60383012631531

Epoch: 5| Step: 4
Training loss: 0.9383298062506111
Validation loss: 2.636499466431374

Epoch: 5| Step: 5
Training loss: 0.7050700728783529
Validation loss: 2.583326237166308

Epoch: 5| Step: 6
Training loss: 0.9774573536811624
Validation loss: 2.5433211172807506

Epoch: 5| Step: 7
Training loss: 1.0791657441674098
Validation loss: 2.5420678335456235

Epoch: 5| Step: 8
Training loss: 1.5275102217311955
Validation loss: 2.6040424978535666

Epoch: 5| Step: 9
Training loss: 1.0780788356461808
Validation loss: 2.5880947238883425

Epoch: 5| Step: 10
Training loss: 1.1065705540775195
Validation loss: 2.6057018497938076

Epoch: 5| Step: 11
Training loss: 0.8739774041866698
Validation loss: 2.6430704091068375

Epoch: 204| Step: 0
Training loss: 0.7998819651550076
Validation loss: 2.649257529209361

Epoch: 5| Step: 1
Training loss: 1.0560297584025338
Validation loss: 2.637581450061942

Epoch: 5| Step: 2
Training loss: 0.6926877274471999
Validation loss: 2.622377349475218

Epoch: 5| Step: 3
Training loss: 0.9336798081576879
Validation loss: 2.672321720962954

Epoch: 5| Step: 4
Training loss: 0.9281886223458806
Validation loss: 2.6261712746045225

Epoch: 5| Step: 5
Training loss: 1.294010537860773
Validation loss: 2.613696367092692

Epoch: 5| Step: 6
Training loss: 1.2828061028157236
Validation loss: 2.604795999141742

Epoch: 5| Step: 7
Training loss: 0.6285794753791926
Validation loss: 2.630888752064121

Epoch: 5| Step: 8
Training loss: 0.9898301904196707
Validation loss: 2.639601253191771

Epoch: 5| Step: 9
Training loss: 1.2312997585253331
Validation loss: 2.558118773191149

Epoch: 5| Step: 10
Training loss: 0.5453488990855819
Validation loss: 2.6717464237619324

Epoch: 5| Step: 11
Training loss: 0.6607086985031492
Validation loss: 2.6182740760008794

Epoch: 205| Step: 0
Training loss: 1.53159663111171
Validation loss: 2.611360803179488

Epoch: 5| Step: 1
Training loss: 0.7894909139476347
Validation loss: 2.610557451939774

Epoch: 5| Step: 2
Training loss: 0.84112979098081
Validation loss: 2.6067395368762214

Epoch: 5| Step: 3
Training loss: 0.8527775067243721
Validation loss: 2.6118019071746943

Epoch: 5| Step: 4
Training loss: 1.1510211660823584
Validation loss: 2.626927716251664

Epoch: 5| Step: 5
Training loss: 0.6630186291158815
Validation loss: 2.6295735767247774

Epoch: 5| Step: 6
Training loss: 1.2499153585387481
Validation loss: 2.6194233430032945

Epoch: 5| Step: 7
Training loss: 0.744764451994673
Validation loss: 2.595301390120191

Epoch: 5| Step: 8
Training loss: 0.7884016385505096
Validation loss: 2.6147578106501017

Epoch: 5| Step: 9
Training loss: 0.6961674523857906
Validation loss: 2.6700853894422636

Epoch: 5| Step: 10
Training loss: 1.203508093147024
Validation loss: 2.596985438263563

Epoch: 5| Step: 11
Training loss: 1.164309942585156
Validation loss: 2.6663487283347904

Epoch: 206| Step: 0
Training loss: 1.0305464685615813
Validation loss: 2.6691958285082613

Epoch: 5| Step: 1
Training loss: 0.9465378944924202
Validation loss: 2.577608885304378

Epoch: 5| Step: 2
Training loss: 0.7015497576059756
Validation loss: 2.61934212581097

Epoch: 5| Step: 3
Training loss: 1.069092549534803
Validation loss: 2.6156226096223993

Epoch: 5| Step: 4
Training loss: 0.7580931625536909
Validation loss: 2.5752027461099316

Epoch: 5| Step: 5
Training loss: 1.0324801419544463
Validation loss: 2.57699727912096

Epoch: 5| Step: 6
Training loss: 0.6129515666823713
Validation loss: 2.5909764769654475

Epoch: 5| Step: 7
Training loss: 1.1715655617662473
Validation loss: 2.5426026084128615

Epoch: 5| Step: 8
Training loss: 0.8513726539025013
Validation loss: 2.599535884912279

Epoch: 5| Step: 9
Training loss: 1.1565027733887874
Validation loss: 2.6276394123678837

Epoch: 5| Step: 10
Training loss: 1.338478215515906
Validation loss: 2.537315573669091

Epoch: 5| Step: 11
Training loss: 0.9635545403247711
Validation loss: 2.6010347199465

Epoch: 207| Step: 0
Training loss: 0.7795917459832893
Validation loss: 2.588065807243227

Epoch: 5| Step: 1
Training loss: 0.5357397754599594
Validation loss: 2.6256654440877902

Epoch: 5| Step: 2
Training loss: 0.8947473123472212
Validation loss: 2.594068469370135

Epoch: 5| Step: 3
Training loss: 1.220302082559468
Validation loss: 2.58038468985751

Epoch: 5| Step: 4
Training loss: 0.9310846809243846
Validation loss: 2.6476950603487297

Epoch: 5| Step: 5
Training loss: 0.9052346559713238
Validation loss: 2.61622246937514

Epoch: 5| Step: 6
Training loss: 0.7572299251722795
Validation loss: 2.619179604221554

Epoch: 5| Step: 7
Training loss: 0.8715468113726063
Validation loss: 2.6018427945069

Epoch: 5| Step: 8
Training loss: 1.2961885864806546
Validation loss: 2.6720315987722985

Epoch: 5| Step: 9
Training loss: 0.8526593415139783
Validation loss: 2.6247773832959003

Epoch: 5| Step: 10
Training loss: 0.6552800549146001
Validation loss: 2.6401074634038997

Epoch: 5| Step: 11
Training loss: 2.9109197037583354
Validation loss: 2.600270461188973

Epoch: 208| Step: 0
Training loss: 0.720145570688651
Validation loss: 2.609162304826971

Epoch: 5| Step: 1
Training loss: 0.7408585144057279
Validation loss: 2.5487991818554443

Epoch: 5| Step: 2
Training loss: 0.8925325478033824
Validation loss: 2.5416211074643953

Epoch: 5| Step: 3
Training loss: 0.7636877190002432
Validation loss: 2.604519964412584

Epoch: 5| Step: 4
Training loss: 1.185326444190323
Validation loss: 2.573621855298932

Epoch: 5| Step: 5
Training loss: 1.3178591535097293
Validation loss: 2.6029719867591146

Epoch: 5| Step: 6
Training loss: 1.2372603193967697
Validation loss: 2.5911409170337345

Epoch: 5| Step: 7
Training loss: 0.9091041607324406
Validation loss: 2.5965608892658847

Epoch: 5| Step: 8
Training loss: 0.826848683994508
Validation loss: 2.6312132901540277

Epoch: 5| Step: 9
Training loss: 1.0513300260368033
Validation loss: 2.5883907885621436

Epoch: 5| Step: 10
Training loss: 0.8811304051837793
Validation loss: 2.5773866655843745

Epoch: 5| Step: 11
Training loss: 0.7646624294671903
Validation loss: 2.5996827827634283

Epoch: 209| Step: 0
Training loss: 1.3902389333360312
Validation loss: 2.6097169735766457

Epoch: 5| Step: 1
Training loss: 0.6905124296385852
Validation loss: 2.66429516399984

Epoch: 5| Step: 2
Training loss: 1.0004461008677965
Validation loss: 2.659105587292381

Epoch: 5| Step: 3
Training loss: 0.9948563912524515
Validation loss: 2.5753783381700495

Epoch: 5| Step: 4
Training loss: 0.866915170334269
Validation loss: 2.567579244240717

Epoch: 5| Step: 5
Training loss: 1.0516563657043536
Validation loss: 2.5885278533833067

Epoch: 5| Step: 6
Training loss: 0.9982226789878614
Validation loss: 2.6250391590134305

Epoch: 5| Step: 7
Training loss: 0.5717488582301113
Validation loss: 2.6098867169699744

Epoch: 5| Step: 8
Training loss: 0.9431532798556769
Validation loss: 2.6554201475362342

Epoch: 5| Step: 9
Training loss: 1.2303577675799027
Validation loss: 2.620795288375839

Epoch: 5| Step: 10
Training loss: 0.8173264059021601
Validation loss: 2.5998061306517424

Epoch: 5| Step: 11
Training loss: 1.0822124122970938
Validation loss: 2.6171360143655136

Epoch: 210| Step: 0
Training loss: 1.341421549581503
Validation loss: 2.6277721125777105

Epoch: 5| Step: 1
Training loss: 0.9091866039172846
Validation loss: 2.6285081347508408

Epoch: 5| Step: 2
Training loss: 0.740272782670521
Validation loss: 2.6341687226903416

Epoch: 5| Step: 3
Training loss: 0.8817175767786988
Validation loss: 2.634678218250427

Epoch: 5| Step: 4
Training loss: 1.2521120348458383
Validation loss: 2.699669314078616

Epoch: 5| Step: 5
Training loss: 0.8094619660069111
Validation loss: 2.6175294870915713

Epoch: 5| Step: 6
Training loss: 1.046123918435906
Validation loss: 2.6216027930490253

Epoch: 5| Step: 7
Training loss: 0.7784989940438358
Validation loss: 2.689458669279539

Epoch: 5| Step: 8
Training loss: 0.9262070461305836
Validation loss: 2.579461304336352

Epoch: 5| Step: 9
Training loss: 0.7102253039939643
Validation loss: 2.6480267974276943

Epoch: 5| Step: 10
Training loss: 0.9972677156850056
Validation loss: 2.6355232881883603

Epoch: 5| Step: 11
Training loss: 0.9632894993635327
Validation loss: 2.6239942334424793

Epoch: 211| Step: 0
Training loss: 0.9485271116151418
Validation loss: 2.654597583735097

Epoch: 5| Step: 1
Training loss: 1.6048209189691727
Validation loss: 2.6739686121419215

Epoch: 5| Step: 2
Training loss: 0.836399129163452
Validation loss: 2.6276772561067

Epoch: 5| Step: 3
Training loss: 0.8178374963948146
Validation loss: 2.693269746103741

Epoch: 5| Step: 4
Training loss: 0.9225389061970588
Validation loss: 2.6404767342801567

Epoch: 5| Step: 5
Training loss: 0.9391819806501907
Validation loss: 2.6733096251383794

Epoch: 5| Step: 6
Training loss: 1.0756084538837933
Validation loss: 2.6550380746981332

Epoch: 5| Step: 7
Training loss: 1.0519413553253052
Validation loss: 2.6026319934506787

Epoch: 5| Step: 8
Training loss: 1.0994107488791331
Validation loss: 2.6106160538057166

Epoch: 5| Step: 9
Training loss: 0.670026320609458
Validation loss: 2.636347942887307

Epoch: 5| Step: 10
Training loss: 0.7168067702771941
Validation loss: 2.650801813907985

Epoch: 5| Step: 11
Training loss: 0.42528830874985374
Validation loss: 2.630781916908475

Epoch: 212| Step: 0
Training loss: 0.8940904689068766
Validation loss: 2.654840211178731

Epoch: 5| Step: 1
Training loss: 0.7684898882332825
Validation loss: 2.6931622501977386

Epoch: 5| Step: 2
Training loss: 0.9441523092333677
Validation loss: 2.6271922176423543

Epoch: 5| Step: 3
Training loss: 1.0949185260091376
Validation loss: 2.614560895927378

Epoch: 5| Step: 4
Training loss: 1.15860971451382
Validation loss: 2.615181677137553

Epoch: 5| Step: 5
Training loss: 0.9018811447875339
Validation loss: 2.6069950587849284

Epoch: 5| Step: 6
Training loss: 0.731264751644179
Validation loss: 2.592365366402021

Epoch: 5| Step: 7
Training loss: 0.7836185409564483
Validation loss: 2.5814263312832093

Epoch: 5| Step: 8
Training loss: 1.165415547142723
Validation loss: 2.672881501968245

Epoch: 5| Step: 9
Training loss: 1.0860893088513244
Validation loss: 2.6733913357448236

Epoch: 5| Step: 10
Training loss: 0.7748534987017729
Validation loss: 2.5765443561039265

Epoch: 5| Step: 11
Training loss: 2.3909259681488377
Validation loss: 2.6612843956194583

Epoch: 213| Step: 0
Training loss: 1.4008072535265488
Validation loss: 2.6990357929059843

Epoch: 5| Step: 1
Training loss: 1.0472886136700217
Validation loss: 2.6146560686691154

Epoch: 5| Step: 2
Training loss: 0.6419569683017935
Validation loss: 2.582663113934982

Epoch: 5| Step: 3
Training loss: 0.7230458214750606
Validation loss: 2.61200272285486

Epoch: 5| Step: 4
Training loss: 0.8169744968892878
Validation loss: 2.6111049513935813

Epoch: 5| Step: 5
Training loss: 0.8928181932673054
Validation loss: 2.6547679431650297

Epoch: 5| Step: 6
Training loss: 1.0934022623136765
Validation loss: 2.6312433881518005

Epoch: 5| Step: 7
Training loss: 0.7633915457399556
Validation loss: 2.622033437307385

Epoch: 5| Step: 8
Training loss: 0.7691518167637567
Validation loss: 2.614512048689295

Epoch: 5| Step: 9
Training loss: 0.9411894362622439
Validation loss: 2.568554177287937

Epoch: 5| Step: 10
Training loss: 0.9628177328936378
Validation loss: 2.6002523752902253

Epoch: 5| Step: 11
Training loss: 0.2969482732997214
Validation loss: 2.5650479241158077

Epoch: 214| Step: 0
Training loss: 1.300288476481397
Validation loss: 2.6314703919268783

Epoch: 5| Step: 1
Training loss: 0.747663753396134
Validation loss: 2.575039051278294

Epoch: 5| Step: 2
Training loss: 0.7558160813818579
Validation loss: 2.61651257215109

Epoch: 5| Step: 3
Training loss: 0.9135876587817505
Validation loss: 2.6198626667258225

Epoch: 5| Step: 4
Training loss: 0.7947326734921492
Validation loss: 2.62942902882696

Epoch: 5| Step: 5
Training loss: 1.3648124774217156
Validation loss: 2.6484326125318356

Epoch: 5| Step: 6
Training loss: 0.6519332325016459
Validation loss: 2.628528565951154

Epoch: 5| Step: 7
Training loss: 0.6985547199920134
Validation loss: 2.60367829639037

Epoch: 5| Step: 8
Training loss: 0.9675617313651778
Validation loss: 2.6340593390989464

Epoch: 5| Step: 9
Training loss: 0.8023473173097463
Validation loss: 2.609017802629402

Epoch: 5| Step: 10
Training loss: 0.6524028865484305
Validation loss: 2.617321821343361

Epoch: 5| Step: 11
Training loss: 1.0771236468702061
Validation loss: 2.6427546947554106

Epoch: 215| Step: 0
Training loss: 0.9733076250805066
Validation loss: 2.621124862433185

Epoch: 5| Step: 1
Training loss: 0.770046390894694
Validation loss: 2.6654628455394827

Epoch: 5| Step: 2
Training loss: 1.1700225939566113
Validation loss: 2.628758407902207

Epoch: 5| Step: 3
Training loss: 1.0030001696342103
Validation loss: 2.6610371330396028

Epoch: 5| Step: 4
Training loss: 0.6198040269105396
Validation loss: 2.636074271853017

Epoch: 5| Step: 5
Training loss: 0.7028791845632291
Validation loss: 2.6281183279756397

Epoch: 5| Step: 6
Training loss: 1.1264977022495533
Validation loss: 2.676885402106133

Epoch: 5| Step: 7
Training loss: 0.8190410751806648
Validation loss: 2.674384684071544

Epoch: 5| Step: 8
Training loss: 1.3321363569836675
Validation loss: 2.6920252929163415

Epoch: 5| Step: 9
Training loss: 0.9987512778988947
Validation loss: 2.665861419205037

Epoch: 5| Step: 10
Training loss: 1.1251558619719573
Validation loss: 2.6405825075421183

Epoch: 5| Step: 11
Training loss: 1.1448804303167601
Validation loss: 2.6956192100091836

Epoch: 216| Step: 0
Training loss: 1.5692326263054264
Validation loss: 2.6229997802505953

Epoch: 5| Step: 1
Training loss: 0.6054336783803491
Validation loss: 2.6192422989793993

Epoch: 5| Step: 2
Training loss: 0.711559568456911
Validation loss: 2.663042908150579

Epoch: 5| Step: 3
Training loss: 1.1073314488544386
Validation loss: 2.6624453531546424

Epoch: 5| Step: 4
Training loss: 0.6447447220984541
Validation loss: 2.6445944030523627

Epoch: 5| Step: 5
Training loss: 0.6681093213032204
Validation loss: 2.5715427797489823

Epoch: 5| Step: 6
Training loss: 0.855823843778641
Validation loss: 2.5664588346082664

Epoch: 5| Step: 7
Training loss: 0.6250118016082432
Validation loss: 2.600216846868307

Epoch: 5| Step: 8
Training loss: 1.2448145120777514
Validation loss: 2.644967674708048

Epoch: 5| Step: 9
Training loss: 0.8394068091437413
Validation loss: 2.686569553664907

Epoch: 5| Step: 10
Training loss: 0.8331457205025087
Validation loss: 2.6487080314897415

Epoch: 5| Step: 11
Training loss: 0.6670513880806804
Validation loss: 2.6066995217817

Epoch: 217| Step: 0
Training loss: 1.1450124516705444
Validation loss: 2.6280240056503374

Epoch: 5| Step: 1
Training loss: 1.0525079883625665
Validation loss: 2.673638763670055

Epoch: 5| Step: 2
Training loss: 0.7383761471102851
Validation loss: 2.6274064175182454

Epoch: 5| Step: 3
Training loss: 0.9075370725305236
Validation loss: 2.6117093462541288

Epoch: 5| Step: 4
Training loss: 0.6700945261917988
Validation loss: 2.6520605671143453

Epoch: 5| Step: 5
Training loss: 1.2274080022921805
Validation loss: 2.625034899706676

Epoch: 5| Step: 6
Training loss: 0.7507351610087225
Validation loss: 2.7041325501365194

Epoch: 5| Step: 7
Training loss: 0.945593516297792
Validation loss: 2.692908262409583

Epoch: 5| Step: 8
Training loss: 0.9229889298185358
Validation loss: 2.6622937988225743

Epoch: 5| Step: 9
Training loss: 0.9314884085433105
Validation loss: 2.647406183152897

Epoch: 5| Step: 10
Training loss: 0.9829390815765314
Validation loss: 2.6912417423814383

Epoch: 5| Step: 11
Training loss: 0.9555562388678875
Validation loss: 2.6751908962074697

Epoch: 218| Step: 0
Training loss: 0.8622979825926687
Validation loss: 2.6103605933127723

Epoch: 5| Step: 1
Training loss: 0.8213594204660639
Validation loss: 2.591944429920895

Epoch: 5| Step: 2
Training loss: 0.8471651896230532
Validation loss: 2.6744589311130738

Epoch: 5| Step: 3
Training loss: 1.0283745065810546
Validation loss: 2.6046065429481704

Epoch: 5| Step: 4
Training loss: 0.9650760942312827
Validation loss: 2.6273680707849616

Epoch: 5| Step: 5
Training loss: 0.7186364208540785
Validation loss: 2.6243959935423566

Epoch: 5| Step: 6
Training loss: 0.6398173334912275
Validation loss: 2.69074047252879

Epoch: 5| Step: 7
Training loss: 0.8558823095371381
Validation loss: 2.6558580034516797

Epoch: 5| Step: 8
Training loss: 0.8391849506612478
Validation loss: 2.696270356924534

Epoch: 5| Step: 9
Training loss: 0.985852479971796
Validation loss: 2.6930833527095133

Epoch: 5| Step: 10
Training loss: 1.0477515579099184
Validation loss: 2.7013884977216747

Epoch: 5| Step: 11
Training loss: 2.48812860951932
Validation loss: 2.644921920521716

Epoch: 219| Step: 0
Training loss: 1.1719282011035788
Validation loss: 2.678580308399922

Epoch: 5| Step: 1
Training loss: 1.140866084291661
Validation loss: 2.6283731623877036

Epoch: 5| Step: 2
Training loss: 0.9036262612692204
Validation loss: 2.6540786320345675

Epoch: 5| Step: 3
Training loss: 0.7716035774948931
Validation loss: 2.7245750981115164

Epoch: 5| Step: 4
Training loss: 1.1123921910029344
Validation loss: 2.713365575942892

Epoch: 5| Step: 5
Training loss: 0.8064691024083583
Validation loss: 2.6907579834403252

Epoch: 5| Step: 6
Training loss: 0.7578294496508751
Validation loss: 2.5745873348955906

Epoch: 5| Step: 7
Training loss: 0.8816345593231542
Validation loss: 2.7033954881934243

Epoch: 5| Step: 8
Training loss: 0.987883295444556
Validation loss: 2.6317212100433567

Epoch: 5| Step: 9
Training loss: 0.5757866557681437
Validation loss: 2.6702054404993354

Epoch: 5| Step: 10
Training loss: 0.8438898606413698
Validation loss: 2.675885358581081

Epoch: 5| Step: 11
Training loss: 0.47806459307078364
Validation loss: 2.6735950086915152

Epoch: 220| Step: 0
Training loss: 0.6940851630538925
Validation loss: 2.6530029945792792

Epoch: 5| Step: 1
Training loss: 0.8019618565771081
Validation loss: 2.6444207059894915

Epoch: 5| Step: 2
Training loss: 0.7010040082259142
Validation loss: 2.7298016767927975

Epoch: 5| Step: 3
Training loss: 0.8933648913654771
Validation loss: 2.6932138722273846

Epoch: 5| Step: 4
Training loss: 0.7991519635319403
Validation loss: 2.714216098454337

Epoch: 5| Step: 5
Training loss: 1.2753724451799386
Validation loss: 2.603646483284206

Epoch: 5| Step: 6
Training loss: 0.8845937532472161
Validation loss: 2.639128029316338

Epoch: 5| Step: 7
Training loss: 0.861078619771264
Validation loss: 2.7205004044896874

Epoch: 5| Step: 8
Training loss: 1.2349596691109996
Validation loss: 2.6878342420632015

Epoch: 5| Step: 9
Training loss: 0.5937786597311887
Validation loss: 2.649497998571063

Epoch: 5| Step: 10
Training loss: 1.1204397174530039
Validation loss: 2.6690661927220627

Epoch: 5| Step: 11
Training loss: 0.7429237729166126
Validation loss: 2.6943502615879376

Epoch: 221| Step: 0
Training loss: 0.6131158593572603
Validation loss: 2.6613200438542073

Epoch: 5| Step: 1
Training loss: 0.8344977270727363
Validation loss: 2.7087063324663236

Epoch: 5| Step: 2
Training loss: 1.1241232316486707
Validation loss: 2.7097985277968637

Epoch: 5| Step: 3
Training loss: 0.7254979528218154
Validation loss: 2.656809448717366

Epoch: 5| Step: 4
Training loss: 0.6740163346753398
Validation loss: 2.642782864530193

Epoch: 5| Step: 5
Training loss: 1.0320214940316754
Validation loss: 2.631602978230645

Epoch: 5| Step: 6
Training loss: 0.6024557887670261
Validation loss: 2.6336571746796427

Epoch: 5| Step: 7
Training loss: 0.8037598086362261
Validation loss: 2.6634017016669524

Epoch: 5| Step: 8
Training loss: 1.3560603277239394
Validation loss: 2.7091659268703134

Epoch: 5| Step: 9
Training loss: 1.0306180693958407
Validation loss: 2.6959023608804413

Epoch: 5| Step: 10
Training loss: 0.753620508625708
Validation loss: 2.6708984263418363

Epoch: 5| Step: 11
Training loss: 1.200620049978256
Validation loss: 2.6820335683748717

Epoch: 222| Step: 0
Training loss: 0.7498158387738357
Validation loss: 2.627091690814534

Epoch: 5| Step: 1
Training loss: 1.2479505427140298
Validation loss: 2.6882870357103434

Epoch: 5| Step: 2
Training loss: 0.7642090608103078
Validation loss: 2.7258765989263827

Epoch: 5| Step: 3
Training loss: 1.0274813599763633
Validation loss: 2.7579217804464013

Epoch: 5| Step: 4
Training loss: 1.2720148295551732
Validation loss: 2.746708514882772

Epoch: 5| Step: 5
Training loss: 0.7738841144885815
Validation loss: 2.6551261319445887

Epoch: 5| Step: 6
Training loss: 0.687090621787749
Validation loss: 2.6425827187974935

Epoch: 5| Step: 7
Training loss: 0.7055409568763977
Validation loss: 2.6560544970503184

Epoch: 5| Step: 8
Training loss: 0.7585027245263269
Validation loss: 2.7024791658970555

Epoch: 5| Step: 9
Training loss: 1.0856304146165503
Validation loss: 2.678065202802886

Epoch: 5| Step: 10
Training loss: 0.8474372545719249
Validation loss: 2.710191741370808

Epoch: 5| Step: 11
Training loss: 0.38655603241501957
Validation loss: 2.652001206643946

Epoch: 223| Step: 0
Training loss: 0.7494586739423653
Validation loss: 2.6556327701082947

Epoch: 5| Step: 1
Training loss: 0.7034780251867316
Validation loss: 2.665649646050307

Epoch: 5| Step: 2
Training loss: 0.6189876090536643
Validation loss: 2.7446488929015835

Epoch: 5| Step: 3
Training loss: 1.0255057715295857
Validation loss: 2.6538100386787886

Epoch: 5| Step: 4
Training loss: 1.1420374968798004
Validation loss: 2.7791698906654365

Epoch: 5| Step: 5
Training loss: 1.0988668370538726
Validation loss: 2.7311627475177866

Epoch: 5| Step: 6
Training loss: 1.1783911042752357
Validation loss: 2.710729629506203

Epoch: 5| Step: 7
Training loss: 1.1111183437800776
Validation loss: 2.686639171064056

Epoch: 5| Step: 8
Training loss: 0.5574045661104832
Validation loss: 2.647719511910529

Epoch: 5| Step: 9
Training loss: 0.8146775117239171
Validation loss: 2.674511042290119

Epoch: 5| Step: 10
Training loss: 0.7186160584744649
Validation loss: 2.610747827093032

Epoch: 5| Step: 11
Training loss: 0.6343626885558372
Validation loss: 2.6733834022445464

Epoch: 224| Step: 0
Training loss: 1.0667583177848825
Validation loss: 2.6860737934487737

Epoch: 5| Step: 1
Training loss: 0.6891594712582504
Validation loss: 2.657230379531102

Epoch: 5| Step: 2
Training loss: 0.7800702151459581
Validation loss: 2.6933444960720085

Epoch: 5| Step: 3
Training loss: 0.6087496556588516
Validation loss: 2.687318921457533

Epoch: 5| Step: 4
Training loss: 1.005222274341003
Validation loss: 2.672976794623309

Epoch: 5| Step: 5
Training loss: 0.8877568826840999
Validation loss: 2.776354853776767

Epoch: 5| Step: 6
Training loss: 0.671515035678232
Validation loss: 2.6519424741685356

Epoch: 5| Step: 7
Training loss: 1.3133495850856516
Validation loss: 2.611364120429328

Epoch: 5| Step: 8
Training loss: 0.9803028346257999
Validation loss: 2.671178689836978

Epoch: 5| Step: 9
Training loss: 0.7305410012808725
Validation loss: 2.6910598487669954

Epoch: 5| Step: 10
Training loss: 0.7525176864269137
Validation loss: 2.6817484271595884

Epoch: 5| Step: 11
Training loss: 0.7033940118525563
Validation loss: 2.711259242010245

Epoch: 225| Step: 0
Training loss: 0.5408469808332882
Validation loss: 2.6311594851609215

Epoch: 5| Step: 1
Training loss: 0.7061413596998614
Validation loss: 2.639520282388745

Epoch: 5| Step: 2
Training loss: 0.8734718670848269
Validation loss: 2.611660991520326

Epoch: 5| Step: 3
Training loss: 0.8275792464835044
Validation loss: 2.6237902275613343

Epoch: 5| Step: 4
Training loss: 0.6979829747219548
Validation loss: 2.6785519810379306

Epoch: 5| Step: 5
Training loss: 1.0796611732994055
Validation loss: 2.687544042389042

Epoch: 5| Step: 6
Training loss: 0.7717324932301204
Validation loss: 2.695487959306105

Epoch: 5| Step: 7
Training loss: 1.2838765645991173
Validation loss: 2.699251666974729

Epoch: 5| Step: 8
Training loss: 0.7201480537092143
Validation loss: 2.679129999442802

Epoch: 5| Step: 9
Training loss: 0.8722885900977226
Validation loss: 2.7098893769584627

Epoch: 5| Step: 10
Training loss: 0.7835785686509388
Validation loss: 2.6882863299022404

Epoch: 5| Step: 11
Training loss: 0.710215233093865
Validation loss: 2.6838112881299576

Epoch: 226| Step: 0
Training loss: 0.7195961159824474
Validation loss: 2.647475211267889

Epoch: 5| Step: 1
Training loss: 0.6351203514173756
Validation loss: 2.6616401324107057

Epoch: 5| Step: 2
Training loss: 1.006800120888613
Validation loss: 2.650477022596146

Epoch: 5| Step: 3
Training loss: 0.9474834073810584
Validation loss: 2.637816914882851

Epoch: 5| Step: 4
Training loss: 1.1213662484252411
Validation loss: 2.651160019566614

Epoch: 5| Step: 5
Training loss: 0.7409985304546327
Validation loss: 2.695588736269188

Epoch: 5| Step: 6
Training loss: 0.719495303967747
Validation loss: 2.6023500336878755

Epoch: 5| Step: 7
Training loss: 0.6895848005304162
Validation loss: 2.645632305668375

Epoch: 5| Step: 8
Training loss: 1.0959395155332037
Validation loss: 2.717450547533113

Epoch: 5| Step: 9
Training loss: 0.47397151516479813
Validation loss: 2.6639650015641756

Epoch: 5| Step: 10
Training loss: 1.0825162275829157
Validation loss: 2.7373813342149997

Epoch: 5| Step: 11
Training loss: 0.38222941932136906
Validation loss: 2.690399682996351

Epoch: 227| Step: 0
Training loss: 0.5901857104837357
Validation loss: 2.71828456343945

Epoch: 5| Step: 1
Training loss: 1.141106386371981
Validation loss: 2.695192369373139

Epoch: 5| Step: 2
Training loss: 0.7713776333519311
Validation loss: 2.6800244771019917

Epoch: 5| Step: 3
Training loss: 0.865153978457439
Validation loss: 2.6248817644285065

Epoch: 5| Step: 4
Training loss: 0.7940663976172069
Validation loss: 2.6049638646939397

Epoch: 5| Step: 5
Training loss: 0.5470368009719826
Validation loss: 2.704959434356706

Epoch: 5| Step: 6
Training loss: 0.667943831308034
Validation loss: 2.6023461781512105

Epoch: 5| Step: 7
Training loss: 1.300530761794921
Validation loss: 2.6481879387738476

Epoch: 5| Step: 8
Training loss: 1.016562923756138
Validation loss: 2.62583431919309

Epoch: 5| Step: 9
Training loss: 0.5799960710951492
Validation loss: 2.6114950419157417

Epoch: 5| Step: 10
Training loss: 0.8718527322748995
Validation loss: 2.6848402427643476

Epoch: 5| Step: 11
Training loss: 0.758595131304158
Validation loss: 2.728139230138277

Epoch: 228| Step: 0
Training loss: 0.9585804447907773
Validation loss: 2.7073711312170654

Epoch: 5| Step: 1
Training loss: 0.48887619394318976
Validation loss: 2.6954652199347895

Epoch: 5| Step: 2
Training loss: 1.1209854977543363
Validation loss: 2.624636855816385

Epoch: 5| Step: 3
Training loss: 0.778756779110029
Validation loss: 2.66365611611582

Epoch: 5| Step: 4
Training loss: 0.4125352078642317
Validation loss: 2.643339052719272

Epoch: 5| Step: 5
Training loss: 1.1321987199345833
Validation loss: 2.641009906502502

Epoch: 5| Step: 6
Training loss: 0.9386363454151593
Validation loss: 2.7146347660706933

Epoch: 5| Step: 7
Training loss: 0.8731579464572058
Validation loss: 2.6097244401809214

Epoch: 5| Step: 8
Training loss: 0.7959346833196076
Validation loss: 2.7346573820080518

Epoch: 5| Step: 9
Training loss: 1.048567243981986
Validation loss: 2.6040723376674055

Epoch: 5| Step: 10
Training loss: 0.6860123274184892
Validation loss: 2.6583853497294077

Epoch: 5| Step: 11
Training loss: 0.7280642668317598
Validation loss: 2.6724431324348275

Epoch: 229| Step: 0
Training loss: 0.7329645613186963
Validation loss: 2.687983343736004

Epoch: 5| Step: 1
Training loss: 0.7089076985913401
Validation loss: 2.6337252316715674

Epoch: 5| Step: 2
Training loss: 0.7616390480011874
Validation loss: 2.684253713275456

Epoch: 5| Step: 3
Training loss: 1.09770653225996
Validation loss: 2.6735724398195626

Epoch: 5| Step: 4
Training loss: 0.7138761214546555
Validation loss: 2.69329308678832

Epoch: 5| Step: 5
Training loss: 0.7377709537556598
Validation loss: 2.5738792002539914

Epoch: 5| Step: 6
Training loss: 0.8133499761413394
Validation loss: 2.6580200206991904

Epoch: 5| Step: 7
Training loss: 0.6594610221398075
Validation loss: 2.6313191941647913

Epoch: 5| Step: 8
Training loss: 0.6134475433957709
Validation loss: 2.742512726222474

Epoch: 5| Step: 9
Training loss: 1.2097045035560408
Validation loss: 2.6376775660712863

Epoch: 5| Step: 10
Training loss: 0.6525384760799473
Validation loss: 2.7282618388916466

Epoch: 5| Step: 11
Training loss: 1.0558545472729415
Validation loss: 2.683777152748667

Epoch: 230| Step: 0
Training loss: 0.7925569564376386
Validation loss: 2.648269299142516

Epoch: 5| Step: 1
Training loss: 0.749748187707515
Validation loss: 2.6892397520498856

Epoch: 5| Step: 2
Training loss: 0.5032595247294949
Validation loss: 2.7241648941543835

Epoch: 5| Step: 3
Training loss: 0.8257231158650847
Validation loss: 2.6621450495037973

Epoch: 5| Step: 4
Training loss: 0.9362309449603397
Validation loss: 2.690944811090028

Epoch: 5| Step: 5
Training loss: 1.1248410430506826
Validation loss: 2.7010386358955896

Epoch: 5| Step: 6
Training loss: 0.6927441513629611
Validation loss: 2.654780766923934

Epoch: 5| Step: 7
Training loss: 0.7008867029227065
Validation loss: 2.682150758665493

Epoch: 5| Step: 8
Training loss: 0.5887509258125299
Validation loss: 2.663998615173843

Epoch: 5| Step: 9
Training loss: 1.2766579002862917
Validation loss: 2.7433766271037947

Epoch: 5| Step: 10
Training loss: 0.6113784818049034
Validation loss: 2.7277907963183328

Epoch: 5| Step: 11
Training loss: 0.490464585800941
Validation loss: 2.6669230462052322

Epoch: 231| Step: 0
Training loss: 1.0539398368986443
Validation loss: 2.61693113599209

Epoch: 5| Step: 1
Training loss: 0.6764940240402907
Validation loss: 2.68292099072927

Epoch: 5| Step: 2
Training loss: 0.7047125378408865
Validation loss: 2.663572816414235

Epoch: 5| Step: 3
Training loss: 0.9951556107549999
Validation loss: 2.672746605392554

Epoch: 5| Step: 4
Training loss: 0.7199149021218756
Validation loss: 2.7010716851612853

Epoch: 5| Step: 5
Training loss: 0.7277057226399762
Validation loss: 2.7276718047251864

Epoch: 5| Step: 6
Training loss: 0.6164784765051989
Validation loss: 2.6926110592555554

Epoch: 5| Step: 7
Training loss: 0.7512588664847113
Validation loss: 2.681272395765884

Epoch: 5| Step: 8
Training loss: 0.6512014015061999
Validation loss: 2.6817668598911415

Epoch: 5| Step: 9
Training loss: 0.9254514533324415
Validation loss: 2.7646997236594824

Epoch: 5| Step: 10
Training loss: 1.066267514548951
Validation loss: 2.6522805679728703

Epoch: 5| Step: 11
Training loss: 0.4606700703324493
Validation loss: 2.734884712304629

Epoch: 232| Step: 0
Training loss: 0.6321249629498366
Validation loss: 2.6438958753797794

Epoch: 5| Step: 1
Training loss: 0.7912192753616385
Validation loss: 2.765721317632747

Epoch: 5| Step: 2
Training loss: 1.1063728005737883
Validation loss: 2.6937947814594234

Epoch: 5| Step: 3
Training loss: 0.6147764893789921
Validation loss: 2.704536007245881

Epoch: 5| Step: 4
Training loss: 0.8022481369206141
Validation loss: 2.6618933325293943

Epoch: 5| Step: 5
Training loss: 0.5778510243522857
Validation loss: 2.7094592938918893

Epoch: 5| Step: 6
Training loss: 0.6037171900662065
Validation loss: 2.6943734878332863

Epoch: 5| Step: 7
Training loss: 0.7467266015140699
Validation loss: 2.730486977534106

Epoch: 5| Step: 8
Training loss: 1.3281836104082723
Validation loss: 2.744778708488283

Epoch: 5| Step: 9
Training loss: 0.8018795390309099
Validation loss: 2.7150923068569743

Epoch: 5| Step: 10
Training loss: 0.569155289795506
Validation loss: 2.65552134523963

Epoch: 5| Step: 11
Training loss: 0.4201423598462254
Validation loss: 2.7156979541175694

Epoch: 233| Step: 0
Training loss: 0.7453211433981091
Validation loss: 2.6631466698095037

Epoch: 5| Step: 1
Training loss: 1.0770883413723498
Validation loss: 2.6786834978697835

Epoch: 5| Step: 2
Training loss: 0.5829710829009995
Validation loss: 2.7686889723516788

Epoch: 5| Step: 3
Training loss: 0.7534531729107166
Validation loss: 2.7076509288461343

Epoch: 5| Step: 4
Training loss: 0.8700905741208323
Validation loss: 2.6658322095366773

Epoch: 5| Step: 5
Training loss: 0.8020363996241202
Validation loss: 2.7122083006819127

Epoch: 5| Step: 6
Training loss: 0.5759307874183861
Validation loss: 2.6767121192458534

Epoch: 5| Step: 7
Training loss: 0.7193338262074891
Validation loss: 2.722481888488085

Epoch: 5| Step: 8
Training loss: 1.0215504845548269
Validation loss: 2.738118470233584

Epoch: 5| Step: 9
Training loss: 0.7770132771294118
Validation loss: 2.739669114330328

Epoch: 5| Step: 10
Training loss: 0.9627804954332944
Validation loss: 2.729156105855839

Epoch: 5| Step: 11
Training loss: 0.399282065221201
Validation loss: 2.713736846821082

Epoch: 234| Step: 0
Training loss: 0.5976007473174941
Validation loss: 2.73955402551985

Epoch: 5| Step: 1
Training loss: 0.5733723533274888
Validation loss: 2.648778422720573

Epoch: 5| Step: 2
Training loss: 0.9914007597065582
Validation loss: 2.718684276064093

Epoch: 5| Step: 3
Training loss: 0.623319464578546
Validation loss: 2.7337335106553398

Epoch: 5| Step: 4
Training loss: 0.6571523275862827
Validation loss: 2.756782072673646

Epoch: 5| Step: 5
Training loss: 0.8175122740754462
Validation loss: 2.693332020060727

Epoch: 5| Step: 6
Training loss: 0.7739669066853201
Validation loss: 2.7567012049918773

Epoch: 5| Step: 7
Training loss: 0.8583261504999244
Validation loss: 2.6882469078234674

Epoch: 5| Step: 8
Training loss: 1.1114566239281582
Validation loss: 2.737237249680731

Epoch: 5| Step: 9
Training loss: 1.070427992778019
Validation loss: 2.7230953955177473

Epoch: 5| Step: 10
Training loss: 0.5088055803835642
Validation loss: 2.769955984958283

Epoch: 5| Step: 11
Training loss: 0.4647787994400186
Validation loss: 2.734423017534351

Epoch: 235| Step: 0
Training loss: 0.6254381551318846
Validation loss: 2.7209942861116385

Epoch: 5| Step: 1
Training loss: 0.6070043471964689
Validation loss: 2.648912355356721

Epoch: 5| Step: 2
Training loss: 0.7670248041680565
Validation loss: 2.7232144448088955

Epoch: 5| Step: 3
Training loss: 1.0220829976565067
Validation loss: 2.609288037158734

Epoch: 5| Step: 4
Training loss: 0.8876858449500284
Validation loss: 2.6860952957134376

Epoch: 5| Step: 5
Training loss: 0.789859482545312
Validation loss: 2.6950066286947987

Epoch: 5| Step: 6
Training loss: 0.6849880494864302
Validation loss: 2.7263396717676778

Epoch: 5| Step: 7
Training loss: 0.7665688282969381
Validation loss: 2.7310750976591347

Epoch: 5| Step: 8
Training loss: 0.5745327149580766
Validation loss: 2.6469948214177768

Epoch: 5| Step: 9
Training loss: 0.6757616029209673
Validation loss: 2.6643686985565056

Epoch: 5| Step: 10
Training loss: 1.062366645522504
Validation loss: 2.6196460089313374

Epoch: 5| Step: 11
Training loss: 0.8043793764269496
Validation loss: 2.674106376293633

Epoch: 236| Step: 0
Training loss: 0.9848133806439076
Validation loss: 2.6558157659399884

Epoch: 5| Step: 1
Training loss: 0.7568945289820305
Validation loss: 2.69473554545149

Epoch: 5| Step: 2
Training loss: 0.7385090471461232
Validation loss: 2.6615767157118517

Epoch: 5| Step: 3
Training loss: 0.7914221954998775
Validation loss: 2.7071839400069186

Epoch: 5| Step: 4
Training loss: 0.6381057423255369
Validation loss: 2.689941709080673

Epoch: 5| Step: 5
Training loss: 0.7818668219293403
Validation loss: 2.6963854584484817

Epoch: 5| Step: 6
Training loss: 0.9188024103695214
Validation loss: 2.6489026646696785

Epoch: 5| Step: 7
Training loss: 0.9386203429466886
Validation loss: 2.737098942878274

Epoch: 5| Step: 8
Training loss: 1.0111623287037665
Validation loss: 2.7121160841997165

Epoch: 5| Step: 9
Training loss: 0.6357698917944663
Validation loss: 2.604333778105774

Epoch: 5| Step: 10
Training loss: 0.8768010676695943
Validation loss: 2.7198492217697807

Epoch: 5| Step: 11
Training loss: 1.6540865893963796
Validation loss: 2.6849054150760345

Epoch: 237| Step: 0
Training loss: 0.7887588898872647
Validation loss: 2.5951560931584954

Epoch: 5| Step: 1
Training loss: 0.7121954049328275
Validation loss: 2.6792699082526488

Epoch: 5| Step: 2
Training loss: 0.5986284314939609
Validation loss: 2.6789510176403715

Epoch: 5| Step: 3
Training loss: 0.8142091673889412
Validation loss: 2.6483367780739444

Epoch: 5| Step: 4
Training loss: 1.1255950413709246
Validation loss: 2.7085449148330323

Epoch: 5| Step: 5
Training loss: 0.6131428847975706
Validation loss: 2.7015789366104976

Epoch: 5| Step: 6
Training loss: 0.9601513197471981
Validation loss: 2.698294257224084

Epoch: 5| Step: 7
Training loss: 0.5783975577307486
Validation loss: 2.649730702353301

Epoch: 5| Step: 8
Training loss: 0.6958415986520073
Validation loss: 2.6554572250027824

Epoch: 5| Step: 9
Training loss: 0.774558632285623
Validation loss: 2.683382432253459

Epoch: 5| Step: 10
Training loss: 0.9712969002022968
Validation loss: 2.748480409479162

Epoch: 5| Step: 11
Training loss: 0.877913155575107
Validation loss: 2.7103897204563587

Epoch: 238| Step: 0
Training loss: 0.661438616261013
Validation loss: 2.6695170529324526

Epoch: 5| Step: 1
Training loss: 0.7335001421631179
Validation loss: 2.7118961313946364

Epoch: 5| Step: 2
Training loss: 0.6919130095367957
Validation loss: 2.69635664023795

Epoch: 5| Step: 3
Training loss: 1.2432435063511451
Validation loss: 2.691253074565099

Epoch: 5| Step: 4
Training loss: 0.8636382042486481
Validation loss: 2.6386526047318015

Epoch: 5| Step: 5
Training loss: 0.8075253712356095
Validation loss: 2.653936010236341

Epoch: 5| Step: 6
Training loss: 0.700595565742499
Validation loss: 2.664476289803642

Epoch: 5| Step: 7
Training loss: 0.7971109900999844
Validation loss: 2.705675325907433

Epoch: 5| Step: 8
Training loss: 0.616835578346788
Validation loss: 2.6999285841550997

Epoch: 5| Step: 9
Training loss: 0.7635904644356254
Validation loss: 2.6749524227409327

Epoch: 5| Step: 10
Training loss: 0.573247048456485
Validation loss: 2.671737518640244

Epoch: 5| Step: 11
Training loss: 0.6162121949583544
Validation loss: 2.674117502474034

Epoch: 239| Step: 0
Training loss: 0.7863824483542666
Validation loss: 2.6750941450124084

Epoch: 5| Step: 1
Training loss: 0.6444403150739498
Validation loss: 2.7096110679978196

Epoch: 5| Step: 2
Training loss: 0.9646204330911622
Validation loss: 2.7323638277248183

Epoch: 5| Step: 3
Training loss: 0.7981813979330435
Validation loss: 2.711341029025955

Epoch: 5| Step: 4
Training loss: 0.6197875340641847
Validation loss: 2.6618143964503918

Epoch: 5| Step: 5
Training loss: 0.8031243261193443
Validation loss: 2.735735772635245

Epoch: 5| Step: 6
Training loss: 0.8349194254231992
Validation loss: 2.7452686276636595

Epoch: 5| Step: 7
Training loss: 0.6310357240019455
Validation loss: 2.665444851654181

Epoch: 5| Step: 8
Training loss: 0.9602175240639969
Validation loss: 2.6972448526365684

Epoch: 5| Step: 9
Training loss: 0.929774592832104
Validation loss: 2.7678283671598716

Epoch: 5| Step: 10
Training loss: 0.9829535136014461
Validation loss: 2.6727107304433386

Epoch: 5| Step: 11
Training loss: 0.5858271940035342
Validation loss: 2.678354367286524

Epoch: 240| Step: 0
Training loss: 0.864773595319847
Validation loss: 2.6979511484620717

Epoch: 5| Step: 1
Training loss: 0.6821313528946816
Validation loss: 2.7517048543497937

Epoch: 5| Step: 2
Training loss: 0.7738915468941482
Validation loss: 2.7879217826588416

Epoch: 5| Step: 3
Training loss: 0.7864046183720214
Validation loss: 2.7277897001320155

Epoch: 5| Step: 4
Training loss: 0.7990015489875951
Validation loss: 2.7503046640056863

Epoch: 5| Step: 5
Training loss: 0.6576860700513997
Validation loss: 2.77221344992826

Epoch: 5| Step: 6
Training loss: 0.7883070549271397
Validation loss: 2.6781883346505158

Epoch: 5| Step: 7
Training loss: 0.844585358388763
Validation loss: 2.6348850382483007

Epoch: 5| Step: 8
Training loss: 0.8539396581370532
Validation loss: 2.695736834161398

Epoch: 5| Step: 9
Training loss: 0.5358631171387681
Validation loss: 2.715517526716006

Epoch: 5| Step: 10
Training loss: 1.15988916475971
Validation loss: 2.698374732663816

Epoch: 5| Step: 11
Training loss: 0.38580982243041195
Validation loss: 2.6613983973692577

Epoch: 241| Step: 0
Training loss: 0.8029745072252871
Validation loss: 2.612623693649924

Epoch: 5| Step: 1
Training loss: 1.0310846253933743
Validation loss: 2.6679063960059444

Epoch: 5| Step: 2
Training loss: 0.9794340106881753
Validation loss: 2.6806939276842265

Epoch: 5| Step: 3
Training loss: 0.6388884710803485
Validation loss: 2.716319038718009

Epoch: 5| Step: 4
Training loss: 0.7459411864555177
Validation loss: 2.6883540496828116

Epoch: 5| Step: 5
Training loss: 0.5978081952591613
Validation loss: 2.7123188306951986

Epoch: 5| Step: 6
Training loss: 0.7644444141076818
Validation loss: 2.711740545230848

Epoch: 5| Step: 7
Training loss: 0.6059340873020148
Validation loss: 2.7072484386633455

Epoch: 5| Step: 8
Training loss: 0.920005648740759
Validation loss: 2.72614765381492

Epoch: 5| Step: 9
Training loss: 0.47845966245422394
Validation loss: 2.708583601367864

Epoch: 5| Step: 10
Training loss: 0.879802535075225
Validation loss: 2.6921079668520904

Epoch: 5| Step: 11
Training loss: 0.43157192045919657
Validation loss: 2.6505882809803154

Epoch: 242| Step: 0
Training loss: 0.8304986584105384
Validation loss: 2.7215088515907784

Epoch: 5| Step: 1
Training loss: 0.8903695124872508
Validation loss: 2.68756186613689

Epoch: 5| Step: 2
Training loss: 0.6131218867169431
Validation loss: 2.738131188431577

Epoch: 5| Step: 3
Training loss: 0.7797232396070422
Validation loss: 2.732609594921341

Epoch: 5| Step: 4
Training loss: 0.7960708899393174
Validation loss: 2.6589151214178424

Epoch: 5| Step: 5
Training loss: 0.8031208379615374
Validation loss: 2.688495263181163

Epoch: 5| Step: 6
Training loss: 0.5671368852210342
Validation loss: 2.7248532567774473

Epoch: 5| Step: 7
Training loss: 0.4393781979581486
Validation loss: 2.7397569968777638

Epoch: 5| Step: 8
Training loss: 0.7102061691616749
Validation loss: 2.7546421267270205

Epoch: 5| Step: 9
Training loss: 0.7200406552466169
Validation loss: 2.7515369404709165

Epoch: 5| Step: 10
Training loss: 1.0226513704397708
Validation loss: 2.6886801715888904

Epoch: 5| Step: 11
Training loss: 0.7249134587562881
Validation loss: 2.703302943522958

Epoch: 243| Step: 0
Training loss: 0.7110187358345944
Validation loss: 2.691411417461098

Epoch: 5| Step: 1
Training loss: 0.6471327097866211
Validation loss: 2.750476329905493

Epoch: 5| Step: 2
Training loss: 0.790406470574021
Validation loss: 2.730423882824809

Epoch: 5| Step: 3
Training loss: 0.8936059822409915
Validation loss: 2.687075363293662

Epoch: 5| Step: 4
Training loss: 0.6199582834975936
Validation loss: 2.7654211288856034

Epoch: 5| Step: 5
Training loss: 0.7169812872132642
Validation loss: 2.608087320933922

Epoch: 5| Step: 6
Training loss: 0.7295988073910201
Validation loss: 2.703954690600171

Epoch: 5| Step: 7
Training loss: 0.8892458895850235
Validation loss: 2.7321247105570152

Epoch: 5| Step: 8
Training loss: 0.67018131315077
Validation loss: 2.694277349897156

Epoch: 5| Step: 9
Training loss: 0.6107699493744626
Validation loss: 2.712228392554882

Epoch: 5| Step: 10
Training loss: 1.0815762551311174
Validation loss: 2.686060608710473

Epoch: 5| Step: 11
Training loss: 0.9441269620665147
Validation loss: 2.759840218916583

Epoch: 244| Step: 0
Training loss: 0.6283143854024723
Validation loss: 2.6938555847976904

Epoch: 5| Step: 1
Training loss: 0.690895754184064
Validation loss: 2.6872363626558338

Epoch: 5| Step: 2
Training loss: 0.8059233646994758
Validation loss: 2.734489645598131

Epoch: 5| Step: 3
Training loss: 1.0337915601759633
Validation loss: 2.677933551736482

Epoch: 5| Step: 4
Training loss: 0.5074359965249858
Validation loss: 2.68541279406055

Epoch: 5| Step: 5
Training loss: 1.1503282410265652
Validation loss: 2.669992657578715

Epoch: 5| Step: 6
Training loss: 0.8184214274840853
Validation loss: 2.7326829343383534

Epoch: 5| Step: 7
Training loss: 0.8151568475991257
Validation loss: 2.7356934411517444

Epoch: 5| Step: 8
Training loss: 0.8097048510772316
Validation loss: 2.7506045088885616

Epoch: 5| Step: 9
Training loss: 1.0392625659130628
Validation loss: 2.755830378462095

Epoch: 5| Step: 10
Training loss: 0.7669845887641439
Validation loss: 2.744865808565329

Epoch: 5| Step: 11
Training loss: 0.2442329308535037
Validation loss: 2.6909604933014806

Epoch: 245| Step: 0
Training loss: 0.7217412155827135
Validation loss: 2.7726343738233554

Epoch: 5| Step: 1
Training loss: 1.0646023426983986
Validation loss: 2.65942427637728

Epoch: 5| Step: 2
Training loss: 0.7403596555635522
Validation loss: 2.707124375452062

Epoch: 5| Step: 3
Training loss: 0.4901725608487946
Validation loss: 2.666090580185822

Epoch: 5| Step: 4
Training loss: 0.5625577208255903
Validation loss: 2.702537494826312

Epoch: 5| Step: 5
Training loss: 0.5559859056075686
Validation loss: 2.678312282401391

Epoch: 5| Step: 6
Training loss: 0.643984036355865
Validation loss: 2.676125066716546

Epoch: 5| Step: 7
Training loss: 0.7731999504499819
Validation loss: 2.746321428608904

Epoch: 5| Step: 8
Training loss: 1.0315383161306073
Validation loss: 2.763699358656316

Epoch: 5| Step: 9
Training loss: 0.6760725595227138
Validation loss: 2.762343358076636

Epoch: 5| Step: 10
Training loss: 0.41493961713606736
Validation loss: 2.760231243359694

Epoch: 5| Step: 11
Training loss: 0.8549649571047019
Validation loss: 2.769785555062516

Epoch: 246| Step: 0
Training loss: 0.8125847258775118
Validation loss: 2.726795077310069

Epoch: 5| Step: 1
Training loss: 0.47619043741197653
Validation loss: 2.727607963830824

Epoch: 5| Step: 2
Training loss: 0.5115927329943135
Validation loss: 2.663445458124835

Epoch: 5| Step: 3
Training loss: 0.9878132733659091
Validation loss: 2.704272961743822

Epoch: 5| Step: 4
Training loss: 0.7824259490784549
Validation loss: 2.72727802073201

Epoch: 5| Step: 5
Training loss: 0.5332924345348589
Validation loss: 2.7586261928497633

Epoch: 5| Step: 6
Training loss: 1.0723440006149647
Validation loss: 2.725070734739196

Epoch: 5| Step: 7
Training loss: 0.7360809477937987
Validation loss: 2.7332179700582686

Epoch: 5| Step: 8
Training loss: 0.7593921832114605
Validation loss: 2.624568205469523

Epoch: 5| Step: 9
Training loss: 0.5698449818310447
Validation loss: 2.6575976337801177

Epoch: 5| Step: 10
Training loss: 0.6464436221459372
Validation loss: 2.670073788834104

Epoch: 5| Step: 11
Training loss: 0.21461032845001005
Validation loss: 2.7163309721179467

Epoch: 247| Step: 0
Training loss: 0.6576106180758515
Validation loss: 2.7381502121042742

Epoch: 5| Step: 1
Training loss: 1.0128416803541338
Validation loss: 2.778718918205955

Epoch: 5| Step: 2
Training loss: 0.7748840368328219
Validation loss: 2.7442799162893863

Epoch: 5| Step: 3
Training loss: 0.8215906993137103
Validation loss: 2.750602208292791

Epoch: 5| Step: 4
Training loss: 0.5175201383533078
Validation loss: 2.6744799825982195

Epoch: 5| Step: 5
Training loss: 0.9790483497938858
Validation loss: 2.7077087904903876

Epoch: 5| Step: 6
Training loss: 0.5310317600992864
Validation loss: 2.6478776443171226

Epoch: 5| Step: 7
Training loss: 0.763336888670103
Validation loss: 2.6681080340122065

Epoch: 5| Step: 8
Training loss: 0.7188946951468387
Validation loss: 2.6645732550372028

Epoch: 5| Step: 9
Training loss: 0.6409196176177865
Validation loss: 2.7263911538631

Epoch: 5| Step: 10
Training loss: 0.5803801395764632
Validation loss: 2.743564149663687

Epoch: 5| Step: 11
Training loss: 0.7705124539427693
Validation loss: 2.7133547681314076

Epoch: 248| Step: 0
Training loss: 0.8619027156675075
Validation loss: 2.709345339943096

Epoch: 5| Step: 1
Training loss: 0.6064656080698352
Validation loss: 2.7093421499922052

Epoch: 5| Step: 2
Training loss: 0.8643523256164782
Validation loss: 2.744270967802193

Epoch: 5| Step: 3
Training loss: 0.5953191801882826
Validation loss: 2.680588480863037

Epoch: 5| Step: 4
Training loss: 0.45979119669699087
Validation loss: 2.7682633898758677

Epoch: 5| Step: 5
Training loss: 0.6071422951559463
Validation loss: 2.728381889777662

Epoch: 5| Step: 6
Training loss: 0.7206315829529706
Validation loss: 2.757992750262284

Epoch: 5| Step: 7
Training loss: 0.4290996518481035
Validation loss: 2.7472024509053616

Epoch: 5| Step: 8
Training loss: 0.9509876237258487
Validation loss: 2.7467464179683456

Epoch: 5| Step: 9
Training loss: 0.7757834105062988
Validation loss: 2.6754938310019636

Epoch: 5| Step: 10
Training loss: 0.7520121761766766
Validation loss: 2.653945970766757

Epoch: 5| Step: 11
Training loss: 0.2821357607380191
Validation loss: 2.7594161553660084

Epoch: 249| Step: 0
Training loss: 0.917582718864884
Validation loss: 2.69200487866132

Epoch: 5| Step: 1
Training loss: 0.891121876296306
Validation loss: 2.7340202755402947

Epoch: 5| Step: 2
Training loss: 0.6335754975160449
Validation loss: 2.7911324677903955

Epoch: 5| Step: 3
Training loss: 0.642398751218563
Validation loss: 2.742777939253789

Epoch: 5| Step: 4
Training loss: 0.8122945672533196
Validation loss: 2.7685987358020383

Epoch: 5| Step: 5
Training loss: 0.5077279827503832
Validation loss: 2.711617607092202

Epoch: 5| Step: 6
Training loss: 0.5014588115147317
Validation loss: 2.717864615870679

Epoch: 5| Step: 7
Training loss: 0.7018236196841161
Validation loss: 2.7896312486342945

Epoch: 5| Step: 8
Training loss: 0.673592921685453
Validation loss: 2.7591006338796915

Epoch: 5| Step: 9
Training loss: 0.865984589292036
Validation loss: 2.707493029350919

Epoch: 5| Step: 10
Training loss: 0.5370825466044691
Validation loss: 2.832768974243346

Epoch: 5| Step: 11
Training loss: 0.4725444913787053
Validation loss: 2.7192483003203085

Epoch: 250| Step: 0
Training loss: 0.6972187357718681
Validation loss: 2.7431902125393126

Epoch: 5| Step: 1
Training loss: 0.599670084014105
Validation loss: 2.7165848452488186

Epoch: 5| Step: 2
Training loss: 0.8361495987816197
Validation loss: 2.82999899020587

Epoch: 5| Step: 3
Training loss: 0.8310272535016342
Validation loss: 2.7286842201262305

Epoch: 5| Step: 4
Training loss: 0.6398006811307076
Validation loss: 2.6846403388267097

Epoch: 5| Step: 5
Training loss: 0.9194344040942559
Validation loss: 2.7987212439975493

Epoch: 5| Step: 6
Training loss: 0.6104043434209766
Validation loss: 2.7525776176411387

Epoch: 5| Step: 7
Training loss: 0.754259530737736
Validation loss: 2.7303568353670307

Epoch: 5| Step: 8
Training loss: 0.9217336190643136
Validation loss: 2.7993185497013786

Epoch: 5| Step: 9
Training loss: 0.6622474998953989
Validation loss: 2.754192162500084

Epoch: 5| Step: 10
Training loss: 0.5102652078499452
Validation loss: 2.7497820623333036

Epoch: 5| Step: 11
Training loss: 0.7865301608870351
Validation loss: 2.7713837160627204

Epoch: 251| Step: 0
Training loss: 0.677203253372239
Validation loss: 2.7247979065853065

Epoch: 5| Step: 1
Training loss: 0.6010739212593191
Validation loss: 2.7259434869034243

Epoch: 5| Step: 2
Training loss: 1.0615589799168494
Validation loss: 2.675663242383123

Epoch: 5| Step: 3
Training loss: 0.47754950014654773
Validation loss: 2.691864299506383

Epoch: 5| Step: 4
Training loss: 1.0201774098811618
Validation loss: 2.7349295843934724

Epoch: 5| Step: 5
Training loss: 0.7178835414595537
Validation loss: 2.6731347800560443

Epoch: 5| Step: 6
Training loss: 0.7328441979033291
Validation loss: 2.633672132431796

Epoch: 5| Step: 7
Training loss: 0.5306455033994837
Validation loss: 2.7471636283820065

Epoch: 5| Step: 8
Training loss: 0.6351595082029361
Validation loss: 2.7574278839747657

Epoch: 5| Step: 9
Training loss: 0.6302609750078847
Validation loss: 2.7156979431434762

Epoch: 5| Step: 10
Training loss: 0.7267231917342943
Validation loss: 2.733085353629772

Epoch: 5| Step: 11
Training loss: 0.9439681401048878
Validation loss: 2.664707899922577

Epoch: 252| Step: 0
Training loss: 0.7119193371235927
Validation loss: 2.7712235259662905

Epoch: 5| Step: 1
Training loss: 1.0822338369056523
Validation loss: 2.7470737624053503

Epoch: 5| Step: 2
Training loss: 0.7630027708100771
Validation loss: 2.662285306121785

Epoch: 5| Step: 3
Training loss: 0.5652219558753979
Validation loss: 2.6731548032778223

Epoch: 5| Step: 4
Training loss: 0.5847901109195242
Validation loss: 2.7203623605504723

Epoch: 5| Step: 5
Training loss: 0.553178992572671
Validation loss: 2.680932685256929

Epoch: 5| Step: 6
Training loss: 0.9331817994968453
Validation loss: 2.835658876798118

Epoch: 5| Step: 7
Training loss: 0.3991563520545623
Validation loss: 2.664584337139363

Epoch: 5| Step: 8
Training loss: 0.8085402687556714
Validation loss: 2.6991689689377516

Epoch: 5| Step: 9
Training loss: 0.5620881268141593
Validation loss: 2.7222841045883484

Epoch: 5| Step: 10
Training loss: 0.4372953208611941
Validation loss: 2.7015974509907386

Epoch: 5| Step: 11
Training loss: 0.6865454028591793
Validation loss: 2.7121423467944705

Epoch: 253| Step: 0
Training loss: 0.4638734837154934
Validation loss: 2.7124995148126545

Epoch: 5| Step: 1
Training loss: 0.686172634481787
Validation loss: 2.715653347720499

Epoch: 5| Step: 2
Training loss: 0.9994143618906962
Validation loss: 2.749475848212856

Epoch: 5| Step: 3
Training loss: 0.43860612412172345
Validation loss: 2.748528928755871

Epoch: 5| Step: 4
Training loss: 0.720009032762346
Validation loss: 2.700337218268706

Epoch: 5| Step: 5
Training loss: 0.6400909523858327
Validation loss: 2.757370636926852

Epoch: 5| Step: 6
Training loss: 0.4195818034140693
Validation loss: 2.7331047704450895

Epoch: 5| Step: 7
Training loss: 0.9411178400337566
Validation loss: 2.697706915214563

Epoch: 5| Step: 8
Training loss: 0.9404284832749624
Validation loss: 2.768228785077293

Epoch: 5| Step: 9
Training loss: 0.47400054813506226
Validation loss: 2.7266066947495915

Epoch: 5| Step: 10
Training loss: 0.7303114941075474
Validation loss: 2.7003548766409966

Epoch: 5| Step: 11
Training loss: 0.8293993160244982
Validation loss: 2.7178855778738127

Epoch: 254| Step: 0
Training loss: 0.6214784594337611
Validation loss: 2.72195795226969

Epoch: 5| Step: 1
Training loss: 0.6073937363561933
Validation loss: 2.7101662277957317

Epoch: 5| Step: 2
Training loss: 1.0196067226727041
Validation loss: 2.6818776499405392

Epoch: 5| Step: 3
Training loss: 0.6072543486639288
Validation loss: 2.709224716852587

Epoch: 5| Step: 4
Training loss: 0.4810174584551279
Validation loss: 2.7245786202539644

Epoch: 5| Step: 5
Training loss: 1.1281562082301155
Validation loss: 2.713047770962505

Epoch: 5| Step: 6
Training loss: 0.6792036504758588
Validation loss: 2.7037557994153074

Epoch: 5| Step: 7
Training loss: 0.6562634875410168
Validation loss: 2.7165512825932376

Epoch: 5| Step: 8
Training loss: 0.754841318507573
Validation loss: 2.6991336365606657

Epoch: 5| Step: 9
Training loss: 0.6181404145404518
Validation loss: 2.708743237996166

Epoch: 5| Step: 10
Training loss: 0.5557892562808605
Validation loss: 2.7335921411181574

Epoch: 5| Step: 11
Training loss: 0.5992045822358603
Validation loss: 2.686106982458633

Epoch: 255| Step: 0
Training loss: 0.9126706081437166
Validation loss: 2.7670220045375813

Epoch: 5| Step: 1
Training loss: 0.7513909554546124
Validation loss: 2.744691663557431

Epoch: 5| Step: 2
Training loss: 0.5420894776049109
Validation loss: 2.723715489918612

Epoch: 5| Step: 3
Training loss: 0.5811393355572521
Validation loss: 2.7624610000550147

Epoch: 5| Step: 4
Training loss: 0.8970365132966657
Validation loss: 2.73673674177956

Epoch: 5| Step: 5
Training loss: 0.8975654350271556
Validation loss: 2.7145156332743814

Epoch: 5| Step: 6
Training loss: 0.5791688207773816
Validation loss: 2.6542743179451915

Epoch: 5| Step: 7
Training loss: 0.7256447112357586
Validation loss: 2.725059295294982

Epoch: 5| Step: 8
Training loss: 0.6164636834176608
Validation loss: 2.642164673077804

Epoch: 5| Step: 9
Training loss: 0.5323256374151977
Validation loss: 2.7417619923906487

Epoch: 5| Step: 10
Training loss: 0.5708980167477414
Validation loss: 2.7976336560210937

Epoch: 5| Step: 11
Training loss: 0.6530685509923342
Validation loss: 2.7492754769297183

Epoch: 256| Step: 0
Training loss: 0.9401161883458206
Validation loss: 2.6987726714274607

Epoch: 5| Step: 1
Training loss: 0.9377180163879302
Validation loss: 2.69500634486384

Epoch: 5| Step: 2
Training loss: 0.7317735981917273
Validation loss: 2.749175930818935

Epoch: 5| Step: 3
Training loss: 0.6744833151985538
Validation loss: 2.772491114515875

Epoch: 5| Step: 4
Training loss: 0.43158226136438255
Validation loss: 2.713309134674967

Epoch: 5| Step: 5
Training loss: 0.8397235163299664
Validation loss: 2.8161649208181587

Epoch: 5| Step: 6
Training loss: 0.531923512264695
Validation loss: 2.782413546454983

Epoch: 5| Step: 7
Training loss: 0.5079449407558934
Validation loss: 2.734240250673236

Epoch: 5| Step: 8
Training loss: 0.48499054405491787
Validation loss: 2.6965494275414463

Epoch: 5| Step: 9
Training loss: 0.5731962273286555
Validation loss: 2.761169353767786

Epoch: 5| Step: 10
Training loss: 0.7655005061859909
Validation loss: 2.8078319558085347

Epoch: 5| Step: 11
Training loss: 0.5528286155995437
Validation loss: 2.785017783212644

Epoch: 257| Step: 0
Training loss: 0.8445835587837308
Validation loss: 2.773576075714075

Epoch: 5| Step: 1
Training loss: 0.8398069151851428
Validation loss: 2.729613731011986

Epoch: 5| Step: 2
Training loss: 0.6181122334765511
Validation loss: 2.7379860784656453

Epoch: 5| Step: 3
Training loss: 0.7506127238798348
Validation loss: 2.720602201154045

Epoch: 5| Step: 4
Training loss: 0.6369135505980699
Validation loss: 2.744950242260358

Epoch: 5| Step: 5
Training loss: 0.7746879410829015
Validation loss: 2.7165721669660097

Epoch: 5| Step: 6
Training loss: 0.9103785231141179
Validation loss: 2.7098965730555515

Epoch: 5| Step: 7
Training loss: 0.8845339170630346
Validation loss: 2.7193325996994906

Epoch: 5| Step: 8
Training loss: 0.5494668576517601
Validation loss: 2.6716824921381006

Epoch: 5| Step: 9
Training loss: 0.8899502122004453
Validation loss: 2.7565649955486524

Epoch: 5| Step: 10
Training loss: 0.6606178701227132
Validation loss: 2.774951775736099

Epoch: 5| Step: 11
Training loss: 0.6371937483649085
Validation loss: 2.719523239525761

Epoch: 258| Step: 0
Training loss: 0.5654282907524713
Validation loss: 2.782779469509105

Epoch: 5| Step: 1
Training loss: 0.7683664403996852
Validation loss: 2.7790951078106136

Epoch: 5| Step: 2
Training loss: 0.33905595693999085
Validation loss: 2.6669452243591842

Epoch: 5| Step: 3
Training loss: 0.7088600238798172
Validation loss: 2.7398160006471493

Epoch: 5| Step: 4
Training loss: 0.7408962863511371
Validation loss: 2.673358137512322

Epoch: 5| Step: 5
Training loss: 0.5440153559680719
Validation loss: 2.69868634020315

Epoch: 5| Step: 6
Training loss: 1.061575206627765
Validation loss: 2.755181910358685

Epoch: 5| Step: 7
Training loss: 0.7962200614894144
Validation loss: 2.757927147460731

Epoch: 5| Step: 8
Training loss: 0.47571074866997326
Validation loss: 2.7585835734219004

Epoch: 5| Step: 9
Training loss: 0.8953926902662636
Validation loss: 2.8171622680871278

Epoch: 5| Step: 10
Training loss: 0.5107233397760697
Validation loss: 2.676780892641085

Epoch: 5| Step: 11
Training loss: 0.41509966239575447
Validation loss: 2.708138958974008

Epoch: 259| Step: 0
Training loss: 0.8251750514686285
Validation loss: 2.7224020526864328

Epoch: 5| Step: 1
Training loss: 0.7826553674328489
Validation loss: 2.7654718115958628

Epoch: 5| Step: 2
Training loss: 1.0550911590098748
Validation loss: 2.792181655487735

Epoch: 5| Step: 3
Training loss: 0.6224614325606093
Validation loss: 2.6703129379423887

Epoch: 5| Step: 4
Training loss: 0.6487996342585647
Validation loss: 2.6784099614204524

Epoch: 5| Step: 5
Training loss: 0.8898623028329059
Validation loss: 2.6979729684578864

Epoch: 5| Step: 6
Training loss: 0.4569336876702992
Validation loss: 2.7438046667175264

Epoch: 5| Step: 7
Training loss: 0.43106276898225676
Validation loss: 2.762886552247211

Epoch: 5| Step: 8
Training loss: 0.354169967112403
Validation loss: 2.7120202949989696

Epoch: 5| Step: 9
Training loss: 0.8051307716535874
Validation loss: 2.789833688837997

Epoch: 5| Step: 10
Training loss: 0.6397379572302454
Validation loss: 2.7457712815257778

Epoch: 5| Step: 11
Training loss: 0.40963192077554794
Validation loss: 2.821700349052038

Epoch: 260| Step: 0
Training loss: 0.46888141379448167
Validation loss: 2.7731304446460623

Epoch: 5| Step: 1
Training loss: 0.6460625923513158
Validation loss: 2.765328296184167

Epoch: 5| Step: 2
Training loss: 0.8372609366644909
Validation loss: 2.762629501333813

Epoch: 5| Step: 3
Training loss: 0.6692861315293661
Validation loss: 2.6653166249328604

Epoch: 5| Step: 4
Training loss: 0.504445903337057
Validation loss: 2.7180197089362306

Epoch: 5| Step: 5
Training loss: 0.5271041325723596
Validation loss: 2.7656648061872575

Epoch: 5| Step: 6
Training loss: 0.824881915109006
Validation loss: 2.781384989859347

Epoch: 5| Step: 7
Training loss: 0.8462640254606593
Validation loss: 2.718466345653045

Epoch: 5| Step: 8
Training loss: 0.9252934518777598
Validation loss: 2.75317594796423

Epoch: 5| Step: 9
Training loss: 0.607097305965274
Validation loss: 2.7687404061202177

Epoch: 5| Step: 10
Training loss: 0.888167420460739
Validation loss: 2.7133498877606903

Epoch: 5| Step: 11
Training loss: 0.4648342612444093
Validation loss: 2.7965080759332097

Epoch: 261| Step: 0
Training loss: 0.5398890198911782
Validation loss: 2.7235098786328686

Epoch: 5| Step: 1
Training loss: 0.7670857643684297
Validation loss: 2.766186289035656

Epoch: 5| Step: 2
Training loss: 0.5982311948936373
Validation loss: 2.760398351260669

Epoch: 5| Step: 3
Training loss: 0.6372845248166876
Validation loss: 2.7268255046800265

Epoch: 5| Step: 4
Training loss: 0.5028656853996802
Validation loss: 2.766608406414809

Epoch: 5| Step: 5
Training loss: 0.5811321559522032
Validation loss: 2.7277964083483583

Epoch: 5| Step: 6
Training loss: 1.0662420237199255
Validation loss: 2.686521381547022

Epoch: 5| Step: 7
Training loss: 0.5551329691005025
Validation loss: 2.781315066973048

Epoch: 5| Step: 8
Training loss: 0.611621237981232
Validation loss: 2.736712374086727

Epoch: 5| Step: 9
Training loss: 0.7250375639293329
Validation loss: 2.7764868006622336

Epoch: 5| Step: 10
Training loss: 0.480993465069892
Validation loss: 2.7252331346706717

Epoch: 5| Step: 11
Training loss: 1.0302019284277144
Validation loss: 2.769415658853073

Epoch: 262| Step: 0
Training loss: 0.945942503276658
Validation loss: 2.821049746227665

Epoch: 5| Step: 1
Training loss: 0.9480600702713708
Validation loss: 2.7699524272696463

Epoch: 5| Step: 2
Training loss: 0.798541626233993
Validation loss: 2.747136944811281

Epoch: 5| Step: 3
Training loss: 0.5504067953968286
Validation loss: 2.805813420807308

Epoch: 5| Step: 4
Training loss: 0.6870310441086899
Validation loss: 2.7458340850813614

Epoch: 5| Step: 5
Training loss: 0.7785472275846093
Validation loss: 2.718293637672512

Epoch: 5| Step: 6
Training loss: 0.5853642775103188
Validation loss: 2.7118949298781287

Epoch: 5| Step: 7
Training loss: 0.6945112090335667
Validation loss: 2.7557756107972895

Epoch: 5| Step: 8
Training loss: 0.5495215816910906
Validation loss: 2.718453233972045

Epoch: 5| Step: 9
Training loss: 0.4032525104863158
Validation loss: 2.7301975164644294

Epoch: 5| Step: 10
Training loss: 0.47619176733886426
Validation loss: 2.763558666485147

Epoch: 5| Step: 11
Training loss: 0.8309110524077756
Validation loss: 2.744210365649092

Epoch: 263| Step: 0
Training loss: 0.6388376469956217
Validation loss: 2.7442105611303824

Epoch: 5| Step: 1
Training loss: 0.4903185950654706
Validation loss: 2.816402885022316

Epoch: 5| Step: 2
Training loss: 0.5584273724099248
Validation loss: 2.7518599083560487

Epoch: 5| Step: 3
Training loss: 0.8458992111847254
Validation loss: 2.7843591620397614

Epoch: 5| Step: 4
Training loss: 0.6530055498103478
Validation loss: 2.7413582739007025

Epoch: 5| Step: 5
Training loss: 1.0581428158607085
Validation loss: 2.736599095769137

Epoch: 5| Step: 6
Training loss: 0.3636217469967828
Validation loss: 2.7407521388374865

Epoch: 5| Step: 7
Training loss: 0.47687487448494437
Validation loss: 2.7880924935160807

Epoch: 5| Step: 8
Training loss: 0.7139530573808499
Validation loss: 2.751998272884875

Epoch: 5| Step: 9
Training loss: 0.6135147524912119
Validation loss: 2.7611271297816136

Epoch: 5| Step: 10
Training loss: 0.7260323097432422
Validation loss: 2.8519304673881876

Epoch: 5| Step: 11
Training loss: 0.6808082723343585
Validation loss: 2.7256615506486845

Epoch: 264| Step: 0
Training loss: 0.35600665548484356
Validation loss: 2.79489844112671

Epoch: 5| Step: 1
Training loss: 0.6252482398098738
Validation loss: 2.7868253745415643

Epoch: 5| Step: 2
Training loss: 0.837193338986803
Validation loss: 2.758771439667626

Epoch: 5| Step: 3
Training loss: 0.613731316322873
Validation loss: 2.744498942411523

Epoch: 5| Step: 4
Training loss: 0.6370232444935711
Validation loss: 2.8088266650145086

Epoch: 5| Step: 5
Training loss: 0.7793239885169142
Validation loss: 2.681118485753312

Epoch: 5| Step: 6
Training loss: 0.6091632475106876
Validation loss: 2.778872691900883

Epoch: 5| Step: 7
Training loss: 0.5081060001532544
Validation loss: 2.761488390950465

Epoch: 5| Step: 8
Training loss: 0.6172507772722754
Validation loss: 2.7924538873629228

Epoch: 5| Step: 9
Training loss: 0.8032142708291397
Validation loss: 2.7085281204210774

Epoch: 5| Step: 10
Training loss: 0.8196530552504794
Validation loss: 2.81290035930373

Epoch: 5| Step: 11
Training loss: 0.2627518178303461
Validation loss: 2.676861009135926

Epoch: 265| Step: 0
Training loss: 0.554996135973152
Validation loss: 2.7735372605985202

Epoch: 5| Step: 1
Training loss: 0.3850445776992648
Validation loss: 2.753010178826255

Epoch: 5| Step: 2
Training loss: 0.6274757464915677
Validation loss: 2.7307338267583745

Epoch: 5| Step: 3
Training loss: 0.80311883411935
Validation loss: 2.7680157854026537

Epoch: 5| Step: 4
Training loss: 0.632783912672305
Validation loss: 2.6703124450153832

Epoch: 5| Step: 5
Training loss: 0.5754008160819696
Validation loss: 2.72367131755497

Epoch: 5| Step: 6
Training loss: 0.7733010836431985
Validation loss: 2.7343842569830286

Epoch: 5| Step: 7
Training loss: 0.7693381672401007
Validation loss: 2.7456118693111216

Epoch: 5| Step: 8
Training loss: 0.9184999268333975
Validation loss: 2.7420424978205338

Epoch: 5| Step: 9
Training loss: 0.5507283016212712
Validation loss: 2.7500285884064763

Epoch: 5| Step: 10
Training loss: 0.39833968962834493
Validation loss: 2.726211864146987

Epoch: 5| Step: 11
Training loss: 0.7484237478501937
Validation loss: 2.70817597127687

Epoch: 266| Step: 0
Training loss: 0.5688950940436754
Validation loss: 2.7496132289669606

Epoch: 5| Step: 1
Training loss: 0.7512513688466935
Validation loss: 2.768196336629892

Epoch: 5| Step: 2
Training loss: 0.6988015448609948
Validation loss: 2.7316143777783584

Epoch: 5| Step: 3
Training loss: 0.528782217789231
Validation loss: 2.7091245424751955

Epoch: 5| Step: 4
Training loss: 0.7082413492128893
Validation loss: 2.702160514360633

Epoch: 5| Step: 5
Training loss: 0.7127194551835807
Validation loss: 2.736369820421653

Epoch: 5| Step: 6
Training loss: 0.5585129152510511
Validation loss: 2.76521276645271

Epoch: 5| Step: 7
Training loss: 0.5155474864610982
Validation loss: 2.7369341291550717

Epoch: 5| Step: 8
Training loss: 0.9123613226038236
Validation loss: 2.7511905527805585

Epoch: 5| Step: 9
Training loss: 0.7402965348447701
Validation loss: 2.720532406692513

Epoch: 5| Step: 10
Training loss: 0.35404711229466307
Validation loss: 2.73027295459787

Epoch: 5| Step: 11
Training loss: 0.8488020645824782
Validation loss: 2.7554808639896042

Epoch: 267| Step: 0
Training loss: 0.6495959493289991
Validation loss: 2.711785538361138

Epoch: 5| Step: 1
Training loss: 0.6133136862177054
Validation loss: 2.6848767881461035

Epoch: 5| Step: 2
Training loss: 0.7356293699382669
Validation loss: 2.813207074753287

Epoch: 5| Step: 3
Training loss: 0.4822721519257189
Validation loss: 2.7925784178389637

Epoch: 5| Step: 4
Training loss: 0.4034893060541027
Validation loss: 2.742411847913216

Epoch: 5| Step: 5
Training loss: 0.8819409346990427
Validation loss: 2.7390583330620686

Epoch: 5| Step: 6
Training loss: 0.7576919538440496
Validation loss: 2.676945632084661

Epoch: 5| Step: 7
Training loss: 0.7969463166880104
Validation loss: 2.7348517374699646

Epoch: 5| Step: 8
Training loss: 0.7305197060503481
Validation loss: 2.7814236400992014

Epoch: 5| Step: 9
Training loss: 0.5258788212428117
Validation loss: 2.700839748821233

Epoch: 5| Step: 10
Training loss: 0.7517220278255953
Validation loss: 2.745810809330074

Epoch: 5| Step: 11
Training loss: 0.5004659508166248
Validation loss: 2.776249961243294

Epoch: 268| Step: 0
Training loss: 0.9737962224074994
Validation loss: 2.8426498129358766

Epoch: 5| Step: 1
Training loss: 0.4945979659410046
Validation loss: 2.8178598547696865

Epoch: 5| Step: 2
Training loss: 0.4938144285683148
Validation loss: 2.696860199847522

Epoch: 5| Step: 3
Training loss: 0.39751908160540195
Validation loss: 2.743214826882562

Epoch: 5| Step: 4
Training loss: 0.8368548413470477
Validation loss: 2.7577479627800745

Epoch: 5| Step: 5
Training loss: 0.6147690481637677
Validation loss: 2.7247925873368954

Epoch: 5| Step: 6
Training loss: 0.4671267058453893
Validation loss: 2.7882306152146925

Epoch: 5| Step: 7
Training loss: 0.7120854259152931
Validation loss: 2.7741393584716607

Epoch: 5| Step: 8
Training loss: 0.6967918859620348
Validation loss: 2.815753788883388

Epoch: 5| Step: 9
Training loss: 0.3955194730570344
Validation loss: 2.7329388616336923

Epoch: 5| Step: 10
Training loss: 0.5497820021182342
Validation loss: 2.7953338888056183

Epoch: 5| Step: 11
Training loss: 0.5613407534437722
Validation loss: 2.76660667209802

Epoch: 269| Step: 0
Training loss: 0.8130843555399313
Validation loss: 2.8395662797475008

Epoch: 5| Step: 1
Training loss: 0.6130886382851322
Validation loss: 2.8493564346164955

Epoch: 5| Step: 2
Training loss: 0.4561922082486873
Validation loss: 2.7513100761926936

Epoch: 5| Step: 3
Training loss: 0.5956877659553028
Validation loss: 2.8380132737493384

Epoch: 5| Step: 4
Training loss: 0.8975516222609485
Validation loss: 2.7927169223887147

Epoch: 5| Step: 5
Training loss: 0.4163495545859146
Validation loss: 2.7541177546668547

Epoch: 5| Step: 6
Training loss: 0.5630526741568664
Validation loss: 2.8279351053011035

Epoch: 5| Step: 7
Training loss: 0.7844157736465956
Validation loss: 2.7519945114918714

Epoch: 5| Step: 8
Training loss: 0.45773834565356775
Validation loss: 2.824256763052938

Epoch: 5| Step: 9
Training loss: 0.6400834097004459
Validation loss: 2.778197774659791

Epoch: 5| Step: 10
Training loss: 0.49556274229888825
Validation loss: 2.793359731770993

Epoch: 5| Step: 11
Training loss: 0.6988207147673425
Validation loss: 2.768579277274737

Epoch: 270| Step: 0
Training loss: 0.6301114162819043
Validation loss: 2.769634888740501

Epoch: 5| Step: 1
Training loss: 0.7212350841150063
Validation loss: 2.823548863179257

Epoch: 5| Step: 2
Training loss: 0.5189641280777861
Validation loss: 2.779743089954529

Epoch: 5| Step: 3
Training loss: 0.6159410323879264
Validation loss: 2.738056661598667

Epoch: 5| Step: 4
Training loss: 0.47987937444713685
Validation loss: 2.714489620539988

Epoch: 5| Step: 5
Training loss: 0.7937256906947051
Validation loss: 2.734530896783554

Epoch: 5| Step: 6
Training loss: 0.6033924063413676
Validation loss: 2.70069655996523

Epoch: 5| Step: 7
Training loss: 0.7589479572160335
Validation loss: 2.703148744364918

Epoch: 5| Step: 8
Training loss: 0.7114068043834622
Validation loss: 2.755039110136885

Epoch: 5| Step: 9
Training loss: 0.5987756256959035
Validation loss: 2.720403555730713

Epoch: 5| Step: 10
Training loss: 0.4955056827606154
Validation loss: 2.838072443452163

Epoch: 5| Step: 11
Training loss: 0.19264395171031362
Validation loss: 2.7374166918696736

Epoch: 271| Step: 0
Training loss: 0.5374093345202645
Validation loss: 2.757955905834763

Epoch: 5| Step: 1
Training loss: 0.5948879229750471
Validation loss: 2.8646712491965207

Epoch: 5| Step: 2
Training loss: 0.8123706567956046
Validation loss: 2.769943056037688

Epoch: 5| Step: 3
Training loss: 0.5615178116226325
Validation loss: 2.744230377068957

Epoch: 5| Step: 4
Training loss: 0.5634981941288982
Validation loss: 2.765272509567051

Epoch: 5| Step: 5
Training loss: 0.6026639144366571
Validation loss: 2.7815771946270504

Epoch: 5| Step: 6
Training loss: 0.513898560143729
Validation loss: 2.820050189499368

Epoch: 5| Step: 7
Training loss: 0.5661427641372753
Validation loss: 2.7659081567326864

Epoch: 5| Step: 8
Training loss: 0.7763390493991912
Validation loss: 2.796041524292228

Epoch: 5| Step: 9
Training loss: 0.7301571431267776
Validation loss: 2.7737214278906586

Epoch: 5| Step: 10
Training loss: 0.3781345610552647
Validation loss: 2.7030427512296167

Epoch: 5| Step: 11
Training loss: 0.6727263357621072
Validation loss: 2.745232129933383

Epoch: 272| Step: 0
Training loss: 0.7231446136742441
Validation loss: 2.740995396138996

Epoch: 5| Step: 1
Training loss: 0.5410455082651839
Validation loss: 2.7772201156460903

Epoch: 5| Step: 2
Training loss: 0.81175325997711
Validation loss: 2.8485576003760866

Epoch: 5| Step: 3
Training loss: 0.42483848349648506
Validation loss: 2.7857681394094462

Epoch: 5| Step: 4
Training loss: 0.4426636467614249
Validation loss: 2.76799897498528

Epoch: 5| Step: 5
Training loss: 0.40478219283138517
Validation loss: 2.749508911413197

Epoch: 5| Step: 6
Training loss: 0.822398340383666
Validation loss: 2.780733081914662

Epoch: 5| Step: 7
Training loss: 0.485254120591566
Validation loss: 2.7480628386618773

Epoch: 5| Step: 8
Training loss: 0.6763779315761582
Validation loss: 2.6717413149400087

Epoch: 5| Step: 9
Training loss: 0.6855324855065914
Validation loss: 2.729803263453701

Epoch: 5| Step: 10
Training loss: 0.8072647746539513
Validation loss: 2.7786381276580068

Epoch: 5| Step: 11
Training loss: 0.44945438673272314
Validation loss: 2.7519538722365526

Epoch: 273| Step: 0
Training loss: 0.3988511612205152
Validation loss: 2.817554534315513

Epoch: 5| Step: 1
Training loss: 0.6286411793011624
Validation loss: 2.7454406880597517

Epoch: 5| Step: 2
Training loss: 0.5640741944091439
Validation loss: 2.7339880315257754

Epoch: 5| Step: 3
Training loss: 0.4352346250402896
Validation loss: 2.7624253659933076

Epoch: 5| Step: 4
Training loss: 0.45022293303984995
Validation loss: 2.742441569528554

Epoch: 5| Step: 5
Training loss: 0.5949789178944075
Validation loss: 2.7732228800514385

Epoch: 5| Step: 6
Training loss: 0.8111615527448828
Validation loss: 2.8004837764884627

Epoch: 5| Step: 7
Training loss: 0.5292767172490549
Validation loss: 2.798850642182698

Epoch: 5| Step: 8
Training loss: 0.6386861070452935
Validation loss: 2.7772100696324116

Epoch: 5| Step: 9
Training loss: 0.8245993725175896
Validation loss: 2.7414267663051186

Epoch: 5| Step: 10
Training loss: 0.6904983594268601
Validation loss: 2.8220914793570477

Epoch: 5| Step: 11
Training loss: 0.5320099836179957
Validation loss: 2.820301855459934

Epoch: 274| Step: 0
Training loss: 0.450554859295025
Validation loss: 2.8306208955096706

Epoch: 5| Step: 1
Training loss: 0.4846627703419994
Validation loss: 2.764513959974851

Epoch: 5| Step: 2
Training loss: 0.48908434627111963
Validation loss: 2.7602101062768294

Epoch: 5| Step: 3
Training loss: 0.7422213897998632
Validation loss: 2.7795183813273363

Epoch: 5| Step: 4
Training loss: 0.9931865378268278
Validation loss: 2.7462723277357357

Epoch: 5| Step: 5
Training loss: 0.47910610279244364
Validation loss: 2.7298839581371097

Epoch: 5| Step: 6
Training loss: 0.5842327495569786
Validation loss: 2.8340772932976575

Epoch: 5| Step: 7
Training loss: 0.5006936149866597
Validation loss: 2.7890151667207026

Epoch: 5| Step: 8
Training loss: 0.6160337311207027
Validation loss: 2.708983344545652

Epoch: 5| Step: 9
Training loss: 0.5380378050833827
Validation loss: 2.7433659049341195

Epoch: 5| Step: 10
Training loss: 0.5667373741671918
Validation loss: 2.7867873535324397

Epoch: 5| Step: 11
Training loss: 0.8176544722456279
Validation loss: 2.719284593339958

Epoch: 275| Step: 0
Training loss: 0.4209619106926214
Validation loss: 2.7757536390988986

Epoch: 5| Step: 1
Training loss: 0.5388777319445786
Validation loss: 2.801642409215283

Epoch: 5| Step: 2
Training loss: 0.8341876458976528
Validation loss: 2.802135567491411

Epoch: 5| Step: 3
Training loss: 0.4486054255588145
Validation loss: 2.7717113263054625

Epoch: 5| Step: 4
Training loss: 0.5417913941296597
Validation loss: 2.8094250894847077

Epoch: 5| Step: 5
Training loss: 0.5691467546644785
Validation loss: 2.758283598289152

Epoch: 5| Step: 6
Training loss: 0.43356115201465845
Validation loss: 2.838893852200517

Epoch: 5| Step: 7
Training loss: 0.8398092928183074
Validation loss: 2.7257762420162206

Epoch: 5| Step: 8
Training loss: 0.38957567419931244
Validation loss: 2.772437202698686

Epoch: 5| Step: 9
Training loss: 0.8240448103775625
Validation loss: 2.7861211602446123

Epoch: 5| Step: 10
Training loss: 0.5793391443163424
Validation loss: 2.8817629191413303

Epoch: 5| Step: 11
Training loss: 0.261834190302498
Validation loss: 2.7608729087414186

Epoch: 276| Step: 0
Training loss: 0.4608908160863288
Validation loss: 2.749650669307173

Epoch: 5| Step: 1
Training loss: 0.8983012552201837
Validation loss: 2.7910052602516315

Epoch: 5| Step: 2
Training loss: 0.5416220285900668
Validation loss: 2.784324022305228

Epoch: 5| Step: 3
Training loss: 0.577363156623552
Validation loss: 2.735291815961774

Epoch: 5| Step: 4
Training loss: 0.5976790629502151
Validation loss: 2.721477899369844

Epoch: 5| Step: 5
Training loss: 0.6586323365914007
Validation loss: 2.775700765914363

Epoch: 5| Step: 6
Training loss: 0.6083733812196576
Validation loss: 2.819376918000268

Epoch: 5| Step: 7
Training loss: 0.47327489798896716
Validation loss: 2.737690211064516

Epoch: 5| Step: 8
Training loss: 0.5211192935476531
Validation loss: 2.842852974987535

Epoch: 5| Step: 9
Training loss: 0.46643818757120115
Validation loss: 2.741948840994274

Epoch: 5| Step: 10
Training loss: 0.44448968931046384
Validation loss: 2.8225163402315268

Epoch: 5| Step: 11
Training loss: 0.9174374930166533
Validation loss: 2.744352046112138

Epoch: 277| Step: 0
Training loss: 0.6025758605305159
Validation loss: 2.7608577028065078

Epoch: 5| Step: 1
Training loss: 0.4396945883390347
Validation loss: 2.7333215409892877

Epoch: 5| Step: 2
Training loss: 0.591161884532472
Validation loss: 2.777765909937832

Epoch: 5| Step: 3
Training loss: 0.8203922051353775
Validation loss: 2.7345479020448575

Epoch: 5| Step: 4
Training loss: 0.4054870042752775
Validation loss: 2.7104301930724595

Epoch: 5| Step: 5
Training loss: 0.4720456774671386
Validation loss: 2.743387635299242

Epoch: 5| Step: 6
Training loss: 0.33440870801419587
Validation loss: 2.7418016450250517

Epoch: 5| Step: 7
Training loss: 0.5558071656146465
Validation loss: 2.8202693544928703

Epoch: 5| Step: 8
Training loss: 0.6991588417686861
Validation loss: 2.6777414534660955

Epoch: 5| Step: 9
Training loss: 0.48381756424061334
Validation loss: 2.7305256806252

Epoch: 5| Step: 10
Training loss: 0.8341642449337779
Validation loss: 2.726262587090163

Epoch: 5| Step: 11
Training loss: 0.4112563683790696
Validation loss: 2.7871926074040565

Epoch: 278| Step: 0
Training loss: 0.4897761844355289
Validation loss: 2.8025876244949615

Epoch: 5| Step: 1
Training loss: 0.7185951978416315
Validation loss: 2.770939671954492

Epoch: 5| Step: 2
Training loss: 0.5184253596010501
Validation loss: 2.678775902921181

Epoch: 5| Step: 3
Training loss: 0.6184646574652796
Validation loss: 2.794704028013912

Epoch: 5| Step: 4
Training loss: 0.694575444157433
Validation loss: 2.7423666726144496

Epoch: 5| Step: 5
Training loss: 0.4370908186095523
Validation loss: 2.8022541374609116

Epoch: 5| Step: 6
Training loss: 0.4358736018723736
Validation loss: 2.847164451716015

Epoch: 5| Step: 7
Training loss: 0.6624029178383505
Validation loss: 2.802589382625809

Epoch: 5| Step: 8
Training loss: 0.8192444887834391
Validation loss: 2.733612604576807

Epoch: 5| Step: 9
Training loss: 0.46851129811973113
Validation loss: 2.7780031761803996

Epoch: 5| Step: 10
Training loss: 0.7976638778635647
Validation loss: 2.767369454718413

Epoch: 5| Step: 11
Training loss: 0.262019809821195
Validation loss: 2.880443088605837

Epoch: 279| Step: 0
Training loss: 0.5863315528805007
Validation loss: 2.7847933004403065

Epoch: 5| Step: 1
Training loss: 0.4886172702448224
Validation loss: 2.732520689960129

Epoch: 5| Step: 2
Training loss: 0.566036208721641
Validation loss: 2.7524873437454795

Epoch: 5| Step: 3
Training loss: 0.35239072304716124
Validation loss: 2.80891734219058

Epoch: 5| Step: 4
Training loss: 0.7215120897820071
Validation loss: 2.815867100368574

Epoch: 5| Step: 5
Training loss: 0.6528141358803814
Validation loss: 2.7692497730919112

Epoch: 5| Step: 6
Training loss: 0.8051624563027195
Validation loss: 2.753019199943633

Epoch: 5| Step: 7
Training loss: 0.6277409295034841
Validation loss: 2.7857102230616464

Epoch: 5| Step: 8
Training loss: 0.5514605236070018
Validation loss: 2.7716009730660462

Epoch: 5| Step: 9
Training loss: 0.6361818214490614
Validation loss: 2.7294741625978287

Epoch: 5| Step: 10
Training loss: 0.37094271748576435
Validation loss: 2.702553308262889

Epoch: 5| Step: 11
Training loss: 0.6204427510301883
Validation loss: 2.7901552198613606

Epoch: 280| Step: 0
Training loss: 0.4624179406440983
Validation loss: 2.8469435537370384

Epoch: 5| Step: 1
Training loss: 0.5259564837487924
Validation loss: 2.816755900060505

Epoch: 5| Step: 2
Training loss: 0.5165626496801142
Validation loss: 2.7546809231915277

Epoch: 5| Step: 3
Training loss: 0.7051617052411163
Validation loss: 2.760448705139411

Epoch: 5| Step: 4
Training loss: 0.5915208934695725
Validation loss: 2.6399428447703994

Epoch: 5| Step: 5
Training loss: 0.526618288973032
Validation loss: 2.7509044203971627

Epoch: 5| Step: 6
Training loss: 0.5173777930310349
Validation loss: 2.758233809956623

Epoch: 5| Step: 7
Training loss: 0.8745087198092074
Validation loss: 2.757913013099855

Epoch: 5| Step: 8
Training loss: 0.5021000509789705
Validation loss: 2.731476062669306

Epoch: 5| Step: 9
Training loss: 0.6217291358987201
Validation loss: 2.725204654322997

Epoch: 5| Step: 10
Training loss: 0.7827429049501415
Validation loss: 2.789016381317865

Epoch: 5| Step: 11
Training loss: 0.44066231414039597
Validation loss: 2.7582617835900116

Epoch: 281| Step: 0
Training loss: 0.5632231355653103
Validation loss: 2.80235716511068

Epoch: 5| Step: 1
Training loss: 0.7055019679227941
Validation loss: 2.801526316806067

Epoch: 5| Step: 2
Training loss: 0.668536608510325
Validation loss: 2.856091704040993

Epoch: 5| Step: 3
Training loss: 0.4927967025218057
Validation loss: 2.805729186447103

Epoch: 5| Step: 4
Training loss: 0.520617647016058
Validation loss: 2.7706025405123778

Epoch: 5| Step: 5
Training loss: 0.4659201397082655
Validation loss: 2.8084582568908054

Epoch: 5| Step: 6
Training loss: 0.6852522431552249
Validation loss: 2.8537391611596026

Epoch: 5| Step: 7
Training loss: 0.6522624713265412
Validation loss: 2.7291702253498045

Epoch: 5| Step: 8
Training loss: 0.5046319393600246
Validation loss: 2.790954574938787

Epoch: 5| Step: 9
Training loss: 0.5724572912052556
Validation loss: 2.777185609932114

Epoch: 5| Step: 10
Training loss: 0.49839465396610116
Validation loss: 2.7590256707106904

Epoch: 5| Step: 11
Training loss: 0.3999923213579349
Validation loss: 2.795923362387217

Epoch: 282| Step: 0
Training loss: 0.6403077200491956
Validation loss: 2.7545750304176653

Epoch: 5| Step: 1
Training loss: 0.506961050008367
Validation loss: 2.8381406529956856

Epoch: 5| Step: 2
Training loss: 0.8045088190006704
Validation loss: 2.805647116500465

Epoch: 5| Step: 3
Training loss: 0.6907910125877812
Validation loss: 2.737450183780931

Epoch: 5| Step: 4
Training loss: 0.4748412299834623
Validation loss: 2.798193618964603

Epoch: 5| Step: 5
Training loss: 0.4094963578165845
Validation loss: 2.736867101439695

Epoch: 5| Step: 6
Training loss: 0.46879370803508347
Validation loss: 2.736561122924579

Epoch: 5| Step: 7
Training loss: 0.6680846085931363
Validation loss: 2.781790770060659

Epoch: 5| Step: 8
Training loss: 0.7767066069662686
Validation loss: 2.73798811391508

Epoch: 5| Step: 9
Training loss: 0.5596634552613381
Validation loss: 2.790721642022948

Epoch: 5| Step: 10
Training loss: 0.7043477552572467
Validation loss: 2.774606324099797

Epoch: 5| Step: 11
Training loss: 0.33470864985127446
Validation loss: 2.7822569549425173

Epoch: 283| Step: 0
Training loss: 0.39040213903242726
Validation loss: 2.8125019144122354

Epoch: 5| Step: 1
Training loss: 0.5520078919406316
Validation loss: 2.7857175692077822

Epoch: 5| Step: 2
Training loss: 0.5682872713371508
Validation loss: 2.765335089364624

Epoch: 5| Step: 3
Training loss: 0.5917141293127954
Validation loss: 2.782158310404401

Epoch: 5| Step: 4
Training loss: 0.5400482508065683
Validation loss: 2.839319256775479

Epoch: 5| Step: 5
Training loss: 0.5112038854120019
Validation loss: 2.868685422016735

Epoch: 5| Step: 6
Training loss: 0.7846243655725005
Validation loss: 2.766803145680908

Epoch: 5| Step: 7
Training loss: 0.6620954664001673
Validation loss: 2.7515922979459546

Epoch: 5| Step: 8
Training loss: 0.5065895613655494
Validation loss: 2.803327228788593

Epoch: 5| Step: 9
Training loss: 0.577642935737954
Validation loss: 2.7745205550952505

Epoch: 5| Step: 10
Training loss: 0.3994731532924535
Validation loss: 2.796017716084466

Epoch: 5| Step: 11
Training loss: 0.5688105624306015
Validation loss: 2.7458265454020747

Epoch: 284| Step: 0
Training loss: 0.4992681451994793
Validation loss: 2.8199602771868575

Epoch: 5| Step: 1
Training loss: 0.639112174941184
Validation loss: 2.7858859618150396

Epoch: 5| Step: 2
Training loss: 0.7351413542873141
Validation loss: 2.776320263956616

Epoch: 5| Step: 3
Training loss: 0.6680237596849161
Validation loss: 2.7558968061810973

Epoch: 5| Step: 4
Training loss: 0.5789478220150736
Validation loss: 2.7229174028515764

Epoch: 5| Step: 5
Training loss: 0.5001647498979527
Validation loss: 2.760775459412009

Epoch: 5| Step: 6
Training loss: 0.6190881797166764
Validation loss: 2.794128177315914

Epoch: 5| Step: 7
Training loss: 0.5208473744089195
Validation loss: 2.7589561317291227

Epoch: 5| Step: 8
Training loss: 0.40925854125690303
Validation loss: 2.7930447299110326

Epoch: 5| Step: 9
Training loss: 0.6809127550325172
Validation loss: 2.790410173013745

Epoch: 5| Step: 10
Training loss: 0.5598743138872266
Validation loss: 2.8076038977266986

Epoch: 5| Step: 11
Training loss: 1.0619829266032432
Validation loss: 2.790703873767416

Epoch: 285| Step: 0
Training loss: 0.6018965648143043
Validation loss: 2.7683772743966624

Epoch: 5| Step: 1
Training loss: 0.46482759335433077
Validation loss: 2.8216002668866325

Epoch: 5| Step: 2
Training loss: 0.7066651128655871
Validation loss: 2.767192335392012

Epoch: 5| Step: 3
Training loss: 0.4375033208176057
Validation loss: 2.75696588908796

Epoch: 5| Step: 4
Training loss: 0.45639577522520663
Validation loss: 2.791690033961946

Epoch: 5| Step: 5
Training loss: 0.6456579821453379
Validation loss: 2.788682108493974

Epoch: 5| Step: 6
Training loss: 0.8446407561188204
Validation loss: 2.8178623542833

Epoch: 5| Step: 7
Training loss: 0.6081890891041339
Validation loss: 2.85615466603585

Epoch: 5| Step: 8
Training loss: 0.6796654007048492
Validation loss: 2.7390151734079806

Epoch: 5| Step: 9
Training loss: 0.42919890628321605
Validation loss: 2.8184047227411306

Epoch: 5| Step: 10
Training loss: 0.45777659486967065
Validation loss: 2.7402044228013227

Epoch: 5| Step: 11
Training loss: 0.6694709439087007
Validation loss: 2.823783911385576

Epoch: 286| Step: 0
Training loss: 0.41485365372669825
Validation loss: 2.8099194626732364

Epoch: 5| Step: 1
Training loss: 0.7784181387387493
Validation loss: 2.7182281877630814

Epoch: 5| Step: 2
Training loss: 0.616371871318315
Validation loss: 2.795268160171775

Epoch: 5| Step: 3
Training loss: 0.6821791917729225
Validation loss: 2.858025727574009

Epoch: 5| Step: 4
Training loss: 0.8038236555223081
Validation loss: 2.7761865378839277

Epoch: 5| Step: 5
Training loss: 0.7967921943276474
Validation loss: 2.7011475505639266

Epoch: 5| Step: 6
Training loss: 0.38592640787470667
Validation loss: 2.8014005280518046

Epoch: 5| Step: 7
Training loss: 0.421011535602019
Validation loss: 2.7573049544727715

Epoch: 5| Step: 8
Training loss: 0.5801061244590667
Validation loss: 2.8390295793426326

Epoch: 5| Step: 9
Training loss: 0.6527888669657027
Validation loss: 2.8849718299539404

Epoch: 5| Step: 10
Training loss: 0.5622252482049894
Validation loss: 2.8209320120594152

Epoch: 5| Step: 11
Training loss: 0.4826658303892854
Validation loss: 2.7792560952385594

Epoch: 287| Step: 0
Training loss: 0.6450359102720891
Validation loss: 2.7694063288498456

Epoch: 5| Step: 1
Training loss: 0.6692190236819837
Validation loss: 2.7680609440521127

Epoch: 5| Step: 2
Training loss: 0.6334667826481732
Validation loss: 2.7974622454466296

Epoch: 5| Step: 3
Training loss: 0.8901456245483246
Validation loss: 2.8323072417376847

Epoch: 5| Step: 4
Training loss: 0.49549854045849273
Validation loss: 2.8258909425475736

Epoch: 5| Step: 5
Training loss: 0.4806660347920937
Validation loss: 2.7829775570485267

Epoch: 5| Step: 6
Training loss: 0.7478832334804498
Validation loss: 2.8434278494325986

Epoch: 5| Step: 7
Training loss: 0.43437852377800135
Validation loss: 2.8328037848165826

Epoch: 5| Step: 8
Training loss: 0.5885345379783085
Validation loss: 2.8466500038095557

Epoch: 5| Step: 9
Training loss: 0.6891739579967825
Validation loss: 2.8101744220546614

Epoch: 5| Step: 10
Training loss: 0.5136750659916035
Validation loss: 2.805851706224778

Epoch: 5| Step: 11
Training loss: 0.20308551954845308
Validation loss: 2.803277053309645

Epoch: 288| Step: 0
Training loss: 0.5571846160985198
Validation loss: 2.7829020840424166

Epoch: 5| Step: 1
Training loss: 0.702591715014958
Validation loss: 2.7863222724756467

Epoch: 5| Step: 2
Training loss: 0.5395656393775737
Validation loss: 2.8130333712592166

Epoch: 5| Step: 3
Training loss: 0.6116468189962259
Validation loss: 2.7639550197672795

Epoch: 5| Step: 4
Training loss: 0.48409361510877924
Validation loss: 2.7965857002767156

Epoch: 5| Step: 5
Training loss: 0.5115771206844488
Validation loss: 2.7439470759110587

Epoch: 5| Step: 6
Training loss: 0.5671958681019961
Validation loss: 2.7010183964227226

Epoch: 5| Step: 7
Training loss: 0.7293783607176668
Validation loss: 2.760750499668299

Epoch: 5| Step: 8
Training loss: 0.47307851545389124
Validation loss: 2.810846519093405

Epoch: 5| Step: 9
Training loss: 0.7434063189503011
Validation loss: 2.757962054411142

Epoch: 5| Step: 10
Training loss: 0.5952318171896692
Validation loss: 2.715582972451187

Epoch: 5| Step: 11
Training loss: 0.6181316638429185
Validation loss: 2.8160097951586605

Epoch: 289| Step: 0
Training loss: 0.4588890950753721
Validation loss: 2.8254654358854925

Epoch: 5| Step: 1
Training loss: 0.4775194347381026
Validation loss: 2.7290521566134625

Epoch: 5| Step: 2
Training loss: 0.47019261261070655
Validation loss: 2.70820354126214

Epoch: 5| Step: 3
Training loss: 0.7322915736958502
Validation loss: 2.737324658676096

Epoch: 5| Step: 4
Training loss: 0.7566302013713154
Validation loss: 2.7260303980053027

Epoch: 5| Step: 5
Training loss: 0.5609057404179325
Validation loss: 2.767089710916588

Epoch: 5| Step: 6
Training loss: 0.6058076463821916
Validation loss: 2.818913546946868

Epoch: 5| Step: 7
Training loss: 0.5828583747870117
Validation loss: 2.7284895345668794

Epoch: 5| Step: 8
Training loss: 0.652109206745642
Validation loss: 2.8058619329295786

Epoch: 5| Step: 9
Training loss: 0.6849595730400582
Validation loss: 2.8145382206706477

Epoch: 5| Step: 10
Training loss: 0.7455047359508008
Validation loss: 2.78796936254643

Epoch: 5| Step: 11
Training loss: 0.1436531481794892
Validation loss: 2.89375239784795

Epoch: 290| Step: 0
Training loss: 0.5272805070041551
Validation loss: 2.7540891329595283

Epoch: 5| Step: 1
Training loss: 0.8087328731250447
Validation loss: 2.780686189174447

Epoch: 5| Step: 2
Training loss: 0.7137998035111054
Validation loss: 2.7770321005416396

Epoch: 5| Step: 3
Training loss: 0.6016466651596462
Validation loss: 2.811652755280793

Epoch: 5| Step: 4
Training loss: 0.45812619108953373
Validation loss: 2.812900811351613

Epoch: 5| Step: 5
Training loss: 0.5692121263150585
Validation loss: 2.7844875651167698

Epoch: 5| Step: 6
Training loss: 0.4343450412436008
Validation loss: 2.7947490611165917

Epoch: 5| Step: 7
Training loss: 0.6008905894140127
Validation loss: 2.7757711952715223

Epoch: 5| Step: 8
Training loss: 0.3366432096355987
Validation loss: 2.762527840101483

Epoch: 5| Step: 9
Training loss: 0.5940145605852233
Validation loss: 2.7696722628730153

Epoch: 5| Step: 10
Training loss: 0.4193734246862532
Validation loss: 2.7431108200901533

Epoch: 5| Step: 11
Training loss: 1.3810538623037505
Validation loss: 2.7852626778419327

Epoch: 291| Step: 0
Training loss: 0.5819745644225323
Validation loss: 2.75531417893355

Epoch: 5| Step: 1
Training loss: 0.4679228319111239
Validation loss: 2.8068477277238464

Epoch: 5| Step: 2
Training loss: 0.5196722025864939
Validation loss: 2.734643708604496

Epoch: 5| Step: 3
Training loss: 0.7176416392866632
Validation loss: 2.7389890397255163

Epoch: 5| Step: 4
Training loss: 0.5325970121674454
Validation loss: 2.832749346313006

Epoch: 5| Step: 5
Training loss: 0.6755907749467128
Validation loss: 2.8078981616086924

Epoch: 5| Step: 6
Training loss: 0.5472071592589004
Validation loss: 2.7514912398391402

Epoch: 5| Step: 7
Training loss: 0.59563835917619
Validation loss: 2.8015517554260603

Epoch: 5| Step: 8
Training loss: 0.40329662927731885
Validation loss: 2.7892615695152805

Epoch: 5| Step: 9
Training loss: 0.36022407323419037
Validation loss: 2.767462768160661

Epoch: 5| Step: 10
Training loss: 0.4140732241987177
Validation loss: 2.782916080775406

Epoch: 5| Step: 11
Training loss: 0.5484111464382537
Validation loss: 2.712557295005169

Epoch: 292| Step: 0
Training loss: 0.5539370282100238
Validation loss: 2.7870171506504793

Epoch: 5| Step: 1
Training loss: 0.5200096451800158
Validation loss: 2.7058694611575205

Epoch: 5| Step: 2
Training loss: 0.3528086511217853
Validation loss: 2.7303038962555624

Epoch: 5| Step: 3
Training loss: 0.7386531397775059
Validation loss: 2.7702771228497234

Epoch: 5| Step: 4
Training loss: 0.4365362724448384
Validation loss: 2.8173498265248824

Epoch: 5| Step: 5
Training loss: 0.5352916685416991
Validation loss: 2.7751456395728495

Epoch: 5| Step: 6
Training loss: 0.5258923372131487
Validation loss: 2.7689224958684973

Epoch: 5| Step: 7
Training loss: 0.5683199419847236
Validation loss: 2.7397469675972235

Epoch: 5| Step: 8
Training loss: 0.5647471892788041
Validation loss: 2.686225548270942

Epoch: 5| Step: 9
Training loss: 0.5989048201386908
Validation loss: 2.798058577285886

Epoch: 5| Step: 10
Training loss: 0.5454985052694932
Validation loss: 2.8195264360149466

Epoch: 5| Step: 11
Training loss: 0.7529035234667527
Validation loss: 2.742126362726775

Epoch: 293| Step: 0
Training loss: 0.43232148615316235
Validation loss: 2.8438206863002122

Epoch: 5| Step: 1
Training loss: 0.5365986007960813
Validation loss: 2.8340248369675627

Epoch: 5| Step: 2
Training loss: 0.8474444287290674
Validation loss: 2.730983905647501

Epoch: 5| Step: 3
Training loss: 0.5010269466889392
Validation loss: 2.727634616283888

Epoch: 5| Step: 4
Training loss: 0.6022351455250048
Validation loss: 2.805111933535748

Epoch: 5| Step: 5
Training loss: 0.7365290521950411
Validation loss: 2.7974017409112704

Epoch: 5| Step: 6
Training loss: 0.5296800359689556
Validation loss: 2.7342140332027305

Epoch: 5| Step: 7
Training loss: 0.4325355814481321
Validation loss: 2.864021993025634

Epoch: 5| Step: 8
Training loss: 0.599556091128004
Validation loss: 2.770829965594164

Epoch: 5| Step: 9
Training loss: 0.539494382922723
Validation loss: 2.799610717994535

Epoch: 5| Step: 10
Training loss: 0.48513849136850024
Validation loss: 2.8081962859524645

Epoch: 5| Step: 11
Training loss: 0.5736603909163441
Validation loss: 2.8596853494286956

Epoch: 294| Step: 0
Training loss: 0.4667755824384273
Validation loss: 2.7891119730859786

Epoch: 5| Step: 1
Training loss: 0.4697383157445335
Validation loss: 2.7910569127639215

Epoch: 5| Step: 2
Training loss: 0.39669929279392246
Validation loss: 2.726455699136932

Epoch: 5| Step: 3
Training loss: 0.5577282636280645
Validation loss: 2.788809988378913

Epoch: 5| Step: 4
Training loss: 0.33147701680514763
Validation loss: 2.8304457793153475

Epoch: 5| Step: 5
Training loss: 0.6347258100494032
Validation loss: 2.7906960904420473

Epoch: 5| Step: 6
Training loss: 0.5142599590414634
Validation loss: 2.7909907559460776

Epoch: 5| Step: 7
Training loss: 0.569775341457934
Validation loss: 2.805640066849534

Epoch: 5| Step: 8
Training loss: 0.5280280300705268
Validation loss: 2.8043057421866306

Epoch: 5| Step: 9
Training loss: 0.8537045058141461
Validation loss: 2.836218607187859

Epoch: 5| Step: 10
Training loss: 0.49506185248734363
Validation loss: 2.845439318296163

Epoch: 5| Step: 11
Training loss: 0.17024947518318218
Validation loss: 2.8318283885340656

Epoch: 295| Step: 0
Training loss: 0.6692237886946776
Validation loss: 2.7331846043830317

Epoch: 5| Step: 1
Training loss: 0.34828517047357815
Validation loss: 2.745598188952906

Epoch: 5| Step: 2
Training loss: 0.8293237107723969
Validation loss: 2.7224659901150687

Epoch: 5| Step: 3
Training loss: 0.4882717742000464
Validation loss: 2.8100802255301103

Epoch: 5| Step: 4
Training loss: 0.61269931761503
Validation loss: 2.8310059298364845

Epoch: 5| Step: 5
Training loss: 0.43374981520151384
Validation loss: 2.841139562910499

Epoch: 5| Step: 6
Training loss: 0.5714488009933641
Validation loss: 2.8379065418431515

Epoch: 5| Step: 7
Training loss: 0.4418582796011527
Validation loss: 2.8229898581688055

Epoch: 5| Step: 8
Training loss: 0.5248529739228034
Validation loss: 2.7886996420533094

Epoch: 5| Step: 9
Training loss: 0.5237928010208429
Validation loss: 2.8967980840650576

Epoch: 5| Step: 10
Training loss: 0.5430950319826087
Validation loss: 2.8294589828937693

Epoch: 5| Step: 11
Training loss: 0.36457076959306456
Validation loss: 2.80323581441079

Epoch: 296| Step: 0
Training loss: 0.6823520391024959
Validation loss: 2.8157224631932096

Epoch: 5| Step: 1
Training loss: 0.5758536543023102
Validation loss: 2.8140297261726057

Epoch: 5| Step: 2
Training loss: 0.7003491390981453
Validation loss: 2.889692523839585

Epoch: 5| Step: 3
Training loss: 0.3605554308966186
Validation loss: 2.812913451004808

Epoch: 5| Step: 4
Training loss: 0.6432033847681821
Validation loss: 2.8457728237534985

Epoch: 5| Step: 5
Training loss: 0.5559670639539986
Validation loss: 2.8603000013245836

Epoch: 5| Step: 6
Training loss: 0.8689431298284883
Validation loss: 2.7651510353353204

Epoch: 5| Step: 7
Training loss: 0.5761440981618845
Validation loss: 2.8313846490152246

Epoch: 5| Step: 8
Training loss: 0.5766663062456507
Validation loss: 2.831025345277311

Epoch: 5| Step: 9
Training loss: 0.5642536431221571
Validation loss: 2.8201817229463644

Epoch: 5| Step: 10
Training loss: 0.529377076101004
Validation loss: 2.7749274822875005

Epoch: 5| Step: 11
Training loss: 0.6521332452540526
Validation loss: 2.81685384790528

Epoch: 297| Step: 0
Training loss: 0.7899010612002559
Validation loss: 2.816348988395786

Epoch: 5| Step: 1
Training loss: 0.5889318123904824
Validation loss: 2.778652392555129

Epoch: 5| Step: 2
Training loss: 0.5163568447100794
Validation loss: 2.8061714992574096

Epoch: 5| Step: 3
Training loss: 0.4706129882110436
Validation loss: 2.7999528167785237

Epoch: 5| Step: 4
Training loss: 0.39118560617588505
Validation loss: 2.8004576825558516

Epoch: 5| Step: 5
Training loss: 0.6675500059148808
Validation loss: 2.7740926855176147

Epoch: 5| Step: 6
Training loss: 0.7440936456704016
Validation loss: 2.8090386106902794

Epoch: 5| Step: 7
Training loss: 0.5603445930885209
Validation loss: 2.758312522218071

Epoch: 5| Step: 8
Training loss: 0.720300784398459
Validation loss: 2.7817685897485744

Epoch: 5| Step: 9
Training loss: 0.7929923894957166
Validation loss: 2.759544984673059

Epoch: 5| Step: 10
Training loss: 0.45609572428125394
Validation loss: 2.777698435180061

Epoch: 5| Step: 11
Training loss: 0.5850673572365961
Validation loss: 2.796356128178718

Epoch: 298| Step: 0
Training loss: 0.467867385890969
Validation loss: 2.708813556253536

Epoch: 5| Step: 1
Training loss: 0.6801859025825153
Validation loss: 2.7991575165720466

Epoch: 5| Step: 2
Training loss: 0.4715830386007471
Validation loss: 2.7206641507283944

Epoch: 5| Step: 3
Training loss: 0.4578130832707462
Validation loss: 2.786808150012163

Epoch: 5| Step: 4
Training loss: 0.636616657708002
Validation loss: 2.7921672747021264

Epoch: 5| Step: 5
Training loss: 0.6095968967301185
Validation loss: 2.754505617105875

Epoch: 5| Step: 6
Training loss: 0.43022501876962244
Validation loss: 2.752341747256137

Epoch: 5| Step: 7
Training loss: 0.7534892455803608
Validation loss: 2.775106585090988

Epoch: 5| Step: 8
Training loss: 0.5802628707822433
Validation loss: 2.8141161654938354

Epoch: 5| Step: 9
Training loss: 0.49242790345573867
Validation loss: 2.8190903062784285

Epoch: 5| Step: 10
Training loss: 0.5802388594682519
Validation loss: 2.7847821972926825

Epoch: 5| Step: 11
Training loss: 0.7025485536826626
Validation loss: 2.749251256506485

Epoch: 299| Step: 0
Training loss: 0.5324831562781065
Validation loss: 2.8475040348014344

Epoch: 5| Step: 1
Training loss: 0.48917866445457403
Validation loss: 2.7658428386522216

Epoch: 5| Step: 2
Training loss: 0.47191293450268007
Validation loss: 2.7759239119317725

Epoch: 5| Step: 3
Training loss: 0.8214035045163556
Validation loss: 2.83710250535025

Epoch: 5| Step: 4
Training loss: 0.8413908437241108
Validation loss: 2.783174117087731

Epoch: 5| Step: 5
Training loss: 0.2564165731161685
Validation loss: 2.7789964225323227

Epoch: 5| Step: 6
Training loss: 0.48343653673249876
Validation loss: 2.7704479097656747

Epoch: 5| Step: 7
Training loss: 0.45789968682424415
Validation loss: 2.7653989178623113

Epoch: 5| Step: 8
Training loss: 0.621577044854312
Validation loss: 2.806884733772261

Epoch: 5| Step: 9
Training loss: 0.5382018475040464
Validation loss: 2.781914092370377

Epoch: 5| Step: 10
Training loss: 0.6496271916628302
Validation loss: 2.8295690843480563

Epoch: 5| Step: 11
Training loss: 0.7769993541498826
Validation loss: 2.7793627525844933

Epoch: 300| Step: 0
Training loss: 0.5837926900884308
Validation loss: 2.792679977605039

Epoch: 5| Step: 1
Training loss: 0.563191889051396
Validation loss: 2.7047613626374183

Epoch: 5| Step: 2
Training loss: 0.5004817013191706
Validation loss: 2.7393166928414483

Epoch: 5| Step: 3
Training loss: 0.38608628389680344
Validation loss: 2.80786656430429

Epoch: 5| Step: 4
Training loss: 0.5592872476208747
Validation loss: 2.7323147378040296

Epoch: 5| Step: 5
Training loss: 0.49755035782905527
Validation loss: 2.769676373279455

Epoch: 5| Step: 6
Training loss: 0.36436154113306246
Validation loss: 2.8536606825091595

Epoch: 5| Step: 7
Training loss: 0.5338438327688533
Validation loss: 2.8004648800501277

Epoch: 5| Step: 8
Training loss: 0.31103883318920994
Validation loss: 2.828583769707709

Epoch: 5| Step: 9
Training loss: 0.5037097991540004
Validation loss: 2.7884539519973277

Epoch: 5| Step: 10
Training loss: 0.7359086114028378
Validation loss: 2.7629403879509518

Epoch: 5| Step: 11
Training loss: 0.8187591013511726
Validation loss: 2.804822240229928

Epoch: 301| Step: 0
Training loss: 0.45430244186546176
Validation loss: 2.82585891013653

Epoch: 5| Step: 1
Training loss: 0.34344326769399985
Validation loss: 2.8205485152717995

Epoch: 5| Step: 2
Training loss: 0.6208326882693974
Validation loss: 2.8317766588151256

Epoch: 5| Step: 3
Training loss: 0.5637123764830716
Validation loss: 2.8317462260318598

Epoch: 5| Step: 4
Training loss: 0.3973824800853488
Validation loss: 2.8179585468561226

Epoch: 5| Step: 5
Training loss: 0.8114562299421192
Validation loss: 2.73564329978325

Epoch: 5| Step: 6
Training loss: 0.48958614700266395
Validation loss: 2.776859919114781

Epoch: 5| Step: 7
Training loss: 0.6264881061329154
Validation loss: 2.8461253896471708

Epoch: 5| Step: 8
Training loss: 0.5905451867000844
Validation loss: 2.8236886877321736

Epoch: 5| Step: 9
Training loss: 0.43702699432101305
Validation loss: 2.805026502319724

Epoch: 5| Step: 10
Training loss: 0.4399304658501117
Validation loss: 2.846596323911588

Epoch: 5| Step: 11
Training loss: 0.29758975920864944
Validation loss: 2.798677794027796

Epoch: 302| Step: 0
Training loss: 0.537220197861947
Validation loss: 2.7394672497328485

Epoch: 5| Step: 1
Training loss: 0.6780776328143017
Validation loss: 2.8039253920834124

Epoch: 5| Step: 2
Training loss: 0.5386309624087627
Validation loss: 2.772977140661885

Epoch: 5| Step: 3
Training loss: 0.5628135125353917
Validation loss: 2.739992732411977

Epoch: 5| Step: 4
Training loss: 0.43488146326076255
Validation loss: 2.7939144463041377

Epoch: 5| Step: 5
Training loss: 0.5107815729130296
Validation loss: 2.8108457822115924

Epoch: 5| Step: 6
Training loss: 0.42989424153464517
Validation loss: 2.763482310844768

Epoch: 5| Step: 7
Training loss: 0.622554309306642
Validation loss: 2.76732788175009

Epoch: 5| Step: 8
Training loss: 0.4909688758900925
Validation loss: 2.765979736911293

Epoch: 5| Step: 9
Training loss: 0.500244944894348
Validation loss: 2.7759561447988377

Epoch: 5| Step: 10
Training loss: 0.5845496972218754
Validation loss: 2.7874715169241133

Epoch: 5| Step: 11
Training loss: 0.419571042438011
Validation loss: 2.8939371361584474

Epoch: 303| Step: 0
Training loss: 0.5738699236267019
Validation loss: 2.815514633691445

Epoch: 5| Step: 1
Training loss: 0.52935331824893
Validation loss: 2.7312101304485403

Epoch: 5| Step: 2
Training loss: 0.5994580105766788
Validation loss: 2.7517996466141237

Epoch: 5| Step: 3
Training loss: 0.3553115371315289
Validation loss: 2.740590734640956

Epoch: 5| Step: 4
Training loss: 0.7592048831229948
Validation loss: 2.7931160378911626

Epoch: 5| Step: 5
Training loss: 0.5207139800328907
Validation loss: 2.770034435852323

Epoch: 5| Step: 6
Training loss: 0.5960007471249525
Validation loss: 2.7802631720552258

Epoch: 5| Step: 7
Training loss: 0.4763700534410589
Validation loss: 2.8267615563638384

Epoch: 5| Step: 8
Training loss: 0.37108752596805566
Validation loss: 2.809374457144623

Epoch: 5| Step: 9
Training loss: 0.533895804169339
Validation loss: 2.705939222644311

Epoch: 5| Step: 10
Training loss: 0.579581385151459
Validation loss: 2.801454485321371

Epoch: 5| Step: 11
Training loss: 0.43495110105398627
Validation loss: 2.8042827657743263

Epoch: 304| Step: 0
Training loss: 0.6447411859951926
Validation loss: 2.8378794583028504

Epoch: 5| Step: 1
Training loss: 0.5173643138396646
Validation loss: 2.7732876123750145

Epoch: 5| Step: 2
Training loss: 0.5285316932868982
Validation loss: 2.7881516786786973

Epoch: 5| Step: 3
Training loss: 0.6069306966600456
Validation loss: 2.7885479243116498

Epoch: 5| Step: 4
Training loss: 0.5471912559498014
Validation loss: 2.7129085385468312

Epoch: 5| Step: 5
Training loss: 0.6095599602941969
Validation loss: 2.81142332343321

Epoch: 5| Step: 6
Training loss: 0.7010241594627258
Validation loss: 2.818602888267759

Epoch: 5| Step: 7
Training loss: 0.5104687398181327
Validation loss: 2.7764537223956434

Epoch: 5| Step: 8
Training loss: 0.5533272895952104
Validation loss: 2.797298260847188

Epoch: 5| Step: 9
Training loss: 0.345287903388692
Validation loss: 2.7941783997581084

Epoch: 5| Step: 10
Training loss: 0.5189997313210264
Validation loss: 2.774143709345767

Epoch: 5| Step: 11
Training loss: 0.509254725713812
Validation loss: 2.763438961067922

Epoch: 305| Step: 0
Training loss: 0.5164123938767787
Validation loss: 2.8135262489014106

Epoch: 5| Step: 1
Training loss: 0.6477791304948611
Validation loss: 2.7488328595500353

Epoch: 5| Step: 2
Training loss: 0.4959657008200113
Validation loss: 2.817498984936066

Epoch: 5| Step: 3
Training loss: 0.6367418951964791
Validation loss: 2.775081143896858

Epoch: 5| Step: 4
Training loss: 0.7225088845601001
Validation loss: 2.7756310935276747

Epoch: 5| Step: 5
Training loss: 0.2875791326752335
Validation loss: 2.8180056477975843

Epoch: 5| Step: 6
Training loss: 0.5881867280889554
Validation loss: 2.7369737428465633

Epoch: 5| Step: 7
Training loss: 0.5125097901874601
Validation loss: 2.780437447226205

Epoch: 5| Step: 8
Training loss: 0.7939926827763775
Validation loss: 2.8148928600314824

Epoch: 5| Step: 9
Training loss: 0.40032962241320236
Validation loss: 2.8030508042194233

Epoch: 5| Step: 10
Training loss: 0.4068526969164418
Validation loss: 2.7955719062840068

Epoch: 5| Step: 11
Training loss: 0.5202101666967279
Validation loss: 2.8500544178937353

Epoch: 306| Step: 0
Training loss: 0.4789791897959887
Validation loss: 2.7816640281398075

Epoch: 5| Step: 1
Training loss: 0.5080108841946555
Validation loss: 2.7848146647337955

Epoch: 5| Step: 2
Training loss: 0.4670576380769246
Validation loss: 2.7808460449436536

Epoch: 5| Step: 3
Training loss: 0.5892227390005575
Validation loss: 2.781213202929585

Epoch: 5| Step: 4
Training loss: 0.4701539947972925
Validation loss: 2.8403907014793086

Epoch: 5| Step: 5
Training loss: 0.4517067715070344
Validation loss: 2.788940149182763

Epoch: 5| Step: 6
Training loss: 0.5966463220136262
Validation loss: 2.8112353165886055

Epoch: 5| Step: 7
Training loss: 0.5111346806341541
Validation loss: 2.774078995208441

Epoch: 5| Step: 8
Training loss: 0.4408201191453421
Validation loss: 2.722016090067794

Epoch: 5| Step: 9
Training loss: 0.7854870910506514
Validation loss: 2.7880142193782373

Epoch: 5| Step: 10
Training loss: 0.6871574155181837
Validation loss: 2.822542863756306

Epoch: 5| Step: 11
Training loss: 0.4940084650071168
Validation loss: 2.851170809943711

Epoch: 307| Step: 0
Training loss: 0.5320559446902724
Validation loss: 2.833813385873622

Epoch: 5| Step: 1
Training loss: 0.4155013438247819
Validation loss: 2.777218067814668

Epoch: 5| Step: 2
Training loss: 0.4979182507344776
Validation loss: 2.8455327423062857

Epoch: 5| Step: 3
Training loss: 0.5474850385616092
Validation loss: 2.796779957724603

Epoch: 5| Step: 4
Training loss: 0.684581740171034
Validation loss: 2.8178253831132087

Epoch: 5| Step: 5
Training loss: 0.5146918378043803
Validation loss: 2.768593418180092

Epoch: 5| Step: 6
Training loss: 0.6088144218148979
Validation loss: 2.769825792813731

Epoch: 5| Step: 7
Training loss: 0.8080921183517684
Validation loss: 2.7882505850380737

Epoch: 5| Step: 8
Training loss: 0.6326183209551898
Validation loss: 2.7643261677523285

Epoch: 5| Step: 9
Training loss: 0.5598684851302936
Validation loss: 2.8222404258861418

Epoch: 5| Step: 10
Training loss: 0.4357201954119227
Validation loss: 2.7637238478519555

Epoch: 5| Step: 11
Training loss: 0.45692977430814463
Validation loss: 2.68409510727218

Epoch: 308| Step: 0
Training loss: 0.834904397756746
Validation loss: 2.7864628563009375

Epoch: 5| Step: 1
Training loss: 0.40158678345043547
Validation loss: 2.812454053715412

Epoch: 5| Step: 2
Training loss: 0.5280287355800068
Validation loss: 2.787098250782363

Epoch: 5| Step: 3
Training loss: 0.3693221720566634
Validation loss: 2.7945823863114945

Epoch: 5| Step: 4
Training loss: 0.5658399974175881
Validation loss: 2.780152179202852

Epoch: 5| Step: 5
Training loss: 0.5984590909962341
Validation loss: 2.7419092701959396

Epoch: 5| Step: 6
Training loss: 0.4901585919291103
Validation loss: 2.7738461081512766

Epoch: 5| Step: 7
Training loss: 0.5538468505259456
Validation loss: 2.716802389073941

Epoch: 5| Step: 8
Training loss: 0.3801360867284403
Validation loss: 2.7607506651917424

Epoch: 5| Step: 9
Training loss: 0.4119319081680056
Validation loss: 2.783323397352183

Epoch: 5| Step: 10
Training loss: 0.46183981107119665
Validation loss: 2.816255950797282

Epoch: 5| Step: 11
Training loss: 0.3616658050479968
Validation loss: 2.7978104105126045

Epoch: 309| Step: 0
Training loss: 0.4455582124865253
Validation loss: 2.7274278216743215

Epoch: 5| Step: 1
Training loss: 0.7102203105238478
Validation loss: 2.7678317014635385

Epoch: 5| Step: 2
Training loss: 0.5132783027459799
Validation loss: 2.786517972694151

Epoch: 5| Step: 3
Training loss: 0.5004301009438117
Validation loss: 2.7712654258477643

Epoch: 5| Step: 4
Training loss: 0.4898288919242738
Validation loss: 2.746223889772118

Epoch: 5| Step: 5
Training loss: 0.5857528649934525
Validation loss: 2.7574078422391426

Epoch: 5| Step: 6
Training loss: 0.343390992567417
Validation loss: 2.78756539762729

Epoch: 5| Step: 7
Training loss: 0.39707352411310126
Validation loss: 2.728183526791047

Epoch: 5| Step: 8
Training loss: 0.4790333652284149
Validation loss: 2.7472296943269363

Epoch: 5| Step: 9
Training loss: 0.39244221474551855
Validation loss: 2.7302765639908695

Epoch: 5| Step: 10
Training loss: 0.7064846518280928
Validation loss: 2.728367318355539

Epoch: 5| Step: 11
Training loss: 0.2221371136712698
Validation loss: 2.7850646030208663

Epoch: 310| Step: 0
Training loss: 0.41802856872889566
Validation loss: 2.7567285203067784

Epoch: 5| Step: 1
Training loss: 0.6270640147413393
Validation loss: 2.794167548999672

Epoch: 5| Step: 2
Training loss: 0.525791653307719
Validation loss: 2.7264801530326106

Epoch: 5| Step: 3
Training loss: 0.7601111246733019
Validation loss: 2.8122250493192116

Epoch: 5| Step: 4
Training loss: 0.5142612919325714
Validation loss: 2.7917554518592125

Epoch: 5| Step: 5
Training loss: 0.6841577002030312
Validation loss: 2.7996711641460905

Epoch: 5| Step: 6
Training loss: 0.3878406089045093
Validation loss: 2.7861837352792658

Epoch: 5| Step: 7
Training loss: 0.3176347759435813
Validation loss: 2.7673329900070356

Epoch: 5| Step: 8
Training loss: 0.688855763430677
Validation loss: 2.7999423130371284

Epoch: 5| Step: 9
Training loss: 0.34805828593821986
Validation loss: 2.8011142598358116

Epoch: 5| Step: 10
Training loss: 0.6228912541831129
Validation loss: 2.8537648166378236

Epoch: 5| Step: 11
Training loss: 0.26268535722779374
Validation loss: 2.807236100580537

Epoch: 311| Step: 0
Training loss: 0.4640083018035028
Validation loss: 2.78691433476067

Epoch: 5| Step: 1
Training loss: 0.40444777616515987
Validation loss: 2.770376016527333

Epoch: 5| Step: 2
Training loss: 0.6259299036213533
Validation loss: 2.8083619546893885

Epoch: 5| Step: 3
Training loss: 0.4786578531454463
Validation loss: 2.8056553133350013

Epoch: 5| Step: 4
Training loss: 0.6959015140899049
Validation loss: 2.7666939862369335

Epoch: 5| Step: 5
Training loss: 0.3359045300827831
Validation loss: 2.7477458037923195

Epoch: 5| Step: 6
Training loss: 0.5373029602755175
Validation loss: 2.7642644635544573

Epoch: 5| Step: 7
Training loss: 0.5515577645679389
Validation loss: 2.77555862408666

Epoch: 5| Step: 8
Training loss: 0.48659416183915805
Validation loss: 2.8167571097493274

Epoch: 5| Step: 9
Training loss: 0.4847111151062417
Validation loss: 2.8280912752055056

Epoch: 5| Step: 10
Training loss: 0.46626247956906963
Validation loss: 2.8558620698624186

Epoch: 5| Step: 11
Training loss: 0.8144725184338614
Validation loss: 2.756949854465646

Epoch: 312| Step: 0
Training loss: 0.595837937406167
Validation loss: 2.82085333558339

Epoch: 5| Step: 1
Training loss: 0.5072394438801925
Validation loss: 2.7940832159806566

Epoch: 5| Step: 2
Training loss: 0.5926795143491346
Validation loss: 2.8301016782662884

Epoch: 5| Step: 3
Training loss: 0.5909393947173537
Validation loss: 2.8632085113514973

Epoch: 5| Step: 4
Training loss: 0.5457260050581617
Validation loss: 2.7929521395671753

Epoch: 5| Step: 5
Training loss: 0.5097534938260352
Validation loss: 2.7925913842564527

Epoch: 5| Step: 6
Training loss: 0.3829976432107768
Validation loss: 2.7861224866359944

Epoch: 5| Step: 7
Training loss: 0.8376888574630348
Validation loss: 2.7868022468790814

Epoch: 5| Step: 8
Training loss: 0.6287345414887282
Validation loss: 2.847191272479509

Epoch: 5| Step: 9
Training loss: 0.6551550404314357
Validation loss: 2.755799307057026

Epoch: 5| Step: 10
Training loss: 0.5155947127261272
Validation loss: 2.7893221580246252

Epoch: 5| Step: 11
Training loss: 0.4334216764459176
Validation loss: 2.7525476698309

Epoch: 313| Step: 0
Training loss: 0.45785057768802456
Validation loss: 2.7816284990111098

Epoch: 5| Step: 1
Training loss: 0.6070034388942809
Validation loss: 2.7946383130036456

Epoch: 5| Step: 2
Training loss: 0.5002122964772181
Validation loss: 2.8353390618344965

Epoch: 5| Step: 3
Training loss: 0.5010711996953667
Validation loss: 2.8127728365203146

Epoch: 5| Step: 4
Training loss: 0.5313025616841637
Validation loss: 2.8389614611407565

Epoch: 5| Step: 5
Training loss: 0.38617409778212247
Validation loss: 2.737949810203849

Epoch: 5| Step: 6
Training loss: 0.8107873766644287
Validation loss: 2.798245273692316

Epoch: 5| Step: 7
Training loss: 0.5287514159902816
Validation loss: 2.7314352690669255

Epoch: 5| Step: 8
Training loss: 0.5475706036214816
Validation loss: 2.725943900529428

Epoch: 5| Step: 9
Training loss: 0.5679091672852322
Validation loss: 2.7553762097524994

Epoch: 5| Step: 10
Training loss: 0.6067412018532963
Validation loss: 2.7673006279809442

Epoch: 5| Step: 11
Training loss: 0.5862956160670171
Validation loss: 2.7902645366686394

Epoch: 314| Step: 0
Training loss: 0.33420684721921906
Validation loss: 2.7989286594121636

Epoch: 5| Step: 1
Training loss: 0.5152463389548401
Validation loss: 2.7714895221930345

Epoch: 5| Step: 2
Training loss: 0.589759896488442
Validation loss: 2.786826779020435

Epoch: 5| Step: 3
Training loss: 0.4042282230489585
Validation loss: 2.740459883300153

Epoch: 5| Step: 4
Training loss: 0.5689360062911574
Validation loss: 2.8855107609983293

Epoch: 5| Step: 5
Training loss: 0.8006607709363713
Validation loss: 2.8658954071929172

Epoch: 5| Step: 6
Training loss: 0.5296838338269315
Validation loss: 2.7157874244254105

Epoch: 5| Step: 7
Training loss: 0.6357269519673782
Validation loss: 2.726240665566149

Epoch: 5| Step: 8
Training loss: 0.442414036337302
Validation loss: 2.7298194611708495

Epoch: 5| Step: 9
Training loss: 0.5062150036524666
Validation loss: 2.8434014788001076

Epoch: 5| Step: 10
Training loss: 0.5420700704617065
Validation loss: 2.750308861149448

Epoch: 5| Step: 11
Training loss: 0.6653672807393699
Validation loss: 2.8074218611290167

Epoch: 315| Step: 0
Training loss: 0.5319569596056998
Validation loss: 2.839668761769069

Epoch: 5| Step: 1
Training loss: 0.5377774055020346
Validation loss: 2.7228044736806565

Epoch: 5| Step: 2
Training loss: 0.5282094278511049
Validation loss: 2.829049547652401

Epoch: 5| Step: 3
Training loss: 0.39601154038562936
Validation loss: 2.8604033033406577

Epoch: 5| Step: 4
Training loss: 0.6538419593918152
Validation loss: 2.7872312180980083

Epoch: 5| Step: 5
Training loss: 0.40317980002006354
Validation loss: 2.805269097794905

Epoch: 5| Step: 6
Training loss: 0.36430518121021843
Validation loss: 2.7779339155713765

Epoch: 5| Step: 7
Training loss: 0.4722485794007647
Validation loss: 2.779159202927876

Epoch: 5| Step: 8
Training loss: 0.7156295209850113
Validation loss: 2.751881327977393

Epoch: 5| Step: 9
Training loss: 0.6233196080153581
Validation loss: 2.7422194646582616

Epoch: 5| Step: 10
Training loss: 0.4758193209094219
Validation loss: 2.8051452812128117

Epoch: 5| Step: 11
Training loss: 0.35915274589022084
Validation loss: 2.8004540501022346

Epoch: 316| Step: 0
Training loss: 0.5931392841608845
Validation loss: 2.757759994280775

Epoch: 5| Step: 1
Training loss: 0.6906974952933457
Validation loss: 2.791152085851713

Epoch: 5| Step: 2
Training loss: 0.4561179891106563
Validation loss: 2.804835444013369

Epoch: 5| Step: 3
Training loss: 0.3865678666281183
Validation loss: 2.753894244950193

Epoch: 5| Step: 4
Training loss: 0.5231894004768121
Validation loss: 2.7532827586866295

Epoch: 5| Step: 5
Training loss: 0.4509989089022208
Validation loss: 2.78072664072956

Epoch: 5| Step: 6
Training loss: 0.5589532828864086
Validation loss: 2.8458955202713194

Epoch: 5| Step: 7
Training loss: 0.48822700199140806
Validation loss: 2.7481284708951574

Epoch: 5| Step: 8
Training loss: 0.45737173976815265
Validation loss: 2.7258636868869623

Epoch: 5| Step: 9
Training loss: 0.37829910872735334
Validation loss: 2.8389671578403926

Epoch: 5| Step: 10
Training loss: 0.5056865500013465
Validation loss: 2.757321177979073

Epoch: 5| Step: 11
Training loss: 0.3096047752283179
Validation loss: 2.8170519091798116

Epoch: 317| Step: 0
Training loss: 0.38846390877623
Validation loss: 2.7725603713527622

Epoch: 5| Step: 1
Training loss: 0.4799232953345699
Validation loss: 2.7482489552469995

Epoch: 5| Step: 2
Training loss: 0.6033314297270206
Validation loss: 2.8114196609790336

Epoch: 5| Step: 3
Training loss: 0.684101853229838
Validation loss: 2.8573602829242417

Epoch: 5| Step: 4
Training loss: 0.4144119731236616
Validation loss: 2.7726043112296965

Epoch: 5| Step: 5
Training loss: 0.47980245275240213
Validation loss: 2.7972449265816817

Epoch: 5| Step: 6
Training loss: 0.6323707828535692
Validation loss: 2.756783899655497

Epoch: 5| Step: 7
Training loss: 0.45974318093848177
Validation loss: 2.7696534216387305

Epoch: 5| Step: 8
Training loss: 0.5097569432012589
Validation loss: 2.769127483195929

Epoch: 5| Step: 9
Training loss: 0.3355955335088529
Validation loss: 2.8163229814936575

Epoch: 5| Step: 10
Training loss: 0.36557207458083163
Validation loss: 2.853911681978932

Epoch: 5| Step: 11
Training loss: 1.028391488737468
Validation loss: 2.8273286769690382

Epoch: 318| Step: 0
Training loss: 0.5898991994499598
Validation loss: 2.739206840598481

Epoch: 5| Step: 1
Training loss: 0.6096425080623612
Validation loss: 2.776674450199015

Epoch: 5| Step: 2
Training loss: 0.6007309405192228
Validation loss: 2.88240077275571

Epoch: 5| Step: 3
Training loss: 0.8375097445020716
Validation loss: 2.8369321348716614

Epoch: 5| Step: 4
Training loss: 0.5715549991171791
Validation loss: 2.8041346402675176

Epoch: 5| Step: 5
Training loss: 0.5017943669267907
Validation loss: 2.775010034754941

Epoch: 5| Step: 6
Training loss: 0.3974232948717295
Validation loss: 2.820813082636874

Epoch: 5| Step: 7
Training loss: 0.5590417572574504
Validation loss: 2.8109781209665763

Epoch: 5| Step: 8
Training loss: 0.5307754191970265
Validation loss: 2.7157271231005824

Epoch: 5| Step: 9
Training loss: 0.6500097081486436
Validation loss: 2.7817429345027107

Epoch: 5| Step: 10
Training loss: 0.5019119780184931
Validation loss: 2.8355761806642854

Epoch: 5| Step: 11
Training loss: 0.29838129682732495
Validation loss: 2.7977690342242667

Epoch: 319| Step: 0
Training loss: 0.447983428134485
Validation loss: 2.8058313748513632

Epoch: 5| Step: 1
Training loss: 0.46140553263483497
Validation loss: 2.7416732030479487

Epoch: 5| Step: 2
Training loss: 0.3966236715429776
Validation loss: 2.7936374744053305

Epoch: 5| Step: 3
Training loss: 0.4938270267328917
Validation loss: 2.846087675657936

Epoch: 5| Step: 4
Training loss: 0.8303965956167949
Validation loss: 2.7721661156417374

Epoch: 5| Step: 5
Training loss: 0.4535324960966306
Validation loss: 2.7329331765594858

Epoch: 5| Step: 6
Training loss: 0.4801612428206338
Validation loss: 2.7716457220510695

Epoch: 5| Step: 7
Training loss: 0.6151041044342328
Validation loss: 2.7808581694146537

Epoch: 5| Step: 8
Training loss: 0.5040775569740997
Validation loss: 2.8131770519963104

Epoch: 5| Step: 9
Training loss: 0.4870321394588216
Validation loss: 2.7661219507784667

Epoch: 5| Step: 10
Training loss: 0.4770169983130298
Validation loss: 2.7403966955758663

Epoch: 5| Step: 11
Training loss: 0.46780685273598877
Validation loss: 2.791991031126566

Epoch: 320| Step: 0
Training loss: 0.37675012053631407
Validation loss: 2.7503731810346124

Epoch: 5| Step: 1
Training loss: 0.4598362261577579
Validation loss: 2.7853595325960563

Epoch: 5| Step: 2
Training loss: 0.6247335342765264
Validation loss: 2.7869802907106065

Epoch: 5| Step: 3
Training loss: 0.4216736736990747
Validation loss: 2.7503402672843857

Epoch: 5| Step: 4
Training loss: 0.5327694984601995
Validation loss: 2.8130706985160807

Epoch: 5| Step: 5
Training loss: 0.6446733491484503
Validation loss: 2.727013471411348

Epoch: 5| Step: 6
Training loss: 0.6379911662360149
Validation loss: 2.750729727738799

Epoch: 5| Step: 7
Training loss: 0.4571138291051481
Validation loss: 2.83564901504734

Epoch: 5| Step: 8
Training loss: 0.4185132553093314
Validation loss: 2.8186067722412433

Epoch: 5| Step: 9
Training loss: 0.5578830973511699
Validation loss: 2.7195346693809936

Epoch: 5| Step: 10
Training loss: 0.6788768538068853
Validation loss: 2.7136230944657647

Epoch: 5| Step: 11
Training loss: 0.5781533517844781
Validation loss: 2.78630500561747

Epoch: 321| Step: 0
Training loss: 0.528657083125438
Validation loss: 2.742241484861438

Epoch: 5| Step: 1
Training loss: 0.5173352229349703
Validation loss: 2.761618271096507

Epoch: 5| Step: 2
Training loss: 0.3728339501323097
Validation loss: 2.807447883255836

Epoch: 5| Step: 3
Training loss: 0.35501218126781736
Validation loss: 2.838709948156544

Epoch: 5| Step: 4
Training loss: 0.483608962945965
Validation loss: 2.7885144262416626

Epoch: 5| Step: 5
Training loss: 0.5233382515261105
Validation loss: 2.7699217527747515

Epoch: 5| Step: 6
Training loss: 0.3579704369214262
Validation loss: 2.7378775951663066

Epoch: 5| Step: 7
Training loss: 0.8648733931701703
Validation loss: 2.7617641483012507

Epoch: 5| Step: 8
Training loss: 0.3895525706822208
Validation loss: 2.7446622450040636

Epoch: 5| Step: 9
Training loss: 0.5108403536400778
Validation loss: 2.772516790877493

Epoch: 5| Step: 10
Training loss: 0.34821888048158767
Validation loss: 2.7764648105464396

Epoch: 5| Step: 11
Training loss: 0.7715163598492353
Validation loss: 2.7581681156426257

Epoch: 322| Step: 0
Training loss: 0.5674257245800473
Validation loss: 2.762271823924472

Epoch: 5| Step: 1
Training loss: 0.42469735379046986
Validation loss: 2.766660421050349

Epoch: 5| Step: 2
Training loss: 0.502845623805392
Validation loss: 2.782952098568522

Epoch: 5| Step: 3
Training loss: 0.7284535235815471
Validation loss: 2.8378760627780775

Epoch: 5| Step: 4
Training loss: 0.5400277769485773
Validation loss: 2.7790645699761605

Epoch: 5| Step: 5
Training loss: 0.49943271881094903
Validation loss: 2.733537872781256

Epoch: 5| Step: 6
Training loss: 0.4236899823190484
Validation loss: 2.7177099123845765

Epoch: 5| Step: 7
Training loss: 0.5702395457806688
Validation loss: 2.756045473314173

Epoch: 5| Step: 8
Training loss: 0.689231988385797
Validation loss: 2.734160819975107

Epoch: 5| Step: 9
Training loss: 0.5019139671637324
Validation loss: 2.8107441366149732

Epoch: 5| Step: 10
Training loss: 0.5686039611369149
Validation loss: 2.831672645753008

Epoch: 5| Step: 11
Training loss: 0.462021119693958
Validation loss: 2.783980779144604

Epoch: 323| Step: 0
Training loss: 0.5255012821105648
Validation loss: 2.7330451165479053

Epoch: 5| Step: 1
Training loss: 0.3778714472723244
Validation loss: 2.7159112235861738

Epoch: 5| Step: 2
Training loss: 0.5156577995734284
Validation loss: 2.7943086802303565

Epoch: 5| Step: 3
Training loss: 0.5068637788802876
Validation loss: 2.784444171318898

Epoch: 5| Step: 4
Training loss: 0.4179249321616838
Validation loss: 2.795456965469625

Epoch: 5| Step: 5
Training loss: 0.7032212933194854
Validation loss: 2.7993167930650222

Epoch: 5| Step: 6
Training loss: 0.6548736762761388
Validation loss: 2.830082912892955

Epoch: 5| Step: 7
Training loss: 0.5389811689417223
Validation loss: 2.767373462648374

Epoch: 5| Step: 8
Training loss: 0.3293026273141281
Validation loss: 2.7566996914704727

Epoch: 5| Step: 9
Training loss: 0.7497659953956051
Validation loss: 2.7051241103026693

Epoch: 5| Step: 10
Training loss: 0.7322473343461716
Validation loss: 2.7726086125599334

Epoch: 5| Step: 11
Training loss: 0.4634061107950415
Validation loss: 2.859603896993738

Epoch: 324| Step: 0
Training loss: 0.40064969868931305
Validation loss: 2.716870846028147

Epoch: 5| Step: 1
Training loss: 0.4220672805020557
Validation loss: 2.8386019055802008

Epoch: 5| Step: 2
Training loss: 0.5528488310266186
Validation loss: 2.8694494023720805

Epoch: 5| Step: 3
Training loss: 0.3818784919304407
Validation loss: 2.82405128175945

Epoch: 5| Step: 4
Training loss: 0.38267039561420857
Validation loss: 2.7672951894003135

Epoch: 5| Step: 5
Training loss: 0.39123537060623004
Validation loss: 2.766449534176241

Epoch: 5| Step: 6
Training loss: 0.3705620419838337
Validation loss: 2.814789867705946

Epoch: 5| Step: 7
Training loss: 0.48582312780406317
Validation loss: 2.7843827952152025

Epoch: 5| Step: 8
Training loss: 0.6342571863226676
Validation loss: 2.7813465462404237

Epoch: 5| Step: 9
Training loss: 0.5689436802839025
Validation loss: 2.838896767106004

Epoch: 5| Step: 10
Training loss: 0.512364947737627
Validation loss: 2.819645539494759

Epoch: 5| Step: 11
Training loss: 0.31559699378068556
Validation loss: 2.77503741685884

Epoch: 325| Step: 0
Training loss: 0.3160211315076083
Validation loss: 2.81968478564056

Epoch: 5| Step: 1
Training loss: 0.46277373886323986
Validation loss: 2.757502634797116

Epoch: 5| Step: 2
Training loss: 0.457944072525759
Validation loss: 2.7517628438127733

Epoch: 5| Step: 3
Training loss: 0.33753569378897397
Validation loss: 2.841572228080867

Epoch: 5| Step: 4
Training loss: 0.6482407604637426
Validation loss: 2.829385729348695

Epoch: 5| Step: 5
Training loss: 0.3554898559676277
Validation loss: 2.791826863935328

Epoch: 5| Step: 6
Training loss: 0.4454779401277432
Validation loss: 2.8313950413765427

Epoch: 5| Step: 7
Training loss: 0.6058155912200196
Validation loss: 2.802015964355253

Epoch: 5| Step: 8
Training loss: 0.4401104228761965
Validation loss: 2.8243984694609154

Epoch: 5| Step: 9
Training loss: 0.41378353726322625
Validation loss: 2.8017015421586082

Epoch: 5| Step: 10
Training loss: 0.7005558761472755
Validation loss: 2.8388101899879565

Epoch: 5| Step: 11
Training loss: 0.21222767279657662
Validation loss: 2.8271737404472272

Epoch: 326| Step: 0
Training loss: 0.3859431648610851
Validation loss: 2.776754049299626

Epoch: 5| Step: 1
Training loss: 0.5347335984174494
Validation loss: 2.770036967761881

Epoch: 5| Step: 2
Training loss: 0.28656002609366493
Validation loss: 2.766134283441157

Epoch: 5| Step: 3
Training loss: 0.44645001870816536
Validation loss: 2.7770156523481253

Epoch: 5| Step: 4
Training loss: 0.4275170388088743
Validation loss: 2.8563190417080397

Epoch: 5| Step: 5
Training loss: 0.5338377197957601
Validation loss: 2.7875539402382885

Epoch: 5| Step: 6
Training loss: 0.511767814555376
Validation loss: 2.8114192581617856

Epoch: 5| Step: 7
Training loss: 0.5670261805190279
Validation loss: 2.766058774648457

Epoch: 5| Step: 8
Training loss: 0.5874382128588924
Validation loss: 2.766322426943116

Epoch: 5| Step: 9
Training loss: 0.3982651094478731
Validation loss: 2.7501702111482613

Epoch: 5| Step: 10
Training loss: 0.724808493346962
Validation loss: 2.8199074226203154

Epoch: 5| Step: 11
Training loss: 0.6934472471620562
Validation loss: 2.796939813583938

Epoch: 327| Step: 0
Training loss: 0.5348052384254783
Validation loss: 2.8289312404233535

Epoch: 5| Step: 1
Training loss: 0.7274617198822513
Validation loss: 2.7623007348633877

Epoch: 5| Step: 2
Training loss: 0.31858886451211954
Validation loss: 2.785702887594452

Epoch: 5| Step: 3
Training loss: 0.5459169988598679
Validation loss: 2.8232980355582504

Epoch: 5| Step: 4
Training loss: 0.5507236748220667
Validation loss: 2.7133005709939155

Epoch: 5| Step: 5
Training loss: 0.5394604913759672
Validation loss: 2.804963731400941

Epoch: 5| Step: 6
Training loss: 0.5251358151737552
Validation loss: 2.811718715658185

Epoch: 5| Step: 7
Training loss: 0.5922412274227437
Validation loss: 2.8341825675761325

Epoch: 5| Step: 8
Training loss: 0.4794723289091138
Validation loss: 2.726490289411398

Epoch: 5| Step: 9
Training loss: 0.32971619621244513
Validation loss: 2.822593368982827

Epoch: 5| Step: 10
Training loss: 0.5697576881147753
Validation loss: 2.732076930790572

Epoch: 5| Step: 11
Training loss: 0.398704532823373
Validation loss: 2.872312326102193

Epoch: 328| Step: 0
Training loss: 0.5347223123602632
Validation loss: 2.8418157203285417

Epoch: 5| Step: 1
Training loss: 0.3661703061769548
Validation loss: 2.823530856434349

Epoch: 5| Step: 2
Training loss: 0.42268717259585153
Validation loss: 2.8402879237299747

Epoch: 5| Step: 3
Training loss: 0.4650776539073976
Validation loss: 2.813030039327204

Epoch: 5| Step: 4
Training loss: 0.5107018653605501
Validation loss: 2.783544825943797

Epoch: 5| Step: 5
Training loss: 0.5580731346662781
Validation loss: 2.785638893115049

Epoch: 5| Step: 6
Training loss: 0.4745972243272463
Validation loss: 2.7612963996029225

Epoch: 5| Step: 7
Training loss: 0.7745083033594984
Validation loss: 2.8216114346366794

Epoch: 5| Step: 8
Training loss: 0.445476000033401
Validation loss: 2.779066811263727

Epoch: 5| Step: 9
Training loss: 0.5474897471648029
Validation loss: 2.7685121599145868

Epoch: 5| Step: 10
Training loss: 0.3327398704474467
Validation loss: 2.837557604004768

Epoch: 5| Step: 11
Training loss: 0.19211789592013367
Validation loss: 2.791486984610002

Epoch: 329| Step: 0
Training loss: 0.5145296832030971
Validation loss: 2.7888458766212527

Epoch: 5| Step: 1
Training loss: 0.7036378050110131
Validation loss: 2.807418641077517

Epoch: 5| Step: 2
Training loss: 0.486268633532022
Validation loss: 2.7863973604940826

Epoch: 5| Step: 3
Training loss: 0.3921354274451665
Validation loss: 2.792569503169682

Epoch: 5| Step: 4
Training loss: 0.4664340185081224
Validation loss: 2.808153163005408

Epoch: 5| Step: 5
Training loss: 0.43414337102417305
Validation loss: 2.7539335822153648

Epoch: 5| Step: 6
Training loss: 0.49675676390559786
Validation loss: 2.797420302924253

Epoch: 5| Step: 7
Training loss: 0.5641219543655446
Validation loss: 2.785663439067714

Epoch: 5| Step: 8
Training loss: 0.5857716643576081
Validation loss: 2.8083561340042227

Epoch: 5| Step: 9
Training loss: 0.48877123852411614
Validation loss: 2.788841997507444

Epoch: 5| Step: 10
Training loss: 0.49987096909740986
Validation loss: 2.771949440502369

Epoch: 5| Step: 11
Training loss: 0.3531719876988611
Validation loss: 2.7310744029090097

Epoch: 330| Step: 0
Training loss: 0.4330945104956616
Validation loss: 2.769786796025162

Epoch: 5| Step: 1
Training loss: 0.4315893393035603
Validation loss: 2.831723816068357

Epoch: 5| Step: 2
Training loss: 0.5745514405463295
Validation loss: 2.7892304840932343

Epoch: 5| Step: 3
Training loss: 0.5816262391349993
Validation loss: 2.783224026785549

Epoch: 5| Step: 4
Training loss: 0.4565697320447572
Validation loss: 2.8120732513494193

Epoch: 5| Step: 5
Training loss: 0.4473736062114755
Validation loss: 2.8729982663729277

Epoch: 5| Step: 6
Training loss: 0.45972092961395006
Validation loss: 2.807688687948259

Epoch: 5| Step: 7
Training loss: 0.48189987482072066
Validation loss: 2.804615839801593

Epoch: 5| Step: 8
Training loss: 0.6209165212296311
Validation loss: 2.7320913060777707

Epoch: 5| Step: 9
Training loss: 0.3506642734917474
Validation loss: 2.7480449554501725

Epoch: 5| Step: 10
Training loss: 0.44413112069917443
Validation loss: 2.769462731665668

Epoch: 5| Step: 11
Training loss: 0.21323720910472718
Validation loss: 2.782944505956559

Epoch: 331| Step: 0
Training loss: 0.4957603926528744
Validation loss: 2.747449342227678

Epoch: 5| Step: 1
Training loss: 0.5466078514446676
Validation loss: 2.800009908119337

Epoch: 5| Step: 2
Training loss: 0.3463078936401471
Validation loss: 2.7478975817143176

Epoch: 5| Step: 3
Training loss: 0.5169031312199336
Validation loss: 2.8087901231134946

Epoch: 5| Step: 4
Training loss: 0.5547164855690755
Validation loss: 2.829813669089171

Epoch: 5| Step: 5
Training loss: 0.4264031514313454
Validation loss: 2.799305767041548

Epoch: 5| Step: 6
Training loss: 0.45179316031525046
Validation loss: 2.7907119596459005

Epoch: 5| Step: 7
Training loss: 0.25217986439203194
Validation loss: 2.7618175095053887

Epoch: 5| Step: 8
Training loss: 0.5484293510505428
Validation loss: 2.7953710028559198

Epoch: 5| Step: 9
Training loss: 0.6225050719946936
Validation loss: 2.839342785864614

Epoch: 5| Step: 10
Training loss: 0.4144767272729154
Validation loss: 2.831545800005186

Epoch: 5| Step: 11
Training loss: 0.45228535039641987
Validation loss: 2.748489481608071

Epoch: 332| Step: 0
Training loss: 0.2874667350556604
Validation loss: 2.7942705157381407

Epoch: 5| Step: 1
Training loss: 0.4749987382621069
Validation loss: 2.749880520797143

Epoch: 5| Step: 2
Training loss: 0.45518913061228855
Validation loss: 2.738364916297365

Epoch: 5| Step: 3
Training loss: 0.580216721954064
Validation loss: 2.799109995549289

Epoch: 5| Step: 4
Training loss: 0.33914052619220847
Validation loss: 2.7914642407678185

Epoch: 5| Step: 5
Training loss: 0.3716501582047459
Validation loss: 2.8107153387172175

Epoch: 5| Step: 6
Training loss: 0.3227754548189937
Validation loss: 2.735732535384729

Epoch: 5| Step: 7
Training loss: 0.63790665727267
Validation loss: 2.817708504912441

Epoch: 5| Step: 8
Training loss: 0.5602136877770373
Validation loss: 2.806901421018763

Epoch: 5| Step: 9
Training loss: 0.45143606864494196
Validation loss: 2.8056825663098817

Epoch: 5| Step: 10
Training loss: 0.45973078321026134
Validation loss: 2.849199744508863

Epoch: 5| Step: 11
Training loss: 0.13261668411631267
Validation loss: 2.77736902024245

Epoch: 333| Step: 0
Training loss: 0.3558467699450221
Validation loss: 2.865639080510825

Epoch: 5| Step: 1
Training loss: 0.2800665034991448
Validation loss: 2.8356416528689383

Epoch: 5| Step: 2
Training loss: 0.2888205262954954
Validation loss: 2.7675538422051607

Epoch: 5| Step: 3
Training loss: 0.5344700834664375
Validation loss: 2.793179124854181

Epoch: 5| Step: 4
Training loss: 0.33073435676687474
Validation loss: 2.814538308909877

Epoch: 5| Step: 5
Training loss: 0.48590355843498906
Validation loss: 2.768647437137098

Epoch: 5| Step: 6
Training loss: 0.6713522274521037
Validation loss: 2.7725955347755002

Epoch: 5| Step: 7
Training loss: 0.3207362442478761
Validation loss: 2.8228279512736263

Epoch: 5| Step: 8
Training loss: 0.3179483978918894
Validation loss: 2.8350510415915733

Epoch: 5| Step: 9
Training loss: 0.425468907715218
Validation loss: 2.8712010473845444

Epoch: 5| Step: 10
Training loss: 0.4486578881609198
Validation loss: 2.795502988559329

Epoch: 5| Step: 11
Training loss: 0.6276937608096117
Validation loss: 2.7824789468129305

Epoch: 334| Step: 0
Training loss: 0.4741925422427526
Validation loss: 2.815659704922409

Epoch: 5| Step: 1
Training loss: 0.463203002857611
Validation loss: 2.837888713712633

Epoch: 5| Step: 2
Training loss: 0.45764830903118375
Validation loss: 2.7680056647109996

Epoch: 5| Step: 3
Training loss: 0.48559044038693105
Validation loss: 2.7537546824056003

Epoch: 5| Step: 4
Training loss: 0.4177382716091151
Validation loss: 2.801107468310337

Epoch: 5| Step: 5
Training loss: 0.330750925244445
Validation loss: 2.8244459413467284

Epoch: 5| Step: 6
Training loss: 0.40236921137271925
Validation loss: 2.7747139370880367

Epoch: 5| Step: 7
Training loss: 0.3514390834770641
Validation loss: 2.84125536886106

Epoch: 5| Step: 8
Training loss: 0.5628519546599554
Validation loss: 2.803871159950874

Epoch: 5| Step: 9
Training loss: 0.6933347455875367
Validation loss: 2.8296622775277416

Epoch: 5| Step: 10
Training loss: 0.4523447158618689
Validation loss: 2.8197597585469163

Epoch: 5| Step: 11
Training loss: 0.2886682347544337
Validation loss: 2.7498743686011458

Epoch: 335| Step: 0
Training loss: 0.48818353819689403
Validation loss: 2.7909826940111353

Epoch: 5| Step: 1
Training loss: 0.30512630214124203
Validation loss: 2.793642644789468

Epoch: 5| Step: 2
Training loss: 0.41161035996602213
Validation loss: 2.8548169033465527

Epoch: 5| Step: 3
Training loss: 0.3096440585411356
Validation loss: 2.81606357657283

Epoch: 5| Step: 4
Training loss: 0.4350108624614796
Validation loss: 2.775061243973748

Epoch: 5| Step: 5
Training loss: 0.5294862809479698
Validation loss: 2.7437186318286573

Epoch: 5| Step: 6
Training loss: 0.4210289666445125
Validation loss: 2.779754904747628

Epoch: 5| Step: 7
Training loss: 0.40624785422712123
Validation loss: 2.7663071001367783

Epoch: 5| Step: 8
Training loss: 0.511251658644469
Validation loss: 2.7500951056940828

Epoch: 5| Step: 9
Training loss: 0.6637951032037845
Validation loss: 2.7821374970204964

Epoch: 5| Step: 10
Training loss: 0.3255186220729745
Validation loss: 2.837915338599843

Epoch: 5| Step: 11
Training loss: 0.33232189248274385
Validation loss: 2.8019737460937013

Epoch: 336| Step: 0
Training loss: 0.5986978766225763
Validation loss: 2.8505685127704137

Epoch: 5| Step: 1
Training loss: 0.3820933184294862
Validation loss: 2.8162107254283275

Epoch: 5| Step: 2
Training loss: 0.28836563239986024
Validation loss: 2.842519895813314

Epoch: 5| Step: 3
Training loss: 0.3465784596688825
Validation loss: 2.7972106803189556

Epoch: 5| Step: 4
Training loss: 0.4214296816321706
Validation loss: 2.7601938385666474

Epoch: 5| Step: 5
Training loss: 0.3571327582702602
Validation loss: 2.7656741811398815

Epoch: 5| Step: 6
Training loss: 0.40947510609165705
Validation loss: 2.8321755243142417

Epoch: 5| Step: 7
Training loss: 0.5612014776295373
Validation loss: 2.7845749500321038

Epoch: 5| Step: 8
Training loss: 0.30565243537409353
Validation loss: 2.7263378644657537

Epoch: 5| Step: 9
Training loss: 0.47372647961832315
Validation loss: 2.7788770782624

Epoch: 5| Step: 10
Training loss: 0.543369776326606
Validation loss: 2.7698465265582306

Epoch: 5| Step: 11
Training loss: 0.2958803958239647
Validation loss: 2.793923986025318

Epoch: 337| Step: 0
Training loss: 0.387730997975155
Validation loss: 2.8310780396495696

Epoch: 5| Step: 1
Training loss: 0.4249807058891456
Validation loss: 2.7970681079427577

Epoch: 5| Step: 2
Training loss: 0.6495607138808935
Validation loss: 2.7505453392651003

Epoch: 5| Step: 3
Training loss: 0.44470581756845695
Validation loss: 2.8630273488686364

Epoch: 5| Step: 4
Training loss: 0.4705739140741882
Validation loss: 2.7338416714757305

Epoch: 5| Step: 5
Training loss: 0.43657040610011794
Validation loss: 2.843676667438176

Epoch: 5| Step: 6
Training loss: 0.5733988091411538
Validation loss: 2.789119103691673

Epoch: 5| Step: 7
Training loss: 0.39142309674157644
Validation loss: 2.8392634999279323

Epoch: 5| Step: 8
Training loss: 0.4885067380959742
Validation loss: 2.792100564250445

Epoch: 5| Step: 9
Training loss: 0.40356000377420037
Validation loss: 2.739194089314928

Epoch: 5| Step: 10
Training loss: 0.38863665933993224
Validation loss: 2.83520945792272

Epoch: 5| Step: 11
Training loss: 0.6632727695457635
Validation loss: 2.7733509784509303

Epoch: 338| Step: 0
Training loss: 0.38165659485497383
Validation loss: 2.8199039984092087

Epoch: 5| Step: 1
Training loss: 0.45031839206713786
Validation loss: 2.800021410332293

Epoch: 5| Step: 2
Training loss: 0.6924000941004322
Validation loss: 2.789620864497936

Epoch: 5| Step: 3
Training loss: 0.41297839052087965
Validation loss: 2.835858651318239

Epoch: 5| Step: 4
Training loss: 0.4151474037132413
Validation loss: 2.80631241265257

Epoch: 5| Step: 5
Training loss: 0.4590334277623673
Validation loss: 2.8491151732813913

Epoch: 5| Step: 6
Training loss: 0.5263716886819805
Validation loss: 2.781290025458771

Epoch: 5| Step: 7
Training loss: 0.3112705603476799
Validation loss: 2.826088219322605

Epoch: 5| Step: 8
Training loss: 0.474804653605527
Validation loss: 2.843958291610402

Epoch: 5| Step: 9
Training loss: 0.36332499333019874
Validation loss: 2.7541128238910972

Epoch: 5| Step: 10
Training loss: 0.423952778710321
Validation loss: 2.800595219249541

Epoch: 5| Step: 11
Training loss: 0.2639370185618218
Validation loss: 2.7726811591052662

Epoch: 339| Step: 0
Training loss: 0.35487229746817067
Validation loss: 2.8253863793419485

Epoch: 5| Step: 1
Training loss: 0.6071176533716944
Validation loss: 2.7845185215384762

Epoch: 5| Step: 2
Training loss: 0.4711240255771356
Validation loss: 2.809767144160923

Epoch: 5| Step: 3
Training loss: 0.48547168373520455
Validation loss: 2.821616405890768

Epoch: 5| Step: 4
Training loss: 0.4451712501438213
Validation loss: 2.8012250781819565

Epoch: 5| Step: 5
Training loss: 0.7018563587570015
Validation loss: 2.7358113104191126

Epoch: 5| Step: 6
Training loss: 0.4608746501940938
Validation loss: 2.8019262905618336

Epoch: 5| Step: 7
Training loss: 0.5771215597177823
Validation loss: 2.868016548420015

Epoch: 5| Step: 8
Training loss: 0.5123533434491753
Validation loss: 2.827723269092321

Epoch: 5| Step: 9
Training loss: 0.3567475383235204
Validation loss: 2.830534640836913

Epoch: 5| Step: 10
Training loss: 0.34909756454461277
Validation loss: 2.7256316642793474

Epoch: 5| Step: 11
Training loss: 0.27971357991189566
Validation loss: 2.7708547108525865

Epoch: 340| Step: 0
Training loss: 0.6171336573039308
Validation loss: 2.7603250824232566

Epoch: 5| Step: 1
Training loss: 0.37010249206839807
Validation loss: 2.792151531179219

Epoch: 5| Step: 2
Training loss: 0.3883353650397388
Validation loss: 2.804241481442382

Epoch: 5| Step: 3
Training loss: 0.460450157253567
Validation loss: 2.7836858212581648

Epoch: 5| Step: 4
Training loss: 0.5417449112157169
Validation loss: 2.8233367647216223

Epoch: 5| Step: 5
Training loss: 0.3506994568379484
Validation loss: 2.8335792467510243

Epoch: 5| Step: 6
Training loss: 0.41161959139910625
Validation loss: 2.7817583262501575

Epoch: 5| Step: 7
Training loss: 0.5082936575002881
Validation loss: 2.8173133334667297

Epoch: 5| Step: 8
Training loss: 0.4249806883575715
Validation loss: 2.8031211665881086

Epoch: 5| Step: 9
Training loss: 0.4414165461866951
Validation loss: 2.822050902614304

Epoch: 5| Step: 10
Training loss: 0.48006816384990053
Validation loss: 2.7511674360890948

Epoch: 5| Step: 11
Training loss: 0.19859970439505212
Validation loss: 2.7374320570470236

Epoch: 341| Step: 0
Training loss: 0.4362543970995866
Validation loss: 2.7846289193897418

Epoch: 5| Step: 1
Training loss: 0.48131291733691345
Validation loss: 2.756780688923272

Epoch: 5| Step: 2
Training loss: 0.3867827468476954
Validation loss: 2.76134659320316

Epoch: 5| Step: 3
Training loss: 0.4708508303297211
Validation loss: 2.821309403957629

Epoch: 5| Step: 4
Training loss: 0.4796389415405845
Validation loss: 2.7848573607243945

Epoch: 5| Step: 5
Training loss: 0.38906171790967414
Validation loss: 2.7850641749902256

Epoch: 5| Step: 6
Training loss: 0.5517832522308687
Validation loss: 2.772656684532214

Epoch: 5| Step: 7
Training loss: 0.5255149779231423
Validation loss: 2.8075277386113395

Epoch: 5| Step: 8
Training loss: 0.6766125411629565
Validation loss: 2.8387743140024444

Epoch: 5| Step: 9
Training loss: 0.5378448444683572
Validation loss: 2.684204798266408

Epoch: 5| Step: 10
Training loss: 0.41088742070679046
Validation loss: 2.7531174921228554

Epoch: 5| Step: 11
Training loss: 0.23935112204120354
Validation loss: 2.825527037629847

Epoch: 342| Step: 0
Training loss: 0.5053554956360208
Validation loss: 2.7934609519638927

Epoch: 5| Step: 1
Training loss: 0.5267138639962968
Validation loss: 2.8361685267313783

Epoch: 5| Step: 2
Training loss: 0.4072161336976789
Validation loss: 2.7364855840570335

Epoch: 5| Step: 3
Training loss: 0.31190626245729286
Validation loss: 2.7617829462384136

Epoch: 5| Step: 4
Training loss: 0.5750285037895432
Validation loss: 2.8684898505756924

Epoch: 5| Step: 5
Training loss: 0.2750918072561808
Validation loss: 2.8039147668204105

Epoch: 5| Step: 6
Training loss: 0.3388822480738375
Validation loss: 2.8046358045313866

Epoch: 5| Step: 7
Training loss: 0.6131001830838512
Validation loss: 2.8474525061317535

Epoch: 5| Step: 8
Training loss: 0.36932422976443535
Validation loss: 2.813641496648181

Epoch: 5| Step: 9
Training loss: 0.509606581391814
Validation loss: 2.739749632648237

Epoch: 5| Step: 10
Training loss: 0.49881611677396936
Validation loss: 2.834175014064811

Epoch: 5| Step: 11
Training loss: 0.324114219636308
Validation loss: 2.8117657197415786

Epoch: 343| Step: 0
Training loss: 0.3748772340728954
Validation loss: 2.7960371861754596

Epoch: 5| Step: 1
Training loss: 0.43573666188196025
Validation loss: 2.800965771699655

Epoch: 5| Step: 2
Training loss: 0.5255497120791577
Validation loss: 2.802929712592845

Epoch: 5| Step: 3
Training loss: 0.441467989764501
Validation loss: 2.7309472206467413

Epoch: 5| Step: 4
Training loss: 0.3555124276962628
Validation loss: 2.799007465928408

Epoch: 5| Step: 5
Training loss: 0.4118282932432106
Validation loss: 2.8064724299489527

Epoch: 5| Step: 6
Training loss: 0.41149614458143635
Validation loss: 2.7545058911993907

Epoch: 5| Step: 7
Training loss: 0.5072435272634821
Validation loss: 2.8072053132845074

Epoch: 5| Step: 8
Training loss: 0.6277492376632042
Validation loss: 2.7723081160767533

Epoch: 5| Step: 9
Training loss: 0.460278006929742
Validation loss: 2.750809340878425

Epoch: 5| Step: 10
Training loss: 0.607551855181801
Validation loss: 2.8628300080952327

Epoch: 5| Step: 11
Training loss: 0.314235315649713
Validation loss: 2.7851579584987656

Epoch: 344| Step: 0
Training loss: 0.3860205696065665
Validation loss: 2.8206687589519817

Epoch: 5| Step: 1
Training loss: 0.4324348013581813
Validation loss: 2.785948916540397

Epoch: 5| Step: 2
Training loss: 0.581262964698834
Validation loss: 2.832094529420551

Epoch: 5| Step: 3
Training loss: 0.383828682832101
Validation loss: 2.7629933776833635

Epoch: 5| Step: 4
Training loss: 0.5176333415969795
Validation loss: 2.775449526235831

Epoch: 5| Step: 5
Training loss: 0.4758633033892159
Validation loss: 2.8068590426509905

Epoch: 5| Step: 6
Training loss: 0.46058097887803406
Validation loss: 2.769651344898611

Epoch: 5| Step: 7
Training loss: 0.49065519410057346
Validation loss: 2.8392312545043352

Epoch: 5| Step: 8
Training loss: 0.383705790175583
Validation loss: 2.8697970275459594

Epoch: 5| Step: 9
Training loss: 0.4370497873443882
Validation loss: 2.8101733827497304

Epoch: 5| Step: 10
Training loss: 0.47927402420103793
Validation loss: 2.779043157903342

Epoch: 5| Step: 11
Training loss: 0.42662423354358603
Validation loss: 2.8235956544953935

Epoch: 345| Step: 0
Training loss: 0.421043264869527
Validation loss: 2.7738250390025647

Epoch: 5| Step: 1
Training loss: 0.5039153283062895
Validation loss: 2.785131467733034

Epoch: 5| Step: 2
Training loss: 0.5260553798839522
Validation loss: 2.882726139060388

Epoch: 5| Step: 3
Training loss: 0.5358965410423798
Validation loss: 2.8015641732467076

Epoch: 5| Step: 4
Training loss: 0.49686217681364464
Validation loss: 2.8166493748711545

Epoch: 5| Step: 5
Training loss: 0.43316011825913764
Validation loss: 2.834616368232243

Epoch: 5| Step: 6
Training loss: 0.29763885156841186
Validation loss: 2.7426924426271264

Epoch: 5| Step: 7
Training loss: 0.47996586169100225
Validation loss: 2.821151048685295

Epoch: 5| Step: 8
Training loss: 0.5308175851570911
Validation loss: 2.8344284505406163

Epoch: 5| Step: 9
Training loss: 0.7069662285512629
Validation loss: 2.80639691977147

Epoch: 5| Step: 10
Training loss: 0.5475802098050992
Validation loss: 2.7920809030420264

Epoch: 5| Step: 11
Training loss: 0.42480177604291447
Validation loss: 2.7276210132948107

Epoch: 346| Step: 0
Training loss: 0.406955180317666
Validation loss: 2.7845936011155956

Epoch: 5| Step: 1
Training loss: 0.4664413822303353
Validation loss: 2.7884224443073036

Epoch: 5| Step: 2
Training loss: 0.42760658968178183
Validation loss: 2.8272613625821643

Epoch: 5| Step: 3
Training loss: 0.4408786287215187
Validation loss: 2.831189572894344

Epoch: 5| Step: 4
Training loss: 0.4888616393167285
Validation loss: 2.7241043151386157

Epoch: 5| Step: 5
Training loss: 0.3187977984063113
Validation loss: 2.7611759844867763

Epoch: 5| Step: 6
Training loss: 0.5723664126646526
Validation loss: 2.7700039254429267

Epoch: 5| Step: 7
Training loss: 0.31373868066954724
Validation loss: 2.7760556180697638

Epoch: 5| Step: 8
Training loss: 0.3083148734370415
Validation loss: 2.7678205643711142

Epoch: 5| Step: 9
Training loss: 0.54983127455178
Validation loss: 2.8282561754748063

Epoch: 5| Step: 10
Training loss: 0.6905212557447009
Validation loss: 2.793639796456612

Epoch: 5| Step: 11
Training loss: 0.26973193064547035
Validation loss: 2.8133803402689606

Epoch: 347| Step: 0
Training loss: 0.4752040324447828
Validation loss: 2.779711194050876

Epoch: 5| Step: 1
Training loss: 0.6428524927319265
Validation loss: 2.8139494304686075

Epoch: 5| Step: 2
Training loss: 0.38301783523790206
Validation loss: 2.7961971058146444

Epoch: 5| Step: 3
Training loss: 0.3476072984157493
Validation loss: 2.82526926365155

Epoch: 5| Step: 4
Training loss: 0.40532546111642803
Validation loss: 2.8337426322400363

Epoch: 5| Step: 5
Training loss: 0.38408432103145435
Validation loss: 2.8115758119178738

Epoch: 5| Step: 6
Training loss: 0.559674504617506
Validation loss: 2.8626792798822334

Epoch: 5| Step: 7
Training loss: 0.43923003574068176
Validation loss: 2.8317745434403063

Epoch: 5| Step: 8
Training loss: 0.4525514129283656
Validation loss: 2.8302039519271287

Epoch: 5| Step: 9
Training loss: 0.37036394333340433
Validation loss: 2.7904961727489517

Epoch: 5| Step: 10
Training loss: 0.4059557032156212
Validation loss: 2.7958477982565197

Epoch: 5| Step: 11
Training loss: 0.2074877366785386
Validation loss: 2.7495620913512875

Epoch: 348| Step: 0
Training loss: 0.4080486826789981
Validation loss: 2.79534880413933

Epoch: 5| Step: 1
Training loss: 0.3999313697947226
Validation loss: 2.7613021270151195

Epoch: 5| Step: 2
Training loss: 0.35280569460229305
Validation loss: 2.835243325794086

Epoch: 5| Step: 3
Training loss: 0.37209666401619185
Validation loss: 2.797384744860237

Epoch: 5| Step: 4
Training loss: 0.42718181017509776
Validation loss: 2.795289202742835

Epoch: 5| Step: 5
Training loss: 0.5275973805037883
Validation loss: 2.8148254741209864

Epoch: 5| Step: 6
Training loss: 0.337616097826856
Validation loss: 2.832616064264364

Epoch: 5| Step: 7
Training loss: 0.4080815658999752
Validation loss: 2.6926238060872687

Epoch: 5| Step: 8
Training loss: 0.35279356205393064
Validation loss: 2.811674509056368

Epoch: 5| Step: 9
Training loss: 0.44164070721876375
Validation loss: 2.8757698230884277

Epoch: 5| Step: 10
Training loss: 0.6388901037282958
Validation loss: 2.8164250430089885

Epoch: 5| Step: 11
Training loss: 0.5628667536484521
Validation loss: 2.716602017700207

Epoch: 349| Step: 0
Training loss: 0.4037026355113098
Validation loss: 2.8155561161400326

Epoch: 5| Step: 1
Training loss: 0.6240735817404311
Validation loss: 2.734843444661469

Epoch: 5| Step: 2
Training loss: 0.5444426257834043
Validation loss: 2.7848413511423336

Epoch: 5| Step: 3
Training loss: 0.3099530979215519
Validation loss: 2.8036733757894674

Epoch: 5| Step: 4
Training loss: 0.6083409265366544
Validation loss: 2.781816353443627

Epoch: 5| Step: 5
Training loss: 0.4349271530782206
Validation loss: 2.8074179475274796

Epoch: 5| Step: 6
Training loss: 0.2910116566637075
Validation loss: 2.799526763629677

Epoch: 5| Step: 7
Training loss: 0.4605244547763308
Validation loss: 2.7804742974367724

Epoch: 5| Step: 8
Training loss: 0.5225519118918193
Validation loss: 2.8042568170095583

Epoch: 5| Step: 9
Training loss: 0.3666080203983846
Validation loss: 2.8186621588125367

Epoch: 5| Step: 10
Training loss: 0.43249859702152854
Validation loss: 2.78535018466842

Epoch: 5| Step: 11
Training loss: 0.46422214780300364
Validation loss: 2.7574818190456303

Epoch: 350| Step: 0
Training loss: 0.40158637528746005
Validation loss: 2.804563234457735

Epoch: 5| Step: 1
Training loss: 0.4055707277746993
Validation loss: 2.76991956147023

Epoch: 5| Step: 2
Training loss: 0.36532228605217354
Validation loss: 2.8302788901259515

Epoch: 5| Step: 3
Training loss: 0.32822888864117833
Validation loss: 2.724890009238047

Epoch: 5| Step: 4
Training loss: 0.6009452179379912
Validation loss: 2.7507450907803617

Epoch: 5| Step: 5
Training loss: 0.41366702212908335
Validation loss: 2.831980106286581

Epoch: 5| Step: 6
Training loss: 0.5020256138570386
Validation loss: 2.802149344072084

Epoch: 5| Step: 7
Training loss: 0.37190699559899787
Validation loss: 2.7569385905381156

Epoch: 5| Step: 8
Training loss: 0.388039654610239
Validation loss: 2.80109176794272

Epoch: 5| Step: 9
Training loss: 0.44907706970386035
Validation loss: 2.7654918990641004

Epoch: 5| Step: 10
Training loss: 0.5150118563500178
Validation loss: 2.7975138941480306

Epoch: 5| Step: 11
Training loss: 0.2542728418575369
Validation loss: 2.7801379648800517

Epoch: 351| Step: 0
Training loss: 0.6557677177103677
Validation loss: 2.7584773154774282

Epoch: 5| Step: 1
Training loss: 0.4811504768906757
Validation loss: 2.774963267257936

Epoch: 5| Step: 2
Training loss: 0.5386082213969513
Validation loss: 2.7867936167326715

Epoch: 5| Step: 3
Training loss: 0.45760420399448665
Validation loss: 2.7459975904519904

Epoch: 5| Step: 4
Training loss: 0.5624496384434263
Validation loss: 2.796774196406536

Epoch: 5| Step: 5
Training loss: 0.4487807751040725
Validation loss: 2.7961787914792313

Epoch: 5| Step: 6
Training loss: 0.4514126156007875
Validation loss: 2.805793965447462

Epoch: 5| Step: 7
Training loss: 0.44423109221915114
Validation loss: 2.8365749732075245

Epoch: 5| Step: 8
Training loss: 0.4886102864755049
Validation loss: 2.8303766542902227

Epoch: 5| Step: 9
Training loss: 0.41757702519528017
Validation loss: 2.7692244789807425

Epoch: 5| Step: 10
Training loss: 0.582223002958118
Validation loss: 2.7795790142398795

Epoch: 5| Step: 11
Training loss: 0.6651851812822437
Validation loss: 2.854311874389914

Epoch: 352| Step: 0
Training loss: 0.4934918966381705
Validation loss: 2.832523497848482

Epoch: 5| Step: 1
Training loss: 0.2564720215438281
Validation loss: 2.8244868776015797

Epoch: 5| Step: 2
Training loss: 0.4556800070996682
Validation loss: 2.828608582181763

Epoch: 5| Step: 3
Training loss: 0.4783831666060437
Validation loss: 2.7757233812373476

Epoch: 5| Step: 4
Training loss: 0.4130253848882973
Validation loss: 2.8124527503389185

Epoch: 5| Step: 5
Training loss: 0.34476871610976395
Validation loss: 2.7709383598060433

Epoch: 5| Step: 6
Training loss: 0.44065588917239645
Validation loss: 2.8328457277189956

Epoch: 5| Step: 7
Training loss: 0.4884822889356123
Validation loss: 2.8200786243518627

Epoch: 5| Step: 8
Training loss: 0.327970581958265
Validation loss: 2.7730921964644653

Epoch: 5| Step: 9
Training loss: 0.36103850433555423
Validation loss: 2.803633769094008

Epoch: 5| Step: 10
Training loss: 0.66031935894532
Validation loss: 2.8317210481378923

Epoch: 5| Step: 11
Training loss: 0.49494205665538116
Validation loss: 2.8306827956644693

Epoch: 353| Step: 0
Training loss: 0.34707819640436605
Validation loss: 2.8237402630655404

Epoch: 5| Step: 1
Training loss: 0.5021498773198831
Validation loss: 2.7989069130512223

Epoch: 5| Step: 2
Training loss: 0.4846808175684522
Validation loss: 2.7245000637281027

Epoch: 5| Step: 3
Training loss: 0.3820670128681698
Validation loss: 2.8520868873063194

Epoch: 5| Step: 4
Training loss: 0.4860201860344758
Validation loss: 2.7631651360991327

Epoch: 5| Step: 5
Training loss: 0.6684873029320497
Validation loss: 2.8222993560500043

Epoch: 5| Step: 6
Training loss: 0.5769092302922655
Validation loss: 2.781537898303827

Epoch: 5| Step: 7
Training loss: 0.4175383410580056
Validation loss: 2.7998193341960804

Epoch: 5| Step: 8
Training loss: 0.4483819714502208
Validation loss: 2.752057165810303

Epoch: 5| Step: 9
Training loss: 0.44501220884612813
Validation loss: 2.778868491425948

Epoch: 5| Step: 10
Training loss: 0.36609774048047267
Validation loss: 2.8418210162943125

Epoch: 5| Step: 11
Training loss: 0.27309797188170953
Validation loss: 2.7689939694236183

Epoch: 354| Step: 0
Training loss: 0.5419977686139306
Validation loss: 2.760923685738402

Epoch: 5| Step: 1
Training loss: 0.3985703564713431
Validation loss: 2.7694911119917953

Epoch: 5| Step: 2
Training loss: 0.4978248250792129
Validation loss: 2.7880605630783317

Epoch: 5| Step: 3
Training loss: 0.40339477073441354
Validation loss: 2.8192978158154434

Epoch: 5| Step: 4
Training loss: 0.41815904937689724
Validation loss: 2.8328729996530444

Epoch: 5| Step: 5
Training loss: 0.35904979504052315
Validation loss: 2.7721178667341055

Epoch: 5| Step: 6
Training loss: 0.3480495307213089
Validation loss: 2.7893472663263665

Epoch: 5| Step: 7
Training loss: 0.38177563905835443
Validation loss: 2.86255570986313

Epoch: 5| Step: 8
Training loss: 0.46122987817019345
Validation loss: 2.8040467949895125

Epoch: 5| Step: 9
Training loss: 0.4305523578292615
Validation loss: 2.78112389425068

Epoch: 5| Step: 10
Training loss: 0.5826993346607711
Validation loss: 2.806335650328514

Epoch: 5| Step: 11
Training loss: 0.37582977203717477
Validation loss: 2.8007171886004127

Epoch: 355| Step: 0
Training loss: 0.2769568659606424
Validation loss: 2.8328329665939807

Epoch: 5| Step: 1
Training loss: 0.598074822548351
Validation loss: 2.776890785274877

Epoch: 5| Step: 2
Training loss: 0.4716597685152214
Validation loss: 2.767428052840566

Epoch: 5| Step: 3
Training loss: 0.5088390830962841
Validation loss: 2.757751230022133

Epoch: 5| Step: 4
Training loss: 0.34014451759722375
Validation loss: 2.8174424648305623

Epoch: 5| Step: 5
Training loss: 0.3965198895563714
Validation loss: 2.8095821998688573

Epoch: 5| Step: 6
Training loss: 0.38172971608996564
Validation loss: 2.817623868135776

Epoch: 5| Step: 7
Training loss: 0.43537298931037577
Validation loss: 2.790585904134103

Epoch: 5| Step: 8
Training loss: 0.4292245972370127
Validation loss: 2.7318956996913433

Epoch: 5| Step: 9
Training loss: 0.6679064180615509
Validation loss: 2.777293645207397

Epoch: 5| Step: 10
Training loss: 0.5380977622392733
Validation loss: 2.8244511678833084

Epoch: 5| Step: 11
Training loss: 0.5198949530299851
Validation loss: 2.784113456467275

Epoch: 356| Step: 0
Training loss: 0.48331951691622066
Validation loss: 2.7869382225189043

Epoch: 5| Step: 1
Training loss: 0.4945403280524769
Validation loss: 2.79685575240632

Epoch: 5| Step: 2
Training loss: 0.46370384151108895
Validation loss: 2.7852808392565396

Epoch: 5| Step: 3
Training loss: 0.41951538638450164
Validation loss: 2.8086244195033765

Epoch: 5| Step: 4
Training loss: 0.5013018290201178
Validation loss: 2.7871734818497633

Epoch: 5| Step: 5
Training loss: 0.5334686065525257
Validation loss: 2.7697894214125123

Epoch: 5| Step: 6
Training loss: 0.38436780007915095
Validation loss: 2.8043432281215592

Epoch: 5| Step: 7
Training loss: 0.47704250363652356
Validation loss: 2.8175791336495664

Epoch: 5| Step: 8
Training loss: 0.5107398826299122
Validation loss: 2.8109037390549783

Epoch: 5| Step: 9
Training loss: 0.6901032837676152
Validation loss: 2.834931344861077

Epoch: 5| Step: 10
Training loss: 0.4150889108679178
Validation loss: 2.7707536418229664

Epoch: 5| Step: 11
Training loss: 0.33845925306116725
Validation loss: 2.853858848781713

Epoch: 357| Step: 0
Training loss: 0.36700012620721045
Validation loss: 2.8543661330939916

Epoch: 5| Step: 1
Training loss: 0.4449672699260764
Validation loss: 2.7836167412985287

Epoch: 5| Step: 2
Training loss: 0.3642866721494621
Validation loss: 2.8390350204702677

Epoch: 5| Step: 3
Training loss: 0.28101415812470365
Validation loss: 2.8354686808434146

Epoch: 5| Step: 4
Training loss: 0.4588912057667363
Validation loss: 2.8428528072556203

Epoch: 5| Step: 5
Training loss: 0.44709138099819745
Validation loss: 2.8289068170599765

Epoch: 5| Step: 6
Training loss: 0.24880108349520488
Validation loss: 2.803705573090679

Epoch: 5| Step: 7
Training loss: 0.29010177345361693
Validation loss: 2.800130948626342

Epoch: 5| Step: 8
Training loss: 0.5637644225853328
Validation loss: 2.8110320463566985

Epoch: 5| Step: 9
Training loss: 0.5600432416280102
Validation loss: 2.7574526882580077

Epoch: 5| Step: 10
Training loss: 0.36933278325033597
Validation loss: 2.7568039783585148

Epoch: 5| Step: 11
Training loss: 0.3972277132772207
Validation loss: 2.8095934684257955

Epoch: 358| Step: 0
Training loss: 0.3913845878591419
Validation loss: 2.7485947125008714

Epoch: 5| Step: 1
Training loss: 0.4299013819273668
Validation loss: 2.7494608935870004

Epoch: 5| Step: 2
Training loss: 0.33873829877709877
Validation loss: 2.858240183785128

Epoch: 5| Step: 3
Training loss: 0.259924058712958
Validation loss: 2.7636634098637747

Epoch: 5| Step: 4
Training loss: 0.3748991155025827
Validation loss: 2.8123247339245214

Epoch: 5| Step: 5
Training loss: 0.41733406578376486
Validation loss: 2.8406926687340914

Epoch: 5| Step: 6
Training loss: 0.3743637966587635
Validation loss: 2.760976786136962

Epoch: 5| Step: 7
Training loss: 0.44896017178943076
Validation loss: 2.7802683101419636

Epoch: 5| Step: 8
Training loss: 0.4344404733836246
Validation loss: 2.864852342401121

Epoch: 5| Step: 9
Training loss: 0.3118489994800304
Validation loss: 2.8099758477377863

Epoch: 5| Step: 10
Training loss: 0.595852892450161
Validation loss: 2.808193300266885

Epoch: 5| Step: 11
Training loss: 0.2837756847528593
Validation loss: 2.7864129689644592

Epoch: 359| Step: 0
Training loss: 0.4014843029668698
Validation loss: 2.7902369800085327

Epoch: 5| Step: 1
Training loss: 0.37018952883116624
Validation loss: 2.8873426686259838

Epoch: 5| Step: 2
Training loss: 0.3953525568151771
Validation loss: 2.8432480505317184

Epoch: 5| Step: 3
Training loss: 0.4247758351316713
Validation loss: 2.8049883171989682

Epoch: 5| Step: 4
Training loss: 0.5552679973366662
Validation loss: 2.8176869916313327

Epoch: 5| Step: 5
Training loss: 0.3392736651944924
Validation loss: 2.8109024526302977

Epoch: 5| Step: 6
Training loss: 0.356669880397228
Validation loss: 2.8492008340807664

Epoch: 5| Step: 7
Training loss: 0.44469028638233493
Validation loss: 2.820531947509006

Epoch: 5| Step: 8
Training loss: 0.45389941238269477
Validation loss: 2.699499576606018

Epoch: 5| Step: 9
Training loss: 0.4148220437328398
Validation loss: 2.740627613160625

Epoch: 5| Step: 10
Training loss: 0.4981146971954537
Validation loss: 2.8138675473194583

Epoch: 5| Step: 11
Training loss: 0.5191718557822007
Validation loss: 2.7904283116062385

Epoch: 360| Step: 0
Training loss: 0.4629538126765322
Validation loss: 2.7921985337819075

Epoch: 5| Step: 1
Training loss: 0.3647812465085046
Validation loss: 2.7899738464815957

Epoch: 5| Step: 2
Training loss: 0.5814883625263323
Validation loss: 2.8508482190865747

Epoch: 5| Step: 3
Training loss: 0.635609790241182
Validation loss: 2.8251427334480286

Epoch: 5| Step: 4
Training loss: 0.47248216055440656
Validation loss: 2.845477868291183

Epoch: 5| Step: 5
Training loss: 0.40148860830438304
Validation loss: 2.8056303686820145

Epoch: 5| Step: 6
Training loss: 0.5734356061607915
Validation loss: 2.8047979186131293

Epoch: 5| Step: 7
Training loss: 0.2729879362048602
Validation loss: 2.830976681853444

Epoch: 5| Step: 8
Training loss: 0.34685331483021054
Validation loss: 2.7758315915224703

Epoch: 5| Step: 9
Training loss: 0.487440896730783
Validation loss: 2.8297859850209552

Epoch: 5| Step: 10
Training loss: 0.3511845888715401
Validation loss: 2.82810875412014

Epoch: 5| Step: 11
Training loss: 0.4347905318948036
Validation loss: 2.807540441376345

Epoch: 361| Step: 0
Training loss: 0.4891912449305556
Validation loss: 2.8302436781945928

Epoch: 5| Step: 1
Training loss: 0.7041223234589312
Validation loss: 2.759827613359368

Epoch: 5| Step: 2
Training loss: 0.38274083147834415
Validation loss: 2.7983952871064295

Epoch: 5| Step: 3
Training loss: 0.3962430736465878
Validation loss: 2.7334223077605606

Epoch: 5| Step: 4
Training loss: 0.5066011211961914
Validation loss: 2.7971606934470823

Epoch: 5| Step: 5
Training loss: 0.40800699514231387
Validation loss: 2.7821161514463504

Epoch: 5| Step: 6
Training loss: 0.3195451057246697
Validation loss: 2.720066058955515

Epoch: 5| Step: 7
Training loss: 0.4853666214938174
Validation loss: 2.762733510448777

Epoch: 5| Step: 8
Training loss: 0.5300020819749066
Validation loss: 2.759171317745733

Epoch: 5| Step: 9
Training loss: 0.41077041057390723
Validation loss: 2.749096364329508

Epoch: 5| Step: 10
Training loss: 0.3249681727707516
Validation loss: 2.8056951853708547

Epoch: 5| Step: 11
Training loss: 0.5714893479042863
Validation loss: 2.737769971160971

Epoch: 362| Step: 0
Training loss: 0.7314279551668423
Validation loss: 2.7943750180140854

Epoch: 5| Step: 1
Training loss: 0.4933036833173037
Validation loss: 2.787948143577579

Epoch: 5| Step: 2
Training loss: 0.4507500629446162
Validation loss: 2.7631070767436636

Epoch: 5| Step: 3
Training loss: 0.44132795736667924
Validation loss: 2.818891997048895

Epoch: 5| Step: 4
Training loss: 0.2942578881153621
Validation loss: 2.736883716509844

Epoch: 5| Step: 5
Training loss: 0.3914486784029422
Validation loss: 2.769488002078942

Epoch: 5| Step: 6
Training loss: 0.4717217973507695
Validation loss: 2.756780101549857

Epoch: 5| Step: 7
Training loss: 0.4232324906291495
Validation loss: 2.776376021804199

Epoch: 5| Step: 8
Training loss: 0.45499609342931113
Validation loss: 2.7671839959043245

Epoch: 5| Step: 9
Training loss: 0.3736021492914114
Validation loss: 2.8115899273685483

Epoch: 5| Step: 10
Training loss: 0.28663941930775666
Validation loss: 2.758869323463183

Epoch: 5| Step: 11
Training loss: 0.5762561542488523
Validation loss: 2.7687832997531925

Epoch: 363| Step: 0
Training loss: 0.4770362875229173
Validation loss: 2.8056052219812355

Epoch: 5| Step: 1
Training loss: 0.30969579903023153
Validation loss: 2.809281298185435

Epoch: 5| Step: 2
Training loss: 0.3604280344138722
Validation loss: 2.8142765791912794

Epoch: 5| Step: 3
Training loss: 0.3442260415356441
Validation loss: 2.8087915378300843

Epoch: 5| Step: 4
Training loss: 0.3728203210386035
Validation loss: 2.807856021176567

Epoch: 5| Step: 5
Training loss: 0.4426489528400596
Validation loss: 2.7849230247317758

Epoch: 5| Step: 6
Training loss: 0.4063712635989101
Validation loss: 2.8026471238506008

Epoch: 5| Step: 7
Training loss: 0.4739308785951052
Validation loss: 2.7957057711062974

Epoch: 5| Step: 8
Training loss: 0.45382299595326614
Validation loss: 2.7545702591424557

Epoch: 5| Step: 9
Training loss: 0.49326421646032576
Validation loss: 2.822726012169466

Epoch: 5| Step: 10
Training loss: 0.63918060200092
Validation loss: 2.8569070835129904

Epoch: 5| Step: 11
Training loss: 0.5610319690265212
Validation loss: 2.7822998758468906

Epoch: 364| Step: 0
Training loss: 0.3442569159475841
Validation loss: 2.7793683283921427

Epoch: 5| Step: 1
Training loss: 0.3928720503152291
Validation loss: 2.8109525025981483

Epoch: 5| Step: 2
Training loss: 0.5514216656582466
Validation loss: 2.8184562449683654

Epoch: 5| Step: 3
Training loss: 0.4793640866834042
Validation loss: 2.7938227488286107

Epoch: 5| Step: 4
Training loss: 0.4216642029725476
Validation loss: 2.879040042523648

Epoch: 5| Step: 5
Training loss: 0.5282800909445413
Validation loss: 2.8430700327586367

Epoch: 5| Step: 6
Training loss: 0.3758040986282198
Validation loss: 2.818271698164026

Epoch: 5| Step: 7
Training loss: 0.46222510158437224
Validation loss: 2.7576846956747834

Epoch: 5| Step: 8
Training loss: 0.4744865823774088
Validation loss: 2.804058801428982

Epoch: 5| Step: 9
Training loss: 0.47469366761470666
Validation loss: 2.8101987148141703

Epoch: 5| Step: 10
Training loss: 0.3905722391736743
Validation loss: 2.7876226054656654

Epoch: 5| Step: 11
Training loss: 0.29596059920524725
Validation loss: 2.8645956813661715

Epoch: 365| Step: 0
Training loss: 0.44154436769397587
Validation loss: 2.722453211506959

Epoch: 5| Step: 1
Training loss: 0.5429230265953587
Validation loss: 2.8282216373463416

Epoch: 5| Step: 2
Training loss: 0.5415633145792317
Validation loss: 2.8262564420844583

Epoch: 5| Step: 3
Training loss: 0.42240177045319255
Validation loss: 2.7861844911628313

Epoch: 5| Step: 4
Training loss: 0.4588371852484901
Validation loss: 2.8339848236847796

Epoch: 5| Step: 5
Training loss: 0.3556777004620722
Validation loss: 2.8607820547456493

Epoch: 5| Step: 6
Training loss: 0.5128414272818042
Validation loss: 2.8356880799910944

Epoch: 5| Step: 7
Training loss: 0.46489708858898615
Validation loss: 2.7971794950083515

Epoch: 5| Step: 8
Training loss: 0.39657148334497694
Validation loss: 2.8271013623822085

Epoch: 5| Step: 9
Training loss: 0.3763238665161822
Validation loss: 2.8443836931377855

Epoch: 5| Step: 10
Training loss: 0.4109380083842451
Validation loss: 2.802069239716852

Epoch: 5| Step: 11
Training loss: 0.353911710111759
Validation loss: 2.8409116889190353

Epoch: 366| Step: 0
Training loss: 0.3336427067516765
Validation loss: 2.799239695161276

Epoch: 5| Step: 1
Training loss: 0.3579162763668207
Validation loss: 2.780758775056973

Epoch: 5| Step: 2
Training loss: 0.528590191573463
Validation loss: 2.800666898967207

Epoch: 5| Step: 3
Training loss: 0.41327697088265336
Validation loss: 2.8331557187807013

Epoch: 5| Step: 4
Training loss: 0.41518177047352545
Validation loss: 2.792794744588729

Epoch: 5| Step: 5
Training loss: 0.5226511386227958
Validation loss: 2.856785517156113

Epoch: 5| Step: 6
Training loss: 0.3294176570262412
Validation loss: 2.8537629716789725

Epoch: 5| Step: 7
Training loss: 0.32025822900775675
Validation loss: 2.789261815262539

Epoch: 5| Step: 8
Training loss: 0.3571310684267996
Validation loss: 2.782090445844528

Epoch: 5| Step: 9
Training loss: 0.5920004919282055
Validation loss: 2.731640056513858

Epoch: 5| Step: 10
Training loss: 0.4583682043363985
Validation loss: 2.8253639013537684

Epoch: 5| Step: 11
Training loss: 0.9866234667659897
Validation loss: 2.7992680894394897

Epoch: 367| Step: 0
Training loss: 0.4175961339794446
Validation loss: 2.7669351244042932

Epoch: 5| Step: 1
Training loss: 0.2532215128680454
Validation loss: 2.8927661629430967

Epoch: 5| Step: 2
Training loss: 0.44844828336822884
Validation loss: 2.8001640239141

Epoch: 5| Step: 3
Training loss: 0.46722886913435974
Validation loss: 2.8046164224698087

Epoch: 5| Step: 4
Training loss: 0.4681855458982786
Validation loss: 2.806394625974673

Epoch: 5| Step: 5
Training loss: 0.34844185437274255
Validation loss: 2.8493459194970017

Epoch: 5| Step: 6
Training loss: 0.49771222109717944
Validation loss: 2.886945000687831

Epoch: 5| Step: 7
Training loss: 0.5472402987450224
Validation loss: 2.797846147799398

Epoch: 5| Step: 8
Training loss: 0.5060230123013939
Validation loss: 2.8128407060039415

Epoch: 5| Step: 9
Training loss: 0.641844681615296
Validation loss: 2.791259797656045

Epoch: 5| Step: 10
Training loss: 0.278547334939084
Validation loss: 2.808084030480785

Epoch: 5| Step: 11
Training loss: 0.3543620225255845
Validation loss: 2.8161864351440893

Epoch: 368| Step: 0
Training loss: 0.35371290150544216
Validation loss: 2.7838328348501653

Epoch: 5| Step: 1
Training loss: 0.3051682250041088
Validation loss: 2.7863685248807406

Epoch: 5| Step: 2
Training loss: 0.44539067770049795
Validation loss: 2.7324514598758145

Epoch: 5| Step: 3
Training loss: 0.36768789891998316
Validation loss: 2.768411357024323

Epoch: 5| Step: 4
Training loss: 0.5433557352565291
Validation loss: 2.8782869205081103

Epoch: 5| Step: 5
Training loss: 0.5920497744197463
Validation loss: 2.778668040955787

Epoch: 5| Step: 6
Training loss: 0.4078741984264507
Validation loss: 2.826669437852062

Epoch: 5| Step: 7
Training loss: 0.34493816462551424
Validation loss: 2.777283637017298

Epoch: 5| Step: 8
Training loss: 0.48927776120875255
Validation loss: 2.813763751337135

Epoch: 5| Step: 9
Training loss: 0.4452179925585074
Validation loss: 2.8233567079047863

Epoch: 5| Step: 10
Training loss: 0.37736241944057036
Validation loss: 2.8203631825353286

Epoch: 5| Step: 11
Training loss: 0.45026921722772073
Validation loss: 2.869917423149129

Epoch: 369| Step: 0
Training loss: 0.41939874044610304
Validation loss: 2.760579440278049

Epoch: 5| Step: 1
Training loss: 0.4559038717459015
Validation loss: 2.714191524913759

Epoch: 5| Step: 2
Training loss: 0.45427147752482466
Validation loss: 2.7767939392216854

Epoch: 5| Step: 3
Training loss: 0.45650207009948124
Validation loss: 2.8201291596197526

Epoch: 5| Step: 4
Training loss: 0.4439136888256035
Validation loss: 2.883319734300579

Epoch: 5| Step: 5
Training loss: 0.470044906505065
Validation loss: 2.820875173358915

Epoch: 5| Step: 6
Training loss: 0.3752740216441734
Validation loss: 2.7597332786253683

Epoch: 5| Step: 7
Training loss: 0.5090175123106254
Validation loss: 2.808599764729489

Epoch: 5| Step: 8
Training loss: 0.4035789085610088
Validation loss: 2.8130392652554113

Epoch: 5| Step: 9
Training loss: 0.5640471163102221
Validation loss: 2.800010922813682

Epoch: 5| Step: 10
Training loss: 0.5382202866888975
Validation loss: 2.828721898493222

Epoch: 5| Step: 11
Training loss: 0.20092413749580898
Validation loss: 2.798142904099792

Epoch: 370| Step: 0
Training loss: 0.5176487712509854
Validation loss: 2.8084955671371765

Epoch: 5| Step: 1
Training loss: 0.4759798553064879
Validation loss: 2.7717669940823315

Epoch: 5| Step: 2
Training loss: 0.40040733488616653
Validation loss: 2.81123044712362

Epoch: 5| Step: 3
Training loss: 0.5486394211617895
Validation loss: 2.7327902170461136

Epoch: 5| Step: 4
Training loss: 0.41112521927950363
Validation loss: 2.814221907609954

Epoch: 5| Step: 5
Training loss: 0.48522170726361147
Validation loss: 2.78344835059906

Epoch: 5| Step: 6
Training loss: 0.4735246987190172
Validation loss: 2.8140315971816987

Epoch: 5| Step: 7
Training loss: 0.4406003600190935
Validation loss: 2.732055901319922

Epoch: 5| Step: 8
Training loss: 0.42834396123070345
Validation loss: 2.7443896487227395

Epoch: 5| Step: 9
Training loss: 0.347693794880602
Validation loss: 2.769906284494798

Epoch: 5| Step: 10
Training loss: 0.34260043916484834
Validation loss: 2.7985308450011446

Epoch: 5| Step: 11
Training loss: 0.24721217700213638
Validation loss: 2.7686094212489945

Epoch: 371| Step: 0
Training loss: 0.32561378931966717
Validation loss: 2.836637205707929

Epoch: 5| Step: 1
Training loss: 0.37970876751900046
Validation loss: 2.845275525616234

Epoch: 5| Step: 2
Training loss: 0.40137086295790897
Validation loss: 2.7499728707218027

Epoch: 5| Step: 3
Training loss: 0.4883454089928384
Validation loss: 2.835297980943895

Epoch: 5| Step: 4
Training loss: 0.41875741653137566
Validation loss: 2.72859346883563

Epoch: 5| Step: 5
Training loss: 0.4540886005479528
Validation loss: 2.7892587915012843

Epoch: 5| Step: 6
Training loss: 0.4189763091031324
Validation loss: 2.8017522103364536

Epoch: 5| Step: 7
Training loss: 0.4113304225064096
Validation loss: 2.738353294770739

Epoch: 5| Step: 8
Training loss: 0.5933280499585621
Validation loss: 2.8265675845714617

Epoch: 5| Step: 9
Training loss: 0.4787215743328634
Validation loss: 2.8016001640492885

Epoch: 5| Step: 10
Training loss: 0.28761792718661916
Validation loss: 2.876737504947386

Epoch: 5| Step: 11
Training loss: 0.22526469621654055
Validation loss: 2.7160826310253126

Epoch: 372| Step: 0
Training loss: 0.4293460876747716
Validation loss: 2.7644040596987227

Epoch: 5| Step: 1
Training loss: 0.47576521797918214
Validation loss: 2.7769735727180267

Epoch: 5| Step: 2
Training loss: 0.43920140156500564
Validation loss: 2.798550620633504

Epoch: 5| Step: 3
Training loss: 0.5621097588554381
Validation loss: 2.7882090490699514

Epoch: 5| Step: 4
Training loss: 0.3663674388900498
Validation loss: 2.8357515965980498

Epoch: 5| Step: 5
Training loss: 0.5461796836202066
Validation loss: 2.8927680757475596

Epoch: 5| Step: 6
Training loss: 0.44225654736939857
Validation loss: 2.817476056174055

Epoch: 5| Step: 7
Training loss: 0.42919404565950653
Validation loss: 2.8084803537565968

Epoch: 5| Step: 8
Training loss: 0.3571599198420765
Validation loss: 2.8819429211184806

Epoch: 5| Step: 9
Training loss: 0.4144080897104068
Validation loss: 2.906456557149296

Epoch: 5| Step: 10
Training loss: 0.4435086776138198
Validation loss: 2.8155400200205034

Epoch: 5| Step: 11
Training loss: 0.5988777991070003
Validation loss: 2.8314120332612416

Epoch: 373| Step: 0
Training loss: 0.47832368387675145
Validation loss: 2.7818462254237284

Epoch: 5| Step: 1
Training loss: 0.6466170575302871
Validation loss: 2.8271424358789563

Epoch: 5| Step: 2
Training loss: 0.36481502754808914
Validation loss: 2.8494556674024327

Epoch: 5| Step: 3
Training loss: 0.48801408706719257
Validation loss: 2.865079213773247

Epoch: 5| Step: 4
Training loss: 0.3985888810647339
Validation loss: 2.825442160406189

Epoch: 5| Step: 5
Training loss: 0.5291404633780165
Validation loss: 2.843676171374964

Epoch: 5| Step: 6
Training loss: 0.538856826466927
Validation loss: 2.861408816643876

Epoch: 5| Step: 7
Training loss: 0.6711304997605851
Validation loss: 2.873645342386395

Epoch: 5| Step: 8
Training loss: 0.46523672210588146
Validation loss: 2.7471578100187792

Epoch: 5| Step: 9
Training loss: 0.5492594914091569
Validation loss: 2.814572609053444

Epoch: 5| Step: 10
Training loss: 0.33590387575298997
Validation loss: 2.8180802229719837

Epoch: 5| Step: 11
Training loss: 0.35222006866367983
Validation loss: 2.8170314876090736

Epoch: 374| Step: 0
Training loss: 0.4882240719695918
Validation loss: 2.8338495875773035

Epoch: 5| Step: 1
Training loss: 0.4890079278937102
Validation loss: 2.8512620079538014

Epoch: 5| Step: 2
Training loss: 0.5878224380845526
Validation loss: 2.804338619454439

Epoch: 5| Step: 3
Training loss: 0.3692026237617741
Validation loss: 2.7939893053954217

Epoch: 5| Step: 4
Training loss: 0.41925370041175825
Validation loss: 2.7737584532806188

Epoch: 5| Step: 5
Training loss: 0.5444239046748542
Validation loss: 2.7411049882495

Epoch: 5| Step: 6
Training loss: 0.46820069552866506
Validation loss: 2.8187735630581487

Epoch: 5| Step: 7
Training loss: 0.42760967370350156
Validation loss: 2.854648303490305

Epoch: 5| Step: 8
Training loss: 0.40491902124605234
Validation loss: 2.7982401544141027

Epoch: 5| Step: 9
Training loss: 0.40304840750124715
Validation loss: 2.8274535405968213

Epoch: 5| Step: 10
Training loss: 0.28669572732570403
Validation loss: 2.7467580817420143

Epoch: 5| Step: 11
Training loss: 0.16824033316783152
Validation loss: 2.8193887340718806

Epoch: 375| Step: 0
Training loss: 0.4325126366615934
Validation loss: 2.7541807466244204

Epoch: 5| Step: 1
Training loss: 0.534547947341536
Validation loss: 2.780493322587017

Epoch: 5| Step: 2
Training loss: 0.5076294202163578
Validation loss: 2.8209960581125286

Epoch: 5| Step: 3
Training loss: 0.5017698376359089
Validation loss: 2.791000177524424

Epoch: 5| Step: 4
Training loss: 0.35435695538337486
Validation loss: 2.815747004443733

Epoch: 5| Step: 5
Training loss: 0.5990807007445981
Validation loss: 2.763740346395103

Epoch: 5| Step: 6
Training loss: 0.4781321487640308
Validation loss: 2.7765583514152334

Epoch: 5| Step: 7
Training loss: 0.3979622119116385
Validation loss: 2.8597296058885124

Epoch: 5| Step: 8
Training loss: 0.38730147798548237
Validation loss: 2.778753862482688

Epoch: 5| Step: 9
Training loss: 0.5176418049342975
Validation loss: 2.8074596522266377

Epoch: 5| Step: 10
Training loss: 0.3745197558877254
Validation loss: 2.8314757615689485

Epoch: 5| Step: 11
Training loss: 0.5767934259205372
Validation loss: 2.7899185170645375

Epoch: 376| Step: 0
Training loss: 0.38622497091708674
Validation loss: 2.737327318827207

Epoch: 5| Step: 1
Training loss: 0.3197316508974748
Validation loss: 2.809290736217965

Epoch: 5| Step: 2
Training loss: 0.4506008779018991
Validation loss: 2.7833754244113496

Epoch: 5| Step: 3
Training loss: 0.33956216788104543
Validation loss: 2.8077615805827434

Epoch: 5| Step: 4
Training loss: 0.39267446749680174
Validation loss: 2.808520553547615

Epoch: 5| Step: 5
Training loss: 0.44760816692008565
Validation loss: 2.7650444549323296

Epoch: 5| Step: 6
Training loss: 0.5029766764494698
Validation loss: 2.7128152234900496

Epoch: 5| Step: 7
Training loss: 0.45359590330805294
Validation loss: 2.791147537264144

Epoch: 5| Step: 8
Training loss: 0.415131430725719
Validation loss: 2.7906917831728513

Epoch: 5| Step: 9
Training loss: 0.48697863968057387
Validation loss: 2.787475358742909

Epoch: 5| Step: 10
Training loss: 0.38775757258465077
Validation loss: 2.8195103907480776

Epoch: 5| Step: 11
Training loss: 0.5928437695578889
Validation loss: 2.774845535973996

Epoch: 377| Step: 0
Training loss: 0.42546262105561294
Validation loss: 2.8228746683203614

Epoch: 5| Step: 1
Training loss: 0.43574008163155303
Validation loss: 2.7740264553787872

Epoch: 5| Step: 2
Training loss: 0.34753945349660265
Validation loss: 2.8435032810878456

Epoch: 5| Step: 3
Training loss: 0.490144835422192
Validation loss: 2.775725904378748

Epoch: 5| Step: 4
Training loss: 0.35960463774960943
Validation loss: 2.798614674832263

Epoch: 5| Step: 5
Training loss: 0.48164318730646527
Validation loss: 2.774366568821609

Epoch: 5| Step: 6
Training loss: 0.3722931202264355
Validation loss: 2.8312023414266547

Epoch: 5| Step: 7
Training loss: 0.40204108993046644
Validation loss: 2.815036939911618

Epoch: 5| Step: 8
Training loss: 0.40699285666596285
Validation loss: 2.7956293802492125

Epoch: 5| Step: 9
Training loss: 0.48043274163015826
Validation loss: 2.81745431017054

Epoch: 5| Step: 10
Training loss: 0.33742413816158956
Validation loss: 2.7952171932069714

Epoch: 5| Step: 11
Training loss: 0.5698655349671714
Validation loss: 2.748313625161701

Epoch: 378| Step: 0
Training loss: 0.382257584846496
Validation loss: 2.8404540884473777

Epoch: 5| Step: 1
Training loss: 0.21828079140300266
Validation loss: 2.8150385985147666

Epoch: 5| Step: 2
Training loss: 0.3864551956207041
Validation loss: 2.7593520912725746

Epoch: 5| Step: 3
Training loss: 0.47449837473720613
Validation loss: 2.7891308360272027

Epoch: 5| Step: 4
Training loss: 0.445247545022424
Validation loss: 2.8170256160715224

Epoch: 5| Step: 5
Training loss: 0.32058430978634417
Validation loss: 2.7958906775182655

Epoch: 5| Step: 6
Training loss: 0.4145676033192449
Validation loss: 2.8014734495512625

Epoch: 5| Step: 7
Training loss: 0.5454994613494452
Validation loss: 2.8135099716877563

Epoch: 5| Step: 8
Training loss: 0.51891623212017
Validation loss: 2.757322579472251

Epoch: 5| Step: 9
Training loss: 0.4553434883469308
Validation loss: 2.8026875136442015

Epoch: 5| Step: 10
Training loss: 0.40598319535758853
Validation loss: 2.817783768373316

Epoch: 5| Step: 11
Training loss: 0.4269937871083442
Validation loss: 2.733672209750539

Epoch: 379| Step: 0
Training loss: 0.2879052193409044
Validation loss: 2.8419166076536064

Epoch: 5| Step: 1
Training loss: 0.3900020973442609
Validation loss: 2.8519912954730846

Epoch: 5| Step: 2
Training loss: 0.6449850854332134
Validation loss: 2.8162967944557478

Epoch: 5| Step: 3
Training loss: 0.6354356486711035
Validation loss: 2.7919827372464527

Epoch: 5| Step: 4
Training loss: 0.4147138331086369
Validation loss: 2.7175601478483955

Epoch: 5| Step: 5
Training loss: 0.36262078903630396
Validation loss: 2.7920620635891944

Epoch: 5| Step: 6
Training loss: 0.371640856143157
Validation loss: 2.7607372361705393

Epoch: 5| Step: 7
Training loss: 0.4214396703167218
Validation loss: 2.8097460155597407

Epoch: 5| Step: 8
Training loss: 0.7359620659164143
Validation loss: 2.8016807037624414

Epoch: 5| Step: 9
Training loss: 0.46765088922988496
Validation loss: 2.783869823891145

Epoch: 5| Step: 10
Training loss: 0.3524361457548389
Validation loss: 2.774358254479751

Epoch: 5| Step: 11
Training loss: 0.322574028641386
Validation loss: 2.7416035174331386

Epoch: 380| Step: 0
Training loss: 0.3861101158313746
Validation loss: 2.7777553974018265

Epoch: 5| Step: 1
Training loss: 0.6298258437779451
Validation loss: 2.791237927484891

Epoch: 5| Step: 2
Training loss: 0.6403837214822978
Validation loss: 2.817298024894477

Epoch: 5| Step: 3
Training loss: 0.33316868450882553
Validation loss: 2.8578599709999644

Epoch: 5| Step: 4
Training loss: 0.4069648651931215
Validation loss: 2.7891603002132688

Epoch: 5| Step: 5
Training loss: 0.46064521121504
Validation loss: 2.772903330049798

Epoch: 5| Step: 6
Training loss: 0.3773597935016424
Validation loss: 2.8205465816667448

Epoch: 5| Step: 7
Training loss: 0.3365662700827993
Validation loss: 2.814500009294922

Epoch: 5| Step: 8
Training loss: 0.3198191518600601
Validation loss: 2.821120800591838

Epoch: 5| Step: 9
Training loss: 0.43351186374305123
Validation loss: 2.8002111580961713

Epoch: 5| Step: 10
Training loss: 0.43385660950093957
Validation loss: 2.77552214169282

Epoch: 5| Step: 11
Training loss: 0.1886390716752932
Validation loss: 2.8024442480475895

Epoch: 381| Step: 0
Training loss: 0.2796173657759419
Validation loss: 2.8188942560074994

Epoch: 5| Step: 1
Training loss: 0.3070289558344347
Validation loss: 2.775636419140923

Epoch: 5| Step: 2
Training loss: 0.4154911585829974
Validation loss: 2.8143821211432596

Epoch: 5| Step: 3
Training loss: 0.34201489715728767
Validation loss: 2.790028800941034

Epoch: 5| Step: 4
Training loss: 0.2904439469860043
Validation loss: 2.7847456698541673

Epoch: 5| Step: 5
Training loss: 0.4272773949192453
Validation loss: 2.7777268529568477

Epoch: 5| Step: 6
Training loss: 0.4238586063235307
Validation loss: 2.8117843388507824

Epoch: 5| Step: 7
Training loss: 0.4502985705538296
Validation loss: 2.789785036872

Epoch: 5| Step: 8
Training loss: 0.32203677750627724
Validation loss: 2.7195153273638963

Epoch: 5| Step: 9
Training loss: 0.483286788839623
Validation loss: 2.7728341391014375

Epoch: 5| Step: 10
Training loss: 0.49946467233045994
Validation loss: 2.808990500011158

Epoch: 5| Step: 11
Training loss: 0.6323012417775802
Validation loss: 2.7974847239082066

Epoch: 382| Step: 0
Training loss: 0.29706474564833346
Validation loss: 2.762447707010665

Epoch: 5| Step: 1
Training loss: 0.5468911032349412
Validation loss: 2.7373368815591683

Epoch: 5| Step: 2
Training loss: 0.39633882604011367
Validation loss: 2.844955534646178

Epoch: 5| Step: 3
Training loss: 0.46308048394707335
Validation loss: 2.850463881999109

Epoch: 5| Step: 4
Training loss: 0.35663626794566483
Validation loss: 2.7893101807508534

Epoch: 5| Step: 5
Training loss: 0.473368793323967
Validation loss: 2.818916743295465

Epoch: 5| Step: 6
Training loss: 0.4099699959883215
Validation loss: 2.828531085061959

Epoch: 5| Step: 7
Training loss: 0.46910517270365637
Validation loss: 2.8211119585093134

Epoch: 5| Step: 8
Training loss: 0.42504639161982055
Validation loss: 2.9393277974833287

Epoch: 5| Step: 9
Training loss: 0.4695456269359247
Validation loss: 2.7910821869807876

Epoch: 5| Step: 10
Training loss: 0.36367425887067145
Validation loss: 2.847740950020287

Epoch: 5| Step: 11
Training loss: 0.4257656759511034
Validation loss: 2.8216437793178244

Epoch: 383| Step: 0
Training loss: 0.3854649187074661
Validation loss: 2.8250309157578775

Epoch: 5| Step: 1
Training loss: 0.41265679110600256
Validation loss: 2.8381151643028324

Epoch: 5| Step: 2
Training loss: 0.3632821318913082
Validation loss: 2.7779676234750474

Epoch: 5| Step: 3
Training loss: 0.2515709070021144
Validation loss: 2.7843801657489275

Epoch: 5| Step: 4
Training loss: 0.44394747342927626
Validation loss: 2.791451710401006

Epoch: 5| Step: 5
Training loss: 0.40409147416839
Validation loss: 2.836145897766741

Epoch: 5| Step: 6
Training loss: 0.5184557976692773
Validation loss: 2.806768769710422

Epoch: 5| Step: 7
Training loss: 0.33616296831300563
Validation loss: 2.795967317053166

Epoch: 5| Step: 8
Training loss: 0.47306808940716694
Validation loss: 2.84548204026168

Epoch: 5| Step: 9
Training loss: 0.45160451185419703
Validation loss: 2.753386702351276

Epoch: 5| Step: 10
Training loss: 0.4040483826002433
Validation loss: 2.8448388317271873

Epoch: 5| Step: 11
Training loss: 0.3455546324184959
Validation loss: 2.8082825652343533

Epoch: 384| Step: 0
Training loss: 0.4569028527292875
Validation loss: 2.7526774539532504

Epoch: 5| Step: 1
Training loss: 0.46338438909118784
Validation loss: 2.8105495330041577

Epoch: 5| Step: 2
Training loss: 0.3349159811118397
Validation loss: 2.807367307296217

Epoch: 5| Step: 3
Training loss: 0.40769536320180816
Validation loss: 2.7843041170847154

Epoch: 5| Step: 4
Training loss: 0.4497353941415467
Validation loss: 2.804315483901901

Epoch: 5| Step: 5
Training loss: 0.5245916254217913
Validation loss: 2.852079853174628

Epoch: 5| Step: 6
Training loss: 0.23918765849578447
Validation loss: 2.7802845818783406

Epoch: 5| Step: 7
Training loss: 0.5069459417254256
Validation loss: 2.7162864419464863

Epoch: 5| Step: 8
Training loss: 0.44832990864269395
Validation loss: 2.8670029056730826

Epoch: 5| Step: 9
Training loss: 0.3437717387521514
Validation loss: 2.815349103568488

Epoch: 5| Step: 10
Training loss: 0.5633242978221608
Validation loss: 2.8750707541618903

Epoch: 5| Step: 11
Training loss: 0.45291369542770665
Validation loss: 2.8680285814806146

Epoch: 385| Step: 0
Training loss: 0.2810355667067782
Validation loss: 2.8146769822638045

Epoch: 5| Step: 1
Training loss: 0.3069920682294065
Validation loss: 2.7797476679247834

Epoch: 5| Step: 2
Training loss: 0.47111856955058956
Validation loss: 2.8243776226601325

Epoch: 5| Step: 3
Training loss: 0.2982089290798608
Validation loss: 2.8652604753501203

Epoch: 5| Step: 4
Training loss: 0.4536501537895383
Validation loss: 2.8340202940950294

Epoch: 5| Step: 5
Training loss: 0.5975391048738862
Validation loss: 2.7900173465469797

Epoch: 5| Step: 6
Training loss: 0.28032003407469686
Validation loss: 2.8145390042349048

Epoch: 5| Step: 7
Training loss: 0.45204670628779253
Validation loss: 2.845199344877136

Epoch: 5| Step: 8
Training loss: 0.39956210873944326
Validation loss: 2.8004673028594653

Epoch: 5| Step: 9
Training loss: 0.4112362584250273
Validation loss: 2.847438488218567

Epoch: 5| Step: 10
Training loss: 0.37982092895118824
Validation loss: 2.858295504418849

Epoch: 5| Step: 11
Training loss: 0.5565595065790863
Validation loss: 2.8576800077026006

Epoch: 386| Step: 0
Training loss: 0.455826385664195
Validation loss: 2.803864084576685

Epoch: 5| Step: 1
Training loss: 0.5232314657983144
Validation loss: 2.8714894478354

Epoch: 5| Step: 2
Training loss: 0.4256735324217544
Validation loss: 2.844519392319037

Epoch: 5| Step: 3
Training loss: 0.5049287343492599
Validation loss: 2.8289669989372084

Epoch: 5| Step: 4
Training loss: 0.3735245846517725
Validation loss: 2.831825076962303

Epoch: 5| Step: 5
Training loss: 0.40704806507251895
Validation loss: 2.7734645107906104

Epoch: 5| Step: 6
Training loss: 0.3221816444789873
Validation loss: 2.788397869201984

Epoch: 5| Step: 7
Training loss: 0.5854949806024288
Validation loss: 2.7658722402401663

Epoch: 5| Step: 8
Training loss: 0.3365409000800938
Validation loss: 2.7906266126667187

Epoch: 5| Step: 9
Training loss: 0.33082534362808563
Validation loss: 2.7808636564884557

Epoch: 5| Step: 10
Training loss: 0.3506874426320066
Validation loss: 2.8032701146424657

Epoch: 5| Step: 11
Training loss: 0.16018210179166703
Validation loss: 2.8366607325294217

Epoch: 387| Step: 0
Training loss: 0.31703622527375913
Validation loss: 2.8222951744495006

Epoch: 5| Step: 1
Training loss: 0.396975133684036
Validation loss: 2.8557328512133333

Epoch: 5| Step: 2
Training loss: 0.4201648098154182
Validation loss: 2.8013077493309875

Epoch: 5| Step: 3
Training loss: 0.4895784313551699
Validation loss: 2.8660299405381724

Epoch: 5| Step: 4
Training loss: 0.533032903643316
Validation loss: 2.7341916449697474

Epoch: 5| Step: 5
Training loss: 0.4171358169374019
Validation loss: 2.8209231764283005

Epoch: 5| Step: 6
Training loss: 0.41114991938504275
Validation loss: 2.8438941129561655

Epoch: 5| Step: 7
Training loss: 0.26624087853097195
Validation loss: 2.762639853877208

Epoch: 5| Step: 8
Training loss: 0.4365876255164208
Validation loss: 2.8288353893637628

Epoch: 5| Step: 9
Training loss: 0.45143509489747286
Validation loss: 2.788403134805264

Epoch: 5| Step: 10
Training loss: 0.3655234228357513
Validation loss: 2.8022915444900964

Epoch: 5| Step: 11
Training loss: 0.42311056543518943
Validation loss: 2.8257200437481873

Epoch: 388| Step: 0
Training loss: 0.4578393492132738
Validation loss: 2.810580569965065

Epoch: 5| Step: 1
Training loss: 0.45907484745587523
Validation loss: 2.7558044042406

Epoch: 5| Step: 2
Training loss: 0.39364713808751794
Validation loss: 2.826657703174768

Epoch: 5| Step: 3
Training loss: 0.32465632910437875
Validation loss: 2.8209942938458323

Epoch: 5| Step: 4
Training loss: 0.3930660650595375
Validation loss: 2.8191560221621543

Epoch: 5| Step: 5
Training loss: 0.41895601841334296
Validation loss: 2.8515992462716917

Epoch: 5| Step: 6
Training loss: 0.3725044741137843
Validation loss: 2.8077753154066376

Epoch: 5| Step: 7
Training loss: 0.3204113179807521
Validation loss: 2.769706602154427

Epoch: 5| Step: 8
Training loss: 0.5048691472873389
Validation loss: 2.8551301072621964

Epoch: 5| Step: 9
Training loss: 0.5762301399383367
Validation loss: 2.808545461919551

Epoch: 5| Step: 10
Training loss: 0.40604828448290786
Validation loss: 2.8337918300931966

Epoch: 5| Step: 11
Training loss: 0.6393746292322003
Validation loss: 2.8408036776261394

Epoch: 389| Step: 0
Training loss: 0.3562237194473303
Validation loss: 2.9030734138025474

Epoch: 5| Step: 1
Training loss: 0.5033559233709795
Validation loss: 2.7979741591688874

Epoch: 5| Step: 2
Training loss: 0.5296551663592864
Validation loss: 2.769511966611288

Epoch: 5| Step: 3
Training loss: 0.42320155928816655
Validation loss: 2.7824744554519847

Epoch: 5| Step: 4
Training loss: 0.5028027420567024
Validation loss: 2.7588326581813054

Epoch: 5| Step: 5
Training loss: 0.484989299705291
Validation loss: 2.817409437242182

Epoch: 5| Step: 6
Training loss: 0.4221452977386788
Validation loss: 2.7675893384463564

Epoch: 5| Step: 7
Training loss: 0.31828644274004286
Validation loss: 2.819080657906144

Epoch: 5| Step: 8
Training loss: 0.5444049365793813
Validation loss: 2.833101499179372

Epoch: 5| Step: 9
Training loss: 0.5161960214284925
Validation loss: 2.8359840256138407

Epoch: 5| Step: 10
Training loss: 0.4384363916427948
Validation loss: 2.820248212988646

Epoch: 5| Step: 11
Training loss: 0.3664031071314603
Validation loss: 2.7754757335909783

Epoch: 390| Step: 0
Training loss: 0.3515714008476108
Validation loss: 2.788514875117748

Epoch: 5| Step: 1
Training loss: 0.42308034720402354
Validation loss: 2.8077909642495573

Epoch: 5| Step: 2
Training loss: 0.4617419254792828
Validation loss: 2.826016330195312

Epoch: 5| Step: 3
Training loss: 0.4692665750505799
Validation loss: 2.8203768559912605

Epoch: 5| Step: 4
Training loss: 0.4626049657223638
Validation loss: 2.840345542123177

Epoch: 5| Step: 5
Training loss: 0.4333076908092845
Validation loss: 2.770835861525183

Epoch: 5| Step: 6
Training loss: 0.4976664417846122
Validation loss: 2.8812773286043334

Epoch: 5| Step: 7
Training loss: 0.30867839811167336
Validation loss: 2.8346140587206072

Epoch: 5| Step: 8
Training loss: 0.42925561527873946
Validation loss: 2.8356487242740616

Epoch: 5| Step: 9
Training loss: 0.3204883697396195
Validation loss: 2.867623717813355

Epoch: 5| Step: 10
Training loss: 0.2802575402619392
Validation loss: 2.7904060112670614

Epoch: 5| Step: 11
Training loss: 0.4899318415084725
Validation loss: 2.9025950641764293

Epoch: 391| Step: 0
Training loss: 0.3946551704304376
Validation loss: 2.8664799162744834

Epoch: 5| Step: 1
Training loss: 0.578379446173752
Validation loss: 2.8483709233033663

Epoch: 5| Step: 2
Training loss: 0.42066432168254575
Validation loss: 2.809601574192257

Epoch: 5| Step: 3
Training loss: 0.37939001446444615
Validation loss: 2.7747404449666817

Epoch: 5| Step: 4
Training loss: 0.4054642010031186
Validation loss: 2.861965374946628

Epoch: 5| Step: 5
Training loss: 0.264069956047838
Validation loss: 2.811396000668054

Epoch: 5| Step: 6
Training loss: 0.5061771469913239
Validation loss: 2.8224677412793024

Epoch: 5| Step: 7
Training loss: 0.3062937165217971
Validation loss: 2.8170575197080314

Epoch: 5| Step: 8
Training loss: 0.6258678609701046
Validation loss: 2.8018602024753827

Epoch: 5| Step: 9
Training loss: 0.5536262676218472
Validation loss: 2.858749682592261

Epoch: 5| Step: 10
Training loss: 0.37162443663435396
Validation loss: 2.80361259427045

Epoch: 5| Step: 11
Training loss: 0.2766017120925505
Validation loss: 2.794690619959656

Epoch: 392| Step: 0
Training loss: 0.3162255183080931
Validation loss: 2.7476894613469165

Epoch: 5| Step: 1
Training loss: 0.519246991629557
Validation loss: 2.8160091848622115

Epoch: 5| Step: 2
Training loss: 0.44529108364071457
Validation loss: 2.741363089913752

Epoch: 5| Step: 3
Training loss: 0.48244378970637575
Validation loss: 2.7608542305450725

Epoch: 5| Step: 4
Training loss: 0.3404985455609374
Validation loss: 2.826371975633867

Epoch: 5| Step: 5
Training loss: 0.23886466910032
Validation loss: 2.8004506695039613

Epoch: 5| Step: 6
Training loss: 0.3473502323165233
Validation loss: 2.7926385324176826

Epoch: 5| Step: 7
Training loss: 0.6696377031945391
Validation loss: 2.752093046018647

Epoch: 5| Step: 8
Training loss: 0.3871449520572716
Validation loss: 2.7386702779521213

Epoch: 5| Step: 9
Training loss: 0.5083083446280775
Validation loss: 2.826191281469748

Epoch: 5| Step: 10
Training loss: 0.30828056861272374
Validation loss: 2.779368807339201

Epoch: 5| Step: 11
Training loss: 0.12622808143403993
Validation loss: 2.7960277780170317

Epoch: 393| Step: 0
Training loss: 0.5200203049345037
Validation loss: 2.776516629800628

Epoch: 5| Step: 1
Training loss: 0.4350558022902958
Validation loss: 2.8301673982140536

Epoch: 5| Step: 2
Training loss: 0.373252811809662
Validation loss: 2.8295335476058283

Epoch: 5| Step: 3
Training loss: 0.2834078739206805
Validation loss: 2.8279865715754786

Epoch: 5| Step: 4
Training loss: 0.4994644933248402
Validation loss: 2.7611587978317766

Epoch: 5| Step: 5
Training loss: 0.3487953106524226
Validation loss: 2.7787246454580528

Epoch: 5| Step: 6
Training loss: 0.3773315783131014
Validation loss: 2.768741807215089

Epoch: 5| Step: 7
Training loss: 0.4286336112182262
Validation loss: 2.715292370730702

Epoch: 5| Step: 8
Training loss: 0.3134198122558083
Validation loss: 2.8029304781371644

Epoch: 5| Step: 9
Training loss: 0.48998238823828294
Validation loss: 2.837310318621652

Epoch: 5| Step: 10
Training loss: 0.4421273139998752
Validation loss: 2.78204674327678

Epoch: 5| Step: 11
Training loss: 0.43013615160462426
Validation loss: 2.814948683169891

Epoch: 394| Step: 0
Training loss: 0.3853411170870143
Validation loss: 2.8312558219687003

Epoch: 5| Step: 1
Training loss: 0.37060380013031186
Validation loss: 2.8177628303282884

Epoch: 5| Step: 2
Training loss: 0.3862187399451752
Validation loss: 2.819084801988278

Epoch: 5| Step: 3
Training loss: 0.3454904926071204
Validation loss: 2.754501242425407

Epoch: 5| Step: 4
Training loss: 0.500609086506456
Validation loss: 2.7896072005394497

Epoch: 5| Step: 5
Training loss: 0.4165719123229119
Validation loss: 2.808820514605868

Epoch: 5| Step: 6
Training loss: 0.40207590984086655
Validation loss: 2.8297113637692037

Epoch: 5| Step: 7
Training loss: 0.41155853339089005
Validation loss: 2.800120184794034

Epoch: 5| Step: 8
Training loss: 0.35657007829534704
Validation loss: 2.800993747710332

Epoch: 5| Step: 9
Training loss: 0.547806165041638
Validation loss: 2.8066539511898476

Epoch: 5| Step: 10
Training loss: 0.2788143257580726
Validation loss: 2.8008182759056623

Epoch: 5| Step: 11
Training loss: 0.17820393712227886
Validation loss: 2.8409271622285304

Epoch: 395| Step: 0
Training loss: 0.2950207626584772
Validation loss: 2.801321090251239

Epoch: 5| Step: 1
Training loss: 0.5405662129804242
Validation loss: 2.815679374364552

Epoch: 5| Step: 2
Training loss: 0.3973226470683657
Validation loss: 2.8684650627308383

Epoch: 5| Step: 3
Training loss: 0.4479219044519583
Validation loss: 2.875216546749113

Epoch: 5| Step: 4
Training loss: 0.31559904766084124
Validation loss: 2.7429898022095776

Epoch: 5| Step: 5
Training loss: 0.6079941534511019
Validation loss: 2.892414989073935

Epoch: 5| Step: 6
Training loss: 0.4562431452510572
Validation loss: 2.793793193360918

Epoch: 5| Step: 7
Training loss: 0.406552092399181
Validation loss: 2.7701163953869514

Epoch: 5| Step: 8
Training loss: 0.4863479487656964
Validation loss: 2.8158046522558573

Epoch: 5| Step: 9
Training loss: 0.4166787106044866
Validation loss: 2.783010400713823

Epoch: 5| Step: 10
Training loss: 0.32733917369693605
Validation loss: 2.8572799393573947

Epoch: 5| Step: 11
Training loss: 0.5780194675935619
Validation loss: 2.792404786549741

Epoch: 396| Step: 0
Training loss: 0.3702059918560171
Validation loss: 2.8673440091884794

Epoch: 5| Step: 1
Training loss: 0.6279318232522242
Validation loss: 2.853428993589808

Epoch: 5| Step: 2
Training loss: 0.49362751552127265
Validation loss: 2.8498460733662982

Epoch: 5| Step: 3
Training loss: 0.4965955194162441
Validation loss: 2.8559971575745116

Epoch: 5| Step: 4
Training loss: 0.38399451582936306
Validation loss: 2.87121381097733

Epoch: 5| Step: 5
Training loss: 0.42584385542862313
Validation loss: 2.7807066597426324

Epoch: 5| Step: 6
Training loss: 0.32696692142523964
Validation loss: 2.8157959240154473

Epoch: 5| Step: 7
Training loss: 0.35244124051304465
Validation loss: 2.7718593029278766

Epoch: 5| Step: 8
Training loss: 0.49359051989844593
Validation loss: 2.761336494836405

Epoch: 5| Step: 9
Training loss: 0.6640051199862127
Validation loss: 2.853859332632139

Epoch: 5| Step: 10
Training loss: 0.30686914226667195
Validation loss: 2.8665731986373744

Epoch: 5| Step: 11
Training loss: 0.2487116488648312
Validation loss: 2.8810623528478096

Epoch: 397| Step: 0
Training loss: 0.41845569588126524
Validation loss: 2.877715877015936

Epoch: 5| Step: 1
Training loss: 0.3499254364391139
Validation loss: 2.8356395141026076

Epoch: 5| Step: 2
Training loss: 0.3972706257103102
Validation loss: 2.826270195991335

Epoch: 5| Step: 3
Training loss: 0.44400157714576527
Validation loss: 2.812636093096524

Epoch: 5| Step: 4
Training loss: 0.5673526355380635
Validation loss: 2.8323943929128568

Epoch: 5| Step: 5
Training loss: 0.3784947864949455
Validation loss: 2.821528633098351

Epoch: 5| Step: 6
Training loss: 0.45271414184120917
Validation loss: 2.7617343252876783

Epoch: 5| Step: 7
Training loss: 0.4432018353036466
Validation loss: 2.745084981549603

Epoch: 5| Step: 8
Training loss: 0.24776151718340025
Validation loss: 2.7940834115281223

Epoch: 5| Step: 9
Training loss: 0.43454414888980597
Validation loss: 2.797076525256299

Epoch: 5| Step: 10
Training loss: 0.3967099980654366
Validation loss: 2.798805405319791

Epoch: 5| Step: 11
Training loss: 0.43069039262135966
Validation loss: 2.835660502319643

Epoch: 398| Step: 0
Training loss: 0.3744681679919213
Validation loss: 2.796931910868183

Epoch: 5| Step: 1
Training loss: 0.3279247581197782
Validation loss: 2.804947082209632

Epoch: 5| Step: 2
Training loss: 0.30244486101324874
Validation loss: 2.8663731699688126

Epoch: 5| Step: 3
Training loss: 0.34937992771474613
Validation loss: 2.830180834759581

Epoch: 5| Step: 4
Training loss: 0.4809612912991458
Validation loss: 2.827669626882262

Epoch: 5| Step: 5
Training loss: 0.42091369601248485
Validation loss: 2.8129233642108127

Epoch: 5| Step: 6
Training loss: 0.42305234586748114
Validation loss: 2.7991464508824206

Epoch: 5| Step: 7
Training loss: 0.36457410074078767
Validation loss: 2.8314135910502345

Epoch: 5| Step: 8
Training loss: 0.4289118962706641
Validation loss: 2.8050031351558142

Epoch: 5| Step: 9
Training loss: 0.4467239764916199
Validation loss: 2.798817597516056

Epoch: 5| Step: 10
Training loss: 0.34249673309299566
Validation loss: 2.81981322007009

Epoch: 5| Step: 11
Training loss: 0.4058541974057771
Validation loss: 2.7416293562482856

Epoch: 399| Step: 0
Training loss: 0.2721801048833376
Validation loss: 2.8100358482078835

Epoch: 5| Step: 1
Training loss: 0.4775465982228703
Validation loss: 2.860929986987969

Epoch: 5| Step: 2
Training loss: 0.39593638994261526
Validation loss: 2.7309780746386734

Epoch: 5| Step: 3
Training loss: 0.46354059869307457
Validation loss: 2.7725709949527024

Epoch: 5| Step: 4
Training loss: 0.4091418847441059
Validation loss: 2.7597917365197517

Epoch: 5| Step: 5
Training loss: 0.40622314951269356
Validation loss: 2.803565871612415

Epoch: 5| Step: 6
Training loss: 0.33039445786001703
Validation loss: 2.8382101454483424

Epoch: 5| Step: 7
Training loss: 0.46932487204878176
Validation loss: 2.7618071682672993

Epoch: 5| Step: 8
Training loss: 0.37767148130397216
Validation loss: 2.7642792877812794

Epoch: 5| Step: 9
Training loss: 0.4617825213960347
Validation loss: 2.793562780133515

Epoch: 5| Step: 10
Training loss: 0.26804147406362167
Validation loss: 2.871830921298346

Epoch: 5| Step: 11
Training loss: 0.1340920643897205
Validation loss: 2.835426431639536

Epoch: 400| Step: 0
Training loss: 0.5273602235834767
Validation loss: 2.771033718397053

Epoch: 5| Step: 1
Training loss: 0.3030148345302779
Validation loss: 2.76674015386106

Epoch: 5| Step: 2
Training loss: 0.3835566547427654
Validation loss: 2.837094647978874

Epoch: 5| Step: 3
Training loss: 0.2669642569855858
Validation loss: 2.781100587010416

Epoch: 5| Step: 4
Training loss: 0.5830696111542503
Validation loss: 2.7970382138443255

Epoch: 5| Step: 5
Training loss: 0.3835397546372765
Validation loss: 2.7879017997903643

Epoch: 5| Step: 6
Training loss: 0.44897404515623535
Validation loss: 2.7890711908000245

Epoch: 5| Step: 7
Training loss: 0.439110686077852
Validation loss: 2.7750793468598336

Epoch: 5| Step: 8
Training loss: 0.37125341092735886
Validation loss: 2.797619200284233

Epoch: 5| Step: 9
Training loss: 0.4149647006568318
Validation loss: 2.7628055252523915

Epoch: 5| Step: 10
Training loss: 0.3341462373295635
Validation loss: 2.812103197575227

Epoch: 5| Step: 11
Training loss: 0.5029369761114757
Validation loss: 2.8179841614617205

Epoch: 401| Step: 0
Training loss: 0.3455508699645444
Validation loss: 2.7813785751854914

Epoch: 5| Step: 1
Training loss: 0.40155642983565065
Validation loss: 2.73100087843203

Epoch: 5| Step: 2
Training loss: 0.43286459846788783
Validation loss: 2.8171988336268488

Epoch: 5| Step: 3
Training loss: 0.545008608023882
Validation loss: 2.8130154102096356

Epoch: 5| Step: 4
Training loss: 0.6598220972676837
Validation loss: 2.84991695006984

Epoch: 5| Step: 5
Training loss: 0.37935309263572403
Validation loss: 2.758584527729773

Epoch: 5| Step: 6
Training loss: 0.515067232335878
Validation loss: 2.789074296685924

Epoch: 5| Step: 7
Training loss: 0.3606751185982231
Validation loss: 2.7732072009253237

Epoch: 5| Step: 8
Training loss: 0.33369956783844557
Validation loss: 2.825190681588221

Epoch: 5| Step: 9
Training loss: 0.39129150749357394
Validation loss: 2.825365184710011

Epoch: 5| Step: 10
Training loss: 0.30125268923085435
Validation loss: 2.8175451063355132

Epoch: 5| Step: 11
Training loss: 0.49917467367482826
Validation loss: 2.749118714293552

Epoch: 402| Step: 0
Training loss: 0.44899375920323387
Validation loss: 2.768708932427066

Epoch: 5| Step: 1
Training loss: 0.576874023883031
Validation loss: 2.776668657897092

Epoch: 5| Step: 2
Training loss: 0.5474630463988575
Validation loss: 2.750235818375391

Epoch: 5| Step: 3
Training loss: 0.3382114144497005
Validation loss: 2.791018621942732

Epoch: 5| Step: 4
Training loss: 0.42567220218868373
Validation loss: 2.7586210684700685

Epoch: 5| Step: 5
Training loss: 0.4859202869469923
Validation loss: 2.7422211111532064

Epoch: 5| Step: 6
Training loss: 0.6115228020010771
Validation loss: 2.877324853980572

Epoch: 5| Step: 7
Training loss: 0.41371606333217764
Validation loss: 2.784912701516367

Epoch: 5| Step: 8
Training loss: 0.4443144405321004
Validation loss: 2.7865261616279877

Epoch: 5| Step: 9
Training loss: 0.44470085837056395
Validation loss: 2.8213007244372164

Epoch: 5| Step: 10
Training loss: 0.45786091089611036
Validation loss: 2.769686523733448

Epoch: 5| Step: 11
Training loss: 0.4807093878328292
Validation loss: 2.7697884602054104

Epoch: 403| Step: 0
Training loss: 0.42038548626441374
Validation loss: 2.7946205429899518

Epoch: 5| Step: 1
Training loss: 0.3022076978314324
Validation loss: 2.737889681330779

Epoch: 5| Step: 2
Training loss: 0.4246890732860265
Validation loss: 2.731238644559578

Epoch: 5| Step: 3
Training loss: 0.35527001579025214
Validation loss: 2.798146763219121

Epoch: 5| Step: 4
Training loss: 0.26258742942770974
Validation loss: 2.6969983601268703

Epoch: 5| Step: 5
Training loss: 0.4119246552481357
Validation loss: 2.7966640364434108

Epoch: 5| Step: 6
Training loss: 0.5606087308243262
Validation loss: 2.7870768826075882

Epoch: 5| Step: 7
Training loss: 0.43969052154435473
Validation loss: 2.7717130215871277

Epoch: 5| Step: 8
Training loss: 0.5376238491735179
Validation loss: 2.7990242675711876

Epoch: 5| Step: 9
Training loss: 0.31296409477774945
Validation loss: 2.771854797943365

Epoch: 5| Step: 10
Training loss: 0.39915043494578234
Validation loss: 2.8047244212094404

Epoch: 5| Step: 11
Training loss: 0.19039871746485776
Validation loss: 2.764145615303658

Epoch: 404| Step: 0
Training loss: 0.429121407495757
Validation loss: 2.7408519401529556

Epoch: 5| Step: 1
Training loss: 0.21531308668192314
Validation loss: 2.7847800658400015

Epoch: 5| Step: 2
Training loss: 0.4197337061654416
Validation loss: 2.7420784764656707

Epoch: 5| Step: 3
Training loss: 0.490068947286367
Validation loss: 2.776998256077469

Epoch: 5| Step: 4
Training loss: 0.5275773555298657
Validation loss: 2.8343186885647262

Epoch: 5| Step: 5
Training loss: 0.32021274408906775
Validation loss: 2.763965450011352

Epoch: 5| Step: 6
Training loss: 0.2784895131629659
Validation loss: 2.818016131800929

Epoch: 5| Step: 7
Training loss: 0.5622781209973632
Validation loss: 2.8502565502676687

Epoch: 5| Step: 8
Training loss: 0.4767385220248663
Validation loss: 2.7556830768171188

Epoch: 5| Step: 9
Training loss: 0.40290130944293684
Validation loss: 2.7826711117186944

Epoch: 5| Step: 10
Training loss: 0.31303898107611455
Validation loss: 2.8151515435611763

Epoch: 5| Step: 11
Training loss: 0.37104750897268274
Validation loss: 2.762557528689346

Epoch: 405| Step: 0
Training loss: 0.39811615046272875
Validation loss: 2.788723323938945

Epoch: 5| Step: 1
Training loss: 0.35082555461348497
Validation loss: 2.7731327122232927

Epoch: 5| Step: 2
Training loss: 0.3956311633999446
Validation loss: 2.7227973919647837

Epoch: 5| Step: 3
Training loss: 0.4788584201444869
Validation loss: 2.80432712077924

Epoch: 5| Step: 4
Training loss: 0.3618012089182456
Validation loss: 2.84003658068519

Epoch: 5| Step: 5
Training loss: 0.2988040390779589
Validation loss: 2.7591700216031185

Epoch: 5| Step: 6
Training loss: 0.4196367582208423
Validation loss: 2.8266888830785875

Epoch: 5| Step: 7
Training loss: 0.2681156106340766
Validation loss: 2.821180613330286

Epoch: 5| Step: 8
Training loss: 0.5497925453810218
Validation loss: 2.8195654001948602

Epoch: 5| Step: 9
Training loss: 0.40755379974036304
Validation loss: 2.8796014692537337

Epoch: 5| Step: 10
Training loss: 0.4234519027005981
Validation loss: 2.8101310607952037

Epoch: 5| Step: 11
Training loss: 0.5879112823000053
Validation loss: 2.7788004070977594

Epoch: 406| Step: 0
Training loss: 0.3790372445104796
Validation loss: 2.8221597020248717

Epoch: 5| Step: 1
Training loss: 0.30646565784922153
Validation loss: 2.790226277697397

Epoch: 5| Step: 2
Training loss: 0.37423930898110863
Validation loss: 2.8034919237787377

Epoch: 5| Step: 3
Training loss: 0.3712159407369913
Validation loss: 2.7975792060448064

Epoch: 5| Step: 4
Training loss: 0.25785701540789835
Validation loss: 2.819764116535712

Epoch: 5| Step: 5
Training loss: 0.36416972631890265
Validation loss: 2.826954492253515

Epoch: 5| Step: 6
Training loss: 0.44766910128429677
Validation loss: 2.7900254326348257

Epoch: 5| Step: 7
Training loss: 0.2989283374974927
Validation loss: 2.800049885379229

Epoch: 5| Step: 8
Training loss: 0.39725307118433195
Validation loss: 2.7566515610564313

Epoch: 5| Step: 9
Training loss: 0.3427149187438921
Validation loss: 2.8565742102772695

Epoch: 5| Step: 10
Training loss: 0.5802068342763642
Validation loss: 2.8001455226616296

Epoch: 5| Step: 11
Training loss: 0.37522480107582434
Validation loss: 2.8565186163470764

Epoch: 407| Step: 0
Training loss: 0.4844179134432694
Validation loss: 2.829912214591346

Epoch: 5| Step: 1
Training loss: 0.40277657791850535
Validation loss: 2.8529197424055877

Epoch: 5| Step: 2
Training loss: 0.37729603483485913
Validation loss: 2.8312179449932047

Epoch: 5| Step: 3
Training loss: 0.37461123580390904
Validation loss: 2.7601953969598503

Epoch: 5| Step: 4
Training loss: 0.48427080756559554
Validation loss: 2.7750296379202064

Epoch: 5| Step: 5
Training loss: 0.38339162345346095
Validation loss: 2.8177742212927757

Epoch: 5| Step: 6
Training loss: 0.45297549510827484
Validation loss: 2.8293801537999

Epoch: 5| Step: 7
Training loss: 0.3938595558826211
Validation loss: 2.8058380239436347

Epoch: 5| Step: 8
Training loss: 0.2888097302267486
Validation loss: 2.7938569228372985

Epoch: 5| Step: 9
Training loss: 0.39086548078587957
Validation loss: 2.7772687248186854

Epoch: 5| Step: 10
Training loss: 0.5253794502289463
Validation loss: 2.7569590860955455

Epoch: 5| Step: 11
Training loss: 0.24290980025631354
Validation loss: 2.809712915179362

Epoch: 408| Step: 0
Training loss: 0.3423801023786211
Validation loss: 2.820815459795344

Epoch: 5| Step: 1
Training loss: 0.3867454712238249
Validation loss: 2.818202207557738

Epoch: 5| Step: 2
Training loss: 0.39260141104344043
Validation loss: 2.813071609619848

Epoch: 5| Step: 3
Training loss: 0.22060684196919497
Validation loss: 2.840318223022242

Epoch: 5| Step: 4
Training loss: 0.4760780686442892
Validation loss: 2.73284049073402

Epoch: 5| Step: 5
Training loss: 0.4496617330627374
Validation loss: 2.8201260949806173

Epoch: 5| Step: 6
Training loss: 0.5040509807124179
Validation loss: 2.7452983183504434

Epoch: 5| Step: 7
Training loss: 0.30285207859813573
Validation loss: 2.8343931079077187

Epoch: 5| Step: 8
Training loss: 0.36460753315128736
Validation loss: 2.7273431369092753

Epoch: 5| Step: 9
Training loss: 0.6614312719581568
Validation loss: 2.8247529048376374

Epoch: 5| Step: 10
Training loss: 0.18527697960919792
Validation loss: 2.7725770681222404

Epoch: 5| Step: 11
Training loss: 0.20753625241399576
Validation loss: 2.7557212944593634

Epoch: 409| Step: 0
Training loss: 0.322480471115847
Validation loss: 2.7787419951702987

Epoch: 5| Step: 1
Training loss: 0.5138893392348965
Validation loss: 2.735143077694772

Epoch: 5| Step: 2
Training loss: 0.435549509356961
Validation loss: 2.8009442965170996

Epoch: 5| Step: 3
Training loss: 0.3947499113052587
Validation loss: 2.7674083491630217

Epoch: 5| Step: 4
Training loss: 0.36190135952045116
Validation loss: 2.7656356322807927

Epoch: 5| Step: 5
Training loss: 0.33190280449410203
Validation loss: 2.7196575162879126

Epoch: 5| Step: 6
Training loss: 0.22878197691413354
Validation loss: 2.772556157731528

Epoch: 5| Step: 7
Training loss: 0.33211809032475675
Validation loss: 2.858484692407617

Epoch: 5| Step: 8
Training loss: 0.2846124506576598
Validation loss: 2.8395694948299077

Epoch: 5| Step: 9
Training loss: 0.35393760323325096
Validation loss: 2.779724938817931

Epoch: 5| Step: 10
Training loss: 0.4035011421846865
Validation loss: 2.7842958466895538

Epoch: 5| Step: 11
Training loss: 0.22962712318277773
Validation loss: 2.7554231204206276

Epoch: 410| Step: 0
Training loss: 0.39204602216345263
Validation loss: 2.785657094870834

Epoch: 5| Step: 1
Training loss: 0.36725798397071974
Validation loss: 2.719137889406019

Epoch: 5| Step: 2
Training loss: 0.48734786276199477
Validation loss: 2.8423109395807824

Epoch: 5| Step: 3
Training loss: 0.42338873241038305
Validation loss: 2.785899562010417

Epoch: 5| Step: 4
Training loss: 0.3861634670162605
Validation loss: 2.7464492951143398

Epoch: 5| Step: 5
Training loss: 0.3983906363059983
Validation loss: 2.876831152238773

Epoch: 5| Step: 6
Training loss: 0.48360052026992023
Validation loss: 2.8049086587146834

Epoch: 5| Step: 7
Training loss: 0.4661331565738662
Validation loss: 2.834235364480843

Epoch: 5| Step: 8
Training loss: 0.35451240586981386
Validation loss: 2.8024891709519175

Epoch: 5| Step: 9
Training loss: 0.32123513044462093
Validation loss: 2.8314198888596116

Epoch: 5| Step: 10
Training loss: 0.32193812288369567
Validation loss: 2.804914123531812

Epoch: 5| Step: 11
Training loss: 0.27048026815710846
Validation loss: 2.788493998740806

Epoch: 411| Step: 0
Training loss: 0.35706198662270755
Validation loss: 2.8669958682902537

Epoch: 5| Step: 1
Training loss: 0.4108034930731163
Validation loss: 2.872795076658014

Epoch: 5| Step: 2
Training loss: 0.4279853572178931
Validation loss: 2.762632719652084

Epoch: 5| Step: 3
Training loss: 0.3885399292539694
Validation loss: 2.857265010064574

Epoch: 5| Step: 4
Training loss: 0.542012559662527
Validation loss: 2.766908861287271

Epoch: 5| Step: 5
Training loss: 0.3337538297126296
Validation loss: 2.7637421903438066

Epoch: 5| Step: 6
Training loss: 0.47955217782521287
Validation loss: 2.801569981448894

Epoch: 5| Step: 7
Training loss: 0.37983866143280204
Validation loss: 2.8117587878899206

Epoch: 5| Step: 8
Training loss: 0.36149618003800243
Validation loss: 2.8296062145357515

Epoch: 5| Step: 9
Training loss: 0.4104884301133745
Validation loss: 2.8272313063560053

Epoch: 5| Step: 10
Training loss: 0.41434433180609
Validation loss: 2.7601941444868605

Epoch: 5| Step: 11
Training loss: 0.3785324022100299
Validation loss: 2.8421179591125223

Epoch: 412| Step: 0
Training loss: 0.40415139275952344
Validation loss: 2.8355184478392843

Epoch: 5| Step: 1
Training loss: 0.5072210829376029
Validation loss: 2.841062397114868

Epoch: 5| Step: 2
Training loss: 0.31674819882775734
Validation loss: 2.772701244503308

Epoch: 5| Step: 3
Training loss: 0.3579382787795576
Validation loss: 2.8403995674860525

Epoch: 5| Step: 4
Training loss: 0.4966239648928682
Validation loss: 2.79912695983074

Epoch: 5| Step: 5
Training loss: 0.47649580066627767
Validation loss: 2.7863770779084587

Epoch: 5| Step: 6
Training loss: 0.4116889291347301
Validation loss: 2.811492919756247

Epoch: 5| Step: 7
Training loss: 0.47964248321736935
Validation loss: 2.8300487059579433

Epoch: 5| Step: 8
Training loss: 0.3684316416590938
Validation loss: 2.768801508267236

Epoch: 5| Step: 9
Training loss: 0.3804750116917875
Validation loss: 2.8293360862137287

Epoch: 5| Step: 10
Training loss: 0.36326406294661473
Validation loss: 2.828992805326178

Epoch: 5| Step: 11
Training loss: 0.14683435592956504
Validation loss: 2.8105333269158113

Epoch: 413| Step: 0
Training loss: 0.362613536056516
Validation loss: 2.834454666330319

Epoch: 5| Step: 1
Training loss: 0.44626513861508177
Validation loss: 2.8280045569750496

Epoch: 5| Step: 2
Training loss: 0.5005683648771684
Validation loss: 2.8181039540671136

Epoch: 5| Step: 3
Training loss: 0.5447479572109034
Validation loss: 2.8307410622738383

Epoch: 5| Step: 4
Training loss: 0.31486254747185866
Validation loss: 2.7973694284391186

Epoch: 5| Step: 5
Training loss: 0.3823416792389074
Validation loss: 2.8588442735482866

Epoch: 5| Step: 6
Training loss: 0.7182231298851792
Validation loss: 2.825839381858797

Epoch: 5| Step: 7
Training loss: 0.26206588498018935
Validation loss: 2.823423070401008

Epoch: 5| Step: 8
Training loss: 0.3574289415004895
Validation loss: 2.8581650993525574

Epoch: 5| Step: 9
Training loss: 0.4038798259008761
Validation loss: 2.7672590934672243

Epoch: 5| Step: 10
Training loss: 0.3263696310886697
Validation loss: 2.8592838870403527

Epoch: 5| Step: 11
Training loss: 0.404734407011469
Validation loss: 2.7700955704212675

Epoch: 414| Step: 0
Training loss: 0.4168747104374968
Validation loss: 2.7728325161583505

Epoch: 5| Step: 1
Training loss: 0.42262055604161475
Validation loss: 2.772595033160622

Epoch: 5| Step: 2
Training loss: 0.45956418365269713
Validation loss: 2.837167800525127

Epoch: 5| Step: 3
Training loss: 0.36052189138029983
Validation loss: 2.8383269459183467

Epoch: 5| Step: 4
Training loss: 0.383882254043503
Validation loss: 2.7734013228228447

Epoch: 5| Step: 5
Training loss: 0.5212023826273856
Validation loss: 2.7885275113061536

Epoch: 5| Step: 6
Training loss: 0.4312576735546347
Validation loss: 2.754810900709135

Epoch: 5| Step: 7
Training loss: 0.504833196862069
Validation loss: 2.8072868139523455

Epoch: 5| Step: 8
Training loss: 0.3311219836227623
Validation loss: 2.760589894071596

Epoch: 5| Step: 9
Training loss: 0.33790556372986735
Validation loss: 2.759633195403469

Epoch: 5| Step: 10
Training loss: 0.3742643531615582
Validation loss: 2.782292638502638

Epoch: 5| Step: 11
Training loss: 0.3986923674187492
Validation loss: 2.7922204426802235

Epoch: 415| Step: 0
Training loss: 0.42776149507011435
Validation loss: 2.767969897459551

Epoch: 5| Step: 1
Training loss: 0.32243881195889884
Validation loss: 2.8501548253775524

Epoch: 5| Step: 2
Training loss: 0.41449173685426294
Validation loss: 2.8092791570312667

Epoch: 5| Step: 3
Training loss: 0.48383488844239325
Validation loss: 2.7585996561663304

Epoch: 5| Step: 4
Training loss: 0.3016658630522848
Validation loss: 2.7761585945758935

Epoch: 5| Step: 5
Training loss: 0.3269469936256255
Validation loss: 2.7902818537896943

Epoch: 5| Step: 6
Training loss: 0.4059020533073464
Validation loss: 2.7853530557445345

Epoch: 5| Step: 7
Training loss: 0.3282482846579144
Validation loss: 2.7125863439467777

Epoch: 5| Step: 8
Training loss: 0.32741442443191215
Validation loss: 2.75235619536304

Epoch: 5| Step: 9
Training loss: 0.36235967254856744
Validation loss: 2.8022319702281737

Epoch: 5| Step: 10
Training loss: 0.33538864455048223
Validation loss: 2.75890522490047

Epoch: 5| Step: 11
Training loss: 0.42598960748048914
Validation loss: 2.8487050846431745

Epoch: 416| Step: 0
Training loss: 0.40119856287840516
Validation loss: 2.750345017002153

Epoch: 5| Step: 1
Training loss: 0.4433510733343959
Validation loss: 2.79024589500949

Epoch: 5| Step: 2
Training loss: 0.3693871053658136
Validation loss: 2.7816844093731334

Epoch: 5| Step: 3
Training loss: 0.4048338930909543
Validation loss: 2.80326613145702

Epoch: 5| Step: 4
Training loss: 0.3248976298644669
Validation loss: 2.8104062516849204

Epoch: 5| Step: 5
Training loss: 0.32844112699122974
Validation loss: 2.818727874105133

Epoch: 5| Step: 6
Training loss: 0.36594248786999584
Validation loss: 2.8204331341390136

Epoch: 5| Step: 7
Training loss: 0.47123319608542846
Validation loss: 2.8443025132595396

Epoch: 5| Step: 8
Training loss: 0.3873817463373836
Validation loss: 2.7784225257347313

Epoch: 5| Step: 9
Training loss: 0.37499819198808326
Validation loss: 2.7844670795324222

Epoch: 5| Step: 10
Training loss: 0.3330698486894689
Validation loss: 2.884988182606727

Epoch: 5| Step: 11
Training loss: 0.3029749253004183
Validation loss: 2.779757134757389

Epoch: 417| Step: 0
Training loss: 0.3307024226551812
Validation loss: 2.818850968970894

Epoch: 5| Step: 1
Training loss: 0.33489156510682067
Validation loss: 2.7881474921829907

Epoch: 5| Step: 2
Training loss: 0.4350898808490364
Validation loss: 2.84414800716225

Epoch: 5| Step: 3
Training loss: 0.3863507456082485
Validation loss: 2.8551069796717656

Epoch: 5| Step: 4
Training loss: 0.5353684387553131
Validation loss: 2.74772838490248

Epoch: 5| Step: 5
Training loss: 0.3615945400921398
Validation loss: 2.770069692305345

Epoch: 5| Step: 6
Training loss: 0.4244122150098296
Validation loss: 2.732203724141886

Epoch: 5| Step: 7
Training loss: 0.3185200432065599
Validation loss: 2.7748955990509487

Epoch: 5| Step: 8
Training loss: 0.40055702287390793
Validation loss: 2.815445470219892

Epoch: 5| Step: 9
Training loss: 0.29665779650791485
Validation loss: 2.8238510026074075

Epoch: 5| Step: 10
Training loss: 0.33780723160085857
Validation loss: 2.8197859662696727

Epoch: 5| Step: 11
Training loss: 0.3779921566298314
Validation loss: 2.766284565842512

Epoch: 418| Step: 0
Training loss: 0.30474984924901
Validation loss: 2.803363427292828

Epoch: 5| Step: 1
Training loss: 0.27533205911133296
Validation loss: 2.7945393305629596

Epoch: 5| Step: 2
Training loss: 0.3615792304069456
Validation loss: 2.795207981311368

Epoch: 5| Step: 3
Training loss: 0.3471616162283607
Validation loss: 2.706339833601774

Epoch: 5| Step: 4
Training loss: 0.5213955006964626
Validation loss: 2.7302658485914577

Epoch: 5| Step: 5
Training loss: 0.3180538654051123
Validation loss: 2.819924497816722

Epoch: 5| Step: 6
Training loss: 0.3181414648265741
Validation loss: 2.8342086261593904

Epoch: 5| Step: 7
Training loss: 0.43797766631158735
Validation loss: 2.7245922019718094

Epoch: 5| Step: 8
Training loss: 0.4894985741096747
Validation loss: 2.7065694817869677

Epoch: 5| Step: 9
Training loss: 0.4436525728165079
Validation loss: 2.8006706801206924

Epoch: 5| Step: 10
Training loss: 0.4220146371960586
Validation loss: 2.772262496269216

Epoch: 5| Step: 11
Training loss: 0.4379780235492749
Validation loss: 2.7359696742732527

Epoch: 419| Step: 0
Training loss: 0.3756777281733379
Validation loss: 2.809832190687626

Epoch: 5| Step: 1
Training loss: 0.44875353067969614
Validation loss: 2.748331967486113

Epoch: 5| Step: 2
Training loss: 0.3735908217496837
Validation loss: 2.776246942990501

Epoch: 5| Step: 3
Training loss: 0.3625574592564773
Validation loss: 2.842306724509758

Epoch: 5| Step: 4
Training loss: 0.30226747748388255
Validation loss: 2.760091731302396

Epoch: 5| Step: 5
Training loss: 0.3677443076989166
Validation loss: 2.826504972205295

Epoch: 5| Step: 6
Training loss: 0.3068678069000026
Validation loss: 2.788898730345084

Epoch: 5| Step: 7
Training loss: 0.3828760989550425
Validation loss: 2.7856348490567657

Epoch: 5| Step: 8
Training loss: 0.4752088928163617
Validation loss: 2.810464899786461

Epoch: 5| Step: 9
Training loss: 0.3872359314339924
Validation loss: 2.8274910147715575

Epoch: 5| Step: 10
Training loss: 0.4165884918151178
Validation loss: 2.815223992426802

Epoch: 5| Step: 11
Training loss: 0.4529997060461122
Validation loss: 2.8448575591300793

Epoch: 420| Step: 0
Training loss: 0.43217280105673106
Validation loss: 2.812652520176799

Epoch: 5| Step: 1
Training loss: 0.4726247225248324
Validation loss: 2.8476583012493686

Epoch: 5| Step: 2
Training loss: 0.4669317744867415
Validation loss: 2.8553530473485758

Epoch: 5| Step: 3
Training loss: 0.48984454335904404
Validation loss: 2.8615440417381057

Epoch: 5| Step: 4
Training loss: 0.37973325477230496
Validation loss: 2.8368722690429897

Epoch: 5| Step: 5
Training loss: 0.2827759513632576
Validation loss: 2.7431366954075247

Epoch: 5| Step: 6
Training loss: 0.47739829580576554
Validation loss: 2.7883780073139217

Epoch: 5| Step: 7
Training loss: 0.523487316437016
Validation loss: 2.823614098846019

Epoch: 5| Step: 8
Training loss: 0.43378131692936817
Validation loss: 2.8690010956140197

Epoch: 5| Step: 9
Training loss: 0.2343778768998645
Validation loss: 2.854412939533535

Epoch: 5| Step: 10
Training loss: 0.5032747732869061
Validation loss: 2.7657538274440667

Epoch: 5| Step: 11
Training loss: 0.2529084185638463
Validation loss: 2.8440398637928235

Epoch: 421| Step: 0
Training loss: 0.45220256506151446
Validation loss: 2.8465701117563684

Epoch: 5| Step: 1
Training loss: 0.4003035846167094
Validation loss: 2.82011725330192

Epoch: 5| Step: 2
Training loss: 0.563543913996006
Validation loss: 2.839598829227594

Epoch: 5| Step: 3
Training loss: 0.3941569677467498
Validation loss: 2.8560970013609683

Epoch: 5| Step: 4
Training loss: 0.34596317015103784
Validation loss: 2.7835148508497896

Epoch: 5| Step: 5
Training loss: 0.3397057790321366
Validation loss: 2.819388328869708

Epoch: 5| Step: 6
Training loss: 0.5166160134383735
Validation loss: 2.7780565151130765

Epoch: 5| Step: 7
Training loss: 0.40214413255681897
Validation loss: 2.8281664274493865

Epoch: 5| Step: 8
Training loss: 0.3759907112927244
Validation loss: 2.8009311524182734

Epoch: 5| Step: 9
Training loss: 0.2857170990928861
Validation loss: 2.809691227536463

Epoch: 5| Step: 10
Training loss: 0.39961511825953827
Validation loss: 2.767631603828928

Epoch: 5| Step: 11
Training loss: 0.13252520341758608
Validation loss: 2.734417086686082

Epoch: 422| Step: 0
Training loss: 0.6720192333034893
Validation loss: 2.8250760386088216

Epoch: 5| Step: 1
Training loss: 0.2915080212377714
Validation loss: 2.7869706844475695

Epoch: 5| Step: 2
Training loss: 0.3849961031060114
Validation loss: 2.7894505605706765

Epoch: 5| Step: 3
Training loss: 0.23137795800163233
Validation loss: 2.8316618860468963

Epoch: 5| Step: 4
Training loss: 0.37921116545094324
Validation loss: 2.7943860954884037

Epoch: 5| Step: 5
Training loss: 0.42315150452605205
Validation loss: 2.776023737054482

Epoch: 5| Step: 6
Training loss: 0.5059415242422092
Validation loss: 2.7641431786274597

Epoch: 5| Step: 7
Training loss: 0.47776375693471795
Validation loss: 2.767480551023296

Epoch: 5| Step: 8
Training loss: 0.44370471427765307
Validation loss: 2.8101472798086675

Epoch: 5| Step: 9
Training loss: 0.34433187740916105
Validation loss: 2.7899137065330937

Epoch: 5| Step: 10
Training loss: 0.45687924000850844
Validation loss: 2.778406968913486

Epoch: 5| Step: 11
Training loss: 0.424610558361661
Validation loss: 2.85923957504009

Epoch: 423| Step: 0
Training loss: 0.42726140458057055
Validation loss: 2.818893195248692

Epoch: 5| Step: 1
Training loss: 0.3346017741449558
Validation loss: 2.860416983354129

Epoch: 5| Step: 2
Training loss: 0.32558564367435516
Validation loss: 2.8119794222516075

Epoch: 5| Step: 3
Training loss: 0.2542242992571528
Validation loss: 2.863693728016895

Epoch: 5| Step: 4
Training loss: 0.45080900255584155
Validation loss: 2.871116267870703

Epoch: 5| Step: 5
Training loss: 0.378111329895588
Validation loss: 2.7846537917479326

Epoch: 5| Step: 6
Training loss: 0.5262964657636755
Validation loss: 2.833183741594158

Epoch: 5| Step: 7
Training loss: 0.3240169448615947
Validation loss: 2.785882092843291

Epoch: 5| Step: 8
Training loss: 0.4880888750675578
Validation loss: 2.7812017622347063

Epoch: 5| Step: 9
Training loss: 0.4390793121757326
Validation loss: 2.7741240533672906

Epoch: 5| Step: 10
Training loss: 0.23654576203305974
Validation loss: 2.7522812650620327

Epoch: 5| Step: 11
Training loss: 0.40279224546070025
Validation loss: 2.8065811076586447

Epoch: 424| Step: 0
Training loss: 0.4679643563906544
Validation loss: 2.8063992064867813

Epoch: 5| Step: 1
Training loss: 0.4808410969536609
Validation loss: 2.744872232566115

Epoch: 5| Step: 2
Training loss: 0.3299500369229898
Validation loss: 2.7616548616248697

Epoch: 5| Step: 3
Training loss: 0.3585718135731258
Validation loss: 2.7694998462727694

Epoch: 5| Step: 4
Training loss: 0.3671335018304829
Validation loss: 2.782095266332473

Epoch: 5| Step: 5
Training loss: 0.4453869138414826
Validation loss: 2.8203407208694182

Epoch: 5| Step: 6
Training loss: 0.43479659800466336
Validation loss: 2.769825487957309

Epoch: 5| Step: 7
Training loss: 0.46092731658548713
Validation loss: 2.79376402872021

Epoch: 5| Step: 8
Training loss: 0.33617718595989926
Validation loss: 2.7725420871999407

Epoch: 5| Step: 9
Training loss: 0.4609079836430587
Validation loss: 2.7110227485320495

Epoch: 5| Step: 10
Training loss: 0.33505944897045814
Validation loss: 2.7757540345658382

Epoch: 5| Step: 11
Training loss: 0.12165150323637518
Validation loss: 2.840828705083856

Epoch: 425| Step: 0
Training loss: 0.4817118651584487
Validation loss: 2.773091211325911

Epoch: 5| Step: 1
Training loss: 0.5066258577593195
Validation loss: 2.8396338202022466

Epoch: 5| Step: 2
Training loss: 0.39190869166753733
Validation loss: 2.832399941484289

Epoch: 5| Step: 3
Training loss: 0.43652777274963805
Validation loss: 2.8013685595814377

Epoch: 5| Step: 4
Training loss: 0.3818391765642469
Validation loss: 2.7589485486947907

Epoch: 5| Step: 5
Training loss: 0.5897508257495877
Validation loss: 2.7978051022527275

Epoch: 5| Step: 6
Training loss: 0.5459817403108539
Validation loss: 2.7553949863737106

Epoch: 5| Step: 7
Training loss: 0.3614620269931126
Validation loss: 2.78261215628274

Epoch: 5| Step: 8
Training loss: 0.35190223596910764
Validation loss: 2.765714155437553

Epoch: 5| Step: 9
Training loss: 0.30179419190203827
Validation loss: 2.8264588353351145

Epoch: 5| Step: 10
Training loss: 0.3295429337638302
Validation loss: 2.7432940352600523

Epoch: 5| Step: 11
Training loss: 0.08743621659955984
Validation loss: 2.7948544269974236

Epoch: 426| Step: 0
Training loss: 0.30647650050019914
Validation loss: 2.792609771920581

Epoch: 5| Step: 1
Training loss: 0.3859403463405406
Validation loss: 2.765381096467501

Epoch: 5| Step: 2
Training loss: 0.4353933363083455
Validation loss: 2.8068990373852776

Epoch: 5| Step: 3
Training loss: 0.4903280768950131
Validation loss: 2.78655504552028

Epoch: 5| Step: 4
Training loss: 0.25131762000301827
Validation loss: 2.747986605556518

Epoch: 5| Step: 5
Training loss: 0.33830533459494494
Validation loss: 2.7592914171185683

Epoch: 5| Step: 6
Training loss: 0.39113103514343406
Validation loss: 2.7394542023040933

Epoch: 5| Step: 7
Training loss: 0.3946752946224407
Validation loss: 2.8079021523749557

Epoch: 5| Step: 8
Training loss: 0.2827262283167635
Validation loss: 2.774730259297728

Epoch: 5| Step: 9
Training loss: 0.3618186919723158
Validation loss: 2.798606961428393

Epoch: 5| Step: 10
Training loss: 0.3800287432215026
Validation loss: 2.763853806257569

Epoch: 5| Step: 11
Training loss: 0.23621594312211128
Validation loss: 2.8233769746509094

Epoch: 427| Step: 0
Training loss: 0.41977518757674004
Validation loss: 2.75514493820051

Epoch: 5| Step: 1
Training loss: 0.26304658285316806
Validation loss: 2.783766458174642

Epoch: 5| Step: 2
Training loss: 0.5132571965218002
Validation loss: 2.7341293333594163

Epoch: 5| Step: 3
Training loss: 0.4489223331553836
Validation loss: 2.787112258521132

Epoch: 5| Step: 4
Training loss: 0.5160183417734595
Validation loss: 2.855402046812638

Epoch: 5| Step: 5
Training loss: 0.41957288922579755
Validation loss: 2.7998487373490852

Epoch: 5| Step: 6
Training loss: 0.2757098735049334
Validation loss: 2.825682011708182

Epoch: 5| Step: 7
Training loss: 0.3944741009404672
Validation loss: 2.792094964057878

Epoch: 5| Step: 8
Training loss: 0.48150481191054884
Validation loss: 2.839494577915966

Epoch: 5| Step: 9
Training loss: 0.6746785422751298
Validation loss: 2.7991292666811556

Epoch: 5| Step: 10
Training loss: 0.4395830428618184
Validation loss: 2.88565276427473

Epoch: 5| Step: 11
Training loss: 0.2686539067868045
Validation loss: 2.839007041416078

Epoch: 428| Step: 0
Training loss: 0.4114150756920819
Validation loss: 2.836171020617527

Epoch: 5| Step: 1
Training loss: 0.2832836825797098
Validation loss: 2.801009867128141

Epoch: 5| Step: 2
Training loss: 0.36195727037393977
Validation loss: 2.8521322055769156

Epoch: 5| Step: 3
Training loss: 0.44451535134469816
Validation loss: 2.834855275118333

Epoch: 5| Step: 4
Training loss: 0.4823931171942368
Validation loss: 2.8457920197596724

Epoch: 5| Step: 5
Training loss: 0.5399053866894022
Validation loss: 2.827282476239939

Epoch: 5| Step: 6
Training loss: 0.3993482092406821
Validation loss: 2.7478232583073563

Epoch: 5| Step: 7
Training loss: 0.3701470999595218
Validation loss: 2.7762920464737193

Epoch: 5| Step: 8
Training loss: 0.3078217567949624
Validation loss: 2.8331279201003023

Epoch: 5| Step: 9
Training loss: 0.4357004792870299
Validation loss: 2.8026436856403216

Epoch: 5| Step: 10
Training loss: 0.39320738734211375
Validation loss: 2.715572488070029

Epoch: 5| Step: 11
Training loss: 0.29125838427284023
Validation loss: 2.841457868458029

Epoch: 429| Step: 0
Training loss: 0.393486414588811
Validation loss: 2.7834330716984255

Epoch: 5| Step: 1
Training loss: 0.2395078636941103
Validation loss: 2.825924377219703

Epoch: 5| Step: 2
Training loss: 0.6101116960306343
Validation loss: 2.820446581836608

Epoch: 5| Step: 3
Training loss: 0.37700267327749626
Validation loss: 2.8522559137193055

Epoch: 5| Step: 4
Training loss: 0.3577569526967087
Validation loss: 2.770544221083267

Epoch: 5| Step: 5
Training loss: 0.3511056262572415
Validation loss: 2.8473764394589614

Epoch: 5| Step: 6
Training loss: 0.36806589937769807
Validation loss: 2.80382066115808

Epoch: 5| Step: 7
Training loss: 0.3675038010212521
Validation loss: 2.787951956233758

Epoch: 5| Step: 8
Training loss: 0.2900330770883224
Validation loss: 2.768236595686917

Epoch: 5| Step: 9
Training loss: 0.4012832739512874
Validation loss: 2.815714309777564

Epoch: 5| Step: 10
Training loss: 0.5675042132502705
Validation loss: 2.758390504747794

Epoch: 5| Step: 11
Training loss: 0.2661257679660766
Validation loss: 2.8019682294515666

Epoch: 430| Step: 0
Training loss: 0.29002552450418867
Validation loss: 2.8364628742156923

Epoch: 5| Step: 1
Training loss: 0.4167957960148782
Validation loss: 2.763036169979713

Epoch: 5| Step: 2
Training loss: 0.28119652292681396
Validation loss: 2.7725139817532267

Epoch: 5| Step: 3
Training loss: 0.37346605646609493
Validation loss: 2.788463321583192

Epoch: 5| Step: 4
Training loss: 0.3036151133789066
Validation loss: 2.8279935233675073

Epoch: 5| Step: 5
Training loss: 0.22408272741038876
Validation loss: 2.8173800375322573

Epoch: 5| Step: 6
Training loss: 0.3659379679272117
Validation loss: 2.8061910051008314

Epoch: 5| Step: 7
Training loss: 0.34667613067951486
Validation loss: 2.8008416070468787

Epoch: 5| Step: 8
Training loss: 0.3850557811381832
Validation loss: 2.821176560358332

Epoch: 5| Step: 9
Training loss: 0.41807859528203567
Validation loss: 2.8744932363840516

Epoch: 5| Step: 10
Training loss: 0.5557535967571028
Validation loss: 2.8032630661013775

Epoch: 5| Step: 11
Training loss: 0.35548723612914074
Validation loss: 2.7717530772429293

Epoch: 431| Step: 0
Training loss: 0.4264656306233975
Validation loss: 2.7538329130467654

Epoch: 5| Step: 1
Training loss: 0.3468976262591718
Validation loss: 2.8527458835958

Epoch: 5| Step: 2
Training loss: 0.41028825361399196
Validation loss: 2.789758963940294

Epoch: 5| Step: 3
Training loss: 0.5386594011551312
Validation loss: 2.803249975400368

Epoch: 5| Step: 4
Training loss: 0.43033644482846717
Validation loss: 2.807374338455538

Epoch: 5| Step: 5
Training loss: 0.384374700716724
Validation loss: 2.8147815033623274

Epoch: 5| Step: 6
Training loss: 0.3168505739545146
Validation loss: 2.7802968445732628

Epoch: 5| Step: 7
Training loss: 0.31424475216561676
Validation loss: 2.7763302004784984

Epoch: 5| Step: 8
Training loss: 0.4410901583593922
Validation loss: 2.7401670890408543

Epoch: 5| Step: 9
Training loss: 0.2623102279839182
Validation loss: 2.7886947261132153

Epoch: 5| Step: 10
Training loss: 0.46681918805155664
Validation loss: 2.765461559459091

Epoch: 5| Step: 11
Training loss: 0.33565837885926725
Validation loss: 2.7855948860275896

Epoch: 432| Step: 0
Training loss: 0.3923483788366503
Validation loss: 2.845739304612116

Epoch: 5| Step: 1
Training loss: 0.3572969895940413
Validation loss: 2.7247262653904136

Epoch: 5| Step: 2
Training loss: 0.28028473515618685
Validation loss: 2.8087425280953884

Epoch: 5| Step: 3
Training loss: 0.371757475931076
Validation loss: 2.7811336850193262

Epoch: 5| Step: 4
Training loss: 0.5494521316699418
Validation loss: 2.7530236383225333

Epoch: 5| Step: 5
Training loss: 0.3716693229252503
Validation loss: 2.7594201298468852

Epoch: 5| Step: 6
Training loss: 0.3498628326261514
Validation loss: 2.769022455006617

Epoch: 5| Step: 7
Training loss: 0.43303777086053297
Validation loss: 2.804427174677307

Epoch: 5| Step: 8
Training loss: 0.3497477209754515
Validation loss: 2.780241547680679

Epoch: 5| Step: 9
Training loss: 0.3138738948387825
Validation loss: 2.782165144615905

Epoch: 5| Step: 10
Training loss: 0.36430019101460653
Validation loss: 2.7943511422814744

Epoch: 5| Step: 11
Training loss: 0.505309494613552
Validation loss: 2.823746880541831

Epoch: 433| Step: 0
Training loss: 0.3414872320051729
Validation loss: 2.834153215674949

Epoch: 5| Step: 1
Training loss: 0.42858229599241876
Validation loss: 2.816577255411837

Epoch: 5| Step: 2
Training loss: 0.552150458327793
Validation loss: 2.788287193040472

Epoch: 5| Step: 3
Training loss: 0.5683349132189601
Validation loss: 2.874965529304292

Epoch: 5| Step: 4
Training loss: 0.4632940988543993
Validation loss: 2.8143284434952625

Epoch: 5| Step: 5
Training loss: 0.3446646788816174
Validation loss: 2.835977117929031

Epoch: 5| Step: 6
Training loss: 0.3603237317097286
Validation loss: 2.7689359138937193

Epoch: 5| Step: 7
Training loss: 0.3964655077724946
Validation loss: 2.837516061594538

Epoch: 5| Step: 8
Training loss: 0.30807347441381217
Validation loss: 2.7850876523737313

Epoch: 5| Step: 9
Training loss: 0.24961897752466317
Validation loss: 2.843922686660948

Epoch: 5| Step: 10
Training loss: 0.40340383925542433
Validation loss: 2.8059440142950347

Epoch: 5| Step: 11
Training loss: 0.4011826845252383
Validation loss: 2.874932772085361

Epoch: 434| Step: 0
Training loss: 0.5115012951719828
Validation loss: 2.796155417878674

Epoch: 5| Step: 1
Training loss: 0.4507135317231302
Validation loss: 2.834014797770378

Epoch: 5| Step: 2
Training loss: 0.282699162866954
Validation loss: 2.8682253117440477

Epoch: 5| Step: 3
Training loss: 0.42431449231241786
Validation loss: 2.755707858953805

Epoch: 5| Step: 4
Training loss: 0.36587390904187356
Validation loss: 2.803920977590902

Epoch: 5| Step: 5
Training loss: 0.3644190577114466
Validation loss: 2.7930814244588675

Epoch: 5| Step: 6
Training loss: 0.3387388266589345
Validation loss: 2.839897854869838

Epoch: 5| Step: 7
Training loss: 0.3600720404361018
Validation loss: 2.8419357877602858

Epoch: 5| Step: 8
Training loss: 0.3719518878534002
Validation loss: 2.8249371407697526

Epoch: 5| Step: 9
Training loss: 0.42089415368823135
Validation loss: 2.823617500966774

Epoch: 5| Step: 10
Training loss: 0.35831435877811746
Validation loss: 2.8122300689580593

Epoch: 5| Step: 11
Training loss: 0.11804205530553509
Validation loss: 2.8071732516724985

Epoch: 435| Step: 0
Training loss: 0.2817003697319773
Validation loss: 2.80398016168172

Epoch: 5| Step: 1
Training loss: 0.4217618507954367
Validation loss: 2.8527891020522738

Epoch: 5| Step: 2
Training loss: 0.48750597632241727
Validation loss: 2.81962251720727

Epoch: 5| Step: 3
Training loss: 0.30169281984913554
Validation loss: 2.8159794689095152

Epoch: 5| Step: 4
Training loss: 0.4260530566657074
Validation loss: 2.7903746181823226

Epoch: 5| Step: 5
Training loss: 0.3651526048484054
Validation loss: 2.813449769894953

Epoch: 5| Step: 6
Training loss: 0.46048347289097435
Validation loss: 2.823241283197125

Epoch: 5| Step: 7
Training loss: 0.39283869052876136
Validation loss: 2.8481335582246015

Epoch: 5| Step: 8
Training loss: 0.26278557343498266
Validation loss: 2.8552113011226563

Epoch: 5| Step: 9
Training loss: 0.2871504384473057
Validation loss: 2.816110938502556

Epoch: 5| Step: 10
Training loss: 0.3504587117941686
Validation loss: 2.7638166913124205

Epoch: 5| Step: 11
Training loss: 0.552226287999314
Validation loss: 2.8403031975796016

Epoch: 436| Step: 0
Training loss: 0.3132140822479052
Validation loss: 2.7920711079656066

Epoch: 5| Step: 1
Training loss: 0.34899167950092735
Validation loss: 2.828225824234375

Epoch: 5| Step: 2
Training loss: 0.3197353792926515
Validation loss: 2.8123277805723506

Epoch: 5| Step: 3
Training loss: 0.34246370934258485
Validation loss: 2.795257477123715

Epoch: 5| Step: 4
Training loss: 0.35676810920213653
Validation loss: 2.844904207741051

Epoch: 5| Step: 5
Training loss: 0.541204674256729
Validation loss: 2.7104074086308

Epoch: 5| Step: 6
Training loss: 0.45181400462512294
Validation loss: 2.818792301517494

Epoch: 5| Step: 7
Training loss: 0.38361731416070016
Validation loss: 2.801001521927378

Epoch: 5| Step: 8
Training loss: 0.5105385018605542
Validation loss: 2.794813138462485

Epoch: 5| Step: 9
Training loss: 0.5112058092525991
Validation loss: 2.7254699368897004

Epoch: 5| Step: 10
Training loss: 0.27469734421624187
Validation loss: 2.7998648314263614

Epoch: 5| Step: 11
Training loss: 0.19579929722249717
Validation loss: 2.7959337266690674

Epoch: 437| Step: 0
Training loss: 0.2769938128327797
Validation loss: 2.8147494892251244

Epoch: 5| Step: 1
Training loss: 0.31733522498561395
Validation loss: 2.769833815905388

Epoch: 5| Step: 2
Training loss: 0.38208992552331056
Validation loss: 2.743560733364408

Epoch: 5| Step: 3
Training loss: 0.35334328934674974
Validation loss: 2.7941889624972265

Epoch: 5| Step: 4
Training loss: 0.4063489316642051
Validation loss: 2.785050435171703

Epoch: 5| Step: 5
Training loss: 0.49482742648819356
Validation loss: 2.7612568686224153

Epoch: 5| Step: 6
Training loss: 0.4143734430194677
Validation loss: 2.783785792701489

Epoch: 5| Step: 7
Training loss: 0.3697090817856662
Validation loss: 2.760228090622716

Epoch: 5| Step: 8
Training loss: 0.3011098404461532
Validation loss: 2.7306910775861946

Epoch: 5| Step: 9
Training loss: 0.35784632593709703
Validation loss: 2.723471046659893

Epoch: 5| Step: 10
Training loss: 0.3953266246820408
Validation loss: 2.755531102235625

Epoch: 5| Step: 11
Training loss: 0.13927148749151033
Validation loss: 2.7563756454213526

Epoch: 438| Step: 0
Training loss: 0.5015168724815874
Validation loss: 2.735843097213471

Epoch: 5| Step: 1
Training loss: 0.35064302580017354
Validation loss: 2.755338472250629

Epoch: 5| Step: 2
Training loss: 0.28439383287215036
Validation loss: 2.7598024632649314

Epoch: 5| Step: 3
Training loss: 0.3120493500511908
Validation loss: 2.745440311745941

Epoch: 5| Step: 4
Training loss: 0.3527176423185964
Validation loss: 2.78450578153383

Epoch: 5| Step: 5
Training loss: 0.38169081483822276
Validation loss: 2.7330139333107164

Epoch: 5| Step: 6
Training loss: 0.4088593460370481
Validation loss: 2.793502905925211

Epoch: 5| Step: 7
Training loss: 0.3377032339160934
Validation loss: 2.8260293751969683

Epoch: 5| Step: 8
Training loss: 0.3450158286091689
Validation loss: 2.8057161214150033

Epoch: 5| Step: 9
Training loss: 0.3792690231516127
Validation loss: 2.7934829807615387

Epoch: 5| Step: 10
Training loss: 0.45469633139721616
Validation loss: 2.7594762471777963

Epoch: 5| Step: 11
Training loss: 0.2706082980263752
Validation loss: 2.801848612081103

Epoch: 439| Step: 0
Training loss: 0.31968173281929557
Validation loss: 2.7935028134653828

Epoch: 5| Step: 1
Training loss: 0.3040818895899136
Validation loss: 2.749376197346985

Epoch: 5| Step: 2
Training loss: 0.293755187841016
Validation loss: 2.8024752648856

Epoch: 5| Step: 3
Training loss: 0.4463227841514933
Validation loss: 2.826534937746517

Epoch: 5| Step: 4
Training loss: 0.3541253243420291
Validation loss: 2.7884272538488193

Epoch: 5| Step: 5
Training loss: 0.32226717399456095
Validation loss: 2.7889129748186674

Epoch: 5| Step: 6
Training loss: 0.37860549710162655
Validation loss: 2.7801537228353426

Epoch: 5| Step: 7
Training loss: 0.40151458780953614
Validation loss: 2.7667842238702156

Epoch: 5| Step: 8
Training loss: 0.42981527336083425
Validation loss: 2.909794102607633

Epoch: 5| Step: 9
Training loss: 0.4076190401920754
Validation loss: 2.7531764404883448

Epoch: 5| Step: 10
Training loss: 0.4915279328741628
Validation loss: 2.7999096537955146

Epoch: 5| Step: 11
Training loss: 0.37596744674927274
Validation loss: 2.7597208471640893

Epoch: 440| Step: 0
Training loss: 0.26349834807346817
Validation loss: 2.7857833234851412

Epoch: 5| Step: 1
Training loss: 0.4421611171440781
Validation loss: 2.8246894152286246

Epoch: 5| Step: 2
Training loss: 0.32706031181730444
Validation loss: 2.815449901926805

Epoch: 5| Step: 3
Training loss: 0.24331454327918622
Validation loss: 2.7689394334237956

Epoch: 5| Step: 4
Training loss: 0.40666042283351134
Validation loss: 2.841120076725636

Epoch: 5| Step: 5
Training loss: 0.3030677436552772
Validation loss: 2.8071881713379443

Epoch: 5| Step: 6
Training loss: 0.3780586357833634
Validation loss: 2.7722992043093977

Epoch: 5| Step: 7
Training loss: 0.3911348067895398
Validation loss: 2.8325894632152973

Epoch: 5| Step: 8
Training loss: 0.4099426985159648
Validation loss: 2.7447223630452413

Epoch: 5| Step: 9
Training loss: 0.26330863515904573
Validation loss: 2.850742225592436

Epoch: 5| Step: 10
Training loss: 0.4102585801128706
Validation loss: 2.8175687855253218

Epoch: 5| Step: 11
Training loss: 0.6058974932270416
Validation loss: 2.8143031238942275

Epoch: 441| Step: 0
Training loss: 0.2810173927147599
Validation loss: 2.7845182896430853

Epoch: 5| Step: 1
Training loss: 0.5459671932589321
Validation loss: 2.7988649247406276

Epoch: 5| Step: 2
Training loss: 0.4628856352847002
Validation loss: 2.796906923932355

Epoch: 5| Step: 3
Training loss: 0.41025075277902184
Validation loss: 2.721340651531821

Epoch: 5| Step: 4
Training loss: 0.49312224258019366
Validation loss: 2.7701530242820236

Epoch: 5| Step: 5
Training loss: 0.31051075323422905
Validation loss: 2.8279523638728943

Epoch: 5| Step: 6
Training loss: 0.3186618210800385
Validation loss: 2.756081193467539

Epoch: 5| Step: 7
Training loss: 0.38837030107241877
Validation loss: 2.7657501781460923

Epoch: 5| Step: 8
Training loss: 0.325626740075732
Validation loss: 2.8227045265712847

Epoch: 5| Step: 9
Training loss: 0.4383315800346488
Validation loss: 2.76965043027164

Epoch: 5| Step: 10
Training loss: 0.4224289154036084
Validation loss: 2.7950964055015013

Epoch: 5| Step: 11
Training loss: 0.23318762416217723
Validation loss: 2.7980909386047763

Epoch: 442| Step: 0
Training loss: 0.285341894781064
Validation loss: 2.819448425000977

Epoch: 5| Step: 1
Training loss: 0.3778000049717783
Validation loss: 2.768894748334143

Epoch: 5| Step: 2
Training loss: 0.39598574548410476
Validation loss: 2.786999560168473

Epoch: 5| Step: 3
Training loss: 0.28883453349649035
Validation loss: 2.789335452987587

Epoch: 5| Step: 4
Training loss: 0.42556379172209907
Validation loss: 2.7892849902002115

Epoch: 5| Step: 5
Training loss: 0.27613409612187034
Validation loss: 2.8762669294196996

Epoch: 5| Step: 6
Training loss: 0.4039620750113621
Validation loss: 2.821036864835512

Epoch: 5| Step: 7
Training loss: 0.2815481036588269
Validation loss: 2.782837571793851

Epoch: 5| Step: 8
Training loss: 0.41556793624252764
Validation loss: 2.810592474268195

Epoch: 5| Step: 9
Training loss: 0.2980540103483206
Validation loss: 2.780310000469623

Epoch: 5| Step: 10
Training loss: 0.3224365705760287
Validation loss: 2.7739177556686454

Epoch: 5| Step: 11
Training loss: 0.22254874327730512
Validation loss: 2.84343085052644

Epoch: 443| Step: 0
Training loss: 0.475314303613535
Validation loss: 2.8329896274295523

Epoch: 5| Step: 1
Training loss: 0.4830297740443093
Validation loss: 2.8473291126335454

Epoch: 5| Step: 2
Training loss: 0.3245198908008482
Validation loss: 2.8251621118241426

Epoch: 5| Step: 3
Training loss: 0.3785660189533853
Validation loss: 2.7513227857661455

Epoch: 5| Step: 4
Training loss: 0.5151744087496852
Validation loss: 2.820484198418634

Epoch: 5| Step: 5
Training loss: 0.28547522589192453
Validation loss: 2.8046203683170337

Epoch: 5| Step: 6
Training loss: 0.36459216606703077
Validation loss: 2.768199455171163

Epoch: 5| Step: 7
Training loss: 0.46155343686699224
Validation loss: 2.8169686527058575

Epoch: 5| Step: 8
Training loss: 0.3091458801563244
Validation loss: 2.757019725100595

Epoch: 5| Step: 9
Training loss: 0.3504188373141619
Validation loss: 2.804315264270875

Epoch: 5| Step: 10
Training loss: 0.3367260947610226
Validation loss: 2.765165833253635

Epoch: 5| Step: 11
Training loss: 0.09567057776237477
Validation loss: 2.829614861558496

Epoch: 444| Step: 0
Training loss: 0.3290855109491376
Validation loss: 2.7587938084744392

Epoch: 5| Step: 1
Training loss: 0.42169401030534903
Validation loss: 2.807810865715569

Epoch: 5| Step: 2
Training loss: 0.42785681100086903
Validation loss: 2.807587667558805

Epoch: 5| Step: 3
Training loss: 0.3871273232927037
Validation loss: 2.797029910068707

Epoch: 5| Step: 4
Training loss: 0.3138407674137015
Validation loss: 2.7791237329277023

Epoch: 5| Step: 5
Training loss: 0.25690534690862465
Validation loss: 2.7295237967583574

Epoch: 5| Step: 6
Training loss: 0.37421920075518833
Validation loss: 2.7883085822236064

Epoch: 5| Step: 7
Training loss: 0.3265896480172393
Validation loss: 2.8108242482131747

Epoch: 5| Step: 8
Training loss: 0.37808652083017597
Validation loss: 2.7579417860292743

Epoch: 5| Step: 9
Training loss: 0.27277389108968925
Validation loss: 2.798247769425802

Epoch: 5| Step: 10
Training loss: 0.39006586111705216
Validation loss: 2.7710491301940787

Epoch: 5| Step: 11
Training loss: 0.24196505329018375
Validation loss: 2.7672145966391994

Epoch: 445| Step: 0
Training loss: 0.3267776437636839
Validation loss: 2.7775517353169064

Epoch: 5| Step: 1
Training loss: 0.32670182445584167
Validation loss: 2.8046182607960914

Epoch: 5| Step: 2
Training loss: 0.36948983764869114
Validation loss: 2.7954679462617276

Epoch: 5| Step: 3
Training loss: 0.40517038161071806
Validation loss: 2.7556945621728497

Epoch: 5| Step: 4
Training loss: 0.37588884395506134
Validation loss: 2.769536156912305

Epoch: 5| Step: 5
Training loss: 0.256539249574721
Validation loss: 2.811077726102651

Epoch: 5| Step: 6
Training loss: 0.35146281630516096
Validation loss: 2.8148044399566166

Epoch: 5| Step: 7
Training loss: 0.37224752856498
Validation loss: 2.766187387962468

Epoch: 5| Step: 8
Training loss: 0.3498859483655643
Validation loss: 2.83617185424752

Epoch: 5| Step: 9
Training loss: 0.3357064428380794
Validation loss: 2.768470134038243

Epoch: 5| Step: 10
Training loss: 0.3240872541590806
Validation loss: 2.7554582555787523

Epoch: 5| Step: 11
Training loss: 0.7097332994808027
Validation loss: 2.744643083685187

Epoch: 446| Step: 0
Training loss: 0.30373785997392416
Validation loss: 2.816132185145477

Epoch: 5| Step: 1
Training loss: 0.29562523948708125
Validation loss: 2.8381449442581816

Epoch: 5| Step: 2
Training loss: 0.24167948940941655
Validation loss: 2.839755938893871

Epoch: 5| Step: 3
Training loss: 0.32832859171833884
Validation loss: 2.8337437400249526

Epoch: 5| Step: 4
Training loss: 0.3715833746626401
Validation loss: 2.813752721906351

Epoch: 5| Step: 5
Training loss: 0.2998699651472766
Validation loss: 2.7911896274322534

Epoch: 5| Step: 6
Training loss: 0.4510111667049936
Validation loss: 2.731052521827056

Epoch: 5| Step: 7
Training loss: 0.31398999720027293
Validation loss: 2.806002164430434

Epoch: 5| Step: 8
Training loss: 0.44495163065316506
Validation loss: 2.82263596864691

Epoch: 5| Step: 9
Training loss: 0.41357461508199356
Validation loss: 2.8083565531788537

Epoch: 5| Step: 10
Training loss: 0.4777821427276493
Validation loss: 2.884663326280742

Epoch: 5| Step: 11
Training loss: 0.8406690933405283
Validation loss: 2.8201078515024083

Epoch: 447| Step: 0
Training loss: 0.4036402507108802
Validation loss: 2.8309183674564533

Epoch: 5| Step: 1
Training loss: 0.3445825356958945
Validation loss: 2.8651867294597295

Epoch: 5| Step: 2
Training loss: 0.3174040097714082
Validation loss: 2.79445314242204

Epoch: 5| Step: 3
Training loss: 0.36893370545982224
Validation loss: 2.8254288841556843

Epoch: 5| Step: 4
Training loss: 0.33664504658488104
Validation loss: 2.8617573421596587

Epoch: 5| Step: 5
Training loss: 0.5161052548046937
Validation loss: 2.772464703374466

Epoch: 5| Step: 6
Training loss: 0.4754807279483967
Validation loss: 2.81718784938083

Epoch: 5| Step: 7
Training loss: 0.34724353552679005
Validation loss: 2.7930524444488984

Epoch: 5| Step: 8
Training loss: 0.3996113707193338
Validation loss: 2.8055391391162647

Epoch: 5| Step: 9
Training loss: 0.3425339081957507
Validation loss: 2.773585728369093

Epoch: 5| Step: 10
Training loss: 0.2774162466369349
Validation loss: 2.7922825039136883

Epoch: 5| Step: 11
Training loss: 0.2482748560865379
Validation loss: 2.8332683062571107

Epoch: 448| Step: 0
Training loss: 0.33104616902512374
Validation loss: 2.826537236286525

Epoch: 5| Step: 1
Training loss: 0.3871992189790596
Validation loss: 2.8387684489425746

Epoch: 5| Step: 2
Training loss: 0.26376043174778463
Validation loss: 2.835091624991109

Epoch: 5| Step: 3
Training loss: 0.39161307301335546
Validation loss: 2.836245359834765

Epoch: 5| Step: 4
Training loss: 0.40025785152065874
Validation loss: 2.8121805751396076

Epoch: 5| Step: 5
Training loss: 0.33939421727548535
Validation loss: 2.8094367122696706

Epoch: 5| Step: 6
Training loss: 0.35249583013584274
Validation loss: 2.803445425895849

Epoch: 5| Step: 7
Training loss: 0.40596363171462196
Validation loss: 2.794432150434732

Epoch: 5| Step: 8
Training loss: 0.32558975125958506
Validation loss: 2.8136963913447146

Epoch: 5| Step: 9
Training loss: 0.36001687156031303
Validation loss: 2.8228739609719717

Epoch: 5| Step: 10
Training loss: 0.4119514596675011
Validation loss: 2.819497350818571

Epoch: 5| Step: 11
Training loss: 0.5896978639986717
Validation loss: 2.8256481944735854

Epoch: 449| Step: 0
Training loss: 0.3991176372664952
Validation loss: 2.8149423802714058

Epoch: 5| Step: 1
Training loss: 0.4062290919865772
Validation loss: 2.854275813881417

Epoch: 5| Step: 2
Training loss: 0.5379912194382804
Validation loss: 2.843227041457659

Epoch: 5| Step: 3
Training loss: 0.37389534930779916
Validation loss: 2.836437696161657

Epoch: 5| Step: 4
Training loss: 0.5781277579164449
Validation loss: 2.824665869586296

Epoch: 5| Step: 5
Training loss: 0.3124667865269155
Validation loss: 2.8840881151257816

Epoch: 5| Step: 6
Training loss: 0.5431615912399396
Validation loss: 2.790831662791965

Epoch: 5| Step: 7
Training loss: 0.44780635214589887
Validation loss: 2.86339450905351

Epoch: 5| Step: 8
Training loss: 0.38940043193369983
Validation loss: 2.8919457622934193

Epoch: 5| Step: 9
Training loss: 0.5063273794589258
Validation loss: 2.8249488263291744

Epoch: 5| Step: 10
Training loss: 0.34633869002715306
Validation loss: 2.8685410688746282

Epoch: 5| Step: 11
Training loss: 0.4849367422212761
Validation loss: 2.8283907763680287

Epoch: 450| Step: 0
Training loss: 0.32317225918587694
Validation loss: 2.8459854736451105

Epoch: 5| Step: 1
Training loss: 0.38474839070251887
Validation loss: 2.829004446041002

Epoch: 5| Step: 2
Training loss: 0.37129565317885344
Validation loss: 2.834104591937851

Epoch: 5| Step: 3
Training loss: 0.36598279840403136
Validation loss: 2.8142639880192357

Epoch: 5| Step: 4
Training loss: 0.4734551637331886
Validation loss: 2.8729926890180515

Epoch: 5| Step: 5
Training loss: 0.3513848279645889
Validation loss: 2.741126533588704

Epoch: 5| Step: 6
Training loss: 0.4726369081433206
Validation loss: 2.7925548895959866

Epoch: 5| Step: 7
Training loss: 0.27320811323019634
Validation loss: 2.7551429532856506

Epoch: 5| Step: 8
Training loss: 0.43761490266641523
Validation loss: 2.7590183903174688

Epoch: 5| Step: 9
Training loss: 0.32932295554564706
Validation loss: 2.8642004601049282

Epoch: 5| Step: 10
Training loss: 0.43099433535196724
Validation loss: 2.7979641823463184

Epoch: 5| Step: 11
Training loss: 0.3703592761793231
Validation loss: 2.777565208222407

Testing loss: 2.6880999593192207
