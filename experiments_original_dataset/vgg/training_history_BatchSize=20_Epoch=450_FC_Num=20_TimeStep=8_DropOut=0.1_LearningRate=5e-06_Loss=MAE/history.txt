Epoch: 1| Step: 0
Training loss: 3.015033721923828
Validation loss: 3.169076591730118

Epoch: 5| Step: 1
Training loss: 3.312511444091797
Validation loss: 3.1544147630532584

Epoch: 5| Step: 2
Training loss: 2.954728364944458
Validation loss: 3.1331619024276733

Epoch: 5| Step: 3
Training loss: 3.6475653648376465
Validation loss: 3.1152535577615104

Epoch: 5| Step: 4
Training loss: 3.322382688522339
Validation loss: 3.0952961146831512

Epoch: 5| Step: 5
Training loss: 3.289564847946167
Validation loss: 3.0817496478557587

Epoch: 5| Step: 6
Training loss: 3.603459596633911
Validation loss: 3.065314362446467

Epoch: 5| Step: 7
Training loss: 3.657092332839966
Validation loss: 3.0523041089375815

Epoch: 5| Step: 8
Training loss: 3.096949815750122
Validation loss: 3.0358625948429108

Epoch: 5| Step: 9
Training loss: 2.9237735271453857
Validation loss: 3.0182348688443503

Epoch: 5| Step: 10
Training loss: 3.186769962310791
Validation loss: 3.0031972030798593

Epoch: 5| Step: 11
Training loss: 2.783262014389038
Validation loss: 2.9904648462931314

Epoch: 2| Step: 0
Training loss: 2.8677051067352295
Validation loss: 2.976809481779734

Epoch: 5| Step: 1
Training loss: 2.9124107360839844
Validation loss: 2.963810553153356

Epoch: 5| Step: 2
Training loss: 2.984434127807617
Validation loss: 2.9378530184427896

Epoch: 5| Step: 3
Training loss: 3.2759666442871094
Validation loss: 2.933776706457138

Epoch: 5| Step: 4
Training loss: 3.2498435974121094
Validation loss: 2.920239140590032

Epoch: 5| Step: 5
Training loss: 2.8340353965759277
Validation loss: 2.8971100449562073

Epoch: 5| Step: 6
Training loss: 3.653322696685791
Validation loss: 2.879971444606781

Epoch: 5| Step: 7
Training loss: 3.1758804321289062
Validation loss: 2.867743283510208

Epoch: 5| Step: 8
Training loss: 3.0963597297668457
Validation loss: 2.850535790125529

Epoch: 5| Step: 9
Training loss: 3.3069279193878174
Validation loss: 2.8290467063585916

Epoch: 5| Step: 10
Training loss: 2.5031914710998535
Validation loss: 2.8141603966554007

Epoch: 5| Step: 11
Training loss: 2.6370694637298584
Validation loss: 2.7894658744335175

Epoch: 3| Step: 0
Training loss: 3.2519798278808594
Validation loss: 2.75935161113739

Epoch: 5| Step: 1
Training loss: 3.4995899200439453
Validation loss: 2.7459536492824554

Epoch: 5| Step: 2
Training loss: 2.4518065452575684
Validation loss: 2.7211294372876487

Epoch: 5| Step: 3
Training loss: 2.806905508041382
Validation loss: 2.6926622688770294

Epoch: 5| Step: 4
Training loss: 2.949131727218628
Validation loss: 2.6720859706401825

Epoch: 5| Step: 5
Training loss: 2.511610269546509
Validation loss: 2.6358552674452462

Epoch: 5| Step: 6
Training loss: 2.7471163272857666
Validation loss: 2.6145117779572806

Epoch: 5| Step: 7
Training loss: 2.671046495437622
Validation loss: 2.5861816058556237

Epoch: 5| Step: 8
Training loss: 2.0697293281555176
Validation loss: 2.549032042423884

Epoch: 5| Step: 9
Training loss: 2.698068380355835
Validation loss: 2.520197808742523

Epoch: 5| Step: 10
Training loss: 3.066648483276367
Validation loss: 2.4770343800385795

Epoch: 5| Step: 11
Training loss: 2.547271966934204
Validation loss: 2.435260017712911

Epoch: 4| Step: 0
Training loss: 2.431544065475464
Validation loss: 2.406770487626394

Epoch: 5| Step: 1
Training loss: 2.290592908859253
Validation loss: 2.374131182829539

Epoch: 5| Step: 2
Training loss: 2.7252719402313232
Validation loss: 2.3370998203754425

Epoch: 5| Step: 3
Training loss: 2.068592071533203
Validation loss: 2.318966527779897

Epoch: 5| Step: 4
Training loss: 2.2325637340545654
Validation loss: 2.2746470967928567

Epoch: 5| Step: 5
Training loss: 2.4950366020202637
Validation loss: 2.233309715986252

Epoch: 5| Step: 6
Training loss: 1.9241453409194946
Validation loss: 2.2052880624930062

Epoch: 5| Step: 7
Training loss: 2.8923439979553223
Validation loss: 2.157428498069445

Epoch: 5| Step: 8
Training loss: 2.1549911499023438
Validation loss: 2.1173648287852607

Epoch: 5| Step: 9
Training loss: 2.058785915374756
Validation loss: 2.1002536912759147

Epoch: 5| Step: 10
Training loss: 2.5312623977661133
Validation loss: 2.085481435060501

Epoch: 5| Step: 11
Training loss: 2.653412342071533
Validation loss: 2.0640118519465127

Epoch: 5| Step: 0
Training loss: 2.2494521141052246
Validation loss: 2.0396649887164435

Epoch: 5| Step: 1
Training loss: 2.4352633953094482
Validation loss: 2.0162861992915473

Epoch: 5| Step: 2
Training loss: 2.668095111846924
Validation loss: 1.9957555383443832

Epoch: 5| Step: 3
Training loss: 1.7557979822158813
Validation loss: 2.014924814303716

Epoch: 5| Step: 4
Training loss: 2.1576333045959473
Validation loss: 1.9955813487370808

Epoch: 5| Step: 5
Training loss: 1.9799349308013916
Validation loss: 2.0269571046034494

Epoch: 5| Step: 6
Training loss: 1.3179945945739746
Validation loss: 2.0041867146889367

Epoch: 5| Step: 7
Training loss: 2.2555603981018066
Validation loss: 2.046684523423513

Epoch: 5| Step: 8
Training loss: 1.607526421546936
Validation loss: 2.0730495204528174

Epoch: 5| Step: 9
Training loss: 1.4868710041046143
Validation loss: 2.106472517053286

Epoch: 5| Step: 10
Training loss: 2.636406421661377
Validation loss: 2.1158799628416696

Epoch: 5| Step: 11
Training loss: 1.9893471002578735
Validation loss: 2.1289894382158914

Epoch: 6| Step: 0
Training loss: 1.930426001548767
Validation loss: 2.1111366748809814

Epoch: 5| Step: 1
Training loss: 2.1204018592834473
Validation loss: 2.0910780181487403

Epoch: 5| Step: 2
Training loss: 1.9686092138290405
Validation loss: 2.0657028605540595

Epoch: 5| Step: 3
Training loss: 2.5109329223632812
Validation loss: 2.0517204105854034

Epoch: 5| Step: 4
Training loss: 1.7891477346420288
Validation loss: 2.033064067363739

Epoch: 5| Step: 5
Training loss: 2.26645827293396
Validation loss: 2.013936161994934

Epoch: 5| Step: 6
Training loss: 1.6663265228271484
Validation loss: 2.0033123592535653

Epoch: 5| Step: 7
Training loss: 2.2964062690734863
Validation loss: 1.9944976220528285

Epoch: 5| Step: 8
Training loss: 2.1498138904571533
Validation loss: 2.00861157476902

Epoch: 5| Step: 9
Training loss: 2.0780186653137207
Validation loss: 1.9860454301039379

Epoch: 5| Step: 10
Training loss: 2.183173656463623
Validation loss: 1.9926790595054626

Epoch: 5| Step: 11
Training loss: 1.053406000137329
Validation loss: 2.01102177798748

Epoch: 7| Step: 0
Training loss: 1.5132938623428345
Validation loss: 2.012686252593994

Epoch: 5| Step: 1
Training loss: 1.87583327293396
Validation loss: 2.0058849255243936

Epoch: 5| Step: 2
Training loss: 2.0357577800750732
Validation loss: 2.008333310484886

Epoch: 5| Step: 3
Training loss: 2.145538568496704
Validation loss: 2.0163447111845016

Epoch: 5| Step: 4
Training loss: 2.479419469833374
Validation loss: 2.0033679008483887

Epoch: 5| Step: 5
Training loss: 1.9228191375732422
Validation loss: 2.018227164944013

Epoch: 5| Step: 6
Training loss: 1.9865763187408447
Validation loss: 1.9902698944012325

Epoch: 5| Step: 7
Training loss: 1.8809382915496826
Validation loss: 1.993993764122327

Epoch: 5| Step: 8
Training loss: 2.175337314605713
Validation loss: 1.9826836735010147

Epoch: 5| Step: 9
Training loss: 2.1438961029052734
Validation loss: 1.9982847670714061

Epoch: 5| Step: 10
Training loss: 2.429464817047119
Validation loss: 2.0067890733480453

Epoch: 5| Step: 11
Training loss: 2.4148623943328857
Validation loss: 1.9986275086800258

Epoch: 8| Step: 0
Training loss: 1.5881937742233276
Validation loss: 2.004018858075142

Epoch: 5| Step: 1
Training loss: 2.8966033458709717
Validation loss: 1.9984377175569534

Epoch: 5| Step: 2
Training loss: 1.461368203163147
Validation loss: 1.9954063097635906

Epoch: 5| Step: 3
Training loss: 1.7368049621582031
Validation loss: 2.002793143192927

Epoch: 5| Step: 4
Training loss: 2.1911840438842773
Validation loss: 2.0143023480971656

Epoch: 5| Step: 5
Training loss: 2.2368783950805664
Validation loss: 1.9967656880617142

Epoch: 5| Step: 6
Training loss: 2.3193044662475586
Validation loss: 1.9956014553705852

Epoch: 5| Step: 7
Training loss: 2.0659987926483154
Validation loss: 1.9860696544249852

Epoch: 5| Step: 8
Training loss: 2.3674845695495605
Validation loss: 1.9931918382644653

Epoch: 5| Step: 9
Training loss: 1.3805196285247803
Validation loss: 1.9960702160994213

Epoch: 5| Step: 10
Training loss: 2.1639928817749023
Validation loss: 2.0196669002374015

Epoch: 5| Step: 11
Training loss: 1.7017868757247925
Validation loss: 2.0173792044321694

Epoch: 9| Step: 0
Training loss: 1.927215576171875
Validation loss: 2.0219794859488807

Epoch: 5| Step: 1
Training loss: 1.4719092845916748
Validation loss: 2.0433658361434937

Epoch: 5| Step: 2
Training loss: 2.4506940841674805
Validation loss: 2.0628404716650643

Epoch: 5| Step: 3
Training loss: 2.4508841037750244
Validation loss: 2.037706881761551

Epoch: 5| Step: 4
Training loss: 2.1585259437561035
Validation loss: 2.073194280266762

Epoch: 5| Step: 5
Training loss: 1.4586236476898193
Validation loss: 2.0621517300605774

Epoch: 5| Step: 6
Training loss: 2.034085750579834
Validation loss: 2.0612023721138635

Epoch: 5| Step: 7
Training loss: 1.751980185508728
Validation loss: 2.066013291478157

Epoch: 5| Step: 8
Training loss: 1.918806791305542
Validation loss: 2.0576601028442383

Epoch: 5| Step: 9
Training loss: 2.2536959648132324
Validation loss: 2.047978922724724

Epoch: 5| Step: 10
Training loss: 2.6604716777801514
Validation loss: 2.0318444718917212

Epoch: 5| Step: 11
Training loss: 1.4153475761413574
Validation loss: 2.014586249987284

Epoch: 10| Step: 0
Training loss: 2.0681049823760986
Validation loss: 2.0287696917851767

Epoch: 5| Step: 1
Training loss: 1.4498703479766846
Validation loss: 2.0181664725144706

Epoch: 5| Step: 2
Training loss: 2.1163017749786377
Validation loss: 2.0285160591204963

Epoch: 5| Step: 3
Training loss: 1.8553491830825806
Validation loss: 2.0140384336312613

Epoch: 5| Step: 4
Training loss: 2.417031764984131
Validation loss: 1.9943223496278126

Epoch: 5| Step: 5
Training loss: 2.8011698722839355
Validation loss: 1.9973433464765549

Epoch: 5| Step: 6
Training loss: 1.8712871074676514
Validation loss: 2.0032339096069336

Epoch: 5| Step: 7
Training loss: 1.681971549987793
Validation loss: 1.9826907565196354

Epoch: 5| Step: 8
Training loss: 1.9423820972442627
Validation loss: 2.007471283276876

Epoch: 5| Step: 9
Training loss: 2.143979787826538
Validation loss: 2.028655851880709

Epoch: 5| Step: 10
Training loss: 2.1872637271881104
Validation loss: 2.006072759628296

Epoch: 5| Step: 11
Training loss: 0.8104252815246582
Validation loss: 2.0104110340277352

Epoch: 11| Step: 0
Training loss: 2.6045031547546387
Validation loss: 2.0143185406923294

Epoch: 5| Step: 1
Training loss: 1.9006379842758179
Validation loss: 1.9983159005641937

Epoch: 5| Step: 2
Training loss: 2.280750274658203
Validation loss: 1.989172324538231

Epoch: 5| Step: 3
Training loss: 1.9034111499786377
Validation loss: 1.9971852699915569

Epoch: 5| Step: 4
Training loss: 2.0301730632781982
Validation loss: 1.9897732486327488

Epoch: 5| Step: 5
Training loss: 2.3733139038085938
Validation loss: 1.9852931598822277

Epoch: 5| Step: 6
Training loss: 2.18021821975708
Validation loss: 1.9894895156224568

Epoch: 5| Step: 7
Training loss: 1.8975865840911865
Validation loss: 2.0067950189113617

Epoch: 5| Step: 8
Training loss: 2.0337772369384766
Validation loss: 2.0117089052995047

Epoch: 5| Step: 9
Training loss: 1.5173006057739258
Validation loss: 1.9797928929328918

Epoch: 5| Step: 10
Training loss: 1.8667443990707397
Validation loss: 1.9961326171954472

Epoch: 5| Step: 11
Training loss: 1.3448922634124756
Validation loss: 1.9945807258288066

Epoch: 12| Step: 0
Training loss: 2.129145383834839
Validation loss: 1.9951882312695186

Epoch: 5| Step: 1
Training loss: 1.5927379131317139
Validation loss: 2.0030291229486465

Epoch: 5| Step: 2
Training loss: 2.072636127471924
Validation loss: 1.9801854888598125

Epoch: 5| Step: 3
Training loss: 2.1212472915649414
Validation loss: 1.9936187416315079

Epoch: 5| Step: 4
Training loss: 2.310208559036255
Validation loss: 2.012833600242933

Epoch: 5| Step: 5
Training loss: 1.9343945980072021
Validation loss: 2.015706236163775

Epoch: 5| Step: 6
Training loss: 2.268950939178467
Validation loss: 2.030505806207657

Epoch: 5| Step: 7
Training loss: 1.7743501663208008
Validation loss: 2.0542564342419305

Epoch: 5| Step: 8
Training loss: 2.232936382293701
Validation loss: 2.047354355454445

Epoch: 5| Step: 9
Training loss: 1.5891547203063965
Validation loss: 2.0499596993128457

Epoch: 5| Step: 10
Training loss: 2.1382033824920654
Validation loss: 2.050508961081505

Epoch: 5| Step: 11
Training loss: 1.9038583040237427
Validation loss: 2.028133288025856

Epoch: 13| Step: 0
Training loss: 2.134943962097168
Validation loss: 2.027891938885053

Epoch: 5| Step: 1
Training loss: 2.071444511413574
Validation loss: 2.01489786307017

Epoch: 5| Step: 2
Training loss: 2.042301654815674
Validation loss: 1.9975351244211197

Epoch: 5| Step: 3
Training loss: 2.050952672958374
Validation loss: 2.001576696832975

Epoch: 5| Step: 4
Training loss: 2.142219066619873
Validation loss: 1.9796215097109477

Epoch: 5| Step: 5
Training loss: 2.43477201461792
Validation loss: 2.0078654885292053

Epoch: 5| Step: 6
Training loss: 1.653984785079956
Validation loss: 2.0018648902575173

Epoch: 5| Step: 7
Training loss: 2.2598390579223633
Validation loss: 1.9887025356292725

Epoch: 5| Step: 8
Training loss: 1.9902127981185913
Validation loss: 2.0031153758366904

Epoch: 5| Step: 9
Training loss: 1.9635810852050781
Validation loss: 1.9875804235537846

Epoch: 5| Step: 10
Training loss: 1.4738082885742188
Validation loss: 1.9758990655342739

Epoch: 5| Step: 11
Training loss: 1.9852242469787598
Validation loss: 1.9969950318336487

Epoch: 14| Step: 0
Training loss: 1.5184671878814697
Validation loss: 1.9923222313324611

Epoch: 5| Step: 1
Training loss: 1.4072606563568115
Validation loss: 1.9963541279236476

Epoch: 5| Step: 2
Training loss: 1.5469474792480469
Validation loss: 2.024859756231308

Epoch: 5| Step: 3
Training loss: 2.3866119384765625
Validation loss: 2.0194521844387054

Epoch: 5| Step: 4
Training loss: 2.541168689727783
Validation loss: 2.014225423336029

Epoch: 5| Step: 5
Training loss: 2.1099371910095215
Validation loss: 2.0188554475704827

Epoch: 5| Step: 6
Training loss: 2.210174560546875
Validation loss: 2.022032395005226

Epoch: 5| Step: 7
Training loss: 2.033189535140991
Validation loss: 2.029036045074463

Epoch: 5| Step: 8
Training loss: 2.1494200229644775
Validation loss: 2.0262949218352637

Epoch: 5| Step: 9
Training loss: 1.8345969915390015
Validation loss: 2.0435618658860526

Epoch: 5| Step: 10
Training loss: 2.1053273677825928
Validation loss: 2.019148533542951

Epoch: 5| Step: 11
Training loss: 2.600299835205078
Validation loss: 2.0393176078796387

Epoch: 15| Step: 0
Training loss: 2.1557435989379883
Validation loss: 2.025162324309349

Epoch: 5| Step: 1
Training loss: 1.9191557168960571
Validation loss: 2.046199932694435

Epoch: 5| Step: 2
Training loss: 2.1155457496643066
Validation loss: 2.0216606309016547

Epoch: 5| Step: 3
Training loss: 2.1668426990509033
Validation loss: 2.031672572096189

Epoch: 5| Step: 4
Training loss: 2.249890089035034
Validation loss: 2.0146899869044623

Epoch: 5| Step: 5
Training loss: 2.2787845134735107
Validation loss: 2.0010782877604165

Epoch: 5| Step: 6
Training loss: 1.7882124185562134
Validation loss: 1.9961755474408467

Epoch: 5| Step: 7
Training loss: 1.568307876586914
Validation loss: 1.9966856638590496

Epoch: 5| Step: 8
Training loss: 1.6446940898895264
Validation loss: 1.9961832811435063

Epoch: 5| Step: 9
Training loss: 2.251817226409912
Validation loss: 2.016214152177175

Epoch: 5| Step: 10
Training loss: 1.9899425506591797
Validation loss: 2.0014405151208243

Epoch: 5| Step: 11
Training loss: 1.806528091430664
Validation loss: 1.990222821633021

Epoch: 16| Step: 0
Training loss: 2.1234328746795654
Validation loss: 1.9987102697292964

Epoch: 5| Step: 1
Training loss: 1.3311823606491089
Validation loss: 2.0066408117612204

Epoch: 5| Step: 2
Training loss: 2.5500826835632324
Validation loss: 2.028028428554535

Epoch: 5| Step: 3
Training loss: 1.9410041570663452
Validation loss: 2.017956788341204

Epoch: 5| Step: 4
Training loss: 1.826093077659607
Validation loss: 2.026977544029554

Epoch: 5| Step: 5
Training loss: 1.6172034740447998
Validation loss: 2.034409021337827

Epoch: 5| Step: 6
Training loss: 2.713669538497925
Validation loss: 2.0447707722584405

Epoch: 5| Step: 7
Training loss: 2.124246120452881
Validation loss: 2.060356453061104

Epoch: 5| Step: 8
Training loss: 1.7068939208984375
Validation loss: 2.047200302282969

Epoch: 5| Step: 9
Training loss: 2.271934986114502
Validation loss: 2.076895917455355

Epoch: 5| Step: 10
Training loss: 1.7532126903533936
Validation loss: 2.047799830635389

Epoch: 5| Step: 11
Training loss: 2.4051458835601807
Validation loss: 2.0512368381023407

Epoch: 17| Step: 0
Training loss: 2.2917702198028564
Validation loss: 2.0472143391768136

Epoch: 5| Step: 1
Training loss: 1.6312999725341797
Validation loss: 2.048580765724182

Epoch: 5| Step: 2
Training loss: 1.8346052169799805
Validation loss: 2.0404618084430695

Epoch: 5| Step: 3
Training loss: 2.348879098892212
Validation loss: 2.054558133085569

Epoch: 5| Step: 4
Training loss: 2.0183777809143066
Validation loss: 2.0397550811370215

Epoch: 5| Step: 5
Training loss: 1.637813925743103
Validation loss: 2.025934487581253

Epoch: 5| Step: 6
Training loss: 2.553135395050049
Validation loss: 2.0251401215791702

Epoch: 5| Step: 7
Training loss: 2.106658935546875
Validation loss: 2.0017817417780557

Epoch: 5| Step: 8
Training loss: 1.9336951971054077
Validation loss: 1.9886608570814133

Epoch: 5| Step: 9
Training loss: 1.2831100225448608
Validation loss: 1.9819758186737697

Epoch: 5| Step: 10
Training loss: 2.3029093742370605
Validation loss: 1.9905393819014232

Epoch: 5| Step: 11
Training loss: 2.1685791015625
Validation loss: 1.9758848945299785

Epoch: 18| Step: 0
Training loss: 1.908617615699768
Validation loss: 1.987056240439415

Epoch: 5| Step: 1
Training loss: 2.0304651260375977
Validation loss: 1.9925880432128906

Epoch: 5| Step: 2
Training loss: 1.64508855342865
Validation loss: 2.00632651646932

Epoch: 5| Step: 3
Training loss: 1.8198919296264648
Validation loss: 2.002455751101176

Epoch: 5| Step: 4
Training loss: 2.197025775909424
Validation loss: 2.0231754084428153

Epoch: 5| Step: 5
Training loss: 2.2313003540039062
Validation loss: 2.0121684024731317

Epoch: 5| Step: 6
Training loss: 1.9753408432006836
Validation loss: 2.018151472012202

Epoch: 5| Step: 7
Training loss: 1.9502532482147217
Validation loss: 2.010312149922053

Epoch: 5| Step: 8
Training loss: 2.381911516189575
Validation loss: 2.0121667136748633

Epoch: 5| Step: 9
Training loss: 1.7922027111053467
Validation loss: 1.9997517416874568

Epoch: 5| Step: 10
Training loss: 1.713701605796814
Validation loss: 1.9936015158891678

Epoch: 5| Step: 11
Training loss: 2.304286003112793
Validation loss: 1.9823121577501297

Epoch: 19| Step: 0
Training loss: 1.9996726512908936
Validation loss: 1.9980931729078293

Epoch: 5| Step: 1
Training loss: 2.168062686920166
Validation loss: 2.029996241132418

Epoch: 5| Step: 2
Training loss: 1.8898168802261353
Validation loss: 2.0367205490668616

Epoch: 5| Step: 3
Training loss: 1.5846478939056396
Validation loss: 2.0384155064821243

Epoch: 5| Step: 4
Training loss: 2.4622464179992676
Validation loss: 2.035131052136421

Epoch: 5| Step: 5
Training loss: 2.4568915367126465
Validation loss: 2.056972394386927

Epoch: 5| Step: 6
Training loss: 1.5244152545928955
Validation loss: 2.038806160291036

Epoch: 5| Step: 7
Training loss: 1.881795883178711
Validation loss: 2.044934938351313

Epoch: 5| Step: 8
Training loss: 2.1078221797943115
Validation loss: 2.0463999758164086

Epoch: 5| Step: 9
Training loss: 1.940900444984436
Validation loss: 2.0273345907529197

Epoch: 5| Step: 10
Training loss: 1.9464820623397827
Validation loss: 2.019585967063904

Epoch: 5| Step: 11
Training loss: 1.6442888975143433
Validation loss: 2.041121537486712

Epoch: 20| Step: 0
Training loss: 2.2368149757385254
Validation loss: 2.0103048185507455

Epoch: 5| Step: 1
Training loss: 2.3660271167755127
Validation loss: 2.0103617211182914

Epoch: 5| Step: 2
Training loss: 1.6923965215682983
Validation loss: 2.001483296354612

Epoch: 5| Step: 3
Training loss: 2.14408540725708
Validation loss: 1.9999018609523773

Epoch: 5| Step: 4
Training loss: 1.8599398136138916
Validation loss: 1.9836952239274979

Epoch: 5| Step: 5
Training loss: 1.4855990409851074
Validation loss: 1.9951376616954803

Epoch: 5| Step: 6
Training loss: 2.308532238006592
Validation loss: 1.9999453723430634

Epoch: 5| Step: 7
Training loss: 2.0402913093566895
Validation loss: 1.995054508248965

Epoch: 5| Step: 8
Training loss: 1.963371992111206
Validation loss: 1.9935900270938873

Epoch: 5| Step: 9
Training loss: 2.2759361267089844
Validation loss: 1.9920024077097576

Epoch: 5| Step: 10
Training loss: 1.6405986547470093
Validation loss: 1.9787097324927647

Epoch: 5| Step: 11
Training loss: 2.0339508056640625
Validation loss: 1.9905317723751068

Epoch: 21| Step: 0
Training loss: 2.005330801010132
Validation loss: 1.9922987818717957

Epoch: 5| Step: 1
Training loss: 1.7437427043914795
Validation loss: 1.9921840677658718

Epoch: 5| Step: 2
Training loss: 2.0585434436798096
Validation loss: 1.972964659333229

Epoch: 5| Step: 3
Training loss: 2.268770694732666
Validation loss: 1.9864458739757538

Epoch: 5| Step: 4
Training loss: 1.8266496658325195
Validation loss: 1.9669418980677922

Epoch: 5| Step: 5
Training loss: 1.860947847366333
Validation loss: 1.9796550820271175

Epoch: 5| Step: 6
Training loss: 2.308267116546631
Validation loss: 1.9918306469917297

Epoch: 5| Step: 7
Training loss: 2.3370513916015625
Validation loss: 1.9721608956654866

Epoch: 5| Step: 8
Training loss: 1.9878612756729126
Validation loss: 1.9958787361780803

Epoch: 5| Step: 9
Training loss: 1.4837291240692139
Validation loss: 1.9853443652391434

Epoch: 5| Step: 10
Training loss: 1.8381268978118896
Validation loss: 2.0132100681463876

Epoch: 5| Step: 11
Training loss: 2.106945514678955
Validation loss: 2.026823272307714

Epoch: 22| Step: 0
Training loss: 1.7856614589691162
Validation loss: 2.025835002462069

Epoch: 5| Step: 1
Training loss: 2.0324761867523193
Validation loss: 2.0188995997111

Epoch: 5| Step: 2
Training loss: 1.514775276184082
Validation loss: 2.0341012130180993

Epoch: 5| Step: 3
Training loss: 1.6770788431167603
Validation loss: 2.0262864232063293

Epoch: 5| Step: 4
Training loss: 1.8488028049468994
Validation loss: 2.0303508887688317

Epoch: 5| Step: 5
Training loss: 2.155086040496826
Validation loss: 2.060492917895317

Epoch: 5| Step: 6
Training loss: 1.860775351524353
Validation loss: 2.0361007302999496

Epoch: 5| Step: 7
Training loss: 2.4447274208068848
Validation loss: 2.052696779370308

Epoch: 5| Step: 8
Training loss: 2.1341261863708496
Validation loss: 2.0390834709008536

Epoch: 5| Step: 9
Training loss: 1.8078874349594116
Validation loss: 2.0189373840888343

Epoch: 5| Step: 10
Training loss: 2.397736072540283
Validation loss: 2.0079783449570336

Epoch: 5| Step: 11
Training loss: 2.3218600749969482
Validation loss: 1.966513176759084

Epoch: 23| Step: 0
Training loss: 1.8041731119155884
Validation loss: 2.000897844632467

Epoch: 5| Step: 1
Training loss: 1.9963970184326172
Validation loss: 1.9691725621620815

Epoch: 5| Step: 2
Training loss: 2.4045872688293457
Validation loss: 1.974236269791921

Epoch: 5| Step: 3
Training loss: 1.7502940893173218
Validation loss: 1.9778537154197693

Epoch: 5| Step: 4
Training loss: 1.8586032390594482
Validation loss: 1.981854572892189

Epoch: 5| Step: 5
Training loss: 1.861162543296814
Validation loss: 1.9780387729406357

Epoch: 5| Step: 6
Training loss: 2.0602223873138428
Validation loss: 1.9747733920812607

Epoch: 5| Step: 7
Training loss: 2.76749587059021
Validation loss: 1.9943309376637142

Epoch: 5| Step: 8
Training loss: 1.4054627418518066
Validation loss: 1.979931632677714

Epoch: 5| Step: 9
Training loss: 1.8160426616668701
Validation loss: 1.9851427177588146

Epoch: 5| Step: 10
Training loss: 2.03448486328125
Validation loss: 1.9901020377874374

Epoch: 5| Step: 11
Training loss: 1.3347829580307007
Validation loss: 2.000781704982122

Epoch: 24| Step: 0
Training loss: 2.0536224842071533
Validation loss: 1.9972511231899261

Epoch: 5| Step: 1
Training loss: 1.762325644493103
Validation loss: 2.0031092315912247

Epoch: 5| Step: 2
Training loss: 2.2714409828186035
Validation loss: 1.9856175929307938

Epoch: 5| Step: 3
Training loss: 1.9793217182159424
Validation loss: 2.001483529806137

Epoch: 5| Step: 4
Training loss: 1.5197025537490845
Validation loss: 1.9957582851250966

Epoch: 5| Step: 5
Training loss: 2.388885259628296
Validation loss: 2.0027071088552475

Epoch: 5| Step: 6
Training loss: 1.6384832859039307
Validation loss: 2.0129318485657373

Epoch: 5| Step: 7
Training loss: 2.1177785396575928
Validation loss: 2.0054324865341187

Epoch: 5| Step: 8
Training loss: 1.7536522150039673
Validation loss: 1.9841590921084087

Epoch: 5| Step: 9
Training loss: 1.8582069873809814
Validation loss: 2.014536147316297

Epoch: 5| Step: 10
Training loss: 2.3413689136505127
Validation loss: 2.008579875032107

Epoch: 5| Step: 11
Training loss: 1.0077009201049805
Validation loss: 2.004422962665558

Epoch: 25| Step: 0
Training loss: 2.099440574645996
Validation loss: 2.0025591999292374

Epoch: 5| Step: 1
Training loss: 1.6970611810684204
Validation loss: 2.0266105631987252

Epoch: 5| Step: 2
Training loss: 2.0363755226135254
Validation loss: 2.010684003432592

Epoch: 5| Step: 3
Training loss: 2.28507661819458
Validation loss: 2.009991998473803

Epoch: 5| Step: 4
Training loss: 2.2386672496795654
Validation loss: 2.022206728657087

Epoch: 5| Step: 5
Training loss: 2.017557144165039
Validation loss: 1.9964992105960846

Epoch: 5| Step: 6
Training loss: 1.718754529953003
Validation loss: 2.0121182203292847

Epoch: 5| Step: 7
Training loss: 2.011218786239624
Validation loss: 2.004420667886734

Epoch: 5| Step: 8
Training loss: 1.8312299251556396
Validation loss: 1.9853973686695099

Epoch: 5| Step: 9
Training loss: 1.9564861059188843
Validation loss: 1.983265866835912

Epoch: 5| Step: 10
Training loss: 1.7868049144744873
Validation loss: 1.9729143629471462

Epoch: 5| Step: 11
Training loss: 1.1504285335540771
Validation loss: 1.9888884623845418

Epoch: 26| Step: 0
Training loss: 1.9382270574569702
Validation loss: 1.9650496393442154

Epoch: 5| Step: 1
Training loss: 1.774346113204956
Validation loss: 2.001606593529383

Epoch: 5| Step: 2
Training loss: 2.242284059524536
Validation loss: 1.9790644546349843

Epoch: 5| Step: 3
Training loss: 1.8814226388931274
Validation loss: 1.9817201594511669

Epoch: 5| Step: 4
Training loss: 2.1556453704833984
Validation loss: 1.9799381097157795

Epoch: 5| Step: 5
Training loss: 1.37835693359375
Validation loss: 1.9704065571228664

Epoch: 5| Step: 6
Training loss: 1.9256725311279297
Validation loss: 1.9588675200939178

Epoch: 5| Step: 7
Training loss: 1.302527904510498
Validation loss: 1.9810364643732707

Epoch: 5| Step: 8
Training loss: 1.7063143253326416
Validation loss: 1.9669952690601349

Epoch: 5| Step: 9
Training loss: 2.567880868911743
Validation loss: 1.9893712252378464

Epoch: 5| Step: 10
Training loss: 2.3820536136627197
Validation loss: 1.9830090999603271

Epoch: 5| Step: 11
Training loss: 2.6817150115966797
Validation loss: 1.9901502927144368

Epoch: 27| Step: 0
Training loss: 2.0342488288879395
Validation loss: 2.024394065141678

Epoch: 5| Step: 1
Training loss: 1.7156994342803955
Validation loss: 2.0150037705898285

Epoch: 5| Step: 2
Training loss: 1.7546675205230713
Validation loss: 2.030515561501185

Epoch: 5| Step: 3
Training loss: 2.5937225818634033
Validation loss: 2.046453466018041

Epoch: 5| Step: 4
Training loss: 2.0234837532043457
Validation loss: 2.0492554108301797

Epoch: 5| Step: 5
Training loss: 1.5694180727005005
Validation loss: 2.04207111398379

Epoch: 5| Step: 6
Training loss: 1.5887311697006226
Validation loss: 2.0224195222059884

Epoch: 5| Step: 7
Training loss: 2.2027370929718018
Validation loss: 2.0394184291362762

Epoch: 5| Step: 8
Training loss: 1.937650442123413
Validation loss: 2.031699061393738

Epoch: 5| Step: 9
Training loss: 1.940774917602539
Validation loss: 2.010042910774549

Epoch: 5| Step: 10
Training loss: 1.7784103155136108
Validation loss: 1.965806504090627

Epoch: 5| Step: 11
Training loss: 3.684213638305664
Validation loss: 1.984066550930341

Epoch: 28| Step: 0
Training loss: 1.6483291387557983
Validation loss: 1.9838662842909496

Epoch: 5| Step: 1
Training loss: 2.354055166244507
Validation loss: 1.9803067644437153

Epoch: 5| Step: 2
Training loss: 1.9103100299835205
Validation loss: 1.9654281785090764

Epoch: 5| Step: 3
Training loss: 1.409891963005066
Validation loss: 1.9966996957858403

Epoch: 5| Step: 4
Training loss: 2.3920364379882812
Validation loss: 1.9780645221471786

Epoch: 5| Step: 5
Training loss: 1.7808157205581665
Validation loss: 1.9719158758719761

Epoch: 5| Step: 6
Training loss: 1.9394102096557617
Validation loss: 1.9571292002995808

Epoch: 5| Step: 7
Training loss: 2.125807285308838
Validation loss: 1.9718886464834213

Epoch: 5| Step: 8
Training loss: 1.6345574855804443
Validation loss: 1.9732034653425217

Epoch: 5| Step: 9
Training loss: 2.5965232849121094
Validation loss: 1.9773710171381633

Epoch: 5| Step: 10
Training loss: 1.8828214406967163
Validation loss: 1.9740403095881145

Epoch: 5| Step: 11
Training loss: 1.046772837638855
Validation loss: 1.987837423880895

Epoch: 29| Step: 0
Training loss: 1.7499268054962158
Validation loss: 1.9993848651647568

Epoch: 5| Step: 1
Training loss: 2.081650733947754
Validation loss: 1.9931901892026265

Epoch: 5| Step: 2
Training loss: 2.778815746307373
Validation loss: 1.9975694914658864

Epoch: 5| Step: 3
Training loss: 1.9494625329971313
Validation loss: 1.977880487839381

Epoch: 5| Step: 4
Training loss: 2.1376705169677734
Validation loss: 1.9888820201158524

Epoch: 5| Step: 5
Training loss: 1.915205717086792
Validation loss: 1.9761465241511662

Epoch: 5| Step: 6
Training loss: 2.039588451385498
Validation loss: 1.9854468703269958

Epoch: 5| Step: 7
Training loss: 2.0705389976501465
Validation loss: 2.001527031262716

Epoch: 5| Step: 8
Training loss: 1.3668094873428345
Validation loss: 1.9974244683980942

Epoch: 5| Step: 9
Training loss: 1.6013988256454468
Validation loss: 2.003941689928373

Epoch: 5| Step: 10
Training loss: 1.7281301021575928
Validation loss: 2.0201847851276398

Epoch: 5| Step: 11
Training loss: 1.143540859222412
Validation loss: 2.0002588629722595

Epoch: 30| Step: 0
Training loss: 1.7903423309326172
Validation loss: 1.9738501459360123

Epoch: 5| Step: 1
Training loss: 1.8374677896499634
Validation loss: 1.9662597527106602

Epoch: 5| Step: 2
Training loss: 1.8342692852020264
Validation loss: 1.98027207950751

Epoch: 5| Step: 3
Training loss: 2.0280628204345703
Validation loss: 1.9869015614191692

Epoch: 5| Step: 4
Training loss: 1.8763948678970337
Validation loss: 2.001810853679975

Epoch: 5| Step: 5
Training loss: 1.7310644388198853
Validation loss: 1.9837653984626133

Epoch: 5| Step: 6
Training loss: 1.8744022846221924
Validation loss: 1.9952910492817562

Epoch: 5| Step: 7
Training loss: 1.8878281116485596
Validation loss: 1.9673921316862106

Epoch: 5| Step: 8
Training loss: 1.3584315776824951
Validation loss: 1.9608445713917415

Epoch: 5| Step: 9
Training loss: 1.954087495803833
Validation loss: 1.9859980841477711

Epoch: 5| Step: 10
Training loss: 3.086829900741577
Validation loss: 1.9757745762666066

Epoch: 5| Step: 11
Training loss: 1.65610671043396
Validation loss: 1.975275531411171

Epoch: 31| Step: 0
Training loss: 1.5567370653152466
Validation loss: 1.9994028707345326

Epoch: 5| Step: 1
Training loss: 2.5660622119903564
Validation loss: 2.0247734437386193

Epoch: 5| Step: 2
Training loss: 1.944888710975647
Validation loss: 2.0265192141135535

Epoch: 5| Step: 3
Training loss: 1.6480143070220947
Validation loss: 1.9981945306062698

Epoch: 5| Step: 4
Training loss: 2.233562469482422
Validation loss: 2.0408516923586526

Epoch: 5| Step: 5
Training loss: 1.8093233108520508
Validation loss: 2.0319606910149255

Epoch: 5| Step: 6
Training loss: 1.9464194774627686
Validation loss: 2.03394981722037

Epoch: 5| Step: 7
Training loss: 1.7198657989501953
Validation loss: 2.0450955480337143

Epoch: 5| Step: 8
Training loss: 1.97869074344635
Validation loss: 2.052508349219958

Epoch: 5| Step: 9
Training loss: 2.056344985961914
Validation loss: 2.0196477472782135

Epoch: 5| Step: 10
Training loss: 1.7586820125579834
Validation loss: 1.9762326230605443

Epoch: 5| Step: 11
Training loss: 2.3003573417663574
Validation loss: 1.9837846606969833

Epoch: 32| Step: 0
Training loss: 1.5412124395370483
Validation loss: 1.9908133000135422

Epoch: 5| Step: 1
Training loss: 1.7055237293243408
Validation loss: 1.9979672481616337

Epoch: 5| Step: 2
Training loss: 1.7559181451797485
Validation loss: 1.9837052275737126

Epoch: 5| Step: 3
Training loss: 2.0243208408355713
Validation loss: 1.9721627682447433

Epoch: 5| Step: 4
Training loss: 2.075969934463501
Validation loss: 1.994201550881068

Epoch: 5| Step: 5
Training loss: 1.6378726959228516
Validation loss: 1.9655706882476807

Epoch: 5| Step: 6
Training loss: 2.0831542015075684
Validation loss: 1.9805379559596379

Epoch: 5| Step: 7
Training loss: 2.0442559719085693
Validation loss: 1.9800051003694534

Epoch: 5| Step: 8
Training loss: 2.068183422088623
Validation loss: 1.9706358859936397

Epoch: 5| Step: 9
Training loss: 2.008256435394287
Validation loss: 1.9943813383579254

Epoch: 5| Step: 10
Training loss: 1.5555684566497803
Validation loss: 2.0046875725189843

Epoch: 5| Step: 11
Training loss: 4.033114433288574
Validation loss: 1.9910332014163334

Epoch: 33| Step: 0
Training loss: 1.8226597309112549
Validation loss: 1.9911589374144871

Epoch: 5| Step: 1
Training loss: 1.7610315084457397
Validation loss: 1.9870471407969792

Epoch: 5| Step: 2
Training loss: 1.821898102760315
Validation loss: 1.9659302483002346

Epoch: 5| Step: 3
Training loss: 2.526496171951294
Validation loss: 1.9762238959471385

Epoch: 5| Step: 4
Training loss: 1.4411441087722778
Validation loss: 1.971153701345126

Epoch: 5| Step: 5
Training loss: 1.434200644493103
Validation loss: 1.9659716933965683

Epoch: 5| Step: 6
Training loss: 1.960593819618225
Validation loss: 1.9580139368772507

Epoch: 5| Step: 7
Training loss: 2.621480703353882
Validation loss: 1.9661708424488704

Epoch: 5| Step: 8
Training loss: 1.924955129623413
Validation loss: 1.9703103452920914

Epoch: 5| Step: 9
Training loss: 1.652523398399353
Validation loss: 1.9779155999422073

Epoch: 5| Step: 10
Training loss: 2.192829132080078
Validation loss: 1.9854004631439846

Epoch: 5| Step: 11
Training loss: 2.3698086738586426
Validation loss: 1.9849074681599934

Epoch: 34| Step: 0
Training loss: 1.9687858819961548
Validation loss: 1.99116184314092

Epoch: 5| Step: 1
Training loss: 1.825500249862671
Validation loss: 1.9933936893939972

Epoch: 5| Step: 2
Training loss: 1.9118953943252563
Validation loss: 2.0109852850437164

Epoch: 5| Step: 3
Training loss: 2.185080051422119
Validation loss: 2.0267675668001175

Epoch: 5| Step: 4
Training loss: 1.0805281400680542
Validation loss: 2.036799818277359

Epoch: 5| Step: 5
Training loss: 2.0597546100616455
Validation loss: 2.069212963183721

Epoch: 5| Step: 6
Training loss: 1.9074980020523071
Validation loss: 2.05386591454347

Epoch: 5| Step: 7
Training loss: 2.3687222003936768
Validation loss: 2.0980952133735022

Epoch: 5| Step: 8
Training loss: 1.8656494617462158
Validation loss: 2.0910638868808746

Epoch: 5| Step: 9
Training loss: 1.6272354125976562
Validation loss: 2.0672384748856225

Epoch: 5| Step: 10
Training loss: 2.3863041400909424
Validation loss: 2.0634201020002365

Epoch: 5| Step: 11
Training loss: 2.755979061126709
Validation loss: 2.0073957989613214

Epoch: 35| Step: 0
Training loss: 1.8920243978500366
Validation loss: 2.000720515847206

Epoch: 5| Step: 1
Training loss: 1.9833405017852783
Validation loss: 1.9856402277946472

Epoch: 5| Step: 2
Training loss: 1.8140952587127686
Validation loss: 1.9507559736569722

Epoch: 5| Step: 3
Training loss: 2.0268752574920654
Validation loss: 1.9775153050820033

Epoch: 5| Step: 4
Training loss: 2.185305118560791
Validation loss: 1.9768481055895488

Epoch: 5| Step: 5
Training loss: 1.8983087539672852
Validation loss: 1.9680144935846329

Epoch: 5| Step: 6
Training loss: 2.192033290863037
Validation loss: 1.9925603121519089

Epoch: 5| Step: 7
Training loss: 2.039046049118042
Validation loss: 1.9897299110889435

Epoch: 5| Step: 8
Training loss: 1.5510551929473877
Validation loss: 1.9979909658432007

Epoch: 5| Step: 9
Training loss: 2.312417507171631
Validation loss: 1.9753750612338383

Epoch: 5| Step: 10
Training loss: 1.7183105945587158
Validation loss: 1.9752551466226578

Epoch: 5| Step: 11
Training loss: 2.7575764656066895
Validation loss: 1.9857453952232997

Epoch: 36| Step: 0
Training loss: 1.9452342987060547
Validation loss: 1.955237050851186

Epoch: 5| Step: 1
Training loss: 1.7913291454315186
Validation loss: 1.968188315629959

Epoch: 5| Step: 2
Training loss: 1.6473783254623413
Validation loss: 1.954104259610176

Epoch: 5| Step: 3
Training loss: 1.6975562572479248
Validation loss: 1.9901921649773915

Epoch: 5| Step: 4
Training loss: 2.2411763668060303
Validation loss: 2.0160126934448876

Epoch: 5| Step: 5
Training loss: 2.2737419605255127
Validation loss: 2.0334806690613427

Epoch: 5| Step: 6
Training loss: 2.073514223098755
Validation loss: 2.0403396785259247

Epoch: 5| Step: 7
Training loss: 1.788987398147583
Validation loss: 2.0196946958700814

Epoch: 5| Step: 8
Training loss: 1.694088339805603
Validation loss: 2.0149726370970407

Epoch: 5| Step: 9
Training loss: 2.0665206909179688
Validation loss: 2.0174053559700647

Epoch: 5| Step: 10
Training loss: 1.9530398845672607
Validation loss: 2.0489353438218436

Epoch: 5| Step: 11
Training loss: 1.7497920989990234
Validation loss: 2.02493125696977

Epoch: 37| Step: 0
Training loss: 2.196258783340454
Validation loss: 2.0295007824897766

Epoch: 5| Step: 1
Training loss: 1.213449478149414
Validation loss: 2.0472756127516427

Epoch: 5| Step: 2
Training loss: 2.626887321472168
Validation loss: 2.0273199379444122

Epoch: 5| Step: 3
Training loss: 1.8782272338867188
Validation loss: 2.0388480722904205

Epoch: 5| Step: 4
Training loss: 1.4590293169021606
Validation loss: 2.0447548429171243

Epoch: 5| Step: 5
Training loss: 2.3175249099731445
Validation loss: 2.0413853526115417

Epoch: 5| Step: 6
Training loss: 1.5732465982437134
Validation loss: 2.0336344043413797

Epoch: 5| Step: 7
Training loss: 1.4636634588241577
Validation loss: 2.0050893425941467

Epoch: 5| Step: 8
Training loss: 2.009744882583618
Validation loss: 2.00720622142156

Epoch: 5| Step: 9
Training loss: 2.046621799468994
Validation loss: 1.99806742866834

Epoch: 5| Step: 10
Training loss: 1.975709319114685
Validation loss: 1.9939713577429454

Epoch: 5| Step: 11
Training loss: 2.7503185272216797
Validation loss: 1.9777254611253738

Epoch: 38| Step: 0
Training loss: 2.320971727371216
Validation loss: 1.9692977319161098

Epoch: 5| Step: 1
Training loss: 1.8751239776611328
Validation loss: 1.9615289320548375

Epoch: 5| Step: 2
Training loss: 1.581071138381958
Validation loss: 1.9582398583491643

Epoch: 5| Step: 3
Training loss: 1.6057465076446533
Validation loss: 1.957099253932635

Epoch: 5| Step: 4
Training loss: 1.9611022472381592
Validation loss: 1.9760341544946034

Epoch: 5| Step: 5
Training loss: 2.160907745361328
Validation loss: 1.971279039978981

Epoch: 5| Step: 6
Training loss: 1.889740228652954
Validation loss: 1.9623590658108394

Epoch: 5| Step: 7
Training loss: 1.5521879196166992
Validation loss: 1.957731266816457

Epoch: 5| Step: 8
Training loss: 2.0706496238708496
Validation loss: 1.9610594759384792

Epoch: 5| Step: 9
Training loss: 1.9774659872055054
Validation loss: 1.9812556207180023

Epoch: 5| Step: 10
Training loss: 2.008563995361328
Validation loss: 1.9862206727266312

Epoch: 5| Step: 11
Training loss: 1.944460153579712
Validation loss: 1.9858999401330948

Epoch: 39| Step: 0
Training loss: 1.5710437297821045
Validation loss: 2.002511128783226

Epoch: 5| Step: 1
Training loss: 2.1723341941833496
Validation loss: 1.9696450233459473

Epoch: 5| Step: 2
Training loss: 1.5144556760787964
Validation loss: 1.9958520730336506

Epoch: 5| Step: 3
Training loss: 2.088671922683716
Validation loss: 2.0003049770991006

Epoch: 5| Step: 4
Training loss: 1.906053900718689
Validation loss: 1.9921349535385768

Epoch: 5| Step: 5
Training loss: 2.025899887084961
Validation loss: 1.992633432149887

Epoch: 5| Step: 6
Training loss: 1.4477059841156006
Validation loss: 1.9800999363263447

Epoch: 5| Step: 7
Training loss: 2.614015817642212
Validation loss: 1.974794367949168

Epoch: 5| Step: 8
Training loss: 1.7391226291656494
Validation loss: 1.9940591951211293

Epoch: 5| Step: 9
Training loss: 1.5545892715454102
Validation loss: 1.9947956750790279

Epoch: 5| Step: 10
Training loss: 2.202942371368408
Validation loss: 1.9956650286912918

Epoch: 5| Step: 11
Training loss: 1.652172327041626
Validation loss: 1.9934532344341278

Epoch: 40| Step: 0
Training loss: 1.7663809061050415
Validation loss: 1.9983905653158824

Epoch: 5| Step: 1
Training loss: 1.851921796798706
Validation loss: 1.9650824815034866

Epoch: 5| Step: 2
Training loss: 2.1009421348571777
Validation loss: 1.977124924461047

Epoch: 5| Step: 3
Training loss: 1.685291051864624
Validation loss: 1.9627657234668732

Epoch: 5| Step: 4
Training loss: 1.8994544744491577
Validation loss: 1.9672325352827709

Epoch: 5| Step: 5
Training loss: 2.0130650997161865
Validation loss: 2.003653128941854

Epoch: 5| Step: 6
Training loss: 1.7091453075408936
Validation loss: 1.9697859237591426

Epoch: 5| Step: 7
Training loss: 1.8483409881591797
Validation loss: 1.9880740692218144

Epoch: 5| Step: 8
Training loss: 1.9611555337905884
Validation loss: 1.9816862444082897

Epoch: 5| Step: 9
Training loss: 2.180565357208252
Validation loss: 1.9883743325869243

Epoch: 5| Step: 10
Training loss: 1.6170152425765991
Validation loss: 2.0151489973068237

Epoch: 5| Step: 11
Training loss: 1.3058832883834839
Validation loss: 1.9990501701831818

Epoch: 41| Step: 0
Training loss: 2.557873010635376
Validation loss: 1.9909898986419041

Epoch: 5| Step: 1
Training loss: 1.7456986904144287
Validation loss: 2.00780658920606

Epoch: 5| Step: 2
Training loss: 2.589357852935791
Validation loss: 2.0015814950068793

Epoch: 5| Step: 3
Training loss: 1.554494023323059
Validation loss: 2.0150910168886185

Epoch: 5| Step: 4
Training loss: 1.6479705572128296
Validation loss: 2.0114346941312156

Epoch: 5| Step: 5
Training loss: 1.4309275150299072
Validation loss: 2.0374321937561035

Epoch: 5| Step: 6
Training loss: 2.043637752532959
Validation loss: 2.019565607110659

Epoch: 5| Step: 7
Training loss: 1.771515130996704
Validation loss: 1.9842174698909123

Epoch: 5| Step: 8
Training loss: 1.54488205909729
Validation loss: 2.007885828614235

Epoch: 5| Step: 9
Training loss: 1.7315784692764282
Validation loss: 1.9927418529987335

Epoch: 5| Step: 10
Training loss: 1.9674288034439087
Validation loss: 1.9683983623981476

Epoch: 5| Step: 11
Training loss: 2.656559467315674
Validation loss: 1.963397999604543

Epoch: 42| Step: 0
Training loss: 1.9167839288711548
Validation loss: 1.988935296734174

Epoch: 5| Step: 1
Training loss: 1.5490550994873047
Validation loss: 1.985733966032664

Epoch: 5| Step: 2
Training loss: 1.9154367446899414
Validation loss: 1.9864645103613536

Epoch: 5| Step: 3
Training loss: 1.9303910732269287
Validation loss: 2.0216160863637924

Epoch: 5| Step: 4
Training loss: 1.2507158517837524
Validation loss: 2.00842476884524

Epoch: 5| Step: 5
Training loss: 1.925262212753296
Validation loss: 2.021937300761541

Epoch: 5| Step: 6
Training loss: 1.9607235193252563
Validation loss: 2.01040584842364

Epoch: 5| Step: 7
Training loss: 1.4104652404785156
Validation loss: 2.015071908632914

Epoch: 5| Step: 8
Training loss: 1.9822826385498047
Validation loss: 2.0304202288389206

Epoch: 5| Step: 9
Training loss: 2.2925148010253906
Validation loss: 1.9999099175135295

Epoch: 5| Step: 10
Training loss: 2.351008176803589
Validation loss: 1.9720004151264827

Epoch: 5| Step: 11
Training loss: 2.2619986534118652
Validation loss: 1.991855412721634

Epoch: 43| Step: 0
Training loss: 1.3749195337295532
Validation loss: 1.9728520860274632

Epoch: 5| Step: 1
Training loss: 2.322714328765869
Validation loss: 1.9445380518833797

Epoch: 5| Step: 2
Training loss: 1.9462627172470093
Validation loss: 1.9618330548206966

Epoch: 5| Step: 3
Training loss: 1.5421302318572998
Validation loss: 1.9636000047127407

Epoch: 5| Step: 4
Training loss: 2.412367105484009
Validation loss: 1.9642412414153416

Epoch: 5| Step: 5
Training loss: 1.9871418476104736
Validation loss: 1.941713531812032

Epoch: 5| Step: 6
Training loss: 1.3430439233779907
Validation loss: 1.9970043698946636

Epoch: 5| Step: 7
Training loss: 2.133626699447632
Validation loss: 1.9541642765204112

Epoch: 5| Step: 8
Training loss: 2.234511375427246
Validation loss: 1.9751247366269429

Epoch: 5| Step: 9
Training loss: 1.497503638267517
Validation loss: 1.983836904168129

Epoch: 5| Step: 10
Training loss: 2.160810947418213
Validation loss: 1.9921499292055767

Epoch: 5| Step: 11
Training loss: 1.0202953815460205
Validation loss: 2.0018383463223777

Epoch: 44| Step: 0
Training loss: 1.6865737438201904
Validation loss: 1.97817762196064

Epoch: 5| Step: 1
Training loss: 1.812731146812439
Validation loss: 1.989067276318868

Epoch: 5| Step: 2
Training loss: 1.926121711730957
Validation loss: 2.0048005332549415

Epoch: 5| Step: 3
Training loss: 1.9674358367919922
Validation loss: 2.0218964715798697

Epoch: 5| Step: 4
Training loss: 1.8283166885375977
Validation loss: 2.011687532067299

Epoch: 5| Step: 5
Training loss: 1.9249746799468994
Validation loss: 2.0035968720912933

Epoch: 5| Step: 6
Training loss: 1.7623002529144287
Validation loss: 1.9919623186190922

Epoch: 5| Step: 7
Training loss: 2.115440845489502
Validation loss: 1.99947756032149

Epoch: 5| Step: 8
Training loss: 1.5896272659301758
Validation loss: 1.9917242427666981

Epoch: 5| Step: 9
Training loss: 2.206549882888794
Validation loss: 1.9885301341613133

Epoch: 5| Step: 10
Training loss: 1.8392765522003174
Validation loss: 1.9779970198869705

Epoch: 5| Step: 11
Training loss: 1.592266321182251
Validation loss: 1.9651267727216084

Epoch: 45| Step: 0
Training loss: 1.6907856464385986
Validation loss: 1.993601640065511

Epoch: 5| Step: 1
Training loss: 1.5515196323394775
Validation loss: 1.991030290722847

Epoch: 5| Step: 2
Training loss: 2.0368783473968506
Validation loss: 1.9728391965230305

Epoch: 5| Step: 3
Training loss: 2.1264500617980957
Validation loss: 1.9949838121732075

Epoch: 5| Step: 4
Training loss: 2.0711965560913086
Validation loss: 1.9853270848592122

Epoch: 5| Step: 5
Training loss: 2.015204906463623
Validation loss: 1.9992820819218953

Epoch: 5| Step: 6
Training loss: 1.8457647562026978
Validation loss: 1.9656218936045964

Epoch: 5| Step: 7
Training loss: 1.5603437423706055
Validation loss: 1.9892161687215169

Epoch: 5| Step: 8
Training loss: 1.945117712020874
Validation loss: 1.9939749886592228

Epoch: 5| Step: 9
Training loss: 1.599601149559021
Validation loss: 1.9935345103343327

Epoch: 5| Step: 10
Training loss: 1.9745041131973267
Validation loss: 2.010341987013817

Epoch: 5| Step: 11
Training loss: 1.5645334720611572
Validation loss: 2.0113494098186493

Epoch: 46| Step: 0
Training loss: 1.6871410608291626
Validation loss: 1.9983557562033336

Epoch: 5| Step: 1
Training loss: 1.8261101245880127
Validation loss: 1.9879029492537181

Epoch: 5| Step: 2
Training loss: 2.0417306423187256
Validation loss: 2.0043463905652366

Epoch: 5| Step: 3
Training loss: 1.2949836254119873
Validation loss: 1.9907811532417934

Epoch: 5| Step: 4
Training loss: 1.904099702835083
Validation loss: 1.9799105475346248

Epoch: 5| Step: 5
Training loss: 2.2412376403808594
Validation loss: 1.98062298198541

Epoch: 5| Step: 6
Training loss: 1.8246572017669678
Validation loss: 1.9575940817594528

Epoch: 5| Step: 7
Training loss: 1.5577847957611084
Validation loss: 1.9584128608306248

Epoch: 5| Step: 8
Training loss: 2.284848928451538
Validation loss: 1.9619046499331791

Epoch: 5| Step: 9
Training loss: 2.2074995040893555
Validation loss: 1.9736329317092896

Epoch: 5| Step: 10
Training loss: 1.3407353162765503
Validation loss: 1.9788099080324173

Epoch: 5| Step: 11
Training loss: 1.9981391429901123
Validation loss: 1.9670507113138835

Epoch: 47| Step: 0
Training loss: 1.9604336023330688
Validation loss: 1.9743406424919765

Epoch: 5| Step: 1
Training loss: 1.83185613155365
Validation loss: 1.9561831454435985

Epoch: 5| Step: 2
Training loss: 2.395010471343994
Validation loss: 1.952431286374728

Epoch: 5| Step: 3
Training loss: 1.4725918769836426
Validation loss: 1.9659904887278874

Epoch: 5| Step: 4
Training loss: 2.4509153366088867
Validation loss: 1.9748378743728001

Epoch: 5| Step: 5
Training loss: 1.2208986282348633
Validation loss: 1.98946247001489

Epoch: 5| Step: 6
Training loss: 1.6537940502166748
Validation loss: 2.0017127941052117

Epoch: 5| Step: 7
Training loss: 1.6153266429901123
Validation loss: 1.9740682244300842

Epoch: 5| Step: 8
Training loss: 1.627669095993042
Validation loss: 1.9841339389483135

Epoch: 5| Step: 9
Training loss: 2.1630821228027344
Validation loss: 2.016273279984792

Epoch: 5| Step: 10
Training loss: 1.6564171314239502
Validation loss: 2.015301465988159

Epoch: 5| Step: 11
Training loss: 2.5794947147369385
Validation loss: 2.042856976389885

Epoch: 48| Step: 0
Training loss: 1.9821994304656982
Validation loss: 2.0050524969895682

Epoch: 5| Step: 1
Training loss: 2.081106662750244
Validation loss: 1.9841444542010624

Epoch: 5| Step: 2
Training loss: 2.0633862018585205
Validation loss: 1.9779105981190999

Epoch: 5| Step: 3
Training loss: 1.839311957359314
Validation loss: 2.010034923752149

Epoch: 5| Step: 4
Training loss: 1.831546425819397
Validation loss: 1.9630763034025829

Epoch: 5| Step: 5
Training loss: 2.198516845703125
Validation loss: 1.967539022366206

Epoch: 5| Step: 6
Training loss: 1.7054065465927124
Validation loss: 1.978660856684049

Epoch: 5| Step: 7
Training loss: 1.6897590160369873
Validation loss: 1.9615250925223033

Epoch: 5| Step: 8
Training loss: 2.192317485809326
Validation loss: 1.9864818106094997

Epoch: 5| Step: 9
Training loss: 1.3857905864715576
Validation loss: 1.9856115976969402

Epoch: 5| Step: 10
Training loss: 1.4772651195526123
Validation loss: 1.9492051204045613

Epoch: 5| Step: 11
Training loss: 0.9961861371994019
Validation loss: 1.9753023038307826

Epoch: 49| Step: 0
Training loss: 1.885229468345642
Validation loss: 1.9834407518307369

Epoch: 5| Step: 1
Training loss: 1.7147362232208252
Validation loss: 1.9926372518142064

Epoch: 5| Step: 2
Training loss: 1.7131767272949219
Validation loss: 1.9816734194755554

Epoch: 5| Step: 3
Training loss: 2.594329595565796
Validation loss: 2.0118568390607834

Epoch: 5| Step: 4
Training loss: 1.9048115015029907
Validation loss: 2.017354905605316

Epoch: 5| Step: 5
Training loss: 2.092552900314331
Validation loss: 2.004264459013939

Epoch: 5| Step: 6
Training loss: 1.5339874029159546
Validation loss: 2.0194457521041236

Epoch: 5| Step: 7
Training loss: 1.2410125732421875
Validation loss: 2.008281280597051

Epoch: 5| Step: 8
Training loss: 1.4901186227798462
Validation loss: 2.0224197854598365

Epoch: 5| Step: 9
Training loss: 1.8454434871673584
Validation loss: 2.0127111872037253

Epoch: 5| Step: 10
Training loss: 1.8581043481826782
Validation loss: 2.027690793077151

Epoch: 5| Step: 11
Training loss: 3.051807403564453
Validation loss: 2.0009269962708154

Epoch: 50| Step: 0
Training loss: 1.5200449228286743
Validation loss: 1.9940742750962575

Epoch: 5| Step: 1
Training loss: 2.415053606033325
Validation loss: 1.9691306898991268

Epoch: 5| Step: 2
Training loss: 1.5958101749420166
Validation loss: 1.9724546919266384

Epoch: 5| Step: 3
Training loss: 1.647708535194397
Validation loss: 1.9536064267158508

Epoch: 5| Step: 4
Training loss: 1.5112205743789673
Validation loss: 1.9604565799236298

Epoch: 5| Step: 5
Training loss: 2.0983738899230957
Validation loss: 1.9883489807446797

Epoch: 5| Step: 6
Training loss: 1.6752086877822876
Validation loss: 1.983750452597936

Epoch: 5| Step: 7
Training loss: 2.294283390045166
Validation loss: 1.9725184539953868

Epoch: 5| Step: 8
Training loss: 2.0109941959381104
Validation loss: 1.960424120227496

Epoch: 5| Step: 9
Training loss: 1.8199939727783203
Validation loss: 1.9613233357667923

Epoch: 5| Step: 10
Training loss: 1.6960426568984985
Validation loss: 1.9945877691109974

Epoch: 5| Step: 11
Training loss: 1.731099009513855
Validation loss: 1.98522254327933

Epoch: 51| Step: 0
Training loss: 1.4774330854415894
Validation loss: 1.9704083651304245

Epoch: 5| Step: 1
Training loss: 1.9247970581054688
Validation loss: 1.9858054866393406

Epoch: 5| Step: 2
Training loss: 1.9958326816558838
Validation loss: 1.96987950305144

Epoch: 5| Step: 3
Training loss: 1.5431947708129883
Validation loss: 1.9619119117657344

Epoch: 5| Step: 4
Training loss: 1.980872392654419
Validation loss: 1.9734346270561218

Epoch: 5| Step: 5
Training loss: 1.8453487157821655
Validation loss: 1.9719904015461605

Epoch: 5| Step: 6
Training loss: 1.985206961631775
Validation loss: 1.978651265303294

Epoch: 5| Step: 7
Training loss: 2.044339179992676
Validation loss: 1.978186974922816

Epoch: 5| Step: 8
Training loss: 1.8665844202041626
Validation loss: 1.9611558616161346

Epoch: 5| Step: 9
Training loss: 1.4380929470062256
Validation loss: 1.984313373764356

Epoch: 5| Step: 10
Training loss: 1.6820590496063232
Validation loss: 1.975181058049202

Epoch: 5| Step: 11
Training loss: 2.218208074569702
Validation loss: 1.9913071890672047

Epoch: 52| Step: 0
Training loss: 1.5280821323394775
Validation loss: 2.0117606868346534

Epoch: 5| Step: 1
Training loss: 2.281782388687134
Validation loss: 2.0096268306175866

Epoch: 5| Step: 2
Training loss: 1.8443559408187866
Validation loss: 2.090369959672292

Epoch: 5| Step: 3
Training loss: 1.660112738609314
Validation loss: 2.058856571714083

Epoch: 5| Step: 4
Training loss: 2.0122475624084473
Validation loss: 2.090376913547516

Epoch: 5| Step: 5
Training loss: 2.493272304534912
Validation loss: 2.083561589320501

Epoch: 5| Step: 6
Training loss: 1.798744559288025
Validation loss: 2.0785497973362603

Epoch: 5| Step: 7
Training loss: 2.1747450828552246
Validation loss: 2.058888703584671

Epoch: 5| Step: 8
Training loss: 1.698383092880249
Validation loss: 1.997634157538414

Epoch: 5| Step: 9
Training loss: 1.8146482706069946
Validation loss: 2.0094665537277856

Epoch: 5| Step: 10
Training loss: 1.1852036714553833
Validation loss: 1.9815441419680913

Epoch: 5| Step: 11
Training loss: 1.6820913553237915
Validation loss: 1.9789330959320068

Epoch: 53| Step: 0
Training loss: 1.6606216430664062
Validation loss: 1.9614956478277843

Epoch: 5| Step: 1
Training loss: 1.8695566654205322
Validation loss: 1.9837163239717484

Epoch: 5| Step: 2
Training loss: 1.9315626621246338
Validation loss: 1.9790216088294983

Epoch: 5| Step: 3
Training loss: 1.7875112295150757
Validation loss: 1.9561355412006378

Epoch: 5| Step: 4
Training loss: 1.5425012111663818
Validation loss: 1.965803623199463

Epoch: 5| Step: 5
Training loss: 1.800166368484497
Validation loss: 1.9682891915241878

Epoch: 5| Step: 6
Training loss: 1.7446321249008179
Validation loss: 1.9636581440766652

Epoch: 5| Step: 7
Training loss: 2.013338565826416
Validation loss: 1.9708985338608425

Epoch: 5| Step: 8
Training loss: 2.195460796356201
Validation loss: 1.9749716172615688

Epoch: 5| Step: 9
Training loss: 1.7000534534454346
Validation loss: 2.0133618215719857

Epoch: 5| Step: 10
Training loss: 1.7481117248535156
Validation loss: 1.9947201112906139

Epoch: 5| Step: 11
Training loss: 1.5910526514053345
Validation loss: 2.029397855202357

Epoch: 54| Step: 0
Training loss: 2.5324079990386963
Validation loss: 2.0336097528537116

Epoch: 5| Step: 1
Training loss: 2.160111665725708
Validation loss: 2.0708171327908835

Epoch: 5| Step: 2
Training loss: 1.622348427772522
Validation loss: 2.0369662940502167

Epoch: 5| Step: 3
Training loss: 1.1948169469833374
Validation loss: 2.0480921069780984

Epoch: 5| Step: 4
Training loss: 2.1542434692382812
Validation loss: 2.046599263946215

Epoch: 5| Step: 5
Training loss: 1.7161659002304077
Validation loss: 2.0411936144034066

Epoch: 5| Step: 6
Training loss: 1.6907494068145752
Validation loss: 1.985647181669871

Epoch: 5| Step: 7
Training loss: 1.6848125457763672
Validation loss: 1.967058390378952

Epoch: 5| Step: 8
Training loss: 1.658913254737854
Validation loss: 1.9861502399047215

Epoch: 5| Step: 9
Training loss: 1.5842339992523193
Validation loss: 1.9665921827157338

Epoch: 5| Step: 10
Training loss: 1.62296462059021
Validation loss: 1.9777639955282211

Epoch: 5| Step: 11
Training loss: 3.31929874420166
Validation loss: 1.9517465978860855

Epoch: 55| Step: 0
Training loss: 1.7405250072479248
Validation loss: 1.9586675316095352

Epoch: 5| Step: 1
Training loss: 2.18327260017395
Validation loss: 1.9784147689739864

Epoch: 5| Step: 2
Training loss: 2.176617383956909
Validation loss: 1.9697602341572444

Epoch: 5| Step: 3
Training loss: 1.99240243434906
Validation loss: 1.9776131808757782

Epoch: 5| Step: 4
Training loss: 1.6198688745498657
Validation loss: 1.9608451773722966

Epoch: 5| Step: 5
Training loss: 2.036649227142334
Validation loss: 1.9641668299833934

Epoch: 5| Step: 6
Training loss: 1.8122444152832031
Validation loss: 2.006878266731898

Epoch: 5| Step: 7
Training loss: 2.3098063468933105
Validation loss: 1.9714624832073848

Epoch: 5| Step: 8
Training loss: 1.5186412334442139
Validation loss: 1.9728044668833415

Epoch: 5| Step: 9
Training loss: 1.4081103801727295
Validation loss: 1.997293546795845

Epoch: 5| Step: 10
Training loss: 1.158341407775879
Validation loss: 2.0351459284623465

Epoch: 5| Step: 11
Training loss: 1.1152970790863037
Validation loss: 2.018000473578771

Epoch: 56| Step: 0
Training loss: 1.5574623346328735
Validation loss: 2.0203202168146768

Epoch: 5| Step: 1
Training loss: 1.5059869289398193
Validation loss: 2.0428722202777863

Epoch: 5| Step: 2
Training loss: 1.7852075099945068
Validation loss: 2.0606260697046914

Epoch: 5| Step: 3
Training loss: 2.282817840576172
Validation loss: 2.0241983930269876

Epoch: 5| Step: 4
Training loss: 1.8479324579238892
Validation loss: 2.0401382048924765

Epoch: 5| Step: 5
Training loss: 1.7902936935424805
Validation loss: 2.0742479662100473

Epoch: 5| Step: 6
Training loss: 2.0239617824554443
Validation loss: 2.0773886988560357

Epoch: 5| Step: 7
Training loss: 2.3968074321746826
Validation loss: 2.031824936469396

Epoch: 5| Step: 8
Training loss: 1.0575284957885742
Validation loss: 2.0591039458910623

Epoch: 5| Step: 9
Training loss: 2.004889965057373
Validation loss: 2.044776807228724

Epoch: 5| Step: 10
Training loss: 1.239990472793579
Validation loss: 2.0158459742863974

Epoch: 5| Step: 11
Training loss: 2.041118621826172
Validation loss: 1.990095963080724

Epoch: 57| Step: 0
Training loss: 1.757971167564392
Validation loss: 1.9700391193230946

Epoch: 5| Step: 1
Training loss: 2.281278133392334
Validation loss: 1.9767910540103912

Epoch: 5| Step: 2
Training loss: 1.4726793766021729
Validation loss: 1.9743391076723735

Epoch: 5| Step: 3
Training loss: 1.3318018913269043
Validation loss: 1.958845113714536

Epoch: 5| Step: 4
Training loss: 1.9033037424087524
Validation loss: 1.964918499191602

Epoch: 5| Step: 5
Training loss: 2.212723970413208
Validation loss: 1.9772708465655644

Epoch: 5| Step: 6
Training loss: 1.4768096208572388
Validation loss: 1.983423074086507

Epoch: 5| Step: 7
Training loss: 1.4730714559555054
Validation loss: 1.963327909509341

Epoch: 5| Step: 8
Training loss: 1.963361382484436
Validation loss: 1.9780987401803334

Epoch: 5| Step: 9
Training loss: 2.561124086380005
Validation loss: 1.9444571534792583

Epoch: 5| Step: 10
Training loss: 1.9783903360366821
Validation loss: 1.971333732207616

Epoch: 5| Step: 11
Training loss: 0.9847495555877686
Validation loss: 1.9502980957428615

Epoch: 58| Step: 0
Training loss: 1.627593755722046
Validation loss: 2.0029097894827523

Epoch: 5| Step: 1
Training loss: 2.095268726348877
Validation loss: 2.0200201918681464

Epoch: 5| Step: 2
Training loss: 1.6232526302337646
Validation loss: 2.040362760424614

Epoch: 5| Step: 3
Training loss: 1.9393012523651123
Validation loss: 2.0905562341213226

Epoch: 5| Step: 4
Training loss: 1.6023916006088257
Validation loss: 2.1047886262337365

Epoch: 5| Step: 5
Training loss: 1.6282466650009155
Validation loss: 2.133844256401062

Epoch: 5| Step: 6
Training loss: 2.089754819869995
Validation loss: 2.0949217081069946

Epoch: 5| Step: 7
Training loss: 1.530276894569397
Validation loss: 2.0624512284994125

Epoch: 5| Step: 8
Training loss: 1.87960946559906
Validation loss: 2.0670851320028305

Epoch: 5| Step: 9
Training loss: 2.036170482635498
Validation loss: 2.0266280422608056

Epoch: 5| Step: 10
Training loss: 1.545641303062439
Validation loss: 2.0078260948260627

Epoch: 5| Step: 11
Training loss: 2.663975715637207
Validation loss: 2.010312949617704

Epoch: 59| Step: 0
Training loss: 2.167621612548828
Validation loss: 1.997045228878657

Epoch: 5| Step: 1
Training loss: 1.4219356775283813
Validation loss: 1.9959126214186351

Epoch: 5| Step: 2
Training loss: 1.4767305850982666
Validation loss: 1.9743591944376628

Epoch: 5| Step: 3
Training loss: 1.6714359521865845
Validation loss: 1.975472167134285

Epoch: 5| Step: 4
Training loss: 1.9262958765029907
Validation loss: 1.977062260111173

Epoch: 5| Step: 5
Training loss: 2.1461403369903564
Validation loss: 1.960009107987086

Epoch: 5| Step: 6
Training loss: 2.229806423187256
Validation loss: 1.9855854958295822

Epoch: 5| Step: 7
Training loss: 1.2246699333190918
Validation loss: 1.9797823280096054

Epoch: 5| Step: 8
Training loss: 1.7870010137557983
Validation loss: 2.017180452744166

Epoch: 5| Step: 9
Training loss: 1.6934669017791748
Validation loss: 2.0077694157759347

Epoch: 5| Step: 10
Training loss: 1.5458440780639648
Validation loss: 1.986412266890208

Epoch: 5| Step: 11
Training loss: 2.3005003929138184
Validation loss: 2.008364349603653

Epoch: 60| Step: 0
Training loss: 1.4332448244094849
Validation loss: 1.994974399606387

Epoch: 5| Step: 1
Training loss: 1.3471769094467163
Validation loss: 2.0043066143989563

Epoch: 5| Step: 2
Training loss: 2.579777240753174
Validation loss: 2.0076264341672263

Epoch: 5| Step: 3
Training loss: 1.467323899269104
Validation loss: 1.9944930722316105

Epoch: 5| Step: 4
Training loss: 1.5039854049682617
Validation loss: 2.023964007695516

Epoch: 5| Step: 5
Training loss: 1.3896944522857666
Validation loss: 2.0139067471027374

Epoch: 5| Step: 6
Training loss: 2.7482566833496094
Validation loss: 2.0153410037358603

Epoch: 5| Step: 7
Training loss: 1.5107659101486206
Validation loss: 2.0145204663276672

Epoch: 5| Step: 8
Training loss: 2.0115535259246826
Validation loss: 1.9883992771307628

Epoch: 5| Step: 9
Training loss: 1.4815924167633057
Validation loss: 1.9938158045212429

Epoch: 5| Step: 10
Training loss: 1.4940836429595947
Validation loss: 2.0001287509997687

Epoch: 5| Step: 11
Training loss: 2.397536277770996
Validation loss: 1.986979345480601

Epoch: 61| Step: 0
Training loss: 1.3589051961898804
Validation loss: 1.9652025252580643

Epoch: 5| Step: 1
Training loss: 2.0232646465301514
Validation loss: 1.9966261982917786

Epoch: 5| Step: 2
Training loss: 1.500730276107788
Validation loss: 1.9462427447239559

Epoch: 5| Step: 3
Training loss: 1.4669675827026367
Validation loss: 1.9649966657161713

Epoch: 5| Step: 4
Training loss: 1.7806122303009033
Validation loss: 1.9708624233802159

Epoch: 5| Step: 5
Training loss: 1.8923389911651611
Validation loss: 1.9537039796511333

Epoch: 5| Step: 6
Training loss: 1.4677600860595703
Validation loss: 1.9813384960095088

Epoch: 5| Step: 7
Training loss: 2.230625629425049
Validation loss: 1.9688417067130406

Epoch: 5| Step: 8
Training loss: 1.9642006158828735
Validation loss: 1.9860089123249054

Epoch: 5| Step: 9
Training loss: 1.699779748916626
Validation loss: 1.982280194759369

Epoch: 5| Step: 10
Training loss: 2.0361735820770264
Validation loss: 1.987406238913536

Epoch: 5| Step: 11
Training loss: 2.224975109100342
Validation loss: 2.0099538465340934

Epoch: 62| Step: 0
Training loss: 1.1898765563964844
Validation loss: 2.00452912847201

Epoch: 5| Step: 1
Training loss: 2.1221847534179688
Validation loss: 2.01571794350942

Epoch: 5| Step: 2
Training loss: 1.7852833271026611
Validation loss: 2.0024450669686

Epoch: 5| Step: 3
Training loss: 1.810546875
Validation loss: 1.9806104203065236

Epoch: 5| Step: 4
Training loss: 1.9950315952301025
Validation loss: 1.9914913823207219

Epoch: 5| Step: 5
Training loss: 2.087571620941162
Validation loss: 1.9747434159119923

Epoch: 5| Step: 6
Training loss: 1.8136358261108398
Validation loss: 1.9880214283863704

Epoch: 5| Step: 7
Training loss: 1.667075514793396
Validation loss: 1.9688950230677922

Epoch: 5| Step: 8
Training loss: 1.443290114402771
Validation loss: 1.9954863687356312

Epoch: 5| Step: 9
Training loss: 1.303322196006775
Validation loss: 1.982044165333112

Epoch: 5| Step: 10
Training loss: 1.864750862121582
Validation loss: 1.9903569221496582

Epoch: 5| Step: 11
Training loss: 1.5118958950042725
Validation loss: 2.003761574625969

Epoch: 63| Step: 0
Training loss: 2.0249733924865723
Validation loss: 2.0224918822447457

Epoch: 5| Step: 1
Training loss: 2.398284435272217
Validation loss: 2.0214952876170478

Epoch: 5| Step: 2
Training loss: 1.1466602087020874
Validation loss: 2.0038706759611764

Epoch: 5| Step: 3
Training loss: 1.1180064678192139
Validation loss: 2.0045932034651437

Epoch: 5| Step: 4
Training loss: 1.3846803903579712
Validation loss: 1.9991015245517094

Epoch: 5| Step: 5
Training loss: 1.8880609273910522
Validation loss: 1.994696502884229

Epoch: 5| Step: 6
Training loss: 2.3233370780944824
Validation loss: 2.011632040143013

Epoch: 5| Step: 7
Training loss: 1.8710883855819702
Validation loss: 1.9719919264316559

Epoch: 5| Step: 8
Training loss: 1.690941572189331
Validation loss: 2.009948417544365

Epoch: 5| Step: 9
Training loss: 1.4478036165237427
Validation loss: 1.9895023951927822

Epoch: 5| Step: 10
Training loss: 1.563619613647461
Validation loss: 1.9718523273865383

Epoch: 5| Step: 11
Training loss: 0.6230983734130859
Validation loss: 2.0040396004915237

Epoch: 64| Step: 0
Training loss: 1.9080969095230103
Validation loss: 1.9894763429959614

Epoch: 5| Step: 1
Training loss: 1.9427378177642822
Validation loss: 1.9610914438962936

Epoch: 5| Step: 2
Training loss: 1.4753572940826416
Validation loss: 1.9869527071714401

Epoch: 5| Step: 3
Training loss: 0.9672948122024536
Validation loss: 1.9773471703131993

Epoch: 5| Step: 4
Training loss: 2.0057387351989746
Validation loss: 1.9856552630662918

Epoch: 5| Step: 5
Training loss: 1.8576329946517944
Validation loss: 1.984980821609497

Epoch: 5| Step: 6
Training loss: 1.5213860273361206
Validation loss: 1.9899353682994843

Epoch: 5| Step: 7
Training loss: 1.8796327114105225
Validation loss: 2.0114724139372506

Epoch: 5| Step: 8
Training loss: 1.9128808975219727
Validation loss: 2.0295254538456597

Epoch: 5| Step: 9
Training loss: 2.0023465156555176
Validation loss: 2.012510056296984

Epoch: 5| Step: 10
Training loss: 1.4351832866668701
Validation loss: 2.0205918004115424

Epoch: 5| Step: 11
Training loss: 0.9289236068725586
Validation loss: 2.0374921758969626

Epoch: 65| Step: 0
Training loss: 1.454021692276001
Validation loss: 2.060112953186035

Epoch: 5| Step: 1
Training loss: 1.8392528295516968
Validation loss: 2.050347000360489

Epoch: 5| Step: 2
Training loss: 1.6177217960357666
Validation loss: 2.0478836596012115

Epoch: 5| Step: 3
Training loss: 2.3920435905456543
Validation loss: 2.047174180547396

Epoch: 5| Step: 4
Training loss: 1.7855857610702515
Validation loss: 2.0349246313174567

Epoch: 5| Step: 5
Training loss: 1.7367979288101196
Validation loss: 1.9940541684627533

Epoch: 5| Step: 6
Training loss: 1.8705486059188843
Validation loss: 1.9985199520985286

Epoch: 5| Step: 7
Training loss: 1.7780240774154663
Validation loss: 1.9492871363957722

Epoch: 5| Step: 8
Training loss: 1.309705376625061
Validation loss: 1.956814020872116

Epoch: 5| Step: 9
Training loss: 1.627819299697876
Validation loss: 1.9937015424172084

Epoch: 5| Step: 10
Training loss: 1.6900513172149658
Validation loss: 1.9850804209709167

Epoch: 5| Step: 11
Training loss: 1.4496595859527588
Validation loss: 1.9811819444100063

Epoch: 66| Step: 0
Training loss: 1.7453587055206299
Validation loss: 1.9900062680244446

Epoch: 5| Step: 1
Training loss: 1.8232653141021729
Validation loss: 1.9808305899302165

Epoch: 5| Step: 2
Training loss: 1.6142137050628662
Validation loss: 1.9663774967193604

Epoch: 5| Step: 3
Training loss: 1.5656417608261108
Validation loss: 2.0206059217453003

Epoch: 5| Step: 4
Training loss: 1.8950735330581665
Validation loss: 2.0021830995877585

Epoch: 5| Step: 5
Training loss: 1.4133403301239014
Validation loss: 2.014580433567365

Epoch: 5| Step: 6
Training loss: 1.5898630619049072
Validation loss: 2.0055913825829825

Epoch: 5| Step: 7
Training loss: 2.229844331741333
Validation loss: 1.9908774842818577

Epoch: 5| Step: 8
Training loss: 1.4817609786987305
Validation loss: 1.9719256907701492

Epoch: 5| Step: 9
Training loss: 1.3723713159561157
Validation loss: 1.970506489276886

Epoch: 5| Step: 10
Training loss: 1.933521032333374
Validation loss: 1.9590315620104473

Epoch: 5| Step: 11
Training loss: 1.9776495695114136
Validation loss: 1.9811884264151256

Epoch: 67| Step: 0
Training loss: 1.410400629043579
Validation loss: 1.9984562893708546

Epoch: 5| Step: 1
Training loss: 1.1469646692276
Validation loss: 1.9949212272961934

Epoch: 5| Step: 2
Training loss: 1.845808744430542
Validation loss: 2.0123172303040824

Epoch: 5| Step: 3
Training loss: 1.6925163269042969
Validation loss: 2.028495952486992

Epoch: 5| Step: 4
Training loss: 1.9979959726333618
Validation loss: 2.060159613688787

Epoch: 5| Step: 5
Training loss: 1.3768062591552734
Validation loss: 2.0545588582754135

Epoch: 5| Step: 6
Training loss: 1.2379521131515503
Validation loss: 2.0690977474053702

Epoch: 5| Step: 7
Training loss: 1.6017048358917236
Validation loss: 2.052647074063619

Epoch: 5| Step: 8
Training loss: 2.037576198577881
Validation loss: 2.0358205487330756

Epoch: 5| Step: 9
Training loss: 2.115021228790283
Validation loss: 2.0107034146785736

Epoch: 5| Step: 10
Training loss: 1.9966773986816406
Validation loss: 2.015145778656006

Epoch: 5| Step: 11
Training loss: 2.473404884338379
Validation loss: 1.9713210413853328

Epoch: 68| Step: 0
Training loss: 1.3782825469970703
Validation loss: 1.9722674041986465

Epoch: 5| Step: 1
Training loss: 1.8763892650604248
Validation loss: 2.0039872229099274

Epoch: 5| Step: 2
Training loss: 2.0715909004211426
Validation loss: 1.9749858379364014

Epoch: 5| Step: 3
Training loss: 1.6886036396026611
Validation loss: 1.9537866860628128

Epoch: 5| Step: 4
Training loss: 1.3570058345794678
Validation loss: 1.9733138581116993

Epoch: 5| Step: 5
Training loss: 2.1142754554748535
Validation loss: 1.965309351682663

Epoch: 5| Step: 6
Training loss: 1.6995494365692139
Validation loss: 2.0050277709960938

Epoch: 5| Step: 7
Training loss: 1.0557007789611816
Validation loss: 1.9907247573137283

Epoch: 5| Step: 8
Training loss: 1.4346166849136353
Validation loss: 2.0153450965881348

Epoch: 5| Step: 9
Training loss: 1.4762417078018188
Validation loss: 2.0104837864637375

Epoch: 5| Step: 10
Training loss: 2.3084774017333984
Validation loss: 2.0060106217861176

Epoch: 5| Step: 11
Training loss: 1.9143588542938232
Validation loss: 1.9962934603293736

Epoch: 69| Step: 0
Training loss: 1.469437837600708
Validation loss: 1.9691604375839233

Epoch: 5| Step: 1
Training loss: 1.6855894327163696
Validation loss: 1.9851551204919815

Epoch: 5| Step: 2
Training loss: 1.1950442790985107
Validation loss: 2.0070232500632605

Epoch: 5| Step: 3
Training loss: 1.5510365962982178
Validation loss: 1.980683038632075

Epoch: 5| Step: 4
Training loss: 1.8553581237792969
Validation loss: 2.0055657625198364

Epoch: 5| Step: 5
Training loss: 1.8161252737045288
Validation loss: 2.00947113831838

Epoch: 5| Step: 6
Training loss: 2.1414830684661865
Validation loss: 1.9916224479675293

Epoch: 5| Step: 7
Training loss: 2.2201175689697266
Validation loss: 2.004378065466881

Epoch: 5| Step: 8
Training loss: 1.2276241779327393
Validation loss: 2.001622955004374

Epoch: 5| Step: 9
Training loss: 1.552624225616455
Validation loss: 1.9821067055066426

Epoch: 5| Step: 10
Training loss: 1.3057115077972412
Validation loss: 1.9850309441486995

Epoch: 5| Step: 11
Training loss: 2.339600086212158
Validation loss: 1.9787502189477284

Epoch: 70| Step: 0
Training loss: 1.3414876461029053
Validation loss: 1.969557563463847

Epoch: 5| Step: 1
Training loss: 1.363149881362915
Validation loss: 2.0196362137794495

Epoch: 5| Step: 2
Training loss: 1.8614838123321533
Validation loss: 1.9877982089916866

Epoch: 5| Step: 3
Training loss: 1.9647451639175415
Validation loss: 1.992185801267624

Epoch: 5| Step: 4
Training loss: 1.7754554748535156
Validation loss: 1.9742330312728882

Epoch: 5| Step: 5
Training loss: 1.6697056293487549
Validation loss: 2.048013389110565

Epoch: 5| Step: 6
Training loss: 1.2270758152008057
Validation loss: 2.0237622807423272

Epoch: 5| Step: 7
Training loss: 1.8340181112289429
Validation loss: 2.0307689160108566

Epoch: 5| Step: 8
Training loss: 2.040870189666748
Validation loss: 2.05000402033329

Epoch: 5| Step: 9
Training loss: 1.3819096088409424
Validation loss: 2.050793727238973

Epoch: 5| Step: 10
Training loss: 1.6536130905151367
Validation loss: 2.103095064560572

Epoch: 5| Step: 11
Training loss: 1.7646926641464233
Validation loss: 2.108595455686251

Epoch: 71| Step: 0
Training loss: 1.8832886219024658
Validation loss: 2.0542447020610175

Epoch: 5| Step: 1
Training loss: 1.6010971069335938
Validation loss: 2.0445059339205423

Epoch: 5| Step: 2
Training loss: 1.3609793186187744
Validation loss: 2.0266351103782654

Epoch: 5| Step: 3
Training loss: 1.6113245487213135
Validation loss: 2.028306767344475

Epoch: 5| Step: 4
Training loss: 1.4585171937942505
Validation loss: 2.024620150526365

Epoch: 5| Step: 5
Training loss: 1.7347195148468018
Validation loss: 2.0182500133911767

Epoch: 5| Step: 6
Training loss: 1.486895203590393
Validation loss: 1.9971456329027812

Epoch: 5| Step: 7
Training loss: 1.6307262182235718
Validation loss: 2.024395535389582

Epoch: 5| Step: 8
Training loss: 1.7516899108886719
Validation loss: 2.0083345423142114

Epoch: 5| Step: 9
Training loss: 1.340767502784729
Validation loss: 1.9863935460646946

Epoch: 5| Step: 10
Training loss: 1.6951545476913452
Validation loss: 1.9826674908399582

Epoch: 5| Step: 11
Training loss: 2.427060127258301
Validation loss: 2.012787848711014

Epoch: 72| Step: 0
Training loss: 2.0352025032043457
Validation loss: 2.008851478497187

Epoch: 5| Step: 1
Training loss: 1.1324970722198486
Validation loss: 2.0149674266576767

Epoch: 5| Step: 2
Training loss: 1.1169524192810059
Validation loss: 2.009644786516825

Epoch: 5| Step: 3
Training loss: 1.3463982343673706
Validation loss: 2.0312650402386985

Epoch: 5| Step: 4
Training loss: 1.3581682443618774
Validation loss: 2.0348291347424188

Epoch: 5| Step: 5
Training loss: 1.3407366275787354
Validation loss: 2.0381395469109216

Epoch: 5| Step: 6
Training loss: 1.872462272644043
Validation loss: 2.0334997922182083

Epoch: 5| Step: 7
Training loss: 1.7643029689788818
Validation loss: 2.0367744664351144

Epoch: 5| Step: 8
Training loss: 2.0244526863098145
Validation loss: 2.0074739207824073

Epoch: 5| Step: 9
Training loss: 1.8619639873504639
Validation loss: 1.9770118842522304

Epoch: 5| Step: 10
Training loss: 2.062246799468994
Validation loss: 2.000473752617836

Epoch: 5| Step: 11
Training loss: 1.737379789352417
Validation loss: 2.024384061495463

Epoch: 73| Step: 0
Training loss: 1.8876569271087646
Validation loss: 2.022215560078621

Epoch: 5| Step: 1
Training loss: 1.2301738262176514
Validation loss: 1.9934283643960953

Epoch: 5| Step: 2
Training loss: 1.9243412017822266
Validation loss: 1.9940832952658336

Epoch: 5| Step: 3
Training loss: 1.203421950340271
Validation loss: 2.0174313882986703

Epoch: 5| Step: 4
Training loss: 1.3164215087890625
Validation loss: 2.036184847354889

Epoch: 5| Step: 5
Training loss: 2.1860897541046143
Validation loss: 2.04765651623408

Epoch: 5| Step: 6
Training loss: 1.7002332210540771
Validation loss: 2.0740858763456345

Epoch: 5| Step: 7
Training loss: 2.1986312866210938
Validation loss: 2.086415042479833

Epoch: 5| Step: 8
Training loss: 1.4596061706542969
Validation loss: 2.05960746606191

Epoch: 5| Step: 9
Training loss: 1.9896167516708374
Validation loss: 2.051977460583051

Epoch: 5| Step: 10
Training loss: 1.3471763134002686
Validation loss: 2.0323925067981086

Epoch: 5| Step: 11
Training loss: 0.6402561664581299
Validation loss: 1.9888011366128922

Epoch: 74| Step: 0
Training loss: 1.592761754989624
Validation loss: 1.9885421444972355

Epoch: 5| Step: 1
Training loss: 1.5397135019302368
Validation loss: 1.9877978066603343

Epoch: 5| Step: 2
Training loss: 2.0836195945739746
Validation loss: 2.002035453915596

Epoch: 5| Step: 3
Training loss: 1.6545854806900024
Validation loss: 2.034109572569529

Epoch: 5| Step: 4
Training loss: 1.5141537189483643
Validation loss: 2.021181811889013

Epoch: 5| Step: 5
Training loss: 1.635084867477417
Validation loss: 2.0082193513711295

Epoch: 5| Step: 6
Training loss: 1.2674345970153809
Validation loss: 1.995810608069102

Epoch: 5| Step: 7
Training loss: 1.4252535104751587
Validation loss: 1.9981295615434647

Epoch: 5| Step: 8
Training loss: 1.758236289024353
Validation loss: 2.009978915254275

Epoch: 5| Step: 9
Training loss: 1.9359102249145508
Validation loss: 2.0703216989835105

Epoch: 5| Step: 10
Training loss: 1.9511241912841797
Validation loss: 2.0965529680252075

Epoch: 5| Step: 11
Training loss: 2.996645927429199
Validation loss: 2.101673980553945

Epoch: 75| Step: 0
Training loss: 2.304896831512451
Validation loss: 2.054892991979917

Epoch: 5| Step: 1
Training loss: 1.4617741107940674
Validation loss: 2.0369320263465247

Epoch: 5| Step: 2
Training loss: 1.5340054035186768
Validation loss: 2.062712331612905

Epoch: 5| Step: 3
Training loss: 1.607134222984314
Validation loss: 2.056427761912346

Epoch: 5| Step: 4
Training loss: 1.6507718563079834
Validation loss: 2.0331573337316513

Epoch: 5| Step: 5
Training loss: 2.2461013793945312
Validation loss: 2.017515858014425

Epoch: 5| Step: 6
Training loss: 1.5373083353042603
Validation loss: 2.000126669804255

Epoch: 5| Step: 7
Training loss: 1.6093671321868896
Validation loss: 2.01264159878095

Epoch: 5| Step: 8
Training loss: 1.0908409357070923
Validation loss: 2.0248498370250068

Epoch: 5| Step: 9
Training loss: 1.5639958381652832
Validation loss: 2.021682227651278

Epoch: 5| Step: 10
Training loss: 1.5151312351226807
Validation loss: 2.0044726580381393

Epoch: 5| Step: 11
Training loss: 0.9678456783294678
Validation loss: 2.007248838742574

Epoch: 76| Step: 0
Training loss: 1.632638931274414
Validation loss: 2.0012908975283303

Epoch: 5| Step: 1
Training loss: 1.3804066181182861
Validation loss: 1.9943948835134506

Epoch: 5| Step: 2
Training loss: 1.157041072845459
Validation loss: 2.001057505607605

Epoch: 5| Step: 3
Training loss: 1.1965653896331787
Validation loss: 2.0275028000275293

Epoch: 5| Step: 4
Training loss: 1.8036167621612549
Validation loss: 2.0133807758490243

Epoch: 5| Step: 5
Training loss: 1.5548683404922485
Validation loss: 2.029469534754753

Epoch: 5| Step: 6
Training loss: 1.5849096775054932
Validation loss: 2.0553417056798935

Epoch: 5| Step: 7
Training loss: 2.371372938156128
Validation loss: 2.0409271915753684

Epoch: 5| Step: 8
Training loss: 1.360656976699829
Validation loss: 2.047635570168495

Epoch: 5| Step: 9
Training loss: 1.4007984399795532
Validation loss: 2.019085322817167

Epoch: 5| Step: 10
Training loss: 2.126614809036255
Validation loss: 2.0116594284772873

Epoch: 5| Step: 11
Training loss: 1.2002270221710205
Validation loss: 2.0109303295612335

Epoch: 77| Step: 0
Training loss: 1.4951000213623047
Validation loss: 2.0042779793341956

Epoch: 5| Step: 1
Training loss: 1.8706709146499634
Validation loss: 1.9678250849246979

Epoch: 5| Step: 2
Training loss: 0.9701107144355774
Validation loss: 2.031531939903895

Epoch: 5| Step: 3
Training loss: 1.6711089611053467
Validation loss: 2.066238611936569

Epoch: 5| Step: 4
Training loss: 1.972686767578125
Validation loss: 2.06220850845178

Epoch: 5| Step: 5
Training loss: 1.908433198928833
Validation loss: 2.0306078493595123

Epoch: 5| Step: 6
Training loss: 1.2887747287750244
Validation loss: 2.067436069250107

Epoch: 5| Step: 7
Training loss: 1.4809640645980835
Validation loss: 2.0543463279803595

Epoch: 5| Step: 8
Training loss: 1.820560097694397
Validation loss: 2.0507147113482156

Epoch: 5| Step: 9
Training loss: 1.9806690216064453
Validation loss: 2.0091071128845215

Epoch: 5| Step: 10
Training loss: 0.9578574895858765
Validation loss: 1.9935768246650696

Epoch: 5| Step: 11
Training loss: 2.027017593383789
Validation loss: 2.015419895450274

Epoch: 78| Step: 0
Training loss: 1.529721736907959
Validation loss: 2.005847508708636

Epoch: 5| Step: 1
Training loss: 1.3997535705566406
Validation loss: 1.9903800586859386

Epoch: 5| Step: 2
Training loss: 1.6197688579559326
Validation loss: 2.0018260727326074

Epoch: 5| Step: 3
Training loss: 2.092054843902588
Validation loss: 2.014414166410764

Epoch: 5| Step: 4
Training loss: 1.7045972347259521
Validation loss: 2.004967605074247

Epoch: 5| Step: 5
Training loss: 1.2451685667037964
Validation loss: 2.0193677047888436

Epoch: 5| Step: 6
Training loss: 1.8690290451049805
Validation loss: 2.0240026315053306

Epoch: 5| Step: 7
Training loss: 1.487725019454956
Validation loss: 2.0107359091440835

Epoch: 5| Step: 8
Training loss: 1.4192352294921875
Validation loss: 2.0079786280790963

Epoch: 5| Step: 9
Training loss: 2.1705496311187744
Validation loss: 2.042096977432569

Epoch: 5| Step: 10
Training loss: 1.3832104206085205
Validation loss: 2.026922499140104

Epoch: 5| Step: 11
Training loss: 0.6944541931152344
Validation loss: 2.097092072168986

Epoch: 79| Step: 0
Training loss: 1.3986111879348755
Validation loss: 2.0452748437722525

Epoch: 5| Step: 1
Training loss: 1.2965542078018188
Validation loss: 2.000039984782537

Epoch: 5| Step: 2
Training loss: 1.4947147369384766
Validation loss: 1.9986029018958409

Epoch: 5| Step: 3
Training loss: 1.6603472232818604
Validation loss: 1.99913689494133

Epoch: 5| Step: 4
Training loss: 1.8839836120605469
Validation loss: 1.9940621952215831

Epoch: 5| Step: 5
Training loss: 1.265351414680481
Validation loss: 1.9737905611594517

Epoch: 5| Step: 6
Training loss: 1.6103445291519165
Validation loss: 1.980281005303065

Epoch: 5| Step: 7
Training loss: 1.2636722326278687
Validation loss: 1.9826241830984752

Epoch: 5| Step: 8
Training loss: 1.812487244606018
Validation loss: 2.0014965186516442

Epoch: 5| Step: 9
Training loss: 1.9993547201156616
Validation loss: 2.016826565066973

Epoch: 5| Step: 10
Training loss: 1.9998859167099
Validation loss: 2.0144664694865546

Epoch: 5| Step: 11
Training loss: 1.0237418413162231
Validation loss: 2.022867366671562

Epoch: 80| Step: 0
Training loss: 1.5781934261322021
Validation loss: 2.0230304847160974

Epoch: 5| Step: 1
Training loss: 1.086176872253418
Validation loss: 1.9924429108699162

Epoch: 5| Step: 2
Training loss: 2.4385712146759033
Validation loss: 1.9864076872666676

Epoch: 5| Step: 3
Training loss: 1.3697513341903687
Validation loss: 2.0113497426112494

Epoch: 5| Step: 4
Training loss: 1.3999913930892944
Validation loss: 2.0074748496214547

Epoch: 5| Step: 5
Training loss: 1.8779897689819336
Validation loss: 2.035064165790876

Epoch: 5| Step: 6
Training loss: 1.4666883945465088
Validation loss: 2.018386632204056

Epoch: 5| Step: 7
Training loss: 1.7386411428451538
Validation loss: 2.0183302710453668

Epoch: 5| Step: 8
Training loss: 1.5960289239883423
Validation loss: 2.0671260257562003

Epoch: 5| Step: 9
Training loss: 1.2647091150283813
Validation loss: 2.0435690730810165

Epoch: 5| Step: 10
Training loss: 1.430987000465393
Validation loss: 2.012726296981176

Epoch: 5| Step: 11
Training loss: 0.9905439019203186
Validation loss: 2.00025337934494

Epoch: 81| Step: 0
Training loss: 1.923081398010254
Validation loss: 2.0019635409116745

Epoch: 5| Step: 1
Training loss: 1.4579026699066162
Validation loss: 1.9995747953653336

Epoch: 5| Step: 2
Training loss: 2.020801544189453
Validation loss: 1.9851793944835663

Epoch: 5| Step: 3
Training loss: 1.3322871923446655
Validation loss: 2.031242618958155

Epoch: 5| Step: 4
Training loss: 1.8372089862823486
Validation loss: 2.010336920619011

Epoch: 5| Step: 5
Training loss: 1.5778700113296509
Validation loss: 1.9961492170890172

Epoch: 5| Step: 6
Training loss: 0.9303303956985474
Validation loss: 2.0138803869485855

Epoch: 5| Step: 7
Training loss: 1.324249029159546
Validation loss: 2.0219351053237915

Epoch: 5| Step: 8
Training loss: 1.3919250965118408
Validation loss: 2.011966347694397

Epoch: 5| Step: 9
Training loss: 1.7309280633926392
Validation loss: 2.033079981803894

Epoch: 5| Step: 10
Training loss: 1.9141004085540771
Validation loss: 2.0587924967209497

Epoch: 5| Step: 11
Training loss: 0.7290664911270142
Validation loss: 2.043897052605947

Epoch: 82| Step: 0
Training loss: 1.4982285499572754
Validation loss: 2.0513133158286414

Epoch: 5| Step: 1
Training loss: 1.5149791240692139
Validation loss: 2.0345650961001716

Epoch: 5| Step: 2
Training loss: 1.4681353569030762
Validation loss: 2.047253613670667

Epoch: 5| Step: 3
Training loss: 1.4967825412750244
Validation loss: 2.0448623349269233

Epoch: 5| Step: 4
Training loss: 1.746401071548462
Validation loss: 2.0266640285650888

Epoch: 5| Step: 5
Training loss: 1.4386184215545654
Validation loss: 2.016167705257734

Epoch: 5| Step: 6
Training loss: 1.2160539627075195
Validation loss: 2.031893879175186

Epoch: 5| Step: 7
Training loss: 1.476499080657959
Validation loss: 2.0207765897115073

Epoch: 5| Step: 8
Training loss: 1.110764741897583
Validation loss: 2.0527059386173883

Epoch: 5| Step: 9
Training loss: 1.8406492471694946
Validation loss: 2.0332043170928955

Epoch: 5| Step: 10
Training loss: 1.9052860736846924
Validation loss: 2.015952224532763

Epoch: 5| Step: 11
Training loss: 1.7666293382644653
Validation loss: 2.044708455602328

Epoch: 83| Step: 0
Training loss: 1.7016894817352295
Validation loss: 2.032446260253588

Epoch: 5| Step: 1
Training loss: 2.026872158050537
Validation loss: 2.019893988966942

Epoch: 5| Step: 2
Training loss: 1.4240992069244385
Validation loss: 2.011456082264582

Epoch: 5| Step: 3
Training loss: 1.4466849565505981
Validation loss: 2.0051115304231644

Epoch: 5| Step: 4
Training loss: 1.4864709377288818
Validation loss: 2.0316127240657806

Epoch: 5| Step: 5
Training loss: 1.4700983762741089
Validation loss: 1.9780561476945877

Epoch: 5| Step: 6
Training loss: 0.9391323924064636
Validation loss: 2.03872150182724

Epoch: 5| Step: 7
Training loss: 1.2248557806015015
Validation loss: 2.051123852531115

Epoch: 5| Step: 8
Training loss: 1.2624244689941406
Validation loss: 2.0261314809322357

Epoch: 5| Step: 9
Training loss: 1.617729902267456
Validation loss: 2.0562896033128104

Epoch: 5| Step: 10
Training loss: 1.9461662769317627
Validation loss: 2.0312277724345527

Epoch: 5| Step: 11
Training loss: 2.084256649017334
Validation loss: 2.052100350459417

Epoch: 84| Step: 0
Training loss: 1.6052758693695068
Validation loss: 2.0676678270101547

Epoch: 5| Step: 1
Training loss: 2.2629284858703613
Validation loss: 2.0740423798561096

Epoch: 5| Step: 2
Training loss: 1.565513253211975
Validation loss: 2.075877770781517

Epoch: 5| Step: 3
Training loss: 1.4181064367294312
Validation loss: 2.060785482327143

Epoch: 5| Step: 4
Training loss: 1.187767744064331
Validation loss: 2.0467161734898887

Epoch: 5| Step: 5
Training loss: 1.1319961547851562
Validation loss: 2.0335380733013153

Epoch: 5| Step: 6
Training loss: 1.4001686573028564
Validation loss: 2.034423520167669

Epoch: 5| Step: 7
Training loss: 1.9298019409179688
Validation loss: 2.027262424429258

Epoch: 5| Step: 8
Training loss: 1.7346893548965454
Validation loss: 1.9957938989003499

Epoch: 5| Step: 9
Training loss: 1.2994266748428345
Validation loss: 2.029977480570475

Epoch: 5| Step: 10
Training loss: 1.2285703420639038
Validation loss: 2.0453855246305466

Epoch: 5| Step: 11
Training loss: 1.9339207410812378
Validation loss: 1.9968689680099487

Epoch: 85| Step: 0
Training loss: 1.4472129344940186
Validation loss: 2.0392840256293616

Epoch: 5| Step: 1
Training loss: 1.1634039878845215
Validation loss: 2.0523148079713187

Epoch: 5| Step: 2
Training loss: 1.646894097328186
Validation loss: 2.018411303559939

Epoch: 5| Step: 3
Training loss: 2.0175061225891113
Validation loss: 2.046232670545578

Epoch: 5| Step: 4
Training loss: 1.9841258525848389
Validation loss: 2.0382755994796753

Epoch: 5| Step: 5
Training loss: 1.5570471286773682
Validation loss: 2.0735693126916885

Epoch: 5| Step: 6
Training loss: 1.5677692890167236
Validation loss: 2.0446066906054816

Epoch: 5| Step: 7
Training loss: 0.9463885426521301
Validation loss: 2.0416108866532645

Epoch: 5| Step: 8
Training loss: 1.1803863048553467
Validation loss: 2.046029662092527

Epoch: 5| Step: 9
Training loss: 1.5768953561782837
Validation loss: 2.0358803818623223

Epoch: 5| Step: 10
Training loss: 1.6462154388427734
Validation loss: 2.0194162329037986

Epoch: 5| Step: 11
Training loss: 1.919755458831787
Validation loss: 2.038792078693708

Epoch: 86| Step: 0
Training loss: 1.5523865222930908
Validation loss: 2.0377381394306817

Epoch: 5| Step: 1
Training loss: 1.4740989208221436
Validation loss: 2.0515935669342675

Epoch: 5| Step: 2
Training loss: 1.6384103298187256
Validation loss: 2.0348424216111503

Epoch: 5| Step: 3
Training loss: 1.4526034593582153
Validation loss: 2.041230166951815

Epoch: 5| Step: 4
Training loss: 0.9952009320259094
Validation loss: 2.0436205565929413

Epoch: 5| Step: 5
Training loss: 1.6180098056793213
Validation loss: 2.0862379322449365

Epoch: 5| Step: 6
Training loss: 1.3162938356399536
Validation loss: 2.0729518781105676

Epoch: 5| Step: 7
Training loss: 1.691493272781372
Validation loss: 2.03514056901137

Epoch: 5| Step: 8
Training loss: 1.4564824104309082
Validation loss: 2.061223973830541

Epoch: 5| Step: 9
Training loss: 2.227053165435791
Validation loss: 2.018770933151245

Epoch: 5| Step: 10
Training loss: 1.5354665517807007
Validation loss: 2.02166415254275

Epoch: 5| Step: 11
Training loss: 1.1154533624649048
Validation loss: 2.041120861967405

Epoch: 87| Step: 0
Training loss: 1.6068668365478516
Validation loss: 2.020632932583491

Epoch: 5| Step: 1
Training loss: 1.5866823196411133
Validation loss: 2.0140670786301293

Epoch: 5| Step: 2
Training loss: 1.786393404006958
Validation loss: 2.00019163886706

Epoch: 5| Step: 3
Training loss: 1.3627194166183472
Validation loss: 2.0236356457074485

Epoch: 5| Step: 4
Training loss: 1.6643168926239014
Validation loss: 2.031861568490664

Epoch: 5| Step: 5
Training loss: 1.3984076976776123
Validation loss: 2.0065727780262628

Epoch: 5| Step: 6
Training loss: 1.1921722888946533
Validation loss: 2.051467423637708

Epoch: 5| Step: 7
Training loss: 1.5084340572357178
Validation loss: 2.041166146596273

Epoch: 5| Step: 8
Training loss: 1.1387805938720703
Validation loss: 2.033332794904709

Epoch: 5| Step: 9
Training loss: 1.7338908910751343
Validation loss: 2.023106331626574

Epoch: 5| Step: 10
Training loss: 1.4440078735351562
Validation loss: 2.014262522260348

Epoch: 5| Step: 11
Training loss: 2.974456787109375
Validation loss: 2.0538985282182693

Epoch: 88| Step: 0
Training loss: 1.3342097997665405
Validation loss: 2.021761015057564

Epoch: 5| Step: 1
Training loss: 1.6480998992919922
Validation loss: 2.0335001597801843

Epoch: 5| Step: 2
Training loss: 1.5847638845443726
Validation loss: 2.0283017257849374

Epoch: 5| Step: 3
Training loss: 1.6933069229125977
Validation loss: 2.0194825877745948

Epoch: 5| Step: 4
Training loss: 1.813743233680725
Validation loss: 2.004239564140638

Epoch: 5| Step: 5
Training loss: 1.7401918172836304
Validation loss: 2.024702032407125

Epoch: 5| Step: 6
Training loss: 1.5162146091461182
Validation loss: 2.0251051833232245

Epoch: 5| Step: 7
Training loss: 1.3018220663070679
Validation loss: 2.034315903981527

Epoch: 5| Step: 8
Training loss: 1.737823247909546
Validation loss: 2.0502790808677673

Epoch: 5| Step: 9
Training loss: 1.1978726387023926
Validation loss: 1.998062441746394

Epoch: 5| Step: 10
Training loss: 1.1837854385375977
Validation loss: 1.998939871788025

Epoch: 5| Step: 11
Training loss: 0.27547687292099
Validation loss: 2.0215268234411874

Epoch: 89| Step: 0
Training loss: 1.6510610580444336
Validation loss: 2.0266203532616296

Epoch: 5| Step: 1
Training loss: 1.6824653148651123
Validation loss: 2.067774544159571

Epoch: 5| Step: 2
Training loss: 1.6244407892227173
Validation loss: 2.0504027952750525

Epoch: 5| Step: 3
Training loss: 1.6922378540039062
Validation loss: 2.026067778468132

Epoch: 5| Step: 4
Training loss: 1.2705967426300049
Validation loss: 2.0449726780255637

Epoch: 5| Step: 5
Training loss: 1.4217159748077393
Validation loss: 2.041300485531489

Epoch: 5| Step: 6
Training loss: 1.2236573696136475
Validation loss: 2.060030147433281

Epoch: 5| Step: 7
Training loss: 1.1295926570892334
Validation loss: 2.080654333035151

Epoch: 5| Step: 8
Training loss: 0.8427757024765015
Validation loss: 2.0614642153183618

Epoch: 5| Step: 9
Training loss: 1.6136471033096313
Validation loss: 2.035731886823972

Epoch: 5| Step: 10
Training loss: 2.1621201038360596
Validation loss: 2.048170750339826

Epoch: 5| Step: 11
Training loss: 0.7783658504486084
Validation loss: 2.023069108525912

Epoch: 90| Step: 0
Training loss: 1.3463199138641357
Validation loss: 2.034155026078224

Epoch: 5| Step: 1
Training loss: 1.2115986347198486
Validation loss: 2.0399149507284164

Epoch: 5| Step: 2
Training loss: 1.5049681663513184
Validation loss: 2.044855217138926

Epoch: 5| Step: 3
Training loss: 1.35346519947052
Validation loss: 2.0231778770685196

Epoch: 5| Step: 4
Training loss: 1.715752363204956
Validation loss: 2.023466616868973

Epoch: 5| Step: 5
Training loss: 1.613135576248169
Validation loss: 1.987344538172086

Epoch: 5| Step: 6
Training loss: 1.5278253555297852
Validation loss: 2.012890418370565

Epoch: 5| Step: 7
Training loss: 1.631361722946167
Validation loss: 2.062696342666944

Epoch: 5| Step: 8
Training loss: 1.8992950916290283
Validation loss: 2.094944660862287

Epoch: 5| Step: 9
Training loss: 1.0927925109863281
Validation loss: 2.089552174011866

Epoch: 5| Step: 10
Training loss: 1.5471998453140259
Validation loss: 2.052259549498558

Epoch: 5| Step: 11
Training loss: 0.47993171215057373
Validation loss: 2.046395560105642

Epoch: 91| Step: 0
Training loss: 1.3207406997680664
Validation loss: 2.0523302108049393

Epoch: 5| Step: 1
Training loss: 1.7645714282989502
Validation loss: 2.021993567546209

Epoch: 5| Step: 2
Training loss: 1.561112642288208
Validation loss: 2.04502309858799

Epoch: 5| Step: 3
Training loss: 1.4599562883377075
Validation loss: 2.0591342647870383

Epoch: 5| Step: 4
Training loss: 1.321498155593872
Validation loss: 2.0738819936911264

Epoch: 5| Step: 5
Training loss: 1.2836329936981201
Validation loss: 2.014534185330073

Epoch: 5| Step: 6
Training loss: 1.4833492040634155
Validation loss: 2.059612621863683

Epoch: 5| Step: 7
Training loss: 2.0810256004333496
Validation loss: 2.0615426003932953

Epoch: 5| Step: 8
Training loss: 1.0564649105072021
Validation loss: 2.0602738757928214

Epoch: 5| Step: 9
Training loss: 1.3244355916976929
Validation loss: 2.0774318923552832

Epoch: 5| Step: 10
Training loss: 1.2614392042160034
Validation loss: 2.0489474336306253

Epoch: 5| Step: 11
Training loss: 1.7623472213745117
Validation loss: 2.027103195587794

Epoch: 92| Step: 0
Training loss: 0.9837982058525085
Validation loss: 2.002046381433805

Epoch: 5| Step: 1
Training loss: 1.2183765172958374
Validation loss: 2.0291010985771814

Epoch: 5| Step: 2
Training loss: 2.124131202697754
Validation loss: 2.0645398596922555

Epoch: 5| Step: 3
Training loss: 1.3616020679473877
Validation loss: 2.058096170425415

Epoch: 5| Step: 4
Training loss: 1.3440179824829102
Validation loss: 2.0563094516595206

Epoch: 5| Step: 5
Training loss: 1.5435469150543213
Validation loss: 2.051222155491511

Epoch: 5| Step: 6
Training loss: 2.2520945072174072
Validation loss: 2.0408736368020377

Epoch: 5| Step: 7
Training loss: 1.6049140691757202
Validation loss: 2.025183692574501

Epoch: 5| Step: 8
Training loss: 1.1434967517852783
Validation loss: 2.0824480056762695

Epoch: 5| Step: 9
Training loss: 0.7562142610549927
Validation loss: 2.0276686251163483

Epoch: 5| Step: 10
Training loss: 1.5147795677185059
Validation loss: 2.0488663762807846

Epoch: 5| Step: 11
Training loss: 1.630321979522705
Validation loss: 2.006756862004598

Epoch: 93| Step: 0
Training loss: 0.9610059857368469
Validation loss: 2.023358245690664

Epoch: 5| Step: 1
Training loss: 1.3775402307510376
Validation loss: 2.038050522406896

Epoch: 5| Step: 2
Training loss: 1.0179355144500732
Validation loss: 2.0196350614229837

Epoch: 5| Step: 3
Training loss: 1.5540900230407715
Validation loss: 2.032815863688787

Epoch: 5| Step: 4
Training loss: 1.930173635482788
Validation loss: 2.033501148223877

Epoch: 5| Step: 5
Training loss: 1.7590057849884033
Validation loss: 2.0222294280926385

Epoch: 5| Step: 6
Training loss: 1.106711745262146
Validation loss: 2.0025450189908347

Epoch: 5| Step: 7
Training loss: 1.4179993867874146
Validation loss: 2.0151526828606925

Epoch: 5| Step: 8
Training loss: 1.291896104812622
Validation loss: 2.000205159187317

Epoch: 5| Step: 9
Training loss: 1.4175552129745483
Validation loss: 2.006457731127739

Epoch: 5| Step: 10
Training loss: 1.9395596981048584
Validation loss: 2.066839431722959

Epoch: 5| Step: 11
Training loss: 1.8549176454544067
Validation loss: 1.9997577518224716

Epoch: 94| Step: 0
Training loss: 1.7458775043487549
Validation loss: 2.03955485423406

Epoch: 5| Step: 1
Training loss: 1.2560374736785889
Validation loss: 2.0751552830139794

Epoch: 5| Step: 2
Training loss: 1.1406936645507812
Validation loss: 2.0623714278141656

Epoch: 5| Step: 3
Training loss: 1.3640390634536743
Validation loss: 2.064544012149175

Epoch: 5| Step: 4
Training loss: 1.511627435684204
Validation loss: 2.0348429679870605

Epoch: 5| Step: 5
Training loss: 1.2309434413909912
Validation loss: 2.03959130247434

Epoch: 5| Step: 6
Training loss: 1.2843557596206665
Validation loss: 2.0248845467964807

Epoch: 5| Step: 7
Training loss: 1.8208014965057373
Validation loss: 2.0557971944411597

Epoch: 5| Step: 8
Training loss: 1.4242702722549438
Validation loss: 2.0200648307800293

Epoch: 5| Step: 9
Training loss: 1.3733619451522827
Validation loss: 2.018482521176338

Epoch: 5| Step: 10
Training loss: 1.360968828201294
Validation loss: 2.0422800928354263

Epoch: 5| Step: 11
Training loss: 2.447126626968384
Validation loss: 2.0690987755854926

Epoch: 95| Step: 0
Training loss: 1.442569613456726
Validation loss: 2.0418617924054465

Epoch: 5| Step: 1
Training loss: 1.4998998641967773
Validation loss: 2.0571228365103402

Epoch: 5| Step: 2
Training loss: 1.237824559211731
Validation loss: 2.055057962735494

Epoch: 5| Step: 3
Training loss: 1.2070753574371338
Validation loss: 1.999909594655037

Epoch: 5| Step: 4
Training loss: 2.051723003387451
Validation loss: 2.0404139359792075

Epoch: 5| Step: 5
Training loss: 1.7913854122161865
Validation loss: 2.031715532143911

Epoch: 5| Step: 6
Training loss: 1.6549551486968994
Validation loss: 2.0683239698410034

Epoch: 5| Step: 7
Training loss: 0.8673429489135742
Validation loss: 2.0978344281514487

Epoch: 5| Step: 8
Training loss: 1.3356847763061523
Validation loss: 2.03524582584699

Epoch: 5| Step: 9
Training loss: 1.2555325031280518
Validation loss: 2.0274021873871484

Epoch: 5| Step: 10
Training loss: 1.3948330879211426
Validation loss: 2.0284175326426825

Epoch: 5| Step: 11
Training loss: 1.7857179641723633
Validation loss: 2.018585448463758

Epoch: 96| Step: 0
Training loss: 2.0128960609436035
Validation loss: 2.032843073209127

Epoch: 5| Step: 1
Training loss: 1.6017181873321533
Validation loss: 2.019171878695488

Epoch: 5| Step: 2
Training loss: 1.0304160118103027
Validation loss: 2.0248397986094155

Epoch: 5| Step: 3
Training loss: 1.9794957637786865
Validation loss: 2.0427447458108268

Epoch: 5| Step: 4
Training loss: 0.9062140583992004
Validation loss: 2.018083249529203

Epoch: 5| Step: 5
Training loss: 0.9190031886100769
Validation loss: 2.015303095181783

Epoch: 5| Step: 6
Training loss: 1.8748544454574585
Validation loss: 2.020017941792806

Epoch: 5| Step: 7
Training loss: 0.9506098031997681
Validation loss: 2.035331885019938

Epoch: 5| Step: 8
Training loss: 1.6509130001068115
Validation loss: 2.062547519803047

Epoch: 5| Step: 9
Training loss: 1.3139983415603638
Validation loss: 2.072735607624054

Epoch: 5| Step: 10
Training loss: 1.500215768814087
Validation loss: 2.0630852729082108

Epoch: 5| Step: 11
Training loss: 0.7249783277511597
Validation loss: 2.0770365049441657

Epoch: 97| Step: 0
Training loss: 1.1993544101715088
Validation loss: 2.0756226778030396

Epoch: 5| Step: 1
Training loss: 2.135998249053955
Validation loss: 2.0602867205937705

Epoch: 5| Step: 2
Training loss: 1.2846122980117798
Validation loss: 2.008303244908651

Epoch: 5| Step: 3
Training loss: 0.9631742238998413
Validation loss: 1.9996949632962544

Epoch: 5| Step: 4
Training loss: 1.2575396299362183
Validation loss: 2.067179704705874

Epoch: 5| Step: 5
Training loss: 1.3159270286560059
Validation loss: 2.0500816057125726

Epoch: 5| Step: 6
Training loss: 1.5594894886016846
Validation loss: 2.032994786898295

Epoch: 5| Step: 7
Training loss: 1.1914865970611572
Validation loss: 2.0683170606692634

Epoch: 5| Step: 8
Training loss: 1.1778591871261597
Validation loss: 2.0592941840489707

Epoch: 5| Step: 9
Training loss: 1.4316537380218506
Validation loss: 1.9984177102645238

Epoch: 5| Step: 10
Training loss: 1.6595760583877563
Validation loss: 2.0286665807167688

Epoch: 5| Step: 11
Training loss: 1.386926531791687
Validation loss: 2.0253839641809464

Epoch: 98| Step: 0
Training loss: 1.691396951675415
Validation loss: 2.0339169253905616

Epoch: 5| Step: 1
Training loss: 1.4886560440063477
Validation loss: 2.028584361076355

Epoch: 5| Step: 2
Training loss: 1.32163667678833
Validation loss: 2.04810639222463

Epoch: 5| Step: 3
Training loss: 1.1014238595962524
Validation loss: 2.0096949636936188

Epoch: 5| Step: 4
Training loss: 1.5164941549301147
Validation loss: 2.098282054066658

Epoch: 5| Step: 5
Training loss: 1.1014329195022583
Validation loss: 2.0370632112026215

Epoch: 5| Step: 6
Training loss: 0.9385984539985657
Validation loss: 1.9970894952615101

Epoch: 5| Step: 7
Training loss: 1.3131344318389893
Validation loss: 2.0460403809944787

Epoch: 5| Step: 8
Training loss: 1.632440209388733
Validation loss: 2.0418611814578376

Epoch: 5| Step: 9
Training loss: 1.6366055011749268
Validation loss: 2.021725138028463

Epoch: 5| Step: 10
Training loss: 1.3779609203338623
Validation loss: 1.9998426884412766

Epoch: 5| Step: 11
Training loss: 0.5815820693969727
Validation loss: 2.0170664489269257

Epoch: 99| Step: 0
Training loss: 1.358427882194519
Validation loss: 2.0525087217489877

Epoch: 5| Step: 1
Training loss: 1.1479212045669556
Validation loss: 2.0197596152623496

Epoch: 5| Step: 2
Training loss: 1.7821547985076904
Validation loss: 2.057263066371282

Epoch: 5| Step: 3
Training loss: 0.9598771929740906
Validation loss: 2.0551480750242868

Epoch: 5| Step: 4
Training loss: 0.7472150921821594
Validation loss: 2.0301174322764077

Epoch: 5| Step: 5
Training loss: 1.29123854637146
Validation loss: 2.0206080824136734

Epoch: 5| Step: 6
Training loss: 1.6884711980819702
Validation loss: 2.0578768650690713

Epoch: 5| Step: 7
Training loss: 1.3215065002441406
Validation loss: 2.038467844327291

Epoch: 5| Step: 8
Training loss: 1.2909505367279053
Validation loss: 2.0739631901184716

Epoch: 5| Step: 9
Training loss: 1.355065107345581
Validation loss: 2.0504385183254876

Epoch: 5| Step: 10
Training loss: 1.645973801612854
Validation loss: 2.0821811159451804

Epoch: 5| Step: 11
Training loss: 2.067683219909668
Validation loss: 2.084350431958834

Epoch: 100| Step: 0
Training loss: 1.7674983739852905
Validation loss: 2.031668096780777

Epoch: 5| Step: 1
Training loss: 1.5360113382339478
Validation loss: 2.0345103442668915

Epoch: 5| Step: 2
Training loss: 1.4417845010757446
Validation loss: 2.0285140375296273

Epoch: 5| Step: 3
Training loss: 1.0986570119857788
Validation loss: 2.0420131584008536

Epoch: 5| Step: 4
Training loss: 1.1860744953155518
Validation loss: 2.0374434292316437

Epoch: 5| Step: 5
Training loss: 1.409921407699585
Validation loss: 2.0463787813981376

Epoch: 5| Step: 6
Training loss: 1.1745109558105469
Validation loss: 2.0464563419421515

Epoch: 5| Step: 7
Training loss: 1.2033119201660156
Validation loss: 2.069395119945208

Epoch: 5| Step: 8
Training loss: 1.2970865964889526
Validation loss: 2.057945097486178

Epoch: 5| Step: 9
Training loss: 1.234739065170288
Validation loss: 2.0685236752033234

Epoch: 5| Step: 10
Training loss: 1.7193787097930908
Validation loss: 2.0589258472124734

Epoch: 5| Step: 11
Training loss: 1.4899687767028809
Validation loss: 2.104019363721212

Epoch: 101| Step: 0
Training loss: 1.5776346921920776
Validation loss: 2.063520754377047

Epoch: 5| Step: 1
Training loss: 1.5569640398025513
Validation loss: 2.051318218310674

Epoch: 5| Step: 2
Training loss: 1.048994779586792
Validation loss: 2.010497142871221

Epoch: 5| Step: 3
Training loss: 1.5572227239608765
Validation loss: 2.07432555158933

Epoch: 5| Step: 4
Training loss: 1.7391464710235596
Validation loss: 2.0464423994223275

Epoch: 5| Step: 5
Training loss: 1.337398886680603
Validation loss: 2.0370363295078278

Epoch: 5| Step: 6
Training loss: 1.7135460376739502
Validation loss: 2.064959391951561

Epoch: 5| Step: 7
Training loss: 1.0728824138641357
Validation loss: 2.02685584127903

Epoch: 5| Step: 8
Training loss: 1.205965280532837
Validation loss: 2.048237000902494

Epoch: 5| Step: 9
Training loss: 0.9289739727973938
Validation loss: 2.0478617747624717

Epoch: 5| Step: 10
Training loss: 1.3018078804016113
Validation loss: 2.03702075779438

Epoch: 5| Step: 11
Training loss: 2.0714902877807617
Validation loss: 2.0585912466049194

Epoch: 102| Step: 0
Training loss: 1.9738476276397705
Validation loss: 2.0618935376405716

Epoch: 5| Step: 1
Training loss: 1.5892460346221924
Validation loss: 2.0341355154911676

Epoch: 5| Step: 2
Training loss: 1.5300754308700562
Validation loss: 2.0324353178342185

Epoch: 5| Step: 3
Training loss: 1.205212116241455
Validation loss: 2.0366316785415015

Epoch: 5| Step: 4
Training loss: 1.7667968273162842
Validation loss: 2.0694040805101395

Epoch: 5| Step: 5
Training loss: 0.8054665327072144
Validation loss: 2.032324736316999

Epoch: 5| Step: 6
Training loss: 1.2453359365463257
Validation loss: 2.051769112547239

Epoch: 5| Step: 7
Training loss: 1.2322261333465576
Validation loss: 2.0436059087514877

Epoch: 5| Step: 8
Training loss: 1.1879408359527588
Validation loss: 1.9865360061327617

Epoch: 5| Step: 9
Training loss: 1.2059998512268066
Validation loss: 2.0223421951135

Epoch: 5| Step: 10
Training loss: 0.888370156288147
Validation loss: 2.0454508711894355

Epoch: 5| Step: 11
Training loss: 1.6824917793273926
Validation loss: 2.0237217247486115

Epoch: 103| Step: 0
Training loss: 1.5850543975830078
Validation loss: 2.042142932613691

Epoch: 5| Step: 1
Training loss: 1.6406619548797607
Validation loss: 2.0250961234172187

Epoch: 5| Step: 2
Training loss: 0.9858482480049133
Validation loss: 2.045254240433375

Epoch: 5| Step: 3
Training loss: 1.0671360492706299
Validation loss: 2.069144835074743

Epoch: 5| Step: 4
Training loss: 0.696591854095459
Validation loss: 2.0400119920571647

Epoch: 5| Step: 5
Training loss: 1.8064930438995361
Validation loss: 1.999119331439336

Epoch: 5| Step: 6
Training loss: 1.3910356760025024
Validation loss: 2.032157530387243

Epoch: 5| Step: 7
Training loss: 1.3642126321792603
Validation loss: 2.0507306456565857

Epoch: 5| Step: 8
Training loss: 1.1687568426132202
Validation loss: 2.059915234645208

Epoch: 5| Step: 9
Training loss: 1.4675270318984985
Validation loss: 2.045241172115008

Epoch: 5| Step: 10
Training loss: 1.109155297279358
Validation loss: 2.066880310575167

Epoch: 5| Step: 11
Training loss: 2.204873561859131
Validation loss: 2.0621671080589294

Epoch: 104| Step: 0
Training loss: 1.5133006572723389
Validation loss: 2.041754275560379

Epoch: 5| Step: 1
Training loss: 1.689657211303711
Validation loss: 2.0929052978754044

Epoch: 5| Step: 2
Training loss: 1.2791465520858765
Validation loss: 2.0195402006308236

Epoch: 5| Step: 3
Training loss: 1.0341932773590088
Validation loss: 2.0870184948047004

Epoch: 5| Step: 4
Training loss: 1.4000427722930908
Validation loss: 2.068952053785324

Epoch: 5| Step: 5
Training loss: 0.7747201323509216
Validation loss: 2.053515687584877

Epoch: 5| Step: 6
Training loss: 1.4649715423583984
Validation loss: 2.0329514741897583

Epoch: 5| Step: 7
Training loss: 1.2958390712738037
Validation loss: 2.021861602862676

Epoch: 5| Step: 8
Training loss: 1.3275854587554932
Validation loss: 2.076303099592527

Epoch: 5| Step: 9
Training loss: 0.9262642860412598
Validation loss: 2.040716032187144

Epoch: 5| Step: 10
Training loss: 1.812302827835083
Validation loss: 2.049012621243795

Epoch: 5| Step: 11
Training loss: 1.7451740503311157
Validation loss: 2.049784625569979

Epoch: 105| Step: 0
Training loss: 1.3067632913589478
Validation loss: 2.058071345090866

Epoch: 5| Step: 1
Training loss: 1.147502064704895
Validation loss: 2.070060044527054

Epoch: 5| Step: 2
Training loss: 1.1384973526000977
Validation loss: 2.0190010915199914

Epoch: 5| Step: 3
Training loss: 1.5352509021759033
Validation loss: 2.041231075922648

Epoch: 5| Step: 4
Training loss: 1.6672232151031494
Validation loss: 2.0356795489788055

Epoch: 5| Step: 5
Training loss: 1.0944429636001587
Validation loss: 2.079217334588369

Epoch: 5| Step: 6
Training loss: 1.4848177433013916
Validation loss: 2.036148339509964

Epoch: 5| Step: 7
Training loss: 1.2066789865493774
Validation loss: 2.0439024368921914

Epoch: 5| Step: 8
Training loss: 1.4317866563796997
Validation loss: 2.0291551500558853

Epoch: 5| Step: 9
Training loss: 0.8712038993835449
Validation loss: 1.9894104599952698

Epoch: 5| Step: 10
Training loss: 1.3180873394012451
Validation loss: 2.012866591413816

Epoch: 5| Step: 11
Training loss: 1.893117904663086
Validation loss: 2.0376962373654046

Epoch: 106| Step: 0
Training loss: 1.3455311059951782
Validation loss: 2.038864344358444

Epoch: 5| Step: 1
Training loss: 1.7177168130874634
Validation loss: 2.072652498881022

Epoch: 5| Step: 2
Training loss: 0.945604145526886
Validation loss: 2.0405292560656867

Epoch: 5| Step: 3
Training loss: 1.1633936166763306
Validation loss: 2.028605282306671

Epoch: 5| Step: 4
Training loss: 1.1728311777114868
Validation loss: 2.026549677054087

Epoch: 5| Step: 5
Training loss: 1.46392023563385
Validation loss: 2.0078999747832618

Epoch: 5| Step: 6
Training loss: 1.1245230436325073
Validation loss: 2.0227350294589996

Epoch: 5| Step: 7
Training loss: 0.9641791582107544
Validation loss: 2.0521632730960846

Epoch: 5| Step: 8
Training loss: 0.9476903080940247
Validation loss: 2.044271851579348

Epoch: 5| Step: 9
Training loss: 1.445289969444275
Validation loss: 2.028010979294777

Epoch: 5| Step: 10
Training loss: 1.7552951574325562
Validation loss: 2.030942127108574

Epoch: 5| Step: 11
Training loss: 1.4773801565170288
Validation loss: 2.0164109816153846

Epoch: 107| Step: 0
Training loss: 1.7412227392196655
Validation loss: 2.042160009344419

Epoch: 5| Step: 1
Training loss: 1.0855541229248047
Validation loss: 2.0580988377332687

Epoch: 5| Step: 2
Training loss: 1.2256757020950317
Validation loss: 2.0124965657790503

Epoch: 5| Step: 3
Training loss: 1.3460397720336914
Validation loss: 2.041239713629087

Epoch: 5| Step: 4
Training loss: 1.3192908763885498
Validation loss: 2.030112544695536

Epoch: 5| Step: 5
Training loss: 1.6581127643585205
Validation loss: 2.0519054929415383

Epoch: 5| Step: 6
Training loss: 0.9611433148384094
Validation loss: 2.040206382671992

Epoch: 5| Step: 7
Training loss: 0.9544331431388855
Validation loss: 2.0937361965576806

Epoch: 5| Step: 8
Training loss: 1.196761965751648
Validation loss: 2.0365127325057983

Epoch: 5| Step: 9
Training loss: 1.2591140270233154
Validation loss: 2.0642740428447723

Epoch: 5| Step: 10
Training loss: 1.304291009902954
Validation loss: 2.025715415676435

Epoch: 5| Step: 11
Training loss: 0.6517970561981201
Validation loss: 2.0615696758031845

Epoch: 108| Step: 0
Training loss: 1.2910844087600708
Validation loss: 2.0620150168736777

Epoch: 5| Step: 1
Training loss: 0.9398417472839355
Validation loss: 2.0364710489908853

Epoch: 5| Step: 2
Training loss: 2.203153610229492
Validation loss: 2.046031872431437

Epoch: 5| Step: 3
Training loss: 1.2551109790802002
Validation loss: 2.0799111475547156

Epoch: 5| Step: 4
Training loss: 1.3876402378082275
Validation loss: 2.0820931792259216

Epoch: 5| Step: 5
Training loss: 1.3938075304031372
Validation loss: 2.0949233770370483

Epoch: 5| Step: 6
Training loss: 1.0948916673660278
Validation loss: 2.0360091775655746

Epoch: 5| Step: 7
Training loss: 1.1085844039916992
Validation loss: 1.989415114124616

Epoch: 5| Step: 8
Training loss: 1.4699615240097046
Validation loss: 2.0483274459838867

Epoch: 5| Step: 9
Training loss: 1.0573625564575195
Validation loss: 2.0820122261842093

Epoch: 5| Step: 10
Training loss: 1.0217173099517822
Validation loss: 2.016882225871086

Epoch: 5| Step: 11
Training loss: 0.8904223442077637
Validation loss: 2.0637754102547965

Epoch: 109| Step: 0
Training loss: 1.2163094282150269
Validation loss: 2.0234877367814383

Epoch: 5| Step: 1
Training loss: 1.2949374914169312
Validation loss: 2.047664925456047

Epoch: 5| Step: 2
Training loss: 1.0040276050567627
Validation loss: 2.0391917725404105

Epoch: 5| Step: 3
Training loss: 0.8070657849311829
Validation loss: 2.033320903778076

Epoch: 5| Step: 4
Training loss: 1.649237871170044
Validation loss: 2.071352183818817

Epoch: 5| Step: 5
Training loss: 1.503984808921814
Validation loss: 2.053387224674225

Epoch: 5| Step: 6
Training loss: 1.8543306589126587
Validation loss: 2.0613507330417633

Epoch: 5| Step: 7
Training loss: 0.9895907640457153
Validation loss: 2.062452102700869

Epoch: 5| Step: 8
Training loss: 1.0360472202301025
Validation loss: 2.0379463086525598

Epoch: 5| Step: 9
Training loss: 0.9440925717353821
Validation loss: 2.020327722032865

Epoch: 5| Step: 10
Training loss: 1.5038894414901733
Validation loss: 2.0796033491690955

Epoch: 5| Step: 11
Training loss: 1.5863862037658691
Validation loss: 2.069183200597763

Epoch: 110| Step: 0
Training loss: 1.3322932720184326
Validation loss: 2.035845865805944

Epoch: 5| Step: 1
Training loss: 1.5840469598770142
Validation loss: 2.0196917156378427

Epoch: 5| Step: 2
Training loss: 1.2632758617401123
Validation loss: 2.0172054370244346

Epoch: 5| Step: 3
Training loss: 1.6831529140472412
Validation loss: 2.0477688213189444

Epoch: 5| Step: 4
Training loss: 0.9334174990653992
Validation loss: 2.0482281943162284

Epoch: 5| Step: 5
Training loss: 0.9286390542984009
Validation loss: 2.0627919981877008

Epoch: 5| Step: 6
Training loss: 1.2018808126449585
Validation loss: 2.037372514605522

Epoch: 5| Step: 7
Training loss: 1.5844812393188477
Validation loss: 2.051700527469317

Epoch: 5| Step: 8
Training loss: 1.5699814558029175
Validation loss: 2.036971857150396

Epoch: 5| Step: 9
Training loss: 0.7758700251579285
Validation loss: 2.009392852584521

Epoch: 5| Step: 10
Training loss: 1.0576614141464233
Validation loss: 2.03799798587958

Epoch: 5| Step: 11
Training loss: 1.1152539253234863
Validation loss: 2.0262203166882196

Epoch: 111| Step: 0
Training loss: 1.4963529109954834
Validation loss: 2.0220463623603186

Epoch: 5| Step: 1
Training loss: 1.1104177236557007
Validation loss: 2.0296678841114044

Epoch: 5| Step: 2
Training loss: 1.4819161891937256
Validation loss: 2.0204758693774543

Epoch: 5| Step: 3
Training loss: 1.1716166734695435
Validation loss: 2.0188772728045783

Epoch: 5| Step: 4
Training loss: 1.2093321084976196
Validation loss: 2.0440995742877326

Epoch: 5| Step: 5
Training loss: 1.465982437133789
Validation loss: 2.0326200226942697

Epoch: 5| Step: 6
Training loss: 0.9654638171195984
Validation loss: 2.0481790552536645

Epoch: 5| Step: 7
Training loss: 1.3798778057098389
Validation loss: 2.029571165641149

Epoch: 5| Step: 8
Training loss: 1.0650087594985962
Validation loss: 2.0603364358345666

Epoch: 5| Step: 9
Training loss: 1.1584784984588623
Validation loss: 2.0351005643606186

Epoch: 5| Step: 10
Training loss: 1.1460429430007935
Validation loss: 2.0395580728848777

Epoch: 5| Step: 11
Training loss: 1.6056824922561646
Validation loss: 2.04945108294487

Epoch: 112| Step: 0
Training loss: 1.1639342308044434
Validation loss: 2.0290175726016364

Epoch: 5| Step: 1
Training loss: 1.4986467361450195
Validation loss: 2.0590477536122003

Epoch: 5| Step: 2
Training loss: 1.667565941810608
Validation loss: 2.047716657320658

Epoch: 5| Step: 3
Training loss: 1.479730248451233
Validation loss: 2.027405252059301

Epoch: 5| Step: 4
Training loss: 0.9576044082641602
Validation loss: 2.0744024217128754

Epoch: 5| Step: 5
Training loss: 1.0479609966278076
Validation loss: 2.032321681578954

Epoch: 5| Step: 6
Training loss: 1.3701034784317017
Validation loss: 2.0519394874572754

Epoch: 5| Step: 7
Training loss: 1.0084245204925537
Validation loss: 2.0506992687781653

Epoch: 5| Step: 8
Training loss: 1.0711495876312256
Validation loss: 2.024530147512754

Epoch: 5| Step: 9
Training loss: 1.1824404001235962
Validation loss: 2.077305222551028

Epoch: 5| Step: 10
Training loss: 1.3072631359100342
Validation loss: 2.121697098016739

Epoch: 5| Step: 11
Training loss: 0.5868358612060547
Validation loss: 2.0623863289753595

Epoch: 113| Step: 0
Training loss: 1.0796738862991333
Validation loss: 2.0679808060328164

Epoch: 5| Step: 1
Training loss: 1.1545459032058716
Validation loss: 2.046352763970693

Epoch: 5| Step: 2
Training loss: 0.9752079248428345
Validation loss: 2.033326799670855

Epoch: 5| Step: 3
Training loss: 1.2056856155395508
Validation loss: 2.0449587951103845

Epoch: 5| Step: 4
Training loss: 1.3979781866073608
Validation loss: 2.046056513984998

Epoch: 5| Step: 5
Training loss: 1.7628471851348877
Validation loss: 2.041916330655416

Epoch: 5| Step: 6
Training loss: 1.286203145980835
Validation loss: 2.002277900775274

Epoch: 5| Step: 7
Training loss: 1.065213680267334
Validation loss: 2.061282674471537

Epoch: 5| Step: 8
Training loss: 1.0729963779449463
Validation loss: 2.015785738825798

Epoch: 5| Step: 9
Training loss: 0.928355872631073
Validation loss: 2.024056707819303

Epoch: 5| Step: 10
Training loss: 1.6107507944107056
Validation loss: 2.045868863662084

Epoch: 5| Step: 11
Training loss: 2.1860313415527344
Validation loss: 2.0352129439512887

Epoch: 114| Step: 0
Training loss: 0.9876760244369507
Validation loss: 2.1089513351519904

Epoch: 5| Step: 1
Training loss: 1.7534784078598022
Validation loss: 2.0320636878410974

Epoch: 5| Step: 2
Training loss: 1.8855184316635132
Validation loss: 2.0350580463806787

Epoch: 5| Step: 3
Training loss: 1.1915169954299927
Validation loss: 2.042364796002706

Epoch: 5| Step: 4
Training loss: 1.5565974712371826
Validation loss: 2.0544072836637497

Epoch: 5| Step: 5
Training loss: 1.4956024885177612
Validation loss: 2.000273977716764

Epoch: 5| Step: 6
Training loss: 1.3641806840896606
Validation loss: 2.029435028632482

Epoch: 5| Step: 7
Training loss: 0.9588003158569336
Validation loss: 2.0670685370763144

Epoch: 5| Step: 8
Training loss: 0.9254838824272156
Validation loss: 2.0538881768782935

Epoch: 5| Step: 9
Training loss: 0.9841576814651489
Validation loss: 2.0695722500483194

Epoch: 5| Step: 10
Training loss: 0.7973929643630981
Validation loss: 2.0732566863298416

Epoch: 5| Step: 11
Training loss: 0.3616691827774048
Validation loss: 2.0246433118979135

Epoch: 115| Step: 0
Training loss: 1.1247999668121338
Validation loss: 2.0475584218899407

Epoch: 5| Step: 1
Training loss: 0.8886882066726685
Validation loss: 2.042000005642573

Epoch: 5| Step: 2
Training loss: 1.3752340078353882
Validation loss: 2.061625137925148

Epoch: 5| Step: 3
Training loss: 0.8476044535636902
Validation loss: 2.07275083164374

Epoch: 5| Step: 4
Training loss: 1.0092284679412842
Validation loss: 2.0479912956555686

Epoch: 5| Step: 5
Training loss: 1.4558751583099365
Validation loss: 2.0967293828725815

Epoch: 5| Step: 6
Training loss: 1.3185431957244873
Validation loss: 2.0515248527129493

Epoch: 5| Step: 7
Training loss: 1.8232271671295166
Validation loss: 2.0484619587659836

Epoch: 5| Step: 8
Training loss: 0.9286327362060547
Validation loss: 2.0385634700457254

Epoch: 5| Step: 9
Training loss: 1.6367599964141846
Validation loss: 2.1041996628046036

Epoch: 5| Step: 10
Training loss: 1.0650217533111572
Validation loss: 2.0628052155176797

Epoch: 5| Step: 11
Training loss: 1.4914439916610718
Validation loss: 2.0970510045687356

Epoch: 116| Step: 0
Training loss: 1.1426222324371338
Validation loss: 2.0481357673803964

Epoch: 5| Step: 1
Training loss: 1.4152839183807373
Validation loss: 2.0638935466607413

Epoch: 5| Step: 2
Training loss: 1.2306410074234009
Validation loss: 2.065620849529902

Epoch: 5| Step: 3
Training loss: 1.224623441696167
Validation loss: 2.0455428610245385

Epoch: 5| Step: 4
Training loss: 1.4395328760147095
Validation loss: 2.0719527353843055

Epoch: 5| Step: 5
Training loss: 1.8718535900115967
Validation loss: 2.0612059235572815

Epoch: 5| Step: 6
Training loss: 1.1321866512298584
Validation loss: 2.0364528944094977

Epoch: 5| Step: 7
Training loss: 0.7717020511627197
Validation loss: 2.0798358668883643

Epoch: 5| Step: 8
Training loss: 1.3331760168075562
Validation loss: 2.0056591629981995

Epoch: 5| Step: 9
Training loss: 0.9928910136222839
Validation loss: 1.9822273800770442

Epoch: 5| Step: 10
Training loss: 1.0344213247299194
Validation loss: 2.0255656143029532

Epoch: 5| Step: 11
Training loss: 0.3535574674606323
Validation loss: 2.033966228365898

Epoch: 117| Step: 0
Training loss: 0.7967894673347473
Validation loss: 2.0532668928305307

Epoch: 5| Step: 1
Training loss: 1.1079742908477783
Validation loss: 2.038268799583117

Epoch: 5| Step: 2
Training loss: 1.4062700271606445
Validation loss: 2.0994414538145065

Epoch: 5| Step: 3
Training loss: 1.0378347635269165
Validation loss: 2.0281635224819183

Epoch: 5| Step: 4
Training loss: 1.2922788858413696
Validation loss: 2.0009811321894326

Epoch: 5| Step: 5
Training loss: 1.347830057144165
Validation loss: 2.0407564292351403

Epoch: 5| Step: 6
Training loss: 1.134454369544983
Validation loss: 2.0584247608979545

Epoch: 5| Step: 7
Training loss: 0.9468216896057129
Validation loss: 2.041604389746984

Epoch: 5| Step: 8
Training loss: 1.4573822021484375
Validation loss: 2.0625218053658805

Epoch: 5| Step: 9
Training loss: 1.1853735446929932
Validation loss: 2.0857512752215066

Epoch: 5| Step: 10
Training loss: 1.7461326122283936
Validation loss: 2.0593618800242743

Epoch: 5| Step: 11
Training loss: 2.372746706008911
Validation loss: 2.0358551839987435

Epoch: 118| Step: 0
Training loss: 1.8207876682281494
Validation loss: 2.0343039433161416

Epoch: 5| Step: 1
Training loss: 1.1568470001220703
Validation loss: 2.0381861130396524

Epoch: 5| Step: 2
Training loss: 0.7620944380760193
Validation loss: 2.0318682740132012

Epoch: 5| Step: 3
Training loss: 1.0955904722213745
Validation loss: 2.0800734808047614

Epoch: 5| Step: 4
Training loss: 1.2628644704818726
Validation loss: 2.0540102968613305

Epoch: 5| Step: 5
Training loss: 0.6537551879882812
Validation loss: 2.026166250308355

Epoch: 5| Step: 6
Training loss: 0.9217273592948914
Validation loss: 2.049510876337687

Epoch: 5| Step: 7
Training loss: 1.556633472442627
Validation loss: 2.043334270517031

Epoch: 5| Step: 8
Training loss: 0.985251784324646
Validation loss: 2.0868398447831473

Epoch: 5| Step: 9
Training loss: 1.2489632368087769
Validation loss: 2.081096808115641

Epoch: 5| Step: 10
Training loss: 1.3368726968765259
Validation loss: 2.059198488791784

Epoch: 5| Step: 11
Training loss: 1.1754111051559448
Validation loss: 2.066324681043625

Epoch: 119| Step: 0
Training loss: 0.7766321301460266
Validation loss: 2.058094168702761

Epoch: 5| Step: 1
Training loss: 1.4007869958877563
Validation loss: 2.105197697877884

Epoch: 5| Step: 2
Training loss: 1.0049484968185425
Validation loss: 2.098826472957929

Epoch: 5| Step: 3
Training loss: 1.305666208267212
Validation loss: 2.101286788781484

Epoch: 5| Step: 4
Training loss: 1.4972865581512451
Validation loss: 2.0501897037029266

Epoch: 5| Step: 5
Training loss: 1.161435842514038
Validation loss: 2.0170860638221106

Epoch: 5| Step: 6
Training loss: 1.4245167970657349
Validation loss: 2.0504959523677826

Epoch: 5| Step: 7
Training loss: 1.6353158950805664
Validation loss: 2.035586322347323

Epoch: 5| Step: 8
Training loss: 1.0543991327285767
Validation loss: 2.084675778945287

Epoch: 5| Step: 9
Training loss: 1.3207223415374756
Validation loss: 2.062861531972885

Epoch: 5| Step: 10
Training loss: 0.9717862010002136
Validation loss: 2.0431254456440606

Epoch: 5| Step: 11
Training loss: 0.9489625692367554
Validation loss: 2.0901875346899033

Epoch: 120| Step: 0
Training loss: 1.1737937927246094
Validation loss: 2.09992782274882

Epoch: 5| Step: 1
Training loss: 1.0947240591049194
Validation loss: 2.026497468352318

Epoch: 5| Step: 2
Training loss: 1.4427974224090576
Validation loss: 2.079259733359019

Epoch: 5| Step: 3
Training loss: 1.092975378036499
Validation loss: 2.0382546931505203

Epoch: 5| Step: 4
Training loss: 1.398540735244751
Validation loss: 2.0876037627458572

Epoch: 5| Step: 5
Training loss: 1.1832740306854248
Validation loss: 2.060571094353994

Epoch: 5| Step: 6
Training loss: 0.7763350605964661
Validation loss: 2.076069951057434

Epoch: 5| Step: 7
Training loss: 0.9871423840522766
Validation loss: 2.0301834642887115

Epoch: 5| Step: 8
Training loss: 1.282991647720337
Validation loss: 2.0560993353525796

Epoch: 5| Step: 9
Training loss: 1.2828904390335083
Validation loss: 2.0389845768610635

Epoch: 5| Step: 10
Training loss: 1.0619491338729858
Validation loss: 2.04995167752107

Epoch: 5| Step: 11
Training loss: 1.5264947414398193
Validation loss: 2.059350828329722

Epoch: 121| Step: 0
Training loss: 1.4518225193023682
Validation loss: 2.0435682932535806

Epoch: 5| Step: 1
Training loss: 1.5598678588867188
Validation loss: 2.0393891582886376

Epoch: 5| Step: 2
Training loss: 1.1112165451049805
Validation loss: 2.049770931402842

Epoch: 5| Step: 3
Training loss: 0.8013479113578796
Validation loss: 1.9954407165447872

Epoch: 5| Step: 4
Training loss: 0.7583945989608765
Validation loss: 2.0494399269421897

Epoch: 5| Step: 5
Training loss: 0.8088536262512207
Validation loss: 2.051053062081337

Epoch: 5| Step: 6
Training loss: 1.360264539718628
Validation loss: 2.0472261011600494

Epoch: 5| Step: 7
Training loss: 1.6335241794586182
Validation loss: 2.0655104716618857

Epoch: 5| Step: 8
Training loss: 1.3743822574615479
Validation loss: 2.1039884636799493

Epoch: 5| Step: 9
Training loss: 1.3764969110488892
Validation loss: 2.075453778107961

Epoch: 5| Step: 10
Training loss: 1.0296584367752075
Validation loss: 2.0865456064542136

Epoch: 5| Step: 11
Training loss: 1.400909662246704
Validation loss: 2.0704328417778015

Epoch: 122| Step: 0
Training loss: 1.2410262823104858
Validation loss: 2.03183983763059

Epoch: 5| Step: 1
Training loss: 0.8430530428886414
Validation loss: 2.0487044602632523

Epoch: 5| Step: 2
Training loss: 0.9217236638069153
Validation loss: 2.0076039185126624

Epoch: 5| Step: 3
Training loss: 1.0386908054351807
Validation loss: 2.0439817706743875

Epoch: 5| Step: 4
Training loss: 1.0653188228607178
Validation loss: 2.0128460874160132

Epoch: 5| Step: 5
Training loss: 1.1031615734100342
Validation loss: 2.0509689450263977

Epoch: 5| Step: 6
Training loss: 1.0930801630020142
Validation loss: 2.023458177844683

Epoch: 5| Step: 7
Training loss: 1.44638192653656
Validation loss: 1.9985847026109695

Epoch: 5| Step: 8
Training loss: 1.035292387008667
Validation loss: 2.0535483111937842

Epoch: 5| Step: 9
Training loss: 1.4953521490097046
Validation loss: 2.0680935233831406

Epoch: 5| Step: 10
Training loss: 1.1510010957717896
Validation loss: 2.0307352542877197

Epoch: 5| Step: 11
Training loss: 1.0462653636932373
Validation loss: 2.056547373533249

Epoch: 123| Step: 0
Training loss: 1.1074693202972412
Validation loss: 2.06293153266112

Epoch: 5| Step: 1
Training loss: 0.7597991824150085
Validation loss: 2.09806398053964

Epoch: 5| Step: 2
Training loss: 1.4365582466125488
Validation loss: 2.0305724690357843

Epoch: 5| Step: 3
Training loss: 1.204993486404419
Validation loss: 2.0147183338801065

Epoch: 5| Step: 4
Training loss: 1.2084300518035889
Validation loss: 2.0160332123438516

Epoch: 5| Step: 5
Training loss: 0.8753633499145508
Validation loss: 2.0373540818691254

Epoch: 5| Step: 6
Training loss: 1.1189419031143188
Validation loss: 2.0635375132163367

Epoch: 5| Step: 7
Training loss: 1.2706514596939087
Validation loss: 2.0661071638266244

Epoch: 5| Step: 8
Training loss: 1.131138801574707
Validation loss: 2.065113519628843

Epoch: 5| Step: 9
Training loss: 0.8815265893936157
Validation loss: 2.0691893100738525

Epoch: 5| Step: 10
Training loss: 1.1826874017715454
Validation loss: 2.0586631993452706

Epoch: 5| Step: 11
Training loss: 0.8475078344345093
Validation loss: 2.0417829702297845

Epoch: 124| Step: 0
Training loss: 0.826561450958252
Validation loss: 2.0228976756334305

Epoch: 5| Step: 1
Training loss: 1.423256754875183
Validation loss: 2.0836738497018814

Epoch: 5| Step: 2
Training loss: 0.9551790952682495
Validation loss: 2.059175660212835

Epoch: 5| Step: 3
Training loss: 1.4949376583099365
Validation loss: 2.0828439692656198

Epoch: 5| Step: 4
Training loss: 1.0434824228286743
Validation loss: 2.1091305017471313

Epoch: 5| Step: 5
Training loss: 1.1663522720336914
Validation loss: 2.0529742191235223

Epoch: 5| Step: 6
Training loss: 0.8297330737113953
Validation loss: 2.107583294312159

Epoch: 5| Step: 7
Training loss: 1.0520641803741455
Validation loss: 2.078769172231356

Epoch: 5| Step: 8
Training loss: 1.2136051654815674
Validation loss: 2.09343213836352

Epoch: 5| Step: 9
Training loss: 1.3432538509368896
Validation loss: 2.089557001988093

Epoch: 5| Step: 10
Training loss: 0.9332698583602905
Validation loss: 2.0713000893592834

Epoch: 5| Step: 11
Training loss: 2.4134106636047363
Validation loss: 2.064605250954628

Epoch: 125| Step: 0
Training loss: 1.2503197193145752
Validation loss: 2.0833434611558914

Epoch: 5| Step: 1
Training loss: 1.1670207977294922
Validation loss: 2.0722205440203347

Epoch: 5| Step: 2
Training loss: 1.001778244972229
Validation loss: 2.082744429508845

Epoch: 5| Step: 3
Training loss: 1.358335018157959
Validation loss: 2.0735773344834647

Epoch: 5| Step: 4
Training loss: 1.0412025451660156
Validation loss: 2.0281300048033395

Epoch: 5| Step: 5
Training loss: 1.0334060192108154
Validation loss: 2.0409619510173798

Epoch: 5| Step: 6
Training loss: 1.1165580749511719
Validation loss: 2.048121079802513

Epoch: 5| Step: 7
Training loss: 1.138991355895996
Validation loss: 2.0228998561700187

Epoch: 5| Step: 8
Training loss: 1.0134323835372925
Validation loss: 2.087325389186541

Epoch: 5| Step: 9
Training loss: 1.1388039588928223
Validation loss: 2.065531864762306

Epoch: 5| Step: 10
Training loss: 1.2035845518112183
Validation loss: 2.0481302390495935

Epoch: 5| Step: 11
Training loss: 0.9410547614097595
Validation loss: 2.043615991870562

Epoch: 126| Step: 0
Training loss: 1.055126667022705
Validation loss: 2.0546493430932364

Epoch: 5| Step: 1
Training loss: 1.4613392353057861
Validation loss: 2.072571575641632

Epoch: 5| Step: 2
Training loss: 1.1461374759674072
Validation loss: 2.068786635994911

Epoch: 5| Step: 3
Training loss: 0.8443244099617004
Validation loss: 2.060551459590594

Epoch: 5| Step: 4
Training loss: 1.1330703496932983
Validation loss: 2.0934477845827737

Epoch: 5| Step: 5
Training loss: 0.6339681148529053
Validation loss: 2.0668564438819885

Epoch: 5| Step: 6
Training loss: 0.91844242811203
Validation loss: 2.070943077405294

Epoch: 5| Step: 7
Training loss: 1.1161701679229736
Validation loss: 2.0860962768395743

Epoch: 5| Step: 8
Training loss: 1.7045530080795288
Validation loss: 2.0931143561999

Epoch: 5| Step: 9
Training loss: 1.3061596155166626
Validation loss: 2.062215025226275

Epoch: 5| Step: 10
Training loss: 1.0666475296020508
Validation loss: 2.070397267738978

Epoch: 5| Step: 11
Training loss: 0.676005482673645
Validation loss: 2.067643791437149

Epoch: 127| Step: 0
Training loss: 1.1938074827194214
Validation loss: 2.0779461562633514

Epoch: 5| Step: 1
Training loss: 1.424802541732788
Validation loss: 2.0409826735655465

Epoch: 5| Step: 2
Training loss: 1.618427038192749
Validation loss: 2.0577487548192344

Epoch: 5| Step: 3
Training loss: 1.082647442817688
Validation loss: 2.004196340839068

Epoch: 5| Step: 4
Training loss: 1.0869295597076416
Validation loss: 2.0328319221735

Epoch: 5| Step: 5
Training loss: 0.7344976663589478
Validation loss: 2.0032066702842712

Epoch: 5| Step: 6
Training loss: 1.3460814952850342
Validation loss: 2.0038261115550995

Epoch: 5| Step: 7
Training loss: 1.3455804586410522
Validation loss: 1.991950715581576

Epoch: 5| Step: 8
Training loss: 0.7915297746658325
Validation loss: 2.054832195242246

Epoch: 5| Step: 9
Training loss: 1.1721467971801758
Validation loss: 2.036423201362292

Epoch: 5| Step: 10
Training loss: 0.9926139116287231
Validation loss: 1.999550501505534

Epoch: 5| Step: 11
Training loss: 1.6764293909072876
Validation loss: 2.0388029913107553

Epoch: 128| Step: 0
Training loss: 1.0907827615737915
Validation loss: 2.0253027081489563

Epoch: 5| Step: 1
Training loss: 0.9837859869003296
Validation loss: 2.0094260623057685

Epoch: 5| Step: 2
Training loss: 1.0830330848693848
Validation loss: 2.0256320337454476

Epoch: 5| Step: 3
Training loss: 1.2174800634384155
Validation loss: 2.031303286552429

Epoch: 5| Step: 4
Training loss: 1.0633116960525513
Validation loss: 1.990722045302391

Epoch: 5| Step: 5
Training loss: 1.2010225057601929
Validation loss: 2.0223415195941925

Epoch: 5| Step: 6
Training loss: 1.4328902959823608
Validation loss: 2.017121305068334

Epoch: 5| Step: 7
Training loss: 1.0013267993927002
Validation loss: 2.021963099638621

Epoch: 5| Step: 8
Training loss: 0.9569143056869507
Validation loss: 2.0376870036125183

Epoch: 5| Step: 9
Training loss: 0.8368781208992004
Validation loss: 1.9840284635623295

Epoch: 5| Step: 10
Training loss: 1.0362423658370972
Validation loss: 2.051755224665006

Epoch: 5| Step: 11
Training loss: 1.0599055290222168
Validation loss: 2.032256558537483

Epoch: 129| Step: 0
Training loss: 1.127042531967163
Validation loss: 2.062401453653971

Epoch: 5| Step: 1
Training loss: 1.0616142749786377
Validation loss: 2.040355255206426

Epoch: 5| Step: 2
Training loss: 0.7567497491836548
Validation loss: 2.053658684094747

Epoch: 5| Step: 3
Training loss: 1.161352276802063
Validation loss: 2.025299221277237

Epoch: 5| Step: 4
Training loss: 0.7401360273361206
Validation loss: 2.0560480455557504

Epoch: 5| Step: 5
Training loss: 1.1444408893585205
Validation loss: 2.0518442491690316

Epoch: 5| Step: 6
Training loss: 1.048545479774475
Validation loss: 2.0654318630695343

Epoch: 5| Step: 7
Training loss: 1.1367193460464478
Validation loss: 2.0597939242919288

Epoch: 5| Step: 8
Training loss: 1.1609042882919312
Validation loss: 2.026973972717921

Epoch: 5| Step: 9
Training loss: 1.292944073677063
Validation loss: 2.038144667943319

Epoch: 5| Step: 10
Training loss: 1.1034705638885498
Validation loss: 2.0247917671998343

Epoch: 5| Step: 11
Training loss: 1.4187562465667725
Validation loss: 2.0668105433384576

Epoch: 130| Step: 0
Training loss: 1.024613618850708
Validation loss: 2.0334122627973557

Epoch: 5| Step: 1
Training loss: 1.069340705871582
Validation loss: 2.061997095743815

Epoch: 5| Step: 2
Training loss: 0.7121957540512085
Validation loss: 2.0402492384115853

Epoch: 5| Step: 3
Training loss: 1.2316348552703857
Validation loss: 2.059761345386505

Epoch: 5| Step: 4
Training loss: 0.8943383097648621
Validation loss: 2.0417032837867737

Epoch: 5| Step: 5
Training loss: 0.9666555523872375
Validation loss: 2.036121611793836

Epoch: 5| Step: 6
Training loss: 1.6781189441680908
Validation loss: 2.0498207261164985

Epoch: 5| Step: 7
Training loss: 1.4491093158721924
Validation loss: 2.083374818166097

Epoch: 5| Step: 8
Training loss: 1.0095264911651611
Validation loss: 2.0539649029572806

Epoch: 5| Step: 9
Training loss: 1.0550106763839722
Validation loss: 2.0608657201131186

Epoch: 5| Step: 10
Training loss: 0.692435085773468
Validation loss: 2.0814802100261054

Epoch: 5| Step: 11
Training loss: 1.1083585023880005
Validation loss: 2.0070045540730157

Epoch: 131| Step: 0
Training loss: 0.9032245874404907
Validation loss: 2.0984571476777396

Epoch: 5| Step: 1
Training loss: 1.4421898126602173
Validation loss: 2.109242950876554

Epoch: 5| Step: 2
Training loss: 1.165571928024292
Validation loss: 2.0741160412629447

Epoch: 5| Step: 3
Training loss: 0.8350164294242859
Validation loss: 2.0722227493921914

Epoch: 5| Step: 4
Training loss: 1.3712902069091797
Validation loss: 2.074768697222074

Epoch: 5| Step: 5
Training loss: 1.243609070777893
Validation loss: 2.037462522586187

Epoch: 5| Step: 6
Training loss: 0.8697942495346069
Validation loss: 2.025018443663915

Epoch: 5| Step: 7
Training loss: 1.31182861328125
Validation loss: 2.0286525736252465

Epoch: 5| Step: 8
Training loss: 1.1009682416915894
Validation loss: 2.054415057102839

Epoch: 5| Step: 9
Training loss: 1.0633622407913208
Validation loss: 2.1341943442821503

Epoch: 5| Step: 10
Training loss: 1.3953514099121094
Validation loss: 2.111291249593099

Epoch: 5| Step: 11
Training loss: 0.7369994521141052
Validation loss: 2.0660572399695716

Epoch: 132| Step: 0
Training loss: 1.3337661027908325
Validation loss: 2.0687980949878693

Epoch: 5| Step: 1
Training loss: 0.3460488021373749
Validation loss: 2.005626584092776

Epoch: 5| Step: 2
Training loss: 0.9807558059692383
Validation loss: 2.0663609306017556

Epoch: 5| Step: 3
Training loss: 1.232116937637329
Validation loss: 2.06088624894619

Epoch: 5| Step: 4
Training loss: 1.2131168842315674
Validation loss: 2.0670213202635446

Epoch: 5| Step: 5
Training loss: 1.1879265308380127
Validation loss: 2.05160653591156

Epoch: 5| Step: 6
Training loss: 1.2971481084823608
Validation loss: 2.0587410082419715

Epoch: 5| Step: 7
Training loss: 0.9297711253166199
Validation loss: 2.040182108680407

Epoch: 5| Step: 8
Training loss: 1.2581167221069336
Validation loss: 2.0136988957722983

Epoch: 5| Step: 9
Training loss: 1.085582971572876
Validation loss: 2.070807854334513

Epoch: 5| Step: 10
Training loss: 0.9485570192337036
Validation loss: 2.04691244661808

Epoch: 5| Step: 11
Training loss: 0.7458013296127319
Validation loss: 2.039225419362386

Epoch: 133| Step: 0
Training loss: 1.1165574789047241
Validation loss: 2.090482145547867

Epoch: 5| Step: 1
Training loss: 1.2567144632339478
Validation loss: 2.102513000369072

Epoch: 5| Step: 2
Training loss: 0.9854394197463989
Validation loss: 2.030642877022425

Epoch: 5| Step: 3
Training loss: 0.7879923582077026
Validation loss: 2.0406240820884705

Epoch: 5| Step: 4
Training loss: 1.2064905166625977
Validation loss: 2.062345862388611

Epoch: 5| Step: 5
Training loss: 0.8777246475219727
Validation loss: 2.0787333846092224

Epoch: 5| Step: 6
Training loss: 1.022801399230957
Validation loss: 2.014564588665962

Epoch: 5| Step: 7
Training loss: 1.518143892288208
Validation loss: 1.9978753179311752

Epoch: 5| Step: 8
Training loss: 0.7928192019462585
Validation loss: 2.067665467659632

Epoch: 5| Step: 9
Training loss: 0.8526485562324524
Validation loss: 2.042692025502523

Epoch: 5| Step: 10
Training loss: 1.0103967189788818
Validation loss: 2.034856140613556

Epoch: 5| Step: 11
Training loss: 0.44983363151550293
Validation loss: 2.043611298004786

Epoch: 134| Step: 0
Training loss: 1.1296151876449585
Validation loss: 2.0474143425623574

Epoch: 5| Step: 1
Training loss: 1.1568479537963867
Validation loss: 2.0502339651187262

Epoch: 5| Step: 2
Training loss: 1.3192822933197021
Validation loss: 2.059401457508405

Epoch: 5| Step: 3
Training loss: 0.5305874943733215
Validation loss: 2.0310040613015494

Epoch: 5| Step: 4
Training loss: 0.5768896341323853
Validation loss: 2.053913210829099

Epoch: 5| Step: 5
Training loss: 1.0239640474319458
Validation loss: 2.077626278003057

Epoch: 5| Step: 6
Training loss: 0.6706821918487549
Validation loss: 2.005537668863932

Epoch: 5| Step: 7
Training loss: 0.9205623865127563
Validation loss: 2.063398619492849

Epoch: 5| Step: 8
Training loss: 1.2272180318832397
Validation loss: 2.0584590385357537

Epoch: 5| Step: 9
Training loss: 1.4467971324920654
Validation loss: 2.064829041560491

Epoch: 5| Step: 10
Training loss: 0.775134265422821
Validation loss: 2.048981914917628

Epoch: 5| Step: 11
Training loss: 1.0878111124038696
Validation loss: 2.116601953903834

Epoch: 135| Step: 0
Training loss: 1.0878115892410278
Validation loss: 2.0894164045651755

Epoch: 5| Step: 1
Training loss: 1.5452241897583008
Validation loss: 2.0363835791746774

Epoch: 5| Step: 2
Training loss: 1.3173813819885254
Validation loss: 2.1010655611753464

Epoch: 5| Step: 3
Training loss: 0.6338907480239868
Validation loss: 2.0839280585447946

Epoch: 5| Step: 4
Training loss: 1.171866774559021
Validation loss: 2.0585830360651016

Epoch: 5| Step: 5
Training loss: 1.5031507015228271
Validation loss: 2.0228621810674667

Epoch: 5| Step: 6
Training loss: 1.0252554416656494
Validation loss: 2.0882960855960846

Epoch: 5| Step: 7
Training loss: 0.9477297067642212
Validation loss: 2.0883603195349374

Epoch: 5| Step: 8
Training loss: 1.244728446006775
Validation loss: 2.09354039033254

Epoch: 5| Step: 9
Training loss: 0.4490109086036682
Validation loss: 2.0236152609189353

Epoch: 5| Step: 10
Training loss: 0.7290425300598145
Validation loss: 2.0169505029916763

Epoch: 5| Step: 11
Training loss: 2.502499580383301
Validation loss: 2.0411443610986075

Epoch: 136| Step: 0
Training loss: 1.0897761583328247
Validation loss: 2.0838679621617

Epoch: 5| Step: 1
Training loss: 0.9192950129508972
Validation loss: 2.0533355673154197

Epoch: 5| Step: 2
Training loss: 0.8329706192016602
Validation loss: 2.0017579197883606

Epoch: 5| Step: 3
Training loss: 1.1700495481491089
Validation loss: 2.090441713730494

Epoch: 5| Step: 4
Training loss: 0.630539059638977
Validation loss: 2.0479270617167153

Epoch: 5| Step: 5
Training loss: 0.6292254328727722
Validation loss: 1.9877966344356537

Epoch: 5| Step: 6
Training loss: 1.1623860597610474
Validation loss: 2.0528391301631927

Epoch: 5| Step: 7
Training loss: 1.0831350088119507
Validation loss: 2.012548233071963

Epoch: 5| Step: 8
Training loss: 1.1398617029190063
Validation loss: 2.031235327323278

Epoch: 5| Step: 9
Training loss: 0.9835366010665894
Validation loss: 2.0332397470871606

Epoch: 5| Step: 10
Training loss: 1.3390132188796997
Validation loss: 2.058938667178154

Epoch: 5| Step: 11
Training loss: 0.43649721145629883
Validation loss: 2.0961376428604126

Epoch: 137| Step: 0
Training loss: 0.9090696573257446
Validation loss: 2.1023739775021872

Epoch: 5| Step: 1
Training loss: 1.0932772159576416
Validation loss: 2.062297821044922

Epoch: 5| Step: 2
Training loss: 1.1959781646728516
Validation loss: 2.0601642380158105

Epoch: 5| Step: 3
Training loss: 0.8654814958572388
Validation loss: 2.0349825769662857

Epoch: 5| Step: 4
Training loss: 1.1661360263824463
Validation loss: 2.076445907354355

Epoch: 5| Step: 5
Training loss: 0.6132680773735046
Validation loss: 2.0564439445734024

Epoch: 5| Step: 6
Training loss: 0.7866190075874329
Validation loss: 2.029952108860016

Epoch: 5| Step: 7
Training loss: 0.8906777501106262
Validation loss: 2.00945575038592

Epoch: 5| Step: 8
Training loss: 0.8556682467460632
Validation loss: 2.0337261458237967

Epoch: 5| Step: 9
Training loss: 0.9879919290542603
Validation loss: 2.0738824605941772

Epoch: 5| Step: 10
Training loss: 1.1307884454727173
Validation loss: 2.056531568368276

Epoch: 5| Step: 11
Training loss: 1.378562092781067
Validation loss: 2.044471964240074

Epoch: 138| Step: 0
Training loss: 0.7484567165374756
Validation loss: 2.0237547705570855

Epoch: 5| Step: 1
Training loss: 1.1388466358184814
Validation loss: 2.0140372614065805

Epoch: 5| Step: 2
Training loss: 0.8069313168525696
Validation loss: 2.0579293916622796

Epoch: 5| Step: 3
Training loss: 1.2056632041931152
Validation loss: 2.0402351866165795

Epoch: 5| Step: 4
Training loss: 0.9864183664321899
Validation loss: 2.0558458864688873

Epoch: 5| Step: 5
Training loss: 1.2685353755950928
Validation loss: 2.0706234723329544

Epoch: 5| Step: 6
Training loss: 1.0220075845718384
Validation loss: 2.02479716638724

Epoch: 5| Step: 7
Training loss: 0.6980999708175659
Validation loss: 2.0174761513868966

Epoch: 5| Step: 8
Training loss: 0.895604133605957
Validation loss: 2.047238811850548

Epoch: 5| Step: 9
Training loss: 1.029394268989563
Validation loss: 2.0792029897371926

Epoch: 5| Step: 10
Training loss: 1.065330147743225
Validation loss: 2.054094687104225

Epoch: 5| Step: 11
Training loss: 1.44474458694458
Validation loss: 2.0615236510833106

Epoch: 139| Step: 0
Training loss: 1.3058850765228271
Validation loss: 2.0506281604369483

Epoch: 5| Step: 1
Training loss: 1.6067836284637451
Validation loss: 2.0744139701128006

Epoch: 5| Step: 2
Training loss: 0.7675429582595825
Validation loss: 2.0463037192821503

Epoch: 5| Step: 3
Training loss: 1.0581939220428467
Validation loss: 2.03765739997228

Epoch: 5| Step: 4
Training loss: 0.838119626045227
Validation loss: 2.062183698018392

Epoch: 5| Step: 5
Training loss: 1.1602287292480469
Validation loss: 2.040763626495997

Epoch: 5| Step: 6
Training loss: 0.9952081441879272
Validation loss: 2.0582091410954795

Epoch: 5| Step: 7
Training loss: 0.6425160765647888
Validation loss: 2.1075413525104523

Epoch: 5| Step: 8
Training loss: 0.8396787643432617
Validation loss: 2.0838240534067154

Epoch: 5| Step: 9
Training loss: 0.7171511650085449
Validation loss: 2.106375897924105

Epoch: 5| Step: 10
Training loss: 1.1613647937774658
Validation loss: 2.11230560640494

Epoch: 5| Step: 11
Training loss: 0.5128094553947449
Validation loss: 2.090366000930468

Epoch: 140| Step: 0
Training loss: 1.2655012607574463
Validation loss: 2.1094480057557425

Epoch: 5| Step: 1
Training loss: 0.9107492566108704
Validation loss: 2.0990194231271744

Epoch: 5| Step: 2
Training loss: 0.9859791994094849
Validation loss: 2.0332104663054147

Epoch: 5| Step: 3
Training loss: 1.1304433345794678
Validation loss: 2.0700649321079254

Epoch: 5| Step: 4
Training loss: 0.857500433921814
Validation loss: 2.097411503394445

Epoch: 5| Step: 5
Training loss: 0.6770136952400208
Validation loss: 2.057976573705673

Epoch: 5| Step: 6
Training loss: 1.1884384155273438
Validation loss: 2.0386023422082267

Epoch: 5| Step: 7
Training loss: 0.9755600690841675
Validation loss: 2.029270187020302

Epoch: 5| Step: 8
Training loss: 0.987424373626709
Validation loss: 2.086724355816841

Epoch: 5| Step: 9
Training loss: 1.0978835821151733
Validation loss: 2.0840192834536233

Epoch: 5| Step: 10
Training loss: 0.6928573846817017
Validation loss: 2.084479421377182

Epoch: 5| Step: 11
Training loss: 0.9324525594711304
Validation loss: 2.0570017794768014

Epoch: 141| Step: 0
Training loss: 1.0111658573150635
Validation loss: 2.0302941501140594

Epoch: 5| Step: 1
Training loss: 0.7834643721580505
Validation loss: 2.058702275156975

Epoch: 5| Step: 2
Training loss: 0.6810042262077332
Validation loss: 2.0468160808086395

Epoch: 5| Step: 3
Training loss: 1.1589032411575317
Validation loss: 2.028447096546491

Epoch: 5| Step: 4
Training loss: 0.5667173862457275
Validation loss: 2.0430227468411126

Epoch: 5| Step: 5
Training loss: 0.9881261587142944
Validation loss: 2.0277681052684784

Epoch: 5| Step: 6
Training loss: 1.2467467784881592
Validation loss: 2.0879793663819632

Epoch: 5| Step: 7
Training loss: 0.9774287343025208
Validation loss: 2.061194578806559

Epoch: 5| Step: 8
Training loss: 1.24005126953125
Validation loss: 2.031391590833664

Epoch: 5| Step: 9
Training loss: 0.8688014149665833
Validation loss: 2.0407999406258264

Epoch: 5| Step: 10
Training loss: 0.667837917804718
Validation loss: 2.011320486664772

Epoch: 5| Step: 11
Training loss: 1.7216521501541138
Validation loss: 2.041566034158071

Epoch: 142| Step: 0
Training loss: 1.1692763566970825
Validation loss: 2.0374818543593087

Epoch: 5| Step: 1
Training loss: 0.9577727317810059
Validation loss: 2.016646087169647

Epoch: 5| Step: 2
Training loss: 0.4822865426540375
Validation loss: 2.047883297006289

Epoch: 5| Step: 3
Training loss: 0.8623580932617188
Validation loss: 1.9943473438421886

Epoch: 5| Step: 4
Training loss: 1.475457787513733
Validation loss: 2.049155130982399

Epoch: 5| Step: 5
Training loss: 0.8078625798225403
Validation loss: 2.0332117031017938

Epoch: 5| Step: 6
Training loss: 0.8501778841018677
Validation loss: 1.9756537129481633

Epoch: 5| Step: 7
Training loss: 1.2026375532150269
Validation loss: 2.0367229928572974

Epoch: 5| Step: 8
Training loss: 0.8354536294937134
Validation loss: 2.039891834060351

Epoch: 5| Step: 9
Training loss: 1.086419701576233
Validation loss: 2.021860271692276

Epoch: 5| Step: 10
Training loss: 0.7356946468353271
Validation loss: 2.069930146137873

Epoch: 5| Step: 11
Training loss: 0.36931705474853516
Validation loss: 2.0183253437280655

Epoch: 143| Step: 0
Training loss: 0.7354385256767273
Validation loss: 2.0685600141684213

Epoch: 5| Step: 1
Training loss: 1.43451988697052
Validation loss: 2.0406809945901236

Epoch: 5| Step: 2
Training loss: 0.9405834078788757
Validation loss: 2.046464830636978

Epoch: 5| Step: 3
Training loss: 0.8600571751594543
Validation loss: 2.048565616210302

Epoch: 5| Step: 4
Training loss: 0.5245062112808228
Validation loss: 2.0316455413897834

Epoch: 5| Step: 5
Training loss: 1.1849191188812256
Validation loss: 2.0440624058246613

Epoch: 5| Step: 6
Training loss: 0.7250113487243652
Validation loss: 2.073305914799372

Epoch: 5| Step: 7
Training loss: 0.8977559208869934
Validation loss: 2.030291343728701

Epoch: 5| Step: 8
Training loss: 0.9718294143676758
Validation loss: 2.019059712688128

Epoch: 5| Step: 9
Training loss: 1.091420292854309
Validation loss: 2.064467117190361

Epoch: 5| Step: 10
Training loss: 0.8704061508178711
Validation loss: 2.0478952676057816

Epoch: 5| Step: 11
Training loss: 2.070284366607666
Validation loss: 2.0267800142367682

Epoch: 144| Step: 0
Training loss: 0.8409539461135864
Validation loss: 2.0433695365985236

Epoch: 5| Step: 1
Training loss: 0.764031708240509
Validation loss: 2.0647132992744446

Epoch: 5| Step: 2
Training loss: 0.8132163286209106
Validation loss: 2.079815243681272

Epoch: 5| Step: 3
Training loss: 1.210423231124878
Validation loss: 2.0484721114238105

Epoch: 5| Step: 4
Training loss: 1.242796540260315
Validation loss: 2.076172322034836

Epoch: 5| Step: 5
Training loss: 0.7091537714004517
Validation loss: 2.1013198693593345

Epoch: 5| Step: 6
Training loss: 0.6884888410568237
Validation loss: 2.0167296081781387

Epoch: 5| Step: 7
Training loss: 0.7794192433357239
Validation loss: 2.088406205177307

Epoch: 5| Step: 8
Training loss: 0.8108428716659546
Validation loss: 2.0751432925462723

Epoch: 5| Step: 9
Training loss: 1.0847487449645996
Validation loss: 2.076044941941897

Epoch: 5| Step: 10
Training loss: 0.9903310537338257
Validation loss: 2.0643013219038644

Epoch: 5| Step: 11
Training loss: 0.7315598726272583
Validation loss: 2.0401800175507865

Epoch: 145| Step: 0
Training loss: 1.0271639823913574
Validation loss: 2.068347935875257

Epoch: 5| Step: 1
Training loss: 0.7650606632232666
Validation loss: 2.091350848476092

Epoch: 5| Step: 2
Training loss: 0.8430951237678528
Validation loss: 2.023654525478681

Epoch: 5| Step: 3
Training loss: 1.0332986116409302
Validation loss: 2.0486059337854385

Epoch: 5| Step: 4
Training loss: 0.8031702041625977
Validation loss: 2.107988655567169

Epoch: 5| Step: 5
Training loss: 1.0125133991241455
Validation loss: 2.0961456348498664

Epoch: 5| Step: 6
Training loss: 0.8293312191963196
Validation loss: 2.1024499237537384

Epoch: 5| Step: 7
Training loss: 0.842623233795166
Validation loss: 2.1345730125904083

Epoch: 5| Step: 8
Training loss: 1.2667092084884644
Validation loss: 2.0851334929466248

Epoch: 5| Step: 9
Training loss: 0.8573371767997742
Validation loss: 2.0676322331031165

Epoch: 5| Step: 10
Training loss: 1.2521543502807617
Validation loss: 2.0665957629680634

Epoch: 5| Step: 11
Training loss: 1.4639250040054321
Validation loss: 2.1464870423078537

Epoch: 146| Step: 0
Training loss: 0.909365177154541
Validation loss: 2.058724229534467

Epoch: 5| Step: 1
Training loss: 1.0398359298706055
Validation loss: 2.029556388656298

Epoch: 5| Step: 2
Training loss: 0.7708653211593628
Validation loss: 2.0741508851448693

Epoch: 5| Step: 3
Training loss: 1.1983885765075684
Validation loss: 2.076274241010348

Epoch: 5| Step: 4
Training loss: 0.9607512354850769
Validation loss: 2.0958016365766525

Epoch: 5| Step: 5
Training loss: 1.0602068901062012
Validation loss: 2.06916207075119

Epoch: 5| Step: 6
Training loss: 0.9146801233291626
Validation loss: 2.0244965851306915

Epoch: 5| Step: 7
Training loss: 0.8931046724319458
Validation loss: 2.083953008055687

Epoch: 5| Step: 8
Training loss: 0.6051754951477051
Validation loss: 2.0111375947793326

Epoch: 5| Step: 9
Training loss: 0.7205770611763
Validation loss: 2.04415762424469

Epoch: 5| Step: 10
Training loss: 0.7422617077827454
Validation loss: 2.0764996061722436

Epoch: 5| Step: 11
Training loss: 0.3448960781097412
Validation loss: 2.0604996035496392

Epoch: 147| Step: 0
Training loss: 0.9590337872505188
Validation loss: 2.055142010251681

Epoch: 5| Step: 1
Training loss: 0.8687959909439087
Validation loss: 2.059948821862539

Epoch: 5| Step: 2
Training loss: 0.7613621950149536
Validation loss: 2.0353974203268685

Epoch: 5| Step: 3
Training loss: 1.3400580883026123
Validation loss: 2.0275871604681015

Epoch: 5| Step: 4
Training loss: 1.0512990951538086
Validation loss: 2.028564065694809

Epoch: 5| Step: 5
Training loss: 1.1937694549560547
Validation loss: 2.056043525536855

Epoch: 5| Step: 6
Training loss: 0.733216404914856
Validation loss: 2.0265842427810035

Epoch: 5| Step: 7
Training loss: 0.8856460452079773
Validation loss: 2.0392836332321167

Epoch: 5| Step: 8
Training loss: 1.1593577861785889
Validation loss: 2.0383442590634027

Epoch: 5| Step: 9
Training loss: 0.6540732383728027
Validation loss: 2.0959020803372064

Epoch: 5| Step: 10
Training loss: 0.7271994352340698
Validation loss: 2.018576920032501

Epoch: 5| Step: 11
Training loss: 1.50104558467865
Validation loss: 2.031603773434957

Epoch: 148| Step: 0
Training loss: 0.9981428384780884
Validation loss: 2.0814754962921143

Epoch: 5| Step: 1
Training loss: 0.617121160030365
Validation loss: 2.032125617067019

Epoch: 5| Step: 2
Training loss: 0.8793706893920898
Validation loss: 2.013668109973272

Epoch: 5| Step: 3
Training loss: 1.1469645500183105
Validation loss: 2.0927243332068124

Epoch: 5| Step: 4
Training loss: 0.7414690256118774
Validation loss: 2.0330662578344345

Epoch: 5| Step: 5
Training loss: 1.1980327367782593
Validation loss: 2.088889479637146

Epoch: 5| Step: 6
Training loss: 1.0151646137237549
Validation loss: 2.0847543825705848

Epoch: 5| Step: 7
Training loss: 0.6287654638290405
Validation loss: 2.0411518116792045

Epoch: 5| Step: 8
Training loss: 1.2609412670135498
Validation loss: 2.059662123521169

Epoch: 5| Step: 9
Training loss: 0.881268322467804
Validation loss: 2.0844683895508447

Epoch: 5| Step: 10
Training loss: 0.6943928599357605
Validation loss: 2.1338655799627304

Epoch: 5| Step: 11
Training loss: 2.3653721809387207
Validation loss: 2.0873104631900787

Epoch: 149| Step: 0
Training loss: 0.772077739238739
Validation loss: 2.0755031605561576

Epoch: 5| Step: 1
Training loss: 0.8769102096557617
Validation loss: 2.0909920185804367

Epoch: 5| Step: 2
Training loss: 0.9133694767951965
Validation loss: 2.085128501057625

Epoch: 5| Step: 3
Training loss: 0.6256366968154907
Validation loss: 2.1172840297222137

Epoch: 5| Step: 4
Training loss: 0.9463208913803101
Validation loss: 2.0435084650913873

Epoch: 5| Step: 5
Training loss: 1.144957423210144
Validation loss: 2.074885462721189

Epoch: 5| Step: 6
Training loss: 0.7730916738510132
Validation loss: 2.060057361920675

Epoch: 5| Step: 7
Training loss: 1.3281652927398682
Validation loss: 2.0563388963540397

Epoch: 5| Step: 8
Training loss: 0.8653867840766907
Validation loss: 2.080723156531652

Epoch: 5| Step: 9
Training loss: 0.7348449230194092
Validation loss: 2.0632319698731103

Epoch: 5| Step: 10
Training loss: 0.6965109705924988
Validation loss: 2.004450723528862

Epoch: 5| Step: 11
Training loss: 1.8126028776168823
Validation loss: 2.0726221104462943

Epoch: 150| Step: 0
Training loss: 0.7320489883422852
Validation loss: 2.0663316597541175

Epoch: 5| Step: 1
Training loss: 0.43359407782554626
Validation loss: 2.047532339890798

Epoch: 5| Step: 2
Training loss: 0.8846608996391296
Validation loss: 2.0767078200976052

Epoch: 5| Step: 3
Training loss: 0.7666875720024109
Validation loss: 2.062283307313919

Epoch: 5| Step: 4
Training loss: 1.0372670888900757
Validation loss: 2.0625530580679574

Epoch: 5| Step: 5
Training loss: 1.4260669946670532
Validation loss: 2.052963068087896

Epoch: 5| Step: 6
Training loss: 1.2428791522979736
Validation loss: 2.079484075307846

Epoch: 5| Step: 7
Training loss: 0.735599935054779
Validation loss: 2.085712497433027

Epoch: 5| Step: 8
Training loss: 0.5821371078491211
Validation loss: 2.0912666817506156

Epoch: 5| Step: 9
Training loss: 1.020043134689331
Validation loss: 2.1152172883351645

Epoch: 5| Step: 10
Training loss: 1.0476477146148682
Validation loss: 2.0887532432874045

Epoch: 5| Step: 11
Training loss: 0.9195971488952637
Validation loss: 2.084033211072286

Epoch: 151| Step: 0
Training loss: 0.7079898118972778
Validation loss: 2.0183581511179605

Epoch: 5| Step: 1
Training loss: 1.1507644653320312
Validation loss: 2.0485726793607077

Epoch: 5| Step: 2
Training loss: 0.7280260324478149
Validation loss: 2.123547082146009

Epoch: 5| Step: 3
Training loss: 0.9463236927986145
Validation loss: 2.085817575454712

Epoch: 5| Step: 4
Training loss: 0.8410494923591614
Validation loss: 2.0874029844999313

Epoch: 5| Step: 5
Training loss: 0.6488121151924133
Validation loss: 2.056865930557251

Epoch: 5| Step: 6
Training loss: 0.4053575396537781
Validation loss: 2.038893699645996

Epoch: 5| Step: 7
Training loss: 1.0609502792358398
Validation loss: 2.0866286059220633

Epoch: 5| Step: 8
Training loss: 1.3182685375213623
Validation loss: 2.060780937472979

Epoch: 5| Step: 9
Training loss: 1.0194408893585205
Validation loss: 2.065003623565038

Epoch: 5| Step: 10
Training loss: 0.8910650014877319
Validation loss: 2.0134804099798203

Epoch: 5| Step: 11
Training loss: 0.5693706274032593
Validation loss: 2.0571801364421844

Epoch: 152| Step: 0
Training loss: 1.0251257419586182
Validation loss: 2.0568493455648422

Epoch: 5| Step: 1
Training loss: 0.6789827346801758
Validation loss: 2.0538824796676636

Epoch: 5| Step: 2
Training loss: 0.48658496141433716
Validation loss: 2.054029713074366

Epoch: 5| Step: 3
Training loss: 0.8584820032119751
Validation loss: 2.0870926082134247

Epoch: 5| Step: 4
Training loss: 0.7982780933380127
Validation loss: 2.034796545902888

Epoch: 5| Step: 5
Training loss: 1.1373422145843506
Validation loss: 2.105309655268987

Epoch: 5| Step: 6
Training loss: 1.0950877666473389
Validation loss: 2.101819654305776

Epoch: 5| Step: 7
Training loss: 0.640131950378418
Validation loss: 2.111903245250384

Epoch: 5| Step: 8
Training loss: 1.126417875289917
Validation loss: 2.122546136379242

Epoch: 5| Step: 9
Training loss: 0.6194776296615601
Validation loss: 2.119611536463102

Epoch: 5| Step: 10
Training loss: 0.8181822896003723
Validation loss: 2.1109306315581002

Epoch: 5| Step: 11
Training loss: 0.7915584444999695
Validation loss: 2.093773608406385

Epoch: 153| Step: 0
Training loss: 0.8870515823364258
Validation loss: 2.0904121498266854

Epoch: 5| Step: 1
Training loss: 0.8882411122322083
Validation loss: 2.1158406734466553

Epoch: 5| Step: 2
Training loss: 1.0215739011764526
Validation loss: 2.1622530221939087

Epoch: 5| Step: 3
Training loss: 1.0442025661468506
Validation loss: 2.1526509126027427

Epoch: 5| Step: 4
Training loss: 1.0158939361572266
Validation loss: 2.1309087624152503

Epoch: 5| Step: 5
Training loss: 1.553008794784546
Validation loss: 2.065905044476191

Epoch: 5| Step: 6
Training loss: 0.6945430040359497
Validation loss: 2.0880212684472403

Epoch: 5| Step: 7
Training loss: 0.7172307372093201
Validation loss: 2.094457671046257

Epoch: 5| Step: 8
Training loss: 0.6132093667984009
Validation loss: 2.136233771840731

Epoch: 5| Step: 9
Training loss: 1.1636083126068115
Validation loss: 2.0709800322850547

Epoch: 5| Step: 10
Training loss: 0.5884572863578796
Validation loss: 2.0429984678824744

Epoch: 5| Step: 11
Training loss: 0.6773340702056885
Validation loss: 2.0452737559874854

Epoch: 154| Step: 0
Training loss: 0.5833117365837097
Validation loss: 2.066497713327408

Epoch: 5| Step: 1
Training loss: 0.7935785055160522
Validation loss: 2.071314533551534

Epoch: 5| Step: 2
Training loss: 0.7397685050964355
Validation loss: 2.1246427496274314

Epoch: 5| Step: 3
Training loss: 0.6762868165969849
Validation loss: 2.087076579531034

Epoch: 5| Step: 4
Training loss: 0.9159588813781738
Validation loss: 2.0884021520614624

Epoch: 5| Step: 5
Training loss: 0.41595354676246643
Validation loss: 2.0633201748132706

Epoch: 5| Step: 6
Training loss: 0.7169508337974548
Validation loss: 2.0692747930685678

Epoch: 5| Step: 7
Training loss: 1.304340124130249
Validation loss: 2.067202165722847

Epoch: 5| Step: 8
Training loss: 0.7357190847396851
Validation loss: 2.041166519125303

Epoch: 5| Step: 9
Training loss: 0.8126918077468872
Validation loss: 2.080892259875933

Epoch: 5| Step: 10
Training loss: 0.8177102208137512
Validation loss: 2.080409417549769

Epoch: 5| Step: 11
Training loss: 3.51888108253479
Validation loss: 2.07595261434714

Epoch: 155| Step: 0
Training loss: 0.7753251194953918
Validation loss: 2.064691493908564

Epoch: 5| Step: 1
Training loss: 0.9999980926513672
Validation loss: 2.0449459652105966

Epoch: 5| Step: 2
Training loss: 1.074790358543396
Validation loss: 2.0212022264798484

Epoch: 5| Step: 3
Training loss: 0.5630179643630981
Validation loss: 2.0980901618798575

Epoch: 5| Step: 4
Training loss: 0.7312191128730774
Validation loss: 2.0465368876854577

Epoch: 5| Step: 5
Training loss: 0.4773004651069641
Validation loss: 2.0515505224466324

Epoch: 5| Step: 6
Training loss: 1.08809232711792
Validation loss: 2.0448567122220993

Epoch: 5| Step: 7
Training loss: 0.8976202011108398
Validation loss: 2.0839990228414536

Epoch: 5| Step: 8
Training loss: 0.46400564908981323
Validation loss: 2.0470914443333945

Epoch: 5| Step: 9
Training loss: 0.677789032459259
Validation loss: 2.0429138243198395

Epoch: 5| Step: 10
Training loss: 1.3777602910995483
Validation loss: 2.0668009320894876

Epoch: 5| Step: 11
Training loss: 1.1845746040344238
Validation loss: 2.061333899696668

Epoch: 156| Step: 0
Training loss: 1.2536287307739258
Validation loss: 2.060153911511103

Epoch: 5| Step: 1
Training loss: 0.5932637453079224
Validation loss: 2.073578864336014

Epoch: 5| Step: 2
Training loss: 0.9349498748779297
Validation loss: 2.0730325331290564

Epoch: 5| Step: 3
Training loss: 0.8570696115493774
Validation loss: 2.069398487607638

Epoch: 5| Step: 4
Training loss: 0.8695330619812012
Validation loss: 2.0442612965901694

Epoch: 5| Step: 5
Training loss: 0.480093777179718
Validation loss: 2.0702032099167504

Epoch: 5| Step: 6
Training loss: 0.9231292009353638
Validation loss: 2.0395299196243286

Epoch: 5| Step: 7
Training loss: 0.8548121452331543
Validation loss: 2.0403985679149628

Epoch: 5| Step: 8
Training loss: 0.7817271947860718
Validation loss: 2.010861247777939

Epoch: 5| Step: 9
Training loss: 0.8552831411361694
Validation loss: 2.029793088634809

Epoch: 5| Step: 10
Training loss: 0.8234584927558899
Validation loss: 2.0854833672444024

Epoch: 5| Step: 11
Training loss: 0.8670809268951416
Validation loss: 2.092668727040291

Epoch: 157| Step: 0
Training loss: 0.8319329023361206
Validation loss: 2.050383354226748

Epoch: 5| Step: 1
Training loss: 1.3374769687652588
Validation loss: 2.0681071877479553

Epoch: 5| Step: 2
Training loss: 0.5932915210723877
Validation loss: 2.0492474486430488

Epoch: 5| Step: 3
Training loss: 0.6151033043861389
Validation loss: 2.06198687851429

Epoch: 5| Step: 4
Training loss: 0.6681088209152222
Validation loss: 2.0298329840103784

Epoch: 5| Step: 5
Training loss: 0.8670549392700195
Validation loss: 1.9954789380232494

Epoch: 5| Step: 6
Training loss: 1.1045022010803223
Validation loss: 2.0618759592374167

Epoch: 5| Step: 7
Training loss: 0.550299882888794
Validation loss: 2.076972951491674

Epoch: 5| Step: 8
Training loss: 1.1232694387435913
Validation loss: 2.10238046447436

Epoch: 5| Step: 9
Training loss: 0.6996206045150757
Validation loss: 2.0467016100883484

Epoch: 5| Step: 10
Training loss: 0.6856412887573242
Validation loss: 2.091566945115725

Epoch: 5| Step: 11
Training loss: 1.1708130836486816
Validation loss: 2.1006115476290383

Epoch: 158| Step: 0
Training loss: 1.193979263305664
Validation loss: 2.0497679809729257

Epoch: 5| Step: 1
Training loss: 0.7819610834121704
Validation loss: 2.0512879689534507

Epoch: 5| Step: 2
Training loss: 0.7002806663513184
Validation loss: 2.086100528637568

Epoch: 5| Step: 3
Training loss: 0.8024692535400391
Validation loss: 2.0206341644128165

Epoch: 5| Step: 4
Training loss: 0.7937453389167786
Validation loss: 2.081638067960739

Epoch: 5| Step: 5
Training loss: 0.6548742055892944
Validation loss: 2.0912908414999642

Epoch: 5| Step: 6
Training loss: 0.824820876121521
Validation loss: 2.0670030315717063

Epoch: 5| Step: 7
Training loss: 0.7305857539176941
Validation loss: 2.0285792152086892

Epoch: 5| Step: 8
Training loss: 0.7063169479370117
Validation loss: 2.074601724743843

Epoch: 5| Step: 9
Training loss: 1.0259003639221191
Validation loss: 2.0931710302829742

Epoch: 5| Step: 10
Training loss: 0.5433338284492493
Validation loss: 2.1001236786444983

Epoch: 5| Step: 11
Training loss: 1.4684993028640747
Validation loss: 2.0747872591018677

Epoch: 159| Step: 0
Training loss: 0.6116717457771301
Validation loss: 2.061972642938296

Epoch: 5| Step: 1
Training loss: 0.835737407207489
Validation loss: 2.0262417842944465

Epoch: 5| Step: 2
Training loss: 0.6417540311813354
Validation loss: 2.082262476285299

Epoch: 5| Step: 3
Training loss: 0.6554878950119019
Validation loss: 2.0610170861085257

Epoch: 5| Step: 4
Training loss: 0.6795134544372559
Validation loss: 2.033864582578341

Epoch: 5| Step: 5
Training loss: 1.3651044368743896
Validation loss: 2.0995177725950875

Epoch: 5| Step: 6
Training loss: 0.8739205598831177
Validation loss: 2.100049525499344

Epoch: 5| Step: 7
Training loss: 0.8410047292709351
Validation loss: 2.0462047259012857

Epoch: 5| Step: 8
Training loss: 0.8803720474243164
Validation loss: 2.056248664855957

Epoch: 5| Step: 9
Training loss: 0.8853181004524231
Validation loss: 2.0731231371561685

Epoch: 5| Step: 10
Training loss: 0.7852280735969543
Validation loss: 2.0376273691654205

Epoch: 5| Step: 11
Training loss: 1.221893310546875
Validation loss: 2.045299937327703

Epoch: 160| Step: 0
Training loss: 0.6225312948226929
Validation loss: 2.0180709262688956

Epoch: 5| Step: 1
Training loss: 0.7753645777702332
Validation loss: 2.0922316759824753

Epoch: 5| Step: 2
Training loss: 0.8462033271789551
Validation loss: 2.0629190454880395

Epoch: 5| Step: 3
Training loss: 0.7969909906387329
Validation loss: 2.0787915835777917

Epoch: 5| Step: 4
Training loss: 0.5286668539047241
Validation loss: 2.047326227029165

Epoch: 5| Step: 5
Training loss: 0.6523183584213257
Validation loss: 2.033032943805059

Epoch: 5| Step: 6
Training loss: 1.1084868907928467
Validation loss: 2.0443793137868247

Epoch: 5| Step: 7
Training loss: 1.1285203695297241
Validation loss: 2.035184567173322

Epoch: 5| Step: 8
Training loss: 1.0568170547485352
Validation loss: 2.016445313890775

Epoch: 5| Step: 9
Training loss: 0.4941546320915222
Validation loss: 2.0404863556226096

Epoch: 5| Step: 10
Training loss: 0.754582405090332
Validation loss: 1.9936088770627975

Epoch: 5| Step: 11
Training loss: 0.8404481410980225
Validation loss: 2.087772324681282

Epoch: 161| Step: 0
Training loss: 1.0389184951782227
Validation loss: 2.0833186358213425

Epoch: 5| Step: 1
Training loss: 0.5807154774665833
Validation loss: 2.104551757375399

Epoch: 5| Step: 2
Training loss: 1.1833387613296509
Validation loss: 2.085783009727796

Epoch: 5| Step: 3
Training loss: 0.8075329065322876
Validation loss: 2.07866541047891

Epoch: 5| Step: 4
Training loss: 0.47814980149269104
Validation loss: 2.0693365583817163

Epoch: 5| Step: 5
Training loss: 0.6109477281570435
Validation loss: 2.083538939555486

Epoch: 5| Step: 6
Training loss: 0.720276951789856
Validation loss: 2.076938807964325

Epoch: 5| Step: 7
Training loss: 0.5880845785140991
Validation loss: 2.063857764005661

Epoch: 5| Step: 8
Training loss: 0.7128531336784363
Validation loss: 2.058356980482737

Epoch: 5| Step: 9
Training loss: 0.8325890302658081
Validation loss: 2.046221300959587

Epoch: 5| Step: 10
Training loss: 1.092775821685791
Validation loss: 2.0418937553962073

Epoch: 5| Step: 11
Training loss: 0.834591269493103
Validation loss: 2.0648546864589057

Epoch: 162| Step: 0
Training loss: 0.8905887603759766
Validation loss: 2.1063126772642136

Epoch: 5| Step: 1
Training loss: 0.8872931599617004
Validation loss: 2.0651635030905404

Epoch: 5| Step: 2
Training loss: 0.8108110427856445
Validation loss: 2.0371392915646234

Epoch: 5| Step: 3
Training loss: 0.41034355759620667
Validation loss: 2.091694340109825

Epoch: 5| Step: 4
Training loss: 0.8800102472305298
Validation loss: 2.0784823298454285

Epoch: 5| Step: 5
Training loss: 0.5336925983428955
Validation loss: 2.0663460244735083

Epoch: 5| Step: 6
Training loss: 0.8860677480697632
Validation loss: 2.0637426426013312

Epoch: 5| Step: 7
Training loss: 0.8776171803474426
Validation loss: 2.0960580507914224

Epoch: 5| Step: 8
Training loss: 1.0032973289489746
Validation loss: 2.091033468643824

Epoch: 5| Step: 9
Training loss: 0.6378205418586731
Validation loss: 2.0644307136535645

Epoch: 5| Step: 10
Training loss: 0.8520380258560181
Validation loss: 2.0592100818951926

Epoch: 5| Step: 11
Training loss: 0.3541021943092346
Validation loss: 2.0600164383649826

Epoch: 163| Step: 0
Training loss: 0.7339116334915161
Validation loss: 2.05133223036925

Epoch: 5| Step: 1
Training loss: 0.7239088416099548
Validation loss: 2.069661115606626

Epoch: 5| Step: 2
Training loss: 0.6187176704406738
Validation loss: 2.0610534995794296

Epoch: 5| Step: 3
Training loss: 0.9746509790420532
Validation loss: 2.086785445610682

Epoch: 5| Step: 4
Training loss: 0.46236807107925415
Validation loss: 2.0277694364388785

Epoch: 5| Step: 5
Training loss: 0.4906558096408844
Validation loss: 2.093111217021942

Epoch: 5| Step: 6
Training loss: 0.6281973719596863
Validation loss: 2.049819345275561

Epoch: 5| Step: 7
Training loss: 0.9520794153213501
Validation loss: 2.0456419736146927

Epoch: 5| Step: 8
Training loss: 1.0755689144134521
Validation loss: 2.0312019139528275

Epoch: 5| Step: 9
Training loss: 0.86784428358078
Validation loss: 2.0791935871044793

Epoch: 5| Step: 10
Training loss: 1.2389986515045166
Validation loss: 2.0840779691934586

Epoch: 5| Step: 11
Training loss: 0.5122333765029907
Validation loss: 2.0924405256907144

Epoch: 164| Step: 0
Training loss: 0.5283675789833069
Validation loss: 2.0348595082759857

Epoch: 5| Step: 1
Training loss: 0.8265022039413452
Validation loss: 2.072326565782229

Epoch: 5| Step: 2
Training loss: 0.8663305044174194
Validation loss: 2.0500947535037994

Epoch: 5| Step: 3
Training loss: 0.42937126755714417
Validation loss: 2.0492749561866126

Epoch: 5| Step: 4
Training loss: 0.8218681216239929
Validation loss: 2.0826564729213715

Epoch: 5| Step: 5
Training loss: 0.8395276069641113
Validation loss: 2.060237869620323

Epoch: 5| Step: 6
Training loss: 0.9039443731307983
Validation loss: 2.051751136779785

Epoch: 5| Step: 7
Training loss: 0.6616864204406738
Validation loss: 2.0568013389905295

Epoch: 5| Step: 8
Training loss: 0.6821882724761963
Validation loss: 2.0643626799186072

Epoch: 5| Step: 9
Training loss: 0.9091108441352844
Validation loss: 2.0310835440953574

Epoch: 5| Step: 10
Training loss: 1.0382410287857056
Validation loss: 2.038084094723066

Epoch: 5| Step: 11
Training loss: 0.46178102493286133
Validation loss: 2.0797378520170846

Epoch: 165| Step: 0
Training loss: 0.6271050572395325
Validation loss: 2.0745004961887994

Epoch: 5| Step: 1
Training loss: 0.5146517157554626
Validation loss: 2.0906098037958145

Epoch: 5| Step: 2
Training loss: 0.660925030708313
Validation loss: 2.053693716724714

Epoch: 5| Step: 3
Training loss: 1.0168988704681396
Validation loss: 2.0781467109918594

Epoch: 5| Step: 4
Training loss: 0.6396768093109131
Validation loss: 2.0542418162027993

Epoch: 5| Step: 5
Training loss: 0.6401287913322449
Validation loss: 2.047629098097483

Epoch: 5| Step: 6
Training loss: 0.9771332740783691
Validation loss: 2.0504880994558334

Epoch: 5| Step: 7
Training loss: 0.6548905968666077
Validation loss: 2.0732536564270654

Epoch: 5| Step: 8
Training loss: 0.7472245097160339
Validation loss: 2.0584558894236884

Epoch: 5| Step: 9
Training loss: 1.1733653545379639
Validation loss: 2.0495077619949975

Epoch: 5| Step: 10
Training loss: 0.7748097777366638
Validation loss: 2.0562753627697625

Epoch: 5| Step: 11
Training loss: 0.4160301685333252
Validation loss: 2.034642885128657

Epoch: 166| Step: 0
Training loss: 0.6911516189575195
Validation loss: 2.05030956864357

Epoch: 5| Step: 1
Training loss: 0.986117959022522
Validation loss: 2.0868898828824363

Epoch: 5| Step: 2
Training loss: 0.6285181045532227
Validation loss: 2.067970181504885

Epoch: 5| Step: 3
Training loss: 0.861496090888977
Validation loss: 2.0715006391207376

Epoch: 5| Step: 4
Training loss: 0.7513238787651062
Validation loss: 2.081762373447418

Epoch: 5| Step: 5
Training loss: 0.3760739862918854
Validation loss: 2.042757843931516

Epoch: 5| Step: 6
Training loss: 0.821916401386261
Validation loss: 2.0225619872411094

Epoch: 5| Step: 7
Training loss: 1.1675975322723389
Validation loss: 2.065155103802681

Epoch: 5| Step: 8
Training loss: 0.797276496887207
Validation loss: 2.011294975876808

Epoch: 5| Step: 9
Training loss: 0.5269752144813538
Validation loss: 2.0585776368776956

Epoch: 5| Step: 10
Training loss: 0.9010087847709656
Validation loss: 2.02310349047184

Epoch: 5| Step: 11
Training loss: 0.5208388566970825
Validation loss: 2.0216974516709647

Epoch: 167| Step: 0
Training loss: 0.6563163995742798
Validation loss: 2.0582795292139053

Epoch: 5| Step: 1
Training loss: 0.8662449717521667
Validation loss: 2.0279393742481866

Epoch: 5| Step: 2
Training loss: 1.0680011510849
Validation loss: 2.0719809432824454

Epoch: 5| Step: 3
Training loss: 0.8853633999824524
Validation loss: 2.0574197421471276

Epoch: 5| Step: 4
Training loss: 0.6292980313301086
Validation loss: 2.0694744338591895

Epoch: 5| Step: 5
Training loss: 0.8026873469352722
Validation loss: 2.0529214491446814

Epoch: 5| Step: 6
Training loss: 0.8289140462875366
Validation loss: 2.081463947892189

Epoch: 5| Step: 7
Training loss: 1.177968978881836
Validation loss: 2.0862856904665628

Epoch: 5| Step: 8
Training loss: 0.4843316972255707
Validation loss: 2.045955330133438

Epoch: 5| Step: 9
Training loss: 0.4936157166957855
Validation loss: 2.053530360261599

Epoch: 5| Step: 10
Training loss: 0.533979058265686
Validation loss: 2.079522505402565

Epoch: 5| Step: 11
Training loss: 0.6292900443077087
Validation loss: 2.0508747597535453

Epoch: 168| Step: 0
Training loss: 0.9053877592086792
Validation loss: 2.0757836401462555

Epoch: 5| Step: 1
Training loss: 0.7833844423294067
Validation loss: 2.055939262111982

Epoch: 5| Step: 2
Training loss: 0.34465867280960083
Validation loss: 2.0363957782586417

Epoch: 5| Step: 3
Training loss: 1.0831959247589111
Validation loss: 2.069535111387571

Epoch: 5| Step: 4
Training loss: 0.3616931438446045
Validation loss: 2.0947860181331635

Epoch: 5| Step: 5
Training loss: 0.9445902109146118
Validation loss: 2.07502810160319

Epoch: 5| Step: 6
Training loss: 0.7707259058952332
Validation loss: 2.0599196404218674

Epoch: 5| Step: 7
Training loss: 0.8472533226013184
Validation loss: 2.083632464210192

Epoch: 5| Step: 8
Training loss: 0.6889224648475647
Validation loss: 2.0603086203336716

Epoch: 5| Step: 9
Training loss: 0.26201000809669495
Validation loss: 2.032418961326281

Epoch: 5| Step: 10
Training loss: 0.7613305449485779
Validation loss: 2.053740685184797

Epoch: 5| Step: 11
Training loss: 1.4362289905548096
Validation loss: 2.0753351549307504

Epoch: 169| Step: 0
Training loss: 0.9034793972969055
Validation loss: 2.047432372967402

Epoch: 5| Step: 1
Training loss: 0.8542421460151672
Validation loss: 2.108177269498507

Epoch: 5| Step: 2
Training loss: 0.9735064506530762
Validation loss: 2.11678654452165

Epoch: 5| Step: 3
Training loss: 0.7809553146362305
Validation loss: 2.0426528652509055

Epoch: 5| Step: 4
Training loss: 0.6934850811958313
Validation loss: 2.0474548041820526

Epoch: 5| Step: 5
Training loss: 0.458004891872406
Validation loss: 2.046232596039772

Epoch: 5| Step: 6
Training loss: 0.4770394265651703
Validation loss: 2.0876653492450714

Epoch: 5| Step: 7
Training loss: 0.6127751469612122
Validation loss: 2.0560080905755362

Epoch: 5| Step: 8
Training loss: 1.0242340564727783
Validation loss: 2.076970880230268

Epoch: 5| Step: 9
Training loss: 0.7701452970504761
Validation loss: 2.0784368216991425

Epoch: 5| Step: 10
Training loss: 0.7877055406570435
Validation loss: 2.052800625562668

Epoch: 5| Step: 11
Training loss: 0.20197707414627075
Validation loss: 2.07131456832091

Epoch: 170| Step: 0
Training loss: 1.1263887882232666
Validation loss: 2.074755996465683

Epoch: 5| Step: 1
Training loss: 0.42736369371414185
Validation loss: 2.079870492219925

Epoch: 5| Step: 2
Training loss: 0.3323916494846344
Validation loss: 2.0710274328788123

Epoch: 5| Step: 3
Training loss: 0.6294091939926147
Validation loss: 2.035217985510826

Epoch: 5| Step: 4
Training loss: 0.9015104174613953
Validation loss: 2.0761314928531647

Epoch: 5| Step: 5
Training loss: 0.9653908014297485
Validation loss: 2.060901870330175

Epoch: 5| Step: 6
Training loss: 0.8910132646560669
Validation loss: 2.0642432272434235

Epoch: 5| Step: 7
Training loss: 0.50318443775177
Validation loss: 2.0608482559521994

Epoch: 5| Step: 8
Training loss: 0.8322765231132507
Validation loss: 2.0904489209254584

Epoch: 5| Step: 9
Training loss: 0.7679722309112549
Validation loss: 2.0653309176365533

Epoch: 5| Step: 10
Training loss: 0.4560767710208893
Validation loss: 2.064246897896131

Epoch: 5| Step: 11
Training loss: 0.2127935290336609
Validation loss: 2.065135990579923

Epoch: 171| Step: 0
Training loss: 0.9408685564994812
Validation loss: 2.0613248397906623

Epoch: 5| Step: 1
Training loss: 0.6283780336380005
Validation loss: 2.0553400119145713

Epoch: 5| Step: 2
Training loss: 0.5918039083480835
Validation loss: 2.036367356777191

Epoch: 5| Step: 3
Training loss: 0.7588797807693481
Validation loss: 2.102703203757604

Epoch: 5| Step: 4
Training loss: 0.6913924217224121
Validation loss: 2.1127005318800607

Epoch: 5| Step: 5
Training loss: 0.5837687253952026
Validation loss: 2.045067071914673

Epoch: 5| Step: 6
Training loss: 0.5566290616989136
Validation loss: 2.0602505654096603

Epoch: 5| Step: 7
Training loss: 0.9511593580245972
Validation loss: 2.0980378637711206

Epoch: 5| Step: 8
Training loss: 0.8326622247695923
Validation loss: 2.056905915339788

Epoch: 5| Step: 9
Training loss: 0.6075918674468994
Validation loss: 2.092455883820852

Epoch: 5| Step: 10
Training loss: 1.0057628154754639
Validation loss: 2.0671047468980155

Epoch: 5| Step: 11
Training loss: 0.33445191383361816
Validation loss: 2.062450254956881

Epoch: 172| Step: 0
Training loss: 0.6453710794448853
Validation loss: 2.0553253442049026

Epoch: 5| Step: 1
Training loss: 0.5928897857666016
Validation loss: 2.036779393752416

Epoch: 5| Step: 2
Training loss: 1.213091492652893
Validation loss: 2.0808412035306296

Epoch: 5| Step: 3
Training loss: 0.975010097026825
Validation loss: 2.103664959470431

Epoch: 5| Step: 4
Training loss: 0.5936446189880371
Validation loss: 2.11800246934096

Epoch: 5| Step: 5
Training loss: 1.0563538074493408
Validation loss: 2.104098970691363

Epoch: 5| Step: 6
Training loss: 0.6587111353874207
Validation loss: 2.1536622842152915

Epoch: 5| Step: 7
Training loss: 0.7428702116012573
Validation loss: 2.089932397007942

Epoch: 5| Step: 8
Training loss: 0.8141033053398132
Validation loss: 2.0709536572297416

Epoch: 5| Step: 9
Training loss: 0.7099040150642395
Validation loss: 2.0973319709300995

Epoch: 5| Step: 10
Training loss: 0.5727064609527588
Validation loss: 2.0975608875354133

Epoch: 5| Step: 11
Training loss: 0.43180227279663086
Validation loss: 2.0757561127344766

Epoch: 173| Step: 0
Training loss: 0.8859649896621704
Validation loss: 2.0678546528021493

Epoch: 5| Step: 1
Training loss: 0.9359374046325684
Validation loss: 2.041677082578341

Epoch: 5| Step: 2
Training loss: 0.7348968386650085
Validation loss: 2.0935036142667136

Epoch: 5| Step: 3
Training loss: 0.9275614023208618
Validation loss: 2.0645337949196496

Epoch: 5| Step: 4
Training loss: 0.8834384083747864
Validation loss: 2.1043299386898675

Epoch: 5| Step: 5
Training loss: 0.43472808599472046
Validation loss: 2.147211735447248

Epoch: 5| Step: 6
Training loss: 0.5196240544319153
Validation loss: 2.1243684937556586

Epoch: 5| Step: 7
Training loss: 0.7683570981025696
Validation loss: 2.1220452090104422

Epoch: 5| Step: 8
Training loss: 0.7042428851127625
Validation loss: 2.1472633431355157

Epoch: 5| Step: 9
Training loss: 0.5675839185714722
Validation loss: 2.0803225686152778

Epoch: 5| Step: 10
Training loss: 0.6410095691680908
Validation loss: 2.0437023590008416

Epoch: 5| Step: 11
Training loss: 0.5729084014892578
Validation loss: 2.0607104351123176

Epoch: 174| Step: 0
Training loss: 0.7980179786682129
Validation loss: 2.085214381416639

Epoch: 5| Step: 1
Training loss: 1.0253643989562988
Validation loss: 2.0687613685925803

Epoch: 5| Step: 2
Training loss: 0.6412369608879089
Validation loss: 2.066814293464025

Epoch: 5| Step: 3
Training loss: 0.8642204403877258
Validation loss: 2.062540218234062

Epoch: 5| Step: 4
Training loss: 0.6245197057723999
Validation loss: 2.0478938619295755

Epoch: 5| Step: 5
Training loss: 0.8078001141548157
Validation loss: 2.072209283709526

Epoch: 5| Step: 6
Training loss: 0.7406307458877563
Validation loss: 2.152763138214747

Epoch: 5| Step: 7
Training loss: 0.9391444325447083
Validation loss: 2.1677072942256927

Epoch: 5| Step: 8
Training loss: 0.6881137490272522
Validation loss: 2.1603539834419885

Epoch: 5| Step: 9
Training loss: 1.3741490840911865
Validation loss: 2.1051044215758643

Epoch: 5| Step: 10
Training loss: 0.4629613757133484
Validation loss: 2.0661175350348153

Epoch: 5| Step: 11
Training loss: 0.34688401222229004
Validation loss: 2.079982027411461

Epoch: 175| Step: 0
Training loss: 0.4546682834625244
Validation loss: 2.0432326992352805

Epoch: 5| Step: 1
Training loss: 0.8854548335075378
Validation loss: 2.0617186476786933

Epoch: 5| Step: 2
Training loss: 0.7842239737510681
Validation loss: 2.0436133493979773

Epoch: 5| Step: 3
Training loss: 0.75407475233078
Validation loss: 2.0739745845397315

Epoch: 5| Step: 4
Training loss: 0.5305405259132385
Validation loss: 2.034102807442347

Epoch: 5| Step: 5
Training loss: 0.8447118997573853
Validation loss: 2.075720096627871

Epoch: 5| Step: 6
Training loss: 0.7204675078392029
Validation loss: 2.094079832235972

Epoch: 5| Step: 7
Training loss: 0.8886613845825195
Validation loss: 2.1130011081695557

Epoch: 5| Step: 8
Training loss: 0.9614073038101196
Validation loss: 2.0668946901957193

Epoch: 5| Step: 9
Training loss: 0.7253714799880981
Validation loss: 2.110688711206118

Epoch: 5| Step: 10
Training loss: 0.6508710384368896
Validation loss: 2.1209289828936257

Epoch: 5| Step: 11
Training loss: 0.4169656038284302
Validation loss: 2.092859054605166

Epoch: 176| Step: 0
Training loss: 0.5399691462516785
Validation loss: 2.0726850579182305

Epoch: 5| Step: 1
Training loss: 0.7981367111206055
Validation loss: 2.0325434803962708

Epoch: 5| Step: 2
Training loss: 0.5011552572250366
Validation loss: 2.0763711432615914

Epoch: 5| Step: 3
Training loss: 1.0321784019470215
Validation loss: 2.0451188484827676

Epoch: 5| Step: 4
Training loss: 0.7478798627853394
Validation loss: 2.0393974483013153

Epoch: 5| Step: 5
Training loss: 1.2422500848770142
Validation loss: 2.027734264731407

Epoch: 5| Step: 6
Training loss: 0.519814670085907
Validation loss: 2.046950563788414

Epoch: 5| Step: 7
Training loss: 1.0745428800582886
Validation loss: 2.054903815189997

Epoch: 5| Step: 8
Training loss: 0.7580898404121399
Validation loss: 2.081345667441686

Epoch: 5| Step: 9
Training loss: 0.6210703253746033
Validation loss: 2.1139638970295587

Epoch: 5| Step: 10
Training loss: 0.7924241423606873
Validation loss: 2.078791235884031

Epoch: 5| Step: 11
Training loss: 0.33311641216278076
Validation loss: 2.0507726768652597

Epoch: 177| Step: 0
Training loss: 0.4335514008998871
Validation loss: 2.063895324865977

Epoch: 5| Step: 1
Training loss: 0.6440733671188354
Validation loss: 2.068324754635493

Epoch: 5| Step: 2
Training loss: 0.5027248859405518
Validation loss: 2.073396866520246

Epoch: 5| Step: 3
Training loss: 0.9480412602424622
Validation loss: 2.0704915275176368

Epoch: 5| Step: 4
Training loss: 1.0251213312149048
Validation loss: 2.1131266405185065

Epoch: 5| Step: 5
Training loss: 0.6664149165153503
Validation loss: 2.0676279067993164

Epoch: 5| Step: 6
Training loss: 0.36940062046051025
Validation loss: 2.0808731019496918

Epoch: 5| Step: 7
Training loss: 0.6630836129188538
Validation loss: 2.0209217419226966

Epoch: 5| Step: 8
Training loss: 0.8226419687271118
Validation loss: 2.0492608845233917

Epoch: 5| Step: 9
Training loss: 0.6428493857383728
Validation loss: 2.0595120191574097

Epoch: 5| Step: 10
Training loss: 0.8335440754890442
Validation loss: 2.0787397573391595

Epoch: 5| Step: 11
Training loss: 0.5430067777633667
Validation loss: 2.106150358915329

Epoch: 178| Step: 0
Training loss: 0.6255168318748474
Validation loss: 2.077502563595772

Epoch: 5| Step: 1
Training loss: 0.7034487724304199
Validation loss: 2.048467884461085

Epoch: 5| Step: 2
Training loss: 0.6240196228027344
Validation loss: 2.1177701403697333

Epoch: 5| Step: 3
Training loss: 1.0995604991912842
Validation loss: 2.057093779246012

Epoch: 5| Step: 4
Training loss: 0.5883458852767944
Validation loss: 2.0649093836545944

Epoch: 5| Step: 5
Training loss: 0.3840656876564026
Validation loss: 2.060125549634298

Epoch: 5| Step: 6
Training loss: 0.48583611845970154
Validation loss: 2.064020588994026

Epoch: 5| Step: 7
Training loss: 0.8044372797012329
Validation loss: 2.093456228574117

Epoch: 5| Step: 8
Training loss: 0.9312001466751099
Validation loss: 2.09012134373188

Epoch: 5| Step: 9
Training loss: 0.7537845969200134
Validation loss: 2.078638970851898

Epoch: 5| Step: 10
Training loss: 0.6091371178627014
Validation loss: 2.069073965152105

Epoch: 5| Step: 11
Training loss: 0.46578121185302734
Validation loss: 2.0538015564282737

Epoch: 179| Step: 0
Training loss: 0.694138765335083
Validation loss: 2.0570659836133323

Epoch: 5| Step: 1
Training loss: 0.5624755620956421
Validation loss: 2.0670792957146964

Epoch: 5| Step: 2
Training loss: 0.6359329223632812
Validation loss: 2.1114358454942703

Epoch: 5| Step: 3
Training loss: 0.7395197153091431
Validation loss: 2.0317615320285163

Epoch: 5| Step: 4
Training loss: 0.8642814755439758
Validation loss: 2.0473796129226685

Epoch: 5| Step: 5
Training loss: 0.5207034349441528
Validation loss: 2.0870812237262726

Epoch: 5| Step: 6
Training loss: 0.9124186635017395
Validation loss: 2.0519732187191644

Epoch: 5| Step: 7
Training loss: 1.0045181512832642
Validation loss: 2.06233357389768

Epoch: 5| Step: 8
Training loss: 0.6329024434089661
Validation loss: 2.056260277827581

Epoch: 5| Step: 9
Training loss: 0.3824388384819031
Validation loss: 2.04047000904878

Epoch: 5| Step: 10
Training loss: 0.8018600344657898
Validation loss: 2.0913821011781693

Epoch: 5| Step: 11
Training loss: 0.26909273862838745
Validation loss: 2.071278288960457

Epoch: 180| Step: 0
Training loss: 0.6577546000480652
Validation loss: 2.097883095343908

Epoch: 5| Step: 1
Training loss: 0.7444566488265991
Validation loss: 2.036162033677101

Epoch: 5| Step: 2
Training loss: 0.7528170347213745
Validation loss: 2.0592200458049774

Epoch: 5| Step: 3
Training loss: 0.7009676694869995
Validation loss: 2.057039981087049

Epoch: 5| Step: 4
Training loss: 0.9141761064529419
Validation loss: 2.0819340546925864

Epoch: 5| Step: 5
Training loss: 0.6887869238853455
Validation loss: 2.058753157655398

Epoch: 5| Step: 6
Training loss: 0.7818447947502136
Validation loss: 2.0653082182010016

Epoch: 5| Step: 7
Training loss: 0.5944995880126953
Validation loss: 2.0527166773875556

Epoch: 5| Step: 8
Training loss: 0.3817416727542877
Validation loss: 2.0769775112469993

Epoch: 5| Step: 9
Training loss: 0.5944901704788208
Validation loss: 2.0374429126580558

Epoch: 5| Step: 10
Training loss: 0.5953702330589294
Validation loss: 2.0378795663515725

Epoch: 5| Step: 11
Training loss: 0.5045669078826904
Validation loss: 2.0542481392621994

Epoch: 181| Step: 0
Training loss: 0.5464984178543091
Validation loss: 2.0284175177415213

Epoch: 5| Step: 1
Training loss: 0.4157978892326355
Validation loss: 2.0384750217199326

Epoch: 5| Step: 2
Training loss: 0.6565714478492737
Validation loss: 2.078100179632505

Epoch: 5| Step: 3
Training loss: 0.7107747793197632
Validation loss: 2.0455973545710244

Epoch: 5| Step: 4
Training loss: 1.0037028789520264
Validation loss: 2.002220114072164

Epoch: 5| Step: 5
Training loss: 0.9184262156486511
Validation loss: 2.074553539355596

Epoch: 5| Step: 6
Training loss: 0.7600438594818115
Validation loss: 2.0993479440609613

Epoch: 5| Step: 7
Training loss: 0.6795411109924316
Validation loss: 2.013482928276062

Epoch: 5| Step: 8
Training loss: 0.8445979952812195
Validation loss: 2.0927628179391227

Epoch: 5| Step: 9
Training loss: 0.5030380487442017
Validation loss: 2.1237349460522332

Epoch: 5| Step: 10
Training loss: 0.6858909726142883
Validation loss: 2.0738248030344644

Epoch: 5| Step: 11
Training loss: 0.8070211410522461
Validation loss: 2.088060438632965

Epoch: 182| Step: 0
Training loss: 0.7610313296318054
Validation loss: 2.0483490278323493

Epoch: 5| Step: 1
Training loss: 0.7938696146011353
Validation loss: 2.0459960599740348

Epoch: 5| Step: 2
Training loss: 0.6251375079154968
Validation loss: 2.060896714528402

Epoch: 5| Step: 3
Training loss: 0.6779166460037231
Validation loss: 2.0530364712079368

Epoch: 5| Step: 4
Training loss: 0.7632750272750854
Validation loss: 2.090868353843689

Epoch: 5| Step: 5
Training loss: 0.9285027384757996
Validation loss: 2.059170424938202

Epoch: 5| Step: 6
Training loss: 0.6438618898391724
Validation loss: 2.089134603738785

Epoch: 5| Step: 7
Training loss: 0.7971127033233643
Validation loss: 2.07271176079909

Epoch: 5| Step: 8
Training loss: 0.758068859577179
Validation loss: 2.1495227118333182

Epoch: 5| Step: 9
Training loss: 0.6320152282714844
Validation loss: 2.09908489882946

Epoch: 5| Step: 10
Training loss: 0.4902194142341614
Validation loss: 2.1354622344175973

Epoch: 5| Step: 11
Training loss: 0.980751097202301
Validation loss: 2.0945351968208947

Epoch: 183| Step: 0
Training loss: 0.5131686925888062
Validation loss: 2.0642353196938834

Epoch: 5| Step: 1
Training loss: 0.858765721321106
Validation loss: 2.080950304865837

Epoch: 5| Step: 2
Training loss: 0.6428369283676147
Validation loss: 2.0611625413099923

Epoch: 5| Step: 3
Training loss: 0.6490843892097473
Validation loss: 2.0271185090144477

Epoch: 5| Step: 4
Training loss: 0.8168466687202454
Validation loss: 2.047768771648407

Epoch: 5| Step: 5
Training loss: 1.0480060577392578
Validation loss: 2.1093795150518417

Epoch: 5| Step: 6
Training loss: 0.6332988142967224
Validation loss: 2.0766635636488595

Epoch: 5| Step: 7
Training loss: 0.8451962471008301
Validation loss: 2.093721310297648

Epoch: 5| Step: 8
Training loss: 0.6443151831626892
Validation loss: 2.0803393870592117

Epoch: 5| Step: 9
Training loss: 1.0037845373153687
Validation loss: 2.0762397944927216

Epoch: 5| Step: 10
Training loss: 0.557588517665863
Validation loss: 2.0745947460333505

Epoch: 5| Step: 11
Training loss: 0.4791274666786194
Validation loss: 2.068313017487526

Epoch: 184| Step: 0
Training loss: 0.6970545053482056
Validation loss: 2.0710604190826416

Epoch: 5| Step: 1
Training loss: 0.5456143617630005
Validation loss: 2.0272283355394998

Epoch: 5| Step: 2
Training loss: 0.441678524017334
Validation loss: 2.0645636469125748

Epoch: 5| Step: 3
Training loss: 0.3907293677330017
Validation loss: 2.022960757215818

Epoch: 5| Step: 4
Training loss: 0.5357385873794556
Validation loss: 2.048402632276217

Epoch: 5| Step: 5
Training loss: 0.7183207869529724
Validation loss: 2.036670501033465

Epoch: 5| Step: 6
Training loss: 0.48566102981567383
Validation loss: 2.032225380341212

Epoch: 5| Step: 7
Training loss: 0.690306544303894
Validation loss: 2.045915270845095

Epoch: 5| Step: 8
Training loss: 0.6229525804519653
Validation loss: 2.0677142987648645

Epoch: 5| Step: 9
Training loss: 1.4344265460968018
Validation loss: 2.031135320663452

Epoch: 5| Step: 10
Training loss: 0.6030364036560059
Validation loss: 2.0163250466187796

Epoch: 5| Step: 11
Training loss: 1.3213255405426025
Validation loss: 2.044465829928716

Epoch: 185| Step: 0
Training loss: 0.9675605893135071
Validation loss: 2.0137710322936377

Epoch: 5| Step: 1
Training loss: 0.7498732805252075
Validation loss: 2.0273368060588837

Epoch: 5| Step: 2
Training loss: 0.6664232611656189
Validation loss: 2.0883474349975586

Epoch: 5| Step: 3
Training loss: 0.5214641690254211
Validation loss: 2.0650346279144287

Epoch: 5| Step: 4
Training loss: 0.9477705955505371
Validation loss: 2.081985284884771

Epoch: 5| Step: 5
Training loss: 0.4765914976596832
Validation loss: 2.037147417664528

Epoch: 5| Step: 6
Training loss: 0.689051628112793
Validation loss: 2.0462409953276315

Epoch: 5| Step: 7
Training loss: 0.5210464596748352
Validation loss: 2.046958868702253

Epoch: 5| Step: 8
Training loss: 0.6384226083755493
Validation loss: 2.0415630588928857

Epoch: 5| Step: 9
Training loss: 0.6369398832321167
Validation loss: 2.0675522635380426

Epoch: 5| Step: 10
Training loss: 0.8011425137519836
Validation loss: 2.0230249414841333

Epoch: 5| Step: 11
Training loss: 0.3917701244354248
Validation loss: 2.044784893592199

Epoch: 186| Step: 0
Training loss: 0.3856789469718933
Validation loss: 2.053047036131223

Epoch: 5| Step: 1
Training loss: 0.8418901562690735
Validation loss: 2.053310841321945

Epoch: 5| Step: 2
Training loss: 0.5307480096817017
Validation loss: 2.0760781168937683

Epoch: 5| Step: 3
Training loss: 0.5745176076889038
Validation loss: 2.1057591289281845

Epoch: 5| Step: 4
Training loss: 0.7302659749984741
Validation loss: 2.052407279610634

Epoch: 5| Step: 5
Training loss: 0.5655041337013245
Validation loss: 2.0929806480805078

Epoch: 5| Step: 6
Training loss: 0.577147364616394
Validation loss: 2.0356625417868295

Epoch: 5| Step: 7
Training loss: 0.6464862823486328
Validation loss: 2.056889479358991

Epoch: 5| Step: 8
Training loss: 1.0190560817718506
Validation loss: 2.0414205292860665

Epoch: 5| Step: 9
Training loss: 0.9617568850517273
Validation loss: 2.0909458100795746

Epoch: 5| Step: 10
Training loss: 0.8307205438613892
Validation loss: 2.1161958078543344

Epoch: 5| Step: 11
Training loss: 0.4306713342666626
Validation loss: 2.075527638196945

Epoch: 187| Step: 0
Training loss: 0.4359959661960602
Validation loss: 2.0605258544286094

Epoch: 5| Step: 1
Training loss: 0.5295160412788391
Validation loss: 2.0598046084245047

Epoch: 5| Step: 2
Training loss: 0.9013736844062805
Validation loss: 1.981423705816269

Epoch: 5| Step: 3
Training loss: 0.4099980890750885
Validation loss: 2.080719515681267

Epoch: 5| Step: 4
Training loss: 1.0355515480041504
Validation loss: 2.09689562022686

Epoch: 5| Step: 5
Training loss: 0.8425396084785461
Validation loss: 2.08427856862545

Epoch: 5| Step: 6
Training loss: 0.6523023247718811
Validation loss: 2.0949776271979013

Epoch: 5| Step: 7
Training loss: 0.6631094813346863
Validation loss: 2.06197397907575

Epoch: 5| Step: 8
Training loss: 0.5325015187263489
Validation loss: 2.0872711489597955

Epoch: 5| Step: 9
Training loss: 0.6022207140922546
Validation loss: 2.054395228624344

Epoch: 5| Step: 10
Training loss: 0.6827015280723572
Validation loss: 2.075398991505305

Epoch: 5| Step: 11
Training loss: 0.30218827724456787
Validation loss: 2.0410013596216836

Epoch: 188| Step: 0
Training loss: 0.8159050941467285
Validation loss: 2.072611620028814

Epoch: 5| Step: 1
Training loss: 0.8433016538619995
Validation loss: 1.9922281950712204

Epoch: 5| Step: 2
Training loss: 0.8185997009277344
Validation loss: 2.0785611967245736

Epoch: 5| Step: 3
Training loss: 0.8208686709403992
Validation loss: 2.055208404858907

Epoch: 5| Step: 4
Training loss: 0.5288562774658203
Validation loss: 2.0205594648917518

Epoch: 5| Step: 5
Training loss: 0.4768622815608978
Validation loss: 2.080947811404864

Epoch: 5| Step: 6
Training loss: 0.684095025062561
Validation loss: 2.083335960904757

Epoch: 5| Step: 7
Training loss: 0.4564119279384613
Validation loss: 2.0433892607688904

Epoch: 5| Step: 8
Training loss: 0.38107988238334656
Validation loss: 2.0343707452217736

Epoch: 5| Step: 9
Training loss: 0.6603608727455139
Validation loss: 2.0464662661155066

Epoch: 5| Step: 10
Training loss: 0.5723867416381836
Validation loss: 2.0370016942421594

Epoch: 5| Step: 11
Training loss: 0.3884620666503906
Validation loss: 2.0594770858685174

Epoch: 189| Step: 0
Training loss: 0.8084917068481445
Validation loss: 2.05379352470239

Epoch: 5| Step: 1
Training loss: 0.43105974793434143
Validation loss: 2.0901162773370743

Epoch: 5| Step: 2
Training loss: 0.6185418367385864
Validation loss: 2.0148371309041977

Epoch: 5| Step: 3
Training loss: 0.6288215517997742
Validation loss: 2.0866914242506027

Epoch: 5| Step: 4
Training loss: 0.5869110226631165
Validation loss: 2.0009177327156067

Epoch: 5| Step: 5
Training loss: 0.7167569994926453
Validation loss: 2.0356876800457635

Epoch: 5| Step: 6
Training loss: 0.7177826166152954
Validation loss: 2.050844912727674

Epoch: 5| Step: 7
Training loss: 0.7870068550109863
Validation loss: 2.024923617641131

Epoch: 5| Step: 8
Training loss: 0.8238380551338196
Validation loss: 2.059986670811971

Epoch: 5| Step: 9
Training loss: 0.4739186763763428
Validation loss: 2.081534907221794

Epoch: 5| Step: 10
Training loss: 0.3412606418132782
Validation loss: 2.039575765530268

Epoch: 5| Step: 11
Training loss: 0.44346266984939575
Validation loss: 2.078852807482084

Epoch: 190| Step: 0
Training loss: 0.49153274297714233
Validation loss: 2.0406976441542306

Epoch: 5| Step: 1
Training loss: 0.651733934879303
Validation loss: 2.036467105150223

Epoch: 5| Step: 2
Training loss: 1.0931216478347778
Validation loss: 2.097094804048538

Epoch: 5| Step: 3
Training loss: 0.4773906171321869
Validation loss: 2.0533088793357215

Epoch: 5| Step: 4
Training loss: 0.5885568857192993
Validation loss: 2.0853409667809806

Epoch: 5| Step: 5
Training loss: 0.6529271602630615
Validation loss: 2.0931335439284644

Epoch: 5| Step: 6
Training loss: 0.4204466938972473
Validation loss: 2.0227315624554953

Epoch: 5| Step: 7
Training loss: 1.1054527759552002
Validation loss: 2.0675368855396905

Epoch: 5| Step: 8
Training loss: 0.4824449419975281
Validation loss: 2.0594380646944046

Epoch: 5| Step: 9
Training loss: 0.3097389042377472
Validation loss: 2.0760683765014014

Epoch: 5| Step: 10
Training loss: 0.49510860443115234
Validation loss: 2.067291706800461

Epoch: 5| Step: 11
Training loss: 0.402679443359375
Validation loss: 2.0528560827175775

Epoch: 191| Step: 0
Training loss: 0.6712153553962708
Validation loss: 2.0603734205166497

Epoch: 5| Step: 1
Training loss: 0.3734108507633209
Validation loss: 2.0718365410963693

Epoch: 5| Step: 2
Training loss: 0.5838289856910706
Validation loss: 2.0552341093619666

Epoch: 5| Step: 3
Training loss: 0.45542460680007935
Validation loss: 2.0995222429434457

Epoch: 5| Step: 4
Training loss: 0.8491617441177368
Validation loss: 2.090840498606364

Epoch: 5| Step: 5
Training loss: 0.7021327018737793
Validation loss: 2.0708122799793878

Epoch: 5| Step: 6
Training loss: 0.6188634634017944
Validation loss: 2.066274583339691

Epoch: 5| Step: 7
Training loss: 0.703283429145813
Validation loss: 2.0459248771270118

Epoch: 5| Step: 8
Training loss: 0.8376560211181641
Validation loss: 2.08746629456679

Epoch: 5| Step: 9
Training loss: 0.8545945286750793
Validation loss: 2.0652903070052466

Epoch: 5| Step: 10
Training loss: 0.7142220735549927
Validation loss: 2.0433702220519385

Epoch: 5| Step: 11
Training loss: 0.6440273523330688
Validation loss: 2.080003341039022

Epoch: 192| Step: 0
Training loss: 0.6210400462150574
Validation loss: 2.055994763970375

Epoch: 5| Step: 1
Training loss: 1.046139121055603
Validation loss: 2.057542160153389

Epoch: 5| Step: 2
Training loss: 0.4244101643562317
Validation loss: 2.07956700026989

Epoch: 5| Step: 3
Training loss: 0.4498714804649353
Validation loss: 2.0593068699042

Epoch: 5| Step: 4
Training loss: 1.0058355331420898
Validation loss: 2.0831875453392663

Epoch: 5| Step: 5
Training loss: 0.6351552605628967
Validation loss: 2.0475468933582306

Epoch: 5| Step: 6
Training loss: 0.8307391405105591
Validation loss: 2.1553718944390616

Epoch: 5| Step: 7
Training loss: 0.5998393893241882
Validation loss: 2.045462980866432

Epoch: 5| Step: 8
Training loss: 0.49073201417922974
Validation loss: 2.1331609586874642

Epoch: 5| Step: 9
Training loss: 0.29570335149765015
Validation loss: 2.1089623669783273

Epoch: 5| Step: 10
Training loss: 0.6706493496894836
Validation loss: 2.0414601614077887

Epoch: 5| Step: 11
Training loss: 0.5391263961791992
Validation loss: 2.0739454329013824

Epoch: 193| Step: 0
Training loss: 0.33877333998680115
Validation loss: 2.1222217281659446

Epoch: 5| Step: 1
Training loss: 0.4643334448337555
Validation loss: 2.054704656203588

Epoch: 5| Step: 2
Training loss: 0.5994821786880493
Validation loss: 2.063652351498604

Epoch: 5| Step: 3
Training loss: 0.5076817274093628
Validation loss: 2.068898697694143

Epoch: 5| Step: 4
Training loss: 0.4596809446811676
Validation loss: 2.0597122510274253

Epoch: 5| Step: 5
Training loss: 0.6263891458511353
Validation loss: 2.0026949594418206

Epoch: 5| Step: 6
Training loss: 0.9202843904495239
Validation loss: 2.0321588019529977

Epoch: 5| Step: 7
Training loss: 0.6430165767669678
Validation loss: 2.024758001168569

Epoch: 5| Step: 8
Training loss: 0.7909714579582214
Validation loss: 2.067463373144468

Epoch: 5| Step: 9
Training loss: 0.6374022960662842
Validation loss: 2.0616650680700936

Epoch: 5| Step: 10
Training loss: 0.7438554763793945
Validation loss: 2.0580505232016244

Epoch: 5| Step: 11
Training loss: 0.2636122703552246
Validation loss: 2.045388956864675

Epoch: 194| Step: 0
Training loss: 0.8520712852478027
Validation loss: 2.068626527984937

Epoch: 5| Step: 1
Training loss: 0.7755404710769653
Validation loss: 2.088043451309204

Epoch: 5| Step: 2
Training loss: 0.35181862115859985
Validation loss: 2.0741905172665915

Epoch: 5| Step: 3
Training loss: 0.7420845031738281
Validation loss: 2.1142443319161734

Epoch: 5| Step: 4
Training loss: 0.7803648710250854
Validation loss: 2.059231470028559

Epoch: 5| Step: 5
Training loss: 0.47733259201049805
Validation loss: 2.0795709987481437

Epoch: 5| Step: 6
Training loss: 0.6464309096336365
Validation loss: 2.0185269167025885

Epoch: 5| Step: 7
Training loss: 0.7149616479873657
Validation loss: 2.0422904243071875

Epoch: 5| Step: 8
Training loss: 0.8479238748550415
Validation loss: 2.08639786640803

Epoch: 5| Step: 9
Training loss: 0.8738301396369934
Validation loss: 2.048027435938517

Epoch: 5| Step: 10
Training loss: 0.3705635964870453
Validation loss: 2.029051333665848

Epoch: 5| Step: 11
Training loss: 1.9719996452331543
Validation loss: 2.0963245928287506

Epoch: 195| Step: 0
Training loss: 0.6143652200698853
Validation loss: 2.1187268495559692

Epoch: 5| Step: 1
Training loss: 0.7530416250228882
Validation loss: 2.0912707348664603

Epoch: 5| Step: 2
Training loss: 0.6182035207748413
Validation loss: 2.082004889845848

Epoch: 5| Step: 3
Training loss: 0.7084311246871948
Validation loss: 2.042609135309855

Epoch: 5| Step: 4
Training loss: 0.49919137358665466
Validation loss: 2.0382105708122253

Epoch: 5| Step: 5
Training loss: 0.4522797465324402
Validation loss: 1.9902915507555008

Epoch: 5| Step: 6
Training loss: 0.9484187364578247
Validation loss: 2.09089824060599

Epoch: 5| Step: 7
Training loss: 0.8123634457588196
Validation loss: 1.9814732273419697

Epoch: 5| Step: 8
Training loss: 0.6298667192459106
Validation loss: 2.035012443860372

Epoch: 5| Step: 9
Training loss: 0.5237613916397095
Validation loss: 2.0226216316223145

Epoch: 5| Step: 10
Training loss: 0.7890491485595703
Validation loss: 2.0129160036643348

Epoch: 5| Step: 11
Training loss: 0.5434979796409607
Validation loss: 2.0742605477571487

Epoch: 196| Step: 0
Training loss: 0.7429972290992737
Validation loss: 2.0490260273218155

Epoch: 5| Step: 1
Training loss: 0.7446838617324829
Validation loss: 2.128556326031685

Epoch: 5| Step: 2
Training loss: 0.8501774668693542
Validation loss: 2.03969898323218

Epoch: 5| Step: 3
Training loss: 0.6536725163459778
Validation loss: 2.0933819711208344

Epoch: 5| Step: 4
Training loss: 0.7104564905166626
Validation loss: 2.0661934266487756

Epoch: 5| Step: 5
Training loss: 0.8050772547721863
Validation loss: 2.0899427185455957

Epoch: 5| Step: 6
Training loss: 0.5557514429092407
Validation loss: 2.0748502363761268

Epoch: 5| Step: 7
Training loss: 0.7932525873184204
Validation loss: 2.0256527811288834

Epoch: 5| Step: 8
Training loss: 0.578610897064209
Validation loss: 2.099911401669184

Epoch: 5| Step: 9
Training loss: 0.43583792448043823
Validation loss: 2.0139265755812326

Epoch: 5| Step: 10
Training loss: 0.48549968004226685
Validation loss: 2.0545157144467034

Epoch: 5| Step: 11
Training loss: 0.38118070363998413
Validation loss: 2.1240320056676865

Epoch: 197| Step: 0
Training loss: 0.967167854309082
Validation loss: 2.100405732790629

Epoch: 5| Step: 1
Training loss: 0.6016457676887512
Validation loss: 2.1040879487991333

Epoch: 5| Step: 2
Training loss: 0.5757855176925659
Validation loss: 2.1304929554462433

Epoch: 5| Step: 3
Training loss: 0.8165037035942078
Validation loss: 2.076041892170906

Epoch: 5| Step: 4
Training loss: 0.5643473863601685
Validation loss: 2.105106999476751

Epoch: 5| Step: 5
Training loss: 0.6474238634109497
Validation loss: 2.0459970434506736

Epoch: 5| Step: 6
Training loss: 0.6906312704086304
Validation loss: 2.0554195741812387

Epoch: 5| Step: 7
Training loss: 0.6613785028457642
Validation loss: 2.0317247609297433

Epoch: 5| Step: 8
Training loss: 0.6515384912490845
Validation loss: 2.0791819194952645

Epoch: 5| Step: 9
Training loss: 0.7517338991165161
Validation loss: 1.991078515847524

Epoch: 5| Step: 10
Training loss: 0.3932919502258301
Validation loss: 2.0598497837781906

Epoch: 5| Step: 11
Training loss: 0.4609786868095398
Validation loss: 2.0397632271051407

Epoch: 198| Step: 0
Training loss: 0.7547882795333862
Validation loss: 2.1062021404504776

Epoch: 5| Step: 1
Training loss: 0.629562258720398
Validation loss: 2.085342397292455

Epoch: 5| Step: 2
Training loss: 0.5080874562263489
Validation loss: 2.101959243416786

Epoch: 5| Step: 3
Training loss: 0.3164578974246979
Validation loss: 2.115072021881739

Epoch: 5| Step: 4
Training loss: 0.7393690347671509
Validation loss: 2.004777659972509

Epoch: 5| Step: 5
Training loss: 0.5050631165504456
Validation loss: 2.0201573173205056

Epoch: 5| Step: 6
Training loss: 0.559036374092102
Validation loss: 2.0900792678197226

Epoch: 5| Step: 7
Training loss: 0.7270122766494751
Validation loss: 2.0850611527760825

Epoch: 5| Step: 8
Training loss: 0.8871439695358276
Validation loss: 2.0547036776940026

Epoch: 5| Step: 9
Training loss: 0.4804900288581848
Validation loss: 2.123404487967491

Epoch: 5| Step: 10
Training loss: 0.674454927444458
Validation loss: 2.0456630488236747

Epoch: 5| Step: 11
Training loss: 0.30145007371902466
Validation loss: 2.050074279308319

Epoch: 199| Step: 0
Training loss: 0.6670759916305542
Validation loss: 2.0491919120152793

Epoch: 5| Step: 1
Training loss: 0.6134694814682007
Validation loss: 2.086681698759397

Epoch: 5| Step: 2
Training loss: 0.48776692152023315
Validation loss: 2.0697375535964966

Epoch: 5| Step: 3
Training loss: 0.3596709668636322
Validation loss: 2.0687619050343833

Epoch: 5| Step: 4
Training loss: 0.5612546801567078
Validation loss: 2.0835800915956497

Epoch: 5| Step: 5
Training loss: 0.40927356481552124
Validation loss: 2.0969205449024835

Epoch: 5| Step: 6
Training loss: 0.6963717341423035
Validation loss: 2.1097988188266754

Epoch: 5| Step: 7
Training loss: 0.6953707933425903
Validation loss: 2.096512203415235

Epoch: 5| Step: 8
Training loss: 0.858348548412323
Validation loss: 2.0627683202425637

Epoch: 5| Step: 9
Training loss: 0.6587485074996948
Validation loss: 2.1408983369668326

Epoch: 5| Step: 10
Training loss: 0.7920228838920593
Validation loss: 2.0662235071261725

Epoch: 5| Step: 11
Training loss: 0.25953954458236694
Validation loss: 2.0807011276483536

Epoch: 200| Step: 0
Training loss: 0.6463532447814941
Validation loss: 2.086429258187612

Epoch: 5| Step: 1
Training loss: 0.4709596633911133
Validation loss: 2.051957388718923

Epoch: 5| Step: 2
Training loss: 0.7068773508071899
Validation loss: 2.1193766593933105

Epoch: 5| Step: 3
Training loss: 0.6246820092201233
Validation loss: 2.0841447561979294

Epoch: 5| Step: 4
Training loss: 1.2664425373077393
Validation loss: 2.0516615211963654

Epoch: 5| Step: 5
Training loss: 0.6992825269699097
Validation loss: 2.0027042627334595

Epoch: 5| Step: 6
Training loss: 0.40111374855041504
Validation loss: 2.0298135528961816

Epoch: 5| Step: 7
Training loss: 0.5438040494918823
Validation loss: 2.0825198839108148

Epoch: 5| Step: 8
Training loss: 0.7703388929367065
Validation loss: 2.070956508318583

Epoch: 5| Step: 9
Training loss: 0.6644342541694641
Validation loss: 2.097928528984388

Epoch: 5| Step: 10
Training loss: 0.3829036355018616
Validation loss: 2.0947825461626053

Epoch: 5| Step: 11
Training loss: 0.340762197971344
Validation loss: 2.171286811431249

Epoch: 201| Step: 0
Training loss: 0.6841439604759216
Validation loss: 2.10564058025678

Epoch: 5| Step: 1
Training loss: 0.3692988455295563
Validation loss: 2.1268100887537003

Epoch: 5| Step: 2
Training loss: 0.4377337098121643
Validation loss: 2.0293546666701636

Epoch: 5| Step: 3
Training loss: 1.0676262378692627
Validation loss: 2.0972830951213837

Epoch: 5| Step: 4
Training loss: 0.38777217268943787
Validation loss: 2.087983970840772

Epoch: 5| Step: 5
Training loss: 0.8917688131332397
Validation loss: 2.108051081498464

Epoch: 5| Step: 6
Training loss: 0.642636775970459
Validation loss: 2.0420783708492913

Epoch: 5| Step: 7
Training loss: 0.6857560873031616
Validation loss: 2.0814178685347238

Epoch: 5| Step: 8
Training loss: 0.6726610660552979
Validation loss: 2.090806653102239

Epoch: 5| Step: 9
Training loss: 0.46204057335853577
Validation loss: 2.097169021765391

Epoch: 5| Step: 10
Training loss: 0.4934651255607605
Validation loss: 2.0750097235043845

Epoch: 5| Step: 11
Training loss: 0.8318588137626648
Validation loss: 2.0496956408023834

Epoch: 202| Step: 0
Training loss: 0.4116378426551819
Validation loss: 2.075301324327787

Epoch: 5| Step: 1
Training loss: 0.29696202278137207
Validation loss: 2.0977930476268134

Epoch: 5| Step: 2
Training loss: 0.6288195848464966
Validation loss: 2.0754575530687966

Epoch: 5| Step: 3
Training loss: 1.1078320741653442
Validation loss: 2.06300742427508

Epoch: 5| Step: 4
Training loss: 0.6870143413543701
Validation loss: 2.0717333555221558

Epoch: 5| Step: 5
Training loss: 0.4804895520210266
Validation loss: 2.0883134404818215

Epoch: 5| Step: 6
Training loss: 0.7140070199966431
Validation loss: 2.0738110889991126

Epoch: 5| Step: 7
Training loss: 0.6033555865287781
Validation loss: 2.1396431028842926

Epoch: 5| Step: 8
Training loss: 0.5507289171218872
Validation loss: 2.1453183392683663

Epoch: 5| Step: 9
Training loss: 0.5490779876708984
Validation loss: 2.1458015739917755

Epoch: 5| Step: 10
Training loss: 0.7765956521034241
Validation loss: 2.1281638195117316

Epoch: 5| Step: 11
Training loss: 0.2723231315612793
Validation loss: 2.1182084381580353

Epoch: 203| Step: 0
Training loss: 0.8402959108352661
Validation loss: 2.064194823304812

Epoch: 5| Step: 1
Training loss: 0.699097216129303
Validation loss: 1.9888556798299153

Epoch: 5| Step: 2
Training loss: 0.5049492716789246
Validation loss: 2.0836078474919

Epoch: 5| Step: 3
Training loss: 0.9106343388557434
Validation loss: 2.054212053616842

Epoch: 5| Step: 4
Training loss: 1.0718796253204346
Validation loss: 2.083764930566152

Epoch: 5| Step: 5
Training loss: 0.3161805272102356
Validation loss: 2.0750614255666733

Epoch: 5| Step: 6
Training loss: 0.4271833896636963
Validation loss: 2.054743821422259

Epoch: 5| Step: 7
Training loss: 0.5171535611152649
Validation loss: 2.0770395696163177

Epoch: 5| Step: 8
Training loss: 0.6674340963363647
Validation loss: 2.121039872368177

Epoch: 5| Step: 9
Training loss: 0.7270029187202454
Validation loss: 2.1152333269516626

Epoch: 5| Step: 10
Training loss: 0.697844922542572
Validation loss: 2.11782443523407

Epoch: 5| Step: 11
Training loss: 0.3219478130340576
Validation loss: 2.0647521018981934

Epoch: 204| Step: 0
Training loss: 0.3427885174751282
Validation loss: 2.1005783081054688

Epoch: 5| Step: 1
Training loss: 0.35891687870025635
Validation loss: 2.0614013324181237

Epoch: 5| Step: 2
Training loss: 0.5335642695426941
Validation loss: 2.0288854936758676

Epoch: 5| Step: 3
Training loss: 1.063534140586853
Validation loss: 2.068600277105967

Epoch: 5| Step: 4
Training loss: 0.6736049652099609
Validation loss: 2.0908819188674292

Epoch: 5| Step: 5
Training loss: 0.6604276895523071
Validation loss: 2.0752193927764893

Epoch: 5| Step: 6
Training loss: 0.5780139565467834
Validation loss: 2.071118747194608

Epoch: 5| Step: 7
Training loss: 0.6511414051055908
Validation loss: 2.1075266897678375

Epoch: 5| Step: 8
Training loss: 0.5602023005485535
Validation loss: 2.058704525232315

Epoch: 5| Step: 9
Training loss: 0.7935097813606262
Validation loss: 2.1350086530049643

Epoch: 5| Step: 10
Training loss: 0.8319019079208374
Validation loss: 2.1114595135053

Epoch: 5| Step: 11
Training loss: 0.7990504503250122
Validation loss: 2.1081374436616898

Epoch: 205| Step: 0
Training loss: 0.5953794717788696
Validation loss: 2.098147287964821

Epoch: 5| Step: 1
Training loss: 0.7983998656272888
Validation loss: 2.065583030382792

Epoch: 5| Step: 2
Training loss: 0.40374165773391724
Validation loss: 2.077187826236089

Epoch: 5| Step: 3
Training loss: 0.6447178721427917
Validation loss: 2.1108658760786057

Epoch: 5| Step: 4
Training loss: 0.5391449332237244
Validation loss: 2.089974914987882

Epoch: 5| Step: 5
Training loss: 1.0070337057113647
Validation loss: 2.0691769619782767

Epoch: 5| Step: 6
Training loss: 0.6199324727058411
Validation loss: 2.056892911593119

Epoch: 5| Step: 7
Training loss: 0.6001026034355164
Validation loss: 2.11004838347435

Epoch: 5| Step: 8
Training loss: 0.5824072957038879
Validation loss: 2.096484978993734

Epoch: 5| Step: 9
Training loss: 0.468637079000473
Validation loss: 2.1359814951817193

Epoch: 5| Step: 10
Training loss: 0.4202803671360016
Validation loss: 2.110985572139422

Epoch: 5| Step: 11
Training loss: 0.2196028232574463
Validation loss: 2.08536659181118

Epoch: 206| Step: 0
Training loss: 0.5404142141342163
Validation loss: 2.077132299542427

Epoch: 5| Step: 1
Training loss: 0.3725607693195343
Validation loss: 2.0935793767372766

Epoch: 5| Step: 2
Training loss: 0.6393145322799683
Validation loss: 2.0419216603040695

Epoch: 5| Step: 3
Training loss: 0.7205057144165039
Validation loss: 2.0689863512913385

Epoch: 5| Step: 4
Training loss: 0.49668940901756287
Validation loss: 2.063525895277659

Epoch: 5| Step: 5
Training loss: 0.6344683766365051
Validation loss: 2.080893953641256

Epoch: 5| Step: 6
Training loss: 0.4911251962184906
Validation loss: 2.0641859571139016

Epoch: 5| Step: 7
Training loss: 0.4008735120296478
Validation loss: 2.128439729412397

Epoch: 5| Step: 8
Training loss: 0.5720718502998352
Validation loss: 2.0431916813055673

Epoch: 5| Step: 9
Training loss: 0.3799211084842682
Validation loss: 2.0638821125030518

Epoch: 5| Step: 10
Training loss: 0.4014875292778015
Validation loss: 2.1102304408947625

Epoch: 5| Step: 11
Training loss: 1.5569473505020142
Validation loss: 2.0465765396753945

Epoch: 207| Step: 0
Training loss: 0.4141518473625183
Validation loss: 2.0788851281007132

Epoch: 5| Step: 1
Training loss: 0.7014710903167725
Validation loss: 2.0445026457309723

Epoch: 5| Step: 2
Training loss: 0.46107929944992065
Validation loss: 2.044733931620916

Epoch: 5| Step: 3
Training loss: 0.4882975220680237
Validation loss: 2.1120176961024604

Epoch: 5| Step: 4
Training loss: 0.5823909044265747
Validation loss: 2.0340956499179206

Epoch: 5| Step: 5
Training loss: 0.6923985481262207
Validation loss: 2.060536563396454

Epoch: 5| Step: 6
Training loss: 0.7104995846748352
Validation loss: 2.057731712857882

Epoch: 5| Step: 7
Training loss: 0.6861559152603149
Validation loss: 2.024245952566465

Epoch: 5| Step: 8
Training loss: 0.7148759961128235
Validation loss: 2.0752817541360855

Epoch: 5| Step: 9
Training loss: 0.5292189717292786
Validation loss: 2.05566098789374

Epoch: 5| Step: 10
Training loss: 0.6336245536804199
Validation loss: 2.0089642306168876

Epoch: 5| Step: 11
Training loss: 0.8739805817604065
Validation loss: 2.054129272699356

Epoch: 208| Step: 0
Training loss: 0.5747030377388
Validation loss: 2.05383238196373

Epoch: 5| Step: 1
Training loss: 0.5125433206558228
Validation loss: 2.0325860679149628

Epoch: 5| Step: 2
Training loss: 0.41066044569015503
Validation loss: 2.0450479835271835

Epoch: 5| Step: 3
Training loss: 0.5766648054122925
Validation loss: 2.0539508014917374

Epoch: 5| Step: 4
Training loss: 0.37271201610565186
Validation loss: 2.058105225364367

Epoch: 5| Step: 5
Training loss: 0.5461344718933105
Validation loss: 2.0529969185590744

Epoch: 5| Step: 6
Training loss: 0.5141818523406982
Validation loss: 2.0622585713863373

Epoch: 5| Step: 7
Training loss: 0.43518179655075073
Validation loss: 2.049410035212835

Epoch: 5| Step: 8
Training loss: 0.6630993485450745
Validation loss: 2.0849296202262244

Epoch: 5| Step: 9
Training loss: 0.9113944172859192
Validation loss: 2.024271175265312

Epoch: 5| Step: 10
Training loss: 0.608258068561554
Validation loss: 2.0972935358683267

Epoch: 5| Step: 11
Training loss: 0.9117087125778198
Validation loss: 2.0544411887725196

Epoch: 209| Step: 0
Training loss: 0.6535630226135254
Validation loss: 2.1107219556967416

Epoch: 5| Step: 1
Training loss: 0.5647305250167847
Validation loss: 2.102897569537163

Epoch: 5| Step: 2
Training loss: 0.5454824566841125
Validation loss: 2.015291919310888

Epoch: 5| Step: 3
Training loss: 0.7296612858772278
Validation loss: 2.0178805589675903

Epoch: 5| Step: 4
Training loss: 0.45298415422439575
Validation loss: 2.0859234432379403

Epoch: 5| Step: 5
Training loss: 0.558182418346405
Validation loss: 2.074269930521647

Epoch: 5| Step: 6
Training loss: 0.6101083159446716
Validation loss: 2.083118418852488

Epoch: 5| Step: 7
Training loss: 0.5368920564651489
Validation loss: 2.0595613022645316

Epoch: 5| Step: 8
Training loss: 0.45891228318214417
Validation loss: 2.032376065850258

Epoch: 5| Step: 9
Training loss: 0.780863344669342
Validation loss: 2.0328822980324426

Epoch: 5| Step: 10
Training loss: 0.38817936182022095
Validation loss: 2.0647563437620797

Epoch: 5| Step: 11
Training loss: 0.9386818408966064
Validation loss: 2.0438323070605597

Epoch: 210| Step: 0
Training loss: 0.5273643732070923
Validation loss: 2.0971892376740775

Epoch: 5| Step: 1
Training loss: 0.6140584945678711
Validation loss: 2.042899638414383

Epoch: 5| Step: 2
Training loss: 0.5474494695663452
Validation loss: 2.090117335319519

Epoch: 5| Step: 3
Training loss: 1.0238864421844482
Validation loss: 2.1208746830622354

Epoch: 5| Step: 4
Training loss: 0.6669043302536011
Validation loss: 2.095290939013163

Epoch: 5| Step: 5
Training loss: 0.34963473677635193
Validation loss: 2.0906875282526016

Epoch: 5| Step: 6
Training loss: 0.6753529906272888
Validation loss: 2.043047388394674

Epoch: 5| Step: 7
Training loss: 0.42517930269241333
Validation loss: 2.027824287613233

Epoch: 5| Step: 8
Training loss: 0.7344538569450378
Validation loss: 2.06587016582489

Epoch: 5| Step: 9
Training loss: 0.6359171271324158
Validation loss: 2.0263341466585794

Epoch: 5| Step: 10
Training loss: 0.5013085007667542
Validation loss: 2.077431857585907

Epoch: 5| Step: 11
Training loss: 0.5884703397750854
Validation loss: 2.057219311594963

Epoch: 211| Step: 0
Training loss: 0.4735748767852783
Validation loss: 2.056009978055954

Epoch: 5| Step: 1
Training loss: 0.43700918555259705
Validation loss: 2.0536821534236274

Epoch: 5| Step: 2
Training loss: 0.7421468496322632
Validation loss: 2.056395744283994

Epoch: 5| Step: 3
Training loss: 0.4613122344017029
Validation loss: 2.0700247983137765

Epoch: 5| Step: 4
Training loss: 0.3731069564819336
Validation loss: 2.100171372294426

Epoch: 5| Step: 5
Training loss: 0.6312757730484009
Validation loss: 2.105315253138542

Epoch: 5| Step: 6
Training loss: 0.8068292737007141
Validation loss: 2.0873523404200873

Epoch: 5| Step: 7
Training loss: 0.530163586139679
Validation loss: 2.065639778971672

Epoch: 5| Step: 8
Training loss: 0.48850736021995544
Validation loss: 2.078005621830622

Epoch: 5| Step: 9
Training loss: 0.35175180435180664
Validation loss: 2.110620508591334

Epoch: 5| Step: 10
Training loss: 0.5086236000061035
Validation loss: 2.0676198105017343

Epoch: 5| Step: 11
Training loss: 0.9283238053321838
Validation loss: 2.0685861508051553

Epoch: 212| Step: 0
Training loss: 0.9743949174880981
Validation loss: 2.0800291001796722

Epoch: 5| Step: 1
Training loss: 0.6580089330673218
Validation loss: 2.077669933438301

Epoch: 5| Step: 2
Training loss: 0.7014378309249878
Validation loss: 2.1160971174637475

Epoch: 5| Step: 3
Training loss: 0.3303181529045105
Validation loss: 2.048752471804619

Epoch: 5| Step: 4
Training loss: 0.45586833357810974
Validation loss: 2.0797321250041327

Epoch: 5| Step: 5
Training loss: 0.48962920904159546
Validation loss: 2.052506774663925

Epoch: 5| Step: 6
Training loss: 0.36520346999168396
Validation loss: 2.0596070488293967

Epoch: 5| Step: 7
Training loss: 0.358409583568573
Validation loss: 2.1079962054888406

Epoch: 5| Step: 8
Training loss: 0.7780594825744629
Validation loss: 2.0890015165011087

Epoch: 5| Step: 9
Training loss: 0.3217194676399231
Validation loss: 2.0754688580830893

Epoch: 5| Step: 10
Training loss: 0.5049387216567993
Validation loss: 2.042356883486112

Epoch: 5| Step: 11
Training loss: 0.19792109727859497
Validation loss: 2.0836614221334457

Epoch: 213| Step: 0
Training loss: 0.31265580654144287
Validation loss: 2.108513126770655

Epoch: 5| Step: 1
Training loss: 0.5503009557723999
Validation loss: 2.1027660071849823

Epoch: 5| Step: 2
Training loss: 0.4884810447692871
Validation loss: 2.074370861053467

Epoch: 5| Step: 3
Training loss: 0.298772931098938
Validation loss: 2.089822327097257

Epoch: 5| Step: 4
Training loss: 0.7938376665115356
Validation loss: 2.0840818087259927

Epoch: 5| Step: 5
Training loss: 1.0330922603607178
Validation loss: 2.0602674583594003

Epoch: 5| Step: 6
Training loss: 0.6564667820930481
Validation loss: 2.0670571674903235

Epoch: 5| Step: 7
Training loss: 0.4646390974521637
Validation loss: 2.104512110352516

Epoch: 5| Step: 8
Training loss: 0.5167378187179565
Validation loss: 2.075799196958542

Epoch: 5| Step: 9
Training loss: 0.46990767121315
Validation loss: 2.1212275276581445

Epoch: 5| Step: 10
Training loss: 0.960582435131073
Validation loss: 2.092243875066439

Epoch: 5| Step: 11
Training loss: 0.5475478172302246
Validation loss: 2.0487318535645804

Epoch: 214| Step: 0
Training loss: 0.56109219789505
Validation loss: 2.140762666861216

Epoch: 5| Step: 1
Training loss: 0.47556138038635254
Validation loss: 2.030511279900869

Epoch: 5| Step: 2
Training loss: 0.7991446256637573
Validation loss: 2.085830678542455

Epoch: 5| Step: 3
Training loss: 0.4546593725681305
Validation loss: 2.0403238584597907

Epoch: 5| Step: 4
Training loss: 0.6812257766723633
Validation loss: 2.0237570951382318

Epoch: 5| Step: 5
Training loss: 0.6526777148246765
Validation loss: 2.0552097260951996

Epoch: 5| Step: 6
Training loss: 0.6287508010864258
Validation loss: 2.0552622179190316

Epoch: 5| Step: 7
Training loss: 0.5516675710678101
Validation loss: 2.138417750597

Epoch: 5| Step: 8
Training loss: 0.3175353407859802
Validation loss: 2.02716234823068

Epoch: 5| Step: 9
Training loss: 0.475069522857666
Validation loss: 2.073657840490341

Epoch: 5| Step: 10
Training loss: 0.3240489661693573
Validation loss: 2.0699455589056015

Epoch: 5| Step: 11
Training loss: 1.4800753593444824
Validation loss: 2.0877005457878113

Epoch: 215| Step: 0
Training loss: 0.9538739919662476
Validation loss: 2.09206660091877

Epoch: 5| Step: 1
Training loss: 0.8029386401176453
Validation loss: 2.084469899535179

Epoch: 5| Step: 2
Training loss: 0.5580368638038635
Validation loss: 2.1097915718952813

Epoch: 5| Step: 3
Training loss: 0.5778204798698425
Validation loss: 2.0842533657948175

Epoch: 5| Step: 4
Training loss: 0.557883083820343
Validation loss: 2.009792298078537

Epoch: 5| Step: 5
Training loss: 0.40441927313804626
Validation loss: 2.0166645298401513

Epoch: 5| Step: 6
Training loss: 0.6767053604125977
Validation loss: 2.0480110396941504

Epoch: 5| Step: 7
Training loss: 0.39271801710128784
Validation loss: 2.052194764216741

Epoch: 5| Step: 8
Training loss: 0.5512548685073853
Validation loss: 2.0394952446222305

Epoch: 5| Step: 9
Training loss: 0.6563839316368103
Validation loss: 2.0269130716721215

Epoch: 5| Step: 10
Training loss: 0.43666061758995056
Validation loss: 2.0141358772913613

Epoch: 5| Step: 11
Training loss: 0.3201668858528137
Validation loss: 2.025414059559504

Epoch: 216| Step: 0
Training loss: 0.6369055509567261
Validation loss: 2.0968753695487976

Epoch: 5| Step: 1
Training loss: 0.5026977062225342
Validation loss: 2.0905146400133767

Epoch: 5| Step: 2
Training loss: 0.41965246200561523
Validation loss: 2.1004177580277124

Epoch: 5| Step: 3
Training loss: 0.7573758363723755
Validation loss: 2.059800202647845

Epoch: 5| Step: 4
Training loss: 0.5334455966949463
Validation loss: 2.079581762353579

Epoch: 5| Step: 5
Training loss: 0.4169398248195648
Validation loss: 2.073089048266411

Epoch: 5| Step: 6
Training loss: 0.6677392721176147
Validation loss: 2.039384807149569

Epoch: 5| Step: 7
Training loss: 0.2658303380012512
Validation loss: 1.9843095391988754

Epoch: 5| Step: 8
Training loss: 0.7366647720336914
Validation loss: 2.039578522245089

Epoch: 5| Step: 9
Training loss: 0.42715024948120117
Validation loss: 2.0703988571961722

Epoch: 5| Step: 10
Training loss: 0.6126073598861694
Validation loss: 2.050560474395752

Epoch: 5| Step: 11
Training loss: 0.706977367401123
Validation loss: 2.063044855991999

Epoch: 217| Step: 0
Training loss: 0.7501506209373474
Validation loss: 2.0695747435092926

Epoch: 5| Step: 1
Training loss: 0.7707977294921875
Validation loss: 2.1102585941553116

Epoch: 5| Step: 2
Training loss: 0.6156115531921387
Validation loss: 2.0209577729304633

Epoch: 5| Step: 3
Training loss: 0.835261344909668
Validation loss: 2.04634619752566

Epoch: 5| Step: 4
Training loss: 0.2938168942928314
Validation loss: 2.0768349915742874

Epoch: 5| Step: 5
Training loss: 0.3748738169670105
Validation loss: 2.051103954513868

Epoch: 5| Step: 6
Training loss: 0.5073075294494629
Validation loss: 2.082750419775645

Epoch: 5| Step: 7
Training loss: 0.515175998210907
Validation loss: 2.0696533024311066

Epoch: 5| Step: 8
Training loss: 0.3487699627876282
Validation loss: 2.021849498152733

Epoch: 5| Step: 9
Training loss: 0.3989664912223816
Validation loss: 2.093580722808838

Epoch: 5| Step: 10
Training loss: 0.4567764699459076
Validation loss: 2.0721649676561356

Epoch: 5| Step: 11
Training loss: 0.35581451654434204
Validation loss: 2.0679269333680472

Epoch: 218| Step: 0
Training loss: 0.6848862767219543
Validation loss: 2.114604393641154

Epoch: 5| Step: 1
Training loss: 0.4238895773887634
Validation loss: 2.063669666647911

Epoch: 5| Step: 2
Training loss: 0.4285673201084137
Validation loss: 2.096748247742653

Epoch: 5| Step: 3
Training loss: 0.556348443031311
Validation loss: 2.0099941194057465

Epoch: 5| Step: 4
Training loss: 0.7911160588264465
Validation loss: 2.074606254696846

Epoch: 5| Step: 5
Training loss: 0.40094050765037537
Validation loss: 2.0762507716814675

Epoch: 5| Step: 6
Training loss: 0.7045223116874695
Validation loss: 2.083343972762426

Epoch: 5| Step: 7
Training loss: 0.6874535083770752
Validation loss: 2.1156939764817557

Epoch: 5| Step: 8
Training loss: 0.5524917840957642
Validation loss: 2.0867722183465958

Epoch: 5| Step: 9
Training loss: 0.34992510080337524
Validation loss: 2.0924569070339203

Epoch: 5| Step: 10
Training loss: 0.3438504934310913
Validation loss: 2.0282420963048935

Epoch: 5| Step: 11
Training loss: 0.41038405895233154
Validation loss: 2.065073470274607

Epoch: 219| Step: 0
Training loss: 0.6217141151428223
Validation loss: 2.048732111851374

Epoch: 5| Step: 1
Training loss: 0.3247010111808777
Validation loss: 2.0290806343158088

Epoch: 5| Step: 2
Training loss: 0.5371764302253723
Validation loss: 2.0637121150890985

Epoch: 5| Step: 3
Training loss: 0.6560764908790588
Validation loss: 2.08647849659125

Epoch: 5| Step: 4
Training loss: 0.519029974937439
Validation loss: 2.066172793507576

Epoch: 5| Step: 5
Training loss: 0.5856110453605652
Validation loss: 2.055105914672216

Epoch: 5| Step: 6
Training loss: 0.5153865218162537
Validation loss: 2.1182193060715995

Epoch: 5| Step: 7
Training loss: 1.034751534461975
Validation loss: 2.0494511276483536

Epoch: 5| Step: 8
Training loss: 0.37204626202583313
Validation loss: 2.0280241866906485

Epoch: 5| Step: 9
Training loss: 0.27092546224594116
Validation loss: 2.0832735697428384

Epoch: 5| Step: 10
Training loss: 0.8976606130599976
Validation loss: 2.0205900768438974

Epoch: 5| Step: 11
Training loss: 0.18146497011184692
Validation loss: 2.0697833547989526

Epoch: 220| Step: 0
Training loss: 0.7158739566802979
Validation loss: 2.025400012731552

Epoch: 5| Step: 1
Training loss: 0.5386045575141907
Validation loss: 2.067736263076464

Epoch: 5| Step: 2
Training loss: 0.49845314025878906
Validation loss: 2.0399785389502845

Epoch: 5| Step: 3
Training loss: 0.8499869108200073
Validation loss: 2.1000187546014786

Epoch: 5| Step: 4
Training loss: 0.582872211933136
Validation loss: 2.0974621027708054

Epoch: 5| Step: 5
Training loss: 0.6793254613876343
Validation loss: 2.1647028823693595

Epoch: 5| Step: 6
Training loss: 0.45045551657676697
Validation loss: 2.1035856852928796

Epoch: 5| Step: 7
Training loss: 0.4467211365699768
Validation loss: 2.07282717525959

Epoch: 5| Step: 8
Training loss: 0.47782620787620544
Validation loss: 2.06582643588384

Epoch: 5| Step: 9
Training loss: 0.44626283645629883
Validation loss: 2.082548906405767

Epoch: 5| Step: 10
Training loss: 0.48308366537094116
Validation loss: 2.028333842754364

Epoch: 5| Step: 11
Training loss: 0.4353451728820801
Validation loss: 2.11074690024058

Epoch: 221| Step: 0
Training loss: 0.4670601487159729
Validation loss: 2.059317097067833

Epoch: 5| Step: 1
Training loss: 0.6091307401657104
Validation loss: 2.041090269883474

Epoch: 5| Step: 2
Training loss: 0.20777297019958496
Validation loss: 2.1045510371526084

Epoch: 5| Step: 3
Training loss: 0.4175630509853363
Validation loss: 2.0651044299205146

Epoch: 5| Step: 4
Training loss: 0.6256281137466431
Validation loss: 2.099278668562571

Epoch: 5| Step: 5
Training loss: 0.4931730329990387
Validation loss: 2.1078788538773856

Epoch: 5| Step: 6
Training loss: 0.41392678022384644
Validation loss: 2.077319582303365

Epoch: 5| Step: 7
Training loss: 0.7929210662841797
Validation loss: 2.0802919367949166

Epoch: 5| Step: 8
Training loss: 0.4491456151008606
Validation loss: 2.119655057787895

Epoch: 5| Step: 9
Training loss: 0.8241589665412903
Validation loss: 2.04286527633667

Epoch: 5| Step: 10
Training loss: 0.4879404902458191
Validation loss: 2.0334699104229608

Epoch: 5| Step: 11
Training loss: 0.5725936889648438
Validation loss: 2.0303984681765237

Epoch: 222| Step: 0
Training loss: 0.37961408495903015
Validation loss: 2.051526725292206

Epoch: 5| Step: 1
Training loss: 0.642889142036438
Validation loss: 2.0190305213133493

Epoch: 5| Step: 2
Training loss: 0.403663694858551
Validation loss: 2.045324385166168

Epoch: 5| Step: 3
Training loss: 0.7166239619255066
Validation loss: 2.092670356233915

Epoch: 5| Step: 4
Training loss: 0.45944517850875854
Validation loss: 2.0752887775500617

Epoch: 5| Step: 5
Training loss: 0.3095546364784241
Validation loss: 2.055726091066996

Epoch: 5| Step: 6
Training loss: 0.24972736835479736
Validation loss: 2.09226722518603

Epoch: 5| Step: 7
Training loss: 0.4407026171684265
Validation loss: 2.0544584343830743

Epoch: 5| Step: 8
Training loss: 0.4125833511352539
Validation loss: 2.082535137732824

Epoch: 5| Step: 9
Training loss: 1.4127953052520752
Validation loss: 2.087581366300583

Epoch: 5| Step: 10
Training loss: 0.4246835708618164
Validation loss: 2.116831600666046

Epoch: 5| Step: 11
Training loss: 0.18464922904968262
Validation loss: 2.0367937237024307

Epoch: 223| Step: 0
Training loss: 0.35616523027420044
Validation loss: 2.031305347879728

Epoch: 5| Step: 1
Training loss: 0.4797816276550293
Validation loss: 2.0347754806280136

Epoch: 5| Step: 2
Training loss: 0.29692211747169495
Validation loss: 2.0520229190587997

Epoch: 5| Step: 3
Training loss: 0.8165867924690247
Validation loss: 2.0467797766129174

Epoch: 5| Step: 4
Training loss: 0.7671419382095337
Validation loss: 2.0931408454974494

Epoch: 5| Step: 5
Training loss: 0.32851046323776245
Validation loss: 2.1123098929723105

Epoch: 5| Step: 6
Training loss: 0.46367812156677246
Validation loss: 2.0767395993073783

Epoch: 5| Step: 7
Training loss: 0.34152770042419434
Validation loss: 2.0374456395705542

Epoch: 5| Step: 8
Training loss: 0.35986751317977905
Validation loss: 2.065684253970782

Epoch: 5| Step: 9
Training loss: 0.748404860496521
Validation loss: 2.0641718159119287

Epoch: 5| Step: 10
Training loss: 0.8259850740432739
Validation loss: 2.0213533292214074

Epoch: 5| Step: 11
Training loss: 0.9509900808334351
Validation loss: 2.0193095107873282

Epoch: 224| Step: 0
Training loss: 0.5026532411575317
Validation loss: 2.0715627670288086

Epoch: 5| Step: 1
Training loss: 0.4813639521598816
Validation loss: 2.047863240043322

Epoch: 5| Step: 2
Training loss: 0.675827145576477
Validation loss: 2.0608938237031302

Epoch: 5| Step: 3
Training loss: 0.45019763708114624
Validation loss: 2.0929677287737527

Epoch: 5| Step: 4
Training loss: 0.3471946120262146
Validation loss: 2.046686420838038

Epoch: 5| Step: 5
Training loss: 0.5176886320114136
Validation loss: 2.077133739988009

Epoch: 5| Step: 6
Training loss: 0.34068790078163147
Validation loss: 2.0506138453880944

Epoch: 5| Step: 7
Training loss: 0.25393667817115784
Validation loss: 2.0161669800678887

Epoch: 5| Step: 8
Training loss: 0.7494150400161743
Validation loss: 2.040033996105194

Epoch: 5| Step: 9
Training loss: 0.6286771297454834
Validation loss: 2.041176681717237

Epoch: 5| Step: 10
Training loss: 0.7249383330345154
Validation loss: 2.0461679100990295

Epoch: 5| Step: 11
Training loss: 0.8136356472969055
Validation loss: 2.0743727137645087

Epoch: 225| Step: 0
Training loss: 0.6161488890647888
Validation loss: 2.094807356595993

Epoch: 5| Step: 1
Training loss: 0.3330548405647278
Validation loss: 2.102253566185633

Epoch: 5| Step: 2
Training loss: 0.30767548084259033
Validation loss: 2.120930870374044

Epoch: 5| Step: 3
Training loss: 0.8322755098342896
Validation loss: 2.096482664346695

Epoch: 5| Step: 4
Training loss: 0.40558290481567383
Validation loss: 2.0499898195266724

Epoch: 5| Step: 5
Training loss: 0.6447488069534302
Validation loss: 2.0508025189240775

Epoch: 5| Step: 6
Training loss: 0.5657838582992554
Validation loss: 2.0087154308954873

Epoch: 5| Step: 7
Training loss: 0.3570404052734375
Validation loss: 2.0971432477235794

Epoch: 5| Step: 8
Training loss: 0.3772205412387848
Validation loss: 2.0530879149834314

Epoch: 5| Step: 9
Training loss: 0.7333031892776489
Validation loss: 2.0336617529392242

Epoch: 5| Step: 10
Training loss: 0.38305339217185974
Validation loss: 2.053159346183141

Epoch: 5| Step: 11
Training loss: 0.2964521646499634
Validation loss: 2.032052348057429

Epoch: 226| Step: 0
Training loss: 0.2703818380832672
Validation loss: 2.030115375916163

Epoch: 5| Step: 1
Training loss: 0.5010771751403809
Validation loss: 2.0488522797822952

Epoch: 5| Step: 2
Training loss: 0.520918071269989
Validation loss: 2.0723997404177985

Epoch: 5| Step: 3
Training loss: 0.43435168266296387
Validation loss: 2.1474247723817825

Epoch: 5| Step: 4
Training loss: 0.4448428750038147
Validation loss: 1.9843611617883046

Epoch: 5| Step: 5
Training loss: 0.9373523592948914
Validation loss: 2.0154875069856644

Epoch: 5| Step: 6
Training loss: 0.5331206321716309
Validation loss: 2.0367039690415063

Epoch: 5| Step: 7
Training loss: 0.6740721464157104
Validation loss: 2.0171892096598945

Epoch: 5| Step: 8
Training loss: 0.39508044719696045
Validation loss: 2.0644322286049523

Epoch: 5| Step: 9
Training loss: 0.7169870138168335
Validation loss: 2.0136588315169015

Epoch: 5| Step: 10
Training loss: 0.22633464634418488
Validation loss: 2.067312707503637

Epoch: 5| Step: 11
Training loss: 1.0277807712554932
Validation loss: 2.0249470372994742

Epoch: 227| Step: 0
Training loss: 0.42375707626342773
Validation loss: 2.048499753077825

Epoch: 5| Step: 1
Training loss: 0.4640629291534424
Validation loss: 1.9858526388804119

Epoch: 5| Step: 2
Training loss: 0.3386349678039551
Validation loss: 2.0159734338521957

Epoch: 5| Step: 3
Training loss: 0.7368960976600647
Validation loss: 2.045562023917834

Epoch: 5| Step: 4
Training loss: 0.5565680265426636
Validation loss: 2.0571641623973846

Epoch: 5| Step: 5
Training loss: 0.4492953419685364
Validation loss: 2.010652109980583

Epoch: 5| Step: 6
Training loss: 0.2806985080242157
Validation loss: 2.052061453461647

Epoch: 5| Step: 7
Training loss: 0.29959994554519653
Validation loss: 1.9936813016732533

Epoch: 5| Step: 8
Training loss: 0.39135509729385376
Validation loss: 2.0285677909851074

Epoch: 5| Step: 9
Training loss: 0.9554673433303833
Validation loss: 2.038120379050573

Epoch: 5| Step: 10
Training loss: 0.7691497802734375
Validation loss: 2.0204998900492988

Epoch: 5| Step: 11
Training loss: 0.7423722147941589
Validation loss: 2.043101484576861

Epoch: 228| Step: 0
Training loss: 0.8542318344116211
Validation loss: 2.0759820640087128

Epoch: 5| Step: 1
Training loss: 0.3354474902153015
Validation loss: 2.0479410141706467

Epoch: 5| Step: 2
Training loss: 0.7252142429351807
Validation loss: 2.0370467603206635

Epoch: 5| Step: 3
Training loss: 0.5548373460769653
Validation loss: 2.0026718924442926

Epoch: 5| Step: 4
Training loss: 0.9101352691650391
Validation loss: 2.0145626167456308

Epoch: 5| Step: 5
Training loss: 0.786365807056427
Validation loss: 1.963792045911153

Epoch: 5| Step: 6
Training loss: 0.48259592056274414
Validation loss: 2.02071076631546

Epoch: 5| Step: 7
Training loss: 0.30124202370643616
Validation loss: 2.000370899836222

Epoch: 5| Step: 8
Training loss: 0.44514116644859314
Validation loss: 2.023397609591484

Epoch: 5| Step: 9
Training loss: 0.3557879328727722
Validation loss: 2.075105662147204

Epoch: 5| Step: 10
Training loss: 0.3157491683959961
Validation loss: 2.072600871324539

Epoch: 5| Step: 11
Training loss: 0.24890315532684326
Validation loss: 2.088281417886416

Epoch: 229| Step: 0
Training loss: 0.5435970425605774
Validation loss: 2.0799872676531472

Epoch: 5| Step: 1
Training loss: 0.6110702753067017
Validation loss: 2.051360165079435

Epoch: 5| Step: 2
Training loss: 0.6733428835868835
Validation loss: 2.007163638869921

Epoch: 5| Step: 3
Training loss: 0.7834237813949585
Validation loss: 2.064008206129074

Epoch: 5| Step: 4
Training loss: 0.5305595397949219
Validation loss: 2.0141531676054

Epoch: 5| Step: 5
Training loss: 0.4180656969547272
Validation loss: 2.085113048553467

Epoch: 5| Step: 6
Training loss: 0.5382393598556519
Validation loss: 2.0362098018328347

Epoch: 5| Step: 7
Training loss: 0.48311519622802734
Validation loss: 2.0220225205024085

Epoch: 5| Step: 8
Training loss: 0.49892082810401917
Validation loss: 2.0493229975303016

Epoch: 5| Step: 9
Training loss: 0.3985884189605713
Validation loss: 2.0595225592454276

Epoch: 5| Step: 10
Training loss: 0.48595064878463745
Validation loss: 2.05799201130867

Epoch: 5| Step: 11
Training loss: 0.2848761975765228
Validation loss: 2.056477338075638

Epoch: 230| Step: 0
Training loss: 0.5845200419425964
Validation loss: 2.0583456655343375

Epoch: 5| Step: 1
Training loss: 1.1724417209625244
Validation loss: 2.137496739625931

Epoch: 5| Step: 2
Training loss: 0.3869434893131256
Validation loss: 2.0793950855731964

Epoch: 5| Step: 3
Training loss: 0.4296797215938568
Validation loss: 2.036406929294268

Epoch: 5| Step: 4
Training loss: 0.6806674003601074
Validation loss: 2.049437994758288

Epoch: 5| Step: 5
Training loss: 0.24074585735797882
Validation loss: 2.016037195920944

Epoch: 5| Step: 6
Training loss: 0.37968406081199646
Validation loss: 2.054240107536316

Epoch: 5| Step: 7
Training loss: 0.4150788187980652
Validation loss: 2.020842363437017

Epoch: 5| Step: 8
Training loss: 0.5058158040046692
Validation loss: 2.069598838686943

Epoch: 5| Step: 9
Training loss: 0.3258295953273773
Validation loss: 2.0472092628479004

Epoch: 5| Step: 10
Training loss: 0.44080621004104614
Validation loss: 2.043215091029803

Epoch: 5| Step: 11
Training loss: 0.29739177227020264
Validation loss: 2.0514055689175925

Epoch: 231| Step: 0
Training loss: 0.4093194007873535
Validation loss: 2.062333141764005

Epoch: 5| Step: 1
Training loss: 0.5060585141181946
Validation loss: 2.0503563384215036

Epoch: 5| Step: 2
Training loss: 0.8323527574539185
Validation loss: 2.066054329276085

Epoch: 5| Step: 3
Training loss: 0.48585230112075806
Validation loss: 2.012155920267105

Epoch: 5| Step: 4
Training loss: 0.4451127052307129
Validation loss: 2.0785066932439804

Epoch: 5| Step: 5
Training loss: 0.33222275972366333
Validation loss: 2.040749510129293

Epoch: 5| Step: 6
Training loss: 0.4987640380859375
Validation loss: 2.084606116016706

Epoch: 5| Step: 7
Training loss: 0.48338785767555237
Validation loss: 2.0727575371662774

Epoch: 5| Step: 8
Training loss: 0.5571190118789673
Validation loss: 2.0817658603191376

Epoch: 5| Step: 9
Training loss: 0.3687227666378021
Validation loss: 2.092607706785202

Epoch: 5| Step: 10
Training loss: 0.7595685720443726
Validation loss: 2.0492510298887887

Epoch: 5| Step: 11
Training loss: 0.35744619369506836
Validation loss: 2.0400643845399222

Epoch: 232| Step: 0
Training loss: 0.22380749881267548
Validation loss: 2.1151334096988044

Epoch: 5| Step: 1
Training loss: 0.4092574715614319
Validation loss: 2.122771382331848

Epoch: 5| Step: 2
Training loss: 0.8350774645805359
Validation loss: 2.1061537762482962

Epoch: 5| Step: 3
Training loss: 0.6189144849777222
Validation loss: 2.095427686969439

Epoch: 5| Step: 4
Training loss: 0.47223711013793945
Validation loss: 2.1066428224245706

Epoch: 5| Step: 5
Training loss: 0.4306594729423523
Validation loss: 2.082314779361089

Epoch: 5| Step: 6
Training loss: 0.5785032510757446
Validation loss: 2.0628408640623093

Epoch: 5| Step: 7
Training loss: 0.7177940607070923
Validation loss: 2.0932554999987283

Epoch: 5| Step: 8
Training loss: 0.4519764482975006
Validation loss: 2.0889499386151633

Epoch: 5| Step: 9
Training loss: 0.31913697719573975
Validation loss: 2.0941138714551926

Epoch: 5| Step: 10
Training loss: 0.48636022210121155
Validation loss: 2.055066724618276

Epoch: 5| Step: 11
Training loss: 0.917173445224762
Validation loss: 2.0642536878585815

Epoch: 233| Step: 0
Training loss: 0.42313989996910095
Validation loss: 2.127973640958468

Epoch: 5| Step: 1
Training loss: 0.6163811683654785
Validation loss: 2.132473980387052

Epoch: 5| Step: 2
Training loss: 0.9626449346542358
Validation loss: 2.1708956758181253

Epoch: 5| Step: 3
Training loss: 0.2961714267730713
Validation loss: 2.134056106209755

Epoch: 5| Step: 4
Training loss: 0.37321895360946655
Validation loss: 2.086563761035601

Epoch: 5| Step: 5
Training loss: 0.4805048108100891
Validation loss: 2.08500470717748

Epoch: 5| Step: 6
Training loss: 0.42458677291870117
Validation loss: 2.029728968938192

Epoch: 5| Step: 7
Training loss: 0.5520274639129639
Validation loss: 2.047458291053772

Epoch: 5| Step: 8
Training loss: 0.47865086793899536
Validation loss: 2.054333964983622

Epoch: 5| Step: 9
Training loss: 0.7826725244522095
Validation loss: 2.073140576481819

Epoch: 5| Step: 10
Training loss: 0.5560077428817749
Validation loss: 2.0888279527425766

Epoch: 5| Step: 11
Training loss: 0.34780585765838623
Validation loss: 2.0889850010474524

Epoch: 234| Step: 0
Training loss: 0.4496106207370758
Validation loss: 2.0245867172876992

Epoch: 5| Step: 1
Training loss: 0.40564122796058655
Validation loss: 2.0696115692456565

Epoch: 5| Step: 2
Training loss: 0.49220210313796997
Validation loss: 2.1106704473495483

Epoch: 5| Step: 3
Training loss: 0.3152356743812561
Validation loss: 2.061154385407766

Epoch: 5| Step: 4
Training loss: 0.4669886529445648
Validation loss: 2.011036371191343

Epoch: 5| Step: 5
Training loss: 0.645851731300354
Validation loss: 2.0723522106806436

Epoch: 5| Step: 6
Training loss: 0.6345210075378418
Validation loss: 2.007829487323761

Epoch: 5| Step: 7
Training loss: 0.6567983031272888
Validation loss: 2.068960646788279

Epoch: 5| Step: 8
Training loss: 0.5421870946884155
Validation loss: 2.057973633209864

Epoch: 5| Step: 9
Training loss: 0.5633516311645508
Validation loss: 2.046591733892759

Epoch: 5| Step: 10
Training loss: 0.5328764915466309
Validation loss: 2.0472245464722314

Epoch: 5| Step: 11
Training loss: 0.35215580463409424
Validation loss: 2.0710979402065277

Epoch: 235| Step: 0
Training loss: 0.6610032916069031
Validation loss: 2.0785813281933465

Epoch: 5| Step: 1
Training loss: 0.30194610357284546
Validation loss: 2.0773112575213113

Epoch: 5| Step: 2
Training loss: 0.5587858557701111
Validation loss: 2.0899498462677

Epoch: 5| Step: 3
Training loss: 0.7102615833282471
Validation loss: 2.0933764427900314

Epoch: 5| Step: 4
Training loss: 0.7095426917076111
Validation loss: 2.0612297505140305

Epoch: 5| Step: 5
Training loss: 0.6054731607437134
Validation loss: 2.0741610576709113

Epoch: 5| Step: 6
Training loss: 0.29764583706855774
Validation loss: 2.0281268507242203

Epoch: 5| Step: 7
Training loss: 0.6363170742988586
Validation loss: 2.039998675386111

Epoch: 5| Step: 8
Training loss: 0.29746049642562866
Validation loss: 2.1266201933224997

Epoch: 5| Step: 9
Training loss: 0.3353537917137146
Validation loss: 2.0546815544366837

Epoch: 5| Step: 10
Training loss: 0.45718055963516235
Validation loss: 2.0661694606145224

Epoch: 5| Step: 11
Training loss: 0.28433382511138916
Validation loss: 2.081550727287928

Epoch: 236| Step: 0
Training loss: 0.29173344373703003
Validation loss: 2.0682791670163474

Epoch: 5| Step: 1
Training loss: 0.2856315076351166
Validation loss: 2.0689344505469003

Epoch: 5| Step: 2
Training loss: 0.2520386576652527
Validation loss: 2.117557575305303

Epoch: 5| Step: 3
Training loss: 0.47039586305618286
Validation loss: 2.0661867608626685

Epoch: 5| Step: 4
Training loss: 0.3865543603897095
Validation loss: 2.006019855539004

Epoch: 5| Step: 5
Training loss: 0.8896852731704712
Validation loss: 2.007105549176534

Epoch: 5| Step: 6
Training loss: 0.17672035098075867
Validation loss: 2.052860304713249

Epoch: 5| Step: 7
Training loss: 0.6127564311027527
Validation loss: 2.026052509744962

Epoch: 5| Step: 8
Training loss: 0.3342059850692749
Validation loss: 2.069685990611712

Epoch: 5| Step: 9
Training loss: 0.8711608648300171
Validation loss: 2.010521257917086

Epoch: 5| Step: 10
Training loss: 0.4697600305080414
Validation loss: 2.0662302474180856

Epoch: 5| Step: 11
Training loss: 1.4055715799331665
Validation loss: 2.0469343662261963

Epoch: 237| Step: 0
Training loss: 0.5400232672691345
Validation loss: 2.0840811282396317

Epoch: 5| Step: 1
Training loss: 0.48003435134887695
Validation loss: 2.053931246201197

Epoch: 5| Step: 2
Training loss: 0.35577234625816345
Validation loss: 2.0619316597779593

Epoch: 5| Step: 3
Training loss: 0.5161095857620239
Validation loss: 2.0638108601172767

Epoch: 5| Step: 4
Training loss: 0.5521438717842102
Validation loss: 2.0749318401018777

Epoch: 5| Step: 5
Training loss: 0.5362744927406311
Validation loss: 2.064054658015569

Epoch: 5| Step: 6
Training loss: 0.37868887186050415
Validation loss: 2.072361578543981

Epoch: 5| Step: 7
Training loss: 0.6929944157600403
Validation loss: 2.1065506686766944

Epoch: 5| Step: 8
Training loss: 0.573357105255127
Validation loss: 2.061892886956533

Epoch: 5| Step: 9
Training loss: 0.7050182223320007
Validation loss: 2.0073710133632026

Epoch: 5| Step: 10
Training loss: 0.600480854511261
Validation loss: 2.0511495172977448

Epoch: 5| Step: 11
Training loss: 0.48831701278686523
Validation loss: 2.0379051516453424

Epoch: 238| Step: 0
Training loss: 0.5713011026382446
Validation loss: 2.0311984618504844

Epoch: 5| Step: 1
Training loss: 0.4114148020744324
Validation loss: 2.0215810537338257

Epoch: 5| Step: 2
Training loss: 0.29591506719589233
Validation loss: 2.109754835565885

Epoch: 5| Step: 3
Training loss: 0.4409516751766205
Validation loss: 2.0612563838561377

Epoch: 5| Step: 4
Training loss: 0.40647950768470764
Validation loss: 2.072538524866104

Epoch: 5| Step: 5
Training loss: 0.5015150308609009
Validation loss: 2.064172685146332

Epoch: 5| Step: 6
Training loss: 0.8238767385482788
Validation loss: 2.1024347841739655

Epoch: 5| Step: 7
Training loss: 0.4897530674934387
Validation loss: 2.0439973374207816

Epoch: 5| Step: 8
Training loss: 0.6290778517723083
Validation loss: 2.0840934763352075

Epoch: 5| Step: 9
Training loss: 0.3079835772514343
Validation loss: 2.037090783317884

Epoch: 5| Step: 10
Training loss: 0.7096127271652222
Validation loss: 2.0285927603642144

Epoch: 5| Step: 11
Training loss: 0.3532819151878357
Validation loss: 2.038745234409968

Epoch: 239| Step: 0
Training loss: 0.40225762128829956
Validation loss: 2.064471264680227

Epoch: 5| Step: 1
Training loss: 0.4657912254333496
Validation loss: 2.047505885362625

Epoch: 5| Step: 2
Training loss: 0.4455196261405945
Validation loss: 2.0729059278964996

Epoch: 5| Step: 3
Training loss: 0.6274939775466919
Validation loss: 2.078097234169642

Epoch: 5| Step: 4
Training loss: 0.40091753005981445
Validation loss: 2.135396440823873

Epoch: 5| Step: 5
Training loss: 0.452782541513443
Validation loss: 2.0975298086802163

Epoch: 5| Step: 6
Training loss: 0.5305798649787903
Validation loss: 2.098294203480085

Epoch: 5| Step: 7
Training loss: 0.34878382086753845
Validation loss: 2.084606091181437

Epoch: 5| Step: 8
Training loss: 0.7429725527763367
Validation loss: 2.0714505265156427

Epoch: 5| Step: 9
Training loss: 0.4952055513858795
Validation loss: 2.016888956228892

Epoch: 5| Step: 10
Training loss: 0.4674515724182129
Validation loss: 2.033149167895317

Epoch: 5| Step: 11
Training loss: 0.34879422187805176
Validation loss: 2.0088495314121246

Epoch: 240| Step: 0
Training loss: 0.23616094887256622
Validation loss: 2.115853319565455

Epoch: 5| Step: 1
Training loss: 0.21113674342632294
Validation loss: 2.052078197399775

Epoch: 5| Step: 2
Training loss: 0.7863771319389343
Validation loss: 2.069729725519816

Epoch: 5| Step: 3
Training loss: 0.4953010082244873
Validation loss: 2.1167754332224527

Epoch: 5| Step: 4
Training loss: 0.5405031442642212
Validation loss: 2.0692142297824225

Epoch: 5| Step: 5
Training loss: 0.38942885398864746
Validation loss: 2.128001575668653

Epoch: 5| Step: 6
Training loss: 0.5705620050430298
Validation loss: 2.073000952601433

Epoch: 5| Step: 7
Training loss: 0.33902984857559204
Validation loss: 2.035932977994283

Epoch: 5| Step: 8
Training loss: 0.8522283434867859
Validation loss: 2.0700092166662216

Epoch: 5| Step: 9
Training loss: 0.7214382290840149
Validation loss: 2.0777832021315894

Epoch: 5| Step: 10
Training loss: 0.5321483016014099
Validation loss: 2.0314101527134576

Epoch: 5| Step: 11
Training loss: 0.2846275866031647
Validation loss: 2.0604179898897805

Epoch: 241| Step: 0
Training loss: 0.4438267648220062
Validation loss: 2.0752935111522675

Epoch: 5| Step: 1
Training loss: 0.3845612406730652
Validation loss: 2.017380580306053

Epoch: 5| Step: 2
Training loss: 0.4214444160461426
Validation loss: 2.095185066262881

Epoch: 5| Step: 3
Training loss: 0.3580583333969116
Validation loss: 2.0736515671014786

Epoch: 5| Step: 4
Training loss: 0.5392282009124756
Validation loss: 2.109702001015345

Epoch: 5| Step: 5
Training loss: 0.4783613085746765
Validation loss: 2.0211558590332666

Epoch: 5| Step: 6
Training loss: 0.35663315653800964
Validation loss: 2.077380493283272

Epoch: 5| Step: 7
Training loss: 0.7746663689613342
Validation loss: 2.0232433130343757

Epoch: 5| Step: 8
Training loss: 0.5228374600410461
Validation loss: 2.0081075529257455

Epoch: 5| Step: 9
Training loss: 0.9098447561264038
Validation loss: 2.044507215420405

Epoch: 5| Step: 10
Training loss: 0.4046187400817871
Validation loss: 2.066943188508352

Epoch: 5| Step: 11
Training loss: 0.20793026685714722
Validation loss: 2.1073339531819024

Epoch: 242| Step: 0
Training loss: 0.39110398292541504
Validation loss: 2.0450541377067566

Epoch: 5| Step: 1
Training loss: 0.3381190001964569
Validation loss: 2.0700644304354987

Epoch: 5| Step: 2
Training loss: 0.5334452390670776
Validation loss: 2.038731351494789

Epoch: 5| Step: 3
Training loss: 0.31007447838783264
Validation loss: 2.053727130095164

Epoch: 5| Step: 4
Training loss: 0.5154048204421997
Validation loss: 2.0177548627058663

Epoch: 5| Step: 5
Training loss: 0.7965491414070129
Validation loss: 2.0183679362138114

Epoch: 5| Step: 6
Training loss: 0.6407796144485474
Validation loss: 2.047590454419454

Epoch: 5| Step: 7
Training loss: 0.444368839263916
Validation loss: 2.052852431933085

Epoch: 5| Step: 8
Training loss: 0.42739972472190857
Validation loss: 2.0355303486188254

Epoch: 5| Step: 9
Training loss: 0.4923582971096039
Validation loss: 2.0968512296676636

Epoch: 5| Step: 10
Training loss: 0.7520225644111633
Validation loss: 2.070159842570623

Epoch: 5| Step: 11
Training loss: 0.18118634819984436
Validation loss: 2.078010767698288

Epoch: 243| Step: 0
Training loss: 0.5740333795547485
Validation loss: 2.1117366353670755

Epoch: 5| Step: 1
Training loss: 0.7911871671676636
Validation loss: 2.122135897477468

Epoch: 5| Step: 2
Training loss: 0.5016118884086609
Validation loss: 2.083942865331968

Epoch: 5| Step: 3
Training loss: 0.33626654744148254
Validation loss: 2.089309205611547

Epoch: 5| Step: 4
Training loss: 0.5120379328727722
Validation loss: 2.0207778414090476

Epoch: 5| Step: 5
Training loss: 0.5496873259544373
Validation loss: 2.0901501973470054

Epoch: 5| Step: 6
Training loss: 0.4530883729457855
Validation loss: 2.038683369755745

Epoch: 5| Step: 7
Training loss: 0.5437668561935425
Validation loss: 2.068707451224327

Epoch: 5| Step: 8
Training loss: 0.3501773476600647
Validation loss: 2.045614942908287

Epoch: 5| Step: 9
Training loss: 0.5939143300056458
Validation loss: 2.017094850540161

Epoch: 5| Step: 10
Training loss: 0.4005022644996643
Validation loss: 2.051474745074908

Epoch: 5| Step: 11
Training loss: 0.9384914636611938
Validation loss: 2.140313799182574

Epoch: 244| Step: 0
Training loss: 0.6738591194152832
Validation loss: 2.1167665968338647

Epoch: 5| Step: 1
Training loss: 0.392426073551178
Validation loss: 2.1103243927160897

Epoch: 5| Step: 2
Training loss: 0.3006642758846283
Validation loss: 2.07833631336689

Epoch: 5| Step: 3
Training loss: 0.48189297318458557
Validation loss: 2.061914915839831

Epoch: 5| Step: 4
Training loss: 0.6611626744270325
Validation loss: 2.0190427203973136

Epoch: 5| Step: 5
Training loss: 0.5212649703025818
Validation loss: 2.076729709903399

Epoch: 5| Step: 6
Training loss: 0.2161068171262741
Validation loss: 2.053428590297699

Epoch: 5| Step: 7
Training loss: 0.4380297064781189
Validation loss: 2.0573067317406335

Epoch: 5| Step: 8
Training loss: 0.41920724511146545
Validation loss: 2.0465134332577386

Epoch: 5| Step: 9
Training loss: 0.3980861306190491
Validation loss: 2.086265737811724

Epoch: 5| Step: 10
Training loss: 0.7256582379341125
Validation loss: 2.0527020345131555

Epoch: 5| Step: 11
Training loss: 0.1785660982131958
Validation loss: 2.066506420572599

Epoch: 245| Step: 0
Training loss: 0.674190878868103
Validation loss: 2.0797512531280518

Epoch: 5| Step: 1
Training loss: 0.3986179828643799
Validation loss: 2.1140894989172616

Epoch: 5| Step: 2
Training loss: 0.8844226598739624
Validation loss: 2.1495987524588904

Epoch: 5| Step: 3
Training loss: 0.5259504318237305
Validation loss: 2.0941712160905204

Epoch: 5| Step: 4
Training loss: 0.2784348130226135
Validation loss: 2.0883516867955527

Epoch: 5| Step: 5
Training loss: 0.8694098591804504
Validation loss: 2.1249037037293115

Epoch: 5| Step: 6
Training loss: 0.5675679445266724
Validation loss: 2.0518041402101517

Epoch: 5| Step: 7
Training loss: 0.37918713688850403
Validation loss: 2.058415398001671

Epoch: 5| Step: 8
Training loss: 0.35722318291664124
Validation loss: 1.9922514806191127

Epoch: 5| Step: 9
Training loss: 0.36848974227905273
Validation loss: 2.0530755619208017

Epoch: 5| Step: 10
Training loss: 0.3392435610294342
Validation loss: 2.03635103503863

Epoch: 5| Step: 11
Training loss: 0.6314321756362915
Validation loss: 2.0033418585856757

Epoch: 246| Step: 0
Training loss: 0.5301607847213745
Validation loss: 2.0753453920284906

Epoch: 5| Step: 1
Training loss: 0.5124073624610901
Validation loss: 2.0318928758303323

Epoch: 5| Step: 2
Training loss: 0.7211151123046875
Validation loss: 2.0620231479406357

Epoch: 5| Step: 3
Training loss: 0.2812337279319763
Validation loss: 2.067446544766426

Epoch: 5| Step: 4
Training loss: 0.4155701696872711
Validation loss: 2.158488283554713

Epoch: 5| Step: 5
Training loss: 0.3473464548587799
Validation loss: 2.1057203809420266

Epoch: 5| Step: 6
Training loss: 0.5177735090255737
Validation loss: 2.1176881939172745

Epoch: 5| Step: 7
Training loss: 0.399629145860672
Validation loss: 2.125161831577619

Epoch: 5| Step: 8
Training loss: 0.646909773349762
Validation loss: 2.0769731253385544

Epoch: 5| Step: 9
Training loss: 0.37940478324890137
Validation loss: 2.0852043131987252

Epoch: 5| Step: 10
Training loss: 0.5669220089912415
Validation loss: 2.088903551300367

Epoch: 5| Step: 11
Training loss: 0.854634702205658
Validation loss: 2.094084680080414

Epoch: 247| Step: 0
Training loss: 0.3486941456794739
Validation loss: 2.0883753250042596

Epoch: 5| Step: 1
Training loss: 0.2925642132759094
Validation loss: 2.0811308523019156

Epoch: 5| Step: 2
Training loss: 0.40684542059898376
Validation loss: 2.059397200743357

Epoch: 5| Step: 3
Training loss: 0.6455826759338379
Validation loss: 2.128700445095698

Epoch: 5| Step: 4
Training loss: 0.21105878055095673
Validation loss: 2.0775769849618277

Epoch: 5| Step: 5
Training loss: 0.4671066403388977
Validation loss: 2.0809222708145776

Epoch: 5| Step: 6
Training loss: 0.9327306747436523
Validation loss: 2.058404584725698

Epoch: 5| Step: 7
Training loss: 0.3905305862426758
Validation loss: 2.068437417348226

Epoch: 5| Step: 8
Training loss: 0.3016257882118225
Validation loss: 2.082584857940674

Epoch: 5| Step: 9
Training loss: 0.5438721179962158
Validation loss: 2.1105827192465463

Epoch: 5| Step: 10
Training loss: 0.41509056091308594
Validation loss: 2.109691013892492

Epoch: 5| Step: 11
Training loss: 0.27309322357177734
Validation loss: 2.0899632573127747

Epoch: 248| Step: 0
Training loss: 0.4454660415649414
Validation loss: 2.1106050113836923

Epoch: 5| Step: 1
Training loss: 0.5729221105575562
Validation loss: 2.039030989011129

Epoch: 5| Step: 2
Training loss: 0.6491223573684692
Validation loss: 2.035114044944445

Epoch: 5| Step: 3
Training loss: 0.4495198726654053
Validation loss: 2.091133470336596

Epoch: 5| Step: 4
Training loss: 0.7476505041122437
Validation loss: 1.957407553990682

Epoch: 5| Step: 5
Training loss: 0.3932812213897705
Validation loss: 2.0873079001903534

Epoch: 5| Step: 6
Training loss: 0.539775550365448
Validation loss: 2.0466885219017663

Epoch: 5| Step: 7
Training loss: 0.3229702413082123
Validation loss: 2.0784041633208594

Epoch: 5| Step: 8
Training loss: 0.34841567277908325
Validation loss: 2.068385049700737

Epoch: 5| Step: 9
Training loss: 0.46873754262924194
Validation loss: 2.086750974257787

Epoch: 5| Step: 10
Training loss: 0.5907207727432251
Validation loss: 2.051190108060837

Epoch: 5| Step: 11
Training loss: 0.4323429465293884
Validation loss: 2.0193526446819305

Epoch: 249| Step: 0
Training loss: 0.5740734338760376
Validation loss: 2.0303493241469064

Epoch: 5| Step: 1
Training loss: 0.40237727761268616
Validation loss: 2.0622238516807556

Epoch: 5| Step: 2
Training loss: 0.6671808362007141
Validation loss: 2.032904158035914

Epoch: 5| Step: 3
Training loss: 0.5886906385421753
Validation loss: 2.0017884373664856

Epoch: 5| Step: 4
Training loss: 0.23148012161254883
Validation loss: 2.0348946700493493

Epoch: 5| Step: 5
Training loss: 0.2566433846950531
Validation loss: 2.072762504220009

Epoch: 5| Step: 6
Training loss: 0.6104518175125122
Validation loss: 2.115690549214681

Epoch: 5| Step: 7
Training loss: 0.8852327466011047
Validation loss: 2.127207006017367

Epoch: 5| Step: 8
Training loss: 0.23852606117725372
Validation loss: 2.086303934454918

Epoch: 5| Step: 9
Training loss: 0.4207204282283783
Validation loss: 2.022221734126409

Epoch: 5| Step: 10
Training loss: 0.3472374677658081
Validation loss: 2.032150407632192

Epoch: 5| Step: 11
Training loss: 0.1330956220626831
Validation loss: 2.032192995150884

Epoch: 250| Step: 0
Training loss: 0.8626331090927124
Validation loss: 2.0666860938072205

Epoch: 5| Step: 1
Training loss: 0.26526403427124023
Validation loss: 2.0419920136531196

Epoch: 5| Step: 2
Training loss: 0.7095539569854736
Validation loss: 2.013324091831843

Epoch: 5| Step: 3
Training loss: 0.2758174538612366
Validation loss: 2.0467801839113235

Epoch: 5| Step: 4
Training loss: 0.3461151719093323
Validation loss: 2.031765878200531

Epoch: 5| Step: 5
Training loss: 0.4994215965270996
Validation loss: 2.027830640474955

Epoch: 5| Step: 6
Training loss: 0.28654640913009644
Validation loss: 2.0255067298809686

Epoch: 5| Step: 7
Training loss: 0.2304847687482834
Validation loss: 2.085045794645945

Epoch: 5| Step: 8
Training loss: 0.5781459808349609
Validation loss: 2.064874897400538

Epoch: 5| Step: 9
Training loss: 0.4773184657096863
Validation loss: 2.0560695131619773

Epoch: 5| Step: 10
Training loss: 0.4198593199253082
Validation loss: 2.0455277959505715

Epoch: 5| Step: 11
Training loss: 0.30982181429862976
Validation loss: 2.024738530317942

Epoch: 251| Step: 0
Training loss: 0.49390679597854614
Validation loss: 2.0446087966362634

Epoch: 5| Step: 1
Training loss: 0.672360360622406
Validation loss: 2.070062905550003

Epoch: 5| Step: 2
Training loss: 0.35321044921875
Validation loss: 2.057120909293493

Epoch: 5| Step: 3
Training loss: 0.9612932205200195
Validation loss: 2.116781085729599

Epoch: 5| Step: 4
Training loss: 0.36564236879348755
Validation loss: 2.0805358638366065

Epoch: 5| Step: 5
Training loss: 0.3185219466686249
Validation loss: 2.0773882518212

Epoch: 5| Step: 6
Training loss: 0.2782256007194519
Validation loss: 1.96526537835598

Epoch: 5| Step: 7
Training loss: 0.39373117685317993
Validation loss: 2.0232837001482644

Epoch: 5| Step: 8
Training loss: 0.5549457669258118
Validation loss: 2.046804810563723

Epoch: 5| Step: 9
Training loss: 0.4936765730381012
Validation loss: 2.0313820242881775

Epoch: 5| Step: 10
Training loss: 0.2064536064863205
Validation loss: 2.021517584721247

Epoch: 5| Step: 11
Training loss: 0.21697044372558594
Validation loss: 2.057964021960894

Epoch: 252| Step: 0
Training loss: 0.46980613470077515
Validation loss: 2.1079925100008645

Epoch: 5| Step: 1
Training loss: 0.3638366758823395
Validation loss: 2.093327964345614

Epoch: 5| Step: 2
Training loss: 0.5783469676971436
Validation loss: 2.097080538670222

Epoch: 5| Step: 3
Training loss: 0.3956962525844574
Validation loss: 2.055096377929052

Epoch: 5| Step: 4
Training loss: 0.5628292560577393
Validation loss: 2.1067132502794266

Epoch: 5| Step: 5
Training loss: 0.5678249001502991
Validation loss: 2.0717698683341346

Epoch: 5| Step: 6
Training loss: 0.6342756152153015
Validation loss: 2.1166470795869827

Epoch: 5| Step: 7
Training loss: 0.3026125431060791
Validation loss: 2.0399126360813775

Epoch: 5| Step: 8
Training loss: 0.33179807662963867
Validation loss: 2.1261407484610877

Epoch: 5| Step: 9
Training loss: 0.4182586073875427
Validation loss: 2.0692941149075827

Epoch: 5| Step: 10
Training loss: 0.43068259954452515
Validation loss: 2.0567704141139984

Epoch: 5| Step: 11
Training loss: 0.6297737956047058
Validation loss: 2.06490466495355

Epoch: 253| Step: 0
Training loss: 0.522208571434021
Validation loss: 2.0894001672665277

Epoch: 5| Step: 1
Training loss: 0.4465871751308441
Validation loss: 2.089904561638832

Epoch: 5| Step: 2
Training loss: 0.707223117351532
Validation loss: 2.0985937168200812

Epoch: 5| Step: 3
Training loss: 0.5866395831108093
Validation loss: 2.0888398985068

Epoch: 5| Step: 4
Training loss: 0.4047481119632721
Validation loss: 2.1119098216295242

Epoch: 5| Step: 5
Training loss: 0.5259898900985718
Validation loss: 2.121175100406011

Epoch: 5| Step: 6
Training loss: 0.4308289587497711
Validation loss: 2.1574475169181824

Epoch: 5| Step: 7
Training loss: 0.3252883553504944
Validation loss: 2.1589398731788

Epoch: 5| Step: 8
Training loss: 0.3225335478782654
Validation loss: 2.1302392333745956

Epoch: 5| Step: 9
Training loss: 0.5180031061172485
Validation loss: 2.0961034496625266

Epoch: 5| Step: 10
Training loss: 0.5367748737335205
Validation loss: 2.0528588791688285

Epoch: 5| Step: 11
Training loss: 0.3116738200187683
Validation loss: 2.0600375135739646

Epoch: 254| Step: 0
Training loss: 0.5880746245384216
Validation loss: 2.0772198736667633

Epoch: 5| Step: 1
Training loss: 0.6168082356452942
Validation loss: 2.065911074479421

Epoch: 5| Step: 2
Training loss: 0.9833459854125977
Validation loss: 2.036529997984568

Epoch: 5| Step: 3
Training loss: 0.7599267363548279
Validation loss: 2.0439723134040833

Epoch: 5| Step: 4
Training loss: 0.7219938635826111
Validation loss: 2.085427463054657

Epoch: 5| Step: 5
Training loss: 0.31633785367012024
Validation loss: 2.10604498287042

Epoch: 5| Step: 6
Training loss: 0.5451906323432922
Validation loss: 2.104201858242353

Epoch: 5| Step: 7
Training loss: 0.49888724088668823
Validation loss: 2.180820122361183

Epoch: 5| Step: 8
Training loss: 0.695318877696991
Validation loss: 2.1720350980758667

Epoch: 5| Step: 9
Training loss: 0.5194990634918213
Validation loss: 2.173273434241613

Epoch: 5| Step: 10
Training loss: 0.2800696790218353
Validation loss: 2.1063129802544913

Epoch: 5| Step: 11
Training loss: 0.5993564128875732
Validation loss: 2.0965988785028458

Epoch: 255| Step: 0
Training loss: 0.625970721244812
Validation loss: 2.0822681337594986

Epoch: 5| Step: 1
Training loss: 0.4131702482700348
Validation loss: 2.0830005407333374

Epoch: 5| Step: 2
Training loss: 0.3533666431903839
Validation loss: 2.019728367527326

Epoch: 5| Step: 3
Training loss: 0.5674734115600586
Validation loss: 2.031931310892105

Epoch: 5| Step: 4
Training loss: 0.46120309829711914
Validation loss: 2.05877977112929

Epoch: 5| Step: 5
Training loss: 0.23602800071239471
Validation loss: 2.0595235923926034

Epoch: 5| Step: 6
Training loss: 0.27607354521751404
Validation loss: 2.1025077203909555

Epoch: 5| Step: 7
Training loss: 0.6588127017021179
Validation loss: 2.0747671127319336

Epoch: 5| Step: 8
Training loss: 0.6332694292068481
Validation loss: 2.092779661218325

Epoch: 5| Step: 9
Training loss: 0.6548608541488647
Validation loss: 2.1266370664040246

Epoch: 5| Step: 10
Training loss: 0.3409944176673889
Validation loss: 2.0565288712581

Epoch: 5| Step: 11
Training loss: 0.13635742664337158
Validation loss: 2.0680983712275824

Epoch: 256| Step: 0
Training loss: 0.5368086099624634
Validation loss: 2.0368529508511224

Epoch: 5| Step: 1
Training loss: 0.9055641293525696
Validation loss: 2.0635571579138436

Epoch: 5| Step: 2
Training loss: 0.37300509214401245
Validation loss: 2.03951666255792

Epoch: 5| Step: 3
Training loss: 0.7644671201705933
Validation loss: 2.00463505089283

Epoch: 5| Step: 4
Training loss: 0.6029095649719238
Validation loss: 2.0557153771320977

Epoch: 5| Step: 5
Training loss: 0.6754192113876343
Validation loss: 2.0325187842051187

Epoch: 5| Step: 6
Training loss: 0.2496461123228073
Validation loss: 2.0898010234038034

Epoch: 5| Step: 7
Training loss: 0.3436059057712555
Validation loss: 2.072847828269005

Epoch: 5| Step: 8
Training loss: 0.4710434377193451
Validation loss: 2.0614327689011893

Epoch: 5| Step: 9
Training loss: 0.4331516623497009
Validation loss: 2.0634569277366004

Epoch: 5| Step: 10
Training loss: 0.511853039264679
Validation loss: 2.0435102581977844

Epoch: 5| Step: 11
Training loss: 0.3646427392959595
Validation loss: 2.0581448723872504

Epoch: 257| Step: 0
Training loss: 0.33063337206840515
Validation loss: 2.0372650573650994

Epoch: 5| Step: 1
Training loss: 0.5981521606445312
Validation loss: 2.038354605436325

Epoch: 5| Step: 2
Training loss: 0.7986932992935181
Validation loss: 2.0289566765228906

Epoch: 5| Step: 3
Training loss: 0.562747597694397
Validation loss: 2.023916964729627

Epoch: 5| Step: 4
Training loss: 0.8980436325073242
Validation loss: 2.0004149228334427

Epoch: 5| Step: 5
Training loss: 0.5292744040489197
Validation loss: 2.0421990354855857

Epoch: 5| Step: 6
Training loss: 0.2112017124891281
Validation loss: 2.0798288186391196

Epoch: 5| Step: 7
Training loss: 0.5762983560562134
Validation loss: 2.106398284435272

Epoch: 5| Step: 8
Training loss: 0.5601384043693542
Validation loss: 2.101734528938929

Epoch: 5| Step: 9
Training loss: 0.7838597297668457
Validation loss: 2.159565190474192

Epoch: 5| Step: 10
Training loss: 0.5859295725822449
Validation loss: 2.127430851260821

Epoch: 5| Step: 11
Training loss: 0.7226709127426147
Validation loss: 2.1197912146647773

Epoch: 258| Step: 0
Training loss: 0.5331379175186157
Validation loss: 2.052614708741506

Epoch: 5| Step: 1
Training loss: 0.437644898891449
Validation loss: 2.0637127508719764

Epoch: 5| Step: 2
Training loss: 0.5344606637954712
Validation loss: 2.0317601511875787

Epoch: 5| Step: 3
Training loss: 0.9139183163642883
Validation loss: 2.0132559637228646

Epoch: 5| Step: 4
Training loss: 0.47319260239601135
Validation loss: 2.047298709551493

Epoch: 5| Step: 5
Training loss: 0.43192505836486816
Validation loss: 2.0520670314629874

Epoch: 5| Step: 6
Training loss: 0.5551114678382874
Validation loss: 2.028503189484278

Epoch: 5| Step: 7
Training loss: 0.44589558243751526
Validation loss: 2.1173651417096457

Epoch: 5| Step: 8
Training loss: 0.508628249168396
Validation loss: 2.1485381722450256

Epoch: 5| Step: 9
Training loss: 0.7132101655006409
Validation loss: 2.1925026228030524

Epoch: 5| Step: 10
Training loss: 0.47255927324295044
Validation loss: 2.1029874086380005

Epoch: 5| Step: 11
Training loss: 0.4114513397216797
Validation loss: 2.1237195432186127

Epoch: 259| Step: 0
Training loss: 0.2929441034793854
Validation loss: 2.11724000175794

Epoch: 5| Step: 1
Training loss: 0.5542826652526855
Validation loss: 2.059744656085968

Epoch: 5| Step: 2
Training loss: 0.5812174081802368
Validation loss: 2.1049694071213403

Epoch: 5| Step: 3
Training loss: 0.513767421245575
Validation loss: 2.012587999304136

Epoch: 5| Step: 4
Training loss: 0.4601303040981293
Validation loss: 2.0129979103803635

Epoch: 5| Step: 5
Training loss: 0.6971520185470581
Validation loss: 1.9774804810682933

Epoch: 5| Step: 6
Training loss: 0.463828980922699
Validation loss: 2.0389618277549744

Epoch: 5| Step: 7
Training loss: 0.326253741979599
Validation loss: 2.064759840567907

Epoch: 5| Step: 8
Training loss: 0.564230740070343
Validation loss: 2.052274097998937

Epoch: 5| Step: 9
Training loss: 0.4636985659599304
Validation loss: 2.090401217341423

Epoch: 5| Step: 10
Training loss: 0.8929544687271118
Validation loss: 2.130524675051371

Epoch: 5| Step: 11
Training loss: 0.15843307971954346
Validation loss: 2.163305009404818

Epoch: 260| Step: 0
Training loss: 0.45643264055252075
Validation loss: 2.1114173283179603

Epoch: 5| Step: 1
Training loss: 0.5957804918289185
Validation loss: 2.1077347795168557

Epoch: 5| Step: 2
Training loss: 0.28339263796806335
Validation loss: 2.021381229162216

Epoch: 5| Step: 3
Training loss: 0.5662297010421753
Validation loss: 2.0746392756700516

Epoch: 5| Step: 4
Training loss: 0.34372827410697937
Validation loss: 2.0603956629832587

Epoch: 5| Step: 5
Training loss: 0.4812503755092621
Validation loss: 2.042622814575831

Epoch: 5| Step: 6
Training loss: 0.5170174837112427
Validation loss: 2.02118972937266

Epoch: 5| Step: 7
Training loss: 0.28307369351387024
Validation loss: 2.0180436025063195

Epoch: 5| Step: 8
Training loss: 0.31613919138908386
Validation loss: 1.986689825852712

Epoch: 5| Step: 9
Training loss: 0.35835370421409607
Validation loss: 2.060536632935206

Epoch: 5| Step: 10
Training loss: 0.9816276431083679
Validation loss: 2.0805572668711343

Epoch: 5| Step: 11
Training loss: 0.3890499472618103
Validation loss: 2.067966272433599

Epoch: 261| Step: 0
Training loss: 0.25061675906181335
Validation loss: 2.1086311439673104

Epoch: 5| Step: 1
Training loss: 0.6975712180137634
Validation loss: 2.070815602938334

Epoch: 5| Step: 2
Training loss: 0.4303918778896332
Validation loss: 2.1085850099722543

Epoch: 5| Step: 3
Training loss: 0.33885470032691956
Validation loss: 2.0883795668681464

Epoch: 5| Step: 4
Training loss: 0.5671020746231079
Validation loss: 2.0258234292268753

Epoch: 5| Step: 5
Training loss: 0.22443023324012756
Validation loss: 1.9761749009291332

Epoch: 5| Step: 6
Training loss: 0.5338186025619507
Validation loss: 2.0235252479712167

Epoch: 5| Step: 7
Training loss: 0.4049200117588043
Validation loss: 2.069767653942108

Epoch: 5| Step: 8
Training loss: 0.49528607726097107
Validation loss: 2.00185456375281

Epoch: 5| Step: 9
Training loss: 0.27093181014060974
Validation loss: 2.0177813470363617

Epoch: 5| Step: 10
Training loss: 0.8021184206008911
Validation loss: 2.031532804171244

Epoch: 5| Step: 11
Training loss: 0.2580873966217041
Validation loss: 2.076060563325882

Epoch: 262| Step: 0
Training loss: 0.5161172747612
Validation loss: 2.0936349481344223

Epoch: 5| Step: 1
Training loss: 0.2639019191265106
Validation loss: 2.0602804025014243

Epoch: 5| Step: 2
Training loss: 0.35500669479370117
Validation loss: 2.074393168091774

Epoch: 5| Step: 3
Training loss: 0.468311607837677
Validation loss: 2.0679396291573844

Epoch: 5| Step: 4
Training loss: 0.4763004183769226
Validation loss: 2.076737587650617

Epoch: 5| Step: 5
Training loss: 0.7965598106384277
Validation loss: 2.09786785642306

Epoch: 5| Step: 6
Training loss: 0.2869040071964264
Validation loss: 2.062524368365606

Epoch: 5| Step: 7
Training loss: 0.2463715374469757
Validation loss: 2.056912605961164

Epoch: 5| Step: 8
Training loss: 0.6307658553123474
Validation loss: 2.03250319759051

Epoch: 5| Step: 9
Training loss: 0.42077144980430603
Validation loss: 2.0176169524590173

Epoch: 5| Step: 10
Training loss: 0.581528902053833
Validation loss: 2.077824354171753

Epoch: 5| Step: 11
Training loss: 0.41481560468673706
Validation loss: 2.0563963850339255

Epoch: 263| Step: 0
Training loss: 0.42648378014564514
Validation loss: 2.076623315612475

Epoch: 5| Step: 1
Training loss: 0.6793892979621887
Validation loss: 2.0922466069459915

Epoch: 5| Step: 2
Training loss: 0.43993616104125977
Validation loss: 2.147226666410764

Epoch: 5| Step: 3
Training loss: 0.312438428401947
Validation loss: 2.084407245119413

Epoch: 5| Step: 4
Training loss: 0.7157109379768372
Validation loss: 2.1120872447888055

Epoch: 5| Step: 5
Training loss: 0.4098314344882965
Validation loss: 2.1488115986188254

Epoch: 5| Step: 6
Training loss: 0.5568219423294067
Validation loss: 2.0738778859376907

Epoch: 5| Step: 7
Training loss: 0.41616708040237427
Validation loss: 2.0916673640410104

Epoch: 5| Step: 8
Training loss: 0.27953654527664185
Validation loss: 2.0506147295236588

Epoch: 5| Step: 9
Training loss: 0.43491610884666443
Validation loss: 2.0411463528871536

Epoch: 5| Step: 10
Training loss: 0.542697548866272
Validation loss: 2.088939274350802

Epoch: 5| Step: 11
Training loss: 0.5451951026916504
Validation loss: 2.034900963306427

Epoch: 264| Step: 0
Training loss: 0.76804518699646
Validation loss: 2.077389190594355

Epoch: 5| Step: 1
Training loss: 0.4626635015010834
Validation loss: 2.042155305544535

Epoch: 5| Step: 2
Training loss: 0.3841516077518463
Validation loss: 2.01240444680055

Epoch: 5| Step: 3
Training loss: 0.6459804177284241
Validation loss: 2.0771801273028054

Epoch: 5| Step: 4
Training loss: 0.4081360399723053
Validation loss: 2.0748654206593833

Epoch: 5| Step: 5
Training loss: 0.5476552844047546
Validation loss: 2.089946707089742

Epoch: 5| Step: 6
Training loss: 0.43098658323287964
Validation loss: 2.0642481545607247

Epoch: 5| Step: 7
Training loss: 0.21494083106517792
Validation loss: 2.1005443036556244

Epoch: 5| Step: 8
Training loss: 0.3394322991371155
Validation loss: 2.0615356663862863

Epoch: 5| Step: 9
Training loss: 0.41794830560684204
Validation loss: 2.051975299914678

Epoch: 5| Step: 10
Training loss: 0.32014745473861694
Validation loss: 2.0394501040379205

Epoch: 5| Step: 11
Training loss: 0.2200741171836853
Validation loss: 1.9947495659192402

Epoch: 265| Step: 0
Training loss: 0.29846253991127014
Validation loss: 2.0430716425180435

Epoch: 5| Step: 1
Training loss: 0.5619395971298218
Validation loss: 2.0091239561637244

Epoch: 5| Step: 2
Training loss: 0.5027090907096863
Validation loss: 2.0370657990376153

Epoch: 5| Step: 3
Training loss: 0.27748769521713257
Validation loss: 2.0275497188170752

Epoch: 5| Step: 4
Training loss: 0.5129731297492981
Validation loss: 2.0693240811427436

Epoch: 5| Step: 5
Training loss: 0.377694308757782
Validation loss: 2.086466168363889

Epoch: 5| Step: 6
Training loss: 0.43307381868362427
Validation loss: 2.0777263144652047

Epoch: 5| Step: 7
Training loss: 0.455085426568985
Validation loss: 2.0566762586434684

Epoch: 5| Step: 8
Training loss: 0.4703274667263031
Validation loss: 2.0487841914097467

Epoch: 5| Step: 9
Training loss: 0.6796656847000122
Validation loss: 2.0674027601877847

Epoch: 5| Step: 10
Training loss: 0.296303927898407
Validation loss: 2.046248426040014

Epoch: 5| Step: 11
Training loss: 0.8832589387893677
Validation loss: 2.033564507961273

Epoch: 266| Step: 0
Training loss: 0.7649234533309937
Validation loss: 2.073762277762095

Epoch: 5| Step: 1
Training loss: 0.41339462995529175
Validation loss: 2.048955296476682

Epoch: 5| Step: 2
Training loss: 0.482382208108902
Validation loss: 2.053377350171407

Epoch: 5| Step: 3
Training loss: 0.3191351294517517
Validation loss: 2.116044501463572

Epoch: 5| Step: 4
Training loss: 0.5740886926651001
Validation loss: 2.1209744065999985

Epoch: 5| Step: 5
Training loss: 0.35739046335220337
Validation loss: 2.064221739768982

Epoch: 5| Step: 6
Training loss: 0.4683024287223816
Validation loss: 2.127606069048246

Epoch: 5| Step: 7
Training loss: 0.21435709297657013
Validation loss: 2.092700387040774

Epoch: 5| Step: 8
Training loss: 0.4479944705963135
Validation loss: 2.0849031110604606

Epoch: 5| Step: 9
Training loss: 0.5048812627792358
Validation loss: 2.009179636836052

Epoch: 5| Step: 10
Training loss: 0.5284839272499084
Validation loss: 2.0114183177550635

Epoch: 5| Step: 11
Training loss: 1.069448471069336
Validation loss: 2.027880549430847

Epoch: 267| Step: 0
Training loss: 0.5450601577758789
Validation loss: 2.021586924791336

Epoch: 5| Step: 1
Training loss: 0.605552077293396
Validation loss: 2.0335298627614975

Epoch: 5| Step: 2
Training loss: 0.4295688569545746
Validation loss: 2.120061914126078

Epoch: 5| Step: 3
Training loss: 0.317308247089386
Validation loss: 2.079890857140223

Epoch: 5| Step: 4
Training loss: 0.4280015826225281
Validation loss: 2.112755427757899

Epoch: 5| Step: 5
Training loss: 0.47949185967445374
Validation loss: 2.084266245365143

Epoch: 5| Step: 6
Training loss: 0.43598419427871704
Validation loss: 2.0851340194543204

Epoch: 5| Step: 7
Training loss: 0.37442547082901
Validation loss: 2.0777343412240348

Epoch: 5| Step: 8
Training loss: 0.49905842542648315
Validation loss: 2.0433786114056907

Epoch: 5| Step: 9
Training loss: 0.433879554271698
Validation loss: 2.070114880800247

Epoch: 5| Step: 10
Training loss: 0.699411153793335
Validation loss: 2.0405195355415344

Epoch: 5| Step: 11
Training loss: 0.3396221697330475
Validation loss: 2.10298715531826

Epoch: 268| Step: 0
Training loss: 0.34233951568603516
Validation loss: 2.042041594783465

Epoch: 5| Step: 1
Training loss: 0.3249439597129822
Validation loss: 2.070528596639633

Epoch: 5| Step: 2
Training loss: 0.7894718050956726
Validation loss: 2.0789627929528556

Epoch: 5| Step: 3
Training loss: 0.529072642326355
Validation loss: 2.0992535799741745

Epoch: 5| Step: 4
Training loss: 0.32771027088165283
Validation loss: 2.104195311665535

Epoch: 5| Step: 5
Training loss: 0.2967371344566345
Validation loss: 2.158624013264974

Epoch: 5| Step: 6
Training loss: 0.7837433815002441
Validation loss: 2.137082060178121

Epoch: 5| Step: 7
Training loss: 0.6201211214065552
Validation loss: 2.157186488310496

Epoch: 5| Step: 8
Training loss: 0.530119776725769
Validation loss: 2.139765207966169

Epoch: 5| Step: 9
Training loss: 0.3810705244541168
Validation loss: 2.091374625762304

Epoch: 5| Step: 10
Training loss: 0.3238799273967743
Validation loss: 2.0777981529633203

Epoch: 5| Step: 11
Training loss: 0.36885786056518555
Validation loss: 2.0775329023599625

Epoch: 269| Step: 0
Training loss: 0.3884900212287903
Validation loss: 2.010944207509359

Epoch: 5| Step: 1
Training loss: 0.6328688263893127
Validation loss: 2.0491163780291877

Epoch: 5| Step: 2
Training loss: 0.3131888210773468
Validation loss: 2.0061649829149246

Epoch: 5| Step: 3
Training loss: 0.4145805239677429
Validation loss: 2.0589150885740914

Epoch: 5| Step: 4
Training loss: 0.3001500368118286
Validation loss: 2.1136575589577355

Epoch: 5| Step: 5
Training loss: 0.9544656872749329
Validation loss: 2.122809559106827

Epoch: 5| Step: 6
Training loss: 0.5175015330314636
Validation loss: 2.1185918798049292

Epoch: 5| Step: 7
Training loss: 0.3223443627357483
Validation loss: 2.1800166219472885

Epoch: 5| Step: 8
Training loss: 0.5496187210083008
Validation loss: 2.1401755015055337

Epoch: 5| Step: 9
Training loss: 0.781507134437561
Validation loss: 2.1548241476217904

Epoch: 5| Step: 10
Training loss: 0.46510306000709534
Validation loss: 2.091105361779531

Epoch: 5| Step: 11
Training loss: 0.6671683192253113
Validation loss: 2.093403438727061

Epoch: 270| Step: 0
Training loss: 0.42608457803726196
Validation loss: 2.06561612089475

Epoch: 5| Step: 1
Training loss: 0.5335137248039246
Validation loss: 2.0776704301436744

Epoch: 5| Step: 2
Training loss: 0.3151873052120209
Validation loss: 2.0965566486120224

Epoch: 5| Step: 3
Training loss: 0.7380094528198242
Validation loss: 2.0822671751181283

Epoch: 5| Step: 4
Training loss: 0.4905378222465515
Validation loss: 2.0686455269654593

Epoch: 5| Step: 5
Training loss: 0.7080643177032471
Validation loss: 2.0611760516961417

Epoch: 5| Step: 6
Training loss: 0.4306276738643646
Validation loss: 2.0978074173132577

Epoch: 5| Step: 7
Training loss: 0.27675285935401917
Validation loss: 2.1046115507682166

Epoch: 5| Step: 8
Training loss: 0.2728896141052246
Validation loss: 2.103880599141121

Epoch: 5| Step: 9
Training loss: 0.3370249271392822
Validation loss: 2.087170993288358

Epoch: 5| Step: 10
Training loss: 0.5229897499084473
Validation loss: 2.0579101890325546

Epoch: 5| Step: 11
Training loss: 0.22196272015571594
Validation loss: 2.048887630303701

Epoch: 271| Step: 0
Training loss: 0.4283173978328705
Validation loss: 2.0281727562348046

Epoch: 5| Step: 1
Training loss: 0.41262340545654297
Validation loss: 2.0297873516877494

Epoch: 5| Step: 2
Training loss: 0.4668198227882385
Validation loss: 2.037275259693464

Epoch: 5| Step: 3
Training loss: 0.39324188232421875
Validation loss: 2.134428565700849

Epoch: 5| Step: 4
Training loss: 0.4443848729133606
Validation loss: 2.116121302048365

Epoch: 5| Step: 5
Training loss: 0.44746628403663635
Validation loss: 2.0982306798299155

Epoch: 5| Step: 6
Training loss: 0.298423171043396
Validation loss: 2.085152799884478

Epoch: 5| Step: 7
Training loss: 0.31139862537384033
Validation loss: 2.0833659172058105

Epoch: 5| Step: 8
Training loss: 0.4856896996498108
Validation loss: 2.0430672466754913

Epoch: 5| Step: 9
Training loss: 0.6447556018829346
Validation loss: 2.096572453776995

Epoch: 5| Step: 10
Training loss: 0.6222274899482727
Validation loss: 2.0354148149490356

Epoch: 5| Step: 11
Training loss: 0.22155559062957764
Validation loss: 2.07916629811128

Epoch: 272| Step: 0
Training loss: 0.5423258543014526
Validation loss: 2.071716924508413

Epoch: 5| Step: 1
Training loss: 0.25836431980133057
Validation loss: 2.06378764907519

Epoch: 5| Step: 2
Training loss: 0.4691120684146881
Validation loss: 2.063267250855764

Epoch: 5| Step: 3
Training loss: 0.4287331700325012
Validation loss: 2.1000860134760537

Epoch: 5| Step: 4
Training loss: 0.347034752368927
Validation loss: 2.151020879546801

Epoch: 5| Step: 5
Training loss: 0.4198920726776123
Validation loss: 2.0888873438040414

Epoch: 5| Step: 6
Training loss: 0.6391283273696899
Validation loss: 2.070337270696958

Epoch: 5| Step: 7
Training loss: 0.2768710255622864
Validation loss: 2.0957596798737845

Epoch: 5| Step: 8
Training loss: 0.44369420409202576
Validation loss: 2.049181655049324

Epoch: 5| Step: 9
Training loss: 0.44052404165267944
Validation loss: 2.0649054696162543

Epoch: 5| Step: 10
Training loss: 0.7414569854736328
Validation loss: 2.05630915860335

Epoch: 5| Step: 11
Training loss: 1.7353477478027344
Validation loss: 2.0473586867252984

Epoch: 273| Step: 0
Training loss: 0.30002278089523315
Validation loss: 2.0511676222085953

Epoch: 5| Step: 1
Training loss: 0.5447206497192383
Validation loss: 2.0829996963342032

Epoch: 5| Step: 2
Training loss: 0.3556869626045227
Validation loss: 2.086077496409416

Epoch: 5| Step: 3
Training loss: 0.590868353843689
Validation loss: 2.041412904858589

Epoch: 5| Step: 4
Training loss: 0.31323713064193726
Validation loss: 2.057973235845566

Epoch: 5| Step: 5
Training loss: 0.4988420605659485
Validation loss: 2.0169671326875687

Epoch: 5| Step: 6
Training loss: 0.48981475830078125
Validation loss: 2.055771400531133

Epoch: 5| Step: 7
Training loss: 0.2606183886528015
Validation loss: 2.044611468911171

Epoch: 5| Step: 8
Training loss: 0.33062976598739624
Validation loss: 2.07101505001386

Epoch: 5| Step: 9
Training loss: 0.42812472581863403
Validation loss: 2.0645889192819595

Epoch: 5| Step: 10
Training loss: 0.579504132270813
Validation loss: 2.109982614715894

Epoch: 5| Step: 11
Training loss: 0.7944877743721008
Validation loss: 2.0740451167027154

Epoch: 274| Step: 0
Training loss: 0.4764479696750641
Validation loss: 2.073871230085691

Epoch: 5| Step: 1
Training loss: 0.24610714614391327
Validation loss: 2.088165213664373

Epoch: 5| Step: 2
Training loss: 0.3784087896347046
Validation loss: 2.0615494350592294

Epoch: 5| Step: 3
Training loss: 0.3492446541786194
Validation loss: 2.0256125777959824

Epoch: 5| Step: 4
Training loss: 0.45455580949783325
Validation loss: 2.059961418310801

Epoch: 5| Step: 5
Training loss: 0.39577436447143555
Validation loss: 2.016073395808538

Epoch: 5| Step: 6
Training loss: 0.8077274560928345
Validation loss: 2.008359278241793

Epoch: 5| Step: 7
Training loss: 0.3510434031486511
Validation loss: 2.048209468523661

Epoch: 5| Step: 8
Training loss: 0.6390639543533325
Validation loss: 2.0152967224518457

Epoch: 5| Step: 9
Training loss: 0.16955360770225525
Validation loss: 2.0437926848729453

Epoch: 5| Step: 10
Training loss: 0.36601147055625916
Validation loss: 2.053806722164154

Epoch: 5| Step: 11
Training loss: 0.39872223138809204
Validation loss: 2.053184151649475

Epoch: 275| Step: 0
Training loss: 0.6944383382797241
Validation loss: 2.047209079066912

Epoch: 5| Step: 1
Training loss: 0.2900596559047699
Validation loss: 2.0941040962934494

Epoch: 5| Step: 2
Training loss: 0.38716474175453186
Validation loss: 2.0632802794377008

Epoch: 5| Step: 3
Training loss: 0.6513643860816956
Validation loss: 2.0600786358118057

Epoch: 5| Step: 4
Training loss: 0.328288733959198
Validation loss: 2.0366398096084595

Epoch: 5| Step: 5
Training loss: 0.262214332818985
Validation loss: 2.02273782591025

Epoch: 5| Step: 6
Training loss: 0.287612646818161
Validation loss: 2.031299650669098

Epoch: 5| Step: 7
Training loss: 0.2967188358306885
Validation loss: 2.008948047955831

Epoch: 5| Step: 8
Training loss: 0.49949780106544495
Validation loss: 2.0425676802794137

Epoch: 5| Step: 9
Training loss: 0.34308329224586487
Validation loss: 2.096173271536827

Epoch: 5| Step: 10
Training loss: 0.4777592122554779
Validation loss: 2.0590919156869254

Epoch: 5| Step: 11
Training loss: 0.4642692804336548
Validation loss: 2.08340252439181

Epoch: 276| Step: 0
Training loss: 0.4826682507991791
Validation loss: 2.0083861549695334

Epoch: 5| Step: 1
Training loss: 0.432985782623291
Validation loss: 2.033945103486379

Epoch: 5| Step: 2
Training loss: 0.40650883316993713
Validation loss: 2.0875120709339776

Epoch: 5| Step: 3
Training loss: 0.5098789930343628
Validation loss: 2.0691605707009635

Epoch: 5| Step: 4
Training loss: 0.31303146481513977
Validation loss: 2.073283021648725

Epoch: 5| Step: 5
Training loss: 0.39420580863952637
Validation loss: 2.0780682414770126

Epoch: 5| Step: 6
Training loss: 0.22694258391857147
Validation loss: 2.053109879295031

Epoch: 5| Step: 7
Training loss: 0.38102540373802185
Validation loss: 2.079277515411377

Epoch: 5| Step: 8
Training loss: 0.5276066064834595
Validation loss: 2.0587245424588523

Epoch: 5| Step: 9
Training loss: 0.6449077129364014
Validation loss: 2.0783913185199103

Epoch: 5| Step: 10
Training loss: 0.5114160776138306
Validation loss: 2.0354218582312265

Epoch: 5| Step: 11
Training loss: 0.270671010017395
Validation loss: 2.051896572113037

Epoch: 277| Step: 0
Training loss: 0.5884720683097839
Validation loss: 2.0132164508104324

Epoch: 5| Step: 1
Training loss: 0.4249144494533539
Validation loss: 2.0250105410814285

Epoch: 5| Step: 2
Training loss: 0.3718530535697937
Validation loss: 2.0992694348096848

Epoch: 5| Step: 3
Training loss: 0.32597988843917847
Validation loss: 2.0629588266213736

Epoch: 5| Step: 4
Training loss: 0.48340290784835815
Validation loss: 2.092173308134079

Epoch: 5| Step: 5
Training loss: 0.61717689037323
Validation loss: 2.104991778731346

Epoch: 5| Step: 6
Training loss: 0.39611148834228516
Validation loss: 2.1049559811751046

Epoch: 5| Step: 7
Training loss: 0.5212147831916809
Validation loss: 2.0680572539567947

Epoch: 5| Step: 8
Training loss: 0.4270978569984436
Validation loss: 2.081203818321228

Epoch: 5| Step: 9
Training loss: 0.24090030789375305
Validation loss: 2.032086412111918

Epoch: 5| Step: 10
Training loss: 0.2504616677761078
Validation loss: 2.0452101627985635

Epoch: 5| Step: 11
Training loss: 0.7115920186042786
Validation loss: 2.0669381618499756

Epoch: 278| Step: 0
Training loss: 0.264879047870636
Validation loss: 2.027100463708242

Epoch: 5| Step: 1
Training loss: 0.6271333694458008
Validation loss: 2.019618863860766

Epoch: 5| Step: 2
Training loss: 0.2737690806388855
Validation loss: 2.0411002933979034

Epoch: 5| Step: 3
Training loss: 0.3391239643096924
Validation loss: 2.10246313114961

Epoch: 5| Step: 4
Training loss: 0.3000769019126892
Validation loss: 2.057924876610438

Epoch: 5| Step: 5
Training loss: 0.31412360072135925
Validation loss: 2.068402032057444

Epoch: 5| Step: 6
Training loss: 0.6645931601524353
Validation loss: 2.0615156143903732

Epoch: 5| Step: 7
Training loss: 0.4713282585144043
Validation loss: 2.0964678525924683

Epoch: 5| Step: 8
Training loss: 0.3744540810585022
Validation loss: 2.1106824378172555

Epoch: 5| Step: 9
Training loss: 0.2244117259979248
Validation loss: 2.0267771979173026

Epoch: 5| Step: 10
Training loss: 0.9109804034233093
Validation loss: 2.0279473265012107

Epoch: 5| Step: 11
Training loss: 0.6884085536003113
Validation loss: 2.03756582736969

Epoch: 279| Step: 0
Training loss: 0.4824923574924469
Validation loss: 2.0329215029875436

Epoch: 5| Step: 1
Training loss: 0.5650620460510254
Validation loss: 2.0063771108786264

Epoch: 5| Step: 2
Training loss: 0.42758312821388245
Validation loss: 2.0414147078990936

Epoch: 5| Step: 3
Training loss: 0.21166940033435822
Validation loss: 2.0627624690532684

Epoch: 5| Step: 4
Training loss: 0.49774169921875
Validation loss: 2.0015976428985596

Epoch: 5| Step: 5
Training loss: 0.37760278582572937
Validation loss: 2.0630820244550705

Epoch: 5| Step: 6
Training loss: 0.36239704489707947
Validation loss: 2.034010718266169

Epoch: 5| Step: 7
Training loss: 0.20279860496520996
Validation loss: 2.0206836660703025

Epoch: 5| Step: 8
Training loss: 0.6415917277336121
Validation loss: 2.0752282788356147

Epoch: 5| Step: 9
Training loss: 0.4833337664604187
Validation loss: 2.0776215344667435

Epoch: 5| Step: 10
Training loss: 0.30661892890930176
Validation loss: 2.095817203323046

Epoch: 5| Step: 11
Training loss: 0.2614138126373291
Validation loss: 2.0668718864520392

Epoch: 280| Step: 0
Training loss: 0.3002772331237793
Validation loss: 2.0695440471172333

Epoch: 5| Step: 1
Training loss: 0.5051537752151489
Validation loss: 2.113494281967481

Epoch: 5| Step: 2
Training loss: 0.5416406393051147
Validation loss: 2.109228198726972

Epoch: 5| Step: 3
Training loss: 0.565827488899231
Validation loss: 2.0658810238043466

Epoch: 5| Step: 4
Training loss: 0.19826990365982056
Validation loss: 2.1150368998448053

Epoch: 5| Step: 5
Training loss: 0.4609171450138092
Validation loss: 2.0929511239131293

Epoch: 5| Step: 6
Training loss: 0.4874569773674011
Validation loss: 2.0814154843489328

Epoch: 5| Step: 7
Training loss: 0.4611738324165344
Validation loss: 2.0720794002215066

Epoch: 5| Step: 8
Training loss: 0.2709856629371643
Validation loss: 2.1265316059192023

Epoch: 5| Step: 9
Training loss: 0.3475320041179657
Validation loss: 2.054841622710228

Epoch: 5| Step: 10
Training loss: 0.5968981981277466
Validation loss: 2.0658272554477057

Epoch: 5| Step: 11
Training loss: 0.3444864749908447
Validation loss: 2.058971881866455

Epoch: 281| Step: 0
Training loss: 0.39679011702537537
Validation loss: 2.093948930501938

Epoch: 5| Step: 1
Training loss: 0.39928168058395386
Validation loss: 2.050196478764216

Epoch: 5| Step: 2
Training loss: 0.5447753667831421
Validation loss: 2.052439178029696

Epoch: 5| Step: 3
Training loss: 0.22456768155097961
Validation loss: 2.0581972350676856

Epoch: 5| Step: 4
Training loss: 0.26351967453956604
Validation loss: 2.0871903796990714

Epoch: 5| Step: 5
Training loss: 0.2907021939754486
Validation loss: 2.083555822571119

Epoch: 5| Step: 6
Training loss: 0.49060139060020447
Validation loss: 2.105259949962298

Epoch: 5| Step: 7
Training loss: 0.342353880405426
Validation loss: 2.125218744079272

Epoch: 5| Step: 8
Training loss: 0.7477350234985352
Validation loss: 2.116214240590731

Epoch: 5| Step: 9
Training loss: 0.37134844064712524
Validation loss: 2.0809182127316794

Epoch: 5| Step: 10
Training loss: 0.2548248767852783
Validation loss: 2.0758667290210724

Epoch: 5| Step: 11
Training loss: 1.5409176349639893
Validation loss: 2.1166206498940787

Epoch: 282| Step: 0
Training loss: 0.5846550464630127
Validation loss: 2.030726363261541

Epoch: 5| Step: 1
Training loss: 0.3229314684867859
Validation loss: 2.078533892830213

Epoch: 5| Step: 2
Training loss: 0.5343905687332153
Validation loss: 2.110628679394722

Epoch: 5| Step: 3
Training loss: 0.2251441478729248
Validation loss: 2.0627531160910926

Epoch: 5| Step: 4
Training loss: 0.40602636337280273
Validation loss: 2.09076980749766

Epoch: 5| Step: 5
Training loss: 0.2328777015209198
Validation loss: 2.0774732182423272

Epoch: 5| Step: 6
Training loss: 0.2745806574821472
Validation loss: 2.066341906785965

Epoch: 5| Step: 7
Training loss: 0.706503689289093
Validation loss: 2.0813024441401162

Epoch: 5| Step: 8
Training loss: 0.35477763414382935
Validation loss: 2.0470604598522186

Epoch: 5| Step: 9
Training loss: 0.62758868932724
Validation loss: 2.072063143054644

Epoch: 5| Step: 10
Training loss: 0.3626679480075836
Validation loss: 2.070768396059672

Epoch: 5| Step: 11
Training loss: 0.32102131843566895
Validation loss: 2.086301565170288

Epoch: 283| Step: 0
Training loss: 0.22961834073066711
Validation loss: 2.091057817141215

Epoch: 5| Step: 1
Training loss: 0.4504113793373108
Validation loss: 2.0642868677775064

Epoch: 5| Step: 2
Training loss: 0.3357573449611664
Validation loss: 2.0754979153474173

Epoch: 5| Step: 3
Training loss: 0.8566888570785522
Validation loss: 2.0718734363714852

Epoch: 5| Step: 4
Training loss: 0.22107358276844025
Validation loss: 2.0335482209920883

Epoch: 5| Step: 5
Training loss: 0.40057802200317383
Validation loss: 2.042343184351921

Epoch: 5| Step: 6
Training loss: 0.3195529282093048
Validation loss: 2.054325054089228

Epoch: 5| Step: 7
Training loss: 0.27785053849220276
Validation loss: 2.0439773201942444

Epoch: 5| Step: 8
Training loss: 0.40522894263267517
Validation loss: 2.078127463658651

Epoch: 5| Step: 9
Training loss: 0.3103385269641876
Validation loss: 2.068720296025276

Epoch: 5| Step: 10
Training loss: 0.4951396882534027
Validation loss: 2.0363633086284003

Epoch: 5| Step: 11
Training loss: 0.09376239776611328
Validation loss: 2.0825239419937134

Epoch: 284| Step: 0
Training loss: 0.48105716705322266
Validation loss: 2.101850097378095

Epoch: 5| Step: 1
Training loss: 0.2980075478553772
Validation loss: 2.072333594163259

Epoch: 5| Step: 2
Training loss: 0.2987721562385559
Validation loss: 2.1077884634335837

Epoch: 5| Step: 3
Training loss: 0.374517560005188
Validation loss: 2.035386304060618

Epoch: 5| Step: 4
Training loss: 0.6870604753494263
Validation loss: 2.023192917307218

Epoch: 5| Step: 5
Training loss: 0.23779281973838806
Validation loss: 2.0761816849311194

Epoch: 5| Step: 6
Training loss: 0.39243778586387634
Validation loss: 2.0464844504992166

Epoch: 5| Step: 7
Training loss: 0.32529306411743164
Validation loss: 2.029384265343348

Epoch: 5| Step: 8
Training loss: 0.40148869156837463
Validation loss: 2.0789494663476944

Epoch: 5| Step: 9
Training loss: 0.512267529964447
Validation loss: 2.063127800822258

Epoch: 5| Step: 10
Training loss: 0.2650352120399475
Validation loss: 2.062825843691826

Epoch: 5| Step: 11
Training loss: 0.1623353362083435
Validation loss: 2.084456334511439

Epoch: 285| Step: 0
Training loss: 0.7937940359115601
Validation loss: 2.0366301238536835

Epoch: 5| Step: 1
Training loss: 0.19392189383506775
Validation loss: 2.055756598711014

Epoch: 5| Step: 2
Training loss: 0.3444878160953522
Validation loss: 2.068820665280024

Epoch: 5| Step: 3
Training loss: 0.4903654456138611
Validation loss: 2.0940909336010614

Epoch: 5| Step: 4
Training loss: 0.29094091057777405
Validation loss: 2.072993074854215

Epoch: 5| Step: 5
Training loss: 0.5616772770881653
Validation loss: 2.119516536593437

Epoch: 5| Step: 6
Training loss: 0.49123820662498474
Validation loss: 2.11773673693339

Epoch: 5| Step: 7
Training loss: 0.2642611861228943
Validation loss: 2.1592101454734802

Epoch: 5| Step: 8
Training loss: 0.39266952872276306
Validation loss: 2.0795780370632806

Epoch: 5| Step: 9
Training loss: 0.4151879847049713
Validation loss: 2.0659221708774567

Epoch: 5| Step: 10
Training loss: 0.2401084452867508
Validation loss: 2.093278259038925

Epoch: 5| Step: 11
Training loss: 0.3009524345397949
Validation loss: 2.130594606200854

Epoch: 286| Step: 0
Training loss: 0.32547563314437866
Validation loss: 2.0896669775247574

Epoch: 5| Step: 1
Training loss: 0.3425317406654358
Validation loss: 2.0862900813420615

Epoch: 5| Step: 2
Training loss: 0.39748436212539673
Validation loss: 2.0622706214586892

Epoch: 5| Step: 3
Training loss: 0.4382482171058655
Validation loss: 2.1114290406306586

Epoch: 5| Step: 4
Training loss: 0.5504916310310364
Validation loss: 2.1043332119782767

Epoch: 5| Step: 5
Training loss: 0.5152360796928406
Validation loss: 2.0780870566765466

Epoch: 5| Step: 6
Training loss: 0.3837805986404419
Validation loss: 2.059768026073774

Epoch: 5| Step: 7
Training loss: 0.30310505628585815
Validation loss: 2.0259242802858353

Epoch: 5| Step: 8
Training loss: 0.3109304904937744
Validation loss: 2.072729463378588

Epoch: 5| Step: 9
Training loss: 0.276746928691864
Validation loss: 2.058526630202929

Epoch: 5| Step: 10
Training loss: 0.6247692108154297
Validation loss: 2.0273087869087854

Epoch: 5| Step: 11
Training loss: 0.6681028604507446
Validation loss: 2.064748893181483

Epoch: 287| Step: 0
Training loss: 0.34777915477752686
Validation loss: 2.056178872783979

Epoch: 5| Step: 1
Training loss: 0.6012890934944153
Validation loss: 2.0838547001282373

Epoch: 5| Step: 2
Training loss: 0.7677106857299805
Validation loss: 2.0762977550427117

Epoch: 5| Step: 3
Training loss: 0.2761523723602295
Validation loss: 2.094146251678467

Epoch: 5| Step: 4
Training loss: 0.2561555504798889
Validation loss: 2.0900291899840036

Epoch: 5| Step: 5
Training loss: 0.2178884744644165
Validation loss: 2.051917225122452

Epoch: 5| Step: 6
Training loss: 0.282999724149704
Validation loss: 2.0558432141939798

Epoch: 5| Step: 7
Training loss: 0.43628987669944763
Validation loss: 2.07260595758756

Epoch: 5| Step: 8
Training loss: 0.4281819462776184
Validation loss: 2.021339868505796

Epoch: 5| Step: 9
Training loss: 0.46302109956741333
Validation loss: 2.049473603566488

Epoch: 5| Step: 10
Training loss: 0.46875888109207153
Validation loss: 2.0553085803985596

Epoch: 5| Step: 11
Training loss: 0.11358177661895752
Validation loss: 2.080877870321274

Epoch: 288| Step: 0
Training loss: 0.2964329719543457
Validation loss: 2.0197945137818656

Epoch: 5| Step: 1
Training loss: 0.6547526717185974
Validation loss: 2.132268339395523

Epoch: 5| Step: 2
Training loss: 0.39329439401626587
Validation loss: 2.0938258916139603

Epoch: 5| Step: 3
Training loss: 0.3552688658237457
Validation loss: 2.068121607104937

Epoch: 5| Step: 4
Training loss: 0.3420202136039734
Validation loss: 2.0643739849328995

Epoch: 5| Step: 5
Training loss: 0.2779671549797058
Validation loss: 2.073587010304133

Epoch: 5| Step: 6
Training loss: 0.3487381041049957
Validation loss: 2.045491009950638

Epoch: 5| Step: 7
Training loss: 0.4637022912502289
Validation loss: 2.032713443040848

Epoch: 5| Step: 8
Training loss: 0.4331791400909424
Validation loss: 2.0544793705145517

Epoch: 5| Step: 9
Training loss: 0.29065966606140137
Validation loss: 1.9690835028886795

Epoch: 5| Step: 10
Training loss: 0.6286450028419495
Validation loss: 2.0473007758458457

Epoch: 5| Step: 11
Training loss: 0.19440209865570068
Validation loss: 2.0880433370669684

Epoch: 289| Step: 0
Training loss: 0.4444712698459625
Validation loss: 2.101733257373174

Epoch: 5| Step: 1
Training loss: 0.45385417342185974
Validation loss: 2.127927472194036

Epoch: 5| Step: 2
Training loss: 0.325425922870636
Validation loss: 2.076683630545934

Epoch: 5| Step: 3
Training loss: 0.3124511241912842
Validation loss: 2.140494485696157

Epoch: 5| Step: 4
Training loss: 0.4776231348514557
Validation loss: 2.0536084373792014

Epoch: 5| Step: 5
Training loss: 0.13826975226402283
Validation loss: 2.101783906420072

Epoch: 5| Step: 6
Training loss: 0.6637386083602905
Validation loss: 2.076080560684204

Epoch: 5| Step: 7
Training loss: 0.4668707251548767
Validation loss: 2.041809389988581

Epoch: 5| Step: 8
Training loss: 0.5903463959693909
Validation loss: 2.0510715395212173

Epoch: 5| Step: 9
Training loss: 0.41045910120010376
Validation loss: 2.0614413817723594

Epoch: 5| Step: 10
Training loss: 0.325697124004364
Validation loss: 2.0871233344078064

Epoch: 5| Step: 11
Training loss: 0.6034512519836426
Validation loss: 2.0779792269070945

Epoch: 290| Step: 0
Training loss: 0.22475898265838623
Validation loss: 2.109847421447436

Epoch: 5| Step: 1
Training loss: 0.7186785936355591
Validation loss: 2.1031033297379813

Epoch: 5| Step: 2
Training loss: 0.269374281167984
Validation loss: 2.084698031346003

Epoch: 5| Step: 3
Training loss: 0.2508743405342102
Validation loss: 2.0740807304779687

Epoch: 5| Step: 4
Training loss: 0.40573692321777344
Validation loss: 2.110938310623169

Epoch: 5| Step: 5
Training loss: 0.1860964000225067
Validation loss: 2.1019542664289474

Epoch: 5| Step: 6
Training loss: 0.44279831647872925
Validation loss: 2.0961635460456214

Epoch: 5| Step: 7
Training loss: 0.23381635546684265
Validation loss: 2.0827973981698356

Epoch: 5| Step: 8
Training loss: 0.2940267324447632
Validation loss: 2.0996294766664505

Epoch: 5| Step: 9
Training loss: 0.5134766101837158
Validation loss: 2.0810265640417733

Epoch: 5| Step: 10
Training loss: 0.4213940501213074
Validation loss: 2.0803992599248886

Epoch: 5| Step: 11
Training loss: 0.4345623254776001
Validation loss: 2.086668392022451

Epoch: 291| Step: 0
Training loss: 0.5210949182510376
Validation loss: 2.072516197959582

Epoch: 5| Step: 1
Training loss: 0.3052414357662201
Validation loss: 2.0820723275343576

Epoch: 5| Step: 2
Training loss: 0.4013107419013977
Validation loss: 2.1178151617447534

Epoch: 5| Step: 3
Training loss: 0.319458544254303
Validation loss: 2.125899871190389

Epoch: 5| Step: 4
Training loss: 0.34807801246643066
Validation loss: 2.156659801801046

Epoch: 5| Step: 5
Training loss: 0.20926670730113983
Validation loss: 2.118208631873131

Epoch: 5| Step: 6
Training loss: 0.4150303304195404
Validation loss: 2.102778563896815

Epoch: 5| Step: 7
Training loss: 0.26457786560058594
Validation loss: 2.0622814297676086

Epoch: 5| Step: 8
Training loss: 0.37360936403274536
Validation loss: 2.07528825600942

Epoch: 5| Step: 9
Training loss: 0.4394919276237488
Validation loss: 2.044631779193878

Epoch: 5| Step: 10
Training loss: 0.7697919011116028
Validation loss: 2.0875532080729804

Epoch: 5| Step: 11
Training loss: 0.27486085891723633
Validation loss: 2.1083525915940604

Epoch: 292| Step: 0
Training loss: 0.2706645429134369
Validation loss: 2.07708274324735

Epoch: 5| Step: 1
Training loss: 0.386897474527359
Validation loss: 2.089812844991684

Epoch: 5| Step: 2
Training loss: 0.36152106523513794
Validation loss: 2.0548539956410727

Epoch: 5| Step: 3
Training loss: 0.30165037512779236
Validation loss: 2.064614857236544

Epoch: 5| Step: 4
Training loss: 0.396476149559021
Validation loss: 2.0635258754094443

Epoch: 5| Step: 5
Training loss: 0.8746631741523743
Validation loss: 2.076584964990616

Epoch: 5| Step: 6
Training loss: 0.33527112007141113
Validation loss: 2.0577841947476068

Epoch: 5| Step: 7
Training loss: 0.29890602827072144
Validation loss: 2.091703469554583

Epoch: 5| Step: 8
Training loss: 0.35803622007369995
Validation loss: 2.080262909332911

Epoch: 5| Step: 9
Training loss: 0.510953426361084
Validation loss: 2.108601907889048

Epoch: 5| Step: 10
Training loss: 0.20323605835437775
Validation loss: 2.0849797129631042

Epoch: 5| Step: 11
Training loss: 0.7293286323547363
Validation loss: 2.0817604809999466

Epoch: 293| Step: 0
Training loss: 0.46683281660079956
Validation loss: 2.078424965341886

Epoch: 5| Step: 1
Training loss: 0.35077160596847534
Validation loss: 2.0446627835432687

Epoch: 5| Step: 2
Training loss: 0.5543456077575684
Validation loss: 2.05790384610494

Epoch: 5| Step: 3
Training loss: 0.5128594636917114
Validation loss: 2.046076392134031

Epoch: 5| Step: 4
Training loss: 0.2781105637550354
Validation loss: 2.0671762824058533

Epoch: 5| Step: 5
Training loss: 0.29126349091529846
Validation loss: 1.9908338983853657

Epoch: 5| Step: 6
Training loss: 0.2941260039806366
Validation loss: 2.0979005793730416

Epoch: 5| Step: 7
Training loss: 0.23935870826244354
Validation loss: 2.042985886335373

Epoch: 5| Step: 8
Training loss: 0.32255813479423523
Validation loss: 2.0910625656445823

Epoch: 5| Step: 9
Training loss: 0.3603832423686981
Validation loss: 2.0566995590925217

Epoch: 5| Step: 10
Training loss: 0.7833865284919739
Validation loss: 2.106092005968094

Epoch: 5| Step: 11
Training loss: 0.33016109466552734
Validation loss: 2.06990846991539

Epoch: 294| Step: 0
Training loss: 0.26827186346054077
Validation loss: 2.094712590177854

Epoch: 5| Step: 1
Training loss: 0.2808554768562317
Validation loss: 2.0786060144503913

Epoch: 5| Step: 2
Training loss: 0.737305760383606
Validation loss: 2.100956678390503

Epoch: 5| Step: 3
Training loss: 0.3397754430770874
Validation loss: 2.051295374830564

Epoch: 5| Step: 4
Training loss: 0.3190634846687317
Validation loss: 2.0264078080654144

Epoch: 5| Step: 5
Training loss: 0.33673834800720215
Validation loss: 2.0610073109467826

Epoch: 5| Step: 6
Training loss: 0.6855720281600952
Validation loss: 2.033311660091082

Epoch: 5| Step: 7
Training loss: 0.3887540102005005
Validation loss: 2.0584316154321036

Epoch: 5| Step: 8
Training loss: 0.3688388466835022
Validation loss: 2.035775621732076

Epoch: 5| Step: 9
Training loss: 0.252246230840683
Validation loss: 2.0834434827168784

Epoch: 5| Step: 10
Training loss: 0.4920923709869385
Validation loss: 2.0585735738277435

Epoch: 5| Step: 11
Training loss: 0.37094438076019287
Validation loss: 2.1300359268983207

Epoch: 295| Step: 0
Training loss: 0.3849007189273834
Validation loss: 2.060489758849144

Epoch: 5| Step: 1
Training loss: 0.5424676537513733
Validation loss: 2.082132026553154

Epoch: 5| Step: 2
Training loss: 0.29782941937446594
Validation loss: 2.0509766240914664

Epoch: 5| Step: 3
Training loss: 0.2436884641647339
Validation loss: 2.033259317278862

Epoch: 5| Step: 4
Training loss: 0.656384289264679
Validation loss: 2.0456687659025192

Epoch: 5| Step: 5
Training loss: 0.8006547093391418
Validation loss: 2.0318811585505805

Epoch: 5| Step: 6
Training loss: 0.2716953158378601
Validation loss: 2.0514392852783203

Epoch: 5| Step: 7
Training loss: 0.2261083871126175
Validation loss: 2.07916987935702

Epoch: 5| Step: 8
Training loss: 0.31732821464538574
Validation loss: 2.164524738987287

Epoch: 5| Step: 9
Training loss: 0.6528398394584656
Validation loss: 2.135044793287913

Epoch: 5| Step: 10
Training loss: 0.48288726806640625
Validation loss: 2.0975241710742316

Epoch: 5| Step: 11
Training loss: 0.6126097440719604
Validation loss: 2.14081201950709

Epoch: 296| Step: 0
Training loss: 0.8261944651603699
Validation loss: 2.060152808825175

Epoch: 5| Step: 1
Training loss: 0.14943894743919373
Validation loss: 2.058519517381986

Epoch: 5| Step: 2
Training loss: 0.4814637303352356
Validation loss: 2.038950184981028

Epoch: 5| Step: 3
Training loss: 0.4678402841091156
Validation loss: 2.0694603274265924

Epoch: 5| Step: 4
Training loss: 0.8367264866828918
Validation loss: 2.000149443745613

Epoch: 5| Step: 5
Training loss: 0.32232654094696045
Validation loss: 2.0637619296709695

Epoch: 5| Step: 6
Training loss: 0.4421887993812561
Validation loss: 2.080651124318441

Epoch: 5| Step: 7
Training loss: 0.1574457585811615
Validation loss: 2.1181290497382483

Epoch: 5| Step: 8
Training loss: 0.20602479577064514
Validation loss: 2.1354153056939444

Epoch: 5| Step: 9
Training loss: 0.7680370807647705
Validation loss: 2.203453113635381

Epoch: 5| Step: 10
Training loss: 0.7041029930114746
Validation loss: 2.2103919039169946

Epoch: 5| Step: 11
Training loss: 0.45005226135253906
Validation loss: 2.164681355158488

Epoch: 297| Step: 0
Training loss: 0.5106412172317505
Validation loss: 2.134147197008133

Epoch: 5| Step: 1
Training loss: 0.30301588773727417
Validation loss: 2.1077105353275933

Epoch: 5| Step: 2
Training loss: 0.34643885493278503
Validation loss: 2.098565394679705

Epoch: 5| Step: 3
Training loss: 0.4062899947166443
Validation loss: 2.06242627898852

Epoch: 5| Step: 4
Training loss: 0.7059122323989868
Validation loss: 2.0670963376760483

Epoch: 5| Step: 5
Training loss: 0.6389068365097046
Validation loss: 2.0063635210196176

Epoch: 5| Step: 6
Training loss: 0.32658955454826355
Validation loss: 2.122679149111112

Epoch: 5| Step: 7
Training loss: 0.2987673580646515
Validation loss: 2.0693955371777215

Epoch: 5| Step: 8
Training loss: 0.3852647840976715
Validation loss: 2.0904794285694757

Epoch: 5| Step: 9
Training loss: 0.614767849445343
Validation loss: 2.1618449489275613

Epoch: 5| Step: 10
Training loss: 0.47629299759864807
Validation loss: 2.1540389955043793

Epoch: 5| Step: 11
Training loss: 0.30681613087654114
Validation loss: 2.159976730744044

Epoch: 298| Step: 0
Training loss: 0.6364331245422363
Validation loss: 2.1179332534472146

Epoch: 5| Step: 1
Training loss: 0.43416228890419006
Validation loss: 2.11030246814092

Epoch: 5| Step: 2
Training loss: 0.2330297976732254
Validation loss: 2.1037558366854987

Epoch: 5| Step: 3
Training loss: 0.5824154019355774
Validation loss: 2.0843245337406793

Epoch: 5| Step: 4
Training loss: 0.26824554800987244
Validation loss: 2.074423963824908

Epoch: 5| Step: 5
Training loss: 0.37156739830970764
Validation loss: 2.100230132540067

Epoch: 5| Step: 6
Training loss: 0.4602604806423187
Validation loss: 2.0928660531838736

Epoch: 5| Step: 7
Training loss: 0.30767375230789185
Validation loss: 2.0406591395537057

Epoch: 5| Step: 8
Training loss: 0.5101094245910645
Validation loss: 2.082995673020681

Epoch: 5| Step: 9
Training loss: 0.2487015724182129
Validation loss: 2.082935924331347

Epoch: 5| Step: 10
Training loss: 0.5826622843742371
Validation loss: 2.14121221502622

Epoch: 5| Step: 11
Training loss: 0.20312130451202393
Validation loss: 2.0743108143409095

Epoch: 299| Step: 0
Training loss: 0.4025755822658539
Validation loss: 2.038569912314415

Epoch: 5| Step: 1
Training loss: 0.6545151472091675
Validation loss: 2.094342276453972

Epoch: 5| Step: 2
Training loss: 0.45288294553756714
Validation loss: 2.0773821274439492

Epoch: 5| Step: 3
Training loss: 0.35976213216781616
Validation loss: 2.089493289589882

Epoch: 5| Step: 4
Training loss: 0.19608932733535767
Validation loss: 2.061584562063217

Epoch: 5| Step: 5
Training loss: 0.27660906314849854
Validation loss: 2.099896192550659

Epoch: 5| Step: 6
Training loss: 0.25183433294296265
Validation loss: 2.1260608434677124

Epoch: 5| Step: 7
Training loss: 0.5979329347610474
Validation loss: 2.0996495435635247

Epoch: 5| Step: 8
Training loss: 0.43730419874191284
Validation loss: 2.093989113966624

Epoch: 5| Step: 9
Training loss: 0.5458910465240479
Validation loss: 2.1007982045412064

Epoch: 5| Step: 10
Training loss: 0.2191472053527832
Validation loss: 2.08837221066157

Epoch: 5| Step: 11
Training loss: 0.456199586391449
Validation loss: 2.0488847345113754

Epoch: 300| Step: 0
Training loss: 0.34707412123680115
Validation loss: 2.1069993674755096

Epoch: 5| Step: 1
Training loss: 0.22397108376026154
Validation loss: 2.067136531074842

Epoch: 5| Step: 2
Training loss: 0.47616511583328247
Validation loss: 2.097936431566874

Epoch: 5| Step: 3
Training loss: 0.22061431407928467
Validation loss: 2.1612491508324942

Epoch: 5| Step: 4
Training loss: 0.4912172257900238
Validation loss: 2.107342238227526

Epoch: 5| Step: 5
Training loss: 0.32935020327568054
Validation loss: 2.0678670406341553

Epoch: 5| Step: 6
Training loss: 0.3592345714569092
Validation loss: 2.135315348704656

Epoch: 5| Step: 7
Training loss: 0.32614392042160034
Validation loss: 2.0641382137934365

Epoch: 5| Step: 8
Training loss: 0.33627456426620483
Validation loss: 2.1225329538186393

Epoch: 5| Step: 9
Training loss: 0.6464859247207642
Validation loss: 2.1124680042266846

Epoch: 5| Step: 10
Training loss: 0.4849019944667816
Validation loss: 2.064698114991188

Epoch: 5| Step: 11
Training loss: 0.22529852390289307
Validation loss: 2.0709586242834725

Epoch: 301| Step: 0
Training loss: 0.25331875681877136
Validation loss: 2.081920027732849

Epoch: 5| Step: 1
Training loss: 0.34754136204719543
Validation loss: 2.036508838335673

Epoch: 5| Step: 2
Training loss: 0.35709676146507263
Validation loss: 2.0812572091817856

Epoch: 5| Step: 3
Training loss: 0.6237349510192871
Validation loss: 2.072561820348104

Epoch: 5| Step: 4
Training loss: 0.43411803245544434
Validation loss: 2.0869288941224418

Epoch: 5| Step: 5
Training loss: 0.2084168940782547
Validation loss: 2.089883784453074

Epoch: 5| Step: 6
Training loss: 0.24944040179252625
Validation loss: 2.0800634870926538

Epoch: 5| Step: 7
Training loss: 0.36101484298706055
Validation loss: 2.087341378132502

Epoch: 5| Step: 8
Training loss: 0.39139288663864136
Validation loss: 2.0556373993555703

Epoch: 5| Step: 9
Training loss: 0.6396893262863159
Validation loss: 2.082345113158226

Epoch: 5| Step: 10
Training loss: 0.5657151937484741
Validation loss: 2.0824722051620483

Epoch: 5| Step: 11
Training loss: 0.2367408275604248
Validation loss: 2.0878734985987344

Epoch: 302| Step: 0
Training loss: 0.518937349319458
Validation loss: 2.0769608865181604

Epoch: 5| Step: 1
Training loss: 0.3907786011695862
Validation loss: 2.0749089419841766

Epoch: 5| Step: 2
Training loss: 0.5440267324447632
Validation loss: 2.0835204074780145

Epoch: 5| Step: 3
Training loss: 0.2505810260772705
Validation loss: 2.017163803180059

Epoch: 5| Step: 4
Training loss: 0.25062471628189087
Validation loss: 2.0460417668024697

Epoch: 5| Step: 5
Training loss: 0.7753880023956299
Validation loss: 2.106714442372322

Epoch: 5| Step: 6
Training loss: 0.3958418369293213
Validation loss: 2.1241489996512732

Epoch: 5| Step: 7
Training loss: 0.6666801571846008
Validation loss: 2.1271734784046807

Epoch: 5| Step: 8
Training loss: 0.4550122618675232
Validation loss: 2.134239057699839

Epoch: 5| Step: 9
Training loss: 0.4769543707370758
Validation loss: 2.1194546222686768

Epoch: 5| Step: 10
Training loss: 0.2501136064529419
Validation loss: 2.0537899931271872

Epoch: 5| Step: 11
Training loss: 1.481945276260376
Validation loss: 2.098078886667887

Epoch: 303| Step: 0
Training loss: 0.492669016122818
Validation loss: 2.1203336169322333

Epoch: 5| Step: 1
Training loss: 0.3681045174598694
Validation loss: 2.0329952289660773

Epoch: 5| Step: 2
Training loss: 0.2889806032180786
Validation loss: 2.0894995282093682

Epoch: 5| Step: 3
Training loss: 0.3891705274581909
Validation loss: 2.0906689117352166

Epoch: 5| Step: 4
Training loss: 0.37569934129714966
Validation loss: 2.1077066163221994

Epoch: 5| Step: 5
Training loss: 0.26774102449417114
Validation loss: 2.087245926260948

Epoch: 5| Step: 6
Training loss: 0.1907253861427307
Validation loss: 2.098818759123484

Epoch: 5| Step: 7
Training loss: 0.3706612288951874
Validation loss: 2.124897693594297

Epoch: 5| Step: 8
Training loss: 0.7560959458351135
Validation loss: 2.111520434419314

Epoch: 5| Step: 9
Training loss: 0.3742426335811615
Validation loss: 2.117309262355169

Epoch: 5| Step: 10
Training loss: 0.35827621817588806
Validation loss: 2.090321193138758

Epoch: 5| Step: 11
Training loss: 0.7009170055389404
Validation loss: 2.103326136867205

Epoch: 304| Step: 0
Training loss: 0.3425147533416748
Validation loss: 2.08521760503451

Epoch: 5| Step: 1
Training loss: 0.3763085603713989
Validation loss: 2.059288412332535

Epoch: 5| Step: 2
Training loss: 0.652664303779602
Validation loss: 2.0579036474227905

Epoch: 5| Step: 3
Training loss: 0.29420047998428345
Validation loss: 2.0903655787309012

Epoch: 5| Step: 4
Training loss: 0.2747839093208313
Validation loss: 2.123071238398552

Epoch: 5| Step: 5
Training loss: 0.5850405097007751
Validation loss: 2.1295535564422607

Epoch: 5| Step: 6
Training loss: 0.5089763402938843
Validation loss: 2.1334560563166938

Epoch: 5| Step: 7
Training loss: 0.23950596153736115
Validation loss: 2.1599249243736267

Epoch: 5| Step: 8
Training loss: 0.39425286650657654
Validation loss: 2.1356192330519357

Epoch: 5| Step: 9
Training loss: 0.41785067319869995
Validation loss: 2.0611408849557242

Epoch: 5| Step: 10
Training loss: 0.43096923828125
Validation loss: 2.052501196662585

Epoch: 5| Step: 11
Training loss: 0.66025310754776
Validation loss: 2.0424203922351203

Epoch: 305| Step: 0
Training loss: 0.634261429309845
Validation loss: 2.050183946887652

Epoch: 5| Step: 1
Training loss: 0.6733263731002808
Validation loss: 2.0385404229164124

Epoch: 5| Step: 2
Training loss: 0.3195222020149231
Validation loss: 2.100209136803945

Epoch: 5| Step: 3
Training loss: 0.3375135064125061
Validation loss: 2.0682848940292993

Epoch: 5| Step: 4
Training loss: 0.48392850160598755
Validation loss: 2.1460665414730706

Epoch: 5| Step: 5
Training loss: 0.38080811500549316
Validation loss: 2.128694405158361

Epoch: 5| Step: 6
Training loss: 0.5324411392211914
Validation loss: 2.137618104616801

Epoch: 5| Step: 7
Training loss: 0.2355332374572754
Validation loss: 2.086714814106623

Epoch: 5| Step: 8
Training loss: 0.45205387473106384
Validation loss: 2.126008997360865

Epoch: 5| Step: 9
Training loss: 0.5352481007575989
Validation loss: 2.0872100790341697

Epoch: 5| Step: 10
Training loss: 0.26837342977523804
Validation loss: 2.0680689066648483

Epoch: 5| Step: 11
Training loss: 0.279168963432312
Validation loss: 2.038426453868548

Epoch: 306| Step: 0
Training loss: 0.3610747158527374
Validation loss: 2.037580043077469

Epoch: 5| Step: 1
Training loss: 0.27161067724227905
Validation loss: 2.1056452890237174

Epoch: 5| Step: 2
Training loss: 0.22360849380493164
Validation loss: 2.063125421603521

Epoch: 5| Step: 3
Training loss: 0.25547659397125244
Validation loss: 2.1273327271143594

Epoch: 5| Step: 4
Training loss: 0.45675212144851685
Validation loss: 2.081689511736234

Epoch: 5| Step: 5
Training loss: 0.4234147071838379
Validation loss: 2.10180094341437

Epoch: 5| Step: 6
Training loss: 0.5363026857376099
Validation loss: 2.115030666192373

Epoch: 5| Step: 7
Training loss: 0.267423540353775
Validation loss: 2.1219524343808494

Epoch: 5| Step: 8
Training loss: 0.3506332039833069
Validation loss: 2.130867371956507

Epoch: 5| Step: 9
Training loss: 0.4447709023952484
Validation loss: 2.1053020656108856

Epoch: 5| Step: 10
Training loss: 0.5214158296585083
Validation loss: 2.12383696436882

Epoch: 5| Step: 11
Training loss: 0.9267237186431885
Validation loss: 2.077276051044464

Epoch: 307| Step: 0
Training loss: 0.2860911786556244
Validation loss: 2.1056460042794547

Epoch: 5| Step: 1
Training loss: 0.24286308884620667
Validation loss: 2.0787551204363504

Epoch: 5| Step: 2
Training loss: 0.37115374207496643
Validation loss: 2.090091655651728

Epoch: 5| Step: 3
Training loss: 0.28538140654563904
Validation loss: 2.0989039540290833

Epoch: 5| Step: 4
Training loss: 0.26329362392425537
Validation loss: 2.117849921186765

Epoch: 5| Step: 5
Training loss: 0.29259753227233887
Validation loss: 2.0982970794041953

Epoch: 5| Step: 6
Training loss: 0.4027516841888428
Validation loss: 2.102796028057734

Epoch: 5| Step: 7
Training loss: 0.24710746109485626
Validation loss: 2.0968488107124963

Epoch: 5| Step: 8
Training loss: 0.6817506551742554
Validation loss: 2.065596188108126

Epoch: 5| Step: 9
Training loss: 0.5288737416267395
Validation loss: 2.0310427149136863

Epoch: 5| Step: 10
Training loss: 0.6092954874038696
Validation loss: 2.0913902471462884

Epoch: 5| Step: 11
Training loss: 1.1061921119689941
Validation loss: 2.108009288708369

Epoch: 308| Step: 0
Training loss: 0.3703482747077942
Validation loss: 2.1004405319690704

Epoch: 5| Step: 1
Training loss: 0.3521656394004822
Validation loss: 2.1186876694361367

Epoch: 5| Step: 2
Training loss: 0.4586733877658844
Validation loss: 2.128579691052437

Epoch: 5| Step: 3
Training loss: 0.3948080241680145
Validation loss: 2.1539990405241647

Epoch: 5| Step: 4
Training loss: 0.3810301721096039
Validation loss: 2.09569983681043

Epoch: 5| Step: 5
Training loss: 0.31288179755210876
Validation loss: 2.0488084256649017

Epoch: 5| Step: 6
Training loss: 0.45078045129776
Validation loss: 2.048036982615789

Epoch: 5| Step: 7
Training loss: 0.3303987383842468
Validation loss: 2.0210713744163513

Epoch: 5| Step: 8
Training loss: 0.4233231544494629
Validation loss: 2.036653389533361

Epoch: 5| Step: 9
Training loss: 0.7514286041259766
Validation loss: 2.0371449142694473

Epoch: 5| Step: 10
Training loss: 0.47647133469581604
Validation loss: 2.0302020013332367

Epoch: 5| Step: 11
Training loss: 0.3105699121952057
Validation loss: 1.9796656320492427

Epoch: 309| Step: 0
Training loss: 0.2511395514011383
Validation loss: 2.082856759428978

Epoch: 5| Step: 1
Training loss: 0.3778362572193146
Validation loss: 2.082131713628769

Epoch: 5| Step: 2
Training loss: 0.47963303327560425
Validation loss: 2.1259994755188623

Epoch: 5| Step: 3
Training loss: 0.4096830487251282
Validation loss: 2.120262841383616

Epoch: 5| Step: 4
Training loss: 0.8423683047294617
Validation loss: 2.1461646258831024

Epoch: 5| Step: 5
Training loss: 0.28960734605789185
Validation loss: 2.0728452503681183

Epoch: 5| Step: 6
Training loss: 0.47970613837242126
Validation loss: 2.062670106689135

Epoch: 5| Step: 7
Training loss: 0.27586403489112854
Validation loss: 2.0316953361034393

Epoch: 5| Step: 8
Training loss: 0.4273388981819153
Validation loss: 2.008563910921415

Epoch: 5| Step: 9
Training loss: 0.3835037052631378
Validation loss: 2.083427220582962

Epoch: 5| Step: 10
Training loss: 0.6269159317016602
Validation loss: 1.9761493106683095

Epoch: 5| Step: 11
Training loss: 0.432242214679718
Validation loss: 2.0521357307831445

Epoch: 310| Step: 0
Training loss: 0.3180791139602661
Validation loss: 2.0544623335202536

Epoch: 5| Step: 1
Training loss: 0.36452406644821167
Validation loss: 2.052014177044233

Epoch: 5| Step: 2
Training loss: 0.2921825051307678
Validation loss: 2.122150441010793

Epoch: 5| Step: 3
Training loss: 0.6995911002159119
Validation loss: 2.1303509175777435

Epoch: 5| Step: 4
Training loss: 0.3640100955963135
Validation loss: 2.1463414827982583

Epoch: 5| Step: 5
Training loss: 0.3899855315685272
Validation loss: 2.09771699210008

Epoch: 5| Step: 6
Training loss: 0.3558145761489868
Validation loss: 2.099552353223165

Epoch: 5| Step: 7
Training loss: 0.40301713347435
Validation loss: 2.0786585013071694

Epoch: 5| Step: 8
Training loss: 0.6168233752250671
Validation loss: 2.0794466733932495

Epoch: 5| Step: 9
Training loss: 0.19785645604133606
Validation loss: 2.121762658158938

Epoch: 5| Step: 10
Training loss: 0.41236820816993713
Validation loss: 2.055166949828466

Epoch: 5| Step: 11
Training loss: 1.2458298206329346
Validation loss: 2.0746176689863205

Epoch: 311| Step: 0
Training loss: 0.6751313209533691
Validation loss: 2.0537000596523285

Epoch: 5| Step: 1
Training loss: 0.4668925404548645
Validation loss: 2.0539970099925995

Epoch: 5| Step: 2
Training loss: 0.3601463735103607
Validation loss: 2.068753590186437

Epoch: 5| Step: 3
Training loss: 0.3565140962600708
Validation loss: 2.051379452149073

Epoch: 5| Step: 4
Training loss: 0.3511365056037903
Validation loss: 2.068650340040525

Epoch: 5| Step: 5
Training loss: 0.20102429389953613
Validation loss: 2.1252923210461936

Epoch: 5| Step: 6
Training loss: 0.39952582120895386
Validation loss: 2.135282720128695

Epoch: 5| Step: 7
Training loss: 0.5674171447753906
Validation loss: 2.1066536555687585

Epoch: 5| Step: 8
Training loss: 0.35655006766319275
Validation loss: 2.1112525363763175

Epoch: 5| Step: 9
Training loss: 0.26823702454566956
Validation loss: 2.1047293891509375

Epoch: 5| Step: 10
Training loss: 0.2367551624774933
Validation loss: 2.057154526313146

Epoch: 5| Step: 11
Training loss: 0.4243931174278259
Validation loss: 2.0616771231094995

Epoch: 312| Step: 0
Training loss: 0.5683770179748535
Validation loss: 2.0460677991310754

Epoch: 5| Step: 1
Training loss: 0.16645006835460663
Validation loss: 2.063193827867508

Epoch: 5| Step: 2
Training loss: 0.3717937469482422
Validation loss: 2.082160527507464

Epoch: 5| Step: 3
Training loss: 0.42934855818748474
Validation loss: 2.0789110511541367

Epoch: 5| Step: 4
Training loss: 0.26989978551864624
Validation loss: 2.1148571223020554

Epoch: 5| Step: 5
Training loss: 0.29211100935935974
Validation loss: 2.0604980488618216

Epoch: 5| Step: 6
Training loss: 0.41696494817733765
Validation loss: 2.0522051453590393

Epoch: 5| Step: 7
Training loss: 0.4315904974937439
Validation loss: 2.068348084886869

Epoch: 5| Step: 8
Training loss: 0.20796218514442444
Validation loss: 2.095397179325422

Epoch: 5| Step: 9
Training loss: 0.4527463912963867
Validation loss: 2.0788028885920844

Epoch: 5| Step: 10
Training loss: 0.3845101296901703
Validation loss: 2.0875660479068756

Epoch: 5| Step: 11
Training loss: 0.11303377151489258
Validation loss: 2.0915481795867286

Epoch: 313| Step: 0
Training loss: 0.3107164800167084
Validation loss: 2.0338786939779916

Epoch: 5| Step: 1
Training loss: 0.3365095257759094
Validation loss: 2.0750230997800827

Epoch: 5| Step: 2
Training loss: 0.2402472048997879
Validation loss: 2.122778241833051

Epoch: 5| Step: 3
Training loss: 0.3605647683143616
Validation loss: 2.1154362658659616

Epoch: 5| Step: 4
Training loss: 0.31789883971214294
Validation loss: 2.0749020477135978

Epoch: 5| Step: 5
Training loss: 0.6377907991409302
Validation loss: 2.084164172410965

Epoch: 5| Step: 6
Training loss: 0.39302629232406616
Validation loss: 2.092669645945231

Epoch: 5| Step: 7
Training loss: 0.4320734441280365
Validation loss: 2.1111544171969094

Epoch: 5| Step: 8
Training loss: 0.30729204416275024
Validation loss: 2.105654721458753

Epoch: 5| Step: 9
Training loss: 0.42576584219932556
Validation loss: 2.0537430743376413

Epoch: 5| Step: 10
Training loss: 0.3220732808113098
Validation loss: 2.0890064934889474

Epoch: 5| Step: 11
Training loss: 1.1935327053070068
Validation loss: 2.0323967387278876

Epoch: 314| Step: 0
Training loss: 0.30486923456192017
Validation loss: 2.0885800967613855

Epoch: 5| Step: 1
Training loss: 0.3165383040904999
Validation loss: 2.053355356057485

Epoch: 5| Step: 2
Training loss: 0.41340160369873047
Validation loss: 2.0871497442324958

Epoch: 5| Step: 3
Training loss: 0.2333693951368332
Validation loss: 2.0467639565467834

Epoch: 5| Step: 4
Training loss: 0.23131275177001953
Validation loss: 2.069542169570923

Epoch: 5| Step: 5
Training loss: 0.44362396001815796
Validation loss: 2.07002284626166

Epoch: 5| Step: 6
Training loss: 0.31635791063308716
Validation loss: 2.0897451589504876

Epoch: 5| Step: 7
Training loss: 0.29308146238327026
Validation loss: 2.141032636165619

Epoch: 5| Step: 8
Training loss: 0.3468396067619324
Validation loss: 2.0642491976420083

Epoch: 5| Step: 9
Training loss: 0.6402961611747742
Validation loss: 2.1047802617152533

Epoch: 5| Step: 10
Training loss: 0.5825327634811401
Validation loss: 2.074180990457535

Epoch: 5| Step: 11
Training loss: 0.20921508967876434
Validation loss: 2.0454003512859344

Epoch: 315| Step: 0
Training loss: 0.22691710293293
Validation loss: 2.0725483347972236

Epoch: 5| Step: 1
Training loss: 0.5648834109306335
Validation loss: 2.0637366573015847

Epoch: 5| Step: 2
Training loss: 0.3744596242904663
Validation loss: 2.0488587667544684

Epoch: 5| Step: 3
Training loss: 0.3706989884376526
Validation loss: 2.0648103803396225

Epoch: 5| Step: 4
Training loss: 0.6043731570243835
Validation loss: 2.111784646908442

Epoch: 5| Step: 5
Training loss: 0.2744434177875519
Validation loss: 2.0824621667464576

Epoch: 5| Step: 6
Training loss: 0.5329731106758118
Validation loss: 2.0953940649827323

Epoch: 5| Step: 7
Training loss: 0.5067399144172668
Validation loss: 2.0993558863798776

Epoch: 5| Step: 8
Training loss: 0.38461145758628845
Validation loss: 2.1520494321982064

Epoch: 5| Step: 9
Training loss: 0.39089706540107727
Validation loss: 2.0798798153797784

Epoch: 5| Step: 10
Training loss: 0.2649179697036743
Validation loss: 2.1116575052340827

Epoch: 5| Step: 11
Training loss: 0.26932767033576965
Validation loss: 2.083888237675031

Epoch: 316| Step: 0
Training loss: 0.22291216254234314
Validation loss: 2.070694093902906

Epoch: 5| Step: 1
Training loss: 0.6199474334716797
Validation loss: 2.0888094902038574

Epoch: 5| Step: 2
Training loss: 0.44958192110061646
Validation loss: 2.0780695229768753

Epoch: 5| Step: 3
Training loss: 0.5530925989151001
Validation loss: 2.0768870810667672

Epoch: 5| Step: 4
Training loss: 0.24835050106048584
Validation loss: 2.071572482585907

Epoch: 5| Step: 5
Training loss: 0.3251708149909973
Validation loss: 2.065692961215973

Epoch: 5| Step: 6
Training loss: 0.33498167991638184
Validation loss: 2.1043308873971305

Epoch: 5| Step: 7
Training loss: 0.37976810336112976
Validation loss: 2.07601564625899

Epoch: 5| Step: 8
Training loss: 0.26700320839881897
Validation loss: 2.096365913748741

Epoch: 5| Step: 9
Training loss: 0.3078373074531555
Validation loss: 2.072438215216001

Epoch: 5| Step: 10
Training loss: 0.43375086784362793
Validation loss: 2.037633483608564

Epoch: 5| Step: 11
Training loss: 0.35152947902679443
Validation loss: 2.0642285297314324

Epoch: 317| Step: 0
Training loss: 0.3437897562980652
Validation loss: 2.1070078710714975

Epoch: 5| Step: 1
Training loss: 0.3843630254268646
Validation loss: 2.1247535149256387

Epoch: 5| Step: 2
Training loss: 0.2797855734825134
Validation loss: 2.1458677301804223

Epoch: 5| Step: 3
Training loss: 0.3163277506828308
Validation loss: 2.0882817804813385

Epoch: 5| Step: 4
Training loss: 0.39439207315444946
Validation loss: 2.059596116344134

Epoch: 5| Step: 5
Training loss: 0.38446444272994995
Validation loss: 2.063603197534879

Epoch: 5| Step: 6
Training loss: 0.2663131654262543
Validation loss: 2.056094522277514

Epoch: 5| Step: 7
Training loss: 0.5912669897079468
Validation loss: 2.0998100340366364

Epoch: 5| Step: 8
Training loss: 0.4401962161064148
Validation loss: 2.062916934490204

Epoch: 5| Step: 9
Training loss: 0.326895147562027
Validation loss: 2.071676567196846

Epoch: 5| Step: 10
Training loss: 0.5316389799118042
Validation loss: 2.0612101604541144

Epoch: 5| Step: 11
Training loss: 0.2109871506690979
Validation loss: 2.108613799015681

Epoch: 318| Step: 0
Training loss: 0.5759967565536499
Validation loss: 2.074544390042623

Epoch: 5| Step: 1
Training loss: 0.4396391808986664
Validation loss: 2.0847615053256354

Epoch: 5| Step: 2
Training loss: 0.2728169858455658
Validation loss: 2.089003026485443

Epoch: 5| Step: 3
Training loss: 0.4971272945404053
Validation loss: 2.083479180932045

Epoch: 5| Step: 4
Training loss: 0.4255198836326599
Validation loss: 2.0604849656422934

Epoch: 5| Step: 5
Training loss: 0.49966496229171753
Validation loss: 2.054273560643196

Epoch: 5| Step: 6
Training loss: 0.45537328720092773
Validation loss: 2.057622546950976

Epoch: 5| Step: 7
Training loss: 0.2322189062833786
Validation loss: 2.05396331846714

Epoch: 5| Step: 8
Training loss: 0.18884862959384918
Validation loss: 2.0788834393024445

Epoch: 5| Step: 9
Training loss: 0.25514188408851624
Validation loss: 2.101461480061213

Epoch: 5| Step: 10
Training loss: 0.24754580855369568
Validation loss: 2.0783234238624573

Epoch: 5| Step: 11
Training loss: 0.2858033776283264
Validation loss: 2.041309421261152

Epoch: 319| Step: 0
Training loss: 0.430504709482193
Validation loss: 2.0721297015746436

Epoch: 5| Step: 1
Training loss: 0.40071430802345276
Validation loss: 2.0925084253152213

Epoch: 5| Step: 2
Training loss: 0.1559368222951889
Validation loss: 2.0988201051950455

Epoch: 5| Step: 3
Training loss: 0.36088353395462036
Validation loss: 2.0570843617121377

Epoch: 5| Step: 4
Training loss: 0.4843042492866516
Validation loss: 2.0439128826061883

Epoch: 5| Step: 5
Training loss: 0.3025802969932556
Validation loss: 2.1111534039179483

Epoch: 5| Step: 6
Training loss: 0.2424558401107788
Validation loss: 2.082498167951902

Epoch: 5| Step: 7
Training loss: 0.594273567199707
Validation loss: 2.0403946141401925

Epoch: 5| Step: 8
Training loss: 0.2670868933200836
Validation loss: 2.0469830681880317

Epoch: 5| Step: 9
Training loss: 0.3747556209564209
Validation loss: 2.0381434907515845

Epoch: 5| Step: 10
Training loss: 0.41183751821517944
Validation loss: 2.076276734471321

Epoch: 5| Step: 11
Training loss: 0.16043682396411896
Validation loss: 2.0694288313388824

Epoch: 320| Step: 0
Training loss: 0.315455824136734
Validation loss: 2.021025871237119

Epoch: 5| Step: 1
Training loss: 0.5356366038322449
Validation loss: 2.0601453681786857

Epoch: 5| Step: 2
Training loss: 0.3455530107021332
Validation loss: 2.087174872557322

Epoch: 5| Step: 3
Training loss: 0.4080859124660492
Validation loss: 2.100257361928622

Epoch: 5| Step: 4
Training loss: 0.3688501715660095
Validation loss: 2.1181220958630242

Epoch: 5| Step: 5
Training loss: 0.39614009857177734
Validation loss: 2.083490009109179

Epoch: 5| Step: 6
Training loss: 0.2273969203233719
Validation loss: 2.1052134186029434

Epoch: 5| Step: 7
Training loss: 0.5470593571662903
Validation loss: 2.0675720870494843

Epoch: 5| Step: 8
Training loss: 0.25676387548446655
Validation loss: 2.0634140421946845

Epoch: 5| Step: 9
Training loss: 0.34087952971458435
Validation loss: 2.1283225814501443

Epoch: 5| Step: 10
Training loss: 0.2688753604888916
Validation loss: 2.070993736386299

Epoch: 5| Step: 11
Training loss: 0.26998212933540344
Validation loss: 2.0783293892939887

Epoch: 321| Step: 0
Training loss: 0.2984045445919037
Validation loss: 2.057299410303434

Epoch: 5| Step: 1
Training loss: 0.27325859665870667
Validation loss: 2.067790389060974

Epoch: 5| Step: 2
Training loss: 0.32424646615982056
Validation loss: 2.119388480981191

Epoch: 5| Step: 3
Training loss: 0.40014538168907166
Validation loss: 2.079504579305649

Epoch: 5| Step: 4
Training loss: 0.26314520835876465
Validation loss: 2.0482763051986694

Epoch: 5| Step: 5
Training loss: 0.5282546877861023
Validation loss: 2.124157095948855

Epoch: 5| Step: 6
Training loss: 0.21406877040863037
Validation loss: 2.138772095243136

Epoch: 5| Step: 7
Training loss: 0.29301637411117554
Validation loss: 2.1600520263115564

Epoch: 5| Step: 8
Training loss: 0.8019291162490845
Validation loss: 2.119820073246956

Epoch: 5| Step: 9
Training loss: 0.2991858422756195
Validation loss: 2.0962846825520196

Epoch: 5| Step: 10
Training loss: 0.3738831877708435
Validation loss: 2.1263698041439056

Epoch: 5| Step: 11
Training loss: 0.47886091470718384
Validation loss: 2.060128221909205

Epoch: 322| Step: 0
Training loss: 0.24408134818077087
Validation loss: 2.1115366965532303

Epoch: 5| Step: 1
Training loss: 0.48597249388694763
Validation loss: 2.106503407160441

Epoch: 5| Step: 2
Training loss: 0.6881195902824402
Validation loss: 2.0636176665623984

Epoch: 5| Step: 3
Training loss: 0.41560688614845276
Validation loss: 2.1149091670910516

Epoch: 5| Step: 4
Training loss: 0.37222278118133545
Validation loss: 2.0157790134350457

Epoch: 5| Step: 5
Training loss: 0.3342241644859314
Validation loss: 2.079224099715551

Epoch: 5| Step: 6
Training loss: 0.24386052787303925
Validation loss: 2.0854915330807366

Epoch: 5| Step: 7
Training loss: 0.38717907667160034
Validation loss: 2.098160684108734

Epoch: 5| Step: 8
Training loss: 0.3770214915275574
Validation loss: 2.1097653657197952

Epoch: 5| Step: 9
Training loss: 0.405783474445343
Validation loss: 2.108056515455246

Epoch: 5| Step: 10
Training loss: 0.49738508462905884
Validation loss: 2.098677729566892

Epoch: 5| Step: 11
Training loss: 0.23530328273773193
Validation loss: 2.1049198359251022

Epoch: 323| Step: 0
Training loss: 0.4567830562591553
Validation loss: 2.051259160041809

Epoch: 5| Step: 1
Training loss: 0.30520790815353394
Validation loss: 2.080247407158216

Epoch: 5| Step: 2
Training loss: 0.18416522443294525
Validation loss: 2.0933201213677726

Epoch: 5| Step: 3
Training loss: 0.3681005835533142
Validation loss: 2.112239718437195

Epoch: 5| Step: 4
Training loss: 0.29771026968955994
Validation loss: 2.082783649365107

Epoch: 5| Step: 5
Training loss: 0.30888307094573975
Validation loss: 2.0559390981992087

Epoch: 5| Step: 6
Training loss: 0.19093170762062073
Validation loss: 2.082755063970884

Epoch: 5| Step: 7
Training loss: 0.5533060431480408
Validation loss: 2.052612101038297

Epoch: 5| Step: 8
Training loss: 0.19855542480945587
Validation loss: 2.074702963232994

Epoch: 5| Step: 9
Training loss: 0.29746198654174805
Validation loss: 2.071213255325953

Epoch: 5| Step: 10
Training loss: 0.7517654299736023
Validation loss: 2.0701882988214493

Epoch: 5| Step: 11
Training loss: 0.27521324157714844
Validation loss: 2.087593133250872

Epoch: 324| Step: 0
Training loss: 0.26085585355758667
Validation loss: 2.0620037019252777

Epoch: 5| Step: 1
Training loss: 0.5944989919662476
Validation loss: 2.0309266795714698

Epoch: 5| Step: 2
Training loss: 0.4430411756038666
Validation loss: 2.041751737395922

Epoch: 5| Step: 3
Training loss: 0.3287714421749115
Validation loss: 2.051188955704371

Epoch: 5| Step: 4
Training loss: 0.2670401334762573
Validation loss: 2.062104493379593

Epoch: 5| Step: 5
Training loss: 0.6261906623840332
Validation loss: 2.095562150080999

Epoch: 5| Step: 6
Training loss: 0.24778799712657928
Validation loss: 2.1049237847328186

Epoch: 5| Step: 7
Training loss: 0.19606801867485046
Validation loss: 2.0869490057229996

Epoch: 5| Step: 8
Training loss: 0.3462476432323456
Validation loss: 2.0851818919181824

Epoch: 5| Step: 9
Training loss: 0.3064813017845154
Validation loss: 2.103902821739515

Epoch: 5| Step: 10
Training loss: 0.38996273279190063
Validation loss: 2.087822124361992

Epoch: 5| Step: 11
Training loss: 0.13850164413452148
Validation loss: 2.0619697074095407

Epoch: 325| Step: 0
Training loss: 0.3244590759277344
Validation loss: 2.068448916077614

Epoch: 5| Step: 1
Training loss: 0.29301247000694275
Validation loss: 2.0863909671703973

Epoch: 5| Step: 2
Training loss: 0.3763575851917267
Validation loss: 2.0607944279909134

Epoch: 5| Step: 3
Training loss: 0.3370893895626068
Validation loss: 2.0501468231280646

Epoch: 5| Step: 4
Training loss: 0.2884017825126648
Validation loss: 2.087946966290474

Epoch: 5| Step: 5
Training loss: 0.4046206474304199
Validation loss: 2.0783163060744605

Epoch: 5| Step: 6
Training loss: 0.5239244699478149
Validation loss: 2.08901047706604

Epoch: 5| Step: 7
Training loss: 0.37361475825309753
Validation loss: 2.1160655319690704

Epoch: 5| Step: 8
Training loss: 0.6149013042449951
Validation loss: 2.084599186976751

Epoch: 5| Step: 9
Training loss: 0.3892844319343567
Validation loss: 2.063837026556333

Epoch: 5| Step: 10
Training loss: 0.3565770387649536
Validation loss: 2.074264109134674

Epoch: 5| Step: 11
Training loss: 0.18197575211524963
Validation loss: 2.053501918911934

Epoch: 326| Step: 0
Training loss: 0.46844616532325745
Validation loss: 2.0543206483125687

Epoch: 5| Step: 1
Training loss: 0.4610850214958191
Validation loss: 2.044763875504335

Epoch: 5| Step: 2
Training loss: 0.2907036542892456
Validation loss: 2.094742273290952

Epoch: 5| Step: 3
Training loss: 0.3489108681678772
Validation loss: 2.0829643358786902

Epoch: 5| Step: 4
Training loss: 0.17069199681282043
Validation loss: 2.09150164326032

Epoch: 5| Step: 5
Training loss: 0.28569212555885315
Validation loss: 2.0761899650096893

Epoch: 5| Step: 6
Training loss: 0.5946531891822815
Validation loss: 2.128411943713824

Epoch: 5| Step: 7
Training loss: 0.3037911355495453
Validation loss: 2.0887845108906427

Epoch: 5| Step: 8
Training loss: 0.3544932007789612
Validation loss: 2.095858429869016

Epoch: 5| Step: 9
Training loss: 0.2510867118835449
Validation loss: 2.0414521793524423

Epoch: 5| Step: 10
Training loss: 0.5512259006500244
Validation loss: 2.068039963642756

Epoch: 5| Step: 11
Training loss: 0.5047169923782349
Validation loss: 2.049594963590304

Epoch: 327| Step: 0
Training loss: 0.45536571741104126
Validation loss: 2.0583898623784385

Epoch: 5| Step: 1
Training loss: 0.5258171558380127
Validation loss: 2.049601763486862

Epoch: 5| Step: 2
Training loss: 0.2817024886608124
Validation loss: 2.1080764482418695

Epoch: 5| Step: 3
Training loss: 0.5800239443778992
Validation loss: 2.076212078332901

Epoch: 5| Step: 4
Training loss: 0.29457852244377136
Validation loss: 2.1130647559960685

Epoch: 5| Step: 5
Training loss: 0.3109656274318695
Validation loss: 2.119892338911692

Epoch: 5| Step: 6
Training loss: 0.1822291612625122
Validation loss: 2.142108271519343

Epoch: 5| Step: 7
Training loss: 0.45242518186569214
Validation loss: 2.1498222053050995

Epoch: 5| Step: 8
Training loss: 0.2499409019947052
Validation loss: 2.1125636299451194

Epoch: 5| Step: 9
Training loss: 0.27232182025909424
Validation loss: 2.158063843846321

Epoch: 5| Step: 10
Training loss: 0.4415341019630432
Validation loss: 2.1337058444817862

Epoch: 5| Step: 11
Training loss: 0.5133947730064392
Validation loss: 2.168396770954132

Epoch: 328| Step: 0
Training loss: 0.4408118724822998
Validation loss: 2.170540397365888

Epoch: 5| Step: 1
Training loss: 0.3977534770965576
Validation loss: 2.1187909642855325

Epoch: 5| Step: 2
Training loss: 0.3938771188259125
Validation loss: 2.0844521671533585

Epoch: 5| Step: 3
Training loss: 0.2824379801750183
Validation loss: 2.1159278402725854

Epoch: 5| Step: 4
Training loss: 0.3735889196395874
Validation loss: 2.082744533816973

Epoch: 5| Step: 5
Training loss: 0.31663382053375244
Validation loss: 2.103387882312139

Epoch: 5| Step: 6
Training loss: 0.19340477883815765
Validation loss: 2.0670680105686188

Epoch: 5| Step: 7
Training loss: 0.7216264009475708
Validation loss: 2.030623475710551

Epoch: 5| Step: 8
Training loss: 0.36780351400375366
Validation loss: 2.0673251946767173

Epoch: 5| Step: 9
Training loss: 0.15897516906261444
Validation loss: 2.0800539950529733

Epoch: 5| Step: 10
Training loss: 0.2136925756931305
Validation loss: 2.1551765700181327

Epoch: 5| Step: 11
Training loss: 1.1347885131835938
Validation loss: 2.1494789322217307

Epoch: 329| Step: 0
Training loss: 0.3945161700248718
Validation loss: 2.1393785824378333

Epoch: 5| Step: 1
Training loss: 0.3821044862270355
Validation loss: 2.150431747237841

Epoch: 5| Step: 2
Training loss: 0.4183262884616852
Validation loss: 2.122768133878708

Epoch: 5| Step: 3
Training loss: 0.2873130738735199
Validation loss: 2.1406701306502023

Epoch: 5| Step: 4
Training loss: 0.585763156414032
Validation loss: 2.1133823543787003

Epoch: 5| Step: 5
Training loss: 0.2669092118740082
Validation loss: 2.0732451528310776

Epoch: 5| Step: 6
Training loss: 0.28939634561538696
Validation loss: 2.0949038664499917

Epoch: 5| Step: 7
Training loss: 0.5048457980155945
Validation loss: 2.0816859751939774

Epoch: 5| Step: 8
Training loss: 0.6514740586280823
Validation loss: 2.1392149229844413

Epoch: 5| Step: 9
Training loss: 0.4101502299308777
Validation loss: 2.0982228020826974

Epoch: 5| Step: 10
Training loss: 0.26345038414001465
Validation loss: 2.0851426968971887

Epoch: 5| Step: 11
Training loss: 0.32361066341400146
Validation loss: 2.0693438748518624

Epoch: 330| Step: 0
Training loss: 0.25251367688179016
Validation loss: 2.1219797929128013

Epoch: 5| Step: 1
Training loss: 0.39357897639274597
Validation loss: 2.132979636391004

Epoch: 5| Step: 2
Training loss: 0.34914493560791016
Validation loss: 2.1082810163497925

Epoch: 5| Step: 3
Training loss: 0.27478185296058655
Validation loss: 2.0938084572553635

Epoch: 5| Step: 4
Training loss: 0.2998914420604706
Validation loss: 2.1077944139639535

Epoch: 5| Step: 5
Training loss: 0.3178837299346924
Validation loss: 2.064383253455162

Epoch: 5| Step: 6
Training loss: 0.6577767133712769
Validation loss: 2.0619941602150598

Epoch: 5| Step: 7
Training loss: 0.23357529938220978
Validation loss: 2.096261332432429

Epoch: 5| Step: 8
Training loss: 0.4849328100681305
Validation loss: 2.0212371001640954

Epoch: 5| Step: 9
Training loss: 0.44680356979370117
Validation loss: 2.0327550768852234

Epoch: 5| Step: 10
Training loss: 0.5686962008476257
Validation loss: 2.0462055255969367

Epoch: 5| Step: 11
Training loss: 0.2424454391002655
Validation loss: 2.0582416405280433

Epoch: 331| Step: 0
Training loss: 0.4170827269554138
Validation loss: 2.0817187428474426

Epoch: 5| Step: 1
Training loss: 0.3326775133609772
Validation loss: 2.139764984448751

Epoch: 5| Step: 2
Training loss: 0.3156247138977051
Validation loss: 2.0600801010926566

Epoch: 5| Step: 3
Training loss: 0.6028797030448914
Validation loss: 2.0955073138078055

Epoch: 5| Step: 4
Training loss: 0.25349336862564087
Validation loss: 2.0917393565177917

Epoch: 5| Step: 5
Training loss: 0.4918915331363678
Validation loss: 2.0584420561790466

Epoch: 5| Step: 6
Training loss: 0.2641115188598633
Validation loss: 2.064699500799179

Epoch: 5| Step: 7
Training loss: 0.28872543573379517
Validation loss: 2.0465726107358932

Epoch: 5| Step: 8
Training loss: 0.23102793097496033
Validation loss: 2.060744355122248

Epoch: 5| Step: 9
Training loss: 0.19634728133678436
Validation loss: 2.1013001998265586

Epoch: 5| Step: 10
Training loss: 0.41808953881263733
Validation loss: 2.088542014360428

Epoch: 5| Step: 11
Training loss: 1.0330018997192383
Validation loss: 2.0755258947610855

Epoch: 332| Step: 0
Training loss: 0.36233800649642944
Validation loss: 2.107744370897611

Epoch: 5| Step: 1
Training loss: 0.27050063014030457
Validation loss: 2.103322853644689

Epoch: 5| Step: 2
Training loss: 0.32415860891342163
Validation loss: 2.049000749985377

Epoch: 5| Step: 3
Training loss: 0.46007657051086426
Validation loss: 2.0473180959622064

Epoch: 5| Step: 4
Training loss: 0.2715282440185547
Validation loss: 2.086288645863533

Epoch: 5| Step: 5
Training loss: 0.4440898895263672
Validation loss: 2.1008282750844955

Epoch: 5| Step: 6
Training loss: 0.3559231758117676
Validation loss: 2.0520776410897574

Epoch: 5| Step: 7
Training loss: 0.47871798276901245
Validation loss: 2.0584940960009894

Epoch: 5| Step: 8
Training loss: 0.6241134405136108
Validation loss: 2.125150114297867

Epoch: 5| Step: 9
Training loss: 0.24383655190467834
Validation loss: 2.1081380248069763

Epoch: 5| Step: 10
Training loss: 0.3332783579826355
Validation loss: 2.1116480082273483

Epoch: 5| Step: 11
Training loss: 0.08644402027130127
Validation loss: 2.079072584708532

Epoch: 333| Step: 0
Training loss: 0.6076604723930359
Validation loss: 2.1165934006373086

Epoch: 5| Step: 1
Training loss: 0.33690160512924194
Validation loss: 2.123419016599655

Epoch: 5| Step: 2
Training loss: 0.2834599018096924
Validation loss: 2.0922084897756577

Epoch: 5| Step: 3
Training loss: 0.3052035868167877
Validation loss: 2.0910754005114236

Epoch: 5| Step: 4
Training loss: 0.3412216305732727
Validation loss: 2.107388506333033

Epoch: 5| Step: 5
Training loss: 0.16989269852638245
Validation loss: 2.0969486832618713

Epoch: 5| Step: 6
Training loss: 0.37381529808044434
Validation loss: 2.097597191731135

Epoch: 5| Step: 7
Training loss: 0.4478607773780823
Validation loss: 2.1301396439472833

Epoch: 5| Step: 8
Training loss: 0.24897512793540955
Validation loss: 2.048219308257103

Epoch: 5| Step: 9
Training loss: 0.6932897567749023
Validation loss: 2.068111707766851

Epoch: 5| Step: 10
Training loss: 0.3434778153896332
Validation loss: 2.0738544861475625

Epoch: 5| Step: 11
Training loss: 0.11838749051094055
Validation loss: 2.1245888769626617

Epoch: 334| Step: 0
Training loss: 0.3511645793914795
Validation loss: 2.20985546708107

Epoch: 5| Step: 1
Training loss: 0.7106488347053528
Validation loss: 2.205376277367274

Epoch: 5| Step: 2
Training loss: 0.4557059705257416
Validation loss: 2.186150615413984

Epoch: 5| Step: 3
Training loss: 0.31267714500427246
Validation loss: 2.15301920970281

Epoch: 5| Step: 4
Training loss: 0.26965802907943726
Validation loss: 2.150775949160258

Epoch: 5| Step: 5
Training loss: 0.3892231583595276
Validation loss: 2.0932889531056085

Epoch: 5| Step: 6
Training loss: 0.27924054861068726
Validation loss: 2.1177735924720764

Epoch: 5| Step: 7
Training loss: 0.3638915419578552
Validation loss: 2.139830599228541

Epoch: 5| Step: 8
Training loss: 0.3556443154811859
Validation loss: 2.100143556793531

Epoch: 5| Step: 9
Training loss: 0.1781194657087326
Validation loss: 2.1274488270282745

Epoch: 5| Step: 10
Training loss: 0.2854855954647064
Validation loss: 2.1002047260602317

Epoch: 5| Step: 11
Training loss: 0.17880737781524658
Validation loss: 2.1268901278575263

Epoch: 335| Step: 0
Training loss: 0.6413415670394897
Validation loss: 2.1027448773384094

Epoch: 5| Step: 1
Training loss: 0.41502150893211365
Validation loss: 2.080245723327001

Epoch: 5| Step: 2
Training loss: 0.26513761281967163
Validation loss: 2.0587683071692786

Epoch: 5| Step: 3
Training loss: 0.39156824350357056
Validation loss: 2.093631406625112

Epoch: 5| Step: 4
Training loss: 0.38532212376594543
Validation loss: 2.0605116387208304

Epoch: 5| Step: 5
Training loss: 0.23101100325584412
Validation loss: 2.096744974454244

Epoch: 5| Step: 6
Training loss: 0.36060774326324463
Validation loss: 2.0946272214253745

Epoch: 5| Step: 7
Training loss: 0.5521410703659058
Validation loss: 2.147122025489807

Epoch: 5| Step: 8
Training loss: 0.28765347599983215
Validation loss: 2.109166368842125

Epoch: 5| Step: 9
Training loss: 0.32278555631637573
Validation loss: 2.1323945273955665

Epoch: 5| Step: 10
Training loss: 0.446479469537735
Validation loss: 2.0547274351119995

Epoch: 5| Step: 11
Training loss: 0.09160913527011871
Validation loss: 2.0680450101693473

Epoch: 336| Step: 0
Training loss: 0.5798293352127075
Validation loss: 2.089917153120041

Epoch: 5| Step: 1
Training loss: 0.46751242876052856
Validation loss: 2.0540121495723724

Epoch: 5| Step: 2
Training loss: 0.4905708432197571
Validation loss: 2.0833302587270737

Epoch: 5| Step: 3
Training loss: 0.30275729298591614
Validation loss: 2.016959731777509

Epoch: 5| Step: 4
Training loss: 0.2955186367034912
Validation loss: 2.0166493554910025

Epoch: 5| Step: 5
Training loss: 0.14112842082977295
Validation loss: 2.043922374645869

Epoch: 5| Step: 6
Training loss: 0.41166362166404724
Validation loss: 2.03738963107268

Epoch: 5| Step: 7
Training loss: 0.2631146311759949
Validation loss: 2.0663207918405533

Epoch: 5| Step: 8
Training loss: 0.38041040301322937
Validation loss: 2.039063254992167

Epoch: 5| Step: 9
Training loss: 0.4394306242465973
Validation loss: 2.061976636449496

Epoch: 5| Step: 10
Training loss: 0.2956292927265167
Validation loss: 2.0430368880430856

Epoch: 5| Step: 11
Training loss: 0.14649620652198792
Validation loss: 2.078290676077207

Epoch: 337| Step: 0
Training loss: 0.41486406326293945
Validation loss: 2.078087195754051

Epoch: 5| Step: 1
Training loss: 0.376178115606308
Validation loss: 2.0342827985684075

Epoch: 5| Step: 2
Training loss: 0.24550411105155945
Validation loss: 2.087706372141838

Epoch: 5| Step: 3
Training loss: 0.28587642312049866
Validation loss: 2.050762335459391

Epoch: 5| Step: 4
Training loss: 0.5516476035118103
Validation loss: 2.0791600942611694

Epoch: 5| Step: 5
Training loss: 0.5024690628051758
Validation loss: 2.1061362077792487

Epoch: 5| Step: 6
Training loss: 0.3710538446903229
Validation loss: 2.110117495059967

Epoch: 5| Step: 7
Training loss: 0.24005623161792755
Validation loss: 2.101436456044515

Epoch: 5| Step: 8
Training loss: 0.3244495391845703
Validation loss: 2.128305291136106

Epoch: 5| Step: 9
Training loss: 0.20372486114501953
Validation loss: 2.164879232645035

Epoch: 5| Step: 10
Training loss: 0.2834715247154236
Validation loss: 2.090227872133255

Epoch: 5| Step: 11
Training loss: 0.2896745204925537
Validation loss: 2.0762631396452584

Epoch: 338| Step: 0
Training loss: 0.49813365936279297
Validation loss: 2.13076651096344

Epoch: 5| Step: 1
Training loss: 0.29150038957595825
Validation loss: 2.127829392751058

Epoch: 5| Step: 2
Training loss: 0.4355227053165436
Validation loss: 2.067203069726626

Epoch: 5| Step: 3
Training loss: 0.37908151745796204
Validation loss: 2.0544763952493668

Epoch: 5| Step: 4
Training loss: 0.17339807748794556
Validation loss: 2.087036654353142

Epoch: 5| Step: 5
Training loss: 0.5952490568161011
Validation loss: 2.0770561595757804

Epoch: 5| Step: 6
Training loss: 0.3425944745540619
Validation loss: 2.1155518690745034

Epoch: 5| Step: 7
Training loss: 0.3843596577644348
Validation loss: 2.130021651585897

Epoch: 5| Step: 8
Training loss: 0.21770262718200684
Validation loss: 2.105103015899658

Epoch: 5| Step: 9
Training loss: 0.35543981194496155
Validation loss: 2.105216681957245

Epoch: 5| Step: 10
Training loss: 0.32745057344436646
Validation loss: 2.077726657191912

Epoch: 5| Step: 11
Training loss: 0.26746994256973267
Validation loss: 2.093300148844719

Epoch: 339| Step: 0
Training loss: 0.6712700128555298
Validation loss: 2.0848543594280877

Epoch: 5| Step: 1
Training loss: 0.31864336133003235
Validation loss: 2.060455178221067

Epoch: 5| Step: 2
Training loss: 0.35190433263778687
Validation loss: 2.0938682357470193

Epoch: 5| Step: 3
Training loss: 0.24743004143238068
Validation loss: 2.06616019209226

Epoch: 5| Step: 4
Training loss: 0.3123247027397156
Validation loss: 2.0951131681601205

Epoch: 5| Step: 5
Training loss: 0.28826433420181274
Validation loss: 2.1122361918290458

Epoch: 5| Step: 6
Training loss: 0.27770015597343445
Validation loss: 2.142162397503853

Epoch: 5| Step: 7
Training loss: 0.3678262233734131
Validation loss: 2.1366298496723175

Epoch: 5| Step: 8
Training loss: 0.5040183067321777
Validation loss: 2.1111387610435486

Epoch: 5| Step: 9
Training loss: 0.6304407715797424
Validation loss: 2.07548488676548

Epoch: 5| Step: 10
Training loss: 0.3127479553222656
Validation loss: 2.073149393002192

Epoch: 5| Step: 11
Training loss: 0.43429046869277954
Validation loss: 2.080453018347422

Epoch: 340| Step: 0
Training loss: 0.24942906200885773
Validation loss: 2.0469194054603577

Epoch: 5| Step: 1
Training loss: 0.7099030613899231
Validation loss: 2.0524367541074753

Epoch: 5| Step: 2
Training loss: 0.3347874879837036
Validation loss: 2.0988244265317917

Epoch: 5| Step: 3
Training loss: 0.18524131178855896
Validation loss: 2.1212391704320908

Epoch: 5| Step: 4
Training loss: 0.3504928648471832
Validation loss: 2.127347985903422

Epoch: 5| Step: 5
Training loss: 0.6521114110946655
Validation loss: 2.120519126454989

Epoch: 5| Step: 6
Training loss: 0.30108776688575745
Validation loss: 2.1416817903518677

Epoch: 5| Step: 7
Training loss: 0.21309228241443634
Validation loss: 2.1605059852202735

Epoch: 5| Step: 8
Training loss: 0.3637257218360901
Validation loss: 2.067893629272779

Epoch: 5| Step: 9
Training loss: 0.2444111853837967
Validation loss: 2.0519550939400992

Epoch: 5| Step: 10
Training loss: 0.39904770255088806
Validation loss: 2.0920930802822113

Epoch: 5| Step: 11
Training loss: 0.6367337703704834
Validation loss: 2.091990108291308

Epoch: 341| Step: 0
Training loss: 0.1835349202156067
Validation loss: 2.0471172630786896

Epoch: 5| Step: 1
Training loss: 0.17047493159770966
Validation loss: 2.086300785342852

Epoch: 5| Step: 2
Training loss: 0.5283576846122742
Validation loss: 2.1416538059711456

Epoch: 5| Step: 3
Training loss: 0.4150473475456238
Validation loss: 2.0983343621095023

Epoch: 5| Step: 4
Training loss: 0.2756940722465515
Validation loss: 2.0935472498337426

Epoch: 5| Step: 5
Training loss: 0.24578022956848145
Validation loss: 2.1114795207977295

Epoch: 5| Step: 6
Training loss: 0.3841291069984436
Validation loss: 2.092811495065689

Epoch: 5| Step: 7
Training loss: 0.2847570478916168
Validation loss: 2.1043851425250373

Epoch: 5| Step: 8
Training loss: 0.4014284014701843
Validation loss: 2.1048210859298706

Epoch: 5| Step: 9
Training loss: 0.3720827102661133
Validation loss: 2.0696229934692383

Epoch: 5| Step: 10
Training loss: 0.3450189530849457
Validation loss: 2.139050707221031

Epoch: 5| Step: 11
Training loss: 0.3518696427345276
Validation loss: 2.1090719799200692

Epoch: 342| Step: 0
Training loss: 0.39761796593666077
Validation loss: 2.1203570862611136

Epoch: 5| Step: 1
Training loss: 0.2763577699661255
Validation loss: 2.0642054776350656

Epoch: 5| Step: 2
Training loss: 0.3111755847930908
Validation loss: 2.083681215842565

Epoch: 5| Step: 3
Training loss: 0.2574734389781952
Validation loss: 2.0345828533172607

Epoch: 5| Step: 4
Training loss: 0.5100069046020508
Validation loss: 2.084785893559456

Epoch: 5| Step: 5
Training loss: 0.397588312625885
Validation loss: 2.0408499389886856

Epoch: 5| Step: 6
Training loss: 0.29920393228530884
Validation loss: 2.0514439741770425

Epoch: 5| Step: 7
Training loss: 0.5497214198112488
Validation loss: 2.092931071917216

Epoch: 5| Step: 8
Training loss: 0.3695039451122284
Validation loss: 2.1337048610051474

Epoch: 5| Step: 9
Training loss: 0.25373703241348267
Validation loss: 2.132988760868708

Epoch: 5| Step: 10
Training loss: 0.4488123059272766
Validation loss: 2.1315699170033136

Epoch: 5| Step: 11
Training loss: 0.25271499156951904
Validation loss: 2.10897733271122

Epoch: 343| Step: 0
Training loss: 0.41252559423446655
Validation loss: 2.0848253667354584

Epoch: 5| Step: 1
Training loss: 0.4080442488193512
Validation loss: 2.062670504053434

Epoch: 5| Step: 2
Training loss: 0.401375949382782
Validation loss: 2.10586250325044

Epoch: 5| Step: 3
Training loss: 0.227397158741951
Validation loss: 2.11516143878301

Epoch: 5| Step: 4
Training loss: 0.2684982419013977
Validation loss: 2.0880430191755295

Epoch: 5| Step: 5
Training loss: 0.24239817261695862
Validation loss: 2.092153176665306

Epoch: 5| Step: 6
Training loss: 0.1433272510766983
Validation loss: 2.1126726220051446

Epoch: 5| Step: 7
Training loss: 0.2587697505950928
Validation loss: 2.1038356820742288

Epoch: 5| Step: 8
Training loss: 0.5233475565910339
Validation loss: 2.086062182982763

Epoch: 5| Step: 9
Training loss: 0.39954257011413574
Validation loss: 2.101485143105189

Epoch: 5| Step: 10
Training loss: 0.5785729885101318
Validation loss: 2.0991591413815818

Epoch: 5| Step: 11
Training loss: 0.37040090560913086
Validation loss: 2.092672492067019

Epoch: 344| Step: 0
Training loss: 0.24884013831615448
Validation loss: 2.0506116499503455

Epoch: 5| Step: 1
Training loss: 0.6029645800590515
Validation loss: 2.104435761769613

Epoch: 5| Step: 2
Training loss: 0.6158086657524109
Validation loss: 2.122818022966385

Epoch: 5| Step: 3
Training loss: 0.22858719527721405
Validation loss: 2.115127126375834

Epoch: 5| Step: 4
Training loss: 0.3426204025745392
Validation loss: 2.101232200860977

Epoch: 5| Step: 5
Training loss: 0.3052642345428467
Validation loss: 2.088774800300598

Epoch: 5| Step: 6
Training loss: 0.2889884412288666
Validation loss: 2.1364572246869407

Epoch: 5| Step: 7
Training loss: 0.2434135377407074
Validation loss: 2.0594635357459388

Epoch: 5| Step: 8
Training loss: 0.2303944081068039
Validation loss: 2.077036753296852

Epoch: 5| Step: 9
Training loss: 0.31108593940734863
Validation loss: 2.093893364071846

Epoch: 5| Step: 10
Training loss: 0.22998356819152832
Validation loss: 2.0779456893603006

Epoch: 5| Step: 11
Training loss: 0.38888001441955566
Validation loss: 2.0717780143022537

Epoch: 345| Step: 0
Training loss: 0.423926442861557
Validation loss: 2.1468984335660934

Epoch: 5| Step: 1
Training loss: 0.3753429055213928
Validation loss: 2.1726199636856713

Epoch: 5| Step: 2
Training loss: 0.4785751402378082
Validation loss: 2.1344602505366006

Epoch: 5| Step: 3
Training loss: 0.4823770523071289
Validation loss: 2.1329054137070975

Epoch: 5| Step: 4
Training loss: 0.3588379919528961
Validation loss: 2.0772478580474854

Epoch: 5| Step: 5
Training loss: 0.2872523069381714
Validation loss: 2.0928158362706504

Epoch: 5| Step: 6
Training loss: 0.3950211703777313
Validation loss: 2.0708150366942086

Epoch: 5| Step: 7
Training loss: 0.17241474986076355
Validation loss: 2.0433840105930963

Epoch: 5| Step: 8
Training loss: 0.6005409955978394
Validation loss: 2.0852532039086022

Epoch: 5| Step: 9
Training loss: 0.29006609320640564
Validation loss: 2.0826182862122855

Epoch: 5| Step: 10
Training loss: 0.13918694853782654
Validation loss: 2.101810942093531

Epoch: 5| Step: 11
Training loss: 0.5016076564788818
Validation loss: 2.085410326719284

Epoch: 346| Step: 0
Training loss: 0.2830739915370941
Validation loss: 2.108818382024765

Epoch: 5| Step: 1
Training loss: 0.39752691984176636
Validation loss: 2.1190854956706366

Epoch: 5| Step: 2
Training loss: 0.3306046426296234
Validation loss: 2.170794725418091

Epoch: 5| Step: 3
Training loss: 0.43169665336608887
Validation loss: 2.087600057323774

Epoch: 5| Step: 4
Training loss: 0.6087077260017395
Validation loss: 2.093077520529429

Epoch: 5| Step: 5
Training loss: 0.17640769481658936
Validation loss: 2.089335178335508

Epoch: 5| Step: 6
Training loss: 0.2313002049922943
Validation loss: 2.0893751680850983

Epoch: 5| Step: 7
Training loss: 0.3630739748477936
Validation loss: 2.0965674420197806

Epoch: 5| Step: 8
Training loss: 0.5375494956970215
Validation loss: 2.0573839048544564

Epoch: 5| Step: 9
Training loss: 0.30242788791656494
Validation loss: 2.0994720607995987

Epoch: 5| Step: 10
Training loss: 0.27476683259010315
Validation loss: 2.1007084051767984

Epoch: 5| Step: 11
Training loss: 0.7190068960189819
Validation loss: 2.105229208866755

Epoch: 347| Step: 0
Training loss: 0.4566022753715515
Validation loss: 2.122200091679891

Epoch: 5| Step: 1
Training loss: 0.32517188787460327
Validation loss: 2.1327153394619622

Epoch: 5| Step: 2
Training loss: 0.20018163323402405
Validation loss: 2.089492306113243

Epoch: 5| Step: 3
Training loss: 0.21153727173805237
Validation loss: 2.0934227108955383

Epoch: 5| Step: 4
Training loss: 0.29022133350372314
Validation loss: 2.0623620450496674

Epoch: 5| Step: 5
Training loss: 0.3567220866680145
Validation loss: 2.092645823955536

Epoch: 5| Step: 6
Training loss: 0.31262314319610596
Validation loss: 2.116612419486046

Epoch: 5| Step: 7
Training loss: 0.6787940263748169
Validation loss: 2.0461519261201224

Epoch: 5| Step: 8
Training loss: 0.45437154173851013
Validation loss: 2.0665830274422965

Epoch: 5| Step: 9
Training loss: 0.2480231523513794
Validation loss: 2.137496218085289

Epoch: 5| Step: 10
Training loss: 0.3012022376060486
Validation loss: 2.070676808555921

Epoch: 5| Step: 11
Training loss: 0.19960148632526398
Validation loss: 2.1628004958232245

Epoch: 348| Step: 0
Training loss: 0.19030095636844635
Validation loss: 2.083847244580587

Epoch: 5| Step: 1
Training loss: 0.3549467921257019
Validation loss: 2.1177170276641846

Epoch: 5| Step: 2
Training loss: 0.3080991804599762
Validation loss: 2.081111431121826

Epoch: 5| Step: 3
Training loss: 0.3767167329788208
Validation loss: 2.083153193195661

Epoch: 5| Step: 4
Training loss: 0.5077799558639526
Validation loss: 2.1553679953018823

Epoch: 5| Step: 5
Training loss: 0.3028852939605713
Validation loss: 2.0981863737106323

Epoch: 5| Step: 6
Training loss: 0.24345341324806213
Validation loss: 2.1245799561341605

Epoch: 5| Step: 7
Training loss: 0.30543914437294006
Validation loss: 2.1233766128619513

Epoch: 5| Step: 8
Training loss: 0.2216980904340744
Validation loss: 2.1170151829719543

Epoch: 5| Step: 9
Training loss: 0.4347399175167084
Validation loss: 2.1132562855879464

Epoch: 5| Step: 10
Training loss: 0.463357150554657
Validation loss: 2.053331822156906

Epoch: 5| Step: 11
Training loss: 0.11604246497154236
Validation loss: 2.1189359575510025

Epoch: 349| Step: 0
Training loss: 0.23472687602043152
Validation loss: 2.136299639940262

Epoch: 5| Step: 1
Training loss: 0.5136319994926453
Validation loss: 2.1253178119659424

Epoch: 5| Step: 2
Training loss: 0.2336380034685135
Validation loss: 2.11553555727005

Epoch: 5| Step: 3
Training loss: 0.2592962980270386
Validation loss: 2.097288260857264

Epoch: 5| Step: 4
Training loss: 0.31374141573905945
Validation loss: 2.1333178927501044

Epoch: 5| Step: 5
Training loss: 0.32415875792503357
Validation loss: 2.116883620619774

Epoch: 5| Step: 6
Training loss: 0.3924929201602936
Validation loss: 2.086330989996592

Epoch: 5| Step: 7
Training loss: 0.3230695128440857
Validation loss: 2.102729802330335

Epoch: 5| Step: 8
Training loss: 0.3547009527683258
Validation loss: 2.106532762447993

Epoch: 5| Step: 9
Training loss: 0.27792030572891235
Validation loss: 2.143066202600797

Epoch: 5| Step: 10
Training loss: 0.2613760232925415
Validation loss: 2.069268599152565

Epoch: 5| Step: 11
Training loss: 0.6256120204925537
Validation loss: 2.106521119674047

Epoch: 350| Step: 0
Training loss: 0.2764270603656769
Validation loss: 2.0697566171487174

Epoch: 5| Step: 1
Training loss: 0.24135048687458038
Validation loss: 2.089777961373329

Epoch: 5| Step: 2
Training loss: 0.37583646178245544
Validation loss: 2.084962929288546

Epoch: 5| Step: 3
Training loss: 0.23450803756713867
Validation loss: 2.1635261128346124

Epoch: 5| Step: 4
Training loss: 0.295678049325943
Validation loss: 2.1119738668203354

Epoch: 5| Step: 5
Training loss: 0.29465699195861816
Validation loss: 2.146808688839277

Epoch: 5| Step: 6
Training loss: 0.17891892790794373
Validation loss: 2.122602234284083

Epoch: 5| Step: 7
Training loss: 0.21242034435272217
Validation loss: 2.128253092368444

Epoch: 5| Step: 8
Training loss: 0.3361571431159973
Validation loss: 2.1209061294794083

Epoch: 5| Step: 9
Training loss: 0.5554031133651733
Validation loss: 2.111345817645391

Epoch: 5| Step: 10
Training loss: 0.34684520959854126
Validation loss: 2.1024756332238517

Epoch: 5| Step: 11
Training loss: 0.49069350957870483
Validation loss: 2.0934810241063437

Epoch: 351| Step: 0
Training loss: 0.1887165606021881
Validation loss: 2.1411289821068444

Epoch: 5| Step: 1
Training loss: 0.5713761448860168
Validation loss: 2.1188451598087945

Epoch: 5| Step: 2
Training loss: 0.1759212166070938
Validation loss: 2.129371871550878

Epoch: 5| Step: 3
Training loss: 0.1563389003276825
Validation loss: 2.125603144367536

Epoch: 5| Step: 4
Training loss: 0.46619993448257446
Validation loss: 2.085138440132141

Epoch: 5| Step: 5
Training loss: 0.46949300169944763
Validation loss: 2.116908147931099

Epoch: 5| Step: 6
Training loss: 0.21501684188842773
Validation loss: 2.0988365560770035

Epoch: 5| Step: 7
Training loss: 0.3659038543701172
Validation loss: 2.0875098258256912

Epoch: 5| Step: 8
Training loss: 0.352328896522522
Validation loss: 2.1078896075487137

Epoch: 5| Step: 9
Training loss: 0.3454323410987854
Validation loss: 2.112988159060478

Epoch: 5| Step: 10
Training loss: 0.19358158111572266
Validation loss: 2.0962594747543335

Epoch: 5| Step: 11
Training loss: 0.14590221643447876
Validation loss: 2.082382077972094

Epoch: 352| Step: 0
Training loss: 0.18956029415130615
Validation loss: 2.1514103362957635

Epoch: 5| Step: 1
Training loss: 0.35482755303382874
Validation loss: 2.1460117201010385

Epoch: 5| Step: 2
Training loss: 0.2909400463104248
Validation loss: 2.1049948036670685

Epoch: 5| Step: 3
Training loss: 0.31502383947372437
Validation loss: 2.166556864976883

Epoch: 5| Step: 4
Training loss: 0.22059039771556854
Validation loss: 2.1356033782164254

Epoch: 5| Step: 5
Training loss: 0.29199856519699097
Validation loss: 2.1327786346276603

Epoch: 5| Step: 6
Training loss: 0.29196852445602417
Validation loss: 2.1408682564894357

Epoch: 5| Step: 7
Training loss: 0.33920079469680786
Validation loss: 2.0515356908241906

Epoch: 5| Step: 8
Training loss: 0.7163838744163513
Validation loss: 2.1065308352311454

Epoch: 5| Step: 9
Training loss: 0.2448383867740631
Validation loss: 2.0789513240257897

Epoch: 5| Step: 10
Training loss: 0.33724576234817505
Validation loss: 2.097253695130348

Epoch: 5| Step: 11
Training loss: 0.14665573835372925
Validation loss: 2.1261528780062995

Epoch: 353| Step: 0
Training loss: 0.48396939039230347
Validation loss: 2.0667551855246225

Epoch: 5| Step: 1
Training loss: 0.694608747959137
Validation loss: 2.067703197399775

Epoch: 5| Step: 2
Training loss: 0.34226149320602417
Validation loss: 2.1090220361948013

Epoch: 5| Step: 3
Training loss: 0.3399416208267212
Validation loss: 2.13008776307106

Epoch: 5| Step: 4
Training loss: 0.18172726035118103
Validation loss: 2.1075409998496375

Epoch: 5| Step: 5
Training loss: 0.17806285619735718
Validation loss: 2.0713289827108383

Epoch: 5| Step: 6
Training loss: 0.2325836718082428
Validation loss: 2.107922504345576

Epoch: 5| Step: 7
Training loss: 0.30133679509162903
Validation loss: 2.0665577898422876

Epoch: 5| Step: 8
Training loss: 0.20357505977153778
Validation loss: 2.086523393789927

Epoch: 5| Step: 9
Training loss: 0.47358545660972595
Validation loss: 2.0630233188470206

Epoch: 5| Step: 10
Training loss: 0.30830585956573486
Validation loss: 2.114608292778333

Epoch: 5| Step: 11
Training loss: 0.29177361726760864
Validation loss: 2.102995584408442

Epoch: 354| Step: 0
Training loss: 0.3209795653820038
Validation loss: 2.090765287478765

Epoch: 5| Step: 1
Training loss: 0.30607515573501587
Validation loss: 2.0967467625935874

Epoch: 5| Step: 2
Training loss: 0.5362319946289062
Validation loss: 2.081236869096756

Epoch: 5| Step: 3
Training loss: 0.5645195245742798
Validation loss: 2.037450139721235

Epoch: 5| Step: 4
Training loss: 0.5028173923492432
Validation loss: 2.095910166700681

Epoch: 5| Step: 5
Training loss: 0.2539466619491577
Validation loss: 2.0903838723897934

Epoch: 5| Step: 6
Training loss: 0.253173291683197
Validation loss: 2.080396836002668

Epoch: 5| Step: 7
Training loss: 0.5718724727630615
Validation loss: 2.125437652071317

Epoch: 5| Step: 8
Training loss: 0.5938053727149963
Validation loss: 2.1413734952608743

Epoch: 5| Step: 9
Training loss: 0.42863720655441284
Validation loss: 2.16098560889562

Epoch: 5| Step: 10
Training loss: 0.26984283328056335
Validation loss: 2.1368144005537033

Epoch: 5| Step: 11
Training loss: 0.49498093128204346
Validation loss: 2.1006748378276825

Epoch: 355| Step: 0
Training loss: 0.32146263122558594
Validation loss: 2.060422604282697

Epoch: 5| Step: 1
Training loss: 0.25813180208206177
Validation loss: 2.005155841509501

Epoch: 5| Step: 2
Training loss: 0.3978804051876068
Validation loss: 2.0231222609678903

Epoch: 5| Step: 3
Training loss: 0.5204638838768005
Validation loss: 2.0434068689743676

Epoch: 5| Step: 4
Training loss: 0.5892988443374634
Validation loss: 2.0173036406437554

Epoch: 5| Step: 5
Training loss: 0.255838543176651
Validation loss: 2.039891089002291

Epoch: 5| Step: 6
Training loss: 0.22100071609020233
Validation loss: 2.076994170745214

Epoch: 5| Step: 7
Training loss: 0.22260865569114685
Validation loss: 2.0533098727464676

Epoch: 5| Step: 8
Training loss: 0.26651301980018616
Validation loss: 2.1246390839417777

Epoch: 5| Step: 9
Training loss: 0.5294033288955688
Validation loss: 2.129060447216034

Epoch: 5| Step: 10
Training loss: 0.4175534248352051
Validation loss: 2.1205796202023826

Epoch: 5| Step: 11
Training loss: 0.7276892066001892
Validation loss: 2.1252447416385016

Epoch: 356| Step: 0
Training loss: 0.41048479080200195
Validation loss: 2.114807685216268

Epoch: 5| Step: 1
Training loss: 0.4117358326911926
Validation loss: 2.064107437928518

Epoch: 5| Step: 2
Training loss: 0.3982578217983246
Validation loss: 2.0471780598163605

Epoch: 5| Step: 3
Training loss: 0.5943320393562317
Validation loss: 2.078022321065267

Epoch: 5| Step: 4
Training loss: 0.24189619719982147
Validation loss: 2.0566776394844055

Epoch: 5| Step: 5
Training loss: 0.34402069449424744
Validation loss: 2.0390831331411996

Epoch: 5| Step: 6
Training loss: 0.32816654443740845
Validation loss: 2.0851873407761254

Epoch: 5| Step: 7
Training loss: 0.3413543701171875
Validation loss: 2.121299852927526

Epoch: 5| Step: 8
Training loss: 0.2896997332572937
Validation loss: 2.1209652622540793

Epoch: 5| Step: 9
Training loss: 0.2534298896789551
Validation loss: 2.1206060697635016

Epoch: 5| Step: 10
Training loss: 0.4032854437828064
Validation loss: 2.1625404010216394

Epoch: 5| Step: 11
Training loss: 0.16329383850097656
Validation loss: 2.1274630427360535

Epoch: 357| Step: 0
Training loss: 0.2548845112323761
Validation loss: 2.1288225799798965

Epoch: 5| Step: 1
Training loss: 0.3392539620399475
Validation loss: 2.1332171708345413

Epoch: 5| Step: 2
Training loss: 0.353310763835907
Validation loss: 2.0534206430117288

Epoch: 5| Step: 3
Training loss: 0.5761358141899109
Validation loss: 2.0555542459090552

Epoch: 5| Step: 4
Training loss: 0.23860260844230652
Validation loss: 2.0691454857587814

Epoch: 5| Step: 5
Training loss: 0.482536643743515
Validation loss: 2.07102037469546

Epoch: 5| Step: 6
Training loss: 0.3724033832550049
Validation loss: 2.0853064209222794

Epoch: 5| Step: 7
Training loss: 0.36498740315437317
Validation loss: 2.0966312934954963

Epoch: 5| Step: 8
Training loss: 0.3151721954345703
Validation loss: 2.111402233441671

Epoch: 5| Step: 9
Training loss: 0.5242544412612915
Validation loss: 2.126692612965902

Epoch: 5| Step: 10
Training loss: 0.29802894592285156
Validation loss: 2.1121218651533127

Epoch: 5| Step: 11
Training loss: 0.21099308133125305
Validation loss: 2.126978392402331

Epoch: 358| Step: 0
Training loss: 0.25189071893692017
Validation loss: 2.1247320671876273

Epoch: 5| Step: 1
Training loss: 0.3359972834587097
Validation loss: 2.1127617408831916

Epoch: 5| Step: 2
Training loss: 0.39332836866378784
Validation loss: 2.132895772655805

Epoch: 5| Step: 3
Training loss: 0.2276933491230011
Validation loss: 2.093975762526194

Epoch: 5| Step: 4
Training loss: 0.2561523914337158
Validation loss: 2.047159180045128

Epoch: 5| Step: 5
Training loss: 0.4048287272453308
Validation loss: 2.081274926662445

Epoch: 5| Step: 6
Training loss: 0.31408342719078064
Validation loss: 2.0828784654537835

Epoch: 5| Step: 7
Training loss: 0.5131637454032898
Validation loss: 2.0348725269238153

Epoch: 5| Step: 8
Training loss: 0.17337651550769806
Validation loss: 2.105321158965429

Epoch: 5| Step: 9
Training loss: 0.5118763446807861
Validation loss: 2.0843101739883423

Epoch: 5| Step: 10
Training loss: 0.3759872615337372
Validation loss: 2.0405135303735733

Epoch: 5| Step: 11
Training loss: 0.22440850734710693
Validation loss: 2.0477704405784607

Epoch: 359| Step: 0
Training loss: 0.19190248847007751
Validation loss: 2.0909211983283362

Epoch: 5| Step: 1
Training loss: 0.37955400347709656
Validation loss: 2.0540087620417276

Epoch: 5| Step: 2
Training loss: 0.3508736193180084
Validation loss: 2.0821199864149094

Epoch: 5| Step: 3
Training loss: 0.34507235884666443
Validation loss: 2.0961902141571045

Epoch: 5| Step: 4
Training loss: 0.4065828323364258
Validation loss: 2.10074844956398

Epoch: 5| Step: 5
Training loss: 0.2920597195625305
Validation loss: 2.1121492286523185

Epoch: 5| Step: 6
Training loss: 0.20891380310058594
Validation loss: 2.1055223643779755

Epoch: 5| Step: 7
Training loss: 0.31344088912010193
Validation loss: 2.0369854867458344

Epoch: 5| Step: 8
Training loss: 0.3632552921772003
Validation loss: 2.0689932058254876

Epoch: 5| Step: 9
Training loss: 0.33916670083999634
Validation loss: 2.0673036873340607

Epoch: 5| Step: 10
Training loss: 0.6092149615287781
Validation loss: 2.0507125357786813

Epoch: 5| Step: 11
Training loss: 0.41500556468963623
Validation loss: 2.038189043601354

Epoch: 360| Step: 0
Training loss: 0.3240628242492676
Validation loss: 2.0501826157172522

Epoch: 5| Step: 1
Training loss: 0.24147629737854004
Validation loss: 2.0680634627739587

Epoch: 5| Step: 2
Training loss: 0.182158425450325
Validation loss: 2.0700870752334595

Epoch: 5| Step: 3
Training loss: 0.23906108736991882
Validation loss: 2.096971705555916

Epoch: 5| Step: 4
Training loss: 0.2383558303117752
Validation loss: 2.0838906168937683

Epoch: 5| Step: 5
Training loss: 0.502588152885437
Validation loss: 2.135703424612681

Epoch: 5| Step: 6
Training loss: 0.2915678024291992
Validation loss: 2.137674033641815

Epoch: 5| Step: 7
Training loss: 0.38618582487106323
Validation loss: 2.0499431093533835

Epoch: 5| Step: 8
Training loss: 0.39647334814071655
Validation loss: 2.102828229467074

Epoch: 5| Step: 9
Training loss: 0.4263029992580414
Validation loss: 2.090150331457456

Epoch: 5| Step: 10
Training loss: 0.1954587697982788
Validation loss: 2.0881159752607346

Epoch: 5| Step: 11
Training loss: 0.06712514162063599
Validation loss: 2.1303732643524804

Epoch: 361| Step: 0
Training loss: 0.37028712034225464
Validation loss: 2.0509009708960853

Epoch: 5| Step: 1
Training loss: 0.2692287564277649
Validation loss: 2.133582611878713

Epoch: 5| Step: 2
Training loss: 0.5801126956939697
Validation loss: 2.149657944838206

Epoch: 5| Step: 3
Training loss: 0.40668097138404846
Validation loss: 2.175915708144506

Epoch: 5| Step: 4
Training loss: 0.35563358664512634
Validation loss: 2.1241150399049125

Epoch: 5| Step: 5
Training loss: 0.19788038730621338
Validation loss: 2.138352726896604

Epoch: 5| Step: 6
Training loss: 0.15476207435131073
Validation loss: 2.141834835211436

Epoch: 5| Step: 7
Training loss: 0.2589503824710846
Validation loss: 2.1063198298215866

Epoch: 5| Step: 8
Training loss: 0.2367023527622223
Validation loss: 2.1390031973520913

Epoch: 5| Step: 9
Training loss: 0.2739920914173126
Validation loss: 2.1130766719579697

Epoch: 5| Step: 10
Training loss: 0.5696148872375488
Validation loss: 2.1013730665047965

Epoch: 5| Step: 11
Training loss: 0.29898858070373535
Validation loss: 2.092556446790695

Epoch: 362| Step: 0
Training loss: 0.5420328378677368
Validation loss: 2.0995265543460846

Epoch: 5| Step: 1
Training loss: 0.4599696099758148
Validation loss: 2.075790151953697

Epoch: 5| Step: 2
Training loss: 0.32483458518981934
Validation loss: 2.17111437022686

Epoch: 5| Step: 3
Training loss: 0.5528319478034973
Validation loss: 2.1418094436327615

Epoch: 5| Step: 4
Training loss: 0.5536510348320007
Validation loss: 2.1433234065771103

Epoch: 5| Step: 5
Training loss: 0.37020936608314514
Validation loss: 2.1672367801268897

Epoch: 5| Step: 6
Training loss: 0.3404180407524109
Validation loss: 2.1965113431215286

Epoch: 5| Step: 7
Training loss: 0.29463329911231995
Validation loss: 2.115491420030594

Epoch: 5| Step: 8
Training loss: 0.2989347577095032
Validation loss: 2.1068055977423987

Epoch: 5| Step: 9
Training loss: 0.2787806987762451
Validation loss: 2.1125671416521072

Epoch: 5| Step: 10
Training loss: 0.18157382309436798
Validation loss: 2.1468624571959176

Epoch: 5| Step: 11
Training loss: 0.7295772433280945
Validation loss: 2.097929999232292

Epoch: 363| Step: 0
Training loss: 0.37810951471328735
Validation loss: 2.021498680114746

Epoch: 5| Step: 1
Training loss: 0.5135589838027954
Validation loss: 2.0707746744155884

Epoch: 5| Step: 2
Training loss: 0.3282659649848938
Validation loss: 2.1362275977929435

Epoch: 5| Step: 3
Training loss: 0.3595305383205414
Validation loss: 2.0518244951963425

Epoch: 5| Step: 4
Training loss: 0.6049870252609253
Validation loss: 2.1056563009818396

Epoch: 5| Step: 5
Training loss: 0.2930525243282318
Validation loss: 2.088092322150866

Epoch: 5| Step: 6
Training loss: 0.3726022243499756
Validation loss: 2.102596640586853

Epoch: 5| Step: 7
Training loss: 0.5136750936508179
Validation loss: 2.1217775295178094

Epoch: 5| Step: 8
Training loss: 0.45538464188575745
Validation loss: 2.1104250103235245

Epoch: 5| Step: 9
Training loss: 0.21074576675891876
Validation loss: 2.1083670953909555

Epoch: 5| Step: 10
Training loss: 0.22376903891563416
Validation loss: 2.0812013198932013

Epoch: 5| Step: 11
Training loss: 0.07960408926010132
Validation loss: 2.047427773475647

Epoch: 364| Step: 0
Training loss: 0.30710339546203613
Validation loss: 2.0938560167948403

Epoch: 5| Step: 1
Training loss: 0.3232027590274811
Validation loss: 2.065334285298983

Epoch: 5| Step: 2
Training loss: 0.4140739440917969
Validation loss: 2.0264863769213357

Epoch: 5| Step: 3
Training loss: 0.3025370240211487
Validation loss: 2.058074747522672

Epoch: 5| Step: 4
Training loss: 0.43678349256515503
Validation loss: 2.1223025172948837

Epoch: 5| Step: 5
Training loss: 0.26328372955322266
Validation loss: 2.0831570476293564

Epoch: 5| Step: 6
Training loss: 0.41676560044288635
Validation loss: 2.119844009478887

Epoch: 5| Step: 7
Training loss: 0.22162452340126038
Validation loss: 2.1174123833576837

Epoch: 5| Step: 8
Training loss: 0.5730553865432739
Validation loss: 2.0969764441251755

Epoch: 5| Step: 9
Training loss: 0.41062402725219727
Validation loss: 2.086305504043897

Epoch: 5| Step: 10
Training loss: 0.20232060551643372
Validation loss: 2.0891351898511252

Epoch: 5| Step: 11
Training loss: 0.19576317071914673
Validation loss: 2.112064649661382

Epoch: 365| Step: 0
Training loss: 0.40530601143836975
Validation loss: 2.085712045431137

Epoch: 5| Step: 1
Training loss: 0.49532967805862427
Validation loss: 2.084268271923065

Epoch: 5| Step: 2
Training loss: 0.3206307888031006
Validation loss: 2.114459286133448

Epoch: 5| Step: 3
Training loss: 0.2728462815284729
Validation loss: 2.0498446971178055

Epoch: 5| Step: 4
Training loss: 0.1654036045074463
Validation loss: 2.0649651338656745

Epoch: 5| Step: 5
Training loss: 0.29357510805130005
Validation loss: 2.0647324323654175

Epoch: 5| Step: 6
Training loss: 0.2899203896522522
Validation loss: 2.0473603854576745

Epoch: 5| Step: 7
Training loss: 0.5482938289642334
Validation loss: 2.0262892146905265

Epoch: 5| Step: 8
Training loss: 0.42418384552001953
Validation loss: 2.0412529607613883

Epoch: 5| Step: 9
Training loss: 0.24096617102622986
Validation loss: 2.036452685793241

Epoch: 5| Step: 10
Training loss: 0.36469894647598267
Validation loss: 2.054819087187449

Epoch: 5| Step: 11
Training loss: 0.38691461086273193
Validation loss: 2.0561534663041434

Epoch: 366| Step: 0
Training loss: 0.2659885287284851
Validation loss: 2.070205887158712

Epoch: 5| Step: 1
Training loss: 0.23766550421714783
Validation loss: 2.081017250816027

Epoch: 5| Step: 2
Training loss: 0.2980555593967438
Validation loss: 2.1184700379769006

Epoch: 5| Step: 3
Training loss: 0.29915130138397217
Validation loss: 2.104411467909813

Epoch: 5| Step: 4
Training loss: 0.5596325397491455
Validation loss: 2.097317839662234

Epoch: 5| Step: 5
Training loss: 0.16379369795322418
Validation loss: 2.088133762280146

Epoch: 5| Step: 6
Training loss: 0.2687785029411316
Validation loss: 2.0936780323584876

Epoch: 5| Step: 7
Training loss: 0.32012173533439636
Validation loss: 2.0797125895818076

Epoch: 5| Step: 8
Training loss: 0.4866350293159485
Validation loss: 2.073868617415428

Epoch: 5| Step: 9
Training loss: 0.358737975358963
Validation loss: 2.053228805462519

Epoch: 5| Step: 10
Training loss: 0.3744346499443054
Validation loss: 2.0682302763064704

Epoch: 5| Step: 11
Training loss: 0.6564238667488098
Validation loss: 2.1183665990829468

Epoch: 367| Step: 0
Training loss: 0.2646915912628174
Validation loss: 2.139336735010147

Epoch: 5| Step: 1
Training loss: 0.4112325608730316
Validation loss: 2.112780620654424

Epoch: 5| Step: 2
Training loss: 0.30840352177619934
Validation loss: 2.1841634660959244

Epoch: 5| Step: 3
Training loss: 0.24561159312725067
Validation loss: 2.1258494506279626

Epoch: 5| Step: 4
Training loss: 0.2578330934047699
Validation loss: 2.1283821860949197

Epoch: 5| Step: 5
Training loss: 0.2837945818901062
Validation loss: 2.12094875673453

Epoch: 5| Step: 6
Training loss: 0.23707106709480286
Validation loss: 2.09678881863753

Epoch: 5| Step: 7
Training loss: 0.6367183923721313
Validation loss: 2.0954849272966385

Epoch: 5| Step: 8
Training loss: 0.24295754730701447
Validation loss: 2.064092382788658

Epoch: 5| Step: 9
Training loss: 0.1716700941324234
Validation loss: 2.0568546007076898

Epoch: 5| Step: 10
Training loss: 0.3486991226673126
Validation loss: 2.053580259283384

Epoch: 5| Step: 11
Training loss: 0.22030484676361084
Validation loss: 2.059286634127299

Epoch: 368| Step: 0
Training loss: 0.2562636733055115
Validation loss: 2.1031141181786857

Epoch: 5| Step: 1
Training loss: 0.3904578685760498
Validation loss: 2.113475446899732

Epoch: 5| Step: 2
Training loss: 0.42643317580223083
Validation loss: 2.0971533209085464

Epoch: 5| Step: 3
Training loss: 0.3171156346797943
Validation loss: 2.0805386304855347

Epoch: 5| Step: 4
Training loss: 0.3434395492076874
Validation loss: 2.1346545120080314

Epoch: 5| Step: 5
Training loss: 0.26465755701065063
Validation loss: 2.1224012772242227

Epoch: 5| Step: 6
Training loss: 0.21777088940143585
Validation loss: 2.1014794955650964

Epoch: 5| Step: 7
Training loss: 0.24379344284534454
Validation loss: 2.1025211811065674

Epoch: 5| Step: 8
Training loss: 0.2836286425590515
Validation loss: 2.0528298070033393

Epoch: 5| Step: 9
Training loss: 0.3894082009792328
Validation loss: 2.0506898562113443

Epoch: 5| Step: 10
Training loss: 0.7314648628234863
Validation loss: 2.1075072089831033

Epoch: 5| Step: 11
Training loss: 0.21446633338928223
Validation loss: 2.111580287416776

Epoch: 369| Step: 0
Training loss: 0.42147526144981384
Validation loss: 2.0818638453880944

Epoch: 5| Step: 1
Training loss: 0.4534144401550293
Validation loss: 2.0739736358324685

Epoch: 5| Step: 2
Training loss: 0.3104981780052185
Validation loss: 2.1204668283462524

Epoch: 5| Step: 3
Training loss: 0.304034948348999
Validation loss: 2.0856977899869285

Epoch: 5| Step: 4
Training loss: 0.3930101990699768
Validation loss: 2.0962649236122766

Epoch: 5| Step: 5
Training loss: 0.4101133346557617
Validation loss: 2.082944611708323

Epoch: 5| Step: 6
Training loss: 0.20577239990234375
Validation loss: 2.137632300456365

Epoch: 5| Step: 7
Training loss: 0.30307555198669434
Validation loss: 2.065198674798012

Epoch: 5| Step: 8
Training loss: 0.25456684827804565
Validation loss: 2.0892266730467477

Epoch: 5| Step: 9
Training loss: 0.7008602023124695
Validation loss: 2.064177950223287

Epoch: 5| Step: 10
Training loss: 0.4371001124382019
Validation loss: 2.036046822865804

Epoch: 5| Step: 11
Training loss: 0.7558772563934326
Validation loss: 2.093772997458776

Epoch: 370| Step: 0
Training loss: 0.27640360593795776
Validation loss: 2.130869299173355

Epoch: 5| Step: 1
Training loss: 0.23992213606834412
Validation loss: 2.115168645977974

Epoch: 5| Step: 2
Training loss: 0.5093573331832886
Validation loss: 2.158832480510076

Epoch: 5| Step: 3
Training loss: 0.8415893316268921
Validation loss: 2.1214529126882553

Epoch: 5| Step: 4
Training loss: 0.27954620122909546
Validation loss: 2.1269769221544266

Epoch: 5| Step: 5
Training loss: 0.37465012073516846
Validation loss: 2.1283368319272995

Epoch: 5| Step: 6
Training loss: 0.27751994132995605
Validation loss: 2.1173335015773773

Epoch: 5| Step: 7
Training loss: 0.28885218501091003
Validation loss: 2.165252904097239

Epoch: 5| Step: 8
Training loss: 0.1738695204257965
Validation loss: 2.1374571522076926

Epoch: 5| Step: 9
Training loss: 0.22433333098888397
Validation loss: 2.0899397830168405

Epoch: 5| Step: 10
Training loss: 0.30841636657714844
Validation loss: 2.0986338108778

Epoch: 5| Step: 11
Training loss: 0.27212607860565186
Validation loss: 2.1325531055529914

Epoch: 371| Step: 0
Training loss: 0.42963171005249023
Validation loss: 2.118124629060427

Epoch: 5| Step: 1
Training loss: 0.4145173132419586
Validation loss: 2.1158076028029122

Epoch: 5| Step: 2
Training loss: 0.31678205728530884
Validation loss: 2.1324298034111657

Epoch: 5| Step: 3
Training loss: 0.149913489818573
Validation loss: 2.07023523747921

Epoch: 5| Step: 4
Training loss: 0.4314506947994232
Validation loss: 2.125921050707499

Epoch: 5| Step: 5
Training loss: 0.27862006425857544
Validation loss: 2.1342502733071647

Epoch: 5| Step: 6
Training loss: 0.21978659927845
Validation loss: 2.090377355615298

Epoch: 5| Step: 7
Training loss: 0.3138231635093689
Validation loss: 2.111010084549586

Epoch: 5| Step: 8
Training loss: 0.24248047173023224
Validation loss: 2.09306937456131

Epoch: 5| Step: 9
Training loss: 0.30558905005455017
Validation loss: 2.1048569629589715

Epoch: 5| Step: 10
Training loss: 0.5537164211273193
Validation loss: 2.1006203641494117

Epoch: 5| Step: 11
Training loss: 0.15516874194145203
Validation loss: 2.130481392145157

Epoch: 372| Step: 0
Training loss: 0.42891034483909607
Validation loss: 2.089919626712799

Epoch: 5| Step: 1
Training loss: 0.2954334318637848
Validation loss: 2.1548031022151313

Epoch: 5| Step: 2
Training loss: 0.3514619767665863
Validation loss: 2.0822342286507287

Epoch: 5| Step: 3
Training loss: 0.31584984064102173
Validation loss: 2.0499065667390823

Epoch: 5| Step: 4
Training loss: 0.2969277501106262
Validation loss: 2.087297643224398

Epoch: 5| Step: 5
Training loss: 0.22073522210121155
Validation loss: 2.0932468473911285

Epoch: 5| Step: 6
Training loss: 0.6556612849235535
Validation loss: 2.0451944321393967

Epoch: 5| Step: 7
Training loss: 0.34764909744262695
Validation loss: 2.1107228845357895

Epoch: 5| Step: 8
Training loss: 0.22578763961791992
Validation loss: 2.0861529111862183

Epoch: 5| Step: 9
Training loss: 0.35267430543899536
Validation loss: 2.1482834915320077

Epoch: 5| Step: 10
Training loss: 0.2908407151699066
Validation loss: 2.136463006337484

Epoch: 5| Step: 11
Training loss: 0.3475608825683594
Validation loss: 2.1183575292428336

Epoch: 373| Step: 0
Training loss: 0.4065505564212799
Validation loss: 2.058223620057106

Epoch: 5| Step: 1
Training loss: 0.20949192345142365
Validation loss: 2.1098552346229553

Epoch: 5| Step: 2
Training loss: 0.28062182664871216
Validation loss: 2.079977477590243

Epoch: 5| Step: 3
Training loss: 0.18898120522499084
Validation loss: 2.0966075360774994

Epoch: 5| Step: 4
Training loss: 0.4203335642814636
Validation loss: 2.058787057797114

Epoch: 5| Step: 5
Training loss: 0.40929079055786133
Validation loss: 2.140924349427223

Epoch: 5| Step: 6
Training loss: 0.2804777920246124
Validation loss: 2.1122406472762427

Epoch: 5| Step: 7
Training loss: 0.245870441198349
Validation loss: 2.1110717405875525

Epoch: 5| Step: 8
Training loss: 0.3686143457889557
Validation loss: 2.1416118492682776

Epoch: 5| Step: 9
Training loss: 0.23535194993019104
Validation loss: 2.13979209959507

Epoch: 5| Step: 10
Training loss: 0.48773518204689026
Validation loss: 2.148179034392039

Epoch: 5| Step: 11
Training loss: 0.4551559090614319
Validation loss: 2.0665871600310006

Epoch: 374| Step: 0
Training loss: 0.23824305832386017
Validation loss: 2.096131165822347

Epoch: 5| Step: 1
Training loss: 0.24220523238182068
Validation loss: 2.1113726099332175

Epoch: 5| Step: 2
Training loss: 0.22742852568626404
Validation loss: 2.113801529010137

Epoch: 5| Step: 3
Training loss: 0.40881744027137756
Validation loss: 2.122643619775772

Epoch: 5| Step: 4
Training loss: 0.43700942397117615
Validation loss: 2.090527286132177

Epoch: 5| Step: 5
Training loss: 0.4285697042942047
Validation loss: 2.139574165145556

Epoch: 5| Step: 6
Training loss: 0.19941559433937073
Validation loss: 2.178717722495397

Epoch: 5| Step: 7
Training loss: 0.5058307647705078
Validation loss: 2.1316808660825095

Epoch: 5| Step: 8
Training loss: 0.48303014039993286
Validation loss: 2.090299149354299

Epoch: 5| Step: 9
Training loss: 0.24780504405498505
Validation loss: 2.1575478613376617

Epoch: 5| Step: 10
Training loss: 0.32350677251815796
Validation loss: 2.108138009905815

Epoch: 5| Step: 11
Training loss: 0.22880207002162933
Validation loss: 2.1647829016049704

Epoch: 375| Step: 0
Training loss: 0.25210291147232056
Validation loss: 2.1208771417538324

Epoch: 5| Step: 1
Training loss: 0.495696485042572
Validation loss: 2.153079221645991

Epoch: 5| Step: 2
Training loss: 0.42757242918014526
Validation loss: 2.1261300245920816

Epoch: 5| Step: 3
Training loss: 0.19131922721862793
Validation loss: 2.1007683128118515

Epoch: 5| Step: 4
Training loss: 0.416088730096817
Validation loss: 2.1408970654010773

Epoch: 5| Step: 5
Training loss: 0.2761977016925812
Validation loss: 2.0336708078781762

Epoch: 5| Step: 6
Training loss: 0.4064640998840332
Validation loss: 2.0791819045941033

Epoch: 5| Step: 7
Training loss: 0.36910584568977356
Validation loss: 2.104005679488182

Epoch: 5| Step: 8
Training loss: 0.2796950042247772
Validation loss: 2.0960991978645325

Epoch: 5| Step: 9
Training loss: 0.24465540051460266
Validation loss: 2.11853888630867

Epoch: 5| Step: 10
Training loss: 0.20908446609973907
Validation loss: 2.089228247602781

Epoch: 5| Step: 11
Training loss: 0.0936407744884491
Validation loss: 2.073053335150083

Epoch: 376| Step: 0
Training loss: 0.35167962312698364
Validation loss: 2.090891033411026

Epoch: 5| Step: 1
Training loss: 0.32510390877723694
Validation loss: 2.077515368660291

Epoch: 5| Step: 2
Training loss: 0.3343449532985687
Validation loss: 2.0931473126014075

Epoch: 5| Step: 3
Training loss: 0.3261663317680359
Validation loss: 2.0401179045438766

Epoch: 5| Step: 4
Training loss: 0.5725640058517456
Validation loss: 2.0903204878171286

Epoch: 5| Step: 5
Training loss: 0.3649005889892578
Validation loss: 2.058392142256101

Epoch: 5| Step: 6
Training loss: 0.2844650149345398
Validation loss: 2.0535061905781427

Epoch: 5| Step: 7
Training loss: 0.2365419566631317
Validation loss: 2.0584362000226974

Epoch: 5| Step: 8
Training loss: 0.3165725767612457
Validation loss: 2.092335989077886

Epoch: 5| Step: 9
Training loss: 0.2689651548862457
Validation loss: 2.0736185957988105

Epoch: 5| Step: 10
Training loss: 0.5621733665466309
Validation loss: 2.1128401160240173

Epoch: 5| Step: 11
Training loss: 0.22678852081298828
Validation loss: 2.117039213577906

Epoch: 377| Step: 0
Training loss: 0.2304057776927948
Validation loss: 2.053473323583603

Epoch: 5| Step: 1
Training loss: 0.5341873168945312
Validation loss: 2.1492583751678467

Epoch: 5| Step: 2
Training loss: 0.2581859827041626
Validation loss: 2.0768653055032096

Epoch: 5| Step: 3
Training loss: 0.17164352536201477
Validation loss: 2.0922579914331436

Epoch: 5| Step: 4
Training loss: 0.3207896649837494
Validation loss: 2.0854321122169495

Epoch: 5| Step: 5
Training loss: 0.3378147780895233
Validation loss: 2.081789573033651

Epoch: 5| Step: 6
Training loss: 0.43108946084976196
Validation loss: 2.0702165067195892

Epoch: 5| Step: 7
Training loss: 0.36753028631210327
Validation loss: 2.0710655450820923

Epoch: 5| Step: 8
Training loss: 0.584189772605896
Validation loss: 2.0635263522466025

Epoch: 5| Step: 9
Training loss: 0.25234827399253845
Validation loss: 2.067055806517601

Epoch: 5| Step: 10
Training loss: 0.2248735874891281
Validation loss: 2.138327439626058

Epoch: 5| Step: 11
Training loss: 0.30166685581207275
Validation loss: 2.116904318332672

Epoch: 378| Step: 0
Training loss: 0.2735852599143982
Validation loss: 2.156633362174034

Epoch: 5| Step: 1
Training loss: 0.22076332569122314
Validation loss: 2.1282685101032257

Epoch: 5| Step: 2
Training loss: 0.24910804629325867
Validation loss: 2.09615849951903

Epoch: 5| Step: 3
Training loss: 0.3746868669986725
Validation loss: 2.0964595824480057

Epoch: 5| Step: 4
Training loss: 0.2857810854911804
Validation loss: 2.0702084501584372

Epoch: 5| Step: 5
Training loss: 0.37409496307373047
Validation loss: 2.0877459098895392

Epoch: 5| Step: 6
Training loss: 0.21446636319160461
Validation loss: 2.105572387576103

Epoch: 5| Step: 7
Training loss: 0.6116905212402344
Validation loss: 2.1055401066939035

Epoch: 5| Step: 8
Training loss: 0.351939857006073
Validation loss: 2.1678673873345056

Epoch: 5| Step: 9
Training loss: 0.562446117401123
Validation loss: 2.1311352054278054

Epoch: 5| Step: 10
Training loss: 0.28067007660865784
Validation loss: 2.1185310383637748

Epoch: 5| Step: 11
Training loss: 0.13523423671722412
Validation loss: 2.087330420811971

Epoch: 379| Step: 0
Training loss: 0.370163232088089
Validation loss: 2.137675404548645

Epoch: 5| Step: 1
Training loss: 0.2953113913536072
Validation loss: 2.1380283385515213

Epoch: 5| Step: 2
Training loss: 0.2827252447605133
Validation loss: 2.117462714513143

Epoch: 5| Step: 3
Training loss: 0.4972633421421051
Validation loss: 2.112385779619217

Epoch: 5| Step: 4
Training loss: 0.24011757969856262
Validation loss: 2.0932814876238504

Epoch: 5| Step: 5
Training loss: 0.14151613414287567
Validation loss: 2.0588462899128595

Epoch: 5| Step: 6
Training loss: 0.2273653745651245
Validation loss: 2.0619290471076965

Epoch: 5| Step: 7
Training loss: 0.24337176978588104
Validation loss: 2.0665866335233054

Epoch: 5| Step: 8
Training loss: 0.6510682106018066
Validation loss: 2.068924054503441

Epoch: 5| Step: 9
Training loss: 0.23684215545654297
Validation loss: 2.0933637619018555

Epoch: 5| Step: 10
Training loss: 0.29023775458335876
Validation loss: 2.0874122778574624

Epoch: 5| Step: 11
Training loss: 0.22793591022491455
Validation loss: 2.11496269206206

Epoch: 380| Step: 0
Training loss: 0.17756213247776031
Validation loss: 2.0821705758571625

Epoch: 5| Step: 1
Training loss: 0.3234322667121887
Validation loss: 2.1349448611338935

Epoch: 5| Step: 2
Training loss: 0.5308135747909546
Validation loss: 2.074546421567599

Epoch: 5| Step: 3
Training loss: 0.19783639907836914
Validation loss: 2.0875740299622216

Epoch: 5| Step: 4
Training loss: 0.3305841088294983
Validation loss: 2.1352224946022034

Epoch: 5| Step: 5
Training loss: 0.43820279836654663
Validation loss: 2.1599523772795997

Epoch: 5| Step: 6
Training loss: 0.5119763612747192
Validation loss: 2.179702967405319

Epoch: 5| Step: 7
Training loss: 0.2834852337837219
Validation loss: 2.174222265680631

Epoch: 5| Step: 8
Training loss: 0.3285515308380127
Validation loss: 2.1410428086916604

Epoch: 5| Step: 9
Training loss: 0.226811021566391
Validation loss: 2.1231177101532617

Epoch: 5| Step: 10
Training loss: 0.3037666082382202
Validation loss: 2.1466110746065774

Epoch: 5| Step: 11
Training loss: 0.2718381881713867
Validation loss: 2.130635291337967

Epoch: 381| Step: 0
Training loss: 0.250401109457016
Validation loss: 2.11601929863294

Epoch: 5| Step: 1
Training loss: 0.23619452118873596
Validation loss: 2.1509638726711273

Epoch: 5| Step: 2
Training loss: 0.3674590587615967
Validation loss: 2.112480640411377

Epoch: 5| Step: 3
Training loss: 0.6474770903587341
Validation loss: 2.100336785117785

Epoch: 5| Step: 4
Training loss: 0.27104640007019043
Validation loss: 2.103096375862757

Epoch: 5| Step: 5
Training loss: 0.3545496463775635
Validation loss: 2.0829760134220123

Epoch: 5| Step: 6
Training loss: 0.4281851649284363
Validation loss: 2.1074240803718567

Epoch: 5| Step: 7
Training loss: 0.2193221151828766
Validation loss: 2.0903253157933555

Epoch: 5| Step: 8
Training loss: 0.2595222592353821
Validation loss: 2.0718218982219696

Epoch: 5| Step: 9
Training loss: 0.41846418380737305
Validation loss: 2.103620852033297

Epoch: 5| Step: 10
Training loss: 0.29529231786727905
Validation loss: 2.0962612529595694

Epoch: 5| Step: 11
Training loss: 0.08393204212188721
Validation loss: 2.0819188257058463

Epoch: 382| Step: 0
Training loss: 0.2447781264781952
Validation loss: 2.133835052450498

Epoch: 5| Step: 1
Training loss: 0.47516578435897827
Validation loss: 2.0999002208312354

Epoch: 5| Step: 2
Training loss: 0.20692972838878632
Validation loss: 2.0825893729925156

Epoch: 5| Step: 3
Training loss: 0.2622554898262024
Validation loss: 2.07094436387221

Epoch: 5| Step: 4
Training loss: 0.3690769672393799
Validation loss: 2.0466638803482056

Epoch: 5| Step: 5
Training loss: 0.2842491865158081
Validation loss: 2.0855298042297363

Epoch: 5| Step: 6
Training loss: 0.5958202481269836
Validation loss: 2.021562938888868

Epoch: 5| Step: 7
Training loss: 0.47943010926246643
Validation loss: 2.078074127435684

Epoch: 5| Step: 8
Training loss: 0.19989511370658875
Validation loss: 2.1010787735382714

Epoch: 5| Step: 9
Training loss: 0.19824442267417908
Validation loss: 2.0890111724535623

Epoch: 5| Step: 10
Training loss: 0.3404681384563446
Validation loss: 2.0842876384655633

Epoch: 5| Step: 11
Training loss: 0.22422760725021362
Validation loss: 2.0609946896632514

Epoch: 383| Step: 0
Training loss: 0.5151938199996948
Validation loss: 2.066149358948072

Epoch: 5| Step: 1
Training loss: 0.3401605784893036
Validation loss: 2.089700241883596

Epoch: 5| Step: 2
Training loss: 0.22848054766654968
Validation loss: 2.067305008570353

Epoch: 5| Step: 3
Training loss: 0.2935948371887207
Validation loss: 2.048553173740705

Epoch: 5| Step: 4
Training loss: 0.3304770886898041
Validation loss: 2.1008501599232354

Epoch: 5| Step: 5
Training loss: 0.487440288066864
Validation loss: 2.041594475507736

Epoch: 5| Step: 6
Training loss: 0.237972229719162
Validation loss: 2.078509787718455

Epoch: 5| Step: 7
Training loss: 0.27569469809532166
Validation loss: 2.054296091198921

Epoch: 5| Step: 8
Training loss: 0.3960268199443817
Validation loss: 2.09627232948939

Epoch: 5| Step: 9
Training loss: 0.2817860543727875
Validation loss: 2.119633287191391

Epoch: 5| Step: 10
Training loss: 0.41729170083999634
Validation loss: 2.1179148306449256

Epoch: 5| Step: 11
Training loss: 0.2773161828517914
Validation loss: 2.128708412249883

Epoch: 384| Step: 0
Training loss: 0.23441652953624725
Validation loss: 2.0813793490330377

Epoch: 5| Step: 1
Training loss: 0.23716387152671814
Validation loss: 2.0428068389495215

Epoch: 5| Step: 2
Training loss: 0.30502715706825256
Validation loss: 2.06891268491745

Epoch: 5| Step: 3
Training loss: 0.2751613259315491
Validation loss: 2.057034413019816

Epoch: 5| Step: 4
Training loss: 0.3450004458427429
Validation loss: 2.0724448760350547

Epoch: 5| Step: 5
Training loss: 0.2754042446613312
Validation loss: 2.075026045242945

Epoch: 5| Step: 6
Training loss: 0.4800955653190613
Validation loss: 2.1120251466830573

Epoch: 5| Step: 7
Training loss: 0.31241974234580994
Validation loss: 2.125272343556086

Epoch: 5| Step: 8
Training loss: 0.5284168124198914
Validation loss: 2.116923967997233

Epoch: 5| Step: 9
Training loss: 0.5426961183547974
Validation loss: 2.172654390335083

Epoch: 5| Step: 10
Training loss: 0.2704600989818573
Validation loss: 2.1134194284677505

Epoch: 5| Step: 11
Training loss: 0.3649936616420746
Validation loss: 2.1086207032203674

Epoch: 385| Step: 0
Training loss: 0.26488742232322693
Validation loss: 2.0815149446328483

Epoch: 5| Step: 1
Training loss: 0.37885022163391113
Validation loss: 2.036880557735761

Epoch: 5| Step: 2
Training loss: 0.34214481711387634
Validation loss: 2.044135386745135

Epoch: 5| Step: 3
Training loss: 0.3010140657424927
Validation loss: 2.0739421794811883

Epoch: 5| Step: 4
Training loss: 0.40133294463157654
Validation loss: 2.0888414879639945

Epoch: 5| Step: 5
Training loss: 0.47472715377807617
Validation loss: 2.1023367096980414

Epoch: 5| Step: 6
Training loss: 0.42370471358299255
Validation loss: 2.094112445910772

Epoch: 5| Step: 7
Training loss: 0.23135633766651154
Validation loss: 2.109771947065989

Epoch: 5| Step: 8
Training loss: 0.2718454897403717
Validation loss: 2.112468938032786

Epoch: 5| Step: 9
Training loss: 0.3997708857059479
Validation loss: 2.1030380378166833

Epoch: 5| Step: 10
Training loss: 0.2749135494232178
Validation loss: 2.075701783100764

Epoch: 5| Step: 11
Training loss: 0.18479788303375244
Validation loss: 2.052717606226603

Epoch: 386| Step: 0
Training loss: 0.49540916085243225
Validation loss: 2.0413855562607446

Epoch: 5| Step: 1
Training loss: 0.2653585374355316
Validation loss: 2.0327123353878656

Epoch: 5| Step: 2
Training loss: 0.2731136083602905
Validation loss: 2.055084149042765

Epoch: 5| Step: 3
Training loss: 0.5253924131393433
Validation loss: 2.0777013152837753

Epoch: 5| Step: 4
Training loss: 0.37844228744506836
Validation loss: 2.0509749005238214

Epoch: 5| Step: 5
Training loss: 0.21995870769023895
Validation loss: 2.047969246904055

Epoch: 5| Step: 6
Training loss: 0.4409859776496887
Validation loss: 2.0913281440734863

Epoch: 5| Step: 7
Training loss: 0.24883213639259338
Validation loss: 2.0565862506628036

Epoch: 5| Step: 8
Training loss: 0.15333187580108643
Validation loss: 2.0837716162204742

Epoch: 5| Step: 9
Training loss: 0.26746100187301636
Validation loss: 2.1064503143231073

Epoch: 5| Step: 10
Training loss: 0.3305020332336426
Validation loss: 2.058162530263265

Epoch: 5| Step: 11
Training loss: 0.18400275707244873
Validation loss: 2.0660447229941687

Epoch: 387| Step: 0
Training loss: 0.30783724784851074
Validation loss: 2.050324246287346

Epoch: 5| Step: 1
Training loss: 0.28816595673561096
Validation loss: 2.0788121869166694

Epoch: 5| Step: 2
Training loss: 0.24283678829669952
Validation loss: 2.0877279341220856

Epoch: 5| Step: 3
Training loss: 0.26535552740097046
Validation loss: 2.10180656115214

Epoch: 5| Step: 4
Training loss: 0.3275936245918274
Validation loss: 2.1359710892041526

Epoch: 5| Step: 5
Training loss: 0.22202983498573303
Validation loss: 2.135237986842791

Epoch: 5| Step: 6
Training loss: 0.35587725043296814
Validation loss: 2.1095414658387504

Epoch: 5| Step: 7
Training loss: 0.49075549840927124
Validation loss: 2.1237661043802896

Epoch: 5| Step: 8
Training loss: 0.30761271715164185
Validation loss: 2.1139903565247855

Epoch: 5| Step: 9
Training loss: 0.48088207840919495
Validation loss: 2.1036824683348336

Epoch: 5| Step: 10
Training loss: 0.183592289686203
Validation loss: 2.1188574383656182

Epoch: 5| Step: 11
Training loss: 0.14501440525054932
Validation loss: 2.120127340157827

Epoch: 388| Step: 0
Training loss: 0.3882047235965729
Validation loss: 2.109919091065725

Epoch: 5| Step: 1
Training loss: 0.287552148103714
Validation loss: 2.0843680004278817

Epoch: 5| Step: 2
Training loss: 0.6254376173019409
Validation loss: 2.0836814790964127

Epoch: 5| Step: 3
Training loss: 0.4012121558189392
Validation loss: 2.117805004119873

Epoch: 5| Step: 4
Training loss: 0.42027121782302856
Validation loss: 2.0845920393864312

Epoch: 5| Step: 5
Training loss: 0.26635271310806274
Validation loss: 2.144669219851494

Epoch: 5| Step: 6
Training loss: 0.25288286805152893
Validation loss: 2.10188190639019

Epoch: 5| Step: 7
Training loss: 0.2256888449192047
Validation loss: 2.1201356599728265

Epoch: 5| Step: 8
Training loss: 0.19728504121303558
Validation loss: 2.1703863938649497

Epoch: 5| Step: 9
Training loss: 0.20590949058532715
Validation loss: 2.1031103481849036

Epoch: 5| Step: 10
Training loss: 0.31588128209114075
Validation loss: 2.045621241132418

Epoch: 5| Step: 11
Training loss: 0.25736701488494873
Validation loss: 2.0989028066396713

Epoch: 389| Step: 0
Training loss: 0.19827839732170105
Validation loss: 2.087550406654676

Epoch: 5| Step: 1
Training loss: 0.49690788984298706
Validation loss: 2.1087075074513755

Epoch: 5| Step: 2
Training loss: 0.32998383045196533
Validation loss: 2.0539248238007226

Epoch: 5| Step: 3
Training loss: 0.33920395374298096
Validation loss: 2.088417192300161

Epoch: 5| Step: 4
Training loss: 0.4867011606693268
Validation loss: 2.1026510695616403

Epoch: 5| Step: 5
Training loss: 0.35230839252471924
Validation loss: 2.1251386602719626

Epoch: 5| Step: 6
Training loss: 0.2721734046936035
Validation loss: 2.092112590869268

Epoch: 5| Step: 7
Training loss: 0.327435702085495
Validation loss: 2.1335831036170325

Epoch: 5| Step: 8
Training loss: 0.2721324861049652
Validation loss: 2.0629012833038964

Epoch: 5| Step: 9
Training loss: 0.3214239776134491
Validation loss: 2.0450910131136575

Epoch: 5| Step: 10
Training loss: 0.21404555439949036
Validation loss: 2.0325974822044373

Epoch: 5| Step: 11
Training loss: 0.48585090041160583
Validation loss: 2.0284035205841064

Epoch: 390| Step: 0
Training loss: 0.34404367208480835
Validation loss: 2.051911478241285

Epoch: 5| Step: 1
Training loss: 0.25629907846450806
Validation loss: 2.0416987240314484

Epoch: 5| Step: 2
Training loss: 0.6006795167922974
Validation loss: 2.055529236793518

Epoch: 5| Step: 3
Training loss: 0.3251338005065918
Validation loss: 2.033497487505277

Epoch: 5| Step: 4
Training loss: 0.17995299398899078
Validation loss: 2.037627696990967

Epoch: 5| Step: 5
Training loss: 0.21031470596790314
Validation loss: 2.0752625862757363

Epoch: 5| Step: 6
Training loss: 0.2168840616941452
Validation loss: 2.0585842579603195

Epoch: 5| Step: 7
Training loss: 0.24584846198558807
Validation loss: 2.0730785032113395

Epoch: 5| Step: 8
Training loss: 0.35787105560302734
Validation loss: 2.0783682515223822

Epoch: 5| Step: 9
Training loss: 0.4041768014431
Validation loss: 2.0790070245663324

Epoch: 5| Step: 10
Training loss: 0.47261863946914673
Validation loss: 2.0987274001042047

Epoch: 5| Step: 11
Training loss: 0.14749586582183838
Validation loss: 2.1025912314653397

Epoch: 391| Step: 0
Training loss: 0.30242714285850525
Validation loss: 2.091022953391075

Epoch: 5| Step: 1
Training loss: 0.2967694401741028
Validation loss: 2.0875877986351647

Epoch: 5| Step: 2
Training loss: 0.49266916513442993
Validation loss: 2.119341254234314

Epoch: 5| Step: 3
Training loss: 0.24421396851539612
Validation loss: 2.0547478993733725

Epoch: 5| Step: 4
Training loss: 0.4584384560585022
Validation loss: 2.0476043025652566

Epoch: 5| Step: 5
Training loss: 0.256093829870224
Validation loss: 2.1152485559384027

Epoch: 5| Step: 6
Training loss: 0.39332789182662964
Validation loss: 2.075672229131063

Epoch: 5| Step: 7
Training loss: 0.2941102087497711
Validation loss: 2.0969895273447037

Epoch: 5| Step: 8
Training loss: 0.27793723344802856
Validation loss: 2.0880907823642096

Epoch: 5| Step: 9
Training loss: 0.4755846858024597
Validation loss: 2.112436816096306

Epoch: 5| Step: 10
Training loss: 0.34819096326828003
Validation loss: 2.149682660897573

Epoch: 5| Step: 11
Training loss: 0.7003104090690613
Validation loss: 2.1020996967951455

Epoch: 392| Step: 0
Training loss: 0.2627500891685486
Validation loss: 2.1091187546650567

Epoch: 5| Step: 1
Training loss: 0.37955084443092346
Validation loss: 2.129772648215294

Epoch: 5| Step: 2
Training loss: 0.3083590567111969
Validation loss: 2.1231018006801605

Epoch: 5| Step: 3
Training loss: 0.1806967556476593
Validation loss: 2.1033632109562554

Epoch: 5| Step: 4
Training loss: 0.16852648556232452
Validation loss: 2.062785933415095

Epoch: 5| Step: 5
Training loss: 0.6019431948661804
Validation loss: 2.0803937216599784

Epoch: 5| Step: 6
Training loss: 0.2803739011287689
Validation loss: 2.113899201154709

Epoch: 5| Step: 7
Training loss: 0.33680060505867004
Validation loss: 2.0545263638099036

Epoch: 5| Step: 8
Training loss: 0.3758118152618408
Validation loss: 2.0586464603741965

Epoch: 5| Step: 9
Training loss: 0.25119736790657043
Validation loss: 2.0895096013943353

Epoch: 5| Step: 10
Training loss: 0.2660045623779297
Validation loss: 2.078455939888954

Epoch: 5| Step: 11
Training loss: 0.2716407775878906
Validation loss: 2.122292389472326

Epoch: 393| Step: 0
Training loss: 0.2372165471315384
Validation loss: 2.1651064654191337

Epoch: 5| Step: 1
Training loss: 0.3704976439476013
Validation loss: 2.1185998072226844

Epoch: 5| Step: 2
Training loss: 0.3685263991355896
Validation loss: 2.076791321237882

Epoch: 5| Step: 3
Training loss: 0.2969011962413788
Validation loss: 2.126726026336352

Epoch: 5| Step: 4
Training loss: 0.2179374247789383
Validation loss: 2.133628477652868

Epoch: 5| Step: 5
Training loss: 0.19973935186862946
Validation loss: 2.1089961181084314

Epoch: 5| Step: 6
Training loss: 0.17557509243488312
Validation loss: 2.0459263175725937

Epoch: 5| Step: 7
Training loss: 0.3820381760597229
Validation loss: 2.060151149829229

Epoch: 5| Step: 8
Training loss: 0.23815612494945526
Validation loss: 2.037717709938685

Epoch: 5| Step: 9
Training loss: 0.45212215185165405
Validation loss: 2.0612552215655646

Epoch: 5| Step: 10
Training loss: 0.6318297982215881
Validation loss: 2.0515337785085044

Epoch: 5| Step: 11
Training loss: 0.4140668213367462
Validation loss: 2.0752329329649606

Epoch: 394| Step: 0
Training loss: 0.44758257269859314
Validation loss: 2.1170403758684793

Epoch: 5| Step: 1
Training loss: 0.27276450395584106
Validation loss: 2.168421134352684

Epoch: 5| Step: 2
Training loss: 0.2860116958618164
Validation loss: 2.1889778673648834

Epoch: 5| Step: 3
Training loss: 0.36536329984664917
Validation loss: 2.142027129729589

Epoch: 5| Step: 4
Training loss: 0.31547319889068604
Validation loss: 2.100477953751882

Epoch: 5| Step: 5
Training loss: 0.6195899248123169
Validation loss: 2.103299895922343

Epoch: 5| Step: 6
Training loss: 0.2582870125770569
Validation loss: 2.081603189309438

Epoch: 5| Step: 7
Training loss: 0.2884626090526581
Validation loss: 2.083557645479838

Epoch: 5| Step: 8
Training loss: 0.29701751470565796
Validation loss: 2.107513507207235

Epoch: 5| Step: 9
Training loss: 0.24535635113716125
Validation loss: 2.065216824412346

Epoch: 5| Step: 10
Training loss: 0.38216543197631836
Validation loss: 2.0601786176363626

Epoch: 5| Step: 11
Training loss: 0.33980560302734375
Validation loss: 2.0624846716721854

Epoch: 395| Step: 0
Training loss: 0.22165830433368683
Validation loss: 2.109452188014984

Epoch: 5| Step: 1
Training loss: 0.30664145946502686
Validation loss: 2.1362099597851434

Epoch: 5| Step: 2
Training loss: 0.3837520182132721
Validation loss: 2.1590073853731155

Epoch: 5| Step: 3
Training loss: 0.2840171754360199
Validation loss: 2.13835979004701

Epoch: 5| Step: 4
Training loss: 0.34386196732521057
Validation loss: 2.0930081009864807

Epoch: 5| Step: 5
Training loss: 0.24778568744659424
Validation loss: 2.142871012290319

Epoch: 5| Step: 6
Training loss: 0.27945318818092346
Validation loss: 2.1507055958112082

Epoch: 5| Step: 7
Training loss: 0.3267042636871338
Validation loss: 2.115749016404152

Epoch: 5| Step: 8
Training loss: 0.6113969087600708
Validation loss: 2.086825201908747

Epoch: 5| Step: 9
Training loss: 0.28072118759155273
Validation loss: 2.09448733429114

Epoch: 5| Step: 10
Training loss: 0.2963850796222687
Validation loss: 2.0574544221162796

Epoch: 5| Step: 11
Training loss: 0.2105872631072998
Validation loss: 2.1042915930350623

Epoch: 396| Step: 0
Training loss: 0.44977936148643494
Validation loss: 2.100496838490168

Epoch: 5| Step: 1
Training loss: 0.42998695373535156
Validation loss: 2.0725685507059097

Epoch: 5| Step: 2
Training loss: 0.338115394115448
Validation loss: 2.131764312585195

Epoch: 5| Step: 3
Training loss: 0.359494149684906
Validation loss: 2.127900938193003

Epoch: 5| Step: 4
Training loss: 0.23401165008544922
Validation loss: 2.1198030014832816

Epoch: 5| Step: 5
Training loss: 0.2591632902622223
Validation loss: 2.1206195652484894

Epoch: 5| Step: 6
Training loss: 0.46449145674705505
Validation loss: 2.1166585087776184

Epoch: 5| Step: 7
Training loss: 0.29566726088523865
Validation loss: 2.0645507077376046

Epoch: 5| Step: 8
Training loss: 0.3179773986339569
Validation loss: 2.0706644455591836

Epoch: 5| Step: 9
Training loss: 0.23566994071006775
Validation loss: 2.114270602663358

Epoch: 5| Step: 10
Training loss: 0.19641883671283722
Validation loss: 2.0576584289471307

Epoch: 5| Step: 11
Training loss: 0.23087644577026367
Validation loss: 2.061687091986338

Epoch: 397| Step: 0
Training loss: 0.2707456946372986
Validation loss: 2.0764558215936026

Epoch: 5| Step: 1
Training loss: 0.4065241813659668
Validation loss: 2.0628080119689307

Epoch: 5| Step: 2
Training loss: 0.4723607003688812
Validation loss: 2.064626763264338

Epoch: 5| Step: 3
Training loss: 0.16674953699111938
Validation loss: 2.0722866505384445

Epoch: 5| Step: 4
Training loss: 0.30234983563423157
Validation loss: 2.079297269384066

Epoch: 5| Step: 5
Training loss: 0.22448834776878357
Validation loss: 2.1000860830148063

Epoch: 5| Step: 6
Training loss: 0.5689972639083862
Validation loss: 2.118254760901133

Epoch: 5| Step: 7
Training loss: 0.1465565413236618
Validation loss: 2.1253943542639413

Epoch: 5| Step: 8
Training loss: 0.2663330137729645
Validation loss: 2.1042480816443763

Epoch: 5| Step: 9
Training loss: 0.4032638967037201
Validation loss: 2.0768183221419654

Epoch: 5| Step: 10
Training loss: 0.17257273197174072
Validation loss: 2.042847747604052

Epoch: 5| Step: 11
Training loss: 0.37411123514175415
Validation loss: 2.077077105641365

Epoch: 398| Step: 0
Training loss: 0.20196929574012756
Validation loss: 2.095637336373329

Epoch: 5| Step: 1
Training loss: 0.27855923771858215
Validation loss: 2.074814667304357

Epoch: 5| Step: 2
Training loss: 0.33806467056274414
Validation loss: 2.0604488253593445

Epoch: 5| Step: 3
Training loss: 0.3188556134700775
Validation loss: 2.0944262941678367

Epoch: 5| Step: 4
Training loss: 0.3123275637626648
Validation loss: 2.1072520514329276

Epoch: 5| Step: 5
Training loss: 0.22976982593536377
Validation loss: 2.0936949650446572

Epoch: 5| Step: 6
Training loss: 0.2479734867811203
Validation loss: 2.1541664799054465

Epoch: 5| Step: 7
Training loss: 0.3376329839229584
Validation loss: 2.1059396912654242

Epoch: 5| Step: 8
Training loss: 0.34289664030075073
Validation loss: 2.1190211375554404

Epoch: 5| Step: 9
Training loss: 0.3262958228588104
Validation loss: 2.105783889691035

Epoch: 5| Step: 10
Training loss: 0.6045337915420532
Validation loss: 2.1011311213175454

Epoch: 5| Step: 11
Training loss: 0.18007099628448486
Validation loss: 2.1288221379121146

Epoch: 399| Step: 0
Training loss: 0.2482951432466507
Validation loss: 2.1072320391734443

Epoch: 5| Step: 1
Training loss: 0.4194364547729492
Validation loss: 2.0722312182188034

Epoch: 5| Step: 2
Training loss: 0.4251518249511719
Validation loss: 2.101870904366175

Epoch: 5| Step: 3
Training loss: 0.41100063920021057
Validation loss: 2.070705066124598

Epoch: 5| Step: 4
Training loss: 0.26632457971572876
Validation loss: 2.0489301135142646

Epoch: 5| Step: 5
Training loss: 0.32360929250717163
Validation loss: 2.0838016867637634

Epoch: 5| Step: 6
Training loss: 0.2751210331916809
Validation loss: 2.073469569285711

Epoch: 5| Step: 7
Training loss: 0.21710816025733948
Validation loss: 2.108152076601982

Epoch: 5| Step: 8
Training loss: 0.19342145323753357
Validation loss: 2.1443530519803367

Epoch: 5| Step: 9
Training loss: 0.4986228942871094
Validation loss: 2.0748583475748696

Epoch: 5| Step: 10
Training loss: 0.3136586546897888
Validation loss: 2.096107378602028

Epoch: 5| Step: 11
Training loss: 0.15499591827392578
Validation loss: 2.100344806909561

Epoch: 400| Step: 0
Training loss: 0.175257608294487
Validation loss: 2.058296566208204

Epoch: 5| Step: 1
Training loss: 0.2275286167860031
Validation loss: 2.0681366523106894

Epoch: 5| Step: 2
Training loss: 0.49277257919311523
Validation loss: 2.0701146026452384

Epoch: 5| Step: 3
Training loss: 0.25951889157295227
Validation loss: 2.0745360255241394

Epoch: 5| Step: 4
Training loss: 0.32470136880874634
Validation loss: 2.0907180309295654

Epoch: 5| Step: 5
Training loss: 0.31138676404953003
Validation loss: 2.0739767849445343

Epoch: 5| Step: 6
Training loss: 0.18038234114646912
Validation loss: 2.0726630638043084

Epoch: 5| Step: 7
Training loss: 0.49740272760391235
Validation loss: 2.0846719990173974

Epoch: 5| Step: 8
Training loss: 0.2706243395805359
Validation loss: 2.084355041384697

Epoch: 5| Step: 9
Training loss: 0.37598705291748047
Validation loss: 2.0899326503276825

Epoch: 5| Step: 10
Training loss: 0.24911169707775116
Validation loss: 2.0967460622390113

Epoch: 5| Step: 11
Training loss: 0.17296259105205536
Validation loss: 2.076859404643377

Epoch: 401| Step: 0
Training loss: 0.3463646471500397
Validation loss: 2.0738727301359177

Epoch: 5| Step: 1
Training loss: 0.34945282340049744
Validation loss: 2.0813466757535934

Epoch: 5| Step: 2
Training loss: 0.20506086945533752
Validation loss: 2.0538083016872406

Epoch: 5| Step: 3
Training loss: 0.2179093360900879
Validation loss: 2.0826893945535025

Epoch: 5| Step: 4
Training loss: 0.30605489015579224
Validation loss: 2.0715001076459885

Epoch: 5| Step: 5
Training loss: 0.3786506652832031
Validation loss: 2.110152761141459

Epoch: 5| Step: 6
Training loss: 0.33203402161598206
Validation loss: 2.1162700156370797

Epoch: 5| Step: 7
Training loss: 0.6046514511108398
Validation loss: 2.091749295592308

Epoch: 5| Step: 8
Training loss: 0.20893239974975586
Validation loss: 2.0721475084622702

Epoch: 5| Step: 9
Training loss: 0.3548101782798767
Validation loss: 2.089270810286204

Epoch: 5| Step: 10
Training loss: 0.2567397952079773
Validation loss: 2.085002973675728

Epoch: 5| Step: 11
Training loss: 0.19248586893081665
Validation loss: 2.0930517415205636

Epoch: 402| Step: 0
Training loss: 0.3624494671821594
Validation loss: 2.105724478761355

Epoch: 5| Step: 1
Training loss: 0.29913991689682007
Validation loss: 2.1069085001945496

Epoch: 5| Step: 2
Training loss: 0.27666914463043213
Validation loss: 2.1282575776179633

Epoch: 5| Step: 3
Training loss: 0.36983904242515564
Validation loss: 2.1085723489522934

Epoch: 5| Step: 4
Training loss: 0.3020249903202057
Validation loss: 2.1378156592448554

Epoch: 5| Step: 5
Training loss: 0.5103964805603027
Validation loss: 2.1252790689468384

Epoch: 5| Step: 6
Training loss: 0.19134169816970825
Validation loss: 2.0999368180831275

Epoch: 5| Step: 7
Training loss: 0.25292062759399414
Validation loss: 2.089608669281006

Epoch: 5| Step: 8
Training loss: 0.4510778486728668
Validation loss: 2.0762294133504233

Epoch: 5| Step: 9
Training loss: 0.1693764477968216
Validation loss: 2.0886747588713965

Epoch: 5| Step: 10
Training loss: 0.4457000195980072
Validation loss: 2.083333730697632

Epoch: 5| Step: 11
Training loss: 0.14603936672210693
Validation loss: 2.0930587450663247

Epoch: 403| Step: 0
Training loss: 0.4308377206325531
Validation loss: 2.080985580881437

Epoch: 5| Step: 1
Training loss: 0.27401572465896606
Validation loss: 2.1216933876276016

Epoch: 5| Step: 2
Training loss: 0.17606550455093384
Validation loss: 2.1025106757879257

Epoch: 5| Step: 3
Training loss: 0.4546211361885071
Validation loss: 2.0910494873921075

Epoch: 5| Step: 4
Training loss: 0.2698184847831726
Validation loss: 2.085924665133158

Epoch: 5| Step: 5
Training loss: 0.247623011469841
Validation loss: 2.0720692376295724

Epoch: 5| Step: 6
Training loss: 0.311396062374115
Validation loss: 2.0950806935628257

Epoch: 5| Step: 7
Training loss: 0.14647041261196136
Validation loss: 2.0895937929550805

Epoch: 5| Step: 8
Training loss: 0.4955580234527588
Validation loss: 2.086484049757322

Epoch: 5| Step: 9
Training loss: 0.21469230949878693
Validation loss: 2.1151942859093347

Epoch: 5| Step: 10
Training loss: 0.24575701355934143
Validation loss: 2.0468551913897195

Epoch: 5| Step: 11
Training loss: 0.10234199464321136
Validation loss: 2.0708852261304855

Epoch: 404| Step: 0
Training loss: 0.2380821406841278
Validation loss: 2.0983995348215103

Epoch: 5| Step: 1
Training loss: 0.24929983913898468
Validation loss: 2.0800633827845254

Epoch: 5| Step: 2
Training loss: 0.3889782130718231
Validation loss: 2.065787042180697

Epoch: 5| Step: 3
Training loss: 0.41812199354171753
Validation loss: 2.0553181568781533

Epoch: 5| Step: 4
Training loss: 0.3268203139305115
Validation loss: 2.0795805950959525

Epoch: 5| Step: 5
Training loss: 0.17513377964496613
Validation loss: 2.062767341732979

Epoch: 5| Step: 6
Training loss: 0.38998693227767944
Validation loss: 2.065816899140676

Epoch: 5| Step: 7
Training loss: 0.45783963799476624
Validation loss: 2.0842010428508124

Epoch: 5| Step: 8
Training loss: 0.2958654761314392
Validation loss: 2.1089547177155814

Epoch: 5| Step: 9
Training loss: 0.2242458611726761
Validation loss: 2.1007100343704224

Epoch: 5| Step: 10
Training loss: 0.27887195348739624
Validation loss: 2.051621134082476

Epoch: 5| Step: 11
Training loss: 0.08481669425964355
Validation loss: 2.0853637059529624

Epoch: 405| Step: 0
Training loss: 0.31392788887023926
Validation loss: 2.0568025509516397

Epoch: 5| Step: 1
Training loss: 0.39716655015945435
Validation loss: 2.071836933493614

Epoch: 5| Step: 2
Training loss: 0.37274789810180664
Validation loss: 2.0446438938379288

Epoch: 5| Step: 3
Training loss: 0.39193883538246155
Validation loss: 2.074041023850441

Epoch: 5| Step: 4
Training loss: 0.4333713948726654
Validation loss: 2.130733827749888

Epoch: 5| Step: 5
Training loss: 0.23021848499774933
Validation loss: 2.097783083717028

Epoch: 5| Step: 6
Training loss: 0.2152242213487625
Validation loss: 2.096831182638804

Epoch: 5| Step: 7
Training loss: 0.26497945189476013
Validation loss: 2.073916311065356

Epoch: 5| Step: 8
Training loss: 0.48541170358657837
Validation loss: 2.0931250701347985

Epoch: 5| Step: 9
Training loss: 0.39120760560035706
Validation loss: 2.0799146642287574

Epoch: 5| Step: 10
Training loss: 0.3203597962856293
Validation loss: 2.040130376815796

Epoch: 5| Step: 11
Training loss: 0.14880585670471191
Validation loss: 2.021453087528547

Epoch: 406| Step: 0
Training loss: 0.24466946721076965
Validation loss: 2.0263745089372

Epoch: 5| Step: 1
Training loss: 0.18609420955181122
Validation loss: 2.02303280433019

Epoch: 5| Step: 2
Training loss: 0.3229656219482422
Validation loss: 2.073145881295204

Epoch: 5| Step: 3
Training loss: 0.2670842111110687
Validation loss: 2.0357729494571686

Epoch: 5| Step: 4
Training loss: 0.2703973352909088
Validation loss: 2.068274403611819

Epoch: 5| Step: 5
Training loss: 0.24439768493175507
Validation loss: 2.0506109644969306

Epoch: 5| Step: 6
Training loss: 0.34163156151771545
Validation loss: 2.0952098021904626

Epoch: 5| Step: 7
Training loss: 0.6093289256095886
Validation loss: 2.0578901171684265

Epoch: 5| Step: 8
Training loss: 0.6919277906417847
Validation loss: 2.063760668039322

Epoch: 5| Step: 9
Training loss: 0.21244394779205322
Validation loss: 2.0807505448659263

Epoch: 5| Step: 10
Training loss: 0.20057177543640137
Validation loss: 2.0566437542438507

Epoch: 5| Step: 11
Training loss: 0.18951016664505005
Validation loss: 2.0796841581662497

Epoch: 407| Step: 0
Training loss: 0.16993263363838196
Validation loss: 2.0759456058343253

Epoch: 5| Step: 1
Training loss: 0.25298798084259033
Validation loss: 2.0698969115813575

Epoch: 5| Step: 2
Training loss: 0.21436230838298798
Validation loss: 2.065679907798767

Epoch: 5| Step: 3
Training loss: 0.2914857864379883
Validation loss: 2.07031586766243

Epoch: 5| Step: 4
Training loss: 0.5771709084510803
Validation loss: 2.0845607866843543

Epoch: 5| Step: 5
Training loss: 0.3444638252258301
Validation loss: 2.08503894507885

Epoch: 5| Step: 6
Training loss: 0.23078110814094543
Validation loss: 2.078860253095627

Epoch: 5| Step: 7
Training loss: 0.36834296584129333
Validation loss: 2.1069223433732986

Epoch: 5| Step: 8
Training loss: 0.31293442845344543
Validation loss: 2.1217232992251716

Epoch: 5| Step: 9
Training loss: 0.3321579098701477
Validation loss: 2.0965186059474945

Epoch: 5| Step: 10
Training loss: 0.21381816267967224
Validation loss: 2.1145922541618347

Epoch: 5| Step: 11
Training loss: 0.7604674696922302
Validation loss: 2.1026774595181146

Epoch: 408| Step: 0
Training loss: 0.4674711227416992
Validation loss: 2.1028879483540854

Epoch: 5| Step: 1
Training loss: 0.2539442777633667
Validation loss: 2.100308155020078

Epoch: 5| Step: 2
Training loss: 0.2628163695335388
Validation loss: 2.0999773194392524

Epoch: 5| Step: 3
Training loss: 0.24555666744709015
Validation loss: 2.0547617276509604

Epoch: 5| Step: 4
Training loss: 0.2139192521572113
Validation loss: 2.0712322841087976

Epoch: 5| Step: 5
Training loss: 0.3159390091896057
Validation loss: 2.079411029815674

Epoch: 5| Step: 6
Training loss: 0.3466191589832306
Validation loss: 2.102243493000666

Epoch: 5| Step: 7
Training loss: 0.22944426536560059
Validation loss: 2.09256220360597

Epoch: 5| Step: 8
Training loss: 0.3167015612125397
Validation loss: 2.0929635415474572

Epoch: 5| Step: 9
Training loss: 0.42439860105514526
Validation loss: 2.1334398686885834

Epoch: 5| Step: 10
Training loss: 0.446106493473053
Validation loss: 2.1158056209484735

Epoch: 5| Step: 11
Training loss: 0.1417306661605835
Validation loss: 2.0668110946814218

Epoch: 409| Step: 0
Training loss: 0.46988314390182495
Validation loss: 2.082501247525215

Epoch: 5| Step: 1
Training loss: 0.367549866437912
Validation loss: 2.0928897509972253

Epoch: 5| Step: 2
Training loss: 0.30184224247932434
Validation loss: 2.090531125664711

Epoch: 5| Step: 3
Training loss: 0.17025800049304962
Validation loss: 2.067800978819529

Epoch: 5| Step: 4
Training loss: 0.26845234632492065
Validation loss: 2.072780653834343

Epoch: 5| Step: 5
Training loss: 0.2722195088863373
Validation loss: 2.064656769235929

Epoch: 5| Step: 6
Training loss: 0.3149043023586273
Validation loss: 2.100645045439402

Epoch: 5| Step: 7
Training loss: 0.23205146193504333
Validation loss: 2.0931875705718994

Epoch: 5| Step: 8
Training loss: 0.21847014129161835
Validation loss: 2.1434755424658456

Epoch: 5| Step: 9
Training loss: 0.4188903272151947
Validation loss: 2.0936609903971353

Epoch: 5| Step: 10
Training loss: 0.35467779636383057
Validation loss: 2.1069040447473526

Epoch: 5| Step: 11
Training loss: 0.17499881982803345
Validation loss: 2.1047687282164893

Epoch: 410| Step: 0
Training loss: 0.2392924726009369
Validation loss: 2.104830786585808

Epoch: 5| Step: 1
Training loss: 0.1808246374130249
Validation loss: 2.111671025554339

Epoch: 5| Step: 2
Training loss: 0.3546384572982788
Validation loss: 2.1140295515457788

Epoch: 5| Step: 3
Training loss: 0.32311296463012695
Validation loss: 2.0983570516109467

Epoch: 5| Step: 4
Training loss: 0.22081151604652405
Validation loss: 2.1090836177269616

Epoch: 5| Step: 5
Training loss: 0.2993185818195343
Validation loss: 2.1149336795012155

Epoch: 5| Step: 6
Training loss: 0.3197934329509735
Validation loss: 2.0458288937807083

Epoch: 5| Step: 7
Training loss: 0.21494312584400177
Validation loss: 2.086879774928093

Epoch: 5| Step: 8
Training loss: 0.4750150740146637
Validation loss: 2.0510689417521157

Epoch: 5| Step: 9
Training loss: 0.28102248907089233
Validation loss: 2.057520573337873

Epoch: 5| Step: 10
Training loss: 0.25078701972961426
Validation loss: 2.109358807404836

Epoch: 5| Step: 11
Training loss: 0.16365987062454224
Validation loss: 2.073406904935837

Epoch: 411| Step: 0
Training loss: 0.28457725048065186
Validation loss: 2.046074315905571

Epoch: 5| Step: 1
Training loss: 0.250663697719574
Validation loss: 2.1333971371253333

Epoch: 5| Step: 2
Training loss: 0.4793779253959656
Validation loss: 2.109660749634107

Epoch: 5| Step: 3
Training loss: 0.3741462826728821
Validation loss: 2.136765335996946

Epoch: 5| Step: 4
Training loss: 0.30200374126434326
Validation loss: 2.1311709135770798

Epoch: 5| Step: 5
Training loss: 0.3742007613182068
Validation loss: 2.1357090224822364

Epoch: 5| Step: 6
Training loss: 0.18512320518493652
Validation loss: 2.106885477900505

Epoch: 5| Step: 7
Training loss: 0.27472832798957825
Validation loss: 2.0891366203626

Epoch: 5| Step: 8
Training loss: 0.17957289516925812
Validation loss: 2.091267555952072

Epoch: 5| Step: 9
Training loss: 0.21489357948303223
Validation loss: 2.1122043430805206

Epoch: 5| Step: 10
Training loss: 0.17444899678230286
Validation loss: 2.0985321452220282

Epoch: 5| Step: 11
Training loss: 0.7858386635780334
Validation loss: 2.106136843562126

Epoch: 412| Step: 0
Training loss: 0.22231097519397736
Validation loss: 2.1590075145165124

Epoch: 5| Step: 1
Training loss: 0.5965628027915955
Validation loss: 2.1395397931337357

Epoch: 5| Step: 2
Training loss: 0.19239895045757294
Validation loss: 2.1429891089598336

Epoch: 5| Step: 3
Training loss: 0.20689305663108826
Validation loss: 2.1307911773522696

Epoch: 5| Step: 4
Training loss: 0.32256191968917847
Validation loss: 2.1252895494302115

Epoch: 5| Step: 5
Training loss: 0.19721201062202454
Validation loss: 2.1132683008909225

Epoch: 5| Step: 6
Training loss: 0.3483809232711792
Validation loss: 2.1323005755742392

Epoch: 5| Step: 7
Training loss: 0.23861177265644073
Validation loss: 2.1231621901194253

Epoch: 5| Step: 8
Training loss: 0.21848145127296448
Validation loss: 2.168055792649587

Epoch: 5| Step: 9
Training loss: 0.24994640052318573
Validation loss: 2.119383364915848

Epoch: 5| Step: 10
Training loss: 0.3056734502315521
Validation loss: 2.1342062652111053

Epoch: 5| Step: 11
Training loss: 0.399405300617218
Validation loss: 2.1412819425264993

Epoch: 413| Step: 0
Training loss: 0.22547344863414764
Validation loss: 2.079043264190356

Epoch: 5| Step: 1
Training loss: 0.14105752110481262
Validation loss: 2.096904531121254

Epoch: 5| Step: 2
Training loss: 0.1859324872493744
Validation loss: 2.131463805834452

Epoch: 5| Step: 3
Training loss: 0.31553012132644653
Validation loss: 2.1034306486447654

Epoch: 5| Step: 4
Training loss: 0.2336573600769043
Validation loss: 2.096858258048693

Epoch: 5| Step: 5
Training loss: 0.32592886686325073
Validation loss: 2.114994833866755

Epoch: 5| Step: 6
Training loss: 0.23844139277935028
Validation loss: 2.043956995010376

Epoch: 5| Step: 7
Training loss: 0.2979676425457001
Validation loss: 2.0964602132638297

Epoch: 5| Step: 8
Training loss: 0.5889379382133484
Validation loss: 2.0815083533525467

Epoch: 5| Step: 9
Training loss: 0.2943809926509857
Validation loss: 2.113368441661199

Epoch: 5| Step: 10
Training loss: 0.3174852132797241
Validation loss: 2.135225921869278

Epoch: 5| Step: 11
Training loss: 0.2161102294921875
Validation loss: 2.140851080417633

Epoch: 414| Step: 0
Training loss: 0.17312811315059662
Validation loss: 2.16382826368014

Epoch: 5| Step: 1
Training loss: 0.34510093927383423
Validation loss: 2.100041478872299

Epoch: 5| Step: 2
Training loss: 0.25353124737739563
Validation loss: 2.085514545440674

Epoch: 5| Step: 3
Training loss: 0.2941869795322418
Validation loss: 2.134583776195844

Epoch: 5| Step: 4
Training loss: 0.2836989760398865
Validation loss: 2.0768282065788903

Epoch: 5| Step: 5
Training loss: 0.15703797340393066
Validation loss: 2.103575443228086

Epoch: 5| Step: 6
Training loss: 0.28269240260124207
Validation loss: 2.136716494957606

Epoch: 5| Step: 7
Training loss: 0.1339299976825714
Validation loss: 2.0894310027360916

Epoch: 5| Step: 8
Training loss: 0.26418179273605347
Validation loss: 2.0533083081245422

Epoch: 5| Step: 9
Training loss: 0.4136411249637604
Validation loss: 2.105213155349096

Epoch: 5| Step: 10
Training loss: 0.4534047245979309
Validation loss: 2.0901658286650977

Epoch: 5| Step: 11
Training loss: 0.136327862739563
Validation loss: 2.0858104477326074

Epoch: 415| Step: 0
Training loss: 0.3021603226661682
Validation loss: 2.094942877689997

Epoch: 5| Step: 1
Training loss: 0.19418294727802277
Validation loss: 2.1136484841505685

Epoch: 5| Step: 2
Training loss: 0.19200563430786133
Validation loss: 2.1047246356805167

Epoch: 5| Step: 3
Training loss: 0.28795915842056274
Validation loss: 2.1295827478170395

Epoch: 5| Step: 4
Training loss: 0.18699708580970764
Validation loss: 2.161050468683243

Epoch: 5| Step: 5
Training loss: 0.31507396697998047
Validation loss: 2.1496791491905847

Epoch: 5| Step: 6
Training loss: 0.29745951294898987
Validation loss: 2.1095084895690284

Epoch: 5| Step: 7
Training loss: 0.5630385279655457
Validation loss: 2.1082567274570465

Epoch: 5| Step: 8
Training loss: 0.3051218092441559
Validation loss: 2.0909492572148642

Epoch: 5| Step: 9
Training loss: 0.5884972810745239
Validation loss: 2.0849559903144836

Epoch: 5| Step: 10
Training loss: 0.2838032841682434
Validation loss: 2.1099619964758554

Epoch: 5| Step: 11
Training loss: 0.1474090814590454
Validation loss: 2.1003373811642327

Epoch: 416| Step: 0
Training loss: 0.19667881727218628
Validation loss: 2.117390205462774

Epoch: 5| Step: 1
Training loss: 0.26979294419288635
Validation loss: 2.0972471882899604

Epoch: 5| Step: 2
Training loss: 0.3763888478279114
Validation loss: 2.100070426861445

Epoch: 5| Step: 3
Training loss: 0.25640684366226196
Validation loss: 2.1222642362117767

Epoch: 5| Step: 4
Training loss: 0.22460953891277313
Validation loss: 2.09175713857015

Epoch: 5| Step: 5
Training loss: 0.593963623046875
Validation loss: 2.102950543165207

Epoch: 5| Step: 6
Training loss: 0.30177298188209534
Validation loss: 2.0571122666200004

Epoch: 5| Step: 7
Training loss: 0.2125873565673828
Validation loss: 2.0684267034133277

Epoch: 5| Step: 8
Training loss: 0.40111908316612244
Validation loss: 2.0853927731513977

Epoch: 5| Step: 9
Training loss: 0.25861790776252747
Validation loss: 2.118410641948382

Epoch: 5| Step: 10
Training loss: 0.20501625537872314
Validation loss: 2.078287040193876

Epoch: 5| Step: 11
Training loss: 0.7065620422363281
Validation loss: 2.0907675127188363

Epoch: 417| Step: 0
Training loss: 0.23204532265663147
Validation loss: 2.0826630095640817

Epoch: 5| Step: 1
Training loss: 0.2824544906616211
Validation loss: 2.11297216018041

Epoch: 5| Step: 2
Training loss: 0.19063380360603333
Validation loss: 2.11595190068086

Epoch: 5| Step: 3
Training loss: 0.31418341398239136
Validation loss: 2.0954839487870536

Epoch: 5| Step: 4
Training loss: 0.3448445200920105
Validation loss: 2.1043125887711844

Epoch: 5| Step: 5
Training loss: 0.32010209560394287
Validation loss: 2.157544751962026

Epoch: 5| Step: 6
Training loss: 0.24038073420524597
Validation loss: 2.0987938145796456

Epoch: 5| Step: 7
Training loss: 0.23120620846748352
Validation loss: 2.1420429249604545

Epoch: 5| Step: 8
Training loss: 0.2658437490463257
Validation loss: 2.1434253255526223

Epoch: 5| Step: 9
Training loss: 0.24836695194244385
Validation loss: 2.1076834897200265

Epoch: 5| Step: 10
Training loss: 0.33331602811813354
Validation loss: 2.1132868280013404

Epoch: 5| Step: 11
Training loss: 1.4118742942810059
Validation loss: 2.1345481077829995

Epoch: 418| Step: 0
Training loss: 0.36471983790397644
Validation loss: 2.066855644186338

Epoch: 5| Step: 1
Training loss: 0.24507960677146912
Validation loss: 2.0925723711649575

Epoch: 5| Step: 2
Training loss: 0.2903861999511719
Validation loss: 2.0959378480911255

Epoch: 5| Step: 3
Training loss: 0.1589566022157669
Validation loss: 2.0940984984238944

Epoch: 5| Step: 4
Training loss: 0.40066036581993103
Validation loss: 2.092448259393374

Epoch: 5| Step: 5
Training loss: 0.2281249761581421
Validation loss: 2.0711351285378137

Epoch: 5| Step: 6
Training loss: 0.2606368958950043
Validation loss: 2.065630858143171

Epoch: 5| Step: 7
Training loss: 0.3555591404438019
Validation loss: 2.0995567788680396

Epoch: 5| Step: 8
Training loss: 0.4023391604423523
Validation loss: 2.0979291995366416

Epoch: 5| Step: 9
Training loss: 0.24267549812793732
Validation loss: 2.147896870970726

Epoch: 5| Step: 10
Training loss: 0.3419921398162842
Validation loss: 2.129612828294436

Epoch: 5| Step: 11
Training loss: 0.1700284481048584
Validation loss: 2.118470932046572

Epoch: 419| Step: 0
Training loss: 0.34092408418655396
Validation loss: 2.1181314090887704

Epoch: 5| Step: 1
Training loss: 0.6491324305534363
Validation loss: 2.1831753899653754

Epoch: 5| Step: 2
Training loss: 0.44064396619796753
Validation loss: 2.097535396615664

Epoch: 5| Step: 3
Training loss: 0.34037068486213684
Validation loss: 2.079773177703222

Epoch: 5| Step: 4
Training loss: 0.551386833190918
Validation loss: 2.0317850609620414

Epoch: 5| Step: 5
Training loss: 0.3668276369571686
Validation loss: 2.1140043139457703

Epoch: 5| Step: 6
Training loss: 0.30671924352645874
Validation loss: 2.060566946864128

Epoch: 5| Step: 7
Training loss: 0.3608647882938385
Validation loss: 2.0903057605028152

Epoch: 5| Step: 8
Training loss: 0.21431037783622742
Validation loss: 2.0863077690203986

Epoch: 5| Step: 9
Training loss: 0.2014005184173584
Validation loss: 2.0726801057656608

Epoch: 5| Step: 10
Training loss: 0.3354173004627228
Validation loss: 2.136731723944346

Epoch: 5| Step: 11
Training loss: 0.26328063011169434
Validation loss: 2.1585925072431564

Epoch: 420| Step: 0
Training loss: 0.32056406140327454
Validation loss: 2.1798064907391868

Epoch: 5| Step: 1
Training loss: 0.24817223846912384
Validation loss: 2.165934676925341

Epoch: 5| Step: 2
Training loss: 0.5564486384391785
Validation loss: 2.1598036686579385

Epoch: 5| Step: 3
Training loss: 0.22628569602966309
Validation loss: 2.1439750691254935

Epoch: 5| Step: 4
Training loss: 0.16339626908302307
Validation loss: 2.1088470419247947

Epoch: 5| Step: 5
Training loss: 0.2624686062335968
Validation loss: 2.123569130897522

Epoch: 5| Step: 6
Training loss: 0.3601689338684082
Validation loss: 2.0691470950841904

Epoch: 5| Step: 7
Training loss: 0.6394181847572327
Validation loss: 2.105004002650579

Epoch: 5| Step: 8
Training loss: 0.1828191578388214
Validation loss: 2.084580803910891

Epoch: 5| Step: 9
Training loss: 0.18778176605701447
Validation loss: 2.1401448994874954

Epoch: 5| Step: 10
Training loss: 0.29759910702705383
Validation loss: 2.1502163807551065

Epoch: 5| Step: 11
Training loss: 0.1906440258026123
Validation loss: 2.1273917108774185

Epoch: 421| Step: 0
Training loss: 0.3173558712005615
Validation loss: 2.0984242260456085

Epoch: 5| Step: 1
Training loss: 0.2032628059387207
Validation loss: 2.140338142712911

Epoch: 5| Step: 2
Training loss: 0.24803109467029572
Validation loss: 2.0936009685198465

Epoch: 5| Step: 3
Training loss: 0.3072163462638855
Validation loss: 2.0796683679024377

Epoch: 5| Step: 4
Training loss: 0.3529272675514221
Validation loss: 2.0439496586720147

Epoch: 5| Step: 5
Training loss: 0.3447727560997009
Validation loss: 2.085743804772695

Epoch: 5| Step: 6
Training loss: 0.31206458806991577
Validation loss: 2.061082124710083

Epoch: 5| Step: 7
Training loss: 0.1893017441034317
Validation loss: 2.059891472260157

Epoch: 5| Step: 8
Training loss: 0.20767998695373535
Validation loss: 2.1123030533393226

Epoch: 5| Step: 9
Training loss: 0.5678050518035889
Validation loss: 2.134337469935417

Epoch: 5| Step: 10
Training loss: 0.36534979939460754
Validation loss: 2.134623189767202

Epoch: 5| Step: 11
Training loss: 0.3791612982749939
Validation loss: 2.1077913592259088

Epoch: 422| Step: 0
Training loss: 0.34649237990379333
Validation loss: 2.1301933775345483

Epoch: 5| Step: 1
Training loss: 0.29560375213623047
Validation loss: 2.142294406890869

Epoch: 5| Step: 2
Training loss: 0.32922643423080444
Validation loss: 2.1336527665456138

Epoch: 5| Step: 3
Training loss: 0.3170175552368164
Validation loss: 2.0917756160100303

Epoch: 5| Step: 4
Training loss: 0.24108915030956268
Validation loss: 2.109118158618609

Epoch: 5| Step: 5
Training loss: 0.3775328993797302
Validation loss: 2.099221169948578

Epoch: 5| Step: 6
Training loss: 0.32358667254447937
Validation loss: 2.0662589371204376

Epoch: 5| Step: 7
Training loss: 0.3962857723236084
Validation loss: 2.0529583593209586

Epoch: 5| Step: 8
Training loss: 0.5444278717041016
Validation loss: 2.0956019361813865

Epoch: 5| Step: 9
Training loss: 0.1995617300271988
Validation loss: 2.10381111005942

Epoch: 5| Step: 10
Training loss: 0.4286975860595703
Validation loss: 2.1275272419055304

Epoch: 5| Step: 11
Training loss: 0.42902785539627075
Validation loss: 2.154024283091227

Epoch: 423| Step: 0
Training loss: 0.4706633687019348
Validation loss: 2.1415158808231354

Epoch: 5| Step: 1
Training loss: 0.19850464165210724
Validation loss: 2.146818940838178

Epoch: 5| Step: 2
Training loss: 0.2754950225353241
Validation loss: 2.100139856338501

Epoch: 5| Step: 3
Training loss: 0.3009961247444153
Validation loss: 2.0674682507912316

Epoch: 5| Step: 4
Training loss: 0.3302463889122009
Validation loss: 2.0588675985733667

Epoch: 5| Step: 5
Training loss: 0.29704251885414124
Validation loss: 2.035516699155172

Epoch: 5| Step: 6
Training loss: 0.33775851130485535
Validation loss: 2.070697764555613

Epoch: 5| Step: 7
Training loss: 0.3766597509384155
Validation loss: 2.1028584291537604

Epoch: 5| Step: 8
Training loss: 0.6174284219741821
Validation loss: 2.0788114815950394

Epoch: 5| Step: 9
Training loss: 0.30613118410110474
Validation loss: 2.0593070884545646

Epoch: 5| Step: 10
Training loss: 0.3016938269138336
Validation loss: 2.115644097328186

Epoch: 5| Step: 11
Training loss: 0.4120832681655884
Validation loss: 2.1541202465693154

Epoch: 424| Step: 0
Training loss: 0.3803597092628479
Validation loss: 2.1135329604148865

Epoch: 5| Step: 1
Training loss: 0.21064713597297668
Validation loss: 2.1169357895851135

Epoch: 5| Step: 2
Training loss: 0.5109221935272217
Validation loss: 2.112754687666893

Epoch: 5| Step: 3
Training loss: 0.1983398199081421
Validation loss: 2.1064429531494775

Epoch: 5| Step: 4
Training loss: 0.3083905279636383
Validation loss: 2.052011157075564

Epoch: 5| Step: 5
Training loss: 0.2842782139778137
Validation loss: 2.0344511518875756

Epoch: 5| Step: 6
Training loss: 0.3292730748653412
Validation loss: 2.0652103225390115

Epoch: 5| Step: 7
Training loss: 0.38438349962234497
Validation loss: 2.091968054572741

Epoch: 5| Step: 8
Training loss: 0.28034141659736633
Validation loss: 2.10373384753863

Epoch: 5| Step: 9
Training loss: 0.29423487186431885
Validation loss: 2.118692750732104

Epoch: 5| Step: 10
Training loss: 0.3951943516731262
Validation loss: 2.108658795555433

Epoch: 5| Step: 11
Training loss: 0.23737621307373047
Validation loss: 2.192825044194857

Epoch: 425| Step: 0
Training loss: 0.27586865425109863
Validation loss: 2.1944057047367096

Epoch: 5| Step: 1
Training loss: 0.24392783641815186
Validation loss: 2.174642672141393

Epoch: 5| Step: 2
Training loss: 0.2264489233493805
Validation loss: 2.117197553316752

Epoch: 5| Step: 3
Training loss: 0.3803456723690033
Validation loss: 2.143107761939367

Epoch: 5| Step: 4
Training loss: 0.2818247079849243
Validation loss: 2.166522587339083

Epoch: 5| Step: 5
Training loss: 0.5345146059989929
Validation loss: 2.124691734711329

Epoch: 5| Step: 6
Training loss: 0.36510953307151794
Validation loss: 2.117541899283727

Epoch: 5| Step: 7
Training loss: 0.3021520972251892
Validation loss: 2.100061317284902

Epoch: 5| Step: 8
Training loss: 0.19742918014526367
Validation loss: 2.1224268774191537

Epoch: 5| Step: 9
Training loss: 0.2880488932132721
Validation loss: 2.104233662287394

Epoch: 5| Step: 10
Training loss: 0.19866468012332916
Validation loss: 2.126416047414144

Epoch: 5| Step: 11
Training loss: 0.1566331386566162
Validation loss: 2.0876478354136148

Epoch: 426| Step: 0
Training loss: 0.24452686309814453
Validation loss: 2.1124028066794076

Epoch: 5| Step: 1
Training loss: 0.2035110890865326
Validation loss: 2.128155753016472

Epoch: 5| Step: 2
Training loss: 0.20993192493915558
Validation loss: 2.1019932876030603

Epoch: 5| Step: 3
Training loss: 0.49337440729141235
Validation loss: 2.0951386789480844

Epoch: 5| Step: 4
Training loss: 0.4032929539680481
Validation loss: 2.134812653064728

Epoch: 5| Step: 5
Training loss: 0.3760078549385071
Validation loss: 2.0657352904478707

Epoch: 5| Step: 6
Training loss: 0.19078566133975983
Validation loss: 2.0998741537332535

Epoch: 5| Step: 7
Training loss: 0.3209596574306488
Validation loss: 2.083558609088262

Epoch: 5| Step: 8
Training loss: 0.18445193767547607
Validation loss: 2.0915418515602746

Epoch: 5| Step: 9
Training loss: 0.28353506326675415
Validation loss: 2.137988328933716

Epoch: 5| Step: 10
Training loss: 0.38321441411972046
Validation loss: 2.0785289158423743

Epoch: 5| Step: 11
Training loss: 0.08191728591918945
Validation loss: 2.139918232957522

Epoch: 427| Step: 0
Training loss: 0.3633454442024231
Validation loss: 2.06229596833388

Epoch: 5| Step: 1
Training loss: 0.5336712002754211
Validation loss: 2.152926261226336

Epoch: 5| Step: 2
Training loss: 0.4044104218482971
Validation loss: 2.1306129544973373

Epoch: 5| Step: 3
Training loss: 0.29626715183258057
Validation loss: 2.0937094738086066

Epoch: 5| Step: 4
Training loss: 0.29449188709259033
Validation loss: 2.073637366294861

Epoch: 5| Step: 5
Training loss: 0.2279800921678543
Validation loss: 2.081980506579081

Epoch: 5| Step: 6
Training loss: 0.3969205319881439
Validation loss: 2.054916729529699

Epoch: 5| Step: 7
Training loss: 0.2773347496986389
Validation loss: 2.0656554649273553

Epoch: 5| Step: 8
Training loss: 0.17614582180976868
Validation loss: 2.095541685819626

Epoch: 5| Step: 9
Training loss: 0.2794649600982666
Validation loss: 2.0879593938589096

Epoch: 5| Step: 10
Training loss: 0.23201093077659607
Validation loss: 2.088589623570442

Epoch: 5| Step: 11
Training loss: 0.2650212049484253
Validation loss: 2.0754443208376565

Epoch: 428| Step: 0
Training loss: 0.46589869260787964
Validation loss: 2.0944281866153083

Epoch: 5| Step: 1
Training loss: 0.29654577374458313
Validation loss: 2.140596171220144

Epoch: 5| Step: 2
Training loss: 0.1641002744436264
Validation loss: 2.1214896539847055

Epoch: 5| Step: 3
Training loss: 0.3672223389148712
Validation loss: 2.1246590266625085

Epoch: 5| Step: 4
Training loss: 0.23368434607982635
Validation loss: 2.142332444588343

Epoch: 5| Step: 5
Training loss: 0.37902283668518066
Validation loss: 2.107065116365751

Epoch: 5| Step: 6
Training loss: 0.2463100403547287
Validation loss: 2.067779208223025

Epoch: 5| Step: 7
Training loss: 0.14669738709926605
Validation loss: 2.110278402765592

Epoch: 5| Step: 8
Training loss: 0.26659876108169556
Validation loss: 2.0780713061491647

Epoch: 5| Step: 9
Training loss: 0.29601794481277466
Validation loss: 2.1519461373488107

Epoch: 5| Step: 10
Training loss: 0.15578730404376984
Validation loss: 2.1247284760077796

Epoch: 5| Step: 11
Training loss: 0.2750324010848999
Validation loss: 2.0654432475566864

Epoch: 429| Step: 0
Training loss: 0.29100897908210754
Validation loss: 2.091401676336924

Epoch: 5| Step: 1
Training loss: 0.26780813932418823
Validation loss: 2.102385858694712

Epoch: 5| Step: 2
Training loss: 0.16116417944431305
Validation loss: 2.0515150974194207

Epoch: 5| Step: 3
Training loss: 0.4279541075229645
Validation loss: 2.1143713891506195

Epoch: 5| Step: 4
Training loss: 0.25496333837509155
Validation loss: 2.124684582153956

Epoch: 5| Step: 5
Training loss: 0.28466033935546875
Validation loss: 2.1022572616736093

Epoch: 5| Step: 6
Training loss: 0.21181941032409668
Validation loss: 2.1159355292717614

Epoch: 5| Step: 7
Training loss: 0.25514036417007446
Validation loss: 2.129817247390747

Epoch: 5| Step: 8
Training loss: 0.41163572669029236
Validation loss: 2.136550704638163

Epoch: 5| Step: 9
Training loss: 0.3539823591709137
Validation loss: 2.1322887241840363

Epoch: 5| Step: 10
Training loss: 0.1850956529378891
Validation loss: 2.1149007827043533

Epoch: 5| Step: 11
Training loss: 0.3444535732269287
Validation loss: 2.0708374232053757

Epoch: 430| Step: 0
Training loss: 0.21540141105651855
Validation loss: 2.0755258252223334

Epoch: 5| Step: 1
Training loss: 0.5216659307479858
Validation loss: 2.1356987406810126

Epoch: 5| Step: 2
Training loss: 0.31041255593299866
Validation loss: 2.1146836479504905

Epoch: 5| Step: 3
Training loss: 0.2563146948814392
Validation loss: 2.1170228670040765

Epoch: 5| Step: 4
Training loss: 0.36691606044769287
Validation loss: 2.0774060487747192

Epoch: 5| Step: 5
Training loss: 0.26392072439193726
Validation loss: 2.1194659769535065

Epoch: 5| Step: 6
Training loss: 0.17626291513442993
Validation loss: 2.0734288146098456

Epoch: 5| Step: 7
Training loss: 0.3200746178627014
Validation loss: 2.0414144694805145

Epoch: 5| Step: 8
Training loss: 0.32515764236450195
Validation loss: 2.108041817943255

Epoch: 5| Step: 9
Training loss: 0.27129441499710083
Validation loss: 2.077051376303037

Epoch: 5| Step: 10
Training loss: 0.2964443862438202
Validation loss: 2.105988711118698

Epoch: 5| Step: 11
Training loss: 0.4291366934776306
Validation loss: 2.0872140179077783

Epoch: 431| Step: 0
Training loss: 0.28397563099861145
Validation loss: 2.0901317596435547

Epoch: 5| Step: 1
Training loss: 0.217377707362175
Validation loss: 2.0697428981463113

Epoch: 5| Step: 2
Training loss: 0.2367285192012787
Validation loss: 2.0921527246634164

Epoch: 5| Step: 3
Training loss: 0.32324880361557007
Validation loss: 2.075074478983879

Epoch: 5| Step: 4
Training loss: 0.3198365271091461
Validation loss: 2.0677774796883264

Epoch: 5| Step: 5
Training loss: 0.24915651977062225
Validation loss: 2.0995262215534845

Epoch: 5| Step: 6
Training loss: 0.32812103629112244
Validation loss: 2.1161096145709357

Epoch: 5| Step: 7
Training loss: 0.29623380303382874
Validation loss: 2.124604602654775

Epoch: 5| Step: 8
Training loss: 0.2550598382949829
Validation loss: 2.142490049203237

Epoch: 5| Step: 9
Training loss: 0.23676887154579163
Validation loss: 2.1467231760422387

Epoch: 5| Step: 10
Training loss: 0.5360120534896851
Validation loss: 2.1653414318958917

Epoch: 5| Step: 11
Training loss: 0.29093748331069946
Validation loss: 2.112471262613932

Epoch: 432| Step: 0
Training loss: 0.15942905843257904
Validation loss: 2.135397935907046

Epoch: 5| Step: 1
Training loss: 0.338701456785202
Validation loss: 2.106318101286888

Epoch: 5| Step: 2
Training loss: 0.2993014454841614
Validation loss: 2.069141457478205

Epoch: 5| Step: 3
Training loss: 0.27543413639068604
Validation loss: 2.0725757429997125

Epoch: 5| Step: 4
Training loss: 0.30058473348617554
Validation loss: 2.088020086288452

Epoch: 5| Step: 5
Training loss: 0.22263488173484802
Validation loss: 2.1248382975657782

Epoch: 5| Step: 6
Training loss: 0.3096657693386078
Validation loss: 2.12197038034598

Epoch: 5| Step: 7
Training loss: 0.2032327950000763
Validation loss: 2.116514503955841

Epoch: 5| Step: 8
Training loss: 0.4899154603481293
Validation loss: 2.157238870859146

Epoch: 5| Step: 9
Training loss: 0.1895160973072052
Validation loss: 2.1461467494567237

Epoch: 5| Step: 10
Training loss: 0.46122151613235474
Validation loss: 2.1416981518268585

Epoch: 5| Step: 11
Training loss: 0.39367902278900146
Validation loss: 2.1424379448095956

Epoch: 433| Step: 0
Training loss: 0.49147510528564453
Validation loss: 2.171859453121821

Epoch: 5| Step: 1
Training loss: 0.32932454347610474
Validation loss: 2.1103333979845047

Epoch: 5| Step: 2
Training loss: 0.23305697739124298
Validation loss: 2.1131430665651956

Epoch: 5| Step: 3
Training loss: 0.351065456867218
Validation loss: 2.113860676685969

Epoch: 5| Step: 4
Training loss: 0.19626423716545105
Validation loss: 2.078655237952868

Epoch: 5| Step: 5
Training loss: 0.17229869961738586
Validation loss: 2.1356883694728217

Epoch: 5| Step: 6
Training loss: 0.4656897485256195
Validation loss: 2.0841934432586036

Epoch: 5| Step: 7
Training loss: 0.2080456018447876
Validation loss: 2.085204561551412

Epoch: 5| Step: 8
Training loss: 0.37450486421585083
Validation loss: 2.0936743964751563

Epoch: 5| Step: 9
Training loss: 0.23683829605579376
Validation loss: 2.105033611257871

Epoch: 5| Step: 10
Training loss: 0.19499702751636505
Validation loss: 2.1044531067212424

Epoch: 5| Step: 11
Training loss: 0.1958070695400238
Validation loss: 2.0997922072807946

Epoch: 434| Step: 0
Training loss: 0.3149717152118683
Validation loss: 2.1118664741516113

Epoch: 5| Step: 1
Training loss: 0.17935842275619507
Validation loss: 2.1255041360855103

Epoch: 5| Step: 2
Training loss: 0.15611305832862854
Validation loss: 2.1296384185552597

Epoch: 5| Step: 3
Training loss: 0.39145371317863464
Validation loss: 2.0657345404227576

Epoch: 5| Step: 4
Training loss: 0.2599329352378845
Validation loss: 2.0608471979697547

Epoch: 5| Step: 5
Training loss: 0.217768594622612
Validation loss: 2.0797827392816544

Epoch: 5| Step: 6
Training loss: 0.33335909247398376
Validation loss: 2.0900332778692245

Epoch: 5| Step: 7
Training loss: 0.16646862030029297
Validation loss: 2.0884857972462973

Epoch: 5| Step: 8
Training loss: 0.4589925706386566
Validation loss: 2.050371011098226

Epoch: 5| Step: 9
Training loss: 0.21722061932086945
Validation loss: 2.095422680179278

Epoch: 5| Step: 10
Training loss: 0.444059282541275
Validation loss: 2.104634275039037

Epoch: 5| Step: 11
Training loss: 0.07033795118331909
Validation loss: 2.1075793157021203

Epoch: 435| Step: 0
Training loss: 0.2306729257106781
Validation loss: 2.035768002271652

Epoch: 5| Step: 1
Training loss: 0.2710639536380768
Validation loss: 2.0634111960728965

Epoch: 5| Step: 2
Training loss: 0.4766920208930969
Validation loss: 2.070974032084147

Epoch: 5| Step: 3
Training loss: 0.3649492859840393
Validation loss: 2.071836620569229

Epoch: 5| Step: 4
Training loss: 0.2190554141998291
Validation loss: 2.079447145263354

Epoch: 5| Step: 5
Training loss: 0.22537116706371307
Validation loss: 2.0741864492495856

Epoch: 5| Step: 6
Training loss: 0.37595218420028687
Validation loss: 2.0687828014294305

Epoch: 5| Step: 7
Training loss: 0.264692485332489
Validation loss: 2.117371047536532

Epoch: 5| Step: 8
Training loss: 0.24034380912780762
Validation loss: 2.0718257625897727

Epoch: 5| Step: 9
Training loss: 0.3375155031681061
Validation loss: 2.1060643245776496

Epoch: 5| Step: 10
Training loss: 0.33122220635414124
Validation loss: 2.0905614693959556

Epoch: 5| Step: 11
Training loss: 0.6188579797744751
Validation loss: 2.1273094614346824

Epoch: 436| Step: 0
Training loss: 0.21082842350006104
Validation loss: 2.1304507354895272

Epoch: 5| Step: 1
Training loss: 0.2927098870277405
Validation loss: 2.0887799113988876

Epoch: 5| Step: 2
Training loss: 0.44391441345214844
Validation loss: 2.083526849746704

Epoch: 5| Step: 3
Training loss: 0.3523542881011963
Validation loss: 2.0673831154902778

Epoch: 5| Step: 4
Training loss: 0.20034103095531464
Validation loss: 2.132591719428698

Epoch: 5| Step: 5
Training loss: 0.2447088658809662
Validation loss: 2.082263315717379

Epoch: 5| Step: 6
Training loss: 0.35801053047180176
Validation loss: 2.089475010832151

Epoch: 5| Step: 7
Training loss: 0.22523610293865204
Validation loss: 2.066543703277906

Epoch: 5| Step: 8
Training loss: 0.46503400802612305
Validation loss: 2.086359237631162

Epoch: 5| Step: 9
Training loss: 0.17197124660015106
Validation loss: 2.0767962435881295

Epoch: 5| Step: 10
Training loss: 0.20952367782592773
Validation loss: 2.0683705856402717

Epoch: 5| Step: 11
Training loss: 0.118843674659729
Validation loss: 2.0302871565024057

Epoch: 437| Step: 0
Training loss: 0.2792968153953552
Validation loss: 2.0551693389813104

Epoch: 5| Step: 1
Training loss: 0.3167005181312561
Validation loss: 2.1118450860182443

Epoch: 5| Step: 2
Training loss: 0.2240356206893921
Validation loss: 2.069859097401301

Epoch: 5| Step: 3
Training loss: 0.21825866401195526
Validation loss: 2.068054030338923

Epoch: 5| Step: 4
Training loss: 0.3151882290840149
Validation loss: 2.092118273178736

Epoch: 5| Step: 5
Training loss: 0.2245347797870636
Validation loss: 2.1097761193911233

Epoch: 5| Step: 6
Training loss: 0.2089301347732544
Validation loss: 2.0979491223891578

Epoch: 5| Step: 7
Training loss: 0.3842027485370636
Validation loss: 2.096577301621437

Epoch: 5| Step: 8
Training loss: 0.1927897334098816
Validation loss: 2.048622394601504

Epoch: 5| Step: 9
Training loss: 0.4949262738227844
Validation loss: 2.068682700395584

Epoch: 5| Step: 10
Training loss: 0.2973916232585907
Validation loss: 2.0938835193713508

Epoch: 5| Step: 11
Training loss: 0.07185842096805573
Validation loss: 2.0756480743487677

Epoch: 438| Step: 0
Training loss: 0.477877140045166
Validation loss: 2.129176909724871

Epoch: 5| Step: 1
Training loss: 0.29677626490592957
Validation loss: 2.0775298128525415

Epoch: 5| Step: 2
Training loss: 0.2812183201313019
Validation loss: 2.137730047106743

Epoch: 5| Step: 3
Training loss: 0.4960044026374817
Validation loss: 2.1186711291472116

Epoch: 5| Step: 4
Training loss: 0.2064347267150879
Validation loss: 2.111861457427343

Epoch: 5| Step: 5
Training loss: 0.3349006772041321
Validation loss: 2.0772173206011453

Epoch: 5| Step: 6
Training loss: 0.14698632061481476
Validation loss: 2.074076235294342

Epoch: 5| Step: 7
Training loss: 0.3954832851886749
Validation loss: 2.0931576987107596

Epoch: 5| Step: 8
Training loss: 0.3063879907131195
Validation loss: 2.068248212337494

Epoch: 5| Step: 9
Training loss: 0.29935216903686523
Validation loss: 2.0766944338877997

Epoch: 5| Step: 10
Training loss: 0.29276880621910095
Validation loss: 2.0834608723719916

Epoch: 5| Step: 11
Training loss: 0.18039602041244507
Validation loss: 2.1102909545103707

Epoch: 439| Step: 0
Training loss: 0.48491421341896057
Validation loss: 2.095306326945623

Epoch: 5| Step: 1
Training loss: 0.2768615782260895
Validation loss: 2.119217266639074

Epoch: 5| Step: 2
Training loss: 0.3368053138256073
Validation loss: 2.076271449526151

Epoch: 5| Step: 3
Training loss: 0.4133939743041992
Validation loss: 2.1099898169438043

Epoch: 5| Step: 4
Training loss: 0.3059121072292328
Validation loss: 2.0970768282810845

Epoch: 5| Step: 5
Training loss: 0.21087852120399475
Validation loss: 2.1102142383654914

Epoch: 5| Step: 6
Training loss: 0.22169259190559387
Validation loss: 2.071053594350815

Epoch: 5| Step: 7
Training loss: 0.1677650362253189
Validation loss: 2.069621041417122

Epoch: 5| Step: 8
Training loss: 0.2620963454246521
Validation loss: 2.0442617535591125

Epoch: 5| Step: 9
Training loss: 0.5117019414901733
Validation loss: 2.0076211790243783

Epoch: 5| Step: 10
Training loss: 0.2277267724275589
Validation loss: 2.081788624326388

Epoch: 5| Step: 11
Training loss: 0.2604246139526367
Validation loss: 2.0546772480010986

Epoch: 440| Step: 0
Training loss: 0.2169448435306549
Validation loss: 2.1138422737518945

Epoch: 5| Step: 1
Training loss: 0.3554444909095764
Validation loss: 2.110122342904409

Epoch: 5| Step: 2
Training loss: 0.2089049518108368
Validation loss: 2.0953182578086853

Epoch: 5| Step: 3
Training loss: 0.47659286856651306
Validation loss: 2.0892237424850464

Epoch: 5| Step: 4
Training loss: 0.31642597913742065
Validation loss: 2.123682990670204

Epoch: 5| Step: 5
Training loss: 0.2776033580303192
Validation loss: 2.0674685537815094

Epoch: 5| Step: 6
Training loss: 0.5757126808166504
Validation loss: 2.0694608092308044

Epoch: 5| Step: 7
Training loss: 0.327828973531723
Validation loss: 2.136868099371592

Epoch: 5| Step: 8
Training loss: 0.29836010932922363
Validation loss: 2.083769758542379

Epoch: 5| Step: 9
Training loss: 0.2516336739063263
Validation loss: 2.069051126639048

Epoch: 5| Step: 10
Training loss: 0.2496185600757599
Validation loss: 2.1146475225687027

Epoch: 5| Step: 11
Training loss: 0.10588979721069336
Validation loss: 2.0896499852339425

Epoch: 441| Step: 0
Training loss: 0.2035641223192215
Validation loss: 2.142108514904976

Epoch: 5| Step: 1
Training loss: 0.46610045433044434
Validation loss: 2.1881471474965415

Epoch: 5| Step: 2
Training loss: 0.3598707616329193
Validation loss: 2.1802408695220947

Epoch: 5| Step: 3
Training loss: 0.4326346516609192
Validation loss: 2.140334149201711

Epoch: 5| Step: 4
Training loss: 0.272928923368454
Validation loss: 2.1341418822606406

Epoch: 5| Step: 5
Training loss: 0.2150162160396576
Validation loss: 2.1167283058166504

Epoch: 5| Step: 6
Training loss: 0.3688282370567322
Validation loss: 2.1041040966908136

Epoch: 5| Step: 7
Training loss: 0.33571964502334595
Validation loss: 2.0616414844989777

Epoch: 5| Step: 8
Training loss: 0.3562912940979004
Validation loss: 2.074668124318123

Epoch: 5| Step: 9
Training loss: 0.624722957611084
Validation loss: 2.0972938189903894

Epoch: 5| Step: 10
Training loss: 0.25625160336494446
Validation loss: 2.0856824815273285

Epoch: 5| Step: 11
Training loss: 0.4157654047012329
Validation loss: 2.1120728999376297

Epoch: 442| Step: 0
Training loss: 0.19467082619667053
Validation loss: 2.1254025201002755

Epoch: 5| Step: 1
Training loss: 0.2923555374145508
Validation loss: 2.1341355741024017

Epoch: 5| Step: 2
Training loss: 0.2943582534790039
Validation loss: 2.1528721849123635

Epoch: 5| Step: 3
Training loss: 0.6994829773902893
Validation loss: 2.14318477610747

Epoch: 5| Step: 4
Training loss: 0.2230512648820877
Validation loss: 2.1237995823224387

Epoch: 5| Step: 5
Training loss: 0.35406818985939026
Validation loss: 2.1503317256768546

Epoch: 5| Step: 6
Training loss: 0.1554197072982788
Validation loss: 2.0588476409514747

Epoch: 5| Step: 7
Training loss: 0.1842767894268036
Validation loss: 2.073434149225553

Epoch: 5| Step: 8
Training loss: 0.2654421925544739
Validation loss: 2.088597983121872

Epoch: 5| Step: 9
Training loss: 0.360207736492157
Validation loss: 2.101355016231537

Epoch: 5| Step: 10
Training loss: 0.39784765243530273
Validation loss: 2.073309371868769

Epoch: 5| Step: 11
Training loss: 0.08950436115264893
Validation loss: 2.106662094593048

Epoch: 443| Step: 0
Training loss: 0.23573270440101624
Validation loss: 2.0980898241202035

Epoch: 5| Step: 1
Training loss: 0.2563961446285248
Validation loss: 2.087271422147751

Epoch: 5| Step: 2
Training loss: 0.16797931492328644
Validation loss: 2.1524388591448465

Epoch: 5| Step: 3
Training loss: 0.2815091609954834
Validation loss: 2.093524028857549

Epoch: 5| Step: 4
Training loss: 0.3345542550086975
Validation loss: 2.131554608543714

Epoch: 5| Step: 5
Training loss: 0.2003636658191681
Validation loss: 2.1244349628686905

Epoch: 5| Step: 6
Training loss: 0.2175472229719162
Validation loss: 2.083247164885203

Epoch: 5| Step: 7
Training loss: 0.2564588189125061
Validation loss: 2.0904183139403663

Epoch: 5| Step: 8
Training loss: 0.4898990988731384
Validation loss: 2.1114118496576944

Epoch: 5| Step: 9
Training loss: 0.2523457407951355
Validation loss: 2.0682867765426636

Epoch: 5| Step: 10
Training loss: 0.5592665076255798
Validation loss: 2.0912582774957023

Epoch: 5| Step: 11
Training loss: 0.8231396675109863
Validation loss: 2.1088615357875824

Epoch: 444| Step: 0
Training loss: 0.329619824886322
Validation loss: 2.1011203080415726

Epoch: 5| Step: 1
Training loss: 0.34159940481185913
Validation loss: 2.144801065325737

Epoch: 5| Step: 2
Training loss: 0.33483949303627014
Validation loss: 2.152936498324076

Epoch: 5| Step: 3
Training loss: 0.3427160978317261
Validation loss: 2.134935180346171

Epoch: 5| Step: 4
Training loss: 0.22064778208732605
Validation loss: 2.085253099600474

Epoch: 5| Step: 5
Training loss: 0.31497228145599365
Validation loss: 2.0893282890319824

Epoch: 5| Step: 6
Training loss: 0.2373083084821701
Validation loss: 2.0706974218289056

Epoch: 5| Step: 7
Training loss: 0.18297111988067627
Validation loss: 2.1008178095022836

Epoch: 5| Step: 8
Training loss: 0.2423245906829834
Validation loss: 2.121512711048126

Epoch: 5| Step: 9
Training loss: 0.5507036447525024
Validation loss: 2.066695829232534

Epoch: 5| Step: 10
Training loss: 0.15467163920402527
Validation loss: 2.1138548105955124

Epoch: 5| Step: 11
Training loss: 0.27340584993362427
Validation loss: 2.1304343541463218

Epoch: 445| Step: 0
Training loss: 0.29779791831970215
Validation loss: 2.1079591810703278

Epoch: 5| Step: 1
Training loss: 0.3550907373428345
Validation loss: 2.1108931501706443

Epoch: 5| Step: 2
Training loss: 0.2930507957935333
Validation loss: 2.131295214096705

Epoch: 5| Step: 3
Training loss: 0.17998690903186798
Validation loss: 2.1019016901652017

Epoch: 5| Step: 4
Training loss: 0.367308646440506
Validation loss: 2.1324242999156318

Epoch: 5| Step: 5
Training loss: 0.23482272028923035
Validation loss: 2.1182751109202704

Epoch: 5| Step: 6
Training loss: 0.2577436566352844
Validation loss: 2.1658897350231805

Epoch: 5| Step: 7
Training loss: 0.273567259311676
Validation loss: 2.112072835365931

Epoch: 5| Step: 8
Training loss: 0.3136514127254486
Validation loss: 2.0949589858452478

Epoch: 5| Step: 9
Training loss: 0.1704801768064499
Validation loss: 2.15140937268734

Epoch: 5| Step: 10
Training loss: 0.4287989139556885
Validation loss: 2.1051923781633377

Epoch: 5| Step: 11
Training loss: 0.20987868309020996
Validation loss: 2.091739147901535

Epoch: 446| Step: 0
Training loss: 0.4776341915130615
Validation loss: 2.0606090823809304

Epoch: 5| Step: 1
Training loss: 0.2249070703983307
Validation loss: 2.0666871468226113

Epoch: 5| Step: 2
Training loss: 0.27140018343925476
Validation loss: 2.0394468953212104

Epoch: 5| Step: 3
Training loss: 0.2465500384569168
Validation loss: 2.0905313342809677

Epoch: 5| Step: 4
Training loss: 0.2162599116563797
Validation loss: 2.097162445386251

Epoch: 5| Step: 5
Training loss: 0.29571837186813354
Validation loss: 2.1010151356458664

Epoch: 5| Step: 6
Training loss: 0.3120273947715759
Validation loss: 2.0639681865771613

Epoch: 5| Step: 7
Training loss: 0.194656103849411
Validation loss: 2.095306475957235

Epoch: 5| Step: 8
Training loss: 0.23499050736427307
Validation loss: 2.0761045018831887

Epoch: 5| Step: 9
Training loss: 0.31830257177352905
Validation loss: 2.0808596909046173

Epoch: 5| Step: 10
Training loss: 0.2947581112384796
Validation loss: 2.108577792843183

Epoch: 5| Step: 11
Training loss: 0.26022645831108093
Validation loss: 2.0268625915050507

Epoch: 447| Step: 0
Training loss: 0.5952924489974976
Validation loss: 2.0901407251755395

Epoch: 5| Step: 1
Training loss: 0.2524758279323578
Validation loss: 2.0483226478099823

Epoch: 5| Step: 2
Training loss: 0.2175890952348709
Validation loss: 2.085730324188868

Epoch: 5| Step: 3
Training loss: 0.1952868551015854
Validation loss: 2.090380663673083

Epoch: 5| Step: 4
Training loss: 0.3130829632282257
Validation loss: 2.067911754051844

Epoch: 5| Step: 5
Training loss: 0.15509021282196045
Validation loss: 2.049707591533661

Epoch: 5| Step: 6
Training loss: 0.25170716643333435
Validation loss: 2.1153582582871118

Epoch: 5| Step: 7
Training loss: 0.17453721165657043
Validation loss: 2.129520277182261

Epoch: 5| Step: 8
Training loss: 0.2742972671985626
Validation loss: 2.077158028880755

Epoch: 5| Step: 9
Training loss: 0.23588857054710388
Validation loss: 2.1415075957775116

Epoch: 5| Step: 10
Training loss: 0.35951554775238037
Validation loss: 2.07867431640625

Epoch: 5| Step: 11
Training loss: 0.23572051525115967
Validation loss: 2.091388612985611

Epoch: 448| Step: 0
Training loss: 0.2387530505657196
Validation loss: 2.108862981200218

Epoch: 5| Step: 1
Training loss: 0.33953166007995605
Validation loss: 2.075624560316404

Epoch: 5| Step: 2
Training loss: 0.3556936979293823
Validation loss: 2.0943037221829095

Epoch: 5| Step: 3
Training loss: 0.43995437026023865
Validation loss: 2.117004225651423

Epoch: 5| Step: 4
Training loss: 0.27851757407188416
Validation loss: 2.0945706764856973

Epoch: 5| Step: 5
Training loss: 0.41726407408714294
Validation loss: 2.075010508298874

Epoch: 5| Step: 6
Training loss: 0.2642175853252411
Validation loss: 2.109423895676931

Epoch: 5| Step: 7
Training loss: 0.2019701898097992
Validation loss: 2.0990841587384543

Epoch: 5| Step: 8
Training loss: 0.2650887370109558
Validation loss: 2.114926482240359

Epoch: 5| Step: 9
Training loss: 0.24759244918823242
Validation loss: 2.144412333766619

Epoch: 5| Step: 10
Training loss: 0.3255489468574524
Validation loss: 2.0759109954039254

Epoch: 5| Step: 11
Training loss: 0.19906675815582275
Validation loss: 2.079990645249685

Epoch: 449| Step: 0
Training loss: 0.4078451693058014
Validation loss: 2.076073706150055

Epoch: 5| Step: 1
Training loss: 0.2042882889509201
Validation loss: 2.061795045932134

Epoch: 5| Step: 2
Training loss: 0.2191338986158371
Validation loss: 2.1241788367430368

Epoch: 5| Step: 3
Training loss: 0.2095087468624115
Validation loss: 2.093348200122515

Epoch: 5| Step: 4
Training loss: 0.2089255303144455
Validation loss: 2.0491888175408044

Epoch: 5| Step: 5
Training loss: 0.1733599603176117
Validation loss: 2.077117661635081

Epoch: 5| Step: 6
Training loss: 0.16965484619140625
Validation loss: 2.060546184579531

Epoch: 5| Step: 7
Training loss: 0.5758221745491028
Validation loss: 2.0635004341602325

Epoch: 5| Step: 8
Training loss: 0.2091180384159088
Validation loss: 2.095094159245491

Epoch: 5| Step: 9
Training loss: 0.3509970009326935
Validation loss: 2.1111715932687125

Epoch: 5| Step: 10
Training loss: 0.3083418905735016
Validation loss: 2.0960739850997925

Epoch: 5| Step: 11
Training loss: 0.2512216567993164
Validation loss: 2.068547864754995

Epoch: 450| Step: 0
Training loss: 0.18964442610740662
Validation loss: 2.139576037724813

Epoch: 5| Step: 1
Training loss: 0.3333788514137268
Validation loss: 2.1117199261983237

Epoch: 5| Step: 2
Training loss: 0.15784557163715363
Validation loss: 2.10215957959493

Epoch: 5| Step: 3
Training loss: 0.4349140524864197
Validation loss: 2.168589770793915

Epoch: 5| Step: 4
Training loss: 0.42241963744163513
Validation loss: 2.112255791823069

Epoch: 5| Step: 5
Training loss: 0.2858855128288269
Validation loss: 2.1192761957645416

Epoch: 5| Step: 6
Training loss: 0.42574724555015564
Validation loss: 2.1071048925320306

Epoch: 5| Step: 7
Training loss: 0.12695445120334625
Validation loss: 2.0780727167924247

Epoch: 5| Step: 8
Training loss: 0.2255944460630417
Validation loss: 2.0465690990289054

Epoch: 5| Step: 9
Training loss: 0.5151115655899048
Validation loss: 2.105033189058304

Epoch: 5| Step: 10
Training loss: 0.1900213211774826
Validation loss: 2.099734048048655

Epoch: 5| Step: 11
Training loss: 0.1959904283285141
Validation loss: 2.1223358561595282

Testing loss: 1.9892670748045118
