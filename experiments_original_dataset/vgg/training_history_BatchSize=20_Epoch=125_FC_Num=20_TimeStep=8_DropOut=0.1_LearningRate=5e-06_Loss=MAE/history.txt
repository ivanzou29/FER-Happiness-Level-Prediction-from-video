Epoch: 1| Step: 0
Training loss: 2.998985767364502
Validation loss: 2.8497131864229837

Epoch: 5| Step: 1
Training loss: 2.722677707672119
Validation loss: 2.8385961254437766

Epoch: 5| Step: 2
Training loss: 3.4161477088928223
Validation loss: 2.824669271707535

Epoch: 5| Step: 3
Training loss: 2.164973020553589
Validation loss: 2.816140433152517

Epoch: 5| Step: 4
Training loss: 2.9180502891540527
Validation loss: 2.805259555578232

Epoch: 5| Step: 5
Training loss: 3.302671432495117
Validation loss: 2.790447493394216

Epoch: 5| Step: 6
Training loss: 2.3133091926574707
Validation loss: 2.7827544609705606

Epoch: 5| Step: 7
Training loss: 2.7692747116088867
Validation loss: 2.769227753082911

Epoch: 5| Step: 8
Training loss: 3.560236692428589
Validation loss: 2.7590536077817283

Epoch: 5| Step: 9
Training loss: 2.8503735065460205
Validation loss: 2.7496998806794486

Epoch: 5| Step: 10
Training loss: 3.468911647796631
Validation loss: 2.7388774355252585

Epoch: 5| Step: 11
Training loss: 5.010983467102051
Validation loss: 2.730672279993693

Epoch: 2| Step: 0
Training loss: 3.0560383796691895
Validation loss: 2.7190401752789817

Epoch: 5| Step: 1
Training loss: 2.8110177516937256
Validation loss: 2.699736644824346

Epoch: 5| Step: 2
Training loss: 2.4611892700195312
Validation loss: 2.690531015396118

Epoch: 5| Step: 3
Training loss: 3.0864243507385254
Validation loss: 2.677870978911718

Epoch: 5| Step: 4
Training loss: 3.0308585166931152
Validation loss: 2.6667878528436026

Epoch: 5| Step: 5
Training loss: 2.9314827919006348
Validation loss: 2.647845427195231

Epoch: 5| Step: 6
Training loss: 3.020555019378662
Validation loss: 2.63261079788208

Epoch: 5| Step: 7
Training loss: 2.9574360847473145
Validation loss: 2.620681961377462

Epoch: 5| Step: 8
Training loss: 2.910771608352661
Validation loss: 2.60199573636055

Epoch: 5| Step: 9
Training loss: 2.342822313308716
Validation loss: 2.5795482198397317

Epoch: 5| Step: 10
Training loss: 2.3555831909179688
Validation loss: 2.5657945772012076

Epoch: 5| Step: 11
Training loss: 2.972982168197632
Validation loss: 2.541561265786489

Epoch: 3| Step: 0
Training loss: 2.872300863265991
Validation loss: 2.5232377449671426

Epoch: 5| Step: 1
Training loss: 2.821052074432373
Validation loss: 2.500893294811249

Epoch: 5| Step: 2
Training loss: 2.0325984954833984
Validation loss: 2.4771075497070947

Epoch: 5| Step: 3
Training loss: 2.511971950531006
Validation loss: 2.449557274580002

Epoch: 5| Step: 4
Training loss: 2.1510000228881836
Validation loss: 2.4206760128339133

Epoch: 5| Step: 5
Training loss: 2.2737133502960205
Validation loss: 2.395477299888929

Epoch: 5| Step: 6
Training loss: 2.376868724822998
Validation loss: 2.3701671759287515

Epoch: 5| Step: 7
Training loss: 2.4483847618103027
Validation loss: 2.343889514605204

Epoch: 5| Step: 8
Training loss: 3.262674331665039
Validation loss: 2.326303005218506

Epoch: 5| Step: 9
Training loss: 2.2453460693359375
Validation loss: 2.2833425203959146

Epoch: 5| Step: 10
Training loss: 2.5895354747772217
Validation loss: 2.253565023342768

Epoch: 5| Step: 11
Training loss: 2.1708850860595703
Validation loss: 2.2190214296182

Epoch: 4| Step: 0
Training loss: 2.3094115257263184
Validation loss: 2.188460553685824

Epoch: 5| Step: 1
Training loss: 2.193570852279663
Validation loss: 2.1633390535910926

Epoch: 5| Step: 2
Training loss: 1.7336448431015015
Validation loss: 2.153117204705874

Epoch: 5| Step: 3
Training loss: 2.935636043548584
Validation loss: 2.114813968539238

Epoch: 5| Step: 4
Training loss: 2.087327718734741
Validation loss: 2.0896282146374383

Epoch: 5| Step: 5
Training loss: 1.9240211248397827
Validation loss: 2.085775370399157

Epoch: 5| Step: 6
Training loss: 1.9690927267074585
Validation loss: 2.063467025756836

Epoch: 5| Step: 7
Training loss: 2.3333287239074707
Validation loss: 2.0478250980377197

Epoch: 5| Step: 8
Training loss: 2.158921718597412
Validation loss: 2.030897299448649

Epoch: 5| Step: 9
Training loss: 1.6773903369903564
Validation loss: 2.0210360288619995

Epoch: 5| Step: 10
Training loss: 2.5769410133361816
Validation loss: 2.0258914629618325

Epoch: 5| Step: 11
Training loss: 1.8975321054458618
Validation loss: 2.035143400231997

Epoch: 5| Step: 0
Training loss: 2.157055377960205
Validation loss: 2.0378080556790032

Epoch: 5| Step: 1
Training loss: 1.9653797149658203
Validation loss: 2.0553177098433175

Epoch: 5| Step: 2
Training loss: 2.185364007949829
Validation loss: 2.050324946641922

Epoch: 5| Step: 3
Training loss: 2.9813737869262695
Validation loss: 2.042611156900724

Epoch: 5| Step: 4
Training loss: 2.2076892852783203
Validation loss: 2.046172261238098

Epoch: 5| Step: 5
Training loss: 2.405172824859619
Validation loss: 2.049328605333964

Epoch: 5| Step: 6
Training loss: 2.510155439376831
Validation loss: 2.0431921581427255

Epoch: 5| Step: 7
Training loss: 1.4641730785369873
Validation loss: 2.060647909839948

Epoch: 5| Step: 8
Training loss: 1.5176639556884766
Validation loss: 2.0502316057682037

Epoch: 5| Step: 9
Training loss: 1.2895426750183105
Validation loss: 2.0593834469715753

Epoch: 5| Step: 10
Training loss: 1.7885997295379639
Validation loss: 2.061389446258545

Epoch: 5| Step: 11
Training loss: 3.144434928894043
Validation loss: 2.0697011202573776

Epoch: 6| Step: 0
Training loss: 1.7272922992706299
Validation loss: 2.07259734471639

Epoch: 5| Step: 1
Training loss: 2.1166110038757324
Validation loss: 2.0726507951815925

Epoch: 5| Step: 2
Training loss: 1.9520318508148193
Validation loss: 2.0693617165088654

Epoch: 5| Step: 3
Training loss: 2.031618356704712
Validation loss: 2.0606916695833206

Epoch: 5| Step: 4
Training loss: 1.8240734338760376
Validation loss: 2.0220983177423477

Epoch: 5| Step: 5
Training loss: 2.4154906272888184
Validation loss: 2.0326631565888724

Epoch: 5| Step: 6
Training loss: 1.8038866519927979
Validation loss: 2.034499188264211

Epoch: 5| Step: 7
Training loss: 2.0924153327941895
Validation loss: 2.0232262214024863

Epoch: 5| Step: 8
Training loss: 2.216320037841797
Validation loss: 2.022532323996226

Epoch: 5| Step: 9
Training loss: 2.3246448040008545
Validation loss: 2.0169661541779837

Epoch: 5| Step: 10
Training loss: 1.9915258884429932
Validation loss: 2.0307514021794

Epoch: 5| Step: 11
Training loss: 2.825134038925171
Validation loss: 2.018692915638288

Epoch: 7| Step: 0
Training loss: 1.969663381576538
Validation loss: 2.013284424940745

Epoch: 5| Step: 1
Training loss: 2.3814597129821777
Validation loss: 2.0173624604940414

Epoch: 5| Step: 2
Training loss: 2.0085179805755615
Validation loss: 2.014949177702268

Epoch: 5| Step: 3
Training loss: 2.298203468322754
Validation loss: 2.0140292843182883

Epoch: 5| Step: 4
Training loss: 2.192755937576294
Validation loss: 2.020810847481092

Epoch: 5| Step: 5
Training loss: 1.8011960983276367
Validation loss: 2.017916291952133

Epoch: 5| Step: 6
Training loss: 1.7452938556671143
Validation loss: 2.023808255791664

Epoch: 5| Step: 7
Training loss: 2.0274181365966797
Validation loss: 2.0195872485637665

Epoch: 5| Step: 8
Training loss: 2.1583914756774902
Validation loss: 2.00336691737175

Epoch: 5| Step: 9
Training loss: 2.236647367477417
Validation loss: 1.9925641963879268

Epoch: 5| Step: 10
Training loss: 2.157010793685913
Validation loss: 2.0028487543265023

Epoch: 5| Step: 11
Training loss: 1.1481174230575562
Validation loss: 2.0095538149277368

Epoch: 8| Step: 0
Training loss: 2.09567928314209
Validation loss: 1.9907345573107402

Epoch: 5| Step: 1
Training loss: 2.2453107833862305
Validation loss: 2.027065192659696

Epoch: 5| Step: 2
Training loss: 2.2240493297576904
Validation loss: 2.039937749505043

Epoch: 5| Step: 3
Training loss: 1.810786485671997
Validation loss: 2.0593369901180267

Epoch: 5| Step: 4
Training loss: 2.340681791305542
Validation loss: 2.0853826304276786

Epoch: 5| Step: 5
Training loss: 2.0491597652435303
Validation loss: 2.0841763764619827

Epoch: 5| Step: 6
Training loss: 1.3846842050552368
Validation loss: 2.111748014887174

Epoch: 5| Step: 7
Training loss: 2.2466354370117188
Validation loss: 2.095521718263626

Epoch: 5| Step: 8
Training loss: 1.6446771621704102
Validation loss: 2.1277307669321694

Epoch: 5| Step: 9
Training loss: 1.719842553138733
Validation loss: 2.094643473625183

Epoch: 5| Step: 10
Training loss: 3.0321578979492188
Validation loss: 2.0814906855424247

Epoch: 5| Step: 11
Training loss: 2.07084321975708
Validation loss: 2.078633740544319

Epoch: 9| Step: 0
Training loss: 2.0812652111053467
Validation loss: 2.055391877889633

Epoch: 5| Step: 1
Training loss: 1.8099603652954102
Validation loss: 2.058811739087105

Epoch: 5| Step: 2
Training loss: 2.6761763095855713
Validation loss: 2.0196308493614197

Epoch: 5| Step: 3
Training loss: 2.068610668182373
Validation loss: 2.027316689491272

Epoch: 5| Step: 4
Training loss: 1.9213424921035767
Validation loss: 2.0106027324994407

Epoch: 5| Step: 5
Training loss: 2.67932391166687
Validation loss: 1.9915460050106049

Epoch: 5| Step: 6
Training loss: 1.8138043880462646
Validation loss: 1.9995726098616917

Epoch: 5| Step: 7
Training loss: 1.6902450323104858
Validation loss: 2.0028519282738366

Epoch: 5| Step: 8
Training loss: 2.030595064163208
Validation loss: 1.982154553135236

Epoch: 5| Step: 9
Training loss: 2.2182586193084717
Validation loss: 1.997915968298912

Epoch: 5| Step: 10
Training loss: 1.3553391695022583
Validation loss: 1.9901197403669357

Epoch: 5| Step: 11
Training loss: 2.1570653915405273
Validation loss: 1.9895910372336705

Epoch: 10| Step: 0
Training loss: 1.9642512798309326
Validation loss: 1.9963783423105876

Epoch: 5| Step: 1
Training loss: 1.761914849281311
Validation loss: 1.992220178246498

Epoch: 5| Step: 2
Training loss: 2.029684543609619
Validation loss: 2.017885039250056

Epoch: 5| Step: 3
Training loss: 1.7480751276016235
Validation loss: 2.0098402748505273

Epoch: 5| Step: 4
Training loss: 1.7560234069824219
Validation loss: 1.9989659239848454

Epoch: 5| Step: 5
Training loss: 2.0808119773864746
Validation loss: 2.0086012333631516

Epoch: 5| Step: 6
Training loss: 2.2336907386779785
Validation loss: 2.017049252986908

Epoch: 5| Step: 7
Training loss: 3.1413650512695312
Validation loss: 2.0288386146227517

Epoch: 5| Step: 8
Training loss: 1.9853870868682861
Validation loss: 2.0436581323544183

Epoch: 5| Step: 9
Training loss: 1.7186733484268188
Validation loss: 2.0176812211672464

Epoch: 5| Step: 10
Training loss: 2.1685304641723633
Validation loss: 2.0344278216362

Epoch: 5| Step: 11
Training loss: 2.4509477615356445
Validation loss: 2.042622451980909

Epoch: 11| Step: 0
Training loss: 2.691890239715576
Validation loss: 2.0222326715787253

Epoch: 5| Step: 1
Training loss: 1.9236996173858643
Validation loss: 2.0272791584332785

Epoch: 5| Step: 2
Training loss: 1.55551278591156
Validation loss: 2.0089485148588815

Epoch: 5| Step: 3
Training loss: 2.095227003097534
Validation loss: 2.0043925990660987

Epoch: 5| Step: 4
Training loss: 1.6548618078231812
Validation loss: 1.993177314599355

Epoch: 5| Step: 5
Training loss: 1.8392356634140015
Validation loss: 1.9870951275030773

Epoch: 5| Step: 6
Training loss: 2.4589927196502686
Validation loss: 1.9912611444791157

Epoch: 5| Step: 7
Training loss: 2.146552801132202
Validation loss: 1.9859474003314972

Epoch: 5| Step: 8
Training loss: 2.404461622238159
Validation loss: 2.001396124561628

Epoch: 5| Step: 9
Training loss: 1.5283129215240479
Validation loss: 1.9806153774261475

Epoch: 5| Step: 10
Training loss: 2.3321738243103027
Validation loss: 1.98325015604496

Epoch: 5| Step: 11
Training loss: 1.2827755212783813
Validation loss: 1.9871263404687245

Epoch: 12| Step: 0
Training loss: 2.032095193862915
Validation loss: 1.9773943722248077

Epoch: 5| Step: 1
Training loss: 1.4146274328231812
Validation loss: 1.99050069351991

Epoch: 5| Step: 2
Training loss: 2.242982864379883
Validation loss: 2.01157508790493

Epoch: 5| Step: 3
Training loss: 1.868726134300232
Validation loss: 2.013746534784635

Epoch: 5| Step: 4
Training loss: 2.324672222137451
Validation loss: 2.019359052181244

Epoch: 5| Step: 5
Training loss: 2.2608232498168945
Validation loss: 2.0409231881300607

Epoch: 5| Step: 6
Training loss: 1.9612605571746826
Validation loss: 2.0633782098690667

Epoch: 5| Step: 7
Training loss: 1.9510902166366577
Validation loss: 2.060228019952774

Epoch: 5| Step: 8
Training loss: 1.7917194366455078
Validation loss: 2.075611104567846

Epoch: 5| Step: 9
Training loss: 2.0253448486328125
Validation loss: 2.085321550567945

Epoch: 5| Step: 10
Training loss: 2.702484607696533
Validation loss: 2.094740162293116

Epoch: 5| Step: 11
Training loss: 1.8857667446136475
Validation loss: 2.0574684341748557

Epoch: 13| Step: 0
Training loss: 1.3658065795898438
Validation loss: 2.0530994832515717

Epoch: 5| Step: 1
Training loss: 1.8235679864883423
Validation loss: 2.0423049380381904

Epoch: 5| Step: 2
Training loss: 2.137962818145752
Validation loss: 2.0364279399315515

Epoch: 5| Step: 3
Training loss: 2.0962376594543457
Validation loss: 2.0103414555390677

Epoch: 5| Step: 4
Training loss: 2.2249810695648193
Validation loss: 2.036318843563398

Epoch: 5| Step: 5
Training loss: 1.9810320138931274
Validation loss: 1.9873245060443878

Epoch: 5| Step: 6
Training loss: 2.169647455215454
Validation loss: 2.0051040848096213

Epoch: 5| Step: 7
Training loss: 1.9011256694793701
Validation loss: 2.017764151096344

Epoch: 5| Step: 8
Training loss: 2.1446220874786377
Validation loss: 1.995267187555631

Epoch: 5| Step: 9
Training loss: 1.8417625427246094
Validation loss: 1.9968227098385494

Epoch: 5| Step: 10
Training loss: 2.3806681632995605
Validation loss: 1.992006778717041

Epoch: 5| Step: 11
Training loss: 2.826295852661133
Validation loss: 2.00689805050691

Epoch: 14| Step: 0
Training loss: 2.0046639442443848
Validation loss: 1.9824548264344533

Epoch: 5| Step: 1
Training loss: 2.2528412342071533
Validation loss: 2.0095587372779846

Epoch: 5| Step: 2
Training loss: 2.432939052581787
Validation loss: 1.991947164138158

Epoch: 5| Step: 3
Training loss: 1.736505150794983
Validation loss: 1.990417222181956

Epoch: 5| Step: 4
Training loss: 1.896564245223999
Validation loss: 1.985230619708697

Epoch: 5| Step: 5
Training loss: 1.905707597732544
Validation loss: 2.0041254659493766

Epoch: 5| Step: 6
Training loss: 2.1476263999938965
Validation loss: 1.9735558877388637

Epoch: 5| Step: 7
Training loss: 2.460222005844116
Validation loss: 1.9852479845285416

Epoch: 5| Step: 8
Training loss: 2.5057742595672607
Validation loss: 2.00590185324351

Epoch: 5| Step: 9
Training loss: 1.6677697896957397
Validation loss: 2.0054299434026084

Epoch: 5| Step: 10
Training loss: 1.2488645315170288
Validation loss: 2.0097682774066925

Epoch: 5| Step: 11
Training loss: 1.810988426208496
Validation loss: 2.0128175914287567

Epoch: 15| Step: 0
Training loss: 1.974582314491272
Validation loss: 1.9996462066968281

Epoch: 5| Step: 1
Training loss: 1.7526085376739502
Validation loss: 2.013957435886065

Epoch: 5| Step: 2
Training loss: 1.9367011785507202
Validation loss: 2.012356827656428

Epoch: 5| Step: 3
Training loss: 1.6989753246307373
Validation loss: 2.006150727470716

Epoch: 5| Step: 4
Training loss: 1.492736577987671
Validation loss: 2.0311255951722464

Epoch: 5| Step: 5
Training loss: 2.2165493965148926
Validation loss: 2.016156251231829

Epoch: 5| Step: 6
Training loss: 1.7334883213043213
Validation loss: 2.0111347138881683

Epoch: 5| Step: 7
Training loss: 1.7607650756835938
Validation loss: 2.0184151331583657

Epoch: 5| Step: 8
Training loss: 2.151008129119873
Validation loss: 2.0382517029841742

Epoch: 5| Step: 9
Training loss: 2.6437535285949707
Validation loss: 2.0438386499881744

Epoch: 5| Step: 10
Training loss: 2.60107684135437
Validation loss: 2.0234001825253167

Epoch: 5| Step: 11
Training loss: 1.9263044595718384
Validation loss: 2.0406356304883957

Epoch: 16| Step: 0
Training loss: 2.16467547416687
Validation loss: 2.0442047268152237

Epoch: 5| Step: 1
Training loss: 2.331483840942383
Validation loss: 2.02402929464976

Epoch: 5| Step: 2
Training loss: 2.8289175033569336
Validation loss: 2.03036992251873

Epoch: 5| Step: 3
Training loss: 1.5350563526153564
Validation loss: 2.009689877430598

Epoch: 5| Step: 4
Training loss: 1.702903151512146
Validation loss: 2.029243975877762

Epoch: 5| Step: 5
Training loss: 1.6574068069458008
Validation loss: 2.020908907055855

Epoch: 5| Step: 6
Training loss: 1.6195132732391357
Validation loss: 2.0020727664232254

Epoch: 5| Step: 7
Training loss: 1.9862617254257202
Validation loss: 2.002913494904836

Epoch: 5| Step: 8
Training loss: 1.7932119369506836
Validation loss: 2.0007555882136026

Epoch: 5| Step: 9
Training loss: 2.2784264087677
Validation loss: 1.990279992421468

Epoch: 5| Step: 10
Training loss: 2.340857982635498
Validation loss: 2.0063225428263345

Epoch: 5| Step: 11
Training loss: 1.202980875968933
Validation loss: 1.991647645831108

Epoch: 17| Step: 0
Training loss: 2.3980255126953125
Validation loss: 1.9807591785987217

Epoch: 5| Step: 1
Training loss: 1.9354177713394165
Validation loss: 2.0027459214131036

Epoch: 5| Step: 2
Training loss: 1.8620872497558594
Validation loss: 1.9879425565401714

Epoch: 5| Step: 3
Training loss: 2.6315367221832275
Validation loss: 1.9727395524581273

Epoch: 5| Step: 4
Training loss: 2.0957653522491455
Validation loss: 1.9842719435691833

Epoch: 5| Step: 5
Training loss: 2.0939934253692627
Validation loss: 1.9845381379127502

Epoch: 5| Step: 6
Training loss: 2.005309581756592
Validation loss: 1.976332073410352

Epoch: 5| Step: 7
Training loss: 1.7176300287246704
Validation loss: 1.9791781604290009

Epoch: 5| Step: 8
Training loss: 1.7074159383773804
Validation loss: 1.9963393410046895

Epoch: 5| Step: 9
Training loss: 1.9689016342163086
Validation loss: 1.9761190116405487

Epoch: 5| Step: 10
Training loss: 1.6086618900299072
Validation loss: 1.9939937591552734

Epoch: 5| Step: 11
Training loss: 1.773824691772461
Validation loss: 1.9866521408160527

Epoch: 18| Step: 0
Training loss: 2.3292739391326904
Validation loss: 1.997259298960368

Epoch: 5| Step: 1
Training loss: 2.9484732151031494
Validation loss: 2.005795737107595

Epoch: 5| Step: 2
Training loss: 2.137409210205078
Validation loss: 2.033098131418228

Epoch: 5| Step: 3
Training loss: 1.816788911819458
Validation loss: 1.9977855583031972

Epoch: 5| Step: 4
Training loss: 1.7443630695343018
Validation loss: 2.0299533804257712

Epoch: 5| Step: 5
Training loss: 1.781542181968689
Validation loss: 2.019101063410441

Epoch: 5| Step: 6
Training loss: 1.549704909324646
Validation loss: 2.034600014487902

Epoch: 5| Step: 7
Training loss: 1.870226263999939
Validation loss: 2.0305867940187454

Epoch: 5| Step: 8
Training loss: 2.0970916748046875
Validation loss: 2.03980515897274

Epoch: 5| Step: 9
Training loss: 1.8536440134048462
Validation loss: 2.04477392633756

Epoch: 5| Step: 10
Training loss: 1.601782202720642
Validation loss: 2.038668915629387

Epoch: 5| Step: 11
Training loss: 2.1575236320495605
Validation loss: 2.01908470193545

Epoch: 19| Step: 0
Training loss: 2.1179404258728027
Validation loss: 2.0253538290659585

Epoch: 5| Step: 1
Training loss: 1.9064066410064697
Validation loss: 2.0303424894809723

Epoch: 5| Step: 2
Training loss: 2.303354263305664
Validation loss: 2.04889585574468

Epoch: 5| Step: 3
Training loss: 2.2347166538238525
Validation loss: 2.0178356816371283

Epoch: 5| Step: 4
Training loss: 1.8584327697753906
Validation loss: 2.0164252569278083

Epoch: 5| Step: 5
Training loss: 1.85027277469635
Validation loss: 2.001479317744573

Epoch: 5| Step: 6
Training loss: 2.461195468902588
Validation loss: 2.021465376019478

Epoch: 5| Step: 7
Training loss: 1.9184564352035522
Validation loss: 2.0089542269706726

Epoch: 5| Step: 8
Training loss: 2.0467147827148438
Validation loss: 2.006535972158114

Epoch: 5| Step: 9
Training loss: 1.5238609313964844
Validation loss: 2.0066007574399314

Epoch: 5| Step: 10
Training loss: 1.6104949712753296
Validation loss: 1.9970896542072296

Epoch: 5| Step: 11
Training loss: 1.6270722150802612
Validation loss: 2.0429017593463263

Epoch: 20| Step: 0
Training loss: 1.9974384307861328
Validation loss: 1.978982463479042

Epoch: 5| Step: 1
Training loss: 2.1490437984466553
Validation loss: 1.9813047697146733

Epoch: 5| Step: 2
Training loss: 2.0781922340393066
Validation loss: 1.9916659891605377

Epoch: 5| Step: 3
Training loss: 1.7542083263397217
Validation loss: 1.9628442376852036

Epoch: 5| Step: 4
Training loss: 1.7448638677597046
Validation loss: 1.9912946224212646

Epoch: 5| Step: 5
Training loss: 1.2376145124435425
Validation loss: 1.9741951922575633

Epoch: 5| Step: 6
Training loss: 1.6014131307601929
Validation loss: 1.9758040408293407

Epoch: 5| Step: 7
Training loss: 2.059556484222412
Validation loss: 1.980960617462794

Epoch: 5| Step: 8
Training loss: 2.4456417560577393
Validation loss: 1.9777563959360123

Epoch: 5| Step: 9
Training loss: 2.3198554515838623
Validation loss: 1.987907315293948

Epoch: 5| Step: 10
Training loss: 2.3298182487487793
Validation loss: 1.9824119706948597

Epoch: 5| Step: 11
Training loss: 2.1860079765319824
Validation loss: 1.9689813007911046

Epoch: 21| Step: 0
Training loss: 1.9448976516723633
Validation loss: 1.9635616689920425

Epoch: 5| Step: 1
Training loss: 2.125450372695923
Validation loss: 1.9712843994299571

Epoch: 5| Step: 2
Training loss: 1.3811697959899902
Validation loss: 1.9717216591040294

Epoch: 5| Step: 3
Training loss: 2.2243740558624268
Validation loss: 1.9733477185169856

Epoch: 5| Step: 4
Training loss: 1.758336067199707
Validation loss: 1.97601052125295

Epoch: 5| Step: 5
Training loss: 2.4252007007598877
Validation loss: 1.9673879196246464

Epoch: 5| Step: 6
Training loss: 2.3191161155700684
Validation loss: 1.9695576230684917

Epoch: 5| Step: 7
Training loss: 1.9220861196517944
Validation loss: 1.966739222407341

Epoch: 5| Step: 8
Training loss: 1.5788822174072266
Validation loss: 1.987258677681287

Epoch: 5| Step: 9
Training loss: 2.3351237773895264
Validation loss: 1.9865555117527645

Epoch: 5| Step: 10
Training loss: 1.9792855978012085
Validation loss: 1.9862988690535228

Epoch: 5| Step: 11
Training loss: 1.231986403465271
Validation loss: 1.9825538098812103

Epoch: 22| Step: 0
Training loss: 1.6354377269744873
Validation loss: 1.9665568967660267

Epoch: 5| Step: 1
Training loss: 2.3412833213806152
Validation loss: 2.052314187089602

Epoch: 5| Step: 2
Training loss: 2.1699795722961426
Validation loss: 2.038871705532074

Epoch: 5| Step: 3
Training loss: 2.5980277061462402
Validation loss: 2.0578308006127677

Epoch: 5| Step: 4
Training loss: 2.175548553466797
Validation loss: 2.0282456129789352

Epoch: 5| Step: 5
Training loss: 1.6019474267959595
Validation loss: 2.0370360811551413

Epoch: 5| Step: 6
Training loss: 1.9634500741958618
Validation loss: 2.0626550565163293

Epoch: 5| Step: 7
Training loss: 1.3782285451889038
Validation loss: 2.0459194680054984

Epoch: 5| Step: 8
Training loss: 1.923034429550171
Validation loss: 2.030872960885366

Epoch: 5| Step: 9
Training loss: 2.131786584854126
Validation loss: 2.025347034136454

Epoch: 5| Step: 10
Training loss: 1.9488275051116943
Validation loss: 2.010758544007937

Epoch: 5| Step: 11
Training loss: 2.449906349182129
Validation loss: 2.0009760161240897

Epoch: 23| Step: 0
Training loss: 2.2086596488952637
Validation loss: 2.009685938556989

Epoch: 5| Step: 1
Training loss: 2.1529786586761475
Validation loss: 1.9903192569812138

Epoch: 5| Step: 2
Training loss: 1.956195592880249
Validation loss: 1.9988202253977458

Epoch: 5| Step: 3
Training loss: 2.0558857917785645
Validation loss: 2.00353412826856

Epoch: 5| Step: 4
Training loss: 2.344113826751709
Validation loss: 1.9995899548133214

Epoch: 5| Step: 5
Training loss: 1.6148080825805664
Validation loss: 1.9925510883331299

Epoch: 5| Step: 6
Training loss: 1.4970767498016357
Validation loss: 1.997667317589124

Epoch: 5| Step: 7
Training loss: 2.549992799758911
Validation loss: 1.9898338913917542

Epoch: 5| Step: 8
Training loss: 1.7829803228378296
Validation loss: 1.9702803939580917

Epoch: 5| Step: 9
Training loss: 2.105616807937622
Validation loss: 2.0040845572948456

Epoch: 5| Step: 10
Training loss: 1.4603831768035889
Validation loss: 2.012361561258634

Epoch: 5| Step: 11
Training loss: 2.3453011512756348
Validation loss: 2.0052869816621146

Epoch: 24| Step: 0
Training loss: 2.279651165008545
Validation loss: 1.9937378267447154

Epoch: 5| Step: 1
Training loss: 2.3326966762542725
Validation loss: 1.9974720925092697

Epoch: 5| Step: 2
Training loss: 1.9525381326675415
Validation loss: 2.02405613164107

Epoch: 5| Step: 3
Training loss: 1.7864515781402588
Validation loss: 2.0238296588261924

Epoch: 5| Step: 4
Training loss: 1.4180489778518677
Validation loss: 2.0440512597560883

Epoch: 5| Step: 5
Training loss: 2.1771721839904785
Validation loss: 2.0535348107417426

Epoch: 5| Step: 6
Training loss: 1.2103084325790405
Validation loss: 2.0628730207681656

Epoch: 5| Step: 7
Training loss: 2.088999032974243
Validation loss: 2.037580112616221

Epoch: 5| Step: 8
Training loss: 2.472400665283203
Validation loss: 2.026650329430898

Epoch: 5| Step: 9
Training loss: 2.1106839179992676
Validation loss: 1.9941377192735672

Epoch: 5| Step: 10
Training loss: 1.8363559246063232
Validation loss: 2.0021770695845285

Epoch: 5| Step: 11
Training loss: 1.779347538948059
Validation loss: 1.9979862024386723

Epoch: 25| Step: 0
Training loss: 1.823371171951294
Validation loss: 1.9804138988256454

Epoch: 5| Step: 1
Training loss: 1.480238914489746
Validation loss: 1.9732924848794937

Epoch: 5| Step: 2
Training loss: 1.3365199565887451
Validation loss: 1.9738214313983917

Epoch: 5| Step: 3
Training loss: 3.047867774963379
Validation loss: 1.9667768826087315

Epoch: 5| Step: 4
Training loss: 2.0123400688171387
Validation loss: 1.958193764090538

Epoch: 5| Step: 5
Training loss: 1.9397790431976318
Validation loss: 1.9505017151435216

Epoch: 5| Step: 6
Training loss: 1.5979931354522705
Validation loss: 1.967880293726921

Epoch: 5| Step: 7
Training loss: 2.4601011276245117
Validation loss: 1.9842056979735692

Epoch: 5| Step: 8
Training loss: 1.715592384338379
Validation loss: 1.9945665995279949

Epoch: 5| Step: 9
Training loss: 1.981321930885315
Validation loss: 2.009584034482638

Epoch: 5| Step: 10
Training loss: 2.517643690109253
Validation loss: 2.00713882346948

Epoch: 5| Step: 11
Training loss: 1.1294536590576172
Validation loss: 2.0298039813836417

Epoch: 26| Step: 0
Training loss: 2.320514678955078
Validation loss: 2.0051631977160773

Epoch: 5| Step: 1
Training loss: 1.5848325490951538
Validation loss: 2.0220219045877457

Epoch: 5| Step: 2
Training loss: 2.2695529460906982
Validation loss: 2.0008141299088797

Epoch: 5| Step: 3
Training loss: 1.1126900911331177
Validation loss: 2.0302202850580215

Epoch: 5| Step: 4
Training loss: 1.9072198867797852
Validation loss: 2.0289208789666495

Epoch: 5| Step: 5
Training loss: 2.057284116744995
Validation loss: 2.013161520163218

Epoch: 5| Step: 6
Training loss: 2.1543526649475098
Validation loss: 2.0091316252946854

Epoch: 5| Step: 7
Training loss: 2.6080315113067627
Validation loss: 2.0269440710544586

Epoch: 5| Step: 8
Training loss: 1.3686187267303467
Validation loss: 2.031951606273651

Epoch: 5| Step: 9
Training loss: 2.48118257522583
Validation loss: 2.010228509704272

Epoch: 5| Step: 10
Training loss: 1.6239742040634155
Validation loss: 1.9947886317968369

Epoch: 5| Step: 11
Training loss: 2.2724056243896484
Validation loss: 1.9934320698181789

Epoch: 27| Step: 0
Training loss: 2.438220262527466
Validation loss: 2.0029016931851706

Epoch: 5| Step: 1
Training loss: 2.0672714710235596
Validation loss: 1.991015260418256

Epoch: 5| Step: 2
Training loss: 2.205320358276367
Validation loss: 1.9640719592571259

Epoch: 5| Step: 3
Training loss: 1.6360830068588257
Validation loss: 1.9721512993176777

Epoch: 5| Step: 4
Training loss: 1.7743313312530518
Validation loss: 1.9838124761978786

Epoch: 5| Step: 5
Training loss: 1.8174854516983032
Validation loss: 1.958902175227801

Epoch: 5| Step: 6
Training loss: 2.0314669609069824
Validation loss: 1.9679714490969975

Epoch: 5| Step: 7
Training loss: 1.9731934070587158
Validation loss: 1.9788130273421605

Epoch: 5| Step: 8
Training loss: 1.242671251296997
Validation loss: 1.9802488038937252

Epoch: 5| Step: 9
Training loss: 1.9413836002349854
Validation loss: 1.9931239833434422

Epoch: 5| Step: 10
Training loss: 2.2432949542999268
Validation loss: 2.0060668885707855

Epoch: 5| Step: 11
Training loss: 3.795020580291748
Validation loss: 1.9997207323710124

Epoch: 28| Step: 0
Training loss: 1.3371614217758179
Validation loss: 1.9925846705834072

Epoch: 5| Step: 1
Training loss: 1.5585606098175049
Validation loss: 1.9933160344759624

Epoch: 5| Step: 2
Training loss: 1.8644349575042725
Validation loss: 1.9795912553866704

Epoch: 5| Step: 3
Training loss: 2.321887731552124
Validation loss: 1.999043583869934

Epoch: 5| Step: 4
Training loss: 2.1915154457092285
Validation loss: 2.020583227276802

Epoch: 5| Step: 5
Training loss: 1.311631202697754
Validation loss: 2.0194812516371408

Epoch: 5| Step: 6
Training loss: 2.4219202995300293
Validation loss: 2.0567923188209534

Epoch: 5| Step: 7
Training loss: 2.4483625888824463
Validation loss: 2.0116808861494064

Epoch: 5| Step: 8
Training loss: 2.139963150024414
Validation loss: 2.026800418893496

Epoch: 5| Step: 9
Training loss: 1.7917585372924805
Validation loss: 2.005038390556971

Epoch: 5| Step: 10
Training loss: 1.9581174850463867
Validation loss: 1.9930343975623448

Epoch: 5| Step: 11
Training loss: 2.5109195709228516
Validation loss: 1.9793187081813812

Epoch: 29| Step: 0
Training loss: 2.3531761169433594
Validation loss: 1.9787997057040532

Epoch: 5| Step: 1
Training loss: 2.1633381843566895
Validation loss: 1.9817137519518535

Epoch: 5| Step: 2
Training loss: 1.8649784326553345
Validation loss: 2.0047648201386132

Epoch: 5| Step: 3
Training loss: 1.949121117591858
Validation loss: 1.9982392638921738

Epoch: 5| Step: 4
Training loss: 1.7852404117584229
Validation loss: 1.9632774889469147

Epoch: 5| Step: 5
Training loss: 1.9316562414169312
Validation loss: 1.9565664778153102

Epoch: 5| Step: 6
Training loss: 1.7403234243392944
Validation loss: 1.9565899620453517

Epoch: 5| Step: 7
Training loss: 1.9117826223373413
Validation loss: 1.9757064282894135

Epoch: 5| Step: 8
Training loss: 2.214545249938965
Validation loss: 1.9734047949314117

Epoch: 5| Step: 9
Training loss: 2.1074135303497314
Validation loss: 1.9761497626701992

Epoch: 5| Step: 10
Training loss: 1.6997512578964233
Validation loss: 1.9683007846275966

Epoch: 5| Step: 11
Training loss: 1.3447397947311401
Validation loss: 1.9561550865570705

Epoch: 30| Step: 0
Training loss: 1.9527618885040283
Validation loss: 1.982171227534612

Epoch: 5| Step: 1
Training loss: 1.6948999166488647
Validation loss: 2.0050345758597055

Epoch: 5| Step: 2
Training loss: 2.5912466049194336
Validation loss: 2.022915557026863

Epoch: 5| Step: 3
Training loss: 1.679154634475708
Validation loss: 2.0227816998958588

Epoch: 5| Step: 4
Training loss: 2.1315720081329346
Validation loss: 2.0382081220547357

Epoch: 5| Step: 5
Training loss: 2.102503538131714
Validation loss: 2.0580874184767404

Epoch: 5| Step: 6
Training loss: 1.918688416481018
Validation loss: 2.058459907770157

Epoch: 5| Step: 7
Training loss: 1.6128002405166626
Validation loss: 2.0629452963670096

Epoch: 5| Step: 8
Training loss: 2.2087390422821045
Validation loss: 2.0542496194442115

Epoch: 5| Step: 9
Training loss: 1.9499485492706299
Validation loss: 2.027152806520462

Epoch: 5| Step: 10
Training loss: 1.8395540714263916
Validation loss: 2.0139710108439126

Epoch: 5| Step: 11
Training loss: 1.286365032196045
Validation loss: 2.012791226307551

Epoch: 31| Step: 0
Training loss: 1.7769279479980469
Validation loss: 1.9819489816824596

Epoch: 5| Step: 1
Training loss: 1.938018560409546
Validation loss: 1.9873013993104298

Epoch: 5| Step: 2
Training loss: 1.8486967086791992
Validation loss: 1.9629023919502895

Epoch: 5| Step: 3
Training loss: 2.2588629722595215
Validation loss: 1.9652412136395772

Epoch: 5| Step: 4
Training loss: 1.774656057357788
Validation loss: 1.9597905973593395

Epoch: 5| Step: 5
Training loss: 1.711158037185669
Validation loss: 1.9518022586901982

Epoch: 5| Step: 6
Training loss: 1.7058016061782837
Validation loss: 1.9578099101781845

Epoch: 5| Step: 7
Training loss: 2.344877243041992
Validation loss: 1.9644826253255208

Epoch: 5| Step: 8
Training loss: 1.7993911504745483
Validation loss: 1.959965780377388

Epoch: 5| Step: 9
Training loss: 2.604820966720581
Validation loss: 1.9736460745334625

Epoch: 5| Step: 10
Training loss: 1.6842724084854126
Validation loss: 1.9580819954474766

Epoch: 5| Step: 11
Training loss: 1.9753646850585938
Validation loss: 1.9626650114854176

Epoch: 32| Step: 0
Training loss: 1.8699417114257812
Validation loss: 1.9655370165904362

Epoch: 5| Step: 1
Training loss: 2.055171251296997
Validation loss: 1.9759862373272579

Epoch: 5| Step: 2
Training loss: 1.9802446365356445
Validation loss: 1.989815041422844

Epoch: 5| Step: 3
Training loss: 1.5443973541259766
Validation loss: 1.9840947687625885

Epoch: 5| Step: 4
Training loss: 1.986912727355957
Validation loss: 2.0010703802108765

Epoch: 5| Step: 5
Training loss: 1.6432737112045288
Validation loss: 2.0204447309176126

Epoch: 5| Step: 6
Training loss: 1.9947891235351562
Validation loss: 2.023730844259262

Epoch: 5| Step: 7
Training loss: 2.364348888397217
Validation loss: 2.036738693714142

Epoch: 5| Step: 8
Training loss: 1.484731674194336
Validation loss: 2.025473008553187

Epoch: 5| Step: 9
Training loss: 2.4168925285339355
Validation loss: 2.0307724873224893

Epoch: 5| Step: 10
Training loss: 2.0929312705993652
Validation loss: 2.0299443900585175

Epoch: 5| Step: 11
Training loss: 1.185124158859253
Validation loss: 2.012142231067022

Epoch: 33| Step: 0
Training loss: 2.009120464324951
Validation loss: 1.9996533145507176

Epoch: 5| Step: 1
Training loss: 2.6607494354248047
Validation loss: 2.0013561050097146

Epoch: 5| Step: 2
Training loss: 1.540642261505127
Validation loss: 1.9841719021399815

Epoch: 5| Step: 3
Training loss: 2.0463645458221436
Validation loss: 1.9775629887978237

Epoch: 5| Step: 4
Training loss: 1.6592597961425781
Validation loss: 1.9483065406481426

Epoch: 5| Step: 5
Training loss: 2.111346960067749
Validation loss: 1.9629260152578354

Epoch: 5| Step: 6
Training loss: 2.263016700744629
Validation loss: 1.9795641998449962

Epoch: 5| Step: 7
Training loss: 1.5780622959136963
Validation loss: 1.9668805499871571

Epoch: 5| Step: 8
Training loss: 1.945123314857483
Validation loss: 1.9685730934143066

Epoch: 5| Step: 9
Training loss: 2.1241469383239746
Validation loss: 1.9697794169187546

Epoch: 5| Step: 10
Training loss: 2.2159934043884277
Validation loss: 1.9623768031597137

Epoch: 5| Step: 11
Training loss: 0.4149186611175537
Validation loss: 1.9840459376573563

Epoch: 34| Step: 0
Training loss: 1.4970711469650269
Validation loss: 1.991444284717242

Epoch: 5| Step: 1
Training loss: 1.667636513710022
Validation loss: 2.003819634517034

Epoch: 5| Step: 2
Training loss: 2.3534770011901855
Validation loss: 2.018842190504074

Epoch: 5| Step: 3
Training loss: 2.355466842651367
Validation loss: 2.0456803192694983

Epoch: 5| Step: 4
Training loss: 1.8686901330947876
Validation loss: 2.0623602122068405

Epoch: 5| Step: 5
Training loss: 1.8787562847137451
Validation loss: 2.0600648572047553

Epoch: 5| Step: 6
Training loss: 1.6389405727386475
Validation loss: 2.090410143136978

Epoch: 5| Step: 7
Training loss: 1.584485650062561
Validation loss: 2.067702348033587

Epoch: 5| Step: 8
Training loss: 1.9060256481170654
Validation loss: 2.077443460623423

Epoch: 5| Step: 9
Training loss: 2.5793259143829346
Validation loss: 2.061069523294767

Epoch: 5| Step: 10
Training loss: 2.159630298614502
Validation loss: 2.036403258641561

Epoch: 5| Step: 11
Training loss: 1.8885841369628906
Validation loss: 2.0379575987656913

Epoch: 35| Step: 0
Training loss: 1.8279407024383545
Validation loss: 1.9967526892820995

Epoch: 5| Step: 1
Training loss: 2.0689797401428223
Validation loss: 1.9862335125605266

Epoch: 5| Step: 2
Training loss: 1.5893232822418213
Validation loss: 1.9600167373816173

Epoch: 5| Step: 3
Training loss: 1.7482181787490845
Validation loss: 1.9648623963197072

Epoch: 5| Step: 4
Training loss: 1.5537172555923462
Validation loss: 1.9484438548485439

Epoch: 5| Step: 5
Training loss: 1.5752437114715576
Validation loss: 1.9606822778781254

Epoch: 5| Step: 6
Training loss: 1.8952299356460571
Validation loss: 1.977031523982684

Epoch: 5| Step: 7
Training loss: 2.627882242202759
Validation loss: 1.9570798426866531

Epoch: 5| Step: 8
Training loss: 1.7288364171981812
Validation loss: 1.9659185806910198

Epoch: 5| Step: 9
Training loss: 2.2943310737609863
Validation loss: 1.9530407687028248

Epoch: 5| Step: 10
Training loss: 2.468954563140869
Validation loss: 1.9590931981801987

Epoch: 5| Step: 11
Training loss: 2.828014373779297
Validation loss: 1.9678547779719036

Epoch: 36| Step: 0
Training loss: 2.6584863662719727
Validation loss: 1.9479770710070927

Epoch: 5| Step: 1
Training loss: 1.7664563655853271
Validation loss: 1.9663253476222355

Epoch: 5| Step: 2
Training loss: 1.936536192893982
Validation loss: 1.9720482230186462

Epoch: 5| Step: 3
Training loss: 2.038090467453003
Validation loss: 1.9655031462510426

Epoch: 5| Step: 4
Training loss: 1.8071848154067993
Validation loss: 1.982040286064148

Epoch: 5| Step: 5
Training loss: 2.0106089115142822
Validation loss: 1.9828114708264668

Epoch: 5| Step: 6
Training loss: 1.833411455154419
Validation loss: 2.00691224137942

Epoch: 5| Step: 7
Training loss: 1.7066943645477295
Validation loss: 1.9969175706307094

Epoch: 5| Step: 8
Training loss: 2.0496530532836914
Validation loss: 2.0079233646392822

Epoch: 5| Step: 9
Training loss: 1.9323498010635376
Validation loss: 1.9992532928784688

Epoch: 5| Step: 10
Training loss: 1.7024593353271484
Validation loss: 2.004496013124784

Epoch: 5| Step: 11
Training loss: 1.4394925832748413
Validation loss: 2.0097607572873435

Epoch: 37| Step: 0
Training loss: 1.6390507221221924
Validation loss: 2.011225640773773

Epoch: 5| Step: 1
Training loss: 1.4541645050048828
Validation loss: 2.0282321870326996

Epoch: 5| Step: 2
Training loss: 1.8774563074111938
Validation loss: 2.043196067214012

Epoch: 5| Step: 3
Training loss: 1.707754135131836
Validation loss: 2.0270786633094153

Epoch: 5| Step: 4
Training loss: 2.6407227516174316
Validation loss: 2.032567540804545

Epoch: 5| Step: 5
Training loss: 2.164175510406494
Validation loss: 2.0206324458122253

Epoch: 5| Step: 6
Training loss: 1.8169000148773193
Validation loss: 2.0097601811091104

Epoch: 5| Step: 7
Training loss: 2.0602164268493652
Validation loss: 1.997922495007515

Epoch: 5| Step: 8
Training loss: 2.1545310020446777
Validation loss: 1.9914111097653706

Epoch: 5| Step: 9
Training loss: 1.7349309921264648
Validation loss: 1.9942843516667683

Epoch: 5| Step: 10
Training loss: 2.185576915740967
Validation loss: 1.971251666545868

Epoch: 5| Step: 11
Training loss: 2.397815227508545
Validation loss: 1.9717044333616893

Epoch: 38| Step: 0
Training loss: 2.403468370437622
Validation loss: 1.9789898147185643

Epoch: 5| Step: 1
Training loss: 1.8784862756729126
Validation loss: 1.9769905110200245

Epoch: 5| Step: 2
Training loss: 2.5261268615722656
Validation loss: 1.9968322118123372

Epoch: 5| Step: 3
Training loss: 2.0643067359924316
Validation loss: 1.9903295785188675

Epoch: 5| Step: 4
Training loss: 1.6188068389892578
Validation loss: 1.984499951203664

Epoch: 5| Step: 5
Training loss: 1.8874218463897705
Validation loss: 1.9630249738693237

Epoch: 5| Step: 6
Training loss: 2.0391857624053955
Validation loss: 2.005258490641912

Epoch: 5| Step: 7
Training loss: 1.9290878772735596
Validation loss: 1.9976472457249959

Epoch: 5| Step: 8
Training loss: 0.780057430267334
Validation loss: 2.0031703263521194

Epoch: 5| Step: 9
Training loss: 1.8761367797851562
Validation loss: 1.9969687859217327

Epoch: 5| Step: 10
Training loss: 2.397458791732788
Validation loss: 1.9887127429246902

Epoch: 5| Step: 11
Training loss: 1.0813450813293457
Validation loss: 1.9809514383474986

Epoch: 39| Step: 0
Training loss: 1.780128836631775
Validation loss: 1.9796728392442067

Epoch: 5| Step: 1
Training loss: 2.0603318214416504
Validation loss: 1.9699305941661198

Epoch: 5| Step: 2
Training loss: 1.850062608718872
Validation loss: 1.9736564755439758

Epoch: 5| Step: 3
Training loss: 1.5101807117462158
Validation loss: 1.9810875604550044

Epoch: 5| Step: 4
Training loss: 2.0598998069763184
Validation loss: 1.9783061295747757

Epoch: 5| Step: 5
Training loss: 1.9262745380401611
Validation loss: 1.9683683663606644

Epoch: 5| Step: 6
Training loss: 2.0315380096435547
Validation loss: 1.976412057876587

Epoch: 5| Step: 7
Training loss: 2.456037998199463
Validation loss: 2.00722374022007

Epoch: 5| Step: 8
Training loss: 1.6942955255508423
Validation loss: 1.9869826833407085

Epoch: 5| Step: 9
Training loss: 2.2780933380126953
Validation loss: 1.9846995423237483

Epoch: 5| Step: 10
Training loss: 1.7152620553970337
Validation loss: 1.9932887156804402

Epoch: 5| Step: 11
Training loss: 0.8288424015045166
Validation loss: 1.970211719473203

Epoch: 40| Step: 0
Training loss: 1.4944907426834106
Validation loss: 1.991337463259697

Epoch: 5| Step: 1
Training loss: 1.664920449256897
Validation loss: 1.9920693387587864

Epoch: 5| Step: 2
Training loss: 1.945600152015686
Validation loss: 1.994009147087733

Epoch: 5| Step: 3
Training loss: 1.8134714365005493
Validation loss: 1.9993236313263576

Epoch: 5| Step: 4
Training loss: 2.5481555461883545
Validation loss: 1.9951527764399846

Epoch: 5| Step: 5
Training loss: 1.8039562702178955
Validation loss: 2.004287675023079

Epoch: 5| Step: 6
Training loss: 1.4058500528335571
Validation loss: 2.0218286563952765

Epoch: 5| Step: 7
Training loss: 2.1993002891540527
Validation loss: 2.0043816765149436

Epoch: 5| Step: 8
Training loss: 2.281578779220581
Validation loss: 1.9781429419914882

Epoch: 5| Step: 9
Training loss: 1.3273178339004517
Validation loss: 2.0037311166524887

Epoch: 5| Step: 10
Training loss: 2.06079363822937
Validation loss: 1.9762607912222545

Epoch: 5| Step: 11
Training loss: 4.33800745010376
Validation loss: 1.9929016133149464

Epoch: 41| Step: 0
Training loss: 1.6165049076080322
Validation loss: 1.9589306612809498

Epoch: 5| Step: 1
Training loss: 1.7675632238388062
Validation loss: 1.9634439746538799

Epoch: 5| Step: 2
Training loss: 1.8991172313690186
Validation loss: 1.967995782693227

Epoch: 5| Step: 3
Training loss: 2.127105474472046
Validation loss: 1.9784897069136302

Epoch: 5| Step: 4
Training loss: 2.4372615814208984
Validation loss: 1.951442763209343

Epoch: 5| Step: 5
Training loss: 2.316131114959717
Validation loss: 1.982701763510704

Epoch: 5| Step: 6
Training loss: 2.0751304626464844
Validation loss: 1.9799445668856304

Epoch: 5| Step: 7
Training loss: 1.8885128498077393
Validation loss: 1.989012618859609

Epoch: 5| Step: 8
Training loss: 2.1375343799591064
Validation loss: 1.987034171819687

Epoch: 5| Step: 9
Training loss: 1.499258041381836
Validation loss: 1.9735543330510457

Epoch: 5| Step: 10
Training loss: 2.175295352935791
Validation loss: 1.9854031453529994

Epoch: 5| Step: 11
Training loss: 0.9567298293113708
Validation loss: 1.9716384559869766

Epoch: 42| Step: 0
Training loss: 1.9286224842071533
Validation loss: 1.96904323498408

Epoch: 5| Step: 1
Training loss: 1.6594616174697876
Validation loss: 1.9764355719089508

Epoch: 5| Step: 2
Training loss: 2.0639595985412598
Validation loss: 1.954307700196902

Epoch: 5| Step: 3
Training loss: 1.8871042728424072
Validation loss: 1.9705480635166168

Epoch: 5| Step: 4
Training loss: 1.9172861576080322
Validation loss: 1.9487261027097702

Epoch: 5| Step: 5
Training loss: 1.9676196575164795
Validation loss: 1.9626705000797908

Epoch: 5| Step: 6
Training loss: 1.6414525508880615
Validation loss: 1.971914529800415

Epoch: 5| Step: 7
Training loss: 2.3064467906951904
Validation loss: 1.9694108913342159

Epoch: 5| Step: 8
Training loss: 1.5378810167312622
Validation loss: 1.9806185712416966

Epoch: 5| Step: 9
Training loss: 1.8469396829605103
Validation loss: 1.9977353811264038

Epoch: 5| Step: 10
Training loss: 2.2749593257904053
Validation loss: 1.9974745710690816

Epoch: 5| Step: 11
Training loss: 2.106276750564575
Validation loss: 2.022753338019053

Epoch: 43| Step: 0
Training loss: 1.8030296564102173
Validation loss: 2.0435587565104165

Epoch: 5| Step: 1
Training loss: 1.948958396911621
Validation loss: 2.0765120635430017

Epoch: 5| Step: 2
Training loss: 1.9535611867904663
Validation loss: 2.0860559791326523

Epoch: 5| Step: 3
Training loss: 1.939817190170288
Validation loss: 2.093361626068751

Epoch: 5| Step: 4
Training loss: 2.452510118484497
Validation loss: 2.074268182118734

Epoch: 5| Step: 5
Training loss: 2.201789379119873
Validation loss: 2.0595458994309106

Epoch: 5| Step: 6
Training loss: 1.5935986042022705
Validation loss: 2.0424286127090454

Epoch: 5| Step: 7
Training loss: 1.6002782583236694
Validation loss: 2.037669152021408

Epoch: 5| Step: 8
Training loss: 2.0921013355255127
Validation loss: 2.0213029036919274

Epoch: 5| Step: 9
Training loss: 2.0333034992218018
Validation loss: 2.0262566606203714

Epoch: 5| Step: 10
Training loss: 1.8068172931671143
Validation loss: 1.9995698084433873

Epoch: 5| Step: 11
Training loss: 1.7505900859832764
Validation loss: 2.009253660837809

Epoch: 44| Step: 0
Training loss: 1.951528549194336
Validation loss: 1.973002960284551

Epoch: 5| Step: 1
Training loss: 1.92405104637146
Validation loss: 1.9815780520439148

Epoch: 5| Step: 2
Training loss: 1.2998946905136108
Validation loss: 1.9878895829121273

Epoch: 5| Step: 3
Training loss: 2.1089730262756348
Validation loss: 1.9689785987138748

Epoch: 5| Step: 4
Training loss: 1.7506691217422485
Validation loss: 1.957506572206815

Epoch: 5| Step: 5
Training loss: 2.016223430633545
Validation loss: 1.9657155275344849

Epoch: 5| Step: 6
Training loss: 1.93938410282135
Validation loss: 1.9710172315438588

Epoch: 5| Step: 7
Training loss: 2.1799209117889404
Validation loss: 1.9544147302707036

Epoch: 5| Step: 8
Training loss: 1.6066261529922485
Validation loss: 1.9703468680381775

Epoch: 5| Step: 9
Training loss: 1.7051990032196045
Validation loss: 1.989165152112643

Epoch: 5| Step: 10
Training loss: 2.4845380783081055
Validation loss: 1.972759226957957

Epoch: 5| Step: 11
Training loss: 2.4776763916015625
Validation loss: 1.9787438412507374

Epoch: 45| Step: 0
Training loss: 1.8613840341567993
Validation loss: 1.9871414701143901

Epoch: 5| Step: 1
Training loss: 1.6626713275909424
Validation loss: 1.9880778938531876

Epoch: 5| Step: 2
Training loss: 1.4873144626617432
Validation loss: 1.9643140733242035

Epoch: 5| Step: 3
Training loss: 2.486457109451294
Validation loss: 1.9968937635421753

Epoch: 5| Step: 4
Training loss: 2.052523136138916
Validation loss: 2.009827827413877

Epoch: 5| Step: 5
Training loss: 2.2288410663604736
Validation loss: 2.011075183749199

Epoch: 5| Step: 6
Training loss: 1.5456997156143188
Validation loss: 2.0030979265769324

Epoch: 5| Step: 7
Training loss: 2.8963499069213867
Validation loss: 2.0008194148540497

Epoch: 5| Step: 8
Training loss: 1.697551965713501
Validation loss: 2.0120848764975867

Epoch: 5| Step: 9
Training loss: 1.550062894821167
Validation loss: 2.0056144297122955

Epoch: 5| Step: 10
Training loss: 1.7347698211669922
Validation loss: 2.035131106774012

Epoch: 5| Step: 11
Training loss: 0.6951239109039307
Validation loss: 2.0104318857192993

Epoch: 46| Step: 0
Training loss: 1.5391404628753662
Validation loss: 2.00211600959301

Epoch: 5| Step: 1
Training loss: 1.7133209705352783
Validation loss: 2.0115721076726913

Epoch: 5| Step: 2
Training loss: 1.5293890237808228
Validation loss: 2.0095739414294562

Epoch: 5| Step: 3
Training loss: 2.003239154815674
Validation loss: 2.012218485275904

Epoch: 5| Step: 4
Training loss: 2.3938820362091064
Validation loss: 1.9958262344201405

Epoch: 5| Step: 5
Training loss: 1.4817427396774292
Validation loss: 1.9866095334291458

Epoch: 5| Step: 6
Training loss: 2.23366641998291
Validation loss: 1.9901705632607143

Epoch: 5| Step: 7
Training loss: 1.4776321649551392
Validation loss: 1.9718541105588276

Epoch: 5| Step: 8
Training loss: 2.1203622817993164
Validation loss: 1.9838497340679169

Epoch: 5| Step: 9
Training loss: 2.286012649536133
Validation loss: 1.9693437268336613

Epoch: 5| Step: 10
Training loss: 1.6171700954437256
Validation loss: 1.9483421991268794

Epoch: 5| Step: 11
Training loss: 3.9475021362304688
Validation loss: 1.97292855878671

Epoch: 47| Step: 0
Training loss: 2.0680508613586426
Validation loss: 1.9480286240577698

Epoch: 5| Step: 1
Training loss: 1.9888023138046265
Validation loss: 1.961003601551056

Epoch: 5| Step: 2
Training loss: 1.1255099773406982
Validation loss: 1.9570933282375336

Epoch: 5| Step: 3
Training loss: 2.0097227096557617
Validation loss: 1.9608647873004277

Epoch: 5| Step: 4
Training loss: 2.217377185821533
Validation loss: 1.9576115757226944

Epoch: 5| Step: 5
Training loss: 1.636627197265625
Validation loss: 1.9681442975997925

Epoch: 5| Step: 6
Training loss: 2.4274115562438965
Validation loss: 1.9616680145263672

Epoch: 5| Step: 7
Training loss: 1.4793627262115479
Validation loss: 1.9623661786317825

Epoch: 5| Step: 8
Training loss: 2.0964603424072266
Validation loss: 1.9745783855517705

Epoch: 5| Step: 9
Training loss: 2.15531587600708
Validation loss: 1.9721291959285736

Epoch: 5| Step: 10
Training loss: 1.2421090602874756
Validation loss: 1.9662187695503235

Epoch: 5| Step: 11
Training loss: 3.229491710662842
Validation loss: 1.9798088669776917

Epoch: 48| Step: 0
Training loss: 2.0919909477233887
Validation loss: 1.9901230086882908

Epoch: 5| Step: 1
Training loss: 1.6586097478866577
Validation loss: 2.0084371070067086

Epoch: 5| Step: 2
Training loss: 1.8580490350723267
Validation loss: 1.9833975086609523

Epoch: 5| Step: 3
Training loss: 2.5397396087646484
Validation loss: 1.993487333257993

Epoch: 5| Step: 4
Training loss: 1.8924944400787354
Validation loss: 2.006834660967191

Epoch: 5| Step: 5
Training loss: 1.579209566116333
Validation loss: 1.9863012333710988

Epoch: 5| Step: 6
Training loss: 1.6572307348251343
Validation loss: 2.0008196930090585

Epoch: 5| Step: 7
Training loss: 1.4665510654449463
Validation loss: 2.0038235088189444

Epoch: 5| Step: 8
Training loss: 2.450084924697876
Validation loss: 2.0076801776885986

Epoch: 5| Step: 9
Training loss: 2.03025484085083
Validation loss: 2.0112630228201547

Epoch: 5| Step: 10
Training loss: 1.3575429916381836
Validation loss: 1.9961466491222382

Epoch: 5| Step: 11
Training loss: 2.540513753890991
Validation loss: 1.9836718241373699

Epoch: 49| Step: 0
Training loss: 1.9284988641738892
Validation loss: 1.9783729016780853

Epoch: 5| Step: 1
Training loss: 1.869201421737671
Validation loss: 1.9653448015451431

Epoch: 5| Step: 2
Training loss: 2.413424015045166
Validation loss: 1.9657118568817775

Epoch: 5| Step: 3
Training loss: 1.3828140497207642
Validation loss: 1.9366504053274791

Epoch: 5| Step: 4
Training loss: 1.7268826961517334
Validation loss: 1.9496601422627766

Epoch: 5| Step: 5
Training loss: 1.818856954574585
Validation loss: 1.9580072909593582

Epoch: 5| Step: 6
Training loss: 2.056360960006714
Validation loss: 1.9653422087430954

Epoch: 5| Step: 7
Training loss: 1.713367223739624
Validation loss: 1.9447367389996846

Epoch: 5| Step: 8
Training loss: 2.469478130340576
Validation loss: 1.9540692965189617

Epoch: 5| Step: 9
Training loss: 1.7664695978164673
Validation loss: 1.9619143456220627

Epoch: 5| Step: 10
Training loss: 1.7664819955825806
Validation loss: 1.9492136240005493

Epoch: 5| Step: 11
Training loss: 2.368617534637451
Validation loss: 1.9627194901307423

Epoch: 50| Step: 0
Training loss: 2.0396981239318848
Validation loss: 1.9586735318104427

Epoch: 5| Step: 1
Training loss: 2.080692768096924
Validation loss: 1.9735758751630783

Epoch: 5| Step: 2
Training loss: 2.1621549129486084
Validation loss: 1.9623730132977169

Epoch: 5| Step: 3
Training loss: 1.9287735223770142
Validation loss: 1.9807583888371785

Epoch: 5| Step: 4
Training loss: 1.299926519393921
Validation loss: 1.9937499314546585

Epoch: 5| Step: 5
Training loss: 2.3143177032470703
Validation loss: 1.9979418218135834

Epoch: 5| Step: 6
Training loss: 1.5879884958267212
Validation loss: 2.033962527910868

Epoch: 5| Step: 7
Training loss: 2.094290256500244
Validation loss: 2.0099907716115317

Epoch: 5| Step: 8
Training loss: 1.3931610584259033
Validation loss: 2.003408511479696

Epoch: 5| Step: 9
Training loss: 2.2564399242401123
Validation loss: 2.0416234880685806

Epoch: 5| Step: 10
Training loss: 1.7636773586273193
Validation loss: 2.0265709906816483

Epoch: 5| Step: 11
Training loss: 1.1934118270874023
Validation loss: 2.0185771534840264

Epoch: 51| Step: 0
Training loss: 1.8890260457992554
Validation loss: 2.0023818910121918

Epoch: 5| Step: 1
Training loss: 2.2660739421844482
Validation loss: 2.018489291270574

Epoch: 5| Step: 2
Training loss: 1.7056148052215576
Validation loss: 1.9771570314963658

Epoch: 5| Step: 3
Training loss: 1.7578659057617188
Validation loss: 1.980934038758278

Epoch: 5| Step: 4
Training loss: 2.1001033782958984
Validation loss: 1.9726694375276566

Epoch: 5| Step: 5
Training loss: 2.333583354949951
Validation loss: 1.9667845914761226

Epoch: 5| Step: 6
Training loss: 1.4971500635147095
Validation loss: 1.9596673945585887

Epoch: 5| Step: 7
Training loss: 2.2536983489990234
Validation loss: 1.9582027991612752

Epoch: 5| Step: 8
Training loss: 1.8894418478012085
Validation loss: 1.9476251254479091

Epoch: 5| Step: 9
Training loss: 1.766692876815796
Validation loss: 1.9661947637796402

Epoch: 5| Step: 10
Training loss: 1.6785370111465454
Validation loss: 1.9388603816429775

Epoch: 5| Step: 11
Training loss: 1.5989456176757812
Validation loss: 1.9454703678687413

Epoch: 52| Step: 0
Training loss: 1.6918773651123047
Validation loss: 1.9832457949717839

Epoch: 5| Step: 1
Training loss: 1.9550167322158813
Validation loss: 1.9702686220407486

Epoch: 5| Step: 2
Training loss: 1.6189285516738892
Validation loss: 1.9917132258415222

Epoch: 5| Step: 3
Training loss: 1.6480392217636108
Validation loss: 1.9878485053777695

Epoch: 5| Step: 4
Training loss: 1.769370675086975
Validation loss: 1.9926992803812027

Epoch: 5| Step: 5
Training loss: 2.1897568702697754
Validation loss: 1.9889397670825322

Epoch: 5| Step: 6
Training loss: 1.9056793451309204
Validation loss: 1.9937178939580917

Epoch: 5| Step: 7
Training loss: 2.1949543952941895
Validation loss: 2.0031613806883493

Epoch: 5| Step: 8
Training loss: 1.9457908868789673
Validation loss: 2.007720425724983

Epoch: 5| Step: 9
Training loss: 2.170804977416992
Validation loss: 1.9962552785873413

Epoch: 5| Step: 10
Training loss: 1.5149503946304321
Validation loss: 2.007870336373647

Epoch: 5| Step: 11
Training loss: 0.9279670119285583
Validation loss: 2.002682109673818

Epoch: 53| Step: 0
Training loss: 2.1790785789489746
Validation loss: 1.9966622839371364

Epoch: 5| Step: 1
Training loss: 1.8870584964752197
Validation loss: 1.9747924854358037

Epoch: 5| Step: 2
Training loss: 1.5179773569107056
Validation loss: 1.9578948020935059

Epoch: 5| Step: 3
Training loss: 1.7153394222259521
Validation loss: 1.9412536372741063

Epoch: 5| Step: 4
Training loss: 1.996382474899292
Validation loss: 1.963422988851865

Epoch: 5| Step: 5
Training loss: 2.0857009887695312
Validation loss: 1.9405748198429744

Epoch: 5| Step: 6
Training loss: 2.1321349143981934
Validation loss: 1.9464056591192882

Epoch: 5| Step: 7
Training loss: 1.881752610206604
Validation loss: 1.9613441427548726

Epoch: 5| Step: 8
Training loss: 1.4850513935089111
Validation loss: 1.9570992588996887

Epoch: 5| Step: 9
Training loss: 2.0215675830841064
Validation loss: 1.9538397441307704

Epoch: 5| Step: 10
Training loss: 1.9726123809814453
Validation loss: 1.9434846689303715

Epoch: 5| Step: 11
Training loss: 1.4672305583953857
Validation loss: 1.9761153906583786

Epoch: 54| Step: 0
Training loss: 2.189246416091919
Validation loss: 1.9712563753128052

Epoch: 5| Step: 1
Training loss: 2.502837657928467
Validation loss: 1.998971884449323

Epoch: 5| Step: 2
Training loss: 1.527034878730774
Validation loss: 2.0168708016475043

Epoch: 5| Step: 3
Training loss: 1.7326929569244385
Validation loss: 2.0506987621386847

Epoch: 5| Step: 4
Training loss: 1.8132041692733765
Validation loss: 2.0957909375429153

Epoch: 5| Step: 5
Training loss: 2.2452025413513184
Validation loss: 2.1175664762655892

Epoch: 5| Step: 6
Training loss: 2.137237548828125
Validation loss: 2.1183533519506454

Epoch: 5| Step: 7
Training loss: 2.150202512741089
Validation loss: 2.111936847368876

Epoch: 5| Step: 8
Training loss: 2.23695707321167
Validation loss: 2.1062105298042297

Epoch: 5| Step: 9
Training loss: 2.103620767593384
Validation loss: 2.068682610988617

Epoch: 5| Step: 10
Training loss: 1.223924160003662
Validation loss: 2.026010731856028

Epoch: 5| Step: 11
Training loss: 1.3004965782165527
Validation loss: 2.002174953619639

Epoch: 55| Step: 0
Training loss: 1.5331252813339233
Validation loss: 1.9862588594357173

Epoch: 5| Step: 1
Training loss: 2.2589383125305176
Validation loss: 1.9852865487337112

Epoch: 5| Step: 2
Training loss: 1.5369983911514282
Validation loss: 1.9585496336221695

Epoch: 5| Step: 3
Training loss: 2.6024680137634277
Validation loss: 1.9633779774109523

Epoch: 5| Step: 4
Training loss: 1.6248371601104736
Validation loss: 1.961156850059827

Epoch: 5| Step: 5
Training loss: 1.2370191812515259
Validation loss: 1.9671915173530579

Epoch: 5| Step: 6
Training loss: 2.1562728881835938
Validation loss: 1.9609335611263912

Epoch: 5| Step: 7
Training loss: 1.5085970163345337
Validation loss: 1.9656923413276672

Epoch: 5| Step: 8
Training loss: 1.9449008703231812
Validation loss: 1.967454547683398

Epoch: 5| Step: 9
Training loss: 2.000864028930664
Validation loss: 1.952404757340749

Epoch: 5| Step: 10
Training loss: 2.0462090969085693
Validation loss: 1.9532775084177654

Epoch: 5| Step: 11
Training loss: 2.027066230773926
Validation loss: 1.965742106239001

Epoch: 56| Step: 0
Training loss: 2.027735710144043
Validation loss: 1.9847541898488998

Epoch: 5| Step: 1
Training loss: 1.9804553985595703
Validation loss: 1.999910404284795

Epoch: 5| Step: 2
Training loss: 2.423490047454834
Validation loss: 1.9973567028840382

Epoch: 5| Step: 3
Training loss: 1.4011032581329346
Validation loss: 1.9986196557680767

Epoch: 5| Step: 4
Training loss: 2.2023730278015137
Validation loss: 2.0016410499811172

Epoch: 5| Step: 5
Training loss: 1.6797370910644531
Validation loss: 1.9847698012987773

Epoch: 5| Step: 6
Training loss: 1.8352978229522705
Validation loss: 1.9906988392273586

Epoch: 5| Step: 7
Training loss: 1.767686128616333
Validation loss: 1.9922919621070225

Epoch: 5| Step: 8
Training loss: 1.517804503440857
Validation loss: 2.0001064588626227

Epoch: 5| Step: 9
Training loss: 1.8011773824691772
Validation loss: 1.972847397128741

Epoch: 5| Step: 10
Training loss: 1.599324345588684
Validation loss: 1.9660965700944264

Epoch: 5| Step: 11
Training loss: 2.398216724395752
Validation loss: 1.9944051851828892

Epoch: 57| Step: 0
Training loss: 1.62746262550354
Validation loss: 1.9892347703377407

Epoch: 5| Step: 1
Training loss: 2.005207061767578
Validation loss: 2.0088567634423575

Epoch: 5| Step: 2
Training loss: 1.5857360363006592
Validation loss: 1.9917481889327366

Epoch: 5| Step: 3
Training loss: 1.8890796899795532
Validation loss: 1.9985116372505825

Epoch: 5| Step: 4
Training loss: 1.7989623546600342
Validation loss: 2.0069325814644494

Epoch: 5| Step: 5
Training loss: 1.8920507431030273
Validation loss: 1.9989670316378276

Epoch: 5| Step: 6
Training loss: 2.047520399093628
Validation loss: 2.006605957945188

Epoch: 5| Step: 7
Training loss: 1.5465843677520752
Validation loss: 1.9965908428033192

Epoch: 5| Step: 8
Training loss: 1.5960534811019897
Validation loss: 1.9731930494308472

Epoch: 5| Step: 9
Training loss: 2.011960983276367
Validation loss: 1.9844719022512436

Epoch: 5| Step: 10
Training loss: 2.7134249210357666
Validation loss: 2.0189805130163827

Epoch: 5| Step: 11
Training loss: 0.3719930648803711
Validation loss: 1.9915099839369457

Epoch: 58| Step: 0
Training loss: 1.5692012310028076
Validation loss: 1.98553333679835

Epoch: 5| Step: 1
Training loss: 1.485856533050537
Validation loss: 1.9686107883850734

Epoch: 5| Step: 2
Training loss: 1.8396952152252197
Validation loss: 1.9465640038251877

Epoch: 5| Step: 3
Training loss: 1.6659481525421143
Validation loss: 1.961104730765025

Epoch: 5| Step: 4
Training loss: 1.8585474491119385
Validation loss: 1.9378419766823451

Epoch: 5| Step: 5
Training loss: 1.8282760381698608
Validation loss: 1.951681484778722

Epoch: 5| Step: 6
Training loss: 2.3256211280822754
Validation loss: 1.9486508468786876

Epoch: 5| Step: 7
Training loss: 1.9691731929779053
Validation loss: 1.982035239537557

Epoch: 5| Step: 8
Training loss: 2.598846435546875
Validation loss: 1.9617098569869995

Epoch: 5| Step: 9
Training loss: 1.7750186920166016
Validation loss: 1.9672653178373973

Epoch: 5| Step: 10
Training loss: 1.7330747842788696
Validation loss: 1.95218130449454

Epoch: 5| Step: 11
Training loss: 2.3662378787994385
Validation loss: 1.941206028064092

Epoch: 59| Step: 0
Training loss: 1.9839038848876953
Validation loss: 1.9637308071057002

Epoch: 5| Step: 1
Training loss: 2.3647987842559814
Validation loss: 1.949593409895897

Epoch: 5| Step: 2
Training loss: 2.1760833263397217
Validation loss: 1.9682382494211197

Epoch: 5| Step: 3
Training loss: 2.2168798446655273
Validation loss: 1.9727387030919392

Epoch: 5| Step: 4
Training loss: 2.0613081455230713
Validation loss: 1.9879156748453777

Epoch: 5| Step: 5
Training loss: 1.346531629562378
Validation loss: 1.9900405953327815

Epoch: 5| Step: 6
Training loss: 1.7643346786499023
Validation loss: 1.998426948984464

Epoch: 5| Step: 7
Training loss: 1.5184319019317627
Validation loss: 2.03818641602993

Epoch: 5| Step: 8
Training loss: 1.3047618865966797
Validation loss: 2.0354228963454566

Epoch: 5| Step: 9
Training loss: 1.8204286098480225
Validation loss: 2.0383068968852363

Epoch: 5| Step: 10
Training loss: 1.6865253448486328
Validation loss: 2.0576846450567245

Epoch: 5| Step: 11
Training loss: 2.139131546020508
Validation loss: 2.0427893698215485

Epoch: 60| Step: 0
Training loss: 1.3746166229248047
Validation loss: 2.021565854549408

Epoch: 5| Step: 1
Training loss: 1.6514631509780884
Validation loss: 1.9994669953982036

Epoch: 5| Step: 2
Training loss: 1.8629865646362305
Validation loss: 2.0167396714289985

Epoch: 5| Step: 3
Training loss: 1.9070398807525635
Validation loss: 1.9716375420490901

Epoch: 5| Step: 4
Training loss: 1.5112251043319702
Validation loss: 1.9635796149571736

Epoch: 5| Step: 5
Training loss: 1.9131311178207397
Validation loss: 1.9821611195802689

Epoch: 5| Step: 6
Training loss: 2.215785026550293
Validation loss: 1.964745024840037

Epoch: 5| Step: 7
Training loss: 2.01816987991333
Validation loss: 1.9601504107316334

Epoch: 5| Step: 8
Training loss: 1.9997953176498413
Validation loss: 1.949339712659518

Epoch: 5| Step: 9
Training loss: 2.0580976009368896
Validation loss: 1.948535015185674

Epoch: 5| Step: 10
Training loss: 1.8493382930755615
Validation loss: 1.956093321243922

Epoch: 5| Step: 11
Training loss: 0.7462580800056458
Validation loss: 1.9541137913862865

Epoch: 61| Step: 0
Training loss: 1.6541633605957031
Validation loss: 1.963434249162674

Epoch: 5| Step: 1
Training loss: 1.614417314529419
Validation loss: 1.9593184540669124

Epoch: 5| Step: 2
Training loss: 2.0234482288360596
Validation loss: 1.9751533915599186

Epoch: 5| Step: 3
Training loss: 1.6822181940078735
Validation loss: 2.0005175868670144

Epoch: 5| Step: 4
Training loss: 1.7619736194610596
Validation loss: 2.0294909179210663

Epoch: 5| Step: 5
Training loss: 1.7292044162750244
Validation loss: 2.0510895450909934

Epoch: 5| Step: 6
Training loss: 2.509033679962158
Validation loss: 2.059640650947889

Epoch: 5| Step: 7
Training loss: 1.6232017278671265
Validation loss: 2.0146401822566986

Epoch: 5| Step: 8
Training loss: 1.767040491104126
Validation loss: 2.0409550269444785

Epoch: 5| Step: 9
Training loss: 2.154754638671875
Validation loss: 2.02897509932518

Epoch: 5| Step: 10
Training loss: 1.9950025081634521
Validation loss: 2.011682798465093

Epoch: 5| Step: 11
Training loss: 2.0833020210266113
Validation loss: 1.9837458829085033

Epoch: 62| Step: 0
Training loss: 1.7786248922348022
Validation loss: 1.9716250151395798

Epoch: 5| Step: 1
Training loss: 1.8017780780792236
Validation loss: 1.9435404787460964

Epoch: 5| Step: 2
Training loss: 1.986222267150879
Validation loss: 1.9234143892923992

Epoch: 5| Step: 3
Training loss: 1.7290232181549072
Validation loss: 1.9583287239074707

Epoch: 5| Step: 4
Training loss: 1.3758412599563599
Validation loss: 1.9529200593630474

Epoch: 5| Step: 5
Training loss: 1.6050269603729248
Validation loss: 1.9309047957261403

Epoch: 5| Step: 6
Training loss: 1.9864670038223267
Validation loss: 1.9548062284787495

Epoch: 5| Step: 7
Training loss: 1.4031096696853638
Validation loss: 1.9397585441668828

Epoch: 5| Step: 8
Training loss: 2.5007855892181396
Validation loss: 1.9781676977872849

Epoch: 5| Step: 9
Training loss: 2.0353591442108154
Validation loss: 1.9619955867528915

Epoch: 5| Step: 10
Training loss: 2.088153123855591
Validation loss: 1.9635951568682988

Epoch: 5| Step: 11
Training loss: 2.4433040618896484
Validation loss: 1.978961984316508

Epoch: 63| Step: 0
Training loss: 2.2870607376098633
Validation loss: 1.9747238357861836

Epoch: 5| Step: 1
Training loss: 1.8723208904266357
Validation loss: 1.9820077617963154

Epoch: 5| Step: 2
Training loss: 1.2645231485366821
Validation loss: 1.976542259256045

Epoch: 5| Step: 3
Training loss: 1.2532618045806885
Validation loss: 1.9749132146437962

Epoch: 5| Step: 4
Training loss: 2.4310944080352783
Validation loss: 1.9900704274574916

Epoch: 5| Step: 5
Training loss: 1.7552322149276733
Validation loss: 1.9818592617909114

Epoch: 5| Step: 6
Training loss: 1.661981225013733
Validation loss: 1.96424300968647

Epoch: 5| Step: 7
Training loss: 2.4618301391601562
Validation loss: 1.9760451763868332

Epoch: 5| Step: 8
Training loss: 1.9106948375701904
Validation loss: 1.9774575928846996

Epoch: 5| Step: 9
Training loss: 1.293407678604126
Validation loss: 1.976392428080241

Epoch: 5| Step: 10
Training loss: 1.6820852756500244
Validation loss: 1.9842140525579453

Epoch: 5| Step: 11
Training loss: 2.1416404247283936
Validation loss: 1.9908392628033955

Epoch: 64| Step: 0
Training loss: 1.5537503957748413
Validation loss: 1.977212016781171

Epoch: 5| Step: 1
Training loss: 1.714547872543335
Validation loss: 1.9858367542425792

Epoch: 5| Step: 2
Training loss: 2.0351805686950684
Validation loss: 1.961251253883044

Epoch: 5| Step: 3
Training loss: 1.8825963735580444
Validation loss: 1.9768938074509304

Epoch: 5| Step: 4
Training loss: 2.0386645793914795
Validation loss: 1.9754422803719838

Epoch: 5| Step: 5
Training loss: 2.129511594772339
Validation loss: 1.9560568730036418

Epoch: 5| Step: 6
Training loss: 1.9496965408325195
Validation loss: 2.000165730714798

Epoch: 5| Step: 7
Training loss: 1.649224042892456
Validation loss: 1.9786444654067357

Epoch: 5| Step: 8
Training loss: 1.209869146347046
Validation loss: 1.9596934566895168

Epoch: 5| Step: 9
Training loss: 2.044973611831665
Validation loss: 1.9528868993123372

Epoch: 5| Step: 10
Training loss: 1.5347074270248413
Validation loss: 1.9684212605158489

Epoch: 5| Step: 11
Training loss: 2.1722967624664307
Validation loss: 1.9689063529173534

Epoch: 65| Step: 0
Training loss: 1.8644717931747437
Validation loss: 1.9629569699366887

Epoch: 5| Step: 1
Training loss: 1.8870166540145874
Validation loss: 1.9511846552292507

Epoch: 5| Step: 2
Training loss: 1.6036098003387451
Validation loss: 1.9488276640574138

Epoch: 5| Step: 3
Training loss: 2.317200183868408
Validation loss: 1.9672266244888306

Epoch: 5| Step: 4
Training loss: 1.9096488952636719
Validation loss: 1.9266448467969894

Epoch: 5| Step: 5
Training loss: 2.0604069232940674
Validation loss: 1.9394026001294453

Epoch: 5| Step: 6
Training loss: 2.5154762268066406
Validation loss: 1.956740881005923

Epoch: 5| Step: 7
Training loss: 1.703338861465454
Validation loss: 1.9354813198248546

Epoch: 5| Step: 8
Training loss: 1.0597741603851318
Validation loss: 1.9530238409837086

Epoch: 5| Step: 9
Training loss: 1.5356698036193848
Validation loss: 1.9452323267857234

Epoch: 5| Step: 10
Training loss: 1.9464699029922485
Validation loss: 1.958241621653239

Epoch: 5| Step: 11
Training loss: 1.746579647064209
Validation loss: 1.9708952754735947

Epoch: 66| Step: 0
Training loss: 1.7265723943710327
Validation loss: 1.9981765200694401

Epoch: 5| Step: 1
Training loss: 1.452869176864624
Validation loss: 2.019631341099739

Epoch: 5| Step: 2
Training loss: 1.9863941669464111
Validation loss: 2.0484643826882043

Epoch: 5| Step: 3
Training loss: 2.078993082046509
Validation loss: 2.0710098246733346

Epoch: 5| Step: 4
Training loss: 1.6822526454925537
Validation loss: 2.0720771153767905

Epoch: 5| Step: 5
Training loss: 2.1841208934783936
Validation loss: 2.0590905398130417

Epoch: 5| Step: 6
Training loss: 1.8931541442871094
Validation loss: 2.0764985382556915

Epoch: 5| Step: 7
Training loss: 1.460818886756897
Validation loss: 2.0198770264784494

Epoch: 5| Step: 8
Training loss: 2.4756269454956055
Validation loss: 1.9815979699293773

Epoch: 5| Step: 9
Training loss: 1.4438815116882324
Validation loss: 1.9595524470011394

Epoch: 5| Step: 10
Training loss: 1.953948736190796
Validation loss: 1.9574297418196995

Epoch: 5| Step: 11
Training loss: 1.4440269470214844
Validation loss: 1.95895920197169

Epoch: 67| Step: 0
Training loss: 1.279395341873169
Validation loss: 1.9348690410455067

Epoch: 5| Step: 1
Training loss: 2.043215036392212
Validation loss: 1.9135877639055252

Epoch: 5| Step: 2
Training loss: 2.2066783905029297
Validation loss: 1.962484007080396

Epoch: 5| Step: 3
Training loss: 1.951576828956604
Validation loss: 1.9521838277578354

Epoch: 5| Step: 4
Training loss: 1.8004831075668335
Validation loss: 1.962415079275767

Epoch: 5| Step: 5
Training loss: 1.8116512298583984
Validation loss: 1.9673678775628407

Epoch: 5| Step: 6
Training loss: 2.092773914337158
Validation loss: 1.9376719345649083

Epoch: 5| Step: 7
Training loss: 1.543156385421753
Validation loss: 1.9549621840318043

Epoch: 5| Step: 8
Training loss: 2.114342212677002
Validation loss: 1.9452788134415944

Epoch: 5| Step: 9
Training loss: 1.8497816324234009
Validation loss: 1.947104240457217

Epoch: 5| Step: 10
Training loss: 1.679596185684204
Validation loss: 1.927162026365598

Epoch: 5| Step: 11
Training loss: 2.8032119274139404
Validation loss: 1.9487264305353165

Epoch: 68| Step: 0
Training loss: 1.6384859085083008
Validation loss: 1.950450137257576

Epoch: 5| Step: 1
Training loss: 2.038167953491211
Validation loss: 1.9959596544504166

Epoch: 5| Step: 2
Training loss: 1.865362524986267
Validation loss: 1.9858680218458176

Epoch: 5| Step: 3
Training loss: 1.5277432203292847
Validation loss: 2.0006340742111206

Epoch: 5| Step: 4
Training loss: 1.9334690570831299
Validation loss: 1.9904439946015675

Epoch: 5| Step: 5
Training loss: 1.6423721313476562
Validation loss: 2.0322749515374503

Epoch: 5| Step: 6
Training loss: 1.8782768249511719
Validation loss: 2.0231871207555137

Epoch: 5| Step: 7
Training loss: 1.904934287071228
Validation loss: 2.0047204792499542

Epoch: 5| Step: 8
Training loss: 2.1931838989257812
Validation loss: 2.030837203065554

Epoch: 5| Step: 9
Training loss: 1.6373522281646729
Validation loss: 2.021195665001869

Epoch: 5| Step: 10
Training loss: 1.9650958776474
Validation loss: 2.001040279865265

Epoch: 5| Step: 11
Training loss: 0.891834557056427
Validation loss: 2.0057713290055594

Epoch: 69| Step: 0
Training loss: 1.780832052230835
Validation loss: 2.0091609756151834

Epoch: 5| Step: 1
Training loss: 1.808312177658081
Validation loss: 2.0047216961781182

Epoch: 5| Step: 2
Training loss: 1.907098412513733
Validation loss: 1.9820811649163563

Epoch: 5| Step: 3
Training loss: 1.5813305377960205
Validation loss: 1.9870784680048625

Epoch: 5| Step: 4
Training loss: 1.5574166774749756
Validation loss: 1.980784460902214

Epoch: 5| Step: 5
Training loss: 2.0058226585388184
Validation loss: 1.9714545905590057

Epoch: 5| Step: 6
Training loss: 1.9813579320907593
Validation loss: 1.952931135892868

Epoch: 5| Step: 7
Training loss: 1.6779909133911133
Validation loss: 1.9786471625169118

Epoch: 5| Step: 8
Training loss: 1.6451327800750732
Validation loss: 1.9603691746791203

Epoch: 5| Step: 9
Training loss: 2.1770012378692627
Validation loss: 1.9513517220815022

Epoch: 5| Step: 10
Training loss: 1.99789297580719
Validation loss: 1.9432445267836254

Epoch: 5| Step: 11
Training loss: 0.9582139253616333
Validation loss: 1.953185920914014

Epoch: 70| Step: 0
Training loss: 2.136993646621704
Validation loss: 1.9516578316688538

Epoch: 5| Step: 1
Training loss: 1.9056484699249268
Validation loss: 1.9447644799947739

Epoch: 5| Step: 2
Training loss: 1.7118899822235107
Validation loss: 1.9685248533884685

Epoch: 5| Step: 3
Training loss: 1.9263960123062134
Validation loss: 1.9776822825272877

Epoch: 5| Step: 4
Training loss: 1.4317952394485474
Validation loss: 1.9892258197069168

Epoch: 5| Step: 5
Training loss: 2.0866897106170654
Validation loss: 2.012273078163465

Epoch: 5| Step: 6
Training loss: 2.6000161170959473
Validation loss: 2.0233652144670486

Epoch: 5| Step: 7
Training loss: 1.682012915611267
Validation loss: 2.0096449156602225

Epoch: 5| Step: 8
Training loss: 2.0001444816589355
Validation loss: 2.0194739997386932

Epoch: 5| Step: 9
Training loss: 1.2462235689163208
Validation loss: 1.972950592637062

Epoch: 5| Step: 10
Training loss: 1.4640696048736572
Validation loss: 1.9914873838424683

Epoch: 5| Step: 11
Training loss: 0.37999391555786133
Validation loss: 1.9683790306250255

Epoch: 71| Step: 0
Training loss: 1.7421455383300781
Validation loss: 1.9639868785937626

Epoch: 5| Step: 1
Training loss: 2.013301372528076
Validation loss: 1.956042895714442

Epoch: 5| Step: 2
Training loss: 1.8121812343597412
Validation loss: 1.9521740972995758

Epoch: 5| Step: 3
Training loss: 1.914318323135376
Validation loss: 1.9458295305569966

Epoch: 5| Step: 4
Training loss: 1.4760000705718994
Validation loss: 1.9531118720769882

Epoch: 5| Step: 5
Training loss: 1.1286723613739014
Validation loss: 1.9529038021961849

Epoch: 5| Step: 6
Training loss: 1.3847434520721436
Validation loss: 1.9730591227610905

Epoch: 5| Step: 7
Training loss: 1.7910274267196655
Validation loss: 1.9405556668837864

Epoch: 5| Step: 8
Training loss: 2.010230302810669
Validation loss: 1.9537492543458939

Epoch: 5| Step: 9
Training loss: 2.2702860832214355
Validation loss: 1.950326109925906

Epoch: 5| Step: 10
Training loss: 2.129243850708008
Validation loss: 1.9673161953687668

Epoch: 5| Step: 11
Training loss: 2.5569019317626953
Validation loss: 1.979940339922905

Epoch: 72| Step: 0
Training loss: 1.988250970840454
Validation loss: 1.9796092708905537

Epoch: 5| Step: 1
Training loss: 1.5211267471313477
Validation loss: 2.001164530714353

Epoch: 5| Step: 2
Training loss: 1.6455520391464233
Validation loss: 1.980196590224902

Epoch: 5| Step: 3
Training loss: 1.0759795904159546
Validation loss: 1.9741427103678386

Epoch: 5| Step: 4
Training loss: 1.3587512969970703
Validation loss: 1.9641897231340408

Epoch: 5| Step: 5
Training loss: 1.8320443630218506
Validation loss: 1.9959681977828343

Epoch: 5| Step: 6
Training loss: 2.169328212738037
Validation loss: 1.955796907345454

Epoch: 5| Step: 7
Training loss: 2.049708604812622
Validation loss: 1.9516997287670772

Epoch: 5| Step: 8
Training loss: 1.9746357202529907
Validation loss: 1.9456030974785488

Epoch: 5| Step: 9
Training loss: 2.0819950103759766
Validation loss: 1.9408179074525833

Epoch: 5| Step: 10
Training loss: 2.0078670978546143
Validation loss: 1.9484003732601802

Epoch: 5| Step: 11
Training loss: 1.6116584539413452
Validation loss: 1.9443860153357189

Epoch: 73| Step: 0
Training loss: 1.7887433767318726
Validation loss: 1.9438359141349792

Epoch: 5| Step: 1
Training loss: 1.6424633264541626
Validation loss: 1.9489040523767471

Epoch: 5| Step: 2
Training loss: 1.601017951965332
Validation loss: 1.9542598227659862

Epoch: 5| Step: 3
Training loss: 1.6053507328033447
Validation loss: 1.9538116157054901

Epoch: 5| Step: 4
Training loss: 1.5905132293701172
Validation loss: 1.9512053082386653

Epoch: 5| Step: 5
Training loss: 2.0484867095947266
Validation loss: 1.9593893140554428

Epoch: 5| Step: 6
Training loss: 2.0444130897521973
Validation loss: 1.9511955728133519

Epoch: 5| Step: 7
Training loss: 1.5771596431732178
Validation loss: 1.964728370308876

Epoch: 5| Step: 8
Training loss: 1.600643515586853
Validation loss: 1.982927347222964

Epoch: 5| Step: 9
Training loss: 1.955453634262085
Validation loss: 1.970476657152176

Epoch: 5| Step: 10
Training loss: 2.223081111907959
Validation loss: 1.9685987482468288

Epoch: 5| Step: 11
Training loss: 1.7242544889450073
Validation loss: 1.980253850420316

Epoch: 74| Step: 0
Training loss: 2.1795670986175537
Validation loss: 1.9991809129714966

Epoch: 5| Step: 1
Training loss: 1.7078704833984375
Validation loss: 1.9584544251362483

Epoch: 5| Step: 2
Training loss: 1.361544132232666
Validation loss: 1.983365684747696

Epoch: 5| Step: 3
Training loss: 1.5686559677124023
Validation loss: 1.9691057155529659

Epoch: 5| Step: 4
Training loss: 1.4440670013427734
Validation loss: 1.9522203306357067

Epoch: 5| Step: 5
Training loss: 1.647869348526001
Validation loss: 1.9938899874687195

Epoch: 5| Step: 6
Training loss: 2.115356922149658
Validation loss: 1.9901333699623744

Epoch: 5| Step: 7
Training loss: 1.0971004962921143
Validation loss: 1.9793543219566345

Epoch: 5| Step: 8
Training loss: 2.325554609298706
Validation loss: 1.9825171331564586

Epoch: 5| Step: 9
Training loss: 2.2714056968688965
Validation loss: 1.9432016462087631

Epoch: 5| Step: 10
Training loss: 1.668984055519104
Validation loss: 1.963672697544098

Epoch: 5| Step: 11
Training loss: 1.6229190826416016
Validation loss: 1.9642506788174312

Epoch: 75| Step: 0
Training loss: 2.422527551651001
Validation loss: 1.9369978457689285

Epoch: 5| Step: 1
Training loss: 1.9111149311065674
Validation loss: 1.9527057458957036

Epoch: 5| Step: 2
Training loss: 1.6345418691635132
Validation loss: 1.9791817168394725

Epoch: 5| Step: 3
Training loss: 1.337367296218872
Validation loss: 1.9535011251767476

Epoch: 5| Step: 4
Training loss: 1.9122883081436157
Validation loss: 1.9579379558563232

Epoch: 5| Step: 5
Training loss: 1.4140868186950684
Validation loss: 2.0121505707502365

Epoch: 5| Step: 6
Training loss: 1.6550788879394531
Validation loss: 1.986302837729454

Epoch: 5| Step: 7
Training loss: 2.250967025756836
Validation loss: 2.0383128275473914

Epoch: 5| Step: 8
Training loss: 2.3405892848968506
Validation loss: 2.0181186199188232

Epoch: 5| Step: 9
Training loss: 1.5062649250030518
Validation loss: 2.0163284639517465

Epoch: 5| Step: 10
Training loss: 1.3496744632720947
Validation loss: 1.9776158332824707

Epoch: 5| Step: 11
Training loss: 1.7361063957214355
Validation loss: 1.9716891745726268

Epoch: 76| Step: 0
Training loss: 2.047069787979126
Validation loss: 1.9693931639194489

Epoch: 5| Step: 1
Training loss: 1.830369234085083
Validation loss: 1.9488176852464676

Epoch: 5| Step: 2
Training loss: 1.585137963294983
Validation loss: 1.9545195599397023

Epoch: 5| Step: 3
Training loss: 1.838507056236267
Validation loss: 1.9383927683035533

Epoch: 5| Step: 4
Training loss: 1.8507630825042725
Validation loss: 1.9505325108766556

Epoch: 5| Step: 5
Training loss: 1.6239135265350342
Validation loss: 1.9602839102347691

Epoch: 5| Step: 6
Training loss: 1.612093210220337
Validation loss: 1.9469546775023143

Epoch: 5| Step: 7
Training loss: 1.9189296960830688
Validation loss: 1.94905952612559

Epoch: 5| Step: 8
Training loss: 1.0590708255767822
Validation loss: 1.927736873428027

Epoch: 5| Step: 9
Training loss: 1.8654406070709229
Validation loss: 1.9663178821404774

Epoch: 5| Step: 10
Training loss: 2.238286256790161
Validation loss: 1.9880294452110927

Epoch: 5| Step: 11
Training loss: 0.6859056353569031
Validation loss: 1.966013456384341

Epoch: 77| Step: 0
Training loss: 1.9667870998382568
Validation loss: 2.016198347012202

Epoch: 5| Step: 1
Training loss: 1.6436748504638672
Validation loss: 2.0285960038503013

Epoch: 5| Step: 2
Training loss: 1.9701169729232788
Validation loss: 2.037971928715706

Epoch: 5| Step: 3
Training loss: 1.6204967498779297
Validation loss: 2.054624949892362

Epoch: 5| Step: 4
Training loss: 2.0164384841918945
Validation loss: 2.012013301253319

Epoch: 5| Step: 5
Training loss: 1.930564522743225
Validation loss: 2.0060647328694663

Epoch: 5| Step: 6
Training loss: 1.2458871603012085
Validation loss: 1.993064080675443

Epoch: 5| Step: 7
Training loss: 1.9605449438095093
Validation loss: 2.0142967849969864

Epoch: 5| Step: 8
Training loss: 1.6139230728149414
Validation loss: 1.9706093271573384

Epoch: 5| Step: 9
Training loss: 1.8127925395965576
Validation loss: 1.9826443791389465

Epoch: 5| Step: 10
Training loss: 1.6239515542984009
Validation loss: 1.9822479734818141

Epoch: 5| Step: 11
Training loss: 2.1391072273254395
Validation loss: 1.9439518004655838

Epoch: 78| Step: 0
Training loss: 2.0164942741394043
Validation loss: 1.9425056080023448

Epoch: 5| Step: 1
Training loss: 1.465481162071228
Validation loss: 1.9573245644569397

Epoch: 5| Step: 2
Training loss: 2.174133777618408
Validation loss: 1.9468313852945964

Epoch: 5| Step: 3
Training loss: 2.2021689414978027
Validation loss: 1.9395669102668762

Epoch: 5| Step: 4
Training loss: 1.7709312438964844
Validation loss: 1.9500733613967896

Epoch: 5| Step: 5
Training loss: 1.8070567846298218
Validation loss: 1.9438146601120632

Epoch: 5| Step: 6
Training loss: 1.1321977376937866
Validation loss: 1.9613310098648071

Epoch: 5| Step: 7
Training loss: 1.6104621887207031
Validation loss: 1.9692871570587158

Epoch: 5| Step: 8
Training loss: 1.5277297496795654
Validation loss: 1.9767811050017674

Epoch: 5| Step: 9
Training loss: 1.5069553852081299
Validation loss: 1.962918534874916

Epoch: 5| Step: 10
Training loss: 2.2188689708709717
Validation loss: 1.989838903148969

Epoch: 5| Step: 11
Training loss: 0.29092442989349365
Validation loss: 2.0388332158327103

Epoch: 79| Step: 0
Training loss: 1.9014675617218018
Validation loss: 2.012656033039093

Epoch: 5| Step: 1
Training loss: 2.3718016147613525
Validation loss: 2.0288935055335364

Epoch: 5| Step: 2
Training loss: 1.5609657764434814
Validation loss: 2.0497151911258698

Epoch: 5| Step: 3
Training loss: 1.9893016815185547
Validation loss: 2.0020858397086463

Epoch: 5| Step: 4
Training loss: 1.3803597688674927
Validation loss: 2.0003743916749954

Epoch: 5| Step: 5
Training loss: 2.05110764503479
Validation loss: 2.011001080274582

Epoch: 5| Step: 6
Training loss: 1.594970703125
Validation loss: 1.9759054134289424

Epoch: 5| Step: 7
Training loss: 1.4542508125305176
Validation loss: 1.9476720492045085

Epoch: 5| Step: 8
Training loss: 1.9001874923706055
Validation loss: 1.9464028030633926

Epoch: 5| Step: 9
Training loss: 1.2506492137908936
Validation loss: 1.9790232479572296

Epoch: 5| Step: 10
Training loss: 2.1452319622039795
Validation loss: 1.9533923069636028

Epoch: 5| Step: 11
Training loss: 0.6632499098777771
Validation loss: 1.9747942239046097

Epoch: 80| Step: 0
Training loss: 1.4602657556533813
Validation loss: 1.9741478512684505

Epoch: 5| Step: 1
Training loss: 1.9746150970458984
Validation loss: 1.982298582792282

Epoch: 5| Step: 2
Training loss: 1.2319527864456177
Validation loss: 1.9659895499547322

Epoch: 5| Step: 3
Training loss: 1.4841283559799194
Validation loss: 1.9650401671727498

Epoch: 5| Step: 4
Training loss: 2.1755385398864746
Validation loss: 1.964566210905711

Epoch: 5| Step: 5
Training loss: 1.680964469909668
Validation loss: 1.959357465306918

Epoch: 5| Step: 6
Training loss: 1.9864765405654907
Validation loss: 1.976059541106224

Epoch: 5| Step: 7
Training loss: 1.9482202529907227
Validation loss: 1.9529600242773693

Epoch: 5| Step: 8
Training loss: 1.7559667825698853
Validation loss: 1.9687187522649765

Epoch: 5| Step: 9
Training loss: 1.9738489389419556
Validation loss: 1.9724623014529545

Epoch: 5| Step: 10
Training loss: 1.5830645561218262
Validation loss: 1.9623177349567413

Epoch: 5| Step: 11
Training loss: 0.4898648262023926
Validation loss: 1.9762378285328548

Epoch: 81| Step: 0
Training loss: 2.324479579925537
Validation loss: 2.014713684717814

Epoch: 5| Step: 1
Training loss: 1.4398162364959717
Validation loss: 1.9965109725793202

Epoch: 5| Step: 2
Training loss: 1.3940538167953491
Validation loss: 1.9735693881909053

Epoch: 5| Step: 3
Training loss: 1.7558066844940186
Validation loss: 1.9888897985219955

Epoch: 5| Step: 4
Training loss: 1.6693999767303467
Validation loss: 1.9740093996127446

Epoch: 5| Step: 5
Training loss: 1.1712130308151245
Validation loss: 1.9844970752795537

Epoch: 5| Step: 6
Training loss: 2.262761354446411
Validation loss: 1.9638500263293583

Epoch: 5| Step: 7
Training loss: 1.7757761478424072
Validation loss: 1.9822632024685543

Epoch: 5| Step: 8
Training loss: 2.0838119983673096
Validation loss: 1.9641349812348683

Epoch: 5| Step: 9
Training loss: 1.4444018602371216
Validation loss: 1.9832396060228348

Epoch: 5| Step: 10
Training loss: 1.7047622203826904
Validation loss: 2.002609521150589

Epoch: 5| Step: 11
Training loss: 1.7047595977783203
Validation loss: 1.964999144275983

Epoch: 82| Step: 0
Training loss: 1.517559289932251
Validation loss: 1.9572644035021465

Epoch: 5| Step: 1
Training loss: 2.408280611038208
Validation loss: 1.952024484674136

Epoch: 5| Step: 2
Training loss: 2.1931238174438477
Validation loss: 2.0165340453386307

Epoch: 5| Step: 3
Training loss: 1.278407096862793
Validation loss: 2.001401295264562

Epoch: 5| Step: 4
Training loss: 1.657854437828064
Validation loss: 1.9745410432418187

Epoch: 5| Step: 5
Training loss: 1.3971965312957764
Validation loss: 2.0102517306804657

Epoch: 5| Step: 6
Training loss: 1.8271424770355225
Validation loss: 2.0078034152587256

Epoch: 5| Step: 7
Training loss: 2.3660898208618164
Validation loss: 1.9651194661855698

Epoch: 5| Step: 8
Training loss: 1.6126397848129272
Validation loss: 1.9811272074778874

Epoch: 5| Step: 9
Training loss: 1.9192068576812744
Validation loss: 1.9570647478103638

Epoch: 5| Step: 10
Training loss: 1.0394272804260254
Validation loss: 1.955435703198115

Epoch: 5| Step: 11
Training loss: 1.9767558574676514
Validation loss: 1.9406554748614628

Epoch: 83| Step: 0
Training loss: 1.7355868816375732
Validation loss: 1.9524417072534561

Epoch: 5| Step: 1
Training loss: 1.699528455734253
Validation loss: 1.957704057296117

Epoch: 5| Step: 2
Training loss: 1.5896925926208496
Validation loss: 1.934412196278572

Epoch: 5| Step: 3
Training loss: 1.4978911876678467
Validation loss: 1.9479898909727733

Epoch: 5| Step: 4
Training loss: 1.8233411312103271
Validation loss: 1.9531178176403046

Epoch: 5| Step: 5
Training loss: 1.951314926147461
Validation loss: 1.9484409987926483

Epoch: 5| Step: 6
Training loss: 1.6651256084442139
Validation loss: 1.9624048620462418

Epoch: 5| Step: 7
Training loss: 1.7720829248428345
Validation loss: 1.9523538202047348

Epoch: 5| Step: 8
Training loss: 1.1811015605926514
Validation loss: 1.9685871750116348

Epoch: 5| Step: 9
Training loss: 1.8495019674301147
Validation loss: 1.966257020831108

Epoch: 5| Step: 10
Training loss: 1.889918327331543
Validation loss: 1.9650548646847408

Epoch: 5| Step: 11
Training loss: 2.0219602584838867
Validation loss: 1.9628210465113323

Epoch: 84| Step: 0
Training loss: 2.3536906242370605
Validation loss: 1.979154075185458

Epoch: 5| Step: 1
Training loss: 1.3896477222442627
Validation loss: 1.9889480769634247

Epoch: 5| Step: 2
Training loss: 1.467034101486206
Validation loss: 1.9784083714087803

Epoch: 5| Step: 3
Training loss: 1.364725112915039
Validation loss: 1.9837660143772762

Epoch: 5| Step: 4
Training loss: 1.7420616149902344
Validation loss: 1.9790764103333156

Epoch: 5| Step: 5
Training loss: 1.5141700506210327
Validation loss: 1.9599948823451996

Epoch: 5| Step: 6
Training loss: 2.0862717628479004
Validation loss: 1.9838096350431442

Epoch: 5| Step: 7
Training loss: 1.5610288381576538
Validation loss: 1.9810490757226944

Epoch: 5| Step: 8
Training loss: 1.7916479110717773
Validation loss: 1.9729805092016857

Epoch: 5| Step: 9
Training loss: 1.5115684270858765
Validation loss: 1.9613332599401474

Epoch: 5| Step: 10
Training loss: 2.1256251335144043
Validation loss: 1.9867897878090541

Epoch: 5| Step: 11
Training loss: 1.5357658863067627
Validation loss: 1.9572649002075195

Epoch: 85| Step: 0
Training loss: 2.039358139038086
Validation loss: 1.9682060082753499

Epoch: 5| Step: 1
Training loss: 1.8080368041992188
Validation loss: 1.9412195980548859

Epoch: 5| Step: 2
Training loss: 1.2351725101470947
Validation loss: 1.9584969381491344

Epoch: 5| Step: 3
Training loss: 1.519822359085083
Validation loss: 1.9638794163862865

Epoch: 5| Step: 4
Training loss: 1.6639025211334229
Validation loss: 1.9370435078938801

Epoch: 5| Step: 5
Training loss: 1.9252125024795532
Validation loss: 1.9465511590242386

Epoch: 5| Step: 6
Training loss: 1.7440745830535889
Validation loss: 1.9663264056046803

Epoch: 5| Step: 7
Training loss: 1.6295143365859985
Validation loss: 1.9535559117794037

Epoch: 5| Step: 8
Training loss: 2.0594258308410645
Validation loss: 1.936664879322052

Epoch: 5| Step: 9
Training loss: 1.752816915512085
Validation loss: 1.9526647329330444

Epoch: 5| Step: 10
Training loss: 1.4315667152404785
Validation loss: 1.9621220131715138

Epoch: 5| Step: 11
Training loss: 1.0565056800842285
Validation loss: 1.9624584764242172

Epoch: 86| Step: 0
Training loss: 1.6652443408966064
Validation loss: 1.984732096393903

Epoch: 5| Step: 1
Training loss: 1.8372501134872437
Validation loss: 1.971819092830022

Epoch: 5| Step: 2
Training loss: 1.6278374195098877
Validation loss: 1.9820645054181416

Epoch: 5| Step: 3
Training loss: 1.8066202402114868
Validation loss: 1.9821815341711044

Epoch: 5| Step: 4
Training loss: 2.1610376834869385
Validation loss: 1.9500543574492137

Epoch: 5| Step: 5
Training loss: 1.7088441848754883
Validation loss: 1.9730703433354695

Epoch: 5| Step: 6
Training loss: 1.6271610260009766
Validation loss: 1.9504786332448323

Epoch: 5| Step: 7
Training loss: 1.747265100479126
Validation loss: 1.9599844415982564

Epoch: 5| Step: 8
Training loss: 1.4801042079925537
Validation loss: 1.9734568893909454

Epoch: 5| Step: 9
Training loss: 1.384425163269043
Validation loss: 1.9709160228570302

Epoch: 5| Step: 10
Training loss: 1.3811650276184082
Validation loss: 1.9643182704846065

Epoch: 5| Step: 11
Training loss: 1.6526570320129395
Validation loss: 1.9589200417200725

Epoch: 87| Step: 0
Training loss: 1.7532453536987305
Validation loss: 1.9435471991697948

Epoch: 5| Step: 1
Training loss: 1.8800538778305054
Validation loss: 1.9401385933160782

Epoch: 5| Step: 2
Training loss: 2.161900520324707
Validation loss: 1.9515885760386784

Epoch: 5| Step: 3
Training loss: 1.7315635681152344
Validation loss: 1.951527530948321

Epoch: 5| Step: 4
Training loss: 1.358414888381958
Validation loss: 1.938836395740509

Epoch: 5| Step: 5
Training loss: 1.7481807470321655
Validation loss: 1.9642388224601746

Epoch: 5| Step: 6
Training loss: 1.62493896484375
Validation loss: 1.9533209651708603

Epoch: 5| Step: 7
Training loss: 1.513660192489624
Validation loss: 1.939033105969429

Epoch: 5| Step: 8
Training loss: 1.6415932178497314
Validation loss: 1.9446375916401546

Epoch: 5| Step: 9
Training loss: 1.581278920173645
Validation loss: 1.9794829140106838

Epoch: 5| Step: 10
Training loss: 1.4337660074234009
Validation loss: 1.961357906460762

Epoch: 5| Step: 11
Training loss: 1.8318498134613037
Validation loss: 2.0007995267709098

Epoch: 88| Step: 0
Training loss: 2.1402440071105957
Validation loss: 1.9700289567311604

Epoch: 5| Step: 1
Training loss: 2.0015225410461426
Validation loss: 1.9475864817698796

Epoch: 5| Step: 2
Training loss: 2.1333584785461426
Validation loss: 1.9579151074091594

Epoch: 5| Step: 3
Training loss: 1.2666709423065186
Validation loss: 1.9491850634415944

Epoch: 5| Step: 4
Training loss: 1.796059012413025
Validation loss: 1.959946150581042

Epoch: 5| Step: 5
Training loss: 1.12479829788208
Validation loss: 1.9446892241636913

Epoch: 5| Step: 6
Training loss: 1.720778226852417
Validation loss: 1.9459433952967327

Epoch: 5| Step: 7
Training loss: 1.6343848705291748
Validation loss: 1.9616477886835735

Epoch: 5| Step: 8
Training loss: 1.3124828338623047
Validation loss: 1.9691136876742046

Epoch: 5| Step: 9
Training loss: 1.6102018356323242
Validation loss: 1.9756838530302048

Epoch: 5| Step: 10
Training loss: 2.1758458614349365
Validation loss: 1.9842146237691243

Epoch: 5| Step: 11
Training loss: 1.079764485359192
Validation loss: 1.981562465429306

Epoch: 89| Step: 0
Training loss: 1.9723644256591797
Validation loss: 1.9958291699488957

Epoch: 5| Step: 1
Training loss: 1.5559040307998657
Validation loss: 1.9980017989873886

Epoch: 5| Step: 2
Training loss: 1.5780315399169922
Validation loss: 1.99913423260053

Epoch: 5| Step: 3
Training loss: 1.4971227645874023
Validation loss: 1.9693728039662044

Epoch: 5| Step: 4
Training loss: 1.5999858379364014
Validation loss: 1.9854144155979156

Epoch: 5| Step: 5
Training loss: 1.7299249172210693
Validation loss: 1.9575160096089046

Epoch: 5| Step: 6
Training loss: 1.8513822555541992
Validation loss: 1.9591614703337352

Epoch: 5| Step: 7
Training loss: 1.2264773845672607
Validation loss: 1.9524635672569275

Epoch: 5| Step: 8
Training loss: 1.5347282886505127
Validation loss: 1.9514636645714443

Epoch: 5| Step: 9
Training loss: 2.4218132495880127
Validation loss: 1.9627536783615749

Epoch: 5| Step: 10
Training loss: 1.3699008226394653
Validation loss: 1.9446858316659927

Epoch: 5| Step: 11
Training loss: 3.0123610496520996
Validation loss: 1.939956322312355

Epoch: 90| Step: 0
Training loss: 1.538086175918579
Validation loss: 1.9391166269779205

Epoch: 5| Step: 1
Training loss: 1.7981884479522705
Validation loss: 1.94263490041097

Epoch: 5| Step: 2
Training loss: 1.579864263534546
Validation loss: 1.9441505869229634

Epoch: 5| Step: 3
Training loss: 1.3941824436187744
Validation loss: 1.948107088605563

Epoch: 5| Step: 4
Training loss: 1.4743988513946533
Validation loss: 1.9620376775662105

Epoch: 5| Step: 5
Training loss: 2.07676362991333
Validation loss: 1.9533163607120514

Epoch: 5| Step: 6
Training loss: 1.4543583393096924
Validation loss: 1.9915711432695389

Epoch: 5| Step: 7
Training loss: 1.9426069259643555
Validation loss: 2.0334719320138297

Epoch: 5| Step: 8
Training loss: 1.847360372543335
Validation loss: 2.0183501094579697

Epoch: 5| Step: 9
Training loss: 1.769707441329956
Validation loss: 1.9856920540332794

Epoch: 5| Step: 10
Training loss: 1.554570198059082
Validation loss: 1.9799266010522842

Epoch: 5| Step: 11
Training loss: 1.8745079040527344
Validation loss: 1.9659455766280491

Epoch: 91| Step: 0
Training loss: 1.5439585447311401
Validation loss: 1.9618150095144908

Epoch: 5| Step: 1
Training loss: 1.63913893699646
Validation loss: 1.9421477367480595

Epoch: 5| Step: 2
Training loss: 1.51434326171875
Validation loss: 1.9401201953490574

Epoch: 5| Step: 3
Training loss: 1.5644569396972656
Validation loss: 1.943605254093806

Epoch: 5| Step: 4
Training loss: 1.089017629623413
Validation loss: 1.9359687964121501

Epoch: 5| Step: 5
Training loss: 2.342679977416992
Validation loss: 1.9508171528577805

Epoch: 5| Step: 6
Training loss: 1.6209701299667358
Validation loss: 1.94407919049263

Epoch: 5| Step: 7
Training loss: 1.4773284196853638
Validation loss: 1.9637916783491771

Epoch: 5| Step: 8
Training loss: 1.9154021739959717
Validation loss: 1.9789401441812515

Epoch: 5| Step: 9
Training loss: 1.65352463722229
Validation loss: 1.9767717371384304

Epoch: 5| Step: 10
Training loss: 1.9638690948486328
Validation loss: 1.9799830814202626

Epoch: 5| Step: 11
Training loss: 1.5691238641738892
Validation loss: 1.9847768892844517

Epoch: 92| Step: 0
Training loss: 2.172016143798828
Validation loss: 1.9820104489723842

Epoch: 5| Step: 1
Training loss: 1.6737887859344482
Validation loss: 1.9723691791296005

Epoch: 5| Step: 2
Training loss: 1.5922397375106812
Validation loss: 1.9851029068231583

Epoch: 5| Step: 3
Training loss: 1.8219821453094482
Validation loss: 1.9890492806831996

Epoch: 5| Step: 4
Training loss: 1.6153748035430908
Validation loss: 1.9600929568211238

Epoch: 5| Step: 5
Training loss: 2.0472655296325684
Validation loss: 1.9459926436344783

Epoch: 5| Step: 6
Training loss: 1.5251058340072632
Validation loss: 1.9567109197378159

Epoch: 5| Step: 7
Training loss: 1.3940753936767578
Validation loss: 1.9259790430466335

Epoch: 5| Step: 8
Training loss: 1.5175021886825562
Validation loss: 1.931361163655917

Epoch: 5| Step: 9
Training loss: 1.6825358867645264
Validation loss: 1.9361612399419148

Epoch: 5| Step: 10
Training loss: 1.156707525253296
Validation loss: 1.9351082493861516

Epoch: 5| Step: 11
Training loss: 1.5468074083328247
Validation loss: 1.9451356430848439

Epoch: 93| Step: 0
Training loss: 1.3613954782485962
Validation loss: 1.959099883834521

Epoch: 5| Step: 1
Training loss: 1.1149107217788696
Validation loss: 1.9834382285674412

Epoch: 5| Step: 2
Training loss: 1.3884618282318115
Validation loss: 2.0239304900169373

Epoch: 5| Step: 3
Training loss: 1.740682601928711
Validation loss: 1.9876136432091396

Epoch: 5| Step: 4
Training loss: 1.5760622024536133
Validation loss: 2.0231808622678122

Epoch: 5| Step: 5
Training loss: 1.6928699016571045
Validation loss: 2.0533350855112076

Epoch: 5| Step: 6
Training loss: 2.3607563972473145
Validation loss: 2.018898988763491

Epoch: 5| Step: 7
Training loss: 1.28631591796875
Validation loss: 1.976372167468071

Epoch: 5| Step: 8
Training loss: 1.3975579738616943
Validation loss: 1.9679194490114849

Epoch: 5| Step: 9
Training loss: 2.3730499744415283
Validation loss: 1.9594790538152058

Epoch: 5| Step: 10
Training loss: 1.9430900812149048
Validation loss: 1.9329459716876347

Epoch: 5| Step: 11
Training loss: 2.2842001914978027
Validation loss: 1.9287685304880142

Epoch: 94| Step: 0
Training loss: 1.3183890581130981
Validation loss: 1.9434100886185963

Epoch: 5| Step: 1
Training loss: 2.1871585845947266
Validation loss: 1.9241270820299785

Epoch: 5| Step: 2
Training loss: 1.6773961782455444
Validation loss: 1.9221540838479996

Epoch: 5| Step: 3
Training loss: 1.686579704284668
Validation loss: 1.9246383806069691

Epoch: 5| Step: 4
Training loss: 1.9308735132217407
Validation loss: 1.920250838001569

Epoch: 5| Step: 5
Training loss: 1.6138031482696533
Validation loss: 1.9549215237299602

Epoch: 5| Step: 6
Training loss: 1.4829641580581665
Validation loss: 1.9502297639846802

Epoch: 5| Step: 7
Training loss: 1.4595915079116821
Validation loss: 1.9705101201931636

Epoch: 5| Step: 8
Training loss: 1.7854773998260498
Validation loss: 1.9585880835851033

Epoch: 5| Step: 9
Training loss: 1.569236159324646
Validation loss: 1.9922065436840057

Epoch: 5| Step: 10
Training loss: 1.507380485534668
Validation loss: 1.9973601996898651

Epoch: 5| Step: 11
Training loss: 0.966781497001648
Validation loss: 1.9820807427167892

Epoch: 95| Step: 0
Training loss: 1.4985787868499756
Validation loss: 1.9851713677247365

Epoch: 5| Step: 1
Training loss: 2.213731288909912
Validation loss: 2.03770911693573

Epoch: 5| Step: 2
Training loss: 1.6257431507110596
Validation loss: 2.013493691881498

Epoch: 5| Step: 3
Training loss: 1.5403478145599365
Validation loss: 2.0390703876813254

Epoch: 5| Step: 4
Training loss: 1.076238989830017
Validation loss: 2.015296513835589

Epoch: 5| Step: 5
Training loss: 1.622556447982788
Validation loss: 1.9943948537111282

Epoch: 5| Step: 6
Training loss: 1.7242333889007568
Validation loss: 1.9746827632188797

Epoch: 5| Step: 7
Training loss: 2.3251943588256836
Validation loss: 1.9751492341359456

Epoch: 5| Step: 8
Training loss: 1.481191873550415
Validation loss: 1.9387819369633992

Epoch: 5| Step: 9
Training loss: 1.314308524131775
Validation loss: 1.9436068882544835

Epoch: 5| Step: 10
Training loss: 1.7543331384658813
Validation loss: 1.9345267117023468

Epoch: 5| Step: 11
Training loss: 2.634406566619873
Validation loss: 1.9304000039895375

Epoch: 96| Step: 0
Training loss: 1.5801212787628174
Validation loss: 1.9575807799895604

Epoch: 5| Step: 1
Training loss: 1.462054967880249
Validation loss: 1.9493001103401184

Epoch: 5| Step: 2
Training loss: 1.5067907571792603
Validation loss: 1.9804201970497768

Epoch: 5| Step: 3
Training loss: 1.3173551559448242
Validation loss: 1.9875513116518657

Epoch: 5| Step: 4
Training loss: 1.6190160512924194
Validation loss: 2.017443060874939

Epoch: 5| Step: 5
Training loss: 1.6667228937149048
Validation loss: 1.973899245262146

Epoch: 5| Step: 6
Training loss: 1.3165931701660156
Validation loss: 2.0100569228331246

Epoch: 5| Step: 7
Training loss: 1.3739078044891357
Validation loss: 1.9777027020851772

Epoch: 5| Step: 8
Training loss: 2.0272488594055176
Validation loss: 1.9830448279778163

Epoch: 5| Step: 9
Training loss: 2.112422466278076
Validation loss: 1.9624329408009846

Epoch: 5| Step: 10
Training loss: 1.9719078540802002
Validation loss: 1.9749070803324382

Epoch: 5| Step: 11
Training loss: 1.5005366802215576
Validation loss: 1.9422208319107692

Epoch: 97| Step: 0
Training loss: 1.8038206100463867
Validation loss: 1.9364572415749233

Epoch: 5| Step: 1
Training loss: 1.659494400024414
Validation loss: 1.9439166982968648

Epoch: 5| Step: 2
Training loss: 2.096561908721924
Validation loss: 1.9091409146785736

Epoch: 5| Step: 3
Training loss: 1.714903473854065
Validation loss: 1.936789279182752

Epoch: 5| Step: 4
Training loss: 1.4979724884033203
Validation loss: 1.9271919776995976

Epoch: 5| Step: 5
Training loss: 1.065675139427185
Validation loss: 1.9215372602144878

Epoch: 5| Step: 6
Training loss: 1.393627405166626
Validation loss: 1.97373961408933

Epoch: 5| Step: 7
Training loss: 1.4473916292190552
Validation loss: 1.9604420016209285

Epoch: 5| Step: 8
Training loss: 1.728449821472168
Validation loss: 1.9890191654364269

Epoch: 5| Step: 9
Training loss: 1.821276307106018
Validation loss: 1.9825536111990611

Epoch: 5| Step: 10
Training loss: 1.8146953582763672
Validation loss: 1.9771432826916377

Epoch: 5| Step: 11
Training loss: 1.5877431631088257
Validation loss: 1.9773142139116924

Epoch: 98| Step: 0
Training loss: 1.9307348728179932
Validation loss: 1.940865049759547

Epoch: 5| Step: 1
Training loss: 1.6235475540161133
Validation loss: 1.9314434826374054

Epoch: 5| Step: 2
Training loss: 1.8127692937850952
Validation loss: 1.9095907509326935

Epoch: 5| Step: 3
Training loss: 1.9105920791625977
Validation loss: 1.9307941645383835

Epoch: 5| Step: 4
Training loss: 1.3585305213928223
Validation loss: 1.939914604028066

Epoch: 5| Step: 5
Training loss: 1.9843549728393555
Validation loss: 1.9401607761780422

Epoch: 5| Step: 6
Training loss: 1.6202621459960938
Validation loss: 1.932081828514735

Epoch: 5| Step: 7
Training loss: 1.8177623748779297
Validation loss: 1.9575802435477574

Epoch: 5| Step: 8
Training loss: 1.279559850692749
Validation loss: 1.9645427962144215

Epoch: 5| Step: 9
Training loss: 1.346662163734436
Validation loss: 1.9883293608824413

Epoch: 5| Step: 10
Training loss: 1.137921929359436
Validation loss: 1.9836444507042568

Epoch: 5| Step: 11
Training loss: 1.872359037399292
Validation loss: 1.986797829469045

Epoch: 99| Step: 0
Training loss: 1.1592082977294922
Validation loss: 1.9783277610937755

Epoch: 5| Step: 1
Training loss: 1.7118088006973267
Validation loss: 1.9631569037834804

Epoch: 5| Step: 2
Training loss: 1.6220238208770752
Validation loss: 1.95017704864343

Epoch: 5| Step: 3
Training loss: 1.3521268367767334
Validation loss: 1.9470284084479015

Epoch: 5| Step: 4
Training loss: 1.426304817199707
Validation loss: 1.960394670565923

Epoch: 5| Step: 5
Training loss: 1.6087124347686768
Validation loss: 1.914342314004898

Epoch: 5| Step: 6
Training loss: 1.6439669132232666
Validation loss: 1.931060676773389

Epoch: 5| Step: 7
Training loss: 1.9175174236297607
Validation loss: 1.9093953768412273

Epoch: 5| Step: 8
Training loss: 2.067203998565674
Validation loss: 1.929336632291476

Epoch: 5| Step: 9
Training loss: 1.6095809936523438
Validation loss: 1.9152666727701824

Epoch: 5| Step: 10
Training loss: 1.5570485591888428
Validation loss: 1.9384257545073826

Epoch: 5| Step: 11
Training loss: 2.09114933013916
Validation loss: 1.9419980595509212

Epoch: 100| Step: 0
Training loss: 1.7575010061264038
Validation loss: 1.9471134394407272

Epoch: 5| Step: 1
Training loss: 2.0726065635681152
Validation loss: 1.94135016699632

Epoch: 5| Step: 2
Training loss: 1.5149856805801392
Validation loss: 1.9388313591480255

Epoch: 5| Step: 3
Training loss: 1.454858660697937
Validation loss: 1.9764326512813568

Epoch: 5| Step: 4
Training loss: 1.7134675979614258
Validation loss: 2.0225732624530792

Epoch: 5| Step: 5
Training loss: 1.3396390676498413
Validation loss: 1.9945059369007747

Epoch: 5| Step: 6
Training loss: 1.8503141403198242
Validation loss: 1.9884057988723118

Epoch: 5| Step: 7
Training loss: 1.2438545227050781
Validation loss: 1.9624975423018138

Epoch: 5| Step: 8
Training loss: 2.0895156860351562
Validation loss: 1.9527706801891327

Epoch: 5| Step: 9
Training loss: 1.4963972568511963
Validation loss: 1.940465897321701

Epoch: 5| Step: 10
Training loss: 1.435717225074768
Validation loss: 1.9472652425368626

Epoch: 5| Step: 11
Training loss: 1.7002537250518799
Validation loss: 1.9347430616617203

Epoch: 101| Step: 0
Training loss: 1.3364753723144531
Validation loss: 1.9430826405684154

Epoch: 5| Step: 1
Training loss: 1.756162405014038
Validation loss: 1.9185143808523815

Epoch: 5| Step: 2
Training loss: 1.40169095993042
Validation loss: 1.926403780778249

Epoch: 5| Step: 3
Training loss: 1.468335747718811
Validation loss: 1.9175193011760712

Epoch: 5| Step: 4
Training loss: 1.6670753955841064
Validation loss: 1.9602799862623215

Epoch: 5| Step: 5
Training loss: 1.3167579174041748
Validation loss: 1.9685290306806564

Epoch: 5| Step: 6
Training loss: 1.2401000261306763
Validation loss: 1.9886126667261124

Epoch: 5| Step: 7
Training loss: 1.7238432168960571
Validation loss: 1.9978949477275212

Epoch: 5| Step: 8
Training loss: 2.1894583702087402
Validation loss: 2.029121925433477

Epoch: 5| Step: 9
Training loss: 1.3158371448516846
Validation loss: 2.0240421444177628

Epoch: 5| Step: 10
Training loss: 2.197031259536743
Validation loss: 2.0390784293413162

Epoch: 5| Step: 11
Training loss: 3.0243773460388184
Validation loss: 2.027944261829058

Epoch: 102| Step: 0
Training loss: 1.6005550622940063
Validation loss: 1.9567575305700302

Epoch: 5| Step: 1
Training loss: 1.8569291830062866
Validation loss: 1.926711882154147

Epoch: 5| Step: 2
Training loss: 1.9062631130218506
Validation loss: 1.9448756873607635

Epoch: 5| Step: 3
Training loss: 1.8002078533172607
Validation loss: 1.965219760934512

Epoch: 5| Step: 4
Training loss: 1.4637680053710938
Validation loss: 1.955737665295601

Epoch: 5| Step: 5
Training loss: 1.6148855686187744
Validation loss: 1.9582223693529766

Epoch: 5| Step: 6
Training loss: 1.6375246047973633
Validation loss: 1.9711437026659648

Epoch: 5| Step: 7
Training loss: 1.7096351385116577
Validation loss: 1.9738577703634899

Epoch: 5| Step: 8
Training loss: 2.3128740787506104
Validation loss: 1.9320484499136608

Epoch: 5| Step: 9
Training loss: 1.7606395483016968
Validation loss: 1.9314465820789337

Epoch: 5| Step: 10
Training loss: 1.5185340642929077
Validation loss: 1.9232855091492336

Epoch: 5| Step: 11
Training loss: 1.5630602836608887
Validation loss: 1.9449701408545177

Epoch: 103| Step: 0
Training loss: 1.7999019622802734
Validation loss: 1.9532427390416462

Epoch: 5| Step: 1
Training loss: 1.7195093631744385
Validation loss: 1.9686824431022008

Epoch: 5| Step: 2
Training loss: 1.5099523067474365
Validation loss: 1.9933128009239833

Epoch: 5| Step: 3
Training loss: 1.5323679447174072
Validation loss: 1.99862706164519

Epoch: 5| Step: 4
Training loss: 2.1987526416778564
Validation loss: 2.0018745263417563

Epoch: 5| Step: 5
Training loss: 1.3054485321044922
Validation loss: 2.0111865301926932

Epoch: 5| Step: 6
Training loss: 1.6481319665908813
Validation loss: 2.008153041203817

Epoch: 5| Step: 7
Training loss: 1.8547252416610718
Validation loss: 1.992984006802241

Epoch: 5| Step: 8
Training loss: 1.2450546026229858
Validation loss: 1.966497043768565

Epoch: 5| Step: 9
Training loss: 1.3246413469314575
Validation loss: 1.9530133257309596

Epoch: 5| Step: 10
Training loss: 1.2003453969955444
Validation loss: 1.9628093838691711

Epoch: 5| Step: 11
Training loss: 2.241051197052002
Validation loss: 1.9604787478844325

Epoch: 104| Step: 0
Training loss: 1.1900285482406616
Validation loss: 1.9542855024337769

Epoch: 5| Step: 1
Training loss: 1.8908710479736328
Validation loss: 1.995766282081604

Epoch: 5| Step: 2
Training loss: 1.495248556137085
Validation loss: 1.9238476653893788

Epoch: 5| Step: 3
Training loss: 1.5568163394927979
Validation loss: 1.9590948969125748

Epoch: 5| Step: 4
Training loss: 1.5549936294555664
Validation loss: 1.9586348980665207

Epoch: 5| Step: 5
Training loss: 1.7173763513565063
Validation loss: 1.9451177716255188

Epoch: 5| Step: 6
Training loss: 2.0646677017211914
Validation loss: 1.910742074251175

Epoch: 5| Step: 7
Training loss: 0.9757171869277954
Validation loss: 1.9530337403217952

Epoch: 5| Step: 8
Training loss: 1.2242275476455688
Validation loss: 1.9473986426989238

Epoch: 5| Step: 9
Training loss: 2.178147792816162
Validation loss: 1.976791853706042

Epoch: 5| Step: 10
Training loss: 1.5191808938980103
Validation loss: 1.970126435160637

Epoch: 5| Step: 11
Training loss: 2.295424461364746
Validation loss: 1.9588166574637096

Epoch: 105| Step: 0
Training loss: 1.1941033601760864
Validation loss: 1.983926847577095

Epoch: 5| Step: 1
Training loss: 1.6502065658569336
Validation loss: 2.0169179240862527

Epoch: 5| Step: 2
Training loss: 1.3230489492416382
Validation loss: 2.0192116101582847

Epoch: 5| Step: 3
Training loss: 1.8445091247558594
Validation loss: 2.023479317625364

Epoch: 5| Step: 4
Training loss: 1.6891406774520874
Validation loss: 1.9794818957646687

Epoch: 5| Step: 5
Training loss: 1.5736629962921143
Validation loss: 1.9943691442410152

Epoch: 5| Step: 6
Training loss: 1.7256816625595093
Validation loss: 1.9565252910057704

Epoch: 5| Step: 7
Training loss: 1.2629034519195557
Validation loss: 1.9781797428925831

Epoch: 5| Step: 8
Training loss: 1.5074716806411743
Validation loss: 1.9269845932722092

Epoch: 5| Step: 9
Training loss: 1.5565474033355713
Validation loss: 1.9578022211790085

Epoch: 5| Step: 10
Training loss: 1.9751020669937134
Validation loss: 1.9324912478526433

Epoch: 5| Step: 11
Training loss: 1.5637342929840088
Validation loss: 1.9295647641023

Epoch: 106| Step: 0
Training loss: 1.4561344385147095
Validation loss: 1.9288255621989567

Epoch: 5| Step: 1
Training loss: 1.4328882694244385
Validation loss: 1.9242162108421326

Epoch: 5| Step: 2
Training loss: 1.7542877197265625
Validation loss: 1.9204028795162837

Epoch: 5| Step: 3
Training loss: 1.6978470087051392
Validation loss: 1.9270499398310978

Epoch: 5| Step: 4
Training loss: 2.0632565021514893
Validation loss: 1.9490522692600887

Epoch: 5| Step: 5
Training loss: 1.3812627792358398
Validation loss: 1.9459454516569774

Epoch: 5| Step: 6
Training loss: 1.486877202987671
Validation loss: 1.9478201319773991

Epoch: 5| Step: 7
Training loss: 1.313842535018921
Validation loss: 1.9268843134244282

Epoch: 5| Step: 8
Training loss: 1.631438970565796
Validation loss: 1.9509969453016918

Epoch: 5| Step: 9
Training loss: 1.2339106798171997
Validation loss: 1.9734467019637425

Epoch: 5| Step: 10
Training loss: 1.8114519119262695
Validation loss: 1.9704473863045375

Epoch: 5| Step: 11
Training loss: 1.0556888580322266
Validation loss: 2.0055462767680488

Epoch: 107| Step: 0
Training loss: 1.609885573387146
Validation loss: 2.0067057063182197

Epoch: 5| Step: 1
Training loss: 1.3819597959518433
Validation loss: 2.0136560449997583

Epoch: 5| Step: 2
Training loss: 0.8951953649520874
Validation loss: 2.0267536987861

Epoch: 5| Step: 3
Training loss: 1.1745831966400146
Validation loss: 1.9332767377297084

Epoch: 5| Step: 4
Training loss: 1.6021645069122314
Validation loss: 1.949137106537819

Epoch: 5| Step: 5
Training loss: 1.3869460821151733
Validation loss: 1.941192736228307

Epoch: 5| Step: 6
Training loss: 1.593996286392212
Validation loss: 1.9392602841059368

Epoch: 5| Step: 7
Training loss: 1.9745771884918213
Validation loss: 1.9392364223798115

Epoch: 5| Step: 8
Training loss: 2.1220500469207764
Validation loss: 1.928948352734248

Epoch: 5| Step: 9
Training loss: 1.8133541345596313
Validation loss: 1.9546828518311183

Epoch: 5| Step: 10
Training loss: 1.6426258087158203
Validation loss: 1.9464309612909954

Epoch: 5| Step: 11
Training loss: 2.66015625
Validation loss: 1.9208463728427887

Epoch: 108| Step: 0
Training loss: 1.547093152999878
Validation loss: 1.9500722487767537

Epoch: 5| Step: 1
Training loss: 1.6194254159927368
Validation loss: 1.9595051904519398

Epoch: 5| Step: 2
Training loss: 1.0292174816131592
Validation loss: 1.9695000648498535

Epoch: 5| Step: 3
Training loss: 1.961503267288208
Validation loss: 1.979847510655721

Epoch: 5| Step: 4
Training loss: 1.3654519319534302
Validation loss: 1.981419598062833

Epoch: 5| Step: 5
Training loss: 1.3545098304748535
Validation loss: 1.980863889058431

Epoch: 5| Step: 6
Training loss: 1.8072283267974854
Validation loss: 1.948411871989568

Epoch: 5| Step: 7
Training loss: 1.6275556087493896
Validation loss: 1.9061467200517654

Epoch: 5| Step: 8
Training loss: 1.425356149673462
Validation loss: 1.94257785876592

Epoch: 5| Step: 9
Training loss: 1.266425371170044
Validation loss: 1.9477659563223522

Epoch: 5| Step: 10
Training loss: 2.0071048736572266
Validation loss: 1.9381022204955418

Epoch: 5| Step: 11
Training loss: 1.3751494884490967
Validation loss: 1.9116696119308472

Epoch: 109| Step: 0
Training loss: 1.555660367012024
Validation loss: 1.9246949901183446

Epoch: 5| Step: 1
Training loss: 1.550564169883728
Validation loss: 1.9264902820189793

Epoch: 5| Step: 2
Training loss: 1.6680713891983032
Validation loss: 1.926842565337817

Epoch: 5| Step: 3
Training loss: 1.3911181688308716
Validation loss: 1.89887073636055

Epoch: 5| Step: 4
Training loss: 2.33449387550354
Validation loss: 1.9084620972474415

Epoch: 5| Step: 5
Training loss: 1.4537127017974854
Validation loss: 1.8896813939015071

Epoch: 5| Step: 6
Training loss: 1.3659942150115967
Validation loss: 1.9332165320714314

Epoch: 5| Step: 7
Training loss: 1.5926792621612549
Validation loss: 1.9524054179588954

Epoch: 5| Step: 8
Training loss: 1.4567186832427979
Validation loss: 1.9457297970851262

Epoch: 5| Step: 9
Training loss: 0.8622184991836548
Validation loss: 1.9699322581291199

Epoch: 5| Step: 10
Training loss: 1.7506592273712158
Validation loss: 1.9698430299758911

Epoch: 5| Step: 11
Training loss: 2.3408703804016113
Validation loss: 1.9802402804295223

Epoch: 110| Step: 0
Training loss: 1.4417511224746704
Validation loss: 1.9645962715148926

Epoch: 5| Step: 1
Training loss: 1.1391435861587524
Validation loss: 1.9600585848093033

Epoch: 5| Step: 2
Training loss: 1.6179132461547852
Validation loss: 1.9457708646853764

Epoch: 5| Step: 3
Training loss: 1.2538094520568848
Validation loss: 1.950654963652293

Epoch: 5| Step: 4
Training loss: 1.1723909378051758
Validation loss: 1.9618814637263615

Epoch: 5| Step: 5
Training loss: 1.4856657981872559
Validation loss: 1.9372315108776093

Epoch: 5| Step: 6
Training loss: 2.1585023403167725
Validation loss: 1.9341086347897847

Epoch: 5| Step: 7
Training loss: 1.9815340042114258
Validation loss: 1.9193955014149349

Epoch: 5| Step: 8
Training loss: 1.565914511680603
Validation loss: 1.9123511264721553

Epoch: 5| Step: 9
Training loss: 1.455225944519043
Validation loss: 1.9416831185420353

Epoch: 5| Step: 10
Training loss: 1.6194874048233032
Validation loss: 1.9236145466566086

Epoch: 5| Step: 11
Training loss: 0.6199267506599426
Validation loss: 1.9446937342484791

Epoch: 111| Step: 0
Training loss: 1.2609803676605225
Validation loss: 1.956414173046748

Epoch: 5| Step: 1
Training loss: 1.6976163387298584
Validation loss: 1.965424433350563

Epoch: 5| Step: 2
Training loss: 1.7249466180801392
Validation loss: 1.969503864645958

Epoch: 5| Step: 3
Training loss: 1.384838342666626
Validation loss: 1.9537417143583298

Epoch: 5| Step: 4
Training loss: 1.32082200050354
Validation loss: 1.9965669810771942

Epoch: 5| Step: 5
Training loss: 1.5771567821502686
Validation loss: 1.9763626009225845

Epoch: 5| Step: 6
Training loss: 1.7554090023040771
Validation loss: 1.9606954554716747

Epoch: 5| Step: 7
Training loss: 1.634333848953247
Validation loss: 1.961231380701065

Epoch: 5| Step: 8
Training loss: 1.1763064861297607
Validation loss: 1.9634416103363037

Epoch: 5| Step: 9
Training loss: 1.8048372268676758
Validation loss: 1.9493834624687831

Epoch: 5| Step: 10
Training loss: 1.6969900131225586
Validation loss: 1.9635165830453236

Epoch: 5| Step: 11
Training loss: 0.42947471141815186
Validation loss: 1.9242521822452545

Epoch: 112| Step: 0
Training loss: 1.4452890157699585
Validation loss: 1.9463360011577606

Epoch: 5| Step: 1
Training loss: 1.5171458721160889
Validation loss: 1.952641487121582

Epoch: 5| Step: 2
Training loss: 1.5392440557479858
Validation loss: 1.937068298459053

Epoch: 5| Step: 3
Training loss: 1.4558734893798828
Validation loss: 1.9574625492095947

Epoch: 5| Step: 4
Training loss: 2.0578150749206543
Validation loss: 1.9598694493373234

Epoch: 5| Step: 5
Training loss: 1.3503273725509644
Validation loss: 1.974492569764455

Epoch: 5| Step: 6
Training loss: 1.445400357246399
Validation loss: 1.935436636209488

Epoch: 5| Step: 7
Training loss: 2.189547061920166
Validation loss: 1.9659177362918854

Epoch: 5| Step: 8
Training loss: 1.305180311203003
Validation loss: 1.959779794017474

Epoch: 5| Step: 9
Training loss: 0.9462422132492065
Validation loss: 1.97710586587588

Epoch: 5| Step: 10
Training loss: 1.451902151107788
Validation loss: 1.9746929506460826

Epoch: 5| Step: 11
Training loss: 0.7493191957473755
Validation loss: 1.9606605718533199

Epoch: 113| Step: 0
Training loss: 1.77069091796875
Validation loss: 1.9772318452596664

Epoch: 5| Step: 1
Training loss: 1.8996250629425049
Validation loss: 1.988224019606908

Epoch: 5| Step: 2
Training loss: 1.1122806072235107
Validation loss: 1.9916794002056122

Epoch: 5| Step: 3
Training loss: 1.6258310079574585
Validation loss: 1.968926986058553

Epoch: 5| Step: 4
Training loss: 1.5647470951080322
Validation loss: 1.9747404704491298

Epoch: 5| Step: 5
Training loss: 1.5419738292694092
Validation loss: 1.9473973015944164

Epoch: 5| Step: 6
Training loss: 1.6884273290634155
Validation loss: 1.9685681114594142

Epoch: 5| Step: 7
Training loss: 1.3441389799118042
Validation loss: 1.951282223065694

Epoch: 5| Step: 8
Training loss: 1.2919645309448242
Validation loss: 1.9949710071086884

Epoch: 5| Step: 9
Training loss: 1.4423129558563232
Validation loss: 1.9731985926628113

Epoch: 5| Step: 10
Training loss: 1.2394102811813354
Validation loss: 1.9610989491144817

Epoch: 5| Step: 11
Training loss: 0.5647982358932495
Validation loss: 1.9630730797847111

Epoch: 114| Step: 0
Training loss: 1.30169677734375
Validation loss: 1.961394543449084

Epoch: 5| Step: 1
Training loss: 1.8427000045776367
Validation loss: 1.9441297799348831

Epoch: 5| Step: 2
Training loss: 1.560621738433838
Validation loss: 1.9658029079437256

Epoch: 5| Step: 3
Training loss: 1.6319706439971924
Validation loss: 1.943613275885582

Epoch: 5| Step: 4
Training loss: 1.2399747371673584
Validation loss: 1.9556552469730377

Epoch: 5| Step: 5
Training loss: 1.5809791088104248
Validation loss: 1.9565683603286743

Epoch: 5| Step: 6
Training loss: 1.1162233352661133
Validation loss: 1.9646316419045131

Epoch: 5| Step: 7
Training loss: 2.0372090339660645
Validation loss: 1.9723620613416035

Epoch: 5| Step: 8
Training loss: 1.3756892681121826
Validation loss: 1.9888778428236644

Epoch: 5| Step: 9
Training loss: 1.5199066400527954
Validation loss: 1.9473895678917568

Epoch: 5| Step: 10
Training loss: 1.386330485343933
Validation loss: 1.9388190706570942

Epoch: 5| Step: 11
Training loss: 0.6615308523178101
Validation loss: 1.9525110125541687

Epoch: 115| Step: 0
Training loss: 2.116253137588501
Validation loss: 1.9524052689472835

Epoch: 5| Step: 1
Training loss: 1.8973281383514404
Validation loss: 1.965624322493871

Epoch: 5| Step: 2
Training loss: 1.0300910472869873
Validation loss: 1.980478470524152

Epoch: 5| Step: 3
Training loss: 1.8701038360595703
Validation loss: 1.9765821198622386

Epoch: 5| Step: 4
Training loss: 1.2503083944320679
Validation loss: 1.9435110986232758

Epoch: 5| Step: 5
Training loss: 1.6074326038360596
Validation loss: 1.9838551382223766

Epoch: 5| Step: 6
Training loss: 1.1067864894866943
Validation loss: 1.9698665986458461

Epoch: 5| Step: 7
Training loss: 1.1513949632644653
Validation loss: 1.9738683352867763

Epoch: 5| Step: 8
Training loss: 1.9743030071258545
Validation loss: 1.9412196030219395

Epoch: 5| Step: 9
Training loss: 1.0055596828460693
Validation loss: 1.9458640366792679

Epoch: 5| Step: 10
Training loss: 1.3872959613800049
Validation loss: 1.94223091006279

Epoch: 5| Step: 11
Training loss: 0.8536738753318787
Validation loss: 1.9057230800390244

Epoch: 116| Step: 0
Training loss: 1.5506315231323242
Validation loss: 1.9465798884630203

Epoch: 5| Step: 1
Training loss: 1.3232594728469849
Validation loss: 1.9353194485108058

Epoch: 5| Step: 2
Training loss: 1.597082257270813
Validation loss: 1.9280029187599819

Epoch: 5| Step: 3
Training loss: 1.8249285221099854
Validation loss: 1.9079634100198746

Epoch: 5| Step: 4
Training loss: 1.1875282526016235
Validation loss: 1.9225321213404338

Epoch: 5| Step: 5
Training loss: 1.119157314300537
Validation loss: 1.9141425987084706

Epoch: 5| Step: 6
Training loss: 1.8646295070648193
Validation loss: 1.9351444840431213

Epoch: 5| Step: 7
Training loss: 1.3788949251174927
Validation loss: 1.9222744206587474

Epoch: 5| Step: 8
Training loss: 1.8751566410064697
Validation loss: 1.923520068327586

Epoch: 5| Step: 9
Training loss: 1.5570766925811768
Validation loss: 1.9300988813241322

Epoch: 5| Step: 10
Training loss: 1.2352019548416138
Validation loss: 1.9812796016534169

Epoch: 5| Step: 11
Training loss: 1.8196163177490234
Validation loss: 1.978662316997846

Epoch: 117| Step: 0
Training loss: 1.214474081993103
Validation loss: 1.994415248433749

Epoch: 5| Step: 1
Training loss: 1.7034235000610352
Validation loss: 2.007126346230507

Epoch: 5| Step: 2
Training loss: 1.5796985626220703
Validation loss: 2.023118535677592

Epoch: 5| Step: 3
Training loss: 1.497023344039917
Validation loss: 2.011396740873655

Epoch: 5| Step: 4
Training loss: 0.86552494764328
Validation loss: 1.9970983217159908

Epoch: 5| Step: 5
Training loss: 1.9749923944473267
Validation loss: 1.9802734802166622

Epoch: 5| Step: 6
Training loss: 1.5936170816421509
Validation loss: 1.9630337754885356

Epoch: 5| Step: 7
Training loss: 1.6038440465927124
Validation loss: 1.9318816463152568

Epoch: 5| Step: 8
Training loss: 1.5581763982772827
Validation loss: 1.9544887244701385

Epoch: 5| Step: 9
Training loss: 1.574520468711853
Validation loss: 1.9721866349379222

Epoch: 5| Step: 10
Training loss: 1.3503177165985107
Validation loss: 1.9698571215073268

Epoch: 5| Step: 11
Training loss: 2.021967887878418
Validation loss: 1.9715646107991536

Epoch: 118| Step: 0
Training loss: 1.5706251859664917
Validation loss: 1.9732839067776997

Epoch: 5| Step: 1
Training loss: 1.5326849222183228
Validation loss: 1.9342617044846218

Epoch: 5| Step: 2
Training loss: 2.0733108520507812
Validation loss: 1.971776083111763

Epoch: 5| Step: 3
Training loss: 1.7001317739486694
Validation loss: 1.938682998220126

Epoch: 5| Step: 4
Training loss: 1.2374768257141113
Validation loss: 1.9584093044201534

Epoch: 5| Step: 5
Training loss: 1.071073293685913
Validation loss: 1.954952632387479

Epoch: 5| Step: 6
Training loss: 1.2816870212554932
Validation loss: 1.985569566488266

Epoch: 5| Step: 7
Training loss: 1.473440170288086
Validation loss: 1.971805363893509

Epoch: 5| Step: 8
Training loss: 1.7315032482147217
Validation loss: 1.9836336026589076

Epoch: 5| Step: 9
Training loss: 1.6870861053466797
Validation loss: 1.9942957609891891

Epoch: 5| Step: 10
Training loss: 1.4886505603790283
Validation loss: 1.984411935011546

Epoch: 5| Step: 11
Training loss: 1.444235920906067
Validation loss: 1.990070879459381

Epoch: 119| Step: 0
Training loss: 1.6896520853042603
Validation loss: 1.9271612962086995

Epoch: 5| Step: 1
Training loss: 1.6533762216567993
Validation loss: 1.9038301060597103

Epoch: 5| Step: 2
Training loss: 1.6086599826812744
Validation loss: 1.9243917167186737

Epoch: 5| Step: 3
Training loss: 1.3813726902008057
Validation loss: 1.912850906451543

Epoch: 5| Step: 4
Training loss: 1.5658700466156006
Validation loss: 1.9148229906956356

Epoch: 5| Step: 5
Training loss: 1.2423511743545532
Validation loss: 1.900564322868983

Epoch: 5| Step: 6
Training loss: 1.3230301141738892
Validation loss: 1.9207383294900258

Epoch: 5| Step: 7
Training loss: 1.648437738418579
Validation loss: 1.9212374885876973

Epoch: 5| Step: 8
Training loss: 1.3266053199768066
Validation loss: 1.9237724393606186

Epoch: 5| Step: 9
Training loss: 1.2304922342300415
Validation loss: 1.9452607681353886

Epoch: 5| Step: 10
Training loss: 1.7275307178497314
Validation loss: 1.927982822060585

Epoch: 5| Step: 11
Training loss: 1.089367389678955
Validation loss: 1.96432726085186

Epoch: 120| Step: 0
Training loss: 1.4979737997055054
Validation loss: 1.93392617503802

Epoch: 5| Step: 1
Training loss: 1.0181379318237305
Validation loss: 1.9764202982187271

Epoch: 5| Step: 2
Training loss: 1.475051760673523
Validation loss: 1.9721872856219609

Epoch: 5| Step: 3
Training loss: 1.054642915725708
Validation loss: 1.9684010595083237

Epoch: 5| Step: 4
Training loss: 1.3036620616912842
Validation loss: 1.9845754752556484

Epoch: 5| Step: 5
Training loss: 2.083146333694458
Validation loss: 1.9496158361434937

Epoch: 5| Step: 6
Training loss: 1.0724838972091675
Validation loss: 1.9527654498815536

Epoch: 5| Step: 7
Training loss: 1.4754087924957275
Validation loss: 1.9650710572799046

Epoch: 5| Step: 8
Training loss: 1.2033907175064087
Validation loss: 1.9445744107166927

Epoch: 5| Step: 9
Training loss: 2.210773468017578
Validation loss: 1.950747365752856

Epoch: 5| Step: 10
Training loss: 1.2756493091583252
Validation loss: 1.9541550278663635

Epoch: 5| Step: 11
Training loss: 1.4907296895980835
Validation loss: 1.9484182447195053

Epoch: 121| Step: 0
Training loss: 2.197209596633911
Validation loss: 1.9124142130215962

Epoch: 5| Step: 1
Training loss: 1.3527206182479858
Validation loss: 1.9253851771354675

Epoch: 5| Step: 2
Training loss: 0.9938712120056152
Validation loss: 1.9580830037593842

Epoch: 5| Step: 3
Training loss: 1.8552188873291016
Validation loss: 1.9292013347148895

Epoch: 5| Step: 4
Training loss: 1.162886381149292
Validation loss: 1.9284199178218842

Epoch: 5| Step: 5
Training loss: 1.3621894121170044
Validation loss: 1.9162193934122722

Epoch: 5| Step: 6
Training loss: 1.2213423252105713
Validation loss: 1.9464295009771984

Epoch: 5| Step: 7
Training loss: 1.2900327444076538
Validation loss: 1.9476701219876607

Epoch: 5| Step: 8
Training loss: 1.4598830938339233
Validation loss: 1.9526226371526718

Epoch: 5| Step: 9
Training loss: 1.4450788497924805
Validation loss: 1.9414071689049404

Epoch: 5| Step: 10
Training loss: 1.5792587995529175
Validation loss: 1.9208263059457142

Epoch: 5| Step: 11
Training loss: 0.9856231212615967
Validation loss: 1.9463963160912197

Epoch: 122| Step: 0
Training loss: 0.9714528918266296
Validation loss: 1.9602912416060765

Epoch: 5| Step: 1
Training loss: 1.7759021520614624
Validation loss: 1.9284695436557133

Epoch: 5| Step: 2
Training loss: 1.5092121362686157
Validation loss: 1.9252107242743175

Epoch: 5| Step: 3
Training loss: 1.4135669469833374
Validation loss: 1.9371991952260335

Epoch: 5| Step: 4
Training loss: 1.6108300685882568
Validation loss: 1.9369474053382874

Epoch: 5| Step: 5
Training loss: 0.9953006505966187
Validation loss: 1.9236997961997986

Epoch: 5| Step: 6
Training loss: 1.2798738479614258
Validation loss: 1.957884391148885

Epoch: 5| Step: 7
Training loss: 1.465022087097168
Validation loss: 1.9304812749226887

Epoch: 5| Step: 8
Training loss: 1.9868913888931274
Validation loss: 1.961843565106392

Epoch: 5| Step: 9
Training loss: 1.4498536586761475
Validation loss: 1.934895599881808

Epoch: 5| Step: 10
Training loss: 1.3828041553497314
Validation loss: 1.9332921504974365

Epoch: 5| Step: 11
Training loss: 0.8861657381057739
Validation loss: 1.9280884613593419

Epoch: 123| Step: 0
Training loss: 1.8647634983062744
Validation loss: 1.961193139354388

Epoch: 5| Step: 1
Training loss: 1.4369667768478394
Validation loss: 1.960758273800214

Epoch: 5| Step: 2
Training loss: 1.491713285446167
Validation loss: 1.9749466478824615

Epoch: 5| Step: 3
Training loss: 1.7934831380844116
Validation loss: 1.946836734811465

Epoch: 5| Step: 4
Training loss: 1.520477056503296
Validation loss: 1.9754491498072941

Epoch: 5| Step: 5
Training loss: 1.4695663452148438
Validation loss: 1.9292660405238469

Epoch: 5| Step: 6
Training loss: 1.06241774559021
Validation loss: 1.9237271149953206

Epoch: 5| Step: 7
Training loss: 1.1377886533737183
Validation loss: 1.9407700548569362

Epoch: 5| Step: 8
Training loss: 1.2946196794509888
Validation loss: 1.9442818065484364

Epoch: 5| Step: 9
Training loss: 1.4364354610443115
Validation loss: 1.943608025709788

Epoch: 5| Step: 10
Training loss: 1.1118803024291992
Validation loss: 1.9490870783726375

Epoch: 5| Step: 11
Training loss: 0.8826741576194763
Validation loss: 1.959474578499794

Epoch: 124| Step: 0
Training loss: 0.7382933497428894
Validation loss: 1.9495325138171513

Epoch: 5| Step: 1
Training loss: 1.4619390964508057
Validation loss: 1.9424080153306325

Epoch: 5| Step: 2
Training loss: 1.2586936950683594
Validation loss: 1.9544166674216588

Epoch: 5| Step: 3
Training loss: 1.4208998680114746
Validation loss: 1.9697554310162861

Epoch: 5| Step: 4
Training loss: 1.5984811782836914
Validation loss: 1.9881324768066406

Epoch: 5| Step: 5
Training loss: 1.538029432296753
Validation loss: 1.9994588941335678

Epoch: 5| Step: 6
Training loss: 1.4828917980194092
Validation loss: 1.9759400735298793

Epoch: 5| Step: 7
Training loss: 1.2009975910186768
Validation loss: 1.9480434010426204

Epoch: 5| Step: 8
Training loss: 1.5113462209701538
Validation loss: 1.9349217663208644

Epoch: 5| Step: 9
Training loss: 2.0198299884796143
Validation loss: 1.947232852379481

Epoch: 5| Step: 10
Training loss: 1.432305097579956
Validation loss: 1.9398158093293507

Epoch: 5| Step: 11
Training loss: 1.2416815757751465
Validation loss: 1.9204200357198715

Epoch: 125| Step: 0
Training loss: 1.562137246131897
Validation loss: 1.9173305382331212

Epoch: 5| Step: 1
Training loss: 1.4787800312042236
Validation loss: 1.9501876731713612

Epoch: 5| Step: 2
Training loss: 1.426218032836914
Validation loss: 1.9246369451284409

Epoch: 5| Step: 3
Training loss: 1.1126798391342163
Validation loss: 1.916393592953682

Epoch: 5| Step: 4
Training loss: 1.6506633758544922
Validation loss: 1.9280544072389603

Epoch: 5| Step: 5
Training loss: 1.377558708190918
Validation loss: 1.8946626136700313

Epoch: 5| Step: 6
Training loss: 1.56566321849823
Validation loss: 1.9323706676562626

Epoch: 5| Step: 7
Training loss: 1.6232757568359375
Validation loss: 1.8993397653102875

Epoch: 5| Step: 8
Training loss: 1.4430311918258667
Validation loss: 1.9459226181109746

Epoch: 5| Step: 9
Training loss: 1.3395130634307861
Validation loss: 1.9531309604644775

Epoch: 5| Step: 10
Training loss: 1.6178230047225952
Validation loss: 1.932734449704488

Epoch: 5| Step: 11
Training loss: 0.33286726474761963
Validation loss: 1.9614515453577042

Testing loss: 1.8564747348963786
