Epoch: 1| Step: 0
Training loss: 4.711549758911133
Validation loss: 5.071291605631511

Epoch: 6| Step: 1
Training loss: 4.726892471313477
Validation loss: 5.056171417236328

Epoch: 6| Step: 2
Training loss: 4.7098798751831055
Validation loss: 5.037305037180583

Epoch: 6| Step: 3
Training loss: 5.127791881561279
Validation loss: 5.020004192988078

Epoch: 6| Step: 4
Training loss: 4.28123664855957
Validation loss: 5.002516468365987

Epoch: 6| Step: 5
Training loss: 5.543375015258789
Validation loss: 4.986534396807353

Epoch: 6| Step: 6
Training loss: 6.007493019104004
Validation loss: 4.967363278071086

Epoch: 6| Step: 7
Training loss: 5.663120269775391
Validation loss: 4.9499930540720625

Epoch: 6| Step: 8
Training loss: 4.20367956161499
Validation loss: 4.929778575897217

Epoch: 6| Step: 9
Training loss: 4.80683708190918
Validation loss: 4.911184310913086

Epoch: 6| Step: 10
Training loss: 5.289665699005127
Validation loss: 4.894262234369914

Epoch: 6| Step: 11
Training loss: 4.998398780822754
Validation loss: 4.872450828552246

Epoch: 6| Step: 12
Training loss: 5.796233654022217
Validation loss: 4.856186230977376

Epoch: 6| Step: 13
Training loss: 4.570657730102539
Validation loss: 4.831963300704956

Epoch: 2| Step: 0
Training loss: 4.32230281829834
Validation loss: 4.812330722808838

Epoch: 6| Step: 1
Training loss: 5.094059944152832
Validation loss: 4.790718038876851

Epoch: 6| Step: 2
Training loss: 4.558307647705078
Validation loss: 4.768998463948567

Epoch: 6| Step: 3
Training loss: 5.2046613693237305
Validation loss: 4.745129744211833

Epoch: 6| Step: 4
Training loss: 4.130068778991699
Validation loss: 4.71944522857666

Epoch: 6| Step: 5
Training loss: 4.719790458679199
Validation loss: 4.696724017461141

Epoch: 6| Step: 6
Training loss: 4.177595615386963
Validation loss: 4.672916491826375

Epoch: 6| Step: 7
Training loss: 5.923460006713867
Validation loss: 4.6430792808532715

Epoch: 6| Step: 8
Training loss: 4.221738338470459
Validation loss: 4.613910516103108

Epoch: 6| Step: 9
Training loss: 5.935514450073242
Validation loss: 4.589224537213643

Epoch: 6| Step: 10
Training loss: 5.107478141784668
Validation loss: 4.557183345158895

Epoch: 6| Step: 11
Training loss: 3.373668909072876
Validation loss: 4.528850197792053

Epoch: 6| Step: 12
Training loss: 4.990645408630371
Validation loss: 4.491083900133769

Epoch: 6| Step: 13
Training loss: 4.59019136428833
Validation loss: 4.456424991289775

Epoch: 3| Step: 0
Training loss: 4.509812355041504
Validation loss: 4.4234468539555865

Epoch: 6| Step: 1
Training loss: 4.4749369621276855
Validation loss: 4.38439679145813

Epoch: 6| Step: 2
Training loss: 4.093299865722656
Validation loss: 4.3458781242370605

Epoch: 6| Step: 3
Training loss: 5.3084611892700195
Validation loss: 4.309716463088989

Epoch: 6| Step: 4
Training loss: 3.325856924057007
Validation loss: 4.263150135676066

Epoch: 6| Step: 5
Training loss: 4.025978088378906
Validation loss: 4.22474201520284

Epoch: 6| Step: 6
Training loss: 4.1468706130981445
Validation loss: 4.185853958129883

Epoch: 6| Step: 7
Training loss: 4.305073261260986
Validation loss: 4.135976076126099

Epoch: 6| Step: 8
Training loss: 4.223956108093262
Validation loss: 4.091347972551982

Epoch: 6| Step: 9
Training loss: 4.009421348571777
Validation loss: 4.044857978820801

Epoch: 6| Step: 10
Training loss: 4.5966291427612305
Validation loss: 3.988643209139506

Epoch: 6| Step: 11
Training loss: 4.038378715515137
Validation loss: 3.936065355936686

Epoch: 6| Step: 12
Training loss: 4.770035743713379
Validation loss: 3.875742276509603

Epoch: 6| Step: 13
Training loss: 3.5529136657714844
Validation loss: 3.818488597869873

Epoch: 4| Step: 0
Training loss: 4.271701812744141
Validation loss: 3.761093537012736

Epoch: 6| Step: 1
Training loss: 3.6202902793884277
Validation loss: 3.692378282546997

Epoch: 6| Step: 2
Training loss: 3.7673094272613525
Validation loss: 3.627067724863688

Epoch: 6| Step: 3
Training loss: 4.18450927734375
Validation loss: 3.555143117904663

Epoch: 6| Step: 4
Training loss: 3.578022003173828
Validation loss: 3.4835400183995566

Epoch: 6| Step: 5
Training loss: 3.799962282180786
Validation loss: 3.4087126652399697

Epoch: 6| Step: 6
Training loss: 2.6152291297912598
Validation loss: 3.34128201007843

Epoch: 6| Step: 7
Training loss: 3.283252000808716
Validation loss: 3.274003346761068

Epoch: 6| Step: 8
Training loss: 3.8696110248565674
Validation loss: 3.1836187839508057

Epoch: 6| Step: 9
Training loss: 2.779559850692749
Validation loss: 3.100357095400492

Epoch: 6| Step: 10
Training loss: 3.0829365253448486
Validation loss: 3.0223156611124673

Epoch: 6| Step: 11
Training loss: 2.7720234394073486
Validation loss: 2.939294934272766

Epoch: 6| Step: 12
Training loss: 2.3854551315307617
Validation loss: 2.8544053634007773

Epoch: 6| Step: 13
Training loss: 3.3654823303222656
Validation loss: 2.770526925722758

Epoch: 5| Step: 0
Training loss: 3.0330045223236084
Validation loss: 2.6945608059565225

Epoch: 6| Step: 1
Training loss: 2.826107978820801
Validation loss: 2.6135454177856445

Epoch: 6| Step: 2
Training loss: 2.9627833366394043
Validation loss: 2.525910417238871

Epoch: 6| Step: 3
Training loss: 2.9594857692718506
Validation loss: 2.443369150161743

Epoch: 6| Step: 4
Training loss: 2.048145055770874
Validation loss: 2.3524316549301147

Epoch: 6| Step: 5
Training loss: 1.939029335975647
Validation loss: 2.287145475546519

Epoch: 6| Step: 6
Training loss: 1.662621021270752
Validation loss: 2.213124712308248

Epoch: 6| Step: 7
Training loss: 1.9080923795700073
Validation loss: 2.196683704853058

Epoch: 6| Step: 8
Training loss: 2.444197654724121
Validation loss: 2.1357038021087646

Epoch: 6| Step: 9
Training loss: 1.5925636291503906
Validation loss: 2.121467431386312

Epoch: 6| Step: 10
Training loss: 2.2114205360412598
Validation loss: 2.120895743370056

Epoch: 6| Step: 11
Training loss: 2.3842248916625977
Validation loss: 2.1355400880177817

Epoch: 6| Step: 12
Training loss: 1.6066772937774658
Validation loss: 2.122079690297445

Epoch: 6| Step: 13
Training loss: 3.0099499225616455
Validation loss: 2.1515808701515198

Epoch: 6| Step: 0
Training loss: 2.1341776847839355
Validation loss: 2.1665300130844116

Epoch: 6| Step: 1
Training loss: 2.2829792499542236
Validation loss: 2.1764379143714905

Epoch: 6| Step: 2
Training loss: 2.272709846496582
Validation loss: 2.179889976978302

Epoch: 6| Step: 3
Training loss: 1.8171961307525635
Validation loss: 2.1729233860969543

Epoch: 6| Step: 4
Training loss: 1.657382845878601
Validation loss: 2.1933000683784485

Epoch: 6| Step: 5
Training loss: 1.7029743194580078
Validation loss: 2.1648961901664734

Epoch: 6| Step: 6
Training loss: 2.348830223083496
Validation loss: 2.1708589593569436

Epoch: 6| Step: 7
Training loss: 2.0287671089172363
Validation loss: 2.161586364110311

Epoch: 6| Step: 8
Training loss: 2.3493449687957764
Validation loss: 2.1061227321624756

Epoch: 6| Step: 9
Training loss: 1.8885207176208496
Validation loss: 2.1189653873443604

Epoch: 6| Step: 10
Training loss: 2.157843589782715
Validation loss: 2.1187350153923035

Epoch: 6| Step: 11
Training loss: 2.377575635910034
Validation loss: 2.1139186223347983

Epoch: 6| Step: 12
Training loss: 2.157315254211426
Validation loss: 2.09987606604894

Epoch: 6| Step: 13
Training loss: 2.2008771896362305
Validation loss: 2.1102763414382935

Epoch: 7| Step: 0
Training loss: 2.464716911315918
Validation loss: 2.1212318936983743

Epoch: 6| Step: 1
Training loss: 2.988590717315674
Validation loss: 2.139635602633158

Epoch: 6| Step: 2
Training loss: 1.7549444437026978
Validation loss: 2.1268025437990823

Epoch: 6| Step: 3
Training loss: 1.9217616319656372
Validation loss: 2.117640256881714

Epoch: 6| Step: 4
Training loss: 1.7938332557678223
Validation loss: 2.1494985818862915

Epoch: 6| Step: 5
Training loss: 1.6402159929275513
Validation loss: 2.1589131156603494

Epoch: 6| Step: 6
Training loss: 2.2320854663848877
Validation loss: 2.1558432976404824

Epoch: 6| Step: 7
Training loss: 2.551844835281372
Validation loss: 2.141479790210724

Epoch: 6| Step: 8
Training loss: 1.5063042640686035
Validation loss: 2.1404385566711426

Epoch: 6| Step: 9
Training loss: 2.3823304176330566
Validation loss: 2.151517907778422

Epoch: 6| Step: 10
Training loss: 1.4891078472137451
Validation loss: 2.1357369422912598

Epoch: 6| Step: 11
Training loss: 2.529025077819824
Validation loss: 2.111057003339132

Epoch: 6| Step: 12
Training loss: 2.247134208679199
Validation loss: 2.129903793334961

Epoch: 6| Step: 13
Training loss: 2.1353530883789062
Validation loss: 2.0953186750411987

Epoch: 8| Step: 0
Training loss: 3.1436047554016113
Validation loss: 2.1103718678156533

Epoch: 6| Step: 1
Training loss: 2.259394407272339
Validation loss: 2.116219937801361

Epoch: 6| Step: 2
Training loss: 1.844494342803955
Validation loss: 2.115423639615377

Epoch: 6| Step: 3
Training loss: 2.1767587661743164
Validation loss: 2.098726749420166

Epoch: 6| Step: 4
Training loss: 1.322805404663086
Validation loss: 2.1080076495806375

Epoch: 6| Step: 5
Training loss: 2.316033124923706
Validation loss: 2.1261643171310425

Epoch: 6| Step: 6
Training loss: 2.2495992183685303
Validation loss: 2.138237794240316

Epoch: 6| Step: 7
Training loss: 1.232399344444275
Validation loss: 2.1146501104036965

Epoch: 6| Step: 8
Training loss: 2.5566630363464355
Validation loss: 2.114422082901001

Epoch: 6| Step: 9
Training loss: 1.7175164222717285
Validation loss: 2.138457496960958

Epoch: 6| Step: 10
Training loss: 2.078967571258545
Validation loss: 2.113982299963633

Epoch: 6| Step: 11
Training loss: 2.0244030952453613
Validation loss: 2.118231256802877

Epoch: 6| Step: 12
Training loss: 2.198671340942383
Validation loss: 2.136757731437683

Epoch: 6| Step: 13
Training loss: 2.1941802501678467
Validation loss: 2.1007498105367026

Epoch: 9| Step: 0
Training loss: 1.680426836013794
Validation loss: 2.116002142429352

Epoch: 6| Step: 1
Training loss: 2.953037977218628
Validation loss: 2.107601841290792

Epoch: 6| Step: 2
Training loss: 2.0999608039855957
Validation loss: 2.0950191418329873

Epoch: 6| Step: 3
Training loss: 1.4391751289367676
Validation loss: 2.0970563491185508

Epoch: 6| Step: 4
Training loss: 2.7753138542175293
Validation loss: 2.1163276036580405

Epoch: 6| Step: 5
Training loss: 2.7188782691955566
Validation loss: 2.115347445011139

Epoch: 6| Step: 6
Training loss: 1.0146796703338623
Validation loss: 2.1146980921427407

Epoch: 6| Step: 7
Training loss: 2.0360355377197266
Validation loss: 2.1150970260302224

Epoch: 6| Step: 8
Training loss: 2.368863105773926
Validation loss: 2.1202489336331687

Epoch: 6| Step: 9
Training loss: 2.0019898414611816
Validation loss: 2.1193716724713645

Epoch: 6| Step: 10
Training loss: 1.916980504989624
Validation loss: 2.1231002807617188

Epoch: 6| Step: 11
Training loss: 2.62009859085083
Validation loss: 2.104192773501078

Epoch: 6| Step: 12
Training loss: 1.9866726398468018
Validation loss: 2.108638286590576

Epoch: 6| Step: 13
Training loss: 1.9377837181091309
Validation loss: 2.1044838428497314

Epoch: 10| Step: 0
Training loss: 1.9611648321151733
Validation loss: 2.10940013329188

Epoch: 6| Step: 1
Training loss: 2.3544249534606934
Validation loss: 2.10920649766922

Epoch: 6| Step: 2
Training loss: 1.8079960346221924
Validation loss: 2.107342700163523

Epoch: 6| Step: 3
Training loss: 1.7849631309509277
Validation loss: 2.0828341841697693

Epoch: 6| Step: 4
Training loss: 1.9238446950912476
Validation loss: 2.1008445620536804

Epoch: 6| Step: 5
Training loss: 1.8718931674957275
Validation loss: 2.1054351727167764

Epoch: 6| Step: 6
Training loss: 2.462045669555664
Validation loss: 2.117279887199402

Epoch: 6| Step: 7
Training loss: 1.4726945161819458
Validation loss: 2.1310291290283203

Epoch: 6| Step: 8
Training loss: 2.3087949752807617
Validation loss: 2.116776625315348

Epoch: 6| Step: 9
Training loss: 2.5251734256744385
Validation loss: 2.132608870665232

Epoch: 6| Step: 10
Training loss: 3.0232603549957275
Validation loss: 2.136858344078064

Epoch: 6| Step: 11
Training loss: 2.2623777389526367
Validation loss: 2.129466990629832

Epoch: 6| Step: 12
Training loss: 1.6174979209899902
Validation loss: 2.115703582763672

Epoch: 6| Step: 13
Training loss: 2.0694570541381836
Validation loss: 2.1010806361834207

Epoch: 11| Step: 0
Training loss: 2.2746095657348633
Validation loss: 2.1092568834622702

Epoch: 6| Step: 1
Training loss: 2.2634682655334473
Validation loss: 2.1015566984812417

Epoch: 6| Step: 2
Training loss: 1.9887293577194214
Validation loss: 2.1116319497426352

Epoch: 6| Step: 3
Training loss: 2.2509684562683105
Validation loss: 2.107295036315918

Epoch: 6| Step: 4
Training loss: 2.2003583908081055
Validation loss: 2.0850066343943277

Epoch: 6| Step: 5
Training loss: 2.37528657913208
Validation loss: 2.0817680756251016

Epoch: 6| Step: 6
Training loss: 2.0757172107696533
Validation loss: 2.1161311070124307

Epoch: 6| Step: 7
Training loss: 1.546116828918457
Validation loss: 2.09074338277181

Epoch: 6| Step: 8
Training loss: 2.0267138481140137
Validation loss: 2.0994608402252197

Epoch: 6| Step: 9
Training loss: 2.662565231323242
Validation loss: 2.0965086619059243

Epoch: 6| Step: 10
Training loss: 1.33455491065979
Validation loss: 2.0820783178011575

Epoch: 6| Step: 11
Training loss: 1.6830816268920898
Validation loss: 2.0980084339777627

Epoch: 6| Step: 12
Training loss: 1.884751558303833
Validation loss: 2.0928653677304587

Epoch: 6| Step: 13
Training loss: 2.461073875427246
Validation loss: 2.1129385828971863

Epoch: 12| Step: 0
Training loss: 2.5808651447296143
Validation loss: 2.1040313839912415

Epoch: 6| Step: 1
Training loss: 1.057870626449585
Validation loss: 2.1056127150853476

Epoch: 6| Step: 2
Training loss: 2.072718381881714
Validation loss: 2.062690317630768

Epoch: 6| Step: 3
Training loss: 1.4164607524871826
Validation loss: 2.092071076234182

Epoch: 6| Step: 4
Training loss: 2.5768346786499023
Validation loss: 2.0880072712898254

Epoch: 6| Step: 5
Training loss: 2.456092357635498
Validation loss: 2.075333754221598

Epoch: 6| Step: 6
Training loss: 1.996764063835144
Validation loss: 2.077826817830404

Epoch: 6| Step: 7
Training loss: 2.6292994022369385
Validation loss: 2.1243221759796143

Epoch: 6| Step: 8
Training loss: 1.5402113199234009
Validation loss: 2.1040194829305015

Epoch: 6| Step: 9
Training loss: 2.0043046474456787
Validation loss: 2.087630271911621

Epoch: 6| Step: 10
Training loss: 2.4799644947052
Validation loss: 2.1204870541890464

Epoch: 6| Step: 11
Training loss: 1.6029318571090698
Validation loss: 2.0989999175071716

Epoch: 6| Step: 12
Training loss: 2.809725284576416
Validation loss: 2.0877756079037986

Epoch: 6| Step: 13
Training loss: 1.5611246824264526
Validation loss: 2.100827217102051

Epoch: 13| Step: 0
Training loss: 1.6773532629013062
Validation loss: 2.1135607957839966

Epoch: 6| Step: 1
Training loss: 1.9786713123321533
Validation loss: 2.0943175156911216

Epoch: 6| Step: 2
Training loss: 1.8971593379974365
Validation loss: 2.090424060821533

Epoch: 6| Step: 3
Training loss: 1.9211615324020386
Validation loss: 2.1108941634496055

Epoch: 6| Step: 4
Training loss: 1.3036073446273804
Validation loss: 2.0909581184387207

Epoch: 6| Step: 5
Training loss: 2.281271457672119
Validation loss: 2.1050577958424888

Epoch: 6| Step: 6
Training loss: 1.9195728302001953
Validation loss: 2.080954154332479

Epoch: 6| Step: 7
Training loss: 2.1636314392089844
Validation loss: 2.0992340246836343

Epoch: 6| Step: 8
Training loss: 3.1988847255706787
Validation loss: 2.0990575154622397

Epoch: 6| Step: 9
Training loss: 2.2853844165802
Validation loss: 2.0753051241238913

Epoch: 6| Step: 10
Training loss: 1.9781153202056885
Validation loss: 2.1031713088353476

Epoch: 6| Step: 11
Training loss: 1.791219711303711
Validation loss: 2.089272598425547

Epoch: 6| Step: 12
Training loss: 1.6630427837371826
Validation loss: 2.0858190854390464

Epoch: 6| Step: 13
Training loss: 2.5219128131866455
Validation loss: 2.079976479212443

Epoch: 14| Step: 0
Training loss: 1.8606507778167725
Validation loss: 2.079574704170227

Epoch: 6| Step: 1
Training loss: 1.9603066444396973
Validation loss: 2.066734234491984

Epoch: 6| Step: 2
Training loss: 2.7373812198638916
Validation loss: 2.0822898546854653

Epoch: 6| Step: 3
Training loss: 2.1501803398132324
Validation loss: 2.0818081299463906

Epoch: 6| Step: 4
Training loss: 1.737227201461792
Validation loss: 2.0696125427881875

Epoch: 6| Step: 5
Training loss: 1.5605158805847168
Validation loss: 2.107727348804474

Epoch: 6| Step: 6
Training loss: 1.9883991479873657
Validation loss: 2.074249804019928

Epoch: 6| Step: 7
Training loss: 2.250004291534424
Validation loss: 2.0705462098121643

Epoch: 6| Step: 8
Training loss: 1.5738410949707031
Validation loss: 2.0817493200302124

Epoch: 6| Step: 9
Training loss: 2.0710787773132324
Validation loss: 2.0691133538881936

Epoch: 6| Step: 10
Training loss: 2.20389461517334
Validation loss: 2.0886926651000977

Epoch: 6| Step: 11
Training loss: 1.702455997467041
Validation loss: 2.072941323121389

Epoch: 6| Step: 12
Training loss: 2.3596174716949463
Validation loss: 2.071876347064972

Epoch: 6| Step: 13
Training loss: 2.3803367614746094
Validation loss: 2.0794360041618347

Epoch: 15| Step: 0
Training loss: 2.057300090789795
Validation loss: 2.06740931669871

Epoch: 6| Step: 1
Training loss: 2.5979514122009277
Validation loss: 2.0891877810160318

Epoch: 6| Step: 2
Training loss: 2.1248788833618164
Validation loss: 2.0524741808573403

Epoch: 6| Step: 3
Training loss: 2.4237799644470215
Validation loss: 2.0713269114494324

Epoch: 6| Step: 4
Training loss: 2.6679134368896484
Validation loss: 2.059965888659159

Epoch: 6| Step: 5
Training loss: 2.1353793144226074
Validation loss: 2.097075641155243

Epoch: 6| Step: 6
Training loss: 1.9983456134796143
Validation loss: 2.0678179264068604

Epoch: 6| Step: 7
Training loss: 1.7901188135147095
Validation loss: 2.0930027763048806

Epoch: 6| Step: 8
Training loss: 2.0865724086761475
Validation loss: 2.0748020013173423

Epoch: 6| Step: 9
Training loss: 2.2097370624542236
Validation loss: 2.070580621560415

Epoch: 6| Step: 10
Training loss: 1.4702486991882324
Validation loss: 2.1116899053255715

Epoch: 6| Step: 11
Training loss: 1.4330687522888184
Validation loss: 2.0889653166135154

Epoch: 6| Step: 12
Training loss: 1.5097196102142334
Validation loss: 2.1082761685053506

Epoch: 6| Step: 13
Training loss: 2.2222421169281006
Validation loss: 2.088196257750193

Epoch: 16| Step: 0
Training loss: 1.6580066680908203
Validation loss: 2.0920239289601645

Epoch: 6| Step: 1
Training loss: 2.337198495864868
Validation loss: 2.0639521876970925

Epoch: 6| Step: 2
Training loss: 2.0072858333587646
Validation loss: 2.0763285954793296

Epoch: 6| Step: 3
Training loss: 2.465160369873047
Validation loss: 2.090938448905945

Epoch: 6| Step: 4
Training loss: 2.360598564147949
Validation loss: 2.0760775804519653

Epoch: 6| Step: 5
Training loss: 1.603863000869751
Validation loss: 2.0849661429723105

Epoch: 6| Step: 6
Training loss: 1.5794708728790283
Validation loss: 2.07806259393692

Epoch: 6| Step: 7
Training loss: 1.5995941162109375
Validation loss: 2.072490870952606

Epoch: 6| Step: 8
Training loss: 1.7589367628097534
Validation loss: 2.092434823513031

Epoch: 6| Step: 9
Training loss: 1.6795746088027954
Validation loss: 2.068118393421173

Epoch: 6| Step: 10
Training loss: 2.4520626068115234
Validation loss: 2.072036842505137

Epoch: 6| Step: 11
Training loss: 1.7714459896087646
Validation loss: 2.1094011068344116

Epoch: 6| Step: 12
Training loss: 2.4860715866088867
Validation loss: 2.0970247785250344

Epoch: 6| Step: 13
Training loss: 2.6368393898010254
Validation loss: 2.089373528957367

Epoch: 17| Step: 0
Training loss: 1.4766342639923096
Validation loss: 2.0917378266652427

Epoch: 6| Step: 1
Training loss: 2.2895731925964355
Validation loss: 2.07515017191569

Epoch: 6| Step: 2
Training loss: 2.079453706741333
Validation loss: 2.066303034623464

Epoch: 6| Step: 3
Training loss: 1.8708866834640503
Validation loss: 2.0813503861427307

Epoch: 6| Step: 4
Training loss: 2.3665897846221924
Validation loss: 2.075078308582306

Epoch: 6| Step: 5
Training loss: 1.5691635608673096
Validation loss: 2.0690693060557046

Epoch: 6| Step: 6
Training loss: 2.267038345336914
Validation loss: 2.0855679710706077

Epoch: 6| Step: 7
Training loss: 1.6195886135101318
Validation loss: 2.0791518290837607

Epoch: 6| Step: 8
Training loss: 2.06276798248291
Validation loss: 2.0622827808062234

Epoch: 6| Step: 9
Training loss: 2.068634033203125
Validation loss: 2.0646718541781106

Epoch: 6| Step: 10
Training loss: 1.793416142463684
Validation loss: 2.0565361777941384

Epoch: 6| Step: 11
Training loss: 2.0669538974761963
Validation loss: 2.0731557806332908

Epoch: 6| Step: 12
Training loss: 2.906090259552002
Validation loss: 2.078537702560425

Epoch: 6| Step: 13
Training loss: 1.9616944789886475
Validation loss: 2.0631607373555503

Epoch: 18| Step: 0
Training loss: 2.7161176204681396
Validation loss: 2.0991352796554565

Epoch: 6| Step: 1
Training loss: 1.435025930404663
Validation loss: 2.064066926638285

Epoch: 6| Step: 2
Training loss: 1.8949223756790161
Validation loss: 2.0594602823257446

Epoch: 6| Step: 3
Training loss: 2.159289836883545
Validation loss: 2.066124975681305

Epoch: 6| Step: 4
Training loss: 2.8148655891418457
Validation loss: 2.0796972115834556

Epoch: 6| Step: 5
Training loss: 2.561924695968628
Validation loss: 2.063719471295675

Epoch: 6| Step: 6
Training loss: 1.8791813850402832
Validation loss: 2.080577333768209

Epoch: 6| Step: 7
Training loss: 1.7115986347198486
Validation loss: 2.0657737851142883

Epoch: 6| Step: 8
Training loss: 2.28635835647583
Validation loss: 2.0559439857800803

Epoch: 6| Step: 9
Training loss: 1.4637553691864014
Validation loss: 2.0688188473383584

Epoch: 6| Step: 10
Training loss: 1.7962214946746826
Validation loss: 2.0502354303995767

Epoch: 6| Step: 11
Training loss: 1.5716407299041748
Validation loss: 2.072082221508026

Epoch: 6| Step: 12
Training loss: 2.259580135345459
Validation loss: 2.062822719415029

Epoch: 6| Step: 13
Training loss: 1.8397899866104126
Validation loss: 2.066749850908915

Epoch: 19| Step: 0
Training loss: 2.280794620513916
Validation loss: 2.0712653597195945

Epoch: 6| Step: 1
Training loss: 1.8981592655181885
Validation loss: 2.06705774863561

Epoch: 6| Step: 2
Training loss: 2.0006227493286133
Validation loss: 2.0739494959513345

Epoch: 6| Step: 3
Training loss: 1.9667636156082153
Validation loss: 2.075109124183655

Epoch: 6| Step: 4
Training loss: 1.4359313249588013
Validation loss: 2.0625665386517844

Epoch: 6| Step: 5
Training loss: 2.0070533752441406
Validation loss: 2.055051545302073

Epoch: 6| Step: 6
Training loss: 2.1039693355560303
Validation loss: 2.0620890458424888

Epoch: 6| Step: 7
Training loss: 2.0143041610717773
Validation loss: 2.0680432319641113

Epoch: 6| Step: 8
Training loss: 1.8505502939224243
Validation loss: 2.077781081199646

Epoch: 6| Step: 9
Training loss: 2.683840751647949
Validation loss: 2.0658793846766152

Epoch: 6| Step: 10
Training loss: 2.7720298767089844
Validation loss: 2.081408679485321

Epoch: 6| Step: 11
Training loss: 2.260683298110962
Validation loss: 2.0477816462516785

Epoch: 6| Step: 12
Training loss: 1.4967131614685059
Validation loss: 2.064489483833313

Epoch: 6| Step: 13
Training loss: 1.6515096426010132
Validation loss: 2.061430255572001

Epoch: 20| Step: 0
Training loss: 2.2324166297912598
Validation loss: 2.0582722822825112

Epoch: 6| Step: 1
Training loss: 1.8226268291473389
Validation loss: 2.0654839873313904

Epoch: 6| Step: 2
Training loss: 2.03975772857666
Validation loss: 2.0804771383603415

Epoch: 6| Step: 3
Training loss: 2.030625820159912
Validation loss: 2.0614442030588784

Epoch: 6| Step: 4
Training loss: 2.2519078254699707
Validation loss: 2.0835030674934387

Epoch: 6| Step: 5
Training loss: 1.8778626918792725
Validation loss: 2.0769233107566833

Epoch: 6| Step: 6
Training loss: 1.801552176475525
Validation loss: 2.0681200424830117

Epoch: 6| Step: 7
Training loss: 2.0716264247894287
Validation loss: 2.084388176600138

Epoch: 6| Step: 8
Training loss: 2.01303768157959
Validation loss: 2.0643496910730996

Epoch: 6| Step: 9
Training loss: 2.576061248779297
Validation loss: 2.0776396989822388

Epoch: 6| Step: 10
Training loss: 1.8778539896011353
Validation loss: 2.0602166255315146

Epoch: 6| Step: 11
Training loss: 1.401962399482727
Validation loss: 2.0934231281280518

Epoch: 6| Step: 12
Training loss: 2.107654571533203
Validation loss: 2.079315265019735

Epoch: 6| Step: 13
Training loss: 2.234750747680664
Validation loss: 2.078537086645762

Epoch: 21| Step: 0
Training loss: 2.1194393634796143
Validation loss: 2.0661598841349282

Epoch: 6| Step: 1
Training loss: 2.23822283744812
Validation loss: 2.0466273625691733

Epoch: 6| Step: 2
Training loss: 1.7001051902770996
Validation loss: 2.0633251468340554

Epoch: 6| Step: 3
Training loss: 2.0359601974487305
Validation loss: 2.070545474688212

Epoch: 6| Step: 4
Training loss: 2.7586748600006104
Validation loss: 2.053093194961548

Epoch: 6| Step: 5
Training loss: 1.970078468322754
Validation loss: 2.06603612502416

Epoch: 6| Step: 6
Training loss: 1.3811362981796265
Validation loss: 2.069051444530487

Epoch: 6| Step: 7
Training loss: 0.6679562926292419
Validation loss: 2.0640979210535684

Epoch: 6| Step: 8
Training loss: 2.6051342487335205
Validation loss: 2.0541772643725076

Epoch: 6| Step: 9
Training loss: 1.8880633115768433
Validation loss: 2.072482784589132

Epoch: 6| Step: 10
Training loss: 1.9332029819488525
Validation loss: 2.0983437299728394

Epoch: 6| Step: 11
Training loss: 2.357126474380493
Validation loss: 2.0920209487279258

Epoch: 6| Step: 12
Training loss: 2.3811213970184326
Validation loss: 2.0786146918932595

Epoch: 6| Step: 13
Training loss: 2.3870432376861572
Validation loss: 2.0598695278167725

Epoch: 22| Step: 0
Training loss: 1.826629400253296
Validation loss: 2.0756854017575583

Epoch: 6| Step: 1
Training loss: 2.179741859436035
Validation loss: 2.0796631971995034

Epoch: 6| Step: 2
Training loss: 2.295301675796509
Validation loss: 2.0571046074231467

Epoch: 6| Step: 3
Training loss: 0.8230587840080261
Validation loss: 2.044247567653656

Epoch: 6| Step: 4
Training loss: 1.9528090953826904
Validation loss: 2.063482423623403

Epoch: 6| Step: 5
Training loss: 2.3133797645568848
Validation loss: 2.0456327001253762

Epoch: 6| Step: 6
Training loss: 1.990983247756958
Validation loss: 2.082008341948191

Epoch: 6| Step: 7
Training loss: 1.9060215950012207
Validation loss: 2.0675324400266013

Epoch: 6| Step: 8
Training loss: 2.1518256664276123
Validation loss: 2.047288199265798

Epoch: 6| Step: 9
Training loss: 2.2410974502563477
Validation loss: 2.073289692401886

Epoch: 6| Step: 10
Training loss: 2.324517250061035
Validation loss: 2.0401216745376587

Epoch: 6| Step: 11
Training loss: 1.9152170419692993
Validation loss: 2.060825606187185

Epoch: 6| Step: 12
Training loss: 2.1815173625946045
Validation loss: 2.0490485032399497

Epoch: 6| Step: 13
Training loss: 2.105517625808716
Validation loss: 2.0408809185028076

Epoch: 23| Step: 0
Training loss: 1.8505501747131348
Validation loss: 2.057052214940389

Epoch: 6| Step: 1
Training loss: 2.0114171504974365
Validation loss: 2.0680617888768515

Epoch: 6| Step: 2
Training loss: 1.5657891035079956
Validation loss: 2.059793750445048

Epoch: 6| Step: 3
Training loss: 1.291817307472229
Validation loss: 2.0470662117004395

Epoch: 6| Step: 4
Training loss: 1.7721482515335083
Validation loss: 2.063466807206472

Epoch: 6| Step: 5
Training loss: 1.9322904348373413
Validation loss: 2.0632940332094827

Epoch: 6| Step: 6
Training loss: 1.6256407499313354
Validation loss: 2.0608444015185037

Epoch: 6| Step: 7
Training loss: 2.3550758361816406
Validation loss: 2.057884454727173

Epoch: 6| Step: 8
Training loss: 1.9257895946502686
Validation loss: 2.0714781880378723

Epoch: 6| Step: 9
Training loss: 2.6364798545837402
Validation loss: 2.0771934390068054

Epoch: 6| Step: 10
Training loss: 2.325791835784912
Validation loss: 2.057934602101644

Epoch: 6| Step: 11
Training loss: 2.1243298053741455
Validation loss: 2.0680021246274314

Epoch: 6| Step: 12
Training loss: 2.6270570755004883
Validation loss: 2.062620222568512

Epoch: 6| Step: 13
Training loss: 2.0100488662719727
Validation loss: 2.0473657051722207

Epoch: 24| Step: 0
Training loss: 2.218062400817871
Validation loss: 2.0536270141601562

Epoch: 6| Step: 1
Training loss: 2.1907129287719727
Validation loss: 2.0548777182896933

Epoch: 6| Step: 2
Training loss: 1.2008259296417236
Validation loss: 2.056897521018982

Epoch: 6| Step: 3
Training loss: 1.898331642150879
Validation loss: 2.037957012653351

Epoch: 6| Step: 4
Training loss: 2.1132962703704834
Validation loss: 2.071058710416158

Epoch: 6| Step: 5
Training loss: 2.226931095123291
Validation loss: 2.0537123878796897

Epoch: 6| Step: 6
Training loss: 2.69700288772583
Validation loss: 2.0705401500066123

Epoch: 6| Step: 7
Training loss: 1.8148267269134521
Validation loss: 2.048643946647644

Epoch: 6| Step: 8
Training loss: 1.8738332986831665
Validation loss: 2.0654835601647696

Epoch: 6| Step: 9
Training loss: 2.025890350341797
Validation loss: 2.078241010506948

Epoch: 6| Step: 10
Training loss: 1.7871453762054443
Validation loss: 2.0431523521741233

Epoch: 6| Step: 11
Training loss: 1.8702905178070068
Validation loss: 2.0526662270228067

Epoch: 6| Step: 12
Training loss: 2.3301234245300293
Validation loss: 2.0516782999038696

Epoch: 6| Step: 13
Training loss: 2.122591733932495
Validation loss: 2.049435873826345

Epoch: 25| Step: 0
Training loss: 2.1111955642700195
Validation loss: 2.053903877735138

Epoch: 6| Step: 1
Training loss: 2.296358585357666
Validation loss: 2.051028629144033

Epoch: 6| Step: 2
Training loss: 2.3611912727355957
Validation loss: 2.0736012856165567

Epoch: 6| Step: 3
Training loss: 2.4678196907043457
Validation loss: 2.061182379722595

Epoch: 6| Step: 4
Training loss: 1.7622511386871338
Validation loss: 2.0582344134648642

Epoch: 6| Step: 5
Training loss: 2.3167476654052734
Validation loss: 2.052962064743042

Epoch: 6| Step: 6
Training loss: 2.069838523864746
Validation loss: 2.0597484509150186

Epoch: 6| Step: 7
Training loss: 1.8338552713394165
Validation loss: 2.056687116622925

Epoch: 6| Step: 8
Training loss: 2.7954461574554443
Validation loss: 2.0710158348083496

Epoch: 6| Step: 9
Training loss: 1.9494658708572388
Validation loss: 2.0773245692253113

Epoch: 6| Step: 10
Training loss: 1.7284488677978516
Validation loss: 2.0585617621739707

Epoch: 6| Step: 11
Training loss: 1.3152008056640625
Validation loss: 2.068645397822062

Epoch: 6| Step: 12
Training loss: 1.80149245262146
Validation loss: 2.0582292874654136

Epoch: 6| Step: 13
Training loss: 1.295764446258545
Validation loss: 2.06564470132192

Epoch: 26| Step: 0
Training loss: 1.914358139038086
Validation loss: 2.06229704618454

Epoch: 6| Step: 1
Training loss: 2.2634189128875732
Validation loss: 2.052448332309723

Epoch: 6| Step: 2
Training loss: 2.812145471572876
Validation loss: 2.0502930283546448

Epoch: 6| Step: 3
Training loss: 1.2229549884796143
Validation loss: 2.0478026270866394

Epoch: 6| Step: 4
Training loss: 1.9538354873657227
Validation loss: 2.0613582531611123

Epoch: 6| Step: 5
Training loss: 2.2930636405944824
Validation loss: 2.0684176882108054

Epoch: 6| Step: 6
Training loss: 2.223947048187256
Validation loss: 2.0854211250940957

Epoch: 6| Step: 7
Training loss: 1.883183240890503
Validation loss: 2.068167487780253

Epoch: 6| Step: 8
Training loss: 1.6921110153198242
Validation loss: 2.087083021799723

Epoch: 6| Step: 9
Training loss: 2.0287036895751953
Validation loss: 2.058898945649465

Epoch: 6| Step: 10
Training loss: 1.9585700035095215
Validation loss: 2.053716242313385

Epoch: 6| Step: 11
Training loss: 2.2665748596191406
Validation loss: 2.049697975317637

Epoch: 6| Step: 12
Training loss: 1.883784532546997
Validation loss: 2.056217610836029

Epoch: 6| Step: 13
Training loss: 1.6477025747299194
Validation loss: 2.0521244406700134

Epoch: 27| Step: 0
Training loss: 1.5221091508865356
Validation loss: 2.04539825518926

Epoch: 6| Step: 1
Training loss: 2.0988574028015137
Validation loss: 2.061483899752299

Epoch: 6| Step: 2
Training loss: 2.3571712970733643
Validation loss: 2.0533472498257956

Epoch: 6| Step: 3
Training loss: 1.7830106019973755
Validation loss: 2.055721859137217

Epoch: 6| Step: 4
Training loss: 2.14381742477417
Validation loss: 2.06699667374293

Epoch: 6| Step: 5
Training loss: 2.2210984230041504
Validation loss: 2.0569045543670654

Epoch: 6| Step: 6
Training loss: 2.112135410308838
Validation loss: 2.0459110935529075

Epoch: 6| Step: 7
Training loss: 2.0210704803466797
Validation loss: 2.0534538427988687

Epoch: 6| Step: 8
Training loss: 1.430647850036621
Validation loss: 2.0551602045694985

Epoch: 6| Step: 9
Training loss: 1.2849692106246948
Validation loss: 2.0636473099390664

Epoch: 6| Step: 10
Training loss: 1.4592217206954956
Validation loss: 2.057416836420695

Epoch: 6| Step: 11
Training loss: 2.2687759399414062
Validation loss: 2.0479506055514016

Epoch: 6| Step: 12
Training loss: 2.5031981468200684
Validation loss: 2.059927304585775

Epoch: 6| Step: 13
Training loss: 2.7157602310180664
Validation loss: 2.0536840558052063

Epoch: 28| Step: 0
Training loss: 1.400689721107483
Validation loss: 2.0653945207595825

Epoch: 6| Step: 1
Training loss: 1.8530572652816772
Validation loss: 2.040960907936096

Epoch: 6| Step: 2
Training loss: 2.1266911029815674
Validation loss: 2.0505576133728027

Epoch: 6| Step: 3
Training loss: 1.6470098495483398
Validation loss: 2.055956482887268

Epoch: 6| Step: 4
Training loss: 1.6759123802185059
Validation loss: 2.045351187388102

Epoch: 6| Step: 5
Training loss: 2.0805370807647705
Validation loss: 2.055532375971476

Epoch: 6| Step: 6
Training loss: 2.208949089050293
Validation loss: 2.0507288575172424

Epoch: 6| Step: 7
Training loss: 2.1647982597351074
Validation loss: 2.0548751751581826

Epoch: 6| Step: 8
Training loss: 2.5960981845855713
Validation loss: 2.065602123737335

Epoch: 6| Step: 9
Training loss: 2.219831943511963
Validation loss: 2.073239187399546

Epoch: 6| Step: 10
Training loss: 2.1750640869140625
Validation loss: 2.0495733420054116

Epoch: 6| Step: 11
Training loss: 1.5432018041610718
Validation loss: 2.0690625508626304

Epoch: 6| Step: 12
Training loss: 1.6615886688232422
Validation loss: 2.0506972471872964

Epoch: 6| Step: 13
Training loss: 2.7598989009857178
Validation loss: 2.0537795225779214

Epoch: 29| Step: 0
Training loss: 3.3197989463806152
Validation loss: 2.045602043469747

Epoch: 6| Step: 1
Training loss: 2.438811779022217
Validation loss: 2.0545111497243247

Epoch: 6| Step: 2
Training loss: 1.565317153930664
Validation loss: 2.061752676963806

Epoch: 6| Step: 3
Training loss: 2.091175079345703
Validation loss: 2.051758627096812

Epoch: 6| Step: 4
Training loss: 1.4878652095794678
Validation loss: 2.0631488958994546

Epoch: 6| Step: 5
Training loss: 2.0552797317504883
Validation loss: 2.0600686073303223

Epoch: 6| Step: 6
Training loss: 1.448551893234253
Validation loss: 2.0514127214749656

Epoch: 6| Step: 7
Training loss: 2.025820255279541
Validation loss: 2.051392833391825

Epoch: 6| Step: 8
Training loss: 2.1276438236236572
Validation loss: 2.0450013677279153

Epoch: 6| Step: 9
Training loss: 2.083932399749756
Validation loss: 2.059424897034963

Epoch: 6| Step: 10
Training loss: 1.6972286701202393
Validation loss: 2.0602049032847085

Epoch: 6| Step: 11
Training loss: 2.515918731689453
Validation loss: 2.032083749771118

Epoch: 6| Step: 12
Training loss: 1.9287399053573608
Validation loss: 2.060351630051931

Epoch: 6| Step: 13
Training loss: 1.2689265012741089
Validation loss: 2.059250593185425

Epoch: 30| Step: 0
Training loss: 2.271644353866577
Validation loss: 2.0410163402557373

Epoch: 6| Step: 1
Training loss: 1.7013263702392578
Validation loss: 2.0488028128941855

Epoch: 6| Step: 2
Training loss: 1.9934160709381104
Validation loss: 2.0581648548444114

Epoch: 6| Step: 3
Training loss: 1.5996294021606445
Validation loss: 2.045515855153402

Epoch: 6| Step: 4
Training loss: 2.1467766761779785
Validation loss: 2.060290356477102

Epoch: 6| Step: 5
Training loss: 2.6295199394226074
Validation loss: 2.0699551900227866

Epoch: 6| Step: 6
Training loss: 1.8068022727966309
Validation loss: 2.0462183753649392

Epoch: 6| Step: 7
Training loss: 1.841965913772583
Validation loss: 2.0501821041107178

Epoch: 6| Step: 8
Training loss: 2.2747435569763184
Validation loss: 2.075466295083364

Epoch: 6| Step: 9
Training loss: 1.9775927066802979
Validation loss: 2.0350486238797507

Epoch: 6| Step: 10
Training loss: 1.369733214378357
Validation loss: 2.0434778928756714

Epoch: 6| Step: 11
Training loss: 2.1271092891693115
Validation loss: 2.0516037940979004

Epoch: 6| Step: 12
Training loss: 2.400938034057617
Validation loss: 2.0568708777427673

Epoch: 6| Step: 13
Training loss: 1.9235831499099731
Validation loss: 2.064330220222473

Epoch: 31| Step: 0
Training loss: 2.206838846206665
Validation loss: 2.047341525554657

Epoch: 6| Step: 1
Training loss: 2.2348287105560303
Validation loss: 2.0671734611193338

Epoch: 6| Step: 2
Training loss: 2.190121650695801
Validation loss: 2.0644619266192117

Epoch: 6| Step: 3
Training loss: 2.2926173210144043
Validation loss: 2.073285241921743

Epoch: 6| Step: 4
Training loss: 1.8879327774047852
Validation loss: 2.066399335861206

Epoch: 6| Step: 5
Training loss: 1.3995271921157837
Validation loss: 2.0730239152908325

Epoch: 6| Step: 6
Training loss: 2.1092689037323
Validation loss: 2.0714951356252036

Epoch: 6| Step: 7
Training loss: 1.5894317626953125
Validation loss: 2.048156718413035

Epoch: 6| Step: 8
Training loss: 1.4318530559539795
Validation loss: 2.0636185805002847

Epoch: 6| Step: 9
Training loss: 2.518204689025879
Validation loss: 2.066593050956726

Epoch: 6| Step: 10
Training loss: 1.615923285484314
Validation loss: 2.072999139626821

Epoch: 6| Step: 11
Training loss: 1.9649665355682373
Validation loss: 2.055485169092814

Epoch: 6| Step: 12
Training loss: 1.9906291961669922
Validation loss: 2.0530314445495605

Epoch: 6| Step: 13
Training loss: 2.419424057006836
Validation loss: 2.055294712384542

Epoch: 32| Step: 0
Training loss: 1.861364722251892
Validation loss: 2.072443962097168

Epoch: 6| Step: 1
Training loss: 1.793763518333435
Validation loss: 2.043682813644409

Epoch: 6| Step: 2
Training loss: 2.307264804840088
Validation loss: 2.061210791269938

Epoch: 6| Step: 3
Training loss: 1.705689787864685
Validation loss: 2.056115130583445

Epoch: 6| Step: 4
Training loss: 2.238426446914673
Validation loss: 2.057607193787893

Epoch: 6| Step: 5
Training loss: 2.0885379314422607
Validation loss: 2.0624390840530396

Epoch: 6| Step: 6
Training loss: 2.553333044052124
Validation loss: 2.0483503937721252

Epoch: 6| Step: 7
Training loss: 2.1851272583007812
Validation loss: 2.069159209728241

Epoch: 6| Step: 8
Training loss: 2.201503276824951
Validation loss: 2.0288801789283752

Epoch: 6| Step: 9
Training loss: 2.0162625312805176
Validation loss: 2.0585163633028665

Epoch: 6| Step: 10
Training loss: 1.6275086402893066
Validation loss: 2.0491442680358887

Epoch: 6| Step: 11
Training loss: 1.9079482555389404
Validation loss: 2.0301222602526345

Epoch: 6| Step: 12
Training loss: 1.3520864248275757
Validation loss: 2.058729410171509

Epoch: 6| Step: 13
Training loss: 2.116476058959961
Validation loss: 2.04077140490214

Epoch: 33| Step: 0
Training loss: 2.1230788230895996
Validation loss: 2.0485984881718955

Epoch: 6| Step: 1
Training loss: 2.509631633758545
Validation loss: 2.0172536770502725

Epoch: 6| Step: 2
Training loss: 1.9792147874832153
Validation loss: 2.0418840448061624

Epoch: 6| Step: 3
Training loss: 1.658792495727539
Validation loss: 2.066840390364329

Epoch: 6| Step: 4
Training loss: 1.5036269426345825
Validation loss: 2.0565884510676065

Epoch: 6| Step: 5
Training loss: 1.7170960903167725
Validation loss: 2.0757805705070496

Epoch: 6| Step: 6
Training loss: 2.468021869659424
Validation loss: 2.050844430923462

Epoch: 6| Step: 7
Training loss: 1.595785140991211
Validation loss: 2.03768382469813

Epoch: 6| Step: 8
Training loss: 2.373380661010742
Validation loss: 2.0722694396972656

Epoch: 6| Step: 9
Training loss: 2.277858257293701
Validation loss: 2.0721746484438577

Epoch: 6| Step: 10
Training loss: 1.9402003288269043
Validation loss: 2.065403242905935

Epoch: 6| Step: 11
Training loss: 1.8339020013809204
Validation loss: 2.05141681432724

Epoch: 6| Step: 12
Training loss: 2.1085822582244873
Validation loss: 2.065614918867747

Epoch: 6| Step: 13
Training loss: 1.9154725074768066
Validation loss: 2.035122354825338

Epoch: 34| Step: 0
Training loss: 2.3150081634521484
Validation loss: 2.0434264143308005

Epoch: 6| Step: 1
Training loss: 2.0584378242492676
Validation loss: 2.059679647286733

Epoch: 6| Step: 2
Training loss: 2.1484665870666504
Validation loss: 2.054491857687632

Epoch: 6| Step: 3
Training loss: 2.0173492431640625
Validation loss: 2.02286696434021

Epoch: 6| Step: 4
Training loss: 2.0498335361480713
Validation loss: 2.0552785793940225

Epoch: 6| Step: 5
Training loss: 1.795492172241211
Validation loss: 2.051301419734955

Epoch: 6| Step: 6
Training loss: 1.7954986095428467
Validation loss: 2.0297443668047586

Epoch: 6| Step: 7
Training loss: 1.9583461284637451
Validation loss: 2.048722187678019

Epoch: 6| Step: 8
Training loss: 1.8711875677108765
Validation loss: 2.03753791252772

Epoch: 6| Step: 9
Training loss: 1.5483757257461548
Validation loss: 2.029924988746643

Epoch: 6| Step: 10
Training loss: 2.148557186126709
Validation loss: 2.0506288210550943

Epoch: 6| Step: 11
Training loss: 1.8498554229736328
Validation loss: 2.0495888590812683

Epoch: 6| Step: 12
Training loss: 2.093439817428589
Validation loss: 2.042370597521464

Epoch: 6| Step: 13
Training loss: 2.219135284423828
Validation loss: 2.049150764942169

Epoch: 35| Step: 0
Training loss: 1.6226470470428467
Validation loss: 2.0472482641537986

Epoch: 6| Step: 1
Training loss: 2.245790958404541
Validation loss: 2.057059327761332

Epoch: 6| Step: 2
Training loss: 2.1120762825012207
Validation loss: 2.0604042609532676

Epoch: 6| Step: 3
Training loss: 2.4453444480895996
Validation loss: 2.045206665992737

Epoch: 6| Step: 4
Training loss: 1.7422256469726562
Validation loss: 2.060449997584025

Epoch: 6| Step: 5
Training loss: 1.709409236907959
Validation loss: 2.081048607826233

Epoch: 6| Step: 6
Training loss: 2.4967398643493652
Validation loss: 2.090839207172394

Epoch: 6| Step: 7
Training loss: 2.247685194015503
Validation loss: 2.0863542954126992

Epoch: 6| Step: 8
Training loss: 2.707611083984375
Validation loss: 2.0676196416219077

Epoch: 6| Step: 9
Training loss: 1.5750712156295776
Validation loss: 2.063386082649231

Epoch: 6| Step: 10
Training loss: 1.1193037033081055
Validation loss: 2.076134959856669

Epoch: 6| Step: 11
Training loss: 2.070899486541748
Validation loss: 2.0658679405848184

Epoch: 6| Step: 12
Training loss: 2.010296106338501
Validation loss: 2.0490475495656333

Epoch: 6| Step: 13
Training loss: 2.129692316055298
Validation loss: 2.0408932169278464

Epoch: 36| Step: 0
Training loss: 1.96456778049469
Validation loss: 2.060021718343099

Epoch: 6| Step: 1
Training loss: 1.8979337215423584
Validation loss: 2.0308395822842917

Epoch: 6| Step: 2
Training loss: 1.3245266675949097
Validation loss: 2.0409027536710105

Epoch: 6| Step: 3
Training loss: 1.824191689491272
Validation loss: 2.043916424115499

Epoch: 6| Step: 4
Training loss: 2.6556386947631836
Validation loss: 2.065638283888499

Epoch: 6| Step: 5
Training loss: 1.848090410232544
Validation loss: 2.031357785065969

Epoch: 6| Step: 6
Training loss: 1.6383998394012451
Validation loss: 2.023253639539083

Epoch: 6| Step: 7
Training loss: 1.8672183752059937
Validation loss: 2.0650850733121238

Epoch: 6| Step: 8
Training loss: 2.0993833541870117
Validation loss: 2.04488205909729

Epoch: 6| Step: 9
Training loss: 2.7043731212615967
Validation loss: 2.0457843542099

Epoch: 6| Step: 10
Training loss: 1.6943875551223755
Validation loss: 2.046085000038147

Epoch: 6| Step: 11
Training loss: 1.8386964797973633
Validation loss: 2.037762184937795

Epoch: 6| Step: 12
Training loss: 2.3015034198760986
Validation loss: 2.052738924821218

Epoch: 6| Step: 13
Training loss: 1.963111162185669
Validation loss: 2.03409336010615

Epoch: 37| Step: 0
Training loss: 1.8790473937988281
Validation loss: 2.0658647418022156

Epoch: 6| Step: 1
Training loss: 1.8067322969436646
Validation loss: 2.058658500512441

Epoch: 6| Step: 2
Training loss: 2.329615831375122
Validation loss: 2.037689983844757

Epoch: 6| Step: 3
Training loss: 1.798102617263794
Validation loss: 2.027179002761841

Epoch: 6| Step: 4
Training loss: 1.9156688451766968
Validation loss: 2.070120553175608

Epoch: 6| Step: 5
Training loss: 1.6535437107086182
Validation loss: 2.06289803981781

Epoch: 6| Step: 6
Training loss: 1.5508968830108643
Validation loss: 2.0550846656163535

Epoch: 6| Step: 7
Training loss: 2.2493019104003906
Validation loss: 2.048806289831797

Epoch: 6| Step: 8
Training loss: 2.1584601402282715
Validation loss: 2.05311252673467

Epoch: 6| Step: 9
Training loss: 1.6844274997711182
Validation loss: 2.0520514647165933

Epoch: 6| Step: 10
Training loss: 1.8229694366455078
Validation loss: 2.0468912919362388

Epoch: 6| Step: 11
Training loss: 2.2312774658203125
Validation loss: 2.0546313921610513

Epoch: 6| Step: 12
Training loss: 2.1491265296936035
Validation loss: 2.0577478806177774

Epoch: 6| Step: 13
Training loss: 2.5488667488098145
Validation loss: 2.0632740259170532

Epoch: 38| Step: 0
Training loss: 2.4349684715270996
Validation loss: 2.0409539540608725

Epoch: 6| Step: 1
Training loss: 2.303713321685791
Validation loss: 2.0541507601737976

Epoch: 6| Step: 2
Training loss: 1.903620958328247
Validation loss: 2.0495940844217935

Epoch: 6| Step: 3
Training loss: 2.306349277496338
Validation loss: 2.0634390115737915

Epoch: 6| Step: 4
Training loss: 1.6278183460235596
Validation loss: 2.0365068316459656

Epoch: 6| Step: 5
Training loss: 1.979818344116211
Validation loss: 2.0432883302370706

Epoch: 6| Step: 6
Training loss: 1.9945660829544067
Validation loss: 2.033793012301127

Epoch: 6| Step: 7
Training loss: 2.503286838531494
Validation loss: 2.0424843430519104

Epoch: 6| Step: 8
Training loss: 1.4552253484725952
Validation loss: 2.0415444374084473

Epoch: 6| Step: 9
Training loss: 2.555218458175659
Validation loss: 2.0641144712766013

Epoch: 6| Step: 10
Training loss: 1.720285177230835
Validation loss: 2.0590606729189553

Epoch: 6| Step: 11
Training loss: 1.5822069644927979
Validation loss: 2.038453141848246

Epoch: 6| Step: 12
Training loss: 1.844633936882019
Validation loss: 2.0323304335276284

Epoch: 6| Step: 13
Training loss: 1.6416478157043457
Validation loss: 2.046544849872589

Epoch: 39| Step: 0
Training loss: 2.2856993675231934
Validation loss: 2.044669449329376

Epoch: 6| Step: 1
Training loss: 1.7714992761611938
Validation loss: 2.0409745573997498

Epoch: 6| Step: 2
Training loss: 2.164339542388916
Validation loss: 2.0539939999580383

Epoch: 6| Step: 3
Training loss: 1.7685765027999878
Validation loss: 2.077400008837382

Epoch: 6| Step: 4
Training loss: 2.3535728454589844
Validation loss: 2.0644487539927163

Epoch: 6| Step: 5
Training loss: 2.0494868755340576
Validation loss: 2.072023014227549

Epoch: 6| Step: 6
Training loss: 2.005647659301758
Validation loss: 2.1028172969818115

Epoch: 6| Step: 7
Training loss: 1.4182997941970825
Validation loss: 2.071922481060028

Epoch: 6| Step: 8
Training loss: 2.759997844696045
Validation loss: 2.099713981151581

Epoch: 6| Step: 9
Training loss: 2.219848155975342
Validation loss: 2.0724901954332986

Epoch: 6| Step: 10
Training loss: 1.515434741973877
Validation loss: 2.069444795449575

Epoch: 6| Step: 11
Training loss: 1.9570287466049194
Validation loss: 2.066251516342163

Epoch: 6| Step: 12
Training loss: 1.64768385887146
Validation loss: 2.0412580370903015

Epoch: 6| Step: 13
Training loss: 1.893279790878296
Validation loss: 2.0516383250554404

Epoch: 40| Step: 0
Training loss: 1.7228350639343262
Validation loss: 2.034585257371267

Epoch: 6| Step: 1
Training loss: 2.059668779373169
Validation loss: 2.03975115219752

Epoch: 6| Step: 2
Training loss: 1.4812757968902588
Validation loss: 2.047157367070516

Epoch: 6| Step: 3
Training loss: 1.492856740951538
Validation loss: 2.041861414909363

Epoch: 6| Step: 4
Training loss: 2.033334732055664
Validation loss: 2.040540079275767

Epoch: 6| Step: 5
Training loss: 2.4855735301971436
Validation loss: 2.0387418468793235

Epoch: 6| Step: 6
Training loss: 2.0276429653167725
Validation loss: 2.0357606410980225

Epoch: 6| Step: 7
Training loss: 2.538228988647461
Validation loss: 2.0091633200645447

Epoch: 6| Step: 8
Training loss: 1.6079779863357544
Validation loss: 2.037294169267019

Epoch: 6| Step: 9
Training loss: 2.3255372047424316
Validation loss: 2.0478249986966452

Epoch: 6| Step: 10
Training loss: 2.2679243087768555
Validation loss: 2.053192436695099

Epoch: 6| Step: 11
Training loss: 1.6653926372528076
Validation loss: 2.026792844136556

Epoch: 6| Step: 12
Training loss: 2.007967710494995
Validation loss: 2.036588112513224

Epoch: 6| Step: 13
Training loss: 1.989798903465271
Validation loss: 2.0502983927726746

Epoch: 41| Step: 0
Training loss: 1.5250746011734009
Validation loss: 2.0664592583974204

Epoch: 6| Step: 1
Training loss: 1.8861920833587646
Validation loss: 2.0736565788586936

Epoch: 6| Step: 2
Training loss: 3.1610031127929688
Validation loss: 2.080376168092092

Epoch: 6| Step: 3
Training loss: 2.115065574645996
Validation loss: 2.0845584869384766

Epoch: 6| Step: 4
Training loss: 1.8163244724273682
Validation loss: 2.0737756888071694

Epoch: 6| Step: 5
Training loss: 2.7911953926086426
Validation loss: 2.0992137789726257

Epoch: 6| Step: 6
Training loss: 2.1369943618774414
Validation loss: 2.082012335459391

Epoch: 6| Step: 7
Training loss: 0.948824405670166
Validation loss: 2.036249856154124

Epoch: 6| Step: 8
Training loss: 2.145056962966919
Validation loss: 2.0651731292406716

Epoch: 6| Step: 9
Training loss: 2.1047701835632324
Validation loss: 2.0521886746088662

Epoch: 6| Step: 10
Training loss: 2.429412364959717
Validation loss: 2.053125739097595

Epoch: 6| Step: 11
Training loss: 1.4367246627807617
Validation loss: 2.0438379844029746

Epoch: 6| Step: 12
Training loss: 1.899648666381836
Validation loss: 2.031752824783325

Epoch: 6| Step: 13
Training loss: 1.5692312717437744
Validation loss: 2.0521627267201743

Epoch: 42| Step: 0
Training loss: 2.322727918624878
Validation loss: 2.030688206354777

Epoch: 6| Step: 1
Training loss: 2.4843103885650635
Validation loss: 2.0388659636179605

Epoch: 6| Step: 2
Training loss: 1.7933282852172852
Validation loss: 2.0293009678522744

Epoch: 6| Step: 3
Training loss: 2.004819393157959
Validation loss: 2.041888475418091

Epoch: 6| Step: 4
Training loss: 1.9090824127197266
Validation loss: 2.0262481570243835

Epoch: 6| Step: 5
Training loss: 1.9701576232910156
Validation loss: 2.0236965219179788

Epoch: 6| Step: 6
Training loss: 1.5330004692077637
Validation loss: 2.0423026084899902

Epoch: 6| Step: 7
Training loss: 2.224506378173828
Validation loss: 2.0385285218556723

Epoch: 6| Step: 8
Training loss: 2.04085111618042
Validation loss: 2.0406066179275513

Epoch: 6| Step: 9
Training loss: 2.1633830070495605
Validation loss: 2.0517855882644653

Epoch: 6| Step: 10
Training loss: 1.775280475616455
Validation loss: 2.0479207237561545

Epoch: 6| Step: 11
Training loss: 2.11133074760437
Validation loss: 2.0375762979189553

Epoch: 6| Step: 12
Training loss: 2.0082592964172363
Validation loss: 2.061424215634664

Epoch: 6| Step: 13
Training loss: 1.3298776149749756
Validation loss: 2.033406416575114

Epoch: 43| Step: 0
Training loss: 1.9891595840454102
Validation loss: 2.028727134068807

Epoch: 6| Step: 1
Training loss: 2.1394448280334473
Validation loss: 2.0437209407488504

Epoch: 6| Step: 2
Training loss: 2.247490406036377
Validation loss: 2.033705413341522

Epoch: 6| Step: 3
Training loss: 1.8920347690582275
Validation loss: 2.0401939749717712

Epoch: 6| Step: 4
Training loss: 2.481811046600342
Validation loss: 2.0276338259379068

Epoch: 6| Step: 5
Training loss: 1.761904001235962
Validation loss: 2.055195689201355

Epoch: 6| Step: 6
Training loss: 2.128660202026367
Validation loss: 2.0237695972124734

Epoch: 6| Step: 7
Training loss: 2.101062536239624
Validation loss: 2.0491368174552917

Epoch: 6| Step: 8
Training loss: 2.0947320461273193
Validation loss: 2.0391719142595925

Epoch: 6| Step: 9
Training loss: 2.655561923980713
Validation loss: 2.0171950459480286

Epoch: 6| Step: 10
Training loss: 1.6704920530319214
Validation loss: 2.055059552192688

Epoch: 6| Step: 11
Training loss: 1.1579227447509766
Validation loss: 2.047340671221415

Epoch: 6| Step: 12
Training loss: 1.582165002822876
Validation loss: 2.031669278939565

Epoch: 6| Step: 13
Training loss: 1.735520601272583
Validation loss: 2.0387787222862244

Epoch: 44| Step: 0
Training loss: 1.6040632724761963
Validation loss: 2.0424351493517556

Epoch: 6| Step: 1
Training loss: 2.7132465839385986
Validation loss: 2.0513090093930564

Epoch: 6| Step: 2
Training loss: 2.1249516010284424
Validation loss: 2.083850383758545

Epoch: 6| Step: 3
Training loss: 2.0626773834228516
Validation loss: 2.0612613956133523

Epoch: 6| Step: 4
Training loss: 2.3824751377105713
Validation loss: 2.071320871512095

Epoch: 6| Step: 5
Training loss: 1.9484992027282715
Validation loss: 2.092898428440094

Epoch: 6| Step: 6
Training loss: 1.7440247535705566
Validation loss: 2.071040232976278

Epoch: 6| Step: 7
Training loss: 1.882502794265747
Validation loss: 2.073451598485311

Epoch: 6| Step: 8
Training loss: 2.2489864826202393
Validation loss: 2.0685131549835205

Epoch: 6| Step: 9
Training loss: 1.761324405670166
Validation loss: 2.0489648977915444

Epoch: 6| Step: 10
Training loss: 0.9636837840080261
Validation loss: 2.068247636159261

Epoch: 6| Step: 11
Training loss: 2.246148109436035
Validation loss: 2.054703156153361

Epoch: 6| Step: 12
Training loss: 1.8649131059646606
Validation loss: 2.0477771957715354

Epoch: 6| Step: 13
Training loss: 2.1805944442749023
Validation loss: 2.034674902757009

Epoch: 45| Step: 0
Training loss: 2.2374258041381836
Validation loss: 2.0351720452308655

Epoch: 6| Step: 1
Training loss: 2.1100921630859375
Validation loss: 2.049403270085653

Epoch: 6| Step: 2
Training loss: 1.9708211421966553
Validation loss: 2.033017019430796

Epoch: 6| Step: 3
Training loss: 2.158649206161499
Validation loss: 2.0339011748631797

Epoch: 6| Step: 4
Training loss: 2.1729350090026855
Validation loss: 2.0435765981674194

Epoch: 6| Step: 5
Training loss: 2.6076390743255615
Validation loss: 2.030262808005015

Epoch: 6| Step: 6
Training loss: 2.145379066467285
Validation loss: 2.0474220712979636

Epoch: 6| Step: 7
Training loss: 1.4641077518463135
Validation loss: 2.0309348702430725

Epoch: 6| Step: 8
Training loss: 2.2935245037078857
Validation loss: 2.0379040439923606

Epoch: 6| Step: 9
Training loss: 1.9995335340499878
Validation loss: 2.0563573241233826

Epoch: 6| Step: 10
Training loss: 1.41598379611969
Validation loss: 2.0636526544888816

Epoch: 6| Step: 11
Training loss: 1.606879472732544
Validation loss: 2.0516130725542703

Epoch: 6| Step: 12
Training loss: 1.612392544746399
Validation loss: 2.050473709901174

Epoch: 6| Step: 13
Training loss: 1.7416375875473022
Validation loss: 2.047736485799154

Epoch: 46| Step: 0
Training loss: 2.061638832092285
Validation loss: 2.0460984309514365

Epoch: 6| Step: 1
Training loss: 1.6100506782531738
Validation loss: 2.0332671205202737

Epoch: 6| Step: 2
Training loss: 1.574951171875
Validation loss: 2.0385271310806274

Epoch: 6| Step: 3
Training loss: 2.0245978832244873
Validation loss: 2.0516597032546997

Epoch: 6| Step: 4
Training loss: 1.9627513885498047
Validation loss: 2.041729827721914

Epoch: 6| Step: 5
Training loss: 2.1933975219726562
Validation loss: 2.059459944566091

Epoch: 6| Step: 6
Training loss: 2.3478856086730957
Validation loss: 2.053571363290151

Epoch: 6| Step: 7
Training loss: 2.271510601043701
Validation loss: 2.066758950551351

Epoch: 6| Step: 8
Training loss: 1.527195930480957
Validation loss: 2.0499178369839988

Epoch: 6| Step: 9
Training loss: 2.061136245727539
Validation loss: 2.0585306882858276

Epoch: 6| Step: 10
Training loss: 2.1331348419189453
Validation loss: 2.069821576277415

Epoch: 6| Step: 11
Training loss: 2.146450996398926
Validation loss: 2.0505355397860208

Epoch: 6| Step: 12
Training loss: 1.7118027210235596
Validation loss: 2.0594269831975303

Epoch: 6| Step: 13
Training loss: 1.9826598167419434
Validation loss: 2.071146567662557

Epoch: 47| Step: 0
Training loss: 2.5776684284210205
Validation loss: 2.0559708078702292

Epoch: 6| Step: 1
Training loss: 2.1206092834472656
Validation loss: 2.0359413425127664

Epoch: 6| Step: 2
Training loss: 1.310206413269043
Validation loss: 2.0399534503618875

Epoch: 6| Step: 3
Training loss: 1.6564457416534424
Validation loss: 2.038322687149048

Epoch: 6| Step: 4
Training loss: 1.7709860801696777
Validation loss: 2.0408150355021157

Epoch: 6| Step: 5
Training loss: 2.2700271606445312
Validation loss: 2.036676069100698

Epoch: 6| Step: 6
Training loss: 2.277876853942871
Validation loss: 2.039918899536133

Epoch: 6| Step: 7
Training loss: 1.9993442296981812
Validation loss: 2.0353367726008096

Epoch: 6| Step: 8
Training loss: 2.066911220550537
Validation loss: 2.0498801668485007

Epoch: 6| Step: 9
Training loss: 2.2096736431121826
Validation loss: 2.0278666814168296

Epoch: 6| Step: 10
Training loss: 1.603223443031311
Validation loss: 2.0469256242116294

Epoch: 6| Step: 11
Training loss: 2.823909282684326
Validation loss: 2.0328381260236106

Epoch: 6| Step: 12
Training loss: 1.2650401592254639
Validation loss: 2.04932834704717

Epoch: 6| Step: 13
Training loss: 1.87117338180542
Validation loss: 2.016363541285197

Epoch: 48| Step: 0
Training loss: 1.8562512397766113
Validation loss: 2.0285818179448447

Epoch: 6| Step: 1
Training loss: 2.2847094535827637
Validation loss: 2.018648366133372

Epoch: 6| Step: 2
Training loss: 2.1443066596984863
Validation loss: 2.0405524373054504

Epoch: 6| Step: 3
Training loss: 2.065152645111084
Validation loss: 2.0704574386278787

Epoch: 6| Step: 4
Training loss: 1.8441879749298096
Validation loss: 2.0611877044041953

Epoch: 6| Step: 5
Training loss: 1.6615550518035889
Validation loss: 2.076057553291321

Epoch: 6| Step: 6
Training loss: 2.183774948120117
Validation loss: 2.0790923039118447

Epoch: 6| Step: 7
Training loss: 1.931984782218933
Validation loss: 2.0854657689730325

Epoch: 6| Step: 8
Training loss: 1.1780016422271729
Validation loss: 2.064230799674988

Epoch: 6| Step: 9
Training loss: 1.4789772033691406
Validation loss: 2.037903090318044

Epoch: 6| Step: 10
Training loss: 1.6370234489440918
Validation loss: 2.0623271663983664

Epoch: 6| Step: 11
Training loss: 2.361121654510498
Validation loss: 2.05668173233668

Epoch: 6| Step: 12
Training loss: 2.266906261444092
Validation loss: 2.066277106602987

Epoch: 6| Step: 13
Training loss: 2.5200705528259277
Validation loss: 2.0691675941149392

Epoch: 49| Step: 0
Training loss: 2.077014207839966
Validation loss: 2.021891633669535

Epoch: 6| Step: 1
Training loss: 2.1998047828674316
Validation loss: 2.037492334842682

Epoch: 6| Step: 2
Training loss: 2.9041261672973633
Validation loss: 2.0485703150431314

Epoch: 6| Step: 3
Training loss: 2.178574562072754
Validation loss: 2.0348467032114663

Epoch: 6| Step: 4
Training loss: 1.6633936166763306
Validation loss: 2.0212261279424033

Epoch: 6| Step: 5
Training loss: 1.3590304851531982
Validation loss: 2.0372140208880105

Epoch: 6| Step: 6
Training loss: 1.896713376045227
Validation loss: 2.0341440439224243

Epoch: 6| Step: 7
Training loss: 1.9766416549682617
Validation loss: 2.0211600065231323

Epoch: 6| Step: 8
Training loss: 1.8664968013763428
Validation loss: 2.0335997939109802

Epoch: 6| Step: 9
Training loss: 1.8693169355392456
Validation loss: 2.0365065336227417

Epoch: 6| Step: 10
Training loss: 1.7909924983978271
Validation loss: 2.029112219810486

Epoch: 6| Step: 11
Training loss: 2.1877236366271973
Validation loss: 2.0263410806655884

Epoch: 6| Step: 12
Training loss: 2.099159002304077
Validation loss: 2.05068169037501

Epoch: 6| Step: 13
Training loss: 1.3762905597686768
Validation loss: 2.0360353191693625

Epoch: 50| Step: 0
Training loss: 2.3883397579193115
Validation loss: 2.0528669357299805

Epoch: 6| Step: 1
Training loss: 1.8794806003570557
Validation loss: 2.062260150909424

Epoch: 6| Step: 2
Training loss: 1.8303632736206055
Validation loss: 2.0755921800931296

Epoch: 6| Step: 3
Training loss: 1.82558012008667
Validation loss: 2.08119660615921

Epoch: 6| Step: 4
Training loss: 2.0833778381347656
Validation loss: 2.0773820678393045

Epoch: 6| Step: 5
Training loss: 1.1318897008895874
Validation loss: 2.0587265292803445

Epoch: 6| Step: 6
Training loss: 1.791816234588623
Validation loss: 2.072232484817505

Epoch: 6| Step: 7
Training loss: 1.7974965572357178
Validation loss: 2.0760945677757263

Epoch: 6| Step: 8
Training loss: 2.2324633598327637
Validation loss: 2.0710226694742837

Epoch: 6| Step: 9
Training loss: 2.7834596633911133
Validation loss: 2.0623364448547363

Epoch: 6| Step: 10
Training loss: 1.542961597442627
Validation loss: 2.0657335917154946

Epoch: 6| Step: 11
Training loss: 1.4354281425476074
Validation loss: 2.045384923617045

Epoch: 6| Step: 12
Training loss: 1.8081344366073608
Validation loss: 2.047512670358022

Epoch: 6| Step: 13
Training loss: 2.7174813747406006
Validation loss: 2.039047102133433

Epoch: 51| Step: 0
Training loss: 2.659459352493286
Validation loss: 2.0285171469052634

Epoch: 6| Step: 1
Training loss: 1.5637377500534058
Validation loss: 2.0544488628705344

Epoch: 6| Step: 2
Training loss: 1.4360613822937012
Validation loss: 2.045249342918396

Epoch: 6| Step: 3
Training loss: 1.291398048400879
Validation loss: 2.030575712521871

Epoch: 6| Step: 4
Training loss: 1.6293483972549438
Validation loss: 2.058554947376251

Epoch: 6| Step: 5
Training loss: 2.880260467529297
Validation loss: 2.0344555576642356

Epoch: 6| Step: 6
Training loss: 1.551000952720642
Validation loss: 2.0192954341570535

Epoch: 6| Step: 7
Training loss: 2.3779239654541016
Validation loss: 2.0306999484697976

Epoch: 6| Step: 8
Training loss: 2.178835868835449
Validation loss: 2.048255145549774

Epoch: 6| Step: 9
Training loss: 2.1389360427856445
Validation loss: 2.046636780103048

Epoch: 6| Step: 10
Training loss: 1.9561580419540405
Validation loss: 2.047615170478821

Epoch: 6| Step: 11
Training loss: 1.9614295959472656
Validation loss: 2.0383068919181824

Epoch: 6| Step: 12
Training loss: 2.135843276977539
Validation loss: 2.02150297164917

Epoch: 6| Step: 13
Training loss: 1.7099120616912842
Validation loss: 2.043173909187317

Epoch: 52| Step: 0
Training loss: 1.7217609882354736
Validation loss: 2.0349016785621643

Epoch: 6| Step: 1
Training loss: 2.143981456756592
Validation loss: 2.017633001009623

Epoch: 6| Step: 2
Training loss: 1.5069243907928467
Validation loss: 2.044781823952993

Epoch: 6| Step: 3
Training loss: 2.2495486736297607
Validation loss: 2.0271230737368264

Epoch: 6| Step: 4
Training loss: 2.6549017429351807
Validation loss: 2.0555317203203836

Epoch: 6| Step: 5
Training loss: 1.2978266477584839
Validation loss: 2.016989310582479

Epoch: 6| Step: 6
Training loss: 1.756751537322998
Validation loss: 2.0476731856664023

Epoch: 6| Step: 7
Training loss: 1.5243169069290161
Validation loss: 2.046873907248179

Epoch: 6| Step: 8
Training loss: 1.851507544517517
Validation loss: 2.02458119392395

Epoch: 6| Step: 9
Training loss: 1.9957181215286255
Validation loss: 2.046073575814565

Epoch: 6| Step: 10
Training loss: 2.087416410446167
Validation loss: 2.0104977091153464

Epoch: 6| Step: 11
Training loss: 1.4382160902023315
Validation loss: 2.044410546620687

Epoch: 6| Step: 12
Training loss: 2.703453779220581
Validation loss: 2.0529258648554483

Epoch: 6| Step: 13
Training loss: 2.0980770587921143
Validation loss: 2.054310659567515

Epoch: 53| Step: 0
Training loss: 1.4852153062820435
Validation loss: 2.0597734649976096

Epoch: 6| Step: 1
Training loss: 2.3230509757995605
Validation loss: 2.046285569667816

Epoch: 6| Step: 2
Training loss: 1.7475230693817139
Validation loss: 2.0418012340863547

Epoch: 6| Step: 3
Training loss: 1.7349789142608643
Validation loss: 2.039152761300405

Epoch: 6| Step: 4
Training loss: 2.406985282897949
Validation loss: 2.037502338488897

Epoch: 6| Step: 5
Training loss: 1.498539686203003
Validation loss: 2.0549245476722717

Epoch: 6| Step: 6
Training loss: 1.6624480485916138
Validation loss: 2.057195524374644

Epoch: 6| Step: 7
Training loss: 2.2987148761749268
Validation loss: 2.056677242120107

Epoch: 6| Step: 8
Training loss: 1.4027748107910156
Validation loss: 2.0496570269266763

Epoch: 6| Step: 9
Training loss: 2.412055492401123
Validation loss: 2.046459197998047

Epoch: 6| Step: 10
Training loss: 1.9346163272857666
Validation loss: 2.0598246653874717

Epoch: 6| Step: 11
Training loss: 1.780066728591919
Validation loss: 2.0794568260510764

Epoch: 6| Step: 12
Training loss: 2.7466461658477783
Validation loss: 2.068130910396576

Epoch: 6| Step: 13
Training loss: 1.6954479217529297
Validation loss: 2.0419347882270813

Epoch: 54| Step: 0
Training loss: 2.2377755641937256
Validation loss: 2.0398157437642417

Epoch: 6| Step: 1
Training loss: 1.7939212322235107
Validation loss: 2.0381442308425903

Epoch: 6| Step: 2
Training loss: 1.5657914876937866
Validation loss: 2.038874010245005

Epoch: 6| Step: 3
Training loss: 1.1816394329071045
Validation loss: 2.0401535034179688

Epoch: 6| Step: 4
Training loss: 2.446303606033325
Validation loss: 2.03882904847463

Epoch: 6| Step: 5
Training loss: 2.3061087131500244
Validation loss: 2.0247413714726767

Epoch: 6| Step: 6
Training loss: 2.4027514457702637
Validation loss: 2.0318510135014853

Epoch: 6| Step: 7
Training loss: 1.420640468597412
Validation loss: 2.0409525632858276

Epoch: 6| Step: 8
Training loss: 1.6768478155136108
Validation loss: 2.0346091389656067

Epoch: 6| Step: 9
Training loss: 2.2776498794555664
Validation loss: 2.0437750816345215

Epoch: 6| Step: 10
Training loss: 2.5101020336151123
Validation loss: 2.0276337464650473

Epoch: 6| Step: 11
Training loss: 1.6641795635223389
Validation loss: 2.0596373279889426

Epoch: 6| Step: 12
Training loss: 1.8104844093322754
Validation loss: 2.0476258993148804

Epoch: 6| Step: 13
Training loss: 1.9158891439437866
Validation loss: 2.0493663549423218

Epoch: 55| Step: 0
Training loss: 2.8692729473114014
Validation loss: 2.040914237499237

Epoch: 6| Step: 1
Training loss: 1.3722200393676758
Validation loss: 2.035841166973114

Epoch: 6| Step: 2
Training loss: 1.7032227516174316
Validation loss: 2.0086165269215903

Epoch: 6| Step: 3
Training loss: 1.9922782182693481
Validation loss: 2.046172082424164

Epoch: 6| Step: 4
Training loss: 1.7630966901779175
Validation loss: 2.040567715962728

Epoch: 6| Step: 5
Training loss: 1.9921079874038696
Validation loss: 2.030975262324015

Epoch: 6| Step: 6
Training loss: 1.7574729919433594
Validation loss: 2.033413529396057

Epoch: 6| Step: 7
Training loss: 1.5839723348617554
Validation loss: 2.058616022268931

Epoch: 6| Step: 8
Training loss: 2.092233419418335
Validation loss: 2.0452316204706826

Epoch: 6| Step: 9
Training loss: 1.649308681488037
Validation loss: 2.057423154513041

Epoch: 6| Step: 10
Training loss: 3.03536319732666
Validation loss: 2.0493226647377014

Epoch: 6| Step: 11
Training loss: 2.0620782375335693
Validation loss: 2.068879326184591

Epoch: 6| Step: 12
Training loss: 1.4711601734161377
Validation loss: 2.037012457847595

Epoch: 6| Step: 13
Training loss: 1.7503825426101685
Validation loss: 2.039523800214132

Epoch: 56| Step: 0
Training loss: 1.4147720336914062
Validation loss: 2.034125109513601

Epoch: 6| Step: 1
Training loss: 2.7456302642822266
Validation loss: 2.0364845395088196

Epoch: 6| Step: 2
Training loss: 2.003232002258301
Validation loss: 2.029051939646403

Epoch: 6| Step: 3
Training loss: 2.1027586460113525
Validation loss: 2.0261645317077637

Epoch: 6| Step: 4
Training loss: 1.4498863220214844
Validation loss: 2.027459184328715

Epoch: 6| Step: 5
Training loss: 2.1343417167663574
Validation loss: 2.033957839012146

Epoch: 6| Step: 6
Training loss: 2.0935120582580566
Validation loss: 2.0217414498329163

Epoch: 6| Step: 7
Training loss: 2.323051929473877
Validation loss: 2.027018745740255

Epoch: 6| Step: 8
Training loss: 2.4060330390930176
Validation loss: 2.032125254472097

Epoch: 6| Step: 9
Training loss: 2.1026997566223145
Validation loss: 2.0250430901845298

Epoch: 6| Step: 10
Training loss: 1.1689091920852661
Validation loss: 2.0565988024075827

Epoch: 6| Step: 11
Training loss: 1.376380443572998
Validation loss: 2.032006104787191

Epoch: 6| Step: 12
Training loss: 2.063204526901245
Validation loss: 2.0344828367233276

Epoch: 6| Step: 13
Training loss: 1.853400468826294
Validation loss: 2.016422986984253

Epoch: 57| Step: 0
Training loss: 2.0501976013183594
Validation loss: 2.0323826471964517

Epoch: 6| Step: 1
Training loss: 2.215955972671509
Validation loss: 2.0507500966389975

Epoch: 6| Step: 2
Training loss: 1.959578275680542
Validation loss: 2.0517838994661965

Epoch: 6| Step: 3
Training loss: 1.2415995597839355
Validation loss: 2.0745849013328552

Epoch: 6| Step: 4
Training loss: 1.5928339958190918
Validation loss: 2.0715732971827188

Epoch: 6| Step: 5
Training loss: 1.993523359298706
Validation loss: 2.0497633616129556

Epoch: 6| Step: 6
Training loss: 2.170414686203003
Validation loss: 2.069497227668762

Epoch: 6| Step: 7
Training loss: 2.191573143005371
Validation loss: 2.0902989705403647

Epoch: 6| Step: 8
Training loss: 2.4561755657196045
Validation loss: 2.0677029689153037

Epoch: 6| Step: 9
Training loss: 2.0534729957580566
Validation loss: 2.0856855114301047

Epoch: 6| Step: 10
Training loss: 2.126783847808838
Validation loss: 2.0520744919776917

Epoch: 6| Step: 11
Training loss: 1.4873194694519043
Validation loss: 2.0623499552408853

Epoch: 6| Step: 12
Training loss: 1.6543636322021484
Validation loss: 2.018686354160309

Epoch: 6| Step: 13
Training loss: 1.9267127513885498
Validation loss: 2.017556846141815

Epoch: 58| Step: 0
Training loss: 2.549095392227173
Validation loss: 2.027039388815562

Epoch: 6| Step: 1
Training loss: 1.3946166038513184
Validation loss: 2.035199761390686

Epoch: 6| Step: 2
Training loss: 1.926187515258789
Validation loss: 2.025135060151418

Epoch: 6| Step: 3
Training loss: 1.9013539552688599
Validation loss: 2.028083622455597

Epoch: 6| Step: 4
Training loss: 2.2069780826568604
Validation loss: 2.029802759488424

Epoch: 6| Step: 5
Training loss: 1.6374454498291016
Validation loss: 2.0254058241844177

Epoch: 6| Step: 6
Training loss: 1.709059476852417
Validation loss: 2.0347697138786316

Epoch: 6| Step: 7
Training loss: 1.7331587076187134
Validation loss: 2.0180591344833374

Epoch: 6| Step: 8
Training loss: 2.104090452194214
Validation loss: 2.011197884877523

Epoch: 6| Step: 9
Training loss: 1.452251672744751
Validation loss: 2.01729553937912

Epoch: 6| Step: 10
Training loss: 1.6944551467895508
Validation loss: 2.0328253507614136

Epoch: 6| Step: 11
Training loss: 1.9770431518554688
Validation loss: 2.0180899500846863

Epoch: 6| Step: 12
Training loss: 2.7730469703674316
Validation loss: 2.0266595681508384

Epoch: 6| Step: 13
Training loss: 1.9132544994354248
Validation loss: 2.0228653152783713

Epoch: 59| Step: 0
Training loss: 1.9989573955535889
Validation loss: 2.0481640696525574

Epoch: 6| Step: 1
Training loss: 2.0043797492980957
Validation loss: 2.03001868724823

Epoch: 6| Step: 2
Training loss: 1.5756142139434814
Validation loss: 2.046408792336782

Epoch: 6| Step: 3
Training loss: 1.9168016910552979
Validation loss: 2.0361062486966452

Epoch: 6| Step: 4
Training loss: 2.00559663772583
Validation loss: 2.0533851782480874

Epoch: 6| Step: 5
Training loss: 1.3046633005142212
Validation loss: 2.0264082749684653

Epoch: 6| Step: 6
Training loss: 2.362410306930542
Validation loss: 2.0569992661476135

Epoch: 6| Step: 7
Training loss: 1.6725730895996094
Validation loss: 2.03739070892334

Epoch: 6| Step: 8
Training loss: 1.876440167427063
Validation loss: 2.036737004915873

Epoch: 6| Step: 9
Training loss: 1.4648425579071045
Validation loss: 2.0493190685908

Epoch: 6| Step: 10
Training loss: 2.1469531059265137
Validation loss: 2.045556426048279

Epoch: 6| Step: 11
Training loss: 1.8738024234771729
Validation loss: 2.020076056321462

Epoch: 6| Step: 12
Training loss: 2.3726518154144287
Validation loss: 2.035711109638214

Epoch: 6| Step: 13
Training loss: 2.385129451751709
Validation loss: 2.054177403450012

Epoch: 60| Step: 0
Training loss: 1.761944055557251
Validation loss: 2.0297988851865134

Epoch: 6| Step: 1
Training loss: 2.6334519386291504
Validation loss: 2.028335134188334

Epoch: 6| Step: 2
Training loss: 1.8185451030731201
Validation loss: 2.0159758726755777

Epoch: 6| Step: 3
Training loss: 1.914535641670227
Validation loss: 2.011590619881948

Epoch: 6| Step: 4
Training loss: 1.7737832069396973
Validation loss: 2.02628501256307

Epoch: 6| Step: 5
Training loss: 2.1615445613861084
Validation loss: 2.01279878616333

Epoch: 6| Step: 6
Training loss: 1.8862569332122803
Validation loss: 2.0275290807088218

Epoch: 6| Step: 7
Training loss: 1.6698580980300903
Validation loss: 2.024461348851522

Epoch: 6| Step: 8
Training loss: 2.1736392974853516
Validation loss: 2.026529014110565

Epoch: 6| Step: 9
Training loss: 1.5746641159057617
Validation loss: 2.0064644614855447

Epoch: 6| Step: 10
Training loss: 2.0450077056884766
Validation loss: 2.0302575627962747

Epoch: 6| Step: 11
Training loss: 1.9353342056274414
Validation loss: 2.022489289442698

Epoch: 6| Step: 12
Training loss: 2.0009469985961914
Validation loss: 2.023397227128347

Epoch: 6| Step: 13
Training loss: 1.8342657089233398
Validation loss: 2.032194674015045

Epoch: 61| Step: 0
Training loss: 1.8525176048278809
Validation loss: 2.0369656682014465

Epoch: 6| Step: 1
Training loss: 2.6967475414276123
Validation loss: 2.0555476347605386

Epoch: 6| Step: 2
Training loss: 1.8158921003341675
Validation loss: 2.0621814330418906

Epoch: 6| Step: 3
Training loss: 1.9796171188354492
Validation loss: 2.048880139986674

Epoch: 6| Step: 4
Training loss: 2.1923704147338867
Validation loss: 2.086203853289286

Epoch: 6| Step: 5
Training loss: 1.5113190412521362
Validation loss: 2.0650196075439453

Epoch: 6| Step: 6
Training loss: 1.829302191734314
Validation loss: 2.041645268599192

Epoch: 6| Step: 7
Training loss: 2.105226993560791
Validation loss: 2.062119444211324

Epoch: 6| Step: 8
Training loss: 1.690901756286621
Validation loss: 2.02330873409907

Epoch: 6| Step: 9
Training loss: 1.3552097082138062
Validation loss: 2.033082067966461

Epoch: 6| Step: 10
Training loss: 1.8642805814743042
Validation loss: 2.0358912547429404

Epoch: 6| Step: 11
Training loss: 2.2559711933135986
Validation loss: 2.0649887323379517

Epoch: 6| Step: 12
Training loss: 1.7182855606079102
Validation loss: 2.0430575807889304

Epoch: 6| Step: 13
Training loss: 1.950462818145752
Validation loss: 2.056960086027781

Epoch: 62| Step: 0
Training loss: 1.988351583480835
Validation loss: 2.039805809656779

Epoch: 6| Step: 1
Training loss: 1.6753184795379639
Validation loss: 2.0173943638801575

Epoch: 6| Step: 2
Training loss: 1.6072336435317993
Validation loss: 2.020875553290049

Epoch: 6| Step: 3
Training loss: 2.468651294708252
Validation loss: 2.020667612552643

Epoch: 6| Step: 4
Training loss: 2.2745988368988037
Validation loss: 2.0295210480690002

Epoch: 6| Step: 5
Training loss: 1.5995936393737793
Validation loss: 2.00799153248469

Epoch: 6| Step: 6
Training loss: 1.2985526323318481
Validation loss: 2.02120049794515

Epoch: 6| Step: 7
Training loss: 1.8358674049377441
Validation loss: 2.034085750579834

Epoch: 6| Step: 8
Training loss: 2.34049916267395
Validation loss: 2.0279869039853415

Epoch: 6| Step: 9
Training loss: 1.9332489967346191
Validation loss: 2.0320887366930642

Epoch: 6| Step: 10
Training loss: 1.976596713066101
Validation loss: 2.0118973652521768

Epoch: 6| Step: 11
Training loss: 2.075566291809082
Validation loss: 2.017203708489736

Epoch: 6| Step: 12
Training loss: 1.9095590114593506
Validation loss: 2.0150440335273743

Epoch: 6| Step: 13
Training loss: 1.8540551662445068
Validation loss: 2.0078943371772766

Epoch: 63| Step: 0
Training loss: 1.952910304069519
Validation loss: 2.01730344692866

Epoch: 6| Step: 1
Training loss: 2.2498979568481445
Validation loss: 2.0183051228523254

Epoch: 6| Step: 2
Training loss: 1.782623052597046
Validation loss: 2.0099859038988748

Epoch: 6| Step: 3
Training loss: 1.7760505676269531
Validation loss: 2.008384088675181

Epoch: 6| Step: 4
Training loss: 2.080491065979004
Validation loss: 2.0452524026234946

Epoch: 6| Step: 5
Training loss: 1.4535719156265259
Validation loss: 2.0410910844802856

Epoch: 6| Step: 6
Training loss: 1.7845432758331299
Validation loss: 2.041306793689728

Epoch: 6| Step: 7
Training loss: 1.93070387840271
Validation loss: 2.0487372279167175

Epoch: 6| Step: 8
Training loss: 2.7093944549560547
Validation loss: 2.017188608646393

Epoch: 6| Step: 9
Training loss: 1.8780605792999268
Validation loss: 2.0081165631612143

Epoch: 6| Step: 10
Training loss: 1.6983771324157715
Validation loss: 2.0489190816879272

Epoch: 6| Step: 11
Training loss: 2.0442399978637695
Validation loss: 2.0275147358576455

Epoch: 6| Step: 12
Training loss: 1.9601372480392456
Validation loss: 2.0313750505447388

Epoch: 6| Step: 13
Training loss: 1.6113123893737793
Validation loss: 2.034204383691152

Epoch: 64| Step: 0
Training loss: 2.2422142028808594
Validation loss: 2.033164699872335

Epoch: 6| Step: 1
Training loss: 1.474350929260254
Validation loss: 2.0329317649205527

Epoch: 6| Step: 2
Training loss: 1.8759329319000244
Validation loss: 2.036747475465139

Epoch: 6| Step: 3
Training loss: 1.9538800716400146
Validation loss: 2.055109222730001

Epoch: 6| Step: 4
Training loss: 1.5880911350250244
Validation loss: 2.070305565992991

Epoch: 6| Step: 5
Training loss: 2.2340149879455566
Validation loss: 2.081522981325785

Epoch: 6| Step: 6
Training loss: 1.8831878900527954
Validation loss: 2.0676658352216086

Epoch: 6| Step: 7
Training loss: 2.1753625869750977
Validation loss: 2.091359853744507

Epoch: 6| Step: 8
Training loss: 1.9406406879425049
Validation loss: 2.0766122937202454

Epoch: 6| Step: 9
Training loss: 1.7285505533218384
Validation loss: 2.051547884941101

Epoch: 6| Step: 10
Training loss: 1.1054139137268066
Validation loss: 2.0408040285110474

Epoch: 6| Step: 11
Training loss: 1.891281008720398
Validation loss: 2.0308044950167337

Epoch: 6| Step: 12
Training loss: 2.7044997215270996
Validation loss: 2.046705484390259

Epoch: 6| Step: 13
Training loss: 1.748572587966919
Validation loss: 2.019026299317678

Epoch: 65| Step: 0
Training loss: 2.8662476539611816
Validation loss: 2.029480497042338

Epoch: 6| Step: 1
Training loss: 1.5518059730529785
Validation loss: 2.0116475224494934

Epoch: 6| Step: 2
Training loss: 2.1399378776550293
Validation loss: 2.043341557184855

Epoch: 6| Step: 3
Training loss: 1.5951696634292603
Validation loss: 2.0199801921844482

Epoch: 6| Step: 4
Training loss: 1.6012279987335205
Validation loss: 2.0264361103375754

Epoch: 6| Step: 5
Training loss: 1.7231489419937134
Validation loss: 2.0153244733810425

Epoch: 6| Step: 6
Training loss: 2.032987594604492
Validation loss: 2.0227572321891785

Epoch: 6| Step: 7
Training loss: 2.2716238498687744
Validation loss: 2.020899176597595

Epoch: 6| Step: 8
Training loss: 1.8121219873428345
Validation loss: 2.016571303208669

Epoch: 6| Step: 9
Training loss: 1.656837821006775
Validation loss: 2.001264532407125

Epoch: 6| Step: 10
Training loss: 1.9165101051330566
Validation loss: 2.03241099913915

Epoch: 6| Step: 11
Training loss: 1.9077614545822144
Validation loss: 2.0006805260976157

Epoch: 6| Step: 12
Training loss: 1.6666690111160278
Validation loss: 2.0175276398658752

Epoch: 6| Step: 13
Training loss: 2.228515625
Validation loss: 2.0196192264556885

Epoch: 66| Step: 0
Training loss: 1.4640544652938843
Validation loss: 2.0374284386634827

Epoch: 6| Step: 1
Training loss: 1.8411428928375244
Validation loss: 2.0585084557533264

Epoch: 6| Step: 2
Training loss: 1.5092403888702393
Validation loss: 2.030532956123352

Epoch: 6| Step: 3
Training loss: 1.7305445671081543
Validation loss: 2.0673689246177673

Epoch: 6| Step: 4
Training loss: 2.118915557861328
Validation loss: 2.080755968888601

Epoch: 6| Step: 5
Training loss: 2.3373923301696777
Validation loss: 2.081061820189158

Epoch: 6| Step: 6
Training loss: 1.925164818763733
Validation loss: 2.0839727322260537

Epoch: 6| Step: 7
Training loss: 2.1708877086639404
Validation loss: 2.080182413260142

Epoch: 6| Step: 8
Training loss: 1.3994910717010498
Validation loss: 2.0737770795822144

Epoch: 6| Step: 9
Training loss: 2.172759771347046
Validation loss: 2.0825719634691873

Epoch: 6| Step: 10
Training loss: 2.0872533321380615
Validation loss: 2.0841495196024575

Epoch: 6| Step: 11
Training loss: 1.6252588033676147
Validation loss: 2.0709367990493774

Epoch: 6| Step: 12
Training loss: 2.697345018386841
Validation loss: 2.0517828265825906

Epoch: 6| Step: 13
Training loss: 1.6057831048965454
Validation loss: 2.0326456427574158

Epoch: 67| Step: 0
Training loss: 1.6664037704467773
Validation loss: 2.0251885056495667

Epoch: 6| Step: 1
Training loss: 1.738486886024475
Validation loss: 2.022169589996338

Epoch: 6| Step: 2
Training loss: 2.311638832092285
Validation loss: 2.026581605275472

Epoch: 6| Step: 3
Training loss: 2.560728073120117
Validation loss: 2.0352196097373962

Epoch: 6| Step: 4
Training loss: 2.0173535346984863
Validation loss: 2.0357739528020224

Epoch: 6| Step: 5
Training loss: 2.1855010986328125
Validation loss: 2.038771390914917

Epoch: 6| Step: 6
Training loss: 2.26273512840271
Validation loss: 2.0577489336331687

Epoch: 6| Step: 7
Training loss: 1.751933217048645
Validation loss: 2.047212998072306

Epoch: 6| Step: 8
Training loss: 2.674607038497925
Validation loss: 2.0399819215138755

Epoch: 6| Step: 9
Training loss: 1.8592052459716797
Validation loss: 2.053837478160858

Epoch: 6| Step: 10
Training loss: 1.6938705444335938
Validation loss: 2.041885554790497

Epoch: 6| Step: 11
Training loss: 1.1719119548797607
Validation loss: 2.0313376784324646

Epoch: 6| Step: 12
Training loss: 1.9335813522338867
Validation loss: 2.029071112473806

Epoch: 6| Step: 13
Training loss: 1.4313783645629883
Validation loss: 2.063744386037191

Epoch: 68| Step: 0
Training loss: 1.5568339824676514
Validation loss: 2.0229464968045554

Epoch: 6| Step: 1
Training loss: 1.9027060270309448
Validation loss: 2.027590751647949

Epoch: 6| Step: 2
Training loss: 2.3803114891052246
Validation loss: 2.032123585542043

Epoch: 6| Step: 3
Training loss: 1.4313867092132568
Validation loss: 2.0681755940119424

Epoch: 6| Step: 4
Training loss: 2.0659632682800293
Validation loss: 2.111751357714335

Epoch: 6| Step: 5
Training loss: 1.6532626152038574
Validation loss: 2.0798750718434653

Epoch: 6| Step: 6
Training loss: 2.425642967224121
Validation loss: 2.0876606106758118

Epoch: 6| Step: 7
Training loss: 1.293351411819458
Validation loss: 2.0714885195096335

Epoch: 6| Step: 8
Training loss: 2.1050500869750977
Validation loss: 2.0768519043922424

Epoch: 6| Step: 9
Training loss: 1.9472774267196655
Validation loss: 2.046133577823639

Epoch: 6| Step: 10
Training loss: 2.1732397079467773
Validation loss: 2.051378905773163

Epoch: 6| Step: 11
Training loss: 1.8045175075531006
Validation loss: 2.039180338382721

Epoch: 6| Step: 12
Training loss: 1.884634017944336
Validation loss: 2.0462841391563416

Epoch: 6| Step: 13
Training loss: 2.0854363441467285
Validation loss: 2.0470900932947793

Epoch: 69| Step: 0
Training loss: 3.0575060844421387
Validation loss: 2.045328160127004

Epoch: 6| Step: 1
Training loss: 1.4203686714172363
Validation loss: 2.0317402482032776

Epoch: 6| Step: 2
Training loss: 2.563854932785034
Validation loss: 2.019978622595469

Epoch: 6| Step: 3
Training loss: 1.7820024490356445
Validation loss: 2.0268388390541077

Epoch: 6| Step: 4
Training loss: 2.002938747406006
Validation loss: 2.045502026875814

Epoch: 6| Step: 5
Training loss: 1.8121278285980225
Validation loss: 2.0230606396993003

Epoch: 6| Step: 6
Training loss: 1.4824320077896118
Validation loss: 2.00952011346817

Epoch: 6| Step: 7
Training loss: 2.053448438644409
Validation loss: 2.0148016015688577

Epoch: 6| Step: 8
Training loss: 1.3436213731765747
Validation loss: 2.024687170982361

Epoch: 6| Step: 9
Training loss: 1.5803954601287842
Validation loss: 2.016628305117289

Epoch: 6| Step: 10
Training loss: 1.2962424755096436
Validation loss: 2.0351204872131348

Epoch: 6| Step: 11
Training loss: 1.6325716972351074
Validation loss: 2.0228774150212607

Epoch: 6| Step: 12
Training loss: 2.344909191131592
Validation loss: 2.0245863993962607

Epoch: 6| Step: 13
Training loss: 2.350818634033203
Validation loss: 2.0372304916381836

Epoch: 70| Step: 0
Training loss: 1.5955405235290527
Validation loss: 2.0429109930992126

Epoch: 6| Step: 1
Training loss: 1.461897373199463
Validation loss: 2.0568324526151023

Epoch: 6| Step: 2
Training loss: 1.9701323509216309
Validation loss: 2.0805331667264304

Epoch: 6| Step: 3
Training loss: 1.9503858089447021
Validation loss: 2.069463789463043

Epoch: 6| Step: 4
Training loss: 1.4574933052062988
Validation loss: 2.084204455216726

Epoch: 6| Step: 5
Training loss: 2.0262746810913086
Validation loss: 2.1179462472597756

Epoch: 6| Step: 6
Training loss: 1.4626333713531494
Validation loss: 2.138963222503662

Epoch: 6| Step: 7
Training loss: 2.3045494556427
Validation loss: 2.115424652894338

Epoch: 6| Step: 8
Training loss: 2.0647366046905518
Validation loss: 2.092343807220459

Epoch: 6| Step: 9
Training loss: 2.448030710220337
Validation loss: 2.0838717222213745

Epoch: 6| Step: 10
Training loss: 2.304710626602173
Validation loss: 2.063745061556498

Epoch: 6| Step: 11
Training loss: 2.073155403137207
Validation loss: 2.0279902815818787

Epoch: 6| Step: 12
Training loss: 1.9347800016403198
Validation loss: 2.0300045212109885

Epoch: 6| Step: 13
Training loss: 1.8482228517532349
Validation loss: 2.0290661652882895

Epoch: 71| Step: 0
Training loss: 1.2277112007141113
Validation loss: 2.012061893939972

Epoch: 6| Step: 1
Training loss: 2.006253242492676
Validation loss: 2.0176320672035217

Epoch: 6| Step: 2
Training loss: 1.7833036184310913
Validation loss: 2.0275402069091797

Epoch: 6| Step: 3
Training loss: 1.3374322652816772
Validation loss: 2.02064456542333

Epoch: 6| Step: 4
Training loss: 2.5785319805145264
Validation loss: 2.001985490322113

Epoch: 6| Step: 5
Training loss: 1.7991960048675537
Validation loss: 2.0181842048962912

Epoch: 6| Step: 6
Training loss: 2.5211524963378906
Validation loss: 2.0433794458707175

Epoch: 6| Step: 7
Training loss: 1.854417324066162
Validation loss: 2.0235376755396524

Epoch: 6| Step: 8
Training loss: 1.8303751945495605
Validation loss: 2.018792152404785

Epoch: 6| Step: 9
Training loss: 2.0659303665161133
Validation loss: 2.026595731576284

Epoch: 6| Step: 10
Training loss: 2.1666359901428223
Validation loss: 2.016341427961985

Epoch: 6| Step: 11
Training loss: 1.9273548126220703
Validation loss: 2.0146077275276184

Epoch: 6| Step: 12
Training loss: 1.698110818862915
Validation loss: 2.017930050690969

Epoch: 6| Step: 13
Training loss: 1.782914161682129
Validation loss: 2.0292396744092307

Epoch: 72| Step: 0
Training loss: 2.4256885051727295
Validation loss: 2.0091400146484375

Epoch: 6| Step: 1
Training loss: 1.5295138359069824
Validation loss: 2.0035980145136514

Epoch: 6| Step: 2
Training loss: 1.702204704284668
Validation loss: 2.019025683403015

Epoch: 6| Step: 3
Training loss: 2.581836223602295
Validation loss: 2.013959268728892

Epoch: 6| Step: 4
Training loss: 2.093193531036377
Validation loss: 2.0325740575790405

Epoch: 6| Step: 5
Training loss: 1.8809746503829956
Validation loss: 2.0282798409461975

Epoch: 6| Step: 6
Training loss: 1.525402545928955
Validation loss: 2.021075705687205

Epoch: 6| Step: 7
Training loss: 1.6929233074188232
Validation loss: 2.029426415761312

Epoch: 6| Step: 8
Training loss: 1.4176952838897705
Validation loss: 2.0102341969807944

Epoch: 6| Step: 9
Training loss: 1.8198089599609375
Validation loss: 2.0331610838572183

Epoch: 6| Step: 10
Training loss: 2.618882656097412
Validation loss: 2.0578297773996987

Epoch: 6| Step: 11
Training loss: 2.066744327545166
Validation loss: 2.0846081574757895

Epoch: 6| Step: 12
Training loss: 1.476076602935791
Validation loss: 2.0695757071177163

Epoch: 6| Step: 13
Training loss: 1.560072898864746
Validation loss: 2.053645928700765

Epoch: 73| Step: 0
Training loss: 1.724326729774475
Validation loss: 2.0619439482688904

Epoch: 6| Step: 1
Training loss: 1.5966933965682983
Validation loss: 2.068886379400889

Epoch: 6| Step: 2
Training loss: 1.3265832662582397
Validation loss: 2.0407725969950357

Epoch: 6| Step: 3
Training loss: 1.4990992546081543
Validation loss: 2.058733065923055

Epoch: 6| Step: 4
Training loss: 2.0647969245910645
Validation loss: 2.0133155385653176

Epoch: 6| Step: 5
Training loss: 1.4331464767456055
Validation loss: 2.0216161211331687

Epoch: 6| Step: 6
Training loss: 2.250392198562622
Validation loss: 2.030664066473643

Epoch: 6| Step: 7
Training loss: 2.069603443145752
Validation loss: 2.005810042222341

Epoch: 6| Step: 8
Training loss: 1.837447166442871
Validation loss: 2.038040300210317

Epoch: 6| Step: 9
Training loss: 1.9772849082946777
Validation loss: 2.041470686594645

Epoch: 6| Step: 10
Training loss: 2.5482513904571533
Validation loss: 2.0252166589101157

Epoch: 6| Step: 11
Training loss: 1.8029835224151611
Validation loss: 2.034532308578491

Epoch: 6| Step: 12
Training loss: 2.2994062900543213
Validation loss: 2.033268928527832

Epoch: 6| Step: 13
Training loss: 1.9542348384857178
Validation loss: 2.015539983908335

Epoch: 74| Step: 0
Training loss: 1.956446647644043
Validation loss: 2.0365097522735596

Epoch: 6| Step: 1
Training loss: 2.218003273010254
Validation loss: 2.0174270470937095

Epoch: 6| Step: 2
Training loss: 1.9436661005020142
Validation loss: 2.0210783084233603

Epoch: 6| Step: 3
Training loss: 1.4307467937469482
Validation loss: 2.0196849703788757

Epoch: 6| Step: 4
Training loss: 1.9448273181915283
Validation loss: 2.0189400712649026

Epoch: 6| Step: 5
Training loss: 1.5069780349731445
Validation loss: 2.024835467338562

Epoch: 6| Step: 6
Training loss: 1.9785411357879639
Validation loss: 2.0228505531946817

Epoch: 6| Step: 7
Training loss: 1.6374794244766235
Validation loss: 2.0519966284434

Epoch: 6| Step: 8
Training loss: 1.7670973539352417
Validation loss: 2.0580790440241494

Epoch: 6| Step: 9
Training loss: 2.333207845687866
Validation loss: 2.064486265182495

Epoch: 6| Step: 10
Training loss: 1.5388025045394897
Validation loss: 2.0517841974894204

Epoch: 6| Step: 11
Training loss: 2.19291353225708
Validation loss: 2.045741697152456

Epoch: 6| Step: 12
Training loss: 2.6410183906555176
Validation loss: 2.012260655562083

Epoch: 6| Step: 13
Training loss: 1.3643327951431274
Validation loss: 2.034843146800995

Epoch: 75| Step: 0
Training loss: 2.9225258827209473
Validation loss: 2.0310996174812317

Epoch: 6| Step: 1
Training loss: 1.5450305938720703
Validation loss: 2.003309448560079

Epoch: 6| Step: 2
Training loss: 2.2089014053344727
Validation loss: 2.013406753540039

Epoch: 6| Step: 3
Training loss: 2.0652995109558105
Validation loss: 2.0356089075406394

Epoch: 6| Step: 4
Training loss: 1.954846739768982
Validation loss: 2.022921601931254

Epoch: 6| Step: 5
Training loss: 1.731027364730835
Validation loss: 2.0144784450531006

Epoch: 6| Step: 6
Training loss: 1.688962697982788
Validation loss: 2.035206655661265

Epoch: 6| Step: 7
Training loss: 1.7752137184143066
Validation loss: 2.029803534348806

Epoch: 6| Step: 8
Training loss: 1.8484745025634766
Validation loss: 2.021628220876058

Epoch: 6| Step: 9
Training loss: 1.8496997356414795
Validation loss: 2.027679185072581

Epoch: 6| Step: 10
Training loss: 1.814773678779602
Validation loss: 2.0473792950312295

Epoch: 6| Step: 11
Training loss: 1.6509934663772583
Validation loss: 2.038761337598165

Epoch: 6| Step: 12
Training loss: 1.3837807178497314
Validation loss: 2.0291663805643716

Epoch: 6| Step: 13
Training loss: 1.7006933689117432
Validation loss: 2.028039356072744

Epoch: 76| Step: 0
Training loss: 2.3208694458007812
Validation loss: 2.0343817869822183

Epoch: 6| Step: 1
Training loss: 1.4257097244262695
Validation loss: 2.0286838610967

Epoch: 6| Step: 2
Training loss: 2.1897478103637695
Validation loss: 2.0270361502965293

Epoch: 6| Step: 3
Training loss: 2.210022449493408
Validation loss: 2.0254264076550803

Epoch: 6| Step: 4
Training loss: 2.528174877166748
Validation loss: 2.037071943283081

Epoch: 6| Step: 5
Training loss: 1.952707290649414
Validation loss: 2.0111815333366394

Epoch: 6| Step: 6
Training loss: 1.8577735424041748
Validation loss: 2.018720547358195

Epoch: 6| Step: 7
Training loss: 1.2386744022369385
Validation loss: 2.026362101236979

Epoch: 6| Step: 8
Training loss: 1.6603316068649292
Validation loss: 2.0403974850972495

Epoch: 6| Step: 9
Training loss: 1.6923348903656006
Validation loss: 2.0221040646235147

Epoch: 6| Step: 10
Training loss: 1.5119884014129639
Validation loss: 2.028006672859192

Epoch: 6| Step: 11
Training loss: 1.354050874710083
Validation loss: 2.0093865195910134

Epoch: 6| Step: 12
Training loss: 2.099778413772583
Validation loss: 2.030566235383352

Epoch: 6| Step: 13
Training loss: 2.0563817024230957
Validation loss: 2.0336287021636963

Epoch: 77| Step: 0
Training loss: 2.0397393703460693
Validation loss: 2.0336560010910034

Epoch: 6| Step: 1
Training loss: 1.481018304824829
Validation loss: 2.047158360481262

Epoch: 6| Step: 2
Training loss: 1.9609642028808594
Validation loss: 2.0369611382484436

Epoch: 6| Step: 3
Training loss: 2.1029229164123535
Validation loss: 2.005850851535797

Epoch: 6| Step: 4
Training loss: 1.8931878805160522
Validation loss: 2.0167830983797708

Epoch: 6| Step: 5
Training loss: 1.5229445695877075
Validation loss: 2.0250364542007446

Epoch: 6| Step: 6
Training loss: 2.5145885944366455
Validation loss: 2.002155363559723

Epoch: 6| Step: 7
Training loss: 1.5362398624420166
Validation loss: 2.003550330797831

Epoch: 6| Step: 8
Training loss: 2.0015876293182373
Validation loss: 1.9972642660140991

Epoch: 6| Step: 9
Training loss: 2.1344079971313477
Validation loss: 2.023948391278585

Epoch: 6| Step: 10
Training loss: 1.5514845848083496
Validation loss: 2.0281787713368735

Epoch: 6| Step: 11
Training loss: 1.8655773401260376
Validation loss: 2.009243826071421

Epoch: 6| Step: 12
Training loss: 1.5938036441802979
Validation loss: 2.0148261984189353

Epoch: 6| Step: 13
Training loss: 1.8709304332733154
Validation loss: 2.008173724015554

Epoch: 78| Step: 0
Training loss: 0.820197343826294
Validation loss: 2.034358859062195

Epoch: 6| Step: 1
Training loss: 1.7420670986175537
Validation loss: 2.068021277586619

Epoch: 6| Step: 2
Training loss: 2.1047425270080566
Validation loss: 2.0740628838539124

Epoch: 6| Step: 3
Training loss: 2.5115623474121094
Validation loss: 2.1008509596188865

Epoch: 6| Step: 4
Training loss: 1.7766016721725464
Validation loss: 2.1545952757199607

Epoch: 6| Step: 5
Training loss: 1.7553043365478516
Validation loss: 2.113666911919912

Epoch: 6| Step: 6
Training loss: 2.6054935455322266
Validation loss: 2.12642373641332

Epoch: 6| Step: 7
Training loss: 1.9269099235534668
Validation loss: 2.126086413860321

Epoch: 6| Step: 8
Training loss: 1.8112355470657349
Validation loss: 2.098086675008138

Epoch: 6| Step: 9
Training loss: 1.9575649499893188
Validation loss: 2.075172026952108

Epoch: 6| Step: 10
Training loss: 1.501420021057129
Validation loss: 2.032580633958181

Epoch: 6| Step: 11
Training loss: 2.761841297149658
Validation loss: 2.0269776781400046

Epoch: 6| Step: 12
Training loss: 1.6540095806121826
Validation loss: 2.000620504220327

Epoch: 6| Step: 13
Training loss: 1.5534595251083374
Validation loss: 2.0414631168047586

Epoch: 79| Step: 0
Training loss: 1.664991021156311
Validation loss: 2.0254653692245483

Epoch: 6| Step: 1
Training loss: 1.6259405612945557
Validation loss: 2.0218388040860495

Epoch: 6| Step: 2
Training loss: 2.1305370330810547
Validation loss: 2.0329278111457825

Epoch: 6| Step: 3
Training loss: 1.9249460697174072
Validation loss: 2.0320565501848855

Epoch: 6| Step: 4
Training loss: 1.8899028301239014
Validation loss: 2.030208090941111

Epoch: 6| Step: 5
Training loss: 1.5637164115905762
Validation loss: 2.0113123059272766

Epoch: 6| Step: 6
Training loss: 2.102240562438965
Validation loss: 2.019055664539337

Epoch: 6| Step: 7
Training loss: 1.7797629833221436
Validation loss: 1.995745301246643

Epoch: 6| Step: 8
Training loss: 2.0465822219848633
Validation loss: 2.017603019873301

Epoch: 6| Step: 9
Training loss: 2.115407943725586
Validation loss: 2.013825555642446

Epoch: 6| Step: 10
Training loss: 1.9524636268615723
Validation loss: 2.0503111282984414

Epoch: 6| Step: 11
Training loss: 1.5066274404525757
Validation loss: 2.0411983927090964

Epoch: 6| Step: 12
Training loss: 1.485736608505249
Validation loss: 2.051508069038391

Epoch: 6| Step: 13
Training loss: 2.699253559112549
Validation loss: 2.0618182023366294

Epoch: 80| Step: 0
Training loss: 1.9179491996765137
Validation loss: 2.061809539794922

Epoch: 6| Step: 1
Training loss: 2.1807167530059814
Validation loss: 2.081693112850189

Epoch: 6| Step: 2
Training loss: 1.2436846494674683
Validation loss: 2.0713995695114136

Epoch: 6| Step: 3
Training loss: 2.1667063236236572
Validation loss: 2.089499513308207

Epoch: 6| Step: 4
Training loss: 2.526439666748047
Validation loss: 2.078937848409017

Epoch: 6| Step: 5
Training loss: 1.8326292037963867
Validation loss: 2.069963753223419

Epoch: 6| Step: 6
Training loss: 1.7523928880691528
Validation loss: 2.0568068822224936

Epoch: 6| Step: 7
Training loss: 2.1137478351593018
Validation loss: 2.045112371444702

Epoch: 6| Step: 8
Training loss: 1.3688642978668213
Validation loss: 2.033707857131958

Epoch: 6| Step: 9
Training loss: 1.439976453781128
Validation loss: 2.0229520996411643

Epoch: 6| Step: 10
Training loss: 1.7834562063217163
Validation loss: 2.0144619146982827

Epoch: 6| Step: 11
Training loss: 1.580283522605896
Validation loss: 2.0220003922780356

Epoch: 6| Step: 12
Training loss: 2.5075440406799316
Validation loss: 2.009260058403015

Epoch: 6| Step: 13
Training loss: 1.8022682666778564
Validation loss: 1.9990369478861492

Epoch: 81| Step: 0
Training loss: 1.4900784492492676
Validation loss: 2.0165854692459106

Epoch: 6| Step: 1
Training loss: 1.4724133014678955
Validation loss: 2.008723199367523

Epoch: 6| Step: 2
Training loss: 1.7695112228393555
Validation loss: 1.9982664783795674

Epoch: 6| Step: 3
Training loss: 2.0881476402282715
Validation loss: 2.0312072038650513

Epoch: 6| Step: 4
Training loss: 1.1807923316955566
Validation loss: 2.055041571458181

Epoch: 6| Step: 5
Training loss: 2.222459554672241
Validation loss: 2.0609888831774392

Epoch: 6| Step: 6
Training loss: 2.429020643234253
Validation loss: 2.085803290208181

Epoch: 6| Step: 7
Training loss: 1.0098623037338257
Validation loss: 2.084642549355825

Epoch: 6| Step: 8
Training loss: 2.495807409286499
Validation loss: 2.126936972141266

Epoch: 6| Step: 9
Training loss: 2.560154914855957
Validation loss: 2.070267061392466

Epoch: 6| Step: 10
Training loss: 2.5122759342193604
Validation loss: 2.039488434791565

Epoch: 6| Step: 11
Training loss: 1.8751927614212036
Validation loss: 2.0591907898585

Epoch: 6| Step: 12
Training loss: 1.1962628364562988
Validation loss: 2.0623823006947837

Epoch: 6| Step: 13
Training loss: 2.2946176528930664
Validation loss: 2.0468293825785318

Epoch: 82| Step: 0
Training loss: 1.613071322441101
Validation loss: 2.018866717815399

Epoch: 6| Step: 1
Training loss: 1.6153337955474854
Validation loss: 2.04277636607488

Epoch: 6| Step: 2
Training loss: 2.3349685668945312
Validation loss: 2.047520478566488

Epoch: 6| Step: 3
Training loss: 1.8309133052825928
Validation loss: 2.0019346475601196

Epoch: 6| Step: 4
Training loss: 1.5448943376541138
Validation loss: 2.031100352605184

Epoch: 6| Step: 5
Training loss: 1.2015371322631836
Validation loss: 2.03640083471934

Epoch: 6| Step: 6
Training loss: 1.921504020690918
Validation loss: 2.0352274775505066

Epoch: 6| Step: 7
Training loss: 1.839421033859253
Validation loss: 2.0392680565516152

Epoch: 6| Step: 8
Training loss: 1.7454450130462646
Validation loss: 2.0257973869641623

Epoch: 6| Step: 9
Training loss: 1.6274642944335938
Validation loss: 2.0372777779897056

Epoch: 6| Step: 10
Training loss: 2.108948230743408
Validation loss: 2.022172292073568

Epoch: 6| Step: 11
Training loss: 1.9589848518371582
Validation loss: 2.020626644293467

Epoch: 6| Step: 12
Training loss: 2.0176472663879395
Validation loss: 2.0142332315444946

Epoch: 6| Step: 13
Training loss: 2.3316879272460938
Validation loss: 2.028424541155497

Epoch: 83| Step: 0
Training loss: 1.1259877681732178
Validation loss: 1.9950160185496013

Epoch: 6| Step: 1
Training loss: 2.0543770790100098
Validation loss: 2.0232203602790833

Epoch: 6| Step: 2
Training loss: 1.9893535375595093
Validation loss: 1.9995685815811157

Epoch: 6| Step: 3
Training loss: 1.3932442665100098
Validation loss: 1.9993122816085815

Epoch: 6| Step: 4
Training loss: 2.708904504776001
Validation loss: 2.047125816345215

Epoch: 6| Step: 5
Training loss: 1.8123998641967773
Validation loss: 2.0223701198895774

Epoch: 6| Step: 6
Training loss: 1.9752118587493896
Validation loss: 2.0398681362469993

Epoch: 6| Step: 7
Training loss: 2.746764659881592
Validation loss: 2.0029583970705667

Epoch: 6| Step: 8
Training loss: 1.612960934638977
Validation loss: 2.018893281618754

Epoch: 6| Step: 9
Training loss: 1.9371484518051147
Validation loss: 2.0152543783187866

Epoch: 6| Step: 10
Training loss: 1.92380690574646
Validation loss: 1.9952537020047505

Epoch: 6| Step: 11
Training loss: 1.5441811084747314
Validation loss: 2.034229358037313

Epoch: 6| Step: 12
Training loss: 1.6217334270477295
Validation loss: 2.0219099521636963

Epoch: 6| Step: 13
Training loss: 1.2201313972473145
Validation loss: 2.007475952307383

Epoch: 84| Step: 0
Training loss: 2.0069241523742676
Validation loss: 2.0097991029421487

Epoch: 6| Step: 1
Training loss: 1.9246840476989746
Validation loss: 2.011842985947927

Epoch: 6| Step: 2
Training loss: 1.9991711378097534
Validation loss: 2.0108718474706015

Epoch: 6| Step: 3
Training loss: 2.2143688201904297
Validation loss: 2.024688462416331

Epoch: 6| Step: 4
Training loss: 1.7207129001617432
Validation loss: 2.002140382925669

Epoch: 6| Step: 5
Training loss: 1.6654452085494995
Validation loss: 2.026855687300364

Epoch: 6| Step: 6
Training loss: 1.9821932315826416
Validation loss: 2.0262922445933023

Epoch: 6| Step: 7
Training loss: 1.520735502243042
Validation loss: 2.0151095589001975

Epoch: 6| Step: 8
Training loss: 1.8460490703582764
Validation loss: 2.018717348575592

Epoch: 6| Step: 9
Training loss: 1.400454044342041
Validation loss: 1.9929544727007549

Epoch: 6| Step: 10
Training loss: 1.6689245700836182
Validation loss: 2.0017030040423074

Epoch: 6| Step: 11
Training loss: 1.6145117282867432
Validation loss: 2.0380294720331826

Epoch: 6| Step: 12
Training loss: 2.0496513843536377
Validation loss: 2.0511817932128906

Epoch: 6| Step: 13
Training loss: 1.8805813789367676
Validation loss: 2.0505452950795493

Epoch: 85| Step: 0
Training loss: 1.6916897296905518
Validation loss: 2.0843205650647483

Epoch: 6| Step: 1
Training loss: 2.2816162109375
Validation loss: 2.0933332045873008

Epoch: 6| Step: 2
Training loss: 2.3304731845855713
Validation loss: 2.112689971923828

Epoch: 6| Step: 3
Training loss: 1.7478272914886475
Validation loss: 2.0978203217188516

Epoch: 6| Step: 4
Training loss: 2.2201552391052246
Validation loss: 2.109168291091919

Epoch: 6| Step: 5
Training loss: 2.540618896484375
Validation loss: 2.0748504598935447

Epoch: 6| Step: 6
Training loss: 2.1101696491241455
Validation loss: 2.082927962144216

Epoch: 6| Step: 7
Training loss: 1.835423469543457
Validation loss: 2.060493548711141

Epoch: 6| Step: 8
Training loss: 1.203188419342041
Validation loss: 2.0431570609410605

Epoch: 6| Step: 9
Training loss: 1.226668119430542
Validation loss: 2.0433854858080545

Epoch: 6| Step: 10
Training loss: 1.5569307804107666
Validation loss: 2.0080815156300864

Epoch: 6| Step: 11
Training loss: 1.3314721584320068
Validation loss: 2.037144978841146

Epoch: 6| Step: 12
Training loss: 1.8543505668640137
Validation loss: 2.0215845902760825

Epoch: 6| Step: 13
Training loss: 1.7774546146392822
Validation loss: 2.040096084276835

Epoch: 86| Step: 0
Training loss: 1.919849157333374
Validation loss: 2.045569360256195

Epoch: 6| Step: 1
Training loss: 2.3489596843719482
Validation loss: 2.034953991572062

Epoch: 6| Step: 2
Training loss: 1.6480075120925903
Validation loss: 2.0354353984196982

Epoch: 6| Step: 3
Training loss: 1.4575227499008179
Validation loss: 2.021654029687246

Epoch: 6| Step: 4
Training loss: 2.197761058807373
Validation loss: 2.0402557452519736

Epoch: 6| Step: 5
Training loss: 1.1359927654266357
Validation loss: 2.0520370403925576

Epoch: 6| Step: 6
Training loss: 1.8776462078094482
Validation loss: 2.0285178621610007

Epoch: 6| Step: 7
Training loss: 1.8841290473937988
Validation loss: 2.037430147329966

Epoch: 6| Step: 8
Training loss: 1.180974006652832
Validation loss: 2.0218709905942283

Epoch: 6| Step: 9
Training loss: 1.7339740991592407
Validation loss: 2.000297804673513

Epoch: 6| Step: 10
Training loss: 1.6955976486206055
Validation loss: 1.996300180753072

Epoch: 6| Step: 11
Training loss: 2.5455684661865234
Validation loss: 2.011405269304911

Epoch: 6| Step: 12
Training loss: 1.6335029602050781
Validation loss: 2.018365224202474

Epoch: 6| Step: 13
Training loss: 2.277311325073242
Validation loss: 2.009616732597351

Epoch: 87| Step: 0
Training loss: 1.7634741067886353
Validation loss: 2.0051799019177756

Epoch: 6| Step: 1
Training loss: 1.8356317281723022
Validation loss: 2.0085571805636087

Epoch: 6| Step: 2
Training loss: 2.229154586791992
Validation loss: 2.0250680446624756

Epoch: 6| Step: 3
Training loss: 2.3378217220306396
Validation loss: 2.010856588681539

Epoch: 6| Step: 4
Training loss: 1.742853045463562
Validation loss: 2.005932927131653

Epoch: 6| Step: 5
Training loss: 1.5364099740982056
Validation loss: 1.9961557984352112

Epoch: 6| Step: 6
Training loss: 2.0652029514312744
Validation loss: 2.032929241657257

Epoch: 6| Step: 7
Training loss: 1.2796224355697632
Validation loss: 2.0137577652931213

Epoch: 6| Step: 8
Training loss: 1.4507694244384766
Validation loss: 2.030309319496155

Epoch: 6| Step: 9
Training loss: 1.848055362701416
Validation loss: 2.035005529721578

Epoch: 6| Step: 10
Training loss: 1.45640230178833
Validation loss: 2.013742764790853

Epoch: 6| Step: 11
Training loss: 2.3992397785186768
Validation loss: 2.0208901166915894

Epoch: 6| Step: 12
Training loss: 2.012166738510132
Validation loss: 2.007760544617971

Epoch: 6| Step: 13
Training loss: 1.5170402526855469
Validation loss: 2.0068428913752236

Epoch: 88| Step: 0
Training loss: 1.5928077697753906
Validation loss: 2.0438731710116067

Epoch: 6| Step: 1
Training loss: 1.6906986236572266
Validation loss: 2.052969733874003

Epoch: 6| Step: 2
Training loss: 2.286003351211548
Validation loss: 2.0721296469370523

Epoch: 6| Step: 3
Training loss: 1.563096046447754
Validation loss: 2.0614280502001443

Epoch: 6| Step: 4
Training loss: 1.4875133037567139
Validation loss: 2.091291626294454

Epoch: 6| Step: 5
Training loss: 1.5363883972167969
Validation loss: 2.0871349771817527

Epoch: 6| Step: 6
Training loss: 2.2098512649536133
Validation loss: 2.101732611656189

Epoch: 6| Step: 7
Training loss: 1.9138076305389404
Validation loss: 2.0993319948514304

Epoch: 6| Step: 8
Training loss: 1.7014915943145752
Validation loss: 2.0603208343187966

Epoch: 6| Step: 9
Training loss: 2.1133694648742676
Validation loss: 2.0596261024475098

Epoch: 6| Step: 10
Training loss: 1.3595154285430908
Validation loss: 2.057434062163035

Epoch: 6| Step: 11
Training loss: 2.076420307159424
Validation loss: 2.052491048971812

Epoch: 6| Step: 12
Training loss: 1.920414686203003
Validation loss: 2.0346026619275412

Epoch: 6| Step: 13
Training loss: 2.0469789505004883
Validation loss: 2.0126705169677734

Epoch: 89| Step: 0
Training loss: 2.1547367572784424
Validation loss: 2.0186009804407754

Epoch: 6| Step: 1
Training loss: 1.8654241561889648
Validation loss: 2.0005259116490683

Epoch: 6| Step: 2
Training loss: 1.7497129440307617
Validation loss: 2.0339181423187256

Epoch: 6| Step: 3
Training loss: 1.3254646062850952
Validation loss: 2.0360342264175415

Epoch: 6| Step: 4
Training loss: 2.287266731262207
Validation loss: 2.0376501083374023

Epoch: 6| Step: 5
Training loss: 1.4668910503387451
Validation loss: 2.034278074900309

Epoch: 6| Step: 6
Training loss: 1.852627158164978
Validation loss: 2.0239019195238748

Epoch: 6| Step: 7
Training loss: 1.963500738143921
Validation loss: 2.0024317105611167

Epoch: 6| Step: 8
Training loss: 1.5694124698638916
Validation loss: 2.0254629453023276

Epoch: 6| Step: 9
Training loss: 2.1251087188720703
Validation loss: 2.024547795454661

Epoch: 6| Step: 10
Training loss: 2.0591936111450195
Validation loss: 2.0529398322105408

Epoch: 6| Step: 11
Training loss: 2.109158515930176
Validation loss: 2.1229762633641562

Epoch: 6| Step: 12
Training loss: 2.108722448348999
Validation loss: 2.136614123980204

Epoch: 6| Step: 13
Training loss: 1.4190964698791504
Validation loss: 2.1174148519833884

Epoch: 90| Step: 0
Training loss: 1.8198150396347046
Validation loss: 2.109408378601074

Epoch: 6| Step: 1
Training loss: 1.4684319496154785
Validation loss: 2.0856173237164817

Epoch: 6| Step: 2
Training loss: 1.4152826070785522
Validation loss: 2.0712326963742576

Epoch: 6| Step: 3
Training loss: 1.609866976737976
Validation loss: 2.0461734930674234

Epoch: 6| Step: 4
Training loss: 2.281297206878662
Validation loss: 2.052936832110087

Epoch: 6| Step: 5
Training loss: 2.5141801834106445
Validation loss: 2.0082761446634927

Epoch: 6| Step: 6
Training loss: 2.0447418689727783
Validation loss: 2.0272963444391885

Epoch: 6| Step: 7
Training loss: 1.8917230367660522
Validation loss: 2.00661168495814

Epoch: 6| Step: 8
Training loss: 2.142875909805298
Validation loss: 2.0150060852368674

Epoch: 6| Step: 9
Training loss: 1.3931063413619995
Validation loss: 2.0178018609682717

Epoch: 6| Step: 10
Training loss: 1.7739126682281494
Validation loss: 2.023560384909312

Epoch: 6| Step: 11
Training loss: 1.297514796257019
Validation loss: 1.9982255498568218

Epoch: 6| Step: 12
Training loss: 2.061063289642334
Validation loss: 2.015038311481476

Epoch: 6| Step: 13
Training loss: 1.5891649723052979
Validation loss: 2.0299314061800637

Epoch: 91| Step: 0
Training loss: 1.8611276149749756
Validation loss: 2.0283236106236777

Epoch: 6| Step: 1
Training loss: 1.8529058694839478
Validation loss: 2.0052802364031472

Epoch: 6| Step: 2
Training loss: 0.9599976539611816
Validation loss: 2.0460934241612754

Epoch: 6| Step: 3
Training loss: 2.379486322402954
Validation loss: 2.0493301351865134

Epoch: 6| Step: 4
Training loss: 2.1336615085601807
Validation loss: 2.0487438241640725

Epoch: 6| Step: 5
Training loss: 1.5454914569854736
Validation loss: 2.044879992802938

Epoch: 6| Step: 6
Training loss: 1.3690054416656494
Validation loss: 2.063826302687327

Epoch: 6| Step: 7
Training loss: 2.082833766937256
Validation loss: 2.04168164730072

Epoch: 6| Step: 8
Training loss: 1.7236051559448242
Validation loss: 2.039431711037954

Epoch: 6| Step: 9
Training loss: 1.7785226106643677
Validation loss: 2.0491772294044495

Epoch: 6| Step: 10
Training loss: 2.068274974822998
Validation loss: 2.019428531328837

Epoch: 6| Step: 11
Training loss: 1.438464879989624
Validation loss: 2.010116696357727

Epoch: 6| Step: 12
Training loss: 2.5594849586486816
Validation loss: 2.012659013271332

Epoch: 6| Step: 13
Training loss: 1.3246355056762695
Validation loss: 2.0028889576594033

Epoch: 92| Step: 0
Training loss: 1.3178796768188477
Validation loss: 1.9934608936309814

Epoch: 6| Step: 1
Training loss: 1.644086241722107
Validation loss: 2.0167418320973716

Epoch: 6| Step: 2
Training loss: 1.3096261024475098
Validation loss: 1.9894501368204753

Epoch: 6| Step: 3
Training loss: 1.866707444190979
Validation loss: 2.013815482457479

Epoch: 6| Step: 4
Training loss: 1.7419809103012085
Validation loss: 2.0312588214874268

Epoch: 6| Step: 5
Training loss: 1.7904460430145264
Validation loss: 2.015606423219045

Epoch: 6| Step: 6
Training loss: 1.6333309412002563
Validation loss: 2.0176053643226624

Epoch: 6| Step: 7
Training loss: 2.217959403991699
Validation loss: 2.0701327125231423

Epoch: 6| Step: 8
Training loss: 2.081338405609131
Validation loss: 2.0466464360555015

Epoch: 6| Step: 9
Training loss: 2.049376964569092
Validation loss: 2.0548547506332397

Epoch: 6| Step: 10
Training loss: 1.6063965559005737
Validation loss: 2.0697919527689614

Epoch: 6| Step: 11
Training loss: 2.3416333198547363
Validation loss: 2.052484095096588

Epoch: 6| Step: 12
Training loss: 2.513291120529175
Validation loss: 2.053041140238444

Epoch: 6| Step: 13
Training loss: 1.0161240100860596
Validation loss: 2.0550398429234824

Epoch: 93| Step: 0
Training loss: 1.8234635591506958
Validation loss: 2.033693512280782

Epoch: 6| Step: 1
Training loss: 1.5777442455291748
Validation loss: 2.045792738596598

Epoch: 6| Step: 2
Training loss: 1.9614189863204956
Validation loss: 2.0029733578364053

Epoch: 6| Step: 3
Training loss: 2.1254138946533203
Validation loss: 2.013473113377889

Epoch: 6| Step: 4
Training loss: 2.2874999046325684
Validation loss: 2.0267335176467896

Epoch: 6| Step: 5
Training loss: 1.991091251373291
Validation loss: 2.008909225463867

Epoch: 6| Step: 6
Training loss: 1.984670877456665
Validation loss: 2.0182790557543435

Epoch: 6| Step: 7
Training loss: 2.3116750717163086
Validation loss: 1.9847634832064311

Epoch: 6| Step: 8
Training loss: 1.1011323928833008
Validation loss: 2.034183462460836

Epoch: 6| Step: 9
Training loss: 1.5391743183135986
Validation loss: 2.0217271645863852

Epoch: 6| Step: 10
Training loss: 1.7049959897994995
Validation loss: 2.009573539098104

Epoch: 6| Step: 11
Training loss: 1.7753350734710693
Validation loss: 2.019769310951233

Epoch: 6| Step: 12
Training loss: 2.0148394107818604
Validation loss: 1.999690095583598

Epoch: 6| Step: 13
Training loss: 0.9394249320030212
Validation loss: 2.0150440533955893

Epoch: 94| Step: 0
Training loss: 2.104559898376465
Validation loss: 2.035231113433838

Epoch: 6| Step: 1
Training loss: 1.5619454383850098
Validation loss: 2.0307243267695108

Epoch: 6| Step: 2
Training loss: 1.4213718175888062
Validation loss: 2.071399708588918

Epoch: 6| Step: 3
Training loss: 1.660370111465454
Validation loss: 2.055996219317118

Epoch: 6| Step: 4
Training loss: 1.5679590702056885
Validation loss: 2.0406086246172586

Epoch: 6| Step: 5
Training loss: 2.738199234008789
Validation loss: 2.0445167223612466

Epoch: 6| Step: 6
Training loss: 2.1439332962036133
Validation loss: 2.0159440437952676

Epoch: 6| Step: 7
Training loss: 1.5553085803985596
Validation loss: 1.998323102792104

Epoch: 6| Step: 8
Training loss: 1.5266627073287964
Validation loss: 2.024135152498881

Epoch: 6| Step: 9
Training loss: 1.424298644065857
Validation loss: 2.00575844446818

Epoch: 6| Step: 10
Training loss: 1.8609931468963623
Validation loss: 2.0032202204068503

Epoch: 6| Step: 11
Training loss: 1.8359336853027344
Validation loss: 2.0054343144098916

Epoch: 6| Step: 12
Training loss: 1.6275380849838257
Validation loss: 2.0219013492266336

Epoch: 6| Step: 13
Training loss: 2.045311450958252
Validation loss: 2.0340197682380676

Epoch: 95| Step: 0
Training loss: 2.04522705078125
Validation loss: 2.052371541659037

Epoch: 6| Step: 1
Training loss: 1.3906545639038086
Validation loss: 2.060883939266205

Epoch: 6| Step: 2
Training loss: 1.665298342704773
Validation loss: 2.0563616951306662

Epoch: 6| Step: 3
Training loss: 1.9035158157348633
Validation loss: 2.088356077671051

Epoch: 6| Step: 4
Training loss: 1.7804234027862549
Validation loss: 2.0802073081334433

Epoch: 6| Step: 5
Training loss: 1.7852437496185303
Validation loss: 2.075134555498759

Epoch: 6| Step: 6
Training loss: 2.064725875854492
Validation loss: 2.053624212741852

Epoch: 6| Step: 7
Training loss: 1.5348119735717773
Validation loss: 2.037936588128408

Epoch: 6| Step: 8
Training loss: 1.8661766052246094
Validation loss: 2.056858857472738

Epoch: 6| Step: 9
Training loss: 1.6208678483963013
Validation loss: 2.0366563399632773

Epoch: 6| Step: 10
Training loss: 1.8423893451690674
Validation loss: 2.043669819831848

Epoch: 6| Step: 11
Training loss: 1.9472198486328125
Validation loss: 1.9859609206517537

Epoch: 6| Step: 12
Training loss: 1.6196253299713135
Validation loss: 2.0206220746040344

Epoch: 6| Step: 13
Training loss: 1.83524489402771
Validation loss: 2.019557237625122

Epoch: 96| Step: 0
Training loss: 2.5089612007141113
Validation loss: 2.02102792263031

Epoch: 6| Step: 1
Training loss: 1.8811981678009033
Validation loss: 1.9956374367078145

Epoch: 6| Step: 2
Training loss: 1.3469831943511963
Validation loss: 2.0170978903770447

Epoch: 6| Step: 3
Training loss: 2.199263572692871
Validation loss: 2.022171676158905

Epoch: 6| Step: 4
Training loss: 1.4912574291229248
Validation loss: 2.0049471060434976

Epoch: 6| Step: 5
Training loss: 1.6263539791107178
Validation loss: 2.0250317454338074

Epoch: 6| Step: 6
Training loss: 1.8322155475616455
Validation loss: 2.0295901695887246

Epoch: 6| Step: 7
Training loss: 1.835382103919983
Validation loss: 2.0186084111531577

Epoch: 6| Step: 8
Training loss: 1.271863341331482
Validation loss: 2.063832998275757

Epoch: 6| Step: 9
Training loss: 1.7180843353271484
Validation loss: 2.0673217177391052

Epoch: 6| Step: 10
Training loss: 1.841957926750183
Validation loss: 2.0440844694773355

Epoch: 6| Step: 11
Training loss: 1.983626127243042
Validation loss: 2.0446998278299966

Epoch: 6| Step: 12
Training loss: 1.30417799949646
Validation loss: 2.0200971762339273

Epoch: 6| Step: 13
Training loss: 1.862762689590454
Validation loss: 2.0378877321879068

Epoch: 97| Step: 0
Training loss: 1.7325893640518188
Validation loss: 2.0519051353136697

Epoch: 6| Step: 1
Training loss: 2.1060571670532227
Validation loss: 2.042328953742981

Epoch: 6| Step: 2
Training loss: 1.4386050701141357
Validation loss: 2.0648228526115417

Epoch: 6| Step: 3
Training loss: 1.8799991607666016
Validation loss: 2.0853867530822754

Epoch: 6| Step: 4
Training loss: 1.161740779876709
Validation loss: 2.080196758111318

Epoch: 6| Step: 5
Training loss: 1.7460788488388062
Validation loss: 2.075624664624532

Epoch: 6| Step: 6
Training loss: 1.8327200412750244
Validation loss: 2.04569943745931

Epoch: 6| Step: 7
Training loss: 2.9517781734466553
Validation loss: 2.0454928278923035

Epoch: 6| Step: 8
Training loss: 1.247513771057129
Validation loss: 2.031658867994944

Epoch: 6| Step: 9
Training loss: 2.1335577964782715
Validation loss: 2.0028845071792603

Epoch: 6| Step: 10
Training loss: 1.2744635343551636
Validation loss: 1.9833365281422932

Epoch: 6| Step: 11
Training loss: 1.9038212299346924
Validation loss: 2.0490116278330484

Epoch: 6| Step: 12
Training loss: 1.4459853172302246
Validation loss: 2.0515016913414

Epoch: 6| Step: 13
Training loss: 2.1903018951416016
Validation loss: 2.0598857402801514

Epoch: 98| Step: 0
Training loss: 1.5015015602111816
Validation loss: 2.03574401140213

Epoch: 6| Step: 1
Training loss: 1.8910478353500366
Validation loss: 2.036416252454122

Epoch: 6| Step: 2
Training loss: 2.047450065612793
Validation loss: 2.0428929726282754

Epoch: 6| Step: 3
Training loss: 1.82593834400177
Validation loss: 2.003650744756063

Epoch: 6| Step: 4
Training loss: 1.3583660125732422
Validation loss: 2.0009005268414817

Epoch: 6| Step: 5
Training loss: 1.9491543769836426
Validation loss: 2.0344921549161277

Epoch: 6| Step: 6
Training loss: 1.400783896446228
Validation loss: 2.0404329697291055

Epoch: 6| Step: 7
Training loss: 2.101710796356201
Validation loss: 2.016181747118632

Epoch: 6| Step: 8
Training loss: 1.3584513664245605
Validation loss: 2.036649485429128

Epoch: 6| Step: 9
Training loss: 1.6735360622406006
Validation loss: 2.037408093611399

Epoch: 6| Step: 10
Training loss: 2.146773338317871
Validation loss: 2.062389691670736

Epoch: 6| Step: 11
Training loss: 1.8178213834762573
Validation loss: 2.074897209803263

Epoch: 6| Step: 12
Training loss: 1.7016642093658447
Validation loss: 2.0971364776293435

Epoch: 6| Step: 13
Training loss: 1.61189603805542
Validation loss: 2.106359581152598

Epoch: 99| Step: 0
Training loss: 1.9502969980239868
Validation loss: 2.1083991328875222

Epoch: 6| Step: 1
Training loss: 1.7810057401657104
Validation loss: 2.0691707531611123

Epoch: 6| Step: 2
Training loss: 2.1688942909240723
Validation loss: 2.074137528737386

Epoch: 6| Step: 3
Training loss: 2.4121599197387695
Validation loss: 2.0277019739151

Epoch: 6| Step: 4
Training loss: 1.218505859375
Validation loss: 2.0277087688446045

Epoch: 6| Step: 5
Training loss: 2.0772581100463867
Validation loss: 2.014852285385132

Epoch: 6| Step: 6
Training loss: 0.9143476486206055
Validation loss: 2.005537490049998

Epoch: 6| Step: 7
Training loss: 2.08294677734375
Validation loss: 2.018536547819773

Epoch: 6| Step: 8
Training loss: 2.1550891399383545
Validation loss: 2.0006789167722068

Epoch: 6| Step: 9
Training loss: 1.9151160717010498
Validation loss: 2.026604096094767

Epoch: 6| Step: 10
Training loss: 1.8298509120941162
Validation loss: 2.0263845920562744

Epoch: 6| Step: 11
Training loss: 1.572594404220581
Validation loss: 1.9936877886454265

Epoch: 6| Step: 12
Training loss: 1.3653160333633423
Validation loss: 2.0266632636388144

Epoch: 6| Step: 13
Training loss: 1.3060197830200195
Validation loss: 1.9996411800384521

Epoch: 100| Step: 0
Training loss: 1.781618356704712
Validation loss: 2.0349588791529336

Epoch: 6| Step: 1
Training loss: 1.4370405673980713
Validation loss: 2.0962135593096414

Epoch: 6| Step: 2
Training loss: 1.9241210222244263
Validation loss: 2.0700490276018777

Epoch: 6| Step: 3
Training loss: 2.015118360519409
Validation loss: 2.0791012048721313

Epoch: 6| Step: 4
Training loss: 1.7846084833145142
Validation loss: 2.064257542292277

Epoch: 6| Step: 5
Training loss: 2.120333433151245
Validation loss: 2.0708988904953003

Epoch: 6| Step: 6
Training loss: 1.5499482154846191
Validation loss: 2.0400875012079873

Epoch: 6| Step: 7
Training loss: 1.8226854801177979
Validation loss: 2.022164543469747

Epoch: 6| Step: 8
Training loss: 2.4260451793670654
Validation loss: 2.018346885840098

Epoch: 6| Step: 9
Training loss: 1.1197588443756104
Validation loss: 2.031791011492411

Epoch: 6| Step: 10
Training loss: 1.7003264427185059
Validation loss: 2.012067715326945

Epoch: 6| Step: 11
Training loss: 1.4234569072723389
Validation loss: 2.000201145807902

Epoch: 6| Step: 12
Training loss: 1.1463518142700195
Validation loss: 1.997538963953654

Epoch: 6| Step: 13
Training loss: 2.359933853149414
Validation loss: 2.0240356723467507

Epoch: 101| Step: 0
Training loss: 0.990583598613739
Validation loss: 2.0310178399086

Epoch: 6| Step: 1
Training loss: 1.6413898468017578
Validation loss: 2.0039778550465903

Epoch: 6| Step: 2
Training loss: 1.8515568971633911
Validation loss: 2.0178561011950173

Epoch: 6| Step: 3
Training loss: 1.6315817832946777
Validation loss: 2.0227089524269104

Epoch: 6| Step: 4
Training loss: 1.2334601879119873
Validation loss: 2.024808665116628

Epoch: 6| Step: 5
Training loss: 2.724970817565918
Validation loss: 2.030826210975647

Epoch: 6| Step: 6
Training loss: 2.069456100463867
Validation loss: 2.026592036088308

Epoch: 6| Step: 7
Training loss: 1.4334561824798584
Validation loss: 2.0418978730837503

Epoch: 6| Step: 8
Training loss: 1.6488611698150635
Validation loss: 2.0121731559435525

Epoch: 6| Step: 9
Training loss: 1.7157468795776367
Validation loss: 2.035874048868815

Epoch: 6| Step: 10
Training loss: 2.1347227096557617
Validation loss: 2.0641114314397178

Epoch: 6| Step: 11
Training loss: 0.9970056414604187
Validation loss: 2.0553831259409585

Epoch: 6| Step: 12
Training loss: 2.000732421875
Validation loss: 2.073773721853892

Epoch: 6| Step: 13
Training loss: 1.907265067100525
Validation loss: 2.1117276151974997

Epoch: 102| Step: 0
Training loss: 1.826529622077942
Validation loss: 2.100488543510437

Epoch: 6| Step: 1
Training loss: 1.931447982788086
Validation loss: 2.094149967034658

Epoch: 6| Step: 2
Training loss: 2.0397591590881348
Validation loss: 2.0828356941541037

Epoch: 6| Step: 3
Training loss: 1.904538631439209
Validation loss: 2.0435061852137246

Epoch: 6| Step: 4
Training loss: 2.424020290374756
Validation loss: 2.060160140196482

Epoch: 6| Step: 5
Training loss: 2.024223566055298
Validation loss: 2.029078642527262

Epoch: 6| Step: 6
Training loss: 1.9567463397979736
Validation loss: 2.0479535659154258

Epoch: 6| Step: 7
Training loss: 1.165616750717163
Validation loss: 2.0213074485460916

Epoch: 6| Step: 8
Training loss: 0.8909119963645935
Validation loss: 2.022723396619161

Epoch: 6| Step: 9
Training loss: 1.4521675109863281
Validation loss: 2.007421294848124

Epoch: 6| Step: 10
Training loss: 1.480400562286377
Validation loss: 2.004314879576365

Epoch: 6| Step: 11
Training loss: 1.3312129974365234
Validation loss: 1.9704633355140686

Epoch: 6| Step: 12
Training loss: 2.2444891929626465
Validation loss: 2.0089070399602256

Epoch: 6| Step: 13
Training loss: 1.7020025253295898
Validation loss: 2.033234119415283

Epoch: 103| Step: 0
Training loss: 2.058332920074463
Validation loss: 2.051896552244822

Epoch: 6| Step: 1
Training loss: 1.8719837665557861
Validation loss: 2.03551052014033

Epoch: 6| Step: 2
Training loss: 1.7056236267089844
Validation loss: 2.048638860384623

Epoch: 6| Step: 3
Training loss: 1.3537896871566772
Validation loss: 2.024087051550547

Epoch: 6| Step: 4
Training loss: 1.9767425060272217
Validation loss: 2.0581697622934976

Epoch: 6| Step: 5
Training loss: 1.8017624616622925
Validation loss: 2.038208802541097

Epoch: 6| Step: 6
Training loss: 1.7312384843826294
Validation loss: 2.0233373244603476

Epoch: 6| Step: 7
Training loss: 2.4412052631378174
Validation loss: 2.035216669241587

Epoch: 6| Step: 8
Training loss: 1.5818506479263306
Validation loss: 2.0091106494267783

Epoch: 6| Step: 9
Training loss: 1.603461503982544
Validation loss: 2.048512121041616

Epoch: 6| Step: 10
Training loss: 1.5101006031036377
Validation loss: 2.0181519190470376

Epoch: 6| Step: 11
Training loss: 0.9974174499511719
Validation loss: 2.0183932781219482

Epoch: 6| Step: 12
Training loss: 1.5345613956451416
Validation loss: 2.0153122941652932

Epoch: 6| Step: 13
Training loss: 1.6998701095581055
Validation loss: 2.013441562652588

Epoch: 104| Step: 0
Training loss: 1.4829132556915283
Validation loss: 2.018255968888601

Epoch: 6| Step: 1
Training loss: 1.648921251296997
Validation loss: 2.030669093132019

Epoch: 6| Step: 2
Training loss: 1.442838191986084
Validation loss: 2.0271684726079306

Epoch: 6| Step: 3
Training loss: 1.3845627307891846
Validation loss: 2.0519641240437827

Epoch: 6| Step: 4
Training loss: 1.7267241477966309
Validation loss: 2.0442605018615723

Epoch: 6| Step: 5
Training loss: 1.9869215488433838
Validation loss: 2.0620452165603638

Epoch: 6| Step: 6
Training loss: 1.7816176414489746
Validation loss: 2.00588188568751

Epoch: 6| Step: 7
Training loss: 1.654946208000183
Validation loss: 2.006394843260447

Epoch: 6| Step: 8
Training loss: 1.4371943473815918
Validation loss: 2.01995321114858

Epoch: 6| Step: 9
Training loss: 2.3194527626037598
Validation loss: 2.00856477022171

Epoch: 6| Step: 10
Training loss: 1.7773137092590332
Validation loss: 2.023923675219218

Epoch: 6| Step: 11
Training loss: 1.975771188735962
Validation loss: 1.999172568321228

Epoch: 6| Step: 12
Training loss: 1.2521950006484985
Validation loss: 2.031386077404022

Epoch: 6| Step: 13
Training loss: 1.8216326236724854
Validation loss: 2.037974258263906

Epoch: 105| Step: 0
Training loss: 1.2696499824523926
Validation loss: 2.0355411569277444

Epoch: 6| Step: 1
Training loss: 1.3210241794586182
Validation loss: 2.0455177227656045

Epoch: 6| Step: 2
Training loss: 1.2368634939193726
Validation loss: 2.017983376979828

Epoch: 6| Step: 3
Training loss: 2.5396194458007812
Validation loss: 2.04682989915212

Epoch: 6| Step: 4
Training loss: 1.7115275859832764
Validation loss: 2.03130575021108

Epoch: 6| Step: 5
Training loss: 1.148932933807373
Validation loss: 2.023104727268219

Epoch: 6| Step: 6
Training loss: 2.1584677696228027
Validation loss: 2.0136369268099465

Epoch: 6| Step: 7
Training loss: 1.9314879179000854
Validation loss: 1.9967978398005168

Epoch: 6| Step: 8
Training loss: 2.0838418006896973
Validation loss: 2.0204827586809793

Epoch: 6| Step: 9
Training loss: 1.375218391418457
Validation loss: 1.9982788562774658

Epoch: 6| Step: 10
Training loss: 1.3839049339294434
Validation loss: 2.0322050054868064

Epoch: 6| Step: 11
Training loss: 1.748913288116455
Validation loss: 2.0360707441965737

Epoch: 6| Step: 12
Training loss: 1.4964251518249512
Validation loss: 2.0487079421679177

Epoch: 6| Step: 13
Training loss: 2.4467544555664062
Validation loss: 2.0367153882980347

Epoch: 106| Step: 0
Training loss: 1.5956776142120361
Validation loss: 2.0396053791046143

Epoch: 6| Step: 1
Training loss: 1.4232170581817627
Validation loss: 2.0185863375663757

Epoch: 6| Step: 2
Training loss: 1.4556776285171509
Validation loss: 2.0291027228037515

Epoch: 6| Step: 3
Training loss: 2.2128679752349854
Validation loss: 2.0155099829037986

Epoch: 6| Step: 4
Training loss: 1.3406027555465698
Validation loss: 2.0234095454216003

Epoch: 6| Step: 5
Training loss: 1.8471156358718872
Validation loss: 2.0363915959993997

Epoch: 6| Step: 6
Training loss: 1.3433983325958252
Validation loss: 2.0283518632253013

Epoch: 6| Step: 7
Training loss: 1.5102683305740356
Validation loss: 2.0064603288968406

Epoch: 6| Step: 8
Training loss: 1.7199623584747314
Validation loss: 2.022475481033325

Epoch: 6| Step: 9
Training loss: 1.8007069826126099
Validation loss: 2.031627058982849

Epoch: 6| Step: 10
Training loss: 2.1071062088012695
Validation loss: 2.027578592300415

Epoch: 6| Step: 11
Training loss: 1.6855685710906982
Validation loss: 2.0547581911087036

Epoch: 6| Step: 12
Training loss: 1.5539456605911255
Validation loss: 2.043722152709961

Epoch: 6| Step: 13
Training loss: 1.5624234676361084
Validation loss: 2.0429533322652182

Epoch: 107| Step: 0
Training loss: 1.3954105377197266
Validation loss: 2.065072695414225

Epoch: 6| Step: 1
Training loss: 1.935703992843628
Validation loss: 2.041209359963735

Epoch: 6| Step: 2
Training loss: 0.9214351177215576
Validation loss: 2.0332763393719993

Epoch: 6| Step: 3
Training loss: 1.788914442062378
Validation loss: 2.0313854217529297

Epoch: 6| Step: 4
Training loss: 1.4131821393966675
Validation loss: 2.042250672976176

Epoch: 6| Step: 5
Training loss: 1.7495718002319336
Validation loss: 2.0436330238978067

Epoch: 6| Step: 6
Training loss: 1.801945686340332
Validation loss: 2.015466868877411

Epoch: 6| Step: 7
Training loss: 2.147757053375244
Validation loss: 1.9881561001141865

Epoch: 6| Step: 8
Training loss: 1.5981756448745728
Validation loss: 2.020209709803263

Epoch: 6| Step: 9
Training loss: 2.1437103748321533
Validation loss: 2.0133428374926248

Epoch: 6| Step: 10
Training loss: 1.7981075048446655
Validation loss: 2.0151024063428244

Epoch: 6| Step: 11
Training loss: 1.42713463306427
Validation loss: 2.002963443597158

Epoch: 6| Step: 12
Training loss: 1.4146064519882202
Validation loss: 1.9981942375500996

Epoch: 6| Step: 13
Training loss: 1.804584264755249
Validation loss: 1.9954956372578938

Epoch: 108| Step: 0
Training loss: 1.5785877704620361
Validation loss: 2.019966165224711

Epoch: 6| Step: 1
Training loss: 1.5749750137329102
Validation loss: 2.0108548402786255

Epoch: 6| Step: 2
Training loss: 1.4380850791931152
Validation loss: 2.0149526993433633

Epoch: 6| Step: 3
Training loss: 1.7554388046264648
Validation loss: 2.037344535191854

Epoch: 6| Step: 4
Training loss: 1.7452367544174194
Validation loss: 2.050783892472585

Epoch: 6| Step: 5
Training loss: 2.2750086784362793
Validation loss: 2.0658002495765686

Epoch: 6| Step: 6
Training loss: 1.291350245475769
Validation loss: 2.0863559246063232

Epoch: 6| Step: 7
Training loss: 1.6539137363433838
Validation loss: 2.03568967183431

Epoch: 6| Step: 8
Training loss: 1.877850890159607
Validation loss: 2.0789928038915

Epoch: 6| Step: 9
Training loss: 1.9383964538574219
Validation loss: 2.0257943073908486

Epoch: 6| Step: 10
Training loss: 0.991019606590271
Validation loss: 2.030186196168264

Epoch: 6| Step: 11
Training loss: 2.0469319820404053
Validation loss: 2.0319334467252097

Epoch: 6| Step: 12
Training loss: 1.594227910041809
Validation loss: 2.0157713095347085

Epoch: 6| Step: 13
Training loss: 1.7536457777023315
Validation loss: 2.007997671763102

Epoch: 109| Step: 0
Training loss: 2.0857818126678467
Validation loss: 2.0197725693384805

Epoch: 6| Step: 1
Training loss: 1.3472946882247925
Validation loss: 2.0255401929219565

Epoch: 6| Step: 2
Training loss: 2.0508556365966797
Validation loss: 2.024286131064097

Epoch: 6| Step: 3
Training loss: 1.6267223358154297
Validation loss: 2.0256667335828147

Epoch: 6| Step: 4
Training loss: 1.1624032258987427
Validation loss: 1.9964990814526875

Epoch: 6| Step: 5
Training loss: 1.3944833278656006
Validation loss: 2.020364205042521

Epoch: 6| Step: 6
Training loss: 1.4963464736938477
Validation loss: 1.995958646138509

Epoch: 6| Step: 7
Training loss: 1.9268074035644531
Validation loss: 2.028815984725952

Epoch: 6| Step: 8
Training loss: 1.4262065887451172
Validation loss: 2.0207422971725464

Epoch: 6| Step: 9
Training loss: 1.9164069890975952
Validation loss: 2.0363702376683555

Epoch: 6| Step: 10
Training loss: 1.6949996948242188
Validation loss: 2.0466880400975547

Epoch: 6| Step: 11
Training loss: 1.2465362548828125
Validation loss: 2.037508567174276

Epoch: 6| Step: 12
Training loss: 1.8253450393676758
Validation loss: 2.071745296319326

Epoch: 6| Step: 13
Training loss: 1.9111442565917969
Validation loss: 2.0480955441792807

Epoch: 110| Step: 0
Training loss: 1.656797170639038
Validation loss: 2.0618191162745156

Epoch: 6| Step: 1
Training loss: 1.6749157905578613
Validation loss: 2.0908228158950806

Epoch: 6| Step: 2
Training loss: 2.0103065967559814
Validation loss: 2.095850129922231

Epoch: 6| Step: 3
Training loss: 1.2176451683044434
Validation loss: 2.077284495035807

Epoch: 6| Step: 4
Training loss: 1.7776637077331543
Validation loss: 2.096619506676992

Epoch: 6| Step: 5
Training loss: 1.7726027965545654
Validation loss: 2.0738555192947388

Epoch: 6| Step: 6
Training loss: 2.328434467315674
Validation loss: 2.069083054860433

Epoch: 6| Step: 7
Training loss: 1.482076644897461
Validation loss: 2.0245253841082254

Epoch: 6| Step: 8
Training loss: 2.358534336090088
Validation loss: 2.0276848673820496

Epoch: 6| Step: 9
Training loss: 1.1945641040802002
Validation loss: 2.0022147496541343

Epoch: 6| Step: 10
Training loss: 1.4923244714736938
Validation loss: 1.9979858199755351

Epoch: 6| Step: 11
Training loss: 1.4385887384414673
Validation loss: 2.0087263584136963

Epoch: 6| Step: 12
Training loss: 1.086153507232666
Validation loss: 2.003671487172445

Epoch: 6| Step: 13
Training loss: 1.1972174644470215
Validation loss: 1.985074758529663

Epoch: 111| Step: 0
Training loss: 1.465972661972046
Validation loss: 2.0186360081036887

Epoch: 6| Step: 1
Training loss: 1.3698406219482422
Validation loss: 1.9977887868881226

Epoch: 6| Step: 2
Training loss: 1.573399543762207
Validation loss: 2.0391995708147683

Epoch: 6| Step: 3
Training loss: 1.4505856037139893
Validation loss: 2.0532461404800415

Epoch: 6| Step: 4
Training loss: 1.496802806854248
Validation loss: 2.0144708156585693

Epoch: 6| Step: 5
Training loss: 1.7563203573226929
Validation loss: 2.0538583993911743

Epoch: 6| Step: 6
Training loss: 2.1401116847991943
Validation loss: 2.0382933417956033

Epoch: 6| Step: 7
Training loss: 2.012146234512329
Validation loss: 1.984182357788086

Epoch: 6| Step: 8
Training loss: 1.2628400325775146
Validation loss: 1.99185715119044

Epoch: 6| Step: 9
Training loss: 1.7355602979660034
Validation loss: 2.0261930028597512

Epoch: 6| Step: 10
Training loss: 1.6216936111450195
Validation loss: 2.017180939515432

Epoch: 6| Step: 11
Training loss: 1.6215003728866577
Validation loss: 2.0001794497172036

Epoch: 6| Step: 12
Training loss: 1.5713047981262207
Validation loss: 1.9920579592386882

Epoch: 6| Step: 13
Training loss: 1.4135311841964722
Validation loss: 2.0505303343137107

Epoch: 112| Step: 0
Training loss: 1.5353872776031494
Validation loss: 2.0873993635177612

Epoch: 6| Step: 1
Training loss: 1.4717750549316406
Validation loss: 2.072587867577871

Epoch: 6| Step: 2
Training loss: 1.339748740196228
Validation loss: 2.078637739022573

Epoch: 6| Step: 3
Training loss: 1.7244007587432861
Validation loss: 2.08346156279246

Epoch: 6| Step: 4
Training loss: 2.1033360958099365
Validation loss: 2.094399631023407

Epoch: 6| Step: 5
Training loss: 1.5930578708648682
Validation loss: 2.0841949383417764

Epoch: 6| Step: 6
Training loss: 2.1557843685150146
Validation loss: 2.03834331035614

Epoch: 6| Step: 7
Training loss: 1.8452019691467285
Validation loss: 2.030705451965332

Epoch: 6| Step: 8
Training loss: 1.6591010093688965
Validation loss: 2.0086600383122764

Epoch: 6| Step: 9
Training loss: 1.6765778064727783
Validation loss: 1.996127227942149

Epoch: 6| Step: 10
Training loss: 1.83536958694458
Validation loss: 2.040003021558126

Epoch: 6| Step: 11
Training loss: 1.2814068794250488
Validation loss: 2.017921030521393

Epoch: 6| Step: 12
Training loss: 1.3979825973510742
Validation loss: 2.024893363316854

Epoch: 6| Step: 13
Training loss: 1.3306113481521606
Validation loss: 2.0211912194887796

Epoch: 113| Step: 0
Training loss: 2.048255443572998
Validation loss: 2.022107024987539

Epoch: 6| Step: 1
Training loss: 1.620534896850586
Validation loss: 2.0147327184677124

Epoch: 6| Step: 2
Training loss: 1.6903325319290161
Validation loss: 2.028953770796458

Epoch: 6| Step: 3
Training loss: 1.2422523498535156
Validation loss: 2.0390252073605857

Epoch: 6| Step: 4
Training loss: 1.4610402584075928
Validation loss: 2.0384229024251304

Epoch: 6| Step: 5
Training loss: 1.5087755918502808
Validation loss: 2.032183051109314

Epoch: 6| Step: 6
Training loss: 1.8363796472549438
Validation loss: 2.083977162837982

Epoch: 6| Step: 7
Training loss: 1.16519296169281
Validation loss: 2.077475825945536

Epoch: 6| Step: 8
Training loss: 1.271985650062561
Validation loss: 2.0869617263476052

Epoch: 6| Step: 9
Training loss: 1.8790940046310425
Validation loss: 2.0606722831726074

Epoch: 6| Step: 10
Training loss: 2.2877137660980225
Validation loss: 2.050400654474894

Epoch: 6| Step: 11
Training loss: 1.8443033695220947
Validation loss: 2.042112489541372

Epoch: 6| Step: 12
Training loss: 1.3094793558120728
Validation loss: 2.0371098121007285

Epoch: 6| Step: 13
Training loss: 1.7597036361694336
Validation loss: 2.057536800702413

Epoch: 114| Step: 0
Training loss: 1.9513016939163208
Validation loss: 2.055659214655558

Epoch: 6| Step: 1
Training loss: 1.7899385690689087
Validation loss: 2.0417996843655906

Epoch: 6| Step: 2
Training loss: 1.6758131980895996
Validation loss: 2.064000050226847

Epoch: 6| Step: 3
Training loss: 1.9856903553009033
Validation loss: 2.058688223361969

Epoch: 6| Step: 4
Training loss: 1.5671026706695557
Validation loss: 2.0651299556096396

Epoch: 6| Step: 5
Training loss: 1.6183271408081055
Validation loss: 2.039875010649363

Epoch: 6| Step: 6
Training loss: 1.6881461143493652
Validation loss: 2.022327105204264

Epoch: 6| Step: 7
Training loss: 1.5295671224594116
Validation loss: 2.027762989203135

Epoch: 6| Step: 8
Training loss: 1.4214167594909668
Validation loss: 2.0549305081367493

Epoch: 6| Step: 9
Training loss: 2.3219621181488037
Validation loss: 2.0636279781659446

Epoch: 6| Step: 10
Training loss: 1.7427968978881836
Validation loss: 2.089139183362325

Epoch: 6| Step: 11
Training loss: 1.315028429031372
Validation loss: 2.1240562001864114

Epoch: 6| Step: 12
Training loss: 1.6185553073883057
Validation loss: 2.0798517862955728

Epoch: 6| Step: 13
Training loss: 2.006218671798706
Validation loss: 2.0927987893422446

Epoch: 115| Step: 0
Training loss: 1.3390271663665771
Validation loss: 2.0413057605425515

Epoch: 6| Step: 1
Training loss: 1.0024316310882568
Validation loss: 2.059063990910848

Epoch: 6| Step: 2
Training loss: 1.361444354057312
Validation loss: 2.0107401808102927

Epoch: 6| Step: 3
Training loss: 1.2901501655578613
Validation loss: 2.0032348036766052

Epoch: 6| Step: 4
Training loss: 1.6150826215744019
Validation loss: 2.012882947921753

Epoch: 6| Step: 5
Training loss: 1.5884720087051392
Validation loss: 2.015653351942698

Epoch: 6| Step: 6
Training loss: 3.06449031829834
Validation loss: 2.024600307146708

Epoch: 6| Step: 7
Training loss: 1.7789509296417236
Validation loss: 2.028935492038727

Epoch: 6| Step: 8
Training loss: 1.5222598314285278
Validation loss: 2.015018900235494

Epoch: 6| Step: 9
Training loss: 2.020106554031372
Validation loss: 2.029148797194163

Epoch: 6| Step: 10
Training loss: 1.0649144649505615
Validation loss: 2.010092477003733

Epoch: 6| Step: 11
Training loss: 1.7611122131347656
Validation loss: 2.024808486302694

Epoch: 6| Step: 12
Training loss: 1.7393815517425537
Validation loss: 2.0057366092999778

Epoch: 6| Step: 13
Training loss: 1.6564579010009766
Validation loss: 2.0484258929888406

Epoch: 116| Step: 0
Training loss: 1.4612373113632202
Validation loss: 2.032100200653076

Epoch: 6| Step: 1
Training loss: 2.6350557804107666
Validation loss: 2.0231923262278237

Epoch: 6| Step: 2
Training loss: 0.9572182893753052
Validation loss: 2.0376922686894736

Epoch: 6| Step: 3
Training loss: 1.7168011665344238
Validation loss: 2.0293418367703757

Epoch: 6| Step: 4
Training loss: 1.6219987869262695
Validation loss: 2.0620588461558023

Epoch: 6| Step: 5
Training loss: 1.3426196575164795
Validation loss: 2.03303062915802

Epoch: 6| Step: 6
Training loss: 1.5722112655639648
Validation loss: 2.0239158868789673

Epoch: 6| Step: 7
Training loss: 1.316572666168213
Validation loss: 2.031547725200653

Epoch: 6| Step: 8
Training loss: 1.7686638832092285
Validation loss: 2.0086503624916077

Epoch: 6| Step: 9
Training loss: 1.6564109325408936
Validation loss: 2.005063831806183

Epoch: 6| Step: 10
Training loss: 1.2272803783416748
Validation loss: 2.0235931078592935

Epoch: 6| Step: 11
Training loss: 1.4787235260009766
Validation loss: 2.0041362245877585

Epoch: 6| Step: 12
Training loss: 2.05330228805542
Validation loss: 2.0310338735580444

Epoch: 6| Step: 13
Training loss: 1.6395689249038696
Validation loss: 2.059522867202759

Epoch: 117| Step: 0
Training loss: 2.177722930908203
Validation loss: 2.0736438632011414

Epoch: 6| Step: 1
Training loss: 1.1727745532989502
Validation loss: 2.0216254393259683

Epoch: 6| Step: 2
Training loss: 1.9495753049850464
Validation loss: 2.013026694456736

Epoch: 6| Step: 3
Training loss: 1.2365535497665405
Validation loss: 2.0108872850735984

Epoch: 6| Step: 4
Training loss: 1.6994882822036743
Validation loss: 2.0107741554578147

Epoch: 6| Step: 5
Training loss: 1.1487641334533691
Validation loss: 2.0325921773910522

Epoch: 6| Step: 6
Training loss: 1.988850712776184
Validation loss: 2.049890657265981

Epoch: 6| Step: 7
Training loss: 1.7027888298034668
Validation loss: 2.030659874280294

Epoch: 6| Step: 8
Training loss: 1.8488104343414307
Validation loss: 2.0296132564544678

Epoch: 6| Step: 9
Training loss: 1.087282419204712
Validation loss: 2.0088152090708413

Epoch: 6| Step: 10
Training loss: 1.6638836860656738
Validation loss: 2.02606854836146

Epoch: 6| Step: 11
Training loss: 1.3339154720306396
Validation loss: 2.0397866566975913

Epoch: 6| Step: 12
Training loss: 1.1251850128173828
Validation loss: 2.0310520132382712

Epoch: 6| Step: 13
Training loss: 2.0652637481689453
Validation loss: 2.01204522450765

Epoch: 118| Step: 0
Training loss: 1.1453583240509033
Validation loss: 1.9909967978795369

Epoch: 6| Step: 1
Training loss: 1.5028998851776123
Validation loss: 1.9966073433558147

Epoch: 6| Step: 2
Training loss: 1.8851655721664429
Validation loss: 2.0309516390164695

Epoch: 6| Step: 3
Training loss: 1.7053074836730957
Validation loss: 2.0512398878733316

Epoch: 6| Step: 4
Training loss: 1.3753187656402588
Validation loss: 2.024499992529551

Epoch: 6| Step: 5
Training loss: 1.5581759214401245
Validation loss: 2.025446832180023

Epoch: 6| Step: 6
Training loss: 1.2897398471832275
Validation loss: 2.0800939202308655

Epoch: 6| Step: 7
Training loss: 1.2130001783370972
Validation loss: 2.0678270061810813

Epoch: 6| Step: 8
Training loss: 1.766926646232605
Validation loss: 2.034438729286194

Epoch: 6| Step: 9
Training loss: 2.067607879638672
Validation loss: 2.0399447083473206

Epoch: 6| Step: 10
Training loss: 2.1348447799682617
Validation loss: 2.059296170870463

Epoch: 6| Step: 11
Training loss: 1.6220228672027588
Validation loss: 2.04196967681249

Epoch: 6| Step: 12
Training loss: 1.5692739486694336
Validation loss: 2.008230189482371

Epoch: 6| Step: 13
Training loss: 1.11638343334198
Validation loss: 2.0924015442530313

Epoch: 119| Step: 0
Training loss: 1.794104814529419
Validation loss: 2.028642495473226

Epoch: 6| Step: 1
Training loss: 1.7692034244537354
Validation loss: 2.038091719150543

Epoch: 6| Step: 2
Training loss: 2.2166903018951416
Validation loss: 2.055926740169525

Epoch: 6| Step: 3
Training loss: 1.6252665519714355
Validation loss: 2.0415425499280295

Epoch: 6| Step: 4
Training loss: 1.4006943702697754
Validation loss: 2.0481332540512085

Epoch: 6| Step: 5
Training loss: 1.5313539505004883
Validation loss: 2.0234223008155823

Epoch: 6| Step: 6
Training loss: 0.9790376424789429
Validation loss: 2.0292078455289206

Epoch: 6| Step: 7
Training loss: 1.6949689388275146
Validation loss: 2.027860482533773

Epoch: 6| Step: 8
Training loss: 1.703450083732605
Validation loss: 2.044779141743978

Epoch: 6| Step: 9
Training loss: 1.3508485555648804
Validation loss: 2.051176349322001

Epoch: 6| Step: 10
Training loss: 0.9659147262573242
Validation loss: 2.048584759235382

Epoch: 6| Step: 11
Training loss: 1.9024176597595215
Validation loss: 2.0526042580604553

Epoch: 6| Step: 12
Training loss: 1.5649034976959229
Validation loss: 2.038755218187968

Epoch: 6| Step: 13
Training loss: 1.782236099243164
Validation loss: 2.0447180469830832

Epoch: 120| Step: 0
Training loss: 1.7633588314056396
Validation loss: 2.036211927731832

Epoch: 6| Step: 1
Training loss: 1.1829094886779785
Validation loss: 2.0236316919326782

Epoch: 6| Step: 2
Training loss: 1.254860758781433
Validation loss: 2.0586032470067344

Epoch: 6| Step: 3
Training loss: 1.2317368984222412
Validation loss: 2.0143652160962424

Epoch: 6| Step: 4
Training loss: 1.1930574178695679
Validation loss: 2.036105493704478

Epoch: 6| Step: 5
Training loss: 1.2779388427734375
Validation loss: 2.027237832546234

Epoch: 6| Step: 6
Training loss: 1.5337038040161133
Validation loss: 2.029828210671743

Epoch: 6| Step: 7
Training loss: 2.518697738647461
Validation loss: 2.039718767007192

Epoch: 6| Step: 8
Training loss: 1.932701587677002
Validation loss: 2.0419262250264487

Epoch: 6| Step: 9
Training loss: 1.0904655456542969
Validation loss: 2.0211998422940574

Epoch: 6| Step: 10
Training loss: 1.536048173904419
Validation loss: 2.009030361970266

Epoch: 6| Step: 11
Training loss: 2.186221122741699
Validation loss: 2.060182511806488

Epoch: 6| Step: 12
Training loss: 2.007561683654785
Validation loss: 2.041012704372406

Epoch: 6| Step: 13
Training loss: 1.092447280883789
Validation loss: 2.025008956591288

Epoch: 121| Step: 0
Training loss: 1.5763537883758545
Validation loss: 2.05315770705541

Epoch: 6| Step: 1
Training loss: 1.3550976514816284
Validation loss: 2.071105400721232

Epoch: 6| Step: 2
Training loss: 1.1305148601531982
Validation loss: 2.0226231018702188

Epoch: 6| Step: 3
Training loss: 1.8590614795684814
Validation loss: 2.042659322420756

Epoch: 6| Step: 4
Training loss: 1.6895310878753662
Validation loss: 2.0223249395688376

Epoch: 6| Step: 5
Training loss: 1.2449002265930176
Validation loss: 2.008294105529785

Epoch: 6| Step: 6
Training loss: 1.4483625888824463
Validation loss: 2.031256834665934

Epoch: 6| Step: 7
Training loss: 1.8723161220550537
Validation loss: 2.0403566360473633

Epoch: 6| Step: 8
Training loss: 0.950093686580658
Validation loss: 2.045487622419993

Epoch: 6| Step: 9
Training loss: 1.8314930200576782
Validation loss: 2.0469226439793906

Epoch: 6| Step: 10
Training loss: 1.581812858581543
Validation loss: 2.0383109152317047

Epoch: 6| Step: 11
Training loss: 1.205923318862915
Validation loss: 2.0516536831855774

Epoch: 6| Step: 12
Training loss: 1.8541274070739746
Validation loss: 2.0370609561602273

Epoch: 6| Step: 13
Training loss: 2.232361316680908
Validation loss: 2.0470431248346963

Epoch: 122| Step: 0
Training loss: 1.6303470134735107
Validation loss: 2.0512043833732605

Epoch: 6| Step: 1
Training loss: 1.8350757360458374
Validation loss: 2.034026086330414

Epoch: 6| Step: 2
Training loss: 1.707875370979309
Validation loss: 2.017287274201711

Epoch: 6| Step: 3
Training loss: 1.3324809074401855
Validation loss: 2.00068861246109

Epoch: 6| Step: 4
Training loss: 1.5316815376281738
Validation loss: 1.9928128123283386

Epoch: 6| Step: 5
Training loss: 1.1217882633209229
Validation loss: 2.029578904310862

Epoch: 6| Step: 6
Training loss: 1.3084146976470947
Validation loss: 2.0332048734029136

Epoch: 6| Step: 7
Training loss: 1.7119251489639282
Validation loss: 1.9903876384099324

Epoch: 6| Step: 8
Training loss: 1.8670284748077393
Validation loss: 2.0183448791503906

Epoch: 6| Step: 9
Training loss: 1.86114501953125
Validation loss: 2.0446173946062722

Epoch: 6| Step: 10
Training loss: 1.2462154626846313
Validation loss: 2.050324777762095

Epoch: 6| Step: 11
Training loss: 1.3283547163009644
Validation loss: 2.0754462281862893

Epoch: 6| Step: 12
Training loss: 1.3596067428588867
Validation loss: 2.0892569621404014

Epoch: 6| Step: 13
Training loss: 1.4869177341461182
Validation loss: 2.045714100201925

Epoch: 123| Step: 0
Training loss: 1.884014368057251
Validation loss: 2.045256237188975

Epoch: 6| Step: 1
Training loss: 0.8044106960296631
Validation loss: 2.0344017346700034

Epoch: 6| Step: 2
Training loss: 1.6988139152526855
Validation loss: 2.0400625665982566

Epoch: 6| Step: 3
Training loss: 2.1449553966522217
Validation loss: 2.024619936943054

Epoch: 6| Step: 4
Training loss: 1.4594290256500244
Validation loss: 2.0162283976872764

Epoch: 6| Step: 5
Training loss: 1.3906481266021729
Validation loss: 2.048564314842224

Epoch: 6| Step: 6
Training loss: 1.3410048484802246
Validation loss: 2.0694026748339334

Epoch: 6| Step: 7
Training loss: 1.5326778888702393
Validation loss: 2.045148332913717

Epoch: 6| Step: 8
Training loss: 1.352482557296753
Validation loss: 2.052993873755137

Epoch: 6| Step: 9
Training loss: 1.7066651582717896
Validation loss: 2.018748919169108

Epoch: 6| Step: 10
Training loss: 0.8064404726028442
Validation loss: 2.062450369199117

Epoch: 6| Step: 11
Training loss: 1.72149658203125
Validation loss: 2.0479581356048584

Epoch: 6| Step: 12
Training loss: 2.1359124183654785
Validation loss: 2.04035492738088

Epoch: 6| Step: 13
Training loss: 1.3659992218017578
Validation loss: 2.045907219250997

Epoch: 124| Step: 0
Training loss: 1.3248134851455688
Validation loss: 2.0239266951878867

Epoch: 6| Step: 1
Training loss: 1.5452160835266113
Validation loss: 2.0092808405558267

Epoch: 6| Step: 2
Training loss: 1.8695898056030273
Validation loss: 2.0035101970036826

Epoch: 6| Step: 3
Training loss: 1.662632703781128
Validation loss: 2.038113276163737

Epoch: 6| Step: 4
Training loss: 0.8745254278182983
Validation loss: 2.0520983934402466

Epoch: 6| Step: 5
Training loss: 1.9403038024902344
Validation loss: 2.0623976389567056

Epoch: 6| Step: 6
Training loss: 1.7364400625228882
Validation loss: 2.085810919602712

Epoch: 6| Step: 7
Training loss: 1.6743972301483154
Validation loss: 2.1110676725705466

Epoch: 6| Step: 8
Training loss: 1.6623603105545044
Validation loss: 2.0386593341827393

Epoch: 6| Step: 9
Training loss: 1.0374631881713867
Validation loss: 2.0696834524472556

Epoch: 6| Step: 10
Training loss: 1.2870328426361084
Validation loss: 2.072009325027466

Epoch: 6| Step: 11
Training loss: 1.2526381015777588
Validation loss: 2.0437776247660318

Epoch: 6| Step: 12
Training loss: 1.8683853149414062
Validation loss: 2.0337262948354087

Epoch: 6| Step: 13
Training loss: 1.8021634817123413
Validation loss: 2.0502318143844604

Epoch: 125| Step: 0
Training loss: 1.6826612949371338
Validation loss: 2.0581520398457847

Epoch: 6| Step: 1
Training loss: 1.2380199432373047
Validation loss: 2.0777419606844583

Epoch: 6| Step: 2
Training loss: 1.7017897367477417
Validation loss: 2.0856528282165527

Epoch: 6| Step: 3
Training loss: 1.6355485916137695
Validation loss: 2.041447559992472

Epoch: 6| Step: 4
Training loss: 2.02994441986084
Validation loss: 2.0259203910827637

Epoch: 6| Step: 5
Training loss: 1.9649076461791992
Validation loss: 2.0359755158424377

Epoch: 6| Step: 6
Training loss: 1.6135609149932861
Validation loss: 2.0386605262756348

Epoch: 6| Step: 7
Training loss: 1.5235602855682373
Validation loss: 2.0488275289535522

Epoch: 6| Step: 8
Training loss: 1.342452049255371
Validation loss: 2.00780580441157

Epoch: 6| Step: 9
Training loss: 1.3097847700119019
Validation loss: 2.011802355448405

Epoch: 6| Step: 10
Training loss: 1.342804193496704
Validation loss: 2.0469845732053122

Epoch: 6| Step: 11
Training loss: 1.6071691513061523
Validation loss: 2.0534210403760276

Epoch: 6| Step: 12
Training loss: 1.3471384048461914
Validation loss: 2.0691965421040854

Epoch: 6| Step: 13
Training loss: 1.380979299545288
Validation loss: 2.125794212023417

Epoch: 126| Step: 0
Training loss: 0.8344821929931641
Validation loss: 2.072111348311106

Epoch: 6| Step: 1
Training loss: 0.9837642908096313
Validation loss: 2.0449036161104837

Epoch: 6| Step: 2
Training loss: 1.0735039710998535
Validation loss: 2.0230289101600647

Epoch: 6| Step: 3
Training loss: 1.63114333152771
Validation loss: 2.0320740143458047

Epoch: 6| Step: 4
Training loss: 2.202576160430908
Validation loss: 2.043216864267985

Epoch: 6| Step: 5
Training loss: 2.0053200721740723
Validation loss: 2.051929553349813

Epoch: 6| Step: 6
Training loss: 1.467310905456543
Validation loss: 2.0410818258921304

Epoch: 6| Step: 7
Training loss: 1.8882921934127808
Validation loss: 2.0432278315226235

Epoch: 6| Step: 8
Training loss: 1.1988115310668945
Validation loss: 2.0293969909350076

Epoch: 6| Step: 9
Training loss: 1.6193679571151733
Validation loss: 2.0412023067474365

Epoch: 6| Step: 10
Training loss: 1.2162909507751465
Validation loss: 2.0542297959327698

Epoch: 6| Step: 11
Training loss: 1.5821728706359863
Validation loss: 2.0267199675242105

Epoch: 6| Step: 12
Training loss: 1.6078566312789917
Validation loss: 2.0482723911603293

Epoch: 6| Step: 13
Training loss: 1.6177489757537842
Validation loss: 2.0305097103118896

Epoch: 127| Step: 0
Training loss: 1.6172350645065308
Validation loss: 2.0372438033421836

Epoch: 6| Step: 1
Training loss: 1.117579460144043
Validation loss: 2.022689620653788

Epoch: 6| Step: 2
Training loss: 1.5832384824752808
Validation loss: 1.9987904230753581

Epoch: 6| Step: 3
Training loss: 1.2216908931732178
Validation loss: 2.00629315773646

Epoch: 6| Step: 4
Training loss: 2.0581722259521484
Validation loss: 2.032243808110555

Epoch: 6| Step: 5
Training loss: 0.8422458171844482
Validation loss: 2.0388429959615073

Epoch: 6| Step: 6
Training loss: 2.4424502849578857
Validation loss: 2.0541704297065735

Epoch: 6| Step: 7
Training loss: 1.235980749130249
Validation loss: 2.015636463960012

Epoch: 6| Step: 8
Training loss: 1.3419182300567627
Validation loss: 2.012953201929728

Epoch: 6| Step: 9
Training loss: 1.963641881942749
Validation loss: 2.0195680061976113

Epoch: 6| Step: 10
Training loss: 1.62088942527771
Validation loss: 2.0574554204940796

Epoch: 6| Step: 11
Training loss: 0.9417107105255127
Validation loss: 2.055972774823507

Epoch: 6| Step: 12
Training loss: 1.4843335151672363
Validation loss: 2.051588515440623

Epoch: 6| Step: 13
Training loss: 1.4203612804412842
Validation loss: 2.0762899120648703

Epoch: 128| Step: 0
Training loss: 1.4278775453567505
Validation loss: 2.044459501902262

Epoch: 6| Step: 1
Training loss: 2.055341958999634
Validation loss: 2.047586739063263

Epoch: 6| Step: 2
Training loss: 1.2925755977630615
Validation loss: 2.028011659781138

Epoch: 6| Step: 3
Training loss: 1.3272372484207153
Validation loss: 2.0617939631144204

Epoch: 6| Step: 4
Training loss: 1.4665400981903076
Validation loss: 2.0430727005004883

Epoch: 6| Step: 5
Training loss: 1.1474363803863525
Validation loss: 2.0338327089945474

Epoch: 6| Step: 6
Training loss: 1.1757495403289795
Validation loss: 2.0388917326927185

Epoch: 6| Step: 7
Training loss: 1.1369824409484863
Validation loss: 2.032650570074717

Epoch: 6| Step: 8
Training loss: 1.8269625902175903
Validation loss: 2.039390424887339

Epoch: 6| Step: 9
Training loss: 1.8323822021484375
Validation loss: 2.0384461283683777

Epoch: 6| Step: 10
Training loss: 1.195008635520935
Validation loss: 1.9939662019411724

Epoch: 6| Step: 11
Training loss: 1.4568079710006714
Validation loss: 2.0303760965665183

Epoch: 6| Step: 12
Training loss: 1.5746536254882812
Validation loss: 2.0257574915885925

Epoch: 6| Step: 13
Training loss: 2.005319356918335
Validation loss: 2.0485809644063315

Epoch: 129| Step: 0
Training loss: 1.7197209596633911
Validation loss: 2.0043440063794455

Epoch: 6| Step: 1
Training loss: 1.1632604598999023
Validation loss: 2.0164074699083963

Epoch: 6| Step: 2
Training loss: 1.7951269149780273
Validation loss: 2.0380921363830566

Epoch: 6| Step: 3
Training loss: 1.5465985536575317
Validation loss: 2.0356857577959695

Epoch: 6| Step: 4
Training loss: 1.5433685779571533
Validation loss: 2.0001164078712463

Epoch: 6| Step: 5
Training loss: 1.5435049533843994
Validation loss: 2.0386143128077188

Epoch: 6| Step: 6
Training loss: 1.8498203754425049
Validation loss: 2.0283289750417075

Epoch: 6| Step: 7
Training loss: 1.4429024457931519
Validation loss: 2.0649400552113852

Epoch: 6| Step: 8
Training loss: 1.3440135717391968
Validation loss: 2.083307902018229

Epoch: 6| Step: 9
Training loss: 1.099735140800476
Validation loss: 2.0930827061335244

Epoch: 6| Step: 10
Training loss: 1.3454945087432861
Validation loss: 2.1022916038831077

Epoch: 6| Step: 11
Training loss: 1.4393424987792969
Validation loss: 2.06866192817688

Epoch: 6| Step: 12
Training loss: 1.8353118896484375
Validation loss: 2.0657837788263955

Epoch: 6| Step: 13
Training loss: 1.2090678215026855
Validation loss: 2.0157352685928345

Epoch: 130| Step: 0
Training loss: 1.9519388675689697
Validation loss: 2.0246997674306235

Epoch: 6| Step: 1
Training loss: 1.1815541982650757
Validation loss: 2.0710078477859497

Epoch: 6| Step: 2
Training loss: 1.4542286396026611
Validation loss: 2.062553902467092

Epoch: 6| Step: 3
Training loss: 1.8090345859527588
Validation loss: 2.0639898578325906

Epoch: 6| Step: 4
Training loss: 1.6358410120010376
Validation loss: 2.0602062543233237

Epoch: 6| Step: 5
Training loss: 0.8802007436752319
Validation loss: 2.076677123705546

Epoch: 6| Step: 6
Training loss: 1.4332313537597656
Validation loss: 2.0780397256215415

Epoch: 6| Step: 7
Training loss: 1.468735933303833
Validation loss: 2.095133364200592

Epoch: 6| Step: 8
Training loss: 1.7150956392288208
Validation loss: 2.097738822301229

Epoch: 6| Step: 9
Training loss: 1.1860847473144531
Validation loss: 2.030037264029185

Epoch: 6| Step: 10
Training loss: 1.4369497299194336
Validation loss: 2.0735041300455728

Epoch: 6| Step: 11
Training loss: 1.9921835660934448
Validation loss: 2.0753214160601297

Epoch: 6| Step: 12
Training loss: 1.2308175563812256
Validation loss: 2.040614048639933

Epoch: 6| Step: 13
Training loss: 1.523594856262207
Validation loss: 2.073704481124878

Epoch: 131| Step: 0
Training loss: 1.1048436164855957
Validation loss: 2.0118792255719504

Epoch: 6| Step: 1
Training loss: 1.4396313428878784
Validation loss: 2.0708757241566977

Epoch: 6| Step: 2
Training loss: 1.036595106124878
Validation loss: 2.0739545424779258

Epoch: 6| Step: 3
Training loss: 1.1452882289886475
Validation loss: 2.078282117843628

Epoch: 6| Step: 4
Training loss: 1.477037787437439
Validation loss: 2.0670569936434426

Epoch: 6| Step: 5
Training loss: 1.1987440586090088
Validation loss: 2.025168220202128

Epoch: 6| Step: 6
Training loss: 1.9264289140701294
Validation loss: 2.0535061756769815

Epoch: 6| Step: 7
Training loss: 1.5738310813903809
Validation loss: 2.0432062347730002

Epoch: 6| Step: 8
Training loss: 1.4529340267181396
Validation loss: 2.0779661536216736

Epoch: 6| Step: 9
Training loss: 2.176335334777832
Validation loss: 2.093402942021688

Epoch: 6| Step: 10
Training loss: 2.027761220932007
Validation loss: 2.053159991900126

Epoch: 6| Step: 11
Training loss: 0.835745632648468
Validation loss: 2.1027036905288696

Epoch: 6| Step: 12
Training loss: 1.4212286472320557
Validation loss: 2.067554235458374

Epoch: 6| Step: 13
Training loss: 1.6299958229064941
Validation loss: 2.015717089176178

Epoch: 132| Step: 0
Training loss: 0.9474401473999023
Validation loss: 2.02958615620931

Epoch: 6| Step: 1
Training loss: 1.5828635692596436
Validation loss: 2.040795922279358

Epoch: 6| Step: 2
Training loss: 2.2987382411956787
Validation loss: 2.029471218585968

Epoch: 6| Step: 3
Training loss: 1.8600810766220093
Validation loss: 2.0404550631841025

Epoch: 6| Step: 4
Training loss: 1.2786061763763428
Validation loss: 2.028631329536438

Epoch: 6| Step: 5
Training loss: 1.005050539970398
Validation loss: 2.0464086731274924

Epoch: 6| Step: 6
Training loss: 0.8309221267700195
Validation loss: 2.0555336078008017

Epoch: 6| Step: 7
Training loss: 1.1008899211883545
Validation loss: 2.046060562133789

Epoch: 6| Step: 8
Training loss: 1.4492626190185547
Validation loss: 2.0380916595458984

Epoch: 6| Step: 9
Training loss: 1.7125823497772217
Validation loss: 2.038674811522166

Epoch: 6| Step: 10
Training loss: 1.4284052848815918
Validation loss: 2.0531306664148965

Epoch: 6| Step: 11
Training loss: 1.1406948566436768
Validation loss: 2.0753770073254905

Epoch: 6| Step: 12
Training loss: 2.1311135292053223
Validation loss: 2.04988686243693

Epoch: 6| Step: 13
Training loss: 1.258001446723938
Validation loss: 2.05340983470281

Epoch: 133| Step: 0
Training loss: 1.2065411806106567
Validation loss: 2.0643585324287415

Epoch: 6| Step: 1
Training loss: 1.728532314300537
Validation loss: 2.057840049266815

Epoch: 6| Step: 2
Training loss: 1.6004812717437744
Validation loss: 2.059327244758606

Epoch: 6| Step: 3
Training loss: 0.7763686776161194
Validation loss: 2.0620627800623574

Epoch: 6| Step: 4
Training loss: 1.2291276454925537
Validation loss: 2.056300163269043

Epoch: 6| Step: 5
Training loss: 1.4996508359909058
Validation loss: 2.036757151285807

Epoch: 6| Step: 6
Training loss: 1.250464677810669
Validation loss: 2.0662933190663657

Epoch: 6| Step: 7
Training loss: 1.5495972633361816
Validation loss: 2.0674813787142434

Epoch: 6| Step: 8
Training loss: 2.2020816802978516
Validation loss: 2.0515013138453164

Epoch: 6| Step: 9
Training loss: 1.997180700302124
Validation loss: 2.0698264837265015

Epoch: 6| Step: 10
Training loss: 1.1266865730285645
Validation loss: 2.0809256037076316

Epoch: 6| Step: 11
Training loss: 1.226224422454834
Validation loss: 2.0671408573786416

Epoch: 6| Step: 12
Training loss: 1.3857948780059814
Validation loss: 2.039538860321045

Epoch: 6| Step: 13
Training loss: 1.330655574798584
Validation loss: 2.0486099123954773

Epoch: 134| Step: 0
Training loss: 1.381189227104187
Validation loss: 2.081401308377584

Epoch: 6| Step: 1
Training loss: 1.4108710289001465
Validation loss: 2.1043362816174827

Epoch: 6| Step: 2
Training loss: 1.4271409511566162
Validation loss: 2.0981452266375222

Epoch: 6| Step: 3
Training loss: 2.102036952972412
Validation loss: 2.0954662362734475

Epoch: 6| Step: 4
Training loss: 1.4529469013214111
Validation loss: 2.0668497482935586

Epoch: 6| Step: 5
Training loss: 1.5932557582855225
Validation loss: 2.0095146099726358

Epoch: 6| Step: 6
Training loss: 0.97078937292099
Validation loss: 2.0642932653427124

Epoch: 6| Step: 7
Training loss: 1.2698978185653687
Validation loss: 2.0539257526397705

Epoch: 6| Step: 8
Training loss: 1.276131510734558
Validation loss: 2.0413745045661926

Epoch: 6| Step: 9
Training loss: 1.2094058990478516
Validation loss: 2.066570540269216

Epoch: 6| Step: 10
Training loss: 1.7366892099380493
Validation loss: 2.0442095001538596

Epoch: 6| Step: 11
Training loss: 1.3465852737426758
Validation loss: 2.056316554546356

Epoch: 6| Step: 12
Training loss: 1.3640514612197876
Validation loss: 2.0508310198783875

Epoch: 6| Step: 13
Training loss: 1.717887043952942
Validation loss: 2.0571797291437783

Epoch: 135| Step: 0
Training loss: 1.6819735765457153
Validation loss: 2.0388559103012085

Epoch: 6| Step: 1
Training loss: 1.0269749164581299
Validation loss: 2.080789585908254

Epoch: 6| Step: 2
Training loss: 1.495171308517456
Validation loss: 2.0955814520517984

Epoch: 6| Step: 3
Training loss: 1.7967714071273804
Validation loss: 2.092681427796682

Epoch: 6| Step: 4
Training loss: 0.938522458076477
Validation loss: 2.0896597107251487

Epoch: 6| Step: 5
Training loss: 1.2094906568527222
Validation loss: 2.0523754954338074

Epoch: 6| Step: 6
Training loss: 1.6545480489730835
Validation loss: 2.045377870400747

Epoch: 6| Step: 7
Training loss: 1.3943121433258057
Validation loss: 2.052589774131775

Epoch: 6| Step: 8
Training loss: 1.2383813858032227
Validation loss: 2.061639885107676

Epoch: 6| Step: 9
Training loss: 1.0851638317108154
Validation loss: 2.042448361714681

Epoch: 6| Step: 10
Training loss: 1.818934440612793
Validation loss: 2.0695091485977173

Epoch: 6| Step: 11
Training loss: 1.495815634727478
Validation loss: 2.064203162988027

Epoch: 6| Step: 12
Training loss: 1.389695167541504
Validation loss: 2.0913654565811157

Epoch: 6| Step: 13
Training loss: 1.4682626724243164
Validation loss: 2.044027050336202

Epoch: 136| Step: 0
Training loss: 1.271421194076538
Validation loss: 2.029412885506948

Epoch: 6| Step: 1
Training loss: 1.090588092803955
Validation loss: 2.0370373129844666

Epoch: 6| Step: 2
Training loss: 1.2583894729614258
Validation loss: 2.0721797148386636

Epoch: 6| Step: 3
Training loss: 1.1471993923187256
Validation loss: 2.0700045426686606

Epoch: 6| Step: 4
Training loss: 1.867950677871704
Validation loss: 2.0540511210759482

Epoch: 6| Step: 5
Training loss: 1.3564276695251465
Validation loss: 2.0359222888946533

Epoch: 6| Step: 6
Training loss: 0.8693587183952332
Validation loss: 2.067672868569692

Epoch: 6| Step: 7
Training loss: 1.7587976455688477
Validation loss: 2.0785617232322693

Epoch: 6| Step: 8
Training loss: 1.3645269870758057
Validation loss: 2.111891587575277

Epoch: 6| Step: 9
Training loss: 1.9144798517227173
Validation loss: 2.122128129005432

Epoch: 6| Step: 10
Training loss: 1.3573106527328491
Validation loss: 2.066334883371989

Epoch: 6| Step: 11
Training loss: 1.2681844234466553
Validation loss: 2.071521977583567

Epoch: 6| Step: 12
Training loss: 1.9677271842956543
Validation loss: 2.085655927658081

Epoch: 6| Step: 13
Training loss: 1.211303949356079
Validation loss: 2.0335023999214172

Epoch: 137| Step: 0
Training loss: 1.4572910070419312
Validation loss: 2.0523215532302856

Epoch: 6| Step: 1
Training loss: 1.3391849994659424
Validation loss: 2.0512653390566506

Epoch: 6| Step: 2
Training loss: 1.3170373439788818
Validation loss: 2.057757616043091

Epoch: 6| Step: 3
Training loss: 1.1415305137634277
Validation loss: 2.081885596116384

Epoch: 6| Step: 4
Training loss: 1.750428318977356
Validation loss: 2.0569806893666587

Epoch: 6| Step: 5
Training loss: 1.545530080795288
Validation loss: 2.040894945462545

Epoch: 6| Step: 6
Training loss: 1.268956184387207
Validation loss: 2.039643128712972

Epoch: 6| Step: 7
Training loss: 1.422445297241211
Validation loss: 2.069296578566233

Epoch: 6| Step: 8
Training loss: 1.7246177196502686
Validation loss: 2.0878774722417197

Epoch: 6| Step: 9
Training loss: 1.0651378631591797
Validation loss: 2.084386110305786

Epoch: 6| Step: 10
Training loss: 1.5985686779022217
Validation loss: 2.098877231280009

Epoch: 6| Step: 11
Training loss: 1.3005906343460083
Validation loss: 2.081100265185038

Epoch: 6| Step: 12
Training loss: 1.4739863872528076
Validation loss: 2.063334107398987

Epoch: 6| Step: 13
Training loss: 1.7682876586914062
Validation loss: 2.052987356980642

Epoch: 138| Step: 0
Training loss: 1.3600761890411377
Validation loss: 2.0670161843299866

Epoch: 6| Step: 1
Training loss: 1.0151106119155884
Validation loss: 2.043851991494497

Epoch: 6| Step: 2
Training loss: 1.5403521060943604
Validation loss: 2.0515418450037637

Epoch: 6| Step: 3
Training loss: 1.1681265830993652
Validation loss: 2.092785875002543

Epoch: 6| Step: 4
Training loss: 1.6505603790283203
Validation loss: 2.0970394213994346

Epoch: 6| Step: 5
Training loss: 1.7106865644454956
Validation loss: 2.0748297770818076

Epoch: 6| Step: 6
Training loss: 1.7746888399124146
Validation loss: 2.070777495702108

Epoch: 6| Step: 7
Training loss: 1.293202519416809
Validation loss: 2.0497769514719644

Epoch: 6| Step: 8
Training loss: 1.205725908279419
Validation loss: 2.097861170768738

Epoch: 6| Step: 9
Training loss: 1.4746642112731934
Validation loss: 2.0897653102874756

Epoch: 6| Step: 10
Training loss: 1.1156907081604004
Validation loss: 2.060866375764211

Epoch: 6| Step: 11
Training loss: 1.0357387065887451
Validation loss: 2.058102468649546

Epoch: 6| Step: 12
Training loss: 1.6416141986846924
Validation loss: 2.0343186060587564

Epoch: 6| Step: 13
Training loss: 1.359020709991455
Validation loss: 2.0637649297714233

Epoch: 139| Step: 0
Training loss: 1.3350460529327393
Validation loss: 2.057935913403829

Epoch: 6| Step: 1
Training loss: 1.32747220993042
Validation loss: 2.093963364760081

Epoch: 6| Step: 2
Training loss: 1.04864501953125
Validation loss: 2.0390137434005737

Epoch: 6| Step: 3
Training loss: 1.3855037689208984
Validation loss: 2.0561428467432656

Epoch: 6| Step: 4
Training loss: 1.7692186832427979
Validation loss: 2.0796631574630737

Epoch: 6| Step: 5
Training loss: 1.225615382194519
Validation loss: 2.082240422566732

Epoch: 6| Step: 6
Training loss: 0.9456114768981934
Validation loss: 2.0732783873875937

Epoch: 6| Step: 7
Training loss: 1.8582234382629395
Validation loss: 2.065168301264445

Epoch: 6| Step: 8
Training loss: 1.3801226615905762
Validation loss: 2.047625025113424

Epoch: 6| Step: 9
Training loss: 1.4100048542022705
Validation loss: 2.04125185807546

Epoch: 6| Step: 10
Training loss: 1.1112116575241089
Validation loss: 2.0698956847190857

Epoch: 6| Step: 11
Training loss: 1.8622856140136719
Validation loss: 2.0949923396110535

Epoch: 6| Step: 12
Training loss: 0.9503996968269348
Validation loss: 2.093514323234558

Epoch: 6| Step: 13
Training loss: 1.6624929904937744
Validation loss: 2.0923312107721963

Epoch: 140| Step: 0
Training loss: 2.263204336166382
Validation loss: 2.053102513154348

Epoch: 6| Step: 1
Training loss: 1.0284521579742432
Validation loss: 2.0367858012517295

Epoch: 6| Step: 2
Training loss: 1.150036096572876
Validation loss: 2.034169594446818

Epoch: 6| Step: 3
Training loss: 1.3398585319519043
Validation loss: 2.0686697562535605

Epoch: 6| Step: 4
Training loss: 1.411033034324646
Validation loss: 2.053815941015879

Epoch: 6| Step: 5
Training loss: 0.7616528868675232
Validation loss: 2.058576742808024

Epoch: 6| Step: 6
Training loss: 1.3851810693740845
Validation loss: 2.052511692047119

Epoch: 6| Step: 7
Training loss: 0.9466732144355774
Validation loss: 2.1077138980229697

Epoch: 6| Step: 8
Training loss: 1.069029688835144
Validation loss: 2.0538520018259683

Epoch: 6| Step: 9
Training loss: 1.9108250141143799
Validation loss: 2.102104445298513

Epoch: 6| Step: 10
Training loss: 1.4400475025177002
Validation loss: 2.0787264704704285

Epoch: 6| Step: 11
Training loss: 1.3467594385147095
Validation loss: 2.052859584490458

Epoch: 6| Step: 12
Training loss: 1.7164326906204224
Validation loss: 2.0373401244481406

Epoch: 6| Step: 13
Training loss: 1.077444076538086
Validation loss: 2.0410515864690146

Epoch: 141| Step: 0
Training loss: 1.3515958786010742
Validation loss: 2.045246104399363

Epoch: 6| Step: 1
Training loss: 1.0194849967956543
Validation loss: 2.051204780737559

Epoch: 6| Step: 2
Training loss: 1.2756935358047485
Validation loss: 2.0339398185412088

Epoch: 6| Step: 3
Training loss: 1.4252480268478394
Validation loss: 2.048919061819712

Epoch: 6| Step: 4
Training loss: 1.4731419086456299
Validation loss: 2.0556666056315103

Epoch: 6| Step: 5
Training loss: 1.469154715538025
Validation loss: 2.0654418667157493

Epoch: 6| Step: 6
Training loss: 1.2601770162582397
Validation loss: 2.092118203639984

Epoch: 6| Step: 7
Training loss: 0.9710860252380371
Validation loss: 2.0589996774991355

Epoch: 6| Step: 8
Training loss: 1.3726661205291748
Validation loss: 2.063841938972473

Epoch: 6| Step: 9
Training loss: 1.3227816820144653
Validation loss: 2.0583302974700928

Epoch: 6| Step: 10
Training loss: 1.6008106470108032
Validation loss: 2.0621659557024636

Epoch: 6| Step: 11
Training loss: 1.3813862800598145
Validation loss: 2.058567841847738

Epoch: 6| Step: 12
Training loss: 1.4275251626968384
Validation loss: 2.0545790592829385

Epoch: 6| Step: 13
Training loss: 1.6236774921417236
Validation loss: 2.0832549730936685

Epoch: 142| Step: 0
Training loss: 1.1791343688964844
Validation loss: 2.0723917285601297

Epoch: 6| Step: 1
Training loss: 1.108687400817871
Validation loss: 2.100590248902639

Epoch: 6| Step: 2
Training loss: 1.5226449966430664
Validation loss: 2.06325892607371

Epoch: 6| Step: 3
Training loss: 1.2358033657073975
Validation loss: 2.088237206141154

Epoch: 6| Step: 4
Training loss: 1.9156982898712158
Validation loss: 2.1700644493103027

Epoch: 6| Step: 5
Training loss: 1.1739853620529175
Validation loss: 2.202798624833425

Epoch: 6| Step: 6
Training loss: 1.9971179962158203
Validation loss: 2.272505839665731

Epoch: 6| Step: 7
Training loss: 1.9300283193588257
Validation loss: 2.219795743624369

Epoch: 6| Step: 8
Training loss: 1.6459063291549683
Validation loss: 2.1364787220954895

Epoch: 6| Step: 9
Training loss: 1.7367380857467651
Validation loss: 2.076715330282847

Epoch: 6| Step: 10
Training loss: 0.8077296018600464
Validation loss: 2.0802233815193176

Epoch: 6| Step: 11
Training loss: 1.5241291522979736
Validation loss: 1.9960981607437134

Epoch: 6| Step: 12
Training loss: 2.18333101272583
Validation loss: 2.0690940817197165

Epoch: 6| Step: 13
Training loss: 0.9579710960388184
Validation loss: 2.09016877412796

Epoch: 143| Step: 0
Training loss: 1.1879732608795166
Validation loss: 2.1198893189430237

Epoch: 6| Step: 1
Training loss: 1.1367125511169434
Validation loss: 2.128857135772705

Epoch: 6| Step: 2
Training loss: 1.4035179615020752
Validation loss: 2.147501309712728

Epoch: 6| Step: 3
Training loss: 1.4143259525299072
Validation loss: 2.083701411883036

Epoch: 6| Step: 4
Training loss: 1.3067030906677246
Validation loss: 2.043739100297292

Epoch: 6| Step: 5
Training loss: 1.0090487003326416
Validation loss: 2.0403607885042825

Epoch: 6| Step: 6
Training loss: 1.4239064455032349
Validation loss: 2.0631901224454245

Epoch: 6| Step: 7
Training loss: 1.343090295791626
Validation loss: 2.052777647972107

Epoch: 6| Step: 8
Training loss: 1.3654234409332275
Validation loss: 2.1265182296435037

Epoch: 6| Step: 9
Training loss: 1.6804583072662354
Validation loss: 2.1261829137802124

Epoch: 6| Step: 10
Training loss: 0.9235813617706299
Validation loss: 2.1085745692253113

Epoch: 6| Step: 11
Training loss: 2.029313087463379
Validation loss: 2.10195126136144

Epoch: 6| Step: 12
Training loss: 1.4526751041412354
Validation loss: 2.0708242654800415

Epoch: 6| Step: 13
Training loss: 1.9340627193450928
Validation loss: 2.0861758987108865

Epoch: 144| Step: 0
Training loss: 0.9317801594734192
Validation loss: 2.046010752518972

Epoch: 6| Step: 1
Training loss: 1.4730780124664307
Validation loss: 2.0408238569895425

Epoch: 6| Step: 2
Training loss: 1.3180396556854248
Validation loss: 2.0814227064450583

Epoch: 6| Step: 3
Training loss: 1.2275874614715576
Validation loss: 2.074426213900248

Epoch: 6| Step: 4
Training loss: 1.050524353981018
Validation loss: 2.081455488999685

Epoch: 6| Step: 5
Training loss: 1.8271570205688477
Validation loss: 2.073963463306427

Epoch: 6| Step: 6
Training loss: 1.3660342693328857
Validation loss: 2.10665092865626

Epoch: 6| Step: 7
Training loss: 1.2072564363479614
Validation loss: 2.0566066900889077

Epoch: 6| Step: 8
Training loss: 1.4708023071289062
Validation loss: 2.058932979901632

Epoch: 6| Step: 9
Training loss: 1.9805623292922974
Validation loss: 2.037051280339559

Epoch: 6| Step: 10
Training loss: 0.8115858435630798
Validation loss: 2.0238038897514343

Epoch: 6| Step: 11
Training loss: 1.1811885833740234
Validation loss: 2.0276310443878174

Epoch: 6| Step: 12
Training loss: 0.9570176005363464
Validation loss: 2.049008230368296

Epoch: 6| Step: 13
Training loss: 1.3953245878219604
Validation loss: 2.0454967816670737

Epoch: 145| Step: 0
Training loss: 1.0304251909255981
Validation loss: 2.083053191502889

Epoch: 6| Step: 1
Training loss: 0.9588788747787476
Validation loss: 2.063480257987976

Epoch: 6| Step: 2
Training loss: 1.0172548294067383
Validation loss: 2.0611289342244468

Epoch: 6| Step: 3
Training loss: 1.0582737922668457
Validation loss: 2.0432966152826944

Epoch: 6| Step: 4
Training loss: 1.8465332984924316
Validation loss: 2.031721850236257

Epoch: 6| Step: 5
Training loss: 1.277841329574585
Validation loss: 2.0521427989006042

Epoch: 6| Step: 6
Training loss: 1.4345755577087402
Validation loss: 2.0475978453954062

Epoch: 6| Step: 7
Training loss: 1.8081083297729492
Validation loss: 2.084528664747874

Epoch: 6| Step: 8
Training loss: 1.101019024848938
Validation loss: 2.0433483521143594

Epoch: 6| Step: 9
Training loss: 1.261706829071045
Validation loss: 2.0506136218706765

Epoch: 6| Step: 10
Training loss: 0.8465546369552612
Validation loss: 2.1127907037734985

Epoch: 6| Step: 11
Training loss: 1.4919917583465576
Validation loss: 2.0783844590187073

Epoch: 6| Step: 12
Training loss: 1.5336785316467285
Validation loss: 2.064807931582133

Epoch: 6| Step: 13
Training loss: 1.5473949909210205
Validation loss: 2.038229823112488

Epoch: 146| Step: 0
Training loss: 1.5016833543777466
Validation loss: 2.0745173692703247

Epoch: 6| Step: 1
Training loss: 1.5982213020324707
Validation loss: 2.068494518597921

Epoch: 6| Step: 2
Training loss: 1.068371057510376
Validation loss: 2.087101995944977

Epoch: 6| Step: 3
Training loss: 1.7371089458465576
Validation loss: 2.0782178243001304

Epoch: 6| Step: 4
Training loss: 1.142533302307129
Validation loss: 2.082953234513601

Epoch: 6| Step: 5
Training loss: 1.2603962421417236
Validation loss: 2.073700189590454

Epoch: 6| Step: 6
Training loss: 1.3274519443511963
Validation loss: 2.1025036176045737

Epoch: 6| Step: 7
Training loss: 0.7802501916885376
Validation loss: 2.02725480000178

Epoch: 6| Step: 8
Training loss: 1.3134546279907227
Validation loss: 2.08543332417806

Epoch: 6| Step: 9
Training loss: 1.5817393064498901
Validation loss: 2.085154891014099

Epoch: 6| Step: 10
Training loss: 1.8394266366958618
Validation loss: 2.0611833930015564

Epoch: 6| Step: 11
Training loss: 1.1869302988052368
Validation loss: 2.077410797278086

Epoch: 6| Step: 12
Training loss: 1.3104783296585083
Validation loss: 2.115920603275299

Epoch: 6| Step: 13
Training loss: 1.1351654529571533
Validation loss: 2.057573596636454

Epoch: 147| Step: 0
Training loss: 1.3931347131729126
Validation loss: 2.101460417111715

Epoch: 6| Step: 1
Training loss: 1.0665804147720337
Validation loss: 2.068915069103241

Epoch: 6| Step: 2
Training loss: 0.8989689350128174
Validation loss: 2.0585184892018638

Epoch: 6| Step: 3
Training loss: 1.0684435367584229
Validation loss: 2.0698471665382385

Epoch: 6| Step: 4
Training loss: 1.8330283164978027
Validation loss: 2.102443218231201

Epoch: 6| Step: 5
Training loss: 1.949784517288208
Validation loss: 2.086296478907267

Epoch: 6| Step: 6
Training loss: 1.4204351902008057
Validation loss: 2.058237095673879

Epoch: 6| Step: 7
Training loss: 1.040054440498352
Validation loss: 2.1049193739891052

Epoch: 6| Step: 8
Training loss: 1.0974276065826416
Validation loss: 2.07575531800588

Epoch: 6| Step: 9
Training loss: 1.089185118675232
Validation loss: 2.094541629155477

Epoch: 6| Step: 10
Training loss: 0.9066931009292603
Validation loss: 2.098391056060791

Epoch: 6| Step: 11
Training loss: 1.1708484888076782
Validation loss: 2.0444713632265725

Epoch: 6| Step: 12
Training loss: 1.4019869565963745
Validation loss: 2.0934234460194907

Epoch: 6| Step: 13
Training loss: 1.62551748752594
Validation loss: 2.0742276708285012

Epoch: 148| Step: 0
Training loss: 0.9960695505142212
Validation loss: 2.093647281328837

Epoch: 6| Step: 1
Training loss: 1.5063507556915283
Validation loss: 2.054423769315084

Epoch: 6| Step: 2
Training loss: 1.062751293182373
Validation loss: 2.09309717019399

Epoch: 6| Step: 3
Training loss: 1.3093880414962769
Validation loss: 2.079820215702057

Epoch: 6| Step: 4
Training loss: 2.266108989715576
Validation loss: 2.139414449532827

Epoch: 6| Step: 5
Training loss: 1.08877432346344
Validation loss: 2.0732223192850747

Epoch: 6| Step: 6
Training loss: 1.5641804933547974
Validation loss: 2.0759514371554055

Epoch: 6| Step: 7
Training loss: 1.2721151113510132
Validation loss: 2.067147890726725

Epoch: 6| Step: 8
Training loss: 0.7870069146156311
Validation loss: 2.053385853767395

Epoch: 6| Step: 9
Training loss: 0.7449219226837158
Validation loss: 2.1094943086306253

Epoch: 6| Step: 10
Training loss: 1.0657563209533691
Validation loss: 2.0712015430132547

Epoch: 6| Step: 11
Training loss: 1.1694772243499756
Validation loss: 2.081906338532766

Epoch: 6| Step: 12
Training loss: 1.9730793237686157
Validation loss: 2.0609103639920554

Epoch: 6| Step: 13
Training loss: 0.9953076839447021
Validation loss: 2.1054492791493735

Epoch: 149| Step: 0
Training loss: 0.8880958557128906
Validation loss: 2.0963328878084817

Epoch: 6| Step: 1
Training loss: 1.2325135469436646
Validation loss: 2.072232723236084

Epoch: 6| Step: 2
Training loss: 1.4645910263061523
Validation loss: 2.075508495171865

Epoch: 6| Step: 3
Training loss: 1.1767038106918335
Validation loss: 2.0492040514945984

Epoch: 6| Step: 4
Training loss: 0.9649224281311035
Validation loss: 2.0514848629633584

Epoch: 6| Step: 5
Training loss: 1.2477823495864868
Validation loss: 2.050129850705465

Epoch: 6| Step: 6
Training loss: 1.3027453422546387
Validation loss: 2.0658028523127236

Epoch: 6| Step: 7
Training loss: 0.9132910966873169
Validation loss: 2.0493787924448648

Epoch: 6| Step: 8
Training loss: 1.484809160232544
Validation loss: 2.0553775429725647

Epoch: 6| Step: 9
Training loss: 1.4351227283477783
Validation loss: 2.051758110523224

Epoch: 6| Step: 10
Training loss: 1.361640453338623
Validation loss: 2.099511702855428

Epoch: 6| Step: 11
Training loss: 1.521531343460083
Validation loss: 2.0617915987968445

Epoch: 6| Step: 12
Training loss: 1.6324145793914795
Validation loss: 2.0907708406448364

Epoch: 6| Step: 13
Training loss: 0.9886414408683777
Validation loss: 2.1199160615603128

Epoch: 150| Step: 0
Training loss: 1.288896083831787
Validation loss: 2.082667430241903

Epoch: 6| Step: 1
Training loss: 1.460318922996521
Validation loss: 2.037740429242452

Epoch: 6| Step: 2
Training loss: 1.2741800546646118
Validation loss: 2.0306779543558755

Epoch: 6| Step: 3
Training loss: 1.811187982559204
Validation loss: 2.063666880130768

Epoch: 6| Step: 4
Training loss: 1.5579936504364014
Validation loss: 2.120416005452474

Epoch: 6| Step: 5
Training loss: 1.4017672538757324
Validation loss: 2.0934826532999673

Epoch: 6| Step: 6
Training loss: 0.784043550491333
Validation loss: 2.1059887409210205

Epoch: 6| Step: 7
Training loss: 1.6955044269561768
Validation loss: 2.0686086217562356

Epoch: 6| Step: 8
Training loss: 0.8670960068702698
Validation loss: 2.0767110188802085

Epoch: 6| Step: 9
Training loss: 1.1171735525131226
Validation loss: 2.074289540449778

Epoch: 6| Step: 10
Training loss: 1.0114648342132568
Validation loss: 2.093724846839905

Epoch: 6| Step: 11
Training loss: 1.3079164028167725
Validation loss: 2.097879946231842

Epoch: 6| Step: 12
Training loss: 1.427269697189331
Validation loss: 2.101071000099182

Epoch: 6| Step: 13
Training loss: 1.3621103763580322
Validation loss: 2.1343103647232056

Epoch: 151| Step: 0
Training loss: 1.0327024459838867
Validation loss: 2.084349791208903

Epoch: 6| Step: 1
Training loss: 1.7391114234924316
Validation loss: 2.0790858070055642

Epoch: 6| Step: 2
Training loss: 1.3194057941436768
Validation loss: 2.065923035144806

Epoch: 6| Step: 3
Training loss: 1.3856313228607178
Validation loss: 2.066583514213562

Epoch: 6| Step: 4
Training loss: 1.2304472923278809
Validation loss: 2.0715970396995544

Epoch: 6| Step: 5
Training loss: 0.8296138048171997
Validation loss: 2.0785787105560303

Epoch: 6| Step: 6
Training loss: 0.9501000642776489
Validation loss: 2.0706244905789695

Epoch: 6| Step: 7
Training loss: 1.3747022151947021
Validation loss: 2.118830601374308

Epoch: 6| Step: 8
Training loss: 1.0678187608718872
Validation loss: 2.102742632230123

Epoch: 6| Step: 9
Training loss: 1.3095368146896362
Validation loss: 2.1141077280044556

Epoch: 6| Step: 10
Training loss: 1.0859310626983643
Validation loss: 2.05111555258433

Epoch: 6| Step: 11
Training loss: 1.504771113395691
Validation loss: 2.0857958594957986

Epoch: 6| Step: 12
Training loss: 1.253990650177002
Validation loss: 2.0816144347190857

Epoch: 6| Step: 13
Training loss: 1.6744375228881836
Validation loss: 2.0621686975161233

Epoch: 152| Step: 0
Training loss: 1.0959458351135254
Validation loss: 2.128731449445089

Epoch: 6| Step: 1
Training loss: 1.3160781860351562
Validation loss: 2.0579285422960916

Epoch: 6| Step: 2
Training loss: 1.4312098026275635
Validation loss: 2.076332072416941

Epoch: 6| Step: 3
Training loss: 1.3660266399383545
Validation loss: 2.0702242056528726

Epoch: 6| Step: 4
Training loss: 1.1313953399658203
Validation loss: 2.0589234034220376

Epoch: 6| Step: 5
Training loss: 0.9988937973976135
Validation loss: 2.055338899294535

Epoch: 6| Step: 6
Training loss: 0.7656485438346863
Validation loss: 2.0948262214660645

Epoch: 6| Step: 7
Training loss: 1.2315207719802856
Validation loss: 2.057219604651133

Epoch: 6| Step: 8
Training loss: 1.2301251888275146
Validation loss: 2.082804501056671

Epoch: 6| Step: 9
Training loss: 0.7539222240447998
Validation loss: 2.093926429748535

Epoch: 6| Step: 10
Training loss: 1.27046537399292
Validation loss: 2.095390518506368

Epoch: 6| Step: 11
Training loss: 0.9681383967399597
Validation loss: 2.0540338357289634

Epoch: 6| Step: 12
Training loss: 1.4398741722106934
Validation loss: 2.061979075272878

Epoch: 6| Step: 13
Training loss: 1.9477711915969849
Validation loss: 2.097233851750692

Epoch: 153| Step: 0
Training loss: 1.1066950559616089
Validation loss: 2.068364679813385

Epoch: 6| Step: 1
Training loss: 0.9215958714485168
Validation loss: 2.0873018304506936

Epoch: 6| Step: 2
Training loss: 1.2835004329681396
Validation loss: 2.0422536929448447

Epoch: 6| Step: 3
Training loss: 0.9876912236213684
Validation loss: 2.0437970956166587

Epoch: 6| Step: 4
Training loss: 1.3064063787460327
Validation loss: 2.116486668586731

Epoch: 6| Step: 5
Training loss: 1.7214417457580566
Validation loss: 2.115776260693868

Epoch: 6| Step: 6
Training loss: 0.9240182638168335
Validation loss: 2.1082722743352256

Epoch: 6| Step: 7
Training loss: 1.4631857872009277
Validation loss: 2.063936452070872

Epoch: 6| Step: 8
Training loss: 1.0379325151443481
Validation loss: 2.121491630872091

Epoch: 6| Step: 9
Training loss: 1.4200818538665771
Validation loss: 2.127314031124115

Epoch: 6| Step: 10
Training loss: 1.233155369758606
Validation loss: 2.1095497608184814

Epoch: 6| Step: 11
Training loss: 1.676777720451355
Validation loss: 2.1297461787859597

Epoch: 6| Step: 12
Training loss: 1.0051662921905518
Validation loss: 2.121633509794871

Epoch: 6| Step: 13
Training loss: 1.5042331218719482
Validation loss: 2.1222569346427917

Epoch: 154| Step: 0
Training loss: 1.2748253345489502
Validation loss: 2.0568067034085593

Epoch: 6| Step: 1
Training loss: 1.0408521890640259
Validation loss: 2.104644318421682

Epoch: 6| Step: 2
Training loss: 1.6628352403640747
Validation loss: 2.125196933746338

Epoch: 6| Step: 3
Training loss: 1.5292305946350098
Validation loss: 2.0990878343582153

Epoch: 6| Step: 4
Training loss: 1.2346826791763306
Validation loss: 2.0698296825091043

Epoch: 6| Step: 5
Training loss: 1.7571051120758057
Validation loss: 2.077509601910909

Epoch: 6| Step: 6
Training loss: 1.351540207862854
Validation loss: 2.113635698954264

Epoch: 6| Step: 7
Training loss: 1.0876606702804565
Validation loss: 2.075574060281118

Epoch: 6| Step: 8
Training loss: 1.049787163734436
Validation loss: 2.107811133066813

Epoch: 6| Step: 9
Training loss: 1.0501089096069336
Validation loss: 2.1097002824147544

Epoch: 6| Step: 10
Training loss: 0.9222265481948853
Validation loss: 2.078247825304667

Epoch: 6| Step: 11
Training loss: 0.709854006767273
Validation loss: 2.0967869559923806

Epoch: 6| Step: 12
Training loss: 1.0311968326568604
Validation loss: 2.096890946229299

Epoch: 6| Step: 13
Training loss: 1.4231990575790405
Validation loss: 2.0699342687924704

Epoch: 155| Step: 0
Training loss: 1.1199593544006348
Validation loss: 2.06758979956309

Epoch: 6| Step: 1
Training loss: 1.4674782752990723
Validation loss: 2.0677175919214883

Epoch: 6| Step: 2
Training loss: 1.520326852798462
Validation loss: 2.1067846417427063

Epoch: 6| Step: 3
Training loss: 0.7179558277130127
Validation loss: 2.0983394185702005

Epoch: 6| Step: 4
Training loss: 0.9053634405136108
Validation loss: 2.098762810230255

Epoch: 6| Step: 5
Training loss: 1.0920900106430054
Validation loss: 2.085128903388977

Epoch: 6| Step: 6
Training loss: 0.9526070952415466
Validation loss: 2.0684010783831277

Epoch: 6| Step: 7
Training loss: 1.4722011089324951
Validation loss: 2.0741520126660666

Epoch: 6| Step: 8
Training loss: 1.1866164207458496
Validation loss: 2.069995323816935

Epoch: 6| Step: 9
Training loss: 1.4228582382202148
Validation loss: 2.0645745197931924

Epoch: 6| Step: 10
Training loss: 1.1202417612075806
Validation loss: 2.058056652545929

Epoch: 6| Step: 11
Training loss: 0.5771229267120361
Validation loss: 2.0758840640385947

Epoch: 6| Step: 12
Training loss: 1.2741780281066895
Validation loss: 2.046231726805369

Epoch: 6| Step: 13
Training loss: 1.9267657995224
Validation loss: 2.0639745593070984

Epoch: 156| Step: 0
Training loss: 0.7982027530670166
Validation loss: 2.061245381832123

Epoch: 6| Step: 1
Training loss: 0.9324139356613159
Validation loss: 2.0756630897521973

Epoch: 6| Step: 2
Training loss: 1.1437503099441528
Validation loss: 2.0906903743743896

Epoch: 6| Step: 3
Training loss: 1.1380079984664917
Validation loss: 2.036596139272054

Epoch: 6| Step: 4
Training loss: 1.2951545715332031
Validation loss: 2.0802961389223733

Epoch: 6| Step: 5
Training loss: 1.6693477630615234
Validation loss: 2.1355918844540915

Epoch: 6| Step: 6
Training loss: 1.2481268644332886
Validation loss: 2.058943212032318

Epoch: 6| Step: 7
Training loss: 1.0287281274795532
Validation loss: 2.0869533816973367

Epoch: 6| Step: 8
Training loss: 1.2716310024261475
Validation loss: 2.0394748051961265

Epoch: 6| Step: 9
Training loss: 1.3610633611679077
Validation loss: 2.0579057931900024

Epoch: 6| Step: 10
Training loss: 1.327509880065918
Validation loss: 2.0643732945124307

Epoch: 6| Step: 11
Training loss: 1.0144762992858887
Validation loss: 2.0477642019589744

Epoch: 6| Step: 12
Training loss: 1.0837959051132202
Validation loss: 2.1287711461385093

Epoch: 6| Step: 13
Training loss: 1.257922649383545
Validation loss: 2.0765955448150635

Epoch: 157| Step: 0
Training loss: 1.0260639190673828
Validation loss: 2.043118178844452

Epoch: 6| Step: 1
Training loss: 0.8791579604148865
Validation loss: 2.06600014368693

Epoch: 6| Step: 2
Training loss: 1.1686413288116455
Validation loss: 2.0437553326288858

Epoch: 6| Step: 3
Training loss: 1.452691912651062
Validation loss: 2.044574717680613

Epoch: 6| Step: 4
Training loss: 1.1975765228271484
Validation loss: 2.077213227748871

Epoch: 6| Step: 5
Training loss: 1.4086987972259521
Validation loss: 2.0681111017862954

Epoch: 6| Step: 6
Training loss: 1.1346564292907715
Validation loss: 2.107975800832113

Epoch: 6| Step: 7
Training loss: 0.7707874774932861
Validation loss: 2.0790244539578757

Epoch: 6| Step: 8
Training loss: 1.2329776287078857
Validation loss: 2.081889788309733

Epoch: 6| Step: 9
Training loss: 0.9692108631134033
Validation loss: 2.043893873691559

Epoch: 6| Step: 10
Training loss: 1.7277337312698364
Validation loss: 2.1131250262260437

Epoch: 6| Step: 11
Training loss: 1.317261815071106
Validation loss: 2.0513559182484946

Epoch: 6| Step: 12
Training loss: 1.1667828559875488
Validation loss: 2.029581526915232

Epoch: 6| Step: 13
Training loss: 1.112048864364624
Validation loss: 2.0332758029301963

Epoch: 158| Step: 0
Training loss: 1.2512845993041992
Validation loss: 2.037567913532257

Epoch: 6| Step: 1
Training loss: 1.362607479095459
Validation loss: 2.0671531756718955

Epoch: 6| Step: 2
Training loss: 1.400524377822876
Validation loss: 2.1055883367856345

Epoch: 6| Step: 3
Training loss: 0.8156014680862427
Validation loss: 2.045006811618805

Epoch: 6| Step: 4
Training loss: 1.004178524017334
Validation loss: 2.081574320793152

Epoch: 6| Step: 5
Training loss: 1.2233154773712158
Validation loss: 2.0734300216039023

Epoch: 6| Step: 6
Training loss: 0.7342401742935181
Validation loss: 2.0699973503748574

Epoch: 6| Step: 7
Training loss: 1.0295883417129517
Validation loss: 2.080857515335083

Epoch: 6| Step: 8
Training loss: 1.2641130685806274
Validation loss: 2.1148452361424765

Epoch: 6| Step: 9
Training loss: 1.6558693647384644
Validation loss: 2.080635905265808

Epoch: 6| Step: 10
Training loss: 1.735573410987854
Validation loss: 2.0147719780604043

Epoch: 6| Step: 11
Training loss: 0.9912829399108887
Validation loss: 2.0768022934595742

Epoch: 6| Step: 12
Training loss: 1.1399614810943604
Validation loss: 2.0514458219210305

Epoch: 6| Step: 13
Training loss: 0.9044266939163208
Validation loss: 2.0885496934254966

Epoch: 159| Step: 0
Training loss: 1.0652005672454834
Validation loss: 2.1172964572906494

Epoch: 6| Step: 1
Training loss: 0.9790254831314087
Validation loss: 2.0520870685577393

Epoch: 6| Step: 2
Training loss: 1.4758453369140625
Validation loss: 2.080512503782908

Epoch: 6| Step: 3
Training loss: 1.15896475315094
Validation loss: 2.120380699634552

Epoch: 6| Step: 4
Training loss: 1.1557834148406982
Validation loss: 2.066420594851176

Epoch: 6| Step: 5
Training loss: 1.1422686576843262
Validation loss: 2.072212874889374

Epoch: 6| Step: 6
Training loss: 1.4082871675491333
Validation loss: 2.0410385727882385

Epoch: 6| Step: 7
Training loss: 0.8935937881469727
Validation loss: 2.100453197956085

Epoch: 6| Step: 8
Training loss: 1.212477207183838
Validation loss: 2.0824459989865622

Epoch: 6| Step: 9
Training loss: 1.1640324592590332
Validation loss: 2.0542659560839334

Epoch: 6| Step: 10
Training loss: 1.2556090354919434
Validation loss: 2.0577134688695273

Epoch: 6| Step: 11
Training loss: 1.275590419769287
Validation loss: 2.1005057096481323

Epoch: 6| Step: 12
Training loss: 1.1560547351837158
Validation loss: 2.079581061999003

Epoch: 6| Step: 13
Training loss: 0.7954227924346924
Validation loss: 2.13046133518219

Epoch: 160| Step: 0
Training loss: 1.487213373184204
Validation loss: 2.1066332856814065

Epoch: 6| Step: 1
Training loss: 0.878318190574646
Validation loss: 2.096045196056366

Epoch: 6| Step: 2
Training loss: 1.2260977029800415
Validation loss: 2.105048954486847

Epoch: 6| Step: 3
Training loss: 1.0769801139831543
Validation loss: 2.054939091205597

Epoch: 6| Step: 4
Training loss: 1.319032073020935
Validation loss: 2.0978879928588867

Epoch: 6| Step: 5
Training loss: 1.129307746887207
Validation loss: 2.0680126349131265

Epoch: 6| Step: 6
Training loss: 1.0286896228790283
Validation loss: 2.088252683480581

Epoch: 6| Step: 7
Training loss: 1.0489457845687866
Validation loss: 2.115135749181112

Epoch: 6| Step: 8
Training loss: 0.9098507165908813
Validation loss: 2.0810943643252053

Epoch: 6| Step: 9
Training loss: 1.3400018215179443
Validation loss: 2.090837319691976

Epoch: 6| Step: 10
Training loss: 1.7046027183532715
Validation loss: 2.0699150760968528

Epoch: 6| Step: 11
Training loss: 1.1703929901123047
Validation loss: 2.0906546910603843

Epoch: 6| Step: 12
Training loss: 0.8192110061645508
Validation loss: 2.0911785364151

Epoch: 6| Step: 13
Training loss: 0.7730562686920166
Validation loss: 2.086840808391571

Epoch: 161| Step: 0
Training loss: 1.0175632238388062
Validation loss: 2.070739487806956

Epoch: 6| Step: 1
Training loss: 0.9931203126907349
Validation loss: 2.0532679359118142

Epoch: 6| Step: 2
Training loss: 1.5377254486083984
Validation loss: 2.118674953778585

Epoch: 6| Step: 3
Training loss: 1.3864576816558838
Validation loss: 2.0712629556655884

Epoch: 6| Step: 4
Training loss: 1.3586218357086182
Validation loss: 2.027575691541036

Epoch: 6| Step: 5
Training loss: 1.0241377353668213
Validation loss: 2.099544624487559

Epoch: 6| Step: 6
Training loss: 1.1494951248168945
Validation loss: 2.073995033899943

Epoch: 6| Step: 7
Training loss: 0.8608832955360413
Validation loss: 2.089426259199778

Epoch: 6| Step: 8
Training loss: 1.3345167636871338
Validation loss: 2.112419605255127

Epoch: 6| Step: 9
Training loss: 0.6339471340179443
Validation loss: 2.1115238070487976

Epoch: 6| Step: 10
Training loss: 1.4748958349227905
Validation loss: 2.1443195740381875

Epoch: 6| Step: 11
Training loss: 0.7246772050857544
Validation loss: 2.103372871875763

Epoch: 6| Step: 12
Training loss: 1.3861973285675049
Validation loss: 2.093745450178782

Epoch: 6| Step: 13
Training loss: 1.3533295392990112
Validation loss: 2.0836650927861533

Epoch: 162| Step: 0
Training loss: 0.8322415947914124
Validation loss: 2.0844505627950034

Epoch: 6| Step: 1
Training loss: 1.4146236181259155
Validation loss: 2.098064363002777

Epoch: 6| Step: 2
Training loss: 1.322437047958374
Validation loss: 2.093044320742289

Epoch: 6| Step: 3
Training loss: 0.9434325695037842
Validation loss: 2.0596179366111755

Epoch: 6| Step: 4
Training loss: 0.9623693227767944
Validation loss: 2.0847325126330056

Epoch: 6| Step: 5
Training loss: 1.2961697578430176
Validation loss: 2.077281932036082

Epoch: 6| Step: 6
Training loss: 0.6268044710159302
Validation loss: 2.08893092473348

Epoch: 6| Step: 7
Training loss: 1.3489121198654175
Validation loss: 2.0684714714686074

Epoch: 6| Step: 8
Training loss: 0.8382097482681274
Validation loss: 2.075695037841797

Epoch: 6| Step: 9
Training loss: 1.5413682460784912
Validation loss: 2.0592669248580933

Epoch: 6| Step: 10
Training loss: 1.1533218622207642
Validation loss: 2.07414976755778

Epoch: 6| Step: 11
Training loss: 1.2320024967193604
Validation loss: 2.078719437122345

Epoch: 6| Step: 12
Training loss: 1.1557916402816772
Validation loss: 2.1068332393964133

Epoch: 6| Step: 13
Training loss: 1.3266091346740723
Validation loss: 2.0559446016947427

Epoch: 163| Step: 0
Training loss: 1.209038257598877
Validation loss: 2.0864214499791465

Epoch: 6| Step: 1
Training loss: 0.9217965006828308
Validation loss: 2.0408010681470237

Epoch: 6| Step: 2
Training loss: 1.3375275135040283
Validation loss: 2.0506271719932556

Epoch: 6| Step: 3
Training loss: 0.7909141182899475
Validation loss: 2.0732609629631042

Epoch: 6| Step: 4
Training loss: 1.2804927825927734
Validation loss: 2.063657522201538

Epoch: 6| Step: 5
Training loss: 0.7316528558731079
Validation loss: 2.0491923491160073

Epoch: 6| Step: 6
Training loss: 1.1534383296966553
Validation loss: 2.0956360499064126

Epoch: 6| Step: 7
Training loss: 1.0908622741699219
Validation loss: 2.035776118437449

Epoch: 6| Step: 8
Training loss: 1.5382007360458374
Validation loss: 2.071229656537374

Epoch: 6| Step: 9
Training loss: 1.0657528638839722
Validation loss: 2.0627921422322593

Epoch: 6| Step: 10
Training loss: 1.1746370792388916
Validation loss: 2.0831114053726196

Epoch: 6| Step: 11
Training loss: 0.7565109133720398
Validation loss: 2.0926271279652915

Epoch: 6| Step: 12
Training loss: 1.3679695129394531
Validation loss: 2.044403334458669

Epoch: 6| Step: 13
Training loss: 1.4529640674591064
Validation loss: 2.088619569937388

Epoch: 164| Step: 0
Training loss: 1.0852702856063843
Validation loss: 2.1163238088289895

Epoch: 6| Step: 1
Training loss: 0.9533829689025879
Validation loss: 2.074473738670349

Epoch: 6| Step: 2
Training loss: 1.5683377981185913
Validation loss: 2.0983490546544394

Epoch: 6| Step: 3
Training loss: 1.14760160446167
Validation loss: 2.0427973866462708

Epoch: 6| Step: 4
Training loss: 1.2041670083999634
Validation loss: 2.0982624292373657

Epoch: 6| Step: 5
Training loss: 0.8360458612442017
Validation loss: 2.1198312441507974

Epoch: 6| Step: 6
Training loss: 1.225783348083496
Validation loss: 2.114946961402893

Epoch: 6| Step: 7
Training loss: 1.208040475845337
Validation loss: 2.112195352713267

Epoch: 6| Step: 8
Training loss: 0.8137040734291077
Validation loss: 2.1368238727251687

Epoch: 6| Step: 9
Training loss: 1.0726112127304077
Validation loss: 2.1028878887494407

Epoch: 6| Step: 10
Training loss: 1.2087678909301758
Validation loss: 2.077745715777079

Epoch: 6| Step: 11
Training loss: 1.4382073879241943
Validation loss: 2.091841459274292

Epoch: 6| Step: 12
Training loss: 1.1382843255996704
Validation loss: 2.143895904223124

Epoch: 6| Step: 13
Training loss: 1.5215513706207275
Validation loss: 2.1296693682670593

Epoch: 165| Step: 0
Training loss: 0.7376502752304077
Validation loss: 2.1269278128941855

Epoch: 6| Step: 1
Training loss: 1.1745593547821045
Validation loss: 2.1430957516034446

Epoch: 6| Step: 2
Training loss: 0.9042828679084778
Validation loss: 2.1120516856511435

Epoch: 6| Step: 3
Training loss: 1.1677885055541992
Validation loss: 2.1393797993659973

Epoch: 6| Step: 4
Training loss: 0.9838563203811646
Validation loss: 2.133142073949178

Epoch: 6| Step: 5
Training loss: 0.9484595656394958
Validation loss: 2.104414641857147

Epoch: 6| Step: 6
Training loss: 0.5556074976921082
Validation loss: 2.1493818362553916

Epoch: 6| Step: 7
Training loss: 0.5879313349723816
Validation loss: 2.0886255502700806

Epoch: 6| Step: 8
Training loss: 1.3358633518218994
Validation loss: 2.08297731479009

Epoch: 6| Step: 9
Training loss: 1.2840123176574707
Validation loss: 2.124376674493154

Epoch: 6| Step: 10
Training loss: 2.1289165019989014
Validation loss: 2.103978077570597

Epoch: 6| Step: 11
Training loss: 0.9274054765701294
Validation loss: 2.121816635131836

Epoch: 6| Step: 12
Training loss: 1.6947548389434814
Validation loss: 2.1514435609181723

Epoch: 6| Step: 13
Training loss: 1.2981996536254883
Validation loss: 2.122537930806478

Epoch: 166| Step: 0
Training loss: 1.3186981678009033
Validation loss: 2.192862848440806

Epoch: 6| Step: 1
Training loss: 1.7860636711120605
Validation loss: 2.1392066876093545

Epoch: 6| Step: 2
Training loss: 1.55824875831604
Validation loss: 2.1158112486203513

Epoch: 6| Step: 3
Training loss: 1.1864211559295654
Validation loss: 2.1144089500109353

Epoch: 6| Step: 4
Training loss: 0.9010303020477295
Validation loss: 2.0750747323036194

Epoch: 6| Step: 5
Training loss: 1.013000249862671
Validation loss: 2.070658346017202

Epoch: 6| Step: 6
Training loss: 0.7846927642822266
Validation loss: 2.110150416692098

Epoch: 6| Step: 7
Training loss: 0.8549561500549316
Validation loss: 2.1027592023213706

Epoch: 6| Step: 8
Training loss: 0.9984951019287109
Validation loss: 2.095729192097982

Epoch: 6| Step: 9
Training loss: 1.2110402584075928
Validation loss: 2.0805822213490806

Epoch: 6| Step: 10
Training loss: 0.718526303768158
Validation loss: 2.057217518488566

Epoch: 6| Step: 11
Training loss: 1.3178943395614624
Validation loss: 2.070989648501078

Epoch: 6| Step: 12
Training loss: 1.256843090057373
Validation loss: 2.0912342270215354

Epoch: 6| Step: 13
Training loss: 0.764091968536377
Validation loss: 2.0723411242167153

Epoch: 167| Step: 0
Training loss: 1.7306705713272095
Validation loss: 2.085962494214376

Epoch: 6| Step: 1
Training loss: 1.2788655757904053
Validation loss: 2.041057765483856

Epoch: 6| Step: 2
Training loss: 0.7712489366531372
Validation loss: 2.0936304728190103

Epoch: 6| Step: 3
Training loss: 1.3074644804000854
Validation loss: 2.0431924859682717

Epoch: 6| Step: 4
Training loss: 0.776458740234375
Validation loss: 2.073823889096578

Epoch: 6| Step: 5
Training loss: 1.5711283683776855
Validation loss: 2.0739795565605164

Epoch: 6| Step: 6
Training loss: 1.4715806245803833
Validation loss: 2.0433649818102517

Epoch: 6| Step: 7
Training loss: 0.644578218460083
Validation loss: 2.0733566284179688

Epoch: 6| Step: 8
Training loss: 0.8270551562309265
Validation loss: 2.065301219622294

Epoch: 6| Step: 9
Training loss: 0.9784926176071167
Validation loss: 2.048563222090403

Epoch: 6| Step: 10
Training loss: 0.9322991967201233
Validation loss: 2.0821508367856345

Epoch: 6| Step: 11
Training loss: 1.4595054388046265
Validation loss: 2.049657424290975

Epoch: 6| Step: 12
Training loss: 0.9539099931716919
Validation loss: 2.0764511823654175

Epoch: 6| Step: 13
Training loss: 0.9059156179428101
Validation loss: 2.1067417661348977

Epoch: 168| Step: 0
Training loss: 1.111938238143921
Validation loss: 2.1199503342310586

Epoch: 6| Step: 1
Training loss: 1.6017460823059082
Validation loss: 2.0890509486198425

Epoch: 6| Step: 2
Training loss: 0.8753761053085327
Validation loss: 2.085942884286245

Epoch: 6| Step: 3
Training loss: 0.8978699445724487
Validation loss: 2.071681241194407

Epoch: 6| Step: 4
Training loss: 1.180139183998108
Validation loss: 2.149596949418386

Epoch: 6| Step: 5
Training loss: 1.3772811889648438
Validation loss: 2.0833561420440674

Epoch: 6| Step: 6
Training loss: 1.0238120555877686
Validation loss: 2.088366667429606

Epoch: 6| Step: 7
Training loss: 1.385237216949463
Validation loss: 2.0949522455533347

Epoch: 6| Step: 8
Training loss: 1.6571054458618164
Validation loss: 2.067570070425669

Epoch: 6| Step: 9
Training loss: 1.2622750997543335
Validation loss: 2.0678667028745017

Epoch: 6| Step: 10
Training loss: 0.6306461095809937
Validation loss: 2.068661391735077

Epoch: 6| Step: 11
Training loss: 0.9323673248291016
Validation loss: 2.0547823309898376

Epoch: 6| Step: 12
Training loss: 0.5379981994628906
Validation loss: 2.052313764890035

Epoch: 6| Step: 13
Training loss: 0.7212725877761841
Validation loss: 2.1474047104517617

Epoch: 169| Step: 0
Training loss: 1.1107300519943237
Validation loss: 2.1207821369171143

Epoch: 6| Step: 1
Training loss: 1.196742296218872
Validation loss: 2.0875052014986673

Epoch: 6| Step: 2
Training loss: 1.011671781539917
Validation loss: 2.050890107949575

Epoch: 6| Step: 3
Training loss: 0.9777352213859558
Validation loss: 2.0750030676523843

Epoch: 6| Step: 4
Training loss: 0.9740026593208313
Validation loss: 2.0936301747957864

Epoch: 6| Step: 5
Training loss: 0.9672618508338928
Validation loss: 2.0894298950831094

Epoch: 6| Step: 6
Training loss: 0.9644140601158142
Validation loss: 2.1107654372851052

Epoch: 6| Step: 7
Training loss: 1.8272254467010498
Validation loss: 2.097450315952301

Epoch: 6| Step: 8
Training loss: 1.2260421514511108
Validation loss: 2.104700783888499

Epoch: 6| Step: 9
Training loss: 1.0890581607818604
Validation loss: 2.0909818410873413

Epoch: 6| Step: 10
Training loss: 1.0781347751617432
Validation loss: 2.135315696398417

Epoch: 6| Step: 11
Training loss: 0.9658911824226379
Validation loss: 2.0556389689445496

Epoch: 6| Step: 12
Training loss: 1.126924753189087
Validation loss: 2.137055595715841

Epoch: 6| Step: 13
Training loss: 1.0101839303970337
Validation loss: 2.1154178778330484

Epoch: 170| Step: 0
Training loss: 0.783372163772583
Validation loss: 2.089117149511973

Epoch: 6| Step: 1
Training loss: 1.1440706253051758
Validation loss: 2.077134052912394

Epoch: 6| Step: 2
Training loss: 0.7311885356903076
Validation loss: 2.0675026377042136

Epoch: 6| Step: 3
Training loss: 0.9545676708221436
Validation loss: 2.0822399655977883

Epoch: 6| Step: 4
Training loss: 1.1936485767364502
Validation loss: 2.115675409634908

Epoch: 6| Step: 5
Training loss: 1.1661964654922485
Validation loss: 2.0967697699864707

Epoch: 6| Step: 6
Training loss: 1.437042236328125
Validation loss: 2.0957197745641074

Epoch: 6| Step: 7
Training loss: 0.8070659637451172
Validation loss: 2.1312308311462402

Epoch: 6| Step: 8
Training loss: 1.5646967887878418
Validation loss: 2.087659239768982

Epoch: 6| Step: 9
Training loss: 1.0592252016067505
Validation loss: 2.0756464203198752

Epoch: 6| Step: 10
Training loss: 1.2081637382507324
Validation loss: 2.0864070455233255

Epoch: 6| Step: 11
Training loss: 0.9845391511917114
Validation loss: 2.0480742851893106

Epoch: 6| Step: 12
Training loss: 1.7713321447372437
Validation loss: 2.089228610197703

Epoch: 6| Step: 13
Training loss: 0.45199698209762573
Validation loss: 2.1221381227175393

Epoch: 171| Step: 0
Training loss: 0.7130298018455505
Validation loss: 2.106708288192749

Epoch: 6| Step: 1
Training loss: 1.6525124311447144
Validation loss: 2.045798679192861

Epoch: 6| Step: 2
Training loss: 0.8720403909683228
Validation loss: 2.0691504875818887

Epoch: 6| Step: 3
Training loss: 0.837858259677887
Validation loss: 2.0968110760053

Epoch: 6| Step: 4
Training loss: 0.580669641494751
Validation loss: 2.0832892060279846

Epoch: 6| Step: 5
Training loss: 0.8770108222961426
Validation loss: 2.0913366079330444

Epoch: 6| Step: 6
Training loss: 0.8953570127487183
Validation loss: 2.081305185953776

Epoch: 6| Step: 7
Training loss: 0.8850412964820862
Validation loss: 2.064534584681193

Epoch: 6| Step: 8
Training loss: 1.5146934986114502
Validation loss: 2.0822764237721763

Epoch: 6| Step: 9
Training loss: 1.3098164796829224
Validation loss: 2.1075591246287027

Epoch: 6| Step: 10
Training loss: 1.7699264287948608
Validation loss: 2.089359402656555

Epoch: 6| Step: 11
Training loss: 1.2658014297485352
Validation loss: 2.0714899698893228

Epoch: 6| Step: 12
Training loss: 0.9982312321662903
Validation loss: 2.057401657104492

Epoch: 6| Step: 13
Training loss: 0.8809236288070679
Validation loss: 2.040802796681722

Epoch: 172| Step: 0
Training loss: 1.0412923097610474
Validation loss: 2.1362886826197305

Epoch: 6| Step: 1
Training loss: 0.9784786105155945
Validation loss: 2.1154579520225525

Epoch: 6| Step: 2
Training loss: 1.0152486562728882
Validation loss: 2.1194003423055015

Epoch: 6| Step: 3
Training loss: 0.7866623401641846
Validation loss: 2.129249930381775

Epoch: 6| Step: 4
Training loss: 1.2056688070297241
Validation loss: 2.0671411752700806

Epoch: 6| Step: 5
Training loss: 0.6547455787658691
Validation loss: 2.0282684167226157

Epoch: 6| Step: 6
Training loss: 1.3623228073120117
Validation loss: 2.0658870538075766

Epoch: 6| Step: 7
Training loss: 0.7955308556556702
Validation loss: 2.0884575843811035

Epoch: 6| Step: 8
Training loss: 1.9752025604248047
Validation loss: 2.064993460973104

Epoch: 6| Step: 9
Training loss: 1.0641751289367676
Validation loss: 2.0565452178319297

Epoch: 6| Step: 10
Training loss: 1.1215486526489258
Validation loss: 2.1016531387964883

Epoch: 6| Step: 11
Training loss: 1.5559989213943481
Validation loss: 2.0897050698598227

Epoch: 6| Step: 12
Training loss: 0.971520721912384
Validation loss: 2.045440157254537

Epoch: 6| Step: 13
Training loss: 0.8511267900466919
Validation loss: 2.0506354769070945

Epoch: 173| Step: 0
Training loss: 1.2138715982437134
Validation loss: 2.064982056617737

Epoch: 6| Step: 1
Training loss: 1.3368349075317383
Validation loss: 2.05724690357844

Epoch: 6| Step: 2
Training loss: 0.4918350577354431
Validation loss: 2.076116661230723

Epoch: 6| Step: 3
Training loss: 1.091506004333496
Validation loss: 2.113456209500631

Epoch: 6| Step: 4
Training loss: 1.4664249420166016
Validation loss: 2.05368842681249

Epoch: 6| Step: 5
Training loss: 0.6615076661109924
Validation loss: 2.0971105098724365

Epoch: 6| Step: 6
Training loss: 0.9492321014404297
Validation loss: 2.0811989307403564

Epoch: 6| Step: 7
Training loss: 0.6158608198165894
Validation loss: 2.049461781978607

Epoch: 6| Step: 8
Training loss: 1.5895169973373413
Validation loss: 2.086438775062561

Epoch: 6| Step: 9
Training loss: 0.8304953575134277
Validation loss: 2.1138919393221536

Epoch: 6| Step: 10
Training loss: 0.8202134370803833
Validation loss: 2.0367526610692344

Epoch: 6| Step: 11
Training loss: 1.3499293327331543
Validation loss: 2.054598053296407

Epoch: 6| Step: 12
Training loss: 0.8313513398170471
Validation loss: 2.107595940430959

Epoch: 6| Step: 13
Training loss: 1.2237199544906616
Validation loss: 2.1167712012926736

Epoch: 174| Step: 0
Training loss: 0.9406681060791016
Validation loss: 2.1028572718302407

Epoch: 6| Step: 1
Training loss: 1.2370229959487915
Validation loss: 2.1091356674830117

Epoch: 6| Step: 2
Training loss: 0.7778888940811157
Validation loss: 2.0735034942626953

Epoch: 6| Step: 3
Training loss: 0.8227084875106812
Validation loss: 2.088772177696228

Epoch: 6| Step: 4
Training loss: 0.9177008271217346
Validation loss: 2.108850340048472

Epoch: 6| Step: 5
Training loss: 0.8659386038780212
Validation loss: 2.093302071094513

Epoch: 6| Step: 6
Training loss: 1.2084532976150513
Validation loss: 2.0892042915026345

Epoch: 6| Step: 7
Training loss: 1.2921481132507324
Validation loss: 2.0793683528900146

Epoch: 6| Step: 8
Training loss: 0.9979220628738403
Validation loss: 2.1141253113746643

Epoch: 6| Step: 9
Training loss: 1.3953258991241455
Validation loss: 2.081735153992971

Epoch: 6| Step: 10
Training loss: 0.8318279981613159
Validation loss: 2.1034603913625083

Epoch: 6| Step: 11
Training loss: 1.5737768411636353
Validation loss: 2.0992093880971274

Epoch: 6| Step: 12
Training loss: 0.7886204719543457
Validation loss: 2.099116623401642

Epoch: 6| Step: 13
Training loss: 1.2264894247055054
Validation loss: 2.0773606300354004

Epoch: 175| Step: 0
Training loss: 1.339446783065796
Validation loss: 2.0420520305633545

Epoch: 6| Step: 1
Training loss: 1.0056127309799194
Validation loss: 2.0975610613822937

Epoch: 6| Step: 2
Training loss: 0.9477552175521851
Validation loss: 2.066436290740967

Epoch: 6| Step: 3
Training loss: 1.0486005544662476
Validation loss: 2.1036447485287986

Epoch: 6| Step: 4
Training loss: 0.864788293838501
Validation loss: 2.0897617737452188

Epoch: 6| Step: 5
Training loss: 1.1681734323501587
Validation loss: 2.0411764780680337

Epoch: 6| Step: 6
Training loss: 1.179192066192627
Validation loss: 2.077354073524475

Epoch: 6| Step: 7
Training loss: 0.3988245129585266
Validation loss: 2.0818109711011252

Epoch: 6| Step: 8
Training loss: 0.9239257574081421
Validation loss: 2.062158485253652

Epoch: 6| Step: 9
Training loss: 1.7053296566009521
Validation loss: 2.0764454007148743

Epoch: 6| Step: 10
Training loss: 0.9881226420402527
Validation loss: 2.1434247493743896

Epoch: 6| Step: 11
Training loss: 0.8361188769340515
Validation loss: 2.1406971216201782

Epoch: 6| Step: 12
Training loss: 1.2673349380493164
Validation loss: 2.1500763297080994

Epoch: 6| Step: 13
Training loss: 0.5720084309577942
Validation loss: 2.1096320748329163

Epoch: 176| Step: 0
Training loss: 1.1713026762008667
Validation loss: 2.069555183251699

Epoch: 6| Step: 1
Training loss: 1.2466331720352173
Validation loss: 2.05452831586202

Epoch: 6| Step: 2
Training loss: 1.0426515340805054
Validation loss: 2.109271466732025

Epoch: 6| Step: 3
Training loss: 1.355780839920044
Validation loss: 2.1407567660013833

Epoch: 6| Step: 4
Training loss: 1.346541166305542
Validation loss: 2.149534602959951

Epoch: 6| Step: 5
Training loss: 0.4579893946647644
Validation loss: 2.162332812945048

Epoch: 6| Step: 6
Training loss: 0.7790915966033936
Validation loss: 2.133873244126638

Epoch: 6| Step: 7
Training loss: 0.9763012528419495
Validation loss: 2.0446147521336875

Epoch: 6| Step: 8
Training loss: 1.3231699466705322
Validation loss: 2.071201721827189

Epoch: 6| Step: 9
Training loss: 1.027718424797058
Validation loss: 2.0861563881238303

Epoch: 6| Step: 10
Training loss: 1.2615199089050293
Validation loss: 2.1046385963757834

Epoch: 6| Step: 11
Training loss: 1.1126024723052979
Validation loss: 2.076983471711477

Epoch: 6| Step: 12
Training loss: 0.5789270401000977
Validation loss: 2.074623088041941

Epoch: 6| Step: 13
Training loss: 1.3385705947875977
Validation loss: 2.089537958304087

Epoch: 177| Step: 0
Training loss: 1.075979232788086
Validation loss: 2.083434542020162

Epoch: 6| Step: 1
Training loss: 0.6488655805587769
Validation loss: 2.126436014970144

Epoch: 6| Step: 2
Training loss: 0.6432708501815796
Validation loss: 2.054050068060557

Epoch: 6| Step: 3
Training loss: 1.2253146171569824
Validation loss: 2.0704591274261475

Epoch: 6| Step: 4
Training loss: 1.0588151216506958
Validation loss: 2.133444686730703

Epoch: 6| Step: 5
Training loss: 0.8403458595275879
Validation loss: 2.0644116600354514

Epoch: 6| Step: 6
Training loss: 1.4689198732376099
Validation loss: 2.039188543955485

Epoch: 6| Step: 7
Training loss: 1.2784844636917114
Validation loss: 2.0914905667304993

Epoch: 6| Step: 8
Training loss: 1.485410451889038
Validation loss: 2.092779576778412

Epoch: 6| Step: 9
Training loss: 0.8077066540718079
Validation loss: 2.0831519762674966

Epoch: 6| Step: 10
Training loss: 0.9211611151695251
Validation loss: 2.0620358188947043

Epoch: 6| Step: 11
Training loss: 0.8335095643997192
Validation loss: 2.0832380652427673

Epoch: 6| Step: 12
Training loss: 1.1543161869049072
Validation loss: 2.117064873377482

Epoch: 6| Step: 13
Training loss: 1.2077052593231201
Validation loss: 2.0611228942871094

Epoch: 178| Step: 0
Training loss: 0.6906237602233887
Validation loss: 2.061158458391825

Epoch: 6| Step: 1
Training loss: 0.8257167339324951
Validation loss: 2.0785398880640664

Epoch: 6| Step: 2
Training loss: 0.8649506568908691
Validation loss: 2.092051307360331

Epoch: 6| Step: 3
Training loss: 0.705490231513977
Validation loss: 2.0583861668904624

Epoch: 6| Step: 4
Training loss: 1.0471327304840088
Validation loss: 2.0679990649223328

Epoch: 6| Step: 5
Training loss: 0.9980494976043701
Validation loss: 2.083574036757151

Epoch: 6| Step: 6
Training loss: 0.9694257974624634
Validation loss: 2.1231258312861123

Epoch: 6| Step: 7
Training loss: 1.1647822856903076
Validation loss: 2.1250648895899453

Epoch: 6| Step: 8
Training loss: 1.3228065967559814
Validation loss: 2.1269365350405374

Epoch: 6| Step: 9
Training loss: 0.888756275177002
Validation loss: 2.089495857556661

Epoch: 6| Step: 10
Training loss: 1.020364761352539
Validation loss: 2.0938859780629477

Epoch: 6| Step: 11
Training loss: 1.1484451293945312
Validation loss: 2.051944394906362

Epoch: 6| Step: 12
Training loss: 1.4595704078674316
Validation loss: 2.1224900484085083

Epoch: 6| Step: 13
Training loss: 0.9447525143623352
Validation loss: 2.0756531357765198

Epoch: 179| Step: 0
Training loss: 1.0618681907653809
Validation loss: 2.0934647917747498

Epoch: 6| Step: 1
Training loss: 0.9323750734329224
Validation loss: 2.07616517941157

Epoch: 6| Step: 2
Training loss: 0.6851616501808167
Validation loss: 2.0499959786732993

Epoch: 6| Step: 3
Training loss: 0.7881935238838196
Validation loss: 2.0977423191070557

Epoch: 6| Step: 4
Training loss: 1.2968027591705322
Validation loss: 2.11323877175649

Epoch: 6| Step: 5
Training loss: 0.7313218712806702
Validation loss: 2.0787862141927085

Epoch: 6| Step: 6
Training loss: 1.1701533794403076
Validation loss: 2.088917891184489

Epoch: 6| Step: 7
Training loss: 1.0941851139068604
Validation loss: 2.059496760368347

Epoch: 6| Step: 8
Training loss: 1.2296959161758423
Validation loss: 2.120058794816335

Epoch: 6| Step: 9
Training loss: 1.4270365238189697
Validation loss: 2.067422370115916

Epoch: 6| Step: 10
Training loss: 0.7959431409835815
Validation loss: 2.055370271205902

Epoch: 6| Step: 11
Training loss: 1.020240068435669
Validation loss: 2.0678286949793496

Epoch: 6| Step: 12
Training loss: 1.0686140060424805
Validation loss: 2.0654185811678567

Epoch: 6| Step: 13
Training loss: 1.0044111013412476
Validation loss: 2.073238650957743

Epoch: 180| Step: 0
Training loss: 0.7125254273414612
Validation loss: 2.066914737224579

Epoch: 6| Step: 1
Training loss: 0.7223026752471924
Validation loss: 2.0650545159975686

Epoch: 6| Step: 2
Training loss: 1.1470509767532349
Validation loss: 2.085590740044912

Epoch: 6| Step: 3
Training loss: 1.1717803478240967
Validation loss: 2.0854371786117554

Epoch: 6| Step: 4
Training loss: 0.43873730301856995
Validation loss: 2.0689395864804587

Epoch: 6| Step: 5
Training loss: 0.9533871412277222
Validation loss: 2.0666523575782776

Epoch: 6| Step: 6
Training loss: 1.3973419666290283
Validation loss: 2.10910572608312

Epoch: 6| Step: 7
Training loss: 0.8093087673187256
Validation loss: 2.0841816663742065

Epoch: 6| Step: 8
Training loss: 1.3329836130142212
Validation loss: 2.0904547770818076

Epoch: 6| Step: 9
Training loss: 1.3186683654785156
Validation loss: 2.1004772782325745

Epoch: 6| Step: 10
Training loss: 0.7825403213500977
Validation loss: 2.0818873246510825

Epoch: 6| Step: 11
Training loss: 1.0178277492523193
Validation loss: 2.07573409875234

Epoch: 6| Step: 12
Training loss: 0.6699600219726562
Validation loss: 2.070996960004171

Epoch: 6| Step: 13
Training loss: 1.5183061361312866
Validation loss: 2.0952900449434915

Epoch: 181| Step: 0
Training loss: 0.9329866766929626
Validation loss: 2.1335128943125405

Epoch: 6| Step: 1
Training loss: 0.7124727964401245
Validation loss: 2.0874855717023215

Epoch: 6| Step: 2
Training loss: 0.4423918128013611
Validation loss: 2.0920722683270774

Epoch: 6| Step: 3
Training loss: 1.2606910467147827
Validation loss: 2.0643223921457925

Epoch: 6| Step: 4
Training loss: 1.2701137065887451
Validation loss: 2.0851080417633057

Epoch: 6| Step: 5
Training loss: 0.9855092763900757
Validation loss: 2.081616004308065

Epoch: 6| Step: 6
Training loss: 1.0730061531066895
Validation loss: 2.1140214602152505

Epoch: 6| Step: 7
Training loss: 1.1784451007843018
Validation loss: 2.0551957488059998

Epoch: 6| Step: 8
Training loss: 1.130049228668213
Validation loss: 2.083401083946228

Epoch: 6| Step: 9
Training loss: 0.9793806076049805
Validation loss: 2.097473621368408

Epoch: 6| Step: 10
Training loss: 1.1836001873016357
Validation loss: 2.0841888189315796

Epoch: 6| Step: 11
Training loss: 1.4200628995895386
Validation loss: 2.0971847772598267

Epoch: 6| Step: 12
Training loss: 0.6305136680603027
Validation loss: 2.0912346641222634

Epoch: 6| Step: 13
Training loss: 0.4766245484352112
Validation loss: 2.077290713787079

Epoch: 182| Step: 0
Training loss: 1.3611245155334473
Validation loss: 2.0473015308380127

Epoch: 6| Step: 1
Training loss: 0.5235331654548645
Validation loss: 2.084191302458445

Epoch: 6| Step: 2
Training loss: 1.4154818058013916
Validation loss: 2.0978833436965942

Epoch: 6| Step: 3
Training loss: 1.3340175151824951
Validation loss: 2.0826903184254966

Epoch: 6| Step: 4
Training loss: 0.9443778991699219
Validation loss: 2.109554886817932

Epoch: 6| Step: 5
Training loss: 0.3975197672843933
Validation loss: 2.1047356526056924

Epoch: 6| Step: 6
Training loss: 0.5975711941719055
Validation loss: 2.108268936475118

Epoch: 6| Step: 7
Training loss: 0.952492356300354
Validation loss: 2.0827317237854004

Epoch: 6| Step: 8
Training loss: 1.1262797117233276
Validation loss: 2.1104774276415506

Epoch: 6| Step: 9
Training loss: 1.0634543895721436
Validation loss: 2.038620948791504

Epoch: 6| Step: 10
Training loss: 0.9523470997810364
Validation loss: 2.0625855724016824

Epoch: 6| Step: 11
Training loss: 0.8857962489128113
Validation loss: 2.088923454284668

Epoch: 6| Step: 12
Training loss: 0.7397472262382507
Validation loss: 2.098542869091034

Epoch: 6| Step: 13
Training loss: 1.1111128330230713
Validation loss: 2.0457210739453635

Epoch: 183| Step: 0
Training loss: 1.0279250144958496
Validation loss: 2.0696518421173096

Epoch: 6| Step: 1
Training loss: 0.8398771286010742
Validation loss: 2.0884288946787515

Epoch: 6| Step: 2
Training loss: 1.2972767353057861
Validation loss: 2.035853683948517

Epoch: 6| Step: 3
Training loss: 0.5892373323440552
Validation loss: 2.0814176003138223

Epoch: 6| Step: 4
Training loss: 0.6280554533004761
Validation loss: 2.1053390502929688

Epoch: 6| Step: 5
Training loss: 1.1901172399520874
Validation loss: 2.0494601726531982

Epoch: 6| Step: 6
Training loss: 1.2771363258361816
Validation loss: 2.1057238976160684

Epoch: 6| Step: 7
Training loss: 0.886318564414978
Validation loss: 2.0966472029685974

Epoch: 6| Step: 8
Training loss: 0.7507622241973877
Validation loss: 2.0938642621040344

Epoch: 6| Step: 9
Training loss: 0.8364179134368896
Validation loss: 2.112348179022471

Epoch: 6| Step: 10
Training loss: 1.4992432594299316
Validation loss: 2.0935328602790833

Epoch: 6| Step: 11
Training loss: 0.6785839796066284
Validation loss: 2.1063889463742576

Epoch: 6| Step: 12
Training loss: 1.2235552072525024
Validation loss: 2.095649162928263

Epoch: 6| Step: 13
Training loss: 1.1437270641326904
Validation loss: 2.076884945233663

Epoch: 184| Step: 0
Training loss: 0.9227307438850403
Validation loss: 2.0853025913238525

Epoch: 6| Step: 1
Training loss: 1.0262975692749023
Validation loss: 2.0549022555351257

Epoch: 6| Step: 2
Training loss: 1.0311648845672607
Validation loss: 2.0890970826148987

Epoch: 6| Step: 3
Training loss: 1.2142837047576904
Validation loss: 2.080263674259186

Epoch: 6| Step: 4
Training loss: 0.7045396566390991
Validation loss: 2.088867743810018

Epoch: 6| Step: 5
Training loss: 0.9688830375671387
Validation loss: 2.114748160044352

Epoch: 6| Step: 6
Training loss: 1.0294044017791748
Validation loss: 2.071621060371399

Epoch: 6| Step: 7
Training loss: 0.8635907769203186
Validation loss: 2.121788442134857

Epoch: 6| Step: 8
Training loss: 0.5487713813781738
Validation loss: 2.0493508776028952

Epoch: 6| Step: 9
Training loss: 1.1703726053237915
Validation loss: 2.078144689400991

Epoch: 6| Step: 10
Training loss: 0.9332386255264282
Validation loss: 2.0839027166366577

Epoch: 6| Step: 11
Training loss: 0.6887629628181458
Validation loss: 2.1042710542678833

Epoch: 6| Step: 12
Training loss: 0.8628019690513611
Validation loss: 2.115214745203654

Epoch: 6| Step: 13
Training loss: 1.1411960124969482
Validation loss: 2.076475143432617

Epoch: 185| Step: 0
Training loss: 1.4393773078918457
Validation loss: 2.105469544728597

Epoch: 6| Step: 1
Training loss: 0.9753391742706299
Validation loss: 2.101700405279795

Epoch: 6| Step: 2
Training loss: 1.026207447052002
Validation loss: 2.1228849291801453

Epoch: 6| Step: 3
Training loss: 0.786308228969574
Validation loss: 2.1136704484621682

Epoch: 6| Step: 4
Training loss: 1.1152005195617676
Validation loss: 2.107304890950521

Epoch: 6| Step: 5
Training loss: 1.2008466720581055
Validation loss: 2.1149331529935202

Epoch: 6| Step: 6
Training loss: 1.1477289199829102
Validation loss: 2.080733676751455

Epoch: 6| Step: 7
Training loss: 1.1001044511795044
Validation loss: 2.1064311464627585

Epoch: 6| Step: 8
Training loss: 0.8883097171783447
Validation loss: 2.099539637565613

Epoch: 6| Step: 9
Training loss: 0.9860162138938904
Validation loss: 2.088948428630829

Epoch: 6| Step: 10
Training loss: 0.788418173789978
Validation loss: 2.142733097076416

Epoch: 6| Step: 11
Training loss: 0.6223827600479126
Validation loss: 2.0498404105504355

Epoch: 6| Step: 12
Training loss: 1.4173378944396973
Validation loss: 2.08767839272817

Epoch: 6| Step: 13
Training loss: 0.545292854309082
Validation loss: 2.0468419790267944

Epoch: 186| Step: 0
Training loss: 0.8079577684402466
Validation loss: 2.112752676010132

Epoch: 6| Step: 1
Training loss: 0.8323730230331421
Validation loss: 2.0911362171173096

Epoch: 6| Step: 2
Training loss: 1.419097900390625
Validation loss: 2.0996702909469604

Epoch: 6| Step: 3
Training loss: 1.2370274066925049
Validation loss: 2.055855611960093

Epoch: 6| Step: 4
Training loss: 1.6309980154037476
Validation loss: 2.130198299884796

Epoch: 6| Step: 5
Training loss: 0.9787625074386597
Validation loss: 2.1268758177757263

Epoch: 6| Step: 6
Training loss: 1.0056941509246826
Validation loss: 2.0766918659210205

Epoch: 6| Step: 7
Training loss: 0.5565782189369202
Validation loss: 2.0865903894106546

Epoch: 6| Step: 8
Training loss: 0.6199767589569092
Validation loss: 2.101840078830719

Epoch: 6| Step: 9
Training loss: 0.8064493536949158
Validation loss: 2.0884933471679688

Epoch: 6| Step: 10
Training loss: 0.7376101613044739
Validation loss: 2.108697156111399

Epoch: 6| Step: 11
Training loss: 0.8003922700881958
Validation loss: 2.0778451561927795

Epoch: 6| Step: 12
Training loss: 0.6778694987297058
Validation loss: 2.10073975721995

Epoch: 6| Step: 13
Training loss: 1.1017770767211914
Validation loss: 2.0702757040659585

Epoch: 187| Step: 0
Training loss: 0.7091778516769409
Validation loss: 2.106578826904297

Epoch: 6| Step: 1
Training loss: 0.8659387230873108
Validation loss: 2.064389924208323

Epoch: 6| Step: 2
Training loss: 0.6662659645080566
Validation loss: 2.1026878356933594

Epoch: 6| Step: 3
Training loss: 1.4288854598999023
Validation loss: 2.09783399105072

Epoch: 6| Step: 4
Training loss: 0.8421476483345032
Validation loss: 2.1099648475646973

Epoch: 6| Step: 5
Training loss: 0.5652848482131958
Validation loss: 2.0229148864746094

Epoch: 6| Step: 6
Training loss: 1.108337163925171
Validation loss: 2.086459239323934

Epoch: 6| Step: 7
Training loss: 1.2860524654388428
Validation loss: 2.0874299009641013

Epoch: 6| Step: 8
Training loss: 0.6824567914009094
Validation loss: 2.113726238409678

Epoch: 6| Step: 9
Training loss: 0.9972697496414185
Validation loss: 2.1238301396369934

Epoch: 6| Step: 10
Training loss: 0.9835846424102783
Validation loss: 2.076867163181305

Epoch: 6| Step: 11
Training loss: 1.449090838432312
Validation loss: 2.1244002978006997

Epoch: 6| Step: 12
Training loss: 1.0777194499969482
Validation loss: 2.1560883124669394

Epoch: 6| Step: 13
Training loss: 0.8865343332290649
Validation loss: 2.0964040954907737

Epoch: 188| Step: 0
Training loss: 0.7963806986808777
Validation loss: 2.0726114908854165

Epoch: 6| Step: 1
Training loss: 0.8818743228912354
Validation loss: 2.107116997241974

Epoch: 6| Step: 2
Training loss: 0.8393245935440063
Validation loss: 2.0935840805371604

Epoch: 6| Step: 3
Training loss: 0.861808180809021
Validation loss: 2.1010098854700723

Epoch: 6| Step: 4
Training loss: 0.9452271461486816
Validation loss: 2.0880102713902793

Epoch: 6| Step: 5
Training loss: 0.8806723356246948
Validation loss: 2.0885419845581055

Epoch: 6| Step: 6
Training loss: 1.7273890972137451
Validation loss: 2.0928282737731934

Epoch: 6| Step: 7
Training loss: 0.7633330821990967
Validation loss: 2.12895804643631

Epoch: 6| Step: 8
Training loss: 1.1115705966949463
Validation loss: 2.1122947136561074

Epoch: 6| Step: 9
Training loss: 0.8913504481315613
Validation loss: 2.097372909386953

Epoch: 6| Step: 10
Training loss: 0.8287661075592041
Validation loss: 2.131476640701294

Epoch: 6| Step: 11
Training loss: 0.8121180534362793
Validation loss: 2.127779722213745

Epoch: 6| Step: 12
Training loss: 1.5574249029159546
Validation loss: 2.1204216678937278

Epoch: 6| Step: 13
Training loss: 1.1360845565795898
Validation loss: 2.1336838801701865

Epoch: 189| Step: 0
Training loss: 0.7260425090789795
Validation loss: 2.1386191844940186

Epoch: 6| Step: 1
Training loss: 1.1572743654251099
Validation loss: 2.1194217006365457

Epoch: 6| Step: 2
Training loss: 1.0262653827667236
Validation loss: 2.0937838157018027

Epoch: 6| Step: 3
Training loss: 0.8226169347763062
Validation loss: 2.104284187157949

Epoch: 6| Step: 4
Training loss: 0.9986239075660706
Validation loss: 2.100522041320801

Epoch: 6| Step: 5
Training loss: 0.7187005877494812
Validation loss: 2.090880572795868

Epoch: 6| Step: 6
Training loss: 1.328110933303833
Validation loss: 2.0964794754981995

Epoch: 6| Step: 7
Training loss: 1.3062281608581543
Validation loss: 2.092412312825521

Epoch: 6| Step: 8
Training loss: 0.5465309023857117
Validation loss: 2.0810548464457193

Epoch: 6| Step: 9
Training loss: 1.3788185119628906
Validation loss: 2.0684545437494912

Epoch: 6| Step: 10
Training loss: 1.0219504833221436
Validation loss: 2.1380510330200195

Epoch: 6| Step: 11
Training loss: 1.053293228149414
Validation loss: 2.0907137393951416

Epoch: 6| Step: 12
Training loss: 1.1119697093963623
Validation loss: 2.1587215662002563

Epoch: 6| Step: 13
Training loss: 0.879340410232544
Validation loss: 2.1085201303164163

Epoch: 190| Step: 0
Training loss: 0.713742733001709
Validation loss: 2.131438593069712

Epoch: 6| Step: 1
Training loss: 1.3011877536773682
Validation loss: 2.0606839458147683

Epoch: 6| Step: 2
Training loss: 1.0629923343658447
Validation loss: 2.0757418672243753

Epoch: 6| Step: 3
Training loss: 0.7238152623176575
Validation loss: 2.0574080546696982

Epoch: 6| Step: 4
Training loss: 0.669293224811554
Validation loss: 2.1162010033925376

Epoch: 6| Step: 5
Training loss: 0.6471044421195984
Validation loss: 2.0786536733309426

Epoch: 6| Step: 6
Training loss: 0.7231345176696777
Validation loss: 2.1104441483815513

Epoch: 6| Step: 7
Training loss: 0.7923784255981445
Validation loss: 2.0999327301979065

Epoch: 6| Step: 8
Training loss: 0.6251599788665771
Validation loss: 2.0638192296028137

Epoch: 6| Step: 9
Training loss: 1.2259860038757324
Validation loss: 2.081156015396118

Epoch: 6| Step: 10
Training loss: 1.0977370738983154
Validation loss: 2.0585126082102456

Epoch: 6| Step: 11
Training loss: 0.6826013922691345
Validation loss: 2.043280522028605

Epoch: 6| Step: 12
Training loss: 1.0936450958251953
Validation loss: 2.0923357407251992

Epoch: 6| Step: 13
Training loss: 1.443179726600647
Validation loss: 2.0707507530848184

Epoch: 191| Step: 0
Training loss: 1.125933289527893
Validation loss: 2.0758351484934487

Epoch: 6| Step: 1
Training loss: 1.1493042707443237
Validation loss: 2.0791392723719277

Epoch: 6| Step: 2
Training loss: 0.9209840297698975
Validation loss: 2.138260086377462

Epoch: 6| Step: 3
Training loss: 0.8392653465270996
Validation loss: 2.115726669629415

Epoch: 6| Step: 4
Training loss: 0.7909842133522034
Validation loss: 2.0865920186042786

Epoch: 6| Step: 5
Training loss: 0.7877989411354065
Validation loss: 2.0408170223236084

Epoch: 6| Step: 6
Training loss: 1.0293792486190796
Validation loss: 2.0862627029418945

Epoch: 6| Step: 7
Training loss: 0.8082828521728516
Validation loss: 2.1190967361132302

Epoch: 6| Step: 8
Training loss: 1.3854906558990479
Validation loss: 2.0963996251424155

Epoch: 6| Step: 9
Training loss: 0.667523205280304
Validation loss: 2.057334840297699

Epoch: 6| Step: 10
Training loss: 1.1833183765411377
Validation loss: 2.111239016056061

Epoch: 6| Step: 11
Training loss: 0.900444746017456
Validation loss: 2.0537115335464478

Epoch: 6| Step: 12
Training loss: 1.388648271560669
Validation loss: 2.034463425477346

Epoch: 6| Step: 13
Training loss: 0.7842086553573608
Validation loss: 2.0496938029925027

Epoch: 192| Step: 0
Training loss: 0.8970960974693298
Validation loss: 2.054817259311676

Epoch: 6| Step: 1
Training loss: 1.0894906520843506
Validation loss: 2.0711175203323364

Epoch: 6| Step: 2
Training loss: 1.1497384309768677
Validation loss: 2.057013471921285

Epoch: 6| Step: 3
Training loss: 1.097028136253357
Validation loss: 2.0900906523068747

Epoch: 6| Step: 4
Training loss: 0.8614130020141602
Validation loss: 2.0568411548932395

Epoch: 6| Step: 5
Training loss: 0.909738302230835
Validation loss: 2.097325166066488

Epoch: 6| Step: 6
Training loss: 0.7970438599586487
Validation loss: 2.051189204057058

Epoch: 6| Step: 7
Training loss: 0.7642863988876343
Validation loss: 2.057699461778005

Epoch: 6| Step: 8
Training loss: 0.6755024790763855
Validation loss: 2.111832578976949

Epoch: 6| Step: 9
Training loss: 1.2468372583389282
Validation loss: 2.057731866836548

Epoch: 6| Step: 10
Training loss: 0.8037496209144592
Validation loss: 2.094593902428945

Epoch: 6| Step: 11
Training loss: 0.9989078044891357
Validation loss: 2.03461762269338

Epoch: 6| Step: 12
Training loss: 0.7858617305755615
Validation loss: 2.0880950490633645

Epoch: 6| Step: 13
Training loss: 1.2212092876434326
Validation loss: 2.069665531317393

Epoch: 193| Step: 0
Training loss: 0.6894345879554749
Validation loss: 2.094205995400747

Epoch: 6| Step: 1
Training loss: 1.1642262935638428
Validation loss: 2.108251432577769

Epoch: 6| Step: 2
Training loss: 0.8712754249572754
Validation loss: 2.092042605082194

Epoch: 6| Step: 3
Training loss: 0.8107166290283203
Validation loss: 2.0828776955604553

Epoch: 6| Step: 4
Training loss: 0.5797232389450073
Validation loss: 2.076875845591227

Epoch: 6| Step: 5
Training loss: 0.8640820980072021
Validation loss: 2.0401678482691445

Epoch: 6| Step: 6
Training loss: 1.091814398765564
Validation loss: 2.1288564999898276

Epoch: 6| Step: 7
Training loss: 1.2022348642349243
Validation loss: 2.0907336672147117

Epoch: 6| Step: 8
Training loss: 0.7684816122055054
Validation loss: 2.038929303487142

Epoch: 6| Step: 9
Training loss: 1.075018048286438
Validation loss: 2.0814229051272073

Epoch: 6| Step: 10
Training loss: 0.5541375875473022
Validation loss: 2.0583645701408386

Epoch: 6| Step: 11
Training loss: 0.7481926679611206
Validation loss: 2.045115907986959

Epoch: 6| Step: 12
Training loss: 1.2662750482559204
Validation loss: 2.059757570425669

Epoch: 6| Step: 13
Training loss: 0.9459218978881836
Validation loss: 2.101624588171641

Epoch: 194| Step: 0
Training loss: 1.0519742965698242
Validation loss: 2.0930256843566895

Epoch: 6| Step: 1
Training loss: 0.8332056999206543
Validation loss: 2.04509303967158

Epoch: 6| Step: 2
Training loss: 1.72559654712677
Validation loss: 2.0698970953623452

Epoch: 6| Step: 3
Training loss: 0.5808342695236206
Validation loss: 2.0729369719823203

Epoch: 6| Step: 4
Training loss: 0.8544892072677612
Validation loss: 2.090589086214701

Epoch: 6| Step: 5
Training loss: 0.6775103211402893
Validation loss: 2.046716014544169

Epoch: 6| Step: 6
Training loss: 0.8413716554641724
Validation loss: 2.0768574476242065

Epoch: 6| Step: 7
Training loss: 0.43059754371643066
Validation loss: 2.063033858935038

Epoch: 6| Step: 8
Training loss: 0.8937307000160217
Validation loss: 2.0680447816848755

Epoch: 6| Step: 9
Training loss: 0.6794940233230591
Validation loss: 2.038671096165975

Epoch: 6| Step: 10
Training loss: 1.8543665409088135
Validation loss: 2.0460071166356406

Epoch: 6| Step: 11
Training loss: 0.8865228891372681
Validation loss: 2.053745528062185

Epoch: 6| Step: 12
Training loss: 0.5739154815673828
Validation loss: 2.0983455181121826

Epoch: 6| Step: 13
Training loss: 0.9958369731903076
Validation loss: 2.0508498748143515

Epoch: 195| Step: 0
Training loss: 1.3132624626159668
Validation loss: 2.0792283018430076

Epoch: 6| Step: 1
Training loss: 0.3682563304901123
Validation loss: 2.124318281809489

Epoch: 6| Step: 2
Training loss: 1.1592209339141846
Validation loss: 2.0818543831507363

Epoch: 6| Step: 3
Training loss: 1.0004148483276367
Validation loss: 2.056429843107859

Epoch: 6| Step: 4
Training loss: 1.1216278076171875
Validation loss: 2.0833683411280313

Epoch: 6| Step: 5
Training loss: 0.8339996337890625
Validation loss: 2.0904696782430015

Epoch: 6| Step: 6
Training loss: 1.261000394821167
Validation loss: 2.0797306895256042

Epoch: 6| Step: 7
Training loss: 0.9456088542938232
Validation loss: 2.067915439605713

Epoch: 6| Step: 8
Training loss: 1.1517105102539062
Validation loss: 2.0827907721201577

Epoch: 6| Step: 9
Training loss: 0.9379630088806152
Validation loss: 2.0970715085665383

Epoch: 6| Step: 10
Training loss: 0.5366244316101074
Validation loss: 2.1535017689069114

Epoch: 6| Step: 11
Training loss: 1.0151710510253906
Validation loss: 2.0853611628214517

Epoch: 6| Step: 12
Training loss: 0.5372641682624817
Validation loss: 2.0754952430725098

Epoch: 6| Step: 13
Training loss: 0.8989526629447937
Validation loss: 2.0735018849372864

Epoch: 196| Step: 0
Training loss: 0.8958673477172852
Validation loss: 2.069609781106313

Epoch: 6| Step: 1
Training loss: 1.189850091934204
Validation loss: 2.0698430935541787

Epoch: 6| Step: 2
Training loss: 0.7730684876441956
Validation loss: 2.0552090605099997

Epoch: 6| Step: 3
Training loss: 0.9893198013305664
Validation loss: 2.097422957420349

Epoch: 6| Step: 4
Training loss: 0.9757947325706482
Validation loss: 2.085458437601725

Epoch: 6| Step: 5
Training loss: 0.37626025080680847
Validation loss: 2.1000728011131287

Epoch: 6| Step: 6
Training loss: 0.8662756681442261
Validation loss: 2.0635165572166443

Epoch: 6| Step: 7
Training loss: 0.9292801022529602
Validation loss: 2.0837992827097573

Epoch: 6| Step: 8
Training loss: 1.0523070096969604
Validation loss: 2.052661637465159

Epoch: 6| Step: 9
Training loss: 0.6870476007461548
Validation loss: 2.026501496632894

Epoch: 6| Step: 10
Training loss: 1.3794914484024048
Validation loss: 2.0599673787752786

Epoch: 6| Step: 11
Training loss: 1.50809907913208
Validation loss: 2.0806570847829184

Epoch: 6| Step: 12
Training loss: 0.5020856857299805
Validation loss: 2.096552868684133

Epoch: 6| Step: 13
Training loss: 0.7573914527893066
Validation loss: 2.073124130566915

Epoch: 197| Step: 0
Training loss: 0.5985715389251709
Validation loss: 2.0707245667775473

Epoch: 6| Step: 1
Training loss: 0.8893471956253052
Validation loss: 2.070828298727671

Epoch: 6| Step: 2
Training loss: 0.7809250950813293
Validation loss: 2.093855897585551

Epoch: 6| Step: 3
Training loss: 1.0429856777191162
Validation loss: 2.061196208000183

Epoch: 6| Step: 4
Training loss: 1.0484373569488525
Validation loss: 2.0849955479303994

Epoch: 6| Step: 5
Training loss: 0.9160020351409912
Validation loss: 2.050386925538381

Epoch: 6| Step: 6
Training loss: 0.6762425303459167
Validation loss: 2.107279618581136

Epoch: 6| Step: 7
Training loss: 1.219977617263794
Validation loss: 2.0625332593917847

Epoch: 6| Step: 8
Training loss: 1.112788438796997
Validation loss: 2.0620834032694497

Epoch: 6| Step: 9
Training loss: 0.944454550743103
Validation loss: 2.0902216831843057

Epoch: 6| Step: 10
Training loss: 0.8375817537307739
Validation loss: 2.0609752933184304

Epoch: 6| Step: 11
Training loss: 0.5939220786094666
Validation loss: 2.041696767012278

Epoch: 6| Step: 12
Training loss: 0.9438068866729736
Validation loss: 2.0679142077763877

Epoch: 6| Step: 13
Training loss: 0.9169889688491821
Validation loss: 2.0427194833755493

Epoch: 198| Step: 0
Training loss: 0.8190548419952393
Validation loss: 2.1201104124387107

Epoch: 6| Step: 1
Training loss: 0.6046417951583862
Validation loss: 2.1172284682591758

Epoch: 6| Step: 2
Training loss: 0.6681438684463501
Validation loss: 2.0667174657185874

Epoch: 6| Step: 3
Training loss: 0.8058935403823853
Validation loss: 2.060028553009033

Epoch: 6| Step: 4
Training loss: 0.8933299779891968
Validation loss: 2.1068228681882224

Epoch: 6| Step: 5
Training loss: 0.830230712890625
Validation loss: 2.0630992452303567

Epoch: 6| Step: 6
Training loss: 0.6213985681533813
Validation loss: 2.054900268713633

Epoch: 6| Step: 7
Training loss: 0.9279825687408447
Validation loss: 2.0652186075846353

Epoch: 6| Step: 8
Training loss: 0.7526860237121582
Validation loss: 2.0782586534818015

Epoch: 6| Step: 9
Training loss: 0.9302094578742981
Validation loss: 2.0679962436358132

Epoch: 6| Step: 10
Training loss: 0.8529772758483887
Validation loss: 2.0621054967244468

Epoch: 6| Step: 11
Training loss: 0.6342130899429321
Validation loss: 2.1135270992914834

Epoch: 6| Step: 12
Training loss: 1.0369200706481934
Validation loss: 2.1002622842788696

Epoch: 6| Step: 13
Training loss: 1.6282163858413696
Validation loss: 2.1156431833902993

Epoch: 199| Step: 0
Training loss: 0.9957832098007202
Validation loss: 2.07819531361262

Epoch: 6| Step: 1
Training loss: 0.6141185760498047
Validation loss: 2.0651586850484214

Epoch: 6| Step: 2
Training loss: 0.5487236976623535
Validation loss: 2.1027724941571555

Epoch: 6| Step: 3
Training loss: 1.1910357475280762
Validation loss: 2.0600584348042807

Epoch: 6| Step: 4
Training loss: 0.981122612953186
Validation loss: 2.050406575202942

Epoch: 6| Step: 5
Training loss: 0.4386696219444275
Validation loss: 2.052032550175985

Epoch: 6| Step: 6
Training loss: 1.2249023914337158
Validation loss: 2.056478420893351

Epoch: 6| Step: 7
Training loss: 1.153808355331421
Validation loss: 2.1092387636502585

Epoch: 6| Step: 8
Training loss: 1.183978796005249
Validation loss: 2.0276050368944802

Epoch: 6| Step: 9
Training loss: 0.4892190992832184
Validation loss: 2.088714818159739

Epoch: 6| Step: 10
Training loss: 1.1294670104980469
Validation loss: 2.0368648966153464

Epoch: 6| Step: 11
Training loss: 0.6433050036430359
Validation loss: 2.076270262400309

Epoch: 6| Step: 12
Training loss: 0.5966874957084656
Validation loss: 2.089229643344879

Epoch: 6| Step: 13
Training loss: 0.9728773832321167
Validation loss: 2.083932101726532

Epoch: 200| Step: 0
Training loss: 1.086153507232666
Validation loss: 2.092007875442505

Epoch: 6| Step: 1
Training loss: 0.4886413812637329
Validation loss: 2.0826420386632285

Epoch: 6| Step: 2
Training loss: 1.392999291419983
Validation loss: 2.026884078979492

Epoch: 6| Step: 3
Training loss: 1.2095577716827393
Validation loss: 2.0556072195370994

Epoch: 6| Step: 4
Training loss: 0.4969235062599182
Validation loss: 2.0705663363138833

Epoch: 6| Step: 5
Training loss: 0.7630902528762817
Validation loss: 2.039585053920746

Epoch: 6| Step: 6
Training loss: 1.123032569885254
Validation loss: 2.107070247332255

Epoch: 6| Step: 7
Training loss: 0.8422669768333435
Validation loss: 2.0675554871559143

Epoch: 6| Step: 8
Training loss: 0.7140904068946838
Validation loss: 2.114943524201711

Epoch: 6| Step: 9
Training loss: 0.9228411912918091
Validation loss: 2.0859923164049783

Epoch: 6| Step: 10
Training loss: 1.0479767322540283
Validation loss: 2.0884080131848655

Epoch: 6| Step: 11
Training loss: 0.9622650146484375
Validation loss: 2.1164287328720093

Epoch: 6| Step: 12
Training loss: 0.9712835550308228
Validation loss: 2.1138310631116233

Epoch: 6| Step: 13
Training loss: 0.9164349436759949
Validation loss: 2.088276505470276

Epoch: 201| Step: 0
Training loss: 0.8577558994293213
Validation loss: 2.0532569090525308

Epoch: 6| Step: 1
Training loss: 0.8678293824195862
Validation loss: 2.055388867855072

Epoch: 6| Step: 2
Training loss: 1.1279592514038086
Validation loss: 2.0799810687700906

Epoch: 6| Step: 3
Training loss: 1.0862176418304443
Validation loss: 2.0740934213002524

Epoch: 6| Step: 4
Training loss: 1.319143295288086
Validation loss: 2.1187423865000405

Epoch: 6| Step: 5
Training loss: 1.0253634452819824
Validation loss: 2.1176507472991943

Epoch: 6| Step: 6
Training loss: 0.8850229978561401
Validation loss: 2.089253564675649

Epoch: 6| Step: 7
Training loss: 1.2077374458312988
Validation loss: 2.0542867183685303

Epoch: 6| Step: 8
Training loss: 0.5923511981964111
Validation loss: 2.0993598898251853

Epoch: 6| Step: 9
Training loss: 0.7593686580657959
Validation loss: 2.0834933320681253

Epoch: 6| Step: 10
Training loss: 1.164638876914978
Validation loss: 2.1291040182113647

Epoch: 6| Step: 11
Training loss: 1.2247227430343628
Validation loss: 2.142397920290629

Epoch: 6| Step: 12
Training loss: 1.147283673286438
Validation loss: 2.1625682711601257

Epoch: 6| Step: 13
Training loss: 0.5333552360534668
Validation loss: 2.1341896255811057

Epoch: 202| Step: 0
Training loss: 1.067257046699524
Validation loss: 2.087480982144674

Epoch: 6| Step: 1
Training loss: 0.8891216516494751
Validation loss: 2.0706914265950522

Epoch: 6| Step: 2
Training loss: 0.5704526305198669
Validation loss: 2.0604766607284546

Epoch: 6| Step: 3
Training loss: 1.3491922616958618
Validation loss: 2.037734031677246

Epoch: 6| Step: 4
Training loss: 0.4609861373901367
Validation loss: 2.0693602561950684

Epoch: 6| Step: 5
Training loss: 0.8281978368759155
Validation loss: 2.020222802956899

Epoch: 6| Step: 6
Training loss: 0.748376727104187
Validation loss: 2.094107468922933

Epoch: 6| Step: 7
Training loss: 0.9374300241470337
Validation loss: 2.072464108467102

Epoch: 6| Step: 8
Training loss: 0.8308789730072021
Validation loss: 2.1093432704607644

Epoch: 6| Step: 9
Training loss: 0.6464604139328003
Validation loss: 2.132863998413086

Epoch: 6| Step: 10
Training loss: 1.248023509979248
Validation loss: 2.0881164272626243

Epoch: 6| Step: 11
Training loss: 1.1835200786590576
Validation loss: 2.1090046167373657

Epoch: 6| Step: 12
Training loss: 1.3077834844589233
Validation loss: 2.114690363407135

Epoch: 6| Step: 13
Training loss: 0.5129494667053223
Validation loss: 2.0952224135398865

Epoch: 203| Step: 0
Training loss: 1.1027308702468872
Validation loss: 2.0829805731773376

Epoch: 6| Step: 1
Training loss: 1.0605366230010986
Validation loss: 2.0600392619768777

Epoch: 6| Step: 2
Training loss: 0.9286015629768372
Validation loss: 2.065237879753113

Epoch: 6| Step: 3
Training loss: 0.4592830538749695
Validation loss: 2.075827479362488

Epoch: 6| Step: 4
Training loss: 1.1544238328933716
Validation loss: 2.062908331553141

Epoch: 6| Step: 5
Training loss: 0.8910483121871948
Validation loss: 2.1103424429893494

Epoch: 6| Step: 6
Training loss: 0.9300755858421326
Validation loss: 2.0904924273490906

Epoch: 6| Step: 7
Training loss: 0.8860993385314941
Validation loss: 2.0645016630490622

Epoch: 6| Step: 8
Training loss: 1.1797590255737305
Validation loss: 2.0589125752449036

Epoch: 6| Step: 9
Training loss: 0.7145792245864868
Validation loss: 2.1141563653945923

Epoch: 6| Step: 10
Training loss: 0.7307479381561279
Validation loss: 2.0963042179743447

Epoch: 6| Step: 11
Training loss: 0.377005934715271
Validation loss: 2.127225319544474

Epoch: 6| Step: 12
Training loss: 1.2229747772216797
Validation loss: 2.1471128265062966

Epoch: 6| Step: 13
Training loss: 0.960879921913147
Validation loss: 2.0440355936686196

Epoch: 204| Step: 0
Training loss: 1.5917818546295166
Validation loss: 2.1355993151664734

Epoch: 6| Step: 1
Training loss: 1.5780959129333496
Validation loss: 2.0429000854492188

Epoch: 6| Step: 2
Training loss: 0.7442130446434021
Validation loss: 2.0679946541786194

Epoch: 6| Step: 3
Training loss: 0.9952012896537781
Validation loss: 2.0632408062616983

Epoch: 6| Step: 4
Training loss: 0.6769816875457764
Validation loss: 2.10439270734787

Epoch: 6| Step: 5
Training loss: 0.4492948055267334
Validation loss: 2.029981474081675

Epoch: 6| Step: 6
Training loss: 1.2439508438110352
Validation loss: 2.0653144915898642

Epoch: 6| Step: 7
Training loss: 0.48234090209007263
Validation loss: 2.04980460802714

Epoch: 6| Step: 8
Training loss: 0.7659212350845337
Validation loss: 2.041457156340281

Epoch: 6| Step: 9
Training loss: 0.8800098299980164
Validation loss: 2.040075500806173

Epoch: 6| Step: 10
Training loss: 0.9450778961181641
Validation loss: 2.057822128136953

Epoch: 6| Step: 11
Training loss: 0.6365276575088501
Validation loss: 2.05065647761027

Epoch: 6| Step: 12
Training loss: 0.8814648389816284
Validation loss: 2.0566673278808594

Epoch: 6| Step: 13
Training loss: 0.48307546973228455
Validation loss: 2.0906620422999063

Epoch: 205| Step: 0
Training loss: 0.5572128295898438
Validation loss: 2.062394062678019

Epoch: 6| Step: 1
Training loss: 0.5052552223205566
Validation loss: 2.0791808366775513

Epoch: 6| Step: 2
Training loss: 0.8574987649917603
Validation loss: 2.084422548611959

Epoch: 6| Step: 3
Training loss: 1.5118117332458496
Validation loss: 2.0902395049730935

Epoch: 6| Step: 4
Training loss: 1.1042125225067139
Validation loss: 2.1099393566449485

Epoch: 6| Step: 5
Training loss: 0.662065863609314
Validation loss: 2.1239279905954995

Epoch: 6| Step: 6
Training loss: 0.482089638710022
Validation loss: 2.0602033138275146

Epoch: 6| Step: 7
Training loss: 1.0974091291427612
Validation loss: 2.116223474343618

Epoch: 6| Step: 8
Training loss: 0.8016560673713684
Validation loss: 2.056664288043976

Epoch: 6| Step: 9
Training loss: 1.122721552848816
Validation loss: 2.0842228730519614

Epoch: 6| Step: 10
Training loss: 1.35311758518219
Validation loss: 2.0191102027893066

Epoch: 6| Step: 11
Training loss: 0.8925570249557495
Validation loss: 2.022866447766622

Epoch: 6| Step: 12
Training loss: 0.7455132007598877
Validation loss: 2.0801461736361184

Epoch: 6| Step: 13
Training loss: 0.7477536201477051
Validation loss: 2.066076874732971

Epoch: 206| Step: 0
Training loss: 0.684868335723877
Validation loss: 2.0584068298339844

Epoch: 6| Step: 1
Training loss: 0.9848435521125793
Validation loss: 2.0914898912111917

Epoch: 6| Step: 2
Training loss: 0.9221690893173218
Validation loss: 2.0957985719045005

Epoch: 6| Step: 3
Training loss: 1.0229195356369019
Validation loss: 2.0518343647321067

Epoch: 6| Step: 4
Training loss: 1.126654028892517
Validation loss: 2.087333540121714

Epoch: 6| Step: 5
Training loss: 0.5057381391525269
Validation loss: 2.1254147489865622

Epoch: 6| Step: 6
Training loss: 0.7760342359542847
Validation loss: 2.066671311855316

Epoch: 6| Step: 7
Training loss: 1.248985767364502
Validation loss: 2.100600083669027

Epoch: 6| Step: 8
Training loss: 0.41698700189590454
Validation loss: 2.0970795154571533

Epoch: 6| Step: 9
Training loss: 0.8125076293945312
Validation loss: 2.047667384147644

Epoch: 6| Step: 10
Training loss: 1.1013758182525635
Validation loss: 2.096122622489929

Epoch: 6| Step: 11
Training loss: 0.5336987972259521
Validation loss: 2.0857646465301514

Epoch: 6| Step: 12
Training loss: 0.8932287693023682
Validation loss: 2.0241968631744385

Epoch: 6| Step: 13
Training loss: 1.271053433418274
Validation loss: 2.098630507787069

Epoch: 207| Step: 0
Training loss: 0.6563245058059692
Validation loss: 2.080103894074758

Epoch: 6| Step: 1
Training loss: 0.5595674514770508
Validation loss: 2.0689688126246133

Epoch: 6| Step: 2
Training loss: 1.3160247802734375
Validation loss: 2.0925304690996804

Epoch: 6| Step: 3
Training loss: 0.578544020652771
Validation loss: 2.08946031332016

Epoch: 6| Step: 4
Training loss: 0.5053701400756836
Validation loss: 2.1040650606155396

Epoch: 6| Step: 5
Training loss: 1.0210418701171875
Validation loss: 2.056517938772837

Epoch: 6| Step: 6
Training loss: 1.0818257331848145
Validation loss: 2.0669480562210083

Epoch: 6| Step: 7
Training loss: 0.8652559518814087
Validation loss: 2.050960898399353

Epoch: 6| Step: 8
Training loss: 1.2014026641845703
Validation loss: 2.0731292764345803

Epoch: 6| Step: 9
Training loss: 1.050084114074707
Validation loss: 2.0713442961374917

Epoch: 6| Step: 10
Training loss: 0.5025652647018433
Validation loss: 2.0880088806152344

Epoch: 6| Step: 11
Training loss: 0.7810351848602295
Validation loss: 2.099732597668966

Epoch: 6| Step: 12
Training loss: 0.7560187578201294
Validation loss: 2.076992710431417

Epoch: 6| Step: 13
Training loss: 1.3209943771362305
Validation loss: 2.1171909173329673

Epoch: 208| Step: 0
Training loss: 0.71662837266922
Validation loss: 2.120268185933431

Epoch: 6| Step: 1
Training loss: 0.7466484308242798
Validation loss: 2.09102463722229

Epoch: 6| Step: 2
Training loss: 0.7982022762298584
Validation loss: 2.0960550904273987

Epoch: 6| Step: 3
Training loss: 1.0274347066879272
Validation loss: 2.0894742806752524

Epoch: 6| Step: 4
Training loss: 1.0187572240829468
Validation loss: 2.0497089624404907

Epoch: 6| Step: 5
Training loss: 1.2712159156799316
Validation loss: 2.0674543976783752

Epoch: 6| Step: 6
Training loss: 0.7277966737747192
Validation loss: 2.0644623835881553

Epoch: 6| Step: 7
Training loss: 0.5877515077590942
Validation loss: 2.0485006968180337

Epoch: 6| Step: 8
Training loss: 0.8954906463623047
Validation loss: 2.0739734371503196

Epoch: 6| Step: 9
Training loss: 0.6455560922622681
Validation loss: 2.08045893907547

Epoch: 6| Step: 10
Training loss: 0.7690683603286743
Validation loss: 1.9786012768745422

Epoch: 6| Step: 11
Training loss: 0.5525633096694946
Validation loss: 2.067915439605713

Epoch: 6| Step: 12
Training loss: 0.8813602328300476
Validation loss: 2.050936003526052

Epoch: 6| Step: 13
Training loss: 1.344765543937683
Validation loss: 2.0560960372289023

Epoch: 209| Step: 0
Training loss: 0.7491737604141235
Validation loss: 2.050366977850596

Epoch: 6| Step: 1
Training loss: 1.2441762685775757
Validation loss: 2.0296035408973694

Epoch: 6| Step: 2
Training loss: 0.6871960163116455
Validation loss: 2.082960764567057

Epoch: 6| Step: 3
Training loss: 0.6352654695510864
Validation loss: 2.0816981196403503

Epoch: 6| Step: 4
Training loss: 1.615177869796753
Validation loss: 2.0401599407196045

Epoch: 6| Step: 5
Training loss: 0.4374878704547882
Validation loss: 2.0626580516497293

Epoch: 6| Step: 6
Training loss: 0.5849432945251465
Validation loss: 2.078790307044983

Epoch: 6| Step: 7
Training loss: 1.0083826780319214
Validation loss: 2.0173423886299133

Epoch: 6| Step: 8
Training loss: 1.2375996112823486
Validation loss: 2.0389852126439414

Epoch: 6| Step: 9
Training loss: 0.7166645526885986
Validation loss: 2.046217381954193

Epoch: 6| Step: 10
Training loss: 0.7115738391876221
Validation loss: 2.0810941656430564

Epoch: 6| Step: 11
Training loss: 0.6753810048103333
Validation loss: 2.062192996342977

Epoch: 6| Step: 12
Training loss: 0.8863035440444946
Validation loss: 2.061072806517283

Epoch: 6| Step: 13
Training loss: 0.8261237740516663
Validation loss: 2.121027668317159

Epoch: 210| Step: 0
Training loss: 1.4023171663284302
Validation loss: 2.069209337234497

Epoch: 6| Step: 1
Training loss: 1.0697234869003296
Validation loss: 2.0692267417907715

Epoch: 6| Step: 2
Training loss: 0.7773481011390686
Validation loss: 2.0570621887842813

Epoch: 6| Step: 3
Training loss: 0.7406116724014282
Validation loss: 2.0738428235054016

Epoch: 6| Step: 4
Training loss: 0.7931495904922485
Validation loss: 2.0752959648768106

Epoch: 6| Step: 5
Training loss: 1.1131987571716309
Validation loss: 2.0958913763364158

Epoch: 6| Step: 6
Training loss: 0.9175361394882202
Validation loss: 2.0917367339134216

Epoch: 6| Step: 7
Training loss: 0.6244524121284485
Validation loss: 2.0830615957578025

Epoch: 6| Step: 8
Training loss: 0.4147123396396637
Validation loss: 2.08157217502594

Epoch: 6| Step: 9
Training loss: 0.5140194892883301
Validation loss: 2.054861903190613

Epoch: 6| Step: 10
Training loss: 0.5256247520446777
Validation loss: 2.0667500495910645

Epoch: 6| Step: 11
Training loss: 1.4470237493515015
Validation loss: 2.133944789568583

Epoch: 6| Step: 12
Training loss: 0.5130752325057983
Validation loss: 2.094382325808207

Epoch: 6| Step: 13
Training loss: 0.8024962544441223
Validation loss: 2.0658182501792908

Epoch: 211| Step: 0
Training loss: 1.1151385307312012
Validation loss: 2.0718976259231567

Epoch: 6| Step: 1
Training loss: 0.779092013835907
Validation loss: 2.1040488481521606

Epoch: 6| Step: 2
Training loss: 1.1363046169281006
Validation loss: 2.0881760319073996

Epoch: 6| Step: 3
Training loss: 0.28137826919555664
Validation loss: 2.052708625793457

Epoch: 6| Step: 4
Training loss: 1.1666767597198486
Validation loss: 2.043220063050588

Epoch: 6| Step: 5
Training loss: 0.6072371006011963
Validation loss: 2.056187907854716

Epoch: 6| Step: 6
Training loss: 0.705437421798706
Validation loss: 2.091803471247355

Epoch: 6| Step: 7
Training loss: 0.7179774045944214
Validation loss: 2.0761955181757608

Epoch: 6| Step: 8
Training loss: 0.9516156911849976
Validation loss: 2.0899463097254434

Epoch: 6| Step: 9
Training loss: 0.5983273983001709
Validation loss: 2.0762630701065063

Epoch: 6| Step: 10
Training loss: 1.061124563217163
Validation loss: 2.148657818635305

Epoch: 6| Step: 11
Training loss: 0.7961097359657288
Validation loss: 2.1032509803771973

Epoch: 6| Step: 12
Training loss: 1.1468368768692017
Validation loss: 2.0454284946123757

Epoch: 6| Step: 13
Training loss: 0.6817843914031982
Validation loss: 2.069428284962972

Epoch: 212| Step: 0
Training loss: 0.9076250791549683
Validation loss: 2.0938673416773477

Epoch: 6| Step: 1
Training loss: 1.1271803379058838
Validation loss: 2.033117095629374

Epoch: 6| Step: 2
Training loss: 0.5335416197776794
Validation loss: 2.098515768845876

Epoch: 6| Step: 3
Training loss: 1.5437800884246826
Validation loss: 2.074570576349894

Epoch: 6| Step: 4
Training loss: 0.42409831285476685
Validation loss: 2.0973867376645408

Epoch: 6| Step: 5
Training loss: 0.7815310955047607
Validation loss: 2.11077211300532

Epoch: 6| Step: 6
Training loss: 0.8544692397117615
Validation loss: 2.0901339451471963

Epoch: 6| Step: 7
Training loss: 0.7681170701980591
Validation loss: 2.0650243560473123

Epoch: 6| Step: 8
Training loss: 0.779719889163971
Validation loss: 2.0670858224232993

Epoch: 6| Step: 9
Training loss: 0.8931072354316711
Validation loss: 2.0871161023775735

Epoch: 6| Step: 10
Training loss: 0.6238875389099121
Validation loss: 2.0230343540509543

Epoch: 6| Step: 11
Training loss: 0.8016040921211243
Validation loss: 2.0932867527008057

Epoch: 6| Step: 12
Training loss: 0.6569282412528992
Validation loss: 2.082262913386027

Epoch: 6| Step: 13
Training loss: 0.8612188696861267
Validation loss: 2.0653792222340903

Epoch: 213| Step: 0
Training loss: 1.1785142421722412
Validation loss: 2.086056927839915

Epoch: 6| Step: 1
Training loss: 0.5438961982727051
Validation loss: 2.0739505887031555

Epoch: 6| Step: 2
Training loss: 0.8716472387313843
Validation loss: 2.0944653749465942

Epoch: 6| Step: 3
Training loss: 1.3611845970153809
Validation loss: 2.0616049766540527

Epoch: 6| Step: 4
Training loss: 0.8162819147109985
Validation loss: 2.102309286594391

Epoch: 6| Step: 5
Training loss: 0.8261757493019104
Validation loss: 2.123816212018331

Epoch: 6| Step: 6
Training loss: 0.6949561238288879
Validation loss: 2.077609419822693

Epoch: 6| Step: 7
Training loss: 1.022463083267212
Validation loss: 2.0056363145510354

Epoch: 6| Step: 8
Training loss: 1.115996241569519
Validation loss: 2.043187379837036

Epoch: 6| Step: 9
Training loss: 0.5362684726715088
Validation loss: 2.0851673086484275

Epoch: 6| Step: 10
Training loss: 0.2817072868347168
Validation loss: 2.058705190817515

Epoch: 6| Step: 11
Training loss: 0.5436772108078003
Validation loss: 2.045320967833201

Epoch: 6| Step: 12
Training loss: 1.0791919231414795
Validation loss: 2.0705915888150535

Epoch: 6| Step: 13
Training loss: 0.6680184006690979
Validation loss: 2.0736236373583474

Epoch: 214| Step: 0
Training loss: 0.8791519999504089
Validation loss: 2.0800113876660666

Epoch: 6| Step: 1
Training loss: 0.7492662668228149
Validation loss: 2.1239651441574097

Epoch: 6| Step: 2
Training loss: 1.1371281147003174
Validation loss: 2.058628777662913

Epoch: 6| Step: 3
Training loss: 0.8347927927970886
Validation loss: 2.081606407960256

Epoch: 6| Step: 4
Training loss: 0.6039133071899414
Validation loss: 2.069999078909556

Epoch: 6| Step: 5
Training loss: 1.0067524909973145
Validation loss: 2.0502079129219055

Epoch: 6| Step: 6
Training loss: 0.6864114999771118
Validation loss: 2.067897160847982

Epoch: 6| Step: 7
Training loss: 0.7858550548553467
Validation loss: 2.045160988966624

Epoch: 6| Step: 8
Training loss: 0.8852831125259399
Validation loss: 2.098601679007212

Epoch: 6| Step: 9
Training loss: 0.9480368494987488
Validation loss: 2.1093697349230447

Epoch: 6| Step: 10
Training loss: 0.4790598452091217
Validation loss: 2.096943815549215

Epoch: 6| Step: 11
Training loss: 1.0370142459869385
Validation loss: 2.1014368534088135

Epoch: 6| Step: 12
Training loss: 1.077721357345581
Validation loss: 2.056328515211741

Epoch: 6| Step: 13
Training loss: 0.5892455577850342
Validation loss: 2.088387946287791

Epoch: 215| Step: 0
Training loss: 0.7447452545166016
Validation loss: 2.0440160234769187

Epoch: 6| Step: 1
Training loss: 0.7849130034446716
Validation loss: 2.0286804835001626

Epoch: 6| Step: 2
Training loss: 1.062162160873413
Validation loss: 2.0898014307022095

Epoch: 6| Step: 3
Training loss: 1.1884715557098389
Validation loss: 2.070883830388387

Epoch: 6| Step: 4
Training loss: 0.5759307146072388
Validation loss: 2.056545396645864

Epoch: 6| Step: 5
Training loss: 1.2481642961502075
Validation loss: 2.08095516761144

Epoch: 6| Step: 6
Training loss: 0.8199015855789185
Validation loss: 2.0607340137163797

Epoch: 6| Step: 7
Training loss: 0.892119288444519
Validation loss: 2.0414163072903952

Epoch: 6| Step: 8
Training loss: 0.9665930867195129
Validation loss: 2.0731350978215537

Epoch: 6| Step: 9
Training loss: 0.8753246665000916
Validation loss: 2.087001164754232

Epoch: 6| Step: 10
Training loss: 0.9380226135253906
Validation loss: 2.128444254398346

Epoch: 6| Step: 11
Training loss: 0.7543888092041016
Validation loss: 2.108995576699575

Epoch: 6| Step: 12
Training loss: 0.38822638988494873
Validation loss: 2.093512992064158

Epoch: 6| Step: 13
Training loss: 0.692332923412323
Validation loss: 2.1188431779543557

Epoch: 216| Step: 0
Training loss: 0.6195509433746338
Validation loss: 2.0565584897994995

Epoch: 6| Step: 1
Training loss: 0.8625235557556152
Validation loss: 2.0384958187739053

Epoch: 6| Step: 2
Training loss: 0.39187777042388916
Validation loss: 2.058663328488668

Epoch: 6| Step: 3
Training loss: 0.7545197010040283
Validation loss: 2.0370154778162637

Epoch: 6| Step: 4
Training loss: 1.0643855333328247
Validation loss: 2.081418832143148

Epoch: 6| Step: 5
Training loss: 0.6927473545074463
Validation loss: 2.0632785757382712

Epoch: 6| Step: 6
Training loss: 0.6724879741668701
Validation loss: 2.063266853491465

Epoch: 6| Step: 7
Training loss: 1.062489628791809
Validation loss: 2.0536778370539346

Epoch: 6| Step: 8
Training loss: 0.9778385162353516
Validation loss: 2.0335542360941568

Epoch: 6| Step: 9
Training loss: 0.7346943616867065
Validation loss: 2.0597612261772156

Epoch: 6| Step: 10
Training loss: 0.9364463686943054
Validation loss: 2.05398690700531

Epoch: 6| Step: 11
Training loss: 0.9851409792900085
Validation loss: 2.077329695224762

Epoch: 6| Step: 12
Training loss: 1.1554564237594604
Validation loss: 2.041788617769877

Epoch: 6| Step: 13
Training loss: 0.6031442880630493
Validation loss: 2.089690327644348

Epoch: 217| Step: 0
Training loss: 0.8483051061630249
Validation loss: 2.0541892846425376

Epoch: 6| Step: 1
Training loss: 0.7746531367301941
Validation loss: 2.0637508432070413

Epoch: 6| Step: 2
Training loss: 0.8466157913208008
Validation loss: 2.0716232657432556

Epoch: 6| Step: 3
Training loss: 0.748884916305542
Validation loss: 2.0538227359453836

Epoch: 6| Step: 4
Training loss: 0.2573073208332062
Validation loss: 2.058012227217356

Epoch: 6| Step: 5
Training loss: 0.8704123497009277
Validation loss: 2.0639020601908364

Epoch: 6| Step: 6
Training loss: 1.0711816549301147
Validation loss: 2.033718228340149

Epoch: 6| Step: 7
Training loss: 0.9908586740493774
Validation loss: 2.069402893384298

Epoch: 6| Step: 8
Training loss: 1.0194474458694458
Validation loss: 2.064086695512136

Epoch: 6| Step: 9
Training loss: 0.5796419382095337
Validation loss: 2.0839869379997253

Epoch: 6| Step: 10
Training loss: 0.8634645938873291
Validation loss: 2.047906498114268

Epoch: 6| Step: 11
Training loss: 0.7815228700637817
Validation loss: 2.0865729053815207

Epoch: 6| Step: 12
Training loss: 0.902074933052063
Validation loss: 2.0493792494138083

Epoch: 6| Step: 13
Training loss: 0.7321156859397888
Validation loss: 2.051471789677938

Epoch: 218| Step: 0
Training loss: 1.0923155546188354
Validation loss: 2.0415687759717307

Epoch: 6| Step: 1
Training loss: 0.7257252931594849
Validation loss: 2.066130797068278

Epoch: 6| Step: 2
Training loss: 0.7552525997161865
Validation loss: 2.0559946497281394

Epoch: 6| Step: 3
Training loss: 0.8138118982315063
Validation loss: 2.0638142824172974

Epoch: 6| Step: 4
Training loss: 0.7549862861633301
Validation loss: 2.0527243614196777

Epoch: 6| Step: 5
Training loss: 0.9615494012832642
Validation loss: 2.0994433959325156

Epoch: 6| Step: 6
Training loss: 0.8765652179718018
Validation loss: 2.083252727985382

Epoch: 6| Step: 7
Training loss: 0.7260279655456543
Validation loss: 2.050095001856486

Epoch: 6| Step: 8
Training loss: 0.6817989349365234
Validation loss: 2.0534095565478006

Epoch: 6| Step: 9
Training loss: 0.5341198444366455
Validation loss: 2.0516793529192605

Epoch: 6| Step: 10
Training loss: 0.6551131010055542
Validation loss: 2.042334258556366

Epoch: 6| Step: 11
Training loss: 1.1798479557037354
Validation loss: 2.0481971899668374

Epoch: 6| Step: 12
Training loss: 1.3156719207763672
Validation loss: 2.0725045204162598

Epoch: 6| Step: 13
Training loss: 0.9449558854103088
Validation loss: 2.1031866868336997

Epoch: 219| Step: 0
Training loss: 0.5414108037948608
Validation loss: 2.048299868901571

Epoch: 6| Step: 1
Training loss: 1.2996565103530884
Validation loss: 2.0518829226493835

Epoch: 6| Step: 2
Training loss: 0.5212257504463196
Validation loss: 2.0681594808896384

Epoch: 6| Step: 3
Training loss: 1.2991337776184082
Validation loss: 2.0666774908701577

Epoch: 6| Step: 4
Training loss: 0.8377072811126709
Validation loss: 2.0842288931210837

Epoch: 6| Step: 5
Training loss: 0.6811026930809021
Validation loss: 2.0341964960098267

Epoch: 6| Step: 6
Training loss: 0.6420583128929138
Validation loss: 2.0431102315584817

Epoch: 6| Step: 7
Training loss: 0.8274486064910889
Validation loss: 2.0603405833244324

Epoch: 6| Step: 8
Training loss: 0.8911407589912415
Validation loss: 2.082041561603546

Epoch: 6| Step: 9
Training loss: 1.2021360397338867
Validation loss: 2.0338038206100464

Epoch: 6| Step: 10
Training loss: 0.4801173210144043
Validation loss: 2.0311710039774575

Epoch: 6| Step: 11
Training loss: 0.6167938709259033
Validation loss: 2.0824669202168784

Epoch: 6| Step: 12
Training loss: 0.384359210729599
Validation loss: 2.0603499015172324

Epoch: 6| Step: 13
Training loss: 0.8940582275390625
Validation loss: 2.055636207262675

Epoch: 220| Step: 0
Training loss: 0.8664407730102539
Validation loss: 2.0896260142326355

Epoch: 6| Step: 1
Training loss: 0.8637760877609253
Validation loss: 2.0810897747675576

Epoch: 6| Step: 2
Training loss: 0.5403931140899658
Validation loss: 1.9909995198249817

Epoch: 6| Step: 3
Training loss: 0.6474048495292664
Validation loss: 2.0881091753641763

Epoch: 6| Step: 4
Training loss: 0.8462305665016174
Validation loss: 2.0753579139709473

Epoch: 6| Step: 5
Training loss: 0.8570235967636108
Validation loss: 2.0650876561800637

Epoch: 6| Step: 6
Training loss: 0.6271888613700867
Validation loss: 2.0811736981074014

Epoch: 6| Step: 7
Training loss: 0.9096779823303223
Validation loss: 2.0571123560269675

Epoch: 6| Step: 8
Training loss: 1.0340709686279297
Validation loss: 2.032841364542643

Epoch: 6| Step: 9
Training loss: 0.8132811784744263
Validation loss: 2.007908304532369

Epoch: 6| Step: 10
Training loss: 0.855941653251648
Validation loss: 2.016714930534363

Epoch: 6| Step: 11
Training loss: 0.8014328479766846
Validation loss: 2.044141252835592

Epoch: 6| Step: 12
Training loss: 0.8067147135734558
Validation loss: 2.0395586689313254

Epoch: 6| Step: 13
Training loss: 0.6234986186027527
Validation loss: 2.0385220448176065

Epoch: 221| Step: 0
Training loss: 1.0747406482696533
Validation loss: 2.034652809302012

Epoch: 6| Step: 1
Training loss: 0.6557550430297852
Validation loss: 2.088241159915924

Epoch: 6| Step: 2
Training loss: 0.9788532853126526
Validation loss: 2.0941715240478516

Epoch: 6| Step: 3
Training loss: 0.4819091260433197
Validation loss: 2.0724708636601767

Epoch: 6| Step: 4
Training loss: 0.6974471211433411
Validation loss: 2.048159917195638

Epoch: 6| Step: 5
Training loss: 0.6960224509239197
Validation loss: 2.061606744925181

Epoch: 6| Step: 6
Training loss: 0.7372831106185913
Validation loss: 2.0351985494295755

Epoch: 6| Step: 7
Training loss: 1.1112842559814453
Validation loss: 2.072870592276255

Epoch: 6| Step: 8
Training loss: 0.5680060982704163
Validation loss: 2.055268347263336

Epoch: 6| Step: 9
Training loss: 1.2434883117675781
Validation loss: 2.069263438383738

Epoch: 6| Step: 10
Training loss: 0.6839023232460022
Validation loss: 2.0592533548672995

Epoch: 6| Step: 11
Training loss: 0.7613695859909058
Validation loss: 2.0949048598607383

Epoch: 6| Step: 12
Training loss: 0.5603265762329102
Validation loss: 2.094973146915436

Epoch: 6| Step: 13
Training loss: 0.7165371179580688
Validation loss: 2.0976715683937073

Epoch: 222| Step: 0
Training loss: 0.9295814633369446
Validation loss: 2.0596270163853965

Epoch: 6| Step: 1
Training loss: 0.671606719493866
Validation loss: 2.0359542767206826

Epoch: 6| Step: 2
Training loss: 0.7888006567955017
Validation loss: 2.051887055238088

Epoch: 6| Step: 3
Training loss: 0.9041287302970886
Validation loss: 2.069455166657766

Epoch: 6| Step: 4
Training loss: 0.46881628036499023
Validation loss: 2.0719369451204934

Epoch: 6| Step: 5
Training loss: 0.5913973450660706
Validation loss: 2.0621805985768638

Epoch: 6| Step: 6
Training loss: 0.9274360537528992
Validation loss: 2.0500628550847373

Epoch: 6| Step: 7
Training loss: 0.6937384605407715
Validation loss: 2.055315375328064

Epoch: 6| Step: 8
Training loss: 1.0314397811889648
Validation loss: 2.0404059290885925

Epoch: 6| Step: 9
Training loss: 0.6310344934463501
Validation loss: 2.075339118639628

Epoch: 6| Step: 10
Training loss: 1.003403663635254
Validation loss: 2.0634009639422097

Epoch: 6| Step: 11
Training loss: 0.9429882168769836
Validation loss: 2.050802310307821

Epoch: 6| Step: 12
Training loss: 0.818103551864624
Validation loss: 2.0600480437278748

Epoch: 6| Step: 13
Training loss: 0.6703156232833862
Validation loss: 2.0530255238215127

Epoch: 223| Step: 0
Training loss: 0.6191729307174683
Validation loss: 2.1028555035591125

Epoch: 6| Step: 1
Training loss: 0.8101249933242798
Validation loss: 2.0557424227396646

Epoch: 6| Step: 2
Training loss: 0.764683723449707
Validation loss: 2.013887862364451

Epoch: 6| Step: 3
Training loss: 0.4800456762313843
Validation loss: 2.032882591088613

Epoch: 6| Step: 4
Training loss: 0.811498761177063
Validation loss: 2.0613436102867126

Epoch: 6| Step: 5
Training loss: 0.5996037721633911
Validation loss: 2.0571161905924478

Epoch: 6| Step: 6
Training loss: 0.7266716361045837
Validation loss: 2.026092847188314

Epoch: 6| Step: 7
Training loss: 0.6140029430389404
Validation loss: 2.0501920580863953

Epoch: 6| Step: 8
Training loss: 0.9865408539772034
Validation loss: 2.0412660042444863

Epoch: 6| Step: 9
Training loss: 0.6375858783721924
Validation loss: 2.0482052763303122

Epoch: 6| Step: 10
Training loss: 1.1350376605987549
Validation loss: 2.0321876207987466

Epoch: 6| Step: 11
Training loss: 0.7984130382537842
Validation loss: 2.0461743076642356

Epoch: 6| Step: 12
Training loss: 0.7222248315811157
Validation loss: 2.0798489650090537

Epoch: 6| Step: 13
Training loss: 0.988659143447876
Validation loss: 2.08019224802653

Epoch: 224| Step: 0
Training loss: 0.5025967955589294
Validation loss: 2.0923460125923157

Epoch: 6| Step: 1
Training loss: 1.1873328685760498
Validation loss: 2.023035009702047

Epoch: 6| Step: 2
Training loss: 0.5807998180389404
Validation loss: 2.0828777154286704

Epoch: 6| Step: 3
Training loss: 0.43967652320861816
Validation loss: 2.018858174482981

Epoch: 6| Step: 4
Training loss: 0.6329533457756042
Validation loss: 2.0445005098978677

Epoch: 6| Step: 5
Training loss: 1.3236029148101807
Validation loss: 2.0064596136411033

Epoch: 6| Step: 6
Training loss: 0.5339905023574829
Validation loss: 2.079289138317108

Epoch: 6| Step: 7
Training loss: 1.0620158910751343
Validation loss: 2.0548724134763083

Epoch: 6| Step: 8
Training loss: 0.5384743213653564
Validation loss: 2.0498406887054443

Epoch: 6| Step: 9
Training loss: 0.647334098815918
Validation loss: 2.081973910331726

Epoch: 6| Step: 10
Training loss: 0.464421808719635
Validation loss: 2.0507277448972068

Epoch: 6| Step: 11
Training loss: 0.9375
Validation loss: 2.0783392588297525

Epoch: 6| Step: 12
Training loss: 1.2100763320922852
Validation loss: 2.0433755119641623

Epoch: 6| Step: 13
Training loss: 0.8443688154220581
Validation loss: 2.098096946875254

Epoch: 225| Step: 0
Training loss: 0.8242262601852417
Validation loss: 2.084615627924601

Epoch: 6| Step: 1
Training loss: 0.5207303762435913
Validation loss: 2.0238980054855347

Epoch: 6| Step: 2
Training loss: 0.7418850660324097
Validation loss: 2.052446742852529

Epoch: 6| Step: 3
Training loss: 0.8960026502609253
Validation loss: 2.0753371715545654

Epoch: 6| Step: 4
Training loss: 0.5166592001914978
Validation loss: 2.0313240687052407

Epoch: 6| Step: 5
Training loss: 1.1638760566711426
Validation loss: 2.053561786810557

Epoch: 6| Step: 6
Training loss: 0.9484164118766785
Validation loss: 2.0514597296714783

Epoch: 6| Step: 7
Training loss: 0.6383158564567566
Validation loss: 2.0343381563822427

Epoch: 6| Step: 8
Training loss: 0.752657949924469
Validation loss: 2.044373095035553

Epoch: 6| Step: 9
Training loss: 0.46279025077819824
Validation loss: 2.0519824226697287

Epoch: 6| Step: 10
Training loss: 0.8410302996635437
Validation loss: 2.0374722878138223

Epoch: 6| Step: 11
Training loss: 1.1692278385162354
Validation loss: 2.0483020742734275

Epoch: 6| Step: 12
Training loss: 0.6179764270782471
Validation loss: 2.068239410718282

Epoch: 6| Step: 13
Training loss: 0.6234068274497986
Validation loss: 2.094013730684916

Epoch: 226| Step: 0
Training loss: 1.4234752655029297
Validation loss: 2.027421315511068

Epoch: 6| Step: 1
Training loss: 0.7743148803710938
Validation loss: 2.0593382517496743

Epoch: 6| Step: 2
Training loss: 0.4738098978996277
Validation loss: 2.041670103867849

Epoch: 6| Step: 3
Training loss: 0.9313905239105225
Validation loss: 2.037852168083191

Epoch: 6| Step: 4
Training loss: 0.5242818593978882
Validation loss: 2.039092739423116

Epoch: 6| Step: 5
Training loss: 0.828209400177002
Validation loss: 2.0495515863100686

Epoch: 6| Step: 6
Training loss: 0.7846621870994568
Validation loss: 2.0332962473233542

Epoch: 6| Step: 7
Training loss: 0.5786069631576538
Validation loss: 2.0296260913213096

Epoch: 6| Step: 8
Training loss: 0.4241044521331787
Validation loss: 2.0851850708325705

Epoch: 6| Step: 9
Training loss: 0.9066253900527954
Validation loss: 2.05841992298762

Epoch: 6| Step: 10
Training loss: 1.1458344459533691
Validation loss: 2.036961853504181

Epoch: 6| Step: 11
Training loss: 0.8909412622451782
Validation loss: 2.0978396932284036

Epoch: 6| Step: 12
Training loss: 0.7875404357910156
Validation loss: 2.0803816318511963

Epoch: 6| Step: 13
Training loss: 0.41111651062965393
Validation loss: 2.1025010148684182

Epoch: 227| Step: 0
Training loss: 0.47338807582855225
Validation loss: 2.071243087450663

Epoch: 6| Step: 1
Training loss: 0.8575235605239868
Validation loss: 2.0793805718421936

Epoch: 6| Step: 2
Training loss: 0.8517267107963562
Validation loss: 2.034102956453959

Epoch: 6| Step: 3
Training loss: 1.036628007888794
Validation loss: 2.038338760534922

Epoch: 6| Step: 4
Training loss: 0.6483268737792969
Validation loss: 2.132216195265452

Epoch: 6| Step: 5
Training loss: 0.594860315322876
Validation loss: 2.0667861501375833

Epoch: 6| Step: 6
Training loss: 1.05587899684906
Validation loss: 2.0330081979433694

Epoch: 6| Step: 7
Training loss: 0.6513386964797974
Validation loss: 2.0659064650535583

Epoch: 6| Step: 8
Training loss: 0.652021050453186
Validation loss: 2.113506337006887

Epoch: 6| Step: 9
Training loss: 0.5347548127174377
Validation loss: 2.0453107555707297

Epoch: 6| Step: 10
Training loss: 1.4646360874176025
Validation loss: 2.121301452318827

Epoch: 6| Step: 11
Training loss: 0.47019708156585693
Validation loss: 2.085991640885671

Epoch: 6| Step: 12
Training loss: 0.3369664251804352
Validation loss: 2.0894848306973777

Epoch: 6| Step: 13
Training loss: 0.891025960445404
Validation loss: 2.0599717497825623

Epoch: 228| Step: 0
Training loss: 0.8895816206932068
Validation loss: 2.0650471250216165

Epoch: 6| Step: 1
Training loss: 0.7963689565658569
Validation loss: 2.0685949524243674

Epoch: 6| Step: 2
Training loss: 0.458248108625412
Validation loss: 2.100512603918711

Epoch: 6| Step: 3
Training loss: 0.4344077408313751
Validation loss: 2.107793688774109

Epoch: 6| Step: 4
Training loss: 0.8247456550598145
Validation loss: 2.083161254723867

Epoch: 6| Step: 5
Training loss: 0.4686984419822693
Validation loss: 2.091241260369619

Epoch: 6| Step: 6
Training loss: 0.6747576594352722
Validation loss: 2.068905313809713

Epoch: 6| Step: 7
Training loss: 1.0572341680526733
Validation loss: 2.1302430629730225

Epoch: 6| Step: 8
Training loss: 1.18936026096344
Validation loss: 2.092027425765991

Epoch: 6| Step: 9
Training loss: 0.9743050932884216
Validation loss: 2.0924286444981894

Epoch: 6| Step: 10
Training loss: 0.7870936393737793
Validation loss: 2.049886922041575

Epoch: 6| Step: 11
Training loss: 0.6940622329711914
Validation loss: 2.0941380659739175

Epoch: 6| Step: 12
Training loss: 0.379683256149292
Validation loss: 2.0462746024131775

Epoch: 6| Step: 13
Training loss: 0.7833845019340515
Validation loss: 2.019920547803243

Epoch: 229| Step: 0
Training loss: 1.1319067478179932
Validation loss: 1.9972893397013347

Epoch: 6| Step: 1
Training loss: 0.8296066522598267
Validation loss: 2.115014394124349

Epoch: 6| Step: 2
Training loss: 0.8991524577140808
Validation loss: 2.068759103616079

Epoch: 6| Step: 3
Training loss: 0.4229443669319153
Validation loss: 2.080710490544637

Epoch: 6| Step: 4
Training loss: 0.7888609766960144
Validation loss: 2.0860914985338845

Epoch: 6| Step: 5
Training loss: 0.6420933604240417
Validation loss: 2.066556970278422

Epoch: 6| Step: 6
Training loss: 0.3934727907180786
Validation loss: 2.0863060553868613

Epoch: 6| Step: 7
Training loss: 0.9440113306045532
Validation loss: 2.0554922620455423

Epoch: 6| Step: 8
Training loss: 1.1783441305160522
Validation loss: 2.0839406649271646

Epoch: 6| Step: 9
Training loss: 0.6372326016426086
Validation loss: 2.0527172287305198

Epoch: 6| Step: 10
Training loss: 0.9400540590286255
Validation loss: 2.0902965466181436

Epoch: 6| Step: 11
Training loss: 0.3910863399505615
Validation loss: 2.0715176463127136

Epoch: 6| Step: 12
Training loss: 0.40597009658813477
Validation loss: 2.1008971532185874

Epoch: 6| Step: 13
Training loss: 0.6086807250976562
Validation loss: 2.1014700730641684

Epoch: 230| Step: 0
Training loss: 0.673805832862854
Validation loss: 2.058958729108175

Epoch: 6| Step: 1
Training loss: 0.7855707406997681
Validation loss: 2.058411737283071

Epoch: 6| Step: 2
Training loss: 1.146567702293396
Validation loss: 2.11094335714976

Epoch: 6| Step: 3
Training loss: 0.6233800053596497
Validation loss: 2.07162207365036

Epoch: 6| Step: 4
Training loss: 0.7470985651016235
Validation loss: 2.0529528657595315

Epoch: 6| Step: 5
Training loss: 1.0658938884735107
Validation loss: 2.0771204431851706

Epoch: 6| Step: 6
Training loss: 0.38845378160476685
Validation loss: 2.1260876854260764

Epoch: 6| Step: 7
Training loss: 1.208404541015625
Validation loss: 2.0885244607925415

Epoch: 6| Step: 8
Training loss: 0.7035526037216187
Validation loss: 2.053706407546997

Epoch: 6| Step: 9
Training loss: 0.25683900713920593
Validation loss: 2.069232185681661

Epoch: 6| Step: 10
Training loss: 0.7830031514167786
Validation loss: 2.032025456428528

Epoch: 6| Step: 11
Training loss: 0.8709502816200256
Validation loss: 2.05204443136851

Epoch: 6| Step: 12
Training loss: 0.9126371145248413
Validation loss: 2.025211830933889

Epoch: 6| Step: 13
Training loss: 0.6711719036102295
Validation loss: 2.0634254217147827

Epoch: 231| Step: 0
Training loss: 0.4254736304283142
Validation loss: 2.0865031083424888

Epoch: 6| Step: 1
Training loss: 1.118553876876831
Validation loss: 2.016455352306366

Epoch: 6| Step: 2
Training loss: 0.49703723192214966
Validation loss: 2.0560864011446633

Epoch: 6| Step: 3
Training loss: 0.5807197093963623
Validation loss: 2.0581239064534507

Epoch: 6| Step: 4
Training loss: 0.6614726781845093
Validation loss: 2.1172025203704834

Epoch: 6| Step: 5
Training loss: 0.6987819075584412
Validation loss: 2.088474531968435

Epoch: 6| Step: 6
Training loss: 0.5180600881576538
Validation loss: 2.079475979010264

Epoch: 6| Step: 7
Training loss: 0.953067421913147
Validation loss: 2.0956375201543174

Epoch: 6| Step: 8
Training loss: 1.1605054140090942
Validation loss: 2.0621864795684814

Epoch: 6| Step: 9
Training loss: 1.2508622407913208
Validation loss: 2.118370513121287

Epoch: 6| Step: 10
Training loss: 0.5289340019226074
Validation loss: 2.0378529032071433

Epoch: 6| Step: 11
Training loss: 0.5610558986663818
Validation loss: 2.009660482406616

Epoch: 6| Step: 12
Training loss: 0.9161044359207153
Validation loss: 2.03162674109141

Epoch: 6| Step: 13
Training loss: 0.7448387742042542
Validation loss: 2.0707762638727822

Epoch: 232| Step: 0
Training loss: 0.5388773679733276
Validation loss: 2.115439315636953

Epoch: 6| Step: 1
Training loss: 0.9505909085273743
Validation loss: 2.0545321702957153

Epoch: 6| Step: 2
Training loss: 0.9446592926979065
Validation loss: 2.0127429564793906

Epoch: 6| Step: 3
Training loss: 0.7156287431716919
Validation loss: 2.0356378157933555

Epoch: 6| Step: 4
Training loss: 0.5449509024620056
Validation loss: 2.0637995998064675

Epoch: 6| Step: 5
Training loss: 0.9771900773048401
Validation loss: 2.0760878324508667

Epoch: 6| Step: 6
Training loss: 0.26477962732315063
Validation loss: 2.0681422551472983

Epoch: 6| Step: 7
Training loss: 0.6094455718994141
Validation loss: 2.089957853158315

Epoch: 6| Step: 8
Training loss: 0.8156874179840088
Validation loss: 2.0678106546401978

Epoch: 6| Step: 9
Training loss: 0.40906381607055664
Validation loss: 2.0588496724764505

Epoch: 6| Step: 10
Training loss: 0.47441366314888
Validation loss: 1.981271505355835

Epoch: 6| Step: 11
Training loss: 0.8990908861160278
Validation loss: 2.064329425493876

Epoch: 6| Step: 12
Training loss: 1.242142677307129
Validation loss: 2.0953118801116943

Epoch: 6| Step: 13
Training loss: 1.051222801208496
Validation loss: 2.0685202876726785

Epoch: 233| Step: 0
Training loss: 0.5558249354362488
Validation loss: 2.0911326805750527

Epoch: 6| Step: 1
Training loss: 0.47409728169441223
Validation loss: 2.050811767578125

Epoch: 6| Step: 2
Training loss: 0.5502055287361145
Validation loss: 2.081410745779673

Epoch: 6| Step: 3
Training loss: 0.7876640558242798
Validation loss: 2.072826345761617

Epoch: 6| Step: 4
Training loss: 0.954764723777771
Validation loss: 2.073746979236603

Epoch: 6| Step: 5
Training loss: 0.7444557547569275
Validation loss: 2.0756848454475403

Epoch: 6| Step: 6
Training loss: 0.4760839641094208
Validation loss: 2.0482981403668723

Epoch: 6| Step: 7
Training loss: 0.629241943359375
Validation loss: 2.0504380265871682

Epoch: 6| Step: 8
Training loss: 0.6503180265426636
Validation loss: 2.0759995579719543

Epoch: 6| Step: 9
Training loss: 1.0029776096343994
Validation loss: 2.0279440681139627

Epoch: 6| Step: 10
Training loss: 1.1196209192276
Validation loss: 2.0755491256713867

Epoch: 6| Step: 11
Training loss: 1.007482886314392
Validation loss: 2.0670021176338196

Epoch: 6| Step: 12
Training loss: 0.5736253261566162
Validation loss: 2.0640210111935935

Epoch: 6| Step: 13
Training loss: 0.9638151526451111
Validation loss: 2.0445617039998374

Epoch: 234| Step: 0
Training loss: 0.9006043672561646
Validation loss: 2.070462167263031

Epoch: 6| Step: 1
Training loss: 0.6363329887390137
Validation loss: 2.059944987297058

Epoch: 6| Step: 2
Training loss: 0.9372583627700806
Validation loss: 2.088780641555786

Epoch: 6| Step: 3
Training loss: 0.7161999940872192
Validation loss: 2.0481425523757935

Epoch: 6| Step: 4
Training loss: 0.6470860838890076
Validation loss: 2.0716389417648315

Epoch: 6| Step: 5
Training loss: 0.9628896713256836
Validation loss: 2.0613362391789756

Epoch: 6| Step: 6
Training loss: 0.6811898946762085
Validation loss: 2.0533538659413657

Epoch: 6| Step: 7
Training loss: 0.8152466416358948
Validation loss: 2.0615691343943277

Epoch: 6| Step: 8
Training loss: 0.5644522905349731
Validation loss: 2.1133243838946023

Epoch: 6| Step: 9
Training loss: 0.6009083986282349
Validation loss: 2.0302311380704245

Epoch: 6| Step: 10
Training loss: 0.6169443130493164
Validation loss: 2.054270843664805

Epoch: 6| Step: 11
Training loss: 0.8363064527511597
Validation loss: 2.0826229055722556

Epoch: 6| Step: 12
Training loss: 0.6002882122993469
Validation loss: 2.075511395931244

Epoch: 6| Step: 13
Training loss: 0.8197605609893799
Validation loss: 2.0757813453674316

Epoch: 235| Step: 0
Training loss: 0.8283960819244385
Validation loss: 2.0820309122403464

Epoch: 6| Step: 1
Training loss: 1.044284701347351
Validation loss: 2.0810285011927285

Epoch: 6| Step: 2
Training loss: 0.4796042740345001
Validation loss: 2.139630893866221

Epoch: 6| Step: 3
Training loss: 0.6856454610824585
Validation loss: 2.0727803111076355

Epoch: 6| Step: 4
Training loss: 0.7627089619636536
Validation loss: 2.0455989042917886

Epoch: 6| Step: 5
Training loss: 0.7828615307807922
Validation loss: 2.0755111972490945

Epoch: 6| Step: 6
Training loss: 0.6891522407531738
Validation loss: 2.056110421816508

Epoch: 6| Step: 7
Training loss: 0.715510368347168
Validation loss: 1.9845555226008098

Epoch: 6| Step: 8
Training loss: 0.9770796895027161
Validation loss: 2.028339385986328

Epoch: 6| Step: 9
Training loss: 1.164722204208374
Validation loss: 2.0049688617388406

Epoch: 6| Step: 10
Training loss: 1.1092655658721924
Validation loss: 2.016383429368337

Epoch: 6| Step: 11
Training loss: 0.7373799085617065
Validation loss: 2.0730201601982117

Epoch: 6| Step: 12
Training loss: 0.48182448744773865
Validation loss: 2.002230624357859

Epoch: 6| Step: 13
Training loss: 0.571983814239502
Validation loss: 2.0803990761439004

Epoch: 236| Step: 0
Training loss: 0.5855591893196106
Validation loss: 2.078512946764628

Epoch: 6| Step: 1
Training loss: 0.6371755599975586
Validation loss: 2.117925524711609

Epoch: 6| Step: 2
Training loss: 0.9832019805908203
Validation loss: 2.095282951990763

Epoch: 6| Step: 3
Training loss: 0.833145797252655
Validation loss: 2.092137018839518

Epoch: 6| Step: 4
Training loss: 0.6196154356002808
Validation loss: 2.075928012530009

Epoch: 6| Step: 5
Training loss: 0.6014479398727417
Validation loss: 2.0462703704833984

Epoch: 6| Step: 6
Training loss: 1.4248061180114746
Validation loss: 2.038037975629171

Epoch: 6| Step: 7
Training loss: 0.9964138269424438
Validation loss: 2.0589147210121155

Epoch: 6| Step: 8
Training loss: 0.69715416431427
Validation loss: 1.9987004399299622

Epoch: 6| Step: 9
Training loss: 0.9114810228347778
Validation loss: 1.9980648557345073

Epoch: 6| Step: 10
Training loss: 0.8855674862861633
Validation loss: 2.0429361859957376

Epoch: 6| Step: 11
Training loss: 0.4548623561859131
Validation loss: 2.026209831237793

Epoch: 6| Step: 12
Training loss: 0.6295100450515747
Validation loss: 2.05666313568751

Epoch: 6| Step: 13
Training loss: 0.8104746341705322
Validation loss: 2.0682192047437034

Epoch: 237| Step: 0
Training loss: 0.6778354644775391
Validation loss: 2.0520814458529153

Epoch: 6| Step: 1
Training loss: 0.3811056315898895
Validation loss: 2.0783512592315674

Epoch: 6| Step: 2
Training loss: 0.8846278786659241
Validation loss: 2.0587227741877236

Epoch: 6| Step: 3
Training loss: 0.37843838334083557
Validation loss: 2.0993189016977944

Epoch: 6| Step: 4
Training loss: 0.953438401222229
Validation loss: 2.032546639442444

Epoch: 6| Step: 5
Training loss: 0.8052138090133667
Validation loss: 2.058181663354238

Epoch: 6| Step: 6
Training loss: 0.6852078437805176
Validation loss: 2.0148262977600098

Epoch: 6| Step: 7
Training loss: 0.5797150135040283
Validation loss: 2.034690241018931

Epoch: 6| Step: 8
Training loss: 0.942396879196167
Validation loss: 1.999928057193756

Epoch: 6| Step: 9
Training loss: 0.9003498554229736
Validation loss: 2.0366260210673013

Epoch: 6| Step: 10
Training loss: 0.9490779638290405
Validation loss: 2.0426687598228455

Epoch: 6| Step: 11
Training loss: 0.7467748522758484
Validation loss: 2.101274828116099

Epoch: 6| Step: 12
Training loss: 1.0250511169433594
Validation loss: 2.09801177183787

Epoch: 6| Step: 13
Training loss: 0.8911800384521484
Validation loss: 2.107626477877299

Epoch: 238| Step: 0
Training loss: 0.8941217064857483
Validation loss: 2.0285984675089517

Epoch: 6| Step: 1
Training loss: 0.46587759256362915
Validation loss: 2.07491672039032

Epoch: 6| Step: 2
Training loss: 0.7206261157989502
Validation loss: 2.081591566403707

Epoch: 6| Step: 3
Training loss: 0.8743746876716614
Validation loss: 2.08846116065979

Epoch: 6| Step: 4
Training loss: 0.9502413272857666
Validation loss: 2.051939686139425

Epoch: 6| Step: 5
Training loss: 0.6079908013343811
Validation loss: 2.0528963804244995

Epoch: 6| Step: 6
Training loss: 1.046447515487671
Validation loss: 2.040540039539337

Epoch: 6| Step: 7
Training loss: 0.597975492477417
Validation loss: 2.0582974751790366

Epoch: 6| Step: 8
Training loss: 0.5365316867828369
Validation loss: 2.0198182662328086

Epoch: 6| Step: 9
Training loss: 0.939283013343811
Validation loss: 2.0500533978144326

Epoch: 6| Step: 10
Training loss: 0.6583311557769775
Validation loss: 2.0540536443392434

Epoch: 6| Step: 11
Training loss: 0.86335289478302
Validation loss: 2.1262258688608804

Epoch: 6| Step: 12
Training loss: 0.777379035949707
Validation loss: 2.0963054895401

Epoch: 6| Step: 13
Training loss: 0.33288002014160156
Validation loss: 2.112511177857717

Epoch: 239| Step: 0
Training loss: 0.43185266852378845
Validation loss: 2.034964164098104

Epoch: 6| Step: 1
Training loss: 0.32708293199539185
Validation loss: 2.085773150126139

Epoch: 6| Step: 2
Training loss: 0.7479345798492432
Validation loss: 2.035888115564982

Epoch: 6| Step: 3
Training loss: 0.692824125289917
Validation loss: 2.0781536300977073

Epoch: 6| Step: 4
Training loss: 0.8589303493499756
Validation loss: 2.063370704650879

Epoch: 6| Step: 5
Training loss: 1.0676777362823486
Validation loss: 2.0417922735214233

Epoch: 6| Step: 6
Training loss: 0.47378087043762207
Validation loss: 2.0319711565971375

Epoch: 6| Step: 7
Training loss: 0.7452665567398071
Validation loss: 2.0299071073532104

Epoch: 6| Step: 8
Training loss: 0.8968328237533569
Validation loss: 2.0697650710741677

Epoch: 6| Step: 9
Training loss: 0.7307642698287964
Validation loss: 2.0347381432851157

Epoch: 6| Step: 10
Training loss: 0.5244323015213013
Validation loss: 2.132132887840271

Epoch: 6| Step: 11
Training loss: 1.0568828582763672
Validation loss: 2.0456089774767556

Epoch: 6| Step: 12
Training loss: 0.7979387044906616
Validation loss: 2.0858436226844788

Epoch: 6| Step: 13
Training loss: 1.0506430864334106
Validation loss: 2.063018043835958

Epoch: 240| Step: 0
Training loss: 0.7447576522827148
Validation loss: 2.0811360279719033

Epoch: 6| Step: 1
Training loss: 0.61397385597229
Validation loss: 2.033650736014048

Epoch: 6| Step: 2
Training loss: 0.48144203424453735
Validation loss: 2.043718775113424

Epoch: 6| Step: 3
Training loss: 1.3489196300506592
Validation loss: 2.0786172350247702

Epoch: 6| Step: 4
Training loss: 0.6716834306716919
Validation loss: 2.0228896141052246

Epoch: 6| Step: 5
Training loss: 0.30101311206817627
Validation loss: 2.0722482204437256

Epoch: 6| Step: 6
Training loss: 0.665584146976471
Validation loss: 2.059973180294037

Epoch: 6| Step: 7
Training loss: 0.9713945984840393
Validation loss: 2.092650612195333

Epoch: 6| Step: 8
Training loss: 0.9065303206443787
Validation loss: 2.0671842296918235

Epoch: 6| Step: 9
Training loss: 0.6094259023666382
Validation loss: 2.0527151226997375

Epoch: 6| Step: 10
Training loss: 0.6990630626678467
Validation loss: 2.091070016225179

Epoch: 6| Step: 11
Training loss: 0.44917115569114685
Validation loss: 2.0834096670150757

Epoch: 6| Step: 12
Training loss: 0.7394877672195435
Validation loss: 2.06946329275767

Epoch: 6| Step: 13
Training loss: 0.8678773641586304
Validation loss: 2.0780672430992126

Epoch: 241| Step: 0
Training loss: 0.6420069932937622
Validation loss: 2.064444382985433

Epoch: 6| Step: 1
Training loss: 0.4774923324584961
Validation loss: 2.0580222606658936

Epoch: 6| Step: 2
Training loss: 0.3274242877960205
Validation loss: 2.066882868607839

Epoch: 6| Step: 3
Training loss: 0.4982355833053589
Validation loss: 2.080514907836914

Epoch: 6| Step: 4
Training loss: 0.9393303394317627
Validation loss: 2.0749379793802896

Epoch: 6| Step: 5
Training loss: 0.6510612368583679
Validation loss: 2.073420782883962

Epoch: 6| Step: 6
Training loss: 0.536305844783783
Validation loss: 2.0776939193407693

Epoch: 6| Step: 7
Training loss: 0.8046021461486816
Validation loss: 2.069952428340912

Epoch: 6| Step: 8
Training loss: 1.0380206108093262
Validation loss: 2.042289912700653

Epoch: 6| Step: 9
Training loss: 0.9683660864830017
Validation loss: 2.087766468524933

Epoch: 6| Step: 10
Training loss: 0.49136558175086975
Validation loss: 2.0547805031140647

Epoch: 6| Step: 11
Training loss: 0.3772665560245514
Validation loss: 2.078721741835276

Epoch: 6| Step: 12
Training loss: 1.190846562385559
Validation loss: 2.0748119751612344

Epoch: 6| Step: 13
Training loss: 0.9620990753173828
Validation loss: 2.0525690714518228

Epoch: 242| Step: 0
Training loss: 0.6929113268852234
Validation loss: 2.0994802912076316

Epoch: 6| Step: 1
Training loss: 0.40837156772613525
Validation loss: 2.076243778069814

Epoch: 6| Step: 2
Training loss: 0.7984288930892944
Validation loss: 2.068712592124939

Epoch: 6| Step: 3
Training loss: 0.9144858121871948
Validation loss: 2.0674455563227334

Epoch: 6| Step: 4
Training loss: 0.6593397259712219
Validation loss: 2.11097784837087

Epoch: 6| Step: 5
Training loss: 0.6555632948875427
Validation loss: 2.0953544974327087

Epoch: 6| Step: 6
Training loss: 0.4924566447734833
Validation loss: 2.0732321739196777

Epoch: 6| Step: 7
Training loss: 0.20490510761737823
Validation loss: 2.097054044405619

Epoch: 6| Step: 8
Training loss: 0.6679939031600952
Validation loss: 2.0721325476964316

Epoch: 6| Step: 9
Training loss: 0.9265871047973633
Validation loss: 2.0764816999435425

Epoch: 6| Step: 10
Training loss: 1.2304036617279053
Validation loss: 2.047932247320811

Epoch: 6| Step: 11
Training loss: 0.8376945853233337
Validation loss: 2.056480646133423

Epoch: 6| Step: 12
Training loss: 0.6699958443641663
Validation loss: 2.0632749795913696

Epoch: 6| Step: 13
Training loss: 0.7603535652160645
Validation loss: 2.0887587467829385

Epoch: 243| Step: 0
Training loss: 0.8831150531768799
Validation loss: 2.066311478614807

Epoch: 6| Step: 1
Training loss: 0.4095219373703003
Validation loss: 2.0052502751350403

Epoch: 6| Step: 2
Training loss: 0.540183424949646
Validation loss: 1.9870118896166484

Epoch: 6| Step: 3
Training loss: 0.4449712932109833
Validation loss: 2.0800969203313193

Epoch: 6| Step: 4
Training loss: 0.7855002880096436
Validation loss: 2.0614383220672607

Epoch: 6| Step: 5
Training loss: 0.517292857170105
Validation loss: 2.072505156199137

Epoch: 6| Step: 6
Training loss: 1.2874606847763062
Validation loss: 2.0595049460728965

Epoch: 6| Step: 7
Training loss: 0.6499677896499634
Validation loss: 2.036023179690043

Epoch: 6| Step: 8
Training loss: 0.515526533126831
Validation loss: 2.073253591855367

Epoch: 6| Step: 9
Training loss: 0.479947954416275
Validation loss: 2.0958887537320456

Epoch: 6| Step: 10
Training loss: 0.5939836502075195
Validation loss: 2.079171657562256

Epoch: 6| Step: 11
Training loss: 0.7566049695014954
Validation loss: 2.0629018942515054

Epoch: 6| Step: 12
Training loss: 0.946343183517456
Validation loss: 2.027445117632548

Epoch: 6| Step: 13
Training loss: 0.8447208404541016
Validation loss: 2.060550093650818

Epoch: 244| Step: 0
Training loss: 0.5449394583702087
Validation loss: 2.0429723064104715

Epoch: 6| Step: 1
Training loss: 0.9406980276107788
Validation loss: 2.059601108233134

Epoch: 6| Step: 2
Training loss: 0.5565415024757385
Validation loss: 2.057981530825297

Epoch: 6| Step: 3
Training loss: 0.7372593879699707
Validation loss: 2.0577287475268045

Epoch: 6| Step: 4
Training loss: 0.6027449369430542
Validation loss: 2.058243135611216

Epoch: 6| Step: 5
Training loss: 0.5637469291687012
Validation loss: 2.0744248827298484

Epoch: 6| Step: 6
Training loss: 0.517214834690094
Validation loss: 2.084420680999756

Epoch: 6| Step: 7
Training loss: 0.7863702774047852
Validation loss: 2.0519402225812278

Epoch: 6| Step: 8
Training loss: 0.7302204370498657
Validation loss: 2.0537074406941733

Epoch: 6| Step: 9
Training loss: 0.7392616271972656
Validation loss: 2.0680707693099976

Epoch: 6| Step: 10
Training loss: 0.8362336158752441
Validation loss: 2.0329411824544272

Epoch: 6| Step: 11
Training loss: 0.9932461977005005
Validation loss: 2.109624226888021

Epoch: 6| Step: 12
Training loss: 0.8426656723022461
Validation loss: 2.0489911834398904

Epoch: 6| Step: 13
Training loss: 0.7847006320953369
Validation loss: 2.0962877670923867

Epoch: 245| Step: 0
Training loss: 0.6669285297393799
Validation loss: 2.077820599079132

Epoch: 6| Step: 1
Training loss: 0.6672965288162231
Validation loss: 2.0901737610499063

Epoch: 6| Step: 2
Training loss: 0.681990385055542
Validation loss: 2.0917160511016846

Epoch: 6| Step: 3
Training loss: 0.5659358501434326
Validation loss: 2.1501469214757285

Epoch: 6| Step: 4
Training loss: 0.6875683069229126
Validation loss: 2.0944550236066184

Epoch: 6| Step: 5
Training loss: 1.0286202430725098
Validation loss: 2.000179926554362

Epoch: 6| Step: 6
Training loss: 0.9830082058906555
Validation loss: 2.068679928779602

Epoch: 6| Step: 7
Training loss: 0.5925701260566711
Validation loss: 2.0712751150131226

Epoch: 6| Step: 8
Training loss: 0.8828909397125244
Validation loss: 2.026146173477173

Epoch: 6| Step: 9
Training loss: 0.4810948967933655
Validation loss: 2.0692243178685508

Epoch: 6| Step: 10
Training loss: 0.7522791624069214
Validation loss: 2.052519996960958

Epoch: 6| Step: 11
Training loss: 1.2149107456207275
Validation loss: 2.1368680000305176

Epoch: 6| Step: 12
Training loss: 0.8120195865631104
Validation loss: 2.1256602803866067

Epoch: 6| Step: 13
Training loss: 0.6985430121421814
Validation loss: 2.152183930079142

Epoch: 246| Step: 0
Training loss: 0.6105239987373352
Validation loss: 2.1191319624582925

Epoch: 6| Step: 1
Training loss: 0.9172924757003784
Validation loss: 2.082949678103129

Epoch: 6| Step: 2
Training loss: 0.9525619745254517
Validation loss: 2.094367802143097

Epoch: 6| Step: 3
Training loss: 0.4890057444572449
Validation loss: 2.048945168654124

Epoch: 6| Step: 4
Training loss: 1.0343000888824463
Validation loss: 2.092893640200297

Epoch: 6| Step: 5
Training loss: 0.5695956945419312
Validation loss: 2.0642749865849814

Epoch: 6| Step: 6
Training loss: 0.7833646535873413
Validation loss: 2.043820063273112

Epoch: 6| Step: 7
Training loss: 0.7112833261489868
Validation loss: 2.065529942512512

Epoch: 6| Step: 8
Training loss: 0.6945711374282837
Validation loss: 2.0988489588101706

Epoch: 6| Step: 9
Training loss: 0.5749077200889587
Validation loss: 2.088437020778656

Epoch: 6| Step: 10
Training loss: 0.7082527875900269
Validation loss: 2.1106154521306357

Epoch: 6| Step: 11
Training loss: 1.0622769594192505
Validation loss: 2.144591132799784

Epoch: 6| Step: 12
Training loss: 0.5012821555137634
Validation loss: 2.1287813981374106

Epoch: 6| Step: 13
Training loss: 1.0894527435302734
Validation loss: 2.089714765548706

Epoch: 247| Step: 0
Training loss: 0.6506828665733337
Validation loss: 2.1427870194117227

Epoch: 6| Step: 1
Training loss: 0.41930654644966125
Validation loss: 2.1044638554255166

Epoch: 6| Step: 2
Training loss: 1.1574578285217285
Validation loss: 2.0877517461776733

Epoch: 6| Step: 3
Training loss: 0.4455123543739319
Validation loss: 2.107316474119822

Epoch: 6| Step: 4
Training loss: 0.8180290460586548
Validation loss: 2.041890263557434

Epoch: 6| Step: 5
Training loss: 0.6365721821784973
Validation loss: 2.064088225364685

Epoch: 6| Step: 6
Training loss: 0.8892293572425842
Validation loss: 2.0800328850746155

Epoch: 6| Step: 7
Training loss: 0.698010265827179
Validation loss: 2.1238860487937927

Epoch: 6| Step: 8
Training loss: 0.42733192443847656
Validation loss: 2.0860450069109597

Epoch: 6| Step: 9
Training loss: 0.6043039560317993
Validation loss: 2.061509609222412

Epoch: 6| Step: 10
Training loss: 0.744462251663208
Validation loss: 2.0709932843844094

Epoch: 6| Step: 11
Training loss: 0.7505948543548584
Validation loss: 2.0860063234965005

Epoch: 6| Step: 12
Training loss: 1.152928113937378
Validation loss: 2.063410143057505

Epoch: 6| Step: 13
Training loss: 0.32144200801849365
Validation loss: 2.0800386667251587

Epoch: 248| Step: 0
Training loss: 1.1533299684524536
Validation loss: 2.029887000719706

Epoch: 6| Step: 1
Training loss: 0.5522269010543823
Validation loss: 2.079826374848684

Epoch: 6| Step: 2
Training loss: 0.4158943295478821
Validation loss: 2.0383607149124146

Epoch: 6| Step: 3
Training loss: 0.5134347677230835
Validation loss: 2.050623059272766

Epoch: 6| Step: 4
Training loss: 0.8081485033035278
Validation loss: 2.0729748805363974

Epoch: 6| Step: 5
Training loss: 0.5579627752304077
Validation loss: 2.0694254438082376

Epoch: 6| Step: 6
Training loss: 0.5018993616104126
Validation loss: 2.023080587387085

Epoch: 6| Step: 7
Training loss: 1.2100036144256592
Validation loss: 2.073410987854004

Epoch: 6| Step: 8
Training loss: 0.6139172315597534
Validation loss: 2.0526877641677856

Epoch: 6| Step: 9
Training loss: 0.5135239958763123
Validation loss: 2.054024358590444

Epoch: 6| Step: 10
Training loss: 0.9146972894668579
Validation loss: 2.051474928855896

Epoch: 6| Step: 11
Training loss: 0.6526201963424683
Validation loss: 2.0383092562357583

Epoch: 6| Step: 12
Training loss: 0.42497146129608154
Validation loss: 2.0577165285746255

Epoch: 6| Step: 13
Training loss: 0.9039976596832275
Validation loss: 2.0792487462361655

Epoch: 249| Step: 0
Training loss: 0.9122943878173828
Validation loss: 2.081607977549235

Epoch: 6| Step: 1
Training loss: 0.3575412929058075
Validation loss: 2.000816822052002

Epoch: 6| Step: 2
Training loss: 0.6041932106018066
Validation loss: 2.10779732465744

Epoch: 6| Step: 3
Training loss: 0.41459959745407104
Validation loss: 2.0593459804852805

Epoch: 6| Step: 4
Training loss: 0.757205605506897
Validation loss: 2.0754709045092263

Epoch: 6| Step: 5
Training loss: 1.1521153450012207
Validation loss: 2.077261765797933

Epoch: 6| Step: 6
Training loss: 0.9431204199790955
Validation loss: 2.053894281387329

Epoch: 6| Step: 7
Training loss: 0.890776515007019
Validation loss: 2.0434098641077676

Epoch: 6| Step: 8
Training loss: 0.9797323942184448
Validation loss: 2.024268627166748

Epoch: 6| Step: 9
Training loss: 0.583211362361908
Validation loss: 2.092722713947296

Epoch: 6| Step: 10
Training loss: 0.33352234959602356
Validation loss: 2.0867868463198342

Epoch: 6| Step: 11
Training loss: 0.33743512630462646
Validation loss: 2.0870766838391623

Epoch: 6| Step: 12
Training loss: 0.5431812405586243
Validation loss: 2.086114486058553

Epoch: 6| Step: 13
Training loss: 0.6507624387741089
Validation loss: 2.0416133205095925

Epoch: 250| Step: 0
Training loss: 0.6189071536064148
Validation loss: 2.0106306076049805

Epoch: 6| Step: 1
Training loss: 1.072281837463379
Validation loss: 2.032508114973704

Epoch: 6| Step: 2
Training loss: 0.6945666074752808
Validation loss: 2.0729580521583557

Epoch: 6| Step: 3
Training loss: 0.4364762306213379
Validation loss: 2.0423263907432556

Epoch: 6| Step: 4
Training loss: 0.2579094171524048
Validation loss: 2.077367822329203

Epoch: 6| Step: 5
Training loss: 0.6543798446655273
Validation loss: 2.0536045034726462

Epoch: 6| Step: 6
Training loss: 0.8824928998947144
Validation loss: 2.076013167699178

Epoch: 6| Step: 7
Training loss: 0.823498547077179
Validation loss: 2.0637136697769165

Epoch: 6| Step: 8
Training loss: 0.5627908706665039
Validation loss: 2.075444757938385

Epoch: 6| Step: 9
Training loss: 0.5799860954284668
Validation loss: 2.0917367537816367

Epoch: 6| Step: 10
Training loss: 0.4244108498096466
Validation loss: 2.0398317178090415

Epoch: 6| Step: 11
Training loss: 1.1489410400390625
Validation loss: 2.0683653354644775

Epoch: 6| Step: 12
Training loss: 0.8063827753067017
Validation loss: 2.0339818199475608

Epoch: 6| Step: 13
Training loss: 0.484424889087677
Validation loss: 2.051622748374939

Epoch: 251| Step: 0
Training loss: 0.9778797030448914
Validation loss: 2.076708813508352

Epoch: 6| Step: 1
Training loss: 0.6599753499031067
Validation loss: 2.074758072694143

Epoch: 6| Step: 2
Training loss: 0.5689709186553955
Validation loss: 2.051865736643473

Epoch: 6| Step: 3
Training loss: 0.36840781569480896
Validation loss: 2.04849906762441

Epoch: 6| Step: 4
Training loss: 1.039443850517273
Validation loss: 2.0450398524602256

Epoch: 6| Step: 5
Training loss: 0.6356088519096375
Validation loss: 2.056307772795359

Epoch: 6| Step: 6
Training loss: 0.439056932926178
Validation loss: 2.0388866662979126

Epoch: 6| Step: 7
Training loss: 0.5518951416015625
Validation loss: 2.1271138985951743

Epoch: 6| Step: 8
Training loss: 0.9580250978469849
Validation loss: 2.092271109422048

Epoch: 6| Step: 9
Training loss: 0.30261901021003723
Validation loss: 2.081919531027476

Epoch: 6| Step: 10
Training loss: 0.7297156453132629
Validation loss: 2.082006871700287

Epoch: 6| Step: 11
Training loss: 0.8101518750190735
Validation loss: 2.111718734105428

Epoch: 6| Step: 12
Training loss: 0.5828047394752502
Validation loss: 2.1023037433624268

Epoch: 6| Step: 13
Training loss: 0.6974656581878662
Validation loss: 2.1175504128138223

Epoch: 252| Step: 0
Training loss: 0.8118259906768799
Validation loss: 2.1489850282669067

Epoch: 6| Step: 1
Training loss: 0.7661868929862976
Validation loss: 2.0636066794395447

Epoch: 6| Step: 2
Training loss: 1.0689152479171753
Validation loss: 2.082348724206289

Epoch: 6| Step: 3
Training loss: 0.6197983026504517
Validation loss: 2.080309351285299

Epoch: 6| Step: 4
Training loss: 0.685055136680603
Validation loss: 2.0433579484621682

Epoch: 6| Step: 5
Training loss: 0.5428109169006348
Validation loss: 2.0503945549329123

Epoch: 6| Step: 6
Training loss: 0.3510711193084717
Validation loss: 2.105735421180725

Epoch: 6| Step: 7
Training loss: 0.7717993259429932
Validation loss: 2.1436097423235574

Epoch: 6| Step: 8
Training loss: 0.643817663192749
Validation loss: 2.137050151824951

Epoch: 6| Step: 9
Training loss: 0.8643012046813965
Validation loss: 2.1149884462356567

Epoch: 6| Step: 10
Training loss: 0.35991185903549194
Validation loss: 2.110830783843994

Epoch: 6| Step: 11
Training loss: 0.653222382068634
Validation loss: 2.090871353944143

Epoch: 6| Step: 12
Training loss: 1.057244062423706
Validation loss: 2.040602167447408

Epoch: 6| Step: 13
Training loss: 1.2914791107177734
Validation loss: 2.053623080253601

Epoch: 253| Step: 0
Training loss: 0.891364336013794
Validation loss: 2.0724758307139077

Epoch: 6| Step: 1
Training loss: 0.5030271410942078
Validation loss: 2.0696140130360923

Epoch: 6| Step: 2
Training loss: 0.7565906047821045
Validation loss: 2.055411616961161

Epoch: 6| Step: 3
Training loss: 0.6067674160003662
Validation loss: 2.066080550352732

Epoch: 6| Step: 4
Training loss: 0.4361925721168518
Validation loss: 2.0843143463134766

Epoch: 6| Step: 5
Training loss: 0.7313542366027832
Validation loss: 2.0696420272191367

Epoch: 6| Step: 6
Training loss: 0.46970951557159424
Validation loss: 2.1539817452430725

Epoch: 6| Step: 7
Training loss: 0.9345382452011108
Validation loss: 2.1277072429656982

Epoch: 6| Step: 8
Training loss: 0.591586172580719
Validation loss: 2.0548192858695984

Epoch: 6| Step: 9
Training loss: 0.47190365195274353
Validation loss: 2.039371689160665

Epoch: 6| Step: 10
Training loss: 0.8997090458869934
Validation loss: 2.055795669555664

Epoch: 6| Step: 11
Training loss: 1.092418909072876
Validation loss: 2.0267796516418457

Epoch: 6| Step: 12
Training loss: 0.7711228728294373
Validation loss: 2.0148800810178122

Epoch: 6| Step: 13
Training loss: 0.7085022330284119
Validation loss: 2.0415239731470742

Epoch: 254| Step: 0
Training loss: 0.8669682741165161
Validation loss: 2.0822677612304688

Epoch: 6| Step: 1
Training loss: 0.7269465923309326
Validation loss: 2.054601033528646

Epoch: 6| Step: 2
Training loss: 0.5278152227401733
Validation loss: 2.080591142177582

Epoch: 6| Step: 3
Training loss: 0.5397791862487793
Validation loss: 2.0760120153427124

Epoch: 6| Step: 4
Training loss: 0.9846142530441284
Validation loss: 2.0788878003756204

Epoch: 6| Step: 5
Training loss: 0.6289044618606567
Validation loss: 2.0757092237472534

Epoch: 6| Step: 6
Training loss: 0.4717499613761902
Validation loss: 2.0725839734077454

Epoch: 6| Step: 7
Training loss: 0.8430392146110535
Validation loss: 2.010885794957479

Epoch: 6| Step: 8
Training loss: 0.7414073944091797
Validation loss: 2.027120570341746

Epoch: 6| Step: 9
Training loss: 0.6223505735397339
Validation loss: 2.0439451138178506

Epoch: 6| Step: 10
Training loss: 0.6371889114379883
Validation loss: 2.0787667632102966

Epoch: 6| Step: 11
Training loss: 0.5398842096328735
Validation loss: 2.036924103895823

Epoch: 6| Step: 12
Training loss: 0.5487984418869019
Validation loss: 2.0552199482917786

Epoch: 6| Step: 13
Training loss: 0.613608717918396
Validation loss: 2.0316434701283774

Epoch: 255| Step: 0
Training loss: 0.5981641411781311
Validation loss: 2.089605152606964

Epoch: 6| Step: 1
Training loss: 0.7801650762557983
Validation loss: 2.066777984301249

Epoch: 6| Step: 2
Training loss: 0.3831613063812256
Validation loss: 2.0896366039911904

Epoch: 6| Step: 3
Training loss: 0.7709257006645203
Validation loss: 2.075987378756205

Epoch: 6| Step: 4
Training loss: 0.3131978511810303
Validation loss: 2.0606563687324524

Epoch: 6| Step: 5
Training loss: 0.5840552449226379
Validation loss: 2.0681148568789163

Epoch: 6| Step: 6
Training loss: 0.6345319747924805
Validation loss: 2.087356607119242

Epoch: 6| Step: 7
Training loss: 0.45987120270729065
Validation loss: 2.0521823366483054

Epoch: 6| Step: 8
Training loss: 0.756517767906189
Validation loss: 2.003222564856211

Epoch: 6| Step: 9
Training loss: 1.079732894897461
Validation loss: 2.1019253730773926

Epoch: 6| Step: 10
Training loss: 1.1215311288833618
Validation loss: 2.0958218574523926

Epoch: 6| Step: 11
Training loss: 0.8681577444076538
Validation loss: 2.0667043725649514

Epoch: 6| Step: 12
Training loss: 0.6140300035476685
Validation loss: 2.0435998241106668

Epoch: 6| Step: 13
Training loss: 0.4477108120918274
Validation loss: 2.0478628476460776

Epoch: 256| Step: 0
Training loss: 0.550236701965332
Validation loss: 2.020443876584371

Epoch: 6| Step: 1
Training loss: 0.6932377815246582
Validation loss: 2.0962116916974387

Epoch: 6| Step: 2
Training loss: 0.6336997747421265
Validation loss: 2.0823606053988137

Epoch: 6| Step: 3
Training loss: 0.6153807044029236
Validation loss: 2.053666353225708

Epoch: 6| Step: 4
Training loss: 0.6786842346191406
Validation loss: 2.0777805050214133

Epoch: 6| Step: 5
Training loss: 0.5375655889511108
Validation loss: 2.101986368497213

Epoch: 6| Step: 6
Training loss: 0.7835009694099426
Validation loss: 2.123109440008799

Epoch: 6| Step: 7
Training loss: 0.4455530643463135
Validation loss: 2.0618773102760315

Epoch: 6| Step: 8
Training loss: 0.5715570449829102
Validation loss: 2.05385955174764

Epoch: 6| Step: 9
Training loss: 0.7288353443145752
Validation loss: 2.069650729497274

Epoch: 6| Step: 10
Training loss: 0.5634984970092773
Validation loss: 2.0878453850746155

Epoch: 6| Step: 11
Training loss: 0.4361846446990967
Validation loss: 2.086763918399811

Epoch: 6| Step: 12
Training loss: 0.9420875310897827
Validation loss: 2.0563987294832864

Epoch: 6| Step: 13
Training loss: 0.707485556602478
Validation loss: 2.086693267027537

Epoch: 257| Step: 0
Training loss: 0.6072545051574707
Validation loss: 2.088268299897512

Epoch: 6| Step: 1
Training loss: 0.7283655405044556
Validation loss: 2.1005338430404663

Epoch: 6| Step: 2
Training loss: 1.1212085485458374
Validation loss: 2.1138954559961953

Epoch: 6| Step: 3
Training loss: 0.9508696794509888
Validation loss: 2.103087306022644

Epoch: 6| Step: 4
Training loss: 0.4240405559539795
Validation loss: 2.1068596839904785

Epoch: 6| Step: 5
Training loss: 0.538637638092041
Validation loss: 2.084855099519094

Epoch: 6| Step: 6
Training loss: 0.8297185897827148
Validation loss: 2.0709455410639444

Epoch: 6| Step: 7
Training loss: 0.508544385433197
Validation loss: 2.0776972572008767

Epoch: 6| Step: 8
Training loss: 0.9214636087417603
Validation loss: 2.0651028752326965

Epoch: 6| Step: 9
Training loss: 0.7491846084594727
Validation loss: 2.110732913017273

Epoch: 6| Step: 10
Training loss: 0.6151647567749023
Validation loss: 2.0629608035087585

Epoch: 6| Step: 11
Training loss: 0.4571640193462372
Validation loss: 2.0371272563934326

Epoch: 6| Step: 12
Training loss: 0.5489301681518555
Validation loss: 2.052937110265096

Epoch: 6| Step: 13
Training loss: 0.481095552444458
Validation loss: 2.088341176509857

Epoch: 258| Step: 0
Training loss: 0.8315960168838501
Validation loss: 2.134699821472168

Epoch: 6| Step: 1
Training loss: 0.5443004369735718
Validation loss: 2.145598749319712

Epoch: 6| Step: 2
Training loss: 0.7666915059089661
Validation loss: 2.0660804907480874

Epoch: 6| Step: 3
Training loss: 0.6527447700500488
Validation loss: 2.0817570885022483

Epoch: 6| Step: 4
Training loss: 0.3402104079723358
Validation loss: 2.0686930616696677

Epoch: 6| Step: 5
Training loss: 0.9111384153366089
Validation loss: 2.0716047883033752

Epoch: 6| Step: 6
Training loss: 0.4866065979003906
Validation loss: 2.0366034507751465

Epoch: 6| Step: 7
Training loss: 1.138038158416748
Validation loss: 2.048400262991587

Epoch: 6| Step: 8
Training loss: 0.7116235494613647
Validation loss: 2.0595006148020425

Epoch: 6| Step: 9
Training loss: 0.827307939529419
Validation loss: 2.0686873396237693

Epoch: 6| Step: 10
Training loss: 0.7402191162109375
Validation loss: 2.0693431893984475

Epoch: 6| Step: 11
Training loss: 0.4092859625816345
Validation loss: 2.0985002915064492

Epoch: 6| Step: 12
Training loss: 0.4323870539665222
Validation loss: 2.110392173131307

Epoch: 6| Step: 13
Training loss: 0.7401660680770874
Validation loss: 2.0521633625030518

Epoch: 259| Step: 0
Training loss: 0.41839438676834106
Validation loss: 2.078919529914856

Epoch: 6| Step: 1
Training loss: 0.7461521029472351
Validation loss: 2.0801051457722983

Epoch: 6| Step: 2
Training loss: 0.473154753446579
Validation loss: 2.0380101005236306

Epoch: 6| Step: 3
Training loss: 1.5345139503479004
Validation loss: 2.063603162765503

Epoch: 6| Step: 4
Training loss: 0.451250821352005
Validation loss: 2.061976373195648

Epoch: 6| Step: 5
Training loss: 0.4768531918525696
Validation loss: 2.1334453423817954

Epoch: 6| Step: 6
Training loss: 0.6060190200805664
Validation loss: 2.027460058530172

Epoch: 6| Step: 7
Training loss: 0.4142828583717346
Validation loss: 2.0878564715385437

Epoch: 6| Step: 8
Training loss: 0.23205024003982544
Validation loss: 2.0990182161331177

Epoch: 6| Step: 9
Training loss: 0.41451865434646606
Validation loss: 2.129806319872538

Epoch: 6| Step: 10
Training loss: 1.0863503217697144
Validation loss: 2.0809160272280374

Epoch: 6| Step: 11
Training loss: 0.742563009262085
Validation loss: 2.1146568059921265

Epoch: 6| Step: 12
Training loss: 0.8935911059379578
Validation loss: 2.0986199378967285

Epoch: 6| Step: 13
Training loss: 0.5894132852554321
Validation loss: 2.0827597181002298

Epoch: 260| Step: 0
Training loss: 1.0073264837265015
Validation loss: 2.1205111742019653

Epoch: 6| Step: 1
Training loss: 0.7319788932800293
Validation loss: 2.088569760322571

Epoch: 6| Step: 2
Training loss: 0.6766189336776733
Validation loss: 2.077223559220632

Epoch: 6| Step: 3
Training loss: 0.5127584934234619
Validation loss: 2.1052046616872153

Epoch: 6| Step: 4
Training loss: 0.5262425541877747
Validation loss: 2.1161501010258994

Epoch: 6| Step: 5
Training loss: 0.7149072885513306
Validation loss: 2.073363939921061

Epoch: 6| Step: 6
Training loss: 0.6528584957122803
Validation loss: 2.1038962602615356

Epoch: 6| Step: 7
Training loss: 0.353973925113678
Validation loss: 2.085083266099294

Epoch: 6| Step: 8
Training loss: 0.46579092741012573
Validation loss: 2.0487635135650635

Epoch: 6| Step: 9
Training loss: 0.8264874219894409
Validation loss: 2.0421711802482605

Epoch: 6| Step: 10
Training loss: 1.218261957168579
Validation loss: 2.085737923781077

Epoch: 6| Step: 11
Training loss: 0.7783313393592834
Validation loss: 2.03898952404658

Epoch: 6| Step: 12
Training loss: 0.32405993342399597
Validation loss: 2.081416447957357

Epoch: 6| Step: 13
Training loss: 0.34096965193748474
Validation loss: 2.0828328331311545

Epoch: 261| Step: 0
Training loss: 0.902459979057312
Validation loss: 2.1270376443862915

Epoch: 6| Step: 1
Training loss: 0.817367434501648
Validation loss: 2.100571036338806

Epoch: 6| Step: 2
Training loss: 0.42430609464645386
Validation loss: 2.1539893547693887

Epoch: 6| Step: 3
Training loss: 0.7541376352310181
Validation loss: 2.15699036916097

Epoch: 6| Step: 4
Training loss: 0.36621659994125366
Validation loss: 2.0868446230888367

Epoch: 6| Step: 5
Training loss: 0.5008917450904846
Validation loss: 2.123910129070282

Epoch: 6| Step: 6
Training loss: 0.6867281794548035
Validation loss: 2.0837404131889343

Epoch: 6| Step: 7
Training loss: 0.8865933418273926
Validation loss: 2.081203838189443

Epoch: 6| Step: 8
Training loss: 0.5606337189674377
Validation loss: 2.101842999458313

Epoch: 6| Step: 9
Training loss: 0.6879332065582275
Validation loss: 2.062441110610962

Epoch: 6| Step: 10
Training loss: 0.2852635681629181
Validation loss: 2.0821584860483804

Epoch: 6| Step: 11
Training loss: 0.7673004865646362
Validation loss: 2.050949434439341

Epoch: 6| Step: 12
Training loss: 0.7540990114212036
Validation loss: 2.076459765434265

Epoch: 6| Step: 13
Training loss: 0.3763234615325928
Validation loss: 2.103793760140737

Epoch: 262| Step: 0
Training loss: 0.6105579137802124
Validation loss: 2.1268250544865928

Epoch: 6| Step: 1
Training loss: 0.5292977094650269
Validation loss: 2.0985947052637735

Epoch: 6| Step: 2
Training loss: 0.8386846780776978
Validation loss: 2.083608408768972

Epoch: 6| Step: 3
Training loss: 0.6397094130516052
Validation loss: 2.083263337612152

Epoch: 6| Step: 4
Training loss: 0.6259271502494812
Validation loss: 2.0480908354123435

Epoch: 6| Step: 5
Training loss: 0.4311700761318207
Validation loss: 2.072819093863169

Epoch: 6| Step: 6
Training loss: 0.7141450643539429
Validation loss: 2.085374335447947

Epoch: 6| Step: 7
Training loss: 0.4453718960285187
Validation loss: 2.094399849573771

Epoch: 6| Step: 8
Training loss: 0.8860361576080322
Validation loss: 2.128467043240865

Epoch: 6| Step: 9
Training loss: 0.7127156853675842
Validation loss: 2.0479413270950317

Epoch: 6| Step: 10
Training loss: 1.139011025428772
Validation loss: 2.102313141028086

Epoch: 6| Step: 11
Training loss: 0.8219639658927917
Validation loss: 2.13749752442042

Epoch: 6| Step: 12
Training loss: 0.48951905965805054
Validation loss: 2.080116033554077

Epoch: 6| Step: 13
Training loss: 0.5145386457443237
Validation loss: 2.1041793823242188

Epoch: 263| Step: 0
Training loss: 0.5332614779472351
Validation loss: 2.085524300734202

Epoch: 6| Step: 1
Training loss: 0.7181267738342285
Validation loss: 2.0843798716863

Epoch: 6| Step: 2
Training loss: 0.6892854571342468
Validation loss: 2.057133436203003

Epoch: 6| Step: 3
Training loss: 0.4422561824321747
Validation loss: 2.0856138269106546

Epoch: 6| Step: 4
Training loss: 0.7719427347183228
Validation loss: 2.0253164966901145

Epoch: 6| Step: 5
Training loss: 1.1056766510009766
Validation loss: 2.072537382443746

Epoch: 6| Step: 6
Training loss: 0.7701025009155273
Validation loss: 2.1275200247764587

Epoch: 6| Step: 7
Training loss: 0.5598176717758179
Validation loss: 2.1308982372283936

Epoch: 6| Step: 8
Training loss: 0.5436831116676331
Validation loss: 2.140783449014028

Epoch: 6| Step: 9
Training loss: 0.5768543481826782
Validation loss: 2.095319390296936

Epoch: 6| Step: 10
Training loss: 1.0148860216140747
Validation loss: 2.078980008761088

Epoch: 6| Step: 11
Training loss: 0.46619153022766113
Validation loss: 2.0429121255874634

Epoch: 6| Step: 12
Training loss: 0.6167957782745361
Validation loss: 2.0884819626808167

Epoch: 6| Step: 13
Training loss: 0.7897900342941284
Validation loss: 2.0848490993181863

Epoch: 264| Step: 0
Training loss: 0.517143726348877
Validation loss: 2.0557667215665183

Epoch: 6| Step: 1
Training loss: 0.5315836668014526
Validation loss: 2.092157562573751

Epoch: 6| Step: 2
Training loss: 0.9022295475006104
Validation loss: 2.0850526293118796

Epoch: 6| Step: 3
Training loss: 0.8251165151596069
Validation loss: 2.1123374104499817

Epoch: 6| Step: 4
Training loss: 0.672649085521698
Validation loss: 2.0580420096715293

Epoch: 6| Step: 5
Training loss: 0.5059783458709717
Validation loss: 2.1410685777664185

Epoch: 6| Step: 6
Training loss: 0.8819705247879028
Validation loss: 2.124268333117167

Epoch: 6| Step: 7
Training loss: 0.7898096442222595
Validation loss: 2.1497750083605447

Epoch: 6| Step: 8
Training loss: 0.714078962802887
Validation loss: 2.1169121662775674

Epoch: 6| Step: 9
Training loss: 0.8425803780555725
Validation loss: 2.0598427454630532

Epoch: 6| Step: 10
Training loss: 0.5958309173583984
Validation loss: 2.0957705974578857

Epoch: 6| Step: 11
Training loss: 0.5514018535614014
Validation loss: 2.0233307480812073

Epoch: 6| Step: 12
Training loss: 0.36576753854751587
Validation loss: 2.0615806778271994

Epoch: 6| Step: 13
Training loss: 0.7123596668243408
Validation loss: 2.107451399167379

Epoch: 265| Step: 0
Training loss: 0.8323782682418823
Validation loss: 2.1009301940600076

Epoch: 6| Step: 1
Training loss: 0.8563632965087891
Validation loss: 2.1407567660013833

Epoch: 6| Step: 2
Training loss: 0.7354658842086792
Validation loss: 2.0989445646603904

Epoch: 6| Step: 3
Training loss: 0.3328704237937927
Validation loss: 2.099289337793986

Epoch: 6| Step: 4
Training loss: 0.6201703548431396
Validation loss: 2.092095653216044

Epoch: 6| Step: 5
Training loss: 1.0106881856918335
Validation loss: 2.07456103960673

Epoch: 6| Step: 6
Training loss: 0.3352682590484619
Validation loss: 2.090133806069692

Epoch: 6| Step: 7
Training loss: 0.6180522441864014
Validation loss: 2.082595626513163

Epoch: 6| Step: 8
Training loss: 0.4295787215232849
Validation loss: 2.0857683618863425

Epoch: 6| Step: 9
Training loss: 0.7532401084899902
Validation loss: 2.098938206831614

Epoch: 6| Step: 10
Training loss: 0.940536379814148
Validation loss: 2.0996577739715576

Epoch: 6| Step: 11
Training loss: 0.669205904006958
Validation loss: 2.0919974048932395

Epoch: 6| Step: 12
Training loss: 0.5632300972938538
Validation loss: 2.1004045804341636

Epoch: 6| Step: 13
Training loss: 0.5439863204956055
Validation loss: 2.0306862791379294

Epoch: 266| Step: 0
Training loss: 0.763466477394104
Validation loss: 2.063732306162516

Epoch: 6| Step: 1
Training loss: 0.7739956378936768
Validation loss: 2.092429836591085

Epoch: 6| Step: 2
Training loss: 0.9159351587295532
Validation loss: 2.1253358324368796

Epoch: 6| Step: 3
Training loss: 0.41272661089897156
Validation loss: 2.096278707186381

Epoch: 6| Step: 4
Training loss: 0.25159958004951477
Validation loss: 2.1550024350484214

Epoch: 6| Step: 5
Training loss: 0.5063802003860474
Validation loss: 2.068369289239248

Epoch: 6| Step: 6
Training loss: 0.6454150676727295
Validation loss: 2.125329613685608

Epoch: 6| Step: 7
Training loss: 0.5912150144577026
Validation loss: 2.0710566639900208

Epoch: 6| Step: 8
Training loss: 1.3029409646987915
Validation loss: 2.1271230578422546

Epoch: 6| Step: 9
Training loss: 0.23247769474983215
Validation loss: 2.094248592853546

Epoch: 6| Step: 10
Training loss: 0.6498329639434814
Validation loss: 2.0675523479779563

Epoch: 6| Step: 11
Training loss: 0.559026837348938
Validation loss: 2.1154361764589944

Epoch: 6| Step: 12
Training loss: 0.9520801305770874
Validation loss: 2.102668603261312

Epoch: 6| Step: 13
Training loss: 0.4473060369491577
Validation loss: 2.136151432991028

Epoch: 267| Step: 0
Training loss: 0.6757519245147705
Validation loss: 2.0864333510398865

Epoch: 6| Step: 1
Training loss: 0.7036452293395996
Validation loss: 2.091938336690267

Epoch: 6| Step: 2
Training loss: 0.33867377042770386
Validation loss: 2.136611024538676

Epoch: 6| Step: 3
Training loss: 0.4009976387023926
Validation loss: 2.1244280536969504

Epoch: 6| Step: 4
Training loss: 0.6088615655899048
Validation loss: 2.1477258006731668

Epoch: 6| Step: 5
Training loss: 0.5997723340988159
Validation loss: 2.122601866722107

Epoch: 6| Step: 6
Training loss: 0.9027411937713623
Validation loss: 2.0954458316167197

Epoch: 6| Step: 7
Training loss: 0.643378496170044
Validation loss: 2.1061282555262246

Epoch: 6| Step: 8
Training loss: 0.583471417427063
Validation loss: 2.0602810978889465

Epoch: 6| Step: 9
Training loss: 0.912018895149231
Validation loss: 2.0557546416918435

Epoch: 6| Step: 10
Training loss: 0.6520590782165527
Validation loss: 2.0782668193181357

Epoch: 6| Step: 11
Training loss: 0.7611690163612366
Validation loss: 2.051865736643473

Epoch: 6| Step: 12
Training loss: 0.4265865683555603
Validation loss: 2.1054189602533975

Epoch: 6| Step: 13
Training loss: 0.8718036413192749
Validation loss: 2.0640694896380105

Epoch: 268| Step: 0
Training loss: 0.26315999031066895
Validation loss: 2.1253164211908975

Epoch: 6| Step: 1
Training loss: 0.3908851444721222
Validation loss: 2.1293609340985618

Epoch: 6| Step: 2
Training loss: 0.6066180467605591
Validation loss: 2.1187514662742615

Epoch: 6| Step: 3
Training loss: 0.6627505421638489
Validation loss: 2.08429217338562

Epoch: 6| Step: 4
Training loss: 0.39753103256225586
Validation loss: 2.0929453372955322

Epoch: 6| Step: 5
Training loss: 1.2273975610733032
Validation loss: 2.0937092701594033

Epoch: 6| Step: 6
Training loss: 0.4560506343841553
Validation loss: 2.0587507685025535

Epoch: 6| Step: 7
Training loss: 0.5969802141189575
Validation loss: 2.0959848165512085

Epoch: 6| Step: 8
Training loss: 0.539837121963501
Validation loss: 2.08280873298645

Epoch: 6| Step: 9
Training loss: 0.7639026045799255
Validation loss: 2.068143626054128

Epoch: 6| Step: 10
Training loss: 0.7095841765403748
Validation loss: 2.1019625266393027

Epoch: 6| Step: 11
Training loss: 0.876719057559967
Validation loss: 2.0826210180918374

Epoch: 6| Step: 12
Training loss: 0.6301666498184204
Validation loss: 2.108319262663523

Epoch: 6| Step: 13
Training loss: 1.0543049573898315
Validation loss: 2.1059626738230386

Epoch: 269| Step: 0
Training loss: 0.4587401747703552
Validation loss: 2.102347254753113

Epoch: 6| Step: 1
Training loss: 0.5720462799072266
Validation loss: 2.1106678247451782

Epoch: 6| Step: 2
Training loss: 1.092221975326538
Validation loss: 2.07904585202535

Epoch: 6| Step: 3
Training loss: 0.7285217642784119
Validation loss: 2.051701307296753

Epoch: 6| Step: 4
Training loss: 0.6293176412582397
Validation loss: 2.061400552590688

Epoch: 6| Step: 5
Training loss: 0.4701012969017029
Validation loss: 2.0457785924275718

Epoch: 6| Step: 6
Training loss: 0.8041508197784424
Validation loss: 2.0349572698275247

Epoch: 6| Step: 7
Training loss: 0.5851345062255859
Validation loss: 2.08944038550059

Epoch: 6| Step: 8
Training loss: 1.067917823791504
Validation loss: 2.0353139837582908

Epoch: 6| Step: 9
Training loss: 0.37976133823394775
Validation loss: 2.0650177597999573

Epoch: 6| Step: 10
Training loss: 0.4638580083847046
Validation loss: 2.0801498889923096

Epoch: 6| Step: 11
Training loss: 0.569061279296875
Validation loss: 2.1124346256256104

Epoch: 6| Step: 12
Training loss: 0.4285585880279541
Validation loss: 2.10910435517629

Epoch: 6| Step: 13
Training loss: 0.8801096677780151
Validation loss: 2.132340411345164

Epoch: 270| Step: 0
Training loss: 0.6093477606773376
Validation loss: 2.094028572241465

Epoch: 6| Step: 1
Training loss: 0.488983154296875
Validation loss: 2.0544098814328513

Epoch: 6| Step: 2
Training loss: 0.9127469658851624
Validation loss: 2.034974733988444

Epoch: 6| Step: 3
Training loss: 0.8735198378562927
Validation loss: 2.018956482410431

Epoch: 6| Step: 4
Training loss: 0.5259593725204468
Validation loss: 2.067787786324819

Epoch: 6| Step: 5
Training loss: 0.285758912563324
Validation loss: 2.047671933968862

Epoch: 6| Step: 6
Training loss: 0.5956136584281921
Validation loss: 2.063132325808207

Epoch: 6| Step: 7
Training loss: 0.33983227610588074
Validation loss: 2.0775848428408303

Epoch: 6| Step: 8
Training loss: 0.46343564987182617
Validation loss: 2.1178634564081826

Epoch: 6| Step: 9
Training loss: 0.7865666747093201
Validation loss: 2.1284491817156472

Epoch: 6| Step: 10
Training loss: 1.2878122329711914
Validation loss: 2.11974036693573

Epoch: 6| Step: 11
Training loss: 0.6742178201675415
Validation loss: 2.0930420557657876

Epoch: 6| Step: 12
Training loss: 0.5522709488868713
Validation loss: 2.1195174058278403

Epoch: 6| Step: 13
Training loss: 0.8957793712615967
Validation loss: 2.0883552630742392

Epoch: 271| Step: 0
Training loss: 0.4326932728290558
Validation loss: 2.116438349088033

Epoch: 6| Step: 1
Training loss: 0.6741272807121277
Validation loss: 2.0688532988230386

Epoch: 6| Step: 2
Training loss: 0.46155640482902527
Validation loss: 2.070022940635681

Epoch: 6| Step: 3
Training loss: 0.5446413159370422
Validation loss: 2.0882805784543357

Epoch: 6| Step: 4
Training loss: 0.7506608366966248
Validation loss: 2.0806672175725303

Epoch: 6| Step: 5
Training loss: 0.7658745646476746
Validation loss: 2.1633471250534058

Epoch: 6| Step: 6
Training loss: 0.5894141793251038
Validation loss: 2.159915109475454

Epoch: 6| Step: 7
Training loss: 0.4250074326992035
Validation loss: 2.189413587252299

Epoch: 6| Step: 8
Training loss: 0.8587546348571777
Validation loss: 2.1813448667526245

Epoch: 6| Step: 9
Training loss: 0.6667562127113342
Validation loss: 2.186413367589315

Epoch: 6| Step: 10
Training loss: 0.6638482809066772
Validation loss: 2.051259775956472

Epoch: 6| Step: 11
Training loss: 0.7018005847930908
Validation loss: 2.129065295060476

Epoch: 6| Step: 12
Training loss: 0.5009570121765137
Validation loss: 2.071475863456726

Epoch: 6| Step: 13
Training loss: 1.2142716646194458
Validation loss: 2.095532238483429

Epoch: 272| Step: 0
Training loss: 0.766560435295105
Validation loss: 2.090239187081655

Epoch: 6| Step: 1
Training loss: 0.6601494550704956
Validation loss: 2.112531324227651

Epoch: 6| Step: 2
Training loss: 0.5210240483283997
Validation loss: 2.0864899158477783

Epoch: 6| Step: 3
Training loss: 0.49619972705841064
Validation loss: 2.056029816468557

Epoch: 6| Step: 4
Training loss: 0.7141469120979309
Validation loss: 2.1079246401786804

Epoch: 6| Step: 5
Training loss: 0.6618474721908569
Validation loss: 2.1588085889816284

Epoch: 6| Step: 6
Training loss: 0.7392462491989136
Validation loss: 2.177923401196798

Epoch: 6| Step: 7
Training loss: 1.0638971328735352
Validation loss: 2.1636539697647095

Epoch: 6| Step: 8
Training loss: 0.9465072154998779
Validation loss: 2.16448708375295

Epoch: 6| Step: 9
Training loss: 0.8249121904373169
Validation loss: 2.145302633444468

Epoch: 6| Step: 10
Training loss: 0.6205445528030396
Validation loss: 2.168555756409963

Epoch: 6| Step: 11
Training loss: 0.7515360116958618
Validation loss: 2.134536703427633

Epoch: 6| Step: 12
Training loss: 0.5317776203155518
Validation loss: 2.035259167353312

Epoch: 6| Step: 13
Training loss: 0.24589799344539642
Validation loss: 2.088962892691294

Epoch: 273| Step: 0
Training loss: 0.8954226970672607
Validation loss: 2.0649330615997314

Epoch: 6| Step: 1
Training loss: 0.3694908022880554
Validation loss: 2.0464499394098916

Epoch: 6| Step: 2
Training loss: 1.0265263319015503
Validation loss: 2.0763837695121765

Epoch: 6| Step: 3
Training loss: 0.6896020770072937
Validation loss: 2.0943271120389304

Epoch: 6| Step: 4
Training loss: 0.5959492921829224
Validation loss: 2.0873422225316367

Epoch: 6| Step: 5
Training loss: 0.9240309000015259
Validation loss: 2.123040795326233

Epoch: 6| Step: 6
Training loss: 0.7100731134414673
Validation loss: 2.103483478228251

Epoch: 6| Step: 7
Training loss: 0.5733981728553772
Validation loss: 2.1310154795646667

Epoch: 6| Step: 8
Training loss: 0.4517636299133301
Validation loss: 2.0450130303700766

Epoch: 6| Step: 9
Training loss: 0.5002040863037109
Validation loss: 2.079824149608612

Epoch: 6| Step: 10
Training loss: 0.24814704060554504
Validation loss: 2.047322154045105

Epoch: 6| Step: 11
Training loss: 0.5927460789680481
Validation loss: 2.1104519764582315

Epoch: 6| Step: 12
Training loss: 0.39520102739334106
Validation loss: 2.0635588566462197

Epoch: 6| Step: 13
Training loss: 0.6841386556625366
Validation loss: 2.080885132153829

Epoch: 274| Step: 0
Training loss: 0.4263373613357544
Validation loss: 2.0956994692484536

Epoch: 6| Step: 1
Training loss: 0.4738784432411194
Validation loss: 2.09832896788915

Epoch: 6| Step: 2
Training loss: 0.5078479647636414
Validation loss: 2.06906388203303

Epoch: 6| Step: 3
Training loss: 1.030261516571045
Validation loss: 2.106480062007904

Epoch: 6| Step: 4
Training loss: 0.691254734992981
Validation loss: 2.126669009526571

Epoch: 6| Step: 5
Training loss: 0.3715667724609375
Validation loss: 2.080065747102102

Epoch: 6| Step: 6
Training loss: 0.9388096332550049
Validation loss: 2.0708752075831094

Epoch: 6| Step: 7
Training loss: 0.3097670078277588
Validation loss: 2.0592068831125894

Epoch: 6| Step: 8
Training loss: 0.47001197934150696
Validation loss: 2.0307963490486145

Epoch: 6| Step: 9
Training loss: 1.075408935546875
Validation loss: 2.0464526414871216

Epoch: 6| Step: 10
Training loss: 0.9496261477470398
Validation loss: 2.0813549359639487

Epoch: 6| Step: 11
Training loss: 0.7800214290618896
Validation loss: 2.055494487285614

Epoch: 6| Step: 12
Training loss: 0.35148441791534424
Validation loss: 2.0573197404543557

Epoch: 6| Step: 13
Training loss: 0.8273319005966187
Validation loss: 2.100158929824829

Epoch: 275| Step: 0
Training loss: 0.3697829842567444
Validation loss: 2.072284440199534

Epoch: 6| Step: 1
Training loss: 0.605748176574707
Validation loss: 2.101027528444926

Epoch: 6| Step: 2
Training loss: 0.5088547468185425
Validation loss: 2.1501609285672507

Epoch: 6| Step: 3
Training loss: 0.7725927829742432
Validation loss: 2.159486552079519

Epoch: 6| Step: 4
Training loss: 0.810843288898468
Validation loss: 2.130106786886851

Epoch: 6| Step: 5
Training loss: 0.68565434217453
Validation loss: 2.1352497140566506

Epoch: 6| Step: 6
Training loss: 0.4424193799495697
Validation loss: 2.0515597661336265

Epoch: 6| Step: 7
Training loss: 0.716926097869873
Validation loss: 2.0913254022598267

Epoch: 6| Step: 8
Training loss: 0.6855520009994507
Validation loss: 2.0998228788375854

Epoch: 6| Step: 9
Training loss: 0.6688243746757507
Validation loss: 2.0329209566116333

Epoch: 6| Step: 10
Training loss: 0.6366360187530518
Validation loss: 2.0505820711453757

Epoch: 6| Step: 11
Training loss: 0.35280996561050415
Validation loss: 2.1140519976615906

Epoch: 6| Step: 12
Training loss: 0.985858142375946
Validation loss: 2.125899910926819

Epoch: 6| Step: 13
Training loss: 0.6713413596153259
Validation loss: 2.144630034764608

Epoch: 276| Step: 0
Training loss: 0.5565774440765381
Validation loss: 2.1387521028518677

Epoch: 6| Step: 1
Training loss: 0.5582212209701538
Validation loss: 2.138716717561086

Epoch: 6| Step: 2
Training loss: 0.3322613537311554
Validation loss: 2.090832273165385

Epoch: 6| Step: 3
Training loss: 0.5219385623931885
Validation loss: 2.0690066814422607

Epoch: 6| Step: 4
Training loss: 0.9054348468780518
Validation loss: 2.0946810444196067

Epoch: 6| Step: 5
Training loss: 0.5169806480407715
Validation loss: 2.1069780786832175

Epoch: 6| Step: 6
Training loss: 0.6270270943641663
Validation loss: 2.1003013849258423

Epoch: 6| Step: 7
Training loss: 1.0948957204818726
Validation loss: 2.1144769191741943

Epoch: 6| Step: 8
Training loss: 0.48641642928123474
Validation loss: 2.1109506289164224

Epoch: 6| Step: 9
Training loss: 0.2967416048049927
Validation loss: 2.0974221428235373

Epoch: 6| Step: 10
Training loss: 0.4982367753982544
Validation loss: 2.089124858379364

Epoch: 6| Step: 11
Training loss: 1.0387423038482666
Validation loss: 2.0778410832087197

Epoch: 6| Step: 12
Training loss: 0.6216099262237549
Validation loss: 2.066057105859121

Epoch: 6| Step: 13
Training loss: 0.4907417595386505
Validation loss: 2.0505690972010293

Epoch: 277| Step: 0
Training loss: 0.3470890522003174
Validation loss: 2.0540263454119363

Epoch: 6| Step: 1
Training loss: 0.4633653163909912
Validation loss: 2.101050237814585

Epoch: 6| Step: 2
Training loss: 0.5239747166633606
Validation loss: 2.110696097215017

Epoch: 6| Step: 3
Training loss: 0.7948776483535767
Validation loss: 2.1331985791524253

Epoch: 6| Step: 4
Training loss: 0.40807971358299255
Validation loss: 2.12767086426417

Epoch: 6| Step: 5
Training loss: 0.6060062646865845
Validation loss: 2.0685302217801413

Epoch: 6| Step: 6
Training loss: 0.42454034090042114
Validation loss: 2.12466824054718

Epoch: 6| Step: 7
Training loss: 0.761426568031311
Validation loss: 2.122597058614095

Epoch: 6| Step: 8
Training loss: 0.7607261538505554
Validation loss: 2.0993564128875732

Epoch: 6| Step: 9
Training loss: 1.387511968612671
Validation loss: 2.101490835348765

Epoch: 6| Step: 10
Training loss: 0.47218817472457886
Validation loss: 2.0872517824172974

Epoch: 6| Step: 11
Training loss: 0.6079163551330566
Validation loss: 2.081076502799988

Epoch: 6| Step: 12
Training loss: 0.3469070494174957
Validation loss: 2.088020165761312

Epoch: 6| Step: 13
Training loss: 0.6933214664459229
Validation loss: 2.100477715333303

Epoch: 278| Step: 0
Training loss: 0.49214422702789307
Validation loss: 2.067915161450704

Epoch: 6| Step: 1
Training loss: 0.5367269515991211
Validation loss: 2.1093998154004416

Epoch: 6| Step: 2
Training loss: 0.40134093165397644
Validation loss: 2.081529160340627

Epoch: 6| Step: 3
Training loss: 0.6653147339820862
Validation loss: 2.119966228802999

Epoch: 6| Step: 4
Training loss: 0.7224525213241577
Validation loss: 2.1533498764038086

Epoch: 6| Step: 5
Training loss: 0.4797123372554779
Validation loss: 2.1150312026341758

Epoch: 6| Step: 6
Training loss: 0.7052668333053589
Validation loss: 2.096768101056417

Epoch: 6| Step: 7
Training loss: 0.9564776420593262
Validation loss: 2.1110960245132446

Epoch: 6| Step: 8
Training loss: 0.6875334978103638
Validation loss: 2.118529458840688

Epoch: 6| Step: 9
Training loss: 0.2940034568309784
Validation loss: 2.0758161147435508

Epoch: 6| Step: 10
Training loss: 0.49024498462677
Validation loss: 2.11533659696579

Epoch: 6| Step: 11
Training loss: 0.6084804534912109
Validation loss: 2.1369680563608804

Epoch: 6| Step: 12
Training loss: 0.684023380279541
Validation loss: 2.082932790120443

Epoch: 6| Step: 13
Training loss: 0.8390895128250122
Validation loss: 2.0845518112182617

Epoch: 279| Step: 0
Training loss: 0.3788401782512665
Validation loss: 2.116462488969167

Epoch: 6| Step: 1
Training loss: 0.6216759085655212
Validation loss: 2.1791585286458335

Epoch: 6| Step: 2
Training loss: 0.7966407537460327
Validation loss: 2.175848146279653

Epoch: 6| Step: 3
Training loss: 0.8647656440734863
Validation loss: 2.1790008743604026

Epoch: 6| Step: 4
Training loss: 0.8628370761871338
Validation loss: 2.1676339904467263

Epoch: 6| Step: 5
Training loss: 0.4746463894844055
Validation loss: 2.1376975377400718

Epoch: 6| Step: 6
Training loss: 0.6947237253189087
Validation loss: 2.136426329612732

Epoch: 6| Step: 7
Training loss: 0.41146528720855713
Validation loss: 2.164385437965393

Epoch: 6| Step: 8
Training loss: 0.9599180221557617
Validation loss: 2.092647969722748

Epoch: 6| Step: 9
Training loss: 1.042718529701233
Validation loss: 2.0537588198979697

Epoch: 6| Step: 10
Training loss: 0.34702926874160767
Validation loss: 2.0540789365768433

Epoch: 6| Step: 11
Training loss: 0.4265349507331848
Validation loss: 2.121433357397715

Epoch: 6| Step: 12
Training loss: 0.5146431922912598
Validation loss: 2.068086783091227

Epoch: 6| Step: 13
Training loss: 0.6213603615760803
Validation loss: 2.1231245597203574

Epoch: 280| Step: 0
Training loss: 0.763344943523407
Validation loss: 2.1426239808400473

Epoch: 6| Step: 1
Training loss: 0.4487077593803406
Validation loss: 2.0883994102478027

Epoch: 6| Step: 2
Training loss: 0.6022105813026428
Validation loss: 2.0985237757364907

Epoch: 6| Step: 3
Training loss: 0.441108763217926
Validation loss: 2.1841343442598977

Epoch: 6| Step: 4
Training loss: 0.540647566318512
Validation loss: 2.1405009229977927

Epoch: 6| Step: 5
Training loss: 0.4761810302734375
Validation loss: 2.089398125807444

Epoch: 6| Step: 6
Training loss: 0.5436638593673706
Validation loss: 2.0925334692001343

Epoch: 6| Step: 7
Training loss: 0.8045021295547485
Validation loss: 2.077234387397766

Epoch: 6| Step: 8
Training loss: 0.6798264980316162
Validation loss: 2.142221530278524

Epoch: 6| Step: 9
Training loss: 0.5183510780334473
Validation loss: 2.090090731779734

Epoch: 6| Step: 10
Training loss: 0.9764742255210876
Validation loss: 2.0958737333615622

Epoch: 6| Step: 11
Training loss: 0.8277429938316345
Validation loss: 2.1030689676602683

Epoch: 6| Step: 12
Training loss: 0.5770151615142822
Validation loss: 2.159867823123932

Epoch: 6| Step: 13
Training loss: 0.43532463908195496
Validation loss: 2.1230449080467224

Epoch: 281| Step: 0
Training loss: 0.6841932535171509
Validation loss: 2.1187177499135337

Epoch: 6| Step: 1
Training loss: 0.5286515951156616
Validation loss: 2.150118827819824

Epoch: 6| Step: 2
Training loss: 0.600887656211853
Validation loss: 2.1026458144187927

Epoch: 6| Step: 3
Training loss: 0.6837971210479736
Validation loss: 2.1158149242401123

Epoch: 6| Step: 4
Training loss: 0.7637189626693726
Validation loss: 2.0987490018208823

Epoch: 6| Step: 5
Training loss: 0.9174867868423462
Validation loss: 2.110642393430074

Epoch: 6| Step: 6
Training loss: 0.3894140422344208
Validation loss: 2.0930172006289163

Epoch: 6| Step: 7
Training loss: 0.3007870018482208
Validation loss: 2.1038029193878174

Epoch: 6| Step: 8
Training loss: 0.6332313418388367
Validation loss: 2.065493583679199

Epoch: 6| Step: 9
Training loss: 0.9595677256584167
Validation loss: 2.1336286465326944

Epoch: 6| Step: 10
Training loss: 0.48208311200141907
Validation loss: 2.1272950371106467

Epoch: 6| Step: 11
Training loss: 0.3926846385002136
Validation loss: 2.133777697881063

Epoch: 6| Step: 12
Training loss: 0.6183778643608093
Validation loss: 2.1177895863850913

Epoch: 6| Step: 13
Training loss: 0.39274078607559204
Validation loss: 2.1499122381210327

Epoch: 282| Step: 0
Training loss: 0.6719974875450134
Validation loss: 2.099820137023926

Epoch: 6| Step: 1
Training loss: 0.27932068705558777
Validation loss: 2.063411076863607

Epoch: 6| Step: 2
Training loss: 0.48048484325408936
Validation loss: 2.058192491531372

Epoch: 6| Step: 3
Training loss: 0.8638150691986084
Validation loss: 2.0945148269335427

Epoch: 6| Step: 4
Training loss: 0.7700338363647461
Validation loss: 2.054188887278239

Epoch: 6| Step: 5
Training loss: 0.455358624458313
Validation loss: 2.0893446803092957

Epoch: 6| Step: 6
Training loss: 1.1043460369110107
Validation loss: 2.0478708346684775

Epoch: 6| Step: 7
Training loss: 0.716740608215332
Validation loss: 2.074601709842682

Epoch: 6| Step: 8
Training loss: 0.7014440298080444
Validation loss: 2.1033692757288613

Epoch: 6| Step: 9
Training loss: 0.6227061152458191
Validation loss: 2.103289544582367

Epoch: 6| Step: 10
Training loss: 0.4173397421836853
Validation loss: 2.1244102716445923

Epoch: 6| Step: 11
Training loss: 0.6629825830459595
Validation loss: 2.1444953282674155

Epoch: 6| Step: 12
Training loss: 0.5283017158508301
Validation loss: 2.1072088281313577

Epoch: 6| Step: 13
Training loss: 0.45438843965530396
Validation loss: 2.1217813889185586

Epoch: 283| Step: 0
Training loss: 0.3799002170562744
Validation loss: 2.101825495560964

Epoch: 6| Step: 1
Training loss: 0.3989124894142151
Validation loss: 2.0650597413380942

Epoch: 6| Step: 2
Training loss: 0.676282525062561
Validation loss: 2.036394735177358

Epoch: 6| Step: 3
Training loss: 0.5639539957046509
Validation loss: 2.060015936692556

Epoch: 6| Step: 4
Training loss: 0.43014657497406006
Validation loss: 2.0191680192947388

Epoch: 6| Step: 5
Training loss: 0.9150891304016113
Validation loss: 2.0605284571647644

Epoch: 6| Step: 6
Training loss: 0.5853049755096436
Validation loss: 2.0670946637789407

Epoch: 6| Step: 7
Training loss: 0.6032164692878723
Validation loss: 2.06985334555308

Epoch: 6| Step: 8
Training loss: 0.860312819480896
Validation loss: 2.1231749653816223

Epoch: 6| Step: 9
Training loss: 0.6151416897773743
Validation loss: 2.0913310647010803

Epoch: 6| Step: 10
Training loss: 1.113429307937622
Validation loss: 2.055779814720154

Epoch: 6| Step: 11
Training loss: 0.406690776348114
Validation loss: 2.092233180999756

Epoch: 6| Step: 12
Training loss: 0.5620153546333313
Validation loss: 2.08529927333196

Epoch: 6| Step: 13
Training loss: 0.46102598309516907
Validation loss: 2.1209218502044678

Epoch: 284| Step: 0
Training loss: 0.2533230781555176
Validation loss: 2.1048038005828857

Epoch: 6| Step: 1
Training loss: 1.1044251918792725
Validation loss: 2.0767082969347634

Epoch: 6| Step: 2
Training loss: 0.4356188476085663
Validation loss: 2.09121706088384

Epoch: 6| Step: 3
Training loss: 0.48523086309432983
Validation loss: 2.0547518332799277

Epoch: 6| Step: 4
Training loss: 0.7568415403366089
Validation loss: 2.1035128037134805

Epoch: 6| Step: 5
Training loss: 0.6554250717163086
Validation loss: 2.0992488662401834

Epoch: 6| Step: 6
Training loss: 0.3361498713493347
Validation loss: 2.0837109287579856

Epoch: 6| Step: 7
Training loss: 0.78566974401474
Validation loss: 2.0929238001505532

Epoch: 6| Step: 8
Training loss: 0.4828755557537079
Validation loss: 2.0844568411509194

Epoch: 6| Step: 9
Training loss: 0.5668203830718994
Validation loss: 2.1253732442855835

Epoch: 6| Step: 10
Training loss: 0.6967304348945618
Validation loss: 2.122122585773468

Epoch: 6| Step: 11
Training loss: 0.8070300221443176
Validation loss: 2.0643452405929565

Epoch: 6| Step: 12
Training loss: 0.6393464207649231
Validation loss: 2.114367683728536

Epoch: 6| Step: 13
Training loss: 0.2272598296403885
Validation loss: 2.102275828520457

Epoch: 285| Step: 0
Training loss: 0.6779035329818726
Validation loss: 2.110111395517985

Epoch: 6| Step: 1
Training loss: 1.067284107208252
Validation loss: 2.1192344228426614

Epoch: 6| Step: 2
Training loss: 0.28560352325439453
Validation loss: 2.074682811896006

Epoch: 6| Step: 3
Training loss: 0.454229474067688
Validation loss: 2.094905694325765

Epoch: 6| Step: 4
Training loss: 0.6559749841690063
Validation loss: 2.105715334415436

Epoch: 6| Step: 5
Training loss: 0.5704833269119263
Validation loss: 2.1537402470906577

Epoch: 6| Step: 6
Training loss: 0.5795414447784424
Validation loss: 2.1022040843963623

Epoch: 6| Step: 7
Training loss: 0.4793913960456848
Validation loss: 2.129831910133362

Epoch: 6| Step: 8
Training loss: 0.5168158411979675
Validation loss: 2.1365044514338174

Epoch: 6| Step: 9
Training loss: 0.5004153251647949
Validation loss: 2.080234110355377

Epoch: 6| Step: 10
Training loss: 0.6509994268417358
Validation loss: 2.0952235062917075

Epoch: 6| Step: 11
Training loss: 1.0091302394866943
Validation loss: 2.075004239877065

Epoch: 6| Step: 12
Training loss: 0.45947974920272827
Validation loss: 2.085025111834208

Epoch: 6| Step: 13
Training loss: 0.5919033288955688
Validation loss: 2.0958154002825418

Epoch: 286| Step: 0
Training loss: 0.764098048210144
Validation loss: 2.1087781389554343

Epoch: 6| Step: 1
Training loss: 0.41667428612709045
Validation loss: 2.1263959407806396

Epoch: 6| Step: 2
Training loss: 0.844416081905365
Validation loss: 2.1174316008885703

Epoch: 6| Step: 3
Training loss: 0.4770013093948364
Validation loss: 2.128458042939504

Epoch: 6| Step: 4
Training loss: 0.17424890398979187
Validation loss: 2.1158700188001

Epoch: 6| Step: 5
Training loss: 0.2849448323249817
Validation loss: 2.068696935971578

Epoch: 6| Step: 6
Training loss: 0.8277188539505005
Validation loss: 2.0703519582748413

Epoch: 6| Step: 7
Training loss: 0.48065921664237976
Validation loss: 2.061322013537089

Epoch: 6| Step: 8
Training loss: 1.0036594867706299
Validation loss: 2.0964717070261636

Epoch: 6| Step: 9
Training loss: 0.45612195134162903
Validation loss: 2.0781352122624717

Epoch: 6| Step: 10
Training loss: 0.4320370554924011
Validation loss: 2.1257911920547485

Epoch: 6| Step: 11
Training loss: 0.8287644386291504
Validation loss: 2.1319284041722617

Epoch: 6| Step: 12
Training loss: 0.997219443321228
Validation loss: 2.0873886744181314

Epoch: 6| Step: 13
Training loss: 0.5262167453765869
Validation loss: 2.1404329935709634

Epoch: 287| Step: 0
Training loss: 0.5605406761169434
Validation loss: 2.110318104426066

Epoch: 6| Step: 1
Training loss: 0.8687214851379395
Validation loss: 2.127661645412445

Epoch: 6| Step: 2
Training loss: 0.38065218925476074
Validation loss: 2.0697296857833862

Epoch: 6| Step: 3
Training loss: 0.26322388648986816
Validation loss: 2.0893603563308716

Epoch: 6| Step: 4
Training loss: 0.8076380491256714
Validation loss: 2.0783612926801047

Epoch: 6| Step: 5
Training loss: 1.1054868698120117
Validation loss: 2.145277221997579

Epoch: 6| Step: 6
Training loss: 0.44718247652053833
Validation loss: 2.1238284905751548

Epoch: 6| Step: 7
Training loss: 0.623762309551239
Validation loss: 2.122305373350779

Epoch: 6| Step: 8
Training loss: 0.6814291477203369
Validation loss: 2.073796292146047

Epoch: 6| Step: 9
Training loss: 0.4462171196937561
Validation loss: 2.175259451071421

Epoch: 6| Step: 10
Training loss: 0.5694892406463623
Validation loss: 2.1934601863225303

Epoch: 6| Step: 11
Training loss: 0.6257731318473816
Validation loss: 2.167268753051758

Epoch: 6| Step: 12
Training loss: 0.669380784034729
Validation loss: 2.124521553516388

Epoch: 6| Step: 13
Training loss: 0.2773442268371582
Validation loss: 2.11782568693161

Epoch: 288| Step: 0
Training loss: 0.4682738184928894
Validation loss: 2.117761969566345

Epoch: 6| Step: 1
Training loss: 0.611201286315918
Validation loss: 2.065040131409963

Epoch: 6| Step: 2
Training loss: 0.8288021087646484
Validation loss: 2.1130300760269165

Epoch: 6| Step: 3
Training loss: 1.187117576599121
Validation loss: 2.0572384794553122

Epoch: 6| Step: 4
Training loss: 0.41003555059432983
Validation loss: 2.08191571633021

Epoch: 6| Step: 5
Training loss: 0.7265350222587585
Validation loss: 2.1003857851028442

Epoch: 6| Step: 6
Training loss: 0.8439626097679138
Validation loss: 2.1268412470817566

Epoch: 6| Step: 7
Training loss: 0.4857121706008911
Validation loss: 2.1153926253318787

Epoch: 6| Step: 8
Training loss: 0.7287924289703369
Validation loss: 2.144107182820638

Epoch: 6| Step: 9
Training loss: 0.6940427422523499
Validation loss: 2.132409950097402

Epoch: 6| Step: 10
Training loss: 0.8595712184906006
Validation loss: 2.162539780139923

Epoch: 6| Step: 11
Training loss: 0.6658403277397156
Validation loss: 2.1414498885472617

Epoch: 6| Step: 12
Training loss: 0.2772253751754761
Validation loss: 2.1332882046699524

Epoch: 6| Step: 13
Training loss: 0.838573694229126
Validation loss: 2.0960752169291177

Epoch: 289| Step: 0
Training loss: 0.497380793094635
Validation loss: 2.1169785459836326

Epoch: 6| Step: 1
Training loss: 0.6350176334381104
Validation loss: 2.0769301851590476

Epoch: 6| Step: 2
Training loss: 0.7098138332366943
Validation loss: 2.1293153762817383

Epoch: 6| Step: 3
Training loss: 0.6132763624191284
Validation loss: 2.061990519364675

Epoch: 6| Step: 4
Training loss: 0.5608259439468384
Validation loss: 2.109201192855835

Epoch: 6| Step: 5
Training loss: 0.39234793186187744
Validation loss: 2.0964930256207785

Epoch: 6| Step: 6
Training loss: 0.24996909499168396
Validation loss: 2.118061145146688

Epoch: 6| Step: 7
Training loss: 1.0124902725219727
Validation loss: 2.1370259324709573

Epoch: 6| Step: 8
Training loss: 0.754199743270874
Validation loss: 2.116113324960073

Epoch: 6| Step: 9
Training loss: 0.37454381585121155
Validation loss: 2.0909327268600464

Epoch: 6| Step: 10
Training loss: 0.46713757514953613
Validation loss: 2.0740686456362405

Epoch: 6| Step: 11
Training loss: 0.9108235836029053
Validation loss: 2.09469203154246

Epoch: 6| Step: 12
Training loss: 0.39872515201568604
Validation loss: 2.119458476702372

Epoch: 6| Step: 13
Training loss: 0.5833050012588501
Validation loss: 2.1095131238301597

Epoch: 290| Step: 0
Training loss: 0.6144569516181946
Validation loss: 2.0797666708628335

Epoch: 6| Step: 1
Training loss: 1.1572682857513428
Validation loss: 2.1148648460706077

Epoch: 6| Step: 2
Training loss: 0.6789292693138123
Validation loss: 2.1304808855056763

Epoch: 6| Step: 3
Training loss: 0.4102160930633545
Validation loss: 2.1296722491582236

Epoch: 6| Step: 4
Training loss: 0.5282261371612549
Validation loss: 2.1145044763882956

Epoch: 6| Step: 5
Training loss: 0.5863127708435059
Validation loss: 2.0974791646003723

Epoch: 6| Step: 6
Training loss: 0.6522374153137207
Validation loss: 2.1226890087127686

Epoch: 6| Step: 7
Training loss: 0.3551662266254425
Validation loss: 2.1277615626653037

Epoch: 6| Step: 8
Training loss: 0.5985336303710938
Validation loss: 2.137735585371653

Epoch: 6| Step: 9
Training loss: 0.4959934949874878
Validation loss: 2.124868909517924

Epoch: 6| Step: 10
Training loss: 0.49906599521636963
Validation loss: 2.135398209095001

Epoch: 6| Step: 11
Training loss: 0.4946642518043518
Validation loss: 2.1514495412508645

Epoch: 6| Step: 12
Training loss: 0.7445826530456543
Validation loss: 2.114980459213257

Epoch: 6| Step: 13
Training loss: 0.49636006355285645
Validation loss: 2.1108660101890564

Epoch: 291| Step: 0
Training loss: 0.7602030038833618
Validation loss: 2.0765680273373923

Epoch: 6| Step: 1
Training loss: 0.5111308097839355
Validation loss: 2.097533186276754

Epoch: 6| Step: 2
Training loss: 0.6467499136924744
Validation loss: 2.0431769688924155

Epoch: 6| Step: 3
Training loss: 0.8051924705505371
Validation loss: 2.0434416929880777

Epoch: 6| Step: 4
Training loss: 0.5964987277984619
Validation loss: 2.1005010406176248

Epoch: 6| Step: 5
Training loss: 0.337462842464447
Validation loss: 2.087819735209147

Epoch: 6| Step: 6
Training loss: 0.7482799291610718
Validation loss: 2.110418419043223

Epoch: 6| Step: 7
Training loss: 0.7252416014671326
Validation loss: 2.108781715234121

Epoch: 6| Step: 8
Training loss: 0.8079928159713745
Validation loss: 2.131431738535563

Epoch: 6| Step: 9
Training loss: 0.8844757080078125
Validation loss: 2.1627350449562073

Epoch: 6| Step: 10
Training loss: 0.665739893913269
Validation loss: 2.1705742279688516

Epoch: 6| Step: 11
Training loss: 0.9615371227264404
Validation loss: 2.1588929891586304

Epoch: 6| Step: 12
Training loss: 0.6333198547363281
Validation loss: 2.1956090132395425

Epoch: 6| Step: 13
Training loss: 0.4646463990211487
Validation loss: 2.1406872272491455

Epoch: 292| Step: 0
Training loss: 0.45355868339538574
Validation loss: 2.1159154176712036

Epoch: 6| Step: 1
Training loss: 1.0787067413330078
Validation loss: 2.077091614405314

Epoch: 6| Step: 2
Training loss: 0.5498059391975403
Validation loss: 2.101157029469808

Epoch: 6| Step: 3
Training loss: 0.49485498666763306
Validation loss: 2.1207385460535684

Epoch: 6| Step: 4
Training loss: 1.3578225374221802
Validation loss: 2.059512118498484

Epoch: 6| Step: 5
Training loss: 0.6335242986679077
Validation loss: 2.082898259162903

Epoch: 6| Step: 6
Training loss: 0.12554717063903809
Validation loss: 2.1060644388198853

Epoch: 6| Step: 7
Training loss: 0.42577284574508667
Validation loss: 2.1220547556877136

Epoch: 6| Step: 8
Training loss: 0.7412599325180054
Validation loss: 2.094071169694265

Epoch: 6| Step: 9
Training loss: 0.5609742403030396
Validation loss: 2.1634833415349326

Epoch: 6| Step: 10
Training loss: 0.4733572006225586
Validation loss: 2.1005566120147705

Epoch: 6| Step: 11
Training loss: 0.6236095428466797
Validation loss: 2.1218972206115723

Epoch: 6| Step: 12
Training loss: 0.3921149671077728
Validation loss: 2.1428610483805337

Epoch: 6| Step: 13
Training loss: 0.6057228446006775
Validation loss: 2.109524925549825

Epoch: 293| Step: 0
Training loss: 0.9981345534324646
Validation loss: 2.090766191482544

Epoch: 6| Step: 1
Training loss: 0.8019844889640808
Validation loss: 2.0653191804885864

Epoch: 6| Step: 2
Training loss: 0.8381092548370361
Validation loss: 2.084944486618042

Epoch: 6| Step: 3
Training loss: 0.41351619362831116
Validation loss: 2.0603840351104736

Epoch: 6| Step: 4
Training loss: 0.5456326007843018
Validation loss: 2.0839249889055886

Epoch: 6| Step: 5
Training loss: 0.4541444778442383
Validation loss: 2.069787323474884

Epoch: 6| Step: 6
Training loss: 0.4285193681716919
Validation loss: 2.0974578857421875

Epoch: 6| Step: 7
Training loss: 0.8737322092056274
Validation loss: 2.0990035136540732

Epoch: 6| Step: 8
Training loss: 0.5706555843353271
Validation loss: 2.042433579762777

Epoch: 6| Step: 9
Training loss: 0.8572868704795837
Validation loss: 2.106958786646525

Epoch: 6| Step: 10
Training loss: 0.3452470600605011
Validation loss: 2.1113070050875344

Epoch: 6| Step: 11
Training loss: 0.277654230594635
Validation loss: 2.122613569100698

Epoch: 6| Step: 12
Training loss: 0.2562306523323059
Validation loss: 2.087866206963857

Epoch: 6| Step: 13
Training loss: 0.3978215754032135
Validation loss: 2.116675913333893

Epoch: 294| Step: 0
Training loss: 1.0254958868026733
Validation loss: 2.1120057702064514

Epoch: 6| Step: 1
Training loss: 0.7238369584083557
Validation loss: 2.1114344000816345

Epoch: 6| Step: 2
Training loss: 0.8543050289154053
Validation loss: 2.079907457033793

Epoch: 6| Step: 3
Training loss: 0.49776339530944824
Validation loss: 2.0607317288716636

Epoch: 6| Step: 4
Training loss: 0.5953670144081116
Validation loss: 2.102512756983439

Epoch: 6| Step: 5
Training loss: 0.46146899461746216
Validation loss: 2.096990386644999

Epoch: 6| Step: 6
Training loss: 0.22119495272636414
Validation loss: 2.1065900524457297

Epoch: 6| Step: 7
Training loss: 0.6942516565322876
Validation loss: 2.0870598951975503

Epoch: 6| Step: 8
Training loss: 0.36813831329345703
Validation loss: 2.1082539757092795

Epoch: 6| Step: 9
Training loss: 0.690300703048706
Validation loss: 2.0965754787127175

Epoch: 6| Step: 10
Training loss: 0.7732160091400146
Validation loss: 2.0388906598091125

Epoch: 6| Step: 11
Training loss: 0.2986605763435364
Validation loss: 2.086037894090017

Epoch: 6| Step: 12
Training loss: 0.5344393849372864
Validation loss: 2.0862576961517334

Epoch: 6| Step: 13
Training loss: 0.2745622992515564
Validation loss: 2.131746788819631

Epoch: 295| Step: 0
Training loss: 0.3818131685256958
Validation loss: 2.1140509843826294

Epoch: 6| Step: 1
Training loss: 0.8285149335861206
Validation loss: 2.133472204208374

Epoch: 6| Step: 2
Training loss: 0.6610513925552368
Validation loss: 2.0797337094942727

Epoch: 6| Step: 3
Training loss: 0.48514652252197266
Validation loss: 2.0950751503308616

Epoch: 6| Step: 4
Training loss: 0.5670011043548584
Validation loss: 2.113757848739624

Epoch: 6| Step: 5
Training loss: 0.1711207926273346
Validation loss: 2.1077397068341575

Epoch: 6| Step: 6
Training loss: 0.3409155011177063
Validation loss: 2.117360611756643

Epoch: 6| Step: 7
Training loss: 0.5885939002037048
Validation loss: 2.0754042069117227

Epoch: 6| Step: 8
Training loss: 0.65958571434021
Validation loss: 2.1251747210820517

Epoch: 6| Step: 9
Training loss: 0.46914172172546387
Validation loss: 2.0896517237027488

Epoch: 6| Step: 10
Training loss: 0.6665801405906677
Validation loss: 2.0647315184275308

Epoch: 6| Step: 11
Training loss: 1.001613974571228
Validation loss: 2.0930093924204507

Epoch: 6| Step: 12
Training loss: 0.8080047369003296
Validation loss: 2.082887669404348

Epoch: 6| Step: 13
Training loss: 0.6083320379257202
Validation loss: 2.0796992977460227

Epoch: 296| Step: 0
Training loss: 0.49918800592422485
Validation loss: 2.0986549655596414

Epoch: 6| Step: 1
Training loss: 0.9766601324081421
Validation loss: 2.1259685357411704

Epoch: 6| Step: 2
Training loss: 0.5260930061340332
Validation loss: 2.077580193678538

Epoch: 6| Step: 3
Training loss: 0.8317629098892212
Validation loss: 2.0792195002237954

Epoch: 6| Step: 4
Training loss: 0.5571396350860596
Validation loss: 2.120030641555786

Epoch: 6| Step: 5
Training loss: 0.6873598694801331
Validation loss: 2.100924491882324

Epoch: 6| Step: 6
Training loss: 0.45807966589927673
Validation loss: 2.043584108352661

Epoch: 6| Step: 7
Training loss: 0.7032526731491089
Validation loss: 2.0320032040278115

Epoch: 6| Step: 8
Training loss: 0.51011061668396
Validation loss: 2.0960544546445212

Epoch: 6| Step: 9
Training loss: 0.9022616147994995
Validation loss: 2.0714357495307922

Epoch: 6| Step: 10
Training loss: 0.7056301236152649
Validation loss: 2.092958172162374

Epoch: 6| Step: 11
Training loss: 0.32340800762176514
Validation loss: 2.077163020769755

Epoch: 6| Step: 12
Training loss: 0.25214046239852905
Validation loss: 2.1095693111419678

Epoch: 6| Step: 13
Training loss: 0.42287689447402954
Validation loss: 2.1431418458620706

Epoch: 297| Step: 0
Training loss: 0.561429500579834
Validation loss: 2.112966557343801

Epoch: 6| Step: 1
Training loss: 0.5467118620872498
Validation loss: 2.099865118662516

Epoch: 6| Step: 2
Training loss: 0.8650938272476196
Validation loss: 2.09101273616155

Epoch: 6| Step: 3
Training loss: 0.8866405487060547
Validation loss: 2.1496443351109824

Epoch: 6| Step: 4
Training loss: 0.3623576760292053
Validation loss: 2.0983213782310486

Epoch: 6| Step: 5
Training loss: 0.5002068281173706
Validation loss: 2.1180412769317627

Epoch: 6| Step: 6
Training loss: 0.5235850811004639
Validation loss: 2.138985256354014

Epoch: 6| Step: 7
Training loss: 0.6183754205703735
Validation loss: 2.0665571888287864

Epoch: 6| Step: 8
Training loss: 0.4392526149749756
Validation loss: 2.064333697160085

Epoch: 6| Step: 9
Training loss: 0.3074783682823181
Validation loss: 2.1384952664375305

Epoch: 6| Step: 10
Training loss: 0.33303824067115784
Validation loss: 2.062765896320343

Epoch: 6| Step: 11
Training loss: 0.7486327886581421
Validation loss: 2.08933295806249

Epoch: 6| Step: 12
Training loss: 0.4677526652812958
Validation loss: 2.070324798425039

Epoch: 6| Step: 13
Training loss: 0.5638402700424194
Validation loss: 2.10298490524292

Epoch: 298| Step: 0
Training loss: 0.4711182117462158
Validation loss: 2.1342174808184304

Epoch: 6| Step: 1
Training loss: 0.646221399307251
Validation loss: 2.07692813873291

Epoch: 6| Step: 2
Training loss: 0.7207602262496948
Validation loss: 2.0311888655026755

Epoch: 6| Step: 3
Training loss: 0.4445745348930359
Validation loss: 2.0883793036142984

Epoch: 6| Step: 4
Training loss: 0.37309449911117554
Validation loss: 2.0738206108411155

Epoch: 6| Step: 5
Training loss: 0.726042628288269
Validation loss: 2.089883009592692

Epoch: 6| Step: 6
Training loss: 0.6319184899330139
Validation loss: 2.084679881731669

Epoch: 6| Step: 7
Training loss: 0.4156966507434845
Validation loss: 2.1141616106033325

Epoch: 6| Step: 8
Training loss: 0.49077045917510986
Validation loss: 2.0710620482762656

Epoch: 6| Step: 9
Training loss: 0.42421549558639526
Validation loss: 2.0670357942581177

Epoch: 6| Step: 10
Training loss: 0.5031293034553528
Validation loss: 2.1109605034192405

Epoch: 6| Step: 11
Training loss: 0.4249616861343384
Validation loss: 2.1177138487497964

Epoch: 6| Step: 12
Training loss: 0.6966540813446045
Validation loss: 2.0886893272399902

Epoch: 6| Step: 13
Training loss: 0.8685703873634338
Validation loss: 2.081463932991028

Epoch: 299| Step: 0
Training loss: 0.30852919816970825
Validation loss: 2.004340410232544

Epoch: 6| Step: 1
Training loss: 0.415620893239975
Validation loss: 2.0855968594551086

Epoch: 6| Step: 2
Training loss: 0.5225757956504822
Validation loss: 2.091544508934021

Epoch: 6| Step: 3
Training loss: 0.6056133508682251
Validation loss: 2.0868224104245505

Epoch: 6| Step: 4
Training loss: 0.616095781326294
Validation loss: 2.052781581878662

Epoch: 6| Step: 5
Training loss: 0.45108410716056824
Validation loss: 2.066246589024862

Epoch: 6| Step: 6
Training loss: 0.4010077118873596
Validation loss: 2.1042031248410544

Epoch: 6| Step: 7
Training loss: 0.3741178512573242
Validation loss: 2.0853731830914817

Epoch: 6| Step: 8
Training loss: 0.48823678493499756
Validation loss: 2.1134974161783853

Epoch: 6| Step: 9
Training loss: 0.7014022469520569
Validation loss: 2.136753877003988

Epoch: 6| Step: 10
Training loss: 1.0093090534210205
Validation loss: 2.103862921396891

Epoch: 6| Step: 11
Training loss: 0.48004746437072754
Validation loss: 2.0910939375559487

Epoch: 6| Step: 12
Training loss: 1.0712716579437256
Validation loss: 2.0917188922564187

Epoch: 6| Step: 13
Training loss: 0.28714001178741455
Validation loss: 2.072545866171519

Epoch: 300| Step: 0
Training loss: 0.4891287684440613
Validation loss: 2.054273784160614

Epoch: 6| Step: 1
Training loss: 0.43179821968078613
Validation loss: 2.0883267720540366

Epoch: 6| Step: 2
Training loss: 0.6718516945838928
Validation loss: 2.0935946702957153

Epoch: 6| Step: 3
Training loss: 0.5049259662628174
Validation loss: 2.1074803272883096

Epoch: 6| Step: 4
Training loss: 0.45891091227531433
Validation loss: 2.090908964474996

Epoch: 6| Step: 5
Training loss: 0.8051275014877319
Validation loss: 2.120019574960073

Epoch: 6| Step: 6
Training loss: 0.31763195991516113
Validation loss: 2.0746058424313865

Epoch: 6| Step: 7
Training loss: 0.8095192313194275
Validation loss: 2.07947830359141

Epoch: 6| Step: 8
Training loss: 0.27735382318496704
Validation loss: 2.0993301471074424

Epoch: 6| Step: 9
Training loss: 0.9249998331069946
Validation loss: 2.101663589477539

Epoch: 6| Step: 10
Training loss: 0.42974919080734253
Validation loss: 2.104818900426229

Epoch: 6| Step: 11
Training loss: 0.4101201295852661
Validation loss: 2.1241636276245117

Epoch: 6| Step: 12
Training loss: 0.6498334407806396
Validation loss: 2.146328389644623

Epoch: 6| Step: 13
Training loss: 0.31469446420669556
Validation loss: 2.108597159385681

Epoch: 301| Step: 0
Training loss: 0.8260911107063293
Validation loss: 2.114244560400645

Epoch: 6| Step: 1
Training loss: 0.5355470776557922
Validation loss: 2.1537195642789206

Epoch: 6| Step: 2
Training loss: 0.5909086465835571
Validation loss: 2.1218393246332803

Epoch: 6| Step: 3
Training loss: 0.4869270324707031
Validation loss: 2.1283674836158752

Epoch: 6| Step: 4
Training loss: 0.7904336452484131
Validation loss: 2.088915745417277

Epoch: 6| Step: 5
Training loss: 0.544343888759613
Validation loss: 2.080057521661123

Epoch: 6| Step: 6
Training loss: 0.7914267778396606
Validation loss: 2.102308909098307

Epoch: 6| Step: 7
Training loss: 0.39462709426879883
Validation loss: 2.100119968255361

Epoch: 6| Step: 8
Training loss: 0.4389451742172241
Validation loss: 2.0897270838419595

Epoch: 6| Step: 9
Training loss: 0.410068154335022
Validation loss: 2.08944171667099

Epoch: 6| Step: 10
Training loss: 0.6148267984390259
Validation loss: 2.0735745827356973

Epoch: 6| Step: 11
Training loss: 0.4947757124900818
Validation loss: 2.0880584518114724

Epoch: 6| Step: 12
Training loss: 0.49586376547813416
Validation loss: 2.063511331876119

Epoch: 6| Step: 13
Training loss: 0.4108664095401764
Validation loss: 2.1131216287612915

Epoch: 302| Step: 0
Training loss: 0.47358033061027527
Validation loss: 2.110235631465912

Epoch: 6| Step: 1
Training loss: 0.48166656494140625
Validation loss: 2.0799086491266885

Epoch: 6| Step: 2
Training loss: 0.7270323634147644
Validation loss: 2.0809802810351052

Epoch: 6| Step: 3
Training loss: 0.8303295373916626
Validation loss: 2.1063822905222573

Epoch: 6| Step: 4
Training loss: 0.3734441101551056
Validation loss: 2.1220427751541138

Epoch: 6| Step: 5
Training loss: 0.4815605580806732
Validation loss: 2.125517249107361

Epoch: 6| Step: 6
Training loss: 0.5334504246711731
Validation loss: 2.092217961947123

Epoch: 6| Step: 7
Training loss: 0.5058555006980896
Validation loss: 2.087473968664805

Epoch: 6| Step: 8
Training loss: 1.0386407375335693
Validation loss: 2.114517331123352

Epoch: 6| Step: 9
Training loss: 0.6373193860054016
Validation loss: 2.086191733678182

Epoch: 6| Step: 10
Training loss: 0.759236216545105
Validation loss: 2.094892382621765

Epoch: 6| Step: 11
Training loss: 0.6855825781822205
Validation loss: 2.070312480131785

Epoch: 6| Step: 12
Training loss: 0.37538671493530273
Validation loss: 2.0639646848042807

Epoch: 6| Step: 13
Training loss: 0.4933150112628937
Validation loss: 2.1631378332773843

Epoch: 303| Step: 0
Training loss: 0.4282231628894806
Validation loss: 2.146683990955353

Epoch: 6| Step: 1
Training loss: 0.6705004572868347
Validation loss: 2.1332748333613076

Epoch: 6| Step: 2
Training loss: 0.9458121657371521
Validation loss: 2.1761948664983115

Epoch: 6| Step: 3
Training loss: 0.5026327967643738
Validation loss: 2.1456479032834372

Epoch: 6| Step: 4
Training loss: 0.7248975038528442
Validation loss: 2.12546839316686

Epoch: 6| Step: 5
Training loss: 0.762704610824585
Validation loss: 2.136573870976766

Epoch: 6| Step: 6
Training loss: 0.4627787470817566
Validation loss: 2.056328296661377

Epoch: 6| Step: 7
Training loss: 0.4800834059715271
Validation loss: 2.1137560407320657

Epoch: 6| Step: 8
Training loss: 0.7217870354652405
Validation loss: 2.099075416723887

Epoch: 6| Step: 9
Training loss: 0.42489486932754517
Validation loss: 2.092096189657847

Epoch: 6| Step: 10
Training loss: 0.8189456462860107
Validation loss: 2.046343982219696

Epoch: 6| Step: 11
Training loss: 0.39768147468566895
Validation loss: 2.1125057538350425

Epoch: 6| Step: 12
Training loss: 0.7206377983093262
Validation loss: 2.091393311818441

Epoch: 6| Step: 13
Training loss: 0.4231916069984436
Validation loss: 2.1284645398457847

Epoch: 304| Step: 0
Training loss: 0.683728814125061
Validation loss: 2.1144683758417764

Epoch: 6| Step: 1
Training loss: 0.5453225374221802
Validation loss: 2.1432466308275857

Epoch: 6| Step: 2
Training loss: 0.377772718667984
Validation loss: 2.109143296877543

Epoch: 6| Step: 3
Training loss: 0.432367205619812
Validation loss: 2.066268265247345

Epoch: 6| Step: 4
Training loss: 1.1963201761245728
Validation loss: 2.127938727537791

Epoch: 6| Step: 5
Training loss: 0.5518999099731445
Validation loss: 2.095450003941854

Epoch: 6| Step: 6
Training loss: 0.44367995858192444
Validation loss: 2.083421985308329

Epoch: 6| Step: 7
Training loss: 0.652233362197876
Validation loss: 2.1076722939809165

Epoch: 6| Step: 8
Training loss: 0.5169351100921631
Validation loss: 2.1343660155932107

Epoch: 6| Step: 9
Training loss: 0.4701862335205078
Validation loss: 2.098336935043335

Epoch: 6| Step: 10
Training loss: 0.5458309054374695
Validation loss: 2.157889405886332

Epoch: 6| Step: 11
Training loss: 0.5032162666320801
Validation loss: 2.1703520019849143

Epoch: 6| Step: 12
Training loss: 0.5518300533294678
Validation loss: 2.1570234298706055

Epoch: 6| Step: 13
Training loss: 0.4886046051979065
Validation loss: 2.182301700115204

Epoch: 305| Step: 0
Training loss: 0.6758795380592346
Validation loss: 2.155428131421407

Epoch: 6| Step: 1
Training loss: 0.3455207943916321
Validation loss: 2.114035884539286

Epoch: 6| Step: 2
Training loss: 0.30447205901145935
Validation loss: 2.128226419289907

Epoch: 6| Step: 3
Training loss: 0.3481161892414093
Validation loss: 2.130011260509491

Epoch: 6| Step: 4
Training loss: 0.430533766746521
Validation loss: 2.055704633394877

Epoch: 6| Step: 5
Training loss: 0.44915613532066345
Validation loss: 2.064589520295461

Epoch: 6| Step: 6
Training loss: 1.2538952827453613
Validation loss: 2.045483489831289

Epoch: 6| Step: 7
Training loss: 0.5464327335357666
Validation loss: 2.074618955453237

Epoch: 6| Step: 8
Training loss: 0.9824414253234863
Validation loss: 2.133842666943868

Epoch: 6| Step: 9
Training loss: 0.6825506687164307
Validation loss: 2.11612077554067

Epoch: 6| Step: 10
Training loss: 0.46568548679351807
Validation loss: 2.1066149274508157

Epoch: 6| Step: 11
Training loss: 0.844096839427948
Validation loss: 2.1824063658714294

Epoch: 6| Step: 12
Training loss: 0.522740364074707
Validation loss: 2.1328121026357016

Epoch: 6| Step: 13
Training loss: 0.5069249272346497
Validation loss: 2.10418701171875

Epoch: 306| Step: 0
Training loss: 0.20817092061042786
Validation loss: 2.1035202741622925

Epoch: 6| Step: 1
Training loss: 0.29519322514533997
Validation loss: 2.1134222944577536

Epoch: 6| Step: 2
Training loss: 0.8801517486572266
Validation loss: 2.0505428314208984

Epoch: 6| Step: 3
Training loss: 0.6323051452636719
Validation loss: 2.1393813689549765

Epoch: 6| Step: 4
Training loss: 0.48122358322143555
Validation loss: 2.0845365722974143

Epoch: 6| Step: 5
Training loss: 0.42023104429244995
Validation loss: 2.1156352162361145

Epoch: 6| Step: 6
Training loss: 0.624549388885498
Validation loss: 2.1088381012280784

Epoch: 6| Step: 7
Training loss: 0.6203583478927612
Validation loss: 2.073204437891642

Epoch: 6| Step: 8
Training loss: 0.7688267230987549
Validation loss: 2.132315675417582

Epoch: 6| Step: 9
Training loss: 0.2639613747596741
Validation loss: 2.1246353586514792

Epoch: 6| Step: 10
Training loss: 0.8761370778083801
Validation loss: 2.0882153113683066

Epoch: 6| Step: 11
Training loss: 0.7458608746528625
Validation loss: 2.1231509248415628

Epoch: 6| Step: 12
Training loss: 0.36646556854248047
Validation loss: 2.125996232032776

Epoch: 6| Step: 13
Training loss: 0.6874250173568726
Validation loss: 2.116292178630829

Epoch: 307| Step: 0
Training loss: 0.30164849758148193
Validation loss: 2.100898583730062

Epoch: 6| Step: 1
Training loss: 0.497631698846817
Validation loss: 2.1396984259287515

Epoch: 6| Step: 2
Training loss: 1.0063363313674927
Validation loss: 2.1155059337615967

Epoch: 6| Step: 3
Training loss: 0.5282363891601562
Validation loss: 2.1280418634414673

Epoch: 6| Step: 4
Training loss: 0.7006833553314209
Validation loss: 2.115219235420227

Epoch: 6| Step: 5
Training loss: 0.2655159831047058
Validation loss: 2.077181577682495

Epoch: 6| Step: 6
Training loss: 0.508658766746521
Validation loss: 2.0747852325439453

Epoch: 6| Step: 7
Training loss: 0.5818001627922058
Validation loss: 2.0921976566314697

Epoch: 6| Step: 8
Training loss: 0.7759883403778076
Validation loss: 2.0973867177963257

Epoch: 6| Step: 9
Training loss: 0.7449203133583069
Validation loss: 2.0977940758069358

Epoch: 6| Step: 10
Training loss: 0.3646845817565918
Validation loss: 2.126401702562968

Epoch: 6| Step: 11
Training loss: 0.4440075755119324
Validation loss: 2.106035133202871

Epoch: 6| Step: 12
Training loss: 0.21832603216171265
Validation loss: 2.091541846593221

Epoch: 6| Step: 13
Training loss: 0.4507256746292114
Validation loss: 2.078331728776296

Epoch: 308| Step: 0
Training loss: 0.5142259001731873
Validation loss: 2.095052639643351

Epoch: 6| Step: 1
Training loss: 0.8913241028785706
Validation loss: 2.091443717479706

Epoch: 6| Step: 2
Training loss: 0.7239387035369873
Validation loss: 2.065421481927236

Epoch: 6| Step: 3
Training loss: 0.8914399147033691
Validation loss: 2.1335875590642295

Epoch: 6| Step: 4
Training loss: 0.3484659492969513
Validation loss: 2.0789191722869873

Epoch: 6| Step: 5
Training loss: 0.34693771600723267
Validation loss: 2.1185940305391946

Epoch: 6| Step: 6
Training loss: 0.7398134469985962
Validation loss: 2.0920509099960327

Epoch: 6| Step: 7
Training loss: 0.26295438408851624
Validation loss: 2.112741708755493

Epoch: 6| Step: 8
Training loss: 0.506087064743042
Validation loss: 2.1282199025154114

Epoch: 6| Step: 9
Training loss: 0.5197950601577759
Validation loss: 2.0695848067601523

Epoch: 6| Step: 10
Training loss: 0.557892918586731
Validation loss: 2.1253908475240073

Epoch: 6| Step: 11
Training loss: 0.364274799823761
Validation loss: 2.145598570505778

Epoch: 6| Step: 12
Training loss: 0.41612952947616577
Validation loss: 2.09114279349645

Epoch: 6| Step: 13
Training loss: 0.529782772064209
Validation loss: 2.0748371283213296

Epoch: 309| Step: 0
Training loss: 0.43708521127700806
Validation loss: 2.091115633646647

Epoch: 6| Step: 1
Training loss: 0.6491174101829529
Validation loss: 2.1357869704564414

Epoch: 6| Step: 2
Training loss: 0.5268394351005554
Validation loss: 2.080187221368154

Epoch: 6| Step: 3
Training loss: 0.544001579284668
Validation loss: 2.138839860757192

Epoch: 6| Step: 4
Training loss: 0.5984389185905457
Validation loss: 2.115355054537455

Epoch: 6| Step: 5
Training loss: 0.44751933217048645
Validation loss: 2.1693596839904785

Epoch: 6| Step: 6
Training loss: 1.2197221517562866
Validation loss: 2.181217888991038

Epoch: 6| Step: 7
Training loss: 0.5203115940093994
Validation loss: 2.099793275197347

Epoch: 6| Step: 8
Training loss: 0.3201555609703064
Validation loss: 2.166476051012675

Epoch: 6| Step: 9
Training loss: 0.24903498589992523
Validation loss: 2.1013750632603965

Epoch: 6| Step: 10
Training loss: 0.5393171906471252
Validation loss: 2.1193390091260276

Epoch: 6| Step: 11
Training loss: 0.9591362476348877
Validation loss: 2.1065135995546975

Epoch: 6| Step: 12
Training loss: 0.4363146424293518
Validation loss: 2.130193829536438

Epoch: 6| Step: 13
Training loss: 0.52653568983078
Validation loss: 2.1039045651753745

Epoch: 310| Step: 0
Training loss: 0.3035467863082886
Validation loss: 2.104178726673126

Epoch: 6| Step: 1
Training loss: 0.49640026688575745
Validation loss: 2.1492591897646585

Epoch: 6| Step: 2
Training loss: 0.6577206254005432
Validation loss: 2.122381945451101

Epoch: 6| Step: 3
Training loss: 0.6060740947723389
Validation loss: 2.148582657178243

Epoch: 6| Step: 4
Training loss: 0.5363518595695496
Validation loss: 2.1595542629559836

Epoch: 6| Step: 5
Training loss: 0.981752872467041
Validation loss: 2.1639145016670227

Epoch: 6| Step: 6
Training loss: 0.3388841152191162
Validation loss: 2.1341317097345986

Epoch: 6| Step: 7
Training loss: 0.37585923075675964
Validation loss: 2.080888112386068

Epoch: 6| Step: 8
Training loss: 0.3317539095878601
Validation loss: 2.1130576928456626

Epoch: 6| Step: 9
Training loss: 0.42064130306243896
Validation loss: 2.1152835289637246

Epoch: 6| Step: 10
Training loss: 0.6053606271743774
Validation loss: 2.0669357577959695

Epoch: 6| Step: 11
Training loss: 0.7533139586448669
Validation loss: 2.0850162307421365

Epoch: 6| Step: 12
Training loss: 0.9405261278152466
Validation loss: 2.056325296560923

Epoch: 6| Step: 13
Training loss: 0.33846476674079895
Validation loss: 2.072804550329844

Epoch: 311| Step: 0
Training loss: 0.4285069406032562
Validation loss: 2.090625762939453

Epoch: 6| Step: 1
Training loss: 0.7791260480880737
Validation loss: 2.115442236264547

Epoch: 6| Step: 2
Training loss: 0.5246933698654175
Validation loss: 2.0695263147354126

Epoch: 6| Step: 3
Training loss: 0.6075383424758911
Validation loss: 2.115617593129476

Epoch: 6| Step: 4
Training loss: 0.5336425304412842
Validation loss: 2.1035359104474387

Epoch: 6| Step: 5
Training loss: 0.42168718576431274
Validation loss: 2.0596306125322976

Epoch: 6| Step: 6
Training loss: 0.5930817723274231
Validation loss: 2.0772101879119873

Epoch: 6| Step: 7
Training loss: 0.3817034363746643
Validation loss: 2.0862117608388266

Epoch: 6| Step: 8
Training loss: 0.56737220287323
Validation loss: 2.073353628317515

Epoch: 6| Step: 9
Training loss: 0.7145441770553589
Validation loss: 2.0846871932347617

Epoch: 6| Step: 10
Training loss: 0.7222416400909424
Validation loss: 2.078929305076599

Epoch: 6| Step: 11
Training loss: 0.2584971487522125
Validation loss: 2.1126967072486877

Epoch: 6| Step: 12
Training loss: 0.6694254875183105
Validation loss: 2.1409642100334167

Epoch: 6| Step: 13
Training loss: 0.46998730301856995
Validation loss: 2.0585252245267234

Epoch: 312| Step: 0
Training loss: 0.8092668652534485
Validation loss: 2.076614042123159

Epoch: 6| Step: 1
Training loss: 0.3259311020374298
Validation loss: 2.1149332324663797

Epoch: 6| Step: 2
Training loss: 0.6325361728668213
Validation loss: 2.1324371894200644

Epoch: 6| Step: 3
Training loss: 0.4235307276248932
Validation loss: 2.119512697060903

Epoch: 6| Step: 4
Training loss: 0.42230546474456787
Validation loss: 2.085759401321411

Epoch: 6| Step: 5
Training loss: 0.4305919110774994
Validation loss: 2.0991912682851157

Epoch: 6| Step: 6
Training loss: 0.6405621767044067
Validation loss: 2.0804381370544434

Epoch: 6| Step: 7
Training loss: 0.3413611054420471
Validation loss: 2.107707142829895

Epoch: 6| Step: 8
Training loss: 0.651561439037323
Validation loss: 2.1202844381332397

Epoch: 6| Step: 9
Training loss: 0.9005008339881897
Validation loss: 2.124326924482981

Epoch: 6| Step: 10
Training loss: 0.5272008180618286
Validation loss: 2.1313144167264304

Epoch: 6| Step: 11
Training loss: 0.9595857858657837
Validation loss: 2.173389752705892

Epoch: 6| Step: 12
Training loss: 0.19041261076927185
Validation loss: 2.1711711088816323

Epoch: 6| Step: 13
Training loss: 0.34990811347961426
Validation loss: 2.1724552313486734

Epoch: 313| Step: 0
Training loss: 0.25275593996047974
Validation loss: 2.1493459145228067

Epoch: 6| Step: 1
Training loss: 0.8454737067222595
Validation loss: 2.105802575747172

Epoch: 6| Step: 2
Training loss: 1.0119224786758423
Validation loss: 2.103799303372701

Epoch: 6| Step: 3
Training loss: 0.4955217242240906
Validation loss: 2.08623598019282

Epoch: 6| Step: 4
Training loss: 0.4572335183620453
Validation loss: 2.098926822344462

Epoch: 6| Step: 5
Training loss: 0.5073610544204712
Validation loss: 2.119252920150757

Epoch: 6| Step: 6
Training loss: 0.4663507342338562
Validation loss: 2.1491722663243613

Epoch: 6| Step: 7
Training loss: 0.3148294985294342
Validation loss: 2.1091859936714172

Epoch: 6| Step: 8
Training loss: 0.638310432434082
Validation loss: 2.136086622873942

Epoch: 6| Step: 9
Training loss: 0.8406757712364197
Validation loss: 2.176772872606913

Epoch: 6| Step: 10
Training loss: 0.5594892501831055
Validation loss: 2.158577799797058

Epoch: 6| Step: 11
Training loss: 0.27079302072525024
Validation loss: 2.128787318865458

Epoch: 6| Step: 12
Training loss: 0.4840123951435089
Validation loss: 2.0852129062016806

Epoch: 6| Step: 13
Training loss: 0.4450903534889221
Validation loss: 2.141434073448181

Epoch: 314| Step: 0
Training loss: 0.41615328192710876
Validation loss: 2.106293261051178

Epoch: 6| Step: 1
Training loss: 0.5331375002861023
Validation loss: 2.1330350041389465

Epoch: 6| Step: 2
Training loss: 1.112636923789978
Validation loss: 2.0871044198671975

Epoch: 6| Step: 3
Training loss: 0.26857829093933105
Validation loss: 2.0995992024739585

Epoch: 6| Step: 4
Training loss: 0.2548505961894989
Validation loss: 2.103224217891693

Epoch: 6| Step: 5
Training loss: 0.35317111015319824
Validation loss: 2.1187469959259033

Epoch: 6| Step: 6
Training loss: 0.7268694639205933
Validation loss: 2.1023632089296975

Epoch: 6| Step: 7
Training loss: 0.37563657760620117
Validation loss: 2.1642260551452637

Epoch: 6| Step: 8
Training loss: 0.43895745277404785
Validation loss: 2.1407554944356284

Epoch: 6| Step: 9
Training loss: 0.6308480501174927
Validation loss: 2.1490888595581055

Epoch: 6| Step: 10
Training loss: 0.19868877530097961
Validation loss: 2.1564882596333823

Epoch: 6| Step: 11
Training loss: 0.6798571348190308
Validation loss: 2.106050709883372

Epoch: 6| Step: 12
Training loss: 0.39654386043548584
Validation loss: 2.1204108595848083

Epoch: 6| Step: 13
Training loss: 0.8995773792266846
Validation loss: 2.122249722480774

Epoch: 315| Step: 0
Training loss: 0.45221415162086487
Validation loss: 2.1048651933670044

Epoch: 6| Step: 1
Training loss: 0.6845811605453491
Validation loss: 2.042733093102773

Epoch: 6| Step: 2
Training loss: 0.5389212369918823
Validation loss: 2.1073332031567893

Epoch: 6| Step: 3
Training loss: 0.5809507966041565
Validation loss: 2.1135475436846414

Epoch: 6| Step: 4
Training loss: 0.44863614439964294
Validation loss: 2.1621272563934326

Epoch: 6| Step: 5
Training loss: 0.8059976696968079
Validation loss: 2.162399331728617

Epoch: 6| Step: 6
Training loss: 0.7865086197853088
Validation loss: 2.1379692753156028

Epoch: 6| Step: 7
Training loss: 0.44947031140327454
Validation loss: 2.136155605316162

Epoch: 6| Step: 8
Training loss: 0.42610597610473633
Validation loss: 2.1083006660143533

Epoch: 6| Step: 9
Training loss: 0.5616974830627441
Validation loss: 2.07870751619339

Epoch: 6| Step: 10
Training loss: 0.3194161057472229
Validation loss: 2.072434663772583

Epoch: 6| Step: 11
Training loss: 0.810409426689148
Validation loss: 2.110523502031962

Epoch: 6| Step: 12
Training loss: 0.7675456404685974
Validation loss: 2.0806352694829306

Epoch: 6| Step: 13
Training loss: 0.5817941427230835
Validation loss: 2.1093732913335166

Epoch: 316| Step: 0
Training loss: 0.6783117055892944
Validation loss: 2.0876948634783425

Epoch: 6| Step: 1
Training loss: 0.38777756690979004
Validation loss: 2.154217779636383

Epoch: 6| Step: 2
Training loss: 0.6942917704582214
Validation loss: 2.1454317967096963

Epoch: 6| Step: 3
Training loss: 0.45950886607170105
Validation loss: 2.1373351414998374

Epoch: 6| Step: 4
Training loss: 0.4815240502357483
Validation loss: 2.158630649248759

Epoch: 6| Step: 5
Training loss: 0.3790486752986908
Validation loss: 2.153615931669871

Epoch: 6| Step: 6
Training loss: 0.7528859972953796
Validation loss: 2.1405679980913797

Epoch: 6| Step: 7
Training loss: 0.2776308059692383
Validation loss: 2.1047432025273642

Epoch: 6| Step: 8
Training loss: 0.5410063862800598
Validation loss: 2.107781012852987

Epoch: 6| Step: 9
Training loss: 0.3137171268463135
Validation loss: 2.0895119508107505

Epoch: 6| Step: 10
Training loss: 0.825995922088623
Validation loss: 2.120233436425527

Epoch: 6| Step: 11
Training loss: 0.7949327230453491
Validation loss: 2.135859429836273

Epoch: 6| Step: 12
Training loss: 0.5288165807723999
Validation loss: 2.0749411384264627

Epoch: 6| Step: 13
Training loss: 0.46737098693847656
Validation loss: 2.13047065337499

Epoch: 317| Step: 0
Training loss: 0.24994546175003052
Validation loss: 2.1211100618044534

Epoch: 6| Step: 1
Training loss: 0.6055440902709961
Validation loss: 2.1089711586634317

Epoch: 6| Step: 2
Training loss: 0.5596267580986023
Validation loss: 2.084922730922699

Epoch: 6| Step: 3
Training loss: 0.4643629491329193
Validation loss: 2.122265021006266

Epoch: 6| Step: 4
Training loss: 0.6311458349227905
Validation loss: 2.1128148237864175

Epoch: 6| Step: 5
Training loss: 0.932611346244812
Validation loss: 2.0946163733800254

Epoch: 6| Step: 6
Training loss: 0.7640190720558167
Validation loss: 2.0850894252459207

Epoch: 6| Step: 7
Training loss: 0.5050826668739319
Validation loss: 2.1126587192217507

Epoch: 6| Step: 8
Training loss: 0.5945836901664734
Validation loss: 2.099754254023234

Epoch: 6| Step: 9
Training loss: 0.4405028223991394
Validation loss: 2.129312018553416

Epoch: 6| Step: 10
Training loss: 0.39120376110076904
Validation loss: 2.2067585388819375

Epoch: 6| Step: 11
Training loss: 0.4047105610370636
Validation loss: 2.14098584651947

Epoch: 6| Step: 12
Training loss: 0.3508809208869934
Validation loss: 2.106778860092163

Epoch: 6| Step: 13
Training loss: 0.3650181293487549
Validation loss: 2.1270867586135864

Epoch: 318| Step: 0
Training loss: 0.45462164282798767
Validation loss: 2.1430346965789795

Epoch: 6| Step: 1
Training loss: 0.6400555372238159
Validation loss: 2.085167189439138

Epoch: 6| Step: 2
Training loss: 0.5134952664375305
Validation loss: 2.115854024887085

Epoch: 6| Step: 3
Training loss: 0.46471667289733887
Validation loss: 2.096104641755422

Epoch: 6| Step: 4
Training loss: 0.629805862903595
Validation loss: 2.060363471508026

Epoch: 6| Step: 5
Training loss: 0.44936466217041016
Validation loss: 2.0988561312357583

Epoch: 6| Step: 6
Training loss: 0.31619879603385925
Validation loss: 2.1079636216163635

Epoch: 6| Step: 7
Training loss: 0.39783716201782227
Validation loss: 2.1259851455688477

Epoch: 6| Step: 8
Training loss: 0.4959397614002228
Validation loss: 2.105821887652079

Epoch: 6| Step: 9
Training loss: 0.8441407084465027
Validation loss: 2.1371512015660605

Epoch: 6| Step: 10
Training loss: 0.3820784091949463
Validation loss: 2.110667884349823

Epoch: 6| Step: 11
Training loss: 0.8953715562820435
Validation loss: 2.143184185028076

Epoch: 6| Step: 12
Training loss: 0.34341731667518616
Validation loss: 2.107133686542511

Epoch: 6| Step: 13
Training loss: 0.6582813262939453
Validation loss: 2.137398680051168

Epoch: 319| Step: 0
Training loss: 0.4095194637775421
Validation loss: 2.118062973022461

Epoch: 6| Step: 1
Training loss: 0.5304656028747559
Validation loss: 2.128463308016459

Epoch: 6| Step: 2
Training loss: 0.9105054140090942
Validation loss: 2.0900878310203552

Epoch: 6| Step: 3
Training loss: 0.6104592084884644
Validation loss: 2.076082388559977

Epoch: 6| Step: 4
Training loss: 0.27295976877212524
Validation loss: 2.1430180271466575

Epoch: 6| Step: 5
Training loss: 0.30569988489151
Validation loss: 2.1204839944839478

Epoch: 6| Step: 6
Training loss: 0.5821124315261841
Validation loss: 2.131747861703237

Epoch: 6| Step: 7
Training loss: 0.6507198810577393
Validation loss: 2.1576621929804483

Epoch: 6| Step: 8
Training loss: 0.6021716594696045
Validation loss: 2.1575892567634583

Epoch: 6| Step: 9
Training loss: 0.6569153070449829
Validation loss: 2.1553954680760703

Epoch: 6| Step: 10
Training loss: 0.341490775346756
Validation loss: 2.1344562768936157

Epoch: 6| Step: 11
Training loss: 0.7658405900001526
Validation loss: 2.0904990434646606

Epoch: 6| Step: 12
Training loss: 0.6458280086517334
Validation loss: 2.086185574531555

Epoch: 6| Step: 13
Training loss: 0.6775177717208862
Validation loss: 2.0881555875142417

Epoch: 320| Step: 0
Training loss: 0.39653414487838745
Validation loss: 2.115264097849528

Epoch: 6| Step: 1
Training loss: 0.6348181366920471
Validation loss: 2.0953588684399924

Epoch: 6| Step: 2
Training loss: 0.39110732078552246
Validation loss: 2.091932694117228

Epoch: 6| Step: 3
Training loss: 0.7659177780151367
Validation loss: 2.1324766079584756

Epoch: 6| Step: 4
Training loss: 0.23350869119167328
Validation loss: 2.1245311896006265

Epoch: 6| Step: 5
Training loss: 0.5264663696289062
Validation loss: 2.0824907620747886

Epoch: 6| Step: 6
Training loss: 0.3944455087184906
Validation loss: 2.1306567390759787

Epoch: 6| Step: 7
Training loss: 0.6307977437973022
Validation loss: 2.1564032634099326

Epoch: 6| Step: 8
Training loss: 0.6267083883285522
Validation loss: 2.0658050378163657

Epoch: 6| Step: 9
Training loss: 0.8881005048751831
Validation loss: 2.118903716405233

Epoch: 6| Step: 10
Training loss: 0.25332561135292053
Validation loss: 2.0837854146957397

Epoch: 6| Step: 11
Training loss: 0.5324190258979797
Validation loss: 2.116126795609792

Epoch: 6| Step: 12
Training loss: 0.757401168346405
Validation loss: 2.126666267712911

Epoch: 6| Step: 13
Training loss: 0.27148428559303284
Validation loss: 2.1076990564664206

Epoch: 321| Step: 0
Training loss: 0.4292820692062378
Validation loss: 2.121783415476481

Epoch: 6| Step: 1
Training loss: 0.650765061378479
Validation loss: 2.128251314163208

Epoch: 6| Step: 2
Training loss: 0.6519097685813904
Validation loss: 2.1171505649884543

Epoch: 6| Step: 3
Training loss: 0.6048204898834229
Validation loss: 2.1291868885358176

Epoch: 6| Step: 4
Training loss: 0.628875732421875
Validation loss: 2.1235110759735107

Epoch: 6| Step: 5
Training loss: 0.4435104727745056
Validation loss: 2.1329545378684998

Epoch: 6| Step: 6
Training loss: 0.4560278654098511
Validation loss: 2.120348592599233

Epoch: 6| Step: 7
Training loss: 0.21271204948425293
Validation loss: 2.1165138284365335

Epoch: 6| Step: 8
Training loss: 0.27010494470596313
Validation loss: 2.1343717773755393

Epoch: 6| Step: 9
Training loss: 0.6846132278442383
Validation loss: 2.1705815196037292

Epoch: 6| Step: 10
Training loss: 0.754318356513977
Validation loss: 2.1293806433677673

Epoch: 6| Step: 11
Training loss: 0.536773145198822
Validation loss: 2.1357253392537436

Epoch: 6| Step: 12
Training loss: 0.5096548199653625
Validation loss: 2.1299365162849426

Epoch: 6| Step: 13
Training loss: 0.6275816559791565
Validation loss: 2.1291662057240806

Epoch: 322| Step: 0
Training loss: 0.5744315385818481
Validation loss: 2.1212536295255027

Epoch: 6| Step: 1
Training loss: 0.17919635772705078
Validation loss: 2.091502626736959

Epoch: 6| Step: 2
Training loss: 0.48811182379722595
Validation loss: 2.0786430637041726

Epoch: 6| Step: 3
Training loss: 0.8926573991775513
Validation loss: 2.1013805866241455

Epoch: 6| Step: 4
Training loss: 0.6047177314758301
Validation loss: 2.089136997858683

Epoch: 6| Step: 5
Training loss: 0.3459647297859192
Validation loss: 2.112650136152903

Epoch: 6| Step: 6
Training loss: 0.5068409442901611
Validation loss: 2.0721004207928977

Epoch: 6| Step: 7
Training loss: 0.2880638539791107
Validation loss: 2.1498066782951355

Epoch: 6| Step: 8
Training loss: 0.5003676414489746
Validation loss: 2.091890792051951

Epoch: 6| Step: 9
Training loss: 0.2517094016075134
Validation loss: 2.125666340192159

Epoch: 6| Step: 10
Training loss: 0.46827906370162964
Validation loss: 2.0926166574160256

Epoch: 6| Step: 11
Training loss: 0.4227933883666992
Validation loss: 2.0999740163485208

Epoch: 6| Step: 12
Training loss: 0.5450912714004517
Validation loss: 2.113900303840637

Epoch: 6| Step: 13
Training loss: 0.9755664467811584
Validation loss: 2.0964670379956565

Epoch: 323| Step: 0
Training loss: 0.3168601989746094
Validation loss: 2.0959469278653464

Epoch: 6| Step: 1
Training loss: 0.4907890856266022
Validation loss: 2.161306381225586

Epoch: 6| Step: 2
Training loss: 0.5389137268066406
Validation loss: 2.1037133932113647

Epoch: 6| Step: 3
Training loss: 0.6542955040931702
Validation loss: 2.1051566998163858

Epoch: 6| Step: 4
Training loss: 0.5158016681671143
Validation loss: 2.135515034198761

Epoch: 6| Step: 5
Training loss: 0.442421555519104
Validation loss: 2.0720773935317993

Epoch: 6| Step: 6
Training loss: 0.6515871286392212
Validation loss: 2.1330546140670776

Epoch: 6| Step: 7
Training loss: 0.44419199228286743
Validation loss: 2.026868760585785

Epoch: 6| Step: 8
Training loss: 0.32950279116630554
Validation loss: 2.102650284767151

Epoch: 6| Step: 9
Training loss: 0.5365582704544067
Validation loss: 2.092776298522949

Epoch: 6| Step: 10
Training loss: 0.7399947047233582
Validation loss: 2.0954758524894714

Epoch: 6| Step: 11
Training loss: 0.2204304188489914
Validation loss: 2.110833009084066

Epoch: 6| Step: 12
Training loss: 0.40286684036254883
Validation loss: 2.0748966137568154

Epoch: 6| Step: 13
Training loss: 0.820705771446228
Validation loss: 2.0677145520846048

Epoch: 324| Step: 0
Training loss: 0.41699138283729553
Validation loss: 2.0884993275006614

Epoch: 6| Step: 1
Training loss: 0.46254557371139526
Validation loss: 2.0673877795537314

Epoch: 6| Step: 2
Training loss: 0.8159133195877075
Validation loss: 2.0919047594070435

Epoch: 6| Step: 3
Training loss: 0.5632025003433228
Validation loss: 2.093147397041321

Epoch: 6| Step: 4
Training loss: 0.7354361414909363
Validation loss: 2.0690577626228333

Epoch: 6| Step: 5
Training loss: 0.6412469148635864
Validation loss: 2.1340211629867554

Epoch: 6| Step: 6
Training loss: 0.6383739709854126
Validation loss: 2.138235628604889

Epoch: 6| Step: 7
Training loss: 0.41626134514808655
Validation loss: 2.1075550317764282

Epoch: 6| Step: 8
Training loss: 0.45965731143951416
Validation loss: 2.111563483874003

Epoch: 6| Step: 9
Training loss: 0.271304726600647
Validation loss: 2.067469000816345

Epoch: 6| Step: 10
Training loss: 0.43513453006744385
Validation loss: 2.1530577341715493

Epoch: 6| Step: 11
Training loss: 0.8850382566452026
Validation loss: 2.0532909631729126

Epoch: 6| Step: 12
Training loss: 0.40393927693367004
Validation loss: 2.117645263671875

Epoch: 6| Step: 13
Training loss: 0.33478856086730957
Validation loss: 2.1005963881810508

Epoch: 325| Step: 0
Training loss: 0.4170128107070923
Validation loss: 2.0785059928894043

Epoch: 6| Step: 1
Training loss: 0.9166216254234314
Validation loss: 2.086645185947418

Epoch: 6| Step: 2
Training loss: 0.5688781142234802
Validation loss: 2.140085279941559

Epoch: 6| Step: 3
Training loss: 0.37282663583755493
Validation loss: 2.1133197943369546

Epoch: 6| Step: 4
Training loss: 0.7915385365486145
Validation loss: 2.097209334373474

Epoch: 6| Step: 5
Training loss: 0.5646358132362366
Validation loss: 2.0996630589167276

Epoch: 6| Step: 6
Training loss: 0.28562378883361816
Validation loss: 2.146416664123535

Epoch: 6| Step: 7
Training loss: 0.3695068061351776
Validation loss: 2.1164642175038657

Epoch: 6| Step: 8
Training loss: 0.3921205699443817
Validation loss: 2.1013596256573996

Epoch: 6| Step: 9
Training loss: 0.6950755715370178
Validation loss: 2.14296817779541

Epoch: 6| Step: 10
Training loss: 0.3374573290348053
Validation loss: 2.09326579173406

Epoch: 6| Step: 11
Training loss: 0.5237258076667786
Validation loss: 2.07879771788915

Epoch: 6| Step: 12
Training loss: 0.2466222047805786
Validation loss: 2.138262132803599

Epoch: 6| Step: 13
Training loss: 0.5752685070037842
Validation loss: 2.1099982261657715

Epoch: 326| Step: 0
Training loss: 0.4930424094200134
Validation loss: 2.159966468811035

Epoch: 6| Step: 1
Training loss: 0.3859015107154846
Validation loss: 2.11478720108668

Epoch: 6| Step: 2
Training loss: 0.46599113941192627
Validation loss: 2.107350786526998

Epoch: 6| Step: 3
Training loss: 0.40643253922462463
Validation loss: 2.097585221131643

Epoch: 6| Step: 4
Training loss: 0.22955027222633362
Validation loss: 2.1066741943359375

Epoch: 6| Step: 5
Training loss: 0.2331797182559967
Validation loss: 2.1076345642407737

Epoch: 6| Step: 6
Training loss: 0.5266993641853333
Validation loss: 2.1070972283681235

Epoch: 6| Step: 7
Training loss: 1.1133455038070679
Validation loss: 2.1401557127634683

Epoch: 6| Step: 8
Training loss: 0.6587395071983337
Validation loss: 2.1682748993237815

Epoch: 6| Step: 9
Training loss: 0.5373731851577759
Validation loss: 2.139875888824463

Epoch: 6| Step: 10
Training loss: 0.5161399245262146
Validation loss: 2.1428868174552917

Epoch: 6| Step: 11
Training loss: 0.5506014823913574
Validation loss: 2.141674737135569

Epoch: 6| Step: 12
Training loss: 0.3251745402812958
Validation loss: 2.1316298445065818

Epoch: 6| Step: 13
Training loss: 0.6259034276008606
Validation loss: 2.1684349179267883

Epoch: 327| Step: 0
Training loss: 0.580416202545166
Validation loss: 2.164296507835388

Epoch: 6| Step: 1
Training loss: 0.7457460165023804
Validation loss: 2.1278294920921326

Epoch: 6| Step: 2
Training loss: 0.6953532695770264
Validation loss: 2.1407798329989114

Epoch: 6| Step: 3
Training loss: 0.44216904044151306
Validation loss: 2.1403390169143677

Epoch: 6| Step: 4
Training loss: 0.7652339935302734
Validation loss: 2.1111321449279785

Epoch: 6| Step: 5
Training loss: 0.341071218252182
Validation loss: 2.135778864224752

Epoch: 6| Step: 6
Training loss: 0.6765928864479065
Validation loss: 2.107450465361277

Epoch: 6| Step: 7
Training loss: 0.18923525512218475
Validation loss: 2.1219824949900308

Epoch: 6| Step: 8
Training loss: 0.2943848967552185
Validation loss: 2.1035977602005005

Epoch: 6| Step: 9
Training loss: 0.5091243982315063
Validation loss: 2.133133828639984

Epoch: 6| Step: 10
Training loss: 0.3338397145271301
Validation loss: 2.0616885224978128

Epoch: 6| Step: 11
Training loss: 0.705811619758606
Validation loss: 2.0962992111841836

Epoch: 6| Step: 12
Training loss: 0.4653981626033783
Validation loss: 2.101937691370646

Epoch: 6| Step: 13
Training loss: 0.4566572904586792
Validation loss: 2.112235148747762

Epoch: 328| Step: 0
Training loss: 0.24012990295886993
Validation loss: 2.0835350354512534

Epoch: 6| Step: 1
Training loss: 0.31339550018310547
Validation loss: 2.112759510676066

Epoch: 6| Step: 2
Training loss: 0.4710150361061096
Validation loss: 2.1307400862375894

Epoch: 6| Step: 3
Training loss: 0.24306151270866394
Validation loss: 2.093475600083669

Epoch: 6| Step: 4
Training loss: 0.7724088430404663
Validation loss: 2.109535058339437

Epoch: 6| Step: 5
Training loss: 0.5800669193267822
Validation loss: 2.110049823919932

Epoch: 6| Step: 6
Training loss: 0.4436835050582886
Validation loss: 2.1299272179603577

Epoch: 6| Step: 7
Training loss: 0.4608175754547119
Validation loss: 2.0765227476755777

Epoch: 6| Step: 8
Training loss: 0.3293258249759674
Validation loss: 2.0973177552223206

Epoch: 6| Step: 9
Training loss: 0.7961094975471497
Validation loss: 2.1275100310643515

Epoch: 6| Step: 10
Training loss: 0.5482655167579651
Validation loss: 2.1380945642789206

Epoch: 6| Step: 11
Training loss: 0.33659684658050537
Validation loss: 2.165743033091227

Epoch: 6| Step: 12
Training loss: 0.614336371421814
Validation loss: 2.1309452255566916

Epoch: 6| Step: 13
Training loss: 0.8763177394866943
Validation loss: 2.0908495585123696

Epoch: 329| Step: 0
Training loss: 0.7992125153541565
Validation loss: 2.105179190635681

Epoch: 6| Step: 1
Training loss: 0.32930344343185425
Validation loss: 2.104388117790222

Epoch: 6| Step: 2
Training loss: 0.22424601018428802
Validation loss: 2.0959277947743735

Epoch: 6| Step: 3
Training loss: 0.3064056634902954
Validation loss: 2.1391346057256064

Epoch: 6| Step: 4
Training loss: 0.47528108954429626
Validation loss: 2.127426008383433

Epoch: 6| Step: 5
Training loss: 0.39995622634887695
Validation loss: 2.1494051416714988

Epoch: 6| Step: 6
Training loss: 0.42688536643981934
Validation loss: 2.151507536570231

Epoch: 6| Step: 7
Training loss: 0.6978773474693298
Validation loss: 2.1232429345448813

Epoch: 6| Step: 8
Training loss: 0.6464259028434753
Validation loss: 2.129370152950287

Epoch: 6| Step: 9
Training loss: 0.5317878723144531
Validation loss: 2.1342817147572837

Epoch: 6| Step: 10
Training loss: 0.5502482652664185
Validation loss: 2.153021275997162

Epoch: 6| Step: 11
Training loss: 0.42659756541252136
Validation loss: 2.1560530265172324

Epoch: 6| Step: 12
Training loss: 0.3334812521934509
Validation loss: 2.1735665003458657

Epoch: 6| Step: 13
Training loss: 0.8818105459213257
Validation loss: 2.110097805658976

Epoch: 330| Step: 0
Training loss: 0.8064006567001343
Validation loss: 2.1295126477877298

Epoch: 6| Step: 1
Training loss: 0.5491283535957336
Validation loss: 2.1591485341389975

Epoch: 6| Step: 2
Training loss: 0.37150534987449646
Validation loss: 2.1137755513191223

Epoch: 6| Step: 3
Training loss: 0.7771121859550476
Validation loss: 2.0657684405644736

Epoch: 6| Step: 4
Training loss: 0.45738935470581055
Validation loss: 2.1095285415649414

Epoch: 6| Step: 5
Training loss: 0.5751833915710449
Validation loss: 2.1111297011375427

Epoch: 6| Step: 6
Training loss: 0.5994686484336853
Validation loss: 2.125044027964274

Epoch: 6| Step: 7
Training loss: 0.3697754144668579
Validation loss: 2.1562156478563943

Epoch: 6| Step: 8
Training loss: 0.6929041147232056
Validation loss: 2.1606006423632302

Epoch: 6| Step: 9
Training loss: 0.7667723894119263
Validation loss: 2.164320230484009

Epoch: 6| Step: 10
Training loss: 0.32940736413002014
Validation loss: 2.178677717844645

Epoch: 6| Step: 11
Training loss: 0.6140402555465698
Validation loss: 2.1712286671002707

Epoch: 6| Step: 12
Training loss: 0.38191863894462585
Validation loss: 2.137427051862081

Epoch: 6| Step: 13
Training loss: 0.29598140716552734
Validation loss: 2.139438589413961

Epoch: 331| Step: 0
Training loss: 0.47450339794158936
Validation loss: 2.0973546504974365

Epoch: 6| Step: 1
Training loss: 0.5911216139793396
Validation loss: 2.0989487369855246

Epoch: 6| Step: 2
Training loss: 0.5798532366752625
Validation loss: 2.1581514477729797

Epoch: 6| Step: 3
Training loss: 0.5533198118209839
Validation loss: 2.1105074087778726

Epoch: 6| Step: 4
Training loss: 0.3234558403491974
Validation loss: 2.1218794186909995

Epoch: 6| Step: 5
Training loss: 0.3818621039390564
Validation loss: 2.1045945485432944

Epoch: 6| Step: 6
Training loss: 0.4578821361064911
Validation loss: 2.1292778849601746

Epoch: 6| Step: 7
Training loss: 0.7376116514205933
Validation loss: 2.040812909603119

Epoch: 6| Step: 8
Training loss: 0.45717447996139526
Validation loss: 2.093522290388743

Epoch: 6| Step: 9
Training loss: 0.4754110872745514
Validation loss: 2.09775439898173

Epoch: 6| Step: 10
Training loss: 0.28800076246261597
Validation loss: 2.075969656308492

Epoch: 6| Step: 11
Training loss: 0.6314634680747986
Validation loss: 2.054694434007009

Epoch: 6| Step: 12
Training loss: 1.164726972579956
Validation loss: 2.120723028977712

Epoch: 6| Step: 13
Training loss: 0.23302607238292694
Validation loss: 2.150583585103353

Epoch: 332| Step: 0
Training loss: 0.37092745304107666
Validation loss: 2.1387002070744834

Epoch: 6| Step: 1
Training loss: 0.2624175548553467
Validation loss: 2.0937710205713906

Epoch: 6| Step: 2
Training loss: 0.23746275901794434
Validation loss: 2.1402438084284463

Epoch: 6| Step: 3
Training loss: 0.6360749006271362
Validation loss: 2.1532421708106995

Epoch: 6| Step: 4
Training loss: 0.7122674584388733
Validation loss: 2.1035515467325845

Epoch: 6| Step: 5
Training loss: 0.8013622760772705
Validation loss: 2.1463835636774697

Epoch: 6| Step: 6
Training loss: 0.3195846676826477
Validation loss: 2.1384511391321817

Epoch: 6| Step: 7
Training loss: 0.38004058599472046
Validation loss: 2.1058940092722573

Epoch: 6| Step: 8
Training loss: 0.4745404124259949
Validation loss: 2.1019369761149087

Epoch: 6| Step: 9
Training loss: 0.49774283170700073
Validation loss: 2.15090678135554

Epoch: 6| Step: 10
Training loss: 0.32374507188796997
Validation loss: 2.068898836771647

Epoch: 6| Step: 11
Training loss: 0.3468889594078064
Validation loss: 2.1551780700683594

Epoch: 6| Step: 12
Training loss: 0.6812537908554077
Validation loss: 2.127225915590922

Epoch: 6| Step: 13
Training loss: 0.8955220580101013
Validation loss: 2.1154455145200095

Epoch: 333| Step: 0
Training loss: 0.47942259907722473
Validation loss: 2.13177752494812

Epoch: 6| Step: 1
Training loss: 0.33216220140457153
Validation loss: 2.0711414416631064

Epoch: 6| Step: 2
Training loss: 0.6328290700912476
Validation loss: 2.1792889833450317

Epoch: 6| Step: 3
Training loss: 0.3767814040184021
Validation loss: 2.1426248947779336

Epoch: 6| Step: 4
Training loss: 0.5699417591094971
Validation loss: 2.170248250166575

Epoch: 6| Step: 5
Training loss: 0.621234655380249
Validation loss: 2.1529237826665244

Epoch: 6| Step: 6
Training loss: 0.6391441822052002
Validation loss: 2.1240315238634744

Epoch: 6| Step: 7
Training loss: 0.30641597509384155
Validation loss: 2.14750870068868

Epoch: 6| Step: 8
Training loss: 0.21313421428203583
Validation loss: 2.115091880162557

Epoch: 6| Step: 9
Training loss: 0.6267451047897339
Validation loss: 2.1261688470840454

Epoch: 6| Step: 10
Training loss: 0.668830931186676
Validation loss: 2.124101003011068

Epoch: 6| Step: 11
Training loss: 0.27121496200561523
Validation loss: 2.105547030766805

Epoch: 6| Step: 12
Training loss: 0.6481038928031921
Validation loss: 2.125589688618978

Epoch: 6| Step: 13
Training loss: 0.5073902010917664
Validation loss: 2.137121776739756

Epoch: 334| Step: 0
Training loss: 0.39048105478286743
Validation loss: 2.1458739042282104

Epoch: 6| Step: 1
Training loss: 0.30943408608436584
Validation loss: 2.131533920764923

Epoch: 6| Step: 2
Training loss: 0.2947714030742645
Validation loss: 2.0957578221956887

Epoch: 6| Step: 3
Training loss: 0.6938869953155518
Validation loss: 2.1359343926111856

Epoch: 6| Step: 4
Training loss: 0.7485522627830505
Validation loss: 2.0915091832478843

Epoch: 6| Step: 5
Training loss: 0.4409121870994568
Validation loss: 2.1208627820014954

Epoch: 6| Step: 6
Training loss: 0.8983995914459229
Validation loss: 2.089378853638967

Epoch: 6| Step: 7
Training loss: 0.7250827550888062
Validation loss: 2.115451991558075

Epoch: 6| Step: 8
Training loss: 0.32344794273376465
Validation loss: 2.0932494401931763

Epoch: 6| Step: 9
Training loss: 0.329265296459198
Validation loss: 2.1297559340794883

Epoch: 6| Step: 10
Training loss: 0.42104363441467285
Validation loss: 2.15912135442098

Epoch: 6| Step: 11
Training loss: 0.6465128064155579
Validation loss: 2.1476125915845237

Epoch: 6| Step: 12
Training loss: 0.4460245370864868
Validation loss: 2.13605272769928

Epoch: 6| Step: 13
Training loss: 0.2722929120063782
Validation loss: 2.1247222622235618

Epoch: 335| Step: 0
Training loss: 0.6342397332191467
Validation loss: 2.137113014856974

Epoch: 6| Step: 1
Training loss: 0.7958023548126221
Validation loss: 2.1291988492012024

Epoch: 6| Step: 2
Training loss: 0.3672582507133484
Validation loss: 2.1470490097999573

Epoch: 6| Step: 3
Training loss: 0.39199087023735046
Validation loss: 2.0701250632603965

Epoch: 6| Step: 4
Training loss: 0.25467097759246826
Validation loss: 2.141189237435659

Epoch: 6| Step: 5
Training loss: 0.28295838832855225
Validation loss: 2.0479352275530496

Epoch: 6| Step: 6
Training loss: 0.20602281391620636
Validation loss: 2.1201136310895285

Epoch: 6| Step: 7
Training loss: 0.37235090136528015
Validation loss: 2.0802137653032937

Epoch: 6| Step: 8
Training loss: 0.5157461762428284
Validation loss: 2.0834057927131653

Epoch: 6| Step: 9
Training loss: 0.3602115213871002
Validation loss: 2.14571342865626

Epoch: 6| Step: 10
Training loss: 0.7928069829940796
Validation loss: 2.144840180873871

Epoch: 6| Step: 11
Training loss: 0.8746638298034668
Validation loss: 2.1093669335047402

Epoch: 6| Step: 12
Training loss: 0.7803304195404053
Validation loss: 2.092215597629547

Epoch: 6| Step: 13
Training loss: 0.29730871319770813
Validation loss: 2.1565199891726174

Epoch: 336| Step: 0
Training loss: 0.270845502614975
Validation loss: 2.126000940799713

Epoch: 6| Step: 1
Training loss: 0.2796100378036499
Validation loss: 2.0588893493016562

Epoch: 6| Step: 2
Training loss: 0.3091360926628113
Validation loss: 2.1229488452275596

Epoch: 6| Step: 3
Training loss: 0.923943042755127
Validation loss: 2.0789180397987366

Epoch: 6| Step: 4
Training loss: 0.850426971912384
Validation loss: 2.0800607601801553

Epoch: 6| Step: 5
Training loss: 0.4529402256011963
Validation loss: 2.0816906293233237

Epoch: 6| Step: 6
Training loss: 0.26345086097717285
Validation loss: 2.1126092672348022

Epoch: 6| Step: 7
Training loss: 0.9542850255966187
Validation loss: 2.1171461741129556

Epoch: 6| Step: 8
Training loss: 0.46192240715026855
Validation loss: 2.1569994688034058

Epoch: 6| Step: 9
Training loss: 0.5129309892654419
Validation loss: 2.104720930258433

Epoch: 6| Step: 10
Training loss: 0.37445706129074097
Validation loss: 2.1092328230539956

Epoch: 6| Step: 11
Training loss: 0.24127086997032166
Validation loss: 2.1028168201446533

Epoch: 6| Step: 12
Training loss: 0.5142523050308228
Validation loss: 2.122796575228373

Epoch: 6| Step: 13
Training loss: 0.5452200174331665
Validation loss: 2.0804615020751953

Epoch: 337| Step: 0
Training loss: 0.47021549940109253
Validation loss: 2.113777140776316

Epoch: 6| Step: 1
Training loss: 0.38264596462249756
Validation loss: 2.079902430375417

Epoch: 6| Step: 2
Training loss: 0.414766788482666
Validation loss: 2.0792908867200217

Epoch: 6| Step: 3
Training loss: 0.7999837398529053
Validation loss: 2.0760221083958945

Epoch: 6| Step: 4
Training loss: 0.6556504368782043
Validation loss: 2.072414298852285

Epoch: 6| Step: 5
Training loss: 0.26774054765701294
Validation loss: 2.1045705477396646

Epoch: 6| Step: 6
Training loss: 0.5934475660324097
Validation loss: 2.126928428808848

Epoch: 6| Step: 7
Training loss: 0.5676223039627075
Validation loss: 2.0956942041714988

Epoch: 6| Step: 8
Training loss: 0.5013911724090576
Validation loss: 2.1385700702667236

Epoch: 6| Step: 9
Training loss: 0.5148748755455017
Validation loss: 2.133969306945801

Epoch: 6| Step: 10
Training loss: 0.3431444466114044
Validation loss: 2.1025811433792114

Epoch: 6| Step: 11
Training loss: 0.38808247447013855
Validation loss: 2.1092457373936973

Epoch: 6| Step: 12
Training loss: 0.7050189971923828
Validation loss: 2.1158120234807334

Epoch: 6| Step: 13
Training loss: 0.7285275459289551
Validation loss: 2.056792358557383

Epoch: 338| Step: 0
Training loss: 0.6498600840568542
Validation loss: 2.0659231146176658

Epoch: 6| Step: 1
Training loss: 0.26770684123039246
Validation loss: 2.0767077008883157

Epoch: 6| Step: 2
Training loss: 0.2782967686653137
Validation loss: 2.1311574379603067

Epoch: 6| Step: 3
Training loss: 0.579210638999939
Validation loss: 2.165749212106069

Epoch: 6| Step: 4
Training loss: 0.445464164018631
Validation loss: 2.1285141507784524

Epoch: 6| Step: 5
Training loss: 0.422706663608551
Validation loss: 2.102484862009684

Epoch: 6| Step: 6
Training loss: 0.5986872911453247
Validation loss: 2.1173984011014304

Epoch: 6| Step: 7
Training loss: 0.4265305995941162
Validation loss: 2.0924018224080405

Epoch: 6| Step: 8
Training loss: 0.5623436570167542
Validation loss: 2.0786280035972595

Epoch: 6| Step: 9
Training loss: 0.3246881067752838
Validation loss: 2.1190953850746155

Epoch: 6| Step: 10
Training loss: 0.917308509349823
Validation loss: 2.086323837439219

Epoch: 6| Step: 11
Training loss: 0.29773610830307007
Validation loss: 2.0851568579673767

Epoch: 6| Step: 12
Training loss: 0.7893170714378357
Validation loss: 2.1111181179682412

Epoch: 6| Step: 13
Training loss: 0.40324342250823975
Validation loss: 2.0876376032829285

Epoch: 339| Step: 0
Training loss: 0.5076563954353333
Validation loss: 2.115317722161611

Epoch: 6| Step: 1
Training loss: 0.7730166912078857
Validation loss: 2.095143973827362

Epoch: 6| Step: 2
Training loss: 0.45214253664016724
Validation loss: 2.0846195022265115

Epoch: 6| Step: 3
Training loss: 0.40438324213027954
Validation loss: 2.1137712399164834

Epoch: 6| Step: 4
Training loss: 0.5287079811096191
Validation loss: 2.0747495889663696

Epoch: 6| Step: 5
Training loss: 0.3387150764465332
Validation loss: 2.10037891070048

Epoch: 6| Step: 6
Training loss: 0.5751158595085144
Validation loss: 2.1182052890459695

Epoch: 6| Step: 7
Training loss: 0.49073556065559387
Validation loss: 2.0795199473698935

Epoch: 6| Step: 8
Training loss: 0.5217959880828857
Validation loss: 2.1231098969777427

Epoch: 6| Step: 9
Training loss: 0.4792860150337219
Validation loss: 2.114734490712484

Epoch: 6| Step: 10
Training loss: 0.2990947961807251
Validation loss: 2.0955139795939126

Epoch: 6| Step: 11
Training loss: 0.25377482175827026
Validation loss: 2.1223621169726052

Epoch: 6| Step: 12
Training loss: 0.3222157955169678
Validation loss: 2.131328066190084

Epoch: 6| Step: 13
Training loss: 1.0544254779815674
Validation loss: 2.1174290577570596

Epoch: 340| Step: 0
Training loss: 0.3337860703468323
Validation loss: 2.1187766591707864

Epoch: 6| Step: 1
Training loss: 0.44903773069381714
Validation loss: 2.123208522796631

Epoch: 6| Step: 2
Training loss: 0.8255174160003662
Validation loss: 2.1567004323005676

Epoch: 6| Step: 3
Training loss: 0.4573538303375244
Validation loss: 2.107237994670868

Epoch: 6| Step: 4
Training loss: 0.3304644227027893
Validation loss: 2.0691189567248025

Epoch: 6| Step: 5
Training loss: 0.3010476529598236
Validation loss: 2.131398320198059

Epoch: 6| Step: 6
Training loss: 0.387952983379364
Validation loss: 2.146397511164347

Epoch: 6| Step: 7
Training loss: 0.508249819278717
Validation loss: 2.173371891180674

Epoch: 6| Step: 8
Training loss: 0.45743346214294434
Validation loss: 2.112954040368398

Epoch: 6| Step: 9
Training loss: 0.6029307246208191
Validation loss: 2.1246915459632874

Epoch: 6| Step: 10
Training loss: 0.7300450801849365
Validation loss: 2.0640119512875876

Epoch: 6| Step: 11
Training loss: 0.28373873233795166
Validation loss: 2.0989749431610107

Epoch: 6| Step: 12
Training loss: 0.8434587121009827
Validation loss: 2.0954719185829163

Epoch: 6| Step: 13
Training loss: 0.37326809763908386
Validation loss: 2.0750346183776855

Epoch: 341| Step: 0
Training loss: 0.38217663764953613
Validation loss: 2.082857370376587

Epoch: 6| Step: 1
Training loss: 0.3713377118110657
Validation loss: 2.0667808055877686

Epoch: 6| Step: 2
Training loss: 0.49725574254989624
Validation loss: 2.080293873945872

Epoch: 6| Step: 3
Training loss: 0.47685033082962036
Validation loss: 2.074764927228292

Epoch: 6| Step: 4
Training loss: 0.2796858549118042
Validation loss: 2.0951076547304788

Epoch: 6| Step: 5
Training loss: 0.39342111349105835
Validation loss: 2.0956342220306396

Epoch: 6| Step: 6
Training loss: 1.3467566967010498
Validation loss: 2.128508369127909

Epoch: 6| Step: 7
Training loss: 0.552916407585144
Validation loss: 2.101419905821482

Epoch: 6| Step: 8
Training loss: 0.5486260652542114
Validation loss: 2.111084202925364

Epoch: 6| Step: 9
Training loss: 0.27088892459869385
Validation loss: 2.073046326637268

Epoch: 6| Step: 10
Training loss: 0.36699753999710083
Validation loss: 2.0783823331197104

Epoch: 6| Step: 11
Training loss: 0.6019202470779419
Validation loss: 2.0937326153119407

Epoch: 6| Step: 12
Training loss: 0.4560598134994507
Validation loss: 2.1142996549606323

Epoch: 6| Step: 13
Training loss: 0.28200864791870117
Validation loss: 2.115288734436035

Epoch: 342| Step: 0
Training loss: 0.1978253275156021
Validation loss: 2.1024296283721924

Epoch: 6| Step: 1
Training loss: 0.40845975279808044
Validation loss: 2.1318655212720237

Epoch: 6| Step: 2
Training loss: 0.4451085031032562
Validation loss: 2.11626007159551

Epoch: 6| Step: 3
Training loss: 0.4551544189453125
Validation loss: 2.141630152861277

Epoch: 6| Step: 4
Training loss: 0.8504427075386047
Validation loss: 2.16477370262146

Epoch: 6| Step: 5
Training loss: 0.6967333555221558
Validation loss: 2.1463106274604797

Epoch: 6| Step: 6
Training loss: 0.699853777885437
Validation loss: 2.1341539422671

Epoch: 6| Step: 7
Training loss: 0.20837269723415375
Validation loss: 2.0896865129470825

Epoch: 6| Step: 8
Training loss: 0.4563087224960327
Validation loss: 2.101202448209127

Epoch: 6| Step: 9
Training loss: 0.45164045691490173
Validation loss: 2.089190423488617

Epoch: 6| Step: 10
Training loss: 1.025755524635315
Validation loss: 2.119254251321157

Epoch: 6| Step: 11
Training loss: 0.4826251268386841
Validation loss: 2.0723130106925964

Epoch: 6| Step: 12
Training loss: 0.520696759223938
Validation loss: 2.0941708087921143

Epoch: 6| Step: 13
Training loss: 0.30983418226242065
Validation loss: 2.1016352574030557

Epoch: 343| Step: 0
Training loss: 0.48153966665267944
Validation loss: 2.139610707759857

Epoch: 6| Step: 1
Training loss: 0.42864057421684265
Validation loss: 2.103329658508301

Epoch: 6| Step: 2
Training loss: 0.6219865083694458
Validation loss: 2.1232520739237466

Epoch: 6| Step: 3
Training loss: 0.1969093382358551
Validation loss: 2.146085778872172

Epoch: 6| Step: 4
Training loss: 0.27227771282196045
Validation loss: 2.1004512111345925

Epoch: 6| Step: 5
Training loss: 0.4706115424633026
Validation loss: 2.1077749927838645

Epoch: 6| Step: 6
Training loss: 0.33226478099823
Validation loss: 2.0644948283831277

Epoch: 6| Step: 7
Training loss: 0.8869286179542542
Validation loss: 2.0896218021710715

Epoch: 6| Step: 8
Training loss: 0.7348343133926392
Validation loss: 2.0981720685958862

Epoch: 6| Step: 9
Training loss: 0.4271366596221924
Validation loss: 2.07664426167806

Epoch: 6| Step: 10
Training loss: 0.5349805355072021
Validation loss: 2.0787777105967202

Epoch: 6| Step: 11
Training loss: 0.5605829954147339
Validation loss: 2.1237340172131858

Epoch: 6| Step: 12
Training loss: 0.47267237305641174
Validation loss: 2.1547715266545615

Epoch: 6| Step: 13
Training loss: 0.4045494794845581
Validation loss: 2.098466436068217

Epoch: 344| Step: 0
Training loss: 0.29597359895706177
Validation loss: 2.130628824234009

Epoch: 6| Step: 1
Training loss: 0.7223870754241943
Validation loss: 2.1835216085116067

Epoch: 6| Step: 2
Training loss: 0.47496259212493896
Validation loss: 2.1534627278645835

Epoch: 6| Step: 3
Training loss: 0.3038460612297058
Validation loss: 2.116533319155375

Epoch: 6| Step: 4
Training loss: 0.5132781267166138
Validation loss: 2.145482838153839

Epoch: 6| Step: 5
Training loss: 0.2677302062511444
Validation loss: 2.130940079689026

Epoch: 6| Step: 6
Training loss: 0.7739123106002808
Validation loss: 2.141271193822225

Epoch: 6| Step: 7
Training loss: 0.3610473573207855
Validation loss: 2.0903166135152182

Epoch: 6| Step: 8
Training loss: 0.6134001016616821
Validation loss: 2.101954936981201

Epoch: 6| Step: 9
Training loss: 0.3509155511856079
Validation loss: 2.0945933858553567

Epoch: 6| Step: 10
Training loss: 0.38147103786468506
Validation loss: 2.0994980533917746

Epoch: 6| Step: 11
Training loss: 0.854330837726593
Validation loss: 2.087093790372213

Epoch: 6| Step: 12
Training loss: 0.2388131469488144
Validation loss: 2.09121310710907

Epoch: 6| Step: 13
Training loss: 0.28079062700271606
Validation loss: 2.1171862880388894

Epoch: 345| Step: 0
Training loss: 0.4958730936050415
Validation loss: 2.1015461087226868

Epoch: 6| Step: 1
Training loss: 0.31213903427124023
Validation loss: 2.1455686887105307

Epoch: 6| Step: 2
Training loss: 1.3385674953460693
Validation loss: 2.135843793551127

Epoch: 6| Step: 3
Training loss: 0.32082599401474
Validation loss: 2.134605129559835

Epoch: 6| Step: 4
Training loss: 0.4205568730831146
Validation loss: 2.1113303105036416

Epoch: 6| Step: 5
Training loss: 0.3686465620994568
Validation loss: 2.103392461935679

Epoch: 6| Step: 6
Training loss: 0.40522921085357666
Validation loss: 2.140887280305227

Epoch: 6| Step: 7
Training loss: 0.46878737211227417
Validation loss: 2.104676922162374

Epoch: 6| Step: 8
Training loss: 0.5229157209396362
Validation loss: 2.05972812573115

Epoch: 6| Step: 9
Training loss: 0.6367207765579224
Validation loss: 2.1279017527898154

Epoch: 6| Step: 10
Training loss: 0.6027453541755676
Validation loss: 2.129929761091868

Epoch: 6| Step: 11
Training loss: 0.44167986512184143
Validation loss: 2.121944268544515

Epoch: 6| Step: 12
Training loss: 0.583256721496582
Validation loss: 2.112147549788157

Epoch: 6| Step: 13
Training loss: 0.28724855184555054
Validation loss: 2.1363563537597656

Epoch: 346| Step: 0
Training loss: 0.536260724067688
Validation loss: 2.1166024208068848

Epoch: 6| Step: 1
Training loss: 0.24798430502414703
Validation loss: 2.1196619669596353

Epoch: 6| Step: 2
Training loss: 0.4783930480480194
Validation loss: 2.085151175657908

Epoch: 6| Step: 3
Training loss: 0.2960546612739563
Validation loss: 2.0828275879224143

Epoch: 6| Step: 4
Training loss: 0.27461111545562744
Validation loss: 2.1185543537139893

Epoch: 6| Step: 5
Training loss: 0.47165369987487793
Validation loss: 2.127963344256083

Epoch: 6| Step: 6
Training loss: 0.49986493587493896
Validation loss: 2.10146301984787

Epoch: 6| Step: 7
Training loss: 0.741349458694458
Validation loss: 2.109112560749054

Epoch: 6| Step: 8
Training loss: 0.6204635500907898
Validation loss: 2.112279494603475

Epoch: 6| Step: 9
Training loss: 0.5396699905395508
Validation loss: 2.131468911965688

Epoch: 6| Step: 10
Training loss: 0.9616566300392151
Validation loss: 2.1122988065083823

Epoch: 6| Step: 11
Training loss: 0.264403760433197
Validation loss: 2.1471641858418784

Epoch: 6| Step: 12
Training loss: 0.5195952653884888
Validation loss: 2.167640427748362

Epoch: 6| Step: 13
Training loss: 0.4508296251296997
Validation loss: 2.1045548915863037

Epoch: 347| Step: 0
Training loss: 0.1678278148174286
Validation loss: 2.1330159505208335

Epoch: 6| Step: 1
Training loss: 0.5909140110015869
Validation loss: 2.1140163342158

Epoch: 6| Step: 2
Training loss: 0.6517581343650818
Validation loss: 2.115213771661123

Epoch: 6| Step: 3
Training loss: 0.3697834014892578
Validation loss: 2.1065131028493247

Epoch: 6| Step: 4
Training loss: 0.303117036819458
Validation loss: 2.1436331470807395

Epoch: 6| Step: 5
Training loss: 0.4518144428730011
Validation loss: 2.1472057700157166

Epoch: 6| Step: 6
Training loss: 0.3609086871147156
Validation loss: 2.140178302923838

Epoch: 6| Step: 7
Training loss: 0.5848073363304138
Validation loss: 2.1861157615979514

Epoch: 6| Step: 8
Training loss: 0.344974160194397
Validation loss: 2.1487261056900024

Epoch: 6| Step: 9
Training loss: 0.7401554584503174
Validation loss: 2.134201447168986

Epoch: 6| Step: 10
Training loss: 0.4097777009010315
Validation loss: 2.150609612464905

Epoch: 6| Step: 11
Training loss: 0.5958638191223145
Validation loss: 2.095266342163086

Epoch: 6| Step: 12
Training loss: 0.8156720399856567
Validation loss: 2.0891523957252502

Epoch: 6| Step: 13
Training loss: 0.9048924446105957
Validation loss: 2.132212281227112

Epoch: 348| Step: 0
Training loss: 0.3513283133506775
Validation loss: 2.102538208166758

Epoch: 6| Step: 1
Training loss: 0.8732732534408569
Validation loss: 2.142442206541697

Epoch: 6| Step: 2
Training loss: 0.6826741695404053
Validation loss: 2.1081483364105225

Epoch: 6| Step: 3
Training loss: 0.4559881091117859
Validation loss: 2.1726681192715964

Epoch: 6| Step: 4
Training loss: 0.7622201442718506
Validation loss: 2.1603186329205832

Epoch: 6| Step: 5
Training loss: 0.30403977632522583
Validation loss: 2.133894125620524

Epoch: 6| Step: 6
Training loss: 0.7261067628860474
Validation loss: 2.1377362410227456

Epoch: 6| Step: 7
Training loss: 0.22906099259853363
Validation loss: 2.146775702635447

Epoch: 6| Step: 8
Training loss: 0.6014435887336731
Validation loss: 2.0677510698636374

Epoch: 6| Step: 9
Training loss: 0.34067076444625854
Validation loss: 2.1264527440071106

Epoch: 6| Step: 10
Training loss: 0.287270188331604
Validation loss: 2.096642096837362

Epoch: 6| Step: 11
Training loss: 0.40902239084243774
Validation loss: 2.073853154977163

Epoch: 6| Step: 12
Training loss: 0.29310691356658936
Validation loss: 2.0941835244496665

Epoch: 6| Step: 13
Training loss: 0.5321310758590698
Validation loss: 2.0971368153889975

Epoch: 349| Step: 0
Training loss: 0.4809275269508362
Validation loss: 2.1605039834976196

Epoch: 6| Step: 1
Training loss: 0.39148858189582825
Validation loss: 2.0661885341008506

Epoch: 6| Step: 2
Training loss: 0.6217218637466431
Validation loss: 2.108546813329061

Epoch: 6| Step: 3
Training loss: 0.46225473284721375
Validation loss: 2.1338173747062683

Epoch: 6| Step: 4
Training loss: 0.4627135396003723
Validation loss: 2.133432765801748

Epoch: 6| Step: 5
Training loss: 0.17998182773590088
Validation loss: 2.0847089091936746

Epoch: 6| Step: 6
Training loss: 1.0793631076812744
Validation loss: 2.124949256579081

Epoch: 6| Step: 7
Training loss: 0.8192201852798462
Validation loss: 2.119473477204641

Epoch: 6| Step: 8
Training loss: 0.25642871856689453
Validation loss: 2.1424439946810403

Epoch: 6| Step: 9
Training loss: 0.49823617935180664
Validation loss: 2.069884439309438

Epoch: 6| Step: 10
Training loss: 0.3393990993499756
Validation loss: 2.0557795564333596

Epoch: 6| Step: 11
Training loss: 0.37794098258018494
Validation loss: 2.0903592705726624

Epoch: 6| Step: 12
Training loss: 0.2863055467605591
Validation loss: 2.0981244246164956

Epoch: 6| Step: 13
Training loss: 0.5045581459999084
Validation loss: 2.101774036884308

Epoch: 350| Step: 0
Training loss: 0.38223516941070557
Validation loss: 2.1023568709691367

Epoch: 6| Step: 1
Training loss: 0.19861966371536255
Validation loss: 2.151874045530955

Epoch: 6| Step: 2
Training loss: 0.809272289276123
Validation loss: 2.147930383682251

Epoch: 6| Step: 3
Training loss: 0.32363277673721313
Validation loss: 2.102487782637278

Epoch: 6| Step: 4
Training loss: 0.986039936542511
Validation loss: 2.115782856941223

Epoch: 6| Step: 5
Training loss: 0.3438253402709961
Validation loss: 2.1049088637034097

Epoch: 6| Step: 6
Training loss: 0.39131516218185425
Validation loss: 2.097641408443451

Epoch: 6| Step: 7
Training loss: 0.3020670711994171
Validation loss: 2.074522336324056

Epoch: 6| Step: 8
Training loss: 0.6030313968658447
Validation loss: 2.124855717023214

Epoch: 6| Step: 9
Training loss: 0.26966339349746704
Validation loss: 2.090935985247294

Epoch: 6| Step: 10
Training loss: 0.7824605703353882
Validation loss: 2.1011930108070374

Epoch: 6| Step: 11
Training loss: 0.43013226985931396
Validation loss: 2.1335034569104514

Epoch: 6| Step: 12
Training loss: 0.5157852172851562
Validation loss: 2.1486341754595437

Epoch: 6| Step: 13
Training loss: 0.4584842622280121
Validation loss: 2.0685096780459085

Epoch: 351| Step: 0
Training loss: 0.4355211853981018
Validation loss: 2.1169949173927307

Epoch: 6| Step: 1
Training loss: 0.3848850131034851
Validation loss: 2.1371272007624307

Epoch: 6| Step: 2
Training loss: 0.6326711177825928
Validation loss: 2.1305825114250183

Epoch: 6| Step: 3
Training loss: 0.6704537868499756
Validation loss: 2.0753968358039856

Epoch: 6| Step: 4
Training loss: 0.3869990408420563
Validation loss: 2.098005712032318

Epoch: 6| Step: 5
Training loss: 0.4665656089782715
Validation loss: 2.1054999828338623

Epoch: 6| Step: 6
Training loss: 0.3303142189979553
Validation loss: 2.124123771985372

Epoch: 6| Step: 7
Training loss: 0.7085643410682678
Validation loss: 2.1345073779424033

Epoch: 6| Step: 8
Training loss: 0.2243356704711914
Validation loss: 2.0907474557558694

Epoch: 6| Step: 9
Training loss: 0.40750962495803833
Validation loss: 2.1361743410428367

Epoch: 6| Step: 10
Training loss: 0.3093661069869995
Validation loss: 2.1187498569488525

Epoch: 6| Step: 11
Training loss: 0.31694313883781433
Validation loss: 2.1315624117851257

Epoch: 6| Step: 12
Training loss: 0.9998708367347717
Validation loss: 2.114733556906382

Epoch: 6| Step: 13
Training loss: 0.4054637551307678
Validation loss: 2.070950369040171

Epoch: 352| Step: 0
Training loss: 0.370230495929718
Validation loss: 2.086089253425598

Epoch: 6| Step: 1
Training loss: 0.3496429920196533
Validation loss: 2.1640167236328125

Epoch: 6| Step: 2
Training loss: 0.7403210401535034
Validation loss: 2.0931589206059775

Epoch: 6| Step: 3
Training loss: 0.3467957675457001
Validation loss: 2.138221581776937

Epoch: 6| Step: 4
Training loss: 0.2689044177532196
Validation loss: 2.140211204687754

Epoch: 6| Step: 5
Training loss: 0.4080231785774231
Validation loss: 2.143580953280131

Epoch: 6| Step: 6
Training loss: 0.45694607496261597
Validation loss: 2.1240041851997375

Epoch: 6| Step: 7
Training loss: 0.6913973093032837
Validation loss: 2.1255966822306314

Epoch: 6| Step: 8
Training loss: 0.35226869583129883
Validation loss: 2.0810702045758567

Epoch: 6| Step: 9
Training loss: 0.3398018479347229
Validation loss: 2.1488846143086753

Epoch: 6| Step: 10
Training loss: 0.5241456627845764
Validation loss: 2.072428584098816

Epoch: 6| Step: 11
Training loss: 0.32061269879341125
Validation loss: 2.1399245460828147

Epoch: 6| Step: 12
Training loss: 1.0386877059936523
Validation loss: 2.1403074661890664

Epoch: 6| Step: 13
Training loss: 0.4247351884841919
Validation loss: 2.0714313983917236

Epoch: 353| Step: 0
Training loss: 0.3138025403022766
Validation loss: 2.075410465399424

Epoch: 6| Step: 1
Training loss: 0.5702638626098633
Validation loss: 2.1302308638890586

Epoch: 6| Step: 2
Training loss: 0.4859309792518616
Validation loss: 2.106173038482666

Epoch: 6| Step: 3
Training loss: 0.6741306781768799
Validation loss: 2.060140152772268

Epoch: 6| Step: 4
Training loss: 0.34691327810287476
Validation loss: 2.1070070266723633

Epoch: 6| Step: 5
Training loss: 0.41085711121559143
Validation loss: 2.0860171715418496

Epoch: 6| Step: 6
Training loss: 0.23560650646686554
Validation loss: 2.1535295645395913

Epoch: 6| Step: 7
Training loss: 0.38065940141677856
Validation loss: 2.067217151323954

Epoch: 6| Step: 8
Training loss: 0.45129337906837463
Validation loss: 2.1207944750785828

Epoch: 6| Step: 9
Training loss: 0.627522349357605
Validation loss: 2.075968106587728

Epoch: 6| Step: 10
Training loss: 0.2309492528438568
Validation loss: 2.11288716395696

Epoch: 6| Step: 11
Training loss: 0.6695077419281006
Validation loss: 2.069380005200704

Epoch: 6| Step: 12
Training loss: 0.47039705514907837
Validation loss: 2.0923145016034446

Epoch: 6| Step: 13
Training loss: 0.5019866228103638
Validation loss: 2.114919443925222

Epoch: 354| Step: 0
Training loss: 0.3477356433868408
Validation loss: 2.111049016316732

Epoch: 6| Step: 1
Training loss: 0.3890838027000427
Validation loss: 2.0785618225733438

Epoch: 6| Step: 2
Training loss: 0.2054758220911026
Validation loss: 2.130055864651998

Epoch: 6| Step: 3
Training loss: 0.8637179732322693
Validation loss: 2.1314104199409485

Epoch: 6| Step: 4
Training loss: 0.7912101149559021
Validation loss: 2.146860957145691

Epoch: 6| Step: 5
Training loss: 0.24734485149383545
Validation loss: 2.128369947274526

Epoch: 6| Step: 6
Training loss: 0.5932640433311462
Validation loss: 2.1391217509905496

Epoch: 6| Step: 7
Training loss: 0.48949554562568665
Validation loss: 2.1251312295595803

Epoch: 6| Step: 8
Training loss: 0.5874804258346558
Validation loss: 2.125405172506968

Epoch: 6| Step: 9
Training loss: 0.42288804054260254
Validation loss: 2.1071297327677407

Epoch: 6| Step: 10
Training loss: 0.252575159072876
Validation loss: 2.112842043240865

Epoch: 6| Step: 11
Training loss: 0.48800408840179443
Validation loss: 2.1189743280410767

Epoch: 6| Step: 12
Training loss: 0.1978445202112198
Validation loss: 2.075952629248301

Epoch: 6| Step: 13
Training loss: 0.48430126905441284
Validation loss: 2.1078739960988364

Epoch: 355| Step: 0
Training loss: 0.5821160674095154
Validation loss: 2.0762826204299927

Epoch: 6| Step: 1
Training loss: 0.43766361474990845
Validation loss: 2.113256851832072

Epoch: 6| Step: 2
Training loss: 0.436176598072052
Validation loss: 2.1209827860196433

Epoch: 6| Step: 3
Training loss: 0.5510926246643066
Validation loss: 2.0907169580459595

Epoch: 6| Step: 4
Training loss: 0.66664719581604
Validation loss: 2.133306384086609

Epoch: 6| Step: 5
Training loss: 0.36817437410354614
Validation loss: 2.138672192891439

Epoch: 6| Step: 6
Training loss: 0.462338387966156
Validation loss: 2.1498173673947654

Epoch: 6| Step: 7
Training loss: 0.2884312570095062
Validation loss: 2.137275218963623

Epoch: 6| Step: 8
Training loss: 0.3761708736419678
Validation loss: 2.147969742616018

Epoch: 6| Step: 9
Training loss: 0.30181849002838135
Validation loss: 2.127258618672689

Epoch: 6| Step: 10
Training loss: 0.6387967467308044
Validation loss: 2.1252765456835427

Epoch: 6| Step: 11
Training loss: 0.8607136011123657
Validation loss: 2.0726691484451294

Epoch: 6| Step: 12
Training loss: 0.5538280606269836
Validation loss: 2.125655213991801

Epoch: 6| Step: 13
Training loss: 0.39499783515930176
Validation loss: 2.1089141170183816

Epoch: 356| Step: 0
Training loss: 1.0383868217468262
Validation loss: 2.116681675116221

Epoch: 6| Step: 1
Training loss: 0.24865634739398956
Validation loss: 2.160562833150228

Epoch: 6| Step: 2
Training loss: 0.48364073038101196
Validation loss: 2.1657247145970664

Epoch: 6| Step: 3
Training loss: 0.3146374821662903
Validation loss: 2.1707223057746887

Epoch: 6| Step: 4
Training loss: 0.7108016014099121
Validation loss: 2.1851815780003867

Epoch: 6| Step: 5
Training loss: 0.39166542887687683
Validation loss: 2.159362236658732

Epoch: 6| Step: 6
Training loss: 0.3869820237159729
Validation loss: 2.19065527121226

Epoch: 6| Step: 7
Training loss: 0.5426448583602905
Validation loss: 2.148150364557902

Epoch: 6| Step: 8
Training loss: 0.513422966003418
Validation loss: 2.1643510262171426

Epoch: 6| Step: 9
Training loss: 0.581560492515564
Validation loss: 2.0966970523198447

Epoch: 6| Step: 10
Training loss: 0.5822833776473999
Validation loss: 2.1411258975664773

Epoch: 6| Step: 11
Training loss: 0.36590415239334106
Validation loss: 2.068669617176056

Epoch: 6| Step: 12
Training loss: 0.3691408038139343
Validation loss: 2.140607237815857

Epoch: 6| Step: 13
Training loss: 0.3468719720840454
Validation loss: 2.111612558364868

Epoch: 357| Step: 0
Training loss: 0.5360175371170044
Validation loss: 2.1089529593785605

Epoch: 6| Step: 1
Training loss: 0.2856968343257904
Validation loss: 2.108686645825704

Epoch: 6| Step: 2
Training loss: 0.5026384592056274
Validation loss: 2.1040393114089966

Epoch: 6| Step: 3
Training loss: 0.6844224333763123
Validation loss: 2.1363914807637534

Epoch: 6| Step: 4
Training loss: 0.49666255712509155
Validation loss: 2.1518765489260354

Epoch: 6| Step: 5
Training loss: 0.8876676559448242
Validation loss: 2.1549073259035745

Epoch: 6| Step: 6
Training loss: 0.16575749218463898
Validation loss: 2.157579163710276

Epoch: 6| Step: 7
Training loss: 0.226541668176651
Validation loss: 2.1007840434710183

Epoch: 6| Step: 8
Training loss: 0.5835815668106079
Validation loss: 2.1106537580490112

Epoch: 6| Step: 9
Training loss: 0.55865877866745
Validation loss: 2.119225720564524

Epoch: 6| Step: 10
Training loss: 0.5335588455200195
Validation loss: 2.1040467421213784

Epoch: 6| Step: 11
Training loss: 0.4248185157775879
Validation loss: 2.0886525313059487

Epoch: 6| Step: 12
Training loss: 0.4699016809463501
Validation loss: 2.0268872380256653

Epoch: 6| Step: 13
Training loss: 0.4482947587966919
Validation loss: 2.0951926708221436

Epoch: 358| Step: 0
Training loss: 0.8118181228637695
Validation loss: 2.091840088367462

Epoch: 6| Step: 1
Training loss: 0.35278332233428955
Validation loss: 2.171018679936727

Epoch: 6| Step: 2
Training loss: 0.6200872659683228
Validation loss: 2.1164917747179666

Epoch: 6| Step: 3
Training loss: 0.5341185927391052
Validation loss: 2.1315155227979026

Epoch: 6| Step: 4
Training loss: 0.5008237361907959
Validation loss: 2.135291337966919

Epoch: 6| Step: 5
Training loss: 0.1947464942932129
Validation loss: 2.052092671394348

Epoch: 6| Step: 6
Training loss: 0.2167135775089264
Validation loss: 2.0826005339622498

Epoch: 6| Step: 7
Training loss: 0.4203453063964844
Validation loss: 2.094561994075775

Epoch: 6| Step: 8
Training loss: 0.3350921869277954
Validation loss: 2.072580615679423

Epoch: 6| Step: 9
Training loss: 0.3433229327201843
Validation loss: 2.0888405442237854

Epoch: 6| Step: 10
Training loss: 0.30225804448127747
Validation loss: 2.0696366826693215

Epoch: 6| Step: 11
Training loss: 0.408413827419281
Validation loss: 2.073643207550049

Epoch: 6| Step: 12
Training loss: 0.6942178606987
Validation loss: 2.1003406047821045

Epoch: 6| Step: 13
Training loss: 0.7466387748718262
Validation loss: 2.1076294581095376

Epoch: 359| Step: 0
Training loss: 0.4965358078479767
Validation loss: 2.204829772313436

Epoch: 6| Step: 1
Training loss: 0.8531345129013062
Validation loss: 2.144510885079702

Epoch: 6| Step: 2
Training loss: 0.7563849687576294
Validation loss: 2.18876185019811

Epoch: 6| Step: 3
Training loss: 0.41168761253356934
Validation loss: 2.102860748767853

Epoch: 6| Step: 4
Training loss: 0.5934562683105469
Validation loss: 2.0567210714022317

Epoch: 6| Step: 5
Training loss: 0.4737519323825836
Validation loss: 2.1018422842025757

Epoch: 6| Step: 6
Training loss: 0.43344640731811523
Validation loss: 2.142807443936666

Epoch: 6| Step: 7
Training loss: 0.5751765966415405
Validation loss: 2.119491974512736

Epoch: 6| Step: 8
Training loss: 0.38179296255111694
Validation loss: 2.0658214688301086

Epoch: 6| Step: 9
Training loss: 0.4764404296875
Validation loss: 2.100091358025869

Epoch: 6| Step: 10
Training loss: 0.2660808563232422
Validation loss: 2.083335896333059

Epoch: 6| Step: 11
Training loss: 0.4945969581604004
Validation loss: 2.1186358531316123

Epoch: 6| Step: 12
Training loss: 0.44744405150413513
Validation loss: 2.1811341047286987

Epoch: 6| Step: 13
Training loss: 0.5719957947731018
Validation loss: 2.1967024405797324

Epoch: 360| Step: 0
Training loss: 0.5968884825706482
Validation loss: 2.2331667939821878

Epoch: 6| Step: 1
Training loss: 0.762942373752594
Validation loss: 2.1634186506271362

Epoch: 6| Step: 2
Training loss: 0.41391342878341675
Validation loss: 2.184329390525818

Epoch: 6| Step: 3
Training loss: 0.294708788394928
Validation loss: 2.1280245383580527

Epoch: 6| Step: 4
Training loss: 0.3039250373840332
Validation loss: 2.0893964966138205

Epoch: 6| Step: 5
Training loss: 1.1012067794799805
Validation loss: 2.1185407042503357

Epoch: 6| Step: 6
Training loss: 0.4786708950996399
Validation loss: 2.120577315489451

Epoch: 6| Step: 7
Training loss: 0.35608482360839844
Validation loss: 2.097184936205546

Epoch: 6| Step: 8
Training loss: 0.42157819867134094
Validation loss: 2.1227782567342124

Epoch: 6| Step: 9
Training loss: 0.6711674928665161
Validation loss: 2.084678669770559

Epoch: 6| Step: 10
Training loss: 0.3203302025794983
Validation loss: 2.1326913038889566

Epoch: 6| Step: 11
Training loss: 0.5151516199111938
Validation loss: 2.1698710521062217

Epoch: 6| Step: 12
Training loss: 0.46058106422424316
Validation loss: 2.150851786136627

Epoch: 6| Step: 13
Training loss: 0.4239031672477722
Validation loss: 2.1152519981066384

Epoch: 361| Step: 0
Training loss: 0.3443338871002197
Validation loss: 2.1869092186292014

Epoch: 6| Step: 1
Training loss: 0.3146359622478485
Validation loss: 2.070813755194346

Epoch: 6| Step: 2
Training loss: 0.649324893951416
Validation loss: 2.1094292203585305

Epoch: 6| Step: 3
Training loss: 0.4413849115371704
Validation loss: 2.082213501135508

Epoch: 6| Step: 4
Training loss: 0.32395267486572266
Validation loss: 2.122346878051758

Epoch: 6| Step: 5
Training loss: 0.6352242231369019
Validation loss: 2.115401486555735

Epoch: 6| Step: 6
Training loss: 0.6292956471443176
Validation loss: 2.1279937028884888

Epoch: 6| Step: 7
Training loss: 0.6917707324028015
Validation loss: 2.144795835018158

Epoch: 6| Step: 8
Training loss: 0.39317840337753296
Validation loss: 2.0919390122095742

Epoch: 6| Step: 9
Training loss: 0.5322921276092529
Validation loss: 2.1415724754333496

Epoch: 6| Step: 10
Training loss: 0.4709264934062958
Validation loss: 2.103034496307373

Epoch: 6| Step: 11
Training loss: 0.43791526556015015
Validation loss: 2.0736846725145974

Epoch: 6| Step: 12
Training loss: 0.3835272789001465
Validation loss: 2.116749664147695

Epoch: 6| Step: 13
Training loss: 0.24315118789672852
Validation loss: 2.1435906688372293

Epoch: 362| Step: 0
Training loss: 0.29520383477211
Validation loss: 2.0834208925565085

Epoch: 6| Step: 1
Training loss: 0.3697356879711151
Validation loss: 2.105859855810801

Epoch: 6| Step: 2
Training loss: 0.613323450088501
Validation loss: 2.0827792088190713

Epoch: 6| Step: 3
Training loss: 0.7134407758712769
Validation loss: 2.1461557944615683

Epoch: 6| Step: 4
Training loss: 0.3782646059989929
Validation loss: 2.098466237386068

Epoch: 6| Step: 5
Training loss: 0.3958270847797394
Validation loss: 2.110510766506195

Epoch: 6| Step: 6
Training loss: 0.5219075679779053
Validation loss: 2.0718103845914206

Epoch: 6| Step: 7
Training loss: 0.3091002106666565
Validation loss: 2.112089912096659

Epoch: 6| Step: 8
Training loss: 0.4096301794052124
Validation loss: 2.0813065568606057

Epoch: 6| Step: 9
Training loss: 0.4413972496986389
Validation loss: 2.1348250110944114

Epoch: 6| Step: 10
Training loss: 0.2977282404899597
Validation loss: 2.127666393915812

Epoch: 6| Step: 11
Training loss: 0.7940594553947449
Validation loss: 2.1566611528396606

Epoch: 6| Step: 12
Training loss: 0.3261643648147583
Validation loss: 2.109263062477112

Epoch: 6| Step: 13
Training loss: 0.6643476486206055
Validation loss: 2.1129642923672995

Epoch: 363| Step: 0
Training loss: 0.4175781309604645
Validation loss: 2.106322387854258

Epoch: 6| Step: 1
Training loss: 0.2927023768424988
Validation loss: 2.0801305174827576

Epoch: 6| Step: 2
Training loss: 0.28576046228408813
Validation loss: 2.0823686718940735

Epoch: 6| Step: 3
Training loss: 0.6703100800514221
Validation loss: 2.1181910832722983

Epoch: 6| Step: 4
Training loss: 0.39444077014923096
Validation loss: 2.12624184290568

Epoch: 6| Step: 5
Training loss: 0.6769514083862305
Validation loss: 2.097654481728872

Epoch: 6| Step: 6
Training loss: 0.40931639075279236
Validation loss: 2.1175440152486167

Epoch: 6| Step: 7
Training loss: 0.23344391584396362
Validation loss: 2.1025130351384482

Epoch: 6| Step: 8
Training loss: 0.20627062022686005
Validation loss: 2.101348320643107

Epoch: 6| Step: 9
Training loss: 0.47182220220565796
Validation loss: 2.057417412598928

Epoch: 6| Step: 10
Training loss: 0.48203974962234497
Validation loss: 2.0552470286687217

Epoch: 6| Step: 11
Training loss: 0.26874545216560364
Validation loss: 2.059551159540812

Epoch: 6| Step: 12
Training loss: 0.6983987092971802
Validation loss: 2.0669168829917908

Epoch: 6| Step: 13
Training loss: 0.5255552530288696
Validation loss: 2.0784614086151123

Epoch: 364| Step: 0
Training loss: 0.1984679102897644
Validation loss: 2.105847398440043

Epoch: 6| Step: 1
Training loss: 0.4143841862678528
Validation loss: 2.112092693646749

Epoch: 6| Step: 2
Training loss: 1.02446448802948
Validation loss: 2.0796536008516946

Epoch: 6| Step: 3
Training loss: 0.46687373518943787
Validation loss: 2.1092307567596436

Epoch: 6| Step: 4
Training loss: 0.46921467781066895
Validation loss: 2.1087923645973206

Epoch: 6| Step: 5
Training loss: 0.4509086012840271
Validation loss: 2.0933468540509543

Epoch: 6| Step: 6
Training loss: 0.28307563066482544
Validation loss: 2.0996034145355225

Epoch: 6| Step: 7
Training loss: 0.3399679660797119
Validation loss: 2.1403154134750366

Epoch: 6| Step: 8
Training loss: 0.4609842002391815
Validation loss: 2.1141092777252197

Epoch: 6| Step: 9
Training loss: 0.46376240253448486
Validation loss: 2.089012106259664

Epoch: 6| Step: 10
Training loss: 0.4502158463001251
Validation loss: 2.0829158425331116

Epoch: 6| Step: 11
Training loss: 0.38983309268951416
Validation loss: 2.1200243631998696

Epoch: 6| Step: 12
Training loss: 0.44954913854599
Validation loss: 2.1277197202046714

Epoch: 6| Step: 13
Training loss: 0.34300023317337036
Validation loss: 2.107457002003988

Epoch: 365| Step: 0
Training loss: 0.3044538199901581
Validation loss: 2.1202425559361777

Epoch: 6| Step: 1
Training loss: 0.4778755009174347
Validation loss: 2.1239810784657798

Epoch: 6| Step: 2
Training loss: 0.6892995834350586
Validation loss: 2.129418969154358

Epoch: 6| Step: 3
Training loss: 0.5409536957740784
Validation loss: 2.118456482887268

Epoch: 6| Step: 4
Training loss: 0.33995869755744934
Validation loss: 2.093218723932902

Epoch: 6| Step: 5
Training loss: 0.2687356472015381
Validation loss: 2.0995113452275596

Epoch: 6| Step: 6
Training loss: 0.6762228012084961
Validation loss: 2.08882604042689

Epoch: 6| Step: 7
Training loss: 0.19609196484088898
Validation loss: 2.1033645470937095

Epoch: 6| Step: 8
Training loss: 0.4271574914455414
Validation loss: 2.052399675051371

Epoch: 6| Step: 9
Training loss: 0.39811187982559204
Validation loss: 2.0722453395525613

Epoch: 6| Step: 10
Training loss: 0.2875877320766449
Validation loss: 2.1223113934199014

Epoch: 6| Step: 11
Training loss: 0.4849352538585663
Validation loss: 2.1062015096346536

Epoch: 6| Step: 12
Training loss: 0.297715425491333
Validation loss: 2.1215616861979165

Epoch: 6| Step: 13
Training loss: 0.9243828058242798
Validation loss: 2.116563618183136

Epoch: 366| Step: 0
Training loss: 0.30909428000450134
Validation loss: 2.1523088812828064

Epoch: 6| Step: 1
Training loss: 0.469460666179657
Validation loss: 2.1509889165560403

Epoch: 6| Step: 2
Training loss: 0.29741421341896057
Validation loss: 2.105816125869751

Epoch: 6| Step: 3
Training loss: 0.5144950747489929
Validation loss: 2.1218137741088867

Epoch: 6| Step: 4
Training loss: 0.6125764846801758
Validation loss: 2.122020343939463

Epoch: 6| Step: 5
Training loss: 0.6763853430747986
Validation loss: 2.0621918042500815

Epoch: 6| Step: 6
Training loss: 0.31224438548088074
Validation loss: 2.138675073782603

Epoch: 6| Step: 7
Training loss: 0.30565786361694336
Validation loss: 2.1417288780212402

Epoch: 6| Step: 8
Training loss: 0.5004881024360657
Validation loss: 2.142774820327759

Epoch: 6| Step: 9
Training loss: 0.2953157424926758
Validation loss: 2.156633814175924

Epoch: 6| Step: 10
Training loss: 0.6899363994598389
Validation loss: 2.2145739595095315

Epoch: 6| Step: 11
Training loss: 0.6178747415542603
Validation loss: 2.201066474119822

Epoch: 6| Step: 12
Training loss: 0.3430992364883423
Validation loss: 2.1803502440452576

Epoch: 6| Step: 13
Training loss: 0.7065836787223816
Validation loss: 2.1184555093447366

Epoch: 367| Step: 0
Training loss: 0.7347702980041504
Validation loss: 2.130951782067617

Epoch: 6| Step: 1
Training loss: 0.5078473091125488
Validation loss: 2.0953689018885293

Epoch: 6| Step: 2
Training loss: 0.3467048704624176
Validation loss: 2.1533343394597373

Epoch: 6| Step: 3
Training loss: 0.6630008220672607
Validation loss: 2.074414312839508

Epoch: 6| Step: 4
Training loss: 0.5841168165206909
Validation loss: 2.143177052338918

Epoch: 6| Step: 5
Training loss: 0.370877206325531
Validation loss: 2.1733704209327698

Epoch: 6| Step: 6
Training loss: 0.3182443380355835
Validation loss: 2.1796260873476663

Epoch: 6| Step: 7
Training loss: 0.1985449641942978
Validation loss: 2.1278797388076782

Epoch: 6| Step: 8
Training loss: 0.8254379034042358
Validation loss: 2.1434404651323953

Epoch: 6| Step: 9
Training loss: 0.5731070041656494
Validation loss: 2.1285489201545715

Epoch: 6| Step: 10
Training loss: 0.2798653841018677
Validation loss: 2.1272602876027427

Epoch: 6| Step: 11
Training loss: 0.3014476001262665
Validation loss: 2.0714563131332397

Epoch: 6| Step: 12
Training loss: 0.7023718357086182
Validation loss: 2.1353244185447693

Epoch: 6| Step: 13
Training loss: 0.6533774137496948
Validation loss: 2.1122984886169434

Epoch: 368| Step: 0
Training loss: 0.39787375926971436
Validation loss: 2.0827059149742126

Epoch: 6| Step: 1
Training loss: 0.28929245471954346
Validation loss: 2.117029070854187

Epoch: 6| Step: 2
Training loss: 0.6953775882720947
Validation loss: 2.128305733203888

Epoch: 6| Step: 3
Training loss: 0.5640518069267273
Validation loss: 2.135674794514974

Epoch: 6| Step: 4
Training loss: 0.6267939805984497
Validation loss: 2.1484784483909607

Epoch: 6| Step: 5
Training loss: 0.277804970741272
Validation loss: 2.151947021484375

Epoch: 6| Step: 6
Training loss: 0.3429039716720581
Validation loss: 2.1597184538841248

Epoch: 6| Step: 7
Training loss: 0.5883841514587402
Validation loss: 2.15029106537501

Epoch: 6| Step: 8
Training loss: 0.4114503264427185
Validation loss: 2.1256788969039917

Epoch: 6| Step: 9
Training loss: 0.25608307123184204
Validation loss: 2.108142852783203

Epoch: 6| Step: 10
Training loss: 0.3154306709766388
Validation loss: 2.114921053250631

Epoch: 6| Step: 11
Training loss: 0.41653767228126526
Validation loss: 2.0749356746673584

Epoch: 6| Step: 12
Training loss: 0.6592078804969788
Validation loss: 2.1236143906911216

Epoch: 6| Step: 13
Training loss: 0.29639121890068054
Validation loss: 2.091060479482015

Epoch: 369| Step: 0
Training loss: 0.5415550470352173
Validation loss: 2.1448660691579184

Epoch: 6| Step: 1
Training loss: 0.4414631426334381
Validation loss: 2.1573219497998557

Epoch: 6| Step: 2
Training loss: 0.5728054642677307
Validation loss: 2.0989476442337036

Epoch: 6| Step: 3
Training loss: 0.9334530234336853
Validation loss: 2.127111872037252

Epoch: 6| Step: 4
Training loss: 0.3731817305088043
Validation loss: 2.1311251322428384

Epoch: 6| Step: 5
Training loss: 0.369784951210022
Validation loss: 2.1411299308141074

Epoch: 6| Step: 6
Training loss: 0.41471606492996216
Validation loss: 2.117014686266581

Epoch: 6| Step: 7
Training loss: 0.26764434576034546
Validation loss: 2.112059454123179

Epoch: 6| Step: 8
Training loss: 0.38006746768951416
Validation loss: 2.1311644514401755

Epoch: 6| Step: 9
Training loss: 0.37361323833465576
Validation loss: 2.132824937502543

Epoch: 6| Step: 10
Training loss: 0.23418739438056946
Validation loss: 2.106727639834086

Epoch: 6| Step: 11
Training loss: 0.4638030230998993
Validation loss: 2.073543389638265

Epoch: 6| Step: 12
Training loss: 0.35318654775619507
Validation loss: 2.0953926046689353

Epoch: 6| Step: 13
Training loss: 0.2698201537132263
Validation loss: 2.1192252039909363

Epoch: 370| Step: 0
Training loss: 0.48807239532470703
Validation loss: 2.140799641609192

Epoch: 6| Step: 1
Training loss: 0.2876729965209961
Validation loss: 2.083501160144806

Epoch: 6| Step: 2
Training loss: 0.32029783725738525
Validation loss: 2.1194756031036377

Epoch: 6| Step: 3
Training loss: 0.2932838201522827
Validation loss: 2.1378160317738852

Epoch: 6| Step: 4
Training loss: 0.4820234775543213
Validation loss: 2.14650426308314

Epoch: 6| Step: 5
Training loss: 0.3479490578174591
Validation loss: 2.1098376512527466

Epoch: 6| Step: 6
Training loss: 0.34513700008392334
Validation loss: 2.0785582860310874

Epoch: 6| Step: 7
Training loss: 0.5815452933311462
Validation loss: 2.143375873565674

Epoch: 6| Step: 8
Training loss: 0.48981884121894836
Validation loss: 2.143184781074524

Epoch: 6| Step: 9
Training loss: 0.595687210559845
Validation loss: 2.1373639702796936

Epoch: 6| Step: 10
Training loss: 0.4162443280220032
Validation loss: 2.1380590995152793

Epoch: 6| Step: 11
Training loss: 0.31520718336105347
Validation loss: 2.1645159125328064

Epoch: 6| Step: 12
Training loss: 0.8428335785865784
Validation loss: 2.1513359745343528

Epoch: 6| Step: 13
Training loss: 0.6198036670684814
Validation loss: 2.164954344431559

Epoch: 371| Step: 0
Training loss: 0.5162540078163147
Validation loss: 2.113719860712687

Epoch: 6| Step: 1
Training loss: 0.4880209267139435
Validation loss: 2.120526075363159

Epoch: 6| Step: 2
Training loss: 0.2409535050392151
Validation loss: 2.1682567397753396

Epoch: 6| Step: 3
Training loss: 0.4088461399078369
Validation loss: 2.150599996248881

Epoch: 6| Step: 4
Training loss: 0.37840551137924194
Validation loss: 2.158944010734558

Epoch: 6| Step: 5
Training loss: 0.2550020217895508
Validation loss: 2.115965982278188

Epoch: 6| Step: 6
Training loss: 0.6586500406265259
Validation loss: 2.127066195011139

Epoch: 6| Step: 7
Training loss: 0.37365543842315674
Validation loss: 2.1342546741167703

Epoch: 6| Step: 8
Training loss: 0.42872947454452515
Validation loss: 2.1484076380729675

Epoch: 6| Step: 9
Training loss: 0.49450719356536865
Validation loss: 2.135386308034261

Epoch: 6| Step: 10
Training loss: 0.6016391515731812
Validation loss: 2.1164361238479614

Epoch: 6| Step: 11
Training loss: 0.31003910303115845
Validation loss: 2.1118444403012595

Epoch: 6| Step: 12
Training loss: 0.35996872186660767
Validation loss: 2.101357022921244

Epoch: 6| Step: 13
Training loss: 0.8695005178451538
Validation loss: 2.1430493791898093

Epoch: 372| Step: 0
Training loss: 0.7441861629486084
Validation loss: 2.1193871895472207

Epoch: 6| Step: 1
Training loss: 0.4128110408782959
Validation loss: 2.1717857917149863

Epoch: 6| Step: 2
Training loss: 0.549414873123169
Validation loss: 2.1923542817433677

Epoch: 6| Step: 3
Training loss: 0.34825143218040466
Validation loss: 2.1609524488449097

Epoch: 6| Step: 4
Training loss: 0.5759290456771851
Validation loss: 2.1549672285715737

Epoch: 6| Step: 5
Training loss: 0.35094064474105835
Validation loss: 2.120259463787079

Epoch: 6| Step: 6
Training loss: 0.3517094850540161
Validation loss: 2.125042955080668

Epoch: 6| Step: 7
Training loss: 0.7319618463516235
Validation loss: 2.1309789220492044

Epoch: 6| Step: 8
Training loss: 0.6951150298118591
Validation loss: 2.1257807413736978

Epoch: 6| Step: 9
Training loss: 0.4032871127128601
Validation loss: 2.118207653363546

Epoch: 6| Step: 10
Training loss: 0.7463394403457642
Validation loss: 2.1364536682764688

Epoch: 6| Step: 11
Training loss: 0.27778610587120056
Validation loss: 2.1638845801353455

Epoch: 6| Step: 12
Training loss: 0.3229188621044159
Validation loss: 2.1453569531440735

Epoch: 6| Step: 13
Training loss: 0.3675491213798523
Validation loss: 2.2179946104685464

Epoch: 373| Step: 0
Training loss: 0.42274773120880127
Validation loss: 2.154850880304972

Epoch: 6| Step: 1
Training loss: 0.5984684228897095
Validation loss: 2.1949620842933655

Epoch: 6| Step: 2
Training loss: 0.3889220952987671
Validation loss: 2.13571568330129

Epoch: 6| Step: 3
Training loss: 0.18934008479118347
Validation loss: 2.1575066447257996

Epoch: 6| Step: 4
Training loss: 0.55704665184021
Validation loss: 2.1327080130577087

Epoch: 6| Step: 5
Training loss: 0.5977574586868286
Validation loss: 2.1209279696146646

Epoch: 6| Step: 6
Training loss: 0.579468846321106
Validation loss: 2.1494366923967996

Epoch: 6| Step: 7
Training loss: 0.4412727653980255
Validation loss: 2.1266621947288513

Epoch: 6| Step: 8
Training loss: 0.3331303298473358
Validation loss: 2.0596633752187095

Epoch: 6| Step: 9
Training loss: 0.30620405077934265
Validation loss: 2.118462065855662

Epoch: 6| Step: 10
Training loss: 0.30707138776779175
Validation loss: 2.1057722568511963

Epoch: 6| Step: 11
Training loss: 0.43136364221572876
Validation loss: 2.182807445526123

Epoch: 6| Step: 12
Training loss: 0.298582524061203
Validation loss: 2.172686199347178

Epoch: 6| Step: 13
Training loss: 0.8542220592498779
Validation loss: 2.168821930885315

Epoch: 374| Step: 0
Training loss: 0.30098822712898254
Validation loss: 2.195226271947225

Epoch: 6| Step: 1
Training loss: 0.532370388507843
Validation loss: 2.231280287106832

Epoch: 6| Step: 2
Training loss: 0.7095872163772583
Validation loss: 2.1766397356987

Epoch: 6| Step: 3
Training loss: 0.6510300636291504
Validation loss: 2.1392488876978555

Epoch: 6| Step: 4
Training loss: 0.4110485911369324
Validation loss: 2.112305680910746

Epoch: 6| Step: 5
Training loss: 0.37132877111434937
Validation loss: 2.1574150721232095

Epoch: 6| Step: 6
Training loss: 0.6337828636169434
Validation loss: 2.1169779300689697

Epoch: 6| Step: 7
Training loss: 0.24697034060955048
Validation loss: 2.0918838580449424

Epoch: 6| Step: 8
Training loss: 0.34917712211608887
Validation loss: 2.113775134086609

Epoch: 6| Step: 9
Training loss: 0.4647335410118103
Validation loss: 2.1275480588277182

Epoch: 6| Step: 10
Training loss: 0.2303650975227356
Validation loss: 2.135536233584086

Epoch: 6| Step: 11
Training loss: 0.38113492727279663
Validation loss: 2.1230653524398804

Epoch: 6| Step: 12
Training loss: 0.582483172416687
Validation loss: 2.0709895888964334

Epoch: 6| Step: 13
Training loss: 0.4034006595611572
Validation loss: 2.1211288571357727

Epoch: 375| Step: 0
Training loss: 0.6775364875793457
Validation loss: 2.0851850310961404

Epoch: 6| Step: 1
Training loss: 0.32283902168273926
Validation loss: 2.0997893810272217

Epoch: 6| Step: 2
Training loss: 0.3347506821155548
Validation loss: 2.1310897866884866

Epoch: 6| Step: 3
Training loss: 0.433575838804245
Validation loss: 2.085395008325577

Epoch: 6| Step: 4
Training loss: 0.36045902967453003
Validation loss: 2.0949811736742654

Epoch: 6| Step: 5
Training loss: 0.34850168228149414
Validation loss: 2.101559817790985

Epoch: 6| Step: 6
Training loss: 0.5812656283378601
Validation loss: 2.1200814247131348

Epoch: 6| Step: 7
Training loss: 0.5844968557357788
Validation loss: 2.135295271873474

Epoch: 6| Step: 8
Training loss: 0.7088499069213867
Validation loss: 2.1170289715131125

Epoch: 6| Step: 9
Training loss: 0.6771538257598877
Validation loss: 2.138191024462382

Epoch: 6| Step: 10
Training loss: 0.28138935565948486
Validation loss: 2.0780133406321206

Epoch: 6| Step: 11
Training loss: 0.29629725217819214
Validation loss: 2.0876338481903076

Epoch: 6| Step: 12
Training loss: 0.29547715187072754
Validation loss: 2.1664705673853555

Epoch: 6| Step: 13
Training loss: 0.4325597882270813
Validation loss: 2.078555146853129

Epoch: 376| Step: 0
Training loss: 0.14849482476711273
Validation loss: 2.1029271284739175

Epoch: 6| Step: 1
Training loss: 0.8010804057121277
Validation loss: 2.104179879029592

Epoch: 6| Step: 2
Training loss: 0.46118366718292236
Validation loss: 2.0617034435272217

Epoch: 6| Step: 3
Training loss: 0.3128213882446289
Validation loss: 2.120941778024038

Epoch: 6| Step: 4
Training loss: 0.557969331741333
Validation loss: 2.092155317465464

Epoch: 6| Step: 5
Training loss: 0.5235669612884521
Validation loss: 2.1201144059499106

Epoch: 6| Step: 6
Training loss: 0.5166611671447754
Validation loss: 2.153560221195221

Epoch: 6| Step: 7
Training loss: 0.7213679552078247
Validation loss: 2.13220222791036

Epoch: 6| Step: 8
Training loss: 0.15777742862701416
Validation loss: 2.1535743474960327

Epoch: 6| Step: 9
Training loss: 0.42446863651275635
Validation loss: 2.123412609100342

Epoch: 6| Step: 10
Training loss: 0.34450921416282654
Validation loss: 2.1408591866493225

Epoch: 6| Step: 11
Training loss: 0.3222445845603943
Validation loss: 2.1475247939427695

Epoch: 6| Step: 12
Training loss: 0.64769047498703
Validation loss: 2.163813610871633

Epoch: 6| Step: 13
Training loss: 0.2559772729873657
Validation loss: 2.176134626070658

Epoch: 377| Step: 0
Training loss: 0.38690391182899475
Validation loss: 2.1153988440831504

Epoch: 6| Step: 1
Training loss: 0.2979004383087158
Validation loss: 2.1207148234049478

Epoch: 6| Step: 2
Training loss: 0.3494958281517029
Validation loss: 2.1185378233591714

Epoch: 6| Step: 3
Training loss: 0.34375905990600586
Validation loss: 2.1250937382380166

Epoch: 6| Step: 4
Training loss: 0.2640470266342163
Validation loss: 2.099230686823527

Epoch: 6| Step: 5
Training loss: 0.6225142478942871
Validation loss: 2.1683707237243652

Epoch: 6| Step: 6
Training loss: 0.49011749029159546
Validation loss: 2.127782185872396

Epoch: 6| Step: 7
Training loss: 0.6626793146133423
Validation loss: 2.1238672335942588

Epoch: 6| Step: 8
Training loss: 0.3343158960342407
Validation loss: 2.1126049757003784

Epoch: 6| Step: 9
Training loss: 0.49520739912986755
Validation loss: 2.0954257249832153

Epoch: 6| Step: 10
Training loss: 0.2300877869129181
Validation loss: 2.1099963386853537

Epoch: 6| Step: 11
Training loss: 0.45379865169525146
Validation loss: 2.0748572746912637

Epoch: 6| Step: 12
Training loss: 0.43806034326553345
Validation loss: 2.1024205485979715

Epoch: 6| Step: 13
Training loss: 0.5758147239685059
Validation loss: 2.137996256351471

Epoch: 378| Step: 0
Training loss: 0.9451897144317627
Validation loss: 2.1164381901423135

Epoch: 6| Step: 1
Training loss: 0.22679133713245392
Validation loss: 2.1048646370569863

Epoch: 6| Step: 2
Training loss: 0.44214922189712524
Validation loss: 2.146399895350138

Epoch: 6| Step: 3
Training loss: 0.7237867116928101
Validation loss: 2.1033479372660318

Epoch: 6| Step: 4
Training loss: 0.5848870873451233
Validation loss: 2.084039270877838

Epoch: 6| Step: 5
Training loss: 0.3784901797771454
Validation loss: 2.15038792292277

Epoch: 6| Step: 6
Training loss: 0.4649423658847809
Validation loss: 2.1010276079177856

Epoch: 6| Step: 7
Training loss: 0.24713285267353058
Validation loss: 2.110052525997162

Epoch: 6| Step: 8
Training loss: 0.4252696633338928
Validation loss: 2.0552252332369485

Epoch: 6| Step: 9
Training loss: 0.3366505205631256
Validation loss: 2.1315439144770303

Epoch: 6| Step: 10
Training loss: 0.32641083002090454
Validation loss: 2.1514925956726074

Epoch: 6| Step: 11
Training loss: 0.5534636378288269
Validation loss: 2.1022558212280273

Epoch: 6| Step: 12
Training loss: 0.5397157669067383
Validation loss: 2.1701691150665283

Epoch: 6| Step: 13
Training loss: 0.36217281222343445
Validation loss: 2.2093239625295005

Epoch: 379| Step: 0
Training loss: 0.29904884099960327
Validation loss: 2.161246657371521

Epoch: 6| Step: 1
Training loss: 0.2922514081001282
Validation loss: 2.1754195292790732

Epoch: 6| Step: 2
Training loss: 0.43180784583091736
Validation loss: 2.1697561740875244

Epoch: 6| Step: 3
Training loss: 0.7611085176467896
Validation loss: 2.1338862975438437

Epoch: 6| Step: 4
Training loss: 0.47628259658813477
Validation loss: 2.134324590365092

Epoch: 6| Step: 5
Training loss: 0.5338895320892334
Validation loss: 2.129875361919403

Epoch: 6| Step: 6
Training loss: 0.49165046215057373
Validation loss: 2.157745838165283

Epoch: 6| Step: 7
Training loss: 0.796087920665741
Validation loss: 2.1755292614301047

Epoch: 6| Step: 8
Training loss: 0.3532025218009949
Validation loss: 2.136547247568766

Epoch: 6| Step: 9
Training loss: 0.40579837560653687
Validation loss: 2.179811100165049

Epoch: 6| Step: 10
Training loss: 0.8671395182609558
Validation loss: 2.175862729549408

Epoch: 6| Step: 11
Training loss: 0.3719671666622162
Validation loss: 2.1926618615786233

Epoch: 6| Step: 12
Training loss: 0.3800815939903259
Validation loss: 2.169496536254883

Epoch: 6| Step: 13
Training loss: 0.4575239419937134
Validation loss: 2.20158984263738

Epoch: 380| Step: 0
Training loss: 0.3575321137905121
Validation loss: 2.217903792858124

Epoch: 6| Step: 1
Training loss: 0.5455479025840759
Validation loss: 2.188055078188578

Epoch: 6| Step: 2
Training loss: 0.253357857465744
Validation loss: 2.09754745165507

Epoch: 6| Step: 3
Training loss: 0.3046542704105377
Validation loss: 2.1407184998194375

Epoch: 6| Step: 4
Training loss: 0.5061659216880798
Validation loss: 2.1160409847895303

Epoch: 6| Step: 5
Training loss: 0.6007975339889526
Validation loss: 2.0959319273630777

Epoch: 6| Step: 6
Training loss: 0.2507980763912201
Validation loss: 2.134191652139028

Epoch: 6| Step: 7
Training loss: 0.4955712556838989
Validation loss: 2.1733690102895102

Epoch: 6| Step: 8
Training loss: 0.6021613478660583
Validation loss: 2.209661384423574

Epoch: 6| Step: 9
Training loss: 0.6502428650856018
Validation loss: 2.1660773952802024

Epoch: 6| Step: 10
Training loss: 0.30529817938804626
Validation loss: 2.1490031480789185

Epoch: 6| Step: 11
Training loss: 0.8652046918869019
Validation loss: 2.1171651681264243

Epoch: 6| Step: 12
Training loss: 0.2940899431705475
Validation loss: 2.0925915241241455

Epoch: 6| Step: 13
Training loss: 0.6564618349075317
Validation loss: 2.0714073379834494

Epoch: 381| Step: 0
Training loss: 0.7458510398864746
Validation loss: 2.118993103504181

Epoch: 6| Step: 1
Training loss: 0.2022268921136856
Validation loss: 2.1148199836413064

Epoch: 6| Step: 2
Training loss: 0.3829951584339142
Validation loss: 2.1330073475837708

Epoch: 6| Step: 3
Training loss: 0.8131083250045776
Validation loss: 2.1045631766319275

Epoch: 6| Step: 4
Training loss: 0.2319210320711136
Validation loss: 2.0967259605725608

Epoch: 6| Step: 5
Training loss: 0.4606081247329712
Validation loss: 2.102517565091451

Epoch: 6| Step: 6
Training loss: 0.23587675392627716
Validation loss: 2.1078240275382996

Epoch: 6| Step: 7
Training loss: 0.4675779342651367
Validation loss: 2.136985262235006

Epoch: 6| Step: 8
Training loss: 0.24085482954978943
Validation loss: 2.1338336865107217

Epoch: 6| Step: 9
Training loss: 0.2337285578250885
Validation loss: 2.137454569339752

Epoch: 6| Step: 10
Training loss: 0.3025391101837158
Validation loss: 2.104838411013285

Epoch: 6| Step: 11
Training loss: 0.7924537658691406
Validation loss: 2.1488391160964966

Epoch: 6| Step: 12
Training loss: 0.2766689360141754
Validation loss: 2.10562656323115

Epoch: 6| Step: 13
Training loss: 0.358249306678772
Validation loss: 2.115070343017578

Epoch: 382| Step: 0
Training loss: 0.39255809783935547
Validation loss: 2.1627268195152283

Epoch: 6| Step: 1
Training loss: 0.34231844544410706
Validation loss: 2.109866122404734

Epoch: 6| Step: 2
Training loss: 0.4409017264842987
Validation loss: 2.085683544476827

Epoch: 6| Step: 3
Training loss: 0.4480055272579193
Validation loss: 2.1090185840924582

Epoch: 6| Step: 4
Training loss: 0.523642897605896
Validation loss: 2.1177021066347756

Epoch: 6| Step: 5
Training loss: 0.49615585803985596
Validation loss: 2.092202146848043

Epoch: 6| Step: 6
Training loss: 0.2259538769721985
Validation loss: 2.1573235591252646

Epoch: 6| Step: 7
Training loss: 0.29580801725387573
Validation loss: 2.116546154022217

Epoch: 6| Step: 8
Training loss: 0.378182977437973
Validation loss: 2.1144113540649414

Epoch: 6| Step: 9
Training loss: 0.31446322798728943
Validation loss: 2.139166792233785

Epoch: 6| Step: 10
Training loss: 0.6156247854232788
Validation loss: 2.1552390257517495

Epoch: 6| Step: 11
Training loss: 0.3525492250919342
Validation loss: 2.14726714293162

Epoch: 6| Step: 12
Training loss: 0.5950683355331421
Validation loss: 2.110543409983317

Epoch: 6| Step: 13
Training loss: 0.3364688456058502
Validation loss: 2.1327746709187827

Epoch: 383| Step: 0
Training loss: 0.6734600067138672
Validation loss: 2.1158809264500937

Epoch: 6| Step: 1
Training loss: 0.5464080572128296
Validation loss: 2.170826514561971

Epoch: 6| Step: 2
Training loss: 0.2670046091079712
Validation loss: 2.103421906630198

Epoch: 6| Step: 3
Training loss: 0.263725608587265
Validation loss: 2.1440388361612954

Epoch: 6| Step: 4
Training loss: 0.28636401891708374
Validation loss: 2.1685978174209595

Epoch: 6| Step: 5
Training loss: 0.7034368515014648
Validation loss: 2.146961987018585

Epoch: 6| Step: 6
Training loss: 0.5943742990493774
Validation loss: 2.126327713330587

Epoch: 6| Step: 7
Training loss: 0.4284322261810303
Validation loss: 2.15830526749293

Epoch: 6| Step: 8
Training loss: 0.4031585454940796
Validation loss: 2.140599310398102

Epoch: 6| Step: 9
Training loss: 0.19193387031555176
Validation loss: 2.1363523801167807

Epoch: 6| Step: 10
Training loss: 0.18039149045944214
Validation loss: 2.137323002020518

Epoch: 6| Step: 11
Training loss: 0.592922568321228
Validation loss: 2.14834197362264

Epoch: 6| Step: 12
Training loss: 0.3948427736759186
Validation loss: 2.129559874534607

Epoch: 6| Step: 13
Training loss: 0.3487008810043335
Validation loss: 2.1305887500445047

Epoch: 384| Step: 0
Training loss: 0.4229249954223633
Validation loss: 2.110821863015493

Epoch: 6| Step: 1
Training loss: 0.31689560413360596
Validation loss: 2.1267775495847068

Epoch: 6| Step: 2
Training loss: 0.421914279460907
Validation loss: 2.1259527603785195

Epoch: 6| Step: 3
Training loss: 0.2646051049232483
Validation loss: 2.1661846041679382

Epoch: 6| Step: 4
Training loss: 0.5182269811630249
Validation loss: 2.1826100945472717

Epoch: 6| Step: 5
Training loss: 0.4658707082271576
Validation loss: 2.1703039407730103

Epoch: 6| Step: 6
Training loss: 0.5164295434951782
Validation loss: 2.1941086451212564

Epoch: 6| Step: 7
Training loss: 0.4539180397987366
Validation loss: 2.1959845622380576

Epoch: 6| Step: 8
Training loss: 0.3173842132091522
Validation loss: 2.1744349002838135

Epoch: 6| Step: 9
Training loss: 0.460995078086853
Validation loss: 2.1467755834261575

Epoch: 6| Step: 10
Training loss: 0.2946476638317108
Validation loss: 2.140110711256663

Epoch: 6| Step: 11
Training loss: 0.5103810429573059
Validation loss: 2.0982796351114907

Epoch: 6| Step: 12
Training loss: 0.6326262950897217
Validation loss: 2.143410841623942

Epoch: 6| Step: 13
Training loss: 0.7737010717391968
Validation loss: 2.148184061050415

Epoch: 385| Step: 0
Training loss: 0.4496154189109802
Validation loss: 2.159031629562378

Epoch: 6| Step: 1
Training loss: 0.4181953966617584
Validation loss: 2.1489311257998147

Epoch: 6| Step: 2
Training loss: 0.2693456709384918
Validation loss: 2.1851077874501548

Epoch: 6| Step: 3
Training loss: 0.48166969418525696
Validation loss: 2.1300172209739685

Epoch: 6| Step: 4
Training loss: 0.17559483647346497
Validation loss: 2.129253387451172

Epoch: 6| Step: 5
Training loss: 0.16843634843826294
Validation loss: 2.164570411046346

Epoch: 6| Step: 6
Training loss: 0.7017358541488647
Validation loss: 2.1457874377568564

Epoch: 6| Step: 7
Training loss: 1.0152767896652222
Validation loss: 2.194109042485555

Epoch: 6| Step: 8
Training loss: 0.3784674108028412
Validation loss: 2.1421355406443277

Epoch: 6| Step: 9
Training loss: 0.19667646288871765
Validation loss: 2.1504403154055276

Epoch: 6| Step: 10
Training loss: 0.3972322940826416
Validation loss: 2.158833603064219

Epoch: 6| Step: 11
Training loss: 0.201649010181427
Validation loss: 2.106778542200724

Epoch: 6| Step: 12
Training loss: 0.45751816034317017
Validation loss: 2.110212504863739

Epoch: 6| Step: 13
Training loss: 0.3784848749637604
Validation loss: 2.1268035968144736

Epoch: 386| Step: 0
Training loss: 0.2576289772987366
Validation loss: 2.1266881227493286

Epoch: 6| Step: 1
Training loss: 0.2261774092912674
Validation loss: 2.1328524549802146

Epoch: 6| Step: 2
Training loss: 0.5263627171516418
Validation loss: 2.129840314388275

Epoch: 6| Step: 3
Training loss: 0.21307988464832306
Validation loss: 2.1396223306655884

Epoch: 6| Step: 4
Training loss: 0.33179569244384766
Validation loss: 2.153544843196869

Epoch: 6| Step: 5
Training loss: 0.26884201169013977
Validation loss: 2.1565756797790527

Epoch: 6| Step: 6
Training loss: 0.3919025659561157
Validation loss: 2.1384244163831077

Epoch: 6| Step: 7
Training loss: 0.3182087540626526
Validation loss: 2.1089443961779275

Epoch: 6| Step: 8
Training loss: 0.46104270219802856
Validation loss: 2.187424977620443

Epoch: 6| Step: 9
Training loss: 0.5388059616088867
Validation loss: 2.0806125005086265

Epoch: 6| Step: 10
Training loss: 0.592353880405426
Validation loss: 2.14214297135671

Epoch: 6| Step: 11
Training loss: 0.2898825705051422
Validation loss: 2.1298522551854453

Epoch: 6| Step: 12
Training loss: 0.6485941410064697
Validation loss: 2.15779185295105

Epoch: 6| Step: 13
Training loss: 0.7793059945106506
Validation loss: 2.1478461225827536

Epoch: 387| Step: 0
Training loss: 0.24116650223731995
Validation loss: 2.14545746644338

Epoch: 6| Step: 1
Training loss: 0.24650683999061584
Validation loss: 2.1443742712338767

Epoch: 6| Step: 2
Training loss: 0.24964888393878937
Validation loss: 2.0714468558629355

Epoch: 6| Step: 3
Training loss: 0.4992499351501465
Validation loss: 2.106583217779795

Epoch: 6| Step: 4
Training loss: 0.5022569894790649
Validation loss: 2.1126514275868735

Epoch: 6| Step: 5
Training loss: 0.7224044799804688
Validation loss: 2.1335137089093528

Epoch: 6| Step: 6
Training loss: 0.6759949922561646
Validation loss: 2.0955419540405273

Epoch: 6| Step: 7
Training loss: 0.2265852689743042
Validation loss: 2.1347185174624124

Epoch: 6| Step: 8
Training loss: 0.3710176944732666
Validation loss: 2.1043659448623657

Epoch: 6| Step: 9
Training loss: 0.536541759967804
Validation loss: 2.1575852235158286

Epoch: 6| Step: 10
Training loss: 0.5645202398300171
Validation loss: 2.1482624610265098

Epoch: 6| Step: 11
Training loss: 0.3328196704387665
Validation loss: 2.139927347501119

Epoch: 6| Step: 12
Training loss: 0.20114943385124207
Validation loss: 2.0801237424214682

Epoch: 6| Step: 13
Training loss: 0.33708909153938293
Validation loss: 2.1344478527704873

Epoch: 388| Step: 0
Training loss: 0.3605653643608093
Validation loss: 2.1203970909118652

Epoch: 6| Step: 1
Training loss: 0.2754823565483093
Validation loss: 2.0762463410695395

Epoch: 6| Step: 2
Training loss: 0.40800559520721436
Validation loss: 2.1456361015637717

Epoch: 6| Step: 3
Training loss: 0.4791889190673828
Validation loss: 2.0848529736200967

Epoch: 6| Step: 4
Training loss: 0.30702728033065796
Validation loss: 2.1197271148363748

Epoch: 6| Step: 5
Training loss: 0.4190303087234497
Validation loss: 2.147712687651316

Epoch: 6| Step: 6
Training loss: 0.4403519630432129
Validation loss: 2.1025350093841553

Epoch: 6| Step: 7
Training loss: 0.4694173336029053
Validation loss: 2.116731862227122

Epoch: 6| Step: 8
Training loss: 0.3794538974761963
Validation loss: 2.143258889516195

Epoch: 6| Step: 9
Training loss: 0.9761149883270264
Validation loss: 2.1511351068814597

Epoch: 6| Step: 10
Training loss: 0.372126966714859
Validation loss: 2.1238547364870706

Epoch: 6| Step: 11
Training loss: 0.229074627161026
Validation loss: 2.13152281443278

Epoch: 6| Step: 12
Training loss: 0.3752220869064331
Validation loss: 2.10015861193339

Epoch: 6| Step: 13
Training loss: 0.23954862356185913
Validation loss: 2.1445514957110086

Epoch: 389| Step: 0
Training loss: 0.2615642845630646
Validation loss: 2.1236621737480164

Epoch: 6| Step: 1
Training loss: 0.6062378883361816
Validation loss: 2.148370405038198

Epoch: 6| Step: 2
Training loss: 0.21411827206611633
Validation loss: 2.1335814793904624

Epoch: 6| Step: 3
Training loss: 0.8848885893821716
Validation loss: 2.087352454662323

Epoch: 6| Step: 4
Training loss: 0.2825736105442047
Validation loss: 2.1140394806861877

Epoch: 6| Step: 5
Training loss: 0.25735679268836975
Validation loss: 2.0917381048202515

Epoch: 6| Step: 6
Training loss: 0.40250569581985474
Validation loss: 2.124174396197001

Epoch: 6| Step: 7
Training loss: 0.23897422850131989
Validation loss: 2.135275443394979

Epoch: 6| Step: 8
Training loss: 0.37702468037605286
Validation loss: 2.09272708495458

Epoch: 6| Step: 9
Training loss: 0.4137688875198364
Validation loss: 2.132633070151011

Epoch: 6| Step: 10
Training loss: 0.2861989736557007
Validation loss: 2.094506045182546

Epoch: 6| Step: 11
Training loss: 0.6119472980499268
Validation loss: 2.08272647857666

Epoch: 6| Step: 12
Training loss: 0.8080536127090454
Validation loss: 2.1388519207636514

Epoch: 6| Step: 13
Training loss: 0.4918450713157654
Validation loss: 2.11114635070165

Epoch: 390| Step: 0
Training loss: 0.5434877872467041
Validation loss: 2.0807433327039084

Epoch: 6| Step: 1
Training loss: 0.31117719411849976
Validation loss: 2.1062519749005637

Epoch: 6| Step: 2
Training loss: 0.3358924388885498
Validation loss: 2.09962260723114

Epoch: 6| Step: 3
Training loss: 0.704298734664917
Validation loss: 2.1488905946413674

Epoch: 6| Step: 4
Training loss: 0.22349977493286133
Validation loss: 2.0994495352109275

Epoch: 6| Step: 5
Training loss: 0.2918696105480194
Validation loss: 2.1232974926630654

Epoch: 6| Step: 6
Training loss: 0.24273133277893066
Validation loss: 2.131048937638601

Epoch: 6| Step: 7
Training loss: 0.6112030744552612
Validation loss: 2.1314131816228232

Epoch: 6| Step: 8
Training loss: 0.3991273045539856
Validation loss: 2.1271339058876038

Epoch: 6| Step: 9
Training loss: 0.3376692235469818
Validation loss: 2.099284052848816

Epoch: 6| Step: 10
Training loss: 0.910895824432373
Validation loss: 2.122362951437632

Epoch: 6| Step: 11
Training loss: 0.3776930570602417
Validation loss: 2.0813719034194946

Epoch: 6| Step: 12
Training loss: 0.45783308148384094
Validation loss: 2.093466798464457

Epoch: 6| Step: 13
Training loss: 0.29241281747817993
Validation loss: 2.1422335108121238

Epoch: 391| Step: 0
Training loss: 0.4261583685874939
Validation loss: 2.1268178621927896

Epoch: 6| Step: 1
Training loss: 0.5435105562210083
Validation loss: 2.1451257268587747

Epoch: 6| Step: 2
Training loss: 0.3100309669971466
Validation loss: 2.1362435022989907

Epoch: 6| Step: 3
Training loss: 0.4858348071575165
Validation loss: 2.132659653822581

Epoch: 6| Step: 4
Training loss: 0.5035096406936646
Validation loss: 2.1424673199653625

Epoch: 6| Step: 5
Training loss: 0.17921584844589233
Validation loss: 2.149603625138601

Epoch: 6| Step: 6
Training loss: 0.6627242565155029
Validation loss: 2.1394757827123008

Epoch: 6| Step: 7
Training loss: 0.24672499299049377
Validation loss: 2.1315895915031433

Epoch: 6| Step: 8
Training loss: 0.43004071712493896
Validation loss: 2.1485630869865417

Epoch: 6| Step: 9
Training loss: 0.5093111991882324
Validation loss: 2.122671922047933

Epoch: 6| Step: 10
Training loss: 0.9205856919288635
Validation loss: 2.1070101062456765

Epoch: 6| Step: 11
Training loss: 0.3308444619178772
Validation loss: 2.1497132380803428

Epoch: 6| Step: 12
Training loss: 0.30060696601867676
Validation loss: 2.139756182829539

Epoch: 6| Step: 13
Training loss: 0.3809967637062073
Validation loss: 2.100892345110575

Epoch: 392| Step: 0
Training loss: 0.4247792065143585
Validation loss: 2.075856884320577

Epoch: 6| Step: 1
Training loss: 0.2715355157852173
Validation loss: 2.1229379971822104

Epoch: 6| Step: 2
Training loss: 0.5504035353660583
Validation loss: 2.1509260733922324

Epoch: 6| Step: 3
Training loss: 0.3089315891265869
Validation loss: 2.163394113381704

Epoch: 6| Step: 4
Training loss: 0.3699129521846771
Validation loss: 2.1583741108576455

Epoch: 6| Step: 5
Training loss: 0.4948600232601166
Validation loss: 2.120941718419393

Epoch: 6| Step: 6
Training loss: 0.9177380800247192
Validation loss: 2.171743472417196

Epoch: 6| Step: 7
Training loss: 0.3716532588005066
Validation loss: 2.1146584947903952

Epoch: 6| Step: 8
Training loss: 0.6202219724655151
Validation loss: 2.1240949630737305

Epoch: 6| Step: 9
Training loss: 0.21446767449378967
Validation loss: 2.099694470564524

Epoch: 6| Step: 10
Training loss: 0.3047408163547516
Validation loss: 2.096695303916931

Epoch: 6| Step: 11
Training loss: 0.33092179894447327
Validation loss: 2.130548894405365

Epoch: 6| Step: 12
Training loss: 0.49105310440063477
Validation loss: 2.0926835338274636

Epoch: 6| Step: 13
Training loss: 0.3670780658721924
Validation loss: 2.0989588697751365

Epoch: 393| Step: 0
Training loss: 0.2961893081665039
Validation loss: 2.1054627497990928

Epoch: 6| Step: 1
Training loss: 0.6522827744483948
Validation loss: 2.077829341093699

Epoch: 6| Step: 2
Training loss: 0.550302267074585
Validation loss: 2.090788205464681

Epoch: 6| Step: 3
Training loss: 0.42827463150024414
Validation loss: 2.1120773553848267

Epoch: 6| Step: 4
Training loss: 0.3194078803062439
Validation loss: 2.1040422717730203

Epoch: 6| Step: 5
Training loss: 0.2369040548801422
Validation loss: 2.101338783899943

Epoch: 6| Step: 6
Training loss: 0.39080485701560974
Validation loss: 2.1385920445124307

Epoch: 6| Step: 7
Training loss: 0.4094143509864807
Validation loss: 2.155465225378672

Epoch: 6| Step: 8
Training loss: 0.4226493835449219
Validation loss: 2.188455899556478

Epoch: 6| Step: 9
Training loss: 0.43345460295677185
Validation loss: 2.1590457955996194

Epoch: 6| Step: 10
Training loss: 0.3457656502723694
Validation loss: 2.152688523133596

Epoch: 6| Step: 11
Training loss: 0.45049387216567993
Validation loss: 2.1184691389401755

Epoch: 6| Step: 12
Training loss: 0.19784513115882874
Validation loss: 2.161333441734314

Epoch: 6| Step: 13
Training loss: 0.5227216482162476
Validation loss: 2.113667686780294

Epoch: 394| Step: 0
Training loss: 0.274007648229599
Validation loss: 2.1154223680496216

Epoch: 6| Step: 1
Training loss: 0.4309123754501343
Validation loss: 2.1645365158716836

Epoch: 6| Step: 2
Training loss: 0.47307080030441284
Validation loss: 2.142151335875193

Epoch: 6| Step: 3
Training loss: 0.3330438733100891
Validation loss: 2.131618877251943

Epoch: 6| Step: 4
Training loss: 0.3015937805175781
Validation loss: 2.1357490022977195

Epoch: 6| Step: 5
Training loss: 0.4111884832382202
Validation loss: 2.1272963484128318

Epoch: 6| Step: 6
Training loss: 0.6256119012832642
Validation loss: 2.128447949886322

Epoch: 6| Step: 7
Training loss: 0.5322079658508301
Validation loss: 2.156421144803365

Epoch: 6| Step: 8
Training loss: 0.2801322340965271
Validation loss: 2.192598025004069

Epoch: 6| Step: 9
Training loss: 0.41530925035476685
Validation loss: 2.0946114460627236

Epoch: 6| Step: 10
Training loss: 0.5621366500854492
Validation loss: 2.167391280333201

Epoch: 6| Step: 11
Training loss: 0.30347132682800293
Validation loss: 2.1227690974871316

Epoch: 6| Step: 12
Training loss: 0.4281280040740967
Validation loss: 2.1282145579655967

Epoch: 6| Step: 13
Training loss: 0.21094301342964172
Validation loss: 2.126260459423065

Epoch: 395| Step: 0
Training loss: 0.4380064308643341
Validation loss: 2.1471234560012817

Epoch: 6| Step: 1
Training loss: 0.8212381601333618
Validation loss: 2.1197460492451987

Epoch: 6| Step: 2
Training loss: 0.403293251991272
Validation loss: 2.156050145626068

Epoch: 6| Step: 3
Training loss: 0.3244532346725464
Validation loss: 2.148245890935262

Epoch: 6| Step: 4
Training loss: 0.3375997543334961
Validation loss: 2.130766272544861

Epoch: 6| Step: 5
Training loss: 0.33901816606521606
Validation loss: 2.150303602218628

Epoch: 6| Step: 6
Training loss: 0.21471893787384033
Validation loss: 2.1478540698687234

Epoch: 6| Step: 7
Training loss: 0.44134634733200073
Validation loss: 2.1493112643559775

Epoch: 6| Step: 8
Training loss: 0.23857389390468597
Validation loss: 2.140212893486023

Epoch: 6| Step: 9
Training loss: 0.4570397138595581
Validation loss: 2.096977472305298

Epoch: 6| Step: 10
Training loss: 0.38433653116226196
Validation loss: 2.137008627255758

Epoch: 6| Step: 11
Training loss: 0.3174760937690735
Validation loss: 2.1396167278289795

Epoch: 6| Step: 12
Training loss: 0.4204464256763458
Validation loss: 2.1377052466074624

Epoch: 6| Step: 13
Training loss: 0.3503875732421875
Validation loss: 2.1114487846692405

Epoch: 396| Step: 0
Training loss: 0.2707577347755432
Validation loss: 2.1172585487365723

Epoch: 6| Step: 1
Training loss: 0.4701475501060486
Validation loss: 2.119431734085083

Epoch: 6| Step: 2
Training loss: 0.45009416341781616
Validation loss: 2.1372124552726746

Epoch: 6| Step: 3
Training loss: 0.38839513063430786
Validation loss: 2.125247140725454

Epoch: 6| Step: 4
Training loss: 0.28817424178123474
Validation loss: 2.1517765720685325

Epoch: 6| Step: 5
Training loss: 0.7997592687606812
Validation loss: 2.1564135352770486

Epoch: 6| Step: 6
Training loss: 0.45239317417144775
Validation loss: 2.1353466510772705

Epoch: 6| Step: 7
Training loss: 0.28313425183296204
Validation loss: 2.1742760141690574

Epoch: 6| Step: 8
Training loss: 0.3745409846305847
Validation loss: 2.156433622042338

Epoch: 6| Step: 9
Training loss: 0.3686448931694031
Validation loss: 2.176837682723999

Epoch: 6| Step: 10
Training loss: 0.36680471897125244
Validation loss: 2.1120193004608154

Epoch: 6| Step: 11
Training loss: 0.624058723449707
Validation loss: 2.1266513069470725

Epoch: 6| Step: 12
Training loss: 0.2763141989707947
Validation loss: 2.0824346939722695

Epoch: 6| Step: 13
Training loss: 0.33805543184280396
Validation loss: 2.111676255861918

Epoch: 397| Step: 0
Training loss: 0.22580957412719727
Validation loss: 2.1495463848114014

Epoch: 6| Step: 1
Training loss: 0.27097779512405396
Validation loss: 2.130894144376119

Epoch: 6| Step: 2
Training loss: 0.2748590111732483
Validation loss: 2.0881159702936807

Epoch: 6| Step: 3
Training loss: 0.3814316689968109
Validation loss: 2.100524882475535

Epoch: 6| Step: 4
Training loss: 0.4966832101345062
Validation loss: 2.1636677583058677

Epoch: 6| Step: 5
Training loss: 0.5641570091247559
Validation loss: 2.1215553283691406

Epoch: 6| Step: 6
Training loss: 0.3694121539592743
Validation loss: 2.1569204727808633

Epoch: 6| Step: 7
Training loss: 0.29320406913757324
Validation loss: 2.103798568248749

Epoch: 6| Step: 8
Training loss: 0.3574044108390808
Validation loss: 2.1527233123779297

Epoch: 6| Step: 9
Training loss: 0.6244816780090332
Validation loss: 2.084713617960612

Epoch: 6| Step: 10
Training loss: 0.5661615133285522
Validation loss: 2.1197938521703086

Epoch: 6| Step: 11
Training loss: 0.20019856095314026
Validation loss: 2.107708772023519

Epoch: 6| Step: 12
Training loss: 0.33950942754745483
Validation loss: 2.12274440129598

Epoch: 6| Step: 13
Training loss: 0.6032082438468933
Validation loss: 2.14536581436793

Epoch: 398| Step: 0
Training loss: 0.4622341990470886
Validation loss: 2.124641239643097

Epoch: 6| Step: 1
Training loss: 0.2173328697681427
Validation loss: 2.1172173023223877

Epoch: 6| Step: 2
Training loss: 0.34644997119903564
Validation loss: 2.104524870713552

Epoch: 6| Step: 3
Training loss: 0.3190050721168518
Validation loss: 2.150640527407328

Epoch: 6| Step: 4
Training loss: 0.3302335739135742
Validation loss: 2.154386301835378

Epoch: 6| Step: 5
Training loss: 0.4815847873687744
Validation loss: 2.1268786589304605

Epoch: 6| Step: 6
Training loss: 0.8128098249435425
Validation loss: 2.158538579940796

Epoch: 6| Step: 7
Training loss: 0.4179050922393799
Validation loss: 2.1420645316441855

Epoch: 6| Step: 8
Training loss: 0.20493584871292114
Validation loss: 2.155160129070282

Epoch: 6| Step: 9
Training loss: 0.5221025943756104
Validation loss: 2.1529664595921836

Epoch: 6| Step: 10
Training loss: 0.252582848072052
Validation loss: 2.140053470929464

Epoch: 6| Step: 11
Training loss: 0.6141758561134338
Validation loss: 2.1460342009862265

Epoch: 6| Step: 12
Training loss: 0.6134071946144104
Validation loss: 2.1684181491533914

Epoch: 6| Step: 13
Training loss: 0.19413992762565613
Validation loss: 2.0936516722043357

Epoch: 399| Step: 0
Training loss: 0.285833477973938
Validation loss: 2.157900253931681

Epoch: 6| Step: 1
Training loss: 0.2930670380592346
Validation loss: 2.0898561477661133

Epoch: 6| Step: 2
Training loss: 0.23772089183330536
Validation loss: 2.154950280984243

Epoch: 6| Step: 3
Training loss: 0.4886922538280487
Validation loss: 2.1082972288131714

Epoch: 6| Step: 4
Training loss: 0.6146872639656067
Validation loss: 2.176866968472799

Epoch: 6| Step: 5
Training loss: 0.3062949776649475
Validation loss: 2.1838903427124023

Epoch: 6| Step: 6
Training loss: 0.5834823846817017
Validation loss: 2.1166249910990396

Epoch: 6| Step: 7
Training loss: 0.3580166697502136
Validation loss: 2.1400602658589682

Epoch: 6| Step: 8
Training loss: 0.3665974736213684
Validation loss: 2.1066406965255737

Epoch: 6| Step: 9
Training loss: 0.5504094362258911
Validation loss: 2.1336251298586526

Epoch: 6| Step: 10
Training loss: 0.40929561853408813
Validation loss: 2.1083103020985923

Epoch: 6| Step: 11
Training loss: 0.43416348099708557
Validation loss: 2.088636060555776

Epoch: 6| Step: 12
Training loss: 0.21496422588825226
Validation loss: 2.1122712890307107

Epoch: 6| Step: 13
Training loss: 0.16289576888084412
Validation loss: 2.1567688584327698

Epoch: 400| Step: 0
Training loss: 0.4462745487689972
Validation loss: 2.153754711151123

Epoch: 6| Step: 1
Training loss: 0.2658756375312805
Validation loss: 2.1237599849700928

Epoch: 6| Step: 2
Training loss: 0.5123333930969238
Validation loss: 2.1635916034380593

Epoch: 6| Step: 3
Training loss: 0.47607851028442383
Validation loss: 2.1281513969103494

Epoch: 6| Step: 4
Training loss: 0.2535385191440582
Validation loss: 2.1118433276812234

Epoch: 6| Step: 5
Training loss: 0.46641451120376587
Validation loss: 2.1517781416575112

Epoch: 6| Step: 6
Training loss: 0.347598135471344
Validation loss: 2.119805713494619

Epoch: 6| Step: 7
Training loss: 0.3132651150226593
Validation loss: 2.1028494834899902

Epoch: 6| Step: 8
Training loss: 0.2968364357948303
Validation loss: 2.1117761532465615

Epoch: 6| Step: 9
Training loss: 0.2592373788356781
Validation loss: 2.1034130454063416

Epoch: 6| Step: 10
Training loss: 0.4159933626651764
Validation loss: 2.1470863620440164

Epoch: 6| Step: 11
Training loss: 0.7504389882087708
Validation loss: 2.1292635798454285

Epoch: 6| Step: 12
Training loss: 0.47051623463630676
Validation loss: 2.1396676898002625

Epoch: 6| Step: 13
Training loss: 0.1871798038482666
Validation loss: 2.15207447608312

Testing loss: 2.0606439842594613
