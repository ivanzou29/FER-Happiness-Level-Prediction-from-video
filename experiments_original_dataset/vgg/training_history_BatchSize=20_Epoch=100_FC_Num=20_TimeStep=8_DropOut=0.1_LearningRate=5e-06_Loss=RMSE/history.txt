Epoch: 1| Step: 0
Training loss: 5.288008479205329
Validation loss: 5.9660107383490715

Epoch: 5| Step: 1
Training loss: 6.465910209903111
Validation loss: 5.949689125573607

Epoch: 5| Step: 2
Training loss: 5.764105040800932
Validation loss: 5.932266505464062

Epoch: 5| Step: 3
Training loss: 5.0835718609655345
Validation loss: 5.913137003192224

Epoch: 5| Step: 4
Training loss: 5.866520057638081
Validation loss: 5.896783673513035

Epoch: 5| Step: 5
Training loss: 6.625106234868315
Validation loss: 5.878829066719336

Epoch: 5| Step: 6
Training loss: 6.3752369556146204
Validation loss: 5.860654245391557

Epoch: 5| Step: 7
Training loss: 6.351676010863011
Validation loss: 5.850891733537784

Epoch: 5| Step: 8
Training loss: 5.16556092191947
Validation loss: 5.830939464743559

Epoch: 5| Step: 9
Training loss: 6.419287835666716
Validation loss: 5.815279244912004

Epoch: 5| Step: 10
Training loss: 6.020188381758121
Validation loss: 5.80081924100652

Epoch: 5| Step: 11
Training loss: 6.847193300273375
Validation loss: 5.783610767485636

Epoch: 2| Step: 0
Training loss: 5.641011486391391
Validation loss: 5.766604146544986

Epoch: 5| Step: 1
Training loss: 4.656051119454934
Validation loss: 5.751700149957467

Epoch: 5| Step: 2
Training loss: 6.479188320046045
Validation loss: 5.73123045307516

Epoch: 5| Step: 3
Training loss: 5.431064700004481
Validation loss: 5.713921584437236

Epoch: 5| Step: 4
Training loss: 5.92575485636014
Validation loss: 5.695664438991379

Epoch: 5| Step: 5
Training loss: 5.742529950991733
Validation loss: 5.675733705668487

Epoch: 5| Step: 6
Training loss: 5.86876493701923
Validation loss: 5.659730195375949

Epoch: 5| Step: 7
Training loss: 5.857674232330557
Validation loss: 5.635746142991323

Epoch: 5| Step: 8
Training loss: 5.6216390105373115
Validation loss: 5.61423261557951

Epoch: 5| Step: 9
Training loss: 5.588381274061589
Validation loss: 5.588884585460845

Epoch: 5| Step: 10
Training loss: 6.810967229194982
Validation loss: 5.564963663124802

Epoch: 5| Step: 11
Training loss: 3.29436581842847
Validation loss: 5.5414060397515374

Epoch: 3| Step: 0
Training loss: 5.7554686704645714
Validation loss: 5.518403092998277

Epoch: 5| Step: 1
Training loss: 5.651377565681891
Validation loss: 5.491753978450015

Epoch: 5| Step: 2
Training loss: 5.479531434346392
Validation loss: 5.463903804834758

Epoch: 5| Step: 3
Training loss: 4.135784962330449
Validation loss: 5.432831568844946

Epoch: 5| Step: 4
Training loss: 5.992910965636067
Validation loss: 5.404390570248039

Epoch: 5| Step: 5
Training loss: 5.152520327835667
Validation loss: 5.374304090590238

Epoch: 5| Step: 6
Training loss: 5.9672875335291575
Validation loss: 5.340390002335473

Epoch: 5| Step: 7
Training loss: 6.00053498744054
Validation loss: 5.304855486345306

Epoch: 5| Step: 8
Training loss: 5.377317948995109
Validation loss: 5.271236859079743

Epoch: 5| Step: 9
Training loss: 4.930139777811554
Validation loss: 5.225183758401878

Epoch: 5| Step: 10
Training loss: 5.566371470560207
Validation loss: 5.18864852569564

Epoch: 5| Step: 11
Training loss: 3.933433976475268
Validation loss: 5.1507751529610655

Epoch: 4| Step: 0
Training loss: 5.1462488457134326
Validation loss: 5.104176496638998

Epoch: 5| Step: 1
Training loss: 5.407587139610914
Validation loss: 5.062974405234425

Epoch: 5| Step: 2
Training loss: 6.279624614794612
Validation loss: 5.003458567358099

Epoch: 5| Step: 3
Training loss: 5.3605752829805455
Validation loss: 4.958715995746989

Epoch: 5| Step: 4
Training loss: 5.559519279885005
Validation loss: 4.914065645557523

Epoch: 5| Step: 5
Training loss: 5.1478806514347255
Validation loss: 4.847804728899946

Epoch: 5| Step: 6
Training loss: 4.307176925932932
Validation loss: 4.7924089630798585

Epoch: 5| Step: 7
Training loss: 4.282348937283637
Validation loss: 4.7238257016955645

Epoch: 5| Step: 8
Training loss: 4.209729985800125
Validation loss: 4.673708433687552

Epoch: 5| Step: 9
Training loss: 3.875671697666517
Validation loss: 4.596822865681287

Epoch: 5| Step: 10
Training loss: 4.23464953669231
Validation loss: 4.527818138759175

Epoch: 5| Step: 11
Training loss: 4.0617778429655
Validation loss: 4.463808025779513

Epoch: 5| Step: 0
Training loss: 4.5511410550491735
Validation loss: 4.382718897254614

Epoch: 5| Step: 1
Training loss: 4.280120032222738
Validation loss: 4.292173900381345

Epoch: 5| Step: 2
Training loss: 4.216699850884135
Validation loss: 4.226212962440625

Epoch: 5| Step: 3
Training loss: 4.175693093521038
Validation loss: 4.135063793715831

Epoch: 5| Step: 4
Training loss: 3.5333509018899085
Validation loss: 4.0589577123408525

Epoch: 5| Step: 5
Training loss: 4.213102049777093
Validation loss: 3.953033466309711

Epoch: 5| Step: 6
Training loss: 3.857126669874991
Validation loss: 3.882725835558325

Epoch: 5| Step: 7
Training loss: 3.839232356312183
Validation loss: 3.782898829768547

Epoch: 5| Step: 8
Training loss: 3.505167280224086
Validation loss: 3.7014790779053914

Epoch: 5| Step: 9
Training loss: 3.4410143833718956
Validation loss: 3.582517473728809

Epoch: 5| Step: 10
Training loss: 3.7403739723867324
Validation loss: 3.4882339126889237

Epoch: 5| Step: 11
Training loss: 4.0228372959477205
Validation loss: 3.3694410107259576

Epoch: 6| Step: 0
Training loss: 3.1748198570750326
Validation loss: 3.2731756198133275

Epoch: 5| Step: 1
Training loss: 2.967469913166244
Validation loss: 3.173213237962944

Epoch: 5| Step: 2
Training loss: 2.7943003647882962
Validation loss: 3.1031878846280394

Epoch: 5| Step: 3
Training loss: 3.405673616972031
Validation loss: 3.01048866876648

Epoch: 5| Step: 4
Training loss: 2.9686157196194127
Validation loss: 2.9182528825992544

Epoch: 5| Step: 5
Training loss: 2.51641823719276
Validation loss: 2.8999546806587113

Epoch: 5| Step: 6
Training loss: 2.956268252423255
Validation loss: 2.836421869141401

Epoch: 5| Step: 7
Training loss: 2.625343936004979
Validation loss: 2.7758814256713134

Epoch: 5| Step: 8
Training loss: 2.563470982136783
Validation loss: 2.775566641344297

Epoch: 5| Step: 9
Training loss: 2.7183172824307
Validation loss: 2.794080666751536

Epoch: 5| Step: 10
Training loss: 3.0114612988818377
Validation loss: 2.7580856029521406

Epoch: 5| Step: 11
Training loss: 2.8425367513006963
Validation loss: 2.77702928525314

Epoch: 7| Step: 0
Training loss: 2.9708840179043268
Validation loss: 2.8207987879483647

Epoch: 5| Step: 1
Training loss: 2.4519104107145533
Validation loss: 2.843637736693119

Epoch: 5| Step: 2
Training loss: 2.125157294342186
Validation loss: 2.890862511852014

Epoch: 5| Step: 3
Training loss: 2.890971230056629
Validation loss: 2.900102885794417

Epoch: 5| Step: 4
Training loss: 2.9338577090801294
Validation loss: 2.9265805227767148

Epoch: 5| Step: 5
Training loss: 3.2680590743628533
Validation loss: 2.9375081501840925

Epoch: 5| Step: 6
Training loss: 2.5194546000331934
Validation loss: 2.951351921872271

Epoch: 5| Step: 7
Training loss: 2.5637022780092416
Validation loss: 2.8930635356218177

Epoch: 5| Step: 8
Training loss: 3.604610187973003
Validation loss: 2.887676295283522

Epoch: 5| Step: 9
Training loss: 2.7813509804899423
Validation loss: 2.8492040626977833

Epoch: 5| Step: 10
Training loss: 2.7649768134415935
Validation loss: 2.8785767006456755

Epoch: 5| Step: 11
Training loss: 2.8313431949729666
Validation loss: 2.868201770216383

Epoch: 8| Step: 0
Training loss: 3.0901391120879436
Validation loss: 2.8104633869409748

Epoch: 5| Step: 1
Training loss: 3.003832117959208
Validation loss: 2.75981879087488

Epoch: 5| Step: 2
Training loss: 2.3906535227950214
Validation loss: 2.7653300744112297

Epoch: 5| Step: 3
Training loss: 2.0961703075712874
Validation loss: 2.7491047839815956

Epoch: 5| Step: 4
Training loss: 2.427714537265591
Validation loss: 2.745233910321727

Epoch: 5| Step: 5
Training loss: 2.5551366382052216
Validation loss: 2.8019086837700975

Epoch: 5| Step: 6
Training loss: 2.7526760952061955
Validation loss: 2.726238410000402

Epoch: 5| Step: 7
Training loss: 2.9997332772260052
Validation loss: 2.7681233423819065

Epoch: 5| Step: 8
Training loss: 2.55804260374714
Validation loss: 2.7485472497647465

Epoch: 5| Step: 9
Training loss: 2.760160489461036
Validation loss: 2.7492955056818573

Epoch: 5| Step: 10
Training loss: 2.9600687086018045
Validation loss: 2.7395450978578304

Epoch: 5| Step: 11
Training loss: 2.852951255095789
Validation loss: 2.781406766066639

Epoch: 9| Step: 0
Training loss: 3.3117988852101363
Validation loss: 2.780287983423844

Epoch: 5| Step: 1
Training loss: 3.5962470625890908
Validation loss: 2.740761570008871

Epoch: 5| Step: 2
Training loss: 2.8387464163659746
Validation loss: 2.752451786285384

Epoch: 5| Step: 3
Training loss: 2.5900870506651303
Validation loss: 2.7461350620105174

Epoch: 5| Step: 4
Training loss: 2.2204204235115514
Validation loss: 2.7699223839848974

Epoch: 5| Step: 5
Training loss: 3.004904552600508
Validation loss: 2.7442768755445837

Epoch: 5| Step: 6
Training loss: 2.780712118535364
Validation loss: 2.7455926856740014

Epoch: 5| Step: 7
Training loss: 3.0207075070889915
Validation loss: 2.7624869386585713

Epoch: 5| Step: 8
Training loss: 2.1635401126254186
Validation loss: 2.726615948959296

Epoch: 5| Step: 9
Training loss: 1.8186261793637895
Validation loss: 2.6944988736546525

Epoch: 5| Step: 10
Training loss: 2.376545553755174
Validation loss: 2.707504209125942

Epoch: 5| Step: 11
Training loss: 1.4655980317129635
Validation loss: 2.7386312800666848

Epoch: 10| Step: 0
Training loss: 2.244263966808732
Validation loss: 2.713832591905754

Epoch: 5| Step: 1
Training loss: 2.580719538162906
Validation loss: 2.7213934547228793

Epoch: 5| Step: 2
Training loss: 2.627297712791027
Validation loss: 2.713488676514156

Epoch: 5| Step: 3
Training loss: 2.585574029462048
Validation loss: 2.759636230027056

Epoch: 5| Step: 4
Training loss: 2.5664535355530185
Validation loss: 2.729581696982416

Epoch: 5| Step: 5
Training loss: 2.9470889453752704
Validation loss: 2.7513574984894773

Epoch: 5| Step: 6
Training loss: 2.7604999361734324
Validation loss: 2.7435631050405647

Epoch: 5| Step: 7
Training loss: 2.7894566361645996
Validation loss: 2.7487366006653846

Epoch: 5| Step: 8
Training loss: 2.9529769295199135
Validation loss: 2.710711274615647

Epoch: 5| Step: 9
Training loss: 2.8421809300728937
Validation loss: 2.703493850180111

Epoch: 5| Step: 10
Training loss: 2.4517421834048374
Validation loss: 2.735221975031359

Epoch: 5| Step: 11
Training loss: 1.5806967298855046
Validation loss: 2.7397794266543047

Epoch: 11| Step: 0
Training loss: 2.5748464371899664
Validation loss: 2.7377521513437344

Epoch: 5| Step: 1
Training loss: 1.7399267059542753
Validation loss: 2.7103538837731262

Epoch: 5| Step: 2
Training loss: 3.345591813266175
Validation loss: 2.737504712047034

Epoch: 5| Step: 3
Training loss: 2.7096831748135117
Validation loss: 2.717944727498446

Epoch: 5| Step: 4
Training loss: 2.9393956986707757
Validation loss: 2.6954676578846715

Epoch: 5| Step: 5
Training loss: 2.234621154457501
Validation loss: 2.6814202062710675

Epoch: 5| Step: 6
Training loss: 3.0681556328063904
Validation loss: 2.7254498077698335

Epoch: 5| Step: 7
Training loss: 2.406233651241894
Validation loss: 2.713138818887995

Epoch: 5| Step: 8
Training loss: 2.5515918699631053
Validation loss: 2.695784062215851

Epoch: 5| Step: 9
Training loss: 3.0115688103584692
Validation loss: 2.733842866980457

Epoch: 5| Step: 10
Training loss: 2.278288185753183
Validation loss: 2.710161975815326

Epoch: 5| Step: 11
Training loss: 2.816214418690199
Validation loss: 2.7379663007846036

Epoch: 12| Step: 0
Training loss: 2.3869054443463495
Validation loss: 2.7121909191046893

Epoch: 5| Step: 1
Training loss: 2.056716439352264
Validation loss: 2.7517840999319043

Epoch: 5| Step: 2
Training loss: 2.700980245174066
Validation loss: 2.758832222479961

Epoch: 5| Step: 3
Training loss: 3.2811834419402834
Validation loss: 2.7174862083779945

Epoch: 5| Step: 4
Training loss: 2.5485717176764675
Validation loss: 2.751792810994435

Epoch: 5| Step: 5
Training loss: 3.0509452043111938
Validation loss: 2.750401890171832

Epoch: 5| Step: 6
Training loss: 3.028501857616553
Validation loss: 2.7262338514926867

Epoch: 5| Step: 7
Training loss: 2.4635321608206096
Validation loss: 2.705722123480482

Epoch: 5| Step: 8
Training loss: 2.6032696412419916
Validation loss: 2.7329461969613273

Epoch: 5| Step: 9
Training loss: 2.777690967686829
Validation loss: 2.7519937245587114

Epoch: 5| Step: 10
Training loss: 2.320715564180126
Validation loss: 2.7152553767727152

Epoch: 5| Step: 11
Training loss: 2.1126822082671737
Validation loss: 2.7086531939281397

Epoch: 13| Step: 0
Training loss: 3.408696127487867
Validation loss: 2.6880512337584572

Epoch: 5| Step: 1
Training loss: 2.541412111469666
Validation loss: 2.7432002907942423

Epoch: 5| Step: 2
Training loss: 2.6569935375073297
Validation loss: 2.7044012257945833

Epoch: 5| Step: 3
Training loss: 2.649766076757653
Validation loss: 2.698398861206241

Epoch: 5| Step: 4
Training loss: 2.2882852634383015
Validation loss: 2.7143188481411853

Epoch: 5| Step: 5
Training loss: 2.4882934186748664
Validation loss: 2.7047477180686883

Epoch: 5| Step: 6
Training loss: 2.3578700640649544
Validation loss: 2.7279317673062784

Epoch: 5| Step: 7
Training loss: 2.8219440844624333
Validation loss: 2.710487878104884

Epoch: 5| Step: 8
Training loss: 2.5018229513974726
Validation loss: 2.69532933990083

Epoch: 5| Step: 9
Training loss: 3.019877859260383
Validation loss: 2.697772045506042

Epoch: 5| Step: 10
Training loss: 2.420479649386307
Validation loss: 2.7062046684479917

Epoch: 5| Step: 11
Training loss: 3.366170707530854
Validation loss: 2.7332191930951613

Epoch: 14| Step: 0
Training loss: 2.9264490564847008
Validation loss: 2.7211677244041086

Epoch: 5| Step: 1
Training loss: 2.432486243841278
Validation loss: 2.6881079023205197

Epoch: 5| Step: 2
Training loss: 2.4592762986654204
Validation loss: 2.6859327448280763

Epoch: 5| Step: 3
Training loss: 2.7990269400665406
Validation loss: 2.72738085382509

Epoch: 5| Step: 4
Training loss: 3.0312068975471314
Validation loss: 2.7041518295206286

Epoch: 5| Step: 5
Training loss: 2.6066585266330904
Validation loss: 2.6784391284997464

Epoch: 5| Step: 6
Training loss: 2.3884420962790434
Validation loss: 2.7278428045722043

Epoch: 5| Step: 7
Training loss: 2.064406121042775
Validation loss: 2.68957521470369

Epoch: 5| Step: 8
Training loss: 3.0107828905272465
Validation loss: 2.7212923849049915

Epoch: 5| Step: 9
Training loss: 2.7734109366850714
Validation loss: 2.6812238079887316

Epoch: 5| Step: 10
Training loss: 2.4212693964664265
Validation loss: 2.7050584776310598

Epoch: 5| Step: 11
Training loss: 1.9655405557078192
Validation loss: 2.7540828278477893

Epoch: 15| Step: 0
Training loss: 2.4470011087905372
Validation loss: 2.7022992785793147

Epoch: 5| Step: 1
Training loss: 2.4408119393823435
Validation loss: 2.6888898242492556

Epoch: 5| Step: 2
Training loss: 2.3881095667292693
Validation loss: 2.7153932998605566

Epoch: 5| Step: 3
Training loss: 2.384662347880139
Validation loss: 2.706827454191593

Epoch: 5| Step: 4
Training loss: 2.425931326973651
Validation loss: 2.6867516329550845

Epoch: 5| Step: 5
Training loss: 2.649722887341185
Validation loss: 2.693003209764825

Epoch: 5| Step: 6
Training loss: 3.39097319190707
Validation loss: 2.6566527304429406

Epoch: 5| Step: 7
Training loss: 2.858487517829561
Validation loss: 2.6679081088426364

Epoch: 5| Step: 8
Training loss: 2.70526144460061
Validation loss: 2.6704515454062085

Epoch: 5| Step: 9
Training loss: 1.8580926271679419
Validation loss: 2.6974185989537793

Epoch: 5| Step: 10
Training loss: 3.1385706925002164
Validation loss: 2.694875823688781

Epoch: 5| Step: 11
Training loss: 3.0264053169992335
Validation loss: 2.673886254149891

Epoch: 16| Step: 0
Training loss: 3.0063073293568845
Validation loss: 2.686629084002003

Epoch: 5| Step: 1
Training loss: 2.829294373931053
Validation loss: 2.6794733197297553

Epoch: 5| Step: 2
Training loss: 2.042567605775588
Validation loss: 2.6956303026745823

Epoch: 5| Step: 3
Training loss: 2.5972573339726104
Validation loss: 2.6462627097527207

Epoch: 5| Step: 4
Training loss: 3.1927730850366083
Validation loss: 2.664439479522818

Epoch: 5| Step: 5
Training loss: 2.3873441036115994
Validation loss: 2.6665752191559506

Epoch: 5| Step: 6
Training loss: 2.552133385822685
Validation loss: 2.677742110115304

Epoch: 5| Step: 7
Training loss: 2.6642357554549356
Validation loss: 2.688090599577281

Epoch: 5| Step: 8
Training loss: 2.0519903197404097
Validation loss: 2.660821014709901

Epoch: 5| Step: 9
Training loss: 2.5308549360756527
Validation loss: 2.69397899793124

Epoch: 5| Step: 10
Training loss: 2.367831001063456
Validation loss: 2.694266299594142

Epoch: 5| Step: 11
Training loss: 3.268531929167109
Validation loss: 2.6790937613024903

Epoch: 17| Step: 0
Training loss: 2.3125948499868167
Validation loss: 2.6732144335357724

Epoch: 5| Step: 1
Training loss: 2.72139567415016
Validation loss: 2.6787391296750025

Epoch: 5| Step: 2
Training loss: 2.3790385392712516
Validation loss: 2.694765807653062

Epoch: 5| Step: 3
Training loss: 2.4689097292448072
Validation loss: 2.6684326543040644

Epoch: 5| Step: 4
Training loss: 3.04307170101239
Validation loss: 2.712353683662401

Epoch: 5| Step: 5
Training loss: 2.119354377900491
Validation loss: 2.677128774106383

Epoch: 5| Step: 6
Training loss: 2.22588255020089
Validation loss: 2.6745153138052773

Epoch: 5| Step: 7
Training loss: 2.8300548734163886
Validation loss: 2.6635929264352196

Epoch: 5| Step: 8
Training loss: 3.661145576298103
Validation loss: 2.679699463071524

Epoch: 5| Step: 9
Training loss: 2.3666494028599017
Validation loss: 2.6951684627653965

Epoch: 5| Step: 10
Training loss: 2.0519271119838267
Validation loss: 2.678158938572321

Epoch: 5| Step: 11
Training loss: 3.343622793469647
Validation loss: 2.6880915382595023

Epoch: 18| Step: 0
Training loss: 3.109664213445841
Validation loss: 2.6394864925412977

Epoch: 5| Step: 1
Training loss: 3.0961297640750156
Validation loss: 2.658872435554015

Epoch: 5| Step: 2
Training loss: 2.43283132792043
Validation loss: 2.6759835976526567

Epoch: 5| Step: 3
Training loss: 2.926267209204089
Validation loss: 2.6652732700545894

Epoch: 5| Step: 4
Training loss: 2.606842456688578
Validation loss: 2.666003488738927

Epoch: 5| Step: 5
Training loss: 1.787126318012239
Validation loss: 2.6837402629512788

Epoch: 5| Step: 6
Training loss: 3.0738683401490703
Validation loss: 2.657329007320915

Epoch: 5| Step: 7
Training loss: 2.6422585394911984
Validation loss: 2.671212034162435

Epoch: 5| Step: 8
Training loss: 2.303558590368444
Validation loss: 2.651933764764767

Epoch: 5| Step: 9
Training loss: 2.1487455389965144
Validation loss: 2.6705920576615165

Epoch: 5| Step: 10
Training loss: 2.3259461723390444
Validation loss: 2.68310113315851

Epoch: 5| Step: 11
Training loss: 1.1498821799419747
Validation loss: 2.6660530320595224

Epoch: 19| Step: 0
Training loss: 2.1684522484853526
Validation loss: 2.6410103954949316

Epoch: 5| Step: 1
Training loss: 2.1538799363148855
Validation loss: 2.6939699081735893

Epoch: 5| Step: 2
Training loss: 3.313507214850484
Validation loss: 2.65805037202291

Epoch: 5| Step: 3
Training loss: 2.5930474490330893
Validation loss: 2.6243858224406846

Epoch: 5| Step: 4
Training loss: 1.6578963392452313
Validation loss: 2.693116580751966

Epoch: 5| Step: 5
Training loss: 2.7876543181943854
Validation loss: 2.643309659938065

Epoch: 5| Step: 6
Training loss: 2.497658777698029
Validation loss: 2.6349605396773668

Epoch: 5| Step: 7
Training loss: 2.556134948379802
Validation loss: 2.6803631982541005

Epoch: 5| Step: 8
Training loss: 2.6146324325348647
Validation loss: 2.652407934267132

Epoch: 5| Step: 9
Training loss: 2.750789355650955
Validation loss: 2.7125826139658207

Epoch: 5| Step: 10
Training loss: 2.9191844608665862
Validation loss: 2.6554539254247875

Epoch: 5| Step: 11
Training loss: 2.2332394788958205
Validation loss: 2.7020860671002853

Epoch: 20| Step: 0
Training loss: 2.6851952894856237
Validation loss: 2.632921422257928

Epoch: 5| Step: 1
Training loss: 2.6282421253789954
Validation loss: 2.6930980633987756

Epoch: 5| Step: 2
Training loss: 2.3659444132230116
Validation loss: 2.6413219593028825

Epoch: 5| Step: 3
Training loss: 2.417007477066539
Validation loss: 2.6495710139661326

Epoch: 5| Step: 4
Training loss: 2.0360502596799095
Validation loss: 2.6813992222400302

Epoch: 5| Step: 5
Training loss: 3.328612385912396
Validation loss: 2.6688938798914217

Epoch: 5| Step: 6
Training loss: 2.730111334769708
Validation loss: 2.6514283193679553

Epoch: 5| Step: 7
Training loss: 2.998631960162388
Validation loss: 2.667242458636166

Epoch: 5| Step: 8
Training loss: 2.11665174173615
Validation loss: 2.647486783319755

Epoch: 5| Step: 9
Training loss: 2.390627991917552
Validation loss: 2.6462789570757668

Epoch: 5| Step: 10
Training loss: 2.527006949339332
Validation loss: 2.658060907637183

Epoch: 5| Step: 11
Training loss: 3.2665637551530344
Validation loss: 2.6394392808738645

Epoch: 21| Step: 0
Training loss: 2.6035800934441244
Validation loss: 2.6550257573012805

Epoch: 5| Step: 1
Training loss: 2.4961908885698136
Validation loss: 2.652491652007873

Epoch: 5| Step: 2
Training loss: 2.6100676753598737
Validation loss: 2.650052106393005

Epoch: 5| Step: 3
Training loss: 2.7947230238321907
Validation loss: 2.6906150610928865

Epoch: 5| Step: 4
Training loss: 1.8733087541567377
Validation loss: 2.637507654543552

Epoch: 5| Step: 5
Training loss: 2.7737552084751402
Validation loss: 2.642986757534894

Epoch: 5| Step: 6
Training loss: 2.202288637963599
Validation loss: 2.6405783165712005

Epoch: 5| Step: 7
Training loss: 2.6609400912152954
Validation loss: 2.642341958465429

Epoch: 5| Step: 8
Training loss: 3.1109061760237884
Validation loss: 2.6352949051503534

Epoch: 5| Step: 9
Training loss: 2.518511046630189
Validation loss: 2.66190420373734

Epoch: 5| Step: 10
Training loss: 2.1372968878364493
Validation loss: 2.6228553851672136

Epoch: 5| Step: 11
Training loss: 3.532332397934066
Validation loss: 2.657534501900551

Epoch: 22| Step: 0
Training loss: 2.7705244212414133
Validation loss: 2.613531419063186

Epoch: 5| Step: 1
Training loss: 2.4040264408288743
Validation loss: 2.640489070636639

Epoch: 5| Step: 2
Training loss: 2.896857723114608
Validation loss: 2.6184588860005946

Epoch: 5| Step: 3
Training loss: 2.4008489656938017
Validation loss: 2.6744990820113808

Epoch: 5| Step: 4
Training loss: 2.313656904180841
Validation loss: 2.6426206417568374

Epoch: 5| Step: 5
Training loss: 2.2731446801865793
Validation loss: 2.628018267501995

Epoch: 5| Step: 6
Training loss: 3.0365918469833932
Validation loss: 2.63150958112011

Epoch: 5| Step: 7
Training loss: 2.5597972107080533
Validation loss: 2.6069070143415525

Epoch: 5| Step: 8
Training loss: 2.5300110975783543
Validation loss: 2.654549091511252

Epoch: 5| Step: 9
Training loss: 2.4951802523830464
Validation loss: 2.6131615357094264

Epoch: 5| Step: 10
Training loss: 2.5159648405083717
Validation loss: 2.616406230180432

Epoch: 5| Step: 11
Training loss: 2.28287646695543
Validation loss: 2.621308959827816

Epoch: 23| Step: 0
Training loss: 2.989095738929554
Validation loss: 2.626315184777861

Epoch: 5| Step: 1
Training loss: 2.719273308562447
Validation loss: 2.59865812709577

Epoch: 5| Step: 2
Training loss: 2.4560454654710067
Validation loss: 2.629946207764333

Epoch: 5| Step: 3
Training loss: 2.5425785075832215
Validation loss: 2.6420976268207417

Epoch: 5| Step: 4
Training loss: 2.558703051845922
Validation loss: 2.631853357185461

Epoch: 5| Step: 5
Training loss: 2.1723661896439004
Validation loss: 2.6163261704308156

Epoch: 5| Step: 6
Training loss: 2.6464060866822123
Validation loss: 2.5955808910697593

Epoch: 5| Step: 7
Training loss: 2.706550148051659
Validation loss: 2.6127006691731878

Epoch: 5| Step: 8
Training loss: 2.7014385982626195
Validation loss: 2.668222432993972

Epoch: 5| Step: 9
Training loss: 1.9499781167196273
Validation loss: 2.6450281131899285

Epoch: 5| Step: 10
Training loss: 2.6116219171984127
Validation loss: 2.5947294569017307

Epoch: 5| Step: 11
Training loss: 2.001621542662056
Validation loss: 2.647912934678572

Epoch: 24| Step: 0
Training loss: 2.371861642993414
Validation loss: 2.610687401704382

Epoch: 5| Step: 1
Training loss: 2.7192957538621387
Validation loss: 2.611622153034477

Epoch: 5| Step: 2
Training loss: 2.3066045514418327
Validation loss: 2.626174539101966

Epoch: 5| Step: 3
Training loss: 2.6833229428044736
Validation loss: 2.64096884586135

Epoch: 5| Step: 4
Training loss: 2.5472946289358096
Validation loss: 2.610015288048763

Epoch: 5| Step: 5
Training loss: 2.8335478832317946
Validation loss: 2.6377343790794954

Epoch: 5| Step: 6
Training loss: 2.1665574437512554
Validation loss: 2.6438375151918834

Epoch: 5| Step: 7
Training loss: 2.689770294081693
Validation loss: 2.601236038421065

Epoch: 5| Step: 8
Training loss: 2.3418652903892823
Validation loss: 2.6249982515965042

Epoch: 5| Step: 9
Training loss: 3.1557432466604083
Validation loss: 2.6343866918929613

Epoch: 5| Step: 10
Training loss: 2.3685307987619324
Validation loss: 2.619774836694088

Epoch: 5| Step: 11
Training loss: 1.9564621758493506
Validation loss: 2.5929212548408778

Epoch: 25| Step: 0
Training loss: 2.642802587704599
Validation loss: 2.6188048228774674

Epoch: 5| Step: 1
Training loss: 2.932535399656628
Validation loss: 2.593607513696408

Epoch: 5| Step: 2
Training loss: 2.781446128530619
Validation loss: 2.6163945149670815

Epoch: 5| Step: 3
Training loss: 2.610982342739587
Validation loss: 2.6373625357904804

Epoch: 5| Step: 4
Training loss: 1.9845695099905498
Validation loss: 2.598587148504814

Epoch: 5| Step: 5
Training loss: 2.5728419881219886
Validation loss: 2.6272494162008533

Epoch: 5| Step: 6
Training loss: 3.0385052873754708
Validation loss: 2.6363330624914214

Epoch: 5| Step: 7
Training loss: 2.3043413322519957
Validation loss: 2.6354643411558576

Epoch: 5| Step: 8
Training loss: 2.437497456867163
Validation loss: 2.6230384256544483

Epoch: 5| Step: 9
Training loss: 2.214682813714539
Validation loss: 2.657600418590763

Epoch: 5| Step: 10
Training loss: 2.4598741928743606
Validation loss: 2.6133150593652323

Epoch: 5| Step: 11
Training loss: 2.4290692195899997
Validation loss: 2.5756472365960605

Epoch: 26| Step: 0
Training loss: 2.9234166285770358
Validation loss: 2.6507939495873387

Epoch: 5| Step: 1
Training loss: 2.2466929822261603
Validation loss: 2.6157701478622304

Epoch: 5| Step: 2
Training loss: 2.5608282451121855
Validation loss: 2.6421049398783962

Epoch: 5| Step: 3
Training loss: 2.7967483236086705
Validation loss: 2.6202901564395926

Epoch: 5| Step: 4
Training loss: 2.4527810213963495
Validation loss: 2.589619112317453

Epoch: 5| Step: 5
Training loss: 2.1913646891251646
Validation loss: 2.635879198329176

Epoch: 5| Step: 6
Training loss: 2.512279299631693
Validation loss: 2.6296486979942637

Epoch: 5| Step: 7
Training loss: 2.1299801978681745
Validation loss: 2.6638165544059698

Epoch: 5| Step: 8
Training loss: 2.7762793367047593
Validation loss: 2.652904224683119

Epoch: 5| Step: 9
Training loss: 2.0864331517356067
Validation loss: 2.6047885126894523

Epoch: 5| Step: 10
Training loss: 3.0613011719058782
Validation loss: 2.6254084587200937

Epoch: 5| Step: 11
Training loss: 2.271443229689689
Validation loss: 2.6589351284293086

Epoch: 27| Step: 0
Training loss: 2.1483255253135227
Validation loss: 2.5861206335583757

Epoch: 5| Step: 1
Training loss: 1.964122480570614
Validation loss: 2.6145661772713495

Epoch: 5| Step: 2
Training loss: 1.782068566412844
Validation loss: 2.6106462142273568

Epoch: 5| Step: 3
Training loss: 2.468164881647011
Validation loss: 2.609979970551877

Epoch: 5| Step: 4
Training loss: 2.731396780718294
Validation loss: 2.580595408853795

Epoch: 5| Step: 5
Training loss: 2.6685863578707854
Validation loss: 2.586007016449015

Epoch: 5| Step: 6
Training loss: 2.6889613414580196
Validation loss: 2.5915985798145984

Epoch: 5| Step: 7
Training loss: 3.209505156168649
Validation loss: 2.605136547042715

Epoch: 5| Step: 8
Training loss: 2.706758823971253
Validation loss: 2.6490044376162833

Epoch: 5| Step: 9
Training loss: 2.402827814226766
Validation loss: 2.6155366312197814

Epoch: 5| Step: 10
Training loss: 3.124176679873113
Validation loss: 2.5841555338077153

Epoch: 5| Step: 11
Training loss: 0.727280661759118
Validation loss: 2.612202671233779

Epoch: 28| Step: 0
Training loss: 2.258133492536964
Validation loss: 2.5878488328546165

Epoch: 5| Step: 1
Training loss: 2.200353082586819
Validation loss: 2.585066507487397

Epoch: 5| Step: 2
Training loss: 2.597828794786424
Validation loss: 2.558265707714765

Epoch: 5| Step: 3
Training loss: 3.1617454804802683
Validation loss: 2.601879306783234

Epoch: 5| Step: 4
Training loss: 2.2790074234122226
Validation loss: 2.631600905795255

Epoch: 5| Step: 5
Training loss: 2.0967567831220575
Validation loss: 2.608188928749551

Epoch: 5| Step: 6
Training loss: 3.010239293417999
Validation loss: 2.603138126708078

Epoch: 5| Step: 7
Training loss: 2.5109760616168644
Validation loss: 2.576697622950531

Epoch: 5| Step: 8
Training loss: 2.616963573384503
Validation loss: 2.5724101102043653

Epoch: 5| Step: 9
Training loss: 2.716684806700759
Validation loss: 2.5939812423086184

Epoch: 5| Step: 10
Training loss: 2.2527070185530094
Validation loss: 2.542970304786531

Epoch: 5| Step: 11
Training loss: 1.6543902626385594
Validation loss: 2.5925773302185946

Epoch: 29| Step: 0
Training loss: 2.653947168573233
Validation loss: 2.595481857387044

Epoch: 5| Step: 1
Training loss: 2.1473782234169922
Validation loss: 2.623417740747995

Epoch: 5| Step: 2
Training loss: 2.1599119851936
Validation loss: 2.620825394197416

Epoch: 5| Step: 3
Training loss: 2.8013891520699956
Validation loss: 2.5893170112134056

Epoch: 5| Step: 4
Training loss: 3.3776265979140625
Validation loss: 2.628634396724615

Epoch: 5| Step: 5
Training loss: 2.414230291467249
Validation loss: 2.641134833602151

Epoch: 5| Step: 6
Training loss: 2.3718417400294847
Validation loss: 2.6031219230532923

Epoch: 5| Step: 7
Training loss: 2.262326173796406
Validation loss: 2.6032386245139527

Epoch: 5| Step: 8
Training loss: 2.3105000275919587
Validation loss: 2.639327251403792

Epoch: 5| Step: 9
Training loss: 2.7980752426130313
Validation loss: 2.6230148309685144

Epoch: 5| Step: 10
Training loss: 2.214088701457912
Validation loss: 2.6357713216947816

Epoch: 5| Step: 11
Training loss: 2.118853374648774
Validation loss: 2.5979020578442205

Epoch: 30| Step: 0
Training loss: 2.239496084480244
Validation loss: 2.624764333470076

Epoch: 5| Step: 1
Training loss: 2.004555877622275
Validation loss: 2.585845519213454

Epoch: 5| Step: 2
Training loss: 2.7477005101105396
Validation loss: 2.587627108610816

Epoch: 5| Step: 3
Training loss: 2.5393562029650565
Validation loss: 2.587668627927847

Epoch: 5| Step: 4
Training loss: 2.3427385309313333
Validation loss: 2.597997993801283

Epoch: 5| Step: 5
Training loss: 2.602541261138846
Validation loss: 2.562775058250336

Epoch: 5| Step: 6
Training loss: 2.8476790229713553
Validation loss: 2.588049553363582

Epoch: 5| Step: 7
Training loss: 2.2127162935385365
Validation loss: 2.5570781305251997

Epoch: 5| Step: 8
Training loss: 2.5443538989300385
Validation loss: 2.5696191345291157

Epoch: 5| Step: 9
Training loss: 2.742205323598815
Validation loss: 2.5480472113810704

Epoch: 5| Step: 10
Training loss: 2.7374484854253724
Validation loss: 2.561589311806351

Epoch: 5| Step: 11
Training loss: 1.9820670576097612
Validation loss: 2.5756373782478725

Epoch: 31| Step: 0
Training loss: 2.1076353458191113
Validation loss: 2.5708364167238744

Epoch: 5| Step: 1
Training loss: 2.8135913850604144
Validation loss: 2.5628908952440477

Epoch: 5| Step: 2
Training loss: 3.1000588565284417
Validation loss: 2.5944196648529596

Epoch: 5| Step: 3
Training loss: 2.155911736976506
Validation loss: 2.590987990793802

Epoch: 5| Step: 4
Training loss: 2.129264031539894
Validation loss: 2.5874770307826758

Epoch: 5| Step: 5
Training loss: 2.098585665223368
Validation loss: 2.581095456183734

Epoch: 5| Step: 6
Training loss: 2.560946668290769
Validation loss: 2.598414084427833

Epoch: 5| Step: 7
Training loss: 2.7291312373145122
Validation loss: 2.600428138230439

Epoch: 5| Step: 8
Training loss: 2.458044185983108
Validation loss: 2.587616710441762

Epoch: 5| Step: 9
Training loss: 2.639458663954942
Validation loss: 2.6158194653083786

Epoch: 5| Step: 10
Training loss: 2.480332258178713
Validation loss: 2.5884123577361535

Epoch: 5| Step: 11
Training loss: 2.936447604347991
Validation loss: 2.631316887435021

Epoch: 32| Step: 0
Training loss: 2.589802783394647
Validation loss: 2.5971424981039863

Epoch: 5| Step: 1
Training loss: 1.8885379337442927
Validation loss: 2.597453141458323

Epoch: 5| Step: 2
Training loss: 2.928043972591964
Validation loss: 2.6108911187134662

Epoch: 5| Step: 3
Training loss: 2.3809569090845555
Validation loss: 2.5940666656528095

Epoch: 5| Step: 4
Training loss: 2.6013533591212155
Validation loss: 2.6099976807434184

Epoch: 5| Step: 5
Training loss: 2.2041337970477395
Validation loss: 2.5776406228079947

Epoch: 5| Step: 6
Training loss: 2.0048972016425313
Validation loss: 2.561580174979142

Epoch: 5| Step: 7
Training loss: 2.740948432445633
Validation loss: 2.577746484886705

Epoch: 5| Step: 8
Training loss: 2.435511927594851
Validation loss: 2.5870839292755234

Epoch: 5| Step: 9
Training loss: 2.4203899137209564
Validation loss: 2.577654863127361

Epoch: 5| Step: 10
Training loss: 3.1184429804983815
Validation loss: 2.6129868954107147

Epoch: 5| Step: 11
Training loss: 2.8739648696992846
Validation loss: 2.592493108907607

Epoch: 33| Step: 0
Training loss: 2.6756182767146006
Validation loss: 2.592198455523732

Epoch: 5| Step: 1
Training loss: 2.064243966499299
Validation loss: 2.6043843362755466

Epoch: 5| Step: 2
Training loss: 3.3394718074599496
Validation loss: 2.57985626044544

Epoch: 5| Step: 3
Training loss: 2.4062220584188374
Validation loss: 2.5753435485940734

Epoch: 5| Step: 4
Training loss: 2.1012718254921072
Validation loss: 2.573485617852711

Epoch: 5| Step: 5
Training loss: 2.0150623571246093
Validation loss: 2.6015027968206943

Epoch: 5| Step: 6
Training loss: 1.856632742934267
Validation loss: 2.5866280831227795

Epoch: 5| Step: 7
Training loss: 2.486646561409242
Validation loss: 2.5496952749792157

Epoch: 5| Step: 8
Training loss: 2.9539144762555716
Validation loss: 2.5863815110825095

Epoch: 5| Step: 9
Training loss: 3.028373375814932
Validation loss: 2.5899696031833987

Epoch: 5| Step: 10
Training loss: 2.470083721456303
Validation loss: 2.577386650167041

Epoch: 5| Step: 11
Training loss: 1.5375250093240354
Validation loss: 2.5844744243816375

Epoch: 34| Step: 0
Training loss: 2.832066776447428
Validation loss: 2.5675285010719913

Epoch: 5| Step: 1
Training loss: 1.9923821447689365
Validation loss: 2.5729901628898015

Epoch: 5| Step: 2
Training loss: 2.4633605653894777
Validation loss: 2.592677304388862

Epoch: 5| Step: 3
Training loss: 2.9073092263398874
Validation loss: 2.6178058823669637

Epoch: 5| Step: 4
Training loss: 2.404890394667451
Validation loss: 2.584517970007112

Epoch: 5| Step: 5
Training loss: 2.8475392007515707
Validation loss: 2.591466162480357

Epoch: 5| Step: 6
Training loss: 2.475942251231459
Validation loss: 2.574188085594323

Epoch: 5| Step: 7
Training loss: 1.5878868712959169
Validation loss: 2.5920214772494834

Epoch: 5| Step: 8
Training loss: 1.9917578738834898
Validation loss: 2.6084991591780446

Epoch: 5| Step: 9
Training loss: 2.6769481481319106
Validation loss: 2.603752608124734

Epoch: 5| Step: 10
Training loss: 2.779500432444863
Validation loss: 2.5920998713126173

Epoch: 5| Step: 11
Training loss: 3.274111876294274
Validation loss: 2.627459736015556

Epoch: 35| Step: 0
Training loss: 2.5777781860124698
Validation loss: 2.573670915071314

Epoch: 5| Step: 1
Training loss: 2.2601968919176874
Validation loss: 2.575686559690482

Epoch: 5| Step: 2
Training loss: 2.558776383033332
Validation loss: 2.5840780135969332

Epoch: 5| Step: 3
Training loss: 2.44773009110011
Validation loss: 2.600821770501053

Epoch: 5| Step: 4
Training loss: 2.462665738177714
Validation loss: 2.567065614394491

Epoch: 5| Step: 5
Training loss: 2.508269746635558
Validation loss: 2.6033994358289836

Epoch: 5| Step: 6
Training loss: 2.6921993244285636
Validation loss: 2.570930777629402

Epoch: 5| Step: 7
Training loss: 2.1029681074959314
Validation loss: 2.5614145081007904

Epoch: 5| Step: 8
Training loss: 2.509428650316939
Validation loss: 2.5842070595305993

Epoch: 5| Step: 9
Training loss: 2.8030562478504213
Validation loss: 2.586425059167628

Epoch: 5| Step: 10
Training loss: 2.498465734802985
Validation loss: 2.5770755404326513

Epoch: 5| Step: 11
Training loss: 3.216748254034497
Validation loss: 2.5949935077054365

Epoch: 36| Step: 0
Training loss: 1.828569081158068
Validation loss: 2.5814497230794005

Epoch: 5| Step: 1
Training loss: 2.6558035980305954
Validation loss: 2.5616535129987077

Epoch: 5| Step: 2
Training loss: 2.556993196450776
Validation loss: 2.550147444694623

Epoch: 5| Step: 3
Training loss: 2.5085593564251676
Validation loss: 2.5850656274671

Epoch: 5| Step: 4
Training loss: 3.030703623187051
Validation loss: 2.6131229324168412

Epoch: 5| Step: 5
Training loss: 2.150067740859158
Validation loss: 2.5876501775396643

Epoch: 5| Step: 6
Training loss: 2.3788967288974594
Validation loss: 2.5973842315894076

Epoch: 5| Step: 7
Training loss: 2.692035042402893
Validation loss: 2.5388593973943694

Epoch: 5| Step: 8
Training loss: 1.8768539164321525
Validation loss: 2.5870538320736776

Epoch: 5| Step: 9
Training loss: 2.6859296602197977
Validation loss: 2.597083320631956

Epoch: 5| Step: 10
Training loss: 3.0000947301531293
Validation loss: 2.560011197838035

Epoch: 5| Step: 11
Training loss: 1.8511528495524097
Validation loss: 2.57993808147763

Epoch: 37| Step: 0
Training loss: 2.654202468686497
Validation loss: 2.5994408617590343

Epoch: 5| Step: 1
Training loss: 2.757374499068415
Validation loss: 2.572194091914488

Epoch: 5| Step: 2
Training loss: 2.3065557633826037
Validation loss: 2.576371184017176

Epoch: 5| Step: 3
Training loss: 1.774023421372688
Validation loss: 2.5641591934299344

Epoch: 5| Step: 4
Training loss: 1.9944500211438791
Validation loss: 2.603700311229074

Epoch: 5| Step: 5
Training loss: 2.4080785763996047
Validation loss: 2.5767145132452107

Epoch: 5| Step: 6
Training loss: 2.680906502299598
Validation loss: 2.60199425048276

Epoch: 5| Step: 7
Training loss: 2.651498471657609
Validation loss: 2.5985400271608694

Epoch: 5| Step: 8
Training loss: 2.0986789362806046
Validation loss: 2.583973912193624

Epoch: 5| Step: 9
Training loss: 2.615687518358236
Validation loss: 2.5647521124326405

Epoch: 5| Step: 10
Training loss: 3.221933512706731
Validation loss: 2.6038630550146493

Epoch: 5| Step: 11
Training loss: 2.3135997116270715
Validation loss: 2.595548362509903

Epoch: 38| Step: 0
Training loss: 2.5714263821395758
Validation loss: 2.577765934918547

Epoch: 5| Step: 1
Training loss: 2.903360550669279
Validation loss: 2.5627814463992458

Epoch: 5| Step: 2
Training loss: 2.4139088208314923
Validation loss: 2.5599824005319203

Epoch: 5| Step: 3
Training loss: 2.8748097564115582
Validation loss: 2.5642448664189823

Epoch: 5| Step: 4
Training loss: 2.336178055946964
Validation loss: 2.588105436802475

Epoch: 5| Step: 5
Training loss: 2.438810827453764
Validation loss: 2.596212210388608

Epoch: 5| Step: 6
Training loss: 2.308356723138992
Validation loss: 2.582670820303846

Epoch: 5| Step: 7
Training loss: 2.7288037900913458
Validation loss: 2.5757696084941633

Epoch: 5| Step: 8
Training loss: 2.756803073883114
Validation loss: 2.5333172555045187

Epoch: 5| Step: 9
Training loss: 1.8603924443916822
Validation loss: 2.565428396088394

Epoch: 5| Step: 10
Training loss: 2.27573281526997
Validation loss: 2.565872165840975

Epoch: 5| Step: 11
Training loss: 1.8678521286231027
Validation loss: 2.5798394330772423

Epoch: 39| Step: 0
Training loss: 1.7812356780965488
Validation loss: 2.573786242382565

Epoch: 5| Step: 1
Training loss: 2.7042899736015777
Validation loss: 2.5719975375482074

Epoch: 5| Step: 2
Training loss: 2.3335637818932264
Validation loss: 2.5528915384134168

Epoch: 5| Step: 3
Training loss: 2.2909413201265507
Validation loss: 2.5574002343237128

Epoch: 5| Step: 4
Training loss: 2.9441939033423927
Validation loss: 2.5643365450467512

Epoch: 5| Step: 5
Training loss: 2.0897120924504162
Validation loss: 2.5674545724967386

Epoch: 5| Step: 6
Training loss: 2.5261546525888683
Validation loss: 2.5832101974571233

Epoch: 5| Step: 7
Training loss: 2.7435861699368758
Validation loss: 2.566114737155358

Epoch: 5| Step: 8
Training loss: 2.6865725136659355
Validation loss: 2.5619878955022073

Epoch: 5| Step: 9
Training loss: 2.9472631981538218
Validation loss: 2.5775066905855204

Epoch: 5| Step: 10
Training loss: 1.3692649534536212
Validation loss: 2.604000480435489

Epoch: 5| Step: 11
Training loss: 4.014164402946376
Validation loss: 2.568326002709161

Epoch: 40| Step: 0
Training loss: 2.5495106919508266
Validation loss: 2.550620486308358

Epoch: 5| Step: 1
Training loss: 2.3940955009820026
Validation loss: 2.5762513220516974

Epoch: 5| Step: 2
Training loss: 2.449137465787591
Validation loss: 2.5787637343189633

Epoch: 5| Step: 3
Training loss: 2.405499824404983
Validation loss: 2.594672686221258

Epoch: 5| Step: 4
Training loss: 1.860622596521334
Validation loss: 2.640940619121421

Epoch: 5| Step: 5
Training loss: 2.5156150485961457
Validation loss: 2.621684955715822

Epoch: 5| Step: 6
Training loss: 2.0075309348187265
Validation loss: 2.6121701100703034

Epoch: 5| Step: 7
Training loss: 2.8389896330985116
Validation loss: 2.6391594636523914

Epoch: 5| Step: 8
Training loss: 2.9605084513521227
Validation loss: 2.6331104521248037

Epoch: 5| Step: 9
Training loss: 2.3803384913632715
Validation loss: 2.619037850886042

Epoch: 5| Step: 10
Training loss: 2.77200306077268
Validation loss: 2.611700061453944

Epoch: 5| Step: 11
Training loss: 3.5738721335517223
Validation loss: 2.603335665039536

Epoch: 41| Step: 0
Training loss: 2.2846237735994412
Validation loss: 2.574013801717028

Epoch: 5| Step: 1
Training loss: 2.5506603919193176
Validation loss: 2.5864237110239356

Epoch: 5| Step: 2
Training loss: 2.9795731665085246
Validation loss: 2.5888340603860094

Epoch: 5| Step: 3
Training loss: 2.568082357922018
Validation loss: 2.581015536641247

Epoch: 5| Step: 4
Training loss: 1.9072805026894526
Validation loss: 2.5578226456298205

Epoch: 5| Step: 5
Training loss: 2.686549972464149
Validation loss: 2.5989590086136567

Epoch: 5| Step: 6
Training loss: 2.1839347122760175
Validation loss: 2.590874366661283

Epoch: 5| Step: 7
Training loss: 2.279533785787808
Validation loss: 2.6064590676703303

Epoch: 5| Step: 8
Training loss: 2.287233109877451
Validation loss: 2.593977267101983

Epoch: 5| Step: 9
Training loss: 2.6190243779839784
Validation loss: 2.559166426305119

Epoch: 5| Step: 10
Training loss: 2.9024838892500258
Validation loss: 2.5661316680723703

Epoch: 5| Step: 11
Training loss: 2.697562431341282
Validation loss: 2.5880100438617335

Epoch: 42| Step: 0
Training loss: 2.060441232296332
Validation loss: 2.561517783074023

Epoch: 5| Step: 1
Training loss: 2.2757867689291666
Validation loss: 2.5972780913250144

Epoch: 5| Step: 2
Training loss: 2.997599913241953
Validation loss: 2.601900017717565

Epoch: 5| Step: 3
Training loss: 2.1782878360603575
Validation loss: 2.5889348601988

Epoch: 5| Step: 4
Training loss: 3.2640686707098205
Validation loss: 2.5529277818725373

Epoch: 5| Step: 5
Training loss: 2.411528705094676
Validation loss: 2.537755400860003

Epoch: 5| Step: 6
Training loss: 2.506810543702947
Validation loss: 2.559861057131945

Epoch: 5| Step: 7
Training loss: 2.725355083184071
Validation loss: 2.577143330031125

Epoch: 5| Step: 8
Training loss: 2.083076601104269
Validation loss: 2.6105205206725413

Epoch: 5| Step: 9
Training loss: 2.399536676188963
Validation loss: 2.5934701370249216

Epoch: 5| Step: 10
Training loss: 2.1860368467473084
Validation loss: 2.5912699926843827

Epoch: 5| Step: 11
Training loss: 1.887570712047076
Validation loss: 2.600529397809924

Epoch: 43| Step: 0
Training loss: 2.51881150012033
Validation loss: 2.610724471400186

Epoch: 5| Step: 1
Training loss: 2.0327459841965227
Validation loss: 2.575444405826063

Epoch: 5| Step: 2
Training loss: 2.2234448473682296
Validation loss: 2.6279530471600854

Epoch: 5| Step: 3
Training loss: 2.1996174479712223
Validation loss: 2.6988512811271486

Epoch: 5| Step: 4
Training loss: 1.9812846713236394
Validation loss: 2.6751369582377533

Epoch: 5| Step: 5
Training loss: 3.091340639210088
Validation loss: 2.7243124632583453

Epoch: 5| Step: 6
Training loss: 2.1028052984015995
Validation loss: 2.704061048430813

Epoch: 5| Step: 7
Training loss: 3.0924787895936996
Validation loss: 2.7237849548090334

Epoch: 5| Step: 8
Training loss: 2.6985188306823282
Validation loss: 2.697503571323815

Epoch: 5| Step: 9
Training loss: 2.983436476844236
Validation loss: 2.663906260632554

Epoch: 5| Step: 10
Training loss: 2.7219063863247626
Validation loss: 2.6098745100197913

Epoch: 5| Step: 11
Training loss: 1.7828391498576468
Validation loss: 2.5904688898162402

Epoch: 44| Step: 0
Training loss: 2.705797230681644
Validation loss: 2.5600652370236934

Epoch: 5| Step: 1
Training loss: 2.438443808131288
Validation loss: 2.5351106965802415

Epoch: 5| Step: 2
Training loss: 2.8198225700076347
Validation loss: 2.5962637895460645

Epoch: 5| Step: 3
Training loss: 2.4776453965959684
Validation loss: 2.5683370417601763

Epoch: 5| Step: 4
Training loss: 2.347570128932021
Validation loss: 2.5926132545392124

Epoch: 5| Step: 5
Training loss: 2.1985598402002076
Validation loss: 2.5880123853529597

Epoch: 5| Step: 6
Training loss: 2.8523199042287612
Validation loss: 2.587565195027069

Epoch: 5| Step: 7
Training loss: 2.828761245226454
Validation loss: 2.5860089717641994

Epoch: 5| Step: 8
Training loss: 2.416063386881377
Validation loss: 2.557610215484295

Epoch: 5| Step: 9
Training loss: 1.9842052236904475
Validation loss: 2.5720181356950493

Epoch: 5| Step: 10
Training loss: 2.488771782496652
Validation loss: 2.583473983647927

Epoch: 5| Step: 11
Training loss: 2.2710782423562716
Validation loss: 2.5867237574525888

Epoch: 45| Step: 0
Training loss: 2.659190984471505
Validation loss: 2.5908046874835584

Epoch: 5| Step: 1
Training loss: 3.063499598953074
Validation loss: 2.587577837389094

Epoch: 5| Step: 2
Training loss: 2.135909629924588
Validation loss: 2.583876715445532

Epoch: 5| Step: 3
Training loss: 2.1048976144786105
Validation loss: 2.557636262371745

Epoch: 5| Step: 4
Training loss: 2.5916803214479063
Validation loss: 2.574600453844349

Epoch: 5| Step: 5
Training loss: 2.087522097716182
Validation loss: 2.558849343304961

Epoch: 5| Step: 6
Training loss: 2.202472563106145
Validation loss: 2.577018839574695

Epoch: 5| Step: 7
Training loss: 2.6419398177610685
Validation loss: 2.5906171684315487

Epoch: 5| Step: 8
Training loss: 3.135634675584129
Validation loss: 2.617798880910934

Epoch: 5| Step: 9
Training loss: 2.4121293410737428
Validation loss: 2.61383887377783

Epoch: 5| Step: 10
Training loss: 2.294136958522845
Validation loss: 2.5857455171771635

Epoch: 5| Step: 11
Training loss: 1.1826907197250955
Validation loss: 2.5730537089763867

Epoch: 46| Step: 0
Training loss: 2.8801564952929084
Validation loss: 2.608351946623164

Epoch: 5| Step: 1
Training loss: 2.586778763213432
Validation loss: 2.5932414272488677

Epoch: 5| Step: 2
Training loss: 2.7690957053780596
Validation loss: 2.5796004186881993

Epoch: 5| Step: 3
Training loss: 2.6361112219655594
Validation loss: 2.5867378863217567

Epoch: 5| Step: 4
Training loss: 1.9281584824880704
Validation loss: 2.582016876072967

Epoch: 5| Step: 5
Training loss: 2.4471134464232605
Validation loss: 2.5936599240882354

Epoch: 5| Step: 6
Training loss: 2.753749199034669
Validation loss: 2.603846382790467

Epoch: 5| Step: 7
Training loss: 2.1228199041724047
Validation loss: 2.6145682708083458

Epoch: 5| Step: 8
Training loss: 2.6015117285187483
Validation loss: 2.54867156072839

Epoch: 5| Step: 9
Training loss: 2.2316761924116815
Validation loss: 2.552677472041465

Epoch: 5| Step: 10
Training loss: 2.023107435487825
Validation loss: 2.5909202183530637

Epoch: 5| Step: 11
Training loss: 1.954204840649864
Validation loss: 2.6014119888466296

Epoch: 47| Step: 0
Training loss: 2.8900046842860503
Validation loss: 2.6073605648076255

Epoch: 5| Step: 1
Training loss: 2.509504371434045
Validation loss: 2.554108864273836

Epoch: 5| Step: 2
Training loss: 2.3334788776599953
Validation loss: 2.5772854410933563

Epoch: 5| Step: 3
Training loss: 3.0126758444974717
Validation loss: 2.5791864733841883

Epoch: 5| Step: 4
Training loss: 2.6132561606897737
Validation loss: 2.573784358836008

Epoch: 5| Step: 5
Training loss: 2.5644354605375055
Validation loss: 2.5930519830827485

Epoch: 5| Step: 6
Training loss: 2.52073538934101
Validation loss: 2.5837896287595323

Epoch: 5| Step: 7
Training loss: 1.906055002713815
Validation loss: 2.550787707131252

Epoch: 5| Step: 8
Training loss: 2.5965485699314743
Validation loss: 2.5802360715415924

Epoch: 5| Step: 9
Training loss: 2.1916551635595027
Validation loss: 2.5584674134258245

Epoch: 5| Step: 10
Training loss: 2.1287480006765764
Validation loss: 2.5428039216094587

Epoch: 5| Step: 11
Training loss: 1.237469139099638
Validation loss: 2.575672462764752

Epoch: 48| Step: 0
Training loss: 2.3031460019607217
Validation loss: 2.5839730875466023

Epoch: 5| Step: 1
Training loss: 2.7649499963857265
Validation loss: 2.5561409994636937

Epoch: 5| Step: 2
Training loss: 2.715400561857169
Validation loss: 2.521827038195035

Epoch: 5| Step: 3
Training loss: 2.0974867768263
Validation loss: 2.5639042224496693

Epoch: 5| Step: 4
Training loss: 2.2007825586696277
Validation loss: 2.5469170510344674

Epoch: 5| Step: 5
Training loss: 2.4467669661679996
Validation loss: 2.5593905812131936

Epoch: 5| Step: 6
Training loss: 2.7827879693108337
Validation loss: 2.580102928594916

Epoch: 5| Step: 7
Training loss: 2.7807038017316925
Validation loss: 2.6129509983738313

Epoch: 5| Step: 8
Training loss: 2.3760362673280992
Validation loss: 2.5589621591688205

Epoch: 5| Step: 9
Training loss: 2.30624750648922
Validation loss: 2.5880238816602943

Epoch: 5| Step: 10
Training loss: 2.2942309049551803
Validation loss: 2.600268785937267

Epoch: 5| Step: 11
Training loss: 2.058224610560244
Validation loss: 2.57905207447709

Epoch: 49| Step: 0
Training loss: 2.248084842682745
Validation loss: 2.587377516063549

Epoch: 5| Step: 1
Training loss: 2.617807616600062
Validation loss: 2.5707114701366742

Epoch: 5| Step: 2
Training loss: 2.574880882396837
Validation loss: 2.5380397321275456

Epoch: 5| Step: 3
Training loss: 2.7588736678121943
Validation loss: 2.5435370431873054

Epoch: 5| Step: 4
Training loss: 2.856181544979818
Validation loss: 2.589673427468212

Epoch: 5| Step: 5
Training loss: 2.8906515584189565
Validation loss: 2.5760177207560866

Epoch: 5| Step: 6
Training loss: 2.2689576991825855
Validation loss: 2.535248239941731

Epoch: 5| Step: 7
Training loss: 2.4141144484575427
Validation loss: 2.556527739719343

Epoch: 5| Step: 8
Training loss: 2.469974455604821
Validation loss: 2.5960992109539935

Epoch: 5| Step: 9
Training loss: 1.935282946163381
Validation loss: 2.577156474515432

Epoch: 5| Step: 10
Training loss: 2.3444652229019063
Validation loss: 2.5543556075561336

Epoch: 5| Step: 11
Training loss: 1.8005109406202149
Validation loss: 2.5800207431523656

Epoch: 50| Step: 0
Training loss: 2.83122530288535
Validation loss: 2.562411609148637

Epoch: 5| Step: 1
Training loss: 2.49279988098585
Validation loss: 2.5662906645860284

Epoch: 5| Step: 2
Training loss: 2.4168347486602273
Validation loss: 2.543556690369059

Epoch: 5| Step: 3
Training loss: 1.986903404567988
Validation loss: 2.5950903665590146

Epoch: 5| Step: 4
Training loss: 2.28936265663529
Validation loss: 2.568417980458581

Epoch: 5| Step: 5
Training loss: 2.3680303602721
Validation loss: 2.60192878825156

Epoch: 5| Step: 6
Training loss: 2.2786504487490458
Validation loss: 2.569875739961481

Epoch: 5| Step: 7
Training loss: 2.8243408176745106
Validation loss: 2.570720829555168

Epoch: 5| Step: 8
Training loss: 2.236856856164628
Validation loss: 2.5625834761568225

Epoch: 5| Step: 9
Training loss: 2.5743069206732465
Validation loss: 2.5720096616227344

Epoch: 5| Step: 10
Training loss: 2.557287077630944
Validation loss: 2.5678963286088434

Epoch: 5| Step: 11
Training loss: 3.081109628323544
Validation loss: 2.5495171094388764

Epoch: 51| Step: 0
Training loss: 2.7332682086195352
Validation loss: 2.5449970475300248

Epoch: 5| Step: 1
Training loss: 2.052722527989719
Validation loss: 2.5842903323221256

Epoch: 5| Step: 2
Training loss: 2.7890055674664556
Validation loss: 2.6065444403376685

Epoch: 5| Step: 3
Training loss: 1.989459095482862
Validation loss: 2.5442087223797385

Epoch: 5| Step: 4
Training loss: 1.7782983919957673
Validation loss: 2.5720615851546085

Epoch: 5| Step: 5
Training loss: 1.957945041173521
Validation loss: 2.5775671615508484

Epoch: 5| Step: 6
Training loss: 2.753098995852335
Validation loss: 2.563364104211086

Epoch: 5| Step: 7
Training loss: 2.9202110734188156
Validation loss: 2.5776799328353825

Epoch: 5| Step: 8
Training loss: 2.6909156208169986
Validation loss: 2.588124336869622

Epoch: 5| Step: 9
Training loss: 2.5104230086588126
Validation loss: 2.5681267423879928

Epoch: 5| Step: 10
Training loss: 2.507354219103019
Validation loss: 2.5803988630605703

Epoch: 5| Step: 11
Training loss: 2.175633752504456
Validation loss: 2.5697525867778563

Epoch: 52| Step: 0
Training loss: 2.7597334010138788
Validation loss: 2.5629094889893853

Epoch: 5| Step: 1
Training loss: 2.3775078432613608
Validation loss: 2.6172592039391898

Epoch: 5| Step: 2
Training loss: 2.4575142438753224
Validation loss: 2.5345029180114467

Epoch: 5| Step: 3
Training loss: 2.0371360594189483
Validation loss: 2.5328171415637484

Epoch: 5| Step: 4
Training loss: 2.173305452066547
Validation loss: 2.549260105051302

Epoch: 5| Step: 5
Training loss: 2.7301648670759824
Validation loss: 2.5706332005689116

Epoch: 5| Step: 6
Training loss: 2.244770755065615
Validation loss: 2.5734364039980995

Epoch: 5| Step: 7
Training loss: 2.8311525441758794
Validation loss: 2.5579806653736865

Epoch: 5| Step: 8
Training loss: 2.6722981078893873
Validation loss: 2.5737828188040894

Epoch: 5| Step: 9
Training loss: 2.587222238273567
Validation loss: 2.5484404014447706

Epoch: 5| Step: 10
Training loss: 1.7634095327406287
Validation loss: 2.582801850057139

Epoch: 5| Step: 11
Training loss: 2.522974969855398
Validation loss: 2.5718983817939995

Epoch: 53| Step: 0
Training loss: 2.537369289696019
Validation loss: 2.560530479411638

Epoch: 5| Step: 1
Training loss: 2.5213311914885064
Validation loss: 2.5646649728564004

Epoch: 5| Step: 2
Training loss: 2.4904960225595643
Validation loss: 2.5739148683684854

Epoch: 5| Step: 3
Training loss: 2.099515918159872
Validation loss: 2.559126063293585

Epoch: 5| Step: 4
Training loss: 2.6806724228580925
Validation loss: 2.564026323737803

Epoch: 5| Step: 5
Training loss: 2.5866304604300288
Validation loss: 2.5571042954947636

Epoch: 5| Step: 6
Training loss: 2.22871214846798
Validation loss: 2.5925582078010887

Epoch: 5| Step: 7
Training loss: 2.062832198699806
Validation loss: 2.602994988390113

Epoch: 5| Step: 8
Training loss: 3.107181407896022
Validation loss: 2.542440575411908

Epoch: 5| Step: 9
Training loss: 1.8585268538543647
Validation loss: 2.5718572935017847

Epoch: 5| Step: 10
Training loss: 2.4528393427244763
Validation loss: 2.5695327689194474

Epoch: 5| Step: 11
Training loss: 2.683907347545276
Validation loss: 2.5799013125842922

Epoch: 54| Step: 0
Training loss: 2.763171211965875
Validation loss: 2.554061789690482

Epoch: 5| Step: 1
Training loss: 2.3616437298781032
Validation loss: 2.5404171543101057

Epoch: 5| Step: 2
Training loss: 2.152110009214272
Validation loss: 2.5610439148866155

Epoch: 5| Step: 3
Training loss: 2.772499119145328
Validation loss: 2.5637654769606373

Epoch: 5| Step: 4
Training loss: 2.177172669641767
Validation loss: 2.532148966867384

Epoch: 5| Step: 5
Training loss: 2.519717282073445
Validation loss: 2.55075148778808

Epoch: 5| Step: 6
Training loss: 2.422109777084291
Validation loss: 2.5493416026600126

Epoch: 5| Step: 7
Training loss: 1.8869403211438542
Validation loss: 2.5533017202014725

Epoch: 5| Step: 8
Training loss: 2.3058729323541605
Validation loss: 2.5634308845446747

Epoch: 5| Step: 9
Training loss: 3.060239151977728
Validation loss: 2.5160790935917743

Epoch: 5| Step: 10
Training loss: 2.2673356536895235
Validation loss: 2.575508057215791

Epoch: 5| Step: 11
Training loss: 3.0330707548185143
Validation loss: 2.568621762486475

Epoch: 55| Step: 0
Training loss: 2.595252647375769
Validation loss: 2.540953744637691

Epoch: 5| Step: 1
Training loss: 2.632665250831752
Validation loss: 2.5475986053455593

Epoch: 5| Step: 2
Training loss: 2.553270606157726
Validation loss: 2.5789108427327134

Epoch: 5| Step: 3
Training loss: 2.1092864971667855
Validation loss: 2.5413387678560424

Epoch: 5| Step: 4
Training loss: 2.397200771907209
Validation loss: 2.540870116962112

Epoch: 5| Step: 5
Training loss: 3.076110490458969
Validation loss: 2.5729269627250555

Epoch: 5| Step: 6
Training loss: 2.4570288241181886
Validation loss: 2.5760366516640345

Epoch: 5| Step: 7
Training loss: 2.059839324240367
Validation loss: 2.5590578391179855

Epoch: 5| Step: 8
Training loss: 2.495129609496965
Validation loss: 2.5659557355478135

Epoch: 5| Step: 9
Training loss: 2.19398409472032
Validation loss: 2.567762445236877

Epoch: 5| Step: 10
Training loss: 1.940945115769271
Validation loss: 2.565864409018694

Epoch: 5| Step: 11
Training loss: 3.9127920072256694
Validation loss: 2.5692862536446217

Epoch: 56| Step: 0
Training loss: 2.1439130270668523
Validation loss: 2.5479236308449997

Epoch: 5| Step: 1
Training loss: 2.0849713434678847
Validation loss: 2.5446286426551907

Epoch: 5| Step: 2
Training loss: 2.6793902262848337
Validation loss: 2.5584790541394264

Epoch: 5| Step: 3
Training loss: 2.6236239868551774
Validation loss: 2.5544534084070514

Epoch: 5| Step: 4
Training loss: 2.852618964988423
Validation loss: 2.5600716086520094

Epoch: 5| Step: 5
Training loss: 2.4587348890203846
Validation loss: 2.566223575433078

Epoch: 5| Step: 6
Training loss: 2.3695554063561173
Validation loss: 2.5696059031634757

Epoch: 5| Step: 7
Training loss: 2.6129142834297627
Validation loss: 2.5434185593209095

Epoch: 5| Step: 8
Training loss: 2.4093547459009557
Validation loss: 2.594594928894629

Epoch: 5| Step: 9
Training loss: 2.4348170847406627
Validation loss: 2.553501534370821

Epoch: 5| Step: 10
Training loss: 2.3815713620543417
Validation loss: 2.5301059131039634

Epoch: 5| Step: 11
Training loss: 1.5318034203504745
Validation loss: 2.5694268468019357

Epoch: 57| Step: 0
Training loss: 2.317668191512164
Validation loss: 2.570600713786254

Epoch: 5| Step: 1
Training loss: 1.9002253273314609
Validation loss: 2.5668757651251815

Epoch: 5| Step: 2
Training loss: 2.2126845072737433
Validation loss: 2.562058658895657

Epoch: 5| Step: 3
Training loss: 3.2258245256902045
Validation loss: 2.5302274388900305

Epoch: 5| Step: 4
Training loss: 2.386693976190984
Validation loss: 2.5798851901699544

Epoch: 5| Step: 5
Training loss: 2.672510796463572
Validation loss: 2.584405120403474

Epoch: 5| Step: 6
Training loss: 1.920881433222589
Validation loss: 2.565135623848726

Epoch: 5| Step: 7
Training loss: 2.445750236940923
Validation loss: 2.585287590606193

Epoch: 5| Step: 8
Training loss: 2.366698362469543
Validation loss: 2.555871366441338

Epoch: 5| Step: 9
Training loss: 2.5971400156684523
Validation loss: 2.5730378525234414

Epoch: 5| Step: 10
Training loss: 2.7183674510293705
Validation loss: 2.569249459907307

Epoch: 5| Step: 11
Training loss: 1.5664649248430524
Validation loss: 2.606514161945363

Epoch: 58| Step: 0
Training loss: 2.607459638800734
Validation loss: 2.588162689303042

Epoch: 5| Step: 1
Training loss: 2.5052101203980817
Validation loss: 2.651079748413526

Epoch: 5| Step: 2
Training loss: 2.07703675192659
Validation loss: 2.609714647752648

Epoch: 5| Step: 3
Training loss: 2.473564571699848
Validation loss: 2.6196178027199446

Epoch: 5| Step: 4
Training loss: 2.511146587029334
Validation loss: 2.6288223442151555

Epoch: 5| Step: 5
Training loss: 2.472889387520719
Validation loss: 2.5993083547425972

Epoch: 5| Step: 6
Training loss: 2.964999268967537
Validation loss: 2.575714822733519

Epoch: 5| Step: 7
Training loss: 2.928995198150481
Validation loss: 2.564041178209979

Epoch: 5| Step: 8
Training loss: 2.0865399922849064
Validation loss: 2.578109918415385

Epoch: 5| Step: 9
Training loss: 1.8733566075821637
Validation loss: 2.557432592604615

Epoch: 5| Step: 10
Training loss: 2.322023114374395
Validation loss: 2.5626239397733275

Epoch: 5| Step: 11
Training loss: 3.4484295574005155
Validation loss: 2.5882853272975224

Epoch: 59| Step: 0
Training loss: 2.4207552382390736
Validation loss: 2.5365548020855786

Epoch: 5| Step: 1
Training loss: 2.042189615448467
Validation loss: 2.5294294403566853

Epoch: 5| Step: 2
Training loss: 2.8933397896280053
Validation loss: 2.54771560027395

Epoch: 5| Step: 3
Training loss: 2.2821823723056505
Validation loss: 2.517545740803655

Epoch: 5| Step: 4
Training loss: 2.560023343754671
Validation loss: 2.575638870887522

Epoch: 5| Step: 5
Training loss: 2.2760502329882653
Validation loss: 2.532867658447119

Epoch: 5| Step: 6
Training loss: 2.5199296030172347
Validation loss: 2.5665268059241098

Epoch: 5| Step: 7
Training loss: 2.2346289430376407
Validation loss: 2.5576342037994793

Epoch: 5| Step: 8
Training loss: 2.678305133116442
Validation loss: 2.5447698798062226

Epoch: 5| Step: 9
Training loss: 2.4729314232128585
Validation loss: 2.549597016917232

Epoch: 5| Step: 10
Training loss: 2.7599377102664437
Validation loss: 2.550301429286057

Epoch: 5| Step: 11
Training loss: 1.42446897550723
Validation loss: 2.5493261598542807

Epoch: 60| Step: 0
Training loss: 2.422851956116453
Validation loss: 2.544913595658929

Epoch: 5| Step: 1
Training loss: 2.345694688818354
Validation loss: 2.5660903093635916

Epoch: 5| Step: 2
Training loss: 2.164685762078959
Validation loss: 2.545174380013484

Epoch: 5| Step: 3
Training loss: 2.3886720746243784
Validation loss: 2.5890597254220835

Epoch: 5| Step: 4
Training loss: 2.5281128457511644
Validation loss: 2.561651193950124

Epoch: 5| Step: 5
Training loss: 2.6900673956387435
Validation loss: 2.548702949188171

Epoch: 5| Step: 6
Training loss: 2.3084316035353276
Validation loss: 2.575393590043537

Epoch: 5| Step: 7
Training loss: 2.8938994136326066
Validation loss: 2.551678260782696

Epoch: 5| Step: 8
Training loss: 2.427391218268262
Validation loss: 2.5809934476278795

Epoch: 5| Step: 9
Training loss: 1.818394841914617
Validation loss: 2.599135357797723

Epoch: 5| Step: 10
Training loss: 2.655783668423152
Validation loss: 2.5829527879706013

Epoch: 5| Step: 11
Training loss: 2.047488171702816
Validation loss: 2.5791397486706122

Epoch: 61| Step: 0
Training loss: 2.9424160342361976
Validation loss: 2.571851766086601

Epoch: 5| Step: 1
Training loss: 2.561714889462963
Validation loss: 2.5818175642473364

Epoch: 5| Step: 2
Training loss: 2.258675380671212
Validation loss: 2.5735375444166193

Epoch: 5| Step: 3
Training loss: 1.9060304859281116
Validation loss: 2.5833348702354373

Epoch: 5| Step: 4
Training loss: 2.1763606233214525
Validation loss: 2.620817375488297

Epoch: 5| Step: 5
Training loss: 2.053349860896851
Validation loss: 2.5614184601544947

Epoch: 5| Step: 6
Training loss: 2.36725870661132
Validation loss: 2.5752536543813505

Epoch: 5| Step: 7
Training loss: 2.10751147428853
Validation loss: 2.5825132342390593

Epoch: 5| Step: 8
Training loss: 2.771590528545363
Validation loss: 2.57856054769187

Epoch: 5| Step: 9
Training loss: 2.5735453302227698
Validation loss: 2.5715927329120993

Epoch: 5| Step: 10
Training loss: 2.979601652672041
Validation loss: 2.5513564742026267

Epoch: 5| Step: 11
Training loss: 1.6053453384079377
Validation loss: 2.5564144880603004

Epoch: 62| Step: 0
Training loss: 2.630569906530159
Validation loss: 2.5691640678713914

Epoch: 5| Step: 1
Training loss: 2.562764223944391
Validation loss: 2.563533539638376

Epoch: 5| Step: 2
Training loss: 2.3754810046940196
Validation loss: 2.5447173545085824

Epoch: 5| Step: 3
Training loss: 2.0891159929546856
Validation loss: 2.598128831750612

Epoch: 5| Step: 4
Training loss: 3.129086988089069
Validation loss: 2.623180121859952

Epoch: 5| Step: 5
Training loss: 2.961746467655845
Validation loss: 2.557873280353978

Epoch: 5| Step: 6
Training loss: 2.049653009961119
Validation loss: 2.5324274550551062

Epoch: 5| Step: 7
Training loss: 1.625527809696043
Validation loss: 2.5796516483741527

Epoch: 5| Step: 8
Training loss: 2.3209223604048765
Validation loss: 2.5415421960922497

Epoch: 5| Step: 9
Training loss: 2.548083995482619
Validation loss: 2.537258520678533

Epoch: 5| Step: 10
Training loss: 2.3421536922241604
Validation loss: 2.5847698621910675

Epoch: 5| Step: 11
Training loss: 1.2354558244817622
Validation loss: 2.5831737212638073

Epoch: 63| Step: 0
Training loss: 2.0128148324304695
Validation loss: 2.5577346679615247

Epoch: 5| Step: 1
Training loss: 2.7266481052721363
Validation loss: 2.5739272304206198

Epoch: 5| Step: 2
Training loss: 2.1205734823205016
Validation loss: 2.569121768095919

Epoch: 5| Step: 3
Training loss: 2.5473055797357205
Validation loss: 2.5305953454745156

Epoch: 5| Step: 4
Training loss: 2.18960045379227
Validation loss: 2.575525140453372

Epoch: 5| Step: 5
Training loss: 2.037867638120309
Validation loss: 2.567693185406947

Epoch: 5| Step: 6
Training loss: 2.348371095410138
Validation loss: 2.594237519219893

Epoch: 5| Step: 7
Training loss: 2.4824739296150247
Validation loss: 2.568263589018071

Epoch: 5| Step: 8
Training loss: 3.4936105444411614
Validation loss: 2.593737429852647

Epoch: 5| Step: 9
Training loss: 2.1851303344542736
Validation loss: 2.5852720743261255

Epoch: 5| Step: 10
Training loss: 2.3181061706847887
Validation loss: 2.560955545541438

Epoch: 5| Step: 11
Training loss: 1.7531401526464354
Validation loss: 2.5808333611008476

Epoch: 64| Step: 0
Training loss: 2.3293031105471105
Validation loss: 2.5743123193309025

Epoch: 5| Step: 1
Training loss: 2.5261915549152727
Validation loss: 2.5828139387997133

Epoch: 5| Step: 2
Training loss: 2.207520881286222
Validation loss: 2.582891681562812

Epoch: 5| Step: 3
Training loss: 2.222668907518331
Validation loss: 2.5821130790575

Epoch: 5| Step: 4
Training loss: 2.148462579754184
Validation loss: 2.5433183694372605

Epoch: 5| Step: 5
Training loss: 2.9544380942092268
Validation loss: 2.631203251119095

Epoch: 5| Step: 6
Training loss: 2.3043271575091566
Validation loss: 2.581557583898304

Epoch: 5| Step: 7
Training loss: 2.1125182292084
Validation loss: 2.6141007321228344

Epoch: 5| Step: 8
Training loss: 2.471317067217886
Validation loss: 2.565397045758928

Epoch: 5| Step: 9
Training loss: 2.3642437952974085
Validation loss: 2.536971456779262

Epoch: 5| Step: 10
Training loss: 3.0185478948382807
Validation loss: 2.555135798419383

Epoch: 5| Step: 11
Training loss: 2.5462502491444767
Validation loss: 2.5851989874751675

Epoch: 65| Step: 0
Training loss: 2.552430068355491
Validation loss: 2.54898458222308

Epoch: 5| Step: 1
Training loss: 2.3544182657023893
Validation loss: 2.5630371375916425

Epoch: 5| Step: 2
Training loss: 2.5130638211119773
Validation loss: 2.556470320828437

Epoch: 5| Step: 3
Training loss: 2.4991585269026717
Validation loss: 2.5269428349869854

Epoch: 5| Step: 4
Training loss: 2.014513995908063
Validation loss: 2.5790236168931675

Epoch: 5| Step: 5
Training loss: 2.1500295947499843
Validation loss: 2.5845521325722833

Epoch: 5| Step: 6
Training loss: 2.7174470782983153
Validation loss: 2.5530759334323947

Epoch: 5| Step: 7
Training loss: 2.2136031078712475
Validation loss: 2.5750565697033125

Epoch: 5| Step: 8
Training loss: 2.1005034206610422
Validation loss: 2.514837437906488

Epoch: 5| Step: 9
Training loss: 2.4477873639525916
Validation loss: 2.5610878685931855

Epoch: 5| Step: 10
Training loss: 3.038855695184822
Validation loss: 2.563691060129431

Epoch: 5| Step: 11
Training loss: 2.6584655497645007
Validation loss: 2.5658931828979505

Epoch: 66| Step: 0
Training loss: 2.202783652842019
Validation loss: 2.5258655932434677

Epoch: 5| Step: 1
Training loss: 2.113185013079928
Validation loss: 2.526883617496193

Epoch: 5| Step: 2
Training loss: 3.0496434863237307
Validation loss: 2.5595120245428817

Epoch: 5| Step: 3
Training loss: 2.5177064423454696
Validation loss: 2.5779243352613697

Epoch: 5| Step: 4
Training loss: 2.717840108214757
Validation loss: 2.5607797306813604

Epoch: 5| Step: 5
Training loss: 2.072335115322856
Validation loss: 2.588687563851947

Epoch: 5| Step: 6
Training loss: 2.4132962785514067
Validation loss: 2.583661748150658

Epoch: 5| Step: 7
Training loss: 2.403166640854737
Validation loss: 2.602784722181067

Epoch: 5| Step: 8
Training loss: 2.210711248568736
Validation loss: 2.585539342493993

Epoch: 5| Step: 9
Training loss: 2.884152646240557
Validation loss: 2.5934557000916776

Epoch: 5| Step: 10
Training loss: 2.1188888189249884
Validation loss: 2.580111707208448

Epoch: 5| Step: 11
Training loss: 2.988587925950598
Validation loss: 2.5657639069769895

Epoch: 67| Step: 0
Training loss: 2.0028613602893333
Validation loss: 2.5760094179530184

Epoch: 5| Step: 1
Training loss: 2.4616051146763134
Validation loss: 2.5548593811324696

Epoch: 5| Step: 2
Training loss: 2.5223496870731807
Validation loss: 2.507356180286339

Epoch: 5| Step: 3
Training loss: 2.1188987207120715
Validation loss: 2.570818707245738

Epoch: 5| Step: 4
Training loss: 2.8286306024116867
Validation loss: 2.5588838873830584

Epoch: 5| Step: 5
Training loss: 3.073241101395979
Validation loss: 2.5197004808472148

Epoch: 5| Step: 6
Training loss: 2.37597766630035
Validation loss: 2.548033312427575

Epoch: 5| Step: 7
Training loss: 2.6610642730565783
Validation loss: 2.581824190010263

Epoch: 5| Step: 8
Training loss: 2.4214883803365104
Validation loss: 2.5451034945608337

Epoch: 5| Step: 9
Training loss: 2.239778613662568
Validation loss: 2.566714770983042

Epoch: 5| Step: 10
Training loss: 2.0309079395730856
Validation loss: 2.5756126107171924

Epoch: 5| Step: 11
Training loss: 1.8095133937688894
Validation loss: 2.5359570571229906

Epoch: 68| Step: 0
Training loss: 1.8309109969661674
Validation loss: 2.541323464053058

Epoch: 5| Step: 1
Training loss: 2.2074949604465077
Validation loss: 2.54966652285339

Epoch: 5| Step: 2
Training loss: 2.0151430485309176
Validation loss: 2.5193659015977965

Epoch: 5| Step: 3
Training loss: 2.654305947171076
Validation loss: 2.532601447061519

Epoch: 5| Step: 4
Training loss: 2.476540839163702
Validation loss: 2.5803447261259507

Epoch: 5| Step: 5
Training loss: 2.327199662413561
Validation loss: 2.617484900434943

Epoch: 5| Step: 6
Training loss: 2.4935867064894217
Validation loss: 2.5670926334051862

Epoch: 5| Step: 7
Training loss: 2.4642948561157243
Validation loss: 2.5980092432637343

Epoch: 5| Step: 8
Training loss: 3.1412298274882025
Validation loss: 2.5597462472968555

Epoch: 5| Step: 9
Training loss: 2.510315023767871
Validation loss: 2.5440076160184453

Epoch: 5| Step: 10
Training loss: 2.167339721702345
Validation loss: 2.616939202672001

Epoch: 5| Step: 11
Training loss: 2.232259001843705
Validation loss: 2.549119475217702

Epoch: 69| Step: 0
Training loss: 2.0866939016195922
Validation loss: 2.5645027611009135

Epoch: 5| Step: 1
Training loss: 2.2577555824154167
Validation loss: 2.5789883564788134

Epoch: 5| Step: 2
Training loss: 2.5660066569324465
Validation loss: 2.58398680856234

Epoch: 5| Step: 3
Training loss: 3.1328946909028255
Validation loss: 2.567462988088022

Epoch: 5| Step: 4
Training loss: 2.3102736194609816
Validation loss: 2.5849178374506403

Epoch: 5| Step: 5
Training loss: 2.0838899886003155
Validation loss: 2.553120674104734

Epoch: 5| Step: 6
Training loss: 1.9963585366283279
Validation loss: 2.5346339882483724

Epoch: 5| Step: 7
Training loss: 2.8253069584263364
Validation loss: 2.5980620447294367

Epoch: 5| Step: 8
Training loss: 2.0867172098386186
Validation loss: 2.5576099241740327

Epoch: 5| Step: 9
Training loss: 2.662729326857901
Validation loss: 2.5497620724024666

Epoch: 5| Step: 10
Training loss: 2.230914871308384
Validation loss: 2.585406956794041

Epoch: 5| Step: 11
Training loss: 2.643465128672048
Validation loss: 2.5515205710011224

Epoch: 70| Step: 0
Training loss: 2.984059581765152
Validation loss: 2.6004912736036423

Epoch: 5| Step: 1
Training loss: 1.8770118728002054
Validation loss: 2.580480035535245

Epoch: 5| Step: 2
Training loss: 2.0447331061765457
Validation loss: 2.609000378973843

Epoch: 5| Step: 3
Training loss: 1.6938771442959675
Validation loss: 2.6136080124665573

Epoch: 5| Step: 4
Training loss: 2.6883853075175117
Validation loss: 2.571429298904735

Epoch: 5| Step: 5
Training loss: 2.7520293637416886
Validation loss: 2.6129034517193603

Epoch: 5| Step: 6
Training loss: 2.578594465571738
Validation loss: 2.6055131057250303

Epoch: 5| Step: 7
Training loss: 1.9482940131538884
Validation loss: 2.597238236449901

Epoch: 5| Step: 8
Training loss: 2.2991837296976714
Validation loss: 2.601479316122333

Epoch: 5| Step: 9
Training loss: 2.526201559033644
Validation loss: 2.576087828820423

Epoch: 5| Step: 10
Training loss: 2.7449698827651274
Validation loss: 2.561058844840745

Epoch: 5| Step: 11
Training loss: 2.334311643504145
Validation loss: 2.5627707129045083

Epoch: 71| Step: 0
Training loss: 2.0846685200020056
Validation loss: 2.5778468743012186

Epoch: 5| Step: 1
Training loss: 2.6990977369196587
Validation loss: 2.540863083354238

Epoch: 5| Step: 2
Training loss: 3.2234260148376794
Validation loss: 2.5491726190631163

Epoch: 5| Step: 3
Training loss: 1.965828317094359
Validation loss: 2.561936370767218

Epoch: 5| Step: 4
Training loss: 2.6901203953911095
Validation loss: 2.5373536252490636

Epoch: 5| Step: 5
Training loss: 2.347183256057846
Validation loss: 2.579656816342808

Epoch: 5| Step: 6
Training loss: 2.606117453738074
Validation loss: 2.5812050906316366

Epoch: 5| Step: 7
Training loss: 2.5266393419799584
Validation loss: 2.5383366882525804

Epoch: 5| Step: 8
Training loss: 2.548149024264401
Validation loss: 2.5438578233666167

Epoch: 5| Step: 9
Training loss: 1.6962960901372848
Validation loss: 2.5515189435565735

Epoch: 5| Step: 10
Training loss: 2.3588969775864945
Validation loss: 2.5357231521195587

Epoch: 5| Step: 11
Training loss: 2.1568361674250536
Validation loss: 2.551507070577434

Epoch: 72| Step: 0
Training loss: 2.10258385326623
Validation loss: 2.563041129778321

Epoch: 5| Step: 1
Training loss: 2.0962734672856964
Validation loss: 2.539491666078772

Epoch: 5| Step: 2
Training loss: 2.4269470263886035
Validation loss: 2.5583449109236924

Epoch: 5| Step: 3
Training loss: 2.8820392843265283
Validation loss: 2.5247675772982805

Epoch: 5| Step: 4
Training loss: 2.401111615555688
Validation loss: 2.567613396169461

Epoch: 5| Step: 5
Training loss: 2.582315357177034
Validation loss: 2.5738758250440474

Epoch: 5| Step: 6
Training loss: 2.3651125031501934
Validation loss: 2.6024940587029994

Epoch: 5| Step: 7
Training loss: 2.765037862232204
Validation loss: 2.5864569035768237

Epoch: 5| Step: 8
Training loss: 2.0488944538387504
Validation loss: 2.584214788204319

Epoch: 5| Step: 9
Training loss: 2.1364957982545794
Validation loss: 2.576442217481992

Epoch: 5| Step: 10
Training loss: 2.601589809881526
Validation loss: 2.615116199333276

Epoch: 5| Step: 11
Training loss: 3.4222686401813704
Validation loss: 2.596560870136529

Epoch: 73| Step: 0
Training loss: 2.529156231007631
Validation loss: 2.5745581257019228

Epoch: 5| Step: 1
Training loss: 2.383682842458832
Validation loss: 2.5016396629160336

Epoch: 5| Step: 2
Training loss: 2.400644684670885
Validation loss: 2.5463903235083545

Epoch: 5| Step: 3
Training loss: 2.054331933647412
Validation loss: 2.5634981242892807

Epoch: 5| Step: 4
Training loss: 1.9025566718223796
Validation loss: 2.5618981763416926

Epoch: 5| Step: 5
Training loss: 2.4424925317718436
Validation loss: 2.552773130706895

Epoch: 5| Step: 6
Training loss: 3.164297740338946
Validation loss: 2.5416046054225516

Epoch: 5| Step: 7
Training loss: 2.121930092726999
Validation loss: 2.542677472490008

Epoch: 5| Step: 8
Training loss: 2.9760062431352
Validation loss: 2.5674652941486804

Epoch: 5| Step: 9
Training loss: 2.5232207497492825
Validation loss: 2.5469919072566665

Epoch: 5| Step: 10
Training loss: 2.0715749670077366
Validation loss: 2.5491834292983526

Epoch: 5| Step: 11
Training loss: 2.566329327828381
Validation loss: 2.55129003586507

Epoch: 74| Step: 0
Training loss: 2.245908301617339
Validation loss: 2.5288342537627377

Epoch: 5| Step: 1
Training loss: 2.0927596525663006
Validation loss: 2.527895117022796

Epoch: 5| Step: 2
Training loss: 2.041453162207933
Validation loss: 2.539440193450429

Epoch: 5| Step: 3
Training loss: 2.483094083112023
Validation loss: 2.5237604491628574

Epoch: 5| Step: 4
Training loss: 2.631444921092155
Validation loss: 2.566128425908159

Epoch: 5| Step: 5
Training loss: 2.025617801944193
Validation loss: 2.5770310556716245

Epoch: 5| Step: 6
Training loss: 2.5499650429218224
Validation loss: 2.556478582171496

Epoch: 5| Step: 7
Training loss: 2.79646690417546
Validation loss: 2.557621875635807

Epoch: 5| Step: 8
Training loss: 2.4580764851849186
Validation loss: 2.5331328810475036

Epoch: 5| Step: 9
Training loss: 2.295891272153589
Validation loss: 2.528399302561396

Epoch: 5| Step: 10
Training loss: 2.8031365401797013
Validation loss: 2.5542389051003442

Epoch: 5| Step: 11
Training loss: 1.7898340019316945
Validation loss: 2.5278000318999667

Epoch: 75| Step: 0
Training loss: 2.064615494073097
Validation loss: 2.598564941253899

Epoch: 5| Step: 1
Training loss: 2.082957450018225
Validation loss: 2.5679609485241177

Epoch: 5| Step: 2
Training loss: 2.665386150790295
Validation loss: 2.562346694206114

Epoch: 5| Step: 3
Training loss: 3.371828355015788
Validation loss: 2.593081786551937

Epoch: 5| Step: 4
Training loss: 2.161111630742333
Validation loss: 2.5857267995011926

Epoch: 5| Step: 5
Training loss: 2.2108440042413866
Validation loss: 2.598301222808538

Epoch: 5| Step: 6
Training loss: 2.257974374637537
Validation loss: 2.5577816128055284

Epoch: 5| Step: 7
Training loss: 2.6261141093056093
Validation loss: 2.5679493623981737

Epoch: 5| Step: 8
Training loss: 2.3605465033147564
Validation loss: 2.5818369836100765

Epoch: 5| Step: 9
Training loss: 2.577218746080535
Validation loss: 2.5824153997197463

Epoch: 5| Step: 10
Training loss: 2.35410564197227
Validation loss: 2.5695344429464075

Epoch: 5| Step: 11
Training loss: 1.250591710232362
Validation loss: 2.5560853888029422

Epoch: 76| Step: 0
Training loss: 2.5643132935030244
Validation loss: 2.505748596676398

Epoch: 5| Step: 1
Training loss: 1.9324806168979494
Validation loss: 2.5296499784002666

Epoch: 5| Step: 2
Training loss: 2.3736265126068377
Validation loss: 2.5073157360177323

Epoch: 5| Step: 3
Training loss: 1.9610992608089064
Validation loss: 2.5541758438078244

Epoch: 5| Step: 4
Training loss: 2.5811816042504825
Validation loss: 2.5612496411379304

Epoch: 5| Step: 5
Training loss: 2.5272742236802217
Validation loss: 2.5433710798618083

Epoch: 5| Step: 6
Training loss: 2.55938531410086
Validation loss: 2.5180754563693735

Epoch: 5| Step: 7
Training loss: 2.2626843540681985
Validation loss: 2.559923415683819

Epoch: 5| Step: 8
Training loss: 2.1610789751258412
Validation loss: 2.5774201942123782

Epoch: 5| Step: 9
Training loss: 2.8319015999418005
Validation loss: 2.5500990503995133

Epoch: 5| Step: 10
Training loss: 2.4383078972442993
Validation loss: 2.5333689113573956

Epoch: 5| Step: 11
Training loss: 2.4723243430354214
Validation loss: 2.548856759915329

Epoch: 77| Step: 0
Training loss: 2.4498523823388756
Validation loss: 2.5345958958388204

Epoch: 5| Step: 1
Training loss: 2.275738053545375
Validation loss: 2.5437695111175507

Epoch: 5| Step: 2
Training loss: 2.5399864980383824
Validation loss: 2.5340733382707956

Epoch: 5| Step: 3
Training loss: 2.8577752980125406
Validation loss: 2.541915409757102

Epoch: 5| Step: 4
Training loss: 2.1644099538449786
Validation loss: 2.5649500121190063

Epoch: 5| Step: 5
Training loss: 1.9282108479435534
Validation loss: 2.5391242699567678

Epoch: 5| Step: 6
Training loss: 2.6312412361488366
Validation loss: 2.552873957387593

Epoch: 5| Step: 7
Training loss: 2.1461729009396096
Validation loss: 2.550079714629274

Epoch: 5| Step: 8
Training loss: 2.695623672877727
Validation loss: 2.574329314030624

Epoch: 5| Step: 9
Training loss: 2.3614102105575885
Validation loss: 2.574588484735537

Epoch: 5| Step: 10
Training loss: 2.1481889060722463
Validation loss: 2.587825861666292

Epoch: 5| Step: 11
Training loss: 1.8401533704568185
Validation loss: 2.5435688230773046

Epoch: 78| Step: 0
Training loss: 2.3902827996568115
Validation loss: 2.5071637234429516

Epoch: 5| Step: 1
Training loss: 2.8574006815793846
Validation loss: 2.6007578639328037

Epoch: 5| Step: 2
Training loss: 2.190871991261079
Validation loss: 2.550787304047843

Epoch: 5| Step: 3
Training loss: 2.896291755964676
Validation loss: 2.558071112215455

Epoch: 5| Step: 4
Training loss: 2.9303853335568344
Validation loss: 2.5301052102853685

Epoch: 5| Step: 5
Training loss: 1.8448988357969527
Validation loss: 2.5663495185732437

Epoch: 5| Step: 6
Training loss: 2.0880360994251133
Validation loss: 2.560844429315655

Epoch: 5| Step: 7
Training loss: 2.0762589186098475
Validation loss: 2.600295070263826

Epoch: 5| Step: 8
Training loss: 2.392329786218922
Validation loss: 2.557340179936224

Epoch: 5| Step: 9
Training loss: 1.9282578952686524
Validation loss: 2.5402205266862965

Epoch: 5| Step: 10
Training loss: 2.402550367448608
Validation loss: 2.5161843043388

Epoch: 5| Step: 11
Training loss: 2.6903430183975843
Validation loss: 2.5450008221021023

Epoch: 79| Step: 0
Training loss: 2.7038883608733566
Validation loss: 2.4972372644473753

Epoch: 5| Step: 1
Training loss: 2.496514561004623
Validation loss: 2.5342005224725064

Epoch: 5| Step: 2
Training loss: 1.877519567720361
Validation loss: 2.5632374873015737

Epoch: 5| Step: 3
Training loss: 2.3123911239150132
Validation loss: 2.590960530822963

Epoch: 5| Step: 4
Training loss: 2.7558688049371356
Validation loss: 2.5734284750327165

Epoch: 5| Step: 5
Training loss: 2.2516584641961104
Validation loss: 2.542268651797513

Epoch: 5| Step: 6
Training loss: 2.187764506015892
Validation loss: 2.5464926590647967

Epoch: 5| Step: 7
Training loss: 2.1288984106076994
Validation loss: 2.573196308419475

Epoch: 5| Step: 8
Training loss: 2.704394268534116
Validation loss: 2.5723341090558023

Epoch: 5| Step: 9
Training loss: 2.4307558709810992
Validation loss: 2.5619527922563505

Epoch: 5| Step: 10
Training loss: 2.4606718374091368
Validation loss: 2.5957318972448933

Epoch: 5| Step: 11
Training loss: 1.3614614851004736
Validation loss: 2.5538457636741563

Epoch: 80| Step: 0
Training loss: 2.440365012335781
Validation loss: 2.5759007058382544

Epoch: 5| Step: 1
Training loss: 2.8157968483493825
Validation loss: 2.5615971998559206

Epoch: 5| Step: 2
Training loss: 2.605243816131553
Validation loss: 2.5811545383606216

Epoch: 5| Step: 3
Training loss: 3.0191833374618904
Validation loss: 2.556521470003667

Epoch: 5| Step: 4
Training loss: 1.5500177382407867
Validation loss: 2.525890256663375

Epoch: 5| Step: 5
Training loss: 2.633376335646005
Validation loss: 2.5337702367093957

Epoch: 5| Step: 6
Training loss: 2.552124417551694
Validation loss: 2.5281465720445784

Epoch: 5| Step: 7
Training loss: 2.345740426788912
Validation loss: 2.5341934193929396

Epoch: 5| Step: 8
Training loss: 1.8834056632182117
Validation loss: 2.5469353245492967

Epoch: 5| Step: 9
Training loss: 2.4758024282804545
Validation loss: 2.527723559967219

Epoch: 5| Step: 10
Training loss: 1.7726199244294798
Validation loss: 2.524518784220736

Epoch: 5| Step: 11
Training loss: 2.09523401760555
Validation loss: 2.574828099404759

Epoch: 81| Step: 0
Training loss: 2.22465149368189
Validation loss: 2.5470854861412975

Epoch: 5| Step: 1
Training loss: 2.686655311024082
Validation loss: 2.5158542623362226

Epoch: 5| Step: 2
Training loss: 2.506641150033547
Validation loss: 2.523467045031352

Epoch: 5| Step: 3
Training loss: 2.7216082927317373
Validation loss: 2.540832399549737

Epoch: 5| Step: 4
Training loss: 2.084780482896277
Validation loss: 2.557642974082641

Epoch: 5| Step: 5
Training loss: 1.9785873234402043
Validation loss: 2.5569743693134726

Epoch: 5| Step: 6
Training loss: 2.3867340337135947
Validation loss: 2.5605582773598283

Epoch: 5| Step: 7
Training loss: 2.47857401413074
Validation loss: 2.51243297177512

Epoch: 5| Step: 8
Training loss: 1.972265102773995
Validation loss: 2.5394234346951303

Epoch: 5| Step: 9
Training loss: 2.3487734048681177
Validation loss: 2.479655563543043

Epoch: 5| Step: 10
Training loss: 2.731671200884845
Validation loss: 2.5523558503576274

Epoch: 5| Step: 11
Training loss: 2.173429961640526
Validation loss: 2.55690750971078

Epoch: 82| Step: 0
Training loss: 2.4470643419693308
Validation loss: 2.5632446532934545

Epoch: 5| Step: 1
Training loss: 2.385032545143576
Validation loss: 2.5440535255695247

Epoch: 5| Step: 2
Training loss: 2.5530942095577274
Validation loss: 2.5262308751193507

Epoch: 5| Step: 3
Training loss: 2.287443766918961
Validation loss: 2.5591520015897165

Epoch: 5| Step: 4
Training loss: 2.113810079973889
Validation loss: 2.567914367725095

Epoch: 5| Step: 5
Training loss: 2.4730497170713512
Validation loss: 2.5285386253649387

Epoch: 5| Step: 6
Training loss: 2.4916113304023866
Validation loss: 2.5110430166929305

Epoch: 5| Step: 7
Training loss: 2.143232553385905
Validation loss: 2.533295162335818

Epoch: 5| Step: 8
Training loss: 3.2268123945583347
Validation loss: 2.5569162980272826

Epoch: 5| Step: 9
Training loss: 1.9553629756275632
Validation loss: 2.5535025692133755

Epoch: 5| Step: 10
Training loss: 1.7584359652802513
Validation loss: 2.5395000960989744

Epoch: 5| Step: 11
Training loss: 2.090238672892587
Validation loss: 2.5394175511096173

Epoch: 83| Step: 0
Training loss: 2.8091240860993514
Validation loss: 2.54032827664541

Epoch: 5| Step: 1
Training loss: 2.729911518130225
Validation loss: 2.614598592711117

Epoch: 5| Step: 2
Training loss: 1.8365045199443761
Validation loss: 2.5827094806573103

Epoch: 5| Step: 3
Training loss: 2.3202034767303052
Validation loss: 2.575391518663895

Epoch: 5| Step: 4
Training loss: 2.5425497199104194
Validation loss: 2.6141779187600434

Epoch: 5| Step: 5
Training loss: 2.174324027064598
Validation loss: 2.5986573396022457

Epoch: 5| Step: 6
Training loss: 2.462575990695258
Validation loss: 2.647708098458349

Epoch: 5| Step: 7
Training loss: 2.662581762213587
Validation loss: 2.6299983416033546

Epoch: 5| Step: 8
Training loss: 2.6081401164322746
Validation loss: 2.6059841235365933

Epoch: 5| Step: 9
Training loss: 1.9703819534923466
Validation loss: 2.57570449025143

Epoch: 5| Step: 10
Training loss: 2.077333801635931
Validation loss: 2.5621619776948767

Epoch: 5| Step: 11
Training loss: 2.4926503866697383
Validation loss: 2.5897481372304987

Epoch: 84| Step: 0
Training loss: 2.6199374654455894
Validation loss: 2.529610569965997

Epoch: 5| Step: 1
Training loss: 2.8404824064784617
Validation loss: 2.5295345710206183

Epoch: 5| Step: 2
Training loss: 2.4666424217407266
Validation loss: 2.525542480592056

Epoch: 5| Step: 3
Training loss: 2.2690204301555723
Validation loss: 2.5312335363095975

Epoch: 5| Step: 4
Training loss: 2.1539738015978678
Validation loss: 2.5189836720251284

Epoch: 5| Step: 5
Training loss: 2.4107238002367324
Validation loss: 2.5390234371995146

Epoch: 5| Step: 6
Training loss: 2.7711011905317537
Validation loss: 2.517162528408461

Epoch: 5| Step: 7
Training loss: 2.0078702094545693
Validation loss: 2.548601846406701

Epoch: 5| Step: 8
Training loss: 2.1216123168328873
Validation loss: 2.5323244098746964

Epoch: 5| Step: 9
Training loss: 1.9491281125203992
Validation loss: 2.5444191440759325

Epoch: 5| Step: 10
Training loss: 2.5222412675352284
Validation loss: 2.537980358652498

Epoch: 5| Step: 11
Training loss: 2.314786656808901
Validation loss: 2.5259206873969644

Epoch: 85| Step: 0
Training loss: 2.7327180910460953
Validation loss: 2.546624539937694

Epoch: 5| Step: 1
Training loss: 2.29014410823173
Validation loss: 2.549876786353093

Epoch: 5| Step: 2
Training loss: 2.666466755128831
Validation loss: 2.5094877096590773

Epoch: 5| Step: 3
Training loss: 2.205154025694934
Validation loss: 2.543702409878636

Epoch: 5| Step: 4
Training loss: 1.9425525619877586
Validation loss: 2.5457718533232256

Epoch: 5| Step: 5
Training loss: 2.3157865521992047
Validation loss: 2.560360162378959

Epoch: 5| Step: 6
Training loss: 2.0578150859981617
Validation loss: 2.554516344237915

Epoch: 5| Step: 7
Training loss: 2.3299838844036693
Validation loss: 2.5358744398962516

Epoch: 5| Step: 8
Training loss: 2.8140274986111016
Validation loss: 2.5338552160675816

Epoch: 5| Step: 9
Training loss: 2.5208611815204307
Validation loss: 2.526421549177413

Epoch: 5| Step: 10
Training loss: 1.9939359285244216
Validation loss: 2.554185781101395

Epoch: 5| Step: 11
Training loss: 1.6986750993644086
Validation loss: 2.49677226396721

Epoch: 86| Step: 0
Training loss: 2.3845283708954326
Validation loss: 2.5253160804471704

Epoch: 5| Step: 1
Training loss: 2.4796421866552305
Validation loss: 2.5777136811718098

Epoch: 5| Step: 2
Training loss: 1.755890469387148
Validation loss: 2.5449612415125373

Epoch: 5| Step: 3
Training loss: 2.8597290153437145
Validation loss: 2.556294213031545

Epoch: 5| Step: 4
Training loss: 2.4648828276666572
Validation loss: 2.540923319964567

Epoch: 5| Step: 5
Training loss: 1.9499068947108145
Validation loss: 2.561805826847605

Epoch: 5| Step: 6
Training loss: 2.350518384532525
Validation loss: 2.52529902340003

Epoch: 5| Step: 7
Training loss: 2.2141931510071657
Validation loss: 2.531775172819149

Epoch: 5| Step: 8
Training loss: 2.2282693310573918
Validation loss: 2.546731882423272

Epoch: 5| Step: 9
Training loss: 2.774066176820832
Validation loss: 2.5828973315046992

Epoch: 5| Step: 10
Training loss: 2.4427219111235337
Validation loss: 2.5408585558742782

Epoch: 5| Step: 11
Training loss: 1.5431469005638998
Validation loss: 2.564492625551857

Epoch: 87| Step: 0
Training loss: 2.0740833417872095
Validation loss: 2.5551881367667586

Epoch: 5| Step: 1
Training loss: 1.8136600202328685
Validation loss: 2.555913422988797

Epoch: 5| Step: 2
Training loss: 1.8810224452487054
Validation loss: 2.582812608002316

Epoch: 5| Step: 3
Training loss: 2.9591229598322286
Validation loss: 2.5943810258362077

Epoch: 5| Step: 4
Training loss: 3.206023007810663
Validation loss: 2.603306137322261

Epoch: 5| Step: 5
Training loss: 2.0983215072738934
Validation loss: 2.6030756050787542

Epoch: 5| Step: 6
Training loss: 2.0948205744492157
Validation loss: 2.567749167550297

Epoch: 5| Step: 7
Training loss: 2.292944003073976
Validation loss: 2.5765489635339427

Epoch: 5| Step: 8
Training loss: 2.013108686246622
Validation loss: 2.608406347760034

Epoch: 5| Step: 9
Training loss: 2.653294074216973
Validation loss: 2.6416764131801442

Epoch: 5| Step: 10
Training loss: 2.3821165975993086
Validation loss: 2.5503389949736572

Epoch: 5| Step: 11
Training loss: 3.37725599264491
Validation loss: 2.5708194491682828

Epoch: 88| Step: 0
Training loss: 2.8268720686106863
Validation loss: 2.554864797554653

Epoch: 5| Step: 1
Training loss: 2.266372241738448
Validation loss: 2.5454048133753533

Epoch: 5| Step: 2
Training loss: 2.147931181460553
Validation loss: 2.5216153615845087

Epoch: 5| Step: 3
Training loss: 1.871912512299876
Validation loss: 2.5566815090577535

Epoch: 5| Step: 4
Training loss: 2.797394603008558
Validation loss: 2.555009691334489

Epoch: 5| Step: 5
Training loss: 2.4108980542736735
Validation loss: 2.5731841320266495

Epoch: 5| Step: 6
Training loss: 1.8759431374315985
Validation loss: 2.5230974533193793

Epoch: 5| Step: 7
Training loss: 2.3153457658571024
Validation loss: 2.5408839378080255

Epoch: 5| Step: 8
Training loss: 2.0801787589359764
Validation loss: 2.489676820257995

Epoch: 5| Step: 9
Training loss: 2.8030503789353065
Validation loss: 2.5720862864601943

Epoch: 5| Step: 10
Training loss: 1.9846120377388965
Validation loss: 2.537350132937284

Epoch: 5| Step: 11
Training loss: 2.314897480089076
Validation loss: 2.5456300942063805

Epoch: 89| Step: 0
Training loss: 2.8686129069762623
Validation loss: 2.52796586804672

Epoch: 5| Step: 1
Training loss: 2.2316128390342005
Validation loss: 2.569041711945643

Epoch: 5| Step: 2
Training loss: 2.4768488865798624
Validation loss: 2.557381697634782

Epoch: 5| Step: 3
Training loss: 2.287022120686959
Validation loss: 2.5075645264759765

Epoch: 5| Step: 4
Training loss: 2.2858409931621466
Validation loss: 2.5671138745904707

Epoch: 5| Step: 5
Training loss: 2.664425911825231
Validation loss: 2.559903579782981

Epoch: 5| Step: 6
Training loss: 2.0724537266994174
Validation loss: 2.5647327418826413

Epoch: 5| Step: 7
Training loss: 2.5541485792539134
Validation loss: 2.5977949062427577

Epoch: 5| Step: 8
Training loss: 1.799064562705088
Validation loss: 2.567038451914191

Epoch: 5| Step: 9
Training loss: 2.659497956818959
Validation loss: 2.556411231629313

Epoch: 5| Step: 10
Training loss: 1.7750832068054623
Validation loss: 2.5495833991580046

Epoch: 5| Step: 11
Training loss: 3.5028119371849176
Validation loss: 2.545604185935099

Epoch: 90| Step: 0
Training loss: 2.4679109137298068
Validation loss: 2.524558622351884

Epoch: 5| Step: 1
Training loss: 2.5179536833802065
Validation loss: 2.5017352281036924

Epoch: 5| Step: 2
Training loss: 2.0853259158006603
Validation loss: 2.5117623190415883

Epoch: 5| Step: 3
Training loss: 2.0945016451219267
Validation loss: 2.5089524828274485

Epoch: 5| Step: 4
Training loss: 2.4513151453709594
Validation loss: 2.5123363267591303

Epoch: 5| Step: 5
Training loss: 3.106311765244749
Validation loss: 2.532613336105127

Epoch: 5| Step: 6
Training loss: 2.211675514006101
Validation loss: 2.5481107791207203

Epoch: 5| Step: 7
Training loss: 2.2282626972211217
Validation loss: 2.543120216120754

Epoch: 5| Step: 8
Training loss: 2.381379543995928
Validation loss: 2.5562586721259195

Epoch: 5| Step: 9
Training loss: 2.043034685577058
Validation loss: 2.5362361533882307

Epoch: 5| Step: 10
Training loss: 2.224658352628374
Validation loss: 2.5507441893334453

Epoch: 5| Step: 11
Training loss: 2.058976371284956
Validation loss: 2.535057544011243

Epoch: 91| Step: 0
Training loss: 2.254501290671867
Validation loss: 2.5088349908960823

Epoch: 5| Step: 1
Training loss: 1.9732564183121966
Validation loss: 2.5374039695996946

Epoch: 5| Step: 2
Training loss: 2.628286030629328
Validation loss: 2.5377549546040914

Epoch: 5| Step: 3
Training loss: 2.996385940568068
Validation loss: 2.5282116657015097

Epoch: 5| Step: 4
Training loss: 2.4616333961519903
Validation loss: 2.522356299694996

Epoch: 5| Step: 5
Training loss: 2.7991402259691585
Validation loss: 2.5389695996626402

Epoch: 5| Step: 6
Training loss: 1.8610815343198897
Validation loss: 2.5230484259986943

Epoch: 5| Step: 7
Training loss: 2.3376146502605586
Validation loss: 2.4798506880363433

Epoch: 5| Step: 8
Training loss: 1.9446582843119045
Validation loss: 2.567885778974734

Epoch: 5| Step: 9
Training loss: 2.379268825317442
Validation loss: 2.544567904248852

Epoch: 5| Step: 10
Training loss: 2.0707156382630423
Validation loss: 2.509031389748096

Epoch: 5| Step: 11
Training loss: 1.8519832599781396
Validation loss: 2.5842044551103487

Epoch: 92| Step: 0
Training loss: 1.9522716031095007
Validation loss: 2.5250462697765825

Epoch: 5| Step: 1
Training loss: 2.244952686550399
Validation loss: 2.5381730502459523

Epoch: 5| Step: 2
Training loss: 2.4493118098100135
Validation loss: 2.522811489186139

Epoch: 5| Step: 3
Training loss: 2.2850087175265577
Validation loss: 2.5528853901268738

Epoch: 5| Step: 4
Training loss: 2.373007490671121
Validation loss: 2.5237061758079764

Epoch: 5| Step: 5
Training loss: 2.2208217565677306
Validation loss: 2.530691426659084

Epoch: 5| Step: 6
Training loss: 2.119873370221421
Validation loss: 2.5413357286023746

Epoch: 5| Step: 7
Training loss: 2.1138710989797382
Validation loss: 2.5201368446887247

Epoch: 5| Step: 8
Training loss: 2.232607375720665
Validation loss: 2.5237436256498236

Epoch: 5| Step: 9
Training loss: 3.3040228281225423
Validation loss: 2.5559083275001364

Epoch: 5| Step: 10
Training loss: 2.1835259442387716
Validation loss: 2.508585421567081

Epoch: 5| Step: 11
Training loss: 1.4109969657795034
Validation loss: 2.5475110116046165

Epoch: 93| Step: 0
Training loss: 1.6392728774170369
Validation loss: 2.5822302067869938

Epoch: 5| Step: 1
Training loss: 2.177782107800874
Validation loss: 2.552584249941163

Epoch: 5| Step: 2
Training loss: 2.470134491753158
Validation loss: 2.4718098188568334

Epoch: 5| Step: 3
Training loss: 1.8462349261764244
Validation loss: 2.5357222236333796

Epoch: 5| Step: 4
Training loss: 2.4284358587812944
Validation loss: 2.527970654397512

Epoch: 5| Step: 5
Training loss: 2.185692285467959
Validation loss: 2.527029001171316

Epoch: 5| Step: 6
Training loss: 2.9161788169129674
Validation loss: 2.5614140000345627

Epoch: 5| Step: 7
Training loss: 2.5450251127251877
Validation loss: 2.5454700432923336

Epoch: 5| Step: 8
Training loss: 2.0419746737502167
Validation loss: 2.570979626005466

Epoch: 5| Step: 9
Training loss: 2.2972945264851123
Validation loss: 2.5349377546311627

Epoch: 5| Step: 10
Training loss: 2.772758465234713
Validation loss: 2.5091591068759103

Epoch: 5| Step: 11
Training loss: 2.0379633370827497
Validation loss: 2.5133796132714874

Epoch: 94| Step: 0
Training loss: 2.332768053882102
Validation loss: 2.5834643339710217

Epoch: 5| Step: 1
Training loss: 2.079151559697108
Validation loss: 2.520075937778232

Epoch: 5| Step: 2
Training loss: 2.231926917393892
Validation loss: 2.5580995232812205

Epoch: 5| Step: 3
Training loss: 2.6186681402335648
Validation loss: 2.546399265159647

Epoch: 5| Step: 4
Training loss: 2.530729734854207
Validation loss: 2.517454834358958

Epoch: 5| Step: 5
Training loss: 2.235446379630886
Validation loss: 2.5716997092277785

Epoch: 5| Step: 6
Training loss: 2.3466370158417456
Validation loss: 2.5231174328998986

Epoch: 5| Step: 7
Training loss: 2.467588803472175
Validation loss: 2.5553070837461633

Epoch: 5| Step: 8
Training loss: 2.4499826897768684
Validation loss: 2.569295610521945

Epoch: 5| Step: 9
Training loss: 1.5862868351789075
Validation loss: 2.5460169620333457

Epoch: 5| Step: 10
Training loss: 2.338797665002739
Validation loss: 2.5689472797186825

Epoch: 5| Step: 11
Training loss: 2.9837764119712022
Validation loss: 2.499643236771376

Epoch: 95| Step: 0
Training loss: 2.2339197508657525
Validation loss: 2.541628228871432

Epoch: 5| Step: 1
Training loss: 2.14284539446562
Validation loss: 2.5543702849228014

Epoch: 5| Step: 2
Training loss: 2.382928263869538
Validation loss: 2.5343013374075065

Epoch: 5| Step: 3
Training loss: 2.1924872086781453
Validation loss: 2.526766281151088

Epoch: 5| Step: 4
Training loss: 2.6286222806152137
Validation loss: 2.5350748292988015

Epoch: 5| Step: 5
Training loss: 2.545500401913655
Validation loss: 2.5469636726155143

Epoch: 5| Step: 6
Training loss: 2.3243572290022754
Validation loss: 2.488564942704688

Epoch: 5| Step: 7
Training loss: 2.247976134618147
Validation loss: 2.5117577311969925

Epoch: 5| Step: 8
Training loss: 2.1964574251483917
Validation loss: 2.5186695448881027

Epoch: 5| Step: 9
Training loss: 1.9994626515461544
Validation loss: 2.5235879733137

Epoch: 5| Step: 10
Training loss: 2.5084320919158682
Validation loss: 2.5567398265751726

Epoch: 5| Step: 11
Training loss: 0.870693919020632
Validation loss: 2.510389798101045

Epoch: 96| Step: 0
Training loss: 1.610173962239772
Validation loss: 2.5769572300897767

Epoch: 5| Step: 1
Training loss: 1.9837056029651248
Validation loss: 2.4827008154436405

Epoch: 5| Step: 2
Training loss: 2.341145607025735
Validation loss: 2.5086083303142863

Epoch: 5| Step: 3
Training loss: 2.0627503676607764
Validation loss: 2.5039651420439966

Epoch: 5| Step: 4
Training loss: 2.3286984140740374
Validation loss: 2.575149564658561

Epoch: 5| Step: 5
Training loss: 2.0676830940403734
Validation loss: 2.512236850711073

Epoch: 5| Step: 6
Training loss: 3.1314464454170596
Validation loss: 2.5729978924386954

Epoch: 5| Step: 7
Training loss: 2.4804513525164986
Validation loss: 2.528777201913681

Epoch: 5| Step: 8
Training loss: 2.601846215526207
Validation loss: 2.534666640109186

Epoch: 5| Step: 9
Training loss: 2.368536939072407
Validation loss: 2.5637559449070983

Epoch: 5| Step: 10
Training loss: 1.8673519556891292
Validation loss: 2.5200968578182548

Epoch: 5| Step: 11
Training loss: 2.633866186996488
Validation loss: 2.4926358360803738

Epoch: 97| Step: 0
Training loss: 2.381887387654131
Validation loss: 2.581916344837265

Epoch: 5| Step: 1
Training loss: 2.939854429105471
Validation loss: 2.5488296255445873

Epoch: 5| Step: 2
Training loss: 2.2482811402224003
Validation loss: 2.566548982673899

Epoch: 5| Step: 3
Training loss: 2.0425925847597886
Validation loss: 2.555498976155997

Epoch: 5| Step: 4
Training loss: 2.3374542109446637
Validation loss: 2.4793618523406424

Epoch: 5| Step: 5
Training loss: 2.152060488357736
Validation loss: 2.534973204538205

Epoch: 5| Step: 6
Training loss: 2.0620299294905364
Validation loss: 2.5158576166714837

Epoch: 5| Step: 7
Training loss: 2.7936101857131854
Validation loss: 2.5286585489589144

Epoch: 5| Step: 8
Training loss: 1.7690462706764314
Validation loss: 2.5112692478683476

Epoch: 5| Step: 9
Training loss: 2.3365437923272774
Validation loss: 2.542281038782624

Epoch: 5| Step: 10
Training loss: 2.459728513173864
Validation loss: 2.515656247942016

Epoch: 5| Step: 11
Training loss: 1.9425719539713842
Validation loss: 2.4995238963408832

Epoch: 98| Step: 0
Training loss: 2.4351997281043043
Validation loss: 2.555644899052766

Epoch: 5| Step: 1
Training loss: 2.0713839079828946
Validation loss: 2.5103237753548835

Epoch: 5| Step: 2
Training loss: 2.1958363406928627
Validation loss: 2.5339629544267703

Epoch: 5| Step: 3
Training loss: 2.1053720427262865
Validation loss: 2.514958062229913

Epoch: 5| Step: 4
Training loss: 2.840300595399896
Validation loss: 2.579431653520187

Epoch: 5| Step: 5
Training loss: 2.320156927063066
Validation loss: 2.5719967071300527

Epoch: 5| Step: 6
Training loss: 2.125689226462796
Validation loss: 2.5875199346342668

Epoch: 5| Step: 7
Training loss: 1.9785022490370285
Validation loss: 2.523735418537371

Epoch: 5| Step: 8
Training loss: 1.4521202797843777
Validation loss: 2.5513158202040813

Epoch: 5| Step: 9
Training loss: 2.579699780939215
Validation loss: 2.5275050155547123

Epoch: 5| Step: 10
Training loss: 2.72851265406737
Validation loss: 2.5533240760128275

Epoch: 5| Step: 11
Training loss: 2.1314958134179873
Validation loss: 2.553754739282374

Epoch: 99| Step: 0
Training loss: 2.29434615035742
Validation loss: 2.5980168830816366

Epoch: 5| Step: 1
Training loss: 2.81335859968341
Validation loss: 2.580772731861101

Epoch: 5| Step: 2
Training loss: 2.0474474157490756
Validation loss: 2.609666480651727

Epoch: 5| Step: 3
Training loss: 1.8254660808135899
Validation loss: 2.6093510000377704

Epoch: 5| Step: 4
Training loss: 2.4614245704749305
Validation loss: 2.5350081797786967

Epoch: 5| Step: 5
Training loss: 2.4607144693702407
Validation loss: 2.5313739863983216

Epoch: 5| Step: 6
Training loss: 1.838249147250765
Validation loss: 2.599122572903281

Epoch: 5| Step: 7
Training loss: 2.854540463958424
Validation loss: 2.5583715599592227

Epoch: 5| Step: 8
Training loss: 2.128534071001062
Validation loss: 2.5574959960128054

Epoch: 5| Step: 9
Training loss: 2.077397154501401
Validation loss: 2.5156880799276795

Epoch: 5| Step: 10
Training loss: 2.1351465442044657
Validation loss: 2.550217251156061

Epoch: 5| Step: 11
Training loss: 2.1440654867262916
Validation loss: 2.5027897012127593

Epoch: 100| Step: 0
Training loss: 1.9600552097641246
Validation loss: 2.5439002757317337

Epoch: 5| Step: 1
Training loss: 2.4965264030479877
Validation loss: 2.5033272675393325

Epoch: 5| Step: 2
Training loss: 2.113515675176389
Validation loss: 2.528365131725983

Epoch: 5| Step: 3
Training loss: 2.590498943506087
Validation loss: 2.5257696116657478

Epoch: 5| Step: 4
Training loss: 2.2870785184190905
Validation loss: 2.4926088907630484

Epoch: 5| Step: 5
Training loss: 2.0646612230294217
Validation loss: 2.4996400415043927

Epoch: 5| Step: 6
Training loss: 2.09430174888163
Validation loss: 2.505579158965943

Epoch: 5| Step: 7
Training loss: 1.7991260526218436
Validation loss: 2.4835601805971885

Epoch: 5| Step: 8
Training loss: 2.6044141016076128
Validation loss: 2.5359336668100334

Epoch: 5| Step: 9
Training loss: 2.227218370712087
Validation loss: 2.49134300935583

Epoch: 5| Step: 10
Training loss: 2.6695584968692456
Validation loss: 2.531746156362059

Epoch: 5| Step: 11
Training loss: 1.7852708374909956
Validation loss: 2.5410421312900997

Testing loss: 2.181196321907128
