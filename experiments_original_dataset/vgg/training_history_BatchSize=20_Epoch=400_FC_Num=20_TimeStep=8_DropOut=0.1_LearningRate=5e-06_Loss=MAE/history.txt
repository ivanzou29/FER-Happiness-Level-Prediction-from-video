Epoch: 1| Step: 0
Training loss: 8.548585891723633
Validation loss: 8.687580724557241

Epoch: 5| Step: 1
Training loss: 8.460744857788086
Validation loss: 8.676265438397726

Epoch: 5| Step: 2
Training loss: 8.897738456726074
Validation loss: 8.665561437606812

Epoch: 5| Step: 3
Training loss: 9.543224334716797
Validation loss: 8.655919790267944

Epoch: 5| Step: 4
Training loss: 7.924506187438965
Validation loss: 8.646830956141153

Epoch: 5| Step: 5
Training loss: 8.672016143798828
Validation loss: 8.638836105664572

Epoch: 5| Step: 6
Training loss: 9.10456371307373
Validation loss: 8.630496899286905

Epoch: 5| Step: 7
Training loss: 8.061498641967773
Validation loss: 8.622514526049295

Epoch: 5| Step: 8
Training loss: 8.415913581848145
Validation loss: 8.615659515062967

Epoch: 5| Step: 9
Training loss: 9.282767295837402
Validation loss: 8.607011576493582

Epoch: 5| Step: 10
Training loss: 8.798799514770508
Validation loss: 8.599032600720724

Epoch: 5| Step: 11
Training loss: 9.07432746887207
Validation loss: 8.589332818984985

Epoch: 2| Step: 0
Training loss: 7.5516839027404785
Validation loss: 8.580586155255636

Epoch: 5| Step: 1
Training loss: 9.687891960144043
Validation loss: 8.571431597073873

Epoch: 5| Step: 2
Training loss: 8.461047172546387
Validation loss: 8.562350869178772

Epoch: 5| Step: 3
Training loss: 7.459846496582031
Validation loss: 8.550168434778849

Epoch: 5| Step: 4
Training loss: 8.404191017150879
Validation loss: 8.540440758069357

Epoch: 5| Step: 5
Training loss: 9.408239364624023
Validation loss: 8.529522021611532

Epoch: 5| Step: 6
Training loss: 8.991157531738281
Validation loss: 8.516609191894531

Epoch: 5| Step: 7
Training loss: 9.005134582519531
Validation loss: 8.502158363660177

Epoch: 5| Step: 8
Training loss: 10.026119232177734
Validation loss: 8.489053130149841

Epoch: 5| Step: 9
Training loss: 7.952140808105469
Validation loss: 8.476959904034933

Epoch: 5| Step: 10
Training loss: 8.079087257385254
Validation loss: 8.462053894996643

Epoch: 5| Step: 11
Training loss: 6.137038230895996
Validation loss: 8.448893010616302

Epoch: 3| Step: 0
Training loss: 7.6947922706604
Validation loss: 8.43459838628769

Epoch: 5| Step: 1
Training loss: 9.210988998413086
Validation loss: 8.418408373991648

Epoch: 5| Step: 2
Training loss: 9.721817016601562
Validation loss: 8.402369697888693

Epoch: 5| Step: 3
Training loss: 7.953797340393066
Validation loss: 8.38622643550237

Epoch: 5| Step: 4
Training loss: 8.581745147705078
Validation loss: 8.368474761644999

Epoch: 5| Step: 5
Training loss: 8.58424186706543
Validation loss: 8.353266616662344

Epoch: 5| Step: 6
Training loss: 8.43712329864502
Validation loss: 8.33194331328074

Epoch: 5| Step: 7
Training loss: 9.62919807434082
Validation loss: 8.316252330938974

Epoch: 5| Step: 8
Training loss: 8.465425491333008
Validation loss: 8.297802488009134

Epoch: 5| Step: 9
Training loss: 7.213810920715332
Validation loss: 8.277365942796072

Epoch: 5| Step: 10
Training loss: 7.409863471984863
Validation loss: 8.254852453867594

Epoch: 5| Step: 11
Training loss: 6.865483283996582
Validation loss: 8.234363893667856

Epoch: 4| Step: 0
Training loss: 8.396112442016602
Validation loss: 8.2130233446757

Epoch: 5| Step: 1
Training loss: 8.878524780273438
Validation loss: 8.189353704452515

Epoch: 5| Step: 2
Training loss: 9.386030197143555
Validation loss: 8.169030169645945

Epoch: 5| Step: 3
Training loss: 8.601740837097168
Validation loss: 8.143470466136932

Epoch: 5| Step: 4
Training loss: 7.4603705406188965
Validation loss: 8.120326360066732

Epoch: 5| Step: 5
Training loss: 7.962458610534668
Validation loss: 8.093084792296091

Epoch: 5| Step: 6
Training loss: 7.631352424621582
Validation loss: 8.068204601605734

Epoch: 5| Step: 7
Training loss: 7.300940036773682
Validation loss: 8.042124509811401

Epoch: 5| Step: 8
Training loss: 8.038338661193848
Validation loss: 8.014926989873251

Epoch: 5| Step: 9
Training loss: 7.990107536315918
Validation loss: 7.9929922223091125

Epoch: 5| Step: 10
Training loss: 7.795103549957275
Validation loss: 7.961270034313202

Epoch: 5| Step: 11
Training loss: 9.885110855102539
Validation loss: 7.934517065684001

Epoch: 5| Step: 0
Training loss: 7.021205902099609
Validation loss: 7.907179991404216

Epoch: 5| Step: 1
Training loss: 7.017186164855957
Validation loss: 7.874090790748596

Epoch: 5| Step: 2
Training loss: 7.958154201507568
Validation loss: 7.844114184379578

Epoch: 5| Step: 3
Training loss: 7.514620780944824
Validation loss: 7.816908657550812

Epoch: 5| Step: 4
Training loss: 8.5158109664917
Validation loss: 7.78434419631958

Epoch: 5| Step: 5
Training loss: 7.384590148925781
Validation loss: 7.764433403809865

Epoch: 5| Step: 6
Training loss: 9.267483711242676
Validation loss: 7.729030390580495

Epoch: 5| Step: 7
Training loss: 7.461468696594238
Validation loss: 7.698136528333028

Epoch: 5| Step: 8
Training loss: 9.172860145568848
Validation loss: 7.65981109937032

Epoch: 5| Step: 9
Training loss: 7.6104536056518555
Validation loss: 7.637947499752045

Epoch: 5| Step: 10
Training loss: 6.943028450012207
Validation loss: 7.596166928609212

Epoch: 5| Step: 11
Training loss: 9.331089973449707
Validation loss: 7.566068768501282

Epoch: 6| Step: 0
Training loss: 8.284902572631836
Validation loss: 7.530673623085022

Epoch: 5| Step: 1
Training loss: 7.358071804046631
Validation loss: 7.493011911710103

Epoch: 5| Step: 2
Training loss: 7.20056676864624
Validation loss: 7.450213372707367

Epoch: 5| Step: 3
Training loss: 7.8335700035095215
Validation loss: 7.415778875350952

Epoch: 5| Step: 4
Training loss: 8.376967430114746
Validation loss: 7.3706560532252

Epoch: 5| Step: 5
Training loss: 7.2395172119140625
Validation loss: 7.329782803853353

Epoch: 5| Step: 6
Training loss: 7.340718746185303
Validation loss: 7.288386225700378

Epoch: 5| Step: 7
Training loss: 7.170323371887207
Validation loss: 7.22981862227122

Epoch: 5| Step: 8
Training loss: 7.5258469581604
Validation loss: 7.1830452879269915

Epoch: 5| Step: 9
Training loss: 6.680591583251953
Validation loss: 7.1113987763722735

Epoch: 5| Step: 10
Training loss: 6.519195556640625
Validation loss: 7.068794270356496

Epoch: 5| Step: 11
Training loss: 6.631913185119629
Validation loss: 7.01441075404485

Epoch: 7| Step: 0
Training loss: 7.055432319641113
Validation loss: 6.94196742773056

Epoch: 5| Step: 1
Training loss: 7.787388801574707
Validation loss: 6.890904466311137

Epoch: 5| Step: 2
Training loss: 7.439435005187988
Validation loss: 6.81005613009135

Epoch: 5| Step: 3
Training loss: 5.784230709075928
Validation loss: 6.738051573435466

Epoch: 5| Step: 4
Training loss: 6.088259696960449
Validation loss: 6.671630362669627

Epoch: 5| Step: 5
Training loss: 6.552310943603516
Validation loss: 6.587888876597087

Epoch: 5| Step: 6
Training loss: 6.621188163757324
Validation loss: 6.502543290456136

Epoch: 5| Step: 7
Training loss: 6.3799824714660645
Validation loss: 6.416184326012929

Epoch: 5| Step: 8
Training loss: 6.391825199127197
Validation loss: 6.317725936571757

Epoch: 5| Step: 9
Training loss: 6.940237998962402
Validation loss: 6.224314987659454

Epoch: 5| Step: 10
Training loss: 6.019688606262207
Validation loss: 6.114681680997212

Epoch: 5| Step: 11
Training loss: 6.287130355834961
Validation loss: 6.016135553518931

Epoch: 8| Step: 0
Training loss: 4.957594871520996
Validation loss: 5.903207918008168

Epoch: 5| Step: 1
Training loss: 4.699427604675293
Validation loss: 5.767403542995453

Epoch: 5| Step: 2
Training loss: 6.254435062408447
Validation loss: 5.628645757834117

Epoch: 5| Step: 3
Training loss: 5.539586067199707
Validation loss: 5.474255323410034

Epoch: 5| Step: 4
Training loss: 6.184365749359131
Validation loss: 5.353518009185791

Epoch: 5| Step: 5
Training loss: 6.573822975158691
Validation loss: 5.198160290718079

Epoch: 5| Step: 6
Training loss: 5.419325351715088
Validation loss: 5.0481305321057635

Epoch: 5| Step: 7
Training loss: 5.308798789978027
Validation loss: 4.862285514672597

Epoch: 5| Step: 8
Training loss: 4.958876609802246
Validation loss: 4.723846872647603

Epoch: 5| Step: 9
Training loss: 3.840076446533203
Validation loss: 4.517917136351268

Epoch: 5| Step: 10
Training loss: 4.118056297302246
Validation loss: 4.372466832399368

Epoch: 5| Step: 11
Training loss: 5.053279876708984
Validation loss: 4.157679736614227

Epoch: 9| Step: 0
Training loss: 3.2329204082489014
Validation loss: 3.979444593191147

Epoch: 5| Step: 1
Training loss: 3.5851402282714844
Validation loss: 3.8263198733329773

Epoch: 5| Step: 2
Training loss: 3.6049060821533203
Validation loss: 3.6722144285837808

Epoch: 5| Step: 3
Training loss: 3.7720234394073486
Validation loss: 3.465674877166748

Epoch: 5| Step: 4
Training loss: 3.93176531791687
Validation loss: 3.2589887281258902

Epoch: 5| Step: 5
Training loss: 3.115835666656494
Validation loss: 3.0651824176311493

Epoch: 5| Step: 6
Training loss: 2.7861838340759277
Validation loss: 2.960238993167877

Epoch: 5| Step: 7
Training loss: 2.5279297828674316
Validation loss: 2.8365072111288705

Epoch: 5| Step: 8
Training loss: 2.2665648460388184
Validation loss: 2.7005763153235116

Epoch: 5| Step: 9
Training loss: 2.646540641784668
Validation loss: 2.5665062765280404

Epoch: 5| Step: 10
Training loss: 2.790426731109619
Validation loss: 2.4043364028135934

Epoch: 5| Step: 11
Training loss: 1.0192972421646118
Validation loss: 2.3386112451553345

Epoch: 10| Step: 0
Training loss: 1.710646629333496
Validation loss: 2.3480800688266754

Epoch: 5| Step: 1
Training loss: 2.2810027599334717
Validation loss: 2.342355082432429

Epoch: 5| Step: 2
Training loss: 2.2698092460632324
Validation loss: 2.334420452515284

Epoch: 5| Step: 3
Training loss: 2.483618974685669
Validation loss: 2.4696481625239053

Epoch: 5| Step: 4
Training loss: 2.5574631690979004
Validation loss: 2.502959201733271

Epoch: 5| Step: 5
Training loss: 2.685377359390259
Validation loss: 2.5468978385130563

Epoch: 5| Step: 6
Training loss: 2.01796817779541
Validation loss: 2.5828124483426413

Epoch: 5| Step: 7
Training loss: 3.040313482284546
Validation loss: 2.4808590759833655

Epoch: 5| Step: 8
Training loss: 2.295073986053467
Validation loss: 2.460467666387558

Epoch: 5| Step: 9
Training loss: 2.760704517364502
Validation loss: 2.3523759494225183

Epoch: 5| Step: 10
Training loss: 2.7153682708740234
Validation loss: 2.275983919699987

Epoch: 5| Step: 11
Training loss: 3.0071909427642822
Validation loss: 2.2725617388884225

Epoch: 11| Step: 0
Training loss: 1.9637775421142578
Validation loss: 2.3483261366685233

Epoch: 5| Step: 1
Training loss: 2.268825054168701
Validation loss: 2.390796735882759

Epoch: 5| Step: 2
Training loss: 2.6081748008728027
Validation loss: 2.2632881303628287

Epoch: 5| Step: 3
Training loss: 1.654543161392212
Validation loss: 2.2512714117765427

Epoch: 5| Step: 4
Training loss: 2.0373153686523438
Validation loss: 2.2860994935035706

Epoch: 5| Step: 5
Training loss: 2.482701539993286
Validation loss: 2.3049601962169013

Epoch: 5| Step: 6
Training loss: 2.779463529586792
Validation loss: 2.391119137406349

Epoch: 5| Step: 7
Training loss: 2.3116767406463623
Validation loss: 2.407352233926455

Epoch: 5| Step: 8
Training loss: 1.9770805835723877
Validation loss: 2.3382067680358887

Epoch: 5| Step: 9
Training loss: 1.635157585144043
Validation loss: 2.3290650943915048

Epoch: 5| Step: 10
Training loss: 2.59293794631958
Validation loss: 2.288100635011991

Epoch: 5| Step: 11
Training loss: 2.114309310913086
Validation loss: 2.3333932161331177

Epoch: 12| Step: 0
Training loss: 2.050971508026123
Validation loss: 2.3121916155020394

Epoch: 5| Step: 1
Training loss: 1.768466591835022
Validation loss: 2.244448925058047

Epoch: 5| Step: 2
Training loss: 2.817269802093506
Validation loss: 2.4018478095531464

Epoch: 5| Step: 3
Training loss: 2.8345744609832764
Validation loss: 2.340093493461609

Epoch: 5| Step: 4
Training loss: 2.238602876663208
Validation loss: 2.3978196730216346

Epoch: 5| Step: 5
Training loss: 2.182711601257324
Validation loss: 2.3289862076441445

Epoch: 5| Step: 6
Training loss: 2.879728317260742
Validation loss: 2.360627000530561

Epoch: 5| Step: 7
Training loss: 2.6614036560058594
Validation loss: 2.2939486652612686

Epoch: 5| Step: 8
Training loss: 1.8920307159423828
Validation loss: 2.2702321658531823

Epoch: 5| Step: 9
Training loss: 1.604012131690979
Validation loss: 2.262513150771459

Epoch: 5| Step: 10
Training loss: 1.7118523120880127
Validation loss: 2.355796938141187

Epoch: 5| Step: 11
Training loss: 0.7300781011581421
Validation loss: 2.2990738252798715

Epoch: 13| Step: 0
Training loss: 2.2928366661071777
Validation loss: 2.333634063601494

Epoch: 5| Step: 1
Training loss: 2.3396968841552734
Validation loss: 2.283536672592163

Epoch: 5| Step: 2
Training loss: 1.8483734130859375
Validation loss: 2.2839752435684204

Epoch: 5| Step: 3
Training loss: 1.9112720489501953
Validation loss: 2.2905899782975516

Epoch: 5| Step: 4
Training loss: 2.197087049484253
Validation loss: 2.3225852449735007

Epoch: 5| Step: 5
Training loss: 2.6643612384796143
Validation loss: 2.2756399710973105

Epoch: 5| Step: 6
Training loss: 2.8305795192718506
Validation loss: 2.3584957222143808

Epoch: 5| Step: 7
Training loss: 2.311699390411377
Validation loss: 2.2614213128884635

Epoch: 5| Step: 8
Training loss: 2.530580520629883
Validation loss: 2.3172471026579538

Epoch: 5| Step: 9
Training loss: 2.583862781524658
Validation loss: 2.3547686090071998

Epoch: 5| Step: 10
Training loss: 2.0502164363861084
Validation loss: 2.2439845701058707

Epoch: 5| Step: 11
Training loss: 1.6706745624542236
Validation loss: 2.2636689841747284

Epoch: 14| Step: 0
Training loss: 1.664908766746521
Validation loss: 2.3017816245555878

Epoch: 5| Step: 1
Training loss: 2.043161153793335
Validation loss: 2.2323718667030334

Epoch: 5| Step: 2
Training loss: 2.494626522064209
Validation loss: 2.312004675467809

Epoch: 5| Step: 3
Training loss: 2.2559256553649902
Validation loss: 2.371045152346293

Epoch: 5| Step: 4
Training loss: 1.9398038387298584
Validation loss: 2.2533238232135773

Epoch: 5| Step: 5
Training loss: 2.356849431991577
Validation loss: 2.307282254099846

Epoch: 5| Step: 6
Training loss: 2.054427146911621
Validation loss: 2.3655814627806344

Epoch: 5| Step: 7
Training loss: 2.7429351806640625
Validation loss: 2.2624739706516266

Epoch: 5| Step: 8
Training loss: 1.8117297887802124
Validation loss: 2.292662873864174

Epoch: 5| Step: 9
Training loss: 2.657287120819092
Validation loss: 2.250428761045138

Epoch: 5| Step: 10
Training loss: 2.0776143074035645
Validation loss: 2.287180721759796

Epoch: 5| Step: 11
Training loss: 1.3956010341644287
Validation loss: 2.284797469774882

Epoch: 15| Step: 0
Training loss: 1.6207252740859985
Validation loss: 2.286093056201935

Epoch: 5| Step: 1
Training loss: 2.1987147331237793
Validation loss: 2.2331387947003045

Epoch: 5| Step: 2
Training loss: 2.578662872314453
Validation loss: 2.3197653045256934

Epoch: 5| Step: 3
Training loss: 2.4775121212005615
Validation loss: 2.2860197722911835

Epoch: 5| Step: 4
Training loss: 1.8244903087615967
Validation loss: 2.2449503342310586

Epoch: 5| Step: 5
Training loss: 1.7057263851165771
Validation loss: 2.313710937897364

Epoch: 5| Step: 6
Training loss: 2.388226270675659
Validation loss: 2.2689343194166818

Epoch: 5| Step: 7
Training loss: 2.4038825035095215
Validation loss: 2.184421574076017

Epoch: 5| Step: 8
Training loss: 2.1007981300354004
Validation loss: 2.200681353608767

Epoch: 5| Step: 9
Training loss: 2.208329916000366
Validation loss: 2.2564080208539963

Epoch: 5| Step: 10
Training loss: 2.5783767700195312
Validation loss: 2.2818289697170258

Epoch: 5| Step: 11
Training loss: 2.9581613540649414
Validation loss: 2.319621125857035

Epoch: 16| Step: 0
Training loss: 2.3459866046905518
Validation loss: 2.2143726150194802

Epoch: 5| Step: 1
Training loss: 1.7543483972549438
Validation loss: 2.215946356455485

Epoch: 5| Step: 2
Training loss: 2.4229915142059326
Validation loss: 2.2550524224837623

Epoch: 5| Step: 3
Training loss: 2.231827974319458
Validation loss: 2.196179747581482

Epoch: 5| Step: 4
Training loss: 2.09674334526062
Validation loss: 2.303279012441635

Epoch: 5| Step: 5
Training loss: 2.9754912853240967
Validation loss: 2.251098414262136

Epoch: 5| Step: 6
Training loss: 2.493896484375
Validation loss: 2.3198996086915336

Epoch: 5| Step: 7
Training loss: 2.154768943786621
Validation loss: 2.2668416500091553

Epoch: 5| Step: 8
Training loss: 1.643021821975708
Validation loss: 2.285039613644282

Epoch: 5| Step: 9
Training loss: 2.070378065109253
Validation loss: 2.1796236534913382

Epoch: 5| Step: 10
Training loss: 2.255687713623047
Validation loss: 2.239658862352371

Epoch: 5| Step: 11
Training loss: 1.4238686561584473
Validation loss: 2.2357198695341745

Epoch: 17| Step: 0
Training loss: 2.330993175506592
Validation loss: 2.280633181333542

Epoch: 5| Step: 1
Training loss: 1.4392924308776855
Validation loss: 2.24821870525678

Epoch: 5| Step: 2
Training loss: 2.209815502166748
Validation loss: 2.235318730274836

Epoch: 5| Step: 3
Training loss: 1.6331695318222046
Validation loss: 2.1991292436917624

Epoch: 5| Step: 4
Training loss: 2.114466905593872
Validation loss: 2.2899317542711892

Epoch: 5| Step: 5
Training loss: 2.179858446121216
Validation loss: 2.2341001431147256

Epoch: 5| Step: 6
Training loss: 2.481820583343506
Validation loss: 2.2593374451001487

Epoch: 5| Step: 7
Training loss: 2.7582168579101562
Validation loss: 2.28159436583519

Epoch: 5| Step: 8
Training loss: 2.2942042350769043
Validation loss: 2.2890644570191703

Epoch: 5| Step: 9
Training loss: 3.133251667022705
Validation loss: 2.2954770227273307

Epoch: 5| Step: 10
Training loss: 1.8148542642593384
Validation loss: 2.13776957988739

Epoch: 5| Step: 11
Training loss: 0.5749562978744507
Validation loss: 2.2522257566452026

Epoch: 18| Step: 0
Training loss: 2.5284199714660645
Validation loss: 2.2890970408916473

Epoch: 5| Step: 1
Training loss: 2.076357841491699
Validation loss: 2.279595896601677

Epoch: 5| Step: 2
Training loss: 1.6141523122787476
Validation loss: 2.2968310862779617

Epoch: 5| Step: 3
Training loss: 2.1415979862213135
Validation loss: 2.297629068295161

Epoch: 5| Step: 4
Training loss: 2.4467384815216064
Validation loss: 2.220154340068499

Epoch: 5| Step: 5
Training loss: 2.2451870441436768
Validation loss: 2.340679183602333

Epoch: 5| Step: 6
Training loss: 2.5313308238983154
Validation loss: 2.314943770567576

Epoch: 5| Step: 7
Training loss: 2.6734464168548584
Validation loss: 2.3042639394601188

Epoch: 5| Step: 8
Training loss: 2.0479114055633545
Validation loss: 2.25563408434391

Epoch: 5| Step: 9
Training loss: 2.216245174407959
Validation loss: 2.192371671398481

Epoch: 5| Step: 10
Training loss: 2.0008938312530518
Validation loss: 2.2272279361883798

Epoch: 5| Step: 11
Training loss: 2.3816919326782227
Validation loss: 2.216146558523178

Epoch: 19| Step: 0
Training loss: 2.0605125427246094
Validation loss: 2.2752524514993033

Epoch: 5| Step: 1
Training loss: 1.5958925485610962
Validation loss: 2.1683183709780374

Epoch: 5| Step: 2
Training loss: 2.078540325164795
Validation loss: 2.192939519882202

Epoch: 5| Step: 3
Training loss: 2.4694745540618896
Validation loss: 2.243554189801216

Epoch: 5| Step: 4
Training loss: 2.5814247131347656
Validation loss: 2.1945623556772866

Epoch: 5| Step: 5
Training loss: 1.7170807123184204
Validation loss: 2.2821455697218576

Epoch: 5| Step: 6
Training loss: 2.5802388191223145
Validation loss: 2.264563719431559

Epoch: 5| Step: 7
Training loss: 2.0499682426452637
Validation loss: 2.1762391527493796

Epoch: 5| Step: 8
Training loss: 1.7926270961761475
Validation loss: 2.2136029303073883

Epoch: 5| Step: 9
Training loss: 2.106982707977295
Validation loss: 2.2189579407374063

Epoch: 5| Step: 10
Training loss: 2.4378628730773926
Validation loss: 2.3278320928414664

Epoch: 5| Step: 11
Training loss: 2.5404632091522217
Validation loss: 2.2366706828276315

Epoch: 20| Step: 0
Training loss: 1.7448489665985107
Validation loss: 2.2249643405278525

Epoch: 5| Step: 1
Training loss: 2.3473386764526367
Validation loss: 2.237616648276647

Epoch: 5| Step: 2
Training loss: 2.001471757888794
Validation loss: 2.221041440963745

Epoch: 5| Step: 3
Training loss: 2.461030960083008
Validation loss: 2.2179464598496756

Epoch: 5| Step: 4
Training loss: 3.076932430267334
Validation loss: 2.1743215173482895

Epoch: 5| Step: 5
Training loss: 2.082811117172241
Validation loss: 2.234874735275904

Epoch: 5| Step: 6
Training loss: 1.842586874961853
Validation loss: 2.255945309996605

Epoch: 5| Step: 7
Training loss: 1.6169376373291016
Validation loss: 2.230285093188286

Epoch: 5| Step: 8
Training loss: 1.8696388006210327
Validation loss: 2.2212284406026206

Epoch: 5| Step: 9
Training loss: 1.8244030475616455
Validation loss: 2.204972187678019

Epoch: 5| Step: 10
Training loss: 2.9658360481262207
Validation loss: 2.1979713390270867

Epoch: 5| Step: 11
Training loss: 1.4419620037078857
Validation loss: 2.181565592686335

Epoch: 21| Step: 0
Training loss: 2.168435573577881
Validation loss: 2.2366549571355185

Epoch: 5| Step: 1
Training loss: 1.9438564777374268
Validation loss: 2.1738513161738715

Epoch: 5| Step: 2
Training loss: 1.8297029733657837
Validation loss: 2.284911960363388

Epoch: 5| Step: 3
Training loss: 1.9148670434951782
Validation loss: 2.4257589230934777

Epoch: 5| Step: 4
Training loss: 2.2956888675689697
Validation loss: 2.461462219556173

Epoch: 5| Step: 5
Training loss: 2.817767858505249
Validation loss: 2.446506679058075

Epoch: 5| Step: 6
Training loss: 2.490593433380127
Validation loss: 2.395610809326172

Epoch: 5| Step: 7
Training loss: 2.4653396606445312
Validation loss: 2.4119937221209207

Epoch: 5| Step: 8
Training loss: 2.015291929244995
Validation loss: 2.3132616778214774

Epoch: 5| Step: 9
Training loss: 1.8850902318954468
Validation loss: 2.237423519293467

Epoch: 5| Step: 10
Training loss: 2.4429550170898438
Validation loss: 2.288019508123398

Epoch: 5| Step: 11
Training loss: 3.3056278228759766
Validation loss: 2.2090366234381995

Epoch: 22| Step: 0
Training loss: 2.175475597381592
Validation loss: 2.26267609000206

Epoch: 5| Step: 1
Training loss: 1.598305344581604
Validation loss: 2.1743597189585366

Epoch: 5| Step: 2
Training loss: 2.559007406234741
Validation loss: 2.2316980014244714

Epoch: 5| Step: 3
Training loss: 1.812482237815857
Validation loss: 2.245725999275843

Epoch: 5| Step: 4
Training loss: 2.093695640563965
Validation loss: 2.258808652559916

Epoch: 5| Step: 5
Training loss: 2.056861400604248
Validation loss: 2.2842851082483926

Epoch: 5| Step: 6
Training loss: 1.9479013681411743
Validation loss: 2.2976672848065696

Epoch: 5| Step: 7
Training loss: 2.522136688232422
Validation loss: 2.2559193770090737

Epoch: 5| Step: 8
Training loss: 2.608635425567627
Validation loss: 2.261153449614843

Epoch: 5| Step: 9
Training loss: 2.274519920349121
Validation loss: 2.2120022823413215

Epoch: 5| Step: 10
Training loss: 2.073549747467041
Validation loss: 2.2754211326440177

Epoch: 5| Step: 11
Training loss: 4.309852600097656
Validation loss: 2.2487919529279075

Epoch: 23| Step: 0
Training loss: 1.8220913410186768
Validation loss: 2.241118629773458

Epoch: 5| Step: 1
Training loss: 2.364135980606079
Validation loss: 2.241943284869194

Epoch: 5| Step: 2
Training loss: 2.1023495197296143
Validation loss: 2.27505291501681

Epoch: 5| Step: 3
Training loss: 1.9715254306793213
Validation loss: 2.285423457622528

Epoch: 5| Step: 4
Training loss: 2.6083571910858154
Validation loss: 2.209555894136429

Epoch: 5| Step: 5
Training loss: 2.6557106971740723
Validation loss: 2.263599326213201

Epoch: 5| Step: 6
Training loss: 2.3761403560638428
Validation loss: 2.344320515791575

Epoch: 5| Step: 7
Training loss: 2.2835164070129395
Validation loss: 2.3487542271614075

Epoch: 5| Step: 8
Training loss: 1.6610238552093506
Validation loss: 2.229019353787104

Epoch: 5| Step: 9
Training loss: 2.300637722015381
Validation loss: 2.1960139671961465

Epoch: 5| Step: 10
Training loss: 1.7599846124649048
Validation loss: 2.256315196553866

Epoch: 5| Step: 11
Training loss: 2.6700897216796875
Validation loss: 2.2501332461833954

Epoch: 24| Step: 0
Training loss: 1.7142465114593506
Validation loss: 2.2415148516496024

Epoch: 5| Step: 1
Training loss: 2.574883460998535
Validation loss: 2.1748967369397483

Epoch: 5| Step: 2
Training loss: 1.630816102027893
Validation loss: 2.267799417177836

Epoch: 5| Step: 3
Training loss: 1.7225784063339233
Validation loss: 2.249523272116979

Epoch: 5| Step: 4
Training loss: 2.1295430660247803
Validation loss: 2.3000136613845825

Epoch: 5| Step: 5
Training loss: 2.507412910461426
Validation loss: 2.214886595805486

Epoch: 5| Step: 6
Training loss: 2.0215325355529785
Validation loss: 2.1630980173746743

Epoch: 5| Step: 7
Training loss: 2.078503370285034
Validation loss: 2.2127666076024375

Epoch: 5| Step: 8
Training loss: 2.023787260055542
Validation loss: 2.136435682574908

Epoch: 5| Step: 9
Training loss: 2.2559142112731934
Validation loss: 2.2365554173787436

Epoch: 5| Step: 10
Training loss: 2.624863386154175
Validation loss: 2.1734278251727424

Epoch: 5| Step: 11
Training loss: 2.309878349304199
Validation loss: 2.2298114597797394

Epoch: 25| Step: 0
Training loss: 1.703843355178833
Validation loss: 2.3571146527926126

Epoch: 5| Step: 1
Training loss: 2.3514177799224854
Validation loss: 2.254485751191775

Epoch: 5| Step: 2
Training loss: 2.132258653640747
Validation loss: 2.196632648507754

Epoch: 5| Step: 3
Training loss: 1.8213036060333252
Validation loss: 2.2844493985176086

Epoch: 5| Step: 4
Training loss: 2.847888231277466
Validation loss: 2.260516027609507

Epoch: 5| Step: 5
Training loss: 1.8739982843399048
Validation loss: 2.2506936291853585

Epoch: 5| Step: 6
Training loss: 1.6703617572784424
Validation loss: 2.322370265920957

Epoch: 5| Step: 7
Training loss: 2.275459051132202
Validation loss: 2.1557807375987372

Epoch: 5| Step: 8
Training loss: 1.8874986171722412
Validation loss: 2.134970332185427

Epoch: 5| Step: 9
Training loss: 2.3975400924682617
Validation loss: 2.2108606696128845

Epoch: 5| Step: 10
Training loss: 2.219473361968994
Validation loss: 2.226105749607086

Epoch: 5| Step: 11
Training loss: 3.4733424186706543
Validation loss: 2.2275850971539817

Epoch: 26| Step: 0
Training loss: 1.7464078664779663
Validation loss: 2.2671836018562317

Epoch: 5| Step: 1
Training loss: 2.4231324195861816
Validation loss: 2.2733332415421805

Epoch: 5| Step: 2
Training loss: 2.088552236557007
Validation loss: 2.211126615603765

Epoch: 5| Step: 3
Training loss: 1.8505929708480835
Validation loss: 2.203642249107361

Epoch: 5| Step: 4
Training loss: 2.2028043270111084
Validation loss: 2.289451817671458

Epoch: 5| Step: 5
Training loss: 2.54949688911438
Validation loss: 2.32067146897316

Epoch: 5| Step: 6
Training loss: 2.0423951148986816
Validation loss: 2.1835055202245712

Epoch: 5| Step: 7
Training loss: 2.229757785797119
Validation loss: 2.2237089574337006

Epoch: 5| Step: 8
Training loss: 1.9663124084472656
Validation loss: 2.235539282361666

Epoch: 5| Step: 9
Training loss: 2.1413607597351074
Validation loss: 2.2085324426492057

Epoch: 5| Step: 10
Training loss: 2.108821153640747
Validation loss: 2.273184726635615

Epoch: 5| Step: 11
Training loss: 2.0301804542541504
Validation loss: 2.25694677233696

Epoch: 27| Step: 0
Training loss: 2.0120530128479004
Validation loss: 2.1990850071112313

Epoch: 5| Step: 1
Training loss: 2.293189764022827
Validation loss: 2.301538407802582

Epoch: 5| Step: 2
Training loss: 2.098890781402588
Validation loss: 2.2480741292238235

Epoch: 5| Step: 3
Training loss: 2.269896984100342
Validation loss: 2.329788769284884

Epoch: 5| Step: 4
Training loss: 1.850037932395935
Validation loss: 2.225726137558619

Epoch: 5| Step: 5
Training loss: 1.9553816318511963
Validation loss: 2.2865055749813714

Epoch: 5| Step: 6
Training loss: 2.1318511962890625
Validation loss: 2.2750739653905234

Epoch: 5| Step: 7
Training loss: 2.7902567386627197
Validation loss: 2.246379400293032

Epoch: 5| Step: 8
Training loss: 1.7731233835220337
Validation loss: 2.1931430846452713

Epoch: 5| Step: 9
Training loss: 2.2109930515289307
Validation loss: 2.206017846862475

Epoch: 5| Step: 10
Training loss: 2.307007312774658
Validation loss: 2.2008565415938697

Epoch: 5| Step: 11
Training loss: 2.5858428478240967
Validation loss: 2.227114588022232

Epoch: 28| Step: 0
Training loss: 1.6593605279922485
Validation loss: 2.229982872804006

Epoch: 5| Step: 1
Training loss: 2.5344882011413574
Validation loss: 2.2735288192828498

Epoch: 5| Step: 2
Training loss: 2.078342914581299
Validation loss: 2.3455633322397866

Epoch: 5| Step: 3
Training loss: 2.2093520164489746
Validation loss: 2.25752646724383

Epoch: 5| Step: 4
Training loss: 2.106443405151367
Validation loss: 2.250226358572642

Epoch: 5| Step: 5
Training loss: 2.1685681343078613
Validation loss: 2.348318268855413

Epoch: 5| Step: 6
Training loss: 2.191216230392456
Validation loss: 2.3380925158659616

Epoch: 5| Step: 7
Training loss: 2.2201507091522217
Validation loss: 2.2859082023302713

Epoch: 5| Step: 8
Training loss: 2.2176475524902344
Validation loss: 2.211688756942749

Epoch: 5| Step: 9
Training loss: 1.871813416481018
Validation loss: 2.2273437529802322

Epoch: 5| Step: 10
Training loss: 1.8730872869491577
Validation loss: 2.2222842077414193

Epoch: 5| Step: 11
Training loss: 3.2861976623535156
Validation loss: 2.2250292549530664

Epoch: 29| Step: 0
Training loss: 2.630340576171875
Validation loss: 2.2075906892617545

Epoch: 5| Step: 1
Training loss: 2.607579469680786
Validation loss: 2.267596274614334

Epoch: 5| Step: 2
Training loss: 1.9587208032608032
Validation loss: 2.2840957939624786

Epoch: 5| Step: 3
Training loss: 1.9980148077011108
Validation loss: 2.2404864033063254

Epoch: 5| Step: 4
Training loss: 2.2472805976867676
Validation loss: 2.2784759799639382

Epoch: 5| Step: 5
Training loss: 1.6037299633026123
Validation loss: 2.3017263809839883

Epoch: 5| Step: 6
Training loss: 2.533674716949463
Validation loss: 2.210094541311264

Epoch: 5| Step: 7
Training loss: 2.2662646770477295
Validation loss: 2.2075244237979255

Epoch: 5| Step: 8
Training loss: 1.402377724647522
Validation loss: 2.250886673728625

Epoch: 5| Step: 9
Training loss: 2.2233119010925293
Validation loss: 2.212988888223966

Epoch: 5| Step: 10
Training loss: 1.8478072881698608
Validation loss: 2.3131217509508133

Epoch: 5| Step: 11
Training loss: 1.8389637470245361
Validation loss: 2.2087665498256683

Epoch: 30| Step: 0
Training loss: 2.083028554916382
Validation loss: 2.256537914276123

Epoch: 5| Step: 1
Training loss: 2.2697718143463135
Validation loss: 2.2585590730110803

Epoch: 5| Step: 2
Training loss: 2.663860321044922
Validation loss: 2.339681218067805

Epoch: 5| Step: 3
Training loss: 1.2731341123580933
Validation loss: 2.397822678089142

Epoch: 5| Step: 4
Training loss: 2.332340717315674
Validation loss: 2.284743438164393

Epoch: 5| Step: 5
Training loss: 2.4858546257019043
Validation loss: 2.325432042280833

Epoch: 5| Step: 6
Training loss: 1.8185806274414062
Validation loss: 2.2025830248991647

Epoch: 5| Step: 7
Training loss: 2.2516930103302
Validation loss: 2.229120204846064

Epoch: 5| Step: 8
Training loss: 1.9640922546386719
Validation loss: 2.319076990087827

Epoch: 5| Step: 9
Training loss: 2.376832962036133
Validation loss: 2.2769976456960044

Epoch: 5| Step: 10
Training loss: 2.611886978149414
Validation loss: 2.160614783565203

Epoch: 5| Step: 11
Training loss: 1.3370167016983032
Validation loss: 2.2348291824261346

Epoch: 31| Step: 0
Training loss: 2.4846813678741455
Validation loss: 2.2980726261933646

Epoch: 5| Step: 1
Training loss: 2.6962993144989014
Validation loss: 2.2965372105439505

Epoch: 5| Step: 2
Training loss: 2.3251163959503174
Validation loss: 2.395242323478063

Epoch: 5| Step: 3
Training loss: 2.217960834503174
Validation loss: 2.356249729792277

Epoch: 5| Step: 4
Training loss: 1.836565375328064
Validation loss: 2.233264292279879

Epoch: 5| Step: 5
Training loss: 2.1074745655059814
Validation loss: 2.3457191387812295

Epoch: 5| Step: 6
Training loss: 2.068392276763916
Validation loss: 2.20422600209713

Epoch: 5| Step: 7
Training loss: 2.0677103996276855
Validation loss: 2.1777710169553757

Epoch: 5| Step: 8
Training loss: 2.8914802074432373
Validation loss: 2.2335459937651954

Epoch: 5| Step: 9
Training loss: 1.5277330875396729
Validation loss: 2.206691026687622

Epoch: 5| Step: 10
Training loss: 1.5803314447402954
Validation loss: 2.2254526913166046

Epoch: 5| Step: 11
Training loss: 1.9190136194229126
Validation loss: 2.2101221134265265

Epoch: 32| Step: 0
Training loss: 2.217061996459961
Validation loss: 2.3451874206463494

Epoch: 5| Step: 1
Training loss: 1.8594467639923096
Validation loss: 2.2838126868009567

Epoch: 5| Step: 2
Training loss: 1.868757963180542
Validation loss: 2.312036653359731

Epoch: 5| Step: 3
Training loss: 2.47558331489563
Validation loss: 2.30199471116066

Epoch: 5| Step: 4
Training loss: 1.8581750392913818
Validation loss: 2.197042405605316

Epoch: 5| Step: 5
Training loss: 1.711066484451294
Validation loss: 2.2456160187721252

Epoch: 5| Step: 6
Training loss: 2.334834337234497
Validation loss: 2.2604878147443137

Epoch: 5| Step: 7
Training loss: 2.147547960281372
Validation loss: 2.189506103595098

Epoch: 5| Step: 8
Training loss: 2.1265206336975098
Validation loss: 2.253441130121549

Epoch: 5| Step: 9
Training loss: 1.7958354949951172
Validation loss: 2.208852211634318

Epoch: 5| Step: 10
Training loss: 2.5654330253601074
Validation loss: 2.2262249986330667

Epoch: 5| Step: 11
Training loss: 3.1476035118103027
Validation loss: 2.292573799689611

Epoch: 33| Step: 0
Training loss: 1.8833153247833252
Validation loss: 2.2916148602962494

Epoch: 5| Step: 1
Training loss: 1.8674147129058838
Validation loss: 2.295861065387726

Epoch: 5| Step: 2
Training loss: 2.642962694168091
Validation loss: 2.2469353477160134

Epoch: 5| Step: 3
Training loss: 2.2041594982147217
Validation loss: 2.2190815955400467

Epoch: 5| Step: 4
Training loss: 2.0694925785064697
Validation loss: 2.2761759161949158

Epoch: 5| Step: 5
Training loss: 2.779491424560547
Validation loss: 2.181540379921595

Epoch: 5| Step: 6
Training loss: 2.183001756668091
Validation loss: 2.373036747177442

Epoch: 5| Step: 7
Training loss: 2.001953363418579
Validation loss: 2.2092554569244385

Epoch: 5| Step: 8
Training loss: 1.616062879562378
Validation loss: 2.270664428671201

Epoch: 5| Step: 9
Training loss: 2.3782904148101807
Validation loss: 2.118594671289126

Epoch: 5| Step: 10
Training loss: 1.6520878076553345
Validation loss: 2.2108924885590873

Epoch: 5| Step: 11
Training loss: 2.437530517578125
Validation loss: 2.252120683590571

Epoch: 34| Step: 0
Training loss: 2.154285430908203
Validation loss: 2.2545405328273773

Epoch: 5| Step: 1
Training loss: 1.8761012554168701
Validation loss: 2.1868093609809875

Epoch: 5| Step: 2
Training loss: 2.495690107345581
Validation loss: 2.27470999956131

Epoch: 5| Step: 3
Training loss: 1.7307946681976318
Validation loss: 2.207322080930074

Epoch: 5| Step: 4
Training loss: 2.151702404022217
Validation loss: 2.2165730347236

Epoch: 5| Step: 5
Training loss: 1.9232311248779297
Validation loss: 2.269936755299568

Epoch: 5| Step: 6
Training loss: 2.208156108856201
Validation loss: 2.2224217553933463

Epoch: 5| Step: 7
Training loss: 1.849503517150879
Validation loss: 2.2759938885768256

Epoch: 5| Step: 8
Training loss: 2.2254152297973633
Validation loss: 2.1536492059628167

Epoch: 5| Step: 9
Training loss: 2.13175630569458
Validation loss: 2.2339103619257608

Epoch: 5| Step: 10
Training loss: 1.940660834312439
Validation loss: 2.191361998518308

Epoch: 5| Step: 11
Training loss: 3.390078067779541
Validation loss: 2.2541292359431586

Epoch: 35| Step: 0
Training loss: 2.299973964691162
Validation loss: 2.1933231155077615

Epoch: 5| Step: 1
Training loss: 1.9930810928344727
Validation loss: 2.24883870780468

Epoch: 5| Step: 2
Training loss: 2.2300057411193848
Validation loss: 2.297175034880638

Epoch: 5| Step: 3
Training loss: 2.3120956420898438
Validation loss: 2.3856772979100547

Epoch: 5| Step: 4
Training loss: 2.226710796356201
Validation loss: 2.203863034645716

Epoch: 5| Step: 5
Training loss: 2.5676798820495605
Validation loss: 2.269051800171534

Epoch: 5| Step: 6
Training loss: 2.133577346801758
Validation loss: 2.33342973391215

Epoch: 5| Step: 7
Training loss: 1.661002516746521
Validation loss: 2.2049240271250405

Epoch: 5| Step: 8
Training loss: 1.8509372472763062
Validation loss: 2.2429532756408057

Epoch: 5| Step: 9
Training loss: 2.593017101287842
Validation loss: 2.229093367854754

Epoch: 5| Step: 10
Training loss: 1.464982509613037
Validation loss: 2.2104904651641846

Epoch: 5| Step: 11
Training loss: 2.3792057037353516
Validation loss: 2.2035357604424157

Epoch: 36| Step: 0
Training loss: 1.8271749019622803
Validation loss: 2.152469366788864

Epoch: 5| Step: 1
Training loss: 1.791282296180725
Validation loss: 2.2229691048463187

Epoch: 5| Step: 2
Training loss: 1.559053897857666
Validation loss: 2.2139070481061935

Epoch: 5| Step: 3
Training loss: 2.352313995361328
Validation loss: 2.2408487449089685

Epoch: 5| Step: 4
Training loss: 1.2268080711364746
Validation loss: 2.2264761527379355

Epoch: 5| Step: 5
Training loss: 2.367286443710327
Validation loss: 2.239944249391556

Epoch: 5| Step: 6
Training loss: 2.650041103363037
Validation loss: 2.2393270234266915

Epoch: 5| Step: 7
Training loss: 2.102400541305542
Validation loss: 2.233188678820928

Epoch: 5| Step: 8
Training loss: 2.4034175872802734
Validation loss: 2.220355918010076

Epoch: 5| Step: 9
Training loss: 2.089268445968628
Validation loss: 2.1903193394343057

Epoch: 5| Step: 10
Training loss: 1.9740893840789795
Validation loss: 2.2011787245670953

Epoch: 5| Step: 11
Training loss: 1.348318099975586
Validation loss: 2.2880381047725677

Epoch: 37| Step: 0
Training loss: 2.174356460571289
Validation loss: 2.2999754349390664

Epoch: 5| Step: 1
Training loss: 2.2833704948425293
Validation loss: 2.2762379944324493

Epoch: 5| Step: 2
Training loss: 1.9863388538360596
Validation loss: 2.1779573361078897

Epoch: 5| Step: 3
Training loss: 2.4430251121520996
Validation loss: 2.213218867778778

Epoch: 5| Step: 4
Training loss: 2.6355202198028564
Validation loss: 2.2668468058109283

Epoch: 5| Step: 5
Training loss: 2.254852533340454
Validation loss: 2.280243068933487

Epoch: 5| Step: 6
Training loss: 1.7847522497177124
Validation loss: 2.2725940396388373

Epoch: 5| Step: 7
Training loss: 1.899645447731018
Validation loss: 2.226907044649124

Epoch: 5| Step: 8
Training loss: 1.763366937637329
Validation loss: 2.2659878681103387

Epoch: 5| Step: 9
Training loss: 2.02131724357605
Validation loss: 2.2432387868563333

Epoch: 5| Step: 10
Training loss: 1.9998639822006226
Validation loss: 2.1424610018730164

Epoch: 5| Step: 11
Training loss: 1.8436923027038574
Validation loss: 2.156219263871511

Epoch: 38| Step: 0
Training loss: 2.5152974128723145
Validation loss: 2.2978980342547097

Epoch: 5| Step: 1
Training loss: 2.285644054412842
Validation loss: 2.1564632455507913

Epoch: 5| Step: 2
Training loss: 1.9508785009384155
Validation loss: 2.302717705567678

Epoch: 5| Step: 3
Training loss: 2.139575958251953
Validation loss: 2.1795285592476525

Epoch: 5| Step: 4
Training loss: 1.8121521472930908
Validation loss: 2.1953444331884384

Epoch: 5| Step: 5
Training loss: 1.2430568933486938
Validation loss: 2.17744251092275

Epoch: 5| Step: 6
Training loss: 1.9747803211212158
Validation loss: 2.2662667532761893

Epoch: 5| Step: 7
Training loss: 2.0036392211914062
Validation loss: 2.264744778474172

Epoch: 5| Step: 8
Training loss: 2.5652575492858887
Validation loss: 2.2648363957802453

Epoch: 5| Step: 9
Training loss: 2.8540632724761963
Validation loss: 2.272227386633555

Epoch: 5| Step: 10
Training loss: 1.9925251007080078
Validation loss: 2.2102152009805045

Epoch: 5| Step: 11
Training loss: 1.90621018409729
Validation loss: 2.2569829324881234

Epoch: 39| Step: 0
Training loss: 1.7306991815567017
Validation loss: 2.2065250178178153

Epoch: 5| Step: 1
Training loss: 2.178295612335205
Validation loss: 2.253186126550039

Epoch: 5| Step: 2
Training loss: 1.1460071802139282
Validation loss: 2.1550622433423996

Epoch: 5| Step: 3
Training loss: 2.268890380859375
Validation loss: 2.228615462779999

Epoch: 5| Step: 4
Training loss: 2.480393648147583
Validation loss: 2.335085461537043

Epoch: 5| Step: 5
Training loss: 2.0285096168518066
Validation loss: 2.1749711434046426

Epoch: 5| Step: 6
Training loss: 2.285341739654541
Validation loss: 2.1693884879350662

Epoch: 5| Step: 7
Training loss: 2.291555881500244
Validation loss: 2.2914235989252725

Epoch: 5| Step: 8
Training loss: 1.8573287725448608
Validation loss: 2.3641071567932763

Epoch: 5| Step: 9
Training loss: 2.3728089332580566
Validation loss: 2.231907685597738

Epoch: 5| Step: 10
Training loss: 2.1542210578918457
Validation loss: 2.231750726699829

Epoch: 5| Step: 11
Training loss: 1.251319408416748
Validation loss: 2.181868235270182

Epoch: 40| Step: 0
Training loss: 1.5801303386688232
Validation loss: 2.2505225340525308

Epoch: 5| Step: 1
Training loss: 1.564721703529358
Validation loss: 2.2834606617689133

Epoch: 5| Step: 2
Training loss: 2.701580047607422
Validation loss: 2.1353854139645896

Epoch: 5| Step: 3
Training loss: 2.576209306716919
Validation loss: 2.3075151294469833

Epoch: 5| Step: 4
Training loss: 2.692277669906616
Validation loss: 2.1854354391495385

Epoch: 5| Step: 5
Training loss: 1.5295671224594116
Validation loss: 2.248948951562246

Epoch: 5| Step: 6
Training loss: 1.9961048364639282
Validation loss: 2.3323405534029007

Epoch: 5| Step: 7
Training loss: 2.429612874984741
Validation loss: 2.2407676676909127

Epoch: 5| Step: 8
Training loss: 1.459995985031128
Validation loss: 2.291087215145429

Epoch: 5| Step: 9
Training loss: 1.6648451089859009
Validation loss: 2.196773111820221

Epoch: 5| Step: 10
Training loss: 2.316258668899536
Validation loss: 2.202178582549095

Epoch: 5| Step: 11
Training loss: 2.724637269973755
Validation loss: 2.2146270871162415

Epoch: 41| Step: 0
Training loss: 1.9465796947479248
Validation loss: 2.1960066854953766

Epoch: 5| Step: 1
Training loss: 2.2493176460266113
Validation loss: 2.23017651339372

Epoch: 5| Step: 2
Training loss: 1.7614799737930298
Validation loss: 2.258066634337107

Epoch: 5| Step: 3
Training loss: 2.4907302856445312
Validation loss: 2.2901941537857056

Epoch: 5| Step: 4
Training loss: 3.0047872066497803
Validation loss: 2.2943417578935623

Epoch: 5| Step: 5
Training loss: 2.2603299617767334
Validation loss: 2.3259250621000924

Epoch: 5| Step: 6
Training loss: 2.516613006591797
Validation loss: 2.2931015690167746

Epoch: 5| Step: 7
Training loss: 1.9734376668930054
Validation loss: 2.3360417783260345

Epoch: 5| Step: 8
Training loss: 1.7943341732025146
Validation loss: 2.2416997055212655

Epoch: 5| Step: 9
Training loss: 1.753474235534668
Validation loss: 2.2712694853544235

Epoch: 5| Step: 10
Training loss: 2.0274951457977295
Validation loss: 2.32917720079422

Epoch: 5| Step: 11
Training loss: 2.328828811645508
Validation loss: 2.2254789421955743

Epoch: 42| Step: 0
Training loss: 1.6860997676849365
Validation loss: 2.2742251555124917

Epoch: 5| Step: 1
Training loss: 2.6360459327697754
Validation loss: 2.28534663716952

Epoch: 5| Step: 2
Training loss: 1.9713351726531982
Validation loss: 2.3401515086491904

Epoch: 5| Step: 3
Training loss: 2.409501314163208
Validation loss: 2.2146204312642417

Epoch: 5| Step: 4
Training loss: 2.063751697540283
Validation loss: 2.3696187138557434

Epoch: 5| Step: 5
Training loss: 2.47461199760437
Validation loss: 2.2864528596401215

Epoch: 5| Step: 6
Training loss: 2.2998995780944824
Validation loss: 2.2177009681860604

Epoch: 5| Step: 7
Training loss: 1.8007676601409912
Validation loss: 2.251690705617269

Epoch: 5| Step: 8
Training loss: 2.218575954437256
Validation loss: 2.3275743623574576

Epoch: 5| Step: 9
Training loss: 1.5875720977783203
Validation loss: 2.2202953596909842

Epoch: 5| Step: 10
Training loss: 1.584943175315857
Validation loss: 2.2879131734371185

Epoch: 5| Step: 11
Training loss: 1.760749101638794
Validation loss: 2.1996435721715293

Epoch: 43| Step: 0
Training loss: 2.2756025791168213
Validation loss: 2.221772606174151

Epoch: 5| Step: 1
Training loss: 2.2335991859436035
Validation loss: 2.18366472919782

Epoch: 5| Step: 2
Training loss: 2.2947707176208496
Validation loss: 2.135515640179316

Epoch: 5| Step: 3
Training loss: 1.5816179513931274
Validation loss: 2.2462230076392493

Epoch: 5| Step: 4
Training loss: 1.9234638214111328
Validation loss: 2.205453559756279

Epoch: 5| Step: 5
Training loss: 1.9706313610076904
Validation loss: 2.327211653192838

Epoch: 5| Step: 6
Training loss: 1.4168134927749634
Validation loss: 2.2247375696897507

Epoch: 5| Step: 7
Training loss: 2.51598858833313
Validation loss: 2.099519948164622

Epoch: 5| Step: 8
Training loss: 1.8899503946304321
Validation loss: 2.1484782149394355

Epoch: 5| Step: 9
Training loss: 2.015881061553955
Validation loss: 2.179308295249939

Epoch: 5| Step: 10
Training loss: 2.1826395988464355
Validation loss: 2.2818497767051062

Epoch: 5| Step: 11
Training loss: 1.1371452808380127
Validation loss: 2.28197971979777

Epoch: 44| Step: 0
Training loss: 2.001438856124878
Validation loss: 2.2459912101427713

Epoch: 5| Step: 1
Training loss: 2.285951852798462
Validation loss: 2.204312245051066

Epoch: 5| Step: 2
Training loss: 2.1455655097961426
Validation loss: 2.2852715154488883

Epoch: 5| Step: 3
Training loss: 2.369861602783203
Validation loss: 2.3130605667829514

Epoch: 5| Step: 4
Training loss: 2.34098744392395
Validation loss: 2.2563065538803735

Epoch: 5| Step: 5
Training loss: 2.1477503776550293
Validation loss: 2.24077179034551

Epoch: 5| Step: 6
Training loss: 1.7110540866851807
Validation loss: 2.233169356981913

Epoch: 5| Step: 7
Training loss: 2.234252452850342
Validation loss: 2.151306852698326

Epoch: 5| Step: 8
Training loss: 1.8960002660751343
Validation loss: 2.221689502398173

Epoch: 5| Step: 9
Training loss: 2.1113874912261963
Validation loss: 2.217726454138756

Epoch: 5| Step: 10
Training loss: 1.876407265663147
Validation loss: 2.210022449493408

Epoch: 5| Step: 11
Training loss: 3.922194480895996
Validation loss: 2.204320957263311

Epoch: 45| Step: 0
Training loss: 2.1050305366516113
Validation loss: 2.1971468726793923

Epoch: 5| Step: 1
Training loss: 1.8574765920639038
Validation loss: 2.267583906650543

Epoch: 5| Step: 2
Training loss: 1.65915846824646
Validation loss: 2.1883722643057504

Epoch: 5| Step: 3
Training loss: 2.046243667602539
Validation loss: 2.1482940514882407

Epoch: 5| Step: 4
Training loss: 1.7893661260604858
Validation loss: 2.1219899902741113

Epoch: 5| Step: 5
Training loss: 2.171983480453491
Validation loss: 2.266441519061724

Epoch: 5| Step: 6
Training loss: 1.945754051208496
Validation loss: 2.217311124006907

Epoch: 5| Step: 7
Training loss: 1.8491106033325195
Validation loss: 2.079092353582382

Epoch: 5| Step: 8
Training loss: 2.2723004817962646
Validation loss: 2.256679594516754

Epoch: 5| Step: 9
Training loss: 2.383770704269409
Validation loss: 2.18437389532725

Epoch: 5| Step: 10
Training loss: 2.3713483810424805
Validation loss: 2.2897347857554755

Epoch: 5| Step: 11
Training loss: 2.356519937515259
Validation loss: 2.2280397514502206

Epoch: 46| Step: 0
Training loss: 2.2657923698425293
Validation loss: 2.2175479233264923

Epoch: 5| Step: 1
Training loss: 1.4337108135223389
Validation loss: 2.222551862398783

Epoch: 5| Step: 2
Training loss: 2.368969440460205
Validation loss: 2.157718966404597

Epoch: 5| Step: 3
Training loss: 1.4698861837387085
Validation loss: 2.184539794921875

Epoch: 5| Step: 4
Training loss: 1.869901418685913
Validation loss: 2.155122439066569

Epoch: 5| Step: 5
Training loss: 2.072180986404419
Validation loss: 2.220372830828031

Epoch: 5| Step: 6
Training loss: 2.3283119201660156
Validation loss: 2.293624763687452

Epoch: 5| Step: 7
Training loss: 1.5946511030197144
Validation loss: 2.1535626550515494

Epoch: 5| Step: 8
Training loss: 2.6935417652130127
Validation loss: 2.2838898450136185

Epoch: 5| Step: 9
Training loss: 2.517326831817627
Validation loss: 2.2472586085398993

Epoch: 5| Step: 10
Training loss: 1.8336303234100342
Validation loss: 2.277904654542605

Epoch: 5| Step: 11
Training loss: 1.0807418823242188
Validation loss: 2.2175647616386414

Epoch: 47| Step: 0
Training loss: 2.217519760131836
Validation loss: 2.1922220289707184

Epoch: 5| Step: 1
Training loss: 2.3414244651794434
Validation loss: 2.262076978882154

Epoch: 5| Step: 2
Training loss: 2.2812304496765137
Validation loss: 2.2001620829105377

Epoch: 5| Step: 3
Training loss: 1.7903330326080322
Validation loss: 2.2255473285913467

Epoch: 5| Step: 4
Training loss: 2.2934024333953857
Validation loss: 2.2685491194327674

Epoch: 5| Step: 5
Training loss: 2.121835231781006
Validation loss: 2.292521466811498

Epoch: 5| Step: 6
Training loss: 2.0461537837982178
Validation loss: 2.3270175059636435

Epoch: 5| Step: 7
Training loss: 2.4125545024871826
Validation loss: 2.317499284942945

Epoch: 5| Step: 8
Training loss: 2.423410177230835
Validation loss: 2.3512765963872275

Epoch: 5| Step: 9
Training loss: 1.9422109127044678
Validation loss: 2.23356727262338

Epoch: 5| Step: 10
Training loss: 2.0212759971618652
Validation loss: 2.1955398470163345

Epoch: 5| Step: 11
Training loss: 1.6620641946792603
Validation loss: 2.1455619633197784

Epoch: 48| Step: 0
Training loss: 2.4713776111602783
Validation loss: 2.206483945250511

Epoch: 5| Step: 1
Training loss: 1.9827556610107422
Validation loss: 2.2084928154945374

Epoch: 5| Step: 2
Training loss: 1.6984355449676514
Validation loss: 2.223019560178121

Epoch: 5| Step: 3
Training loss: 2.567990779876709
Validation loss: 2.325286030769348

Epoch: 5| Step: 4
Training loss: 1.636216402053833
Validation loss: 2.3071894347667694

Epoch: 5| Step: 5
Training loss: 2.3977644443511963
Validation loss: 2.341509814063708

Epoch: 5| Step: 6
Training loss: 1.7073566913604736
Validation loss: 2.2980139950911203

Epoch: 5| Step: 7
Training loss: 1.7650247812271118
Validation loss: 2.301191985607147

Epoch: 5| Step: 8
Training loss: 1.9632078409194946
Validation loss: 2.282051940759023

Epoch: 5| Step: 9
Training loss: 2.314798593521118
Validation loss: 2.3720009525616965

Epoch: 5| Step: 10
Training loss: 2.1851799488067627
Validation loss: 2.2439137895902

Epoch: 5| Step: 11
Training loss: 1.9026250839233398
Validation loss: 2.2253073255221048

Epoch: 49| Step: 0
Training loss: 1.2850685119628906
Validation loss: 2.202006702621778

Epoch: 5| Step: 1
Training loss: 1.7714917659759521
Validation loss: 2.1491874754428864

Epoch: 5| Step: 2
Training loss: 1.827765703201294
Validation loss: 2.1497886776924133

Epoch: 5| Step: 3
Training loss: 1.8374322652816772
Validation loss: 2.2055941224098206

Epoch: 5| Step: 4
Training loss: 1.5788720846176147
Validation loss: 2.2240924139817557

Epoch: 5| Step: 5
Training loss: 2.042222499847412
Validation loss: 2.3088797529538474

Epoch: 5| Step: 6
Training loss: 1.8320468664169312
Validation loss: 2.251859188079834

Epoch: 5| Step: 7
Training loss: 2.3976051807403564
Validation loss: 2.255888650814692

Epoch: 5| Step: 8
Training loss: 3.051351308822632
Validation loss: 2.2574288845062256

Epoch: 5| Step: 9
Training loss: 2.1514625549316406
Validation loss: 2.3107064962387085

Epoch: 5| Step: 10
Training loss: 2.349597454071045
Validation loss: 2.3304849416017532

Epoch: 5| Step: 11
Training loss: 4.476903438568115
Validation loss: 2.269345223903656

Epoch: 50| Step: 0
Training loss: 1.4803483486175537
Validation loss: 2.263899783293406

Epoch: 5| Step: 1
Training loss: 2.2276971340179443
Validation loss: 2.297434523701668

Epoch: 5| Step: 2
Training loss: 2.2401785850524902
Validation loss: 2.259529506166776

Epoch: 5| Step: 3
Training loss: 2.0684683322906494
Validation loss: 2.2948700884977975

Epoch: 5| Step: 4
Training loss: 2.3370041847229004
Validation loss: 2.108807529012362

Epoch: 5| Step: 5
Training loss: 2.311030149459839
Validation loss: 2.2183745900789895

Epoch: 5| Step: 6
Training loss: 1.9812980890274048
Validation loss: 2.2608613123496375

Epoch: 5| Step: 7
Training loss: 2.053837776184082
Validation loss: 2.272674322128296

Epoch: 5| Step: 8
Training loss: 2.121171712875366
Validation loss: 2.18365308145682

Epoch: 5| Step: 9
Training loss: 1.8461315631866455
Validation loss: 2.1391350825627646

Epoch: 5| Step: 10
Training loss: 2.0090737342834473
Validation loss: 2.113925168911616

Epoch: 5| Step: 11
Training loss: 2.189103364944458
Validation loss: 2.142227162917455

Epoch: 51| Step: 0
Training loss: 2.128359794616699
Validation loss: 2.1884410232305527

Epoch: 5| Step: 1
Training loss: 2.7817587852478027
Validation loss: 2.2902176082134247

Epoch: 5| Step: 2
Training loss: 2.1647350788116455
Validation loss: 2.189427296320597

Epoch: 5| Step: 3
Training loss: 2.0657811164855957
Validation loss: 2.226405511299769

Epoch: 5| Step: 4
Training loss: 1.5709807872772217
Validation loss: 2.272163430849711

Epoch: 5| Step: 5
Training loss: 1.8623275756835938
Validation loss: 2.310816466808319

Epoch: 5| Step: 6
Training loss: 2.1356589794158936
Validation loss: 2.3296204109986625

Epoch: 5| Step: 7
Training loss: 2.0853333473205566
Validation loss: 2.265659431616465

Epoch: 5| Step: 8
Training loss: 2.3076679706573486
Validation loss: 2.3012129863103232

Epoch: 5| Step: 9
Training loss: 1.543229579925537
Validation loss: 2.2924853761990867

Epoch: 5| Step: 10
Training loss: 1.58352792263031
Validation loss: 2.235215872526169

Epoch: 5| Step: 11
Training loss: 1.3558684587478638
Validation loss: 2.259903132915497

Epoch: 52| Step: 0
Training loss: 2.606902599334717
Validation loss: 2.2647735873858132

Epoch: 5| Step: 1
Training loss: 1.6915359497070312
Validation loss: 2.1397067109743753

Epoch: 5| Step: 2
Training loss: 1.8470218181610107
Validation loss: 2.2713483224312463

Epoch: 5| Step: 3
Training loss: 1.7838112115859985
Validation loss: 2.2203003416458764

Epoch: 5| Step: 4
Training loss: 2.2798123359680176
Validation loss: 2.269039864341418

Epoch: 5| Step: 5
Training loss: 1.6541204452514648
Validation loss: 2.171069706479708

Epoch: 5| Step: 6
Training loss: 1.957268476486206
Validation loss: 2.276781514286995

Epoch: 5| Step: 7
Training loss: 2.1675875186920166
Validation loss: 2.1938670873641968

Epoch: 5| Step: 8
Training loss: 2.587775468826294
Validation loss: 2.1955950409173965

Epoch: 5| Step: 9
Training loss: 2.2044482231140137
Validation loss: 2.255369022488594

Epoch: 5| Step: 10
Training loss: 2.223741054534912
Validation loss: 2.1952672203381858

Epoch: 5| Step: 11
Training loss: 1.546743392944336
Validation loss: 2.1718778858582177

Epoch: 53| Step: 0
Training loss: 2.023206949234009
Validation loss: 2.1670961380004883

Epoch: 5| Step: 1
Training loss: 1.6546075344085693
Validation loss: 2.1305159429709115

Epoch: 5| Step: 2
Training loss: 2.5100021362304688
Validation loss: 2.2032583157221475

Epoch: 5| Step: 3
Training loss: 2.053933620452881
Validation loss: 2.1513669540484748

Epoch: 5| Step: 4
Training loss: 2.440783977508545
Validation loss: 2.287133206923803

Epoch: 5| Step: 5
Training loss: 2.03741455078125
Validation loss: 2.226975699265798

Epoch: 5| Step: 6
Training loss: 1.9956629276275635
Validation loss: 2.1583555241425834

Epoch: 5| Step: 7
Training loss: 1.97933030128479
Validation loss: 2.2778844833374023

Epoch: 5| Step: 8
Training loss: 2.3996877670288086
Validation loss: 2.258465220530828

Epoch: 5| Step: 9
Training loss: 1.8959964513778687
Validation loss: 2.3181951393683753

Epoch: 5| Step: 10
Training loss: 1.7887979745864868
Validation loss: 2.3122006555398307

Epoch: 5| Step: 11
Training loss: 2.1731207370758057
Validation loss: 2.261957824230194

Epoch: 54| Step: 0
Training loss: 2.390845775604248
Validation loss: 2.2690855960051217

Epoch: 5| Step: 1
Training loss: 1.9547417163848877
Validation loss: 2.2150666217009225

Epoch: 5| Step: 2
Training loss: 2.594170570373535
Validation loss: 2.14836152891318

Epoch: 5| Step: 3
Training loss: 2.120337963104248
Validation loss: 2.2039217750231423

Epoch: 5| Step: 4
Training loss: 1.9218450784683228
Validation loss: 2.160932496190071

Epoch: 5| Step: 5
Training loss: 1.796741247177124
Validation loss: 2.218362728754679

Epoch: 5| Step: 6
Training loss: 2.0599935054779053
Validation loss: 2.2497466256221137

Epoch: 5| Step: 7
Training loss: 2.734920024871826
Validation loss: 2.1531211535135903

Epoch: 5| Step: 8
Training loss: 1.7025598287582397
Validation loss: 2.1779339760541916

Epoch: 5| Step: 9
Training loss: 1.8892056941986084
Validation loss: 2.2760733564694724

Epoch: 5| Step: 10
Training loss: 1.9230804443359375
Validation loss: 2.233738362789154

Epoch: 5| Step: 11
Training loss: 2.373074531555176
Validation loss: 2.2168445189793906

Epoch: 55| Step: 0
Training loss: 2.3726067543029785
Validation loss: 2.2027911047140756

Epoch: 5| Step: 1
Training loss: 2.0076546669006348
Validation loss: 2.2171270896991095

Epoch: 5| Step: 2
Training loss: 1.7969996929168701
Validation loss: 2.1229636122783027

Epoch: 5| Step: 3
Training loss: 1.8923107385635376
Validation loss: 2.3048530220985413

Epoch: 5| Step: 4
Training loss: 2.419532060623169
Validation loss: 2.2393857141335807

Epoch: 5| Step: 5
Training loss: 2.053635835647583
Validation loss: 2.3049118171135583

Epoch: 5| Step: 6
Training loss: 2.1608681678771973
Validation loss: 2.2192793786525726

Epoch: 5| Step: 7
Training loss: 1.9876350164413452
Validation loss: 2.2141630301872888

Epoch: 5| Step: 8
Training loss: 1.843798279762268
Validation loss: 2.1897837022940316

Epoch: 5| Step: 9
Training loss: 2.036024570465088
Validation loss: 2.1942640592654548

Epoch: 5| Step: 10
Training loss: 1.8851683139801025
Validation loss: 2.123036260406176

Epoch: 5| Step: 11
Training loss: 1.9306142330169678
Validation loss: 2.1766147166490555

Epoch: 56| Step: 0
Training loss: 1.6758644580841064
Validation loss: 2.24589932958285

Epoch: 5| Step: 1
Training loss: 2.4213147163391113
Validation loss: 2.2509849667549133

Epoch: 5| Step: 2
Training loss: 1.86200749874115
Validation loss: 2.2064125587542853

Epoch: 5| Step: 3
Training loss: 2.658337354660034
Validation loss: 2.2494556605815887

Epoch: 5| Step: 4
Training loss: 2.27736759185791
Validation loss: 2.182155594229698

Epoch: 5| Step: 5
Training loss: 1.5591102838516235
Validation loss: 2.255669489502907

Epoch: 5| Step: 6
Training loss: 2.199134111404419
Validation loss: 2.217136656244596

Epoch: 5| Step: 7
Training loss: 1.6945149898529053
Validation loss: 2.2269910673300424

Epoch: 5| Step: 8
Training loss: 2.250441551208496
Validation loss: 2.178842564423879

Epoch: 5| Step: 9
Training loss: 1.9838119745254517
Validation loss: 2.179429749647776

Epoch: 5| Step: 10
Training loss: 1.6880632638931274
Validation loss: 2.147487382094065

Epoch: 5| Step: 11
Training loss: 0.9567259550094604
Validation loss: 2.196255495150884

Epoch: 57| Step: 0
Training loss: 1.8755056858062744
Validation loss: 2.211490968863169

Epoch: 5| Step: 1
Training loss: 2.4210598468780518
Validation loss: 2.282039701938629

Epoch: 5| Step: 2
Training loss: 2.088235855102539
Validation loss: 2.246460641423861

Epoch: 5| Step: 3
Training loss: 2.0077102184295654
Validation loss: 2.3319251388311386

Epoch: 5| Step: 4
Training loss: 1.8279311656951904
Validation loss: 2.238292694091797

Epoch: 5| Step: 5
Training loss: 2.0981528759002686
Validation loss: 2.267508496840795

Epoch: 5| Step: 6
Training loss: 2.2535641193389893
Validation loss: 2.251002495487531

Epoch: 5| Step: 7
Training loss: 1.8890597820281982
Validation loss: 2.3118893156449

Epoch: 5| Step: 8
Training loss: 2.066326856613159
Validation loss: 2.265990654627482

Epoch: 5| Step: 9
Training loss: 1.9314903020858765
Validation loss: 2.228489508231481

Epoch: 5| Step: 10
Training loss: 2.3631036281585693
Validation loss: 2.3099801341692605

Epoch: 5| Step: 11
Training loss: 1.4229071140289307
Validation loss: 2.229524532953898

Epoch: 58| Step: 0
Training loss: 2.0651040077209473
Validation loss: 2.308925857146581

Epoch: 5| Step: 1
Training loss: 1.7868282794952393
Validation loss: 2.2804509500662484

Epoch: 5| Step: 2
Training loss: 1.7730640172958374
Validation loss: 2.341822405656179

Epoch: 5| Step: 3
Training loss: 1.3535401821136475
Validation loss: 2.3055741091569266

Epoch: 5| Step: 4
Training loss: 2.0821471214294434
Validation loss: 2.386272390683492

Epoch: 5| Step: 5
Training loss: 2.0709919929504395
Validation loss: 2.4178916215896606

Epoch: 5| Step: 6
Training loss: 2.835721254348755
Validation loss: 2.3221259315808616

Epoch: 5| Step: 7
Training loss: 1.9007160663604736
Validation loss: 2.2972187300523124

Epoch: 5| Step: 8
Training loss: 2.489157199859619
Validation loss: 2.2706491698821387

Epoch: 5| Step: 9
Training loss: 1.9190051555633545
Validation loss: 2.2851635615030923

Epoch: 5| Step: 10
Training loss: 2.0474417209625244
Validation loss: 2.288730929295222

Epoch: 5| Step: 11
Training loss: 0.9978150129318237
Validation loss: 2.216525211930275

Epoch: 59| Step: 0
Training loss: 1.4801762104034424
Validation loss: 2.2052319198846817

Epoch: 5| Step: 1
Training loss: 2.275691270828247
Validation loss: 2.2849601109822593

Epoch: 5| Step: 2
Training loss: 1.7534255981445312
Validation loss: 2.102475052078565

Epoch: 5| Step: 3
Training loss: 1.57818603515625
Validation loss: 2.1542535026868186

Epoch: 5| Step: 4
Training loss: 1.810232162475586
Validation loss: 2.279048298796018

Epoch: 5| Step: 5
Training loss: 2.439004421234131
Validation loss: 2.237417235970497

Epoch: 5| Step: 6
Training loss: 1.908704400062561
Validation loss: 2.176393672823906

Epoch: 5| Step: 7
Training loss: 2.364161252975464
Validation loss: 2.1976105769475303

Epoch: 5| Step: 8
Training loss: 1.9641574621200562
Validation loss: 2.174143756429354

Epoch: 5| Step: 9
Training loss: 2.5956501960754395
Validation loss: 2.405699531237284

Epoch: 5| Step: 10
Training loss: 1.4436900615692139
Validation loss: 2.2934065659840903

Epoch: 5| Step: 11
Training loss: 2.210638999938965
Validation loss: 2.2458825409412384

Epoch: 60| Step: 0
Training loss: 2.602128744125366
Validation loss: 2.203909014662107

Epoch: 5| Step: 1
Training loss: 1.9249372482299805
Validation loss: 2.278537010153135

Epoch: 5| Step: 2
Training loss: 2.2144570350646973
Validation loss: 2.243766744931539

Epoch: 5| Step: 3
Training loss: 2.096968173980713
Validation loss: 2.1687704076369605

Epoch: 5| Step: 4
Training loss: 2.8213653564453125
Validation loss: 2.097460776567459

Epoch: 5| Step: 5
Training loss: 1.5901286602020264
Validation loss: 2.127991726001104

Epoch: 5| Step: 6
Training loss: 1.121355652809143
Validation loss: 2.2066121300061545

Epoch: 5| Step: 7
Training loss: 2.2580718994140625
Validation loss: 2.23442205786705

Epoch: 5| Step: 8
Training loss: 1.8189300298690796
Validation loss: 2.1818974167108536

Epoch: 5| Step: 9
Training loss: 1.4115885496139526
Validation loss: 2.127707600593567

Epoch: 5| Step: 10
Training loss: 2.1756253242492676
Validation loss: 2.227638676762581

Epoch: 5| Step: 11
Training loss: 2.718644618988037
Validation loss: 2.1749325692653656

Epoch: 61| Step: 0
Training loss: 1.6758689880371094
Validation loss: 2.124192545811335

Epoch: 5| Step: 1
Training loss: 1.412950873374939
Validation loss: 2.253496597210566

Epoch: 5| Step: 2
Training loss: 2.6354002952575684
Validation loss: 2.2773138284683228

Epoch: 5| Step: 3
Training loss: 1.8711891174316406
Validation loss: 2.2369463046391806

Epoch: 5| Step: 4
Training loss: 2.089919328689575
Validation loss: 2.1709992090861

Epoch: 5| Step: 5
Training loss: 2.092212200164795
Validation loss: 2.3156313747167587

Epoch: 5| Step: 6
Training loss: 1.9373337030410767
Validation loss: 2.152430549263954

Epoch: 5| Step: 7
Training loss: 2.542517900466919
Validation loss: 2.260284195343653

Epoch: 5| Step: 8
Training loss: 1.7464287281036377
Validation loss: 2.2841478486855826

Epoch: 5| Step: 9
Training loss: 2.3327345848083496
Validation loss: 2.2907379269599915

Epoch: 5| Step: 10
Training loss: 1.9636223316192627
Validation loss: 2.315156032641729

Epoch: 5| Step: 11
Training loss: 1.3990190029144287
Validation loss: 2.3083366652329764

Epoch: 62| Step: 0
Training loss: 1.9509111642837524
Validation loss: 2.3458153307437897

Epoch: 5| Step: 1
Training loss: 2.1911158561706543
Validation loss: 2.2887535840272903

Epoch: 5| Step: 2
Training loss: 2.291308641433716
Validation loss: 2.270722975333532

Epoch: 5| Step: 3
Training loss: 2.2091827392578125
Validation loss: 2.220994313557943

Epoch: 5| Step: 4
Training loss: 2.1505379676818848
Validation loss: 2.3449299037456512

Epoch: 5| Step: 5
Training loss: 2.202421188354492
Validation loss: 2.1910723199446998

Epoch: 5| Step: 6
Training loss: 1.9031509160995483
Validation loss: 2.183876449863116

Epoch: 5| Step: 7
Training loss: 1.7520427703857422
Validation loss: 2.2041812936464944

Epoch: 5| Step: 8
Training loss: 2.2607078552246094
Validation loss: 2.1923085004091263

Epoch: 5| Step: 9
Training loss: 2.0349621772766113
Validation loss: 2.278092324733734

Epoch: 5| Step: 10
Training loss: 1.7524471282958984
Validation loss: 2.1591745018959045

Epoch: 5| Step: 11
Training loss: 2.2206921577453613
Validation loss: 2.255591740210851

Epoch: 63| Step: 0
Training loss: 1.5820561647415161
Validation loss: 2.1286746064821878

Epoch: 5| Step: 1
Training loss: 2.238884687423706
Validation loss: 2.3032072484493256

Epoch: 5| Step: 2
Training loss: 2.5995559692382812
Validation loss: 2.3095459640026093

Epoch: 5| Step: 3
Training loss: 1.5815140008926392
Validation loss: 2.254355862736702

Epoch: 5| Step: 4
Training loss: 2.220125198364258
Validation loss: 2.3535686433315277

Epoch: 5| Step: 5
Training loss: 1.782379388809204
Validation loss: 2.2987283070882163

Epoch: 5| Step: 6
Training loss: 1.569419264793396
Validation loss: 2.2620037297407785

Epoch: 5| Step: 7
Training loss: 1.6138694286346436
Validation loss: 2.257041027148565

Epoch: 5| Step: 8
Training loss: 1.6720794439315796
Validation loss: 2.2694579561551413

Epoch: 5| Step: 9
Training loss: 1.9296159744262695
Validation loss: 2.19610266884168

Epoch: 5| Step: 10
Training loss: 2.6514556407928467
Validation loss: 2.206933190425237

Epoch: 5| Step: 11
Training loss: 2.8968505859375
Validation loss: 2.105486830075582

Epoch: 64| Step: 0
Training loss: 2.078557252883911
Validation loss: 2.173043737808863

Epoch: 5| Step: 1
Training loss: 1.6701068878173828
Validation loss: 2.1641786694526672

Epoch: 5| Step: 2
Training loss: 2.127288818359375
Validation loss: 2.1822995195786157

Epoch: 5| Step: 3
Training loss: 2.0689868927001953
Validation loss: 2.2046144356330237

Epoch: 5| Step: 4
Training loss: 1.8959522247314453
Validation loss: 2.2940750122070312

Epoch: 5| Step: 5
Training loss: 2.1877365112304688
Validation loss: 2.347696160276731

Epoch: 5| Step: 6
Training loss: 1.796089768409729
Validation loss: 2.2564458002646766

Epoch: 5| Step: 7
Training loss: 2.039818286895752
Validation loss: 2.240725109974543

Epoch: 5| Step: 8
Training loss: 2.1001458168029785
Validation loss: 2.2428773840268454

Epoch: 5| Step: 9
Training loss: 2.409470319747925
Validation loss: 2.1900658855835595

Epoch: 5| Step: 10
Training loss: 1.8520519733428955
Validation loss: 2.212988257408142

Epoch: 5| Step: 11
Training loss: 3.2349143028259277
Validation loss: 2.340652257204056

Epoch: 65| Step: 0
Training loss: 1.6812530755996704
Validation loss: 2.147716154654821

Epoch: 5| Step: 1
Training loss: 2.1921210289001465
Validation loss: 2.2950307726860046

Epoch: 5| Step: 2
Training loss: 1.7709687948226929
Validation loss: 2.238207300504049

Epoch: 5| Step: 3
Training loss: 2.4066338539123535
Validation loss: 2.222403292854627

Epoch: 5| Step: 4
Training loss: 2.149491548538208
Validation loss: 2.2051192224025726

Epoch: 5| Step: 5
Training loss: 2.2669661045074463
Validation loss: 2.1420126954714456

Epoch: 5| Step: 6
Training loss: 2.153597831726074
Validation loss: 2.2635870973269143

Epoch: 5| Step: 7
Training loss: 1.795828104019165
Validation loss: 2.273844450712204

Epoch: 5| Step: 8
Training loss: 1.8220767974853516
Validation loss: 2.2276545663674674

Epoch: 5| Step: 9
Training loss: 2.432682514190674
Validation loss: 2.285026729106903

Epoch: 5| Step: 10
Training loss: 1.6561305522918701
Validation loss: 2.1626011629899344

Epoch: 5| Step: 11
Training loss: 1.9365203380584717
Validation loss: 2.2223349114259086

Epoch: 66| Step: 0
Training loss: 1.6016576290130615
Validation loss: 2.3401900629202523

Epoch: 5| Step: 1
Training loss: 2.2404582500457764
Validation loss: 2.1391595204671225

Epoch: 5| Step: 2
Training loss: 2.0828261375427246
Validation loss: 2.164258594314257

Epoch: 5| Step: 3
Training loss: 2.4922938346862793
Validation loss: 2.2556383113066354

Epoch: 5| Step: 4
Training loss: 1.7876131534576416
Validation loss: 2.2995076229174933

Epoch: 5| Step: 5
Training loss: 1.927594542503357
Validation loss: 2.2753573854764304

Epoch: 5| Step: 6
Training loss: 2.132486581802368
Validation loss: 2.2845300833384194

Epoch: 5| Step: 7
Training loss: 1.8120893239974976
Validation loss: 2.230317880709966

Epoch: 5| Step: 8
Training loss: 2.103137493133545
Validation loss: 2.2837455372015634

Epoch: 5| Step: 9
Training loss: 1.992505431175232
Validation loss: 2.195485437909762

Epoch: 5| Step: 10
Training loss: 2.497739791870117
Validation loss: 2.218701551357905

Epoch: 5| Step: 11
Training loss: 3.625643253326416
Validation loss: 2.294609119494756

Epoch: 67| Step: 0
Training loss: 2.0763099193573
Validation loss: 2.1928173998991647

Epoch: 5| Step: 1
Training loss: 1.4793145656585693
Validation loss: 2.1017212023337684

Epoch: 5| Step: 2
Training loss: 1.4400217533111572
Validation loss: 2.2442473669846854

Epoch: 5| Step: 3
Training loss: 1.9113658666610718
Validation loss: 2.3153451482454934

Epoch: 5| Step: 4
Training loss: 1.9557243585586548
Validation loss: 2.4114624857902527

Epoch: 5| Step: 5
Training loss: 1.849649429321289
Validation loss: 2.468467026948929

Epoch: 5| Step: 6
Training loss: 2.5291037559509277
Validation loss: 2.4174276938041053

Epoch: 5| Step: 7
Training loss: 2.23524808883667
Validation loss: 2.4798488120237985

Epoch: 5| Step: 8
Training loss: 2.6674304008483887
Validation loss: 2.550786316394806

Epoch: 5| Step: 9
Training loss: 2.399027109146118
Validation loss: 2.3806792894999185

Epoch: 5| Step: 10
Training loss: 1.7830520868301392
Validation loss: 2.306557774543762

Epoch: 5| Step: 11
Training loss: 2.3270461559295654
Validation loss: 2.1997988869746528

Epoch: 68| Step: 0
Training loss: 1.9757273197174072
Validation loss: 2.199704796075821

Epoch: 5| Step: 1
Training loss: 2.530123710632324
Validation loss: 2.279601275920868

Epoch: 5| Step: 2
Training loss: 2.153069257736206
Validation loss: 2.339548796415329

Epoch: 5| Step: 3
Training loss: 2.4274356365203857
Validation loss: 2.193048973878225

Epoch: 5| Step: 4
Training loss: 1.980968713760376
Validation loss: 2.173974816997846

Epoch: 5| Step: 5
Training loss: 1.5682557821273804
Validation loss: 2.2413177440563836

Epoch: 5| Step: 6
Training loss: 2.0303103923797607
Validation loss: 2.202665776014328

Epoch: 5| Step: 7
Training loss: 1.5956193208694458
Validation loss: 2.329226275285085

Epoch: 5| Step: 8
Training loss: 2.1110196113586426
Validation loss: 2.2092107137044272

Epoch: 5| Step: 9
Training loss: 1.9164044857025146
Validation loss: 2.148096024990082

Epoch: 5| Step: 10
Training loss: 2.3327066898345947
Validation loss: 2.136843686302503

Epoch: 5| Step: 11
Training loss: 1.0175318717956543
Validation loss: 2.3613247772057853

Epoch: 69| Step: 0
Training loss: 1.8688608407974243
Validation loss: 2.298971508940061

Epoch: 5| Step: 1
Training loss: 2.153653383255005
Validation loss: 2.2981388767560325

Epoch: 5| Step: 2
Training loss: 2.250701427459717
Validation loss: 2.3276508847872415

Epoch: 5| Step: 3
Training loss: 1.9443485736846924
Validation loss: 2.2921105374892554

Epoch: 5| Step: 4
Training loss: 1.2251602411270142
Validation loss: 2.2022657990455627

Epoch: 5| Step: 5
Training loss: 2.6555356979370117
Validation loss: 2.2021988878647485

Epoch: 5| Step: 6
Training loss: 1.5531495809555054
Validation loss: 2.225016569097837

Epoch: 5| Step: 7
Training loss: 2.2774205207824707
Validation loss: 2.2662883400917053

Epoch: 5| Step: 8
Training loss: 1.9520097970962524
Validation loss: 2.067251240213712

Epoch: 5| Step: 9
Training loss: 1.812909483909607
Validation loss: 2.1558951884508133

Epoch: 5| Step: 10
Training loss: 2.2784314155578613
Validation loss: 2.1869343916575112

Epoch: 5| Step: 11
Training loss: 1.6957788467407227
Validation loss: 2.211765299240748

Epoch: 70| Step: 0
Training loss: 1.6070703268051147
Validation loss: 2.335656354824702

Epoch: 5| Step: 1
Training loss: 2.4545304775238037
Validation loss: 2.2499193052450814

Epoch: 5| Step: 2
Training loss: 2.0254344940185547
Validation loss: 2.2066593567530313

Epoch: 5| Step: 3
Training loss: 1.901108980178833
Validation loss: 2.1570580303668976

Epoch: 5| Step: 4
Training loss: 1.9048945903778076
Validation loss: 2.312107260028521

Epoch: 5| Step: 5
Training loss: 1.7442066669464111
Validation loss: 2.2891353964805603

Epoch: 5| Step: 6
Training loss: 1.9990533590316772
Validation loss: 2.2768780291080475

Epoch: 5| Step: 7
Training loss: 1.8980553150177002
Validation loss: 2.2622409562269845

Epoch: 5| Step: 8
Training loss: 2.110563039779663
Validation loss: 2.2258426447709403

Epoch: 5| Step: 9
Training loss: 2.826462507247925
Validation loss: 2.2802623758713403

Epoch: 5| Step: 10
Training loss: 2.34222674369812
Validation loss: 2.2003906269868216

Epoch: 5| Step: 11
Training loss: 2.6144580841064453
Validation loss: 2.1906343003114066

Epoch: 71| Step: 0
Training loss: 1.967200517654419
Validation loss: 2.3233318428198495

Epoch: 5| Step: 1
Training loss: 1.7198207378387451
Validation loss: 2.251154273748398

Epoch: 5| Step: 2
Training loss: 2.1033217906951904
Validation loss: 2.254825154940287

Epoch: 5| Step: 3
Training loss: 1.8899612426757812
Validation loss: 2.265660966436068

Epoch: 5| Step: 4
Training loss: 1.6165885925292969
Validation loss: 2.207093839844068

Epoch: 5| Step: 5
Training loss: 2.1141867637634277
Validation loss: 2.214914013942083

Epoch: 5| Step: 6
Training loss: 2.0422635078430176
Validation loss: 2.2256567577521005

Epoch: 5| Step: 7
Training loss: 2.76609468460083
Validation loss: 2.25977930923303

Epoch: 5| Step: 8
Training loss: 2.229365587234497
Validation loss: 2.177485167980194

Epoch: 5| Step: 9
Training loss: 2.060076951980591
Validation loss: 2.161672761042913

Epoch: 5| Step: 10
Training loss: 1.8180313110351562
Validation loss: 2.2167141834894815

Epoch: 5| Step: 11
Training loss: 2.163599967956543
Validation loss: 2.2079482128222785

Epoch: 72| Step: 0
Training loss: 1.9982459545135498
Validation loss: 2.1997691889603934

Epoch: 5| Step: 1
Training loss: 1.908513069152832
Validation loss: 2.1193475226561227

Epoch: 5| Step: 2
Training loss: 1.7761242389678955
Validation loss: 2.2462443808714547

Epoch: 5| Step: 3
Training loss: 1.94878351688385
Validation loss: 2.2483798613150916

Epoch: 5| Step: 4
Training loss: 1.9071245193481445
Validation loss: 2.202315161625544

Epoch: 5| Step: 5
Training loss: 2.2720513343811035
Validation loss: 2.2845091968774796

Epoch: 5| Step: 6
Training loss: 2.0917067527770996
Validation loss: 2.204789231220881

Epoch: 5| Step: 7
Training loss: 2.1951441764831543
Validation loss: 2.123887211084366

Epoch: 5| Step: 8
Training loss: 2.077986001968384
Validation loss: 2.2370004057884216

Epoch: 5| Step: 9
Training loss: 2.113659381866455
Validation loss: 2.1729910373687744

Epoch: 5| Step: 10
Training loss: 2.249757766723633
Validation loss: 2.2536752919356027

Epoch: 5| Step: 11
Training loss: 2.0205607414245605
Validation loss: 2.1664588153362274

Epoch: 73| Step: 0
Training loss: 2.1644062995910645
Validation loss: 2.1786379913489022

Epoch: 5| Step: 1
Training loss: 1.4878982305526733
Validation loss: 2.16325314839681

Epoch: 5| Step: 2
Training loss: 2.560002088546753
Validation loss: 2.2844360768795013

Epoch: 5| Step: 3
Training loss: 2.050952434539795
Validation loss: 2.3034719030062356

Epoch: 5| Step: 4
Training loss: 1.9216852188110352
Validation loss: 2.2200016379356384

Epoch: 5| Step: 5
Training loss: 1.8327810764312744
Validation loss: 2.16500091056029

Epoch: 5| Step: 6
Training loss: 2.102679967880249
Validation loss: 2.2119284321864447

Epoch: 5| Step: 7
Training loss: 2.151435136795044
Validation loss: 2.178061231970787

Epoch: 5| Step: 8
Training loss: 1.5943124294281006
Validation loss: 2.1157890458901725

Epoch: 5| Step: 9
Training loss: 1.8515357971191406
Validation loss: 2.1868940939505896

Epoch: 5| Step: 10
Training loss: 2.3063671588897705
Validation loss: 2.2234988609949746

Epoch: 5| Step: 11
Training loss: 2.638484477996826
Validation loss: 2.2477667729059854

Epoch: 74| Step: 0
Training loss: 2.121192455291748
Validation loss: 2.2601803640524545

Epoch: 5| Step: 1
Training loss: 1.7010294198989868
Validation loss: 2.1620370000600815

Epoch: 5| Step: 2
Training loss: 2.1347930431365967
Validation loss: 2.236663947502772

Epoch: 5| Step: 3
Training loss: 2.064990520477295
Validation loss: 2.155372674266497

Epoch: 5| Step: 4
Training loss: 2.05637788772583
Validation loss: 2.1895840068658194

Epoch: 5| Step: 5
Training loss: 2.2063846588134766
Validation loss: 2.154709647099177

Epoch: 5| Step: 6
Training loss: 2.4666600227355957
Validation loss: 2.125483383735021

Epoch: 5| Step: 7
Training loss: 2.2298145294189453
Validation loss: 2.120845471819242

Epoch: 5| Step: 8
Training loss: 1.7387298345565796
Validation loss: 2.2520327270030975

Epoch: 5| Step: 9
Training loss: 1.8295854330062866
Validation loss: 2.1679715116818747

Epoch: 5| Step: 10
Training loss: 2.1956982612609863
Validation loss: 2.241818646589915

Epoch: 5| Step: 11
Training loss: 1.7217743396759033
Validation loss: 2.1597225219011307

Epoch: 75| Step: 0
Training loss: 1.7530944347381592
Validation loss: 2.2970785895983377

Epoch: 5| Step: 1
Training loss: 1.7408310174942017
Validation loss: 2.266156941652298

Epoch: 5| Step: 2
Training loss: 1.9935001134872437
Validation loss: 2.1990790516138077

Epoch: 5| Step: 3
Training loss: 2.061763048171997
Validation loss: 2.1726485937833786

Epoch: 5| Step: 4
Training loss: 2.2542388439178467
Validation loss: 2.174233297506968

Epoch: 5| Step: 5
Training loss: 2.44435715675354
Validation loss: 2.2160993864138923

Epoch: 5| Step: 6
Training loss: 2.2143895626068115
Validation loss: 2.1073778569698334

Epoch: 5| Step: 7
Training loss: 2.1051383018493652
Validation loss: 2.2598943014939628

Epoch: 5| Step: 8
Training loss: 1.9549438953399658
Validation loss: 2.2584514170885086

Epoch: 5| Step: 9
Training loss: 2.0800039768218994
Validation loss: 2.2257985870043435

Epoch: 5| Step: 10
Training loss: 1.8337440490722656
Validation loss: 2.1440055618683496

Epoch: 5| Step: 11
Training loss: 0.792465329170227
Validation loss: 2.180059110124906

Epoch: 76| Step: 0
Training loss: 1.8761409521102905
Validation loss: 2.262746433417002

Epoch: 5| Step: 1
Training loss: 1.9869000911712646
Validation loss: 2.30295459429423

Epoch: 5| Step: 2
Training loss: 1.763347864151001
Validation loss: 2.1870091259479523

Epoch: 5| Step: 3
Training loss: 1.4179607629776
Validation loss: 2.172794848680496

Epoch: 5| Step: 4
Training loss: 1.7133514881134033
Validation loss: 2.2191607455412545

Epoch: 5| Step: 5
Training loss: 2.3913469314575195
Validation loss: 2.2721199045578637

Epoch: 5| Step: 6
Training loss: 1.6750905513763428
Validation loss: 2.293133666117986

Epoch: 5| Step: 7
Training loss: 2.4384372234344482
Validation loss: 2.1866013606389365

Epoch: 5| Step: 8
Training loss: 2.1123690605163574
Validation loss: 2.199373538295428

Epoch: 5| Step: 9
Training loss: 2.364928722381592
Validation loss: 2.3097296406825385

Epoch: 5| Step: 10
Training loss: 2.3972511291503906
Validation loss: 2.2935092399517694

Epoch: 5| Step: 11
Training loss: 1.4219233989715576
Validation loss: 2.2291360149780908

Epoch: 77| Step: 0
Training loss: 2.1648175716400146
Validation loss: 2.2102932582298913

Epoch: 5| Step: 1
Training loss: 1.89372980594635
Validation loss: 2.1408629020055137

Epoch: 5| Step: 2
Training loss: 2.1209206581115723
Validation loss: 2.181005055705706

Epoch: 5| Step: 3
Training loss: 1.492735505104065
Validation loss: 2.227891062696775

Epoch: 5| Step: 4
Training loss: 1.7223857641220093
Validation loss: 2.2060338159402213

Epoch: 5| Step: 5
Training loss: 2.0377211570739746
Validation loss: 2.1937746902306876

Epoch: 5| Step: 6
Training loss: 1.6000715494155884
Validation loss: 2.226720859607061

Epoch: 5| Step: 7
Training loss: 2.3402562141418457
Validation loss: 2.134074568748474

Epoch: 5| Step: 8
Training loss: 2.502004384994507
Validation loss: 2.224901999036471

Epoch: 5| Step: 9
Training loss: 1.8008480072021484
Validation loss: 2.1897650559743247

Epoch: 5| Step: 10
Training loss: 1.8417212963104248
Validation loss: 2.263617600003878

Epoch: 5| Step: 11
Training loss: 1.8490360975265503
Validation loss: 2.292275701959928

Epoch: 78| Step: 0
Training loss: 1.807469367980957
Validation loss: 2.178243483106295

Epoch: 5| Step: 1
Training loss: 2.2052230834960938
Validation loss: 2.1568132738272348

Epoch: 5| Step: 2
Training loss: 1.949387788772583
Validation loss: 2.147918293873469

Epoch: 5| Step: 3
Training loss: 2.009490489959717
Validation loss: 2.252617950240771

Epoch: 5| Step: 4
Training loss: 2.0524563789367676
Validation loss: 2.343196158607801

Epoch: 5| Step: 5
Training loss: 2.0244007110595703
Validation loss: 2.4960389882326126

Epoch: 5| Step: 6
Training loss: 2.401028871536255
Validation loss: 2.4397183458010354

Epoch: 5| Step: 7
Training loss: 2.129427194595337
Validation loss: 2.3087834417819977

Epoch: 5| Step: 8
Training loss: 2.207886219024658
Validation loss: 2.2982148627440133

Epoch: 5| Step: 9
Training loss: 1.851544976234436
Validation loss: 2.338382030526797

Epoch: 5| Step: 10
Training loss: 1.6316916942596436
Validation loss: 2.127044598261515

Epoch: 5| Step: 11
Training loss: 2.2885589599609375
Validation loss: 2.16793363293012

Epoch: 79| Step: 0
Training loss: 1.5546348094940186
Validation loss: 2.300087551275889

Epoch: 5| Step: 1
Training loss: 2.0714030265808105
Validation loss: 2.250166247288386

Epoch: 5| Step: 2
Training loss: 2.0846900939941406
Validation loss: 2.2693551580111184

Epoch: 5| Step: 3
Training loss: 1.757745385169983
Validation loss: 2.234003007411957

Epoch: 5| Step: 4
Training loss: 2.346496105194092
Validation loss: 2.226548954844475

Epoch: 5| Step: 5
Training loss: 2.5828793048858643
Validation loss: 2.274801194667816

Epoch: 5| Step: 6
Training loss: 2.1736247539520264
Validation loss: 2.2198131630818048

Epoch: 5| Step: 7
Training loss: 2.460205316543579
Validation loss: 2.2036593606074653

Epoch: 5| Step: 8
Training loss: 1.9435237646102905
Validation loss: 2.1298999985059104

Epoch: 5| Step: 9
Training loss: 1.8634898662567139
Validation loss: 2.2195704181989035

Epoch: 5| Step: 10
Training loss: 2.5346949100494385
Validation loss: 2.243983179330826

Epoch: 5| Step: 11
Training loss: 1.8135011196136475
Validation loss: 2.247339501976967

Epoch: 80| Step: 0
Training loss: 2.1461617946624756
Validation loss: 2.1927807529767356

Epoch: 5| Step: 1
Training loss: 1.9712657928466797
Validation loss: 2.3388217886288962

Epoch: 5| Step: 2
Training loss: 2.2665905952453613
Validation loss: 2.308078487714132

Epoch: 5| Step: 3
Training loss: 2.3129196166992188
Validation loss: 2.337959125638008

Epoch: 5| Step: 4
Training loss: 2.2550556659698486
Validation loss: 2.3038700073957443

Epoch: 5| Step: 5
Training loss: 2.4199366569519043
Validation loss: 2.3689229587713876

Epoch: 5| Step: 6
Training loss: 2.378431797027588
Validation loss: 2.294907291730245

Epoch: 5| Step: 7
Training loss: 1.530239462852478
Validation loss: 2.2772516508897147

Epoch: 5| Step: 8
Training loss: 1.779130220413208
Validation loss: 2.176926309863726

Epoch: 5| Step: 9
Training loss: 2.0084807872772217
Validation loss: 2.246506169438362

Epoch: 5| Step: 10
Training loss: 1.943499207496643
Validation loss: 2.2439968387285867

Epoch: 5| Step: 11
Training loss: 1.6410428285598755
Validation loss: 2.217216377456983

Epoch: 81| Step: 0
Training loss: 1.888667345046997
Validation loss: 2.1765865087509155

Epoch: 5| Step: 1
Training loss: 2.3078343868255615
Validation loss: 2.2704844375451407

Epoch: 5| Step: 2
Training loss: 1.5360838174819946
Validation loss: 2.1940071185429892

Epoch: 5| Step: 3
Training loss: 2.1725335121154785
Validation loss: 2.1182124515374503

Epoch: 5| Step: 4
Training loss: 2.363105297088623
Validation loss: 2.2163558254639306

Epoch: 5| Step: 5
Training loss: 2.1549174785614014
Validation loss: 2.215940694014231

Epoch: 5| Step: 6
Training loss: 1.823604941368103
Validation loss: 2.175312320391337

Epoch: 5| Step: 7
Training loss: 1.9276643991470337
Validation loss: 2.1478878259658813

Epoch: 5| Step: 8
Training loss: 1.8313112258911133
Validation loss: 2.242138018210729

Epoch: 5| Step: 9
Training loss: 1.7280511856079102
Validation loss: 2.294854015111923

Epoch: 5| Step: 10
Training loss: 1.9002500772476196
Validation loss: 2.2720636427402496

Epoch: 5| Step: 11
Training loss: 1.8576956987380981
Validation loss: 2.241936797897021

Epoch: 82| Step: 0
Training loss: 1.9795854091644287
Validation loss: 2.256924400726954

Epoch: 5| Step: 1
Training loss: 1.3800140619277954
Validation loss: 2.3538978000481925

Epoch: 5| Step: 2
Training loss: 2.6400279998779297
Validation loss: 2.4338635305563607

Epoch: 5| Step: 3
Training loss: 2.194326877593994
Validation loss: 2.609636207421621

Epoch: 5| Step: 4
Training loss: 1.5496139526367188
Validation loss: 2.5159093737602234

Epoch: 5| Step: 5
Training loss: 2.3063080310821533
Validation loss: 2.5790135661760965

Epoch: 5| Step: 6
Training loss: 2.671613931655884
Validation loss: 2.487394521633784

Epoch: 5| Step: 7
Training loss: 2.181020975112915
Validation loss: 2.4274470855792365

Epoch: 5| Step: 8
Training loss: 2.3075695037841797
Validation loss: 2.3922167321046195

Epoch: 5| Step: 9
Training loss: 2.6536200046539307
Validation loss: 2.18597050011158

Epoch: 5| Step: 10
Training loss: 1.774773359298706
Validation loss: 2.208387022217115

Epoch: 5| Step: 11
Training loss: 1.0954539775848389
Validation loss: 2.128486384948095

Epoch: 83| Step: 0
Training loss: 2.00437068939209
Validation loss: 2.243028442064921

Epoch: 5| Step: 1
Training loss: 2.066100597381592
Validation loss: 2.1126639097929

Epoch: 5| Step: 2
Training loss: 1.779567003250122
Validation loss: 2.103741337855657

Epoch: 5| Step: 3
Training loss: 1.980177879333496
Validation loss: 2.2243167708317437

Epoch: 5| Step: 4
Training loss: 2.345629930496216
Validation loss: 2.1285380125045776

Epoch: 5| Step: 5
Training loss: 1.9817012548446655
Validation loss: 2.140651444594065

Epoch: 5| Step: 6
Training loss: 1.4140703678131104
Validation loss: 2.1467102766036987

Epoch: 5| Step: 7
Training loss: 2.326211929321289
Validation loss: 2.1185723344484964

Epoch: 5| Step: 8
Training loss: 2.676631450653076
Validation loss: 2.220627541343371

Epoch: 5| Step: 9
Training loss: 1.4900249242782593
Validation loss: 2.245782340566317

Epoch: 5| Step: 10
Training loss: 1.569024682044983
Validation loss: 2.1943370401859283

Epoch: 5| Step: 11
Training loss: 2.2803072929382324
Validation loss: 2.1926661481459937

Epoch: 84| Step: 0
Training loss: 2.3261168003082275
Validation loss: 2.1858633855978646

Epoch: 5| Step: 1
Training loss: 2.0479819774627686
Validation loss: 2.1912112087011337

Epoch: 5| Step: 2
Training loss: 1.9882776737213135
Validation loss: 2.1846107840538025

Epoch: 5| Step: 3
Training loss: 1.5818414688110352
Validation loss: 2.314430683851242

Epoch: 5| Step: 4
Training loss: 1.5439033508300781
Validation loss: 2.277972012758255

Epoch: 5| Step: 5
Training loss: 1.477601408958435
Validation loss: 2.1254308074712753

Epoch: 5| Step: 6
Training loss: 2.3732619285583496
Validation loss: 2.186953733364741

Epoch: 5| Step: 7
Training loss: 2.32305645942688
Validation loss: 2.1919045547644296

Epoch: 5| Step: 8
Training loss: 1.853844404220581
Validation loss: 2.1017035444577536

Epoch: 5| Step: 9
Training loss: 1.8334503173828125
Validation loss: 2.158764029542605

Epoch: 5| Step: 10
Training loss: 1.5517253875732422
Validation loss: 2.1468905011812844

Epoch: 5| Step: 11
Training loss: 2.431084394454956
Validation loss: 2.265329827864965

Epoch: 85| Step: 0
Training loss: 1.9205833673477173
Validation loss: 2.2136917114257812

Epoch: 5| Step: 1
Training loss: 1.9257328510284424
Validation loss: 2.22696061929067

Epoch: 5| Step: 2
Training loss: 2.0466666221618652
Validation loss: 2.24058968325456

Epoch: 5| Step: 3
Training loss: 1.5712934732437134
Validation loss: 2.2527198791503906

Epoch: 5| Step: 4
Training loss: 2.3035483360290527
Validation loss: 2.03180002172788

Epoch: 5| Step: 5
Training loss: 2.29945707321167
Validation loss: 2.1155566523472467

Epoch: 5| Step: 6
Training loss: 2.0772836208343506
Validation loss: 2.2846927543481192

Epoch: 5| Step: 7
Training loss: 1.8208433389663696
Validation loss: 2.175798177719116

Epoch: 5| Step: 8
Training loss: 1.7097396850585938
Validation loss: 2.200309415658315

Epoch: 5| Step: 9
Training loss: 2.114345073699951
Validation loss: 2.12092233200868

Epoch: 5| Step: 10
Training loss: 1.8191791772842407
Validation loss: 2.287326902151108

Epoch: 5| Step: 11
Training loss: 2.802501678466797
Validation loss: 2.2091295967499414

Epoch: 86| Step: 0
Training loss: 1.9626553058624268
Validation loss: 2.3834058940410614

Epoch: 5| Step: 1
Training loss: 1.839175820350647
Validation loss: 2.221355050802231

Epoch: 5| Step: 2
Training loss: 2.1917831897735596
Validation loss: 2.1335124323765435

Epoch: 5| Step: 3
Training loss: 2.0588252544403076
Validation loss: 2.1865540146827698

Epoch: 5| Step: 4
Training loss: 2.4153475761413574
Validation loss: 2.1227363497018814

Epoch: 5| Step: 5
Training loss: 2.027216672897339
Validation loss: 2.2412647704283395

Epoch: 5| Step: 6
Training loss: 1.8497251272201538
Validation loss: 2.2265040973822274

Epoch: 5| Step: 7
Training loss: 1.6067893505096436
Validation loss: 2.123371516664823

Epoch: 5| Step: 8
Training loss: 1.5683108568191528
Validation loss: 2.200358306368192

Epoch: 5| Step: 9
Training loss: 2.104795217514038
Validation loss: 2.182781974474589

Epoch: 5| Step: 10
Training loss: 1.7135852575302124
Validation loss: 2.177737464507421

Epoch: 5| Step: 11
Training loss: 3.061408519744873
Validation loss: 2.153497169415156

Epoch: 87| Step: 0
Training loss: 1.639909029006958
Validation loss: 2.2293574263652167

Epoch: 5| Step: 1
Training loss: 2.3085293769836426
Validation loss: 2.1396047472953796

Epoch: 5| Step: 2
Training loss: 1.2993292808532715
Validation loss: 2.218679075439771

Epoch: 5| Step: 3
Training loss: 2.082609176635742
Validation loss: 2.28379879395167

Epoch: 5| Step: 4
Training loss: 2.1594955921173096
Validation loss: 2.256332998474439

Epoch: 5| Step: 5
Training loss: 1.7860376834869385
Validation loss: 2.2844974994659424

Epoch: 5| Step: 6
Training loss: 2.0086922645568848
Validation loss: 2.258461202184359

Epoch: 5| Step: 7
Training loss: 2.2780394554138184
Validation loss: 2.2790669898192086

Epoch: 5| Step: 8
Training loss: 1.5779693126678467
Validation loss: 2.1916753699382148

Epoch: 5| Step: 9
Training loss: 1.923666000366211
Validation loss: 2.12019112209479

Epoch: 5| Step: 10
Training loss: 2.1323912143707275
Validation loss: 2.168302208185196

Epoch: 5| Step: 11
Training loss: 2.5804615020751953
Validation loss: 2.2126901050408683

Epoch: 88| Step: 0
Training loss: 1.4056670665740967
Validation loss: 2.160097728172938

Epoch: 5| Step: 1
Training loss: 1.8846021890640259
Validation loss: 2.153738165895144

Epoch: 5| Step: 2
Training loss: 2.1326301097869873
Validation loss: 2.256047561764717

Epoch: 5| Step: 3
Training loss: 2.0205085277557373
Validation loss: 2.2455445925394693

Epoch: 5| Step: 4
Training loss: 1.7234939336776733
Validation loss: 2.2197452584902444

Epoch: 5| Step: 5
Training loss: 2.2768452167510986
Validation loss: 2.210283021132151

Epoch: 5| Step: 6
Training loss: 2.2437920570373535
Validation loss: 2.2309684654076896

Epoch: 5| Step: 7
Training loss: 1.739748239517212
Validation loss: 2.281662662823995

Epoch: 5| Step: 8
Training loss: 1.8445768356323242
Validation loss: 2.2324297229448953

Epoch: 5| Step: 9
Training loss: 1.9247795343399048
Validation loss: 2.2081762303908667

Epoch: 5| Step: 10
Training loss: 2.016979694366455
Validation loss: 2.193595061699549

Epoch: 5| Step: 11
Training loss: 1.6812443733215332
Validation loss: 2.24008110165596

Epoch: 89| Step: 0
Training loss: 1.85337233543396
Validation loss: 2.1275201042493186

Epoch: 5| Step: 1
Training loss: 1.5091265439987183
Validation loss: 2.1720360070466995

Epoch: 5| Step: 2
Training loss: 2.2266998291015625
Validation loss: 2.279498800635338

Epoch: 5| Step: 3
Training loss: 2.32597017288208
Validation loss: 2.3166321516036987

Epoch: 5| Step: 4
Training loss: 2.094879150390625
Validation loss: 2.345864584048589

Epoch: 5| Step: 5
Training loss: 2.062568187713623
Validation loss: 2.4027080088853836

Epoch: 5| Step: 6
Training loss: 1.8641557693481445
Validation loss: 2.340184052785238

Epoch: 5| Step: 7
Training loss: 2.462759256362915
Validation loss: 2.329853802919388

Epoch: 5| Step: 8
Training loss: 1.9784317016601562
Validation loss: 2.3283798495928445

Epoch: 5| Step: 9
Training loss: 2.1292667388916016
Validation loss: 2.3805392185846963

Epoch: 5| Step: 10
Training loss: 1.8759227991104126
Validation loss: 2.259271666407585

Epoch: 5| Step: 11
Training loss: 2.026352882385254
Validation loss: 2.1852473268906274

Epoch: 90| Step: 0
Training loss: 1.2954673767089844
Validation loss: 2.2278576542933783

Epoch: 5| Step: 1
Training loss: 2.4440054893493652
Validation loss: 2.271883502602577

Epoch: 5| Step: 2
Training loss: 1.7676990032196045
Validation loss: 2.3632406493028006

Epoch: 5| Step: 3
Training loss: 2.762310743331909
Validation loss: 2.3730983436107635

Epoch: 5| Step: 4
Training loss: 1.9889580011367798
Validation loss: 2.3690232237180076

Epoch: 5| Step: 5
Training loss: 2.129251718521118
Validation loss: 2.3922220170497894

Epoch: 5| Step: 6
Training loss: 2.2357547283172607
Validation loss: 2.4270493586858115

Epoch: 5| Step: 7
Training loss: 2.1393775939941406
Validation loss: 2.245433752735456

Epoch: 5| Step: 8
Training loss: 2.309022903442383
Validation loss: 2.2889345784982047

Epoch: 5| Step: 9
Training loss: 1.872772216796875
Validation loss: 2.137941002845764

Epoch: 5| Step: 10
Training loss: 2.0638809204101562
Validation loss: 2.169491062561671

Epoch: 5| Step: 11
Training loss: 1.3459062576293945
Validation loss: 2.1354091465473175

Epoch: 91| Step: 0
Training loss: 2.047609806060791
Validation loss: 2.336346353093783

Epoch: 5| Step: 1
Training loss: 2.129098892211914
Validation loss: 2.5087425857782364

Epoch: 5| Step: 2
Training loss: 2.512399196624756
Validation loss: 2.5588998099168143

Epoch: 5| Step: 3
Training loss: 2.2737369537353516
Validation loss: 2.6672382752100625

Epoch: 5| Step: 4
Training loss: 2.902597427368164
Validation loss: 2.5503620902697244

Epoch: 5| Step: 5
Training loss: 2.180830478668213
Validation loss: 2.663436541954676

Epoch: 5| Step: 6
Training loss: 2.694047451019287
Validation loss: 2.607183337211609

Epoch: 5| Step: 7
Training loss: 2.200824022293091
Validation loss: 2.57299742102623

Epoch: 5| Step: 8
Training loss: 1.7922000885009766
Validation loss: 2.363856852054596

Epoch: 5| Step: 9
Training loss: 1.6446077823638916
Validation loss: 2.1703960498174033

Epoch: 5| Step: 10
Training loss: 1.4360041618347168
Validation loss: 2.2004913687705994

Epoch: 5| Step: 11
Training loss: 1.3466730117797852
Validation loss: 2.178582231203715

Epoch: 92| Step: 0
Training loss: 1.5893604755401611
Validation loss: 2.163640866676966

Epoch: 5| Step: 1
Training loss: 2.2399253845214844
Validation loss: 2.1927012652158737

Epoch: 5| Step: 2
Training loss: 2.102652072906494
Validation loss: 2.2974352637926736

Epoch: 5| Step: 3
Training loss: 2.007488965988159
Validation loss: 2.223240544398626

Epoch: 5| Step: 4
Training loss: 1.930415153503418
Validation loss: 2.3487425645192466

Epoch: 5| Step: 5
Training loss: 2.2073752880096436
Validation loss: 2.2208843330542245

Epoch: 5| Step: 6
Training loss: 2.3015594482421875
Validation loss: 2.2370785673459372

Epoch: 5| Step: 7
Training loss: 2.191516637802124
Validation loss: 2.25826562444369

Epoch: 5| Step: 8
Training loss: 2.3095810413360596
Validation loss: 2.298736850420634

Epoch: 5| Step: 9
Training loss: 2.093463897705078
Validation loss: 2.227325980861982

Epoch: 5| Step: 10
Training loss: 2.2245147228240967
Validation loss: 2.259222388267517

Epoch: 5| Step: 11
Training loss: 1.2154604196548462
Validation loss: 2.2223361134529114

Epoch: 93| Step: 0
Training loss: 2.0516982078552246
Validation loss: 2.2794117430845895

Epoch: 5| Step: 1
Training loss: 1.8424606323242188
Validation loss: 2.1196421682834625

Epoch: 5| Step: 2
Training loss: 1.953594446182251
Validation loss: 2.2382639447848

Epoch: 5| Step: 3
Training loss: 2.4652726650238037
Validation loss: 2.1025422314802804

Epoch: 5| Step: 4
Training loss: 1.5282394886016846
Validation loss: 2.171271567543348

Epoch: 5| Step: 5
Training loss: 1.7527068853378296
Validation loss: 2.219940240184466

Epoch: 5| Step: 6
Training loss: 1.620792031288147
Validation loss: 2.276043305794398

Epoch: 5| Step: 7
Training loss: 1.8443810939788818
Validation loss: 2.2073278625806174

Epoch: 5| Step: 8
Training loss: 1.8006536960601807
Validation loss: 2.1988381892442703

Epoch: 5| Step: 9
Training loss: 2.6334378719329834
Validation loss: 2.1668729186058044

Epoch: 5| Step: 10
Training loss: 1.966019630432129
Validation loss: 2.2081560442845025

Epoch: 5| Step: 11
Training loss: 2.7161705493927
Validation loss: 2.087768187125524

Epoch: 94| Step: 0
Training loss: 2.1633214950561523
Validation loss: 2.152800718943278

Epoch: 5| Step: 1
Training loss: 1.8932666778564453
Validation loss: 2.1473606675863266

Epoch: 5| Step: 2
Training loss: 2.5535988807678223
Validation loss: 2.143947869539261

Epoch: 5| Step: 3
Training loss: 1.491363286972046
Validation loss: 2.2106522619724274

Epoch: 5| Step: 4
Training loss: 1.7497562170028687
Validation loss: 2.1705314069986343

Epoch: 5| Step: 5
Training loss: 1.863882064819336
Validation loss: 2.1495836476484933

Epoch: 5| Step: 6
Training loss: 2.700392484664917
Validation loss: 2.20416430135568

Epoch: 5| Step: 7
Training loss: 1.1730455160140991
Validation loss: 2.160933405160904

Epoch: 5| Step: 8
Training loss: 1.9438488483428955
Validation loss: 2.203376958767573

Epoch: 5| Step: 9
Training loss: 1.7145719528198242
Validation loss: 2.1845511893431344

Epoch: 5| Step: 10
Training loss: 2.072946548461914
Validation loss: 2.237720141808192

Epoch: 5| Step: 11
Training loss: 1.5499205589294434
Validation loss: 2.1526911755402884

Epoch: 95| Step: 0
Training loss: 2.0349502563476562
Validation loss: 2.245235467950503

Epoch: 5| Step: 1
Training loss: 1.9772647619247437
Validation loss: 2.2315168231725693

Epoch: 5| Step: 2
Training loss: 1.5018678903579712
Validation loss: 2.252319152156512

Epoch: 5| Step: 3
Training loss: 1.7891432046890259
Validation loss: 2.1752641598383584

Epoch: 5| Step: 4
Training loss: 2.003364086151123
Validation loss: 2.1916968872149787

Epoch: 5| Step: 5
Training loss: 2.354487895965576
Validation loss: 2.2214533984661102

Epoch: 5| Step: 6
Training loss: 2.1271533966064453
Validation loss: 2.242183397213618

Epoch: 5| Step: 7
Training loss: 1.2913181781768799
Validation loss: 2.2027781903743744

Epoch: 5| Step: 8
Training loss: 2.301705837249756
Validation loss: 2.2935174703598022

Epoch: 5| Step: 9
Training loss: 2.0634284019470215
Validation loss: 2.184999297062556

Epoch: 5| Step: 10
Training loss: 1.7079614400863647
Validation loss: 2.225079928835233

Epoch: 5| Step: 11
Training loss: 2.773338794708252
Validation loss: 2.2725360095500946

Epoch: 96| Step: 0
Training loss: 1.7111164331436157
Validation loss: 2.2011420677105584

Epoch: 5| Step: 1
Training loss: 2.135723829269409
Validation loss: 2.173287053902944

Epoch: 5| Step: 2
Training loss: 1.5014441013336182
Validation loss: 2.251621554295222

Epoch: 5| Step: 3
Training loss: 2.133458137512207
Validation loss: 2.203791926304499

Epoch: 5| Step: 4
Training loss: 1.8972975015640259
Validation loss: 2.2413693418105445

Epoch: 5| Step: 5
Training loss: 1.7866318225860596
Validation loss: 2.1788595716158548

Epoch: 5| Step: 6
Training loss: 1.696175217628479
Validation loss: 2.1758705774943032

Epoch: 5| Step: 7
Training loss: 2.4121456146240234
Validation loss: 2.2267153213421502

Epoch: 5| Step: 8
Training loss: 2.1541330814361572
Validation loss: 2.1808931479851403

Epoch: 5| Step: 9
Training loss: 1.8586504459381104
Validation loss: 2.206035315990448

Epoch: 5| Step: 10
Training loss: 2.0767247676849365
Validation loss: 2.206676413615545

Epoch: 5| Step: 11
Training loss: 1.6052576303482056
Validation loss: 2.1747039159139

Epoch: 97| Step: 0
Training loss: 1.4013961553573608
Validation loss: 2.2306386133035025

Epoch: 5| Step: 1
Training loss: 1.5474025011062622
Validation loss: 2.358795151114464

Epoch: 5| Step: 2
Training loss: 2.628997802734375
Validation loss: 2.1431610137224197

Epoch: 5| Step: 3
Training loss: 1.525416374206543
Validation loss: 2.269706775744756

Epoch: 5| Step: 4
Training loss: 2.2625114917755127
Validation loss: 2.235289474328359

Epoch: 5| Step: 5
Training loss: 1.6454347372055054
Validation loss: 2.214818318684896

Epoch: 5| Step: 6
Training loss: 2.341179609298706
Validation loss: 2.166252533594767

Epoch: 5| Step: 7
Training loss: 2.414717197418213
Validation loss: 2.3200992196798325

Epoch: 5| Step: 8
Training loss: 1.9624168872833252
Validation loss: 2.2720183581113815

Epoch: 5| Step: 9
Training loss: 1.33466637134552
Validation loss: 2.2346515158812204

Epoch: 5| Step: 10
Training loss: 2.4275104999542236
Validation loss: 2.2438113391399384

Epoch: 5| Step: 11
Training loss: 1.3180301189422607
Validation loss: 2.1897936711708703

Epoch: 98| Step: 0
Training loss: 1.6610469818115234
Validation loss: 2.242147073149681

Epoch: 5| Step: 1
Training loss: 1.5194838047027588
Validation loss: 2.1777766346931458

Epoch: 5| Step: 2
Training loss: 2.1830320358276367
Validation loss: 2.2031916677951813

Epoch: 5| Step: 3
Training loss: 1.7583668231964111
Validation loss: 2.204084426164627

Epoch: 5| Step: 4
Training loss: 2.408639669418335
Validation loss: 2.294987534483274

Epoch: 5| Step: 5
Training loss: 1.7981771230697632
Validation loss: 2.2691686948140464

Epoch: 5| Step: 6
Training loss: 1.8657677173614502
Validation loss: 2.3126666247844696

Epoch: 5| Step: 7
Training loss: 2.128439426422119
Validation loss: 2.338991552591324

Epoch: 5| Step: 8
Training loss: 2.4955132007598877
Validation loss: 2.353707412878672

Epoch: 5| Step: 9
Training loss: 1.5765321254730225
Validation loss: 2.271740128596624

Epoch: 5| Step: 10
Training loss: 1.821686029434204
Validation loss: 2.3006078004837036

Epoch: 5| Step: 11
Training loss: 2.7440645694732666
Validation loss: 2.204756667216619

Epoch: 99| Step: 0
Training loss: 2.093475103378296
Validation loss: 2.1800375084082284

Epoch: 5| Step: 1
Training loss: 2.0756781101226807
Validation loss: 2.2108898063500724

Epoch: 5| Step: 2
Training loss: 1.8755252361297607
Validation loss: 2.247970387339592

Epoch: 5| Step: 3
Training loss: 2.1540749073028564
Validation loss: 2.248644138375918

Epoch: 5| Step: 4
Training loss: 1.7332961559295654
Validation loss: 2.178612604737282

Epoch: 5| Step: 5
Training loss: 2.1569173336029053
Validation loss: 2.218941534558932

Epoch: 5| Step: 6
Training loss: 2.4079036712646484
Validation loss: 2.2206440518299737

Epoch: 5| Step: 7
Training loss: 1.3355839252471924
Validation loss: 2.1747231483459473

Epoch: 5| Step: 8
Training loss: 2.609692096710205
Validation loss: 2.191199481487274

Epoch: 5| Step: 9
Training loss: 1.3758569955825806
Validation loss: 2.216909577449163

Epoch: 5| Step: 10
Training loss: 2.007944107055664
Validation loss: 2.1923279066880546

Epoch: 5| Step: 11
Training loss: 1.121046543121338
Validation loss: 2.193967496355375

Epoch: 100| Step: 0
Training loss: 2.130753993988037
Validation loss: 2.202900876601537

Epoch: 5| Step: 1
Training loss: 1.6132447719573975
Validation loss: 2.262097716331482

Epoch: 5| Step: 2
Training loss: 1.9766165018081665
Validation loss: 2.220010126630465

Epoch: 5| Step: 3
Training loss: 1.786717176437378
Validation loss: 2.2449884017308555

Epoch: 5| Step: 4
Training loss: 2.367750644683838
Validation loss: 2.3191813925902047

Epoch: 5| Step: 5
Training loss: 1.5055501461029053
Validation loss: 2.1997144371271133

Epoch: 5| Step: 6
Training loss: 2.77376389503479
Validation loss: 2.174308588107427

Epoch: 5| Step: 7
Training loss: 2.064244270324707
Validation loss: 2.2777748008569083

Epoch: 5| Step: 8
Training loss: 1.3836395740509033
Validation loss: 2.1841185639301934

Epoch: 5| Step: 9
Training loss: 1.6483761072158813
Validation loss: 2.2227023442586265

Epoch: 5| Step: 10
Training loss: 2.031139373779297
Validation loss: 2.1879134625196457

Epoch: 5| Step: 11
Training loss: 1.3450500965118408
Validation loss: 2.224292576313019

Epoch: 101| Step: 0
Training loss: 2.0695559978485107
Validation loss: 2.1709137558937073

Epoch: 5| Step: 1
Training loss: 1.6716922521591187
Validation loss: 2.201668212811152

Epoch: 5| Step: 2
Training loss: 2.130580186843872
Validation loss: 2.2208454310894012

Epoch: 5| Step: 3
Training loss: 1.5713932514190674
Validation loss: 2.1545373300711312

Epoch: 5| Step: 4
Training loss: 1.8524589538574219
Validation loss: 2.2605279088020325

Epoch: 5| Step: 5
Training loss: 1.991212248802185
Validation loss: 2.2565202911694846

Epoch: 5| Step: 6
Training loss: 1.6985822916030884
Validation loss: 2.217285007238388

Epoch: 5| Step: 7
Training loss: 1.9084653854370117
Validation loss: 2.191894436875979

Epoch: 5| Step: 8
Training loss: 2.02172589302063
Validation loss: 2.09597780307134

Epoch: 5| Step: 9
Training loss: 1.8466295003890991
Validation loss: 2.217646340529124

Epoch: 5| Step: 10
Training loss: 2.632040500640869
Validation loss: 2.2299134035905204

Epoch: 5| Step: 11
Training loss: 1.6174577474594116
Validation loss: 2.2793801923592887

Epoch: 102| Step: 0
Training loss: 1.5034921169281006
Validation loss: 2.308189938465754

Epoch: 5| Step: 1
Training loss: 1.9514529705047607
Validation loss: 2.2510786255200705

Epoch: 5| Step: 2
Training loss: 2.0364842414855957
Validation loss: 2.242212345202764

Epoch: 5| Step: 3
Training loss: 2.6260058879852295
Validation loss: 2.318840737144152

Epoch: 5| Step: 4
Training loss: 1.9570411443710327
Validation loss: 2.2245244532823563

Epoch: 5| Step: 5
Training loss: 1.597780704498291
Validation loss: 2.219241440296173

Epoch: 5| Step: 6
Training loss: 1.8507709503173828
Validation loss: 2.3711941242218018

Epoch: 5| Step: 7
Training loss: 1.7717605829238892
Validation loss: 2.2594674030939736

Epoch: 5| Step: 8
Training loss: 2.2501187324523926
Validation loss: 2.194939931233724

Epoch: 5| Step: 9
Training loss: 1.5370240211486816
Validation loss: 2.289103388786316

Epoch: 5| Step: 10
Training loss: 1.8392959833145142
Validation loss: 2.1990163971980414

Epoch: 5| Step: 11
Training loss: 2.5552544593811035
Validation loss: 2.1561679244041443

Epoch: 103| Step: 0
Training loss: 1.655409574508667
Validation loss: 2.177279457449913

Epoch: 5| Step: 1
Training loss: 1.9910399913787842
Validation loss: 2.31812513868014

Epoch: 5| Step: 2
Training loss: 1.876816987991333
Validation loss: 2.1745409617821374

Epoch: 5| Step: 3
Training loss: 1.752324104309082
Validation loss: 2.1557626326878867

Epoch: 5| Step: 4
Training loss: 1.8191511631011963
Validation loss: 2.3435279925664267

Epoch: 5| Step: 5
Training loss: 2.5699915885925293
Validation loss: 2.305756981174151

Epoch: 5| Step: 6
Training loss: 1.7661815881729126
Validation loss: 2.2323823322852454

Epoch: 5| Step: 7
Training loss: 2.226067066192627
Validation loss: 2.2095529437065125

Epoch: 5| Step: 8
Training loss: 2.155852794647217
Validation loss: 2.136438106497129

Epoch: 5| Step: 9
Training loss: 1.5178407430648804
Validation loss: 2.2381721337636313

Epoch: 5| Step: 10
Training loss: 1.727154016494751
Validation loss: 2.1772266725699105

Epoch: 5| Step: 11
Training loss: 2.2352170944213867
Validation loss: 2.2387482722600303

Epoch: 104| Step: 0
Training loss: 1.8649280071258545
Validation loss: 2.2648939291636148

Epoch: 5| Step: 1
Training loss: 1.640329360961914
Validation loss: 2.201903387904167

Epoch: 5| Step: 2
Training loss: 1.804261565208435
Validation loss: 2.1666016479333243

Epoch: 5| Step: 3
Training loss: 2.4363293647766113
Validation loss: 2.170303836464882

Epoch: 5| Step: 4
Training loss: 1.8167808055877686
Validation loss: 2.188315828641256

Epoch: 5| Step: 5
Training loss: 1.0699081420898438
Validation loss: 2.2379442850748696

Epoch: 5| Step: 6
Training loss: 1.965851068496704
Validation loss: 2.334225212534269

Epoch: 5| Step: 7
Training loss: 1.9667167663574219
Validation loss: 2.401497890551885

Epoch: 5| Step: 8
Training loss: 1.8432350158691406
Validation loss: 2.247372249762217

Epoch: 5| Step: 9
Training loss: 1.8609964847564697
Validation loss: 2.28704234957695

Epoch: 5| Step: 10
Training loss: 2.6677582263946533
Validation loss: 2.2676961421966553

Epoch: 5| Step: 11
Training loss: 1.3049955368041992
Validation loss: 2.351002871990204

Epoch: 105| Step: 0
Training loss: 1.5830183029174805
Validation loss: 2.3023474415143332

Epoch: 5| Step: 1
Training loss: 2.209735155105591
Validation loss: 2.3678364157676697

Epoch: 5| Step: 2
Training loss: 1.5479302406311035
Validation loss: 2.2805779725313187

Epoch: 5| Step: 3
Training loss: 1.7572963237762451
Validation loss: 2.2350491136312485

Epoch: 5| Step: 4
Training loss: 2.456101417541504
Validation loss: 2.2610284785429635

Epoch: 5| Step: 5
Training loss: 2.529378890991211
Validation loss: 2.2278934915860495

Epoch: 5| Step: 6
Training loss: 1.6054985523223877
Validation loss: 2.209244747956594

Epoch: 5| Step: 7
Training loss: 2.5591483116149902
Validation loss: 2.1827678084373474

Epoch: 5| Step: 8
Training loss: 1.9980039596557617
Validation loss: 2.2850281099478402

Epoch: 5| Step: 9
Training loss: 1.9847244024276733
Validation loss: 2.273023694753647

Epoch: 5| Step: 10
Training loss: 1.6322033405303955
Validation loss: 2.108835572997729

Epoch: 5| Step: 11
Training loss: 1.9214537143707275
Validation loss: 2.2075673838456473

Epoch: 106| Step: 0
Training loss: 2.096360683441162
Validation loss: 2.1907147268454232

Epoch: 5| Step: 1
Training loss: 1.9600178003311157
Validation loss: 2.1849349538485208

Epoch: 5| Step: 2
Training loss: 1.7076826095581055
Validation loss: 2.210520327091217

Epoch: 5| Step: 3
Training loss: 1.922869324684143
Validation loss: 2.260667865475019

Epoch: 5| Step: 4
Training loss: 1.388912558555603
Validation loss: 2.236861159404119

Epoch: 5| Step: 5
Training loss: 1.9819457530975342
Validation loss: 2.2403271993001304

Epoch: 5| Step: 6
Training loss: 2.0294744968414307
Validation loss: 2.1335907727479935

Epoch: 5| Step: 7
Training loss: 2.160555601119995
Validation loss: 2.218414088090261

Epoch: 5| Step: 8
Training loss: 1.7794948816299438
Validation loss: 2.108962560693423

Epoch: 5| Step: 9
Training loss: 1.6896253824234009
Validation loss: 2.2202211022377014

Epoch: 5| Step: 10
Training loss: 2.199488878250122
Validation loss: 2.255983740091324

Epoch: 5| Step: 11
Training loss: 0.8445757031440735
Validation loss: 2.2682839582363763

Epoch: 107| Step: 0
Training loss: 2.6594595909118652
Validation loss: 2.35792338848114

Epoch: 5| Step: 1
Training loss: 1.9207853078842163
Validation loss: 2.14986186226209

Epoch: 5| Step: 2
Training loss: 2.097935438156128
Validation loss: 2.169709940751394

Epoch: 5| Step: 3
Training loss: 1.8585033416748047
Validation loss: 2.1632271806399026

Epoch: 5| Step: 4
Training loss: 1.9441922903060913
Validation loss: 2.164671083291372

Epoch: 5| Step: 5
Training loss: 1.7424761056900024
Validation loss: 2.1988615095615387

Epoch: 5| Step: 6
Training loss: 1.739614486694336
Validation loss: 2.1519232193628945

Epoch: 5| Step: 7
Training loss: 2.2222981452941895
Validation loss: 2.2156228572130203

Epoch: 5| Step: 8
Training loss: 1.5097696781158447
Validation loss: 2.262963821490606

Epoch: 5| Step: 9
Training loss: 1.769534707069397
Validation loss: 2.3297772109508514

Epoch: 5| Step: 10
Training loss: 2.164179563522339
Validation loss: 2.2185009817282357

Epoch: 5| Step: 11
Training loss: 1.851001262664795
Validation loss: 2.19355175892512

Epoch: 108| Step: 0
Training loss: 1.4473943710327148
Validation loss: 2.2175532082716622

Epoch: 5| Step: 1
Training loss: 2.0940980911254883
Validation loss: 2.263554190595945

Epoch: 5| Step: 2
Training loss: 1.8979504108428955
Validation loss: 2.3038574556509652

Epoch: 5| Step: 3
Training loss: 1.6537920236587524
Validation loss: 2.2612578024466834

Epoch: 5| Step: 4
Training loss: 2.5168986320495605
Validation loss: 2.3834194044272103

Epoch: 5| Step: 5
Training loss: 2.0787649154663086
Validation loss: 2.3630868395169577

Epoch: 5| Step: 6
Training loss: 2.5565407276153564
Validation loss: 2.3791533956925073

Epoch: 5| Step: 7
Training loss: 2.0002999305725098
Validation loss: 2.3354432433843613

Epoch: 5| Step: 8
Training loss: 2.2052690982818604
Validation loss: 2.304607401291529

Epoch: 5| Step: 9
Training loss: 1.5852079391479492
Validation loss: 2.237406939268112

Epoch: 5| Step: 10
Training loss: 1.41425621509552
Validation loss: 2.1858529647191367

Epoch: 5| Step: 11
Training loss: 1.5642644166946411
Validation loss: 2.2965259154637656

Epoch: 109| Step: 0
Training loss: 1.5503127574920654
Validation loss: 2.226800431807836

Epoch: 5| Step: 1
Training loss: 2.1574902534484863
Validation loss: 2.1389240274826684

Epoch: 5| Step: 2
Training loss: 1.8741047382354736
Validation loss: 2.1679938435554504

Epoch: 5| Step: 3
Training loss: 2.0232951641082764
Validation loss: 2.175088499983152

Epoch: 5| Step: 4
Training loss: 1.9526468515396118
Validation loss: 2.278069665034612

Epoch: 5| Step: 5
Training loss: 1.49216628074646
Validation loss: 2.3429621358712516

Epoch: 5| Step: 6
Training loss: 1.6559474468231201
Validation loss: 2.264347309867541

Epoch: 5| Step: 7
Training loss: 1.9320510625839233
Validation loss: 2.413992762565613

Epoch: 5| Step: 8
Training loss: 2.118413209915161
Validation loss: 2.233686332901319

Epoch: 5| Step: 9
Training loss: 2.6689956188201904
Validation loss: 2.2593068033456802

Epoch: 5| Step: 10
Training loss: 1.9509607553482056
Validation loss: 2.386653314034144

Epoch: 5| Step: 11
Training loss: 1.9308340549468994
Validation loss: 2.1741253385941186

Epoch: 110| Step: 0
Training loss: 1.7314980030059814
Validation loss: 2.165034756064415

Epoch: 5| Step: 1
Training loss: 1.2456008195877075
Validation loss: 2.255187844236692

Epoch: 5| Step: 2
Training loss: 2.070228099822998
Validation loss: 2.2856183548768363

Epoch: 5| Step: 3
Training loss: 1.7894859313964844
Validation loss: 2.207460264364878

Epoch: 5| Step: 4
Training loss: 1.9119428396224976
Validation loss: 2.3363534609476724

Epoch: 5| Step: 5
Training loss: 1.5086675882339478
Validation loss: 2.1928098797798157

Epoch: 5| Step: 6
Training loss: 2.2969400882720947
Validation loss: 2.254601309696833

Epoch: 5| Step: 7
Training loss: 1.6043535470962524
Validation loss: 2.201668212811152

Epoch: 5| Step: 8
Training loss: 2.12035870552063
Validation loss: 2.305041084686915

Epoch: 5| Step: 9
Training loss: 1.906476378440857
Validation loss: 2.2856010595957437

Epoch: 5| Step: 10
Training loss: 2.5213558673858643
Validation loss: 2.221802999575933

Epoch: 5| Step: 11
Training loss: 1.5355218648910522
Validation loss: 2.138467475771904

Epoch: 111| Step: 0
Training loss: 2.016643524169922
Validation loss: 2.2357213894526162

Epoch: 5| Step: 1
Training loss: 1.5347745418548584
Validation loss: 2.172970245281855

Epoch: 5| Step: 2
Training loss: 1.7139049768447876
Validation loss: 2.061478873093923

Epoch: 5| Step: 3
Training loss: 1.5823302268981934
Validation loss: 2.19264783958594

Epoch: 5| Step: 4
Training loss: 2.0673928260803223
Validation loss: 2.215373362104098

Epoch: 5| Step: 5
Training loss: 2.441277027130127
Validation loss: 2.1817276080449424

Epoch: 5| Step: 6
Training loss: 1.946681261062622
Validation loss: 2.1799130141735077

Epoch: 5| Step: 7
Training loss: 1.9603408575057983
Validation loss: 2.2005598843097687

Epoch: 5| Step: 8
Training loss: 1.5379083156585693
Validation loss: 2.0780009627342224

Epoch: 5| Step: 9
Training loss: 2.2878823280334473
Validation loss: 2.175457775592804

Epoch: 5| Step: 10
Training loss: 1.5552797317504883
Validation loss: 2.3139382004737854

Epoch: 5| Step: 11
Training loss: 1.2232285737991333
Validation loss: 2.186591391762098

Epoch: 112| Step: 0
Training loss: 1.2770026922225952
Validation loss: 2.2626320819060006

Epoch: 5| Step: 1
Training loss: 1.3271896839141846
Validation loss: 2.265162448088328

Epoch: 5| Step: 2
Training loss: 1.96469247341156
Validation loss: 2.2281200289726257

Epoch: 5| Step: 3
Training loss: 2.4195244312286377
Validation loss: 2.2784191419680915

Epoch: 5| Step: 4
Training loss: 1.730237603187561
Validation loss: 2.232425014177958

Epoch: 5| Step: 5
Training loss: 2.1224565505981445
Validation loss: 2.2029774288336434

Epoch: 5| Step: 6
Training loss: 2.2322206497192383
Validation loss: 2.086303487420082

Epoch: 5| Step: 7
Training loss: 1.7618224620819092
Validation loss: 2.207887649536133

Epoch: 5| Step: 8
Training loss: 2.65785551071167
Validation loss: 2.1159531424442926

Epoch: 5| Step: 9
Training loss: 1.710031270980835
Validation loss: 2.1700531293948493

Epoch: 5| Step: 10
Training loss: 1.4650379419326782
Validation loss: 2.2124203642209372

Epoch: 5| Step: 11
Training loss: 1.172151803970337
Validation loss: 2.1700178931156793

Epoch: 113| Step: 0
Training loss: 1.485572099685669
Validation loss: 2.2348681886990867

Epoch: 5| Step: 1
Training loss: 1.8047335147857666
Validation loss: 2.2628214210271835

Epoch: 5| Step: 2
Training loss: 2.1929965019226074
Validation loss: 2.265517920255661

Epoch: 5| Step: 3
Training loss: 1.9281070232391357
Validation loss: 2.2891194423039756

Epoch: 5| Step: 4
Training loss: 2.401441812515259
Validation loss: 2.3641217847665152

Epoch: 5| Step: 5
Training loss: 1.6993051767349243
Validation loss: 2.456896642843882

Epoch: 5| Step: 6
Training loss: 2.3721654415130615
Validation loss: 2.403727342685064

Epoch: 5| Step: 7
Training loss: 2.047919750213623
Validation loss: 2.3661823173364005

Epoch: 5| Step: 8
Training loss: 1.851920485496521
Validation loss: 2.2866451293230057

Epoch: 5| Step: 9
Training loss: 2.054607391357422
Validation loss: 2.2430085639158883

Epoch: 5| Step: 10
Training loss: 1.9383084774017334
Validation loss: 2.2144139806429544

Epoch: 5| Step: 11
Training loss: 1.8111703395843506
Validation loss: 2.1447632014751434

Epoch: 114| Step: 0
Training loss: 1.7296520471572876
Validation loss: 2.2151984721422195

Epoch: 5| Step: 1
Training loss: 1.886164665222168
Validation loss: 2.1068540861209235

Epoch: 5| Step: 2
Training loss: 2.219269275665283
Validation loss: 2.2367904682954154

Epoch: 5| Step: 3
Training loss: 1.9437440633773804
Validation loss: 2.287806232770284

Epoch: 5| Step: 4
Training loss: 2.062743902206421
Validation loss: 2.270152767499288

Epoch: 5| Step: 5
Training loss: 2.016500949859619
Validation loss: 2.2346342901388803

Epoch: 5| Step: 6
Training loss: 2.718808650970459
Validation loss: 2.1971922715504966

Epoch: 5| Step: 7
Training loss: 1.9045894145965576
Validation loss: 2.2442354957262673

Epoch: 5| Step: 8
Training loss: 1.611609697341919
Validation loss: 2.161909729242325

Epoch: 5| Step: 9
Training loss: 2.169463634490967
Validation loss: 2.193675229946772

Epoch: 5| Step: 10
Training loss: 1.5556209087371826
Validation loss: 2.223861808578173

Epoch: 5| Step: 11
Training loss: 3.158377170562744
Validation loss: 2.3810705045859017

Epoch: 115| Step: 0
Training loss: 1.13252854347229
Validation loss: 2.258642146984736

Epoch: 5| Step: 1
Training loss: 1.586666464805603
Validation loss: 2.18526798983415

Epoch: 5| Step: 2
Training loss: 1.9776157140731812
Validation loss: 2.2044627169768014

Epoch: 5| Step: 3
Training loss: 2.2268407344818115
Validation loss: 2.255196824669838

Epoch: 5| Step: 4
Training loss: 1.7956870794296265
Validation loss: 2.2057920595010123

Epoch: 5| Step: 5
Training loss: 1.1560884714126587
Validation loss: 2.216469715038935

Epoch: 5| Step: 6
Training loss: 1.720594048500061
Validation loss: 2.1672794620196023

Epoch: 5| Step: 7
Training loss: 2.135307788848877
Validation loss: 2.1622275610764823

Epoch: 5| Step: 8
Training loss: 1.9007049798965454
Validation loss: 2.259660452604294

Epoch: 5| Step: 9
Training loss: 2.007887601852417
Validation loss: 2.1937347104152045

Epoch: 5| Step: 10
Training loss: 2.5385255813598633
Validation loss: 2.1789936323960624

Epoch: 5| Step: 11
Training loss: 2.3670122623443604
Validation loss: 2.2288436939318976

Epoch: 116| Step: 0
Training loss: 1.9672586917877197
Validation loss: 2.2495154986778894

Epoch: 5| Step: 1
Training loss: 1.7528798580169678
Validation loss: 2.2789327204227448

Epoch: 5| Step: 2
Training loss: 2.1592307090759277
Validation loss: 2.2604670276244483

Epoch: 5| Step: 3
Training loss: 2.0640547275543213
Validation loss: 2.157665252685547

Epoch: 5| Step: 4
Training loss: 2.3525094985961914
Validation loss: 2.281501536568006

Epoch: 5| Step: 5
Training loss: 2.1377015113830566
Validation loss: 2.1926099359989166

Epoch: 5| Step: 6
Training loss: 1.7231353521347046
Validation loss: 2.213861952225367

Epoch: 5| Step: 7
Training loss: 2.2474465370178223
Validation loss: 2.1720958004395166

Epoch: 5| Step: 8
Training loss: 2.103052854537964
Validation loss: 2.1789457201957703

Epoch: 5| Step: 9
Training loss: 2.0086934566497803
Validation loss: 2.226473202308019

Epoch: 5| Step: 10
Training loss: 1.3637042045593262
Validation loss: 2.2243600338697433

Epoch: 5| Step: 11
Training loss: 1.0568747520446777
Validation loss: 2.295241594314575

Epoch: 117| Step: 0
Training loss: 2.066497802734375
Validation loss: 2.2018366356690726

Epoch: 5| Step: 1
Training loss: 2.1302497386932373
Validation loss: 2.332933376232783

Epoch: 5| Step: 2
Training loss: 1.8780502080917358
Validation loss: 2.3921541372934976

Epoch: 5| Step: 3
Training loss: 2.1215481758117676
Validation loss: 2.368850141763687

Epoch: 5| Step: 4
Training loss: 1.5331223011016846
Validation loss: 2.2420173039038978

Epoch: 5| Step: 5
Training loss: 1.533914566040039
Validation loss: 2.3253997961680093

Epoch: 5| Step: 6
Training loss: 2.6668267250061035
Validation loss: 2.296616146961848

Epoch: 5| Step: 7
Training loss: 1.844139814376831
Validation loss: 2.235410968462626

Epoch: 5| Step: 8
Training loss: 1.5356546640396118
Validation loss: 2.094315692782402

Epoch: 5| Step: 9
Training loss: 1.690517783164978
Validation loss: 2.133518397808075

Epoch: 5| Step: 10
Training loss: 1.7864007949829102
Validation loss: 2.1406082610289254

Epoch: 5| Step: 11
Training loss: 1.7122676372528076
Validation loss: 2.185551861921946

Epoch: 118| Step: 0
Training loss: 2.1346936225891113
Validation loss: 2.213397830724716

Epoch: 5| Step: 1
Training loss: 2.2437212467193604
Validation loss: 2.1253227591514587

Epoch: 5| Step: 2
Training loss: 1.7359298467636108
Validation loss: 2.129110117753347

Epoch: 5| Step: 3
Training loss: 2.0815937519073486
Validation loss: 2.208599105477333

Epoch: 5| Step: 4
Training loss: 1.6273616552352905
Validation loss: 2.290741433699926

Epoch: 5| Step: 5
Training loss: 1.6122350692749023
Validation loss: 2.318949451049169

Epoch: 5| Step: 6
Training loss: 1.5313993692398071
Validation loss: 2.2345387041568756

Epoch: 5| Step: 7
Training loss: 2.0329744815826416
Validation loss: 2.2435987691084542

Epoch: 5| Step: 8
Training loss: 1.8176450729370117
Validation loss: 2.2358526488145194

Epoch: 5| Step: 9
Training loss: 2.5441713333129883
Validation loss: 2.2343688110510507

Epoch: 5| Step: 10
Training loss: 1.5858771800994873
Validation loss: 2.1987770398457847

Epoch: 5| Step: 11
Training loss: 1.567069172859192
Validation loss: 2.1327046900987625

Epoch: 119| Step: 0
Training loss: 1.175986409187317
Validation loss: 2.139076014359792

Epoch: 5| Step: 1
Training loss: 1.7629356384277344
Validation loss: 2.2143998642762504

Epoch: 5| Step: 2
Training loss: 1.7028331756591797
Validation loss: 2.168534984191259

Epoch: 5| Step: 3
Training loss: 1.742383360862732
Validation loss: 2.1112028807401657

Epoch: 5| Step: 4
Training loss: 1.6052982807159424
Validation loss: 2.2744745115439096

Epoch: 5| Step: 5
Training loss: 2.229245662689209
Validation loss: 2.136343479156494

Epoch: 5| Step: 6
Training loss: 2.0115890502929688
Validation loss: 2.1976682990789413

Epoch: 5| Step: 7
Training loss: 2.0640459060668945
Validation loss: 2.190630485614141

Epoch: 5| Step: 8
Training loss: 1.6630909442901611
Validation loss: 2.1176103552182517

Epoch: 5| Step: 9
Training loss: 1.788426160812378
Validation loss: 2.1830911934375763

Epoch: 5| Step: 10
Training loss: 2.16933012008667
Validation loss: 2.1761526664098105

Epoch: 5| Step: 11
Training loss: 3.9107861518859863
Validation loss: 2.293568253517151

Epoch: 120| Step: 0
Training loss: 2.129455089569092
Validation loss: 2.2627138197422028

Epoch: 5| Step: 1
Training loss: 1.7304096221923828
Validation loss: 2.296624337633451

Epoch: 5| Step: 2
Training loss: 2.183300495147705
Validation loss: 2.300046687324842

Epoch: 5| Step: 3
Training loss: 1.5202040672302246
Validation loss: 2.183877403537432

Epoch: 5| Step: 4
Training loss: 1.8260257244110107
Validation loss: 2.312753384311994

Epoch: 5| Step: 5
Training loss: 1.870918869972229
Validation loss: 2.195454716682434

Epoch: 5| Step: 6
Training loss: 1.3286744356155396
Validation loss: 2.2101127157608667

Epoch: 5| Step: 7
Training loss: 2.055467128753662
Validation loss: 2.227749486764272

Epoch: 5| Step: 8
Training loss: 2.319878339767456
Validation loss: 2.3080522616704306

Epoch: 5| Step: 9
Training loss: 1.799848198890686
Validation loss: 2.2562269270420074

Epoch: 5| Step: 10
Training loss: 1.954663872718811
Validation loss: 2.1812704702218375

Epoch: 5| Step: 11
Training loss: 1.3284509181976318
Validation loss: 2.109768122434616

Epoch: 121| Step: 0
Training loss: 1.810319185256958
Validation loss: 2.284876455863317

Epoch: 5| Step: 1
Training loss: 2.0622856616973877
Validation loss: 2.209998925526937

Epoch: 5| Step: 2
Training loss: 1.745836853981018
Validation loss: 2.3341079652309418

Epoch: 5| Step: 3
Training loss: 1.834686517715454
Validation loss: 2.4216792583465576

Epoch: 5| Step: 4
Training loss: 2.119541645050049
Validation loss: 2.34615758061409

Epoch: 5| Step: 5
Training loss: 1.9310035705566406
Validation loss: 2.33415317038695

Epoch: 5| Step: 6
Training loss: 1.393067717552185
Validation loss: 2.2899119754632316

Epoch: 5| Step: 7
Training loss: 2.2426905632019043
Validation loss: 2.3287574847539267

Epoch: 5| Step: 8
Training loss: 2.697714328765869
Validation loss: 2.201922650138537

Epoch: 5| Step: 9
Training loss: 1.2947666645050049
Validation loss: 2.2374528596798577

Epoch: 5| Step: 10
Training loss: 1.3936712741851807
Validation loss: 2.254591936866442

Epoch: 5| Step: 11
Training loss: 0.8624470233917236
Validation loss: 2.229380110899607

Epoch: 122| Step: 0
Training loss: 1.642474889755249
Validation loss: 2.181841949621836

Epoch: 5| Step: 1
Training loss: 1.3414757251739502
Validation loss: 2.1672977656126022

Epoch: 5| Step: 2
Training loss: 1.5436336994171143
Validation loss: 2.1828377544879913

Epoch: 5| Step: 3
Training loss: 1.521214485168457
Validation loss: 2.203450327118238

Epoch: 5| Step: 4
Training loss: 2.112560272216797
Validation loss: 2.288714960217476

Epoch: 5| Step: 5
Training loss: 2.4870917797088623
Validation loss: 2.147954156001409

Epoch: 5| Step: 6
Training loss: 2.0726890563964844
Validation loss: 2.1154476950565972

Epoch: 5| Step: 7
Training loss: 1.6017433404922485
Validation loss: 2.247508982817332

Epoch: 5| Step: 8
Training loss: 2.696052074432373
Validation loss: 2.342364947001139

Epoch: 5| Step: 9
Training loss: 1.5529086589813232
Validation loss: 2.2121747632821402

Epoch: 5| Step: 10
Training loss: 2.3695645332336426
Validation loss: 2.3688956101735434

Epoch: 5| Step: 11
Training loss: 3.433180332183838
Validation loss: 2.3565554022789

Epoch: 123| Step: 0
Training loss: 1.7441673278808594
Validation loss: 2.3054929077625275

Epoch: 5| Step: 1
Training loss: 1.9640092849731445
Validation loss: 2.223851809899012

Epoch: 5| Step: 2
Training loss: 1.4913051128387451
Validation loss: 2.2440090775489807

Epoch: 5| Step: 3
Training loss: 1.7338063716888428
Validation loss: 2.2854686776796975

Epoch: 5| Step: 4
Training loss: 1.7253338098526
Validation loss: 2.2510487089554467

Epoch: 5| Step: 5
Training loss: 2.0308210849761963
Validation loss: 2.2566717068354287

Epoch: 5| Step: 6
Training loss: 1.7343013286590576
Validation loss: 2.1987717052300773

Epoch: 5| Step: 7
Training loss: 1.628218412399292
Validation loss: 2.158308352033297

Epoch: 5| Step: 8
Training loss: 1.570717215538025
Validation loss: 2.286858563621839

Epoch: 5| Step: 9
Training loss: 2.4534709453582764
Validation loss: 2.2054078032573066

Epoch: 5| Step: 10
Training loss: 1.7553752660751343
Validation loss: 2.1781776001056037

Epoch: 5| Step: 11
Training loss: 2.1824073791503906
Validation loss: 2.207149306933085

Epoch: 124| Step: 0
Training loss: 1.9989131689071655
Validation loss: 2.169249211748441

Epoch: 5| Step: 1
Training loss: 1.7743005752563477
Validation loss: 2.201300715406736

Epoch: 5| Step: 2
Training loss: 2.116593599319458
Validation loss: 2.2236672143141427

Epoch: 5| Step: 3
Training loss: 1.4108877182006836
Validation loss: 2.1417368352413177

Epoch: 5| Step: 4
Training loss: 1.8754711151123047
Validation loss: 2.1673179417848587

Epoch: 5| Step: 5
Training loss: 2.0063047409057617
Validation loss: 2.0874488949775696

Epoch: 5| Step: 6
Training loss: 1.3092796802520752
Validation loss: 2.2553688983122506

Epoch: 5| Step: 7
Training loss: 2.806400775909424
Validation loss: 2.292451575398445

Epoch: 5| Step: 8
Training loss: 1.7293376922607422
Validation loss: 2.301284909248352

Epoch: 5| Step: 9
Training loss: 1.5585999488830566
Validation loss: 2.264837697148323

Epoch: 5| Step: 10
Training loss: 2.241748094558716
Validation loss: 2.18069597085317

Epoch: 5| Step: 11
Training loss: 0.5590134859085083
Validation loss: 2.190233359734217

Epoch: 125| Step: 0
Training loss: 2.2508633136749268
Validation loss: 2.2237747510274253

Epoch: 5| Step: 1
Training loss: 1.3814129829406738
Validation loss: 2.209698642293612

Epoch: 5| Step: 2
Training loss: 1.7891480922698975
Validation loss: 2.1535119662682214

Epoch: 5| Step: 3
Training loss: 1.8418430089950562
Validation loss: 2.230540951093038

Epoch: 5| Step: 4
Training loss: 1.3310208320617676
Validation loss: 2.1674633820851645

Epoch: 5| Step: 5
Training loss: 1.7507902383804321
Validation loss: 2.1678252120812735

Epoch: 5| Step: 6
Training loss: 2.303759813308716
Validation loss: 2.2730610370635986

Epoch: 5| Step: 7
Training loss: 1.8605024814605713
Validation loss: 2.279717003305753

Epoch: 5| Step: 8
Training loss: 1.8403031826019287
Validation loss: 2.272381360332171

Epoch: 5| Step: 9
Training loss: 1.8732078075408936
Validation loss: 2.280621121327082

Epoch: 5| Step: 10
Training loss: 1.811437964439392
Validation loss: 2.289387588699659

Epoch: 5| Step: 11
Training loss: 1.6594605445861816
Validation loss: 2.1490868081649146

Epoch: 126| Step: 0
Training loss: 1.7394800186157227
Validation loss: 2.222295567393303

Epoch: 5| Step: 1
Training loss: 1.1496168375015259
Validation loss: 2.3063220431407294

Epoch: 5| Step: 2
Training loss: 1.8155921697616577
Validation loss: 2.3351164162158966

Epoch: 5| Step: 3
Training loss: 2.4142563343048096
Validation loss: 2.3263999819755554

Epoch: 5| Step: 4
Training loss: 2.4951601028442383
Validation loss: 2.2152209977308908

Epoch: 5| Step: 5
Training loss: 1.3880846500396729
Validation loss: 2.3385812441507974

Epoch: 5| Step: 6
Training loss: 1.3779499530792236
Validation loss: 2.2837184220552444

Epoch: 5| Step: 7
Training loss: 2.2817468643188477
Validation loss: 2.305113971233368

Epoch: 5| Step: 8
Training loss: 1.9112743139266968
Validation loss: 2.2977426052093506

Epoch: 5| Step: 9
Training loss: 2.1879420280456543
Validation loss: 2.2661228477954865

Epoch: 5| Step: 10
Training loss: 2.177612543106079
Validation loss: 2.1737166146437326

Epoch: 5| Step: 11
Training loss: 1.9535229206085205
Validation loss: 2.1933439572652182

Epoch: 127| Step: 0
Training loss: 2.2734858989715576
Validation loss: 2.071680635213852

Epoch: 5| Step: 1
Training loss: 1.7019332647323608
Validation loss: 2.1534335613250732

Epoch: 5| Step: 2
Training loss: 1.957680344581604
Validation loss: 2.271883651614189

Epoch: 5| Step: 3
Training loss: 1.9469902515411377
Validation loss: 2.206821938355764

Epoch: 5| Step: 4
Training loss: 1.9573676586151123
Validation loss: 2.2210361460844674

Epoch: 5| Step: 5
Training loss: 2.2241082191467285
Validation loss: 2.160705750187238

Epoch: 5| Step: 6
Training loss: 1.8227611780166626
Validation loss: 2.189697747429212

Epoch: 5| Step: 7
Training loss: 1.7499067783355713
Validation loss: 2.177385856707891

Epoch: 5| Step: 8
Training loss: 1.7113739252090454
Validation loss: 2.1602939615646997

Epoch: 5| Step: 9
Training loss: 1.9195305109024048
Validation loss: 2.1837027023235955

Epoch: 5| Step: 10
Training loss: 1.7566553354263306
Validation loss: 2.2417975664138794

Epoch: 5| Step: 11
Training loss: 1.714761734008789
Validation loss: 2.207701643308004

Epoch: 128| Step: 0
Training loss: 1.5212806463241577
Validation loss: 2.1982935667037964

Epoch: 5| Step: 1
Training loss: 2.1670947074890137
Validation loss: 2.138263389468193

Epoch: 5| Step: 2
Training loss: 1.9972683191299438
Validation loss: 2.198960249622663

Epoch: 5| Step: 3
Training loss: 2.1545913219451904
Validation loss: 2.292552500963211

Epoch: 5| Step: 4
Training loss: 1.508636713027954
Validation loss: 2.2642676532268524

Epoch: 5| Step: 5
Training loss: 2.5118367671966553
Validation loss: 2.267637759447098

Epoch: 5| Step: 6
Training loss: 1.5954153537750244
Validation loss: 2.2849317441383996

Epoch: 5| Step: 7
Training loss: 1.9187324047088623
Validation loss: 2.2866099079449973

Epoch: 5| Step: 8
Training loss: 1.4316174983978271
Validation loss: 2.2778678238391876

Epoch: 5| Step: 9
Training loss: 1.940728783607483
Validation loss: 2.1742427945137024

Epoch: 5| Step: 10
Training loss: 1.4884679317474365
Validation loss: 2.217034657796224

Epoch: 5| Step: 11
Training loss: 1.3058968782424927
Validation loss: 2.1906987875699997

Epoch: 129| Step: 0
Training loss: 1.343393087387085
Validation loss: 2.087815577785174

Epoch: 5| Step: 1
Training loss: 2.071843385696411
Validation loss: 2.257254014412562

Epoch: 5| Step: 2
Training loss: 1.518740177154541
Validation loss: 2.217820962270101

Epoch: 5| Step: 3
Training loss: 1.5042400360107422
Validation loss: 2.2694647908210754

Epoch: 5| Step: 4
Training loss: 2.517972946166992
Validation loss: 2.1756961743036904

Epoch: 5| Step: 5
Training loss: 1.9906944036483765
Validation loss: 2.127408782641093

Epoch: 5| Step: 6
Training loss: 2.0646042823791504
Validation loss: 2.113227824370066

Epoch: 5| Step: 7
Training loss: 1.7350883483886719
Validation loss: 2.1783086309830346

Epoch: 5| Step: 8
Training loss: 1.631084680557251
Validation loss: 2.251393814881643

Epoch: 5| Step: 9
Training loss: 2.2171578407287598
Validation loss: 2.2449994583924613

Epoch: 5| Step: 10
Training loss: 1.2331444025039673
Validation loss: 2.250843197107315

Epoch: 5| Step: 11
Training loss: 1.825453281402588
Validation loss: 2.3438791930675507

Epoch: 130| Step: 0
Training loss: 1.9183094501495361
Validation loss: 2.2207804967959723

Epoch: 5| Step: 1
Training loss: 1.9245685338974
Validation loss: 2.319550404946009

Epoch: 5| Step: 2
Training loss: 2.4990477561950684
Validation loss: 2.2591116428375244

Epoch: 5| Step: 3
Training loss: 1.903965950012207
Validation loss: 2.2846966236829758

Epoch: 5| Step: 4
Training loss: 2.0917234420776367
Validation loss: 2.404851327339808

Epoch: 5| Step: 5
Training loss: 1.4269721508026123
Validation loss: 2.1912832260131836

Epoch: 5| Step: 6
Training loss: 2.237711191177368
Validation loss: 2.181205357114474

Epoch: 5| Step: 7
Training loss: 1.2887274026870728
Validation loss: 2.2831075489521027

Epoch: 5| Step: 8
Training loss: 1.6044025421142578
Validation loss: 2.193705956141154

Epoch: 5| Step: 9
Training loss: 1.994028091430664
Validation loss: 2.246665139993032

Epoch: 5| Step: 10
Training loss: 1.373048186302185
Validation loss: 2.2503029505411782

Epoch: 5| Step: 11
Training loss: 2.079880714416504
Validation loss: 2.187196041146914

Epoch: 131| Step: 0
Training loss: 1.8481372594833374
Validation loss: 2.2092584371566772

Epoch: 5| Step: 1
Training loss: 1.4287610054016113
Validation loss: 2.2395318895578384

Epoch: 5| Step: 2
Training loss: 2.491583824157715
Validation loss: 2.1756483068068824

Epoch: 5| Step: 3
Training loss: 1.7955182790756226
Validation loss: 2.2139350175857544

Epoch: 5| Step: 4
Training loss: 1.9711978435516357
Validation loss: 2.200639416774114

Epoch: 5| Step: 5
Training loss: 1.6247761249542236
Validation loss: 2.202630271514257

Epoch: 5| Step: 6
Training loss: 1.5335264205932617
Validation loss: 2.1809463997681937

Epoch: 5| Step: 7
Training loss: 1.7310978174209595
Validation loss: 2.2607929011185965

Epoch: 5| Step: 8
Training loss: 1.6152509450912476
Validation loss: 2.1547295997540155

Epoch: 5| Step: 9
Training loss: 1.8518946170806885
Validation loss: 2.175534044702848

Epoch: 5| Step: 10
Training loss: 2.2384018898010254
Validation loss: 2.3235678672790527

Epoch: 5| Step: 11
Training loss: 0.7991911172866821
Validation loss: 2.2974970936775208

Epoch: 132| Step: 0
Training loss: 1.963543176651001
Validation loss: 2.2685192028681436

Epoch: 5| Step: 1
Training loss: 2.0084290504455566
Validation loss: 2.2224379082520804

Epoch: 5| Step: 2
Training loss: 1.6032531261444092
Validation loss: 2.2360475858052573

Epoch: 5| Step: 3
Training loss: 1.503638505935669
Validation loss: 2.2063712825377784

Epoch: 5| Step: 4
Training loss: 1.9656295776367188
Validation loss: 2.2334046264489493

Epoch: 5| Step: 5
Training loss: 0.999789834022522
Validation loss: 2.240385040640831

Epoch: 5| Step: 6
Training loss: 2.162984609603882
Validation loss: 2.215848977367083

Epoch: 5| Step: 7
Training loss: 2.2608656883239746
Validation loss: 2.219077557325363

Epoch: 5| Step: 8
Training loss: 1.5657167434692383
Validation loss: 2.162593185901642

Epoch: 5| Step: 9
Training loss: 1.5989452600479126
Validation loss: 2.241765469312668

Epoch: 5| Step: 10
Training loss: 1.8536850214004517
Validation loss: 2.25017212331295

Epoch: 5| Step: 11
Training loss: 1.316195011138916
Validation loss: 2.2542260736227036

Epoch: 133| Step: 0
Training loss: 2.145174026489258
Validation loss: 2.323840081691742

Epoch: 5| Step: 1
Training loss: 2.2117269039154053
Validation loss: 2.3694796164830527

Epoch: 5| Step: 2
Training loss: 2.186460018157959
Validation loss: 2.4361071983973184

Epoch: 5| Step: 3
Training loss: 2.591841697692871
Validation loss: 2.4213462620973587

Epoch: 5| Step: 4
Training loss: 1.997915506362915
Validation loss: 2.274099846680959

Epoch: 5| Step: 5
Training loss: 1.8478111028671265
Validation loss: 2.2438188393910727

Epoch: 5| Step: 6
Training loss: 1.8566974401474
Validation loss: 2.252398282289505

Epoch: 5| Step: 7
Training loss: 1.6830917596817017
Validation loss: 2.229452053705851

Epoch: 5| Step: 8
Training loss: 1.8010141849517822
Validation loss: 2.1801406343777976

Epoch: 5| Step: 9
Training loss: 1.6574039459228516
Validation loss: 2.118257443110148

Epoch: 5| Step: 10
Training loss: 1.399518609046936
Validation loss: 2.2440879543622336

Epoch: 5| Step: 11
Training loss: 1.1489487886428833
Validation loss: 2.176615754763285

Epoch: 134| Step: 0
Training loss: 1.737971305847168
Validation loss: 2.2116798410813012

Epoch: 5| Step: 1
Training loss: 1.4158480167388916
Validation loss: 2.207738384604454

Epoch: 5| Step: 2
Training loss: 2.124237060546875
Validation loss: 2.269945735732714

Epoch: 5| Step: 3
Training loss: 1.8365447521209717
Validation loss: 2.211750070254008

Epoch: 5| Step: 4
Training loss: 1.5293303728103638
Validation loss: 2.2044503589471183

Epoch: 5| Step: 5
Training loss: 2.1894662380218506
Validation loss: 2.3044613053401313

Epoch: 5| Step: 6
Training loss: 1.9176498651504517
Validation loss: 2.1694339166084924

Epoch: 5| Step: 7
Training loss: 1.72198486328125
Validation loss: 2.1574304501215615

Epoch: 5| Step: 8
Training loss: 1.7883899211883545
Validation loss: 2.2427177329858146

Epoch: 5| Step: 9
Training loss: 1.690168023109436
Validation loss: 2.3383778085311255

Epoch: 5| Step: 10
Training loss: 1.4818036556243896
Validation loss: 2.2557895282904306

Epoch: 5| Step: 11
Training loss: 1.7360117435455322
Validation loss: 2.238973875840505

Epoch: 135| Step: 0
Training loss: 2.101998805999756
Validation loss: 2.236370066801707

Epoch: 5| Step: 1
Training loss: 1.5586470365524292
Validation loss: 2.320796012878418

Epoch: 5| Step: 2
Training loss: 1.977081298828125
Validation loss: 2.3126341005166373

Epoch: 5| Step: 3
Training loss: 1.9404834508895874
Validation loss: 2.3662000944217048

Epoch: 5| Step: 4
Training loss: 1.8458524942398071
Validation loss: 2.253714144229889

Epoch: 5| Step: 5
Training loss: 1.7492605447769165
Validation loss: 2.197894205649694

Epoch: 5| Step: 6
Training loss: 1.9575151205062866
Validation loss: 2.1750054160753884

Epoch: 5| Step: 7
Training loss: 2.056546449661255
Validation loss: 2.156591087579727

Epoch: 5| Step: 8
Training loss: 1.950084924697876
Validation loss: 2.2192000647385917

Epoch: 5| Step: 9
Training loss: 1.7871723175048828
Validation loss: 2.1356252282857895

Epoch: 5| Step: 10
Training loss: 1.4722440242767334
Validation loss: 2.152838702003161

Epoch: 5| Step: 11
Training loss: 2.450807809829712
Validation loss: 2.14665458103021

Epoch: 136| Step: 0
Training loss: 1.6183398962020874
Validation loss: 2.209781954685847

Epoch: 5| Step: 1
Training loss: 1.4008814096450806
Validation loss: 2.293253779411316

Epoch: 5| Step: 2
Training loss: 1.7117996215820312
Validation loss: 2.386712908744812

Epoch: 5| Step: 3
Training loss: 2.1392436027526855
Validation loss: 2.2759625017642975

Epoch: 5| Step: 4
Training loss: 2.0079455375671387
Validation loss: 2.4138917525609336

Epoch: 5| Step: 5
Training loss: 1.7828891277313232
Validation loss: 2.2730404188235602

Epoch: 5| Step: 6
Training loss: 1.51180899143219
Validation loss: 2.3028307954470315

Epoch: 5| Step: 7
Training loss: 2.2811100482940674
Validation loss: 2.2639697194099426

Epoch: 5| Step: 8
Training loss: 2.0034594535827637
Validation loss: 2.123890201250712

Epoch: 5| Step: 9
Training loss: 1.376495599746704
Validation loss: 2.2485091189543405

Epoch: 5| Step: 10
Training loss: 1.9197571277618408
Validation loss: 2.2767503758271537

Epoch: 5| Step: 11
Training loss: 2.9039814472198486
Validation loss: 2.172152409950892

Epoch: 137| Step: 0
Training loss: 1.3542759418487549
Validation loss: 2.2521464079618454

Epoch: 5| Step: 1
Training loss: 1.7450382709503174
Validation loss: 2.2592131247123084

Epoch: 5| Step: 2
Training loss: 1.5551049709320068
Validation loss: 2.0957950403292975

Epoch: 5| Step: 3
Training loss: 1.9869709014892578
Validation loss: 2.346276491880417

Epoch: 5| Step: 4
Training loss: 2.0866000652313232
Validation loss: 2.227693180243174

Epoch: 5| Step: 5
Training loss: 1.6196054220199585
Validation loss: 2.159530828396479

Epoch: 5| Step: 6
Training loss: 1.6170008182525635
Validation loss: 2.163121203581492

Epoch: 5| Step: 7
Training loss: 1.4950172901153564
Validation loss: 2.190247341990471

Epoch: 5| Step: 8
Training loss: 2.1605582237243652
Validation loss: 2.3346420327822366

Epoch: 5| Step: 9
Training loss: 1.6289860010147095
Validation loss: 2.228038559357325

Epoch: 5| Step: 10
Training loss: 2.3176984786987305
Validation loss: 2.1768727699915567

Epoch: 5| Step: 11
Training loss: 1.9963070154190063
Validation loss: 2.3223264465729394

Epoch: 138| Step: 0
Training loss: 1.467655062675476
Validation loss: 2.2393476416667304

Epoch: 5| Step: 1
Training loss: 1.4159820079803467
Validation loss: 2.2493631839752197

Epoch: 5| Step: 2
Training loss: 1.4433698654174805
Validation loss: 2.2896394431591034

Epoch: 5| Step: 3
Training loss: 1.8617607355117798
Validation loss: 2.1933802167574563

Epoch: 5| Step: 4
Training loss: 1.6776123046875
Validation loss: 2.184380277991295

Epoch: 5| Step: 5
Training loss: 1.6989895105361938
Validation loss: 2.1684685746828714

Epoch: 5| Step: 6
Training loss: 2.481982946395874
Validation loss: 2.2368045300245285

Epoch: 5| Step: 7
Training loss: 2.100381374359131
Validation loss: 2.220017279187838

Epoch: 5| Step: 8
Training loss: 1.740617036819458
Validation loss: 2.1923969288667045

Epoch: 5| Step: 9
Training loss: 1.1521039009094238
Validation loss: 2.2568573455015817

Epoch: 5| Step: 10
Training loss: 2.158409595489502
Validation loss: 2.2559666832288108

Epoch: 5| Step: 11
Training loss: 1.3813633918762207
Validation loss: 2.2578724970420203

Epoch: 139| Step: 0
Training loss: 1.6363312005996704
Validation loss: 2.213865801692009

Epoch: 5| Step: 1
Training loss: 1.5109251737594604
Validation loss: 2.2933723429838815

Epoch: 5| Step: 2
Training loss: 1.4249809980392456
Validation loss: 2.281035214662552

Epoch: 5| Step: 3
Training loss: 1.4855929613113403
Validation loss: 2.2290439109007516

Epoch: 5| Step: 4
Training loss: 1.8898885250091553
Validation loss: 2.285343254605929

Epoch: 5| Step: 5
Training loss: 1.4389069080352783
Validation loss: 2.239425390958786

Epoch: 5| Step: 6
Training loss: 1.2107665538787842
Validation loss: 2.2118828495343528

Epoch: 5| Step: 7
Training loss: 2.155926465988159
Validation loss: 2.181690439581871

Epoch: 5| Step: 8
Training loss: 2.6727027893066406
Validation loss: 2.2377482056617737

Epoch: 5| Step: 9
Training loss: 1.526822805404663
Validation loss: 2.2079726457595825

Epoch: 5| Step: 10
Training loss: 2.003394365310669
Validation loss: 2.2097088396549225

Epoch: 5| Step: 11
Training loss: 1.6690688133239746
Validation loss: 2.2899327278137207

Epoch: 140| Step: 0
Training loss: 1.6563880443572998
Validation loss: 2.2757560859123864

Epoch: 5| Step: 1
Training loss: 2.3208961486816406
Validation loss: 2.254833588997523

Epoch: 5| Step: 2
Training loss: 1.4794867038726807
Validation loss: 2.1298739661773047

Epoch: 5| Step: 3
Training loss: 1.4400055408477783
Validation loss: 2.1993941317001977

Epoch: 5| Step: 4
Training loss: 1.433241605758667
Validation loss: 2.2775301784276962

Epoch: 5| Step: 5
Training loss: 1.5437276363372803
Validation loss: 2.294055849313736

Epoch: 5| Step: 6
Training loss: 1.9998658895492554
Validation loss: 2.187822610139847

Epoch: 5| Step: 7
Training loss: 2.185412883758545
Validation loss: 2.1557574768861136

Epoch: 5| Step: 8
Training loss: 1.7627605199813843
Validation loss: 2.0990970780452094

Epoch: 5| Step: 9
Training loss: 1.8759803771972656
Validation loss: 2.2503851552804313

Epoch: 5| Step: 10
Training loss: 1.919088363647461
Validation loss: 2.1958596060673394

Epoch: 5| Step: 11
Training loss: 1.098354458808899
Validation loss: 2.1548716922601066

Epoch: 141| Step: 0
Training loss: 1.6441514492034912
Validation loss: 2.258178268869718

Epoch: 5| Step: 1
Training loss: 1.6007633209228516
Validation loss: 2.266429767012596

Epoch: 5| Step: 2
Training loss: 2.3030457496643066
Validation loss: 2.291842738787333

Epoch: 5| Step: 3
Training loss: 1.5750648975372314
Validation loss: 2.2120703558127084

Epoch: 5| Step: 4
Training loss: 1.3024542331695557
Validation loss: 2.276086673140526

Epoch: 5| Step: 5
Training loss: 1.8102235794067383
Validation loss: 2.238535995284716

Epoch: 5| Step: 6
Training loss: 1.8247684240341187
Validation loss: 2.284752835830053

Epoch: 5| Step: 7
Training loss: 1.7714452743530273
Validation loss: 2.2301985770463943

Epoch: 5| Step: 8
Training loss: 2.1081461906433105
Validation loss: 2.1856113374233246

Epoch: 5| Step: 9
Training loss: 1.5566288232803345
Validation loss: 2.2029715478420258

Epoch: 5| Step: 10
Training loss: 1.8930881023406982
Validation loss: 2.253858983516693

Epoch: 5| Step: 11
Training loss: 2.251265048980713
Validation loss: 2.1739547749360404

Epoch: 142| Step: 0
Training loss: 1.5771971940994263
Validation loss: 2.181843712925911

Epoch: 5| Step: 1
Training loss: 1.8826732635498047
Validation loss: 2.224308987458547

Epoch: 5| Step: 2
Training loss: 2.289595127105713
Validation loss: 2.1821325918038688

Epoch: 5| Step: 3
Training loss: 1.6867001056671143
Validation loss: 2.249391491214434

Epoch: 5| Step: 4
Training loss: 1.1788733005523682
Validation loss: 2.2608358561992645

Epoch: 5| Step: 5
Training loss: 1.438948392868042
Validation loss: 2.246034195025762

Epoch: 5| Step: 6
Training loss: 1.9113407135009766
Validation loss: 2.2071136832237244

Epoch: 5| Step: 7
Training loss: 1.439728021621704
Validation loss: 2.2723782459894815

Epoch: 5| Step: 8
Training loss: 1.6474626064300537
Validation loss: 2.214421272277832

Epoch: 5| Step: 9
Training loss: 2.153413772583008
Validation loss: 2.219960868358612

Epoch: 5| Step: 10
Training loss: 2.2231974601745605
Validation loss: 2.336037149031957

Epoch: 5| Step: 11
Training loss: 1.489268183708191
Validation loss: 2.242217481136322

Epoch: 143| Step: 0
Training loss: 1.5270428657531738
Validation loss: 2.354867031176885

Epoch: 5| Step: 1
Training loss: 1.3080852031707764
Validation loss: 2.246647377808889

Epoch: 5| Step: 2
Training loss: 1.6637585163116455
Validation loss: 2.206045846144358

Epoch: 5| Step: 3
Training loss: 1.865722894668579
Validation loss: 2.1619758705298104

Epoch: 5| Step: 4
Training loss: 1.5239231586456299
Validation loss: 2.2698224931955338

Epoch: 5| Step: 5
Training loss: 1.7459659576416016
Validation loss: 2.2994481921195984

Epoch: 5| Step: 6
Training loss: 1.9025182723999023
Validation loss: 2.204151834050814

Epoch: 5| Step: 7
Training loss: 1.662026047706604
Validation loss: 2.367986877759298

Epoch: 5| Step: 8
Training loss: 1.9920848608016968
Validation loss: 2.3004861921072006

Epoch: 5| Step: 9
Training loss: 2.1931328773498535
Validation loss: 2.2848082780838013

Epoch: 5| Step: 10
Training loss: 1.998486876487732
Validation loss: 2.2384639581044516

Epoch: 5| Step: 11
Training loss: 1.3345812559127808
Validation loss: 2.2943849166234336

Epoch: 144| Step: 0
Training loss: 1.5318683385849
Validation loss: 2.243839979171753

Epoch: 5| Step: 1
Training loss: 2.4020729064941406
Validation loss: 2.3097170343001685

Epoch: 5| Step: 2
Training loss: 1.6400439739227295
Validation loss: 2.094738319516182

Epoch: 5| Step: 3
Training loss: 2.206373453140259
Validation loss: 2.1520359913508096

Epoch: 5| Step: 4
Training loss: 1.808779001235962
Validation loss: 2.274651130040487

Epoch: 5| Step: 5
Training loss: 1.4488643407821655
Validation loss: 2.185625731945038

Epoch: 5| Step: 6
Training loss: 1.8688373565673828
Validation loss: 2.1250716149806976

Epoch: 5| Step: 7
Training loss: 1.3913463354110718
Validation loss: 2.248548001050949

Epoch: 5| Step: 8
Training loss: 1.6153875589370728
Validation loss: 2.18884905676047

Epoch: 5| Step: 9
Training loss: 1.738147497177124
Validation loss: 2.274750972787539

Epoch: 5| Step: 10
Training loss: 1.6649267673492432
Validation loss: 2.2944882412751517

Epoch: 5| Step: 11
Training loss: 2.364307403564453
Validation loss: 2.2071255644162497

Epoch: 145| Step: 0
Training loss: 1.8848679065704346
Validation loss: 2.3119852046171823

Epoch: 5| Step: 1
Training loss: 1.9852794408798218
Validation loss: 2.376388261715571

Epoch: 5| Step: 2
Training loss: 1.6079676151275635
Validation loss: 2.3015297651290894

Epoch: 5| Step: 3
Training loss: 1.5672447681427002
Validation loss: 2.291442036628723

Epoch: 5| Step: 4
Training loss: 1.966688871383667
Validation loss: 2.266670882701874

Epoch: 5| Step: 5
Training loss: 1.4420273303985596
Validation loss: 2.210323845346769

Epoch: 5| Step: 6
Training loss: 1.984177827835083
Validation loss: 2.315494269132614

Epoch: 5| Step: 7
Training loss: 1.6637624502182007
Validation loss: 2.2458514471848807

Epoch: 5| Step: 8
Training loss: 1.925737977027893
Validation loss: 2.1792658219734826

Epoch: 5| Step: 9
Training loss: 1.5570037364959717
Validation loss: 2.2802010029554367

Epoch: 5| Step: 10
Training loss: 1.958242416381836
Validation loss: 2.200665866335233

Epoch: 5| Step: 11
Training loss: 0.7512319087982178
Validation loss: 2.2740028152863183

Epoch: 146| Step: 0
Training loss: 2.33188796043396
Validation loss: 2.238164479533831

Epoch: 5| Step: 1
Training loss: 1.5258724689483643
Validation loss: 2.267400731643041

Epoch: 5| Step: 2
Training loss: 1.6493873596191406
Validation loss: 2.2327758967876434

Epoch: 5| Step: 3
Training loss: 1.4868957996368408
Validation loss: 2.118815685311953

Epoch: 5| Step: 4
Training loss: 1.4887455701828003
Validation loss: 2.2489134867986045

Epoch: 5| Step: 5
Training loss: 1.4473906755447388
Validation loss: 2.2088259061177573

Epoch: 5| Step: 6
Training loss: 1.4350563287734985
Validation loss: 2.3045389552911124

Epoch: 5| Step: 7
Training loss: 1.832824945449829
Validation loss: 2.2935071289539337

Epoch: 5| Step: 8
Training loss: 1.9802865982055664
Validation loss: 2.243279109398524

Epoch: 5| Step: 9
Training loss: 1.6596364974975586
Validation loss: 2.2084873964389167

Epoch: 5| Step: 10
Training loss: 2.000750780105591
Validation loss: 2.202770541111628

Epoch: 5| Step: 11
Training loss: 1.8457432985305786
Validation loss: 2.2076078951358795

Epoch: 147| Step: 0
Training loss: 1.5934998989105225
Validation loss: 2.3087744961182275

Epoch: 5| Step: 1
Training loss: 2.148181438446045
Validation loss: 2.1674391428629556

Epoch: 5| Step: 2
Training loss: 2.436347484588623
Validation loss: 2.294007663925489

Epoch: 5| Step: 3
Training loss: 1.5291420221328735
Validation loss: 2.269147604703903

Epoch: 5| Step: 4
Training loss: 1.521937608718872
Validation loss: 2.291722148656845

Epoch: 5| Step: 5
Training loss: 1.6742370128631592
Validation loss: 2.2261047263940177

Epoch: 5| Step: 6
Training loss: 2.0195889472961426
Validation loss: 2.263636236389478

Epoch: 5| Step: 7
Training loss: 2.129626512527466
Validation loss: 2.284938762585322

Epoch: 5| Step: 8
Training loss: 1.492530345916748
Validation loss: 2.291567246119181

Epoch: 5| Step: 9
Training loss: 1.5527647733688354
Validation loss: 2.269231160481771

Epoch: 5| Step: 10
Training loss: 1.8111207485198975
Validation loss: 2.173718507091204

Epoch: 5| Step: 11
Training loss: 2.4991464614868164
Validation loss: 2.2329229613145194

Epoch: 148| Step: 0
Training loss: 1.6131057739257812
Validation loss: 2.2121179501215615

Epoch: 5| Step: 1
Training loss: 1.468377709388733
Validation loss: 2.2110014905532203

Epoch: 5| Step: 2
Training loss: 1.2669687271118164
Validation loss: 2.2045635332663855

Epoch: 5| Step: 3
Training loss: 1.4137217998504639
Validation loss: 2.1993537644545236

Epoch: 5| Step: 4
Training loss: 1.8819366693496704
Validation loss: 2.224883198738098

Epoch: 5| Step: 5
Training loss: 2.0258231163024902
Validation loss: 2.1981973548730216

Epoch: 5| Step: 6
Training loss: 2.0359292030334473
Validation loss: 2.2760059386491776

Epoch: 5| Step: 7
Training loss: 1.9285293817520142
Validation loss: 2.1200658778349557

Epoch: 5| Step: 8
Training loss: 1.7306960821151733
Validation loss: 2.2333074857791266

Epoch: 5| Step: 9
Training loss: 1.6496000289916992
Validation loss: 2.2468283077081046

Epoch: 5| Step: 10
Training loss: 1.639992356300354
Validation loss: 2.1795237362384796

Epoch: 5| Step: 11
Training loss: 1.3835868835449219
Validation loss: 2.2155593434969583

Epoch: 149| Step: 0
Training loss: 1.9650156497955322
Validation loss: 2.2608090738455453

Epoch: 5| Step: 1
Training loss: 1.8594201803207397
Validation loss: 2.203925391038259

Epoch: 5| Step: 2
Training loss: 1.8039432764053345
Validation loss: 2.196621427933375

Epoch: 5| Step: 3
Training loss: 1.719024896621704
Validation loss: 2.2811361650625863

Epoch: 5| Step: 4
Training loss: 1.4194161891937256
Validation loss: 2.2106359054644904

Epoch: 5| Step: 5
Training loss: 1.3805420398712158
Validation loss: 2.197041943669319

Epoch: 5| Step: 6
Training loss: 1.8133827447891235
Validation loss: 2.2738896161317825

Epoch: 5| Step: 7
Training loss: 2.122974157333374
Validation loss: 2.239952733119329

Epoch: 5| Step: 8
Training loss: 1.4411038160324097
Validation loss: 2.1564535746971765

Epoch: 5| Step: 9
Training loss: 1.8163235187530518
Validation loss: 2.2197600106398263

Epoch: 5| Step: 10
Training loss: 1.348358392715454
Validation loss: 2.294722934563955

Epoch: 5| Step: 11
Training loss: 3.9056437015533447
Validation loss: 2.1489696204662323

Epoch: 150| Step: 0
Training loss: 1.7469593286514282
Validation loss: 2.142869239052137

Epoch: 5| Step: 1
Training loss: 2.0239386558532715
Validation loss: 2.264873822530111

Epoch: 5| Step: 2
Training loss: 1.8014854192733765
Validation loss: 2.310588220755259

Epoch: 5| Step: 3
Training loss: 1.6746559143066406
Validation loss: 2.335605949163437

Epoch: 5| Step: 4
Training loss: 1.7991262674331665
Validation loss: 2.1899974048137665

Epoch: 5| Step: 5
Training loss: 1.773810625076294
Validation loss: 2.296325614054998

Epoch: 5| Step: 6
Training loss: 1.6329139471054077
Validation loss: 2.2422426591316857

Epoch: 5| Step: 7
Training loss: 1.9414608478546143
Validation loss: 2.2944168945153556

Epoch: 5| Step: 8
Training loss: 1.9623416662216187
Validation loss: 2.1785544951756797

Epoch: 5| Step: 9
Training loss: 1.3953964710235596
Validation loss: 2.2329447269439697

Epoch: 5| Step: 10
Training loss: 1.2340738773345947
Validation loss: 2.1386310160160065

Epoch: 5| Step: 11
Training loss: 2.3102190494537354
Validation loss: 2.2665221889813743

Epoch: 151| Step: 0
Training loss: 1.8963050842285156
Validation loss: 2.2663534929354987

Epoch: 5| Step: 1
Training loss: 1.4490315914154053
Validation loss: 2.22537562251091

Epoch: 5| Step: 2
Training loss: 1.6422803401947021
Validation loss: 2.2395275433858237

Epoch: 5| Step: 3
Training loss: 1.8682454824447632
Validation loss: 2.2754955192406974

Epoch: 5| Step: 4
Training loss: 1.6392618417739868
Validation loss: 2.1999253580967584

Epoch: 5| Step: 5
Training loss: 1.8651421070098877
Validation loss: 2.278068040808042

Epoch: 5| Step: 6
Training loss: 1.9892723560333252
Validation loss: 2.241774226228396

Epoch: 5| Step: 7
Training loss: 1.4252458810806274
Validation loss: 2.3067511469125748

Epoch: 5| Step: 8
Training loss: 2.4276955127716064
Validation loss: 2.1626720428466797

Epoch: 5| Step: 9
Training loss: 1.1089229583740234
Validation loss: 2.251546556750933

Epoch: 5| Step: 10
Training loss: 1.907651662826538
Validation loss: 2.160735900203387

Epoch: 5| Step: 11
Training loss: 1.8161481618881226
Validation loss: 2.1186856081088385

Epoch: 152| Step: 0
Training loss: 1.7957862615585327
Validation loss: 2.186268319686254

Epoch: 5| Step: 1
Training loss: 2.0150973796844482
Validation loss: 2.155799155433973

Epoch: 5| Step: 2
Training loss: 1.2415359020233154
Validation loss: 2.2309000392754874

Epoch: 5| Step: 3
Training loss: 2.5640385150909424
Validation loss: 2.2400504102309546

Epoch: 5| Step: 4
Training loss: 1.1451444625854492
Validation loss: 2.2277244925498962

Epoch: 5| Step: 5
Training loss: 1.1264737844467163
Validation loss: 2.194682498772939

Epoch: 5| Step: 6
Training loss: 1.6742738485336304
Validation loss: 2.2094444185495377

Epoch: 5| Step: 7
Training loss: 2.064788579940796
Validation loss: 2.232798303167025

Epoch: 5| Step: 8
Training loss: 1.6239007711410522
Validation loss: 2.2841684917608895

Epoch: 5| Step: 9
Training loss: 1.8085581064224243
Validation loss: 2.2469842384258905

Epoch: 5| Step: 10
Training loss: 1.784725546836853
Validation loss: 2.3255921602249146

Epoch: 5| Step: 11
Training loss: 1.929226040840149
Validation loss: 2.258566568295161

Epoch: 153| Step: 0
Training loss: 1.2411737442016602
Validation loss: 2.229404220978419

Epoch: 5| Step: 1
Training loss: 1.7785943746566772
Validation loss: 2.215566317240397

Epoch: 5| Step: 2
Training loss: 1.7321462631225586
Validation loss: 2.288080414136251

Epoch: 5| Step: 3
Training loss: 1.9296766519546509
Validation loss: 2.3302545150121055

Epoch: 5| Step: 4
Training loss: 1.406631588935852
Validation loss: 2.20634134610494

Epoch: 5| Step: 5
Training loss: 1.7264446020126343
Validation loss: 2.317973921696345

Epoch: 5| Step: 6
Training loss: 1.7355310916900635
Validation loss: 2.227965330084165

Epoch: 5| Step: 7
Training loss: 1.8457324504852295
Validation loss: 2.222703590989113

Epoch: 5| Step: 8
Training loss: 1.9946540594100952
Validation loss: 2.216617921988169

Epoch: 5| Step: 9
Training loss: 1.7079460620880127
Validation loss: 2.224839980403582

Epoch: 5| Step: 10
Training loss: 1.3835629224777222
Validation loss: 2.233469237883886

Epoch: 5| Step: 11
Training loss: 0.696222186088562
Validation loss: 2.2916508615016937

Epoch: 154| Step: 0
Training loss: 1.538851261138916
Validation loss: 2.3351998329162598

Epoch: 5| Step: 1
Training loss: 2.098799228668213
Validation loss: 2.404841204484304

Epoch: 5| Step: 2
Training loss: 1.915872573852539
Validation loss: 2.2996663451194763

Epoch: 5| Step: 3
Training loss: 1.797079086303711
Validation loss: 2.2358963787555695

Epoch: 5| Step: 4
Training loss: 1.623355507850647
Validation loss: 2.199908564488093

Epoch: 5| Step: 5
Training loss: 1.9001468420028687
Validation loss: 2.185974657535553

Epoch: 5| Step: 6
Training loss: 1.5612858533859253
Validation loss: 2.2011419037977853

Epoch: 5| Step: 7
Training loss: 2.6837196350097656
Validation loss: 2.2173075675964355

Epoch: 5| Step: 8
Training loss: 1.2080392837524414
Validation loss: 2.208755830923716

Epoch: 5| Step: 9
Training loss: 1.9290735721588135
Validation loss: 2.261374056339264

Epoch: 5| Step: 10
Training loss: 1.8442356586456299
Validation loss: 2.2541619638601937

Epoch: 5| Step: 11
Training loss: 1.7453525066375732
Validation loss: 2.27953893939654

Epoch: 155| Step: 0
Training loss: 2.3007991313934326
Validation loss: 2.2813772559165955

Epoch: 5| Step: 1
Training loss: 1.6321661472320557
Validation loss: 2.1149283597866693

Epoch: 5| Step: 2
Training loss: 1.396698236465454
Validation loss: 2.2288088699181876

Epoch: 5| Step: 3
Training loss: 1.9770724773406982
Validation loss: 2.1768546998500824

Epoch: 5| Step: 4
Training loss: 2.6030097007751465
Validation loss: 2.1708108484745026

Epoch: 5| Step: 5
Training loss: 1.899139404296875
Validation loss: 2.303525427977244

Epoch: 5| Step: 6
Training loss: 1.3918936252593994
Validation loss: 2.265514592329661

Epoch: 5| Step: 7
Training loss: 0.8706203699111938
Validation loss: 2.2172608375549316

Epoch: 5| Step: 8
Training loss: 1.377099633216858
Validation loss: 2.1782094140847525

Epoch: 5| Step: 9
Training loss: 1.6303802728652954
Validation loss: 2.1343972782293954

Epoch: 5| Step: 10
Training loss: 1.6785154342651367
Validation loss: 2.1805709997812905

Epoch: 5| Step: 11
Training loss: 0.8237476944923401
Validation loss: 2.187885656952858

Epoch: 156| Step: 0
Training loss: 1.6952073574066162
Validation loss: 2.2518992672363916

Epoch: 5| Step: 1
Training loss: 1.7511570453643799
Validation loss: 2.255181367198626

Epoch: 5| Step: 2
Training loss: 1.9547538757324219
Validation loss: 2.3653704772392907

Epoch: 5| Step: 3
Training loss: 1.890952706336975
Validation loss: 2.3106620063384375

Epoch: 5| Step: 4
Training loss: 2.0857231616973877
Validation loss: 2.2571933567523956

Epoch: 5| Step: 5
Training loss: 2.061607599258423
Validation loss: 2.2649556497732797

Epoch: 5| Step: 6
Training loss: 1.8534196615219116
Validation loss: 2.292800714572271

Epoch: 5| Step: 7
Training loss: 2.2011516094207764
Validation loss: 2.30338121453921

Epoch: 5| Step: 8
Training loss: 1.1984570026397705
Validation loss: 2.300348713994026

Epoch: 5| Step: 9
Training loss: 1.8829752206802368
Validation loss: 2.178098907073339

Epoch: 5| Step: 10
Training loss: 1.6096551418304443
Validation loss: 2.1703056593736014

Epoch: 5| Step: 11
Training loss: 1.8378479480743408
Validation loss: 2.199678877989451

Epoch: 157| Step: 0
Training loss: 1.1293890476226807
Validation loss: 2.2022400299708047

Epoch: 5| Step: 1
Training loss: 1.6080182790756226
Validation loss: 2.112941970427831

Epoch: 5| Step: 2
Training loss: 1.7031962871551514
Validation loss: 2.2143285274505615

Epoch: 5| Step: 3
Training loss: 2.049887180328369
Validation loss: 2.169766128063202

Epoch: 5| Step: 4
Training loss: 1.949488639831543
Validation loss: 2.2201237777868905

Epoch: 5| Step: 5
Training loss: 2.420964241027832
Validation loss: 2.157927726705869

Epoch: 5| Step: 6
Training loss: 1.326080560684204
Validation loss: 2.2117239038149514

Epoch: 5| Step: 7
Training loss: 1.3311784267425537
Validation loss: 2.2437022725741067

Epoch: 5| Step: 8
Training loss: 1.615850806236267
Validation loss: 2.2522424260775247

Epoch: 5| Step: 9
Training loss: 2.140300989151001
Validation loss: 2.1626146932442984

Epoch: 5| Step: 10
Training loss: 1.4533218145370483
Validation loss: 2.2303787916898727

Epoch: 5| Step: 11
Training loss: 0.8382049202919006
Validation loss: 2.304164002339045

Epoch: 158| Step: 0
Training loss: 1.8507473468780518
Validation loss: 2.2256780713796616

Epoch: 5| Step: 1
Training loss: 1.7668483257293701
Validation loss: 2.2104030698537827

Epoch: 5| Step: 2
Training loss: 1.8324687480926514
Validation loss: 2.2336307813723884

Epoch: 5| Step: 3
Training loss: 1.5441720485687256
Validation loss: 2.2221923172473907

Epoch: 5| Step: 4
Training loss: 1.5652377605438232
Validation loss: 2.1819058507680893

Epoch: 5| Step: 5
Training loss: 1.655511498451233
Validation loss: 2.2018130868673325

Epoch: 5| Step: 6
Training loss: 1.5701031684875488
Validation loss: 2.214584082365036

Epoch: 5| Step: 7
Training loss: 1.770943284034729
Validation loss: 2.1115036656459174

Epoch: 5| Step: 8
Training loss: 1.2547717094421387
Validation loss: 2.1403531779845557

Epoch: 5| Step: 9
Training loss: 1.8029282093048096
Validation loss: 2.169905627767245

Epoch: 5| Step: 10
Training loss: 1.8435777425765991
Validation loss: 2.1961395839850106

Epoch: 5| Step: 11
Training loss: 2.114168167114258
Validation loss: 2.1593210697174072

Epoch: 159| Step: 0
Training loss: 1.5853967666625977
Validation loss: 2.165883476535479

Epoch: 5| Step: 1
Training loss: 1.5536638498306274
Validation loss: 2.07166155676047

Epoch: 5| Step: 2
Training loss: 1.4899160861968994
Validation loss: 2.2175790617863336

Epoch: 5| Step: 3
Training loss: 2.3411343097686768
Validation loss: 2.1858453899621964

Epoch: 5| Step: 4
Training loss: 1.312951922416687
Validation loss: 2.250971242785454

Epoch: 5| Step: 5
Training loss: 1.6886482238769531
Validation loss: 2.303941319386164

Epoch: 5| Step: 6
Training loss: 1.8805478811264038
Validation loss: 2.188329646984736

Epoch: 5| Step: 7
Training loss: 1.6370773315429688
Validation loss: 2.2381463597218194

Epoch: 5| Step: 8
Training loss: 1.5973505973815918
Validation loss: 2.240106741587321

Epoch: 5| Step: 9
Training loss: 1.9027019739151
Validation loss: 2.1623580555121102

Epoch: 5| Step: 10
Training loss: 1.758522391319275
Validation loss: 2.1435120602448783

Epoch: 5| Step: 11
Training loss: 1.9705314636230469
Validation loss: 2.293579558531443

Epoch: 160| Step: 0
Training loss: 1.5287261009216309
Validation loss: 2.1153914282719293

Epoch: 5| Step: 1
Training loss: 1.9026644229888916
Validation loss: 2.2224275271097818

Epoch: 5| Step: 2
Training loss: 2.0300698280334473
Validation loss: 2.2575518091519675

Epoch: 5| Step: 3
Training loss: 1.12830650806427
Validation loss: 2.258744557698568

Epoch: 5| Step: 4
Training loss: 1.6194721460342407
Validation loss: 2.229153573513031

Epoch: 5| Step: 5
Training loss: 2.213749885559082
Validation loss: 2.2916787217060723

Epoch: 5| Step: 6
Training loss: 1.2702642679214478
Validation loss: 2.3214467465877533

Epoch: 5| Step: 7
Training loss: 1.862575888633728
Validation loss: 2.233831266562144

Epoch: 5| Step: 8
Training loss: 1.5974206924438477
Validation loss: 2.2657972474892936

Epoch: 5| Step: 9
Training loss: 1.7465641498565674
Validation loss: 2.186737611889839

Epoch: 5| Step: 10
Training loss: 1.758868932723999
Validation loss: 2.1890019873778024

Epoch: 5| Step: 11
Training loss: 2.1795670986175537
Validation loss: 2.1049323032299676

Epoch: 161| Step: 0
Training loss: 2.539015531539917
Validation loss: 2.2325069457292557

Epoch: 5| Step: 1
Training loss: 2.2948391437530518
Validation loss: 2.173106158773104

Epoch: 5| Step: 2
Training loss: 1.3119850158691406
Validation loss: 2.20512056350708

Epoch: 5| Step: 3
Training loss: 1.1931045055389404
Validation loss: 2.1491711288690567

Epoch: 5| Step: 4
Training loss: 2.1489338874816895
Validation loss: 2.219522143403689

Epoch: 5| Step: 5
Training loss: 1.750079870223999
Validation loss: 2.236033687988917

Epoch: 5| Step: 6
Training loss: 1.174034833908081
Validation loss: 2.258618727326393

Epoch: 5| Step: 7
Training loss: 1.763654351234436
Validation loss: 2.3309013346831002

Epoch: 5| Step: 8
Training loss: 2.0556185245513916
Validation loss: 2.216495250662168

Epoch: 5| Step: 9
Training loss: 1.4235689640045166
Validation loss: 2.229375238219897

Epoch: 5| Step: 10
Training loss: 1.6760742664337158
Validation loss: 2.178308069705963

Epoch: 5| Step: 11
Training loss: 0.9613704681396484
Validation loss: 2.175707240899404

Epoch: 162| Step: 0
Training loss: 1.8463119268417358
Validation loss: 2.2144237756729126

Epoch: 5| Step: 1
Training loss: 1.5585881471633911
Validation loss: 2.1442590604225793

Epoch: 5| Step: 2
Training loss: 2.026892900466919
Validation loss: 2.240329841772715

Epoch: 5| Step: 3
Training loss: 1.3932092189788818
Validation loss: 2.2945859332879386

Epoch: 5| Step: 4
Training loss: 2.340705394744873
Validation loss: 2.3062055508295694

Epoch: 5| Step: 5
Training loss: 1.8047202825546265
Validation loss: 2.26233563820521

Epoch: 5| Step: 6
Training loss: 1.8793132305145264
Validation loss: 2.216108977794647

Epoch: 5| Step: 7
Training loss: 1.3134124279022217
Validation loss: 2.1788534273703895

Epoch: 5| Step: 8
Training loss: 1.934225082397461
Validation loss: 2.228515346844991

Epoch: 5| Step: 9
Training loss: 1.6188640594482422
Validation loss: 2.1542610228061676

Epoch: 5| Step: 10
Training loss: 1.5084527730941772
Validation loss: 2.126365214586258

Epoch: 5| Step: 11
Training loss: 1.4203943014144897
Validation loss: 2.2383019725481668

Epoch: 163| Step: 0
Training loss: 1.8671945333480835
Validation loss: 2.2106502453486123

Epoch: 5| Step: 1
Training loss: 1.75882887840271
Validation loss: 2.26801073551178

Epoch: 5| Step: 2
Training loss: 1.802528977394104
Validation loss: 2.209413021802902

Epoch: 5| Step: 3
Training loss: 1.7403854131698608
Validation loss: 2.387352466583252

Epoch: 5| Step: 4
Training loss: 1.7779449224472046
Validation loss: 2.1897451281547546

Epoch: 5| Step: 5
Training loss: 1.815835952758789
Validation loss: 2.2995754381020865

Epoch: 5| Step: 6
Training loss: 1.415502667427063
Validation loss: 2.182807038227717

Epoch: 5| Step: 7
Training loss: 1.3031002283096313
Validation loss: 2.1951471070448556

Epoch: 5| Step: 8
Training loss: 1.5691616535186768
Validation loss: 2.244756897290548

Epoch: 5| Step: 9
Training loss: 2.104158639907837
Validation loss: 2.153105288743973

Epoch: 5| Step: 10
Training loss: 1.6945326328277588
Validation loss: 2.1433740754922233

Epoch: 5| Step: 11
Training loss: 2.9868273735046387
Validation loss: 2.151033247510592

Epoch: 164| Step: 0
Training loss: 2.4155783653259277
Validation loss: 2.2058869699637094

Epoch: 5| Step: 1
Training loss: 1.3589894771575928
Validation loss: 2.327994386355082

Epoch: 5| Step: 2
Training loss: 1.497485637664795
Validation loss: 2.294046312570572

Epoch: 5| Step: 3
Training loss: 2.198870897293091
Validation loss: 2.308993548154831

Epoch: 5| Step: 4
Training loss: 1.4054718017578125
Validation loss: 2.270170991619428

Epoch: 5| Step: 5
Training loss: 1.9481914043426514
Validation loss: 2.400024185578028

Epoch: 5| Step: 6
Training loss: 1.8168176412582397
Validation loss: 2.309075658520063

Epoch: 5| Step: 7
Training loss: 1.2549281120300293
Validation loss: 2.2304035673538842

Epoch: 5| Step: 8
Training loss: 1.704163908958435
Validation loss: 2.3120540976524353

Epoch: 5| Step: 9
Training loss: 1.478790521621704
Validation loss: 2.2448547780513763

Epoch: 5| Step: 10
Training loss: 1.6270771026611328
Validation loss: 2.128274902701378

Epoch: 5| Step: 11
Training loss: 1.050832986831665
Validation loss: 2.2044659554958344

Epoch: 165| Step: 0
Training loss: 1.4750553369522095
Validation loss: 2.1987007906039557

Epoch: 5| Step: 1
Training loss: 1.5260660648345947
Validation loss: 2.251910080512365

Epoch: 5| Step: 2
Training loss: 1.6978375911712646
Validation loss: 2.231041287382444

Epoch: 5| Step: 3
Training loss: 1.8876945972442627
Validation loss: 2.2495183746019998

Epoch: 5| Step: 4
Training loss: 1.3955928087234497
Validation loss: 2.300996700922648

Epoch: 5| Step: 5
Training loss: 2.155197858810425
Validation loss: 2.2229498525460563

Epoch: 5| Step: 6
Training loss: 2.2775356769561768
Validation loss: 2.134912038842837

Epoch: 5| Step: 7
Training loss: 1.5005481243133545
Validation loss: 2.1628993650277457

Epoch: 5| Step: 8
Training loss: 1.4962141513824463
Validation loss: 2.154615114132563

Epoch: 5| Step: 9
Training loss: 1.599851131439209
Validation loss: 2.168672725558281

Epoch: 5| Step: 10
Training loss: 1.8004264831542969
Validation loss: 2.2354934215545654

Epoch: 5| Step: 11
Training loss: 1.5231598615646362
Validation loss: 2.314945081869761

Epoch: 166| Step: 0
Training loss: 1.7477149963378906
Validation loss: 2.2002216577529907

Epoch: 5| Step: 1
Training loss: 1.8580280542373657
Validation loss: 2.2607805033524833

Epoch: 5| Step: 2
Training loss: 2.0555031299591064
Validation loss: 2.214329034090042

Epoch: 5| Step: 3
Training loss: 1.4305421113967896
Validation loss: 2.2415906687577567

Epoch: 5| Step: 4
Training loss: 1.8736953735351562
Validation loss: 2.2022928595542908

Epoch: 5| Step: 5
Training loss: 1.433541178703308
Validation loss: 2.148212437828382

Epoch: 5| Step: 6
Training loss: 1.2043750286102295
Validation loss: 2.2293233474095664

Epoch: 5| Step: 7
Training loss: 1.3524144887924194
Validation loss: 2.204876273870468

Epoch: 5| Step: 8
Training loss: 2.4910309314727783
Validation loss: 2.1311884224414825

Epoch: 5| Step: 9
Training loss: 1.3438364267349243
Validation loss: 2.1220831871032715

Epoch: 5| Step: 10
Training loss: 1.9354333877563477
Validation loss: 2.3163302838802338

Epoch: 5| Step: 11
Training loss: 1.2301464080810547
Validation loss: 2.1774508555730185

Epoch: 167| Step: 0
Training loss: 1.5960460901260376
Validation loss: 2.2004943738381066

Epoch: 5| Step: 1
Training loss: 2.11008358001709
Validation loss: 2.1519162555535636

Epoch: 5| Step: 2
Training loss: 1.2663309574127197
Validation loss: 2.1802454193433127

Epoch: 5| Step: 3
Training loss: 1.318572998046875
Validation loss: 2.1436796436707177

Epoch: 5| Step: 4
Training loss: 1.8632075786590576
Validation loss: 2.127755100528399

Epoch: 5| Step: 5
Training loss: 1.5981401205062866
Validation loss: 2.2412729362646737

Epoch: 5| Step: 6
Training loss: 1.0320978164672852
Validation loss: 2.135104055205981

Epoch: 5| Step: 7
Training loss: 1.451128602027893
Validation loss: 2.150561352570852

Epoch: 5| Step: 8
Training loss: 2.2659506797790527
Validation loss: 2.0783260613679886

Epoch: 5| Step: 9
Training loss: 1.6621463298797607
Validation loss: 2.197765459616979

Epoch: 5| Step: 10
Training loss: 1.2662914991378784
Validation loss: 2.1361628274122872

Epoch: 5| Step: 11
Training loss: 1.0850703716278076
Validation loss: 2.2053719013929367

Epoch: 168| Step: 0
Training loss: 1.9042539596557617
Validation loss: 2.1694187770287194

Epoch: 5| Step: 1
Training loss: 1.259570837020874
Validation loss: 2.3691822439432144

Epoch: 5| Step: 2
Training loss: 1.9436275959014893
Validation loss: 2.3496139645576477

Epoch: 5| Step: 3
Training loss: 1.8954111337661743
Validation loss: 2.2524236937363944

Epoch: 5| Step: 4
Training loss: 1.8119529485702515
Validation loss: 2.282475789388021

Epoch: 5| Step: 5
Training loss: 1.7349939346313477
Validation loss: 2.257264311114947

Epoch: 5| Step: 6
Training loss: 1.5266269445419312
Validation loss: 2.2061886390050254

Epoch: 5| Step: 7
Training loss: 1.5325443744659424
Validation loss: 2.2221026370922723

Epoch: 5| Step: 8
Training loss: 1.5803163051605225
Validation loss: 2.17452065149943

Epoch: 5| Step: 9
Training loss: 1.9813899993896484
Validation loss: 2.2340049147605896

Epoch: 5| Step: 10
Training loss: 1.9298455715179443
Validation loss: 2.1512361615896225

Epoch: 5| Step: 11
Training loss: 1.7821599245071411
Validation loss: 2.256366178393364

Epoch: 169| Step: 0
Training loss: 1.450485348701477
Validation loss: 2.1382922182480493

Epoch: 5| Step: 1
Training loss: 1.5142543315887451
Validation loss: 2.11596642434597

Epoch: 5| Step: 2
Training loss: 1.9387133121490479
Validation loss: 2.1298339664936066

Epoch: 5| Step: 3
Training loss: 1.8400176763534546
Validation loss: 2.136998479564985

Epoch: 5| Step: 4
Training loss: 1.388146162033081
Validation loss: 2.2610949029525123

Epoch: 5| Step: 5
Training loss: 1.3609225749969482
Validation loss: 2.2948779662450156

Epoch: 5| Step: 6
Training loss: 2.005465269088745
Validation loss: 2.201911802093188

Epoch: 5| Step: 7
Training loss: 1.491080403327942
Validation loss: 2.17904927333196

Epoch: 5| Step: 8
Training loss: 1.4840008020401
Validation loss: 2.2443854312102

Epoch: 5| Step: 9
Training loss: 1.8764833211898804
Validation loss: 2.1862901747226715

Epoch: 5| Step: 10
Training loss: 1.6165376901626587
Validation loss: 2.252854829033216

Epoch: 5| Step: 11
Training loss: 1.0178107023239136
Validation loss: 2.2088499814271927

Epoch: 170| Step: 0
Training loss: 1.5862764120101929
Validation loss: 2.277785062789917

Epoch: 5| Step: 1
Training loss: 1.6872432231903076
Validation loss: 2.2246988266706467

Epoch: 5| Step: 2
Training loss: 1.7493336200714111
Validation loss: 2.2378349602222443

Epoch: 5| Step: 3
Training loss: 1.8356082439422607
Validation loss: 2.293242394924164

Epoch: 5| Step: 4
Training loss: 1.637524962425232
Validation loss: 2.1991726557413735

Epoch: 5| Step: 5
Training loss: 1.5911840200424194
Validation loss: 2.2393594880898795

Epoch: 5| Step: 6
Training loss: 1.9388574361801147
Validation loss: 2.215960770845413

Epoch: 5| Step: 7
Training loss: 1.1274008750915527
Validation loss: 2.284348954757055

Epoch: 5| Step: 8
Training loss: 1.7425029277801514
Validation loss: 2.190300698081652

Epoch: 5| Step: 9
Training loss: 1.3279832601547241
Validation loss: 2.219292546312014

Epoch: 5| Step: 10
Training loss: 1.8689205646514893
Validation loss: 2.0561067909002304

Epoch: 5| Step: 11
Training loss: 1.399121880531311
Validation loss: 2.178545445203781

Epoch: 171| Step: 0
Training loss: 1.707741141319275
Validation loss: 2.1909209191799164

Epoch: 5| Step: 1
Training loss: 1.8444874286651611
Validation loss: 2.245301599303881

Epoch: 5| Step: 2
Training loss: 1.999189019203186
Validation loss: 2.2209164599577584

Epoch: 5| Step: 3
Training loss: 2.0550942420959473
Validation loss: 2.289739807446798

Epoch: 5| Step: 4
Training loss: 1.4267421960830688
Validation loss: 2.1949694057305655

Epoch: 5| Step: 5
Training loss: 1.6912176609039307
Validation loss: 2.2686330874760947

Epoch: 5| Step: 6
Training loss: 1.7594273090362549
Validation loss: 2.197859307130178

Epoch: 5| Step: 7
Training loss: 1.3843357563018799
Validation loss: 2.1710007886091867

Epoch: 5| Step: 8
Training loss: 1.0888035297393799
Validation loss: 2.233062207698822

Epoch: 5| Step: 9
Training loss: 1.381905198097229
Validation loss: 2.13198787967364

Epoch: 5| Step: 10
Training loss: 2.030543804168701
Validation loss: 2.2527755200862885

Epoch: 5| Step: 11
Training loss: 1.6298589706420898
Validation loss: 2.1874158481756845

Epoch: 172| Step: 0
Training loss: 1.7488420009613037
Validation loss: 2.2795245250066123

Epoch: 5| Step: 1
Training loss: 1.1474332809448242
Validation loss: 2.1494685212771096

Epoch: 5| Step: 2
Training loss: 1.7692992687225342
Validation loss: 2.1905078887939453

Epoch: 5| Step: 3
Training loss: 1.860533356666565
Validation loss: 2.1965264081954956

Epoch: 5| Step: 4
Training loss: 0.9767406582832336
Validation loss: 2.152146448691686

Epoch: 5| Step: 5
Training loss: 1.2579847574234009
Validation loss: 2.1011268496513367

Epoch: 5| Step: 6
Training loss: 1.8955339193344116
Validation loss: 2.178016404310862

Epoch: 5| Step: 7
Training loss: 2.0078063011169434
Validation loss: 2.1663627177476883

Epoch: 5| Step: 8
Training loss: 1.7249253988265991
Validation loss: 2.1507872939109802

Epoch: 5| Step: 9
Training loss: 1.5287729501724243
Validation loss: 2.1947246342897415

Epoch: 5| Step: 10
Training loss: 1.2382102012634277
Validation loss: 2.168799117207527

Epoch: 5| Step: 11
Training loss: 1.42435622215271
Validation loss: 2.2589429914951324

Epoch: 173| Step: 0
Training loss: 2.113086223602295
Validation loss: 2.268615166346232

Epoch: 5| Step: 1
Training loss: 0.9758197665214539
Validation loss: 2.266392394900322

Epoch: 5| Step: 2
Training loss: 2.134608745574951
Validation loss: 2.235291908184687

Epoch: 5| Step: 3
Training loss: 2.4545018672943115
Validation loss: 2.261747658252716

Epoch: 5| Step: 4
Training loss: 1.2132991552352905
Validation loss: 2.175955211122831

Epoch: 5| Step: 5
Training loss: 1.3008928298950195
Validation loss: 2.184089501698812

Epoch: 5| Step: 6
Training loss: 1.4147682189941406
Validation loss: 2.239866549770037

Epoch: 5| Step: 7
Training loss: 1.5592858791351318
Validation loss: 2.213111251592636

Epoch: 5| Step: 8
Training loss: 1.5759446620941162
Validation loss: 2.3286598225434623

Epoch: 5| Step: 9
Training loss: 1.3449240922927856
Validation loss: 2.118113492925962

Epoch: 5| Step: 10
Training loss: 1.6984440088272095
Validation loss: 2.1698587934176126

Epoch: 5| Step: 11
Training loss: 1.7588597536087036
Validation loss: 2.165942137440046

Epoch: 174| Step: 0
Training loss: 2.0803256034851074
Validation loss: 2.260334074497223

Epoch: 5| Step: 1
Training loss: 1.6310555934906006
Validation loss: 2.093134433031082

Epoch: 5| Step: 2
Training loss: 1.5164940357208252
Validation loss: 2.2997461458047233

Epoch: 5| Step: 3
Training loss: 1.5951437950134277
Validation loss: 2.159524589776993

Epoch: 5| Step: 4
Training loss: 1.5599886178970337
Validation loss: 2.1466982066631317

Epoch: 5| Step: 5
Training loss: 1.414634108543396
Validation loss: 2.2998908360799155

Epoch: 5| Step: 6
Training loss: 1.2894502878189087
Validation loss: 2.1919766068458557

Epoch: 5| Step: 7
Training loss: 1.516943335533142
Validation loss: 2.205627034107844

Epoch: 5| Step: 8
Training loss: 1.4396860599517822
Validation loss: 2.213945825894674

Epoch: 5| Step: 9
Training loss: 1.4982134103775024
Validation loss: 2.190549597144127

Epoch: 5| Step: 10
Training loss: 2.318330764770508
Validation loss: 2.2490978787342706

Epoch: 5| Step: 11
Training loss: 1.7692762613296509
Validation loss: 2.2211258312066398

Epoch: 175| Step: 0
Training loss: 1.5702003240585327
Validation loss: 2.257015109062195

Epoch: 5| Step: 1
Training loss: 1.753251314163208
Validation loss: 2.2452808221181235

Epoch: 5| Step: 2
Training loss: 1.5710570812225342
Validation loss: 2.2260827322800956

Epoch: 5| Step: 3
Training loss: 1.1980046033859253
Validation loss: 2.266038512190183

Epoch: 5| Step: 4
Training loss: 2.2285959720611572
Validation loss: 2.204484408100446

Epoch: 5| Step: 5
Training loss: 1.161668300628662
Validation loss: 2.2012274811665216

Epoch: 5| Step: 6
Training loss: 1.8729280233383179
Validation loss: 2.181874066591263

Epoch: 5| Step: 7
Training loss: 2.141479969024658
Validation loss: 2.2290967802206674

Epoch: 5| Step: 8
Training loss: 1.7139142751693726
Validation loss: 2.194657196601232

Epoch: 5| Step: 9
Training loss: 1.3086638450622559
Validation loss: 2.031814162929853

Epoch: 5| Step: 10
Training loss: 1.5807764530181885
Validation loss: 2.168868839740753

Epoch: 5| Step: 11
Training loss: 2.742563247680664
Validation loss: 2.2048282672961554

Epoch: 176| Step: 0
Training loss: 1.7093799114227295
Validation loss: 2.226540118455887

Epoch: 5| Step: 1
Training loss: 1.2237536907196045
Validation loss: 2.247059464454651

Epoch: 5| Step: 2
Training loss: 1.1940081119537354
Validation loss: 2.1686949729919434

Epoch: 5| Step: 3
Training loss: 1.3666446208953857
Validation loss: 2.187363957365354

Epoch: 5| Step: 4
Training loss: 1.9956095218658447
Validation loss: 2.248694211244583

Epoch: 5| Step: 5
Training loss: 0.9669724702835083
Validation loss: 2.2005345871051154

Epoch: 5| Step: 6
Training loss: 1.6194061040878296
Validation loss: 2.308082381884257

Epoch: 5| Step: 7
Training loss: 1.6829206943511963
Validation loss: 2.2533810436725616

Epoch: 5| Step: 8
Training loss: 1.5517656803131104
Validation loss: 2.2256349523862204

Epoch: 5| Step: 9
Training loss: 2.350848436355591
Validation loss: 2.1646953920523324

Epoch: 5| Step: 10
Training loss: 1.057196855545044
Validation loss: 2.1891882618268332

Epoch: 5| Step: 11
Training loss: 1.9238711595535278
Validation loss: 2.2427537937959037

Epoch: 177| Step: 0
Training loss: 1.7116811275482178
Validation loss: 2.1577488283316293

Epoch: 5| Step: 1
Training loss: 1.458067536354065
Validation loss: 2.2300102214018502

Epoch: 5| Step: 2
Training loss: 1.018615961074829
Validation loss: 2.2433213889598846

Epoch: 5| Step: 3
Training loss: 1.2541288137435913
Validation loss: 2.200172409415245

Epoch: 5| Step: 4
Training loss: 1.7139431238174438
Validation loss: 2.113572453459104

Epoch: 5| Step: 5
Training loss: 1.9933693408966064
Validation loss: 2.2675428291161857

Epoch: 5| Step: 6
Training loss: 1.7111625671386719
Validation loss: 2.3169902165730796

Epoch: 5| Step: 7
Training loss: 1.7458359003067017
Validation loss: 2.2002519915501275

Epoch: 5| Step: 8
Training loss: 1.2209686040878296
Validation loss: 2.2521093487739563

Epoch: 5| Step: 9
Training loss: 1.7055240869522095
Validation loss: 2.1742796997229257

Epoch: 5| Step: 10
Training loss: 1.4966851472854614
Validation loss: 2.149703378478686

Epoch: 5| Step: 11
Training loss: 0.6920039653778076
Validation loss: 2.2623249838749566

Epoch: 178| Step: 0
Training loss: 2.1656713485717773
Validation loss: 2.254418447613716

Epoch: 5| Step: 1
Training loss: 1.780328392982483
Validation loss: 2.339282582203547

Epoch: 5| Step: 2
Training loss: 1.8825724124908447
Validation loss: 2.2878107130527496

Epoch: 5| Step: 3
Training loss: 1.5819084644317627
Validation loss: 2.3110657731691995

Epoch: 5| Step: 4
Training loss: 1.5576560497283936
Validation loss: 2.296673133969307

Epoch: 5| Step: 5
Training loss: 1.3746534585952759
Validation loss: 2.2919543584187827

Epoch: 5| Step: 6
Training loss: 1.4387027025222778
Validation loss: 2.2597745954990387

Epoch: 5| Step: 7
Training loss: 1.3845150470733643
Validation loss: 2.30257914463679

Epoch: 5| Step: 8
Training loss: 1.8039538860321045
Validation loss: 2.25480509797732

Epoch: 5| Step: 9
Training loss: 1.9785106182098389
Validation loss: 2.175668249527613

Epoch: 5| Step: 10
Training loss: 1.5337026119232178
Validation loss: 2.2660902440547943

Epoch: 5| Step: 11
Training loss: 1.2192938327789307
Validation loss: 2.2297109266122184

Epoch: 179| Step: 0
Training loss: 1.646754503250122
Validation loss: 2.1864185482263565

Epoch: 5| Step: 1
Training loss: 1.2237575054168701
Validation loss: 2.2146782279014587

Epoch: 5| Step: 2
Training loss: 1.867661476135254
Validation loss: 2.16292904317379

Epoch: 5| Step: 3
Training loss: 1.4119285345077515
Validation loss: 2.301715205113093

Epoch: 5| Step: 4
Training loss: 1.5143206119537354
Validation loss: 2.257235566775004

Epoch: 5| Step: 5
Training loss: 1.7223888635635376
Validation loss: 2.2868363658587136

Epoch: 5| Step: 6
Training loss: 1.9079357385635376
Validation loss: 2.2433738112449646

Epoch: 5| Step: 7
Training loss: 1.796451210975647
Validation loss: 2.1367580046256385

Epoch: 5| Step: 8
Training loss: 1.576112985610962
Validation loss: 2.2428149630626044

Epoch: 5| Step: 9
Training loss: 1.1530296802520752
Validation loss: 2.147264396150907

Epoch: 5| Step: 10
Training loss: 1.770932912826538
Validation loss: 2.127169519662857

Epoch: 5| Step: 11
Training loss: 1.893601417541504
Validation loss: 2.254079928000768

Epoch: 180| Step: 0
Training loss: 1.4074772596359253
Validation loss: 2.2707825203736625

Epoch: 5| Step: 1
Training loss: 1.5969339609146118
Validation loss: 2.331756035486857

Epoch: 5| Step: 2
Training loss: 1.2223875522613525
Validation loss: 2.268996606270472

Epoch: 5| Step: 3
Training loss: 2.029635429382324
Validation loss: 2.214687685171763

Epoch: 5| Step: 4
Training loss: 1.7303863763809204
Validation loss: 2.1165738105773926

Epoch: 5| Step: 5
Training loss: 1.754018783569336
Validation loss: 2.1733183413743973

Epoch: 5| Step: 6
Training loss: 1.1730265617370605
Validation loss: 2.16925156613191

Epoch: 5| Step: 7
Training loss: 1.9134256839752197
Validation loss: 2.27528977394104

Epoch: 5| Step: 8
Training loss: 1.3641996383666992
Validation loss: 2.232308546702067

Epoch: 5| Step: 9
Training loss: 1.2720482349395752
Validation loss: 2.149521162112554

Epoch: 5| Step: 10
Training loss: 1.8159347772598267
Validation loss: 2.1926050980885825

Epoch: 5| Step: 11
Training loss: 1.1776937246322632
Validation loss: 2.132353271047274

Epoch: 181| Step: 0
Training loss: 1.5113632678985596
Validation loss: 2.28352090716362

Epoch: 5| Step: 1
Training loss: 0.8797200322151184
Validation loss: 2.1594402293364205

Epoch: 5| Step: 2
Training loss: 2.0423083305358887
Validation loss: 2.3065749406814575

Epoch: 5| Step: 3
Training loss: 1.6942325830459595
Validation loss: 2.1635275383790336

Epoch: 5| Step: 4
Training loss: 1.33404541015625
Validation loss: 2.089230388402939

Epoch: 5| Step: 5
Training loss: 1.2569400072097778
Validation loss: 2.221945181488991

Epoch: 5| Step: 6
Training loss: 2.1824216842651367
Validation loss: 2.212512637178103

Epoch: 5| Step: 7
Training loss: 1.7266461849212646
Validation loss: 2.24985342224439

Epoch: 5| Step: 8
Training loss: 1.4632976055145264
Validation loss: 2.2198505202929177

Epoch: 5| Step: 9
Training loss: 1.8143558502197266
Validation loss: 2.140995144844055

Epoch: 5| Step: 10
Training loss: 1.3252137899398804
Validation loss: 2.259158064921697

Epoch: 5| Step: 11
Training loss: 1.0347373485565186
Validation loss: 2.1314624001582465

Epoch: 182| Step: 0
Training loss: 1.4426767826080322
Validation loss: 2.15437380472819

Epoch: 5| Step: 1
Training loss: 1.566727876663208
Validation loss: 2.165937984983126

Epoch: 5| Step: 2
Training loss: 1.117501974105835
Validation loss: 2.174477865298589

Epoch: 5| Step: 3
Training loss: 1.7774559259414673
Validation loss: 2.2827965319156647

Epoch: 5| Step: 4
Training loss: 1.3194328546524048
Validation loss: 2.1823126872380576

Epoch: 5| Step: 5
Training loss: 1.687618613243103
Validation loss: 2.1515206495920816

Epoch: 5| Step: 6
Training loss: 1.6056640148162842
Validation loss: 2.173167953888575

Epoch: 5| Step: 7
Training loss: 1.9080299139022827
Validation loss: 2.2768163730700812

Epoch: 5| Step: 8
Training loss: 1.1910946369171143
Validation loss: 2.167089660962423

Epoch: 5| Step: 9
Training loss: 1.6789095401763916
Validation loss: 2.246439903974533

Epoch: 5| Step: 10
Training loss: 1.674839735031128
Validation loss: 2.1545614997545877

Epoch: 5| Step: 11
Training loss: 0.6561068892478943
Validation loss: 2.1413096884886422

Epoch: 183| Step: 0
Training loss: 1.4689671993255615
Validation loss: 2.107177128394445

Epoch: 5| Step: 1
Training loss: 1.6955280303955078
Validation loss: 2.1934248308340707

Epoch: 5| Step: 2
Training loss: 1.6123504638671875
Validation loss: 2.2302381892999015

Epoch: 5| Step: 3
Training loss: 1.3961939811706543
Validation loss: 2.2081778248151145

Epoch: 5| Step: 4
Training loss: 1.6632589101791382
Validation loss: 2.3156122217575708

Epoch: 5| Step: 5
Training loss: 1.0191943645477295
Validation loss: 2.271057332555453

Epoch: 5| Step: 6
Training loss: 1.6924047470092773
Validation loss: 2.2544951339562735

Epoch: 5| Step: 7
Training loss: 1.3280327320098877
Validation loss: 2.2818512618541718

Epoch: 5| Step: 8
Training loss: 1.4328774213790894
Validation loss: 2.177774359782537

Epoch: 5| Step: 9
Training loss: 1.3901917934417725
Validation loss: 2.2635210156440735

Epoch: 5| Step: 10
Training loss: 2.2087631225585938
Validation loss: 2.272711197535197

Epoch: 5| Step: 11
Training loss: 1.3677371740341187
Validation loss: 2.2705307751893997

Epoch: 184| Step: 0
Training loss: 1.7387651205062866
Validation loss: 2.2715256611506143

Epoch: 5| Step: 1
Training loss: 1.6100505590438843
Validation loss: 2.232129077116648

Epoch: 5| Step: 2
Training loss: 1.9408619403839111
Validation loss: 2.0904156267642975

Epoch: 5| Step: 3
Training loss: 1.8813610076904297
Validation loss: 2.3113990823427835

Epoch: 5| Step: 4
Training loss: 1.267256498336792
Validation loss: 2.3048216501871743

Epoch: 5| Step: 5
Training loss: 1.0233428478240967
Validation loss: 2.229372094074885

Epoch: 5| Step: 6
Training loss: 1.646628737449646
Validation loss: 2.2660814821720123

Epoch: 5| Step: 7
Training loss: 1.4050118923187256
Validation loss: 2.2832302351792655

Epoch: 5| Step: 8
Training loss: 1.5163518190383911
Validation loss: 2.279566243290901

Epoch: 5| Step: 9
Training loss: 1.735742211341858
Validation loss: 2.199015955130259

Epoch: 5| Step: 10
Training loss: 1.567610502243042
Validation loss: 2.2788425236940384

Epoch: 5| Step: 11
Training loss: 2.748744487762451
Validation loss: 2.250838120778402

Epoch: 185| Step: 0
Training loss: 1.77688729763031
Validation loss: 2.188169851899147

Epoch: 5| Step: 1
Training loss: 1.9845558404922485
Validation loss: 2.2165091832478843

Epoch: 5| Step: 2
Training loss: 1.3796027898788452
Validation loss: 2.2937118907769523

Epoch: 5| Step: 3
Training loss: 1.4804073572158813
Validation loss: 2.225140189131101

Epoch: 5| Step: 4
Training loss: 1.2987921237945557
Validation loss: 2.3022813399632773

Epoch: 5| Step: 5
Training loss: 1.9662296772003174
Validation loss: 2.1428276548782983

Epoch: 5| Step: 6
Training loss: 1.5566112995147705
Validation loss: 2.2056427597999573

Epoch: 5| Step: 7
Training loss: 1.3930516242980957
Validation loss: 2.357474227746328

Epoch: 5| Step: 8
Training loss: 1.4292633533477783
Validation loss: 2.302072192231814

Epoch: 5| Step: 9
Training loss: 1.4161431789398193
Validation loss: 2.269396742184957

Epoch: 5| Step: 10
Training loss: 1.4181840419769287
Validation loss: 2.3542313128709793

Epoch: 5| Step: 11
Training loss: 3.670856475830078
Validation loss: 2.3603685100873313

Epoch: 186| Step: 0
Training loss: 2.139220952987671
Validation loss: 2.2753205448389053

Epoch: 5| Step: 1
Training loss: 2.1857805252075195
Validation loss: 2.2593265771865845

Epoch: 5| Step: 2
Training loss: 1.7739951610565186
Validation loss: 2.255071848630905

Epoch: 5| Step: 3
Training loss: 1.1598618030548096
Validation loss: 2.254296431938807

Epoch: 5| Step: 4
Training loss: 1.3902032375335693
Validation loss: 2.205466186006864

Epoch: 5| Step: 5
Training loss: 1.3925256729125977
Validation loss: 2.220976769924164

Epoch: 5| Step: 6
Training loss: 1.8436912298202515
Validation loss: 2.3905435601870217

Epoch: 5| Step: 7
Training loss: 1.407039761543274
Validation loss: 2.325837234656016

Epoch: 5| Step: 8
Training loss: 1.739423394203186
Validation loss: 2.2863609244426093

Epoch: 5| Step: 9
Training loss: 1.7642357349395752
Validation loss: 2.253411134084066

Epoch: 5| Step: 10
Training loss: 1.5893547534942627
Validation loss: 2.1290853867928186

Epoch: 5| Step: 11
Training loss: 1.6659998893737793
Validation loss: 2.255998834967613

Epoch: 187| Step: 0
Training loss: 1.342252492904663
Validation loss: 2.2115677992502847

Epoch: 5| Step: 1
Training loss: 1.785088300704956
Validation loss: 2.223538110653559

Epoch: 5| Step: 2
Training loss: 1.0927937030792236
Validation loss: 2.2345603555440903

Epoch: 5| Step: 3
Training loss: 1.865728735923767
Validation loss: 2.42238786816597

Epoch: 5| Step: 4
Training loss: 1.8116264343261719
Validation loss: 2.411430502931277

Epoch: 5| Step: 5
Training loss: 2.2408957481384277
Validation loss: 2.4020843307177224

Epoch: 5| Step: 6
Training loss: 1.897142767906189
Validation loss: 2.3358091612656913

Epoch: 5| Step: 7
Training loss: 1.3631056547164917
Validation loss: 2.2209766109784446

Epoch: 5| Step: 8
Training loss: 1.0539133548736572
Validation loss: 2.2402078012625375

Epoch: 5| Step: 9
Training loss: 1.8901865482330322
Validation loss: 2.1786087652047477

Epoch: 5| Step: 10
Training loss: 1.9775753021240234
Validation loss: 2.1467429449160895

Epoch: 5| Step: 11
Training loss: 1.5235105752944946
Validation loss: 2.176606426636378

Epoch: 188| Step: 0
Training loss: 1.6755651235580444
Validation loss: 2.2608238557974496

Epoch: 5| Step: 1
Training loss: 1.7317867279052734
Validation loss: 2.257272591193517

Epoch: 5| Step: 2
Training loss: 1.3856031894683838
Validation loss: 2.2166524678468704

Epoch: 5| Step: 3
Training loss: 1.2520382404327393
Validation loss: 2.13082821170489

Epoch: 5| Step: 4
Training loss: 1.5774204730987549
Validation loss: 2.255710239211718

Epoch: 5| Step: 5
Training loss: 1.0784357786178589
Validation loss: 2.2098532617092133

Epoch: 5| Step: 6
Training loss: 1.5501441955566406
Validation loss: 2.2619279275337854

Epoch: 5| Step: 7
Training loss: 2.063725471496582
Validation loss: 2.2455842594305673

Epoch: 5| Step: 8
Training loss: 1.5864508152008057
Validation loss: 2.173225541909536

Epoch: 5| Step: 9
Training loss: 1.4934091567993164
Validation loss: 2.295171062151591

Epoch: 5| Step: 10
Training loss: 1.5743976831436157
Validation loss: 2.2311020493507385

Epoch: 5| Step: 11
Training loss: 2.9929118156433105
Validation loss: 2.181467125813166

Epoch: 189| Step: 0
Training loss: 1.9251571893692017
Validation loss: 2.2105595568815866

Epoch: 5| Step: 1
Training loss: 1.6140735149383545
Validation loss: 2.1382356683413186

Epoch: 5| Step: 2
Training loss: 1.3269120454788208
Validation loss: 2.1901219288508096

Epoch: 5| Step: 3
Training loss: 1.5378360748291016
Validation loss: 2.1965110699335733

Epoch: 5| Step: 4
Training loss: 1.9403365850448608
Validation loss: 2.176106502612432

Epoch: 5| Step: 5
Training loss: 1.6342010498046875
Validation loss: 2.2239706168572106

Epoch: 5| Step: 6
Training loss: 1.0960547924041748
Validation loss: 2.0784687250852585

Epoch: 5| Step: 7
Training loss: 1.0757280588150024
Validation loss: 2.2222917129596076

Epoch: 5| Step: 8
Training loss: 1.6777572631835938
Validation loss: 2.1255985697110495

Epoch: 5| Step: 9
Training loss: 1.5332896709442139
Validation loss: 2.1870528062184653

Epoch: 5| Step: 10
Training loss: 1.4934988021850586
Validation loss: 2.165767361720403

Epoch: 5| Step: 11
Training loss: 2.2546277046203613
Validation loss: 2.2780124694108963

Epoch: 190| Step: 0
Training loss: 1.7555805444717407
Validation loss: 2.2365649143854776

Epoch: 5| Step: 1
Training loss: 1.1214354038238525
Validation loss: 2.2660479644934335

Epoch: 5| Step: 2
Training loss: 1.603064775466919
Validation loss: 2.2005136609077454

Epoch: 5| Step: 3
Training loss: 1.252618670463562
Validation loss: 2.211734523375829

Epoch: 5| Step: 4
Training loss: 1.4624780416488647
Validation loss: 2.118761420249939

Epoch: 5| Step: 5
Training loss: 1.4272282123565674
Validation loss: 2.1889040619134903

Epoch: 5| Step: 6
Training loss: 1.0601717233657837
Validation loss: 2.1733305205901465

Epoch: 5| Step: 7
Training loss: 1.5704230070114136
Validation loss: 2.2018914818763733

Epoch: 5| Step: 8
Training loss: 1.9875342845916748
Validation loss: 2.1612902134656906

Epoch: 5| Step: 9
Training loss: 1.1205050945281982
Validation loss: 2.2127649585405984

Epoch: 5| Step: 10
Training loss: 1.7478454113006592
Validation loss: 2.1954630265633264

Epoch: 5| Step: 11
Training loss: 1.7730449438095093
Validation loss: 2.271902730067571

Epoch: 191| Step: 0
Training loss: 1.9452416896820068
Validation loss: 2.2286523083845773

Epoch: 5| Step: 1
Training loss: 1.2431901693344116
Validation loss: 2.2190402249495187

Epoch: 5| Step: 2
Training loss: 1.1950441598892212
Validation loss: 2.1945474793513617

Epoch: 5| Step: 3
Training loss: 1.6137962341308594
Validation loss: 2.2344693342844644

Epoch: 5| Step: 4
Training loss: 1.3127570152282715
Validation loss: 2.2810793618361154

Epoch: 5| Step: 5
Training loss: 1.857778549194336
Validation loss: 2.152255356311798

Epoch: 5| Step: 6
Training loss: 1.1747575998306274
Validation loss: 2.2440652549266815

Epoch: 5| Step: 7
Training loss: 1.4276458024978638
Validation loss: 2.2728685239950814

Epoch: 5| Step: 8
Training loss: 1.565016269683838
Validation loss: 2.2268226395050683

Epoch: 5| Step: 9
Training loss: 1.492675542831421
Validation loss: 2.303261091311773

Epoch: 5| Step: 10
Training loss: 1.62469482421875
Validation loss: 2.2757275154193244

Epoch: 5| Step: 11
Training loss: 1.6562433242797852
Validation loss: 2.2174658874670663

Epoch: 192| Step: 0
Training loss: 1.691398024559021
Validation loss: 2.3297099173069

Epoch: 5| Step: 1
Training loss: 1.6351972818374634
Validation loss: 2.1852558652559915

Epoch: 5| Step: 2
Training loss: 1.2360780239105225
Validation loss: 2.1497321873903275

Epoch: 5| Step: 3
Training loss: 1.5566452741622925
Validation loss: 2.2224601954221725

Epoch: 5| Step: 4
Training loss: 1.1632053852081299
Validation loss: 2.2480462342500687

Epoch: 5| Step: 5
Training loss: 1.7798326015472412
Validation loss: 2.2665701707204184

Epoch: 5| Step: 6
Training loss: 1.6402498483657837
Validation loss: 2.2222837607065835

Epoch: 5| Step: 7
Training loss: 1.232611894607544
Validation loss: 2.2390362918376923

Epoch: 5| Step: 8
Training loss: 1.1505258083343506
Validation loss: 2.231691837310791

Epoch: 5| Step: 9
Training loss: 1.6409237384796143
Validation loss: 2.4075206518173218

Epoch: 5| Step: 10
Training loss: 1.7162507772445679
Validation loss: 2.262308975060781

Epoch: 5| Step: 11
Training loss: 2.9507946968078613
Validation loss: 2.2782543152570724

Epoch: 193| Step: 0
Training loss: 2.247572183609009
Validation loss: 2.391143411397934

Epoch: 5| Step: 1
Training loss: 1.849032998085022
Validation loss: 2.3054773211479187

Epoch: 5| Step: 2
Training loss: 1.471877098083496
Validation loss: 2.520911604166031

Epoch: 5| Step: 3
Training loss: 1.786413550376892
Validation loss: 2.378230005502701

Epoch: 5| Step: 4
Training loss: 1.805780053138733
Validation loss: 2.2931601901849112

Epoch: 5| Step: 5
Training loss: 1.5043702125549316
Validation loss: 2.257791300614675

Epoch: 5| Step: 6
Training loss: 0.733026385307312
Validation loss: 2.235800822575887

Epoch: 5| Step: 7
Training loss: 1.7751750946044922
Validation loss: 2.2637625684340796

Epoch: 5| Step: 8
Training loss: 1.273147463798523
Validation loss: 2.159122640887896

Epoch: 5| Step: 9
Training loss: 1.811815857887268
Validation loss: 2.176343401273092

Epoch: 5| Step: 10
Training loss: 1.9405406713485718
Validation loss: 2.2499469816684723

Epoch: 5| Step: 11
Training loss: 2.1454734802246094
Validation loss: 2.2737582127253213

Epoch: 194| Step: 0
Training loss: 1.5676058530807495
Validation loss: 2.3039871156215668

Epoch: 5| Step: 1
Training loss: 1.9521840810775757
Validation loss: 2.2387546052535376

Epoch: 5| Step: 2
Training loss: 1.6219236850738525
Validation loss: 2.2156806041797004

Epoch: 5| Step: 3
Training loss: 1.102750539779663
Validation loss: 2.1769889891147614

Epoch: 5| Step: 4
Training loss: 1.4014862775802612
Validation loss: 2.286277840534846

Epoch: 5| Step: 5
Training loss: 1.0737015008926392
Validation loss: 2.23001728951931

Epoch: 5| Step: 6
Training loss: 1.2988789081573486
Validation loss: 2.2047232687473297

Epoch: 5| Step: 7
Training loss: 2.014920234680176
Validation loss: 2.2784440964460373

Epoch: 5| Step: 8
Training loss: 1.659902572631836
Validation loss: 2.2576084534327188

Epoch: 5| Step: 9
Training loss: 1.581109642982483
Validation loss: 2.3562175780534744

Epoch: 5| Step: 10
Training loss: 1.3577795028686523
Validation loss: 2.325310915708542

Epoch: 5| Step: 11
Training loss: 1.0869731903076172
Validation loss: 2.2385252763827643

Epoch: 195| Step: 0
Training loss: 1.1490182876586914
Validation loss: 2.174865206082662

Epoch: 5| Step: 1
Training loss: 1.248290777206421
Validation loss: 2.19315804541111

Epoch: 5| Step: 2
Training loss: 1.5707021951675415
Validation loss: 2.193675066033999

Epoch: 5| Step: 3
Training loss: 1.2321751117706299
Validation loss: 2.188493996858597

Epoch: 5| Step: 4
Training loss: 1.397581696510315
Validation loss: 2.16846493879954

Epoch: 5| Step: 5
Training loss: 1.6540822982788086
Validation loss: 2.226441522439321

Epoch: 5| Step: 6
Training loss: 1.3044298887252808
Validation loss: 2.2544161826372147

Epoch: 5| Step: 7
Training loss: 1.4898533821105957
Validation loss: 2.1856406331062317

Epoch: 5| Step: 8
Training loss: 1.0329320430755615
Validation loss: 2.2287383725245795

Epoch: 5| Step: 9
Training loss: 1.8737752437591553
Validation loss: 2.1968235025803247

Epoch: 5| Step: 10
Training loss: 2.1215157508850098
Validation loss: 2.2664313117663064

Epoch: 5| Step: 11
Training loss: 0.9841177463531494
Validation loss: 2.1850948383410773

Epoch: 196| Step: 0
Training loss: 1.216604471206665
Validation loss: 2.309896618127823

Epoch: 5| Step: 1
Training loss: 1.3868411779403687
Validation loss: 2.3245926797389984

Epoch: 5| Step: 2
Training loss: 1.5638607740402222
Validation loss: 2.3593935867150626

Epoch: 5| Step: 3
Training loss: 2.671673059463501
Validation loss: 2.3396266798178353

Epoch: 5| Step: 4
Training loss: 1.887770414352417
Validation loss: 2.3244090527296066

Epoch: 5| Step: 5
Training loss: 1.388739824295044
Validation loss: 2.262427101532618

Epoch: 5| Step: 6
Training loss: 1.3305323123931885
Validation loss: 2.2365600615739822

Epoch: 5| Step: 7
Training loss: 1.6761270761489868
Validation loss: 2.219827344020208

Epoch: 5| Step: 8
Training loss: 1.8152027130126953
Validation loss: 2.2386821508407593

Epoch: 5| Step: 9
Training loss: 0.9509655237197876
Validation loss: 2.278299634655317

Epoch: 5| Step: 10
Training loss: 1.573585867881775
Validation loss: 2.237315277258555

Epoch: 5| Step: 11
Training loss: 1.194528579711914
Validation loss: 2.259497880935669

Epoch: 197| Step: 0
Training loss: 1.6966415643692017
Validation loss: 2.249314030011495

Epoch: 5| Step: 1
Training loss: 1.730806589126587
Validation loss: 2.1912910689910254

Epoch: 5| Step: 2
Training loss: 1.7197176218032837
Validation loss: 2.234787791967392

Epoch: 5| Step: 3
Training loss: 1.5409654378890991
Validation loss: 2.191271166006724

Epoch: 5| Step: 4
Training loss: 1.1029983758926392
Validation loss: 2.206176112095515

Epoch: 5| Step: 5
Training loss: 1.3247054815292358
Validation loss: 2.2917340298493705

Epoch: 5| Step: 6
Training loss: 1.366706371307373
Validation loss: 2.214194734891256

Epoch: 5| Step: 7
Training loss: 1.314231514930725
Validation loss: 2.2063274880250296

Epoch: 5| Step: 8
Training loss: 1.658361792564392
Validation loss: 2.241066967447599

Epoch: 5| Step: 9
Training loss: 1.6343166828155518
Validation loss: 2.1962570597728095

Epoch: 5| Step: 10
Training loss: 1.134075403213501
Validation loss: 2.225387136141459

Epoch: 5| Step: 11
Training loss: 1.7461549043655396
Validation loss: 2.1436882466077805

Epoch: 198| Step: 0
Training loss: 1.7706305980682373
Validation loss: 2.209670841693878

Epoch: 5| Step: 1
Training loss: 1.1807769536972046
Validation loss: 2.1360781441132226

Epoch: 5| Step: 2
Training loss: 1.291794776916504
Validation loss: 2.2329814533392587

Epoch: 5| Step: 3
Training loss: 1.6265453100204468
Validation loss: 2.218002751469612

Epoch: 5| Step: 4
Training loss: 1.6528164148330688
Validation loss: 2.198755696415901

Epoch: 5| Step: 5
Training loss: 0.7172081470489502
Validation loss: 2.1993907392024994

Epoch: 5| Step: 6
Training loss: 2.1916556358337402
Validation loss: 2.227951983610789

Epoch: 5| Step: 7
Training loss: 1.775303840637207
Validation loss: 2.225059966246287

Epoch: 5| Step: 8
Training loss: 0.8535276651382446
Validation loss: 2.257865071296692

Epoch: 5| Step: 9
Training loss: 1.5634682178497314
Validation loss: 2.222041537364324

Epoch: 5| Step: 10
Training loss: 1.8045963048934937
Validation loss: 2.2561186651388803

Epoch: 5| Step: 11
Training loss: 0.9906812906265259
Validation loss: 2.280681014060974

Epoch: 199| Step: 0
Training loss: 1.56582510471344
Validation loss: 2.1967634359995523

Epoch: 5| Step: 1
Training loss: 1.0266034603118896
Validation loss: 2.1463478257258735

Epoch: 5| Step: 2
Training loss: 1.4318431615829468
Validation loss: 2.2168454627195993

Epoch: 5| Step: 3
Training loss: 1.125725507736206
Validation loss: 2.261892467737198

Epoch: 5| Step: 4
Training loss: 1.5067856311798096
Validation loss: 2.2243836522102356

Epoch: 5| Step: 5
Training loss: 1.1079376935958862
Validation loss: 2.1760001679261527

Epoch: 5| Step: 6
Training loss: 1.5105435848236084
Validation loss: 2.1890047639608383

Epoch: 5| Step: 7
Training loss: 1.4302799701690674
Validation loss: 2.2968386709690094

Epoch: 5| Step: 8
Training loss: 1.0993692874908447
Validation loss: 2.2513003597656884

Epoch: 5| Step: 9
Training loss: 2.318233013153076
Validation loss: 2.1738635897636414

Epoch: 5| Step: 10
Training loss: 1.458766222000122
Validation loss: 2.2227819363276162

Epoch: 5| Step: 11
Training loss: 0.7965059876441956
Validation loss: 2.299292266368866

Epoch: 200| Step: 0
Training loss: 1.4598621129989624
Validation loss: 2.2385951429605484

Epoch: 5| Step: 1
Training loss: 1.0395618677139282
Validation loss: 2.171856085459391

Epoch: 5| Step: 2
Training loss: 1.2374259233474731
Validation loss: 2.2117727597554526

Epoch: 5| Step: 3
Training loss: 1.3841208219528198
Validation loss: 2.2497895658016205

Epoch: 5| Step: 4
Training loss: 1.4275882244110107
Validation loss: 2.1317101468642554

Epoch: 5| Step: 5
Training loss: 1.8669188022613525
Validation loss: 2.2554925133784614

Epoch: 5| Step: 6
Training loss: 1.3861125707626343
Validation loss: 2.2758388221263885

Epoch: 5| Step: 7
Training loss: 2.0750644207000732
Validation loss: 2.2230262458324432

Epoch: 5| Step: 8
Training loss: 1.5327236652374268
Validation loss: 2.2552457600831985

Epoch: 5| Step: 9
Training loss: 1.8794782161712646
Validation loss: 2.3005697280168533

Epoch: 5| Step: 10
Training loss: 1.0574138164520264
Validation loss: 2.2216790666182837

Epoch: 5| Step: 11
Training loss: 1.0919750928878784
Validation loss: 2.1764818876981735

Epoch: 201| Step: 0
Training loss: 1.26437246799469
Validation loss: 2.2187045166889825

Epoch: 5| Step: 1
Training loss: 2.359199047088623
Validation loss: 2.179148276646932

Epoch: 5| Step: 2
Training loss: 1.8717437982559204
Validation loss: 2.1280462791522345

Epoch: 5| Step: 3
Training loss: 1.1038668155670166
Validation loss: 2.1493439624706903

Epoch: 5| Step: 4
Training loss: 1.1520768404006958
Validation loss: 2.194795404871305

Epoch: 5| Step: 5
Training loss: 1.040658712387085
Validation loss: 2.2291609197854996

Epoch: 5| Step: 6
Training loss: 1.831390380859375
Validation loss: 2.195993850628535

Epoch: 5| Step: 7
Training loss: 1.033042550086975
Validation loss: 2.238036493460337

Epoch: 5| Step: 8
Training loss: 1.3763717412948608
Validation loss: 2.229218910137812

Epoch: 5| Step: 9
Training loss: 1.6982320547103882
Validation loss: 2.3335984547932944

Epoch: 5| Step: 10
Training loss: 1.3414254188537598
Validation loss: 2.3922223448753357

Epoch: 5| Step: 11
Training loss: 1.0284204483032227
Validation loss: 2.2857790986696878

Epoch: 202| Step: 0
Training loss: 1.302686333656311
Validation loss: 2.232954278588295

Epoch: 5| Step: 1
Training loss: 1.686171293258667
Validation loss: 2.189334829648336

Epoch: 5| Step: 2
Training loss: 1.482277274131775
Validation loss: 2.224843511978785

Epoch: 5| Step: 3
Training loss: 1.4619858264923096
Validation loss: 2.155638371904691

Epoch: 5| Step: 4
Training loss: 1.4890083074569702
Validation loss: 2.2076533834139505

Epoch: 5| Step: 5
Training loss: 1.529284119606018
Validation loss: 2.1498033305009208

Epoch: 5| Step: 6
Training loss: 1.7975257635116577
Validation loss: 2.1844965666532516

Epoch: 5| Step: 7
Training loss: 1.4351942539215088
Validation loss: 2.227157006661097

Epoch: 5| Step: 8
Training loss: 1.4412038326263428
Validation loss: 2.1553359230359397

Epoch: 5| Step: 9
Training loss: 1.7012560367584229
Validation loss: 2.1851008534431458

Epoch: 5| Step: 10
Training loss: 1.3496185541152954
Validation loss: 2.2036942491928735

Epoch: 5| Step: 11
Training loss: 0.8366539478302002
Validation loss: 2.1393794417381287

Epoch: 203| Step: 0
Training loss: 1.4042021036148071
Validation loss: 2.2393670678138733

Epoch: 5| Step: 1
Training loss: 1.9921791553497314
Validation loss: 2.2907931208610535

Epoch: 5| Step: 2
Training loss: 1.4742317199707031
Validation loss: 2.2245616018772125

Epoch: 5| Step: 3
Training loss: 1.0863336324691772
Validation loss: 2.257892683148384

Epoch: 5| Step: 4
Training loss: 1.3407695293426514
Validation loss: 2.216597547133764

Epoch: 5| Step: 5
Training loss: 1.4960540533065796
Validation loss: 2.2025043268998465

Epoch: 5| Step: 6
Training loss: 1.3033275604248047
Validation loss: 2.2168442706267038

Epoch: 5| Step: 7
Training loss: 1.725080132484436
Validation loss: 2.2540307492017746

Epoch: 5| Step: 8
Training loss: 1.536620020866394
Validation loss: 2.209573283791542

Epoch: 5| Step: 9
Training loss: 1.4733749628067017
Validation loss: 2.195748190085093

Epoch: 5| Step: 10
Training loss: 1.4942233562469482
Validation loss: 2.2731863309939704

Epoch: 5| Step: 11
Training loss: 0.564594566822052
Validation loss: 2.1978789319594703

Epoch: 204| Step: 0
Training loss: 1.700844168663025
Validation loss: 2.2822682708501816

Epoch: 5| Step: 1
Training loss: 1.4036928415298462
Validation loss: 2.179364860057831

Epoch: 5| Step: 2
Training loss: 1.3190807104110718
Validation loss: 2.1652873754501343

Epoch: 5| Step: 3
Training loss: 1.227242112159729
Validation loss: 2.2669834395249686

Epoch: 5| Step: 4
Training loss: 1.5626890659332275
Validation loss: 2.227420538663864

Epoch: 5| Step: 5
Training loss: 1.359629511833191
Validation loss: 2.2000343898932138

Epoch: 5| Step: 6
Training loss: 1.5543217658996582
Validation loss: 2.159060388803482

Epoch: 5| Step: 7
Training loss: 1.5770759582519531
Validation loss: 2.1536552409331002

Epoch: 5| Step: 8
Training loss: 1.6059300899505615
Validation loss: 2.2146133482456207

Epoch: 5| Step: 9
Training loss: 1.1954649686813354
Validation loss: 2.171132509907087

Epoch: 5| Step: 10
Training loss: 1.9171645641326904
Validation loss: 2.285648599267006

Epoch: 5| Step: 11
Training loss: 1.5339937210083008
Validation loss: 2.1877534886201224

Epoch: 205| Step: 0
Training loss: 1.4363703727722168
Validation loss: 2.1380020876725516

Epoch: 5| Step: 1
Training loss: 1.0845615863800049
Validation loss: 2.2556049724419913

Epoch: 5| Step: 2
Training loss: 1.402313232421875
Validation loss: 2.2073655823866525

Epoch: 5| Step: 3
Training loss: 1.6961755752563477
Validation loss: 2.221949130296707

Epoch: 5| Step: 4
Training loss: 1.6280959844589233
Validation loss: 2.217688580354055

Epoch: 5| Step: 5
Training loss: 1.695650339126587
Validation loss: 2.255950669447581

Epoch: 5| Step: 6
Training loss: 1.4904162883758545
Validation loss: 2.150623361269633

Epoch: 5| Step: 7
Training loss: 0.8196452856063843
Validation loss: 2.146987939874331

Epoch: 5| Step: 8
Training loss: 1.6758915185928345
Validation loss: 2.2626868188381195

Epoch: 5| Step: 9
Training loss: 1.2746187448501587
Validation loss: 2.204984058936437

Epoch: 5| Step: 10
Training loss: 1.3733890056610107
Validation loss: 2.2772925794124603

Epoch: 5| Step: 11
Training loss: 0.5798991322517395
Validation loss: 2.2344846427440643

Epoch: 206| Step: 0
Training loss: 1.399319052696228
Validation loss: 2.2765362560749054

Epoch: 5| Step: 1
Training loss: 1.6424347162246704
Validation loss: 2.2472353676954904

Epoch: 5| Step: 2
Training loss: 1.108412504196167
Validation loss: 2.128035227457682

Epoch: 5| Step: 3
Training loss: 1.3549604415893555
Validation loss: 2.1350083301464715

Epoch: 5| Step: 4
Training loss: 1.2122598886489868
Validation loss: 2.1867494881153107

Epoch: 5| Step: 5
Training loss: 0.9120903015136719
Validation loss: 2.2109230856100717

Epoch: 5| Step: 6
Training loss: 1.2732239961624146
Validation loss: 2.166328196724256

Epoch: 5| Step: 7
Training loss: 1.8289295434951782
Validation loss: 2.2698413133621216

Epoch: 5| Step: 8
Training loss: 2.049137592315674
Validation loss: 2.2348041385412216

Epoch: 5| Step: 9
Training loss: 1.5887877941131592
Validation loss: 2.2076727598905563

Epoch: 5| Step: 10
Training loss: 1.7709239721298218
Validation loss: 2.1405587941408157

Epoch: 5| Step: 11
Training loss: 1.0839978456497192
Validation loss: 2.206747899452845

Epoch: 207| Step: 0
Training loss: 1.63413405418396
Validation loss: 2.256128430366516

Epoch: 5| Step: 1
Training loss: 1.1588267087936401
Validation loss: 2.279176726937294

Epoch: 5| Step: 2
Training loss: 1.1929519176483154
Validation loss: 2.23860369126002

Epoch: 5| Step: 3
Training loss: 1.653191328048706
Validation loss: 2.214338014523188

Epoch: 5| Step: 4
Training loss: 1.418944001197815
Validation loss: 2.2589961936076484

Epoch: 5| Step: 5
Training loss: 1.056777000427246
Validation loss: 2.2297493318716683

Epoch: 5| Step: 6
Training loss: 1.4242078065872192
Validation loss: 2.236976280808449

Epoch: 5| Step: 7
Training loss: 1.6594486236572266
Validation loss: 2.1929942617813745

Epoch: 5| Step: 8
Training loss: 1.6489328145980835
Validation loss: 2.2275133629639945

Epoch: 5| Step: 9
Training loss: 0.7472440004348755
Validation loss: 2.3023065278927484

Epoch: 5| Step: 10
Training loss: 1.697264313697815
Validation loss: 2.186952918767929

Epoch: 5| Step: 11
Training loss: 0.49421226978302
Validation loss: 2.2371137539545694

Epoch: 208| Step: 0
Training loss: 1.3350489139556885
Validation loss: 2.2937059849500656

Epoch: 5| Step: 1
Training loss: 1.6347167491912842
Validation loss: 2.2652737200260162

Epoch: 5| Step: 2
Training loss: 1.2080093622207642
Validation loss: 2.22575381398201

Epoch: 5| Step: 3
Training loss: 1.2732930183410645
Validation loss: 2.315394545594851

Epoch: 5| Step: 4
Training loss: 1.5502393245697021
Validation loss: 2.25527186691761

Epoch: 5| Step: 5
Training loss: 1.7006524801254272
Validation loss: 2.1191627234220505

Epoch: 5| Step: 6
Training loss: 1.6550323963165283
Validation loss: 2.261569991707802

Epoch: 5| Step: 7
Training loss: 1.2117093801498413
Validation loss: 2.1860317091147103

Epoch: 5| Step: 8
Training loss: 1.3095464706420898
Validation loss: 2.2514059841632843

Epoch: 5| Step: 9
Training loss: 2.2322893142700195
Validation loss: 2.294971684614817

Epoch: 5| Step: 10
Training loss: 1.2942413091659546
Validation loss: 2.372990667819977

Epoch: 5| Step: 11
Training loss: 1.872197151184082
Validation loss: 2.2506060798962912

Epoch: 209| Step: 0
Training loss: 1.833905577659607
Validation loss: 2.302350382010142

Epoch: 5| Step: 1
Training loss: 1.5328905582427979
Validation loss: 2.1642873138189316

Epoch: 5| Step: 2
Training loss: 1.512054204940796
Validation loss: 2.2100248634815216

Epoch: 5| Step: 3
Training loss: 1.1989572048187256
Validation loss: 2.190762052933375

Epoch: 5| Step: 4
Training loss: 1.5110883712768555
Validation loss: 2.3141286770502725

Epoch: 5| Step: 5
Training loss: 1.475599765777588
Validation loss: 2.277872085571289

Epoch: 5| Step: 6
Training loss: 1.7545974254608154
Validation loss: 2.2443438271681466

Epoch: 5| Step: 7
Training loss: 1.676618218421936
Validation loss: 2.2011175652345023

Epoch: 5| Step: 8
Training loss: 1.3839045763015747
Validation loss: 2.208086589972178

Epoch: 5| Step: 9
Training loss: 1.5441627502441406
Validation loss: 2.130591298143069

Epoch: 5| Step: 10
Training loss: 1.5002301931381226
Validation loss: 2.234375054637591

Epoch: 5| Step: 11
Training loss: 0.8523520231246948
Validation loss: 2.257872134447098

Epoch: 210| Step: 0
Training loss: 1.951825499534607
Validation loss: 2.3033383886019387

Epoch: 5| Step: 1
Training loss: 1.4141536951065063
Validation loss: 2.3693928917249045

Epoch: 5| Step: 2
Training loss: 1.3223426342010498
Validation loss: 2.2555314203103385

Epoch: 5| Step: 3
Training loss: 1.4816105365753174
Validation loss: 2.14661697546641

Epoch: 5| Step: 4
Training loss: 1.3430181741714478
Validation loss: 2.2376254300276437

Epoch: 5| Step: 5
Training loss: 1.6332721710205078
Validation loss: 2.2355614999930062

Epoch: 5| Step: 6
Training loss: 1.0239263772964478
Validation loss: 2.2708427409331002

Epoch: 5| Step: 7
Training loss: 1.4727890491485596
Validation loss: 2.2171544979015985

Epoch: 5| Step: 8
Training loss: 1.3611571788787842
Validation loss: 2.2862892895936966

Epoch: 5| Step: 9
Training loss: 1.9731868505477905
Validation loss: 2.2450312077999115

Epoch: 5| Step: 10
Training loss: 1.1225261688232422
Validation loss: 2.2630205849806466

Epoch: 5| Step: 11
Training loss: 1.442073106765747
Validation loss: 2.149140884478887

Epoch: 211| Step: 0
Training loss: 1.7014827728271484
Validation loss: 2.2229814926783242

Epoch: 5| Step: 1
Training loss: 1.7052122354507446
Validation loss: 2.2194128781557083

Epoch: 5| Step: 2
Training loss: 1.7678115367889404
Validation loss: 2.2159534792105355

Epoch: 5| Step: 3
Training loss: 1.3102933168411255
Validation loss: 2.117918233076731

Epoch: 5| Step: 4
Training loss: 1.3560903072357178
Validation loss: 2.199549376964569

Epoch: 5| Step: 5
Training loss: 1.161367416381836
Validation loss: 2.233008856574694

Epoch: 5| Step: 6
Training loss: 1.1904399394989014
Validation loss: 2.2023799270391464

Epoch: 5| Step: 7
Training loss: 1.2577646970748901
Validation loss: 2.1954809725284576

Epoch: 5| Step: 8
Training loss: 1.119260549545288
Validation loss: 2.2261906067530313

Epoch: 5| Step: 9
Training loss: 0.9880260229110718
Validation loss: 2.270509993036588

Epoch: 5| Step: 10
Training loss: 1.6079578399658203
Validation loss: 2.1741373042265573

Epoch: 5| Step: 11
Training loss: 0.8552616238594055
Validation loss: 2.225493475794792

Epoch: 212| Step: 0
Training loss: 1.930351972579956
Validation loss: 2.1726116140683494

Epoch: 5| Step: 1
Training loss: 1.1563482284545898
Validation loss: 2.27924149731795

Epoch: 5| Step: 2
Training loss: 1.6062450408935547
Validation loss: 2.314833660920461

Epoch: 5| Step: 3
Training loss: 1.5357857942581177
Validation loss: 2.2446846663951874

Epoch: 5| Step: 4
Training loss: 1.3221672773361206
Validation loss: 2.2581008076667786

Epoch: 5| Step: 5
Training loss: 2.193279504776001
Validation loss: 2.218524470925331

Epoch: 5| Step: 6
Training loss: 1.0341167449951172
Validation loss: 2.241451938947042

Epoch: 5| Step: 7
Training loss: 1.245605707168579
Validation loss: 2.2623216112454734

Epoch: 5| Step: 8
Training loss: 1.6994264125823975
Validation loss: 2.267429456114769

Epoch: 5| Step: 9
Training loss: 1.0860693454742432
Validation loss: 2.2807210832834244

Epoch: 5| Step: 10
Training loss: 1.4538549184799194
Validation loss: 2.3220136562983194

Epoch: 5| Step: 11
Training loss: 1.753038763999939
Validation loss: 2.2406056374311447

Epoch: 213| Step: 0
Training loss: 1.2284057140350342
Validation loss: 2.276561056574186

Epoch: 5| Step: 1
Training loss: 1.2523219585418701
Validation loss: 2.185425172249476

Epoch: 5| Step: 2
Training loss: 1.6251401901245117
Validation loss: 2.1899677415688834

Epoch: 5| Step: 3
Training loss: 1.637311577796936
Validation loss: 2.272040362159411

Epoch: 5| Step: 4
Training loss: 1.3823964595794678
Validation loss: 2.231270909309387

Epoch: 5| Step: 5
Training loss: 1.0836683511734009
Validation loss: 2.129213258624077

Epoch: 5| Step: 6
Training loss: 1.3330051898956299
Validation loss: 2.205714841683706

Epoch: 5| Step: 7
Training loss: 1.3286939859390259
Validation loss: 2.152269184589386

Epoch: 5| Step: 8
Training loss: 1.5310688018798828
Validation loss: 2.2741080125172934

Epoch: 5| Step: 9
Training loss: 1.5039169788360596
Validation loss: 2.256201446056366

Epoch: 5| Step: 10
Training loss: 1.185097098350525
Validation loss: 2.215566655000051

Epoch: 5| Step: 11
Training loss: 0.8996314406394958
Validation loss: 2.2498902132113776

Epoch: 214| Step: 0
Training loss: 1.2062723636627197
Validation loss: 2.189765771230062

Epoch: 5| Step: 1
Training loss: 1.1629321575164795
Validation loss: 2.1209312876065574

Epoch: 5| Step: 2
Training loss: 1.4254188537597656
Validation loss: 2.2349650959173837

Epoch: 5| Step: 3
Training loss: 1.5837652683258057
Validation loss: 2.234647830327352

Epoch: 5| Step: 4
Training loss: 0.9842885136604309
Validation loss: 2.1796582440535226

Epoch: 5| Step: 5
Training loss: 1.4814666509628296
Validation loss: 2.25992543498675

Epoch: 5| Step: 6
Training loss: 1.1461280584335327
Validation loss: 2.1904046883185706

Epoch: 5| Step: 7
Training loss: 1.5317130088806152
Validation loss: 2.220004975795746

Epoch: 5| Step: 8
Training loss: 1.9838626384735107
Validation loss: 2.24030968050162

Epoch: 5| Step: 9
Training loss: 1.6770336627960205
Validation loss: 2.2378027141094208

Epoch: 5| Step: 10
Training loss: 1.400898814201355
Validation loss: 2.2476813793182373

Epoch: 5| Step: 11
Training loss: 0.7158010601997375
Validation loss: 2.2258290698130927

Epoch: 215| Step: 0
Training loss: 1.6650102138519287
Validation loss: 2.183146968483925

Epoch: 5| Step: 1
Training loss: 1.8654524087905884
Validation loss: 2.1589633524417877

Epoch: 5| Step: 2
Training loss: 2.1906657218933105
Validation loss: 2.268383890390396

Epoch: 5| Step: 3
Training loss: 1.0167406797409058
Validation loss: 2.1890625854333243

Epoch: 5| Step: 4
Training loss: 1.0289270877838135
Validation loss: 2.264757658044497

Epoch: 5| Step: 5
Training loss: 1.2162964344024658
Validation loss: 2.2195913245280585

Epoch: 5| Step: 6
Training loss: 1.0403074026107788
Validation loss: 2.229403088490168

Epoch: 5| Step: 7
Training loss: 1.087392807006836
Validation loss: 2.168257122238477

Epoch: 5| Step: 8
Training loss: 1.0200445652008057
Validation loss: 2.142715627948443

Epoch: 5| Step: 9
Training loss: 1.5274512767791748
Validation loss: 2.211651956041654

Epoch: 5| Step: 10
Training loss: 1.8859760761260986
Validation loss: 2.2217457741498947

Epoch: 5| Step: 11
Training loss: 0.4273562431335449
Validation loss: 2.173005779584249

Epoch: 216| Step: 0
Training loss: 1.2572333812713623
Validation loss: 2.203252832094828

Epoch: 5| Step: 1
Training loss: 1.1875011920928955
Validation loss: 2.1893482208251953

Epoch: 5| Step: 2
Training loss: 1.491319179534912
Validation loss: 2.197992295026779

Epoch: 5| Step: 3
Training loss: 1.2677547931671143
Validation loss: 2.1937628239393234

Epoch: 5| Step: 4
Training loss: 0.9328279495239258
Validation loss: 2.1189677764972052

Epoch: 5| Step: 5
Training loss: 1.291118860244751
Validation loss: 2.1179650078217187

Epoch: 5| Step: 6
Training loss: 1.53647780418396
Validation loss: 2.1490392833948135

Epoch: 5| Step: 7
Training loss: 1.8352149724960327
Validation loss: 2.2264746775229773

Epoch: 5| Step: 8
Training loss: 1.3669202327728271
Validation loss: 2.270542780558268

Epoch: 5| Step: 9
Training loss: 1.1668591499328613
Validation loss: 2.2543406734863916

Epoch: 5| Step: 10
Training loss: 1.984029769897461
Validation loss: 2.2945488691329956

Epoch: 5| Step: 11
Training loss: 1.608649492263794
Validation loss: 2.2039048224687576

Epoch: 217| Step: 0
Training loss: 1.1166832447052002
Validation loss: 2.201403404275576

Epoch: 5| Step: 1
Training loss: 1.7406864166259766
Validation loss: 2.2379620323578515

Epoch: 5| Step: 2
Training loss: 1.320495367050171
Validation loss: 2.1451396544774375

Epoch: 5| Step: 3
Training loss: 1.797989845275879
Validation loss: 2.215803066889445

Epoch: 5| Step: 4
Training loss: 1.8008060455322266
Validation loss: 2.1280559649070105

Epoch: 5| Step: 5
Training loss: 1.5499837398529053
Validation loss: 2.1599136938651404

Epoch: 5| Step: 6
Training loss: 1.3070108890533447
Validation loss: 2.2195222675800323

Epoch: 5| Step: 7
Training loss: 0.8099163770675659
Validation loss: 2.147933085759481

Epoch: 5| Step: 8
Training loss: 1.6034667491912842
Validation loss: 2.2140773038069406

Epoch: 5| Step: 9
Training loss: 1.2952580451965332
Validation loss: 2.278628041346868

Epoch: 5| Step: 10
Training loss: 1.1036767959594727
Validation loss: 2.275602623820305

Epoch: 5| Step: 11
Training loss: 1.3676602840423584
Validation loss: 2.230025991797447

Epoch: 218| Step: 0
Training loss: 1.2792069911956787
Validation loss: 2.263885736465454

Epoch: 5| Step: 1
Training loss: 1.3158940076828003
Validation loss: 2.1667386293411255

Epoch: 5| Step: 2
Training loss: 1.7191253900527954
Validation loss: 2.2229374994834266

Epoch: 5| Step: 3
Training loss: 1.0891934633255005
Validation loss: 2.2952041625976562

Epoch: 5| Step: 4
Training loss: 0.9842398762702942
Validation loss: 2.1744726399580636

Epoch: 5| Step: 5
Training loss: 1.632775068283081
Validation loss: 2.157342185576757

Epoch: 5| Step: 6
Training loss: 1.4202688932418823
Validation loss: 2.194025829434395

Epoch: 5| Step: 7
Training loss: 1.363438367843628
Validation loss: 2.244877646366755

Epoch: 5| Step: 8
Training loss: 1.1536977291107178
Validation loss: 2.1686290204524994

Epoch: 5| Step: 9
Training loss: 0.9508190155029297
Validation loss: 2.2032393515110016

Epoch: 5| Step: 10
Training loss: 1.9191728830337524
Validation loss: 2.179780344168345

Epoch: 5| Step: 11
Training loss: 0.6189923882484436
Validation loss: 2.1896054595708847

Epoch: 219| Step: 0
Training loss: 1.6904560327529907
Validation loss: 2.1565860559542975

Epoch: 5| Step: 1
Training loss: 1.609339714050293
Validation loss: 2.167862221598625

Epoch: 5| Step: 2
Training loss: 1.450549840927124
Validation loss: 2.3371443152427673

Epoch: 5| Step: 3
Training loss: 1.5975719690322876
Validation loss: 2.2646721601486206

Epoch: 5| Step: 4
Training loss: 1.2794593572616577
Validation loss: 2.299948275089264

Epoch: 5| Step: 5
Training loss: 0.9855432510375977
Validation loss: 2.1930639495452247

Epoch: 5| Step: 6
Training loss: 1.4653024673461914
Validation loss: 2.1536614249149957

Epoch: 5| Step: 7
Training loss: 1.4060800075531006
Validation loss: 2.2792887141307197

Epoch: 5| Step: 8
Training loss: 1.2027957439422607
Validation loss: 2.25942533214887

Epoch: 5| Step: 9
Training loss: 1.4677069187164307
Validation loss: 2.1542926927407584

Epoch: 5| Step: 10
Training loss: 1.1319934129714966
Validation loss: 2.266220365961393

Epoch: 5| Step: 11
Training loss: 0.5542425513267517
Validation loss: 2.1863293449083963

Epoch: 220| Step: 0
Training loss: 0.9200407862663269
Validation loss: 2.1660596132278442

Epoch: 5| Step: 1
Training loss: 1.3750203847885132
Validation loss: 2.231084853410721

Epoch: 5| Step: 2
Training loss: 1.7776683568954468
Validation loss: 2.1727417459090552

Epoch: 5| Step: 3
Training loss: 1.4813268184661865
Validation loss: 2.1450092494487762

Epoch: 5| Step: 4
Training loss: 0.7991731762886047
Validation loss: 2.224821930130323

Epoch: 5| Step: 5
Training loss: 1.6523828506469727
Validation loss: 2.2320422927538552

Epoch: 5| Step: 6
Training loss: 1.2795921564102173
Validation loss: 2.154027506709099

Epoch: 5| Step: 7
Training loss: 1.0253665447235107
Validation loss: 2.150921548406283

Epoch: 5| Step: 8
Training loss: 1.5814313888549805
Validation loss: 2.1506426682074866

Epoch: 5| Step: 9
Training loss: 1.1115608215332031
Validation loss: 2.303709571560224

Epoch: 5| Step: 10
Training loss: 2.043607473373413
Validation loss: 2.319891318678856

Epoch: 5| Step: 11
Training loss: 1.253572702407837
Validation loss: 2.263231873512268

Epoch: 221| Step: 0
Training loss: 1.5897899866104126
Validation loss: 2.202413181463877

Epoch: 5| Step: 1
Training loss: 1.4594786167144775
Validation loss: 2.161516770720482

Epoch: 5| Step: 2
Training loss: 0.9068466424942017
Validation loss: 2.218680282433828

Epoch: 5| Step: 3
Training loss: 1.325539469718933
Validation loss: 2.216915011405945

Epoch: 5| Step: 4
Training loss: 1.1996583938598633
Validation loss: 2.1390927781661353

Epoch: 5| Step: 5
Training loss: 2.0121397972106934
Validation loss: 2.2258324921131134

Epoch: 5| Step: 6
Training loss: 1.778717279434204
Validation loss: 2.270184854666392

Epoch: 5| Step: 7
Training loss: 1.4162310361862183
Validation loss: 2.1954960028330484

Epoch: 5| Step: 8
Training loss: 1.1205942630767822
Validation loss: 2.15780316789945

Epoch: 5| Step: 9
Training loss: 1.3985404968261719
Validation loss: 2.153699820240339

Epoch: 5| Step: 10
Training loss: 1.3091130256652832
Validation loss: 2.1138761838277182

Epoch: 5| Step: 11
Training loss: 1.123655080795288
Validation loss: 2.2292881309986115

Epoch: 222| Step: 0
Training loss: 1.723339319229126
Validation loss: 2.1874427795410156

Epoch: 5| Step: 1
Training loss: 1.4356391429901123
Validation loss: 2.194230298201243

Epoch: 5| Step: 2
Training loss: 1.7661056518554688
Validation loss: 2.2077762534221015

Epoch: 5| Step: 3
Training loss: 1.0762709379196167
Validation loss: 2.199831555287043

Epoch: 5| Step: 4
Training loss: 1.1328489780426025
Validation loss: 2.2561519940694175

Epoch: 5| Step: 5
Training loss: 1.4839410781860352
Validation loss: 2.084050034483274

Epoch: 5| Step: 6
Training loss: 0.6753386855125427
Validation loss: 2.170189782977104

Epoch: 5| Step: 7
Training loss: 1.2516381740570068
Validation loss: 2.235231046875318

Epoch: 5| Step: 8
Training loss: 1.2282432317733765
Validation loss: 2.2326134939988456

Epoch: 5| Step: 9
Training loss: 1.1153361797332764
Validation loss: 2.2006476521492004

Epoch: 5| Step: 10
Training loss: 1.2432781457901
Validation loss: 2.2152765691280365

Epoch: 5| Step: 11
Training loss: 2.260350227355957
Validation loss: 2.301505426565806

Epoch: 223| Step: 0
Training loss: 1.0880005359649658
Validation loss: 2.2465764780839286

Epoch: 5| Step: 1
Training loss: 1.289158821105957
Validation loss: 2.2417350759108863

Epoch: 5| Step: 2
Training loss: 1.0930731296539307
Validation loss: 2.1529279301563897

Epoch: 5| Step: 3
Training loss: 1.463622808456421
Validation loss: 2.218493248025576

Epoch: 5| Step: 4
Training loss: 1.2892355918884277
Validation loss: 2.20229372382164

Epoch: 5| Step: 5
Training loss: 1.0151110887527466
Validation loss: 2.1610898822546005

Epoch: 5| Step: 6
Training loss: 1.1956058740615845
Validation loss: 2.1613927682240806

Epoch: 5| Step: 7
Training loss: 1.5313441753387451
Validation loss: 2.2188990265130997

Epoch: 5| Step: 8
Training loss: 1.8822170495986938
Validation loss: 2.2120865881443024

Epoch: 5| Step: 9
Training loss: 1.422877550125122
Validation loss: 2.1600922445456185

Epoch: 5| Step: 10
Training loss: 1.3122847080230713
Validation loss: 2.2583015064398446

Epoch: 5| Step: 11
Training loss: 2.2270898818969727
Validation loss: 2.1945353150367737

Epoch: 224| Step: 0
Training loss: 1.8989970684051514
Validation loss: 2.20524300634861

Epoch: 5| Step: 1
Training loss: 1.173757791519165
Validation loss: 2.2453198432922363

Epoch: 5| Step: 2
Training loss: 0.8796294331550598
Validation loss: 2.1152312457561493

Epoch: 5| Step: 3
Training loss: 1.404967188835144
Validation loss: 2.2182771464188895

Epoch: 5| Step: 4
Training loss: 1.4545873403549194
Validation loss: 2.282549644509951

Epoch: 5| Step: 5
Training loss: 1.011563777923584
Validation loss: 2.2364576160907745

Epoch: 5| Step: 6
Training loss: 1.3724969625473022
Validation loss: 2.219937120874723

Epoch: 5| Step: 7
Training loss: 1.3301935195922852
Validation loss: 2.2408359150091806

Epoch: 5| Step: 8
Training loss: 1.2187364101409912
Validation loss: 2.2142034769058228

Epoch: 5| Step: 9
Training loss: 1.271274447441101
Validation loss: 2.20694762468338

Epoch: 5| Step: 10
Training loss: 1.2779521942138672
Validation loss: 2.1878904501597085

Epoch: 5| Step: 11
Training loss: 2.041944742202759
Validation loss: 2.2696457654237747

Epoch: 225| Step: 0
Training loss: 2.4438095092773438
Validation loss: 2.2634063909451165

Epoch: 5| Step: 1
Training loss: 1.2642309665679932
Validation loss: 2.257568269968033

Epoch: 5| Step: 2
Training loss: 1.2668708562850952
Validation loss: 2.226029266913732

Epoch: 5| Step: 3
Training loss: 1.5233792066574097
Validation loss: 2.1797131349643073

Epoch: 5| Step: 4
Training loss: 1.0803844928741455
Validation loss: 2.2534639686346054

Epoch: 5| Step: 5
Training loss: 1.8955276012420654
Validation loss: 2.203787470857302

Epoch: 5| Step: 6
Training loss: 1.5085022449493408
Validation loss: 2.2919882784287133

Epoch: 5| Step: 7
Training loss: 1.4025665521621704
Validation loss: 2.1620933264493942

Epoch: 5| Step: 8
Training loss: 0.74705970287323
Validation loss: 2.2357677072286606

Epoch: 5| Step: 9
Training loss: 0.9858830571174622
Validation loss: 2.2018179247776666

Epoch: 5| Step: 10
Training loss: 0.9531604051589966
Validation loss: 2.1796085139115653

Epoch: 5| Step: 11
Training loss: 0.6030391454696655
Validation loss: 2.191705897450447

Epoch: 226| Step: 0
Training loss: 1.6478245258331299
Validation loss: 2.232771928111712

Epoch: 5| Step: 1
Training loss: 1.260311484336853
Validation loss: 2.2941479285558066

Epoch: 5| Step: 2
Training loss: 0.9883409738540649
Validation loss: 2.149066443244616

Epoch: 5| Step: 3
Training loss: 1.646244764328003
Validation loss: 2.164537633458773

Epoch: 5| Step: 4
Training loss: 1.6928167343139648
Validation loss: 2.2567243774731955

Epoch: 5| Step: 5
Training loss: 1.5353825092315674
Validation loss: 2.1618384420871735

Epoch: 5| Step: 6
Training loss: 0.9534035921096802
Validation loss: 2.1937666883071265

Epoch: 5| Step: 7
Training loss: 1.4723089933395386
Validation loss: 2.2135408272345862

Epoch: 5| Step: 8
Training loss: 1.0329267978668213
Validation loss: 2.179140105843544

Epoch: 5| Step: 9
Training loss: 1.2896047830581665
Validation loss: 2.237772136926651

Epoch: 5| Step: 10
Training loss: 1.3785501718521118
Validation loss: 2.212938050429026

Epoch: 5| Step: 11
Training loss: 0.8043884038925171
Validation loss: 2.150704731543859

Epoch: 227| Step: 0
Training loss: 1.4023417234420776
Validation loss: 2.1872344811757407

Epoch: 5| Step: 1
Training loss: 1.2139521837234497
Validation loss: 2.144925465186437

Epoch: 5| Step: 2
Training loss: 1.126077651977539
Validation loss: 2.1245946089426675

Epoch: 5| Step: 3
Training loss: 1.5835063457489014
Validation loss: 2.2226330836613974

Epoch: 5| Step: 4
Training loss: 1.1509546041488647
Validation loss: 2.181540767351786

Epoch: 5| Step: 5
Training loss: 1.6547482013702393
Validation loss: 2.240998089313507

Epoch: 5| Step: 6
Training loss: 1.4834827184677124
Validation loss: 2.194256007671356

Epoch: 5| Step: 7
Training loss: 1.0290099382400513
Validation loss: 2.153010845184326

Epoch: 5| Step: 8
Training loss: 1.2654694318771362
Validation loss: 2.1713622361421585

Epoch: 5| Step: 9
Training loss: 1.2375625371932983
Validation loss: 2.1961355606714883

Epoch: 5| Step: 10
Training loss: 1.350487232208252
Validation loss: 2.1492283741633096

Epoch: 5| Step: 11
Training loss: 0.8406863212585449
Validation loss: 2.209542085727056

Epoch: 228| Step: 0
Training loss: 1.109255313873291
Validation loss: 2.1830756465593972

Epoch: 5| Step: 1
Training loss: 1.4862425327301025
Validation loss: 2.1775442411502204

Epoch: 5| Step: 2
Training loss: 1.3275843858718872
Validation loss: 2.136870672305425

Epoch: 5| Step: 3
Training loss: 1.4261934757232666
Validation loss: 2.1774346778790155

Epoch: 5| Step: 4
Training loss: 1.2099264860153198
Validation loss: 2.069198578596115

Epoch: 5| Step: 5
Training loss: 1.6030981540679932
Validation loss: 2.255023409922918

Epoch: 5| Step: 6
Training loss: 1.0843064785003662
Validation loss: 2.1593158841133118

Epoch: 5| Step: 7
Training loss: 0.6766394376754761
Validation loss: 2.171018441518148

Epoch: 5| Step: 8
Training loss: 1.0127575397491455
Validation loss: 2.153424551089605

Epoch: 5| Step: 9
Training loss: 1.3379907608032227
Validation loss: 2.1530734300613403

Epoch: 5| Step: 10
Training loss: 1.741693139076233
Validation loss: 2.203231299916903

Epoch: 5| Step: 11
Training loss: 1.5491763353347778
Validation loss: 2.1682603855927787

Epoch: 229| Step: 0
Training loss: 1.4616854190826416
Validation loss: 2.2213158011436462

Epoch: 5| Step: 1
Training loss: 1.0480384826660156
Validation loss: 2.1538290729125342

Epoch: 5| Step: 2
Training loss: 1.4646648168563843
Validation loss: 2.2003342608610788

Epoch: 5| Step: 3
Training loss: 1.5020102262496948
Validation loss: 2.131173307696978

Epoch: 5| Step: 4
Training loss: 1.2465589046478271
Validation loss: 2.260326862335205

Epoch: 5| Step: 5
Training loss: 1.1464837789535522
Validation loss: 2.293169950445493

Epoch: 5| Step: 6
Training loss: 0.8951194882392883
Validation loss: 2.196448117494583

Epoch: 5| Step: 7
Training loss: 1.6927299499511719
Validation loss: 2.220581183830897

Epoch: 5| Step: 8
Training loss: 1.38494074344635
Validation loss: 2.1806006530920663

Epoch: 5| Step: 9
Training loss: 0.8337553143501282
Validation loss: 2.1118805756171546

Epoch: 5| Step: 10
Training loss: 1.7023862600326538
Validation loss: 2.250184973080953

Epoch: 5| Step: 11
Training loss: 1.5388574600219727
Validation loss: 2.2278520266215005

Epoch: 230| Step: 0
Training loss: 1.8320363759994507
Validation loss: 2.251140018304189

Epoch: 5| Step: 1
Training loss: 0.999762237071991
Validation loss: 2.2890264689922333

Epoch: 5| Step: 2
Training loss: 0.843358039855957
Validation loss: 2.2025414407253265

Epoch: 5| Step: 3
Training loss: 1.9341245889663696
Validation loss: 2.281838739911715

Epoch: 5| Step: 4
Training loss: 1.952005386352539
Validation loss: 2.159566948811213

Epoch: 5| Step: 5
Training loss: 0.7603689432144165
Validation loss: 2.2437997261683145

Epoch: 5| Step: 6
Training loss: 1.2233058214187622
Validation loss: 2.1918106277783713

Epoch: 5| Step: 7
Training loss: 1.2912061214447021
Validation loss: 2.163471390803655

Epoch: 5| Step: 8
Training loss: 1.3411083221435547
Validation loss: 2.218705728650093

Epoch: 5| Step: 9
Training loss: 1.764348030090332
Validation loss: 2.23914535343647

Epoch: 5| Step: 10
Training loss: 1.3069801330566406
Validation loss: 2.1817490061124167

Epoch: 5| Step: 11
Training loss: 0.8134691715240479
Validation loss: 2.3253679970900216

Epoch: 231| Step: 0
Training loss: 1.8703800439834595
Validation loss: 2.202680135766665

Epoch: 5| Step: 1
Training loss: 1.4213764667510986
Validation loss: 2.229897752404213

Epoch: 5| Step: 2
Training loss: 1.494567632675171
Validation loss: 2.2195112307866416

Epoch: 5| Step: 3
Training loss: 1.1443126201629639
Validation loss: 2.2278826783100762

Epoch: 5| Step: 4
Training loss: 0.730636715888977
Validation loss: 2.210809071858724

Epoch: 5| Step: 5
Training loss: 1.2522900104522705
Validation loss: 2.1527305096387863

Epoch: 5| Step: 6
Training loss: 1.080349326133728
Validation loss: 2.250175898273786

Epoch: 5| Step: 7
Training loss: 1.49788498878479
Validation loss: 2.174565762281418

Epoch: 5| Step: 8
Training loss: 1.015856146812439
Validation loss: 2.1441638618707657

Epoch: 5| Step: 9
Training loss: 1.1740608215332031
Validation loss: 2.1604219724734626

Epoch: 5| Step: 10
Training loss: 1.1952546834945679
Validation loss: 2.192387749751409

Epoch: 5| Step: 11
Training loss: 2.6702237129211426
Validation loss: 2.1916215320428214

Epoch: 232| Step: 0
Training loss: 1.3098517656326294
Validation loss: 2.211008538802465

Epoch: 5| Step: 1
Training loss: 1.048935890197754
Validation loss: 2.209372967481613

Epoch: 5| Step: 2
Training loss: 1.14592444896698
Validation loss: 2.2581069568792977

Epoch: 5| Step: 3
Training loss: 1.4049222469329834
Validation loss: 2.243144616484642

Epoch: 5| Step: 4
Training loss: 1.780156135559082
Validation loss: 2.1844271421432495

Epoch: 5| Step: 5
Training loss: 1.7307326793670654
Validation loss: 2.2469090620676675

Epoch: 5| Step: 6
Training loss: 1.1919748783111572
Validation loss: 2.1865225235621133

Epoch: 5| Step: 7
Training loss: 1.7366422414779663
Validation loss: 2.14345146715641

Epoch: 5| Step: 8
Training loss: 1.1648409366607666
Validation loss: 2.1612322678168616

Epoch: 5| Step: 9
Training loss: 0.7002483606338501
Validation loss: 2.226102203130722

Epoch: 5| Step: 10
Training loss: 1.5927702188491821
Validation loss: 2.2030579497416816

Epoch: 5| Step: 11
Training loss: 1.1255590915679932
Validation loss: 2.2095215171575546

Epoch: 233| Step: 0
Training loss: 1.0296427011489868
Validation loss: 2.1628056367238364

Epoch: 5| Step: 1
Training loss: 1.5250704288482666
Validation loss: 2.156695604324341

Epoch: 5| Step: 2
Training loss: 1.453934907913208
Validation loss: 2.2221204986174903

Epoch: 5| Step: 3
Training loss: 1.7601035833358765
Validation loss: 2.2899848918120065

Epoch: 5| Step: 4
Training loss: 1.4363243579864502
Validation loss: 2.2846429695685706

Epoch: 5| Step: 5
Training loss: 1.6184167861938477
Validation loss: 2.3234394242366156

Epoch: 5| Step: 6
Training loss: 1.8701670169830322
Validation loss: 2.2432883034149804

Epoch: 5| Step: 7
Training loss: 1.0508931875228882
Validation loss: 2.213019828001658

Epoch: 5| Step: 8
Training loss: 1.381049394607544
Validation loss: 2.232763643066088

Epoch: 5| Step: 9
Training loss: 1.290238380432129
Validation loss: 2.2091073294480643

Epoch: 5| Step: 10
Training loss: 1.322507619857788
Validation loss: 2.283824404080709

Epoch: 5| Step: 11
Training loss: 1.7914042472839355
Validation loss: 2.2934871216615043

Epoch: 234| Step: 0
Training loss: 2.167762041091919
Validation loss: 2.1995991418759027

Epoch: 5| Step: 1
Training loss: 1.927959680557251
Validation loss: 2.2347595393657684

Epoch: 5| Step: 2
Training loss: 1.0776188373565674
Validation loss: 2.1234851082166037

Epoch: 5| Step: 3
Training loss: 1.2888565063476562
Validation loss: 2.144407590230306

Epoch: 5| Step: 4
Training loss: 1.432287335395813
Validation loss: 2.140003984173139

Epoch: 5| Step: 5
Training loss: 1.2816178798675537
Validation loss: 2.266548921664556

Epoch: 5| Step: 6
Training loss: 1.372509241104126
Validation loss: 2.188683087627093

Epoch: 5| Step: 7
Training loss: 1.1594080924987793
Validation loss: 2.2080138623714447

Epoch: 5| Step: 8
Training loss: 1.3531914949417114
Validation loss: 2.2188766101996102

Epoch: 5| Step: 9
Training loss: 1.5224181413650513
Validation loss: 2.19470843176047

Epoch: 5| Step: 10
Training loss: 1.1006295680999756
Validation loss: 2.16249543428421

Epoch: 5| Step: 11
Training loss: 0.5044159889221191
Validation loss: 2.1359725495179496

Epoch: 235| Step: 0
Training loss: 0.5510739088058472
Validation loss: 2.1864313582579293

Epoch: 5| Step: 1
Training loss: 1.0904018878936768
Validation loss: 2.220713476339976

Epoch: 5| Step: 2
Training loss: 1.8035284280776978
Validation loss: 2.219241887331009

Epoch: 5| Step: 3
Training loss: 1.1375420093536377
Validation loss: 2.3059437225262323

Epoch: 5| Step: 4
Training loss: 1.373656153678894
Validation loss: 2.2789985040823617

Epoch: 5| Step: 5
Training loss: 0.9785435795783997
Validation loss: 2.2072889705499015

Epoch: 5| Step: 6
Training loss: 1.6056773662567139
Validation loss: 2.1800777465105057

Epoch: 5| Step: 7
Training loss: 1.3436263799667358
Validation loss: 2.154770791530609

Epoch: 5| Step: 8
Training loss: 1.249194860458374
Validation loss: 2.234290584921837

Epoch: 5| Step: 9
Training loss: 1.670953392982483
Validation loss: 2.277476812402407

Epoch: 5| Step: 10
Training loss: 1.3665012121200562
Validation loss: 2.1875564952691398

Epoch: 5| Step: 11
Training loss: 3.2223429679870605
Validation loss: 2.210358997186025

Epoch: 236| Step: 0
Training loss: 1.4561084508895874
Validation loss: 2.254630466302236

Epoch: 5| Step: 1
Training loss: 1.09591805934906
Validation loss: 2.234230717023214

Epoch: 5| Step: 2
Training loss: 1.402854323387146
Validation loss: 2.1068298270305

Epoch: 5| Step: 3
Training loss: 1.360704779624939
Validation loss: 2.217836022377014

Epoch: 5| Step: 4
Training loss: 1.3342483043670654
Validation loss: 2.1526236732800803

Epoch: 5| Step: 5
Training loss: 0.8178043365478516
Validation loss: 2.2608641187349954

Epoch: 5| Step: 6
Training loss: 1.6484239101409912
Validation loss: 2.1925116082032523

Epoch: 5| Step: 7
Training loss: 1.4612343311309814
Validation loss: 2.1548947195212045

Epoch: 5| Step: 8
Training loss: 1.8105170726776123
Validation loss: 2.1397672841946282

Epoch: 5| Step: 9
Training loss: 1.179558515548706
Validation loss: 2.167791485786438

Epoch: 5| Step: 10
Training loss: 0.9959406852722168
Validation loss: 2.141512076059977

Epoch: 5| Step: 11
Training loss: 1.4311631917953491
Validation loss: 2.191952089468638

Epoch: 237| Step: 0
Training loss: 0.9283396601676941
Validation loss: 2.168146034081777

Epoch: 5| Step: 1
Training loss: 1.789658784866333
Validation loss: 2.1852512508630753

Epoch: 5| Step: 2
Training loss: 1.6652532815933228
Validation loss: 2.1582885136206946

Epoch: 5| Step: 3
Training loss: 1.7504123449325562
Validation loss: 2.169204354286194

Epoch: 5| Step: 4
Training loss: 0.7833903431892395
Validation loss: 2.1702153980731964

Epoch: 5| Step: 5
Training loss: 0.8337607383728027
Validation loss: 2.1112325936555862

Epoch: 5| Step: 6
Training loss: 1.4707762002944946
Validation loss: 2.146629477540652

Epoch: 5| Step: 7
Training loss: 0.8133234977722168
Validation loss: 2.194887558619181

Epoch: 5| Step: 8
Training loss: 0.9653497934341431
Validation loss: 2.253404493133227

Epoch: 5| Step: 9
Training loss: 1.5251100063323975
Validation loss: 2.118280107776324

Epoch: 5| Step: 10
Training loss: 1.0143612623214722
Validation loss: 2.2388201554616294

Epoch: 5| Step: 11
Training loss: 2.4732260704040527
Validation loss: 2.1304842034975686

Epoch: 238| Step: 0
Training loss: 2.265300750732422
Validation loss: 2.160599668820699

Epoch: 5| Step: 1
Training loss: 1.7715791463851929
Validation loss: 2.1853841046492257

Epoch: 5| Step: 2
Training loss: 1.4238979816436768
Validation loss: 2.186369131008784

Epoch: 5| Step: 3
Training loss: 0.814680278301239
Validation loss: 2.075701763232549

Epoch: 5| Step: 4
Training loss: 1.0270178318023682
Validation loss: 2.1846367766459784

Epoch: 5| Step: 5
Training loss: 1.025642991065979
Validation loss: 2.171781837940216

Epoch: 5| Step: 6
Training loss: 0.9604889154434204
Validation loss: 2.0574606508016586

Epoch: 5| Step: 7
Training loss: 1.223003625869751
Validation loss: 2.1649151345094046

Epoch: 5| Step: 8
Training loss: 0.813754677772522
Validation loss: 2.175470824042956

Epoch: 5| Step: 9
Training loss: 1.03291916847229
Validation loss: 2.1429063032070794

Epoch: 5| Step: 10
Training loss: 1.0440846681594849
Validation loss: 2.153194715579351

Epoch: 5| Step: 11
Training loss: 2.2791390419006348
Validation loss: 2.1829351087411246

Epoch: 239| Step: 0
Training loss: 1.5147777795791626
Validation loss: 2.19301138818264

Epoch: 5| Step: 1
Training loss: 0.9678618311882019
Validation loss: 2.2513151516517005

Epoch: 5| Step: 2
Training loss: 1.7899078130722046
Validation loss: 2.146618823210398

Epoch: 5| Step: 3
Training loss: 1.2669411897659302
Validation loss: 2.1911043375730515

Epoch: 5| Step: 4
Training loss: 1.3465614318847656
Validation loss: 2.2181944300731025

Epoch: 5| Step: 5
Training loss: 1.217462420463562
Validation loss: 2.2603524327278137

Epoch: 5| Step: 6
Training loss: 0.8244062662124634
Validation loss: 2.121583769718806

Epoch: 5| Step: 7
Training loss: 1.394898772239685
Validation loss: 2.102458486954371

Epoch: 5| Step: 8
Training loss: 1.2100932598114014
Validation loss: 2.2417944570382438

Epoch: 5| Step: 9
Training loss: 1.719577431678772
Validation loss: 2.1829948077599206

Epoch: 5| Step: 10
Training loss: 1.6005122661590576
Validation loss: 2.2173957029978433

Epoch: 5| Step: 11
Training loss: 1.1106301546096802
Validation loss: 2.2619875570138297

Epoch: 240| Step: 0
Training loss: 1.3193142414093018
Validation loss: 2.1468005726734796

Epoch: 5| Step: 1
Training loss: 1.3657609224319458
Validation loss: 2.111410235365232

Epoch: 5| Step: 2
Training loss: 0.7619792222976685
Validation loss: 2.1346840610106788

Epoch: 5| Step: 3
Training loss: 1.3594967126846313
Validation loss: 2.1771831115086875

Epoch: 5| Step: 4
Training loss: 1.1859447956085205
Validation loss: 2.2320709725221

Epoch: 5| Step: 5
Training loss: 1.1959507465362549
Validation loss: 2.1810931066672006

Epoch: 5| Step: 6
Training loss: 1.272209882736206
Validation loss: 2.203896716237068

Epoch: 5| Step: 7
Training loss: 1.113754153251648
Validation loss: 2.1575485865275064

Epoch: 5| Step: 8
Training loss: 1.384339451789856
Validation loss: 2.097535719474157

Epoch: 5| Step: 9
Training loss: 1.5987952947616577
Validation loss: 2.152444710334142

Epoch: 5| Step: 10
Training loss: 1.0182745456695557
Validation loss: 2.1785407960414886

Epoch: 5| Step: 11
Training loss: 2.646634340286255
Validation loss: 2.278448740641276

Epoch: 241| Step: 0
Training loss: 1.2991957664489746
Validation loss: 2.1544217417637506

Epoch: 5| Step: 1
Training loss: 1.6004365682601929
Validation loss: 2.15294241408507

Epoch: 5| Step: 2
Training loss: 1.1491050720214844
Validation loss: 2.1962792575359344

Epoch: 5| Step: 3
Training loss: 0.8717449903488159
Validation loss: 2.2029676834742227

Epoch: 5| Step: 4
Training loss: 1.2721951007843018
Validation loss: 2.1566534340381622

Epoch: 5| Step: 5
Training loss: 1.2102456092834473
Validation loss: 2.0903245011965432

Epoch: 5| Step: 6
Training loss: 1.1765416860580444
Validation loss: 2.1654637455940247

Epoch: 5| Step: 7
Training loss: 1.3200188875198364
Validation loss: 2.1446730494499207

Epoch: 5| Step: 8
Training loss: 1.4059120416641235
Validation loss: 2.201284115513166

Epoch: 5| Step: 9
Training loss: 1.3056526184082031
Validation loss: 2.2049489319324493

Epoch: 5| Step: 10
Training loss: 1.2323545217514038
Validation loss: 2.2120496282974877

Epoch: 5| Step: 11
Training loss: 2.1957201957702637
Validation loss: 2.204053064187368

Epoch: 242| Step: 0
Training loss: 1.672342300415039
Validation loss: 2.224942614634832

Epoch: 5| Step: 1
Training loss: 0.9152324795722961
Validation loss: 2.185375581185023

Epoch: 5| Step: 2
Training loss: 1.3953993320465088
Validation loss: 2.121627484758695

Epoch: 5| Step: 3
Training loss: 1.6830635070800781
Validation loss: 2.1351800709962845

Epoch: 5| Step: 4
Training loss: 1.3190929889678955
Validation loss: 2.211189717054367

Epoch: 5| Step: 5
Training loss: 1.5639617443084717
Validation loss: 2.228434830904007

Epoch: 5| Step: 6
Training loss: 1.0490370988845825
Validation loss: 2.3096144000689187

Epoch: 5| Step: 7
Training loss: 1.5549556016921997
Validation loss: 2.1913012017806373

Epoch: 5| Step: 8
Training loss: 1.2768217325210571
Validation loss: 2.078023428718249

Epoch: 5| Step: 9
Training loss: 0.8229855298995972
Validation loss: 2.1874523162841797

Epoch: 5| Step: 10
Training loss: 1.0013612508773804
Validation loss: 2.1732637137174606

Epoch: 5| Step: 11
Training loss: 0.6936793923377991
Validation loss: 2.1771369824806848

Epoch: 243| Step: 0
Training loss: 1.253623604774475
Validation loss: 2.140834793448448

Epoch: 5| Step: 1
Training loss: 1.242409348487854
Validation loss: 2.126196026802063

Epoch: 5| Step: 2
Training loss: 1.4600813388824463
Validation loss: 2.2255645294984183

Epoch: 5| Step: 3
Training loss: 0.6964021921157837
Validation loss: 2.180955414970716

Epoch: 5| Step: 4
Training loss: 1.117868185043335
Validation loss: 2.204115321238836

Epoch: 5| Step: 5
Training loss: 0.7162830233573914
Validation loss: 2.12023131052653

Epoch: 5| Step: 6
Training loss: 1.1738651990890503
Validation loss: 2.1521912018458047

Epoch: 5| Step: 7
Training loss: 1.3865878582000732
Validation loss: 2.1783885955810547

Epoch: 5| Step: 8
Training loss: 1.310420036315918
Validation loss: 2.1617256700992584

Epoch: 5| Step: 9
Training loss: 1.3396170139312744
Validation loss: 2.2418320228656134

Epoch: 5| Step: 10
Training loss: 1.8945872783660889
Validation loss: 2.2237075169881186

Epoch: 5| Step: 11
Training loss: 1.106713056564331
Validation loss: 2.2144355177879333

Epoch: 244| Step: 0
Training loss: 0.9015985727310181
Validation loss: 2.1268278459707894

Epoch: 5| Step: 1
Training loss: 1.766005516052246
Validation loss: 2.1695015082756677

Epoch: 5| Step: 2
Training loss: 1.1638035774230957
Validation loss: 2.103238135576248

Epoch: 5| Step: 3
Training loss: 1.2843408584594727
Validation loss: 2.2538001239299774

Epoch: 5| Step: 4
Training loss: 1.8123691082000732
Validation loss: 2.270986263950666

Epoch: 5| Step: 5
Training loss: 1.2757151126861572
Validation loss: 2.194794774055481

Epoch: 5| Step: 6
Training loss: 1.513296127319336
Validation loss: 2.1327822456757226

Epoch: 5| Step: 7
Training loss: 0.9090132713317871
Validation loss: 2.201385627190272

Epoch: 5| Step: 8
Training loss: 0.6771446466445923
Validation loss: 2.095983440677325

Epoch: 5| Step: 9
Training loss: 1.3723982572555542
Validation loss: 2.120360886057218

Epoch: 5| Step: 10
Training loss: 1.447569489479065
Validation loss: 2.169046640396118

Epoch: 5| Step: 11
Training loss: 0.7967585921287537
Validation loss: 2.192045365770658

Epoch: 245| Step: 0
Training loss: 1.7801368236541748
Validation loss: 2.1423492431640625

Epoch: 5| Step: 1
Training loss: 0.8267663717269897
Validation loss: 2.1962238550186157

Epoch: 5| Step: 2
Training loss: 1.1446168422698975
Validation loss: 2.1971615900595984

Epoch: 5| Step: 3
Training loss: 1.0823360681533813
Validation loss: 2.2264369229475656

Epoch: 5| Step: 4
Training loss: 0.8873996734619141
Validation loss: 2.2053155303001404

Epoch: 5| Step: 5
Training loss: 1.850541114807129
Validation loss: 2.23274893561999

Epoch: 5| Step: 6
Training loss: 1.4106519222259521
Validation loss: 2.190238763888677

Epoch: 5| Step: 7
Training loss: 1.453878402709961
Validation loss: 2.097825194398562

Epoch: 5| Step: 8
Training loss: 0.9530013799667358
Validation loss: 2.112137943506241

Epoch: 5| Step: 9
Training loss: 1.1210399866104126
Validation loss: 2.1505309840043387

Epoch: 5| Step: 10
Training loss: 1.481456995010376
Validation loss: 2.111333171526591

Epoch: 5| Step: 11
Training loss: 1.7381700277328491
Validation loss: 2.108078896999359

Epoch: 246| Step: 0
Training loss: 0.8840610384941101
Validation loss: 2.215925465027491

Epoch: 5| Step: 1
Training loss: 1.3882440328598022
Validation loss: 2.1640346944332123

Epoch: 5| Step: 2
Training loss: 0.9976257085800171
Validation loss: 2.149743919571241

Epoch: 5| Step: 3
Training loss: 0.9660362005233765
Validation loss: 2.219239890575409

Epoch: 5| Step: 4
Training loss: 1.4823534488677979
Validation loss: 2.20938178896904

Epoch: 5| Step: 5
Training loss: 1.4829075336456299
Validation loss: 2.128404716650645

Epoch: 5| Step: 6
Training loss: 1.385416865348816
Validation loss: 2.1774796495834985

Epoch: 5| Step: 7
Training loss: 1.1648300886154175
Validation loss: 2.1007293413082757

Epoch: 5| Step: 8
Training loss: 1.33237886428833
Validation loss: 2.173959329724312

Epoch: 5| Step: 9
Training loss: 0.9912846684455872
Validation loss: 2.161162108182907

Epoch: 5| Step: 10
Training loss: 1.3110883235931396
Validation loss: 2.162163202961286

Epoch: 5| Step: 11
Training loss: 1.32759428024292
Validation loss: 2.156027168035507

Epoch: 247| Step: 0
Training loss: 0.9768339991569519
Validation loss: 2.1546609153350196

Epoch: 5| Step: 1
Training loss: 1.5149751901626587
Validation loss: 2.1376866350571313

Epoch: 5| Step: 2
Training loss: 1.1861363649368286
Validation loss: 2.0715557436148324

Epoch: 5| Step: 3
Training loss: 1.1081739664077759
Validation loss: 2.1161235123872757

Epoch: 5| Step: 4
Training loss: 0.8144685626029968
Validation loss: 2.170853147904078

Epoch: 5| Step: 5
Training loss: 1.191946029663086
Validation loss: 2.154761031270027

Epoch: 5| Step: 6
Training loss: 1.7346292734146118
Validation loss: 2.248903289437294

Epoch: 5| Step: 7
Training loss: 1.5020897388458252
Validation loss: 2.2244940449794135

Epoch: 5| Step: 8
Training loss: 1.1994884014129639
Validation loss: 2.080573861797651

Epoch: 5| Step: 9
Training loss: 1.568561315536499
Validation loss: 2.2385295778512955

Epoch: 5| Step: 10
Training loss: 1.1969702243804932
Validation loss: 2.1202608992656073

Epoch: 5| Step: 11
Training loss: 1.1852893829345703
Validation loss: 2.1810269256432853

Epoch: 248| Step: 0
Training loss: 1.2350540161132812
Validation loss: 2.130170931418737

Epoch: 5| Step: 1
Training loss: 1.1914101839065552
Validation loss: 2.1468539436658225

Epoch: 5| Step: 2
Training loss: 1.0358943939208984
Validation loss: 2.186131482323011

Epoch: 5| Step: 3
Training loss: 0.6249464750289917
Validation loss: 2.1872103214263916

Epoch: 5| Step: 4
Training loss: 1.0808517932891846
Validation loss: 2.115462303161621

Epoch: 5| Step: 5
Training loss: 1.0964277982711792
Validation loss: 2.105508029460907

Epoch: 5| Step: 6
Training loss: 1.821263313293457
Validation loss: 2.1809918185075126

Epoch: 5| Step: 7
Training loss: 1.1754738092422485
Validation loss: 2.1745651264985404

Epoch: 5| Step: 8
Training loss: 1.5160975456237793
Validation loss: 2.1290837675333023

Epoch: 5| Step: 9
Training loss: 1.497074007987976
Validation loss: 2.1495745529731116

Epoch: 5| Step: 10
Training loss: 1.287139892578125
Validation loss: 2.189440757036209

Epoch: 5| Step: 11
Training loss: 0.30776870250701904
Validation loss: 2.1294981986284256

Epoch: 249| Step: 0
Training loss: 0.7945234179496765
Validation loss: 2.1600672701994577

Epoch: 5| Step: 1
Training loss: 1.5393275022506714
Validation loss: 2.2911921640237174

Epoch: 5| Step: 2
Training loss: 1.1983768939971924
Validation loss: 2.2042517264684043

Epoch: 5| Step: 3
Training loss: 1.672231912612915
Validation loss: 2.178550044695536

Epoch: 5| Step: 4
Training loss: 0.9377585649490356
Validation loss: 2.1896154284477234

Epoch: 5| Step: 5
Training loss: 1.200243592262268
Validation loss: 2.1540110061566033

Epoch: 5| Step: 6
Training loss: 1.1844346523284912
Validation loss: 2.2012679179509482

Epoch: 5| Step: 7
Training loss: 1.1224983930587769
Validation loss: 2.1714627693096795

Epoch: 5| Step: 8
Training loss: 1.4019126892089844
Validation loss: 2.2717109819253287

Epoch: 5| Step: 9
Training loss: 1.354445457458496
Validation loss: 2.157334625720978

Epoch: 5| Step: 10
Training loss: 1.676973581314087
Validation loss: 2.1561966985464096

Epoch: 5| Step: 11
Training loss: 0.7319908738136292
Validation loss: 2.138378212849299

Epoch: 250| Step: 0
Training loss: 1.4956772327423096
Validation loss: 2.158574422200521

Epoch: 5| Step: 1
Training loss: 0.9907066226005554
Validation loss: 2.209000592430433

Epoch: 5| Step: 2
Training loss: 1.476510763168335
Validation loss: 2.1607648730278015

Epoch: 5| Step: 3
Training loss: 1.5054079294204712
Validation loss: 2.271571864684423

Epoch: 5| Step: 4
Training loss: 1.4603767395019531
Validation loss: 2.203655779361725

Epoch: 5| Step: 5
Training loss: 1.7564843893051147
Validation loss: 2.2718701362609863

Epoch: 5| Step: 6
Training loss: 1.1558001041412354
Validation loss: 2.2829566299915314

Epoch: 5| Step: 7
Training loss: 0.9734542965888977
Validation loss: 2.1891255577405295

Epoch: 5| Step: 8
Training loss: 1.216840386390686
Validation loss: 2.1112764328718185

Epoch: 5| Step: 9
Training loss: 1.4203639030456543
Validation loss: 2.1763060241937637

Epoch: 5| Step: 10
Training loss: 0.8523796200752258
Validation loss: 2.194211388627688

Epoch: 5| Step: 11
Training loss: 0.8134826421737671
Validation loss: 2.116375148296356

Epoch: 251| Step: 0
Training loss: 1.265112042427063
Validation loss: 2.1234806378682456

Epoch: 5| Step: 1
Training loss: 1.0019549131393433
Validation loss: 2.2351272106170654

Epoch: 5| Step: 2
Training loss: 1.255464792251587
Validation loss: 2.1534726470708847

Epoch: 5| Step: 3
Training loss: 1.0963233709335327
Validation loss: 2.1167920430501304

Epoch: 5| Step: 4
Training loss: 1.5247728824615479
Validation loss: 2.1656741201877594

Epoch: 5| Step: 5
Training loss: 0.9240714907646179
Validation loss: 2.107397347688675

Epoch: 5| Step: 6
Training loss: 1.3220206499099731
Validation loss: 2.1309469044208527

Epoch: 5| Step: 7
Training loss: 1.2496628761291504
Validation loss: 2.191621869802475

Epoch: 5| Step: 8
Training loss: 1.4697716236114502
Validation loss: 2.1847824305295944

Epoch: 5| Step: 9
Training loss: 1.1909606456756592
Validation loss: 2.207905203104019

Epoch: 5| Step: 10
Training loss: 1.7541437149047852
Validation loss: 2.177586391568184

Epoch: 5| Step: 11
Training loss: 1.1573302745819092
Validation loss: 2.119702070951462

Epoch: 252| Step: 0
Training loss: 1.179982304573059
Validation loss: 2.1775026669104895

Epoch: 5| Step: 1
Training loss: 1.8994967937469482
Validation loss: 2.2054677506287894

Epoch: 5| Step: 2
Training loss: 1.6047182083129883
Validation loss: 2.1093448251485825

Epoch: 5| Step: 3
Training loss: 1.169960379600525
Validation loss: 2.1874778668085733

Epoch: 5| Step: 4
Training loss: 1.5642950534820557
Validation loss: 2.1785742541154227

Epoch: 5| Step: 5
Training loss: 1.1753239631652832
Validation loss: 2.203843096892039

Epoch: 5| Step: 6
Training loss: 0.7737216949462891
Validation loss: 2.152330865462621

Epoch: 5| Step: 7
Training loss: 1.3398258686065674
Validation loss: 2.1575096050898233

Epoch: 5| Step: 8
Training loss: 0.9142999649047852
Validation loss: 2.1735580960909524

Epoch: 5| Step: 9
Training loss: 1.1908601522445679
Validation loss: 2.187208036581675

Epoch: 5| Step: 10
Training loss: 0.9901361465454102
Validation loss: 2.17638653020064

Epoch: 5| Step: 11
Training loss: 1.532348871231079
Validation loss: 2.1380104223887124

Epoch: 253| Step: 0
Training loss: 1.39588463306427
Validation loss: 2.177812854448954

Epoch: 5| Step: 1
Training loss: 1.7049407958984375
Validation loss: 2.1577462404966354

Epoch: 5| Step: 2
Training loss: 1.414501428604126
Validation loss: 2.1372370620568595

Epoch: 5| Step: 3
Training loss: 1.1274396181106567
Validation loss: 2.1573010633389154

Epoch: 5| Step: 4
Training loss: 1.4350483417510986
Validation loss: 2.017765993873278

Epoch: 5| Step: 5
Training loss: 0.5388792157173157
Validation loss: 2.187742273012797

Epoch: 5| Step: 6
Training loss: 1.2145886421203613
Validation loss: 2.141484429438909

Epoch: 5| Step: 7
Training loss: 0.9091639518737793
Validation loss: 2.2690074145793915

Epoch: 5| Step: 8
Training loss: 0.6770972609519958
Validation loss: 2.21970501045386

Epoch: 5| Step: 9
Training loss: 1.6660900115966797
Validation loss: 2.0754986852407455

Epoch: 5| Step: 10
Training loss: 1.3886797428131104
Validation loss: 2.2136084040006003

Epoch: 5| Step: 11
Training loss: 1.0530744791030884
Validation loss: 2.189242353041967

Epoch: 254| Step: 0
Training loss: 0.8294447660446167
Validation loss: 2.1575248539447784

Epoch: 5| Step: 1
Training loss: 1.1959041357040405
Validation loss: 2.132108122110367

Epoch: 5| Step: 2
Training loss: 1.3962633609771729
Validation loss: 2.175084203481674

Epoch: 5| Step: 3
Training loss: 1.1665947437286377
Validation loss: 2.119802708427111

Epoch: 5| Step: 4
Training loss: 1.160217523574829
Validation loss: 2.04073233405749

Epoch: 5| Step: 5
Training loss: 1.5045608282089233
Validation loss: 2.0227057536443076

Epoch: 5| Step: 6
Training loss: 1.2736190557479858
Validation loss: 2.098968505859375

Epoch: 5| Step: 7
Training loss: 1.3128694295883179
Validation loss: 2.175964837272962

Epoch: 5| Step: 8
Training loss: 1.4632478952407837
Validation loss: 2.058158357938131

Epoch: 5| Step: 9
Training loss: 0.6671528816223145
Validation loss: 2.175886571407318

Epoch: 5| Step: 10
Training loss: 1.591789960861206
Validation loss: 2.213768392801285

Epoch: 5| Step: 11
Training loss: 0.9430707693099976
Validation loss: 2.189492185910543

Epoch: 255| Step: 0
Training loss: 0.7461434602737427
Validation loss: 2.1242638528347015

Epoch: 5| Step: 1
Training loss: 1.3249938488006592
Validation loss: 2.150607412060102

Epoch: 5| Step: 2
Training loss: 1.0440704822540283
Validation loss: 2.194466774662336

Epoch: 5| Step: 3
Training loss: 1.5179917812347412
Validation loss: 2.1880564788977304

Epoch: 5| Step: 4
Training loss: 1.1350369453430176
Validation loss: 2.1253122886021933

Epoch: 5| Step: 5
Training loss: 1.2227842807769775
Validation loss: 2.083651085694631

Epoch: 5| Step: 6
Training loss: 1.2114135026931763
Validation loss: 2.164252147078514

Epoch: 5| Step: 7
Training loss: 1.1729525327682495
Validation loss: 2.100208650032679

Epoch: 5| Step: 8
Training loss: 1.7112452983856201
Validation loss: 2.1010198841492334

Epoch: 5| Step: 9
Training loss: 1.0915924310684204
Validation loss: 2.1413495391607285

Epoch: 5| Step: 10
Training loss: 1.2742376327514648
Validation loss: 2.180458461244901

Epoch: 5| Step: 11
Training loss: 1.3843369483947754
Validation loss: 2.1153750518957772

Epoch: 256| Step: 0
Training loss: 1.629473328590393
Validation loss: 2.1450971265633902

Epoch: 5| Step: 1
Training loss: 0.8219009637832642
Validation loss: 2.1666207015514374

Epoch: 5| Step: 2
Training loss: 1.8178306818008423
Validation loss: 2.205289045969645

Epoch: 5| Step: 3
Training loss: 0.9426217079162598
Validation loss: 2.127816836039225

Epoch: 5| Step: 4
Training loss: 0.8426234126091003
Validation loss: 2.1215959886709848

Epoch: 5| Step: 5
Training loss: 0.8611215353012085
Validation loss: 2.1506561636924744

Epoch: 5| Step: 6
Training loss: 1.0213849544525146
Validation loss: 2.0880989134311676

Epoch: 5| Step: 7
Training loss: 1.4148836135864258
Validation loss: 2.1948721557855606

Epoch: 5| Step: 8
Training loss: 1.1955265998840332
Validation loss: 2.1688300569852195

Epoch: 5| Step: 9
Training loss: 0.8975065350532532
Validation loss: 2.2037261923154197

Epoch: 5| Step: 10
Training loss: 1.4419723749160767
Validation loss: 2.203577438990275

Epoch: 5| Step: 11
Training loss: 1.800645351409912
Validation loss: 2.1230076054732003

Epoch: 257| Step: 0
Training loss: 1.172663927078247
Validation loss: 2.105985472599665

Epoch: 5| Step: 1
Training loss: 1.2998394966125488
Validation loss: 2.1354597012201944

Epoch: 5| Step: 2
Training loss: 1.5561612844467163
Validation loss: 2.0999008069435754

Epoch: 5| Step: 3
Training loss: 0.6949142217636108
Validation loss: 2.1741916984319687

Epoch: 5| Step: 4
Training loss: 1.4857213497161865
Validation loss: 2.1268810580174127

Epoch: 5| Step: 5
Training loss: 1.653855562210083
Validation loss: 2.2349473983049393

Epoch: 5| Step: 6
Training loss: 1.3024743795394897
Validation loss: 2.2048590977986655

Epoch: 5| Step: 7
Training loss: 0.8869245648384094
Validation loss: 2.115691805879275

Epoch: 5| Step: 8
Training loss: 1.405204176902771
Validation loss: 2.1505781511465707

Epoch: 5| Step: 9
Training loss: 1.0889893770217896
Validation loss: 2.08026430507501

Epoch: 5| Step: 10
Training loss: 1.0452148914337158
Validation loss: 2.194356679916382

Epoch: 5| Step: 11
Training loss: 2.1898651123046875
Validation loss: 2.132832944393158

Epoch: 258| Step: 0
Training loss: 1.2164490222930908
Validation loss: 2.252119700113932

Epoch: 5| Step: 1
Training loss: 1.4540194272994995
Validation loss: 2.148757447799047

Epoch: 5| Step: 2
Training loss: 1.1435703039169312
Validation loss: 2.2316028575102487

Epoch: 5| Step: 3
Training loss: 1.724608063697815
Validation loss: 2.1710726618766785

Epoch: 5| Step: 4
Training loss: 0.8658846616744995
Validation loss: 2.1897583305835724

Epoch: 5| Step: 5
Training loss: 0.7083407044410706
Validation loss: 2.219336668650309

Epoch: 5| Step: 6
Training loss: 1.448672890663147
Validation loss: 2.1998027712106705

Epoch: 5| Step: 7
Training loss: 1.8582298755645752
Validation loss: 2.205759048461914

Epoch: 5| Step: 8
Training loss: 1.1513551473617554
Validation loss: 2.2083836843570075

Epoch: 5| Step: 9
Training loss: 1.3330153226852417
Validation loss: 2.165264601508776

Epoch: 5| Step: 10
Training loss: 1.5705724954605103
Validation loss: 2.131498023867607

Epoch: 5| Step: 11
Training loss: 0.6472151279449463
Validation loss: 2.220480799674988

Epoch: 259| Step: 0
Training loss: 1.0651825666427612
Validation loss: 2.1409413814544678

Epoch: 5| Step: 1
Training loss: 0.8774020075798035
Validation loss: 2.16124527156353

Epoch: 5| Step: 2
Training loss: 0.9623649716377258
Validation loss: 2.203706522782644

Epoch: 5| Step: 3
Training loss: 1.3862675428390503
Validation loss: 2.1423354148864746

Epoch: 5| Step: 4
Training loss: 1.1906887292861938
Validation loss: 2.146935095389684

Epoch: 5| Step: 5
Training loss: 0.7509256601333618
Validation loss: 2.0573007067044577

Epoch: 5| Step: 6
Training loss: 1.2370046377182007
Validation loss: 2.17700765033563

Epoch: 5| Step: 7
Training loss: 1.6475130319595337
Validation loss: 2.207318603992462

Epoch: 5| Step: 8
Training loss: 1.4998773336410522
Validation loss: 2.182764306664467

Epoch: 5| Step: 9
Training loss: 1.4138776063919067
Validation loss: 2.135206783811251

Epoch: 5| Step: 10
Training loss: 1.1351852416992188
Validation loss: 2.2284294962882996

Epoch: 5| Step: 11
Training loss: 1.0905075073242188
Validation loss: 2.256580506761869

Epoch: 260| Step: 0
Training loss: 2.0472095012664795
Validation loss: 2.192927653590838

Epoch: 5| Step: 1
Training loss: 1.1536214351654053
Validation loss: 2.1928945183753967

Epoch: 5| Step: 2
Training loss: 0.9484685063362122
Validation loss: 2.1529440780480704

Epoch: 5| Step: 3
Training loss: 1.16716468334198
Validation loss: 2.181766947110494

Epoch: 5| Step: 4
Training loss: 0.8913581967353821
Validation loss: 2.1534825017054877

Epoch: 5| Step: 5
Training loss: 0.9330136179924011
Validation loss: 2.187188828984896

Epoch: 5| Step: 6
Training loss: 1.5731534957885742
Validation loss: 2.216324190298716

Epoch: 5| Step: 7
Training loss: 1.1907622814178467
Validation loss: 2.280049333969752

Epoch: 5| Step: 8
Training loss: 1.3299437761306763
Validation loss: 2.2298115293184915

Epoch: 5| Step: 9
Training loss: 1.3465325832366943
Validation loss: 2.1389888177315393

Epoch: 5| Step: 10
Training loss: 1.2171382904052734
Validation loss: 2.1167242427666983

Epoch: 5| Step: 11
Training loss: 1.3120481967926025
Validation loss: 2.2017985731363297

Epoch: 261| Step: 0
Training loss: 1.0477330684661865
Validation loss: 2.212556625405947

Epoch: 5| Step: 1
Training loss: 1.5607765913009644
Validation loss: 2.1813513388236365

Epoch: 5| Step: 2
Training loss: 1.262094259262085
Validation loss: 2.188544347882271

Epoch: 5| Step: 3
Training loss: 1.637751817703247
Validation loss: 2.1825658977031708

Epoch: 5| Step: 4
Training loss: 0.9266529083251953
Validation loss: 2.1599532266457877

Epoch: 5| Step: 5
Training loss: 1.0530939102172852
Validation loss: 2.1416953057050705

Epoch: 5| Step: 6
Training loss: 0.9959020614624023
Validation loss: 2.155007873972257

Epoch: 5| Step: 7
Training loss: 1.4350656270980835
Validation loss: 2.1481862564881644

Epoch: 5| Step: 8
Training loss: 0.8996761441230774
Validation loss: 2.1761419822772345

Epoch: 5| Step: 9
Training loss: 1.0382322072982788
Validation loss: 2.187607924143473

Epoch: 5| Step: 10
Training loss: 1.136883020401001
Validation loss: 2.174937297900518

Epoch: 5| Step: 11
Training loss: 1.7691069841384888
Validation loss: 2.2145434617996216

Epoch: 262| Step: 0
Training loss: 0.8918590545654297
Validation loss: 2.152413383126259

Epoch: 5| Step: 1
Training loss: 1.1923015117645264
Validation loss: 2.1608355094989142

Epoch: 5| Step: 2
Training loss: 1.2763981819152832
Validation loss: 2.204994430144628

Epoch: 5| Step: 3
Training loss: 1.1113954782485962
Validation loss: 2.2495266646146774

Epoch: 5| Step: 4
Training loss: 1.4873136281967163
Validation loss: 2.1508803218603134

Epoch: 5| Step: 5
Training loss: 1.1080578565597534
Validation loss: 2.2242060899734497

Epoch: 5| Step: 6
Training loss: 1.5944840908050537
Validation loss: 2.1219323575496674

Epoch: 5| Step: 7
Training loss: 1.0799713134765625
Validation loss: 2.07489667336146

Epoch: 5| Step: 8
Training loss: 1.4032827615737915
Validation loss: 2.12591644624869

Epoch: 5| Step: 9
Training loss: 1.146187424659729
Validation loss: 2.173949350913366

Epoch: 5| Step: 10
Training loss: 0.846218466758728
Validation loss: 2.130128249526024

Epoch: 5| Step: 11
Training loss: 0.9971323609352112
Validation loss: 2.108725825945536

Epoch: 263| Step: 0
Training loss: 1.2389395236968994
Validation loss: 2.1754096895456314

Epoch: 5| Step: 1
Training loss: 1.1535556316375732
Validation loss: 2.2034808893998465

Epoch: 5| Step: 2
Training loss: 1.2008134126663208
Validation loss: 2.315189947684606

Epoch: 5| Step: 3
Training loss: 1.3472851514816284
Validation loss: 2.3550962110360465

Epoch: 5| Step: 4
Training loss: 1.5833278894424438
Validation loss: 2.3840914368629456

Epoch: 5| Step: 5
Training loss: 1.248131513595581
Validation loss: 2.2515015999476113

Epoch: 5| Step: 6
Training loss: 1.9313074350357056
Validation loss: 2.2363920360803604

Epoch: 5| Step: 7
Training loss: 1.0071518421173096
Validation loss: 2.0884442379077277

Epoch: 5| Step: 8
Training loss: 1.1086459159851074
Validation loss: 2.19175819059213

Epoch: 5| Step: 9
Training loss: 0.9136443138122559
Validation loss: 2.218018631140391

Epoch: 5| Step: 10
Training loss: 1.2118057012557983
Validation loss: 2.2068608105182648

Epoch: 5| Step: 11
Training loss: 1.868709921836853
Validation loss: 2.2159856408834457

Epoch: 264| Step: 0
Training loss: 1.003053903579712
Validation loss: 2.256335516770681

Epoch: 5| Step: 1
Training loss: 0.6141458749771118
Validation loss: 2.2175759176413217

Epoch: 5| Step: 2
Training loss: 1.4342762231826782
Validation loss: 2.206608384847641

Epoch: 5| Step: 3
Training loss: 1.3986378908157349
Validation loss: 2.186024948954582

Epoch: 5| Step: 4
Training loss: 1.2782667875289917
Validation loss: 2.2151276965936026

Epoch: 5| Step: 5
Training loss: 0.9768053293228149
Validation loss: 2.151346584161123

Epoch: 5| Step: 6
Training loss: 1.237333059310913
Validation loss: 2.17181159555912

Epoch: 5| Step: 7
Training loss: 1.5456684827804565
Validation loss: 2.247588793436686

Epoch: 5| Step: 8
Training loss: 1.1006509065628052
Validation loss: 2.2384425699710846

Epoch: 5| Step: 9
Training loss: 1.0211025476455688
Validation loss: 2.089908391237259

Epoch: 5| Step: 10
Training loss: 1.2377914190292358
Validation loss: 2.1615566412607827

Epoch: 5| Step: 11
Training loss: 0.37080180644989014
Validation loss: 2.1460340321063995

Epoch: 265| Step: 0
Training loss: 1.1733229160308838
Validation loss: 2.149557555715243

Epoch: 5| Step: 1
Training loss: 1.318223237991333
Validation loss: 2.1630325814088187

Epoch: 5| Step: 2
Training loss: 1.161471962928772
Validation loss: 2.1621419886747995

Epoch: 5| Step: 3
Training loss: 1.4764292240142822
Validation loss: 2.1622999558846154

Epoch: 5| Step: 4
Training loss: 0.9576126337051392
Validation loss: 2.108407845099767

Epoch: 5| Step: 5
Training loss: 0.7151468992233276
Validation loss: 2.188460484147072

Epoch: 5| Step: 6
Training loss: 1.000888705253601
Validation loss: 2.209954544901848

Epoch: 5| Step: 7
Training loss: 0.713447093963623
Validation loss: 2.1566824515660605

Epoch: 5| Step: 8
Training loss: 1.027724027633667
Validation loss: 2.1833363274733224

Epoch: 5| Step: 9
Training loss: 1.835071325302124
Validation loss: 2.1573301206032434

Epoch: 5| Step: 10
Training loss: 1.4001128673553467
Validation loss: 2.2206860035657883

Epoch: 5| Step: 11
Training loss: 0.9599184393882751
Validation loss: 2.1999668926000595

Epoch: 266| Step: 0
Training loss: 0.8479791879653931
Validation loss: 2.1702738602956138

Epoch: 5| Step: 1
Training loss: 1.2335089445114136
Validation loss: 2.234362229704857

Epoch: 5| Step: 2
Training loss: 1.187986135482788
Validation loss: 2.3033888141314187

Epoch: 5| Step: 3
Training loss: 1.322001338005066
Validation loss: 2.2856738418340683

Epoch: 5| Step: 4
Training loss: 1.5105648040771484
Validation loss: 2.208633462587992

Epoch: 5| Step: 5
Training loss: 0.890334963798523
Validation loss: 2.1918957581122718

Epoch: 5| Step: 6
Training loss: 1.298500657081604
Validation loss: 2.1641254127025604

Epoch: 5| Step: 7
Training loss: 1.7886279821395874
Validation loss: 2.157034526268641

Epoch: 5| Step: 8
Training loss: 1.5687049627304077
Validation loss: 2.1431653797626495

Epoch: 5| Step: 9
Training loss: 1.368478536605835
Validation loss: 2.135246157646179

Epoch: 5| Step: 10
Training loss: 1.1920870542526245
Validation loss: 2.1478592604398727

Epoch: 5| Step: 11
Training loss: 1.5857675075531006
Validation loss: 2.2130602300167084

Epoch: 267| Step: 0
Training loss: 1.3478524684906006
Validation loss: 2.1795251071453094

Epoch: 5| Step: 1
Training loss: 0.9787986874580383
Validation loss: 2.1154493937889733

Epoch: 5| Step: 2
Training loss: 1.7150846719741821
Validation loss: 2.04621122777462

Epoch: 5| Step: 3
Training loss: 1.5288259983062744
Validation loss: 2.139769916733106

Epoch: 5| Step: 4
Training loss: 1.1532541513442993
Validation loss: 2.1235655744870505

Epoch: 5| Step: 5
Training loss: 1.0266568660736084
Validation loss: 2.206857850154241

Epoch: 5| Step: 6
Training loss: 1.1226720809936523
Validation loss: 2.130315735936165

Epoch: 5| Step: 7
Training loss: 1.2989208698272705
Validation loss: 2.1672503550847373

Epoch: 5| Step: 8
Training loss: 0.7723778486251831
Validation loss: 2.1643506636222205

Epoch: 5| Step: 9
Training loss: 1.2498953342437744
Validation loss: 2.2040198147296906

Epoch: 5| Step: 10
Training loss: 0.9291481971740723
Validation loss: 2.1556845208009086

Epoch: 5| Step: 11
Training loss: 0.44352877140045166
Validation loss: 2.148019015789032

Epoch: 268| Step: 0
Training loss: 1.180016040802002
Validation loss: 2.157604922850927

Epoch: 5| Step: 1
Training loss: 1.135117530822754
Validation loss: 2.1647789478302

Epoch: 5| Step: 2
Training loss: 0.8913345336914062
Validation loss: 2.125991096099218

Epoch: 5| Step: 3
Training loss: 1.4111135005950928
Validation loss: 2.157642458875974

Epoch: 5| Step: 4
Training loss: 1.0242769718170166
Validation loss: 2.1140680015087128

Epoch: 5| Step: 5
Training loss: 0.996167004108429
Validation loss: 2.1669814387957254

Epoch: 5| Step: 6
Training loss: 0.724966287612915
Validation loss: 2.138594090938568

Epoch: 5| Step: 7
Training loss: 1.2411895990371704
Validation loss: 2.1923104375600815

Epoch: 5| Step: 8
Training loss: 1.0348987579345703
Validation loss: 2.1069296846787133

Epoch: 5| Step: 9
Training loss: 1.1192700862884521
Validation loss: 2.154116084178289

Epoch: 5| Step: 10
Training loss: 1.186233639717102
Validation loss: 2.1284944117069244

Epoch: 5| Step: 11
Training loss: 2.5464940071105957
Validation loss: 2.1881586015224457

Epoch: 269| Step: 0
Training loss: 1.0363175868988037
Validation loss: 2.1243727654218674

Epoch: 5| Step: 1
Training loss: 1.4846702814102173
Validation loss: 2.320141384998957

Epoch: 5| Step: 2
Training loss: 1.166319489479065
Validation loss: 2.2429531117280326

Epoch: 5| Step: 3
Training loss: 1.1992157697677612
Validation loss: 2.1529418180386224

Epoch: 5| Step: 4
Training loss: 1.3456599712371826
Validation loss: 2.212880621353785

Epoch: 5| Step: 5
Training loss: 1.0939960479736328
Validation loss: 2.108815222978592

Epoch: 5| Step: 6
Training loss: 1.6375532150268555
Validation loss: 2.1484053879976273

Epoch: 5| Step: 7
Training loss: 1.2106258869171143
Validation loss: 2.1195858220259347

Epoch: 5| Step: 8
Training loss: 1.177509069442749
Validation loss: 2.12171733379364

Epoch: 5| Step: 9
Training loss: 1.2861971855163574
Validation loss: 2.2229415675004325

Epoch: 5| Step: 10
Training loss: 1.1147347688674927
Validation loss: 2.152640253305435

Epoch: 5| Step: 11
Training loss: 1.1581110954284668
Validation loss: 2.0665208448966346

Epoch: 270| Step: 0
Training loss: 2.1226553916931152
Validation loss: 2.19300739467144

Epoch: 5| Step: 1
Training loss: 1.0652390718460083
Validation loss: 2.06475963195165

Epoch: 5| Step: 2
Training loss: 1.1597248315811157
Validation loss: 2.239853709936142

Epoch: 5| Step: 3
Training loss: 0.848616898059845
Validation loss: 2.2637427349885306

Epoch: 5| Step: 4
Training loss: 1.380065679550171
Validation loss: 2.250453144311905

Epoch: 5| Step: 5
Training loss: 0.9965084791183472
Validation loss: 2.1948408683141074

Epoch: 5| Step: 6
Training loss: 0.807171642780304
Validation loss: 2.1183449774980545

Epoch: 5| Step: 7
Training loss: 1.747450828552246
Validation loss: 2.2288155357042947

Epoch: 5| Step: 8
Training loss: 1.1207808256149292
Validation loss: 2.1009183824062347

Epoch: 5| Step: 9
Training loss: 0.8750581741333008
Validation loss: 2.1264843742052713

Epoch: 5| Step: 10
Training loss: 1.233588457107544
Validation loss: 2.188676953315735

Epoch: 5| Step: 11
Training loss: 1.408911108970642
Validation loss: 2.138947993516922

Epoch: 271| Step: 0
Training loss: 1.244946837425232
Validation loss: 2.1575411210457482

Epoch: 5| Step: 1
Training loss: 1.2473933696746826
Validation loss: 2.219873776038488

Epoch: 5| Step: 2
Training loss: 1.4026515483856201
Validation loss: 2.2027385433514914

Epoch: 5| Step: 3
Training loss: 1.3908385038375854
Validation loss: 2.1910544633865356

Epoch: 5| Step: 4
Training loss: 0.905136227607727
Validation loss: 2.1687721262375512

Epoch: 5| Step: 5
Training loss: 1.7194188833236694
Validation loss: 2.128072773416837

Epoch: 5| Step: 6
Training loss: 0.8070617914199829
Validation loss: 2.1649063428243003

Epoch: 5| Step: 7
Training loss: 0.7656850814819336
Validation loss: 2.245345031221708

Epoch: 5| Step: 8
Training loss: 1.4735381603240967
Validation loss: 2.2502067585786185

Epoch: 5| Step: 9
Training loss: 1.1032464504241943
Validation loss: 2.1521241764227548

Epoch: 5| Step: 10
Training loss: 1.6299622058868408
Validation loss: 2.1580233176549277

Epoch: 5| Step: 11
Training loss: 0.6798276901245117
Validation loss: 2.199763963619868

Epoch: 272| Step: 0
Training loss: 1.0944764614105225
Validation loss: 2.14542356133461

Epoch: 5| Step: 1
Training loss: 1.2439370155334473
Validation loss: 2.1657942831516266

Epoch: 5| Step: 2
Training loss: 1.391789197921753
Validation loss: 2.1232279539108276

Epoch: 5| Step: 3
Training loss: 1.1161383390426636
Validation loss: 2.2327901870012283

Epoch: 5| Step: 4
Training loss: 1.7899843454360962
Validation loss: 2.1514557898044586

Epoch: 5| Step: 5
Training loss: 0.8688902854919434
Validation loss: 2.1405499428510666

Epoch: 5| Step: 6
Training loss: 0.836107611656189
Validation loss: 2.2126448104778924

Epoch: 5| Step: 7
Training loss: 1.8083503246307373
Validation loss: 2.163389131426811

Epoch: 5| Step: 8
Training loss: 1.4258918762207031
Validation loss: 2.212784101565679

Epoch: 5| Step: 9
Training loss: 1.0674341917037964
Validation loss: 2.1881248503923416

Epoch: 5| Step: 10
Training loss: 0.9168971180915833
Validation loss: 2.0872874557971954

Epoch: 5| Step: 11
Training loss: 0.5308759212493896
Validation loss: 2.175991694132487

Epoch: 273| Step: 0
Training loss: 1.1607309579849243
Validation loss: 2.206038326025009

Epoch: 5| Step: 1
Training loss: 0.44397735595703125
Validation loss: 2.1457206159830093

Epoch: 5| Step: 2
Training loss: 0.9758644104003906
Validation loss: 2.1621084908644357

Epoch: 5| Step: 3
Training loss: 2.0255630016326904
Validation loss: 2.2504979918400445

Epoch: 5| Step: 4
Training loss: 0.9914296269416809
Validation loss: 2.204453691840172

Epoch: 5| Step: 5
Training loss: 1.478873610496521
Validation loss: 2.184834043184916

Epoch: 5| Step: 6
Training loss: 1.3669769763946533
Validation loss: 2.1111177653074265

Epoch: 5| Step: 7
Training loss: 1.0590964555740356
Validation loss: 2.073112944761912

Epoch: 5| Step: 8
Training loss: 1.4560163021087646
Validation loss: 2.1644255071878433

Epoch: 5| Step: 9
Training loss: 1.343487024307251
Validation loss: 2.1826037565867105

Epoch: 5| Step: 10
Training loss: 0.6282035112380981
Validation loss: 2.0516433119773865

Epoch: 5| Step: 11
Training loss: 0.9521169662475586
Validation loss: 2.134351432323456

Epoch: 274| Step: 0
Training loss: 1.011441707611084
Validation loss: 2.1704378525416055

Epoch: 5| Step: 1
Training loss: 1.0738918781280518
Validation loss: 2.1363643060127893

Epoch: 5| Step: 2
Training loss: 1.210880160331726
Validation loss: 2.1798009276390076

Epoch: 5| Step: 3
Training loss: 0.8785134553909302
Validation loss: 2.1141290217638016

Epoch: 5| Step: 4
Training loss: 0.8866588473320007
Validation loss: 2.142701049645742

Epoch: 5| Step: 5
Training loss: 1.0510705709457397
Validation loss: 2.166022300720215

Epoch: 5| Step: 6
Training loss: 1.109865427017212
Validation loss: 2.17524424691995

Epoch: 5| Step: 7
Training loss: 1.5707110166549683
Validation loss: 2.1587799191474915

Epoch: 5| Step: 8
Training loss: 1.3198089599609375
Validation loss: 2.1799515783786774

Epoch: 5| Step: 9
Training loss: 1.4051518440246582
Validation loss: 2.2505460381507874

Epoch: 5| Step: 10
Training loss: 0.9970934987068176
Validation loss: 2.140435049931208

Epoch: 5| Step: 11
Training loss: 0.5417080521583557
Validation loss: 2.0719723800818124

Epoch: 275| Step: 0
Training loss: 1.0503302812576294
Validation loss: 2.1510166625181832

Epoch: 5| Step: 1
Training loss: 0.9480831027030945
Validation loss: 2.170643925666809

Epoch: 5| Step: 2
Training loss: 0.8332521319389343
Validation loss: 2.109677309791247

Epoch: 5| Step: 3
Training loss: 1.499114751815796
Validation loss: 2.192204346259435

Epoch: 5| Step: 4
Training loss: 1.1464693546295166
Validation loss: 2.075940489768982

Epoch: 5| Step: 5
Training loss: 0.8402255773544312
Validation loss: 2.097782308856646

Epoch: 5| Step: 6
Training loss: 1.5392059087753296
Validation loss: 2.224953164656957

Epoch: 5| Step: 7
Training loss: 1.2451566457748413
Validation loss: 2.2235249876976013

Epoch: 5| Step: 8
Training loss: 0.8814398050308228
Validation loss: 2.1912734508514404

Epoch: 5| Step: 9
Training loss: 1.1517527103424072
Validation loss: 2.2729396522045135

Epoch: 5| Step: 10
Training loss: 1.7676963806152344
Validation loss: 2.0840738664070764

Epoch: 5| Step: 11
Training loss: 1.7116326093673706
Validation loss: 2.1932606945435205

Epoch: 276| Step: 0
Training loss: 1.0149846076965332
Validation loss: 2.1381693383057914

Epoch: 5| Step: 1
Training loss: 1.0081632137298584
Validation loss: 2.158539061745008

Epoch: 5| Step: 2
Training loss: 1.4851897954940796
Validation loss: 2.1754096150398254

Epoch: 5| Step: 3
Training loss: 1.4640843868255615
Validation loss: 2.1348238736391068

Epoch: 5| Step: 4
Training loss: 0.9040220379829407
Validation loss: 2.16938516497612

Epoch: 5| Step: 5
Training loss: 1.4918830394744873
Validation loss: 2.1424166709184647

Epoch: 5| Step: 6
Training loss: 0.7252739667892456
Validation loss: 2.138407344619433

Epoch: 5| Step: 7
Training loss: 1.23763906955719
Validation loss: 2.1275389045476913

Epoch: 5| Step: 8
Training loss: 0.8952716588973999
Validation loss: 2.1739876766999564

Epoch: 5| Step: 9
Training loss: 0.7589253187179565
Validation loss: 2.0687193671862283

Epoch: 5| Step: 10
Training loss: 1.414907693862915
Validation loss: 2.067857945958773

Epoch: 5| Step: 11
Training loss: 0.26502716541290283
Validation loss: 2.1492322236299515

Epoch: 277| Step: 0
Training loss: 1.332139015197754
Validation loss: 2.140234187245369

Epoch: 5| Step: 1
Training loss: 1.0349400043487549
Validation loss: 2.116381267706553

Epoch: 5| Step: 2
Training loss: 1.2716790437698364
Validation loss: 2.089319492379824

Epoch: 5| Step: 3
Training loss: 1.0693869590759277
Validation loss: 2.120209569732348

Epoch: 5| Step: 4
Training loss: 1.1313397884368896
Validation loss: 2.148741622765859

Epoch: 5| Step: 5
Training loss: 0.9112857580184937
Validation loss: 2.081131170193354

Epoch: 5| Step: 6
Training loss: 0.8250777125358582
Validation loss: 2.1330883552630744

Epoch: 5| Step: 7
Training loss: 1.4366816282272339
Validation loss: 2.089405357837677

Epoch: 5| Step: 8
Training loss: 1.0841318368911743
Validation loss: 2.130190908908844

Epoch: 5| Step: 9
Training loss: 1.7064294815063477
Validation loss: 2.063897172609965

Epoch: 5| Step: 10
Training loss: 0.9950698614120483
Validation loss: 2.1103806545337043

Epoch: 5| Step: 11
Training loss: 0.9116100072860718
Validation loss: 2.1609478692213693

Epoch: 278| Step: 0
Training loss: 1.160506010055542
Validation loss: 2.076926772793134

Epoch: 5| Step: 1
Training loss: 0.912171483039856
Validation loss: 2.134800841410955

Epoch: 5| Step: 2
Training loss: 1.1411598920822144
Validation loss: 2.0980878124634423

Epoch: 5| Step: 3
Training loss: 1.1672204732894897
Validation loss: 2.0963043371836343

Epoch: 5| Step: 4
Training loss: 1.148037075996399
Validation loss: 2.116211493810018

Epoch: 5| Step: 5
Training loss: 1.1288260221481323
Validation loss: 2.20541446407636

Epoch: 5| Step: 6
Training loss: 2.0702128410339355
Validation loss: 2.053397392233213

Epoch: 5| Step: 7
Training loss: 0.6908847093582153
Validation loss: 2.1440634578466415

Epoch: 5| Step: 8
Training loss: 1.241736888885498
Validation loss: 2.1587956696748734

Epoch: 5| Step: 9
Training loss: 1.3096721172332764
Validation loss: 2.152169863382975

Epoch: 5| Step: 10
Training loss: 0.6625844240188599
Validation loss: 2.126932750145594

Epoch: 5| Step: 11
Training loss: 1.1076011657714844
Validation loss: 2.104192386070887

Epoch: 279| Step: 0
Training loss: 1.0851367712020874
Validation loss: 2.107179676493009

Epoch: 5| Step: 1
Training loss: 1.2558057308197021
Validation loss: 2.100741704305013

Epoch: 5| Step: 2
Training loss: 1.4649616479873657
Validation loss: 2.114065408706665

Epoch: 5| Step: 3
Training loss: 0.8208668828010559
Validation loss: 2.1342205703258514

Epoch: 5| Step: 4
Training loss: 1.7183796167373657
Validation loss: 2.155548637111982

Epoch: 5| Step: 5
Training loss: 1.043104887008667
Validation loss: 2.1935803393522897

Epoch: 5| Step: 6
Training loss: 1.4014676809310913
Validation loss: 2.1458061933517456

Epoch: 5| Step: 7
Training loss: 1.277296543121338
Validation loss: 2.1965637703736625

Epoch: 5| Step: 8
Training loss: 1.0764809846878052
Validation loss: 2.109644224246343

Epoch: 5| Step: 9
Training loss: 0.6833401918411255
Validation loss: 2.166141465306282

Epoch: 5| Step: 10
Training loss: 0.9207180142402649
Validation loss: 2.151112198829651

Epoch: 5| Step: 11
Training loss: 0.5309204459190369
Validation loss: 2.1362913896640143

Epoch: 280| Step: 0
Training loss: 1.1208326816558838
Validation loss: 2.2136179705460868

Epoch: 5| Step: 1
Training loss: 0.9282200932502747
Validation loss: 2.1436387598514557

Epoch: 5| Step: 2
Training loss: 1.2256460189819336
Validation loss: 2.185550183057785

Epoch: 5| Step: 3
Training loss: 1.0385653972625732
Validation loss: 2.152575299143791

Epoch: 5| Step: 4
Training loss: 1.1404502391815186
Validation loss: 2.2388785034418106

Epoch: 5| Step: 5
Training loss: 1.1815886497497559
Validation loss: 2.2143369019031525

Epoch: 5| Step: 6
Training loss: 1.0201599597930908
Validation loss: 2.1797001510858536

Epoch: 5| Step: 7
Training loss: 1.0205496549606323
Validation loss: 2.2121083984772363

Epoch: 5| Step: 8
Training loss: 1.0865232944488525
Validation loss: 2.2292254169782004

Epoch: 5| Step: 9
Training loss: 1.6519203186035156
Validation loss: 2.2122954775889716

Epoch: 5| Step: 10
Training loss: 1.8483467102050781
Validation loss: 2.2645941774050393

Epoch: 5| Step: 11
Training loss: 2.3082027435302734
Validation loss: 2.239999920129776

Epoch: 281| Step: 0
Training loss: 1.0491234064102173
Validation loss: 2.2722273568312326

Epoch: 5| Step: 1
Training loss: 0.8634885549545288
Validation loss: 2.170922428369522

Epoch: 5| Step: 2
Training loss: 0.9773164987564087
Validation loss: 2.14841236670812

Epoch: 5| Step: 3
Training loss: 1.5424368381500244
Validation loss: 2.115827371676763

Epoch: 5| Step: 4
Training loss: 1.229278326034546
Validation loss: 2.0865646799405417

Epoch: 5| Step: 5
Training loss: 1.1105420589447021
Validation loss: 2.197071820497513

Epoch: 5| Step: 6
Training loss: 1.1013553142547607
Validation loss: 2.182234803835551

Epoch: 5| Step: 7
Training loss: 1.4458439350128174
Validation loss: 2.0886031736930213

Epoch: 5| Step: 8
Training loss: 1.2892436981201172
Validation loss: 2.133460824688276

Epoch: 5| Step: 9
Training loss: 1.0363644361495972
Validation loss: 2.117605964342753

Epoch: 5| Step: 10
Training loss: 0.9296857118606567
Validation loss: 2.1974195142587027

Epoch: 5| Step: 11
Training loss: 1.1882412433624268
Validation loss: 2.0940055350462594

Epoch: 282| Step: 0
Training loss: 1.1781039237976074
Validation loss: 2.212587962547938

Epoch: 5| Step: 1
Training loss: 1.1474533081054688
Validation loss: 2.112619717915853

Epoch: 5| Step: 2
Training loss: 1.2125004529953003
Validation loss: 2.1841429670651755

Epoch: 5| Step: 3
Training loss: 1.058462381362915
Validation loss: 2.140793631474177

Epoch: 5| Step: 4
Training loss: 1.3871774673461914
Validation loss: 2.120162988702456

Epoch: 5| Step: 5
Training loss: 1.0782599449157715
Validation loss: 2.075722426176071

Epoch: 5| Step: 6
Training loss: 1.1337851285934448
Validation loss: 2.179658720890681

Epoch: 5| Step: 7
Training loss: 0.7459689378738403
Validation loss: 2.236885299285253

Epoch: 5| Step: 8
Training loss: 0.710745096206665
Validation loss: 2.2475219617287316

Epoch: 5| Step: 9
Training loss: 0.7977202534675598
Validation loss: 2.1638057132562003

Epoch: 5| Step: 10
Training loss: 1.33878493309021
Validation loss: 2.1036612490812936

Epoch: 5| Step: 11
Training loss: 1.286615252494812
Validation loss: 2.1501479099194207

Epoch: 283| Step: 0
Training loss: 1.4386932849884033
Validation loss: 2.2410330176353455

Epoch: 5| Step: 1
Training loss: 0.9344367980957031
Validation loss: 2.24911692738533

Epoch: 5| Step: 2
Training loss: 0.8869794607162476
Validation loss: 2.0975658049186072

Epoch: 5| Step: 3
Training loss: 1.3520326614379883
Validation loss: 2.1878836154937744

Epoch: 5| Step: 4
Training loss: 1.1957645416259766
Validation loss: 2.1150561471780143

Epoch: 5| Step: 5
Training loss: 1.6337053775787354
Validation loss: 2.1882229447364807

Epoch: 5| Step: 6
Training loss: 0.8752292394638062
Validation loss: 2.12547575434049

Epoch: 5| Step: 7
Training loss: 1.130932331085205
Validation loss: 2.1613784631093345

Epoch: 5| Step: 8
Training loss: 1.0539039373397827
Validation loss: 2.197150011857351

Epoch: 5| Step: 9
Training loss: 0.8775525093078613
Validation loss: 2.210589438676834

Epoch: 5| Step: 10
Training loss: 1.00714111328125
Validation loss: 2.266910801331202

Epoch: 5| Step: 11
Training loss: 0.9304941892623901
Validation loss: 2.1716843048731485

Epoch: 284| Step: 0
Training loss: 0.4976502060890198
Validation loss: 2.0735338230927787

Epoch: 5| Step: 1
Training loss: 1.8709701299667358
Validation loss: 2.1403043319781623

Epoch: 5| Step: 2
Training loss: 1.3348414897918701
Validation loss: 2.162463520963987

Epoch: 5| Step: 3
Training loss: 0.6079906821250916
Validation loss: 2.1368058125178018

Epoch: 5| Step: 4
Training loss: 1.1092487573623657
Validation loss: 2.146363213658333

Epoch: 5| Step: 5
Training loss: 0.9556255340576172
Validation loss: 2.2028231620788574

Epoch: 5| Step: 6
Training loss: 2.192753314971924
Validation loss: 2.1590034812688828

Epoch: 5| Step: 7
Training loss: 1.2199819087982178
Validation loss: 2.1408553272485733

Epoch: 5| Step: 8
Training loss: 0.9180479049682617
Validation loss: 2.2239601413408914

Epoch: 5| Step: 9
Training loss: 0.8164579272270203
Validation loss: 2.1824451982975006

Epoch: 5| Step: 10
Training loss: 0.7950992584228516
Validation loss: 2.207831730445226

Epoch: 5| Step: 11
Training loss: 0.9833945035934448
Validation loss: 2.188901980717977

Epoch: 285| Step: 0
Training loss: 0.9339276552200317
Validation loss: 2.1478770027558007

Epoch: 5| Step: 1
Training loss: 1.0015662908554077
Validation loss: 2.1250830441713333

Epoch: 5| Step: 2
Training loss: 0.7958162426948547
Validation loss: 2.1952743430932364

Epoch: 5| Step: 3
Training loss: 1.1993753910064697
Validation loss: 2.113249272108078

Epoch: 5| Step: 4
Training loss: 0.7815788984298706
Validation loss: 2.1260242561499276

Epoch: 5| Step: 5
Training loss: 1.7823402881622314
Validation loss: 2.091791088382403

Epoch: 5| Step: 6
Training loss: 1.5597585439682007
Validation loss: 2.1153377294540405

Epoch: 5| Step: 7
Training loss: 1.0318052768707275
Validation loss: 2.1932292779286704

Epoch: 5| Step: 8
Training loss: 0.897198498249054
Validation loss: 2.152134031057358

Epoch: 5| Step: 9
Training loss: 0.8591585159301758
Validation loss: 2.129698852698008

Epoch: 5| Step: 10
Training loss: 0.9803091883659363
Validation loss: 2.1650211910406747

Epoch: 5| Step: 11
Training loss: 0.9489220380783081
Validation loss: 2.202212482690811

Epoch: 286| Step: 0
Training loss: 1.1186256408691406
Validation loss: 2.268281022707621

Epoch: 5| Step: 1
Training loss: 1.4060595035552979
Validation loss: 2.1626031398773193

Epoch: 5| Step: 2
Training loss: 1.146680235862732
Validation loss: 2.1889979392290115

Epoch: 5| Step: 3
Training loss: 0.9909411668777466
Validation loss: 2.218705723683039

Epoch: 5| Step: 4
Training loss: 1.2365936040878296
Validation loss: 2.1999319096406302

Epoch: 5| Step: 5
Training loss: 0.9515942335128784
Validation loss: 2.2088329990704856

Epoch: 5| Step: 6
Training loss: 0.770195484161377
Validation loss: 2.159600242972374

Epoch: 5| Step: 7
Training loss: 1.4357588291168213
Validation loss: 2.076969549059868

Epoch: 5| Step: 8
Training loss: 1.0311862230300903
Validation loss: 2.219679832458496

Epoch: 5| Step: 9
Training loss: 1.0624499320983887
Validation loss: 2.118627150853475

Epoch: 5| Step: 10
Training loss: 0.856009840965271
Validation loss: 2.127997492750486

Epoch: 5| Step: 11
Training loss: 1.253373146057129
Validation loss: 2.2298490007718406

Epoch: 287| Step: 0
Training loss: 1.5139615535736084
Validation loss: 2.1813193360964456

Epoch: 5| Step: 1
Training loss: 1.0575740337371826
Validation loss: 2.1799309849739075

Epoch: 5| Step: 2
Training loss: 1.6458545923233032
Validation loss: 2.204654574394226

Epoch: 5| Step: 3
Training loss: 1.1115888357162476
Validation loss: 2.192779983083407

Epoch: 5| Step: 4
Training loss: 1.0845361948013306
Validation loss: 2.2028634448846183

Epoch: 5| Step: 5
Training loss: 1.0634794235229492
Validation loss: 2.147124985853831

Epoch: 5| Step: 6
Training loss: 1.4809465408325195
Validation loss: 2.1505143344402313

Epoch: 5| Step: 7
Training loss: 1.700311303138733
Validation loss: 2.183006316423416

Epoch: 5| Step: 8
Training loss: 0.624785304069519
Validation loss: 2.0965827057758966

Epoch: 5| Step: 9
Training loss: 1.045352578163147
Validation loss: 2.1930327117443085

Epoch: 5| Step: 10
Training loss: 0.7088877558708191
Validation loss: 2.1427504966656366

Epoch: 5| Step: 11
Training loss: 0.7315818071365356
Validation loss: 2.1495736291011176

Epoch: 288| Step: 0
Training loss: 1.464512586593628
Validation loss: 2.205958609779676

Epoch: 5| Step: 1
Training loss: 1.0336077213287354
Validation loss: 2.1522732923428216

Epoch: 5| Step: 2
Training loss: 1.2354247570037842
Validation loss: 2.1764407257239022

Epoch: 5| Step: 3
Training loss: 1.1104305982589722
Validation loss: 2.1717782020568848

Epoch: 5| Step: 4
Training loss: 1.4981426000595093
Validation loss: 2.181790292263031

Epoch: 5| Step: 5
Training loss: 1.1593048572540283
Validation loss: 2.094229578971863

Epoch: 5| Step: 6
Training loss: 0.8896812200546265
Validation loss: 2.1572034657001495

Epoch: 5| Step: 7
Training loss: 0.8926185369491577
Validation loss: 2.1706284483273826

Epoch: 5| Step: 8
Training loss: 1.304674744606018
Validation loss: 2.1722847670316696

Epoch: 5| Step: 9
Training loss: 0.6894766092300415
Validation loss: 2.2016692956288657

Epoch: 5| Step: 10
Training loss: 0.9842904210090637
Validation loss: 2.2024707198143005

Epoch: 5| Step: 11
Training loss: 0.8183578252792358
Validation loss: 2.200511326392492

Epoch: 289| Step: 0
Training loss: 1.4139918088912964
Validation loss: 2.154458597302437

Epoch: 5| Step: 1
Training loss: 1.1614558696746826
Validation loss: 2.1405383348464966

Epoch: 5| Step: 2
Training loss: 0.945599377155304
Validation loss: 2.1567514141400657

Epoch: 5| Step: 3
Training loss: 0.9528166055679321
Validation loss: 2.161861558755239

Epoch: 5| Step: 4
Training loss: 1.2066373825073242
Validation loss: 2.1306303093830743

Epoch: 5| Step: 5
Training loss: 0.8843185305595398
Validation loss: 2.1221903264522552

Epoch: 5| Step: 6
Training loss: 0.9540907144546509
Validation loss: 2.1785744627316794

Epoch: 5| Step: 7
Training loss: 0.8075069189071655
Validation loss: 2.0969149072964988

Epoch: 5| Step: 8
Training loss: 1.268240213394165
Validation loss: 2.1238910953203836

Epoch: 5| Step: 9
Training loss: 1.5465167760849
Validation loss: 2.170079087217649

Epoch: 5| Step: 10
Training loss: 0.9461358189582825
Validation loss: 2.172644793987274

Epoch: 5| Step: 11
Training loss: 0.3989217281341553
Validation loss: 2.114319011569023

Epoch: 290| Step: 0
Training loss: 1.3475183248519897
Validation loss: 2.079363758365313

Epoch: 5| Step: 1
Training loss: 0.8682762980461121
Validation loss: 2.1969028065601983

Epoch: 5| Step: 2
Training loss: 0.8435900807380676
Validation loss: 2.0920066287120185

Epoch: 5| Step: 3
Training loss: 0.724524199962616
Validation loss: 2.1269750396410623

Epoch: 5| Step: 4
Training loss: 1.0673935413360596
Validation loss: 2.1265193074941635

Epoch: 5| Step: 5
Training loss: 1.3684587478637695
Validation loss: 2.16766157746315

Epoch: 5| Step: 6
Training loss: 1.1528376340866089
Validation loss: 2.2460534274578094

Epoch: 5| Step: 7
Training loss: 0.6988323330879211
Validation loss: 2.045946111281713

Epoch: 5| Step: 8
Training loss: 1.0152045488357544
Validation loss: 2.0910142759482064

Epoch: 5| Step: 9
Training loss: 1.2843263149261475
Validation loss: 2.134323164820671

Epoch: 5| Step: 10
Training loss: 0.8196489214897156
Validation loss: 2.138340483109156

Epoch: 5| Step: 11
Training loss: 2.411848783493042
Validation loss: 2.159025917450587

Epoch: 291| Step: 0
Training loss: 1.865135908126831
Validation loss: 2.1175409952799478

Epoch: 5| Step: 1
Training loss: 1.0556319952011108
Validation loss: 2.1542150725920997

Epoch: 5| Step: 2
Training loss: 0.5649412274360657
Validation loss: 2.176804299155871

Epoch: 5| Step: 3
Training loss: 0.7347596287727356
Validation loss: 2.1105808715025582

Epoch: 5| Step: 4
Training loss: 0.6435181498527527
Validation loss: 2.140822942058245

Epoch: 5| Step: 5
Training loss: 1.0669710636138916
Validation loss: 2.1088673075040183

Epoch: 5| Step: 6
Training loss: 0.7437738180160522
Validation loss: 2.198195810119311

Epoch: 5| Step: 7
Training loss: 1.3538506031036377
Validation loss: 2.1703230241934457

Epoch: 5| Step: 8
Training loss: 1.2920420169830322
Validation loss: 2.0977424482504525

Epoch: 5| Step: 9
Training loss: 0.4678596556186676
Validation loss: 2.220976769924164

Epoch: 5| Step: 10
Training loss: 1.5862067937850952
Validation loss: 2.1036570171515145

Epoch: 5| Step: 11
Training loss: 1.414843201637268
Validation loss: 2.074282060066859

Epoch: 292| Step: 0
Training loss: 0.6972072720527649
Validation loss: 2.1637223859628043

Epoch: 5| Step: 1
Training loss: 0.9350164532661438
Validation loss: 2.0884737571080527

Epoch: 5| Step: 2
Training loss: 1.1041451692581177
Validation loss: 2.20523938536644

Epoch: 5| Step: 3
Training loss: 1.4769394397735596
Validation loss: 2.151601731777191

Epoch: 5| Step: 4
Training loss: 0.9355924725532532
Validation loss: 2.153525690237681

Epoch: 5| Step: 5
Training loss: 0.7325313687324524
Validation loss: 2.2010355790456138

Epoch: 5| Step: 6
Training loss: 1.3616564273834229
Validation loss: 2.174568017323812

Epoch: 5| Step: 7
Training loss: 1.1226660013198853
Validation loss: 2.102657879392306

Epoch: 5| Step: 8
Training loss: 1.219652771949768
Validation loss: 2.2042511701583862

Epoch: 5| Step: 9
Training loss: 0.892859160900116
Validation loss: 2.1884009738763175

Epoch: 5| Step: 10
Training loss: 1.499026894569397
Validation loss: 2.0897292544444404

Epoch: 5| Step: 11
Training loss: 1.1719093322753906
Validation loss: 2.1698288222153983

Epoch: 293| Step: 0
Training loss: 1.07893705368042
Validation loss: 2.1244869927565255

Epoch: 5| Step: 1
Training loss: 1.002340316772461
Validation loss: 2.1390542834997177

Epoch: 5| Step: 2
Training loss: 1.109589695930481
Validation loss: 2.163394490877787

Epoch: 5| Step: 3
Training loss: 1.2936732769012451
Validation loss: 2.213690087199211

Epoch: 5| Step: 4
Training loss: 1.1334145069122314
Validation loss: 2.1801056067148843

Epoch: 5| Step: 5
Training loss: 0.8058287501335144
Validation loss: 2.142896552880605

Epoch: 5| Step: 6
Training loss: 1.176312804222107
Validation loss: 2.20073231558005

Epoch: 5| Step: 7
Training loss: 0.6958869695663452
Validation loss: 2.1780195087194443

Epoch: 5| Step: 8
Training loss: 1.1175262928009033
Validation loss: 2.160772686203321

Epoch: 5| Step: 9
Training loss: 1.3603990077972412
Validation loss: 2.097053309281667

Epoch: 5| Step: 10
Training loss: 1.111840009689331
Validation loss: 2.17487171292305

Epoch: 5| Step: 11
Training loss: 0.7965974807739258
Validation loss: 2.091126322746277

Epoch: 294| Step: 0
Training loss: 1.0678184032440186
Validation loss: 2.1900179584821067

Epoch: 5| Step: 1
Training loss: 0.8581653833389282
Validation loss: 2.129766354958216

Epoch: 5| Step: 2
Training loss: 0.8561155200004578
Validation loss: 2.173600902160009

Epoch: 5| Step: 3
Training loss: 0.9976779818534851
Validation loss: 2.1281442244847617

Epoch: 5| Step: 4
Training loss: 1.275960922241211
Validation loss: 2.1717721670866013

Epoch: 5| Step: 5
Training loss: 1.6234416961669922
Validation loss: 2.0840234210093818

Epoch: 5| Step: 6
Training loss: 1.4934314489364624
Validation loss: 2.065744921565056

Epoch: 5| Step: 7
Training loss: 0.8229662775993347
Validation loss: 2.100746045509974

Epoch: 5| Step: 8
Training loss: 0.9912868738174438
Validation loss: 2.1307128916184106

Epoch: 5| Step: 9
Training loss: 0.8487520217895508
Validation loss: 2.136391431093216

Epoch: 5| Step: 10
Training loss: 1.1514657735824585
Validation loss: 2.0670057932535806

Epoch: 5| Step: 11
Training loss: 1.0523772239685059
Validation loss: 2.09714042643706

Epoch: 295| Step: 0
Training loss: 1.0569484233856201
Validation loss: 2.100184808174769

Epoch: 5| Step: 1
Training loss: 1.425416350364685
Validation loss: 2.1338943441708884

Epoch: 5| Step: 2
Training loss: 0.994982123374939
Validation loss: 2.1559635351101556

Epoch: 5| Step: 3
Training loss: 0.8642641305923462
Validation loss: 2.1907858848571777

Epoch: 5| Step: 4
Training loss: 1.3999013900756836
Validation loss: 2.11241152882576

Epoch: 5| Step: 5
Training loss: 1.0577892065048218
Validation loss: 2.1417176574468613

Epoch: 5| Step: 6
Training loss: 0.7318639755249023
Validation loss: 2.162766695022583

Epoch: 5| Step: 7
Training loss: 0.8327913284301758
Validation loss: 2.172888378302256

Epoch: 5| Step: 8
Training loss: 0.6921641826629639
Validation loss: 2.1483532041311264

Epoch: 5| Step: 9
Training loss: 1.3588025569915771
Validation loss: 2.1360044280687966

Epoch: 5| Step: 10
Training loss: 1.3432447910308838
Validation loss: 2.0616425275802612

Epoch: 5| Step: 11
Training loss: 0.24290019273757935
Validation loss: 2.0894306351741156

Epoch: 296| Step: 0
Training loss: 0.9629376530647278
Validation loss: 2.176390325029691

Epoch: 5| Step: 1
Training loss: 0.8567412495613098
Validation loss: 2.127969736854235

Epoch: 5| Step: 2
Training loss: 1.1442219018936157
Validation loss: 2.1099415024121604

Epoch: 5| Step: 3
Training loss: 0.6920472383499146
Validation loss: 2.1597659389177957

Epoch: 5| Step: 4
Training loss: 1.3247020244598389
Validation loss: 2.105596140027046

Epoch: 5| Step: 5
Training loss: 1.189410924911499
Validation loss: 2.0728026380141578

Epoch: 5| Step: 6
Training loss: 1.1676452159881592
Validation loss: 2.189498787124952

Epoch: 5| Step: 7
Training loss: 1.20319402217865
Validation loss: 2.1344192872444787

Epoch: 5| Step: 8
Training loss: 1.2287883758544922
Validation loss: 2.1077307562033334

Epoch: 5| Step: 9
Training loss: 1.1725362539291382
Validation loss: 2.1254355063041053

Epoch: 5| Step: 10
Training loss: 0.9404864311218262
Validation loss: 2.060062358776728

Epoch: 5| Step: 11
Training loss: 1.486457347869873
Validation loss: 2.1322113623221717

Epoch: 297| Step: 0
Training loss: 0.825583279132843
Validation loss: 2.178225100040436

Epoch: 5| Step: 1
Training loss: 1.4704949855804443
Validation loss: 2.149694378177325

Epoch: 5| Step: 2
Training loss: 1.01596200466156
Validation loss: 2.105300505956014

Epoch: 5| Step: 3
Training loss: 1.1047991514205933
Validation loss: 2.1058470954497657

Epoch: 5| Step: 4
Training loss: 1.3952319622039795
Validation loss: 2.147875428199768

Epoch: 5| Step: 5
Training loss: 1.11891770362854
Validation loss: 2.185075839360555

Epoch: 5| Step: 6
Training loss: 1.1847007274627686
Validation loss: 2.155167187253634

Epoch: 5| Step: 7
Training loss: 1.4328819513320923
Validation loss: 2.141126881043116

Epoch: 5| Step: 8
Training loss: 0.8854225277900696
Validation loss: 2.0763912200927734

Epoch: 5| Step: 9
Training loss: 0.8550370335578918
Validation loss: 2.151806761821111

Epoch: 5| Step: 10
Training loss: 0.6977313756942749
Validation loss: 2.163744732737541

Epoch: 5| Step: 11
Training loss: 2.3931078910827637
Validation loss: 2.175597901145617

Epoch: 298| Step: 0
Training loss: 1.1204001903533936
Validation loss: 2.123279099663099

Epoch: 5| Step: 1
Training loss: 1.0175889730453491
Validation loss: 2.1950877706209817

Epoch: 5| Step: 2
Training loss: 0.7826345562934875
Validation loss: 2.1143812338511148

Epoch: 5| Step: 3
Training loss: 0.7417211532592773
Validation loss: 2.1759352584679923

Epoch: 5| Step: 4
Training loss: 1.328954815864563
Validation loss: 2.1629670908053718

Epoch: 5| Step: 5
Training loss: 1.355730414390564
Validation loss: 2.129543741544088

Epoch: 5| Step: 6
Training loss: 0.9200252294540405
Validation loss: 2.0798680931329727

Epoch: 5| Step: 7
Training loss: 0.7184010744094849
Validation loss: 2.1240517993768058

Epoch: 5| Step: 8
Training loss: 1.0761148929595947
Validation loss: 2.1171086927254996

Epoch: 5| Step: 9
Training loss: 0.7506745457649231
Validation loss: 2.1613667060931525

Epoch: 5| Step: 10
Training loss: 1.4688230752944946
Validation loss: 2.1030778189500174

Epoch: 5| Step: 11
Training loss: 0.7762541770935059
Validation loss: 2.1428346633911133

Epoch: 299| Step: 0
Training loss: 0.7272250652313232
Validation loss: 2.081235552827517

Epoch: 5| Step: 1
Training loss: 0.7649377584457397
Validation loss: 2.1399517258008323

Epoch: 5| Step: 2
Training loss: 0.7356746792793274
Validation loss: 2.17118963599205

Epoch: 5| Step: 3
Training loss: 0.8241437077522278
Validation loss: 2.1301410496234894

Epoch: 5| Step: 4
Training loss: 1.012036681175232
Validation loss: 2.1474627008040748

Epoch: 5| Step: 5
Training loss: 0.9336961507797241
Validation loss: 2.11126708984375

Epoch: 5| Step: 6
Training loss: 1.8188345432281494
Validation loss: 2.1747815956672034

Epoch: 5| Step: 7
Training loss: 0.8588916659355164
Validation loss: 2.125026226043701

Epoch: 5| Step: 8
Training loss: 1.562155842781067
Validation loss: 2.0551024774710336

Epoch: 5| Step: 9
Training loss: 0.915652871131897
Validation loss: 2.1651285042365394

Epoch: 5| Step: 10
Training loss: 1.3310937881469727
Validation loss: 2.1388225853443146

Epoch: 5| Step: 11
Training loss: 1.7247322797775269
Validation loss: 2.105119749903679

Epoch: 300| Step: 0
Training loss: 1.556372046470642
Validation loss: 2.1474573065837226

Epoch: 5| Step: 1
Training loss: 0.8570891618728638
Validation loss: 2.1107826928297677

Epoch: 5| Step: 2
Training loss: 0.9496258497238159
Validation loss: 2.1402858942747116

Epoch: 5| Step: 3
Training loss: 1.1139624118804932
Validation loss: 2.1955676078796387

Epoch: 5| Step: 4
Training loss: 1.3000972270965576
Validation loss: 2.213439186414083

Epoch: 5| Step: 5
Training loss: 0.8751535415649414
Validation loss: 2.1128111481666565

Epoch: 5| Step: 6
Training loss: 0.8574914932250977
Validation loss: 2.218008726835251

Epoch: 5| Step: 7
Training loss: 0.7902828454971313
Validation loss: 2.2050926436980567

Epoch: 5| Step: 8
Training loss: 0.9774695634841919
Validation loss: 2.1623867203791938

Epoch: 5| Step: 9
Training loss: 1.078179121017456
Validation loss: 2.1752152343591056

Epoch: 5| Step: 10
Training loss: 1.2011607885360718
Validation loss: 2.1112939715385437

Epoch: 5| Step: 11
Training loss: 1.347792148590088
Validation loss: 2.2216217617193856

Epoch: 301| Step: 0
Training loss: 1.1660581827163696
Validation loss: 2.124278316895167

Epoch: 5| Step: 1
Training loss: 0.6595199108123779
Validation loss: 2.226172849535942

Epoch: 5| Step: 2
Training loss: 1.1364134550094604
Validation loss: 2.1484189877907434

Epoch: 5| Step: 3
Training loss: 1.1996835470199585
Validation loss: 2.069650247693062

Epoch: 5| Step: 4
Training loss: 1.1735341548919678
Validation loss: 2.1599602848291397

Epoch: 5| Step: 5
Training loss: 0.7801828384399414
Validation loss: 2.1888262828191123

Epoch: 5| Step: 6
Training loss: 0.9206143617630005
Validation loss: 2.1594917476177216

Epoch: 5| Step: 7
Training loss: 0.8207752108573914
Validation loss: 2.112300142645836

Epoch: 5| Step: 8
Training loss: 1.011556625366211
Validation loss: 2.2314091324806213

Epoch: 5| Step: 9
Training loss: 1.3619436025619507
Validation loss: 2.2103376189867654

Epoch: 5| Step: 10
Training loss: 1.2423055171966553
Validation loss: 2.232482979695002

Epoch: 5| Step: 11
Training loss: 1.3928282260894775
Validation loss: 2.194686641295751

Epoch: 302| Step: 0
Training loss: 0.8670827150344849
Validation loss: 2.261164421836535

Epoch: 5| Step: 1
Training loss: 1.1236135959625244
Validation loss: 2.083805521329244

Epoch: 5| Step: 2
Training loss: 0.8942452669143677
Validation loss: 2.179597869515419

Epoch: 5| Step: 3
Training loss: 0.9970315098762512
Validation loss: 2.144949500759443

Epoch: 5| Step: 4
Training loss: 1.3004801273345947
Validation loss: 2.0688017904758453

Epoch: 5| Step: 5
Training loss: 1.0185222625732422
Validation loss: 2.169102276364962

Epoch: 5| Step: 6
Training loss: 0.8641740083694458
Validation loss: 2.108507921298345

Epoch: 5| Step: 7
Training loss: 1.4086182117462158
Validation loss: 2.1329130679368973

Epoch: 5| Step: 8
Training loss: 1.0095980167388916
Validation loss: 2.107096095879873

Epoch: 5| Step: 9
Training loss: 1.0117453336715698
Validation loss: 2.2236370742321014

Epoch: 5| Step: 10
Training loss: 0.9466805458068848
Validation loss: 2.147522449493408

Epoch: 5| Step: 11
Training loss: 1.5779591798782349
Validation loss: 2.232248211900393

Epoch: 303| Step: 0
Training loss: 0.9692555665969849
Validation loss: 2.1145155280828476

Epoch: 5| Step: 1
Training loss: 1.1652514934539795
Validation loss: 2.195360243320465

Epoch: 5| Step: 2
Training loss: 1.2121975421905518
Validation loss: 2.1638931185007095

Epoch: 5| Step: 3
Training loss: 1.0862162113189697
Validation loss: 2.104146217306455

Epoch: 5| Step: 4
Training loss: 1.017327070236206
Validation loss: 2.1430008908112845

Epoch: 5| Step: 5
Training loss: 1.0198930501937866
Validation loss: 2.1327089915672937

Epoch: 5| Step: 6
Training loss: 1.228046178817749
Validation loss: 2.1551923205455146

Epoch: 5| Step: 7
Training loss: 0.7893890142440796
Validation loss: 2.171598588426908

Epoch: 5| Step: 8
Training loss: 0.7268624901771545
Validation loss: 2.113671511411667

Epoch: 5| Step: 9
Training loss: 1.0061496496200562
Validation loss: 2.164708529909452

Epoch: 5| Step: 10
Training loss: 0.699906051158905
Validation loss: 2.0388724158207574

Epoch: 5| Step: 11
Training loss: 3.3342642784118652
Validation loss: 2.145655627051989

Epoch: 304| Step: 0
Training loss: 1.156958818435669
Validation loss: 2.075796604156494

Epoch: 5| Step: 1
Training loss: 0.8679744601249695
Validation loss: 2.2081753263870874

Epoch: 5| Step: 2
Training loss: 1.0722568035125732
Validation loss: 2.176263689994812

Epoch: 5| Step: 3
Training loss: 1.1446444988250732
Validation loss: 2.190876310070356

Epoch: 5| Step: 4
Training loss: 0.7563015222549438
Validation loss: 2.0682622690995536

Epoch: 5| Step: 5
Training loss: 0.9194024801254272
Validation loss: 2.098325942953428

Epoch: 5| Step: 6
Training loss: 0.8315297961235046
Validation loss: 2.2128556619087854

Epoch: 5| Step: 7
Training loss: 0.9150373339653015
Validation loss: 2.133276949326197

Epoch: 5| Step: 8
Training loss: 1.0248947143554688
Validation loss: 2.167029316226641

Epoch: 5| Step: 9
Training loss: 1.5647997856140137
Validation loss: 2.1323124965031943

Epoch: 5| Step: 10
Training loss: 0.9977145195007324
Validation loss: 2.1625871111949286

Epoch: 5| Step: 11
Training loss: 0.6131204962730408
Validation loss: 2.161488691965739

Epoch: 305| Step: 0
Training loss: 0.8771361112594604
Validation loss: 2.0651783496141434

Epoch: 5| Step: 1
Training loss: 1.1240661144256592
Validation loss: 2.2577351282040277

Epoch: 5| Step: 2
Training loss: 1.050446629524231
Validation loss: 2.1046051383018494

Epoch: 5| Step: 3
Training loss: 0.8831756711006165
Validation loss: 2.1463500459988913

Epoch: 5| Step: 4
Training loss: 0.7026357054710388
Validation loss: 2.1610384583473206

Epoch: 5| Step: 5
Training loss: 1.207969307899475
Validation loss: 2.1660053531328836

Epoch: 5| Step: 6
Training loss: 0.9542616605758667
Validation loss: 2.1769243677457175

Epoch: 5| Step: 7
Training loss: 0.9130718111991882
Validation loss: 2.15200604001681

Epoch: 5| Step: 8
Training loss: 1.1400935649871826
Validation loss: 2.1861090660095215

Epoch: 5| Step: 9
Training loss: 0.8048783540725708
Validation loss: 2.1019363751014075

Epoch: 5| Step: 10
Training loss: 1.4687473773956299
Validation loss: 2.148540531595548

Epoch: 5| Step: 11
Training loss: 1.5394320487976074
Validation loss: 2.1441203455130258

Epoch: 306| Step: 0
Training loss: 1.1218348741531372
Validation loss: 2.1221276919047036

Epoch: 5| Step: 1
Training loss: 1.2157938480377197
Validation loss: 2.1231844325860343

Epoch: 5| Step: 2
Training loss: 1.0717490911483765
Validation loss: 2.0750778019428253

Epoch: 5| Step: 3
Training loss: 1.1083452701568604
Validation loss: 2.209366907676061

Epoch: 5| Step: 4
Training loss: 1.3358653783798218
Validation loss: 2.1847614645957947

Epoch: 5| Step: 5
Training loss: 1.1719468832015991
Validation loss: 2.0845385690530143

Epoch: 5| Step: 6
Training loss: 1.3731327056884766
Validation loss: 2.221653461456299

Epoch: 5| Step: 7
Training loss: 1.2144638299942017
Validation loss: 2.2132225831349692

Epoch: 5| Step: 8
Training loss: 0.7948765754699707
Validation loss: 2.1419264326492944

Epoch: 5| Step: 9
Training loss: 0.8900405168533325
Validation loss: 2.1328508158524833

Epoch: 5| Step: 10
Training loss: 0.8689826726913452
Validation loss: 2.1593386779228845

Epoch: 5| Step: 11
Training loss: 0.4752182364463806
Validation loss: 2.1229380816221237

Epoch: 307| Step: 0
Training loss: 1.0267670154571533
Validation loss: 2.0991779615481696

Epoch: 5| Step: 1
Training loss: 0.8564950227737427
Validation loss: 2.104494576652845

Epoch: 5| Step: 2
Training loss: 1.4389183521270752
Validation loss: 2.0705093244711557

Epoch: 5| Step: 3
Training loss: 0.8635088205337524
Validation loss: 2.0596207777659097

Epoch: 5| Step: 4
Training loss: 0.8668051958084106
Validation loss: 2.156745582818985

Epoch: 5| Step: 5
Training loss: 1.045244812965393
Validation loss: 2.1397248208522797

Epoch: 5| Step: 6
Training loss: 0.8982242345809937
Validation loss: 2.0924130976200104

Epoch: 5| Step: 7
Training loss: 1.2398518323898315
Validation loss: 2.0910891195138297

Epoch: 5| Step: 8
Training loss: 1.0928704738616943
Validation loss: 2.1505873699982962

Epoch: 5| Step: 9
Training loss: 1.241696834564209
Validation loss: 2.091295823454857

Epoch: 5| Step: 10
Training loss: 1.0588247776031494
Validation loss: 2.148700401186943

Epoch: 5| Step: 11
Training loss: 1.2495107650756836
Validation loss: 2.1359897553920746

Epoch: 308| Step: 0
Training loss: 1.4142088890075684
Validation loss: 2.1158712108929953

Epoch: 5| Step: 1
Training loss: 0.6666409373283386
Validation loss: 2.143567750851313

Epoch: 5| Step: 2
Training loss: 0.5750118494033813
Validation loss: 2.1089111665884652

Epoch: 5| Step: 3
Training loss: 1.0745736360549927
Validation loss: 2.1217575669288635

Epoch: 5| Step: 4
Training loss: 1.2561105489730835
Validation loss: 2.100485468904177

Epoch: 5| Step: 5
Training loss: 0.8563499450683594
Validation loss: 2.1221087723970413

Epoch: 5| Step: 6
Training loss: 1.1556886434555054
Validation loss: 2.182567829887072

Epoch: 5| Step: 7
Training loss: 1.093252420425415
Validation loss: 2.1366367489099503

Epoch: 5| Step: 8
Training loss: 1.0087887048721313
Validation loss: 2.126260682940483

Epoch: 5| Step: 9
Training loss: 0.9759725332260132
Validation loss: 2.166992644468943

Epoch: 5| Step: 10
Training loss: 1.0287929773330688
Validation loss: 2.1887606183687844

Epoch: 5| Step: 11
Training loss: 1.179960012435913
Validation loss: 2.1141035109758377

Epoch: 309| Step: 0
Training loss: 0.8469641804695129
Validation loss: 2.157793641090393

Epoch: 5| Step: 1
Training loss: 1.1182302236557007
Validation loss: 2.0830059399207435

Epoch: 5| Step: 2
Training loss: 0.9390401840209961
Validation loss: 2.116168811917305

Epoch: 5| Step: 3
Training loss: 1.433363914489746
Validation loss: 2.1647188117106757

Epoch: 5| Step: 4
Training loss: 0.8600403666496277
Validation loss: 2.188956633210182

Epoch: 5| Step: 5
Training loss: 1.2828190326690674
Validation loss: 2.214352086186409

Epoch: 5| Step: 6
Training loss: 1.0758779048919678
Validation loss: 2.1145701507727304

Epoch: 5| Step: 7
Training loss: 1.033866047859192
Validation loss: 2.167700916528702

Epoch: 5| Step: 8
Training loss: 1.4342968463897705
Validation loss: 2.113333930571874

Epoch: 5| Step: 9
Training loss: 0.5951231718063354
Validation loss: 2.1897389193375907

Epoch: 5| Step: 10
Training loss: 0.9677221179008484
Validation loss: 2.159399295846621

Epoch: 5| Step: 11
Training loss: 1.7719273567199707
Validation loss: 2.201988533139229

Epoch: 310| Step: 0
Training loss: 0.8614007234573364
Validation loss: 2.230221023162206

Epoch: 5| Step: 1
Training loss: 1.370849847793579
Validation loss: 2.2165919890006385

Epoch: 5| Step: 2
Training loss: 1.0350494384765625
Validation loss: 2.341466794411341

Epoch: 5| Step: 3
Training loss: 1.0543034076690674
Validation loss: 2.222115541497866

Epoch: 5| Step: 4
Training loss: 0.5154269933700562
Validation loss: 2.100631500283877

Epoch: 5| Step: 5
Training loss: 0.7855454683303833
Validation loss: 2.12796343366305

Epoch: 5| Step: 6
Training loss: 1.1616294384002686
Validation loss: 2.142497956752777

Epoch: 5| Step: 7
Training loss: 1.2464511394500732
Validation loss: 2.131160780787468

Epoch: 5| Step: 8
Training loss: 1.6703113317489624
Validation loss: 2.177309403816859

Epoch: 5| Step: 9
Training loss: 0.7785005569458008
Validation loss: 2.2210704485575357

Epoch: 5| Step: 10
Training loss: 1.2382187843322754
Validation loss: 2.1787411024173102

Epoch: 5| Step: 11
Training loss: 1.201882004737854
Validation loss: 2.1420345505078635

Epoch: 311| Step: 0
Training loss: 0.6584852933883667
Validation loss: 2.2650552690029144

Epoch: 5| Step: 1
Training loss: 1.1578022241592407
Validation loss: 2.3362876127163568

Epoch: 5| Step: 2
Training loss: 1.267704963684082
Validation loss: 2.2667256643374762

Epoch: 5| Step: 3
Training loss: 1.3279297351837158
Validation loss: 2.228646402557691

Epoch: 5| Step: 4
Training loss: 1.0739949941635132
Validation loss: 2.239930013815562

Epoch: 5| Step: 5
Training loss: 1.284894347190857
Validation loss: 2.1502890338500342

Epoch: 5| Step: 6
Training loss: 0.8780279159545898
Validation loss: 2.1533340215682983

Epoch: 5| Step: 7
Training loss: 1.2508265972137451
Validation loss: 2.1172954688469567

Epoch: 5| Step: 8
Training loss: 0.9647151827812195
Validation loss: 2.2345782617727914

Epoch: 5| Step: 9
Training loss: 1.1198489665985107
Validation loss: 2.1719391544659934

Epoch: 5| Step: 10
Training loss: 0.6965344548225403
Validation loss: 2.230913003285726

Epoch: 5| Step: 11
Training loss: 1.1199944019317627
Validation loss: 2.1378717720508575

Epoch: 312| Step: 0
Training loss: 0.7776778936386108
Validation loss: 2.1710993299881616

Epoch: 5| Step: 1
Training loss: 1.290246605873108
Validation loss: 2.1520571410655975

Epoch: 5| Step: 2
Training loss: 1.0818097591400146
Validation loss: 2.387100398540497

Epoch: 5| Step: 3
Training loss: 0.8614848256111145
Validation loss: 2.297579119602839

Epoch: 5| Step: 4
Training loss: 1.143943190574646
Validation loss: 2.369865983724594

Epoch: 5| Step: 5
Training loss: 1.50967538356781
Validation loss: 2.239911208550135

Epoch: 5| Step: 6
Training loss: 2.093752384185791
Validation loss: 2.2010155618190765

Epoch: 5| Step: 7
Training loss: 0.44756031036376953
Validation loss: 2.196051150560379

Epoch: 5| Step: 8
Training loss: 0.7544485926628113
Validation loss: 2.138261467218399

Epoch: 5| Step: 9
Training loss: 0.8628966212272644
Validation loss: 2.1529325544834137

Epoch: 5| Step: 10
Training loss: 1.3325812816619873
Validation loss: 2.1122742195924125

Epoch: 5| Step: 11
Training loss: 2.588165760040283
Validation loss: 2.224603439370791

Epoch: 313| Step: 0
Training loss: 1.528132438659668
Validation loss: 2.0823197215795517

Epoch: 5| Step: 1
Training loss: 0.9875065684318542
Validation loss: 2.056374286611875

Epoch: 5| Step: 2
Training loss: 1.1837505102157593
Validation loss: 2.1122333655754724

Epoch: 5| Step: 3
Training loss: 0.9692739248275757
Validation loss: 2.0484294990698495

Epoch: 5| Step: 4
Training loss: 1.025951623916626
Validation loss: 2.166675552725792

Epoch: 5| Step: 5
Training loss: 0.729076087474823
Validation loss: 2.1688514053821564

Epoch: 5| Step: 6
Training loss: 0.8183959722518921
Validation loss: 2.173068900903066

Epoch: 5| Step: 7
Training loss: 1.3208872079849243
Validation loss: 2.111686776081721

Epoch: 5| Step: 8
Training loss: 0.6240682005882263
Validation loss: 2.1138609747091928

Epoch: 5| Step: 9
Training loss: 0.7644599080085754
Validation loss: 2.1188811908165612

Epoch: 5| Step: 10
Training loss: 1.0510586500167847
Validation loss: 2.1150013556083045

Epoch: 5| Step: 11
Training loss: 1.4157960414886475
Validation loss: 2.072355901201566

Epoch: 314| Step: 0
Training loss: 1.6313045024871826
Validation loss: 2.075170715649923

Epoch: 5| Step: 1
Training loss: 0.9976731538772583
Validation loss: 2.1556473076343536

Epoch: 5| Step: 2
Training loss: 0.8660401105880737
Validation loss: 2.1340246200561523

Epoch: 5| Step: 3
Training loss: 0.998954176902771
Validation loss: 2.1918722689151764

Epoch: 5| Step: 4
Training loss: 0.7767888307571411
Validation loss: 2.1709940433502197

Epoch: 5| Step: 5
Training loss: 1.0739892721176147
Validation loss: 2.1727920323610306

Epoch: 5| Step: 6
Training loss: 0.533373236656189
Validation loss: 2.10583633184433

Epoch: 5| Step: 7
Training loss: 1.0051711797714233
Validation loss: 2.0120428850253425

Epoch: 5| Step: 8
Training loss: 0.7161210775375366
Validation loss: 2.151143491268158

Epoch: 5| Step: 9
Training loss: 1.0804845094680786
Validation loss: 2.137352228164673

Epoch: 5| Step: 10
Training loss: 1.1840598583221436
Validation loss: 2.148027072350184

Epoch: 5| Step: 11
Training loss: 0.5486733913421631
Validation loss: 2.1141797055800757

Epoch: 315| Step: 0
Training loss: 1.468306303024292
Validation loss: 2.105493331948916

Epoch: 5| Step: 1
Training loss: 0.899101734161377
Validation loss: 2.1617521742979684

Epoch: 5| Step: 2
Training loss: 0.6160649061203003
Validation loss: 2.0966291477282843

Epoch: 5| Step: 3
Training loss: 0.6808050274848938
Validation loss: 2.1529637277126312

Epoch: 5| Step: 4
Training loss: 1.0446211099624634
Validation loss: 2.1347293158372245

Epoch: 5| Step: 5
Training loss: 0.7501865029335022
Validation loss: 2.0649701406558356

Epoch: 5| Step: 6
Training loss: 1.2599527835845947
Validation loss: 2.122473736604055

Epoch: 5| Step: 7
Training loss: 1.0072380304336548
Validation loss: 2.1479299167792

Epoch: 5| Step: 8
Training loss: 1.4190709590911865
Validation loss: 2.178309972087542

Epoch: 5| Step: 9
Training loss: 0.9774425625801086
Validation loss: 2.0634804517030716

Epoch: 5| Step: 10
Training loss: 0.8543761968612671
Validation loss: 2.1600066324075065

Epoch: 5| Step: 11
Training loss: 0.4457187354564667
Validation loss: 2.208506405353546

Epoch: 316| Step: 0
Training loss: 0.9506039619445801
Validation loss: 2.1181623488664627

Epoch: 5| Step: 1
Training loss: 1.3030505180358887
Validation loss: 2.187698354323705

Epoch: 5| Step: 2
Training loss: 1.3412553071975708
Validation loss: 2.074055557449659

Epoch: 5| Step: 3
Training loss: 0.7815995812416077
Validation loss: 2.0955916394790015

Epoch: 5| Step: 4
Training loss: 0.9921520352363586
Validation loss: 2.1207738369703293

Epoch: 5| Step: 5
Training loss: 0.7211780548095703
Validation loss: 2.118758643666903

Epoch: 5| Step: 6
Training loss: 1.1244479417800903
Validation loss: 2.1621772050857544

Epoch: 5| Step: 7
Training loss: 1.0388556718826294
Validation loss: 2.1656780391931534

Epoch: 5| Step: 8
Training loss: 0.9407134056091309
Validation loss: 2.1867341746886573

Epoch: 5| Step: 9
Training loss: 1.1754435300827026
Validation loss: 2.166839142640432

Epoch: 5| Step: 10
Training loss: 1.210198163986206
Validation loss: 2.1551711410284042

Epoch: 5| Step: 11
Training loss: 0.9795343279838562
Validation loss: 2.129723608493805

Epoch: 317| Step: 0
Training loss: 1.1877683401107788
Validation loss: 2.12168188393116

Epoch: 5| Step: 1
Training loss: 0.7806174755096436
Validation loss: 2.0993692725896835

Epoch: 5| Step: 2
Training loss: 1.1479147672653198
Validation loss: 2.2007119059562683

Epoch: 5| Step: 3
Training loss: 0.6388589143753052
Validation loss: 2.1756706734498343

Epoch: 5| Step: 4
Training loss: 1.6659090518951416
Validation loss: 2.127697452902794

Epoch: 5| Step: 5
Training loss: 0.9950380325317383
Validation loss: 2.1391365428765616

Epoch: 5| Step: 6
Training loss: 0.860668957233429
Validation loss: 2.143209387858709

Epoch: 5| Step: 7
Training loss: 0.9039348363876343
Validation loss: 2.1393908063570657

Epoch: 5| Step: 8
Training loss: 1.1815688610076904
Validation loss: 2.223786403735479

Epoch: 5| Step: 9
Training loss: 1.077174186706543
Validation loss: 2.103606720765432

Epoch: 5| Step: 10
Training loss: 0.7094460725784302
Validation loss: 2.1779205749432244

Epoch: 5| Step: 11
Training loss: 0.8116052150726318
Validation loss: 2.218096395333608

Epoch: 318| Step: 0
Training loss: 0.8825178146362305
Validation loss: 2.1975089261929193

Epoch: 5| Step: 1
Training loss: 1.5017898082733154
Validation loss: 2.1610521028439202

Epoch: 5| Step: 2
Training loss: 1.4299124479293823
Validation loss: 2.127496416370074

Epoch: 5| Step: 3
Training loss: 1.0951759815216064
Validation loss: 2.184431125720342

Epoch: 5| Step: 4
Training loss: 0.8258762359619141
Validation loss: 2.161260947585106

Epoch: 5| Step: 5
Training loss: 1.0504858493804932
Validation loss: 2.226493855317434

Epoch: 5| Step: 6
Training loss: 1.139923095703125
Validation loss: 2.110955332716306

Epoch: 5| Step: 7
Training loss: 1.0055385828018188
Validation loss: 2.2073186536629996

Epoch: 5| Step: 8
Training loss: 0.7716402411460876
Validation loss: 2.2239125072956085

Epoch: 5| Step: 9
Training loss: 0.8218919038772583
Validation loss: 2.159902503093084

Epoch: 5| Step: 10
Training loss: 0.9405509233474731
Validation loss: 2.1452146669228873

Epoch: 5| Step: 11
Training loss: 1.6317697763442993
Validation loss: 2.18462943037351

Epoch: 319| Step: 0
Training loss: 1.199784517288208
Validation loss: 2.1184021731217704

Epoch: 5| Step: 1
Training loss: 1.053687334060669
Validation loss: 2.1486554543177285

Epoch: 5| Step: 2
Training loss: 1.143143892288208
Validation loss: 2.099809775749842

Epoch: 5| Step: 3
Training loss: 0.40208783745765686
Validation loss: 2.065449222922325

Epoch: 5| Step: 4
Training loss: 1.2451493740081787
Validation loss: 2.157199333111445

Epoch: 5| Step: 5
Training loss: 1.0776336193084717
Validation loss: 2.0845375806093216

Epoch: 5| Step: 6
Training loss: 0.9658159017562866
Validation loss: 2.1523102124532065

Epoch: 5| Step: 7
Training loss: 1.062547206878662
Validation loss: 2.165312811732292

Epoch: 5| Step: 8
Training loss: 0.7754595875740051
Validation loss: 2.1569794515768685

Epoch: 5| Step: 9
Training loss: 0.8072745203971863
Validation loss: 2.092465619246165

Epoch: 5| Step: 10
Training loss: 0.9083834886550903
Validation loss: 2.1957293450832367

Epoch: 5| Step: 11
Training loss: 0.22927254438400269
Validation loss: 2.1607811053593955

Epoch: 320| Step: 0
Training loss: 0.742835283279419
Validation loss: 2.1613645950953164

Epoch: 5| Step: 1
Training loss: 1.1697853803634644
Validation loss: 2.130571350455284

Epoch: 5| Step: 2
Training loss: 0.766830563545227
Validation loss: 2.1118183384339013

Epoch: 5| Step: 3
Training loss: 1.3045672178268433
Validation loss: 2.130400245388349

Epoch: 5| Step: 4
Training loss: 1.3000829219818115
Validation loss: 2.1214199165503183

Epoch: 5| Step: 5
Training loss: 0.6649399995803833
Validation loss: 2.146912475426992

Epoch: 5| Step: 6
Training loss: 1.128481149673462
Validation loss: 2.173847804466883

Epoch: 5| Step: 7
Training loss: 1.4437034130096436
Validation loss: 2.176602045694987

Epoch: 5| Step: 8
Training loss: 0.6143903732299805
Validation loss: 2.1589473138252893

Epoch: 5| Step: 9
Training loss: 1.3011338710784912
Validation loss: 2.1202219327290854

Epoch: 5| Step: 10
Training loss: 0.8433018922805786
Validation loss: 2.1928991079330444

Epoch: 5| Step: 11
Training loss: 1.0569255352020264
Validation loss: 2.133121281862259

Epoch: 321| Step: 0
Training loss: 0.9086635708808899
Validation loss: 2.1772665282090506

Epoch: 5| Step: 1
Training loss: 1.0872445106506348
Validation loss: 2.1402717332045236

Epoch: 5| Step: 2
Training loss: 1.334078311920166
Validation loss: 2.16092386841774

Epoch: 5| Step: 3
Training loss: 1.3572474718093872
Validation loss: 2.1003143191337585

Epoch: 5| Step: 4
Training loss: 1.0249626636505127
Validation loss: 2.0800833056370416

Epoch: 5| Step: 5
Training loss: 1.0560426712036133
Validation loss: 2.1663199762503305

Epoch: 5| Step: 6
Training loss: 0.96339350938797
Validation loss: 2.2027227779229483

Epoch: 5| Step: 7
Training loss: 0.650124192237854
Validation loss: 2.1864353915055594

Epoch: 5| Step: 8
Training loss: 0.9187048673629761
Validation loss: 2.1071763137976327

Epoch: 5| Step: 9
Training loss: 0.9347183108329773
Validation loss: 2.156290277838707

Epoch: 5| Step: 10
Training loss: 0.7537553310394287
Validation loss: 2.0751306265592575

Epoch: 5| Step: 11
Training loss: 0.6453944444656372
Validation loss: 2.1789924452702203

Epoch: 322| Step: 0
Training loss: 0.8361770510673523
Validation loss: 2.1195307622353234

Epoch: 5| Step: 1
Training loss: 1.4961917400360107
Validation loss: 2.143877789378166

Epoch: 5| Step: 2
Training loss: 0.9420052766799927
Validation loss: 2.088390757640203

Epoch: 5| Step: 3
Training loss: 0.8160511255264282
Validation loss: 2.223096380631129

Epoch: 5| Step: 4
Training loss: 0.8410150408744812
Validation loss: 2.114582667748133

Epoch: 5| Step: 5
Training loss: 0.6293679475784302
Validation loss: 2.166864290833473

Epoch: 5| Step: 6
Training loss: 1.0120010375976562
Validation loss: 2.107701227068901

Epoch: 5| Step: 7
Training loss: 0.6749881505966187
Validation loss: 2.0941002617279687

Epoch: 5| Step: 8
Training loss: 1.2826368808746338
Validation loss: 2.064113959670067

Epoch: 5| Step: 9
Training loss: 0.9296806454658508
Validation loss: 2.1610728601614633

Epoch: 5| Step: 10
Training loss: 0.8604463338851929
Validation loss: 2.1689651906490326

Epoch: 5| Step: 11
Training loss: 1.4128299951553345
Validation loss: 2.118039146065712

Epoch: 323| Step: 0
Training loss: 1.4034700393676758
Validation loss: 2.1745216945807138

Epoch: 5| Step: 1
Training loss: 0.9426677823066711
Validation loss: 2.0817220956087112

Epoch: 5| Step: 2
Training loss: 1.0074697732925415
Validation loss: 2.114371140797933

Epoch: 5| Step: 3
Training loss: 0.8442047238349915
Validation loss: 2.2008189757665

Epoch: 5| Step: 4
Training loss: 0.9217058420181274
Validation loss: 2.1845134695370994

Epoch: 5| Step: 5
Training loss: 1.0929160118103027
Validation loss: 2.2147091825803122

Epoch: 5| Step: 6
Training loss: 1.011284351348877
Validation loss: 2.141969710588455

Epoch: 5| Step: 7
Training loss: 0.9072502851486206
Validation loss: 2.119685187935829

Epoch: 5| Step: 8
Training loss: 1.1696312427520752
Validation loss: 2.096271738409996

Epoch: 5| Step: 9
Training loss: 0.7207452058792114
Validation loss: 2.139761452873548

Epoch: 5| Step: 10
Training loss: 0.986200213432312
Validation loss: 2.159880737463633

Epoch: 5| Step: 11
Training loss: 1.161466121673584
Validation loss: 2.1935796489318213

Epoch: 324| Step: 0
Training loss: 0.8642207980155945
Validation loss: 2.2226244310537973

Epoch: 5| Step: 1
Training loss: 1.4095642566680908
Validation loss: 2.171186919013659

Epoch: 5| Step: 2
Training loss: 1.0808159112930298
Validation loss: 2.1699866702159247

Epoch: 5| Step: 3
Training loss: 1.260790467262268
Validation loss: 2.161194086074829

Epoch: 5| Step: 4
Training loss: 0.8522381782531738
Validation loss: 2.149448017279307

Epoch: 5| Step: 5
Training loss: 0.8009435534477234
Validation loss: 2.2211965719858804

Epoch: 5| Step: 6
Training loss: 0.8472129702568054
Validation loss: 2.202156792084376

Epoch: 5| Step: 7
Training loss: 0.9927471280097961
Validation loss: 2.253530502319336

Epoch: 5| Step: 8
Training loss: 1.496946930885315
Validation loss: 2.1409760465224585

Epoch: 5| Step: 9
Training loss: 0.7982264757156372
Validation loss: 2.13792285323143

Epoch: 5| Step: 10
Training loss: 0.5724964141845703
Validation loss: 2.116231953104337

Epoch: 5| Step: 11
Training loss: 0.9623569250106812
Validation loss: 2.1449821293354034

Epoch: 325| Step: 0
Training loss: 1.1062471866607666
Validation loss: 2.134801760315895

Epoch: 5| Step: 1
Training loss: 0.6958395838737488
Validation loss: 2.153324062625567

Epoch: 5| Step: 2
Training loss: 1.0317695140838623
Validation loss: 2.1030384997526803

Epoch: 5| Step: 3
Training loss: 0.693825364112854
Validation loss: 2.161355117956797

Epoch: 5| Step: 4
Training loss: 1.2548460960388184
Validation loss: 2.109330097834269

Epoch: 5| Step: 5
Training loss: 1.1281147003173828
Validation loss: 2.148069923122724

Epoch: 5| Step: 6
Training loss: 0.8242511749267578
Validation loss: 2.0811153252919516

Epoch: 5| Step: 7
Training loss: 0.6275614500045776
Validation loss: 2.1908401350180307

Epoch: 5| Step: 8
Training loss: 0.8468599319458008
Validation loss: 2.1967016011476517

Epoch: 5| Step: 9
Training loss: 0.789071798324585
Validation loss: 2.2277830094099045

Epoch: 5| Step: 10
Training loss: 0.9295015335083008
Validation loss: 2.1941977043946586

Epoch: 5| Step: 11
Training loss: 2.5026328563690186
Validation loss: 2.1333428670962653

Epoch: 326| Step: 0
Training loss: 1.0131021738052368
Validation loss: 2.2228223433097205

Epoch: 5| Step: 1
Training loss: 0.9591013789176941
Validation loss: 2.1083886424700418

Epoch: 5| Step: 2
Training loss: 0.6911731958389282
Validation loss: 2.1343212326367698

Epoch: 5| Step: 3
Training loss: 0.9209185838699341
Validation loss: 2.236263950665792

Epoch: 5| Step: 4
Training loss: 0.963911235332489
Validation loss: 2.115594521164894

Epoch: 5| Step: 5
Training loss: 0.8658170700073242
Validation loss: 2.1617316404978433

Epoch: 5| Step: 6
Training loss: 0.7070282697677612
Validation loss: 2.1833311120669046

Epoch: 5| Step: 7
Training loss: 1.1935352087020874
Validation loss: 2.1786913871765137

Epoch: 5| Step: 8
Training loss: 0.7079620957374573
Validation loss: 2.0966509332259498

Epoch: 5| Step: 9
Training loss: 1.1492582559585571
Validation loss: 2.1514833718538284

Epoch: 5| Step: 10
Training loss: 1.1704474687576294
Validation loss: 2.092865844567617

Epoch: 5| Step: 11
Training loss: 1.231433391571045
Validation loss: 2.227451200286547

Epoch: 327| Step: 0
Training loss: 1.0431474447250366
Validation loss: 2.2250458349784217

Epoch: 5| Step: 1
Training loss: 0.8416627049446106
Validation loss: 2.163722967108091

Epoch: 5| Step: 2
Training loss: 1.1355087757110596
Validation loss: 2.159704570968946

Epoch: 5| Step: 3
Training loss: 0.7767303586006165
Validation loss: 2.123092696070671

Epoch: 5| Step: 4
Training loss: 0.9746975898742676
Validation loss: 2.165844311316808

Epoch: 5| Step: 5
Training loss: 0.8482881784439087
Validation loss: 2.2368589689334235

Epoch: 5| Step: 6
Training loss: 0.9807578325271606
Validation loss: 2.1233607729276023

Epoch: 5| Step: 7
Training loss: 0.8732942342758179
Validation loss: 2.1282819906870523

Epoch: 5| Step: 8
Training loss: 1.073289155960083
Validation loss: 2.1452146569887796

Epoch: 5| Step: 9
Training loss: 1.2437827587127686
Validation loss: 2.117062817017237

Epoch: 5| Step: 10
Training loss: 0.5681982636451721
Validation loss: 2.1375327706336975

Epoch: 5| Step: 11
Training loss: 0.5663618445396423
Validation loss: 2.11997885008653

Epoch: 328| Step: 0
Training loss: 1.2075055837631226
Validation loss: 2.1326055775086084

Epoch: 5| Step: 1
Training loss: 0.8552311658859253
Validation loss: 2.0749309410651526

Epoch: 5| Step: 2
Training loss: 0.5803016424179077
Validation loss: 2.1454079300165176

Epoch: 5| Step: 3
Training loss: 0.886947512626648
Validation loss: 2.1546045194069543

Epoch: 5| Step: 4
Training loss: 0.8360705375671387
Validation loss: 2.14855232834816

Epoch: 5| Step: 5
Training loss: 1.5000532865524292
Validation loss: 2.091415762901306

Epoch: 5| Step: 6
Training loss: 1.0318403244018555
Validation loss: 2.0597637047370276

Epoch: 5| Step: 7
Training loss: 0.8912738561630249
Validation loss: 2.163091113169988

Epoch: 5| Step: 8
Training loss: 1.0809977054595947
Validation loss: 2.1492050935824714

Epoch: 5| Step: 9
Training loss: 1.0681053400039673
Validation loss: 2.0876767486333847

Epoch: 5| Step: 10
Training loss: 0.7999909520149231
Validation loss: 2.196524277329445

Epoch: 5| Step: 11
Training loss: 0.8053253889083862
Validation loss: 2.0995913793643317

Epoch: 329| Step: 0
Training loss: 0.6994152069091797
Validation loss: 2.1143278032541275

Epoch: 5| Step: 1
Training loss: 1.0156489610671997
Validation loss: 2.1553276230891547

Epoch: 5| Step: 2
Training loss: 0.9879451990127563
Validation loss: 2.103009353081385

Epoch: 5| Step: 3
Training loss: 1.0108245611190796
Validation loss: 2.1259986758232117

Epoch: 5| Step: 4
Training loss: 1.3457581996917725
Validation loss: 2.114561835924784

Epoch: 5| Step: 5
Training loss: 0.7920413017272949
Validation loss: 2.143157477180163

Epoch: 5| Step: 6
Training loss: 0.7293569445610046
Validation loss: 2.1409835666418076

Epoch: 5| Step: 7
Training loss: 1.3763025999069214
Validation loss: 2.1515230536460876

Epoch: 5| Step: 8
Training loss: 1.1083273887634277
Validation loss: 2.1636643360058465

Epoch: 5| Step: 9
Training loss: 0.753036379814148
Validation loss: 2.155672868092855

Epoch: 5| Step: 10
Training loss: 1.0603258609771729
Validation loss: 2.0964042941729226

Epoch: 5| Step: 11
Training loss: 1.362334132194519
Validation loss: 2.128031298518181

Epoch: 330| Step: 0
Training loss: 0.949959933757782
Validation loss: 2.051318640510241

Epoch: 5| Step: 1
Training loss: 1.1327927112579346
Validation loss: 2.1239229142665863

Epoch: 5| Step: 2
Training loss: 0.7249403595924377
Validation loss: 2.1179284354050956

Epoch: 5| Step: 3
Training loss: 0.6761419773101807
Validation loss: 2.110405201713244

Epoch: 5| Step: 4
Training loss: 0.6931127309799194
Validation loss: 2.1400878727436066

Epoch: 5| Step: 5
Training loss: 1.316091775894165
Validation loss: 2.060590381423632

Epoch: 5| Step: 6
Training loss: 1.3390988111495972
Validation loss: 2.1781755785147348

Epoch: 5| Step: 7
Training loss: 0.9220108985900879
Validation loss: 2.0803710520267487

Epoch: 5| Step: 8
Training loss: 0.7491518259048462
Validation loss: 2.1350293109814324

Epoch: 5| Step: 9
Training loss: 0.7340558767318726
Validation loss: 2.142072672645251

Epoch: 5| Step: 10
Training loss: 1.1597979068756104
Validation loss: 2.195516973733902

Epoch: 5| Step: 11
Training loss: 1.44283926486969
Validation loss: 2.1618854850530624

Epoch: 331| Step: 0
Training loss: 1.3419965505599976
Validation loss: 2.138737067580223

Epoch: 5| Step: 1
Training loss: 0.6366984844207764
Validation loss: 2.1977378080288568

Epoch: 5| Step: 2
Training loss: 0.9995449185371399
Validation loss: 2.166523536046346

Epoch: 5| Step: 3
Training loss: 0.6626503467559814
Validation loss: 2.17281810939312

Epoch: 5| Step: 4
Training loss: 0.9994617700576782
Validation loss: 2.125777617096901

Epoch: 5| Step: 5
Training loss: 0.9461735486984253
Validation loss: 2.1276736110448837

Epoch: 5| Step: 6
Training loss: 1.3864803314208984
Validation loss: 2.1672697365283966

Epoch: 5| Step: 7
Training loss: 0.8772586584091187
Validation loss: 2.1108335504929223

Epoch: 5| Step: 8
Training loss: 1.062506914138794
Validation loss: 2.0979457795619965

Epoch: 5| Step: 9
Training loss: 0.5840588212013245
Validation loss: 2.075296233097712

Epoch: 5| Step: 10
Training loss: 0.9402545690536499
Validation loss: 2.1745461374521255

Epoch: 5| Step: 11
Training loss: 0.3970631957054138
Validation loss: 2.128751814365387

Epoch: 332| Step: 0
Training loss: 0.9853655099868774
Validation loss: 2.115222603082657

Epoch: 5| Step: 1
Training loss: 0.7800816297531128
Validation loss: 2.136730079849561

Epoch: 5| Step: 2
Training loss: 1.0907495021820068
Validation loss: 2.1506692270437875

Epoch: 5| Step: 3
Training loss: 1.078261137008667
Validation loss: 2.105933422843615

Epoch: 5| Step: 4
Training loss: 1.0382121801376343
Validation loss: 2.2494511157274246

Epoch: 5| Step: 5
Training loss: 1.0101823806762695
Validation loss: 2.1715231587489447

Epoch: 5| Step: 6
Training loss: 1.1039936542510986
Validation loss: 2.1219047904014587

Epoch: 5| Step: 7
Training loss: 0.6328778266906738
Validation loss: 2.182455653945605

Epoch: 5| Step: 8
Training loss: 1.024098515510559
Validation loss: 2.1216879387696586

Epoch: 5| Step: 9
Training loss: 0.9327061772346497
Validation loss: 2.1670056084791818

Epoch: 5| Step: 10
Training loss: 0.667060375213623
Validation loss: 2.128064746658007

Epoch: 5| Step: 11
Training loss: 0.5131885409355164
Validation loss: 2.1413510193427405

Epoch: 333| Step: 0
Training loss: 0.8344337344169617
Validation loss: 2.0791787008444467

Epoch: 5| Step: 1
Training loss: 0.9097617864608765
Validation loss: 2.092738375067711

Epoch: 5| Step: 2
Training loss: 1.1731330156326294
Validation loss: 2.143887092669805

Epoch: 5| Step: 3
Training loss: 0.8114597201347351
Validation loss: 2.1766890535751977

Epoch: 5| Step: 4
Training loss: 1.3852078914642334
Validation loss: 2.190320909023285

Epoch: 5| Step: 5
Training loss: 1.1073733568191528
Validation loss: 2.1860966831445694

Epoch: 5| Step: 6
Training loss: 0.8321760296821594
Validation loss: 2.136890267332395

Epoch: 5| Step: 7
Training loss: 0.5702269673347473
Validation loss: 2.196805953979492

Epoch: 5| Step: 8
Training loss: 0.5181509852409363
Validation loss: 2.115047519405683

Epoch: 5| Step: 9
Training loss: 0.7682917714118958
Validation loss: 2.1322540988524756

Epoch: 5| Step: 10
Training loss: 1.2083051204681396
Validation loss: 2.1628844837347665

Epoch: 5| Step: 11
Training loss: 0.4624606966972351
Validation loss: 2.1054801444212594

Epoch: 334| Step: 0
Training loss: 0.7359007596969604
Validation loss: 2.1161563644806543

Epoch: 5| Step: 1
Training loss: 0.7312606573104858
Validation loss: 2.069756974776586

Epoch: 5| Step: 2
Training loss: 0.6029542684555054
Validation loss: 2.188966602087021

Epoch: 5| Step: 3
Training loss: 0.8074246644973755
Validation loss: 2.2162095457315445

Epoch: 5| Step: 4
Training loss: 0.8754454851150513
Validation loss: 2.165569414695104

Epoch: 5| Step: 5
Training loss: 0.7358980178833008
Validation loss: 2.2170112977425256

Epoch: 5| Step: 6
Training loss: 1.123291015625
Validation loss: 2.1706363459428153

Epoch: 5| Step: 7
Training loss: 1.1176761388778687
Validation loss: 2.166651258865992

Epoch: 5| Step: 8
Training loss: 1.1967079639434814
Validation loss: 2.1223597079515457

Epoch: 5| Step: 9
Training loss: 1.199997901916504
Validation loss: 2.1364665726820626

Epoch: 5| Step: 10
Training loss: 0.9550660848617554
Validation loss: 2.0579640567302704

Epoch: 5| Step: 11
Training loss: 0.22767645120620728
Validation loss: 2.073548197746277

Epoch: 335| Step: 0
Training loss: 0.9437606930732727
Validation loss: 2.1557228912909827

Epoch: 5| Step: 1
Training loss: 1.472956657409668
Validation loss: 2.1114870806535087

Epoch: 5| Step: 2
Training loss: 0.8381932377815247
Validation loss: 2.0909350216388702

Epoch: 5| Step: 3
Training loss: 0.8356797099113464
Validation loss: 2.1316580971082053

Epoch: 5| Step: 4
Training loss: 1.2631762027740479
Validation loss: 2.147103786468506

Epoch: 5| Step: 5
Training loss: 0.6371091604232788
Validation loss: 2.1371309012174606

Epoch: 5| Step: 6
Training loss: 0.8312211036682129
Validation loss: 2.132637823621432

Epoch: 5| Step: 7
Training loss: 1.5696684122085571
Validation loss: 2.151920070250829

Epoch: 5| Step: 8
Training loss: 0.6197144389152527
Validation loss: 2.1801808923482895

Epoch: 5| Step: 9
Training loss: 0.5262728929519653
Validation loss: 2.176744977633158

Epoch: 5| Step: 10
Training loss: 0.7630432844161987
Validation loss: 2.094763696193695

Epoch: 5| Step: 11
Training loss: 1.4122862815856934
Validation loss: 2.1662943611542382

Epoch: 336| Step: 0
Training loss: 1.004945993423462
Validation loss: 2.1293483475844064

Epoch: 5| Step: 1
Training loss: 0.789603590965271
Validation loss: 2.1484074791272483

Epoch: 5| Step: 2
Training loss: 0.7393438220024109
Validation loss: 2.1128804087638855

Epoch: 5| Step: 3
Training loss: 0.9095922708511353
Validation loss: 2.1395598153273263

Epoch: 5| Step: 4
Training loss: 0.8849539756774902
Validation loss: 2.1012819359699884

Epoch: 5| Step: 5
Training loss: 0.6651169061660767
Validation loss: 2.138188819090525

Epoch: 5| Step: 6
Training loss: 1.754809021949768
Validation loss: 2.205059508482615

Epoch: 5| Step: 7
Training loss: 1.3033998012542725
Validation loss: 2.129456266760826

Epoch: 5| Step: 8
Training loss: 1.0609722137451172
Validation loss: 2.1272695461908975

Epoch: 5| Step: 9
Training loss: 0.8134772181510925
Validation loss: 2.1975187907616296

Epoch: 5| Step: 10
Training loss: 0.8878172039985657
Validation loss: 2.0843725899855294

Epoch: 5| Step: 11
Training loss: 0.9527411460876465
Validation loss: 2.1061013837655387

Epoch: 337| Step: 0
Training loss: 1.2477973699569702
Validation loss: 2.114248295625051

Epoch: 5| Step: 1
Training loss: 0.43883436918258667
Validation loss: 2.1433592637379966

Epoch: 5| Step: 2
Training loss: 0.8281269073486328
Validation loss: 2.110664948821068

Epoch: 5| Step: 3
Training loss: 1.1392343044281006
Validation loss: 2.0784977773825326

Epoch: 5| Step: 4
Training loss: 0.7203711271286011
Validation loss: 2.12344628572464

Epoch: 5| Step: 5
Training loss: 1.0098596811294556
Validation loss: 2.1194721460342407

Epoch: 5| Step: 6
Training loss: 0.6019870638847351
Validation loss: 2.1990954677263894

Epoch: 5| Step: 7
Training loss: 0.9286335706710815
Validation loss: 2.155380075176557

Epoch: 5| Step: 8
Training loss: 0.8745946884155273
Validation loss: 2.139552722374598

Epoch: 5| Step: 9
Training loss: 0.7054599523544312
Validation loss: 2.1055469612280526

Epoch: 5| Step: 10
Training loss: 1.0778800249099731
Validation loss: 2.0909320215384164

Epoch: 5| Step: 11
Training loss: 2.3088393211364746
Validation loss: 2.171913425127665

Epoch: 338| Step: 0
Training loss: 0.892987847328186
Validation loss: 2.2216124484936395

Epoch: 5| Step: 1
Training loss: 1.1756188869476318
Validation loss: 2.2061905562877655

Epoch: 5| Step: 2
Training loss: 0.7724517583847046
Validation loss: 2.189454029003779

Epoch: 5| Step: 3
Training loss: 1.1952450275421143
Validation loss: 2.269969920317332

Epoch: 5| Step: 4
Training loss: 0.8356137275695801
Validation loss: 2.14588392774264

Epoch: 5| Step: 5
Training loss: 0.5108147263526917
Validation loss: 2.127255837122599

Epoch: 5| Step: 6
Training loss: 0.9839754104614258
Validation loss: 2.097293575604757

Epoch: 5| Step: 7
Training loss: 0.9858735799789429
Validation loss: 2.127148320277532

Epoch: 5| Step: 8
Training loss: 1.2717126607894897
Validation loss: 2.1058176706234613

Epoch: 5| Step: 9
Training loss: 1.0128748416900635
Validation loss: 2.2152630587418876

Epoch: 5| Step: 10
Training loss: 0.8252881765365601
Validation loss: 2.125391254822413

Epoch: 5| Step: 11
Training loss: 0.3327234983444214
Validation loss: 2.1321922143300376

Epoch: 339| Step: 0
Training loss: 0.961786150932312
Validation loss: 2.079347471396128

Epoch: 5| Step: 1
Training loss: 0.5827935338020325
Validation loss: 2.1124355594317117

Epoch: 5| Step: 2
Training loss: 0.9875818490982056
Validation loss: 2.1395502984523773

Epoch: 5| Step: 3
Training loss: 1.2089611291885376
Validation loss: 2.156367594997088

Epoch: 5| Step: 4
Training loss: 0.8018922805786133
Validation loss: 2.1362847139437995

Epoch: 5| Step: 5
Training loss: 0.6931672692298889
Validation loss: 2.199163337548574

Epoch: 5| Step: 6
Training loss: 1.356603741645813
Validation loss: 2.1538700312376022

Epoch: 5| Step: 7
Training loss: 0.8878231048583984
Validation loss: 2.117642809947332

Epoch: 5| Step: 8
Training loss: 0.8766319155693054
Validation loss: 2.2222447792689004

Epoch: 5| Step: 9
Training loss: 0.7239020466804504
Validation loss: 2.1580040901899338

Epoch: 5| Step: 10
Training loss: 0.7933415174484253
Validation loss: 2.168940469622612

Epoch: 5| Step: 11
Training loss: 0.28671854734420776
Validation loss: 2.146388992667198

Epoch: 340| Step: 0
Training loss: 1.2362194061279297
Validation loss: 2.125244970122973

Epoch: 5| Step: 1
Training loss: 0.868852972984314
Validation loss: 2.191495214899381

Epoch: 5| Step: 2
Training loss: 1.295326828956604
Validation loss: 2.1460729936758676

Epoch: 5| Step: 3
Training loss: 1.1070505380630493
Validation loss: 2.1470185816287994

Epoch: 5| Step: 4
Training loss: 1.03110671043396
Validation loss: 2.126851866642634

Epoch: 5| Step: 5
Training loss: 0.6907159090042114
Validation loss: 2.183119982481003

Epoch: 5| Step: 6
Training loss: 0.9093982577323914
Validation loss: 2.2164886395136514

Epoch: 5| Step: 7
Training loss: 0.6315183043479919
Validation loss: 2.159980371594429

Epoch: 5| Step: 8
Training loss: 1.2774606943130493
Validation loss: 2.1406151801347733

Epoch: 5| Step: 9
Training loss: 0.8131961822509766
Validation loss: 2.1839016377925873

Epoch: 5| Step: 10
Training loss: 1.156485915184021
Validation loss: 2.1118329713741937

Epoch: 5| Step: 11
Training loss: 2.6223104000091553
Validation loss: 2.0551190773646035

Epoch: 341| Step: 0
Training loss: 0.9926842451095581
Validation loss: 2.19101149837176

Epoch: 5| Step: 1
Training loss: 0.9740597009658813
Validation loss: 2.0487723449865975

Epoch: 5| Step: 2
Training loss: 1.0810350179672241
Validation loss: 2.1217206617196402

Epoch: 5| Step: 3
Training loss: 0.8021464347839355
Validation loss: 2.1242855489254

Epoch: 5| Step: 4
Training loss: 0.7892564535140991
Validation loss: 2.1443061381578445

Epoch: 5| Step: 5
Training loss: 1.0969523191452026
Validation loss: 2.1031665404637656

Epoch: 5| Step: 6
Training loss: 1.225023627281189
Validation loss: 2.078381155927976

Epoch: 5| Step: 7
Training loss: 0.8447386622428894
Validation loss: 2.0869392305612564

Epoch: 5| Step: 8
Training loss: 1.0221316814422607
Validation loss: 2.1434543430805206

Epoch: 5| Step: 9
Training loss: 0.5854423642158508
Validation loss: 2.12703330318133

Epoch: 5| Step: 10
Training loss: 0.5324217081069946
Validation loss: 2.1424613098303475

Epoch: 5| Step: 11
Training loss: 1.295494794845581
Validation loss: 2.152830719947815

Epoch: 342| Step: 0
Training loss: 1.1453793048858643
Validation loss: 2.093711713949839

Epoch: 5| Step: 1
Training loss: 0.6504348516464233
Validation loss: 2.136451691389084

Epoch: 5| Step: 2
Training loss: 0.5826512575149536
Validation loss: 2.156372537215551

Epoch: 5| Step: 3
Training loss: 1.298689603805542
Validation loss: 2.067309096455574

Epoch: 5| Step: 4
Training loss: 0.5939934849739075
Validation loss: 2.149210458000501

Epoch: 5| Step: 5
Training loss: 1.230713129043579
Validation loss: 2.0963126371304193

Epoch: 5| Step: 6
Training loss: 0.4941596984863281
Validation loss: 2.139269212881724

Epoch: 5| Step: 7
Training loss: 0.9865862131118774
Validation loss: 2.1783648282289505

Epoch: 5| Step: 8
Training loss: 0.7491022348403931
Validation loss: 2.139159088333448

Epoch: 5| Step: 9
Training loss: 1.0667343139648438
Validation loss: 2.112077201406161

Epoch: 5| Step: 10
Training loss: 1.4033148288726807
Validation loss: 2.1593729704618454

Epoch: 5| Step: 11
Training loss: 0.36339816451072693
Validation loss: 2.2139030545949936

Epoch: 343| Step: 0
Training loss: 1.0022804737091064
Validation loss: 2.14290089905262

Epoch: 5| Step: 1
Training loss: 1.0022634267807007
Validation loss: 2.1611160337924957

Epoch: 5| Step: 2
Training loss: 0.6092658042907715
Validation loss: 2.150402863820394

Epoch: 5| Step: 3
Training loss: 1.492706537246704
Validation loss: 2.143415888150533

Epoch: 5| Step: 4
Training loss: 0.6318503022193909
Validation loss: 2.1284929712613425

Epoch: 5| Step: 5
Training loss: 0.7382220029830933
Validation loss: 2.112354705731074

Epoch: 5| Step: 6
Training loss: 0.7138875126838684
Validation loss: 2.17865056792895

Epoch: 5| Step: 7
Training loss: 0.965213418006897
Validation loss: 2.1029396057128906

Epoch: 5| Step: 8
Training loss: 1.103711724281311
Validation loss: 2.1858518024285636

Epoch: 5| Step: 9
Training loss: 0.9299306869506836
Validation loss: 2.0967176208893457

Epoch: 5| Step: 10
Training loss: 1.0533740520477295
Validation loss: 2.217856208483378

Epoch: 5| Step: 11
Training loss: 0.22306370735168457
Validation loss: 2.136138468980789

Epoch: 344| Step: 0
Training loss: 0.6241509318351746
Validation loss: 2.1544672697782516

Epoch: 5| Step: 1
Training loss: 0.965229868888855
Validation loss: 2.1582657992839813

Epoch: 5| Step: 2
Training loss: 0.9326605796813965
Validation loss: 2.098395347595215

Epoch: 5| Step: 3
Training loss: 0.7146461606025696
Validation loss: 2.169786969820658

Epoch: 5| Step: 4
Training loss: 1.5682967901229858
Validation loss: 2.0789000391960144

Epoch: 5| Step: 5
Training loss: 0.822823703289032
Validation loss: 2.124971995751063

Epoch: 5| Step: 6
Training loss: 1.0225322246551514
Validation loss: 2.1090292682250342

Epoch: 5| Step: 7
Training loss: 0.41009721159935
Validation loss: 2.12907441953818

Epoch: 5| Step: 8
Training loss: 0.7611587047576904
Validation loss: 2.22730486591657

Epoch: 5| Step: 9
Training loss: 0.562857985496521
Validation loss: 2.1338926553726196

Epoch: 5| Step: 10
Training loss: 1.2556647062301636
Validation loss: 2.166985183954239

Epoch: 5| Step: 11
Training loss: 0.3880774676799774
Validation loss: 2.180161034067472

Epoch: 345| Step: 0
Training loss: 0.6526012420654297
Validation loss: 2.068387890855471

Epoch: 5| Step: 1
Training loss: 0.8132143020629883
Validation loss: 2.1134143273035684

Epoch: 5| Step: 2
Training loss: 1.0618094205856323
Validation loss: 2.1153357873360314

Epoch: 5| Step: 3
Training loss: 1.5184775590896606
Validation loss: 2.175380597511927

Epoch: 5| Step: 4
Training loss: 0.7531932592391968
Validation loss: 2.1667241950829825

Epoch: 5| Step: 5
Training loss: 0.6857889890670776
Validation loss: 2.1599063773949942

Epoch: 5| Step: 6
Training loss: 0.8368607759475708
Validation loss: 2.117041746775309

Epoch: 5| Step: 7
Training loss: 0.8928540349006653
Validation loss: 2.1671595126390457

Epoch: 5| Step: 8
Training loss: 0.9862747192382812
Validation loss: 2.132441759109497

Epoch: 5| Step: 9
Training loss: 0.7447178959846497
Validation loss: 2.135936896006266

Epoch: 5| Step: 10
Training loss: 0.7219131588935852
Validation loss: 2.067069505651792

Epoch: 5| Step: 11
Training loss: 0.7130253911018372
Validation loss: 2.0971340934435525

Epoch: 346| Step: 0
Training loss: 0.7620722055435181
Validation loss: 2.1755715807278952

Epoch: 5| Step: 1
Training loss: 0.6542426347732544
Validation loss: 2.113125508030256

Epoch: 5| Step: 2
Training loss: 1.5011051893234253
Validation loss: 2.1152691394090652

Epoch: 5| Step: 3
Training loss: 0.9610639810562134
Validation loss: 2.106188625097275

Epoch: 5| Step: 4
Training loss: 1.1857980489730835
Validation loss: 2.159609446922938

Epoch: 5| Step: 5
Training loss: 0.5966041684150696
Validation loss: 2.197108452518781

Epoch: 5| Step: 6
Training loss: 1.1017986536026
Validation loss: 2.208905657132467

Epoch: 5| Step: 7
Training loss: 0.7466395497322083
Validation loss: 2.2231145799160004

Epoch: 5| Step: 8
Training loss: 1.0925034284591675
Validation loss: 2.1686823715766272

Epoch: 5| Step: 9
Training loss: 0.9579863548278809
Validation loss: 2.1928549955288568

Epoch: 5| Step: 10
Training loss: 1.275534987449646
Validation loss: 2.1400286008914313

Epoch: 5| Step: 11
Training loss: 0.2311779260635376
Validation loss: 2.100140482187271

Epoch: 347| Step: 0
Training loss: 0.8926680684089661
Validation loss: 2.15450249115626

Epoch: 5| Step: 1
Training loss: 1.29617440700531
Validation loss: 2.1706627905368805

Epoch: 5| Step: 2
Training loss: 1.2298188209533691
Validation loss: 2.0990643749634423

Epoch: 5| Step: 3
Training loss: 0.9261784553527832
Validation loss: 2.137281194329262

Epoch: 5| Step: 4
Training loss: 0.6130410432815552
Validation loss: 2.041184181968371

Epoch: 5| Step: 5
Training loss: 0.6125256419181824
Validation loss: 2.120456730326017

Epoch: 5| Step: 6
Training loss: 1.3791773319244385
Validation loss: 2.1542193591594696

Epoch: 5| Step: 7
Training loss: 0.7282642722129822
Validation loss: 2.16308556497097

Epoch: 5| Step: 8
Training loss: 1.2624269723892212
Validation loss: 2.2323678384224572

Epoch: 5| Step: 9
Training loss: 0.7508941888809204
Validation loss: 2.2093287110328674

Epoch: 5| Step: 10
Training loss: 1.0006731748580933
Validation loss: 2.096121753255526

Epoch: 5| Step: 11
Training loss: 1.1779547929763794
Validation loss: 2.183712179462115

Epoch: 348| Step: 0
Training loss: 0.9396761655807495
Validation loss: 2.1432604442040124

Epoch: 5| Step: 1
Training loss: 0.8549820184707642
Validation loss: 2.1767999082803726

Epoch: 5| Step: 2
Training loss: 1.5603634119033813
Validation loss: 2.1307584245999656

Epoch: 5| Step: 3
Training loss: 1.0846399068832397
Validation loss: 2.13630448281765

Epoch: 5| Step: 4
Training loss: 1.0335772037506104
Validation loss: 2.1743880907694497

Epoch: 5| Step: 5
Training loss: 0.7598154544830322
Validation loss: 2.117109735806783

Epoch: 5| Step: 6
Training loss: 0.5014216303825378
Validation loss: 2.177711253364881

Epoch: 5| Step: 7
Training loss: 0.9043110609054565
Validation loss: 2.085331534345945

Epoch: 5| Step: 8
Training loss: 0.8141172528266907
Validation loss: 2.1860975871483483

Epoch: 5| Step: 9
Training loss: 0.9121348261833191
Validation loss: 2.136970897515615

Epoch: 5| Step: 10
Training loss: 1.3481086492538452
Validation loss: 2.1383227606614432

Epoch: 5| Step: 11
Training loss: 0.23455610871315002
Validation loss: 2.141973152756691

Epoch: 349| Step: 0
Training loss: 0.6809738278388977
Validation loss: 2.130610764026642

Epoch: 5| Step: 1
Training loss: 0.8878812789916992
Validation loss: 2.1978323260943093

Epoch: 5| Step: 2
Training loss: 0.556486189365387
Validation loss: 2.2053359697262445

Epoch: 5| Step: 3
Training loss: 0.7755910158157349
Validation loss: 2.1666482388973236

Epoch: 5| Step: 4
Training loss: 1.093104362487793
Validation loss: 2.1391675074895224

Epoch: 5| Step: 5
Training loss: 1.07674241065979
Validation loss: 2.1336552749077478

Epoch: 5| Step: 6
Training loss: 1.4332354068756104
Validation loss: 2.0810842315355935

Epoch: 5| Step: 7
Training loss: 0.6693552732467651
Validation loss: 2.113100156188011

Epoch: 5| Step: 8
Training loss: 0.8655449151992798
Validation loss: 2.1333790322144828

Epoch: 5| Step: 9
Training loss: 1.0367209911346436
Validation loss: 2.1543917655944824

Epoch: 5| Step: 10
Training loss: 0.9024818539619446
Validation loss: 2.114760105808576

Epoch: 5| Step: 11
Training loss: 0.4148958921432495
Validation loss: 2.10055144627889

Epoch: 350| Step: 0
Training loss: 0.9215496778488159
Validation loss: 2.1383419086535773

Epoch: 5| Step: 1
Training loss: 0.4666321873664856
Validation loss: 2.1620704531669617

Epoch: 5| Step: 2
Training loss: 1.1600024700164795
Validation loss: 2.1305063466231027

Epoch: 5| Step: 3
Training loss: 0.9685570597648621
Validation loss: 2.173041140039762

Epoch: 5| Step: 4
Training loss: 0.9973281025886536
Validation loss: 2.133723313609759

Epoch: 5| Step: 5
Training loss: 0.7941954731941223
Validation loss: 2.0897079010804496

Epoch: 5| Step: 6
Training loss: 0.40807971358299255
Validation loss: 2.175682937105497

Epoch: 5| Step: 7
Training loss: 1.1625990867614746
Validation loss: 2.0873535623153052

Epoch: 5| Step: 8
Training loss: 0.7632429599761963
Validation loss: 2.1587091386318207

Epoch: 5| Step: 9
Training loss: 1.1950559616088867
Validation loss: 2.1124965300162635

Epoch: 5| Step: 10
Training loss: 0.7950724363327026
Validation loss: 2.162746195991834

Epoch: 5| Step: 11
Training loss: 0.8906800150871277
Validation loss: 2.1675151785214744

Epoch: 351| Step: 0
Training loss: 0.8248445391654968
Validation loss: 2.1367345800002417

Epoch: 5| Step: 1
Training loss: 0.7192314863204956
Validation loss: 2.115021084745725

Epoch: 5| Step: 2
Training loss: 1.0150668621063232
Validation loss: 2.194571723540624

Epoch: 5| Step: 3
Training loss: 0.8499920964241028
Validation loss: 2.230053881804148

Epoch: 5| Step: 4
Training loss: 1.1786495447158813
Validation loss: 2.1289284030596414

Epoch: 5| Step: 5
Training loss: 0.9812313914299011
Validation loss: 2.1160854498545327

Epoch: 5| Step: 6
Training loss: 1.0888025760650635
Validation loss: 2.1651112735271454

Epoch: 5| Step: 7
Training loss: 0.3155122995376587
Validation loss: 2.1033050318559012

Epoch: 5| Step: 8
Training loss: 0.8222882151603699
Validation loss: 2.127201279004415

Epoch: 5| Step: 9
Training loss: 0.7424376010894775
Validation loss: 2.164886156717936

Epoch: 5| Step: 10
Training loss: 0.6068571209907532
Validation loss: 2.1444318890571594

Epoch: 5| Step: 11
Training loss: 1.0085530281066895
Validation loss: 2.148851533730825

Epoch: 352| Step: 0
Training loss: 0.748031735420227
Validation loss: 2.1341818422079086

Epoch: 5| Step: 1
Training loss: 0.9775111079216003
Validation loss: 2.0929161061843238

Epoch: 5| Step: 2
Training loss: 0.8611199259757996
Validation loss: 2.0370060056447983

Epoch: 5| Step: 3
Training loss: 0.9311107397079468
Validation loss: 2.1841040352980294

Epoch: 5| Step: 4
Training loss: 1.061172366142273
Validation loss: 2.128485624988874

Epoch: 5| Step: 5
Training loss: 1.7494598627090454
Validation loss: 2.167627880970637

Epoch: 5| Step: 6
Training loss: 0.7263733148574829
Validation loss: 2.188910643259684

Epoch: 5| Step: 7
Training loss: 0.6352887153625488
Validation loss: 2.13444713751475

Epoch: 5| Step: 8
Training loss: 0.9232724905014038
Validation loss: 2.1746926506360373

Epoch: 5| Step: 9
Training loss: 0.8112495541572571
Validation loss: 2.134884183605512

Epoch: 5| Step: 10
Training loss: 0.4191330075263977
Validation loss: 2.134651333093643

Epoch: 5| Step: 11
Training loss: 0.5279166102409363
Validation loss: 2.1564411421616874

Epoch: 353| Step: 0
Training loss: 1.0762584209442139
Validation loss: 2.035100450118383

Epoch: 5| Step: 1
Training loss: 0.8197922706604004
Validation loss: 2.109036405881246

Epoch: 5| Step: 2
Training loss: 1.0078297853469849
Validation loss: 2.122437392671903

Epoch: 5| Step: 3
Training loss: 0.69771409034729
Validation loss: 2.092864175637563

Epoch: 5| Step: 4
Training loss: 0.8498684763908386
Validation loss: 2.0654937624931335

Epoch: 5| Step: 5
Training loss: 0.9230445623397827
Validation loss: 2.218717490633329

Epoch: 5| Step: 6
Training loss: 1.0423119068145752
Validation loss: 2.158795769015948

Epoch: 5| Step: 7
Training loss: 0.5634875297546387
Validation loss: 2.1589993139108024

Epoch: 5| Step: 8
Training loss: 0.6446107625961304
Validation loss: 2.293354704976082

Epoch: 5| Step: 9
Training loss: 0.8803775906562805
Validation loss: 2.2199591298898063

Epoch: 5| Step: 10
Training loss: 1.0731662511825562
Validation loss: 2.1763763080040612

Epoch: 5| Step: 11
Training loss: 0.9113674163818359
Validation loss: 2.1645635465780892

Epoch: 354| Step: 0
Training loss: 0.9734218716621399
Validation loss: 2.1260801007350287

Epoch: 5| Step: 1
Training loss: 0.7809256911277771
Validation loss: 2.106911857922872

Epoch: 5| Step: 2
Training loss: 1.032714605331421
Validation loss: 2.1537262350320816

Epoch: 5| Step: 3
Training loss: 0.7168418765068054
Validation loss: 2.109305972854296

Epoch: 5| Step: 4
Training loss: 1.6517088413238525
Validation loss: 2.1472780456145606

Epoch: 5| Step: 5
Training loss: 0.6800847053527832
Validation loss: 2.183352530002594

Epoch: 5| Step: 6
Training loss: 1.2529200315475464
Validation loss: 2.1624828527371087

Epoch: 5| Step: 7
Training loss: 0.5439483523368835
Validation loss: 2.1779218216737113

Epoch: 5| Step: 8
Training loss: 0.9194612503051758
Validation loss: 2.2338762432336807

Epoch: 5| Step: 9
Training loss: 0.668851375579834
Validation loss: 2.2370413641134896

Epoch: 5| Step: 10
Training loss: 1.1334693431854248
Validation loss: 2.1535686403512955

Epoch: 5| Step: 11
Training loss: 1.3564382791519165
Validation loss: 2.141731917858124

Epoch: 355| Step: 0
Training loss: 1.3493303060531616
Validation loss: 2.1231189916531243

Epoch: 5| Step: 1
Training loss: 0.8630388379096985
Validation loss: 2.1169113318125405

Epoch: 5| Step: 2
Training loss: 0.8402067422866821
Validation loss: 2.1699662456909814

Epoch: 5| Step: 3
Training loss: 1.3137626647949219
Validation loss: 2.1602552781502404

Epoch: 5| Step: 4
Training loss: 1.0939671993255615
Validation loss: 2.137746145327886

Epoch: 5| Step: 5
Training loss: 1.3351058959960938
Validation loss: 2.1105112582445145

Epoch: 5| Step: 6
Training loss: 0.89380943775177
Validation loss: 2.0780254701773324

Epoch: 5| Step: 7
Training loss: 1.0338990688323975
Validation loss: 2.2559614529212317

Epoch: 5| Step: 8
Training loss: 0.6190465092658997
Validation loss: 2.2199789583683014

Epoch: 5| Step: 9
Training loss: 1.2186776399612427
Validation loss: 2.2368795722723007

Epoch: 5| Step: 10
Training loss: 1.0512406826019287
Validation loss: 2.3040797412395477

Epoch: 5| Step: 11
Training loss: 0.5732553005218506
Validation loss: 2.1768266558647156

Epoch: 356| Step: 0
Training loss: 0.8181007504463196
Validation loss: 2.1560646146535873

Epoch: 5| Step: 1
Training loss: 0.7619891166687012
Validation loss: 2.110596314072609

Epoch: 5| Step: 2
Training loss: 1.0531737804412842
Validation loss: 2.1240433057149253

Epoch: 5| Step: 3
Training loss: 0.7527391314506531
Validation loss: 2.1570862283309302

Epoch: 5| Step: 4
Training loss: 1.167614221572876
Validation loss: 2.0775601118803024

Epoch: 5| Step: 5
Training loss: 0.9989833831787109
Validation loss: 2.1651603877544403

Epoch: 5| Step: 6
Training loss: 0.9434342384338379
Validation loss: 2.1211566478013992

Epoch: 5| Step: 7
Training loss: 1.096213459968567
Validation loss: 2.108385309576988

Epoch: 5| Step: 8
Training loss: 1.28092360496521
Validation loss: 2.190737783908844

Epoch: 5| Step: 9
Training loss: 0.7618241310119629
Validation loss: 2.15924563507239

Epoch: 5| Step: 10
Training loss: 1.0349905490875244
Validation loss: 2.2164213756720224

Epoch: 5| Step: 11
Training loss: 0.6143935918807983
Validation loss: 2.2005787640810013

Epoch: 357| Step: 0
Training loss: 1.606284737586975
Validation loss: 2.2869276801745095

Epoch: 5| Step: 1
Training loss: 0.9163627624511719
Validation loss: 2.130428751309713

Epoch: 5| Step: 2
Training loss: 1.1842963695526123
Validation loss: 2.1113994220892587

Epoch: 5| Step: 3
Training loss: 0.6827758550643921
Validation loss: 2.1443471908569336

Epoch: 5| Step: 4
Training loss: 1.1863147020339966
Validation loss: 2.0566548655430474

Epoch: 5| Step: 5
Training loss: 0.6636298894882202
Validation loss: 2.0911847203969955

Epoch: 5| Step: 6
Training loss: 1.234573483467102
Validation loss: 2.154286672671636

Epoch: 5| Step: 7
Training loss: 0.7787770628929138
Validation loss: 2.069769859313965

Epoch: 5| Step: 8
Training loss: 0.8321115374565125
Validation loss: 2.1565238386392593

Epoch: 5| Step: 9
Training loss: 0.7825406193733215
Validation loss: 2.071034441391627

Epoch: 5| Step: 10
Training loss: 0.9676691293716431
Validation loss: 2.1764253079891205

Epoch: 5| Step: 11
Training loss: 0.17100147902965546
Validation loss: 2.1547700564066568

Epoch: 358| Step: 0
Training loss: 0.7194820046424866
Validation loss: 2.1388738652070365

Epoch: 5| Step: 1
Training loss: 1.3955928087234497
Validation loss: 2.1652276118596396

Epoch: 5| Step: 2
Training loss: 0.7923165559768677
Validation loss: 2.119681636492411

Epoch: 5| Step: 3
Training loss: 0.8422072529792786
Validation loss: 2.166707843542099

Epoch: 5| Step: 4
Training loss: 0.9025033712387085
Validation loss: 2.095342849691709

Epoch: 5| Step: 5
Training loss: 0.6206761598587036
Validation loss: 2.1379820803801217

Epoch: 5| Step: 6
Training loss: 1.246132254600525
Validation loss: 2.177404676874479

Epoch: 5| Step: 7
Training loss: 1.1002801656723022
Validation loss: 2.12253945072492

Epoch: 5| Step: 8
Training loss: 0.8264971971511841
Validation loss: 2.0970733563105264

Epoch: 5| Step: 9
Training loss: 1.4007148742675781
Validation loss: 2.0770178884267807

Epoch: 5| Step: 10
Training loss: 0.6886013150215149
Validation loss: 2.184883177280426

Epoch: 5| Step: 11
Training loss: 0.422957181930542
Validation loss: 2.1747536907593408

Epoch: 359| Step: 0
Training loss: 1.1277751922607422
Validation loss: 2.1693491836388907

Epoch: 5| Step: 1
Training loss: 0.6785944104194641
Validation loss: 2.1900523553291955

Epoch: 5| Step: 2
Training loss: 0.5734344720840454
Validation loss: 2.136868327856064

Epoch: 5| Step: 3
Training loss: 1.1262567043304443
Validation loss: 2.1159724791844687

Epoch: 5| Step: 4
Training loss: 0.8341388702392578
Validation loss: 2.184997017184893

Epoch: 5| Step: 5
Training loss: 0.835253894329071
Validation loss: 2.1212512453397117

Epoch: 5| Step: 6
Training loss: 1.0063152313232422
Validation loss: 2.0906969010829926

Epoch: 5| Step: 7
Training loss: 0.6775471568107605
Validation loss: 2.174577757716179

Epoch: 5| Step: 8
Training loss: 0.9197267293930054
Validation loss: 2.158148725827535

Epoch: 5| Step: 9
Training loss: 0.7981410026550293
Validation loss: 2.1788787990808487

Epoch: 5| Step: 10
Training loss: 0.9042322039604187
Validation loss: 2.0937536706527076

Epoch: 5| Step: 11
Training loss: 0.28277599811553955
Validation loss: 2.1202077766259513

Epoch: 360| Step: 0
Training loss: 1.0480821132659912
Validation loss: 2.1580022672812142

Epoch: 5| Step: 1
Training loss: 0.7969217300415039
Validation loss: 2.155949463446935

Epoch: 5| Step: 2
Training loss: 0.7237012386322021
Validation loss: 2.2036513884862265

Epoch: 5| Step: 3
Training loss: 1.106880784034729
Validation loss: 2.1982778211434684

Epoch: 5| Step: 4
Training loss: 0.9313194155693054
Validation loss: 2.2231845756371817

Epoch: 5| Step: 5
Training loss: 0.8309684991836548
Validation loss: 2.1695970396200814

Epoch: 5| Step: 6
Training loss: 0.986386775970459
Validation loss: 2.1250252723693848

Epoch: 5| Step: 7
Training loss: 0.7377513647079468
Validation loss: 2.1461637914180756

Epoch: 5| Step: 8
Training loss: 0.606861412525177
Validation loss: 2.1625687976678214

Epoch: 5| Step: 9
Training loss: 1.173378348350525
Validation loss: 2.1082675059636435

Epoch: 5| Step: 10
Training loss: 0.5846414566040039
Validation loss: 2.134757161140442

Epoch: 5| Step: 11
Training loss: 2.5446150302886963
Validation loss: 2.18950854241848

Epoch: 361| Step: 0
Training loss: 0.5814608335494995
Validation loss: 2.190125788251559

Epoch: 5| Step: 1
Training loss: 0.4602874219417572
Validation loss: 2.1828800787528357

Epoch: 5| Step: 2
Training loss: 0.9156738519668579
Validation loss: 2.1540305515130362

Epoch: 5| Step: 3
Training loss: 0.7878860235214233
Validation loss: 2.1920008063316345

Epoch: 5| Step: 4
Training loss: 0.733404278755188
Validation loss: 2.1554926931858063

Epoch: 5| Step: 5
Training loss: 0.9821685552597046
Validation loss: 2.218361030022303

Epoch: 5| Step: 6
Training loss: 0.8469230532646179
Validation loss: 2.210279037555059

Epoch: 5| Step: 7
Training loss: 1.105865716934204
Validation loss: 2.185708830753962

Epoch: 5| Step: 8
Training loss: 0.7944701313972473
Validation loss: 2.236965631445249

Epoch: 5| Step: 9
Training loss: 0.8021532893180847
Validation loss: 2.2063936293125153

Epoch: 5| Step: 10
Training loss: 1.1667225360870361
Validation loss: 2.167106951276461

Epoch: 5| Step: 11
Training loss: 1.7892444133758545
Validation loss: 2.2054923673470817

Epoch: 362| Step: 0
Training loss: 0.9679906964302063
Validation loss: 2.1429714361826577

Epoch: 5| Step: 1
Training loss: 0.7781087756156921
Validation loss: 2.1595007479190826

Epoch: 5| Step: 2
Training loss: 0.8441618084907532
Validation loss: 2.1472021689017615

Epoch: 5| Step: 3
Training loss: 0.902644157409668
Validation loss: 2.1525909900665283

Epoch: 5| Step: 4
Training loss: 0.5800670981407166
Validation loss: 2.1852354307969413

Epoch: 5| Step: 5
Training loss: 1.196040391921997
Validation loss: 2.1604646146297455

Epoch: 5| Step: 6
Training loss: 1.405561089515686
Validation loss: 2.2007159938414893

Epoch: 5| Step: 7
Training loss: 0.577154815196991
Validation loss: 2.203107769290606

Epoch: 5| Step: 8
Training loss: 0.9631624221801758
Validation loss: 2.1384622355302176

Epoch: 5| Step: 9
Training loss: 0.7241018414497375
Validation loss: 2.1644325852394104

Epoch: 5| Step: 10
Training loss: 0.9566303491592407
Validation loss: 2.2007488906383514

Epoch: 5| Step: 11
Training loss: 0.4152573347091675
Validation loss: 2.1686592549085617

Epoch: 363| Step: 0
Training loss: 1.097063422203064
Validation loss: 2.173108403881391

Epoch: 5| Step: 1
Training loss: 1.0823237895965576
Validation loss: 2.149487982193629

Epoch: 5| Step: 2
Training loss: 0.8333908915519714
Validation loss: 2.101311902205149

Epoch: 5| Step: 3
Training loss: 0.7823829650878906
Validation loss: 2.2013546923796334

Epoch: 5| Step: 4
Training loss: 0.6162483096122742
Validation loss: 2.158583094676336

Epoch: 5| Step: 5
Training loss: 0.8292080760002136
Validation loss: 2.159065713485082

Epoch: 5| Step: 6
Training loss: 1.1452879905700684
Validation loss: 2.2133015592892966

Epoch: 5| Step: 7
Training loss: 1.408571481704712
Validation loss: 2.152992228666941

Epoch: 5| Step: 8
Training loss: 0.791031002998352
Validation loss: 2.096096764008204

Epoch: 5| Step: 9
Training loss: 0.8343289494514465
Validation loss: 2.1048738012711206

Epoch: 5| Step: 10
Training loss: 0.6229885220527649
Validation loss: 2.06663316488266

Epoch: 5| Step: 11
Training loss: 1.325019359588623
Validation loss: 2.098979483048121

Epoch: 364| Step: 0
Training loss: 0.9182955026626587
Validation loss: 2.1809963385264077

Epoch: 5| Step: 1
Training loss: 0.5301644206047058
Validation loss: 2.1315023799737296

Epoch: 5| Step: 2
Training loss: 0.8761459589004517
Validation loss: 2.1390776932239532

Epoch: 5| Step: 3
Training loss: 1.0268261432647705
Validation loss: 2.165571024020513

Epoch: 5| Step: 4
Training loss: 1.3023903369903564
Validation loss: 2.184424877166748

Epoch: 5| Step: 5
Training loss: 0.9028574824333191
Validation loss: 2.131766771276792

Epoch: 5| Step: 6
Training loss: 1.2429569959640503
Validation loss: 2.1758005718390145

Epoch: 5| Step: 7
Training loss: 0.6363264322280884
Validation loss: 2.1703303307294846

Epoch: 5| Step: 8
Training loss: 1.1781036853790283
Validation loss: 2.1721190363168716

Epoch: 5| Step: 9
Training loss: 0.7759339213371277
Validation loss: 2.1604629506667457

Epoch: 5| Step: 10
Training loss: 0.4472900927066803
Validation loss: 2.056094432870547

Epoch: 5| Step: 11
Training loss: 0.4348921477794647
Validation loss: 2.1871827095746994

Epoch: 365| Step: 0
Training loss: 0.9674805402755737
Validation loss: 2.138475884993871

Epoch: 5| Step: 1
Training loss: 0.8969618082046509
Validation loss: 2.1793141464392343

Epoch: 5| Step: 2
Training loss: 0.7341233491897583
Validation loss: 2.1750501592954

Epoch: 5| Step: 3
Training loss: 0.6928172707557678
Validation loss: 2.2785642643769584

Epoch: 5| Step: 4
Training loss: 1.0499796867370605
Validation loss: 2.177349731326103

Epoch: 5| Step: 5
Training loss: 0.6740537881851196
Validation loss: 2.2357838998238244

Epoch: 5| Step: 6
Training loss: 1.0243415832519531
Validation loss: 2.165207549929619

Epoch: 5| Step: 7
Training loss: 0.8773493766784668
Validation loss: 2.1741547087828317

Epoch: 5| Step: 8
Training loss: 1.1210360527038574
Validation loss: 2.1542642017205558

Epoch: 5| Step: 9
Training loss: 0.8956278562545776
Validation loss: 2.1515885343154273

Epoch: 5| Step: 10
Training loss: 0.9746567010879517
Validation loss: 2.252030367652575

Epoch: 5| Step: 11
Training loss: 0.8919321298599243
Validation loss: 2.191980799039205

Epoch: 366| Step: 0
Training loss: 0.8783577084541321
Validation loss: 2.1276129881540933

Epoch: 5| Step: 1
Training loss: 0.9572315216064453
Validation loss: 2.1131312797466912

Epoch: 5| Step: 2
Training loss: 1.1031132936477661
Validation loss: 2.1103134950002036

Epoch: 5| Step: 3
Training loss: 1.051361322402954
Validation loss: 2.179633537928263

Epoch: 5| Step: 4
Training loss: 0.8188310861587524
Validation loss: 2.173156216740608

Epoch: 5| Step: 5
Training loss: 0.7455176115036011
Validation loss: 2.234659324089686

Epoch: 5| Step: 6
Training loss: 0.7794901728630066
Validation loss: 2.180123428503672

Epoch: 5| Step: 7
Training loss: 1.1108967065811157
Validation loss: 2.134346842765808

Epoch: 5| Step: 8
Training loss: 0.6751955151557922
Validation loss: 2.125349849462509

Epoch: 5| Step: 9
Training loss: 0.6659060716629028
Validation loss: 2.165564924478531

Epoch: 5| Step: 10
Training loss: 0.7940627336502075
Validation loss: 2.095197389523188

Epoch: 5| Step: 11
Training loss: 0.2898188829421997
Validation loss: 2.128248224655787

Epoch: 367| Step: 0
Training loss: 0.6747317314147949
Validation loss: 2.128112956881523

Epoch: 5| Step: 1
Training loss: 0.837466835975647
Validation loss: 2.1237029333909354

Epoch: 5| Step: 2
Training loss: 1.0716068744659424
Validation loss: 2.072910651564598

Epoch: 5| Step: 3
Training loss: 0.6813194155693054
Validation loss: 2.093163624405861

Epoch: 5| Step: 4
Training loss: 1.2708075046539307
Validation loss: 2.1099185844262442

Epoch: 5| Step: 5
Training loss: 0.6239990592002869
Validation loss: 2.169097120563189

Epoch: 5| Step: 6
Training loss: 0.7791444659233093
Validation loss: 2.124812677502632

Epoch: 5| Step: 7
Training loss: 0.9628828167915344
Validation loss: 2.1629485487937927

Epoch: 5| Step: 8
Training loss: 1.0163781642913818
Validation loss: 2.2400978604952493

Epoch: 5| Step: 9
Training loss: 1.042590856552124
Validation loss: 2.205067122975985

Epoch: 5| Step: 10
Training loss: 0.9014352560043335
Validation loss: 2.166542192300161

Epoch: 5| Step: 11
Training loss: 0.6945235729217529
Validation loss: 2.2194087157646814

Epoch: 368| Step: 0
Training loss: 0.991458535194397
Validation loss: 2.0538846055666604

Epoch: 5| Step: 1
Training loss: 0.5598198175430298
Validation loss: 2.130436420440674

Epoch: 5| Step: 2
Training loss: 0.5492943525314331
Validation loss: 2.2000095397233963

Epoch: 5| Step: 3
Training loss: 1.0266135931015015
Validation loss: 2.176177754998207

Epoch: 5| Step: 4
Training loss: 0.9312571287155151
Validation loss: 2.081150939067205

Epoch: 5| Step: 5
Training loss: 0.7231729030609131
Validation loss: 2.1714890201886496

Epoch: 5| Step: 6
Training loss: 0.7098963856697083
Validation loss: 2.14867340028286

Epoch: 5| Step: 7
Training loss: 1.0194530487060547
Validation loss: 2.1383588860432305

Epoch: 5| Step: 8
Training loss: 1.0524433851242065
Validation loss: 2.207868362466494

Epoch: 5| Step: 9
Training loss: 1.2488738298416138
Validation loss: 2.1384829183419547

Epoch: 5| Step: 10
Training loss: 0.6797378063201904
Validation loss: 2.177209655443827

Epoch: 5| Step: 11
Training loss: 0.953518271446228
Validation loss: 2.145659143726031

Epoch: 369| Step: 0
Training loss: 0.870455265045166
Validation loss: 2.0661626060803733

Epoch: 5| Step: 1
Training loss: 0.7527644038200378
Validation loss: 2.153475215037664

Epoch: 5| Step: 2
Training loss: 1.1846745014190674
Validation loss: 2.1721916596094766

Epoch: 5| Step: 3
Training loss: 0.711688220500946
Validation loss: 2.0850215206543603

Epoch: 5| Step: 4
Training loss: 0.6325291395187378
Validation loss: 2.09668796757857

Epoch: 5| Step: 5
Training loss: 1.0371754169464111
Validation loss: 2.054542968670527

Epoch: 5| Step: 6
Training loss: 1.040418028831482
Validation loss: 2.119090219338735

Epoch: 5| Step: 7
Training loss: 1.1640396118164062
Validation loss: 2.141183465719223

Epoch: 5| Step: 8
Training loss: 0.8990437388420105
Validation loss: 2.137107700109482

Epoch: 5| Step: 9
Training loss: 0.7882511019706726
Validation loss: 2.209170197447141

Epoch: 5| Step: 10
Training loss: 0.7101561427116394
Validation loss: 2.164440924922625

Epoch: 5| Step: 11
Training loss: 0.9646418690681458
Validation loss: 2.265899340311686

Epoch: 370| Step: 0
Training loss: 0.8077012896537781
Validation loss: 2.167267178495725

Epoch: 5| Step: 1
Training loss: 0.9830533862113953
Validation loss: 2.1125967552264533

Epoch: 5| Step: 2
Training loss: 0.8348792195320129
Validation loss: 2.0884795685609183

Epoch: 5| Step: 3
Training loss: 0.5423511266708374
Validation loss: 2.09653569261233

Epoch: 5| Step: 4
Training loss: 0.9109736680984497
Validation loss: 2.055724561214447

Epoch: 5| Step: 5
Training loss: 0.7121291160583496
Validation loss: 2.1730764508247375

Epoch: 5| Step: 6
Training loss: 1.2915723323822021
Validation loss: 2.1562960197528205

Epoch: 5| Step: 7
Training loss: 0.8894755244255066
Validation loss: 2.124142716328303

Epoch: 5| Step: 8
Training loss: 0.7733352780342102
Validation loss: 2.0842291365067163

Epoch: 5| Step: 9
Training loss: 1.1571362018585205
Validation loss: 2.1216239035129547

Epoch: 5| Step: 10
Training loss: 0.9236260652542114
Validation loss: 2.167342255512873

Epoch: 5| Step: 11
Training loss: 1.678981065750122
Validation loss: 2.2254732002814612

Epoch: 371| Step: 0
Training loss: 1.1457078456878662
Validation loss: 2.245263785123825

Epoch: 5| Step: 1
Training loss: 1.0234944820404053
Validation loss: 2.271898532907168

Epoch: 5| Step: 2
Training loss: 0.7416677474975586
Validation loss: 2.269289215405782

Epoch: 5| Step: 3
Training loss: 0.7421057820320129
Validation loss: 2.1595829327901206

Epoch: 5| Step: 4
Training loss: 1.1389306783676147
Validation loss: 2.1019004782040915

Epoch: 5| Step: 5
Training loss: 1.16929030418396
Validation loss: 2.1528541495402655

Epoch: 5| Step: 6
Training loss: 0.7511895895004272
Validation loss: 2.1240743150313697

Epoch: 5| Step: 7
Training loss: 0.9044896364212036
Validation loss: 2.1523035168647766

Epoch: 5| Step: 8
Training loss: 1.5515940189361572
Validation loss: 2.0793358435233436

Epoch: 5| Step: 9
Training loss: 0.574478268623352
Validation loss: 2.124910846352577

Epoch: 5| Step: 10
Training loss: 1.171241044998169
Validation loss: 2.1846776604652405

Epoch: 5| Step: 11
Training loss: 0.5811543464660645
Validation loss: 2.2061770210663476

Epoch: 372| Step: 0
Training loss: 0.6191174387931824
Validation loss: 2.1221537590026855

Epoch: 5| Step: 1
Training loss: 0.6224532127380371
Validation loss: 2.1846477687358856

Epoch: 5| Step: 2
Training loss: 1.231411337852478
Validation loss: 2.203024685382843

Epoch: 5| Step: 3
Training loss: 0.9737316370010376
Validation loss: 2.087212840716044

Epoch: 5| Step: 4
Training loss: 1.00167715549469
Validation loss: 2.0041994005441666

Epoch: 5| Step: 5
Training loss: 1.0874090194702148
Validation loss: 2.138977641860644

Epoch: 5| Step: 6
Training loss: 0.6735484004020691
Validation loss: 2.190947045882543

Epoch: 5| Step: 7
Training loss: 0.8176828622817993
Validation loss: 2.0915633539358773

Epoch: 5| Step: 8
Training loss: 0.6329927444458008
Validation loss: 2.1165392647186914

Epoch: 5| Step: 9
Training loss: 0.6775513291358948
Validation loss: 2.051381846268972

Epoch: 5| Step: 10
Training loss: 0.7828040719032288
Validation loss: 2.166411191225052

Epoch: 5| Step: 11
Training loss: 0.6854795217514038
Validation loss: 2.1352935830752053

Epoch: 373| Step: 0
Training loss: 0.9590665698051453
Validation loss: 2.0854839185873666

Epoch: 5| Step: 1
Training loss: 0.4726697504520416
Validation loss: 2.0984278519948325

Epoch: 5| Step: 2
Training loss: 1.3368024826049805
Validation loss: 2.035674065351486

Epoch: 5| Step: 3
Training loss: 0.7890155911445618
Validation loss: 2.12949475646019

Epoch: 5| Step: 4
Training loss: 0.3943241536617279
Validation loss: 2.132308855652809

Epoch: 5| Step: 5
Training loss: 0.5208116769790649
Validation loss: 2.102700561285019

Epoch: 5| Step: 6
Training loss: 1.1625518798828125
Validation loss: 2.0870527823766074

Epoch: 5| Step: 7
Training loss: 0.6467878222465515
Validation loss: 2.061645522713661

Epoch: 5| Step: 8
Training loss: 0.8720932006835938
Validation loss: 2.106146593888601

Epoch: 5| Step: 9
Training loss: 0.8308877944946289
Validation loss: 2.1244288881619773

Epoch: 5| Step: 10
Training loss: 1.0038731098175049
Validation loss: 2.206293612718582

Epoch: 5| Step: 11
Training loss: 1.0072342157363892
Validation loss: 2.1511088609695435

Epoch: 374| Step: 0
Training loss: 0.7163614630699158
Validation loss: 2.1883422831694284

Epoch: 5| Step: 1
Training loss: 0.8353932499885559
Validation loss: 2.0852805574735007

Epoch: 5| Step: 2
Training loss: 0.7494597434997559
Validation loss: 2.117796023686727

Epoch: 5| Step: 3
Training loss: 0.5937288999557495
Validation loss: 2.150454675157865

Epoch: 5| Step: 4
Training loss: 0.6638195514678955
Validation loss: 2.239910677075386

Epoch: 5| Step: 5
Training loss: 0.9204741716384888
Validation loss: 2.141202757755915

Epoch: 5| Step: 6
Training loss: 0.40002766251564026
Validation loss: 2.200835873683294

Epoch: 5| Step: 7
Training loss: 1.1676627397537231
Validation loss: 2.207800010840098

Epoch: 5| Step: 8
Training loss: 1.2938528060913086
Validation loss: 2.1715810696283975

Epoch: 5| Step: 9
Training loss: 0.8499619364738464
Validation loss: 2.2021061182022095

Epoch: 5| Step: 10
Training loss: 0.9269921183586121
Validation loss: 2.1455771873394647

Epoch: 5| Step: 11
Training loss: 1.0893412828445435
Validation loss: 2.1609523048003516

Epoch: 375| Step: 0
Training loss: 0.6147577166557312
Validation loss: 2.1601935227711997

Epoch: 5| Step: 1
Training loss: 0.7532893419265747
Validation loss: 2.22768106063207

Epoch: 5| Step: 2
Training loss: 0.6063014268875122
Validation loss: 2.0713234345118203

Epoch: 5| Step: 3
Training loss: 0.5454367399215698
Validation loss: 2.144132301211357

Epoch: 5| Step: 4
Training loss: 0.6468836069107056
Validation loss: 2.1990099201599755

Epoch: 5| Step: 5
Training loss: 0.6423624753952026
Validation loss: 2.1452987492084503

Epoch: 5| Step: 6
Training loss: 1.2877650260925293
Validation loss: 2.1311525404453278

Epoch: 5| Step: 7
Training loss: 1.0815610885620117
Validation loss: 2.1336671809355416

Epoch: 5| Step: 8
Training loss: 0.9483340382575989
Validation loss: 2.071401074528694

Epoch: 5| Step: 9
Training loss: 0.9324228167533875
Validation loss: 2.1580000122388205

Epoch: 5| Step: 10
Training loss: 0.7379511594772339
Validation loss: 2.2226459980010986

Epoch: 5| Step: 11
Training loss: 0.7912001609802246
Validation loss: 2.1265662958224616

Epoch: 376| Step: 0
Training loss: 0.6003236770629883
Validation loss: 2.1624113818009696

Epoch: 5| Step: 1
Training loss: 0.7952166795730591
Validation loss: 2.104764277736346

Epoch: 5| Step: 2
Training loss: 0.7482759356498718
Validation loss: 2.1216001758972802

Epoch: 5| Step: 3
Training loss: 0.8967887163162231
Validation loss: 2.1353642443815866

Epoch: 5| Step: 4
Training loss: 0.8342475891113281
Validation loss: 2.1459890802701316

Epoch: 5| Step: 5
Training loss: 0.9787203073501587
Validation loss: 2.135019466280937

Epoch: 5| Step: 6
Training loss: 0.9372194409370422
Validation loss: 2.193353364864985

Epoch: 5| Step: 7
Training loss: 0.9866365194320679
Validation loss: 2.0982129722833633

Epoch: 5| Step: 8
Training loss: 0.6386231184005737
Validation loss: 2.110877960920334

Epoch: 5| Step: 9
Training loss: 0.7643542289733887
Validation loss: 2.0608820418516793

Epoch: 5| Step: 10
Training loss: 0.7427411079406738
Validation loss: 2.0802239030599594

Epoch: 5| Step: 11
Training loss: 0.27494436502456665
Validation loss: 2.1242031157016754

Epoch: 377| Step: 0
Training loss: 0.9793428182601929
Validation loss: 2.1672782003879547

Epoch: 5| Step: 1
Training loss: 1.3911911249160767
Validation loss: 2.2393130362033844

Epoch: 5| Step: 2
Training loss: 1.1086456775665283
Validation loss: 2.1446381211280823

Epoch: 5| Step: 3
Training loss: 0.6995657086372375
Validation loss: 2.1951469580332437

Epoch: 5| Step: 4
Training loss: 0.9214850664138794
Validation loss: 2.198199912905693

Epoch: 5| Step: 5
Training loss: 0.9329417943954468
Validation loss: 2.2530803928772607

Epoch: 5| Step: 6
Training loss: 0.6393759846687317
Validation loss: 2.2162995040416718

Epoch: 5| Step: 7
Training loss: 0.8214534521102905
Validation loss: 2.182449067632357

Epoch: 5| Step: 8
Training loss: 0.45879927277565
Validation loss: 2.20450296998024

Epoch: 5| Step: 9
Training loss: 0.40044617652893066
Validation loss: 2.245336393515269

Epoch: 5| Step: 10
Training loss: 1.1146643161773682
Validation loss: 2.155384590228399

Epoch: 5| Step: 11
Training loss: 2.2940521240234375
Validation loss: 2.197338496645292

Epoch: 378| Step: 0
Training loss: 0.8429714441299438
Validation loss: 2.2094140698512397

Epoch: 5| Step: 1
Training loss: 0.7066723108291626
Validation loss: 2.14336288968722

Epoch: 5| Step: 2
Training loss: 0.9932514429092407
Validation loss: 2.1151505510012307

Epoch: 5| Step: 3
Training loss: 0.4896715581417084
Validation loss: 2.140996515750885

Epoch: 5| Step: 4
Training loss: 0.8745583295822144
Validation loss: 2.150223736961683

Epoch: 5| Step: 5
Training loss: 0.5719261169433594
Validation loss: 2.213626742362976

Epoch: 5| Step: 6
Training loss: 0.8558971285820007
Validation loss: 2.1735760122537613

Epoch: 5| Step: 7
Training loss: 0.9516805410385132
Validation loss: 2.1547206242879233

Epoch: 5| Step: 8
Training loss: 0.430011510848999
Validation loss: 2.161763181289037

Epoch: 5| Step: 9
Training loss: 1.3136169910430908
Validation loss: 2.1596199721097946

Epoch: 5| Step: 10
Training loss: 0.9372519254684448
Validation loss: 2.1435968627532325

Epoch: 5| Step: 11
Training loss: 1.9100408554077148
Validation loss: 2.159279132882754

Epoch: 379| Step: 0
Training loss: 0.7879064679145813
Validation loss: 2.2238836089769998

Epoch: 5| Step: 1
Training loss: 0.8654121160507202
Validation loss: 2.1693806797266006

Epoch: 5| Step: 2
Training loss: 0.724996030330658
Validation loss: 2.1840756833553314

Epoch: 5| Step: 3
Training loss: 0.6190636157989502
Validation loss: 2.1628762235244117

Epoch: 5| Step: 4
Training loss: 0.5777484774589539
Validation loss: 2.1607204327980676

Epoch: 5| Step: 5
Training loss: 0.9904426336288452
Validation loss: 2.0277788738409677

Epoch: 5| Step: 6
Training loss: 0.7875861525535583
Validation loss: 2.142194996277491

Epoch: 5| Step: 7
Training loss: 1.0272884368896484
Validation loss: 2.1624808311462402

Epoch: 5| Step: 8
Training loss: 0.9342260360717773
Validation loss: 2.1695324778556824

Epoch: 5| Step: 9
Training loss: 1.260581374168396
Validation loss: 2.1729919215043387

Epoch: 5| Step: 10
Training loss: 0.6894909143447876
Validation loss: 2.1922275573015213

Epoch: 5| Step: 11
Training loss: 0.36471420526504517
Validation loss: 2.1200749973456063

Epoch: 380| Step: 0
Training loss: 0.8484193086624146
Validation loss: 2.194207176566124

Epoch: 5| Step: 1
Training loss: 0.5092263221740723
Validation loss: 2.1214563449223838

Epoch: 5| Step: 2
Training loss: 0.6720818281173706
Validation loss: 2.1056088904539743

Epoch: 5| Step: 3
Training loss: 0.4123679995536804
Validation loss: 2.1521638333797455

Epoch: 5| Step: 4
Training loss: 1.0643174648284912
Validation loss: 2.151805743575096

Epoch: 5| Step: 5
Training loss: 1.1650639772415161
Validation loss: 2.1368998934825263

Epoch: 5| Step: 6
Training loss: 0.8566610217094421
Validation loss: 2.1527506709098816

Epoch: 5| Step: 7
Training loss: 1.0798866748809814
Validation loss: 2.210248256723086

Epoch: 5| Step: 8
Training loss: 0.8542565107345581
Validation loss: 2.2119618356227875

Epoch: 5| Step: 9
Training loss: 0.9279724359512329
Validation loss: 2.2227827509244285

Epoch: 5| Step: 10
Training loss: 0.8300590515136719
Validation loss: 2.2535420258839927

Epoch: 5| Step: 11
Training loss: 0.4416050910949707
Validation loss: 2.189200053612391

Epoch: 381| Step: 0
Training loss: 1.0199201107025146
Validation loss: 2.1069539984067283

Epoch: 5| Step: 1
Training loss: 0.7245747447013855
Validation loss: 2.096351072192192

Epoch: 5| Step: 2
Training loss: 1.406423807144165
Validation loss: 2.117448404431343

Epoch: 5| Step: 3
Training loss: 0.8091772794723511
Validation loss: 2.2220174769560495

Epoch: 5| Step: 4
Training loss: 1.348490834236145
Validation loss: 2.1855386743942895

Epoch: 5| Step: 5
Training loss: 1.0023777484893799
Validation loss: 2.1903303811947503

Epoch: 5| Step: 6
Training loss: 0.70632004737854
Validation loss: 2.157749359806379

Epoch: 5| Step: 7
Training loss: 0.8576557040214539
Validation loss: 2.170838475227356

Epoch: 5| Step: 8
Training loss: 0.7071604132652283
Validation loss: 2.203458478053411

Epoch: 5| Step: 9
Training loss: 0.8414537310600281
Validation loss: 2.2463796635468802

Epoch: 5| Step: 10
Training loss: 0.765696108341217
Validation loss: 2.251148740450541

Epoch: 5| Step: 11
Training loss: 0.7363080978393555
Validation loss: 2.242322862148285

Epoch: 382| Step: 0
Training loss: 1.061431884765625
Validation loss: 2.1283296843369803

Epoch: 5| Step: 1
Training loss: 0.9291529655456543
Validation loss: 2.138475095232328

Epoch: 5| Step: 2
Training loss: 1.1471285820007324
Validation loss: 2.100230728586515

Epoch: 5| Step: 3
Training loss: 1.0101797580718994
Validation loss: 2.1195112466812134

Epoch: 5| Step: 4
Training loss: 0.6239988207817078
Validation loss: 2.1698863208293915

Epoch: 5| Step: 5
Training loss: 0.9927627444267273
Validation loss: 2.1009873151779175

Epoch: 5| Step: 6
Training loss: 0.6941779851913452
Validation loss: 2.1693601310253143

Epoch: 5| Step: 7
Training loss: 0.8714104890823364
Validation loss: 2.132815425594648

Epoch: 5| Step: 8
Training loss: 0.7894846796989441
Validation loss: 2.1733851234118142

Epoch: 5| Step: 9
Training loss: 0.891994297504425
Validation loss: 2.181750257809957

Epoch: 5| Step: 10
Training loss: 0.34960848093032837
Validation loss: 2.1715851376454034

Epoch: 5| Step: 11
Training loss: 0.6661256551742554
Validation loss: 2.0973336895306907

Epoch: 383| Step: 0
Training loss: 0.5385150909423828
Validation loss: 2.1775799691677094

Epoch: 5| Step: 1
Training loss: 0.6736093759536743
Validation loss: 2.157046919067701

Epoch: 5| Step: 2
Training loss: 0.52666175365448
Validation loss: 2.111677790681521

Epoch: 5| Step: 3
Training loss: 0.5650585889816284
Validation loss: 2.123441388209661

Epoch: 5| Step: 4
Training loss: 0.3748612105846405
Validation loss: 2.1534178406000137

Epoch: 5| Step: 5
Training loss: 0.9441407918930054
Validation loss: 2.154557839035988

Epoch: 5| Step: 6
Training loss: 1.209726333618164
Validation loss: 2.120456581314405

Epoch: 5| Step: 7
Training loss: 0.5396896004676819
Validation loss: 2.1224930385748544

Epoch: 5| Step: 8
Training loss: 0.8616940379142761
Validation loss: 2.139790882666906

Epoch: 5| Step: 9
Training loss: 1.1700712442398071
Validation loss: 2.2011504620313644

Epoch: 5| Step: 10
Training loss: 1.0018343925476074
Validation loss: 2.173567553361257

Epoch: 5| Step: 11
Training loss: 0.4770234227180481
Validation loss: 2.0870912621418634

Epoch: 384| Step: 0
Training loss: 0.752609133720398
Validation loss: 2.1701742311318717

Epoch: 5| Step: 1
Training loss: 0.9004871249198914
Validation loss: 2.1934444457292557

Epoch: 5| Step: 2
Training loss: 0.7546536326408386
Validation loss: 2.174667795499166

Epoch: 5| Step: 3
Training loss: 0.7751847505569458
Validation loss: 2.1462627351284027

Epoch: 5| Step: 4
Training loss: 0.5400936007499695
Validation loss: 2.1921357959508896

Epoch: 5| Step: 5
Training loss: 0.7003868818283081
Validation loss: 2.1584754288196564

Epoch: 5| Step: 6
Training loss: 0.9476755261421204
Validation loss: 2.1146457294623056

Epoch: 5| Step: 7
Training loss: 0.6934951543807983
Validation loss: 2.1969029307365417

Epoch: 5| Step: 8
Training loss: 0.8804531097412109
Validation loss: 2.1796068946520486

Epoch: 5| Step: 9
Training loss: 1.0131429433822632
Validation loss: 2.091753671566645

Epoch: 5| Step: 10
Training loss: 1.0370807647705078
Validation loss: 2.187244266271591

Epoch: 5| Step: 11
Training loss: 0.8506932258605957
Validation loss: 2.161184996366501

Epoch: 385| Step: 0
Training loss: 0.8960541486740112
Validation loss: 2.1472534835338593

Epoch: 5| Step: 1
Training loss: 0.9030288457870483
Validation loss: 2.1735871930917106

Epoch: 5| Step: 2
Training loss: 0.7945385575294495
Validation loss: 2.239187479019165

Epoch: 5| Step: 3
Training loss: 0.7872377634048462
Validation loss: 2.252641499042511

Epoch: 5| Step: 4
Training loss: 0.821681022644043
Validation loss: 2.2455349564552307

Epoch: 5| Step: 5
Training loss: 0.739975094795227
Validation loss: 2.2119754751523337

Epoch: 5| Step: 6
Training loss: 0.71613609790802
Validation loss: 2.162796954313914

Epoch: 5| Step: 7
Training loss: 0.8069364428520203
Validation loss: 2.1353308310111365

Epoch: 5| Step: 8
Training loss: 0.949640154838562
Validation loss: 2.0770868410666785

Epoch: 5| Step: 9
Training loss: 1.514305830001831
Validation loss: 2.172944481174151

Epoch: 5| Step: 10
Training loss: 1.0112212896347046
Validation loss: 2.1130375961462655

Epoch: 5| Step: 11
Training loss: 0.786190390586853
Validation loss: 2.101363350947698

Epoch: 386| Step: 0
Training loss: 1.314843773841858
Validation loss: 2.1372601687908173

Epoch: 5| Step: 1
Training loss: 0.7801123857498169
Validation loss: 2.1376245617866516

Epoch: 5| Step: 2
Training loss: 0.7124271392822266
Validation loss: 2.11509503920873

Epoch: 5| Step: 3
Training loss: 0.9951750040054321
Validation loss: 2.205628752708435

Epoch: 5| Step: 4
Training loss: 0.7095250487327576
Validation loss: 2.16805292169253

Epoch: 5| Step: 5
Training loss: 0.8491839170455933
Validation loss: 2.1953024864196777

Epoch: 5| Step: 6
Training loss: 0.8879057765007019
Validation loss: 2.1526430447896323

Epoch: 5| Step: 7
Training loss: 0.8486173748970032
Validation loss: 2.1428954054911933

Epoch: 5| Step: 8
Training loss: 0.7162914276123047
Validation loss: 2.1434867084026337

Epoch: 5| Step: 9
Training loss: 0.9189966320991516
Validation loss: 2.1659894237915673

Epoch: 5| Step: 10
Training loss: 0.621800422668457
Validation loss: 2.1354041397571564

Epoch: 5| Step: 11
Training loss: 0.5064104795455933
Validation loss: 2.15593129893144

Epoch: 387| Step: 0
Training loss: 1.1770812273025513
Validation loss: 2.199282372991244

Epoch: 5| Step: 1
Training loss: 0.2844897508621216
Validation loss: 2.160332495967547

Epoch: 5| Step: 2
Training loss: 0.9232422113418579
Validation loss: 2.148432662089666

Epoch: 5| Step: 3
Training loss: 0.5307351350784302
Validation loss: 2.140439420938492

Epoch: 5| Step: 4
Training loss: 0.9776015281677246
Validation loss: 2.1911793798208237

Epoch: 5| Step: 5
Training loss: 0.7302549481391907
Validation loss: 2.1373112897078195

Epoch: 5| Step: 6
Training loss: 0.8229231834411621
Validation loss: 2.1677442838748298

Epoch: 5| Step: 7
Training loss: 1.318375587463379
Validation loss: 2.198277235031128

Epoch: 5| Step: 8
Training loss: 0.4999573826789856
Validation loss: 2.1348691433668137

Epoch: 5| Step: 9
Training loss: 1.1271549463272095
Validation loss: 2.219988058010737

Epoch: 5| Step: 10
Training loss: 0.4028360843658447
Validation loss: 2.169144848982493

Epoch: 5| Step: 11
Training loss: 0.4503437280654907
Validation loss: 2.1319419195254645

Epoch: 388| Step: 0
Training loss: 0.680491030216217
Validation loss: 2.187701756755511

Epoch: 5| Step: 1
Training loss: 0.5365280508995056
Validation loss: 2.1638927161693573

Epoch: 5| Step: 2
Training loss: 0.6043281555175781
Validation loss: 2.2618162482976913

Epoch: 5| Step: 3
Training loss: 1.3159936666488647
Validation loss: 2.1965683499972024

Epoch: 5| Step: 4
Training loss: 0.8845950961112976
Validation loss: 2.1615855991840363

Epoch: 5| Step: 5
Training loss: 0.9386740922927856
Validation loss: 2.166278511285782

Epoch: 5| Step: 6
Training loss: 0.5996993184089661
Validation loss: 2.173647334178289

Epoch: 5| Step: 7
Training loss: 1.1534922122955322
Validation loss: 2.0948344320058823

Epoch: 5| Step: 8
Training loss: 1.0786454677581787
Validation loss: 2.197445034980774

Epoch: 5| Step: 9
Training loss: 0.5766115188598633
Validation loss: 2.1273535192012787

Epoch: 5| Step: 10
Training loss: 0.6761544942855835
Validation loss: 2.087446709473928

Epoch: 5| Step: 11
Training loss: 0.3946223855018616
Validation loss: 2.172566662232081

Epoch: 389| Step: 0
Training loss: 0.7514292597770691
Validation loss: 2.146241863568624

Epoch: 5| Step: 1
Training loss: 0.7508853673934937
Validation loss: 2.1882981409629187

Epoch: 5| Step: 2
Training loss: 0.702353298664093
Validation loss: 2.1981817384560904

Epoch: 5| Step: 3
Training loss: 0.6178046464920044
Validation loss: 2.105130672454834

Epoch: 5| Step: 4
Training loss: 1.092011570930481
Validation loss: 2.160602698723475

Epoch: 5| Step: 5
Training loss: 0.5085288882255554
Validation loss: 2.1873410443464913

Epoch: 5| Step: 6
Training loss: 1.3397525548934937
Validation loss: 2.1653014570474625

Epoch: 5| Step: 7
Training loss: 0.3851071000099182
Validation loss: 2.1504370272159576

Epoch: 5| Step: 8
Training loss: 0.6232037544250488
Validation loss: 2.177114193638166

Epoch: 5| Step: 9
Training loss: 0.9545574188232422
Validation loss: 2.1981594562530518

Epoch: 5| Step: 10
Training loss: 1.365748405456543
Validation loss: 2.1352699597676597

Epoch: 5| Step: 11
Training loss: 0.7465186715126038
Validation loss: 2.151235615213712

Epoch: 390| Step: 0
Training loss: 0.9171192049980164
Validation loss: 2.134180039167404

Epoch: 5| Step: 1
Training loss: 0.38010385632514954
Validation loss: 2.2018576711416245

Epoch: 5| Step: 2
Training loss: 0.7073988318443298
Validation loss: 2.171187644203504

Epoch: 5| Step: 3
Training loss: 0.9609473943710327
Validation loss: 2.140666643778483

Epoch: 5| Step: 4
Training loss: 1.0467218160629272
Validation loss: 2.234197199344635

Epoch: 5| Step: 5
Training loss: 0.6485158205032349
Validation loss: 2.221438318490982

Epoch: 5| Step: 6
Training loss: 0.7433143854141235
Validation loss: 2.187579929828644

Epoch: 5| Step: 7
Training loss: 0.961567223072052
Validation loss: 2.2215535044670105

Epoch: 5| Step: 8
Training loss: 0.7720523476600647
Validation loss: 2.298470397790273

Epoch: 5| Step: 9
Training loss: 0.7450393438339233
Validation loss: 2.2180622220039368

Epoch: 5| Step: 10
Training loss: 0.9660852551460266
Validation loss: 2.123996694882711

Epoch: 5| Step: 11
Training loss: 0.9424259066581726
Validation loss: 2.1685050229231515

Epoch: 391| Step: 0
Training loss: 0.8258078694343567
Validation loss: 2.1540711571772895

Epoch: 5| Step: 1
Training loss: 0.9114608764648438
Validation loss: 2.069321403900782

Epoch: 5| Step: 2
Training loss: 0.49291157722473145
Validation loss: 2.165920709570249

Epoch: 5| Step: 3
Training loss: 0.8052147030830383
Validation loss: 2.1519741217295327

Epoch: 5| Step: 4
Training loss: 0.7162221670150757
Validation loss: 2.2110498001178107

Epoch: 5| Step: 5
Training loss: 0.6531792879104614
Validation loss: 2.046270896991094

Epoch: 5| Step: 6
Training loss: 0.5702592134475708
Validation loss: 2.0966462194919586

Epoch: 5| Step: 7
Training loss: 0.7680834531784058
Validation loss: 2.1288338601589203

Epoch: 5| Step: 8
Training loss: 0.9014724493026733
Validation loss: 2.149768888950348

Epoch: 5| Step: 9
Training loss: 0.6791602969169617
Validation loss: 2.0777684152126312

Epoch: 5| Step: 10
Training loss: 1.1960022449493408
Validation loss: 2.058849891026815

Epoch: 5| Step: 11
Training loss: 0.25085991621017456
Validation loss: 2.0905113418896994

Epoch: 392| Step: 0
Training loss: 0.4732763171195984
Validation loss: 2.1580562194188437

Epoch: 5| Step: 1
Training loss: 0.8652278780937195
Validation loss: 2.1578443497419357

Epoch: 5| Step: 2
Training loss: 1.4062530994415283
Validation loss: 2.1468277871608734

Epoch: 5| Step: 3
Training loss: 0.5940669775009155
Validation loss: 2.281976302464803

Epoch: 5| Step: 4
Training loss: 0.9126491546630859
Validation loss: 2.245679756005605

Epoch: 5| Step: 5
Training loss: 0.6948415040969849
Validation loss: 2.252903237938881

Epoch: 5| Step: 6
Training loss: 0.8200573921203613
Validation loss: 2.1743255654970803

Epoch: 5| Step: 7
Training loss: 0.8789671063423157
Validation loss: 2.152377595504125

Epoch: 5| Step: 8
Training loss: 0.9655609130859375
Validation loss: 2.1383953591187796

Epoch: 5| Step: 9
Training loss: 0.5735330581665039
Validation loss: 2.048003608981768

Epoch: 5| Step: 10
Training loss: 0.5919221639633179
Validation loss: 2.126630832751592

Epoch: 5| Step: 11
Training loss: 2.0848846435546875
Validation loss: 2.1287187337875366

Epoch: 393| Step: 0
Training loss: 0.7893391251564026
Validation loss: 2.2038080344597497

Epoch: 5| Step: 1
Training loss: 1.266743779182434
Validation loss: 2.123978614807129

Epoch: 5| Step: 2
Training loss: 2.1783347129821777
Validation loss: 2.123130684097608

Epoch: 5| Step: 3
Training loss: 0.5276746153831482
Validation loss: 2.131620724995931

Epoch: 5| Step: 4
Training loss: 0.47646936774253845
Validation loss: 2.083035637935003

Epoch: 5| Step: 5
Training loss: 0.622679591178894
Validation loss: 2.180327216784159

Epoch: 5| Step: 6
Training loss: 0.8679195642471313
Validation loss: 2.174960787097613

Epoch: 5| Step: 7
Training loss: 0.7893867492675781
Validation loss: 2.2265430639187493

Epoch: 5| Step: 8
Training loss: 0.9477704763412476
Validation loss: 2.225659395257632

Epoch: 5| Step: 9
Training loss: 0.8611493110656738
Validation loss: 2.090722327431043

Epoch: 5| Step: 10
Training loss: 0.6566480398178101
Validation loss: 2.1211305807034173

Epoch: 5| Step: 11
Training loss: 0.6455374956130981
Validation loss: 2.105056792497635

Epoch: 394| Step: 0
Training loss: 0.6440621614456177
Validation loss: 2.111669600009918

Epoch: 5| Step: 1
Training loss: 1.146690011024475
Validation loss: 2.1048535058895745

Epoch: 5| Step: 2
Training loss: 1.0688972473144531
Validation loss: 2.1004940420389175

Epoch: 5| Step: 3
Training loss: 0.6865876913070679
Validation loss: 2.0660891234874725

Epoch: 5| Step: 4
Training loss: 0.9331197738647461
Validation loss: 2.0916204899549484

Epoch: 5| Step: 5
Training loss: 0.6020221710205078
Validation loss: 2.0783651570479074

Epoch: 5| Step: 6
Training loss: 0.712615966796875
Validation loss: 2.117330332597097

Epoch: 5| Step: 7
Training loss: 0.6668153405189514
Validation loss: 2.1701667110125222

Epoch: 5| Step: 8
Training loss: 0.663348376750946
Validation loss: 2.1860082745552063

Epoch: 5| Step: 9
Training loss: 0.5358441472053528
Validation loss: 2.075017640988032

Epoch: 5| Step: 10
Training loss: 1.1044389009475708
Validation loss: 2.2068734566370645

Epoch: 5| Step: 11
Training loss: 0.9150885343551636
Validation loss: 2.1534715493520102

Epoch: 395| Step: 0
Training loss: 0.6752651929855347
Validation loss: 2.1459843764702478

Epoch: 5| Step: 1
Training loss: 0.824603259563446
Validation loss: 2.1982150971889496

Epoch: 5| Step: 2
Training loss: 0.9468424916267395
Validation loss: 2.090000053246816

Epoch: 5| Step: 3
Training loss: 0.8981359601020813
Validation loss: 2.1087140341599784

Epoch: 5| Step: 4
Training loss: 0.6618469953536987
Validation loss: 2.1772818168004355

Epoch: 5| Step: 5
Training loss: 0.5445793867111206
Validation loss: 2.196150322755178

Epoch: 5| Step: 6
Training loss: 1.1605929136276245
Validation loss: 2.0752601573864617

Epoch: 5| Step: 7
Training loss: 1.086155652999878
Validation loss: 2.0900572637716928

Epoch: 5| Step: 8
Training loss: 0.5462738871574402
Validation loss: 2.092742602030436

Epoch: 5| Step: 9
Training loss: 0.8455144762992859
Validation loss: 2.1706569145123162

Epoch: 5| Step: 10
Training loss: 0.7395399808883667
Validation loss: 2.1327823946873345

Epoch: 5| Step: 11
Training loss: 0.19829943776130676
Validation loss: 2.1809721887111664

Epoch: 396| Step: 0
Training loss: 0.6508380174636841
Validation loss: 2.151095082362493

Epoch: 5| Step: 1
Training loss: 0.8851392865180969
Validation loss: 2.153079648812612

Epoch: 5| Step: 2
Training loss: 1.2984635829925537
Validation loss: 2.132525146007538

Epoch: 5| Step: 3
Training loss: 0.704864501953125
Validation loss: 2.151781916618347

Epoch: 5| Step: 4
Training loss: 0.5295302867889404
Validation loss: 2.1152521073818207

Epoch: 5| Step: 5
Training loss: 0.9964569211006165
Validation loss: 2.0812931954860687

Epoch: 5| Step: 6
Training loss: 0.7181174755096436
Validation loss: 2.101238429546356

Epoch: 5| Step: 7
Training loss: 0.6194044351577759
Validation loss: 2.188893144329389

Epoch: 5| Step: 8
Training loss: 0.8003759384155273
Validation loss: 2.1397725691397986

Epoch: 5| Step: 9
Training loss: 0.6227082014083862
Validation loss: 2.0704612682263055

Epoch: 5| Step: 10
Training loss: 0.6072945594787598
Validation loss: 2.1554691245158515

Epoch: 5| Step: 11
Training loss: 0.9381405115127563
Validation loss: 2.0873633672793708

Epoch: 397| Step: 0
Training loss: 0.7598389387130737
Validation loss: 2.16784376402696

Epoch: 5| Step: 1
Training loss: 0.9660730361938477
Validation loss: 2.1576383461554847

Epoch: 5| Step: 2
Training loss: 1.1662178039550781
Validation loss: 2.1267744998137155

Epoch: 5| Step: 3
Training loss: 0.38832888007164
Validation loss: 2.1722107181946435

Epoch: 5| Step: 4
Training loss: 0.6421337723731995
Validation loss: 2.184708073735237

Epoch: 5| Step: 5
Training loss: 0.5649022459983826
Validation loss: 2.076586370666822

Epoch: 5| Step: 6
Training loss: 0.6566545963287354
Validation loss: 2.153813267747561

Epoch: 5| Step: 7
Training loss: 0.5584633946418762
Validation loss: 2.1128055254618325

Epoch: 5| Step: 8
Training loss: 0.9702685475349426
Validation loss: 2.164386600255966

Epoch: 5| Step: 9
Training loss: 0.7876114845275879
Validation loss: 2.0783369690179825

Epoch: 5| Step: 10
Training loss: 0.9327993392944336
Validation loss: 2.0932844479878745

Epoch: 5| Step: 11
Training loss: 0.14414238929748535
Validation loss: 2.12332891424497

Epoch: 398| Step: 0
Training loss: 0.6537779569625854
Validation loss: 2.094290092587471

Epoch: 5| Step: 1
Training loss: 1.2742831707000732
Validation loss: 2.161939779917399

Epoch: 5| Step: 2
Training loss: 0.6008387207984924
Validation loss: 2.125683754682541

Epoch: 5| Step: 3
Training loss: 0.8230770826339722
Validation loss: 2.1385393142700195

Epoch: 5| Step: 4
Training loss: 0.5327193737030029
Validation loss: 2.1591298580169678

Epoch: 5| Step: 5
Training loss: 0.8930026292800903
Validation loss: 2.119796266158422

Epoch: 5| Step: 6
Training loss: 0.7253788113594055
Validation loss: 2.125094468394915

Epoch: 5| Step: 7
Training loss: 1.1793835163116455
Validation loss: 2.155290504296621

Epoch: 5| Step: 8
Training loss: 0.7268308401107788
Validation loss: 2.1113463838895163

Epoch: 5| Step: 9
Training loss: 0.9443926811218262
Validation loss: 2.1826802094777427

Epoch: 5| Step: 10
Training loss: 0.6846515536308289
Validation loss: 2.1812561502059302

Epoch: 5| Step: 11
Training loss: 0.279765248298645
Validation loss: 2.0473075956106186

Epoch: 399| Step: 0
Training loss: 0.9313200116157532
Validation loss: 2.1373989631732306

Epoch: 5| Step: 1
Training loss: 1.1027988195419312
Validation loss: 2.1761506646871567

Epoch: 5| Step: 2
Training loss: 0.519130289554596
Validation loss: 2.0928479780753455

Epoch: 5| Step: 3
Training loss: 0.5875987410545349
Validation loss: 2.190659855802854

Epoch: 5| Step: 4
Training loss: 0.6887291669845581
Validation loss: 2.160506546497345

Epoch: 5| Step: 5
Training loss: 0.7015901803970337
Validation loss: 2.1482278555631638

Epoch: 5| Step: 6
Training loss: 0.6627620458602905
Validation loss: 2.147760863105456

Epoch: 5| Step: 7
Training loss: 0.9189101457595825
Validation loss: 2.2629139026006064

Epoch: 5| Step: 8
Training loss: 1.3564766645431519
Validation loss: 2.2324948410193124

Epoch: 5| Step: 9
Training loss: 1.4350435733795166
Validation loss: 2.2919242282708487

Epoch: 5| Step: 10
Training loss: 0.8797189593315125
Validation loss: 2.2411818454662957

Epoch: 5| Step: 11
Training loss: 0.824626088142395
Validation loss: 2.152199233571688

Epoch: 400| Step: 0
Training loss: 0.7909423112869263
Validation loss: 2.1219360530376434

Epoch: 5| Step: 1
Training loss: 0.8831577301025391
Validation loss: 2.0962415089209876

Epoch: 5| Step: 2
Training loss: 0.3960697650909424
Validation loss: 2.1484680424133935

Epoch: 5| Step: 3
Training loss: 0.9491987228393555
Validation loss: 2.0632235258817673

Epoch: 5| Step: 4
Training loss: 1.2052990198135376
Validation loss: 2.166600008805593

Epoch: 5| Step: 5
Training loss: 0.9324105381965637
Validation loss: 2.1305160770813623

Epoch: 5| Step: 6
Training loss: 0.687873363494873
Validation loss: 2.097146878639857

Epoch: 5| Step: 7
Training loss: 0.706396222114563
Validation loss: 2.154035290082296

Epoch: 5| Step: 8
Training loss: 0.5261338949203491
Validation loss: 2.1630058834950128

Epoch: 5| Step: 9
Training loss: 0.6496945023536682
Validation loss: 2.123416841030121

Epoch: 5| Step: 10
Training loss: 0.5801177620887756
Validation loss: 2.1773105959097543

Epoch: 5| Step: 11
Training loss: 1.7227351665496826
Validation loss: 2.1507727603117623

Testing loss: 2.069385222393832
