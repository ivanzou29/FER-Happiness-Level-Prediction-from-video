Epoch: 1| Step: 0
Training loss: 5.794889948197356
Validation loss: 6.260273881533288

Epoch: 5| Step: 1
Training loss: 6.518008594283706
Validation loss: 6.2396491678253625

Epoch: 5| Step: 2
Training loss: 6.243403806816495
Validation loss: 6.219622207383478

Epoch: 5| Step: 3
Training loss: 7.225036261972421
Validation loss: 6.19796938406272

Epoch: 5| Step: 4
Training loss: 6.116179050616424
Validation loss: 6.175521745403135

Epoch: 5| Step: 5
Training loss: 6.211470594260217
Validation loss: 6.1524061411767

Epoch: 5| Step: 6
Training loss: 6.547778665818123
Validation loss: 6.135812233919631

Epoch: 5| Step: 7
Training loss: 6.745652105368328
Validation loss: 6.113753158993848

Epoch: 5| Step: 8
Training loss: 6.489783547763837
Validation loss: 6.091125359948631

Epoch: 5| Step: 9
Training loss: 5.886610530068627
Validation loss: 6.072132350031246

Epoch: 5| Step: 10
Training loss: 4.994550023550084
Validation loss: 6.052385905893598

Epoch: 5| Step: 11
Training loss: 6.066537672634704
Validation loss: 6.038728613463212

Epoch: 2| Step: 0
Training loss: 6.521244836402678
Validation loss: 6.022920433772503

Epoch: 5| Step: 1
Training loss: 6.447808169765273
Validation loss: 6.003651468152935

Epoch: 5| Step: 2
Training loss: 6.033527794052295
Validation loss: 5.9860904980408085

Epoch: 5| Step: 3
Training loss: 5.603989419887665
Validation loss: 5.968375049417934

Epoch: 5| Step: 4
Training loss: 6.598860509358616
Validation loss: 5.94882583573032

Epoch: 5| Step: 5
Training loss: 5.4516893480871484
Validation loss: 5.929792856412141

Epoch: 5| Step: 6
Training loss: 6.965803541288691
Validation loss: 5.911069434281153

Epoch: 5| Step: 7
Training loss: 5.704871842919929
Validation loss: 5.883290562280613

Epoch: 5| Step: 8
Training loss: 5.7193973362490365
Validation loss: 5.866071253693118

Epoch: 5| Step: 9
Training loss: 6.189258672296518
Validation loss: 5.8385979964175965

Epoch: 5| Step: 10
Training loss: 4.976088185366096
Validation loss: 5.816571173753923

Epoch: 5| Step: 11
Training loss: 5.4559226306004955
Validation loss: 5.792118784412237

Epoch: 3| Step: 0
Training loss: 5.040703463431468
Validation loss: 5.769053858465441

Epoch: 5| Step: 1
Training loss: 6.201354881649982
Validation loss: 5.739842323049321

Epoch: 5| Step: 2
Training loss: 6.182375857244072
Validation loss: 5.714936664805503

Epoch: 5| Step: 3
Training loss: 5.381496495572616
Validation loss: 5.689959738241997

Epoch: 5| Step: 4
Training loss: 5.326570793183445
Validation loss: 5.657915765788617

Epoch: 5| Step: 5
Training loss: 5.500723011004902
Validation loss: 5.625033350245192

Epoch: 5| Step: 6
Training loss: 6.312491237520991
Validation loss: 5.597609951682333

Epoch: 5| Step: 7
Training loss: 6.382324200071963
Validation loss: 5.557450706639704

Epoch: 5| Step: 8
Training loss: 4.766129864074791
Validation loss: 5.522081236486176

Epoch: 5| Step: 9
Training loss: 6.145998712243474
Validation loss: 5.485950218395272

Epoch: 5| Step: 10
Training loss: 5.697824350709924
Validation loss: 5.4477767075405685

Epoch: 5| Step: 11
Training loss: 3.4566012874834615
Validation loss: 5.405318214807663

Epoch: 4| Step: 0
Training loss: 5.29305415348535
Validation loss: 5.370057206444097

Epoch: 5| Step: 1
Training loss: 5.842898056841033
Validation loss: 5.3277399589598256

Epoch: 5| Step: 2
Training loss: 5.6313410303885085
Validation loss: 5.272497135666223

Epoch: 5| Step: 3
Training loss: 4.985589815101455
Validation loss: 5.239464474714593

Epoch: 5| Step: 4
Training loss: 4.461014675134201
Validation loss: 5.177378581459326

Epoch: 5| Step: 5
Training loss: 4.965337961301959
Validation loss: 5.122811385111378

Epoch: 5| Step: 6
Training loss: 4.935718069968233
Validation loss: 5.068556047861051

Epoch: 5| Step: 7
Training loss: 4.784402045155434
Validation loss: 5.016784217107822

Epoch: 5| Step: 8
Training loss: 5.149608426809061
Validation loss: 4.951487883365422

Epoch: 5| Step: 9
Training loss: 5.146627243925388
Validation loss: 4.89328682868715

Epoch: 5| Step: 10
Training loss: 5.735510773399969
Validation loss: 4.82937628077444

Epoch: 5| Step: 11
Training loss: 5.061057556367759
Validation loss: 4.7540027668166145

Epoch: 5| Step: 0
Training loss: 3.921024184627418
Validation loss: 4.674362277497205

Epoch: 5| Step: 1
Training loss: 5.45558089340828
Validation loss: 4.59491953591512

Epoch: 5| Step: 2
Training loss: 4.793449446147673
Validation loss: 4.51502283606628

Epoch: 5| Step: 3
Training loss: 4.451108027322909
Validation loss: 4.429560920212007

Epoch: 5| Step: 4
Training loss: 4.3109291643461
Validation loss: 4.340831434752694

Epoch: 5| Step: 5
Training loss: 4.125274880238214
Validation loss: 4.25413433639292

Epoch: 5| Step: 6
Training loss: 3.811353792583256
Validation loss: 4.1492880208572895

Epoch: 5| Step: 7
Training loss: 4.699696453924785
Validation loss: 4.05899959293729

Epoch: 5| Step: 8
Training loss: 3.53556506074589
Validation loss: 3.963796447839455

Epoch: 5| Step: 9
Training loss: 4.279341446310557
Validation loss: 3.8596412474188395

Epoch: 5| Step: 10
Training loss: 3.51950605004505
Validation loss: 3.739849987812417

Epoch: 5| Step: 11
Training loss: 4.336152602350284
Validation loss: 3.64164263974141

Epoch: 6| Step: 0
Training loss: 4.343204601270368
Validation loss: 3.517140244209281

Epoch: 5| Step: 1
Training loss: 3.6017584426769282
Validation loss: 3.405099709545122

Epoch: 5| Step: 2
Training loss: 3.3462371132808775
Validation loss: 3.3069668507705883

Epoch: 5| Step: 3
Training loss: 3.1483523828250912
Validation loss: 3.2109003026189096

Epoch: 5| Step: 4
Training loss: 3.022848224631888
Validation loss: 3.0898734315137006

Epoch: 5| Step: 5
Training loss: 2.9460472586804203
Validation loss: 3.038765638638898

Epoch: 5| Step: 6
Training loss: 2.9845887751682563
Validation loss: 2.9546857171176835

Epoch: 5| Step: 7
Training loss: 2.4565664073028373
Validation loss: 2.87235084053463

Epoch: 5| Step: 8
Training loss: 2.5651754043420705
Validation loss: 2.811635990237402

Epoch: 5| Step: 9
Training loss: 2.7095965936101556
Validation loss: 2.7982419756285766

Epoch: 5| Step: 10
Training loss: 2.713344945140739
Validation loss: 2.7754565523510895

Epoch: 5| Step: 11
Training loss: 2.897054254773724
Validation loss: 2.7686341540611985

Epoch: 7| Step: 0
Training loss: 2.2817392739037268
Validation loss: 2.7473754857953505

Epoch: 5| Step: 1
Training loss: 2.5663547830051514
Validation loss: 2.759596016493902

Epoch: 5| Step: 2
Training loss: 2.2206788611113972
Validation loss: 2.787526501114777

Epoch: 5| Step: 3
Training loss: 2.892454485984388
Validation loss: 2.813926236251146

Epoch: 5| Step: 4
Training loss: 3.752120626385336
Validation loss: 2.8463516246973932

Epoch: 5| Step: 5
Training loss: 3.5277967193842588
Validation loss: 2.8156190601869087

Epoch: 5| Step: 6
Training loss: 2.767252987087277
Validation loss: 2.8619888428144686

Epoch: 5| Step: 7
Training loss: 2.9296702473450336
Validation loss: 2.8757526753125275

Epoch: 5| Step: 8
Training loss: 2.1610816228969125
Validation loss: 2.8149813973154885

Epoch: 5| Step: 9
Training loss: 2.5769874606317775
Validation loss: 2.84308951256699

Epoch: 5| Step: 10
Training loss: 2.476638455835666
Validation loss: 2.8570805048241277

Epoch: 5| Step: 11
Training loss: 2.7261165046452827
Validation loss: 2.822354275940167

Epoch: 8| Step: 0
Training loss: 3.078901473735908
Validation loss: 2.8144745782885625

Epoch: 5| Step: 1
Training loss: 2.2127006698383265
Validation loss: 2.7613119341016343

Epoch: 5| Step: 2
Training loss: 2.4350315212582947
Validation loss: 2.7915869257816417

Epoch: 5| Step: 3
Training loss: 2.8006469183593845
Validation loss: 2.7987148051670636

Epoch: 5| Step: 4
Training loss: 2.832071827564904
Validation loss: 2.7626861108253826

Epoch: 5| Step: 5
Training loss: 3.192011314754462
Validation loss: 2.729975090460499

Epoch: 5| Step: 6
Training loss: 2.551616164026821
Validation loss: 2.7795959547641966

Epoch: 5| Step: 7
Training loss: 3.2005865691935056
Validation loss: 2.7548779083356147

Epoch: 5| Step: 8
Training loss: 1.9745164617304798
Validation loss: 2.747397303769169

Epoch: 5| Step: 9
Training loss: 2.93594189166948
Validation loss: 2.7184885491246984

Epoch: 5| Step: 10
Training loss: 2.5988629055405044
Validation loss: 2.751988013871884

Epoch: 5| Step: 11
Training loss: 2.008726394410174
Validation loss: 2.7462353550018808

Epoch: 9| Step: 0
Training loss: 2.7246099000335517
Validation loss: 2.756777290804173

Epoch: 5| Step: 1
Training loss: 2.4504842941257214
Validation loss: 2.7528798492492395

Epoch: 5| Step: 2
Training loss: 2.444454932431157
Validation loss: 2.73302433987878

Epoch: 5| Step: 3
Training loss: 2.533071357164713
Validation loss: 2.7492044482988796

Epoch: 5| Step: 4
Training loss: 2.9635040513228645
Validation loss: 2.765916891553162

Epoch: 5| Step: 5
Training loss: 3.349568660922388
Validation loss: 2.712514728148713

Epoch: 5| Step: 6
Training loss: 2.3493706002362926
Validation loss: 2.744878066631548

Epoch: 5| Step: 7
Training loss: 2.716445296771868
Validation loss: 2.755490911712084

Epoch: 5| Step: 8
Training loss: 2.4593478442465684
Validation loss: 2.7450030110961667

Epoch: 5| Step: 9
Training loss: 2.810641034678365
Validation loss: 2.7343137534412163

Epoch: 5| Step: 10
Training loss: 2.732767384561847
Validation loss: 2.742389914205018

Epoch: 5| Step: 11
Training loss: 3.221025865992779
Validation loss: 2.7406387737628353

Epoch: 10| Step: 0
Training loss: 2.523020328961458
Validation loss: 2.734655420365621

Epoch: 5| Step: 1
Training loss: 3.156509086626021
Validation loss: 2.7229911784275376

Epoch: 5| Step: 2
Training loss: 2.305950685011833
Validation loss: 2.7496125858687543

Epoch: 5| Step: 3
Training loss: 2.4809690917002913
Validation loss: 2.7453852970065835

Epoch: 5| Step: 4
Training loss: 3.162795126190425
Validation loss: 2.7293862528707664

Epoch: 5| Step: 5
Training loss: 2.699671485130091
Validation loss: 2.74657340493437

Epoch: 5| Step: 6
Training loss: 2.724325579557964
Validation loss: 2.7521477714597147

Epoch: 5| Step: 7
Training loss: 2.90935244116145
Validation loss: 2.743198375095742

Epoch: 5| Step: 8
Training loss: 2.624737408537402
Validation loss: 2.719676923042006

Epoch: 5| Step: 9
Training loss: 2.4922274882298323
Validation loss: 2.7554156736780424

Epoch: 5| Step: 10
Training loss: 2.5301925899496918
Validation loss: 2.729889003636288

Epoch: 5| Step: 11
Training loss: 0.8291116990187559
Validation loss: 2.7206985389614227

Epoch: 11| Step: 0
Training loss: 3.15158158818045
Validation loss: 2.7483254666290065

Epoch: 5| Step: 1
Training loss: 2.278838149901402
Validation loss: 2.7278547166935723

Epoch: 5| Step: 2
Training loss: 2.835925225685817
Validation loss: 2.7159701967493284

Epoch: 5| Step: 3
Training loss: 2.8086227818714224
Validation loss: 2.7316613346600196

Epoch: 5| Step: 4
Training loss: 3.481642126055017
Validation loss: 2.739964057420938

Epoch: 5| Step: 5
Training loss: 2.683628043187455
Validation loss: 2.723609450969442

Epoch: 5| Step: 6
Training loss: 2.1303455212230062
Validation loss: 2.724816653298496

Epoch: 5| Step: 7
Training loss: 2.3318941469002
Validation loss: 2.7200470457613206

Epoch: 5| Step: 8
Training loss: 1.6749950778945797
Validation loss: 2.707224766950583

Epoch: 5| Step: 9
Training loss: 2.7081928705813363
Validation loss: 2.739059805555917

Epoch: 5| Step: 10
Training loss: 2.975057066041526
Validation loss: 2.72444818126979

Epoch: 5| Step: 11
Training loss: 2.2631824876109756
Validation loss: 2.7099337373118804

Epoch: 12| Step: 0
Training loss: 2.238153956656581
Validation loss: 2.7122073208994135

Epoch: 5| Step: 1
Training loss: 2.3660564679189515
Validation loss: 2.687512870876039

Epoch: 5| Step: 2
Training loss: 2.7160546984550957
Validation loss: 2.7177006936444164

Epoch: 5| Step: 3
Training loss: 3.4635747845818363
Validation loss: 2.7128957368909195

Epoch: 5| Step: 4
Training loss: 2.65141907249532
Validation loss: 2.7292529898136726

Epoch: 5| Step: 5
Training loss: 2.419560464714041
Validation loss: 2.7266271814873804

Epoch: 5| Step: 6
Training loss: 2.902673304704264
Validation loss: 2.736983963768285

Epoch: 5| Step: 7
Training loss: 2.942346025066662
Validation loss: 2.7067607067379447

Epoch: 5| Step: 8
Training loss: 2.851051431085611
Validation loss: 2.7208777246363876

Epoch: 5| Step: 9
Training loss: 2.5725297727057543
Validation loss: 2.716295650857521

Epoch: 5| Step: 10
Training loss: 1.9690277267022775
Validation loss: 2.714035964188968

Epoch: 5| Step: 11
Training loss: 2.136048708785385
Validation loss: 2.6972010017993773

Epoch: 13| Step: 0
Training loss: 2.403407114283497
Validation loss: 2.708338019782682

Epoch: 5| Step: 1
Training loss: 3.1997126569484537
Validation loss: 2.673985118357824

Epoch: 5| Step: 2
Training loss: 3.2452141663774268
Validation loss: 2.7319602040030913

Epoch: 5| Step: 3
Training loss: 2.922794462564542
Validation loss: 2.704071349671713

Epoch: 5| Step: 4
Training loss: 2.2835032165518054
Validation loss: 2.6930650859644674

Epoch: 5| Step: 5
Training loss: 2.5544018133635498
Validation loss: 2.727393358024015

Epoch: 5| Step: 6
Training loss: 2.7180761620332725
Validation loss: 2.7319163758545244

Epoch: 5| Step: 7
Training loss: 2.2427145308642076
Validation loss: 2.6697191423281437

Epoch: 5| Step: 8
Training loss: 2.4823361073585986
Validation loss: 2.6886868406757984

Epoch: 5| Step: 9
Training loss: 2.67298428892691
Validation loss: 2.7133839659649115

Epoch: 5| Step: 10
Training loss: 2.1251538164904433
Validation loss: 2.70567821176895

Epoch: 5| Step: 11
Training loss: 2.250420637018348
Validation loss: 2.736053024574763

Epoch: 14| Step: 0
Training loss: 2.8912537586865565
Validation loss: 2.715144750434598

Epoch: 5| Step: 1
Training loss: 2.355587477087857
Validation loss: 2.6861599900857627

Epoch: 5| Step: 2
Training loss: 2.7385130170617593
Validation loss: 2.67945985040246

Epoch: 5| Step: 3
Training loss: 2.4601672708041
Validation loss: 2.712523510387159

Epoch: 5| Step: 4
Training loss: 2.1598074495181603
Validation loss: 2.702167039886915

Epoch: 5| Step: 5
Training loss: 2.15001395908526
Validation loss: 2.6939540627904703

Epoch: 5| Step: 6
Training loss: 2.3634450808399343
Validation loss: 2.698353762672031

Epoch: 5| Step: 7
Training loss: 2.912331074412266
Validation loss: 2.726956248886096

Epoch: 5| Step: 8
Training loss: 2.342253855960737
Validation loss: 2.719347950157814

Epoch: 5| Step: 9
Training loss: 3.3865734451960483
Validation loss: 2.6894190021271855

Epoch: 5| Step: 10
Training loss: 3.2677459400085533
Validation loss: 2.7113860068027837

Epoch: 5| Step: 11
Training loss: 1.1823470092905966
Validation loss: 2.709050704631736

Epoch: 15| Step: 0
Training loss: 2.6692940365162747
Validation loss: 2.712877764670217

Epoch: 5| Step: 1
Training loss: 2.8114676382206
Validation loss: 2.6653189357817477

Epoch: 5| Step: 2
Training loss: 2.6595461869866694
Validation loss: 2.6784437349702563

Epoch: 5| Step: 3
Training loss: 2.610818977336781
Validation loss: 2.649738736664108

Epoch: 5| Step: 4
Training loss: 2.634789514115199
Validation loss: 2.688399386172912

Epoch: 5| Step: 5
Training loss: 2.842331417187629
Validation loss: 2.6824768903660607

Epoch: 5| Step: 6
Training loss: 2.4243873608857474
Validation loss: 2.6656582882805027

Epoch: 5| Step: 7
Training loss: 2.22116977750722
Validation loss: 2.684508703067669

Epoch: 5| Step: 8
Training loss: 2.5160068198507335
Validation loss: 2.6999502925064784

Epoch: 5| Step: 9
Training loss: 2.981137741822369
Validation loss: 2.679977742335191

Epoch: 5| Step: 10
Training loss: 2.708781855685894
Validation loss: 2.684611757175236

Epoch: 5| Step: 11
Training loss: 2.29912078472434
Validation loss: 2.708439914122335

Epoch: 16| Step: 0
Training loss: 2.827371992321684
Validation loss: 2.693004238956117

Epoch: 5| Step: 1
Training loss: 3.0091460999516944
Validation loss: 2.680195199603387

Epoch: 5| Step: 2
Training loss: 1.8066355442284976
Validation loss: 2.6706128215861775

Epoch: 5| Step: 3
Training loss: 2.5798674272882343
Validation loss: 2.6837965635522396

Epoch: 5| Step: 4
Training loss: 2.409609839328622
Validation loss: 2.6882024482781555

Epoch: 5| Step: 5
Training loss: 2.6809698211895086
Validation loss: 2.685583965623365

Epoch: 5| Step: 6
Training loss: 2.736496979365885
Validation loss: 2.6572873801258248

Epoch: 5| Step: 7
Training loss: 2.2274785884423207
Validation loss: 2.686184857044411

Epoch: 5| Step: 8
Training loss: 2.8273434059499136
Validation loss: 2.6728052858400777

Epoch: 5| Step: 9
Training loss: 3.2365690152031887
Validation loss: 2.704957329982896

Epoch: 5| Step: 10
Training loss: 2.3813343904214515
Validation loss: 2.6920692096094294

Epoch: 5| Step: 11
Training loss: 2.321077471162096
Validation loss: 2.6709877571081018

Epoch: 17| Step: 0
Training loss: 3.1585627476720237
Validation loss: 2.6947479836298043

Epoch: 5| Step: 1
Training loss: 2.17278879825081
Validation loss: 2.6853679010113054

Epoch: 5| Step: 2
Training loss: 2.8705811750146752
Validation loss: 2.679355589660854

Epoch: 5| Step: 3
Training loss: 2.864222685334805
Validation loss: 2.6880461152727073

Epoch: 5| Step: 4
Training loss: 2.2573585977974995
Validation loss: 2.692694073066852

Epoch: 5| Step: 5
Training loss: 2.7768780925560934
Validation loss: 2.693678662003817

Epoch: 5| Step: 6
Training loss: 2.7434751959545527
Validation loss: 2.6870552848321725

Epoch: 5| Step: 7
Training loss: 2.183055285834961
Validation loss: 2.6936313970349013

Epoch: 5| Step: 8
Training loss: 2.32936329520611
Validation loss: 2.6742956339342987

Epoch: 5| Step: 9
Training loss: 2.803415674216695
Validation loss: 2.6745763957257576

Epoch: 5| Step: 10
Training loss: 2.6336256633534827
Validation loss: 2.684663528816698

Epoch: 5| Step: 11
Training loss: 1.4504374600550711
Validation loss: 2.6454130061629924

Epoch: 18| Step: 0
Training loss: 2.4341531909577014
Validation loss: 2.6813634297135196

Epoch: 5| Step: 1
Training loss: 2.806004037251902
Validation loss: 2.629432493294128

Epoch: 5| Step: 2
Training loss: 2.7240711623992024
Validation loss: 2.6802936680227702

Epoch: 5| Step: 3
Training loss: 1.9907572679876813
Validation loss: 2.6573269885945727

Epoch: 5| Step: 4
Training loss: 2.65843182882563
Validation loss: 2.6648634175566714

Epoch: 5| Step: 5
Training loss: 2.5494397127542565
Validation loss: 2.654297354059314

Epoch: 5| Step: 6
Training loss: 3.118044627811698
Validation loss: 2.662091268886939

Epoch: 5| Step: 7
Training loss: 2.1858946222731364
Validation loss: 2.690732265288146

Epoch: 5| Step: 8
Training loss: 2.2132419398217156
Validation loss: 2.6669005586948855

Epoch: 5| Step: 9
Training loss: 3.283192087094771
Validation loss: 2.6582857334475323

Epoch: 5| Step: 10
Training loss: 2.535773109659434
Validation loss: 2.662498451286188

Epoch: 5| Step: 11
Training loss: 1.4680363158897392
Validation loss: 2.643156098857626

Epoch: 19| Step: 0
Training loss: 1.790186699555593
Validation loss: 2.6560181572656854

Epoch: 5| Step: 1
Training loss: 2.1997057848047246
Validation loss: 2.6308221207859983

Epoch: 5| Step: 2
Training loss: 2.8972119313397933
Validation loss: 2.642439457727043

Epoch: 5| Step: 3
Training loss: 2.6347699684916015
Validation loss: 2.6586946233444437

Epoch: 5| Step: 4
Training loss: 2.9094866705584383
Validation loss: 2.6748474830749798

Epoch: 5| Step: 5
Training loss: 2.7298206002113727
Validation loss: 2.657666643892275

Epoch: 5| Step: 6
Training loss: 2.2513030835236414
Validation loss: 2.656170282850644

Epoch: 5| Step: 7
Training loss: 2.875221243928558
Validation loss: 2.651082307745106

Epoch: 5| Step: 8
Training loss: 2.831178818369994
Validation loss: 2.634038185197182

Epoch: 5| Step: 9
Training loss: 2.3625614299558313
Validation loss: 2.6444535950716985

Epoch: 5| Step: 10
Training loss: 3.0211488405526232
Validation loss: 2.6348344715154637

Epoch: 5| Step: 11
Training loss: 2.1652183338047997
Validation loss: 2.6435329970451806

Epoch: 20| Step: 0
Training loss: 1.3690674853413711
Validation loss: 2.64784165753106

Epoch: 5| Step: 1
Training loss: 2.3842686940664577
Validation loss: 2.6407580633702734

Epoch: 5| Step: 2
Training loss: 2.59727615214323
Validation loss: 2.6303239790669095

Epoch: 5| Step: 3
Training loss: 2.786136492149472
Validation loss: 2.633110584171582

Epoch: 5| Step: 4
Training loss: 2.7762426669776663
Validation loss: 2.625461333471583

Epoch: 5| Step: 5
Training loss: 3.353515340619528
Validation loss: 2.641321436518801

Epoch: 5| Step: 6
Training loss: 2.052279725980217
Validation loss: 2.64306934543749

Epoch: 5| Step: 7
Training loss: 2.7904977391392225
Validation loss: 2.6217452072068705

Epoch: 5| Step: 8
Training loss: 3.056081156367049
Validation loss: 2.6471303454098942

Epoch: 5| Step: 9
Training loss: 2.43124280992244
Validation loss: 2.6174361722864417

Epoch: 5| Step: 10
Training loss: 2.350492620577058
Validation loss: 2.648924044888304

Epoch: 5| Step: 11
Training loss: 3.291911506399708
Validation loss: 2.6453230333203033

Epoch: 21| Step: 0
Training loss: 2.538699643543315
Validation loss: 2.6428186382829706

Epoch: 5| Step: 1
Training loss: 2.4504440138826555
Validation loss: 2.6428783365575677

Epoch: 5| Step: 2
Training loss: 2.769735955554025
Validation loss: 2.628661924196661

Epoch: 5| Step: 3
Training loss: 2.5330005761833756
Validation loss: 2.659540770848172

Epoch: 5| Step: 4
Training loss: 2.5481697021335887
Validation loss: 2.625698412975411

Epoch: 5| Step: 5
Training loss: 2.517461071149061
Validation loss: 2.64409054531079

Epoch: 5| Step: 6
Training loss: 2.772677293204786
Validation loss: 2.630076974792697

Epoch: 5| Step: 7
Training loss: 2.282503593584054
Validation loss: 2.651910415929581

Epoch: 5| Step: 8
Training loss: 2.195303268684717
Validation loss: 2.6325586651275668

Epoch: 5| Step: 9
Training loss: 2.6110860730947993
Validation loss: 2.628900551565417

Epoch: 5| Step: 10
Training loss: 3.0458491236690097
Validation loss: 2.644561406784872

Epoch: 5| Step: 11
Training loss: 1.984692225293694
Validation loss: 2.6335851401542216

Epoch: 22| Step: 0
Training loss: 1.7174843029209987
Validation loss: 2.6206744655062306

Epoch: 5| Step: 1
Training loss: 2.380950900940208
Validation loss: 2.6327550562960145

Epoch: 5| Step: 2
Training loss: 2.4282531429534746
Validation loss: 2.643679144881531

Epoch: 5| Step: 3
Training loss: 2.9814170038882883
Validation loss: 2.6359325301103333

Epoch: 5| Step: 4
Training loss: 2.366100502349644
Validation loss: 2.6243720817383136

Epoch: 5| Step: 5
Training loss: 2.57697506314559
Validation loss: 2.628220977572889

Epoch: 5| Step: 6
Training loss: 2.5644168662350055
Validation loss: 2.6265315590903864

Epoch: 5| Step: 7
Training loss: 1.6954391361877936
Validation loss: 2.6090751559429197

Epoch: 5| Step: 8
Training loss: 3.1153363154363234
Validation loss: 2.6284171523777293

Epoch: 5| Step: 9
Training loss: 3.0651244770804267
Validation loss: 2.6348790850574875

Epoch: 5| Step: 10
Training loss: 2.776567868478165
Validation loss: 2.634703043238519

Epoch: 5| Step: 11
Training loss: 3.2016148426548763
Validation loss: 2.6365008756314308

Epoch: 23| Step: 0
Training loss: 2.764540896249305
Validation loss: 2.6320022445534352

Epoch: 5| Step: 1
Training loss: 2.238743066995302
Validation loss: 2.611157857079657

Epoch: 5| Step: 2
Training loss: 2.8719695332008293
Validation loss: 2.632549963293122

Epoch: 5| Step: 3
Training loss: 1.9888682520036678
Validation loss: 2.6045050680907376

Epoch: 5| Step: 4
Training loss: 2.7180073918739613
Validation loss: 2.602988282941439

Epoch: 5| Step: 5
Training loss: 2.73870219479254
Validation loss: 2.6112392070870434

Epoch: 5| Step: 6
Training loss: 2.0327502065932217
Validation loss: 2.6036470327103025

Epoch: 5| Step: 7
Training loss: 3.1718061467857845
Validation loss: 2.6022542161827054

Epoch: 5| Step: 8
Training loss: 2.638233343202844
Validation loss: 2.6195125064545235

Epoch: 5| Step: 9
Training loss: 2.2556684933446394
Validation loss: 2.622856491121733

Epoch: 5| Step: 10
Training loss: 2.702730271289024
Validation loss: 2.606295872321951

Epoch: 5| Step: 11
Training loss: 2.1851297889064747
Validation loss: 2.6038085436942886

Epoch: 24| Step: 0
Training loss: 2.946971314879922
Validation loss: 2.5927149687626305

Epoch: 5| Step: 1
Training loss: 2.7230001968456565
Validation loss: 2.585646560145058

Epoch: 5| Step: 2
Training loss: 2.5060021827304646
Validation loss: 2.6226111585346565

Epoch: 5| Step: 3
Training loss: 3.023302020997647
Validation loss: 2.606553934062863

Epoch: 5| Step: 4
Training loss: 2.1037997564822457
Validation loss: 2.6221057702383654

Epoch: 5| Step: 5
Training loss: 2.4691658152710647
Validation loss: 2.6054760972376476

Epoch: 5| Step: 6
Training loss: 2.5819906211345836
Validation loss: 2.609855778882312

Epoch: 5| Step: 7
Training loss: 2.707111836344468
Validation loss: 2.605319474961227

Epoch: 5| Step: 8
Training loss: 2.600417334734719
Validation loss: 2.624217068004533

Epoch: 5| Step: 9
Training loss: 2.3188115155473525
Validation loss: 2.6136090767231366

Epoch: 5| Step: 10
Training loss: 2.5496199156290658
Validation loss: 2.5988015730882497

Epoch: 5| Step: 11
Training loss: 1.373754197063057
Validation loss: 2.6095307773834593

Epoch: 25| Step: 0
Training loss: 3.000851192518328
Validation loss: 2.6108802557802693

Epoch: 5| Step: 1
Training loss: 2.3965700316102496
Validation loss: 2.6114076551387453

Epoch: 5| Step: 2
Training loss: 2.7677206084860124
Validation loss: 2.6002488891366418

Epoch: 5| Step: 3
Training loss: 2.225791396080771
Validation loss: 2.6068987051246437

Epoch: 5| Step: 4
Training loss: 2.37185561180986
Validation loss: 2.6349819877812353

Epoch: 5| Step: 5
Training loss: 2.93598135793105
Validation loss: 2.6398963035642584

Epoch: 5| Step: 6
Training loss: 2.27905230284627
Validation loss: 2.654124802903528

Epoch: 5| Step: 7
Training loss: 2.4000220019603566
Validation loss: 2.6421232919920437

Epoch: 5| Step: 8
Training loss: 2.7928234569398227
Validation loss: 2.6774993874994095

Epoch: 5| Step: 9
Training loss: 2.760538715087611
Validation loss: 2.6682136464205874

Epoch: 5| Step: 10
Training loss: 2.1318160303840346
Validation loss: 2.670752841809761

Epoch: 5| Step: 11
Training loss: 3.8901901308484126
Validation loss: 2.6288719911879603

Epoch: 26| Step: 0
Training loss: 2.5082822936009594
Validation loss: 2.6041651357010474

Epoch: 5| Step: 1
Training loss: 2.878381316361745
Validation loss: 2.5967633349988666

Epoch: 5| Step: 2
Training loss: 2.857703215280757
Validation loss: 2.628736572684815

Epoch: 5| Step: 3
Training loss: 2.3333713891695256
Validation loss: 2.5980509905031415

Epoch: 5| Step: 4
Training loss: 2.3150524795878495
Validation loss: 2.6174274505390978

Epoch: 5| Step: 5
Training loss: 2.48116973824011
Validation loss: 2.6022657793668333

Epoch: 5| Step: 6
Training loss: 2.6822676179171974
Validation loss: 2.6347894877226725

Epoch: 5| Step: 7
Training loss: 2.9893509689216935
Validation loss: 2.6270157892819737

Epoch: 5| Step: 8
Training loss: 2.570073728283108
Validation loss: 2.6360466597377705

Epoch: 5| Step: 9
Training loss: 2.914435886873528
Validation loss: 2.6294996244726825

Epoch: 5| Step: 10
Training loss: 2.2117129202832917
Validation loss: 2.615539681103903

Epoch: 5| Step: 11
Training loss: 2.4167172547230518
Validation loss: 2.6200508813552266

Epoch: 27| Step: 0
Training loss: 3.0777469925731338
Validation loss: 2.6265417710514476

Epoch: 5| Step: 1
Training loss: 3.5056266516159447
Validation loss: 2.591637267981436

Epoch: 5| Step: 2
Training loss: 2.37800568570804
Validation loss: 2.612193042116279

Epoch: 5| Step: 3
Training loss: 1.9799925703814822
Validation loss: 2.600009007621714

Epoch: 5| Step: 4
Training loss: 2.418716734033948
Validation loss: 2.6043922377484994

Epoch: 5| Step: 5
Training loss: 2.656185373754267
Validation loss: 2.5922268987707837

Epoch: 5| Step: 6
Training loss: 2.7475024065557325
Validation loss: 2.6113834265875977

Epoch: 5| Step: 7
Training loss: 2.3498124108620786
Validation loss: 2.599119396735896

Epoch: 5| Step: 8
Training loss: 2.0360289476281603
Validation loss: 2.6046953669144903

Epoch: 5| Step: 9
Training loss: 2.009069976674057
Validation loss: 2.5942225466231355

Epoch: 5| Step: 10
Training loss: 2.7812811174687875
Validation loss: 2.6384804348191597

Epoch: 5| Step: 11
Training loss: 1.3484042538183396
Validation loss: 2.628007120035708

Epoch: 28| Step: 0
Training loss: 2.7293324213919385
Validation loss: 2.6046160742492392

Epoch: 5| Step: 1
Training loss: 2.6738853699245566
Validation loss: 2.603317875183294

Epoch: 5| Step: 2
Training loss: 2.083342348715031
Validation loss: 2.606698641442715

Epoch: 5| Step: 3
Training loss: 2.2416798086620195
Validation loss: 2.625831884690247

Epoch: 5| Step: 4
Training loss: 1.8511059033080308
Validation loss: 2.5740188189112274

Epoch: 5| Step: 5
Training loss: 2.894091862368005
Validation loss: 2.651062443819798

Epoch: 5| Step: 6
Training loss: 2.450908266764035
Validation loss: 2.57852503822942

Epoch: 5| Step: 7
Training loss: 2.205031091207037
Validation loss: 2.6453966896823755

Epoch: 5| Step: 8
Training loss: 1.9717611869454998
Validation loss: 2.6416790831561863

Epoch: 5| Step: 9
Training loss: 3.1517008110414504
Validation loss: 2.632877741457153

Epoch: 5| Step: 10
Training loss: 3.1582831453413833
Validation loss: 2.611056351482025

Epoch: 5| Step: 11
Training loss: 3.4586382045952195
Validation loss: 2.620950769806489

Epoch: 29| Step: 0
Training loss: 2.429001493601931
Validation loss: 2.598735124460728

Epoch: 5| Step: 1
Training loss: 2.383714248877221
Validation loss: 2.60674694531776

Epoch: 5| Step: 2
Training loss: 2.3695643612906117
Validation loss: 2.59007415590454

Epoch: 5| Step: 3
Training loss: 2.024841528449086
Validation loss: 2.574544751870681

Epoch: 5| Step: 4
Training loss: 2.1146379159982893
Validation loss: 2.5707154890488724

Epoch: 5| Step: 5
Training loss: 2.83011755116171
Validation loss: 2.5874932325892015

Epoch: 5| Step: 6
Training loss: 2.7568057548770626
Validation loss: 2.59162028711734

Epoch: 5| Step: 7
Training loss: 2.915523541188799
Validation loss: 2.5867952823790508

Epoch: 5| Step: 8
Training loss: 3.0014444688409836
Validation loss: 2.6009191189089345

Epoch: 5| Step: 9
Training loss: 2.895910266613562
Validation loss: 2.6276366638553332

Epoch: 5| Step: 10
Training loss: 2.49553071120726
Validation loss: 2.614924903737113

Epoch: 5| Step: 11
Training loss: 1.3733128687497371
Validation loss: 2.601786625766554

Epoch: 30| Step: 0
Training loss: 2.2445580050357288
Validation loss: 2.5825760844133034

Epoch: 5| Step: 1
Training loss: 2.29846032894371
Validation loss: 2.622621147126144

Epoch: 5| Step: 2
Training loss: 2.1409166791686065
Validation loss: 2.585891012521108

Epoch: 5| Step: 3
Training loss: 2.98882852167983
Validation loss: 2.5955475779002355

Epoch: 5| Step: 4
Training loss: 2.1940651604739916
Validation loss: 2.5859505805753655

Epoch: 5| Step: 5
Training loss: 2.5029310210808973
Validation loss: 2.5924280390351795

Epoch: 5| Step: 6
Training loss: 3.0502207066461486
Validation loss: 2.6032732454625664

Epoch: 5| Step: 7
Training loss: 3.1645801262068094
Validation loss: 2.5853178812828084

Epoch: 5| Step: 8
Training loss: 2.2595761284797438
Validation loss: 2.604678474994929

Epoch: 5| Step: 9
Training loss: 1.6166006304176062
Validation loss: 2.604964619772741

Epoch: 5| Step: 10
Training loss: 3.000661935894784
Validation loss: 2.6069095027191747

Epoch: 5| Step: 11
Training loss: 2.557132868811972
Validation loss: 2.585549432038897

Epoch: 31| Step: 0
Training loss: 2.0841824009344743
Validation loss: 2.5620236729427273

Epoch: 5| Step: 1
Training loss: 3.1155616133965505
Validation loss: 2.6132518764759043

Epoch: 5| Step: 2
Training loss: 2.0241653134982895
Validation loss: 2.617718102866625

Epoch: 5| Step: 3
Training loss: 1.8988788860844532
Validation loss: 2.5666091157500985

Epoch: 5| Step: 4
Training loss: 2.22374045907644
Validation loss: 2.606072088613897

Epoch: 5| Step: 5
Training loss: 2.7938367655207577
Validation loss: 2.572259075028044

Epoch: 5| Step: 6
Training loss: 2.6205884102382893
Validation loss: 2.595705650908172

Epoch: 5| Step: 7
Training loss: 2.6902094645293353
Validation loss: 2.57856450813974

Epoch: 5| Step: 8
Training loss: 2.519377758466554
Validation loss: 2.597614335795151

Epoch: 5| Step: 9
Training loss: 3.0620879849799856
Validation loss: 2.589779405671997

Epoch: 5| Step: 10
Training loss: 2.7731974753090602
Validation loss: 2.5960074141858893

Epoch: 5| Step: 11
Training loss: 1.3209341718687282
Validation loss: 2.5856167189985153

Epoch: 32| Step: 0
Training loss: 2.866276318195958
Validation loss: 2.622320385592279

Epoch: 5| Step: 1
Training loss: 2.404140786528059
Validation loss: 2.6141165561107043

Epoch: 5| Step: 2
Training loss: 2.0385945100973664
Validation loss: 2.571020301365534

Epoch: 5| Step: 3
Training loss: 2.6596425550551714
Validation loss: 2.575735425864484

Epoch: 5| Step: 4
Training loss: 2.31740750421422
Validation loss: 2.6101518681373417

Epoch: 5| Step: 5
Training loss: 2.5721368779176386
Validation loss: 2.5936961800380307

Epoch: 5| Step: 6
Training loss: 2.6385653436870755
Validation loss: 2.582953230263726

Epoch: 5| Step: 7
Training loss: 2.308374488087277
Validation loss: 2.591290127108755

Epoch: 5| Step: 8
Training loss: 2.642337311615092
Validation loss: 2.5898369510459744

Epoch: 5| Step: 9
Training loss: 3.2519874364743946
Validation loss: 2.5963772218242407

Epoch: 5| Step: 10
Training loss: 2.1460886929858285
Validation loss: 2.572536935982884

Epoch: 5| Step: 11
Training loss: 2.3749003138451736
Validation loss: 2.6180896589574694

Epoch: 33| Step: 0
Training loss: 2.8719281910815604
Validation loss: 2.567606130168964

Epoch: 5| Step: 1
Training loss: 1.9999591107957024
Validation loss: 2.622772550878219

Epoch: 5| Step: 2
Training loss: 2.739019754166552
Validation loss: 2.618385951518942

Epoch: 5| Step: 3
Training loss: 2.446174152896234
Validation loss: 2.6146378163186834

Epoch: 5| Step: 4
Training loss: 2.089364882891709
Validation loss: 2.616241834609231

Epoch: 5| Step: 5
Training loss: 2.99842443418613
Validation loss: 2.6040728602998096

Epoch: 5| Step: 6
Training loss: 2.5246679182080567
Validation loss: 2.6041075788788115

Epoch: 5| Step: 7
Training loss: 3.000339170992375
Validation loss: 2.6285626289366495

Epoch: 5| Step: 8
Training loss: 1.9822057446454
Validation loss: 2.6224687232172816

Epoch: 5| Step: 9
Training loss: 2.4425429970774357
Validation loss: 2.6022354034709303

Epoch: 5| Step: 10
Training loss: 2.4745802783535056
Validation loss: 2.5991518423834474

Epoch: 5| Step: 11
Training loss: 2.6145432508418103
Validation loss: 2.5771928084508335

Epoch: 34| Step: 0
Training loss: 2.9637975241504195
Validation loss: 2.5880325719902766

Epoch: 5| Step: 1
Training loss: 2.5439551530819746
Validation loss: 2.5719549193698086

Epoch: 5| Step: 2
Training loss: 2.520488988724024
Validation loss: 2.6016557006637413

Epoch: 5| Step: 3
Training loss: 2.1448187296640424
Validation loss: 2.597196281074628

Epoch: 5| Step: 4
Training loss: 2.9777462825564585
Validation loss: 2.592193630641243

Epoch: 5| Step: 5
Training loss: 2.605309614500443
Validation loss: 2.610753953266569

Epoch: 5| Step: 6
Training loss: 2.823630032838476
Validation loss: 2.588608199146573

Epoch: 5| Step: 7
Training loss: 2.4626536364965355
Validation loss: 2.556309631230396

Epoch: 5| Step: 8
Training loss: 1.8203814579422752
Validation loss: 2.592542727371816

Epoch: 5| Step: 9
Training loss: 2.7398903291570096
Validation loss: 2.583971146068892

Epoch: 5| Step: 10
Training loss: 2.142982020599518
Validation loss: 2.586246057178263

Epoch: 5| Step: 11
Training loss: 1.4370531133871847
Validation loss: 2.57071705796866

Epoch: 35| Step: 0
Training loss: 2.2667713290715454
Validation loss: 2.582388035164899

Epoch: 5| Step: 1
Training loss: 2.8482636901424674
Validation loss: 2.5647372001045703

Epoch: 5| Step: 2
Training loss: 2.6349974488566317
Validation loss: 2.593963813395021

Epoch: 5| Step: 3
Training loss: 2.5486241050710037
Validation loss: 2.5846748246552544

Epoch: 5| Step: 4
Training loss: 2.3020850019031767
Validation loss: 2.6068122522580417

Epoch: 5| Step: 5
Training loss: 2.922180812560021
Validation loss: 2.5640394192341973

Epoch: 5| Step: 6
Training loss: 2.7114271441812936
Validation loss: 2.611902992048027

Epoch: 5| Step: 7
Training loss: 2.227797423434923
Validation loss: 2.5940347882844685

Epoch: 5| Step: 8
Training loss: 2.953631806658406
Validation loss: 2.6204722918939387

Epoch: 5| Step: 9
Training loss: 2.160987625037211
Validation loss: 2.5961013155564934

Epoch: 5| Step: 10
Training loss: 2.2023476385790652
Validation loss: 2.6225553399033084

Epoch: 5| Step: 11
Training loss: 1.157573561009649
Validation loss: 2.5916267076603

Epoch: 36| Step: 0
Training loss: 2.2974077502172
Validation loss: 2.604518638984763

Epoch: 5| Step: 1
Training loss: 2.9913451600231697
Validation loss: 2.591525870717162

Epoch: 5| Step: 2
Training loss: 2.254976702652246
Validation loss: 2.605487558429475

Epoch: 5| Step: 3
Training loss: 2.9671854815644463
Validation loss: 2.601172079015738

Epoch: 5| Step: 4
Training loss: 2.446214308519756
Validation loss: 2.585709768296109

Epoch: 5| Step: 5
Training loss: 2.2613655829214308
Validation loss: 2.6264536216086185

Epoch: 5| Step: 6
Training loss: 2.8481254034186474
Validation loss: 2.585234213135988

Epoch: 5| Step: 7
Training loss: 2.5108400887357187
Validation loss: 2.6057596954523508

Epoch: 5| Step: 8
Training loss: 1.7562660705265556
Validation loss: 2.6062103885961148

Epoch: 5| Step: 9
Training loss: 1.9378936121647885
Validation loss: 2.559920811781899

Epoch: 5| Step: 10
Training loss: 2.9519772191292906
Validation loss: 2.5864986433180106

Epoch: 5| Step: 11
Training loss: 3.1473632191334855
Validation loss: 2.5823855673975085

Epoch: 37| Step: 0
Training loss: 1.8731890516050371
Validation loss: 2.535498378025209

Epoch: 5| Step: 1
Training loss: 2.9284325111484257
Validation loss: 2.572841069170102

Epoch: 5| Step: 2
Training loss: 2.636663230028899
Validation loss: 2.5695500465263064

Epoch: 5| Step: 3
Training loss: 2.9065745182771163
Validation loss: 2.5523621556046834

Epoch: 5| Step: 4
Training loss: 2.854000188794093
Validation loss: 2.574541919665538

Epoch: 5| Step: 5
Training loss: 2.6410198932145477
Validation loss: 2.5680572409412536

Epoch: 5| Step: 6
Training loss: 2.067950128083066
Validation loss: 2.5654179040710563

Epoch: 5| Step: 7
Training loss: 2.353798345149322
Validation loss: 2.577701537679468

Epoch: 5| Step: 8
Training loss: 2.9757788720475697
Validation loss: 2.5684351882091825

Epoch: 5| Step: 9
Training loss: 2.492118810586016
Validation loss: 2.5577426572292903

Epoch: 5| Step: 10
Training loss: 2.011430264130103
Validation loss: 2.5794040743735374

Epoch: 5| Step: 11
Training loss: 1.0445656998288093
Validation loss: 2.5876057248468975

Epoch: 38| Step: 0
Training loss: 2.2104417224821806
Validation loss: 2.581843857498501

Epoch: 5| Step: 1
Training loss: 2.6103328385914235
Validation loss: 2.5793476827469135

Epoch: 5| Step: 2
Training loss: 2.557473253276199
Validation loss: 2.5647394272759585

Epoch: 5| Step: 3
Training loss: 2.612481923017976
Validation loss: 2.543458054556311

Epoch: 5| Step: 4
Training loss: 2.2105931529478933
Validation loss: 2.563445409191901

Epoch: 5| Step: 5
Training loss: 1.9679820667163084
Validation loss: 2.5745679534557273

Epoch: 5| Step: 6
Training loss: 2.9302121925984035
Validation loss: 2.593289353550173

Epoch: 5| Step: 7
Training loss: 2.427540508211212
Validation loss: 2.5756428647549927

Epoch: 5| Step: 8
Training loss: 2.892796870685252
Validation loss: 2.5758662299177524

Epoch: 5| Step: 9
Training loss: 2.4628894633472678
Validation loss: 2.5899594925016545

Epoch: 5| Step: 10
Training loss: 2.744596808584663
Validation loss: 2.571805696106017

Epoch: 5| Step: 11
Training loss: 0.8829222416818
Validation loss: 2.5923946240380995

Epoch: 39| Step: 0
Training loss: 2.3298729600777204
Validation loss: 2.582525835938913

Epoch: 5| Step: 1
Training loss: 1.8489296781083493
Validation loss: 2.5626958679147447

Epoch: 5| Step: 2
Training loss: 3.216428345332627
Validation loss: 2.5847966942167293

Epoch: 5| Step: 3
Training loss: 1.8859579949580898
Validation loss: 2.5706903823376734

Epoch: 5| Step: 4
Training loss: 2.932429381005613
Validation loss: 2.590602556460431

Epoch: 5| Step: 5
Training loss: 2.410708273017288
Validation loss: 2.5748042519865217

Epoch: 5| Step: 6
Training loss: 2.631192124697532
Validation loss: 2.5666048349533273

Epoch: 5| Step: 7
Training loss: 2.8064528835846794
Validation loss: 2.6045520853297828

Epoch: 5| Step: 8
Training loss: 2.38072748734248
Validation loss: 2.5928427112853414

Epoch: 5| Step: 9
Training loss: 1.795061207739856
Validation loss: 2.596322572465522

Epoch: 5| Step: 10
Training loss: 3.007725781268162
Validation loss: 2.5812572255930166

Epoch: 5| Step: 11
Training loss: 2.9498316248025174
Validation loss: 2.5898707845359494

Epoch: 40| Step: 0
Training loss: 2.4943626741101417
Validation loss: 2.584528144256624

Epoch: 5| Step: 1
Training loss: 2.1323417171933436
Validation loss: 2.597160739533615

Epoch: 5| Step: 2
Training loss: 2.492674394358698
Validation loss: 2.593782635372397

Epoch: 5| Step: 3
Training loss: 2.430263438760272
Validation loss: 2.6028213147524686

Epoch: 5| Step: 4
Training loss: 2.3236362272238926
Validation loss: 2.582212498507801

Epoch: 5| Step: 5
Training loss: 2.6618756130743564
Validation loss: 2.6332371309871894

Epoch: 5| Step: 6
Training loss: 2.3483787097792974
Validation loss: 2.6237518166179403

Epoch: 5| Step: 7
Training loss: 2.502955025415545
Validation loss: 2.607635588346837

Epoch: 5| Step: 8
Training loss: 3.3867456419689974
Validation loss: 2.6109509077932103

Epoch: 5| Step: 9
Training loss: 2.3931456597293947
Validation loss: 2.6254653196564615

Epoch: 5| Step: 10
Training loss: 2.72845568143934
Validation loss: 2.5845764665903443

Epoch: 5| Step: 11
Training loss: 1.2752455531007059
Validation loss: 2.592597234166118

Epoch: 41| Step: 0
Training loss: 3.0556876259977526
Validation loss: 2.5819779783477452

Epoch: 5| Step: 1
Training loss: 2.101035807243149
Validation loss: 2.625484762389833

Epoch: 5| Step: 2
Training loss: 2.609039285044547
Validation loss: 2.564043351744465

Epoch: 5| Step: 3
Training loss: 2.9069756043010515
Validation loss: 2.5437581428503724

Epoch: 5| Step: 4
Training loss: 2.1409439628925586
Validation loss: 2.5741161968543964

Epoch: 5| Step: 5
Training loss: 2.6006567125649025
Validation loss: 2.586152958033413

Epoch: 5| Step: 6
Training loss: 2.3256849777086215
Validation loss: 2.5728710469102474

Epoch: 5| Step: 7
Training loss: 2.3264090339459003
Validation loss: 2.55997614509798

Epoch: 5| Step: 8
Training loss: 2.273804415428645
Validation loss: 2.5521222883612005

Epoch: 5| Step: 9
Training loss: 2.1642849253572556
Validation loss: 2.588713282698213

Epoch: 5| Step: 10
Training loss: 2.8253666192554774
Validation loss: 2.575517692345432

Epoch: 5| Step: 11
Training loss: 2.0446560312514213
Validation loss: 2.587082128368344

Epoch: 42| Step: 0
Training loss: 2.562600296662853
Validation loss: 2.5534721501138034

Epoch: 5| Step: 1
Training loss: 2.7718481533466406
Validation loss: 2.5428243733804297

Epoch: 5| Step: 2
Training loss: 3.2908417517125392
Validation loss: 2.5855861090855856

Epoch: 5| Step: 3
Training loss: 2.5655241078694004
Validation loss: 2.567720209420514

Epoch: 5| Step: 4
Training loss: 2.5345750797941506
Validation loss: 2.581300082733033

Epoch: 5| Step: 5
Training loss: 2.067158726083225
Validation loss: 2.5929977329554164

Epoch: 5| Step: 6
Training loss: 2.1470407835627476
Validation loss: 2.5923811889419563

Epoch: 5| Step: 7
Training loss: 1.9458007199850995
Validation loss: 2.5891161952017203

Epoch: 5| Step: 8
Training loss: 2.985127938242886
Validation loss: 2.563214725746134

Epoch: 5| Step: 9
Training loss: 2.1390369399823674
Validation loss: 2.564957514151375

Epoch: 5| Step: 10
Training loss: 2.2827860220353338
Validation loss: 2.558734631724407

Epoch: 5| Step: 11
Training loss: 1.792192145477101
Validation loss: 2.5540869509551345

Epoch: 43| Step: 0
Training loss: 2.126632624247066
Validation loss: 2.6048369053777845

Epoch: 5| Step: 1
Training loss: 1.8023886963953355
Validation loss: 2.618567688300479

Epoch: 5| Step: 2
Training loss: 3.4268214039678786
Validation loss: 2.6079019511739605

Epoch: 5| Step: 3
Training loss: 2.581497575834482
Validation loss: 2.6243818630060027

Epoch: 5| Step: 4
Training loss: 2.5865394836633206
Validation loss: 2.6408074709054317

Epoch: 5| Step: 5
Training loss: 2.8769491471459263
Validation loss: 2.6739553342791744

Epoch: 5| Step: 6
Training loss: 2.117692837812478
Validation loss: 2.6465164576764124

Epoch: 5| Step: 7
Training loss: 2.76786876974872
Validation loss: 2.6684153840635823

Epoch: 5| Step: 8
Training loss: 2.386410857224711
Validation loss: 2.6566122294256793

Epoch: 5| Step: 9
Training loss: 2.026672487355122
Validation loss: 2.604634431154582

Epoch: 5| Step: 10
Training loss: 2.591742416534118
Validation loss: 2.6057311864297743

Epoch: 5| Step: 11
Training loss: 3.1591122179329374
Validation loss: 2.591081119412944

Epoch: 44| Step: 0
Training loss: 2.0294291624801546
Validation loss: 2.574296760052398

Epoch: 5| Step: 1
Training loss: 2.57150750947316
Validation loss: 2.559250180046227

Epoch: 5| Step: 2
Training loss: 3.0083024852012907
Validation loss: 2.5746678648941272

Epoch: 5| Step: 3
Training loss: 2.3615785123659045
Validation loss: 2.5778096092819265

Epoch: 5| Step: 4
Training loss: 2.321126262137925
Validation loss: 2.573613803385423

Epoch: 5| Step: 5
Training loss: 2.8219670649282125
Validation loss: 2.557042851097829

Epoch: 5| Step: 6
Training loss: 2.2916231902651205
Validation loss: 2.5528094497844873

Epoch: 5| Step: 7
Training loss: 2.919294554006875
Validation loss: 2.5510225011547742

Epoch: 5| Step: 8
Training loss: 2.419527158650581
Validation loss: 2.565278578249064

Epoch: 5| Step: 9
Training loss: 2.1348070592602353
Validation loss: 2.5669448535096793

Epoch: 5| Step: 10
Training loss: 2.2924025192252224
Validation loss: 2.551159159388638

Epoch: 5| Step: 11
Training loss: 3.875333464025704
Validation loss: 2.5763318887239204

Epoch: 45| Step: 0
Training loss: 2.0129843277148205
Validation loss: 2.559298702122774

Epoch: 5| Step: 1
Training loss: 2.458004320617305
Validation loss: 2.531180769362141

Epoch: 5| Step: 2
Training loss: 2.068561086643865
Validation loss: 2.5599572390037295

Epoch: 5| Step: 3
Training loss: 2.885073553036925
Validation loss: 2.5567472089363865

Epoch: 5| Step: 4
Training loss: 2.741031065972523
Validation loss: 2.5359969584384614

Epoch: 5| Step: 5
Training loss: 3.0653987322724237
Validation loss: 2.5590366785788077

Epoch: 5| Step: 6
Training loss: 1.912289230101869
Validation loss: 2.5441136944497016

Epoch: 5| Step: 7
Training loss: 2.01310856781358
Validation loss: 2.5652987307941366

Epoch: 5| Step: 8
Training loss: 2.411059341763619
Validation loss: 2.561251545538373

Epoch: 5| Step: 9
Training loss: 2.7216082927317373
Validation loss: 2.5748134807822436

Epoch: 5| Step: 10
Training loss: 3.022565218061725
Validation loss: 2.5794632415060117

Epoch: 5| Step: 11
Training loss: 1.969854862269239
Validation loss: 2.5803951171692994

Epoch: 46| Step: 0
Training loss: 2.2835284834209375
Validation loss: 2.576870973565232

Epoch: 5| Step: 1
Training loss: 2.3642392573363162
Validation loss: 2.5825510314608966

Epoch: 5| Step: 2
Training loss: 2.8082999339697534
Validation loss: 2.6023509269500105

Epoch: 5| Step: 3
Training loss: 2.6082084012403106
Validation loss: 2.6005493192044025

Epoch: 5| Step: 4
Training loss: 2.7888393793697297
Validation loss: 2.603939165986406

Epoch: 5| Step: 5
Training loss: 2.1103774337912684
Validation loss: 2.5565509008133507

Epoch: 5| Step: 6
Training loss: 2.845895481873851
Validation loss: 2.585235738661017

Epoch: 5| Step: 7
Training loss: 2.7068766760353005
Validation loss: 2.5573834339983965

Epoch: 5| Step: 8
Training loss: 2.0374690000832034
Validation loss: 2.55645635886483

Epoch: 5| Step: 9
Training loss: 2.739692095977524
Validation loss: 2.592680116783181

Epoch: 5| Step: 10
Training loss: 2.307330255350777
Validation loss: 2.579570372810846

Epoch: 5| Step: 11
Training loss: 1.0959419085498527
Validation loss: 2.580134593067503

Epoch: 47| Step: 0
Training loss: 2.6845125849217983
Validation loss: 2.580702189058454

Epoch: 5| Step: 1
Training loss: 2.9183633683026318
Validation loss: 2.5796547175788427

Epoch: 5| Step: 2
Training loss: 2.2038751501940443
Validation loss: 2.584918394700625

Epoch: 5| Step: 3
Training loss: 2.966303248773477
Validation loss: 2.5739003371885176

Epoch: 5| Step: 4
Training loss: 2.16914415542972
Validation loss: 2.591293462384817

Epoch: 5| Step: 5
Training loss: 1.9521662685997803
Validation loss: 2.5975073635485257

Epoch: 5| Step: 6
Training loss: 2.265024355490054
Validation loss: 2.6053797693800522

Epoch: 5| Step: 7
Training loss: 2.055216905975895
Validation loss: 2.5879634611808155

Epoch: 5| Step: 8
Training loss: 2.602861601290474
Validation loss: 2.5919592317094793

Epoch: 5| Step: 9
Training loss: 2.5718288412853583
Validation loss: 2.5596934937419475

Epoch: 5| Step: 10
Training loss: 2.9399455827101417
Validation loss: 2.604585767718491

Epoch: 5| Step: 11
Training loss: 2.6474425661018794
Validation loss: 2.573231258284675

Epoch: 48| Step: 0
Training loss: 2.5693697142401657
Validation loss: 2.5772052974000834

Epoch: 5| Step: 1
Training loss: 2.553657254006724
Validation loss: 2.5349280749882466

Epoch: 5| Step: 2
Training loss: 2.555613125507385
Validation loss: 2.558018467804658

Epoch: 5| Step: 3
Training loss: 2.3414574155158827
Validation loss: 2.5716949579096435

Epoch: 5| Step: 4
Training loss: 2.5224325818673368
Validation loss: 2.5280026417637456

Epoch: 5| Step: 5
Training loss: 2.467618755509101
Validation loss: 2.551200372710719

Epoch: 5| Step: 6
Training loss: 2.1675597208808814
Validation loss: 2.5672129152463556

Epoch: 5| Step: 7
Training loss: 2.458734792052393
Validation loss: 2.565230914758794

Epoch: 5| Step: 8
Training loss: 1.9568095129185756
Validation loss: 2.561442823907335

Epoch: 5| Step: 9
Training loss: 2.5127429446150855
Validation loss: 2.580116885806371

Epoch: 5| Step: 10
Training loss: 3.057598629325268
Validation loss: 2.5885155764108596

Epoch: 5| Step: 11
Training loss: 3.605040222028238
Validation loss: 2.5714245007277112

Epoch: 49| Step: 0
Training loss: 2.4176034975037943
Validation loss: 2.534088246797308

Epoch: 5| Step: 1
Training loss: 2.0921491509726957
Validation loss: 2.568768757537396

Epoch: 5| Step: 2
Training loss: 2.506118820448426
Validation loss: 2.5547042480604154

Epoch: 5| Step: 3
Training loss: 2.662370877425766
Validation loss: 2.5642403531037643

Epoch: 5| Step: 4
Training loss: 3.158185912812559
Validation loss: 2.544688856494681

Epoch: 5| Step: 5
Training loss: 2.110075092696956
Validation loss: 2.5625949508629255

Epoch: 5| Step: 6
Training loss: 2.166059653520055
Validation loss: 2.5440840690000543

Epoch: 5| Step: 7
Training loss: 2.266552228937212
Validation loss: 2.5737787969620025

Epoch: 5| Step: 8
Training loss: 2.099259373080494
Validation loss: 2.5609662575510366

Epoch: 5| Step: 9
Training loss: 2.7497269754993527
Validation loss: 2.572387955020123

Epoch: 5| Step: 10
Training loss: 3.4436248313463156
Validation loss: 2.5609249744648164

Epoch: 5| Step: 11
Training loss: 0.5306923969273338
Validation loss: 2.570627801913555

Epoch: 50| Step: 0
Training loss: 2.002639697437226
Validation loss: 2.5893881441630278

Epoch: 5| Step: 1
Training loss: 2.688054493323364
Validation loss: 2.552711336887562

Epoch: 5| Step: 2
Training loss: 2.6169309575758297
Validation loss: 2.590831550950494

Epoch: 5| Step: 3
Training loss: 1.860790707478236
Validation loss: 2.568522284965236

Epoch: 5| Step: 4
Training loss: 2.6680834006924403
Validation loss: 2.577521856636497

Epoch: 5| Step: 5
Training loss: 2.2541611657865843
Validation loss: 2.6018039870042045

Epoch: 5| Step: 6
Training loss: 2.4411528188774922
Validation loss: 2.5618737936532785

Epoch: 5| Step: 7
Training loss: 2.4702921046766875
Validation loss: 2.584616762697693

Epoch: 5| Step: 8
Training loss: 3.4339227269253785
Validation loss: 2.561178529579057

Epoch: 5| Step: 9
Training loss: 2.2111118638800398
Validation loss: 2.5924103007835964

Epoch: 5| Step: 10
Training loss: 2.439093826747694
Validation loss: 2.5636566002006274

Epoch: 5| Step: 11
Training loss: 2.9251856687908573
Validation loss: 2.5576826303020246

Epoch: 51| Step: 0
Training loss: 2.1852983566954602
Validation loss: 2.5720752519136276

Epoch: 5| Step: 1
Training loss: 2.7787720860999086
Validation loss: 2.5716196348245317

Epoch: 5| Step: 2
Training loss: 2.739452856943119
Validation loss: 2.5798733495459363

Epoch: 5| Step: 3
Training loss: 2.8546734288061457
Validation loss: 2.591557974442467

Epoch: 5| Step: 4
Training loss: 1.7038089883602383
Validation loss: 2.550269281436909

Epoch: 5| Step: 5
Training loss: 2.132129378138116
Validation loss: 2.5842450453263073

Epoch: 5| Step: 6
Training loss: 2.5481784971945065
Validation loss: 2.5640062503041734

Epoch: 5| Step: 7
Training loss: 2.9402916811581954
Validation loss: 2.5612332228977897

Epoch: 5| Step: 8
Training loss: 2.494560236274102
Validation loss: 2.5643719681862818

Epoch: 5| Step: 9
Training loss: 2.518323505347931
Validation loss: 2.5643636509204657

Epoch: 5| Step: 10
Training loss: 2.438568565701544
Validation loss: 2.542090221717287

Epoch: 5| Step: 11
Training loss: 1.352407599164412
Validation loss: 2.537598670174848

Epoch: 52| Step: 0
Training loss: 2.915154546498052
Validation loss: 2.5313155593545273

Epoch: 5| Step: 1
Training loss: 2.24857656169464
Validation loss: 2.558820230103808

Epoch: 5| Step: 2
Training loss: 2.830604098919405
Validation loss: 2.5448969080791572

Epoch: 5| Step: 3
Training loss: 2.414522886356183
Validation loss: 2.555507703231758

Epoch: 5| Step: 4
Training loss: 2.5103834052408396
Validation loss: 2.572599632149109

Epoch: 5| Step: 5
Training loss: 2.659487916227953
Validation loss: 2.572699376762365

Epoch: 5| Step: 6
Training loss: 2.305322074813371
Validation loss: 2.5767286738657456

Epoch: 5| Step: 7
Training loss: 2.326937276502234
Validation loss: 2.568862838618075

Epoch: 5| Step: 8
Training loss: 1.9165162842952184
Validation loss: 2.591654133740834

Epoch: 5| Step: 9
Training loss: 2.432093762685889
Validation loss: 2.618658178293212

Epoch: 5| Step: 10
Training loss: 2.5165124121711724
Validation loss: 2.580960204056959

Epoch: 5| Step: 11
Training loss: 2.674485743637442
Validation loss: 2.6150653567027273

Epoch: 53| Step: 0
Training loss: 2.370090127671805
Validation loss: 2.620501508665145

Epoch: 5| Step: 1
Training loss: 2.7686185852965752
Validation loss: 2.564948972212427

Epoch: 5| Step: 2
Training loss: 1.899226334814432
Validation loss: 2.55697142051899

Epoch: 5| Step: 3
Training loss: 2.6589766924676916
Validation loss: 2.610093370030554

Epoch: 5| Step: 4
Training loss: 2.5999957341379236
Validation loss: 2.576323228332393

Epoch: 5| Step: 5
Training loss: 2.915399566799419
Validation loss: 2.5982375257061645

Epoch: 5| Step: 6
Training loss: 2.82758785647592
Validation loss: 2.60623190177531

Epoch: 5| Step: 7
Training loss: 2.3954685983974415
Validation loss: 2.5815558003005146

Epoch: 5| Step: 8
Training loss: 2.2467384010355964
Validation loss: 2.5474430106118

Epoch: 5| Step: 9
Training loss: 2.4738418605223744
Validation loss: 2.582576395986953

Epoch: 5| Step: 10
Training loss: 2.009344206910728
Validation loss: 2.5874553789447

Epoch: 5| Step: 11
Training loss: 2.4124819819118475
Validation loss: 2.567988685381207

Epoch: 54| Step: 0
Training loss: 2.8325750420807134
Validation loss: 2.5978367907662894

Epoch: 5| Step: 1
Training loss: 1.840521750282495
Validation loss: 2.5534976362007433

Epoch: 5| Step: 2
Training loss: 2.0859572734681358
Validation loss: 2.560138036395184

Epoch: 5| Step: 3
Training loss: 2.5662326144350946
Validation loss: 2.5518394133071602

Epoch: 5| Step: 4
Training loss: 3.1015880208923257
Validation loss: 2.5244889484958692

Epoch: 5| Step: 5
Training loss: 2.6450184946549333
Validation loss: 2.55339786125132

Epoch: 5| Step: 6
Training loss: 2.5526052966242165
Validation loss: 2.5697413875783

Epoch: 5| Step: 7
Training loss: 2.7523804678675297
Validation loss: 2.570666303314418

Epoch: 5| Step: 8
Training loss: 2.234101285374996
Validation loss: 2.5471755164465955

Epoch: 5| Step: 9
Training loss: 2.290424137233991
Validation loss: 2.5648335244684404

Epoch: 5| Step: 10
Training loss: 2.125612843721844
Validation loss: 2.5514697303890164

Epoch: 5| Step: 11
Training loss: 2.981852638865997
Validation loss: 2.547165629805048

Epoch: 55| Step: 0
Training loss: 2.2360637125345226
Validation loss: 2.5590174588657186

Epoch: 5| Step: 1
Training loss: 2.3039131544752847
Validation loss: 2.5633046546091536

Epoch: 5| Step: 2
Training loss: 2.9652840710785844
Validation loss: 2.5713836926815308

Epoch: 5| Step: 3
Training loss: 2.678914662122938
Validation loss: 2.57436725842191

Epoch: 5| Step: 4
Training loss: 2.5875086318899463
Validation loss: 2.606069027649846

Epoch: 5| Step: 5
Training loss: 2.532996340556613
Validation loss: 2.5791527982430345

Epoch: 5| Step: 6
Training loss: 2.6702880608258925
Validation loss: 2.603727217153523

Epoch: 5| Step: 7
Training loss: 2.789593814282223
Validation loss: 2.5874842025901166

Epoch: 5| Step: 8
Training loss: 2.3745178937978775
Validation loss: 2.6016213770285983

Epoch: 5| Step: 9
Training loss: 2.2463578309429404
Validation loss: 2.577153672163257

Epoch: 5| Step: 10
Training loss: 1.7203670177777601
Validation loss: 2.5703672192593725

Epoch: 5| Step: 11
Training loss: 2.7243590099743225
Validation loss: 2.578084533065558

Epoch: 56| Step: 0
Training loss: 2.1835902560347717
Validation loss: 2.5924901890178207

Epoch: 5| Step: 1
Training loss: 2.362015516063817
Validation loss: 2.580089061789924

Epoch: 5| Step: 2
Training loss: 2.421425660811201
Validation loss: 2.5977902638373056

Epoch: 5| Step: 3
Training loss: 2.997175158285441
Validation loss: 2.6301033540429057

Epoch: 5| Step: 4
Training loss: 2.4993511311563936
Validation loss: 2.624206892423802

Epoch: 5| Step: 5
Training loss: 2.6906661080333683
Validation loss: 2.658300989850118

Epoch: 5| Step: 6
Training loss: 2.0524080926388026
Validation loss: 2.6498675278775226

Epoch: 5| Step: 7
Training loss: 2.9266300778140244
Validation loss: 2.6625014884180436

Epoch: 5| Step: 8
Training loss: 2.8169671080879373
Validation loss: 2.624905603467508

Epoch: 5| Step: 9
Training loss: 2.42914322524977
Validation loss: 2.5823784852959246

Epoch: 5| Step: 10
Training loss: 2.4036472660830532
Validation loss: 2.6009720083484567

Epoch: 5| Step: 11
Training loss: 0.8107178657061382
Validation loss: 2.569385380681821

Epoch: 57| Step: 0
Training loss: 2.3715536309454786
Validation loss: 2.5639338242351872

Epoch: 5| Step: 1
Training loss: 2.2875945816915038
Validation loss: 2.5559317487851043

Epoch: 5| Step: 2
Training loss: 2.4397621417192505
Validation loss: 2.576375814891956

Epoch: 5| Step: 3
Training loss: 2.9113675252893736
Validation loss: 2.5505795596243317

Epoch: 5| Step: 4
Training loss: 2.1449805728770643
Validation loss: 2.5543471526701724

Epoch: 5| Step: 5
Training loss: 2.930476456268193
Validation loss: 2.5272507746249344

Epoch: 5| Step: 6
Training loss: 2.3784376663209956
Validation loss: 2.5641923293882436

Epoch: 5| Step: 7
Training loss: 2.3373981106833144
Validation loss: 2.561710127381377

Epoch: 5| Step: 8
Training loss: 2.676650926473219
Validation loss: 2.5644015219600944

Epoch: 5| Step: 9
Training loss: 2.1254791392772328
Validation loss: 2.5776782024360063

Epoch: 5| Step: 10
Training loss: 2.7664191188906146
Validation loss: 2.547360235534996

Epoch: 5| Step: 11
Training loss: 1.3571731449275366
Validation loss: 2.5622516527242842

Epoch: 58| Step: 0
Training loss: 2.612508662451295
Validation loss: 2.5249118493685088

Epoch: 5| Step: 1
Training loss: 2.6556745915710227
Validation loss: 2.544372651565956

Epoch: 5| Step: 2
Training loss: 2.4898753187837297
Validation loss: 2.5502336546181454

Epoch: 5| Step: 3
Training loss: 3.0083454403056855
Validation loss: 2.573149382276746

Epoch: 5| Step: 4
Training loss: 2.0744340285602907
Validation loss: 2.548024524663018

Epoch: 5| Step: 5
Training loss: 2.576480132683928
Validation loss: 2.568305363347041

Epoch: 5| Step: 6
Training loss: 2.2436342257327495
Validation loss: 2.5616882868416786

Epoch: 5| Step: 7
Training loss: 2.1585683108034326
Validation loss: 2.5679321939458117

Epoch: 5| Step: 8
Training loss: 2.6994181889167868
Validation loss: 2.551059880989277

Epoch: 5| Step: 9
Training loss: 2.0345564707083508
Validation loss: 2.5445271515493597

Epoch: 5| Step: 10
Training loss: 2.3231309412730683
Validation loss: 2.567213491817873

Epoch: 5| Step: 11
Training loss: 2.4831177031157536
Validation loss: 2.5552949873336703

Epoch: 59| Step: 0
Training loss: 3.199112477010454
Validation loss: 2.58550511612832

Epoch: 5| Step: 1
Training loss: 2.4754830784844386
Validation loss: 2.6055460341247274

Epoch: 5| Step: 2
Training loss: 2.291855810047096
Validation loss: 2.6078789966319014

Epoch: 5| Step: 3
Training loss: 2.5752555831435378
Validation loss: 2.6216924280217357

Epoch: 5| Step: 4
Training loss: 2.0828426418999464
Validation loss: 2.636216273525414

Epoch: 5| Step: 5
Training loss: 2.519272617993772
Validation loss: 2.620724071616656

Epoch: 5| Step: 6
Training loss: 2.0843026258723234
Validation loss: 2.636840843858924

Epoch: 5| Step: 7
Training loss: 2.633028921406743
Validation loss: 2.6190056136662117

Epoch: 5| Step: 8
Training loss: 2.5705160043036783
Validation loss: 2.632851280583324

Epoch: 5| Step: 9
Training loss: 2.1475223326049173
Validation loss: 2.608534081618147

Epoch: 5| Step: 10
Training loss: 2.6400726462974977
Validation loss: 2.580473845189364

Epoch: 5| Step: 11
Training loss: 0.5594279855535543
Validation loss: 2.573072190674406

Epoch: 60| Step: 0
Training loss: 2.825126280536246
Validation loss: 2.619800424782363

Epoch: 5| Step: 1
Training loss: 2.4473388855754346
Validation loss: 2.5976037691785567

Epoch: 5| Step: 2
Training loss: 2.331630755464484
Validation loss: 2.5637250546104013

Epoch: 5| Step: 3
Training loss: 1.8277446644626485
Validation loss: 2.5789153207432394

Epoch: 5| Step: 4
Training loss: 2.7226821701151405
Validation loss: 2.568103761124829

Epoch: 5| Step: 5
Training loss: 2.5165512559545524
Validation loss: 2.54801198235738

Epoch: 5| Step: 6
Training loss: 2.9559220888248454
Validation loss: 2.561129742510014

Epoch: 5| Step: 7
Training loss: 2.4455769063820703
Validation loss: 2.5344519516080526

Epoch: 5| Step: 8
Training loss: 2.4205883915519215
Validation loss: 2.56344020078998

Epoch: 5| Step: 9
Training loss: 2.20808361248982
Validation loss: 2.5420257882686714

Epoch: 5| Step: 10
Training loss: 2.6106935927074364
Validation loss: 2.53794893152093

Epoch: 5| Step: 11
Training loss: 0.9519916111832954
Validation loss: 2.5636493152356423

Epoch: 61| Step: 0
Training loss: 2.552770519511471
Validation loss: 2.571074306213986

Epoch: 5| Step: 1
Training loss: 2.1805798744524787
Validation loss: 2.554516828398553

Epoch: 5| Step: 2
Training loss: 2.8752849271812324
Validation loss: 2.57049450138169

Epoch: 5| Step: 3
Training loss: 1.9640580838077153
Validation loss: 2.578218909200527

Epoch: 5| Step: 4
Training loss: 2.085282012016867
Validation loss: 2.568707712046589

Epoch: 5| Step: 5
Training loss: 2.6013755387493585
Validation loss: 2.555462640879229

Epoch: 5| Step: 6
Training loss: 2.1011201187286783
Validation loss: 2.5780867255866604

Epoch: 5| Step: 7
Training loss: 2.4011909510169844
Validation loss: 2.5668773209114195

Epoch: 5| Step: 8
Training loss: 1.7891098082838326
Validation loss: 2.5691345630829634

Epoch: 5| Step: 9
Training loss: 2.883625691169022
Validation loss: 2.552586783491524

Epoch: 5| Step: 10
Training loss: 3.1300097173472925
Validation loss: 2.5395333503976234

Epoch: 5| Step: 11
Training loss: 3.494393353947059
Validation loss: 2.5546978086055536

Epoch: 62| Step: 0
Training loss: 2.7105235902385623
Validation loss: 2.5542937372894934

Epoch: 5| Step: 1
Training loss: 2.0398672569320095
Validation loss: 2.565669735492551

Epoch: 5| Step: 2
Training loss: 2.2484872819109483
Validation loss: 2.5496118073967855

Epoch: 5| Step: 3
Training loss: 2.6599898993508297
Validation loss: 2.550778033111865

Epoch: 5| Step: 4
Training loss: 2.7748797038354756
Validation loss: 2.584008633631149

Epoch: 5| Step: 5
Training loss: 2.257649135289297
Validation loss: 2.553662711880076

Epoch: 5| Step: 6
Training loss: 2.2976042958559453
Validation loss: 2.5533369307102562

Epoch: 5| Step: 7
Training loss: 2.9606205511432164
Validation loss: 2.5579244966247825

Epoch: 5| Step: 8
Training loss: 2.4005382172764884
Validation loss: 2.5575262390722284

Epoch: 5| Step: 9
Training loss: 2.3488331921407175
Validation loss: 2.5612329475141733

Epoch: 5| Step: 10
Training loss: 2.396445574831075
Validation loss: 2.55409029591832

Epoch: 5| Step: 11
Training loss: 1.010760822216504
Validation loss: 2.5482019135063454

Epoch: 63| Step: 0
Training loss: 2.4793493914117075
Validation loss: 2.5493408272097224

Epoch: 5| Step: 1
Training loss: 2.0786400637112075
Validation loss: 2.5444990359640767

Epoch: 5| Step: 2
Training loss: 2.377320812063285
Validation loss: 2.554248585458188

Epoch: 5| Step: 3
Training loss: 2.87424094089694
Validation loss: 2.5600608288720457

Epoch: 5| Step: 4
Training loss: 2.422466378150889
Validation loss: 2.579099420914681

Epoch: 5| Step: 5
Training loss: 2.91984920347485
Validation loss: 2.553962219595873

Epoch: 5| Step: 6
Training loss: 1.884693077153787
Validation loss: 2.5553978837365463

Epoch: 5| Step: 7
Training loss: 2.7683159619298667
Validation loss: 2.58456295626111

Epoch: 5| Step: 8
Training loss: 1.8338748464490031
Validation loss: 2.5696906600438503

Epoch: 5| Step: 9
Training loss: 2.6168116057602435
Validation loss: 2.5743587959411194

Epoch: 5| Step: 10
Training loss: 2.587503471925037
Validation loss: 2.577181926826269

Epoch: 5| Step: 11
Training loss: 2.004931449764708
Validation loss: 2.576973336127856

Epoch: 64| Step: 0
Training loss: 2.3615458019757103
Validation loss: 2.5649379088971433

Epoch: 5| Step: 1
Training loss: 2.1243062850464827
Validation loss: 2.593948341354265

Epoch: 5| Step: 2
Training loss: 2.2525230672419387
Validation loss: 2.5810605569985148

Epoch: 5| Step: 3
Training loss: 2.6073072086795084
Validation loss: 2.579237214439841

Epoch: 5| Step: 4
Training loss: 2.832232953485221
Validation loss: 2.5832873514656693

Epoch: 5| Step: 5
Training loss: 2.052249869416435
Validation loss: 2.5878817806452643

Epoch: 5| Step: 6
Training loss: 2.040518288502132
Validation loss: 2.5993282625644287

Epoch: 5| Step: 7
Training loss: 2.0762704016632214
Validation loss: 2.549186804077613

Epoch: 5| Step: 8
Training loss: 3.6252728063598507
Validation loss: 2.6186492140319317

Epoch: 5| Step: 9
Training loss: 2.2825199929371833
Validation loss: 2.5901666807179553

Epoch: 5| Step: 10
Training loss: 2.4163504316886497
Validation loss: 2.5626529322322984

Epoch: 5| Step: 11
Training loss: 1.9837611893624945
Validation loss: 2.5758706341608346

Epoch: 65| Step: 0
Training loss: 3.2564070709477875
Validation loss: 2.5431217669084183

Epoch: 5| Step: 1
Training loss: 2.122210185974945
Validation loss: 2.5451385140400657

Epoch: 5| Step: 2
Training loss: 2.1942489056714334
Validation loss: 2.5493927799093337

Epoch: 5| Step: 3
Training loss: 2.632878877159603
Validation loss: 2.556086399280699

Epoch: 5| Step: 4
Training loss: 2.0469573492126916
Validation loss: 2.517596587790854

Epoch: 5| Step: 5
Training loss: 2.630628364689534
Validation loss: 2.5463044789372242

Epoch: 5| Step: 6
Training loss: 2.234406370996447
Validation loss: 2.5436594191661124

Epoch: 5| Step: 7
Training loss: 2.067727371499715
Validation loss: 2.566919326783408

Epoch: 5| Step: 8
Training loss: 2.2850016223726417
Validation loss: 2.555599450400144

Epoch: 5| Step: 9
Training loss: 2.766134786227637
Validation loss: 2.5849057585472983

Epoch: 5| Step: 10
Training loss: 2.6650694792602816
Validation loss: 2.529343672114487

Epoch: 5| Step: 11
Training loss: 2.6638763452189718
Validation loss: 2.5532540237777033

Epoch: 66| Step: 0
Training loss: 2.3400689273039994
Validation loss: 2.551595381715463

Epoch: 5| Step: 1
Training loss: 2.6013394280184166
Validation loss: 2.543526497972003

Epoch: 5| Step: 2
Training loss: 2.776967813235921
Validation loss: 2.5548463046832763

Epoch: 5| Step: 3
Training loss: 2.060748772876823
Validation loss: 2.540808365989952

Epoch: 5| Step: 4
Training loss: 2.47222539875336
Validation loss: 2.570868624244547

Epoch: 5| Step: 5
Training loss: 1.9245583634519599
Validation loss: 2.543576009331415

Epoch: 5| Step: 6
Training loss: 2.4572317165960174
Validation loss: 2.554862762023327

Epoch: 5| Step: 7
Training loss: 3.4590978275348823
Validation loss: 2.535276963583496

Epoch: 5| Step: 8
Training loss: 2.2337707556137567
Validation loss: 2.564151611577335

Epoch: 5| Step: 9
Training loss: 2.680754424137306
Validation loss: 2.5742116068392153

Epoch: 5| Step: 10
Training loss: 2.119234791434589
Validation loss: 2.563995378581597

Epoch: 5| Step: 11
Training loss: 1.0699115754070816
Validation loss: 2.5152853465959613

Epoch: 67| Step: 0
Training loss: 2.7061106339793612
Validation loss: 2.552331244176596

Epoch: 5| Step: 1
Training loss: 2.080642093623753
Validation loss: 2.5565716894699833

Epoch: 5| Step: 2
Training loss: 1.5831072127182193
Validation loss: 2.5251213888065687

Epoch: 5| Step: 3
Training loss: 2.727383902480098
Validation loss: 2.5580417066630874

Epoch: 5| Step: 4
Training loss: 2.380310746430548
Validation loss: 2.60998967634549

Epoch: 5| Step: 5
Training loss: 2.214479339062242
Validation loss: 2.5751889628608238

Epoch: 5| Step: 6
Training loss: 3.4374647658883184
Validation loss: 2.6170895572384483

Epoch: 5| Step: 7
Training loss: 2.010490086718645
Validation loss: 2.5797135054295905

Epoch: 5| Step: 8
Training loss: 2.7062164445519103
Validation loss: 2.5820977245243912

Epoch: 5| Step: 9
Training loss: 2.1339521891306763
Validation loss: 2.600926161984294

Epoch: 5| Step: 10
Training loss: 2.426667522999679
Validation loss: 2.5695906942575633

Epoch: 5| Step: 11
Training loss: 3.19071992290201
Validation loss: 2.6031287655415802

Epoch: 68| Step: 0
Training loss: 2.603247935676837
Validation loss: 2.569498031647376

Epoch: 5| Step: 1
Training loss: 2.195374728912561
Validation loss: 2.564719188995323

Epoch: 5| Step: 2
Training loss: 2.361674621755285
Validation loss: 2.547893673446557

Epoch: 5| Step: 3
Training loss: 2.4802428615772256
Validation loss: 2.551354846653405

Epoch: 5| Step: 4
Training loss: 2.0825293197491233
Validation loss: 2.556895422812351

Epoch: 5| Step: 5
Training loss: 2.4868868239803086
Validation loss: 2.5358226117841265

Epoch: 5| Step: 6
Training loss: 2.91217929236783
Validation loss: 2.534856793273013

Epoch: 5| Step: 7
Training loss: 2.089420111668703
Validation loss: 2.552319026625277

Epoch: 5| Step: 8
Training loss: 2.216502488540846
Validation loss: 2.551244003435882

Epoch: 5| Step: 9
Training loss: 2.4425772582283964
Validation loss: 2.5569992299633832

Epoch: 5| Step: 10
Training loss: 3.179766979676961
Validation loss: 2.5498255934942415

Epoch: 5| Step: 11
Training loss: 1.7446332109912257
Validation loss: 2.5595426940010086

Epoch: 69| Step: 0
Training loss: 2.964289959036173
Validation loss: 2.5709974696120823

Epoch: 5| Step: 1
Training loss: 1.9748172216703341
Validation loss: 2.5415454246703804

Epoch: 5| Step: 2
Training loss: 1.7421396017974216
Validation loss: 2.5567180212869554

Epoch: 5| Step: 3
Training loss: 2.781227197446465
Validation loss: 2.5395436148996815

Epoch: 5| Step: 4
Training loss: 2.3476970751571975
Validation loss: 2.5556676658339677

Epoch: 5| Step: 5
Training loss: 2.7178341430068986
Validation loss: 2.5497219384435192

Epoch: 5| Step: 6
Training loss: 2.492764014644936
Validation loss: 2.5581307106255675

Epoch: 5| Step: 7
Training loss: 2.986960045449278
Validation loss: 2.535430689584596

Epoch: 5| Step: 8
Training loss: 2.307472124354982
Validation loss: 2.554456585666313

Epoch: 5| Step: 9
Training loss: 1.9397062230608546
Validation loss: 2.5592635076487515

Epoch: 5| Step: 10
Training loss: 2.19732920914945
Validation loss: 2.523275368189328

Epoch: 5| Step: 11
Training loss: 2.3999385547719565
Validation loss: 2.5354298040905894

Epoch: 70| Step: 0
Training loss: 1.9335341935667056
Validation loss: 2.5390030252386806

Epoch: 5| Step: 1
Training loss: 2.311646381262583
Validation loss: 2.575316620005533

Epoch: 5| Step: 2
Training loss: 3.0659154414132956
Validation loss: 2.5709124408949044

Epoch: 5| Step: 3
Training loss: 2.4029811106688292
Validation loss: 2.5718693757488174

Epoch: 5| Step: 4
Training loss: 2.1807274747273584
Validation loss: 2.5643048133390574

Epoch: 5| Step: 5
Training loss: 2.1560539488191166
Validation loss: 2.576405736080404

Epoch: 5| Step: 6
Training loss: 3.064765870453768
Validation loss: 2.5656877592885095

Epoch: 5| Step: 7
Training loss: 2.441494724959363
Validation loss: 2.5632569234093436

Epoch: 5| Step: 8
Training loss: 2.253601899911542
Validation loss: 2.601132873862991

Epoch: 5| Step: 9
Training loss: 2.0794374150780106
Validation loss: 2.5778201105957548

Epoch: 5| Step: 10
Training loss: 2.7094259747876492
Validation loss: 2.6027562454574227

Epoch: 5| Step: 11
Training loss: 1.7778868128532892
Validation loss: 2.570657303088775

Epoch: 71| Step: 0
Training loss: 2.651144978746681
Validation loss: 2.565092310740896

Epoch: 5| Step: 1
Training loss: 2.7388133621721105
Validation loss: 2.570850772015384

Epoch: 5| Step: 2
Training loss: 2.638517904695444
Validation loss: 2.5623387968329245

Epoch: 5| Step: 3
Training loss: 1.867936307401216
Validation loss: 2.563428497348249

Epoch: 5| Step: 4
Training loss: 2.5854373690267876
Validation loss: 2.5633223307397817

Epoch: 5| Step: 5
Training loss: 2.8506215672554904
Validation loss: 2.5680539644588394

Epoch: 5| Step: 6
Training loss: 2.2871479451407217
Validation loss: 2.5469712042239756

Epoch: 5| Step: 7
Training loss: 2.7856908769287734
Validation loss: 2.571067540697715

Epoch: 5| Step: 8
Training loss: 2.4240300588538104
Validation loss: 2.5781380701215415

Epoch: 5| Step: 9
Training loss: 1.8834654756059859
Validation loss: 2.5586549707907085

Epoch: 5| Step: 10
Training loss: 2.193410898284537
Validation loss: 2.5491158431420615

Epoch: 5| Step: 11
Training loss: 1.6156440040164273
Validation loss: 2.5675839412702066

Epoch: 72| Step: 0
Training loss: 1.7355912901118904
Validation loss: 2.55733229817874

Epoch: 5| Step: 1
Training loss: 2.3969704182517817
Validation loss: 2.5582108189223502

Epoch: 5| Step: 2
Training loss: 2.4256458091088975
Validation loss: 2.581915017424794

Epoch: 5| Step: 3
Training loss: 2.2815000841156197
Validation loss: 2.6060413758888683

Epoch: 5| Step: 4
Training loss: 2.361287838424171
Validation loss: 2.6376544074048387

Epoch: 5| Step: 5
Training loss: 1.840866484935694
Validation loss: 2.6598750081070905

Epoch: 5| Step: 6
Training loss: 2.564341371981918
Validation loss: 2.6609022781421334

Epoch: 5| Step: 7
Training loss: 2.9543557806420813
Validation loss: 2.65134414840814

Epoch: 5| Step: 8
Training loss: 3.3822560898946423
Validation loss: 2.6601909498882117

Epoch: 5| Step: 9
Training loss: 2.3555885904422857
Validation loss: 2.6626656115131393

Epoch: 5| Step: 10
Training loss: 2.823249956751676
Validation loss: 2.636316037919271

Epoch: 5| Step: 11
Training loss: 2.5153025544877883
Validation loss: 2.5942770219530047

Epoch: 73| Step: 0
Training loss: 2.1939033519909663
Validation loss: 2.5531992256770772

Epoch: 5| Step: 1
Training loss: 2.6461287706488723
Validation loss: 2.539007692968176

Epoch: 5| Step: 2
Training loss: 2.3222639823375184
Validation loss: 2.554271617483924

Epoch: 5| Step: 3
Training loss: 2.4356301789770747
Validation loss: 2.553250035742041

Epoch: 5| Step: 4
Training loss: 2.1515054887741045
Validation loss: 2.533473394285589

Epoch: 5| Step: 5
Training loss: 2.597513983709972
Validation loss: 2.5352590390190857

Epoch: 5| Step: 6
Training loss: 2.113609302604816
Validation loss: 2.565664852977371

Epoch: 5| Step: 7
Training loss: 2.41356033978725
Validation loss: 2.5522447567446007

Epoch: 5| Step: 8
Training loss: 3.1148079033121983
Validation loss: 2.568035872166033

Epoch: 5| Step: 9
Training loss: 2.306993165236304
Validation loss: 2.553499982106204

Epoch: 5| Step: 10
Training loss: 2.6345546855713335
Validation loss: 2.5654567856961448

Epoch: 5| Step: 11
Training loss: 2.033055017007399
Validation loss: 2.5404257298548183

Epoch: 74| Step: 0
Training loss: 1.9672981843116955
Validation loss: 2.5523863430884908

Epoch: 5| Step: 1
Training loss: 2.2433009556346355
Validation loss: 2.54558512236782

Epoch: 5| Step: 2
Training loss: 2.8850806599519383
Validation loss: 2.535070299318718

Epoch: 5| Step: 3
Training loss: 2.0031384638722147
Validation loss: 2.5482759932455346

Epoch: 5| Step: 4
Training loss: 2.3409660589991446
Validation loss: 2.5392568699704143

Epoch: 5| Step: 5
Training loss: 2.497970233901763
Validation loss: 2.5693096728391884

Epoch: 5| Step: 6
Training loss: 3.1510088622011856
Validation loss: 2.5487966718231116

Epoch: 5| Step: 7
Training loss: 2.593328878387443
Validation loss: 2.5670491366055725

Epoch: 5| Step: 8
Training loss: 2.2480241789281115
Validation loss: 2.5567426785003997

Epoch: 5| Step: 9
Training loss: 2.2965896325371453
Validation loss: 2.572967752085936

Epoch: 5| Step: 10
Training loss: 2.377447673971893
Validation loss: 2.5752863158453416

Epoch: 5| Step: 11
Training loss: 2.379723118936893
Validation loss: 2.5664036371923236

Epoch: 75| Step: 0
Training loss: 2.7909666768527512
Validation loss: 2.59672438272337

Epoch: 5| Step: 1
Training loss: 2.5972051013602093
Validation loss: 2.6052394310397915

Epoch: 5| Step: 2
Training loss: 2.273965780747212
Validation loss: 2.590869529727303

Epoch: 5| Step: 3
Training loss: 3.267090828923499
Validation loss: 2.5770182035188354

Epoch: 5| Step: 4
Training loss: 1.4683525684033514
Validation loss: 2.6080591573112613

Epoch: 5| Step: 5
Training loss: 2.4371934355619356
Validation loss: 2.61940440329576

Epoch: 5| Step: 6
Training loss: 2.5929887872549853
Validation loss: 2.6187902183448797

Epoch: 5| Step: 7
Training loss: 2.2948831238417147
Validation loss: 2.6271961539352726

Epoch: 5| Step: 8
Training loss: 2.4022494662011624
Validation loss: 2.598161503885071

Epoch: 5| Step: 9
Training loss: 2.4351477399181083
Validation loss: 2.5868278192391285

Epoch: 5| Step: 10
Training loss: 1.8440996258813624
Validation loss: 2.5579464994023633

Epoch: 5| Step: 11
Training loss: 1.7216558687376775
Validation loss: 2.5430587971375735

Epoch: 76| Step: 0
Training loss: 2.665390802182099
Validation loss: 2.5574685104870247

Epoch: 5| Step: 1
Training loss: 2.1674599540205386
Validation loss: 2.5293387587527154

Epoch: 5| Step: 2
Training loss: 2.0011680291738494
Validation loss: 2.540814197482195

Epoch: 5| Step: 3
Training loss: 2.140608627368101
Validation loss: 2.5622370980472313

Epoch: 5| Step: 4
Training loss: 1.9194799246348084
Validation loss: 2.5538212340868958

Epoch: 5| Step: 5
Training loss: 2.5420385203350455
Validation loss: 2.5430774616652387

Epoch: 5| Step: 6
Training loss: 2.3897279539858256
Validation loss: 2.558783231518502

Epoch: 5| Step: 7
Training loss: 2.366690807040318
Validation loss: 2.563385651444762

Epoch: 5| Step: 8
Training loss: 2.8785189778317086
Validation loss: 2.543000388546813

Epoch: 5| Step: 9
Training loss: 2.1796649671914397
Validation loss: 2.559332137783348

Epoch: 5| Step: 10
Training loss: 3.2103559055474213
Validation loss: 2.5851187048366686

Epoch: 5| Step: 11
Training loss: 1.485639976775828
Validation loss: 2.5536669015582625

Epoch: 77| Step: 0
Training loss: 2.7887878282718
Validation loss: 2.545921646517684

Epoch: 5| Step: 1
Training loss: 2.3791281310087786
Validation loss: 2.5540095955146422

Epoch: 5| Step: 2
Training loss: 2.5962884270327122
Validation loss: 2.5973319422455323

Epoch: 5| Step: 3
Training loss: 2.5879867132809813
Validation loss: 2.5610928393505406

Epoch: 5| Step: 4
Training loss: 2.257288466097598
Validation loss: 2.5496066993140993

Epoch: 5| Step: 5
Training loss: 2.181840605692795
Validation loss: 2.552864610365293

Epoch: 5| Step: 6
Training loss: 2.189126636074755
Validation loss: 2.5534047786296927

Epoch: 5| Step: 7
Training loss: 3.051377632569094
Validation loss: 2.5629339315938577

Epoch: 5| Step: 8
Training loss: 2.2543350420087114
Validation loss: 2.5444418512275155

Epoch: 5| Step: 9
Training loss: 2.4330460374445666
Validation loss: 2.547194423810428

Epoch: 5| Step: 10
Training loss: 1.9769404355320064
Validation loss: 2.5658860359176954

Epoch: 5| Step: 11
Training loss: 0.7141815203216642
Validation loss: 2.5290391945386723

Epoch: 78| Step: 0
Training loss: 2.492913406508508
Validation loss: 2.574017340769645

Epoch: 5| Step: 1
Training loss: 2.6174948440690438
Validation loss: 2.5972100049058464

Epoch: 5| Step: 2
Training loss: 2.121815820242303
Validation loss: 2.545536578895486

Epoch: 5| Step: 3
Training loss: 2.316284176470891
Validation loss: 2.5784455495056893

Epoch: 5| Step: 4
Training loss: 1.8353159400184125
Validation loss: 2.576176309569704

Epoch: 5| Step: 5
Training loss: 2.474499345484501
Validation loss: 2.596947376789619

Epoch: 5| Step: 6
Training loss: 2.488236215803718
Validation loss: 2.5473407132342927

Epoch: 5| Step: 7
Training loss: 2.595265325017612
Validation loss: 2.608898404848634

Epoch: 5| Step: 8
Training loss: 3.173659250314907
Validation loss: 2.5862613947650974

Epoch: 5| Step: 9
Training loss: 2.4254235635106833
Validation loss: 2.576617291332327

Epoch: 5| Step: 10
Training loss: 1.871086295795923
Validation loss: 2.5637743425135824

Epoch: 5| Step: 11
Training loss: 2.5198035750962555
Validation loss: 2.5441793518383244

Epoch: 79| Step: 0
Training loss: 2.339636893832654
Validation loss: 2.5795862353216195

Epoch: 5| Step: 1
Training loss: 2.5559741405319167
Validation loss: 2.536837595810891

Epoch: 5| Step: 2
Training loss: 2.491677163228494
Validation loss: 2.550062252512734

Epoch: 5| Step: 3
Training loss: 2.740969482485797
Validation loss: 2.5341283853050682

Epoch: 5| Step: 4
Training loss: 2.4751813147820387
Validation loss: 2.51101294568162

Epoch: 5| Step: 5
Training loss: 2.857266007902833
Validation loss: 2.5578018399534748

Epoch: 5| Step: 6
Training loss: 2.0111948460709383
Validation loss: 2.5437817697314116

Epoch: 5| Step: 7
Training loss: 2.6387217507777025
Validation loss: 2.5280801917633116

Epoch: 5| Step: 8
Training loss: 2.6993560976893303
Validation loss: 2.5451085453268747

Epoch: 5| Step: 9
Training loss: 1.2563681988124515
Validation loss: 2.5333523594827776

Epoch: 5| Step: 10
Training loss: 2.038135069184989
Validation loss: 2.55460798118405

Epoch: 5| Step: 11
Training loss: 2.3327665208193293
Validation loss: 2.559877076699561

Epoch: 80| Step: 0
Training loss: 2.7943210982429076
Validation loss: 2.551370736629024

Epoch: 5| Step: 1
Training loss: 1.9429109755739549
Validation loss: 2.548126030463955

Epoch: 5| Step: 2
Training loss: 2.315016125155288
Validation loss: 2.5504163020465627

Epoch: 5| Step: 3
Training loss: 1.9704537663953725
Validation loss: 2.5602307584007424

Epoch: 5| Step: 4
Training loss: 2.3328221192516114
Validation loss: 2.542449402013411

Epoch: 5| Step: 5
Training loss: 2.036574910787358
Validation loss: 2.5726052274644

Epoch: 5| Step: 6
Training loss: 2.415385849577174
Validation loss: 2.599034903907532

Epoch: 5| Step: 7
Training loss: 2.6080060097385274
Validation loss: 2.6308818835999763

Epoch: 5| Step: 8
Training loss: 2.3050536818469736
Validation loss: 2.601592494268556

Epoch: 5| Step: 9
Training loss: 2.7283299354931323
Validation loss: 2.5673877459188823

Epoch: 5| Step: 10
Training loss: 2.460334437517305
Validation loss: 2.572377906536552

Epoch: 5| Step: 11
Training loss: 4.399511500897935
Validation loss: 2.5520657493348837

Epoch: 81| Step: 0
Training loss: 1.9769685953797849
Validation loss: 2.580871271454641

Epoch: 5| Step: 1
Training loss: 2.6763842272249105
Validation loss: 2.5677384760997946

Epoch: 5| Step: 2
Training loss: 2.013836325767007
Validation loss: 2.5549562334267404

Epoch: 5| Step: 3
Training loss: 2.784987948817918
Validation loss: 2.515322941560037

Epoch: 5| Step: 4
Training loss: 2.59330377991744
Validation loss: 2.5506604931820296

Epoch: 5| Step: 5
Training loss: 2.511121996384305
Validation loss: 2.5686054687183173

Epoch: 5| Step: 6
Training loss: 2.500207224840528
Validation loss: 2.5668930625512223

Epoch: 5| Step: 7
Training loss: 2.5015435222260893
Validation loss: 2.540368406500482

Epoch: 5| Step: 8
Training loss: 2.5282276146885163
Validation loss: 2.5290403297351607

Epoch: 5| Step: 9
Training loss: 1.9694977808540588
Validation loss: 2.562839427425577

Epoch: 5| Step: 10
Training loss: 2.0682767251767737
Validation loss: 2.55517015943122

Epoch: 5| Step: 11
Training loss: 3.6531157794506446
Validation loss: 2.564124801780787

Epoch: 82| Step: 0
Training loss: 1.9463819145720211
Validation loss: 2.565116794509916

Epoch: 5| Step: 1
Training loss: 2.2957742349964927
Validation loss: 2.5519281664537323

Epoch: 5| Step: 2
Training loss: 2.2398901677452874
Validation loss: 2.565518872710256

Epoch: 5| Step: 3
Training loss: 2.3399749871897835
Validation loss: 2.555833782954301

Epoch: 5| Step: 4
Training loss: 2.1979737357253004
Validation loss: 2.5773457303116176

Epoch: 5| Step: 5
Training loss: 2.757768236188685
Validation loss: 2.5761874576586092

Epoch: 5| Step: 6
Training loss: 2.74734073722278
Validation loss: 2.6218787323989945

Epoch: 5| Step: 7
Training loss: 3.0162297566474034
Validation loss: 2.5820264292030903

Epoch: 5| Step: 8
Training loss: 2.2615588301285836
Validation loss: 2.5937973462421664

Epoch: 5| Step: 9
Training loss: 2.461024110269073
Validation loss: 2.580742988331284

Epoch: 5| Step: 10
Training loss: 2.0678688454643916
Validation loss: 2.582063516019897

Epoch: 5| Step: 11
Training loss: 1.8567807347558434
Validation loss: 2.5808057353455682

Epoch: 83| Step: 0
Training loss: 2.5156920998669547
Validation loss: 2.5391458155338538

Epoch: 5| Step: 1
Training loss: 2.801677821052248
Validation loss: 2.5438180297327584

Epoch: 5| Step: 2
Training loss: 2.4275629009107917
Validation loss: 2.6069563089264576

Epoch: 5| Step: 3
Training loss: 1.9434110855047044
Validation loss: 2.550320574456251

Epoch: 5| Step: 4
Training loss: 1.942264114059524
Validation loss: 2.5672508564717695

Epoch: 5| Step: 5
Training loss: 2.3561017908085216
Validation loss: 2.6008839528997085

Epoch: 5| Step: 6
Training loss: 2.107938941686562
Validation loss: 2.5786857688696627

Epoch: 5| Step: 7
Training loss: 2.9776561259888075
Validation loss: 2.537260047641873

Epoch: 5| Step: 8
Training loss: 2.3476199942278955
Validation loss: 2.5618118276979165

Epoch: 5| Step: 9
Training loss: 2.4788517043986116
Validation loss: 2.609507091018964

Epoch: 5| Step: 10
Training loss: 2.2684812234190166
Validation loss: 2.5851868983573465

Epoch: 5| Step: 11
Training loss: 2.232430952826305
Validation loss: 2.543776060247374

Epoch: 84| Step: 0
Training loss: 2.513876929585466
Validation loss: 2.5719411534777707

Epoch: 5| Step: 1
Training loss: 2.4699122916027707
Validation loss: 2.547903726866691

Epoch: 5| Step: 2
Training loss: 2.3615883052032385
Validation loss: 2.540814265903915

Epoch: 5| Step: 3
Training loss: 2.2625031107675655
Validation loss: 2.573797663283912

Epoch: 5| Step: 4
Training loss: 2.1025929246976283
Validation loss: 2.546770565645558

Epoch: 5| Step: 5
Training loss: 2.0882015442827058
Validation loss: 2.53544218138805

Epoch: 5| Step: 6
Training loss: 2.68446329346868
Validation loss: 2.5191223798483393

Epoch: 5| Step: 7
Training loss: 2.7829876732671464
Validation loss: 2.5377803519209556

Epoch: 5| Step: 8
Training loss: 2.0996711473471157
Validation loss: 2.549115905495335

Epoch: 5| Step: 9
Training loss: 2.346944132877453
Validation loss: 2.5603800859210044

Epoch: 5| Step: 10
Training loss: 2.641144018687264
Validation loss: 2.5459945966858526

Epoch: 5| Step: 11
Training loss: 2.828583906677378
Validation loss: 2.5485247006321035

Epoch: 85| Step: 0
Training loss: 2.5858418887807493
Validation loss: 2.491946867483794

Epoch: 5| Step: 1
Training loss: 2.3401278162551575
Validation loss: 2.5376355900735863

Epoch: 5| Step: 2
Training loss: 2.5088037926229205
Validation loss: 2.5526577841474754

Epoch: 5| Step: 3
Training loss: 1.9552111661386131
Validation loss: 2.563807281959007

Epoch: 5| Step: 4
Training loss: 2.919796127622592
Validation loss: 2.5976188484883793

Epoch: 5| Step: 5
Training loss: 2.249108985801041
Validation loss: 2.5622363924108136

Epoch: 5| Step: 6
Training loss: 2.1211364629389546
Validation loss: 2.5681750793476033

Epoch: 5| Step: 7
Training loss: 2.784694467492388
Validation loss: 2.587838333849157

Epoch: 5| Step: 8
Training loss: 1.8123499051790442
Validation loss: 2.576916713976824

Epoch: 5| Step: 9
Training loss: 2.536709584371434
Validation loss: 2.580241309565986

Epoch: 5| Step: 10
Training loss: 2.53786433192932
Validation loss: 2.620947305498679

Epoch: 5| Step: 11
Training loss: 1.471345110389948
Validation loss: 2.608031793283798

Epoch: 86| Step: 0
Training loss: 2.612886179439614
Validation loss: 2.594071854687589

Epoch: 5| Step: 1
Training loss: 2.027811867356257
Validation loss: 2.6308608627409527

Epoch: 5| Step: 2
Training loss: 1.8930878164494072
Validation loss: 2.580620956205238

Epoch: 5| Step: 3
Training loss: 1.8693382613112124
Validation loss: 2.562664096509291

Epoch: 5| Step: 4
Training loss: 3.1128857599527486
Validation loss: 2.5738493442553265

Epoch: 5| Step: 5
Training loss: 2.819302787625513
Validation loss: 2.5426866538001196

Epoch: 5| Step: 6
Training loss: 2.444277023111425
Validation loss: 2.5861166501102573

Epoch: 5| Step: 7
Training loss: 1.9625012974825902
Validation loss: 2.5541763610925527

Epoch: 5| Step: 8
Training loss: 2.0843173818331193
Validation loss: 2.531010157207182

Epoch: 5| Step: 9
Training loss: 2.6429717340996586
Validation loss: 2.5132325368201345

Epoch: 5| Step: 10
Training loss: 2.2962072530639386
Validation loss: 2.5277397714163374

Epoch: 5| Step: 11
Training loss: 3.6741031460640134
Validation loss: 2.55310965680882

Epoch: 87| Step: 0
Training loss: 2.337697364512373
Validation loss: 2.561136530399254

Epoch: 5| Step: 1
Training loss: 2.1048423387286137
Validation loss: 2.5421833987868228

Epoch: 5| Step: 2
Training loss: 2.6945059191408194
Validation loss: 2.528785777647361

Epoch: 5| Step: 3
Training loss: 2.0772193713646283
Validation loss: 2.568718204162285

Epoch: 5| Step: 4
Training loss: 2.39875289384072
Validation loss: 2.53691405341529

Epoch: 5| Step: 5
Training loss: 2.4122383608288684
Validation loss: 2.554243914466477

Epoch: 5| Step: 6
Training loss: 1.7283020922131183
Validation loss: 2.566579664807648

Epoch: 5| Step: 7
Training loss: 2.670763107860393
Validation loss: 2.5357070778994393

Epoch: 5| Step: 8
Training loss: 2.5662365164869403
Validation loss: 2.543421570697976

Epoch: 5| Step: 9
Training loss: 2.453521502092547
Validation loss: 2.538350346780201

Epoch: 5| Step: 10
Training loss: 2.64899944994047
Validation loss: 2.562211760925502

Epoch: 5| Step: 11
Training loss: 1.7565007041019773
Validation loss: 2.558459457484024

Epoch: 88| Step: 0
Training loss: 2.292300905257986
Validation loss: 2.5733887989567785

Epoch: 5| Step: 1
Training loss: 2.956471318354027
Validation loss: 2.5883701787030398

Epoch: 5| Step: 2
Training loss: 2.4357718185642545
Validation loss: 2.5658728995147406

Epoch: 5| Step: 3
Training loss: 2.779657572370203
Validation loss: 2.588377317332032

Epoch: 5| Step: 4
Training loss: 1.7156225708212964
Validation loss: 2.551937818595668

Epoch: 5| Step: 5
Training loss: 1.743576522456254
Validation loss: 2.576526338852885

Epoch: 5| Step: 6
Training loss: 3.015658679833378
Validation loss: 2.5540912196719163

Epoch: 5| Step: 7
Training loss: 2.4644782857899905
Validation loss: 2.5048513191132105

Epoch: 5| Step: 8
Training loss: 2.056292816922187
Validation loss: 2.5556471185993472

Epoch: 5| Step: 9
Training loss: 2.050459656704314
Validation loss: 2.5301353802665685

Epoch: 5| Step: 10
Training loss: 2.416851913543126
Validation loss: 2.565955607788184

Epoch: 5| Step: 11
Training loss: 2.054555678399719
Validation loss: 2.5306333136019603

Epoch: 89| Step: 0
Training loss: 2.2861241564939183
Validation loss: 2.5725817533168165

Epoch: 5| Step: 1
Training loss: 1.8399503316602557
Validation loss: 2.5671784097205252

Epoch: 5| Step: 2
Training loss: 2.91419127642529
Validation loss: 2.554465184080064

Epoch: 5| Step: 3
Training loss: 2.4993755514378475
Validation loss: 2.5511818980569765

Epoch: 5| Step: 4
Training loss: 2.4138901534794797
Validation loss: 2.551376674416126

Epoch: 5| Step: 5
Training loss: 2.1077536674416026
Validation loss: 2.5244034924952996

Epoch: 5| Step: 6
Training loss: 2.052434926645128
Validation loss: 2.5793831924383555

Epoch: 5| Step: 7
Training loss: 2.2978017585178567
Validation loss: 2.570096900655598

Epoch: 5| Step: 8
Training loss: 2.9611312279446325
Validation loss: 2.5807094258856718

Epoch: 5| Step: 9
Training loss: 2.467885312622887
Validation loss: 2.546545034615426

Epoch: 5| Step: 10
Training loss: 2.2156875321746914
Validation loss: 2.563047172309242

Epoch: 5| Step: 11
Training loss: 2.569772866598716
Validation loss: 2.5089821845721185

Epoch: 90| Step: 0
Training loss: 2.06425447690205
Validation loss: 2.545227465722508

Epoch: 5| Step: 1
Training loss: 2.0734890733757068
Validation loss: 2.5514866358420547

Epoch: 5| Step: 2
Training loss: 2.442110347688422
Validation loss: 2.552950191544361

Epoch: 5| Step: 3
Training loss: 2.5998536875711573
Validation loss: 2.52452548953691

Epoch: 5| Step: 4
Training loss: 2.8473610221298316
Validation loss: 2.564577090464683

Epoch: 5| Step: 5
Training loss: 2.14961526666465
Validation loss: 2.521862373021062

Epoch: 5| Step: 6
Training loss: 2.481040492209007
Validation loss: 2.531230910743349

Epoch: 5| Step: 7
Training loss: 2.029037091806845
Validation loss: 2.5634009824237665

Epoch: 5| Step: 8
Training loss: 1.8183486888993532
Validation loss: 2.5355451938919575

Epoch: 5| Step: 9
Training loss: 2.4579243939460342
Validation loss: 2.5437941454431745

Epoch: 5| Step: 10
Training loss: 2.8964020607403484
Validation loss: 2.568060741782661

Epoch: 5| Step: 11
Training loss: 2.740956087024397
Validation loss: 2.586220866924678

Epoch: 91| Step: 0
Training loss: 2.179360860872255
Validation loss: 2.5671999558966787

Epoch: 5| Step: 1
Training loss: 2.0473996720285723
Validation loss: 2.601654287863132

Epoch: 5| Step: 2
Training loss: 2.4775540746490394
Validation loss: 2.5539720740927434

Epoch: 5| Step: 3
Training loss: 2.6768559657419235
Validation loss: 2.5965046980879194

Epoch: 5| Step: 4
Training loss: 1.7981412986677008
Validation loss: 2.589210663022538

Epoch: 5| Step: 5
Training loss: 2.708870047183075
Validation loss: 2.5889117451597055

Epoch: 5| Step: 6
Training loss: 3.2756737693004934
Validation loss: 2.578937880167902

Epoch: 5| Step: 7
Training loss: 2.2903247256531087
Validation loss: 2.565010217537213

Epoch: 5| Step: 8
Training loss: 2.0375678770776524
Validation loss: 2.5863586075221368

Epoch: 5| Step: 9
Training loss: 2.4404283197650227
Validation loss: 2.562284656330728

Epoch: 5| Step: 10
Training loss: 2.266065883490123
Validation loss: 2.5436691632185036

Epoch: 5| Step: 11
Training loss: 2.4679701333858697
Validation loss: 2.540753252546761

Epoch: 92| Step: 0
Training loss: 2.5328068596072875
Validation loss: 2.5207320001165012

Epoch: 5| Step: 1
Training loss: 2.1917947299031004
Validation loss: 2.5352091732290734

Epoch: 5| Step: 2
Training loss: 2.541352445429813
Validation loss: 2.522706747785162

Epoch: 5| Step: 3
Training loss: 2.1141846254292957
Validation loss: 2.5413134334645022

Epoch: 5| Step: 4
Training loss: 2.8043653042759353
Validation loss: 2.54189084320346

Epoch: 5| Step: 5
Training loss: 2.7209270135973833
Validation loss: 2.535300095468772

Epoch: 5| Step: 6
Training loss: 2.6012983674919545
Validation loss: 2.56388165667051

Epoch: 5| Step: 7
Training loss: 2.7583729117820313
Validation loss: 2.527417802389081

Epoch: 5| Step: 8
Training loss: 2.3679639090674494
Validation loss: 2.502562568522598

Epoch: 5| Step: 9
Training loss: 1.8540780407016213
Validation loss: 2.5349082022128004

Epoch: 5| Step: 10
Training loss: 1.7437180437557516
Validation loss: 2.517253565774725

Epoch: 5| Step: 11
Training loss: 1.9494716808906782
Validation loss: 2.557855498601668

Epoch: 93| Step: 0
Training loss: 1.9105373384670177
Validation loss: 2.5300397569940216

Epoch: 5| Step: 1
Training loss: 2.770734818698259
Validation loss: 2.5698384212038863

Epoch: 5| Step: 2
Training loss: 1.531745908193476
Validation loss: 2.566351484994661

Epoch: 5| Step: 3
Training loss: 2.6975698555005345
Validation loss: 2.561109524190466

Epoch: 5| Step: 4
Training loss: 2.282752600372909
Validation loss: 2.59989435824939

Epoch: 5| Step: 5
Training loss: 2.902494896383998
Validation loss: 2.617664631484971

Epoch: 5| Step: 6
Training loss: 2.1271432278451723
Validation loss: 2.636223493617341

Epoch: 5| Step: 7
Training loss: 2.784098934098322
Validation loss: 2.656451363504408

Epoch: 5| Step: 8
Training loss: 2.2555227317467925
Validation loss: 2.5926266079675684

Epoch: 5| Step: 9
Training loss: 2.0896168237996164
Validation loss: 2.611086799771059

Epoch: 5| Step: 10
Training loss: 2.7474267364258482
Validation loss: 2.5831679969351566

Epoch: 5| Step: 11
Training loss: 1.652185743636541
Validation loss: 2.5827290875550095

Epoch: 94| Step: 0
Training loss: 2.3925773278059896
Validation loss: 2.5282626439532825

Epoch: 5| Step: 1
Training loss: 2.7469516678353814
Validation loss: 2.5345327416815717

Epoch: 5| Step: 2
Training loss: 1.9755327761592734
Validation loss: 2.5476430815202655

Epoch: 5| Step: 3
Training loss: 2.536663248190997
Validation loss: 2.5525839697326735

Epoch: 5| Step: 4
Training loss: 2.587301119472704
Validation loss: 2.511641952582486

Epoch: 5| Step: 5
Training loss: 2.294837307284928
Validation loss: 2.5223868892452557

Epoch: 5| Step: 6
Training loss: 2.3754250999273774
Validation loss: 2.5543935258587283

Epoch: 5| Step: 7
Training loss: 2.5614474856496128
Validation loss: 2.514123073375278

Epoch: 5| Step: 8
Training loss: 2.3879594091227596
Validation loss: 2.516137250631502

Epoch: 5| Step: 9
Training loss: 1.784168596238446
Validation loss: 2.5311186642581074

Epoch: 5| Step: 10
Training loss: 2.3729118402938276
Validation loss: 2.5214695495437534

Epoch: 5| Step: 11
Training loss: 1.66581848337648
Validation loss: 2.5011181516337353

Epoch: 95| Step: 0
Training loss: 2.5332517832462997
Validation loss: 2.5286947036771674

Epoch: 5| Step: 1
Training loss: 2.5671105195087645
Validation loss: 2.529420874660123

Epoch: 5| Step: 2
Training loss: 2.157493564423724
Validation loss: 2.5523408111128765

Epoch: 5| Step: 3
Training loss: 2.227958375497446
Validation loss: 2.5297986371181156

Epoch: 5| Step: 4
Training loss: 2.715029220283308
Validation loss: 2.5511957428648557

Epoch: 5| Step: 5
Training loss: 2.044120857584947
Validation loss: 2.5585497864496336

Epoch: 5| Step: 6
Training loss: 1.9762771460775739
Validation loss: 2.5790875997939344

Epoch: 5| Step: 7
Training loss: 2.5371990232068544
Validation loss: 2.562856424556301

Epoch: 5| Step: 8
Training loss: 2.7360944300969794
Validation loss: 2.558821932491737

Epoch: 5| Step: 9
Training loss: 2.416472679332613
Validation loss: 2.550148983417912

Epoch: 5| Step: 10
Training loss: 2.2088188021640565
Validation loss: 2.535618364235941

Epoch: 5| Step: 11
Training loss: 2.3919785600804966
Validation loss: 2.572316452369978

Epoch: 96| Step: 0
Training loss: 2.032363586352439
Validation loss: 2.5624069103917155

Epoch: 5| Step: 1
Training loss: 2.9830055490071947
Validation loss: 2.536722693613032

Epoch: 5| Step: 2
Training loss: 2.62589239664417
Validation loss: 2.5370046326255777

Epoch: 5| Step: 3
Training loss: 2.2285214022027438
Validation loss: 2.5148420043319866

Epoch: 5| Step: 4
Training loss: 2.1254163222046856
Validation loss: 2.514942293743786

Epoch: 5| Step: 5
Training loss: 1.944962129101625
Validation loss: 2.543808411217341

Epoch: 5| Step: 6
Training loss: 2.1054909444852927
Validation loss: 2.5243808864673785

Epoch: 5| Step: 7
Training loss: 2.6152513316874666
Validation loss: 2.5359980787687113

Epoch: 5| Step: 8
Training loss: 2.391774418582314
Validation loss: 2.5344711733882197

Epoch: 5| Step: 9
Training loss: 2.026443899150383
Validation loss: 2.5390759863862082

Epoch: 5| Step: 10
Training loss: 2.576305880470348
Validation loss: 2.512380913146941

Epoch: 5| Step: 11
Training loss: 3.356944921855886
Validation loss: 2.52524407500722

Epoch: 97| Step: 0
Training loss: 2.722747757412424
Validation loss: 2.540221400733495

Epoch: 5| Step: 1
Training loss: 2.003687082541496
Validation loss: 2.5233755822552273

Epoch: 5| Step: 2
Training loss: 2.0482095342750375
Validation loss: 2.5534318293675526

Epoch: 5| Step: 3
Training loss: 2.036621620545814
Validation loss: 2.5577233928367478

Epoch: 5| Step: 4
Training loss: 2.225167998925835
Validation loss: 2.60638296548943

Epoch: 5| Step: 5
Training loss: 1.9325042429454262
Validation loss: 2.630412108330111

Epoch: 5| Step: 6
Training loss: 3.1586216240576905
Validation loss: 2.6468920967243474

Epoch: 5| Step: 7
Training loss: 2.288227124158487
Validation loss: 2.6241698882587032

Epoch: 5| Step: 8
Training loss: 2.7382696698388784
Validation loss: 2.6326980641414237

Epoch: 5| Step: 9
Training loss: 2.2349553988314006
Validation loss: 2.5825167577974706

Epoch: 5| Step: 10
Training loss: 1.9799553621443047
Validation loss: 2.5655437628538014

Epoch: 5| Step: 11
Training loss: 4.0549128181314185
Validation loss: 2.5556688669441607

Epoch: 98| Step: 0
Training loss: 2.5249618791780777
Validation loss: 2.535767738644297

Epoch: 5| Step: 1
Training loss: 2.38755112039052
Validation loss: 2.5390702271955234

Epoch: 5| Step: 2
Training loss: 2.5666892071349325
Validation loss: 2.524995891485869

Epoch: 5| Step: 3
Training loss: 2.0265104900383197
Validation loss: 2.535690509945643

Epoch: 5| Step: 4
Training loss: 2.2942581320738333
Validation loss: 2.523880113692953

Epoch: 5| Step: 5
Training loss: 2.258478614197476
Validation loss: 2.498452983471843

Epoch: 5| Step: 6
Training loss: 3.3689695099209276
Validation loss: 2.557496201881231

Epoch: 5| Step: 7
Training loss: 1.916668546371644
Validation loss: 2.5425554673125044

Epoch: 5| Step: 8
Training loss: 2.0295916316625613
Validation loss: 2.5223223620709194

Epoch: 5| Step: 9
Training loss: 1.8930732701344162
Validation loss: 2.5187782424056455

Epoch: 5| Step: 10
Training loss: 2.460844686059787
Validation loss: 2.5531205982308824

Epoch: 5| Step: 11
Training loss: 1.409044117793899
Validation loss: 2.519716631552867

Epoch: 99| Step: 0
Training loss: 1.8506777295218024
Validation loss: 2.529753607674891

Epoch: 5| Step: 1
Training loss: 2.8581019835272126
Validation loss: 2.5688934235084098

Epoch: 5| Step: 2
Training loss: 1.94280734248809
Validation loss: 2.5442857979393283

Epoch: 5| Step: 3
Training loss: 1.9947252453402156
Validation loss: 2.5437197028128056

Epoch: 5| Step: 4
Training loss: 2.198953995428561
Validation loss: 2.562617167453597

Epoch: 5| Step: 5
Training loss: 2.8191346644036854
Validation loss: 2.543110534418702

Epoch: 5| Step: 6
Training loss: 2.114916269435079
Validation loss: 2.5553785005915666

Epoch: 5| Step: 7
Training loss: 2.9142204016892035
Validation loss: 2.52159122365742

Epoch: 5| Step: 8
Training loss: 2.420280374568661
Validation loss: 2.543734953146131

Epoch: 5| Step: 9
Training loss: 2.217172195994685
Validation loss: 2.543669874005634

Epoch: 5| Step: 10
Training loss: 1.9094055822642257
Validation loss: 2.542205711694973

Epoch: 5| Step: 11
Training loss: 1.89851674357986
Validation loss: 2.5252817105367193

Epoch: 100| Step: 0
Training loss: 2.0088164791745347
Validation loss: 2.5773791958754564

Epoch: 5| Step: 1
Training loss: 1.9542066096905297
Validation loss: 2.59609862549154

Epoch: 5| Step: 2
Training loss: 2.7342456896042435
Validation loss: 2.6041685612989527

Epoch: 5| Step: 3
Training loss: 2.2920970397032723
Validation loss: 2.6225447336229686

Epoch: 5| Step: 4
Training loss: 2.5248927594063644
Validation loss: 2.626183844599639

Epoch: 5| Step: 5
Training loss: 2.2123587525534822
Validation loss: 2.5936867771333207

Epoch: 5| Step: 6
Training loss: 2.000576651411134
Validation loss: 2.604253238510565

Epoch: 5| Step: 7
Training loss: 2.580309687813068
Validation loss: 2.6140500217526785

Epoch: 5| Step: 8
Training loss: 2.540947598742336
Validation loss: 2.600368962945727

Epoch: 5| Step: 9
Training loss: 1.7981964559614108
Validation loss: 2.57914778718422

Epoch: 5| Step: 10
Training loss: 2.5876699677449198
Validation loss: 2.5523432320324826

Epoch: 5| Step: 11
Training loss: 3.5508209998462634
Validation loss: 2.574371190591161

Epoch: 101| Step: 0
Training loss: 2.3540132748303253
Validation loss: 2.536260449616859

Epoch: 5| Step: 1
Training loss: 1.7975900968592071
Validation loss: 2.5431175325136697

Epoch: 5| Step: 2
Training loss: 2.3673141999534555
Validation loss: 2.5274791140814337

Epoch: 5| Step: 3
Training loss: 3.075055911168368
Validation loss: 2.534343606869661

Epoch: 5| Step: 4
Training loss: 2.4284100378729776
Validation loss: 2.5577391422652633

Epoch: 5| Step: 5
Training loss: 1.6702519319292168
Validation loss: 2.5717080298076587

Epoch: 5| Step: 6
Training loss: 2.709695581039822
Validation loss: 2.5834127165277496

Epoch: 5| Step: 7
Training loss: 1.8713752041136842
Validation loss: 2.5788906020281335

Epoch: 5| Step: 8
Training loss: 2.250232578548772
Validation loss: 2.5626625808064833

Epoch: 5| Step: 9
Training loss: 2.5836254282884603
Validation loss: 2.520368577869731

Epoch: 5| Step: 10
Training loss: 2.480277274843968
Validation loss: 2.5301840307629386

Epoch: 5| Step: 11
Training loss: 1.8529668061792812
Validation loss: 2.523625814617457

Epoch: 102| Step: 0
Training loss: 1.6144455225387326
Validation loss: 2.5210860371360857

Epoch: 5| Step: 1
Training loss: 2.821138382555711
Validation loss: 2.5172285809470853

Epoch: 5| Step: 2
Training loss: 2.716330668572107
Validation loss: 2.5383386137571993

Epoch: 5| Step: 3
Training loss: 1.8146483087421585
Validation loss: 2.5412758359957675

Epoch: 5| Step: 4
Training loss: 2.2073193387404304
Validation loss: 2.5182673278147303

Epoch: 5| Step: 5
Training loss: 2.1352004771392505
Validation loss: 2.5792560215777085

Epoch: 5| Step: 6
Training loss: 1.5970354809530989
Validation loss: 2.5428664796795837

Epoch: 5| Step: 7
Training loss: 2.5433072803841132
Validation loss: 2.553347886720903

Epoch: 5| Step: 8
Training loss: 3.0251248798918087
Validation loss: 2.5635844858854333

Epoch: 5| Step: 9
Training loss: 2.0535113663508606
Validation loss: 2.590037550083274

Epoch: 5| Step: 10
Training loss: 2.5388966667599653
Validation loss: 2.6054120493700053

Epoch: 5| Step: 11
Training loss: 2.5620922601601905
Validation loss: 2.5809495326913816

Epoch: 103| Step: 0
Training loss: 2.489521669611079
Validation loss: 2.5631525984218304

Epoch: 5| Step: 1
Training loss: 2.100619420024585
Validation loss: 2.531854474924513

Epoch: 5| Step: 2
Training loss: 2.5662097594408495
Validation loss: 2.5521431208763135

Epoch: 5| Step: 3
Training loss: 2.2758811585653143
Validation loss: 2.5511186969467445

Epoch: 5| Step: 4
Training loss: 3.023848315970973
Validation loss: 2.5073723768285223

Epoch: 5| Step: 5
Training loss: 2.122358363158183
Validation loss: 2.5533276865397063

Epoch: 5| Step: 6
Training loss: 1.4309502533450342
Validation loss: 2.5307333344365484

Epoch: 5| Step: 7
Training loss: 2.689117388522515
Validation loss: 2.537226418998046

Epoch: 5| Step: 8
Training loss: 2.6081819833673063
Validation loss: 2.5532046767478587

Epoch: 5| Step: 9
Training loss: 1.7678842184682395
Validation loss: 2.5317805993894242

Epoch: 5| Step: 10
Training loss: 2.040900677086092
Validation loss: 2.5364617159048684

Epoch: 5| Step: 11
Training loss: 1.7872335088590408
Validation loss: 2.520715030279676

Epoch: 104| Step: 0
Training loss: 1.7595902333300064
Validation loss: 2.5407865999198047

Epoch: 5| Step: 1
Training loss: 2.489365178423333
Validation loss: 2.496935917760098

Epoch: 5| Step: 2
Training loss: 2.2973254534113363
Validation loss: 2.545507567104286

Epoch: 5| Step: 3
Training loss: 2.624877381866899
Validation loss: 2.5086440810060275

Epoch: 5| Step: 4
Training loss: 2.432349117888451
Validation loss: 2.512701598662524

Epoch: 5| Step: 5
Training loss: 2.6097344248036753
Validation loss: 2.523707403938574

Epoch: 5| Step: 6
Training loss: 2.446389640522211
Validation loss: 2.5311967349629376

Epoch: 5| Step: 7
Training loss: 2.270895149252855
Validation loss: 2.524699793963257

Epoch: 5| Step: 8
Training loss: 2.2829241945277565
Validation loss: 2.535950099986629

Epoch: 5| Step: 9
Training loss: 2.2215062604013616
Validation loss: 2.544516300059505

Epoch: 5| Step: 10
Training loss: 2.153841968417031
Validation loss: 2.558614067792907

Epoch: 5| Step: 11
Training loss: 2.010140935407315
Validation loss: 2.6109581140465004

Epoch: 105| Step: 0
Training loss: 2.545906491224795
Validation loss: 2.5387922446378233

Epoch: 5| Step: 1
Training loss: 2.8201558500200123
Validation loss: 2.5514906227404968

Epoch: 5| Step: 2
Training loss: 2.357213931642873
Validation loss: 2.5738848912068764

Epoch: 5| Step: 3
Training loss: 1.8024584061986146
Validation loss: 2.546329233088186

Epoch: 5| Step: 4
Training loss: 1.8638517198237605
Validation loss: 2.559673436782537

Epoch: 5| Step: 5
Training loss: 2.829228812777225
Validation loss: 2.5282890599807972

Epoch: 5| Step: 6
Training loss: 2.1413736635252616
Validation loss: 2.562667465165262

Epoch: 5| Step: 7
Training loss: 1.7889390261490676
Validation loss: 2.577643000696294

Epoch: 5| Step: 8
Training loss: 2.4791075328110965
Validation loss: 2.520656805451818

Epoch: 5| Step: 9
Training loss: 1.9937688198815724
Validation loss: 2.530023864585166

Epoch: 5| Step: 10
Training loss: 2.600919260228964
Validation loss: 2.544812640961072

Epoch: 5| Step: 11
Training loss: 2.380718774688702
Validation loss: 2.5563155536593736

Epoch: 106| Step: 0
Training loss: 2.383813666467148
Validation loss: 2.5525860751873752

Epoch: 5| Step: 1
Training loss: 1.7935976741324802
Validation loss: 2.5706385567039667

Epoch: 5| Step: 2
Training loss: 2.274553582124484
Validation loss: 2.579959490289229

Epoch: 5| Step: 3
Training loss: 2.6136945959245854
Validation loss: 2.553840967469868

Epoch: 5| Step: 4
Training loss: 2.151293932983145
Validation loss: 2.5679179306580107

Epoch: 5| Step: 5
Training loss: 2.5635653816458244
Validation loss: 2.5986680739594523

Epoch: 5| Step: 6
Training loss: 2.0735819785656595
Validation loss: 2.5939867168245483

Epoch: 5| Step: 7
Training loss: 2.7290223838192897
Validation loss: 2.5712134686639505

Epoch: 5| Step: 8
Training loss: 2.603393002346036
Validation loss: 2.589585703273025

Epoch: 5| Step: 9
Training loss: 2.588794984965424
Validation loss: 2.5760143541327083

Epoch: 5| Step: 10
Training loss: 1.3711446551575535
Validation loss: 2.5686235318604895

Epoch: 5| Step: 11
Training loss: 2.6115182994221104
Validation loss: 2.5443535006839295

Epoch: 107| Step: 0
Training loss: 1.923154823486049
Validation loss: 2.5490350787840788

Epoch: 5| Step: 1
Training loss: 1.7536465934779717
Validation loss: 2.520631543009191

Epoch: 5| Step: 2
Training loss: 2.326517663937412
Validation loss: 2.5190966071062295

Epoch: 5| Step: 3
Training loss: 2.0613797931510165
Validation loss: 2.527348470708024

Epoch: 5| Step: 4
Training loss: 2.1466483139454047
Validation loss: 2.5119801351181676

Epoch: 5| Step: 5
Training loss: 2.4702756006716995
Validation loss: 2.520521898709408

Epoch: 5| Step: 6
Training loss: 2.1992796759017423
Validation loss: 2.526882072468397

Epoch: 5| Step: 7
Training loss: 2.2365009357698606
Validation loss: 2.5356531072645767

Epoch: 5| Step: 8
Training loss: 2.6271070470705182
Validation loss: 2.531630679731352

Epoch: 5| Step: 9
Training loss: 2.8230731165325955
Validation loss: 2.518826857877958

Epoch: 5| Step: 10
Training loss: 2.485804596326788
Validation loss: 2.5213457734781817

Epoch: 5| Step: 11
Training loss: 2.8297942067189923
Validation loss: 2.5245658941989264

Epoch: 108| Step: 0
Training loss: 2.229970365250404
Validation loss: 2.5308959108888893

Epoch: 5| Step: 1
Training loss: 1.9274657273863582
Validation loss: 2.5189945763227573

Epoch: 5| Step: 2
Training loss: 2.1277064871181617
Validation loss: 2.509817753706871

Epoch: 5| Step: 3
Training loss: 2.4783600742596557
Validation loss: 2.526088601426819

Epoch: 5| Step: 4
Training loss: 2.421591366802462
Validation loss: 2.539717929069969

Epoch: 5| Step: 5
Training loss: 1.9304146574215635
Validation loss: 2.505808468244837

Epoch: 5| Step: 6
Training loss: 1.9280986345117637
Validation loss: 2.548005923664777

Epoch: 5| Step: 7
Training loss: 2.2510772881137973
Validation loss: 2.5163149785841075

Epoch: 5| Step: 8
Training loss: 2.391583518555605
Validation loss: 2.5343124599869933

Epoch: 5| Step: 9
Training loss: 2.4451562996112965
Validation loss: 2.545066667381809

Epoch: 5| Step: 10
Training loss: 2.7371067896934593
Validation loss: 2.553895215010353

Epoch: 5| Step: 11
Training loss: 2.912078754921598
Validation loss: 2.572547926071715

Epoch: 109| Step: 0
Training loss: 2.7690179561695434
Validation loss: 2.5238736251132803

Epoch: 5| Step: 1
Training loss: 3.0594549805704294
Validation loss: 2.5565925207000855

Epoch: 5| Step: 2
Training loss: 1.7808091136670032
Validation loss: 2.5972488275027708

Epoch: 5| Step: 3
Training loss: 2.033397302507247
Validation loss: 2.5899258155152602

Epoch: 5| Step: 4
Training loss: 2.22674431309499
Validation loss: 2.5566069054571665

Epoch: 5| Step: 5
Training loss: 2.497914970679472
Validation loss: 2.5744183530010356

Epoch: 5| Step: 6
Training loss: 2.29123914950185
Validation loss: 2.616552968703579

Epoch: 5| Step: 7
Training loss: 2.155708908522881
Validation loss: 2.579365110286717

Epoch: 5| Step: 8
Training loss: 2.160271253507973
Validation loss: 2.5780593979320763

Epoch: 5| Step: 9
Training loss: 1.9172917742613267
Validation loss: 2.5695371762860053

Epoch: 5| Step: 10
Training loss: 2.186423554552023
Validation loss: 2.5660995694983924

Epoch: 5| Step: 11
Training loss: 1.5594668130086142
Validation loss: 2.571360033530953

Epoch: 110| Step: 0
Training loss: 2.1859840589886157
Validation loss: 2.539336141854988

Epoch: 5| Step: 1
Training loss: 2.02651131358684
Validation loss: 2.554215647200321

Epoch: 5| Step: 2
Training loss: 2.2367456837590405
Validation loss: 2.5486001177027213

Epoch: 5| Step: 3
Training loss: 2.706314762741344
Validation loss: 2.531008500874548

Epoch: 5| Step: 4
Training loss: 2.349668938063351
Validation loss: 2.5374314219035243

Epoch: 5| Step: 5
Training loss: 1.8342513112571328
Validation loss: 2.517077518288658

Epoch: 5| Step: 6
Training loss: 2.947343930164205
Validation loss: 2.47620200292141

Epoch: 5| Step: 7
Training loss: 1.916499241136838
Validation loss: 2.5338835066024226

Epoch: 5| Step: 8
Training loss: 2.5138373805811467
Validation loss: 2.5163945942036063

Epoch: 5| Step: 9
Training loss: 2.082354837146072
Validation loss: 2.545603167393968

Epoch: 5| Step: 10
Training loss: 2.4389310695077677
Validation loss: 2.535788693765876

Epoch: 5| Step: 11
Training loss: 1.1731521767510273
Validation loss: 2.513239797958441

Epoch: 111| Step: 0
Training loss: 2.2815775178927864
Validation loss: 2.546951078281072

Epoch: 5| Step: 1
Training loss: 2.4090346040247477
Validation loss: 2.544383201083025

Epoch: 5| Step: 2
Training loss: 2.186489852913132
Validation loss: 2.536622131562839

Epoch: 5| Step: 3
Training loss: 2.216876891452358
Validation loss: 2.510104129589314

Epoch: 5| Step: 4
Training loss: 1.736337187564229
Validation loss: 2.562561643060616

Epoch: 5| Step: 5
Training loss: 2.494004977009449
Validation loss: 2.54493989545288

Epoch: 5| Step: 6
Training loss: 2.557235893268034
Validation loss: 2.5443184196423734

Epoch: 5| Step: 7
Training loss: 1.9769401340325365
Validation loss: 2.5669113544669666

Epoch: 5| Step: 8
Training loss: 2.579846726233823
Validation loss: 2.541332615073787

Epoch: 5| Step: 9
Training loss: 1.9852088317753038
Validation loss: 2.5215280786612917

Epoch: 5| Step: 10
Training loss: 2.5187594392282513
Validation loss: 2.522359708398279

Epoch: 5| Step: 11
Training loss: 1.469733213492011
Validation loss: 2.5035852790896658

Epoch: 112| Step: 0
Training loss: 1.9733965702599652
Validation loss: 2.5568924234188715

Epoch: 5| Step: 1
Training loss: 2.3499014935240066
Validation loss: 2.53403741318342

Epoch: 5| Step: 2
Training loss: 1.9042280761810895
Validation loss: 2.5576566732203014

Epoch: 5| Step: 3
Training loss: 2.2378386214625103
Validation loss: 2.5270749459647686

Epoch: 5| Step: 4
Training loss: 1.971713908003864
Validation loss: 2.518527455433508

Epoch: 5| Step: 5
Training loss: 2.6154648306787798
Validation loss: 2.53123504532215

Epoch: 5| Step: 6
Training loss: 1.765126250725357
Validation loss: 2.543489401900539

Epoch: 5| Step: 7
Training loss: 1.735589229557179
Validation loss: 2.530133691950731

Epoch: 5| Step: 8
Training loss: 2.762733974300882
Validation loss: 2.5239142744023795

Epoch: 5| Step: 9
Training loss: 3.105014523089809
Validation loss: 2.5611181157836462

Epoch: 5| Step: 10
Training loss: 2.0846746958443894
Validation loss: 2.5340999171761336

Epoch: 5| Step: 11
Training loss: 1.441476546230045
Validation loss: 2.5585760217882356

Epoch: 113| Step: 0
Training loss: 1.7923412014305706
Validation loss: 2.542682684352667

Epoch: 5| Step: 1
Training loss: 2.1552385915921772
Validation loss: 2.55429518211936

Epoch: 5| Step: 2
Training loss: 2.490284830218024
Validation loss: 2.5609725765101574

Epoch: 5| Step: 3
Training loss: 2.0427618268400916
Validation loss: 2.5271107263068404

Epoch: 5| Step: 4
Training loss: 2.4239812736480326
Validation loss: 2.5308355180452287

Epoch: 5| Step: 5
Training loss: 3.1241667590307056
Validation loss: 2.527452913626123

Epoch: 5| Step: 6
Training loss: 2.3736070262243087
Validation loss: 2.4868080453103585

Epoch: 5| Step: 7
Training loss: 2.3769205258844583
Validation loss: 2.5259830835110217

Epoch: 5| Step: 8
Training loss: 2.1147815504957337
Validation loss: 2.5127085371444093

Epoch: 5| Step: 9
Training loss: 1.6024599863612177
Validation loss: 2.4996247526517386

Epoch: 5| Step: 10
Training loss: 2.2031558420173294
Validation loss: 2.5468600493072233

Epoch: 5| Step: 11
Training loss: 1.3730332440368467
Validation loss: 2.554872548889754

Epoch: 114| Step: 0
Training loss: 1.9951655250851754
Validation loss: 2.5429705508958698

Epoch: 5| Step: 1
Training loss: 2.872403174512283
Validation loss: 2.55651413750602

Epoch: 5| Step: 2
Training loss: 2.6222364319759355
Validation loss: 2.542193691665809

Epoch: 5| Step: 3
Training loss: 1.897943817123134
Validation loss: 2.611949480572024

Epoch: 5| Step: 4
Training loss: 2.4121629469632926
Validation loss: 2.591674157854479

Epoch: 5| Step: 5
Training loss: 1.9015431687587843
Validation loss: 2.558074774293724

Epoch: 5| Step: 6
Training loss: 2.2817116884183553
Validation loss: 2.5960657245854035

Epoch: 5| Step: 7
Training loss: 1.99208678944659
Validation loss: 2.532725049595163

Epoch: 5| Step: 8
Training loss: 1.6481617339824801
Validation loss: 2.581672470397369

Epoch: 5| Step: 9
Training loss: 2.7669121284828697
Validation loss: 2.542725664231058

Epoch: 5| Step: 10
Training loss: 2.3226636284057567
Validation loss: 2.5783658233063536

Epoch: 5| Step: 11
Training loss: 1.7988085088167671
Validation loss: 2.529669821797004

Epoch: 115| Step: 0
Training loss: 2.2253429620000036
Validation loss: 2.5430507656452543

Epoch: 5| Step: 1
Training loss: 2.457484362718382
Validation loss: 2.551158458476042

Epoch: 5| Step: 2
Training loss: 2.514428938387393
Validation loss: 2.506612888900253

Epoch: 5| Step: 3
Training loss: 2.3447463905802084
Validation loss: 2.4883210973977476

Epoch: 5| Step: 4
Training loss: 2.118096413418054
Validation loss: 2.4937834059438493

Epoch: 5| Step: 5
Training loss: 1.739239580678937
Validation loss: 2.524345187459539

Epoch: 5| Step: 6
Training loss: 1.8344915011841483
Validation loss: 2.5100174041603123

Epoch: 5| Step: 7
Training loss: 2.6257913395768107
Validation loss: 2.5241068020326467

Epoch: 5| Step: 8
Training loss: 2.077579397986451
Validation loss: 2.520677968956906

Epoch: 5| Step: 9
Training loss: 2.0896892740074673
Validation loss: 2.508799270642772

Epoch: 5| Step: 10
Training loss: 2.7494740416665766
Validation loss: 2.5114161149385414

Epoch: 5| Step: 11
Training loss: 1.9979756362162724
Validation loss: 2.5146850543766575

Epoch: 116| Step: 0
Training loss: 2.43114209560817
Validation loss: 2.549574032279393

Epoch: 5| Step: 1
Training loss: 2.5969608150400565
Validation loss: 2.503970795512136

Epoch: 5| Step: 2
Training loss: 2.629327930113455
Validation loss: 2.5230233292485735

Epoch: 5| Step: 3
Training loss: 1.790094003286877
Validation loss: 2.514744513691655

Epoch: 5| Step: 4
Training loss: 2.351594335397567
Validation loss: 2.533135594840662

Epoch: 5| Step: 5
Training loss: 1.8362749804101834
Validation loss: 2.520473901224196

Epoch: 5| Step: 6
Training loss: 2.0338490217846323
Validation loss: 2.5426828093747287

Epoch: 5| Step: 7
Training loss: 2.3652088721465203
Validation loss: 2.5150666693375783

Epoch: 5| Step: 8
Training loss: 2.502474990247204
Validation loss: 2.526953736389341

Epoch: 5| Step: 9
Training loss: 1.9139422943361128
Validation loss: 2.5428231896434426

Epoch: 5| Step: 10
Training loss: 1.975337738421435
Validation loss: 2.5603792400951066

Epoch: 5| Step: 11
Training loss: 3.223682069214336
Validation loss: 2.50750905673926

Epoch: 117| Step: 0
Training loss: 2.0408542989098124
Validation loss: 2.5345771237797456

Epoch: 5| Step: 1
Training loss: 2.084246803928234
Validation loss: 2.522430596961113

Epoch: 5| Step: 2
Training loss: 2.2239574518730567
Validation loss: 2.523919562402661

Epoch: 5| Step: 3
Training loss: 2.733350638203
Validation loss: 2.556338668099985

Epoch: 5| Step: 4
Training loss: 1.7254042386741482
Validation loss: 2.5038120293706196

Epoch: 5| Step: 5
Training loss: 2.1148816604513887
Validation loss: 2.5135428378980755

Epoch: 5| Step: 6
Training loss: 2.007444830453493
Validation loss: 2.5330703022100405

Epoch: 5| Step: 7
Training loss: 2.1878648726111183
Validation loss: 2.5013747011942935

Epoch: 5| Step: 8
Training loss: 2.9917039605014852
Validation loss: 2.5529848893753515

Epoch: 5| Step: 9
Training loss: 2.5663545043002034
Validation loss: 2.5203527545493056

Epoch: 5| Step: 10
Training loss: 1.9154816018428085
Validation loss: 2.508980971010423

Epoch: 5| Step: 11
Training loss: 1.361530874470324
Validation loss: 2.501995240173925

Epoch: 118| Step: 0
Training loss: 1.9553651094118834
Validation loss: 2.523230415248075

Epoch: 5| Step: 1
Training loss: 2.0456186180586293
Validation loss: 2.5448669560387107

Epoch: 5| Step: 2
Training loss: 2.3657484055132483
Validation loss: 2.5574778756421153

Epoch: 5| Step: 3
Training loss: 1.9250888159934052
Validation loss: 2.5908366160976763

Epoch: 5| Step: 4
Training loss: 2.3398631099861635
Validation loss: 2.5888339759656245

Epoch: 5| Step: 5
Training loss: 1.8753598821496353
Validation loss: 2.568439493029639

Epoch: 5| Step: 6
Training loss: 2.589211963674367
Validation loss: 2.583907018816976

Epoch: 5| Step: 7
Training loss: 2.170929847177745
Validation loss: 2.5945811874023827

Epoch: 5| Step: 8
Training loss: 2.1611204564999245
Validation loss: 2.573202821260344

Epoch: 5| Step: 9
Training loss: 2.8727054561646965
Validation loss: 2.5526658710296015

Epoch: 5| Step: 10
Training loss: 2.445303334959362
Validation loss: 2.5578854441897834

Epoch: 5| Step: 11
Training loss: 1.2595415256101437
Validation loss: 2.501756980527164

Epoch: 119| Step: 0
Training loss: 2.0471459129370775
Validation loss: 2.5517408699128192

Epoch: 5| Step: 1
Training loss: 2.532263752950718
Validation loss: 2.525043444999376

Epoch: 5| Step: 2
Training loss: 2.230484783696202
Validation loss: 2.5052929220901357

Epoch: 5| Step: 3
Training loss: 2.725477817185496
Validation loss: 2.4968328401573427

Epoch: 5| Step: 4
Training loss: 1.7680869703089879
Validation loss: 2.4924104804055833

Epoch: 5| Step: 5
Training loss: 2.218900648563563
Validation loss: 2.499472417396378

Epoch: 5| Step: 6
Training loss: 2.102606645163253
Validation loss: 2.5150899100806394

Epoch: 5| Step: 7
Training loss: 1.9309249184589514
Validation loss: 2.526174621753567

Epoch: 5| Step: 8
Training loss: 2.3293568469241674
Validation loss: 2.5531512394104965

Epoch: 5| Step: 9
Training loss: 2.0527046411975935
Validation loss: 2.546574007280513

Epoch: 5| Step: 10
Training loss: 2.2699195936641545
Validation loss: 2.537561092048444

Epoch: 5| Step: 11
Training loss: 2.669872671370181
Validation loss: 2.529073381798444

Epoch: 120| Step: 0
Training loss: 2.3602576215402977
Validation loss: 2.532312617548071

Epoch: 5| Step: 1
Training loss: 3.189252035292397
Validation loss: 2.51265865476604

Epoch: 5| Step: 2
Training loss: 1.914854423029402
Validation loss: 2.4919688010247665

Epoch: 5| Step: 3
Training loss: 1.7076636218961525
Validation loss: 2.5163835246763324

Epoch: 5| Step: 4
Training loss: 2.1456282681252192
Validation loss: 2.5067209500495338

Epoch: 5| Step: 5
Training loss: 2.699944096445681
Validation loss: 2.545131839611173

Epoch: 5| Step: 6
Training loss: 1.9553046309654356
Validation loss: 2.519182469872278

Epoch: 5| Step: 7
Training loss: 1.5250209306625073
Validation loss: 2.520583925966396

Epoch: 5| Step: 8
Training loss: 2.2822215480528993
Validation loss: 2.534046684601848

Epoch: 5| Step: 9
Training loss: 1.7352633563858901
Validation loss: 2.526923713192519

Epoch: 5| Step: 10
Training loss: 2.3134134911199933
Validation loss: 2.560087972255724

Epoch: 5| Step: 11
Training loss: 2.362255434971263
Validation loss: 2.5666384154061292

Epoch: 121| Step: 0
Training loss: 2.163445229754152
Validation loss: 2.5730847903521163

Epoch: 5| Step: 1
Training loss: 1.6618991454379968
Validation loss: 2.5711502750550363

Epoch: 5| Step: 2
Training loss: 2.3428656371889742
Validation loss: 2.589870155472202

Epoch: 5| Step: 3
Training loss: 2.101881719119664
Validation loss: 2.5850917820036194

Epoch: 5| Step: 4
Training loss: 2.9126493489361875
Validation loss: 2.584550137718437

Epoch: 5| Step: 5
Training loss: 1.82585661915785
Validation loss: 2.5461894518819945

Epoch: 5| Step: 6
Training loss: 1.8582546160438014
Validation loss: 2.604679531458226

Epoch: 5| Step: 7
Training loss: 2.3977949542971317
Validation loss: 2.5736298261280965

Epoch: 5| Step: 8
Training loss: 2.512201479357932
Validation loss: 2.533318161343852

Epoch: 5| Step: 9
Training loss: 2.7025677762632765
Validation loss: 2.5382456790979098

Epoch: 5| Step: 10
Training loss: 1.843373211652913
Validation loss: 2.513340977386045

Epoch: 5| Step: 11
Training loss: 1.129017543916584
Validation loss: 2.521033227235632

Epoch: 122| Step: 0
Training loss: 1.5780733307793064
Validation loss: 2.5184427990612885

Epoch: 5| Step: 1
Training loss: 1.6402112166533906
Validation loss: 2.517427525283677

Epoch: 5| Step: 2
Training loss: 2.188196779722873
Validation loss: 2.5292933126495685

Epoch: 5| Step: 3
Training loss: 1.9426231331504245
Validation loss: 2.527326899240911

Epoch: 5| Step: 4
Training loss: 1.9582124902762659
Validation loss: 2.5139299214306265

Epoch: 5| Step: 5
Training loss: 2.576079788470963
Validation loss: 2.4814185259045196

Epoch: 5| Step: 6
Training loss: 2.6723505678855504
Validation loss: 2.510614649825935

Epoch: 5| Step: 7
Training loss: 2.114890566400333
Validation loss: 2.545281553382779

Epoch: 5| Step: 8
Training loss: 2.9081577069468088
Validation loss: 2.532529201583984

Epoch: 5| Step: 9
Training loss: 2.423449195425317
Validation loss: 2.50890652094636

Epoch: 5| Step: 10
Training loss: 1.8171215986797438
Validation loss: 2.5350219816399755

Epoch: 5| Step: 11
Training loss: 2.5987008884004035
Validation loss: 2.580671220597855

Epoch: 123| Step: 0
Training loss: 1.6231215697359862
Validation loss: 2.530208659940918

Epoch: 5| Step: 1
Training loss: 2.542338631609377
Validation loss: 2.556281309083746

Epoch: 5| Step: 2
Training loss: 2.024025143161855
Validation loss: 2.5130540670987576

Epoch: 5| Step: 3
Training loss: 2.5018587831671564
Validation loss: 2.5242522492188577

Epoch: 5| Step: 4
Training loss: 2.4307566556540263
Validation loss: 2.525699636893193

Epoch: 5| Step: 5
Training loss: 2.002632673347544
Validation loss: 2.5565113708135785

Epoch: 5| Step: 6
Training loss: 2.581058659516193
Validation loss: 2.5264255363097354

Epoch: 5| Step: 7
Training loss: 2.5898201827736154
Validation loss: 2.575821354030948

Epoch: 5| Step: 8
Training loss: 1.8686640180627292
Validation loss: 2.5386368693106

Epoch: 5| Step: 9
Training loss: 2.275211336988326
Validation loss: 2.5080103929819937

Epoch: 5| Step: 10
Training loss: 1.5906757548990023
Validation loss: 2.499295838846398

Epoch: 5| Step: 11
Training loss: 2.1124627014117805
Validation loss: 2.5193515841671013

Epoch: 124| Step: 0
Training loss: 2.0232035969341338
Validation loss: 2.5185564348545846

Epoch: 5| Step: 1
Training loss: 2.0251072655042486
Validation loss: 2.5425768548795546

Epoch: 5| Step: 2
Training loss: 2.326391611682823
Validation loss: 2.545632942968424

Epoch: 5| Step: 3
Training loss: 1.3015712595778823
Validation loss: 2.5493910673283104

Epoch: 5| Step: 4
Training loss: 1.956357188837811
Validation loss: 2.5337654926796853

Epoch: 5| Step: 5
Training loss: 2.25572123579347
Validation loss: 2.569180684828359

Epoch: 5| Step: 6
Training loss: 2.963706782366586
Validation loss: 2.5663753722494698

Epoch: 5| Step: 7
Training loss: 1.978193010122276
Validation loss: 2.575016357391525

Epoch: 5| Step: 8
Training loss: 2.2101956797831566
Validation loss: 2.584142344195387

Epoch: 5| Step: 9
Training loss: 2.3926740852886472
Validation loss: 2.5319426927044892

Epoch: 5| Step: 10
Training loss: 2.374634363237807
Validation loss: 2.5787103354540424

Epoch: 5| Step: 11
Training loss: 2.4381852776127433
Validation loss: 2.5592592378550036

Epoch: 125| Step: 0
Training loss: 1.771687454982077
Validation loss: 2.5220500726133133

Epoch: 5| Step: 1
Training loss: 1.813049561944061
Validation loss: 2.500058511208242

Epoch: 5| Step: 2
Training loss: 2.1391102798732065
Validation loss: 2.504948998482164

Epoch: 5| Step: 3
Training loss: 2.054303731723737
Validation loss: 2.479424769058539

Epoch: 5| Step: 4
Training loss: 1.906138807712166
Validation loss: 2.494100314944497

Epoch: 5| Step: 5
Training loss: 1.742280281914914
Validation loss: 2.507160910216121

Epoch: 5| Step: 6
Training loss: 2.5999764771497795
Validation loss: 2.4833838327018136

Epoch: 5| Step: 7
Training loss: 2.967568413348348
Validation loss: 2.5096041438182364

Epoch: 5| Step: 8
Training loss: 2.4839979161485664
Validation loss: 2.513979264883457

Epoch: 5| Step: 9
Training loss: 2.334387427607168
Validation loss: 2.5736422667482053

Epoch: 5| Step: 10
Training loss: 2.0765347239959504
Validation loss: 2.5142619110613738

Epoch: 5| Step: 11
Training loss: 2.1194458350558514
Validation loss: 2.539022881614484

Epoch: 126| Step: 0
Training loss: 1.6576427146264807
Validation loss: 2.532274823673484

Epoch: 5| Step: 1
Training loss: 1.906300340831994
Validation loss: 2.535501622135238

Epoch: 5| Step: 2
Training loss: 1.818272704323754
Validation loss: 2.5431441223645606

Epoch: 5| Step: 3
Training loss: 2.4163011954183156
Validation loss: 2.5606816399650545

Epoch: 5| Step: 4
Training loss: 2.462544234599825
Validation loss: 2.585128600040982

Epoch: 5| Step: 5
Training loss: 1.9099027313310362
Validation loss: 2.5767344684016154

Epoch: 5| Step: 6
Training loss: 2.031098110682319
Validation loss: 2.6266226975477136

Epoch: 5| Step: 7
Training loss: 2.3534716590162033
Validation loss: 2.599603035315071

Epoch: 5| Step: 8
Training loss: 2.4179291113345247
Validation loss: 2.6388089219464024

Epoch: 5| Step: 9
Training loss: 2.369335144561064
Validation loss: 2.558949680177607

Epoch: 5| Step: 10
Training loss: 2.3219006173734544
Validation loss: 2.57727608238736

Epoch: 5| Step: 11
Training loss: 2.379044953109549
Validation loss: 2.572317448747864

Epoch: 127| Step: 0
Training loss: 1.9976818836463681
Validation loss: 2.5208618159826184

Epoch: 5| Step: 1
Training loss: 2.3830786384416838
Validation loss: 2.5189556913420104

Epoch: 5| Step: 2
Training loss: 2.413648748896686
Validation loss: 2.5178651964161243

Epoch: 5| Step: 3
Training loss: 2.197022773037772
Validation loss: 2.514228097295602

Epoch: 5| Step: 4
Training loss: 1.76501927070796
Validation loss: 2.5149041953776896

Epoch: 5| Step: 5
Training loss: 2.6849738380109445
Validation loss: 2.51300845101951

Epoch: 5| Step: 6
Training loss: 2.4544077635526658
Validation loss: 2.529402519778916

Epoch: 5| Step: 7
Training loss: 2.065966611653322
Validation loss: 2.482122183576757

Epoch: 5| Step: 8
Training loss: 1.8720602513830449
Validation loss: 2.5193402240106604

Epoch: 5| Step: 9
Training loss: 1.6630404203483824
Validation loss: 2.524218972671579

Epoch: 5| Step: 10
Training loss: 2.3401259823655405
Validation loss: 2.5298688283597754

Epoch: 5| Step: 11
Training loss: 2.5423383502716477
Validation loss: 2.5123209293250417

Epoch: 128| Step: 0
Training loss: 1.6825515813983718
Validation loss: 2.53619120690599

Epoch: 5| Step: 1
Training loss: 2.809486809564636
Validation loss: 2.556346630642172

Epoch: 5| Step: 2
Training loss: 2.532176189752784
Validation loss: 2.587744785254077

Epoch: 5| Step: 3
Training loss: 2.2156528831632074
Validation loss: 2.5854974912099986

Epoch: 5| Step: 4
Training loss: 1.728535832001413
Validation loss: 2.621523534309596

Epoch: 5| Step: 5
Training loss: 1.656713672728378
Validation loss: 2.6361066997970406

Epoch: 5| Step: 6
Training loss: 1.8098565259731347
Validation loss: 2.6157405440356376

Epoch: 5| Step: 7
Training loss: 2.3251875196740475
Validation loss: 2.6369410743702115

Epoch: 5| Step: 8
Training loss: 2.1750856448444615
Validation loss: 2.620189925928319

Epoch: 5| Step: 9
Training loss: 2.1014984007635755
Validation loss: 2.6073459761832516

Epoch: 5| Step: 10
Training loss: 2.3580740063793093
Validation loss: 2.541010331527822

Epoch: 5| Step: 11
Training loss: 2.30001004672966
Validation loss: 2.5484385966180296

Epoch: 129| Step: 0
Training loss: 2.1541427045285064
Validation loss: 2.4957261389404013

Epoch: 5| Step: 1
Training loss: 2.161622031267444
Validation loss: 2.4965252291920303

Epoch: 5| Step: 2
Training loss: 2.4417136525221554
Validation loss: 2.479991220079283

Epoch: 5| Step: 3
Training loss: 2.0535723194570563
Validation loss: 2.543564386336369

Epoch: 5| Step: 4
Training loss: 2.0172423741613352
Validation loss: 2.5384306292589796

Epoch: 5| Step: 5
Training loss: 1.9483474894200519
Validation loss: 2.5022781085566304

Epoch: 5| Step: 6
Training loss: 1.927007010383306
Validation loss: 2.532701550986852

Epoch: 5| Step: 7
Training loss: 2.6933929242097876
Validation loss: 2.514342192238967

Epoch: 5| Step: 8
Training loss: 2.523117659290928
Validation loss: 2.529114175332447

Epoch: 5| Step: 9
Training loss: 2.1405699785498364
Validation loss: 2.5100135334442872

Epoch: 5| Step: 10
Training loss: 1.5144054579495891
Validation loss: 2.506928459414743

Epoch: 5| Step: 11
Training loss: 2.374324903409018
Validation loss: 2.575665960025538

Epoch: 130| Step: 0
Training loss: 1.9655242408920892
Validation loss: 2.566392063390035

Epoch: 5| Step: 1
Training loss: 1.6219058289289852
Validation loss: 2.562976347060401

Epoch: 5| Step: 2
Training loss: 1.6036031980216685
Validation loss: 2.5877483439169477

Epoch: 5| Step: 3
Training loss: 1.7863427023727654
Validation loss: 2.5861420449670525

Epoch: 5| Step: 4
Training loss: 1.817776792561472
Validation loss: 2.633750291953171

Epoch: 5| Step: 5
Training loss: 3.0567245520626516
Validation loss: 2.6516732673235186

Epoch: 5| Step: 6
Training loss: 1.5732241534212341
Validation loss: 2.6540229605502272

Epoch: 5| Step: 7
Training loss: 2.1580840341152663
Validation loss: 2.64321639084508

Epoch: 5| Step: 8
Training loss: 1.9673401765000915
Validation loss: 2.678871315941286

Epoch: 5| Step: 9
Training loss: 3.028812647670288
Validation loss: 2.6465593991314176

Epoch: 5| Step: 10
Training loss: 2.368880469118574
Validation loss: 2.62589339160869

Epoch: 5| Step: 11
Training loss: 2.48845965406115
Validation loss: 2.558504059362481

Epoch: 131| Step: 0
Training loss: 2.2238281593074825
Validation loss: 2.4980455388117027

Epoch: 5| Step: 1
Training loss: 2.2346404658187433
Validation loss: 2.507324769472868

Epoch: 5| Step: 2
Training loss: 2.178263756424761
Validation loss: 2.515118707923039

Epoch: 5| Step: 3
Training loss: 2.4169874526468775
Validation loss: 2.5466622846896065

Epoch: 5| Step: 4
Training loss: 2.033347704581248
Validation loss: 2.538763116645831

Epoch: 5| Step: 5
Training loss: 1.9749884689573882
Validation loss: 2.5452667845759067

Epoch: 5| Step: 6
Training loss: 2.968613470853195
Validation loss: 2.552373935087776

Epoch: 5| Step: 7
Training loss: 1.7863874134040556
Validation loss: 2.5709857735244572

Epoch: 5| Step: 8
Training loss: 2.44309463103462
Validation loss: 2.503454541561167

Epoch: 5| Step: 9
Training loss: 2.0854341849837126
Validation loss: 2.5074684247697205

Epoch: 5| Step: 10
Training loss: 1.9036857993909433
Validation loss: 2.497698670377936

Epoch: 5| Step: 11
Training loss: 2.0094089914534776
Validation loss: 2.540746472759977

Epoch: 132| Step: 0
Training loss: 1.9660816577938784
Validation loss: 2.5872775981985536

Epoch: 5| Step: 1
Training loss: 2.45918138607131
Validation loss: 2.5952277167961832

Epoch: 5| Step: 2
Training loss: 1.8514178899636862
Validation loss: 2.607577993836372

Epoch: 5| Step: 3
Training loss: 2.3706524860972067
Validation loss: 2.676373967888686

Epoch: 5| Step: 4
Training loss: 2.2369719665435155
Validation loss: 2.679787642273195

Epoch: 5| Step: 5
Training loss: 1.6826816575268753
Validation loss: 2.6765226984340136

Epoch: 5| Step: 6
Training loss: 2.802383709280463
Validation loss: 2.663000598076803

Epoch: 5| Step: 7
Training loss: 1.50496511463276
Validation loss: 2.685234571388849

Epoch: 5| Step: 8
Training loss: 1.816677343996267
Validation loss: 2.686725319982543

Epoch: 5| Step: 9
Training loss: 1.6002407667683
Validation loss: 2.6421931198484456

Epoch: 5| Step: 10
Training loss: 2.4285550437502756
Validation loss: 2.5996054236852286

Epoch: 5| Step: 11
Training loss: 3.4160752288521468
Validation loss: 2.5268107171019536

Epoch: 133| Step: 0
Training loss: 2.4900924821707293
Validation loss: 2.519258574089952

Epoch: 5| Step: 1
Training loss: 2.0958485121837764
Validation loss: 2.518566418024232

Epoch: 5| Step: 2
Training loss: 2.1823061727862583
Validation loss: 2.524001321309752

Epoch: 5| Step: 3
Training loss: 2.208933214966254
Validation loss: 2.5686982756803505

Epoch: 5| Step: 4
Training loss: 2.444437376166249
Validation loss: 2.5707035868675745

Epoch: 5| Step: 5
Training loss: 1.9899019182657287
Validation loss: 2.57365337177468

Epoch: 5| Step: 6
Training loss: 2.3561628087756414
Validation loss: 2.5632446842982435

Epoch: 5| Step: 7
Training loss: 1.8246975582817058
Validation loss: 2.5511313836326583

Epoch: 5| Step: 8
Training loss: 2.017031156950817
Validation loss: 2.5557544980381923

Epoch: 5| Step: 9
Training loss: 2.1179051608140145
Validation loss: 2.53034781637818

Epoch: 5| Step: 10
Training loss: 2.8731242155846153
Validation loss: 2.5172770724391405

Epoch: 5| Step: 11
Training loss: 0.7567943536963136
Validation loss: 2.511248792284404

Epoch: 134| Step: 0
Training loss: 2.374191548127941
Validation loss: 2.5491016226587755

Epoch: 5| Step: 1
Training loss: 2.576318466261423
Validation loss: 2.516877003010503

Epoch: 5| Step: 2
Training loss: 2.081758692437728
Validation loss: 2.583704523111719

Epoch: 5| Step: 3
Training loss: 2.231904271045213
Validation loss: 2.6009335449706903

Epoch: 5| Step: 4
Training loss: 1.6312006975813231
Validation loss: 2.6199743815132943

Epoch: 5| Step: 5
Training loss: 1.8914023448552404
Validation loss: 2.5859299051686113

Epoch: 5| Step: 6
Training loss: 1.6657771915951347
Validation loss: 2.661348054446272

Epoch: 5| Step: 7
Training loss: 2.063666736163865
Validation loss: 2.6707262559028275

Epoch: 5| Step: 8
Training loss: 2.4372865632339584
Validation loss: 2.646686245021504

Epoch: 5| Step: 9
Training loss: 2.042192067124412
Validation loss: 2.626540087971709

Epoch: 5| Step: 10
Training loss: 2.2347458751694598
Validation loss: 2.5861315928106903

Epoch: 5| Step: 11
Training loss: 1.0695833938850254
Validation loss: 2.573316662052693

Epoch: 135| Step: 0
Training loss: 2.6744969759567603
Validation loss: 2.5675227979646427

Epoch: 5| Step: 1
Training loss: 2.061313866064834
Validation loss: 2.5608388975260703

Epoch: 5| Step: 2
Training loss: 1.758105579951081
Validation loss: 2.5394345289722158

Epoch: 5| Step: 3
Training loss: 2.3686748402128197
Validation loss: 2.5236945282191656

Epoch: 5| Step: 4
Training loss: 1.7923301606739341
Validation loss: 2.534599599673703

Epoch: 5| Step: 5
Training loss: 1.737755445186166
Validation loss: 2.5226302927555633

Epoch: 5| Step: 6
Training loss: 2.9300139792047
Validation loss: 2.547706517021257

Epoch: 5| Step: 7
Training loss: 2.209857906244154
Validation loss: 2.5077914418319773

Epoch: 5| Step: 8
Training loss: 1.8252591223505101
Validation loss: 2.4696705828047096

Epoch: 5| Step: 9
Training loss: 1.1622678504405095
Validation loss: 2.4905843212103473

Epoch: 5| Step: 10
Training loss: 2.1143280651939627
Validation loss: 2.5511997652629597

Epoch: 5| Step: 11
Training loss: 2.830988830242537
Validation loss: 2.51354312245885

Epoch: 136| Step: 0
Training loss: 2.016374315661498
Validation loss: 2.565246147576807

Epoch: 5| Step: 1
Training loss: 1.62894620777767
Validation loss: 2.5757732261260453

Epoch: 5| Step: 2
Training loss: 2.164786648005821
Validation loss: 2.6249402584362165

Epoch: 5| Step: 3
Training loss: 2.257956952288655
Validation loss: 2.653636162427975

Epoch: 5| Step: 4
Training loss: 2.0579132171290944
Validation loss: 2.652948895702948

Epoch: 5| Step: 5
Training loss: 2.0332901319489927
Validation loss: 2.6125273821732726

Epoch: 5| Step: 6
Training loss: 1.8065803146605721
Validation loss: 2.619336831341074

Epoch: 5| Step: 7
Training loss: 3.1119789453397324
Validation loss: 2.5903919650474907

Epoch: 5| Step: 8
Training loss: 1.6502078705674519
Validation loss: 2.5187302235252105

Epoch: 5| Step: 9
Training loss: 1.758365391564064
Validation loss: 2.595557259201467

Epoch: 5| Step: 10
Training loss: 2.36275639025791
Validation loss: 2.5481376014630546

Epoch: 5| Step: 11
Training loss: 1.6262275754070092
Validation loss: 2.5549674741051995

Epoch: 137| Step: 0
Training loss: 2.0829773662361175
Validation loss: 2.5503990272527295

Epoch: 5| Step: 1
Training loss: 2.3607519312903906
Validation loss: 2.5620182251258425

Epoch: 5| Step: 2
Training loss: 1.7997320267100039
Validation loss: 2.569217742478624

Epoch: 5| Step: 3
Training loss: 2.1807138084549256
Validation loss: 2.5501579878521663

Epoch: 5| Step: 4
Training loss: 2.3606028614415004
Validation loss: 2.520134964405502

Epoch: 5| Step: 5
Training loss: 2.790101784657685
Validation loss: 2.5606495370853883

Epoch: 5| Step: 6
Training loss: 1.4624929052979625
Validation loss: 2.492821528065445

Epoch: 5| Step: 7
Training loss: 1.7465094769098137
Validation loss: 2.5231398651992936

Epoch: 5| Step: 8
Training loss: 2.242180801009429
Validation loss: 2.536172425111648

Epoch: 5| Step: 9
Training loss: 1.754382979888217
Validation loss: 2.554765908129745

Epoch: 5| Step: 10
Training loss: 1.6171660490962985
Validation loss: 2.5254832499335116

Epoch: 5| Step: 11
Training loss: 1.9985352158983316
Validation loss: 2.5650325061580013

Epoch: 138| Step: 0
Training loss: 1.874243520085639
Validation loss: 2.5635789328827956

Epoch: 5| Step: 1
Training loss: 2.1136384052255566
Validation loss: 2.570374413684754

Epoch: 5| Step: 2
Training loss: 1.9062436838514405
Validation loss: 2.544508995432791

Epoch: 5| Step: 3
Training loss: 1.6171117939943151
Validation loss: 2.535932468104546

Epoch: 5| Step: 4
Training loss: 2.2553124759817313
Validation loss: 2.5310209351177066

Epoch: 5| Step: 5
Training loss: 1.8236711811606416
Validation loss: 2.5463766456860726

Epoch: 5| Step: 6
Training loss: 2.1196254755680886
Validation loss: 2.532764905733018

Epoch: 5| Step: 7
Training loss: 1.77790726332513
Validation loss: 2.557687395998267

Epoch: 5| Step: 8
Training loss: 3.019126795913389
Validation loss: 2.600609420534734

Epoch: 5| Step: 9
Training loss: 1.8849831885440649
Validation loss: 2.5390043203095014

Epoch: 5| Step: 10
Training loss: 2.0850702547454176
Validation loss: 2.564669198789389

Epoch: 5| Step: 11
Training loss: 2.2960124569598155
Validation loss: 2.5680365336568536

Epoch: 139| Step: 0
Training loss: 2.6042339367125305
Validation loss: 2.5890493694579466

Epoch: 5| Step: 1
Training loss: 2.267518193046825
Validation loss: 2.5701807910137853

Epoch: 5| Step: 2
Training loss: 2.0014858686799752
Validation loss: 2.529866491955372

Epoch: 5| Step: 3
Training loss: 2.35638602190484
Validation loss: 2.5814985455795765

Epoch: 5| Step: 4
Training loss: 1.9428913415475464
Validation loss: 2.5850431464976666

Epoch: 5| Step: 5
Training loss: 2.123514890628897
Validation loss: 2.539185357667165

Epoch: 5| Step: 6
Training loss: 1.8033959196774099
Validation loss: 2.5202982284668427

Epoch: 5| Step: 7
Training loss: 2.550980143949423
Validation loss: 2.5786846709378155

Epoch: 5| Step: 8
Training loss: 1.1665710455445817
Validation loss: 2.489365808941022

Epoch: 5| Step: 9
Training loss: 2.0511353395949885
Validation loss: 2.549439800427408

Epoch: 5| Step: 10
Training loss: 1.78122416695049
Validation loss: 2.547473181938092

Epoch: 5| Step: 11
Training loss: 1.5300094873470786
Validation loss: 2.5034744556914967

Epoch: 140| Step: 0
Training loss: 1.8598580894888483
Validation loss: 2.5251057860747186

Epoch: 5| Step: 1
Training loss: 1.7538002169020461
Validation loss: 2.537446729605116

Epoch: 5| Step: 2
Training loss: 1.846087315855304
Validation loss: 2.59467414876719

Epoch: 5| Step: 3
Training loss: 1.8839578903902474
Validation loss: 2.6530588391145824

Epoch: 5| Step: 4
Training loss: 2.706912611966715
Validation loss: 2.665735541642107

Epoch: 5| Step: 5
Training loss: 2.3016143482218463
Validation loss: 2.659629097352115

Epoch: 5| Step: 6
Training loss: 1.829771034425245
Validation loss: 2.5833909248782514

Epoch: 5| Step: 7
Training loss: 2.0209976863555275
Validation loss: 2.6203727393750564

Epoch: 5| Step: 8
Training loss: 1.8134380412491249
Validation loss: 2.571491722680935

Epoch: 5| Step: 9
Training loss: 1.9462827537882263
Validation loss: 2.5603039371908034

Epoch: 5| Step: 10
Training loss: 2.3961469914877247
Validation loss: 2.5891702926134794

Epoch: 5| Step: 11
Training loss: 1.755070968671074
Validation loss: 2.560580224528761

Epoch: 141| Step: 0
Training loss: 1.3883542154916158
Validation loss: 2.5376213326596546

Epoch: 5| Step: 1
Training loss: 1.9507428710486534
Validation loss: 2.5702502775535634

Epoch: 5| Step: 2
Training loss: 2.0153533989128967
Validation loss: 2.5479121368525974

Epoch: 5| Step: 3
Training loss: 2.126073902514359
Validation loss: 2.5049475707965274

Epoch: 5| Step: 4
Training loss: 2.472091345114761
Validation loss: 2.538912356901418

Epoch: 5| Step: 5
Training loss: 2.282519157304204
Validation loss: 2.5033559883906764

Epoch: 5| Step: 6
Training loss: 1.7144081066354686
Validation loss: 2.5521528247532705

Epoch: 5| Step: 7
Training loss: 2.3824192410498433
Validation loss: 2.5409148555696324

Epoch: 5| Step: 8
Training loss: 1.9464535717839755
Validation loss: 2.541561845014566

Epoch: 5| Step: 9
Training loss: 1.273441384900492
Validation loss: 2.5472742442551826

Epoch: 5| Step: 10
Training loss: 2.6447605952064985
Validation loss: 2.554529428209383

Epoch: 5| Step: 11
Training loss: 1.4943592185890677
Validation loss: 2.5553766268020084

Epoch: 142| Step: 0
Training loss: 1.6495941587772052
Validation loss: 2.5677602864568443

Epoch: 5| Step: 1
Training loss: 2.3722204708159405
Validation loss: 2.565317012779643

Epoch: 5| Step: 2
Training loss: 2.166901856886728
Validation loss: 2.6226203365251437

Epoch: 5| Step: 3
Training loss: 2.359785536865327
Validation loss: 2.646285909458018

Epoch: 5| Step: 4
Training loss: 2.0092190220689727
Validation loss: 2.567697630750985

Epoch: 5| Step: 5
Training loss: 2.2115729938477497
Validation loss: 2.5929295571278708

Epoch: 5| Step: 6
Training loss: 1.9320970696059774
Validation loss: 2.598138444168463

Epoch: 5| Step: 7
Training loss: 1.831556636929138
Validation loss: 2.5730487323694633

Epoch: 5| Step: 8
Training loss: 1.757099057691757
Validation loss: 2.557441537405749

Epoch: 5| Step: 9
Training loss: 1.9030786618258646
Validation loss: 2.4968630580751796

Epoch: 5| Step: 10
Training loss: 1.6376402816670919
Validation loss: 2.56456875449612

Epoch: 5| Step: 11
Training loss: 3.306035914277354
Validation loss: 2.5979160188512496

Epoch: 143| Step: 0
Training loss: 2.00592807551837
Validation loss: 2.5299604176388986

Epoch: 5| Step: 1
Training loss: 2.002518736790927
Validation loss: 2.517153715747163

Epoch: 5| Step: 2
Training loss: 2.2113472387002955
Validation loss: 2.518285426576824

Epoch: 5| Step: 3
Training loss: 1.757520456425654
Validation loss: 2.5007409428283087

Epoch: 5| Step: 4
Training loss: 2.137973563399274
Validation loss: 2.53735085724001

Epoch: 5| Step: 5
Training loss: 2.4561534095777926
Validation loss: 2.484350256326801

Epoch: 5| Step: 6
Training loss: 2.3673987971007673
Validation loss: 2.526704726091896

Epoch: 5| Step: 7
Training loss: 1.6692971293440773
Validation loss: 2.5670579753387543

Epoch: 5| Step: 8
Training loss: 1.6525938597785628
Validation loss: 2.576080185668672

Epoch: 5| Step: 9
Training loss: 1.6775417372717425
Validation loss: 2.551301374464854

Epoch: 5| Step: 10
Training loss: 2.3410680048604626
Validation loss: 2.59045592792839

Epoch: 5| Step: 11
Training loss: 3.0506687119128078
Validation loss: 2.589998327890492

Epoch: 144| Step: 0
Training loss: 2.1539476791232963
Validation loss: 2.599757407406675

Epoch: 5| Step: 1
Training loss: 2.55365417300678
Validation loss: 2.575909701241356

Epoch: 5| Step: 2
Training loss: 2.2725357417117067
Validation loss: 2.58911554101496

Epoch: 5| Step: 3
Training loss: 1.7491806700813681
Validation loss: 2.600244205267044

Epoch: 5| Step: 4
Training loss: 1.8164566525265096
Validation loss: 2.600296904044136

Epoch: 5| Step: 5
Training loss: 1.586108945402295
Validation loss: 2.636416548376845

Epoch: 5| Step: 6
Training loss: 1.885659309355771
Validation loss: 2.594678042504565

Epoch: 5| Step: 7
Training loss: 2.1538051068146506
Validation loss: 2.572276801623541

Epoch: 5| Step: 8
Training loss: 1.6238732466348704
Validation loss: 2.5784343649466375

Epoch: 5| Step: 9
Training loss: 1.4732352416294403
Validation loss: 2.5274539119682813

Epoch: 5| Step: 10
Training loss: 2.2396874928464445
Validation loss: 2.563765341342238

Epoch: 5| Step: 11
Training loss: 3.26128453088378
Validation loss: 2.5236037527300272

Epoch: 145| Step: 0
Training loss: 2.323841429784677
Validation loss: 2.5508850294638696

Epoch: 5| Step: 1
Training loss: 1.6667324371076295
Validation loss: 2.5876922838510676

Epoch: 5| Step: 2
Training loss: 1.523902939341389
Validation loss: 2.5457858972973915

Epoch: 5| Step: 3
Training loss: 1.886426188214191
Validation loss: 2.609928841357727

Epoch: 5| Step: 4
Training loss: 1.7141005311013837
Validation loss: 2.585525504845817

Epoch: 5| Step: 5
Training loss: 1.9831018042928545
Validation loss: 2.626803966575007

Epoch: 5| Step: 6
Training loss: 1.8350778068448985
Validation loss: 2.6175887070774806

Epoch: 5| Step: 7
Training loss: 2.5789445903693458
Validation loss: 2.5726840162434423

Epoch: 5| Step: 8
Training loss: 1.9843806469453977
Validation loss: 2.5942694591944133

Epoch: 5| Step: 9
Training loss: 1.5582537363840832
Validation loss: 2.568869988917756

Epoch: 5| Step: 10
Training loss: 2.274747490755402
Validation loss: 2.5049924810344923

Epoch: 5| Step: 11
Training loss: 2.714337330520999
Validation loss: 2.542394273348249

Epoch: 146| Step: 0
Training loss: 2.232132860433809
Validation loss: 2.5223548779236924

Epoch: 5| Step: 1
Training loss: 1.9092965092735326
Validation loss: 2.5464679182058907

Epoch: 5| Step: 2
Training loss: 1.8720279662945063
Validation loss: 2.5098494578806423

Epoch: 5| Step: 3
Training loss: 2.276391276752098
Validation loss: 2.536433767451727

Epoch: 5| Step: 4
Training loss: 2.2694585529180933
Validation loss: 2.523863229968461

Epoch: 5| Step: 5
Training loss: 1.7111132805811904
Validation loss: 2.52628107542253

Epoch: 5| Step: 6
Training loss: 1.5228054985388007
Validation loss: 2.582136474250493

Epoch: 5| Step: 7
Training loss: 2.448492255751905
Validation loss: 2.578502080294544

Epoch: 5| Step: 8
Training loss: 1.6989206337580811
Validation loss: 2.56127510025611

Epoch: 5| Step: 9
Training loss: 1.6744909765638847
Validation loss: 2.5321075062311698

Epoch: 5| Step: 10
Training loss: 1.7377645689060386
Validation loss: 2.5849652147996287

Epoch: 5| Step: 11
Training loss: 1.411800071008056
Validation loss: 2.562865537452715

Epoch: 147| Step: 0
Training loss: 1.9168869665945865
Validation loss: 2.5977921490985105

Epoch: 5| Step: 1
Training loss: 1.6221521071010534
Validation loss: 2.6241882635891316

Epoch: 5| Step: 2
Training loss: 2.3266217799989595
Validation loss: 2.6239001301096057

Epoch: 5| Step: 3
Training loss: 1.7857568177198935
Validation loss: 2.5429685507684914

Epoch: 5| Step: 4
Training loss: 2.1663037754258556
Validation loss: 2.617808815762758

Epoch: 5| Step: 5
Training loss: 1.4330030674392442
Validation loss: 2.58605463121867

Epoch: 5| Step: 6
Training loss: 1.7326968898336443
Validation loss: 2.5515645271849188

Epoch: 5| Step: 7
Training loss: 1.8810195933836944
Validation loss: 2.563127502896596

Epoch: 5| Step: 8
Training loss: 2.0028463613213336
Validation loss: 2.5347103986653052

Epoch: 5| Step: 9
Training loss: 2.827693843116321
Validation loss: 2.54827476526057

Epoch: 5| Step: 10
Training loss: 1.5044808219075272
Validation loss: 2.5825431131695202

Epoch: 5| Step: 11
Training loss: 2.276153410402464
Validation loss: 2.54719230999908

Epoch: 148| Step: 0
Training loss: 1.584512606030458
Validation loss: 2.5261013705614364

Epoch: 5| Step: 1
Training loss: 1.50045133794112
Validation loss: 2.59638174431993

Epoch: 5| Step: 2
Training loss: 2.1794441114603624
Validation loss: 2.5731544243204474

Epoch: 5| Step: 3
Training loss: 1.4404121423719596
Validation loss: 2.574941087098231

Epoch: 5| Step: 4
Training loss: 2.8646351942511945
Validation loss: 2.5451809099159517

Epoch: 5| Step: 5
Training loss: 2.1191791021132445
Validation loss: 2.5533835478987688

Epoch: 5| Step: 6
Training loss: 1.442205026836255
Validation loss: 2.6140069528877374

Epoch: 5| Step: 7
Training loss: 2.10007557505902
Validation loss: 2.5854155713882605

Epoch: 5| Step: 8
Training loss: 1.3646118316392413
Validation loss: 2.577928400731781

Epoch: 5| Step: 9
Training loss: 2.2194828381305642
Validation loss: 2.6379022725391987

Epoch: 5| Step: 10
Training loss: 2.2579698342807797
Validation loss: 2.6271715037962773

Epoch: 5| Step: 11
Training loss: 1.0399725807683586
Validation loss: 2.577855841718209

Epoch: 149| Step: 0
Training loss: 1.9633989425581724
Validation loss: 2.61420600696334

Epoch: 5| Step: 1
Training loss: 1.6006754581909581
Validation loss: 2.574260566614905

Epoch: 5| Step: 2
Training loss: 2.292904074697448
Validation loss: 2.507692645131272

Epoch: 5| Step: 3
Training loss: 2.061091317661294
Validation loss: 2.5217467825752995

Epoch: 5| Step: 4
Training loss: 2.273539957051517
Validation loss: 2.501792952219548

Epoch: 5| Step: 5
Training loss: 1.7077274255948414
Validation loss: 2.5995752115963984

Epoch: 5| Step: 6
Training loss: 2.462305954002163
Validation loss: 2.577055973400128

Epoch: 5| Step: 7
Training loss: 1.9437862674972621
Validation loss: 2.5309613224140404

Epoch: 5| Step: 8
Training loss: 1.5696906381492528
Validation loss: 2.5713731612184607

Epoch: 5| Step: 9
Training loss: 2.080687126591167
Validation loss: 2.5957496051439612

Epoch: 5| Step: 10
Training loss: 1.4257620196156051
Validation loss: 2.5473202236271315

Epoch: 5| Step: 11
Training loss: 2.280671555850711
Validation loss: 2.5750143185004486

Epoch: 150| Step: 0
Training loss: 1.7984980012078164
Validation loss: 2.6033519360499997

Epoch: 5| Step: 1
Training loss: 1.408064286455004
Validation loss: 2.6539453606338754

Epoch: 5| Step: 2
Training loss: 1.7312818558719536
Validation loss: 2.7625595604184934

Epoch: 5| Step: 3
Training loss: 2.2376647419725417
Validation loss: 2.7516983668763553

Epoch: 5| Step: 4
Training loss: 2.3477832931190594
Validation loss: 2.733086300484411

Epoch: 5| Step: 5
Training loss: 2.244432873533447
Validation loss: 2.8268907920435096

Epoch: 5| Step: 6
Training loss: 1.6026777896659088
Validation loss: 2.711269204461694

Epoch: 5| Step: 7
Training loss: 1.9250112235993007
Validation loss: 2.7064714830081216

Epoch: 5| Step: 8
Training loss: 1.6632125188083895
Validation loss: 2.719347975729662

Epoch: 5| Step: 9
Training loss: 2.822731481204709
Validation loss: 2.5923808823787673

Epoch: 5| Step: 10
Training loss: 1.5021929605224857
Validation loss: 2.5227489024002296

Epoch: 5| Step: 11
Training loss: 1.9307076541376869
Validation loss: 2.52980484936698

Epoch: 151| Step: 0
Training loss: 2.3100019829811735
Validation loss: 2.504749082846194

Epoch: 5| Step: 1
Training loss: 2.1852289672579532
Validation loss: 2.576927951383123

Epoch: 5| Step: 2
Training loss: 2.3158464704234505
Validation loss: 2.5416820980343586

Epoch: 5| Step: 3
Training loss: 1.7444742701681113
Validation loss: 2.5238517956533175

Epoch: 5| Step: 4
Training loss: 1.603931740076538
Validation loss: 2.512053183147259

Epoch: 5| Step: 5
Training loss: 2.1734987405229687
Validation loss: 2.5077679631129843

Epoch: 5| Step: 6
Training loss: 1.6981088806443099
Validation loss: 2.528714267788135

Epoch: 5| Step: 7
Training loss: 1.3863395494821733
Validation loss: 2.555572994029859

Epoch: 5| Step: 8
Training loss: 1.7912761203434673
Validation loss: 2.5637190098023264

Epoch: 5| Step: 9
Training loss: 1.79291875100493
Validation loss: 2.5863073263180425

Epoch: 5| Step: 10
Training loss: 2.0594670508134456
Validation loss: 2.642634509364505

Epoch: 5| Step: 11
Training loss: 3.1730894573115274
Validation loss: 2.659573248837577

Epoch: 152| Step: 0
Training loss: 1.803929950199916
Validation loss: 2.596899697790359

Epoch: 5| Step: 1
Training loss: 1.6216237867723222
Validation loss: 2.5445422428320366

Epoch: 5| Step: 2
Training loss: 2.069341006954621
Validation loss: 2.5460114097332065

Epoch: 5| Step: 3
Training loss: 1.9628460475737342
Validation loss: 2.5171356680466976

Epoch: 5| Step: 4
Training loss: 1.56926475985424
Validation loss: 2.5470536682241876

Epoch: 5| Step: 5
Training loss: 1.812517757986486
Validation loss: 2.5420279298238917

Epoch: 5| Step: 6
Training loss: 1.888658367688579
Validation loss: 2.5511658414123835

Epoch: 5| Step: 7
Training loss: 1.452064455293659
Validation loss: 2.6111250850515493

Epoch: 5| Step: 8
Training loss: 1.5807533660326751
Validation loss: 2.518356270066064

Epoch: 5| Step: 9
Training loss: 2.5864122767399236
Validation loss: 2.5314878893552564

Epoch: 5| Step: 10
Training loss: 2.3568771984623194
Validation loss: 2.5838278186953896

Epoch: 5| Step: 11
Training loss: 1.834963471155615
Validation loss: 2.5653940737309116

Epoch: 153| Step: 0
Training loss: 2.8752821079004067
Validation loss: 2.6459040231848263

Epoch: 5| Step: 1
Training loss: 1.5678168815808566
Validation loss: 2.5968866723659385

Epoch: 5| Step: 2
Training loss: 2.0152905800352365
Validation loss: 2.704228773025938

Epoch: 5| Step: 3
Training loss: 2.182598945148877
Validation loss: 2.629664617307808

Epoch: 5| Step: 4
Training loss: 1.8724188522458989
Validation loss: 2.6653779884725584

Epoch: 5| Step: 5
Training loss: 1.738957717083132
Validation loss: 2.684949266929993

Epoch: 5| Step: 6
Training loss: 1.7357933499619052
Validation loss: 2.674426464885122

Epoch: 5| Step: 7
Training loss: 1.8685759166661131
Validation loss: 2.5926650259912805

Epoch: 5| Step: 8
Training loss: 1.9093184867025041
Validation loss: 2.6257377450659374

Epoch: 5| Step: 9
Training loss: 1.5792031712535952
Validation loss: 2.5726018293447632

Epoch: 5| Step: 10
Training loss: 1.233259735403062
Validation loss: 2.566330767817746

Epoch: 5| Step: 11
Training loss: 1.2047577715019666
Validation loss: 2.5631025892888877

Epoch: 154| Step: 0
Training loss: 1.6407459032832064
Validation loss: 2.5364125043317647

Epoch: 5| Step: 1
Training loss: 1.845042470737813
Validation loss: 2.483351568634065

Epoch: 5| Step: 2
Training loss: 2.0851347446583275
Validation loss: 2.55571356416776

Epoch: 5| Step: 3
Training loss: 2.0400521518548485
Validation loss: 2.5273620707001654

Epoch: 5| Step: 4
Training loss: 1.7662854605082752
Validation loss: 2.6024044381368547

Epoch: 5| Step: 5
Training loss: 2.3245907782283672
Validation loss: 2.5789434925476864

Epoch: 5| Step: 6
Training loss: 2.070190195753578
Validation loss: 2.592119711858917

Epoch: 5| Step: 7
Training loss: 1.9994225860589907
Validation loss: 2.581246680533897

Epoch: 5| Step: 8
Training loss: 1.9837054226823831
Validation loss: 2.504420770636723

Epoch: 5| Step: 9
Training loss: 1.620496304275644
Validation loss: 2.540503878206775

Epoch: 5| Step: 10
Training loss: 1.8696230402346603
Validation loss: 2.5885763907965815

Epoch: 5| Step: 11
Training loss: 0.7213196637179908
Validation loss: 2.5985703009830625

Epoch: 155| Step: 0
Training loss: 1.7136513424667832
Validation loss: 2.576837218047182

Epoch: 5| Step: 1
Training loss: 1.3247499103967249
Validation loss: 2.634466638324989

Epoch: 5| Step: 2
Training loss: 2.8232259733406764
Validation loss: 2.65687336432503

Epoch: 5| Step: 3
Training loss: 1.4641995653868543
Validation loss: 2.6413639246112512

Epoch: 5| Step: 4
Training loss: 2.155529288768768
Validation loss: 2.6886933323971385

Epoch: 5| Step: 5
Training loss: 2.186897194775085
Validation loss: 2.634963367263013

Epoch: 5| Step: 6
Training loss: 1.6325360661914246
Validation loss: 2.5972027165201195

Epoch: 5| Step: 7
Training loss: 2.024011125594309
Validation loss: 2.630354914341947

Epoch: 5| Step: 8
Training loss: 1.7809394431852446
Validation loss: 2.6116358276859915

Epoch: 5| Step: 9
Training loss: 1.2104458210640847
Validation loss: 2.582795569119555

Epoch: 5| Step: 10
Training loss: 1.3865847670611533
Validation loss: 2.5476809008654584

Epoch: 5| Step: 11
Training loss: 2.6971873079347812
Validation loss: 2.565105923621388

Epoch: 156| Step: 0
Training loss: 1.521630648632027
Validation loss: 2.5504584310193126

Epoch: 5| Step: 1
Training loss: 1.8766366808964865
Validation loss: 2.5946370392807507

Epoch: 5| Step: 2
Training loss: 1.597271264286213
Validation loss: 2.5284550231746303

Epoch: 5| Step: 3
Training loss: 1.8438600410339259
Validation loss: 2.5133674079531314

Epoch: 5| Step: 4
Training loss: 1.5924874334872534
Validation loss: 2.560068581936516

Epoch: 5| Step: 5
Training loss: 1.2691937746311872
Validation loss: 2.5843432026651727

Epoch: 5| Step: 6
Training loss: 2.1347986831269288
Validation loss: 2.567258529779428

Epoch: 5| Step: 7
Training loss: 2.1607906796440446
Validation loss: 2.5536967075940975

Epoch: 5| Step: 8
Training loss: 1.731924989956956
Validation loss: 2.5609055381147385

Epoch: 5| Step: 9
Training loss: 1.9858647559024134
Validation loss: 2.581218859074443

Epoch: 5| Step: 10
Training loss: 2.0949727373921263
Validation loss: 2.5709002633452855

Epoch: 5| Step: 11
Training loss: 2.8310112319879783
Validation loss: 2.5665493426405064

Epoch: 157| Step: 0
Training loss: 1.5578903102286192
Validation loss: 2.5716318785009378

Epoch: 5| Step: 1
Training loss: 1.8069165488196164
Validation loss: 2.594536907063908

Epoch: 5| Step: 2
Training loss: 1.7491493882623337
Validation loss: 2.594737986945195

Epoch: 5| Step: 3
Training loss: 1.6966599414195016
Validation loss: 2.5971714074019485

Epoch: 5| Step: 4
Training loss: 1.5399590219272354
Validation loss: 2.600997596176916

Epoch: 5| Step: 5
Training loss: 1.582478928508555
Validation loss: 2.6538223018251257

Epoch: 5| Step: 6
Training loss: 2.3296769876837775
Validation loss: 2.6432909402378217

Epoch: 5| Step: 7
Training loss: 1.9821328539700243
Validation loss: 2.7104579087231873

Epoch: 5| Step: 8
Training loss: 2.2894624224026368
Validation loss: 2.5869014245743758

Epoch: 5| Step: 9
Training loss: 1.3452284464347417
Validation loss: 2.5964819450399568

Epoch: 5| Step: 10
Training loss: 2.2643455312666045
Validation loss: 2.496131017145058

Epoch: 5| Step: 11
Training loss: 1.5771791248465745
Validation loss: 2.553596403569543

Epoch: 158| Step: 0
Training loss: 2.2281413587314756
Validation loss: 2.568492016673019

Epoch: 5| Step: 1
Training loss: 1.559415137131794
Validation loss: 2.5914973661090532

Epoch: 5| Step: 2
Training loss: 2.039496832296872
Validation loss: 2.544823649285222

Epoch: 5| Step: 3
Training loss: 1.9656096950596214
Validation loss: 2.527707250161975

Epoch: 5| Step: 4
Training loss: 1.700611464542245
Validation loss: 2.547034728613376

Epoch: 5| Step: 5
Training loss: 1.8387324060445032
Validation loss: 2.506148315960783

Epoch: 5| Step: 6
Training loss: 1.7625077673558276
Validation loss: 2.4845970982216072

Epoch: 5| Step: 7
Training loss: 1.8045423705299812
Validation loss: 2.55112872792278

Epoch: 5| Step: 8
Training loss: 1.9505514049977812
Validation loss: 2.562907752493551

Epoch: 5| Step: 9
Training loss: 2.027754255126432
Validation loss: 2.585000612737213

Epoch: 5| Step: 10
Training loss: 1.751088144690456
Validation loss: 2.605857652333763

Epoch: 5| Step: 11
Training loss: 0.7951749356653505
Validation loss: 2.646493564040781

Epoch: 159| Step: 0
Training loss: 1.9299387285656133
Validation loss: 2.614579585757869

Epoch: 5| Step: 1
Training loss: 1.9796822395044058
Validation loss: 2.610056546379418

Epoch: 5| Step: 2
Training loss: 1.5547704626596293
Validation loss: 2.65189707257545

Epoch: 5| Step: 3
Training loss: 2.4877280394342254
Validation loss: 2.6342763255544255

Epoch: 5| Step: 4
Training loss: 1.6853280395040384
Validation loss: 2.6464293189146075

Epoch: 5| Step: 5
Training loss: 1.7913253000621356
Validation loss: 2.5832769223688805

Epoch: 5| Step: 6
Training loss: 1.5223815388312385
Validation loss: 2.5638418909756786

Epoch: 5| Step: 7
Training loss: 1.5174755321962226
Validation loss: 2.638101737817483

Epoch: 5| Step: 8
Training loss: 1.8643147223585093
Validation loss: 2.552446811768234

Epoch: 5| Step: 9
Training loss: 1.7664066711182327
Validation loss: 2.5209984698996464

Epoch: 5| Step: 10
Training loss: 1.7905995791563103
Validation loss: 2.6056487532646466

Epoch: 5| Step: 11
Training loss: 0.7038632649666416
Validation loss: 2.527607435791199

Epoch: 160| Step: 0
Training loss: 1.8982440865659551
Validation loss: 2.5105601476818324

Epoch: 5| Step: 1
Training loss: 2.1836500894174176
Validation loss: 2.5912425932078325

Epoch: 5| Step: 2
Training loss: 1.6671198308309247
Validation loss: 2.5324104380610457

Epoch: 5| Step: 3
Training loss: 2.0170512513139687
Validation loss: 2.556343758844799

Epoch: 5| Step: 4
Training loss: 1.5114547932761038
Validation loss: 2.5869576131405245

Epoch: 5| Step: 5
Training loss: 1.8270274723202815
Validation loss: 2.5156887630808775

Epoch: 5| Step: 6
Training loss: 1.321157467217481
Validation loss: 2.542582234953505

Epoch: 5| Step: 7
Training loss: 2.237799201438926
Validation loss: 2.584732827657863

Epoch: 5| Step: 8
Training loss: 1.56584419954572
Validation loss: 2.55724961400984

Epoch: 5| Step: 9
Training loss: 1.4777773748762175
Validation loss: 2.5890432648298183

Epoch: 5| Step: 10
Training loss: 1.5979465510007982
Validation loss: 2.5808971913617946

Epoch: 5| Step: 11
Training loss: 2.272109020411381
Validation loss: 2.6290139416671643

Epoch: 161| Step: 0
Training loss: 2.152710926562948
Validation loss: 2.6205250008813485

Epoch: 5| Step: 1
Training loss: 1.9253675778681862
Validation loss: 2.6534220545299023

Epoch: 5| Step: 2
Training loss: 1.506797646649748
Validation loss: 2.713119339736744

Epoch: 5| Step: 3
Training loss: 1.9389690859269573
Validation loss: 2.7811867353123283

Epoch: 5| Step: 4
Training loss: 1.4612793547958876
Validation loss: 2.655043537437863

Epoch: 5| Step: 5
Training loss: 1.5247612312880219
Validation loss: 2.6558639769456525

Epoch: 5| Step: 6
Training loss: 1.7574716873384517
Validation loss: 2.598676904540579

Epoch: 5| Step: 7
Training loss: 1.816725639237678
Validation loss: 2.610458286214425

Epoch: 5| Step: 8
Training loss: 1.94310221288454
Validation loss: 2.6151083834447686

Epoch: 5| Step: 9
Training loss: 2.353355459247927
Validation loss: 2.5689790778255372

Epoch: 5| Step: 10
Training loss: 1.5418556544308362
Validation loss: 2.5454078458190965

Epoch: 5| Step: 11
Training loss: 1.3036657204090945
Validation loss: 2.5639284385954544

Epoch: 162| Step: 0
Training loss: 1.8322174042758606
Validation loss: 2.596310933071034

Epoch: 5| Step: 1
Training loss: 1.6730650472177344
Validation loss: 2.5551482474385803

Epoch: 5| Step: 2
Training loss: 2.1774788334515205
Validation loss: 2.5726991779025377

Epoch: 5| Step: 3
Training loss: 1.631153925262472
Validation loss: 2.5015556660991076

Epoch: 5| Step: 4
Training loss: 1.6881067103694845
Validation loss: 2.593534089106302

Epoch: 5| Step: 5
Training loss: 1.7668962881224684
Validation loss: 2.5666970524186534

Epoch: 5| Step: 6
Training loss: 1.6985609864208775
Validation loss: 2.5764171839277354

Epoch: 5| Step: 7
Training loss: 1.801076868910883
Validation loss: 2.6382051738011962

Epoch: 5| Step: 8
Training loss: 1.9147280411796572
Validation loss: 2.6430926295502437

Epoch: 5| Step: 9
Training loss: 2.0344027187726765
Validation loss: 2.6064004447565465

Epoch: 5| Step: 10
Training loss: 1.4886568651766428
Validation loss: 2.6128400953891986

Epoch: 5| Step: 11
Training loss: 1.351486733137548
Validation loss: 2.5602310416524774

Epoch: 163| Step: 0
Training loss: 1.6100025620055103
Validation loss: 2.586187740484267

Epoch: 5| Step: 1
Training loss: 1.9220589650504
Validation loss: 2.597406927013298

Epoch: 5| Step: 2
Training loss: 1.558486284647839
Validation loss: 2.619603324070781

Epoch: 5| Step: 3
Training loss: 1.5644755272565056
Validation loss: 2.593448054498301

Epoch: 5| Step: 4
Training loss: 2.394836605447389
Validation loss: 2.576729564443962

Epoch: 5| Step: 5
Training loss: 1.5695998059609981
Validation loss: 2.5783669868727297

Epoch: 5| Step: 6
Training loss: 1.3520509135038532
Validation loss: 2.608708679190016

Epoch: 5| Step: 7
Training loss: 1.6638697839459875
Validation loss: 2.622753000922676

Epoch: 5| Step: 8
Training loss: 1.6604725255947492
Validation loss: 2.5114645960373854

Epoch: 5| Step: 9
Training loss: 1.705788375952822
Validation loss: 2.6279550449788074

Epoch: 5| Step: 10
Training loss: 2.0121275847463957
Validation loss: 2.584315683621301

Epoch: 5| Step: 11
Training loss: 2.5425818833150324
Validation loss: 2.6215860290174766

Epoch: 164| Step: 0
Training loss: 1.8322130450596001
Validation loss: 2.5980034158800205

Epoch: 5| Step: 1
Training loss: 1.105345378771753
Validation loss: 2.5971366993756773

Epoch: 5| Step: 2
Training loss: 1.9452423940994494
Validation loss: 2.597673700030234

Epoch: 5| Step: 3
Training loss: 1.5648718570007603
Validation loss: 2.6203908740617368

Epoch: 5| Step: 4
Training loss: 1.272909792284761
Validation loss: 2.564076020404473

Epoch: 5| Step: 5
Training loss: 1.8678768912352193
Validation loss: 2.5598125748209806

Epoch: 5| Step: 6
Training loss: 1.5880634359281691
Validation loss: 2.568299851495325

Epoch: 5| Step: 7
Training loss: 1.7423743588264196
Validation loss: 2.590285733858173

Epoch: 5| Step: 8
Training loss: 1.510949779567111
Validation loss: 2.528349961565828

Epoch: 5| Step: 9
Training loss: 2.569124358805603
Validation loss: 2.600764456721769

Epoch: 5| Step: 10
Training loss: 1.629835929219167
Validation loss: 2.6005535479448225

Epoch: 5| Step: 11
Training loss: 1.8973320148076516
Validation loss: 2.5595409474585913

Epoch: 165| Step: 0
Training loss: 1.848886350564763
Validation loss: 2.6153808412189314

Epoch: 5| Step: 1
Training loss: 1.7344981656717744
Validation loss: 2.6973281934121207

Epoch: 5| Step: 2
Training loss: 1.5733053051477888
Validation loss: 2.5630476839276266

Epoch: 5| Step: 3
Training loss: 1.3682031836896595
Validation loss: 2.611022315026033

Epoch: 5| Step: 4
Training loss: 1.6166739270286474
Validation loss: 2.6299604292770624

Epoch: 5| Step: 5
Training loss: 1.257286672679693
Validation loss: 2.679574721236565

Epoch: 5| Step: 6
Training loss: 2.3788358931637137
Validation loss: 2.5882741161723666

Epoch: 5| Step: 7
Training loss: 1.9542580941725471
Validation loss: 2.659696971589742

Epoch: 5| Step: 8
Training loss: 1.4144451824851223
Validation loss: 2.6496319960638455

Epoch: 5| Step: 9
Training loss: 1.5584995174364378
Validation loss: 2.639590180987052

Epoch: 5| Step: 10
Training loss: 1.9954755986766515
Validation loss: 2.6274850564405288

Epoch: 5| Step: 11
Training loss: 1.613163165557706
Validation loss: 2.625143766250718

Epoch: 166| Step: 0
Training loss: 1.659421224004182
Validation loss: 2.629844199679887

Epoch: 5| Step: 1
Training loss: 1.3621697909382617
Validation loss: 2.6119970826244177

Epoch: 5| Step: 2
Training loss: 1.3349240569327192
Validation loss: 2.58260821476716

Epoch: 5| Step: 3
Training loss: 1.3561068305465844
Validation loss: 2.6021937901702716

Epoch: 5| Step: 4
Training loss: 1.9012141388991597
Validation loss: 2.59639958552685

Epoch: 5| Step: 5
Training loss: 1.7655327696890668
Validation loss: 2.601351191938386

Epoch: 5| Step: 6
Training loss: 2.4216479779559585
Validation loss: 2.6056249286715345

Epoch: 5| Step: 7
Training loss: 1.971352083783748
Validation loss: 2.572034357633452

Epoch: 5| Step: 8
Training loss: 1.296473705297266
Validation loss: 2.5324984168059963

Epoch: 5| Step: 9
Training loss: 1.15376209967686
Validation loss: 2.631639281447086

Epoch: 5| Step: 10
Training loss: 2.2396058428912107
Validation loss: 2.602542585665171

Epoch: 5| Step: 11
Training loss: 0.49905674593671195
Validation loss: 2.6139882551625977

Epoch: 167| Step: 0
Training loss: 1.1309440198986018
Validation loss: 2.5572608465498647

Epoch: 5| Step: 1
Training loss: 1.4407638317412608
Validation loss: 2.6097377403142583

Epoch: 5| Step: 2
Training loss: 1.8413421943408987
Validation loss: 2.621977394205146

Epoch: 5| Step: 3
Training loss: 1.7569715056347808
Validation loss: 2.61267089938807

Epoch: 5| Step: 4
Training loss: 1.592369753483302
Validation loss: 2.5567540084607514

Epoch: 5| Step: 5
Training loss: 1.6540033469621773
Validation loss: 2.634639347670869

Epoch: 5| Step: 6
Training loss: 1.8792011243729945
Validation loss: 2.636369198835119

Epoch: 5| Step: 7
Training loss: 2.0269099894234595
Validation loss: 2.5655975383693606

Epoch: 5| Step: 8
Training loss: 1.6615612592077296
Validation loss: 2.618952999273928

Epoch: 5| Step: 9
Training loss: 1.7072297772991625
Validation loss: 2.5777128564489735

Epoch: 5| Step: 10
Training loss: 2.0205494658360585
Validation loss: 2.6368910010317164

Epoch: 5| Step: 11
Training loss: 1.5620763585845694
Validation loss: 2.577640769258229

Epoch: 168| Step: 0
Training loss: 1.6987375564624703
Validation loss: 2.584910082055617

Epoch: 5| Step: 1
Training loss: 1.877534996448155
Validation loss: 2.5281810326765854

Epoch: 5| Step: 2
Training loss: 1.5656824889449856
Validation loss: 2.58412805889665

Epoch: 5| Step: 3
Training loss: 1.3482949774999622
Validation loss: 2.5547949683773536

Epoch: 5| Step: 4
Training loss: 1.3216175649324304
Validation loss: 2.540186440566345

Epoch: 5| Step: 5
Training loss: 1.7853433523478628
Validation loss: 2.5751424703720622

Epoch: 5| Step: 6
Training loss: 2.175184294686505
Validation loss: 2.5458624685673343

Epoch: 5| Step: 7
Training loss: 1.7206138215289053
Validation loss: 2.5635910967717033

Epoch: 5| Step: 8
Training loss: 1.3491274998858267
Validation loss: 2.657776283751497

Epoch: 5| Step: 9
Training loss: 1.9357728335445223
Validation loss: 2.643858308880676

Epoch: 5| Step: 10
Training loss: 1.6670547589814646
Validation loss: 2.6340880770566706

Epoch: 5| Step: 11
Training loss: 1.611595473796352
Validation loss: 2.7884865886581642

Epoch: 169| Step: 0
Training loss: 1.7972417042596895
Validation loss: 2.7315350489263883

Epoch: 5| Step: 1
Training loss: 1.9470482860861027
Validation loss: 2.8830223076067925

Epoch: 5| Step: 2
Training loss: 2.1182045833779743
Validation loss: 2.9349172039094493

Epoch: 5| Step: 3
Training loss: 1.7337318808909021
Validation loss: 2.8216157827241277

Epoch: 5| Step: 4
Training loss: 2.01045237560546
Validation loss: 2.8115986298000712

Epoch: 5| Step: 5
Training loss: 1.3407236663149922
Validation loss: 2.65860585850684

Epoch: 5| Step: 6
Training loss: 1.5087214285002775
Validation loss: 2.6085824010129333

Epoch: 5| Step: 7
Training loss: 2.061944250890532
Validation loss: 2.6103640145859783

Epoch: 5| Step: 8
Training loss: 1.7168134009354632
Validation loss: 2.5720946907593176

Epoch: 5| Step: 9
Training loss: 1.456354224277753
Validation loss: 2.5262604975871574

Epoch: 5| Step: 10
Training loss: 1.534278210852223
Validation loss: 2.5455126990230883

Epoch: 5| Step: 11
Training loss: 2.024710472036669
Validation loss: 2.605025032994613

Epoch: 170| Step: 0
Training loss: 2.1781348163925363
Validation loss: 2.6137490188874093

Epoch: 5| Step: 1
Training loss: 1.8245263177338369
Validation loss: 2.58845280520977

Epoch: 5| Step: 2
Training loss: 1.5060446064942725
Validation loss: 2.6021497672655802

Epoch: 5| Step: 3
Training loss: 1.7900308045874713
Validation loss: 2.6156394669449066

Epoch: 5| Step: 4
Training loss: 1.7512664299683618
Validation loss: 2.6500587227450914

Epoch: 5| Step: 5
Training loss: 1.3359631987659808
Validation loss: 2.6260948679396137

Epoch: 5| Step: 6
Training loss: 1.8218011621918564
Validation loss: 2.6381792878854724

Epoch: 5| Step: 7
Training loss: 2.1307850797657526
Validation loss: 2.593894630827229

Epoch: 5| Step: 8
Training loss: 1.4312376363295223
Validation loss: 2.7062540190845272

Epoch: 5| Step: 9
Training loss: 1.4163976114622983
Validation loss: 2.5971657674748663

Epoch: 5| Step: 10
Training loss: 1.4624929052979625
Validation loss: 2.5968258058530154

Epoch: 5| Step: 11
Training loss: 1.3671571564713116
Validation loss: 2.6000475324357324

Epoch: 171| Step: 0
Training loss: 1.3097147225472776
Validation loss: 2.634592173574243

Epoch: 5| Step: 1
Training loss: 1.680138957543838
Validation loss: 2.563785769267153

Epoch: 5| Step: 2
Training loss: 1.868718497224474
Validation loss: 2.614551127312679

Epoch: 5| Step: 3
Training loss: 1.5991560557962425
Validation loss: 2.6030657399344608

Epoch: 5| Step: 4
Training loss: 1.4458596508404917
Validation loss: 2.5727598950788204

Epoch: 5| Step: 5
Training loss: 1.552849838474284
Validation loss: 2.485656259941428

Epoch: 5| Step: 6
Training loss: 1.8581839842148313
Validation loss: 2.5800635014710838

Epoch: 5| Step: 7
Training loss: 2.208851831373908
Validation loss: 2.6349600571024467

Epoch: 5| Step: 8
Training loss: 1.3706113830808448
Validation loss: 2.5665294863425685

Epoch: 5| Step: 9
Training loss: 1.4841742932000357
Validation loss: 2.6207249756737627

Epoch: 5| Step: 10
Training loss: 1.5562472546411528
Validation loss: 2.6800102617828845

Epoch: 5| Step: 11
Training loss: 2.0113425486379555
Validation loss: 2.575237529872946

Epoch: 172| Step: 0
Training loss: 2.4370533460586463
Validation loss: 2.6123171378816425

Epoch: 5| Step: 1
Training loss: 1.5097338042662563
Validation loss: 2.5393888136669274

Epoch: 5| Step: 2
Training loss: 1.2768057060391456
Validation loss: 2.5951590406722973

Epoch: 5| Step: 3
Training loss: 1.3431122619394096
Validation loss: 2.5803266083630905

Epoch: 5| Step: 4
Training loss: 1.5060955807369696
Validation loss: 2.5984762460706676

Epoch: 5| Step: 5
Training loss: 1.7457545418208384
Validation loss: 2.580238254534308

Epoch: 5| Step: 6
Training loss: 1.42212448446555
Validation loss: 2.6763963238374697

Epoch: 5| Step: 7
Training loss: 1.704289659322659
Validation loss: 2.615413311132742

Epoch: 5| Step: 8
Training loss: 1.5119015289918587
Validation loss: 2.602403449461043

Epoch: 5| Step: 9
Training loss: 1.800617400884565
Validation loss: 2.5929503567878354

Epoch: 5| Step: 10
Training loss: 1.769282443510346
Validation loss: 2.583580696788935

Epoch: 5| Step: 11
Training loss: 1.4879889413925163
Validation loss: 2.6390027361845148

Epoch: 173| Step: 0
Training loss: 1.6790388407301422
Validation loss: 2.590867018275658

Epoch: 5| Step: 1
Training loss: 1.6169777701931174
Validation loss: 2.580941297715628

Epoch: 5| Step: 2
Training loss: 2.5531316563345565
Validation loss: 2.5725114763310977

Epoch: 5| Step: 3
Training loss: 1.4063545612032984
Validation loss: 2.5186091231396754

Epoch: 5| Step: 4
Training loss: 1.1881419504592972
Validation loss: 2.4790322416924098

Epoch: 5| Step: 5
Training loss: 1.4793282899625906
Validation loss: 2.5419411309110105

Epoch: 5| Step: 6
Training loss: 1.4909469480740873
Validation loss: 2.600622112172027

Epoch: 5| Step: 7
Training loss: 1.0214885179132944
Validation loss: 2.540676454959091

Epoch: 5| Step: 8
Training loss: 1.6541766018252844
Validation loss: 2.6067671774204366

Epoch: 5| Step: 9
Training loss: 2.0235813634683475
Validation loss: 2.63569153921606

Epoch: 5| Step: 10
Training loss: 1.5091038051568122
Validation loss: 2.6560757635977335

Epoch: 5| Step: 11
Training loss: 0.9521445249819455
Validation loss: 2.6438640577393957

Epoch: 174| Step: 0
Training loss: 1.8982054015142542
Validation loss: 2.6023398642204145

Epoch: 5| Step: 1
Training loss: 1.5101348701775277
Validation loss: 2.595682270855129

Epoch: 5| Step: 2
Training loss: 1.658940271591184
Validation loss: 2.571724110777811

Epoch: 5| Step: 3
Training loss: 1.651081441727081
Validation loss: 2.5824885191882254

Epoch: 5| Step: 4
Training loss: 1.9552725619980122
Validation loss: 2.549897785257445

Epoch: 5| Step: 5
Training loss: 1.3353525855548818
Validation loss: 2.6426927720692963

Epoch: 5| Step: 6
Training loss: 1.1826578097056595
Validation loss: 2.550942595492088

Epoch: 5| Step: 7
Training loss: 2.0719611746932025
Validation loss: 2.620873109842143

Epoch: 5| Step: 8
Training loss: 1.3889437166624248
Validation loss: 2.6028517735013224

Epoch: 5| Step: 9
Training loss: 1.3685743001406585
Validation loss: 2.6400104123509864

Epoch: 5| Step: 10
Training loss: 1.8709275842840005
Validation loss: 2.605322308025618

Epoch: 5| Step: 11
Training loss: 1.0164716272930578
Validation loss: 2.617444723214174

Epoch: 175| Step: 0
Training loss: 1.7432383289064086
Validation loss: 2.5592787313463

Epoch: 5| Step: 1
Training loss: 2.2304094243218575
Validation loss: 2.594947940454897

Epoch: 5| Step: 2
Training loss: 1.4497259440076533
Validation loss: 2.6388910571028075

Epoch: 5| Step: 3
Training loss: 1.5303953471552245
Validation loss: 2.6068627909402866

Epoch: 5| Step: 4
Training loss: 1.7615300857785618
Validation loss: 2.622827675551762

Epoch: 5| Step: 5
Training loss: 1.486514988304969
Validation loss: 2.6833073492351924

Epoch: 5| Step: 6
Training loss: 1.3509524958861627
Validation loss: 2.6588283142765894

Epoch: 5| Step: 7
Training loss: 1.6546094434732652
Validation loss: 2.66804163597267

Epoch: 5| Step: 8
Training loss: 1.1203947114241513
Validation loss: 2.7557834494928173

Epoch: 5| Step: 9
Training loss: 1.6909053492481378
Validation loss: 2.6817835107324535

Epoch: 5| Step: 10
Training loss: 1.4956323295569887
Validation loss: 2.671661398159202

Epoch: 5| Step: 11
Training loss: 1.8460392075794083
Validation loss: 2.562994265765859

Epoch: 176| Step: 0
Training loss: 1.296745477665932
Validation loss: 2.590528417795502

Epoch: 5| Step: 1
Training loss: 1.3749226635078213
Validation loss: 2.6086988124995276

Epoch: 5| Step: 2
Training loss: 1.794212026605896
Validation loss: 2.5787597375803935

Epoch: 5| Step: 3
Training loss: 1.717176237060709
Validation loss: 2.5506889030560678

Epoch: 5| Step: 4
Training loss: 2.326612864731209
Validation loss: 2.5691571716576926

Epoch: 5| Step: 5
Training loss: 1.3750434781916605
Validation loss: 2.4996807768783325

Epoch: 5| Step: 6
Training loss: 1.3623710588810676
Validation loss: 2.6405284984343487

Epoch: 5| Step: 7
Training loss: 1.6957834881604583
Validation loss: 2.600985603405607

Epoch: 5| Step: 8
Training loss: 1.6661328255504448
Validation loss: 2.5936089825883326

Epoch: 5| Step: 9
Training loss: 1.4540892652372055
Validation loss: 2.6647120082070104

Epoch: 5| Step: 10
Training loss: 1.3407175312254092
Validation loss: 2.548954374224279

Epoch: 5| Step: 11
Training loss: 1.3140833250883555
Validation loss: 2.632008279738114

Epoch: 177| Step: 0
Training loss: 1.3953193980491803
Validation loss: 2.6216550928039424

Epoch: 5| Step: 1
Training loss: 2.1368834381517092
Validation loss: 2.6446659311157785

Epoch: 5| Step: 2
Training loss: 1.9904625699113303
Validation loss: 2.7590076641245007

Epoch: 5| Step: 3
Training loss: 1.1424061702871515
Validation loss: 2.672601796175039

Epoch: 5| Step: 4
Training loss: 1.7735237403100184
Validation loss: 2.6952060918028815

Epoch: 5| Step: 5
Training loss: 1.6997004385285817
Validation loss: 2.686216362011379

Epoch: 5| Step: 6
Training loss: 1.341272109916881
Validation loss: 2.6747190088721218

Epoch: 5| Step: 7
Training loss: 1.3620608313191471
Validation loss: 2.571341755876782

Epoch: 5| Step: 8
Training loss: 1.5486032098968674
Validation loss: 2.5066488642252738

Epoch: 5| Step: 9
Training loss: 1.5924320381310733
Validation loss: 2.5644171722673255

Epoch: 5| Step: 10
Training loss: 1.460846515617076
Validation loss: 2.4932714932967937

Epoch: 5| Step: 11
Training loss: 1.144188214344817
Validation loss: 2.6107237902844695

Epoch: 178| Step: 0
Training loss: 1.2166418279873241
Validation loss: 2.539776921632479

Epoch: 5| Step: 1
Training loss: 2.3521489524191392
Validation loss: 2.572571856190566

Epoch: 5| Step: 2
Training loss: 1.3727327641377858
Validation loss: 2.5613476480462625

Epoch: 5| Step: 3
Training loss: 1.6739678519294248
Validation loss: 2.5967210372075233

Epoch: 5| Step: 4
Training loss: 1.4447636567444126
Validation loss: 2.557635021402436

Epoch: 5| Step: 5
Training loss: 1.1855475788648548
Validation loss: 2.6568259568445143

Epoch: 5| Step: 6
Training loss: 1.773103859055687
Validation loss: 2.574783390619446

Epoch: 5| Step: 7
Training loss: 1.7127283208630684
Validation loss: 2.620840413812272

Epoch: 5| Step: 8
Training loss: 1.3100164167088952
Validation loss: 2.6038893011521824

Epoch: 5| Step: 9
Training loss: 1.380756336560232
Validation loss: 2.5983956052025823

Epoch: 5| Step: 10
Training loss: 1.2535055595795053
Validation loss: 2.641540778607176

Epoch: 5| Step: 11
Training loss: 1.5687936298032883
Validation loss: 2.597099397484054

Epoch: 179| Step: 0
Training loss: 1.3899971048064235
Validation loss: 2.596561107340533

Epoch: 5| Step: 1
Training loss: 1.466430374459216
Validation loss: 2.6002623790923947

Epoch: 5| Step: 2
Training loss: 1.578669237017687
Validation loss: 2.612528165485955

Epoch: 5| Step: 3
Training loss: 1.4615101227541887
Validation loss: 2.6130478074707426

Epoch: 5| Step: 4
Training loss: 1.5134533927503642
Validation loss: 2.584498367071174

Epoch: 5| Step: 5
Training loss: 1.4311620893507742
Validation loss: 2.647181120085636

Epoch: 5| Step: 6
Training loss: 1.1722682547357053
Validation loss: 2.651993029351277

Epoch: 5| Step: 7
Training loss: 1.9544731675182518
Validation loss: 2.570643926353413

Epoch: 5| Step: 8
Training loss: 1.3370336753553063
Validation loss: 2.626886390112538

Epoch: 5| Step: 9
Training loss: 1.4272571188741976
Validation loss: 2.5833477140354515

Epoch: 5| Step: 10
Training loss: 2.0036275866948308
Validation loss: 2.583697006304682

Epoch: 5| Step: 11
Training loss: 1.4937663887433685
Validation loss: 2.6446325901585674

Epoch: 180| Step: 0
Training loss: 1.8669065639201665
Validation loss: 2.53088968954268

Epoch: 5| Step: 1
Training loss: 1.6966243186392274
Validation loss: 2.589775721297573

Epoch: 5| Step: 2
Training loss: 1.5196495500423273
Validation loss: 2.6385731484489936

Epoch: 5| Step: 3
Training loss: 1.3178606460456792
Validation loss: 2.637795781699946

Epoch: 5| Step: 4
Training loss: 1.201757570462301
Validation loss: 2.596194811757707

Epoch: 5| Step: 5
Training loss: 1.9216614271138277
Validation loss: 2.5982454019030685

Epoch: 5| Step: 6
Training loss: 1.343981478958012
Validation loss: 2.616028524344881

Epoch: 5| Step: 7
Training loss: 1.7639599941803459
Validation loss: 2.571188911586397

Epoch: 5| Step: 8
Training loss: 1.352483446650999
Validation loss: 2.6083272021854316

Epoch: 5| Step: 9
Training loss: 1.8400412289519938
Validation loss: 2.5540386157480905

Epoch: 5| Step: 10
Training loss: 0.9957000253478718
Validation loss: 2.6544194477402736

Epoch: 5| Step: 11
Training loss: 1.4975003236442306
Validation loss: 2.604446126566088

Epoch: 181| Step: 0
Training loss: 1.4323372388583326
Validation loss: 2.5581162956034404

Epoch: 5| Step: 1
Training loss: 1.3227184878113887
Validation loss: 2.57746813719573

Epoch: 5| Step: 2
Training loss: 0.8407046142088497
Validation loss: 2.66706350597379

Epoch: 5| Step: 3
Training loss: 2.152979706622072
Validation loss: 2.695532549292731

Epoch: 5| Step: 4
Training loss: 1.1892589792742982
Validation loss: 2.6798395497416667

Epoch: 5| Step: 5
Training loss: 1.6639841267213797
Validation loss: 2.6407168220039976

Epoch: 5| Step: 6
Training loss: 1.9351136062352683
Validation loss: 2.744570277416433

Epoch: 5| Step: 7
Training loss: 1.3523460718726683
Validation loss: 2.7374394982763373

Epoch: 5| Step: 8
Training loss: 1.8496735026955695
Validation loss: 2.634881324574799

Epoch: 5| Step: 9
Training loss: 1.1141096814023828
Validation loss: 2.669660978260316

Epoch: 5| Step: 10
Training loss: 1.352000391590468
Validation loss: 2.62891682305744

Epoch: 5| Step: 11
Training loss: 0.9590063150852303
Validation loss: 2.5591400844464984

Epoch: 182| Step: 0
Training loss: 0.9811740177646594
Validation loss: 2.639204913103015

Epoch: 5| Step: 1
Training loss: 1.3788092041446565
Validation loss: 2.60669513532779

Epoch: 5| Step: 2
Training loss: 1.1677286162757279
Validation loss: 2.572832787004888

Epoch: 5| Step: 3
Training loss: 1.8496909682455156
Validation loss: 2.591806629721197

Epoch: 5| Step: 4
Training loss: 1.8260460142122672
Validation loss: 2.5652380364561664

Epoch: 5| Step: 5
Training loss: 1.7364144920607307
Validation loss: 2.536311176007827

Epoch: 5| Step: 6
Training loss: 2.0679760686718223
Validation loss: 2.664958385580393

Epoch: 5| Step: 7
Training loss: 2.046555588821669
Validation loss: 2.6547983167007674

Epoch: 5| Step: 8
Training loss: 1.1130771382926679
Validation loss: 2.674635147454148

Epoch: 5| Step: 9
Training loss: 1.6924231029717882
Validation loss: 2.643706966618057

Epoch: 5| Step: 10
Training loss: 1.0976786763897015
Validation loss: 2.6011593098605967

Epoch: 5| Step: 11
Training loss: 0.9017236403612102
Validation loss: 2.683724160984298

Epoch: 183| Step: 0
Training loss: 1.2324692222822384
Validation loss: 2.596755898074484

Epoch: 5| Step: 1
Training loss: 2.5998480018788666
Validation loss: 2.634154916109762

Epoch: 5| Step: 2
Training loss: 1.6686025661532446
Validation loss: 2.637297872358292

Epoch: 5| Step: 3
Training loss: 1.4466689883856594
Validation loss: 2.6164673910574736

Epoch: 5| Step: 4
Training loss: 0.7480965540552239
Validation loss: 2.5867728414038598

Epoch: 5| Step: 5
Training loss: 1.1750146134462047
Validation loss: 2.5838218439858003

Epoch: 5| Step: 6
Training loss: 1.6360965538492696
Validation loss: 2.660405749002597

Epoch: 5| Step: 7
Training loss: 1.3243966222260866
Validation loss: 2.6423983365908206

Epoch: 5| Step: 8
Training loss: 1.2395967541563826
Validation loss: 2.5828811931763855

Epoch: 5| Step: 9
Training loss: 1.1239694007326286
Validation loss: 2.690597711706071

Epoch: 5| Step: 10
Training loss: 1.1818023318781743
Validation loss: 2.6874535283055523

Epoch: 5| Step: 11
Training loss: 2.348366526776792
Validation loss: 2.608439351985279

Epoch: 184| Step: 0
Training loss: 1.280497120420174
Validation loss: 2.5707147161816297

Epoch: 5| Step: 1
Training loss: 1.456326311592351
Validation loss: 2.6240609415599465

Epoch: 5| Step: 2
Training loss: 1.1761712222824388
Validation loss: 2.6829922356863447

Epoch: 5| Step: 3
Training loss: 1.16334824122593
Validation loss: 2.586379667435986

Epoch: 5| Step: 4
Training loss: 1.4245627853519796
Validation loss: 2.577668066665774

Epoch: 5| Step: 5
Training loss: 1.7626436432004737
Validation loss: 2.597234105583336

Epoch: 5| Step: 6
Training loss: 1.0947641847732077
Validation loss: 2.6271124090712874

Epoch: 5| Step: 7
Training loss: 1.4088609828067218
Validation loss: 2.58200640721761

Epoch: 5| Step: 8
Training loss: 1.1842517597426196
Validation loss: 2.6627233314574283

Epoch: 5| Step: 9
Training loss: 1.571177078533599
Validation loss: 2.6872223037847824

Epoch: 5| Step: 10
Training loss: 2.2439318527440895
Validation loss: 2.6404556167420097

Epoch: 5| Step: 11
Training loss: 2.286763882623347
Validation loss: 2.6198289437545923

Epoch: 185| Step: 0
Training loss: 1.2641738767089294
Validation loss: 2.743622939398098

Epoch: 5| Step: 1
Training loss: 1.1339306804521512
Validation loss: 2.670694648179085

Epoch: 5| Step: 2
Training loss: 1.6574551498305923
Validation loss: 2.6940021296589265

Epoch: 5| Step: 3
Training loss: 1.0099938612458659
Validation loss: 2.7131896068218624

Epoch: 5| Step: 4
Training loss: 1.4333813585323472
Validation loss: 2.7846344507617014

Epoch: 5| Step: 5
Training loss: 1.7380726206876211
Validation loss: 2.737926298709039

Epoch: 5| Step: 6
Training loss: 2.0633813535477286
Validation loss: 2.7160990422364484

Epoch: 5| Step: 7
Training loss: 1.3598915960079563
Validation loss: 2.5909388659198376

Epoch: 5| Step: 8
Training loss: 1.166760588453009
Validation loss: 2.633378772605115

Epoch: 5| Step: 9
Training loss: 2.0826149528439197
Validation loss: 2.6181061645920627

Epoch: 5| Step: 10
Training loss: 1.288267965809267
Validation loss: 2.6351045617211115

Epoch: 5| Step: 11
Training loss: 1.0301502027526488
Validation loss: 2.5897781110589886

Epoch: 186| Step: 0
Training loss: 1.631191197062598
Validation loss: 2.632153187953509

Epoch: 5| Step: 1
Training loss: 1.0229528313256615
Validation loss: 2.5594288635175264

Epoch: 5| Step: 2
Training loss: 1.6393538864236272
Validation loss: 2.5796537625443996

Epoch: 5| Step: 3
Training loss: 1.526643714579554
Validation loss: 2.5898311800721205

Epoch: 5| Step: 4
Training loss: 1.2431547609567084
Validation loss: 2.5597033164718193

Epoch: 5| Step: 5
Training loss: 1.864040004341877
Validation loss: 2.6250673467080436

Epoch: 5| Step: 6
Training loss: 1.42106655738655
Validation loss: 2.6754416479970193

Epoch: 5| Step: 7
Training loss: 1.4670557842504774
Validation loss: 2.6551643284627797

Epoch: 5| Step: 8
Training loss: 1.394147633165919
Validation loss: 2.667823575316228

Epoch: 5| Step: 9
Training loss: 1.5187233785172045
Validation loss: 2.5630611952670974

Epoch: 5| Step: 10
Training loss: 1.4410560409904767
Validation loss: 2.671136876818332

Epoch: 5| Step: 11
Training loss: 1.4581117279979177
Validation loss: 2.639577582628288

Epoch: 187| Step: 0
Training loss: 0.8915279562776739
Validation loss: 2.6540103595845754

Epoch: 5| Step: 1
Training loss: 1.4493655724196222
Validation loss: 2.597764340400977

Epoch: 5| Step: 2
Training loss: 1.3445340907384375
Validation loss: 2.6865925957354535

Epoch: 5| Step: 3
Training loss: 1.525361084010927
Validation loss: 2.6317310734643216

Epoch: 5| Step: 4
Training loss: 1.3605092895818736
Validation loss: 2.656880692797676

Epoch: 5| Step: 5
Training loss: 1.3262037405418925
Validation loss: 2.655882290090781

Epoch: 5| Step: 6
Training loss: 2.02622387482676
Validation loss: 2.6031018000038664

Epoch: 5| Step: 7
Training loss: 1.3437869931828799
Validation loss: 2.6026676759318086

Epoch: 5| Step: 8
Training loss: 1.7123865410190064
Validation loss: 2.6853964209749055

Epoch: 5| Step: 9
Training loss: 0.8846804007269286
Validation loss: 2.46936696628534

Epoch: 5| Step: 10
Training loss: 1.2944562486229494
Validation loss: 2.629118995314928

Epoch: 5| Step: 11
Training loss: 3.0252813980746684
Validation loss: 2.575673565837509

Epoch: 188| Step: 0
Training loss: 1.3956657517834612
Validation loss: 2.581821565871579

Epoch: 5| Step: 1
Training loss: 1.4799606538388144
Validation loss: 2.5929359629351993

Epoch: 5| Step: 2
Training loss: 1.3688415548979604
Validation loss: 2.5234097064901846

Epoch: 5| Step: 3
Training loss: 2.4186892321934854
Validation loss: 2.681948931873724

Epoch: 5| Step: 4
Training loss: 1.1443653702552097
Validation loss: 2.642719916284599

Epoch: 5| Step: 5
Training loss: 0.9668037183114812
Validation loss: 2.6635743940419188

Epoch: 5| Step: 6
Training loss: 0.995972928966174
Validation loss: 2.646941793215284

Epoch: 5| Step: 7
Training loss: 1.026174365658854
Validation loss: 2.709448501663485

Epoch: 5| Step: 8
Training loss: 1.5860535527504684
Validation loss: 2.588268581596957

Epoch: 5| Step: 9
Training loss: 1.2140027044979431
Validation loss: 2.645833711298718

Epoch: 5| Step: 10
Training loss: 1.811496325184577
Validation loss: 2.5605967672236494

Epoch: 5| Step: 11
Training loss: 1.2155547192809137
Validation loss: 2.6554379661835528

Epoch: 189| Step: 0
Training loss: 1.1025572809922202
Validation loss: 2.601639772247031

Epoch: 5| Step: 1
Training loss: 1.331173752226447
Validation loss: 2.619150968185586

Epoch: 5| Step: 2
Training loss: 0.8998054042355411
Validation loss: 2.635895747087922

Epoch: 5| Step: 3
Training loss: 1.1149405444762424
Validation loss: 2.655084675996919

Epoch: 5| Step: 4
Training loss: 1.7193807658269031
Validation loss: 2.6263621084943756

Epoch: 5| Step: 5
Training loss: 1.34358649035286
Validation loss: 2.6463810824310707

Epoch: 5| Step: 6
Training loss: 1.5019678082883132
Validation loss: 2.5847011464919083

Epoch: 5| Step: 7
Training loss: 1.496808630760098
Validation loss: 2.6243677172522304

Epoch: 5| Step: 8
Training loss: 1.347277247997305
Validation loss: 2.6324361311400137

Epoch: 5| Step: 9
Training loss: 2.1348462591273085
Validation loss: 2.621510494812393

Epoch: 5| Step: 10
Training loss: 1.1249781712427602
Validation loss: 2.5767839238302495

Epoch: 5| Step: 11
Training loss: 0.33327010667702645
Validation loss: 2.5887826785608836

Epoch: 190| Step: 0
Training loss: 1.3301569037277317
Validation loss: 2.689404736732042

Epoch: 5| Step: 1
Training loss: 0.843355404454435
Validation loss: 2.630800544366079

Epoch: 5| Step: 2
Training loss: 1.3215176200687915
Validation loss: 2.644461164574119

Epoch: 5| Step: 3
Training loss: 1.5711775337691312
Validation loss: 2.6417038573967435

Epoch: 5| Step: 4
Training loss: 1.0463615980528431
Validation loss: 2.6694000299712726

Epoch: 5| Step: 5
Training loss: 1.4019658421587724
Validation loss: 2.7272263787135107

Epoch: 5| Step: 6
Training loss: 2.175447010276059
Validation loss: 2.668837255604459

Epoch: 5| Step: 7
Training loss: 1.34921020257713
Validation loss: 2.6927950910885206

Epoch: 5| Step: 8
Training loss: 1.4614238235557386
Validation loss: 2.6191930004689024

Epoch: 5| Step: 9
Training loss: 1.2831093392436057
Validation loss: 2.657710806881924

Epoch: 5| Step: 10
Training loss: 1.8366605592869585
Validation loss: 2.645127481388291

Epoch: 5| Step: 11
Training loss: 0.7774807986498024
Validation loss: 2.549151088086708

Epoch: 191| Step: 0
Training loss: 1.0377926632008525
Validation loss: 2.6473813909786745

Epoch: 5| Step: 1
Training loss: 1.4913603402410733
Validation loss: 2.5730790590217665

Epoch: 5| Step: 2
Training loss: 1.2847229479309414
Validation loss: 2.5873620257548158

Epoch: 5| Step: 3
Training loss: 1.9417408706609556
Validation loss: 2.6367848743577307

Epoch: 5| Step: 4
Training loss: 1.4265524254868285
Validation loss: 2.6475036929083484

Epoch: 5| Step: 5
Training loss: 1.192704790712562
Validation loss: 2.6058120768230775

Epoch: 5| Step: 6
Training loss: 1.1561102911596788
Validation loss: 2.6988259658587666

Epoch: 5| Step: 7
Training loss: 1.272455784867014
Validation loss: 2.6541767256908946

Epoch: 5| Step: 8
Training loss: 2.0677043104412878
Validation loss: 2.6471014075370474

Epoch: 5| Step: 9
Training loss: 1.6554357578505912
Validation loss: 2.692238743981235

Epoch: 5| Step: 10
Training loss: 1.1752684225729226
Validation loss: 2.6569136220678877

Epoch: 5| Step: 11
Training loss: 0.7471873871066504
Validation loss: 2.630591836044916

Epoch: 192| Step: 0
Training loss: 1.702328416913723
Validation loss: 2.587760340452057

Epoch: 5| Step: 1
Training loss: 0.9024250274648054
Validation loss: 2.5975229214748286

Epoch: 5| Step: 2
Training loss: 1.3044164227505515
Validation loss: 2.646650866987607

Epoch: 5| Step: 3
Training loss: 2.2607420820396844
Validation loss: 2.6935678631424302

Epoch: 5| Step: 4
Training loss: 1.4510090506841218
Validation loss: 2.602214975796475

Epoch: 5| Step: 5
Training loss: 1.2155100476356913
Validation loss: 2.551609662272822

Epoch: 5| Step: 6
Training loss: 1.3577958065363214
Validation loss: 2.5784397626678968

Epoch: 5| Step: 7
Training loss: 1.2220718888584607
Validation loss: 2.5739272072635373

Epoch: 5| Step: 8
Training loss: 1.244018021655406
Validation loss: 2.5877988595107437

Epoch: 5| Step: 9
Training loss: 1.1063281920649672
Validation loss: 2.6759955624333087

Epoch: 5| Step: 10
Training loss: 1.3909501542128753
Validation loss: 2.6381285790710827

Epoch: 5| Step: 11
Training loss: 1.1341464902796174
Validation loss: 2.612651131257266

Epoch: 193| Step: 0
Training loss: 1.4543813381212698
Validation loss: 2.6696290620920378

Epoch: 5| Step: 1
Training loss: 1.214602332950778
Validation loss: 2.7065337009627974

Epoch: 5| Step: 2
Training loss: 1.2417906121128734
Validation loss: 2.664115110979747

Epoch: 5| Step: 3
Training loss: 1.410420739052029
Validation loss: 2.6821147168997905

Epoch: 5| Step: 4
Training loss: 1.1932970895448964
Validation loss: 2.675872203459839

Epoch: 5| Step: 5
Training loss: 1.3561205876922346
Validation loss: 2.6604304384747883

Epoch: 5| Step: 6
Training loss: 1.8011425259974012
Validation loss: 2.7282159741335055

Epoch: 5| Step: 7
Training loss: 1.5895409447987334
Validation loss: 2.679393305444945

Epoch: 5| Step: 8
Training loss: 1.3733995399827632
Validation loss: 2.7246979255825363

Epoch: 5| Step: 9
Training loss: 1.5055069764633473
Validation loss: 2.667538058442339

Epoch: 5| Step: 10
Training loss: 1.1337808087924974
Validation loss: 2.585569557220699

Epoch: 5| Step: 11
Training loss: 1.5135427899847655
Validation loss: 2.558845383401077

Epoch: 194| Step: 0
Training loss: 0.7608494811487518
Validation loss: 2.5905938268180995

Epoch: 5| Step: 1
Training loss: 1.4963822447703625
Validation loss: 2.6252436676162136

Epoch: 5| Step: 2
Training loss: 1.79203808801058
Validation loss: 2.5759954423429714

Epoch: 5| Step: 3
Training loss: 0.8963603679849576
Validation loss: 2.551911458566196

Epoch: 5| Step: 4
Training loss: 1.221541411382975
Validation loss: 2.609242407348118

Epoch: 5| Step: 5
Training loss: 1.314138706460551
Validation loss: 2.5559776540365458

Epoch: 5| Step: 6
Training loss: 1.2978329624884026
Validation loss: 2.630084521460884

Epoch: 5| Step: 7
Training loss: 1.2409784923229745
Validation loss: 2.5750433450587638

Epoch: 5| Step: 8
Training loss: 1.422845027492285
Validation loss: 2.6694286851806988

Epoch: 5| Step: 9
Training loss: 2.357339549424677
Validation loss: 2.6646585142690755

Epoch: 5| Step: 10
Training loss: 1.274683524104766
Validation loss: 2.7109679990842888

Epoch: 5| Step: 11
Training loss: 1.0898958692769711
Validation loss: 2.7658069159238514

Epoch: 195| Step: 0
Training loss: 1.7836383401290452
Validation loss: 2.806552153776647

Epoch: 5| Step: 1
Training loss: 1.2677494162571519
Validation loss: 2.7200944890207164

Epoch: 5| Step: 2
Training loss: 1.0228508585617326
Validation loss: 2.710671062733381

Epoch: 5| Step: 3
Training loss: 1.2743271604410575
Validation loss: 2.603344571369775

Epoch: 5| Step: 4
Training loss: 1.6205775162831146
Validation loss: 2.657608384254498

Epoch: 5| Step: 5
Training loss: 1.6222416869321021
Validation loss: 2.59584845640044

Epoch: 5| Step: 6
Training loss: 0.9739143783252169
Validation loss: 2.530353085044507

Epoch: 5| Step: 7
Training loss: 1.4058489333536375
Validation loss: 2.578910237959943

Epoch: 5| Step: 8
Training loss: 2.206238839010478
Validation loss: 2.5634115466395593

Epoch: 5| Step: 9
Training loss: 1.665293493436219
Validation loss: 2.654172013475511

Epoch: 5| Step: 10
Training loss: 1.4031866404156224
Validation loss: 2.6128265411020357

Epoch: 5| Step: 11
Training loss: 0.7496488464363894
Validation loss: 2.6988470113202676

Epoch: 196| Step: 0
Training loss: 1.6737255657027854
Validation loss: 2.6611604032340237

Epoch: 5| Step: 1
Training loss: 0.8066612037823131
Validation loss: 2.75092019233371

Epoch: 5| Step: 2
Training loss: 1.3842260172914
Validation loss: 2.79076724841483

Epoch: 5| Step: 3
Training loss: 1.216809513032533
Validation loss: 2.718105590568568

Epoch: 5| Step: 4
Training loss: 0.8895692088653347
Validation loss: 2.741783362275285

Epoch: 5| Step: 5
Training loss: 1.14518437937477
Validation loss: 2.7411653365167936

Epoch: 5| Step: 6
Training loss: 2.347731197131992
Validation loss: 2.6535780351767175

Epoch: 5| Step: 7
Training loss: 1.647386188541159
Validation loss: 2.708303118806196

Epoch: 5| Step: 8
Training loss: 1.1754351134927863
Validation loss: 2.6359195769672423

Epoch: 5| Step: 9
Training loss: 1.3005116501212648
Validation loss: 2.6074087078319224

Epoch: 5| Step: 10
Training loss: 1.362520634206211
Validation loss: 2.6118965167543537

Epoch: 5| Step: 11
Training loss: 1.7263461016202242
Validation loss: 2.6006532823411668

Epoch: 197| Step: 0
Training loss: 0.6730593954151612
Validation loss: 2.5976469723337416

Epoch: 5| Step: 1
Training loss: 1.3966114759958916
Validation loss: 2.5915634828267646

Epoch: 5| Step: 2
Training loss: 0.9812716961545572
Validation loss: 2.612017616351553

Epoch: 5| Step: 3
Training loss: 1.1131370584904638
Validation loss: 2.676174443075314

Epoch: 5| Step: 4
Training loss: 1.4499968627369584
Validation loss: 2.70001113015106

Epoch: 5| Step: 5
Training loss: 2.1230852813194696
Validation loss: 2.7934971698539313

Epoch: 5| Step: 6
Training loss: 1.7424901177715804
Validation loss: 2.746739792199508

Epoch: 5| Step: 7
Training loss: 0.7622848754466314
Validation loss: 2.721586300867793

Epoch: 5| Step: 8
Training loss: 1.3270985844492826
Validation loss: 2.6376067147504334

Epoch: 5| Step: 9
Training loss: 1.0729007472860277
Validation loss: 2.645128230635415

Epoch: 5| Step: 10
Training loss: 1.467120626304772
Validation loss: 2.6813674420865583

Epoch: 5| Step: 11
Training loss: 1.1995911159883466
Validation loss: 2.566886268599038

Epoch: 198| Step: 0
Training loss: 1.4560152249326226
Validation loss: 2.6763444962047997

Epoch: 5| Step: 1
Training loss: 1.512389357121836
Validation loss: 2.56584311490137

Epoch: 5| Step: 2
Training loss: 1.6332904171008988
Validation loss: 2.6237772826250954

Epoch: 5| Step: 3
Training loss: 2.0753671803829423
Validation loss: 2.5172609889556234

Epoch: 5| Step: 4
Training loss: 0.7588525301239931
Validation loss: 2.7311112971698512

Epoch: 5| Step: 5
Training loss: 1.173508687914044
Validation loss: 2.718193932737558

Epoch: 5| Step: 6
Training loss: 1.3597082847597
Validation loss: 2.656856890143849

Epoch: 5| Step: 7
Training loss: 1.1369868745541107
Validation loss: 2.6252513681886542

Epoch: 5| Step: 8
Training loss: 1.2019312001467344
Validation loss: 2.6206312572181045

Epoch: 5| Step: 9
Training loss: 1.4447807364771172
Validation loss: 2.612910222969348

Epoch: 5| Step: 10
Training loss: 1.1369595616680785
Validation loss: 2.6221256375765827

Epoch: 5| Step: 11
Training loss: 0.9700803236296288
Validation loss: 2.569868306405071

Epoch: 199| Step: 0
Training loss: 1.206883245486397
Validation loss: 2.644160328729317

Epoch: 5| Step: 1
Training loss: 1.2559672023111312
Validation loss: 2.61015898525411

Epoch: 5| Step: 2
Training loss: 1.198094042486024
Validation loss: 2.5884702942575455

Epoch: 5| Step: 3
Training loss: 1.3943641199143137
Validation loss: 2.571448962837813

Epoch: 5| Step: 4
Training loss: 1.1761239905160956
Validation loss: 2.628892332647629

Epoch: 5| Step: 5
Training loss: 1.6603926187430684
Validation loss: 2.6379301288421706

Epoch: 5| Step: 6
Training loss: 1.5295656243344082
Validation loss: 2.654292788021711

Epoch: 5| Step: 7
Training loss: 1.8996188408852872
Validation loss: 2.523866670093069

Epoch: 5| Step: 8
Training loss: 1.2848833716192436
Validation loss: 2.6018474105910436

Epoch: 5| Step: 9
Training loss: 1.2505352781521504
Validation loss: 2.6350726379284923

Epoch: 5| Step: 10
Training loss: 1.37556818580033
Validation loss: 2.6539489128779468

Epoch: 5| Step: 11
Training loss: 0.8271177392012232
Validation loss: 2.703333657357196

Epoch: 200| Step: 0
Training loss: 1.0897851196706918
Validation loss: 2.696313773408917

Epoch: 5| Step: 1
Training loss: 0.8224550151407898
Validation loss: 2.682253627445644

Epoch: 5| Step: 2
Training loss: 1.1025471175974848
Validation loss: 2.6870554401071693

Epoch: 5| Step: 3
Training loss: 1.1473273796109564
Validation loss: 2.7480340454409395

Epoch: 5| Step: 4
Training loss: 1.5947447271766688
Validation loss: 2.642379178088315

Epoch: 5| Step: 5
Training loss: 0.9257676650712463
Validation loss: 2.7009908818243202

Epoch: 5| Step: 6
Training loss: 1.6685849197401237
Validation loss: 2.611884442808534

Epoch: 5| Step: 7
Training loss: 1.1008981094438368
Validation loss: 2.6089924019773205

Epoch: 5| Step: 8
Training loss: 1.3762871613019882
Validation loss: 2.582623635502559

Epoch: 5| Step: 9
Training loss: 1.4252000434068217
Validation loss: 2.6031755137951924

Epoch: 5| Step: 10
Training loss: 1.3497882288383505
Validation loss: 2.579704170935661

Epoch: 5| Step: 11
Training loss: 3.6700668752954115
Validation loss: 2.5908383070340846

Testing loss: 2.498829209321166
