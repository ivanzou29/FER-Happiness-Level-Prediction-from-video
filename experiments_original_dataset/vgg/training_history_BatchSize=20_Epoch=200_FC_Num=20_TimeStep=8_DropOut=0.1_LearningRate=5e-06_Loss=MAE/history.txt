Epoch: 1| Step: 0
Training loss: 6.505831241607666
Validation loss: 6.506804545720418

Epoch: 5| Step: 1
Training loss: 6.164628028869629
Validation loss: 6.4907949566841125

Epoch: 5| Step: 2
Training loss: 7.3644514083862305
Validation loss: 6.471974611282349

Epoch: 5| Step: 3
Training loss: 6.254981994628906
Validation loss: 6.458181619644165

Epoch: 5| Step: 4
Training loss: 6.624413967132568
Validation loss: 6.443291862805684

Epoch: 5| Step: 5
Training loss: 6.755803108215332
Validation loss: 6.4276688893636065

Epoch: 5| Step: 6
Training loss: 7.280007362365723
Validation loss: 6.413011451562245

Epoch: 5| Step: 7
Training loss: 6.139110088348389
Validation loss: 6.400687913099925

Epoch: 5| Step: 8
Training loss: 5.600650787353516
Validation loss: 6.385304152965546

Epoch: 5| Step: 9
Training loss: 6.223473072052002
Validation loss: 6.369147479534149

Epoch: 5| Step: 10
Training loss: 6.443743705749512
Validation loss: 6.353387792905171

Epoch: 5| Step: 11
Training loss: 7.127232551574707
Validation loss: 6.336605707804362

Epoch: 2| Step: 0
Training loss: 5.948393821716309
Validation loss: 6.31977911790212

Epoch: 5| Step: 1
Training loss: 6.294692516326904
Validation loss: 6.300517439842224

Epoch: 5| Step: 2
Training loss: 6.880084991455078
Validation loss: 6.280700623989105

Epoch: 5| Step: 3
Training loss: 6.7399773597717285
Validation loss: 6.2587085366249084

Epoch: 5| Step: 4
Training loss: 5.659300804138184
Validation loss: 6.238701164722443

Epoch: 5| Step: 5
Training loss: 5.929997444152832
Validation loss: 6.215807696183522

Epoch: 5| Step: 6
Training loss: 6.813633918762207
Validation loss: 6.193758308887482

Epoch: 5| Step: 7
Training loss: 6.458861351013184
Validation loss: 6.165685375531514

Epoch: 5| Step: 8
Training loss: 5.642714977264404
Validation loss: 6.144021272659302

Epoch: 5| Step: 9
Training loss: 6.452078342437744
Validation loss: 6.114578763643901

Epoch: 5| Step: 10
Training loss: 5.984918117523193
Validation loss: 6.087977230548859

Epoch: 5| Step: 11
Training loss: 7.239956378936768
Validation loss: 6.055955628554027

Epoch: 3| Step: 0
Training loss: 5.979832649230957
Validation loss: 6.02407584587733

Epoch: 5| Step: 1
Training loss: 6.697818756103516
Validation loss: 5.996467610200246

Epoch: 5| Step: 2
Training loss: 6.322597026824951
Validation loss: 5.9638142585754395

Epoch: 5| Step: 3
Training loss: 5.768566608428955
Validation loss: 5.931286096572876

Epoch: 5| Step: 4
Training loss: 6.254232883453369
Validation loss: 5.892331083615621

Epoch: 5| Step: 5
Training loss: 6.930000305175781
Validation loss: 5.855758190155029

Epoch: 5| Step: 6
Training loss: 6.214852333068848
Validation loss: 5.809855043888092

Epoch: 5| Step: 7
Training loss: 4.987795352935791
Validation loss: 5.769575397173564

Epoch: 5| Step: 8
Training loss: 5.330960273742676
Validation loss: 5.727027356624603

Epoch: 5| Step: 9
Training loss: 5.2863287925720215
Validation loss: 5.684868554274241

Epoch: 5| Step: 10
Training loss: 5.02258825302124
Validation loss: 5.63535749912262

Epoch: 5| Step: 11
Training loss: 6.849976062774658
Validation loss: 5.582035660743713

Epoch: 4| Step: 0
Training loss: 4.6269354820251465
Validation loss: 5.526434818903605

Epoch: 5| Step: 1
Training loss: 6.118454933166504
Validation loss: 5.4757155776023865

Epoch: 5| Step: 2
Training loss: 6.688077449798584
Validation loss: 5.419186611970265

Epoch: 5| Step: 3
Training loss: 5.24110221862793
Validation loss: 5.346350570519765

Epoch: 5| Step: 4
Training loss: 5.063907623291016
Validation loss: 5.282847921053569

Epoch: 5| Step: 5
Training loss: 5.78366756439209
Validation loss: 5.211286167303721

Epoch: 5| Step: 6
Training loss: 5.53367805480957
Validation loss: 5.139878749847412

Epoch: 5| Step: 7
Training loss: 4.668798446655273
Validation loss: 5.062274277210236

Epoch: 5| Step: 8
Training loss: 4.3277788162231445
Validation loss: 4.987198034922282

Epoch: 5| Step: 9
Training loss: 4.837922096252441
Validation loss: 4.901407420635223

Epoch: 5| Step: 10
Training loss: 5.147923469543457
Validation loss: 4.820750117301941

Epoch: 5| Step: 11
Training loss: 3.937978506088257
Validation loss: 4.722507039705913

Epoch: 5| Step: 0
Training loss: 4.650717258453369
Validation loss: 4.630402892827988

Epoch: 5| Step: 1
Training loss: 5.87007999420166
Validation loss: 4.529991090297699

Epoch: 5| Step: 2
Training loss: 4.061245918273926
Validation loss: 4.419059594472249

Epoch: 5| Step: 3
Training loss: 4.216885089874268
Validation loss: 4.327242563168208

Epoch: 5| Step: 4
Training loss: 3.8063158988952637
Validation loss: 4.2012982567151385

Epoch: 5| Step: 5
Training loss: 4.150605201721191
Validation loss: 4.11511617898941

Epoch: 5| Step: 6
Training loss: 3.375427722930908
Validation loss: 4.004911690950394

Epoch: 5| Step: 7
Training loss: 4.672998428344727
Validation loss: 3.8843381901582084

Epoch: 5| Step: 8
Training loss: 2.9241554737091064
Validation loss: 3.790222386519114

Epoch: 5| Step: 9
Training loss: 4.213820457458496
Validation loss: 3.6542093753814697

Epoch: 5| Step: 10
Training loss: 3.486983060836792
Validation loss: 3.5497295757134757

Epoch: 5| Step: 11
Training loss: 4.783840179443359
Validation loss: 3.424089918533961

Epoch: 6| Step: 0
Training loss: 4.125607490539551
Validation loss: 3.307484269142151

Epoch: 5| Step: 1
Training loss: 3.2190890312194824
Validation loss: 3.203125258286794

Epoch: 5| Step: 2
Training loss: 3.0455634593963623
Validation loss: 3.080659826596578

Epoch: 5| Step: 3
Training loss: 3.2072417736053467
Validation loss: 2.9672221342722573

Epoch: 5| Step: 4
Training loss: 3.165161371231079
Validation loss: 2.833880841732025

Epoch: 5| Step: 5
Training loss: 2.3327090740203857
Validation loss: 2.7331388890743256

Epoch: 5| Step: 6
Training loss: 2.1790616512298584
Validation loss: 2.634992092847824

Epoch: 5| Step: 7
Training loss: 3.2325751781463623
Validation loss: 2.5368870198726654

Epoch: 5| Step: 8
Training loss: 2.1206917762756348
Validation loss: 2.4641684740781784

Epoch: 5| Step: 9
Training loss: 1.6579005718231201
Validation loss: 2.4275109271208444

Epoch: 5| Step: 10
Training loss: 2.6055867671966553
Validation loss: 2.369154671827952

Epoch: 5| Step: 11
Training loss: 2.9339852333068848
Validation loss: 2.3511309921741486

Epoch: 7| Step: 0
Training loss: 1.6560161113739014
Validation loss: 2.3518937677145004

Epoch: 5| Step: 1
Training loss: 2.146430730819702
Validation loss: 2.345788151025772

Epoch: 5| Step: 2
Training loss: 1.915658950805664
Validation loss: 2.3613550812005997

Epoch: 5| Step: 3
Training loss: 2.2114596366882324
Validation loss: 2.365401695171992

Epoch: 5| Step: 4
Training loss: 2.6583335399627686
Validation loss: 2.3704433739185333

Epoch: 5| Step: 5
Training loss: 2.2708754539489746
Validation loss: 2.399617830912272

Epoch: 5| Step: 6
Training loss: 2.3137660026550293
Validation loss: 2.378695329030355

Epoch: 5| Step: 7
Training loss: 2.622187376022339
Validation loss: 2.3688148160775504

Epoch: 5| Step: 8
Training loss: 1.7761561870574951
Validation loss: 2.3634432355562844

Epoch: 5| Step: 9
Training loss: 2.8140673637390137
Validation loss: 2.380248705546061

Epoch: 5| Step: 10
Training loss: 3.107372522354126
Validation loss: 2.3624872664610543

Epoch: 5| Step: 11
Training loss: 0.401433527469635
Validation loss: 2.356017212073008

Epoch: 8| Step: 0
Training loss: 2.1861605644226074
Validation loss: 2.3507098853588104

Epoch: 5| Step: 1
Training loss: 2.369805335998535
Validation loss: 2.313698927561442

Epoch: 5| Step: 2
Training loss: 2.626319169998169
Validation loss: 2.327696144580841

Epoch: 5| Step: 3
Training loss: 2.11480712890625
Validation loss: 2.334296574195226

Epoch: 5| Step: 4
Training loss: 1.9403365850448608
Validation loss: 2.3216480712095895

Epoch: 5| Step: 5
Training loss: 1.9592010974884033
Validation loss: 2.316634933153788

Epoch: 5| Step: 6
Training loss: 1.6680047512054443
Validation loss: 2.3172084291776023

Epoch: 5| Step: 7
Training loss: 1.8513730764389038
Validation loss: 2.2905486623446145

Epoch: 5| Step: 8
Training loss: 2.528921604156494
Validation loss: 2.3211851716041565

Epoch: 5| Step: 9
Training loss: 2.6870226860046387
Validation loss: 2.344069942831993

Epoch: 5| Step: 10
Training loss: 2.8402726650238037
Validation loss: 2.3286037345727286

Epoch: 5| Step: 11
Training loss: 1.4660063982009888
Validation loss: 2.3064428170522056

Epoch: 9| Step: 0
Training loss: 2.6714580059051514
Validation loss: 2.298926442861557

Epoch: 5| Step: 1
Training loss: 2.3255772590637207
Validation loss: 2.3158654471238456

Epoch: 5| Step: 2
Training loss: 2.0967819690704346
Validation loss: 2.306490550438563

Epoch: 5| Step: 3
Training loss: 2.1348564624786377
Validation loss: 2.2847098410129547

Epoch: 5| Step: 4
Training loss: 1.8035961389541626
Validation loss: 2.30549526711305

Epoch: 5| Step: 5
Training loss: 2.424354314804077
Validation loss: 2.310488740603129

Epoch: 5| Step: 6
Training loss: 2.428879976272583
Validation loss: 2.327176034450531

Epoch: 5| Step: 7
Training loss: 1.6366256475448608
Validation loss: 2.309022923310598

Epoch: 5| Step: 8
Training loss: 1.4590835571289062
Validation loss: 2.30013973514239

Epoch: 5| Step: 9
Training loss: 2.292494297027588
Validation loss: 2.289221634467443

Epoch: 5| Step: 10
Training loss: 2.7670388221740723
Validation loss: 2.278032273054123

Epoch: 5| Step: 11
Training loss: 2.4247193336486816
Validation loss: 2.260005091627439

Epoch: 10| Step: 0
Training loss: 2.0708272457122803
Validation loss: 2.30108513434728

Epoch: 5| Step: 1
Training loss: 2.3863718509674072
Validation loss: 2.2900319496790567

Epoch: 5| Step: 2
Training loss: 2.1704390048980713
Validation loss: 2.2878756572802863

Epoch: 5| Step: 3
Training loss: 1.7860409021377563
Validation loss: 2.2692623486121497

Epoch: 5| Step: 4
Training loss: 2.2790682315826416
Validation loss: 2.253571708997091

Epoch: 5| Step: 5
Training loss: 1.8299789428710938
Validation loss: 2.2382148802280426

Epoch: 5| Step: 6
Training loss: 2.5476653575897217
Validation loss: 2.2551584939161935

Epoch: 5| Step: 7
Training loss: 1.9143791198730469
Validation loss: 2.259003202120463

Epoch: 5| Step: 8
Training loss: 2.0140461921691895
Validation loss: 2.2651106218496957

Epoch: 5| Step: 9
Training loss: 2.9757866859436035
Validation loss: 2.268440544605255

Epoch: 5| Step: 10
Training loss: 1.9938182830810547
Validation loss: 2.2836400270462036

Epoch: 5| Step: 11
Training loss: 1.9818040132522583
Validation loss: 2.2976586669683456

Epoch: 11| Step: 0
Training loss: 1.8651068210601807
Validation loss: 2.2491315752267838

Epoch: 5| Step: 1
Training loss: 2.7281553745269775
Validation loss: 2.258158346017202

Epoch: 5| Step: 2
Training loss: 2.411374568939209
Validation loss: 2.262762427330017

Epoch: 5| Step: 3
Training loss: 2.4853577613830566
Validation loss: 2.289982408285141

Epoch: 5| Step: 4
Training loss: 1.6952623128890991
Validation loss: 2.291241238514582

Epoch: 5| Step: 5
Training loss: 2.0352702140808105
Validation loss: 2.2831580142180123

Epoch: 5| Step: 6
Training loss: 2.225358724594116
Validation loss: 2.264951060215632

Epoch: 5| Step: 7
Training loss: 2.177354335784912
Validation loss: 2.272785777846972

Epoch: 5| Step: 8
Training loss: 1.8572412729263306
Validation loss: 2.2250288079182305

Epoch: 5| Step: 9
Training loss: 2.692276954650879
Validation loss: 2.2768593033154807

Epoch: 5| Step: 10
Training loss: 1.8977153301239014
Validation loss: 2.2619450787703195

Epoch: 5| Step: 11
Training loss: 1.9303793907165527
Validation loss: 2.2440600196520486

Epoch: 12| Step: 0
Training loss: 2.186204195022583
Validation loss: 2.256621072689692

Epoch: 5| Step: 1
Training loss: 1.9019434452056885
Validation loss: 2.2616352488597236

Epoch: 5| Step: 2
Training loss: 2.7594971656799316
Validation loss: 2.282575771212578

Epoch: 5| Step: 3
Training loss: 1.7912883758544922
Validation loss: 2.2582174241542816

Epoch: 5| Step: 4
Training loss: 2.0323901176452637
Validation loss: 2.261907388766607

Epoch: 5| Step: 5
Training loss: 2.3858861923217773
Validation loss: 2.2493025759855905

Epoch: 5| Step: 6
Training loss: 2.7729029655456543
Validation loss: 2.2336473564306893

Epoch: 5| Step: 7
Training loss: 1.7892910242080688
Validation loss: 2.2504943211873374

Epoch: 5| Step: 8
Training loss: 2.3386104106903076
Validation loss: 2.2648059527079263

Epoch: 5| Step: 9
Training loss: 2.4734816551208496
Validation loss: 2.2513589213291803

Epoch: 5| Step: 10
Training loss: 1.5839704275131226
Validation loss: 2.2477738857269287

Epoch: 5| Step: 11
Training loss: 0.9305224418640137
Validation loss: 2.2595456391572952

Epoch: 13| Step: 0
Training loss: 1.6708341836929321
Validation loss: 2.230342596769333

Epoch: 5| Step: 1
Training loss: 2.4736568927764893
Validation loss: 2.2538071870803833

Epoch: 5| Step: 2
Training loss: 2.6562342643737793
Validation loss: 2.2409217109282813

Epoch: 5| Step: 3
Training loss: 2.2344911098480225
Validation loss: 2.2388141602277756

Epoch: 5| Step: 4
Training loss: 2.1633851528167725
Validation loss: 2.2592865278323493

Epoch: 5| Step: 5
Training loss: 1.794650673866272
Validation loss: 2.241338516275088

Epoch: 5| Step: 6
Training loss: 2.4312539100646973
Validation loss: 2.235917329788208

Epoch: 5| Step: 7
Training loss: 2.6205246448516846
Validation loss: 2.2135790089766183

Epoch: 5| Step: 8
Training loss: 2.0086069107055664
Validation loss: 2.2025689482688904

Epoch: 5| Step: 9
Training loss: 1.6116313934326172
Validation loss: 2.259385496377945

Epoch: 5| Step: 10
Training loss: 1.4811360836029053
Validation loss: 2.2284162441889444

Epoch: 5| Step: 11
Training loss: 2.6509876251220703
Validation loss: 2.2076563636461892

Epoch: 14| Step: 0
Training loss: 1.908951759338379
Validation loss: 2.2194349467754364

Epoch: 5| Step: 1
Training loss: 1.7036501169204712
Validation loss: 2.21089860300223

Epoch: 5| Step: 2
Training loss: 1.8281103372573853
Validation loss: 2.2270716428756714

Epoch: 5| Step: 3
Training loss: 2.2599523067474365
Validation loss: 2.214162697394689

Epoch: 5| Step: 4
Training loss: 2.744291305541992
Validation loss: 2.2098664989074073

Epoch: 5| Step: 5
Training loss: 2.2613017559051514
Validation loss: 2.232882469892502

Epoch: 5| Step: 6
Training loss: 1.8618800640106201
Validation loss: 2.1888906260331473

Epoch: 5| Step: 7
Training loss: 2.052128314971924
Validation loss: 2.2278584142525992

Epoch: 5| Step: 8
Training loss: 2.5771472454071045
Validation loss: 2.2106763074795404

Epoch: 5| Step: 9
Training loss: 2.317444086074829
Validation loss: 2.238946189483007

Epoch: 5| Step: 10
Training loss: 1.758954405784607
Validation loss: 2.2037950605154037

Epoch: 5| Step: 11
Training loss: 1.9798319339752197
Validation loss: 2.2147164841492972

Epoch: 15| Step: 0
Training loss: 1.8146053552627563
Validation loss: 2.2125270714362464

Epoch: 5| Step: 1
Training loss: 2.0566506385803223
Validation loss: 2.2024844139814377

Epoch: 5| Step: 2
Training loss: 2.1821770668029785
Validation loss: 2.1977409720420837

Epoch: 5| Step: 3
Training loss: 2.013636350631714
Validation loss: 2.2016684661308923

Epoch: 5| Step: 4
Training loss: 2.025926113128662
Validation loss: 2.188980594277382

Epoch: 5| Step: 5
Training loss: 2.1576850414276123
Validation loss: 2.2231674442688623

Epoch: 5| Step: 6
Training loss: 2.469212770462036
Validation loss: 2.1751892367998757

Epoch: 5| Step: 7
Training loss: 2.0387351512908936
Validation loss: 2.1997255086898804

Epoch: 5| Step: 8
Training loss: 2.364670753479004
Validation loss: 2.194074104229609

Epoch: 5| Step: 9
Training loss: 2.4076504707336426
Validation loss: 2.1842290510733924

Epoch: 5| Step: 10
Training loss: 1.8781760931015015
Validation loss: 2.1870501339435577

Epoch: 5| Step: 11
Training loss: 1.4411183595657349
Validation loss: 2.1874903440475464

Epoch: 16| Step: 0
Training loss: 2.573035717010498
Validation loss: 2.19620688756307

Epoch: 5| Step: 1
Training loss: 2.10211181640625
Validation loss: 2.1923828621705375

Epoch: 5| Step: 2
Training loss: 1.7968021631240845
Validation loss: 2.2103487253189087

Epoch: 5| Step: 3
Training loss: 2.159686326980591
Validation loss: 2.1656489421923957

Epoch: 5| Step: 4
Training loss: 2.2436678409576416
Validation loss: 2.212828685839971

Epoch: 5| Step: 5
Training loss: 1.6668663024902344
Validation loss: 2.1981013069550195

Epoch: 5| Step: 6
Training loss: 1.6573175191879272
Validation loss: 2.2023325165112815

Epoch: 5| Step: 7
Training loss: 2.3263254165649414
Validation loss: 2.193726524710655

Epoch: 5| Step: 8
Training loss: 1.678572416305542
Validation loss: 2.175842593113581

Epoch: 5| Step: 9
Training loss: 2.337735652923584
Validation loss: 2.145561228195826

Epoch: 5| Step: 10
Training loss: 2.6455345153808594
Validation loss: 2.155212789773941

Epoch: 5| Step: 11
Training loss: 1.506286382675171
Validation loss: 2.208820730447769

Epoch: 17| Step: 0
Training loss: 2.3993592262268066
Validation loss: 2.1806462754805884

Epoch: 5| Step: 1
Training loss: 1.6085898876190186
Validation loss: 2.155059407154719

Epoch: 5| Step: 2
Training loss: 1.834023118019104
Validation loss: 2.1703189412752786

Epoch: 5| Step: 3
Training loss: 2.3747048377990723
Validation loss: 2.1666557639837265

Epoch: 5| Step: 4
Training loss: 2.1820526123046875
Validation loss: 2.1689399778842926

Epoch: 5| Step: 5
Training loss: 1.7499357461929321
Validation loss: 2.1767466018597283

Epoch: 5| Step: 6
Training loss: 2.67425537109375
Validation loss: 2.1680827687184014

Epoch: 5| Step: 7
Training loss: 1.6601417064666748
Validation loss: 2.1547549913326898

Epoch: 5| Step: 8
Training loss: 1.690041184425354
Validation loss: 2.1605933705965676

Epoch: 5| Step: 9
Training loss: 2.4621803760528564
Validation loss: 2.1502515971660614

Epoch: 5| Step: 10
Training loss: 2.2391104698181152
Validation loss: 2.1490054378906884

Epoch: 5| Step: 11
Training loss: 1.792180061340332
Validation loss: 2.160357361038526

Epoch: 18| Step: 0
Training loss: 2.521221160888672
Validation loss: 2.1627177000045776

Epoch: 5| Step: 1
Training loss: 2.3178319931030273
Validation loss: 2.1711462885141373

Epoch: 5| Step: 2
Training loss: 1.9800316095352173
Validation loss: 2.1576349288225174

Epoch: 5| Step: 3
Training loss: 2.3984503746032715
Validation loss: 2.195323348045349

Epoch: 5| Step: 4
Training loss: 1.9201877117156982
Validation loss: 2.1335504949092865

Epoch: 5| Step: 5
Training loss: 1.2268558740615845
Validation loss: 2.1649729708830514

Epoch: 5| Step: 6
Training loss: 2.103332996368408
Validation loss: 2.1623626401027045

Epoch: 5| Step: 7
Training loss: 2.097724199295044
Validation loss: 2.1495003749926886

Epoch: 5| Step: 8
Training loss: 2.5384182929992676
Validation loss: 2.161165490746498

Epoch: 5| Step: 9
Training loss: 2.1815075874328613
Validation loss: 2.140054558714231

Epoch: 5| Step: 10
Training loss: 1.6216787099838257
Validation loss: 2.1525513579448066

Epoch: 5| Step: 11
Training loss: 2.157789707183838
Validation loss: 2.173060715198517

Epoch: 19| Step: 0
Training loss: 2.6220202445983887
Validation loss: 2.182145267724991

Epoch: 5| Step: 1
Training loss: 2.140746593475342
Validation loss: 2.1411574433247247

Epoch: 5| Step: 2
Training loss: 2.0248703956604004
Validation loss: 2.159648522734642

Epoch: 5| Step: 3
Training loss: 2.960175037384033
Validation loss: 2.146323800086975

Epoch: 5| Step: 4
Training loss: 1.1990503072738647
Validation loss: 2.16986154516538

Epoch: 5| Step: 5
Training loss: 2.021629810333252
Validation loss: 2.1706537107626596

Epoch: 5| Step: 6
Training loss: 1.9539668560028076
Validation loss: 2.131001611550649

Epoch: 5| Step: 7
Training loss: 2.844860076904297
Validation loss: 2.152232979734739

Epoch: 5| Step: 8
Training loss: 2.1285998821258545
Validation loss: 2.1697581311066947

Epoch: 5| Step: 9
Training loss: 1.5057367086410522
Validation loss: 2.1582812567551932

Epoch: 5| Step: 10
Training loss: 1.6479244232177734
Validation loss: 2.146082252264023

Epoch: 5| Step: 11
Training loss: 1.4425733089447021
Validation loss: 2.1384904434283576

Epoch: 20| Step: 0
Training loss: 2.2473347187042236
Validation loss: 2.153101126352946

Epoch: 5| Step: 1
Training loss: 1.845039963722229
Validation loss: 2.132211079200109

Epoch: 5| Step: 2
Training loss: 2.2530064582824707
Validation loss: 2.147180696328481

Epoch: 5| Step: 3
Training loss: 2.4878687858581543
Validation loss: 2.169963409503301

Epoch: 5| Step: 4
Training loss: 1.679221749305725
Validation loss: 2.1791961242755256

Epoch: 5| Step: 5
Training loss: 2.2974061965942383
Validation loss: 2.1608540068070092

Epoch: 5| Step: 6
Training loss: 2.3997437953948975
Validation loss: 2.1658002535502114

Epoch: 5| Step: 7
Training loss: 2.079345464706421
Validation loss: 2.166075587272644

Epoch: 5| Step: 8
Training loss: 2.365446090698242
Validation loss: 2.200727239251137

Epoch: 5| Step: 9
Training loss: 1.3322679996490479
Validation loss: 2.1821504880984626

Epoch: 5| Step: 10
Training loss: 2.140472888946533
Validation loss: 2.1587776293357215

Epoch: 5| Step: 11
Training loss: 1.1424006223678589
Validation loss: 2.170101394255956

Epoch: 21| Step: 0
Training loss: 2.547715187072754
Validation loss: 2.1388713320096335

Epoch: 5| Step: 1
Training loss: 2.579777956008911
Validation loss: 2.148215884963671

Epoch: 5| Step: 2
Training loss: 1.972562551498413
Validation loss: 2.147139847278595

Epoch: 5| Step: 3
Training loss: 1.9641739130020142
Validation loss: 2.160032312075297

Epoch: 5| Step: 4
Training loss: 1.9569742679595947
Validation loss: 2.156537036101023

Epoch: 5| Step: 5
Training loss: 1.9795650243759155
Validation loss: 2.1373145381609597

Epoch: 5| Step: 6
Training loss: 2.0284860134124756
Validation loss: 2.146584471066793

Epoch: 5| Step: 7
Training loss: 2.2124483585357666
Validation loss: 2.124996066093445

Epoch: 5| Step: 8
Training loss: 1.6844068765640259
Validation loss: 2.146661733587583

Epoch: 5| Step: 9
Training loss: 1.7104320526123047
Validation loss: 2.1394148667653403

Epoch: 5| Step: 10
Training loss: 1.8955323696136475
Validation loss: 2.145832896232605

Epoch: 5| Step: 11
Training loss: 2.3373985290527344
Validation loss: 2.1616382002830505

Epoch: 22| Step: 0
Training loss: 2.2911293506622314
Validation loss: 2.120357761780421

Epoch: 5| Step: 1
Training loss: 1.3590342998504639
Validation loss: 2.082377076148987

Epoch: 5| Step: 2
Training loss: 2.3442740440368652
Validation loss: 2.109891345103582

Epoch: 5| Step: 3
Training loss: 1.741990327835083
Validation loss: 2.165499289830526

Epoch: 5| Step: 4
Training loss: 1.8550660610198975
Validation loss: 2.1352942287921906

Epoch: 5| Step: 5
Training loss: 2.6083621978759766
Validation loss: 2.1284454564253488

Epoch: 5| Step: 6
Training loss: 1.7890961170196533
Validation loss: 2.1078944504261017

Epoch: 5| Step: 7
Training loss: 2.1896331310272217
Validation loss: 2.14788681268692

Epoch: 5| Step: 8
Training loss: 2.3692970275878906
Validation loss: 2.14884223540624

Epoch: 5| Step: 9
Training loss: 2.3446619510650635
Validation loss: 2.1398075918356576

Epoch: 5| Step: 10
Training loss: 1.6320469379425049
Validation loss: 2.1227419128020606

Epoch: 5| Step: 11
Training loss: 3.2470314502716064
Validation loss: 2.126955951253573

Epoch: 23| Step: 0
Training loss: 2.145388603210449
Validation loss: 2.1535154481728873

Epoch: 5| Step: 1
Training loss: 2.2282371520996094
Validation loss: 2.1469725916783013

Epoch: 5| Step: 2
Training loss: 2.2212440967559814
Validation loss: 2.122104858358701

Epoch: 5| Step: 3
Training loss: 2.0553722381591797
Validation loss: 2.124061261614164

Epoch: 5| Step: 4
Training loss: 2.018463134765625
Validation loss: 2.1029290854930878

Epoch: 5| Step: 5
Training loss: 2.10443377494812
Validation loss: 2.1547300070524216

Epoch: 5| Step: 6
Training loss: 1.7017513513565063
Validation loss: 2.129865432778994

Epoch: 5| Step: 7
Training loss: 2.387547492980957
Validation loss: 2.111976479490598

Epoch: 5| Step: 8
Training loss: 2.405611753463745
Validation loss: 2.1270994891723

Epoch: 5| Step: 9
Training loss: 1.6294918060302734
Validation loss: 2.1045519361893334

Epoch: 5| Step: 10
Training loss: 1.857813835144043
Validation loss: 2.126234402259191

Epoch: 5| Step: 11
Training loss: 1.8215503692626953
Validation loss: 2.112122724453608

Epoch: 24| Step: 0
Training loss: 1.7614103555679321
Validation loss: 2.150173455476761

Epoch: 5| Step: 1
Training loss: 2.826488733291626
Validation loss: 2.140078162153562

Epoch: 5| Step: 2
Training loss: 2.1982548236846924
Validation loss: 2.100624163945516

Epoch: 5| Step: 3
Training loss: 1.8746856451034546
Validation loss: 2.1139541616042457

Epoch: 5| Step: 4
Training loss: 2.056950092315674
Validation loss: 2.118767887353897

Epoch: 5| Step: 5
Training loss: 1.6841297149658203
Validation loss: 2.1422848453124366

Epoch: 5| Step: 6
Training loss: 1.9036391973495483
Validation loss: 2.1352955102920532

Epoch: 5| Step: 7
Training loss: 1.4944298267364502
Validation loss: 2.130361571907997

Epoch: 5| Step: 8
Training loss: 2.509143590927124
Validation loss: 2.1337918688853583

Epoch: 5| Step: 9
Training loss: 2.232145309448242
Validation loss: 2.1115792393684387

Epoch: 5| Step: 10
Training loss: 1.8614639043807983
Validation loss: 2.158698191245397

Epoch: 5| Step: 11
Training loss: 2.8591392040252686
Validation loss: 2.121079752842585

Epoch: 25| Step: 0
Training loss: 2.616893768310547
Validation loss: 2.120043640335401

Epoch: 5| Step: 1
Training loss: 1.7631534337997437
Validation loss: 2.111159776647886

Epoch: 5| Step: 2
Training loss: 2.685454845428467
Validation loss: 2.1313321391741433

Epoch: 5| Step: 3
Training loss: 2.1831214427948
Validation loss: 2.1092892636855445

Epoch: 5| Step: 4
Training loss: 1.4889699220657349
Validation loss: 2.177691568930944

Epoch: 5| Step: 5
Training loss: 1.842896819114685
Validation loss: 2.16214328010877

Epoch: 5| Step: 6
Training loss: 2.3564956188201904
Validation loss: 2.1443236072858176

Epoch: 5| Step: 7
Training loss: 2.178666591644287
Validation loss: 2.1481029043594995

Epoch: 5| Step: 8
Training loss: 2.205439567565918
Validation loss: 2.0911744783322015

Epoch: 5| Step: 9
Training loss: 1.4894956350326538
Validation loss: 2.1565368423859277

Epoch: 5| Step: 10
Training loss: 2.0276706218719482
Validation loss: 2.116208071509997

Epoch: 5| Step: 11
Training loss: 1.560613751411438
Validation loss: 2.1418714871009192

Epoch: 26| Step: 0
Training loss: 1.8171279430389404
Validation loss: 2.1082725723584494

Epoch: 5| Step: 1
Training loss: 1.7292726039886475
Validation loss: 2.1563721001148224

Epoch: 5| Step: 2
Training loss: 1.873535394668579
Validation loss: 2.145677919189135

Epoch: 5| Step: 3
Training loss: 2.0793700218200684
Validation loss: 2.122436140974363

Epoch: 5| Step: 4
Training loss: 1.8491472005844116
Validation loss: 2.1276480158170066

Epoch: 5| Step: 5
Training loss: 2.3066468238830566
Validation loss: 2.1241358617941537

Epoch: 5| Step: 6
Training loss: 2.7064530849456787
Validation loss: 2.132776295145353

Epoch: 5| Step: 7
Training loss: 1.7990003824234009
Validation loss: 2.1178111086289086

Epoch: 5| Step: 8
Training loss: 2.6255290508270264
Validation loss: 2.123058175047239

Epoch: 5| Step: 9
Training loss: 1.792715311050415
Validation loss: 2.1414667268594108

Epoch: 5| Step: 10
Training loss: 1.8663250207901
Validation loss: 2.1255682508150735

Epoch: 5| Step: 11
Training loss: 2.275503396987915
Validation loss: 2.1126381158828735

Epoch: 27| Step: 0
Training loss: 2.0913679599761963
Validation loss: 2.1132724632819495

Epoch: 5| Step: 1
Training loss: 1.6504653692245483
Validation loss: 2.121880571047465

Epoch: 5| Step: 2
Training loss: 1.7540462017059326
Validation loss: 2.1605218251546225

Epoch: 5| Step: 3
Training loss: 2.428593397140503
Validation loss: 2.108233024676641

Epoch: 5| Step: 4
Training loss: 1.96926748752594
Validation loss: 2.1229945371548333

Epoch: 5| Step: 5
Training loss: 2.018118381500244
Validation loss: 2.1243332078059516

Epoch: 5| Step: 6
Training loss: 2.5063045024871826
Validation loss: 2.12569789091746

Epoch: 5| Step: 7
Training loss: 2.6234307289123535
Validation loss: 2.131157174706459

Epoch: 5| Step: 8
Training loss: 2.4351885318756104
Validation loss: 2.1018198132514954

Epoch: 5| Step: 9
Training loss: 1.6774747371673584
Validation loss: 2.1333841582139335

Epoch: 5| Step: 10
Training loss: 1.5825376510620117
Validation loss: 2.150426909327507

Epoch: 5| Step: 11
Training loss: 1.4066160917282104
Validation loss: 2.1203552732865014

Epoch: 28| Step: 0
Training loss: 2.6694350242614746
Validation loss: 2.123958150545756

Epoch: 5| Step: 1
Training loss: 2.318538188934326
Validation loss: 2.1261711418628693

Epoch: 5| Step: 2
Training loss: 2.3557846546173096
Validation loss: 2.1100359559059143

Epoch: 5| Step: 3
Training loss: 2.21468448638916
Validation loss: 2.1385392447312674

Epoch: 5| Step: 4
Training loss: 1.1353501081466675
Validation loss: 2.1057605048020682

Epoch: 5| Step: 5
Training loss: 1.437746286392212
Validation loss: 2.1159362296263375

Epoch: 5| Step: 6
Training loss: 2.2617268562316895
Validation loss: 2.109854464729627

Epoch: 5| Step: 7
Training loss: 1.7511835098266602
Validation loss: 2.126862198114395

Epoch: 5| Step: 8
Training loss: 1.5181660652160645
Validation loss: 2.1013741542895636

Epoch: 5| Step: 9
Training loss: 2.2829537391662598
Validation loss: 2.101522922515869

Epoch: 5| Step: 10
Training loss: 2.3012118339538574
Validation loss: 2.1209488213062286

Epoch: 5| Step: 11
Training loss: 2.0739054679870605
Validation loss: 2.1122923741738

Epoch: 29| Step: 0
Training loss: 2.190610408782959
Validation loss: 2.1193267156680426

Epoch: 5| Step: 1
Training loss: 2.1833298206329346
Validation loss: 2.1273329059282937

Epoch: 5| Step: 2
Training loss: 2.1003053188323975
Validation loss: 2.113101859887441

Epoch: 5| Step: 3
Training loss: 2.12691330909729
Validation loss: 2.125074411431948

Epoch: 5| Step: 4
Training loss: 2.4010629653930664
Validation loss: 2.117334693670273

Epoch: 5| Step: 5
Training loss: 2.064408779144287
Validation loss: 2.122200275460879

Epoch: 5| Step: 6
Training loss: 2.2375435829162598
Validation loss: 2.1532437006632485

Epoch: 5| Step: 7
Training loss: 1.6326195001602173
Validation loss: 2.1345546593268714

Epoch: 5| Step: 8
Training loss: 1.5834705829620361
Validation loss: 2.1560647090276084

Epoch: 5| Step: 9
Training loss: 2.050041675567627
Validation loss: 2.121556560198466

Epoch: 5| Step: 10
Training loss: 1.963191270828247
Validation loss: 2.1000590523084006

Epoch: 5| Step: 11
Training loss: 1.2769782543182373
Validation loss: 2.1014620264371238

Epoch: 30| Step: 0
Training loss: 2.1758530139923096
Validation loss: 2.101876730720202

Epoch: 5| Step: 1
Training loss: 1.893629789352417
Validation loss: 2.08754034837087

Epoch: 5| Step: 2
Training loss: 2.451754093170166
Validation loss: 2.1043092062075934

Epoch: 5| Step: 3
Training loss: 1.8866300582885742
Validation loss: 2.108300507068634

Epoch: 5| Step: 4
Training loss: 2.3838050365448
Validation loss: 2.090226878722509

Epoch: 5| Step: 5
Training loss: 1.6113879680633545
Validation loss: 2.095118040839831

Epoch: 5| Step: 6
Training loss: 1.8035300970077515
Validation loss: 2.1169058134158454

Epoch: 5| Step: 7
Training loss: 2.4143433570861816
Validation loss: 2.131179084380468

Epoch: 5| Step: 8
Training loss: 1.5347641706466675
Validation loss: 2.140822703639666

Epoch: 5| Step: 9
Training loss: 1.7530990839004517
Validation loss: 2.1175113916397095

Epoch: 5| Step: 10
Training loss: 2.5229713916778564
Validation loss: 2.111495484908422

Epoch: 5| Step: 11
Training loss: 1.9140266180038452
Validation loss: 2.1070239543914795

Epoch: 31| Step: 0
Training loss: 2.088534116744995
Validation loss: 2.1112383902072906

Epoch: 5| Step: 1
Training loss: 2.413616418838501
Validation loss: 2.0921257734298706

Epoch: 5| Step: 2
Training loss: 2.3390650749206543
Validation loss: 2.116541340947151

Epoch: 5| Step: 3
Training loss: 1.944393515586853
Validation loss: 2.098088428378105

Epoch: 5| Step: 4
Training loss: 2.145052194595337
Validation loss: 2.134908194343249

Epoch: 5| Step: 5
Training loss: 1.7493091821670532
Validation loss: 2.1525745342175164

Epoch: 5| Step: 6
Training loss: 1.8775520324707031
Validation loss: 2.100420837601026

Epoch: 5| Step: 7
Training loss: 1.5714952945709229
Validation loss: 2.0965302089850106

Epoch: 5| Step: 8
Training loss: 1.8842365741729736
Validation loss: 2.116523673137029

Epoch: 5| Step: 9
Training loss: 2.230553388595581
Validation loss: 2.117940460642179

Epoch: 5| Step: 10
Training loss: 2.093703031539917
Validation loss: 2.108996411164602

Epoch: 5| Step: 11
Training loss: 2.082181453704834
Validation loss: 2.100299894809723

Epoch: 32| Step: 0
Training loss: 2.287576198577881
Validation loss: 2.1457276344299316

Epoch: 5| Step: 1
Training loss: 1.5449517965316772
Validation loss: 2.1236989349126816

Epoch: 5| Step: 2
Training loss: 2.3842976093292236
Validation loss: 2.108506456017494

Epoch: 5| Step: 3
Training loss: 2.3040337562561035
Validation loss: 2.1370514134565988

Epoch: 5| Step: 4
Training loss: 1.6528055667877197
Validation loss: 2.10791669289271

Epoch: 5| Step: 5
Training loss: 2.3226776123046875
Validation loss: 2.1359466711680093

Epoch: 5| Step: 6
Training loss: 1.8846852779388428
Validation loss: 2.1450207034746804

Epoch: 5| Step: 7
Training loss: 2.110067129135132
Validation loss: 2.1348999390999475

Epoch: 5| Step: 8
Training loss: 1.2935521602630615
Validation loss: 2.110902006427447

Epoch: 5| Step: 9
Training loss: 1.9993594884872437
Validation loss: 2.115039353569349

Epoch: 5| Step: 10
Training loss: 2.0022709369659424
Validation loss: 2.09838197628657

Epoch: 5| Step: 11
Training loss: 3.4529099464416504
Validation loss: 2.080944910645485

Epoch: 33| Step: 0
Training loss: 2.464475393295288
Validation loss: 2.0983309845129647

Epoch: 5| Step: 1
Training loss: 1.5241787433624268
Validation loss: 2.1068389614423118

Epoch: 5| Step: 2
Training loss: 2.548206090927124
Validation loss: 2.11963282028834

Epoch: 5| Step: 3
Training loss: 2.4706978797912598
Validation loss: 2.1401586482922235

Epoch: 5| Step: 4
Training loss: 1.7907871007919312
Validation loss: 2.0972106059392295

Epoch: 5| Step: 5
Training loss: 1.5361320972442627
Validation loss: 2.1289605448643365

Epoch: 5| Step: 6
Training loss: 2.36665940284729
Validation loss: 2.127846449613571

Epoch: 5| Step: 7
Training loss: 2.0420708656311035
Validation loss: 2.1522073298692703

Epoch: 5| Step: 8
Training loss: 1.358280897140503
Validation loss: 2.1028543512026467

Epoch: 5| Step: 9
Training loss: 1.6974983215332031
Validation loss: 2.0983529090881348

Epoch: 5| Step: 10
Training loss: 2.397801399230957
Validation loss: 2.098607321580251

Epoch: 5| Step: 11
Training loss: 2.087164878845215
Validation loss: 2.0972264210383096

Epoch: 34| Step: 0
Training loss: 2.3488147258758545
Validation loss: 2.102434034148852

Epoch: 5| Step: 1
Training loss: 1.7436788082122803
Validation loss: 2.1159280290206275

Epoch: 5| Step: 2
Training loss: 2.59580659866333
Validation loss: 2.0862357765436172

Epoch: 5| Step: 3
Training loss: 1.6287342309951782
Validation loss: 2.1326387375593185

Epoch: 5| Step: 4
Training loss: 2.2332465648651123
Validation loss: 2.1101562728484473

Epoch: 5| Step: 5
Training loss: 2.5415546894073486
Validation loss: 2.093881552418073

Epoch: 5| Step: 6
Training loss: 2.2679054737091064
Validation loss: 2.1167133450508118

Epoch: 5| Step: 7
Training loss: 1.6202595233917236
Validation loss: 2.0916418780883155

Epoch: 5| Step: 8
Training loss: 1.503833532333374
Validation loss: 2.089729825655619

Epoch: 5| Step: 9
Training loss: 2.001070499420166
Validation loss: 2.087110002835592

Epoch: 5| Step: 10
Training loss: 1.5029290914535522
Validation loss: 2.0796171128749847

Epoch: 5| Step: 11
Training loss: 2.7414069175720215
Validation loss: 2.0915422489245734

Epoch: 35| Step: 0
Training loss: 1.4982661008834839
Validation loss: 2.115638459722201

Epoch: 5| Step: 1
Training loss: 2.0625057220458984
Validation loss: 2.1295617868502936

Epoch: 5| Step: 2
Training loss: 1.8934091329574585
Validation loss: 2.0833480209112167

Epoch: 5| Step: 3
Training loss: 1.8996728658676147
Validation loss: 2.1113835871219635

Epoch: 5| Step: 4
Training loss: 1.8927924633026123
Validation loss: 2.112472260991732

Epoch: 5| Step: 5
Training loss: 2.0268054008483887
Validation loss: 2.0864202777544656

Epoch: 5| Step: 6
Training loss: 2.082479953765869
Validation loss: 2.1011542131503425

Epoch: 5| Step: 7
Training loss: 2.290102481842041
Validation loss: 2.098037595550219

Epoch: 5| Step: 8
Training loss: 2.3728628158569336
Validation loss: 2.1106809775034585

Epoch: 5| Step: 9
Training loss: 2.3127713203430176
Validation loss: 2.10657391945521

Epoch: 5| Step: 10
Training loss: 2.059183120727539
Validation loss: 2.1222494145234427

Epoch: 5| Step: 11
Training loss: 1.3200256824493408
Validation loss: 2.1079119791587195

Epoch: 36| Step: 0
Training loss: 2.0323219299316406
Validation loss: 2.1237528572479882

Epoch: 5| Step: 1
Training loss: 1.6231584548950195
Validation loss: 2.1178964922825494

Epoch: 5| Step: 2
Training loss: 2.167985439300537
Validation loss: 2.1271226704120636

Epoch: 5| Step: 3
Training loss: 2.2052788734436035
Validation loss: 2.1066608478625617

Epoch: 5| Step: 4
Training loss: 1.8488057851791382
Validation loss: 2.1532803078492484

Epoch: 5| Step: 5
Training loss: 2.561022996902466
Validation loss: 2.180884545048078

Epoch: 5| Step: 6
Training loss: 1.6221818923950195
Validation loss: 2.1425660898288093

Epoch: 5| Step: 7
Training loss: 2.0180466175079346
Validation loss: 2.0945362001657486

Epoch: 5| Step: 8
Training loss: 2.411790370941162
Validation loss: 2.1289072583119073

Epoch: 5| Step: 9
Training loss: 2.3031904697418213
Validation loss: 2.1436277429262796

Epoch: 5| Step: 10
Training loss: 1.6488968133926392
Validation loss: 2.101548060774803

Epoch: 5| Step: 11
Training loss: 0.4306715130805969
Validation loss: 2.096845974524816

Epoch: 37| Step: 0
Training loss: 1.621341347694397
Validation loss: 2.0682915300130844

Epoch: 5| Step: 1
Training loss: 2.4463515281677246
Validation loss: 2.1194842557112374

Epoch: 5| Step: 2
Training loss: 2.1671714782714844
Validation loss: 2.0698019762833915

Epoch: 5| Step: 3
Training loss: 2.0229263305664062
Validation loss: 2.0690852055946984

Epoch: 5| Step: 4
Training loss: 2.0149872303009033
Validation loss: 2.0552978962659836

Epoch: 5| Step: 5
Training loss: 2.1231532096862793
Validation loss: 2.116084838906924

Epoch: 5| Step: 6
Training loss: 1.9299333095550537
Validation loss: 2.073176542917887

Epoch: 5| Step: 7
Training loss: 1.9460785388946533
Validation loss: 2.092892492810885

Epoch: 5| Step: 8
Training loss: 2.4636948108673096
Validation loss: 2.114926556746165

Epoch: 5| Step: 9
Training loss: 1.844561219215393
Validation loss: 2.0919387290875116

Epoch: 5| Step: 10
Training loss: 1.9552640914916992
Validation loss: 2.0728283673524857

Epoch: 5| Step: 11
Training loss: 0.9861456751823425
Validation loss: 2.1133183191219964

Epoch: 38| Step: 0
Training loss: 2.0837621688842773
Validation loss: 2.112734337647756

Epoch: 5| Step: 1
Training loss: 2.269838333129883
Validation loss: 2.077281415462494

Epoch: 5| Step: 2
Training loss: 2.1907272338867188
Validation loss: 2.0816769848267236

Epoch: 5| Step: 3
Training loss: 2.21882963180542
Validation loss: 2.1044489641984305

Epoch: 5| Step: 4
Training loss: 2.1507256031036377
Validation loss: 2.089707205692927

Epoch: 5| Step: 5
Training loss: 1.3767763376235962
Validation loss: 2.100028778115908

Epoch: 5| Step: 6
Training loss: 1.9508192539215088
Validation loss: 2.1046308130025864

Epoch: 5| Step: 7
Training loss: 2.227170705795288
Validation loss: 2.1136097262303033

Epoch: 5| Step: 8
Training loss: 1.9207576513290405
Validation loss: 2.124020283420881

Epoch: 5| Step: 9
Training loss: 2.1615941524505615
Validation loss: 2.1208480149507523

Epoch: 5| Step: 10
Training loss: 1.9207313060760498
Validation loss: 2.1117437879244485

Epoch: 5| Step: 11
Training loss: 2.4578633308410645
Validation loss: 2.119003822406133

Epoch: 39| Step: 0
Training loss: 2.27876615524292
Validation loss: 2.0925988803307214

Epoch: 5| Step: 1
Training loss: 2.176431894302368
Validation loss: 2.0986723800500235

Epoch: 5| Step: 2
Training loss: 1.872031569480896
Validation loss: 2.095613976319631

Epoch: 5| Step: 3
Training loss: 2.1307315826416016
Validation loss: 2.119395077228546

Epoch: 5| Step: 4
Training loss: 1.6926456689834595
Validation loss: 2.121661384900411

Epoch: 5| Step: 5
Training loss: 1.5560252666473389
Validation loss: 2.081398665904999

Epoch: 5| Step: 6
Training loss: 2.207202434539795
Validation loss: 2.1126752148071923

Epoch: 5| Step: 7
Training loss: 1.8665220737457275
Validation loss: 2.0798458258310952

Epoch: 5| Step: 8
Training loss: 1.996368646621704
Validation loss: 2.1185958286126456

Epoch: 5| Step: 9
Training loss: 2.0672457218170166
Validation loss: 2.065641979376475

Epoch: 5| Step: 10
Training loss: 2.521307945251465
Validation loss: 2.0933031489451728

Epoch: 5| Step: 11
Training loss: 1.5645123720169067
Validation loss: 2.125891779859861

Epoch: 40| Step: 0
Training loss: 1.6250536441802979
Validation loss: 2.1039510866006217

Epoch: 5| Step: 1
Training loss: 1.9178617000579834
Validation loss: 2.0907269567251205

Epoch: 5| Step: 2
Training loss: 2.361896514892578
Validation loss: 2.075269937515259

Epoch: 5| Step: 3
Training loss: 1.9360897541046143
Validation loss: 2.1131207893292108

Epoch: 5| Step: 4
Training loss: 2.5291011333465576
Validation loss: 2.109463627139727

Epoch: 5| Step: 5
Training loss: 1.66274893283844
Validation loss: 2.131792366504669

Epoch: 5| Step: 6
Training loss: 1.7737972736358643
Validation loss: 2.0872337967157364

Epoch: 5| Step: 7
Training loss: 1.7248176336288452
Validation loss: 2.094604184230169

Epoch: 5| Step: 8
Training loss: 2.1327157020568848
Validation loss: 2.097961818178495

Epoch: 5| Step: 9
Training loss: 2.384711742401123
Validation loss: 2.0920681754748025

Epoch: 5| Step: 10
Training loss: 1.931073784828186
Validation loss: 2.0989593664805093

Epoch: 5| Step: 11
Training loss: 2.8868205547332764
Validation loss: 2.0878467758496604

Epoch: 41| Step: 0
Training loss: 2.1812894344329834
Validation loss: 2.104569971561432

Epoch: 5| Step: 1
Training loss: 1.4776549339294434
Validation loss: 2.113743637998899

Epoch: 5| Step: 2
Training loss: 3.0043106079101562
Validation loss: 2.085740958650907

Epoch: 5| Step: 3
Training loss: 1.9869188070297241
Validation loss: 2.098628188172976

Epoch: 5| Step: 4
Training loss: 1.722312569618225
Validation loss: 2.112700934211413

Epoch: 5| Step: 5
Training loss: 1.2662557363510132
Validation loss: 2.141006261110306

Epoch: 5| Step: 6
Training loss: 2.168135166168213
Validation loss: 2.095323234796524

Epoch: 5| Step: 7
Training loss: 1.9023504257202148
Validation loss: 2.1128471245368323

Epoch: 5| Step: 8
Training loss: 2.338513135910034
Validation loss: 2.076720585425695

Epoch: 5| Step: 9
Training loss: 1.5144929885864258
Validation loss: 2.0996853758891425

Epoch: 5| Step: 10
Training loss: 2.6127407550811768
Validation loss: 2.0834870437781015

Epoch: 5| Step: 11
Training loss: 1.3904426097869873
Validation loss: 2.093505303064982

Epoch: 42| Step: 0
Training loss: 1.8038257360458374
Validation loss: 2.1487354834874473

Epoch: 5| Step: 1
Training loss: 1.9581104516983032
Validation loss: 2.1039328277111053

Epoch: 5| Step: 2
Training loss: 1.9356534481048584
Validation loss: 2.14883291721344

Epoch: 5| Step: 3
Training loss: 1.7592369318008423
Validation loss: 2.117981493473053

Epoch: 5| Step: 4
Training loss: 2.1382927894592285
Validation loss: 2.1021868288517

Epoch: 5| Step: 5
Training loss: 1.842442512512207
Validation loss: 2.177856206893921

Epoch: 5| Step: 6
Training loss: 2.112520694732666
Validation loss: 2.1126299699147544

Epoch: 5| Step: 7
Training loss: 2.444488048553467
Validation loss: 2.140595411260923

Epoch: 5| Step: 8
Training loss: 2.2313461303710938
Validation loss: 2.122373044490814

Epoch: 5| Step: 9
Training loss: 2.234123706817627
Validation loss: 2.1262806554635367

Epoch: 5| Step: 10
Training loss: 2.0781731605529785
Validation loss: 2.1421203960975013

Epoch: 5| Step: 11
Training loss: 0.8412895202636719
Validation loss: 2.0902480681737265

Epoch: 43| Step: 0
Training loss: 1.9313795566558838
Validation loss: 2.138923426469167

Epoch: 5| Step: 1
Training loss: 1.6277214288711548
Validation loss: 2.106465737024943

Epoch: 5| Step: 2
Training loss: 2.464916229248047
Validation loss: 2.11871337890625

Epoch: 5| Step: 3
Training loss: 1.8955962657928467
Validation loss: 2.137332503994306

Epoch: 5| Step: 4
Training loss: 2.08436918258667
Validation loss: 2.122376948595047

Epoch: 5| Step: 5
Training loss: 2.265381336212158
Validation loss: 2.0834703346093497

Epoch: 5| Step: 6
Training loss: 1.9159513711929321
Validation loss: 2.109520216782888

Epoch: 5| Step: 7
Training loss: 2.406402587890625
Validation loss: 2.125085865457853

Epoch: 5| Step: 8
Training loss: 1.9311443567276
Validation loss: 2.0937006821235022

Epoch: 5| Step: 9
Training loss: 2.0854249000549316
Validation loss: 2.0853015830119452

Epoch: 5| Step: 10
Training loss: 1.9254239797592163
Validation loss: 2.097589756051699

Epoch: 5| Step: 11
Training loss: 2.026038646697998
Validation loss: 2.07109896838665

Epoch: 44| Step: 0
Training loss: 2.330186605453491
Validation loss: 2.0823474675416946

Epoch: 5| Step: 1
Training loss: 2.338975191116333
Validation loss: 2.077473908662796

Epoch: 5| Step: 2
Training loss: 1.6427829265594482
Validation loss: 2.0716358174880347

Epoch: 5| Step: 3
Training loss: 2.608724594116211
Validation loss: 2.053185989459356

Epoch: 5| Step: 4
Training loss: 1.7385610342025757
Validation loss: 2.062316214044889

Epoch: 5| Step: 5
Training loss: 2.031259775161743
Validation loss: 2.0956988086303077

Epoch: 5| Step: 6
Training loss: 1.708247423171997
Validation loss: 2.0985239247481027

Epoch: 5| Step: 7
Training loss: 1.925868272781372
Validation loss: 2.08778016269207

Epoch: 5| Step: 8
Training loss: 2.012575149536133
Validation loss: 2.096449767549833

Epoch: 5| Step: 9
Training loss: 1.7696895599365234
Validation loss: 2.106047203143438

Epoch: 5| Step: 10
Training loss: 1.824162244796753
Validation loss: 2.1076535085837045

Epoch: 5| Step: 11
Training loss: 2.3885927200317383
Validation loss: 2.097581466039022

Epoch: 45| Step: 0
Training loss: 2.4231345653533936
Validation loss: 2.099779705206553

Epoch: 5| Step: 1
Training loss: 1.6510074138641357
Validation loss: 2.1251760125160217

Epoch: 5| Step: 2
Training loss: 1.9702069759368896
Validation loss: 2.0764470199743905

Epoch: 5| Step: 3
Training loss: 1.959323525428772
Validation loss: 2.0790825684865317

Epoch: 5| Step: 4
Training loss: 1.3672311305999756
Validation loss: 2.1014430075883865

Epoch: 5| Step: 5
Training loss: 2.7395236492156982
Validation loss: 2.0810286104679108

Epoch: 5| Step: 6
Training loss: 2.0031685829162598
Validation loss: 2.1095877836147943

Epoch: 5| Step: 7
Training loss: 2.026158571243286
Validation loss: 2.097296416759491

Epoch: 5| Step: 8
Training loss: 2.0733718872070312
Validation loss: 2.105617344379425

Epoch: 5| Step: 9
Training loss: 1.8954181671142578
Validation loss: 2.1069161792596183

Epoch: 5| Step: 10
Training loss: 1.9243923425674438
Validation loss: 2.092945764462153

Epoch: 5| Step: 11
Training loss: 1.675036072731018
Validation loss: 2.104430466890335

Epoch: 46| Step: 0
Training loss: 2.227355480194092
Validation loss: 2.0993429919083915

Epoch: 5| Step: 1
Training loss: 1.5060937404632568
Validation loss: 2.1266303658485413

Epoch: 5| Step: 2
Training loss: 2.3810408115386963
Validation loss: 2.1068746000528336

Epoch: 5| Step: 3
Training loss: 2.179637908935547
Validation loss: 2.1164462019999823

Epoch: 5| Step: 4
Training loss: 2.306037664413452
Validation loss: 2.103534445166588

Epoch: 5| Step: 5
Training loss: 1.5706380605697632
Validation loss: 2.103820631901423

Epoch: 5| Step: 6
Training loss: 1.6639865636825562
Validation loss: 2.1316838562488556

Epoch: 5| Step: 7
Training loss: 2.299222707748413
Validation loss: 2.0786419808864594

Epoch: 5| Step: 8
Training loss: 2.366162061691284
Validation loss: 2.1145628839731216

Epoch: 5| Step: 9
Training loss: 1.6779234409332275
Validation loss: 2.1032796601454415

Epoch: 5| Step: 10
Training loss: 1.6786311864852905
Validation loss: 2.114037369688352

Epoch: 5| Step: 11
Training loss: 2.6905012130737305
Validation loss: 2.0777794470389686

Epoch: 47| Step: 0
Training loss: 1.708409070968628
Validation loss: 2.082076479991277

Epoch: 5| Step: 1
Training loss: 1.8539235591888428
Validation loss: 2.092362845937411

Epoch: 5| Step: 2
Training loss: 2.5252976417541504
Validation loss: 2.0685542076826096

Epoch: 5| Step: 3
Training loss: 1.7572977542877197
Validation loss: 2.0939778784910836

Epoch: 5| Step: 4
Training loss: 2.3196754455566406
Validation loss: 2.0858031113942466

Epoch: 5| Step: 5
Training loss: 1.3196115493774414
Validation loss: 2.0971201062202454

Epoch: 5| Step: 6
Training loss: 1.8159511089324951
Validation loss: 2.0774622758229575

Epoch: 5| Step: 7
Training loss: 2.445831298828125
Validation loss: 2.1066468755404153

Epoch: 5| Step: 8
Training loss: 1.906869649887085
Validation loss: 2.097761864463488

Epoch: 5| Step: 9
Training loss: 1.7924836874008179
Validation loss: 2.1016390174627304

Epoch: 5| Step: 10
Training loss: 2.525695562362671
Validation loss: 2.09930249551932

Epoch: 5| Step: 11
Training loss: 1.5349576473236084
Validation loss: 2.0650804936885834

Epoch: 48| Step: 0
Training loss: 1.6861177682876587
Validation loss: 2.122440665960312

Epoch: 5| Step: 1
Training loss: 2.1207525730133057
Validation loss: 2.0772853245337806

Epoch: 5| Step: 2
Training loss: 2.1339111328125
Validation loss: 2.0750160912672677

Epoch: 5| Step: 3
Training loss: 2.389876127243042
Validation loss: 2.116485685110092

Epoch: 5| Step: 4
Training loss: 2.3809916973114014
Validation loss: 2.0951724698146186

Epoch: 5| Step: 5
Training loss: 2.231647253036499
Validation loss: 2.1022639820973077

Epoch: 5| Step: 6
Training loss: 2.5511574745178223
Validation loss: 2.105621501803398

Epoch: 5| Step: 7
Training loss: 1.482583999633789
Validation loss: 2.0900351653496423

Epoch: 5| Step: 8
Training loss: 2.0614542961120605
Validation loss: 2.0745141754547753

Epoch: 5| Step: 9
Training loss: 1.8191293478012085
Validation loss: 2.068566088875135

Epoch: 5| Step: 10
Training loss: 1.2112921476364136
Validation loss: 2.1030681480964026

Epoch: 5| Step: 11
Training loss: 1.4761414527893066
Validation loss: 2.0890434632698693

Epoch: 49| Step: 0
Training loss: 1.9384441375732422
Validation loss: 2.0934717257817588

Epoch: 5| Step: 1
Training loss: 2.0798206329345703
Validation loss: 2.0893408755461373

Epoch: 5| Step: 2
Training loss: 1.5523746013641357
Validation loss: 2.0841602881749473

Epoch: 5| Step: 3
Training loss: 2.0254058837890625
Validation loss: 2.1086233456929526

Epoch: 5| Step: 4
Training loss: 1.6259410381317139
Validation loss: 2.1115494767824807

Epoch: 5| Step: 5
Training loss: 2.2253215312957764
Validation loss: 2.102678264180819

Epoch: 5| Step: 6
Training loss: 2.4979162216186523
Validation loss: 2.171552896499634

Epoch: 5| Step: 7
Training loss: 2.1843624114990234
Validation loss: 2.107125307122866

Epoch: 5| Step: 8
Training loss: 2.3171238899230957
Validation loss: 2.112858459353447

Epoch: 5| Step: 9
Training loss: 2.0114147663116455
Validation loss: 2.14856385687987

Epoch: 5| Step: 10
Training loss: 1.4831334352493286
Validation loss: 2.0994766106208167

Epoch: 5| Step: 11
Training loss: 1.7898130416870117
Validation loss: 2.124429980913798

Epoch: 50| Step: 0
Training loss: 1.488795280456543
Validation loss: 2.1318523238102594

Epoch: 5| Step: 1
Training loss: 2.5108838081359863
Validation loss: 2.0611334492762885

Epoch: 5| Step: 2
Training loss: 1.9065046310424805
Validation loss: 2.0977231760819754

Epoch: 5| Step: 3
Training loss: 1.7267566919326782
Validation loss: 2.104036102692286

Epoch: 5| Step: 4
Training loss: 1.9604442119598389
Validation loss: 2.0732456694046655

Epoch: 5| Step: 5
Training loss: 1.9142690896987915
Validation loss: 2.1132048616806665

Epoch: 5| Step: 6
Training loss: 1.6099321842193604
Validation loss: 2.0942508528629937

Epoch: 5| Step: 7
Training loss: 2.2927374839782715
Validation loss: 2.1152387658754983

Epoch: 5| Step: 8
Training loss: 1.9530308246612549
Validation loss: 2.1002479245265326

Epoch: 5| Step: 9
Training loss: 1.679947853088379
Validation loss: 2.1179578403631845

Epoch: 5| Step: 10
Training loss: 2.7307040691375732
Validation loss: 2.1388199478387833

Epoch: 5| Step: 11
Training loss: 3.100839138031006
Validation loss: 2.113939662774404

Epoch: 51| Step: 0
Training loss: 1.6327568292617798
Validation loss: 2.0992645919322968

Epoch: 5| Step: 1
Training loss: 2.517233371734619
Validation loss: 2.111446628967921

Epoch: 5| Step: 2
Training loss: 2.091620683670044
Validation loss: 2.0895167092482247

Epoch: 5| Step: 3
Training loss: 2.126826763153076
Validation loss: 2.1306802928447723

Epoch: 5| Step: 4
Training loss: 1.366299033164978
Validation loss: 2.115569661060969

Epoch: 5| Step: 5
Training loss: 1.9694645404815674
Validation loss: 2.07621431350708

Epoch: 5| Step: 6
Training loss: 2.1279664039611816
Validation loss: 2.0884754955768585

Epoch: 5| Step: 7
Training loss: 1.7179762125015259
Validation loss: 2.116765543818474

Epoch: 5| Step: 8
Training loss: 1.974027395248413
Validation loss: 2.0628797759612403

Epoch: 5| Step: 9
Training loss: 1.6879806518554688
Validation loss: 2.090801631410917

Epoch: 5| Step: 10
Training loss: 2.6582186222076416
Validation loss: 2.079437846938769

Epoch: 5| Step: 11
Training loss: 1.6654260158538818
Validation loss: 2.1046948234240213

Epoch: 52| Step: 0
Training loss: 1.9886407852172852
Validation loss: 2.057408705353737

Epoch: 5| Step: 1
Training loss: 2.1531636714935303
Validation loss: 2.08872759838899

Epoch: 5| Step: 2
Training loss: 2.8453502655029297
Validation loss: 2.10136815905571

Epoch: 5| Step: 3
Training loss: 1.2296890020370483
Validation loss: 2.1086968779563904

Epoch: 5| Step: 4
Training loss: 1.9464422464370728
Validation loss: 2.128221939007441

Epoch: 5| Step: 5
Training loss: 2.2903594970703125
Validation loss: 2.138475015759468

Epoch: 5| Step: 6
Training loss: 1.9400851726531982
Validation loss: 2.147712618112564

Epoch: 5| Step: 7
Training loss: 2.134765386581421
Validation loss: 2.1389484852552414

Epoch: 5| Step: 8
Training loss: 2.002774953842163
Validation loss: 2.1752006113529205

Epoch: 5| Step: 9
Training loss: 1.4287673234939575
Validation loss: 2.1484205226103463

Epoch: 5| Step: 10
Training loss: 2.6984105110168457
Validation loss: 2.1616694182157516

Epoch: 5| Step: 11
Training loss: 1.8359999656677246
Validation loss: 2.1073398292064667

Epoch: 53| Step: 0
Training loss: 1.8816330432891846
Validation loss: 2.081174219648043

Epoch: 5| Step: 1
Training loss: 1.9180784225463867
Validation loss: 2.1067731380462646

Epoch: 5| Step: 2
Training loss: 1.7183736562728882
Validation loss: 2.12078133225441

Epoch: 5| Step: 3
Training loss: 1.8460420370101929
Validation loss: 2.0485645631949105

Epoch: 5| Step: 4
Training loss: 2.521181583404541
Validation loss: 2.0627321749925613

Epoch: 5| Step: 5
Training loss: 1.8417450189590454
Validation loss: 2.0794821977615356

Epoch: 5| Step: 6
Training loss: 2.0448601245880127
Validation loss: 2.0519933899243674

Epoch: 5| Step: 7
Training loss: 2.7129533290863037
Validation loss: 2.0641747216383615

Epoch: 5| Step: 8
Training loss: 1.744397521018982
Validation loss: 2.085729996363322

Epoch: 5| Step: 9
Training loss: 1.7163641452789307
Validation loss: 2.0777438282966614

Epoch: 5| Step: 10
Training loss: 1.5218634605407715
Validation loss: 2.0995783706506095

Epoch: 5| Step: 11
Training loss: 3.020045280456543
Validation loss: 2.085321918129921

Epoch: 54| Step: 0
Training loss: 2.071415662765503
Validation loss: 2.0447579820950827

Epoch: 5| Step: 1
Training loss: 1.811821699142456
Validation loss: 2.102722485860189

Epoch: 5| Step: 2
Training loss: 2.0897650718688965
Validation loss: 2.0778565406799316

Epoch: 5| Step: 3
Training loss: 1.8624862432479858
Validation loss: 2.0841794262329736

Epoch: 5| Step: 4
Training loss: 1.974532127380371
Validation loss: 2.113521640499433

Epoch: 5| Step: 5
Training loss: 2.2911596298217773
Validation loss: 2.049060652653376

Epoch: 5| Step: 6
Training loss: 1.9209461212158203
Validation loss: 2.065753221511841

Epoch: 5| Step: 7
Training loss: 1.9397777318954468
Validation loss: 2.0880661755800247

Epoch: 5| Step: 8
Training loss: 2.01487398147583
Validation loss: 2.059421862165133

Epoch: 5| Step: 9
Training loss: 1.9534155130386353
Validation loss: 2.0392028590043387

Epoch: 5| Step: 10
Training loss: 2.103458881378174
Validation loss: 2.1211363077163696

Epoch: 5| Step: 11
Training loss: 1.868730902671814
Validation loss: 2.1101750632127128

Epoch: 55| Step: 0
Training loss: 1.6320817470550537
Validation loss: 2.0942186067501702

Epoch: 5| Step: 1
Training loss: 1.8714778423309326
Validation loss: 2.0795588294665017

Epoch: 5| Step: 2
Training loss: 2.4863524436950684
Validation loss: 2.056160474816958

Epoch: 5| Step: 3
Training loss: 2.502011775970459
Validation loss: 2.080427279074987

Epoch: 5| Step: 4
Training loss: 1.824392318725586
Validation loss: 2.096474061409632

Epoch: 5| Step: 5
Training loss: 1.593912124633789
Validation loss: 2.1130829006433487

Epoch: 5| Step: 6
Training loss: 1.6428139209747314
Validation loss: 2.1079401075839996

Epoch: 5| Step: 7
Training loss: 2.6960439682006836
Validation loss: 2.0796750336885452

Epoch: 5| Step: 8
Training loss: 1.4973804950714111
Validation loss: 2.107678552468618

Epoch: 5| Step: 9
Training loss: 1.6553843021392822
Validation loss: 2.1249619175990424

Epoch: 5| Step: 10
Training loss: 2.412365674972534
Validation loss: 2.103754391272863

Epoch: 5| Step: 11
Training loss: 1.733057975769043
Validation loss: 2.133870725830396

Epoch: 56| Step: 0
Training loss: 1.7619930505752563
Validation loss: 2.1258148004611335

Epoch: 5| Step: 1
Training loss: 2.1545777320861816
Validation loss: 2.1259263505538306

Epoch: 5| Step: 2
Training loss: 1.862023115158081
Validation loss: 2.1167444586753845

Epoch: 5| Step: 3
Training loss: 2.802410840988159
Validation loss: 2.0814437667528787

Epoch: 5| Step: 4
Training loss: 1.9777882099151611
Validation loss: 2.0789671391248703

Epoch: 5| Step: 5
Training loss: 1.8769252300262451
Validation loss: 2.083651229739189

Epoch: 5| Step: 6
Training loss: 2.1530020236968994
Validation loss: 2.062985986471176

Epoch: 5| Step: 7
Training loss: 1.990662932395935
Validation loss: 2.1038628617922464

Epoch: 5| Step: 8
Training loss: 2.0736477375030518
Validation loss: 2.080996260046959

Epoch: 5| Step: 9
Training loss: 1.821244478225708
Validation loss: 2.1112170269091926

Epoch: 5| Step: 10
Training loss: 1.309183120727539
Validation loss: 2.11369925737381

Epoch: 5| Step: 11
Training loss: 1.127671718597412
Validation loss: 2.064960072437922

Epoch: 57| Step: 0
Training loss: 2.5740878582000732
Validation loss: 2.0569859196742377

Epoch: 5| Step: 1
Training loss: 2.243537425994873
Validation loss: 2.089946245153745

Epoch: 5| Step: 2
Training loss: 2.0869572162628174
Validation loss: 2.068184087673823

Epoch: 5| Step: 3
Training loss: 1.6124231815338135
Validation loss: 2.07444828748703

Epoch: 5| Step: 4
Training loss: 1.6478554010391235
Validation loss: 2.0849598397811255

Epoch: 5| Step: 5
Training loss: 1.6501200199127197
Validation loss: 2.130779499808947

Epoch: 5| Step: 6
Training loss: 1.8669474124908447
Validation loss: 2.0843914449214935

Epoch: 5| Step: 7
Training loss: 2.099215269088745
Validation loss: 2.109736993908882

Epoch: 5| Step: 8
Training loss: 1.9703471660614014
Validation loss: 2.106548309326172

Epoch: 5| Step: 9
Training loss: 1.5830562114715576
Validation loss: 2.10171040892601

Epoch: 5| Step: 10
Training loss: 1.923659086227417
Validation loss: 2.0784827520449958

Epoch: 5| Step: 11
Training loss: 3.883021593093872
Validation loss: 2.119640201330185

Epoch: 58| Step: 0
Training loss: 1.697609543800354
Validation loss: 2.100570480028788

Epoch: 5| Step: 1
Training loss: 1.901550531387329
Validation loss: 2.1090189019838967

Epoch: 5| Step: 2
Training loss: 1.8535972833633423
Validation loss: 2.0837587465842566

Epoch: 5| Step: 3
Training loss: 2.3993351459503174
Validation loss: 2.0900944819053016

Epoch: 5| Step: 4
Training loss: 1.776717185974121
Validation loss: 2.094270666440328

Epoch: 5| Step: 5
Training loss: 1.7147207260131836
Validation loss: 2.0963856478532157

Epoch: 5| Step: 6
Training loss: 1.9012588262557983
Validation loss: 2.066638340552648

Epoch: 5| Step: 7
Training loss: 2.071115016937256
Validation loss: 2.101582184433937

Epoch: 5| Step: 8
Training loss: 1.821632981300354
Validation loss: 2.069101015726725

Epoch: 5| Step: 9
Training loss: 2.351684093475342
Validation loss: 2.101959064602852

Epoch: 5| Step: 10
Training loss: 1.9677366018295288
Validation loss: 2.070946862300237

Epoch: 5| Step: 11
Training loss: 3.4511518478393555
Validation loss: 2.0697150031725564

Epoch: 59| Step: 0
Training loss: 1.8048903942108154
Validation loss: 2.095401624838511

Epoch: 5| Step: 1
Training loss: 2.3617031574249268
Validation loss: 2.103270639975866

Epoch: 5| Step: 2
Training loss: 1.6378860473632812
Validation loss: 2.136549254258474

Epoch: 5| Step: 3
Training loss: 1.6698391437530518
Validation loss: 2.0753613909085593

Epoch: 5| Step: 4
Training loss: 1.3786590099334717
Validation loss: 2.089424267411232

Epoch: 5| Step: 5
Training loss: 2.2802767753601074
Validation loss: 2.069584935903549

Epoch: 5| Step: 6
Training loss: 2.4730775356292725
Validation loss: 2.095696916182836

Epoch: 5| Step: 7
Training loss: 1.9090635776519775
Validation loss: 2.107183297475179

Epoch: 5| Step: 8
Training loss: 1.8210251331329346
Validation loss: 2.089298958579699

Epoch: 5| Step: 9
Training loss: 2.3952794075012207
Validation loss: 2.117751573522886

Epoch: 5| Step: 10
Training loss: 1.813381552696228
Validation loss: 2.0994897137085595

Epoch: 5| Step: 11
Training loss: 1.7982351779937744
Validation loss: 2.0812201350927353

Epoch: 60| Step: 0
Training loss: 1.9786615371704102
Validation loss: 2.11709733804067

Epoch: 5| Step: 1
Training loss: 1.7867977619171143
Validation loss: 2.1015278895696006

Epoch: 5| Step: 2
Training loss: 1.7771297693252563
Validation loss: 2.092841068903605

Epoch: 5| Step: 3
Training loss: 1.592932105064392
Validation loss: 2.0993558714787164

Epoch: 5| Step: 4
Training loss: 1.6829191446304321
Validation loss: 2.116266449292501

Epoch: 5| Step: 5
Training loss: 1.6481139659881592
Validation loss: 2.160705327987671

Epoch: 5| Step: 6
Training loss: 2.69077205657959
Validation loss: 2.1258882582187653

Epoch: 5| Step: 7
Training loss: 2.0161752700805664
Validation loss: 2.1483286321163177

Epoch: 5| Step: 8
Training loss: 2.507909059524536
Validation loss: 2.1522267758846283

Epoch: 5| Step: 9
Training loss: 1.9833037853240967
Validation loss: 2.1215777844190598

Epoch: 5| Step: 10
Training loss: 2.188973903656006
Validation loss: 2.1178580224514008

Epoch: 5| Step: 11
Training loss: 3.098646640777588
Validation loss: 2.116924673318863

Epoch: 61| Step: 0
Training loss: 1.741187334060669
Validation loss: 2.05336199204127

Epoch: 5| Step: 1
Training loss: 2.084921360015869
Validation loss: 2.085377568999926

Epoch: 5| Step: 2
Training loss: 1.9387342929840088
Validation loss: 2.092587704459826

Epoch: 5| Step: 3
Training loss: 1.7462413311004639
Validation loss: 2.138601675629616

Epoch: 5| Step: 4
Training loss: 2.114196300506592
Validation loss: 2.122927447160085

Epoch: 5| Step: 5
Training loss: 2.164071559906006
Validation loss: 2.118826429049174

Epoch: 5| Step: 6
Training loss: 2.3680946826934814
Validation loss: 2.1788288056850433

Epoch: 5| Step: 7
Training loss: 2.200526475906372
Validation loss: 2.172326331337293

Epoch: 5| Step: 8
Training loss: 2.0241925716400146
Validation loss: 2.147729843854904

Epoch: 5| Step: 9
Training loss: 2.478891611099243
Validation loss: 2.1612908194462457

Epoch: 5| Step: 10
Training loss: 2.085768699645996
Validation loss: 2.1421111871798835

Epoch: 5| Step: 11
Training loss: 2.1990137100219727
Validation loss: 2.1238469928503036

Epoch: 62| Step: 0
Training loss: 1.7882980108261108
Validation loss: 2.1233600030342736

Epoch: 5| Step: 1
Training loss: 1.8888816833496094
Validation loss: 2.1085565785566964

Epoch: 5| Step: 2
Training loss: 1.8529287576675415
Validation loss: 2.1071429401636124

Epoch: 5| Step: 3
Training loss: 1.3174251317977905
Validation loss: 2.070961738626162

Epoch: 5| Step: 4
Training loss: 1.9112485647201538
Validation loss: 2.1172044525543847

Epoch: 5| Step: 5
Training loss: 2.92698335647583
Validation loss: 2.061523218949636

Epoch: 5| Step: 6
Training loss: 2.165468215942383
Validation loss: 2.080111155907313

Epoch: 5| Step: 7
Training loss: 2.1429505348205566
Validation loss: 2.0664274245500565

Epoch: 5| Step: 8
Training loss: 2.1446871757507324
Validation loss: 2.0741753429174423

Epoch: 5| Step: 9
Training loss: 1.5749855041503906
Validation loss: 2.0666956106821694

Epoch: 5| Step: 10
Training loss: 2.0378470420837402
Validation loss: 2.0656309723854065

Epoch: 5| Step: 11
Training loss: 1.541200041770935
Validation loss: 2.0732264121373496

Epoch: 63| Step: 0
Training loss: 1.9841737747192383
Validation loss: 2.097153291106224

Epoch: 5| Step: 1
Training loss: 2.278968334197998
Validation loss: 2.0763241599003472

Epoch: 5| Step: 2
Training loss: 1.5559478998184204
Validation loss: 2.1531455417474112

Epoch: 5| Step: 3
Training loss: 1.6716938018798828
Validation loss: 2.101385459303856

Epoch: 5| Step: 4
Training loss: 1.8763058185577393
Validation loss: 2.102851385871569

Epoch: 5| Step: 5
Training loss: 1.3447743654251099
Validation loss: 2.1260688404242196

Epoch: 5| Step: 6
Training loss: 2.1634163856506348
Validation loss: 2.1506856034199395

Epoch: 5| Step: 7
Training loss: 1.8436346054077148
Validation loss: 2.0968443155288696

Epoch: 5| Step: 8
Training loss: 2.3940935134887695
Validation loss: 2.08716611067454

Epoch: 5| Step: 9
Training loss: 2.107269763946533
Validation loss: 2.082048033674558

Epoch: 5| Step: 10
Training loss: 2.395583152770996
Validation loss: 2.1078332563241324

Epoch: 5| Step: 11
Training loss: 2.7448363304138184
Validation loss: 2.0838033507267633

Epoch: 64| Step: 0
Training loss: 1.994629144668579
Validation loss: 2.1080210556586585

Epoch: 5| Step: 1
Training loss: 2.0345253944396973
Validation loss: 2.0768761187791824

Epoch: 5| Step: 2
Training loss: 1.6282122135162354
Validation loss: 2.0812454322973886

Epoch: 5| Step: 3
Training loss: 1.9175907373428345
Validation loss: 2.0961409707864127

Epoch: 5| Step: 4
Training loss: 2.450655698776245
Validation loss: 2.044250264763832

Epoch: 5| Step: 5
Training loss: 2.268908739089966
Validation loss: 2.122288237015406

Epoch: 5| Step: 6
Training loss: 1.3746612071990967
Validation loss: 2.0269957383473716

Epoch: 5| Step: 7
Training loss: 2.1261138916015625
Validation loss: 2.0708781580130258

Epoch: 5| Step: 8
Training loss: 1.3473138809204102
Validation loss: 2.0452788025140762

Epoch: 5| Step: 9
Training loss: 2.4435343742370605
Validation loss: 2.100815072655678

Epoch: 5| Step: 10
Training loss: 1.787672996520996
Validation loss: 2.111469104886055

Epoch: 5| Step: 11
Training loss: 2.938427448272705
Validation loss: 2.075668215751648

Epoch: 65| Step: 0
Training loss: 2.4667861461639404
Validation loss: 2.071513131260872

Epoch: 5| Step: 1
Training loss: 2.5751304626464844
Validation loss: 2.0664239674806595

Epoch: 5| Step: 2
Training loss: 1.8827295303344727
Validation loss: 2.0936601807673774

Epoch: 5| Step: 3
Training loss: 1.6697795391082764
Validation loss: 2.0847828537225723

Epoch: 5| Step: 4
Training loss: 1.441606044769287
Validation loss: 2.092057779431343

Epoch: 5| Step: 5
Training loss: 1.9840571880340576
Validation loss: 2.08140300710996

Epoch: 5| Step: 6
Training loss: 1.8950477838516235
Validation loss: 2.0787703692913055

Epoch: 5| Step: 7
Training loss: 2.2030417919158936
Validation loss: 2.0759013295173645

Epoch: 5| Step: 8
Training loss: 1.7670443058013916
Validation loss: 2.084843466679255

Epoch: 5| Step: 9
Training loss: 2.3471477031707764
Validation loss: 2.0683738042910895

Epoch: 5| Step: 10
Training loss: 1.3832604885101318
Validation loss: 2.0926294773817062

Epoch: 5| Step: 11
Training loss: 2.407736301422119
Validation loss: 2.087112863858541

Epoch: 66| Step: 0
Training loss: 1.9360301494598389
Validation loss: 2.1429379185040793

Epoch: 5| Step: 1
Training loss: 2.2575740814208984
Validation loss: 2.1044317881266275

Epoch: 5| Step: 2
Training loss: 2.1928036212921143
Validation loss: 2.0692390898863473

Epoch: 5| Step: 3
Training loss: 1.9571197032928467
Validation loss: 2.0927971055110297

Epoch: 5| Step: 4
Training loss: 2.308414936065674
Validation loss: 2.1387755374113717

Epoch: 5| Step: 5
Training loss: 2.355069637298584
Validation loss: 2.102853645881017

Epoch: 5| Step: 6
Training loss: 2.219423294067383
Validation loss: 2.073543111483256

Epoch: 5| Step: 7
Training loss: 1.8881508111953735
Validation loss: 2.08769358197848

Epoch: 5| Step: 8
Training loss: 1.762407898902893
Validation loss: 2.138053779800733

Epoch: 5| Step: 9
Training loss: 1.0565307140350342
Validation loss: 2.0812103102604547

Epoch: 5| Step: 10
Training loss: 1.855425477027893
Validation loss: 2.1135937521855035

Epoch: 5| Step: 11
Training loss: 0.777894139289856
Validation loss: 2.1110010693470636

Epoch: 67| Step: 0
Training loss: 1.8280572891235352
Validation loss: 2.1119153847297034

Epoch: 5| Step: 1
Training loss: 2.20576810836792
Validation loss: 2.0862727661927543

Epoch: 5| Step: 2
Training loss: 2.1213161945343018
Validation loss: 2.140870288014412

Epoch: 5| Step: 3
Training loss: 1.8454437255859375
Validation loss: 2.186104247967402

Epoch: 5| Step: 4
Training loss: 1.8799289464950562
Validation loss: 2.124570310115814

Epoch: 5| Step: 5
Training loss: 1.8391910791397095
Validation loss: 2.163005808989207

Epoch: 5| Step: 6
Training loss: 1.9884271621704102
Validation loss: 2.155994027853012

Epoch: 5| Step: 7
Training loss: 1.7522567510604858
Validation loss: 2.1599146674076715

Epoch: 5| Step: 8
Training loss: 1.9689851999282837
Validation loss: 2.1387065996726355

Epoch: 5| Step: 9
Training loss: 1.9707224369049072
Validation loss: 2.10725037753582

Epoch: 5| Step: 10
Training loss: 2.0098586082458496
Validation loss: 2.1299158235390983

Epoch: 5| Step: 11
Training loss: 3.8807053565979004
Validation loss: 2.1242609123388925

Epoch: 68| Step: 0
Training loss: 1.8589824438095093
Validation loss: 2.1015975028276443

Epoch: 5| Step: 1
Training loss: 1.9474823474884033
Validation loss: 2.036867067217827

Epoch: 5| Step: 2
Training loss: 2.149148941040039
Validation loss: 2.104140818119049

Epoch: 5| Step: 3
Training loss: 1.953338384628296
Validation loss: 2.101290156443914

Epoch: 5| Step: 4
Training loss: 1.944128394126892
Validation loss: 2.09511129061381

Epoch: 5| Step: 5
Training loss: 2.0087292194366455
Validation loss: 2.0505084296067557

Epoch: 5| Step: 6
Training loss: 1.9688129425048828
Validation loss: 2.084838127096494

Epoch: 5| Step: 7
Training loss: 2.139909029006958
Validation loss: 2.085788701971372

Epoch: 5| Step: 8
Training loss: 1.8083240985870361
Validation loss: 2.098079040646553

Epoch: 5| Step: 9
Training loss: 1.6003100872039795
Validation loss: 2.107076480984688

Epoch: 5| Step: 10
Training loss: 1.901070237159729
Validation loss: 2.078479583064715

Epoch: 5| Step: 11
Training loss: 2.2917702198028564
Validation loss: 2.09631339708964

Epoch: 69| Step: 0
Training loss: 2.116513729095459
Validation loss: 2.068454682826996

Epoch: 5| Step: 1
Training loss: 1.8762750625610352
Validation loss: 2.101808488368988

Epoch: 5| Step: 2
Training loss: 2.4630985260009766
Validation loss: 2.099014694492022

Epoch: 5| Step: 3
Training loss: 2.184447765350342
Validation loss: 2.045693968733152

Epoch: 5| Step: 4
Training loss: 2.3935515880584717
Validation loss: 2.0834594617287316

Epoch: 5| Step: 5
Training loss: 2.172422170639038
Validation loss: 2.061140557130178

Epoch: 5| Step: 6
Training loss: 2.0610480308532715
Validation loss: 2.106998453537623

Epoch: 5| Step: 7
Training loss: 1.4871838092803955
Validation loss: 2.0905040999253592

Epoch: 5| Step: 8
Training loss: 1.38919997215271
Validation loss: 2.0318456838528314

Epoch: 5| Step: 9
Training loss: 1.4548046588897705
Validation loss: 2.0726016561190286

Epoch: 5| Step: 10
Training loss: 1.950614333152771
Validation loss: 2.04735404253006

Epoch: 5| Step: 11
Training loss: 1.3180367946624756
Validation loss: 2.0530710965394974

Epoch: 70| Step: 0
Training loss: 1.5920195579528809
Validation loss: 2.080681726336479

Epoch: 5| Step: 1
Training loss: 2.283303737640381
Validation loss: 2.1127446591854095

Epoch: 5| Step: 2
Training loss: 1.4244768619537354
Validation loss: 2.1430030216773353

Epoch: 5| Step: 3
Training loss: 1.9573215246200562
Validation loss: 2.1014372408390045

Epoch: 5| Step: 4
Training loss: 2.261990785598755
Validation loss: 2.1624717762072883

Epoch: 5| Step: 5
Training loss: 1.5051355361938477
Validation loss: 2.107097248236338

Epoch: 5| Step: 6
Training loss: 2.562230348587036
Validation loss: 2.1492368380228677

Epoch: 5| Step: 7
Training loss: 1.873964548110962
Validation loss: 2.1493629117806754

Epoch: 5| Step: 8
Training loss: 2.1301190853118896
Validation loss: 2.174587940176328

Epoch: 5| Step: 9
Training loss: 2.229267120361328
Validation loss: 2.1111173729101815

Epoch: 5| Step: 10
Training loss: 1.972415566444397
Validation loss: 2.0966776659091315

Epoch: 5| Step: 11
Training loss: 1.1961287260055542
Validation loss: 2.094611649711927

Epoch: 71| Step: 0
Training loss: 2.044273853302002
Validation loss: 2.0947848012049994

Epoch: 5| Step: 1
Training loss: 2.6373937129974365
Validation loss: 2.093644137183825

Epoch: 5| Step: 2
Training loss: 2.102491855621338
Validation loss: 2.083894819021225

Epoch: 5| Step: 3
Training loss: 1.5770971775054932
Validation loss: 2.0657514482736588

Epoch: 5| Step: 4
Training loss: 1.5412371158599854
Validation loss: 2.111336966355642

Epoch: 5| Step: 5
Training loss: 1.8568826913833618
Validation loss: 2.0690134714047113

Epoch: 5| Step: 6
Training loss: 1.77654230594635
Validation loss: 2.1006065358718238

Epoch: 5| Step: 7
Training loss: 1.948781967163086
Validation loss: 2.0834197402000427

Epoch: 5| Step: 8
Training loss: 1.9266986846923828
Validation loss: 2.1064474483331046

Epoch: 5| Step: 9
Training loss: 1.995052695274353
Validation loss: 2.1203261067469916

Epoch: 5| Step: 10
Training loss: 2.25380277633667
Validation loss: 2.1268426030874252

Epoch: 5| Step: 11
Training loss: 2.1672348976135254
Validation loss: 2.123101443052292

Epoch: 72| Step: 0
Training loss: 1.97189462184906
Validation loss: 2.0673402845859528

Epoch: 5| Step: 1
Training loss: 1.9045528173446655
Validation loss: 2.0796876152356467

Epoch: 5| Step: 2
Training loss: 1.490515947341919
Validation loss: 2.0602973898251853

Epoch: 5| Step: 3
Training loss: 1.460074782371521
Validation loss: 2.107060452302297

Epoch: 5| Step: 4
Training loss: 2.038031816482544
Validation loss: 2.1068576325972876

Epoch: 5| Step: 5
Training loss: 2.142982006072998
Validation loss: 2.098416199286779

Epoch: 5| Step: 6
Training loss: 1.777456283569336
Validation loss: 2.0571590761343637

Epoch: 5| Step: 7
Training loss: 2.5774688720703125
Validation loss: 2.0551179150740304

Epoch: 5| Step: 8
Training loss: 1.8648889064788818
Validation loss: 2.0745801577965417

Epoch: 5| Step: 9
Training loss: 2.205040454864502
Validation loss: 2.0805267890294394

Epoch: 5| Step: 10
Training loss: 2.366727590560913
Validation loss: 2.0590416391690574

Epoch: 5| Step: 11
Training loss: 2.468350410461426
Validation loss: 2.07441637913386

Epoch: 73| Step: 0
Training loss: 1.5155824422836304
Validation loss: 2.1126261750857034

Epoch: 5| Step: 1
Training loss: 2.4753730297088623
Validation loss: 2.0700971434513726

Epoch: 5| Step: 2
Training loss: 1.7995147705078125
Validation loss: 2.079643468062083

Epoch: 5| Step: 3
Training loss: 1.677424669265747
Validation loss: 2.088603218396505

Epoch: 5| Step: 4
Training loss: 2.017080307006836
Validation loss: 2.1260382483402886

Epoch: 5| Step: 5
Training loss: 2.4428112506866455
Validation loss: 2.068103795250257

Epoch: 5| Step: 6
Training loss: 2.285341739654541
Validation loss: 2.062183767557144

Epoch: 5| Step: 7
Training loss: 1.3791683912277222
Validation loss: 2.1164728105068207

Epoch: 5| Step: 8
Training loss: 1.8626735210418701
Validation loss: 2.077554225921631

Epoch: 5| Step: 9
Training loss: 1.9380820989608765
Validation loss: 2.116337612271309

Epoch: 5| Step: 10
Training loss: 1.7142741680145264
Validation loss: 2.100609242916107

Epoch: 5| Step: 11
Training loss: 3.135298728942871
Validation loss: 2.0908925185600915

Epoch: 74| Step: 0
Training loss: 1.5123441219329834
Validation loss: 2.073041006922722

Epoch: 5| Step: 1
Training loss: 2.043260335922241
Validation loss: 2.0477638940016427

Epoch: 5| Step: 2
Training loss: 1.802085518836975
Validation loss: 2.0764813870191574

Epoch: 5| Step: 3
Training loss: 2.037554979324341
Validation loss: 2.0418970038493476

Epoch: 5| Step: 4
Training loss: 2.302855968475342
Validation loss: 2.078462784488996

Epoch: 5| Step: 5
Training loss: 1.6072492599487305
Validation loss: 2.094539294640223

Epoch: 5| Step: 6
Training loss: 1.5939394235610962
Validation loss: 2.0907032241423926

Epoch: 5| Step: 7
Training loss: 2.732819080352783
Validation loss: 2.0571055511633554

Epoch: 5| Step: 8
Training loss: 1.877920389175415
Validation loss: 2.116195206840833

Epoch: 5| Step: 9
Training loss: 1.2002333402633667
Validation loss: 2.077082638939222

Epoch: 5| Step: 10
Training loss: 2.1157050132751465
Validation loss: 2.104848181207975

Epoch: 5| Step: 11
Training loss: 3.4720802307128906
Validation loss: 2.085230827331543

Epoch: 75| Step: 0
Training loss: 1.6790679693222046
Validation loss: 2.1017372955878577

Epoch: 5| Step: 1
Training loss: 1.7648159265518188
Validation loss: 2.0692198326190314

Epoch: 5| Step: 2
Training loss: 1.6244933605194092
Validation loss: 2.077043265104294

Epoch: 5| Step: 3
Training loss: 2.19576096534729
Validation loss: 2.109078496694565

Epoch: 5| Step: 4
Training loss: 2.019737958908081
Validation loss: 2.076784074306488

Epoch: 5| Step: 5
Training loss: 2.3739633560180664
Validation loss: 2.099272226293882

Epoch: 5| Step: 6
Training loss: 2.1661436557769775
Validation loss: 2.075744236509005

Epoch: 5| Step: 7
Training loss: 1.4537224769592285
Validation loss: 2.104694833358129

Epoch: 5| Step: 8
Training loss: 2.390104055404663
Validation loss: 2.093110124270121

Epoch: 5| Step: 9
Training loss: 1.7214643955230713
Validation loss: 2.107075557112694

Epoch: 5| Step: 10
Training loss: 1.773224115371704
Validation loss: 2.088770146171252

Epoch: 5| Step: 11
Training loss: 2.770080089569092
Validation loss: 2.107542723417282

Epoch: 76| Step: 0
Training loss: 1.7792351245880127
Validation loss: 2.0871903548638024

Epoch: 5| Step: 1
Training loss: 1.7839361429214478
Validation loss: 2.1090135673681893

Epoch: 5| Step: 2
Training loss: 2.058138847351074
Validation loss: 2.09500652551651

Epoch: 5| Step: 3
Training loss: 1.7426822185516357
Validation loss: 2.0959718277057013

Epoch: 5| Step: 4
Training loss: 1.918521523475647
Validation loss: 2.1256057719389596

Epoch: 5| Step: 5
Training loss: 1.8137134313583374
Validation loss: 2.093559776743253

Epoch: 5| Step: 6
Training loss: 1.9300100803375244
Validation loss: 2.080922747651736

Epoch: 5| Step: 7
Training loss: 2.064662218093872
Validation loss: 2.1041202942530313

Epoch: 5| Step: 8
Training loss: 2.130772352218628
Validation loss: 2.106398805975914

Epoch: 5| Step: 9
Training loss: 2.168963670730591
Validation loss: 2.1330150763193765

Epoch: 5| Step: 10
Training loss: 1.8490476608276367
Validation loss: 2.099382976690928

Epoch: 5| Step: 11
Training loss: 1.5534623861312866
Validation loss: 2.0521591951449714

Epoch: 77| Step: 0
Training loss: 2.3318638801574707
Validation loss: 2.114084700743357

Epoch: 5| Step: 1
Training loss: 1.463526964187622
Validation loss: 2.0932198564211526

Epoch: 5| Step: 2
Training loss: 1.5438759326934814
Validation loss: 2.040987804532051

Epoch: 5| Step: 3
Training loss: 2.0500662326812744
Validation loss: 2.0690733194351196

Epoch: 5| Step: 4
Training loss: 2.5345401763916016
Validation loss: 2.1100555757681527

Epoch: 5| Step: 5
Training loss: 2.028564453125
Validation loss: 2.129630928238233

Epoch: 5| Step: 6
Training loss: 2.325589656829834
Validation loss: 2.1024906635284424

Epoch: 5| Step: 7
Training loss: 1.9436413049697876
Validation loss: 2.082290212313334

Epoch: 5| Step: 8
Training loss: 1.59023118019104
Validation loss: 2.0942669014135995

Epoch: 5| Step: 9
Training loss: 1.2689344882965088
Validation loss: 2.0804825127124786

Epoch: 5| Step: 10
Training loss: 1.9126754999160767
Validation loss: 2.101907958587011

Epoch: 5| Step: 11
Training loss: 1.192971110343933
Validation loss: 2.0840983986854553

Epoch: 78| Step: 0
Training loss: 2.3739147186279297
Validation loss: 2.1004745264848075

Epoch: 5| Step: 1
Training loss: 2.1689505577087402
Validation loss: 2.0711072037617364

Epoch: 5| Step: 2
Training loss: 1.6143863201141357
Validation loss: 2.0777172644933066

Epoch: 5| Step: 3
Training loss: 2.585108995437622
Validation loss: 2.0827065209547677

Epoch: 5| Step: 4
Training loss: 2.1736977100372314
Validation loss: 2.11549840370814

Epoch: 5| Step: 5
Training loss: 1.811079978942871
Validation loss: 2.1341290722290673

Epoch: 5| Step: 6
Training loss: 2.1566920280456543
Validation loss: 2.095729966958364

Epoch: 5| Step: 7
Training loss: 1.688270926475525
Validation loss: 2.10045126080513

Epoch: 5| Step: 8
Training loss: 1.5489492416381836
Validation loss: 2.099488233526548

Epoch: 5| Step: 9
Training loss: 2.0132641792297363
Validation loss: 2.0641220211982727

Epoch: 5| Step: 10
Training loss: 1.9417365789413452
Validation loss: 2.109310587247213

Epoch: 5| Step: 11
Training loss: 2.464247226715088
Validation loss: 2.0988165885210037

Epoch: 79| Step: 0
Training loss: 1.933074951171875
Validation loss: 2.0723723620176315

Epoch: 5| Step: 1
Training loss: 1.547852635383606
Validation loss: 2.090868204832077

Epoch: 5| Step: 2
Training loss: 2.167428493499756
Validation loss: 2.0746868600447974

Epoch: 5| Step: 3
Training loss: 1.9434902667999268
Validation loss: 2.1200516621271768

Epoch: 5| Step: 4
Training loss: 1.94440495967865
Validation loss: 2.098319580157598

Epoch: 5| Step: 5
Training loss: 1.630758285522461
Validation loss: 2.142901415626208

Epoch: 5| Step: 6
Training loss: 2.015852451324463
Validation loss: 2.1374976684649787

Epoch: 5| Step: 7
Training loss: 1.8484461307525635
Validation loss: 2.1124277065197625

Epoch: 5| Step: 8
Training loss: 1.9368336200714111
Validation loss: 2.148162543773651

Epoch: 5| Step: 9
Training loss: 2.4197239875793457
Validation loss: 2.0985467235247293

Epoch: 5| Step: 10
Training loss: 1.734452486038208
Validation loss: 2.142803673942884

Epoch: 5| Step: 11
Training loss: 2.071564197540283
Validation loss: 2.176018272837003

Epoch: 80| Step: 0
Training loss: 1.7970983982086182
Validation loss: 2.0840085446834564

Epoch: 5| Step: 1
Training loss: 2.2243576049804688
Validation loss: 2.0875398019949594

Epoch: 5| Step: 2
Training loss: 1.9758723974227905
Validation loss: 2.119405229886373

Epoch: 5| Step: 3
Training loss: 1.4888132810592651
Validation loss: 2.0883506735165915

Epoch: 5| Step: 4
Training loss: 2.218402624130249
Validation loss: 2.0838489135106406

Epoch: 5| Step: 5
Training loss: 1.96328604221344
Validation loss: 2.0652696788311005

Epoch: 5| Step: 6
Training loss: 1.5336339473724365
Validation loss: 2.0878235896428428

Epoch: 5| Step: 7
Training loss: 1.8568248748779297
Validation loss: 2.1007914543151855

Epoch: 5| Step: 8
Training loss: 2.0474789142608643
Validation loss: 2.082636167605718

Epoch: 5| Step: 9
Training loss: 2.249755620956421
Validation loss: 2.096057097117106

Epoch: 5| Step: 10
Training loss: 1.843540906906128
Validation loss: 2.0971627136071525

Epoch: 5| Step: 11
Training loss: 2.092146873474121
Validation loss: 2.0751689225435257

Epoch: 81| Step: 0
Training loss: 1.9428752660751343
Validation loss: 2.080140774448713

Epoch: 5| Step: 1
Training loss: 2.1992619037628174
Validation loss: 2.0735989809036255

Epoch: 5| Step: 2
Training loss: 1.9937489032745361
Validation loss: 2.0748414248228073

Epoch: 5| Step: 3
Training loss: 1.7825825214385986
Validation loss: 2.075958455602328

Epoch: 5| Step: 4
Training loss: 1.8841453790664673
Validation loss: 2.1223881542682648

Epoch: 5| Step: 5
Training loss: 1.7534434795379639
Validation loss: 2.1062009384234748

Epoch: 5| Step: 6
Training loss: 1.9632117748260498
Validation loss: 2.151880274216334

Epoch: 5| Step: 7
Training loss: 1.6732215881347656
Validation loss: 2.1503894329071045

Epoch: 5| Step: 8
Training loss: 2.1542696952819824
Validation loss: 2.1789133548736572

Epoch: 5| Step: 9
Training loss: 1.7549612522125244
Validation loss: 2.1396616796652475

Epoch: 5| Step: 10
Training loss: 2.3602294921875
Validation loss: 2.1324888269106546

Epoch: 5| Step: 11
Training loss: 2.3686327934265137
Validation loss: 2.090246334671974

Epoch: 82| Step: 0
Training loss: 1.954583764076233
Validation loss: 2.0756643265485764

Epoch: 5| Step: 1
Training loss: 1.2439440488815308
Validation loss: 2.134804904460907

Epoch: 5| Step: 2
Training loss: 1.6935123205184937
Validation loss: 2.0692728658517203

Epoch: 5| Step: 3
Training loss: 1.7948023080825806
Validation loss: 2.0509173224369683

Epoch: 5| Step: 4
Training loss: 1.414443016052246
Validation loss: 2.086021895209948

Epoch: 5| Step: 5
Training loss: 1.918402075767517
Validation loss: 2.0716978311538696

Epoch: 5| Step: 6
Training loss: 1.6419994831085205
Validation loss: 2.089217722415924

Epoch: 5| Step: 7
Training loss: 2.0683376789093018
Validation loss: 2.0626593629519143

Epoch: 5| Step: 8
Training loss: 2.116833448410034
Validation loss: 2.0287703772385917

Epoch: 5| Step: 9
Training loss: 2.120699882507324
Validation loss: 2.1098520259062448

Epoch: 5| Step: 10
Training loss: 2.789044141769409
Validation loss: 2.070110027988752

Epoch: 5| Step: 11
Training loss: 2.3457531929016113
Validation loss: 2.084855616092682

Epoch: 83| Step: 0
Training loss: 1.7804819345474243
Validation loss: 2.1016500095526376

Epoch: 5| Step: 1
Training loss: 1.8555307388305664
Validation loss: 2.1120860278606415

Epoch: 5| Step: 2
Training loss: 2.3232455253601074
Validation loss: 2.0518372456232705

Epoch: 5| Step: 3
Training loss: 1.8658008575439453
Validation loss: 2.0912243922551474

Epoch: 5| Step: 4
Training loss: 1.9420379400253296
Validation loss: 2.056366980075836

Epoch: 5| Step: 5
Training loss: 1.836448311805725
Validation loss: 2.030324255426725

Epoch: 5| Step: 6
Training loss: 1.7936195135116577
Validation loss: 2.040721853574117

Epoch: 5| Step: 7
Training loss: 2.396057367324829
Validation loss: 2.031834155321121

Epoch: 5| Step: 8
Training loss: 2.074113130569458
Validation loss: 2.085777426759402

Epoch: 5| Step: 9
Training loss: 1.6568466424942017
Validation loss: 2.0690483351548514

Epoch: 5| Step: 10
Training loss: 1.726131796836853
Validation loss: 2.0903612027565637

Epoch: 5| Step: 11
Training loss: 0.7784767150878906
Validation loss: 2.090889756878217

Epoch: 84| Step: 0
Training loss: 1.5224250555038452
Validation loss: 2.1344980796178183

Epoch: 5| Step: 1
Training loss: 1.4839344024658203
Validation loss: 2.1094687382380166

Epoch: 5| Step: 2
Training loss: 2.147395372390747
Validation loss: 2.133671442667643

Epoch: 5| Step: 3
Training loss: 1.9170081615447998
Validation loss: 2.1005054712295532

Epoch: 5| Step: 4
Training loss: 1.3622660636901855
Validation loss: 2.0943595866362252

Epoch: 5| Step: 5
Training loss: 2.109508991241455
Validation loss: 2.0977801928917565

Epoch: 5| Step: 6
Training loss: 2.0421576499938965
Validation loss: 2.1435649444659552

Epoch: 5| Step: 7
Training loss: 2.3982930183410645
Validation loss: 2.0706196228663125

Epoch: 5| Step: 8
Training loss: 2.735725164413452
Validation loss: 2.1086678355932236

Epoch: 5| Step: 9
Training loss: 1.6229228973388672
Validation loss: 2.0657682518164315

Epoch: 5| Step: 10
Training loss: 1.6702630519866943
Validation loss: 2.069321403900782

Epoch: 5| Step: 11
Training loss: 2.268864393234253
Validation loss: 2.039542923370997

Epoch: 85| Step: 0
Training loss: 1.668064832687378
Validation loss: 2.071073199311892

Epoch: 5| Step: 1
Training loss: 1.414876937866211
Validation loss: 2.0498450994491577

Epoch: 5| Step: 2
Training loss: 1.8698533773422241
Validation loss: 2.05036294957002

Epoch: 5| Step: 3
Training loss: 1.6880252361297607
Validation loss: 2.0200463781754174

Epoch: 5| Step: 4
Training loss: 1.8822782039642334
Validation loss: 2.0864116797844567

Epoch: 5| Step: 5
Training loss: 2.258626699447632
Validation loss: 2.0622688631216683

Epoch: 5| Step: 6
Training loss: 1.9258816242218018
Validation loss: 2.054182012875875

Epoch: 5| Step: 7
Training loss: 1.373605489730835
Validation loss: 2.0776235659917197

Epoch: 5| Step: 8
Training loss: 2.1645045280456543
Validation loss: 2.0566106836001077

Epoch: 5| Step: 9
Training loss: 2.54341983795166
Validation loss: 2.04525159796079

Epoch: 5| Step: 10
Training loss: 2.376499652862549
Validation loss: 2.0525663246711097

Epoch: 5| Step: 11
Training loss: 1.6359739303588867
Validation loss: 2.07981846233209

Epoch: 86| Step: 0
Training loss: 1.8848159313201904
Validation loss: 2.0849738915761313

Epoch: 5| Step: 1
Training loss: 1.7211185693740845
Validation loss: 2.064836780230204

Epoch: 5| Step: 2
Training loss: 1.8343479633331299
Validation loss: 2.084514652689298

Epoch: 5| Step: 3
Training loss: 1.8452295064926147
Validation loss: 2.0896022071441016

Epoch: 5| Step: 4
Training loss: 2.1456592082977295
Validation loss: 2.1123184710741043

Epoch: 5| Step: 5
Training loss: 2.031092405319214
Validation loss: 2.104211022456487

Epoch: 5| Step: 6
Training loss: 1.693433403968811
Validation loss: 2.136138732234637

Epoch: 5| Step: 7
Training loss: 1.486609697341919
Validation loss: 2.1198203414678574

Epoch: 5| Step: 8
Training loss: 2.8952507972717285
Validation loss: 2.1459625413020453

Epoch: 5| Step: 9
Training loss: 2.214111328125
Validation loss: 2.132167637348175

Epoch: 5| Step: 10
Training loss: 1.0356535911560059
Validation loss: 2.0795437643925347

Epoch: 5| Step: 11
Training loss: 1.8051555156707764
Validation loss: 2.0876314838727317

Epoch: 87| Step: 0
Training loss: 2.375929355621338
Validation loss: 2.145847280820211

Epoch: 5| Step: 1
Training loss: 1.9133514165878296
Validation loss: 2.0884282092253366

Epoch: 5| Step: 2
Training loss: 1.741699457168579
Validation loss: 2.0893744428952536

Epoch: 5| Step: 3
Training loss: 1.69012451171875
Validation loss: 2.1027906785408654

Epoch: 5| Step: 4
Training loss: 1.9152326583862305
Validation loss: 2.0894844929377236

Epoch: 5| Step: 5
Training loss: 1.7476049661636353
Validation loss: 2.0614887525637946

Epoch: 5| Step: 6
Training loss: 1.7649917602539062
Validation loss: 2.1234859625498452

Epoch: 5| Step: 7
Training loss: 1.9093408584594727
Validation loss: 2.0869846791028976

Epoch: 5| Step: 8
Training loss: 1.5892055034637451
Validation loss: 2.0937957564989724

Epoch: 5| Step: 9
Training loss: 2.2534923553466797
Validation loss: 2.094441682100296

Epoch: 5| Step: 10
Training loss: 2.0466880798339844
Validation loss: 2.1078354716300964

Epoch: 5| Step: 11
Training loss: 1.328883171081543
Validation loss: 2.062014584740003

Epoch: 88| Step: 0
Training loss: 1.5332775115966797
Validation loss: 2.0932688117027283

Epoch: 5| Step: 1
Training loss: 1.8312110900878906
Validation loss: 2.080644354224205

Epoch: 5| Step: 2
Training loss: 2.115291118621826
Validation loss: 2.0539818704128265

Epoch: 5| Step: 3
Training loss: 2.813657760620117
Validation loss: 2.1009248793125153

Epoch: 5| Step: 4
Training loss: 1.568028211593628
Validation loss: 2.0790455788373947

Epoch: 5| Step: 5
Training loss: 1.9143636226654053
Validation loss: 2.0909816523392997

Epoch: 5| Step: 6
Training loss: 2.088158369064331
Validation loss: 2.06571763753891

Epoch: 5| Step: 7
Training loss: 1.4656049013137817
Validation loss: 2.067308952411016

Epoch: 5| Step: 8
Training loss: 1.8684231042861938
Validation loss: 2.0836990724007287

Epoch: 5| Step: 9
Training loss: 2.2234091758728027
Validation loss: 2.0841299990812936

Epoch: 5| Step: 10
Training loss: 1.5195167064666748
Validation loss: 2.097054382165273

Epoch: 5| Step: 11
Training loss: 1.4441792964935303
Validation loss: 2.0923758198817572

Epoch: 89| Step: 0
Training loss: 2.031001329421997
Validation loss: 2.070835212866465

Epoch: 5| Step: 1
Training loss: 1.853290319442749
Validation loss: 2.103760759035746

Epoch: 5| Step: 2
Training loss: 1.996500015258789
Validation loss: 2.071752965450287

Epoch: 5| Step: 3
Training loss: 1.713683843612671
Validation loss: 2.0890875260035195

Epoch: 5| Step: 4
Training loss: 1.8973948955535889
Validation loss: 2.053542951742808

Epoch: 5| Step: 5
Training loss: 1.596906304359436
Validation loss: 2.0681349635124207

Epoch: 5| Step: 6
Training loss: 1.829031229019165
Validation loss: 2.0487174888451896

Epoch: 5| Step: 7
Training loss: 1.538846731185913
Validation loss: 2.0884618063767753

Epoch: 5| Step: 8
Training loss: 1.8966560363769531
Validation loss: 2.0740926961104074

Epoch: 5| Step: 9
Training loss: 2.09920072555542
Validation loss: 2.114740471045176

Epoch: 5| Step: 10
Training loss: 2.3708693981170654
Validation loss: 2.077212775746981

Epoch: 5| Step: 11
Training loss: 2.088703155517578
Validation loss: 2.142057031393051

Epoch: 90| Step: 0
Training loss: 2.24172043800354
Validation loss: 2.113138015071551

Epoch: 5| Step: 1
Training loss: 1.9160534143447876
Validation loss: 2.0797509054342904

Epoch: 5| Step: 2
Training loss: 1.861517310142517
Validation loss: 2.0688074181477227

Epoch: 5| Step: 3
Training loss: 2.3763699531555176
Validation loss: 2.0890848686297736

Epoch: 5| Step: 4
Training loss: 1.4915317296981812
Validation loss: 2.1259560684363046

Epoch: 5| Step: 5
Training loss: 1.5892293453216553
Validation loss: 2.1040376275777817

Epoch: 5| Step: 6
Training loss: 2.3121063709259033
Validation loss: 2.119516889254252

Epoch: 5| Step: 7
Training loss: 1.7890422344207764
Validation loss: 2.079293688138326

Epoch: 5| Step: 8
Training loss: 1.5342437028884888
Validation loss: 2.136322264870008

Epoch: 5| Step: 9
Training loss: 1.6937181949615479
Validation loss: 2.075624629855156

Epoch: 5| Step: 10
Training loss: 1.9381835460662842
Validation loss: 2.1022191594044366

Epoch: 5| Step: 11
Training loss: 2.758450508117676
Validation loss: 2.060609062512716

Epoch: 91| Step: 0
Training loss: 1.9280083179473877
Validation loss: 2.0608535756667457

Epoch: 5| Step: 1
Training loss: 1.6293036937713623
Validation loss: 2.0347703943649926

Epoch: 5| Step: 2
Training loss: 1.7084146738052368
Validation loss: 2.093262871106466

Epoch: 5| Step: 3
Training loss: 2.5145325660705566
Validation loss: 2.0733217895030975

Epoch: 5| Step: 4
Training loss: 1.915753722190857
Validation loss: 2.1053213824828467

Epoch: 5| Step: 5
Training loss: 1.9884757995605469
Validation loss: 2.140251949429512

Epoch: 5| Step: 6
Training loss: 1.4638839960098267
Validation loss: 2.1038848310709

Epoch: 5| Step: 7
Training loss: 1.5458379983901978
Validation loss: 2.11408702035745

Epoch: 5| Step: 8
Training loss: 2.446012496948242
Validation loss: 2.082734818259875

Epoch: 5| Step: 9
Training loss: 1.802337884902954
Validation loss: 2.1028675933678946

Epoch: 5| Step: 10
Training loss: 2.6293082237243652
Validation loss: 2.061145464579264

Epoch: 5| Step: 11
Training loss: 0.9102696180343628
Validation loss: 2.0739377290010452

Epoch: 92| Step: 0
Training loss: 1.7226604223251343
Validation loss: 2.0846563627322516

Epoch: 5| Step: 1
Training loss: 1.6470892429351807
Validation loss: 2.0844029734532037

Epoch: 5| Step: 2
Training loss: 2.1724159717559814
Validation loss: 2.094862605134646

Epoch: 5| Step: 3
Training loss: 1.4804317951202393
Validation loss: 2.1227738857269287

Epoch: 5| Step: 4
Training loss: 2.236081123352051
Validation loss: 2.138488680124283

Epoch: 5| Step: 5
Training loss: 1.72261643409729
Validation loss: 2.1332325786352158

Epoch: 5| Step: 6
Training loss: 2.513232946395874
Validation loss: 2.177004059155782

Epoch: 5| Step: 7
Training loss: 2.095855474472046
Validation loss: 2.1653724312782288

Epoch: 5| Step: 8
Training loss: 1.9339196681976318
Validation loss: 2.1518359382947287

Epoch: 5| Step: 9
Training loss: 1.443671464920044
Validation loss: 2.096106082201004

Epoch: 5| Step: 10
Training loss: 1.8326408863067627
Validation loss: 2.1215445498625436

Epoch: 5| Step: 11
Training loss: 2.651080846786499
Validation loss: 2.0800298204024634

Epoch: 93| Step: 0
Training loss: 2.035414695739746
Validation loss: 2.084488958120346

Epoch: 5| Step: 1
Training loss: 1.6143321990966797
Validation loss: 2.1063179075717926

Epoch: 5| Step: 2
Training loss: 1.3528543710708618
Validation loss: 2.0645929823319116

Epoch: 5| Step: 3
Training loss: 1.1826459169387817
Validation loss: 2.05911419292291

Epoch: 5| Step: 4
Training loss: 1.869253396987915
Validation loss: 2.1046938647826514

Epoch: 5| Step: 5
Training loss: 2.000251054763794
Validation loss: 2.0979477365811667

Epoch: 5| Step: 6
Training loss: 2.061739683151245
Validation loss: 2.0600977391004562

Epoch: 5| Step: 7
Training loss: 2.061474323272705
Validation loss: 2.0649208972851434

Epoch: 5| Step: 8
Training loss: 2.114790678024292
Validation loss: 2.0720583498477936

Epoch: 5| Step: 9
Training loss: 2.3963146209716797
Validation loss: 2.0644947389761605

Epoch: 5| Step: 10
Training loss: 2.070427894592285
Validation loss: 2.091108798980713

Epoch: 5| Step: 11
Training loss: 1.9165736436843872
Validation loss: 2.0854079524676004

Epoch: 94| Step: 0
Training loss: 1.7377169132232666
Validation loss: 2.1179434061050415

Epoch: 5| Step: 1
Training loss: 2.1567516326904297
Validation loss: 2.1054534167051315

Epoch: 5| Step: 2
Training loss: 2.328519582748413
Validation loss: 2.119750459988912

Epoch: 5| Step: 3
Training loss: 1.6325340270996094
Validation loss: 2.1047548751036325

Epoch: 5| Step: 4
Training loss: 2.0296075344085693
Validation loss: 2.071943625807762

Epoch: 5| Step: 5
Training loss: 1.7043697834014893
Validation loss: 2.090416058897972

Epoch: 5| Step: 6
Training loss: 1.235870122909546
Validation loss: 2.0884410788615546

Epoch: 5| Step: 7
Training loss: 1.9436531066894531
Validation loss: 2.0797612021366754

Epoch: 5| Step: 8
Training loss: 2.158482074737549
Validation loss: 2.086088294784228

Epoch: 5| Step: 9
Training loss: 2.1941208839416504
Validation loss: 2.075974628329277

Epoch: 5| Step: 10
Training loss: 1.4414030313491821
Validation loss: 2.0789642930030823

Epoch: 5| Step: 11
Training loss: 1.5933266878128052
Validation loss: 2.0806596875190735

Epoch: 95| Step: 0
Training loss: 1.9726022481918335
Validation loss: 2.1148464381694794

Epoch: 5| Step: 1
Training loss: 2.029818534851074
Validation loss: 2.0690116435289383

Epoch: 5| Step: 2
Training loss: 1.1003016233444214
Validation loss: 2.0826676289240518

Epoch: 5| Step: 3
Training loss: 1.684461236000061
Validation loss: 2.0793361365795135

Epoch: 5| Step: 4
Training loss: 1.8601181507110596
Validation loss: 2.0831659535566964

Epoch: 5| Step: 5
Training loss: 1.8597825765609741
Validation loss: 2.1001892338196435

Epoch: 5| Step: 6
Training loss: 2.3455913066864014
Validation loss: 2.088656172156334

Epoch: 5| Step: 7
Training loss: 1.8607984781265259
Validation loss: 2.068778306245804

Epoch: 5| Step: 8
Training loss: 2.2946829795837402
Validation loss: 2.079231321811676

Epoch: 5| Step: 9
Training loss: 2.1063201427459717
Validation loss: 2.0752687454223633

Epoch: 5| Step: 10
Training loss: 1.7439014911651611
Validation loss: 2.1268150210380554

Epoch: 5| Step: 11
Training loss: 1.1584051847457886
Validation loss: 2.0905540535847345

Epoch: 96| Step: 0
Training loss: 1.9188867807388306
Validation loss: 2.0916956861813865

Epoch: 5| Step: 1
Training loss: 1.6689916849136353
Validation loss: 2.0554005752007165

Epoch: 5| Step: 2
Training loss: 1.6780658960342407
Validation loss: 2.094060848156611

Epoch: 5| Step: 3
Training loss: 2.210782289505005
Validation loss: 2.090663035710653

Epoch: 5| Step: 4
Training loss: 0.8850300908088684
Validation loss: 2.122171774506569

Epoch: 5| Step: 5
Training loss: 2.2322728633880615
Validation loss: 2.109156906604767

Epoch: 5| Step: 6
Training loss: 1.7418556213378906
Validation loss: 2.0576576789220176

Epoch: 5| Step: 7
Training loss: 2.17956805229187
Validation loss: 2.0529221345980964

Epoch: 5| Step: 8
Training loss: 1.7567631006240845
Validation loss: 2.0818644364674888

Epoch: 5| Step: 9
Training loss: 2.1643519401550293
Validation loss: 2.0750778317451477

Epoch: 5| Step: 10
Training loss: 1.8331663608551025
Validation loss: 2.07209246357282

Epoch: 5| Step: 11
Training loss: 1.6909945011138916
Validation loss: 2.083507165312767

Epoch: 97| Step: 0
Training loss: 1.4215298891067505
Validation loss: 2.0620922843615213

Epoch: 5| Step: 1
Training loss: 2.2921175956726074
Validation loss: 2.049355591336886

Epoch: 5| Step: 2
Training loss: 1.8426307439804077
Validation loss: 2.107562546928724

Epoch: 5| Step: 3
Training loss: 1.8975036144256592
Validation loss: 2.088779384891192

Epoch: 5| Step: 4
Training loss: 1.5704857110977173
Validation loss: 2.078776001930237

Epoch: 5| Step: 5
Training loss: 1.593366265296936
Validation loss: 2.0873552908500037

Epoch: 5| Step: 6
Training loss: 2.0140891075134277
Validation loss: 2.080566237370173

Epoch: 5| Step: 7
Training loss: 1.4141098260879517
Validation loss: 2.0955006927251816

Epoch: 5| Step: 8
Training loss: 2.4655447006225586
Validation loss: 2.1056525309880576

Epoch: 5| Step: 9
Training loss: 2.007488489151001
Validation loss: 2.0955199152231216

Epoch: 5| Step: 10
Training loss: 1.8987178802490234
Validation loss: 2.0781212796767554

Epoch: 5| Step: 11
Training loss: 1.954545021057129
Validation loss: 2.07523442308108

Epoch: 98| Step: 0
Training loss: 1.2903621196746826
Validation loss: 2.0890506307284036

Epoch: 5| Step: 1
Training loss: 1.3212435245513916
Validation loss: 2.114317372441292

Epoch: 5| Step: 2
Training loss: 1.7082531452178955
Validation loss: 2.0899514853954315

Epoch: 5| Step: 3
Training loss: 2.5850021839141846
Validation loss: 2.083297605315844

Epoch: 5| Step: 4
Training loss: 2.478341579437256
Validation loss: 2.1024492979049683

Epoch: 5| Step: 5
Training loss: 1.7067210674285889
Validation loss: 2.1049075424671173

Epoch: 5| Step: 6
Training loss: 1.9729706048965454
Validation loss: 2.140341430902481

Epoch: 5| Step: 7
Training loss: 2.0238518714904785
Validation loss: 2.102651988466581

Epoch: 5| Step: 8
Training loss: 1.6092841625213623
Validation loss: 2.1180994659662247

Epoch: 5| Step: 9
Training loss: 1.9431289434432983
Validation loss: 2.0950560172398887

Epoch: 5| Step: 10
Training loss: 2.028982400894165
Validation loss: 2.1180715511242547

Epoch: 5| Step: 11
Training loss: 1.5322597026824951
Validation loss: 2.0597231090068817

Epoch: 99| Step: 0
Training loss: 1.5738259553909302
Validation loss: 2.0482705583175025

Epoch: 5| Step: 1
Training loss: 1.4906954765319824
Validation loss: 2.072668338815371

Epoch: 5| Step: 2
Training loss: 1.5649464130401611
Validation loss: 2.0673483659823737

Epoch: 5| Step: 3
Training loss: 2.2301745414733887
Validation loss: 2.060285051663717

Epoch: 5| Step: 4
Training loss: 1.8323755264282227
Validation loss: 2.115653410553932

Epoch: 5| Step: 5
Training loss: 2.3247103691101074
Validation loss: 2.088746855656306

Epoch: 5| Step: 6
Training loss: 1.8832883834838867
Validation loss: 2.100483993689219

Epoch: 5| Step: 7
Training loss: 1.6106303930282593
Validation loss: 2.060869812965393

Epoch: 5| Step: 8
Training loss: 1.9870887994766235
Validation loss: 2.081584225098292

Epoch: 5| Step: 9
Training loss: 2.2102572917938232
Validation loss: 2.089476635058721

Epoch: 5| Step: 10
Training loss: 1.8026511669158936
Validation loss: 2.1113640815019608

Epoch: 5| Step: 11
Training loss: 1.944666862487793
Validation loss: 2.107081929842631

Epoch: 100| Step: 0
Training loss: 1.0596472024917603
Validation loss: 2.1066153148810067

Epoch: 5| Step: 1
Training loss: 1.9291999340057373
Validation loss: 2.0935483872890472

Epoch: 5| Step: 2
Training loss: 1.571950078010559
Validation loss: 2.1363408317168555

Epoch: 5| Step: 3
Training loss: 1.9282382726669312
Validation loss: 2.186014403899511

Epoch: 5| Step: 4
Training loss: 2.0494656562805176
Validation loss: 2.1861263066530228

Epoch: 5| Step: 5
Training loss: 1.8191407918930054
Validation loss: 2.1667789866526923

Epoch: 5| Step: 6
Training loss: 1.749283790588379
Validation loss: 2.120577181379

Epoch: 5| Step: 7
Training loss: 2.877587080001831
Validation loss: 2.1532314121723175

Epoch: 5| Step: 8
Training loss: 1.6816065311431885
Validation loss: 2.1708174447218576

Epoch: 5| Step: 9
Training loss: 1.8707844018936157
Validation loss: 2.1086971312761307

Epoch: 5| Step: 10
Training loss: 2.1476218700408936
Validation loss: 2.081033622225126

Epoch: 5| Step: 11
Training loss: 0.8689221739768982
Validation loss: 2.0841927031675973

Epoch: 101| Step: 0
Training loss: 1.7652616500854492
Validation loss: 2.087569365898768

Epoch: 5| Step: 1
Training loss: 1.5404112339019775
Validation loss: 2.0780615160862603

Epoch: 5| Step: 2
Training loss: 2.1585326194763184
Validation loss: 2.0546525716781616

Epoch: 5| Step: 3
Training loss: 1.1790173053741455
Validation loss: 2.0965329309304557

Epoch: 5| Step: 4
Training loss: 2.3083949089050293
Validation loss: 2.0789181043704352

Epoch: 5| Step: 5
Training loss: 1.7253246307373047
Validation loss: 2.0981438606977463

Epoch: 5| Step: 6
Training loss: 1.5647079944610596
Validation loss: 2.08712071677049

Epoch: 5| Step: 7
Training loss: 2.344057559967041
Validation loss: 2.0910712430874505

Epoch: 5| Step: 8
Training loss: 1.9492559432983398
Validation loss: 2.091999595363935

Epoch: 5| Step: 9
Training loss: 2.31088924407959
Validation loss: 2.060138533512751

Epoch: 5| Step: 10
Training loss: 1.874495267868042
Validation loss: 2.0913549413283667

Epoch: 5| Step: 11
Training loss: 2.1611690521240234
Validation loss: 2.0741200099388757

Epoch: 102| Step: 0
Training loss: 1.7662779092788696
Validation loss: 2.072446217139562

Epoch: 5| Step: 1
Training loss: 2.3059797286987305
Validation loss: 2.0558737367391586

Epoch: 5| Step: 2
Training loss: 1.4126287698745728
Validation loss: 2.08709483842055

Epoch: 5| Step: 3
Training loss: 1.527859091758728
Validation loss: 2.0752156376838684

Epoch: 5| Step: 4
Training loss: 1.9011383056640625
Validation loss: 2.071858902772268

Epoch: 5| Step: 5
Training loss: 2.086671829223633
Validation loss: 2.1331541538238525

Epoch: 5| Step: 6
Training loss: 1.7603847980499268
Validation loss: 2.1010805567105613

Epoch: 5| Step: 7
Training loss: 2.04838228225708
Validation loss: 2.049815148115158

Epoch: 5| Step: 8
Training loss: 1.5770829916000366
Validation loss: 2.110134487350782

Epoch: 5| Step: 9
Training loss: 1.9673820734024048
Validation loss: 2.137007842461268

Epoch: 5| Step: 10
Training loss: 1.8694603443145752
Validation loss: 2.1384315192699432

Epoch: 5| Step: 11
Training loss: 1.9760605096817017
Validation loss: 2.162325402100881

Epoch: 103| Step: 0
Training loss: 1.5721080303192139
Validation loss: 2.1424980660279593

Epoch: 5| Step: 1
Training loss: 1.660517692565918
Validation loss: 2.1424093743165336

Epoch: 5| Step: 2
Training loss: 2.122331142425537
Validation loss: 2.1091301242510476

Epoch: 5| Step: 3
Training loss: 1.596824288368225
Validation loss: 2.093722571929296

Epoch: 5| Step: 4
Training loss: 1.6939704418182373
Validation loss: 2.1906575560569763

Epoch: 5| Step: 5
Training loss: 2.0058581829071045
Validation loss: 2.1304147144158683

Epoch: 5| Step: 6
Training loss: 1.8729188442230225
Validation loss: 2.1186940173308053

Epoch: 5| Step: 7
Training loss: 2.6933021545410156
Validation loss: 2.1127797414859137

Epoch: 5| Step: 8
Training loss: 1.6314910650253296
Validation loss: 2.046993484099706

Epoch: 5| Step: 9
Training loss: 1.9922641515731812
Validation loss: 2.0643069744110107

Epoch: 5| Step: 10
Training loss: 1.4462945461273193
Validation loss: 2.0869860450426736

Epoch: 5| Step: 11
Training loss: 0.5441931486129761
Validation loss: 2.079854274789492

Epoch: 104| Step: 0
Training loss: 2.5108180046081543
Validation loss: 2.079927012324333

Epoch: 5| Step: 1
Training loss: 1.558476209640503
Validation loss: 2.0935272028048835

Epoch: 5| Step: 2
Training loss: 1.919964075088501
Validation loss: 2.0407480200131736

Epoch: 5| Step: 3
Training loss: 1.9793323278427124
Validation loss: 2.043237696091334

Epoch: 5| Step: 4
Training loss: 1.191448450088501
Validation loss: 2.054669345418612

Epoch: 5| Step: 5
Training loss: 1.8803374767303467
Validation loss: 2.0809210489193597

Epoch: 5| Step: 6
Training loss: 1.5955884456634521
Validation loss: 2.0752534717321396

Epoch: 5| Step: 7
Training loss: 1.7385669946670532
Validation loss: 2.0750054518381753

Epoch: 5| Step: 8
Training loss: 1.8020856380462646
Validation loss: 2.110287234187126

Epoch: 5| Step: 9
Training loss: 1.8363046646118164
Validation loss: 2.102433721224467

Epoch: 5| Step: 10
Training loss: 2.216841220855713
Validation loss: 2.1511200219392776

Epoch: 5| Step: 11
Training loss: 1.8787860870361328
Validation loss: 2.1431159178415933

Epoch: 105| Step: 0
Training loss: 1.6843808889389038
Validation loss: 2.1061348219712577

Epoch: 5| Step: 1
Training loss: 1.5116941928863525
Validation loss: 2.118666395545006

Epoch: 5| Step: 2
Training loss: 1.875632643699646
Validation loss: 2.103277251124382

Epoch: 5| Step: 3
Training loss: 2.0069944858551025
Validation loss: 2.1166330873966217

Epoch: 5| Step: 4
Training loss: 1.9377654790878296
Validation loss: 2.098641499876976

Epoch: 5| Step: 5
Training loss: 2.165159225463867
Validation loss: 2.12444240351518

Epoch: 5| Step: 6
Training loss: 1.5097161531448364
Validation loss: 2.089569335182508

Epoch: 5| Step: 7
Training loss: 1.6743367910385132
Validation loss: 2.105856637159983

Epoch: 5| Step: 8
Training loss: 1.8323142528533936
Validation loss: 2.1125303407510123

Epoch: 5| Step: 9
Training loss: 1.5859620571136475
Validation loss: 2.113755722840627

Epoch: 5| Step: 10
Training loss: 2.0479605197906494
Validation loss: 2.091153174638748

Epoch: 5| Step: 11
Training loss: 2.691276788711548
Validation loss: 2.13588148355484

Epoch: 106| Step: 0
Training loss: 1.8925647735595703
Validation loss: 2.127759099006653

Epoch: 5| Step: 1
Training loss: 1.9146102666854858
Validation loss: 2.1096623837947845

Epoch: 5| Step: 2
Training loss: 1.4758912324905396
Validation loss: 2.083958258231481

Epoch: 5| Step: 3
Training loss: 1.4993095397949219
Validation loss: 2.076010117928187

Epoch: 5| Step: 4
Training loss: 1.5577731132507324
Validation loss: 2.0532873570919037

Epoch: 5| Step: 5
Training loss: 1.7420969009399414
Validation loss: 2.0642427851756415

Epoch: 5| Step: 6
Training loss: 1.1416723728179932
Validation loss: 2.0646541664997735

Epoch: 5| Step: 7
Training loss: 2.36732816696167
Validation loss: 2.0854759762684503

Epoch: 5| Step: 8
Training loss: 1.8137414455413818
Validation loss: 2.093845864137014

Epoch: 5| Step: 9
Training loss: 1.949415922164917
Validation loss: 2.0858287413915

Epoch: 5| Step: 10
Training loss: 2.7515830993652344
Validation loss: 2.091127182046572

Epoch: 5| Step: 11
Training loss: 2.3057522773742676
Validation loss: 2.0715534687042236

Epoch: 107| Step: 0
Training loss: 1.3013558387756348
Validation loss: 2.074719414114952

Epoch: 5| Step: 1
Training loss: 1.6995322704315186
Validation loss: 2.0908573120832443

Epoch: 5| Step: 2
Training loss: 2.1717212200164795
Validation loss: 2.1325128426154456

Epoch: 5| Step: 3
Training loss: 1.988990068435669
Validation loss: 2.0882985244194665

Epoch: 5| Step: 4
Training loss: 1.4689451456069946
Validation loss: 2.1158463756243386

Epoch: 5| Step: 5
Training loss: 2.113529682159424
Validation loss: 2.1462600578864417

Epoch: 5| Step: 6
Training loss: 2.007004976272583
Validation loss: 2.1480063249667487

Epoch: 5| Step: 7
Training loss: 2.044327974319458
Validation loss: 2.1021157950162888

Epoch: 5| Step: 8
Training loss: 1.5058202743530273
Validation loss: 2.132255415121714

Epoch: 5| Step: 9
Training loss: 2.031560182571411
Validation loss: 2.110990693171819

Epoch: 5| Step: 10
Training loss: 1.7639448642730713
Validation loss: 2.10588646431764

Epoch: 5| Step: 11
Training loss: 0.461287260055542
Validation loss: 2.0644259303808212

Epoch: 108| Step: 0
Training loss: 2.0596468448638916
Validation loss: 2.139637211958567

Epoch: 5| Step: 1
Training loss: 1.6874548196792603
Validation loss: 2.136084794998169

Epoch: 5| Step: 2
Training loss: 1.5243747234344482
Validation loss: 2.128048519293467

Epoch: 5| Step: 3
Training loss: 1.801645278930664
Validation loss: 2.141244560480118

Epoch: 5| Step: 4
Training loss: 1.8474229574203491
Validation loss: 2.179513523976008

Epoch: 5| Step: 5
Training loss: 2.0680975914001465
Validation loss: 2.141184076666832

Epoch: 5| Step: 6
Training loss: 1.4392263889312744
Validation loss: 2.085085834066073

Epoch: 5| Step: 7
Training loss: 2.3510262966156006
Validation loss: 2.1058562099933624

Epoch: 5| Step: 8
Training loss: 2.092830181121826
Validation loss: 2.0669208665688834

Epoch: 5| Step: 9
Training loss: 1.9623768329620361
Validation loss: 2.0900085816780725

Epoch: 5| Step: 10
Training loss: 1.3293979167938232
Validation loss: 2.131926308075587

Epoch: 5| Step: 11
Training loss: 1.086801290512085
Validation loss: 2.069477657477061

Epoch: 109| Step: 0
Training loss: 2.1059484481811523
Validation loss: 2.04095321893692

Epoch: 5| Step: 1
Training loss: 1.4988106489181519
Validation loss: 2.095231900612513

Epoch: 5| Step: 2
Training loss: 2.0171115398406982
Validation loss: 2.084791898727417

Epoch: 5| Step: 3
Training loss: 1.648005723953247
Validation loss: 2.0925569385290146

Epoch: 5| Step: 4
Training loss: 1.7803916931152344
Validation loss: 2.1216967900594077

Epoch: 5| Step: 5
Training loss: 1.6170718669891357
Validation loss: 2.1325805385907493

Epoch: 5| Step: 6
Training loss: 1.5217711925506592
Validation loss: 2.077151820063591

Epoch: 5| Step: 7
Training loss: 1.519683837890625
Validation loss: 2.101489389936129

Epoch: 5| Step: 8
Training loss: 1.6967744827270508
Validation loss: 2.0431295931339264

Epoch: 5| Step: 9
Training loss: 2.2024426460266113
Validation loss: 2.0922080079714456

Epoch: 5| Step: 10
Training loss: 2.15010142326355
Validation loss: 2.093786045908928

Epoch: 5| Step: 11
Training loss: 2.596839666366577
Validation loss: 2.1337439020474753

Epoch: 110| Step: 0
Training loss: 1.9003782272338867
Validation loss: 2.074036176005999

Epoch: 5| Step: 1
Training loss: 1.6572177410125732
Validation loss: 2.076499581336975

Epoch: 5| Step: 2
Training loss: 1.0302178859710693
Validation loss: 2.123387341698011

Epoch: 5| Step: 3
Training loss: 1.7231426239013672
Validation loss: 2.0992488265037537

Epoch: 5| Step: 4
Training loss: 1.9033443927764893
Validation loss: 2.0983762741088867

Epoch: 5| Step: 5
Training loss: 2.4494757652282715
Validation loss: 2.055657575527827

Epoch: 5| Step: 6
Training loss: 2.0759365558624268
Validation loss: 2.081792106231054

Epoch: 5| Step: 7
Training loss: 1.985232949256897
Validation loss: 2.084077517191569

Epoch: 5| Step: 8
Training loss: 1.6818252801895142
Validation loss: 2.1140022029479346

Epoch: 5| Step: 9
Training loss: 1.5238784551620483
Validation loss: 2.0615284740924835

Epoch: 5| Step: 10
Training loss: 2.037879228591919
Validation loss: 2.1314940998951593

Epoch: 5| Step: 11
Training loss: 1.1472399234771729
Validation loss: 2.0760933309793472

Epoch: 111| Step: 0
Training loss: 1.5682384967803955
Validation loss: 2.080834537744522

Epoch: 5| Step: 1
Training loss: 1.6230064630508423
Validation loss: 2.0810826619466147

Epoch: 5| Step: 2
Training loss: 1.8051341772079468
Validation loss: 2.097567915916443

Epoch: 5| Step: 3
Training loss: 1.752086877822876
Validation loss: 2.0979604770739875

Epoch: 5| Step: 4
Training loss: 2.165684938430786
Validation loss: 2.1096556087334952

Epoch: 5| Step: 5
Training loss: 1.8784259557724
Validation loss: 2.135652542114258

Epoch: 5| Step: 6
Training loss: 1.943751573562622
Validation loss: 2.1348829617102942

Epoch: 5| Step: 7
Training loss: 1.8714176416397095
Validation loss: 2.0855023662249246

Epoch: 5| Step: 8
Training loss: 1.7465770244598389
Validation loss: 2.114763393998146

Epoch: 5| Step: 9
Training loss: 1.2594808340072632
Validation loss: 2.0558887223402658

Epoch: 5| Step: 10
Training loss: 1.9570467472076416
Validation loss: 2.0814952701330185

Epoch: 5| Step: 11
Training loss: 1.2683417797088623
Validation loss: 2.1095200181007385

Epoch: 112| Step: 0
Training loss: 2.124946355819702
Validation loss: 2.0900500367085137

Epoch: 5| Step: 1
Training loss: 1.9076728820800781
Validation loss: 2.0516925950845084

Epoch: 5| Step: 2
Training loss: 1.803210973739624
Validation loss: 2.063494930664698

Epoch: 5| Step: 3
Training loss: 1.2402448654174805
Validation loss: 2.041559025645256

Epoch: 5| Step: 4
Training loss: 1.9694509506225586
Validation loss: 2.105116292834282

Epoch: 5| Step: 5
Training loss: 2.016340970993042
Validation loss: 2.0943194031715393

Epoch: 5| Step: 6
Training loss: 1.6673263311386108
Validation loss: 2.0679167807102203

Epoch: 5| Step: 7
Training loss: 1.8787647485733032
Validation loss: 2.128337879975637

Epoch: 5| Step: 8
Training loss: 1.5405336618423462
Validation loss: 2.102934872110685

Epoch: 5| Step: 9
Training loss: 2.0843851566314697
Validation loss: 2.083464960257212

Epoch: 5| Step: 10
Training loss: 1.5300804376602173
Validation loss: 2.121956765651703

Epoch: 5| Step: 11
Training loss: 3.6311535835266113
Validation loss: 2.114931325117747

Epoch: 113| Step: 0
Training loss: 1.9544874429702759
Validation loss: 2.1111468573411307

Epoch: 5| Step: 1
Training loss: 1.3204238414764404
Validation loss: 2.1458254009485245

Epoch: 5| Step: 2
Training loss: 2.1986923217773438
Validation loss: 2.133609354496002

Epoch: 5| Step: 3
Training loss: 1.5828628540039062
Validation loss: 2.125641485055288

Epoch: 5| Step: 4
Training loss: 1.6385408639907837
Validation loss: 2.1658012668291726

Epoch: 5| Step: 5
Training loss: 2.3715639114379883
Validation loss: 2.1547480821609497

Epoch: 5| Step: 6
Training loss: 1.6139637231826782
Validation loss: 2.1370481302340827

Epoch: 5| Step: 7
Training loss: 1.8231481313705444
Validation loss: 2.1452903052171073

Epoch: 5| Step: 8
Training loss: 1.9952974319458008
Validation loss: 2.098177363475164

Epoch: 5| Step: 9
Training loss: 1.7562370300292969
Validation loss: 2.0873443434635797

Epoch: 5| Step: 10
Training loss: 1.6376186609268188
Validation loss: 2.0737723857164383

Epoch: 5| Step: 11
Training loss: 2.4769608974456787
Validation loss: 2.089426333705584

Epoch: 114| Step: 0
Training loss: 1.911869764328003
Validation loss: 2.066450814406077

Epoch: 5| Step: 1
Training loss: 1.6512157917022705
Validation loss: 2.076734950145086

Epoch: 5| Step: 2
Training loss: 1.5895878076553345
Validation loss: 2.05606480439504

Epoch: 5| Step: 3
Training loss: 1.7614548206329346
Validation loss: 2.11088935037454

Epoch: 5| Step: 4
Training loss: 2.1956653594970703
Validation loss: 2.1285253514846167

Epoch: 5| Step: 5
Training loss: 1.6458370685577393
Validation loss: 2.1139735033114753

Epoch: 5| Step: 6
Training loss: 2.073667049407959
Validation loss: 2.105293944478035

Epoch: 5| Step: 7
Training loss: 1.657812476158142
Validation loss: 2.073692192633947

Epoch: 5| Step: 8
Training loss: 1.8469784259796143
Validation loss: 2.0936081409454346

Epoch: 5| Step: 9
Training loss: 1.75140380859375
Validation loss: 2.099340721964836

Epoch: 5| Step: 10
Training loss: 1.6792519092559814
Validation loss: 2.1102616836627326

Epoch: 5| Step: 11
Training loss: 2.252500534057617
Validation loss: 2.1110969136158624

Epoch: 115| Step: 0
Training loss: 1.4887479543685913
Validation loss: 2.1243519286314645

Epoch: 5| Step: 1
Training loss: 1.9103657007217407
Validation loss: 2.0997890730698905

Epoch: 5| Step: 2
Training loss: 1.4910849332809448
Validation loss: 2.1171364337205887

Epoch: 5| Step: 3
Training loss: 2.0128321647644043
Validation loss: 2.099982519944509

Epoch: 5| Step: 4
Training loss: 2.3134849071502686
Validation loss: 2.0742799937725067

Epoch: 5| Step: 5
Training loss: 1.6515157222747803
Validation loss: 2.0904658983151116

Epoch: 5| Step: 6
Training loss: 1.5119705200195312
Validation loss: 2.060167113939921

Epoch: 5| Step: 7
Training loss: 1.7152907848358154
Validation loss: 2.076744094491005

Epoch: 5| Step: 8
Training loss: 1.7883796691894531
Validation loss: 2.1067322194576263

Epoch: 5| Step: 9
Training loss: 2.1135504245758057
Validation loss: 2.1194570511579514

Epoch: 5| Step: 10
Training loss: 1.6828782558441162
Validation loss: 2.0937795639038086

Epoch: 5| Step: 11
Training loss: 1.223572850227356
Validation loss: 2.1052424808343253

Epoch: 116| Step: 0
Training loss: 2.069598436355591
Validation loss: 2.0885374198357263

Epoch: 5| Step: 1
Training loss: 1.680428147315979
Validation loss: 2.0904993613560996

Epoch: 5| Step: 2
Training loss: 1.804949164390564
Validation loss: 2.0688980569442115

Epoch: 5| Step: 3
Training loss: 1.547305703163147
Validation loss: 2.042284737030665

Epoch: 5| Step: 4
Training loss: 1.6101967096328735
Validation loss: 2.0577573428551355

Epoch: 5| Step: 5
Training loss: 2.7444539070129395
Validation loss: 2.097844883799553

Epoch: 5| Step: 6
Training loss: 1.845754623413086
Validation loss: 2.106489991148313

Epoch: 5| Step: 7
Training loss: 1.2528146505355835
Validation loss: 2.0918711572885513

Epoch: 5| Step: 8
Training loss: 1.3948090076446533
Validation loss: 2.0843212554852166

Epoch: 5| Step: 9
Training loss: 1.930739164352417
Validation loss: 2.098809445897738

Epoch: 5| Step: 10
Training loss: 1.5143098831176758
Validation loss: 2.047883555293083

Epoch: 5| Step: 11
Training loss: 1.640275239944458
Validation loss: 2.100249543786049

Epoch: 117| Step: 0
Training loss: 1.340868592262268
Validation loss: 2.137296254436175

Epoch: 5| Step: 1
Training loss: 2.368377208709717
Validation loss: 2.1559952398141227

Epoch: 5| Step: 2
Training loss: 1.7291027307510376
Validation loss: 2.098227317134539

Epoch: 5| Step: 3
Training loss: 1.6624572277069092
Validation loss: 2.1231688410043716

Epoch: 5| Step: 4
Training loss: 1.8244287967681885
Validation loss: 2.1487777332464852

Epoch: 5| Step: 5
Training loss: 2.0691301822662354
Validation loss: 2.148282532890638

Epoch: 5| Step: 6
Training loss: 1.5551674365997314
Validation loss: 2.135546093185743

Epoch: 5| Step: 7
Training loss: 1.4062764644622803
Validation loss: 2.147925078868866

Epoch: 5| Step: 8
Training loss: 1.6390968561172485
Validation loss: 2.0947559624910355

Epoch: 5| Step: 9
Training loss: 2.2657694816589355
Validation loss: 2.0865072955687842

Epoch: 5| Step: 10
Training loss: 1.3872599601745605
Validation loss: 2.1167962700128555

Epoch: 5| Step: 11
Training loss: 3.057666301727295
Validation loss: 2.0604257037242255

Epoch: 118| Step: 0
Training loss: 1.704146385192871
Validation loss: 2.0705969582001367

Epoch: 5| Step: 1
Training loss: 2.1190311908721924
Validation loss: 2.0590448081493378

Epoch: 5| Step: 2
Training loss: 1.5879106521606445
Validation loss: 2.1047969609498978

Epoch: 5| Step: 3
Training loss: 1.4520350694656372
Validation loss: 2.073976809779803

Epoch: 5| Step: 4
Training loss: 2.0028164386749268
Validation loss: 2.0821191320816674

Epoch: 5| Step: 5
Training loss: 1.8261781930923462
Validation loss: 2.062653308113416

Epoch: 5| Step: 6
Training loss: 1.8933614492416382
Validation loss: 2.0338218609491983

Epoch: 5| Step: 7
Training loss: 1.5331482887268066
Validation loss: 2.0635140389204025

Epoch: 5| Step: 8
Training loss: 2.0197720527648926
Validation loss: 2.025540381669998

Epoch: 5| Step: 9
Training loss: 2.3616416454315186
Validation loss: 2.0707860440015793

Epoch: 5| Step: 10
Training loss: 1.6336933374404907
Validation loss: 2.048933580517769

Epoch: 5| Step: 11
Training loss: 1.5569109916687012
Validation loss: 2.1606531143188477

Epoch: 119| Step: 0
Training loss: 1.744951605796814
Validation loss: 2.127841075261434

Epoch: 5| Step: 1
Training loss: 1.4770944118499756
Validation loss: 2.0951752165953317

Epoch: 5| Step: 2
Training loss: 2.2672388553619385
Validation loss: 2.104084928830465

Epoch: 5| Step: 3
Training loss: 1.4794342517852783
Validation loss: 2.142520676056544

Epoch: 5| Step: 4
Training loss: 1.918701171875
Validation loss: 2.128403812646866

Epoch: 5| Step: 5
Training loss: 2.125331401824951
Validation loss: 2.1062537680069604

Epoch: 5| Step: 6
Training loss: 1.6067821979522705
Validation loss: 2.1121782263120017

Epoch: 5| Step: 7
Training loss: 1.812422513961792
Validation loss: 2.102100759744644

Epoch: 5| Step: 8
Training loss: 1.8216125965118408
Validation loss: 2.0892886320749917

Epoch: 5| Step: 9
Training loss: 1.635244369506836
Validation loss: 2.1080261369546256

Epoch: 5| Step: 10
Training loss: 1.733620047569275
Validation loss: 2.092251936594645

Epoch: 5| Step: 11
Training loss: 0.5251860618591309
Validation loss: 2.060860718290011

Epoch: 120| Step: 0
Training loss: 1.7275125980377197
Validation loss: 2.062435587247213

Epoch: 5| Step: 1
Training loss: 1.4970722198486328
Validation loss: 2.095760236183802

Epoch: 5| Step: 2
Training loss: 1.5464389324188232
Validation loss: 2.123228838046392

Epoch: 5| Step: 3
Training loss: 2.4610540866851807
Validation loss: 2.113528460264206

Epoch: 5| Step: 4
Training loss: 1.8306219577789307
Validation loss: 2.1287036736806235

Epoch: 5| Step: 5
Training loss: 1.3748544454574585
Validation loss: 2.1266984889904657

Epoch: 5| Step: 6
Training loss: 1.6845906972885132
Validation loss: 2.10630264878273

Epoch: 5| Step: 7
Training loss: 1.6304314136505127
Validation loss: 2.1413048853476844

Epoch: 5| Step: 8
Training loss: 2.6158835887908936
Validation loss: 2.117041418949763

Epoch: 5| Step: 9
Training loss: 1.5988141298294067
Validation loss: 2.0729304204384484

Epoch: 5| Step: 10
Training loss: 1.213590383529663
Validation loss: 2.138163005312284

Epoch: 5| Step: 11
Training loss: 1.9225308895111084
Validation loss: 2.131807650129

Epoch: 121| Step: 0
Training loss: 1.8448102474212646
Validation loss: 2.10572915772597

Epoch: 5| Step: 1
Training loss: 2.1671853065490723
Validation loss: 2.125992923974991

Epoch: 5| Step: 2
Training loss: 1.1631654500961304
Validation loss: 2.1609502186377845

Epoch: 5| Step: 3
Training loss: 1.7814220190048218
Validation loss: 2.154267430305481

Epoch: 5| Step: 4
Training loss: 2.365018844604492
Validation loss: 2.11583582063516

Epoch: 5| Step: 5
Training loss: 2.0355398654937744
Validation loss: 2.0796704391638436

Epoch: 5| Step: 6
Training loss: 1.7474339008331299
Validation loss: 2.0882792274157205

Epoch: 5| Step: 7
Training loss: 1.2884278297424316
Validation loss: 2.0949910829464593

Epoch: 5| Step: 8
Training loss: 1.6365070343017578
Validation loss: 2.0691440453131995

Epoch: 5| Step: 9
Training loss: 1.488940954208374
Validation loss: 2.115390737851461

Epoch: 5| Step: 10
Training loss: 1.7359542846679688
Validation loss: 2.0906962056954703

Epoch: 5| Step: 11
Training loss: 1.157923936843872
Validation loss: 2.0932938208182654

Epoch: 122| Step: 0
Training loss: 2.2235405445098877
Validation loss: 2.0941918989022574

Epoch: 5| Step: 1
Training loss: 1.479163408279419
Validation loss: 2.0757144143184028

Epoch: 5| Step: 2
Training loss: 1.2729090452194214
Validation loss: 2.0906167725721994

Epoch: 5| Step: 3
Training loss: 2.123603343963623
Validation loss: 2.100669801235199

Epoch: 5| Step: 4
Training loss: 1.208373785018921
Validation loss: 2.072792927424113

Epoch: 5| Step: 5
Training loss: 1.8560197353363037
Validation loss: 2.0554272135098777

Epoch: 5| Step: 6
Training loss: 2.178712844848633
Validation loss: 2.103379795948664

Epoch: 5| Step: 7
Training loss: 1.6717240810394287
Validation loss: 2.0765312860409417

Epoch: 5| Step: 8
Training loss: 1.8230184316635132
Validation loss: 2.085108295083046

Epoch: 5| Step: 9
Training loss: 1.6401586532592773
Validation loss: 2.0957041233778

Epoch: 5| Step: 10
Training loss: 1.4500868320465088
Validation loss: 2.1240771214167276

Epoch: 5| Step: 11
Training loss: 2.013439893722534
Validation loss: 2.100073277950287

Epoch: 123| Step: 0
Training loss: 1.3413236141204834
Validation loss: 2.082586392760277

Epoch: 5| Step: 1
Training loss: 1.706203818321228
Validation loss: 2.0999805380900702

Epoch: 5| Step: 2
Training loss: 1.5429023504257202
Validation loss: 2.101822927594185

Epoch: 5| Step: 3
Training loss: 1.7720085382461548
Validation loss: 2.070038934548696

Epoch: 5| Step: 4
Training loss: 1.4531046152114868
Validation loss: 2.0798548758029938

Epoch: 5| Step: 5
Training loss: 1.7708680629730225
Validation loss: 2.0743869841098785

Epoch: 5| Step: 6
Training loss: 1.6008422374725342
Validation loss: 2.088582535584768

Epoch: 5| Step: 7
Training loss: 1.5245306491851807
Validation loss: 2.1322027842203775

Epoch: 5| Step: 8
Training loss: 2.2184062004089355
Validation loss: 2.1128355264663696

Epoch: 5| Step: 9
Training loss: 2.281585693359375
Validation loss: 2.1080702592929206

Epoch: 5| Step: 10
Training loss: 1.9593740701675415
Validation loss: 2.131980538368225

Epoch: 5| Step: 11
Training loss: 1.0557427406311035
Validation loss: 2.0736275613307953

Epoch: 124| Step: 0
Training loss: 1.6913076639175415
Validation loss: 2.116132770975431

Epoch: 5| Step: 1
Training loss: 1.8984792232513428
Validation loss: 2.110519841313362

Epoch: 5| Step: 2
Training loss: 1.333423376083374
Validation loss: 2.1573359121878943

Epoch: 5| Step: 3
Training loss: 1.7445663213729858
Validation loss: 2.1004818926254907

Epoch: 5| Step: 4
Training loss: 2.3636245727539062
Validation loss: 2.089142913619677

Epoch: 5| Step: 5
Training loss: 1.5167100429534912
Validation loss: 2.0853190422058105

Epoch: 5| Step: 6
Training loss: 1.615465521812439
Validation loss: 2.052557880679766

Epoch: 5| Step: 7
Training loss: 1.973791480064392
Validation loss: 2.1021838386853537

Epoch: 5| Step: 8
Training loss: 1.7976917028427124
Validation loss: 2.1245018194119134

Epoch: 5| Step: 9
Training loss: 1.2291182279586792
Validation loss: 2.078718195358912

Epoch: 5| Step: 10
Training loss: 2.4130630493164062
Validation loss: 2.0995957801739373

Epoch: 5| Step: 11
Training loss: 0.6428107619285583
Validation loss: 2.0777306854724884

Epoch: 125| Step: 0
Training loss: 2.03385329246521
Validation loss: 2.0787464380264282

Epoch: 5| Step: 1
Training loss: 2.048631191253662
Validation loss: 2.0539135485887527

Epoch: 5| Step: 2
Training loss: 2.441556453704834
Validation loss: 2.11861914396286

Epoch: 5| Step: 3
Training loss: 1.8317210674285889
Validation loss: 2.123597631851832

Epoch: 5| Step: 4
Training loss: 1.4595685005187988
Validation loss: 2.089264820019404

Epoch: 5| Step: 5
Training loss: 1.7776250839233398
Validation loss: 2.08837121228377

Epoch: 5| Step: 6
Training loss: 1.3981878757476807
Validation loss: 2.0812265823284783

Epoch: 5| Step: 7
Training loss: 1.4740817546844482
Validation loss: 2.148828665415446

Epoch: 5| Step: 8
Training loss: 1.6666386127471924
Validation loss: 2.1276670346657434

Epoch: 5| Step: 9
Training loss: 1.328811764717102
Validation loss: 2.124913444121679

Epoch: 5| Step: 10
Training loss: 1.3203794956207275
Validation loss: 2.1644640068213143

Epoch: 5| Step: 11
Training loss: 0.8183612823486328
Validation loss: 2.1068709095319114

Epoch: 126| Step: 0
Training loss: 2.219954013824463
Validation loss: 2.129770720998446

Epoch: 5| Step: 1
Training loss: 1.1443061828613281
Validation loss: 2.1205702225367227

Epoch: 5| Step: 2
Training loss: 2.2314743995666504
Validation loss: 2.1065770437320075

Epoch: 5| Step: 3
Training loss: 1.5498539209365845
Validation loss: 2.121027633547783

Epoch: 5| Step: 4
Training loss: 2.1256930828094482
Validation loss: 2.1167846570412316

Epoch: 5| Step: 5
Training loss: 1.2951595783233643
Validation loss: 2.0987374583880105

Epoch: 5| Step: 6
Training loss: 1.4372248649597168
Validation loss: 2.100833088159561

Epoch: 5| Step: 7
Training loss: 1.5857212543487549
Validation loss: 2.14721243083477

Epoch: 5| Step: 8
Training loss: 1.5514276027679443
Validation loss: 2.135560929775238

Epoch: 5| Step: 9
Training loss: 1.5731948614120483
Validation loss: 2.112193912267685

Epoch: 5| Step: 10
Training loss: 1.6428277492523193
Validation loss: 2.1155894050995507

Epoch: 5| Step: 11
Training loss: 2.645838737487793
Validation loss: 2.089852586388588

Epoch: 127| Step: 0
Training loss: 1.412385106086731
Validation loss: 2.0837595214446387

Epoch: 5| Step: 1
Training loss: 1.4747676849365234
Validation loss: 2.0890287905931473

Epoch: 5| Step: 2
Training loss: 1.8017879724502563
Validation loss: 2.1036976228157678

Epoch: 5| Step: 3
Training loss: 1.7224376201629639
Validation loss: 2.1102751344442368

Epoch: 5| Step: 4
Training loss: 2.2410473823547363
Validation loss: 2.0599626352389655

Epoch: 5| Step: 5
Training loss: 1.382581353187561
Validation loss: 2.1161861966053643

Epoch: 5| Step: 6
Training loss: 1.9807029962539673
Validation loss: 2.107005620996157

Epoch: 5| Step: 7
Training loss: 1.3391697406768799
Validation loss: 2.1134092609087625

Epoch: 5| Step: 8
Training loss: 1.7393594980239868
Validation loss: 2.090884953737259

Epoch: 5| Step: 9
Training loss: 1.5172685384750366
Validation loss: 2.1049887438615165

Epoch: 5| Step: 10
Training loss: 2.1705596446990967
Validation loss: 2.0965818812449775

Epoch: 5| Step: 11
Training loss: 1.3612796068191528
Validation loss: 2.0966172019640603

Epoch: 128| Step: 0
Training loss: 1.6233621835708618
Validation loss: 2.09146186709404

Epoch: 5| Step: 1
Training loss: 1.263961672782898
Validation loss: 2.0662321547667184

Epoch: 5| Step: 2
Training loss: 1.7243191003799438
Validation loss: 2.0872377852598825

Epoch: 5| Step: 3
Training loss: 2.187293291091919
Validation loss: 2.0773039857546487

Epoch: 5| Step: 4
Training loss: 1.6052703857421875
Validation loss: 2.0704649140437446

Epoch: 5| Step: 5
Training loss: 1.7310857772827148
Validation loss: 2.1372900754213333

Epoch: 5| Step: 6
Training loss: 1.8108091354370117
Validation loss: 2.08317365248998

Epoch: 5| Step: 7
Training loss: 1.8520219326019287
Validation loss: 2.1367945472399392

Epoch: 5| Step: 8
Training loss: 1.6399377584457397
Validation loss: 2.0891045331954956

Epoch: 5| Step: 9
Training loss: 1.6284754276275635
Validation loss: 2.1055035491784415

Epoch: 5| Step: 10
Training loss: 1.9206691980361938
Validation loss: 2.112133204936981

Epoch: 5| Step: 11
Training loss: 1.2515969276428223
Validation loss: 2.0695684452851615

Epoch: 129| Step: 0
Training loss: 1.4739747047424316
Validation loss: 2.0977900524934134

Epoch: 5| Step: 1
Training loss: 1.8457788228988647
Validation loss: 2.0709709376096725

Epoch: 5| Step: 2
Training loss: 1.5922342538833618
Validation loss: 2.0748010327418647

Epoch: 5| Step: 3
Training loss: 1.4395530223846436
Validation loss: 2.06986103951931

Epoch: 5| Step: 4
Training loss: 1.9372942447662354
Validation loss: 2.1156129787365594

Epoch: 5| Step: 5
Training loss: 1.8283441066741943
Validation loss: 2.0773991296688714

Epoch: 5| Step: 6
Training loss: 0.9998952746391296
Validation loss: 2.063123881816864

Epoch: 5| Step: 7
Training loss: 1.7252838611602783
Validation loss: 2.0736159483591714

Epoch: 5| Step: 8
Training loss: 1.6170241832733154
Validation loss: 2.0817565421263375

Epoch: 5| Step: 9
Training loss: 1.749685287475586
Validation loss: 2.0490015794833503

Epoch: 5| Step: 10
Training loss: 2.3347041606903076
Validation loss: 2.116769959529241

Epoch: 5| Step: 11
Training loss: 1.589287519454956
Validation loss: 2.1386112173398337

Epoch: 130| Step: 0
Training loss: 1.671338677406311
Validation loss: 2.1065262307723365

Epoch: 5| Step: 1
Training loss: 1.8446743488311768
Validation loss: 2.1186266044775643

Epoch: 5| Step: 2
Training loss: 2.4228389263153076
Validation loss: 2.09568423529466

Epoch: 5| Step: 3
Training loss: 1.5192046165466309
Validation loss: 2.108419269323349

Epoch: 5| Step: 4
Training loss: 1.51809561252594
Validation loss: 2.1844826390345893

Epoch: 5| Step: 5
Training loss: 1.430403709411621
Validation loss: 2.159291868408521

Epoch: 5| Step: 6
Training loss: 1.7512966394424438
Validation loss: 2.1318969378868737

Epoch: 5| Step: 7
Training loss: 1.5845932960510254
Validation loss: 2.1265172511339188

Epoch: 5| Step: 8
Training loss: 1.4422105550765991
Validation loss: 2.1045049329598746

Epoch: 5| Step: 9
Training loss: 1.7600078582763672
Validation loss: 2.0629980017741523

Epoch: 5| Step: 10
Training loss: 1.8470828533172607
Validation loss: 2.061913604537646

Epoch: 5| Step: 11
Training loss: 0.7150234580039978
Validation loss: 2.0944337050120034

Epoch: 131| Step: 0
Training loss: 1.8488270044326782
Validation loss: 2.0958579828341803

Epoch: 5| Step: 1
Training loss: 1.5103230476379395
Validation loss: 2.086468676726023

Epoch: 5| Step: 2
Training loss: 1.5357860326766968
Validation loss: 2.0690148820479712

Epoch: 5| Step: 3
Training loss: 1.8644075393676758
Validation loss: 2.115755637486776

Epoch: 5| Step: 4
Training loss: 1.5355253219604492
Validation loss: 2.065110221505165

Epoch: 5| Step: 5
Training loss: 1.7377846240997314
Validation loss: 2.1090045670668283

Epoch: 5| Step: 6
Training loss: 1.6968657970428467
Validation loss: 2.0851045002539954

Epoch: 5| Step: 7
Training loss: 1.367974877357483
Validation loss: 2.0720309168100357

Epoch: 5| Step: 8
Training loss: 1.5957980155944824
Validation loss: 2.1544811725616455

Epoch: 5| Step: 9
Training loss: 2.008730173110962
Validation loss: 2.1553771793842316

Epoch: 5| Step: 10
Training loss: 1.5056244134902954
Validation loss: 2.1243431021769843

Epoch: 5| Step: 11
Training loss: 2.35451078414917
Validation loss: 2.1541689733664193

Epoch: 132| Step: 0
Training loss: 1.6136337518692017
Validation loss: 2.1259413758913674

Epoch: 5| Step: 1
Training loss: 1.342256784439087
Validation loss: 2.1360780398050943

Epoch: 5| Step: 2
Training loss: 1.2821826934814453
Validation loss: 2.0930947015682855

Epoch: 5| Step: 3
Training loss: 1.6809465885162354
Validation loss: 2.0950403263171515

Epoch: 5| Step: 4
Training loss: 1.4266724586486816
Validation loss: 2.0899932185808816

Epoch: 5| Step: 5
Training loss: 2.093794584274292
Validation loss: 2.1267920633157096

Epoch: 5| Step: 6
Training loss: 1.7025272846221924
Validation loss: 2.1031117836634317

Epoch: 5| Step: 7
Training loss: 2.100053071975708
Validation loss: 2.070169980327288

Epoch: 5| Step: 8
Training loss: 2.2428956031799316
Validation loss: 2.138973221182823

Epoch: 5| Step: 9
Training loss: 1.5919485092163086
Validation loss: 2.0883444448312125

Epoch: 5| Step: 10
Training loss: 1.8100417852401733
Validation loss: 2.1084889521201453

Epoch: 5| Step: 11
Training loss: 1.2668747901916504
Validation loss: 2.1067555199066796

Epoch: 133| Step: 0
Training loss: 2.088236093521118
Validation loss: 2.143199930588404

Epoch: 5| Step: 1
Training loss: 1.7792736291885376
Validation loss: 2.093398322661718

Epoch: 5| Step: 2
Training loss: 1.4012476205825806
Validation loss: 2.054088811079661

Epoch: 5| Step: 3
Training loss: 2.0044949054718018
Validation loss: 2.0904333790143332

Epoch: 5| Step: 4
Training loss: 1.2753933668136597
Validation loss: 2.0613968620697656

Epoch: 5| Step: 5
Training loss: 0.9545990824699402
Validation loss: 2.133599797884623

Epoch: 5| Step: 6
Training loss: 1.4347445964813232
Validation loss: 2.067497968673706

Epoch: 5| Step: 7
Training loss: 1.052475929260254
Validation loss: 2.166308502356211

Epoch: 5| Step: 8
Training loss: 1.8567899465560913
Validation loss: 2.080637459953626

Epoch: 5| Step: 9
Training loss: 2.5609354972839355
Validation loss: 2.1202906171480813

Epoch: 5| Step: 10
Training loss: 2.037306308746338
Validation loss: 2.086389352877935

Epoch: 5| Step: 11
Training loss: 0.5312496423721313
Validation loss: 2.0924665133158364

Epoch: 134| Step: 0
Training loss: 1.3141744136810303
Validation loss: 2.1384532352288566

Epoch: 5| Step: 1
Training loss: 1.8709571361541748
Validation loss: 2.084975317120552

Epoch: 5| Step: 2
Training loss: 1.945709228515625
Validation loss: 2.058048889040947

Epoch: 5| Step: 3
Training loss: 1.9737794399261475
Validation loss: 2.068374380469322

Epoch: 5| Step: 4
Training loss: 1.123961091041565
Validation loss: 2.1028248171011605

Epoch: 5| Step: 5
Training loss: 1.5944898128509521
Validation loss: 2.108094573020935

Epoch: 5| Step: 6
Training loss: 2.25557541847229
Validation loss: 2.1000904192527137

Epoch: 5| Step: 7
Training loss: 1.8159888982772827
Validation loss: 2.1152115166187286

Epoch: 5| Step: 8
Training loss: 1.9458379745483398
Validation loss: 2.0413359701633453

Epoch: 5| Step: 9
Training loss: 1.9117228984832764
Validation loss: 2.095383942127228

Epoch: 5| Step: 10
Training loss: 1.5800634622573853
Validation loss: 2.107040892044703

Epoch: 5| Step: 11
Training loss: 0.1253821849822998
Validation loss: 2.1187642415364585

Epoch: 135| Step: 0
Training loss: 1.7187683582305908
Validation loss: 2.105046341816584

Epoch: 5| Step: 1
Training loss: 1.7290242910385132
Validation loss: 2.135029191772143

Epoch: 5| Step: 2
Training loss: 1.4552581310272217
Validation loss: 2.1709961593151093

Epoch: 5| Step: 3
Training loss: 1.7512712478637695
Validation loss: 2.2106778671344123

Epoch: 5| Step: 4
Training loss: 1.4364101886749268
Validation loss: 2.228048160672188

Epoch: 5| Step: 5
Training loss: 1.8381496667861938
Validation loss: 2.2348139037688575

Epoch: 5| Step: 6
Training loss: 1.9275175333023071
Validation loss: 2.177660425504049

Epoch: 5| Step: 7
Training loss: 2.230727195739746
Validation loss: 2.167213504513105

Epoch: 5| Step: 8
Training loss: 1.4947298765182495
Validation loss: 2.1130149314800897

Epoch: 5| Step: 9
Training loss: 1.903074026107788
Validation loss: 2.096013824144999

Epoch: 5| Step: 10
Training loss: 1.1397536993026733
Validation loss: 2.1026409516731897

Epoch: 5| Step: 11
Training loss: 2.400899648666382
Validation loss: 2.115319455663363

Epoch: 136| Step: 0
Training loss: 1.7661113739013672
Validation loss: 2.078871935606003

Epoch: 5| Step: 1
Training loss: 1.4355586767196655
Validation loss: 2.106207405527433

Epoch: 5| Step: 2
Training loss: 2.3452916145324707
Validation loss: 2.0901774764060974

Epoch: 5| Step: 3
Training loss: 2.03019380569458
Validation loss: 2.0842306514581046

Epoch: 5| Step: 4
Training loss: 1.7082979679107666
Validation loss: 2.0855967551469803

Epoch: 5| Step: 5
Training loss: 1.5602799654006958
Validation loss: 2.1124534557263055

Epoch: 5| Step: 6
Training loss: 2.0079073905944824
Validation loss: 2.1195332457621894

Epoch: 5| Step: 7
Training loss: 1.2335948944091797
Validation loss: 2.126228764653206

Epoch: 5| Step: 8
Training loss: 1.0915660858154297
Validation loss: 2.0796158810456595

Epoch: 5| Step: 9
Training loss: 1.899735450744629
Validation loss: 2.1080117473999658

Epoch: 5| Step: 10
Training loss: 1.5446388721466064
Validation loss: 2.14167121052742

Epoch: 5| Step: 11
Training loss: 1.5951306819915771
Validation loss: 2.104398642977079

Epoch: 137| Step: 0
Training loss: 1.9628992080688477
Validation loss: 2.1984797418117523

Epoch: 5| Step: 1
Training loss: 1.5218925476074219
Validation loss: 2.191178649663925

Epoch: 5| Step: 2
Training loss: 1.8844108581542969
Validation loss: 2.1854435255130134

Epoch: 5| Step: 3
Training loss: 2.0949161052703857
Validation loss: 2.2474150160948434

Epoch: 5| Step: 4
Training loss: 1.4353094100952148
Validation loss: 2.2369115948677063

Epoch: 5| Step: 5
Training loss: 2.2099337577819824
Validation loss: 2.197542125980059

Epoch: 5| Step: 6
Training loss: 1.4610865116119385
Validation loss: 2.129240850607554

Epoch: 5| Step: 7
Training loss: 1.4190905094146729
Validation loss: 2.1155558129151664

Epoch: 5| Step: 8
Training loss: 1.2325267791748047
Validation loss: 2.1013048390547433

Epoch: 5| Step: 9
Training loss: 1.6037225723266602
Validation loss: 2.1057647317647934

Epoch: 5| Step: 10
Training loss: 1.7038652896881104
Validation loss: 2.1290285090605416

Epoch: 5| Step: 11
Training loss: 1.4636532068252563
Validation loss: 2.0994452983140945

Epoch: 138| Step: 0
Training loss: 2.2701897621154785
Validation loss: 2.0697487394014993

Epoch: 5| Step: 1
Training loss: 1.678816795349121
Validation loss: 2.055088301499685

Epoch: 5| Step: 2
Training loss: 1.6277334690093994
Validation loss: 2.064574177066485

Epoch: 5| Step: 3
Training loss: 1.2749288082122803
Validation loss: 2.107282986243566

Epoch: 5| Step: 4
Training loss: 1.7385177612304688
Validation loss: 2.091414213180542

Epoch: 5| Step: 5
Training loss: 1.707632064819336
Validation loss: 2.089124028881391

Epoch: 5| Step: 6
Training loss: 1.7810814380645752
Validation loss: 2.129897112647692

Epoch: 5| Step: 7
Training loss: 1.7269264459609985
Validation loss: 2.110093663136164

Epoch: 5| Step: 8
Training loss: 1.3825269937515259
Validation loss: 2.153859863678614

Epoch: 5| Step: 9
Training loss: 1.581447720527649
Validation loss: 2.143399879336357

Epoch: 5| Step: 10
Training loss: 1.6353833675384521
Validation loss: 2.167757973074913

Epoch: 5| Step: 11
Training loss: 0.7939263582229614
Validation loss: 2.125488966703415

Epoch: 139| Step: 0
Training loss: 1.6007118225097656
Validation loss: 2.170327747861544

Epoch: 5| Step: 1
Training loss: 1.4093269109725952
Validation loss: 2.142745614051819

Epoch: 5| Step: 2
Training loss: 1.1584017276763916
Validation loss: 2.162655050555865

Epoch: 5| Step: 3
Training loss: 1.679836630821228
Validation loss: 2.1335336615641913

Epoch: 5| Step: 4
Training loss: 1.8425410985946655
Validation loss: 2.047748630245527

Epoch: 5| Step: 5
Training loss: 2.4859230518341064
Validation loss: 2.1283323566118875

Epoch: 5| Step: 6
Training loss: 1.5179997682571411
Validation loss: 2.1122650603453317

Epoch: 5| Step: 7
Training loss: 1.273308515548706
Validation loss: 2.1324401597181954

Epoch: 5| Step: 8
Training loss: 1.1610782146453857
Validation loss: 2.126435990134875

Epoch: 5| Step: 9
Training loss: 2.1808829307556152
Validation loss: 2.107715437809626

Epoch: 5| Step: 10
Training loss: 1.6396703720092773
Validation loss: 2.131749282280604

Epoch: 5| Step: 11
Training loss: 2.660801410675049
Validation loss: 2.1102909992138543

Epoch: 140| Step: 0
Training loss: 1.3015528917312622
Validation loss: 2.097060645620028

Epoch: 5| Step: 1
Training loss: 1.6107488870620728
Validation loss: 2.1118720124165216

Epoch: 5| Step: 2
Training loss: 1.5048186779022217
Validation loss: 2.0684216966231666

Epoch: 5| Step: 3
Training loss: 1.1839983463287354
Validation loss: 2.1084994872411094

Epoch: 5| Step: 4
Training loss: 1.47968327999115
Validation loss: 2.1242589006821313

Epoch: 5| Step: 5
Training loss: 2.008650302886963
Validation loss: 2.1132225592931113

Epoch: 5| Step: 6
Training loss: 2.098722219467163
Validation loss: 2.119752506415049

Epoch: 5| Step: 7
Training loss: 1.3041459321975708
Validation loss: 2.0787792603174844

Epoch: 5| Step: 8
Training loss: 1.6395660638809204
Validation loss: 2.108035425345103

Epoch: 5| Step: 9
Training loss: 1.6206839084625244
Validation loss: 2.1554043690363565

Epoch: 5| Step: 10
Training loss: 1.892096757888794
Validation loss: 2.0563851396242776

Epoch: 5| Step: 11
Training loss: 2.305325984954834
Validation loss: 2.145103762547175

Epoch: 141| Step: 0
Training loss: 1.5353349447250366
Validation loss: 2.099580521384875

Epoch: 5| Step: 1
Training loss: 1.8537956476211548
Validation loss: 2.124207695325216

Epoch: 5| Step: 2
Training loss: 1.1490237712860107
Validation loss: 2.070295120278994

Epoch: 5| Step: 3
Training loss: 1.9197890758514404
Validation loss: 2.0635479589303336

Epoch: 5| Step: 4
Training loss: 1.5589687824249268
Validation loss: 2.0713311036427817

Epoch: 5| Step: 5
Training loss: 1.356050729751587
Validation loss: 2.1523964554071426

Epoch: 5| Step: 6
Training loss: 1.7722934484481812
Validation loss: 2.13849006096522

Epoch: 5| Step: 7
Training loss: 1.5850765705108643
Validation loss: 2.1083605885505676

Epoch: 5| Step: 8
Training loss: 1.2076761722564697
Validation loss: 2.052067533135414

Epoch: 5| Step: 9
Training loss: 1.9749990701675415
Validation loss: 2.1084719945987067

Epoch: 5| Step: 10
Training loss: 1.564704418182373
Validation loss: 2.1097326576709747

Epoch: 5| Step: 11
Training loss: 1.5174709558486938
Validation loss: 2.1093822717666626

Epoch: 142| Step: 0
Training loss: 1.6837756633758545
Validation loss: 2.1050218840440116

Epoch: 5| Step: 1
Training loss: 1.8010495901107788
Validation loss: 2.18148897588253

Epoch: 5| Step: 2
Training loss: 1.3309332132339478
Validation loss: 2.148442660768827

Epoch: 5| Step: 3
Training loss: 1.460719108581543
Validation loss: 2.147796481847763

Epoch: 5| Step: 4
Training loss: 1.5233242511749268
Validation loss: 2.171465868751208

Epoch: 5| Step: 5
Training loss: 2.0591721534729004
Validation loss: 2.1809044679005942

Epoch: 5| Step: 6
Training loss: 1.3258841037750244
Validation loss: 2.1850156436363855

Epoch: 5| Step: 7
Training loss: 1.318548560142517
Validation loss: 2.146423945824305

Epoch: 5| Step: 8
Training loss: 2.358506441116333
Validation loss: 2.12288598716259

Epoch: 5| Step: 9
Training loss: 1.7334470748901367
Validation loss: 2.1337983856598535

Epoch: 5| Step: 10
Training loss: 1.093786597251892
Validation loss: 2.0846929351488748

Epoch: 5| Step: 11
Training loss: 1.2319376468658447
Validation loss: 2.1225311209758124

Epoch: 143| Step: 0
Training loss: 1.1527748107910156
Validation loss: 2.0809291303157806

Epoch: 5| Step: 1
Training loss: 2.0268898010253906
Validation loss: 2.1007496466239295

Epoch: 5| Step: 2
Training loss: 1.1499357223510742
Validation loss: 2.0637665738662085

Epoch: 5| Step: 3
Training loss: 1.5787439346313477
Validation loss: 2.0836851447820663

Epoch: 5| Step: 4
Training loss: 1.3292540311813354
Validation loss: 2.0665967414776483

Epoch: 5| Step: 5
Training loss: 1.9019683599472046
Validation loss: 2.13155460357666

Epoch: 5| Step: 6
Training loss: 1.8069909811019897
Validation loss: 2.0948515087366104

Epoch: 5| Step: 7
Training loss: 1.3460052013397217
Validation loss: 2.055484727025032

Epoch: 5| Step: 8
Training loss: 2.209730625152588
Validation loss: 2.130500709017118

Epoch: 5| Step: 9
Training loss: 2.001415491104126
Validation loss: 2.080873191356659

Epoch: 5| Step: 10
Training loss: 1.2623417377471924
Validation loss: 2.154451847076416

Epoch: 5| Step: 11
Training loss: 1.0274794101715088
Validation loss: 2.195849751432737

Epoch: 144| Step: 0
Training loss: 1.720786452293396
Validation loss: 2.1514269361893334

Epoch: 5| Step: 1
Training loss: 1.4703638553619385
Validation loss: 2.142003044486046

Epoch: 5| Step: 2
Training loss: 1.562249779701233
Validation loss: 2.223152110973994

Epoch: 5| Step: 3
Training loss: 1.777728796005249
Validation loss: 2.1533111234505973

Epoch: 5| Step: 4
Training loss: 1.8953806161880493
Validation loss: 2.1291593462228775

Epoch: 5| Step: 5
Training loss: 1.0805456638336182
Validation loss: 2.1466020941734314

Epoch: 5| Step: 6
Training loss: 1.7778202295303345
Validation loss: 2.106464962164561

Epoch: 5| Step: 7
Training loss: 1.7536423206329346
Validation loss: 2.124302993218104

Epoch: 5| Step: 8
Training loss: 2.329009532928467
Validation loss: 2.065359200040499

Epoch: 5| Step: 9
Training loss: 1.5771749019622803
Validation loss: 2.115418314933777

Epoch: 5| Step: 10
Training loss: 1.3389999866485596
Validation loss: 2.083485340078672

Epoch: 5| Step: 11
Training loss: 1.347340703010559
Validation loss: 2.048733895023664

Epoch: 145| Step: 0
Training loss: 1.5697423219680786
Validation loss: 2.1310868163903556

Epoch: 5| Step: 1
Training loss: 1.6465966701507568
Validation loss: 2.080269048611323

Epoch: 5| Step: 2
Training loss: 1.4566657543182373
Validation loss: 2.074659898877144

Epoch: 5| Step: 3
Training loss: 1.559195637702942
Validation loss: 2.105954418579737

Epoch: 5| Step: 4
Training loss: 1.44777512550354
Validation loss: 2.079001873731613

Epoch: 5| Step: 5
Training loss: 1.7468526363372803
Validation loss: 2.1271926860014596

Epoch: 5| Step: 6
Training loss: 1.3790361881256104
Validation loss: 2.1818371762832007

Epoch: 5| Step: 7
Training loss: 1.3623987436294556
Validation loss: 2.1325437277555466

Epoch: 5| Step: 8
Training loss: 1.8848295211791992
Validation loss: 2.09481680393219

Epoch: 5| Step: 9
Training loss: 1.9251632690429688
Validation loss: 2.1800598800182343

Epoch: 5| Step: 10
Training loss: 1.2682632207870483
Validation loss: 2.1294357627630234

Epoch: 5| Step: 11
Training loss: 1.1112045049667358
Validation loss: 2.1684915920098624

Epoch: 146| Step: 0
Training loss: 2.040318489074707
Validation loss: 2.2152317563692727

Epoch: 5| Step: 1
Training loss: 1.770669937133789
Validation loss: 2.17160235842069

Epoch: 5| Step: 2
Training loss: 1.882772445678711
Validation loss: 2.1933218042055764

Epoch: 5| Step: 3
Training loss: 1.906550645828247
Validation loss: 2.197898586591085

Epoch: 5| Step: 4
Training loss: 1.10630202293396
Validation loss: 2.214526762564977

Epoch: 5| Step: 5
Training loss: 1.477569580078125
Validation loss: 2.199970414241155

Epoch: 5| Step: 6
Training loss: 1.3467888832092285
Validation loss: 2.1787375013033548

Epoch: 5| Step: 7
Training loss: 1.0883290767669678
Validation loss: 2.1433390428622565

Epoch: 5| Step: 8
Training loss: 1.5710771083831787
Validation loss: 2.111416826645533

Epoch: 5| Step: 9
Training loss: 1.8251606225967407
Validation loss: 2.119212677081426

Epoch: 5| Step: 10
Training loss: 1.58687162399292
Validation loss: 2.1020338435967765

Epoch: 5| Step: 11
Training loss: 2.0536446571350098
Validation loss: 2.0996299982070923

Epoch: 147| Step: 0
Training loss: 1.128536581993103
Validation loss: 2.0633574575185776

Epoch: 5| Step: 1
Training loss: 1.6010286808013916
Validation loss: 2.1041750808556876

Epoch: 5| Step: 2
Training loss: 1.873086929321289
Validation loss: 2.0824709137280784

Epoch: 5| Step: 3
Training loss: 1.568373441696167
Validation loss: 2.1414853930473328

Epoch: 5| Step: 4
Training loss: 1.4828358888626099
Validation loss: 2.0729624778032303

Epoch: 5| Step: 5
Training loss: 1.0491236448287964
Validation loss: 2.14418263733387

Epoch: 5| Step: 6
Training loss: 2.0218167304992676
Validation loss: 2.1317786326011023

Epoch: 5| Step: 7
Training loss: 1.806030035018921
Validation loss: 2.1378181080023446

Epoch: 5| Step: 8
Training loss: 2.053131103515625
Validation loss: 2.1572910050551095

Epoch: 5| Step: 9
Training loss: 0.9510089755058289
Validation loss: 2.1441830098629

Epoch: 5| Step: 10
Training loss: 1.904543161392212
Validation loss: 2.1182332982619605

Epoch: 5| Step: 11
Training loss: 2.177006721496582
Validation loss: 2.124889850616455

Epoch: 148| Step: 0
Training loss: 1.7729361057281494
Validation loss: 2.184328888853391

Epoch: 5| Step: 1
Training loss: 1.9081242084503174
Validation loss: 2.1452910900115967

Epoch: 5| Step: 2
Training loss: 1.3243564367294312
Validation loss: 2.1523571411768594

Epoch: 5| Step: 3
Training loss: 1.71041738986969
Validation loss: 2.1001548568407693

Epoch: 5| Step: 4
Training loss: 1.535197377204895
Validation loss: 2.1160847544670105

Epoch: 5| Step: 5
Training loss: 1.4319298267364502
Validation loss: 2.118343725800514

Epoch: 5| Step: 6
Training loss: 2.016784906387329
Validation loss: 2.1118900577227273

Epoch: 5| Step: 7
Training loss: 1.3440216779708862
Validation loss: 2.1252803653478622

Epoch: 5| Step: 8
Training loss: 1.0690945386886597
Validation loss: 2.1156753301620483

Epoch: 5| Step: 9
Training loss: 1.881427526473999
Validation loss: 2.1128917137781777

Epoch: 5| Step: 10
Training loss: 1.3309376239776611
Validation loss: 2.185113400220871

Epoch: 5| Step: 11
Training loss: 0.7788106203079224
Validation loss: 2.157962034145991

Epoch: 149| Step: 0
Training loss: 1.2676929235458374
Validation loss: 2.1238988737265267

Epoch: 5| Step: 1
Training loss: 1.1834877729415894
Validation loss: 2.1519293586413064

Epoch: 5| Step: 2
Training loss: 1.6398723125457764
Validation loss: 2.1267001231511435

Epoch: 5| Step: 3
Training loss: 1.1231790781021118
Validation loss: 2.11160842080911

Epoch: 5| Step: 4
Training loss: 1.346490502357483
Validation loss: 2.2010270059108734

Epoch: 5| Step: 5
Training loss: 1.5890123844146729
Validation loss: 2.134360904494921

Epoch: 5| Step: 6
Training loss: 1.826250672340393
Validation loss: 2.10314904153347

Epoch: 5| Step: 7
Training loss: 1.5029710531234741
Validation loss: 2.1387686679760614

Epoch: 5| Step: 8
Training loss: 1.2057517766952515
Validation loss: 2.120978613694509

Epoch: 5| Step: 9
Training loss: 1.713971734046936
Validation loss: 2.1108680963516235

Epoch: 5| Step: 10
Training loss: 2.5993168354034424
Validation loss: 2.134261285265287

Epoch: 5| Step: 11
Training loss: 1.5709152221679688
Validation loss: 2.0997690757115683

Epoch: 150| Step: 0
Training loss: 1.891334891319275
Validation loss: 2.1160629242658615

Epoch: 5| Step: 1
Training loss: 1.279780387878418
Validation loss: 2.098531032601992

Epoch: 5| Step: 2
Training loss: 2.1398487091064453
Validation loss: 2.1520380030075708

Epoch: 5| Step: 3
Training loss: 1.5709561109542847
Validation loss: 2.083115210135778

Epoch: 5| Step: 4
Training loss: 1.468031644821167
Validation loss: 2.126668224732081

Epoch: 5| Step: 5
Training loss: 1.6689655780792236
Validation loss: 2.138816883166631

Epoch: 5| Step: 6
Training loss: 1.662200927734375
Validation loss: 2.165091887116432

Epoch: 5| Step: 7
Training loss: 1.2354378700256348
Validation loss: 2.1054982990026474

Epoch: 5| Step: 8
Training loss: 1.5936132669448853
Validation loss: 2.1380166759093604

Epoch: 5| Step: 9
Training loss: 1.0038013458251953
Validation loss: 2.107819457848867

Epoch: 5| Step: 10
Training loss: 1.5102262496948242
Validation loss: 2.1999116291602454

Epoch: 5| Step: 11
Training loss: 1.2229969501495361
Validation loss: 2.1884084890286126

Epoch: 151| Step: 0
Training loss: 1.6608161926269531
Validation loss: 2.1661476294199624

Epoch: 5| Step: 1
Training loss: 1.556699514389038
Validation loss: 2.1453898400068283

Epoch: 5| Step: 2
Training loss: 1.8659414052963257
Validation loss: 2.1645402312278748

Epoch: 5| Step: 3
Training loss: 1.3152599334716797
Validation loss: 2.168634980916977

Epoch: 5| Step: 4
Training loss: 1.1965487003326416
Validation loss: 2.131202603379885

Epoch: 5| Step: 5
Training loss: 1.5035632848739624
Validation loss: 2.150731603304545

Epoch: 5| Step: 6
Training loss: 1.9733870029449463
Validation loss: 2.1080857465664544

Epoch: 5| Step: 7
Training loss: 1.6307775974273682
Validation loss: 2.1437850842873254

Epoch: 5| Step: 8
Training loss: 1.7838447093963623
Validation loss: 2.1239951848983765

Epoch: 5| Step: 9
Training loss: 1.444157600402832
Validation loss: 2.0920336097478867

Epoch: 5| Step: 10
Training loss: 1.5840909481048584
Validation loss: 2.0640092939138412

Epoch: 5| Step: 11
Training loss: 0.9220289587974548
Validation loss: 2.1552597482999167

Epoch: 152| Step: 0
Training loss: 1.5426260232925415
Validation loss: 2.14544548590978

Epoch: 5| Step: 1
Training loss: 1.0937960147857666
Validation loss: 2.131524274746577

Epoch: 5| Step: 2
Training loss: 2.201246976852417
Validation loss: 2.1693571905295053

Epoch: 5| Step: 3
Training loss: 1.1425905227661133
Validation loss: 2.2003744691610336

Epoch: 5| Step: 4
Training loss: 1.0946935415267944
Validation loss: 2.2017709612846375

Epoch: 5| Step: 5
Training loss: 1.722602128982544
Validation loss: 2.167271892229716

Epoch: 5| Step: 6
Training loss: 1.521047592163086
Validation loss: 2.153506721059481

Epoch: 5| Step: 7
Training loss: 1.2703605890274048
Validation loss: 2.134268879890442

Epoch: 5| Step: 8
Training loss: 1.60037362575531
Validation loss: 2.180027802785238

Epoch: 5| Step: 9
Training loss: 2.0839593410491943
Validation loss: 2.1554106573263803

Epoch: 5| Step: 10
Training loss: 1.5900341272354126
Validation loss: 2.141553004582723

Epoch: 5| Step: 11
Training loss: 2.1389918327331543
Validation loss: 2.1505041420459747

Epoch: 153| Step: 0
Training loss: 1.860835313796997
Validation loss: 2.1883713006973267

Epoch: 5| Step: 1
Training loss: 1.220725655555725
Validation loss: 2.1295440644025803

Epoch: 5| Step: 2
Training loss: 1.3420774936676025
Validation loss: 2.132436916232109

Epoch: 5| Step: 3
Training loss: 1.6288524866104126
Validation loss: 2.1397972653309503

Epoch: 5| Step: 4
Training loss: 1.357113242149353
Validation loss: 2.1308430631955466

Epoch: 5| Step: 5
Training loss: 1.077028512954712
Validation loss: 2.146390368541082

Epoch: 5| Step: 6
Training loss: 1.295119047164917
Validation loss: 2.0684559593598046

Epoch: 5| Step: 7
Training loss: 1.9526002407073975
Validation loss: 2.1085283358891806

Epoch: 5| Step: 8
Training loss: 1.7224628925323486
Validation loss: 2.095071772734324

Epoch: 5| Step: 9
Training loss: 1.4922797679901123
Validation loss: 2.102877681454023

Epoch: 5| Step: 10
Training loss: 1.730817437171936
Validation loss: 2.1513479501008987

Epoch: 5| Step: 11
Training loss: 1.0928174257278442
Validation loss: 2.151990363995234

Epoch: 154| Step: 0
Training loss: 1.3502179384231567
Validation loss: 2.1553827126820884

Epoch: 5| Step: 1
Training loss: 2.051154613494873
Validation loss: 2.1628762036561966

Epoch: 5| Step: 2
Training loss: 1.4417126178741455
Validation loss: 2.26596928636233

Epoch: 5| Step: 3
Training loss: 1.6847188472747803
Validation loss: 2.2073042690753937

Epoch: 5| Step: 4
Training loss: 1.4585620164871216
Validation loss: 2.2570522824923196

Epoch: 5| Step: 5
Training loss: 1.6997696161270142
Validation loss: 2.250986705223719

Epoch: 5| Step: 6
Training loss: 1.0685462951660156
Validation loss: 2.210292771458626

Epoch: 5| Step: 7
Training loss: 1.7935959100723267
Validation loss: 2.1378034154574075

Epoch: 5| Step: 8
Training loss: 1.3344653844833374
Validation loss: 2.1323607663313546

Epoch: 5| Step: 9
Training loss: 1.3029508590698242
Validation loss: 2.1144374360640845

Epoch: 5| Step: 10
Training loss: 1.8160021305084229
Validation loss: 2.1157296101252236

Epoch: 5| Step: 11
Training loss: 1.073079228401184
Validation loss: 2.0759279082218804

Epoch: 155| Step: 0
Training loss: 1.6354026794433594
Validation loss: 2.0851368804772696

Epoch: 5| Step: 1
Training loss: 1.8472474813461304
Validation loss: 2.1141797552506127

Epoch: 5| Step: 2
Training loss: 1.2681106328964233
Validation loss: 2.074859003225962

Epoch: 5| Step: 3
Training loss: 1.3769632577896118
Validation loss: 2.1488185922304788

Epoch: 5| Step: 4
Training loss: 1.399843454360962
Validation loss: 2.115659495194753

Epoch: 5| Step: 5
Training loss: 1.6330190896987915
Validation loss: 2.101070284843445

Epoch: 5| Step: 6
Training loss: 1.224461317062378
Validation loss: 2.168086568514506

Epoch: 5| Step: 7
Training loss: 1.7733380794525146
Validation loss: 2.1810386081536612

Epoch: 5| Step: 8
Training loss: 1.772552251815796
Validation loss: 2.1835025946299234

Epoch: 5| Step: 9
Training loss: 1.5345516204833984
Validation loss: 2.20347232123216

Epoch: 5| Step: 10
Training loss: 1.6365524530410767
Validation loss: 2.1884502172470093

Epoch: 5| Step: 11
Training loss: 1.3760805130004883
Validation loss: 2.24312957127889

Epoch: 156| Step: 0
Training loss: 1.437495231628418
Validation loss: 2.1584492921829224

Epoch: 5| Step: 1
Training loss: 1.440394401550293
Validation loss: 2.0532442927360535

Epoch: 5| Step: 2
Training loss: 1.7110223770141602
Validation loss: 2.1255065302054086

Epoch: 5| Step: 3
Training loss: 1.6644313335418701
Validation loss: 2.126651073495547

Epoch: 5| Step: 4
Training loss: 1.327132225036621
Validation loss: 2.116255447268486

Epoch: 5| Step: 5
Training loss: 1.951712965965271
Validation loss: 2.107526804010073

Epoch: 5| Step: 6
Training loss: 1.2644283771514893
Validation loss: 2.120562493801117

Epoch: 5| Step: 7
Training loss: 1.5447593927383423
Validation loss: 2.120713025331497

Epoch: 5| Step: 8
Training loss: 0.9676622152328491
Validation loss: 2.1194585065046945

Epoch: 5| Step: 9
Training loss: 1.827203392982483
Validation loss: 2.0707721263170242

Epoch: 5| Step: 10
Training loss: 1.5237172842025757
Validation loss: 2.125725120306015

Epoch: 5| Step: 11
Training loss: 1.5437990427017212
Validation loss: 2.0998849223057428

Epoch: 157| Step: 0
Training loss: 1.3279212713241577
Validation loss: 2.1306104262669883

Epoch: 5| Step: 1
Training loss: 1.6030174493789673
Validation loss: 2.1231393913427987

Epoch: 5| Step: 2
Training loss: 2.084078788757324
Validation loss: 2.1588153392076492

Epoch: 5| Step: 3
Training loss: 1.6297962665557861
Validation loss: 2.170009841521581

Epoch: 5| Step: 4
Training loss: 1.5725696086883545
Validation loss: 2.178473229209582

Epoch: 5| Step: 5
Training loss: 1.41728675365448
Validation loss: 2.1660379419724145

Epoch: 5| Step: 6
Training loss: 1.1729334592819214
Validation loss: 2.2125299175580344

Epoch: 5| Step: 7
Training loss: 1.3199536800384521
Validation loss: 2.140925665696462

Epoch: 5| Step: 8
Training loss: 2.107924222946167
Validation loss: 2.1455231805642447

Epoch: 5| Step: 9
Training loss: 1.2914589643478394
Validation loss: 2.1154740105072656

Epoch: 5| Step: 10
Training loss: 1.076425313949585
Validation loss: 2.1083486874898276

Epoch: 5| Step: 11
Training loss: 0.7804831862449646
Validation loss: 2.133457680543264

Epoch: 158| Step: 0
Training loss: 1.477729082107544
Validation loss: 2.107843821247419

Epoch: 5| Step: 1
Training loss: 1.8263705968856812
Validation loss: 2.1231106172005334

Epoch: 5| Step: 2
Training loss: 1.5942271947860718
Validation loss: 2.0851865311463675

Epoch: 5| Step: 3
Training loss: 1.7159764766693115
Validation loss: 2.1210655172665915

Epoch: 5| Step: 4
Training loss: 1.3864147663116455
Validation loss: 2.0738619218269982

Epoch: 5| Step: 5
Training loss: 1.4898412227630615
Validation loss: 2.1506084352731705

Epoch: 5| Step: 6
Training loss: 1.1680892705917358
Validation loss: 2.2022707810004554

Epoch: 5| Step: 7
Training loss: 1.3730885982513428
Validation loss: 2.122542922695478

Epoch: 5| Step: 8
Training loss: 1.3081004619598389
Validation loss: 2.2071778972943625

Epoch: 5| Step: 9
Training loss: 1.4057990312576294
Validation loss: 2.165461445848147

Epoch: 5| Step: 10
Training loss: 1.7104160785675049
Validation loss: 2.180298467477163

Epoch: 5| Step: 11
Training loss: 1.5362892150878906
Validation loss: 2.182260056336721

Epoch: 159| Step: 0
Training loss: 1.1802833080291748
Validation loss: 2.1601330439249673

Epoch: 5| Step: 1
Training loss: 1.2842435836791992
Validation loss: 2.1070709824562073

Epoch: 5| Step: 2
Training loss: 1.560916543006897
Validation loss: 2.126464198033015

Epoch: 5| Step: 3
Training loss: 1.5030295848846436
Validation loss: 2.126898765563965

Epoch: 5| Step: 4
Training loss: 1.3768397569656372
Validation loss: 2.112605929374695

Epoch: 5| Step: 5
Training loss: 1.3423105478286743
Validation loss: 2.108653257290522

Epoch: 5| Step: 6
Training loss: 1.387887954711914
Validation loss: 2.1086003134648004

Epoch: 5| Step: 7
Training loss: 1.766876459121704
Validation loss: 2.153029203414917

Epoch: 5| Step: 8
Training loss: 1.323582410812378
Validation loss: 2.1575913230578103

Epoch: 5| Step: 9
Training loss: 2.044691562652588
Validation loss: 2.1632109036048255

Epoch: 5| Step: 10
Training loss: 1.4958677291870117
Validation loss: 2.154312382141749

Epoch: 5| Step: 11
Training loss: 1.8088876008987427
Validation loss: 2.150595411658287

Epoch: 160| Step: 0
Training loss: 1.4711295366287231
Validation loss: 2.11515803138415

Epoch: 5| Step: 1
Training loss: 1.0851151943206787
Validation loss: 2.1249457796414695

Epoch: 5| Step: 2
Training loss: 1.501755952835083
Validation loss: 2.1558422247568765

Epoch: 5| Step: 3
Training loss: 1.1535894870758057
Validation loss: 2.159895598888397

Epoch: 5| Step: 4
Training loss: 1.1475849151611328
Validation loss: 2.132917503515879

Epoch: 5| Step: 5
Training loss: 2.123880386352539
Validation loss: 2.176080291469892

Epoch: 5| Step: 6
Training loss: 1.9647152423858643
Validation loss: 2.174165894587835

Epoch: 5| Step: 7
Training loss: 1.561895489692688
Validation loss: 2.129373848438263

Epoch: 5| Step: 8
Training loss: 1.986762285232544
Validation loss: 2.131516362229983

Epoch: 5| Step: 9
Training loss: 1.4790740013122559
Validation loss: 2.118587260444959

Epoch: 5| Step: 10
Training loss: 1.292757272720337
Validation loss: 2.081910029053688

Epoch: 5| Step: 11
Training loss: 0.6932365894317627
Validation loss: 2.098307261864344

Epoch: 161| Step: 0
Training loss: 1.2541474103927612
Validation loss: 2.1304735789696374

Epoch: 5| Step: 1
Training loss: 1.665858268737793
Validation loss: 2.1053177217642465

Epoch: 5| Step: 2
Training loss: 1.4276725053787231
Validation loss: 2.129526828726133

Epoch: 5| Step: 3
Training loss: 1.0909608602523804
Validation loss: 2.1425881634155908

Epoch: 5| Step: 4
Training loss: 1.9535497426986694
Validation loss: 2.0799458722273507

Epoch: 5| Step: 5
Training loss: 1.3569234609603882
Validation loss: 2.108183960119883

Epoch: 5| Step: 6
Training loss: 1.313439130783081
Validation loss: 2.170558586716652

Epoch: 5| Step: 7
Training loss: 1.7883737087249756
Validation loss: 2.172903895378113

Epoch: 5| Step: 8
Training loss: 1.3990015983581543
Validation loss: 2.193553318579992

Epoch: 5| Step: 9
Training loss: 1.3118104934692383
Validation loss: 2.1504750102758408

Epoch: 5| Step: 10
Training loss: 1.939936876296997
Validation loss: 2.1491508185863495

Epoch: 5| Step: 11
Training loss: 0.8410615921020508
Validation loss: 2.1156214624643326

Epoch: 162| Step: 0
Training loss: 1.1579045057296753
Validation loss: 2.156901324788729

Epoch: 5| Step: 1
Training loss: 1.3394219875335693
Validation loss: 2.175396059950193

Epoch: 5| Step: 2
Training loss: 0.7517236471176147
Validation loss: 2.174327810605367

Epoch: 5| Step: 3
Training loss: 1.0986242294311523
Validation loss: 2.2120591700077057

Epoch: 5| Step: 4
Training loss: 1.4318288564682007
Validation loss: 2.1383689045906067

Epoch: 5| Step: 5
Training loss: 1.289196252822876
Validation loss: 2.1818779706954956

Epoch: 5| Step: 6
Training loss: 1.7322622537612915
Validation loss: 2.101108213265737

Epoch: 5| Step: 7
Training loss: 1.9457504749298096
Validation loss: 2.120373154679934

Epoch: 5| Step: 8
Training loss: 1.5188629627227783
Validation loss: 2.1336862444877625

Epoch: 5| Step: 9
Training loss: 2.2439303398132324
Validation loss: 2.1351620256900787

Epoch: 5| Step: 10
Training loss: 1.6109378337860107
Validation loss: 2.1115267972151437

Epoch: 5| Step: 11
Training loss: 2.049415349960327
Validation loss: 2.0971482197443643

Epoch: 163| Step: 0
Training loss: 1.3866851329803467
Validation loss: 2.113745073477427

Epoch: 5| Step: 1
Training loss: 1.442347764968872
Validation loss: 2.1963220834732056

Epoch: 5| Step: 2
Training loss: 1.510891079902649
Validation loss: 2.114975616335869

Epoch: 5| Step: 3
Training loss: 1.4164625406265259
Validation loss: 2.2013066013654075

Epoch: 5| Step: 4
Training loss: 2.0217654705047607
Validation loss: 2.1914051671822867

Epoch: 5| Step: 5
Training loss: 1.1968400478363037
Validation loss: 2.231867695848147

Epoch: 5| Step: 6
Training loss: 1.535083532333374
Validation loss: 2.1682076454162598

Epoch: 5| Step: 7
Training loss: 1.5970311164855957
Validation loss: 2.212504059076309

Epoch: 5| Step: 8
Training loss: 1.4882442951202393
Validation loss: 2.178319349884987

Epoch: 5| Step: 9
Training loss: 1.4055681228637695
Validation loss: 2.1294895857572556

Epoch: 5| Step: 10
Training loss: 1.4986097812652588
Validation loss: 2.1163873275121055

Epoch: 5| Step: 11
Training loss: 1.1002448797225952
Validation loss: 2.094457894563675

Epoch: 164| Step: 0
Training loss: 1.567458152770996
Validation loss: 2.1168697526057563

Epoch: 5| Step: 1
Training loss: 1.7463524341583252
Validation loss: 2.121331771214803

Epoch: 5| Step: 2
Training loss: 1.307145357131958
Validation loss: 2.1656353771686554

Epoch: 5| Step: 3
Training loss: 1.3318079710006714
Validation loss: 2.157143145799637

Epoch: 5| Step: 4
Training loss: 1.3799773454666138
Validation loss: 2.108731990059217

Epoch: 5| Step: 5
Training loss: 1.4394943714141846
Validation loss: 2.1616561114788055

Epoch: 5| Step: 6
Training loss: 2.014087200164795
Validation loss: 2.1626141319672265

Epoch: 5| Step: 7
Training loss: 1.2184175252914429
Validation loss: 2.194805219769478

Epoch: 5| Step: 8
Training loss: 1.708343505859375
Validation loss: 2.212216407060623

Epoch: 5| Step: 9
Training loss: 1.4542633295059204
Validation loss: 2.183331827322642

Epoch: 5| Step: 10
Training loss: 1.205187439918518
Validation loss: 2.1628994743029275

Epoch: 5| Step: 11
Training loss: 1.5951385498046875
Validation loss: 2.226655145486196

Epoch: 165| Step: 0
Training loss: 1.49807870388031
Validation loss: 2.1776506255070367

Epoch: 5| Step: 1
Training loss: 1.5826871395111084
Validation loss: 2.1303565055131912

Epoch: 5| Step: 2
Training loss: 1.5674325227737427
Validation loss: 2.1260314087073007

Epoch: 5| Step: 3
Training loss: 0.9688685536384583
Validation loss: 2.190376063187917

Epoch: 5| Step: 4
Training loss: 1.305053472518921
Validation loss: 2.0903777877489724

Epoch: 5| Step: 5
Training loss: 1.0831106901168823
Validation loss: 2.2048140366872153

Epoch: 5| Step: 6
Training loss: 1.09123694896698
Validation loss: 2.1401912023623786

Epoch: 5| Step: 7
Training loss: 1.6680965423583984
Validation loss: 2.093291992942492

Epoch: 5| Step: 8
Training loss: 1.5818697214126587
Validation loss: 2.1020686427752175

Epoch: 5| Step: 9
Training loss: 1.8779430389404297
Validation loss: 2.0942323058843613

Epoch: 5| Step: 10
Training loss: 1.3773666620254517
Validation loss: 2.1025466372569404

Epoch: 5| Step: 11
Training loss: 2.581061840057373
Validation loss: 2.159584408005079

Epoch: 166| Step: 0
Training loss: 1.834946632385254
Validation loss: 2.150163307785988

Epoch: 5| Step: 1
Training loss: 1.1779677867889404
Validation loss: 2.1212377746899924

Epoch: 5| Step: 2
Training loss: 1.2241935729980469
Validation loss: 2.1448784470558167

Epoch: 5| Step: 3
Training loss: 1.0301620960235596
Validation loss: 2.1489923149347305

Epoch: 5| Step: 4
Training loss: 1.1116911172866821
Validation loss: 2.1303820659716926

Epoch: 5| Step: 5
Training loss: 1.1759848594665527
Validation loss: 2.151089752713839

Epoch: 5| Step: 6
Training loss: 1.2774699926376343
Validation loss: 2.1276076336701712

Epoch: 5| Step: 7
Training loss: 1.8702430725097656
Validation loss: 2.1548592001199722

Epoch: 5| Step: 8
Training loss: 1.6116752624511719
Validation loss: 2.1646190683046975

Epoch: 5| Step: 9
Training loss: 2.0270254611968994
Validation loss: 2.1482421259085336

Epoch: 5| Step: 10
Training loss: 1.6225723028182983
Validation loss: 2.1236200034618378

Epoch: 5| Step: 11
Training loss: 0.7630040645599365
Validation loss: 2.1236260384321213

Epoch: 167| Step: 0
Training loss: 1.2085422277450562
Validation loss: 2.1241795072952905

Epoch: 5| Step: 1
Training loss: 1.5817381143569946
Validation loss: 2.1383250802755356

Epoch: 5| Step: 2
Training loss: 1.4019956588745117
Validation loss: 2.158037001887957

Epoch: 5| Step: 3
Training loss: 1.4061561822891235
Validation loss: 2.1996402541796365

Epoch: 5| Step: 4
Training loss: 1.5382623672485352
Validation loss: 2.1660235126813254

Epoch: 5| Step: 5
Training loss: 1.5044089555740356
Validation loss: 2.1997958620389304

Epoch: 5| Step: 6
Training loss: 0.9460689425468445
Validation loss: 2.2049362460772195

Epoch: 5| Step: 7
Training loss: 1.2688896656036377
Validation loss: 2.190673753619194

Epoch: 5| Step: 8
Training loss: 2.1464622020721436
Validation loss: 2.17333921790123

Epoch: 5| Step: 9
Training loss: 1.447291612625122
Validation loss: 2.21249920129776

Epoch: 5| Step: 10
Training loss: 1.740168809890747
Validation loss: 2.193977882464727

Epoch: 5| Step: 11
Training loss: 0.9589086771011353
Validation loss: 2.09662734468778

Epoch: 168| Step: 0
Training loss: 1.1720457077026367
Validation loss: 2.1739697555700936

Epoch: 5| Step: 1
Training loss: 1.133266806602478
Validation loss: 2.1448707530895867

Epoch: 5| Step: 2
Training loss: 1.615055799484253
Validation loss: 2.091030533115069

Epoch: 5| Step: 3
Training loss: 1.6997697353363037
Validation loss: 2.1146394461393356

Epoch: 5| Step: 4
Training loss: 1.373392105102539
Validation loss: 2.118106782436371

Epoch: 5| Step: 5
Training loss: 0.9632213711738586
Validation loss: 2.1171118021011353

Epoch: 5| Step: 6
Training loss: 1.648108720779419
Validation loss: 2.1323934396107993

Epoch: 5| Step: 7
Training loss: 1.638710618019104
Validation loss: 2.135124146938324

Epoch: 5| Step: 8
Training loss: 1.3186320066452026
Validation loss: 2.1624327103296914

Epoch: 5| Step: 9
Training loss: 1.5119998455047607
Validation loss: 2.1707427402337394

Epoch: 5| Step: 10
Training loss: 1.5888488292694092
Validation loss: 2.1536977042754493

Epoch: 5| Step: 11
Training loss: 2.2060706615448
Validation loss: 2.189806640148163

Epoch: 169| Step: 0
Training loss: 1.8440053462982178
Validation loss: 2.2332767049471536

Epoch: 5| Step: 1
Training loss: 1.3840091228485107
Validation loss: 2.1497640311717987

Epoch: 5| Step: 2
Training loss: 1.0415494441986084
Validation loss: 2.1718436082204184

Epoch: 5| Step: 3
Training loss: 1.7354748249053955
Validation loss: 2.129661187529564

Epoch: 5| Step: 4
Training loss: 1.3923418521881104
Validation loss: 2.2431949377059937

Epoch: 5| Step: 5
Training loss: 1.7762062549591064
Validation loss: 2.218568503856659

Epoch: 5| Step: 6
Training loss: 0.8377411961555481
Validation loss: 2.2123928368091583

Epoch: 5| Step: 7
Training loss: 1.8175216913223267
Validation loss: 2.1683921913305917

Epoch: 5| Step: 8
Training loss: 0.7192463278770447
Validation loss: 2.1282925804456077

Epoch: 5| Step: 9
Training loss: 1.2488478422164917
Validation loss: 2.166066517432531

Epoch: 5| Step: 10
Training loss: 1.4409509897232056
Validation loss: 2.1628967424233756

Epoch: 5| Step: 11
Training loss: 0.9638575315475464
Validation loss: 2.113329475124677

Epoch: 170| Step: 0
Training loss: 1.2667800188064575
Validation loss: 2.1290329496065774

Epoch: 5| Step: 1
Training loss: 1.606147050857544
Validation loss: 2.136054833730062

Epoch: 5| Step: 2
Training loss: 1.9423837661743164
Validation loss: 2.1027508030335107

Epoch: 5| Step: 3
Training loss: 0.6804079413414001
Validation loss: 2.14871779580911

Epoch: 5| Step: 4
Training loss: 1.2848849296569824
Validation loss: 2.1821692089239755

Epoch: 5| Step: 5
Training loss: 1.5414307117462158
Validation loss: 2.114359756310781

Epoch: 5| Step: 6
Training loss: 1.2137320041656494
Validation loss: 2.1339780390262604

Epoch: 5| Step: 7
Training loss: 1.2047632932662964
Validation loss: 2.214717070261637

Epoch: 5| Step: 8
Training loss: 1.783886194229126
Validation loss: 2.1980835845073066

Epoch: 5| Step: 9
Training loss: 1.5560901165008545
Validation loss: 2.23924054702123

Epoch: 5| Step: 10
Training loss: 1.4619507789611816
Validation loss: 2.1916136046250663

Epoch: 5| Step: 11
Training loss: 1.1877906322479248
Validation loss: 2.1557049502929053

Epoch: 171| Step: 0
Training loss: 1.6526237726211548
Validation loss: 2.163669983545939

Epoch: 5| Step: 1
Training loss: 1.1284065246582031
Validation loss: 2.144855668147405

Epoch: 5| Step: 2
Training loss: 1.6993894577026367
Validation loss: 2.165537233153979

Epoch: 5| Step: 3
Training loss: 1.1325781345367432
Validation loss: 2.1211768438418708

Epoch: 5| Step: 4
Training loss: 1.716369867324829
Validation loss: 2.176949510971705

Epoch: 5| Step: 5
Training loss: 1.498715877532959
Validation loss: 2.160252556204796

Epoch: 5| Step: 6
Training loss: 1.6078312397003174
Validation loss: 2.117495854695638

Epoch: 5| Step: 7
Training loss: 1.4197101593017578
Validation loss: 2.1672282367944717

Epoch: 5| Step: 8
Training loss: 0.7818003296852112
Validation loss: 2.114612584312757

Epoch: 5| Step: 9
Training loss: 1.7677570581436157
Validation loss: 2.1410525987545648

Epoch: 5| Step: 10
Training loss: 1.4261125326156616
Validation loss: 2.144697815179825

Epoch: 5| Step: 11
Training loss: 1.8454135656356812
Validation loss: 2.1788064539432526

Epoch: 172| Step: 0
Training loss: 1.3675791025161743
Validation loss: 2.1919817278782525

Epoch: 5| Step: 1
Training loss: 1.3587266206741333
Validation loss: 2.183684224883715

Epoch: 5| Step: 2
Training loss: 1.6342490911483765
Validation loss: 2.193714588880539

Epoch: 5| Step: 3
Training loss: 0.9718878865242004
Validation loss: 2.158702860275904

Epoch: 5| Step: 4
Training loss: 1.1617612838745117
Validation loss: 2.143049548069636

Epoch: 5| Step: 5
Training loss: 1.715355634689331
Validation loss: 2.133477325240771

Epoch: 5| Step: 6
Training loss: 1.164258599281311
Validation loss: 2.0523535708586373

Epoch: 5| Step: 7
Training loss: 1.6918933391571045
Validation loss: 2.157895257075628

Epoch: 5| Step: 8
Training loss: 1.0378903150558472
Validation loss: 2.139664555589358

Epoch: 5| Step: 9
Training loss: 1.4646222591400146
Validation loss: 2.196377237637838

Epoch: 5| Step: 10
Training loss: 1.5604755878448486
Validation loss: 2.1574230988820395

Epoch: 5| Step: 11
Training loss: 0.5675814747810364
Validation loss: 2.1916392097870507

Epoch: 173| Step: 0
Training loss: 1.2365851402282715
Validation loss: 2.1452394177516303

Epoch: 5| Step: 1
Training loss: 1.5282361507415771
Validation loss: 2.1797748655080795

Epoch: 5| Step: 2
Training loss: 0.9587959051132202
Validation loss: 2.18131152788798

Epoch: 5| Step: 3
Training loss: 1.308447241783142
Validation loss: 2.146208316087723

Epoch: 5| Step: 4
Training loss: 1.5452216863632202
Validation loss: 2.183237502972285

Epoch: 5| Step: 5
Training loss: 1.1214654445648193
Validation loss: 2.184202919403712

Epoch: 5| Step: 6
Training loss: 1.4053035974502563
Validation loss: 2.1476987401644387

Epoch: 5| Step: 7
Training loss: 1.4900051355361938
Validation loss: 2.1227656106154122

Epoch: 5| Step: 8
Training loss: 1.3656234741210938
Validation loss: 2.1593084037303925

Epoch: 5| Step: 9
Training loss: 1.6476703882217407
Validation loss: 2.1651171147823334

Epoch: 5| Step: 10
Training loss: 1.679549217224121
Validation loss: 2.193237488468488

Epoch: 5| Step: 11
Training loss: 0.9887616634368896
Validation loss: 2.122928038239479

Epoch: 174| Step: 0
Training loss: 1.221909761428833
Validation loss: 2.1696403324604034

Epoch: 5| Step: 1
Training loss: 1.0976786613464355
Validation loss: 2.2158929308255515

Epoch: 5| Step: 2
Training loss: 0.9253185391426086
Validation loss: 2.1924419502417245

Epoch: 5| Step: 3
Training loss: 1.7099777460098267
Validation loss: 2.213113854328791

Epoch: 5| Step: 4
Training loss: 1.642867088317871
Validation loss: 2.2040545592705407

Epoch: 5| Step: 5
Training loss: 1.6680994033813477
Validation loss: 2.1973575254281363

Epoch: 5| Step: 6
Training loss: 1.4601786136627197
Validation loss: 2.144537622729937

Epoch: 5| Step: 7
Training loss: 1.0808169841766357
Validation loss: 2.121788581212362

Epoch: 5| Step: 8
Training loss: 1.2095599174499512
Validation loss: 2.1603926370541253

Epoch: 5| Step: 9
Training loss: 1.8180291652679443
Validation loss: 2.1344890842835107

Epoch: 5| Step: 10
Training loss: 1.3581682443618774
Validation loss: 2.1333547035853067

Epoch: 5| Step: 11
Training loss: 1.371487021446228
Validation loss: 2.091543917854627

Epoch: 175| Step: 0
Training loss: 0.9038270711898804
Validation loss: 2.1599107484022775

Epoch: 5| Step: 1
Training loss: 1.933267593383789
Validation loss: 2.134562482436498

Epoch: 5| Step: 2
Training loss: 1.36312997341156
Validation loss: 2.1210990101099014

Epoch: 5| Step: 3
Training loss: 1.0219151973724365
Validation loss: 2.1369245002667108

Epoch: 5| Step: 4
Training loss: 1.3649985790252686
Validation loss: 2.2082620660463967

Epoch: 5| Step: 5
Training loss: 1.1743046045303345
Validation loss: 2.1858396033445993

Epoch: 5| Step: 6
Training loss: 1.3280925750732422
Validation loss: 2.265628377596537

Epoch: 5| Step: 7
Training loss: 1.372287631034851
Validation loss: 2.2349865436553955

Epoch: 5| Step: 8
Training loss: 1.5624114274978638
Validation loss: 2.188113883137703

Epoch: 5| Step: 9
Training loss: 2.1891143321990967
Validation loss: 2.267741620540619

Epoch: 5| Step: 10
Training loss: 1.5434528589248657
Validation loss: 2.204633524020513

Epoch: 5| Step: 11
Training loss: 0.9486380219459534
Validation loss: 2.175146703918775

Epoch: 176| Step: 0
Training loss: 1.776484489440918
Validation loss: 2.1777335107326508

Epoch: 5| Step: 1
Training loss: 1.0837184190750122
Validation loss: 2.1797414273023605

Epoch: 5| Step: 2
Training loss: 1.4278042316436768
Validation loss: 2.16777070860068

Epoch: 5| Step: 3
Training loss: 1.3509790897369385
Validation loss: 2.137502213319143

Epoch: 5| Step: 4
Training loss: 1.1413335800170898
Validation loss: 2.110609749952952

Epoch: 5| Step: 5
Training loss: 1.2431223392486572
Validation loss: 2.178578366835912

Epoch: 5| Step: 6
Training loss: 0.9628435373306274
Validation loss: 2.139595905939738

Epoch: 5| Step: 7
Training loss: 1.664628028869629
Validation loss: 2.1727901051441827

Epoch: 5| Step: 8
Training loss: 1.681860327720642
Validation loss: 2.1410571932792664

Epoch: 5| Step: 9
Training loss: 0.8936406970024109
Validation loss: 2.2052406072616577

Epoch: 5| Step: 10
Training loss: 1.6436793804168701
Validation loss: 2.192162344853083

Epoch: 5| Step: 11
Training loss: 1.791379451751709
Validation loss: 2.17079496383667

Epoch: 177| Step: 0
Training loss: 1.9249489307403564
Validation loss: 2.184362923105558

Epoch: 5| Step: 1
Training loss: 0.95941561460495
Validation loss: 2.205060069759687

Epoch: 5| Step: 2
Training loss: 1.4474961757659912
Validation loss: 2.1928304185469947

Epoch: 5| Step: 3
Training loss: 1.1934411525726318
Validation loss: 2.1150538275639215

Epoch: 5| Step: 4
Training loss: 1.0614575147628784
Validation loss: 2.1692819197972617

Epoch: 5| Step: 5
Training loss: 1.7057344913482666
Validation loss: 2.1697777062654495

Epoch: 5| Step: 6
Training loss: 1.1794731616973877
Validation loss: 2.241106222073237

Epoch: 5| Step: 7
Training loss: 1.333383321762085
Validation loss: 2.1638323068618774

Epoch: 5| Step: 8
Training loss: 1.3407810926437378
Validation loss: 2.179733708500862

Epoch: 5| Step: 9
Training loss: 1.2185776233673096
Validation loss: 2.116788705190023

Epoch: 5| Step: 10
Training loss: 1.2678782939910889
Validation loss: 2.0984948674837747

Epoch: 5| Step: 11
Training loss: 1.515459656715393
Validation loss: 2.1543146868546805

Epoch: 178| Step: 0
Training loss: 1.4873214960098267
Validation loss: 2.147277355194092

Epoch: 5| Step: 1
Training loss: 1.2756097316741943
Validation loss: 2.1117675056060157

Epoch: 5| Step: 2
Training loss: 1.453096628189087
Validation loss: 2.1516135931015015

Epoch: 5| Step: 3
Training loss: 1.6249510049819946
Validation loss: 2.13809801141421

Epoch: 5| Step: 4
Training loss: 1.482805609703064
Validation loss: 2.180674066146215

Epoch: 5| Step: 5
Training loss: 1.8805910348892212
Validation loss: 2.201500450571378

Epoch: 5| Step: 6
Training loss: 1.612823247909546
Validation loss: 2.1552006900310516

Epoch: 5| Step: 7
Training loss: 1.1298794746398926
Validation loss: 2.1492278476556144

Epoch: 5| Step: 8
Training loss: 1.3785240650177002
Validation loss: 2.2182153711716333

Epoch: 5| Step: 9
Training loss: 1.2265570163726807
Validation loss: 2.229562724630038

Epoch: 5| Step: 10
Training loss: 0.9943214654922485
Validation loss: 2.218455215295156

Epoch: 5| Step: 11
Training loss: 1.0548069477081299
Validation loss: 2.246094584465027

Epoch: 179| Step: 0
Training loss: 1.4335871934890747
Validation loss: 2.2494104454914727

Epoch: 5| Step: 1
Training loss: 1.3324825763702393
Validation loss: 2.216636295119921

Epoch: 5| Step: 2
Training loss: 2.05072283744812
Validation loss: 2.188122436404228

Epoch: 5| Step: 3
Training loss: 1.5562357902526855
Validation loss: 2.1578625241915383

Epoch: 5| Step: 4
Training loss: 0.8307867050170898
Validation loss: 2.1312490105628967

Epoch: 5| Step: 5
Training loss: 1.0362502336502075
Validation loss: 2.1342008163531623

Epoch: 5| Step: 6
Training loss: 1.6977096796035767
Validation loss: 2.1002019345760345

Epoch: 5| Step: 7
Training loss: 1.3154115676879883
Validation loss: 2.141215667128563

Epoch: 5| Step: 8
Training loss: 1.2506910562515259
Validation loss: 2.1053488105535507

Epoch: 5| Step: 9
Training loss: 1.5346519947052002
Validation loss: 2.132417157292366

Epoch: 5| Step: 10
Training loss: 0.9321308135986328
Validation loss: 2.1299001971880593

Epoch: 5| Step: 11
Training loss: 1.829024314880371
Validation loss: 2.121637523174286

Epoch: 180| Step: 0
Training loss: 1.1538615226745605
Validation loss: 2.1920883854230246

Epoch: 5| Step: 1
Training loss: 1.031166911125183
Validation loss: 2.195252979795138

Epoch: 5| Step: 2
Training loss: 1.2864130735397339
Validation loss: 2.2812047402064004

Epoch: 5| Step: 3
Training loss: 1.5860037803649902
Validation loss: 2.219612101713816

Epoch: 5| Step: 4
Training loss: 1.3788713216781616
Validation loss: 2.2545242607593536

Epoch: 5| Step: 5
Training loss: 1.8752110004425049
Validation loss: 2.2519161850214005

Epoch: 5| Step: 6
Training loss: 0.8725069165229797
Validation loss: 2.2561344603697457

Epoch: 5| Step: 7
Training loss: 1.4260327816009521
Validation loss: 2.1789106726646423

Epoch: 5| Step: 8
Training loss: 0.8136804699897766
Validation loss: 2.1967504421869912

Epoch: 5| Step: 9
Training loss: 1.811819076538086
Validation loss: 2.13482295970122

Epoch: 5| Step: 10
Training loss: 1.5664794445037842
Validation loss: 2.130051463842392

Epoch: 5| Step: 11
Training loss: 1.7332608699798584
Validation loss: 2.096325606107712

Epoch: 181| Step: 0
Training loss: 1.514980673789978
Validation loss: 2.214000125726064

Epoch: 5| Step: 1
Training loss: 1.615618109703064
Validation loss: 2.1737207720677056

Epoch: 5| Step: 2
Training loss: 1.4920332431793213
Validation loss: 2.148991803328196

Epoch: 5| Step: 3
Training loss: 1.6202656030654907
Validation loss: 2.1403047293424606

Epoch: 5| Step: 4
Training loss: 1.111526608467102
Validation loss: 2.1321917523940406

Epoch: 5| Step: 5
Training loss: 1.1585389375686646
Validation loss: 2.1634152829647064

Epoch: 5| Step: 6
Training loss: 0.991040825843811
Validation loss: 2.183466523885727

Epoch: 5| Step: 7
Training loss: 1.66073739528656
Validation loss: 2.166666328907013

Epoch: 5| Step: 8
Training loss: 1.5861488580703735
Validation loss: 2.201483110586802

Epoch: 5| Step: 9
Training loss: 1.4245655536651611
Validation loss: 2.1767410586277642

Epoch: 5| Step: 10
Training loss: 0.8711608648300171
Validation loss: 2.2103914568821588

Epoch: 5| Step: 11
Training loss: 2.0787148475646973
Validation loss: 2.1432031989097595

Epoch: 182| Step: 0
Training loss: 1.9392725229263306
Validation loss: 2.1435634195804596

Epoch: 5| Step: 1
Training loss: 1.5562427043914795
Validation loss: 2.143504207332929

Epoch: 5| Step: 2
Training loss: 1.2483181953430176
Validation loss: 2.1565570384263992

Epoch: 5| Step: 3
Training loss: 1.1965891122817993
Validation loss: 2.1276674469312034

Epoch: 5| Step: 4
Training loss: 1.09830641746521
Validation loss: 2.1685683826605477

Epoch: 5| Step: 5
Training loss: 1.3892909288406372
Validation loss: 2.1740804612636566

Epoch: 5| Step: 6
Training loss: 1.5064431428909302
Validation loss: 2.1458305219809213

Epoch: 5| Step: 7
Training loss: 1.4823839664459229
Validation loss: 2.1865098973115287

Epoch: 5| Step: 8
Training loss: 1.3457667827606201
Validation loss: 2.1787910560766854

Epoch: 5| Step: 9
Training loss: 1.0873820781707764
Validation loss: 2.1632370154062905

Epoch: 5| Step: 10
Training loss: 0.7130602598190308
Validation loss: 2.191919833421707

Epoch: 5| Step: 11
Training loss: 1.0074377059936523
Validation loss: 2.1835276087125144

Epoch: 183| Step: 0
Training loss: 1.5041511058807373
Validation loss: 2.1610023180643716

Epoch: 5| Step: 1
Training loss: 1.050061583518982
Validation loss: 2.191494102279345

Epoch: 5| Step: 2
Training loss: 1.0883996486663818
Validation loss: 2.1944185197353363

Epoch: 5| Step: 3
Training loss: 1.4861348867416382
Validation loss: 2.1869756281375885

Epoch: 5| Step: 4
Training loss: 1.9504600763320923
Validation loss: 2.2068389455477395

Epoch: 5| Step: 5
Training loss: 0.9322355389595032
Validation loss: 2.19487926363945

Epoch: 5| Step: 6
Training loss: 1.4264702796936035
Validation loss: 2.182468165953954

Epoch: 5| Step: 7
Training loss: 1.6766042709350586
Validation loss: 2.19528791308403

Epoch: 5| Step: 8
Training loss: 0.9843427538871765
Validation loss: 2.1713220526774726

Epoch: 5| Step: 9
Training loss: 0.8730066418647766
Validation loss: 2.164263313015302

Epoch: 5| Step: 10
Training loss: 1.3057001829147339
Validation loss: 2.161656682689985

Epoch: 5| Step: 11
Training loss: 0.9929194450378418
Validation loss: 2.1892434606949487

Epoch: 184| Step: 0
Training loss: 1.7173032760620117
Validation loss: 2.139701505502065

Epoch: 5| Step: 1
Training loss: 1.1073402166366577
Validation loss: 2.0706197718779245

Epoch: 5| Step: 2
Training loss: 0.9881874918937683
Validation loss: 2.1965197771787643

Epoch: 5| Step: 3
Training loss: 1.1941967010498047
Validation loss: 2.1490763972202935

Epoch: 5| Step: 4
Training loss: 1.0385323762893677
Validation loss: 2.1336157669623694

Epoch: 5| Step: 5
Training loss: 1.9585329294204712
Validation loss: 2.2064832548300424

Epoch: 5| Step: 6
Training loss: 1.1614506244659424
Validation loss: 2.192746713757515

Epoch: 5| Step: 7
Training loss: 1.202603816986084
Validation loss: 2.15826024611791

Epoch: 5| Step: 8
Training loss: 1.5534675121307373
Validation loss: 2.159626215696335

Epoch: 5| Step: 9
Training loss: 1.0786172151565552
Validation loss: 2.212618425488472

Epoch: 5| Step: 10
Training loss: 1.164858341217041
Validation loss: 2.1878853738307953

Epoch: 5| Step: 11
Training loss: 0.5584688186645508
Validation loss: 2.303715169429779

Epoch: 185| Step: 0
Training loss: 1.6348655223846436
Validation loss: 2.288613180319468

Epoch: 5| Step: 1
Training loss: 1.2293751239776611
Validation loss: 2.2442473818858466

Epoch: 5| Step: 2
Training loss: 0.7670673131942749
Validation loss: 2.2502628167470298

Epoch: 5| Step: 3
Training loss: 1.3210270404815674
Validation loss: 2.248799135287603

Epoch: 5| Step: 4
Training loss: 2.034794330596924
Validation loss: 2.1955863386392593

Epoch: 5| Step: 5
Training loss: 1.323601484298706
Validation loss: 2.120630845427513

Epoch: 5| Step: 6
Training loss: 1.17885422706604
Validation loss: 2.1623840034008026

Epoch: 5| Step: 7
Training loss: 1.1170313358306885
Validation loss: 2.188562979300817

Epoch: 5| Step: 8
Training loss: 1.7283309698104858
Validation loss: 2.1541295250256858

Epoch: 5| Step: 9
Training loss: 0.9092920422554016
Validation loss: 2.160695175329844

Epoch: 5| Step: 10
Training loss: 1.2645410299301147
Validation loss: 2.1635011533896127

Epoch: 5| Step: 11
Training loss: 1.235041856765747
Validation loss: 2.1455677847067514

Epoch: 186| Step: 0
Training loss: 0.9514428377151489
Validation loss: 2.113135283191999

Epoch: 5| Step: 1
Training loss: 0.9609612226486206
Validation loss: 2.1320449113845825

Epoch: 5| Step: 2
Training loss: 1.2468429803848267
Validation loss: 2.1323043008645377

Epoch: 5| Step: 3
Training loss: 1.3007519245147705
Validation loss: 2.218873381614685

Epoch: 5| Step: 4
Training loss: 1.6332199573516846
Validation loss: 2.188112889726957

Epoch: 5| Step: 5
Training loss: 1.1232516765594482
Validation loss: 2.2380966941515603

Epoch: 5| Step: 6
Training loss: 0.8355607986450195
Validation loss: 2.2290982604026794

Epoch: 5| Step: 7
Training loss: 1.1165268421173096
Validation loss: 2.211978485186895

Epoch: 5| Step: 8
Training loss: 1.528977394104004
Validation loss: 2.2018882731596627

Epoch: 5| Step: 9
Training loss: 1.4148874282836914
Validation loss: 2.181137333313624

Epoch: 5| Step: 10
Training loss: 1.7002378702163696
Validation loss: 2.1586812237898507

Epoch: 5| Step: 11
Training loss: 2.2637200355529785
Validation loss: 2.22019225358963

Epoch: 187| Step: 0
Training loss: 2.2100272178649902
Validation loss: 2.137931674718857

Epoch: 5| Step: 1
Training loss: 1.1732810735702515
Validation loss: 2.1602971305449805

Epoch: 5| Step: 2
Training loss: 1.5195680856704712
Validation loss: 2.1741863638162613

Epoch: 5| Step: 3
Training loss: 1.2105529308319092
Validation loss: 2.1597250252962112

Epoch: 5| Step: 4
Training loss: 1.4031140804290771
Validation loss: 2.200517709056536

Epoch: 5| Step: 5
Training loss: 1.0635114908218384
Validation loss: 2.176505739490191

Epoch: 5| Step: 6
Training loss: 1.205867886543274
Validation loss: 2.1605889002482095

Epoch: 5| Step: 7
Training loss: 1.0605186223983765
Validation loss: 2.1784093528985977

Epoch: 5| Step: 8
Training loss: 0.900501549243927
Validation loss: 2.1584813992182412

Epoch: 5| Step: 9
Training loss: 1.6635706424713135
Validation loss: 2.1454205214977264

Epoch: 5| Step: 10
Training loss: 0.8266925811767578
Validation loss: 2.2565650989611945

Epoch: 5| Step: 11
Training loss: 0.3223527669906616
Validation loss: 2.2228775272766748

Epoch: 188| Step: 0
Training loss: 1.8799114227294922
Validation loss: 2.2427255709966025

Epoch: 5| Step: 1
Training loss: 0.8515669107437134
Validation loss: 2.277526209751765

Epoch: 5| Step: 2
Training loss: 1.372238039970398
Validation loss: 2.2474894722302756

Epoch: 5| Step: 3
Training loss: 1.340726613998413
Validation loss: 2.1831765472888947

Epoch: 5| Step: 4
Training loss: 1.105243444442749
Validation loss: 2.273523504535357

Epoch: 5| Step: 5
Training loss: 1.2301723957061768
Validation loss: 2.1485700756311417

Epoch: 5| Step: 6
Training loss: 0.847186267375946
Validation loss: 2.187989746530851

Epoch: 5| Step: 7
Training loss: 1.7307946681976318
Validation loss: 2.184592694044113

Epoch: 5| Step: 8
Training loss: 1.4296190738677979
Validation loss: 2.2146150370438895

Epoch: 5| Step: 9
Training loss: 1.0601989030838013
Validation loss: 2.1901434808969498

Epoch: 5| Step: 10
Training loss: 1.0335050821304321
Validation loss: 2.1693070431550345

Epoch: 5| Step: 11
Training loss: 0.8076108694076538
Validation loss: 2.117092380921046

Epoch: 189| Step: 0
Training loss: 1.6196693181991577
Validation loss: 2.1417378236850104

Epoch: 5| Step: 1
Training loss: 1.4179539680480957
Validation loss: 2.1890110075473785

Epoch: 5| Step: 2
Training loss: 1.392414927482605
Validation loss: 2.1410257667303085

Epoch: 5| Step: 3
Training loss: 1.1012052297592163
Validation loss: 2.1585304588079453

Epoch: 5| Step: 4
Training loss: 1.3667452335357666
Validation loss: 2.2119121700525284

Epoch: 5| Step: 5
Training loss: 1.4503248929977417
Validation loss: 2.2080331444740295

Epoch: 5| Step: 6
Training loss: 1.1245744228363037
Validation loss: 2.158558482925097

Epoch: 5| Step: 7
Training loss: 1.6705013513565063
Validation loss: 2.176644191145897

Epoch: 5| Step: 8
Training loss: 1.2892239093780518
Validation loss: 2.1759925385316214

Epoch: 5| Step: 9
Training loss: 0.772950291633606
Validation loss: 2.220403641462326

Epoch: 5| Step: 10
Training loss: 0.8568288087844849
Validation loss: 2.2030848562717438

Epoch: 5| Step: 11
Training loss: 0.8608444929122925
Validation loss: 2.2128860702117286

Epoch: 190| Step: 0
Training loss: 1.5194437503814697
Validation loss: 2.2131309310595193

Epoch: 5| Step: 1
Training loss: 1.1118369102478027
Validation loss: 2.158582935730616

Epoch: 5| Step: 2
Training loss: 1.7003233432769775
Validation loss: 2.174978122115135

Epoch: 5| Step: 3
Training loss: 1.4404939413070679
Validation loss: 2.162874311208725

Epoch: 5| Step: 4
Training loss: 1.4233238697052002
Validation loss: 2.156282896796862

Epoch: 5| Step: 5
Training loss: 0.8941307067871094
Validation loss: 2.2123941779136658

Epoch: 5| Step: 6
Training loss: 0.9678627848625183
Validation loss: 2.198161388436953

Epoch: 5| Step: 7
Training loss: 1.0944864749908447
Validation loss: 2.149673104286194

Epoch: 5| Step: 8
Training loss: 0.8982504606246948
Validation loss: 2.1249928176403046

Epoch: 5| Step: 9
Training loss: 1.4196231365203857
Validation loss: 2.217697804172834

Epoch: 5| Step: 10
Training loss: 1.1676146984100342
Validation loss: 2.166728009780248

Epoch: 5| Step: 11
Training loss: 1.346294641494751
Validation loss: 2.1486452519893646

Epoch: 191| Step: 0
Training loss: 0.9165422320365906
Validation loss: 2.2342737863461175

Epoch: 5| Step: 1
Training loss: 1.6653172969818115
Validation loss: 2.2314635515213013

Epoch: 5| Step: 2
Training loss: 1.1589794158935547
Validation loss: 2.230187550187111

Epoch: 5| Step: 3
Training loss: 1.2605215311050415
Validation loss: 2.1453721821308136

Epoch: 5| Step: 4
Training loss: 1.5003836154937744
Validation loss: 2.2115208009878793

Epoch: 5| Step: 5
Training loss: 1.2658064365386963
Validation loss: 2.188037564357122

Epoch: 5| Step: 6
Training loss: 1.0555810928344727
Validation loss: 2.1984153737624488

Epoch: 5| Step: 7
Training loss: 1.4903926849365234
Validation loss: 2.152834410468737

Epoch: 5| Step: 8
Training loss: 0.7840756177902222
Validation loss: 2.196632961432139

Epoch: 5| Step: 9
Training loss: 1.6727184057235718
Validation loss: 2.1780631293853125

Epoch: 5| Step: 10
Training loss: 1.1308603286743164
Validation loss: 2.146745895346006

Epoch: 5| Step: 11
Training loss: 1.3874759674072266
Validation loss: 2.2344302435715995

Epoch: 192| Step: 0
Training loss: 1.3417714834213257
Validation loss: 2.1594593822956085

Epoch: 5| Step: 1
Training loss: 0.8943266868591309
Validation loss: 2.232884719967842

Epoch: 5| Step: 2
Training loss: 1.7159998416900635
Validation loss: 2.1556619703769684

Epoch: 5| Step: 3
Training loss: 0.7178552746772766
Validation loss: 2.16767884294192

Epoch: 5| Step: 4
Training loss: 1.7508659362792969
Validation loss: 2.2114632626374564

Epoch: 5| Step: 5
Training loss: 1.090773105621338
Validation loss: 2.2247765163580575

Epoch: 5| Step: 6
Training loss: 1.2667529582977295
Validation loss: 2.124020501971245

Epoch: 5| Step: 7
Training loss: 1.43791925907135
Validation loss: 2.186534489194552

Epoch: 5| Step: 8
Training loss: 1.0590760707855225
Validation loss: 2.1227538188298545

Epoch: 5| Step: 9
Training loss: 1.2021989822387695
Validation loss: 2.2153574377298355

Epoch: 5| Step: 10
Training loss: 0.8688606023788452
Validation loss: 2.2155603915452957

Epoch: 5| Step: 11
Training loss: 1.0524507761001587
Validation loss: 2.24408166607221

Epoch: 193| Step: 0
Training loss: 1.2270028591156006
Validation loss: 2.129806404312452

Epoch: 5| Step: 1
Training loss: 1.1059315204620361
Validation loss: 2.1230179915825524

Epoch: 5| Step: 2
Training loss: 0.9953784942626953
Validation loss: 2.1526562670866647

Epoch: 5| Step: 3
Training loss: 0.9416232109069824
Validation loss: 2.197836091121038

Epoch: 5| Step: 4
Training loss: 1.7472823858261108
Validation loss: 2.169704074660937

Epoch: 5| Step: 5
Training loss: 1.0615023374557495
Validation loss: 2.1462884644667306

Epoch: 5| Step: 6
Training loss: 1.33888840675354
Validation loss: 2.174318015575409

Epoch: 5| Step: 7
Training loss: 1.3011499643325806
Validation loss: 2.1921259661515555

Epoch: 5| Step: 8
Training loss: 1.3583545684814453
Validation loss: 2.1387475778659186

Epoch: 5| Step: 9
Training loss: 1.3616851568222046
Validation loss: 2.268457517027855

Epoch: 5| Step: 10
Training loss: 1.131134271621704
Validation loss: 2.2840936382611594

Epoch: 5| Step: 11
Training loss: 0.6138534545898438
Validation loss: 2.221526116132736

Epoch: 194| Step: 0
Training loss: 1.7917327880859375
Validation loss: 2.2230058014392853

Epoch: 5| Step: 1
Training loss: 0.7382127046585083
Validation loss: 2.309634173909823

Epoch: 5| Step: 2
Training loss: 1.211463451385498
Validation loss: 2.1884408642848334

Epoch: 5| Step: 3
Training loss: 1.5909560918807983
Validation loss: 2.220469738046328

Epoch: 5| Step: 4
Training loss: 1.2980104684829712
Validation loss: 2.22727137307326

Epoch: 5| Step: 5
Training loss: 1.3785836696624756
Validation loss: 2.1231610625982285

Epoch: 5| Step: 6
Training loss: 1.2475321292877197
Validation loss: 2.2519115855296454

Epoch: 5| Step: 7
Training loss: 1.5790616273880005
Validation loss: 2.166310022274653

Epoch: 5| Step: 8
Training loss: 1.6571471691131592
Validation loss: 2.17758442958196

Epoch: 5| Step: 9
Training loss: 1.4327924251556396
Validation loss: 2.1900889575481415

Epoch: 5| Step: 10
Training loss: 0.8430124521255493
Validation loss: 2.1510483473539352

Epoch: 5| Step: 11
Training loss: 1.1466021537780762
Validation loss: 2.210514177878698

Epoch: 195| Step: 0
Training loss: 1.6632797718048096
Validation loss: 2.16666641831398

Epoch: 5| Step: 1
Training loss: 1.3157827854156494
Validation loss: 2.2477110574642816

Epoch: 5| Step: 2
Training loss: 1.6712360382080078
Validation loss: 2.336700956026713

Epoch: 5| Step: 3
Training loss: 1.3706625699996948
Validation loss: 2.32848613957564

Epoch: 5| Step: 4
Training loss: 1.5866758823394775
Validation loss: 2.3105066468318305

Epoch: 5| Step: 5
Training loss: 1.2412828207015991
Validation loss: 2.2783828477064767

Epoch: 5| Step: 6
Training loss: 1.4967296123504639
Validation loss: 2.2759017447630563

Epoch: 5| Step: 7
Training loss: 1.6143252849578857
Validation loss: 2.2053096095720925

Epoch: 5| Step: 8
Training loss: 0.7887197732925415
Validation loss: 2.209529380003611

Epoch: 5| Step: 9
Training loss: 1.3106377124786377
Validation loss: 2.207695076862971

Epoch: 5| Step: 10
Training loss: 0.7653695940971375
Validation loss: 2.1758352518081665

Epoch: 5| Step: 11
Training loss: 0.13929876685142517
Validation loss: 2.1390797197818756

Epoch: 196| Step: 0
Training loss: 1.3597885370254517
Validation loss: 2.1973014970620475

Epoch: 5| Step: 1
Training loss: 1.3932387828826904
Validation loss: 2.146721134583155

Epoch: 5| Step: 2
Training loss: 1.0742056369781494
Validation loss: 2.1431700785954795

Epoch: 5| Step: 3
Training loss: 0.7785897254943848
Validation loss: 2.1456765681505203

Epoch: 5| Step: 4
Training loss: 1.5686732530593872
Validation loss: 2.1507564584414163

Epoch: 5| Step: 5
Training loss: 1.714037299156189
Validation loss: 2.177885894974073

Epoch: 5| Step: 6
Training loss: 0.753852903842926
Validation loss: 2.2251032094160714

Epoch: 5| Step: 7
Training loss: 1.2459981441497803
Validation loss: 2.198613186677297

Epoch: 5| Step: 8
Training loss: 1.4274578094482422
Validation loss: 2.2241350213686624

Epoch: 5| Step: 9
Training loss: 0.8658685684204102
Validation loss: 2.1743761946757636

Epoch: 5| Step: 10
Training loss: 0.8163784146308899
Validation loss: 2.1671948532263436

Epoch: 5| Step: 11
Training loss: 2.161665678024292
Validation loss: 2.1696059008439383

Epoch: 197| Step: 0
Training loss: 1.028167486190796
Validation loss: 2.174461921056112

Epoch: 5| Step: 1
Training loss: 1.557616949081421
Validation loss: 2.205608849724134

Epoch: 5| Step: 2
Training loss: 1.2395020723342896
Validation loss: 2.2232287724812827

Epoch: 5| Step: 3
Training loss: 1.003774642944336
Validation loss: 2.2375775277614594

Epoch: 5| Step: 4
Training loss: 1.5609689950942993
Validation loss: 2.1928249994913735

Epoch: 5| Step: 5
Training loss: 1.2139546871185303
Validation loss: 2.2079836626847587

Epoch: 5| Step: 6
Training loss: 1.3155351877212524
Validation loss: 2.233337094386419

Epoch: 5| Step: 7
Training loss: 0.9492406845092773
Validation loss: 2.1477884650230408

Epoch: 5| Step: 8
Training loss: 1.1307737827301025
Validation loss: 2.174125517408053

Epoch: 5| Step: 9
Training loss: 1.1141633987426758
Validation loss: 2.249501725037893

Epoch: 5| Step: 10
Training loss: 1.1088651418685913
Validation loss: 2.2320735454559326

Epoch: 5| Step: 11
Training loss: 0.3627232313156128
Validation loss: 2.183989495038986

Epoch: 198| Step: 0
Training loss: 1.1116167306900024
Validation loss: 2.172901580731074

Epoch: 5| Step: 1
Training loss: 0.9960182905197144
Validation loss: 2.221387133002281

Epoch: 5| Step: 2
Training loss: 1.1592077016830444
Validation loss: 2.1572778125603995

Epoch: 5| Step: 3
Training loss: 1.2965061664581299
Validation loss: 2.1569054474433265

Epoch: 5| Step: 4
Training loss: 0.8751594424247742
Validation loss: 2.2241536329189935

Epoch: 5| Step: 5
Training loss: 1.0951629877090454
Validation loss: 2.212921271721522

Epoch: 5| Step: 6
Training loss: 1.0750949382781982
Validation loss: 2.200691024462382

Epoch: 5| Step: 7
Training loss: 1.1419181823730469
Validation loss: 2.197859153151512

Epoch: 5| Step: 8
Training loss: 1.0512664318084717
Validation loss: 2.1455255250136056

Epoch: 5| Step: 9
Training loss: 1.635457992553711
Validation loss: 2.1744157870610556

Epoch: 5| Step: 10
Training loss: 1.1300384998321533
Validation loss: 2.205799678961436

Epoch: 5| Step: 11
Training loss: 1.8443551063537598
Validation loss: 2.240343749523163

Epoch: 199| Step: 0
Training loss: 1.3449519872665405
Validation loss: 2.183662782112757

Epoch: 5| Step: 1
Training loss: 1.021924614906311
Validation loss: 2.217755973339081

Epoch: 5| Step: 2
Training loss: 1.6381194591522217
Validation loss: 2.1804786920547485

Epoch: 5| Step: 3
Training loss: 1.2406361103057861
Validation loss: 2.1712097575267157

Epoch: 5| Step: 4
Training loss: 0.7583069205284119
Validation loss: 2.20697487394015

Epoch: 5| Step: 5
Training loss: 0.8666200637817383
Validation loss: 2.168826843301455

Epoch: 5| Step: 6
Training loss: 0.8933453559875488
Validation loss: 2.1361297766367593

Epoch: 5| Step: 7
Training loss: 1.239485502243042
Validation loss: 2.179409936070442

Epoch: 5| Step: 8
Training loss: 1.20830237865448
Validation loss: 2.149657835563024

Epoch: 5| Step: 9
Training loss: 1.1656553745269775
Validation loss: 2.218176061908404

Epoch: 5| Step: 10
Training loss: 1.2561734914779663
Validation loss: 2.234653557340304

Epoch: 5| Step: 11
Training loss: 1.7035529613494873
Validation loss: 2.1911100993553796

Epoch: 200| Step: 0
Training loss: 0.9045488238334656
Validation loss: 2.1660159776608148

Epoch: 5| Step: 1
Training loss: 0.9047352075576782
Validation loss: 2.1953483720620475

Epoch: 5| Step: 2
Training loss: 1.0919147729873657
Validation loss: 2.200458988547325

Epoch: 5| Step: 3
Training loss: 1.817604660987854
Validation loss: 2.1738061606884003

Epoch: 5| Step: 4
Training loss: 1.1692469120025635
Validation loss: 2.138153597712517

Epoch: 5| Step: 5
Training loss: 1.180736780166626
Validation loss: 2.1189107100168862

Epoch: 5| Step: 6
Training loss: 0.9697545170783997
Validation loss: 2.2390116254488626

Epoch: 5| Step: 7
Training loss: 1.0518169403076172
Validation loss: 2.1786006689071655

Epoch: 5| Step: 8
Training loss: 1.1034208536148071
Validation loss: 2.185622145732244

Epoch: 5| Step: 9
Training loss: 1.3845092058181763
Validation loss: 2.218515624602636

Epoch: 5| Step: 10
Training loss: 1.2977042198181152
Validation loss: 2.2177693297465644

Epoch: 5| Step: 11
Training loss: 1.5469844341278076
Validation loss: 2.160290921727816

Testing loss: 2.1470683204184335
