Epoch: 1| Step: 0
Training loss: 7.249540380181143
Validation loss: 6.901331097753321

Epoch: 6| Step: 1
Training loss: 7.1368227127929895
Validation loss: 6.864823641548069

Epoch: 6| Step: 2
Training loss: 6.746852564807534
Validation loss: 6.834166576787233

Epoch: 6| Step: 3
Training loss: 7.362184931647223
Validation loss: 6.796475617232297

Epoch: 6| Step: 4
Training loss: 7.225905269944717
Validation loss: 6.764655791907785

Epoch: 6| Step: 5
Training loss: 7.1780370365610535
Validation loss: 6.733095358744347

Epoch: 6| Step: 6
Training loss: 6.186387087215857
Validation loss: 6.70537908041451

Epoch: 6| Step: 7
Training loss: 7.1475177110610675
Validation loss: 6.6771904217190885

Epoch: 6| Step: 8
Training loss: 5.76012458083743
Validation loss: 6.649462037089198

Epoch: 6| Step: 9
Training loss: 6.522542743652466
Validation loss: 6.622780818051939

Epoch: 6| Step: 10
Training loss: 7.359621469051557
Validation loss: 6.603392193586639

Epoch: 6| Step: 11
Training loss: 6.539980077684022
Validation loss: 6.5764688685905766

Epoch: 6| Step: 12
Training loss: 6.204235525199574
Validation loss: 6.547455463760464

Epoch: 6| Step: 13
Training loss: 6.552005187166464
Validation loss: 6.525457414401161

Epoch: 2| Step: 0
Training loss: 6.491326046561938
Validation loss: 6.4906368308769915

Epoch: 6| Step: 1
Training loss: 7.427450105903344
Validation loss: 6.463287258341369

Epoch: 6| Step: 2
Training loss: 6.374851898268187
Validation loss: 6.433345305805562

Epoch: 6| Step: 3
Training loss: 6.498866642666255
Validation loss: 6.403638800676251

Epoch: 6| Step: 4
Training loss: 6.1346763937119295
Validation loss: 6.376373791241118

Epoch: 6| Step: 5
Training loss: 6.425346382986478
Validation loss: 6.334509271905835

Epoch: 6| Step: 6
Training loss: 6.868783533155037
Validation loss: 6.307492526757178

Epoch: 6| Step: 7
Training loss: 6.855777014080671
Validation loss: 6.27477364505458

Epoch: 6| Step: 8
Training loss: 6.806213838395386
Validation loss: 6.240168608237814

Epoch: 6| Step: 9
Training loss: 5.782964998474743
Validation loss: 6.2083223927377995

Epoch: 6| Step: 10
Training loss: 6.008205207520281
Validation loss: 6.166587038642973

Epoch: 6| Step: 11
Training loss: 5.899286595549142
Validation loss: 6.1225384806883625

Epoch: 6| Step: 12
Training loss: 6.025207971806087
Validation loss: 6.089365263601613

Epoch: 6| Step: 13
Training loss: 5.668913937924592
Validation loss: 6.053068631234174

Epoch: 3| Step: 0
Training loss: 6.187363131772214
Validation loss: 6.000740588364575

Epoch: 6| Step: 1
Training loss: 4.6674097468635845
Validation loss: 5.957792413162291

Epoch: 6| Step: 2
Training loss: 7.074871738740492
Validation loss: 5.912742154926884

Epoch: 6| Step: 3
Training loss: 5.779822590887103
Validation loss: 5.866338364489498

Epoch: 6| Step: 4
Training loss: 5.902661075809698
Validation loss: 5.820366461928263

Epoch: 6| Step: 5
Training loss: 6.118965757655404
Validation loss: 5.768423226725281

Epoch: 6| Step: 6
Training loss: 5.562280714877543
Validation loss: 5.707904822793966

Epoch: 6| Step: 7
Training loss: 6.1099169556613555
Validation loss: 5.654385225948699

Epoch: 6| Step: 8
Training loss: 6.073740184122033
Validation loss: 5.592101438460012

Epoch: 6| Step: 9
Training loss: 4.966280149401448
Validation loss: 5.536623196615906

Epoch: 6| Step: 10
Training loss: 5.374814407338181
Validation loss: 5.471989542257715

Epoch: 6| Step: 11
Training loss: 5.652928509942912
Validation loss: 5.405547285623596

Epoch: 6| Step: 12
Training loss: 4.647525473489456
Validation loss: 5.33358981091991

Epoch: 6| Step: 13
Training loss: 6.151950012202368
Validation loss: 5.2613269383436245

Epoch: 4| Step: 0
Training loss: 5.2863358607144315
Validation loss: 5.190438996836273

Epoch: 6| Step: 1
Training loss: 6.008121398207239
Validation loss: 5.104945729285094

Epoch: 6| Step: 2
Training loss: 5.803365441324253
Validation loss: 5.025509135705464

Epoch: 6| Step: 3
Training loss: 4.23046131080544
Validation loss: 4.939271086122218

Epoch: 6| Step: 4
Training loss: 5.341753670414859
Validation loss: 4.840477639950138

Epoch: 6| Step: 5
Training loss: 4.701215286593291
Validation loss: 4.749622748267979

Epoch: 6| Step: 6
Training loss: 4.629506570381457
Validation loss: 4.657407851345906

Epoch: 6| Step: 7
Training loss: 4.740019703433777
Validation loss: 4.566168699239545

Epoch: 6| Step: 8
Training loss: 4.440249169033813
Validation loss: 4.470188220653358

Epoch: 6| Step: 9
Training loss: 4.708385681041385
Validation loss: 4.361912434385378

Epoch: 6| Step: 10
Training loss: 4.346736183390711
Validation loss: 4.272631172203767

Epoch: 6| Step: 11
Training loss: 3.817574297888315
Validation loss: 4.145358449808494

Epoch: 6| Step: 12
Training loss: 3.934362705687205
Validation loss: 4.047698026842909

Epoch: 6| Step: 13
Training loss: 3.042928947609555
Validation loss: 3.9349318914404434

Epoch: 5| Step: 0
Training loss: 3.8745111957013667
Validation loss: 3.817053301077868

Epoch: 6| Step: 1
Training loss: 3.429481587061469
Validation loss: 3.7115024498005504

Epoch: 6| Step: 2
Training loss: 3.3390481280034057
Validation loss: 3.5931855131565373

Epoch: 6| Step: 3
Training loss: 3.230145181044499
Validation loss: 3.4889956914208735

Epoch: 6| Step: 4
Training loss: 4.320807375166245
Validation loss: 3.3620116539805536

Epoch: 6| Step: 5
Training loss: 4.023184818370102
Validation loss: 3.268503383769135

Epoch: 6| Step: 6
Training loss: 3.4444119407460123
Validation loss: 3.138573503169257

Epoch: 6| Step: 7
Training loss: 2.5389992104491923
Validation loss: 3.066436508256198

Epoch: 6| Step: 8
Training loss: 3.082413372917086
Validation loss: 2.983600602529574

Epoch: 6| Step: 9
Training loss: 2.182750231893036
Validation loss: 2.9006613591112793

Epoch: 6| Step: 10
Training loss: 3.3916682031676415
Validation loss: 2.8659852683688527

Epoch: 6| Step: 11
Training loss: 2.6127937443788563
Validation loss: 2.7812135386845154

Epoch: 6| Step: 12
Training loss: 2.8513594881715867
Validation loss: 2.7633343421955665

Epoch: 6| Step: 13
Training loss: 2.3743356478232327
Validation loss: 2.7318993978487995

Epoch: 6| Step: 0
Training loss: 2.6115207643861122
Validation loss: 2.7354278426705902

Epoch: 6| Step: 1
Training loss: 2.983718240582473
Validation loss: 2.750641328993885

Epoch: 6| Step: 2
Training loss: 2.314129023655025
Validation loss: 2.7491032698915556

Epoch: 6| Step: 3
Training loss: 3.0627386817564197
Validation loss: 2.7527350061093907

Epoch: 6| Step: 4
Training loss: 3.019481821383518
Validation loss: 2.8062393018352942

Epoch: 6| Step: 5
Training loss: 3.383851206815714
Validation loss: 2.8503219205175556

Epoch: 6| Step: 6
Training loss: 3.1380923863189945
Validation loss: 2.811368644068646

Epoch: 6| Step: 7
Training loss: 2.2212171135884584
Validation loss: 2.8635508994495633

Epoch: 6| Step: 8
Training loss: 1.9499114187612792
Validation loss: 2.835464648294617

Epoch: 6| Step: 9
Training loss: 3.297677471252569
Validation loss: 2.864555092874675

Epoch: 6| Step: 10
Training loss: 2.5578914231676926
Validation loss: 2.8548518330685075

Epoch: 6| Step: 11
Training loss: 2.2907256766516997
Validation loss: 2.872074795187338

Epoch: 6| Step: 12
Training loss: 2.59249718985042
Validation loss: 2.8396941525578074

Epoch: 6| Step: 13
Training loss: 2.73577330666847
Validation loss: 2.8227010740790774

Epoch: 7| Step: 0
Training loss: 2.172362128866434
Validation loss: 2.827362421400488

Epoch: 6| Step: 1
Training loss: 2.9473193386838297
Validation loss: 2.790342092608823

Epoch: 6| Step: 2
Training loss: 2.475010719661425
Validation loss: 2.7613744021946878

Epoch: 6| Step: 3
Training loss: 2.519561246944736
Validation loss: 2.7548678836194886

Epoch: 6| Step: 4
Training loss: 2.9244898554990737
Validation loss: 2.7526378262620317

Epoch: 6| Step: 5
Training loss: 2.660958727820815
Validation loss: 2.7134334862366813

Epoch: 6| Step: 6
Training loss: 2.051437534497889
Validation loss: 2.7257006284045606

Epoch: 6| Step: 7
Training loss: 2.676236880972724
Validation loss: 2.7321437924143344

Epoch: 6| Step: 8
Training loss: 3.0940716508830786
Validation loss: 2.7498594594936216

Epoch: 6| Step: 9
Training loss: 2.4817702355772715
Validation loss: 2.7433558598779704

Epoch: 6| Step: 10
Training loss: 3.7576411916026657
Validation loss: 2.7264906209745536

Epoch: 6| Step: 11
Training loss: 1.5132292069450235
Validation loss: 2.724086770603099

Epoch: 6| Step: 12
Training loss: 2.5599434357592963
Validation loss: 2.70398890925471

Epoch: 6| Step: 13
Training loss: 3.253943178624482
Validation loss: 2.7187674803190145

Epoch: 8| Step: 0
Training loss: 3.155743548863153
Validation loss: 2.723390426418595

Epoch: 6| Step: 1
Training loss: 2.150679649450221
Validation loss: 2.7111946299157457

Epoch: 6| Step: 2
Training loss: 3.4583596990721635
Validation loss: 2.735513235877909

Epoch: 6| Step: 3
Training loss: 1.4479889702982784
Validation loss: 2.734189940956841

Epoch: 6| Step: 4
Training loss: 3.3100805983857944
Validation loss: 2.724312452318953

Epoch: 6| Step: 5
Training loss: 3.061299925802399
Validation loss: 2.753539783813575

Epoch: 6| Step: 6
Training loss: 2.5571688579172105
Validation loss: 2.7382524010865903

Epoch: 6| Step: 7
Training loss: 2.878302294709756
Validation loss: 2.6926212456576084

Epoch: 6| Step: 8
Training loss: 2.216074014852988
Validation loss: 2.7217458391402753

Epoch: 6| Step: 9
Training loss: 2.3133151705392567
Validation loss: 2.7204324770695036

Epoch: 6| Step: 10
Training loss: 3.064131321734749
Validation loss: 2.727531938444532

Epoch: 6| Step: 11
Training loss: 2.7863007878243713
Validation loss: 2.7270977147138185

Epoch: 6| Step: 12
Training loss: 2.102887158031563
Validation loss: 2.7526392409665337

Epoch: 6| Step: 13
Training loss: 2.678869628655938
Validation loss: 2.766934259143575

Epoch: 9| Step: 0
Training loss: 2.504869962960463
Validation loss: 2.7026730492185114

Epoch: 6| Step: 1
Training loss: 2.8190264953201734
Validation loss: 2.7396447400848887

Epoch: 6| Step: 2
Training loss: 2.81366646207548
Validation loss: 2.7316924387856725

Epoch: 6| Step: 3
Training loss: 2.7061209421021246
Validation loss: 2.7739488586959204

Epoch: 6| Step: 4
Training loss: 2.9752431433556756
Validation loss: 2.7123042315785812

Epoch: 6| Step: 5
Training loss: 2.552224000959598
Validation loss: 2.739912968132765

Epoch: 6| Step: 6
Training loss: 2.334595770143762
Validation loss: 2.7293766222460456

Epoch: 6| Step: 7
Training loss: 3.127168437114002
Validation loss: 2.734457599663878

Epoch: 6| Step: 8
Training loss: 2.824195956696144
Validation loss: 2.7489710096438236

Epoch: 6| Step: 9
Training loss: 2.4649694927563965
Validation loss: 2.7052549228663962

Epoch: 6| Step: 10
Training loss: 1.6716092335174175
Validation loss: 2.725847254287717

Epoch: 6| Step: 11
Training loss: 2.6977170087267464
Validation loss: 2.732840043618529

Epoch: 6| Step: 12
Training loss: 2.338512723498653
Validation loss: 2.7177629688795566

Epoch: 6| Step: 13
Training loss: 3.373993052278159
Validation loss: 2.7323508918055013

Epoch: 10| Step: 0
Training loss: 2.8875153181982585
Validation loss: 2.7349972988629063

Epoch: 6| Step: 1
Training loss: 2.4487125049970455
Validation loss: 2.742833799473831

Epoch: 6| Step: 2
Training loss: 2.6553220137670035
Validation loss: 2.714869803251038

Epoch: 6| Step: 3
Training loss: 2.981483376763239
Validation loss: 2.7527898595292246

Epoch: 6| Step: 4
Training loss: 1.9550238572247949
Validation loss: 2.67754037025808

Epoch: 6| Step: 5
Training loss: 2.7901327179546977
Validation loss: 2.7392500951502994

Epoch: 6| Step: 6
Training loss: 2.91813591780819
Validation loss: 2.736258172559899

Epoch: 6| Step: 7
Training loss: 2.5811936120623846
Validation loss: 2.718793846741437

Epoch: 6| Step: 8
Training loss: 2.267805431450095
Validation loss: 2.7081569956569376

Epoch: 6| Step: 9
Training loss: 2.26651173043387
Validation loss: 2.694996720396369

Epoch: 6| Step: 10
Training loss: 2.828825300144099
Validation loss: 2.7333731423557164

Epoch: 6| Step: 11
Training loss: 2.899919732397037
Validation loss: 2.689607976381463

Epoch: 6| Step: 12
Training loss: 3.2797682550019527
Validation loss: 2.708212781326126

Epoch: 6| Step: 13
Training loss: 2.5222775654408984
Validation loss: 2.725426722429608

Epoch: 11| Step: 0
Training loss: 2.7004879122094323
Validation loss: 2.697677930679791

Epoch: 6| Step: 1
Training loss: 2.530034373807539
Validation loss: 2.6647422423014353

Epoch: 6| Step: 2
Training loss: 2.4467247732921362
Validation loss: 2.741636983561975

Epoch: 6| Step: 3
Training loss: 2.183429309201195
Validation loss: 2.7072352653128506

Epoch: 6| Step: 4
Training loss: 2.9181640232832473
Validation loss: 2.7104214516982803

Epoch: 6| Step: 5
Training loss: 2.91508928060806
Validation loss: 2.705443385834508

Epoch: 6| Step: 6
Training loss: 3.2846081216326724
Validation loss: 2.746053667350238

Epoch: 6| Step: 7
Training loss: 3.0632021352119407
Validation loss: 2.735659502866536

Epoch: 6| Step: 8
Training loss: 2.705893801886882
Validation loss: 2.734877389441122

Epoch: 6| Step: 9
Training loss: 3.09099880384103
Validation loss: 2.6744196859479055

Epoch: 6| Step: 10
Training loss: 3.0793192913822383
Validation loss: 2.7033682182717182

Epoch: 6| Step: 11
Training loss: 1.8853909892938323
Validation loss: 2.6980827064430564

Epoch: 6| Step: 12
Training loss: 2.2445776557838757
Validation loss: 2.7230952532420845

Epoch: 6| Step: 13
Training loss: 2.0090859972110335
Validation loss: 2.7204865065650568

Epoch: 12| Step: 0
Training loss: 2.5224664195522117
Validation loss: 2.671683589035321

Epoch: 6| Step: 1
Training loss: 3.3054921137886333
Validation loss: 2.7410230201859545

Epoch: 6| Step: 2
Training loss: 3.177587016885286
Validation loss: 2.7158038520519914

Epoch: 6| Step: 3
Training loss: 2.744178331869496
Validation loss: 2.699776966690685

Epoch: 6| Step: 4
Training loss: 2.7078891292059537
Validation loss: 2.712418766240976

Epoch: 6| Step: 5
Training loss: 2.5035110614060643
Validation loss: 2.729266380837455

Epoch: 6| Step: 6
Training loss: 2.0099065525480495
Validation loss: 2.7402143198966527

Epoch: 6| Step: 7
Training loss: 2.308166257777212
Validation loss: 2.7347137096068685

Epoch: 6| Step: 8
Training loss: 2.147121067743298
Validation loss: 2.7508330961695533

Epoch: 6| Step: 9
Training loss: 2.7809649546423585
Validation loss: 2.698464199361857

Epoch: 6| Step: 10
Training loss: 2.4973366855993273
Validation loss: 2.713898301561063

Epoch: 6| Step: 11
Training loss: 3.382847457599399
Validation loss: 2.6938964957329166

Epoch: 6| Step: 12
Training loss: 2.081323442509325
Validation loss: 2.7165853864606126

Epoch: 6| Step: 13
Training loss: 2.8977056437890436
Validation loss: 2.716631403696124

Epoch: 13| Step: 0
Training loss: 2.6180920304630937
Validation loss: 2.702812367847722

Epoch: 6| Step: 1
Training loss: 2.562926001145451
Validation loss: 2.702031585111564

Epoch: 6| Step: 2
Training loss: 2.198911601379731
Validation loss: 2.709484557474369

Epoch: 6| Step: 3
Training loss: 2.944390190472384
Validation loss: 2.689087391541777

Epoch: 6| Step: 4
Training loss: 2.1146359993024566
Validation loss: 2.6764310544338286

Epoch: 6| Step: 5
Training loss: 2.813581046984942
Validation loss: 2.725476971567427

Epoch: 6| Step: 6
Training loss: 2.46463268119914
Validation loss: 2.7050671298357885

Epoch: 6| Step: 7
Training loss: 2.666490807297642
Validation loss: 2.7219797878481944

Epoch: 6| Step: 8
Training loss: 2.7198407846021437
Validation loss: 2.7005795086501143

Epoch: 6| Step: 9
Training loss: 1.8560083508139222
Validation loss: 2.685290115566797

Epoch: 6| Step: 10
Training loss: 3.5965652716918735
Validation loss: 2.700005497161544

Epoch: 6| Step: 11
Training loss: 2.484148219092445
Validation loss: 2.723878955353106

Epoch: 6| Step: 12
Training loss: 3.1024442327437822
Validation loss: 2.7087573281989834

Epoch: 6| Step: 13
Training loss: 2.7079923170535753
Validation loss: 2.7315660708440856

Epoch: 14| Step: 0
Training loss: 2.0460558700987796
Validation loss: 2.7330110472348736

Epoch: 6| Step: 1
Training loss: 2.453220341281475
Validation loss: 2.6819480132659748

Epoch: 6| Step: 2
Training loss: 2.2404699891763564
Validation loss: 2.701227878478211

Epoch: 6| Step: 3
Training loss: 2.1913965670393805
Validation loss: 2.7168321531790225

Epoch: 6| Step: 4
Training loss: 3.7829013717907434
Validation loss: 2.6832263885732064

Epoch: 6| Step: 5
Training loss: 1.8936697662781175
Validation loss: 2.6888871863738975

Epoch: 6| Step: 6
Training loss: 2.743028995261927
Validation loss: 2.7183832381591073

Epoch: 6| Step: 7
Training loss: 2.9892917894079325
Validation loss: 2.6595597384903917

Epoch: 6| Step: 8
Training loss: 2.728423349817634
Validation loss: 2.7289064346373118

Epoch: 6| Step: 9
Training loss: 3.231886343949917
Validation loss: 2.700972734761623

Epoch: 6| Step: 10
Training loss: 2.0036916041536093
Validation loss: 2.702927187111201

Epoch: 6| Step: 11
Training loss: 2.9061440069087427
Validation loss: 2.690566848794021

Epoch: 6| Step: 12
Training loss: 2.908407907340536
Validation loss: 2.6955986866152046

Epoch: 6| Step: 13
Training loss: 2.4414134765518045
Validation loss: 2.7400502772718864

Epoch: 15| Step: 0
Training loss: 2.9620797160959116
Validation loss: 2.7019972019590495

Epoch: 6| Step: 1
Training loss: 3.147265649241343
Validation loss: 2.6964368750890357

Epoch: 6| Step: 2
Training loss: 2.189060853226428
Validation loss: 2.673073602015324

Epoch: 6| Step: 3
Training loss: 2.5127252961677815
Validation loss: 2.715426478063576

Epoch: 6| Step: 4
Training loss: 3.3030489563647234
Validation loss: 2.697311853983588

Epoch: 6| Step: 5
Training loss: 2.1524696936340217
Validation loss: 2.692715470816759

Epoch: 6| Step: 6
Training loss: 2.3618189804003182
Validation loss: 2.6918537301252914

Epoch: 6| Step: 7
Training loss: 3.0862687717761434
Validation loss: 2.71564023709019

Epoch: 6| Step: 8
Training loss: 2.544959535708007
Validation loss: 2.693778267554994

Epoch: 6| Step: 9
Training loss: 2.0179786838430243
Validation loss: 2.724275929090043

Epoch: 6| Step: 10
Training loss: 2.2870336922389307
Validation loss: 2.7444051268906238

Epoch: 6| Step: 11
Training loss: 2.8993382455248113
Validation loss: 2.727361669438739

Epoch: 6| Step: 12
Training loss: 2.9059001753084055
Validation loss: 2.715509434601618

Epoch: 6| Step: 13
Training loss: 2.453932319509923
Validation loss: 2.726885990456125

Epoch: 16| Step: 0
Training loss: 3.094608996810364
Validation loss: 2.703325988118282

Epoch: 6| Step: 1
Training loss: 3.255954862314539
Validation loss: 2.6625278560990067

Epoch: 6| Step: 2
Training loss: 2.646042993203456
Validation loss: 2.6820467840215803

Epoch: 6| Step: 3
Training loss: 2.2912682851674653
Validation loss: 2.7402969610598973

Epoch: 6| Step: 4
Training loss: 2.666706283592946
Validation loss: 2.7071309330482687

Epoch: 6| Step: 5
Training loss: 3.1071169527975315
Validation loss: 2.7039795776053057

Epoch: 6| Step: 6
Training loss: 2.837687979365826
Validation loss: 2.654307803519092

Epoch: 6| Step: 7
Training loss: 1.423682436926641
Validation loss: 2.6959436092393716

Epoch: 6| Step: 8
Training loss: 2.439363305398332
Validation loss: 2.669570568592635

Epoch: 6| Step: 9
Training loss: 2.8770535639926846
Validation loss: 2.6864936925881584

Epoch: 6| Step: 10
Training loss: 2.55019111291131
Validation loss: 2.6934637538646724

Epoch: 6| Step: 11
Training loss: 2.393638357243239
Validation loss: 2.6923786800234275

Epoch: 6| Step: 12
Training loss: 2.684797303062694
Validation loss: 2.692740454319241

Epoch: 6| Step: 13
Training loss: 2.2547762297515117
Validation loss: 2.723138563069673

Epoch: 17| Step: 0
Training loss: 3.0353142931624673
Validation loss: 2.6990287923701084

Epoch: 6| Step: 1
Training loss: 3.217029593225173
Validation loss: 2.6884353547703115

Epoch: 6| Step: 2
Training loss: 1.8151696374397368
Validation loss: 2.706097888269004

Epoch: 6| Step: 3
Training loss: 3.0596800296518096
Validation loss: 2.6743382779273444

Epoch: 6| Step: 4
Training loss: 2.4981176919570167
Validation loss: 2.679039019386053

Epoch: 6| Step: 5
Training loss: 2.0749495488663277
Validation loss: 2.7179587517247703

Epoch: 6| Step: 6
Training loss: 2.66413812166429
Validation loss: 2.679419219560726

Epoch: 6| Step: 7
Training loss: 2.1589877674344615
Validation loss: 2.71902043543183

Epoch: 6| Step: 8
Training loss: 2.6707433791542274
Validation loss: 2.6874357555901875

Epoch: 6| Step: 9
Training loss: 2.8720156895626023
Validation loss: 2.696249344775115

Epoch: 6| Step: 10
Training loss: 2.757152445964954
Validation loss: 2.681397836636156

Epoch: 6| Step: 11
Training loss: 2.9653516090685224
Validation loss: 2.681156730659845

Epoch: 6| Step: 12
Training loss: 2.6016184941128304
Validation loss: 2.7092440810026694

Epoch: 6| Step: 13
Training loss: 1.969385982907734
Validation loss: 2.6722068803584307

Epoch: 18| Step: 0
Training loss: 2.290691121852718
Validation loss: 2.6703275545818257

Epoch: 6| Step: 1
Training loss: 2.2705937063726185
Validation loss: 2.70623343318012

Epoch: 6| Step: 2
Training loss: 2.3419292243928784
Validation loss: 2.7032920624075185

Epoch: 6| Step: 3
Training loss: 2.383340645714415
Validation loss: 2.639242446091722

Epoch: 6| Step: 4
Training loss: 3.2006495889331115
Validation loss: 2.7085078525557313

Epoch: 6| Step: 5
Training loss: 2.8317731226652874
Validation loss: 2.665687020978947

Epoch: 6| Step: 6
Training loss: 2.7400105847899097
Validation loss: 2.6951528971866443

Epoch: 6| Step: 7
Training loss: 3.1527415500824376
Validation loss: 2.6751587526505665

Epoch: 6| Step: 8
Training loss: 2.1669382756503506
Validation loss: 2.6599523734128905

Epoch: 6| Step: 9
Training loss: 2.8548715282602637
Validation loss: 2.6850335905672136

Epoch: 6| Step: 10
Training loss: 3.0705600473719126
Validation loss: 2.683682465694844

Epoch: 6| Step: 11
Training loss: 2.346798757642954
Validation loss: 2.716419785247981

Epoch: 6| Step: 12
Training loss: 2.0854978633879733
Validation loss: 2.6930173823214347

Epoch: 6| Step: 13
Training loss: 2.914955145620008
Validation loss: 2.678529761762338

Epoch: 19| Step: 0
Training loss: 3.080469158655343
Validation loss: 2.666679446865292

Epoch: 6| Step: 1
Training loss: 3.240196701483822
Validation loss: 2.6704249992802085

Epoch: 6| Step: 2
Training loss: 2.4223629367661266
Validation loss: 2.659824599001944

Epoch: 6| Step: 3
Training loss: 2.3521812866826233
Validation loss: 2.6704095015179456

Epoch: 6| Step: 4
Training loss: 2.422226123583079
Validation loss: 2.682875165464807

Epoch: 6| Step: 5
Training loss: 1.7786256296584464
Validation loss: 2.677776919712582

Epoch: 6| Step: 6
Training loss: 2.2605211318761635
Validation loss: 2.6720552885565727

Epoch: 6| Step: 7
Training loss: 2.7802441095990043
Validation loss: 2.689257616274928

Epoch: 6| Step: 8
Training loss: 2.802107110093975
Validation loss: 2.6954363955710723

Epoch: 6| Step: 9
Training loss: 2.474407040243311
Validation loss: 2.6742394824965183

Epoch: 6| Step: 10
Training loss: 3.3704260455490824
Validation loss: 2.683512827593861

Epoch: 6| Step: 11
Training loss: 2.4562728026595915
Validation loss: 2.651307672871217

Epoch: 6| Step: 12
Training loss: 2.4105754469193714
Validation loss: 2.7143578110467645

Epoch: 6| Step: 13
Training loss: 2.398646640667839
Validation loss: 2.690943441476355

Epoch: 20| Step: 0
Training loss: 2.5207826803703792
Validation loss: 2.6417932879148935

Epoch: 6| Step: 1
Training loss: 2.455869852016084
Validation loss: 2.6828139429342173

Epoch: 6| Step: 2
Training loss: 2.584503975063521
Validation loss: 2.6553983033500654

Epoch: 6| Step: 3
Training loss: 3.0519145272261707
Validation loss: 2.66014973718534

Epoch: 6| Step: 4
Training loss: 3.0287246409577464
Validation loss: 2.647680003597219

Epoch: 6| Step: 5
Training loss: 2.909125925254322
Validation loss: 2.6573944468692305

Epoch: 6| Step: 6
Training loss: 2.2769823261927056
Validation loss: 2.62702117793958

Epoch: 6| Step: 7
Training loss: 2.5710240454600934
Validation loss: 2.7185071347089043

Epoch: 6| Step: 8
Training loss: 2.2098849861285776
Validation loss: 2.681730879644493

Epoch: 6| Step: 9
Training loss: 2.7784764894592913
Validation loss: 2.690184767710537

Epoch: 6| Step: 10
Training loss: 3.2024471403073
Validation loss: 2.6823905531546712

Epoch: 6| Step: 11
Training loss: 1.8180541736055813
Validation loss: 2.627428415026848

Epoch: 6| Step: 12
Training loss: 2.250363532474208
Validation loss: 2.712737219848846

Epoch: 6| Step: 13
Training loss: 2.468347927138798
Validation loss: 2.673272761834349

Epoch: 21| Step: 0
Training loss: 2.329294614968298
Validation loss: 2.6807532901887803

Epoch: 6| Step: 1
Training loss: 2.7804026652385225
Validation loss: 2.662063922899881

Epoch: 6| Step: 2
Training loss: 1.9486545518326048
Validation loss: 2.6963948900638863

Epoch: 6| Step: 3
Training loss: 2.4284719879564314
Validation loss: 2.716254086164411

Epoch: 6| Step: 4
Training loss: 2.129114095358604
Validation loss: 2.6567875037797957

Epoch: 6| Step: 5
Training loss: 2.48376361353637
Validation loss: 2.6676316502125665

Epoch: 6| Step: 6
Training loss: 2.500020408547069
Validation loss: 2.7216366756614336

Epoch: 6| Step: 7
Training loss: 2.870434328503777
Validation loss: 2.7421335140757526

Epoch: 6| Step: 8
Training loss: 3.014135912153935
Validation loss: 2.7156965421172137

Epoch: 6| Step: 9
Training loss: 2.8517347309930754
Validation loss: 2.709549254343358

Epoch: 6| Step: 10
Training loss: 3.485163167584482
Validation loss: 2.7376017541423447

Epoch: 6| Step: 11
Training loss: 3.0095694822728265
Validation loss: 2.722086937671959

Epoch: 6| Step: 12
Training loss: 2.287421774438642
Validation loss: 2.6859857152103106

Epoch: 6| Step: 13
Training loss: 1.7532774343874882
Validation loss: 2.6836544883254914

Epoch: 22| Step: 0
Training loss: 2.1834691648478923
Validation loss: 2.694417021525554

Epoch: 6| Step: 1
Training loss: 3.495917664254492
Validation loss: 2.7152188780614073

Epoch: 6| Step: 2
Training loss: 1.6613277116887566
Validation loss: 2.647304986694221

Epoch: 6| Step: 3
Training loss: 2.6825355986751003
Validation loss: 2.6737365409746547

Epoch: 6| Step: 4
Training loss: 2.189060853226428
Validation loss: 2.698124046652464

Epoch: 6| Step: 5
Training loss: 1.5864919811278155
Validation loss: 2.6501784852337753

Epoch: 6| Step: 6
Training loss: 3.237865978160507
Validation loss: 2.6904058936532924

Epoch: 6| Step: 7
Training loss: 3.0908621208171585
Validation loss: 2.6850584309599803

Epoch: 6| Step: 8
Training loss: 2.2154133382182373
Validation loss: 2.6826254232710918

Epoch: 6| Step: 9
Training loss: 2.7152012431834787
Validation loss: 2.6848080038263964

Epoch: 6| Step: 10
Training loss: 2.5178457373889285
Validation loss: 2.7033878411780474

Epoch: 6| Step: 11
Training loss: 2.5294769105206187
Validation loss: 2.6624578526344314

Epoch: 6| Step: 12
Training loss: 3.0700292092589487
Validation loss: 2.6791920106518674

Epoch: 6| Step: 13
Training loss: 2.4651725054070344
Validation loss: 2.6426681048366563

Epoch: 23| Step: 0
Training loss: 2.3943235422378804
Validation loss: 2.658026695702957

Epoch: 6| Step: 1
Training loss: 2.7333383393435655
Validation loss: 2.6996511875705322

Epoch: 6| Step: 2
Training loss: 2.860603777236008
Validation loss: 2.6686568482912683

Epoch: 6| Step: 3
Training loss: 1.8526968398646164
Validation loss: 2.65656718435975

Epoch: 6| Step: 4
Training loss: 2.4110465855126497
Validation loss: 2.627369643685048

Epoch: 6| Step: 5
Training loss: 3.113908233113643
Validation loss: 2.6530351519488766

Epoch: 6| Step: 6
Training loss: 3.0122589141488385
Validation loss: 2.683775960852645

Epoch: 6| Step: 7
Training loss: 1.9838027729786136
Validation loss: 2.6510852342983946

Epoch: 6| Step: 8
Training loss: 2.8097401959740105
Validation loss: 2.6598227614437224

Epoch: 6| Step: 9
Training loss: 2.0623871743524766
Validation loss: 2.6691508543761158

Epoch: 6| Step: 10
Training loss: 2.9133003608647607
Validation loss: 2.653615699923915

Epoch: 6| Step: 11
Training loss: 2.7281611873852816
Validation loss: 2.6240282682150284

Epoch: 6| Step: 12
Training loss: 2.2428959913421123
Validation loss: 2.6639305223754652

Epoch: 6| Step: 13
Training loss: 2.6785715520949562
Validation loss: 2.6928644977395417

Epoch: 24| Step: 0
Training loss: 2.129720157812298
Validation loss: 2.6550037826539876

Epoch: 6| Step: 1
Training loss: 2.9149626704290945
Validation loss: 2.662857454330314

Epoch: 6| Step: 2
Training loss: 2.948942583303232
Validation loss: 2.6196530244113427

Epoch: 6| Step: 3
Training loss: 2.949696159879507
Validation loss: 2.6726430343067764

Epoch: 6| Step: 4
Training loss: 2.278514842310051
Validation loss: 2.6913452584452333

Epoch: 6| Step: 5
Training loss: 2.752775958621231
Validation loss: 2.6844758310502406

Epoch: 6| Step: 6
Training loss: 3.037139205540801
Validation loss: 2.645679053867264

Epoch: 6| Step: 7
Training loss: 2.51783390092413
Validation loss: 2.6281798116235207

Epoch: 6| Step: 8
Training loss: 2.428143271201969
Validation loss: 2.662406996175701

Epoch: 6| Step: 9
Training loss: 1.8804135690476629
Validation loss: 2.6876992587955564

Epoch: 6| Step: 10
Training loss: 2.7736471607317155
Validation loss: 2.6786337245781455

Epoch: 6| Step: 11
Training loss: 2.4926712379825147
Validation loss: 2.6646211994772337

Epoch: 6| Step: 12
Training loss: 2.35701810828703
Validation loss: 2.711037361878178

Epoch: 6| Step: 13
Training loss: 2.640727565962971
Validation loss: 2.716280038114253

Epoch: 25| Step: 0
Training loss: 2.015167302647577
Validation loss: 2.645775641665921

Epoch: 6| Step: 1
Training loss: 3.1714883202186326
Validation loss: 2.68344480053966

Epoch: 6| Step: 2
Training loss: 2.4499699415581766
Validation loss: 2.654366217936195

Epoch: 6| Step: 3
Training loss: 2.8339675492694867
Validation loss: 2.705270448680792

Epoch: 6| Step: 4
Training loss: 2.182790427618584
Validation loss: 2.699693813741232

Epoch: 6| Step: 5
Training loss: 2.518534807804927
Validation loss: 2.664683369380982

Epoch: 6| Step: 6
Training loss: 2.995813627713211
Validation loss: 2.696564461932852

Epoch: 6| Step: 7
Training loss: 2.653895512677904
Validation loss: 2.6482599099481976

Epoch: 6| Step: 8
Training loss: 2.290108295362052
Validation loss: 2.703489422350806

Epoch: 6| Step: 9
Training loss: 2.794753735361078
Validation loss: 2.6862128672304704

Epoch: 6| Step: 10
Training loss: 2.485947980684813
Validation loss: 2.6623817131021963

Epoch: 6| Step: 11
Training loss: 2.1596723293852937
Validation loss: 2.6368981721843485

Epoch: 6| Step: 12
Training loss: 2.787143763201046
Validation loss: 2.693773244770773

Epoch: 6| Step: 13
Training loss: 2.4543657991699717
Validation loss: 2.650565358799458

Epoch: 26| Step: 0
Training loss: 2.8369611253626386
Validation loss: 2.654329840067324

Epoch: 6| Step: 1
Training loss: 2.583970996132929
Validation loss: 2.6874654161460683

Epoch: 6| Step: 2
Training loss: 2.7910991680223156
Validation loss: 2.660176475474155

Epoch: 6| Step: 3
Training loss: 3.0031759617001454
Validation loss: 2.698445424191772

Epoch: 6| Step: 4
Training loss: 2.8419160064161666
Validation loss: 2.6899194103114192

Epoch: 6| Step: 5
Training loss: 2.345047655089054
Validation loss: 2.6741264331042096

Epoch: 6| Step: 6
Training loss: 2.9340579380589467
Validation loss: 2.6527003487232355

Epoch: 6| Step: 7
Training loss: 2.917462612719939
Validation loss: 2.64016573672289

Epoch: 6| Step: 8
Training loss: 2.320606765326117
Validation loss: 2.636381889771358

Epoch: 6| Step: 9
Training loss: 2.621499133988637
Validation loss: 2.61406812619738

Epoch: 6| Step: 10
Training loss: 1.9225399448724405
Validation loss: 2.6405303908033444

Epoch: 6| Step: 11
Training loss: 2.179217763074385
Validation loss: 2.686500274658189

Epoch: 6| Step: 12
Training loss: 1.9442137407255033
Validation loss: 2.6503139963600466

Epoch: 6| Step: 13
Training loss: 2.181170434238416
Validation loss: 2.6927663967776234

Epoch: 27| Step: 0
Training loss: 2.3291527444586033
Validation loss: 2.6610914351953276

Epoch: 6| Step: 1
Training loss: 3.0051674842812908
Validation loss: 2.6608472347722723

Epoch: 6| Step: 2
Training loss: 3.0477647313708593
Validation loss: 2.648350672015918

Epoch: 6| Step: 3
Training loss: 2.3464966002886123
Validation loss: 2.6217908467612303

Epoch: 6| Step: 4
Training loss: 2.4562415474704973
Validation loss: 2.682036383372342

Epoch: 6| Step: 5
Training loss: 2.887842437123326
Validation loss: 2.653497219447712

Epoch: 6| Step: 6
Training loss: 2.668059094799721
Validation loss: 2.676306538870295

Epoch: 6| Step: 7
Training loss: 2.003403866499995
Validation loss: 2.6252957434797377

Epoch: 6| Step: 8
Training loss: 2.544496888680335
Validation loss: 2.644507403808546

Epoch: 6| Step: 9
Training loss: 2.7674252959853973
Validation loss: 2.6693580179009975

Epoch: 6| Step: 10
Training loss: 2.908081134110319
Validation loss: 2.6575772802767963

Epoch: 6| Step: 11
Training loss: 2.2446825984883794
Validation loss: 2.685408761836794

Epoch: 6| Step: 12
Training loss: 2.462825184375445
Validation loss: 2.6439097513281213

Epoch: 6| Step: 13
Training loss: 2.4294922189032477
Validation loss: 2.640711149055645

Epoch: 28| Step: 0
Training loss: 2.1917572012454816
Validation loss: 2.659574096733771

Epoch: 6| Step: 1
Training loss: 2.71905077443446
Validation loss: 2.6244161955726892

Epoch: 6| Step: 2
Training loss: 2.646179677166707
Validation loss: 2.6798212223775355

Epoch: 6| Step: 3
Training loss: 2.6227368180777564
Validation loss: 2.6319655840004352

Epoch: 6| Step: 4
Training loss: 2.311819646605283
Validation loss: 2.658185889201982

Epoch: 6| Step: 5
Training loss: 2.411347575490057
Validation loss: 2.632685793158588

Epoch: 6| Step: 6
Training loss: 2.3069739427951057
Validation loss: 2.6663771611260767

Epoch: 6| Step: 7
Training loss: 2.8569625933865086
Validation loss: 2.7079766160846575

Epoch: 6| Step: 8
Training loss: 2.3112476153694095
Validation loss: 2.628768562085687

Epoch: 6| Step: 9
Training loss: 2.7321347023693523
Validation loss: 2.64899839990226

Epoch: 6| Step: 10
Training loss: 2.4402659446368133
Validation loss: 2.6944088217968414

Epoch: 6| Step: 11
Training loss: 2.911462518806156
Validation loss: 2.62162215264376

Epoch: 6| Step: 12
Training loss: 2.832995693808103
Validation loss: 2.6614013685685842

Epoch: 6| Step: 13
Training loss: 2.4135343597349794
Validation loss: 2.6622455549964523

Epoch: 29| Step: 0
Training loss: 2.514148349849075
Validation loss: 2.6469094548540646

Epoch: 6| Step: 1
Training loss: 2.2291597978242477
Validation loss: 2.6342106247101995

Epoch: 6| Step: 2
Training loss: 2.2967948640091627
Validation loss: 2.6530921865110795

Epoch: 6| Step: 3
Training loss: 2.3639219818408703
Validation loss: 2.6730311608316004

Epoch: 6| Step: 4
Training loss: 3.082113247978448
Validation loss: 2.659617783565717

Epoch: 6| Step: 5
Training loss: 2.7866511673321357
Validation loss: 2.673374209016183

Epoch: 6| Step: 6
Training loss: 2.2266748232701614
Validation loss: 2.6572947971789618

Epoch: 6| Step: 7
Training loss: 2.584040657751082
Validation loss: 2.6628877766314956

Epoch: 6| Step: 8
Training loss: 3.2120843403195645
Validation loss: 2.6720250851601484

Epoch: 6| Step: 9
Training loss: 3.246392228305138
Validation loss: 2.688622654184392

Epoch: 6| Step: 10
Training loss: 2.2208654500369827
Validation loss: 2.6323251471272826

Epoch: 6| Step: 11
Training loss: 2.718184927610647
Validation loss: 2.683042511275133

Epoch: 6| Step: 12
Training loss: 1.728262914083188
Validation loss: 2.6512832431606546

Epoch: 6| Step: 13
Training loss: 2.2315141195627928
Validation loss: 2.6484365997763035

Epoch: 30| Step: 0
Training loss: 1.8604802925646933
Validation loss: 2.6350531999645224

Epoch: 6| Step: 1
Training loss: 2.5870766334817614
Validation loss: 2.644711479382708

Epoch: 6| Step: 2
Training loss: 1.9045292326190193
Validation loss: 2.625510370503193

Epoch: 6| Step: 3
Training loss: 2.765290148447815
Validation loss: 2.617139111731049

Epoch: 6| Step: 4
Training loss: 2.335198429016442
Validation loss: 2.6619286218087774

Epoch: 6| Step: 5
Training loss: 3.0515598373284276
Validation loss: 2.6933424527026477

Epoch: 6| Step: 6
Training loss: 2.8706941287576755
Validation loss: 2.675893464717138

Epoch: 6| Step: 7
Training loss: 2.054349225993499
Validation loss: 2.6606537161906747

Epoch: 6| Step: 8
Training loss: 1.9987706936354865
Validation loss: 2.632393853685196

Epoch: 6| Step: 9
Training loss: 2.9634332530880148
Validation loss: 2.6797890602195427

Epoch: 6| Step: 10
Training loss: 2.5584154838601605
Validation loss: 2.6434995816719096

Epoch: 6| Step: 11
Training loss: 2.644829467006502
Validation loss: 2.6644780644989527

Epoch: 6| Step: 12
Training loss: 2.915063762719892
Validation loss: 2.6699058162017435

Epoch: 6| Step: 13
Training loss: 2.9358939792397862
Validation loss: 2.6903581428592287

Epoch: 31| Step: 0
Training loss: 2.30513146213817
Validation loss: 2.651506062260857

Epoch: 6| Step: 1
Training loss: 2.6309195485416192
Validation loss: 2.6945559264472796

Epoch: 6| Step: 2
Training loss: 2.529034999413665
Validation loss: 2.6665084662797485

Epoch: 6| Step: 3
Training loss: 2.4536287798795327
Validation loss: 2.634994885212267

Epoch: 6| Step: 4
Training loss: 2.0779857158592168
Validation loss: 2.6275460747509194

Epoch: 6| Step: 5
Training loss: 2.5000589363780548
Validation loss: 2.6639484668239812

Epoch: 6| Step: 6
Training loss: 2.610648021710648
Validation loss: 2.6415358106852707

Epoch: 6| Step: 7
Training loss: 2.720736074145423
Validation loss: 2.704449852651815

Epoch: 6| Step: 8
Training loss: 2.482615201491761
Validation loss: 2.6297896149472257

Epoch: 6| Step: 9
Training loss: 2.315733942308321
Validation loss: 2.593675926407027

Epoch: 6| Step: 10
Training loss: 2.9590196664046413
Validation loss: 2.6597992017433123

Epoch: 6| Step: 11
Training loss: 2.8334452289102705
Validation loss: 2.641460956020895

Epoch: 6| Step: 12
Training loss: 2.6379194676367237
Validation loss: 2.6481973094669824

Epoch: 6| Step: 13
Training loss: 2.527626552413223
Validation loss: 2.647698313316191

Epoch: 32| Step: 0
Training loss: 2.008265581478693
Validation loss: 2.6288621434918293

Epoch: 6| Step: 1
Training loss: 2.1335938528054603
Validation loss: 2.665296088107146

Epoch: 6| Step: 2
Training loss: 1.8576421276155406
Validation loss: 2.6171892004814126

Epoch: 6| Step: 3
Training loss: 2.5263705848933475
Validation loss: 2.6249221003039276

Epoch: 6| Step: 4
Training loss: 2.8134809690611102
Validation loss: 2.662723551575046

Epoch: 6| Step: 5
Training loss: 1.908894315109169
Validation loss: 2.6415062812549013

Epoch: 6| Step: 6
Training loss: 2.525091332020762
Validation loss: 2.651732623896206

Epoch: 6| Step: 7
Training loss: 2.794999671349139
Validation loss: 2.669876496367255

Epoch: 6| Step: 8
Training loss: 2.6686848116558095
Validation loss: 2.655473139236353

Epoch: 6| Step: 9
Training loss: 2.8040238554262187
Validation loss: 2.627276039366441

Epoch: 6| Step: 10
Training loss: 3.7483430380644003
Validation loss: 2.6431099299454277

Epoch: 6| Step: 11
Training loss: 2.3018531051286337
Validation loss: 2.596646051761671

Epoch: 6| Step: 12
Training loss: 2.175960841548822
Validation loss: 2.648244770130472

Epoch: 6| Step: 13
Training loss: 2.959800481773516
Validation loss: 2.6041630757624983

Epoch: 33| Step: 0
Training loss: 2.6004788544654565
Validation loss: 2.639810620894348

Epoch: 6| Step: 1
Training loss: 2.055307853082151
Validation loss: 2.625929804024251

Epoch: 6| Step: 2
Training loss: 2.2872195587851007
Validation loss: 2.6309396967040652

Epoch: 6| Step: 3
Training loss: 2.554664728372326
Validation loss: 2.6649677159427676

Epoch: 6| Step: 4
Training loss: 2.8403749664350957
Validation loss: 2.61255427704178

Epoch: 6| Step: 5
Training loss: 2.4722011924830274
Validation loss: 2.6234247537151423

Epoch: 6| Step: 6
Training loss: 2.6999567240319813
Validation loss: 2.6598594974276577

Epoch: 6| Step: 7
Training loss: 2.0532112184766143
Validation loss: 2.6356585747185437

Epoch: 6| Step: 8
Training loss: 3.3421504392704735
Validation loss: 2.6204472600609083

Epoch: 6| Step: 9
Training loss: 2.122560222476802
Validation loss: 2.665989511662404

Epoch: 6| Step: 10
Training loss: 2.611567506966807
Validation loss: 2.6860337360532966

Epoch: 6| Step: 11
Training loss: 2.6059188339638983
Validation loss: 2.6377506902314956

Epoch: 6| Step: 12
Training loss: 1.8521584626083083
Validation loss: 2.6423880505674977

Epoch: 6| Step: 13
Training loss: 2.8519101283718706
Validation loss: 2.6749754051907937

Epoch: 34| Step: 0
Training loss: 2.3176414451519745
Validation loss: 2.651625253612528

Epoch: 6| Step: 1
Training loss: 2.8015522128510413
Validation loss: 2.7083480296592075

Epoch: 6| Step: 2
Training loss: 2.739906079290628
Validation loss: 2.621706122141695

Epoch: 6| Step: 3
Training loss: 2.0863941849972716
Validation loss: 2.6824999287069926

Epoch: 6| Step: 4
Training loss: 2.331843025113035
Validation loss: 2.6352755140618287

Epoch: 6| Step: 5
Training loss: 2.2056202927298942
Validation loss: 2.6612696770519473

Epoch: 6| Step: 6
Training loss: 2.489261260540962
Validation loss: 2.647869878235994

Epoch: 6| Step: 7
Training loss: 2.644335425379871
Validation loss: 2.691371627754715

Epoch: 6| Step: 8
Training loss: 2.539194332515014
Validation loss: 2.62931549227383

Epoch: 6| Step: 9
Training loss: 2.8690345905568173
Validation loss: 2.643269435531979

Epoch: 6| Step: 10
Training loss: 2.5105525464103224
Validation loss: 2.61559446826709

Epoch: 6| Step: 11
Training loss: 2.9380557569350816
Validation loss: 2.6451123874874916

Epoch: 6| Step: 12
Training loss: 2.583236989921725
Validation loss: 2.656202622533403

Epoch: 6| Step: 13
Training loss: 2.4248846242927913
Validation loss: 2.5981123368504706

Epoch: 35| Step: 0
Training loss: 2.9281835332371653
Validation loss: 2.6433971683624127

Epoch: 6| Step: 1
Training loss: 2.7289439297315456
Validation loss: 2.645922799487636

Epoch: 6| Step: 2
Training loss: 2.50457278707041
Validation loss: 2.644743542247768

Epoch: 6| Step: 3
Training loss: 2.639810109100534
Validation loss: 2.64790644990124

Epoch: 6| Step: 4
Training loss: 2.2565037719370453
Validation loss: 2.632999960605125

Epoch: 6| Step: 5
Training loss: 2.2715792582826944
Validation loss: 2.655894685804035

Epoch: 6| Step: 6
Training loss: 2.8508503900006734
Validation loss: 2.6195998731499253

Epoch: 6| Step: 7
Training loss: 2.2791790903184044
Validation loss: 2.6185243295380958

Epoch: 6| Step: 8
Training loss: 2.337290598419713
Validation loss: 2.714781587104

Epoch: 6| Step: 9
Training loss: 2.5752984475816025
Validation loss: 2.6276249098675755

Epoch: 6| Step: 10
Training loss: 2.3851739907128158
Validation loss: 2.6557056991299386

Epoch: 6| Step: 11
Training loss: 3.0412674384944
Validation loss: 2.669485261569552

Epoch: 6| Step: 12
Training loss: 1.8840004113717248
Validation loss: 2.6286120011523444

Epoch: 6| Step: 13
Training loss: 2.542665900085099
Validation loss: 2.673542075208535

Epoch: 36| Step: 0
Training loss: 2.6924424965614473
Validation loss: 2.6324380217788756

Epoch: 6| Step: 1
Training loss: 2.621079105160047
Validation loss: 2.6737780867009895

Epoch: 6| Step: 2
Training loss: 2.8519191571156335
Validation loss: 2.6581987301063505

Epoch: 6| Step: 3
Training loss: 2.189551889742455
Validation loss: 2.65628119057687

Epoch: 6| Step: 4
Training loss: 2.5137604621506355
Validation loss: 2.6442143350370593

Epoch: 6| Step: 5
Training loss: 2.5458649112555647
Validation loss: 2.627618210562512

Epoch: 6| Step: 6
Training loss: 2.4400481574199646
Validation loss: 2.6424432998776797

Epoch: 6| Step: 7
Training loss: 2.045932348876174
Validation loss: 2.6433449304846617

Epoch: 6| Step: 8
Training loss: 3.2073125495160593
Validation loss: 2.6798126814271632

Epoch: 6| Step: 9
Training loss: 2.6933557456409103
Validation loss: 2.625133162859893

Epoch: 6| Step: 10
Training loss: 2.1735242989469414
Validation loss: 2.6604209316361866

Epoch: 6| Step: 11
Training loss: 3.4443537963369586
Validation loss: 2.5965860480728518

Epoch: 6| Step: 12
Training loss: 2.4207223425769167
Validation loss: 2.647119770044462

Epoch: 6| Step: 13
Training loss: 1.9728936080901
Validation loss: 2.6346992425872195

Epoch: 37| Step: 0
Training loss: 2.836093866750624
Validation loss: 2.6502877133207456

Epoch: 6| Step: 1
Training loss: 2.7125339699301283
Validation loss: 2.578105641302004

Epoch: 6| Step: 2
Training loss: 2.960884838592137
Validation loss: 2.667865026942257

Epoch: 6| Step: 3
Training loss: 2.1067960444491285
Validation loss: 2.6352574045260426

Epoch: 6| Step: 4
Training loss: 2.6963491022097914
Validation loss: 2.680834873967019

Epoch: 6| Step: 5
Training loss: 2.2155148197643495
Validation loss: 2.6541634386443227

Epoch: 6| Step: 6
Training loss: 2.120613170155685
Validation loss: 2.6463285468326054

Epoch: 6| Step: 7
Training loss: 2.7614339333608275
Validation loss: 2.638525886553717

Epoch: 6| Step: 8
Training loss: 2.014820618513315
Validation loss: 2.6863451110086856

Epoch: 6| Step: 9
Training loss: 2.7032472439505546
Validation loss: 2.5720049417763673

Epoch: 6| Step: 10
Training loss: 1.8785162062871124
Validation loss: 2.6261261991589238

Epoch: 6| Step: 11
Training loss: 3.180310687356698
Validation loss: 2.6745416224738876

Epoch: 6| Step: 12
Training loss: 2.8825863798619675
Validation loss: 2.650394073311669

Epoch: 6| Step: 13
Training loss: 1.5623773145193849
Validation loss: 2.700410865793549

Epoch: 38| Step: 0
Training loss: 2.449992323882865
Validation loss: 2.640578741687943

Epoch: 6| Step: 1
Training loss: 1.6885890978349067
Validation loss: 2.5906369474754425

Epoch: 6| Step: 2
Training loss: 2.4956200378506206
Validation loss: 2.6351454423097898

Epoch: 6| Step: 3
Training loss: 2.867314889349026
Validation loss: 2.661057374217428

Epoch: 6| Step: 4
Training loss: 2.852914985874268
Validation loss: 2.6493777516200705

Epoch: 6| Step: 5
Training loss: 2.40413443964135
Validation loss: 2.630851324569895

Epoch: 6| Step: 6
Training loss: 3.1808054315470753
Validation loss: 2.629824216888458

Epoch: 6| Step: 7
Training loss: 2.6534057648355533
Validation loss: 2.6192899239942307

Epoch: 6| Step: 8
Training loss: 2.381811112903639
Validation loss: 2.6234278285090813

Epoch: 6| Step: 9
Training loss: 2.1187668431155515
Validation loss: 2.60046659189309

Epoch: 6| Step: 10
Training loss: 1.8170046241168154
Validation loss: 2.6126485380810966

Epoch: 6| Step: 11
Training loss: 1.9634211644062771
Validation loss: 2.6551247700446776

Epoch: 6| Step: 12
Training loss: 2.4417099420490294
Validation loss: 2.618496847245384

Epoch: 6| Step: 13
Training loss: 3.5483712556770657
Validation loss: 2.5980411406928696

Epoch: 39| Step: 0
Training loss: 2.4702418202007177
Validation loss: 2.6359830757788334

Epoch: 6| Step: 1
Training loss: 3.395697811363466
Validation loss: 2.652582673747794

Epoch: 6| Step: 2
Training loss: 2.3631021731287354
Validation loss: 2.6377177514679233

Epoch: 6| Step: 3
Training loss: 2.6729823266218236
Validation loss: 2.6049530952633746

Epoch: 6| Step: 4
Training loss: 2.716799332201441
Validation loss: 2.6020122517349358

Epoch: 6| Step: 5
Training loss: 1.302879862975636
Validation loss: 2.6182322680003005

Epoch: 6| Step: 6
Training loss: 2.813523085268125
Validation loss: 2.591680628093963

Epoch: 6| Step: 7
Training loss: 2.2884320637556197
Validation loss: 2.623861732133276

Epoch: 6| Step: 8
Training loss: 2.1890018212392315
Validation loss: 2.6329016212902414

Epoch: 6| Step: 9
Training loss: 3.044846705694991
Validation loss: 2.6490890916680176

Epoch: 6| Step: 10
Training loss: 2.4991020497356
Validation loss: 2.6206666358692856

Epoch: 6| Step: 11
Training loss: 2.152072674803976
Validation loss: 2.5972567984942154

Epoch: 6| Step: 12
Training loss: 2.5488183032317946
Validation loss: 2.5790051894000747

Epoch: 6| Step: 13
Training loss: 2.3297842372814603
Validation loss: 2.5826696548300205

Epoch: 40| Step: 0
Training loss: 1.5769383718704317
Validation loss: 2.6122800147296688

Epoch: 6| Step: 1
Training loss: 2.2379509114531477
Validation loss: 2.6243029986046023

Epoch: 6| Step: 2
Training loss: 2.2841496263787175
Validation loss: 2.582862262434915

Epoch: 6| Step: 3
Training loss: 2.4257903905134253
Validation loss: 2.6449134208676672

Epoch: 6| Step: 4
Training loss: 3.55805772582085
Validation loss: 2.580429118729166

Epoch: 6| Step: 5
Training loss: 2.777300999308371
Validation loss: 2.6465480369802985

Epoch: 6| Step: 6
Training loss: 3.0804462491054654
Validation loss: 2.677052647356633

Epoch: 6| Step: 7
Training loss: 2.6259956288239588
Validation loss: 2.6175972840727977

Epoch: 6| Step: 8
Training loss: 2.8146733681607876
Validation loss: 2.638654361029535

Epoch: 6| Step: 9
Training loss: 1.809128750134774
Validation loss: 2.613565920771333

Epoch: 6| Step: 10
Training loss: 2.4892200752950617
Validation loss: 2.6075441100844627

Epoch: 6| Step: 11
Training loss: 2.462881138153319
Validation loss: 2.6095843811698987

Epoch: 6| Step: 12
Training loss: 1.8793268506219203
Validation loss: 2.634103641433857

Epoch: 6| Step: 13
Training loss: 2.3735865352165133
Validation loss: 2.6048826123597184

Epoch: 41| Step: 0
Training loss: 2.002244405257817
Validation loss: 2.602038839146612

Epoch: 6| Step: 1
Training loss: 3.01118513988351
Validation loss: 2.5926165881131347

Epoch: 6| Step: 2
Training loss: 2.612643633092741
Validation loss: 2.573055137480863

Epoch: 6| Step: 3
Training loss: 3.1909815903780823
Validation loss: 2.575413474431878

Epoch: 6| Step: 4
Training loss: 2.460930137017755
Validation loss: 2.6591486952973464

Epoch: 6| Step: 5
Training loss: 2.2367140257929066
Validation loss: 2.5976299389723274

Epoch: 6| Step: 6
Training loss: 2.080280190266068
Validation loss: 2.620105547647478

Epoch: 6| Step: 7
Training loss: 2.554837563683187
Validation loss: 2.6704478328332706

Epoch: 6| Step: 8
Training loss: 2.5119078284683742
Validation loss: 2.596813950660715

Epoch: 6| Step: 9
Training loss: 2.4375150631170186
Validation loss: 2.6150828387169396

Epoch: 6| Step: 10
Training loss: 2.490763577347755
Validation loss: 2.5724380192088008

Epoch: 6| Step: 11
Training loss: 2.5343298365923266
Validation loss: 2.608007594315953

Epoch: 6| Step: 12
Training loss: 2.434055829457144
Validation loss: 2.643752193224563

Epoch: 6| Step: 13
Training loss: 2.1661717020666833
Validation loss: 2.681375281571864

Epoch: 42| Step: 0
Training loss: 2.575703448901552
Validation loss: 2.622636336378931

Epoch: 6| Step: 1
Training loss: 2.4890279323287228
Validation loss: 2.567847758151638

Epoch: 6| Step: 2
Training loss: 2.6071637315157075
Validation loss: 2.6322057762569755

Epoch: 6| Step: 3
Training loss: 2.302924875495884
Validation loss: 2.6099258724613703

Epoch: 6| Step: 4
Training loss: 2.508629401424979
Validation loss: 2.6406755461360136

Epoch: 6| Step: 5
Training loss: 2.7918348878498573
Validation loss: 2.643132375564201

Epoch: 6| Step: 6
Training loss: 2.587527060252051
Validation loss: 2.6627538679395264

Epoch: 6| Step: 7
Training loss: 1.9753041238460851
Validation loss: 2.5823389005681836

Epoch: 6| Step: 8
Training loss: 3.0991582896799876
Validation loss: 2.5929130521398975

Epoch: 6| Step: 9
Training loss: 1.9684606672547593
Validation loss: 2.640500105212252

Epoch: 6| Step: 10
Training loss: 2.6422701795061703
Validation loss: 2.5971692845417174

Epoch: 6| Step: 11
Training loss: 3.325456579310045
Validation loss: 2.606494173707005

Epoch: 6| Step: 12
Training loss: 2.0175435006936437
Validation loss: 2.577136565028466

Epoch: 6| Step: 13
Training loss: 2.1088711737351074
Validation loss: 2.602892530913669

Epoch: 43| Step: 0
Training loss: 2.3551946325520845
Validation loss: 2.6209642934500423

Epoch: 6| Step: 1
Training loss: 3.300295533327251
Validation loss: 2.595125882863002

Epoch: 6| Step: 2
Training loss: 2.8769880967303334
Validation loss: 2.583779301654852

Epoch: 6| Step: 3
Training loss: 2.174633771383663
Validation loss: 2.611478022797995

Epoch: 6| Step: 4
Training loss: 2.51518255098323
Validation loss: 2.6308476089784607

Epoch: 6| Step: 5
Training loss: 2.714618481408257
Validation loss: 2.606123369709843

Epoch: 6| Step: 6
Training loss: 2.6572294336855125
Validation loss: 2.6217925594131426

Epoch: 6| Step: 7
Training loss: 2.2608963652205682
Validation loss: 2.60296765508693

Epoch: 6| Step: 8
Training loss: 2.325047039253445
Validation loss: 2.636098183025267

Epoch: 6| Step: 9
Training loss: 1.7039126753303313
Validation loss: 2.6118608842857616

Epoch: 6| Step: 10
Training loss: 2.205488952263123
Validation loss: 2.6219474058038763

Epoch: 6| Step: 11
Training loss: 2.7933314374706355
Validation loss: 2.634502951100472

Epoch: 6| Step: 12
Training loss: 2.3824922940588915
Validation loss: 2.6060169868989065

Epoch: 6| Step: 13
Training loss: 2.46028327117307
Validation loss: 2.589852449566483

Epoch: 44| Step: 0
Training loss: 2.754510821271529
Validation loss: 2.631188288770674

Epoch: 6| Step: 1
Training loss: 2.7638851231773534
Validation loss: 2.6145014401765825

Epoch: 6| Step: 2
Training loss: 2.938207987425016
Validation loss: 2.6834753344459936

Epoch: 6| Step: 3
Training loss: 1.8110245585806468
Validation loss: 2.646232144393589

Epoch: 6| Step: 4
Training loss: 2.029987353581466
Validation loss: 2.6204569270851947

Epoch: 6| Step: 5
Training loss: 2.82112333947222
Validation loss: 2.594385567127954

Epoch: 6| Step: 6
Training loss: 2.402374713977281
Validation loss: 2.645371679645616

Epoch: 6| Step: 7
Training loss: 2.966998738195076
Validation loss: 2.671894348550382

Epoch: 6| Step: 8
Training loss: 2.649044451186883
Validation loss: 2.590594145096812

Epoch: 6| Step: 9
Training loss: 1.8490589454749522
Validation loss: 2.6019859236684173

Epoch: 6| Step: 10
Training loss: 2.6128947566634624
Validation loss: 2.665714411784449

Epoch: 6| Step: 11
Training loss: 2.1069733687765013
Validation loss: 2.619368461467835

Epoch: 6| Step: 12
Training loss: 2.328431589305698
Validation loss: 2.6408830174300197

Epoch: 6| Step: 13
Training loss: 2.5764951235611955
Validation loss: 2.597098858148017

Epoch: 45| Step: 0
Training loss: 1.9642821584396875
Validation loss: 2.648455414387928

Epoch: 6| Step: 1
Training loss: 1.9407127569385036
Validation loss: 2.603602834062728

Epoch: 6| Step: 2
Training loss: 2.3205934091190508
Validation loss: 2.587899530743324

Epoch: 6| Step: 3
Training loss: 2.8353829169991736
Validation loss: 2.6573290559198637

Epoch: 6| Step: 4
Training loss: 2.5312168448831707
Validation loss: 2.6316139066197777

Epoch: 6| Step: 5
Training loss: 3.3994271076218388
Validation loss: 2.6125269144670447

Epoch: 6| Step: 6
Training loss: 1.9197558372936383
Validation loss: 2.6270113459945796

Epoch: 6| Step: 7
Training loss: 2.470553741160849
Validation loss: 2.606724182585439

Epoch: 6| Step: 8
Training loss: 2.7738957416054104
Validation loss: 2.6187701132706778

Epoch: 6| Step: 9
Training loss: 2.7258201834690823
Validation loss: 2.624018152475566

Epoch: 6| Step: 10
Training loss: 2.924042249851814
Validation loss: 2.6676112280325204

Epoch: 6| Step: 11
Training loss: 2.613201693249032
Validation loss: 2.653744971183268

Epoch: 6| Step: 12
Training loss: 2.312629180599265
Validation loss: 2.6222337725105684

Epoch: 6| Step: 13
Training loss: 1.760041514795694
Validation loss: 2.5825177925533396

Epoch: 46| Step: 0
Training loss: 3.1609415368258484
Validation loss: 2.595023987511599

Epoch: 6| Step: 1
Training loss: 2.3426065325863226
Validation loss: 2.600517230977159

Epoch: 6| Step: 2
Training loss: 2.0241047705270376
Validation loss: 2.5867044362238896

Epoch: 6| Step: 3
Training loss: 3.0477758396352823
Validation loss: 2.5647941182517076

Epoch: 6| Step: 4
Training loss: 1.8438372833799048
Validation loss: 2.634183803873897

Epoch: 6| Step: 5
Training loss: 2.122662885906137
Validation loss: 2.5719590329006903

Epoch: 6| Step: 6
Training loss: 2.0609941476204825
Validation loss: 2.6416601375495135

Epoch: 6| Step: 7
Training loss: 1.8327291172114293
Validation loss: 2.617380770858577

Epoch: 6| Step: 8
Training loss: 2.602261194564748
Validation loss: 2.617168627618718

Epoch: 6| Step: 9
Training loss: 2.9542561943000236
Validation loss: 2.5749360987070578

Epoch: 6| Step: 10
Training loss: 2.516859237511656
Validation loss: 2.5763712148639963

Epoch: 6| Step: 11
Training loss: 3.045622582891622
Validation loss: 2.627478715959819

Epoch: 6| Step: 12
Training loss: 2.4684422941024904
Validation loss: 2.5962142421982484

Epoch: 6| Step: 13
Training loss: 2.957293117120183
Validation loss: 2.632207572709814

Epoch: 47| Step: 0
Training loss: 2.848448508404057
Validation loss: 2.6206784779254906

Epoch: 6| Step: 1
Training loss: 2.098998139590038
Validation loss: 2.612269260249454

Epoch: 6| Step: 2
Training loss: 3.2232092920346935
Validation loss: 2.6067440452050357

Epoch: 6| Step: 3
Training loss: 2.170322110049762
Validation loss: 2.608028163262483

Epoch: 6| Step: 4
Training loss: 2.4499855118926495
Validation loss: 2.6494270884006985

Epoch: 6| Step: 5
Training loss: 1.874777844301724
Validation loss: 2.6476949965650136

Epoch: 6| Step: 6
Training loss: 2.047338302245218
Validation loss: 2.6303158930071926

Epoch: 6| Step: 7
Training loss: 3.1364061857812726
Validation loss: 2.6459882545671842

Epoch: 6| Step: 8
Training loss: 2.450963519842379
Validation loss: 2.610312394365506

Epoch: 6| Step: 9
Training loss: 1.668621855541138
Validation loss: 2.5839026859410574

Epoch: 6| Step: 10
Training loss: 2.591940374936615
Validation loss: 2.6203207514403024

Epoch: 6| Step: 11
Training loss: 2.7640500514222928
Validation loss: 2.64007074231194

Epoch: 6| Step: 12
Training loss: 2.134959722491878
Validation loss: 2.5881258338227378

Epoch: 6| Step: 13
Training loss: 2.596754608852402
Validation loss: 2.5959071798418707

Epoch: 48| Step: 0
Training loss: 2.4524935741904224
Validation loss: 2.609931003321154

Epoch: 6| Step: 1
Training loss: 3.371244248161459
Validation loss: 2.585013817185171

Epoch: 6| Step: 2
Training loss: 2.495371061723538
Validation loss: 2.5818701466342606

Epoch: 6| Step: 3
Training loss: 2.250031576994675
Validation loss: 2.6387193714594797

Epoch: 6| Step: 4
Training loss: 3.1981272343368135
Validation loss: 2.5987291916697193

Epoch: 6| Step: 5
Training loss: 2.3005750269023477
Validation loss: 2.5943693164655053

Epoch: 6| Step: 6
Training loss: 2.3833303420397076
Validation loss: 2.5954553750442777

Epoch: 6| Step: 7
Training loss: 2.499469128510581
Validation loss: 2.6218099283684415

Epoch: 6| Step: 8
Training loss: 2.4696257764132814
Validation loss: 2.5965366484329615

Epoch: 6| Step: 9
Training loss: 1.9177952083848033
Validation loss: 2.6170339890433687

Epoch: 6| Step: 10
Training loss: 2.050000200038993
Validation loss: 2.632905288706316

Epoch: 6| Step: 11
Training loss: 2.404491624296803
Validation loss: 2.567690763484328

Epoch: 6| Step: 12
Training loss: 2.3987599507135893
Validation loss: 2.605603955681722

Epoch: 6| Step: 13
Training loss: 1.566665970348988
Validation loss: 2.627110783077852

Epoch: 49| Step: 0
Training loss: 2.817394659853773
Validation loss: 2.6486339214933894

Epoch: 6| Step: 1
Training loss: 2.297986650366723
Validation loss: 2.6798728752707275

Epoch: 6| Step: 2
Training loss: 2.649472014893276
Validation loss: 2.602192631531627

Epoch: 6| Step: 3
Training loss: 2.4518208529881838
Validation loss: 2.58186459063578

Epoch: 6| Step: 4
Training loss: 2.6705460840765345
Validation loss: 2.5931310872775515

Epoch: 6| Step: 5
Training loss: 2.1308011922052055
Validation loss: 2.5966930467965628

Epoch: 6| Step: 6
Training loss: 1.9711129676344676
Validation loss: 2.5910195529140583

Epoch: 6| Step: 7
Training loss: 2.5152818907852663
Validation loss: 2.638069903013687

Epoch: 6| Step: 8
Training loss: 2.5057523352223803
Validation loss: 2.6331578451746447

Epoch: 6| Step: 9
Training loss: 2.1575400874545503
Validation loss: 2.5802329799279375

Epoch: 6| Step: 10
Training loss: 2.4750887459921733
Validation loss: 2.608747562955051

Epoch: 6| Step: 11
Training loss: 2.6957440459270465
Validation loss: 2.632222457557597

Epoch: 6| Step: 12
Training loss: 1.9721023235082393
Validation loss: 2.6128192487523894

Epoch: 6| Step: 13
Training loss: 3.130458184974841
Validation loss: 2.6531770471171354

Epoch: 50| Step: 0
Training loss: 1.905637611455026
Validation loss: 2.6157490815173774

Epoch: 6| Step: 1
Training loss: 2.7100869199319835
Validation loss: 2.5701916172469033

Epoch: 6| Step: 2
Training loss: 2.5737500610647985
Validation loss: 2.5776496603134387

Epoch: 6| Step: 3
Training loss: 2.0469783145368994
Validation loss: 2.5922616725348204

Epoch: 6| Step: 4
Training loss: 2.654840431949953
Validation loss: 2.631053302870154

Epoch: 6| Step: 5
Training loss: 2.303380045750669
Validation loss: 2.5609697564486824

Epoch: 6| Step: 6
Training loss: 3.145403211548595
Validation loss: 2.5936838470969845

Epoch: 6| Step: 7
Training loss: 2.37400455694878
Validation loss: 2.5788600143606897

Epoch: 6| Step: 8
Training loss: 2.478283497767436
Validation loss: 2.6153439229860536

Epoch: 6| Step: 9
Training loss: 1.9314616460781706
Validation loss: 2.5963397444946548

Epoch: 6| Step: 10
Training loss: 2.8224668437676077
Validation loss: 2.5997003682197084

Epoch: 6| Step: 11
Training loss: 2.1784888906276603
Validation loss: 2.6422162048958264

Epoch: 6| Step: 12
Training loss: 2.377728751777378
Validation loss: 2.639093560652799

Epoch: 6| Step: 13
Training loss: 2.703105066479519
Validation loss: 2.594397353006546

Epoch: 51| Step: 0
Training loss: 2.140291842409538
Validation loss: 2.613888018634186

Epoch: 6| Step: 1
Training loss: 2.2772392654660107
Validation loss: 2.664485043961483

Epoch: 6| Step: 2
Training loss: 1.817511240886364
Validation loss: 2.6401860551343943

Epoch: 6| Step: 3
Training loss: 2.4118762934578233
Validation loss: 2.675928977730886

Epoch: 6| Step: 4
Training loss: 3.2002768158392247
Validation loss: 2.6490878541648173

Epoch: 6| Step: 5
Training loss: 2.3167701679774946
Validation loss: 2.6150120286196854

Epoch: 6| Step: 6
Training loss: 1.9526825670762957
Validation loss: 2.5849705297092522

Epoch: 6| Step: 7
Training loss: 1.8712395151337646
Validation loss: 2.618154220059809

Epoch: 6| Step: 8
Training loss: 3.7467749396955337
Validation loss: 2.5920461857197328

Epoch: 6| Step: 9
Training loss: 3.238392569143643
Validation loss: 2.6001234532660016

Epoch: 6| Step: 10
Training loss: 1.7631954255046456
Validation loss: 2.585349524151529

Epoch: 6| Step: 11
Training loss: 2.208354937849588
Validation loss: 2.643720945013745

Epoch: 6| Step: 12
Training loss: 1.57507550800311
Validation loss: 2.620551222297864

Epoch: 6| Step: 13
Training loss: 2.797135324989864
Validation loss: 2.5863981115238914

Epoch: 52| Step: 0
Training loss: 2.4273395539521587
Validation loss: 2.558610554026005

Epoch: 6| Step: 1
Training loss: 2.257107528923964
Validation loss: 2.614917769199812

Epoch: 6| Step: 2
Training loss: 1.6177353967424002
Validation loss: 2.6189509433804625

Epoch: 6| Step: 3
Training loss: 2.9319065489298453
Validation loss: 2.602047146702597

Epoch: 6| Step: 4
Training loss: 2.5636595916802527
Validation loss: 2.6068638122216092

Epoch: 6| Step: 5
Training loss: 1.6051278970687932
Validation loss: 2.559176266585041

Epoch: 6| Step: 6
Training loss: 2.4072800450448213
Validation loss: 2.585288097823286

Epoch: 6| Step: 7
Training loss: 2.6594041833946074
Validation loss: 2.596916931034163

Epoch: 6| Step: 8
Training loss: 3.161898251908167
Validation loss: 2.6107800597368636

Epoch: 6| Step: 9
Training loss: 2.434233800198897
Validation loss: 2.6328454925854565

Epoch: 6| Step: 10
Training loss: 2.6363772927053115
Validation loss: 2.6010427251672836

Epoch: 6| Step: 11
Training loss: 1.9407413195949454
Validation loss: 2.5742493137056033

Epoch: 6| Step: 12
Training loss: 2.4154899845661855
Validation loss: 2.5672345346548453

Epoch: 6| Step: 13
Training loss: 2.873746515763914
Validation loss: 2.5506108038651405

Epoch: 53| Step: 0
Training loss: 3.125355967274796
Validation loss: 2.605000283649451

Epoch: 6| Step: 1
Training loss: 2.6527075988469724
Validation loss: 2.650207888048381

Epoch: 6| Step: 2
Training loss: 2.1407489601497134
Validation loss: 2.66800868021703

Epoch: 6| Step: 3
Training loss: 2.739405163288396
Validation loss: 2.7131920196918995

Epoch: 6| Step: 4
Training loss: 2.2425050942523637
Validation loss: 2.719720952081287

Epoch: 6| Step: 5
Training loss: 2.756227551150431
Validation loss: 2.745250154502704

Epoch: 6| Step: 6
Training loss: 2.1319133274432103
Validation loss: 2.785972086944375

Epoch: 6| Step: 7
Training loss: 2.648645263444575
Validation loss: 2.736337143027498

Epoch: 6| Step: 8
Training loss: 2.452010563689186
Validation loss: 2.740699081550578

Epoch: 6| Step: 9
Training loss: 2.5139188489539546
Validation loss: 2.7209489049117894

Epoch: 6| Step: 10
Training loss: 1.7037734450856297
Validation loss: 2.700211941677622

Epoch: 6| Step: 11
Training loss: 1.992783879790464
Validation loss: 2.5951366624512677

Epoch: 6| Step: 12
Training loss: 2.286175153455087
Validation loss: 2.5758171001142074

Epoch: 6| Step: 13
Training loss: 3.260483632400396
Validation loss: 2.588398894294169

Epoch: 54| Step: 0
Training loss: 2.7492386891194034
Validation loss: 2.616322130453453

Epoch: 6| Step: 1
Training loss: 1.979534402781999
Validation loss: 2.6150517265766675

Epoch: 6| Step: 2
Training loss: 2.2265126005236366
Validation loss: 2.5954378297214165

Epoch: 6| Step: 3
Training loss: 2.7440196814985076
Validation loss: 2.6044506884504743

Epoch: 6| Step: 4
Training loss: 3.3100147641132147
Validation loss: 2.64459473361398

Epoch: 6| Step: 5
Training loss: 1.9703806224787066
Validation loss: 2.61179306771993

Epoch: 6| Step: 6
Training loss: 3.1881002721106086
Validation loss: 2.6361535641604137

Epoch: 6| Step: 7
Training loss: 2.6195184604367827
Validation loss: 2.625792247564183

Epoch: 6| Step: 8
Training loss: 2.9249225573598925
Validation loss: 2.5950091419536694

Epoch: 6| Step: 9
Training loss: 2.1213785616075103
Validation loss: 2.5730881936250944

Epoch: 6| Step: 10
Training loss: 2.3321177404265856
Validation loss: 2.6071574521138365

Epoch: 6| Step: 11
Training loss: 2.032824331684558
Validation loss: 2.5968815692890437

Epoch: 6| Step: 12
Training loss: 1.9703161882431033
Validation loss: 2.576726576572106

Epoch: 6| Step: 13
Training loss: 2.088270618484441
Validation loss: 2.5660902319375745

Epoch: 55| Step: 0
Training loss: 2.0964681716784637
Validation loss: 2.6183508569562823

Epoch: 6| Step: 1
Training loss: 2.22645670321566
Validation loss: 2.5998666637416674

Epoch: 6| Step: 2
Training loss: 2.671452003591889
Validation loss: 2.6221991537537765

Epoch: 6| Step: 3
Training loss: 2.4039432318232086
Validation loss: 2.6255115131761886

Epoch: 6| Step: 4
Training loss: 2.280960064583145
Validation loss: 2.6457073351878506

Epoch: 6| Step: 5
Training loss: 2.158012001930498
Validation loss: 2.6318023283162453

Epoch: 6| Step: 6
Training loss: 2.589492244658022
Validation loss: 2.609050433594388

Epoch: 6| Step: 7
Training loss: 2.618784676187948
Validation loss: 2.6399040667606894

Epoch: 6| Step: 8
Training loss: 2.377549860578864
Validation loss: 2.6233276459302246

Epoch: 6| Step: 9
Training loss: 2.366555913384325
Validation loss: 2.6175886463552898

Epoch: 6| Step: 10
Training loss: 2.1749033500857813
Validation loss: 2.6442578849202456

Epoch: 6| Step: 11
Training loss: 2.6096126425340382
Validation loss: 2.6246967443258047

Epoch: 6| Step: 12
Training loss: 3.0551417176486253
Validation loss: 2.632159128438878

Epoch: 6| Step: 13
Training loss: 2.5184961839487574
Validation loss: 2.6116551014056433

Epoch: 56| Step: 0
Training loss: 2.276079144085636
Validation loss: 2.5713412652256404

Epoch: 6| Step: 1
Training loss: 2.0515420138403213
Validation loss: 2.6107433028475713

Epoch: 6| Step: 2
Training loss: 2.8567085549107376
Validation loss: 2.5823324069222577

Epoch: 6| Step: 3
Training loss: 1.8213981043514107
Validation loss: 2.6150641486843904

Epoch: 6| Step: 4
Training loss: 1.7987048575944544
Validation loss: 2.594185191340671

Epoch: 6| Step: 5
Training loss: 2.8571440117697424
Validation loss: 2.585043492360216

Epoch: 6| Step: 6
Training loss: 2.1453308949303547
Validation loss: 2.5886224213456424

Epoch: 6| Step: 7
Training loss: 2.4666772180623693
Validation loss: 2.6213221291784135

Epoch: 6| Step: 8
Training loss: 2.2928421011526003
Validation loss: 2.599062569056248

Epoch: 6| Step: 9
Training loss: 2.6247507612796097
Validation loss: 2.570024066421495

Epoch: 6| Step: 10
Training loss: 2.3649182411562384
Validation loss: 2.571871191171056

Epoch: 6| Step: 11
Training loss: 2.010869055993344
Validation loss: 2.621373850925836

Epoch: 6| Step: 12
Training loss: 3.489614609915029
Validation loss: 2.596051034222948

Epoch: 6| Step: 13
Training loss: 2.4873974726264825
Validation loss: 2.5860875480890484

Epoch: 57| Step: 0
Training loss: 1.907879555013523
Validation loss: 2.5717682122162024

Epoch: 6| Step: 1
Training loss: 2.447878140626576
Validation loss: 2.598968228083691

Epoch: 6| Step: 2
Training loss: 2.8298385234365555
Validation loss: 2.6489199608711016

Epoch: 6| Step: 3
Training loss: 2.471926130882415
Validation loss: 2.6637452832566137

Epoch: 6| Step: 4
Training loss: 1.7396570825838438
Validation loss: 2.6432786582986236

Epoch: 6| Step: 5
Training loss: 2.4667321179272323
Validation loss: 2.622268042280808

Epoch: 6| Step: 6
Training loss: 2.380178127194537
Validation loss: 2.665588955860988

Epoch: 6| Step: 7
Training loss: 2.2567841719101063
Validation loss: 2.6147953317317807

Epoch: 6| Step: 8
Training loss: 2.9095404261382942
Validation loss: 2.631883300657038

Epoch: 6| Step: 9
Training loss: 2.199058296489073
Validation loss: 2.626246901717152

Epoch: 6| Step: 10
Training loss: 2.300091625544704
Validation loss: 2.636941029162796

Epoch: 6| Step: 11
Training loss: 2.870262222804936
Validation loss: 2.6819942469960676

Epoch: 6| Step: 12
Training loss: 2.554648302809959
Validation loss: 2.611970961695088

Epoch: 6| Step: 13
Training loss: 2.3231670660931774
Validation loss: 2.6032126599313674

Epoch: 58| Step: 0
Training loss: 1.784207749420123
Validation loss: 2.586466540168548

Epoch: 6| Step: 1
Training loss: 1.77878259120955
Validation loss: 2.6070815570303574

Epoch: 6| Step: 2
Training loss: 2.183661881204547
Validation loss: 2.578243769212262

Epoch: 6| Step: 3
Training loss: 2.7123015651985702
Validation loss: 2.6038762858937026

Epoch: 6| Step: 4
Training loss: 2.0849664263686534
Validation loss: 2.606597914980142

Epoch: 6| Step: 5
Training loss: 2.61731794800838
Validation loss: 2.6370294081796453

Epoch: 6| Step: 6
Training loss: 2.515093634741282
Validation loss: 2.571467595144891

Epoch: 6| Step: 7
Training loss: 1.9654832409804341
Validation loss: 2.5764572760550317

Epoch: 6| Step: 8
Training loss: 2.7607924487487936
Validation loss: 2.617870093763215

Epoch: 6| Step: 9
Training loss: 2.771043802934552
Validation loss: 2.588211995449616

Epoch: 6| Step: 10
Training loss: 2.9631419971029263
Validation loss: 2.564516328689873

Epoch: 6| Step: 11
Training loss: 2.334148423562695
Validation loss: 2.553135656227961

Epoch: 6| Step: 12
Training loss: 2.4070427319513756
Validation loss: 2.5935058785268894

Epoch: 6| Step: 13
Training loss: 2.489953262319427
Validation loss: 2.570521476621754

Epoch: 59| Step: 0
Training loss: 2.43125997114711
Validation loss: 2.5692060073560974

Epoch: 6| Step: 1
Training loss: 2.448890384157066
Validation loss: 2.6404385698407378

Epoch: 6| Step: 2
Training loss: 2.6121685128058707
Validation loss: 2.583657695546835

Epoch: 6| Step: 3
Training loss: 3.228499083064095
Validation loss: 2.591430699521868

Epoch: 6| Step: 4
Training loss: 2.0791410099299092
Validation loss: 2.593472967711616

Epoch: 6| Step: 5
Training loss: 2.7173898736701183
Validation loss: 2.6255805266761394

Epoch: 6| Step: 6
Training loss: 2.3999865372598075
Validation loss: 2.6059061014107767

Epoch: 6| Step: 7
Training loss: 2.184920724962656
Validation loss: 2.55751413179224

Epoch: 6| Step: 8
Training loss: 2.184541063449701
Validation loss: 2.586572037183388

Epoch: 6| Step: 9
Training loss: 2.715786776975167
Validation loss: 2.5701070778801043

Epoch: 6| Step: 10
Training loss: 1.8867508468898977
Validation loss: 2.604962835040676

Epoch: 6| Step: 11
Training loss: 1.7963915630668237
Validation loss: 2.586617433220351

Epoch: 6| Step: 12
Training loss: 2.1532484531306237
Validation loss: 2.6571015283341377

Epoch: 6| Step: 13
Training loss: 3.022285813787665
Validation loss: 2.5738134069847423

Epoch: 60| Step: 0
Training loss: 2.367426189814836
Validation loss: 2.5951178517343996

Epoch: 6| Step: 1
Training loss: 2.197766002053056
Validation loss: 2.5550447422248226

Epoch: 6| Step: 2
Training loss: 3.0793550618669974
Validation loss: 2.626617690063833

Epoch: 6| Step: 3
Training loss: 1.7309937380408038
Validation loss: 2.6043258364035826

Epoch: 6| Step: 4
Training loss: 2.4299602784728918
Validation loss: 2.610236583403289

Epoch: 6| Step: 5
Training loss: 2.5623274954440722
Validation loss: 2.614132425604643

Epoch: 6| Step: 6
Training loss: 2.4438918987160343
Validation loss: 2.622729212390228

Epoch: 6| Step: 7
Training loss: 2.4792079334404136
Validation loss: 2.6250824688263887

Epoch: 6| Step: 8
Training loss: 2.8133177522104296
Validation loss: 2.6167422698775877

Epoch: 6| Step: 9
Training loss: 2.0295982100395036
Validation loss: 2.5783003468079144

Epoch: 6| Step: 10
Training loss: 1.787996132562709
Validation loss: 2.6075879371520094

Epoch: 6| Step: 11
Training loss: 2.5457933621512643
Validation loss: 2.601438425826547

Epoch: 6| Step: 12
Training loss: 2.1581428070615223
Validation loss: 2.5468838853427536

Epoch: 6| Step: 13
Training loss: 2.8402733982822403
Validation loss: 2.638892182688303

Epoch: 61| Step: 0
Training loss: 2.461256412247829
Validation loss: 2.590350002330745

Epoch: 6| Step: 1
Training loss: 1.9585086933378373
Validation loss: 2.5972214872752444

Epoch: 6| Step: 2
Training loss: 2.549236677026683
Validation loss: 2.5854162514865817

Epoch: 6| Step: 3
Training loss: 1.771588407614035
Validation loss: 2.6120162357781833

Epoch: 6| Step: 4
Training loss: 2.845263068132696
Validation loss: 2.6048244459387186

Epoch: 6| Step: 5
Training loss: 1.725776873367583
Validation loss: 2.5823814781690344

Epoch: 6| Step: 6
Training loss: 1.9931629859364437
Validation loss: 2.536452453314032

Epoch: 6| Step: 7
Training loss: 2.3494105837624404
Validation loss: 2.5768306218681514

Epoch: 6| Step: 8
Training loss: 2.737204259635379
Validation loss: 2.5735797002030303

Epoch: 6| Step: 9
Training loss: 1.4943758910211182
Validation loss: 2.593487967618231

Epoch: 6| Step: 10
Training loss: 2.6341930358236256
Validation loss: 2.6094034159135306

Epoch: 6| Step: 11
Training loss: 2.8667906608675326
Validation loss: 2.598709466571309

Epoch: 6| Step: 12
Training loss: 2.874834470544735
Validation loss: 2.532957294019265

Epoch: 6| Step: 13
Training loss: 2.811369944414194
Validation loss: 2.609344939098691

Epoch: 62| Step: 0
Training loss: 2.699886609274896
Validation loss: 2.6189819409239505

Epoch: 6| Step: 1
Training loss: 2.2545677021053203
Validation loss: 2.610789450544424

Epoch: 6| Step: 2
Training loss: 1.7896529643405246
Validation loss: 2.578054053361139

Epoch: 6| Step: 3
Training loss: 2.084487696951036
Validation loss: 2.6157980955419378

Epoch: 6| Step: 4
Training loss: 1.4550310165664966
Validation loss: 2.5910120918352972

Epoch: 6| Step: 5
Training loss: 2.646924692383302
Validation loss: 2.6091950253610903

Epoch: 6| Step: 6
Training loss: 2.8797342877201526
Validation loss: 2.596506056301224

Epoch: 6| Step: 7
Training loss: 2.251894682947215
Validation loss: 2.6087413939897797

Epoch: 6| Step: 8
Training loss: 2.325381614786792
Validation loss: 2.564678088332385

Epoch: 6| Step: 9
Training loss: 2.6402701415940872
Validation loss: 2.630929773677826

Epoch: 6| Step: 10
Training loss: 2.784646264422583
Validation loss: 2.59188713064146

Epoch: 6| Step: 11
Training loss: 2.059890599169795
Validation loss: 2.6157071382120307

Epoch: 6| Step: 12
Training loss: 2.556732385910591
Validation loss: 2.6321704583490253

Epoch: 6| Step: 13
Training loss: 3.030270762416238
Validation loss: 2.6438335510711046

Epoch: 63| Step: 0
Training loss: 2.5563429388858228
Validation loss: 2.598434966348562

Epoch: 6| Step: 1
Training loss: 2.364026871013737
Validation loss: 2.6391720357763395

Epoch: 6| Step: 2
Training loss: 2.5310725397139344
Validation loss: 2.6091836185284363

Epoch: 6| Step: 3
Training loss: 2.3606626521050096
Validation loss: 2.5708169799564837

Epoch: 6| Step: 4
Training loss: 2.913780382833402
Validation loss: 2.595434859559036

Epoch: 6| Step: 5
Training loss: 1.9858370223540014
Validation loss: 2.583737546819713

Epoch: 6| Step: 6
Training loss: 2.4235953834798223
Validation loss: 2.6179768600801188

Epoch: 6| Step: 7
Training loss: 3.1000694697810016
Validation loss: 2.615369098622335

Epoch: 6| Step: 8
Training loss: 2.3403783324460927
Validation loss: 2.5987575405024295

Epoch: 6| Step: 9
Training loss: 1.7840641612801742
Validation loss: 2.598810827519828

Epoch: 6| Step: 10
Training loss: 2.1951654459616576
Validation loss: 2.593528523621857

Epoch: 6| Step: 11
Training loss: 1.7148598776647654
Validation loss: 2.589274793204091

Epoch: 6| Step: 12
Training loss: 2.5105575796338027
Validation loss: 2.585867121143084

Epoch: 6| Step: 13
Training loss: 3.0576334063167736
Validation loss: 2.583184135394518

Epoch: 64| Step: 0
Training loss: 2.3723248925822906
Validation loss: 2.571837694493141

Epoch: 6| Step: 1
Training loss: 2.995523609886541
Validation loss: 2.57017793467406

Epoch: 6| Step: 2
Training loss: 3.251702522954787
Validation loss: 2.595475201422573

Epoch: 6| Step: 3
Training loss: 1.9519827592549552
Validation loss: 2.619768333457548

Epoch: 6| Step: 4
Training loss: 2.5186386538143077
Validation loss: 2.6265928037863158

Epoch: 6| Step: 5
Training loss: 1.5232807567852715
Validation loss: 2.6502272598418033

Epoch: 6| Step: 6
Training loss: 2.2810438925246537
Validation loss: 2.6852839670670843

Epoch: 6| Step: 7
Training loss: 2.7830742842985394
Validation loss: 2.664869303763918

Epoch: 6| Step: 8
Training loss: 1.8955327169441996
Validation loss: 2.65212523394076

Epoch: 6| Step: 9
Training loss: 2.752975068356004
Validation loss: 2.6513274113134377

Epoch: 6| Step: 10
Training loss: 1.9612196761073042
Validation loss: 2.641106014343973

Epoch: 6| Step: 11
Training loss: 2.168613537279583
Validation loss: 2.622031183027788

Epoch: 6| Step: 12
Training loss: 2.765435508658857
Validation loss: 2.5931853020528397

Epoch: 6| Step: 13
Training loss: 2.290772928454763
Validation loss: 2.5793662117803042

Epoch: 65| Step: 0
Training loss: 2.727286606088639
Validation loss: 2.574900172745992

Epoch: 6| Step: 1
Training loss: 2.6599224956952163
Validation loss: 2.595378349275704

Epoch: 6| Step: 2
Training loss: 2.264354691694701
Validation loss: 2.5635945688364448

Epoch: 6| Step: 3
Training loss: 2.3415266553985448
Validation loss: 2.606280153315082

Epoch: 6| Step: 4
Training loss: 2.2787152147175296
Validation loss: 2.5817972866906875

Epoch: 6| Step: 5
Training loss: 2.612301493134729
Validation loss: 2.6080577365524253

Epoch: 6| Step: 6
Training loss: 1.8926482290978046
Validation loss: 2.5734181063488153

Epoch: 6| Step: 7
Training loss: 2.5971365272496394
Validation loss: 2.617505136829134

Epoch: 6| Step: 8
Training loss: 3.2277509149457466
Validation loss: 2.572550532638952

Epoch: 6| Step: 9
Training loss: 2.0548125834520268
Validation loss: 2.585942939683431

Epoch: 6| Step: 10
Training loss: 1.9183241132331796
Validation loss: 2.587040261722951

Epoch: 6| Step: 11
Training loss: 2.7949826109316236
Validation loss: 2.623160277656511

Epoch: 6| Step: 12
Training loss: 1.9018742728130091
Validation loss: 2.623902038257055

Epoch: 6| Step: 13
Training loss: 2.1390785144237086
Validation loss: 2.5928589389494054

Epoch: 66| Step: 0
Training loss: 2.107450949934108
Validation loss: 2.6016246799679026

Epoch: 6| Step: 1
Training loss: 2.4357173954816385
Validation loss: 2.5887414610811086

Epoch: 6| Step: 2
Training loss: 2.418423857866695
Validation loss: 2.5821769238505885

Epoch: 6| Step: 3
Training loss: 2.406110189760597
Validation loss: 2.563005006076311

Epoch: 6| Step: 4
Training loss: 2.21622925603962
Validation loss: 2.6032951626032776

Epoch: 6| Step: 5
Training loss: 2.4137128558232046
Validation loss: 2.558113157840014

Epoch: 6| Step: 6
Training loss: 2.1386447852522337
Validation loss: 2.6040163581703504

Epoch: 6| Step: 7
Training loss: 2.132166279018087
Validation loss: 2.5940378787672884

Epoch: 6| Step: 8
Training loss: 2.2673193548179706
Validation loss: 2.6154426641804394

Epoch: 6| Step: 9
Training loss: 2.6142795178520863
Validation loss: 2.550803277396197

Epoch: 6| Step: 10
Training loss: 1.7108883088587064
Validation loss: 2.610084467698842

Epoch: 6| Step: 11
Training loss: 2.225092245182827
Validation loss: 2.614092409670028

Epoch: 6| Step: 12
Training loss: 3.0880061302321864
Validation loss: 2.575432544785413

Epoch: 6| Step: 13
Training loss: 3.071709002242564
Validation loss: 2.594368443429863

Epoch: 67| Step: 0
Training loss: 2.6183811483341497
Validation loss: 2.5996037652012243

Epoch: 6| Step: 1
Training loss: 2.3783164710463147
Validation loss: 2.602656244308222

Epoch: 6| Step: 2
Training loss: 2.511016605177969
Validation loss: 2.6165643585962663

Epoch: 6| Step: 3
Training loss: 2.43298341987376
Validation loss: 2.6677539118982176

Epoch: 6| Step: 4
Training loss: 2.1814768020197337
Validation loss: 2.6788310025099653

Epoch: 6| Step: 5
Training loss: 2.817916909405419
Validation loss: 2.63683286066736

Epoch: 6| Step: 6
Training loss: 1.8844825650666448
Validation loss: 2.6347553318012085

Epoch: 6| Step: 7
Training loss: 2.2146550389114177
Validation loss: 2.652133789141909

Epoch: 6| Step: 8
Training loss: 2.655611836685161
Validation loss: 2.590706077076971

Epoch: 6| Step: 9
Training loss: 2.0269603329933026
Validation loss: 2.5609165432072323

Epoch: 6| Step: 10
Training loss: 1.9836342698143314
Validation loss: 2.594767987360056

Epoch: 6| Step: 11
Training loss: 2.4256996718493933
Validation loss: 2.5935174002778596

Epoch: 6| Step: 12
Training loss: 3.4786192564223444
Validation loss: 2.602797618855029

Epoch: 6| Step: 13
Training loss: 1.7725748661301663
Validation loss: 2.5998364776149523

Epoch: 68| Step: 0
Training loss: 2.3169518997277123
Validation loss: 2.5755525489965487

Epoch: 6| Step: 1
Training loss: 2.0883479103783196
Validation loss: 2.6007844909054967

Epoch: 6| Step: 2
Training loss: 2.3030391682297524
Validation loss: 2.6149012510376806

Epoch: 6| Step: 3
Training loss: 2.060499550515496
Validation loss: 2.58960815247979

Epoch: 6| Step: 4
Training loss: 2.3382134720563394
Validation loss: 2.57233537189811

Epoch: 6| Step: 5
Training loss: 2.7334313208376178
Validation loss: 2.595469077460886

Epoch: 6| Step: 6
Training loss: 2.303074780024047
Validation loss: 2.574870604439795

Epoch: 6| Step: 7
Training loss: 2.530738967360472
Validation loss: 2.590667056734321

Epoch: 6| Step: 8
Training loss: 2.438887176957202
Validation loss: 2.5952469094975847

Epoch: 6| Step: 9
Training loss: 2.1623817279203164
Validation loss: 2.643388915598014

Epoch: 6| Step: 10
Training loss: 2.4590677575964017
Validation loss: 2.650987041237862

Epoch: 6| Step: 11
Training loss: 2.384734832289937
Validation loss: 2.649933938936428

Epoch: 6| Step: 12
Training loss: 2.239413149969452
Validation loss: 2.6208913832049165

Epoch: 6| Step: 13
Training loss: 2.993962252106899
Validation loss: 2.6106891939384913

Epoch: 69| Step: 0
Training loss: 2.744704957541899
Validation loss: 2.566390418280122

Epoch: 6| Step: 1
Training loss: 2.349696638939577
Validation loss: 2.590195008206314

Epoch: 6| Step: 2
Training loss: 2.1646681396006295
Validation loss: 2.6013006282818494

Epoch: 6| Step: 3
Training loss: 2.5428155480805246
Validation loss: 2.5557106061445056

Epoch: 6| Step: 4
Training loss: 2.4379238836033523
Validation loss: 2.5794760506667904

Epoch: 6| Step: 5
Training loss: 2.2582139446987166
Validation loss: 2.6169798052160065

Epoch: 6| Step: 6
Training loss: 2.2198568457765395
Validation loss: 2.627248996489649

Epoch: 6| Step: 7
Training loss: 2.363098137437255
Validation loss: 2.5355510982168155

Epoch: 6| Step: 8
Training loss: 2.037713082995754
Validation loss: 2.6160554629637987

Epoch: 6| Step: 9
Training loss: 2.9322077376085924
Validation loss: 2.5861792168104283

Epoch: 6| Step: 10
Training loss: 2.9196256251262
Validation loss: 2.6147992828876627

Epoch: 6| Step: 11
Training loss: 2.037112886127727
Validation loss: 2.546786051252018

Epoch: 6| Step: 12
Training loss: 2.371529301918574
Validation loss: 2.52759380567717

Epoch: 6| Step: 13
Training loss: 2.4967379268599945
Validation loss: 2.5980642050967746

Epoch: 70| Step: 0
Training loss: 2.3969654449149265
Validation loss: 2.622234545346936

Epoch: 6| Step: 1
Training loss: 2.6721181480019
Validation loss: 2.6555504120715283

Epoch: 6| Step: 2
Training loss: 2.6236161717000925
Validation loss: 2.613510509521652

Epoch: 6| Step: 3
Training loss: 1.6788974767058973
Validation loss: 2.6618868986044304

Epoch: 6| Step: 4
Training loss: 2.243854501144927
Validation loss: 2.6958199433392656

Epoch: 6| Step: 5
Training loss: 2.340432323883133
Validation loss: 2.72554381832435

Epoch: 6| Step: 6
Training loss: 1.845241525239584
Validation loss: 2.7280592358073887

Epoch: 6| Step: 7
Training loss: 3.3816431856977425
Validation loss: 2.6591135110885005

Epoch: 6| Step: 8
Training loss: 1.6465825496197881
Validation loss: 2.6664579031607856

Epoch: 6| Step: 9
Training loss: 3.272555940410748
Validation loss: 2.6183455756581333

Epoch: 6| Step: 10
Training loss: 2.2223160790120295
Validation loss: 2.631488048087812

Epoch: 6| Step: 11
Training loss: 2.434676662651564
Validation loss: 2.5671184292906832

Epoch: 6| Step: 12
Training loss: 2.016687748801428
Validation loss: 2.599524875168435

Epoch: 6| Step: 13
Training loss: 2.1950532481832004
Validation loss: 2.6169402807581617

Epoch: 71| Step: 0
Training loss: 2.2804686370880947
Validation loss: 2.590215243032681

Epoch: 6| Step: 1
Training loss: 2.833110314362066
Validation loss: 2.548995042502011

Epoch: 6| Step: 2
Training loss: 1.8432172878544084
Validation loss: 2.588549152775358

Epoch: 6| Step: 3
Training loss: 2.68435298391069
Validation loss: 2.601406287466472

Epoch: 6| Step: 4
Training loss: 2.8244354460381405
Validation loss: 2.5599597885405942

Epoch: 6| Step: 5
Training loss: 2.179194787781878
Validation loss: 2.5718510746760392

Epoch: 6| Step: 6
Training loss: 2.8890828735887566
Validation loss: 2.6295350878121937

Epoch: 6| Step: 7
Training loss: 2.0812165632798196
Validation loss: 2.5850804071568976

Epoch: 6| Step: 8
Training loss: 2.061459365492362
Validation loss: 2.5747369563982936

Epoch: 6| Step: 9
Training loss: 1.8127695080558803
Validation loss: 2.576281464477278

Epoch: 6| Step: 10
Training loss: 1.810942737219596
Validation loss: 2.5712302906676188

Epoch: 6| Step: 11
Training loss: 2.363442659777192
Validation loss: 2.6106870173822583

Epoch: 6| Step: 12
Training loss: 2.834005575278215
Validation loss: 2.597882284402405

Epoch: 6| Step: 13
Training loss: 2.5220112741325735
Validation loss: 2.640173849055569

Epoch: 72| Step: 0
Training loss: 2.7810960362712875
Validation loss: 2.619012285691914

Epoch: 6| Step: 1
Training loss: 2.2256383215985736
Validation loss: 2.5737820815955015

Epoch: 6| Step: 2
Training loss: 2.2052086250065925
Validation loss: 2.5588939539164053

Epoch: 6| Step: 3
Training loss: 2.5418072229095303
Validation loss: 2.588984358841342

Epoch: 6| Step: 4
Training loss: 2.7987034111694307
Validation loss: 2.6590626504419603

Epoch: 6| Step: 5
Training loss: 2.38014316817436
Validation loss: 2.6153213452328505

Epoch: 6| Step: 6
Training loss: 1.6944791793737257
Validation loss: 2.627914793458312

Epoch: 6| Step: 7
Training loss: 1.958789332712459
Validation loss: 2.548120549035662

Epoch: 6| Step: 8
Training loss: 1.7932058273186708
Validation loss: 2.622301576669956

Epoch: 6| Step: 9
Training loss: 2.382550334578843
Validation loss: 2.583119665559247

Epoch: 6| Step: 10
Training loss: 2.429388389697713
Validation loss: 2.5630372577449245

Epoch: 6| Step: 11
Training loss: 1.5888172181659155
Validation loss: 2.5826432372822445

Epoch: 6| Step: 12
Training loss: 2.605693481453087
Validation loss: 2.580392399181067

Epoch: 6| Step: 13
Training loss: 2.978590066948836
Validation loss: 2.590082448140461

Epoch: 73| Step: 0
Training loss: 1.3950163694672342
Validation loss: 2.5956765645440467

Epoch: 6| Step: 1
Training loss: 2.7794578864826702
Validation loss: 2.555395426835813

Epoch: 6| Step: 2
Training loss: 2.2329958413986932
Validation loss: 2.584305693048027

Epoch: 6| Step: 3
Training loss: 2.039644706304042
Validation loss: 2.5970450157824465

Epoch: 6| Step: 4
Training loss: 2.3151688511282753
Validation loss: 2.6284505780794607

Epoch: 6| Step: 5
Training loss: 2.5393373311295826
Validation loss: 2.6309205755881147

Epoch: 6| Step: 6
Training loss: 2.3980939289751557
Validation loss: 2.6058380307540627

Epoch: 6| Step: 7
Training loss: 2.069087979923655
Validation loss: 2.6042744550650148

Epoch: 6| Step: 8
Training loss: 2.1798091293909594
Validation loss: 2.594889287185533

Epoch: 6| Step: 9
Training loss: 2.7709651619281295
Validation loss: 2.6838676834777795

Epoch: 6| Step: 10
Training loss: 2.6701832373388865
Validation loss: 2.596701218428623

Epoch: 6| Step: 11
Training loss: 2.4199009879798754
Validation loss: 2.593979637673918

Epoch: 6| Step: 12
Training loss: 1.926628684634172
Validation loss: 2.618630947784584

Epoch: 6| Step: 13
Training loss: 2.8732589757492506
Validation loss: 2.5715226529586244

Epoch: 74| Step: 0
Training loss: 2.03480465244266
Validation loss: 2.53685568347991

Epoch: 6| Step: 1
Training loss: 2.925504011762649
Validation loss: 2.547725785020169

Epoch: 6| Step: 2
Training loss: 2.40779549644056
Validation loss: 2.552433796907397

Epoch: 6| Step: 3
Training loss: 2.087192343694667
Validation loss: 2.571669663752822

Epoch: 6| Step: 4
Training loss: 2.666411586323586
Validation loss: 2.588199091347245

Epoch: 6| Step: 5
Training loss: 2.066214482255443
Validation loss: 2.541570510504545

Epoch: 6| Step: 6
Training loss: 2.2472394326704537
Validation loss: 2.5931256933204456

Epoch: 6| Step: 7
Training loss: 2.074499193906225
Validation loss: 2.582482595234285

Epoch: 6| Step: 8
Training loss: 1.6091499541626595
Validation loss: 2.596990223641564

Epoch: 6| Step: 9
Training loss: 2.627392904347562
Validation loss: 2.590869667761216

Epoch: 6| Step: 10
Training loss: 2.8740209488075363
Validation loss: 2.61421608087032

Epoch: 6| Step: 11
Training loss: 2.3185632964694123
Validation loss: 2.5493132888296555

Epoch: 6| Step: 12
Training loss: 2.6243159901579554
Validation loss: 2.5315524575960717

Epoch: 6| Step: 13
Training loss: 2.004179402375021
Validation loss: 2.602674344037639

Epoch: 75| Step: 0
Training loss: 1.6927465894239662
Validation loss: 2.587193179406349

Epoch: 6| Step: 1
Training loss: 2.9973908840550654
Validation loss: 2.58107428579964

Epoch: 6| Step: 2
Training loss: 2.025927804396773
Validation loss: 2.573314116098202

Epoch: 6| Step: 3
Training loss: 2.68285945080313
Validation loss: 2.545075028193534

Epoch: 6| Step: 4
Training loss: 2.057294576779653
Validation loss: 2.6217585335083946

Epoch: 6| Step: 5
Training loss: 2.7180580047750595
Validation loss: 2.5914336282723123

Epoch: 6| Step: 6
Training loss: 2.0752182903139644
Validation loss: 2.5984170741235912

Epoch: 6| Step: 7
Training loss: 1.8559197771106473
Validation loss: 2.576872457780123

Epoch: 6| Step: 8
Training loss: 3.0909946386462943
Validation loss: 2.57590053422147

Epoch: 6| Step: 9
Training loss: 1.9589717784716212
Validation loss: 2.586113876674096

Epoch: 6| Step: 10
Training loss: 2.5598680889893766
Validation loss: 2.610322487104642

Epoch: 6| Step: 11
Training loss: 2.6886950652444077
Validation loss: 2.6260857682923793

Epoch: 6| Step: 12
Training loss: 1.982024475254484
Validation loss: 2.640559013189293

Epoch: 6| Step: 13
Training loss: 2.4077269740080514
Validation loss: 2.647535112224391

Epoch: 76| Step: 0
Training loss: 2.2870359856927296
Validation loss: 2.619438220855324

Epoch: 6| Step: 1
Training loss: 1.937299718041848
Validation loss: 2.5987982130448377

Epoch: 6| Step: 2
Training loss: 3.009725700376017
Validation loss: 2.5976699866980937

Epoch: 6| Step: 3
Training loss: 3.1480742971530242
Validation loss: 2.6003513514486136

Epoch: 6| Step: 4
Training loss: 1.6438750999043976
Validation loss: 2.6447100219705146

Epoch: 6| Step: 5
Training loss: 1.9074791244424447
Validation loss: 2.576946027506087

Epoch: 6| Step: 6
Training loss: 1.708319136707895
Validation loss: 2.6064646436580188

Epoch: 6| Step: 7
Training loss: 2.5304639561258235
Validation loss: 2.577514761171151

Epoch: 6| Step: 8
Training loss: 1.9954962087971329
Validation loss: 2.606660028186582

Epoch: 6| Step: 9
Training loss: 2.591921426041301
Validation loss: 2.62098571585021

Epoch: 6| Step: 10
Training loss: 2.4985984688364153
Validation loss: 2.554487899153287

Epoch: 6| Step: 11
Training loss: 2.152076552295126
Validation loss: 2.603417606707411

Epoch: 6| Step: 12
Training loss: 2.3253351687779897
Validation loss: 2.597388094491536

Epoch: 6| Step: 13
Training loss: 2.3915998677706836
Validation loss: 2.5287789579183184

Epoch: 77| Step: 0
Training loss: 1.9022457403044297
Validation loss: 2.59657348400325

Epoch: 6| Step: 1
Training loss: 2.193131201434452
Validation loss: 2.5439263653675015

Epoch: 6| Step: 2
Training loss: 2.5482655105231053
Validation loss: 2.6142848073643608

Epoch: 6| Step: 3
Training loss: 2.282307627866001
Validation loss: 2.553060917884706

Epoch: 6| Step: 4
Training loss: 2.2830050262582984
Validation loss: 2.537661560126947

Epoch: 6| Step: 5
Training loss: 2.4831138624800366
Validation loss: 2.5745568755256043

Epoch: 6| Step: 6
Training loss: 2.6256475104130006
Validation loss: 2.637413389281418

Epoch: 6| Step: 7
Training loss: 2.0974656343429694
Validation loss: 2.5726912292888877

Epoch: 6| Step: 8
Training loss: 2.153082691325067
Validation loss: 2.5906047057924115

Epoch: 6| Step: 9
Training loss: 2.327401067841729
Validation loss: 2.570504425829575

Epoch: 6| Step: 10
Training loss: 2.2675850643869917
Validation loss: 2.595230369485544

Epoch: 6| Step: 11
Training loss: 3.0227958530617163
Validation loss: 2.609750792955057

Epoch: 6| Step: 12
Training loss: 2.2923985670773166
Validation loss: 2.585065273921743

Epoch: 6| Step: 13
Training loss: 2.3124503053016614
Validation loss: 2.6169680299357325

Epoch: 78| Step: 0
Training loss: 2.782801506110723
Validation loss: 2.56860828426409

Epoch: 6| Step: 1
Training loss: 2.8639086859440512
Validation loss: 2.579762564879561

Epoch: 6| Step: 2
Training loss: 2.7263465948889634
Validation loss: 2.5674289811912807

Epoch: 6| Step: 3
Training loss: 2.1712604998135383
Validation loss: 2.5854062920627854

Epoch: 6| Step: 4
Training loss: 2.4058457072087003
Validation loss: 2.5474232432663118

Epoch: 6| Step: 5
Training loss: 2.5024838506309
Validation loss: 2.6268164692518456

Epoch: 6| Step: 6
Training loss: 2.0184953936471604
Validation loss: 2.5866600325669755

Epoch: 6| Step: 7
Training loss: 2.132070782701346
Validation loss: 2.5714107049530734

Epoch: 6| Step: 8
Training loss: 2.0292778418110067
Validation loss: 2.5689570322627158

Epoch: 6| Step: 9
Training loss: 2.033638825944678
Validation loss: 2.5455085895862717

Epoch: 6| Step: 10
Training loss: 2.6880962686216137
Validation loss: 2.552977282119584

Epoch: 6| Step: 11
Training loss: 2.041825917579105
Validation loss: 2.5088514035899796

Epoch: 6| Step: 12
Training loss: 2.0980906116711724
Validation loss: 2.572036041619291

Epoch: 6| Step: 13
Training loss: 2.3800931828953957
Validation loss: 2.61643322755793

Epoch: 79| Step: 0
Training loss: 1.9160438714390264
Validation loss: 2.5605746223348795

Epoch: 6| Step: 1
Training loss: 2.953612272237491
Validation loss: 2.6005441774746285

Epoch: 6| Step: 2
Training loss: 1.6726004194325486
Validation loss: 2.641248979148541

Epoch: 6| Step: 3
Training loss: 2.360240853190793
Validation loss: 2.630556915651655

Epoch: 6| Step: 4
Training loss: 2.847104787084616
Validation loss: 2.6436041479858643

Epoch: 6| Step: 5
Training loss: 2.4666666825612387
Validation loss: 2.6449341535154125

Epoch: 6| Step: 6
Training loss: 2.6661689015576826
Validation loss: 2.6253580727148584

Epoch: 6| Step: 7
Training loss: 2.0468296890485194
Validation loss: 2.553497348311699

Epoch: 6| Step: 8
Training loss: 1.6076925427587938
Validation loss: 2.6180249748388973

Epoch: 6| Step: 9
Training loss: 2.5960034612153526
Validation loss: 2.610246448086839

Epoch: 6| Step: 10
Training loss: 2.305384229961224
Validation loss: 2.601854676420711

Epoch: 6| Step: 11
Training loss: 2.1607925553991207
Validation loss: 2.594511402930643

Epoch: 6| Step: 12
Training loss: 2.443395088355605
Validation loss: 2.5877727515288895

Epoch: 6| Step: 13
Training loss: 2.190874167732015
Validation loss: 2.5512383184394505

Epoch: 80| Step: 0
Training loss: 2.735592467524442
Validation loss: 2.6182857050247597

Epoch: 6| Step: 1
Training loss: 2.460949416358798
Validation loss: 2.53640341780875

Epoch: 6| Step: 2
Training loss: 2.2344360343226413
Validation loss: 2.54114699653296

Epoch: 6| Step: 3
Training loss: 2.211900696703547
Validation loss: 2.584512185234618

Epoch: 6| Step: 4
Training loss: 2.606721728329534
Validation loss: 2.596948665916004

Epoch: 6| Step: 5
Training loss: 2.7090401729676215
Validation loss: 2.5989470905272283

Epoch: 6| Step: 6
Training loss: 2.0701505777628393
Validation loss: 2.5761121039678527

Epoch: 6| Step: 7
Training loss: 1.6141089285924344
Validation loss: 2.5797826042797563

Epoch: 6| Step: 8
Training loss: 2.293145921871118
Validation loss: 2.5899232264349674

Epoch: 6| Step: 9
Training loss: 1.7485544501387704
Validation loss: 2.584809209840377

Epoch: 6| Step: 10
Training loss: 2.980971867604869
Validation loss: 2.682854577906307

Epoch: 6| Step: 11
Training loss: 2.48389319780276
Validation loss: 2.621879319682634

Epoch: 6| Step: 12
Training loss: 1.792714751293243
Validation loss: 2.6102779295745155

Epoch: 6| Step: 13
Training loss: 2.0590426047957964
Validation loss: 2.606219258420604

Epoch: 81| Step: 0
Training loss: 2.4635981633252113
Validation loss: 2.5202041555389325

Epoch: 6| Step: 1
Training loss: 2.3857690697996823
Validation loss: 2.542534075658376

Epoch: 6| Step: 2
Training loss: 2.6885305690918155
Validation loss: 2.5588859565965785

Epoch: 6| Step: 3
Training loss: 2.7129583824050574
Validation loss: 2.577274706330935

Epoch: 6| Step: 4
Training loss: 1.6803824473077462
Validation loss: 2.5892819753785847

Epoch: 6| Step: 5
Training loss: 2.3534384307231386
Validation loss: 2.5899843663955227

Epoch: 6| Step: 6
Training loss: 1.8938034704735949
Validation loss: 2.604046755255231

Epoch: 6| Step: 7
Training loss: 3.0424642867011684
Validation loss: 2.537839311234904

Epoch: 6| Step: 8
Training loss: 2.4429877690037567
Validation loss: 2.570841679696044

Epoch: 6| Step: 9
Training loss: 2.5091990978113463
Validation loss: 2.584733127441395

Epoch: 6| Step: 10
Training loss: 2.5318139472329557
Validation loss: 2.5711302842857973

Epoch: 6| Step: 11
Training loss: 1.957827347122973
Validation loss: 2.5106135775213114

Epoch: 6| Step: 12
Training loss: 1.701413475775879
Validation loss: 2.5711284606129894

Epoch: 6| Step: 13
Training loss: 1.9957116166219935
Validation loss: 2.567425761946405

Epoch: 82| Step: 0
Training loss: 1.9108433648018168
Validation loss: 2.6457659394899897

Epoch: 6| Step: 1
Training loss: 2.420719781817995
Validation loss: 2.6491710205938324

Epoch: 6| Step: 2
Training loss: 2.7749767061922643
Validation loss: 2.6030856113880807

Epoch: 6| Step: 3
Training loss: 2.4297519687550806
Validation loss: 2.6592229474681943

Epoch: 6| Step: 4
Training loss: 2.5420261399840687
Validation loss: 2.6521048421854063

Epoch: 6| Step: 5
Training loss: 2.6149288622952063
Validation loss: 2.631627118774019

Epoch: 6| Step: 6
Training loss: 1.2509870923304154
Validation loss: 2.6038567218711264

Epoch: 6| Step: 7
Training loss: 2.5323047088910675
Validation loss: 2.6231756531402124

Epoch: 6| Step: 8
Training loss: 1.8862439934475
Validation loss: 2.6059116976423864

Epoch: 6| Step: 9
Training loss: 2.287625327090517
Validation loss: 2.625053155451683

Epoch: 6| Step: 10
Training loss: 2.4401394174174404
Validation loss: 2.6371763533999935

Epoch: 6| Step: 11
Training loss: 2.3328387780826962
Validation loss: 2.5566935775398254

Epoch: 6| Step: 12
Training loss: 2.183102356241491
Validation loss: 2.578187005424466

Epoch: 6| Step: 13
Training loss: 2.1587482299090595
Validation loss: 2.571153381453621

Epoch: 83| Step: 0
Training loss: 2.923067390179244
Validation loss: 2.580219366003563

Epoch: 6| Step: 1
Training loss: 3.00237148648309
Validation loss: 2.582616996404518

Epoch: 6| Step: 2
Training loss: 2.8705037659123858
Validation loss: 2.585740173125451

Epoch: 6| Step: 3
Training loss: 2.502389242977671
Validation loss: 2.539145764672892

Epoch: 6| Step: 4
Training loss: 1.5992030930789272
Validation loss: 2.580787255139936

Epoch: 6| Step: 5
Training loss: 1.5178625363165936
Validation loss: 2.538160584504122

Epoch: 6| Step: 6
Training loss: 1.467108275658236
Validation loss: 2.5440805937368784

Epoch: 6| Step: 7
Training loss: 2.0241237345707854
Validation loss: 2.5955049636706153

Epoch: 6| Step: 8
Training loss: 2.6222946213122458
Validation loss: 2.5676947097468488

Epoch: 6| Step: 9
Training loss: 2.310490843737616
Validation loss: 2.5802486420122617

Epoch: 6| Step: 10
Training loss: 1.8063670348164118
Validation loss: 2.614272541151426

Epoch: 6| Step: 11
Training loss: 2.28926517774069
Validation loss: 2.6104384746893867

Epoch: 6| Step: 12
Training loss: 2.230666063336376
Validation loss: 2.652910448227521

Epoch: 6| Step: 13
Training loss: 2.094125856284485
Validation loss: 2.601136547879311

Epoch: 84| Step: 0
Training loss: 1.9728675049319966
Validation loss: 2.657860219244117

Epoch: 6| Step: 1
Training loss: 2.947896537217788
Validation loss: 2.630107421953563

Epoch: 6| Step: 2
Training loss: 2.583455164918069
Validation loss: 2.6076440228376265

Epoch: 6| Step: 3
Training loss: 1.9190351392382328
Validation loss: 2.6285754029148176

Epoch: 6| Step: 4
Training loss: 1.8655491109010547
Validation loss: 2.6108805107077657

Epoch: 6| Step: 5
Training loss: 2.762638526999031
Validation loss: 2.6452997125090087

Epoch: 6| Step: 6
Training loss: 2.3803339840857327
Validation loss: 2.614029424184105

Epoch: 6| Step: 7
Training loss: 2.043329794145831
Validation loss: 2.5835333921020416

Epoch: 6| Step: 8
Training loss: 1.713092091803412
Validation loss: 2.560550956422146

Epoch: 6| Step: 9
Training loss: 2.473563222286513
Validation loss: 2.591483631192002

Epoch: 6| Step: 10
Training loss: 2.3535373037772307
Validation loss: 2.592886217900836

Epoch: 6| Step: 11
Training loss: 2.4107681066570272
Validation loss: 2.546842703585249

Epoch: 6| Step: 12
Training loss: 2.2174264963175316
Validation loss: 2.5770980639230725

Epoch: 6| Step: 13
Training loss: 2.2559288113298988
Validation loss: 2.5633103554749486

Epoch: 85| Step: 0
Training loss: 2.4638886694589677
Validation loss: 2.617741927449867

Epoch: 6| Step: 1
Training loss: 1.4242366419268362
Validation loss: 2.579017022454246

Epoch: 6| Step: 2
Training loss: 2.333154149214445
Validation loss: 2.612181640769331

Epoch: 6| Step: 3
Training loss: 2.068187155321306
Validation loss: 2.5954519685663513

Epoch: 6| Step: 4
Training loss: 1.5503542526026857
Validation loss: 2.570106150219836

Epoch: 6| Step: 5
Training loss: 1.3058538192005515
Validation loss: 2.6213245015493585

Epoch: 6| Step: 6
Training loss: 2.9405177422156723
Validation loss: 2.595116450686539

Epoch: 6| Step: 7
Training loss: 2.207749511511352
Validation loss: 2.638072493795141

Epoch: 6| Step: 8
Training loss: 2.181529261684606
Validation loss: 2.601072599394872

Epoch: 6| Step: 9
Training loss: 2.49899338483908
Validation loss: 2.5896236811405258

Epoch: 6| Step: 10
Training loss: 2.6484167047545037
Validation loss: 2.577421242577207

Epoch: 6| Step: 11
Training loss: 2.570830226341938
Validation loss: 2.58971214823123

Epoch: 6| Step: 12
Training loss: 2.4391013533963473
Validation loss: 2.5242527923130287

Epoch: 6| Step: 13
Training loss: 2.1856915218973705
Validation loss: 2.565860870335804

Epoch: 86| Step: 0
Training loss: 2.4146794885596523
Validation loss: 2.639997253440623

Epoch: 6| Step: 1
Training loss: 2.6831642484604457
Validation loss: 2.6273726458042357

Epoch: 6| Step: 2
Training loss: 2.302137716580195
Validation loss: 2.606657200387155

Epoch: 6| Step: 3
Training loss: 2.426563965943748
Validation loss: 2.5918810135331833

Epoch: 6| Step: 4
Training loss: 1.7498332352879686
Validation loss: 2.6558845343400765

Epoch: 6| Step: 5
Training loss: 2.008470716829431
Validation loss: 2.651376884166392

Epoch: 6| Step: 6
Training loss: 2.0794550719235754
Validation loss: 2.602014931868299

Epoch: 6| Step: 7
Training loss: 2.694270454985344
Validation loss: 2.552053075079048

Epoch: 6| Step: 8
Training loss: 2.6852959754956593
Validation loss: 2.6228876697572607

Epoch: 6| Step: 9
Training loss: 1.730802069050888
Validation loss: 2.583046933162124

Epoch: 6| Step: 10
Training loss: 1.7863519783354371
Validation loss: 2.589987941159095

Epoch: 6| Step: 11
Training loss: 1.9757741931745516
Validation loss: 2.5708625459994887

Epoch: 6| Step: 12
Training loss: 2.5466214855373748
Validation loss: 2.635899772140385

Epoch: 6| Step: 13
Training loss: 2.3553043643405496
Validation loss: 2.607344882699891

Epoch: 87| Step: 0
Training loss: 2.3417247923382796
Validation loss: 2.60238148854588

Epoch: 6| Step: 1
Training loss: 2.566584146915316
Validation loss: 2.5897165826307837

Epoch: 6| Step: 2
Training loss: 1.7060222655405233
Validation loss: 2.5768582555433635

Epoch: 6| Step: 3
Training loss: 1.8833699647609914
Validation loss: 2.5980856786680753

Epoch: 6| Step: 4
Training loss: 2.1829873541318467
Validation loss: 2.5810493760734463

Epoch: 6| Step: 5
Training loss: 2.4503458401786293
Validation loss: 2.544125701502857

Epoch: 6| Step: 6
Training loss: 2.1555635769466495
Validation loss: 2.57257345487058

Epoch: 6| Step: 7
Training loss: 1.5694646111977173
Validation loss: 2.606573554064612

Epoch: 6| Step: 8
Training loss: 2.3034236222644666
Validation loss: 2.5834080982669314

Epoch: 6| Step: 9
Training loss: 2.954834781165332
Validation loss: 2.5920344887968336

Epoch: 6| Step: 10
Training loss: 2.0264620177358794
Validation loss: 2.5821150834886852

Epoch: 6| Step: 11
Training loss: 2.1548258183089826
Validation loss: 2.6582141271508783

Epoch: 6| Step: 12
Training loss: 2.493884713494768
Validation loss: 2.644756763934598

Epoch: 6| Step: 13
Training loss: 2.2940919584818187
Validation loss: 2.6619441017722902

Epoch: 88| Step: 0
Training loss: 2.461147141988183
Validation loss: 2.6605345633922064

Epoch: 6| Step: 1
Training loss: 2.800250866414643
Validation loss: 2.681411336981375

Epoch: 6| Step: 2
Training loss: 2.2921095217889325
Validation loss: 2.61367653450232

Epoch: 6| Step: 3
Training loss: 2.430018755051562
Validation loss: 2.6027165508046393

Epoch: 6| Step: 4
Training loss: 2.8340654736199458
Validation loss: 2.6128141387726265

Epoch: 6| Step: 5
Training loss: 2.33000752165403
Validation loss: 2.5299819784314166

Epoch: 6| Step: 6
Training loss: 1.8062289042049393
Validation loss: 2.5829613838277683

Epoch: 6| Step: 7
Training loss: 1.5020196351800974
Validation loss: 2.5718503485016173

Epoch: 6| Step: 8
Training loss: 2.2241550212663386
Validation loss: 2.5378628601305944

Epoch: 6| Step: 9
Training loss: 2.272449711410013
Validation loss: 2.5747052872775638

Epoch: 6| Step: 10
Training loss: 1.9950750031868638
Validation loss: 2.567766917542423

Epoch: 6| Step: 11
Training loss: 1.7432435944523068
Validation loss: 2.5579998385071674

Epoch: 6| Step: 12
Training loss: 1.9805138336407322
Validation loss: 2.5852925705515264

Epoch: 6| Step: 13
Training loss: 2.2546260748709073
Validation loss: 2.607966897796332

Epoch: 89| Step: 0
Training loss: 1.8361167008620585
Validation loss: 2.629076018385398

Epoch: 6| Step: 1
Training loss: 2.1987934141660355
Validation loss: 2.5913258296742434

Epoch: 6| Step: 2
Training loss: 2.160061328864995
Validation loss: 2.6328858498336754

Epoch: 6| Step: 3
Training loss: 1.2954333461809537
Validation loss: 2.6616942319197032

Epoch: 6| Step: 4
Training loss: 1.5305980929544378
Validation loss: 2.6282704053427928

Epoch: 6| Step: 5
Training loss: 2.3863587053256263
Validation loss: 2.6704692153970435

Epoch: 6| Step: 6
Training loss: 1.7956072771981635
Validation loss: 2.6848979151977006

Epoch: 6| Step: 7
Training loss: 2.5245066170170345
Validation loss: 2.6731267305894324

Epoch: 6| Step: 8
Training loss: 2.6049260570846187
Validation loss: 2.672913109848102

Epoch: 6| Step: 9
Training loss: 3.061781818492744
Validation loss: 2.6243802050382716

Epoch: 6| Step: 10
Training loss: 2.342130686533421
Validation loss: 2.595903919376728

Epoch: 6| Step: 11
Training loss: 2.4496923837419624
Validation loss: 2.597467829627757

Epoch: 6| Step: 12
Training loss: 2.53619645559946
Validation loss: 2.6183700395128184

Epoch: 6| Step: 13
Training loss: 2.1120237321459494
Validation loss: 2.5481247205362174

Epoch: 90| Step: 0
Training loss: 1.9273249569190423
Validation loss: 2.6010506616166214

Epoch: 6| Step: 1
Training loss: 2.7919124286329744
Validation loss: 2.5817239167736745

Epoch: 6| Step: 2
Training loss: 2.323305813021151
Validation loss: 2.5619660108000635

Epoch: 6| Step: 3
Training loss: 2.2606264945761687
Validation loss: 2.5438804730470546

Epoch: 6| Step: 4
Training loss: 1.7782052100783476
Validation loss: 2.591700130708616

Epoch: 6| Step: 5
Training loss: 2.1594718414541094
Validation loss: 2.570557316925436

Epoch: 6| Step: 6
Training loss: 2.007599221861803
Validation loss: 2.6011513508280424

Epoch: 6| Step: 7
Training loss: 2.171478125447755
Validation loss: 2.5506561544606843

Epoch: 6| Step: 8
Training loss: 2.2179419967042935
Validation loss: 2.596552189220256

Epoch: 6| Step: 9
Training loss: 2.819162572875975
Validation loss: 2.6465693498883827

Epoch: 6| Step: 10
Training loss: 2.2061344451468674
Validation loss: 2.627597749599539

Epoch: 6| Step: 11
Training loss: 2.183972812022243
Validation loss: 2.6698861555767195

Epoch: 6| Step: 12
Training loss: 1.969216609337108
Validation loss: 2.621256944983406

Epoch: 6| Step: 13
Training loss: 2.5344514734134576
Validation loss: 2.6538633956795623

Epoch: 91| Step: 0
Training loss: 1.740837497855331
Validation loss: 2.5627479898431664

Epoch: 6| Step: 1
Training loss: 1.944707937401396
Validation loss: 2.584551798174925

Epoch: 6| Step: 2
Training loss: 2.0453761779337887
Validation loss: 2.555188268952581

Epoch: 6| Step: 3
Training loss: 1.8069058610199866
Validation loss: 2.5655774346363103

Epoch: 6| Step: 4
Training loss: 2.2748137303484834
Validation loss: 2.5643522809768813

Epoch: 6| Step: 5
Training loss: 1.9601991030713284
Validation loss: 2.607497828754851

Epoch: 6| Step: 6
Training loss: 2.4890815729343205
Validation loss: 2.583665839197785

Epoch: 6| Step: 7
Training loss: 2.415390784986056
Validation loss: 2.544357912622639

Epoch: 6| Step: 8
Training loss: 1.7878260441843652
Validation loss: 2.6093303958331795

Epoch: 6| Step: 9
Training loss: 2.1024930234015398
Validation loss: 2.5866951039150483

Epoch: 6| Step: 10
Training loss: 3.421070300377072
Validation loss: 2.5433550422595226

Epoch: 6| Step: 11
Training loss: 1.5949256898795607
Validation loss: 2.619022526971748

Epoch: 6| Step: 12
Training loss: 2.431683275698998
Validation loss: 2.606823981953554

Epoch: 6| Step: 13
Training loss: 2.1922650345939187
Validation loss: 2.6236135666432245

Epoch: 92| Step: 0
Training loss: 2.281405299923074
Validation loss: 2.6329912375915123

Epoch: 6| Step: 1
Training loss: 1.8943395143996864
Validation loss: 2.6020892949235814

Epoch: 6| Step: 2
Training loss: 1.6250193668091721
Validation loss: 2.641801545663898

Epoch: 6| Step: 3
Training loss: 1.673789381115194
Validation loss: 2.591291235034268

Epoch: 6| Step: 4
Training loss: 1.135165644670481
Validation loss: 2.68889165672137

Epoch: 6| Step: 5
Training loss: 1.9179570650261417
Validation loss: 2.686834016238753

Epoch: 6| Step: 6
Training loss: 2.7434402603811647
Validation loss: 2.7281276287752227

Epoch: 6| Step: 7
Training loss: 1.4105666981870015
Validation loss: 2.7563629375222254

Epoch: 6| Step: 8
Training loss: 2.685841425608218
Validation loss: 2.67851301280916

Epoch: 6| Step: 9
Training loss: 2.5176090922200864
Validation loss: 2.6901502626845093

Epoch: 6| Step: 10
Training loss: 2.3322231399080384
Validation loss: 2.6039475208899017

Epoch: 6| Step: 11
Training loss: 2.6005780531118745
Validation loss: 2.572573439424401

Epoch: 6| Step: 12
Training loss: 2.3150787409332736
Validation loss: 2.581221737833914

Epoch: 6| Step: 13
Training loss: 3.005253959498928
Validation loss: 2.5796654770956793

Epoch: 93| Step: 0
Training loss: 2.1176242729750054
Validation loss: 2.6214493398040437

Epoch: 6| Step: 1
Training loss: 2.0624798860436124
Validation loss: 2.558104567804607

Epoch: 6| Step: 2
Training loss: 2.338471024316398
Validation loss: 2.571006619338945

Epoch: 6| Step: 3
Training loss: 2.0049579678741134
Validation loss: 2.542517352924875

Epoch: 6| Step: 4
Training loss: 1.7670914628083907
Validation loss: 2.55325952531131

Epoch: 6| Step: 5
Training loss: 2.2071486720353772
Validation loss: 2.56207937184357

Epoch: 6| Step: 6
Training loss: 2.5810487756506264
Validation loss: 2.577448993255869

Epoch: 6| Step: 7
Training loss: 1.39806292754617
Validation loss: 2.578015812575028

Epoch: 6| Step: 8
Training loss: 1.9663920738851968
Validation loss: 2.536014703471322

Epoch: 6| Step: 9
Training loss: 2.610095992387548
Validation loss: 2.538057662495207

Epoch: 6| Step: 10
Training loss: 2.7869810570715376
Validation loss: 2.6130031709541073

Epoch: 6| Step: 11
Training loss: 2.2537107597739117
Validation loss: 2.5823310681827976

Epoch: 6| Step: 12
Training loss: 2.2172567151095164
Validation loss: 2.6225165017684313

Epoch: 6| Step: 13
Training loss: 2.0806135607812037
Validation loss: 2.667750634976798

Epoch: 94| Step: 0
Training loss: 2.7836029729227296
Validation loss: 2.6164880985227708

Epoch: 6| Step: 1
Training loss: 2.010880912452894
Validation loss: 2.6271852601073054

Epoch: 6| Step: 2
Training loss: 2.6251121678683336
Validation loss: 2.622322154722644

Epoch: 6| Step: 3
Training loss: 1.673164298358762
Validation loss: 2.633868600872293

Epoch: 6| Step: 4
Training loss: 1.6413952427185885
Validation loss: 2.6281502304045405

Epoch: 6| Step: 5
Training loss: 1.799450960136055
Validation loss: 2.612841483131321

Epoch: 6| Step: 6
Training loss: 2.1104484934790353
Validation loss: 2.5874336962106046

Epoch: 6| Step: 7
Training loss: 2.434658840022019
Validation loss: 2.5975579494147243

Epoch: 6| Step: 8
Training loss: 1.775868233036905
Validation loss: 2.5989245920278057

Epoch: 6| Step: 9
Training loss: 2.6644685944724844
Validation loss: 2.5856117742561504

Epoch: 6| Step: 10
Training loss: 2.5443775124702617
Validation loss: 2.5687375639949344

Epoch: 6| Step: 11
Training loss: 2.119284629323747
Validation loss: 2.5793264190631766

Epoch: 6| Step: 12
Training loss: 2.308090232506698
Validation loss: 2.5758851387995683

Epoch: 6| Step: 13
Training loss: 1.7218910645775751
Validation loss: 2.5910210865349854

Epoch: 95| Step: 0
Training loss: 2.333840644273415
Validation loss: 2.5939982345249555

Epoch: 6| Step: 1
Training loss: 1.7102520410051283
Validation loss: 2.5641315972383985

Epoch: 6| Step: 2
Training loss: 1.5443398094104586
Validation loss: 2.56090992541671

Epoch: 6| Step: 3
Training loss: 2.729654564574176
Validation loss: 2.5145184470346

Epoch: 6| Step: 4
Training loss: 2.114655617165931
Validation loss: 2.5251936652567895

Epoch: 6| Step: 5
Training loss: 1.7508359683472554
Validation loss: 2.573771505909796

Epoch: 6| Step: 6
Training loss: 1.6297420123191706
Validation loss: 2.599859740068642

Epoch: 6| Step: 7
Training loss: 2.3981796275128917
Validation loss: 2.6103142667770722

Epoch: 6| Step: 8
Training loss: 2.1209407631795725
Validation loss: 2.591777250459489

Epoch: 6| Step: 9
Training loss: 2.7927751380663923
Validation loss: 2.6315393435275496

Epoch: 6| Step: 10
Training loss: 1.9067529733949002
Validation loss: 2.604021546452923

Epoch: 6| Step: 11
Training loss: 1.8893572127009384
Validation loss: 2.59561664560665

Epoch: 6| Step: 12
Training loss: 2.2413769895253193
Validation loss: 2.684687836092377

Epoch: 6| Step: 13
Training loss: 2.3099453192179897
Validation loss: 2.646743968135823

Epoch: 96| Step: 0
Training loss: 1.8588084151036273
Validation loss: 2.6497663166968892

Epoch: 6| Step: 1
Training loss: 1.884824635268741
Validation loss: 2.611848142664883

Epoch: 6| Step: 2
Training loss: 2.557405571560031
Validation loss: 2.616436173883091

Epoch: 6| Step: 3
Training loss: 2.0674591554899315
Validation loss: 2.6123344557542603

Epoch: 6| Step: 4
Training loss: 1.7401529928887483
Validation loss: 2.635528989265392

Epoch: 6| Step: 5
Training loss: 2.1441078532406257
Validation loss: 2.6186287626548737

Epoch: 6| Step: 6
Training loss: 2.1382164317778396
Validation loss: 2.5991526947021018

Epoch: 6| Step: 7
Training loss: 2.5245736697005134
Validation loss: 2.619966782973261

Epoch: 6| Step: 8
Training loss: 1.9787115544182732
Validation loss: 2.589061605529692

Epoch: 6| Step: 9
Training loss: 2.487355873111436
Validation loss: 2.581992360186238

Epoch: 6| Step: 10
Training loss: 2.4586678832265583
Validation loss: 2.6084371468925487

Epoch: 6| Step: 11
Training loss: 1.8712950659901348
Validation loss: 2.5606980850184557

Epoch: 6| Step: 12
Training loss: 1.922398503654015
Validation loss: 2.5370490909077623

Epoch: 6| Step: 13
Training loss: 2.201025862365492
Validation loss: 2.6009526268187906

Epoch: 97| Step: 0
Training loss: 1.6293531943597173
Validation loss: 2.588170204655246

Epoch: 6| Step: 1
Training loss: 3.0499736972362577
Validation loss: 2.5881801073842765

Epoch: 6| Step: 2
Training loss: 2.0501465024004824
Validation loss: 2.5638815404314355

Epoch: 6| Step: 3
Training loss: 1.8894705282044293
Validation loss: 2.545987760622782

Epoch: 6| Step: 4
Training loss: 2.3995981793993977
Validation loss: 2.600304919177063

Epoch: 6| Step: 5
Training loss: 1.4382058773981112
Validation loss: 2.5969822518319137

Epoch: 6| Step: 6
Training loss: 2.199133537633678
Validation loss: 2.6017041936249576

Epoch: 6| Step: 7
Training loss: 2.0316793134805273
Validation loss: 2.6650504688257874

Epoch: 6| Step: 8
Training loss: 2.1807427808508066
Validation loss: 2.670022973260616

Epoch: 6| Step: 9
Training loss: 2.8297450025541138
Validation loss: 2.6536030614598527

Epoch: 6| Step: 10
Training loss: 1.860482791467363
Validation loss: 2.6101694173137258

Epoch: 6| Step: 11
Training loss: 1.7615004444408695
Validation loss: 2.5953441990756287

Epoch: 6| Step: 12
Training loss: 1.8192569144220965
Validation loss: 2.5912359685252637

Epoch: 6| Step: 13
Training loss: 1.7822048907072772
Validation loss: 2.6104489779369073

Epoch: 98| Step: 0
Training loss: 1.9762188156534006
Validation loss: 2.622456930914179

Epoch: 6| Step: 1
Training loss: 2.3420827403189666
Validation loss: 2.5861478107287237

Epoch: 6| Step: 2
Training loss: 1.2269086410100019
Validation loss: 2.496641971438838

Epoch: 6| Step: 3
Training loss: 2.280215721298478
Validation loss: 2.5818793655638093

Epoch: 6| Step: 4
Training loss: 1.8079747238502255
Validation loss: 2.5493985956622427

Epoch: 6| Step: 5
Training loss: 2.039716009306346
Validation loss: 2.495274345091911

Epoch: 6| Step: 6
Training loss: 2.8152166174144235
Validation loss: 2.5894003325965005

Epoch: 6| Step: 7
Training loss: 1.9230854595435019
Validation loss: 2.5921501373118505

Epoch: 6| Step: 8
Training loss: 2.1984204864385863
Validation loss: 2.6004090143315364

Epoch: 6| Step: 9
Training loss: 2.702376157197405
Validation loss: 2.6155383631593954

Epoch: 6| Step: 10
Training loss: 2.136145143385252
Validation loss: 2.6271631471235675

Epoch: 6| Step: 11
Training loss: 2.163106438602058
Validation loss: 2.5677001107002333

Epoch: 6| Step: 12
Training loss: 1.8731991702985178
Validation loss: 2.6169301831731975

Epoch: 6| Step: 13
Training loss: 1.417669007117693
Validation loss: 2.6276276319279583

Epoch: 99| Step: 0
Training loss: 2.2546841288942554
Validation loss: 2.6402198887052424

Epoch: 6| Step: 1
Training loss: 1.792333818763486
Validation loss: 2.6128697472858526

Epoch: 6| Step: 2
Training loss: 1.652363806348061
Validation loss: 2.6325462651934517

Epoch: 6| Step: 3
Training loss: 1.9232239989746212
Validation loss: 2.5749486603294676

Epoch: 6| Step: 4
Training loss: 2.4506763458904826
Validation loss: 2.6191302476374396

Epoch: 6| Step: 5
Training loss: 2.2594592151274204
Validation loss: 2.5602200142124727

Epoch: 6| Step: 6
Training loss: 2.4527741199474296
Validation loss: 2.579202507727282

Epoch: 6| Step: 7
Training loss: 2.414984172192629
Validation loss: 2.600850997941412

Epoch: 6| Step: 8
Training loss: 1.9050798420431954
Validation loss: 2.6403050275833753

Epoch: 6| Step: 9
Training loss: 1.8642351120155698
Validation loss: 2.582994413190868

Epoch: 6| Step: 10
Training loss: 1.9577953194780018
Validation loss: 2.6342134908126646

Epoch: 6| Step: 11
Training loss: 2.3168931420405476
Validation loss: 2.5926272401941786

Epoch: 6| Step: 12
Training loss: 1.9772813417133435
Validation loss: 2.6093733857962667

Epoch: 6| Step: 13
Training loss: 2.061537431301687
Validation loss: 2.573715708798899

Epoch: 100| Step: 0
Training loss: 1.9220350865625895
Validation loss: 2.6639304254184326

Epoch: 6| Step: 1
Training loss: 1.9008041512159812
Validation loss: 2.725152322320765

Epoch: 6| Step: 2
Training loss: 1.89234102415415
Validation loss: 2.8015237601658862

Epoch: 6| Step: 3
Training loss: 2.7086361838010453
Validation loss: 2.74206147080904

Epoch: 6| Step: 4
Training loss: 1.9107416734145914
Validation loss: 2.7118270836264746

Epoch: 6| Step: 5
Training loss: 1.963768727524669
Validation loss: 2.6226684418516966

Epoch: 6| Step: 6
Training loss: 2.391411745351106
Validation loss: 2.6284772155346987

Epoch: 6| Step: 7
Training loss: 1.8181701627271039
Validation loss: 2.5703999853270494

Epoch: 6| Step: 8
Training loss: 2.0937893991891205
Validation loss: 2.5412834900067347

Epoch: 6| Step: 9
Training loss: 2.448493618982346
Validation loss: 2.5909185313043173

Epoch: 6| Step: 10
Training loss: 2.4238353055959814
Validation loss: 2.5525328778706604

Epoch: 6| Step: 11
Training loss: 2.7365070859014717
Validation loss: 2.6057033785857238

Epoch: 6| Step: 12
Training loss: 2.256058800539764
Validation loss: 2.5911702421690443

Epoch: 6| Step: 13
Training loss: 1.9863009380629317
Validation loss: 2.547359802660993

Epoch: 101| Step: 0
Training loss: 2.424408209254394
Validation loss: 2.6007052394324304

Epoch: 6| Step: 1
Training loss: 2.230037827962083
Validation loss: 2.635920922408693

Epoch: 6| Step: 2
Training loss: 2.070864506671713
Validation loss: 2.667204792642283

Epoch: 6| Step: 3
Training loss: 1.7706749190737596
Validation loss: 2.6068324876646556

Epoch: 6| Step: 4
Training loss: 1.8825292730398453
Validation loss: 2.6934404441651285

Epoch: 6| Step: 5
Training loss: 2.1539772329163265
Validation loss: 2.5651255082276982

Epoch: 6| Step: 6
Training loss: 1.759928671410162
Validation loss: 2.620596552848397

Epoch: 6| Step: 7
Training loss: 2.544947169566832
Validation loss: 2.6137385479046626

Epoch: 6| Step: 8
Training loss: 2.2092250487120895
Validation loss: 2.5789485040034585

Epoch: 6| Step: 9
Training loss: 2.301452331599602
Validation loss: 2.6294159756408497

Epoch: 6| Step: 10
Training loss: 2.301197059764207
Validation loss: 2.572634883590709

Epoch: 6| Step: 11
Training loss: 1.9475495371559908
Validation loss: 2.6450423813076367

Epoch: 6| Step: 12
Training loss: 1.5773647478887312
Validation loss: 2.5497949941668328

Epoch: 6| Step: 13
Training loss: 1.833562345361786
Validation loss: 2.622657396643733

Epoch: 102| Step: 0
Training loss: 3.0814811882894464
Validation loss: 2.599464662776762

Epoch: 6| Step: 1
Training loss: 2.306008067273258
Validation loss: 2.573575384680393

Epoch: 6| Step: 2
Training loss: 2.1009043971320236
Validation loss: 2.609509477938146

Epoch: 6| Step: 3
Training loss: 1.6594473009468396
Validation loss: 2.623530703281164

Epoch: 6| Step: 4
Training loss: 1.4822421360743405
Validation loss: 2.6327097388795027

Epoch: 6| Step: 5
Training loss: 1.5700751737346776
Validation loss: 2.6526249402696647

Epoch: 6| Step: 6
Training loss: 2.3734597682849987
Validation loss: 2.6568105816679886

Epoch: 6| Step: 7
Training loss: 2.0948142008910677
Validation loss: 2.5577517611578604

Epoch: 6| Step: 8
Training loss: 1.1423870742047901
Validation loss: 2.6028219082444326

Epoch: 6| Step: 9
Training loss: 2.058355154727474
Validation loss: 2.589228538295326

Epoch: 6| Step: 10
Training loss: 2.2722653647847753
Validation loss: 2.5928146483552004

Epoch: 6| Step: 11
Training loss: 1.8826311586037514
Validation loss: 2.5602130919668946

Epoch: 6| Step: 12
Training loss: 2.3202633836473456
Validation loss: 2.579979000646804

Epoch: 6| Step: 13
Training loss: 1.9148276531861164
Validation loss: 2.5845936859118677

Epoch: 103| Step: 0
Training loss: 2.0578263243932824
Validation loss: 2.5249305614831643

Epoch: 6| Step: 1
Training loss: 2.0036064057469947
Validation loss: 2.5854717038731496

Epoch: 6| Step: 2
Training loss: 2.05359414603421
Validation loss: 2.572808473193828

Epoch: 6| Step: 3
Training loss: 1.9290358952909727
Validation loss: 2.5687507592267402

Epoch: 6| Step: 4
Training loss: 1.754266035054782
Validation loss: 2.626802915228023

Epoch: 6| Step: 5
Training loss: 1.693832102682446
Validation loss: 2.6103368726155978

Epoch: 6| Step: 6
Training loss: 2.4348974761685356
Validation loss: 2.6316681741762906

Epoch: 6| Step: 7
Training loss: 1.4831353884147065
Validation loss: 2.608901553879619

Epoch: 6| Step: 8
Training loss: 2.322699555199588
Validation loss: 2.640180922868915

Epoch: 6| Step: 9
Training loss: 2.5793088102432855
Validation loss: 2.61896110903721

Epoch: 6| Step: 10
Training loss: 1.780172524074383
Validation loss: 2.6002574774824687

Epoch: 6| Step: 11
Training loss: 1.7789526060930745
Validation loss: 2.576328861831705

Epoch: 6| Step: 12
Training loss: 1.8887064002588607
Validation loss: 2.5928081043174425

Epoch: 6| Step: 13
Training loss: 2.333322445526152
Validation loss: 2.6029101023177272

Epoch: 104| Step: 0
Training loss: 1.6678194430347726
Validation loss: 2.5960306612044817

Epoch: 6| Step: 1
Training loss: 1.630367145379316
Validation loss: 2.60714286616326

Epoch: 6| Step: 2
Training loss: 1.4563351520315386
Validation loss: 2.5485148698985283

Epoch: 6| Step: 3
Training loss: 2.0267568337727715
Validation loss: 2.677082326470766

Epoch: 6| Step: 4
Training loss: 2.0539273208344104
Validation loss: 2.6093539086743895

Epoch: 6| Step: 5
Training loss: 2.4106473499673364
Validation loss: 2.6080964052942672

Epoch: 6| Step: 6
Training loss: 2.400886503048155
Validation loss: 2.635426296372342

Epoch: 6| Step: 7
Training loss: 1.458144511759823
Validation loss: 2.6690179819821225

Epoch: 6| Step: 8
Training loss: 2.059199842954806
Validation loss: 2.6741230525447146

Epoch: 6| Step: 9
Training loss: 1.987668285802736
Validation loss: 2.6684521692806995

Epoch: 6| Step: 10
Training loss: 1.49745168388257
Validation loss: 2.6384574978115864

Epoch: 6| Step: 11
Training loss: 2.1290231655109406
Validation loss: 2.687856946203006

Epoch: 6| Step: 12
Training loss: 2.048887006497202
Validation loss: 2.655193896807493

Epoch: 6| Step: 13
Training loss: 2.8645329881347683
Validation loss: 2.5168230903930193

Epoch: 105| Step: 0
Training loss: 1.748576266293641
Validation loss: 2.5554474955209106

Epoch: 6| Step: 1
Training loss: 2.919229380675995
Validation loss: 2.5701471988663087

Epoch: 6| Step: 2
Training loss: 2.033171581129888
Validation loss: 2.626830522401358

Epoch: 6| Step: 3
Training loss: 1.6373951681811074
Validation loss: 2.5840823154240993

Epoch: 6| Step: 4
Training loss: 1.8097749811527997
Validation loss: 2.5634760199652202

Epoch: 6| Step: 5
Training loss: 2.031766385684165
Validation loss: 2.5988047267086603

Epoch: 6| Step: 6
Training loss: 1.9767539191756567
Validation loss: 2.5884816695589676

Epoch: 6| Step: 7
Training loss: 1.6371713526905725
Validation loss: 2.5258906735521536

Epoch: 6| Step: 8
Training loss: 1.9986103713819408
Validation loss: 2.5763731427895395

Epoch: 6| Step: 9
Training loss: 1.9485028314841522
Validation loss: 2.555092160279143

Epoch: 6| Step: 10
Training loss: 1.8921383562329177
Validation loss: 2.6036734355499433

Epoch: 6| Step: 11
Training loss: 2.4354947963307376
Validation loss: 2.5941365271889536

Epoch: 6| Step: 12
Training loss: 1.865182797982092
Validation loss: 2.5750844423096155

Epoch: 6| Step: 13
Training loss: 1.765884785402882
Validation loss: 2.6046455070224233

Epoch: 106| Step: 0
Training loss: 2.0145151794119234
Validation loss: 2.6393999421909413

Epoch: 6| Step: 1
Training loss: 1.7175210894271293
Validation loss: 2.664380543985131

Epoch: 6| Step: 2
Training loss: 2.2109901233247182
Validation loss: 2.7082284955983553

Epoch: 6| Step: 3
Training loss: 1.7952714482088512
Validation loss: 2.7180638525365177

Epoch: 6| Step: 4
Training loss: 2.4618391050543504
Validation loss: 2.6250831500008402

Epoch: 6| Step: 5
Training loss: 1.836584358701886
Validation loss: 2.7073051310418843

Epoch: 6| Step: 6
Training loss: 2.6161712039722578
Validation loss: 2.6921788819732853

Epoch: 6| Step: 7
Training loss: 1.8609420199783742
Validation loss: 2.601583593395664

Epoch: 6| Step: 8
Training loss: 1.8995650596713112
Validation loss: 2.573028211968492

Epoch: 6| Step: 9
Training loss: 1.9155894514211218
Validation loss: 2.5919224225481465

Epoch: 6| Step: 10
Training loss: 1.9040832712733105
Validation loss: 2.5862041539510163

Epoch: 6| Step: 11
Training loss: 2.1384967331610487
Validation loss: 2.568598692831774

Epoch: 6| Step: 12
Training loss: 1.8416625021402675
Validation loss: 2.5773192254308728

Epoch: 6| Step: 13
Training loss: 2.196320977494328
Validation loss: 2.574303756336834

Epoch: 107| Step: 0
Training loss: 1.9033830690093252
Validation loss: 2.6368671215367954

Epoch: 6| Step: 1
Training loss: 2.1787048093537753
Validation loss: 2.630196816195713

Epoch: 6| Step: 2
Training loss: 1.5025703342624324
Validation loss: 2.560959430419915

Epoch: 6| Step: 3
Training loss: 2.1310418572685097
Validation loss: 2.523718866461999

Epoch: 6| Step: 4
Training loss: 1.7824512914821398
Validation loss: 2.557134826781503

Epoch: 6| Step: 5
Training loss: 2.4499358811065246
Validation loss: 2.6834876101038234

Epoch: 6| Step: 6
Training loss: 1.558412087162345
Validation loss: 2.573688736159119

Epoch: 6| Step: 7
Training loss: 2.58917476247212
Validation loss: 2.6324108960757244

Epoch: 6| Step: 8
Training loss: 1.5431679126308602
Validation loss: 2.6093260099947924

Epoch: 6| Step: 9
Training loss: 2.007605872301876
Validation loss: 2.6389858869382667

Epoch: 6| Step: 10
Training loss: 1.8828866397933726
Validation loss: 2.6740778715140556

Epoch: 6| Step: 11
Training loss: 1.653096345534164
Validation loss: 2.69488042786739

Epoch: 6| Step: 12
Training loss: 2.0607186919257554
Validation loss: 2.6078209046627805

Epoch: 6| Step: 13
Training loss: 1.8857875129076713
Validation loss: 2.631640889543042

Epoch: 108| Step: 0
Training loss: 1.8043264052556791
Validation loss: 2.5846987827838674

Epoch: 6| Step: 1
Training loss: 1.7372032680574718
Validation loss: 2.624504693546799

Epoch: 6| Step: 2
Training loss: 2.4917945671638964
Validation loss: 2.6368333805739175

Epoch: 6| Step: 3
Training loss: 1.8140417973456648
Validation loss: 2.6336779582184673

Epoch: 6| Step: 4
Training loss: 1.6232390766208082
Validation loss: 2.646891567534172

Epoch: 6| Step: 5
Training loss: 2.429498793949284
Validation loss: 2.6130396375359064

Epoch: 6| Step: 6
Training loss: 2.3055341814064048
Validation loss: 2.6113003995836332

Epoch: 6| Step: 7
Training loss: 1.9238078004954315
Validation loss: 2.608855190011619

Epoch: 6| Step: 8
Training loss: 2.1160298803848203
Validation loss: 2.5589851681805063

Epoch: 6| Step: 9
Training loss: 1.448002965903011
Validation loss: 2.5990486256746363

Epoch: 6| Step: 10
Training loss: 1.475454409157049
Validation loss: 2.5586070596673935

Epoch: 6| Step: 11
Training loss: 1.6335594987311528
Validation loss: 2.5303635948625263

Epoch: 6| Step: 12
Training loss: 2.413575157182323
Validation loss: 2.5950748323297415

Epoch: 6| Step: 13
Training loss: 1.5320771766326562
Validation loss: 2.612496342268578

Epoch: 109| Step: 0
Training loss: 2.493088323247335
Validation loss: 2.6796924379709197

Epoch: 6| Step: 1
Training loss: 1.4470516154713122
Validation loss: 2.5670106777003268

Epoch: 6| Step: 2
Training loss: 2.5225461915156435
Validation loss: 2.6791507639395675

Epoch: 6| Step: 3
Training loss: 1.9432845364829843
Validation loss: 2.591493582593256

Epoch: 6| Step: 4
Training loss: 1.7358041322363797
Validation loss: 2.602720871444284

Epoch: 6| Step: 5
Training loss: 1.4115291263333196
Validation loss: 2.6013992151409693

Epoch: 6| Step: 6
Training loss: 1.8034768275334039
Validation loss: 2.4911697366343835

Epoch: 6| Step: 7
Training loss: 1.5775034218583273
Validation loss: 2.6071375621610002

Epoch: 6| Step: 8
Training loss: 2.070503888190791
Validation loss: 2.6010910233191753

Epoch: 6| Step: 9
Training loss: 2.0978785562194746
Validation loss: 2.603237296525713

Epoch: 6| Step: 10
Training loss: 1.8724700389548152
Validation loss: 2.6325690876685193

Epoch: 6| Step: 11
Training loss: 2.3093444326646466
Validation loss: 2.5960287019576143

Epoch: 6| Step: 12
Training loss: 2.3220042217127546
Validation loss: 2.5867878417589827

Epoch: 6| Step: 13
Training loss: 1.893377271173739
Validation loss: 2.6199310801567903

Epoch: 110| Step: 0
Training loss: 1.7040720415154287
Validation loss: 2.556065272439543

Epoch: 6| Step: 1
Training loss: 1.1584839761784078
Validation loss: 2.5696465152176806

Epoch: 6| Step: 2
Training loss: 1.960041342902606
Validation loss: 2.6675633522287887

Epoch: 6| Step: 3
Training loss: 2.3147157930458078
Validation loss: 2.619878116543869

Epoch: 6| Step: 4
Training loss: 1.7449746866221023
Validation loss: 2.6227744068191514

Epoch: 6| Step: 5
Training loss: 2.3659976197115484
Validation loss: 2.6661392574498723

Epoch: 6| Step: 6
Training loss: 2.620018273646568
Validation loss: 2.6653986290249865

Epoch: 6| Step: 7
Training loss: 1.6697643897322811
Validation loss: 2.6212289759190424

Epoch: 6| Step: 8
Training loss: 1.9661079723089614
Validation loss: 2.681308119113585

Epoch: 6| Step: 9
Training loss: 2.0878929088212486
Validation loss: 2.620534133106063

Epoch: 6| Step: 10
Training loss: 1.911829739970487
Validation loss: 2.55110517687316

Epoch: 6| Step: 11
Training loss: 2.0164956275141512
Validation loss: 2.638835383313374

Epoch: 6| Step: 12
Training loss: 1.2808290115578054
Validation loss: 2.6057957906756317

Epoch: 6| Step: 13
Training loss: 1.7440549139511625
Validation loss: 2.554842882943031

Epoch: 111| Step: 0
Training loss: 2.9276617345266382
Validation loss: 2.5879827672521225

Epoch: 6| Step: 1
Training loss: 2.1377370245616367
Validation loss: 2.6099687612668894

Epoch: 6| Step: 2
Training loss: 1.9236796520277195
Validation loss: 2.667596168250362

Epoch: 6| Step: 3
Training loss: 1.7406052730408108
Validation loss: 2.613020081292183

Epoch: 6| Step: 4
Training loss: 1.1742261570375163
Validation loss: 2.632791853011586

Epoch: 6| Step: 5
Training loss: 1.584902796968708
Validation loss: 2.566856232574442

Epoch: 6| Step: 6
Training loss: 2.0126152337296186
Validation loss: 2.582935984621782

Epoch: 6| Step: 7
Training loss: 1.4714383621657259
Validation loss: 2.5735599830692273

Epoch: 6| Step: 8
Training loss: 1.5010484369228074
Validation loss: 2.6048784020880347

Epoch: 6| Step: 9
Training loss: 2.0529488869764494
Validation loss: 2.635605610544047

Epoch: 6| Step: 10
Training loss: 1.8609311299891633
Validation loss: 2.6236527633883426

Epoch: 6| Step: 11
Training loss: 1.741715234629895
Validation loss: 2.5852126059178047

Epoch: 6| Step: 12
Training loss: 1.7966427860312535
Validation loss: 2.631594775302871

Epoch: 6| Step: 13
Training loss: 1.9489824232049693
Validation loss: 2.656139663199825

Epoch: 112| Step: 0
Training loss: 2.411207072032589
Validation loss: 2.6184295819409376

Epoch: 6| Step: 1
Training loss: 1.7526839655204682
Validation loss: 2.6065641328234626

Epoch: 6| Step: 2
Training loss: 1.7575032280014586
Validation loss: 2.604747392118016

Epoch: 6| Step: 3
Training loss: 1.9757614020108252
Validation loss: 2.6205597744336417

Epoch: 6| Step: 4
Training loss: 1.9880820063979272
Validation loss: 2.6174024427220703

Epoch: 6| Step: 5
Training loss: 1.7098383747927224
Validation loss: 2.5685410661335966

Epoch: 6| Step: 6
Training loss: 1.767895277033125
Validation loss: 2.579144316798812

Epoch: 6| Step: 7
Training loss: 1.8625579005720596
Validation loss: 2.6377070931702704

Epoch: 6| Step: 8
Training loss: 1.6714785096809337
Validation loss: 2.624934165371231

Epoch: 6| Step: 9
Training loss: 1.804775813860688
Validation loss: 2.549281818257789

Epoch: 6| Step: 10
Training loss: 1.8808143745022337
Validation loss: 2.616889435605543

Epoch: 6| Step: 11
Training loss: 1.8107938958040075
Validation loss: 2.612623815325094

Epoch: 6| Step: 12
Training loss: 1.887135587970953
Validation loss: 2.588958051773645

Epoch: 6| Step: 13
Training loss: 2.2730374852793043
Validation loss: 2.5916135484049945

Epoch: 113| Step: 0
Training loss: 2.181610025244222
Validation loss: 2.6910051656914664

Epoch: 6| Step: 1
Training loss: 1.315378755915912
Validation loss: 2.6465613397384096

Epoch: 6| Step: 2
Training loss: 1.487017558103848
Validation loss: 2.598949200468255

Epoch: 6| Step: 3
Training loss: 2.5017411844268427
Validation loss: 2.6445714138930985

Epoch: 6| Step: 4
Training loss: 1.694706681115015
Validation loss: 2.637739678049426

Epoch: 6| Step: 5
Training loss: 1.584684356042402
Validation loss: 2.5867955070374395

Epoch: 6| Step: 6
Training loss: 2.087073313340667
Validation loss: 2.6059367204274535

Epoch: 6| Step: 7
Training loss: 2.027209327078049
Validation loss: 2.665057223136868

Epoch: 6| Step: 8
Training loss: 1.3867071446752497
Validation loss: 2.6211814808837923

Epoch: 6| Step: 9
Training loss: 2.493848671550509
Validation loss: 2.6328884759009417

Epoch: 6| Step: 10
Training loss: 1.6346311525300676
Validation loss: 2.6233148615460227

Epoch: 6| Step: 11
Training loss: 1.9165404181434424
Validation loss: 2.6371862227865503

Epoch: 6| Step: 12
Training loss: 1.869161416379596
Validation loss: 2.663038890550346

Epoch: 6| Step: 13
Training loss: 1.8175831253373218
Validation loss: 2.610543741196441

Epoch: 114| Step: 0
Training loss: 1.839322998473189
Validation loss: 2.569830898629215

Epoch: 6| Step: 1
Training loss: 1.2734471420203892
Validation loss: 2.511460310245486

Epoch: 6| Step: 2
Training loss: 2.0523615098293013
Validation loss: 2.6633126703573997

Epoch: 6| Step: 3
Training loss: 2.800549187616297
Validation loss: 2.6590038161549865

Epoch: 6| Step: 4
Training loss: 1.6958300947428653
Validation loss: 2.5829364461480435

Epoch: 6| Step: 5
Training loss: 1.8411570273944386
Validation loss: 2.603711268978886

Epoch: 6| Step: 6
Training loss: 1.3969298179162302
Validation loss: 2.596066723328049

Epoch: 6| Step: 7
Training loss: 1.4615715405354017
Validation loss: 2.570798586379247

Epoch: 6| Step: 8
Training loss: 1.9175877085772817
Validation loss: 2.5990968385737925

Epoch: 6| Step: 9
Training loss: 1.29156284017533
Validation loss: 2.623746345521109

Epoch: 6| Step: 10
Training loss: 1.6742879976947973
Validation loss: 2.6303967902523606

Epoch: 6| Step: 11
Training loss: 2.5388840832747097
Validation loss: 2.627203047160249

Epoch: 6| Step: 12
Training loss: 2.131738525066268
Validation loss: 2.7340419457461222

Epoch: 6| Step: 13
Training loss: 2.2861935079111815
Validation loss: 2.6615788879761904

Epoch: 115| Step: 0
Training loss: 2.0047128701035564
Validation loss: 2.610847172067808

Epoch: 6| Step: 1
Training loss: 1.5565977389795007
Validation loss: 2.699962198911184

Epoch: 6| Step: 2
Training loss: 1.7183496182271598
Validation loss: 2.6987082352380085

Epoch: 6| Step: 3
Training loss: 1.6003276251100678
Validation loss: 2.621832692741206

Epoch: 6| Step: 4
Training loss: 1.9423014305867978
Validation loss: 2.6426636540344086

Epoch: 6| Step: 5
Training loss: 1.9314718915260265
Validation loss: 2.6551258850067447

Epoch: 6| Step: 6
Training loss: 1.8179403410209458
Validation loss: 2.5970966243011095

Epoch: 6| Step: 7
Training loss: 2.0677031573816147
Validation loss: 2.647947808139338

Epoch: 6| Step: 8
Training loss: 1.8754223030083041
Validation loss: 2.6300863609107585

Epoch: 6| Step: 9
Training loss: 1.5970380188507678
Validation loss: 2.6038593161727452

Epoch: 6| Step: 10
Training loss: 1.4895528332270909
Validation loss: 2.5783118440373247

Epoch: 6| Step: 11
Training loss: 1.6076717808184877
Validation loss: 2.5629922347529757

Epoch: 6| Step: 12
Training loss: 2.043120690379436
Validation loss: 2.5832140623267112

Epoch: 6| Step: 13
Training loss: 2.72075605375203
Validation loss: 2.614944316570205

Epoch: 116| Step: 0
Training loss: 1.8766895311542595
Validation loss: 2.620914261684855

Epoch: 6| Step: 1
Training loss: 2.6551683804267423
Validation loss: 2.5660941806614694

Epoch: 6| Step: 2
Training loss: 2.3143733916250024
Validation loss: 2.6213047873089756

Epoch: 6| Step: 3
Training loss: 1.7940305005375832
Validation loss: 2.623686893462065

Epoch: 6| Step: 4
Training loss: 1.5061493234505798
Validation loss: 2.672758198116652

Epoch: 6| Step: 5
Training loss: 1.6961958029964175
Validation loss: 2.6502694064976136

Epoch: 6| Step: 6
Training loss: 1.7361316891616276
Validation loss: 2.8044606066552276

Epoch: 6| Step: 7
Training loss: 2.058300829899742
Validation loss: 2.684254808736438

Epoch: 6| Step: 8
Training loss: 2.092387197136146
Validation loss: 2.6928640402975015

Epoch: 6| Step: 9
Training loss: 1.5556957100368867
Validation loss: 2.62610695220727

Epoch: 6| Step: 10
Training loss: 1.3493701595839755
Validation loss: 2.6349744212087134

Epoch: 6| Step: 11
Training loss: 1.6957576184940293
Validation loss: 2.650731513885967

Epoch: 6| Step: 12
Training loss: 1.3061141933680813
Validation loss: 2.6218422864556126

Epoch: 6| Step: 13
Training loss: 1.7934390180614246
Validation loss: 2.5654931691629645

Epoch: 117| Step: 0
Training loss: 1.8454501831474628
Validation loss: 2.608952455705663

Epoch: 6| Step: 1
Training loss: 1.83327443577342
Validation loss: 2.6304085582904473

Epoch: 6| Step: 2
Training loss: 2.123118970501378
Validation loss: 2.5818674840658438

Epoch: 6| Step: 3
Training loss: 1.5905046518660113
Validation loss: 2.601030595109379

Epoch: 6| Step: 4
Training loss: 2.2696222231255945
Validation loss: 2.6244353943601526

Epoch: 6| Step: 5
Training loss: 1.5045211525745696
Validation loss: 2.631395768139672

Epoch: 6| Step: 6
Training loss: 2.1980077956654087
Validation loss: 2.622359287243437

Epoch: 6| Step: 7
Training loss: 1.7325893523279106
Validation loss: 2.6025820119628733

Epoch: 6| Step: 8
Training loss: 2.026432369057084
Validation loss: 2.6500892402209875

Epoch: 6| Step: 9
Training loss: 1.9259881146421751
Validation loss: 2.7466786803018306

Epoch: 6| Step: 10
Training loss: 1.7002960648502194
Validation loss: 2.730401878283898

Epoch: 6| Step: 11
Training loss: 1.5211322264269658
Validation loss: 2.664769083626786

Epoch: 6| Step: 12
Training loss: 0.8965288537653711
Validation loss: 2.550541023754564

Epoch: 6| Step: 13
Training loss: 2.2504434148645194
Validation loss: 2.625269936503109

Epoch: 118| Step: 0
Training loss: 1.8422955740950806
Validation loss: 2.638956246157755

Epoch: 6| Step: 1
Training loss: 1.629599444313685
Validation loss: 2.6237535772106884

Epoch: 6| Step: 2
Training loss: 1.7642788777127911
Validation loss: 2.6029390467872413

Epoch: 6| Step: 3
Training loss: 1.5523312603198962
Validation loss: 2.5369573228950695

Epoch: 6| Step: 4
Training loss: 2.0481323573585954
Validation loss: 2.5660230330164153

Epoch: 6| Step: 5
Training loss: 1.5677811446237464
Validation loss: 2.6109488912562573

Epoch: 6| Step: 6
Training loss: 1.7453502463115547
Validation loss: 2.676549811332216

Epoch: 6| Step: 7
Training loss: 1.6021903691378656
Validation loss: 2.6229745831709415

Epoch: 6| Step: 8
Training loss: 2.1857145379793823
Validation loss: 2.583525040394125

Epoch: 6| Step: 9
Training loss: 1.5239429124567778
Validation loss: 2.6482722588137286

Epoch: 6| Step: 10
Training loss: 1.9275542912339192
Validation loss: 2.7262857436947794

Epoch: 6| Step: 11
Training loss: 2.460243345180489
Validation loss: 2.726705013656824

Epoch: 6| Step: 12
Training loss: 1.9170210413964524
Validation loss: 2.7025291065362493

Epoch: 6| Step: 13
Training loss: 1.4988098191134356
Validation loss: 2.7658636704961337

Epoch: 119| Step: 0
Training loss: 1.84653534065347
Validation loss: 2.79153465319454

Epoch: 6| Step: 1
Training loss: 2.2665923059645112
Validation loss: 2.7099265963008037

Epoch: 6| Step: 2
Training loss: 1.8456778711276616
Validation loss: 2.7369383213952903

Epoch: 6| Step: 3
Training loss: 1.2874622469061208
Validation loss: 2.6818232056247893

Epoch: 6| Step: 4
Training loss: 1.6445768445143625
Validation loss: 2.655307423022322

Epoch: 6| Step: 5
Training loss: 1.4742473233622213
Validation loss: 2.578138763699253

Epoch: 6| Step: 6
Training loss: 1.9237522788031196
Validation loss: 2.7374103374690417

Epoch: 6| Step: 7
Training loss: 1.6664466076849411
Validation loss: 2.6145036135573347

Epoch: 6| Step: 8
Training loss: 1.2518393811526016
Validation loss: 2.6375477333028208

Epoch: 6| Step: 9
Training loss: 1.6751937014045097
Validation loss: 2.617028386227979

Epoch: 6| Step: 10
Training loss: 1.8166396780663265
Validation loss: 2.6074686301012475

Epoch: 6| Step: 11
Training loss: 1.708924385107812
Validation loss: 2.6605615815853154

Epoch: 6| Step: 12
Training loss: 1.6661659521724819
Validation loss: 2.681897104125245

Epoch: 6| Step: 13
Training loss: 1.9591064415094497
Validation loss: 2.6245102349802005

Epoch: 120| Step: 0
Training loss: 2.373597082080854
Validation loss: 2.599599852091913

Epoch: 6| Step: 1
Training loss: 2.214726951250969
Validation loss: 2.698317499222301

Epoch: 6| Step: 2
Training loss: 1.6494944289183624
Validation loss: 2.6575361242318207

Epoch: 6| Step: 3
Training loss: 1.5412320564011335
Validation loss: 2.6021658853508414

Epoch: 6| Step: 4
Training loss: 1.8017629070261647
Validation loss: 2.6318636579593013

Epoch: 6| Step: 5
Training loss: 1.7300143710956242
Validation loss: 2.7517477463811515

Epoch: 6| Step: 6
Training loss: 2.076369612599703
Validation loss: 2.6044139490342144

Epoch: 6| Step: 7
Training loss: 1.3711739106397096
Validation loss: 2.699169521002474

Epoch: 6| Step: 8
Training loss: 1.5289274234699315
Validation loss: 2.6920406588586774

Epoch: 6| Step: 9
Training loss: 1.3672186275753375
Validation loss: 2.6064346406636467

Epoch: 6| Step: 10
Training loss: 1.2325837381170668
Validation loss: 2.568540192054261

Epoch: 6| Step: 11
Training loss: 2.337006595372111
Validation loss: 2.643417672386839

Epoch: 6| Step: 12
Training loss: 1.536142900922451
Validation loss: 2.6612120412995526

Epoch: 6| Step: 13
Training loss: 1.3834504202426159
Validation loss: 2.687036932743132

Epoch: 121| Step: 0
Training loss: 1.6941142967875085
Validation loss: 2.592470244013414

Epoch: 6| Step: 1
Training loss: 1.5063654621871034
Validation loss: 2.6199079049161065

Epoch: 6| Step: 2
Training loss: 1.938509893250919
Validation loss: 2.608228054501667

Epoch: 6| Step: 3
Training loss: 2.775490787854349
Validation loss: 2.620783143606578

Epoch: 6| Step: 4
Training loss: 1.4754377653000759
Validation loss: 2.6290814141559276

Epoch: 6| Step: 5
Training loss: 1.8497110759807092
Validation loss: 2.6309514774172187

Epoch: 6| Step: 6
Training loss: 1.6027063518382831
Validation loss: 2.6102440123659716

Epoch: 6| Step: 7
Training loss: 1.5401181700810236
Validation loss: 2.5996305377422666

Epoch: 6| Step: 8
Training loss: 1.742339260180031
Validation loss: 2.6297788338563532

Epoch: 6| Step: 9
Training loss: 1.7290332773380783
Validation loss: 2.597068004880147

Epoch: 6| Step: 10
Training loss: 2.0279885738434644
Validation loss: 2.642544998295884

Epoch: 6| Step: 11
Training loss: 1.4530338545896369
Validation loss: 2.6277860434238405

Epoch: 6| Step: 12
Training loss: 1.4977720722271557
Validation loss: 2.5990336731493935

Epoch: 6| Step: 13
Training loss: 1.5222907812376028
Validation loss: 2.605730141830084

Epoch: 122| Step: 0
Training loss: 1.6630158334002394
Validation loss: 2.6017958008533597

Epoch: 6| Step: 1
Training loss: 2.7623394777083794
Validation loss: 2.598535894540785

Epoch: 6| Step: 2
Training loss: 1.713049364727071
Validation loss: 2.549067203226973

Epoch: 6| Step: 3
Training loss: 1.784758475496596
Validation loss: 2.634712657956911

Epoch: 6| Step: 4
Training loss: 1.5073943670154673
Validation loss: 2.6328665541958762

Epoch: 6| Step: 5
Training loss: 2.153752303960789
Validation loss: 2.624969573071658

Epoch: 6| Step: 6
Training loss: 1.2363191095056607
Validation loss: 2.6696849718825746

Epoch: 6| Step: 7
Training loss: 1.4357254021111885
Validation loss: 2.5755972367163196

Epoch: 6| Step: 8
Training loss: 1.146430409085779
Validation loss: 2.6432704277137984

Epoch: 6| Step: 9
Training loss: 2.0493435715862423
Validation loss: 2.6215397416965303

Epoch: 6| Step: 10
Training loss: 1.3739028368026487
Validation loss: 2.724415280665008

Epoch: 6| Step: 11
Training loss: 1.8679553890986909
Validation loss: 2.697007903783728

Epoch: 6| Step: 12
Training loss: 1.696481820038047
Validation loss: 2.731771439417992

Epoch: 6| Step: 13
Training loss: 1.6281464998139963
Validation loss: 2.7206875996216295

Epoch: 123| Step: 0
Training loss: 1.8922006015969766
Validation loss: 2.691205803909424

Epoch: 6| Step: 1
Training loss: 1.3370040294840428
Validation loss: 2.6974129347705027

Epoch: 6| Step: 2
Training loss: 1.500161400694657
Validation loss: 2.7362568365191424

Epoch: 6| Step: 3
Training loss: 1.7000183328874192
Validation loss: 2.612603982197608

Epoch: 6| Step: 4
Training loss: 1.6967868283233118
Validation loss: 2.6780568936567106

Epoch: 6| Step: 5
Training loss: 1.5725148258207766
Validation loss: 2.651331128179055

Epoch: 6| Step: 6
Training loss: 1.7285034179256458
Validation loss: 2.6210628229127346

Epoch: 6| Step: 7
Training loss: 1.5880288302064973
Validation loss: 2.5850399953034224

Epoch: 6| Step: 8
Training loss: 1.5900848730695016
Validation loss: 2.677944302184574

Epoch: 6| Step: 9
Training loss: 1.9908781648199827
Validation loss: 2.640479104490358

Epoch: 6| Step: 10
Training loss: 1.2019798476676797
Validation loss: 2.6350715220213297

Epoch: 6| Step: 11
Training loss: 1.1928893816713673
Validation loss: 2.54722165359977

Epoch: 6| Step: 12
Training loss: 1.8836442052221714
Validation loss: 2.656164736407766

Epoch: 6| Step: 13
Training loss: 2.6229474353475313
Validation loss: 2.6560187594419604

Epoch: 124| Step: 0
Training loss: 1.4702290331897883
Validation loss: 2.664374749910476

Epoch: 6| Step: 1
Training loss: 2.2228344140272434
Validation loss: 2.6203756016575577

Epoch: 6| Step: 2
Training loss: 1.6617700967894868
Validation loss: 2.6194061440555316

Epoch: 6| Step: 3
Training loss: 1.6988129229818212
Validation loss: 2.7055194370810236

Epoch: 6| Step: 4
Training loss: 1.8408682981353424
Validation loss: 2.644441108162785

Epoch: 6| Step: 5
Training loss: 1.2295102700622462
Validation loss: 2.6563949694997087

Epoch: 6| Step: 6
Training loss: 0.9534054953155686
Validation loss: 2.6347148976156864

Epoch: 6| Step: 7
Training loss: 1.9267841691130023
Validation loss: 2.6468572862941406

Epoch: 6| Step: 8
Training loss: 1.4578428079249175
Validation loss: 2.6561329161326914

Epoch: 6| Step: 9
Training loss: 1.6268156618661105
Validation loss: 2.6497849569099015

Epoch: 6| Step: 10
Training loss: 1.644660201646159
Validation loss: 2.6638322359658937

Epoch: 6| Step: 11
Training loss: 2.0580813151941233
Validation loss: 2.6397199415240564

Epoch: 6| Step: 12
Training loss: 1.7870294605168453
Validation loss: 2.727167508715828

Epoch: 6| Step: 13
Training loss: 2.174196388603905
Validation loss: 2.612208170311025

Epoch: 125| Step: 0
Training loss: 1.7730272801726916
Validation loss: 2.6736141887388367

Epoch: 6| Step: 1
Training loss: 1.9608978632230378
Validation loss: 2.6299029988240004

Epoch: 6| Step: 2
Training loss: 1.6150601903133397
Validation loss: 2.756027378771231

Epoch: 6| Step: 3
Training loss: 2.6095290452634803
Validation loss: 2.6858068795774916

Epoch: 6| Step: 4
Training loss: 1.2126235053487056
Validation loss: 2.6370541206228966

Epoch: 6| Step: 5
Training loss: 1.632963547724324
Validation loss: 2.6212717101035303

Epoch: 6| Step: 6
Training loss: 1.632043830965525
Validation loss: 2.659910335368031

Epoch: 6| Step: 7
Training loss: 1.001458058736462
Validation loss: 2.628861954548719

Epoch: 6| Step: 8
Training loss: 1.496879192179183
Validation loss: 2.6445265619188505

Epoch: 6| Step: 9
Training loss: 1.4340030595169522
Validation loss: 2.5890070127881137

Epoch: 6| Step: 10
Training loss: 1.4025520871259791
Validation loss: 2.531298664394439

Epoch: 6| Step: 11
Training loss: 1.304355601964799
Validation loss: 2.6886507276495637

Epoch: 6| Step: 12
Training loss: 2.340267289537824
Validation loss: 2.674893590706152

Epoch: 6| Step: 13
Training loss: 1.5795452412317605
Validation loss: 2.6773517538395737

Epoch: 126| Step: 0
Training loss: 1.6166970803982008
Validation loss: 2.6980708506551547

Epoch: 6| Step: 1
Training loss: 1.2112645845745695
Validation loss: 2.656962175825791

Epoch: 6| Step: 2
Training loss: 1.2852304547346145
Validation loss: 2.6660090370702334

Epoch: 6| Step: 3
Training loss: 1.7907528284059326
Validation loss: 2.614416524928321

Epoch: 6| Step: 4
Training loss: 1.5885547408102692
Validation loss: 2.6644449789134024

Epoch: 6| Step: 5
Training loss: 1.3421263533176202
Validation loss: 2.607456301344009

Epoch: 6| Step: 6
Training loss: 1.3534763875451064
Validation loss: 2.6849956376734694

Epoch: 6| Step: 7
Training loss: 2.666677226601991
Validation loss: 2.6223384443037454

Epoch: 6| Step: 8
Training loss: 1.8110217939610513
Validation loss: 2.739174226062426

Epoch: 6| Step: 9
Training loss: 1.5968084720855058
Validation loss: 2.6213380535824764

Epoch: 6| Step: 10
Training loss: 1.182917940184546
Validation loss: 2.7230483237564433

Epoch: 6| Step: 11
Training loss: 1.7405072650094804
Validation loss: 2.761022837078682

Epoch: 6| Step: 12
Training loss: 1.499687798117091
Validation loss: 2.83968656822915

Epoch: 6| Step: 13
Training loss: 2.053237693631766
Validation loss: 2.8201598516208715

Epoch: 127| Step: 0
Training loss: 1.4713322280553536
Validation loss: 2.783965738675799

Epoch: 6| Step: 1
Training loss: 1.1942829360492853
Validation loss: 2.802282082884422

Epoch: 6| Step: 2
Training loss: 1.4327008951665334
Validation loss: 2.7580840757831777

Epoch: 6| Step: 3
Training loss: 1.8892708965547655
Validation loss: 2.6330730788475734

Epoch: 6| Step: 4
Training loss: 1.0865143266234494
Validation loss: 2.7132911395635855

Epoch: 6| Step: 5
Training loss: 1.3779549059057252
Validation loss: 2.545907989589388

Epoch: 6| Step: 6
Training loss: 1.6365949269801279
Validation loss: 2.6233203449032754

Epoch: 6| Step: 7
Training loss: 2.155429628742365
Validation loss: 2.6085556936901173

Epoch: 6| Step: 8
Training loss: 2.4396422338067087
Validation loss: 2.5931945190648515

Epoch: 6| Step: 9
Training loss: 1.8288488666668892
Validation loss: 2.7077347362906266

Epoch: 6| Step: 10
Training loss: 1.3382632885121195
Validation loss: 2.6915143659825875

Epoch: 6| Step: 11
Training loss: 1.2204526110133773
Validation loss: 2.6287328125347504

Epoch: 6| Step: 12
Training loss: 1.5012019428117613
Validation loss: 2.622135794714037

Epoch: 6| Step: 13
Training loss: 1.3839887368620405
Validation loss: 2.630892127762302

Epoch: 128| Step: 0
Training loss: 1.543497733690027
Validation loss: 2.661988817014737

Epoch: 6| Step: 1
Training loss: 1.5774333684666064
Validation loss: 2.6645600571161308

Epoch: 6| Step: 2
Training loss: 1.616630273914045
Validation loss: 2.66340978238987

Epoch: 6| Step: 3
Training loss: 1.125514707441251
Validation loss: 2.66858704283102

Epoch: 6| Step: 4
Training loss: 1.5756962281847429
Validation loss: 2.638768553639234

Epoch: 6| Step: 5
Training loss: 1.721388992980677
Validation loss: 2.664936850696022

Epoch: 6| Step: 6
Training loss: 1.7110504391814327
Validation loss: 2.697339579208064

Epoch: 6| Step: 7
Training loss: 1.3082596537421374
Validation loss: 2.7286699634137226

Epoch: 6| Step: 8
Training loss: 1.7227585950279145
Validation loss: 2.6939661542606697

Epoch: 6| Step: 9
Training loss: 1.584259047017836
Validation loss: 2.786174015739296

Epoch: 6| Step: 10
Training loss: 2.128481649350615
Validation loss: 2.694015102219536

Epoch: 6| Step: 11
Training loss: 1.5522656770990604
Validation loss: 2.7240253146064743

Epoch: 6| Step: 12
Training loss: 1.5060882196563299
Validation loss: 2.739744048728853

Epoch: 6| Step: 13
Training loss: 1.5530638531136267
Validation loss: 2.746363677663025

Epoch: 129| Step: 0
Training loss: 1.5646527528494978
Validation loss: 2.6627753794404376

Epoch: 6| Step: 1
Training loss: 1.7811374963400581
Validation loss: 2.6862442720191493

Epoch: 6| Step: 2
Training loss: 1.224401672368744
Validation loss: 2.6788223842347327

Epoch: 6| Step: 3
Training loss: 1.7969394838123756
Validation loss: 2.649102096666688

Epoch: 6| Step: 4
Training loss: 1.7527738114016729
Validation loss: 2.6415511995545655

Epoch: 6| Step: 5
Training loss: 1.4606460851829501
Validation loss: 2.6408302934588384

Epoch: 6| Step: 6
Training loss: 1.783668081411448
Validation loss: 2.7542218976583444

Epoch: 6| Step: 7
Training loss: 1.7453811181222165
Validation loss: 2.670364518065361

Epoch: 6| Step: 8
Training loss: 2.3306575032446144
Validation loss: 2.7004231527547153

Epoch: 6| Step: 9
Training loss: 1.4058055599222639
Validation loss: 2.6145361608578703

Epoch: 6| Step: 10
Training loss: 1.0802742364411821
Validation loss: 2.708189613245853

Epoch: 6| Step: 11
Training loss: 1.1072405308387239
Validation loss: 2.7704696105826034

Epoch: 6| Step: 12
Training loss: 1.655341997105242
Validation loss: 2.7548254476545115

Epoch: 6| Step: 13
Training loss: 1.58395201324255
Validation loss: 2.8695234853028597

Epoch: 130| Step: 0
Training loss: 2.1623315602230546
Validation loss: 2.81662945826255

Epoch: 6| Step: 1
Training loss: 1.4498685218132863
Validation loss: 2.6737770463937762

Epoch: 6| Step: 2
Training loss: 2.591595409758881
Validation loss: 2.6240981611547056

Epoch: 6| Step: 3
Training loss: 1.2602546629816598
Validation loss: 2.6537931262246652

Epoch: 6| Step: 4
Training loss: 1.8039003447266242
Validation loss: 2.7458099464574413

Epoch: 6| Step: 5
Training loss: 1.414611878292005
Validation loss: 2.6521770966150027

Epoch: 6| Step: 6
Training loss: 1.3875511142835246
Validation loss: 2.6045722848986093

Epoch: 6| Step: 7
Training loss: 1.325334287256119
Validation loss: 2.671496938984635

Epoch: 6| Step: 8
Training loss: 1.3950717423562133
Validation loss: 2.7724419898066137

Epoch: 6| Step: 9
Training loss: 1.6044967939202743
Validation loss: 2.748784504654071

Epoch: 6| Step: 10
Training loss: 1.2519328432627355
Validation loss: 2.7270045026940872

Epoch: 6| Step: 11
Training loss: 1.4112908192383204
Validation loss: 2.7668359982326987

Epoch: 6| Step: 12
Training loss: 1.656301893464936
Validation loss: 2.7477107489774806

Epoch: 6| Step: 13
Training loss: 1.6126095017505349
Validation loss: 2.659913950606245

Epoch: 131| Step: 0
Training loss: 1.339353154618854
Validation loss: 2.593033580576808

Epoch: 6| Step: 1
Training loss: 1.6099260738531116
Validation loss: 2.6539209215149624

Epoch: 6| Step: 2
Training loss: 1.038527271983418
Validation loss: 2.575334290838627

Epoch: 6| Step: 3
Training loss: 1.1006356526801053
Validation loss: 2.7385222890774594

Epoch: 6| Step: 4
Training loss: 1.2183398999525568
Validation loss: 2.6955010831898285

Epoch: 6| Step: 5
Training loss: 1.1289183936076421
Validation loss: 2.735545200447435

Epoch: 6| Step: 6
Training loss: 1.6478140858946964
Validation loss: 2.6438359107569855

Epoch: 6| Step: 7
Training loss: 1.3399870770813407
Validation loss: 2.6849412047841166

Epoch: 6| Step: 8
Training loss: 1.4173888815194926
Validation loss: 2.7496297905004106

Epoch: 6| Step: 9
Training loss: 1.9098155960221201
Validation loss: 2.6832786497226664

Epoch: 6| Step: 10
Training loss: 2.517133746055665
Validation loss: 2.7717166128569133

Epoch: 6| Step: 11
Training loss: 1.9366329468020103
Validation loss: 2.771814421200003

Epoch: 6| Step: 12
Training loss: 1.8842987905499147
Validation loss: 2.8706824460030758

Epoch: 6| Step: 13
Training loss: 1.5628991952216362
Validation loss: 2.6993208708079344

Epoch: 132| Step: 0
Training loss: 1.2518840419616057
Validation loss: 2.678456920113795

Epoch: 6| Step: 1
Training loss: 1.5197868230305445
Validation loss: 2.685840892996127

Epoch: 6| Step: 2
Training loss: 1.3607164538465977
Validation loss: 2.606896348205968

Epoch: 6| Step: 3
Training loss: 1.7931910690735324
Validation loss: 2.7000283675410763

Epoch: 6| Step: 4
Training loss: 1.1799933434961363
Validation loss: 2.713965843469262

Epoch: 6| Step: 5
Training loss: 1.951114932461769
Validation loss: 2.668150657756219

Epoch: 6| Step: 6
Training loss: 1.3843815409417553
Validation loss: 2.66534573402815

Epoch: 6| Step: 7
Training loss: 1.0368194462182876
Validation loss: 2.6474423559707714

Epoch: 6| Step: 8
Training loss: 0.8331576678774548
Validation loss: 2.6406194773358562

Epoch: 6| Step: 9
Training loss: 1.597312162695766
Validation loss: 2.704275323793955

Epoch: 6| Step: 10
Training loss: 2.2646648608718842
Validation loss: 2.7249919809579244

Epoch: 6| Step: 11
Training loss: 1.9689206246204818
Validation loss: 2.7305728890675267

Epoch: 6| Step: 12
Training loss: 1.8822639267662473
Validation loss: 2.82058314383588

Epoch: 6| Step: 13
Training loss: 1.182950994126297
Validation loss: 2.7752938232434876

Epoch: 133| Step: 0
Training loss: 1.3578534435073617
Validation loss: 2.688434187110232

Epoch: 6| Step: 1
Training loss: 0.5590749415318762
Validation loss: 2.7385214474873454

Epoch: 6| Step: 2
Training loss: 1.7690443164758185
Validation loss: 2.786690338078336

Epoch: 6| Step: 3
Training loss: 1.2765477117758128
Validation loss: 2.6616105983547964

Epoch: 6| Step: 4
Training loss: 1.4962620254581498
Validation loss: 2.6031248195689347

Epoch: 6| Step: 5
Training loss: 1.5810439054652818
Validation loss: 2.6294863374031987

Epoch: 6| Step: 6
Training loss: 1.4573589702967638
Validation loss: 2.6513960076270884

Epoch: 6| Step: 7
Training loss: 1.7608857818292927
Validation loss: 2.7078014487282975

Epoch: 6| Step: 8
Training loss: 1.4391228181704327
Validation loss: 2.7369184889571923

Epoch: 6| Step: 9
Training loss: 1.82059578062497
Validation loss: 2.799544894607517

Epoch: 6| Step: 10
Training loss: 1.3389173591501022
Validation loss: 2.6855540956342323

Epoch: 6| Step: 11
Training loss: 2.2621954907938693
Validation loss: 2.717276557572873

Epoch: 6| Step: 12
Training loss: 1.5909304642170496
Validation loss: 2.7247346655547173

Epoch: 6| Step: 13
Training loss: 1.135819436592588
Validation loss: 2.8503719823247753

Epoch: 134| Step: 0
Training loss: 1.8053747412629824
Validation loss: 2.9578907707217477

Epoch: 6| Step: 1
Training loss: 1.0209538265402232
Validation loss: 2.823306043921602

Epoch: 6| Step: 2
Training loss: 1.2257294468238977
Validation loss: 2.8080372336374357

Epoch: 6| Step: 3
Training loss: 1.582887770886157
Validation loss: 2.825069807534827

Epoch: 6| Step: 4
Training loss: 1.3955753382155027
Validation loss: 2.766491985743097

Epoch: 6| Step: 5
Training loss: 1.567951306073557
Validation loss: 2.6822990244545375

Epoch: 6| Step: 6
Training loss: 1.0377853690497594
Validation loss: 2.7761611173217453

Epoch: 6| Step: 7
Training loss: 1.498212384924713
Validation loss: 2.7078741613588475

Epoch: 6| Step: 8
Training loss: 2.2232314506914266
Validation loss: 2.6502317579159946

Epoch: 6| Step: 9
Training loss: 1.6126687131639805
Validation loss: 2.817167520478671

Epoch: 6| Step: 10
Training loss: 1.4223466866307963
Validation loss: 2.7538775214822824

Epoch: 6| Step: 11
Training loss: 1.5982337411608127
Validation loss: 2.720585484824233

Epoch: 6| Step: 12
Training loss: 1.3982549793325942
Validation loss: 2.6360638518653423

Epoch: 6| Step: 13
Training loss: 1.4581722261357224
Validation loss: 2.7730868982060835

Epoch: 135| Step: 0
Training loss: 1.0720127273024673
Validation loss: 2.676728189168309

Epoch: 6| Step: 1
Training loss: 1.2752434965505155
Validation loss: 2.7350358945431026

Epoch: 6| Step: 2
Training loss: 1.2937106398340206
Validation loss: 2.672355630934429

Epoch: 6| Step: 3
Training loss: 1.5342331457506775
Validation loss: 2.725356380828344

Epoch: 6| Step: 4
Training loss: 1.4570625035919973
Validation loss: 2.6517575889246965

Epoch: 6| Step: 5
Training loss: 1.20459721643784
Validation loss: 2.6510340322648136

Epoch: 6| Step: 6
Training loss: 1.6997714842751313
Validation loss: 2.6640278952878376

Epoch: 6| Step: 7
Training loss: 1.4179204927329876
Validation loss: 2.7007661792002495

Epoch: 6| Step: 8
Training loss: 2.321426689231026
Validation loss: 2.705033336135488

Epoch: 6| Step: 9
Training loss: 1.287662369943024
Validation loss: 2.8045536246620317

Epoch: 6| Step: 10
Training loss: 1.7116428819815868
Validation loss: 2.658053754337116

Epoch: 6| Step: 11
Training loss: 1.1749827566301967
Validation loss: 2.6636879845090244

Epoch: 6| Step: 12
Training loss: 1.9066942041360322
Validation loss: 2.698693231194945

Epoch: 6| Step: 13
Training loss: 1.3196866510285978
Validation loss: 2.6612012904511277

Epoch: 136| Step: 0
Training loss: 1.2040411198428398
Validation loss: 2.679413331949012

Epoch: 6| Step: 1
Training loss: 1.5064230728436656
Validation loss: 2.7228551834819714

Epoch: 6| Step: 2
Training loss: 1.4168693547079585
Validation loss: 2.6760565326100063

Epoch: 6| Step: 3
Training loss: 2.035816985960056
Validation loss: 2.6652423859826735

Epoch: 6| Step: 4
Training loss: 0.9415651559269995
Validation loss: 2.72110665152455

Epoch: 6| Step: 5
Training loss: 1.4109488502628884
Validation loss: 2.8198924927476043

Epoch: 6| Step: 6
Training loss: 1.0864780096294289
Validation loss: 2.821803550336683

Epoch: 6| Step: 7
Training loss: 2.2061403890294873
Validation loss: 2.7981650078703617

Epoch: 6| Step: 8
Training loss: 1.4251018420853092
Validation loss: 2.894989224547261

Epoch: 6| Step: 9
Training loss: 1.4524304770871082
Validation loss: 2.773011159588488

Epoch: 6| Step: 10
Training loss: 1.4331974656374618
Validation loss: 2.6838089339796696

Epoch: 6| Step: 11
Training loss: 1.1680265176323412
Validation loss: 2.8092589317959

Epoch: 6| Step: 12
Training loss: 1.796667203083324
Validation loss: 2.755909436927177

Epoch: 6| Step: 13
Training loss: 1.6750722954933601
Validation loss: 2.701339440654555

Epoch: 137| Step: 0
Training loss: 1.383434134376487
Validation loss: 2.728399494078147

Epoch: 6| Step: 1
Training loss: 1.2468386728449212
Validation loss: 2.697681613143353

Epoch: 6| Step: 2
Training loss: 1.491264017555628
Validation loss: 2.7347972144267767

Epoch: 6| Step: 3
Training loss: 1.1447973365168906
Validation loss: 2.7859746257642444

Epoch: 6| Step: 4
Training loss: 1.5482677778581246
Validation loss: 2.697209244603126

Epoch: 6| Step: 5
Training loss: 1.4950905566394599
Validation loss: 2.7126965930558598

Epoch: 6| Step: 6
Training loss: 1.7397395157134272
Validation loss: 2.836445996643726

Epoch: 6| Step: 7
Training loss: 1.1312274235111228
Validation loss: 2.8705285863329473

Epoch: 6| Step: 8
Training loss: 1.113482219559224
Validation loss: 2.8155998525226833

Epoch: 6| Step: 9
Training loss: 1.4739200420820153
Validation loss: 2.811356389695731

Epoch: 6| Step: 10
Training loss: 1.7546318609260203
Validation loss: 2.75335513252545

Epoch: 6| Step: 11
Training loss: 1.4800701158256016
Validation loss: 2.7488619877240694

Epoch: 6| Step: 12
Training loss: 2.3118960648706515
Validation loss: 2.6803610263882374

Epoch: 6| Step: 13
Training loss: 1.6795180124337326
Validation loss: 2.636039725573041

Epoch: 138| Step: 0
Training loss: 1.3845861235200265
Validation loss: 2.6987582014865357

Epoch: 6| Step: 1
Training loss: 1.5089205292642995
Validation loss: 2.7803660856227324

Epoch: 6| Step: 2
Training loss: 1.270088707236336
Validation loss: 2.6489987749159543

Epoch: 6| Step: 3
Training loss: 1.9994712369032392
Validation loss: 2.7417555466094323

Epoch: 6| Step: 4
Training loss: 1.4134541251338977
Validation loss: 2.7038483432821154

Epoch: 6| Step: 5
Training loss: 1.040798028530919
Validation loss: 2.688859758228036

Epoch: 6| Step: 6
Training loss: 2.061346598548367
Validation loss: 2.7665342427546467

Epoch: 6| Step: 7
Training loss: 1.4537986916467287
Validation loss: 2.8596990155075126

Epoch: 6| Step: 8
Training loss: 1.5126697003712557
Validation loss: 2.937856219722166

Epoch: 6| Step: 9
Training loss: 1.6193126039545829
Validation loss: 2.9900884478488705

Epoch: 6| Step: 10
Training loss: 1.3494269196635869
Validation loss: 2.925155932734105

Epoch: 6| Step: 11
Training loss: 1.6692029331182419
Validation loss: 2.851677377555466

Epoch: 6| Step: 12
Training loss: 1.6741800550296062
Validation loss: 2.7021973916488107

Epoch: 6| Step: 13
Training loss: 1.3907360932626707
Validation loss: 2.6576509259520646

Epoch: 139| Step: 0
Training loss: 1.5833994282763721
Validation loss: 2.730486329931187

Epoch: 6| Step: 1
Training loss: 1.663687578688322
Validation loss: 2.717564949375469

Epoch: 6| Step: 2
Training loss: 1.2631999200179478
Validation loss: 2.746320068525815

Epoch: 6| Step: 3
Training loss: 1.555102958950436
Validation loss: 2.67403305379277

Epoch: 6| Step: 4
Training loss: 1.8113304837433424
Validation loss: 2.698695233702081

Epoch: 6| Step: 5
Training loss: 1.6225150254880756
Validation loss: 2.726690527998863

Epoch: 6| Step: 6
Training loss: 2.065583438426314
Validation loss: 2.6965439641532583

Epoch: 6| Step: 7
Training loss: 1.33143835212821
Validation loss: 2.7788263111558487

Epoch: 6| Step: 8
Training loss: 1.1984588501780393
Validation loss: 2.753421937457424

Epoch: 6| Step: 9
Training loss: 1.4543218298530032
Validation loss: 2.8191359893576067

Epoch: 6| Step: 10
Training loss: 1.7081127799720965
Validation loss: 2.8381911081717037

Epoch: 6| Step: 11
Training loss: 1.4206723167638844
Validation loss: 2.833734236197873

Epoch: 6| Step: 12
Training loss: 1.3115399800590193
Validation loss: 2.734464749271146

Epoch: 6| Step: 13
Training loss: 1.9273443784121265
Validation loss: 2.7102882128063897

Epoch: 140| Step: 0
Training loss: 1.1650280116565164
Validation loss: 2.6613923056537336

Epoch: 6| Step: 1
Training loss: 1.057549218189022
Validation loss: 2.666284821907827

Epoch: 6| Step: 2
Training loss: 1.4752455393845456
Validation loss: 2.724926403930007

Epoch: 6| Step: 3
Training loss: 1.535591044502745
Validation loss: 2.7155921105843026

Epoch: 6| Step: 4
Training loss: 1.6220901552349687
Validation loss: 2.7373227461238363

Epoch: 6| Step: 5
Training loss: 1.3194612546597257
Validation loss: 2.710077741242168

Epoch: 6| Step: 6
Training loss: 1.1397054440607897
Validation loss: 2.759350500001646

Epoch: 6| Step: 7
Training loss: 2.0975728222614682
Validation loss: 2.7632225219479474

Epoch: 6| Step: 8
Training loss: 1.122945817464031
Validation loss: 2.733565045242653

Epoch: 6| Step: 9
Training loss: 1.4041199552801455
Validation loss: 2.809707328877178

Epoch: 6| Step: 10
Training loss: 1.8334663155038546
Validation loss: 2.904331558523253

Epoch: 6| Step: 11
Training loss: 1.8905310489230636
Validation loss: 2.860285115579956

Epoch: 6| Step: 12
Training loss: 2.0437034904950786
Validation loss: 2.9922261181655805

Epoch: 6| Step: 13
Training loss: 1.2339093259454486
Validation loss: 2.816827327239379

Epoch: 141| Step: 0
Training loss: 1.0697874465953245
Validation loss: 2.7288209875813036

Epoch: 6| Step: 1
Training loss: 1.0978449323311792
Validation loss: 2.7769318251455406

Epoch: 6| Step: 2
Training loss: 1.4564835488005472
Validation loss: 2.671342807883716

Epoch: 6| Step: 3
Training loss: 1.2085833893660436
Validation loss: 2.694485317217355

Epoch: 6| Step: 4
Training loss: 1.6292857361556576
Validation loss: 2.7012570051237446

Epoch: 6| Step: 5
Training loss: 1.813605201772458
Validation loss: 2.649699792711576

Epoch: 6| Step: 6
Training loss: 0.8715386729849116
Validation loss: 2.7315937829743877

Epoch: 6| Step: 7
Training loss: 1.4418301256304562
Validation loss: 2.7217794764356187

Epoch: 6| Step: 8
Training loss: 1.2580977880469528
Validation loss: 2.6876355661902145

Epoch: 6| Step: 9
Training loss: 1.2423928049156747
Validation loss: 2.781084862996378

Epoch: 6| Step: 10
Training loss: 1.8689453278082218
Validation loss: 2.7508927976769493

Epoch: 6| Step: 11
Training loss: 2.1033648735297286
Validation loss: 2.711220366481782

Epoch: 6| Step: 12
Training loss: 1.4049645376651176
Validation loss: 2.7789974163016415

Epoch: 6| Step: 13
Training loss: 1.0105322873272156
Validation loss: 2.7427142761220176

Epoch: 142| Step: 0
Training loss: 1.6385833388952937
Validation loss: 2.7764246224979057

Epoch: 6| Step: 1
Training loss: 1.3710183669013998
Validation loss: 2.7517793851886725

Epoch: 6| Step: 2
Training loss: 1.3259792272226594
Validation loss: 2.7403244978933934

Epoch: 6| Step: 3
Training loss: 1.3228246051064136
Validation loss: 2.709476484006239

Epoch: 6| Step: 4
Training loss: 1.4836536461670116
Validation loss: 2.6437072521989236

Epoch: 6| Step: 5
Training loss: 1.5464831539880568
Validation loss: 2.7969931323572124

Epoch: 6| Step: 6
Training loss: 1.5760145522476892
Validation loss: 2.7413882026212386

Epoch: 6| Step: 7
Training loss: 1.0340640081704175
Validation loss: 2.545335362790103

Epoch: 6| Step: 8
Training loss: 1.373260611642602
Validation loss: 2.7059657434323734

Epoch: 6| Step: 9
Training loss: 1.576240018106629
Validation loss: 2.7541880361985114

Epoch: 6| Step: 10
Training loss: 1.1812077005068817
Validation loss: 2.7301559596524663

Epoch: 6| Step: 11
Training loss: 1.4370413338723311
Validation loss: 2.7213786341587847

Epoch: 6| Step: 12
Training loss: 1.5147863997905304
Validation loss: 2.729827456279114

Epoch: 6| Step: 13
Training loss: 1.9572002162821744
Validation loss: 2.7518231244106843

Epoch: 143| Step: 0
Training loss: 1.7824066823578975
Validation loss: 2.790363083324424

Epoch: 6| Step: 1
Training loss: 0.9957578204798665
Validation loss: 2.7009816722236284

Epoch: 6| Step: 2
Training loss: 1.487427233671254
Validation loss: 2.7443253460635075

Epoch: 6| Step: 3
Training loss: 2.0272814202695724
Validation loss: 2.8179745551305895

Epoch: 6| Step: 4
Training loss: 1.4549479381515076
Validation loss: 2.6759996905115213

Epoch: 6| Step: 5
Training loss: 0.7765742187843855
Validation loss: 2.7336320576214512

Epoch: 6| Step: 6
Training loss: 1.5053106710982345
Validation loss: 2.738577035409758

Epoch: 6| Step: 7
Training loss: 1.2109925288340833
Validation loss: 2.664408969816213

Epoch: 6| Step: 8
Training loss: 1.6243435193864562
Validation loss: 2.6759236615748385

Epoch: 6| Step: 9
Training loss: 1.3507655445639801
Validation loss: 2.6455109817900837

Epoch: 6| Step: 10
Training loss: 1.2611465337561303
Validation loss: 2.6654385381121988

Epoch: 6| Step: 11
Training loss: 1.4483903434838166
Validation loss: 2.736970029767892

Epoch: 6| Step: 12
Training loss: 1.4186451877411672
Validation loss: 2.6939922840410997

Epoch: 6| Step: 13
Training loss: 1.1527137291719523
Validation loss: 2.734450740673483

Epoch: 144| Step: 0
Training loss: 1.5528415475002806
Validation loss: 2.841296902051402

Epoch: 6| Step: 1
Training loss: 1.7463817657586476
Validation loss: 2.6862115062986853

Epoch: 6| Step: 2
Training loss: 1.4693681755215728
Validation loss: 2.675957822890681

Epoch: 6| Step: 3
Training loss: 1.4303083895556925
Validation loss: 2.8198724123316685

Epoch: 6| Step: 4
Training loss: 0.8729457583317768
Validation loss: 2.800750959260052

Epoch: 6| Step: 5
Training loss: 1.2519410321727296
Validation loss: 2.8097172145030997

Epoch: 6| Step: 6
Training loss: 1.2934814082174648
Validation loss: 2.798336279547365

Epoch: 6| Step: 7
Training loss: 1.9160334190607855
Validation loss: 2.7979139106909234

Epoch: 6| Step: 8
Training loss: 1.2509681766893015
Validation loss: 2.766854151344265

Epoch: 6| Step: 9
Training loss: 0.7174283190552788
Validation loss: 2.6644316386771565

Epoch: 6| Step: 10
Training loss: 0.9040475588162852
Validation loss: 2.7555544707294435

Epoch: 6| Step: 11
Training loss: 1.3006398350365902
Validation loss: 2.7254315993994354

Epoch: 6| Step: 12
Training loss: 1.4494533297554497
Validation loss: 2.6882788838002245

Epoch: 6| Step: 13
Training loss: 1.3839078541272933
Validation loss: 2.665765138067657

Epoch: 145| Step: 0
Training loss: 1.3896235599824336
Validation loss: 2.7091655528514975

Epoch: 6| Step: 1
Training loss: 1.0223983264542256
Validation loss: 2.755918116926882

Epoch: 6| Step: 2
Training loss: 1.390247079309401
Validation loss: 2.7065033868185555

Epoch: 6| Step: 3
Training loss: 1.3624220712056663
Validation loss: 2.716729696006793

Epoch: 6| Step: 4
Training loss: 1.3458439679901741
Validation loss: 2.765706910610405

Epoch: 6| Step: 5
Training loss: 1.808787852473174
Validation loss: 2.7614094274548604

Epoch: 6| Step: 6
Training loss: 1.8238119125054137
Validation loss: 2.654907725156079

Epoch: 6| Step: 7
Training loss: 1.4631415076874636
Validation loss: 2.639111689035185

Epoch: 6| Step: 8
Training loss: 1.202094987165971
Validation loss: 2.7925678383360326

Epoch: 6| Step: 9
Training loss: 1.0832512653272128
Validation loss: 2.732788904755974

Epoch: 6| Step: 10
Training loss: 1.3007915599517517
Validation loss: 2.7235067563380206

Epoch: 6| Step: 11
Training loss: 0.9461441165234145
Validation loss: 2.7505738642171464

Epoch: 6| Step: 12
Training loss: 0.9856851124740923
Validation loss: 2.7638618466850398

Epoch: 6| Step: 13
Training loss: 1.2659070207010148
Validation loss: 2.68165883620474

Epoch: 146| Step: 0
Training loss: 1.0038594038308388
Validation loss: 2.769989348826031

Epoch: 6| Step: 1
Training loss: 1.4993263162307644
Validation loss: 2.729113852497062

Epoch: 6| Step: 2
Training loss: 1.2052486552508104
Validation loss: 2.7754466055428484

Epoch: 6| Step: 3
Training loss: 0.7645835410454769
Validation loss: 2.7011725958296595

Epoch: 6| Step: 4
Training loss: 1.2172780562712868
Validation loss: 2.6284063278621717

Epoch: 6| Step: 5
Training loss: 1.1706331921406388
Validation loss: 2.6746185078239115

Epoch: 6| Step: 6
Training loss: 1.0760034335872222
Validation loss: 2.751788901308364

Epoch: 6| Step: 7
Training loss: 1.054512009325733
Validation loss: 2.6725879483907247

Epoch: 6| Step: 8
Training loss: 1.45542815433879
Validation loss: 2.7474219780471922

Epoch: 6| Step: 9
Training loss: 2.086254310123478
Validation loss: 2.7270024116891536

Epoch: 6| Step: 10
Training loss: 1.787680546105572
Validation loss: 2.695231855724789

Epoch: 6| Step: 11
Training loss: 1.4860896597212252
Validation loss: 2.792346491998466

Epoch: 6| Step: 12
Training loss: 1.2132443512699191
Validation loss: 2.682050399052611

Epoch: 6| Step: 13
Training loss: 1.2998723701034458
Validation loss: 2.7669768827856145

Epoch: 147| Step: 0
Training loss: 1.3790009982054972
Validation loss: 2.8391318498034286

Epoch: 6| Step: 1
Training loss: 1.5546861198074118
Validation loss: 2.895185402669137

Epoch: 6| Step: 2
Training loss: 1.729167095628555
Validation loss: 2.8720326797871683

Epoch: 6| Step: 3
Training loss: 1.1490732626038758
Validation loss: 2.8147696908904165

Epoch: 6| Step: 4
Training loss: 1.4781804983676365
Validation loss: 2.7745722495428273

Epoch: 6| Step: 5
Training loss: 1.437567170273818
Validation loss: 2.6965186769581484

Epoch: 6| Step: 6
Training loss: 0.9824870336322475
Validation loss: 2.6921728008663806

Epoch: 6| Step: 7
Training loss: 0.8609515208021703
Validation loss: 2.787038344627835

Epoch: 6| Step: 8
Training loss: 1.5795029771081799
Validation loss: 2.642418983706843

Epoch: 6| Step: 9
Training loss: 1.1885107657683585
Validation loss: 2.7318158117227385

Epoch: 6| Step: 10
Training loss: 0.8963906897832906
Validation loss: 2.6444912057058274

Epoch: 6| Step: 11
Training loss: 1.5563073848577342
Validation loss: 2.687945484232985

Epoch: 6| Step: 12
Training loss: 1.8603293910670289
Validation loss: 2.7514567273800727

Epoch: 6| Step: 13
Training loss: 1.0588375247236081
Validation loss: 2.8476839975575903

Epoch: 148| Step: 0
Training loss: 1.4659751490090844
Validation loss: 2.86647199387429

Epoch: 6| Step: 1
Training loss: 0.9682123168715835
Validation loss: 2.8402135329272493

Epoch: 6| Step: 2
Training loss: 1.9997061871244006
Validation loss: 2.8077975768589787

Epoch: 6| Step: 3
Training loss: 1.291535011883211
Validation loss: 2.7010688973576946

Epoch: 6| Step: 4
Training loss: 1.4027151821929982
Validation loss: 2.6819145431335514

Epoch: 6| Step: 5
Training loss: 1.5198745928027384
Validation loss: 2.7198438015317596

Epoch: 6| Step: 6
Training loss: 1.2392156787680821
Validation loss: 2.682999428020942

Epoch: 6| Step: 7
Training loss: 1.5282541668992824
Validation loss: 2.650498847373007

Epoch: 6| Step: 8
Training loss: 1.468003509418544
Validation loss: 2.783908502079996

Epoch: 6| Step: 9
Training loss: 1.5854485420434727
Validation loss: 2.685950949122777

Epoch: 6| Step: 10
Training loss: 1.2882340977207503
Validation loss: 2.690767298179852

Epoch: 6| Step: 11
Training loss: 1.245302529097669
Validation loss: 2.789010140918611

Epoch: 6| Step: 12
Training loss: 0.9361042122597675
Validation loss: 2.7044541283058576

Epoch: 6| Step: 13
Training loss: 1.0095211005988538
Validation loss: 2.7857440472679347

Epoch: 149| Step: 0
Training loss: 1.3424143696048847
Validation loss: 2.754618898353605

Epoch: 6| Step: 1
Training loss: 1.3626509906504147
Validation loss: 2.7529126261831633

Epoch: 6| Step: 2
Training loss: 1.7004713330700096
Validation loss: 2.74006543190416

Epoch: 6| Step: 3
Training loss: 1.1987340488108453
Validation loss: 2.718431476043015

Epoch: 6| Step: 4
Training loss: 1.3327955810617873
Validation loss: 2.6309979503057663

Epoch: 6| Step: 5
Training loss: 0.8771447055272632
Validation loss: 2.714247442754861

Epoch: 6| Step: 6
Training loss: 0.9746739551499549
Validation loss: 2.6958655264542304

Epoch: 6| Step: 7
Training loss: 1.3409264641269651
Validation loss: 2.746831687148892

Epoch: 6| Step: 8
Training loss: 1.6341792323076634
Validation loss: 2.6534070078127674

Epoch: 6| Step: 9
Training loss: 1.037456964266655
Validation loss: 2.7122109799731815

Epoch: 6| Step: 10
Training loss: 0.9390597084752894
Validation loss: 2.772902559798135

Epoch: 6| Step: 11
Training loss: 0.9595251481545969
Validation loss: 2.648094897770982

Epoch: 6| Step: 12
Training loss: 1.9589483499304703
Validation loss: 2.674454668793969

Epoch: 6| Step: 13
Training loss: 1.302155464717567
Validation loss: 2.7933214654040657

Epoch: 150| Step: 0
Training loss: 1.14786136214737
Validation loss: 2.744674380919418

Epoch: 6| Step: 1
Training loss: 2.1426426643937324
Validation loss: 2.688113778280182

Epoch: 6| Step: 2
Training loss: 1.6530150724901937
Validation loss: 2.685047272420554

Epoch: 6| Step: 3
Training loss: 1.1698233383026364
Validation loss: 2.730155479349392

Epoch: 6| Step: 4
Training loss: 0.8345076551960506
Validation loss: 2.6264548130414753

Epoch: 6| Step: 5
Training loss: 1.0603139491567426
Validation loss: 2.764509345997562

Epoch: 6| Step: 6
Training loss: 1.384582679619043
Validation loss: 2.6237505406607378

Epoch: 6| Step: 7
Training loss: 1.022861347657928
Validation loss: 2.7469940518505873

Epoch: 6| Step: 8
Training loss: 1.4447226480593685
Validation loss: 2.753561098370233

Epoch: 6| Step: 9
Training loss: 1.6316277252995135
Validation loss: 2.632625614706246

Epoch: 6| Step: 10
Training loss: 0.5923920461838699
Validation loss: 2.6101340219768545

Epoch: 6| Step: 11
Training loss: 0.7994736579100512
Validation loss: 2.656639541785052

Epoch: 6| Step: 12
Training loss: 1.1187673748521219
Validation loss: 2.68177519828978

Epoch: 6| Step: 13
Training loss: 1.1583541076956163
Validation loss: 2.7934086522104535

Epoch: 151| Step: 0
Training loss: 1.0632254424013887
Validation loss: 2.7149307346816904

Epoch: 6| Step: 1
Training loss: 1.1609156014801725
Validation loss: 2.7496201223922174

Epoch: 6| Step: 2
Training loss: 1.2075617837204335
Validation loss: 2.7550097119298065

Epoch: 6| Step: 3
Training loss: 0.6783845624472914
Validation loss: 2.6766759411550995

Epoch: 6| Step: 4
Training loss: 1.0406203673663423
Validation loss: 2.778320384011606

Epoch: 6| Step: 5
Training loss: 1.483793606587339
Validation loss: 2.8563179392007125

Epoch: 6| Step: 6
Training loss: 0.8973631696610688
Validation loss: 2.691546771880008

Epoch: 6| Step: 7
Training loss: 1.079982153162258
Validation loss: 2.707820848737152

Epoch: 6| Step: 8
Training loss: 0.7709714705610298
Validation loss: 2.7168465305144585

Epoch: 6| Step: 9
Training loss: 1.2998689768861025
Validation loss: 2.689440699271367

Epoch: 6| Step: 10
Training loss: 1.0988938491969906
Validation loss: 2.7676433805903993

Epoch: 6| Step: 11
Training loss: 2.3684731193307194
Validation loss: 2.7427093139793497

Epoch: 6| Step: 12
Training loss: 1.452502537789155
Validation loss: 2.768871133650275

Epoch: 6| Step: 13
Training loss: 0.9494497073163881
Validation loss: 2.7570581313959717

Epoch: 152| Step: 0
Training loss: 1.1125242102056756
Validation loss: 2.7848163698748856

Epoch: 6| Step: 1
Training loss: 1.0898318272967351
Validation loss: 2.7266770040958126

Epoch: 6| Step: 2
Training loss: 1.1258282261828378
Validation loss: 2.8519028830629933

Epoch: 6| Step: 3
Training loss: 1.5262648730603863
Validation loss: 2.6826560109405913

Epoch: 6| Step: 4
Training loss: 1.0716514287510948
Validation loss: 2.7554101323222793

Epoch: 6| Step: 5
Training loss: 1.2521391208214607
Validation loss: 2.7273361361843613

Epoch: 6| Step: 6
Training loss: 1.0680109603119414
Validation loss: 2.761172854415227

Epoch: 6| Step: 7
Training loss: 1.0696744478829694
Validation loss: 2.8496000321574764

Epoch: 6| Step: 8
Training loss: 0.8621878280168928
Validation loss: 2.702618795931049

Epoch: 6| Step: 9
Training loss: 1.7060638410020257
Validation loss: 2.769588855454589

Epoch: 6| Step: 10
Training loss: 1.358087083030053
Validation loss: 2.651339865790206

Epoch: 6| Step: 11
Training loss: 0.9070772473141757
Validation loss: 2.733384888635737

Epoch: 6| Step: 12
Training loss: 1.139890878708374
Validation loss: 2.6808315018669453

Epoch: 6| Step: 13
Training loss: 1.9692309564122699
Validation loss: 2.75141955352218

Epoch: 153| Step: 0
Training loss: 1.043321414144112
Validation loss: 2.8208644534657203

Epoch: 6| Step: 1
Training loss: 0.8470400491048801
Validation loss: 2.7187399005336914

Epoch: 6| Step: 2
Training loss: 1.1037424580196478
Validation loss: 2.7956221205573373

Epoch: 6| Step: 3
Training loss: 0.9330214018907114
Validation loss: 2.7870985537494684

Epoch: 6| Step: 4
Training loss: 1.4123811789979352
Validation loss: 2.6911553799771375

Epoch: 6| Step: 5
Training loss: 1.003218953614006
Validation loss: 2.8423131869170906

Epoch: 6| Step: 6
Training loss: 2.0801141153723255
Validation loss: 2.7545421254007905

Epoch: 6| Step: 7
Training loss: 1.4476640695936105
Validation loss: 2.843974974400098

Epoch: 6| Step: 8
Training loss: 1.5566465983162525
Validation loss: 2.856735734657312

Epoch: 6| Step: 9
Training loss: 1.1374896080464632
Validation loss: 2.8465337298201945

Epoch: 6| Step: 10
Training loss: 1.0613873209361158
Validation loss: 2.8718994809263654

Epoch: 6| Step: 11
Training loss: 1.2003580949858754
Validation loss: 2.7856984941503056

Epoch: 6| Step: 12
Training loss: 1.2172210101116705
Validation loss: 2.7748773195453014

Epoch: 6| Step: 13
Training loss: 1.1796207535410494
Validation loss: 2.6905073594306543

Epoch: 154| Step: 0
Training loss: 1.8759363379626572
Validation loss: 2.7812497714038997

Epoch: 6| Step: 1
Training loss: 1.2314276939783457
Validation loss: 2.80316205632819

Epoch: 6| Step: 2
Training loss: 1.1966995967294034
Validation loss: 2.7272560381619537

Epoch: 6| Step: 3
Training loss: 0.7516825399675243
Validation loss: 2.7848963177030557

Epoch: 6| Step: 4
Training loss: 1.4161363431840073
Validation loss: 2.8301107765843283

Epoch: 6| Step: 5
Training loss: 1.6775089774197127
Validation loss: 2.6775725742670966

Epoch: 6| Step: 6
Training loss: 1.3326673135690676
Validation loss: 2.749952561518399

Epoch: 6| Step: 7
Training loss: 0.8928179929869395
Validation loss: 2.7565263985861437

Epoch: 6| Step: 8
Training loss: 1.2494983620207372
Validation loss: 2.7461571068868693

Epoch: 6| Step: 9
Training loss: 1.1443780269197343
Validation loss: 2.755340729232407

Epoch: 6| Step: 10
Training loss: 1.2212551974261134
Validation loss: 2.7671619749408736

Epoch: 6| Step: 11
Training loss: 0.825137309005273
Validation loss: 2.709350179861413

Epoch: 6| Step: 12
Training loss: 1.2045124030608827
Validation loss: 2.7058559580159467

Epoch: 6| Step: 13
Training loss: 0.7235238717839442
Validation loss: 2.739289530288834

Epoch: 155| Step: 0
Training loss: 0.9749204028479406
Validation loss: 2.6766353682623594

Epoch: 6| Step: 1
Training loss: 2.314684892469863
Validation loss: 2.7744216390701206

Epoch: 6| Step: 2
Training loss: 1.5367463784771693
Validation loss: 2.752197139291843

Epoch: 6| Step: 3
Training loss: 0.8151033947893251
Validation loss: 2.6525382793179957

Epoch: 6| Step: 4
Training loss: 0.9851753674678304
Validation loss: 2.7612170564532055

Epoch: 6| Step: 5
Training loss: 0.7742400966130397
Validation loss: 2.781040098006165

Epoch: 6| Step: 6
Training loss: 1.1188769071407385
Validation loss: 2.702277048697012

Epoch: 6| Step: 7
Training loss: 1.090538541760755
Validation loss: 2.803097868596343

Epoch: 6| Step: 8
Training loss: 1.5838990288447807
Validation loss: 2.7854208586458453

Epoch: 6| Step: 9
Training loss: 1.2793778488507626
Validation loss: 2.8523310352892897

Epoch: 6| Step: 10
Training loss: 1.4101708324238442
Validation loss: 2.7211752119346237

Epoch: 6| Step: 11
Training loss: 0.5904856845499705
Validation loss: 2.7548658353996194

Epoch: 6| Step: 12
Training loss: 0.859599482954286
Validation loss: 2.719236703037565

Epoch: 6| Step: 13
Training loss: 0.9722101498414383
Validation loss: 2.732468956157013

Epoch: 156| Step: 0
Training loss: 1.1856007697284376
Validation loss: 2.6875508769342824

Epoch: 6| Step: 1
Training loss: 1.3114121788251762
Validation loss: 2.6409952780640316

Epoch: 6| Step: 2
Training loss: 1.0525412302708066
Validation loss: 2.6740842612473554

Epoch: 6| Step: 3
Training loss: 0.9001382072612396
Validation loss: 2.7216432165415374

Epoch: 6| Step: 4
Training loss: 1.0775601109600517
Validation loss: 2.667011243690883

Epoch: 6| Step: 5
Training loss: 0.7577054842864847
Validation loss: 2.75106039699277

Epoch: 6| Step: 6
Training loss: 0.8565683831030615
Validation loss: 2.772238229422095

Epoch: 6| Step: 7
Training loss: 1.4018197528430891
Validation loss: 2.692018480801453

Epoch: 6| Step: 8
Training loss: 1.6774487146761454
Validation loss: 2.670839402722045

Epoch: 6| Step: 9
Training loss: 1.0519006715340298
Validation loss: 2.7866992501661287

Epoch: 6| Step: 10
Training loss: 1.2497981862231282
Validation loss: 2.77280451038817

Epoch: 6| Step: 11
Training loss: 1.0593813960689682
Validation loss: 2.7750757241442074

Epoch: 6| Step: 12
Training loss: 2.0209031895889207
Validation loss: 2.7054877860398046

Epoch: 6| Step: 13
Training loss: 1.0163600315900767
Validation loss: 2.8097255019967418

Epoch: 157| Step: 0
Training loss: 0.7879240680456558
Validation loss: 2.7985029828113235

Epoch: 6| Step: 1
Training loss: 1.5580218420297256
Validation loss: 2.794449974970551

Epoch: 6| Step: 2
Training loss: 1.0811280154176124
Validation loss: 2.8096399529552736

Epoch: 6| Step: 3
Training loss: 0.9564282756002382
Validation loss: 2.7705145105104605

Epoch: 6| Step: 4
Training loss: 1.1575164045650317
Validation loss: 2.773282601056017

Epoch: 6| Step: 5
Training loss: 1.385416800515687
Validation loss: 2.7047375332622923

Epoch: 6| Step: 6
Training loss: 1.1534800988089862
Validation loss: 2.771786193686583

Epoch: 6| Step: 7
Training loss: 1.1490239832162088
Validation loss: 2.8086568359307384

Epoch: 6| Step: 8
Training loss: 0.9564946752939409
Validation loss: 2.7871391296580597

Epoch: 6| Step: 9
Training loss: 1.7791899430169111
Validation loss: 2.7028581344204614

Epoch: 6| Step: 10
Training loss: 1.3631499044110122
Validation loss: 2.800131338876571

Epoch: 6| Step: 11
Training loss: 1.2917615435220893
Validation loss: 2.739084536805973

Epoch: 6| Step: 12
Training loss: 1.0196408033887132
Validation loss: 2.6543997959134202

Epoch: 6| Step: 13
Training loss: 1.0591799531148822
Validation loss: 2.736457438638805

Epoch: 158| Step: 0
Training loss: 1.6705716480736934
Validation loss: 2.6815744027418646

Epoch: 6| Step: 1
Training loss: 1.6299185043275972
Validation loss: 2.7437892630048095

Epoch: 6| Step: 2
Training loss: 1.824574993236733
Validation loss: 2.687684799464661

Epoch: 6| Step: 3
Training loss: 1.2899493316931372
Validation loss: 2.764562427831707

Epoch: 6| Step: 4
Training loss: 1.0914763114794626
Validation loss: 2.8447919201417182

Epoch: 6| Step: 5
Training loss: 0.8756662284734777
Validation loss: 2.690444427468319

Epoch: 6| Step: 6
Training loss: 1.015500339780344
Validation loss: 2.7736355419820193

Epoch: 6| Step: 7
Training loss: 1.135222456301602
Validation loss: 2.8131695974606554

Epoch: 6| Step: 8
Training loss: 0.7437751653565107
Validation loss: 2.8083528955685715

Epoch: 6| Step: 9
Training loss: 0.865651153004117
Validation loss: 2.7557998531842887

Epoch: 6| Step: 10
Training loss: 0.8710933394495249
Validation loss: 2.7427142616340228

Epoch: 6| Step: 11
Training loss: 1.1579554584086762
Validation loss: 2.776785878999326

Epoch: 6| Step: 12
Training loss: 0.6867227061638346
Validation loss: 2.6659080996040094

Epoch: 6| Step: 13
Training loss: 1.1203582158464207
Validation loss: 2.7154893871257553

Epoch: 159| Step: 0
Training loss: 1.179066222847471
Validation loss: 2.8458277618964316

Epoch: 6| Step: 1
Training loss: 1.2697871023737066
Validation loss: 2.7693593878030835

Epoch: 6| Step: 2
Training loss: 0.8941780625784711
Validation loss: 2.7927987569370014

Epoch: 6| Step: 3
Training loss: 0.8856466256505034
Validation loss: 2.848106735870753

Epoch: 6| Step: 4
Training loss: 0.8156701013365176
Validation loss: 2.7710639934091095

Epoch: 6| Step: 5
Training loss: 1.0815410398720102
Validation loss: 2.751493936840145

Epoch: 6| Step: 6
Training loss: 1.1720925192818221
Validation loss: 2.7272237651697373

Epoch: 6| Step: 7
Training loss: 1.856896680193679
Validation loss: 2.7433012740956864

Epoch: 6| Step: 8
Training loss: 1.3128576699603776
Validation loss: 2.745301365201048

Epoch: 6| Step: 9
Training loss: 1.3483289725787575
Validation loss: 2.744198937209437

Epoch: 6| Step: 10
Training loss: 0.7845295544826144
Validation loss: 2.766395088064835

Epoch: 6| Step: 11
Training loss: 1.1523785084800222
Validation loss: 2.729362500180092

Epoch: 6| Step: 12
Training loss: 0.8027877604235304
Validation loss: 2.724373610127809

Epoch: 6| Step: 13
Training loss: 1.1733910481570675
Validation loss: 2.7624801888194224

Epoch: 160| Step: 0
Training loss: 1.043824091582967
Validation loss: 2.748382309299319

Epoch: 6| Step: 1
Training loss: 1.2602338526954489
Validation loss: 2.8005398939374526

Epoch: 6| Step: 2
Training loss: 0.6418118995769938
Validation loss: 2.764764253109957

Epoch: 6| Step: 3
Training loss: 1.8616230301736112
Validation loss: 2.7618783259927473

Epoch: 6| Step: 4
Training loss: 0.8841649051927954
Validation loss: 2.745403436360738

Epoch: 6| Step: 5
Training loss: 0.8861408114729135
Validation loss: 2.755524014498392

Epoch: 6| Step: 6
Training loss: 1.2556829017060163
Validation loss: 2.7047618988694

Epoch: 6| Step: 7
Training loss: 0.9975630750289396
Validation loss: 2.683350086949649

Epoch: 6| Step: 8
Training loss: 1.4527821290141665
Validation loss: 2.7431533865779185

Epoch: 6| Step: 9
Training loss: 1.3331800859518845
Validation loss: 2.7110258852047586

Epoch: 6| Step: 10
Training loss: 1.2603579525894204
Validation loss: 2.747099575081694

Epoch: 6| Step: 11
Training loss: 1.0041698896322064
Validation loss: 2.8132544459300455

Epoch: 6| Step: 12
Training loss: 1.0700061666007914
Validation loss: 2.7892401217508267

Epoch: 6| Step: 13
Training loss: 1.5513492187934743
Validation loss: 2.816772183204381

Epoch: 161| Step: 0
Training loss: 1.7216788566184893
Validation loss: 2.7611238017729747

Epoch: 6| Step: 1
Training loss: 1.0735855178173175
Validation loss: 2.741083979115629

Epoch: 6| Step: 2
Training loss: 1.0610020119291137
Validation loss: 2.704995597746458

Epoch: 6| Step: 3
Training loss: 1.835427071249226
Validation loss: 2.7747349815861555

Epoch: 6| Step: 4
Training loss: 0.9254591176170802
Validation loss: 2.790658047413839

Epoch: 6| Step: 5
Training loss: 0.7131233984940087
Validation loss: 2.8121823590658326

Epoch: 6| Step: 6
Training loss: 0.9062531898705478
Validation loss: 2.770342651937497

Epoch: 6| Step: 7
Training loss: 0.8156663745310075
Validation loss: 2.7709437733106643

Epoch: 6| Step: 8
Training loss: 0.8564339683764451
Validation loss: 2.7649182064841935

Epoch: 6| Step: 9
Training loss: 1.1743806119564462
Validation loss: 2.807306779149603

Epoch: 6| Step: 10
Training loss: 0.9871348490596238
Validation loss: 2.752216125295525

Epoch: 6| Step: 11
Training loss: 1.3366124193895712
Validation loss: 2.800794302583195

Epoch: 6| Step: 12
Training loss: 0.9041593377011145
Validation loss: 2.785637142116989

Epoch: 6| Step: 13
Training loss: 1.1364508768752555
Validation loss: 2.7315249749101587

Epoch: 162| Step: 0
Training loss: 1.0853895822222237
Validation loss: 2.7523110244744364

Epoch: 6| Step: 1
Training loss: 1.3179417831836842
Validation loss: 2.754238994146927

Epoch: 6| Step: 2
Training loss: 0.7876957301964705
Validation loss: 2.6628335782596326

Epoch: 6| Step: 3
Training loss: 1.3306627151211439
Validation loss: 2.7649205562475627

Epoch: 6| Step: 4
Training loss: 1.889581944283925
Validation loss: 2.811238627678629

Epoch: 6| Step: 5
Training loss: 1.193145533005854
Validation loss: 2.7137942693851818

Epoch: 6| Step: 6
Training loss: 1.1442611427689713
Validation loss: 2.826765601328113

Epoch: 6| Step: 7
Training loss: 1.0658555058391816
Validation loss: 2.7137515718445866

Epoch: 6| Step: 8
Training loss: 0.9401989868756654
Validation loss: 2.7540124462384803

Epoch: 6| Step: 9
Training loss: 0.8894911458463041
Validation loss: 2.8596013158512292

Epoch: 6| Step: 10
Training loss: 1.176902413882074
Validation loss: 2.663624508409495

Epoch: 6| Step: 11
Training loss: 0.7959572237923586
Validation loss: 2.7295458192964395

Epoch: 6| Step: 12
Training loss: 0.6904785915898322
Validation loss: 2.7573415121701808

Epoch: 6| Step: 13
Training loss: 0.8512202283719744
Validation loss: 2.7848276780017196

Epoch: 163| Step: 0
Training loss: 1.8672324458502583
Validation loss: 2.7542108029182555

Epoch: 6| Step: 1
Training loss: 1.0813679228407649
Validation loss: 2.8914841758316574

Epoch: 6| Step: 2
Training loss: 1.3786065745867806
Validation loss: 2.844152401131025

Epoch: 6| Step: 3
Training loss: 1.4162570510783006
Validation loss: 2.775302413981092

Epoch: 6| Step: 4
Training loss: 1.3178079087501027
Validation loss: 2.7300576704172976

Epoch: 6| Step: 5
Training loss: 1.2064328484974431
Validation loss: 2.799544809444181

Epoch: 6| Step: 6
Training loss: 0.9857705532623701
Validation loss: 2.7940673374807834

Epoch: 6| Step: 7
Training loss: 1.2477803072465452
Validation loss: 2.6899427505224827

Epoch: 6| Step: 8
Training loss: 0.9513044950237278
Validation loss: 2.7686278282519767

Epoch: 6| Step: 9
Training loss: 1.0001099049254194
Validation loss: 2.7645970821158516

Epoch: 6| Step: 10
Training loss: 0.9402416829616416
Validation loss: 2.7381596413535263

Epoch: 6| Step: 11
Training loss: 0.8333912511407996
Validation loss: 2.820517661961933

Epoch: 6| Step: 12
Training loss: 0.6141323816658268
Validation loss: 2.85986711613517

Epoch: 6| Step: 13
Training loss: 0.9870198156731059
Validation loss: 2.84077992983734

Epoch: 164| Step: 0
Training loss: 1.4018348471766744
Validation loss: 2.746607363887804

Epoch: 6| Step: 1
Training loss: 1.2023918097633965
Validation loss: 2.774316582135974

Epoch: 6| Step: 2
Training loss: 0.6276897250748239
Validation loss: 2.7332818162141503

Epoch: 6| Step: 3
Training loss: 1.0981928372476222
Validation loss: 2.692449698702944

Epoch: 6| Step: 4
Training loss: 0.5015202893710158
Validation loss: 2.71975572480251

Epoch: 6| Step: 5
Training loss: 1.8468432583477519
Validation loss: 2.669711525366995

Epoch: 6| Step: 6
Training loss: 1.3092021381923653
Validation loss: 2.6658230852926006

Epoch: 6| Step: 7
Training loss: 1.4263032140675673
Validation loss: 2.7390090765986628

Epoch: 6| Step: 8
Training loss: 1.1962605126535844
Validation loss: 2.825429091597578

Epoch: 6| Step: 9
Training loss: 0.6321787781050099
Validation loss: 2.7793248832615665

Epoch: 6| Step: 10
Training loss: 0.984567714173911
Validation loss: 2.8467644863683015

Epoch: 6| Step: 11
Training loss: 0.9573343225273009
Validation loss: 2.8391565106113874

Epoch: 6| Step: 12
Training loss: 1.0480215142786282
Validation loss: 2.8264025365784793

Epoch: 6| Step: 13
Training loss: 1.1909513011363928
Validation loss: 2.70898939158354

Epoch: 165| Step: 0
Training loss: 1.3037190297765004
Validation loss: 2.769132936115149

Epoch: 6| Step: 1
Training loss: 1.0327995680375972
Validation loss: 2.8211818774619632

Epoch: 6| Step: 2
Training loss: 1.0315769139773285
Validation loss: 2.817741821616549

Epoch: 6| Step: 3
Training loss: 1.0883423228766427
Validation loss: 2.753778376214469

Epoch: 6| Step: 4
Training loss: 0.8671723098111812
Validation loss: 2.7839580453464645

Epoch: 6| Step: 5
Training loss: 1.2735102346044227
Validation loss: 2.8014136486717116

Epoch: 6| Step: 6
Training loss: 0.9916686556232499
Validation loss: 2.6820685333970387

Epoch: 6| Step: 7
Training loss: 1.741064008759838
Validation loss: 2.7926761642893148

Epoch: 6| Step: 8
Training loss: 1.4860341486902675
Validation loss: 2.919810492220907

Epoch: 6| Step: 9
Training loss: 0.7061094735022616
Validation loss: 2.8961299405865124

Epoch: 6| Step: 10
Training loss: 0.8167649352708005
Validation loss: 2.915274155943508

Epoch: 6| Step: 11
Training loss: 0.9360042083352191
Validation loss: 2.881004393639878

Epoch: 6| Step: 12
Training loss: 1.1538434114179055
Validation loss: 2.823967718045241

Epoch: 6| Step: 13
Training loss: 1.2206551748394903
Validation loss: 2.829420446372583

Epoch: 166| Step: 0
Training loss: 0.6025120313321628
Validation loss: 2.765302635701492

Epoch: 6| Step: 1
Training loss: 1.1517305455983646
Validation loss: 2.664426433804432

Epoch: 6| Step: 2
Training loss: 1.0010582569558977
Validation loss: 2.835931923320461

Epoch: 6| Step: 3
Training loss: 1.0943420987327674
Validation loss: 2.768974797097981

Epoch: 6| Step: 4
Training loss: 0.9962245481295974
Validation loss: 2.7863246327110076

Epoch: 6| Step: 5
Training loss: 1.8930710031661688
Validation loss: 2.730928847041712

Epoch: 6| Step: 6
Training loss: 1.023110898153147
Validation loss: 2.822384947264034

Epoch: 6| Step: 7
Training loss: 1.3512815503187379
Validation loss: 2.737419083384994

Epoch: 6| Step: 8
Training loss: 1.263634564705311
Validation loss: 2.7510158078760876

Epoch: 6| Step: 9
Training loss: 1.2546398358062196
Validation loss: 2.8112984174485915

Epoch: 6| Step: 10
Training loss: 1.1882959007548812
Validation loss: 2.861969734618334

Epoch: 6| Step: 11
Training loss: 1.4585406383127002
Validation loss: 2.9062669404879466

Epoch: 6| Step: 12
Training loss: 1.1600115136693248
Validation loss: 2.8934778792741644

Epoch: 6| Step: 13
Training loss: 1.31379613002289
Validation loss: 2.8801404221836786

Epoch: 167| Step: 0
Training loss: 1.3852765387702153
Validation loss: 2.7798629116429785

Epoch: 6| Step: 1
Training loss: 0.8401080048472039
Validation loss: 2.719790482469055

Epoch: 6| Step: 2
Training loss: 0.7053902059535431
Validation loss: 2.7396203148573455

Epoch: 6| Step: 3
Training loss: 0.8203001475539465
Validation loss: 2.7302695416795357

Epoch: 6| Step: 4
Training loss: 0.8302918641408624
Validation loss: 2.807117029725521

Epoch: 6| Step: 5
Training loss: 1.0584039834738324
Validation loss: 2.682205796333247

Epoch: 6| Step: 6
Training loss: 1.1242050435156514
Validation loss: 2.733637777582462

Epoch: 6| Step: 7
Training loss: 1.2442444858287043
Validation loss: 2.744611648553272

Epoch: 6| Step: 8
Training loss: 0.9790218969960892
Validation loss: 2.73527624627387

Epoch: 6| Step: 9
Training loss: 0.9883041077635478
Validation loss: 2.8384312016168995

Epoch: 6| Step: 10
Training loss: 1.0181864788866815
Validation loss: 2.720186431376666

Epoch: 6| Step: 11
Training loss: 0.8840233929460339
Validation loss: 2.720089797870431

Epoch: 6| Step: 12
Training loss: 1.476928665535697
Validation loss: 2.700650149823245

Epoch: 6| Step: 13
Training loss: 1.6294371108086512
Validation loss: 2.777914969447237

Epoch: 168| Step: 0
Training loss: 0.8185699119235216
Validation loss: 2.8222347763821913

Epoch: 6| Step: 1
Training loss: 1.8240456999357504
Validation loss: 2.8743679485219347

Epoch: 6| Step: 2
Training loss: 1.4935414827126483
Validation loss: 2.870643300123331

Epoch: 6| Step: 3
Training loss: 1.468226887499432
Validation loss: 2.9094629199998767

Epoch: 6| Step: 4
Training loss: 0.7200925147700682
Validation loss: 2.7577686252291835

Epoch: 6| Step: 5
Training loss: 1.0873597526003123
Validation loss: 2.784803513513394

Epoch: 6| Step: 6
Training loss: 1.0260592360694687
Validation loss: 2.7465876591377527

Epoch: 6| Step: 7
Training loss: 1.0246845248342904
Validation loss: 2.8254858386894823

Epoch: 6| Step: 8
Training loss: 1.1611728003620823
Validation loss: 2.8012894755005835

Epoch: 6| Step: 9
Training loss: 0.6638396394046835
Validation loss: 2.724196448534303

Epoch: 6| Step: 10
Training loss: 0.7136139009394034
Validation loss: 2.817349117789378

Epoch: 6| Step: 11
Training loss: 0.9455535203097721
Validation loss: 2.6811443405851687

Epoch: 6| Step: 12
Training loss: 0.9893182131675631
Validation loss: 2.7655594812595816

Epoch: 6| Step: 13
Training loss: 0.7823139194281515
Validation loss: 2.8247947404499008

Epoch: 169| Step: 0
Training loss: 0.8637950628204462
Validation loss: 2.8164806735310615

Epoch: 6| Step: 1
Training loss: 1.441264820138478
Validation loss: 2.732304586674961

Epoch: 6| Step: 2
Training loss: 0.8571898335401791
Validation loss: 2.881325549323309

Epoch: 6| Step: 3
Training loss: 1.0625195781923518
Validation loss: 2.8575382969454544

Epoch: 6| Step: 4
Training loss: 1.3945819834822402
Validation loss: 2.78002231090384

Epoch: 6| Step: 5
Training loss: 1.018223182810236
Validation loss: 2.809367109209124

Epoch: 6| Step: 6
Training loss: 0.6525263958923018
Validation loss: 2.662058041684738

Epoch: 6| Step: 7
Training loss: 0.7625339547398496
Validation loss: 2.7405728969166665

Epoch: 6| Step: 8
Training loss: 0.7576414485468188
Validation loss: 2.8440385888634236

Epoch: 6| Step: 9
Training loss: 1.0224074210340863
Validation loss: 2.768073799220775

Epoch: 6| Step: 10
Training loss: 1.7568113739857985
Validation loss: 2.773391694599554

Epoch: 6| Step: 11
Training loss: 0.9858286282117257
Validation loss: 2.750245415689664

Epoch: 6| Step: 12
Training loss: 1.3960728605871082
Validation loss: 2.749147933390438

Epoch: 6| Step: 13
Training loss: 1.2348438290066592
Validation loss: 2.8283494259637414

Epoch: 170| Step: 0
Training loss: 1.1821776123601424
Validation loss: 2.780241708470602

Epoch: 6| Step: 1
Training loss: 1.103904183096277
Validation loss: 2.820786933761486

Epoch: 6| Step: 2
Training loss: 1.0764780041847823
Validation loss: 2.7789550127783205

Epoch: 6| Step: 3
Training loss: 0.9548009926722479
Validation loss: 2.66119690797476

Epoch: 6| Step: 4
Training loss: 1.4549516251640062
Validation loss: 2.705287634199259

Epoch: 6| Step: 5
Training loss: 1.1076462937083942
Validation loss: 2.7583775216180952

Epoch: 6| Step: 6
Training loss: 1.7171166027869302
Validation loss: 2.7760127401842856

Epoch: 6| Step: 7
Training loss: 0.9543039503549621
Validation loss: 2.8228140433450934

Epoch: 6| Step: 8
Training loss: 0.7410767123350784
Validation loss: 2.769923560330695

Epoch: 6| Step: 9
Training loss: 0.5660183334549048
Validation loss: 2.7657524481824063

Epoch: 6| Step: 10
Training loss: 0.9463350424603862
Validation loss: 2.7821962339962636

Epoch: 6| Step: 11
Training loss: 0.9377507510221642
Validation loss: 2.7731841352186057

Epoch: 6| Step: 12
Training loss: 1.0355446140951012
Validation loss: 2.7689074991751244

Epoch: 6| Step: 13
Training loss: 0.8429792910845727
Validation loss: 2.771063448497665

Epoch: 171| Step: 0
Training loss: 0.7735733914686911
Validation loss: 2.839483910823737

Epoch: 6| Step: 1
Training loss: 1.0242889589735993
Validation loss: 2.7471889954338216

Epoch: 6| Step: 2
Training loss: 0.6785015853632802
Validation loss: 2.8206672762325633

Epoch: 6| Step: 3
Training loss: 0.8613952472163287
Validation loss: 2.750815285137437

Epoch: 6| Step: 4
Training loss: 1.1239434685252963
Validation loss: 2.8225385170970148

Epoch: 6| Step: 5
Training loss: 0.6907189827401585
Validation loss: 2.813085466836116

Epoch: 6| Step: 6
Training loss: 1.169480738953778
Validation loss: 2.8250281447862484

Epoch: 6| Step: 7
Training loss: 0.8525536045437879
Validation loss: 2.740746085762658

Epoch: 6| Step: 8
Training loss: 0.9883509675415324
Validation loss: 2.784579202547215

Epoch: 6| Step: 9
Training loss: 0.7926401293600621
Validation loss: 2.717434531987556

Epoch: 6| Step: 10
Training loss: 0.5799759283496664
Validation loss: 2.821575484322519

Epoch: 6| Step: 11
Training loss: 2.23797711874248
Validation loss: 2.7126672450012106

Epoch: 6| Step: 12
Training loss: 0.8633420068410705
Validation loss: 2.814065850549059

Epoch: 6| Step: 13
Training loss: 0.96745065489322
Validation loss: 2.7705231160675843

Epoch: 172| Step: 0
Training loss: 0.8444318488782279
Validation loss: 2.688597373774476

Epoch: 6| Step: 1
Training loss: 0.9056612272631583
Validation loss: 2.830295060370694

Epoch: 6| Step: 2
Training loss: 0.9018863658228498
Validation loss: 2.768393242830995

Epoch: 6| Step: 3
Training loss: 1.2723001655197725
Validation loss: 2.7270457250354125

Epoch: 6| Step: 4
Training loss: 0.7984289836989249
Validation loss: 2.7392398246587057

Epoch: 6| Step: 5
Training loss: 1.887299947684336
Validation loss: 2.8351624816114054

Epoch: 6| Step: 6
Training loss: 0.6092904839227576
Validation loss: 2.7787162297539574

Epoch: 6| Step: 7
Training loss: 1.5066920253144365
Validation loss: 2.7621277789962666

Epoch: 6| Step: 8
Training loss: 0.7890204616716952
Validation loss: 2.7952639381337088

Epoch: 6| Step: 9
Training loss: 1.060723952092928
Validation loss: 2.7695446937711803

Epoch: 6| Step: 10
Training loss: 1.0647249487182286
Validation loss: 2.8062930527905423

Epoch: 6| Step: 11
Training loss: 0.7026679354818471
Validation loss: 2.850007212222605

Epoch: 6| Step: 12
Training loss: 0.972162941230408
Validation loss: 2.8199022017535698

Epoch: 6| Step: 13
Training loss: 1.2110778727233227
Validation loss: 2.80746810207663

Epoch: 173| Step: 0
Training loss: 0.9432672491167207
Validation loss: 2.7658782957934935

Epoch: 6| Step: 1
Training loss: 1.9080999184442857
Validation loss: 2.8005940664283235

Epoch: 6| Step: 2
Training loss: 1.178109332316917
Validation loss: 2.818984560007296

Epoch: 6| Step: 3
Training loss: 0.983607795499911
Validation loss: 2.7145888540505054

Epoch: 6| Step: 4
Training loss: 0.678316487467114
Validation loss: 2.6978962331658383

Epoch: 6| Step: 5
Training loss: 0.7220741608248605
Validation loss: 2.6599837073087667

Epoch: 6| Step: 6
Training loss: 0.9202864586557316
Validation loss: 2.7105710884064957

Epoch: 6| Step: 7
Training loss: 0.7110925861601419
Validation loss: 2.72247416007323

Epoch: 6| Step: 8
Training loss: 1.1771813860988407
Validation loss: 2.836898962999475

Epoch: 6| Step: 9
Training loss: 0.8452250691042722
Validation loss: 2.7585282446078074

Epoch: 6| Step: 10
Training loss: 0.688368400572575
Validation loss: 2.8254424522298502

Epoch: 6| Step: 11
Training loss: 0.9551790960254568
Validation loss: 2.8236964276103547

Epoch: 6| Step: 12
Training loss: 1.226921077723883
Validation loss: 2.8665302295892943

Epoch: 6| Step: 13
Training loss: 0.8475438759848132
Validation loss: 2.854167232838224

Epoch: 174| Step: 0
Training loss: 1.119395281992926
Validation loss: 2.7738386983329266

Epoch: 6| Step: 1
Training loss: 1.0511343550604297
Validation loss: 2.8177579263117556

Epoch: 6| Step: 2
Training loss: 0.768967165162878
Validation loss: 2.791792273661076

Epoch: 6| Step: 3
Training loss: 0.7265946165800495
Validation loss: 2.811525741245836

Epoch: 6| Step: 4
Training loss: 0.7984198387267992
Validation loss: 2.820780890431356

Epoch: 6| Step: 5
Training loss: 1.1424478049010458
Validation loss: 2.848784883694821

Epoch: 6| Step: 6
Training loss: 0.6186175137103666
Validation loss: 2.8590264168695594

Epoch: 6| Step: 7
Training loss: 0.811645094730423
Validation loss: 2.820196471641048

Epoch: 6| Step: 8
Training loss: 0.7751229542442409
Validation loss: 2.8333994820296753

Epoch: 6| Step: 9
Training loss: 0.6524858148721043
Validation loss: 2.8935628035370695

Epoch: 6| Step: 10
Training loss: 0.8480025608006084
Validation loss: 2.846008773094983

Epoch: 6| Step: 11
Training loss: 0.8787617882579553
Validation loss: 2.850135773776429

Epoch: 6| Step: 12
Training loss: 2.0147267787270615
Validation loss: 2.8157368577421664

Epoch: 6| Step: 13
Training loss: 0.920389757006205
Validation loss: 2.934962292482593

Epoch: 175| Step: 0
Training loss: 1.126572992749495
Validation loss: 2.7652688524489735

Epoch: 6| Step: 1
Training loss: 1.6825738282464755
Validation loss: 2.749136818173262

Epoch: 6| Step: 2
Training loss: 0.7624406572606921
Validation loss: 2.8392883065421217

Epoch: 6| Step: 3
Training loss: 1.1880303252745583
Validation loss: 2.764045371977773

Epoch: 6| Step: 4
Training loss: 0.6616406877720139
Validation loss: 2.830756127943538

Epoch: 6| Step: 5
Training loss: 1.1588008682624322
Validation loss: 2.7175582085920027

Epoch: 6| Step: 6
Training loss: 1.0477302246375637
Validation loss: 2.905634490159203

Epoch: 6| Step: 7
Training loss: 0.9568727945991281
Validation loss: 2.8007274500150094

Epoch: 6| Step: 8
Training loss: 0.9255218786356442
Validation loss: 2.834524736301082

Epoch: 6| Step: 9
Training loss: 1.2543466335371733
Validation loss: 2.7727089368211075

Epoch: 6| Step: 10
Training loss: 1.3561305648319633
Validation loss: 2.8494514350097147

Epoch: 6| Step: 11
Training loss: 0.7454035097613252
Validation loss: 2.833927181130352

Epoch: 6| Step: 12
Training loss: 1.0840928032060424
Validation loss: 2.7542183701417966

Epoch: 6| Step: 13
Training loss: 0.8040655380529659
Validation loss: 2.7588895688273967

Epoch: 176| Step: 0
Training loss: 0.9300053798355858
Validation loss: 2.8286096217371424

Epoch: 6| Step: 1
Training loss: 1.015632335929786
Validation loss: 2.775490787854349

Epoch: 6| Step: 2
Training loss: 0.9508753633584955
Validation loss: 2.8220724459909867

Epoch: 6| Step: 3
Training loss: 0.8169248111309393
Validation loss: 2.787094903884741

Epoch: 6| Step: 4
Training loss: 1.2123562285140843
Validation loss: 2.7564362432020313

Epoch: 6| Step: 5
Training loss: 0.8088466230451303
Validation loss: 2.819119977106805

Epoch: 6| Step: 6
Training loss: 0.9112219731085384
Validation loss: 2.7057669193007055

Epoch: 6| Step: 7
Training loss: 1.8088618629731923
Validation loss: 2.770755527713747

Epoch: 6| Step: 8
Training loss: 0.573377083238402
Validation loss: 2.745790713553033

Epoch: 6| Step: 9
Training loss: 0.8702365780490942
Validation loss: 2.7757085537089914

Epoch: 6| Step: 10
Training loss: 0.9739427446283999
Validation loss: 2.8483494044505817

Epoch: 6| Step: 11
Training loss: 0.8865536439417673
Validation loss: 2.7141722216816238

Epoch: 6| Step: 12
Training loss: 0.9223363982483904
Validation loss: 2.8457731937813917

Epoch: 6| Step: 13
Training loss: 0.9314878326456784
Validation loss: 2.725479683376168

Epoch: 177| Step: 0
Training loss: 1.2846386919560473
Validation loss: 2.8258818130661894

Epoch: 6| Step: 1
Training loss: 0.7691298856513409
Validation loss: 2.8228035278920984

Epoch: 6| Step: 2
Training loss: 1.1174861268754772
Validation loss: 2.7430491094607383

Epoch: 6| Step: 3
Training loss: 0.8515956067290433
Validation loss: 2.8793062633526434

Epoch: 6| Step: 4
Training loss: 1.0787592694535166
Validation loss: 2.8258639828965855

Epoch: 6| Step: 5
Training loss: 1.3136027562665424
Validation loss: 2.936788919295042

Epoch: 6| Step: 6
Training loss: 1.733982144788531
Validation loss: 2.8853185111380233

Epoch: 6| Step: 7
Training loss: 0.9907858251716584
Validation loss: 2.894991214806948

Epoch: 6| Step: 8
Training loss: 1.1646027815303246
Validation loss: 2.802717035574449

Epoch: 6| Step: 9
Training loss: 1.0597460341760683
Validation loss: 2.727055298321386

Epoch: 6| Step: 10
Training loss: 0.7895941501235507
Validation loss: 2.778742170347142

Epoch: 6| Step: 11
Training loss: 1.0858041146231863
Validation loss: 2.792728298124904

Epoch: 6| Step: 12
Training loss: 0.9607542840235279
Validation loss: 2.8618279308084222

Epoch: 6| Step: 13
Training loss: 0.8065147763558245
Validation loss: 2.7421146973657238

Epoch: 178| Step: 0
Training loss: 0.935382486128121
Validation loss: 2.7249972159695184

Epoch: 6| Step: 1
Training loss: 0.6730484584406704
Validation loss: 2.778943780848123

Epoch: 6| Step: 2
Training loss: 0.7918139538195692
Validation loss: 2.7996221366865752

Epoch: 6| Step: 3
Training loss: 0.8872912739053254
Validation loss: 2.9154163382693903

Epoch: 6| Step: 4
Training loss: 1.6488887657323712
Validation loss: 2.82836879290635

Epoch: 6| Step: 5
Training loss: 0.9513506398242995
Validation loss: 2.8173180883984763

Epoch: 6| Step: 6
Training loss: 1.0809112701806753
Validation loss: 2.817875281915641

Epoch: 6| Step: 7
Training loss: 0.6807206293187049
Validation loss: 2.74952436437574

Epoch: 6| Step: 8
Training loss: 1.477160458867023
Validation loss: 2.7799016491555895

Epoch: 6| Step: 9
Training loss: 1.0056657030629705
Validation loss: 2.756568606553354

Epoch: 6| Step: 10
Training loss: 0.7993347501426699
Validation loss: 2.800310919165622

Epoch: 6| Step: 11
Training loss: 0.6586380605396354
Validation loss: 2.7671162523416664

Epoch: 6| Step: 12
Training loss: 0.8969445470767413
Validation loss: 2.726983301141201

Epoch: 6| Step: 13
Training loss: 0.6814401107593925
Validation loss: 2.7505035228409658

Epoch: 179| Step: 0
Training loss: 0.997173397403219
Validation loss: 2.8159450483180404

Epoch: 6| Step: 1
Training loss: 0.764302337386767
Validation loss: 2.752685824758624

Epoch: 6| Step: 2
Training loss: 0.7715746090426615
Validation loss: 2.8358260203747467

Epoch: 6| Step: 3
Training loss: 0.9662947766982098
Validation loss: 2.842825078937452

Epoch: 6| Step: 4
Training loss: 1.4369581279295265
Validation loss: 2.706206753497556

Epoch: 6| Step: 5
Training loss: 0.728927414107457
Validation loss: 2.8152593075293213

Epoch: 6| Step: 6
Training loss: 1.8145675048254561
Validation loss: 2.8495629324036096

Epoch: 6| Step: 7
Training loss: 0.955364036280536
Validation loss: 2.7798024100013827

Epoch: 6| Step: 8
Training loss: 0.6867425821137695
Validation loss: 2.847467884589288

Epoch: 6| Step: 9
Training loss: 0.9136476471923202
Validation loss: 2.8218116544736764

Epoch: 6| Step: 10
Training loss: 0.7353981276886952
Validation loss: 2.8225381792187654

Epoch: 6| Step: 11
Training loss: 1.2643489291510417
Validation loss: 2.8359511053706514

Epoch: 6| Step: 12
Training loss: 0.9617029878268258
Validation loss: 2.8164617962414655

Epoch: 6| Step: 13
Training loss: 0.7744314184565007
Validation loss: 2.828897044143931

Epoch: 180| Step: 0
Training loss: 1.325481431696459
Validation loss: 2.807657240429886

Epoch: 6| Step: 1
Training loss: 1.1645384973801824
Validation loss: 2.827505546157394

Epoch: 6| Step: 2
Training loss: 0.8385225771672034
Validation loss: 2.8497911499418596

Epoch: 6| Step: 3
Training loss: 0.6952717372646962
Validation loss: 2.781609858402683

Epoch: 6| Step: 4
Training loss: 1.2197532437096288
Validation loss: 2.827217223319437

Epoch: 6| Step: 5
Training loss: 0.5668454802038928
Validation loss: 2.8538341374915133

Epoch: 6| Step: 6
Training loss: 1.0506474860041315
Validation loss: 2.797111714324855

Epoch: 6| Step: 7
Training loss: 0.9493247392922636
Validation loss: 2.7909569810882133

Epoch: 6| Step: 8
Training loss: 0.7681942085890001
Validation loss: 2.8384009836780804

Epoch: 6| Step: 9
Training loss: 1.0725115162335617
Validation loss: 2.847685051080348

Epoch: 6| Step: 10
Training loss: 0.9975087008180443
Validation loss: 2.8665367517493543

Epoch: 6| Step: 11
Training loss: 0.8315511401811511
Validation loss: 2.8235734313995975

Epoch: 6| Step: 12
Training loss: 0.70514040431505
Validation loss: 2.907053299775565

Epoch: 6| Step: 13
Training loss: 1.7422247228366612
Validation loss: 2.8471088485062017

Epoch: 181| Step: 0
Training loss: 0.545834095665591
Validation loss: 2.829690292809195

Epoch: 6| Step: 1
Training loss: 0.7261299158114772
Validation loss: 2.7719737027101172

Epoch: 6| Step: 2
Training loss: 1.2174749306794312
Validation loss: 2.7816384647837586

Epoch: 6| Step: 3
Training loss: 0.9629005601846244
Validation loss: 2.7809210450588338

Epoch: 6| Step: 4
Training loss: 0.8110796177279023
Validation loss: 2.8118569804621303

Epoch: 6| Step: 5
Training loss: 1.053284679951082
Validation loss: 2.6904257292582803

Epoch: 6| Step: 6
Training loss: 0.93874337078451
Validation loss: 2.7825394188190034

Epoch: 6| Step: 7
Training loss: 1.0487472531415685
Validation loss: 2.804414131917964

Epoch: 6| Step: 8
Training loss: 0.5603108723367346
Validation loss: 2.931024014262113

Epoch: 6| Step: 9
Training loss: 1.1945517119706546
Validation loss: 2.867029876949816

Epoch: 6| Step: 10
Training loss: 1.1351603414064042
Validation loss: 2.934911723913293

Epoch: 6| Step: 11
Training loss: 1.6755764353685358
Validation loss: 2.7921711242912832

Epoch: 6| Step: 12
Training loss: 0.9594134829379528
Validation loss: 2.8256716405232174

Epoch: 6| Step: 13
Training loss: 0.7336132887898186
Validation loss: 2.7990619626516207

Epoch: 182| Step: 0
Training loss: 1.7203004952686627
Validation loss: 2.7985824544579025

Epoch: 6| Step: 1
Training loss: 0.9677665086607885
Validation loss: 2.8128277199157563

Epoch: 6| Step: 2
Training loss: 0.7904675127069879
Validation loss: 2.6558297965588067

Epoch: 6| Step: 3
Training loss: 0.8074903838349792
Validation loss: 2.73469978946724

Epoch: 6| Step: 4
Training loss: 0.6321811116414818
Validation loss: 2.703034945184112

Epoch: 6| Step: 5
Training loss: 0.6259580898088494
Validation loss: 2.748245893590707

Epoch: 6| Step: 6
Training loss: 0.9983909297583072
Validation loss: 2.8522212412902284

Epoch: 6| Step: 7
Training loss: 0.7282824923085893
Validation loss: 2.8467206285694067

Epoch: 6| Step: 8
Training loss: 0.8586053349387615
Validation loss: 2.7852747795204076

Epoch: 6| Step: 9
Training loss: 1.320268302945193
Validation loss: 2.849055249636369

Epoch: 6| Step: 10
Training loss: 0.7993240123053662
Validation loss: 2.813596102147805

Epoch: 6| Step: 11
Training loss: 0.7309465120892646
Validation loss: 2.8486119303233792

Epoch: 6| Step: 12
Training loss: 1.089440985742275
Validation loss: 2.785886436075723

Epoch: 6| Step: 13
Training loss: 1.0652525533391741
Validation loss: 2.7526009282021193

Epoch: 183| Step: 0
Training loss: 0.9027487436337049
Validation loss: 2.7420763824642207

Epoch: 6| Step: 1
Training loss: 0.9275756700191367
Validation loss: 2.7370116391903703

Epoch: 6| Step: 2
Training loss: 0.6307689023173588
Validation loss: 2.7910120514441275

Epoch: 6| Step: 3
Training loss: 0.9132476500244148
Validation loss: 2.7865279477178913

Epoch: 6| Step: 4
Training loss: 1.155417168157785
Validation loss: 2.8001428760678686

Epoch: 6| Step: 5
Training loss: 0.8388079976526001
Validation loss: 2.7994146768401644

Epoch: 6| Step: 6
Training loss: 0.7411803388750641
Validation loss: 2.8435237501080572

Epoch: 6| Step: 7
Training loss: 0.7440636462347373
Validation loss: 2.679649093248895

Epoch: 6| Step: 8
Training loss: 0.8176713841993324
Validation loss: 2.745669133588337

Epoch: 6| Step: 9
Training loss: 0.9621038104510881
Validation loss: 2.85279444729166

Epoch: 6| Step: 10
Training loss: 1.547609482375827
Validation loss: 2.8196495171576452

Epoch: 6| Step: 11
Training loss: 0.5535749641868085
Validation loss: 2.7969631415602496

Epoch: 6| Step: 12
Training loss: 0.7502278140892552
Validation loss: 2.8182341154994224

Epoch: 6| Step: 13
Training loss: 1.2427699804670114
Validation loss: 2.803503893616455

Epoch: 184| Step: 0
Training loss: 0.9472677329128447
Validation loss: 2.78222857629523

Epoch: 6| Step: 1
Training loss: 0.6097229184451095
Validation loss: 2.8178814301879314

Epoch: 6| Step: 2
Training loss: 0.7200651161895287
Validation loss: 2.8550320216096177

Epoch: 6| Step: 3
Training loss: 0.7682665972023195
Validation loss: 2.7783924524721892

Epoch: 6| Step: 4
Training loss: 1.0939913892040969
Validation loss: 2.7244297930055748

Epoch: 6| Step: 5
Training loss: 0.7490372836786552
Validation loss: 2.8270059974641875

Epoch: 6| Step: 6
Training loss: 1.0399123423571248
Validation loss: 2.8498501866545403

Epoch: 6| Step: 7
Training loss: 0.9948722380652387
Validation loss: 2.7505736619647925

Epoch: 6| Step: 8
Training loss: 0.8762615169905613
Validation loss: 2.8205938366222827

Epoch: 6| Step: 9
Training loss: 0.5859075920101412
Validation loss: 2.8293716605467094

Epoch: 6| Step: 10
Training loss: 0.9108179658487429
Validation loss: 2.783120073116661

Epoch: 6| Step: 11
Training loss: 0.7352801487100663
Validation loss: 2.820802253334049

Epoch: 6| Step: 12
Training loss: 1.607021573955093
Validation loss: 2.761336627946574

Epoch: 6| Step: 13
Training loss: 1.0917241544850438
Validation loss: 2.8416001993574107

Epoch: 185| Step: 0
Training loss: 0.961907618157347
Validation loss: 2.800010997319196

Epoch: 6| Step: 1
Training loss: 1.032161309986658
Validation loss: 2.8106819281207462

Epoch: 6| Step: 2
Training loss: 1.6115756497855411
Validation loss: 2.851209491496052

Epoch: 6| Step: 3
Training loss: 0.6314077916606763
Validation loss: 2.750897911174322

Epoch: 6| Step: 4
Training loss: 0.6514818585300666
Validation loss: 2.7881236486339738

Epoch: 6| Step: 5
Training loss: 1.237170518496975
Validation loss: 2.792127533254308

Epoch: 6| Step: 6
Training loss: 0.7302894576244542
Validation loss: 2.720636612078447

Epoch: 6| Step: 7
Training loss: 0.7829284186206149
Validation loss: 2.6826086702640923

Epoch: 6| Step: 8
Training loss: 0.9745627413125376
Validation loss: 2.7830786033570605

Epoch: 6| Step: 9
Training loss: 0.7348591446364054
Validation loss: 2.700712770405472

Epoch: 6| Step: 10
Training loss: 0.596405140948445
Validation loss: 2.8443190735351056

Epoch: 6| Step: 11
Training loss: 1.0478637353309137
Validation loss: 2.787803700642759

Epoch: 6| Step: 12
Training loss: 0.4369949081853151
Validation loss: 2.890297927910449

Epoch: 6| Step: 13
Training loss: 0.7226112970340675
Validation loss: 2.824410086904354

Epoch: 186| Step: 0
Training loss: 0.9170855554856782
Validation loss: 2.756958120415177

Epoch: 6| Step: 1
Training loss: 1.031328834063582
Validation loss: 2.7721468219131253

Epoch: 6| Step: 2
Training loss: 1.2072379419826988
Validation loss: 2.7498396913446577

Epoch: 6| Step: 3
Training loss: 0.6393295541536586
Validation loss: 2.8145193691783295

Epoch: 6| Step: 4
Training loss: 0.8380936241108559
Validation loss: 2.7784109162282493

Epoch: 6| Step: 5
Training loss: 0.6427172246490049
Validation loss: 2.893022385059775

Epoch: 6| Step: 6
Training loss: 1.6082801427923543
Validation loss: 2.8446185563695288

Epoch: 6| Step: 7
Training loss: 0.8387227228223303
Validation loss: 2.8239835761694025

Epoch: 6| Step: 8
Training loss: 1.0978141481043484
Validation loss: 2.8446837209314437

Epoch: 6| Step: 9
Training loss: 0.9776038454218184
Validation loss: 2.790190510460878

Epoch: 6| Step: 10
Training loss: 0.526925436753028
Validation loss: 2.813938924253151

Epoch: 6| Step: 11
Training loss: 0.6984934321458579
Validation loss: 2.840381891404169

Epoch: 6| Step: 12
Training loss: 0.7179477194610576
Validation loss: 2.8591239832915765

Epoch: 6| Step: 13
Training loss: 0.9334470881099605
Validation loss: 2.7699432281846

Epoch: 187| Step: 0
Training loss: 1.0232663775936106
Validation loss: 2.8043653042759353

Epoch: 6| Step: 1
Training loss: 0.838027480537474
Validation loss: 2.7400212004460918

Epoch: 6| Step: 2
Training loss: 0.7239381709595886
Validation loss: 2.8447330997285856

Epoch: 6| Step: 3
Training loss: 0.9027166215445832
Validation loss: 2.8071397918403407

Epoch: 6| Step: 4
Training loss: 0.6790804289457939
Validation loss: 2.765071978836458

Epoch: 6| Step: 5
Training loss: 1.338463119201081
Validation loss: 2.8886727003569646

Epoch: 6| Step: 6
Training loss: 1.5854944070544763
Validation loss: 2.8460220929644526

Epoch: 6| Step: 7
Training loss: 1.2256364667590456
Validation loss: 2.9042854231895316

Epoch: 6| Step: 8
Training loss: 0.5736431428721408
Validation loss: 2.859629030877389

Epoch: 6| Step: 9
Training loss: 0.8204603516078555
Validation loss: 2.8237806501859857

Epoch: 6| Step: 10
Training loss: 0.8156076202879415
Validation loss: 2.8561182009771735

Epoch: 6| Step: 11
Training loss: 0.7588383132091956
Validation loss: 2.8603107331829407

Epoch: 6| Step: 12
Training loss: 0.7231202981148118
Validation loss: 2.865302579345792

Epoch: 6| Step: 13
Training loss: 0.6217194290713475
Validation loss: 2.8450237886722607

Epoch: 188| Step: 0
Training loss: 0.7761214725158025
Validation loss: 2.7351746906558523

Epoch: 6| Step: 1
Training loss: 1.1871240924350932
Validation loss: 2.882872803978254

Epoch: 6| Step: 2
Training loss: 0.8805079805964526
Validation loss: 2.826809993639973

Epoch: 6| Step: 3
Training loss: 1.2506949400325689
Validation loss: 2.7654426284689495

Epoch: 6| Step: 4
Training loss: 0.8264632917261364
Validation loss: 2.764404487334723

Epoch: 6| Step: 5
Training loss: 0.889933736134544
Validation loss: 2.8632540352409688

Epoch: 6| Step: 6
Training loss: 0.5729144327524733
Validation loss: 2.870067719315208

Epoch: 6| Step: 7
Training loss: 0.678260642869844
Validation loss: 2.8902347610582675

Epoch: 6| Step: 8
Training loss: 0.7126648009593702
Validation loss: 2.967152938922725

Epoch: 6| Step: 9
Training loss: 0.740018546413294
Validation loss: 2.794502416982224

Epoch: 6| Step: 10
Training loss: 0.8458888882838109
Validation loss: 2.908463793691364

Epoch: 6| Step: 11
Training loss: 0.8052257478384522
Validation loss: 2.797519559840144

Epoch: 6| Step: 12
Training loss: 1.8088407739139272
Validation loss: 2.8173012618631366

Epoch: 6| Step: 13
Training loss: 0.7602682926921367
Validation loss: 2.7802705790437243

Epoch: 189| Step: 0
Training loss: 0.5426730716205888
Validation loss: 2.913850641944083

Epoch: 6| Step: 1
Training loss: 1.023389800612703
Validation loss: 2.8565638886535183

Epoch: 6| Step: 2
Training loss: 0.8171716050303456
Validation loss: 2.792933494505414

Epoch: 6| Step: 3
Training loss: 1.1608421789700842
Validation loss: 2.8112743956831916

Epoch: 6| Step: 4
Training loss: 1.6218608466028792
Validation loss: 2.767127525100398

Epoch: 6| Step: 5
Training loss: 0.8017737216277102
Validation loss: 2.8573285754901874

Epoch: 6| Step: 6
Training loss: 1.2085139972632157
Validation loss: 2.7875683768970885

Epoch: 6| Step: 7
Training loss: 0.7836819752158386
Validation loss: 2.846216871481765

Epoch: 6| Step: 8
Training loss: 0.5535195640579946
Validation loss: 2.8537288989037335

Epoch: 6| Step: 9
Training loss: 0.5331673243314775
Validation loss: 2.7381809450245087

Epoch: 6| Step: 10
Training loss: 0.6439199149318615
Validation loss: 2.7839158958012025

Epoch: 6| Step: 11
Training loss: 1.0277011380245644
Validation loss: 2.8465994438085436

Epoch: 6| Step: 12
Training loss: 0.6883767995857585
Validation loss: 2.779798364599526

Epoch: 6| Step: 13
Training loss: 0.7351010973812543
Validation loss: 2.7814371138933733

Epoch: 190| Step: 0
Training loss: 0.7670377814426095
Validation loss: 2.8037489770328166

Epoch: 6| Step: 1
Training loss: 0.888438468715208
Validation loss: 2.7810487852996824

Epoch: 6| Step: 2
Training loss: 0.8484025473797876
Validation loss: 2.7858899306256375

Epoch: 6| Step: 3
Training loss: 0.7561119899453462
Validation loss: 2.8322401929926815

Epoch: 6| Step: 4
Training loss: 1.5776691344888196
Validation loss: 2.794512633675

Epoch: 6| Step: 5
Training loss: 1.0423615363217094
Validation loss: 2.8713220899093264

Epoch: 6| Step: 6
Training loss: 1.0022427324396463
Validation loss: 2.8398798363521

Epoch: 6| Step: 7
Training loss: 0.8487546633562791
Validation loss: 2.797434930144059

Epoch: 6| Step: 8
Training loss: 0.7456581481830137
Validation loss: 2.8230623346073203

Epoch: 6| Step: 9
Training loss: 0.8513790948030301
Validation loss: 2.8697724015731017

Epoch: 6| Step: 10
Training loss: 0.748131331414605
Validation loss: 2.7940637251627938

Epoch: 6| Step: 11
Training loss: 0.9660029069963394
Validation loss: 2.8061849126368936

Epoch: 6| Step: 12
Training loss: 0.8849903351854087
Validation loss: 2.805135622060776

Epoch: 6| Step: 13
Training loss: 1.0635014470659534
Validation loss: 2.7954909169442916

Epoch: 191| Step: 0
Training loss: 1.2142472842089713
Validation loss: 2.820002615433691

Epoch: 6| Step: 1
Training loss: 0.752046732835284
Validation loss: 2.7186946936349607

Epoch: 6| Step: 2
Training loss: 0.5668311531328183
Validation loss: 2.774302058614904

Epoch: 6| Step: 3
Training loss: 0.6046277265552292
Validation loss: 2.8099661115048677

Epoch: 6| Step: 4
Training loss: 1.0296624998261705
Validation loss: 2.8989905269332494

Epoch: 6| Step: 5
Training loss: 0.82131827321762
Validation loss: 2.9712358474019926

Epoch: 6| Step: 6
Training loss: 1.1283353530174522
Validation loss: 2.8377977755524117

Epoch: 6| Step: 7
Training loss: 0.7432141882374644
Validation loss: 2.876526220156069

Epoch: 6| Step: 8
Training loss: 0.6597636483108062
Validation loss: 2.8117146066499275

Epoch: 6| Step: 9
Training loss: 1.7086671720130184
Validation loss: 2.8401792416402105

Epoch: 6| Step: 10
Training loss: 0.8648542684382344
Validation loss: 2.8749995300734867

Epoch: 6| Step: 11
Training loss: 0.9294092098422522
Validation loss: 2.753564085569799

Epoch: 6| Step: 12
Training loss: 1.1736538927505702
Validation loss: 2.851925594258084

Epoch: 6| Step: 13
Training loss: 0.8288411696446029
Validation loss: 2.842423335674045

Epoch: 192| Step: 0
Training loss: 0.8312730513510015
Validation loss: 2.7953035568057283

Epoch: 6| Step: 1
Training loss: 0.6530153848754742
Validation loss: 2.922692393650715

Epoch: 6| Step: 2
Training loss: 0.8988503875694239
Validation loss: 2.8594671627124053

Epoch: 6| Step: 3
Training loss: 1.1920585472590612
Validation loss: 2.913379933561402

Epoch: 6| Step: 4
Training loss: 0.9925549945440638
Validation loss: 2.9536697988536216

Epoch: 6| Step: 5
Training loss: 1.063831336725405
Validation loss: 2.94617973531935

Epoch: 6| Step: 6
Training loss: 1.6593136073822943
Validation loss: 2.8614161281484276

Epoch: 6| Step: 7
Training loss: 0.995398484472892
Validation loss: 2.837933457102318

Epoch: 6| Step: 8
Training loss: 0.6199050660669877
Validation loss: 2.7843239188369826

Epoch: 6| Step: 9
Training loss: 0.5937708047936168
Validation loss: 2.7894432171329258

Epoch: 6| Step: 10
Training loss: 0.7366007090366006
Validation loss: 2.766046912128539

Epoch: 6| Step: 11
Training loss: 0.7359384168226358
Validation loss: 2.7595111921318116

Epoch: 6| Step: 12
Training loss: 0.7655706191699423
Validation loss: 2.818121160043647

Epoch: 6| Step: 13
Training loss: 0.5697326325049726
Validation loss: 2.909167469515909

Epoch: 193| Step: 0
Training loss: 0.7969939199237255
Validation loss: 2.8957986257837938

Epoch: 6| Step: 1
Training loss: 0.6703098608289573
Validation loss: 2.815369025706107

Epoch: 6| Step: 2
Training loss: 1.607739256144189
Validation loss: 2.7915109809241803

Epoch: 6| Step: 3
Training loss: 0.8059372317434621
Validation loss: 2.854664937726916

Epoch: 6| Step: 4
Training loss: 0.4959873025186045
Validation loss: 2.804652887695731

Epoch: 6| Step: 5
Training loss: 0.7904548446840766
Validation loss: 2.8901786459581826

Epoch: 6| Step: 6
Training loss: 0.7140563630689682
Validation loss: 2.816588277309078

Epoch: 6| Step: 7
Training loss: 1.0761879367633636
Validation loss: 2.9171875193425105

Epoch: 6| Step: 8
Training loss: 0.7319366068202242
Validation loss: 2.8110257982879383

Epoch: 6| Step: 9
Training loss: 1.255463106039449
Validation loss: 2.7458629845816085

Epoch: 6| Step: 10
Training loss: 0.9092466204761109
Validation loss: 2.767287406647195

Epoch: 6| Step: 11
Training loss: 0.9879055289052671
Validation loss: 2.9010109389005843

Epoch: 6| Step: 12
Training loss: 1.2158872287214118
Validation loss: 2.852406081743916

Epoch: 6| Step: 13
Training loss: 0.6423704281265863
Validation loss: 2.7336709414915665

Epoch: 194| Step: 0
Training loss: 0.432320469352503
Validation loss: 2.808919018553733

Epoch: 6| Step: 1
Training loss: 1.0579968560862567
Validation loss: 2.8149429731538356

Epoch: 6| Step: 2
Training loss: 1.0382288980596885
Validation loss: 2.8043749111745986

Epoch: 6| Step: 3
Training loss: 0.8055179347830445
Validation loss: 2.8212747385328876

Epoch: 6| Step: 4
Training loss: 0.722364707080011
Validation loss: 2.856409435427291

Epoch: 6| Step: 5
Training loss: 0.5625023047082098
Validation loss: 2.8129431198866013

Epoch: 6| Step: 6
Training loss: 0.46237377493397747
Validation loss: 2.834297217241452

Epoch: 6| Step: 7
Training loss: 0.9835333480650168
Validation loss: 2.902996279104496

Epoch: 6| Step: 8
Training loss: 0.5686686614844935
Validation loss: 2.7684625268271352

Epoch: 6| Step: 9
Training loss: 0.94728406121315
Validation loss: 2.866121944711741

Epoch: 6| Step: 10
Training loss: 1.620881804433652
Validation loss: 2.783362133101742

Epoch: 6| Step: 11
Training loss: 1.2454418522030377
Validation loss: 2.7275675876727004

Epoch: 6| Step: 12
Training loss: 0.5368628473649469
Validation loss: 2.854204265783059

Epoch: 6| Step: 13
Training loss: 0.697240919856229
Validation loss: 2.8233654796236993

Epoch: 195| Step: 0
Training loss: 0.5958843518358129
Validation loss: 2.8116771059307895

Epoch: 6| Step: 1
Training loss: 0.7578740045816842
Validation loss: 2.814093879893296

Epoch: 6| Step: 2
Training loss: 0.8284396167729523
Validation loss: 2.8628571921851558

Epoch: 6| Step: 3
Training loss: 0.49811381469861693
Validation loss: 2.782192084956977

Epoch: 6| Step: 4
Training loss: 0.9600540069448779
Validation loss: 2.9052299910857706

Epoch: 6| Step: 5
Training loss: 0.7498142489245718
Validation loss: 2.8268705223757054

Epoch: 6| Step: 6
Training loss: 1.564992594960399
Validation loss: 2.782270230108697

Epoch: 6| Step: 7
Training loss: 0.8516338213529934
Validation loss: 2.8578076122889393

Epoch: 6| Step: 8
Training loss: 1.016159503844159
Validation loss: 2.872485623148018

Epoch: 6| Step: 9
Training loss: 0.7726600670021129
Validation loss: 2.80429931617847

Epoch: 6| Step: 10
Training loss: 1.143783064400778
Validation loss: 2.775898746630943

Epoch: 6| Step: 11
Training loss: 0.46057237290842024
Validation loss: 2.82850673902254

Epoch: 6| Step: 12
Training loss: 0.6722944857460719
Validation loss: 2.8761559802287127

Epoch: 6| Step: 13
Training loss: 0.6074344596908382
Validation loss: 2.845258724759581

Epoch: 196| Step: 0
Training loss: 0.6653582329394134
Validation loss: 2.8499425597843957

Epoch: 6| Step: 1
Training loss: 0.5222811095311096
Validation loss: 2.8399163979775226

Epoch: 6| Step: 2
Training loss: 0.5466235536442343
Validation loss: 2.7597242578572447

Epoch: 6| Step: 3
Training loss: 0.8131580622267904
Validation loss: 2.8139673290719402

Epoch: 6| Step: 4
Training loss: 0.8447118151485454
Validation loss: 2.7704590613963984

Epoch: 6| Step: 5
Training loss: 1.6442070503257247
Validation loss: 2.7559786094214673

Epoch: 6| Step: 6
Training loss: 0.5258089690249145
Validation loss: 2.78430818448316

Epoch: 6| Step: 7
Training loss: 0.5788161038985866
Validation loss: 2.8001070013491116

Epoch: 6| Step: 8
Training loss: 0.6340845768047721
Validation loss: 2.772527805196967

Epoch: 6| Step: 9
Training loss: 0.8635437855312978
Validation loss: 2.873286261700324

Epoch: 6| Step: 10
Training loss: 1.1498001215179745
Validation loss: 2.854350429847079

Epoch: 6| Step: 11
Training loss: 0.6945669055621532
Validation loss: 2.8727235765601646

Epoch: 6| Step: 12
Training loss: 0.8446541286570157
Validation loss: 2.8520629165026383

Epoch: 6| Step: 13
Training loss: 1.0809116561813126
Validation loss: 2.690451103259064

Epoch: 197| Step: 0
Training loss: 0.7664876476618847
Validation loss: 2.790048505094824

Epoch: 6| Step: 1
Training loss: 0.6680631961196126
Validation loss: 2.7263753147233207

Epoch: 6| Step: 2
Training loss: 0.8537873767361943
Validation loss: 2.7934440866317223

Epoch: 6| Step: 3
Training loss: 0.7985222937541797
Validation loss: 2.850261499443331

Epoch: 6| Step: 4
Training loss: 0.7235928626107557
Validation loss: 2.8275690041533554

Epoch: 6| Step: 5
Training loss: 0.8626542727394708
Validation loss: 2.784315855437741

Epoch: 6| Step: 6
Training loss: 0.8397884971718458
Validation loss: 2.8341906643570955

Epoch: 6| Step: 7
Training loss: 0.4062569324195358
Validation loss: 2.8085889608442267

Epoch: 6| Step: 8
Training loss: 1.130657698546987
Validation loss: 2.755727309233153

Epoch: 6| Step: 9
Training loss: 0.7529317457514831
Validation loss: 2.8691659280947945

Epoch: 6| Step: 10
Training loss: 1.4804492637136943
Validation loss: 2.8250816226521693

Epoch: 6| Step: 11
Training loss: 0.9871462610898607
Validation loss: 2.8242278391303577

Epoch: 6| Step: 12
Training loss: 0.8230657241321314
Validation loss: 2.813982085625752

Epoch: 6| Step: 13
Training loss: 0.7470900190160265
Validation loss: 2.799859129677203

Epoch: 198| Step: 0
Training loss: 1.1156448704421895
Validation loss: 2.790943213329448

Epoch: 6| Step: 1
Training loss: 0.8192763551274147
Validation loss: 2.9334890158116935

Epoch: 6| Step: 2
Training loss: 0.7133980395331581
Validation loss: 2.812911844122739

Epoch: 6| Step: 3
Training loss: 0.8075609106823631
Validation loss: 2.8695589630065497

Epoch: 6| Step: 4
Training loss: 0.754168805669066
Validation loss: 2.8962156240118704

Epoch: 6| Step: 5
Training loss: 0.6897514713557866
Validation loss: 2.8412623721008754

Epoch: 6| Step: 6
Training loss: 1.502472508666127
Validation loss: 2.815227055344925

Epoch: 6| Step: 7
Training loss: 0.6517877550709049
Validation loss: 2.8562118947876987

Epoch: 6| Step: 8
Training loss: 0.7159439958455028
Validation loss: 2.8215843636807847

Epoch: 6| Step: 9
Training loss: 0.705660085827909
Validation loss: 2.835445343833007

Epoch: 6| Step: 10
Training loss: 0.6757326053465048
Validation loss: 2.80332940815376

Epoch: 6| Step: 11
Training loss: 0.6098773304135755
Validation loss: 2.841050330263505

Epoch: 6| Step: 12
Training loss: 0.6586198704292276
Validation loss: 2.790062120605155

Epoch: 6| Step: 13
Training loss: 0.7343195630515619
Validation loss: 2.9035828770311434

Epoch: 199| Step: 0
Training loss: 0.5117271073219473
Validation loss: 2.7794804176244163

Epoch: 6| Step: 1
Training loss: 0.8370625776987118
Validation loss: 2.7973065886853914

Epoch: 6| Step: 2
Training loss: 0.7208888117070842
Validation loss: 2.9082209968914423

Epoch: 6| Step: 3
Training loss: 0.42583094315626363
Validation loss: 2.8635808589321337

Epoch: 6| Step: 4
Training loss: 0.5940135571637741
Validation loss: 2.8973830259429665

Epoch: 6| Step: 5
Training loss: 0.733433627365024
Validation loss: 2.820248589887893

Epoch: 6| Step: 6
Training loss: 0.7418226047772241
Validation loss: 2.8522821363141695

Epoch: 6| Step: 7
Training loss: 1.4856986318146106
Validation loss: 2.810883057232996

Epoch: 6| Step: 8
Training loss: 0.7196909922864148
Validation loss: 2.793959748134056

Epoch: 6| Step: 9
Training loss: 0.630292442846166
Validation loss: 2.848061447723656

Epoch: 6| Step: 10
Training loss: 1.0178351196736457
Validation loss: 2.831021106385272

Epoch: 6| Step: 11
Training loss: 1.0009427990685287
Validation loss: 2.8260987823110257

Epoch: 6| Step: 12
Training loss: 0.6778140062497446
Validation loss: 2.8779052208657703

Epoch: 6| Step: 13
Training loss: 0.7215337747743388
Validation loss: 2.775603130311397

Epoch: 200| Step: 0
Training loss: 0.5587108462651719
Validation loss: 2.7567914273845147

Epoch: 6| Step: 1
Training loss: 1.1918500230129447
Validation loss: 2.8340147872544406

Epoch: 6| Step: 2
Training loss: 0.6689877016322695
Validation loss: 2.8032664929207014

Epoch: 6| Step: 3
Training loss: 0.9658397830740101
Validation loss: 2.845433055007297

Epoch: 6| Step: 4
Training loss: 0.5548292435619178
Validation loss: 2.821416129946511

Epoch: 6| Step: 5
Training loss: 1.7184555495070897
Validation loss: 2.823336683794516

Epoch: 6| Step: 6
Training loss: 0.5234353933718977
Validation loss: 2.834256033624568

Epoch: 6| Step: 7
Training loss: 0.81107936051975
Validation loss: 2.891376892452042

Epoch: 6| Step: 8
Training loss: 0.687352988390657
Validation loss: 2.7635268677680584

Epoch: 6| Step: 9
Training loss: 0.7184135644749353
Validation loss: 2.7973167738286464

Epoch: 6| Step: 10
Training loss: 0.5000531049183625
Validation loss: 2.88950998606939

Epoch: 6| Step: 11
Training loss: 0.4571909503193822
Validation loss: 2.8029150786059116

Epoch: 6| Step: 12
Training loss: 0.4930162264879152
Validation loss: 2.7246099875391336

Epoch: 6| Step: 13
Training loss: 0.49821508222458666
Validation loss: 2.7652068531434106

Testing loss: 2.625021838691618
