Epoch: 1| Step: 0
Training loss: 6.378741195047691
Validation loss: 5.369303856592486

Epoch: 5| Step: 1
Training loss: 5.5534393582215635
Validation loss: 5.3490966090598535

Epoch: 5| Step: 2
Training loss: 4.7160697550318496
Validation loss: 5.330371312322418

Epoch: 5| Step: 3
Training loss: 5.8739765980312475
Validation loss: 5.307986002217991

Epoch: 5| Step: 4
Training loss: 4.382219951101166
Validation loss: 5.290271802973236

Epoch: 5| Step: 5
Training loss: 4.71769854218263
Validation loss: 5.274016872650978

Epoch: 5| Step: 6
Training loss: 4.992782533432381
Validation loss: 5.261119737632596

Epoch: 5| Step: 7
Training loss: 5.823197559913054
Validation loss: 5.247035915504113

Epoch: 5| Step: 8
Training loss: 5.541688541378741
Validation loss: 5.234280098581455

Epoch: 5| Step: 9
Training loss: 6.119210757557722
Validation loss: 5.217981232385792

Epoch: 5| Step: 10
Training loss: 4.797980861369639
Validation loss: 5.200849170918437

Epoch: 5| Step: 11
Training loss: 5.71493119272644
Validation loss: 5.1847017469983125

Epoch: 2| Step: 0
Training loss: 5.698870014818795
Validation loss: 5.166322568489442

Epoch: 5| Step: 1
Training loss: 4.952685989515405
Validation loss: 5.145603679314883

Epoch: 5| Step: 2
Training loss: 5.63566476930342
Validation loss: 5.1298613093654275

Epoch: 5| Step: 3
Training loss: 5.1355679111248635
Validation loss: 5.112633625513357

Epoch: 5| Step: 4
Training loss: 5.4822754060635885
Validation loss: 5.090613009643796

Epoch: 5| Step: 5
Training loss: 5.41607637367887
Validation loss: 5.069423101836034

Epoch: 5| Step: 6
Training loss: 4.667115099115156
Validation loss: 5.044215490706856

Epoch: 5| Step: 7
Training loss: 4.941418987755322
Validation loss: 5.027166190046212

Epoch: 5| Step: 8
Training loss: 5.082312351108353
Validation loss: 5.001939270326055

Epoch: 5| Step: 9
Training loss: 4.468286023362007
Validation loss: 4.972016058838338

Epoch: 5| Step: 10
Training loss: 5.689609010802129
Validation loss: 4.950413568476096

Epoch: 5| Step: 11
Training loss: 2.8249575755216774
Validation loss: 4.924194495817056

Epoch: 3| Step: 0
Training loss: 5.689645886388712
Validation loss: 4.898833182302657

Epoch: 5| Step: 1
Training loss: 5.360404135428334
Validation loss: 4.870585333735532

Epoch: 5| Step: 2
Training loss: 4.330865206008747
Validation loss: 4.8405361629548915

Epoch: 5| Step: 3
Training loss: 5.254181059843593
Validation loss: 4.807645826701908

Epoch: 5| Step: 4
Training loss: 5.39491026456375
Validation loss: 4.772984884377615

Epoch: 5| Step: 5
Training loss: 4.643817869283438
Validation loss: 4.739593173285809

Epoch: 5| Step: 6
Training loss: 4.398594042091079
Validation loss: 4.698637434089806

Epoch: 5| Step: 7
Training loss: 4.94855892898456
Validation loss: 4.65977690933562

Epoch: 5| Step: 8
Training loss: 4.528674847460727
Validation loss: 4.620959114699537

Epoch: 5| Step: 9
Training loss: 4.254305285749422
Validation loss: 4.578020526444722

Epoch: 5| Step: 10
Training loss: 4.556613835379886
Validation loss: 4.539132665375265

Epoch: 5| Step: 11
Training loss: 2.8433535792117053
Validation loss: 4.492522570511423

Epoch: 4| Step: 0
Training loss: 3.5365547238202315
Validation loss: 4.446452785096997

Epoch: 5| Step: 1
Training loss: 4.748732949969598
Validation loss: 4.393287629660144

Epoch: 5| Step: 2
Training loss: 5.03847085007744
Validation loss: 4.344384702787731

Epoch: 5| Step: 3
Training loss: 4.202850900100617
Validation loss: 4.281210692659165

Epoch: 5| Step: 4
Training loss: 4.806296970648855
Validation loss: 4.233619439539355

Epoch: 5| Step: 5
Training loss: 4.024558968400975
Validation loss: 4.168532467170287

Epoch: 5| Step: 6
Training loss: 4.394319222315591
Validation loss: 4.098988808789641

Epoch: 5| Step: 7
Training loss: 3.8721270832455525
Validation loss: 4.033771386804538

Epoch: 5| Step: 8
Training loss: 4.317128227232901
Validation loss: 3.9629587186725925

Epoch: 5| Step: 9
Training loss: 4.123560105062551
Validation loss: 3.8895169560810308

Epoch: 5| Step: 10
Training loss: 3.375077988465253
Validation loss: 3.80159635516989

Epoch: 5| Step: 11
Training loss: 3.26683408995827
Validation loss: 3.7308386973743732

Epoch: 5| Step: 0
Training loss: 3.238551442616308
Validation loss: 3.6413812411265947

Epoch: 5| Step: 1
Training loss: 3.8966412581982413
Validation loss: 3.570473108776285

Epoch: 5| Step: 2
Training loss: 4.125276729664748
Validation loss: 3.473879083571153

Epoch: 5| Step: 3
Training loss: 2.627824716728992
Validation loss: 3.38195979741289

Epoch: 5| Step: 4
Training loss: 3.288698008585587
Validation loss: 3.290873804253291

Epoch: 5| Step: 5
Training loss: 3.144543684466875
Validation loss: 3.2132630631884136

Epoch: 5| Step: 6
Training loss: 3.0787912025435995
Validation loss: 3.1148822581437807

Epoch: 5| Step: 7
Training loss: 3.127251843701288
Validation loss: 3.0219565846351784

Epoch: 5| Step: 8
Training loss: 2.195024030201962
Validation loss: 2.947108084831208

Epoch: 5| Step: 9
Training loss: 3.7395239411776235
Validation loss: 2.8741416548225636

Epoch: 5| Step: 10
Training loss: 2.921678016264814
Validation loss: 2.8170748801843453

Epoch: 5| Step: 11
Training loss: 3.006330962488672
Validation loss: 2.7601763866621116

Epoch: 6| Step: 0
Training loss: 2.0598777516210847
Validation loss: 2.70576858247031

Epoch: 5| Step: 1
Training loss: 3.021329711822108
Validation loss: 2.6810606430935007

Epoch: 5| Step: 2
Training loss: 2.5367555437629887
Validation loss: 2.6549239158325055

Epoch: 5| Step: 3
Training loss: 2.4425692542418482
Validation loss: 2.6301208569675474

Epoch: 5| Step: 4
Training loss: 2.3371201395242447
Validation loss: 2.660476530850853

Epoch: 5| Step: 5
Training loss: 2.933597163415541
Validation loss: 2.6797390034789217

Epoch: 5| Step: 6
Training loss: 2.2698841969532553
Validation loss: 2.690288088119077

Epoch: 5| Step: 7
Training loss: 2.6190360302276514
Validation loss: 2.7368640760523304

Epoch: 5| Step: 8
Training loss: 3.388391840464495
Validation loss: 2.730774050604492

Epoch: 5| Step: 9
Training loss: 2.510750543913554
Validation loss: 2.7501681774906546

Epoch: 5| Step: 10
Training loss: 3.1158880522552495
Validation loss: 2.788152900777961

Epoch: 5| Step: 11
Training loss: 2.391435074531241
Validation loss: 2.7600897913357842

Epoch: 7| Step: 0
Training loss: 2.3074241812536087
Validation loss: 2.744127281219874

Epoch: 5| Step: 1
Training loss: 2.5619908268903524
Validation loss: 2.7888467350837263

Epoch: 5| Step: 2
Training loss: 2.967333164426201
Validation loss: 2.7649254425992447

Epoch: 5| Step: 3
Training loss: 3.233028112995454
Validation loss: 2.749672008591723

Epoch: 5| Step: 4
Training loss: 2.0647607608417298
Validation loss: 2.7240021169047877

Epoch: 5| Step: 5
Training loss: 2.186289425075123
Validation loss: 2.696109565416551

Epoch: 5| Step: 6
Training loss: 2.2135282508593144
Validation loss: 2.685935607518921

Epoch: 5| Step: 7
Training loss: 2.821035783753725
Validation loss: 2.6932027732978656

Epoch: 5| Step: 8
Training loss: 3.024550437623986
Validation loss: 2.6519646390038547

Epoch: 5| Step: 9
Training loss: 2.523450443955047
Validation loss: 2.6394005519224177

Epoch: 5| Step: 10
Training loss: 2.9111858825043577
Validation loss: 2.6180569035020413

Epoch: 5| Step: 11
Training loss: 3.2853565495195043
Validation loss: 2.62626727107435

Epoch: 8| Step: 0
Training loss: 2.2794660098517765
Validation loss: 2.632009245970273

Epoch: 5| Step: 1
Training loss: 2.889109941323064
Validation loss: 2.637087866295603

Epoch: 5| Step: 2
Training loss: 2.835865702915627
Validation loss: 2.6504192233621775

Epoch: 5| Step: 3
Training loss: 2.0954213090674383
Validation loss: 2.6248225008277792

Epoch: 5| Step: 4
Training loss: 2.443395478662618
Validation loss: 2.637599720659194

Epoch: 5| Step: 5
Training loss: 2.7962393437925583
Validation loss: 2.626089021547558

Epoch: 5| Step: 6
Training loss: 2.7922240218051195
Validation loss: 2.6304792673799335

Epoch: 5| Step: 7
Training loss: 2.19396833762427
Validation loss: 2.6245121464691996

Epoch: 5| Step: 8
Training loss: 3.1229729753999034
Validation loss: 2.624332801102256

Epoch: 5| Step: 9
Training loss: 2.4391911826440094
Validation loss: 2.6134659949414183

Epoch: 5| Step: 10
Training loss: 2.4571844638425837
Validation loss: 2.621696077015312

Epoch: 5| Step: 11
Training loss: 2.6489152055520453
Validation loss: 2.6209769718025004

Epoch: 9| Step: 0
Training loss: 2.8749139192382414
Validation loss: 2.619475951740729

Epoch: 5| Step: 1
Training loss: 2.668265955890594
Validation loss: 2.6323898836527797

Epoch: 5| Step: 2
Training loss: 2.3947560638883005
Validation loss: 2.6121119347878246

Epoch: 5| Step: 3
Training loss: 2.580986792789619
Validation loss: 2.6347183589027763

Epoch: 5| Step: 4
Training loss: 2.1408212390804033
Validation loss: 2.6201474887888643

Epoch: 5| Step: 5
Training loss: 3.096868465351251
Validation loss: 2.614704358515496

Epoch: 5| Step: 6
Training loss: 2.173737859094287
Validation loss: 2.605655539554715

Epoch: 5| Step: 7
Training loss: 3.1326246704719996
Validation loss: 2.6231169948072472

Epoch: 5| Step: 8
Training loss: 2.4282397897262764
Validation loss: 2.6101694782085154

Epoch: 5| Step: 9
Training loss: 2.525114653599805
Validation loss: 2.635898690502359

Epoch: 5| Step: 10
Training loss: 2.2355037585734334
Validation loss: 2.6274978167533574

Epoch: 5| Step: 11
Training loss: 2.4750039765297127
Validation loss: 2.609740465805452

Epoch: 10| Step: 0
Training loss: 2.5497220280550428
Validation loss: 2.6118608310373257

Epoch: 5| Step: 1
Training loss: 2.633257095424415
Validation loss: 2.6324436880267337

Epoch: 5| Step: 2
Training loss: 2.833778252917215
Validation loss: 2.6029344746205565

Epoch: 5| Step: 3
Training loss: 2.4705227631487396
Validation loss: 2.6036586049705193

Epoch: 5| Step: 4
Training loss: 2.9291636901522002
Validation loss: 2.624404745124898

Epoch: 5| Step: 5
Training loss: 1.7819403933350773
Validation loss: 2.627837203208316

Epoch: 5| Step: 6
Training loss: 2.4542807996685765
Validation loss: 2.6278772895850313

Epoch: 5| Step: 7
Training loss: 2.496465855235641
Validation loss: 2.6300608426781236

Epoch: 5| Step: 8
Training loss: 2.4762624083453133
Validation loss: 2.608602253291752

Epoch: 5| Step: 9
Training loss: 2.687186023202919
Validation loss: 2.6256062057429044

Epoch: 5| Step: 10
Training loss: 2.909873917984574
Validation loss: 2.645148918410144

Epoch: 5| Step: 11
Training loss: 2.9587178226682593
Validation loss: 2.6228521544138395

Epoch: 11| Step: 0
Training loss: 2.7024962294814268
Validation loss: 2.60973627669386

Epoch: 5| Step: 1
Training loss: 2.8014666837188287
Validation loss: 2.6124420529194925

Epoch: 5| Step: 2
Training loss: 1.876122710747154
Validation loss: 2.6032866720465915

Epoch: 5| Step: 3
Training loss: 2.4986223239539886
Validation loss: 2.614781806576063

Epoch: 5| Step: 4
Training loss: 2.730450587833015
Validation loss: 2.6066605693553955

Epoch: 5| Step: 5
Training loss: 2.566684934212548
Validation loss: 2.6094902797368587

Epoch: 5| Step: 6
Training loss: 3.026076946392117
Validation loss: 2.6184915890046563

Epoch: 5| Step: 7
Training loss: 3.089938040547316
Validation loss: 2.606714548474457

Epoch: 5| Step: 8
Training loss: 2.1355497241241053
Validation loss: 2.621920861141295

Epoch: 5| Step: 9
Training loss: 2.4632181892102554
Validation loss: 2.6077080120762943

Epoch: 5| Step: 10
Training loss: 2.175111623070168
Validation loss: 2.6182883571179163

Epoch: 5| Step: 11
Training loss: 3.0014338245839993
Validation loss: 2.6123436546390315

Epoch: 12| Step: 0
Training loss: 2.7689171286402017
Validation loss: 2.6127042299658223

Epoch: 5| Step: 1
Training loss: 2.9156707334866945
Validation loss: 2.6011337675431143

Epoch: 5| Step: 2
Training loss: 2.9224885510562206
Validation loss: 2.610942605738629

Epoch: 5| Step: 3
Training loss: 2.3943318070807735
Validation loss: 2.5897882569717434

Epoch: 5| Step: 4
Training loss: 2.1287102565314537
Validation loss: 2.603042307681706

Epoch: 5| Step: 5
Training loss: 2.5769833898219945
Validation loss: 2.5855180644137867

Epoch: 5| Step: 6
Training loss: 2.0415760201812714
Validation loss: 2.612350503394958

Epoch: 5| Step: 7
Training loss: 2.2583025232256797
Validation loss: 2.5992921501446093

Epoch: 5| Step: 8
Training loss: 2.5420542770581758
Validation loss: 2.6062714171044195

Epoch: 5| Step: 9
Training loss: 2.6375927190167006
Validation loss: 2.613636541994815

Epoch: 5| Step: 10
Training loss: 2.8105955669752762
Validation loss: 2.6056769238778794

Epoch: 5| Step: 11
Training loss: 1.7657704926357116
Validation loss: 2.6149486094081626

Epoch: 13| Step: 0
Training loss: 2.2637731942516255
Validation loss: 2.603650981706959

Epoch: 5| Step: 1
Training loss: 2.8724005184095027
Validation loss: 2.6013521523729373

Epoch: 5| Step: 2
Training loss: 2.6779024723860516
Validation loss: 2.6283762049358446

Epoch: 5| Step: 3
Training loss: 2.8119083206023805
Validation loss: 2.6027085201974107

Epoch: 5| Step: 4
Training loss: 2.9474283809227573
Validation loss: 2.620320652869622

Epoch: 5| Step: 5
Training loss: 2.680443481931052
Validation loss: 2.609122772361321

Epoch: 5| Step: 6
Training loss: 2.7497738831931993
Validation loss: 2.6190829838443785

Epoch: 5| Step: 7
Training loss: 2.3318206334173013
Validation loss: 2.5803603028343916

Epoch: 5| Step: 8
Training loss: 1.9716705579012568
Validation loss: 2.6020587604381515

Epoch: 5| Step: 9
Training loss: 2.1453114464431478
Validation loss: 2.595348551126782

Epoch: 5| Step: 10
Training loss: 2.6309023303494903
Validation loss: 2.595036777285953

Epoch: 5| Step: 11
Training loss: 1.865916565774614
Validation loss: 2.6131360327758335

Epoch: 14| Step: 0
Training loss: 2.589571240847755
Validation loss: 2.586525223126057

Epoch: 5| Step: 1
Training loss: 2.150064081523382
Validation loss: 2.5892687121273124

Epoch: 5| Step: 2
Training loss: 2.826697563626314
Validation loss: 2.595927062084992

Epoch: 5| Step: 3
Training loss: 2.630621295399775
Validation loss: 2.6031654658536336

Epoch: 5| Step: 4
Training loss: 2.5869534159367475
Validation loss: 2.6297764237816414

Epoch: 5| Step: 5
Training loss: 2.407343331187948
Validation loss: 2.598581257427826

Epoch: 5| Step: 6
Training loss: 3.0142914190219003
Validation loss: 2.627515843661542

Epoch: 5| Step: 7
Training loss: 2.7435909494515753
Validation loss: 2.626138932029365

Epoch: 5| Step: 8
Training loss: 2.9169310495350587
Validation loss: 2.610325954096147

Epoch: 5| Step: 9
Training loss: 2.233201152059322
Validation loss: 2.616739912334171

Epoch: 5| Step: 10
Training loss: 2.123225986256432
Validation loss: 2.610183647626251

Epoch: 5| Step: 11
Training loss: 1.2175691214489555
Validation loss: 2.586311528411361

Epoch: 15| Step: 0
Training loss: 2.00667435861087
Validation loss: 2.584051975664457

Epoch: 5| Step: 1
Training loss: 1.9995545844954954
Validation loss: 2.5845225978157846

Epoch: 5| Step: 2
Training loss: 2.651102711112752
Validation loss: 2.5940628514184114

Epoch: 5| Step: 3
Training loss: 3.3287285629080694
Validation loss: 2.5948498167436136

Epoch: 5| Step: 4
Training loss: 2.82411516561532
Validation loss: 2.592522238651636

Epoch: 5| Step: 5
Training loss: 2.5384762131104535
Validation loss: 2.583305783022337

Epoch: 5| Step: 6
Training loss: 1.7805879265945017
Validation loss: 2.59889000679872

Epoch: 5| Step: 7
Training loss: 2.525412999737743
Validation loss: 2.5924004678616686

Epoch: 5| Step: 8
Training loss: 3.141089257993884
Validation loss: 2.591030039029032

Epoch: 5| Step: 9
Training loss: 2.0977428567578564
Validation loss: 2.5770445399549877

Epoch: 5| Step: 10
Training loss: 2.7454215864503237
Validation loss: 2.576325256547801

Epoch: 5| Step: 11
Training loss: 2.503508585329079
Validation loss: 2.591458177511067

Epoch: 16| Step: 0
Training loss: 2.4047782657737575
Validation loss: 2.5804259965484526

Epoch: 5| Step: 1
Training loss: 2.491263382680026
Validation loss: 2.581662823606684

Epoch: 5| Step: 2
Training loss: 2.551317330966694
Validation loss: 2.587305834452633

Epoch: 5| Step: 3
Training loss: 2.6763813765884
Validation loss: 2.572254502396226

Epoch: 5| Step: 4
Training loss: 2.45839295611305
Validation loss: 2.5875433615646313

Epoch: 5| Step: 5
Training loss: 2.6249171652666905
Validation loss: 2.5769207424866036

Epoch: 5| Step: 6
Training loss: 3.077428283847427
Validation loss: 2.5937623441164965

Epoch: 5| Step: 7
Training loss: 2.204483587296062
Validation loss: 2.59409411189098

Epoch: 5| Step: 8
Training loss: 2.3781081491041256
Validation loss: 2.5820407030449064

Epoch: 5| Step: 9
Training loss: 2.652940011736334
Validation loss: 2.5973080585754262

Epoch: 5| Step: 10
Training loss: 2.263892728286119
Validation loss: 2.590494349382888

Epoch: 5| Step: 11
Training loss: 3.0319802889120298
Validation loss: 2.5915648627959444

Epoch: 17| Step: 0
Training loss: 3.0912263383588363
Validation loss: 2.5959910588747253

Epoch: 5| Step: 1
Training loss: 3.002479482258261
Validation loss: 2.6002519798746837

Epoch: 5| Step: 2
Training loss: 2.604017594203313
Validation loss: 2.5769780256722

Epoch: 5| Step: 3
Training loss: 2.483214485174876
Validation loss: 2.5706088814112977

Epoch: 5| Step: 4
Training loss: 2.4591836159291254
Validation loss: 2.578901258801046

Epoch: 5| Step: 5
Training loss: 1.8362904960056905
Validation loss: 2.590168326067955

Epoch: 5| Step: 6
Training loss: 2.3339183845927307
Validation loss: 2.598252584132685

Epoch: 5| Step: 7
Training loss: 2.24134050381202
Validation loss: 2.562101247822761

Epoch: 5| Step: 8
Training loss: 2.6546276748140083
Validation loss: 2.5721143380187423

Epoch: 5| Step: 9
Training loss: 2.7945965911503734
Validation loss: 2.5721311927527193

Epoch: 5| Step: 10
Training loss: 2.1973311622170644
Validation loss: 2.5609939770680477

Epoch: 5| Step: 11
Training loss: 1.9383420037523673
Validation loss: 2.584091376532601

Epoch: 18| Step: 0
Training loss: 3.0603412103840006
Validation loss: 2.59907896619385

Epoch: 5| Step: 1
Training loss: 3.004922325412538
Validation loss: 2.569116667870265

Epoch: 5| Step: 2
Training loss: 2.3452995772644267
Validation loss: 2.5858382641055515

Epoch: 5| Step: 3
Training loss: 2.3761993190893156
Validation loss: 2.5705023891566734

Epoch: 5| Step: 4
Training loss: 2.5901972326642544
Validation loss: 2.5922982047954872

Epoch: 5| Step: 5
Training loss: 2.7409439962595195
Validation loss: 2.5882641024970976

Epoch: 5| Step: 6
Training loss: 2.3178034616443006
Validation loss: 2.592542083629191

Epoch: 5| Step: 7
Training loss: 1.9354329311425202
Validation loss: 2.5651806247114886

Epoch: 5| Step: 8
Training loss: 2.507027286230409
Validation loss: 2.5633165078226883

Epoch: 5| Step: 9
Training loss: 2.3597928113023334
Validation loss: 2.587266828102044

Epoch: 5| Step: 10
Training loss: 2.3528439904926572
Validation loss: 2.586164800636569

Epoch: 5| Step: 11
Training loss: 2.7967126042621224
Validation loss: 2.5627007367043957

Epoch: 19| Step: 0
Training loss: 2.3896088279244334
Validation loss: 2.5709851977989153

Epoch: 5| Step: 1
Training loss: 2.552966736985864
Validation loss: 2.57727594555265

Epoch: 5| Step: 2
Training loss: 2.4302008475983974
Validation loss: 2.5908110295261335

Epoch: 5| Step: 3
Training loss: 3.048349190141146
Validation loss: 2.5668068722623256

Epoch: 5| Step: 4
Training loss: 2.9989674698660775
Validation loss: 2.580832348764749

Epoch: 5| Step: 5
Training loss: 2.3503963582604683
Validation loss: 2.567706014594733

Epoch: 5| Step: 6
Training loss: 2.553100279521445
Validation loss: 2.5679424145660237

Epoch: 5| Step: 7
Training loss: 2.6022078713107213
Validation loss: 2.5811117673256945

Epoch: 5| Step: 8
Training loss: 2.4805038329519484
Validation loss: 2.5562779786460466

Epoch: 5| Step: 9
Training loss: 2.3845577664904107
Validation loss: 2.5545065307292285

Epoch: 5| Step: 10
Training loss: 1.983700134381336
Validation loss: 2.5473460169504443

Epoch: 5| Step: 11
Training loss: 2.1654468061228624
Validation loss: 2.5660558777832936

Epoch: 20| Step: 0
Training loss: 2.601873888963457
Validation loss: 2.5486961593666044

Epoch: 5| Step: 1
Training loss: 2.7699242919601463
Validation loss: 2.5670307276402085

Epoch: 5| Step: 2
Training loss: 2.375770544236864
Validation loss: 2.556253503487696

Epoch: 5| Step: 3
Training loss: 2.3001710247640417
Validation loss: 2.584475454509947

Epoch: 5| Step: 4
Training loss: 3.343814742272611
Validation loss: 2.5705699540494327

Epoch: 5| Step: 5
Training loss: 1.940941369257522
Validation loss: 2.5918961338027575

Epoch: 5| Step: 6
Training loss: 2.743578696497203
Validation loss: 2.5662631416386903

Epoch: 5| Step: 7
Training loss: 2.28499995292146
Validation loss: 2.609043713248155

Epoch: 5| Step: 8
Training loss: 1.7525403113633338
Validation loss: 2.579390999112995

Epoch: 5| Step: 9
Training loss: 2.679282288456704
Validation loss: 2.5960783485111105

Epoch: 5| Step: 10
Training loss: 2.5173044226098895
Validation loss: 2.5905864066948556

Epoch: 5| Step: 11
Training loss: 2.5588854907325174
Validation loss: 2.580222892694486

Epoch: 21| Step: 0
Training loss: 2.222830445447647
Validation loss: 2.5898639914065416

Epoch: 5| Step: 1
Training loss: 2.5073916833821643
Validation loss: 2.5766161925190727

Epoch: 5| Step: 2
Training loss: 2.781721353772329
Validation loss: 2.600829134685823

Epoch: 5| Step: 3
Training loss: 2.088117738795051
Validation loss: 2.5891934897530557

Epoch: 5| Step: 4
Training loss: 2.765494823086117
Validation loss: 2.58354034414771

Epoch: 5| Step: 5
Training loss: 1.90563973836182
Validation loss: 2.580697569796427

Epoch: 5| Step: 6
Training loss: 2.7890565161547327
Validation loss: 2.5732434267334243

Epoch: 5| Step: 7
Training loss: 2.5225898570907574
Validation loss: 2.5873367580575284

Epoch: 5| Step: 8
Training loss: 2.325380794556273
Validation loss: 2.559437705278293

Epoch: 5| Step: 9
Training loss: 2.752854166554577
Validation loss: 2.563499364357915

Epoch: 5| Step: 10
Training loss: 2.1725420030543483
Validation loss: 2.5789429956387817

Epoch: 5| Step: 11
Training loss: 4.834401418247548
Validation loss: 2.5788928304587153

Epoch: 22| Step: 0
Training loss: 1.8100581985938333
Validation loss: 2.5942173234258283

Epoch: 5| Step: 1
Training loss: 2.096670021919675
Validation loss: 2.5583001606547757

Epoch: 5| Step: 2
Training loss: 2.8848821555784054
Validation loss: 2.554331561227043

Epoch: 5| Step: 3
Training loss: 2.695519657743338
Validation loss: 2.556290721335791

Epoch: 5| Step: 4
Training loss: 2.5197081038039393
Validation loss: 2.562622811700705

Epoch: 5| Step: 5
Training loss: 2.6188855484362246
Validation loss: 2.5724405718229844

Epoch: 5| Step: 6
Training loss: 2.734693323407508
Validation loss: 2.541942488968197

Epoch: 5| Step: 7
Training loss: 2.230519095418839
Validation loss: 2.5715413928984234

Epoch: 5| Step: 8
Training loss: 2.669680134476087
Validation loss: 2.547201950836593

Epoch: 5| Step: 9
Training loss: 2.6145144348388034
Validation loss: 2.5680947789963744

Epoch: 5| Step: 10
Training loss: 2.435495481583616
Validation loss: 2.554248243204298

Epoch: 5| Step: 11
Training loss: 2.7358696040819543
Validation loss: 2.5648411236711888

Epoch: 23| Step: 0
Training loss: 2.9500831398320604
Validation loss: 2.5512380030385926

Epoch: 5| Step: 1
Training loss: 2.6546653059581193
Validation loss: 2.539632117126499

Epoch: 5| Step: 2
Training loss: 2.285650946386666
Validation loss: 2.551315045353838

Epoch: 5| Step: 3
Training loss: 2.967742749049542
Validation loss: 2.5482380326430816

Epoch: 5| Step: 4
Training loss: 2.4398336732175636
Validation loss: 2.560146817502419

Epoch: 5| Step: 5
Training loss: 3.0579828697308593
Validation loss: 2.542209068383473

Epoch: 5| Step: 6
Training loss: 1.820645674310825
Validation loss: 2.5573878156892564

Epoch: 5| Step: 7
Training loss: 2.061468386581398
Validation loss: 2.5610104123578754

Epoch: 5| Step: 8
Training loss: 2.551196685189085
Validation loss: 2.5820736018337

Epoch: 5| Step: 9
Training loss: 2.158970981899385
Validation loss: 2.566516157764793

Epoch: 5| Step: 10
Training loss: 2.116387022373956
Validation loss: 2.561375700858949

Epoch: 5| Step: 11
Training loss: 3.43824787674101
Validation loss: 2.564863886285976

Epoch: 24| Step: 0
Training loss: 2.536160920949115
Validation loss: 2.5602860112967405

Epoch: 5| Step: 1
Training loss: 1.9403678219920553
Validation loss: 2.549305222486821

Epoch: 5| Step: 2
Training loss: 2.20238877568764
Validation loss: 2.527625703487352

Epoch: 5| Step: 3
Training loss: 3.1654033315910866
Validation loss: 2.555177456907285

Epoch: 5| Step: 4
Training loss: 2.644728412350038
Validation loss: 2.5650944098014326

Epoch: 5| Step: 5
Training loss: 2.3785937374906596
Validation loss: 2.5599210756647772

Epoch: 5| Step: 6
Training loss: 2.9277469158858325
Validation loss: 2.5457217017723193

Epoch: 5| Step: 7
Training loss: 2.216089399600175
Validation loss: 2.5649375099739786

Epoch: 5| Step: 8
Training loss: 2.104947565291001
Validation loss: 2.5545582130996025

Epoch: 5| Step: 9
Training loss: 2.934991617791913
Validation loss: 2.5664102524291192

Epoch: 5| Step: 10
Training loss: 2.11652524380552
Validation loss: 2.562690239334289

Epoch: 5| Step: 11
Training loss: 2.6666206316153303
Validation loss: 2.5532943278782887

Epoch: 25| Step: 0
Training loss: 2.5549280829115517
Validation loss: 2.548031460527627

Epoch: 5| Step: 1
Training loss: 2.5182460612085706
Validation loss: 2.553422315150341

Epoch: 5| Step: 2
Training loss: 2.2358209159734694
Validation loss: 2.5658362000827153

Epoch: 5| Step: 3
Training loss: 2.891022196106233
Validation loss: 2.553312415688027

Epoch: 5| Step: 4
Training loss: 2.125471735933048
Validation loss: 2.558519811750975

Epoch: 5| Step: 5
Training loss: 2.6502143053454774
Validation loss: 2.5711650381422073

Epoch: 5| Step: 6
Training loss: 2.630495223208689
Validation loss: 2.5709187837080725

Epoch: 5| Step: 7
Training loss: 2.3837666586667394
Validation loss: 2.5660470549552232

Epoch: 5| Step: 8
Training loss: 2.680936827965779
Validation loss: 2.580296913590537

Epoch: 5| Step: 9
Training loss: 2.4809577519956885
Validation loss: 2.5712567327495006

Epoch: 5| Step: 10
Training loss: 2.3086644918637336
Validation loss: 2.5872326937031636

Epoch: 5| Step: 11
Training loss: 2.1101683078549884
Validation loss: 2.5788428915800736

Epoch: 26| Step: 0
Training loss: 2.53981706411047
Validation loss: 2.5781484930335954

Epoch: 5| Step: 1
Training loss: 2.667295937995934
Validation loss: 2.5789591663150833

Epoch: 5| Step: 2
Training loss: 2.5096283515170206
Validation loss: 2.5664804952053584

Epoch: 5| Step: 3
Training loss: 3.2532630092284816
Validation loss: 2.5823868618697072

Epoch: 5| Step: 4
Training loss: 2.5083985401519775
Validation loss: 2.5770236543197176

Epoch: 5| Step: 5
Training loss: 2.3151183898511754
Validation loss: 2.5650581213728296

Epoch: 5| Step: 6
Training loss: 1.6484425621497363
Validation loss: 2.555948731608832

Epoch: 5| Step: 7
Training loss: 2.4810545222154654
Validation loss: 2.569164692338384

Epoch: 5| Step: 8
Training loss: 2.556177760364922
Validation loss: 2.5533058521117384

Epoch: 5| Step: 9
Training loss: 2.5289797550958313
Validation loss: 2.5540811186512884

Epoch: 5| Step: 10
Training loss: 1.9690483714875602
Validation loss: 2.5468810769849175

Epoch: 5| Step: 11
Training loss: 2.7666301732548146
Validation loss: 2.5424331046212205

Epoch: 27| Step: 0
Training loss: 2.691906000919357
Validation loss: 2.5540869159496826

Epoch: 5| Step: 1
Training loss: 2.3746889814213326
Validation loss: 2.5662869368117094

Epoch: 5| Step: 2
Training loss: 2.6838662177171333
Validation loss: 2.579053946472822

Epoch: 5| Step: 3
Training loss: 2.6559486667027117
Validation loss: 2.5936062363151398

Epoch: 5| Step: 4
Training loss: 1.7249791406669486
Validation loss: 2.5492227124654807

Epoch: 5| Step: 5
Training loss: 2.9619015052899
Validation loss: 2.5479636527714784

Epoch: 5| Step: 6
Training loss: 2.244268428659261
Validation loss: 2.566388053190846

Epoch: 5| Step: 7
Training loss: 2.7666877385757944
Validation loss: 2.572021125174245

Epoch: 5| Step: 8
Training loss: 2.6236192614153504
Validation loss: 2.5723116172283995

Epoch: 5| Step: 9
Training loss: 2.245314912522625
Validation loss: 2.5703724329491813

Epoch: 5| Step: 10
Training loss: 2.310032842988873
Validation loss: 2.563504471884281

Epoch: 5| Step: 11
Training loss: 1.8564254061350542
Validation loss: 2.5686589596928346

Epoch: 28| Step: 0
Training loss: 3.1772502584328977
Validation loss: 2.552504393168725

Epoch: 5| Step: 1
Training loss: 1.914458191122977
Validation loss: 2.565029597610481

Epoch: 5| Step: 2
Training loss: 2.483038776858471
Validation loss: 2.560030507102132

Epoch: 5| Step: 3
Training loss: 2.573934490155691
Validation loss: 2.5336092131020576

Epoch: 5| Step: 4
Training loss: 2.4448444540086545
Validation loss: 2.5571384086187097

Epoch: 5| Step: 5
Training loss: 2.3363211326322277
Validation loss: 2.5268740642557512

Epoch: 5| Step: 6
Training loss: 2.450780051477034
Validation loss: 2.54980839651484

Epoch: 5| Step: 7
Training loss: 2.844200014831101
Validation loss: 2.55348837315995

Epoch: 5| Step: 8
Training loss: 2.0830665290379455
Validation loss: 2.5315547806721357

Epoch: 5| Step: 9
Training loss: 2.3611304213787627
Validation loss: 2.5409495261780393

Epoch: 5| Step: 10
Training loss: 2.6767747357295204
Validation loss: 2.5531852497165213

Epoch: 5| Step: 11
Training loss: 2.0337954491130636
Validation loss: 2.564982096031419

Epoch: 29| Step: 0
Training loss: 2.9808843680358663
Validation loss: 2.548897176418626

Epoch: 5| Step: 1
Training loss: 2.372384287320685
Validation loss: 2.564579906559464

Epoch: 5| Step: 2
Training loss: 2.906102002385085
Validation loss: 2.5647273424271138

Epoch: 5| Step: 3
Training loss: 2.891760525751304
Validation loss: 2.5595538602006953

Epoch: 5| Step: 4
Training loss: 2.260923571962218
Validation loss: 2.5709229877693405

Epoch: 5| Step: 5
Training loss: 2.0152574544148107
Validation loss: 2.5745878152818054

Epoch: 5| Step: 6
Training loss: 1.8747938042750125
Validation loss: 2.5608172706744097

Epoch: 5| Step: 7
Training loss: 2.313723678562803
Validation loss: 2.555861849644943

Epoch: 5| Step: 8
Training loss: 2.1314521895005547
Validation loss: 2.562451687799324

Epoch: 5| Step: 9
Training loss: 2.880325692092701
Validation loss: 2.560691906982353

Epoch: 5| Step: 10
Training loss: 2.1168661964668187
Validation loss: 2.5723483130996088

Epoch: 5| Step: 11
Training loss: 3.390716129607731
Validation loss: 2.5712912067269653

Epoch: 30| Step: 0
Training loss: 2.7060712513026086
Validation loss: 2.5960547957902027

Epoch: 5| Step: 1
Training loss: 2.790075550902239
Validation loss: 2.5732468761230063

Epoch: 5| Step: 2
Training loss: 2.257355218006513
Validation loss: 2.5561770452831865

Epoch: 5| Step: 3
Training loss: 2.3491390071384917
Validation loss: 2.5470002344463607

Epoch: 5| Step: 4
Training loss: 2.6111040611262095
Validation loss: 2.5485221006757226

Epoch: 5| Step: 5
Training loss: 2.7270637641672826
Validation loss: 2.5484632832626004

Epoch: 5| Step: 6
Training loss: 2.359826152185024
Validation loss: 2.5620120599667837

Epoch: 5| Step: 7
Training loss: 2.569656241912354
Validation loss: 2.5258970291310514

Epoch: 5| Step: 8
Training loss: 2.1941385082732467
Validation loss: 2.536424669255149

Epoch: 5| Step: 9
Training loss: 2.433448750445532
Validation loss: 2.533850158552324

Epoch: 5| Step: 10
Training loss: 2.313017606800981
Validation loss: 2.5500479593940497

Epoch: 5| Step: 11
Training loss: 2.196739845947887
Validation loss: 2.5547926722662506

Epoch: 31| Step: 0
Training loss: 2.910417419593694
Validation loss: 2.528499458913888

Epoch: 5| Step: 1
Training loss: 2.2848004447226
Validation loss: 2.5400519179434773

Epoch: 5| Step: 2
Training loss: 2.4952923319460782
Validation loss: 2.5111148794522418

Epoch: 5| Step: 3
Training loss: 2.734720698710798
Validation loss: 2.536735644184887

Epoch: 5| Step: 4
Training loss: 3.082364488579198
Validation loss: 2.523685181374059

Epoch: 5| Step: 5
Training loss: 2.6044561199813296
Validation loss: 2.5373483632886726

Epoch: 5| Step: 6
Training loss: 2.2817725014319494
Validation loss: 2.544820003271079

Epoch: 5| Step: 7
Training loss: 2.157126428258259
Validation loss: 2.5468028551738637

Epoch: 5| Step: 8
Training loss: 2.281778770722637
Validation loss: 2.52561866259769

Epoch: 5| Step: 9
Training loss: 2.031677083819843
Validation loss: 2.538696243083875

Epoch: 5| Step: 10
Training loss: 2.103104490092287
Validation loss: 2.5125894377179874

Epoch: 5| Step: 11
Training loss: 2.3566308642108904
Validation loss: 2.547480271387498

Epoch: 32| Step: 0
Training loss: 2.65064078087259
Validation loss: 2.5610309611705246

Epoch: 5| Step: 1
Training loss: 1.9639700128087898
Validation loss: 2.5550621411293504

Epoch: 5| Step: 2
Training loss: 2.9680571701322296
Validation loss: 2.5500821708080763

Epoch: 5| Step: 3
Training loss: 2.811878220386107
Validation loss: 2.5588667862203938

Epoch: 5| Step: 4
Training loss: 2.1524032335317695
Validation loss: 2.5687161931445353

Epoch: 5| Step: 5
Training loss: 1.978948427180811
Validation loss: 2.5527581036492952

Epoch: 5| Step: 6
Training loss: 2.6577299595237744
Validation loss: 2.561626669301151

Epoch: 5| Step: 7
Training loss: 2.788917687340423
Validation loss: 2.5498792096121066

Epoch: 5| Step: 8
Training loss: 2.3592632343017654
Validation loss: 2.5762155686751704

Epoch: 5| Step: 9
Training loss: 2.22377390993933
Validation loss: 2.5545499805452305

Epoch: 5| Step: 10
Training loss: 2.5797525528226863
Validation loss: 2.5638612295095915

Epoch: 5| Step: 11
Training loss: 1.4502952669677855
Validation loss: 2.566421857115786

Epoch: 33| Step: 0
Training loss: 2.6598143953089424
Validation loss: 2.5600523656652556

Epoch: 5| Step: 1
Training loss: 1.9360511654051213
Validation loss: 2.5542836662386934

Epoch: 5| Step: 2
Training loss: 2.335710189119132
Validation loss: 2.5588946760032756

Epoch: 5| Step: 3
Training loss: 2.0277513156830635
Validation loss: 2.5316705825273953

Epoch: 5| Step: 4
Training loss: 2.3590457509687206
Validation loss: 2.5504541971201657

Epoch: 5| Step: 5
Training loss: 2.3581605526700655
Validation loss: 2.5436080230656746

Epoch: 5| Step: 6
Training loss: 2.1396208029650854
Validation loss: 2.5509594265532365

Epoch: 5| Step: 7
Training loss: 2.6517455559901255
Validation loss: 2.553962721365134

Epoch: 5| Step: 8
Training loss: 2.6149445445086807
Validation loss: 2.542002164606423

Epoch: 5| Step: 9
Training loss: 3.164586454736921
Validation loss: 2.5313393769359935

Epoch: 5| Step: 10
Training loss: 2.5330924404789728
Validation loss: 2.5491757405524758

Epoch: 5| Step: 11
Training loss: 3.034845481093924
Validation loss: 2.5299678938478265

Epoch: 34| Step: 0
Training loss: 1.8537224512503299
Validation loss: 2.5253943856062087

Epoch: 5| Step: 1
Training loss: 2.5610203076160345
Validation loss: 2.5236872302432576

Epoch: 5| Step: 2
Training loss: 2.495135151598737
Validation loss: 2.5533314410153674

Epoch: 5| Step: 3
Training loss: 2.6323627574535795
Validation loss: 2.545474800632029

Epoch: 5| Step: 4
Training loss: 1.9221237765934265
Validation loss: 2.5540859319073403

Epoch: 5| Step: 5
Training loss: 2.165948479783773
Validation loss: 2.5428817585697154

Epoch: 5| Step: 6
Training loss: 2.0236163557385085
Validation loss: 2.5129119744054367

Epoch: 5| Step: 7
Training loss: 2.9380885407133817
Validation loss: 2.536846030734725

Epoch: 5| Step: 8
Training loss: 2.6433409318017005
Validation loss: 2.5214158336208823

Epoch: 5| Step: 9
Training loss: 3.0668085113837162
Validation loss: 2.534625632189028

Epoch: 5| Step: 10
Training loss: 2.522828019650931
Validation loss: 2.5391434485418602

Epoch: 5| Step: 11
Training loss: 2.230679316694406
Validation loss: 2.53318409359895

Epoch: 35| Step: 0
Training loss: 3.294396069625207
Validation loss: 2.5447867204636547

Epoch: 5| Step: 1
Training loss: 2.6841605974579013
Validation loss: 2.5338723409745176

Epoch: 5| Step: 2
Training loss: 2.6464370779618176
Validation loss: 2.5365084395789275

Epoch: 5| Step: 3
Training loss: 2.121085432117093
Validation loss: 2.5420417443748837

Epoch: 5| Step: 4
Training loss: 2.700601976892866
Validation loss: 2.565300585718749

Epoch: 5| Step: 5
Training loss: 2.150215107115206
Validation loss: 2.5701952678532516

Epoch: 5| Step: 6
Training loss: 2.1672019908505824
Validation loss: 2.5750068611991854

Epoch: 5| Step: 7
Training loss: 2.1981673496951104
Validation loss: 2.5749989177800345

Epoch: 5| Step: 8
Training loss: 2.36370472542399
Validation loss: 2.585117813305721

Epoch: 5| Step: 9
Training loss: 2.1159673461702084
Validation loss: 2.5832319137189663

Epoch: 5| Step: 10
Training loss: 2.670130645470254
Validation loss: 2.5616351893552483

Epoch: 5| Step: 11
Training loss: 1.4467310362146968
Validation loss: 2.559881840250778

Epoch: 36| Step: 0
Training loss: 2.2468500340206106
Validation loss: 2.558646858188311

Epoch: 5| Step: 1
Training loss: 2.7924715466531054
Validation loss: 2.5767887081723906

Epoch: 5| Step: 2
Training loss: 2.382776478979784
Validation loss: 2.5853294087843826

Epoch: 5| Step: 3
Training loss: 2.271322833390856
Validation loss: 2.5536924635034755

Epoch: 5| Step: 4
Training loss: 2.5603832713453865
Validation loss: 2.564555235604742

Epoch: 5| Step: 5
Training loss: 2.285530463984354
Validation loss: 2.5458047057215967

Epoch: 5| Step: 6
Training loss: 2.1618355540602696
Validation loss: 2.545147620118624

Epoch: 5| Step: 7
Training loss: 2.7853368671164125
Validation loss: 2.524824074480188

Epoch: 5| Step: 8
Training loss: 1.7905589013274388
Validation loss: 2.5324220906738617

Epoch: 5| Step: 9
Training loss: 2.6988461536772084
Validation loss: 2.5379284032759974

Epoch: 5| Step: 10
Training loss: 3.0279723074791884
Validation loss: 2.5512096557405255

Epoch: 5| Step: 11
Training loss: 0.9917421317570911
Validation loss: 2.5286246743120677

Epoch: 37| Step: 0
Training loss: 2.86042041116142
Validation loss: 2.5276286118433178

Epoch: 5| Step: 1
Training loss: 2.5610643412451704
Validation loss: 2.536577575721507

Epoch: 5| Step: 2
Training loss: 2.0955193857667527
Validation loss: 2.5488447127892546

Epoch: 5| Step: 3
Training loss: 1.970047961875973
Validation loss: 2.523516674394054

Epoch: 5| Step: 4
Training loss: 2.6661513744628778
Validation loss: 2.5396369558112606

Epoch: 5| Step: 5
Training loss: 2.470976682453372
Validation loss: 2.5281666001338254

Epoch: 5| Step: 6
Training loss: 2.1961908178546223
Validation loss: 2.530779869470331

Epoch: 5| Step: 7
Training loss: 2.18549222085232
Validation loss: 2.5192756956940903

Epoch: 5| Step: 8
Training loss: 1.9856085960375789
Validation loss: 2.5253389790370995

Epoch: 5| Step: 9
Training loss: 2.733707804343322
Validation loss: 2.5340830250988176

Epoch: 5| Step: 10
Training loss: 3.316952861406089
Validation loss: 2.5537909335364466

Epoch: 5| Step: 11
Training loss: 2.089656300917243
Validation loss: 2.5433737397660976

Epoch: 38| Step: 0
Training loss: 2.517396575560998
Validation loss: 2.5394796644982502

Epoch: 5| Step: 1
Training loss: 2.189436573030655
Validation loss: 2.5399656205716674

Epoch: 5| Step: 2
Training loss: 2.922281981494961
Validation loss: 2.5679962984577824

Epoch: 5| Step: 3
Training loss: 1.9521034315683412
Validation loss: 2.560975322866904

Epoch: 5| Step: 4
Training loss: 2.7065120931313262
Validation loss: 2.5839224971591004

Epoch: 5| Step: 5
Training loss: 1.924028384247143
Validation loss: 2.5955260948126497

Epoch: 5| Step: 6
Training loss: 2.1106430198435633
Validation loss: 2.5566224733101226

Epoch: 5| Step: 7
Training loss: 2.66088875027597
Validation loss: 2.5733008593361597

Epoch: 5| Step: 8
Training loss: 2.7203409209894835
Validation loss: 2.585068405870773

Epoch: 5| Step: 9
Training loss: 2.220290173304903
Validation loss: 2.5991054116157657

Epoch: 5| Step: 10
Training loss: 2.968698922771958
Validation loss: 2.570509565812834

Epoch: 5| Step: 11
Training loss: 2.5338156613243417
Validation loss: 2.5652549324975884

Epoch: 39| Step: 0
Training loss: 2.27782821082544
Validation loss: 2.561338952503994

Epoch: 5| Step: 1
Training loss: 2.447953233378121
Validation loss: 2.5238935965814764

Epoch: 5| Step: 2
Training loss: 2.697138866896137
Validation loss: 2.5126637905183165

Epoch: 5| Step: 3
Training loss: 2.6712203088162574
Validation loss: 2.5351291022196603

Epoch: 5| Step: 4
Training loss: 2.516641731222885
Validation loss: 2.5375106764319804

Epoch: 5| Step: 5
Training loss: 2.8377435991357705
Validation loss: 2.5335611185032336

Epoch: 5| Step: 6
Training loss: 2.8824125183011504
Validation loss: 2.534662905017858

Epoch: 5| Step: 7
Training loss: 2.104425231859768
Validation loss: 2.533108813653498

Epoch: 5| Step: 8
Training loss: 2.42224669526751
Validation loss: 2.5264599791302

Epoch: 5| Step: 9
Training loss: 1.6491519771703673
Validation loss: 2.5388101951247015

Epoch: 5| Step: 10
Training loss: 2.49685203723112
Validation loss: 2.539404602479125

Epoch: 5| Step: 11
Training loss: 2.94808707851131
Validation loss: 2.532574711218836

Epoch: 40| Step: 0
Training loss: 2.184618441614717
Validation loss: 2.534238338588008

Epoch: 5| Step: 1
Training loss: 2.47821586605852
Validation loss: 2.5393923657670308

Epoch: 5| Step: 2
Training loss: 2.0161123943257615
Validation loss: 2.536966920396421

Epoch: 5| Step: 3
Training loss: 2.417784750104805
Validation loss: 2.5229854080344207

Epoch: 5| Step: 4
Training loss: 2.8201670939403822
Validation loss: 2.524748348531055

Epoch: 5| Step: 5
Training loss: 2.913121784947472
Validation loss: 2.531137318712931

Epoch: 5| Step: 6
Training loss: 2.477371613133182
Validation loss: 2.538823187872047

Epoch: 5| Step: 7
Training loss: 2.361934057195406
Validation loss: 2.538059783914304

Epoch: 5| Step: 8
Training loss: 2.0450147955622726
Validation loss: 2.527201244143443

Epoch: 5| Step: 9
Training loss: 2.6040428640819404
Validation loss: 2.53155526333801

Epoch: 5| Step: 10
Training loss: 2.621213270665884
Validation loss: 2.516910512796958

Epoch: 5| Step: 11
Training loss: 2.765520858959102
Validation loss: 2.51795290023608

Epoch: 41| Step: 0
Training loss: 2.6858944199831516
Validation loss: 2.541654337920842

Epoch: 5| Step: 1
Training loss: 2.759292680802027
Validation loss: 2.523289238163586

Epoch: 5| Step: 2
Training loss: 2.5703813259568387
Validation loss: 2.5373562170737567

Epoch: 5| Step: 3
Training loss: 2.0840173234274477
Validation loss: 2.5304435281182607

Epoch: 5| Step: 4
Training loss: 2.6818353258592995
Validation loss: 2.5395773771517103

Epoch: 5| Step: 5
Training loss: 2.4905912734444047
Validation loss: 2.525270624891835

Epoch: 5| Step: 6
Training loss: 1.8898801360899138
Validation loss: 2.5240724510773473

Epoch: 5| Step: 7
Training loss: 2.80352665671923
Validation loss: 2.532443036213562

Epoch: 5| Step: 8
Training loss: 2.0032961624979357
Validation loss: 2.5340011347575206

Epoch: 5| Step: 9
Training loss: 2.304233622713464
Validation loss: 2.5269123320393327

Epoch: 5| Step: 10
Training loss: 2.5428267994535223
Validation loss: 2.531027525084816

Epoch: 5| Step: 11
Training loss: 2.1910352205817207
Validation loss: 2.530373511819255

Epoch: 42| Step: 0
Training loss: 1.941120333888336
Validation loss: 2.5404292218489997

Epoch: 5| Step: 1
Training loss: 3.031800682149428
Validation loss: 2.5448061257283543

Epoch: 5| Step: 2
Training loss: 1.916927451208102
Validation loss: 2.5442307559201396

Epoch: 5| Step: 3
Training loss: 3.06330549585135
Validation loss: 2.539228107235704

Epoch: 5| Step: 4
Training loss: 1.868708418061362
Validation loss: 2.556069675822423

Epoch: 5| Step: 5
Training loss: 2.2197451441767893
Validation loss: 2.556294759033622

Epoch: 5| Step: 6
Training loss: 2.200457208981431
Validation loss: 2.551864152695766

Epoch: 5| Step: 7
Training loss: 2.4133036880709673
Validation loss: 2.54178308522574

Epoch: 5| Step: 8
Training loss: 3.0034646055581913
Validation loss: 2.5495109530147113

Epoch: 5| Step: 9
Training loss: 2.504818088223241
Validation loss: 2.55214646060227

Epoch: 5| Step: 10
Training loss: 2.371339386183798
Validation loss: 2.5692910287494968

Epoch: 5| Step: 11
Training loss: 2.8429780687901167
Validation loss: 2.5396746440386986

Epoch: 43| Step: 0
Training loss: 2.469598455338262
Validation loss: 2.5420105081416566

Epoch: 5| Step: 1
Training loss: 2.7881830789775934
Validation loss: 2.5512114702885462

Epoch: 5| Step: 2
Training loss: 2.2556198719586824
Validation loss: 2.5317341690741273

Epoch: 5| Step: 3
Training loss: 2.0755869345547264
Validation loss: 2.5279456065139243

Epoch: 5| Step: 4
Training loss: 2.7251779270704315
Validation loss: 2.5281345048182695

Epoch: 5| Step: 5
Training loss: 3.265142523793348
Validation loss: 2.5271656576984523

Epoch: 5| Step: 6
Training loss: 2.1993468875719806
Validation loss: 2.5337878365899513

Epoch: 5| Step: 7
Training loss: 2.2977921088714797
Validation loss: 2.515652828181102

Epoch: 5| Step: 8
Training loss: 2.0129421625067043
Validation loss: 2.5515448112365213

Epoch: 5| Step: 9
Training loss: 2.5919722014102122
Validation loss: 2.518683057641667

Epoch: 5| Step: 10
Training loss: 2.3522004437638433
Validation loss: 2.52928779040734

Epoch: 5| Step: 11
Training loss: 2.115170239209748
Validation loss: 2.529040251174867

Epoch: 44| Step: 0
Training loss: 2.1112630800572654
Validation loss: 2.5263748158999717

Epoch: 5| Step: 1
Training loss: 2.2119835848966636
Validation loss: 2.529588735033565

Epoch: 5| Step: 2
Training loss: 2.315224151305565
Validation loss: 2.5388094536302632

Epoch: 5| Step: 3
Training loss: 2.959544314542976
Validation loss: 2.530125586055863

Epoch: 5| Step: 4
Training loss: 2.4928916964671655
Validation loss: 2.5442993659635706

Epoch: 5| Step: 5
Training loss: 2.461782352808651
Validation loss: 2.538815882516792

Epoch: 5| Step: 6
Training loss: 2.8648956868353435
Validation loss: 2.53553794961527

Epoch: 5| Step: 7
Training loss: 2.319739685252728
Validation loss: 2.519710047486655

Epoch: 5| Step: 8
Training loss: 2.536355227359817
Validation loss: 2.5483759141532625

Epoch: 5| Step: 9
Training loss: 2.1661391227332665
Validation loss: 2.5603402386818765

Epoch: 5| Step: 10
Training loss: 2.5464525867110086
Validation loss: 2.5456114640045

Epoch: 5| Step: 11
Training loss: 1.4367451551789467
Validation loss: 2.55643547989415

Epoch: 45| Step: 0
Training loss: 2.8292719585917907
Validation loss: 2.55029714059242

Epoch: 5| Step: 1
Training loss: 2.9143989102902133
Validation loss: 2.5576692653314512

Epoch: 5| Step: 2
Training loss: 3.153797216375689
Validation loss: 2.5581604374688705

Epoch: 5| Step: 3
Training loss: 2.1467707046429036
Validation loss: 2.5174852328923327

Epoch: 5| Step: 4
Training loss: 1.9445539473928948
Validation loss: 2.560592526810404

Epoch: 5| Step: 5
Training loss: 2.5137515466686255
Validation loss: 2.540224617302812

Epoch: 5| Step: 6
Training loss: 2.0870319595558473
Validation loss: 2.530404636520498

Epoch: 5| Step: 7
Training loss: 1.7621526416429822
Validation loss: 2.547030804944926

Epoch: 5| Step: 8
Training loss: 2.695032519850278
Validation loss: 2.5422055124036653

Epoch: 5| Step: 9
Training loss: 1.914103480309071
Validation loss: 2.5094953735350973

Epoch: 5| Step: 10
Training loss: 2.514293436713559
Validation loss: 2.5469609930580903

Epoch: 5| Step: 11
Training loss: 2.036972787434645
Validation loss: 2.547471509012335

Epoch: 46| Step: 0
Training loss: 2.9394549094159865
Validation loss: 2.556726814140271

Epoch: 5| Step: 1
Training loss: 2.4858963824503597
Validation loss: 2.5482554721746697

Epoch: 5| Step: 2
Training loss: 2.359981332640446
Validation loss: 2.5264015662360073

Epoch: 5| Step: 3
Training loss: 2.7890797675957937
Validation loss: 2.5536662908070884

Epoch: 5| Step: 4
Training loss: 1.6109299046275387
Validation loss: 2.5480962859715914

Epoch: 5| Step: 5
Training loss: 2.5053013858974507
Validation loss: 2.5343610106998153

Epoch: 5| Step: 6
Training loss: 2.5456452940710963
Validation loss: 2.546224335478863

Epoch: 5| Step: 7
Training loss: 1.9136566977552174
Validation loss: 2.536480150905723

Epoch: 5| Step: 8
Training loss: 2.2459316560056957
Validation loss: 2.545121550808136

Epoch: 5| Step: 9
Training loss: 2.7520472102329703
Validation loss: 2.551067334304681

Epoch: 5| Step: 10
Training loss: 2.590350577587352
Validation loss: 2.5495044887533385

Epoch: 5| Step: 11
Training loss: 1.882683017441329
Validation loss: 2.5490958393537606

Epoch: 47| Step: 0
Training loss: 2.5272929025809
Validation loss: 2.5511211852243694

Epoch: 5| Step: 1
Training loss: 1.7148138578064527
Validation loss: 2.5457705382819444

Epoch: 5| Step: 2
Training loss: 1.9487266760330169
Validation loss: 2.5506464351528266

Epoch: 5| Step: 3
Training loss: 2.5291073996959437
Validation loss: 2.5443004865424825

Epoch: 5| Step: 4
Training loss: 2.0160035953262603
Validation loss: 2.546463065193068

Epoch: 5| Step: 5
Training loss: 2.8988247430203624
Validation loss: 2.542177396542027

Epoch: 5| Step: 6
Training loss: 2.644515112147262
Validation loss: 2.5487023138612024

Epoch: 5| Step: 7
Training loss: 2.6309009710137334
Validation loss: 2.5504711794146866

Epoch: 5| Step: 8
Training loss: 2.0275862297037524
Validation loss: 2.5381020671062386

Epoch: 5| Step: 9
Training loss: 2.644420176304752
Validation loss: 2.550442048478169

Epoch: 5| Step: 10
Training loss: 2.861203802226604
Validation loss: 2.546887865794631

Epoch: 5| Step: 11
Training loss: 2.170293437964682
Validation loss: 2.5405847573622053

Epoch: 48| Step: 0
Training loss: 1.8628995812381357
Validation loss: 2.5567152004181946

Epoch: 5| Step: 1
Training loss: 2.1410246984063006
Validation loss: 2.526904956867444

Epoch: 5| Step: 2
Training loss: 2.1669910872715774
Validation loss: 2.548009202534313

Epoch: 5| Step: 3
Training loss: 2.869756145684396
Validation loss: 2.53978734160589

Epoch: 5| Step: 4
Training loss: 2.1038359076763147
Validation loss: 2.5481554802687247

Epoch: 5| Step: 5
Training loss: 2.5637677475990586
Validation loss: 2.539767743493611

Epoch: 5| Step: 6
Training loss: 2.510123545733108
Validation loss: 2.542599785558593

Epoch: 5| Step: 7
Training loss: 2.9965248643240403
Validation loss: 2.5102120839777773

Epoch: 5| Step: 8
Training loss: 2.372511614177161
Validation loss: 2.527584659939498

Epoch: 5| Step: 9
Training loss: 2.40326783310109
Validation loss: 2.5214246175960255

Epoch: 5| Step: 10
Training loss: 2.592979224707677
Validation loss: 2.515765634400658

Epoch: 5| Step: 11
Training loss: 2.3211523520494213
Validation loss: 2.5184410476833143

Epoch: 49| Step: 0
Training loss: 2.269773801885301
Validation loss: 2.532072769479046

Epoch: 5| Step: 1
Training loss: 2.2638191129180756
Validation loss: 2.5265687504024408

Epoch: 5| Step: 2
Training loss: 2.13483107066024
Validation loss: 2.5389437212426653

Epoch: 5| Step: 3
Training loss: 2.265619001709463
Validation loss: 2.5240120720793793

Epoch: 5| Step: 4
Training loss: 2.686559645680208
Validation loss: 2.5192846606331676

Epoch: 5| Step: 5
Training loss: 2.555964066385673
Validation loss: 2.5312676723475547

Epoch: 5| Step: 6
Training loss: 2.16472398033589
Validation loss: 2.5416104292250146

Epoch: 5| Step: 7
Training loss: 2.8288097922444773
Validation loss: 2.535335050526717

Epoch: 5| Step: 8
Training loss: 2.067033697679486
Validation loss: 2.5316177815251986

Epoch: 5| Step: 9
Training loss: 2.861585252685342
Validation loss: 2.530038893172017

Epoch: 5| Step: 10
Training loss: 2.432483499437688
Validation loss: 2.5365524346339634

Epoch: 5| Step: 11
Training loss: 2.9532766151866143
Validation loss: 2.542892747906446

Epoch: 50| Step: 0
Training loss: 2.5509332258157604
Validation loss: 2.528971105385608

Epoch: 5| Step: 1
Training loss: 2.5287046468215566
Validation loss: 2.5192590886861526

Epoch: 5| Step: 2
Training loss: 2.148331629138603
Validation loss: 2.530588193019498

Epoch: 5| Step: 3
Training loss: 2.5749480121882873
Validation loss: 2.5212337449116697

Epoch: 5| Step: 4
Training loss: 2.1433776087165235
Validation loss: 2.5174486784484813

Epoch: 5| Step: 5
Training loss: 2.7907131236687412
Validation loss: 2.5291685211723687

Epoch: 5| Step: 6
Training loss: 2.394668848959956
Validation loss: 2.5286951004608413

Epoch: 5| Step: 7
Training loss: 2.6815213081726728
Validation loss: 2.5255945235977113

Epoch: 5| Step: 8
Training loss: 2.3620217742497696
Validation loss: 2.532541946090114

Epoch: 5| Step: 9
Training loss: 2.3892317557896168
Validation loss: 2.5305556965944334

Epoch: 5| Step: 10
Training loss: 2.270084911052327
Validation loss: 2.5122629211950906

Epoch: 5| Step: 11
Training loss: 1.5373590792451832
Validation loss: 2.53144985555971

Epoch: 51| Step: 0
Training loss: 2.696086120152517
Validation loss: 2.5485650327491713

Epoch: 5| Step: 1
Training loss: 2.2904588001528765
Validation loss: 2.526359331010385

Epoch: 5| Step: 2
Training loss: 2.5665578579648756
Validation loss: 2.525603416940335

Epoch: 5| Step: 3
Training loss: 2.305159801645128
Validation loss: 2.5296262784339105

Epoch: 5| Step: 4
Training loss: 2.8358113915013714
Validation loss: 2.5330771496031708

Epoch: 5| Step: 5
Training loss: 2.4568919034661216
Validation loss: 2.5453621090027063

Epoch: 5| Step: 6
Training loss: 2.268366660948401
Validation loss: 2.5400464562456717

Epoch: 5| Step: 7
Training loss: 2.3976855761293554
Validation loss: 2.5451307076887475

Epoch: 5| Step: 8
Training loss: 2.786557565983965
Validation loss: 2.5483064724224023

Epoch: 5| Step: 9
Training loss: 2.1304537407150863
Validation loss: 2.5342147638518617

Epoch: 5| Step: 10
Training loss: 2.1722519362233905
Validation loss: 2.5490090492315383

Epoch: 5| Step: 11
Training loss: 1.8366155143487128
Validation loss: 2.5358197128259383

Epoch: 52| Step: 0
Training loss: 2.5663448425099635
Validation loss: 2.5357227407649643

Epoch: 5| Step: 1
Training loss: 1.7748950228743448
Validation loss: 2.5255022095596495

Epoch: 5| Step: 2
Training loss: 2.3947993714909823
Validation loss: 2.523883461297599

Epoch: 5| Step: 3
Training loss: 1.7891223347748704
Validation loss: 2.527024382076351

Epoch: 5| Step: 4
Training loss: 2.9590114478959517
Validation loss: 2.5454951645992474

Epoch: 5| Step: 5
Training loss: 1.8268624535050495
Validation loss: 2.5444355185450265

Epoch: 5| Step: 6
Training loss: 2.020336942237224
Validation loss: 2.559977652690002

Epoch: 5| Step: 7
Training loss: 2.638500555365502
Validation loss: 2.5398374147706746

Epoch: 5| Step: 8
Training loss: 2.7046478039380966
Validation loss: 2.5461672285069805

Epoch: 5| Step: 9
Training loss: 2.4964616531247703
Validation loss: 2.550339579255179

Epoch: 5| Step: 10
Training loss: 3.2949716578930324
Validation loss: 2.546412420097404

Epoch: 5| Step: 11
Training loss: 1.593060886773602
Validation loss: 2.5402065809976917

Epoch: 53| Step: 0
Training loss: 2.885875036599415
Validation loss: 2.5405358348525886

Epoch: 5| Step: 1
Training loss: 2.6276568636542197
Validation loss: 2.5409203720907323

Epoch: 5| Step: 2
Training loss: 2.555359544930934
Validation loss: 2.54400561670642

Epoch: 5| Step: 3
Training loss: 2.257697924178432
Validation loss: 2.5372215228589883

Epoch: 5| Step: 4
Training loss: 1.9911198167217954
Validation loss: 2.537861129983129

Epoch: 5| Step: 5
Training loss: 2.417573024431877
Validation loss: 2.539450751722434

Epoch: 5| Step: 6
Training loss: 2.5187290541012213
Validation loss: 2.5521708583744633

Epoch: 5| Step: 7
Training loss: 1.7309629539743525
Validation loss: 2.5363665543909524

Epoch: 5| Step: 8
Training loss: 2.7111424964988506
Validation loss: 2.5450245974837817

Epoch: 5| Step: 9
Training loss: 2.467655663648135
Validation loss: 2.535260962942771

Epoch: 5| Step: 10
Training loss: 2.5465583838498493
Validation loss: 2.526762740788014

Epoch: 5| Step: 11
Training loss: 1.9104782488377685
Validation loss: 2.530669840507038

Epoch: 54| Step: 0
Training loss: 2.898064519939292
Validation loss: 2.5396880802357122

Epoch: 5| Step: 1
Training loss: 2.2938772348149103
Validation loss: 2.5247553719467417

Epoch: 5| Step: 2
Training loss: 2.5393715068878553
Validation loss: 2.553205252591915

Epoch: 5| Step: 3
Training loss: 2.5639928795511815
Validation loss: 2.550886894869672

Epoch: 5| Step: 4
Training loss: 2.352138512107474
Validation loss: 2.5530607641879204

Epoch: 5| Step: 5
Training loss: 2.577324205355096
Validation loss: 2.574674763710316

Epoch: 5| Step: 6
Training loss: 2.228049333954186
Validation loss: 2.555347190242961

Epoch: 5| Step: 7
Training loss: 1.8808509454112439
Validation loss: 2.5493636347018658

Epoch: 5| Step: 8
Training loss: 2.628262626682207
Validation loss: 2.56780162020223

Epoch: 5| Step: 9
Training loss: 2.4772899052817356
Validation loss: 2.5851560604755957

Epoch: 5| Step: 10
Training loss: 2.1635017632551525
Validation loss: 2.5590377655305976

Epoch: 5| Step: 11
Training loss: 1.5603814831151102
Validation loss: 2.5306253231485214

Epoch: 55| Step: 0
Training loss: 2.581181327146471
Validation loss: 2.554605181317555

Epoch: 5| Step: 1
Training loss: 2.3583741749528366
Validation loss: 2.55092929646079

Epoch: 5| Step: 2
Training loss: 2.5911508429141796
Validation loss: 2.55948221248376

Epoch: 5| Step: 3
Training loss: 2.0902312587942222
Validation loss: 2.551319137650706

Epoch: 5| Step: 4
Training loss: 2.0903659631567666
Validation loss: 2.5508424324148358

Epoch: 5| Step: 5
Training loss: 2.289303607415908
Validation loss: 2.552118808473827

Epoch: 5| Step: 6
Training loss: 2.8196315630209705
Validation loss: 2.5438844913917107

Epoch: 5| Step: 7
Training loss: 2.6956371167178372
Validation loss: 2.5386047420145164

Epoch: 5| Step: 8
Training loss: 2.343679198149331
Validation loss: 2.533686838509194

Epoch: 5| Step: 9
Training loss: 2.3673429028958517
Validation loss: 2.515098048634743

Epoch: 5| Step: 10
Training loss: 2.29395518619496
Validation loss: 2.533241842263727

Epoch: 5| Step: 11
Training loss: 2.80185754331911
Validation loss: 2.5256463216668124

Epoch: 56| Step: 0
Training loss: 2.2980328191301083
Validation loss: 2.5226625368589883

Epoch: 5| Step: 1
Training loss: 2.1991739759748943
Validation loss: 2.518997017459232

Epoch: 5| Step: 2
Training loss: 2.242632246934172
Validation loss: 2.5198040600130613

Epoch: 5| Step: 3
Training loss: 2.468248533672128
Validation loss: 2.5345969736749265

Epoch: 5| Step: 4
Training loss: 2.020120619581284
Validation loss: 2.5461825031965697

Epoch: 5| Step: 5
Training loss: 2.420856187704894
Validation loss: 2.524433970664921

Epoch: 5| Step: 6
Training loss: 2.6645075183031466
Validation loss: 2.5298274363784055

Epoch: 5| Step: 7
Training loss: 2.95895504574986
Validation loss: 2.5289867392635155

Epoch: 5| Step: 8
Training loss: 2.69921027042807
Validation loss: 2.538757067184842

Epoch: 5| Step: 9
Training loss: 2.7356360443150267
Validation loss: 2.5126920349914155

Epoch: 5| Step: 10
Training loss: 2.123577763947261
Validation loss: 2.5176068628139334

Epoch: 5| Step: 11
Training loss: 1.9781968066062372
Validation loss: 2.533542383868966

Epoch: 57| Step: 0
Training loss: 2.1910788551601765
Validation loss: 2.542697683049242

Epoch: 5| Step: 1
Training loss: 2.2490152747287278
Validation loss: 2.542552931580623

Epoch: 5| Step: 2
Training loss: 1.950944461495406
Validation loss: 2.569095976858543

Epoch: 5| Step: 3
Training loss: 2.6230237878847156
Validation loss: 2.581661746180676

Epoch: 5| Step: 4
Training loss: 2.809212522295592
Validation loss: 2.563712775110349

Epoch: 5| Step: 5
Training loss: 1.9975166400316593
Validation loss: 2.6025167782743774

Epoch: 5| Step: 6
Training loss: 2.356172522933053
Validation loss: 2.575733053928748

Epoch: 5| Step: 7
Training loss: 2.3307488524104643
Validation loss: 2.6084518550923996

Epoch: 5| Step: 8
Training loss: 2.512238491739963
Validation loss: 2.6148721616470554

Epoch: 5| Step: 9
Training loss: 2.7602834033587764
Validation loss: 2.5822249477908383

Epoch: 5| Step: 10
Training loss: 2.6312469446159983
Validation loss: 2.5748955392173127

Epoch: 5| Step: 11
Training loss: 3.3185145637637494
Validation loss: 2.5709747922137107

Epoch: 58| Step: 0
Training loss: 3.333945901533651
Validation loss: 2.5846601099072637

Epoch: 5| Step: 1
Training loss: 1.8945077796347414
Validation loss: 2.5289207738554147

Epoch: 5| Step: 2
Training loss: 2.572414663250665
Validation loss: 2.536978350421041

Epoch: 5| Step: 3
Training loss: 2.618076731368236
Validation loss: 2.523598216069425

Epoch: 5| Step: 4
Training loss: 2.9844734215609807
Validation loss: 2.5196964259058343

Epoch: 5| Step: 5
Training loss: 1.831330838551099
Validation loss: 2.5171795379809527

Epoch: 5| Step: 6
Training loss: 2.2592386671539537
Validation loss: 2.5344425601632614

Epoch: 5| Step: 7
Training loss: 2.2023673411848392
Validation loss: 2.5287852787392353

Epoch: 5| Step: 8
Training loss: 2.168227171746157
Validation loss: 2.5271198934146932

Epoch: 5| Step: 9
Training loss: 2.482460003671826
Validation loss: 2.5195955391500884

Epoch: 5| Step: 10
Training loss: 2.319922623166132
Validation loss: 2.536837725036955

Epoch: 5| Step: 11
Training loss: 0.9112615136673727
Validation loss: 2.5341705576904325

Epoch: 59| Step: 0
Training loss: 2.36090028482287
Validation loss: 2.542226715348135

Epoch: 5| Step: 1
Training loss: 2.1922930930625797
Validation loss: 2.521991784071542

Epoch: 5| Step: 2
Training loss: 2.558805174500596
Validation loss: 2.5419456466926063

Epoch: 5| Step: 3
Training loss: 2.50649067396175
Validation loss: 2.53005569445709

Epoch: 5| Step: 4
Training loss: 2.5887115443240867
Validation loss: 2.5382468767109665

Epoch: 5| Step: 5
Training loss: 2.243260462495159
Validation loss: 2.5294228049881298

Epoch: 5| Step: 6
Training loss: 2.1992896493761407
Validation loss: 2.5301800731108344

Epoch: 5| Step: 7
Training loss: 2.224318487827345
Validation loss: 2.5677880719063495

Epoch: 5| Step: 8
Training loss: 1.9907256503687318
Validation loss: 2.5510791684425533

Epoch: 5| Step: 9
Training loss: 3.276286849331725
Validation loss: 2.5329619532801373

Epoch: 5| Step: 10
Training loss: 2.289777624502351
Validation loss: 2.5403903579903386

Epoch: 5| Step: 11
Training loss: 2.1629985300835965
Validation loss: 2.545603912763188

Epoch: 60| Step: 0
Training loss: 2.64630563280156
Validation loss: 2.5655805206779863

Epoch: 5| Step: 1
Training loss: 2.3535602992712783
Validation loss: 2.554442947146061

Epoch: 5| Step: 2
Training loss: 2.3782614349247524
Validation loss: 2.5370070251071364

Epoch: 5| Step: 3
Training loss: 1.91699504803499
Validation loss: 2.586716698749712

Epoch: 5| Step: 4
Training loss: 2.3866207520989517
Validation loss: 2.590151136135955

Epoch: 5| Step: 5
Training loss: 2.4966724184663502
Validation loss: 2.571794695119976

Epoch: 5| Step: 6
Training loss: 2.6687007140135743
Validation loss: 2.5784972028146935

Epoch: 5| Step: 7
Training loss: 2.49829596618979
Validation loss: 2.5596194727685004

Epoch: 5| Step: 8
Training loss: 2.125062604991739
Validation loss: 2.5522315676450744

Epoch: 5| Step: 9
Training loss: 1.9682511802775429
Validation loss: 2.5479246192167557

Epoch: 5| Step: 10
Training loss: 2.817452795789176
Validation loss: 2.5485920997751337

Epoch: 5| Step: 11
Training loss: 3.3277957377287897
Validation loss: 2.526479723723865

Epoch: 61| Step: 0
Training loss: 2.3474955829095365
Validation loss: 2.5332171955173757

Epoch: 5| Step: 1
Training loss: 2.862547068646181
Validation loss: 2.5291340779232225

Epoch: 5| Step: 2
Training loss: 2.22062099174054
Validation loss: 2.5144728476443388

Epoch: 5| Step: 3
Training loss: 1.4938017417214193
Validation loss: 2.514444473043904

Epoch: 5| Step: 4
Training loss: 2.566507322971666
Validation loss: 2.549525985573625

Epoch: 5| Step: 5
Training loss: 2.3861200109199143
Validation loss: 2.5497260761549323

Epoch: 5| Step: 6
Training loss: 2.4916668291208817
Validation loss: 2.5421725431540363

Epoch: 5| Step: 7
Training loss: 2.773987105809218
Validation loss: 2.5178805441640133

Epoch: 5| Step: 8
Training loss: 2.462113163185746
Validation loss: 2.5294642841016652

Epoch: 5| Step: 9
Training loss: 2.0743348399863866
Validation loss: 2.5482680405705103

Epoch: 5| Step: 10
Training loss: 2.653096559909038
Validation loss: 2.5311345360562925

Epoch: 5| Step: 11
Training loss: 1.8767524159401807
Validation loss: 2.5253931386275736

Epoch: 62| Step: 0
Training loss: 2.327515183019234
Validation loss: 2.5155623212947256

Epoch: 5| Step: 1
Training loss: 2.623620988019351
Validation loss: 2.512957349117

Epoch: 5| Step: 2
Training loss: 2.733956441179271
Validation loss: 2.506921053190523

Epoch: 5| Step: 3
Training loss: 2.0011086967185876
Validation loss: 2.520010239760722

Epoch: 5| Step: 4
Training loss: 2.1266690599593483
Validation loss: 2.5317664659550476

Epoch: 5| Step: 5
Training loss: 3.2653297400350283
Validation loss: 2.5366723102861033

Epoch: 5| Step: 6
Training loss: 2.540341005488007
Validation loss: 2.5168025812706722

Epoch: 5| Step: 7
Training loss: 2.296342852962521
Validation loss: 2.5214848398946406

Epoch: 5| Step: 8
Training loss: 2.2041948034248953
Validation loss: 2.5281488196622623

Epoch: 5| Step: 9
Training loss: 2.1894468091317245
Validation loss: 2.5379274618966883

Epoch: 5| Step: 10
Training loss: 2.033744454121311
Validation loss: 2.545244248710209

Epoch: 5| Step: 11
Training loss: 1.9431013539845752
Validation loss: 2.53769793497946

Epoch: 63| Step: 0
Training loss: 2.7030293001202095
Validation loss: 2.540559575770082

Epoch: 5| Step: 1
Training loss: 2.807827437779808
Validation loss: 2.5415869306866594

Epoch: 5| Step: 2
Training loss: 2.16181018830347
Validation loss: 2.5468331140455645

Epoch: 5| Step: 3
Training loss: 2.4185663079585873
Validation loss: 2.5374059467079415

Epoch: 5| Step: 4
Training loss: 1.7918323913340872
Validation loss: 2.5095464746803406

Epoch: 5| Step: 5
Training loss: 2.046933704728303
Validation loss: 2.528178828310425

Epoch: 5| Step: 6
Training loss: 2.663082714519502
Validation loss: 2.5294956006468485

Epoch: 5| Step: 7
Training loss: 2.5035564874607847
Validation loss: 2.5299877700899582

Epoch: 5| Step: 8
Training loss: 2.7195151118430068
Validation loss: 2.525625105394265

Epoch: 5| Step: 9
Training loss: 2.362031060559658
Validation loss: 2.5400638972653136

Epoch: 5| Step: 10
Training loss: 2.4410574946213615
Validation loss: 2.536209577285612

Epoch: 5| Step: 11
Training loss: 2.153882039473337
Validation loss: 2.5217743344169516

Epoch: 64| Step: 0
Training loss: 2.632689340127523
Validation loss: 2.515586157710166

Epoch: 5| Step: 1
Training loss: 2.5369065741815344
Validation loss: 2.547243033187404

Epoch: 5| Step: 2
Training loss: 2.491770263950777
Validation loss: 2.5241324980362503

Epoch: 5| Step: 3
Training loss: 1.7325309366433812
Validation loss: 2.5409442169297094

Epoch: 5| Step: 4
Training loss: 2.257163829085201
Validation loss: 2.521796719574235

Epoch: 5| Step: 5
Training loss: 2.1752274799871305
Validation loss: 2.53314457543602

Epoch: 5| Step: 6
Training loss: 2.1344187071585234
Validation loss: 2.561373971080134

Epoch: 5| Step: 7
Training loss: 2.4758642517987455
Validation loss: 2.5422484886264223

Epoch: 5| Step: 8
Training loss: 2.7041761526481185
Validation loss: 2.5943584915685993

Epoch: 5| Step: 9
Training loss: 2.684510453418224
Validation loss: 2.602672740945639

Epoch: 5| Step: 10
Training loss: 2.4760952577955258
Validation loss: 2.5775000305989777

Epoch: 5| Step: 11
Training loss: 2.268271958611369
Validation loss: 2.584103832141137

Epoch: 65| Step: 0
Training loss: 2.0709865408496433
Validation loss: 2.5461264448318954

Epoch: 5| Step: 1
Training loss: 2.816051106276376
Validation loss: 2.5388398019011276

Epoch: 5| Step: 2
Training loss: 2.4295121402566693
Validation loss: 2.5344157496702904

Epoch: 5| Step: 3
Training loss: 2.151908373544823
Validation loss: 2.5241019355445453

Epoch: 5| Step: 4
Training loss: 2.3488489253805733
Validation loss: 2.5169789834681513

Epoch: 5| Step: 5
Training loss: 2.27901851258536
Validation loss: 2.5082576946775603

Epoch: 5| Step: 6
Training loss: 2.7751169197264205
Validation loss: 2.5214492752070927

Epoch: 5| Step: 7
Training loss: 2.0753011232215623
Validation loss: 2.512554984653497

Epoch: 5| Step: 8
Training loss: 2.5379271800699663
Validation loss: 2.540888723282837

Epoch: 5| Step: 9
Training loss: 2.863650101742949
Validation loss: 2.5158614369360364

Epoch: 5| Step: 10
Training loss: 2.2698401866230227
Validation loss: 2.5129294436477885

Epoch: 5| Step: 11
Training loss: 1.9970784306069718
Validation loss: 2.4967374891881406

Epoch: 66| Step: 0
Training loss: 3.095046571248685
Validation loss: 2.5190208213736134

Epoch: 5| Step: 1
Training loss: 2.043303540662387
Validation loss: 2.5352530674014444

Epoch: 5| Step: 2
Training loss: 2.303617170688697
Validation loss: 2.524672931160553

Epoch: 5| Step: 3
Training loss: 1.7836728266038904
Validation loss: 2.5558425555287205

Epoch: 5| Step: 4
Training loss: 1.9878023841239494
Validation loss: 2.561884119874236

Epoch: 5| Step: 5
Training loss: 2.4646296823829252
Validation loss: 2.5925309330619286

Epoch: 5| Step: 6
Training loss: 2.0232172665726162
Validation loss: 2.5992190179957504

Epoch: 5| Step: 7
Training loss: 3.0701442992751304
Validation loss: 2.6235243532436536

Epoch: 5| Step: 8
Training loss: 2.139285705824783
Validation loss: 2.593011275959225

Epoch: 5| Step: 9
Training loss: 2.810478161892407
Validation loss: 2.618746700148222

Epoch: 5| Step: 10
Training loss: 2.7297647903059867
Validation loss: 2.597778489527955

Epoch: 5| Step: 11
Training loss: 2.4827350505946897
Validation loss: 2.5909615775431876

Epoch: 67| Step: 0
Training loss: 1.6457028236633358
Validation loss: 2.545235904066436

Epoch: 5| Step: 1
Training loss: 2.6418704193992424
Validation loss: 2.541001339636956

Epoch: 5| Step: 2
Training loss: 2.2270179684226274
Validation loss: 2.529417815195219

Epoch: 5| Step: 3
Training loss: 1.7764999231005114
Validation loss: 2.5140916325169598

Epoch: 5| Step: 4
Training loss: 3.061209270413512
Validation loss: 2.5228332173926087

Epoch: 5| Step: 5
Training loss: 2.457275863624675
Validation loss: 2.524891783658338

Epoch: 5| Step: 6
Training loss: 2.381611005196277
Validation loss: 2.535787773138821

Epoch: 5| Step: 7
Training loss: 2.5251327819658984
Validation loss: 2.502393756691926

Epoch: 5| Step: 8
Training loss: 2.5066807174627
Validation loss: 2.524308757934451

Epoch: 5| Step: 9
Training loss: 2.666031185565853
Validation loss: 2.5343701594220653

Epoch: 5| Step: 10
Training loss: 2.3841979954765757
Validation loss: 2.5400076803957345

Epoch: 5| Step: 11
Training loss: 2.5227891780059264
Validation loss: 2.5012617503456873

Epoch: 68| Step: 0
Training loss: 2.6659743980042663
Validation loss: 2.537693695449128

Epoch: 5| Step: 1
Training loss: 2.95370929730332
Validation loss: 2.533919406428677

Epoch: 5| Step: 2
Training loss: 1.9462482698857941
Validation loss: 2.523291746010571

Epoch: 5| Step: 3
Training loss: 3.0779631131584986
Validation loss: 2.506348234932498

Epoch: 5| Step: 4
Training loss: 2.1738590536462175
Validation loss: 2.5155403328305046

Epoch: 5| Step: 5
Training loss: 2.4183527775549547
Validation loss: 2.5243253651721593

Epoch: 5| Step: 6
Training loss: 2.490848001909334
Validation loss: 2.5599293219910244

Epoch: 5| Step: 7
Training loss: 2.328987013201214
Validation loss: 2.5811062385605963

Epoch: 5| Step: 8
Training loss: 1.8699120471282495
Validation loss: 2.5831209154371324

Epoch: 5| Step: 9
Training loss: 2.4598516096934437
Validation loss: 2.5725937124544656

Epoch: 5| Step: 10
Training loss: 1.902406100087536
Validation loss: 2.574674256331567

Epoch: 5| Step: 11
Training loss: 1.193847855956016
Validation loss: 2.5719901680605166

Epoch: 69| Step: 0
Training loss: 2.4870809537552705
Validation loss: 2.575608229174864

Epoch: 5| Step: 1
Training loss: 2.4221133207149927
Validation loss: 2.550313489007168

Epoch: 5| Step: 2
Training loss: 2.191249685423459
Validation loss: 2.5550124091079076

Epoch: 5| Step: 3
Training loss: 2.1782388008851647
Validation loss: 2.5626284675649735

Epoch: 5| Step: 4
Training loss: 2.6884425972075774
Validation loss: 2.529791478483724

Epoch: 5| Step: 5
Training loss: 2.356009906709111
Validation loss: 2.5200570555880955

Epoch: 5| Step: 6
Training loss: 2.4139856616386868
Validation loss: 2.5261879331315193

Epoch: 5| Step: 7
Training loss: 2.5330862284492563
Validation loss: 2.5296374902932253

Epoch: 5| Step: 8
Training loss: 2.7819400745631984
Validation loss: 2.511448000666848

Epoch: 5| Step: 9
Training loss: 2.3381660573250986
Validation loss: 2.5072480474612724

Epoch: 5| Step: 10
Training loss: 1.8923758604386762
Validation loss: 2.50729631397898

Epoch: 5| Step: 11
Training loss: 3.043702807050801
Validation loss: 2.529928188014728

Epoch: 70| Step: 0
Training loss: 2.6443523757821477
Validation loss: 2.5144411504054505

Epoch: 5| Step: 1
Training loss: 2.480086073304666
Validation loss: 2.5158938744008

Epoch: 5| Step: 2
Training loss: 2.3646348339863823
Validation loss: 2.5163768805679254

Epoch: 5| Step: 3
Training loss: 2.124219526688496
Validation loss: 2.5155183560214676

Epoch: 5| Step: 4
Training loss: 2.2070153699995627
Validation loss: 2.5279196623979403

Epoch: 5| Step: 5
Training loss: 2.3952192652921998
Validation loss: 2.5103928233764763

Epoch: 5| Step: 6
Training loss: 2.035653608177922
Validation loss: 2.5083887620570144

Epoch: 5| Step: 7
Training loss: 2.856623091422842
Validation loss: 2.5289519400049274

Epoch: 5| Step: 8
Training loss: 2.27065555214901
Validation loss: 2.523662777540171

Epoch: 5| Step: 9
Training loss: 2.557024805216443
Validation loss: 2.506785030762027

Epoch: 5| Step: 10
Training loss: 2.323099742112723
Validation loss: 2.5346567242722693

Epoch: 5| Step: 11
Training loss: 2.4614001611224916
Validation loss: 2.521639672620431

Epoch: 71| Step: 0
Training loss: 2.0613290179151114
Validation loss: 2.5305664097045684

Epoch: 5| Step: 1
Training loss: 2.647837703156729
Validation loss: 2.551834301897683

Epoch: 5| Step: 2
Training loss: 2.236715411504505
Validation loss: 2.5478901702384817

Epoch: 5| Step: 3
Training loss: 2.753110167239325
Validation loss: 2.5439581091541252

Epoch: 5| Step: 4
Training loss: 2.5762490585599362
Validation loss: 2.540448511804272

Epoch: 5| Step: 5
Training loss: 2.3855668954866465
Validation loss: 2.5611303592389794

Epoch: 5| Step: 6
Training loss: 2.6351301819060176
Validation loss: 2.5416056118860118

Epoch: 5| Step: 7
Training loss: 2.43382210678078
Validation loss: 2.5449403931458043

Epoch: 5| Step: 8
Training loss: 2.3732969301446527
Validation loss: 2.560319876386863

Epoch: 5| Step: 9
Training loss: 1.8761490162225916
Validation loss: 2.5331611953359356

Epoch: 5| Step: 10
Training loss: 2.4088095391065933
Validation loss: 2.519686364418823

Epoch: 5| Step: 11
Training loss: 1.5206869481674334
Validation loss: 2.558914805063329

Epoch: 72| Step: 0
Training loss: 2.114426279734444
Validation loss: 2.5464313292260723

Epoch: 5| Step: 1
Training loss: 2.4629574191106207
Validation loss: 2.5383835456972172

Epoch: 5| Step: 2
Training loss: 2.5070525827329373
Validation loss: 2.5442186595574143

Epoch: 5| Step: 3
Training loss: 2.2151632196295625
Validation loss: 2.5295339465882427

Epoch: 5| Step: 4
Training loss: 2.246856188529563
Validation loss: 2.5282084868940946

Epoch: 5| Step: 5
Training loss: 2.111110623119811
Validation loss: 2.52197520085736

Epoch: 5| Step: 6
Training loss: 2.5425432496719966
Validation loss: 2.5177902238875265

Epoch: 5| Step: 7
Training loss: 2.5524075568157385
Validation loss: 2.525235426269907

Epoch: 5| Step: 8
Training loss: 2.1895443763739615
Validation loss: 2.5403663300248005

Epoch: 5| Step: 9
Training loss: 2.9644196097620354
Validation loss: 2.5188104391931945

Epoch: 5| Step: 10
Training loss: 2.394783641463798
Validation loss: 2.5201301671146985

Epoch: 5| Step: 11
Training loss: 2.6241208375345275
Validation loss: 2.5326194786904157

Epoch: 73| Step: 0
Training loss: 2.364321645184603
Validation loss: 2.513948071177157

Epoch: 5| Step: 1
Training loss: 2.6724148032130284
Validation loss: 2.541812342757941

Epoch: 5| Step: 2
Training loss: 1.7557878150827388
Validation loss: 2.515745158119727

Epoch: 5| Step: 3
Training loss: 2.203935514659424
Validation loss: 2.510019450333959

Epoch: 5| Step: 4
Training loss: 2.250623298777854
Validation loss: 2.5229091110767365

Epoch: 5| Step: 5
Training loss: 2.311507037627976
Validation loss: 2.5237914625467974

Epoch: 5| Step: 6
Training loss: 2.4758139841955775
Validation loss: 2.522566590931425

Epoch: 5| Step: 7
Training loss: 1.9343843943625059
Validation loss: 2.5341712476213725

Epoch: 5| Step: 8
Training loss: 2.7594468242417483
Validation loss: 2.5202585437262663

Epoch: 5| Step: 9
Training loss: 2.8601336697372464
Validation loss: 2.5131758502064927

Epoch: 5| Step: 10
Training loss: 2.416138580326729
Validation loss: 2.520960533989232

Epoch: 5| Step: 11
Training loss: 1.593815671278348
Validation loss: 2.517707906198735

Epoch: 74| Step: 0
Training loss: 2.2754184966774735
Validation loss: 2.550087897337888

Epoch: 5| Step: 1
Training loss: 2.033728510597143
Validation loss: 2.5615721666551483

Epoch: 5| Step: 2
Training loss: 2.0945669829220708
Validation loss: 2.552308696735367

Epoch: 5| Step: 3
Training loss: 1.7001287720097573
Validation loss: 2.555749736511611

Epoch: 5| Step: 4
Training loss: 1.8845511991449015
Validation loss: 2.5736490486557146

Epoch: 5| Step: 5
Training loss: 2.5193683896916097
Validation loss: 2.553200867613969

Epoch: 5| Step: 6
Training loss: 3.4449956839081812
Validation loss: 2.576017707258751

Epoch: 5| Step: 7
Training loss: 2.507586032232077
Validation loss: 2.555451771683534

Epoch: 5| Step: 8
Training loss: 2.6203805149193027
Validation loss: 2.557299446254688

Epoch: 5| Step: 9
Training loss: 2.1342323802923566
Validation loss: 2.5570151431389037

Epoch: 5| Step: 10
Training loss: 2.503960809693457
Validation loss: 2.546520153827511

Epoch: 5| Step: 11
Training loss: 2.8104330308879373
Validation loss: 2.5183359075499867

Epoch: 75| Step: 0
Training loss: 2.0798390139122556
Validation loss: 2.5088989780175956

Epoch: 5| Step: 1
Training loss: 2.226682211351481
Validation loss: 2.5179535610755983

Epoch: 5| Step: 2
Training loss: 2.8685866431971005
Validation loss: 2.5248790811944835

Epoch: 5| Step: 3
Training loss: 2.887814862147425
Validation loss: 2.523508832649629

Epoch: 5| Step: 4
Training loss: 2.0202021711041174
Validation loss: 2.5182236622405356

Epoch: 5| Step: 5
Training loss: 1.959443514902137
Validation loss: 2.5141484960464804

Epoch: 5| Step: 6
Training loss: 2.403805965381079
Validation loss: 2.519505116723925

Epoch: 5| Step: 7
Training loss: 2.402737716997452
Validation loss: 2.5374221276171434

Epoch: 5| Step: 8
Training loss: 2.2343843900043074
Validation loss: 2.540361195530564

Epoch: 5| Step: 9
Training loss: 2.2149976781139733
Validation loss: 2.518278448233439

Epoch: 5| Step: 10
Training loss: 2.8662675010389744
Validation loss: 2.5067011825826366

Epoch: 5| Step: 11
Training loss: 2.5342986033034003
Validation loss: 2.527024676912452

Epoch: 76| Step: 0
Training loss: 1.6903444970590442
Validation loss: 2.541249672238738

Epoch: 5| Step: 1
Training loss: 2.3135914675387728
Validation loss: 2.540629152996052

Epoch: 5| Step: 2
Training loss: 2.536938715151313
Validation loss: 2.527180976480318

Epoch: 5| Step: 3
Training loss: 2.5993741199136955
Validation loss: 2.5339645127788746

Epoch: 5| Step: 4
Training loss: 2.4675150812648607
Validation loss: 2.5257324199870834

Epoch: 5| Step: 5
Training loss: 1.8199209684462623
Validation loss: 2.520144629913553

Epoch: 5| Step: 6
Training loss: 2.705065873872303
Validation loss: 2.5246598518193313

Epoch: 5| Step: 7
Training loss: 1.8393619497745521
Validation loss: 2.5340661897521497

Epoch: 5| Step: 8
Training loss: 2.5203901379446654
Validation loss: 2.5408161269739997

Epoch: 5| Step: 9
Training loss: 2.306130684761593
Validation loss: 2.5165825002903377

Epoch: 5| Step: 10
Training loss: 2.931492119979092
Validation loss: 2.522613615288281

Epoch: 5| Step: 11
Training loss: 3.118731964609597
Validation loss: 2.555363891216653

Epoch: 77| Step: 0
Training loss: 1.94940991888054
Validation loss: 2.5519819641741543

Epoch: 5| Step: 1
Training loss: 1.9620364328048459
Validation loss: 2.518619816068528

Epoch: 5| Step: 2
Training loss: 3.063925586464144
Validation loss: 2.5172053362709543

Epoch: 5| Step: 3
Training loss: 1.6954397689934089
Validation loss: 2.528017138116222

Epoch: 5| Step: 4
Training loss: 2.571441217043225
Validation loss: 2.5271397291611724

Epoch: 5| Step: 5
Training loss: 2.316234357094477
Validation loss: 2.525762716929953

Epoch: 5| Step: 6
Training loss: 2.33656287354133
Validation loss: 2.5292322295383065

Epoch: 5| Step: 7
Training loss: 2.658684008038949
Validation loss: 2.5299832035155494

Epoch: 5| Step: 8
Training loss: 1.920192074704967
Validation loss: 2.543624266064063

Epoch: 5| Step: 9
Training loss: 2.775687924594988
Validation loss: 2.518959879590891

Epoch: 5| Step: 10
Training loss: 2.483940710339949
Validation loss: 2.527230652799647

Epoch: 5| Step: 11
Training loss: 1.9620695456020856
Validation loss: 2.55251484680715

Epoch: 78| Step: 0
Training loss: 2.016641286685016
Validation loss: 2.5392595028867353

Epoch: 5| Step: 1
Training loss: 2.7904451933856036
Validation loss: 2.510988377465336

Epoch: 5| Step: 2
Training loss: 2.4229264468790803
Validation loss: 2.5110414579623437

Epoch: 5| Step: 3
Training loss: 2.170461510307107
Validation loss: 2.5287018811306377

Epoch: 5| Step: 4
Training loss: 2.565428944018735
Validation loss: 2.5275449992046943

Epoch: 5| Step: 5
Training loss: 1.8828653035337448
Validation loss: 2.5352052665246974

Epoch: 5| Step: 6
Training loss: 2.496917922852963
Validation loss: 2.512464635040239

Epoch: 5| Step: 7
Training loss: 2.3893443149090063
Validation loss: 2.517256119098854

Epoch: 5| Step: 8
Training loss: 2.2886300052707056
Validation loss: 2.5212706798612543

Epoch: 5| Step: 9
Training loss: 2.1745086728833307
Validation loss: 2.5097471046011797

Epoch: 5| Step: 10
Training loss: 2.6473543095689074
Validation loss: 2.5218164691648157

Epoch: 5| Step: 11
Training loss: 3.1306976257539416
Validation loss: 2.537036592233912

Epoch: 79| Step: 0
Training loss: 2.4564430490977585
Validation loss: 2.5237781700185735

Epoch: 5| Step: 1
Training loss: 2.7604577883170616
Validation loss: 2.520837270849216

Epoch: 5| Step: 2
Training loss: 2.139505803809303
Validation loss: 2.53168048259271

Epoch: 5| Step: 3
Training loss: 2.1147623847610504
Validation loss: 2.5309295137443226

Epoch: 5| Step: 4
Training loss: 2.213429263383835
Validation loss: 2.5193718990432075

Epoch: 5| Step: 5
Training loss: 1.801376211389255
Validation loss: 2.525843342471032

Epoch: 5| Step: 6
Training loss: 2.8812913473807558
Validation loss: 2.531195435897413

Epoch: 5| Step: 7
Training loss: 2.3953598107370606
Validation loss: 2.539055555285224

Epoch: 5| Step: 8
Training loss: 2.717783613662228
Validation loss: 2.544806328719679

Epoch: 5| Step: 9
Training loss: 2.0670402722396455
Validation loss: 2.53781513385427

Epoch: 5| Step: 10
Training loss: 2.4280655037403958
Validation loss: 2.5392078534116007

Epoch: 5| Step: 11
Training loss: 1.4502840881918282
Validation loss: 2.5365311353028206

Epoch: 80| Step: 0
Training loss: 3.155942543086948
Validation loss: 2.5458532401793046

Epoch: 5| Step: 1
Training loss: 2.3026017400772942
Validation loss: 2.5670646527415624

Epoch: 5| Step: 2
Training loss: 2.0682782237385315
Validation loss: 2.565359067434958

Epoch: 5| Step: 3
Training loss: 2.4177104953776474
Validation loss: 2.524984057064524

Epoch: 5| Step: 4
Training loss: 2.372737208126025
Validation loss: 2.5609029778819985

Epoch: 5| Step: 5
Training loss: 2.354488542095892
Validation loss: 2.5440838073792835

Epoch: 5| Step: 6
Training loss: 2.069182811074399
Validation loss: 2.5289563591719957

Epoch: 5| Step: 7
Training loss: 2.6566965961884352
Validation loss: 2.5299777966493795

Epoch: 5| Step: 8
Training loss: 2.318614916709656
Validation loss: 2.4970996284579097

Epoch: 5| Step: 9
Training loss: 1.9819128425904606
Validation loss: 2.4956499161827086

Epoch: 5| Step: 10
Training loss: 2.144469658083536
Validation loss: 2.531155297976372

Epoch: 5| Step: 11
Training loss: 2.5672632931777377
Validation loss: 2.525632600336267

Epoch: 81| Step: 0
Training loss: 2.5931641250200057
Validation loss: 2.5463971857993863

Epoch: 5| Step: 1
Training loss: 2.1652346304601373
Validation loss: 2.53764835982553

Epoch: 5| Step: 2
Training loss: 2.5876662822865444
Validation loss: 2.5688960685873936

Epoch: 5| Step: 3
Training loss: 1.9852813693283433
Validation loss: 2.5580397144363385

Epoch: 5| Step: 4
Training loss: 2.2476719362137834
Validation loss: 2.5995718143385442

Epoch: 5| Step: 5
Training loss: 2.73880866137194
Validation loss: 2.5694393348356654

Epoch: 5| Step: 6
Training loss: 2.4478576869487734
Validation loss: 2.5806922460866857

Epoch: 5| Step: 7
Training loss: 2.404429849624213
Validation loss: 2.5691268567112724

Epoch: 5| Step: 8
Training loss: 2.207638169281485
Validation loss: 2.5862927264873656

Epoch: 5| Step: 9
Training loss: 2.54322356604223
Validation loss: 2.5941801671960354

Epoch: 5| Step: 10
Training loss: 2.0511106971243436
Validation loss: 2.5523894314569597

Epoch: 5| Step: 11
Training loss: 2.2714673711610986
Validation loss: 2.5765503901005617

Epoch: 82| Step: 0
Training loss: 2.513633460971775
Validation loss: 2.515605515746171

Epoch: 5| Step: 1
Training loss: 2.8087393307790918
Validation loss: 2.5547070439297856

Epoch: 5| Step: 2
Training loss: 1.854014451140344
Validation loss: 2.5154299058155583

Epoch: 5| Step: 3
Training loss: 2.938779836200592
Validation loss: 2.503168688776615

Epoch: 5| Step: 4
Training loss: 2.1772955345397103
Validation loss: 2.5148682848185944

Epoch: 5| Step: 5
Training loss: 1.8027186367219967
Validation loss: 2.525976594434165

Epoch: 5| Step: 6
Training loss: 2.370975497720509
Validation loss: 2.519686723195109

Epoch: 5| Step: 7
Training loss: 2.1698146350638132
Validation loss: 2.5144455634688847

Epoch: 5| Step: 8
Training loss: 2.2302823230978306
Validation loss: 2.515949642960898

Epoch: 5| Step: 9
Training loss: 2.595580408827938
Validation loss: 2.5395346178155194

Epoch: 5| Step: 10
Training loss: 2.414895219602991
Validation loss: 2.542177132771178

Epoch: 5| Step: 11
Training loss: 1.309725235231794
Validation loss: 2.532480301938863

Epoch: 83| Step: 0
Training loss: 2.741000622331395
Validation loss: 2.522920793791928

Epoch: 5| Step: 1
Training loss: 2.892221865457552
Validation loss: 2.5348711681295932

Epoch: 5| Step: 2
Training loss: 2.995337359703828
Validation loss: 2.517393012155266

Epoch: 5| Step: 3
Training loss: 2.324947672429406
Validation loss: 2.547941320107173

Epoch: 5| Step: 4
Training loss: 2.2904694175185774
Validation loss: 2.5246579198170354

Epoch: 5| Step: 5
Training loss: 2.401135049081118
Validation loss: 2.5512587999425422

Epoch: 5| Step: 6
Training loss: 2.426024493861947
Validation loss: 2.522987951620351

Epoch: 5| Step: 7
Training loss: 1.7359626994806188
Validation loss: 2.5304696132041697

Epoch: 5| Step: 8
Training loss: 2.289203418130704
Validation loss: 2.5105796394368665

Epoch: 5| Step: 9
Training loss: 2.0355055613581174
Validation loss: 2.525505246233433

Epoch: 5| Step: 10
Training loss: 1.519941181500438
Validation loss: 2.528780808203765

Epoch: 5| Step: 11
Training loss: 1.3648104684895561
Validation loss: 2.525930438919263

Epoch: 84| Step: 0
Training loss: 1.9728792272262758
Validation loss: 2.547148812676124

Epoch: 5| Step: 1
Training loss: 2.6500539882126732
Validation loss: 2.548881972561386

Epoch: 5| Step: 2
Training loss: 2.6439169504104556
Validation loss: 2.566690151511746

Epoch: 5| Step: 3
Training loss: 2.2737546090052585
Validation loss: 2.5853490438437268

Epoch: 5| Step: 4
Training loss: 2.040065241125714
Validation loss: 2.5983747936947332

Epoch: 5| Step: 5
Training loss: 2.27963973394687
Validation loss: 2.604232841922465

Epoch: 5| Step: 6
Training loss: 2.6574445843234438
Validation loss: 2.5855511725390437

Epoch: 5| Step: 7
Training loss: 2.3718924017909893
Validation loss: 2.5692922544227583

Epoch: 5| Step: 8
Training loss: 2.2896553808046964
Validation loss: 2.565925556997977

Epoch: 5| Step: 9
Training loss: 2.664602812178108
Validation loss: 2.5297677287934954

Epoch: 5| Step: 10
Training loss: 1.9211987181690013
Validation loss: 2.550357921731686

Epoch: 5| Step: 11
Training loss: 2.3775079435422386
Validation loss: 2.5394535839450265

Epoch: 85| Step: 0
Training loss: 2.2617288697960127
Validation loss: 2.535119176435825

Epoch: 5| Step: 1
Training loss: 2.0536963099068943
Validation loss: 2.51546527126413

Epoch: 5| Step: 2
Training loss: 2.359823424312316
Validation loss: 2.514179837412902

Epoch: 5| Step: 3
Training loss: 2.2710970337604186
Validation loss: 2.5347390872504576

Epoch: 5| Step: 4
Training loss: 2.7538910128124567
Validation loss: 2.522396150318929

Epoch: 5| Step: 5
Training loss: 2.000143284433433
Validation loss: 2.556137719366047

Epoch: 5| Step: 6
Training loss: 2.2034753831942986
Validation loss: 2.5544796760945494

Epoch: 5| Step: 7
Training loss: 1.8214919562757734
Validation loss: 2.5622265871461942

Epoch: 5| Step: 8
Training loss: 2.5956105372877682
Validation loss: 2.5458158853518817

Epoch: 5| Step: 9
Training loss: 2.887308228304837
Validation loss: 2.5500880921175875

Epoch: 5| Step: 10
Training loss: 1.995250964429417
Validation loss: 2.564633423393284

Epoch: 5| Step: 11
Training loss: 3.0477547182527394
Validation loss: 2.5298695744380377

Epoch: 86| Step: 0
Training loss: 2.303110184227172
Validation loss: 2.5507206152602038

Epoch: 5| Step: 1
Training loss: 2.6731130843468898
Validation loss: 2.5683311470520827

Epoch: 5| Step: 2
Training loss: 1.9266664896154266
Validation loss: 2.5375993356851465

Epoch: 5| Step: 3
Training loss: 2.0500069455284993
Validation loss: 2.551307596655821

Epoch: 5| Step: 4
Training loss: 2.281002815127778
Validation loss: 2.563798590884228

Epoch: 5| Step: 5
Training loss: 2.457013007310059
Validation loss: 2.5354598362699905

Epoch: 5| Step: 6
Training loss: 2.4255998085952926
Validation loss: 2.5481945239317993

Epoch: 5| Step: 7
Training loss: 2.9930686350509865
Validation loss: 2.5618614781359357

Epoch: 5| Step: 8
Training loss: 1.7737377433541568
Validation loss: 2.5538729828380995

Epoch: 5| Step: 9
Training loss: 1.617048764382318
Validation loss: 2.5540875538267303

Epoch: 5| Step: 10
Training loss: 2.6360883397131682
Validation loss: 2.532285533433645

Epoch: 5| Step: 11
Training loss: 2.345585320632871
Validation loss: 2.520522623906642

Epoch: 87| Step: 0
Training loss: 2.183209161891703
Validation loss: 2.532200171856239

Epoch: 5| Step: 1
Training loss: 2.666506543915217
Validation loss: 2.501111331929614

Epoch: 5| Step: 2
Training loss: 2.2346097382704317
Validation loss: 2.5214241822393775

Epoch: 5| Step: 3
Training loss: 2.8543379980486705
Validation loss: 2.520570383991228

Epoch: 5| Step: 4
Training loss: 2.213323054270641
Validation loss: 2.516366663687257

Epoch: 5| Step: 5
Training loss: 2.7835407038967914
Validation loss: 2.5134365403384065

Epoch: 5| Step: 6
Training loss: 2.244197887888602
Validation loss: 2.52489646173718

Epoch: 5| Step: 7
Training loss: 2.160251608428692
Validation loss: 2.5377388423643956

Epoch: 5| Step: 8
Training loss: 2.3732341425595065
Validation loss: 2.5380264692102386

Epoch: 5| Step: 9
Training loss: 2.0228994235853386
Validation loss: 2.5193168174317195

Epoch: 5| Step: 10
Training loss: 1.975969308491244
Validation loss: 2.523988693082001

Epoch: 5| Step: 11
Training loss: 1.6147908313276427
Validation loss: 2.5149774172004746

Epoch: 88| Step: 0
Training loss: 2.1644901445269724
Validation loss: 2.524323806772508

Epoch: 5| Step: 1
Training loss: 2.6419181591702303
Validation loss: 2.524712038930967

Epoch: 5| Step: 2
Training loss: 2.3533555605579832
Validation loss: 2.5348466939861436

Epoch: 5| Step: 3
Training loss: 2.225219964287875
Validation loss: 2.566476144521115

Epoch: 5| Step: 4
Training loss: 1.638034046243121
Validation loss: 2.5498218104804047

Epoch: 5| Step: 5
Training loss: 2.349366946885255
Validation loss: 2.5828872162153815

Epoch: 5| Step: 6
Training loss: 2.6218400736904752
Validation loss: 2.59260853388467

Epoch: 5| Step: 7
Training loss: 1.8661817451561302
Validation loss: 2.581037567732352

Epoch: 5| Step: 8
Training loss: 2.3981768438498112
Validation loss: 2.6049982739465403

Epoch: 5| Step: 9
Training loss: 2.7630621463276923
Validation loss: 2.5901722534259677

Epoch: 5| Step: 10
Training loss: 2.75194602082786
Validation loss: 2.579543380516226

Epoch: 5| Step: 11
Training loss: 1.1772905465541883
Validation loss: 2.547737303248419

Epoch: 89| Step: 0
Training loss: 2.149641441786762
Validation loss: 2.552332166620753

Epoch: 5| Step: 1
Training loss: 2.1186974127891007
Validation loss: 2.541576578675135

Epoch: 5| Step: 2
Training loss: 2.1277898538555
Validation loss: 2.531298165981593

Epoch: 5| Step: 3
Training loss: 2.1997982366115574
Validation loss: 2.539298773311642

Epoch: 5| Step: 4
Training loss: 2.564365173365643
Validation loss: 2.5336216032144168

Epoch: 5| Step: 5
Training loss: 2.028462654302189
Validation loss: 2.515802890498213

Epoch: 5| Step: 6
Training loss: 1.979447140813911
Validation loss: 2.5055441059690664

Epoch: 5| Step: 7
Training loss: 2.552580171347895
Validation loss: 2.524697496057814

Epoch: 5| Step: 8
Training loss: 2.1295724928680806
Validation loss: 2.518515056146928

Epoch: 5| Step: 9
Training loss: 2.427112748345732
Validation loss: 2.5364610540126074

Epoch: 5| Step: 10
Training loss: 2.9051654391691484
Validation loss: 2.529610593528772

Epoch: 5| Step: 11
Training loss: 3.316693512569897
Validation loss: 2.527996102855944

Epoch: 90| Step: 0
Training loss: 2.3788703702779657
Validation loss: 2.5228182581056133

Epoch: 5| Step: 1
Training loss: 2.484167030314824
Validation loss: 2.51991021512307

Epoch: 5| Step: 2
Training loss: 1.922316585765259
Validation loss: 2.5129096143287604

Epoch: 5| Step: 3
Training loss: 2.4891901916202777
Validation loss: 2.517241908061019

Epoch: 5| Step: 4
Training loss: 2.384214195338613
Validation loss: 2.554874885756169

Epoch: 5| Step: 5
Training loss: 2.2042622978747404
Validation loss: 2.5270910062985292

Epoch: 5| Step: 6
Training loss: 2.6714128239533976
Validation loss: 2.53194501542251

Epoch: 5| Step: 7
Training loss: 2.1594174106258865
Validation loss: 2.5261248676454104

Epoch: 5| Step: 8
Training loss: 2.0850563045373187
Validation loss: 2.53181352347208

Epoch: 5| Step: 9
Training loss: 2.46015719198413
Validation loss: 2.567341874430926

Epoch: 5| Step: 10
Training loss: 2.1752317546276148
Validation loss: 2.5441314882965314

Epoch: 5| Step: 11
Training loss: 2.280763339036167
Validation loss: 2.532519571574516

Epoch: 91| Step: 0
Training loss: 1.8845969959781206
Validation loss: 2.5331332536059854

Epoch: 5| Step: 1
Training loss: 2.7035742590335645
Validation loss: 2.5315147387046455

Epoch: 5| Step: 2
Training loss: 1.9854923616798894
Validation loss: 2.5290966961172336

Epoch: 5| Step: 3
Training loss: 1.842214170979534
Validation loss: 2.527364930226774

Epoch: 5| Step: 4
Training loss: 1.9058899461249361
Validation loss: 2.532038958164163

Epoch: 5| Step: 5
Training loss: 2.930956756304026
Validation loss: 2.5137598614631247

Epoch: 5| Step: 6
Training loss: 2.2879874663709923
Validation loss: 2.5210109298715766

Epoch: 5| Step: 7
Training loss: 1.99272567361272
Validation loss: 2.519391744531663

Epoch: 5| Step: 8
Training loss: 2.7939829445484254
Validation loss: 2.5249888943122647

Epoch: 5| Step: 9
Training loss: 2.1915626946023146
Validation loss: 2.541058224539153

Epoch: 5| Step: 10
Training loss: 2.6983817054445036
Validation loss: 2.534395175168363

Epoch: 5| Step: 11
Training loss: 2.5760874701866654
Validation loss: 2.5416817325916794

Epoch: 92| Step: 0
Training loss: 2.4411497912175775
Validation loss: 2.53079269736631

Epoch: 5| Step: 1
Training loss: 2.643510765271664
Validation loss: 2.5357970459926533

Epoch: 5| Step: 2
Training loss: 2.108847432036672
Validation loss: 2.5255512875822363

Epoch: 5| Step: 3
Training loss: 2.262836397569278
Validation loss: 2.504445125618902

Epoch: 5| Step: 4
Training loss: 2.8004727373231533
Validation loss: 2.525580036940263

Epoch: 5| Step: 5
Training loss: 1.640628342398009
Validation loss: 2.534985638928286

Epoch: 5| Step: 6
Training loss: 2.114644342553992
Validation loss: 2.5223172814310595

Epoch: 5| Step: 7
Training loss: 2.3912781465173034
Validation loss: 2.5189225360978114

Epoch: 5| Step: 8
Training loss: 2.5835478191139956
Validation loss: 2.496598600097205

Epoch: 5| Step: 9
Training loss: 2.0996371954915567
Validation loss: 2.4960631486572016

Epoch: 5| Step: 10
Training loss: 2.0764491846125384
Validation loss: 2.498418061111404

Epoch: 5| Step: 11
Training loss: 2.5925961421256014
Validation loss: 2.509253296962983

Epoch: 93| Step: 0
Training loss: 2.294248051842383
Validation loss: 2.5245846521622073

Epoch: 5| Step: 1
Training loss: 2.164137966341245
Validation loss: 2.525328774812227

Epoch: 5| Step: 2
Training loss: 2.383126059991384
Validation loss: 2.54114831005762

Epoch: 5| Step: 3
Training loss: 2.118497661316485
Validation loss: 2.5347038457079507

Epoch: 5| Step: 4
Training loss: 2.5042178812571123
Validation loss: 2.5534504919920264

Epoch: 5| Step: 5
Training loss: 2.4292560942619428
Validation loss: 2.535108412030195

Epoch: 5| Step: 6
Training loss: 2.3023726912932747
Validation loss: 2.5272902257519667

Epoch: 5| Step: 7
Training loss: 2.375476789299669
Validation loss: 2.5523642145369227

Epoch: 5| Step: 8
Training loss: 1.8010488712599861
Validation loss: 2.569530286872848

Epoch: 5| Step: 9
Training loss: 2.423167123967113
Validation loss: 2.531938612248752

Epoch: 5| Step: 10
Training loss: 2.4533489149400456
Validation loss: 2.5576917965884607

Epoch: 5| Step: 11
Training loss: 2.3037088676336612
Validation loss: 2.5637010457885743

Epoch: 94| Step: 0
Training loss: 2.8980947944822604
Validation loss: 2.538978915672756

Epoch: 5| Step: 1
Training loss: 1.9399924704808678
Validation loss: 2.579041081289553

Epoch: 5| Step: 2
Training loss: 2.279338506140264
Validation loss: 2.5354236075829504

Epoch: 5| Step: 3
Training loss: 2.4580872514912087
Validation loss: 2.5589911348838537

Epoch: 5| Step: 4
Training loss: 2.0741826573336994
Validation loss: 2.547387993914305

Epoch: 5| Step: 5
Training loss: 1.5565851026945305
Validation loss: 2.5453781729871374

Epoch: 5| Step: 6
Training loss: 2.0871212918432014
Validation loss: 2.552739375643902

Epoch: 5| Step: 7
Training loss: 2.2770357267167833
Validation loss: 2.534562024115727

Epoch: 5| Step: 8
Training loss: 2.121716599317596
Validation loss: 2.521105528288663

Epoch: 5| Step: 9
Training loss: 2.4470672648810736
Validation loss: 2.5196707280312944

Epoch: 5| Step: 10
Training loss: 2.8607676298836195
Validation loss: 2.52228739603379

Epoch: 5| Step: 11
Training loss: 2.0813605568421165
Validation loss: 2.53016788994253

Epoch: 95| Step: 0
Training loss: 1.935733112571428
Validation loss: 2.522858402661989

Epoch: 5| Step: 1
Training loss: 2.5035190610226654
Validation loss: 2.517662838067231

Epoch: 5| Step: 2
Training loss: 2.8206212939342223
Validation loss: 2.5210358102258263

Epoch: 5| Step: 3
Training loss: 1.6784077581946362
Validation loss: 2.526364482164993

Epoch: 5| Step: 4
Training loss: 2.1658740672436823
Validation loss: 2.5216986961299304

Epoch: 5| Step: 5
Training loss: 2.1783918132486653
Validation loss: 2.491759405967193

Epoch: 5| Step: 6
Training loss: 2.2504059107532304
Validation loss: 2.535552156057242

Epoch: 5| Step: 7
Training loss: 2.496321260354905
Validation loss: 2.5064424157104224

Epoch: 5| Step: 8
Training loss: 1.8452070265819134
Validation loss: 2.4977369436832086

Epoch: 5| Step: 9
Training loss: 2.373450325786198
Validation loss: 2.5025628463927667

Epoch: 5| Step: 10
Training loss: 2.2546443689229934
Validation loss: 2.5377954069921893

Epoch: 5| Step: 11
Training loss: 3.4862760139225157
Validation loss: 2.535561237795042

Epoch: 96| Step: 0
Training loss: 2.0864385224606576
Validation loss: 2.5288975659412722

Epoch: 5| Step: 1
Training loss: 2.2879567258383804
Validation loss: 2.5138075405878193

Epoch: 5| Step: 2
Training loss: 2.191098767908462
Validation loss: 2.532931452222357

Epoch: 5| Step: 3
Training loss: 2.0566019052771374
Validation loss: 2.5221469263783427

Epoch: 5| Step: 4
Training loss: 2.1365557230068744
Validation loss: 2.4840910647342334

Epoch: 5| Step: 5
Training loss: 1.8552485606397817
Validation loss: 2.5286053629084444

Epoch: 5| Step: 6
Training loss: 2.3327254343616866
Validation loss: 2.549468586282463

Epoch: 5| Step: 7
Training loss: 2.2146445963565773
Validation loss: 2.539753081479966

Epoch: 5| Step: 8
Training loss: 2.4295646415632124
Validation loss: 2.533296303467994

Epoch: 5| Step: 9
Training loss: 2.415174308472914
Validation loss: 2.52275908949578

Epoch: 5| Step: 10
Training loss: 2.7938947943047294
Validation loss: 2.514701511847621

Epoch: 5| Step: 11
Training loss: 3.1062388490902717
Validation loss: 2.537516233630314

Epoch: 97| Step: 0
Training loss: 2.781985324993686
Validation loss: 2.518936138200948

Epoch: 5| Step: 1
Training loss: 1.990496287833276
Validation loss: 2.547033987563138

Epoch: 5| Step: 2
Training loss: 2.4191307024549755
Validation loss: 2.533120159122897

Epoch: 5| Step: 3
Training loss: 2.791550837908463
Validation loss: 2.567246799244608

Epoch: 5| Step: 4
Training loss: 2.3987021036221625
Validation loss: 2.544073674434713

Epoch: 5| Step: 5
Training loss: 2.1966306591218276
Validation loss: 2.5200652667958883

Epoch: 5| Step: 6
Training loss: 1.6626041809939884
Validation loss: 2.5428771760843074

Epoch: 5| Step: 7
Training loss: 2.023034957847696
Validation loss: 2.531276282813742

Epoch: 5| Step: 8
Training loss: 2.1822947014276957
Validation loss: 2.555034252280553

Epoch: 5| Step: 9
Training loss: 1.4892681384119482
Validation loss: 2.5186893012508316

Epoch: 5| Step: 10
Training loss: 2.6791060904086184
Validation loss: 2.526720165616908

Epoch: 5| Step: 11
Training loss: 3.1909756130624345
Validation loss: 2.5312542895684964

Epoch: 98| Step: 0
Training loss: 2.4831708953095637
Validation loss: 2.5104455167977773

Epoch: 5| Step: 1
Training loss: 2.244365737288293
Validation loss: 2.530617768407733

Epoch: 5| Step: 2
Training loss: 2.5470204692088454
Validation loss: 2.5226663684770028

Epoch: 5| Step: 3
Training loss: 2.3550978537799456
Validation loss: 2.4986849862871203

Epoch: 5| Step: 4
Training loss: 1.895854998733752
Validation loss: 2.5258932417428293

Epoch: 5| Step: 5
Training loss: 2.5429955640747406
Validation loss: 2.531720106009977

Epoch: 5| Step: 6
Training loss: 2.0609389668792755
Validation loss: 2.5287658605299734

Epoch: 5| Step: 7
Training loss: 2.5556790821886213
Validation loss: 2.5098761112419594

Epoch: 5| Step: 8
Training loss: 2.104946659164371
Validation loss: 2.5131145393940026

Epoch: 5| Step: 9
Training loss: 1.8120544148962983
Validation loss: 2.5279118107332574

Epoch: 5| Step: 10
Training loss: 2.2672395412327084
Validation loss: 2.536759307101641

Epoch: 5| Step: 11
Training loss: 2.7634311746440563
Validation loss: 2.524632484927975

Epoch: 99| Step: 0
Training loss: 2.65088308843092
Validation loss: 2.5248326439680797

Epoch: 5| Step: 1
Training loss: 1.7763692678614467
Validation loss: 2.534840470579397

Epoch: 5| Step: 2
Training loss: 2.657972248710387
Validation loss: 2.568087970816064

Epoch: 5| Step: 3
Training loss: 2.3288032516640254
Validation loss: 2.571205838067895

Epoch: 5| Step: 4
Training loss: 2.264480933360334
Validation loss: 2.557824140897783

Epoch: 5| Step: 5
Training loss: 2.360953907938
Validation loss: 2.5692182026026

Epoch: 5| Step: 6
Training loss: 2.477272966685534
Validation loss: 2.5794337486143744

Epoch: 5| Step: 7
Training loss: 1.9570659702898752
Validation loss: 2.5776921804841737

Epoch: 5| Step: 8
Training loss: 2.3377742626835
Validation loss: 2.581801446103811

Epoch: 5| Step: 9
Training loss: 2.28698740567975
Validation loss: 2.5658433859185186

Epoch: 5| Step: 10
Training loss: 1.7742142509695682
Validation loss: 2.551220683188414

Epoch: 5| Step: 11
Training loss: 2.529563059111105
Validation loss: 2.517909223291014

Epoch: 100| Step: 0
Training loss: 2.087727325305357
Validation loss: 2.533721394342116

Epoch: 5| Step: 1
Training loss: 2.215101439002467
Validation loss: 2.5170442475297032

Epoch: 5| Step: 2
Training loss: 2.617995407893129
Validation loss: 2.51695796646982

Epoch: 5| Step: 3
Training loss: 2.401980786700117
Validation loss: 2.5122570847201247

Epoch: 5| Step: 4
Training loss: 1.9398843184126322
Validation loss: 2.507203625357687

Epoch: 5| Step: 5
Training loss: 2.854617637777458
Validation loss: 2.517424873479935

Epoch: 5| Step: 6
Training loss: 2.3327036643781445
Validation loss: 2.5274657033812633

Epoch: 5| Step: 7
Training loss: 2.2033735635559832
Validation loss: 2.5288116460952264

Epoch: 5| Step: 8
Training loss: 2.300351269476507
Validation loss: 2.5114566751287666

Epoch: 5| Step: 9
Training loss: 2.276646292983008
Validation loss: 2.502842816668434

Epoch: 5| Step: 10
Training loss: 1.8458012953389646
Validation loss: 2.514918490726512

Epoch: 5| Step: 11
Training loss: 2.4921846300066743
Validation loss: 2.524619594252074

Epoch: 101| Step: 0
Training loss: 2.321619455642993
Validation loss: 2.5175148832922343

Epoch: 5| Step: 1
Training loss: 1.5738042470295153
Validation loss: 2.5305680663265644

Epoch: 5| Step: 2
Training loss: 2.5276631502796687
Validation loss: 2.5320756648804754

Epoch: 5| Step: 3
Training loss: 2.6546794062732983
Validation loss: 2.5824891538967703

Epoch: 5| Step: 4
Training loss: 2.5831161735895205
Validation loss: 2.549837036005536

Epoch: 5| Step: 5
Training loss: 1.9699653023118509
Validation loss: 2.5643567282385007

Epoch: 5| Step: 6
Training loss: 2.552452112658443
Validation loss: 2.5980077634765886

Epoch: 5| Step: 7
Training loss: 2.054377195184763
Validation loss: 2.536921865470983

Epoch: 5| Step: 8
Training loss: 2.3763024623644102
Validation loss: 2.539389748636489

Epoch: 5| Step: 9
Training loss: 2.2363236473071986
Validation loss: 2.5335409330857317

Epoch: 5| Step: 10
Training loss: 2.070512524424822
Validation loss: 2.5472379203545157

Epoch: 5| Step: 11
Training loss: 1.7757081942754673
Validation loss: 2.51992250701797

Epoch: 102| Step: 0
Training loss: 2.1201536227292985
Validation loss: 2.554878138312938

Epoch: 5| Step: 1
Training loss: 1.8724300574162367
Validation loss: 2.5280823844269693

Epoch: 5| Step: 2
Training loss: 1.7660518569115289
Validation loss: 2.5498970177680675

Epoch: 5| Step: 3
Training loss: 1.9257173663022125
Validation loss: 2.5213546305871852

Epoch: 5| Step: 4
Training loss: 2.529208549223952
Validation loss: 2.5305533058648755

Epoch: 5| Step: 5
Training loss: 3.1602048363269026
Validation loss: 2.5307592889615984

Epoch: 5| Step: 6
Training loss: 3.025183988918539
Validation loss: 2.5302128845295364

Epoch: 5| Step: 7
Training loss: 2.01460394021994
Validation loss: 2.5266728284499824

Epoch: 5| Step: 8
Training loss: 1.6094687721562486
Validation loss: 2.526600452767927

Epoch: 5| Step: 9
Training loss: 2.4068917743868004
Validation loss: 2.522211105531775

Epoch: 5| Step: 10
Training loss: 2.130033254229505
Validation loss: 2.4939147998338296

Epoch: 5| Step: 11
Training loss: 2.1640855257757985
Validation loss: 2.509152799960963

Epoch: 103| Step: 0
Training loss: 2.3589448852568995
Validation loss: 2.5259731611158487

Epoch: 5| Step: 1
Training loss: 2.242706345130428
Validation loss: 2.532347806064768

Epoch: 5| Step: 2
Training loss: 1.8254021475861113
Validation loss: 2.5518523027337316

Epoch: 5| Step: 3
Training loss: 2.332387210126446
Validation loss: 2.5642328450991325

Epoch: 5| Step: 4
Training loss: 2.3533553579378665
Validation loss: 2.556175416916967

Epoch: 5| Step: 5
Training loss: 2.190486177625062
Validation loss: 2.5442348537549613

Epoch: 5| Step: 6
Training loss: 1.9521203470809132
Validation loss: 2.5648121443276923

Epoch: 5| Step: 7
Training loss: 2.2530524423373643
Validation loss: 2.5677759511116167

Epoch: 5| Step: 8
Training loss: 2.1481800271856217
Validation loss: 2.5506748490781432

Epoch: 5| Step: 9
Training loss: 2.6867882429244205
Validation loss: 2.5482958904178483

Epoch: 5| Step: 10
Training loss: 2.388580245649031
Validation loss: 2.5390656652186303

Epoch: 5| Step: 11
Training loss: 1.3073936311185905
Validation loss: 2.547677578681321

Epoch: 104| Step: 0
Training loss: 2.194672840910825
Validation loss: 2.5784411303970423

Epoch: 5| Step: 1
Training loss: 2.5339080606174065
Validation loss: 2.557233630426279

Epoch: 5| Step: 2
Training loss: 1.61177276949792
Validation loss: 2.5595658375161086

Epoch: 5| Step: 3
Training loss: 2.6135777417872466
Validation loss: 2.5732407204939287

Epoch: 5| Step: 4
Training loss: 2.5134350265686165
Validation loss: 2.566509432486918

Epoch: 5| Step: 5
Training loss: 2.5953396441505987
Validation loss: 2.5371665018221896

Epoch: 5| Step: 6
Training loss: 2.428997861865168
Validation loss: 2.5317331920389927

Epoch: 5| Step: 7
Training loss: 1.8826210272843142
Validation loss: 2.541555731859072

Epoch: 5| Step: 8
Training loss: 2.1158932041122718
Validation loss: 2.5099232467058834

Epoch: 5| Step: 9
Training loss: 1.5819468534587275
Validation loss: 2.5107092442843353

Epoch: 5| Step: 10
Training loss: 2.632504317813531
Validation loss: 2.504034335648759

Epoch: 5| Step: 11
Training loss: 0.7466436227225572
Validation loss: 2.5244509391132595

Epoch: 105| Step: 0
Training loss: 2.2855015681262865
Validation loss: 2.5058979280221165

Epoch: 5| Step: 1
Training loss: 1.6926370772011248
Validation loss: 2.5093635603159807

Epoch: 5| Step: 2
Training loss: 2.5143465383096006
Validation loss: 2.5289405365541433

Epoch: 5| Step: 3
Training loss: 2.0546299451302126
Validation loss: 2.5136931210252085

Epoch: 5| Step: 4
Training loss: 2.0494552539818307
Validation loss: 2.5172813996304497

Epoch: 5| Step: 5
Training loss: 2.085236277925797
Validation loss: 2.5333097303591807

Epoch: 5| Step: 6
Training loss: 2.0470062679684924
Validation loss: 2.5179752010081735

Epoch: 5| Step: 7
Training loss: 2.72898350651874
Validation loss: 2.5041905884914546

Epoch: 5| Step: 8
Training loss: 2.238430584091757
Validation loss: 2.5316815969852717

Epoch: 5| Step: 9
Training loss: 2.486762860596343
Validation loss: 2.5262560501101685

Epoch: 5| Step: 10
Training loss: 2.3369122260883923
Validation loss: 2.5163970773398066

Epoch: 5| Step: 11
Training loss: 1.6241076293335814
Validation loss: 2.531645881244383

Epoch: 106| Step: 0
Training loss: 1.8459061768268346
Validation loss: 2.519146296937969

Epoch: 5| Step: 1
Training loss: 2.1216462541523713
Validation loss: 2.557471171266637

Epoch: 5| Step: 2
Training loss: 2.0533620526216825
Validation loss: 2.6099611183719675

Epoch: 5| Step: 3
Training loss: 1.9784393446471888
Validation loss: 2.6116807462251477

Epoch: 5| Step: 4
Training loss: 2.604543267039888
Validation loss: 2.6484231338936546

Epoch: 5| Step: 5
Training loss: 2.892110247123812
Validation loss: 2.644208549370585

Epoch: 5| Step: 6
Training loss: 2.1202279531535613
Validation loss: 2.6647636110007262

Epoch: 5| Step: 7
Training loss: 1.406740357418309
Validation loss: 2.62811466143945

Epoch: 5| Step: 8
Training loss: 2.8074036943285674
Validation loss: 2.63415985646786

Epoch: 5| Step: 9
Training loss: 2.2740785933629257
Validation loss: 2.59569264245482

Epoch: 5| Step: 10
Training loss: 2.4319223999015813
Validation loss: 2.5828718932073618

Epoch: 5| Step: 11
Training loss: 2.2591837906291086
Validation loss: 2.5257813204808475

Epoch: 107| Step: 0
Training loss: 2.9776391512675158
Validation loss: 2.5343679251613245

Epoch: 5| Step: 1
Training loss: 1.7194323485727374
Validation loss: 2.5203567571946097

Epoch: 5| Step: 2
Training loss: 2.25728170630055
Validation loss: 2.5281258502513966

Epoch: 5| Step: 3
Training loss: 1.785248468133162
Validation loss: 2.560439630585987

Epoch: 5| Step: 4
Training loss: 2.328161252142773
Validation loss: 2.583087372350806

Epoch: 5| Step: 5
Training loss: 2.031399178528946
Validation loss: 2.5624063288617944

Epoch: 5| Step: 6
Training loss: 1.8845765646554946
Validation loss: 2.570299927314534

Epoch: 5| Step: 7
Training loss: 2.426088273771956
Validation loss: 2.5755291827111186

Epoch: 5| Step: 8
Training loss: 2.7722617652568418
Validation loss: 2.5438198065962228

Epoch: 5| Step: 9
Training loss: 2.6940792192339216
Validation loss: 2.5411723404023276

Epoch: 5| Step: 10
Training loss: 2.3071131468542445
Validation loss: 2.5286122263211532

Epoch: 5| Step: 11
Training loss: 2.4667484523342678
Validation loss: 2.509145622015247

Epoch: 108| Step: 0
Training loss: 2.2766776051218964
Validation loss: 2.5085393143565673

Epoch: 5| Step: 1
Training loss: 2.6131187582317805
Validation loss: 2.519224265467801

Epoch: 5| Step: 2
Training loss: 2.485569504810644
Validation loss: 2.557321914732219

Epoch: 5| Step: 3
Training loss: 2.4068782035907357
Validation loss: 2.6016178258868656

Epoch: 5| Step: 4
Training loss: 2.86616352308525
Validation loss: 2.6051858179298244

Epoch: 5| Step: 5
Training loss: 2.064194416736924
Validation loss: 2.6183064929619255

Epoch: 5| Step: 6
Training loss: 2.2037147111496096
Validation loss: 2.5893279914661718

Epoch: 5| Step: 7
Training loss: 2.1357033389813838
Validation loss: 2.6108410841624563

Epoch: 5| Step: 8
Training loss: 1.9263942276852328
Validation loss: 2.636900225387053

Epoch: 5| Step: 9
Training loss: 2.066699982446375
Validation loss: 2.6048442696524363

Epoch: 5| Step: 10
Training loss: 1.5063482102156598
Validation loss: 2.5659974738911626

Epoch: 5| Step: 11
Training loss: 1.330462429638655
Validation loss: 2.531851075080651

Epoch: 109| Step: 0
Training loss: 2.090877327281947
Validation loss: 2.5507026064376026

Epoch: 5| Step: 1
Training loss: 1.7822508426214252
Validation loss: 2.546175999272256

Epoch: 5| Step: 2
Training loss: 1.7781074643736947
Validation loss: 2.5405319930378707

Epoch: 5| Step: 3
Training loss: 2.2205930764770043
Validation loss: 2.5659375665160047

Epoch: 5| Step: 4
Training loss: 2.1780834790600085
Validation loss: 2.5319137958739306

Epoch: 5| Step: 5
Training loss: 2.3362741897498167
Validation loss: 2.541817380522379

Epoch: 5| Step: 6
Training loss: 2.276011370028771
Validation loss: 2.535028529856224

Epoch: 5| Step: 7
Training loss: 2.1062086288056605
Validation loss: 2.549389348901144

Epoch: 5| Step: 8
Training loss: 2.798879235620204
Validation loss: 2.592112978277361

Epoch: 5| Step: 9
Training loss: 2.409045886409121
Validation loss: 2.556837310880009

Epoch: 5| Step: 10
Training loss: 2.307781457401665
Validation loss: 2.506741961728963

Epoch: 5| Step: 11
Training loss: 1.8989678415244216
Validation loss: 2.5269770329177303

Epoch: 110| Step: 0
Training loss: 2.194926163424301
Validation loss: 2.544259503097581

Epoch: 5| Step: 1
Training loss: 1.9577268784197301
Validation loss: 2.4933612773875455

Epoch: 5| Step: 2
Training loss: 2.0484458195730535
Validation loss: 2.5151007206658123

Epoch: 5| Step: 3
Training loss: 2.06876565979162
Validation loss: 2.5103225426552354

Epoch: 5| Step: 4
Training loss: 1.692457335031551
Validation loss: 2.526089942444606

Epoch: 5| Step: 5
Training loss: 2.5762478554766233
Validation loss: 2.543967719293616

Epoch: 5| Step: 6
Training loss: 2.4256273303749314
Validation loss: 2.526352245206504

Epoch: 5| Step: 7
Training loss: 1.837059489795042
Validation loss: 2.519883874864787

Epoch: 5| Step: 8
Training loss: 2.7881719626067554
Validation loss: 2.5131387883835603

Epoch: 5| Step: 9
Training loss: 2.887927967409556
Validation loss: 2.5316354944692847

Epoch: 5| Step: 10
Training loss: 2.0451398877190177
Validation loss: 2.5028685880941275

Epoch: 5| Step: 11
Training loss: 2.3605213538240086
Validation loss: 2.540282147254706

Epoch: 111| Step: 0
Training loss: 2.350511791421202
Validation loss: 2.530472163007381

Epoch: 5| Step: 1
Training loss: 2.0185848062203293
Validation loss: 2.5945814937055944

Epoch: 5| Step: 2
Training loss: 1.9794283509841137
Validation loss: 2.6042750806493977

Epoch: 5| Step: 3
Training loss: 2.626130087873378
Validation loss: 2.640657800925923

Epoch: 5| Step: 4
Training loss: 2.0194050437701803
Validation loss: 2.6505431635230754

Epoch: 5| Step: 5
Training loss: 1.9919027686001354
Validation loss: 2.6707685458755734

Epoch: 5| Step: 6
Training loss: 2.4913396559075225
Validation loss: 2.6630658796054223

Epoch: 5| Step: 7
Training loss: 1.8790882680684549
Validation loss: 2.673411267863654

Epoch: 5| Step: 8
Training loss: 2.282400703234051
Validation loss: 2.6592265711123426

Epoch: 5| Step: 9
Training loss: 2.3535753931077883
Validation loss: 2.620810810400689

Epoch: 5| Step: 10
Training loss: 2.4546712873616707
Validation loss: 2.5907489006130704

Epoch: 5| Step: 11
Training loss: 1.9194634667407942
Validation loss: 2.5626787030315796

Epoch: 112| Step: 0
Training loss: 1.7357057157436104
Validation loss: 2.535368864903905

Epoch: 5| Step: 1
Training loss: 2.216638769485729
Validation loss: 2.558428272205667

Epoch: 5| Step: 2
Training loss: 2.3505827931857346
Validation loss: 2.545372716863853

Epoch: 5| Step: 3
Training loss: 2.1618356643455185
Validation loss: 2.5238166953279073

Epoch: 5| Step: 4
Training loss: 1.8499733587872709
Validation loss: 2.5263095451496187

Epoch: 5| Step: 5
Training loss: 2.4334664839628584
Validation loss: 2.512372178610941

Epoch: 5| Step: 6
Training loss: 2.0907067344209294
Validation loss: 2.5139029316893398

Epoch: 5| Step: 7
Training loss: 2.6494383594651656
Validation loss: 2.533615827704391

Epoch: 5| Step: 8
Training loss: 2.212710259570841
Validation loss: 2.518988037693534

Epoch: 5| Step: 9
Training loss: 2.3737237412384866
Validation loss: 2.5007165477978432

Epoch: 5| Step: 10
Training loss: 2.17169946194427
Validation loss: 2.5127433281037157

Epoch: 5| Step: 11
Training loss: 0.82870801160495
Validation loss: 2.5071374652156626

Epoch: 113| Step: 0
Training loss: 1.6909258647032652
Validation loss: 2.5414198823366396

Epoch: 5| Step: 1
Training loss: 2.6910299140461102
Validation loss: 2.5214930779710483

Epoch: 5| Step: 2
Training loss: 2.1572446878482543
Validation loss: 2.5206548506759034

Epoch: 5| Step: 3
Training loss: 2.5251070056563245
Validation loss: 2.5438298194915303

Epoch: 5| Step: 4
Training loss: 2.0373441390821156
Validation loss: 2.5364455288688506

Epoch: 5| Step: 5
Training loss: 2.022483453482524
Validation loss: 2.5347753511954436

Epoch: 5| Step: 6
Training loss: 2.3220678811546276
Validation loss: 2.5597763046553363

Epoch: 5| Step: 7
Training loss: 2.17194415743929
Validation loss: 2.5124140795919465

Epoch: 5| Step: 8
Training loss: 2.2863463864622875
Validation loss: 2.51487209671065

Epoch: 5| Step: 9
Training loss: 2.1058978774043515
Validation loss: 2.5381806862164407

Epoch: 5| Step: 10
Training loss: 1.8612494116808471
Validation loss: 2.548904729595708

Epoch: 5| Step: 11
Training loss: 2.471154888601577
Validation loss: 2.5386175421101953

Epoch: 114| Step: 0
Training loss: 1.9886591763859938
Validation loss: 2.497288865048357

Epoch: 5| Step: 1
Training loss: 2.640603150045973
Validation loss: 2.5323420982616716

Epoch: 5| Step: 2
Training loss: 1.8810321415574007
Validation loss: 2.541767373721616

Epoch: 5| Step: 3
Training loss: 2.6869486753376823
Validation loss: 2.5379819438941853

Epoch: 5| Step: 4
Training loss: 2.0593801078675154
Validation loss: 2.5395379917258154

Epoch: 5| Step: 5
Training loss: 1.9030531044394559
Validation loss: 2.521810398747634

Epoch: 5| Step: 6
Training loss: 2.571365094536724
Validation loss: 2.527189754175167

Epoch: 5| Step: 7
Training loss: 1.792179041795136
Validation loss: 2.5460855610097264

Epoch: 5| Step: 8
Training loss: 1.9387197039344248
Validation loss: 2.5184798222755216

Epoch: 5| Step: 9
Training loss: 2.2067597618902695
Validation loss: 2.513925428429377

Epoch: 5| Step: 10
Training loss: 2.159373467495895
Validation loss: 2.5315514961872796

Epoch: 5| Step: 11
Training loss: 1.6575246260756922
Validation loss: 2.5283671925190134

Epoch: 115| Step: 0
Training loss: 2.090645495486758
Validation loss: 2.5117718822976074

Epoch: 5| Step: 1
Training loss: 2.5914931072575476
Validation loss: 2.519057583703343

Epoch: 5| Step: 2
Training loss: 2.0329317613549365
Validation loss: 2.512064857031111

Epoch: 5| Step: 3
Training loss: 2.0870669161236615
Validation loss: 2.5233989196914512

Epoch: 5| Step: 4
Training loss: 1.9998305368154607
Validation loss: 2.4767006595874945

Epoch: 5| Step: 5
Training loss: 1.6939907986684906
Validation loss: 2.4964759386811726

Epoch: 5| Step: 6
Training loss: 1.945684925875726
Validation loss: 2.507630899178255

Epoch: 5| Step: 7
Training loss: 3.0032586837054915
Validation loss: 2.518435351751932

Epoch: 5| Step: 8
Training loss: 2.367378050937275
Validation loss: 2.5034600473767186

Epoch: 5| Step: 9
Training loss: 2.0048922070758337
Validation loss: 2.513671072737717

Epoch: 5| Step: 10
Training loss: 1.9894510661260025
Validation loss: 2.516957508632786

Epoch: 5| Step: 11
Training loss: 1.561828163668971
Validation loss: 2.496652877820046

Epoch: 116| Step: 0
Training loss: 2.539981335398665
Validation loss: 2.52798181072514

Epoch: 5| Step: 1
Training loss: 2.873459112802759
Validation loss: 2.519544547191297

Epoch: 5| Step: 2
Training loss: 2.193048144276923
Validation loss: 2.526865175385191

Epoch: 5| Step: 3
Training loss: 2.3133419669188995
Validation loss: 2.5227381245894933

Epoch: 5| Step: 4
Training loss: 1.920168359249404
Validation loss: 2.56333230620894

Epoch: 5| Step: 5
Training loss: 1.7341711938381297
Validation loss: 2.5362439009453825

Epoch: 5| Step: 6
Training loss: 2.0211288655536825
Validation loss: 2.5549531073351144

Epoch: 5| Step: 7
Training loss: 2.111891538132451
Validation loss: 2.569156380921606

Epoch: 5| Step: 8
Training loss: 2.021807039465929
Validation loss: 2.5721243527720223

Epoch: 5| Step: 9
Training loss: 2.218141606694084
Validation loss: 2.539965859149907

Epoch: 5| Step: 10
Training loss: 1.964499714576349
Validation loss: 2.528010445990941

Epoch: 5| Step: 11
Training loss: 1.186065560363819
Validation loss: 2.509153859032848

Epoch: 117| Step: 0
Training loss: 1.9445920169174076
Validation loss: 2.5196295489867095

Epoch: 5| Step: 1
Training loss: 2.47820191618767
Validation loss: 2.486602046927414

Epoch: 5| Step: 2
Training loss: 2.6651639479258553
Validation loss: 2.492247458188122

Epoch: 5| Step: 3
Training loss: 2.0328086155143996
Validation loss: 2.5159337345957935

Epoch: 5| Step: 4
Training loss: 2.2141270360916296
Validation loss: 2.5210176957445136

Epoch: 5| Step: 5
Training loss: 1.6279173119983643
Validation loss: 2.503087676171247

Epoch: 5| Step: 6
Training loss: 1.857522827357296
Validation loss: 2.5439730808062917

Epoch: 5| Step: 7
Training loss: 2.474143113045271
Validation loss: 2.516720053651789

Epoch: 5| Step: 8
Training loss: 1.7260339540697938
Validation loss: 2.51411027896511

Epoch: 5| Step: 9
Training loss: 1.9681502140061815
Validation loss: 2.4999740003187525

Epoch: 5| Step: 10
Training loss: 2.6391276792491776
Validation loss: 2.52114363145101

Epoch: 5| Step: 11
Training loss: 2.3379934187927818
Validation loss: 2.5194476761867888

Epoch: 118| Step: 0
Training loss: 2.3159297562391092
Validation loss: 2.5350967364974233

Epoch: 5| Step: 1
Training loss: 1.7864690248338126
Validation loss: 2.5338603990301083

Epoch: 5| Step: 2
Training loss: 2.188122252108721
Validation loss: 2.5076919023586566

Epoch: 5| Step: 3
Training loss: 2.488353303018792
Validation loss: 2.516125027104584

Epoch: 5| Step: 4
Training loss: 1.920276628474268
Validation loss: 2.548762427563667

Epoch: 5| Step: 5
Training loss: 2.0327396505850293
Validation loss: 2.5810704331213015

Epoch: 5| Step: 6
Training loss: 2.219878648413936
Validation loss: 2.5613496066723607

Epoch: 5| Step: 7
Training loss: 2.2087939759622377
Validation loss: 2.548931785219718

Epoch: 5| Step: 8
Training loss: 1.7562858224928273
Validation loss: 2.547363788218853

Epoch: 5| Step: 9
Training loss: 2.0548714094930616
Validation loss: 2.5486161924606607

Epoch: 5| Step: 10
Training loss: 1.906108788434802
Validation loss: 2.5235006877597663

Epoch: 5| Step: 11
Training loss: 4.22740359583863
Validation loss: 2.5348334790261378

Epoch: 119| Step: 0
Training loss: 2.0783017879234458
Validation loss: 2.548491321980036

Epoch: 5| Step: 1
Training loss: 2.011541918047328
Validation loss: 2.5743339505079006

Epoch: 5| Step: 2
Training loss: 2.024844707609772
Validation loss: 2.552793381973862

Epoch: 5| Step: 3
Training loss: 2.416203706616575
Validation loss: 2.550984883224866

Epoch: 5| Step: 4
Training loss: 2.386775988502736
Validation loss: 2.5713610283477593

Epoch: 5| Step: 5
Training loss: 2.351969737532937
Validation loss: 2.527430391865552

Epoch: 5| Step: 6
Training loss: 2.010733887413054
Validation loss: 2.547875970207169

Epoch: 5| Step: 7
Training loss: 2.225508698164689
Validation loss: 2.549059486850362

Epoch: 5| Step: 8
Training loss: 2.459904141923252
Validation loss: 2.5216668159243616

Epoch: 5| Step: 9
Training loss: 1.534799082899379
Validation loss: 2.4842089591531273

Epoch: 5| Step: 10
Training loss: 1.9853360709783578
Validation loss: 2.50709504414552

Epoch: 5| Step: 11
Training loss: 1.0685537883160001
Validation loss: 2.516748686794955

Epoch: 120| Step: 0
Training loss: 2.024756984492816
Validation loss: 2.5158126516230213

Epoch: 5| Step: 1
Training loss: 2.094979224272708
Validation loss: 2.5168808671181764

Epoch: 5| Step: 2
Training loss: 1.9203629166617058
Validation loss: 2.515307858617994

Epoch: 5| Step: 3
Training loss: 1.8591679690208416
Validation loss: 2.495658693322601

Epoch: 5| Step: 4
Training loss: 2.365826810545852
Validation loss: 2.5282928516384304

Epoch: 5| Step: 5
Training loss: 2.7331007249837125
Validation loss: 2.5157687262631336

Epoch: 5| Step: 6
Training loss: 2.2877453865219017
Validation loss: 2.4748259231089422

Epoch: 5| Step: 7
Training loss: 1.8757575094364285
Validation loss: 2.514858130937003

Epoch: 5| Step: 8
Training loss: 2.1928549481181667
Validation loss: 2.516543143811519

Epoch: 5| Step: 9
Training loss: 1.542968904519375
Validation loss: 2.532992308860856

Epoch: 5| Step: 10
Training loss: 1.92697867719318
Validation loss: 2.549395571862051

Epoch: 5| Step: 11
Training loss: 2.9941696095914434
Validation loss: 2.5680596509132534

Epoch: 121| Step: 0
Training loss: 2.8457555720222705
Validation loss: 2.520547619435959

Epoch: 5| Step: 1
Training loss: 1.941494055130527
Validation loss: 2.5221225513030996

Epoch: 5| Step: 2
Training loss: 2.0384622326089814
Validation loss: 2.497487335332072

Epoch: 5| Step: 3
Training loss: 2.4100024206695427
Validation loss: 2.546902888482738

Epoch: 5| Step: 4
Training loss: 2.2898179197595288
Validation loss: 2.533143575414968

Epoch: 5| Step: 5
Training loss: 2.0954783124408984
Validation loss: 2.516491055729948

Epoch: 5| Step: 6
Training loss: 2.3035398567714473
Validation loss: 2.538296224922333

Epoch: 5| Step: 7
Training loss: 2.176075338489957
Validation loss: 2.5330331118357554

Epoch: 5| Step: 8
Training loss: 1.745500365607716
Validation loss: 2.52867310833716

Epoch: 5| Step: 9
Training loss: 1.9075191837811016
Validation loss: 2.5188312711453795

Epoch: 5| Step: 10
Training loss: 1.9973374763992455
Validation loss: 2.501784673097843

Epoch: 5| Step: 11
Training loss: 2.9465523697908242
Validation loss: 2.514526447188917

Epoch: 122| Step: 0
Training loss: 2.0749438036926846
Validation loss: 2.546214172037556

Epoch: 5| Step: 1
Training loss: 2.114593155059805
Validation loss: 2.5381014330396927

Epoch: 5| Step: 2
Training loss: 2.150376655055099
Validation loss: 2.5285871140759655

Epoch: 5| Step: 3
Training loss: 1.9590190606740479
Validation loss: 2.5620365692943934

Epoch: 5| Step: 4
Training loss: 2.142821472870175
Validation loss: 2.543688401266052

Epoch: 5| Step: 5
Training loss: 2.0425090090157254
Validation loss: 2.5451851681995703

Epoch: 5| Step: 6
Training loss: 2.2670819037760754
Validation loss: 2.583532127043047

Epoch: 5| Step: 7
Training loss: 2.2764384071602373
Validation loss: 2.577736380215446

Epoch: 5| Step: 8
Training loss: 2.431384116741847
Validation loss: 2.5477349715327535

Epoch: 5| Step: 9
Training loss: 2.0215935866483243
Validation loss: 2.5303078142012585

Epoch: 5| Step: 10
Training loss: 2.0097454577917935
Validation loss: 2.52786293966344

Epoch: 5| Step: 11
Training loss: 1.1230666183726496
Validation loss: 2.491685204825019

Epoch: 123| Step: 0
Training loss: 2.0368415751586872
Validation loss: 2.509392231873744

Epoch: 5| Step: 1
Training loss: 1.7753471814034605
Validation loss: 2.543928146060323

Epoch: 5| Step: 2
Training loss: 1.996631288655503
Validation loss: 2.505772911001289

Epoch: 5| Step: 3
Training loss: 2.1825306715235673
Validation loss: 2.5032476748322954

Epoch: 5| Step: 4
Training loss: 2.2790229063937537
Validation loss: 2.5378740512595797

Epoch: 5| Step: 5
Training loss: 1.911540522527772
Validation loss: 2.499175690811348

Epoch: 5| Step: 6
Training loss: 2.2189638276557875
Validation loss: 2.5252834965090223

Epoch: 5| Step: 7
Training loss: 1.7743369354970169
Validation loss: 2.504018311911444

Epoch: 5| Step: 8
Training loss: 2.5289823947835224
Validation loss: 2.51113711633645

Epoch: 5| Step: 9
Training loss: 2.0858764639507705
Validation loss: 2.5004376068174965

Epoch: 5| Step: 10
Training loss: 2.113347022536714
Validation loss: 2.5239623540598832

Epoch: 5| Step: 11
Training loss: 2.613001787099654
Validation loss: 2.520763957169763

Epoch: 124| Step: 0
Training loss: 2.257853365729598
Validation loss: 2.527422318571275

Epoch: 5| Step: 1
Training loss: 2.4819245159096477
Validation loss: 2.514276707898096

Epoch: 5| Step: 2
Training loss: 2.571910419428796
Validation loss: 2.5377789427053483

Epoch: 5| Step: 3
Training loss: 2.1132961420743768
Validation loss: 2.559987099858405

Epoch: 5| Step: 4
Training loss: 1.9263628532131167
Validation loss: 2.5324095711249077

Epoch: 5| Step: 5
Training loss: 2.291781220318423
Validation loss: 2.533922205629312

Epoch: 5| Step: 6
Training loss: 1.9150437934190672
Validation loss: 2.531735028393874

Epoch: 5| Step: 7
Training loss: 1.6698072249111509
Validation loss: 2.522170493781839

Epoch: 5| Step: 8
Training loss: 2.0901836938760927
Validation loss: 2.514463152432583

Epoch: 5| Step: 9
Training loss: 2.0903015205778166
Validation loss: 2.4908880236077446

Epoch: 5| Step: 10
Training loss: 1.6902109199590962
Validation loss: 2.5238091044616264

Epoch: 5| Step: 11
Training loss: 1.8773077432304404
Validation loss: 2.5372158730042558

Epoch: 125| Step: 0
Training loss: 2.054646886852064
Validation loss: 2.522242870546211

Epoch: 5| Step: 1
Training loss: 2.351137750228714
Validation loss: 2.562424992029548

Epoch: 5| Step: 2
Training loss: 1.9241491988975075
Validation loss: 2.571822469815261

Epoch: 5| Step: 3
Training loss: 1.7479665386131062
Validation loss: 2.5914946444315805

Epoch: 5| Step: 4
Training loss: 1.8194181676557417
Validation loss: 2.588051092582915

Epoch: 5| Step: 5
Training loss: 2.5969415355472085
Validation loss: 2.5793611510681216

Epoch: 5| Step: 6
Training loss: 1.819862932346636
Validation loss: 2.572121919572922

Epoch: 5| Step: 7
Training loss: 2.559748963922201
Validation loss: 2.551936932990296

Epoch: 5| Step: 8
Training loss: 1.713297013863867
Validation loss: 2.563703103364263

Epoch: 5| Step: 9
Training loss: 2.0390352561563003
Validation loss: 2.573512357153067

Epoch: 5| Step: 10
Training loss: 2.348700216678303
Validation loss: 2.527596049856132

Epoch: 5| Step: 11
Training loss: 2.015329265338419
Validation loss: 2.564989400448875

Epoch: 126| Step: 0
Training loss: 2.0845247549452353
Validation loss: 2.5468126964164446

Epoch: 5| Step: 1
Training loss: 2.3769862251829466
Validation loss: 2.5479545294650863

Epoch: 5| Step: 2
Training loss: 1.8966084527108613
Validation loss: 2.5450214123527735

Epoch: 5| Step: 3
Training loss: 2.1957857429612067
Validation loss: 2.5513079762946416

Epoch: 5| Step: 4
Training loss: 2.0572559852564023
Validation loss: 2.546652357047091

Epoch: 5| Step: 5
Training loss: 1.9135683628546531
Validation loss: 2.545576134929265

Epoch: 5| Step: 6
Training loss: 2.058266658964357
Validation loss: 2.5336161452989705

Epoch: 5| Step: 7
Training loss: 1.7225095379348025
Validation loss: 2.515451054058137

Epoch: 5| Step: 8
Training loss: 2.716754751201114
Validation loss: 2.5136392507780045

Epoch: 5| Step: 9
Training loss: 1.8089635483299273
Validation loss: 2.535490287322088

Epoch: 5| Step: 10
Training loss: 1.8920195929498724
Validation loss: 2.5668142914634697

Epoch: 5| Step: 11
Training loss: 2.0602597872799353
Validation loss: 2.51589382306978

Epoch: 127| Step: 0
Training loss: 2.0245997798691575
Validation loss: 2.496495405107219

Epoch: 5| Step: 1
Training loss: 1.8193563151997205
Validation loss: 2.5460150852558057

Epoch: 5| Step: 2
Training loss: 1.4360574865177718
Validation loss: 2.5542669270882286

Epoch: 5| Step: 3
Training loss: 1.981433159577997
Validation loss: 2.55081971603451

Epoch: 5| Step: 4
Training loss: 2.1509502351431795
Validation loss: 2.544446284486303

Epoch: 5| Step: 5
Training loss: 1.7620619885671858
Validation loss: 2.5833184731476493

Epoch: 5| Step: 6
Training loss: 1.8283753834945247
Validation loss: 2.5221039325808334

Epoch: 5| Step: 7
Training loss: 2.7100015833100484
Validation loss: 2.545695154453576

Epoch: 5| Step: 8
Training loss: 2.403758555063307
Validation loss: 2.5524783834276237

Epoch: 5| Step: 9
Training loss: 2.3158904300590963
Validation loss: 2.5500825525771305

Epoch: 5| Step: 10
Training loss: 2.1510423440139355
Validation loss: 2.533481720815711

Epoch: 5| Step: 11
Training loss: 1.648904815531504
Validation loss: 2.5280446569865918

Epoch: 128| Step: 0
Training loss: 1.8772770724161265
Validation loss: 2.4958327410150076

Epoch: 5| Step: 1
Training loss: 1.9014977173752667
Validation loss: 2.4798989349840213

Epoch: 5| Step: 2
Training loss: 1.6622612745935663
Validation loss: 2.5286324628691887

Epoch: 5| Step: 3
Training loss: 2.534991477936936
Validation loss: 2.503175383817566

Epoch: 5| Step: 4
Training loss: 1.8816468362070193
Validation loss: 2.5402969821921015

Epoch: 5| Step: 5
Training loss: 2.061061473064778
Validation loss: 2.522225079824236

Epoch: 5| Step: 6
Training loss: 2.1418164132851754
Validation loss: 2.538940109824408

Epoch: 5| Step: 7
Training loss: 2.540613727614955
Validation loss: 2.52864158910257

Epoch: 5| Step: 8
Training loss: 1.6269826531449694
Validation loss: 2.5437537415872935

Epoch: 5| Step: 9
Training loss: 1.9764277596969075
Validation loss: 2.5463555475206405

Epoch: 5| Step: 10
Training loss: 2.161059116739401
Validation loss: 2.5248678698448894

Epoch: 5| Step: 11
Training loss: 2.748511431698883
Validation loss: 2.5522660670092807

Epoch: 129| Step: 0
Training loss: 1.7451849498945315
Validation loss: 2.530692883001319

Epoch: 5| Step: 1
Training loss: 2.3579784580117065
Validation loss: 2.5407406665268106

Epoch: 5| Step: 2
Training loss: 2.4217278220463765
Validation loss: 2.5466532347380673

Epoch: 5| Step: 3
Training loss: 1.7719438623573336
Validation loss: 2.5712412998637677

Epoch: 5| Step: 4
Training loss: 1.807495970451116
Validation loss: 2.5781130318412036

Epoch: 5| Step: 5
Training loss: 1.7125692729443613
Validation loss: 2.556190491895376

Epoch: 5| Step: 6
Training loss: 2.40840983373804
Validation loss: 2.567749237188692

Epoch: 5| Step: 7
Training loss: 2.0899114009567192
Validation loss: 2.561517337079673

Epoch: 5| Step: 8
Training loss: 2.008700519514945
Validation loss: 2.5249646528999197

Epoch: 5| Step: 9
Training loss: 1.8717813204089533
Validation loss: 2.509992497700172

Epoch: 5| Step: 10
Training loss: 2.362753665768253
Validation loss: 2.526469791483151

Epoch: 5| Step: 11
Training loss: 0.882718781754616
Validation loss: 2.553459268863945

Epoch: 130| Step: 0
Training loss: 1.6189438869466821
Validation loss: 2.5321205824116233

Epoch: 5| Step: 1
Training loss: 2.1432446787857216
Validation loss: 2.520671107586733

Epoch: 5| Step: 2
Training loss: 1.6519256134881404
Validation loss: 2.5420655943268238

Epoch: 5| Step: 3
Training loss: 2.2039495778278746
Validation loss: 2.550569978292055

Epoch: 5| Step: 4
Training loss: 2.4792960210654154
Validation loss: 2.5533061478037418

Epoch: 5| Step: 5
Training loss: 2.051980792225253
Validation loss: 2.5627677513978666

Epoch: 5| Step: 6
Training loss: 2.3118100554704886
Validation loss: 2.5686743094746975

Epoch: 5| Step: 7
Training loss: 1.7687598561797495
Validation loss: 2.5784266362839623

Epoch: 5| Step: 8
Training loss: 1.891198063532488
Validation loss: 2.563418142470483

Epoch: 5| Step: 9
Training loss: 2.0257617459606907
Validation loss: 2.573147085170865

Epoch: 5| Step: 10
Training loss: 2.613396019118913
Validation loss: 2.52220355906656

Epoch: 5| Step: 11
Training loss: 0.7650646183049098
Validation loss: 2.534765051707783

Epoch: 131| Step: 0
Training loss: 1.5870560333128618
Validation loss: 2.574800166150427

Epoch: 5| Step: 1
Training loss: 2.459229860785427
Validation loss: 2.556690873210096

Epoch: 5| Step: 2
Training loss: 1.6208737143591387
Validation loss: 2.5184122207735484

Epoch: 5| Step: 3
Training loss: 1.8622204461970595
Validation loss: 2.5283062736678423

Epoch: 5| Step: 4
Training loss: 1.5196879877289309
Validation loss: 2.5530309254354235

Epoch: 5| Step: 5
Training loss: 2.4743781339274324
Validation loss: 2.5653229725006246

Epoch: 5| Step: 6
Training loss: 1.9052855756677034
Validation loss: 2.578287331450821

Epoch: 5| Step: 7
Training loss: 1.8856297859027478
Validation loss: 2.568435420275159

Epoch: 5| Step: 8
Training loss: 2.1049050901858224
Validation loss: 2.5543449747741316

Epoch: 5| Step: 9
Training loss: 2.251101118435679
Validation loss: 2.5683258363881274

Epoch: 5| Step: 10
Training loss: 2.343525176391406
Validation loss: 2.564656664287738

Epoch: 5| Step: 11
Training loss: 1.324259124410434
Validation loss: 2.522582276315965

Epoch: 132| Step: 0
Training loss: 2.366108966539903
Validation loss: 2.51002872735564

Epoch: 5| Step: 1
Training loss: 1.7551543758561976
Validation loss: 2.5286701226107313

Epoch: 5| Step: 2
Training loss: 1.8729027781185492
Validation loss: 2.554243253292938

Epoch: 5| Step: 3
Training loss: 1.4721139572129736
Validation loss: 2.5253942361261523

Epoch: 5| Step: 4
Training loss: 1.8843607887757032
Validation loss: 2.5310904723395287

Epoch: 5| Step: 5
Training loss: 1.9543749052364277
Validation loss: 2.5492857443068786

Epoch: 5| Step: 6
Training loss: 1.9151657972948268
Validation loss: 2.5264780998091103

Epoch: 5| Step: 7
Training loss: 2.214541675346875
Validation loss: 2.5391649352709287

Epoch: 5| Step: 8
Training loss: 1.8794258017947674
Validation loss: 2.53245054039792

Epoch: 5| Step: 9
Training loss: 2.623374344756819
Validation loss: 2.5494476929469787

Epoch: 5| Step: 10
Training loss: 1.9506198533664656
Validation loss: 2.5245348234332945

Epoch: 5| Step: 11
Training loss: 2.3339636382773885
Validation loss: 2.559837846432311

Epoch: 133| Step: 0
Training loss: 2.1881373975457596
Validation loss: 2.5836132549068327

Epoch: 5| Step: 1
Training loss: 2.6278544755065294
Validation loss: 2.6100506545470243

Epoch: 5| Step: 2
Training loss: 2.1633548612459004
Validation loss: 2.591557886277557

Epoch: 5| Step: 3
Training loss: 1.441381934976572
Validation loss: 2.5803723683664668

Epoch: 5| Step: 4
Training loss: 1.9863490700906832
Validation loss: 2.5675019625563706

Epoch: 5| Step: 5
Training loss: 1.8033244612728798
Validation loss: 2.6192902748163642

Epoch: 5| Step: 6
Training loss: 2.038175894374652
Validation loss: 2.5519173347567277

Epoch: 5| Step: 7
Training loss: 1.535874836789192
Validation loss: 2.544418929340898

Epoch: 5| Step: 8
Training loss: 2.0050534539457874
Validation loss: 2.553281072222013

Epoch: 5| Step: 9
Training loss: 2.268414168289756
Validation loss: 2.5804994495647247

Epoch: 5| Step: 10
Training loss: 1.7247199674336855
Validation loss: 2.5480526851697167

Epoch: 5| Step: 11
Training loss: 2.618589657629455
Validation loss: 2.5772953663725096

Epoch: 134| Step: 0
Training loss: 1.7474324601073195
Validation loss: 2.5082851610173225

Epoch: 5| Step: 1
Training loss: 1.9573414570023102
Validation loss: 2.544656778279964

Epoch: 5| Step: 2
Training loss: 1.9847648417894168
Validation loss: 2.5462071414874328

Epoch: 5| Step: 3
Training loss: 2.136359203710329
Validation loss: 2.530024365212292

Epoch: 5| Step: 4
Training loss: 2.0128129372243135
Validation loss: 2.5266581238671004

Epoch: 5| Step: 5
Training loss: 2.2520604765582304
Validation loss: 2.539430214102226

Epoch: 5| Step: 6
Training loss: 2.6749704733671793
Validation loss: 2.5345397967762846

Epoch: 5| Step: 7
Training loss: 2.153058108327426
Validation loss: 2.5119622697340347

Epoch: 5| Step: 8
Training loss: 1.588329146714245
Validation loss: 2.511172753885462

Epoch: 5| Step: 9
Training loss: 1.667022651166064
Validation loss: 2.541654095592574

Epoch: 5| Step: 10
Training loss: 2.0611164191772624
Validation loss: 2.602222874312677

Epoch: 5| Step: 11
Training loss: 1.322965405785346
Validation loss: 2.5855498700456665

Epoch: 135| Step: 0
Training loss: 2.519699682475704
Validation loss: 2.583137359927998

Epoch: 5| Step: 1
Training loss: 1.939225628159604
Validation loss: 2.595054704301464

Epoch: 5| Step: 2
Training loss: 2.3216260281100816
Validation loss: 2.617766848536431

Epoch: 5| Step: 3
Training loss: 2.2641452560938173
Validation loss: 2.5803549014308196

Epoch: 5| Step: 4
Training loss: 1.9326804113624139
Validation loss: 2.5796493108469267

Epoch: 5| Step: 5
Training loss: 1.86907174393065
Validation loss: 2.5795706192793486

Epoch: 5| Step: 6
Training loss: 1.482205542258135
Validation loss: 2.563620120918256

Epoch: 5| Step: 7
Training loss: 1.9445277703308874
Validation loss: 2.5297648405677795

Epoch: 5| Step: 8
Training loss: 1.9909054688832046
Validation loss: 2.5484429469109817

Epoch: 5| Step: 9
Training loss: 1.6930860675040469
Validation loss: 2.5562065500112454

Epoch: 5| Step: 10
Training loss: 2.0166085379343643
Validation loss: 2.5470132907229357

Epoch: 5| Step: 11
Training loss: 2.0138253154439805
Validation loss: 2.5742685547614075

Epoch: 136| Step: 0
Training loss: 2.5859859035606334
Validation loss: 2.54631864091593

Epoch: 5| Step: 1
Training loss: 2.1416322885962717
Validation loss: 2.565543360152716

Epoch: 5| Step: 2
Training loss: 1.9225465795184498
Validation loss: 2.5374006926861976

Epoch: 5| Step: 3
Training loss: 2.0106779202180887
Validation loss: 2.524034825067381

Epoch: 5| Step: 4
Training loss: 1.5690316057687057
Validation loss: 2.531874312814509

Epoch: 5| Step: 5
Training loss: 1.6914565715396128
Validation loss: 2.54713785340202

Epoch: 5| Step: 6
Training loss: 1.5949926580660703
Validation loss: 2.5376717147604904

Epoch: 5| Step: 7
Training loss: 2.1664893248924737
Validation loss: 2.5286997086468714

Epoch: 5| Step: 8
Training loss: 1.7132737047800752
Validation loss: 2.55629017338978

Epoch: 5| Step: 9
Training loss: 2.0456369164595007
Validation loss: 2.5626206253317347

Epoch: 5| Step: 10
Training loss: 2.2339468592485114
Validation loss: 2.6153109869016467

Epoch: 5| Step: 11
Training loss: 2.34736639128078
Validation loss: 2.560359489204967

Epoch: 137| Step: 0
Training loss: 2.3282945814391667
Validation loss: 2.5729690899057895

Epoch: 5| Step: 1
Training loss: 2.554452494506777
Validation loss: 2.5598458097323435

Epoch: 5| Step: 2
Training loss: 1.561469844735814
Validation loss: 2.5509315473705225

Epoch: 5| Step: 3
Training loss: 1.776757044947688
Validation loss: 2.5401825415168173

Epoch: 5| Step: 4
Training loss: 1.921382872057776
Validation loss: 2.543490745461107

Epoch: 5| Step: 5
Training loss: 2.384897789194494
Validation loss: 2.50454484767746

Epoch: 5| Step: 6
Training loss: 2.0534823404262883
Validation loss: 2.5477631040467017

Epoch: 5| Step: 7
Training loss: 1.9862964368785063
Validation loss: 2.5646403220874343

Epoch: 5| Step: 8
Training loss: 1.9419238131710752
Validation loss: 2.538085741799222

Epoch: 5| Step: 9
Training loss: 1.499480634421182
Validation loss: 2.60564955770782

Epoch: 5| Step: 10
Training loss: 1.7962981251725145
Validation loss: 2.5478007500502833

Epoch: 5| Step: 11
Training loss: 1.2619739664085807
Validation loss: 2.57892674011639

Epoch: 138| Step: 0
Training loss: 1.8720449685702973
Validation loss: 2.587084305584328

Epoch: 5| Step: 1
Training loss: 2.188684851059718
Validation loss: 2.625650153178468

Epoch: 5| Step: 2
Training loss: 2.590489279731638
Validation loss: 2.566070567589232

Epoch: 5| Step: 3
Training loss: 1.9429144115081773
Validation loss: 2.5931077146593813

Epoch: 5| Step: 4
Training loss: 1.40808629835696
Validation loss: 2.5932633697977607

Epoch: 5| Step: 5
Training loss: 1.9874063601717313
Validation loss: 2.566678408703223

Epoch: 5| Step: 6
Training loss: 1.7775784180373981
Validation loss: 2.5637505666433644

Epoch: 5| Step: 7
Training loss: 2.2751051826056186
Validation loss: 2.5471475782976074

Epoch: 5| Step: 8
Training loss: 1.7306226399282645
Validation loss: 2.580682487848342

Epoch: 5| Step: 9
Training loss: 2.130566318964997
Validation loss: 2.5628571338981887

Epoch: 5| Step: 10
Training loss: 1.6834108470154405
Validation loss: 2.5382109872116843

Epoch: 5| Step: 11
Training loss: 1.8315289750323516
Validation loss: 2.5511876007017507

Epoch: 139| Step: 0
Training loss: 1.9638729541149484
Validation loss: 2.532119158276435

Epoch: 5| Step: 1
Training loss: 2.1974213269486262
Validation loss: 2.5339759465455685

Epoch: 5| Step: 2
Training loss: 1.9882931212424955
Validation loss: 2.533114005986622

Epoch: 5| Step: 3
Training loss: 1.525788825466025
Validation loss: 2.562023870692446

Epoch: 5| Step: 4
Training loss: 1.7889520202906783
Validation loss: 2.53110973534669

Epoch: 5| Step: 5
Training loss: 1.6544803305984506
Validation loss: 2.559524483326837

Epoch: 5| Step: 6
Training loss: 2.163316729011157
Validation loss: 2.5623319307120545

Epoch: 5| Step: 7
Training loss: 1.7963698630800673
Validation loss: 2.567288344405674

Epoch: 5| Step: 8
Training loss: 2.1003443935102877
Validation loss: 2.579146057769656

Epoch: 5| Step: 9
Training loss: 2.3488123835003343
Validation loss: 2.590638243576575

Epoch: 5| Step: 10
Training loss: 1.6839504350902303
Validation loss: 2.588113389893854

Epoch: 5| Step: 11
Training loss: 1.7794944410631173
Validation loss: 2.5694724374970312

Epoch: 140| Step: 0
Training loss: 1.6335538796330487
Validation loss: 2.5448537423652096

Epoch: 5| Step: 1
Training loss: 2.373442892303268
Validation loss: 2.5393679312863378

Epoch: 5| Step: 2
Training loss: 1.9547542033108225
Validation loss: 2.542173793625258

Epoch: 5| Step: 3
Training loss: 1.7996821493740596
Validation loss: 2.5472618074529394

Epoch: 5| Step: 4
Training loss: 1.9604677648367776
Validation loss: 2.5461372875085866

Epoch: 5| Step: 5
Training loss: 2.163749809948292
Validation loss: 2.5758594075683736

Epoch: 5| Step: 6
Training loss: 1.8428630311793717
Validation loss: 2.519982810548406

Epoch: 5| Step: 7
Training loss: 1.8030292108700998
Validation loss: 2.542898103872402

Epoch: 5| Step: 8
Training loss: 1.7310075114950527
Validation loss: 2.5491965153112517

Epoch: 5| Step: 9
Training loss: 1.850468179383303
Validation loss: 2.5550263206410215

Epoch: 5| Step: 10
Training loss: 2.0771607191030306
Validation loss: 2.5562197749520257

Epoch: 5| Step: 11
Training loss: 1.5784765173077928
Validation loss: 2.5530683459031387

Epoch: 141| Step: 0
Training loss: 1.448587861224514
Validation loss: 2.5698611163612535

Epoch: 5| Step: 1
Training loss: 2.0131976274939856
Validation loss: 2.56252113581679

Epoch: 5| Step: 2
Training loss: 1.8470936860352956
Validation loss: 2.606458949518719

Epoch: 5| Step: 3
Training loss: 2.274950710223796
Validation loss: 2.577441807015042

Epoch: 5| Step: 4
Training loss: 2.176236390975654
Validation loss: 2.591208821717998

Epoch: 5| Step: 5
Training loss: 1.699755353714672
Validation loss: 2.6277933887493368

Epoch: 5| Step: 6
Training loss: 1.9035413289815242
Validation loss: 2.6139693406813933

Epoch: 5| Step: 7
Training loss: 2.1774516790308254
Validation loss: 2.5732702612024103

Epoch: 5| Step: 8
Training loss: 1.9650611832972433
Validation loss: 2.5474207611257813

Epoch: 5| Step: 9
Training loss: 1.538789908963011
Validation loss: 2.546432995032823

Epoch: 5| Step: 10
Training loss: 2.063181793346442
Validation loss: 2.559275416454036

Epoch: 5| Step: 11
Training loss: 1.110205326163343
Validation loss: 2.522709331030783

Epoch: 142| Step: 0
Training loss: 1.8848649863503246
Validation loss: 2.5641914422040113

Epoch: 5| Step: 1
Training loss: 2.0037735863509294
Validation loss: 2.530076264983477

Epoch: 5| Step: 2
Training loss: 1.820993648021498
Validation loss: 2.5708059090481363

Epoch: 5| Step: 3
Training loss: 1.9278262038230018
Validation loss: 2.539407818127059

Epoch: 5| Step: 4
Training loss: 1.6082823664573234
Validation loss: 2.5449249353436767

Epoch: 5| Step: 5
Training loss: 1.9179365539956184
Validation loss: 2.543550072326277

Epoch: 5| Step: 6
Training loss: 2.5019766622563333
Validation loss: 2.566808459052062

Epoch: 5| Step: 7
Training loss: 1.6615931138365665
Validation loss: 2.548625227646245

Epoch: 5| Step: 8
Training loss: 1.6382856129746013
Validation loss: 2.5381377663628295

Epoch: 5| Step: 9
Training loss: 1.870518096102109
Validation loss: 2.5426319795860324

Epoch: 5| Step: 10
Training loss: 2.0925578808726524
Validation loss: 2.592798588996539

Epoch: 5| Step: 11
Training loss: 1.687448359511685
Validation loss: 2.6041902591908204

Epoch: 143| Step: 0
Training loss: 1.971006220787911
Validation loss: 2.5994915781480854

Epoch: 5| Step: 1
Training loss: 2.4566467663577036
Validation loss: 2.605345601570147

Epoch: 5| Step: 2
Training loss: 2.077239342598245
Validation loss: 2.6093091956424264

Epoch: 5| Step: 3
Training loss: 1.9789452345268965
Validation loss: 2.58259129377944

Epoch: 5| Step: 4
Training loss: 1.880741927776992
Validation loss: 2.5760106442860433

Epoch: 5| Step: 5
Training loss: 1.497470869312758
Validation loss: 2.5613297178212964

Epoch: 5| Step: 6
Training loss: 1.763216857680893
Validation loss: 2.5362314257216583

Epoch: 5| Step: 7
Training loss: 1.6183292210242173
Validation loss: 2.5948343193584344

Epoch: 5| Step: 8
Training loss: 1.950557761018895
Validation loss: 2.54141025083602

Epoch: 5| Step: 9
Training loss: 1.9053146068479387
Validation loss: 2.515102652110006

Epoch: 5| Step: 10
Training loss: 1.6723100327973512
Validation loss: 2.5589089973507786

Epoch: 5| Step: 11
Training loss: 2.2255314095928256
Validation loss: 2.536452600184129

Epoch: 144| Step: 0
Training loss: 1.8552782462853183
Validation loss: 2.5333923724054377

Epoch: 5| Step: 1
Training loss: 1.6885549285512211
Validation loss: 2.532510439702791

Epoch: 5| Step: 2
Training loss: 2.101837253691022
Validation loss: 2.5248454824072195

Epoch: 5| Step: 3
Training loss: 1.647357170848492
Validation loss: 2.528134632524483

Epoch: 5| Step: 4
Training loss: 1.5796765546862868
Validation loss: 2.565932394145048

Epoch: 5| Step: 5
Training loss: 1.9593023648708552
Validation loss: 2.546073647086419

Epoch: 5| Step: 6
Training loss: 2.1851146226231393
Validation loss: 2.5607844828551634

Epoch: 5| Step: 7
Training loss: 2.0779366085160613
Validation loss: 2.5647498232990817

Epoch: 5| Step: 8
Training loss: 2.1378001487541307
Validation loss: 2.546161618010502

Epoch: 5| Step: 9
Training loss: 1.843450683608688
Validation loss: 2.5441770793361433

Epoch: 5| Step: 10
Training loss: 1.6558615750862655
Validation loss: 2.546736535987103

Epoch: 5| Step: 11
Training loss: 0.8074562807323933
Validation loss: 2.525790272161793

Epoch: 145| Step: 0
Training loss: 1.454437811347194
Validation loss: 2.563723066800088

Epoch: 5| Step: 1
Training loss: 2.2059827086115975
Validation loss: 2.5904903995041746

Epoch: 5| Step: 2
Training loss: 1.8913522377794982
Validation loss: 2.592937874713148

Epoch: 5| Step: 3
Training loss: 2.5187425901999703
Validation loss: 2.6345708241050856

Epoch: 5| Step: 4
Training loss: 2.25293349723345
Validation loss: 2.5877424243261715

Epoch: 5| Step: 5
Training loss: 1.4802050192051117
Validation loss: 2.6477070891796384

Epoch: 5| Step: 6
Training loss: 1.6605077034927493
Validation loss: 2.565683384028518

Epoch: 5| Step: 7
Training loss: 1.7288327028651007
Validation loss: 2.5302752199489373

Epoch: 5| Step: 8
Training loss: 1.780826250501634
Validation loss: 2.5701277974714634

Epoch: 5| Step: 9
Training loss: 1.6740555847948018
Validation loss: 2.585878223611846

Epoch: 5| Step: 10
Training loss: 1.4750550663900845
Validation loss: 2.5355822651450746

Epoch: 5| Step: 11
Training loss: 2.9807645518453145
Validation loss: 2.571881944624593

Epoch: 146| Step: 0
Training loss: 1.4887805011228759
Validation loss: 2.6323849890323294

Epoch: 5| Step: 1
Training loss: 1.7744236023666915
Validation loss: 2.5382083923459904

Epoch: 5| Step: 2
Training loss: 1.651591822021962
Validation loss: 2.5591100254382497

Epoch: 5| Step: 3
Training loss: 2.2442946684102747
Validation loss: 2.5907809717877477

Epoch: 5| Step: 4
Training loss: 1.6968379738493213
Validation loss: 2.564592987608434

Epoch: 5| Step: 5
Training loss: 2.081239932840646
Validation loss: 2.5612363452029205

Epoch: 5| Step: 6
Training loss: 1.9419626095017588
Validation loss: 2.5751963347672984

Epoch: 5| Step: 7
Training loss: 1.975512681886078
Validation loss: 2.582364128689286

Epoch: 5| Step: 8
Training loss: 1.6451319234061919
Validation loss: 2.5879474408132785

Epoch: 5| Step: 9
Training loss: 1.6907072318733043
Validation loss: 2.5982091711996183

Epoch: 5| Step: 10
Training loss: 1.9808133218685497
Validation loss: 2.5381784044296136

Epoch: 5| Step: 11
Training loss: 2.283177436834213
Validation loss: 2.5566307244474635

Epoch: 147| Step: 0
Training loss: 2.1141630860707967
Validation loss: 2.5308545788825834

Epoch: 5| Step: 1
Training loss: 1.267098640308459
Validation loss: 2.5608787951937604

Epoch: 5| Step: 2
Training loss: 1.8042280264530308
Validation loss: 2.542579636734754

Epoch: 5| Step: 3
Training loss: 1.8762735492161149
Validation loss: 2.550459529417023

Epoch: 5| Step: 4
Training loss: 2.167790036095397
Validation loss: 2.536300573332034

Epoch: 5| Step: 5
Training loss: 1.689129431260354
Validation loss: 2.5698670578128837

Epoch: 5| Step: 6
Training loss: 1.755346441825333
Validation loss: 2.5430647504258217

Epoch: 5| Step: 7
Training loss: 2.3682625221155753
Validation loss: 2.5164309132806415

Epoch: 5| Step: 8
Training loss: 1.8900142345195186
Validation loss: 2.544805169326701

Epoch: 5| Step: 9
Training loss: 1.622617735977317
Validation loss: 2.5819481813704592

Epoch: 5| Step: 10
Training loss: 1.5786514159627951
Validation loss: 2.5651386136035055

Epoch: 5| Step: 11
Training loss: 2.037977492660211
Validation loss: 2.5804629966493846

Epoch: 148| Step: 0
Training loss: 2.1034804884048954
Validation loss: 2.641182834910438

Epoch: 5| Step: 1
Training loss: 1.6378579192622862
Validation loss: 2.662961702581262

Epoch: 5| Step: 2
Training loss: 1.4554616537857907
Validation loss: 2.6845860985562036

Epoch: 5| Step: 3
Training loss: 2.4436927769197934
Validation loss: 2.7651105104048983

Epoch: 5| Step: 4
Training loss: 1.700509469041536
Validation loss: 2.6927602690380286

Epoch: 5| Step: 5
Training loss: 1.8411890768523969
Validation loss: 2.6126442452662095

Epoch: 5| Step: 6
Training loss: 2.124287766418873
Validation loss: 2.6272101161947248

Epoch: 5| Step: 7
Training loss: 1.6301082868822796
Validation loss: 2.5760449119595763

Epoch: 5| Step: 8
Training loss: 1.9531829215044267
Validation loss: 2.548449982987359

Epoch: 5| Step: 9
Training loss: 2.135821780102704
Validation loss: 2.569052370904696

Epoch: 5| Step: 10
Training loss: 1.4130291614317514
Validation loss: 2.5274009796376538

Epoch: 5| Step: 11
Training loss: 1.943329685310268
Validation loss: 2.58039724997959

Epoch: 149| Step: 0
Training loss: 2.340803201204668
Validation loss: 2.5280283806896304

Epoch: 5| Step: 1
Training loss: 1.9608240588685275
Validation loss: 2.581734259795714

Epoch: 5| Step: 2
Training loss: 1.7795747609052222
Validation loss: 2.5230245931479836

Epoch: 5| Step: 3
Training loss: 1.5812063067886797
Validation loss: 2.560525109891824

Epoch: 5| Step: 4
Training loss: 2.227315567892671
Validation loss: 2.589916713448208

Epoch: 5| Step: 5
Training loss: 1.3795680978329894
Validation loss: 2.5507254329102644

Epoch: 5| Step: 6
Training loss: 1.7476018413725216
Validation loss: 2.5498267934603827

Epoch: 5| Step: 7
Training loss: 1.767152446260878
Validation loss: 2.5773344889452545

Epoch: 5| Step: 8
Training loss: 2.0544410238632373
Validation loss: 2.578720501798651

Epoch: 5| Step: 9
Training loss: 1.5447439291384535
Validation loss: 2.5254739313431003

Epoch: 5| Step: 10
Training loss: 1.7866351055920897
Validation loss: 2.5482717518219435

Epoch: 5| Step: 11
Training loss: 1.030388848227076
Validation loss: 2.5321902149758193

Epoch: 150| Step: 0
Training loss: 1.5487451519093591
Validation loss: 2.570057623457799

Epoch: 5| Step: 1
Training loss: 1.2763411293784632
Validation loss: 2.590538779351275

Epoch: 5| Step: 2
Training loss: 2.5793333054193592
Validation loss: 2.540123300256732

Epoch: 5| Step: 3
Training loss: 2.0538548860334074
Validation loss: 2.528049781129857

Epoch: 5| Step: 4
Training loss: 1.710466084790525
Validation loss: 2.5570329404476277

Epoch: 5| Step: 5
Training loss: 1.674688093837
Validation loss: 2.5773559444370657

Epoch: 5| Step: 6
Training loss: 1.8117551259562736
Validation loss: 2.5727861225869244

Epoch: 5| Step: 7
Training loss: 1.746996686651694
Validation loss: 2.5839108365090797

Epoch: 5| Step: 8
Training loss: 1.5642449363076616
Validation loss: 2.5829136812669025

Epoch: 5| Step: 9
Training loss: 1.839764311871519
Validation loss: 2.628461598943567

Epoch: 5| Step: 10
Training loss: 1.7561503371879699
Validation loss: 2.639990220527405

Epoch: 5| Step: 11
Training loss: 2.0015822350796935
Validation loss: 2.5829227810897204

Testing loss: 2.215272655987623
