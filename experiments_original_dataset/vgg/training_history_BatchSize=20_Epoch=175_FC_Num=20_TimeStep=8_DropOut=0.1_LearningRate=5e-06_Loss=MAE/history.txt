Epoch: 1| Step: 0
Training loss: 4.829823970794678
Validation loss: 5.1874755422274275

Epoch: 5| Step: 1
Training loss: 5.238658428192139
Validation loss: 5.1736588676770525

Epoch: 5| Step: 2
Training loss: 6.2907915115356445
Validation loss: 5.158104161421458

Epoch: 5| Step: 3
Training loss: 5.517402172088623
Validation loss: 5.140638053417206

Epoch: 5| Step: 4
Training loss: 5.362139701843262
Validation loss: 5.1224639018376665

Epoch: 5| Step: 5
Training loss: 4.439317226409912
Validation loss: 5.10606449842453

Epoch: 5| Step: 6
Training loss: 5.414726734161377
Validation loss: 5.087473511695862

Epoch: 5| Step: 7
Training loss: 5.788430213928223
Validation loss: 5.071063876152039

Epoch: 5| Step: 8
Training loss: 5.130285263061523
Validation loss: 5.054215172926585

Epoch: 5| Step: 9
Training loss: 4.366512298583984
Validation loss: 5.0342961351076765

Epoch: 5| Step: 10
Training loss: 4.8624138832092285
Validation loss: 5.017171482245128

Epoch: 5| Step: 11
Training loss: 3.7437984943389893
Validation loss: 4.996750771999359

Epoch: 2| Step: 0
Training loss: 5.195097923278809
Validation loss: 4.976905167102814

Epoch: 5| Step: 1
Training loss: 5.985271453857422
Validation loss: 4.955941081047058

Epoch: 5| Step: 2
Training loss: 4.709662437438965
Validation loss: 4.938311258951823

Epoch: 5| Step: 3
Training loss: 4.748214244842529
Validation loss: 4.9157039920489

Epoch: 5| Step: 4
Training loss: 4.127480983734131
Validation loss: 4.892272313435872

Epoch: 5| Step: 5
Training loss: 4.871219158172607
Validation loss: 4.8709315458933515

Epoch: 5| Step: 6
Training loss: 4.51168966293335
Validation loss: 4.849957158168157

Epoch: 5| Step: 7
Training loss: 5.141781806945801
Validation loss: 4.823420067628224

Epoch: 5| Step: 8
Training loss: 5.269658088684082
Validation loss: 4.798702557881673

Epoch: 5| Step: 9
Training loss: 5.179827690124512
Validation loss: 4.772504210472107

Epoch: 5| Step: 10
Training loss: 4.302233695983887
Validation loss: 4.751517454783122

Epoch: 5| Step: 11
Training loss: 6.614108085632324
Validation loss: 4.721022695302963

Epoch: 3| Step: 0
Training loss: 4.088539123535156
Validation loss: 4.694376925627391

Epoch: 5| Step: 1
Training loss: 4.372919082641602
Validation loss: 4.662303566932678

Epoch: 5| Step: 2
Training loss: 5.407821178436279
Validation loss: 4.629520704348882

Epoch: 5| Step: 3
Training loss: 4.321143627166748
Validation loss: 4.598487436771393

Epoch: 5| Step: 4
Training loss: 5.394026279449463
Validation loss: 4.564356505870819

Epoch: 5| Step: 5
Training loss: 4.706526756286621
Validation loss: 4.527335445086162

Epoch: 5| Step: 6
Training loss: 3.7498302459716797
Validation loss: 4.488113522529602

Epoch: 5| Step: 7
Training loss: 4.756817817687988
Validation loss: 4.447123169898987

Epoch: 5| Step: 8
Training loss: 4.996416091918945
Validation loss: 4.405404667059581

Epoch: 5| Step: 9
Training loss: 4.82907772064209
Validation loss: 4.360417008399963

Epoch: 5| Step: 10
Training loss: 3.9745895862579346
Validation loss: 4.317463556925456

Epoch: 5| Step: 11
Training loss: 3.985701084136963
Validation loss: 4.265651295582454

Epoch: 4| Step: 0
Training loss: 4.086014270782471
Validation loss: 4.217843542496364

Epoch: 5| Step: 1
Training loss: 4.054620265960693
Validation loss: 4.163696040709813

Epoch: 5| Step: 2
Training loss: 3.937297821044922
Validation loss: 4.113596657911937

Epoch: 5| Step: 3
Training loss: 4.757082462310791
Validation loss: 4.055563469727834

Epoch: 5| Step: 4
Training loss: 4.400797367095947
Validation loss: 4.0025579531987505

Epoch: 5| Step: 5
Training loss: 3.713219165802002
Validation loss: 3.9484504063924155

Epoch: 5| Step: 6
Training loss: 4.220395565032959
Validation loss: 3.8801193237304688

Epoch: 5| Step: 7
Training loss: 3.9489407539367676
Validation loss: 3.8267005681991577

Epoch: 5| Step: 8
Training loss: 4.24954080581665
Validation loss: 3.7614066898822784

Epoch: 5| Step: 9
Training loss: 4.807669162750244
Validation loss: 3.6958199044068656

Epoch: 5| Step: 10
Training loss: 2.549079418182373
Validation loss: 3.6273564398288727

Epoch: 5| Step: 11
Training loss: 1.6598304510116577
Validation loss: 3.5654576619466147

Epoch: 5| Step: 0
Training loss: 3.3249640464782715
Validation loss: 3.4911266764005027

Epoch: 5| Step: 1
Training loss: 3.524214506149292
Validation loss: 3.4109912713368735

Epoch: 5| Step: 2
Training loss: 2.4715139865875244
Validation loss: 3.3373828331629434

Epoch: 5| Step: 3
Training loss: 3.54480242729187
Validation loss: 3.257640689611435

Epoch: 5| Step: 4
Training loss: 3.0919556617736816
Validation loss: 3.1845072408517203

Epoch: 5| Step: 5
Training loss: 3.067335605621338
Validation loss: 3.100116858879725

Epoch: 5| Step: 6
Training loss: 3.325726270675659
Validation loss: 3.032665103673935

Epoch: 5| Step: 7
Training loss: 3.3524322509765625
Validation loss: 2.9409635762373605

Epoch: 5| Step: 8
Training loss: 2.513233184814453
Validation loss: 2.8715277115503945

Epoch: 5| Step: 9
Training loss: 3.0120091438293457
Validation loss: 2.804005821545919

Epoch: 5| Step: 10
Training loss: 2.65769100189209
Validation loss: 2.711946730812391

Epoch: 5| Step: 11
Training loss: 3.4425370693206787
Validation loss: 2.6382838785648346

Epoch: 6| Step: 0
Training loss: 2.766453742980957
Validation loss: 2.570125917593638

Epoch: 5| Step: 1
Training loss: 1.8868945837020874
Validation loss: 2.47178785999616

Epoch: 5| Step: 2
Training loss: 2.370985984802246
Validation loss: 2.4123106400171914

Epoch: 5| Step: 3
Training loss: 2.606961727142334
Validation loss: 2.36533784866333

Epoch: 5| Step: 4
Training loss: 1.2684134244918823
Validation loss: 2.323219339052836

Epoch: 5| Step: 5
Training loss: 2.6198666095733643
Validation loss: 2.320872883001963

Epoch: 5| Step: 6
Training loss: 1.8969545364379883
Validation loss: 2.299854129552841

Epoch: 5| Step: 7
Training loss: 2.1662497520446777
Validation loss: 2.299314667781194

Epoch: 5| Step: 8
Training loss: 2.262617349624634
Validation loss: 2.331822862227758

Epoch: 5| Step: 9
Training loss: 2.3608694076538086
Validation loss: 2.3322055836518607

Epoch: 5| Step: 10
Training loss: 2.6563823223114014
Validation loss: 2.354803437987963

Epoch: 5| Step: 11
Training loss: 3.708275318145752
Validation loss: 2.3912954131762185

Epoch: 7| Step: 0
Training loss: 1.4919214248657227
Validation loss: 2.405012066165606

Epoch: 5| Step: 1
Training loss: 2.642876386642456
Validation loss: 2.451181630293528

Epoch: 5| Step: 2
Training loss: 2.4461569786071777
Validation loss: 2.4341169943412146

Epoch: 5| Step: 3
Training loss: 3.056809425354004
Validation loss: 2.440236578385035

Epoch: 5| Step: 4
Training loss: 2.410055160522461
Validation loss: 2.4388305892546973

Epoch: 5| Step: 5
Training loss: 2.635934352874756
Validation loss: 2.3912582794825235

Epoch: 5| Step: 6
Training loss: 1.7080333232879639
Validation loss: 2.3704045613606772

Epoch: 5| Step: 7
Training loss: 2.165240526199341
Validation loss: 2.3611688812573752

Epoch: 5| Step: 8
Training loss: 2.2692911624908447
Validation loss: 2.330346326033274

Epoch: 5| Step: 9
Training loss: 2.5285191535949707
Validation loss: 2.317302420735359

Epoch: 5| Step: 10
Training loss: 2.1165401935577393
Validation loss: 2.300283948580424

Epoch: 5| Step: 11
Training loss: 1.010768175125122
Validation loss: 2.315133015314738

Epoch: 8| Step: 0
Training loss: 2.2647042274475098
Validation loss: 2.291259909669558

Epoch: 5| Step: 1
Training loss: 1.4107897281646729
Validation loss: 2.2933907359838486

Epoch: 5| Step: 2
Training loss: 1.8326705694198608
Validation loss: 2.282947599887848

Epoch: 5| Step: 3
Training loss: 2.505492925643921
Validation loss: 2.290668472647667

Epoch: 5| Step: 4
Training loss: 2.2050795555114746
Validation loss: 2.295397529999415

Epoch: 5| Step: 5
Training loss: 2.253373384475708
Validation loss: 2.2861331502596536

Epoch: 5| Step: 6
Training loss: 2.108713150024414
Validation loss: 2.2910668750603995

Epoch: 5| Step: 7
Training loss: 2.8113818168640137
Validation loss: 2.2987450857957206

Epoch: 5| Step: 8
Training loss: 2.4685769081115723
Validation loss: 2.2594814002513885

Epoch: 5| Step: 9
Training loss: 1.5377185344696045
Validation loss: 2.298284967740377

Epoch: 5| Step: 10
Training loss: 2.738175868988037
Validation loss: 2.302662452061971

Epoch: 5| Step: 11
Training loss: 1.5258917808532715
Validation loss: 2.2929940621058145

Epoch: 9| Step: 0
Training loss: 2.132073163986206
Validation loss: 2.2832226951917014

Epoch: 5| Step: 1
Training loss: 2.5335845947265625
Validation loss: 2.296909218033155

Epoch: 5| Step: 2
Training loss: 2.1369552612304688
Validation loss: 2.29071769118309

Epoch: 5| Step: 3
Training loss: 2.102938175201416
Validation loss: 2.287751540541649

Epoch: 5| Step: 4
Training loss: 1.5868622064590454
Validation loss: 2.269671549399694

Epoch: 5| Step: 5
Training loss: 2.464548110961914
Validation loss: 2.2907584061225257

Epoch: 5| Step: 6
Training loss: 2.395233154296875
Validation loss: 2.2545757989088693

Epoch: 5| Step: 7
Training loss: 2.3499515056610107
Validation loss: 2.289139519135157

Epoch: 5| Step: 8
Training loss: 2.665903091430664
Validation loss: 2.2871212859948478

Epoch: 5| Step: 9
Training loss: 1.9392528533935547
Validation loss: 2.2799017131328583

Epoch: 5| Step: 10
Training loss: 1.931745171546936
Validation loss: 2.298501874009768

Epoch: 5| Step: 11
Training loss: 1.1738923788070679
Validation loss: 2.268309007088343

Epoch: 10| Step: 0
Training loss: 2.150052309036255
Validation loss: 2.27943255007267

Epoch: 5| Step: 1
Training loss: 2.7527527809143066
Validation loss: 2.263322244087855

Epoch: 5| Step: 2
Training loss: 2.7619049549102783
Validation loss: 2.2521414905786514

Epoch: 5| Step: 3
Training loss: 1.8384580612182617
Validation loss: 2.302610402305921

Epoch: 5| Step: 4
Training loss: 1.8249919414520264
Validation loss: 2.2870130290587745

Epoch: 5| Step: 5
Training loss: 1.5251566171646118
Validation loss: 2.272125095129013

Epoch: 5| Step: 6
Training loss: 2.4444456100463867
Validation loss: 2.276797115802765

Epoch: 5| Step: 7
Training loss: 1.9135973453521729
Validation loss: 2.2753055493036904

Epoch: 5| Step: 8
Training loss: 2.165541887283325
Validation loss: 2.289442698160807

Epoch: 5| Step: 9
Training loss: 2.573005437850952
Validation loss: 2.27016614874204

Epoch: 5| Step: 10
Training loss: 2.1135573387145996
Validation loss: 2.287976637482643

Epoch: 5| Step: 11
Training loss: 0.8538346290588379
Validation loss: 2.280037293831507

Epoch: 11| Step: 0
Training loss: 1.8344097137451172
Validation loss: 2.283090482155482

Epoch: 5| Step: 1
Training loss: 1.9027087688446045
Validation loss: 2.3031090994675956

Epoch: 5| Step: 2
Training loss: 2.817467451095581
Validation loss: 2.2805020262797675

Epoch: 5| Step: 3
Training loss: 2.383817195892334
Validation loss: 2.268503963947296

Epoch: 5| Step: 4
Training loss: 2.4570586681365967
Validation loss: 2.268936107556025

Epoch: 5| Step: 5
Training loss: 2.204530715942383
Validation loss: 2.2487548490365348

Epoch: 5| Step: 6
Training loss: 1.7296619415283203
Validation loss: 2.2454454402128854

Epoch: 5| Step: 7
Training loss: 2.0171608924865723
Validation loss: 2.2822667757670083

Epoch: 5| Step: 8
Training loss: 1.6884746551513672
Validation loss: 2.257811809579531

Epoch: 5| Step: 9
Training loss: 2.4488987922668457
Validation loss: 2.2775227377812066

Epoch: 5| Step: 10
Training loss: 2.182791233062744
Validation loss: 2.2751463701327643

Epoch: 5| Step: 11
Training loss: 1.8139424324035645
Validation loss: 2.254381517569224

Epoch: 12| Step: 0
Training loss: 1.9330253601074219
Validation loss: 2.2668307522932687

Epoch: 5| Step: 1
Training loss: 2.754878282546997
Validation loss: 2.273362477620443

Epoch: 5| Step: 2
Training loss: 2.45695161819458
Validation loss: 2.295765608549118

Epoch: 5| Step: 3
Training loss: 2.295973300933838
Validation loss: 2.2734575271606445

Epoch: 5| Step: 4
Training loss: 2.4035074710845947
Validation loss: 2.2965647280216217

Epoch: 5| Step: 5
Training loss: 1.8825442790985107
Validation loss: 2.2720241794983544

Epoch: 5| Step: 6
Training loss: 2.3799140453338623
Validation loss: 2.272117296854655

Epoch: 5| Step: 7
Training loss: 2.1165261268615723
Validation loss: 2.272165854771932

Epoch: 5| Step: 8
Training loss: 1.4004795551300049
Validation loss: 2.273059149583181

Epoch: 5| Step: 9
Training loss: 1.713004469871521
Validation loss: 2.2574945390224457

Epoch: 5| Step: 10
Training loss: 2.4144434928894043
Validation loss: 2.252061198155085

Epoch: 5| Step: 11
Training loss: 2.3745410442352295
Validation loss: 2.2589601079622903

Epoch: 13| Step: 0
Training loss: 1.892364501953125
Validation loss: 2.2438681920369468

Epoch: 5| Step: 1
Training loss: 1.8234695196151733
Validation loss: 2.2613371262947717

Epoch: 5| Step: 2
Training loss: 1.8154226541519165
Validation loss: 2.252383142709732

Epoch: 5| Step: 3
Training loss: 2.2080318927764893
Validation loss: 2.246499866247177

Epoch: 5| Step: 4
Training loss: 2.320272922515869
Validation loss: 2.268097514907519

Epoch: 5| Step: 5
Training loss: 1.5786532163619995
Validation loss: 2.244265074531237

Epoch: 5| Step: 6
Training loss: 2.274346113204956
Validation loss: 2.2858516524235406

Epoch: 5| Step: 7
Training loss: 2.653041124343872
Validation loss: 2.263973226149877

Epoch: 5| Step: 8
Training loss: 2.3012890815734863
Validation loss: 2.2567333777745566

Epoch: 5| Step: 9
Training loss: 1.8364976644515991
Validation loss: 2.2672773698965707

Epoch: 5| Step: 10
Training loss: 2.916144371032715
Validation loss: 2.2999722560246787

Epoch: 5| Step: 11
Training loss: 2.6757984161376953
Validation loss: 2.23424985508124

Epoch: 14| Step: 0
Training loss: 2.2849230766296387
Validation loss: 2.2754855851332345

Epoch: 5| Step: 1
Training loss: 1.7135343551635742
Validation loss: 2.260179509719213

Epoch: 5| Step: 2
Training loss: 1.7735382318496704
Validation loss: 2.2632739742596946

Epoch: 5| Step: 3
Training loss: 2.088667392730713
Validation loss: 2.2389135559399924

Epoch: 5| Step: 4
Training loss: 2.5708343982696533
Validation loss: 2.258825490872065

Epoch: 5| Step: 5
Training loss: 2.225893974304199
Validation loss: 2.255285153786341

Epoch: 5| Step: 6
Training loss: 1.9663610458374023
Validation loss: 2.2516912718613944

Epoch: 5| Step: 7
Training loss: 2.3832690715789795
Validation loss: 2.237152377764384

Epoch: 5| Step: 8
Training loss: 1.7528464794158936
Validation loss: 2.2469654977321625

Epoch: 5| Step: 9
Training loss: 2.3587889671325684
Validation loss: 2.2623804261287055

Epoch: 5| Step: 10
Training loss: 2.2542595863342285
Validation loss: 2.272764931122462

Epoch: 5| Step: 11
Training loss: 2.7924697399139404
Validation loss: 2.2538979202508926

Epoch: 15| Step: 0
Training loss: 1.9760792255401611
Validation loss: 2.2326649526755014

Epoch: 5| Step: 1
Training loss: 2.342442512512207
Validation loss: 2.2434510538975396

Epoch: 5| Step: 2
Training loss: 2.343992233276367
Validation loss: 2.250577916701635

Epoch: 5| Step: 3
Training loss: 2.1905274391174316
Validation loss: 2.233728438615799

Epoch: 5| Step: 4
Training loss: 2.095698595046997
Validation loss: 2.233932316303253

Epoch: 5| Step: 5
Training loss: 2.4317233562469482
Validation loss: 2.2358810702959695

Epoch: 5| Step: 6
Training loss: 1.7348381280899048
Validation loss: 2.233330801129341

Epoch: 5| Step: 7
Training loss: 2.055785655975342
Validation loss: 2.2257755945126214

Epoch: 5| Step: 8
Training loss: 1.7800567150115967
Validation loss: 2.225978597998619

Epoch: 5| Step: 9
Training loss: 2.5080971717834473
Validation loss: 2.2415422896544137

Epoch: 5| Step: 10
Training loss: 1.9036144018173218
Validation loss: 2.256153558691343

Epoch: 5| Step: 11
Training loss: 2.5772643089294434
Validation loss: 2.221490686138471

Epoch: 16| Step: 0
Training loss: 2.4680492877960205
Validation loss: 2.2368574738502502

Epoch: 5| Step: 1
Training loss: 1.9704570770263672
Validation loss: 2.2372116843859353

Epoch: 5| Step: 2
Training loss: 1.7627172470092773
Validation loss: 2.2343711853027344

Epoch: 5| Step: 3
Training loss: 2.0652453899383545
Validation loss: 2.215946704149246

Epoch: 5| Step: 4
Training loss: 2.1827621459960938
Validation loss: 2.2170012245575585

Epoch: 5| Step: 5
Training loss: 2.149697780609131
Validation loss: 2.2150230556726456

Epoch: 5| Step: 6
Training loss: 1.5235638618469238
Validation loss: 2.2186486621697745

Epoch: 5| Step: 7
Training loss: 2.0291383266448975
Validation loss: 2.2293529560168586

Epoch: 5| Step: 8
Training loss: 2.560859441757202
Validation loss: 2.2343272815148034

Epoch: 5| Step: 9
Training loss: 2.6477162837982178
Validation loss: 2.210175762573878

Epoch: 5| Step: 10
Training loss: 1.8216218948364258
Validation loss: 2.2410669922828674

Epoch: 5| Step: 11
Training loss: 3.181804656982422
Validation loss: 2.2334407965342202

Epoch: 17| Step: 0
Training loss: 2.704939365386963
Validation loss: 2.208321531613668

Epoch: 5| Step: 1
Training loss: 1.838017225265503
Validation loss: 2.2144736647605896

Epoch: 5| Step: 2
Training loss: 2.6687328815460205
Validation loss: 2.2365329762299857

Epoch: 5| Step: 3
Training loss: 2.2439568042755127
Validation loss: 2.2259209156036377

Epoch: 5| Step: 4
Training loss: 2.105747699737549
Validation loss: 2.234002947807312

Epoch: 5| Step: 5
Training loss: 1.824122667312622
Validation loss: 2.2312514086564383

Epoch: 5| Step: 6
Training loss: 2.2465264797210693
Validation loss: 2.2231781582037606

Epoch: 5| Step: 7
Training loss: 2.0524380207061768
Validation loss: 2.229281574487686

Epoch: 5| Step: 8
Training loss: 1.5997083187103271
Validation loss: 2.2418024043242135

Epoch: 5| Step: 9
Training loss: 1.8064098358154297
Validation loss: 2.226161773006121

Epoch: 5| Step: 10
Training loss: 2.597595691680908
Validation loss: 2.223336393634478

Epoch: 5| Step: 11
Training loss: 0.4546457529067993
Validation loss: 2.219483698407809

Epoch: 18| Step: 0
Training loss: 2.0722849369049072
Validation loss: 2.222872644662857

Epoch: 5| Step: 1
Training loss: 1.855635643005371
Validation loss: 2.201837698618571

Epoch: 5| Step: 2
Training loss: 1.981065034866333
Validation loss: 2.2091550827026367

Epoch: 5| Step: 3
Training loss: 1.832688331604004
Validation loss: 2.2249298840761185

Epoch: 5| Step: 4
Training loss: 2.5790820121765137
Validation loss: 2.215565284093221

Epoch: 5| Step: 5
Training loss: 2.2903683185577393
Validation loss: 2.221354936559995

Epoch: 5| Step: 6
Training loss: 2.6217641830444336
Validation loss: 2.223756248752276

Epoch: 5| Step: 7
Training loss: 2.2571372985839844
Validation loss: 2.216888795296351

Epoch: 5| Step: 8
Training loss: 1.6541035175323486
Validation loss: 2.219707945982615

Epoch: 5| Step: 9
Training loss: 1.5198602676391602
Validation loss: 2.2115976959466934

Epoch: 5| Step: 10
Training loss: 2.1760165691375732
Validation loss: 2.207131673892339

Epoch: 5| Step: 11
Training loss: 2.330878257751465
Validation loss: 2.214957798520724

Epoch: 19| Step: 0
Training loss: 2.35461163520813
Validation loss: 2.222661405801773

Epoch: 5| Step: 1
Training loss: 2.0243794918060303
Validation loss: 2.2467816273371377

Epoch: 5| Step: 2
Training loss: 2.4095447063446045
Validation loss: 2.2490966419378915

Epoch: 5| Step: 3
Training loss: 2.0146853923797607
Validation loss: 2.260136604309082

Epoch: 5| Step: 4
Training loss: 1.9084644317626953
Validation loss: 2.286122585336367

Epoch: 5| Step: 5
Training loss: 1.819104790687561
Validation loss: 2.23685692747434

Epoch: 5| Step: 6
Training loss: 2.1880977153778076
Validation loss: 2.252737949291865

Epoch: 5| Step: 7
Training loss: 1.888872742652893
Validation loss: 2.2430149813493094

Epoch: 5| Step: 8
Training loss: 2.5393412113189697
Validation loss: 2.232030818859736

Epoch: 5| Step: 9
Training loss: 1.7180118560791016
Validation loss: 2.2278919517993927

Epoch: 5| Step: 10
Training loss: 2.6618943214416504
Validation loss: 2.244112422068914

Epoch: 5| Step: 11
Training loss: 1.5564024448394775
Validation loss: 2.2251692513624826

Epoch: 20| Step: 0
Training loss: 2.026559352874756
Validation loss: 2.241742620865504

Epoch: 5| Step: 1
Training loss: 1.7218844890594482
Validation loss: 2.210103929042816

Epoch: 5| Step: 2
Training loss: 2.848985433578491
Validation loss: 2.194696307182312

Epoch: 5| Step: 3
Training loss: 2.0705199241638184
Validation loss: 2.2062057157357535

Epoch: 5| Step: 4
Training loss: 1.5950933694839478
Validation loss: 2.2273893455664315

Epoch: 5| Step: 5
Training loss: 1.8027188777923584
Validation loss: 2.2303932160139084

Epoch: 5| Step: 6
Training loss: 2.577606678009033
Validation loss: 2.188573107123375

Epoch: 5| Step: 7
Training loss: 1.999502182006836
Validation loss: 2.2177989880243936

Epoch: 5| Step: 8
Training loss: 2.398277759552002
Validation loss: 2.2083769838015237

Epoch: 5| Step: 9
Training loss: 2.2869672775268555
Validation loss: 2.204226771990458

Epoch: 5| Step: 10
Training loss: 1.755772352218628
Validation loss: 2.2186894565820694

Epoch: 5| Step: 11
Training loss: 1.8752895593643188
Validation loss: 2.1981770396232605

Epoch: 21| Step: 0
Training loss: 2.7922863960266113
Validation loss: 2.18540487686793

Epoch: 5| Step: 1
Training loss: 2.672121524810791
Validation loss: 2.1858943849802017

Epoch: 5| Step: 2
Training loss: 1.6230818033218384
Validation loss: 2.195431411266327

Epoch: 5| Step: 3
Training loss: 1.6144979000091553
Validation loss: 2.206622133652369

Epoch: 5| Step: 4
Training loss: 2.03725266456604
Validation loss: 2.1969505548477173

Epoch: 5| Step: 5
Training loss: 1.9957425594329834
Validation loss: 2.207401067018509

Epoch: 5| Step: 6
Training loss: 2.1307907104492188
Validation loss: 2.1807836492856345

Epoch: 5| Step: 7
Training loss: 2.291383981704712
Validation loss: 2.1942650924126306

Epoch: 5| Step: 8
Training loss: 1.321136236190796
Validation loss: 2.218253970146179

Epoch: 5| Step: 9
Training loss: 2.04024076461792
Validation loss: 2.1592577348152795

Epoch: 5| Step: 10
Training loss: 2.2621347904205322
Validation loss: 2.1615735540787377

Epoch: 5| Step: 11
Training loss: 3.149667263031006
Validation loss: 2.195322036743164

Epoch: 22| Step: 0
Training loss: 1.765953779220581
Validation loss: 2.1779737770557404

Epoch: 5| Step: 1
Training loss: 1.962397813796997
Validation loss: 2.1970306634902954

Epoch: 5| Step: 2
Training loss: 1.7631524801254272
Validation loss: 2.205386077364286

Epoch: 5| Step: 3
Training loss: 2.010918140411377
Validation loss: 2.183904508749644

Epoch: 5| Step: 4
Training loss: 2.4578192234039307
Validation loss: 2.199224899212519

Epoch: 5| Step: 5
Training loss: 2.161257028579712
Validation loss: 2.190103312333425

Epoch: 5| Step: 6
Training loss: 2.0647873878479004
Validation loss: 2.1979285975297294

Epoch: 5| Step: 7
Training loss: 2.0931544303894043
Validation loss: 2.197459191083908

Epoch: 5| Step: 8
Training loss: 2.506829023361206
Validation loss: 2.162775610884031

Epoch: 5| Step: 9
Training loss: 1.7613677978515625
Validation loss: 2.213562568028768

Epoch: 5| Step: 10
Training loss: 2.103262424468994
Validation loss: 2.179663891593615

Epoch: 5| Step: 11
Training loss: 1.911422848701477
Validation loss: 2.1891716023286185

Epoch: 23| Step: 0
Training loss: 2.142066240310669
Validation loss: 2.1626103719075522

Epoch: 5| Step: 1
Training loss: 1.5440363883972168
Validation loss: 2.1889437238375344

Epoch: 5| Step: 2
Training loss: 1.9619232416152954
Validation loss: 2.1759628554185233

Epoch: 5| Step: 3
Training loss: 1.7512823343276978
Validation loss: 2.1849577774604163

Epoch: 5| Step: 4
Training loss: 1.3721061944961548
Validation loss: 2.182836433251699

Epoch: 5| Step: 5
Training loss: 2.0156383514404297
Validation loss: 2.2018267015616098

Epoch: 5| Step: 6
Training loss: 2.00453519821167
Validation loss: 2.209086755911509

Epoch: 5| Step: 7
Training loss: 1.9984554052352905
Validation loss: 2.204375838239988

Epoch: 5| Step: 8
Training loss: 2.2322566509246826
Validation loss: 2.199582740664482

Epoch: 5| Step: 9
Training loss: 3.5854899883270264
Validation loss: 2.187520071864128

Epoch: 5| Step: 10
Training loss: 2.0903258323669434
Validation loss: 2.189379096031189

Epoch: 5| Step: 11
Training loss: 3.397088050842285
Validation loss: 2.167769193649292

Epoch: 24| Step: 0
Training loss: 2.0450546741485596
Validation loss: 2.1711805711189904

Epoch: 5| Step: 1
Training loss: 1.8394343852996826
Validation loss: 2.1811081171035767

Epoch: 5| Step: 2
Training loss: 2.114783763885498
Validation loss: 2.167146290342013

Epoch: 5| Step: 3
Training loss: 1.776106834411621
Validation loss: 2.1854988833268485

Epoch: 5| Step: 4
Training loss: 2.2440483570098877
Validation loss: 2.158554121851921

Epoch: 5| Step: 5
Training loss: 1.8106663227081299
Validation loss: 2.189553697903951

Epoch: 5| Step: 6
Training loss: 1.871222734451294
Validation loss: 2.189534470438957

Epoch: 5| Step: 7
Training loss: 2.3045105934143066
Validation loss: 2.1878833770751953

Epoch: 5| Step: 8
Training loss: 2.329883337020874
Validation loss: 2.18831496934096

Epoch: 5| Step: 9
Training loss: 2.4270031452178955
Validation loss: 2.180627793073654

Epoch: 5| Step: 10
Training loss: 1.812401533126831
Validation loss: 2.1630170047283173

Epoch: 5| Step: 11
Training loss: 2.0673012733459473
Validation loss: 2.1484322547912598

Epoch: 25| Step: 0
Training loss: 2.1153149604797363
Validation loss: 2.165631910165151

Epoch: 5| Step: 1
Training loss: 2.076630115509033
Validation loss: 2.1590167929728827

Epoch: 5| Step: 2
Training loss: 2.2267024517059326
Validation loss: 2.1510015577077866

Epoch: 5| Step: 3
Training loss: 2.2905588150024414
Validation loss: 2.1643086870511374

Epoch: 5| Step: 4
Training loss: 1.9743382930755615
Validation loss: 2.178024262189865

Epoch: 5| Step: 5
Training loss: 1.6555302143096924
Validation loss: 2.158577765027682

Epoch: 5| Step: 6
Training loss: 2.2965526580810547
Validation loss: 2.1680777172247567

Epoch: 5| Step: 7
Training loss: 2.2472939491271973
Validation loss: 2.1792149245738983

Epoch: 5| Step: 8
Training loss: 1.506024956703186
Validation loss: 2.14538703362147

Epoch: 5| Step: 9
Training loss: 2.0635762214660645
Validation loss: 2.1677587628364563

Epoch: 5| Step: 10
Training loss: 2.0525152683258057
Validation loss: 2.1683861712614694

Epoch: 5| Step: 11
Training loss: 1.9765270948410034
Validation loss: 2.166721150279045

Epoch: 26| Step: 0
Training loss: 2.1218152046203613
Validation loss: 2.1539329638083777

Epoch: 5| Step: 1
Training loss: 2.456500768661499
Validation loss: 2.177834471066793

Epoch: 5| Step: 2
Training loss: 1.9784408807754517
Validation loss: 2.1580525636672974

Epoch: 5| Step: 3
Training loss: 2.2224783897399902
Validation loss: 2.1837326139211655

Epoch: 5| Step: 4
Training loss: 1.8868749141693115
Validation loss: 2.1818121820688248

Epoch: 5| Step: 5
Training loss: 2.037057876586914
Validation loss: 2.156902387738228

Epoch: 5| Step: 6
Training loss: 2.3723106384277344
Validation loss: 2.1670163720846176

Epoch: 5| Step: 7
Training loss: 2.5203347206115723
Validation loss: 2.1587822288274765

Epoch: 5| Step: 8
Training loss: 2.2328994274139404
Validation loss: 2.174364854892095

Epoch: 5| Step: 9
Training loss: 1.6544907093048096
Validation loss: 2.1515907645225525

Epoch: 5| Step: 10
Training loss: 1.4310331344604492
Validation loss: 2.1525152126948037

Epoch: 5| Step: 11
Training loss: 0.8789430856704712
Validation loss: 2.142626782258352

Epoch: 27| Step: 0
Training loss: 2.5659215450286865
Validation loss: 2.145376871029536

Epoch: 5| Step: 1
Training loss: 2.4601383209228516
Validation loss: 2.1220254749059677

Epoch: 5| Step: 2
Training loss: 1.8467681407928467
Validation loss: 2.163414607445399

Epoch: 5| Step: 3
Training loss: 2.0363929271698
Validation loss: 2.1668330977360406

Epoch: 5| Step: 4
Training loss: 2.0835258960723877
Validation loss: 2.1442364305257797

Epoch: 5| Step: 5
Training loss: 1.8459193706512451
Validation loss: 2.1771141787370047

Epoch: 5| Step: 6
Training loss: 1.8430322408676147
Validation loss: 2.1649311830600104

Epoch: 5| Step: 7
Training loss: 1.669264554977417
Validation loss: 2.163878853122393

Epoch: 5| Step: 8
Training loss: 2.288414716720581
Validation loss: 2.1573271652062735

Epoch: 5| Step: 9
Training loss: 2.1542975902557373
Validation loss: 2.168996885418892

Epoch: 5| Step: 10
Training loss: 1.9068816900253296
Validation loss: 2.1360400219758353

Epoch: 5| Step: 11
Training loss: 1.9413297176361084
Validation loss: 2.15630204975605

Epoch: 28| Step: 0
Training loss: 1.6461670398712158
Validation loss: 2.149107486009598

Epoch: 5| Step: 1
Training loss: 2.2751107215881348
Validation loss: 2.1442764600118003

Epoch: 5| Step: 2
Training loss: 1.6918216943740845
Validation loss: 2.14984663327535

Epoch: 5| Step: 3
Training loss: 1.3333126306533813
Validation loss: 2.1289072980483374

Epoch: 5| Step: 4
Training loss: 1.8477890491485596
Validation loss: 2.140748461087545

Epoch: 5| Step: 5
Training loss: 1.8322162628173828
Validation loss: 2.1608263502518334

Epoch: 5| Step: 6
Training loss: 2.2188992500305176
Validation loss: 2.1620378891626992

Epoch: 5| Step: 7
Training loss: 2.727755308151245
Validation loss: 2.147682398557663

Epoch: 5| Step: 8
Training loss: 2.9004054069519043
Validation loss: 2.1393122375011444

Epoch: 5| Step: 9
Training loss: 2.350282669067383
Validation loss: 2.155530591805776

Epoch: 5| Step: 10
Training loss: 1.2804367542266846
Validation loss: 2.157383307814598

Epoch: 5| Step: 11
Training loss: 3.2037696838378906
Validation loss: 2.1618820875883102

Epoch: 29| Step: 0
Training loss: 1.3817522525787354
Validation loss: 2.1599527100721994

Epoch: 5| Step: 1
Training loss: 1.5676288604736328
Validation loss: 2.165631572405497

Epoch: 5| Step: 2
Training loss: 2.4278724193573
Validation loss: 2.1868518193562827

Epoch: 5| Step: 3
Training loss: 1.6734545230865479
Validation loss: 2.155052974820137

Epoch: 5| Step: 4
Training loss: 2.598600149154663
Validation loss: 2.128279000520706

Epoch: 5| Step: 5
Training loss: 2.3185875415802
Validation loss: 2.1524232625961304

Epoch: 5| Step: 6
Training loss: 1.974098801612854
Validation loss: 2.126828501621882

Epoch: 5| Step: 7
Training loss: 2.7288498878479004
Validation loss: 2.139996260404587

Epoch: 5| Step: 8
Training loss: 1.8481597900390625
Validation loss: 2.136505792538325

Epoch: 5| Step: 9
Training loss: 2.223191499710083
Validation loss: 2.1253250340620675

Epoch: 5| Step: 10
Training loss: 1.7553329467773438
Validation loss: 2.152897129456202

Epoch: 5| Step: 11
Training loss: 1.9560569524765015
Validation loss: 2.1580552955468497

Epoch: 30| Step: 0
Training loss: 1.9325748682022095
Validation loss: 2.160696417093277

Epoch: 5| Step: 1
Training loss: 2.2090203762054443
Validation loss: 2.1305246452490487

Epoch: 5| Step: 2
Training loss: 2.333336353302002
Validation loss: 2.139084776242574

Epoch: 5| Step: 3
Training loss: 2.1322174072265625
Validation loss: 2.1349616597096124

Epoch: 5| Step: 4
Training loss: 1.8347761631011963
Validation loss: 2.139866426587105

Epoch: 5| Step: 5
Training loss: 1.7874482870101929
Validation loss: 2.1503635992606482

Epoch: 5| Step: 6
Training loss: 2.716064929962158
Validation loss: 2.1435129890839257

Epoch: 5| Step: 7
Training loss: 2.283346176147461
Validation loss: 2.1548249224821725

Epoch: 5| Step: 8
Training loss: 2.1540040969848633
Validation loss: 2.1405502557754517

Epoch: 5| Step: 9
Training loss: 1.6288597583770752
Validation loss: 2.1447387834390006

Epoch: 5| Step: 10
Training loss: 1.5951719284057617
Validation loss: 2.1506329576174417

Epoch: 5| Step: 11
Training loss: 1.576347827911377
Validation loss: 2.1496540357669196

Epoch: 31| Step: 0
Training loss: 2.982611894607544
Validation loss: 2.1347785741090775

Epoch: 5| Step: 1
Training loss: 1.9876205921173096
Validation loss: 2.1447850515445075

Epoch: 5| Step: 2
Training loss: 1.752183198928833
Validation loss: 2.1324011832475662

Epoch: 5| Step: 3
Training loss: 1.806064248085022
Validation loss: 2.134945899248123

Epoch: 5| Step: 4
Training loss: 1.791234016418457
Validation loss: 2.136584465702375

Epoch: 5| Step: 5
Training loss: 2.2848987579345703
Validation loss: 2.1359693010648093

Epoch: 5| Step: 6
Training loss: 1.9058862924575806
Validation loss: 2.1539499362309775

Epoch: 5| Step: 7
Training loss: 1.870897889137268
Validation loss: 2.1341104060411453

Epoch: 5| Step: 8
Training loss: 1.7517845630645752
Validation loss: 2.146756718556086

Epoch: 5| Step: 9
Training loss: 2.1803038120269775
Validation loss: 2.109680304924647

Epoch: 5| Step: 10
Training loss: 2.157586097717285
Validation loss: 2.1391049524148307

Epoch: 5| Step: 11
Training loss: 1.7410337924957275
Validation loss: 2.1476659725109735

Epoch: 32| Step: 0
Training loss: 2.7087860107421875
Validation loss: 2.145199636618296

Epoch: 5| Step: 1
Training loss: 1.8152862787246704
Validation loss: 2.1114375789960227

Epoch: 5| Step: 2
Training loss: 1.9717222452163696
Validation loss: 2.1258679727713266

Epoch: 5| Step: 3
Training loss: 1.7344791889190674
Validation loss: 2.1108670781056085

Epoch: 5| Step: 4
Training loss: 1.8494399785995483
Validation loss: 2.150889346996943

Epoch: 5| Step: 5
Training loss: 1.9711729288101196
Validation loss: 2.1404214402039847

Epoch: 5| Step: 6
Training loss: 1.921282172203064
Validation loss: 2.1175646434227624

Epoch: 5| Step: 7
Training loss: 2.2756729125976562
Validation loss: 2.118954132000605

Epoch: 5| Step: 8
Training loss: 1.8202457427978516
Validation loss: 2.14067180454731

Epoch: 5| Step: 9
Training loss: 2.116711139678955
Validation loss: 2.1052661687135696

Epoch: 5| Step: 10
Training loss: 1.9689689874649048
Validation loss: 2.124313563108444

Epoch: 5| Step: 11
Training loss: 2.4633030891418457
Validation loss: 2.1155361980199814

Epoch: 33| Step: 0
Training loss: 2.197450637817383
Validation loss: 2.1284775833288827

Epoch: 5| Step: 1
Training loss: 2.1073179244995117
Validation loss: 2.108585854371389

Epoch: 5| Step: 2
Training loss: 1.839115858078003
Validation loss: 2.122210885087649

Epoch: 5| Step: 3
Training loss: 1.801923394203186
Validation loss: 2.1092418283224106

Epoch: 5| Step: 4
Training loss: 2.8313815593719482
Validation loss: 2.120724380016327

Epoch: 5| Step: 5
Training loss: 2.4108004570007324
Validation loss: 2.136270528038343

Epoch: 5| Step: 6
Training loss: 1.9652321338653564
Validation loss: 2.1237958818674088

Epoch: 5| Step: 7
Training loss: 1.3947975635528564
Validation loss: 2.12075167397658

Epoch: 5| Step: 8
Training loss: 1.7412841320037842
Validation loss: 2.1282677551110587

Epoch: 5| Step: 9
Training loss: 1.5335947275161743
Validation loss: 2.121824194987615

Epoch: 5| Step: 10
Training loss: 2.550075054168701
Validation loss: 2.11670982837677

Epoch: 5| Step: 11
Training loss: 1.2647234201431274
Validation loss: 2.129312684138616

Epoch: 34| Step: 0
Training loss: 1.9260705709457397
Validation loss: 2.1161919881900153

Epoch: 5| Step: 1
Training loss: 2.0442049503326416
Validation loss: 2.1273755033810935

Epoch: 5| Step: 2
Training loss: 1.7751922607421875
Validation loss: 2.1572210689385733

Epoch: 5| Step: 3
Training loss: 1.87973952293396
Validation loss: 2.136596903204918

Epoch: 5| Step: 4
Training loss: 2.0082719326019287
Validation loss: 2.1484488199154534

Epoch: 5| Step: 5
Training loss: 1.9976303577423096
Validation loss: 2.1415152748425803

Epoch: 5| Step: 6
Training loss: 2.0782933235168457
Validation loss: 2.1335502564907074

Epoch: 5| Step: 7
Training loss: 1.884778380393982
Validation loss: 2.134563754002253

Epoch: 5| Step: 8
Training loss: 2.3639607429504395
Validation loss: 2.103953500588735

Epoch: 5| Step: 9
Training loss: 1.9330089092254639
Validation loss: 2.11779648065567

Epoch: 5| Step: 10
Training loss: 1.9429092407226562
Validation loss: 2.14810041586558

Epoch: 5| Step: 11
Training loss: 3.381479263305664
Validation loss: 2.13524799545606

Epoch: 35| Step: 0
Training loss: 1.7518603801727295
Validation loss: 2.1075033148129783

Epoch: 5| Step: 1
Training loss: 1.6500180959701538
Validation loss: 2.103680436809858

Epoch: 5| Step: 2
Training loss: 1.7091996669769287
Validation loss: 2.1203929831584296

Epoch: 5| Step: 3
Training loss: 2.7134063243865967
Validation loss: 2.087749178210894

Epoch: 5| Step: 4
Training loss: 1.4273650646209717
Validation loss: 2.1282552232344947

Epoch: 5| Step: 5
Training loss: 2.3450725078582764
Validation loss: 2.1125555435816445

Epoch: 5| Step: 6
Training loss: 1.8460159301757812
Validation loss: 2.094564437866211

Epoch: 5| Step: 7
Training loss: 2.5712180137634277
Validation loss: 2.130537281433741

Epoch: 5| Step: 8
Training loss: 1.9727576971054077
Validation loss: 2.1243254194657006

Epoch: 5| Step: 9
Training loss: 2.3232741355895996
Validation loss: 2.1217380464076996

Epoch: 5| Step: 10
Training loss: 1.931617021560669
Validation loss: 2.135605971018473

Epoch: 5| Step: 11
Training loss: 1.4935929775238037
Validation loss: 2.1177496711413064

Epoch: 36| Step: 0
Training loss: 1.723548173904419
Validation loss: 2.120233808954557

Epoch: 5| Step: 1
Training loss: 2.597656726837158
Validation loss: 2.118408650159836

Epoch: 5| Step: 2
Training loss: 1.9390207529067993
Validation loss: 2.108815794189771

Epoch: 5| Step: 3
Training loss: 2.280655860900879
Validation loss: 2.114496191342672

Epoch: 5| Step: 4
Training loss: 2.356106758117676
Validation loss: 2.116464967528979

Epoch: 5| Step: 5
Training loss: 2.112027168273926
Validation loss: 2.1248196363449097

Epoch: 5| Step: 6
Training loss: 1.9160616397857666
Validation loss: 2.120676800608635

Epoch: 5| Step: 7
Training loss: 2.2671573162078857
Validation loss: 2.1385633796453476

Epoch: 5| Step: 8
Training loss: 1.446134328842163
Validation loss: 2.0980872064828873

Epoch: 5| Step: 9
Training loss: 2.1890552043914795
Validation loss: 2.134840120871862

Epoch: 5| Step: 10
Training loss: 1.2830435037612915
Validation loss: 2.133959541718165

Epoch: 5| Step: 11
Training loss: 2.100372552871704
Validation loss: 2.121829261382421

Epoch: 37| Step: 0
Training loss: 1.8537906408309937
Validation loss: 2.128368710478147

Epoch: 5| Step: 1
Training loss: 1.6833451986312866
Validation loss: 2.129968206087748

Epoch: 5| Step: 2
Training loss: 1.7394897937774658
Validation loss: 2.1330137501160302

Epoch: 5| Step: 3
Training loss: 2.2171177864074707
Validation loss: 2.1220168521006904

Epoch: 5| Step: 4
Training loss: 2.25880765914917
Validation loss: 2.143547664086024

Epoch: 5| Step: 5
Training loss: 2.3065624237060547
Validation loss: 2.1169500251611075

Epoch: 5| Step: 6
Training loss: 2.004542827606201
Validation loss: 2.135095457235972

Epoch: 5| Step: 7
Training loss: 1.772770881652832
Validation loss: 2.1055772999922433

Epoch: 5| Step: 8
Training loss: 1.7601341009140015
Validation loss: 2.1356159845987954

Epoch: 5| Step: 9
Training loss: 1.9672584533691406
Validation loss: 2.1074372082948685

Epoch: 5| Step: 10
Training loss: 2.151341676712036
Validation loss: 2.115237911542257

Epoch: 5| Step: 11
Training loss: 4.012234687805176
Validation loss: 2.127317945162455

Epoch: 38| Step: 0
Training loss: 1.4458311796188354
Validation loss: 2.091851989428202

Epoch: 5| Step: 1
Training loss: 1.9062073230743408
Validation loss: 2.0902526577313743

Epoch: 5| Step: 2
Training loss: 2.216447353363037
Validation loss: 2.1042895962794623

Epoch: 5| Step: 3
Training loss: 2.24018931388855
Validation loss: 2.0880070279041925

Epoch: 5| Step: 4
Training loss: 1.3901479244232178
Validation loss: 2.1148554186026254

Epoch: 5| Step: 5
Training loss: 1.909367561340332
Validation loss: 2.1083233704169593

Epoch: 5| Step: 6
Training loss: 2.4051921367645264
Validation loss: 2.098445018132528

Epoch: 5| Step: 7
Training loss: 2.5082221031188965
Validation loss: 2.1404136369625726

Epoch: 5| Step: 8
Training loss: 2.359586000442505
Validation loss: 2.1198981751998267

Epoch: 5| Step: 9
Training loss: 2.5700812339782715
Validation loss: 2.1060809592405954

Epoch: 5| Step: 10
Training loss: 1.5357530117034912
Validation loss: 2.1019180665413537

Epoch: 5| Step: 11
Training loss: 1.1749814748764038
Validation loss: 2.0994999508062997

Epoch: 39| Step: 0
Training loss: 2.0013339519500732
Validation loss: 2.1112871368726096

Epoch: 5| Step: 1
Training loss: 2.419888496398926
Validation loss: 2.108013868331909

Epoch: 5| Step: 2
Training loss: 1.8226178884506226
Validation loss: 2.0859193205833435

Epoch: 5| Step: 3
Training loss: 1.6996479034423828
Validation loss: 2.0934932430585227

Epoch: 5| Step: 4
Training loss: 1.4436380863189697
Validation loss: 2.1135855267445245

Epoch: 5| Step: 5
Training loss: 2.134702682495117
Validation loss: 2.1213877697785697

Epoch: 5| Step: 6
Training loss: 1.9060500860214233
Validation loss: 2.1151164968808494

Epoch: 5| Step: 7
Training loss: 1.4891256093978882
Validation loss: 2.1252754032611847

Epoch: 5| Step: 8
Training loss: 2.2127089500427246
Validation loss: 2.1389859269062677

Epoch: 5| Step: 9
Training loss: 2.3644886016845703
Validation loss: 2.138041317462921

Epoch: 5| Step: 10
Training loss: 2.0752360820770264
Validation loss: 2.1169947385787964

Epoch: 5| Step: 11
Training loss: 5.4824090003967285
Validation loss: 2.1103935291369758

Epoch: 40| Step: 0
Training loss: 1.7283004522323608
Validation loss: 2.1213519076506295

Epoch: 5| Step: 1
Training loss: 2.566420078277588
Validation loss: 2.094425141811371

Epoch: 5| Step: 2
Training loss: 2.1586155891418457
Validation loss: 2.1116823703050613

Epoch: 5| Step: 3
Training loss: 2.4255568981170654
Validation loss: 2.1329213281472525

Epoch: 5| Step: 4
Training loss: 1.5579583644866943
Validation loss: 2.109287107984225

Epoch: 5| Step: 5
Training loss: 2.050899028778076
Validation loss: 2.0962559332450232

Epoch: 5| Step: 6
Training loss: 1.7595546245574951
Validation loss: 2.086783707141876

Epoch: 5| Step: 7
Training loss: 1.905282974243164
Validation loss: 2.1084628651539483

Epoch: 5| Step: 8
Training loss: 1.661461591720581
Validation loss: 2.1100471019744873

Epoch: 5| Step: 9
Training loss: 2.3427233695983887
Validation loss: 2.1121421257654824

Epoch: 5| Step: 10
Training loss: 2.1441025733947754
Validation loss: 2.1216045717398324

Epoch: 5| Step: 11
Training loss: 1.2002758979797363
Validation loss: 2.098484163482984

Epoch: 41| Step: 0
Training loss: 2.019874334335327
Validation loss: 2.0969445407390594

Epoch: 5| Step: 1
Training loss: 1.9603322744369507
Validation loss: 2.10184716184934

Epoch: 5| Step: 2
Training loss: 2.9892945289611816
Validation loss: 2.1165772875150046

Epoch: 5| Step: 3
Training loss: 1.895037293434143
Validation loss: 2.124933511018753

Epoch: 5| Step: 4
Training loss: 2.316254138946533
Validation loss: 2.1174852748711905

Epoch: 5| Step: 5
Training loss: 2.2074272632598877
Validation loss: 2.1089461694161096

Epoch: 5| Step: 6
Training loss: 1.6890567541122437
Validation loss: 2.144029900431633

Epoch: 5| Step: 7
Training loss: 1.4299240112304688
Validation loss: 2.1330588360627494

Epoch: 5| Step: 8
Training loss: 2.1017496585845947
Validation loss: 2.1278060724337897

Epoch: 5| Step: 9
Training loss: 1.7314720153808594
Validation loss: 2.1193061222632728

Epoch: 5| Step: 10
Training loss: 1.7971220016479492
Validation loss: 2.133685603737831

Epoch: 5| Step: 11
Training loss: 1.1396009922027588
Validation loss: 2.1111674904823303

Epoch: 42| Step: 0
Training loss: 1.4727811813354492
Validation loss: 2.119859824577967

Epoch: 5| Step: 1
Training loss: 1.5426080226898193
Validation loss: 2.1259132027626038

Epoch: 5| Step: 2
Training loss: 1.8689429759979248
Validation loss: 2.1330966552098594

Epoch: 5| Step: 3
Training loss: 1.9058725833892822
Validation loss: 2.129975234468778

Epoch: 5| Step: 4
Training loss: 2.3607993125915527
Validation loss: 2.1411869823932648

Epoch: 5| Step: 5
Training loss: 1.7143207788467407
Validation loss: 2.133711487054825

Epoch: 5| Step: 6
Training loss: 2.624159336090088
Validation loss: 2.147231643398603

Epoch: 5| Step: 7
Training loss: 1.8383525609970093
Validation loss: 2.1319835583368936

Epoch: 5| Step: 8
Training loss: 2.678816795349121
Validation loss: 2.110088735818863

Epoch: 5| Step: 9
Training loss: 2.0230154991149902
Validation loss: 2.0879363069931665

Epoch: 5| Step: 10
Training loss: 1.987453818321228
Validation loss: 2.095752085248629

Epoch: 5| Step: 11
Training loss: 2.8805902004241943
Validation loss: 2.0883478124936423

Epoch: 43| Step: 0
Training loss: 1.8892133235931396
Validation loss: 2.093045944968859

Epoch: 5| Step: 1
Training loss: 1.9819660186767578
Validation loss: 2.0851235737403235

Epoch: 5| Step: 2
Training loss: 2.2903337478637695
Validation loss: 2.0922249853610992

Epoch: 5| Step: 3
Training loss: 1.6194934844970703
Validation loss: 2.1159862081209817

Epoch: 5| Step: 4
Training loss: 1.6799194812774658
Validation loss: 2.1222598254680634

Epoch: 5| Step: 5
Training loss: 2.7568137645721436
Validation loss: 2.084268425901731

Epoch: 5| Step: 6
Training loss: 1.4193060398101807
Validation loss: 2.1103467543919883

Epoch: 5| Step: 7
Training loss: 2.3664822578430176
Validation loss: 2.09648605187734

Epoch: 5| Step: 8
Training loss: 1.863641381263733
Validation loss: 2.09315753976504

Epoch: 5| Step: 9
Training loss: 1.9417721033096313
Validation loss: 2.100059558947881

Epoch: 5| Step: 10
Training loss: 2.2380142211914062
Validation loss: 2.0894477466742196

Epoch: 5| Step: 11
Training loss: 2.1789894104003906
Validation loss: 2.095237135887146

Epoch: 44| Step: 0
Training loss: 1.85348379611969
Validation loss: 2.083925078312556

Epoch: 5| Step: 1
Training loss: 1.7218033075332642
Validation loss: 2.0823980470498404

Epoch: 5| Step: 2
Training loss: 1.9864013195037842
Validation loss: 2.100911791125933

Epoch: 5| Step: 3
Training loss: 1.7392752170562744
Validation loss: 2.105843891700109

Epoch: 5| Step: 4
Training loss: 1.8047412633895874
Validation loss: 2.1005840500195823

Epoch: 5| Step: 5
Training loss: 2.23394513130188
Validation loss: 2.124949331084887

Epoch: 5| Step: 6
Training loss: 1.671663522720337
Validation loss: 2.1244129141171775

Epoch: 5| Step: 7
Training loss: 2.003208875656128
Validation loss: 2.0983132819334664

Epoch: 5| Step: 8
Training loss: 2.0762763023376465
Validation loss: 2.117527504762014

Epoch: 5| Step: 9
Training loss: 2.3511877059936523
Validation loss: 2.120027373234431

Epoch: 5| Step: 10
Training loss: 2.470268964767456
Validation loss: 2.114512880643209

Epoch: 5| Step: 11
Training loss: 2.029529094696045
Validation loss: 2.093024959166845

Epoch: 45| Step: 0
Training loss: 1.4868485927581787
Validation loss: 2.111027548710505

Epoch: 5| Step: 1
Training loss: 2.3639912605285645
Validation loss: 2.0885309477647147

Epoch: 5| Step: 2
Training loss: 2.164278030395508
Validation loss: 2.1126543283462524

Epoch: 5| Step: 3
Training loss: 1.6079394817352295
Validation loss: 2.0965679585933685

Epoch: 5| Step: 4
Training loss: 2.0366852283477783
Validation loss: 2.1045848379532495

Epoch: 5| Step: 5
Training loss: 2.070349931716919
Validation loss: 2.1275717963775

Epoch: 5| Step: 6
Training loss: 1.8692700862884521
Validation loss: 2.1085940450429916

Epoch: 5| Step: 7
Training loss: 2.3261606693267822
Validation loss: 2.108040908972422

Epoch: 5| Step: 8
Training loss: 2.113140106201172
Validation loss: 2.1297784397999444

Epoch: 5| Step: 9
Training loss: 2.2502875328063965
Validation loss: 2.116431877017021

Epoch: 5| Step: 10
Training loss: 2.3404603004455566
Validation loss: 2.1159556061029434

Epoch: 5| Step: 11
Training loss: 2.3196520805358887
Validation loss: 2.1198728481928506

Epoch: 46| Step: 0
Training loss: 1.5784534215927124
Validation loss: 2.1156023740768433

Epoch: 5| Step: 1
Training loss: 2.1729443073272705
Validation loss: 2.0962446182966232

Epoch: 5| Step: 2
Training loss: 1.6434978246688843
Validation loss: 2.0897559920946756

Epoch: 5| Step: 3
Training loss: 2.5560824871063232
Validation loss: 2.0995635290940604

Epoch: 5| Step: 4
Training loss: 2.318495750427246
Validation loss: 2.102719783782959

Epoch: 5| Step: 5
Training loss: 1.9316227436065674
Validation loss: 2.0778882056474686

Epoch: 5| Step: 6
Training loss: 1.9417709112167358
Validation loss: 2.114014595746994

Epoch: 5| Step: 7
Training loss: 1.8228123188018799
Validation loss: 2.123492414752642

Epoch: 5| Step: 8
Training loss: 1.8219707012176514
Validation loss: 2.1099006136258445

Epoch: 5| Step: 9
Training loss: 1.8001620769500732
Validation loss: 2.1573812613884606

Epoch: 5| Step: 10
Training loss: 2.472987174987793
Validation loss: 2.1722193211317062

Epoch: 5| Step: 11
Training loss: 1.37819242477417
Validation loss: 2.1622116565704346

Epoch: 47| Step: 0
Training loss: 2.2090137004852295
Validation loss: 2.1737034817536673

Epoch: 5| Step: 1
Training loss: 2.1144914627075195
Validation loss: 2.1610560913880668

Epoch: 5| Step: 2
Training loss: 1.9354530572891235
Validation loss: 2.1669486661752067

Epoch: 5| Step: 3
Training loss: 1.1861321926116943
Validation loss: 2.157160460948944

Epoch: 5| Step: 4
Training loss: 2.1239020824432373
Validation loss: 2.155632028977076

Epoch: 5| Step: 5
Training loss: 1.9279117584228516
Validation loss: 2.101362665494283

Epoch: 5| Step: 6
Training loss: 1.9912738800048828
Validation loss: 2.103138506412506

Epoch: 5| Step: 7
Training loss: 1.6685149669647217
Validation loss: 2.1077612787485123

Epoch: 5| Step: 8
Training loss: 2.8906362056732178
Validation loss: 2.0913121104240417

Epoch: 5| Step: 9
Training loss: 2.4690988063812256
Validation loss: 2.0869766672452292

Epoch: 5| Step: 10
Training loss: 1.774287462234497
Validation loss: 2.0955803940693536

Epoch: 5| Step: 11
Training loss: 0.9079858064651489
Validation loss: 2.0808518131573996

Epoch: 48| Step: 0
Training loss: 1.8391697406768799
Validation loss: 2.0861308375994363

Epoch: 5| Step: 1
Training loss: 2.21822452545166
Validation loss: 2.0822761207818985

Epoch: 5| Step: 2
Training loss: 2.4076602458953857
Validation loss: 2.1104828218619027

Epoch: 5| Step: 3
Training loss: 1.7698434591293335
Validation loss: 2.126898874839147

Epoch: 5| Step: 4
Training loss: 2.4780097007751465
Validation loss: 2.0910502821207047

Epoch: 5| Step: 5
Training loss: 2.054124593734741
Validation loss: 2.0826788246631622

Epoch: 5| Step: 6
Training loss: 2.291830539703369
Validation loss: 2.0922614336013794

Epoch: 5| Step: 7
Training loss: 1.5948362350463867
Validation loss: 2.0807955960432687

Epoch: 5| Step: 8
Training loss: 1.899092435836792
Validation loss: 2.0659607152144113

Epoch: 5| Step: 9
Training loss: 1.9635112285614014
Validation loss: 2.0846735636393228

Epoch: 5| Step: 10
Training loss: 1.6402565240859985
Validation loss: 2.072615404923757

Epoch: 5| Step: 11
Training loss: 1.795265793800354
Validation loss: 2.095608835419019

Epoch: 49| Step: 0
Training loss: 2.3140439987182617
Validation loss: 2.0673230439424515

Epoch: 5| Step: 1
Training loss: 1.8673375844955444
Validation loss: 2.0931653678417206

Epoch: 5| Step: 2
Training loss: 2.2136731147766113
Validation loss: 2.0929289062817893

Epoch: 5| Step: 3
Training loss: 2.0377910137176514
Validation loss: 2.0998261272907257

Epoch: 5| Step: 4
Training loss: 1.4420961141586304
Validation loss: 2.101256420214971

Epoch: 5| Step: 5
Training loss: 2.0153253078460693
Validation loss: 2.0916857024033866

Epoch: 5| Step: 6
Training loss: 1.4972119331359863
Validation loss: 2.0840268234411874

Epoch: 5| Step: 7
Training loss: 1.7061576843261719
Validation loss: 2.1066488325595856

Epoch: 5| Step: 8
Training loss: 2.2068874835968018
Validation loss: 2.0800280471642814

Epoch: 5| Step: 9
Training loss: 2.311152935028076
Validation loss: 2.1133570869763694

Epoch: 5| Step: 10
Training loss: 2.303772449493408
Validation loss: 2.1144012908140817

Epoch: 5| Step: 11
Training loss: 1.35121488571167
Validation loss: 2.0973332275946936

Epoch: 50| Step: 0
Training loss: 2.0048890113830566
Validation loss: 2.128727525472641

Epoch: 5| Step: 1
Training loss: 1.9580090045928955
Validation loss: 2.100527892510096

Epoch: 5| Step: 2
Training loss: 2.3648505210876465
Validation loss: 2.1184334953626

Epoch: 5| Step: 3
Training loss: 2.362067222595215
Validation loss: 2.1227548321088157

Epoch: 5| Step: 4
Training loss: 1.3172752857208252
Validation loss: 2.1172483215729394

Epoch: 5| Step: 5
Training loss: 2.247403383255005
Validation loss: 2.1246539851029715

Epoch: 5| Step: 6
Training loss: 2.27099609375
Validation loss: 2.113383491834005

Epoch: 5| Step: 7
Training loss: 1.6163547039031982
Validation loss: 2.11810169617335

Epoch: 5| Step: 8
Training loss: 1.8008941411972046
Validation loss: 2.101765831311544

Epoch: 5| Step: 9
Training loss: 1.9646015167236328
Validation loss: 2.0899879237016044

Epoch: 5| Step: 10
Training loss: 1.8845813274383545
Validation loss: 2.1021810869375863

Epoch: 5| Step: 11
Training loss: 3.0943992137908936
Validation loss: 2.081261694431305

Epoch: 51| Step: 0
Training loss: 2.260213851928711
Validation loss: 2.090982715288798

Epoch: 5| Step: 1
Training loss: 1.7155059576034546
Validation loss: 2.0903948644797006

Epoch: 5| Step: 2
Training loss: 1.8157564401626587
Validation loss: 2.080143555998802

Epoch: 5| Step: 3
Training loss: 2.1023945808410645
Validation loss: 2.0786362985769906

Epoch: 5| Step: 4
Training loss: 2.3145155906677246
Validation loss: 2.1040484656890235

Epoch: 5| Step: 5
Training loss: 2.201672315597534
Validation loss: 2.0876363764206567

Epoch: 5| Step: 6
Training loss: 2.215355396270752
Validation loss: 2.0872743725776672

Epoch: 5| Step: 7
Training loss: 1.8259069919586182
Validation loss: 2.0728843907515206

Epoch: 5| Step: 8
Training loss: 1.909217119216919
Validation loss: 2.1047156701485314

Epoch: 5| Step: 9
Training loss: 1.741233229637146
Validation loss: 2.097262437144915

Epoch: 5| Step: 10
Training loss: 1.987146019935608
Validation loss: 2.087902178366979

Epoch: 5| Step: 11
Training loss: 1.5499095916748047
Validation loss: 2.093885526061058

Epoch: 52| Step: 0
Training loss: 2.257300853729248
Validation loss: 2.043152074019114

Epoch: 5| Step: 1
Training loss: 1.8587671518325806
Validation loss: 2.0818235079447427

Epoch: 5| Step: 2
Training loss: 1.9375625848770142
Validation loss: 2.077165345350901

Epoch: 5| Step: 3
Training loss: 2.6364474296569824
Validation loss: 2.0690722266832986

Epoch: 5| Step: 4
Training loss: 1.8128515481948853
Validation loss: 2.07987242937088

Epoch: 5| Step: 5
Training loss: 1.7743823528289795
Validation loss: 2.086075762907664

Epoch: 5| Step: 6
Training loss: 1.7790504693984985
Validation loss: 2.0726200292507806

Epoch: 5| Step: 7
Training loss: 1.4710235595703125
Validation loss: 2.097138454516729

Epoch: 5| Step: 8
Training loss: 2.180474042892456
Validation loss: 2.116246114174525

Epoch: 5| Step: 9
Training loss: 1.9315265417099
Validation loss: 2.1141993751128516

Epoch: 5| Step: 10
Training loss: 1.8085482120513916
Validation loss: 2.100616996486982

Epoch: 5| Step: 11
Training loss: 2.5095698833465576
Validation loss: 2.1492972324291864

Epoch: 53| Step: 0
Training loss: 1.9002068042755127
Validation loss: 2.119338408112526

Epoch: 5| Step: 1
Training loss: 1.7104257345199585
Validation loss: 2.1258582770824432

Epoch: 5| Step: 2
Training loss: 2.3347671031951904
Validation loss: 2.1156495859225593

Epoch: 5| Step: 3
Training loss: 2.101475715637207
Validation loss: 2.1562241117159524

Epoch: 5| Step: 4
Training loss: 2.411355972290039
Validation loss: 2.133777270714442

Epoch: 5| Step: 5
Training loss: 1.7752392292022705
Validation loss: 2.1244773169358573

Epoch: 5| Step: 6
Training loss: 1.7750908136367798
Validation loss: 2.135516256093979

Epoch: 5| Step: 7
Training loss: 2.0726497173309326
Validation loss: 2.112868602077166

Epoch: 5| Step: 8
Training loss: 1.657223105430603
Validation loss: 2.11648199458917

Epoch: 5| Step: 9
Training loss: 2.4789576530456543
Validation loss: 2.1021117667357125

Epoch: 5| Step: 10
Training loss: 1.4460532665252686
Validation loss: 2.0991209348042807

Epoch: 5| Step: 11
Training loss: 3.364530086517334
Validation loss: 2.087762917081515

Epoch: 54| Step: 0
Training loss: 2.3375437259674072
Validation loss: 2.0741499165693917

Epoch: 5| Step: 1
Training loss: 1.6982460021972656
Validation loss: 2.081260030468305

Epoch: 5| Step: 2
Training loss: 1.8541616201400757
Validation loss: 2.0931251297394433

Epoch: 5| Step: 3
Training loss: 2.508779287338257
Validation loss: 2.087906320889791

Epoch: 5| Step: 4
Training loss: 1.86569082736969
Validation loss: 2.0849190652370453

Epoch: 5| Step: 5
Training loss: 1.7072219848632812
Validation loss: 2.0860791355371475

Epoch: 5| Step: 6
Training loss: 1.7464174032211304
Validation loss: 2.0591633915901184

Epoch: 5| Step: 7
Training loss: 2.110142946243286
Validation loss: 2.100926955540975

Epoch: 5| Step: 8
Training loss: 1.6150983572006226
Validation loss: 2.071512093146642

Epoch: 5| Step: 9
Training loss: 2.2891712188720703
Validation loss: 2.0911586582660675

Epoch: 5| Step: 10
Training loss: 2.077803373336792
Validation loss: 2.100366855661074

Epoch: 5| Step: 11
Training loss: 2.807055950164795
Validation loss: 2.085036506255468

Epoch: 55| Step: 0
Training loss: 2.004626750946045
Validation loss: 2.068861852089564

Epoch: 5| Step: 1
Training loss: 2.3801846504211426
Validation loss: 2.0459375381469727

Epoch: 5| Step: 2
Training loss: 1.5441844463348389
Validation loss: 2.0697761178016663

Epoch: 5| Step: 3
Training loss: 2.437516212463379
Validation loss: 2.054034799337387

Epoch: 5| Step: 4
Training loss: 1.7159286737442017
Validation loss: 2.08328939974308

Epoch: 5| Step: 5
Training loss: 1.900526762008667
Validation loss: 2.074668144186338

Epoch: 5| Step: 6
Training loss: 2.0017313957214355
Validation loss: 2.0881575544675193

Epoch: 5| Step: 7
Training loss: 1.9647737741470337
Validation loss: 2.0544281204541526

Epoch: 5| Step: 8
Training loss: 1.781132459640503
Validation loss: 2.078322798013687

Epoch: 5| Step: 9
Training loss: 2.4482202529907227
Validation loss: 2.0794948438803353

Epoch: 5| Step: 10
Training loss: 1.9463088512420654
Validation loss: 2.0818276504675546

Epoch: 5| Step: 11
Training loss: 1.405907154083252
Validation loss: 2.07093678911527

Epoch: 56| Step: 0
Training loss: 1.865283727645874
Validation loss: 2.0891740769147873

Epoch: 5| Step: 1
Training loss: 2.158644914627075
Validation loss: 2.1024889846642814

Epoch: 5| Step: 2
Training loss: 1.886705756187439
Validation loss: 2.0933778832356134

Epoch: 5| Step: 3
Training loss: 2.0756492614746094
Validation loss: 2.131981318195661

Epoch: 5| Step: 4
Training loss: 1.4462978839874268
Validation loss: 2.148476163546244

Epoch: 5| Step: 5
Training loss: 1.7087682485580444
Validation loss: 2.147205730279287

Epoch: 5| Step: 6
Training loss: 2.9141457080841064
Validation loss: 2.1575366954008737

Epoch: 5| Step: 7
Training loss: 2.036487340927124
Validation loss: 2.183183431625366

Epoch: 5| Step: 8
Training loss: 2.103180408477783
Validation loss: 2.134859159588814

Epoch: 5| Step: 9
Training loss: 2.098311424255371
Validation loss: 2.1347072571516037

Epoch: 5| Step: 10
Training loss: 1.7739880084991455
Validation loss: 2.1180705626805625

Epoch: 5| Step: 11
Training loss: 2.569465160369873
Validation loss: 2.1284480641285577

Epoch: 57| Step: 0
Training loss: 1.9580800533294678
Validation loss: 2.0992186019817987

Epoch: 5| Step: 1
Training loss: 1.8452873229980469
Validation loss: 2.0931430657704673

Epoch: 5| Step: 2
Training loss: 1.966138243675232
Validation loss: 2.0768922666708627

Epoch: 5| Step: 3
Training loss: 2.044006586074829
Validation loss: 2.0462911625703177

Epoch: 5| Step: 4
Training loss: 2.4919705390930176
Validation loss: 2.0706318517525992

Epoch: 5| Step: 5
Training loss: 1.7529093027114868
Validation loss: 2.0792216012875238

Epoch: 5| Step: 6
Training loss: 1.7586116790771484
Validation loss: 2.0978066474199295

Epoch: 5| Step: 7
Training loss: 1.3436310291290283
Validation loss: 2.0954926858345666

Epoch: 5| Step: 8
Training loss: 2.4130334854125977
Validation loss: 2.0805599937836328

Epoch: 5| Step: 9
Training loss: 2.0823957920074463
Validation loss: 2.0646418233712516

Epoch: 5| Step: 10
Training loss: 2.347388744354248
Validation loss: 2.0927622665961585

Epoch: 5| Step: 11
Training loss: 1.6684622764587402
Validation loss: 2.0850733617941537

Epoch: 58| Step: 0
Training loss: 1.9133532047271729
Validation loss: 2.1017549137274423

Epoch: 5| Step: 1
Training loss: 1.9956867694854736
Validation loss: 2.065265397230784

Epoch: 5| Step: 2
Training loss: 1.8016369342803955
Validation loss: 2.091399922966957

Epoch: 5| Step: 3
Training loss: 1.8473777770996094
Validation loss: 2.0674739331007004

Epoch: 5| Step: 4
Training loss: 2.2098793983459473
Validation loss: 2.067069113254547

Epoch: 5| Step: 5
Training loss: 1.7496836185455322
Validation loss: 2.076708351572355

Epoch: 5| Step: 6
Training loss: 1.8281707763671875
Validation loss: 2.0677101463079453

Epoch: 5| Step: 7
Training loss: 1.8312448263168335
Validation loss: 2.0780364871025085

Epoch: 5| Step: 8
Training loss: 2.101585865020752
Validation loss: 2.0662142684062323

Epoch: 5| Step: 9
Training loss: 2.2593672275543213
Validation loss: 2.055325840910276

Epoch: 5| Step: 10
Training loss: 2.0184521675109863
Validation loss: 2.0900959571202598

Epoch: 5| Step: 11
Training loss: 2.2589452266693115
Validation loss: 2.0935488690932593

Epoch: 59| Step: 0
Training loss: 1.789575219154358
Validation loss: 2.1092208474874496

Epoch: 5| Step: 1
Training loss: 2.404226779937744
Validation loss: 2.1146648625532785

Epoch: 5| Step: 2
Training loss: 1.946349859237671
Validation loss: 2.1698365012804666

Epoch: 5| Step: 3
Training loss: 1.6633384227752686
Validation loss: 2.0996755262215934

Epoch: 5| Step: 4
Training loss: 2.123210906982422
Validation loss: 2.136352946360906

Epoch: 5| Step: 5
Training loss: 2.0276105403900146
Validation loss: 2.14340707163016

Epoch: 5| Step: 6
Training loss: 1.613252878189087
Validation loss: 2.112195923924446

Epoch: 5| Step: 7
Training loss: 2.2640368938446045
Validation loss: 2.1022404929002128

Epoch: 5| Step: 8
Training loss: 1.9125471115112305
Validation loss: 2.0784780085086823

Epoch: 5| Step: 9
Training loss: 2.0281853675842285
Validation loss: 2.0954599380493164

Epoch: 5| Step: 10
Training loss: 2.3529467582702637
Validation loss: 2.082808176676432

Epoch: 5| Step: 11
Training loss: 0.8617031574249268
Validation loss: 2.0832992494106293

Epoch: 60| Step: 0
Training loss: 2.256932020187378
Validation loss: 2.107622375090917

Epoch: 5| Step: 1
Training loss: 1.2273205518722534
Validation loss: 2.0941938161849976

Epoch: 5| Step: 2
Training loss: 2.0300304889678955
Validation loss: 2.1055211623509726

Epoch: 5| Step: 3
Training loss: 1.9317394495010376
Validation loss: 2.1065683712561927

Epoch: 5| Step: 4
Training loss: 2.112285614013672
Validation loss: 2.105679372946421

Epoch: 5| Step: 5
Training loss: 2.8987433910369873
Validation loss: 2.11864697933197

Epoch: 5| Step: 6
Training loss: 1.6225650310516357
Validation loss: 2.1241230020920434

Epoch: 5| Step: 7
Training loss: 1.8804935216903687
Validation loss: 2.1322710116704306

Epoch: 5| Step: 8
Training loss: 1.7773234844207764
Validation loss: 2.1253762245178223

Epoch: 5| Step: 9
Training loss: 1.7016851902008057
Validation loss: 2.112713729341825

Epoch: 5| Step: 10
Training loss: 2.4908106327056885
Validation loss: 2.0949263920386634

Epoch: 5| Step: 11
Training loss: 1.2197345495224
Validation loss: 2.106500352422396

Epoch: 61| Step: 0
Training loss: 2.3150768280029297
Validation loss: 2.0901656250158944

Epoch: 5| Step: 1
Training loss: 2.2546794414520264
Validation loss: 2.067084620396296

Epoch: 5| Step: 2
Training loss: 2.4079105854034424
Validation loss: 2.068444083134333

Epoch: 5| Step: 3
Training loss: 1.886397361755371
Validation loss: 2.070693622032801

Epoch: 5| Step: 4
Training loss: 1.4576694965362549
Validation loss: 2.07275328040123

Epoch: 5| Step: 5
Training loss: 1.2882249355316162
Validation loss: 2.064034710327784

Epoch: 5| Step: 6
Training loss: 2.105875253677368
Validation loss: 2.0702885737021766

Epoch: 5| Step: 7
Training loss: 1.5814927816390991
Validation loss: 2.0719257046779

Epoch: 5| Step: 8
Training loss: 2.554783582687378
Validation loss: 2.0724741170803704

Epoch: 5| Step: 9
Training loss: 2.152164936065674
Validation loss: 2.0868983964125314

Epoch: 5| Step: 10
Training loss: 2.007333278656006
Validation loss: 2.090036710103353

Epoch: 5| Step: 11
Training loss: 1.5301916599273682
Validation loss: 2.068120782574018

Epoch: 62| Step: 0
Training loss: 1.9326398372650146
Validation loss: 2.07053575416406

Epoch: 5| Step: 1
Training loss: 1.3427603244781494
Validation loss: 2.0648182034492493

Epoch: 5| Step: 2
Training loss: 1.5660312175750732
Validation loss: 2.062137320637703

Epoch: 5| Step: 3
Training loss: 2.021307945251465
Validation loss: 2.0594319800535836

Epoch: 5| Step: 4
Training loss: 2.028686046600342
Validation loss: 2.070654427011808

Epoch: 5| Step: 5
Training loss: 1.798219084739685
Validation loss: 2.0877296030521393

Epoch: 5| Step: 6
Training loss: 1.4902371168136597
Validation loss: 2.089379921555519

Epoch: 5| Step: 7
Training loss: 2.7004218101501465
Validation loss: 2.1072472482919693

Epoch: 5| Step: 8
Training loss: 1.4695899486541748
Validation loss: 2.089955359697342

Epoch: 5| Step: 9
Training loss: 2.6740450859069824
Validation loss: 2.1423864414294562

Epoch: 5| Step: 10
Training loss: 2.8334364891052246
Validation loss: 2.145098110040029

Epoch: 5| Step: 11
Training loss: 1.3136932849884033
Validation loss: 2.1625475883483887

Epoch: 63| Step: 0
Training loss: 1.6103527545928955
Validation loss: 2.1555773417154946

Epoch: 5| Step: 1
Training loss: 1.6829757690429688
Validation loss: 2.1414225002129874

Epoch: 5| Step: 2
Training loss: 2.492748498916626
Validation loss: 2.1405148804187775

Epoch: 5| Step: 3
Training loss: 1.7625993490219116
Validation loss: 2.1471136758724847

Epoch: 5| Step: 4
Training loss: 1.66975998878479
Validation loss: 2.130893051624298

Epoch: 5| Step: 5
Training loss: 1.9231408834457397
Validation loss: 2.1092929442723594

Epoch: 5| Step: 6
Training loss: 2.230191230773926
Validation loss: 2.109850654999415

Epoch: 5| Step: 7
Training loss: 1.887495994567871
Validation loss: 2.0903903047243753

Epoch: 5| Step: 8
Training loss: 1.751788854598999
Validation loss: 2.078243523836136

Epoch: 5| Step: 9
Training loss: 1.6935317516326904
Validation loss: 2.088739891846975

Epoch: 5| Step: 10
Training loss: 2.900500535964966
Validation loss: 2.064016396800677

Epoch: 5| Step: 11
Training loss: 1.5876339673995972
Validation loss: 2.0710747440656028

Epoch: 64| Step: 0
Training loss: 2.246572971343994
Validation loss: 2.0600781540075936

Epoch: 5| Step: 1
Training loss: 2.1076722145080566
Validation loss: 2.078019440174103

Epoch: 5| Step: 2
Training loss: 1.613136649131775
Validation loss: 2.0687321921189628

Epoch: 5| Step: 3
Training loss: 2.2162654399871826
Validation loss: 2.0902933279673257

Epoch: 5| Step: 4
Training loss: 2.3024349212646484
Validation loss: 2.0719571063915887

Epoch: 5| Step: 5
Training loss: 1.138519287109375
Validation loss: 2.092566505074501

Epoch: 5| Step: 6
Training loss: 1.694085717201233
Validation loss: 2.0747761030991874

Epoch: 5| Step: 7
Training loss: 2.731046438217163
Validation loss: 2.0908552507559457

Epoch: 5| Step: 8
Training loss: 1.5085700750350952
Validation loss: 2.058118606607119

Epoch: 5| Step: 9
Training loss: 1.5382544994354248
Validation loss: 2.082820415496826

Epoch: 5| Step: 10
Training loss: 2.4985673427581787
Validation loss: 2.077283894022306

Epoch: 5| Step: 11
Training loss: 2.4111599922180176
Validation loss: 2.102356255054474

Epoch: 65| Step: 0
Training loss: 1.943872094154358
Validation loss: 2.0680862168471017

Epoch: 5| Step: 1
Training loss: 1.8648185729980469
Validation loss: 2.091821332772573

Epoch: 5| Step: 2
Training loss: 1.8130950927734375
Validation loss: 2.085722873608271

Epoch: 5| Step: 3
Training loss: 1.678480863571167
Validation loss: 2.0905233124891915

Epoch: 5| Step: 4
Training loss: 1.7523510456085205
Validation loss: 2.1159797310829163

Epoch: 5| Step: 5
Training loss: 2.1458258628845215
Validation loss: 2.1191083739201226

Epoch: 5| Step: 6
Training loss: 2.0040130615234375
Validation loss: 2.1180268973112106

Epoch: 5| Step: 7
Training loss: 2.0822365283966064
Validation loss: 2.1240106374025345

Epoch: 5| Step: 8
Training loss: 2.1064674854278564
Validation loss: 2.139370580514272

Epoch: 5| Step: 9
Training loss: 2.235673427581787
Validation loss: 2.115140880147616

Epoch: 5| Step: 10
Training loss: 2.1087443828582764
Validation loss: 2.1037923445304236

Epoch: 5| Step: 11
Training loss: 1.9477041959762573
Validation loss: 2.1152010560035706

Epoch: 66| Step: 0
Training loss: 2.1678459644317627
Validation loss: 2.0958633373181024

Epoch: 5| Step: 1
Training loss: 1.762314796447754
Validation loss: 2.076253225406011

Epoch: 5| Step: 2
Training loss: 1.9682849645614624
Validation loss: 2.086271603902181

Epoch: 5| Step: 3
Training loss: 2.019186019897461
Validation loss: 2.0943352033694587

Epoch: 5| Step: 4
Training loss: 1.3908380270004272
Validation loss: 2.0669903109471

Epoch: 5| Step: 5
Training loss: 2.2637736797332764
Validation loss: 2.072109411160151

Epoch: 5| Step: 6
Training loss: 2.035285711288452
Validation loss: 2.1059856514135995

Epoch: 5| Step: 7
Training loss: 1.926845908164978
Validation loss: 2.0692457258701324

Epoch: 5| Step: 8
Training loss: 2.7557501792907715
Validation loss: 2.0795230170090995

Epoch: 5| Step: 9
Training loss: 1.7164446115493774
Validation loss: 2.070429573456446

Epoch: 5| Step: 10
Training loss: 1.7367057800292969
Validation loss: 2.09059010942777

Epoch: 5| Step: 11
Training loss: 1.04579496383667
Validation loss: 2.0781575590372086

Epoch: 67| Step: 0
Training loss: 2.5818426609039307
Validation loss: 2.0598148504892984

Epoch: 5| Step: 1
Training loss: 2.041922092437744
Validation loss: 2.0733537822961807

Epoch: 5| Step: 2
Training loss: 1.875054121017456
Validation loss: 2.0782040605942407

Epoch: 5| Step: 3
Training loss: 1.5790094137191772
Validation loss: 2.058889995018641

Epoch: 5| Step: 4
Training loss: 2.127781391143799
Validation loss: 2.0977624555428824

Epoch: 5| Step: 5
Training loss: 1.475799798965454
Validation loss: 2.0602644085884094

Epoch: 5| Step: 6
Training loss: 1.865729570388794
Validation loss: 2.0785948087771735

Epoch: 5| Step: 7
Training loss: 1.5449283123016357
Validation loss: 2.077979857722918

Epoch: 5| Step: 8
Training loss: 2.2505972385406494
Validation loss: 2.069057881832123

Epoch: 5| Step: 9
Training loss: 1.9240894317626953
Validation loss: 2.0958045522371926

Epoch: 5| Step: 10
Training loss: 2.1613101959228516
Validation loss: 2.0802575002113977

Epoch: 5| Step: 11
Training loss: 2.909834861755371
Validation loss: 2.1055777966976166

Epoch: 68| Step: 0
Training loss: 1.7633733749389648
Validation loss: 2.0868447522322335

Epoch: 5| Step: 1
Training loss: 2.7513272762298584
Validation loss: 2.123340661327044

Epoch: 5| Step: 2
Training loss: 1.7259973287582397
Validation loss: 2.115012134114901

Epoch: 5| Step: 3
Training loss: 1.6667464971542358
Validation loss: 2.111324225862821

Epoch: 5| Step: 4
Training loss: 2.3736019134521484
Validation loss: 2.101219654083252

Epoch: 5| Step: 5
Training loss: 1.8058754205703735
Validation loss: 2.1114627371231713

Epoch: 5| Step: 6
Training loss: 1.8782052993774414
Validation loss: 2.0840882460276284

Epoch: 5| Step: 7
Training loss: 1.8820549249649048
Validation loss: 2.088392679889997

Epoch: 5| Step: 8
Training loss: 2.5563509464263916
Validation loss: 2.0890470842520394

Epoch: 5| Step: 9
Training loss: 2.2524938583374023
Validation loss: 2.08513306081295

Epoch: 5| Step: 10
Training loss: 0.9305734634399414
Validation loss: 2.0939944038788476

Epoch: 5| Step: 11
Training loss: 1.2773855924606323
Validation loss: 2.067988524834315

Epoch: 69| Step: 0
Training loss: 2.3026323318481445
Validation loss: 2.1013861348231635

Epoch: 5| Step: 1
Training loss: 1.6780086755752563
Validation loss: 2.0510477175315223

Epoch: 5| Step: 2
Training loss: 1.5559642314910889
Validation loss: 2.1106719970703125

Epoch: 5| Step: 3
Training loss: 1.8219505548477173
Validation loss: 2.1036012123028436

Epoch: 5| Step: 4
Training loss: 1.9281202554702759
Validation loss: 2.112479731440544

Epoch: 5| Step: 5
Training loss: 1.8705501556396484
Validation loss: 2.1197519352038703

Epoch: 5| Step: 6
Training loss: 2.5944764614105225
Validation loss: 2.1221784253915152

Epoch: 5| Step: 7
Training loss: 2.0262062549591064
Validation loss: 2.1133503963549933

Epoch: 5| Step: 8
Training loss: 2.0450613498687744
Validation loss: 2.12303996582826

Epoch: 5| Step: 9
Training loss: 1.439450740814209
Validation loss: 2.1061160365740457

Epoch: 5| Step: 10
Training loss: 2.152905225753784
Validation loss: 2.0685040603081384

Epoch: 5| Step: 11
Training loss: 2.388456344604492
Validation loss: 2.0964861512184143

Epoch: 70| Step: 0
Training loss: 1.9939613342285156
Validation loss: 2.0720715324083963

Epoch: 5| Step: 1
Training loss: 2.3299503326416016
Validation loss: 2.075441539287567

Epoch: 5| Step: 2
Training loss: 2.1080098152160645
Validation loss: 2.05459896226724

Epoch: 5| Step: 3
Training loss: 2.0741477012634277
Validation loss: 2.074268341064453

Epoch: 5| Step: 4
Training loss: 1.4747564792633057
Validation loss: 2.0858955532312393

Epoch: 5| Step: 5
Training loss: 2.1445462703704834
Validation loss: 2.0852238833904266

Epoch: 5| Step: 6
Training loss: 0.9937852621078491
Validation loss: 2.0907410830259323

Epoch: 5| Step: 7
Training loss: 2.15278697013855
Validation loss: 2.0715523064136505

Epoch: 5| Step: 8
Training loss: 2.0056700706481934
Validation loss: 2.0928163280089698

Epoch: 5| Step: 9
Training loss: 2.5266566276550293
Validation loss: 2.0557538022597632

Epoch: 5| Step: 10
Training loss: 2.200185775756836
Validation loss: 2.099899505575498

Epoch: 5| Step: 11
Training loss: 1.8427215814590454
Validation loss: 2.0601771771907806

Epoch: 71| Step: 0
Training loss: 1.6253677606582642
Validation loss: 2.074851075808207

Epoch: 5| Step: 1
Training loss: 1.8244664669036865
Validation loss: 2.0657604932785034

Epoch: 5| Step: 2
Training loss: 1.845343828201294
Validation loss: 2.049309333165487

Epoch: 5| Step: 3
Training loss: 1.2790671586990356
Validation loss: 2.1046394606431327

Epoch: 5| Step: 4
Training loss: 2.180560350418091
Validation loss: 2.1133268624544144

Epoch: 5| Step: 5
Training loss: 2.0100817680358887
Validation loss: 2.113407110174497

Epoch: 5| Step: 6
Training loss: 2.096827268600464
Validation loss: 2.1228003054857254

Epoch: 5| Step: 7
Training loss: 2.237802267074585
Validation loss: 2.147674858570099

Epoch: 5| Step: 8
Training loss: 1.9161694049835205
Validation loss: 2.137490118543307

Epoch: 5| Step: 9
Training loss: 1.9907182455062866
Validation loss: 2.14742319782575

Epoch: 5| Step: 10
Training loss: 2.8483824729919434
Validation loss: 2.160251870751381

Epoch: 5| Step: 11
Training loss: 1.9801077842712402
Validation loss: 2.1382270654042563

Epoch: 72| Step: 0
Training loss: 1.7568531036376953
Validation loss: 2.117793227235476

Epoch: 5| Step: 1
Training loss: 2.528031826019287
Validation loss: 2.115467349688212

Epoch: 5| Step: 2
Training loss: 2.3898966312408447
Validation loss: 2.108270322283109

Epoch: 5| Step: 3
Training loss: 1.3669220209121704
Validation loss: 2.1030156960090003

Epoch: 5| Step: 4
Training loss: 1.7345821857452393
Validation loss: 2.0741818894942603

Epoch: 5| Step: 5
Training loss: 2.0697827339172363
Validation loss: 2.071848769982656

Epoch: 5| Step: 6
Training loss: 1.4540421962738037
Validation loss: 2.0721999456485114

Epoch: 5| Step: 7
Training loss: 1.708078384399414
Validation loss: 2.045939559737841

Epoch: 5| Step: 8
Training loss: 1.9746402502059937
Validation loss: 2.0714083313941956

Epoch: 5| Step: 9
Training loss: 2.2235310077667236
Validation loss: 2.0891883224248886

Epoch: 5| Step: 10
Training loss: 2.0673987865448
Validation loss: 2.0551929473876953

Epoch: 5| Step: 11
Training loss: 1.9857312440872192
Validation loss: 2.045480857292811

Epoch: 73| Step: 0
Training loss: 1.2875614166259766
Validation loss: 2.0665797044833503

Epoch: 5| Step: 1
Training loss: 2.4079623222351074
Validation loss: 2.061296592156092

Epoch: 5| Step: 2
Training loss: 2.321338176727295
Validation loss: 2.0788509945074716

Epoch: 5| Step: 3
Training loss: 2.120983123779297
Validation loss: 2.082014188170433

Epoch: 5| Step: 4
Training loss: 2.252398729324341
Validation loss: 2.08340755601724

Epoch: 5| Step: 5
Training loss: 1.9216228723526
Validation loss: 2.089514801899592

Epoch: 5| Step: 6
Training loss: 2.2822182178497314
Validation loss: 2.0834700961907706

Epoch: 5| Step: 7
Training loss: 1.6062030792236328
Validation loss: 2.074320157368978

Epoch: 5| Step: 8
Training loss: 1.4161412715911865
Validation loss: 2.0554684499899545

Epoch: 5| Step: 9
Training loss: 1.8863632678985596
Validation loss: 2.0635967502991357

Epoch: 5| Step: 10
Training loss: 2.1239497661590576
Validation loss: 2.1174916525681815

Epoch: 5| Step: 11
Training loss: 0.7694804668426514
Validation loss: 2.075590506196022

Epoch: 74| Step: 0
Training loss: 2.2397472858428955
Validation loss: 2.103022128343582

Epoch: 5| Step: 1
Training loss: 1.5203216075897217
Validation loss: 2.0874075889587402

Epoch: 5| Step: 2
Training loss: 2.1153664588928223
Validation loss: 2.0916215727726617

Epoch: 5| Step: 3
Training loss: 1.9611088037490845
Validation loss: 2.1122284134229026

Epoch: 5| Step: 4
Training loss: 2.3686158657073975
Validation loss: 2.104203090071678

Epoch: 5| Step: 5
Training loss: 1.903558373451233
Validation loss: 2.088841497898102

Epoch: 5| Step: 6
Training loss: 2.274937868118286
Validation loss: 2.074053779244423

Epoch: 5| Step: 7
Training loss: 1.8632736206054688
Validation loss: 2.0741331477959952

Epoch: 5| Step: 8
Training loss: 1.7148103713989258
Validation loss: 2.1039014210303626

Epoch: 5| Step: 9
Training loss: 2.255317211151123
Validation loss: 2.1013518969217935

Epoch: 5| Step: 10
Training loss: 1.4545948505401611
Validation loss: 2.10385433336099

Epoch: 5| Step: 11
Training loss: 0.7136048078536987
Validation loss: 2.0850407977898917

Epoch: 75| Step: 0
Training loss: 1.5100679397583008
Validation loss: 2.077226758003235

Epoch: 5| Step: 1
Training loss: 1.7806915044784546
Validation loss: 2.074510042866071

Epoch: 5| Step: 2
Training loss: 1.6574628353118896
Validation loss: 2.067260737220446

Epoch: 5| Step: 3
Training loss: 2.1571202278137207
Validation loss: 2.0710279643535614

Epoch: 5| Step: 4
Training loss: 2.7121033668518066
Validation loss: 2.0733636717001596

Epoch: 5| Step: 5
Training loss: 1.6935694217681885
Validation loss: 2.063857927918434

Epoch: 5| Step: 6
Training loss: 2.072795867919922
Validation loss: 2.0763916124900184

Epoch: 5| Step: 7
Training loss: 1.8928951025009155
Validation loss: 2.064213832219442

Epoch: 5| Step: 8
Training loss: 2.234182119369507
Validation loss: 2.0853948344786963

Epoch: 5| Step: 9
Training loss: 1.5516088008880615
Validation loss: 2.0581564009189606

Epoch: 5| Step: 10
Training loss: 1.7611217498779297
Validation loss: 2.091305057207743

Epoch: 5| Step: 11
Training loss: 3.7296643257141113
Validation loss: 2.0633613963921866

Epoch: 76| Step: 0
Training loss: 2.436455249786377
Validation loss: 2.0827169567346573

Epoch: 5| Step: 1
Training loss: 1.580186128616333
Validation loss: 2.078709284464518

Epoch: 5| Step: 2
Training loss: 1.7740684747695923
Validation loss: 2.0589241733153663

Epoch: 5| Step: 3
Training loss: 1.945752501487732
Validation loss: 2.0729690988858542

Epoch: 5| Step: 4
Training loss: 2.0994369983673096
Validation loss: 2.069978584845861

Epoch: 5| Step: 5
Training loss: 2.0487701892852783
Validation loss: 2.0622070531050363

Epoch: 5| Step: 6
Training loss: 1.6276750564575195
Validation loss: 2.057104522983233

Epoch: 5| Step: 7
Training loss: 2.58992075920105
Validation loss: 2.043336937824885

Epoch: 5| Step: 8
Training loss: 1.9767545461654663
Validation loss: 2.047579606374105

Epoch: 5| Step: 9
Training loss: 1.840057611465454
Validation loss: 2.0666593809922538

Epoch: 5| Step: 10
Training loss: 1.5890130996704102
Validation loss: 2.0745584865411124

Epoch: 5| Step: 11
Training loss: 1.2886226177215576
Validation loss: 2.0638960699240365

Epoch: 77| Step: 0
Training loss: 2.1468701362609863
Validation loss: 2.0711877594391503

Epoch: 5| Step: 1
Training loss: 1.7583385705947876
Validation loss: 2.0900068332751593

Epoch: 5| Step: 2
Training loss: 1.886498212814331
Validation loss: 2.0786953568458557

Epoch: 5| Step: 3
Training loss: 2.4556777477264404
Validation loss: 2.0646887669960656

Epoch: 5| Step: 4
Training loss: 2.1670546531677246
Validation loss: 2.081225817402204

Epoch: 5| Step: 5
Training loss: 1.9325048923492432
Validation loss: 2.1020884613196054

Epoch: 5| Step: 6
Training loss: 1.7073997259140015
Validation loss: 2.1034404933452606

Epoch: 5| Step: 7
Training loss: 1.5536402463912964
Validation loss: 2.0995595504840217

Epoch: 5| Step: 8
Training loss: 2.0426151752471924
Validation loss: 2.10489913324515

Epoch: 5| Step: 9
Training loss: 2.1904256343841553
Validation loss: 2.093758155902227

Epoch: 5| Step: 10
Training loss: 1.9052501916885376
Validation loss: 2.124784121910731

Epoch: 5| Step: 11
Training loss: 1.1388007402420044
Validation loss: 2.1158114125331244

Epoch: 78| Step: 0
Training loss: 2.4050559997558594
Validation loss: 2.0870095044374466

Epoch: 5| Step: 1
Training loss: 1.5105359554290771
Validation loss: 2.097286805510521

Epoch: 5| Step: 2
Training loss: 1.8284080028533936
Validation loss: 2.0938155899445214

Epoch: 5| Step: 3
Training loss: 1.8708488941192627
Validation loss: 2.084722563624382

Epoch: 5| Step: 4
Training loss: 2.1836116313934326
Validation loss: 2.079062044620514

Epoch: 5| Step: 5
Training loss: 1.9933563470840454
Validation loss: 2.0981627702713013

Epoch: 5| Step: 6
Training loss: 1.8894459009170532
Validation loss: 2.0880296428998313

Epoch: 5| Step: 7
Training loss: 1.7396094799041748
Validation loss: 2.085071394840876

Epoch: 5| Step: 8
Training loss: 1.8502966165542603
Validation loss: 2.0481523921092353

Epoch: 5| Step: 9
Training loss: 2.148160457611084
Validation loss: 2.059086576104164

Epoch: 5| Step: 10
Training loss: 1.9554860591888428
Validation loss: 2.0629886190096536

Epoch: 5| Step: 11
Training loss: 1.6699879169464111
Validation loss: 2.0716032683849335

Epoch: 79| Step: 0
Training loss: 1.7899274826049805
Validation loss: 2.049815778930982

Epoch: 5| Step: 1
Training loss: 1.3599202632904053
Validation loss: 2.0656415124734244

Epoch: 5| Step: 2
Training loss: 1.6949913501739502
Validation loss: 2.0485537151495614

Epoch: 5| Step: 3
Training loss: 2.0198073387145996
Validation loss: 2.085488627354304

Epoch: 5| Step: 4
Training loss: 2.1007754802703857
Validation loss: 2.0600898464520774

Epoch: 5| Step: 5
Training loss: 1.7133296728134155
Validation loss: 2.0600178192059198

Epoch: 5| Step: 6
Training loss: 1.9920654296875
Validation loss: 2.083887909849485

Epoch: 5| Step: 7
Training loss: 2.7532033920288086
Validation loss: 2.066168690721194

Epoch: 5| Step: 8
Training loss: 2.108522415161133
Validation loss: 2.069724832971891

Epoch: 5| Step: 9
Training loss: 1.7568012475967407
Validation loss: 2.0912766655286155

Epoch: 5| Step: 10
Training loss: 2.4629580974578857
Validation loss: 2.071743369102478

Epoch: 5| Step: 11
Training loss: 1.1783478260040283
Validation loss: 2.070937400062879

Epoch: 80| Step: 0
Training loss: 2.310760974884033
Validation loss: 2.087126220266024

Epoch: 5| Step: 1
Training loss: 1.8434078693389893
Validation loss: 2.0695841113726297

Epoch: 5| Step: 2
Training loss: 2.2116198539733887
Validation loss: 2.0490823735793433

Epoch: 5| Step: 3
Training loss: 1.8997204303741455
Validation loss: 2.069649671514829

Epoch: 5| Step: 4
Training loss: 1.8481366634368896
Validation loss: 2.042133798201879

Epoch: 5| Step: 5
Training loss: 1.6040109395980835
Validation loss: 2.0796837409337363

Epoch: 5| Step: 6
Training loss: 1.8700129985809326
Validation loss: 2.0779957274595895

Epoch: 5| Step: 7
Training loss: 1.7309259176254272
Validation loss: 2.0882501552502313

Epoch: 5| Step: 8
Training loss: 1.6056560277938843
Validation loss: 2.091630553205808

Epoch: 5| Step: 9
Training loss: 2.1139583587646484
Validation loss: 2.1046884953975677

Epoch: 5| Step: 10
Training loss: 2.1827125549316406
Validation loss: 2.1266451627016068

Epoch: 5| Step: 11
Training loss: 2.8748176097869873
Validation loss: 2.10083769261837

Epoch: 81| Step: 0
Training loss: 2.1096858978271484
Validation loss: 2.0947316884994507

Epoch: 5| Step: 1
Training loss: 1.6581485271453857
Validation loss: 2.0867744584878287

Epoch: 5| Step: 2
Training loss: 2.217130661010742
Validation loss: 2.097828065355619

Epoch: 5| Step: 3
Training loss: 1.6470390558242798
Validation loss: 2.085307762026787

Epoch: 5| Step: 4
Training loss: 1.876098394393921
Validation loss: 2.0812662839889526

Epoch: 5| Step: 5
Training loss: 2.1046011447906494
Validation loss: 2.075960432489713

Epoch: 5| Step: 6
Training loss: 2.5117862224578857
Validation loss: 2.0783187548319497

Epoch: 5| Step: 7
Training loss: 1.7984386682510376
Validation loss: 2.0808057387669883

Epoch: 5| Step: 8
Training loss: 2.113124370574951
Validation loss: 2.0644504030545554

Epoch: 5| Step: 9
Training loss: 1.7046430110931396
Validation loss: 2.0841868966817856

Epoch: 5| Step: 10
Training loss: 1.545245885848999
Validation loss: 2.066455458601316

Epoch: 5| Step: 11
Training loss: 0.7955949902534485
Validation loss: 2.043419972062111

Epoch: 82| Step: 0
Training loss: 2.067819118499756
Validation loss: 2.05086442331473

Epoch: 5| Step: 1
Training loss: 1.5807212591171265
Validation loss: 2.052555878957113

Epoch: 5| Step: 2
Training loss: 1.6994094848632812
Validation loss: 2.07208580772082

Epoch: 5| Step: 3
Training loss: 2.1283392906188965
Validation loss: 2.053701172272364

Epoch: 5| Step: 4
Training loss: 2.255880355834961
Validation loss: 2.0700574268897376

Epoch: 5| Step: 5
Training loss: 1.6732755899429321
Validation loss: 2.064734091361364

Epoch: 5| Step: 6
Training loss: 2.221543788909912
Validation loss: 2.0298758347829184

Epoch: 5| Step: 7
Training loss: 2.8559370040893555
Validation loss: 2.0747747222582498

Epoch: 5| Step: 8
Training loss: 1.5460056066513062
Validation loss: 2.0765967865784964

Epoch: 5| Step: 9
Training loss: 2.1779441833496094
Validation loss: 2.06964144607385

Epoch: 5| Step: 10
Training loss: 1.0207722187042236
Validation loss: 2.081727479894956

Epoch: 5| Step: 11
Training loss: 1.0044260025024414
Validation loss: 2.089620143175125

Epoch: 83| Step: 0
Training loss: 1.544211745262146
Validation loss: 2.098705768585205

Epoch: 5| Step: 1
Training loss: 2.5108628273010254
Validation loss: 2.1220907171567283

Epoch: 5| Step: 2
Training loss: 2.072265625
Validation loss: 2.103717645009359

Epoch: 5| Step: 3
Training loss: 1.4208934307098389
Validation loss: 2.126919075846672

Epoch: 5| Step: 4
Training loss: 1.8799728155136108
Validation loss: 2.13087859749794

Epoch: 5| Step: 5
Training loss: 1.5687379837036133
Validation loss: 2.1426943192879357

Epoch: 5| Step: 6
Training loss: 2.800593137741089
Validation loss: 2.14079017440478

Epoch: 5| Step: 7
Training loss: 1.474099040031433
Validation loss: 2.1407624781131744

Epoch: 5| Step: 8
Training loss: 2.1497364044189453
Validation loss: 2.123342290520668

Epoch: 5| Step: 9
Training loss: 1.6613318920135498
Validation loss: 2.1008792320887246

Epoch: 5| Step: 10
Training loss: 1.9528446197509766
Validation loss: 2.1086904108524323

Epoch: 5| Step: 11
Training loss: 2.4624722003936768
Validation loss: 2.073141167561213

Epoch: 84| Step: 0
Training loss: 2.1382076740264893
Validation loss: 2.081286832690239

Epoch: 5| Step: 1
Training loss: 1.7376857995986938
Validation loss: 2.063353901108106

Epoch: 5| Step: 2
Training loss: 1.744455099105835
Validation loss: 2.040552005171776

Epoch: 5| Step: 3
Training loss: 1.9319331645965576
Validation loss: 2.058240761359533

Epoch: 5| Step: 4
Training loss: 2.416398525238037
Validation loss: 2.0628395477930703

Epoch: 5| Step: 5
Training loss: 2.308072566986084
Validation loss: 2.054008742173513

Epoch: 5| Step: 6
Training loss: 1.9894847869873047
Validation loss: 2.0354062815507254

Epoch: 5| Step: 7
Training loss: 1.4709711074829102
Validation loss: 2.0538541674613953

Epoch: 5| Step: 8
Training loss: 1.8068996667861938
Validation loss: 2.0577230900526047

Epoch: 5| Step: 9
Training loss: 1.980187177658081
Validation loss: 2.051333670814832

Epoch: 5| Step: 10
Training loss: 1.8095037937164307
Validation loss: 2.056431179245313

Epoch: 5| Step: 11
Training loss: 2.2733240127563477
Validation loss: 2.059676239887873

Epoch: 85| Step: 0
Training loss: 2.1288251876831055
Validation loss: 2.0604801724354425

Epoch: 5| Step: 1
Training loss: 1.4891963005065918
Validation loss: 2.0516326477130256

Epoch: 5| Step: 2
Training loss: 2.0139389038085938
Validation loss: 2.035229211052259

Epoch: 5| Step: 3
Training loss: 2.1645967960357666
Validation loss: 2.0660318434238434

Epoch: 5| Step: 4
Training loss: 1.7829692363739014
Validation loss: 2.0696182201306024

Epoch: 5| Step: 5
Training loss: 2.2647500038146973
Validation loss: 2.0525165845950446

Epoch: 5| Step: 6
Training loss: 1.8755643367767334
Validation loss: 2.0584992518027625

Epoch: 5| Step: 7
Training loss: 1.6474460363388062
Validation loss: 2.086132084329923

Epoch: 5| Step: 8
Training loss: 1.8527519702911377
Validation loss: 2.0551633834838867

Epoch: 5| Step: 9
Training loss: 1.5315684080123901
Validation loss: 2.048928419748942

Epoch: 5| Step: 10
Training loss: 2.3683834075927734
Validation loss: 2.072345202167829

Epoch: 5| Step: 11
Training loss: 1.0942647457122803
Validation loss: 2.0901491045951843

Epoch: 86| Step: 0
Training loss: 1.7338240146636963
Validation loss: 2.0775714069604874

Epoch: 5| Step: 1
Training loss: 1.8456615209579468
Validation loss: 2.0643739451964698

Epoch: 5| Step: 2
Training loss: 2.150754928588867
Validation loss: 2.0820218920707703

Epoch: 5| Step: 3
Training loss: 2.725407361984253
Validation loss: 2.095700109998385

Epoch: 5| Step: 4
Training loss: 1.9835010766983032
Validation loss: 2.102933277686437

Epoch: 5| Step: 5
Training loss: 2.0808098316192627
Validation loss: 2.0978919665018716

Epoch: 5| Step: 6
Training loss: 1.50286066532135
Validation loss: 2.09394334256649

Epoch: 5| Step: 7
Training loss: 1.4521236419677734
Validation loss: 2.1059377988179526

Epoch: 5| Step: 8
Training loss: 1.71061110496521
Validation loss: 2.0969213048617044

Epoch: 5| Step: 9
Training loss: 1.8275419473648071
Validation loss: 2.095800737539927

Epoch: 5| Step: 10
Training loss: 1.8268572092056274
Validation loss: 2.072248270114263

Epoch: 5| Step: 11
Training loss: 2.66853666305542
Validation loss: 2.0811604211727777

Epoch: 87| Step: 0
Training loss: 2.174532651901245
Validation loss: 2.0788095196088157

Epoch: 5| Step: 1
Training loss: 1.4737707376480103
Validation loss: 2.061066841085752

Epoch: 5| Step: 2
Training loss: 2.2108521461486816
Validation loss: 2.06685471534729

Epoch: 5| Step: 3
Training loss: 1.7156345844268799
Validation loss: 2.048661231994629

Epoch: 5| Step: 4
Training loss: 2.1272339820861816
Validation loss: 2.0671899914741516

Epoch: 5| Step: 5
Training loss: 2.2531044483184814
Validation loss: 2.0711668183406196

Epoch: 5| Step: 6
Training loss: 1.9939687252044678
Validation loss: 2.05962206919988

Epoch: 5| Step: 7
Training loss: 1.6851634979248047
Validation loss: 2.04975896080335

Epoch: 5| Step: 8
Training loss: 2.197211742401123
Validation loss: 2.047454615434011

Epoch: 5| Step: 9
Training loss: 1.7995140552520752
Validation loss: 2.02659144004186

Epoch: 5| Step: 10
Training loss: 1.3487471342086792
Validation loss: 2.0734897504250207

Epoch: 5| Step: 11
Training loss: 2.2045555114746094
Validation loss: 2.0590504010518393

Epoch: 88| Step: 0
Training loss: 2.194206714630127
Validation loss: 2.0649365534385047

Epoch: 5| Step: 1
Training loss: 1.801660180091858
Validation loss: 2.058324153224627

Epoch: 5| Step: 2
Training loss: 2.4467570781707764
Validation loss: 2.071363463997841

Epoch: 5| Step: 3
Training loss: 2.287806272506714
Validation loss: 2.0830949395895004

Epoch: 5| Step: 4
Training loss: 1.3059403896331787
Validation loss: 2.0671706845362983

Epoch: 5| Step: 5
Training loss: 1.8203834295272827
Validation loss: 2.087500641743342

Epoch: 5| Step: 6
Training loss: 1.8969186544418335
Validation loss: 2.1026419699192047

Epoch: 5| Step: 7
Training loss: 2.4571709632873535
Validation loss: 2.0931190152963004

Epoch: 5| Step: 8
Training loss: 1.8944165706634521
Validation loss: 2.1121411323547363

Epoch: 5| Step: 9
Training loss: 1.4552438259124756
Validation loss: 2.107530544201533

Epoch: 5| Step: 10
Training loss: 1.2763352394104004
Validation loss: 2.1185639798641205

Epoch: 5| Step: 11
Training loss: 1.6136524677276611
Validation loss: 2.1047648737827935

Epoch: 89| Step: 0
Training loss: 2.152571439743042
Validation loss: 2.0832972526550293

Epoch: 5| Step: 1
Training loss: 1.4571406841278076
Validation loss: 2.091491629679998

Epoch: 5| Step: 2
Training loss: 2.1186294555664062
Validation loss: 2.0936883290608725

Epoch: 5| Step: 3
Training loss: 2.449963331222534
Validation loss: 2.083736300468445

Epoch: 5| Step: 4
Training loss: 1.5028575658798218
Validation loss: 2.0549458861351013

Epoch: 5| Step: 5
Training loss: 1.997449278831482
Validation loss: 2.0582104424635568

Epoch: 5| Step: 6
Training loss: 1.9541654586791992
Validation loss: 2.0705913305282593

Epoch: 5| Step: 7
Training loss: 1.9111931324005127
Validation loss: 2.0607809126377106

Epoch: 5| Step: 8
Training loss: 1.983899474143982
Validation loss: 2.0660780519247055

Epoch: 5| Step: 9
Training loss: 1.1772161722183228
Validation loss: 2.0513617048660913

Epoch: 5| Step: 10
Training loss: 2.4088966846466064
Validation loss: 2.054833327730497

Epoch: 5| Step: 11
Training loss: 2.1163430213928223
Validation loss: 2.049421767393748

Epoch: 90| Step: 0
Training loss: 1.7107187509536743
Validation loss: 2.068774715065956

Epoch: 5| Step: 1
Training loss: 2.6605985164642334
Validation loss: 2.076908399661382

Epoch: 5| Step: 2
Training loss: 1.8686449527740479
Validation loss: 2.0605068653821945

Epoch: 5| Step: 3
Training loss: 1.8072288036346436
Validation loss: 2.0930864165226617

Epoch: 5| Step: 4
Training loss: 2.0289387702941895
Validation loss: 2.080506612857183

Epoch: 5| Step: 5
Training loss: 2.145249128341675
Validation loss: 2.0815327564875283

Epoch: 5| Step: 6
Training loss: 1.8047187328338623
Validation loss: 2.1019119918346405

Epoch: 5| Step: 7
Training loss: 1.470301866531372
Validation loss: 2.0982327510913215

Epoch: 5| Step: 8
Training loss: 1.949907898902893
Validation loss: 2.0649875005086265

Epoch: 5| Step: 9
Training loss: 1.9228713512420654
Validation loss: 2.05617593228817

Epoch: 5| Step: 10
Training loss: 1.6192573308944702
Validation loss: 2.074487715959549

Epoch: 5| Step: 11
Training loss: 2.643401622772217
Validation loss: 2.076902389526367

Epoch: 91| Step: 0
Training loss: 1.6617717742919922
Validation loss: 2.082888960838318

Epoch: 5| Step: 1
Training loss: 2.414003849029541
Validation loss: 2.066347618897756

Epoch: 5| Step: 2
Training loss: 2.087049961090088
Validation loss: 2.061682716012001

Epoch: 5| Step: 3
Training loss: 1.295050024986267
Validation loss: 2.072700281937917

Epoch: 5| Step: 4
Training loss: 1.6159031391143799
Validation loss: 2.0831072131792703

Epoch: 5| Step: 5
Training loss: 2.304483413696289
Validation loss: 2.0533063312371573

Epoch: 5| Step: 6
Training loss: 2.1999900341033936
Validation loss: 2.0481994648774466

Epoch: 5| Step: 7
Training loss: 1.9065256118774414
Validation loss: 2.067504112919172

Epoch: 5| Step: 8
Training loss: 1.666656494140625
Validation loss: 2.0508888016144433

Epoch: 5| Step: 9
Training loss: 1.7960221767425537
Validation loss: 2.061111569404602

Epoch: 5| Step: 10
Training loss: 2.141324281692505
Validation loss: 2.084458460410436

Epoch: 5| Step: 11
Training loss: 1.2780059576034546
Validation loss: 2.049193893869718

Epoch: 92| Step: 0
Training loss: 1.8144137859344482
Validation loss: 2.09632242222627

Epoch: 5| Step: 1
Training loss: 1.9459556341171265
Validation loss: 2.1000718772411346

Epoch: 5| Step: 2
Training loss: 2.1403610706329346
Validation loss: 2.1131958017746606

Epoch: 5| Step: 3
Training loss: 1.6024547815322876
Validation loss: 2.1113049338261285

Epoch: 5| Step: 4
Training loss: 1.9440109729766846
Validation loss: 2.103381007909775

Epoch: 5| Step: 5
Training loss: 1.8181054592132568
Validation loss: 2.137979030609131

Epoch: 5| Step: 6
Training loss: 1.8017501831054688
Validation loss: 2.1004929145177207

Epoch: 5| Step: 7
Training loss: 1.8885685205459595
Validation loss: 2.0887102286020913

Epoch: 5| Step: 8
Training loss: 2.244748592376709
Validation loss: 2.092693110307058

Epoch: 5| Step: 9
Training loss: 2.1572518348693848
Validation loss: 2.105485046903292

Epoch: 5| Step: 10
Training loss: 2.1534063816070557
Validation loss: 2.081715608636538

Epoch: 5| Step: 11
Training loss: 0.6830357313156128
Validation loss: 2.0864145507415137

Epoch: 93| Step: 0
Training loss: 1.8660027980804443
Validation loss: 2.0816129396359124

Epoch: 5| Step: 1
Training loss: 1.4739866256713867
Validation loss: 2.0877748330434165

Epoch: 5| Step: 2
Training loss: 2.681603193283081
Validation loss: 2.0907673935095468

Epoch: 5| Step: 3
Training loss: 1.9033876657485962
Validation loss: 2.09056656062603

Epoch: 5| Step: 4
Training loss: 2.249166488647461
Validation loss: 2.067777673403422

Epoch: 5| Step: 5
Training loss: 1.378401517868042
Validation loss: 2.0436701675256095

Epoch: 5| Step: 6
Training loss: 1.9214509725570679
Validation loss: 2.0585458974043527

Epoch: 5| Step: 7
Training loss: 2.112698793411255
Validation loss: 2.058009922504425

Epoch: 5| Step: 8
Training loss: 1.7190641164779663
Validation loss: 2.0581529438495636

Epoch: 5| Step: 9
Training loss: 1.7274188995361328
Validation loss: 2.057274252176285

Epoch: 5| Step: 10
Training loss: 1.7449830770492554
Validation loss: 2.064800719420115

Epoch: 5| Step: 11
Training loss: 1.9515879154205322
Validation loss: 2.0692265977462134

Epoch: 94| Step: 0
Training loss: 1.6429818868637085
Validation loss: 2.065548370281855

Epoch: 5| Step: 1
Training loss: 2.1978259086608887
Validation loss: 2.079103097319603

Epoch: 5| Step: 2
Training loss: 1.9736030101776123
Validation loss: 2.076925372083982

Epoch: 5| Step: 3
Training loss: 1.836103081703186
Validation loss: 2.095649396379789

Epoch: 5| Step: 4
Training loss: 2.260251522064209
Validation loss: 2.099475542704264

Epoch: 5| Step: 5
Training loss: 1.5579328536987305
Validation loss: 2.077109838525454

Epoch: 5| Step: 6
Training loss: 2.0203123092651367
Validation loss: 2.0633724629879

Epoch: 5| Step: 7
Training loss: 1.7595157623291016
Validation loss: 2.0687813758850098

Epoch: 5| Step: 8
Training loss: 2.0757803916931152
Validation loss: 2.0648618787527084

Epoch: 5| Step: 9
Training loss: 1.7067168951034546
Validation loss: 2.0764685571193695

Epoch: 5| Step: 10
Training loss: 1.7415771484375
Validation loss: 2.0826699485381446

Epoch: 5| Step: 11
Training loss: 1.901921033859253
Validation loss: 2.095597450931867

Epoch: 95| Step: 0
Training loss: 1.851182222366333
Validation loss: 2.0629429866870246

Epoch: 5| Step: 1
Training loss: 2.156186103820801
Validation loss: 2.0479538987080255

Epoch: 5| Step: 2
Training loss: 1.5769450664520264
Validation loss: 2.0508891145388284

Epoch: 5| Step: 3
Training loss: 2.507577419281006
Validation loss: 2.0474303861459098

Epoch: 5| Step: 4
Training loss: 1.2890570163726807
Validation loss: 2.047323410709699

Epoch: 5| Step: 5
Training loss: 1.7374670505523682
Validation loss: 2.0720565716425576

Epoch: 5| Step: 6
Training loss: 2.265530586242676
Validation loss: 2.0479470243056617

Epoch: 5| Step: 7
Training loss: 1.715256929397583
Validation loss: 2.059566284219424

Epoch: 5| Step: 8
Training loss: 1.5868414640426636
Validation loss: 2.057538022597631

Epoch: 5| Step: 9
Training loss: 2.1485910415649414
Validation loss: 2.0533820539712906

Epoch: 5| Step: 10
Training loss: 1.7980220317840576
Validation loss: 2.097164432207743

Epoch: 5| Step: 11
Training loss: 2.25394868850708
Validation loss: 2.079395775993665

Epoch: 96| Step: 0
Training loss: 2.3887343406677246
Validation loss: 2.081788564721743

Epoch: 5| Step: 1
Training loss: 1.7377325296401978
Validation loss: 2.095267121990522

Epoch: 5| Step: 2
Training loss: 2.1191048622131348
Validation loss: 2.0657109171152115

Epoch: 5| Step: 3
Training loss: 2.120255708694458
Validation loss: 2.0780865599711738

Epoch: 5| Step: 4
Training loss: 1.5295765399932861
Validation loss: 2.068889374534289

Epoch: 5| Step: 5
Training loss: 1.3956387042999268
Validation loss: 2.048012653986613

Epoch: 5| Step: 6
Training loss: 2.1498422622680664
Validation loss: 2.044605458776156

Epoch: 5| Step: 7
Training loss: 1.7465025186538696
Validation loss: 2.064719001452128

Epoch: 5| Step: 8
Training loss: 2.092923641204834
Validation loss: 2.0849886735280356

Epoch: 5| Step: 9
Training loss: 1.7386871576309204
Validation loss: 2.0653569400310516

Epoch: 5| Step: 10
Training loss: 2.0063986778259277
Validation loss: 2.078042576710383

Epoch: 5| Step: 11
Training loss: 0.6849569082260132
Validation loss: 2.0629503627618155

Epoch: 97| Step: 0
Training loss: 2.0900161266326904
Validation loss: 2.0779967506726584

Epoch: 5| Step: 1
Training loss: 1.9154052734375
Validation loss: 2.079524333278338

Epoch: 5| Step: 2
Training loss: 1.6419200897216797
Validation loss: 2.0639898677666983

Epoch: 5| Step: 3
Training loss: 2.3900933265686035
Validation loss: 2.0709436486164727

Epoch: 5| Step: 4
Training loss: 2.0570731163024902
Validation loss: 2.0734183142582574

Epoch: 5| Step: 5
Training loss: 1.9248979091644287
Validation loss: 2.0482458720604577

Epoch: 5| Step: 6
Training loss: 1.3965939283370972
Validation loss: 2.059922138849894

Epoch: 5| Step: 7
Training loss: 2.23014760017395
Validation loss: 2.0497499108314514

Epoch: 5| Step: 8
Training loss: 1.2310079336166382
Validation loss: 2.0517937193314233

Epoch: 5| Step: 9
Training loss: 2.1902401447296143
Validation loss: 2.0583656827608743

Epoch: 5| Step: 10
Training loss: 1.817683458328247
Validation loss: 2.0482125679651895

Epoch: 5| Step: 11
Training loss: 1.8947651386260986
Validation loss: 2.073622385660807

Epoch: 98| Step: 0
Training loss: 1.1883466243743896
Validation loss: 2.0717821270227432

Epoch: 5| Step: 1
Training loss: 2.125819206237793
Validation loss: 2.095389445622762

Epoch: 5| Step: 2
Training loss: 1.6327297687530518
Validation loss: 2.053405558069547

Epoch: 5| Step: 3
Training loss: 2.4161911010742188
Validation loss: 2.042694608370463

Epoch: 5| Step: 4
Training loss: 1.7582305669784546
Validation loss: 2.0537541757027307

Epoch: 5| Step: 5
Training loss: 1.9115629196166992
Validation loss: 2.073282688856125

Epoch: 5| Step: 6
Training loss: 2.1947124004364014
Validation loss: 2.0804901470740638

Epoch: 5| Step: 7
Training loss: 1.9552310705184937
Validation loss: 2.069547325372696

Epoch: 5| Step: 8
Training loss: 1.6162025928497314
Validation loss: 2.083768238623937

Epoch: 5| Step: 9
Training loss: 1.6591689586639404
Validation loss: 2.0694887240727744

Epoch: 5| Step: 10
Training loss: 1.9809468984603882
Validation loss: 2.0786567827065787

Epoch: 5| Step: 11
Training loss: 2.9788284301757812
Validation loss: 2.081270361940066

Epoch: 99| Step: 0
Training loss: 1.5357134342193604
Validation loss: 2.0890956868728003

Epoch: 5| Step: 1
Training loss: 1.9729270935058594
Validation loss: 2.0932984203100204

Epoch: 5| Step: 2
Training loss: 1.6755638122558594
Validation loss: 2.0846080432335534

Epoch: 5| Step: 3
Training loss: 1.179983139038086
Validation loss: 2.107505818208059

Epoch: 5| Step: 4
Training loss: 1.6833308935165405
Validation loss: 2.1099050541718802

Epoch: 5| Step: 5
Training loss: 2.107387065887451
Validation loss: 2.106208791335424

Epoch: 5| Step: 6
Training loss: 2.2910900115966797
Validation loss: 2.106000691652298

Epoch: 5| Step: 7
Training loss: 1.940044641494751
Validation loss: 2.1101525078217187

Epoch: 5| Step: 8
Training loss: 2.4799907207489014
Validation loss: 2.09541521469752

Epoch: 5| Step: 9
Training loss: 1.4174964427947998
Validation loss: 2.0634448478619256

Epoch: 5| Step: 10
Training loss: 2.1071298122406006
Validation loss: 2.093274399638176

Epoch: 5| Step: 11
Training loss: 2.746345043182373
Validation loss: 2.056784967581431

Epoch: 100| Step: 0
Training loss: 1.9161287546157837
Validation loss: 2.0514596650997796

Epoch: 5| Step: 1
Training loss: 1.577274203300476
Validation loss: 2.045043701926867

Epoch: 5| Step: 2
Training loss: 1.4889863729476929
Validation loss: 2.0683993250131607

Epoch: 5| Step: 3
Training loss: 1.4995917081832886
Validation loss: 2.0274848441282907

Epoch: 5| Step: 4
Training loss: 2.0044422149658203
Validation loss: 2.034780586759249

Epoch: 5| Step: 5
Training loss: 1.9774574041366577
Validation loss: 2.0515608489513397

Epoch: 5| Step: 6
Training loss: 2.1311466693878174
Validation loss: 2.0355154722929

Epoch: 5| Step: 7
Training loss: 2.5388102531433105
Validation loss: 2.077325160304705

Epoch: 5| Step: 8
Training loss: 2.096996784210205
Validation loss: 2.061112662156423

Epoch: 5| Step: 9
Training loss: 1.56868577003479
Validation loss: 2.052960758407911

Epoch: 5| Step: 10
Training loss: 1.9699878692626953
Validation loss: 2.0702580312887826

Epoch: 5| Step: 11
Training loss: 1.391475796699524
Validation loss: 2.060183455546697

Epoch: 101| Step: 0
Training loss: 2.102292537689209
Validation loss: 2.0731424440940223

Epoch: 5| Step: 1
Training loss: 1.8110520839691162
Validation loss: 2.0539874881505966

Epoch: 5| Step: 2
Training loss: 2.012068510055542
Validation loss: 2.067909856637319

Epoch: 5| Step: 3
Training loss: 1.869230031967163
Validation loss: 2.0881776014963784

Epoch: 5| Step: 4
Training loss: 1.7679109573364258
Validation loss: 2.0962388118108115

Epoch: 5| Step: 5
Training loss: 2.011155605316162
Validation loss: 2.063528756300608

Epoch: 5| Step: 6
Training loss: 1.1834746599197388
Validation loss: 2.059485619266828

Epoch: 5| Step: 7
Training loss: 2.6879138946533203
Validation loss: 2.0672879219055176

Epoch: 5| Step: 8
Training loss: 1.7399132251739502
Validation loss: 2.054615626732508

Epoch: 5| Step: 9
Training loss: 1.692300796508789
Validation loss: 2.063883458574613

Epoch: 5| Step: 10
Training loss: 1.4088480472564697
Validation loss: 2.054553672671318

Epoch: 5| Step: 11
Training loss: 2.826064109802246
Validation loss: 2.0654330303271613

Epoch: 102| Step: 0
Training loss: 1.6943289041519165
Validation loss: 2.0813399056593576

Epoch: 5| Step: 1
Training loss: 2.2397701740264893
Validation loss: 2.080311805009842

Epoch: 5| Step: 2
Training loss: 1.7027534246444702
Validation loss: 2.0941816717386246

Epoch: 5| Step: 3
Training loss: 1.6974093914031982
Validation loss: 2.102918619910876

Epoch: 5| Step: 4
Training loss: 2.086662769317627
Validation loss: 2.1119586378335953

Epoch: 5| Step: 5
Training loss: 1.9784200191497803
Validation loss: 2.108372022708257

Epoch: 5| Step: 6
Training loss: 1.9631191492080688
Validation loss: 2.120398739973704

Epoch: 5| Step: 7
Training loss: 1.9571716785430908
Validation loss: 2.07499860227108

Epoch: 5| Step: 8
Training loss: 1.5553386211395264
Validation loss: 2.0606701026360192

Epoch: 5| Step: 9
Training loss: 1.7233158349990845
Validation loss: 2.061329503854116

Epoch: 5| Step: 10
Training loss: 2.1641361713409424
Validation loss: 2.0544680108626685

Epoch: 5| Step: 11
Training loss: 1.4526786804199219
Validation loss: 2.079556862513224

Epoch: 103| Step: 0
Training loss: 2.693918228149414
Validation loss: 2.0610751112302146

Epoch: 5| Step: 1
Training loss: 2.106039047241211
Validation loss: 2.0741753230492272

Epoch: 5| Step: 2
Training loss: 1.9064950942993164
Validation loss: 2.084940547744433

Epoch: 5| Step: 3
Training loss: 1.2028017044067383
Validation loss: 2.0642696420351663

Epoch: 5| Step: 4
Training loss: 1.7919622659683228
Validation loss: 2.0643258591492972

Epoch: 5| Step: 5
Training loss: 1.3869824409484863
Validation loss: 2.065043772260348

Epoch: 5| Step: 6
Training loss: 1.9739097356796265
Validation loss: 2.072057008743286

Epoch: 5| Step: 7
Training loss: 2.3470091819763184
Validation loss: 2.0612127085526786

Epoch: 5| Step: 8
Training loss: 1.6069858074188232
Validation loss: 2.073719839255015

Epoch: 5| Step: 9
Training loss: 1.635854721069336
Validation loss: 2.0456587076187134

Epoch: 5| Step: 10
Training loss: 1.9163223505020142
Validation loss: 2.068866118788719

Epoch: 5| Step: 11
Training loss: 1.9539958238601685
Validation loss: 2.0918794920047126

Epoch: 104| Step: 0
Training loss: 1.9528553485870361
Validation loss: 2.0540741880734763

Epoch: 5| Step: 1
Training loss: 1.4508647918701172
Validation loss: 2.0786591172218323

Epoch: 5| Step: 2
Training loss: 1.487005591392517
Validation loss: 2.0768481642007828

Epoch: 5| Step: 3
Training loss: 1.503920316696167
Validation loss: 2.070492073893547

Epoch: 5| Step: 4
Training loss: 2.174027681350708
Validation loss: 2.089951276779175

Epoch: 5| Step: 5
Training loss: 2.4474892616271973
Validation loss: 2.072719564040502

Epoch: 5| Step: 6
Training loss: 2.177649974822998
Validation loss: 2.082621991634369

Epoch: 5| Step: 7
Training loss: 1.9891300201416016
Validation loss: 2.0511673788229623

Epoch: 5| Step: 8
Training loss: 2.6113121509552
Validation loss: 2.066945066054662

Epoch: 5| Step: 9
Training loss: 0.9747599363327026
Validation loss: 2.0357346137364707

Epoch: 5| Step: 10
Training loss: 1.8597530126571655
Validation loss: 2.0433267951011658

Epoch: 5| Step: 11
Training loss: 0.9536073207855225
Validation loss: 2.054704859852791

Epoch: 105| Step: 0
Training loss: 2.0601837635040283
Validation loss: 2.0495513528585434

Epoch: 5| Step: 1
Training loss: 2.6810410022735596
Validation loss: 2.0636002520720163

Epoch: 5| Step: 2
Training loss: 1.914150595664978
Validation loss: 2.052623296777407

Epoch: 5| Step: 3
Training loss: 1.7472162246704102
Validation loss: 2.0508366376161575

Epoch: 5| Step: 4
Training loss: 1.682529091835022
Validation loss: 2.0670979768037796

Epoch: 5| Step: 5
Training loss: 1.8223068714141846
Validation loss: 2.078638960917791

Epoch: 5| Step: 6
Training loss: 1.7483686208724976
Validation loss: 2.0374892950057983

Epoch: 5| Step: 7
Training loss: 1.4814236164093018
Validation loss: 2.062745983401934

Epoch: 5| Step: 8
Training loss: 1.9291225671768188
Validation loss: 2.0923147002855935

Epoch: 5| Step: 9
Training loss: 1.8427562713623047
Validation loss: 2.1116281946500144

Epoch: 5| Step: 10
Training loss: 1.6724601984024048
Validation loss: 2.0831964115301767

Epoch: 5| Step: 11
Training loss: 0.7958651781082153
Validation loss: 2.0953198770682016

Epoch: 106| Step: 0
Training loss: 1.841779112815857
Validation loss: 2.09042019645373

Epoch: 5| Step: 1
Training loss: 1.930779218673706
Validation loss: 2.1019448091586432

Epoch: 5| Step: 2
Training loss: 2.3338465690612793
Validation loss: 2.1007236490646997

Epoch: 5| Step: 3
Training loss: 2.201026439666748
Validation loss: 2.104694743951162

Epoch: 5| Step: 4
Training loss: 1.4397835731506348
Validation loss: 2.108621726433436

Epoch: 5| Step: 5
Training loss: 1.7619752883911133
Validation loss: 2.0771521081527076

Epoch: 5| Step: 6
Training loss: 1.3601309061050415
Validation loss: 2.064802254239718

Epoch: 5| Step: 7
Training loss: 2.287938356399536
Validation loss: 2.037244290113449

Epoch: 5| Step: 8
Training loss: 1.613884687423706
Validation loss: 2.0395335058371225

Epoch: 5| Step: 9
Training loss: 2.020582914352417
Validation loss: 2.059528241554896

Epoch: 5| Step: 10
Training loss: 1.858007788658142
Validation loss: 2.0641466031471887

Epoch: 5| Step: 11
Training loss: 1.8763360977172852
Validation loss: 2.0445591708024344

Epoch: 107| Step: 0
Training loss: 1.281860113143921
Validation loss: 2.0533579140901566

Epoch: 5| Step: 1
Training loss: 1.7177631855010986
Validation loss: 2.0576399813095727

Epoch: 5| Step: 2
Training loss: 1.8484933376312256
Validation loss: 2.052231172720591

Epoch: 5| Step: 3
Training loss: 2.1142737865448
Validation loss: 2.025218203663826

Epoch: 5| Step: 4
Training loss: 1.7078931331634521
Validation loss: 2.0603946099678674

Epoch: 5| Step: 5
Training loss: 1.6802412271499634
Validation loss: 2.0634017239014306

Epoch: 5| Step: 6
Training loss: 2.479581832885742
Validation loss: 2.044735550880432

Epoch: 5| Step: 7
Training loss: 1.9333808422088623
Validation loss: 2.052113284667333

Epoch: 5| Step: 8
Training loss: 1.5635638236999512
Validation loss: 2.0415792167186737

Epoch: 5| Step: 9
Training loss: 1.9344367980957031
Validation loss: 2.0486749360958734

Epoch: 5| Step: 10
Training loss: 2.0041346549987793
Validation loss: 2.0503173718849816

Epoch: 5| Step: 11
Training loss: 1.817389726638794
Validation loss: 2.0503234217564263

Epoch: 108| Step: 0
Training loss: 2.0301952362060547
Validation loss: 2.053946072856585

Epoch: 5| Step: 1
Training loss: 1.6953742504119873
Validation loss: 2.0902059276898703

Epoch: 5| Step: 2
Training loss: 2.4110195636749268
Validation loss: 2.074008817474047

Epoch: 5| Step: 3
Training loss: 1.839561104774475
Validation loss: 2.10347888370355

Epoch: 5| Step: 4
Training loss: 1.5796968936920166
Validation loss: 2.1192303200562796

Epoch: 5| Step: 5
Training loss: 1.2693114280700684
Validation loss: 2.0862266520659127

Epoch: 5| Step: 6
Training loss: 2.2334117889404297
Validation loss: 2.0717912216981254

Epoch: 5| Step: 7
Training loss: 1.995897650718689
Validation loss: 2.0435165464878082

Epoch: 5| Step: 8
Training loss: 1.6895112991333008
Validation loss: 2.0695943882068

Epoch: 5| Step: 9
Training loss: 2.2048540115356445
Validation loss: 2.0496239066123962

Epoch: 5| Step: 10
Training loss: 1.6349573135375977
Validation loss: 2.0721457401911416

Epoch: 5| Step: 11
Training loss: 1.3002759218215942
Validation loss: 2.0650853315989175

Epoch: 109| Step: 0
Training loss: 2.1817665100097656
Validation loss: 2.0627306352059045

Epoch: 5| Step: 1
Training loss: 1.6381562948226929
Validation loss: 2.069683223962784

Epoch: 5| Step: 2
Training loss: 1.5845500230789185
Validation loss: 2.034307370583216

Epoch: 5| Step: 3
Training loss: 2.288236141204834
Validation loss: 2.050863986214002

Epoch: 5| Step: 4
Training loss: 1.9703233242034912
Validation loss: 2.0798572450876236

Epoch: 5| Step: 5
Training loss: 2.0798985958099365
Validation loss: 2.0552921940883

Epoch: 5| Step: 6
Training loss: 1.4955734014511108
Validation loss: 2.0604729851086936

Epoch: 5| Step: 7
Training loss: 1.6673345565795898
Validation loss: 2.079571694135666

Epoch: 5| Step: 8
Training loss: 1.7451226711273193
Validation loss: 2.090301667650541

Epoch: 5| Step: 9
Training loss: 1.583242654800415
Validation loss: 2.0813032686710358

Epoch: 5| Step: 10
Training loss: 2.053556203842163
Validation loss: 2.0905953347682953

Epoch: 5| Step: 11
Training loss: 1.2562024593353271
Validation loss: 2.075554539759954

Epoch: 110| Step: 0
Training loss: 1.63273024559021
Validation loss: 2.0638816157976785

Epoch: 5| Step: 1
Training loss: 2.1590018272399902
Validation loss: 2.063298220435778

Epoch: 5| Step: 2
Training loss: 1.93988037109375
Validation loss: 2.0565845916668573

Epoch: 5| Step: 3
Training loss: 2.1081583499908447
Validation loss: 2.0417270163695016

Epoch: 5| Step: 4
Training loss: 1.8558260202407837
Validation loss: 2.0643961826960244

Epoch: 5| Step: 5
Training loss: 1.9589383602142334
Validation loss: 2.0533867528041205

Epoch: 5| Step: 6
Training loss: 1.5161168575286865
Validation loss: 2.0568398038546243

Epoch: 5| Step: 7
Training loss: 1.9817705154418945
Validation loss: 2.0589263240496316

Epoch: 5| Step: 8
Training loss: 1.7371654510498047
Validation loss: 2.0365341703097024

Epoch: 5| Step: 9
Training loss: 1.8420441150665283
Validation loss: 2.0773306538661322

Epoch: 5| Step: 10
Training loss: 1.5326802730560303
Validation loss: 2.0664204259713492

Epoch: 5| Step: 11
Training loss: 0.7602454423904419
Validation loss: 2.074821944038073

Epoch: 111| Step: 0
Training loss: 1.632818579673767
Validation loss: 2.070786456267039

Epoch: 5| Step: 1
Training loss: 1.761630654335022
Validation loss: 2.080472151438395

Epoch: 5| Step: 2
Training loss: 2.343414545059204
Validation loss: 2.0641283293565116

Epoch: 5| Step: 3
Training loss: 1.7839562892913818
Validation loss: 2.070494592189789

Epoch: 5| Step: 4
Training loss: 1.0986979007720947
Validation loss: 2.071972260872523

Epoch: 5| Step: 5
Training loss: 1.5818815231323242
Validation loss: 2.09391126036644

Epoch: 5| Step: 6
Training loss: 2.0100722312927246
Validation loss: 2.076301092902819

Epoch: 5| Step: 7
Training loss: 1.985650658607483
Validation loss: 2.0861048499743142

Epoch: 5| Step: 8
Training loss: 1.9695419073104858
Validation loss: 2.0546590040127435

Epoch: 5| Step: 9
Training loss: 2.4381673336029053
Validation loss: 2.0739902555942535

Epoch: 5| Step: 10
Training loss: 1.6026197671890259
Validation loss: 2.0533486107985177

Epoch: 5| Step: 11
Training loss: 1.0747179985046387
Validation loss: 2.0631907085577645

Epoch: 112| Step: 0
Training loss: 1.5276588201522827
Validation loss: 2.051355933149656

Epoch: 5| Step: 1
Training loss: 1.9510033130645752
Validation loss: 2.0680025120576224

Epoch: 5| Step: 2
Training loss: 1.6205809116363525
Validation loss: 2.075051893790563

Epoch: 5| Step: 3
Training loss: 2.0960428714752197
Validation loss: 2.0614008754491806

Epoch: 5| Step: 4
Training loss: 1.598341703414917
Validation loss: 2.0807235538959503

Epoch: 5| Step: 5
Training loss: 1.890880823135376
Validation loss: 2.068795750538508

Epoch: 5| Step: 6
Training loss: 1.3662598133087158
Validation loss: 2.077528933684031

Epoch: 5| Step: 7
Training loss: 1.6227744817733765
Validation loss: 2.0948855876922607

Epoch: 5| Step: 8
Training loss: 1.8829975128173828
Validation loss: 2.114676664272944

Epoch: 5| Step: 9
Training loss: 1.9192501306533813
Validation loss: 2.0825853099425635

Epoch: 5| Step: 10
Training loss: 2.7520015239715576
Validation loss: 2.086293086409569

Epoch: 5| Step: 11
Training loss: 0.8022528886795044
Validation loss: 2.0907177527745566

Epoch: 113| Step: 0
Training loss: 1.7941135168075562
Validation loss: 2.072643051544825

Epoch: 5| Step: 1
Training loss: 1.687891960144043
Validation loss: 2.0742776691913605

Epoch: 5| Step: 2
Training loss: 1.8367201089859009
Validation loss: 2.080634226401647

Epoch: 5| Step: 3
Training loss: 1.5522531270980835
Validation loss: 2.0331029693285623

Epoch: 5| Step: 4
Training loss: 2.458818197250366
Validation loss: 2.046824331084887

Epoch: 5| Step: 5
Training loss: 1.8473838567733765
Validation loss: 2.0594290693600974

Epoch: 5| Step: 6
Training loss: 1.4106123447418213
Validation loss: 2.0381070921818414

Epoch: 5| Step: 7
Training loss: 2.122561454772949
Validation loss: 2.042052060365677

Epoch: 5| Step: 8
Training loss: 1.6756350994110107
Validation loss: 2.046787520249685

Epoch: 5| Step: 9
Training loss: 1.321872353553772
Validation loss: 2.0413749317328134

Epoch: 5| Step: 10
Training loss: 2.267024517059326
Validation loss: 2.037013312180837

Epoch: 5| Step: 11
Training loss: 2.1414458751678467
Validation loss: 2.062412679195404

Epoch: 114| Step: 0
Training loss: 1.381130576133728
Validation loss: 2.0718402663866677

Epoch: 5| Step: 1
Training loss: 1.6812610626220703
Validation loss: 2.065984567006429

Epoch: 5| Step: 2
Training loss: 1.900416612625122
Validation loss: 2.0600735545158386

Epoch: 5| Step: 3
Training loss: 1.8572295904159546
Validation loss: 2.064424733320872

Epoch: 5| Step: 4
Training loss: 1.5651509761810303
Validation loss: 2.062780871987343

Epoch: 5| Step: 5
Training loss: 2.163167953491211
Validation loss: 2.0896666248639426

Epoch: 5| Step: 6
Training loss: 1.9211833477020264
Validation loss: 2.119823177655538

Epoch: 5| Step: 7
Training loss: 1.7524265050888062
Validation loss: 2.10721862812837

Epoch: 5| Step: 8
Training loss: 2.039872884750366
Validation loss: 2.1129064758618674

Epoch: 5| Step: 9
Training loss: 1.9200048446655273
Validation loss: 2.084515934189161

Epoch: 5| Step: 10
Training loss: 1.645577073097229
Validation loss: 2.099916751186053

Epoch: 5| Step: 11
Training loss: 2.6298489570617676
Validation loss: 2.0972572018702826

Epoch: 115| Step: 0
Training loss: 1.5382921695709229
Validation loss: 2.1027713219324746

Epoch: 5| Step: 1
Training loss: 2.1727256774902344
Validation loss: 2.0521775633096695

Epoch: 5| Step: 2
Training loss: 1.6628544330596924
Validation loss: 2.0529747953017554

Epoch: 5| Step: 3
Training loss: 1.9350974559783936
Validation loss: 2.037625730037689

Epoch: 5| Step: 4
Training loss: 1.858668565750122
Validation loss: 2.06518983344237

Epoch: 5| Step: 5
Training loss: 1.682326078414917
Validation loss: 2.0628000100453696

Epoch: 5| Step: 6
Training loss: 2.0110902786254883
Validation loss: 2.041816229621569

Epoch: 5| Step: 7
Training loss: 1.9760973453521729
Validation loss: 2.065329392751058

Epoch: 5| Step: 8
Training loss: 1.6469262838363647
Validation loss: 2.043361375729243

Epoch: 5| Step: 9
Training loss: 2.1029436588287354
Validation loss: 2.0552048087120056

Epoch: 5| Step: 10
Training loss: 1.4002110958099365
Validation loss: 2.0517969528834024

Epoch: 5| Step: 11
Training loss: 2.1080374717712402
Validation loss: 2.08879092335701

Epoch: 116| Step: 0
Training loss: 2.262051820755005
Validation loss: 2.0829461763302484

Epoch: 5| Step: 1
Training loss: 2.029146194458008
Validation loss: 2.081409603357315

Epoch: 5| Step: 2
Training loss: 2.2836315631866455
Validation loss: 2.09528756638368

Epoch: 5| Step: 3
Training loss: 1.1676220893859863
Validation loss: 2.0657067000865936

Epoch: 5| Step: 4
Training loss: 1.6289012432098389
Validation loss: 2.065880691011747

Epoch: 5| Step: 5
Training loss: 1.755157232284546
Validation loss: 2.0633439968029657

Epoch: 5| Step: 6
Training loss: 2.0003371238708496
Validation loss: 2.077341988682747

Epoch: 5| Step: 7
Training loss: 1.6286284923553467
Validation loss: 2.1119010945161185

Epoch: 5| Step: 8
Training loss: 1.5606434345245361
Validation loss: 2.099525814255079

Epoch: 5| Step: 9
Training loss: 2.038846254348755
Validation loss: 2.1058485011259713

Epoch: 5| Step: 10
Training loss: 1.7985633611679077
Validation loss: 2.1156689524650574

Epoch: 5| Step: 11
Training loss: 0.7022854685783386
Validation loss: 2.119246155023575

Epoch: 117| Step: 0
Training loss: 1.299579381942749
Validation loss: 2.0677110850811005

Epoch: 5| Step: 1
Training loss: 2.0029993057250977
Validation loss: 2.076002617677053

Epoch: 5| Step: 2
Training loss: 1.1793584823608398
Validation loss: 2.0896828869978585

Epoch: 5| Step: 3
Training loss: 1.899178147315979
Validation loss: 2.0617130448420844

Epoch: 5| Step: 4
Training loss: 1.827996850013733
Validation loss: 2.0449143052101135

Epoch: 5| Step: 5
Training loss: 2.2613086700439453
Validation loss: 2.0527715384960175

Epoch: 5| Step: 6
Training loss: 2.042989730834961
Validation loss: 2.0624997466802597

Epoch: 5| Step: 7
Training loss: 1.814089059829712
Validation loss: 2.059842864672343

Epoch: 5| Step: 8
Training loss: 1.9119552373886108
Validation loss: 2.064587930838267

Epoch: 5| Step: 9
Training loss: 1.4009592533111572
Validation loss: 2.0336929907401404

Epoch: 5| Step: 10
Training loss: 2.181910753250122
Validation loss: 2.057506183783213

Epoch: 5| Step: 11
Training loss: 1.9411097764968872
Validation loss: 2.0633908410867057

Epoch: 118| Step: 0
Training loss: 1.8028209209442139
Validation loss: 2.0793741047382355

Epoch: 5| Step: 1
Training loss: 1.7345876693725586
Validation loss: 2.069230874379476

Epoch: 5| Step: 2
Training loss: 1.6967159509658813
Validation loss: 2.1170682410399118

Epoch: 5| Step: 3
Training loss: 1.7163455486297607
Validation loss: 2.10062767068545

Epoch: 5| Step: 4
Training loss: 1.690871000289917
Validation loss: 2.1158774296442666

Epoch: 5| Step: 5
Training loss: 1.677553415298462
Validation loss: 2.0917402505874634

Epoch: 5| Step: 6
Training loss: 2.02537202835083
Validation loss: 2.1100813299417496

Epoch: 5| Step: 7
Training loss: 1.534515142440796
Validation loss: 2.091782341400782

Epoch: 5| Step: 8
Training loss: 2.1793696880340576
Validation loss: 2.0998481065034866

Epoch: 5| Step: 9
Training loss: 2.294102191925049
Validation loss: 2.088435485959053

Epoch: 5| Step: 10
Training loss: 1.5559964179992676
Validation loss: 2.0834806015094123

Epoch: 5| Step: 11
Training loss: 1.7276009321212769
Validation loss: 2.0774085422356925

Epoch: 119| Step: 0
Training loss: 1.5950019359588623
Validation loss: 2.0756917148828506

Epoch: 5| Step: 1
Training loss: 1.4686423540115356
Validation loss: 2.0844834546248117

Epoch: 5| Step: 2
Training loss: 2.146604537963867
Validation loss: 2.108598987261454

Epoch: 5| Step: 3
Training loss: 2.0890955924987793
Validation loss: 2.110145077109337

Epoch: 5| Step: 4
Training loss: 2.012037515640259
Validation loss: 2.0940218220154443

Epoch: 5| Step: 5
Training loss: 1.8309917449951172
Validation loss: 2.1013297786315284

Epoch: 5| Step: 6
Training loss: 1.5656569004058838
Validation loss: 2.0663404961427054

Epoch: 5| Step: 7
Training loss: 1.457285761833191
Validation loss: 2.063333367307981

Epoch: 5| Step: 8
Training loss: 1.7580257654190063
Validation loss: 2.075355519851049

Epoch: 5| Step: 9
Training loss: 1.9455463886260986
Validation loss: 2.091527054707209

Epoch: 5| Step: 10
Training loss: 1.9397480487823486
Validation loss: 2.0961893250544867

Epoch: 5| Step: 11
Training loss: 1.2770916223526
Validation loss: 2.106466124455134

Epoch: 120| Step: 0
Training loss: 1.659828782081604
Validation loss: 2.078276897470156

Epoch: 5| Step: 1
Training loss: 1.7327194213867188
Validation loss: 2.1180131236712136

Epoch: 5| Step: 2
Training loss: 2.0772194862365723
Validation loss: 2.103292480111122

Epoch: 5| Step: 3
Training loss: 1.7807499170303345
Validation loss: 2.1157916138569512

Epoch: 5| Step: 4
Training loss: 1.8413196802139282
Validation loss: 2.0969543556372323

Epoch: 5| Step: 5
Training loss: 1.8919023275375366
Validation loss: 2.099949538707733

Epoch: 5| Step: 6
Training loss: 1.8758147954940796
Validation loss: 2.0968868136405945

Epoch: 5| Step: 7
Training loss: 1.2029091119766235
Validation loss: 2.1009761691093445

Epoch: 5| Step: 8
Training loss: 1.85288405418396
Validation loss: 2.085442120830218

Epoch: 5| Step: 9
Training loss: 1.9958244562149048
Validation loss: 2.0806610584259033

Epoch: 5| Step: 10
Training loss: 1.2923030853271484
Validation loss: 2.0889065911372504

Epoch: 5| Step: 11
Training loss: 2.3172059059143066
Validation loss: 2.05236646036307

Epoch: 121| Step: 0
Training loss: 1.3885619640350342
Validation loss: 2.056868483622869

Epoch: 5| Step: 1
Training loss: 1.1066789627075195
Validation loss: 2.0769577622413635

Epoch: 5| Step: 2
Training loss: 1.5235391855239868
Validation loss: 2.0427114417155585

Epoch: 5| Step: 3
Training loss: 1.2655327320098877
Validation loss: 2.0474450290203094

Epoch: 5| Step: 4
Training loss: 1.809110403060913
Validation loss: 2.0463539560635886

Epoch: 5| Step: 5
Training loss: 2.0274782180786133
Validation loss: 2.0409212360779443

Epoch: 5| Step: 6
Training loss: 2.1207828521728516
Validation loss: 2.0533035894234977

Epoch: 5| Step: 7
Training loss: 1.9960949420928955
Validation loss: 2.0634881605704627

Epoch: 5| Step: 8
Training loss: 1.9231960773468018
Validation loss: 2.082380915681521

Epoch: 5| Step: 9
Training loss: 1.7983789443969727
Validation loss: 2.112982377409935

Epoch: 5| Step: 10
Training loss: 2.405791759490967
Validation loss: 2.1018404215574265

Epoch: 5| Step: 11
Training loss: 3.147507667541504
Validation loss: 2.119456792871157

Epoch: 122| Step: 0
Training loss: 2.1169514656066895
Validation loss: 2.1168940414985022

Epoch: 5| Step: 1
Training loss: 1.2118480205535889
Validation loss: 2.104469522833824

Epoch: 5| Step: 2
Training loss: 2.1307358741760254
Validation loss: 2.1015712271134057

Epoch: 5| Step: 3
Training loss: 2.1854214668273926
Validation loss: 2.085396319627762

Epoch: 5| Step: 4
Training loss: 1.2797000408172607
Validation loss: 2.1364653607209525

Epoch: 5| Step: 5
Training loss: 1.850372314453125
Validation loss: 2.1383884251117706

Epoch: 5| Step: 6
Training loss: 1.9591827392578125
Validation loss: 2.1499980092048645

Epoch: 5| Step: 7
Training loss: 1.8626244068145752
Validation loss: 2.0841586043437323

Epoch: 5| Step: 8
Training loss: 2.0234484672546387
Validation loss: 2.094984104235967

Epoch: 5| Step: 9
Training loss: 1.498036503791809
Validation loss: 2.0884001602729163

Epoch: 5| Step: 10
Training loss: 1.4189221858978271
Validation loss: 2.073965862393379

Epoch: 5| Step: 11
Training loss: 1.2782865762710571
Validation loss: 2.068303724129995

Epoch: 123| Step: 0
Training loss: 1.8746850490570068
Validation loss: 2.0784009446700416

Epoch: 5| Step: 1
Training loss: 1.73896062374115
Validation loss: 2.0740950157245

Epoch: 5| Step: 2
Training loss: 1.7551466226577759
Validation loss: 2.060036852955818

Epoch: 5| Step: 3
Training loss: 1.538722038269043
Validation loss: 2.0853537072738013

Epoch: 5| Step: 4
Training loss: 1.639161467552185
Validation loss: 2.1004297335942588

Epoch: 5| Step: 5
Training loss: 1.8449052572250366
Validation loss: 2.098460445801417

Epoch: 5| Step: 6
Training loss: 1.6905332803726196
Validation loss: 2.0981333603461585

Epoch: 5| Step: 7
Training loss: 1.9265124797821045
Validation loss: 2.1204365144173303

Epoch: 5| Step: 8
Training loss: 2.3998827934265137
Validation loss: 2.130442256728808

Epoch: 5| Step: 9
Training loss: 1.56044602394104
Validation loss: 2.1553246080875397

Epoch: 5| Step: 10
Training loss: 1.5112746953964233
Validation loss: 2.1220131466786065

Epoch: 5| Step: 11
Training loss: 1.030595302581787
Validation loss: 2.124978760878245

Epoch: 124| Step: 0
Training loss: 1.8337777853012085
Validation loss: 2.0731316904226937

Epoch: 5| Step: 1
Training loss: 1.3688253164291382
Validation loss: 2.102776994307836

Epoch: 5| Step: 2
Training loss: 2.1727733612060547
Validation loss: 2.062873750925064

Epoch: 5| Step: 3
Training loss: 2.258765459060669
Validation loss: 2.04194683333238

Epoch: 5| Step: 4
Training loss: 1.4131615161895752
Validation loss: 2.0534170170625052

Epoch: 5| Step: 5
Training loss: 1.9285558462142944
Validation loss: 2.055240978797277

Epoch: 5| Step: 6
Training loss: 1.8422958850860596
Validation loss: 2.0395388454198837

Epoch: 5| Step: 7
Training loss: 1.8254934549331665
Validation loss: 2.06144184867541

Epoch: 5| Step: 8
Training loss: 1.3797023296356201
Validation loss: 2.044043650229772

Epoch: 5| Step: 9
Training loss: 1.4060499668121338
Validation loss: 2.0450955579678216

Epoch: 5| Step: 10
Training loss: 1.776441216468811
Validation loss: 2.0421671917041144

Epoch: 5| Step: 11
Training loss: 2.522059679031372
Validation loss: 2.0632387499014535

Epoch: 125| Step: 0
Training loss: 1.7853384017944336
Validation loss: 2.0430965522925058

Epoch: 5| Step: 1
Training loss: 1.9157898426055908
Validation loss: 2.0709744840860367

Epoch: 5| Step: 2
Training loss: 1.2297855615615845
Validation loss: 2.072606777151426

Epoch: 5| Step: 3
Training loss: 1.860547423362732
Validation loss: 2.0831369856993356

Epoch: 5| Step: 4
Training loss: 1.19264554977417
Validation loss: 2.0649148474136987

Epoch: 5| Step: 5
Training loss: 2.044588565826416
Validation loss: 2.068543220559756

Epoch: 5| Step: 6
Training loss: 2.18286395072937
Validation loss: 2.0755410691102347

Epoch: 5| Step: 7
Training loss: 1.9176229238510132
Validation loss: 2.1000339140494666

Epoch: 5| Step: 8
Training loss: 1.712011694908142
Validation loss: 2.1203768253326416

Epoch: 5| Step: 9
Training loss: 1.6897376775741577
Validation loss: 2.1288145383199057

Epoch: 5| Step: 10
Training loss: 1.6831544637680054
Validation loss: 2.1082043647766113

Epoch: 5| Step: 11
Training loss: 1.8411065340042114
Validation loss: 2.0906458546717963

Epoch: 126| Step: 0
Training loss: 1.6224524974822998
Validation loss: 2.084315483768781

Epoch: 5| Step: 1
Training loss: 2.6571357250213623
Validation loss: 2.0804575930039086

Epoch: 5| Step: 2
Training loss: 1.1952779293060303
Validation loss: 2.043634553750356

Epoch: 5| Step: 3
Training loss: 1.3674452304840088
Validation loss: 2.05961083372434

Epoch: 5| Step: 4
Training loss: 2.083718776702881
Validation loss: 2.067015235622724

Epoch: 5| Step: 5
Training loss: 1.5000810623168945
Validation loss: 2.058716540535291

Epoch: 5| Step: 6
Training loss: 1.3614693880081177
Validation loss: 2.047474483648936

Epoch: 5| Step: 7
Training loss: 1.9808223247528076
Validation loss: 2.059710587064425

Epoch: 5| Step: 8
Training loss: 2.1658544540405273
Validation loss: 2.0738133043050766

Epoch: 5| Step: 9
Training loss: 1.7036746740341187
Validation loss: 2.07789941628774

Epoch: 5| Step: 10
Training loss: 1.7287184000015259
Validation loss: 2.088436856865883

Epoch: 5| Step: 11
Training loss: 0.8655163049697876
Validation loss: 2.0881246527036033

Epoch: 127| Step: 0
Training loss: 1.810779333114624
Validation loss: 2.0600231885910034

Epoch: 5| Step: 1
Training loss: 1.9570461511611938
Validation loss: 2.103196437160174

Epoch: 5| Step: 2
Training loss: 1.4706838130950928
Validation loss: 2.0795561919609704

Epoch: 5| Step: 3
Training loss: 1.7725610733032227
Validation loss: 2.1125119477510452

Epoch: 5| Step: 4
Training loss: 1.0041239261627197
Validation loss: 2.0967645744482675

Epoch: 5| Step: 5
Training loss: 1.7376686334609985
Validation loss: 2.0783958981434503

Epoch: 5| Step: 6
Training loss: 1.6054185628890991
Validation loss: 2.0718669394652047

Epoch: 5| Step: 7
Training loss: 2.3815388679504395
Validation loss: 2.045936440428098

Epoch: 5| Step: 8
Training loss: 1.6998313665390015
Validation loss: 2.074746231238047

Epoch: 5| Step: 9
Training loss: 1.7919038534164429
Validation loss: 2.065035422643026

Epoch: 5| Step: 10
Training loss: 1.7438337802886963
Validation loss: 2.0658676425615945

Epoch: 5| Step: 11
Training loss: 2.5076465606689453
Validation loss: 2.094185933470726

Epoch: 128| Step: 0
Training loss: 1.4430592060089111
Validation loss: 2.1020783185958862

Epoch: 5| Step: 1
Training loss: 2.1985325813293457
Validation loss: 2.113047868013382

Epoch: 5| Step: 2
Training loss: 2.5757317543029785
Validation loss: 2.1160702208677926

Epoch: 5| Step: 3
Training loss: 1.2831816673278809
Validation loss: 2.12546277542909

Epoch: 5| Step: 4
Training loss: 1.2713873386383057
Validation loss: 2.1108142087856927

Epoch: 5| Step: 5
Training loss: 0.9555341005325317
Validation loss: 2.124363789955775

Epoch: 5| Step: 6
Training loss: 2.005523204803467
Validation loss: 2.101240615049998

Epoch: 5| Step: 7
Training loss: 1.837646484375
Validation loss: 2.0877512147029242

Epoch: 5| Step: 8
Training loss: 1.9413493871688843
Validation loss: 2.1167947947978973

Epoch: 5| Step: 9
Training loss: 1.5391952991485596
Validation loss: 2.0534279197454453

Epoch: 5| Step: 10
Training loss: 1.949986457824707
Validation loss: 2.0530835886796317

Epoch: 5| Step: 11
Training loss: 1.3827471733093262
Validation loss: 2.0506516695022583

Epoch: 129| Step: 0
Training loss: 1.341235876083374
Validation loss: 2.0719907929499946

Epoch: 5| Step: 1
Training loss: 1.740125298500061
Validation loss: 2.0333765099445977

Epoch: 5| Step: 2
Training loss: 1.6991033554077148
Validation loss: 2.0571682105461755

Epoch: 5| Step: 3
Training loss: 2.008920192718506
Validation loss: 2.0979437629381814

Epoch: 5| Step: 4
Training loss: 1.8568328619003296
Validation loss: 2.092845156788826

Epoch: 5| Step: 5
Training loss: 2.296854019165039
Validation loss: 2.107228323817253

Epoch: 5| Step: 6
Training loss: 1.7174081802368164
Validation loss: 2.1100122978289924

Epoch: 5| Step: 7
Training loss: 1.9392706155776978
Validation loss: 2.102626865108808

Epoch: 5| Step: 8
Training loss: 2.1859984397888184
Validation loss: 2.0902139196793237

Epoch: 5| Step: 9
Training loss: 1.2162424325942993
Validation loss: 2.1114686826864877

Epoch: 5| Step: 10
Training loss: 1.3436038494110107
Validation loss: 2.0961783727010093

Epoch: 5| Step: 11
Training loss: 1.0484764575958252
Validation loss: 2.0899479190508523

Epoch: 130| Step: 0
Training loss: 1.9738695621490479
Validation loss: 2.1062159538269043

Epoch: 5| Step: 1
Training loss: 1.63057541847229
Validation loss: 2.037186215321223

Epoch: 5| Step: 2
Training loss: 1.9694989919662476
Validation loss: 2.041334092617035

Epoch: 5| Step: 3
Training loss: 1.4493920803070068
Validation loss: 2.0435378551483154

Epoch: 5| Step: 4
Training loss: 1.5258387327194214
Validation loss: 2.0557333678007126

Epoch: 5| Step: 5
Training loss: 2.1919634342193604
Validation loss: 2.066639244556427

Epoch: 5| Step: 6
Training loss: 1.7413578033447266
Validation loss: 2.074911112586657

Epoch: 5| Step: 7
Training loss: 1.798654556274414
Validation loss: 2.049450238545736

Epoch: 5| Step: 8
Training loss: 1.5400670766830444
Validation loss: 2.055084764957428

Epoch: 5| Step: 9
Training loss: 1.6098897457122803
Validation loss: 2.070878396431605

Epoch: 5| Step: 10
Training loss: 1.7823712825775146
Validation loss: 2.0705895721912384

Epoch: 5| Step: 11
Training loss: 1.845404863357544
Validation loss: 2.0940670520067215

Epoch: 131| Step: 0
Training loss: 1.5284230709075928
Validation loss: 2.1116266399621964

Epoch: 5| Step: 1
Training loss: 1.6509466171264648
Validation loss: 2.15963077545166

Epoch: 5| Step: 2
Training loss: 1.3812952041625977
Validation loss: 2.1547731359799704

Epoch: 5| Step: 3
Training loss: 1.7663568258285522
Validation loss: 2.160899887482325

Epoch: 5| Step: 4
Training loss: 1.4611866474151611
Validation loss: 2.1348875711361566

Epoch: 5| Step: 5
Training loss: 1.6640026569366455
Validation loss: 2.1255493263403573

Epoch: 5| Step: 6
Training loss: 1.5982439517974854
Validation loss: 2.130387475093206

Epoch: 5| Step: 7
Training loss: 1.5841524600982666
Validation loss: 2.100779891014099

Epoch: 5| Step: 8
Training loss: 2.278902769088745
Validation loss: 2.0732115457455316

Epoch: 5| Step: 9
Training loss: 2.057218551635742
Validation loss: 2.1206129044294357

Epoch: 5| Step: 10
Training loss: 1.819504976272583
Validation loss: 2.1042256305615106

Epoch: 5| Step: 11
Training loss: 1.7709951400756836
Validation loss: 2.064383938908577

Epoch: 132| Step: 0
Training loss: 2.2612900733947754
Validation loss: 2.0376999378204346

Epoch: 5| Step: 1
Training loss: 1.5656245946884155
Validation loss: 2.034787426392237

Epoch: 5| Step: 2
Training loss: 1.7524677515029907
Validation loss: 2.057331229249636

Epoch: 5| Step: 3
Training loss: 1.7236716747283936
Validation loss: 2.0651401976744332

Epoch: 5| Step: 4
Training loss: 1.7281392812728882
Validation loss: 2.084485818942388

Epoch: 5| Step: 5
Training loss: 2.4925119876861572
Validation loss: 2.073096642891566

Epoch: 5| Step: 6
Training loss: 1.6092166900634766
Validation loss: 2.0624974916378656

Epoch: 5| Step: 7
Training loss: 1.0105841159820557
Validation loss: 2.1116141229867935

Epoch: 5| Step: 8
Training loss: 1.5582971572875977
Validation loss: 2.1314242084821067

Epoch: 5| Step: 9
Training loss: 1.8912327289581299
Validation loss: 2.1084420879681907

Epoch: 5| Step: 10
Training loss: 1.5813592672348022
Validation loss: 2.141077697277069

Epoch: 5| Step: 11
Training loss: 0.8065560460090637
Validation loss: 2.124935900171598

Epoch: 133| Step: 0
Training loss: 1.8799282312393188
Validation loss: 2.112015108267466

Epoch: 5| Step: 1
Training loss: 1.5360877513885498
Validation loss: 2.089187666773796

Epoch: 5| Step: 2
Training loss: 2.2212209701538086
Validation loss: 2.1270986795425415

Epoch: 5| Step: 3
Training loss: 1.687557578086853
Validation loss: 2.104936515291532

Epoch: 5| Step: 4
Training loss: 1.0220493078231812
Validation loss: 2.1008132795492807

Epoch: 5| Step: 5
Training loss: 1.6432454586029053
Validation loss: 2.094367802143097

Epoch: 5| Step: 6
Training loss: 1.532774806022644
Validation loss: 2.0619893968105316

Epoch: 5| Step: 7
Training loss: 1.1409164667129517
Validation loss: 2.0617327292760215

Epoch: 5| Step: 8
Training loss: 2.1249499320983887
Validation loss: 2.1213599741458893

Epoch: 5| Step: 9
Training loss: 1.5528843402862549
Validation loss: 2.129884089032809

Epoch: 5| Step: 10
Training loss: 2.0836639404296875
Validation loss: 2.1180118719736734

Epoch: 5| Step: 11
Training loss: 2.0653021335601807
Validation loss: 2.149112562338511

Epoch: 134| Step: 0
Training loss: 1.5085688829421997
Validation loss: 2.1186632762352624

Epoch: 5| Step: 1
Training loss: 1.5379588603973389
Validation loss: 2.112282852331797

Epoch: 5| Step: 2
Training loss: 2.070164918899536
Validation loss: 2.11844938993454

Epoch: 5| Step: 3
Training loss: 1.6916773319244385
Validation loss: 2.093428134918213

Epoch: 5| Step: 4
Training loss: 2.3189523220062256
Validation loss: 2.0864564329385757

Epoch: 5| Step: 5
Training loss: 1.7360016107559204
Validation loss: 2.0974993854761124

Epoch: 5| Step: 6
Training loss: 1.5893142223358154
Validation loss: 2.089515045285225

Epoch: 5| Step: 7
Training loss: 1.319732427597046
Validation loss: 2.089317411184311

Epoch: 5| Step: 8
Training loss: 1.251258134841919
Validation loss: 2.080356314778328

Epoch: 5| Step: 9
Training loss: 2.0076828002929688
Validation loss: 2.0835845470428467

Epoch: 5| Step: 10
Training loss: 1.4568836688995361
Validation loss: 2.064961145321528

Epoch: 5| Step: 11
Training loss: 1.2450028657913208
Validation loss: 2.078676536679268

Epoch: 135| Step: 0
Training loss: 1.4515740871429443
Validation loss: 2.1026507019996643

Epoch: 5| Step: 1
Training loss: 1.8236873149871826
Validation loss: 2.145519365866979

Epoch: 5| Step: 2
Training loss: 1.3726991415023804
Validation loss: 2.1050591419140496

Epoch: 5| Step: 3
Training loss: 1.139193058013916
Validation loss: 2.1051277865966163

Epoch: 5| Step: 4
Training loss: 1.9955594539642334
Validation loss: 2.1215646862983704

Epoch: 5| Step: 5
Training loss: 1.5051944255828857
Validation loss: 2.1295472035805383

Epoch: 5| Step: 6
Training loss: 2.7686705589294434
Validation loss: 2.1219341655572257

Epoch: 5| Step: 7
Training loss: 1.5027492046356201
Validation loss: 2.114660774668058

Epoch: 5| Step: 8
Training loss: 1.1690349578857422
Validation loss: 2.107666557033857

Epoch: 5| Step: 9
Training loss: 1.5097572803497314
Validation loss: 2.091531351208687

Epoch: 5| Step: 10
Training loss: 2.093059778213501
Validation loss: 2.0866676966349282

Epoch: 5| Step: 11
Training loss: 1.3769927024841309
Validation loss: 2.0769431640704474

Epoch: 136| Step: 0
Training loss: 1.1570782661437988
Validation loss: 2.0957632809877396

Epoch: 5| Step: 1
Training loss: 1.8172543048858643
Validation loss: 2.0979308585325875

Epoch: 5| Step: 2
Training loss: 1.391120195388794
Validation loss: 2.121191223462423

Epoch: 5| Step: 3
Training loss: 1.612370491027832
Validation loss: 2.1171935697396598

Epoch: 5| Step: 4
Training loss: 1.7641674280166626
Validation loss: 2.0980376650889716

Epoch: 5| Step: 5
Training loss: 2.482950448989868
Validation loss: 2.080623214443525

Epoch: 5| Step: 6
Training loss: 1.638769507408142
Validation loss: 2.088657110929489

Epoch: 5| Step: 7
Training loss: 1.5293498039245605
Validation loss: 2.0894858986139297

Epoch: 5| Step: 8
Training loss: 1.7511694431304932
Validation loss: 2.108701397975286

Epoch: 5| Step: 9
Training loss: 1.7938086986541748
Validation loss: 2.0939134856065116

Epoch: 5| Step: 10
Training loss: 1.533653974533081
Validation loss: 2.120911419391632

Epoch: 5| Step: 11
Training loss: 0.6650317311286926
Validation loss: 2.1156761795282364

Epoch: 137| Step: 0
Training loss: 1.3607271909713745
Validation loss: 2.0458801736434302

Epoch: 5| Step: 1
Training loss: 1.9921016693115234
Validation loss: 2.0615433851877847

Epoch: 5| Step: 2
Training loss: 1.6817424297332764
Validation loss: 2.0570282290379205

Epoch: 5| Step: 3
Training loss: 1.9887866973876953
Validation loss: 2.0575439731280007

Epoch: 5| Step: 4
Training loss: 1.720323920249939
Validation loss: 2.039548089106878

Epoch: 5| Step: 5
Training loss: 1.5776246786117554
Validation loss: 2.025497486193975

Epoch: 5| Step: 6
Training loss: 1.9782993793487549
Validation loss: 2.066585158308347

Epoch: 5| Step: 7
Training loss: 1.56598961353302
Validation loss: 2.0742807437976203

Epoch: 5| Step: 8
Training loss: 1.336411714553833
Validation loss: 2.1134522457917533

Epoch: 5| Step: 9
Training loss: 1.698581337928772
Validation loss: 2.106834272543589

Epoch: 5| Step: 10
Training loss: 2.022012233734131
Validation loss: 2.1057522346576056

Epoch: 5| Step: 11
Training loss: 1.1956586837768555
Validation loss: 2.0837135364611945

Epoch: 138| Step: 0
Training loss: 1.6738983392715454
Validation loss: 2.11027991771698

Epoch: 5| Step: 1
Training loss: 1.6395502090454102
Validation loss: 2.0786992957194648

Epoch: 5| Step: 2
Training loss: 1.869251012802124
Validation loss: 2.0667563478151956

Epoch: 5| Step: 3
Training loss: 1.5987282991409302
Validation loss: 2.0781362851460776

Epoch: 5| Step: 4
Training loss: 1.2036699056625366
Validation loss: 2.081143538157145

Epoch: 5| Step: 5
Training loss: 1.8607057332992554
Validation loss: 2.0892503708601

Epoch: 5| Step: 6
Training loss: 1.965574860572815
Validation loss: 2.0955937753121057

Epoch: 5| Step: 7
Training loss: 1.3491746187210083
Validation loss: 2.05904887119929

Epoch: 5| Step: 8
Training loss: 1.2590476274490356
Validation loss: 2.0964407175779343

Epoch: 5| Step: 9
Training loss: 1.9945602416992188
Validation loss: 2.092714170614878

Epoch: 5| Step: 10
Training loss: 1.5526137351989746
Validation loss: 2.06659563879172

Epoch: 5| Step: 11
Training loss: 1.7896182537078857
Validation loss: 2.0597756803035736

Epoch: 139| Step: 0
Training loss: 1.1004871129989624
Validation loss: 2.0802227507034936

Epoch: 5| Step: 1
Training loss: 2.5195536613464355
Validation loss: 2.1102176755666733

Epoch: 5| Step: 2
Training loss: 1.582319736480713
Validation loss: 2.1062216609716415

Epoch: 5| Step: 3
Training loss: 1.6389353275299072
Validation loss: 2.1167823324600854

Epoch: 5| Step: 4
Training loss: 1.7282397747039795
Validation loss: 2.091676672299703

Epoch: 5| Step: 5
Training loss: 1.7821595668792725
Validation loss: 2.1058528125286102

Epoch: 5| Step: 6
Training loss: 1.7083936929702759
Validation loss: 2.1025145749251046

Epoch: 5| Step: 7
Training loss: 1.3522319793701172
Validation loss: 2.1060869892438254

Epoch: 5| Step: 8
Training loss: 1.3284447193145752
Validation loss: 2.087176655729612

Epoch: 5| Step: 9
Training loss: 1.7111504077911377
Validation loss: 2.057542771100998

Epoch: 5| Step: 10
Training loss: 1.4242446422576904
Validation loss: 2.0721619576215744

Epoch: 5| Step: 11
Training loss: 2.0912628173828125
Validation loss: 2.070230891307195

Epoch: 140| Step: 0
Training loss: 1.244624137878418
Validation loss: 2.099531352519989

Epoch: 5| Step: 1
Training loss: 1.5712566375732422
Validation loss: 2.116066108147303

Epoch: 5| Step: 2
Training loss: 1.1149451732635498
Validation loss: 2.142834926644961

Epoch: 5| Step: 3
Training loss: 2.202519655227661
Validation loss: 2.1780524601538978

Epoch: 5| Step: 4
Training loss: 1.4076590538024902
Validation loss: 2.1767548422018685

Epoch: 5| Step: 5
Training loss: 1.8009830713272095
Validation loss: 2.181735853354136

Epoch: 5| Step: 6
Training loss: 1.9652440547943115
Validation loss: 2.1749028861522675

Epoch: 5| Step: 7
Training loss: 2.013258457183838
Validation loss: 2.1858381430308023

Epoch: 5| Step: 8
Training loss: 1.6402778625488281
Validation loss: 2.147781491279602

Epoch: 5| Step: 9
Training loss: 1.6702802181243896
Validation loss: 2.167925571401914

Epoch: 5| Step: 10
Training loss: 1.5339455604553223
Validation loss: 2.104667733112971

Epoch: 5| Step: 11
Training loss: 1.9451498985290527
Validation loss: 2.0796521256367364

Epoch: 141| Step: 0
Training loss: 1.7284812927246094
Validation loss: 2.089334636926651

Epoch: 5| Step: 1
Training loss: 2.0888772010803223
Validation loss: 2.057745178540548

Epoch: 5| Step: 2
Training loss: 1.9863519668579102
Validation loss: 2.0797850588957467

Epoch: 5| Step: 3
Training loss: 1.6323859691619873
Validation loss: 2.041807934641838

Epoch: 5| Step: 4
Training loss: 1.6123043298721313
Validation loss: 2.0776891161998114

Epoch: 5| Step: 5
Training loss: 1.1428134441375732
Validation loss: 2.0798659722010293

Epoch: 5| Step: 6
Training loss: 2.171821117401123
Validation loss: 2.103027358651161

Epoch: 5| Step: 7
Training loss: 1.3107423782348633
Validation loss: 2.065017600854238

Epoch: 5| Step: 8
Training loss: 1.5365228652954102
Validation loss: 2.0672405809164047

Epoch: 5| Step: 9
Training loss: 1.524155855178833
Validation loss: 2.091193735599518

Epoch: 5| Step: 10
Training loss: 1.4814445972442627
Validation loss: 2.0591690689325333

Epoch: 5| Step: 11
Training loss: 0.24286115169525146
Validation loss: 2.0987972070773444

Epoch: 142| Step: 0
Training loss: 1.4641815423965454
Validation loss: 2.086497589945793

Epoch: 5| Step: 1
Training loss: 1.506928563117981
Validation loss: 2.1059052646160126

Epoch: 5| Step: 2
Training loss: 1.7024672031402588
Validation loss: 2.12458303074042

Epoch: 5| Step: 3
Training loss: 1.1685278415679932
Validation loss: 2.07923956712087

Epoch: 5| Step: 4
Training loss: 2.0128326416015625
Validation loss: 2.0914136519034705

Epoch: 5| Step: 5
Training loss: 2.141317367553711
Validation loss: 2.0963368018468223

Epoch: 5| Step: 6
Training loss: 2.161536455154419
Validation loss: 2.0729931642611823

Epoch: 5| Step: 7
Training loss: 1.422048568725586
Validation loss: 2.0821010917425156

Epoch: 5| Step: 8
Training loss: 0.927233099937439
Validation loss: 2.0762807726860046

Epoch: 5| Step: 9
Training loss: 2.0031819343566895
Validation loss: 2.0983283718427024

Epoch: 5| Step: 10
Training loss: 1.3583202362060547
Validation loss: 2.0964545657237372

Epoch: 5| Step: 11
Training loss: 1.283595085144043
Validation loss: 2.116080090403557

Epoch: 143| Step: 0
Training loss: 1.3554041385650635
Validation loss: 2.110851695140203

Epoch: 5| Step: 1
Training loss: 1.2462598085403442
Validation loss: 2.1658091147740683

Epoch: 5| Step: 2
Training loss: 1.8578722476959229
Validation loss: 2.2133603940407434

Epoch: 5| Step: 3
Training loss: 1.827383279800415
Validation loss: 2.217019940416018

Epoch: 5| Step: 4
Training loss: 1.7163019180297852
Validation loss: 2.215845286846161

Epoch: 5| Step: 5
Training loss: 1.6409120559692383
Validation loss: 2.199486414591471

Epoch: 5| Step: 6
Training loss: 1.4172130823135376
Validation loss: 2.2015016923348107

Epoch: 5| Step: 7
Training loss: 1.2756294012069702
Validation loss: 2.13507878780365

Epoch: 5| Step: 8
Training loss: 1.7388206720352173
Validation loss: 2.0990906357765198

Epoch: 5| Step: 9
Training loss: 1.8253729343414307
Validation loss: 2.0694554994503656

Epoch: 5| Step: 10
Training loss: 2.0640642642974854
Validation loss: 2.077717666824659

Epoch: 5| Step: 11
Training loss: 2.2186295986175537
Validation loss: 2.098631958166758

Epoch: 144| Step: 0
Training loss: 1.7294756174087524
Validation loss: 2.0365208834409714

Epoch: 5| Step: 1
Training loss: 1.645376443862915
Validation loss: 2.0722158402204514

Epoch: 5| Step: 2
Training loss: 1.39357590675354
Validation loss: 2.0607716540495553

Epoch: 5| Step: 3
Training loss: 1.7616736888885498
Validation loss: 2.0566720763842263

Epoch: 5| Step: 4
Training loss: 1.5564390420913696
Validation loss: 2.067838271458944

Epoch: 5| Step: 5
Training loss: 1.9433362483978271
Validation loss: 2.065293997526169

Epoch: 5| Step: 6
Training loss: 1.721555471420288
Validation loss: 2.068304866552353

Epoch: 5| Step: 7
Training loss: 1.667968988418579
Validation loss: 2.064808721343676

Epoch: 5| Step: 8
Training loss: 1.4341696500778198
Validation loss: 2.0950961162646613

Epoch: 5| Step: 9
Training loss: 2.079085350036621
Validation loss: 2.1252823024988174

Epoch: 5| Step: 10
Training loss: 1.9271491765975952
Validation loss: 2.1299886306126914

Epoch: 5| Step: 11
Training loss: 0.8970401287078857
Validation loss: 2.1887392898400626

Epoch: 145| Step: 0
Training loss: 1.7362995147705078
Validation loss: 2.1752130538225174

Epoch: 5| Step: 1
Training loss: 1.8188974857330322
Validation loss: 2.154014458258947

Epoch: 5| Step: 2
Training loss: 1.6321099996566772
Validation loss: 2.146258776386579

Epoch: 5| Step: 3
Training loss: 1.5094797611236572
Validation loss: 2.098576252659162

Epoch: 5| Step: 4
Training loss: 1.716493010520935
Validation loss: 2.0490089058876038

Epoch: 5| Step: 5
Training loss: 2.1751277446746826
Validation loss: 2.0663954466581345

Epoch: 5| Step: 6
Training loss: 1.3538789749145508
Validation loss: 2.0695511996746063

Epoch: 5| Step: 7
Training loss: 1.7631851434707642
Validation loss: 2.0613288233677545

Epoch: 5| Step: 8
Training loss: 1.4140799045562744
Validation loss: 2.0461558053890863

Epoch: 5| Step: 9
Training loss: 1.8468414545059204
Validation loss: 2.0735029925902686

Epoch: 5| Step: 10
Training loss: 1.2106187343597412
Validation loss: 2.084879716237386

Epoch: 5| Step: 11
Training loss: 1.0882182121276855
Validation loss: 2.073792273799578

Epoch: 146| Step: 0
Training loss: 1.733227014541626
Validation loss: 2.069636821746826

Epoch: 5| Step: 1
Training loss: 2.022467613220215
Validation loss: 2.1815597116947174

Epoch: 5| Step: 2
Training loss: 1.9301111698150635
Validation loss: 2.1485459059476852

Epoch: 5| Step: 3
Training loss: 1.6191154718399048
Validation loss: 2.2020236402750015

Epoch: 5| Step: 4
Training loss: 1.9171394109725952
Validation loss: 2.2534390737613044

Epoch: 5| Step: 5
Training loss: 1.653622031211853
Validation loss: 2.2293816655874252

Epoch: 5| Step: 6
Training loss: 1.5813432931900024
Validation loss: 2.2527835071086884

Epoch: 5| Step: 7
Training loss: 1.315139889717102
Validation loss: 2.2478325963020325

Epoch: 5| Step: 8
Training loss: 1.4348050355911255
Validation loss: 2.1770331660906472

Epoch: 5| Step: 9
Training loss: 1.4455783367156982
Validation loss: 2.1398943265279136

Epoch: 5| Step: 10
Training loss: 1.8771547079086304
Validation loss: 2.0857096314430237

Epoch: 5| Step: 11
Training loss: 0.6448854804039001
Validation loss: 2.0772366523742676

Epoch: 147| Step: 0
Training loss: 2.110365390777588
Validation loss: 2.056945542494456

Epoch: 5| Step: 1
Training loss: 1.70758056640625
Validation loss: 2.0510179003079734

Epoch: 5| Step: 2
Training loss: 1.9853054285049438
Validation loss: 2.0829093853632608

Epoch: 5| Step: 3
Training loss: 1.7290561199188232
Validation loss: 2.0813677509625754

Epoch: 5| Step: 4
Training loss: 1.8264716863632202
Validation loss: 2.067076250910759

Epoch: 5| Step: 5
Training loss: 1.6933314800262451
Validation loss: 2.068320711453756

Epoch: 5| Step: 6
Training loss: 2.033017635345459
Validation loss: 2.0514115194479623

Epoch: 5| Step: 7
Training loss: 1.1625254154205322
Validation loss: 2.0723940481742225

Epoch: 5| Step: 8
Training loss: 1.6543724536895752
Validation loss: 2.035568336645762

Epoch: 5| Step: 9
Training loss: 1.394208550453186
Validation loss: 2.11235744257768

Epoch: 5| Step: 10
Training loss: 1.092315673828125
Validation loss: 2.0958562393983207

Epoch: 5| Step: 11
Training loss: 2.1264185905456543
Validation loss: 2.1103304624557495

Epoch: 148| Step: 0
Training loss: 2.0979456901550293
Validation loss: 2.1453562676906586

Epoch: 5| Step: 1
Training loss: 1.3773072957992554
Validation loss: 2.136453519264857

Epoch: 5| Step: 2
Training loss: 0.7289537191390991
Validation loss: 2.1264431873957315

Epoch: 5| Step: 3
Training loss: 2.129957675933838
Validation loss: 2.1185033718744912

Epoch: 5| Step: 4
Training loss: 1.1377718448638916
Validation loss: 2.1476828157901764

Epoch: 5| Step: 5
Training loss: 1.7170403003692627
Validation loss: 2.0985497385263443

Epoch: 5| Step: 6
Training loss: 2.068075656890869
Validation loss: 2.118109186490377

Epoch: 5| Step: 7
Training loss: 1.5218756198883057
Validation loss: 2.0836668809254966

Epoch: 5| Step: 8
Training loss: 1.7738447189331055
Validation loss: 2.1175892452398934

Epoch: 5| Step: 9
Training loss: 1.5343793630599976
Validation loss: 2.0801841765642166

Epoch: 5| Step: 10
Training loss: 1.3675554990768433
Validation loss: 2.0760469933350882

Epoch: 5| Step: 11
Training loss: 1.5652186870574951
Validation loss: 2.062520051995913

Epoch: 149| Step: 0
Training loss: 1.7102683782577515
Validation loss: 2.061016177137693

Epoch: 5| Step: 1
Training loss: 1.6568000316619873
Validation loss: 2.070249413450559

Epoch: 5| Step: 2
Training loss: 1.3510706424713135
Validation loss: 2.0537394980589547

Epoch: 5| Step: 3
Training loss: 1.9216029644012451
Validation loss: 2.075779154896736

Epoch: 5| Step: 4
Training loss: 1.2803623676300049
Validation loss: 2.074718584616979

Epoch: 5| Step: 5
Training loss: 1.7883110046386719
Validation loss: 2.102912207444509

Epoch: 5| Step: 6
Training loss: 1.2096669673919678
Validation loss: 2.1018668512503305

Epoch: 5| Step: 7
Training loss: 1.6639143228530884
Validation loss: 2.118540475765864

Epoch: 5| Step: 8
Training loss: 1.1935055255889893
Validation loss: 2.1453053851922355

Epoch: 5| Step: 9
Training loss: 1.7281932830810547
Validation loss: 2.12663471698761

Epoch: 5| Step: 10
Training loss: 1.7270187139511108
Validation loss: 2.1012013852596283

Epoch: 5| Step: 11
Training loss: 1.118707537651062
Validation loss: 2.1110620448986688

Epoch: 150| Step: 0
Training loss: 1.2889429330825806
Validation loss: 2.0739966134230294

Epoch: 5| Step: 1
Training loss: 1.4674988985061646
Validation loss: 2.0655432840188346

Epoch: 5| Step: 2
Training loss: 1.9031178951263428
Validation loss: 2.0957253774007163

Epoch: 5| Step: 3
Training loss: 1.466126799583435
Validation loss: 2.092807168761889

Epoch: 5| Step: 4
Training loss: 1.5687214136123657
Validation loss: 2.141934871673584

Epoch: 5| Step: 5
Training loss: 1.7078174352645874
Validation loss: 2.0924201061328254

Epoch: 5| Step: 6
Training loss: 1.5725219249725342
Validation loss: 2.1080107192198434

Epoch: 5| Step: 7
Training loss: 1.4892165660858154
Validation loss: 2.101076846321424

Epoch: 5| Step: 8
Training loss: 1.5916328430175781
Validation loss: 2.0853051245212555

Epoch: 5| Step: 9
Training loss: 1.427914023399353
Validation loss: 2.101969987154007

Epoch: 5| Step: 10
Training loss: 1.574721336364746
Validation loss: 2.104765002926191

Epoch: 5| Step: 11
Training loss: 1.459938406944275
Validation loss: 2.100748216112455

Epoch: 151| Step: 0
Training loss: 2.0431292057037354
Validation loss: 2.0634365727504096

Epoch: 5| Step: 1
Training loss: 1.6195478439331055
Validation loss: 2.0630232195059457

Epoch: 5| Step: 2
Training loss: 1.4251664876937866
Validation loss: 2.105530232191086

Epoch: 5| Step: 3
Training loss: 1.9426405429840088
Validation loss: 2.0933354943990707

Epoch: 5| Step: 4
Training loss: 1.2739403247833252
Validation loss: 2.062793438633283

Epoch: 5| Step: 5
Training loss: 1.8311790227890015
Validation loss: 2.0851741582155228

Epoch: 5| Step: 6
Training loss: 1.359100341796875
Validation loss: 2.0614509085814157

Epoch: 5| Step: 7
Training loss: 1.8539139032363892
Validation loss: 2.088579093416532

Epoch: 5| Step: 8
Training loss: 0.9927921295166016
Validation loss: 2.0986727525790534

Epoch: 5| Step: 9
Training loss: 1.2380640506744385
Validation loss: 2.134988804658254

Epoch: 5| Step: 10
Training loss: 1.6835148334503174
Validation loss: 2.142596503098806

Epoch: 5| Step: 11
Training loss: 0.30066633224487305
Validation loss: 2.114032352964083

Epoch: 152| Step: 0
Training loss: 1.7155416011810303
Validation loss: 2.12990839779377

Epoch: 5| Step: 1
Training loss: 1.4065868854522705
Validation loss: 2.03703739742438

Epoch: 5| Step: 2
Training loss: 1.2686493396759033
Validation loss: 2.0575685501098633

Epoch: 5| Step: 3
Training loss: 1.7895400524139404
Validation loss: 2.0385338018337884

Epoch: 5| Step: 4
Training loss: 1.5205892324447632
Validation loss: 2.068652222553889

Epoch: 5| Step: 5
Training loss: 1.12064528465271
Validation loss: 2.0760799795389175

Epoch: 5| Step: 6
Training loss: 1.9879226684570312
Validation loss: 2.0614376962184906

Epoch: 5| Step: 7
Training loss: 1.4933605194091797
Validation loss: 2.0751544137795768

Epoch: 5| Step: 8
Training loss: 1.4259161949157715
Validation loss: 2.074959839383761

Epoch: 5| Step: 9
Training loss: 1.5891624689102173
Validation loss: 2.0894470711549125

Epoch: 5| Step: 10
Training loss: 2.0577495098114014
Validation loss: 2.102695350845655

Epoch: 5| Step: 11
Training loss: 1.0878901481628418
Validation loss: 2.1079437186320624

Epoch: 153| Step: 0
Training loss: 1.7042310237884521
Validation loss: 2.1206601411104202

Epoch: 5| Step: 1
Training loss: 1.6941559314727783
Validation loss: 2.132411534587542

Epoch: 5| Step: 2
Training loss: 1.4606971740722656
Validation loss: 2.1265860547622046

Epoch: 5| Step: 3
Training loss: 1.3759443759918213
Validation loss: 2.115939219792684

Epoch: 5| Step: 4
Training loss: 1.6163976192474365
Validation loss: 2.100085566441218

Epoch: 5| Step: 5
Training loss: 1.5551745891571045
Validation loss: 2.075111841162046

Epoch: 5| Step: 6
Training loss: 1.6708166599273682
Validation loss: 2.0870110988616943

Epoch: 5| Step: 7
Training loss: 1.3291401863098145
Validation loss: 2.052815596262614

Epoch: 5| Step: 8
Training loss: 1.5493221282958984
Validation loss: 2.043325290083885

Epoch: 5| Step: 9
Training loss: 1.4001731872558594
Validation loss: 2.093196620543798

Epoch: 5| Step: 10
Training loss: 1.400789499282837
Validation loss: 2.073460176587105

Epoch: 5| Step: 11
Training loss: 3.0966334342956543
Validation loss: 2.1298136860132217

Epoch: 154| Step: 0
Training loss: 1.3284401893615723
Validation loss: 2.1541725993156433

Epoch: 5| Step: 1
Training loss: 1.464163064956665
Validation loss: 2.1323427657286325

Epoch: 5| Step: 2
Training loss: 1.2826671600341797
Validation loss: 2.1899760911862054

Epoch: 5| Step: 3
Training loss: 1.4168404340744019
Validation loss: 2.1774351000785828

Epoch: 5| Step: 4
Training loss: 1.153731107711792
Validation loss: 2.183517982562383

Epoch: 5| Step: 5
Training loss: 2.3417716026306152
Validation loss: 2.13919398188591

Epoch: 5| Step: 6
Training loss: 1.2890280485153198
Validation loss: 2.094429617126783

Epoch: 5| Step: 7
Training loss: 0.8927736282348633
Validation loss: 2.1027721663316092

Epoch: 5| Step: 8
Training loss: 1.7581684589385986
Validation loss: 2.086694603164991

Epoch: 5| Step: 9
Training loss: 1.9355747699737549
Validation loss: 2.0867561797300973

Epoch: 5| Step: 10
Training loss: 1.8445606231689453
Validation loss: 2.056242590149244

Epoch: 5| Step: 11
Training loss: 2.7220115661621094
Validation loss: 2.045480822523435

Epoch: 155| Step: 0
Training loss: 1.65475332736969
Validation loss: 2.0677177061637244

Epoch: 5| Step: 1
Training loss: 1.5376126766204834
Validation loss: 2.062251389026642

Epoch: 5| Step: 2
Training loss: 1.7492589950561523
Validation loss: 2.0691266506910324

Epoch: 5| Step: 3
Training loss: 1.5038697719573975
Validation loss: 2.0644065688053765

Epoch: 5| Step: 4
Training loss: 1.7922439575195312
Validation loss: 2.0977026174465814

Epoch: 5| Step: 5
Training loss: 1.5165178775787354
Validation loss: 2.0649991929531097

Epoch: 5| Step: 6
Training loss: 1.1104047298431396
Validation loss: 2.0568928023179374

Epoch: 5| Step: 7
Training loss: 1.8193504810333252
Validation loss: 2.061553423603376

Epoch: 5| Step: 8
Training loss: 1.2929474115371704
Validation loss: 2.086958631873131

Epoch: 5| Step: 9
Training loss: 1.3949613571166992
Validation loss: 2.0848552783330283

Epoch: 5| Step: 10
Training loss: 1.6615623235702515
Validation loss: 2.149753530820211

Epoch: 5| Step: 11
Training loss: 2.2497806549072266
Validation loss: 2.19169474641482

Epoch: 156| Step: 0
Training loss: 1.5166282653808594
Validation loss: 2.166082168618838

Epoch: 5| Step: 1
Training loss: 1.7790710926055908
Validation loss: 2.1960393289724984

Epoch: 5| Step: 2
Training loss: 1.6072006225585938
Validation loss: 2.1781385242938995

Epoch: 5| Step: 3
Training loss: 1.4783662557601929
Validation loss: 2.158468638857206

Epoch: 5| Step: 4
Training loss: 1.149109959602356
Validation loss: 2.1445480485757193

Epoch: 5| Step: 5
Training loss: 1.0620243549346924
Validation loss: 2.106146271030108

Epoch: 5| Step: 6
Training loss: 1.2468417882919312
Validation loss: 2.0701836993296943

Epoch: 5| Step: 7
Training loss: 1.5018060207366943
Validation loss: 2.0643385847409568

Epoch: 5| Step: 8
Training loss: 1.6330333948135376
Validation loss: 2.053572108348211

Epoch: 5| Step: 9
Training loss: 2.1571784019470215
Validation loss: 2.066347435116768

Epoch: 5| Step: 10
Training loss: 1.8652217388153076
Validation loss: 2.0544421325127282

Epoch: 5| Step: 11
Training loss: 1.8350088596343994
Validation loss: 2.056949953238169

Epoch: 157| Step: 0
Training loss: 1.5859378576278687
Validation loss: 2.08767901857694

Epoch: 5| Step: 1
Training loss: 1.458885669708252
Validation loss: 2.0625404566526413

Epoch: 5| Step: 2
Training loss: 1.6966100931167603
Validation loss: 2.132361799478531

Epoch: 5| Step: 3
Training loss: 1.531039834022522
Validation loss: 2.1609148532152176

Epoch: 5| Step: 4
Training loss: 1.9136368036270142
Validation loss: 2.162878170609474

Epoch: 5| Step: 5
Training loss: 2.1749672889709473
Validation loss: 2.1422659307718277

Epoch: 5| Step: 6
Training loss: 1.5121204853057861
Validation loss: 2.1478688567876816

Epoch: 5| Step: 7
Training loss: 1.1442086696624756
Validation loss: 2.140395477414131

Epoch: 5| Step: 8
Training loss: 1.2604645490646362
Validation loss: 2.1183131088813147

Epoch: 5| Step: 9
Training loss: 1.259101152420044
Validation loss: 2.1371890058120093

Epoch: 5| Step: 10
Training loss: 1.1934831142425537
Validation loss: 2.1256744116544724

Epoch: 5| Step: 11
Training loss: 0.8295546770095825
Validation loss: 2.077003926038742

Epoch: 158| Step: 0
Training loss: 1.1393930912017822
Validation loss: 2.1210929850737252

Epoch: 5| Step: 1
Training loss: 2.0557003021240234
Validation loss: 2.130095660686493

Epoch: 5| Step: 2
Training loss: 1.3721039295196533
Validation loss: 2.1235768844683967

Epoch: 5| Step: 3
Training loss: 2.159662961959839
Validation loss: 2.108018716176351

Epoch: 5| Step: 4
Training loss: 1.560274600982666
Validation loss: 2.109013353784879

Epoch: 5| Step: 5
Training loss: 1.5832126140594482
Validation loss: 2.102597802877426

Epoch: 5| Step: 6
Training loss: 1.2933391332626343
Validation loss: 2.1110560595989227

Epoch: 5| Step: 7
Training loss: 1.2289974689483643
Validation loss: 2.0904532819986343

Epoch: 5| Step: 8
Training loss: 1.6178315877914429
Validation loss: 2.0629408061504364

Epoch: 5| Step: 9
Training loss: 1.320007562637329
Validation loss: 2.0656908253828683

Epoch: 5| Step: 10
Training loss: 1.2635301351547241
Validation loss: 2.0896450728178024

Epoch: 5| Step: 11
Training loss: 1.2177674770355225
Validation loss: 2.125273664792379

Epoch: 159| Step: 0
Training loss: 1.5274988412857056
Validation loss: 2.104642147819201

Epoch: 5| Step: 1
Training loss: 1.425950527191162
Validation loss: 2.121671269337336

Epoch: 5| Step: 2
Training loss: 1.41062331199646
Validation loss: 2.128430505593618

Epoch: 5| Step: 3
Training loss: 1.1535941362380981
Validation loss: 2.1264751007159552

Epoch: 5| Step: 4
Training loss: 1.1996046304702759
Validation loss: 2.1081095933914185

Epoch: 5| Step: 5
Training loss: 1.3558719158172607
Validation loss: 2.0760736564795175

Epoch: 5| Step: 6
Training loss: 1.5924303531646729
Validation loss: 2.0738368183374405

Epoch: 5| Step: 7
Training loss: 1.868599534034729
Validation loss: 2.093023806810379

Epoch: 5| Step: 8
Training loss: 1.2043657302856445
Validation loss: 2.0530924052000046

Epoch: 5| Step: 9
Training loss: 1.942918062210083
Validation loss: 2.0737932870785394

Epoch: 5| Step: 10
Training loss: 1.2473093271255493
Validation loss: 2.066213587919871

Epoch: 5| Step: 11
Training loss: 3.518237590789795
Validation loss: 2.089488128821055

Epoch: 160| Step: 0
Training loss: 1.1641299724578857
Validation loss: 2.11012597878774

Epoch: 5| Step: 1
Training loss: 1.0903414487838745
Validation loss: 2.131524940331777

Epoch: 5| Step: 2
Training loss: 1.7224071025848389
Validation loss: 2.1080588648716607

Epoch: 5| Step: 3
Training loss: 1.426645278930664
Validation loss: 2.1167224645614624

Epoch: 5| Step: 4
Training loss: 1.73760187625885
Validation loss: 2.1263965169588723

Epoch: 5| Step: 5
Training loss: 0.9666112065315247
Validation loss: 2.0958866278330484

Epoch: 5| Step: 6
Training loss: 1.3754193782806396
Validation loss: 2.1016861647367477

Epoch: 5| Step: 7
Training loss: 1.8862626552581787
Validation loss: 2.067481199900309

Epoch: 5| Step: 8
Training loss: 1.3944345712661743
Validation loss: 2.1148793945709863

Epoch: 5| Step: 9
Training loss: 1.8770250082015991
Validation loss: 2.129350001613299

Epoch: 5| Step: 10
Training loss: 1.70989191532135
Validation loss: 2.094148099422455

Epoch: 5| Step: 11
Training loss: 1.7665835618972778
Validation loss: 2.086105634768804

Epoch: 161| Step: 0
Training loss: 2.1185877323150635
Validation loss: 2.0861236999432244

Epoch: 5| Step: 1
Training loss: 0.9521317481994629
Validation loss: 2.097610672314962

Epoch: 5| Step: 2
Training loss: 1.1965055465698242
Validation loss: 2.0697223593791327

Epoch: 5| Step: 3
Training loss: 1.2777042388916016
Validation loss: 2.084965651233991

Epoch: 5| Step: 4
Training loss: 1.6353927850723267
Validation loss: 2.1183867156505585

Epoch: 5| Step: 5
Training loss: 1.4948875904083252
Validation loss: 2.139871895313263

Epoch: 5| Step: 6
Training loss: 1.3938720226287842
Validation loss: 2.1154564221700034

Epoch: 5| Step: 7
Training loss: 1.392485499382019
Validation loss: 2.150601347287496

Epoch: 5| Step: 8
Training loss: 1.5596942901611328
Validation loss: 2.1438558995723724

Epoch: 5| Step: 9
Training loss: 1.777889609336853
Validation loss: 2.166109730799993

Epoch: 5| Step: 10
Training loss: 1.4667435884475708
Validation loss: 2.1468572417894998

Epoch: 5| Step: 11
Training loss: 0.9620790481567383
Validation loss: 2.157527893781662

Epoch: 162| Step: 0
Training loss: 1.568829894065857
Validation loss: 2.1143184155225754

Epoch: 5| Step: 1
Training loss: 1.3666355609893799
Validation loss: 2.127939601739248

Epoch: 5| Step: 2
Training loss: 2.0833182334899902
Validation loss: 2.1469722539186478

Epoch: 5| Step: 3
Training loss: 1.741502046585083
Validation loss: 2.1106187949577966

Epoch: 5| Step: 4
Training loss: 0.7905627489089966
Validation loss: 2.0759912381569543

Epoch: 5| Step: 5
Training loss: 1.178754448890686
Validation loss: 2.0755007565021515

Epoch: 5| Step: 6
Training loss: 1.1270530223846436
Validation loss: 2.0461233655611673

Epoch: 5| Step: 7
Training loss: 1.5763190984725952
Validation loss: 2.0614038358132043

Epoch: 5| Step: 8
Training loss: 1.2168924808502197
Validation loss: 2.1230361064275107

Epoch: 5| Step: 9
Training loss: 1.9297033548355103
Validation loss: 2.1010458717743554

Epoch: 5| Step: 10
Training loss: 1.5948209762573242
Validation loss: 2.1262266288201013

Epoch: 5| Step: 11
Training loss: 0.5238374471664429
Validation loss: 2.1274229139089584

Epoch: 163| Step: 0
Training loss: 1.433654546737671
Validation loss: 2.1372892508904138

Epoch: 5| Step: 1
Training loss: 1.5793447494506836
Validation loss: 2.118009626865387

Epoch: 5| Step: 2
Training loss: 1.7704471349716187
Validation loss: 2.11999174952507

Epoch: 5| Step: 3
Training loss: 1.3169419765472412
Validation loss: 2.1523175140221915

Epoch: 5| Step: 4
Training loss: 1.105297565460205
Validation loss: 2.0845488558212915

Epoch: 5| Step: 5
Training loss: 1.480851411819458
Validation loss: 2.1396413495143256

Epoch: 5| Step: 6
Training loss: 1.1613762378692627
Validation loss: 2.0905988663434982

Epoch: 5| Step: 7
Training loss: 1.8283056020736694
Validation loss: 2.0907323360443115

Epoch: 5| Step: 8
Training loss: 1.5205657482147217
Validation loss: 2.1126151780287423

Epoch: 5| Step: 9
Training loss: 1.5597310066223145
Validation loss: 2.087257797519366

Epoch: 5| Step: 10
Training loss: 1.4102376699447632
Validation loss: 2.126054063439369

Epoch: 5| Step: 11
Training loss: 1.7361581325531006
Validation loss: 2.132602488001188

Epoch: 164| Step: 0
Training loss: 1.0589762926101685
Validation loss: 2.130432923634847

Epoch: 5| Step: 1
Training loss: 1.6178219318389893
Validation loss: 2.087044765551885

Epoch: 5| Step: 2
Training loss: 1.2583088874816895
Validation loss: 2.116581862171491

Epoch: 5| Step: 3
Training loss: 1.5196110010147095
Validation loss: 2.118601515889168

Epoch: 5| Step: 4
Training loss: 1.1957762241363525
Validation loss: 2.084851304690043

Epoch: 5| Step: 5
Training loss: 1.4573200941085815
Validation loss: 2.1027028461297355

Epoch: 5| Step: 6
Training loss: 1.545473337173462
Validation loss: 2.0806442350149155

Epoch: 5| Step: 7
Training loss: 1.1473798751831055
Validation loss: 2.0943556080261865

Epoch: 5| Step: 8
Training loss: 1.7027156352996826
Validation loss: 2.1004288345575333

Epoch: 5| Step: 9
Training loss: 1.6929727792739868
Validation loss: 2.108128031094869

Epoch: 5| Step: 10
Training loss: 1.856833815574646
Validation loss: 2.1371447990338006

Epoch: 5| Step: 11
Training loss: 1.1148145198822021
Validation loss: 2.132471034924189

Epoch: 165| Step: 0
Training loss: 1.207948088645935
Validation loss: 2.132234662771225

Epoch: 5| Step: 1
Training loss: 1.1751841306686401
Validation loss: 2.137412130832672

Epoch: 5| Step: 2
Training loss: 1.6522823572158813
Validation loss: 2.0906793773174286

Epoch: 5| Step: 3
Training loss: 1.3493568897247314
Validation loss: 2.108639379342397

Epoch: 5| Step: 4
Training loss: 1.1432294845581055
Validation loss: 2.0721498479445777

Epoch: 5| Step: 5
Training loss: 1.6945539712905884
Validation loss: 2.092713395754496

Epoch: 5| Step: 6
Training loss: 1.9349730014801025
Validation loss: 2.120766525467237

Epoch: 5| Step: 7
Training loss: 1.1263962984085083
Validation loss: 2.0886327673991523

Epoch: 5| Step: 8
Training loss: 1.443190574645996
Validation loss: 2.0779971182346344

Epoch: 5| Step: 9
Training loss: 1.6483408212661743
Validation loss: 2.078438172737757

Epoch: 5| Step: 10
Training loss: 1.0327386856079102
Validation loss: 2.11453640460968

Epoch: 5| Step: 11
Training loss: 2.4716548919677734
Validation loss: 2.1190080046653748

Epoch: 166| Step: 0
Training loss: 1.2079248428344727
Validation loss: 2.106513892610868

Epoch: 5| Step: 1
Training loss: 1.4248863458633423
Validation loss: 2.0882595628499985

Epoch: 5| Step: 2
Training loss: 1.5457700490951538
Validation loss: 2.09538268049558

Epoch: 5| Step: 3
Training loss: 1.644548773765564
Validation loss: 2.0712826500336328

Epoch: 5| Step: 4
Training loss: 1.8184973001480103
Validation loss: 2.099965731302897

Epoch: 5| Step: 5
Training loss: 1.5960441827774048
Validation loss: 2.0843460957209268

Epoch: 5| Step: 6
Training loss: 1.4254415035247803
Validation loss: 2.1190398236115775

Epoch: 5| Step: 7
Training loss: 0.9516045451164246
Validation loss: 2.0864051431417465

Epoch: 5| Step: 8
Training loss: 1.4114856719970703
Validation loss: 2.0964475323756537

Epoch: 5| Step: 9
Training loss: 1.1287224292755127
Validation loss: 2.0860963662465415

Epoch: 5| Step: 10
Training loss: 1.391782522201538
Validation loss: 2.131658762693405

Epoch: 5| Step: 11
Training loss: 1.5529361963272095
Validation loss: 2.0803506275018058

Epoch: 167| Step: 0
Training loss: 1.4391214847564697
Validation loss: 2.0986124773820243

Epoch: 5| Step: 1
Training loss: 1.1477196216583252
Validation loss: 2.134498586257299

Epoch: 5| Step: 2
Training loss: 1.4988820552825928
Validation loss: 2.1705462634563446

Epoch: 5| Step: 3
Training loss: 2.4333386421203613
Validation loss: 2.197080006202062

Epoch: 5| Step: 4
Training loss: 1.3476096391677856
Validation loss: 2.1646485875050225

Epoch: 5| Step: 5
Training loss: 1.2455965280532837
Validation loss: 2.1658095518747964

Epoch: 5| Step: 6
Training loss: 1.4551266431808472
Validation loss: 2.160037249326706

Epoch: 5| Step: 7
Training loss: 1.1774132251739502
Validation loss: 2.13923309246699

Epoch: 5| Step: 8
Training loss: 1.3601030111312866
Validation loss: 2.1156976372003555

Epoch: 5| Step: 9
Training loss: 0.6594331860542297
Validation loss: 2.1181233127911887

Epoch: 5| Step: 10
Training loss: 1.5732533931732178
Validation loss: 2.055073007941246

Epoch: 5| Step: 11
Training loss: 2.9204506874084473
Validation loss: 2.0992218454678855

Epoch: 168| Step: 0
Training loss: 0.9812746047973633
Validation loss: 2.114385555187861

Epoch: 5| Step: 1
Training loss: 1.1833715438842773
Validation loss: 2.1043739517529807

Epoch: 5| Step: 2
Training loss: 1.2986962795257568
Validation loss: 2.1100393682718277

Epoch: 5| Step: 3
Training loss: 1.2838534116744995
Validation loss: 2.129681477944056

Epoch: 5| Step: 4
Training loss: 1.3786811828613281
Validation loss: 2.1774246593316398

Epoch: 5| Step: 5
Training loss: 1.0917388200759888
Validation loss: 2.160041406750679

Epoch: 5| Step: 6
Training loss: 1.528352975845337
Validation loss: 2.1536439259847007

Epoch: 5| Step: 7
Training loss: 1.4544665813446045
Validation loss: 2.167895639936129

Epoch: 5| Step: 8
Training loss: 1.422350525856018
Validation loss: 2.1573477586110434

Epoch: 5| Step: 9
Training loss: 1.44692862033844
Validation loss: 2.111274073521296

Epoch: 5| Step: 10
Training loss: 2.5468478202819824
Validation loss: 2.0762888193130493

Epoch: 5| Step: 11
Training loss: 1.2714604139328003
Validation loss: 2.0331702331701913

Epoch: 169| Step: 0
Training loss: 1.857458472251892
Validation loss: 2.0781006515026093

Epoch: 5| Step: 1
Training loss: 1.2043136358261108
Validation loss: 2.0797009418408074

Epoch: 5| Step: 2
Training loss: 1.6545225381851196
Validation loss: 2.0731056233247123

Epoch: 5| Step: 3
Training loss: 1.303177833557129
Validation loss: 2.1071414848168692

Epoch: 5| Step: 4
Training loss: 1.0561803579330444
Validation loss: 2.103142018119494

Epoch: 5| Step: 5
Training loss: 1.4944753646850586
Validation loss: 2.151267498731613

Epoch: 5| Step: 6
Training loss: 2.144535779953003
Validation loss: 2.1410546799500785

Epoch: 5| Step: 7
Training loss: 1.5441982746124268
Validation loss: 2.167372077703476

Epoch: 5| Step: 8
Training loss: 0.7722717523574829
Validation loss: 2.104939674337705

Epoch: 5| Step: 9
Training loss: 1.7579110860824585
Validation loss: 2.122145732243856

Epoch: 5| Step: 10
Training loss: 1.2785654067993164
Validation loss: 2.130330150326093

Epoch: 5| Step: 11
Training loss: 1.0757070779800415
Validation loss: 2.0471512426932654

Epoch: 170| Step: 0
Training loss: 1.5348408222198486
Validation loss: 2.076053023338318

Epoch: 5| Step: 1
Training loss: 1.3335249423980713
Validation loss: 2.057976002494494

Epoch: 5| Step: 2
Training loss: 1.491445541381836
Validation loss: 2.0759639938672385

Epoch: 5| Step: 3
Training loss: 1.5054851770401
Validation loss: 2.0488965014616647

Epoch: 5| Step: 4
Training loss: 1.172237753868103
Validation loss: 2.073197548588117

Epoch: 5| Step: 5
Training loss: 1.0913221836090088
Validation loss: 2.0890487829844155

Epoch: 5| Step: 6
Training loss: 1.168653130531311
Validation loss: 2.0283696403106055

Epoch: 5| Step: 7
Training loss: 1.198829174041748
Validation loss: 2.0587157209714255

Epoch: 5| Step: 8
Training loss: 2.081080436706543
Validation loss: 2.14129309852918

Epoch: 5| Step: 9
Training loss: 1.0894116163253784
Validation loss: 2.178226888179779

Epoch: 5| Step: 10
Training loss: 1.8088724613189697
Validation loss: 2.1864177882671356

Epoch: 5| Step: 11
Training loss: 2.045466899871826
Validation loss: 2.2249848941961923

Epoch: 171| Step: 0
Training loss: 2.0328192710876465
Validation loss: 2.210927724838257

Epoch: 5| Step: 1
Training loss: 2.1313822269439697
Validation loss: 2.212336073319117

Epoch: 5| Step: 2
Training loss: 1.3565342426300049
Validation loss: 2.1249426106611886

Epoch: 5| Step: 3
Training loss: 1.611980676651001
Validation loss: 2.1187651256720224

Epoch: 5| Step: 4
Training loss: 1.2623974084854126
Validation loss: 2.119151179989179

Epoch: 5| Step: 5
Training loss: 0.7443681955337524
Validation loss: 2.090969373782476

Epoch: 5| Step: 6
Training loss: 1.2663791179656982
Validation loss: 2.0664392908414206

Epoch: 5| Step: 7
Training loss: 1.3412294387817383
Validation loss: 2.072100907564163

Epoch: 5| Step: 8
Training loss: 1.3706796169281006
Validation loss: 2.054805353283882

Epoch: 5| Step: 9
Training loss: 0.9545595049858093
Validation loss: 2.033371408780416

Epoch: 5| Step: 10
Training loss: 1.4737575054168701
Validation loss: 2.035966540376345

Epoch: 5| Step: 11
Training loss: 0.9493438005447388
Validation loss: 2.1053971648216248

Epoch: 172| Step: 0
Training loss: 0.8831706047058105
Validation loss: 2.060943305492401

Epoch: 5| Step: 1
Training loss: 1.2811305522918701
Validation loss: 2.1071827560663223

Epoch: 5| Step: 2
Training loss: 1.1928926706314087
Validation loss: 2.104809711376826

Epoch: 5| Step: 3
Training loss: 0.7994004487991333
Validation loss: 2.0925419678290686

Epoch: 5| Step: 4
Training loss: 1.2951726913452148
Validation loss: 2.13864636917909

Epoch: 5| Step: 5
Training loss: 1.6901874542236328
Validation loss: 2.1074065566062927

Epoch: 5| Step: 6
Training loss: 1.3404706716537476
Validation loss: 2.1053612579902015

Epoch: 5| Step: 7
Training loss: 1.6886990070343018
Validation loss: 2.0699862788120904

Epoch: 5| Step: 8
Training loss: 1.4119398593902588
Validation loss: 2.074351037542025

Epoch: 5| Step: 9
Training loss: 1.4377557039260864
Validation loss: 2.1087284833192825

Epoch: 5| Step: 10
Training loss: 1.827043890953064
Validation loss: 2.0845826814572015

Epoch: 5| Step: 11
Training loss: 2.2490181922912598
Validation loss: 2.082290068268776

Epoch: 173| Step: 0
Training loss: 1.6720329523086548
Validation loss: 2.077022055784861

Epoch: 5| Step: 1
Training loss: 1.2641148567199707
Validation loss: 2.0372132609287896

Epoch: 5| Step: 2
Training loss: 1.2848767042160034
Validation loss: 2.0670369366804757

Epoch: 5| Step: 3
Training loss: 1.0588970184326172
Validation loss: 2.0733720461527505

Epoch: 5| Step: 4
Training loss: 1.228428602218628
Validation loss: 2.0990610818068185

Epoch: 5| Step: 5
Training loss: 1.7111828327178955
Validation loss: 2.0775461296240487

Epoch: 5| Step: 6
Training loss: 2.331885576248169
Validation loss: 2.093628058830897

Epoch: 5| Step: 7
Training loss: 1.2978875637054443
Validation loss: 2.085122341910998

Epoch: 5| Step: 8
Training loss: 1.2094494104385376
Validation loss: 2.071113641063372

Epoch: 5| Step: 9
Training loss: 1.341229796409607
Validation loss: 2.0846686710913978

Epoch: 5| Step: 10
Training loss: 1.0934900045394897
Validation loss: 2.0891401171684265

Epoch: 5| Step: 11
Training loss: 0.3489534854888916
Validation loss: 2.0487554520368576

Epoch: 174| Step: 0
Training loss: 1.2901779413223267
Validation loss: 2.067870537439982

Epoch: 5| Step: 1
Training loss: 1.5617141723632812
Validation loss: 2.046692728996277

Epoch: 5| Step: 2
Training loss: 1.806976318359375
Validation loss: 2.0961221555868783

Epoch: 5| Step: 3
Training loss: 1.007581353187561
Validation loss: 2.091384465495745

Epoch: 5| Step: 4
Training loss: 1.5452535152435303
Validation loss: 2.1107391317685447

Epoch: 5| Step: 5
Training loss: 1.6590667963027954
Validation loss: 2.133343974749247

Epoch: 5| Step: 6
Training loss: 1.382070541381836
Validation loss: 2.117776075998942

Epoch: 5| Step: 7
Training loss: 1.2072985172271729
Validation loss: 2.1294405361016593

Epoch: 5| Step: 8
Training loss: 1.5265905857086182
Validation loss: 2.114947095513344

Epoch: 5| Step: 9
Training loss: 0.7857480645179749
Validation loss: 2.0925903022289276

Epoch: 5| Step: 10
Training loss: 1.1149821281433105
Validation loss: 2.0913886427879333

Epoch: 5| Step: 11
Training loss: 1.630621075630188
Validation loss: 2.0746193478504815

Epoch: 175| Step: 0
Training loss: 1.165724754333496
Validation loss: 2.1052023669083915

Epoch: 5| Step: 1
Training loss: 1.2243820428848267
Validation loss: 2.0833199123541513

Epoch: 5| Step: 2
Training loss: 1.5008236169815063
Validation loss: 2.102486545840899

Epoch: 5| Step: 3
Training loss: 1.4262555837631226
Validation loss: 2.090494026740392

Epoch: 5| Step: 4
Training loss: 1.407730221748352
Validation loss: 2.1325749655564628

Epoch: 5| Step: 5
Training loss: 1.4542958736419678
Validation loss: 2.096801310777664

Epoch: 5| Step: 6
Training loss: 1.8655815124511719
Validation loss: 2.088205153743426

Epoch: 5| Step: 7
Training loss: 1.1036165952682495
Validation loss: 2.0705814411242804

Epoch: 5| Step: 8
Training loss: 1.0830379724502563
Validation loss: 2.1063517133394876

Epoch: 5| Step: 9
Training loss: 1.5243695974349976
Validation loss: 2.062112038334211

Epoch: 5| Step: 10
Training loss: 1.135258436203003
Validation loss: 2.092849021156629

Epoch: 5| Step: 11
Training loss: 1.6975553035736084
Validation loss: 2.1220077872276306

Testing loss: 2.091593719214844
